Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 0.5072868466377258
Batch 2/64 loss: 0.42321115732192993
Batch 3/64 loss: 0.40275728702545166
Batch 4/64 loss: 0.39522039890289307
Batch 5/64 loss: 0.39230358600616455
Batch 6/64 loss: 0.39013803005218506
Batch 7/64 loss: 0.3900423049926758
Batch 8/64 loss: 0.3894879221916199
Batch 9/64 loss: 0.38869303464889526
Batch 10/64 loss: 0.3884636163711548
Batch 11/64 loss: 0.3889390230178833
Batch 12/64 loss: 0.3875531554222107
Batch 13/64 loss: 0.3869994878768921
Batch 14/64 loss: 0.38791775703430176
Batch 15/64 loss: 0.38680386543273926
Batch 16/64 loss: 0.38749122619628906
Batch 17/64 loss: 0.3864328861236572
Batch 18/64 loss: 0.38618600368499756
Batch 19/64 loss: 0.3868192434310913
Batch 20/64 loss: 0.3867436647415161
Batch 21/64 loss: 0.3866081237792969
Batch 22/64 loss: 0.3862220048904419
Batch 23/64 loss: 0.38536006212234497
Batch 24/64 loss: 0.38542473316192627
Batch 25/64 loss: 0.38591641187667847
Batch 26/64 loss: 0.3851901888847351
Batch 27/64 loss: 0.3873680830001831
Batch 28/64 loss: 0.3846067786216736
Batch 29/64 loss: 0.38514238595962524
Batch 30/64 loss: 0.3849634528160095
Batch 31/64 loss: 0.38539057970046997
Batch 32/64 loss: 0.3844568729400635
Batch 33/64 loss: 0.38434135913848877
Batch 34/64 loss: 0.3845479488372803
Batch 35/64 loss: 0.38414299488067627
Batch 36/64 loss: 0.3848686218261719
Batch 37/64 loss: 0.384851336479187
Batch 38/64 loss: 0.38507503271102905
Batch 39/64 loss: 0.38458430767059326
Batch 40/64 loss: 0.3839677572250366
Batch 41/64 loss: 0.38372135162353516
Batch 42/64 loss: 0.38416367769241333
Batch 43/64 loss: 0.384177029132843
Batch 44/64 loss: 0.38463664054870605
Batch 45/64 loss: 0.3839973211288452
Batch 46/64 loss: 0.3837273120880127
Batch 47/64 loss: 0.3839263319969177
Batch 48/64 loss: 0.3828458786010742
Batch 49/64 loss: 0.3832838535308838
Batch 50/64 loss: 0.384182870388031
Batch 51/64 loss: 0.3841909170150757
Batch 52/64 loss: 0.3836607336997986
Batch 53/64 loss: 0.3838547468185425
Batch 54/64 loss: 0.38333308696746826
Batch 55/64 loss: 0.38335931301116943
Batch 56/64 loss: 0.38511693477630615
Batch 57/64 loss: 0.38225412368774414
Batch 58/64 loss: 0.3847392201423645
Batch 59/64 loss: 0.3831822872161865
Batch 60/64 loss: 0.383053183555603
Batch 61/64 loss: 0.3822338581085205
Batch 62/64 loss: 0.3829686641693115
Batch 63/64 loss: 0.38252484798431396
Batch 64/64 loss: 0.38374119997024536
Epoch 1  Train loss: 0.38828956262738096  Val loss: 0.3838802758361056
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 0.38254523277282715
Batch 2/64 loss: 0.38311898708343506
Batch 3/64 loss: 0.3829801082611084
Batch 4/64 loss: 0.38248419761657715
Batch 5/64 loss: 0.38283783197402954
Batch 6/64 loss: 0.3821795582771301
Batch 7/64 loss: 0.38395917415618896
Batch 8/64 loss: 0.3824406862258911
Batch 9/64 loss: 0.382945716381073
Batch 10/64 loss: 0.38261330127716064
Batch 11/64 loss: 0.38285255432128906
Batch 12/64 loss: 0.38148069381713867
Batch 13/64 loss: 0.3829003572463989
Batch 14/64 loss: 0.3802705407142639
Batch 15/64 loss: 0.38216066360473633
Batch 16/64 loss: 0.3811072111129761
Batch 17/64 loss: 0.3832939863204956
Batch 18/64 loss: 0.3812434673309326
Batch 19/64 loss: 0.3802525997161865
Batch 20/64 loss: 0.38147610425949097
Batch 21/64 loss: 0.3807162046432495
Batch 22/64 loss: 0.3814573287963867
Batch 23/64 loss: 0.38174086809158325
Batch 24/64 loss: 0.38217341899871826
Batch 25/64 loss: 0.381062388420105
Batch 26/64 loss: 0.38069355487823486
Batch 27/64 loss: 0.3818659782409668
Batch 28/64 loss: 0.38159847259521484
Batch 29/64 loss: 0.38048553466796875
Batch 30/64 loss: 0.38137710094451904
Batch 31/64 loss: 0.379966676235199
Batch 32/64 loss: 0.3806132674217224
Batch 33/64 loss: 0.3802785873413086
Batch 34/64 loss: 0.3809385895729065
Batch 35/64 loss: 0.3788996934890747
Batch 36/64 loss: 0.3816503882408142
Batch 37/64 loss: 0.3808211088180542
Batch 38/64 loss: 0.3811250329017639
Batch 39/64 loss: 0.3806886076927185
Batch 40/64 loss: 0.3805781602859497
Batch 41/64 loss: 0.38112545013427734
Batch 42/64 loss: 0.38034582138061523
Batch 43/64 loss: 0.3805042505264282
Batch 44/64 loss: 0.3799368143081665
Batch 45/64 loss: 0.37820661067962646
Batch 46/64 loss: 0.3799320459365845
Batch 47/64 loss: 0.37872469425201416
Batch 48/64 loss: 0.38077354431152344
Batch 49/64 loss: 0.3795626163482666
Batch 50/64 loss: 0.38060927391052246
Batch 51/64 loss: 0.3801640272140503
Batch 52/64 loss: 0.3793066740036011
Batch 53/64 loss: 0.3802416920661926
Batch 54/64 loss: 0.3801448941230774
Batch 55/64 loss: 0.3783172369003296
Batch 56/64 loss: 0.37774574756622314
Batch 57/64 loss: 0.38090944290161133
Batch 58/64 loss: 0.37730151414871216
Batch 59/64 loss: 0.37961244583129883
Batch 60/64 loss: 0.3810896873474121
Batch 61/64 loss: 0.3794093132019043
Batch 62/64 loss: 0.37812507152557373
Batch 63/64 loss: 0.379988431930542
Batch 64/64 loss: 0.3791847229003906
Epoch 2  Train loss: 0.38086807494070013  Val loss: 0.37956895369434684
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 0.3799915313720703
Batch 2/64 loss: 0.3785528540611267
Batch 3/64 loss: 0.37820953130722046
Batch 4/64 loss: 0.3786047101020813
Batch 5/64 loss: 0.37795424461364746
Batch 6/64 loss: 0.379793643951416
Batch 7/64 loss: 0.378254771232605
Batch 8/64 loss: 0.378864049911499
Batch 9/64 loss: 0.37842321395874023
Batch 10/64 loss: 0.3786390423774719
Batch 11/64 loss: 0.37766730785369873
Batch 12/64 loss: 0.3780917525291443
Batch 13/64 loss: 0.3785417675971985
Batch 14/64 loss: 0.3799683451652527
Batch 15/64 loss: 0.3792942762374878
Batch 16/64 loss: 0.37901628017425537
Batch 17/64 loss: 0.3789151906967163
Batch 18/64 loss: 0.3791508674621582
Batch 19/64 loss: 0.37951886653900146
Batch 20/64 loss: 0.37841951847076416
Batch 21/64 loss: 0.3796745538711548
Batch 22/64 loss: 0.3793220520019531
Batch 23/64 loss: 0.3777151107788086
Batch 24/64 loss: 0.37811583280563354
Batch 25/64 loss: 0.3792332410812378
Batch 26/64 loss: 0.37886595726013184
Batch 27/64 loss: 0.37879031896591187
Batch 28/64 loss: 0.37690913677215576
Batch 29/64 loss: 0.3779590129852295
Batch 30/64 loss: 0.37875449657440186
Batch 31/64 loss: 0.37787872552871704
Batch 32/64 loss: 0.3778313398361206
Batch 33/64 loss: 0.3767186403274536
Batch 34/64 loss: 0.37916767597198486
Batch 35/64 loss: 0.3777649402618408
Batch 36/64 loss: 0.37820965051651
Batch 37/64 loss: 0.3763076066970825
Batch 38/64 loss: 0.37726426124572754
Batch 39/64 loss: 0.37878990173339844
Batch 40/64 loss: 0.3789561986923218
Batch 41/64 loss: 0.37720078229904175
Batch 42/64 loss: 0.37777823209762573
Batch 43/64 loss: 0.378196656703949
Batch 44/64 loss: 0.37823086977005005
Batch 45/64 loss: 0.37738513946533203
Batch 46/64 loss: 0.3799685835838318
Batch 47/64 loss: 0.3787119388580322
Batch 48/64 loss: 0.377774715423584
Batch 49/64 loss: 0.3786481022834778
Batch 50/64 loss: 0.3780256509780884
Batch 51/64 loss: 0.37582623958587646
Batch 52/64 loss: 0.37656623125076294
Batch 53/64 loss: 0.37904632091522217
Batch 54/64 loss: 0.3767528533935547
Batch 55/64 loss: 0.37734317779541016
Batch 56/64 loss: 0.3792381286621094
Batch 57/64 loss: 0.3787330389022827
Batch 58/64 loss: 0.378673791885376
Batch 59/64 loss: 0.37866663932800293
Batch 60/64 loss: 0.3777916431427002
Batch 61/64 loss: 0.3780137300491333
Batch 62/64 loss: 0.3777744770050049
Batch 63/64 loss: 0.3777315616607666
Batch 64/64 loss: 0.37813669443130493
Epoch 3  Train loss: 0.3783181403197494  Val loss: 0.37720307574649037
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 0.3763771057128906
Batch 2/64 loss: 0.3792279362678528
Batch 3/64 loss: 0.3780035376548767
Batch 4/64 loss: 0.37708520889282227
Batch 5/64 loss: 0.37707293033599854
Batch 6/64 loss: 0.37899500131607056
Batch 7/64 loss: 0.37842124700546265
Batch 8/64 loss: 0.37671637535095215
Batch 9/64 loss: 0.37888264656066895
Batch 10/64 loss: 0.37828850746154785
Batch 11/64 loss: 0.3786460757255554
Batch 12/64 loss: 0.3757138252258301
Batch 13/64 loss: 0.37704604864120483
Batch 14/64 loss: 0.37459826469421387
Batch 15/64 loss: 0.3771883249282837
Batch 16/64 loss: 0.37615257501602173
Batch 17/64 loss: 0.37950944900512695
Batch 18/64 loss: 0.37587839365005493
Batch 19/64 loss: 0.3768017292022705
Batch 20/64 loss: 0.3742564916610718
Batch 21/64 loss: 0.37824785709381104
Batch 22/64 loss: 0.3785027265548706
Batch 23/64 loss: 0.3757505416870117
Batch 24/64 loss: 0.3778953552246094
Batch 25/64 loss: 0.37702298164367676
Batch 26/64 loss: 0.3771008253097534
Batch 27/64 loss: 0.37665075063705444
Batch 28/64 loss: 0.37577927112579346
Batch 29/64 loss: 0.3766077756881714
Batch 30/64 loss: 0.37520670890808105
Batch 31/64 loss: 0.37871503829956055
Batch 32/64 loss: 0.37386876344680786
Batch 33/64 loss: 0.3770030736923218
Batch 34/64 loss: 0.3758167028427124
Batch 35/64 loss: 0.37643158435821533
Batch 36/64 loss: 0.3770357370376587
Batch 37/64 loss: 0.37720268964767456
Batch 38/64 loss: 0.3771580457687378
Batch 39/64 loss: 0.3758094310760498
Batch 40/64 loss: 0.37644702196121216
Batch 41/64 loss: 0.3746457099914551
Batch 42/64 loss: 0.37548792362213135
Batch 43/64 loss: 0.3753129839897156
Batch 44/64 loss: 0.3763357996940613
Batch 45/64 loss: 0.37483227252960205
Batch 46/64 loss: 0.378115177154541
Batch 47/64 loss: 0.3758387565612793
Batch 48/64 loss: 0.3782879114151001
Batch 49/64 loss: 0.37637048959732056
Batch 50/64 loss: 0.37688779830932617
Batch 51/64 loss: 0.37434226274490356
Batch 52/64 loss: 0.37466859817504883
Batch 53/64 loss: 0.3754321336746216
Batch 54/64 loss: 0.3748966455459595
Batch 55/64 loss: 0.3746582865715027
Batch 56/64 loss: 0.3759028911590576
Batch 57/64 loss: 0.3760967254638672
Batch 58/64 loss: 0.377341628074646
Batch 59/64 loss: 0.37781625986099243
Batch 60/64 loss: 0.3756701946258545
Batch 61/64 loss: 0.3753480911254883
Batch 62/64 loss: 0.377170205116272
Batch 63/64 loss: 0.3762475252151489
Batch 64/64 loss: 0.3768308162689209
Epoch 4  Train loss: 0.3766187284507003  Val loss: 0.3759119649932966
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 0.3747863173484802
Batch 2/64 loss: 0.3762401342391968
Batch 3/64 loss: 0.3748713731765747
Batch 4/64 loss: 0.3749999403953552
Batch 5/64 loss: 0.3778696060180664
Batch 6/64 loss: 0.37686222791671753
Batch 7/64 loss: 0.3764857053756714
Batch 8/64 loss: 0.37651658058166504
Batch 9/64 loss: 0.3751579523086548
Batch 10/64 loss: 0.37225341796875
Batch 11/64 loss: 0.3724559545516968
Batch 12/64 loss: 0.3761255145072937
Batch 13/64 loss: 0.3746300935745239
Batch 14/64 loss: 0.3738970160484314
Batch 15/64 loss: 0.37339532375335693
Batch 16/64 loss: 0.3761598467826843
Batch 17/64 loss: 0.3754563331604004
Batch 18/64 loss: 0.37562263011932373
Batch 19/64 loss: 0.37593603134155273
Batch 20/64 loss: 0.3744863271713257
Batch 21/64 loss: 0.37510526180267334
Batch 22/64 loss: 0.37503308057785034
Batch 23/64 loss: 0.3754899501800537
Batch 24/64 loss: 0.37485694885253906
Batch 25/64 loss: 0.3756387233734131
Batch 26/64 loss: 0.3743624687194824
Batch 27/64 loss: 0.37418049573898315
Batch 28/64 loss: 0.3735737204551697
Batch 29/64 loss: 0.3745105266571045
Batch 30/64 loss: 0.37578272819519043
Batch 31/64 loss: 0.37361085414886475
Batch 32/64 loss: 0.3728383779525757
Batch 33/64 loss: 0.37544870376586914
Batch 34/64 loss: 0.3749504089355469
Batch 35/64 loss: 0.3734232187271118
Batch 36/64 loss: 0.37420928478240967
Batch 37/64 loss: 0.3748505115509033
Batch 38/64 loss: 0.37605297565460205
Batch 39/64 loss: 0.37619805335998535
Batch 40/64 loss: 0.37209367752075195
Batch 41/64 loss: 0.3740365505218506
Batch 42/64 loss: 0.3755838871002197
Batch 43/64 loss: 0.3743414878845215
Batch 44/64 loss: 0.3747164011001587
Batch 45/64 loss: 0.375149130821228
Batch 46/64 loss: 0.3735220432281494
Batch 47/64 loss: 0.3742581605911255
Batch 48/64 loss: 0.37368738651275635
Batch 49/64 loss: 0.3765578269958496
Batch 50/64 loss: 0.3732093572616577
Batch 51/64 loss: 0.3754246234893799
Batch 52/64 loss: 0.37261104583740234
Batch 53/64 loss: 0.3729820251464844
Batch 54/64 loss: 0.37526214122772217
Batch 55/64 loss: 0.37450623512268066
Batch 56/64 loss: 0.3728339672088623
Batch 57/64 loss: 0.37439703941345215
Batch 58/64 loss: 0.3767697215080261
Batch 59/64 loss: 0.37862682342529297
Batch 60/64 loss: 0.3746473789215088
Batch 61/64 loss: 0.37418973445892334
Batch 62/64 loss: 0.3728083372116089
Batch 63/64 loss: 0.3751908540725708
Batch 64/64 loss: 0.37599116563796997
Epoch 5  Train loss: 0.37480351106793275  Val loss: 0.3752184768312985
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 0.37421882152557373
Batch 2/64 loss: 0.3736610412597656
Batch 3/64 loss: 0.37411928176879883
Batch 4/64 loss: 0.37429285049438477
Batch 5/64 loss: 0.3737044930458069
Batch 6/64 loss: 0.37358760833740234
Batch 7/64 loss: 0.3741506338119507
Batch 8/64 loss: 0.3740738034248352
Batch 9/64 loss: 0.3756029009819031
Batch 10/64 loss: 0.37445300817489624
Batch 11/64 loss: 0.37422794103622437
Batch 12/64 loss: 0.3746812343597412
Batch 13/64 loss: 0.3745678663253784
Batch 14/64 loss: 0.37193453311920166
Batch 15/64 loss: 0.37483423948287964
Batch 16/64 loss: 0.3740854263305664
Batch 17/64 loss: 0.37519556283950806
Batch 18/64 loss: 0.37257349491119385
Batch 19/64 loss: 0.3717963695526123
Batch 20/64 loss: 0.37154340744018555
Batch 21/64 loss: 0.3743399381637573
Batch 22/64 loss: 0.37305641174316406
Batch 23/64 loss: 0.37383317947387695
Batch 24/64 loss: 0.372427761554718
Batch 25/64 loss: 0.3731292486190796
Batch 26/64 loss: 0.37264716625213623
Batch 27/64 loss: 0.3740556836128235
Batch 28/64 loss: 0.3721521496772766
Batch 29/64 loss: 0.3726142644882202
Batch 30/64 loss: 0.37495970726013184
Batch 31/64 loss: 0.3750675916671753
Batch 32/64 loss: 0.37337565422058105
Batch 33/64 loss: 0.37322354316711426
Batch 34/64 loss: 0.374492883682251
Batch 35/64 loss: 0.3746609687805176
Batch 36/64 loss: 0.3720266819000244
Batch 37/64 loss: 0.3740282654762268
Batch 38/64 loss: 0.37254536151885986
Batch 39/64 loss: 0.37382763624191284
Batch 40/64 loss: 0.3735552430152893
Batch 41/64 loss: 0.37131810188293457
Batch 42/64 loss: 0.37482500076293945
Batch 43/64 loss: 0.37358129024505615
Batch 44/64 loss: 0.37394213676452637
Batch 45/64 loss: 0.3730955123901367
Batch 46/64 loss: 0.37305450439453125
Batch 47/64 loss: 0.3752833604812622
Batch 48/64 loss: 0.371063768863678
Batch 49/64 loss: 0.37261879444122314
Batch 50/64 loss: 0.37323617935180664
Batch 51/64 loss: 0.37259602546691895
Batch 52/64 loss: 0.3712577819824219
Batch 53/64 loss: 0.37211692333221436
Batch 54/64 loss: 0.3748403787612915
Batch 55/64 loss: 0.3737797141075134
Batch 56/64 loss: 0.37495458126068115
Batch 57/64 loss: 0.37223732471466064
Batch 58/64 loss: 0.37393254041671753
Batch 59/64 loss: 0.37320518493652344
Batch 60/64 loss: 0.3734040856361389
Batch 61/64 loss: 0.3730277419090271
Batch 62/64 loss: 0.3728789687156677
Batch 63/64 loss: 0.37428849935531616
Batch 64/64 loss: 0.37135666608810425
Epoch 6  Train loss: 0.37349615307415235  Val loss: 0.3733706066698553
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.37410175800323486
Batch 2/64 loss: 0.3729759454727173
Batch 3/64 loss: 0.3713688850402832
Batch 4/64 loss: 0.37251418828964233
Batch 5/64 loss: 0.37352681159973145
Batch 6/64 loss: 0.3725653290748596
Batch 7/64 loss: 0.369407057762146
Batch 8/64 loss: 0.36931538581848145
Batch 9/64 loss: 0.37289828062057495
Batch 10/64 loss: 0.3718700408935547
Batch 11/64 loss: 0.3714170455932617
Batch 12/64 loss: 0.369073748588562
Batch 13/64 loss: 0.36999452114105225
Batch 14/64 loss: 0.37223386764526367
Batch 15/64 loss: 0.3724302649497986
Batch 16/64 loss: 0.3723665475845337
Batch 17/64 loss: 0.3728838562965393
Batch 18/64 loss: 0.3703460693359375
Batch 19/64 loss: 0.3744240999221802
Batch 20/64 loss: 0.37327396869659424
Batch 21/64 loss: 0.3729467988014221
Batch 22/64 loss: 0.3743501305580139
Batch 23/64 loss: 0.3759118318557739
Batch 24/64 loss: 0.37242013216018677
Batch 25/64 loss: 0.37470924854278564
Batch 26/64 loss: 0.37254321575164795
Batch 27/64 loss: 0.3744075298309326
Batch 28/64 loss: 0.3733674883842468
Batch 29/64 loss: 0.3726397752761841
Batch 30/64 loss: 0.3719857931137085
Batch 31/64 loss: 0.37359607219696045
Batch 32/64 loss: 0.3711053729057312
Batch 33/64 loss: 0.3745964765548706
Batch 34/64 loss: 0.3740122318267822
Batch 35/64 loss: 0.3727385997772217
Batch 36/64 loss: 0.3754268288612366
Batch 37/64 loss: 0.3721599578857422
Batch 38/64 loss: 0.36836469173431396
Batch 39/64 loss: 0.3722892999649048
Batch 40/64 loss: 0.3718111515045166
Batch 41/64 loss: 0.3744626045227051
Batch 42/64 loss: 0.37298905849456787
Batch 43/64 loss: 0.37369292974472046
Batch 44/64 loss: 0.3705843687057495
Batch 45/64 loss: 0.3707854151725769
Batch 46/64 loss: 0.3730792999267578
Batch 47/64 loss: 0.37131422758102417
Batch 48/64 loss: 0.3714030981063843
Batch 49/64 loss: 0.37153518199920654
Batch 50/64 loss: 0.37445229291915894
Batch 51/64 loss: 0.3696413040161133
Batch 52/64 loss: 0.369548499584198
Batch 53/64 loss: 0.3726719617843628
Batch 54/64 loss: 0.37071967124938965
Batch 55/64 loss: 0.369611918926239
Batch 56/64 loss: 0.37174171209335327
Batch 57/64 loss: 0.3734446167945862
Batch 58/64 loss: 0.37454283237457275
Batch 59/64 loss: 0.3720628023147583
Batch 60/64 loss: 0.3701118230819702
Batch 61/64 loss: 0.37221968173980713
Batch 62/64 loss: 0.3730321526527405
Batch 63/64 loss: 0.37238001823425293
Batch 64/64 loss: 0.37328004837036133
Epoch 7  Train loss: 0.37233502444098976  Val loss: 0.3727476760693842
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 0.37134242057800293
Batch 2/64 loss: 0.37148308753967285
Batch 3/64 loss: 0.3720594644546509
Batch 4/64 loss: 0.37261050939559937
Batch 5/64 loss: 0.3723521828651428
Batch 6/64 loss: 0.37289172410964966
Batch 7/64 loss: 0.3722172975540161
Batch 8/64 loss: 0.3714556097984314
Batch 9/64 loss: 0.3703547716140747
Batch 10/64 loss: 0.37093472480773926
Batch 11/64 loss: 0.3709273338317871
Batch 12/64 loss: 0.36813318729400635
Batch 13/64 loss: 0.37303274869918823
Batch 14/64 loss: 0.37080472707748413
Batch 15/64 loss: 0.3698931932449341
Batch 16/64 loss: 0.36908501386642456
Batch 17/64 loss: 0.37366318702697754
Batch 18/64 loss: 0.3716471791267395
Batch 19/64 loss: 0.3695446848869324
Batch 20/64 loss: 0.3728633522987366
Batch 21/64 loss: 0.3689051866531372
Batch 22/64 loss: 0.3695955276489258
Batch 23/64 loss: 0.3720506429672241
Batch 24/64 loss: 0.3704495429992676
Batch 25/64 loss: 0.373626708984375
Batch 26/64 loss: 0.37195807695388794
Batch 27/64 loss: 0.36852288246154785
Batch 28/64 loss: 0.37063276767730713
Batch 29/64 loss: 0.3689952492713928
Batch 30/64 loss: 0.3696454167366028
Batch 31/64 loss: 0.371626615524292
Batch 32/64 loss: 0.37142080068588257
Batch 33/64 loss: 0.3723258972167969
Batch 34/64 loss: 0.3706777095794678
Batch 35/64 loss: 0.37177979946136475
Batch 36/64 loss: 0.3709349036216736
Batch 37/64 loss: 0.3711048364639282
Batch 38/64 loss: 0.3694577217102051
Batch 39/64 loss: 0.3709077835083008
Batch 40/64 loss: 0.3676110506057739
Batch 41/64 loss: 0.3704538345336914
Batch 42/64 loss: 0.37166035175323486
Batch 43/64 loss: 0.36969196796417236
Batch 44/64 loss: 0.3726765513420105
Batch 45/64 loss: 0.37305283546447754
Batch 46/64 loss: 0.37150782346725464
Batch 47/64 loss: 0.3679032325744629
Batch 48/64 loss: 0.3707773685455322
Batch 49/64 loss: 0.3717624545097351
Batch 50/64 loss: 0.3738396167755127
Batch 51/64 loss: 0.3707202076911926
Batch 52/64 loss: 0.3732415437698364
Batch 53/64 loss: 0.37119126319885254
Batch 54/64 loss: 0.3694443106651306
Batch 55/64 loss: 0.3694031238555908
Batch 56/64 loss: 0.3728947639465332
Batch 57/64 loss: 0.370815634727478
Batch 58/64 loss: 0.37131863832473755
Batch 59/64 loss: 0.37194526195526123
Batch 60/64 loss: 0.37028539180755615
Batch 61/64 loss: 0.36899232864379883
Batch 62/64 loss: 0.3728037476539612
Batch 63/64 loss: 0.3704807162284851
Batch 64/64 loss: 0.3692474365234375
Epoch 8  Train loss: 0.3710325343936097  Val loss: 0.37328734840314415
Epoch 9
-------------------------------
Batch 1/64 loss: 0.3723781108856201
Batch 2/64 loss: 0.37214767932891846
Batch 3/64 loss: 0.3740333914756775
Batch 4/64 loss: 0.36793971061706543
Batch 5/64 loss: 0.37109339237213135
Batch 6/64 loss: 0.36905980110168457
Batch 7/64 loss: 0.3699219822883606
Batch 8/64 loss: 0.3707483410835266
Batch 9/64 loss: 0.3728412389755249
Batch 10/64 loss: 0.3722299337387085
Batch 11/64 loss: 0.3715543746948242
Batch 12/64 loss: 0.37149739265441895
Batch 13/64 loss: 0.37145596742630005
Batch 14/64 loss: 0.3708568215370178
Batch 15/64 loss: 0.3712330460548401
Batch 16/64 loss: 0.3678109049797058
Batch 17/64 loss: 0.36989450454711914
Batch 18/64 loss: 0.3701496720314026
Batch 19/64 loss: 0.36772000789642334
Batch 20/64 loss: 0.3739446997642517
Batch 21/64 loss: 0.370258092880249
Batch 22/64 loss: 0.3702508211135864
Batch 23/64 loss: 0.37186670303344727
Batch 24/64 loss: 0.3700767755508423
Batch 25/64 loss: 0.3690744638442993
Batch 26/64 loss: 0.3707383871078491
Batch 27/64 loss: 0.3704264163970947
Batch 28/64 loss: 0.37071943283081055
Batch 29/64 loss: 0.37141096591949463
Batch 30/64 loss: 0.37106943130493164
Batch 31/64 loss: 0.36825788021087646
Batch 32/64 loss: 0.3717951774597168
Batch 33/64 loss: 0.37214159965515137
Batch 34/64 loss: 0.3726508617401123
Batch 35/64 loss: 0.37045323848724365
Batch 36/64 loss: 0.3723348379135132
Batch 37/64 loss: 0.37133359909057617
Batch 38/64 loss: 0.3719637393951416
Batch 39/64 loss: 0.36841946840286255
Batch 40/64 loss: 0.3701828122138977
Batch 41/64 loss: 0.3715440034866333
Batch 42/64 loss: 0.3708733320236206
Batch 43/64 loss: 0.3695131540298462
Batch 44/64 loss: 0.371615469455719
Batch 45/64 loss: 0.3710235357284546
Batch 46/64 loss: 0.3695845603942871
Batch 47/64 loss: 0.3676668405532837
Batch 48/64 loss: 0.36984968185424805
Batch 49/64 loss: 0.36951667070388794
Batch 50/64 loss: 0.3693411350250244
Batch 51/64 loss: 0.3733658194541931
Batch 52/64 loss: 0.3709193468093872
Batch 53/64 loss: 0.3692525625228882
Batch 54/64 loss: 0.3710945248603821
Batch 55/64 loss: 0.3701765537261963
Batch 56/64 loss: 0.3682482838630676
Batch 57/64 loss: 0.37135612964630127
Batch 58/64 loss: 0.3707379102706909
Batch 59/64 loss: 0.3696622848510742
Batch 60/64 loss: 0.3692086935043335
Batch 61/64 loss: 0.37283360958099365
Batch 62/64 loss: 0.36661040782928467
Batch 63/64 loss: 0.3711555004119873
Batch 64/64 loss: 0.37505853176116943
Epoch 9  Train loss: 0.3706726209790099  Val loss: 0.37017530469140647
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: 0.3668893575668335
Batch 2/64 loss: 0.3692953586578369
Batch 3/64 loss: 0.36771631240844727
Batch 4/64 loss: 0.3727536201477051
Batch 5/64 loss: 0.36948323249816895
Batch 6/64 loss: 0.36796557903289795
Batch 7/64 loss: 0.3695470094680786
Batch 8/64 loss: 0.36805474758148193
Batch 9/64 loss: 0.36994004249572754
Batch 10/64 loss: 0.3709319829940796
Batch 11/64 loss: 0.3689754009246826
Batch 12/64 loss: 0.3699710965156555
Batch 13/64 loss: 0.36984050273895264
Batch 14/64 loss: 0.3703117370605469
Batch 15/64 loss: 0.3703557252883911
Batch 16/64 loss: 0.3687098026275635
Batch 17/64 loss: 0.3705679774284363
Batch 18/64 loss: 0.37078648805618286
Batch 19/64 loss: 0.3699263334274292
Batch 20/64 loss: 0.3699495792388916
Batch 21/64 loss: 0.370344877243042
Batch 22/64 loss: 0.3685256242752075
Batch 23/64 loss: 0.36964309215545654
Batch 24/64 loss: 0.3694063425064087
Batch 25/64 loss: 0.3703221082687378
Batch 26/64 loss: 0.37022829055786133
Batch 27/64 loss: 0.36973392963409424
Batch 28/64 loss: 0.3684159517288208
Batch 29/64 loss: 0.36977720260620117
Batch 30/64 loss: 0.37118780612945557
Batch 31/64 loss: 0.3686337471008301
Batch 32/64 loss: 0.37041574716567993
Batch 33/64 loss: 0.36897486448287964
Batch 34/64 loss: 0.36761748790740967
Batch 35/64 loss: 0.3669343590736389
Batch 36/64 loss: 0.36912596225738525
Batch 37/64 loss: 0.36992180347442627
Batch 38/64 loss: 0.3704495429992676
Batch 39/64 loss: 0.36856579780578613
Batch 40/64 loss: 0.36929285526275635
Batch 41/64 loss: 0.3676571846008301
Batch 42/64 loss: 0.3691020607948303
Batch 43/64 loss: 0.3702213764190674
Batch 44/64 loss: 0.3710033893585205
Batch 45/64 loss: 0.3694319725036621
Batch 46/64 loss: 0.3701028823852539
Batch 47/64 loss: 0.3669576644897461
Batch 48/64 loss: 0.3718940019607544
Batch 49/64 loss: 0.3701635003089905
Batch 50/64 loss: 0.3680992126464844
Batch 51/64 loss: 0.3707119822502136
Batch 52/64 loss: 0.3652727007865906
Batch 53/64 loss: 0.36888349056243896
Batch 54/64 loss: 0.36888575553894043
Batch 55/64 loss: 0.3676985502243042
Batch 56/64 loss: 0.369545578956604
Batch 57/64 loss: 0.3683895468711853
Batch 58/64 loss: 0.368161141872406
Batch 59/64 loss: 0.367919921875
Batch 60/64 loss: 0.36598825454711914
Batch 61/64 loss: 0.36956703662872314
Batch 62/64 loss: 0.3723030090332031
Batch 63/64 loss: 0.3694220781326294
Batch 64/64 loss: 0.3686174750328064
Epoch 10  Train loss: 0.369307210632399  Val loss: 0.3705299783408437
Epoch 11
-------------------------------
Batch 1/64 loss: 0.36777055263519287
Batch 2/64 loss: 0.37079858779907227
Batch 3/64 loss: 0.3690154552459717
Batch 4/64 loss: 0.3678874969482422
Batch 5/64 loss: 0.3679741621017456
Batch 6/64 loss: 0.3682044744491577
Batch 7/64 loss: 0.36801445484161377
Batch 8/64 loss: 0.36897075176239014
Batch 9/64 loss: 0.36672770977020264
Batch 10/64 loss: 0.3688421845436096
Batch 11/64 loss: 0.36796319484710693
Batch 12/64 loss: 0.36862635612487793
Batch 13/64 loss: 0.36814332008361816
Batch 14/64 loss: 0.3666343688964844
Batch 15/64 loss: 0.37006300687789917
Batch 16/64 loss: 0.3693169355392456
Batch 17/64 loss: 0.36884355545043945
Batch 18/64 loss: 0.37042367458343506
Batch 19/64 loss: 0.37274694442749023
Batch 20/64 loss: 0.36758893728256226
Batch 21/64 loss: 0.37081873416900635
Batch 22/64 loss: 0.3665611147880554
Batch 23/64 loss: 0.36726099252700806
Batch 24/64 loss: 0.3678090572357178
Batch 25/64 loss: 0.3669024705886841
Batch 26/64 loss: 0.37104737758636475
Batch 27/64 loss: 0.36890721321105957
Batch 28/64 loss: 0.3712390661239624
Batch 29/64 loss: 0.3685816526412964
Batch 30/64 loss: 0.37016093730926514
Batch 31/64 loss: 0.3699686527252197
Batch 32/64 loss: 0.36905622482299805
Batch 33/64 loss: 0.3702017068862915
Batch 34/64 loss: 0.3696831464767456
Batch 35/64 loss: 0.3707619905471802
Batch 36/64 loss: 0.36707013845443726
Batch 37/64 loss: 0.37123966217041016
Batch 38/64 loss: 0.37006521224975586
Batch 39/64 loss: 0.3658972978591919
Batch 40/64 loss: 0.3709782361984253
Batch 41/64 loss: 0.3698630928993225
Batch 42/64 loss: 0.36974072456359863
Batch 43/64 loss: 0.3709747791290283
Batch 44/64 loss: 0.3701976537704468
Batch 45/64 loss: 0.36925041675567627
Batch 46/64 loss: 0.370799720287323
Batch 47/64 loss: 0.37040138244628906
Batch 48/64 loss: 0.3695533275604248
Batch 49/64 loss: 0.369684100151062
Batch 50/64 loss: 0.36979758739471436
Batch 51/64 loss: 0.3671472668647766
Batch 52/64 loss: 0.37185806035995483
Batch 53/64 loss: 0.36999648809432983
Batch 54/64 loss: 0.3685910105705261
Batch 55/64 loss: 0.36841851472854614
Batch 56/64 loss: 0.3649437427520752
Batch 57/64 loss: 0.36849766969680786
Batch 58/64 loss: 0.3697180151939392
Batch 59/64 loss: 0.3680497407913208
Batch 60/64 loss: 0.3659491539001465
Batch 61/64 loss: 0.3695790767669678
Batch 62/64 loss: 0.3698016405105591
Batch 63/64 loss: 0.36771178245544434
Batch 64/64 loss: 0.36979788541793823
Epoch 11  Train loss: 0.36904533914491244  Val loss: 0.37033327707310315
Epoch 12
-------------------------------
Batch 1/64 loss: 0.3693646192550659
Batch 2/64 loss: 0.36991608142852783
Batch 3/64 loss: 0.36726105213165283
Batch 4/64 loss: 0.36873918771743774
Batch 5/64 loss: 0.3700602054595947
Batch 6/64 loss: 0.3697068691253662
Batch 7/64 loss: 0.37093496322631836
Batch 8/64 loss: 0.37129127979278564
Batch 9/64 loss: 0.36545300483703613
Batch 10/64 loss: 0.368807852268219
Batch 11/64 loss: 0.3676025867462158
Batch 12/64 loss: 0.36642688512802124
Batch 13/64 loss: 0.3696349263191223
Batch 14/64 loss: 0.37006622552871704
Batch 15/64 loss: 0.3700711727142334
Batch 16/64 loss: 0.36974066495895386
Batch 17/64 loss: 0.3681851625442505
Batch 18/64 loss: 0.3685080409049988
Batch 19/64 loss: 0.3687293529510498
Batch 20/64 loss: 0.36742883920669556
Batch 21/64 loss: 0.3678928017616272
Batch 22/64 loss: 0.36760592460632324
Batch 23/64 loss: 0.3694593906402588
Batch 24/64 loss: 0.3670704960823059
Batch 25/64 loss: 0.36789393424987793
Batch 26/64 loss: 0.3648031949996948
Batch 27/64 loss: 0.3697022795677185
Batch 28/64 loss: 0.3696522116661072
Batch 29/64 loss: 0.3688891530036926
Batch 30/64 loss: 0.3697032928466797
Batch 31/64 loss: 0.36885207891464233
Batch 32/64 loss: 0.3682937026023865
Batch 33/64 loss: 0.3666996955871582
Batch 34/64 loss: 0.36723941564559937
Batch 35/64 loss: 0.368710994720459
Batch 36/64 loss: 0.3689032196998596
Batch 37/64 loss: 0.36761194467544556
Batch 38/64 loss: 0.36960798501968384
Batch 39/64 loss: 0.3714628219604492
Batch 40/64 loss: 0.3699793815612793
Batch 41/64 loss: 0.36693501472473145
Batch 42/64 loss: 0.3701043128967285
Batch 43/64 loss: 0.3691380023956299
Batch 44/64 loss: 0.36901724338531494
Batch 45/64 loss: 0.36604177951812744
Batch 46/64 loss: 0.3699108362197876
Batch 47/64 loss: 0.36929547786712646
Batch 48/64 loss: 0.36812376976013184
Batch 49/64 loss: 0.3699818253517151
Batch 50/64 loss: 0.3700258731842041
Batch 51/64 loss: 0.36799633502960205
Batch 52/64 loss: 0.37025320529937744
Batch 53/64 loss: 0.3699451684951782
Batch 54/64 loss: 0.3720351457595825
Batch 55/64 loss: 0.36743128299713135
Batch 56/64 loss: 0.3655349016189575
Batch 57/64 loss: 0.3687080144882202
Batch 58/64 loss: 0.36673808097839355
Batch 59/64 loss: 0.3678897023200989
Batch 60/64 loss: 0.3687601685523987
Batch 61/64 loss: 0.36672312021255493
Batch 62/64 loss: 0.36626946926116943
Batch 63/64 loss: 0.36578941345214844
Batch 64/64 loss: 0.3692031502723694
Epoch 12  Train loss: 0.36858844546710745  Val loss: 0.37083175829595716
Epoch 13
-------------------------------
Batch 1/64 loss: 0.37063974142074585
Batch 2/64 loss: 0.3697788715362549
Batch 3/64 loss: 0.36871063709259033
Batch 4/64 loss: 0.3687470555305481
Batch 5/64 loss: 0.3705790042877197
Batch 6/64 loss: 0.36843764781951904
Batch 7/64 loss: 0.3674301505088806
Batch 8/64 loss: 0.36906158924102783
Batch 9/64 loss: 0.36656999588012695
Batch 10/64 loss: 0.36618828773498535
Batch 11/64 loss: 0.3658183813095093
Batch 12/64 loss: 0.36932897567749023
Batch 13/64 loss: 0.37012505531311035
Batch 14/64 loss: 0.36590009927749634
Batch 15/64 loss: 0.3701559901237488
Batch 16/64 loss: 0.3678802251815796
Batch 17/64 loss: 0.3712002635002136
Batch 18/64 loss: 0.3684743642807007
Batch 19/64 loss: 0.3685442805290222
Batch 20/64 loss: 0.367681622505188
Batch 21/64 loss: 0.36884015798568726
Batch 22/64 loss: 0.3683720827102661
Batch 23/64 loss: 0.36953258514404297
Batch 24/64 loss: 0.3668016791343689
Batch 25/64 loss: 0.36866652965545654
Batch 26/64 loss: 0.3699578046798706
Batch 27/64 loss: 0.3658043146133423
Batch 28/64 loss: 0.368818461894989
Batch 29/64 loss: 0.369398832321167
Batch 30/64 loss: 0.3658219575881958
Batch 31/64 loss: 0.3656836748123169
Batch 32/64 loss: 0.36762678623199463
Batch 33/64 loss: 0.36784279346466064
Batch 34/64 loss: 0.3683987259864807
Batch 35/64 loss: 0.36917436122894287
Batch 36/64 loss: 0.36903703212738037
Batch 37/64 loss: 0.3700668215751648
Batch 38/64 loss: 0.36748528480529785
Batch 39/64 loss: 0.3661525249481201
Batch 40/64 loss: 0.3678693175315857
Batch 41/64 loss: 0.3682376742362976
Batch 42/64 loss: 0.3669719099998474
Batch 43/64 loss: 0.370352566242218
Batch 44/64 loss: 0.36492854356765747
Batch 45/64 loss: 0.3665626645088196
Batch 46/64 loss: 0.36819136142730713
Batch 47/64 loss: 0.370200514793396
Batch 48/64 loss: 0.3659082055091858
Batch 49/64 loss: 0.36734509468078613
Batch 50/64 loss: 0.3682316541671753
Batch 51/64 loss: 0.3654191493988037
Batch 52/64 loss: 0.3659731149673462
Batch 53/64 loss: 0.3672625422477722
Batch 54/64 loss: 0.3663210868835449
Batch 55/64 loss: 0.36599045991897583
Batch 56/64 loss: 0.36659425497055054
Batch 57/64 loss: 0.36794382333755493
Batch 58/64 loss: 0.36746370792388916
Batch 59/64 loss: 0.3698430061340332
Batch 60/64 loss: 0.3678075075149536
Batch 61/64 loss: 0.3653678894042969
Batch 62/64 loss: 0.3643817901611328
Batch 63/64 loss: 0.3681034445762634
Batch 64/64 loss: 0.36515331268310547
Epoch 13  Train loss: 0.36787248499253217  Val loss: 0.3693975712015866
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: 0.3631073832511902
Batch 2/64 loss: 0.3685762882232666
Batch 3/64 loss: 0.3680884838104248
Batch 4/64 loss: 0.3692587614059448
Batch 5/64 loss: 0.3661925792694092
Batch 6/64 loss: 0.3662757873535156
Batch 7/64 loss: 0.369881272315979
Batch 8/64 loss: 0.36902862787246704
Batch 9/64 loss: 0.36879056692123413
Batch 10/64 loss: 0.3669707179069519
Batch 11/64 loss: 0.36916637420654297
Batch 12/64 loss: 0.3660270571708679
Batch 13/64 loss: 0.3670691251754761
Batch 14/64 loss: 0.3652743101119995
Batch 15/64 loss: 0.36651164293289185
Batch 16/64 loss: 0.3666718006134033
Batch 17/64 loss: 0.36810439825057983
Batch 18/64 loss: 0.3680418133735657
Batch 19/64 loss: 0.3685568571090698
Batch 20/64 loss: 0.3685188293457031
Batch 21/64 loss: 0.3722844123840332
Batch 22/64 loss: 0.36987197399139404
Batch 23/64 loss: 0.36598122119903564
Batch 24/64 loss: 0.369346559047699
Batch 25/64 loss: 0.3636590242385864
Batch 26/64 loss: 0.3669080138206482
Batch 27/64 loss: 0.3663918972015381
Batch 28/64 loss: 0.3694823384284973
Batch 29/64 loss: 0.36688345670700073
Batch 30/64 loss: 0.36879831552505493
Batch 31/64 loss: 0.3654547929763794
Batch 32/64 loss: 0.37034159898757935
Batch 33/64 loss: 0.36675167083740234
Batch 34/64 loss: 0.3662395477294922
Batch 35/64 loss: 0.36868590116500854
Batch 36/64 loss: 0.368644118309021
Batch 37/64 loss: 0.3650819659233093
Batch 38/64 loss: 0.37059515714645386
Batch 39/64 loss: 0.3672330379486084
Batch 40/64 loss: 0.3654078245162964
Batch 41/64 loss: 0.36753273010253906
Batch 42/64 loss: 0.3662172555923462
Batch 43/64 loss: 0.3683176636695862
Batch 44/64 loss: 0.36636584997177124
Batch 45/64 loss: 0.366361141204834
Batch 46/64 loss: 0.3682030439376831
Batch 47/64 loss: 0.366690993309021
Batch 48/64 loss: 0.3715320825576782
Batch 49/64 loss: 0.3665972948074341
Batch 50/64 loss: 0.3666853904724121
Batch 51/64 loss: 0.36477887630462646
Batch 52/64 loss: 0.36820101737976074
Batch 53/64 loss: 0.3681596517562866
Batch 54/64 loss: 0.36733269691467285
Batch 55/64 loss: 0.36601686477661133
Batch 56/64 loss: 0.3656041622161865
Batch 57/64 loss: 0.3626329302787781
Batch 58/64 loss: 0.36468684673309326
Batch 59/64 loss: 0.365084171295166
Batch 60/64 loss: 0.36627197265625
Batch 61/64 loss: 0.36911678314208984
Batch 62/64 loss: 0.3705672025680542
Batch 63/64 loss: 0.36503517627716064
Batch 64/64 loss: 0.36989402770996094
Epoch 14  Train loss: 0.36736576977898094  Val loss: 0.3694913084154686
Epoch 15
-------------------------------
Batch 1/64 loss: 0.3680558204650879
Batch 2/64 loss: 0.36676138639450073
Batch 3/64 loss: 0.36461639404296875
Batch 4/64 loss: 0.3715967535972595
Batch 5/64 loss: 0.36564409732818604
Batch 6/64 loss: 0.3679739236831665
Batch 7/64 loss: 0.3686257600784302
Batch 8/64 loss: 0.3671801686286926
Batch 9/64 loss: 0.36665624380111694
Batch 10/64 loss: 0.3653860092163086
Batch 11/64 loss: 0.367367148399353
Batch 12/64 loss: 0.36524057388305664
Batch 13/64 loss: 0.3679370880126953
Batch 14/64 loss: 0.3696889877319336
Batch 15/64 loss: 0.36610889434814453
Batch 16/64 loss: 0.37050437927246094
Batch 17/64 loss: 0.37161946296691895
Batch 18/64 loss: 0.36751651763916016
Batch 19/64 loss: 0.36600005626678467
Batch 20/64 loss: 0.36493104696273804
Batch 21/64 loss: 0.36678069829940796
Batch 22/64 loss: 0.36580127477645874
Batch 23/64 loss: 0.3674877882003784
Batch 24/64 loss: 0.36787736415863037
Batch 25/64 loss: 0.36783599853515625
Batch 26/64 loss: 0.36794513463974
Batch 27/64 loss: 0.36949872970581055
Batch 28/64 loss: 0.36801689863204956
Batch 29/64 loss: 0.36799585819244385
Batch 30/64 loss: 0.3692589998245239
Batch 31/64 loss: 0.36780881881713867
Batch 32/64 loss: 0.36702799797058105
Batch 33/64 loss: 0.36794358491897583
Batch 34/64 loss: 0.36754757165908813
Batch 35/64 loss: 0.3683411478996277
Batch 36/64 loss: 0.36919236183166504
Batch 37/64 loss: 0.36559343338012695
Batch 38/64 loss: 0.36786431074142456
Batch 39/64 loss: 0.36376631259918213
Batch 40/64 loss: 0.36926090717315674
Batch 41/64 loss: 0.3657947778701782
Batch 42/64 loss: 0.36959123611450195
Batch 43/64 loss: 0.3646431565284729
Batch 44/64 loss: 0.3681674599647522
Batch 45/64 loss: 0.36725175380706787
Batch 46/64 loss: 0.36725056171417236
Batch 47/64 loss: 0.36734485626220703
Batch 48/64 loss: 0.3679313659667969
Batch 49/64 loss: 0.36695969104766846
Batch 50/64 loss: 0.3641214966773987
Batch 51/64 loss: 0.3672885298728943
Batch 52/64 loss: 0.36449289321899414
Batch 53/64 loss: 0.3672202229499817
Batch 54/64 loss: 0.3650364279747009
Batch 55/64 loss: 0.3651862144470215
Batch 56/64 loss: 0.368569016456604
Batch 57/64 loss: 0.3691056966781616
Batch 58/64 loss: 0.36786866188049316
Batch 59/64 loss: 0.3647494316101074
Batch 60/64 loss: 0.3672025203704834
Batch 61/64 loss: 0.36612218618392944
Batch 62/64 loss: 0.3670605421066284
Batch 63/64 loss: 0.36480194330215454
Batch 64/64 loss: 0.3629276752471924
Epoch 15  Train loss: 0.3671876439861223  Val loss: 0.3682665960075929
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: 0.3658798336982727
Batch 2/64 loss: 0.3653526306152344
Batch 3/64 loss: 0.36790263652801514
Batch 4/64 loss: 0.3664438724517822
Batch 5/64 loss: 0.36853963136672974
Batch 6/64 loss: 0.36420750617980957
Batch 7/64 loss: 0.36791616678237915
Batch 8/64 loss: 0.36865127086639404
Batch 9/64 loss: 0.3657752275466919
Batch 10/64 loss: 0.36847829818725586
Batch 11/64 loss: 0.36732912063598633
Batch 12/64 loss: 0.36752986907958984
Batch 13/64 loss: 0.36686038970947266
Batch 14/64 loss: 0.3651461601257324
Batch 15/64 loss: 0.3660088777542114
Batch 16/64 loss: 0.36728620529174805
Batch 17/64 loss: 0.3655592203140259
Batch 18/64 loss: 0.36641740798950195
Batch 19/64 loss: 0.3680882453918457
Batch 20/64 loss: 0.36874067783355713
Batch 21/64 loss: 0.36903029680252075
Batch 22/64 loss: 0.36993157863616943
Batch 23/64 loss: 0.368366539478302
Batch 24/64 loss: 0.36964964866638184
Batch 25/64 loss: 0.3672487139701843
Batch 26/64 loss: 0.368607759475708
Batch 27/64 loss: 0.36684203147888184
Batch 28/64 loss: 0.3699023723602295
Batch 29/64 loss: 0.36842721700668335
Batch 30/64 loss: 0.36719071865081787
Batch 31/64 loss: 0.36957240104675293
Batch 32/64 loss: 0.36773085594177246
Batch 33/64 loss: 0.3661155700683594
Batch 34/64 loss: 0.36673688888549805
Batch 35/64 loss: 0.3675720691680908
Batch 36/64 loss: 0.366216778755188
Batch 37/64 loss: 0.36689019203186035
Batch 38/64 loss: 0.3689441680908203
Batch 39/64 loss: 0.36423587799072266
Batch 40/64 loss: 0.36525440216064453
Batch 41/64 loss: 0.3688942790031433
Batch 42/64 loss: 0.3683776259422302
Batch 43/64 loss: 0.3685671091079712
Batch 44/64 loss: 0.36665189266204834
Batch 45/64 loss: 0.36520326137542725
Batch 46/64 loss: 0.3676036596298218
Batch 47/64 loss: 0.36602187156677246
Batch 48/64 loss: 0.36469995975494385
Batch 49/64 loss: 0.3661375045776367
Batch 50/64 loss: 0.3655431270599365
Batch 51/64 loss: 0.36617088317871094
Batch 52/64 loss: 0.36917251348495483
Batch 53/64 loss: 0.3682934045791626
Batch 54/64 loss: 0.3663260340690613
Batch 55/64 loss: 0.3674810528755188
Batch 56/64 loss: 0.36668825149536133
Batch 57/64 loss: 0.3665506839752197
Batch 58/64 loss: 0.3647648096084595
Batch 59/64 loss: 0.36680877208709717
Batch 60/64 loss: 0.3662828207015991
Batch 61/64 loss: 0.3696278929710388
Batch 62/64 loss: 0.3679168224334717
Batch 63/64 loss: 0.3669235110282898
Batch 64/64 loss: 0.3624417185783386
Epoch 16  Train loss: 0.3671391115469091  Val loss: 0.3687822503322588
Epoch 17
-------------------------------
Batch 1/64 loss: 0.3689342737197876
Batch 2/64 loss: 0.3665584325790405
Batch 3/64 loss: 0.3646668791770935
Batch 4/64 loss: 0.3664091229438782
Batch 5/64 loss: 0.36509156227111816
Batch 6/64 loss: 0.36525529623031616
Batch 7/64 loss: 0.3655734658241272
Batch 8/64 loss: 0.3669471740722656
Batch 9/64 loss: 0.3630574941635132
Batch 10/64 loss: 0.3680729866027832
Batch 11/64 loss: 0.36684978008270264
Batch 12/64 loss: 0.366582989692688
Batch 13/64 loss: 0.3674778342247009
Batch 14/64 loss: 0.3675358295440674
Batch 15/64 loss: 0.36798936128616333
Batch 16/64 loss: 0.36714088916778564
Batch 17/64 loss: 0.3664667010307312
Batch 18/64 loss: 0.36837542057037354
Batch 19/64 loss: 0.3688792586326599
Batch 20/64 loss: 0.3642938733100891
Batch 21/64 loss: 0.3666989803314209
Batch 22/64 loss: 0.3664931654930115
Batch 23/64 loss: 0.36416876316070557
Batch 24/64 loss: 0.3642757534980774
Batch 25/64 loss: 0.3658425807952881
Batch 26/64 loss: 0.3667062520980835
Batch 27/64 loss: 0.3644171953201294
Batch 28/64 loss: 0.36622917652130127
Batch 29/64 loss: 0.36690276861190796
Batch 30/64 loss: 0.36784887313842773
Batch 31/64 loss: 0.36361241340637207
Batch 32/64 loss: 0.36455202102661133
Batch 33/64 loss: 0.3656773567199707
Batch 34/64 loss: 0.3661980628967285
Batch 35/64 loss: 0.3669808506965637
Batch 36/64 loss: 0.3651123046875
Batch 37/64 loss: 0.3656342029571533
Batch 38/64 loss: 0.36569809913635254
Batch 39/64 loss: 0.3673774003982544
Batch 40/64 loss: 0.36816608905792236
Batch 41/64 loss: 0.36927634477615356
Batch 42/64 loss: 0.3681952953338623
Batch 43/64 loss: 0.36696845293045044
Batch 44/64 loss: 0.3663785457611084
Batch 45/64 loss: 0.36701714992523193
Batch 46/64 loss: 0.36468231678009033
Batch 47/64 loss: 0.36405372619628906
Batch 48/64 loss: 0.36743849515914917
Batch 49/64 loss: 0.3678072690963745
Batch 50/64 loss: 0.3662739396095276
Batch 51/64 loss: 0.3680451512336731
Batch 52/64 loss: 0.36808693408966064
Batch 53/64 loss: 0.36881887912750244
Batch 54/64 loss: 0.3645300269126892
Batch 55/64 loss: 0.3646026849746704
Batch 56/64 loss: 0.36631810665130615
Batch 57/64 loss: 0.36724984645843506
Batch 58/64 loss: 0.3724924325942993
Batch 59/64 loss: 0.3660038709640503
Batch 60/64 loss: 0.36558032035827637
Batch 61/64 loss: 0.3646240234375
Batch 62/64 loss: 0.36757147312164307
Batch 63/64 loss: 0.3650779724121094
Batch 64/64 loss: 0.36642587184906006
Epoch 17  Train loss: 0.36647315446068257  Val loss: 0.36713923416596506
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: 0.3650989532470703
Batch 2/64 loss: 0.36637425422668457
Batch 3/64 loss: 0.36642444133758545
Batch 4/64 loss: 0.36788004636764526
Batch 5/64 loss: 0.3671060800552368
Batch 6/64 loss: 0.36411720514297485
Batch 7/64 loss: 0.3646355867385864
Batch 8/64 loss: 0.36368125677108765
Batch 9/64 loss: 0.36247891187667847
Batch 10/64 loss: 0.36567747592926025
Batch 11/64 loss: 0.36924201250076294
Batch 12/64 loss: 0.36570775508880615
Batch 13/64 loss: 0.367090106010437
Batch 14/64 loss: 0.3645443320274353
Batch 15/64 loss: 0.36548304557800293
Batch 16/64 loss: 0.362831711769104
Batch 17/64 loss: 0.3654828667640686
Batch 18/64 loss: 0.366199254989624
Batch 19/64 loss: 0.36753249168395996
Batch 20/64 loss: 0.366554856300354
Batch 21/64 loss: 0.36684900522232056
Batch 22/64 loss: 0.3658576011657715
Batch 23/64 loss: 0.3637535572052002
Batch 24/64 loss: 0.36688435077667236
Batch 25/64 loss: 0.36799806356430054
Batch 26/64 loss: 0.36494171619415283
Batch 27/64 loss: 0.36605870723724365
Batch 28/64 loss: 0.36706799268722534
Batch 29/64 loss: 0.3682783246040344
Batch 30/64 loss: 0.36412370204925537
Batch 31/64 loss: 0.3645426630973816
Batch 32/64 loss: 0.3632279634475708
Batch 33/64 loss: 0.3664204478263855
Batch 34/64 loss: 0.36581528186798096
Batch 35/64 loss: 0.3649848699569702
Batch 36/64 loss: 0.3636031150817871
Batch 37/64 loss: 0.36765384674072266
Batch 38/64 loss: 0.36460304260253906
Batch 39/64 loss: 0.36578118801116943
Batch 40/64 loss: 0.36824941635131836
Batch 41/64 loss: 0.3646746873855591
Batch 42/64 loss: 0.36585718393325806
Batch 43/64 loss: 0.36651790142059326
Batch 44/64 loss: 0.36693185567855835
Batch 45/64 loss: 0.3701087236404419
Batch 46/64 loss: 0.36703550815582275
Batch 47/64 loss: 0.3676733374595642
Batch 48/64 loss: 0.3679952621459961
Batch 49/64 loss: 0.36275458335876465
Batch 50/64 loss: 0.3663581609725952
Batch 51/64 loss: 0.36543965339660645
Batch 52/64 loss: 0.36763620376586914
Batch 53/64 loss: 0.3663991093635559
Batch 54/64 loss: 0.3633311986923218
Batch 55/64 loss: 0.36557304859161377
Batch 56/64 loss: 0.36460793018341064
Batch 57/64 loss: 0.3660527467727661
Batch 58/64 loss: 0.366550087928772
Batch 59/64 loss: 0.36759984493255615
Batch 60/64 loss: 0.36437952518463135
Batch 61/64 loss: 0.36751705408096313
Batch 62/64 loss: 0.3627002239227295
Batch 63/64 loss: 0.36511099338531494
Batch 64/64 loss: 0.36431658267974854
Epoch 18  Train loss: 0.36584909429737167  Val loss: 0.3675611228058019
Epoch 19
-------------------------------
Batch 1/64 loss: 0.36805397272109985
Batch 2/64 loss: 0.36620408296585083
Batch 3/64 loss: 0.36499953269958496
Batch 4/64 loss: 0.36710453033447266
Batch 5/64 loss: 0.36605650186538696
Batch 6/64 loss: 0.36652159690856934
Batch 7/64 loss: 0.3644075393676758
Batch 8/64 loss: 0.36674726009368896
Batch 9/64 loss: 0.36473923921585083
Batch 10/64 loss: 0.3656119108200073
Batch 11/64 loss: 0.3667566776275635
Batch 12/64 loss: 0.36288607120513916
Batch 13/64 loss: 0.3662533760070801
Batch 14/64 loss: 0.36724984645843506
Batch 15/64 loss: 0.3663133978843689
Batch 16/64 loss: 0.37043267488479614
Batch 17/64 loss: 0.36875349283218384
Batch 18/64 loss: 0.36491113901138306
Batch 19/64 loss: 0.36324775218963623
Batch 20/64 loss: 0.3657888174057007
Batch 21/64 loss: 0.36526358127593994
Batch 22/64 loss: 0.36723291873931885
Batch 23/64 loss: 0.36440813541412354
Batch 24/64 loss: 0.36486661434173584
Batch 25/64 loss: 0.363547146320343
Batch 26/64 loss: 0.3647851347923279
Batch 27/64 loss: 0.36657845973968506
Batch 28/64 loss: 0.3685554265975952
Batch 29/64 loss: 0.36526262760162354
Batch 30/64 loss: 0.36478281021118164
Batch 31/64 loss: 0.3645493984222412
Batch 32/64 loss: 0.36783134937286377
Batch 33/64 loss: 0.3659754991531372
Batch 34/64 loss: 0.3679358959197998
Batch 35/64 loss: 0.3662865161895752
Batch 36/64 loss: 0.3656408190727234
Batch 37/64 loss: 0.36614203453063965
Batch 38/64 loss: 0.3636683225631714
Batch 39/64 loss: 0.3669849634170532
Batch 40/64 loss: 0.3695415258407593
Batch 41/64 loss: 0.3671128749847412
Batch 42/64 loss: 0.3600170612335205
Batch 43/64 loss: 0.36545896530151367
Batch 44/64 loss: 0.3642536401748657
Batch 45/64 loss: 0.36640477180480957
Batch 46/64 loss: 0.3663092851638794
Batch 47/64 loss: 0.36519181728363037
Batch 48/64 loss: 0.36533230543136597
Batch 49/64 loss: 0.3684999942779541
Batch 50/64 loss: 0.3638700246810913
Batch 51/64 loss: 0.36677753925323486
Batch 52/64 loss: 0.36616551876068115
Batch 53/64 loss: 0.3675506114959717
Batch 54/64 loss: 0.3658890724182129
Batch 55/64 loss: 0.3649660348892212
Batch 56/64 loss: 0.36468052864074707
Batch 57/64 loss: 0.365988552570343
Batch 58/64 loss: 0.3625072240829468
Batch 59/64 loss: 0.3679024577140808
Batch 60/64 loss: 0.362529993057251
Batch 61/64 loss: 0.36396610736846924
Batch 62/64 loss: 0.36640918254852295
Batch 63/64 loss: 0.36530280113220215
Batch 64/64 loss: 0.36733657121658325
Epoch 19  Train loss: 0.3658269393677805  Val loss: 0.3667733337461334
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 0.3659282326698303
Batch 2/64 loss: 0.36830925941467285
Batch 3/64 loss: 0.3654480576515198
Batch 4/64 loss: 0.3665306568145752
Batch 5/64 loss: 0.36956435441970825
Batch 6/64 loss: 0.36450231075286865
Batch 7/64 loss: 0.3654961585998535
Batch 8/64 loss: 0.3671899437904358
Batch 9/64 loss: 0.3647644519805908
Batch 10/64 loss: 0.3648008704185486
Batch 11/64 loss: 0.3654746413230896
Batch 12/64 loss: 0.36721622943878174
Batch 13/64 loss: 0.3653782606124878
Batch 14/64 loss: 0.36487048864364624
Batch 15/64 loss: 0.3611152172088623
Batch 16/64 loss: 0.36395275592803955
Batch 17/64 loss: 0.3648049831390381
Batch 18/64 loss: 0.3662031888961792
Batch 19/64 loss: 0.3655073046684265
Batch 20/64 loss: 0.3641633987426758
Batch 21/64 loss: 0.3620067238807678
Batch 22/64 loss: 0.3648970127105713
Batch 23/64 loss: 0.3661041259765625
Batch 24/64 loss: 0.364976167678833
Batch 25/64 loss: 0.3649876117706299
Batch 26/64 loss: 0.3675154447555542
Batch 27/64 loss: 0.3645073175430298
Batch 28/64 loss: 0.3662681579589844
Batch 29/64 loss: 0.370765745639801
Batch 30/64 loss: 0.3680994510650635
Batch 31/64 loss: 0.36694443225860596
Batch 32/64 loss: 0.36354494094848633
Batch 33/64 loss: 0.36799800395965576
Batch 34/64 loss: 0.36365246772766113
Batch 35/64 loss: 0.367753803730011
Batch 36/64 loss: 0.36282843351364136
Batch 37/64 loss: 0.3665170669555664
Batch 38/64 loss: 0.36630964279174805
Batch 39/64 loss: 0.3670375347137451
Batch 40/64 loss: 0.36727917194366455
Batch 41/64 loss: 0.36469078063964844
Batch 42/64 loss: 0.3633188009262085
Batch 43/64 loss: 0.36537373065948486
Batch 44/64 loss: 0.36285436153411865
Batch 45/64 loss: 0.3650047183036804
Batch 46/64 loss: 0.36439234018325806
Batch 47/64 loss: 0.3660435676574707
Batch 48/64 loss: 0.36934614181518555
Batch 49/64 loss: 0.3665459156036377
Batch 50/64 loss: 0.36508655548095703
Batch 51/64 loss: 0.365708589553833
Batch 52/64 loss: 0.36449187994003296
Batch 53/64 loss: 0.3670271039009094
Batch 54/64 loss: 0.36799055337905884
Batch 55/64 loss: 0.36773788928985596
Batch 56/64 loss: 0.36475443840026855
Batch 57/64 loss: 0.3653390407562256
Batch 58/64 loss: 0.36241614818573
Batch 59/64 loss: 0.3674274682998657
Batch 60/64 loss: 0.36808937788009644
Batch 61/64 loss: 0.36485302448272705
Batch 62/64 loss: 0.3682255744934082
Batch 63/64 loss: 0.36662548780441284
Batch 64/64 loss: 0.36843836307525635
Epoch 20  Train loss: 0.3658178240645166  Val loss: 0.36779903792024066
Epoch 21
-------------------------------
Batch 1/64 loss: 0.3659026622772217
Batch 2/64 loss: 0.3681298494338989
Batch 3/64 loss: 0.3635387420654297
Batch 4/64 loss: 0.36593472957611084
Batch 5/64 loss: 0.36613452434539795
Batch 6/64 loss: 0.36870938539505005
Batch 7/64 loss: 0.36557507514953613
Batch 8/64 loss: 0.36467093229293823
Batch 9/64 loss: 0.36694467067718506
Batch 10/64 loss: 0.36433637142181396
Batch 11/64 loss: 0.36505126953125
Batch 12/64 loss: 0.36522603034973145
Batch 13/64 loss: 0.3654392957687378
Batch 14/64 loss: 0.360540509223938
Batch 15/64 loss: 0.36221086978912354
Batch 16/64 loss: 0.36810362339019775
Batch 17/64 loss: 0.3679744005203247
Batch 18/64 loss: 0.3644435405731201
Batch 19/64 loss: 0.36178678274154663
Batch 20/64 loss: 0.3631969690322876
Batch 21/64 loss: 0.364737868309021
Batch 22/64 loss: 0.36459624767303467
Batch 23/64 loss: 0.36371827125549316
Batch 24/64 loss: 0.36280953884124756
Batch 25/64 loss: 0.36576616764068604
Batch 26/64 loss: 0.3629140257835388
Batch 27/64 loss: 0.3669471740722656
Batch 28/64 loss: 0.363165020942688
Batch 29/64 loss: 0.36594855785369873
Batch 30/64 loss: 0.3626319169998169
Batch 31/64 loss: 0.36181819438934326
Batch 32/64 loss: 0.36394309997558594
Batch 33/64 loss: 0.3633366823196411
Batch 34/64 loss: 0.36867833137512207
Batch 35/64 loss: 0.36427199840545654
Batch 36/64 loss: 0.3660057783126831
Batch 37/64 loss: 0.36621516942977905
Batch 38/64 loss: 0.36314892768859863
Batch 39/64 loss: 0.3647928237915039
Batch 40/64 loss: 0.3675963878631592
Batch 41/64 loss: 0.36341750621795654
Batch 42/64 loss: 0.36471253633499146
Batch 43/64 loss: 0.3675650358200073
Batch 44/64 loss: 0.3638049364089966
Batch 45/64 loss: 0.36512744426727295
Batch 46/64 loss: 0.3640490770339966
Batch 47/64 loss: 0.36401379108428955
Batch 48/64 loss: 0.3648001551628113
Batch 49/64 loss: 0.3613484501838684
Batch 50/64 loss: 0.3655942678451538
Batch 51/64 loss: 0.3655427098274231
Batch 52/64 loss: 0.36394011974334717
Batch 53/64 loss: 0.3656991124153137
Batch 54/64 loss: 0.36473244428634644
Batch 55/64 loss: 0.3695797920227051
Batch 56/64 loss: 0.36518603563308716
Batch 57/64 loss: 0.3657768964767456
Batch 58/64 loss: 0.3676791191101074
Batch 59/64 loss: 0.364357590675354
Batch 60/64 loss: 0.3641083836555481
Batch 61/64 loss: 0.3664894104003906
Batch 62/64 loss: 0.3646460175514221
Batch 63/64 loss: 0.36719244718551636
Batch 64/64 loss: 0.35941433906555176
Epoch 21  Train loss: 0.3649539835312787  Val loss: 0.36676766536489797
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 0.36479514837265015
Batch 2/64 loss: 0.3632487654685974
Batch 3/64 loss: 0.3661758303642273
Batch 4/64 loss: 0.36436450481414795
Batch 5/64 loss: 0.3676884174346924
Batch 6/64 loss: 0.36771857738494873
Batch 7/64 loss: 0.3668341040611267
Batch 8/64 loss: 0.3673213720321655
Batch 9/64 loss: 0.36289119720458984
Batch 10/64 loss: 0.36811625957489014
Batch 11/64 loss: 0.36451780796051025
Batch 12/64 loss: 0.3654059171676636
Batch 13/64 loss: 0.3626018762588501
Batch 14/64 loss: 0.3631938099861145
Batch 15/64 loss: 0.36684608459472656
Batch 16/64 loss: 0.3631291389465332
Batch 17/64 loss: 0.3663311004638672
Batch 18/64 loss: 0.36621904373168945
Batch 19/64 loss: 0.36401742696762085
Batch 20/64 loss: 0.3649437427520752
Batch 21/64 loss: 0.36619699001312256
Batch 22/64 loss: 0.36292076110839844
Batch 23/64 loss: 0.3672366142272949
Batch 24/64 loss: 0.3641771674156189
Batch 25/64 loss: 0.36382806301116943
Batch 26/64 loss: 0.36813151836395264
Batch 27/64 loss: 0.364132821559906
Batch 28/64 loss: 0.3656415343284607
Batch 29/64 loss: 0.36365485191345215
Batch 30/64 loss: 0.3650341033935547
Batch 31/64 loss: 0.3636777400970459
Batch 32/64 loss: 0.36538034677505493
Batch 33/64 loss: 0.36317014694213867
Batch 34/64 loss: 0.3624262809753418
Batch 35/64 loss: 0.3637063503265381
Batch 36/64 loss: 0.36573338508605957
Batch 37/64 loss: 0.365398108959198
Batch 38/64 loss: 0.3643587827682495
Batch 39/64 loss: 0.3650254011154175
Batch 40/64 loss: 0.3645585775375366
Batch 41/64 loss: 0.3673228621482849
Batch 42/64 loss: 0.3665316104888916
Batch 43/64 loss: 0.3654857277870178
Batch 44/64 loss: 0.36799150705337524
Batch 45/64 loss: 0.36652064323425293
Batch 46/64 loss: 0.36407631635665894
Batch 47/64 loss: 0.36510396003723145
Batch 48/64 loss: 0.3663926124572754
Batch 49/64 loss: 0.36726880073547363
Batch 50/64 loss: 0.36541640758514404
Batch 51/64 loss: 0.3636080026626587
Batch 52/64 loss: 0.36414968967437744
Batch 53/64 loss: 0.365885853767395
Batch 54/64 loss: 0.3645017147064209
Batch 55/64 loss: 0.3667515516281128
Batch 56/64 loss: 0.365649938583374
Batch 57/64 loss: 0.36671900749206543
Batch 58/64 loss: 0.3642542362213135
Batch 59/64 loss: 0.362247109413147
Batch 60/64 loss: 0.3643481135368347
Batch 61/64 loss: 0.3653111457824707
Batch 62/64 loss: 0.36442720890045166
Batch 63/64 loss: 0.36353689432144165
Batch 64/64 loss: 0.365370512008667
Epoch 22  Train loss: 0.36514946619669597  Val loss: 0.3666872543977298
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: 0.36303210258483887
Batch 2/64 loss: 0.36440783739089966
Batch 3/64 loss: 0.36302465200424194
Batch 4/64 loss: 0.36355412006378174
Batch 5/64 loss: 0.36182230710983276
Batch 6/64 loss: 0.36690568923950195
Batch 7/64 loss: 0.3638027310371399
Batch 8/64 loss: 0.36627352237701416
Batch 9/64 loss: 0.3640905022621155
Batch 10/64 loss: 0.3652557134628296
Batch 11/64 loss: 0.36624211072921753
Batch 12/64 loss: 0.36250489950180054
Batch 13/64 loss: 0.36821287870407104
Batch 14/64 loss: 0.3653939366340637
Batch 15/64 loss: 0.3614909052848816
Batch 16/64 loss: 0.36203068494796753
Batch 17/64 loss: 0.3636176586151123
Batch 18/64 loss: 0.36102229356765747
Batch 19/64 loss: 0.36491286754608154
Batch 20/64 loss: 0.36351656913757324
Batch 21/64 loss: 0.36571836471557617
Batch 22/64 loss: 0.3637348413467407
Batch 23/64 loss: 0.366294264793396
Batch 24/64 loss: 0.3672524690628052
Batch 25/64 loss: 0.3663827180862427
Batch 26/64 loss: 0.36517876386642456
Batch 27/64 loss: 0.3666161894798279
Batch 28/64 loss: 0.3614073395729065
Batch 29/64 loss: 0.36445891857147217
Batch 30/64 loss: 0.3626314401626587
Batch 31/64 loss: 0.36334228515625
Batch 32/64 loss: 0.36243510246276855
Batch 33/64 loss: 0.36509066820144653
Batch 34/64 loss: 0.36512625217437744
Batch 35/64 loss: 0.36131662130355835
Batch 36/64 loss: 0.36650967597961426
Batch 37/64 loss: 0.3664214015007019
Batch 38/64 loss: 0.36405372619628906
Batch 39/64 loss: 0.36785995960235596
Batch 40/64 loss: 0.36620938777923584
Batch 41/64 loss: 0.3639889359474182
Batch 42/64 loss: 0.36411792039871216
Batch 43/64 loss: 0.36389005184173584
Batch 44/64 loss: 0.3645350933074951
Batch 45/64 loss: 0.3677173852920532
Batch 46/64 loss: 0.3629359006881714
Batch 47/64 loss: 0.3638952970504761
Batch 48/64 loss: 0.3670375347137451
Batch 49/64 loss: 0.36311471462249756
Batch 50/64 loss: 0.36383092403411865
Batch 51/64 loss: 0.3658531904220581
Batch 52/64 loss: 0.36496198177337646
Batch 53/64 loss: 0.363930344581604
Batch 54/64 loss: 0.3647482395172119
Batch 55/64 loss: 0.3626307249069214
Batch 56/64 loss: 0.36573362350463867
Batch 57/64 loss: 0.3660096526145935
Batch 58/64 loss: 0.3631651997566223
Batch 59/64 loss: 0.36310791969299316
Batch 60/64 loss: 0.3661457300186157
Batch 61/64 loss: 0.3641124963760376
Batch 62/64 loss: 0.362196683883667
Batch 63/64 loss: 0.36612391471862793
Batch 64/64 loss: 0.36337804794311523
Epoch 23  Train loss: 0.36447798224056466  Val loss: 0.36581309308710785
Saving best model, epoch: 23
Epoch 24
-------------------------------
Batch 1/64 loss: 0.36136555671691895
Batch 2/64 loss: 0.3636312484741211
Batch 3/64 loss: 0.3673728108406067
Batch 4/64 loss: 0.36636877059936523
Batch 5/64 loss: 0.36506056785583496
Batch 6/64 loss: 0.3636280298233032
Batch 7/64 loss: 0.36303019523620605
Batch 8/64 loss: 0.36493152379989624
Batch 9/64 loss: 0.36288583278656006
Batch 10/64 loss: 0.363563597202301
Batch 11/64 loss: 0.36451923847198486
Batch 12/64 loss: 0.3622533082962036
Batch 13/64 loss: 0.36343204975128174
Batch 14/64 loss: 0.36562567949295044
Batch 15/64 loss: 0.36593687534332275
Batch 16/64 loss: 0.3668932318687439
Batch 17/64 loss: 0.361575722694397
Batch 18/64 loss: 0.3621281385421753
Batch 19/64 loss: 0.36534643173217773
Batch 20/64 loss: 0.36502665281295776
Batch 21/64 loss: 0.36388999223709106
Batch 22/64 loss: 0.3622121214866638
Batch 23/64 loss: 0.36847221851348877
Batch 24/64 loss: 0.3621519207954407
Batch 25/64 loss: 0.3639284372329712
Batch 26/64 loss: 0.36951231956481934
Batch 27/64 loss: 0.36383724212646484
Batch 28/64 loss: 0.3630547523498535
Batch 29/64 loss: 0.36324048042297363
Batch 30/64 loss: 0.3646280765533447
Batch 31/64 loss: 0.3685319423675537
Batch 32/64 loss: 0.36312687397003174
Batch 33/64 loss: 0.36537784337997437
Batch 34/64 loss: 0.3643987774848938
Batch 35/64 loss: 0.3650221824645996
Batch 36/64 loss: 0.3646000027656555
Batch 37/64 loss: 0.3647749423980713
Batch 38/64 loss: 0.36727237701416016
Batch 39/64 loss: 0.369106650352478
Batch 40/64 loss: 0.36545807123184204
Batch 41/64 loss: 0.3616284132003784
Batch 42/64 loss: 0.3657951354980469
Batch 43/64 loss: 0.3655616044998169
Batch 44/64 loss: 0.3651174306869507
Batch 45/64 loss: 0.36323070526123047
Batch 46/64 loss: 0.3641524910926819
Batch 47/64 loss: 0.36243700981140137
Batch 48/64 loss: 0.365628719329834
Batch 49/64 loss: 0.36437225341796875
Batch 50/64 loss: 0.36569666862487793
Batch 51/64 loss: 0.36577510833740234
Batch 52/64 loss: 0.3632711172103882
Batch 53/64 loss: 0.3654686212539673
Batch 54/64 loss: 0.3651788830757141
Batch 55/64 loss: 0.3642706871032715
Batch 56/64 loss: 0.3635331392288208
Batch 57/64 loss: 0.36341238021850586
Batch 58/64 loss: 0.3633621335029602
Batch 59/64 loss: 0.3645176887512207
Batch 60/64 loss: 0.3656538724899292
Batch 61/64 loss: 0.36501777172088623
Batch 62/64 loss: 0.3623391389846802
Batch 63/64 loss: 0.36371660232543945
Batch 64/64 loss: 0.3637884855270386
Epoch 24  Train loss: 0.36453571179333855  Val loss: 0.3655423747305198
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 0.36389708518981934
Batch 2/64 loss: 0.3637552261352539
Batch 3/64 loss: 0.3608624339103699
Batch 4/64 loss: 0.36377859115600586
Batch 5/64 loss: 0.3645578622817993
Batch 6/64 loss: 0.3625389337539673
Batch 7/64 loss: 0.3636770248413086
Batch 8/64 loss: 0.36322033405303955
Batch 9/64 loss: 0.3622233271598816
Batch 10/64 loss: 0.3637021780014038
Batch 11/64 loss: 0.36340808868408203
Batch 12/64 loss: 0.3673821687698364
Batch 13/64 loss: 0.3648228049278259
Batch 14/64 loss: 0.364859938621521
Batch 15/64 loss: 0.36250758171081543
Batch 16/64 loss: 0.3642486333847046
Batch 17/64 loss: 0.3607029318809509
Batch 18/64 loss: 0.36425840854644775
Batch 19/64 loss: 0.3622710704803467
Batch 20/64 loss: 0.36559319496154785
Batch 21/64 loss: 0.3662787079811096
Batch 22/64 loss: 0.3604252338409424
Batch 23/64 loss: 0.36439400911331177
Batch 24/64 loss: 0.3675258755683899
Batch 25/64 loss: 0.362922728061676
Batch 26/64 loss: 0.36463284492492676
Batch 27/64 loss: 0.36098361015319824
Batch 28/64 loss: 0.36177313327789307
Batch 29/64 loss: 0.364709734916687
Batch 30/64 loss: 0.3632885813713074
Batch 31/64 loss: 0.3640402555465698
Batch 32/64 loss: 0.36591213941574097
Batch 33/64 loss: 0.36118000745773315
Batch 34/64 loss: 0.3653087615966797
Batch 35/64 loss: 0.3655966520309448
Batch 36/64 loss: 0.36493825912475586
Batch 37/64 loss: 0.36704546213150024
Batch 38/64 loss: 0.36509275436401367
Batch 39/64 loss: 0.36526358127593994
Batch 40/64 loss: 0.3661651611328125
Batch 41/64 loss: 0.3642633557319641
Batch 42/64 loss: 0.362967848777771
Batch 43/64 loss: 0.36446666717529297
Batch 44/64 loss: 0.3614088296890259
Batch 45/64 loss: 0.36499089002609253
Batch 46/64 loss: 0.36402642726898193
Batch 47/64 loss: 0.36185121536254883
Batch 48/64 loss: 0.3619866371154785
Batch 49/64 loss: 0.36611032485961914
Batch 50/64 loss: 0.3648589849472046
Batch 51/64 loss: 0.3669353723526001
Batch 52/64 loss: 0.3624880909919739
Batch 53/64 loss: 0.3618010878562927
Batch 54/64 loss: 0.3646388053894043
Batch 55/64 loss: 0.3618038296699524
Batch 56/64 loss: 0.3656867742538452
Batch 57/64 loss: 0.3627854585647583
Batch 58/64 loss: 0.3623192310333252
Batch 59/64 loss: 0.3608602285385132
Batch 60/64 loss: 0.3636664152145386
Batch 61/64 loss: 0.36548930406570435
Batch 62/64 loss: 0.3613516688346863
Batch 63/64 loss: 0.3680456876754761
Batch 64/64 loss: 0.36481738090515137
Epoch 25  Train loss: 0.36389272914213294  Val loss: 0.3656402181104286
Epoch 26
-------------------------------
Batch 1/64 loss: 0.3632427453994751
Batch 2/64 loss: 0.3631018400192261
Batch 3/64 loss: 0.36727219820022583
Batch 4/64 loss: 0.36633241176605225
Batch 5/64 loss: 0.3652912378311157
Batch 6/64 loss: 0.36569058895111084
Batch 7/64 loss: 0.36246180534362793
Batch 8/64 loss: 0.36241018772125244
Batch 9/64 loss: 0.36224526166915894
Batch 10/64 loss: 0.36389458179473877
Batch 11/64 loss: 0.36340391635894775
Batch 12/64 loss: 0.36354053020477295
Batch 13/64 loss: 0.3634212017059326
Batch 14/64 loss: 0.3615310788154602
Batch 15/64 loss: 0.3629559278488159
Batch 16/64 loss: 0.36410510540008545
Batch 17/64 loss: 0.3645823001861572
Batch 18/64 loss: 0.36186617612838745
Batch 19/64 loss: 0.36619722843170166
Batch 20/64 loss: 0.3616107106208801
Batch 21/64 loss: 0.366762638092041
Batch 22/64 loss: 0.3646019697189331
Batch 23/64 loss: 0.3641904592514038
Batch 24/64 loss: 0.36261701583862305
Batch 25/64 loss: 0.3631552457809448
Batch 26/64 loss: 0.3620970845222473
Batch 27/64 loss: 0.3628283739089966
Batch 28/64 loss: 0.3641887307167053
Batch 29/64 loss: 0.36138808727264404
Batch 30/64 loss: 0.3631981611251831
Batch 31/64 loss: 0.36349916458129883
Batch 32/64 loss: 0.3645932674407959
Batch 33/64 loss: 0.3677746057510376
Batch 34/64 loss: 0.3614811897277832
Batch 35/64 loss: 0.3628823757171631
Batch 36/64 loss: 0.36358124017715454
Batch 37/64 loss: 0.36406707763671875
Batch 38/64 loss: 0.3637871742248535
Batch 39/64 loss: 0.3656117916107178
Batch 40/64 loss: 0.36198484897613525
Batch 41/64 loss: 0.36366820335388184
Batch 42/64 loss: 0.36248284578323364
Batch 43/64 loss: 0.36418312788009644
Batch 44/64 loss: 0.3658633232116699
Batch 45/64 loss: 0.3640042543411255
Batch 46/64 loss: 0.36541277170181274
Batch 47/64 loss: 0.36643481254577637
Batch 48/64 loss: 0.3603034019470215
Batch 49/64 loss: 0.3638843297958374
Batch 50/64 loss: 0.3609943985939026
Batch 51/64 loss: 0.3633267879486084
Batch 52/64 loss: 0.35986995697021484
Batch 53/64 loss: 0.364829421043396
Batch 54/64 loss: 0.36472976207733154
Batch 55/64 loss: 0.36598801612854004
Batch 56/64 loss: 0.36521220207214355
Batch 57/64 loss: 0.36751294136047363
Batch 58/64 loss: 0.3658956289291382
Batch 59/64 loss: 0.3621358871459961
Batch 60/64 loss: 0.36530929803848267
Batch 61/64 loss: 0.36726176738739014
Batch 62/64 loss: 0.36240077018737793
Batch 63/64 loss: 0.3661457300186157
Batch 64/64 loss: 0.3635493516921997
Epoch 26  Train loss: 0.36392092845019175  Val loss: 0.36571835959490223
Epoch 27
-------------------------------
Batch 1/64 loss: 0.3621309995651245
Batch 2/64 loss: 0.3617398738861084
Batch 3/64 loss: 0.36454254388809204
Batch 4/64 loss: 0.3649364709854126
Batch 5/64 loss: 0.3632640838623047
Batch 6/64 loss: 0.36517763137817383
Batch 7/64 loss: 0.3645355701446533
Batch 8/64 loss: 0.3653007745742798
Batch 9/64 loss: 0.3635294437408447
Batch 10/64 loss: 0.3647826910018921
Batch 11/64 loss: 0.3623734712600708
Batch 12/64 loss: 0.3627750277519226
Batch 13/64 loss: 0.3664891719818115
Batch 14/64 loss: 0.36053168773651123
Batch 15/64 loss: 0.36277639865875244
Batch 16/64 loss: 0.3647692799568176
Batch 17/64 loss: 0.36562931537628174
Batch 18/64 loss: 0.363105833530426
Batch 19/64 loss: 0.36581951379776
Batch 20/64 loss: 0.36644989252090454
Batch 21/64 loss: 0.363033652305603
Batch 22/64 loss: 0.3645280599594116
Batch 23/64 loss: 0.36555230617523193
Batch 24/64 loss: 0.36331844329833984
Batch 25/64 loss: 0.36589086055755615
Batch 26/64 loss: 0.36163270473480225
Batch 27/64 loss: 0.363484263420105
Batch 28/64 loss: 0.36350953578948975
Batch 29/64 loss: 0.36365044116973877
Batch 30/64 loss: 0.3651261329650879
Batch 31/64 loss: 0.36407244205474854
Batch 32/64 loss: 0.3621346950531006
Batch 33/64 loss: 0.362549364566803
Batch 34/64 loss: 0.36339300870895386
Batch 35/64 loss: 0.3608208894729614
Batch 36/64 loss: 0.36361396312713623
Batch 37/64 loss: 0.36490845680236816
Batch 38/64 loss: 0.3639216423034668
Batch 39/64 loss: 0.3652958273887634
Batch 40/64 loss: 0.3599131107330322
Batch 41/64 loss: 0.36222004890441895
Batch 42/64 loss: 0.3650989532470703
Batch 43/64 loss: 0.3648488521575928
Batch 44/64 loss: 0.3624533414840698
Batch 45/64 loss: 0.3642127513885498
Batch 46/64 loss: 0.36282771825790405
Batch 47/64 loss: 0.3670639991760254
Batch 48/64 loss: 0.3650479316711426
Batch 49/64 loss: 0.3649817705154419
Batch 50/64 loss: 0.36879193782806396
Batch 51/64 loss: 0.3617035150527954
Batch 52/64 loss: 0.36426907777786255
Batch 53/64 loss: 0.3643789291381836
Batch 54/64 loss: 0.36282503604888916
Batch 55/64 loss: 0.3626059293746948
Batch 56/64 loss: 0.3646198511123657
Batch 57/64 loss: 0.36106252670288086
Batch 58/64 loss: 0.36213362216949463
Batch 59/64 loss: 0.3625293970108032
Batch 60/64 loss: 0.3645482063293457
Batch 61/64 loss: 0.36461341381073
Batch 62/64 loss: 0.3659380078315735
Batch 63/64 loss: 0.36364495754241943
Batch 64/64 loss: 0.3630750775337219
Epoch 27  Train loss: 0.363854675433215  Val loss: 0.366165095178532
Epoch 28
-------------------------------
Batch 1/64 loss: 0.36627912521362305
Batch 2/64 loss: 0.36293327808380127
Batch 3/64 loss: 0.3624724745750427
Batch 4/64 loss: 0.3601731061935425
Batch 5/64 loss: 0.3631448745727539
Batch 6/64 loss: 0.3635435104370117
Batch 7/64 loss: 0.36499977111816406
Batch 8/64 loss: 0.3609153628349304
Batch 9/64 loss: 0.361961305141449
Batch 10/64 loss: 0.363857626914978
Batch 11/64 loss: 0.3634521961212158
Batch 12/64 loss: 0.36327826976776123
Batch 13/64 loss: 0.36522138118743896
Batch 14/64 loss: 0.36249446868896484
Batch 15/64 loss: 0.36526232957839966
Batch 16/64 loss: 0.3619866967201233
Batch 17/64 loss: 0.36141252517700195
Batch 18/64 loss: 0.3626335859298706
Batch 19/64 loss: 0.36598849296569824
Batch 20/64 loss: 0.3662581443786621
Batch 21/64 loss: 0.36566162109375
Batch 22/64 loss: 0.3623267412185669
Batch 23/64 loss: 0.36274415254592896
Batch 24/64 loss: 0.36458128690719604
Batch 25/64 loss: 0.36745381355285645
Batch 26/64 loss: 0.36236608028411865
Batch 27/64 loss: 0.361771821975708
Batch 28/64 loss: 0.36899441480636597
Batch 29/64 loss: 0.36328768730163574
Batch 30/64 loss: 0.36227262020111084
Batch 31/64 loss: 0.3607172966003418
Batch 32/64 loss: 0.3612768054008484
Batch 33/64 loss: 0.3654292821884155
Batch 34/64 loss: 0.3615161180496216
Batch 35/64 loss: 0.3632131814956665
Batch 36/64 loss: 0.3619067668914795
Batch 37/64 loss: 0.36228108406066895
Batch 38/64 loss: 0.364216685295105
Batch 39/64 loss: 0.36428409814834595
Batch 40/64 loss: 0.364069402217865
Batch 41/64 loss: 0.3648224472999573
Batch 42/64 loss: 0.362779438495636
Batch 43/64 loss: 0.36275434494018555
Batch 44/64 loss: 0.3617740869522095
Batch 45/64 loss: 0.36230146884918213
Batch 46/64 loss: 0.36733007431030273
Batch 47/64 loss: 0.3640102744102478
Batch 48/64 loss: 0.36148542165756226
Batch 49/64 loss: 0.36250054836273193
Batch 50/64 loss: 0.36079931259155273
Batch 51/64 loss: 0.3646354675292969
Batch 52/64 loss: 0.3644847869873047
Batch 53/64 loss: 0.36339354515075684
Batch 54/64 loss: 0.36333346366882324
Batch 55/64 loss: 0.3601568937301636
Batch 56/64 loss: 0.36385148763656616
Batch 57/64 loss: 0.3639596700668335
Batch 58/64 loss: 0.36466270685195923
Batch 59/64 loss: 0.364462673664093
Batch 60/64 loss: 0.36256110668182373
Batch 61/64 loss: 0.3633580207824707
Batch 62/64 loss: 0.3638286590576172
Batch 63/64 loss: 0.3608856201171875
Batch 64/64 loss: 0.3616983890533447
Epoch 28  Train loss: 0.36335756544973336  Val loss: 0.3645663892280605
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: 0.3659518361091614
Batch 2/64 loss: 0.36060476303100586
Batch 3/64 loss: 0.36258387565612793
Batch 4/64 loss: 0.36255478858947754
Batch 5/64 loss: 0.3595927953720093
Batch 6/64 loss: 0.3626565933227539
Batch 7/64 loss: 0.3609243631362915
Batch 8/64 loss: 0.3640506863594055
Batch 9/64 loss: 0.3608459234237671
Batch 10/64 loss: 0.361253023147583
Batch 11/64 loss: 0.3626037836074829
Batch 12/64 loss: 0.36100685596466064
Batch 13/64 loss: 0.362845778465271
Batch 14/64 loss: 0.36293697357177734
Batch 15/64 loss: 0.3613700866699219
Batch 16/64 loss: 0.36266469955444336
Batch 17/64 loss: 0.3655713200569153
Batch 18/64 loss: 0.36379683017730713
Batch 19/64 loss: 0.36105215549468994
Batch 20/64 loss: 0.3623753786087036
Batch 21/64 loss: 0.3609654903411865
Batch 22/64 loss: 0.36129164695739746
Batch 23/64 loss: 0.3614100217819214
Batch 24/64 loss: 0.3617653250694275
Batch 25/64 loss: 0.36475974321365356
Batch 26/64 loss: 0.36457276344299316
Batch 27/64 loss: 0.36165428161621094
Batch 28/64 loss: 0.3619488477706909
Batch 29/64 loss: 0.36046719551086426
Batch 30/64 loss: 0.36259156465530396
Batch 31/64 loss: 0.36194121837615967
Batch 32/64 loss: 0.3638256788253784
Batch 33/64 loss: 0.3648231029510498
Batch 34/64 loss: 0.3639780879020691
Batch 35/64 loss: 0.36282479763031006
Batch 36/64 loss: 0.3629292845726013
Batch 37/64 loss: 0.3630916476249695
Batch 38/64 loss: 0.3632206916809082
Batch 39/64 loss: 0.36192911863327026
Batch 40/64 loss: 0.3669007420539856
Batch 41/64 loss: 0.36557960510253906
Batch 42/64 loss: 0.36357712745666504
Batch 43/64 loss: 0.36221742630004883
Batch 44/64 loss: 0.36373424530029297
Batch 45/64 loss: 0.3634904623031616
Batch 46/64 loss: 0.3612384796142578
Batch 47/64 loss: 0.36238646507263184
Batch 48/64 loss: 0.3614203929901123
Batch 49/64 loss: 0.3615916967391968
Batch 50/64 loss: 0.36507636308670044
Batch 51/64 loss: 0.36339497566223145
Batch 52/64 loss: 0.3626038432121277
Batch 53/64 loss: 0.3611640930175781
Batch 54/64 loss: 0.3620643615722656
Batch 55/64 loss: 0.3625950217247009
Batch 56/64 loss: 0.3648156523704529
Batch 57/64 loss: 0.3625732660293579
Batch 58/64 loss: 0.36334025859832764
Batch 59/64 loss: 0.3611568212509155
Batch 60/64 loss: 0.36536550521850586
Batch 61/64 loss: 0.36343979835510254
Batch 62/64 loss: 0.3613021969795227
Batch 63/64 loss: 0.3604578971862793
Batch 64/64 loss: 0.3594622015953064
Epoch 29  Train loss: 0.36264025674146766  Val loss: 0.36319169289467673
Saving best model, epoch: 29
Epoch 30
-------------------------------
Batch 1/64 loss: 0.3649005889892578
Batch 2/64 loss: 0.36315029859542847
Batch 3/64 loss: 0.3623924255371094
Batch 4/64 loss: 0.36353540420532227
Batch 5/64 loss: 0.36244726181030273
Batch 6/64 loss: 0.36223113536834717
Batch 7/64 loss: 0.364335298538208
Batch 8/64 loss: 0.363877534866333
Batch 9/64 loss: 0.35848385095596313
Batch 10/64 loss: 0.3639868497848511
Batch 11/64 loss: 0.3624964952468872
Batch 12/64 loss: 0.36097991466522217
Batch 13/64 loss: 0.3598051071166992
Batch 14/64 loss: 0.35946786403656006
Batch 15/64 loss: 0.36161816120147705
Batch 16/64 loss: 0.3621193766593933
Batch 17/64 loss: 0.363243043422699
Batch 18/64 loss: 0.36249303817749023
Batch 19/64 loss: 0.3612617254257202
Batch 20/64 loss: 0.36336541175842285
Batch 21/64 loss: 0.36426663398742676
Batch 22/64 loss: 0.36202919483184814
Batch 23/64 loss: 0.3604719638824463
Batch 24/64 loss: 0.36011117696762085
Batch 25/64 loss: 0.36167335510253906
Batch 26/64 loss: 0.3620588779449463
Batch 27/64 loss: 0.36115288734436035
Batch 28/64 loss: 0.3610926866531372
Batch 29/64 loss: 0.3635059595108032
Batch 30/64 loss: 0.36158961057662964
Batch 31/64 loss: 0.3639446496963501
Batch 32/64 loss: 0.3631269931793213
Batch 33/64 loss: 0.36098575592041016
Batch 34/64 loss: 0.36271852254867554
Batch 35/64 loss: 0.3630669116973877
Batch 36/64 loss: 0.36408472061157227
Batch 37/64 loss: 0.3638097047805786
Batch 38/64 loss: 0.36278432607650757
Batch 39/64 loss: 0.3628392219543457
Batch 40/64 loss: 0.3619484305381775
Batch 41/64 loss: 0.3609352111816406
Batch 42/64 loss: 0.358695387840271
Batch 43/64 loss: 0.3589547872543335
Batch 44/64 loss: 0.36083757877349854
Batch 45/64 loss: 0.36141180992126465
Batch 46/64 loss: 0.361772358417511
Batch 47/64 loss: 0.3635507822036743
Batch 48/64 loss: 0.36001724004745483
Batch 49/64 loss: 0.36602604389190674
Batch 50/64 loss: 0.3640761375427246
Batch 51/64 loss: 0.3616147041320801
Batch 52/64 loss: 0.35998570919036865
Batch 53/64 loss: 0.3622368574142456
Batch 54/64 loss: 0.3650643825531006
Batch 55/64 loss: 0.36311835050582886
Batch 56/64 loss: 0.3608282804489136
Batch 57/64 loss: 0.36063194274902344
Batch 58/64 loss: 0.3632323741912842
Batch 59/64 loss: 0.36121565103530884
Batch 60/64 loss: 0.3603506088256836
Batch 61/64 loss: 0.36017465591430664
Batch 62/64 loss: 0.36250603199005127
Batch 63/64 loss: 0.36287516355514526
Batch 64/64 loss: 0.362848162651062
Epoch 30  Train loss: 0.36212863594877953  Val loss: 0.3637070115079585
Epoch 31
-------------------------------
Batch 1/64 loss: 0.35890233516693115
Batch 2/64 loss: 0.36048996448516846
Batch 3/64 loss: 0.36042165756225586
Batch 4/64 loss: 0.36340582370758057
Batch 5/64 loss: 0.3630472421646118
Batch 6/64 loss: 0.3606421947479248
Batch 7/64 loss: 0.3631049394607544
Batch 8/64 loss: 0.3622211217880249
Batch 9/64 loss: 0.35861289501190186
Batch 10/64 loss: 0.36186128854751587
Batch 11/64 loss: 0.36281442642211914
Batch 12/64 loss: 0.35898900032043457
Batch 13/64 loss: 0.3632185459136963
Batch 14/64 loss: 0.362357497215271
Batch 15/64 loss: 0.36327993869781494
Batch 16/64 loss: 0.36404716968536377
Batch 17/64 loss: 0.3660116195678711
Batch 18/64 loss: 0.36079198122024536
Batch 19/64 loss: 0.3625243902206421
Batch 20/64 loss: 0.3619483709335327
Batch 21/64 loss: 0.36157655715942383
Batch 22/64 loss: 0.36121034622192383
Batch 23/64 loss: 0.36138415336608887
Batch 24/64 loss: 0.36202436685562134
Batch 25/64 loss: 0.3606613874435425
Batch 26/64 loss: 0.360278844833374
Batch 27/64 loss: 0.3608015775680542
Batch 28/64 loss: 0.36052095890045166
Batch 29/64 loss: 0.36421942710876465
Batch 30/64 loss: 0.3609941005706787
Batch 31/64 loss: 0.3627774715423584
Batch 32/64 loss: 0.36588621139526367
Batch 33/64 loss: 0.3638785481452942
Batch 34/64 loss: 0.3643229007720947
Batch 35/64 loss: 0.3630562424659729
Batch 36/64 loss: 0.36093735694885254
Batch 37/64 loss: 0.3611588478088379
Batch 38/64 loss: 0.36162877082824707
Batch 39/64 loss: 0.36335110664367676
Batch 40/64 loss: 0.36308205127716064
Batch 41/64 loss: 0.36284947395324707
Batch 42/64 loss: 0.35906147956848145
Batch 43/64 loss: 0.364524781703949
Batch 44/64 loss: 0.36110496520996094
Batch 45/64 loss: 0.36473655700683594
Batch 46/64 loss: 0.3590148687362671
Batch 47/64 loss: 0.36420702934265137
Batch 48/64 loss: 0.3611271381378174
Batch 49/64 loss: 0.3595637083053589
Batch 50/64 loss: 0.36795639991760254
Batch 51/64 loss: 0.36254316568374634
Batch 52/64 loss: 0.36182546615600586
Batch 53/64 loss: 0.36294251680374146
Batch 54/64 loss: 0.3613550066947937
Batch 55/64 loss: 0.36002683639526367
Batch 56/64 loss: 0.36521512269973755
Batch 57/64 loss: 0.3619953393936157
Batch 58/64 loss: 0.3622252345085144
Batch 59/64 loss: 0.3612360954284668
Batch 60/64 loss: 0.36458921432495117
Batch 61/64 loss: 0.36230766773223877
Batch 62/64 loss: 0.3586372137069702
Batch 63/64 loss: 0.3618224859237671
Batch 64/64 loss: 0.36170506477355957
Epoch 31  Train loss: 0.3621112187703451  Val loss: 0.3637928092192948
Epoch 32
-------------------------------
Batch 1/64 loss: 0.36171793937683105
Batch 2/64 loss: 0.36166656017303467
Batch 3/64 loss: 0.363559365272522
Batch 4/64 loss: 0.3619687557220459
Batch 5/64 loss: 0.36226534843444824
Batch 6/64 loss: 0.360693097114563
Batch 7/64 loss: 0.3598707914352417
Batch 8/64 loss: 0.3561714291572571
Batch 9/64 loss: 0.3634801506996155
Batch 10/64 loss: 0.36369824409484863
Batch 11/64 loss: 0.3612818121910095
Batch 12/64 loss: 0.36334967613220215
Batch 13/64 loss: 0.36112815141677856
Batch 14/64 loss: 0.3627176284790039
Batch 15/64 loss: 0.3627808094024658
Batch 16/64 loss: 0.3616463541984558
Batch 17/64 loss: 0.361982524394989
Batch 18/64 loss: 0.3614475727081299
Batch 19/64 loss: 0.36048924922943115
Batch 20/64 loss: 0.3577902317047119
Batch 21/64 loss: 0.3618185520172119
Batch 22/64 loss: 0.36521124839782715
Batch 23/64 loss: 0.3623506426811218
Batch 24/64 loss: 0.36013078689575195
Batch 25/64 loss: 0.362528920173645
Batch 26/64 loss: 0.36339515447616577
Batch 27/64 loss: 0.3630019426345825
Batch 28/64 loss: 0.3576195240020752
Batch 29/64 loss: 0.36494624614715576
Batch 30/64 loss: 0.3621923327445984
Batch 31/64 loss: 0.3605635166168213
Batch 32/64 loss: 0.3628012537956238
Batch 33/64 loss: 0.36138916015625
Batch 34/64 loss: 0.3625674247741699
Batch 35/64 loss: 0.35952723026275635
Batch 36/64 loss: 0.3622478246688843
Batch 37/64 loss: 0.3626589775085449
Batch 38/64 loss: 0.3616807460784912
Batch 39/64 loss: 0.36390942335128784
Batch 40/64 loss: 0.3645275831222534
Batch 41/64 loss: 0.3603660464286804
Batch 42/64 loss: 0.36257994174957275
Batch 43/64 loss: 0.36212819814682007
Batch 44/64 loss: 0.36181890964508057
Batch 45/64 loss: 0.3585134744644165
Batch 46/64 loss: 0.3613933324813843
Batch 47/64 loss: 0.36274921894073486
Batch 48/64 loss: 0.35858577489852905
Batch 49/64 loss: 0.3603801727294922
Batch 50/64 loss: 0.3613438606262207
Batch 51/64 loss: 0.36320388317108154
Batch 52/64 loss: 0.35956239700317383
Batch 53/64 loss: 0.3610572814941406
Batch 54/64 loss: 0.3646482825279236
Batch 55/64 loss: 0.3612552285194397
Batch 56/64 loss: 0.35907459259033203
Batch 57/64 loss: 0.36262619495391846
Batch 58/64 loss: 0.360632061958313
Batch 59/64 loss: 0.3637208938598633
Batch 60/64 loss: 0.3640894889831543
Batch 61/64 loss: 0.36474180221557617
Batch 62/64 loss: 0.36119937896728516
Batch 63/64 loss: 0.35863447189331055
Batch 64/64 loss: 0.36049890518188477
Epoch 32  Train loss: 0.3617169137094535  Val loss: 0.3632264905369159
Epoch 33
-------------------------------
Batch 1/64 loss: 0.363338828086853
Batch 2/64 loss: 0.3612692356109619
Batch 3/64 loss: 0.360190749168396
Batch 4/64 loss: 0.35909396409988403
Batch 5/64 loss: 0.360998272895813
Batch 6/64 loss: 0.36094510555267334
Batch 7/64 loss: 0.364526629447937
Batch 8/64 loss: 0.363991916179657
Batch 9/64 loss: 0.35943782329559326
Batch 10/64 loss: 0.3609253764152527
Batch 11/64 loss: 0.3609244227409363
Batch 12/64 loss: 0.3620797395706177
Batch 13/64 loss: 0.3634932041168213
Batch 14/64 loss: 0.3617178201675415
Batch 15/64 loss: 0.3591066002845764
Batch 16/64 loss: 0.36095285415649414
Batch 17/64 loss: 0.36303240060806274
Batch 18/64 loss: 0.36557936668395996
Batch 19/64 loss: 0.3606410026550293
Batch 20/64 loss: 0.3629636764526367
Batch 21/64 loss: 0.3621569275856018
Batch 22/64 loss: 0.36067652702331543
Batch 23/64 loss: 0.3620563745498657
Batch 24/64 loss: 0.36123043298721313
Batch 25/64 loss: 0.35995692014694214
Batch 26/64 loss: 0.35984158515930176
Batch 27/64 loss: 0.35825884342193604
Batch 28/64 loss: 0.3615725040435791
Batch 29/64 loss: 0.36197566986083984
Batch 30/64 loss: 0.3592301607131958
Batch 31/64 loss: 0.36046767234802246
Batch 32/64 loss: 0.36383122205734253
Batch 33/64 loss: 0.361015260219574
Batch 34/64 loss: 0.359356164932251
Batch 35/64 loss: 0.3590046167373657
Batch 36/64 loss: 0.3645648956298828
Batch 37/64 loss: 0.35808753967285156
Batch 38/64 loss: 0.3568880558013916
Batch 39/64 loss: 0.3616827726364136
Batch 40/64 loss: 0.36358052492141724
Batch 41/64 loss: 0.3613276481628418
Batch 42/64 loss: 0.36166805028915405
Batch 43/64 loss: 0.3608277440071106
Batch 44/64 loss: 0.3617785573005676
Batch 45/64 loss: 0.3597292900085449
Batch 46/64 loss: 0.3606749176979065
Batch 47/64 loss: 0.3626776933670044
Batch 48/64 loss: 0.3602491617202759
Batch 49/64 loss: 0.36117470264434814
Batch 50/64 loss: 0.36206722259521484
Batch 51/64 loss: 0.36062347888946533
Batch 52/64 loss: 0.3610491156578064
Batch 53/64 loss: 0.3623182773590088
Batch 54/64 loss: 0.36245954036712646
Batch 55/64 loss: 0.3576401472091675
Batch 56/64 loss: 0.3633638620376587
Batch 57/64 loss: 0.36476635932922363
Batch 58/64 loss: 0.36254018545150757
Batch 59/64 loss: 0.3652137517929077
Batch 60/64 loss: 0.36124753952026367
Batch 61/64 loss: 0.3585386276245117
Batch 62/64 loss: 0.35851794481277466
Batch 63/64 loss: 0.36338818073272705
Batch 64/64 loss: 0.3607141971588135
Epoch 33  Train loss: 0.361333667530733  Val loss: 0.3629863008191086
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: 0.3617773652076721
Batch 2/64 loss: 0.358468234539032
Batch 3/64 loss: 0.35761600732803345
Batch 4/64 loss: 0.3618922233581543
Batch 5/64 loss: 0.36270177364349365
Batch 6/64 loss: 0.3633401393890381
Batch 7/64 loss: 0.3595503568649292
Batch 8/64 loss: 0.36338233947753906
Batch 9/64 loss: 0.36270672082901
Batch 10/64 loss: 0.35727763175964355
Batch 11/64 loss: 0.3607155680656433
Batch 12/64 loss: 0.36074668169021606
Batch 13/64 loss: 0.36133021116256714
Batch 14/64 loss: 0.36131930351257324
Batch 15/64 loss: 0.35931575298309326
Batch 16/64 loss: 0.35762250423431396
Batch 17/64 loss: 0.3614133596420288
Batch 18/64 loss: 0.3607144355773926
Batch 19/64 loss: 0.3631264567375183
Batch 20/64 loss: 0.3616310954093933
Batch 21/64 loss: 0.3585054874420166
Batch 22/64 loss: 0.360034704208374
Batch 23/64 loss: 0.36166179180145264
Batch 24/64 loss: 0.35691213607788086
Batch 25/64 loss: 0.36226749420166016
Batch 26/64 loss: 0.3596973419189453
Batch 27/64 loss: 0.36046916246414185
Batch 28/64 loss: 0.3603406548500061
Batch 29/64 loss: 0.3596312999725342
Batch 30/64 loss: 0.3617316484451294
Batch 31/64 loss: 0.362846314907074
Batch 32/64 loss: 0.36468029022216797
Batch 33/64 loss: 0.3617047071456909
Batch 34/64 loss: 0.358032763004303
Batch 35/64 loss: 0.361599326133728
Batch 36/64 loss: 0.3617463707923889
Batch 37/64 loss: 0.3614349365234375
Batch 38/64 loss: 0.35979366302490234
Batch 39/64 loss: 0.3615792393684387
Batch 40/64 loss: 0.3607463836669922
Batch 41/64 loss: 0.3605400323867798
Batch 42/64 loss: 0.3634951710700989
Batch 43/64 loss: 0.36240971088409424
Batch 44/64 loss: 0.35958385467529297
Batch 45/64 loss: 0.36293721199035645
Batch 46/64 loss: 0.36401617527008057
Batch 47/64 loss: 0.36102616786956787
Batch 48/64 loss: 0.3627525568008423
Batch 49/64 loss: 0.3618401288986206
Batch 50/64 loss: 0.36072248220443726
Batch 51/64 loss: 0.36347246170043945
Batch 52/64 loss: 0.36225205659866333
Batch 53/64 loss: 0.3599340319633484
Batch 54/64 loss: 0.3619888424873352
Batch 55/64 loss: 0.36180686950683594
Batch 56/64 loss: 0.36039304733276367
Batch 57/64 loss: 0.36157089471817017
Batch 58/64 loss: 0.35969364643096924
Batch 59/64 loss: 0.361594557762146
Batch 60/64 loss: 0.36127907037734985
Batch 61/64 loss: 0.359768271446228
Batch 62/64 loss: 0.3610631227493286
Batch 63/64 loss: 0.36005938053131104
Batch 64/64 loss: 0.36294078826904297
Epoch 34  Train loss: 0.3610740268931669  Val loss: 0.3623491273712866
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: 0.36155688762664795
Batch 2/64 loss: 0.36163830757141113
Batch 3/64 loss: 0.35961270332336426
Batch 4/64 loss: 0.3600633144378662
Batch 5/64 loss: 0.3579564094543457
Batch 6/64 loss: 0.36251163482666016
Batch 7/64 loss: 0.36038708686828613
Batch 8/64 loss: 0.3588855266571045
Batch 9/64 loss: 0.36119794845581055
Batch 10/64 loss: 0.3619105815887451
Batch 11/64 loss: 0.35840386152267456
Batch 12/64 loss: 0.3632654547691345
Batch 13/64 loss: 0.3584127426147461
Batch 14/64 loss: 0.35906875133514404
Batch 15/64 loss: 0.35716694593429565
Batch 16/64 loss: 0.3614206910133362
Batch 17/64 loss: 0.35982298851013184
Batch 18/64 loss: 0.3617965579032898
Batch 19/64 loss: 0.36050522327423096
Batch 20/64 loss: 0.36556804180145264
Batch 21/64 loss: 0.3619263172149658
Batch 22/64 loss: 0.35931599140167236
Batch 23/64 loss: 0.3615718483924866
Batch 24/64 loss: 0.3603261113166809
Batch 25/64 loss: 0.3613475561141968
Batch 26/64 loss: 0.36424458026885986
Batch 27/64 loss: 0.36118555068969727
Batch 28/64 loss: 0.3624650835990906
Batch 29/64 loss: 0.36515307426452637
Batch 30/64 loss: 0.36062419414520264
Batch 31/64 loss: 0.3620297908782959
Batch 32/64 loss: 0.3595327138900757
Batch 33/64 loss: 0.35870349407196045
Batch 34/64 loss: 0.35870349407196045
Batch 35/64 loss: 0.3617023825645447
Batch 36/64 loss: 0.3578885793685913
Batch 37/64 loss: 0.36078786849975586
Batch 38/64 loss: 0.3645438551902771
Batch 39/64 loss: 0.3589766025543213
Batch 40/64 loss: 0.3601416349411011
Batch 41/64 loss: 0.360687255859375
Batch 42/64 loss: 0.3595561981201172
Batch 43/64 loss: 0.3572554588317871
Batch 44/64 loss: 0.3609812259674072
Batch 45/64 loss: 0.35856908559799194
Batch 46/64 loss: 0.3594178557395935
Batch 47/64 loss: 0.35875236988067627
Batch 48/64 loss: 0.36170345544815063
Batch 49/64 loss: 0.3583974242210388
Batch 50/64 loss: 0.35891997814178467
Batch 51/64 loss: 0.3634105920791626
Batch 52/64 loss: 0.3604034185409546
Batch 53/64 loss: 0.358928918838501
Batch 54/64 loss: 0.3606824278831482
Batch 55/64 loss: 0.3601458668708801
Batch 56/64 loss: 0.3588097095489502
Batch 57/64 loss: 0.36017054319381714
Batch 58/64 loss: 0.3599785566329956
Batch 59/64 loss: 0.36057454347610474
Batch 60/64 loss: 0.3584883213043213
Batch 61/64 loss: 0.3616791367530823
Batch 62/64 loss: 0.3590567708015442
Batch 63/64 loss: 0.35782456398010254
Batch 64/64 loss: 0.35675036907196045
Epoch 35  Train loss: 0.36038084450890034  Val loss: 0.36354802482316584
Epoch 36
-------------------------------
Batch 1/64 loss: 0.3623744249343872
Batch 2/64 loss: 0.35985851287841797
Batch 3/64 loss: 0.359113872051239
Batch 4/64 loss: 0.360771119594574
Batch 5/64 loss: 0.36079734563827515
Batch 6/64 loss: 0.3578602075576782
Batch 7/64 loss: 0.3622626066207886
Batch 8/64 loss: 0.3578009605407715
Batch 9/64 loss: 0.3591512441635132
Batch 10/64 loss: 0.363039493560791
Batch 11/64 loss: 0.36285650730133057
Batch 12/64 loss: 0.36106836795806885
Batch 13/64 loss: 0.35987389087677
Batch 14/64 loss: 0.3604933023452759
Batch 15/64 loss: 0.3608208894729614
Batch 16/64 loss: 0.3608260750770569
Batch 17/64 loss: 0.3629642724990845
Batch 18/64 loss: 0.36158084869384766
Batch 19/64 loss: 0.36249685287475586
Batch 20/64 loss: 0.3625907897949219
Batch 21/64 loss: 0.35986030101776123
Batch 22/64 loss: 0.35464727878570557
Batch 23/64 loss: 0.3591092824935913
Batch 24/64 loss: 0.3587195873260498
Batch 25/64 loss: 0.36066365242004395
Batch 26/64 loss: 0.36574941873550415
Batch 27/64 loss: 0.3605431318283081
Batch 28/64 loss: 0.3593897819519043
Batch 29/64 loss: 0.3594897985458374
Batch 30/64 loss: 0.36126041412353516
Batch 31/64 loss: 0.36165428161621094
Batch 32/64 loss: 0.3591495752334595
Batch 33/64 loss: 0.36492693424224854
Batch 34/64 loss: 0.3576531410217285
Batch 35/64 loss: 0.36320340633392334
Batch 36/64 loss: 0.36055028438568115
Batch 37/64 loss: 0.35928022861480713
Batch 38/64 loss: 0.3643835783004761
Batch 39/64 loss: 0.3581113815307617
Batch 40/64 loss: 0.35838067531585693
Batch 41/64 loss: 0.3605227470397949
Batch 42/64 loss: 0.3633163571357727
Batch 43/64 loss: 0.3594698905944824
Batch 44/64 loss: 0.3552436828613281
Batch 45/64 loss: 0.36416929960250854
Batch 46/64 loss: 0.36157476902008057
Batch 47/64 loss: 0.36460816860198975
Batch 48/64 loss: 0.35937803983688354
Batch 49/64 loss: 0.3628354072570801
Batch 50/64 loss: 0.3605935573577881
Batch 51/64 loss: 0.3588784337043762
Batch 52/64 loss: 0.3564314842224121
Batch 53/64 loss: 0.36107081174850464
Batch 54/64 loss: 0.35898280143737793
Batch 55/64 loss: 0.36041390895843506
Batch 56/64 loss: 0.35638535022735596
Batch 57/64 loss: 0.36052024364471436
Batch 58/64 loss: 0.35959291458129883
Batch 59/64 loss: 0.3595636487007141
Batch 60/64 loss: 0.35889554023742676
Batch 61/64 loss: 0.36048388481140137
Batch 62/64 loss: 0.3607677221298218
Batch 63/64 loss: 0.3613523244857788
Batch 64/64 loss: 0.36244380474090576
Epoch 36  Train loss: 0.36050527937272014  Val loss: 0.36175091446879803
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 0.3603525161743164
Batch 2/64 loss: 0.36385953426361084
Batch 3/64 loss: 0.36226969957351685
Batch 4/64 loss: 0.3615936040878296
Batch 5/64 loss: 0.35739046335220337
Batch 6/64 loss: 0.36025428771972656
Batch 7/64 loss: 0.35758060216903687
Batch 8/64 loss: 0.3587106466293335
Batch 9/64 loss: 0.36019808053970337
Batch 10/64 loss: 0.35995030403137207
Batch 11/64 loss: 0.3609962463378906
Batch 12/64 loss: 0.3623412847518921
Batch 13/64 loss: 0.36032116413116455
Batch 14/64 loss: 0.35836899280548096
Batch 15/64 loss: 0.3627452254295349
Batch 16/64 loss: 0.35887157917022705
Batch 17/64 loss: 0.3578745126724243
Batch 18/64 loss: 0.35978269577026367
Batch 19/64 loss: 0.35712480545043945
Batch 20/64 loss: 0.35700857639312744
Batch 21/64 loss: 0.3592723608016968
Batch 22/64 loss: 0.3648609519004822
Batch 23/64 loss: 0.35787802934646606
Batch 24/64 loss: 0.3602412939071655
Batch 25/64 loss: 0.3607519268989563
Batch 26/64 loss: 0.36137449741363525
Batch 27/64 loss: 0.35755372047424316
Batch 28/64 loss: 0.36160725355148315
Batch 29/64 loss: 0.3574897050857544
Batch 30/64 loss: 0.35721349716186523
Batch 31/64 loss: 0.3593435287475586
Batch 32/64 loss: 0.3596792221069336
Batch 33/64 loss: 0.3610832691192627
Batch 34/64 loss: 0.3607417941093445
Batch 35/64 loss: 0.35637563467025757
Batch 36/64 loss: 0.3581489324569702
Batch 37/64 loss: 0.36300039291381836
Batch 38/64 loss: 0.3589940071105957
Batch 39/64 loss: 0.3603461980819702
Batch 40/64 loss: 0.36254918575286865
Batch 41/64 loss: 0.3594653606414795
Batch 42/64 loss: 0.3595167398452759
Batch 43/64 loss: 0.35907208919525146
Batch 44/64 loss: 0.35975903272628784
Batch 45/64 loss: 0.3582667112350464
Batch 46/64 loss: 0.3596266508102417
Batch 47/64 loss: 0.35693079233169556
Batch 48/64 loss: 0.3599659204483032
Batch 49/64 loss: 0.3620215654373169
Batch 50/64 loss: 0.3603948950767517
Batch 51/64 loss: 0.35965263843536377
Batch 52/64 loss: 0.3582465648651123
Batch 53/64 loss: 0.36137449741363525
Batch 54/64 loss: 0.36058509349823
Batch 55/64 loss: 0.3615708351135254
Batch 56/64 loss: 0.3589463233947754
Batch 57/64 loss: 0.35734713077545166
Batch 58/64 loss: 0.3586798906326294
Batch 59/64 loss: 0.3628082275390625
Batch 60/64 loss: 0.35737645626068115
Batch 61/64 loss: 0.3592197299003601
Batch 62/64 loss: 0.3618919849395752
Batch 63/64 loss: 0.3605698347091675
Batch 64/64 loss: 0.3594125509262085
Epoch 37  Train loss: 0.3598266447291655  Val loss: 0.36251875788895127
Epoch 38
-------------------------------
Batch 1/64 loss: 0.36315929889678955
Batch 2/64 loss: 0.3615241050720215
Batch 3/64 loss: 0.3595353960990906
Batch 4/64 loss: 0.35710203647613525
Batch 5/64 loss: 0.3601006865501404
Batch 6/64 loss: 0.3607773780822754
Batch 7/64 loss: 0.36284905672073364
Batch 8/64 loss: 0.3581390380859375
Batch 9/64 loss: 0.35655248165130615
Batch 10/64 loss: 0.36163508892059326
Batch 11/64 loss: 0.35251665115356445
Batch 12/64 loss: 0.3601014018058777
Batch 13/64 loss: 0.3591172695159912
Batch 14/64 loss: 0.3588019013404846
Batch 15/64 loss: 0.36115455627441406
Batch 16/64 loss: 0.3577168583869934
Batch 17/64 loss: 0.3612227439880371
Batch 18/64 loss: 0.3579290509223938
Batch 19/64 loss: 0.35881364345550537
Batch 20/64 loss: 0.3578639030456543
Batch 21/64 loss: 0.36048996448516846
Batch 22/64 loss: 0.35921192169189453
Batch 23/64 loss: 0.35884881019592285
Batch 24/64 loss: 0.358881413936615
Batch 25/64 loss: 0.3625635504722595
Batch 26/64 loss: 0.35744524002075195
Batch 27/64 loss: 0.35999661684036255
Batch 28/64 loss: 0.362030029296875
Batch 29/64 loss: 0.35949623584747314
Batch 30/64 loss: 0.35944342613220215
Batch 31/64 loss: 0.35592252016067505
Batch 32/64 loss: 0.3580971956253052
Batch 33/64 loss: 0.36146581172943115
Batch 34/64 loss: 0.3570869565010071
Batch 35/64 loss: 0.3579534888267517
Batch 36/64 loss: 0.3548683524131775
Batch 37/64 loss: 0.358070433139801
Batch 38/64 loss: 0.3593481779098511
Batch 39/64 loss: 0.36156678199768066
Batch 40/64 loss: 0.3622133731842041
Batch 41/64 loss: 0.36068177223205566
Batch 42/64 loss: 0.35972487926483154
Batch 43/64 loss: 0.3586687445640564
Batch 44/64 loss: 0.3611520528793335
Batch 45/64 loss: 0.360903799533844
Batch 46/64 loss: 0.3592381477355957
Batch 47/64 loss: 0.35904139280319214
Batch 48/64 loss: 0.36156153678894043
Batch 49/64 loss: 0.35613179206848145
Batch 50/64 loss: 0.35782575607299805
Batch 51/64 loss: 0.35928839445114136
Batch 52/64 loss: 0.36010122299194336
Batch 53/64 loss: 0.36266028881073
Batch 54/64 loss: 0.35718655586242676
Batch 55/64 loss: 0.35773372650146484
Batch 56/64 loss: 0.36233192682266235
Batch 57/64 loss: 0.3546721935272217
Batch 58/64 loss: 0.3595716953277588
Batch 59/64 loss: 0.3604179620742798
Batch 60/64 loss: 0.35785698890686035
Batch 61/64 loss: 0.36139655113220215
Batch 62/64 loss: 0.3640473484992981
Batch 63/64 loss: 0.3623228669166565
Batch 64/64 loss: 0.35688960552215576
Epoch 38  Train loss: 0.3594321199491912  Val loss: 0.3616896142664644
Saving best model, epoch: 38
Epoch 39
-------------------------------
Batch 1/64 loss: 0.36068952083587646
Batch 2/64 loss: 0.35930556058883667
Batch 3/64 loss: 0.358031690120697
Batch 4/64 loss: 0.3592177629470825
Batch 5/64 loss: 0.3572426438331604
Batch 6/64 loss: 0.3584012985229492
Batch 7/64 loss: 0.36203038692474365
Batch 8/64 loss: 0.35808056592941284
Batch 9/64 loss: 0.3590657711029053
Batch 10/64 loss: 0.3633890748023987
Batch 11/64 loss: 0.3599739670753479
Batch 12/64 loss: 0.3567779064178467
Batch 13/64 loss: 0.35718828439712524
Batch 14/64 loss: 0.3573906421661377
Batch 15/64 loss: 0.3580336570739746
Batch 16/64 loss: 0.36145710945129395
Batch 17/64 loss: 0.3570058345794678
Batch 18/64 loss: 0.35913628339767456
Batch 19/64 loss: 0.36085301637649536
Batch 20/64 loss: 0.35817277431488037
Batch 21/64 loss: 0.35908961296081543
Batch 22/64 loss: 0.35737109184265137
Batch 23/64 loss: 0.36015403270721436
Batch 24/64 loss: 0.3591959476470947
Batch 25/64 loss: 0.3572181463241577
Batch 26/64 loss: 0.35890257358551025
Batch 27/64 loss: 0.36049216985702515
Batch 28/64 loss: 0.3600219488143921
Batch 29/64 loss: 0.3589169979095459
Batch 30/64 loss: 0.3584917187690735
Batch 31/64 loss: 0.3594200611114502
Batch 32/64 loss: 0.3592795729637146
Batch 33/64 loss: 0.3603161573410034
Batch 34/64 loss: 0.35858649015426636
Batch 35/64 loss: 0.36081254482269287
Batch 36/64 loss: 0.356309175491333
Batch 37/64 loss: 0.36083167791366577
Batch 38/64 loss: 0.36154472827911377
Batch 39/64 loss: 0.36090087890625
Batch 40/64 loss: 0.3569819927215576
Batch 41/64 loss: 0.35885947942733765
Batch 42/64 loss: 0.3596012592315674
Batch 43/64 loss: 0.36105889081954956
Batch 44/64 loss: 0.3615097403526306
Batch 45/64 loss: 0.36006033420562744
Batch 46/64 loss: 0.36041176319122314
Batch 47/64 loss: 0.3578885793685913
Batch 48/64 loss: 0.3556210994720459
Batch 49/64 loss: 0.36170506477355957
Batch 50/64 loss: 0.3583793640136719
Batch 51/64 loss: 0.36099404096603394
Batch 52/64 loss: 0.3614426255226135
Batch 53/64 loss: 0.3573591709136963
Batch 54/64 loss: 0.361301064491272
Batch 55/64 loss: 0.3568292260169983
Batch 56/64 loss: 0.35889071226119995
Batch 57/64 loss: 0.36024415493011475
Batch 58/64 loss: 0.35951656103134155
Batch 59/64 loss: 0.3611724376678467
Batch 60/64 loss: 0.3587886095046997
Batch 61/64 loss: 0.3574235439300537
Batch 62/64 loss: 0.3606877326965332
Batch 63/64 loss: 0.3598102331161499
Batch 64/64 loss: 0.3605480194091797
Epoch 39  Train loss: 0.3593136937010522  Val loss: 0.36101524608651386
Saving best model, epoch: 39
Epoch 40
-------------------------------
Batch 1/64 loss: 0.35907673835754395
Batch 2/64 loss: 0.35823243856430054
Batch 3/64 loss: 0.3607981204986572
Batch 4/64 loss: 0.357998251914978
Batch 5/64 loss: 0.3595758080482483
Batch 6/64 loss: 0.3586195111274719
Batch 7/64 loss: 0.3622562289237976
Batch 8/64 loss: 0.36015188694000244
Batch 9/64 loss: 0.355251669883728
Batch 10/64 loss: 0.3581315279006958
Batch 11/64 loss: 0.3582606315612793
Batch 12/64 loss: 0.3585585355758667
Batch 13/64 loss: 0.3605738878250122
Batch 14/64 loss: 0.36015743017196655
Batch 15/64 loss: 0.3608778715133667
Batch 16/64 loss: 0.35734987258911133
Batch 17/64 loss: 0.3578636646270752
Batch 18/64 loss: 0.3603416681289673
Batch 19/64 loss: 0.3556253910064697
Batch 20/64 loss: 0.35630619525909424
Batch 21/64 loss: 0.35844868421554565
Batch 22/64 loss: 0.36064422130584717
Batch 23/64 loss: 0.3567994236946106
Batch 24/64 loss: 0.35893625020980835
Batch 25/64 loss: 0.35418450832366943
Batch 26/64 loss: 0.3575385808944702
Batch 27/64 loss: 0.3592371940612793
Batch 28/64 loss: 0.3582901954650879
Batch 29/64 loss: 0.36099690198898315
Batch 30/64 loss: 0.3629724979400635
Batch 31/64 loss: 0.356603741645813
Batch 32/64 loss: 0.362216591835022
Batch 33/64 loss: 0.35779446363449097
Batch 34/64 loss: 0.35999882221221924
Batch 35/64 loss: 0.35848498344421387
Batch 36/64 loss: 0.3626216650009155
Batch 37/64 loss: 0.3607597351074219
Batch 38/64 loss: 0.3579663038253784
Batch 39/64 loss: 0.3569374084472656
Batch 40/64 loss: 0.35775458812713623
Batch 41/64 loss: 0.3589738607406616
Batch 42/64 loss: 0.3614988327026367
Batch 43/64 loss: 0.3587278127670288
Batch 44/64 loss: 0.35906922817230225
Batch 45/64 loss: 0.36070024967193604
Batch 46/64 loss: 0.3606466054916382
Batch 47/64 loss: 0.36203843355178833
Batch 48/64 loss: 0.35931921005249023
Batch 49/64 loss: 0.35889315605163574
Batch 50/64 loss: 0.3577146530151367
Batch 51/64 loss: 0.36099064350128174
Batch 52/64 loss: 0.3574296236038208
Batch 53/64 loss: 0.35532355308532715
Batch 54/64 loss: 0.3587973117828369
Batch 55/64 loss: 0.35705506801605225
Batch 56/64 loss: 0.3577359914779663
Batch 57/64 loss: 0.35955631732940674
Batch 58/64 loss: 0.3568210005760193
Batch 59/64 loss: 0.35759222507476807
Batch 60/64 loss: 0.3573873043060303
Batch 61/64 loss: 0.35772407054901123
Batch 62/64 loss: 0.3609297275543213
Batch 63/64 loss: 0.3615245819091797
Batch 64/64 loss: 0.3562506437301636
Epoch 40  Train loss: 0.3588836319306318  Val loss: 0.36164449518898506
Epoch 41
-------------------------------
Batch 1/64 loss: 0.3580712080001831
Batch 2/64 loss: 0.36029088497161865
Batch 3/64 loss: 0.3584914207458496
Batch 4/64 loss: 0.3577650189399719
Batch 5/64 loss: 0.3565666675567627
Batch 6/64 loss: 0.3602031469345093
Batch 7/64 loss: 0.35518068075180054
Batch 8/64 loss: 0.35905367136001587
Batch 9/64 loss: 0.36157578229904175
Batch 10/64 loss: 0.3591342568397522
Batch 11/64 loss: 0.357300341129303
Batch 12/64 loss: 0.3599836230278015
Batch 13/64 loss: 0.3585137128829956
Batch 14/64 loss: 0.3602392077445984
Batch 15/64 loss: 0.3627971410751343
Batch 16/64 loss: 0.35761559009552
Batch 17/64 loss: 0.355751097202301
Batch 18/64 loss: 0.35896432399749756
Batch 19/64 loss: 0.3603002429008484
Batch 20/64 loss: 0.36175525188446045
Batch 21/64 loss: 0.35637712478637695
Batch 22/64 loss: 0.3591300845146179
Batch 23/64 loss: 0.36123865842819214
Batch 24/64 loss: 0.3595998287200928
Batch 25/64 loss: 0.35548460483551025
Batch 26/64 loss: 0.3575904369354248
Batch 27/64 loss: 0.3572697043418884
Batch 28/64 loss: 0.3568035364151001
Batch 29/64 loss: 0.3614393472671509
Batch 30/64 loss: 0.357082724571228
Batch 31/64 loss: 0.3580514192581177
Batch 32/64 loss: 0.35815441608428955
Batch 33/64 loss: 0.3555118441581726
Batch 34/64 loss: 0.35847485065460205
Batch 35/64 loss: 0.35720986127853394
Batch 36/64 loss: 0.35670530796051025
Batch 37/64 loss: 0.36229997873306274
Batch 38/64 loss: 0.3600841760635376
Batch 39/64 loss: 0.35649216175079346
Batch 40/64 loss: 0.3594238758087158
Batch 41/64 loss: 0.3606829047203064
Batch 42/64 loss: 0.35740208625793457
Batch 43/64 loss: 0.35645198822021484
Batch 44/64 loss: 0.35642844438552856
Batch 45/64 loss: 0.3556642532348633
Batch 46/64 loss: 0.3593015670776367
Batch 47/64 loss: 0.35818934440612793
Batch 48/64 loss: 0.35798585414886475
Batch 49/64 loss: 0.35923314094543457
Batch 50/64 loss: 0.3578070402145386
Batch 51/64 loss: 0.35571444034576416
Batch 52/64 loss: 0.36062777042388916
Batch 53/64 loss: 0.3611956238746643
Batch 54/64 loss: 0.35938751697540283
Batch 55/64 loss: 0.3561899662017822
Batch 56/64 loss: 0.35724765062332153
Batch 57/64 loss: 0.3584388494491577
Batch 58/64 loss: 0.35677599906921387
Batch 59/64 loss: 0.3592872619628906
Batch 60/64 loss: 0.3595541715621948
Batch 61/64 loss: 0.36450862884521484
Batch 62/64 loss: 0.3579239845275879
Batch 63/64 loss: 0.3566906452178955
Batch 64/64 loss: 0.3600984215736389
Epoch 41  Train loss: 0.3585371005768869  Val loss: 0.3616842314140084
Epoch 42
-------------------------------
Batch 1/64 loss: 0.3625056743621826
Batch 2/64 loss: 0.3588411808013916
Batch 3/64 loss: 0.3560565114021301
Batch 4/64 loss: 0.35725271701812744
Batch 5/64 loss: 0.3558086156845093
Batch 6/64 loss: 0.35425257682800293
Batch 7/64 loss: 0.3607797622680664
Batch 8/64 loss: 0.35723990201950073
Batch 9/64 loss: 0.35819393396377563
Batch 10/64 loss: 0.355998158454895
Batch 11/64 loss: 0.3594856262207031
Batch 12/64 loss: 0.3565230369567871
Batch 13/64 loss: 0.35793328285217285
Batch 14/64 loss: 0.3591073751449585
Batch 15/64 loss: 0.3574908971786499
Batch 16/64 loss: 0.35809820890426636
Batch 17/64 loss: 0.3602789640426636
Batch 18/64 loss: 0.35350239276885986
Batch 19/64 loss: 0.35657966136932373
Batch 20/64 loss: 0.35743021965026855
Batch 21/64 loss: 0.3603389263153076
Batch 22/64 loss: 0.3600059747695923
Batch 23/64 loss: 0.36149144172668457
Batch 24/64 loss: 0.35738492012023926
Batch 25/64 loss: 0.3628801107406616
Batch 26/64 loss: 0.35780787467956543
Batch 27/64 loss: 0.3624284267425537
Batch 28/64 loss: 0.3627880811691284
Batch 29/64 loss: 0.3586122989654541
Batch 30/64 loss: 0.35837578773498535
Batch 31/64 loss: 0.3596295118331909
Batch 32/64 loss: 0.3603334426879883
Batch 33/64 loss: 0.3610442280769348
Batch 34/64 loss: 0.3566674590110779
Batch 35/64 loss: 0.3546409010887146
Batch 36/64 loss: 0.35666465759277344
Batch 37/64 loss: 0.35701286792755127
Batch 38/64 loss: 0.3563727140426636
Batch 39/64 loss: 0.36155545711517334
Batch 40/64 loss: 0.35721588134765625
Batch 41/64 loss: 0.35645997524261475
Batch 42/64 loss: 0.3574817180633545
Batch 43/64 loss: 0.3545899987220764
Batch 44/64 loss: 0.3529461622238159
Batch 45/64 loss: 0.3563053607940674
Batch 46/64 loss: 0.3583824634552002
Batch 47/64 loss: 0.3595707416534424
Batch 48/64 loss: 0.35666561126708984
Batch 49/64 loss: 0.35860931873321533
Batch 50/64 loss: 0.3593076467514038
Batch 51/64 loss: 0.3567599058151245
Batch 52/64 loss: 0.3596888780593872
Batch 53/64 loss: 0.35901522636413574
Batch 54/64 loss: 0.35540956258773804
Batch 55/64 loss: 0.3577226400375366
Batch 56/64 loss: 0.3581116199493408
Batch 57/64 loss: 0.3581801652908325
Batch 58/64 loss: 0.3554159998893738
Batch 59/64 loss: 0.3600144386291504
Batch 60/64 loss: 0.3603835105895996
Batch 61/64 loss: 0.3592807650566101
Batch 62/64 loss: 0.35743647813796997
Batch 63/64 loss: 0.3579378128051758
Batch 64/64 loss: 0.3628852367401123
Epoch 42  Train loss: 0.3581874445372937  Val loss: 0.3625504122566931
Epoch 43
-------------------------------
Batch 1/64 loss: 0.3580058217048645
Batch 2/64 loss: 0.362728476524353
Batch 3/64 loss: 0.35922563076019287
Batch 4/64 loss: 0.3570138216018677
Batch 5/64 loss: 0.3561106324195862
Batch 6/64 loss: 0.3587096333503723
Batch 7/64 loss: 0.3590635061264038
Batch 8/64 loss: 0.3609445095062256
Batch 9/64 loss: 0.36245065927505493
Batch 10/64 loss: 0.3592482805252075
Batch 11/64 loss: 0.3582608699798584
Batch 12/64 loss: 0.3586117625236511
Batch 13/64 loss: 0.360008180141449
Batch 14/64 loss: 0.3617534637451172
Batch 15/64 loss: 0.35865044593811035
Batch 16/64 loss: 0.3560302257537842
Batch 17/64 loss: 0.35677844285964966
Batch 18/64 loss: 0.356248140335083
Batch 19/64 loss: 0.359991192817688
Batch 20/64 loss: 0.3580390214920044
Batch 21/64 loss: 0.3543073534965515
Batch 22/64 loss: 0.36209702491760254
Batch 23/64 loss: 0.3596489429473877
Batch 24/64 loss: 0.35701870918273926
Batch 25/64 loss: 0.3578014373779297
Batch 26/64 loss: 0.3593231439590454
Batch 27/64 loss: 0.35849153995513916
Batch 28/64 loss: 0.35411232709884644
Batch 29/64 loss: 0.3584790825843811
Batch 30/64 loss: 0.3559606075286865
Batch 31/64 loss: 0.3549039363861084
Batch 32/64 loss: 0.358370304107666
Batch 33/64 loss: 0.3550781011581421
Batch 34/64 loss: 0.3612027168273926
Batch 35/64 loss: 0.3564075231552124
Batch 36/64 loss: 0.359197735786438
Batch 37/64 loss: 0.3604395389556885
Batch 38/64 loss: 0.3574509024620056
Batch 39/64 loss: 0.35753291845321655
Batch 40/64 loss: 0.3577674627304077
Batch 41/64 loss: 0.3564409017562866
Batch 42/64 loss: 0.35762280225753784
Batch 43/64 loss: 0.35859429836273193
Batch 44/64 loss: 0.3564799427986145
Batch 45/64 loss: 0.35507071018218994
Batch 46/64 loss: 0.3551422357559204
Batch 47/64 loss: 0.35676294565200806
Batch 48/64 loss: 0.356221079826355
Batch 49/64 loss: 0.35730862617492676
Batch 50/64 loss: 0.3579219579696655
Batch 51/64 loss: 0.35965782403945923
Batch 52/64 loss: 0.357144832611084
Batch 53/64 loss: 0.3556220531463623
Batch 54/64 loss: 0.3611823320388794
Batch 55/64 loss: 0.35634177923202515
Batch 56/64 loss: 0.36049771308898926
Batch 57/64 loss: 0.3553321361541748
Batch 58/64 loss: 0.35751378536224365
Batch 59/64 loss: 0.3589603304862976
Batch 60/64 loss: 0.35551750659942627
Batch 61/64 loss: 0.3579162359237671
Batch 62/64 loss: 0.3625885844230652
Batch 63/64 loss: 0.355576753616333
Batch 64/64 loss: 0.35318076610565186
Epoch 43  Train loss: 0.3579571289174697  Val loss: 0.3598593885136634
Saving best model, epoch: 43
Epoch 44
-------------------------------
Batch 1/64 loss: 0.35720574855804443
Batch 2/64 loss: 0.35735785961151123
Batch 3/64 loss: 0.3585219383239746
Batch 4/64 loss: 0.356243371963501
Batch 5/64 loss: 0.35533130168914795
Batch 6/64 loss: 0.3579481840133667
Batch 7/64 loss: 0.3532067537307739
Batch 8/64 loss: 0.3573547601699829
Batch 9/64 loss: 0.35562604665756226
Batch 10/64 loss: 0.35641294717788696
Batch 11/64 loss: 0.357917845249176
Batch 12/64 loss: 0.3589968681335449
Batch 13/64 loss: 0.35746175050735474
Batch 14/64 loss: 0.35639917850494385
Batch 15/64 loss: 0.3580475449562073
Batch 16/64 loss: 0.35816890001296997
Batch 17/64 loss: 0.35655927658081055
Batch 18/64 loss: 0.3537914752960205
Batch 19/64 loss: 0.3540741205215454
Batch 20/64 loss: 0.35592442750930786
Batch 21/64 loss: 0.3570380210876465
Batch 22/64 loss: 0.35414403676986694
Batch 23/64 loss: 0.35812222957611084
Batch 24/64 loss: 0.35370945930480957
Batch 25/64 loss: 0.35764485597610474
Batch 26/64 loss: 0.35929226875305176
Batch 27/64 loss: 0.35775959491729736
Batch 28/64 loss: 0.35721826553344727
Batch 29/64 loss: 0.36112165451049805
Batch 30/64 loss: 0.3597067594528198
Batch 31/64 loss: 0.36094701290130615
Batch 32/64 loss: 0.3554220199584961
Batch 33/64 loss: 0.3573899269104004
Batch 34/64 loss: 0.3587610125541687
Batch 35/64 loss: 0.35395073890686035
Batch 36/64 loss: 0.35648322105407715
Batch 37/64 loss: 0.35427772998809814
Batch 38/64 loss: 0.3560473322868347
Batch 39/64 loss: 0.3572293519973755
Batch 40/64 loss: 0.3561314344406128
Batch 41/64 loss: 0.3562570810317993
Batch 42/64 loss: 0.3587285280227661
Batch 43/64 loss: 0.35537099838256836
Batch 44/64 loss: 0.35651302337646484
Batch 45/64 loss: 0.3568423390388489
Batch 46/64 loss: 0.3597937226295471
Batch 47/64 loss: 0.3611740469932556
Batch 48/64 loss: 0.36040008068084717
Batch 49/64 loss: 0.35401248931884766
Batch 50/64 loss: 0.35780495405197144
Batch 51/64 loss: 0.3563317060470581
Batch 52/64 loss: 0.35515129566192627
Batch 53/64 loss: 0.3561939001083374
Batch 54/64 loss: 0.358165442943573
Batch 55/64 loss: 0.3595621585845947
Batch 56/64 loss: 0.3574827313423157
Batch 57/64 loss: 0.35992205142974854
Batch 58/64 loss: 0.355211079120636
Batch 59/64 loss: 0.35886746644973755
Batch 60/64 loss: 0.35961902141571045
Batch 61/64 loss: 0.3560529947280884
Batch 62/64 loss: 0.35754966735839844
Batch 63/64 loss: 0.3547849655151367
Batch 64/64 loss: 0.3608878254890442
Epoch 44  Train loss: 0.3571357621866114  Val loss: 0.36020420814297865
Epoch 45
-------------------------------
Batch 1/64 loss: 0.35640645027160645
Batch 2/64 loss: 0.3588715195655823
Batch 3/64 loss: 0.35613906383514404
Batch 4/64 loss: 0.3580443859100342
Batch 5/64 loss: 0.35809826850891113
Batch 6/64 loss: 0.35297679901123047
Batch 7/64 loss: 0.36111271381378174
Batch 8/64 loss: 0.3589692711830139
Batch 9/64 loss: 0.3574245572090149
Batch 10/64 loss: 0.35608065128326416
Batch 11/64 loss: 0.353998064994812
Batch 12/64 loss: 0.3518720269203186
Batch 13/64 loss: 0.3572126626968384
Batch 14/64 loss: 0.35536623001098633
Batch 15/64 loss: 0.36230242252349854
Batch 16/64 loss: 0.35712730884552
Batch 17/64 loss: 0.35846251249313354
Batch 18/64 loss: 0.3548927307128906
Batch 19/64 loss: 0.35823261737823486
Batch 20/64 loss: 0.35478508472442627
Batch 21/64 loss: 0.3536425828933716
Batch 22/64 loss: 0.3548034429550171
Batch 23/64 loss: 0.35632646083831787
Batch 24/64 loss: 0.3605717420578003
Batch 25/64 loss: 0.35702306032180786
Batch 26/64 loss: 0.35644400119781494
Batch 27/64 loss: 0.3562948703765869
Batch 28/64 loss: 0.3568841814994812
Batch 29/64 loss: 0.3536836504936218
Batch 30/64 loss: 0.35558587312698364
Batch 31/64 loss: 0.3544830083847046
Batch 32/64 loss: 0.34973573684692383
Batch 33/64 loss: 0.35541969537734985
Batch 34/64 loss: 0.3588830828666687
Batch 35/64 loss: 0.3543661832809448
Batch 36/64 loss: 0.36023616790771484
Batch 37/64 loss: 0.3591039180755615
Batch 38/64 loss: 0.35634422302246094
Batch 39/64 loss: 0.357416033744812
Batch 40/64 loss: 0.35880279541015625
Batch 41/64 loss: 0.3564974069595337
Batch 42/64 loss: 0.3569049835205078
Batch 43/64 loss: 0.356736421585083
Batch 44/64 loss: 0.3589184284210205
Batch 45/64 loss: 0.3555706739425659
Batch 46/64 loss: 0.356473445892334
Batch 47/64 loss: 0.35852885246276855
Batch 48/64 loss: 0.3562436103820801
Batch 49/64 loss: 0.3607310652732849
Batch 50/64 loss: 0.35645854473114014
Batch 51/64 loss: 0.3587120771408081
Batch 52/64 loss: 0.3552933931350708
Batch 53/64 loss: 0.3566861152648926
Batch 54/64 loss: 0.36051344871520996
Batch 55/64 loss: 0.3530641794204712
Batch 56/64 loss: 0.3605128526687622
Batch 57/64 loss: 0.3564305901527405
Batch 58/64 loss: 0.3563159108161926
Batch 59/64 loss: 0.3541761636734009
Batch 60/64 loss: 0.3578718900680542
Batch 61/64 loss: 0.3579789996147156
Batch 62/64 loss: 0.35774654150009155
Batch 63/64 loss: 0.35866808891296387
Batch 64/64 loss: 0.3557320833206177
Epoch 45  Train loss: 0.3568354321461098  Val loss: 0.3587215352304203
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: 0.3536432981491089
Batch 2/64 loss: 0.3571254014968872
Batch 3/64 loss: 0.3579362630844116
Batch 4/64 loss: 0.3584192991256714
Batch 5/64 loss: 0.35493266582489014
Batch 6/64 loss: 0.3570091724395752
Batch 7/64 loss: 0.3567918539047241
Batch 8/64 loss: 0.3563304543495178
Batch 9/64 loss: 0.3512163758277893
Batch 10/64 loss: 0.35375380516052246
Batch 11/64 loss: 0.3583945035934448
Batch 12/64 loss: 0.35726118087768555
Batch 13/64 loss: 0.3589932918548584
Batch 14/64 loss: 0.3565043807029724
Batch 15/64 loss: 0.3609299659729004
Batch 16/64 loss: 0.3535587191581726
Batch 17/64 loss: 0.35642820596694946
Batch 18/64 loss: 0.3585778474807739
Batch 19/64 loss: 0.35760390758514404
Batch 20/64 loss: 0.3585140109062195
Batch 21/64 loss: 0.3595517873764038
Batch 22/64 loss: 0.3566051125526428
Batch 23/64 loss: 0.35963964462280273
Batch 24/64 loss: 0.3565954566001892
Batch 25/64 loss: 0.3600432872772217
Batch 26/64 loss: 0.35683149099349976
Batch 27/64 loss: 0.35564589500427246
Batch 28/64 loss: 0.35537755489349365
Batch 29/64 loss: 0.36083877086639404
Batch 30/64 loss: 0.35901033878326416
Batch 31/64 loss: 0.35338884592056274
Batch 32/64 loss: 0.3553398847579956
Batch 33/64 loss: 0.355413556098938
Batch 34/64 loss: 0.35627198219299316
Batch 35/64 loss: 0.35575973987579346
Batch 36/64 loss: 0.35489702224731445
Batch 37/64 loss: 0.35547566413879395
Batch 38/64 loss: 0.3571721315383911
Batch 39/64 loss: 0.35546815395355225
Batch 40/64 loss: 0.3559786081314087
Batch 41/64 loss: 0.35713082551956177
Batch 42/64 loss: 0.3565932512283325
Batch 43/64 loss: 0.3544480800628662
Batch 44/64 loss: 0.3568917512893677
Batch 45/64 loss: 0.3572967052459717
Batch 46/64 loss: 0.3570011854171753
Batch 47/64 loss: 0.3542941212654114
Batch 48/64 loss: 0.35516679286956787
Batch 49/64 loss: 0.35568881034851074
Batch 50/64 loss: 0.35763251781463623
Batch 51/64 loss: 0.3543394207954407
Batch 52/64 loss: 0.35393059253692627
Batch 53/64 loss: 0.35744374990463257
Batch 54/64 loss: 0.3540741205215454
Batch 55/64 loss: 0.35685479640960693
Batch 56/64 loss: 0.3535810708999634
Batch 57/64 loss: 0.35288894176483154
Batch 58/64 loss: 0.35754936933517456
Batch 59/64 loss: 0.3586742877960205
Batch 60/64 loss: 0.35614269971847534
Batch 61/64 loss: 0.3625379800796509
Batch 62/64 loss: 0.35773152112960815
Batch 63/64 loss: 0.35164380073547363
Batch 64/64 loss: 0.3564523458480835
Epoch 46  Train loss: 0.3564879244449092  Val loss: 0.35991187910853384
Epoch 47
-------------------------------
Batch 1/64 loss: 0.3568457365036011
Batch 2/64 loss: 0.35906732082366943
Batch 3/64 loss: 0.3593331575393677
Batch 4/64 loss: 0.35511350631713867
Batch 5/64 loss: 0.35631418228149414
Batch 6/64 loss: 0.35862863063812256
Batch 7/64 loss: 0.3589220643043518
Batch 8/64 loss: 0.3579294681549072
Batch 9/64 loss: 0.35558509826660156
Batch 10/64 loss: 0.3545585870742798
Batch 11/64 loss: 0.3513904809951782
Batch 12/64 loss: 0.3575557470321655
Batch 13/64 loss: 0.3573651909828186
Batch 14/64 loss: 0.3584127426147461
Batch 15/64 loss: 0.35388052463531494
Batch 16/64 loss: 0.3573175072669983
Batch 17/64 loss: 0.3525813817977905
Batch 18/64 loss: 0.35759830474853516
Batch 19/64 loss: 0.3520078659057617
Batch 20/64 loss: 0.3559759855270386
Batch 21/64 loss: 0.3589683175086975
Batch 22/64 loss: 0.35355132818222046
Batch 23/64 loss: 0.3557472825050354
Batch 24/64 loss: 0.35321611166000366
Batch 25/64 loss: 0.3562150001525879
Batch 26/64 loss: 0.35524982213974
Batch 27/64 loss: 0.3544117212295532
Batch 28/64 loss: 0.3554013967514038
Batch 29/64 loss: 0.35682785511016846
Batch 30/64 loss: 0.3615604639053345
Batch 31/64 loss: 0.3562123775482178
Batch 32/64 loss: 0.3539819121360779
Batch 33/64 loss: 0.35702943801879883
Batch 34/64 loss: 0.3549607992172241
Batch 35/64 loss: 0.3559039831161499
Batch 36/64 loss: 0.3563891649246216
Batch 37/64 loss: 0.3573935031890869
Batch 38/64 loss: 0.35726988315582275
Batch 39/64 loss: 0.35855984687805176
Batch 40/64 loss: 0.3574357032775879
Batch 41/64 loss: 0.35301506519317627
Batch 42/64 loss: 0.3549889326095581
Batch 43/64 loss: 0.35297155380249023
Batch 44/64 loss: 0.3556913137435913
Batch 45/64 loss: 0.36348265409469604
Batch 46/64 loss: 0.35895586013793945
Batch 47/64 loss: 0.35703909397125244
Batch 48/64 loss: 0.35339534282684326
Batch 49/64 loss: 0.3586042523384094
Batch 50/64 loss: 0.3559054732322693
Batch 51/64 loss: 0.3571329116821289
Batch 52/64 loss: 0.35716986656188965
Batch 53/64 loss: 0.35716497898101807
Batch 54/64 loss: 0.3551589846611023
Batch 55/64 loss: 0.3585134744644165
Batch 56/64 loss: 0.3539696931838989
Batch 57/64 loss: 0.35550057888031006
Batch 58/64 loss: 0.35737669467926025
Batch 59/64 loss: 0.36300230026245117
Batch 60/64 loss: 0.3553435802459717
Batch 61/64 loss: 0.3589661121368408
Batch 62/64 loss: 0.3534877300262451
Batch 63/64 loss: 0.35540175437927246
Batch 64/64 loss: 0.3550794720649719
Epoch 47  Train loss: 0.35641125019858866  Val loss: 0.35809236088978874
Saving best model, epoch: 47
Epoch 48
-------------------------------
Batch 1/64 loss: 0.35853004455566406
Batch 2/64 loss: 0.35351866483688354
Batch 3/64 loss: 0.35604655742645264
Batch 4/64 loss: 0.35313332080841064
Batch 5/64 loss: 0.35244059562683105
Batch 6/64 loss: 0.3568234443664551
Batch 7/64 loss: 0.3553285598754883
Batch 8/64 loss: 0.3567596673965454
Batch 9/64 loss: 0.3541114330291748
Batch 10/64 loss: 0.35483890771865845
Batch 11/64 loss: 0.35394805669784546
Batch 12/64 loss: 0.3561764359474182
Batch 13/64 loss: 0.35392773151397705
Batch 14/64 loss: 0.35656726360321045
Batch 15/64 loss: 0.3551504611968994
Batch 16/64 loss: 0.3555992841720581
Batch 17/64 loss: 0.35872137546539307
Batch 18/64 loss: 0.3585021495819092
Batch 19/64 loss: 0.3592008352279663
Batch 20/64 loss: 0.3589453101158142
Batch 21/64 loss: 0.35900944471359253
Batch 22/64 loss: 0.3603174090385437
Batch 23/64 loss: 0.35946744680404663
Batch 24/64 loss: 0.3554050922393799
Batch 25/64 loss: 0.35762590169906616
Batch 26/64 loss: 0.35264724493026733
Batch 27/64 loss: 0.36097943782806396
Batch 28/64 loss: 0.3560658097267151
Batch 29/64 loss: 0.35535353422164917
Batch 30/64 loss: 0.35058271884918213
Batch 31/64 loss: 0.35783934593200684
Batch 32/64 loss: 0.35268402099609375
Batch 33/64 loss: 0.3536788821220398
Batch 34/64 loss: 0.3519415259361267
Batch 35/64 loss: 0.3532549738883972
Batch 36/64 loss: 0.35564732551574707
Batch 37/64 loss: 0.3562091588973999
Batch 38/64 loss: 0.3522437810897827
Batch 39/64 loss: 0.35418641567230225
Batch 40/64 loss: 0.35449373722076416
Batch 41/64 loss: 0.3559185266494751
Batch 42/64 loss: 0.3561016321182251
Batch 43/64 loss: 0.3624647259712219
Batch 44/64 loss: 0.35705673694610596
Batch 45/64 loss: 0.35730528831481934
Batch 46/64 loss: 0.3607429265975952
Batch 47/64 loss: 0.3581768870353699
Batch 48/64 loss: 0.3570106029510498
Batch 49/64 loss: 0.35894501209259033
Batch 50/64 loss: 0.3571370840072632
Batch 51/64 loss: 0.3546783924102783
Batch 52/64 loss: 0.35453110933303833
Batch 53/64 loss: 0.35282397270202637
Batch 54/64 loss: 0.3583430051803589
Batch 55/64 loss: 0.35433852672576904
Batch 56/64 loss: 0.35294777154922485
Batch 57/64 loss: 0.35397374629974365
Batch 58/64 loss: 0.35297900438308716
Batch 59/64 loss: 0.3530464768409729
Batch 60/64 loss: 0.3546544313430786
Batch 61/64 loss: 0.3526037931442261
Batch 62/64 loss: 0.3579394817352295
Batch 63/64 loss: 0.35847795009613037
Batch 64/64 loss: 0.35660749673843384
Epoch 48  Train loss: 0.35588323158376356  Val loss: 0.3578113104469588
Saving best model, epoch: 48
Epoch 49
-------------------------------
Batch 1/64 loss: 0.3547075390815735
Batch 2/64 loss: 0.3573223352432251
Batch 3/64 loss: 0.35550254583358765
Batch 4/64 loss: 0.3538845181465149
Batch 5/64 loss: 0.3524191379547119
Batch 6/64 loss: 0.35322433710098267
Batch 7/64 loss: 0.3532295823097229
Batch 8/64 loss: 0.3518732190132141
Batch 9/64 loss: 0.3540431261062622
Batch 10/64 loss: 0.3582140803337097
Batch 11/64 loss: 0.35631638765335083
Batch 12/64 loss: 0.35693180561065674
Batch 13/64 loss: 0.35606348514556885
Batch 14/64 loss: 0.3546485900878906
Batch 15/64 loss: 0.35274404287338257
Batch 16/64 loss: 0.3571327328681946
Batch 17/64 loss: 0.3552336096763611
Batch 18/64 loss: 0.3552616238594055
Batch 19/64 loss: 0.3551796078681946
Batch 20/64 loss: 0.3538094162940979
Batch 21/64 loss: 0.3560817837715149
Batch 22/64 loss: 0.3557218313217163
Batch 23/64 loss: 0.35174667835235596
Batch 24/64 loss: 0.3537123203277588
Batch 25/64 loss: 0.3561607003211975
Batch 26/64 loss: 0.35112613439559937
Batch 27/64 loss: 0.354978084564209
Batch 28/64 loss: 0.35792702436447144
Batch 29/64 loss: 0.3549080491065979
Batch 30/64 loss: 0.3516915440559387
Batch 31/64 loss: 0.3551650047302246
Batch 32/64 loss: 0.3586265444755554
Batch 33/64 loss: 0.35418760776519775
Batch 34/64 loss: 0.35711783170700073
Batch 35/64 loss: 0.35742413997650146
Batch 36/64 loss: 0.3511449098587036
Batch 37/64 loss: 0.35302597284317017
Batch 38/64 loss: 0.3513953685760498
Batch 39/64 loss: 0.3579777479171753
Batch 40/64 loss: 0.3532048463821411
Batch 41/64 loss: 0.3547414541244507
Batch 42/64 loss: 0.3518432378768921
Batch 43/64 loss: 0.35315561294555664
Batch 44/64 loss: 0.35439562797546387
Batch 45/64 loss: 0.3550822138786316
Batch 46/64 loss: 0.350411057472229
Batch 47/64 loss: 0.35843729972839355
Batch 48/64 loss: 0.3580755591392517
Batch 49/64 loss: 0.35470807552337646
Batch 50/64 loss: 0.35306715965270996
Batch 51/64 loss: 0.3529144525527954
Batch 52/64 loss: 0.3532472252845764
Batch 53/64 loss: 0.35758352279663086
Batch 54/64 loss: 0.3565552234649658
Batch 55/64 loss: 0.35359811782836914
Batch 56/64 loss: 0.354680597782135
Batch 57/64 loss: 0.3569381833076477
Batch 58/64 loss: 0.35603004693984985
Batch 59/64 loss: 0.35552746057510376
Batch 60/64 loss: 0.3531229496002197
Batch 61/64 loss: 0.3558628559112549
Batch 62/64 loss: 0.35662519931793213
Batch 63/64 loss: 0.3602100610733032
Batch 64/64 loss: 0.3539799451828003
Epoch 49  Train loss: 0.35487629806294163  Val loss: 0.3578735985297108
Epoch 50
-------------------------------
Batch 1/64 loss: 0.3568927049636841
Batch 2/64 loss: 0.3572363257408142
Batch 3/64 loss: 0.35177838802337646
Batch 4/64 loss: 0.3548533320426941
Batch 5/64 loss: 0.35549718141555786
Batch 6/64 loss: 0.35012757778167725
Batch 7/64 loss: 0.3550269603729248
Batch 8/64 loss: 0.3556147813796997
Batch 9/64 loss: 0.35406482219696045
Batch 10/64 loss: 0.35198187828063965
Batch 11/64 loss: 0.35759520530700684
Batch 12/64 loss: 0.3536006212234497
Batch 13/64 loss: 0.35456979274749756
Batch 14/64 loss: 0.35311877727508545
Batch 15/64 loss: 0.3561252951622009
Batch 16/64 loss: 0.35400986671447754
Batch 17/64 loss: 0.35196197032928467
Batch 18/64 loss: 0.35436105728149414
Batch 19/64 loss: 0.3546264171600342
Batch 20/64 loss: 0.3515493869781494
Batch 21/64 loss: 0.35586273670196533
Batch 22/64 loss: 0.35482168197631836
Batch 23/64 loss: 0.3544691801071167
Batch 24/64 loss: 0.3534923791885376
Batch 25/64 loss: 0.35831916332244873
Batch 26/64 loss: 0.35336732864379883
Batch 27/64 loss: 0.3533390760421753
Batch 28/64 loss: 0.3562767505645752
Batch 29/64 loss: 0.35450172424316406
Batch 30/64 loss: 0.35534560680389404
Batch 31/64 loss: 0.35530412197113037
Batch 32/64 loss: 0.35550129413604736
Batch 33/64 loss: 0.3547894358634949
Batch 34/64 loss: 0.3591359853744507
Batch 35/64 loss: 0.35625898838043213
Batch 36/64 loss: 0.35588961839675903
Batch 37/64 loss: 0.35496968030929565
Batch 38/64 loss: 0.3545491099357605
Batch 39/64 loss: 0.3566322326660156
Batch 40/64 loss: 0.35650694370269775
Batch 41/64 loss: 0.3536924123764038
Batch 42/64 loss: 0.3546668291091919
Batch 43/64 loss: 0.35304099321365356
Batch 44/64 loss: 0.35641467571258545
Batch 45/64 loss: 0.35836952924728394
Batch 46/64 loss: 0.35831183195114136
Batch 47/64 loss: 0.3511652946472168
Batch 48/64 loss: 0.35880494117736816
Batch 49/64 loss: 0.3526570796966553
Batch 50/64 loss: 0.3515632748603821
Batch 51/64 loss: 0.35380756855010986
Batch 52/64 loss: 0.3551974892616272
Batch 53/64 loss: 0.35616254806518555
Batch 54/64 loss: 0.3567656874656677
Batch 55/64 loss: 0.35705840587615967
Batch 56/64 loss: 0.35835254192352295
Batch 57/64 loss: 0.35483771562576294
Batch 58/64 loss: 0.35509711503982544
Batch 59/64 loss: 0.3515812158584595
Batch 60/64 loss: 0.35590100288391113
Batch 61/64 loss: 0.3519766330718994
Batch 62/64 loss: 0.3552670478820801
Batch 63/64 loss: 0.3564455509185791
Batch 64/64 loss: 0.3579685091972351
Epoch 50  Train loss: 0.3549731630905002  Val loss: 0.3568331500918595
Saving best model, epoch: 50
Epoch 51
-------------------------------
Batch 1/64 loss: 0.3557863235473633
Batch 2/64 loss: 0.3506662845611572
Batch 3/64 loss: 0.353094220161438
Batch 4/64 loss: 0.35611987113952637
Batch 5/64 loss: 0.3504762649536133
Batch 6/64 loss: 0.3504367470741272
Batch 7/64 loss: 0.3534810543060303
Batch 8/64 loss: 0.35970258712768555
Batch 9/64 loss: 0.3548269271850586
Batch 10/64 loss: 0.35017311573028564
Batch 11/64 loss: 0.35502779483795166
Batch 12/64 loss: 0.3529520630836487
Batch 13/64 loss: 0.35020875930786133
Batch 14/64 loss: 0.3519137501716614
Batch 15/64 loss: 0.3535211682319641
Batch 16/64 loss: 0.3495403528213501
Batch 17/64 loss: 0.35361313819885254
Batch 18/64 loss: 0.35704052448272705
Batch 19/64 loss: 0.3535844087600708
Batch 20/64 loss: 0.3546808958053589
Batch 21/64 loss: 0.3566606640815735
Batch 22/64 loss: 0.3526650667190552
Batch 23/64 loss: 0.355241596698761
Batch 24/64 loss: 0.35641032457351685
Batch 25/64 loss: 0.3531108498573303
Batch 26/64 loss: 0.35252559185028076
Batch 27/64 loss: 0.3582015633583069
Batch 28/64 loss: 0.35699570178985596
Batch 29/64 loss: 0.3548644781112671
Batch 30/64 loss: 0.35345011949539185
Batch 31/64 loss: 0.35243797302246094
Batch 32/64 loss: 0.3549220561981201
Batch 33/64 loss: 0.3548247814178467
Batch 34/64 loss: 0.35581064224243164
Batch 35/64 loss: 0.3561441898345947
Batch 36/64 loss: 0.35595405101776123
Batch 37/64 loss: 0.357660174369812
Batch 38/64 loss: 0.35649311542510986
Batch 39/64 loss: 0.35832810401916504
Batch 40/64 loss: 0.3560976982116699
Batch 41/64 loss: 0.35530513525009155
Batch 42/64 loss: 0.3580780029296875
Batch 43/64 loss: 0.3544846773147583
Batch 44/64 loss: 0.3538930416107178
Batch 45/64 loss: 0.35348623991012573
Batch 46/64 loss: 0.35311323404312134
Batch 47/64 loss: 0.35404056310653687
Batch 48/64 loss: 0.35855990648269653
Batch 49/64 loss: 0.3547821044921875
Batch 50/64 loss: 0.3557266592979431
Batch 51/64 loss: 0.3548511862754822
Batch 52/64 loss: 0.35462355613708496
Batch 53/64 loss: 0.3535243272781372
Batch 54/64 loss: 0.35292720794677734
Batch 55/64 loss: 0.35536110401153564
Batch 56/64 loss: 0.3545127511024475
Batch 57/64 loss: 0.35543298721313477
Batch 58/64 loss: 0.35410642623901367
Batch 59/64 loss: 0.35924410820007324
Batch 60/64 loss: 0.3527100086212158
Batch 61/64 loss: 0.35398924350738525
Batch 62/64 loss: 0.3533061742782593
Batch 63/64 loss: 0.35783064365386963
Batch 64/64 loss: 0.3569997549057007
Epoch 51  Train loss: 0.35462406429589965  Val loss: 0.35734270610350516
Epoch 52
-------------------------------
Batch 1/64 loss: 0.355849027633667
Batch 2/64 loss: 0.35423219203948975
Batch 3/64 loss: 0.35865044593811035
Batch 4/64 loss: 0.3501710891723633
Batch 5/64 loss: 0.35098570585250854
Batch 6/64 loss: 0.3546212911605835
Batch 7/64 loss: 0.3536403179168701
Batch 8/64 loss: 0.35740846395492554
Batch 9/64 loss: 0.352742075920105
Batch 10/64 loss: 0.35337066650390625
Batch 11/64 loss: 0.353285551071167
Batch 12/64 loss: 0.357646644115448
Batch 13/64 loss: 0.3531383275985718
Batch 14/64 loss: 0.35647696256637573
Batch 15/64 loss: 0.35748887062072754
Batch 16/64 loss: 0.35407447814941406
Batch 17/64 loss: 0.35250550508499146
Batch 18/64 loss: 0.3529118299484253
Batch 19/64 loss: 0.3510078191757202
Batch 20/64 loss: 0.35074782371520996
Batch 21/64 loss: 0.3539295792579651
Batch 22/64 loss: 0.3552984595298767
Batch 23/64 loss: 0.35428011417388916
Batch 24/64 loss: 0.35731005668640137
Batch 25/64 loss: 0.35453081130981445
Batch 26/64 loss: 0.3537106513977051
Batch 27/64 loss: 0.352336585521698
Batch 28/64 loss: 0.3548949360847473
Batch 29/64 loss: 0.35358619689941406
Batch 30/64 loss: 0.3554280996322632
Batch 31/64 loss: 0.3543497323989868
Batch 32/64 loss: 0.3504316806793213
Batch 33/64 loss: 0.35677480697631836
Batch 34/64 loss: 0.35283946990966797
Batch 35/64 loss: 0.3564246892929077
Batch 36/64 loss: 0.3525526523590088
Batch 37/64 loss: 0.35588377714157104
Batch 38/64 loss: 0.3600102663040161
Batch 39/64 loss: 0.35521751642227173
Batch 40/64 loss: 0.3568480610847473
Batch 41/64 loss: 0.3545687198638916
Batch 42/64 loss: 0.35275256633758545
Batch 43/64 loss: 0.3533869981765747
Batch 44/64 loss: 0.35594654083251953
Batch 45/64 loss: 0.3527255654335022
Batch 46/64 loss: 0.3552868366241455
Batch 47/64 loss: 0.3542487621307373
Batch 48/64 loss: 0.35970383882522583
Batch 49/64 loss: 0.35436779260635376
Batch 50/64 loss: 0.35288500785827637
Batch 51/64 loss: 0.35778748989105225
Batch 52/64 loss: 0.3523205518722534
Batch 53/64 loss: 0.3550678491592407
Batch 54/64 loss: 0.3520025610923767
Batch 55/64 loss: 0.35411667823791504
Batch 56/64 loss: 0.3500169515609741
Batch 57/64 loss: 0.35193943977355957
Batch 58/64 loss: 0.3567410707473755
Batch 59/64 loss: 0.35560959577560425
Batch 60/64 loss: 0.3522524833679199
Batch 61/64 loss: 0.35469257831573486
Batch 62/64 loss: 0.35032618045806885
Batch 63/64 loss: 0.35385948419570923
Batch 64/64 loss: 0.3532707691192627
Epoch 52  Train loss: 0.354276891783172  Val loss: 0.3574192278163949
Epoch 53
-------------------------------
Batch 1/64 loss: 0.3540961742401123
Batch 2/64 loss: 0.35099709033966064
Batch 3/64 loss: 0.35176098346710205
Batch 4/64 loss: 0.3518826961517334
Batch 5/64 loss: 0.3525594472885132
Batch 6/64 loss: 0.3560306429862976
Batch 7/64 loss: 0.35558438301086426
Batch 8/64 loss: 0.35451990365982056
Batch 9/64 loss: 0.3529953956604004
Batch 10/64 loss: 0.3529067039489746
Batch 11/64 loss: 0.35604894161224365
Batch 12/64 loss: 0.34964191913604736
Batch 13/64 loss: 0.35116493701934814
Batch 14/64 loss: 0.3529996871948242
Batch 15/64 loss: 0.35152310132980347
Batch 16/64 loss: 0.3525100350379944
Batch 17/64 loss: 0.35398274660110474
Batch 18/64 loss: 0.3525453209877014
Batch 19/64 loss: 0.35439634323120117
Batch 20/64 loss: 0.35817086696624756
Batch 21/64 loss: 0.3533257246017456
Batch 22/64 loss: 0.351665198802948
Batch 23/64 loss: 0.3520458936691284
Batch 24/64 loss: 0.3569337725639343
Batch 25/64 loss: 0.35149240493774414
Batch 26/64 loss: 0.35195690393447876
Batch 27/64 loss: 0.35414600372314453
Batch 28/64 loss: 0.3499488830566406
Batch 29/64 loss: 0.3555838465690613
Batch 30/64 loss: 0.34876489639282227
Batch 31/64 loss: 0.35503876209259033
Batch 32/64 loss: 0.3516879081726074
Batch 33/64 loss: 0.35614365339279175
Batch 34/64 loss: 0.3528304100036621
Batch 35/64 loss: 0.35300421714782715
Batch 36/64 loss: 0.3521759510040283
Batch 37/64 loss: 0.3509417176246643
Batch 38/64 loss: 0.35341334342956543
Batch 39/64 loss: 0.3525019884109497
Batch 40/64 loss: 0.3538493514060974
Batch 41/64 loss: 0.354397177696228
Batch 42/64 loss: 0.3505594730377197
Batch 43/64 loss: 0.3532535433769226
Batch 44/64 loss: 0.34830689430236816
Batch 45/64 loss: 0.34821903705596924
Batch 46/64 loss: 0.355998158454895
Batch 47/64 loss: 0.3506231904029846
Batch 48/64 loss: 0.35392022132873535
Batch 49/64 loss: 0.3532748222351074
Batch 50/64 loss: 0.3524423837661743
Batch 51/64 loss: 0.35122114419937134
Batch 52/64 loss: 0.35161542892456055
Batch 53/64 loss: 0.3569337725639343
Batch 54/64 loss: 0.35278022289276123
Batch 55/64 loss: 0.3545658588409424
Batch 56/64 loss: 0.3532288074493408
Batch 57/64 loss: 0.354610800743103
Batch 58/64 loss: 0.353928804397583
Batch 59/64 loss: 0.3519907593727112
Batch 60/64 loss: 0.3540533781051636
Batch 61/64 loss: 0.3508515954017639
Batch 62/64 loss: 0.3524867296218872
Batch 63/64 loss: 0.35575348138809204
Batch 64/64 loss: 0.3535579442977905
Epoch 53  Train loss: 0.3530031732484406  Val loss: 0.355998631605168
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: 0.3546901345252991
Batch 2/64 loss: 0.35705631971359253
Batch 3/64 loss: 0.34990131855010986
Batch 4/64 loss: 0.3510427474975586
Batch 5/64 loss: 0.3526451587677002
Batch 6/64 loss: 0.357244074344635
Batch 7/64 loss: 0.3588200807571411
Batch 8/64 loss: 0.35373854637145996
Batch 9/64 loss: 0.35153019428253174
Batch 10/64 loss: 0.3508284091949463
Batch 11/64 loss: 0.3544367551803589
Batch 12/64 loss: 0.34908628463745117
Batch 13/64 loss: 0.34915947914123535
Batch 14/64 loss: 0.35149329900741577
Batch 15/64 loss: 0.3548864722251892
Batch 16/64 loss: 0.3507883548736572
Batch 17/64 loss: 0.35263943672180176
Batch 18/64 loss: 0.3512026071548462
Batch 19/64 loss: 0.355770468711853
Batch 20/64 loss: 0.3520401120185852
Batch 21/64 loss: 0.3529651165008545
Batch 22/64 loss: 0.3530505895614624
Batch 23/64 loss: 0.3529641628265381
Batch 24/64 loss: 0.3499941825866699
Batch 25/64 loss: 0.35484713315963745
Batch 26/64 loss: 0.35114413499832153
Batch 27/64 loss: 0.3492034673690796
Batch 28/64 loss: 0.3518965244293213
Batch 29/64 loss: 0.353290855884552
Batch 30/64 loss: 0.34910309314727783
Batch 31/64 loss: 0.3566761016845703
Batch 32/64 loss: 0.3528348207473755
Batch 33/64 loss: 0.35160958766937256
Batch 34/64 loss: 0.3507269024848938
Batch 35/64 loss: 0.3513981103897095
Batch 36/64 loss: 0.3511120080947876
Batch 37/64 loss: 0.35150718688964844
Batch 38/64 loss: 0.353041410446167
Batch 39/64 loss: 0.3527792692184448
Batch 40/64 loss: 0.351199746131897
Batch 41/64 loss: 0.35035789012908936
Batch 42/64 loss: 0.3549380302429199
Batch 43/64 loss: 0.35358983278274536
Batch 44/64 loss: 0.3531467914581299
Batch 45/64 loss: 0.3502821922302246
Batch 46/64 loss: 0.3547314405441284
Batch 47/64 loss: 0.3601604700088501
Batch 48/64 loss: 0.3498082160949707
Batch 49/64 loss: 0.3527436852455139
Batch 50/64 loss: 0.35161685943603516
Batch 51/64 loss: 0.3535515069961548
Batch 52/64 loss: 0.35079437494277954
Batch 53/64 loss: 0.3560033440589905
Batch 54/64 loss: 0.3554525375366211
Batch 55/64 loss: 0.35614585876464844
Batch 56/64 loss: 0.35075056552886963
Batch 57/64 loss: 0.3553006649017334
Batch 58/64 loss: 0.3472336530685425
Batch 59/64 loss: 0.352091908454895
Batch 60/64 loss: 0.3521801233291626
Batch 61/64 loss: 0.3489452600479126
Batch 62/64 loss: 0.34957969188690186
Batch 63/64 loss: 0.35713130235671997
Batch 64/64 loss: 0.35103321075439453
Epoch 54  Train loss: 0.3526298943687888  Val loss: 0.35574295696933655
Saving best model, epoch: 54
Epoch 55
-------------------------------
Batch 1/64 loss: 0.3532743453979492
Batch 2/64 loss: 0.35312318801879883
Batch 3/64 loss: 0.34697163105010986
Batch 4/64 loss: 0.34606802463531494
Batch 5/64 loss: 0.35841643810272217
Batch 6/64 loss: 0.353047251701355
Batch 7/64 loss: 0.3500128984451294
Batch 8/64 loss: 0.35474228858947754
Batch 9/64 loss: 0.35049641132354736
Batch 10/64 loss: 0.354198157787323
Batch 11/64 loss: 0.3527405261993408
Batch 12/64 loss: 0.3491392135620117
Batch 13/64 loss: 0.3531675338745117
Batch 14/64 loss: 0.3536278009414673
Batch 15/64 loss: 0.3557206392288208
Batch 16/64 loss: 0.35287362337112427
Batch 17/64 loss: 0.35223644971847534
Batch 18/64 loss: 0.3492315411567688
Batch 19/64 loss: 0.3514084219932556
Batch 20/64 loss: 0.3522024154663086
Batch 21/64 loss: 0.35359710454940796
Batch 22/64 loss: 0.3525471091270447
Batch 23/64 loss: 0.3535270690917969
Batch 24/64 loss: 0.3497558832168579
Batch 25/64 loss: 0.34981608390808105
Batch 26/64 loss: 0.34780341386795044
Batch 27/64 loss: 0.3530975580215454
Batch 28/64 loss: 0.3582143783569336
Batch 29/64 loss: 0.3521442413330078
Batch 30/64 loss: 0.35033857822418213
Batch 31/64 loss: 0.35211849212646484
Batch 32/64 loss: 0.35550856590270996
Batch 33/64 loss: 0.3563574552536011
Batch 34/64 loss: 0.3475302457809448
Batch 35/64 loss: 0.35413599014282227
Batch 36/64 loss: 0.354525089263916
Batch 37/64 loss: 0.35137295722961426
Batch 38/64 loss: 0.35225439071655273
Batch 39/64 loss: 0.3537396788597107
Batch 40/64 loss: 0.35003727674484253
Batch 41/64 loss: 0.3542647361755371
Batch 42/64 loss: 0.353617787361145
Batch 43/64 loss: 0.3530338406562805
Batch 44/64 loss: 0.35482752323150635
Batch 45/64 loss: 0.3551977276802063
Batch 46/64 loss: 0.350436270236969
Batch 47/64 loss: 0.3508545756340027
Batch 48/64 loss: 0.35387784242630005
Batch 49/64 loss: 0.35363560914993286
Batch 50/64 loss: 0.3492039442062378
Batch 51/64 loss: 0.34801363945007324
Batch 52/64 loss: 0.3494967222213745
Batch 53/64 loss: 0.3549778461456299
Batch 54/64 loss: 0.35380327701568604
Batch 55/64 loss: 0.3510017395019531
Batch 56/64 loss: 0.35326826572418213
Batch 57/64 loss: 0.35349929332733154
Batch 58/64 loss: 0.3513350486755371
Batch 59/64 loss: 0.35344207286834717
Batch 60/64 loss: 0.34992122650146484
Batch 61/64 loss: 0.3526105284690857
Batch 62/64 loss: 0.35047173500061035
Batch 63/64 loss: 0.35511642694473267
Batch 64/64 loss: 0.35870057344436646
Epoch 55  Train loss: 0.3524086818975561  Val loss: 0.35538839474576445
Saving best model, epoch: 55
Epoch 56
-------------------------------
Batch 1/64 loss: 0.35108327865600586
Batch 2/64 loss: 0.3520556688308716
Batch 3/64 loss: 0.3514164686203003
Batch 4/64 loss: 0.35013484954833984
Batch 5/64 loss: 0.3491191267967224
Batch 6/64 loss: 0.3547831177711487
Batch 7/64 loss: 0.35358119010925293
Batch 8/64 loss: 0.3522905707359314
Batch 9/64 loss: 0.3515318036079407
Batch 10/64 loss: 0.35660064220428467
Batch 11/64 loss: 0.35238564014434814
Batch 12/64 loss: 0.34680771827697754
Batch 13/64 loss: 0.348832905292511
Batch 14/64 loss: 0.35162174701690674
Batch 15/64 loss: 0.35258007049560547
Batch 16/64 loss: 0.3513227701187134
Batch 17/64 loss: 0.3455891013145447
Batch 18/64 loss: 0.34909331798553467
Batch 19/64 loss: 0.35312432050704956
Batch 20/64 loss: 0.3530595898628235
Batch 21/64 loss: 0.35406494140625
Batch 22/64 loss: 0.3541187047958374
Batch 23/64 loss: 0.3504495620727539
Batch 24/64 loss: 0.35138505697250366
Batch 25/64 loss: 0.3491235375404358
Batch 26/64 loss: 0.35462963581085205
Batch 27/64 loss: 0.3533128499984741
Batch 28/64 loss: 0.351040780544281
Batch 29/64 loss: 0.3521939516067505
Batch 30/64 loss: 0.34989869594573975
Batch 31/64 loss: 0.3498401641845703
Batch 32/64 loss: 0.3528141975402832
Batch 33/64 loss: 0.3502468466758728
Batch 34/64 loss: 0.3475363254547119
Batch 35/64 loss: 0.3514716625213623
Batch 36/64 loss: 0.3494246006011963
Batch 37/64 loss: 0.35186946392059326
Batch 38/64 loss: 0.35920417308807373
Batch 39/64 loss: 0.35285550355911255
Batch 40/64 loss: 0.35529565811157227
Batch 41/64 loss: 0.3533296585083008
Batch 42/64 loss: 0.3515433073043823
Batch 43/64 loss: 0.35567164421081543
Batch 44/64 loss: 0.34982794523239136
Batch 45/64 loss: 0.35322755575180054
Batch 46/64 loss: 0.3533811569213867
Batch 47/64 loss: 0.35287487506866455
Batch 48/64 loss: 0.35474586486816406
Batch 49/64 loss: 0.3507765531539917
Batch 50/64 loss: 0.3491377830505371
Batch 51/64 loss: 0.35403215885162354
Batch 52/64 loss: 0.3502908945083618
Batch 53/64 loss: 0.34905552864074707
Batch 54/64 loss: 0.3557337522506714
Batch 55/64 loss: 0.3501725196838379
Batch 56/64 loss: 0.35281306505203247
Batch 57/64 loss: 0.35589295625686646
Batch 58/64 loss: 0.35035377740859985
Batch 59/64 loss: 0.35304296016693115
Batch 60/64 loss: 0.3528088331222534
Batch 61/64 loss: 0.35211706161499023
Batch 62/64 loss: 0.3545333743095398
Batch 63/64 loss: 0.350081205368042
Batch 64/64 loss: 0.3524280786514282
Epoch 56  Train loss: 0.3519616580476948  Val loss: 0.35619540046580467
Epoch 57
-------------------------------
Batch 1/64 loss: 0.35357022285461426
Batch 2/64 loss: 0.35167497396469116
Batch 3/64 loss: 0.35303163528442383
Batch 4/64 loss: 0.3541039824485779
Batch 5/64 loss: 0.35264164209365845
Batch 6/64 loss: 0.3556212782859802
Batch 7/64 loss: 0.3490598201751709
Batch 8/64 loss: 0.3508458137512207
Batch 9/64 loss: 0.35440146923065186
Batch 10/64 loss: 0.34931445121765137
Batch 11/64 loss: 0.35240888595581055
Batch 12/64 loss: 0.35204148292541504
Batch 13/64 loss: 0.35070228576660156
Batch 14/64 loss: 0.3547826409339905
Batch 15/64 loss: 0.34923505783081055
Batch 16/64 loss: 0.3509659171104431
Batch 17/64 loss: 0.35263514518737793
Batch 18/64 loss: 0.3505368232727051
Batch 19/64 loss: 0.3526778221130371
Batch 20/64 loss: 0.3483020067214966
Batch 21/64 loss: 0.3507087230682373
Batch 22/64 loss: 0.35103440284729004
Batch 23/64 loss: 0.3496508002281189
Batch 24/64 loss: 0.35225725173950195
Batch 25/64 loss: 0.3557931184768677
Batch 26/64 loss: 0.35030055046081543
Batch 27/64 loss: 0.3504943251609802
Batch 28/64 loss: 0.3498132824897766
Batch 29/64 loss: 0.3516385555267334
Batch 30/64 loss: 0.34995293617248535
Batch 31/64 loss: 0.35410356521606445
Batch 32/64 loss: 0.35137391090393066
Batch 33/64 loss: 0.35280537605285645
Batch 34/64 loss: 0.34792596101760864
Batch 35/64 loss: 0.354159951210022
Batch 36/64 loss: 0.3492105007171631
Batch 37/64 loss: 0.3491218090057373
Batch 38/64 loss: 0.35183775424957275
Batch 39/64 loss: 0.3484727144241333
Batch 40/64 loss: 0.3519022464752197
Batch 41/64 loss: 0.35296428203582764
Batch 42/64 loss: 0.350286066532135
Batch 43/64 loss: 0.3491858243942261
Batch 44/64 loss: 0.3545425534248352
Batch 45/64 loss: 0.3541072607040405
Batch 46/64 loss: 0.35311830043792725
Batch 47/64 loss: 0.34972572326660156
Batch 48/64 loss: 0.3481879234313965
Batch 49/64 loss: 0.35203003883361816
Batch 50/64 loss: 0.3533104658126831
Batch 51/64 loss: 0.3538174629211426
Batch 52/64 loss: 0.34586477279663086
Batch 53/64 loss: 0.3511854410171509
Batch 54/64 loss: 0.3476969003677368
Batch 55/64 loss: 0.3544565439224243
Batch 56/64 loss: 0.35532522201538086
Batch 57/64 loss: 0.3488616943359375
Batch 58/64 loss: 0.35254406929016113
Batch 59/64 loss: 0.3498879671096802
Batch 60/64 loss: 0.35576963424682617
Batch 61/64 loss: 0.3516518473625183
Batch 62/64 loss: 0.3508058786392212
Batch 63/64 loss: 0.34911036491394043
Batch 64/64 loss: 0.3557436466217041
Epoch 57  Train loss: 0.35156635396620806  Val loss: 0.3542369436152612
Saving best model, epoch: 57
Epoch 58
-------------------------------
Batch 1/64 loss: 0.3487536907196045
Batch 2/64 loss: 0.3517594337463379
Batch 3/64 loss: 0.35376274585723877
Batch 4/64 loss: 0.35705840587615967
Batch 5/64 loss: 0.35423004627227783
Batch 6/64 loss: 0.3505411148071289
Batch 7/64 loss: 0.35305464267730713
Batch 8/64 loss: 0.34609800577163696
Batch 9/64 loss: 0.3500131368637085
Batch 10/64 loss: 0.3482646942138672
Batch 11/64 loss: 0.3518272638320923
Batch 12/64 loss: 0.35260939598083496
Batch 13/64 loss: 0.35301005840301514
Batch 14/64 loss: 0.34995508193969727
Batch 15/64 loss: 0.3511500358581543
Batch 16/64 loss: 0.35138702392578125
Batch 17/64 loss: 0.34914594888687134
Batch 18/64 loss: 0.3560255765914917
Batch 19/64 loss: 0.3517247438430786
Batch 20/64 loss: 0.35052913427352905
Batch 21/64 loss: 0.3476695418357849
Batch 22/64 loss: 0.3493213653564453
Batch 23/64 loss: 0.35490185022354126
Batch 24/64 loss: 0.35721343755722046
Batch 25/64 loss: 0.3528895378112793
Batch 26/64 loss: 0.34868311882019043
Batch 27/64 loss: 0.35345888137817383
Batch 28/64 loss: 0.3550311326980591
Batch 29/64 loss: 0.35215067863464355
Batch 30/64 loss: 0.3476511836051941
Batch 31/64 loss: 0.3460230827331543
Batch 32/64 loss: 0.3470466732978821
Batch 33/64 loss: 0.3487776517868042
Batch 34/64 loss: 0.3484306335449219
Batch 35/64 loss: 0.3487812876701355
Batch 36/64 loss: 0.3505887985229492
Batch 37/64 loss: 0.3529910445213318
Batch 38/64 loss: 0.34716475009918213
Batch 39/64 loss: 0.3506231904029846
Batch 40/64 loss: 0.34928250312805176
Batch 41/64 loss: 0.34935516119003296
Batch 42/64 loss: 0.3442041873931885
Batch 43/64 loss: 0.35301488637924194
Batch 44/64 loss: 0.35093700885772705
Batch 45/64 loss: 0.3495746850967407
Batch 46/64 loss: 0.35305625200271606
Batch 47/64 loss: 0.35006213188171387
Batch 48/64 loss: 0.3481159210205078
Batch 49/64 loss: 0.34860938787460327
Batch 50/64 loss: 0.3480885624885559
Batch 51/64 loss: 0.3507469892501831
Batch 52/64 loss: 0.3491581082344055
Batch 53/64 loss: 0.35477423667907715
Batch 54/64 loss: 0.35130417346954346
Batch 55/64 loss: 0.34590673446655273
Batch 56/64 loss: 0.3475620746612549
Batch 57/64 loss: 0.3472548723220825
Batch 58/64 loss: 0.35467249155044556
Batch 59/64 loss: 0.3461208939552307
Batch 60/64 loss: 0.3516971468925476
Batch 61/64 loss: 0.34615635871887207
Batch 62/64 loss: 0.3509104251861572
Batch 63/64 loss: 0.3528013825416565
Batch 64/64 loss: 0.34804874658584595
Epoch 58  Train loss: 0.35050511617286534  Val loss: 0.354163573779601
Saving best model, epoch: 58
Epoch 59
-------------------------------
Batch 1/64 loss: 0.34989988803863525
Batch 2/64 loss: 0.35028553009033203
Batch 3/64 loss: 0.3469897508621216
Batch 4/64 loss: 0.35348570346832275
Batch 5/64 loss: 0.34582000970840454
Batch 6/64 loss: 0.34605222940444946
Batch 7/64 loss: 0.350754976272583
Batch 8/64 loss: 0.3515758514404297
Batch 9/64 loss: 0.3509265184402466
Batch 10/64 loss: 0.34914684295654297
Batch 11/64 loss: 0.3502455949783325
Batch 12/64 loss: 0.34822964668273926
Batch 13/64 loss: 0.34903883934020996
Batch 14/64 loss: 0.34853893518447876
Batch 15/64 loss: 0.3492645025253296
Batch 16/64 loss: 0.35064804553985596
Batch 17/64 loss: 0.3497633934020996
Batch 18/64 loss: 0.3430262804031372
Batch 19/64 loss: 0.34695249795913696
Batch 20/64 loss: 0.3530779480934143
Batch 21/64 loss: 0.3460061550140381
Batch 22/64 loss: 0.34899938106536865
Batch 23/64 loss: 0.3459755778312683
Batch 24/64 loss: 0.34901952743530273
Batch 25/64 loss: 0.34864282608032227
Batch 26/64 loss: 0.34882813692092896
Batch 27/64 loss: 0.3516288995742798
Batch 28/64 loss: 0.3558015823364258
Batch 29/64 loss: 0.3532877564430237
Batch 30/64 loss: 0.35004961490631104
Batch 31/64 loss: 0.35291218757629395
Batch 32/64 loss: 0.354561448097229
Batch 33/64 loss: 0.33967024087905884
Batch 34/64 loss: 0.350777268409729
Batch 35/64 loss: 0.3492235541343689
Batch 36/64 loss: 0.35015857219696045
Batch 37/64 loss: 0.347298264503479
Batch 38/64 loss: 0.34622693061828613
Batch 39/64 loss: 0.3521180748939514
Batch 40/64 loss: 0.3505154252052307
Batch 41/64 loss: 0.3546849489212036
Batch 42/64 loss: 0.3521938920021057
Batch 43/64 loss: 0.3486449718475342
Batch 44/64 loss: 0.35025638341903687
Batch 45/64 loss: 0.35123002529144287
Batch 46/64 loss: 0.3507397174835205
Batch 47/64 loss: 0.34880775213241577
Batch 48/64 loss: 0.3461427092552185
Batch 49/64 loss: 0.3516867756843567
Batch 50/64 loss: 0.348008394241333
Batch 51/64 loss: 0.3497011661529541
Batch 52/64 loss: 0.3504185676574707
Batch 53/64 loss: 0.34675049781799316
Batch 54/64 loss: 0.34890294075012207
Batch 55/64 loss: 0.34957659244537354
Batch 56/64 loss: 0.34953582286834717
Batch 57/64 loss: 0.34887444972991943
Batch 58/64 loss: 0.3484201431274414
Batch 59/64 loss: 0.35115891695022583
Batch 60/64 loss: 0.3531991243362427
Batch 61/64 loss: 0.3495379090309143
Batch 62/64 loss: 0.3483051657676697
Batch 63/64 loss: 0.3496965169906616
Batch 64/64 loss: 0.3509088158607483
Epoch 59  Train loss: 0.34956987301508585  Val loss: 0.35300371306868356
Saving best model, epoch: 59
Epoch 60
-------------------------------
Batch 1/64 loss: 0.3485299348831177
Batch 2/64 loss: 0.34753328561782837
Batch 3/64 loss: 0.3479318618774414
Batch 4/64 loss: 0.3531167507171631
Batch 5/64 loss: 0.3459054231643677
Batch 6/64 loss: 0.34760189056396484
Batch 7/64 loss: 0.3516526222229004
Batch 8/64 loss: 0.3496509790420532
Batch 9/64 loss: 0.351749062538147
Batch 10/64 loss: 0.347758412361145
Batch 11/64 loss: 0.34884023666381836
Batch 12/64 loss: 0.3491629362106323
Batch 13/64 loss: 0.35014820098876953
Batch 14/64 loss: 0.34682220220565796
Batch 15/64 loss: 0.3514111042022705
Batch 16/64 loss: 0.34367650747299194
Batch 17/64 loss: 0.3489006757736206
Batch 18/64 loss: 0.3455291986465454
Batch 19/64 loss: 0.34947824478149414
Batch 20/64 loss: 0.3507949113845825
Batch 21/64 loss: 0.34894800186157227
Batch 22/64 loss: 0.3477625250816345
Batch 23/64 loss: 0.34803712368011475
Batch 24/64 loss: 0.35143399238586426
Batch 25/64 loss: 0.3467264771461487
Batch 26/64 loss: 0.34939634799957275
Batch 27/64 loss: 0.35255002975463867
Batch 28/64 loss: 0.3497474193572998
Batch 29/64 loss: 0.35171717405319214
Batch 30/64 loss: 0.345752477645874
Batch 31/64 loss: 0.34479910135269165
Batch 32/64 loss: 0.3509178161621094
Batch 33/64 loss: 0.35377442836761475
Batch 34/64 loss: 0.3462718725204468
Batch 35/64 loss: 0.3466253876686096
Batch 36/64 loss: 0.3503098487854004
Batch 37/64 loss: 0.34779196977615356
Batch 38/64 loss: 0.3483595848083496
Batch 39/64 loss: 0.3518589735031128
Batch 40/64 loss: 0.3511633276939392
Batch 41/64 loss: 0.3470575213432312
Batch 42/64 loss: 0.3498721122741699
Batch 43/64 loss: 0.3522190451622009
Batch 44/64 loss: 0.3482234477996826
Batch 45/64 loss: 0.34981274604797363
Batch 46/64 loss: 0.34946268796920776
Batch 47/64 loss: 0.34888017177581787
Batch 48/64 loss: 0.35199666023254395
Batch 49/64 loss: 0.3428438901901245
Batch 50/64 loss: 0.35106784105300903
Batch 51/64 loss: 0.3506404161453247
Batch 52/64 loss: 0.3447064757347107
Batch 53/64 loss: 0.3467221260070801
Batch 54/64 loss: 0.3527058959007263
Batch 55/64 loss: 0.35384929180145264
Batch 56/64 loss: 0.3506354093551636
Batch 57/64 loss: 0.34877508878707886
Batch 58/64 loss: 0.35453516244888306
Batch 59/64 loss: 0.35324031114578247
Batch 60/64 loss: 0.3515082597732544
Batch 61/64 loss: 0.3497791290283203
Batch 62/64 loss: 0.3528423309326172
Batch 63/64 loss: 0.3488926291465759
Batch 64/64 loss: 0.3434908390045166
Epoch 60  Train loss: 0.3493023545134301  Val loss: 0.3531813730079284
Epoch 61
-------------------------------
Batch 1/64 loss: 0.3494448661804199
Batch 2/64 loss: 0.3453409671783447
Batch 3/64 loss: 0.3521583676338196
Batch 4/64 loss: 0.3491487503051758
Batch 5/64 loss: 0.3479510545730591
Batch 6/64 loss: 0.34577369689941406
Batch 7/64 loss: 0.3455880880355835
Batch 8/64 loss: 0.3513200283050537
Batch 9/64 loss: 0.34709692001342773
Batch 10/64 loss: 0.350200891494751
Batch 11/64 loss: 0.3485965132713318
Batch 12/64 loss: 0.3477182388305664
Batch 13/64 loss: 0.3495103716850281
Batch 14/64 loss: 0.34638655185699463
Batch 15/64 loss: 0.3478114604949951
Batch 16/64 loss: 0.3453608751296997
Batch 17/64 loss: 0.3492487072944641
Batch 18/64 loss: 0.35134339332580566
Batch 19/64 loss: 0.35248976945877075
Batch 20/64 loss: 0.35247957706451416
Batch 21/64 loss: 0.34922468662261963
Batch 22/64 loss: 0.346044659614563
Batch 23/64 loss: 0.3457223176956177
Batch 24/64 loss: 0.3497005105018616
Batch 25/64 loss: 0.34354352951049805
Batch 26/64 loss: 0.3504459261894226
Batch 27/64 loss: 0.35291171073913574
Batch 28/64 loss: 0.3520233631134033
Batch 29/64 loss: 0.3502696752548218
Batch 30/64 loss: 0.35120099782943726
Batch 31/64 loss: 0.34438347816467285
Batch 32/64 loss: 0.346388578414917
Batch 33/64 loss: 0.3521268367767334
Batch 34/64 loss: 0.34850770235061646
Batch 35/64 loss: 0.3461712598800659
Batch 36/64 loss: 0.34786456823349
Batch 37/64 loss: 0.3495887517929077
Batch 38/64 loss: 0.35056543350219727
Batch 39/64 loss: 0.35366833209991455
Batch 40/64 loss: 0.34900403022766113
Batch 41/64 loss: 0.3435635566711426
Batch 42/64 loss: 0.3496338129043579
Batch 43/64 loss: 0.3472106456756592
Batch 44/64 loss: 0.3473033905029297
Batch 45/64 loss: 0.3473528027534485
Batch 46/64 loss: 0.3465120196342468
Batch 47/64 loss: 0.349803626537323
Batch 48/64 loss: 0.3482673168182373
Batch 49/64 loss: 0.3401048183441162
Batch 50/64 loss: 0.34879136085510254
Batch 51/64 loss: 0.3495520353317261
Batch 52/64 loss: 0.35012662410736084
Batch 53/64 loss: 0.347875714302063
Batch 54/64 loss: 0.34918761253356934
Batch 55/64 loss: 0.34900015592575073
Batch 56/64 loss: 0.3484691381454468
Batch 57/64 loss: 0.35228073596954346
Batch 58/64 loss: 0.3492385149002075
Batch 59/64 loss: 0.35238152742385864
Batch 60/64 loss: 0.3473687171936035
Batch 61/64 loss: 0.345941424369812
Batch 62/64 loss: 0.35086196660995483
Batch 63/64 loss: 0.3472753167152405
Batch 64/64 loss: 0.3480008840560913
Epoch 61  Train loss: 0.348602806820589  Val loss: 0.3514655427015114
Saving best model, epoch: 61
Epoch 62
-------------------------------
Batch 1/64 loss: 0.345223069190979
Batch 2/64 loss: 0.34803223609924316
Batch 3/64 loss: 0.35271525382995605
Batch 4/64 loss: 0.3443474769592285
Batch 5/64 loss: 0.3467923402786255
Batch 6/64 loss: 0.34886157512664795
Batch 7/64 loss: 0.34559547901153564
Batch 8/64 loss: 0.35021376609802246
Batch 9/64 loss: 0.3545595407485962
Batch 10/64 loss: 0.3436847925186157
Batch 11/64 loss: 0.34822285175323486
Batch 12/64 loss: 0.347786545753479
Batch 13/64 loss: 0.352395236492157
Batch 14/64 loss: 0.34962695837020874
Batch 15/64 loss: 0.3494114875793457
Batch 16/64 loss: 0.347616970539093
Batch 17/64 loss: 0.3458099365234375
Batch 18/64 loss: 0.34591400623321533
Batch 19/64 loss: 0.3479194641113281
Batch 20/64 loss: 0.34860968589782715
Batch 21/64 loss: 0.3464932441711426
Batch 22/64 loss: 0.34615558385849
Batch 23/64 loss: 0.350744366645813
Batch 24/64 loss: 0.348263680934906
Batch 25/64 loss: 0.347139835357666
Batch 26/64 loss: 0.3461359739303589
Batch 27/64 loss: 0.3462373614311218
Batch 28/64 loss: 0.3529294729232788
Batch 29/64 loss: 0.34375178813934326
Batch 30/64 loss: 0.3492633104324341
Batch 31/64 loss: 0.3453000783920288
Batch 32/64 loss: 0.35413026809692383
Batch 33/64 loss: 0.3429340720176697
Batch 34/64 loss: 0.3468930721282959
Batch 35/64 loss: 0.3456454277038574
Batch 36/64 loss: 0.3414039611816406
Batch 37/64 loss: 0.3497680425643921
Batch 38/64 loss: 0.3457329273223877
Batch 39/64 loss: 0.3438553810119629
Batch 40/64 loss: 0.3466604948043823
Batch 41/64 loss: 0.3470454812049866
Batch 42/64 loss: 0.35061073303222656
Batch 43/64 loss: 0.3485487699508667
Batch 44/64 loss: 0.34476637840270996
Batch 45/64 loss: 0.34566187858581543
Batch 46/64 loss: 0.3491760492324829
Batch 47/64 loss: 0.3521547317504883
Batch 48/64 loss: 0.3450753092765808
Batch 49/64 loss: 0.34805595874786377
Batch 50/64 loss: 0.3484145402908325
Batch 51/64 loss: 0.3470644950866699
Batch 52/64 loss: 0.3503881096839905
Batch 53/64 loss: 0.3522357940673828
Batch 54/64 loss: 0.35175251960754395
Batch 55/64 loss: 0.34844762086868286
Batch 56/64 loss: 0.34545689821243286
Batch 57/64 loss: 0.3521437644958496
Batch 58/64 loss: 0.35119760036468506
Batch 59/64 loss: 0.3486224412918091
Batch 60/64 loss: 0.35185301303863525
Batch 61/64 loss: 0.34486544132232666
Batch 62/64 loss: 0.34926629066467285
Batch 63/64 loss: 0.34725290536880493
Batch 64/64 loss: 0.3525475859642029
Epoch 62  Train loss: 0.34803520674799004  Val loss: 0.35152819025557475
Epoch 63
-------------------------------
Batch 1/64 loss: 0.35392558574676514
Batch 2/64 loss: 0.347459077835083
Batch 3/64 loss: 0.3458777070045471
Batch 4/64 loss: 0.3439673185348511
Batch 5/64 loss: 0.3482837677001953
Batch 6/64 loss: 0.3478023409843445
Batch 7/64 loss: 0.3460289239883423
Batch 8/64 loss: 0.3455469012260437
Batch 9/64 loss: 0.34491825103759766
Batch 10/64 loss: 0.3477787971496582
Batch 11/64 loss: 0.3476531505584717
Batch 12/64 loss: 0.3483537435531616
Batch 13/64 loss: 0.3476005792617798
Batch 14/64 loss: 0.3465760350227356
Batch 15/64 loss: 0.34421777725219727
Batch 16/64 loss: 0.3467531204223633
Batch 17/64 loss: 0.3424931764602661
Batch 18/64 loss: 0.3465142250061035
Batch 19/64 loss: 0.34505587816238403
Batch 20/64 loss: 0.34905344247817993
Batch 21/64 loss: 0.3455827236175537
Batch 22/64 loss: 0.3502351641654968
Batch 23/64 loss: 0.34649956226348877
Batch 24/64 loss: 0.3503764867782593
Batch 25/64 loss: 0.34634554386138916
Batch 26/64 loss: 0.34379804134368896
Batch 27/64 loss: 0.34340643882751465
Batch 28/64 loss: 0.34872353076934814
Batch 29/64 loss: 0.3517261743545532
Batch 30/64 loss: 0.34641391038894653
Batch 31/64 loss: 0.3509092330932617
Batch 32/64 loss: 0.345428466796875
Batch 33/64 loss: 0.3502579927444458
Batch 34/64 loss: 0.3456932306289673
Batch 35/64 loss: 0.3526040315628052
Batch 36/64 loss: 0.35464251041412354
Batch 37/64 loss: 0.3455958366394043
Batch 38/64 loss: 0.34728312492370605
Batch 39/64 loss: 0.34868288040161133
Batch 40/64 loss: 0.3495732545852661
Batch 41/64 loss: 0.3475996255874634
Batch 42/64 loss: 0.34444403648376465
Batch 43/64 loss: 0.34962713718414307
Batch 44/64 loss: 0.34468722343444824
Batch 45/64 loss: 0.3475008010864258
Batch 46/64 loss: 0.3454549312591553
Batch 47/64 loss: 0.34252965450286865
Batch 48/64 loss: 0.3474249839782715
Batch 49/64 loss: 0.34586501121520996
Batch 50/64 loss: 0.3459528684616089
Batch 51/64 loss: 0.34729158878326416
Batch 52/64 loss: 0.3473740816116333
Batch 53/64 loss: 0.3498113751411438
Batch 54/64 loss: 0.3492555618286133
Batch 55/64 loss: 0.3487899899482727
Batch 56/64 loss: 0.35072463750839233
Batch 57/64 loss: 0.34459900856018066
Batch 58/64 loss: 0.3454492688179016
Batch 59/64 loss: 0.3448669910430908
Batch 60/64 loss: 0.3483307361602783
Batch 61/64 loss: 0.3497331142425537
Batch 62/64 loss: 0.3436424136161804
Batch 63/64 loss: 0.3465031385421753
Batch 64/64 loss: 0.34320926666259766
Epoch 63  Train loss: 0.3472078912398394  Val loss: 0.3516064370211047
Epoch 64
-------------------------------
Batch 1/64 loss: 0.34848546981811523
Batch 2/64 loss: 0.3491719365119934
Batch 3/64 loss: 0.3441518545150757
Batch 4/64 loss: 0.3491499423980713
Batch 5/64 loss: 0.3456817865371704
Batch 6/64 loss: 0.3481026291847229
Batch 7/64 loss: 0.3456641435623169
Batch 8/64 loss: 0.34446024894714355
Batch 9/64 loss: 0.34991466999053955
Batch 10/64 loss: 0.34922754764556885
Batch 11/64 loss: 0.3459421396255493
Batch 12/64 loss: 0.34623491764068604
Batch 13/64 loss: 0.3506399393081665
Batch 14/64 loss: 0.34231042861938477
Batch 15/64 loss: 0.34491223096847534
Batch 16/64 loss: 0.3520469665527344
Batch 17/64 loss: 0.34889650344848633
Batch 18/64 loss: 0.3413808345794678
Batch 19/64 loss: 0.34750962257385254
Batch 20/64 loss: 0.34999871253967285
Batch 21/64 loss: 0.3480486273765564
Batch 22/64 loss: 0.3411039113998413
Batch 23/64 loss: 0.34878605604171753
Batch 24/64 loss: 0.3496165871620178
Batch 25/64 loss: 0.3487999439239502
Batch 26/64 loss: 0.34639739990234375
Batch 27/64 loss: 0.3452935814857483
Batch 28/64 loss: 0.34640276432037354
Batch 29/64 loss: 0.34453266859054565
Batch 30/64 loss: 0.34618115425109863
Batch 31/64 loss: 0.3481910228729248
Batch 32/64 loss: 0.34917980432510376
Batch 33/64 loss: 0.3442346453666687
Batch 34/64 loss: 0.3462011218070984
Batch 35/64 loss: 0.3497096300125122
Batch 36/64 loss: 0.3468036651611328
Batch 37/64 loss: 0.34551405906677246
Batch 38/64 loss: 0.3475942611694336
Batch 39/64 loss: 0.3490631580352783
Batch 40/64 loss: 0.3466479778289795
Batch 41/64 loss: 0.3488408327102661
Batch 42/64 loss: 0.3467291593551636
Batch 43/64 loss: 0.3457838296890259
Batch 44/64 loss: 0.3445342779159546
Batch 45/64 loss: 0.34926432371139526
Batch 46/64 loss: 0.34539973735809326
Batch 47/64 loss: 0.3467310667037964
Batch 48/64 loss: 0.34998762607574463
Batch 49/64 loss: 0.34337127208709717
Batch 50/64 loss: 0.3483467698097229
Batch 51/64 loss: 0.3494681119918823
Batch 52/64 loss: 0.34851354360580444
Batch 53/64 loss: 0.3414000868797302
Batch 54/64 loss: 0.34319984912872314
Batch 55/64 loss: 0.34246885776519775
Batch 56/64 loss: 0.3469376564025879
Batch 57/64 loss: 0.3482810854911804
Batch 58/64 loss: 0.35012805461883545
Batch 59/64 loss: 0.34686535596847534
Batch 60/64 loss: 0.34961891174316406
Batch 61/64 loss: 0.34599941968917847
Batch 62/64 loss: 0.3470463752746582
Batch 63/64 loss: 0.3471698760986328
Batch 64/64 loss: 0.3434787392616272
Epoch 64  Train loss: 0.34691575999353447  Val loss: 0.3494665364629215
Saving best model, epoch: 64
Epoch 65
-------------------------------
Batch 1/64 loss: 0.3433830142021179
Batch 2/64 loss: 0.3405112028121948
Batch 3/64 loss: 0.344593346118927
Batch 4/64 loss: 0.34629809856414795
Batch 5/64 loss: 0.3489387035369873
Batch 6/64 loss: 0.3439908027648926
Batch 7/64 loss: 0.35078126192092896
Batch 8/64 loss: 0.3449132442474365
Batch 9/64 loss: 0.34440088272094727
Batch 10/64 loss: 0.3488457202911377
Batch 11/64 loss: 0.3468628525733948
Batch 12/64 loss: 0.3459281921386719
Batch 13/64 loss: 0.34214043617248535
Batch 14/64 loss: 0.344496488571167
Batch 15/64 loss: 0.3511313796043396
Batch 16/64 loss: 0.34749794006347656
Batch 17/64 loss: 0.34333693981170654
Batch 18/64 loss: 0.3415292501449585
Batch 19/64 loss: 0.3489391803741455
Batch 20/64 loss: 0.3432868719100952
Batch 21/64 loss: 0.34698259830474854
Batch 22/64 loss: 0.33853983879089355
Batch 23/64 loss: 0.3470226526260376
Batch 24/64 loss: 0.3447704315185547
Batch 25/64 loss: 0.3506230115890503
Batch 26/64 loss: 0.3467726707458496
Batch 27/64 loss: 0.3477742075920105
Batch 28/64 loss: 0.3464280366897583
Batch 29/64 loss: 0.3451078534126282
Batch 30/64 loss: 0.34655672311782837
Batch 31/64 loss: 0.3482964038848877
Batch 32/64 loss: 0.3432612419128418
Batch 33/64 loss: 0.3477846384048462
Batch 34/64 loss: 0.34805119037628174
Batch 35/64 loss: 0.3482092022895813
Batch 36/64 loss: 0.34676313400268555
Batch 37/64 loss: 0.3430386781692505
Batch 38/64 loss: 0.34544575214385986
Batch 39/64 loss: 0.34937816858291626
Batch 40/64 loss: 0.34042513370513916
Batch 41/64 loss: 0.3443978428840637
Batch 42/64 loss: 0.3515293002128601
Batch 43/64 loss: 0.35069358348846436
Batch 44/64 loss: 0.3470523953437805
Batch 45/64 loss: 0.34324514865875244
Batch 46/64 loss: 0.34477806091308594
Batch 47/64 loss: 0.34531110525131226
Batch 48/64 loss: 0.3445286750793457
Batch 49/64 loss: 0.3438955545425415
Batch 50/64 loss: 0.35305672883987427
Batch 51/64 loss: 0.34416675567626953
Batch 52/64 loss: 0.34537625312805176
Batch 53/64 loss: 0.34808826446533203
Batch 54/64 loss: 0.3450090289115906
Batch 55/64 loss: 0.3472837805747986
Batch 56/64 loss: 0.34809988737106323
Batch 57/64 loss: 0.34439629316329956
Batch 58/64 loss: 0.3442745804786682
Batch 59/64 loss: 0.3464563488960266
Batch 60/64 loss: 0.34587562084198
Batch 61/64 loss: 0.3431951403617859
Batch 62/64 loss: 0.34614646434783936
Batch 63/64 loss: 0.34795159101486206
Batch 64/64 loss: 0.34341973066329956
Epoch 65  Train loss: 0.3459672247662264  Val loss: 0.34992868466065924
Epoch 66
-------------------------------
Batch 1/64 loss: 0.3448840379714966
Batch 2/64 loss: 0.34772753715515137
Batch 3/64 loss: 0.34706974029541016
Batch 4/64 loss: 0.3420274257659912
Batch 5/64 loss: 0.34725242853164673
Batch 6/64 loss: 0.3517378568649292
Batch 7/64 loss: 0.3454803228378296
Batch 8/64 loss: 0.3421323299407959
Batch 9/64 loss: 0.34434568881988525
Batch 10/64 loss: 0.34208691120147705
Batch 11/64 loss: 0.343026340007782
Batch 12/64 loss: 0.35012733936309814
Batch 13/64 loss: 0.3457235097885132
Batch 14/64 loss: 0.3463810086250305
Batch 15/64 loss: 0.34285128116607666
Batch 16/64 loss: 0.34769904613494873
Batch 17/64 loss: 0.3459573984146118
Batch 18/64 loss: 0.34573185443878174
Batch 19/64 loss: 0.35100889205932617
Batch 20/64 loss: 0.345178484916687
Batch 21/64 loss: 0.34700238704681396
Batch 22/64 loss: 0.346973180770874
Batch 23/64 loss: 0.3416934013366699
Batch 24/64 loss: 0.3455306887626648
Batch 25/64 loss: 0.34422874450683594
Batch 26/64 loss: 0.35035574436187744
Batch 27/64 loss: 0.3439633250236511
Batch 28/64 loss: 0.3410664200782776
Batch 29/64 loss: 0.3478383421897888
Batch 30/64 loss: 0.34571003913879395
Batch 31/64 loss: 0.3443288803100586
Batch 32/64 loss: 0.34765368700027466
Batch 33/64 loss: 0.3463336229324341
Batch 34/64 loss: 0.34297287464141846
Batch 35/64 loss: 0.3475341200828552
Batch 36/64 loss: 0.34666264057159424
Batch 37/64 loss: 0.3476032018661499
Batch 38/64 loss: 0.3426123261451721
Batch 39/64 loss: 0.3476746082305908
Batch 40/64 loss: 0.3432179093360901
Batch 41/64 loss: 0.3451712131500244
Batch 42/64 loss: 0.3436669111251831
Batch 43/64 loss: 0.34376978874206543
Batch 44/64 loss: 0.3445242643356323
Batch 45/64 loss: 0.34387898445129395
Batch 46/64 loss: 0.3466050624847412
Batch 47/64 loss: 0.34413444995880127
Batch 48/64 loss: 0.3454798460006714
Batch 49/64 loss: 0.3472329378128052
Batch 50/64 loss: 0.34268367290496826
Batch 51/64 loss: 0.343539297580719
Batch 52/64 loss: 0.3459976315498352
Batch 53/64 loss: 0.3501066565513611
Batch 54/64 loss: 0.3407554626464844
Batch 55/64 loss: 0.34695446491241455
Batch 56/64 loss: 0.34395742416381836
Batch 57/64 loss: 0.34450769424438477
Batch 58/64 loss: 0.3436583876609802
Batch 59/64 loss: 0.35076916217803955
Batch 60/64 loss: 0.34478187561035156
Batch 61/64 loss: 0.34547746181488037
Batch 62/64 loss: 0.3445885181427002
Batch 63/64 loss: 0.34605371952056885
Batch 64/64 loss: 0.3449944853782654
Epoch 66  Train loss: 0.3455125698856279  Val loss: 0.3489910388730236
Saving best model, epoch: 66
Epoch 67
-------------------------------
Batch 1/64 loss: 0.341217577457428
Batch 2/64 loss: 0.34287911653518677
Batch 3/64 loss: 0.3471284508705139
Batch 4/64 loss: 0.34647655487060547
Batch 5/64 loss: 0.34534668922424316
Batch 6/64 loss: 0.3496023416519165
Batch 7/64 loss: 0.34512758255004883
Batch 8/64 loss: 0.3413752317428589
Batch 9/64 loss: 0.3465864658355713
Batch 10/64 loss: 0.34644174575805664
Batch 11/64 loss: 0.34570741653442383
Batch 12/64 loss: 0.3502854108810425
Batch 13/64 loss: 0.34529662132263184
Batch 14/64 loss: 0.3466053009033203
Batch 15/64 loss: 0.34460246562957764
Batch 16/64 loss: 0.3452906608581543
Batch 17/64 loss: 0.34160804748535156
Batch 18/64 loss: 0.34752774238586426
Batch 19/64 loss: 0.34966105222702026
Batch 20/64 loss: 0.34562861919403076
Batch 21/64 loss: 0.34578800201416016
Batch 22/64 loss: 0.3395879864692688
Batch 23/64 loss: 0.34199249744415283
Batch 24/64 loss: 0.34690606594085693
Batch 25/64 loss: 0.34309518337249756
Batch 26/64 loss: 0.339339017868042
Batch 27/64 loss: 0.3411164879798889
Batch 28/64 loss: 0.3416467308998108
Batch 29/64 loss: 0.3431558609008789
Batch 30/64 loss: 0.3420757055282593
Batch 31/64 loss: 0.3491860032081604
Batch 32/64 loss: 0.3434607982635498
Batch 33/64 loss: 0.3410677909851074
Batch 34/64 loss: 0.3424370288848877
Batch 35/64 loss: 0.3492565155029297
Batch 36/64 loss: 0.3446465730667114
Batch 37/64 loss: 0.34179723262786865
Batch 38/64 loss: 0.3443845510482788
Batch 39/64 loss: 0.34445416927337646
Batch 40/64 loss: 0.3428201675415039
Batch 41/64 loss: 0.34350132942199707
Batch 42/64 loss: 0.34387362003326416
Batch 43/64 loss: 0.34511053562164307
Batch 44/64 loss: 0.34717440605163574
Batch 45/64 loss: 0.34328973293304443
Batch 46/64 loss: 0.34490513801574707
Batch 47/64 loss: 0.34759336709976196
Batch 48/64 loss: 0.33811748027801514
Batch 49/64 loss: 0.3439345359802246
Batch 50/64 loss: 0.3470867872238159
Batch 51/64 loss: 0.3451616168022156
Batch 52/64 loss: 0.35001683235168457
Batch 53/64 loss: 0.33963263034820557
Batch 54/64 loss: 0.3456713557243347
Batch 55/64 loss: 0.34171062707901
Batch 56/64 loss: 0.34048646688461304
Batch 57/64 loss: 0.34380483627319336
Batch 58/64 loss: 0.34965944290161133
Batch 59/64 loss: 0.34691113233566284
Batch 60/64 loss: 0.3452422022819519
Batch 61/64 loss: 0.3475542664527893
Batch 62/64 loss: 0.34397852420806885
Batch 63/64 loss: 0.34427857398986816
Batch 64/64 loss: 0.3446803092956543
Epoch 67  Train loss: 0.3446245511372884  Val loss: 0.3485047800844068
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: 0.3444420099258423
Batch 2/64 loss: 0.34270811080932617
Batch 3/64 loss: 0.3463071584701538
Batch 4/64 loss: 0.3430737257003784
Batch 5/64 loss: 0.34628093242645264
Batch 6/64 loss: 0.3477060794830322
Batch 7/64 loss: 0.3419150710105896
Batch 8/64 loss: 0.34162330627441406
Batch 9/64 loss: 0.34512758255004883
Batch 10/64 loss: 0.34416019916534424
Batch 11/64 loss: 0.34618818759918213
Batch 12/64 loss: 0.3396737575531006
Batch 13/64 loss: 0.3483966588973999
Batch 14/64 loss: 0.34433335065841675
Batch 15/64 loss: 0.3454124331474304
Batch 16/64 loss: 0.3468925952911377
Batch 17/64 loss: 0.33973193168640137
Batch 18/64 loss: 0.34343624114990234
Batch 19/64 loss: 0.34358829259872437
Batch 20/64 loss: 0.3497160077095032
Batch 21/64 loss: 0.3440402150154114
Batch 22/64 loss: 0.3410625457763672
Batch 23/64 loss: 0.3448803424835205
Batch 24/64 loss: 0.34066545963287354
Batch 25/64 loss: 0.34187912940979004
Batch 26/64 loss: 0.34359312057495117
Batch 27/64 loss: 0.347012460231781
Batch 28/64 loss: 0.34604668617248535
Batch 29/64 loss: 0.3445231318473816
Batch 30/64 loss: 0.342753529548645
Batch 31/64 loss: 0.3466252088546753
Batch 32/64 loss: 0.34611546993255615
Batch 33/64 loss: 0.3419647216796875
Batch 34/64 loss: 0.3446815609931946
Batch 35/64 loss: 0.34470444917678833
Batch 36/64 loss: 0.34515976905822754
Batch 37/64 loss: 0.34439337253570557
Batch 38/64 loss: 0.3425661325454712
Batch 39/64 loss: 0.347511887550354
Batch 40/64 loss: 0.3411562442779541
Batch 41/64 loss: 0.34389084577560425
Batch 42/64 loss: 0.33818161487579346
Batch 43/64 loss: 0.3427457809448242
Batch 44/64 loss: 0.34395134449005127
Batch 45/64 loss: 0.34053105115890503
Batch 46/64 loss: 0.34319061040878296
Batch 47/64 loss: 0.34190380573272705
Batch 48/64 loss: 0.34110361337661743
Batch 49/64 loss: 0.3441368341445923
Batch 50/64 loss: 0.34304261207580566
Batch 51/64 loss: 0.34163087606430054
Batch 52/64 loss: 0.3468364477157593
Batch 53/64 loss: 0.34229111671447754
Batch 54/64 loss: 0.34264248609542847
Batch 55/64 loss: 0.3483424186706543
Batch 56/64 loss: 0.3465806245803833
Batch 57/64 loss: 0.34614038467407227
Batch 58/64 loss: 0.34509289264678955
Batch 59/64 loss: 0.34536856412887573
Batch 60/64 loss: 0.3510745167732239
Batch 61/64 loss: 0.34260278940200806
Batch 62/64 loss: 0.34269416332244873
Batch 63/64 loss: 0.34983980655670166
Batch 64/64 loss: 0.3461787700653076
Epoch 68  Train loss: 0.34424311132992014  Val loss: 0.3477742909565824
Saving best model, epoch: 68
Epoch 69
-------------------------------
Batch 1/64 loss: 0.3465923070907593
Batch 2/64 loss: 0.3427656888961792
Batch 3/64 loss: 0.350857138633728
Batch 4/64 loss: 0.3439997434616089
Batch 5/64 loss: 0.34641873836517334
Batch 6/64 loss: 0.34205377101898193
Batch 7/64 loss: 0.3464111089706421
Batch 8/64 loss: 0.34368598461151123
Batch 9/64 loss: 0.3427203297615051
Batch 10/64 loss: 0.3492998480796814
Batch 11/64 loss: 0.3461064100265503
Batch 12/64 loss: 0.33909380435943604
Batch 13/64 loss: 0.3397480249404907
Batch 14/64 loss: 0.34757936000823975
Batch 15/64 loss: 0.346656858921051
Batch 16/64 loss: 0.3437962532043457
Batch 17/64 loss: 0.3460894823074341
Batch 18/64 loss: 0.3439900279045105
Batch 19/64 loss: 0.34150367975234985
Batch 20/64 loss: 0.3473072648048401
Batch 21/64 loss: 0.34826821088790894
Batch 22/64 loss: 0.34612905979156494
Batch 23/64 loss: 0.33982908725738525
Batch 24/64 loss: 0.33948856592178345
Batch 25/64 loss: 0.34535229206085205
Batch 26/64 loss: 0.34450846910476685
Batch 27/64 loss: 0.34248220920562744
Batch 28/64 loss: 0.33954304456710815
Batch 29/64 loss: 0.33965182304382324
Batch 30/64 loss: 0.33983659744262695
Batch 31/64 loss: 0.34310275316238403
Batch 32/64 loss: 0.3450953960418701
Batch 33/64 loss: 0.34558868408203125
Batch 34/64 loss: 0.34577274322509766
Batch 35/64 loss: 0.3426840305328369
Batch 36/64 loss: 0.34489673376083374
Batch 37/64 loss: 0.3444932699203491
Batch 38/64 loss: 0.3402705788612366
Batch 39/64 loss: 0.340254545211792
Batch 40/64 loss: 0.3405907154083252
Batch 41/64 loss: 0.34409475326538086
Batch 42/64 loss: 0.34104812145233154
Batch 43/64 loss: 0.3449283838272095
Batch 44/64 loss: 0.34131789207458496
Batch 45/64 loss: 0.34596550464630127
Batch 46/64 loss: 0.34535473585128784
Batch 47/64 loss: 0.34498679637908936
Batch 48/64 loss: 0.33959126472473145
Batch 49/64 loss: 0.3451610207557678
Batch 50/64 loss: 0.3449563980102539
Batch 51/64 loss: 0.3405226469039917
Batch 52/64 loss: 0.3445853590965271
Batch 53/64 loss: 0.34149396419525146
Batch 54/64 loss: 0.34451824426651
Batch 55/64 loss: 0.343355655670166
Batch 56/64 loss: 0.34196221828460693
Batch 57/64 loss: 0.34390145540237427
Batch 58/64 loss: 0.34182965755462646
Batch 59/64 loss: 0.3407026529312134
Batch 60/64 loss: 0.3445061445236206
Batch 61/64 loss: 0.3423139452934265
Batch 62/64 loss: 0.34418433904647827
Batch 63/64 loss: 0.34183579683303833
Batch 64/64 loss: 0.3454289436340332
Epoch 69  Train loss: 0.3436345614638983  Val loss: 0.3477774481593129
Epoch 70
-------------------------------
Batch 1/64 loss: 0.33954888582229614
Batch 2/64 loss: 0.3423513174057007
Batch 3/64 loss: 0.3450077772140503
Batch 4/64 loss: 0.3377460241317749
Batch 5/64 loss: 0.3430720567703247
Batch 6/64 loss: 0.3412237763404846
Batch 7/64 loss: 0.3373483419418335
Batch 8/64 loss: 0.34617936611175537
Batch 9/64 loss: 0.3385639786720276
Batch 10/64 loss: 0.3437703847885132
Batch 11/64 loss: 0.3393979072570801
Batch 12/64 loss: 0.338504433631897
Batch 13/64 loss: 0.3459475040435791
Batch 14/64 loss: 0.3417443633079529
Batch 15/64 loss: 0.3482854962348938
Batch 16/64 loss: 0.3458048105239868
Batch 17/64 loss: 0.3424036502838135
Batch 18/64 loss: 0.33942317962646484
Batch 19/64 loss: 0.346305251121521
Batch 20/64 loss: 0.34042292833328247
Batch 21/64 loss: 0.3450348377227783
Batch 22/64 loss: 0.34406280517578125
Batch 23/64 loss: 0.3439962863922119
Batch 24/64 loss: 0.34307390451431274
Batch 25/64 loss: 0.3441351652145386
Batch 26/64 loss: 0.3380831480026245
Batch 27/64 loss: 0.33974891901016235
Batch 28/64 loss: 0.3430376648902893
Batch 29/64 loss: 0.3382261395454407
Batch 30/64 loss: 0.34101271629333496
Batch 31/64 loss: 0.3466686010360718
Batch 32/64 loss: 0.3424486517906189
Batch 33/64 loss: 0.33718329668045044
Batch 34/64 loss: 0.3465430736541748
Batch 35/64 loss: 0.34524214267730713
Batch 36/64 loss: 0.3478139638900757
Batch 37/64 loss: 0.34157925844192505
Batch 38/64 loss: 0.33932018280029297
Batch 39/64 loss: 0.34133201837539673
Batch 40/64 loss: 0.3455038070678711
Batch 41/64 loss: 0.34573400020599365
Batch 42/64 loss: 0.3418542146682739
Batch 43/64 loss: 0.34132474660873413
Batch 44/64 loss: 0.3456558585166931
Batch 45/64 loss: 0.3445502519607544
Batch 46/64 loss: 0.34095048904418945
Batch 47/64 loss: 0.34674882888793945
Batch 48/64 loss: 0.346793532371521
Batch 49/64 loss: 0.34709489345550537
Batch 50/64 loss: 0.34302473068237305
Batch 51/64 loss: 0.3487614393234253
Batch 52/64 loss: 0.34718644618988037
Batch 53/64 loss: 0.34324967861175537
Batch 54/64 loss: 0.337352991104126
Batch 55/64 loss: 0.34359830617904663
Batch 56/64 loss: 0.3465156555175781
Batch 57/64 loss: 0.3394676446914673
Batch 58/64 loss: 0.3455156087875366
Batch 59/64 loss: 0.3425482511520386
Batch 60/64 loss: 0.34122002124786377
Batch 61/64 loss: 0.34584295749664307
Batch 62/64 loss: 0.34542882442474365
Batch 63/64 loss: 0.33924055099487305
Batch 64/64 loss: 0.34060418605804443
Epoch 70  Train loss: 0.3429366443671432  Val loss: 0.3474650448540232
Saving best model, epoch: 70
Epoch 71
-------------------------------
Batch 1/64 loss: 0.3450443148612976
Batch 2/64 loss: 0.3425365686416626
Batch 3/64 loss: 0.33799129724502563
Batch 4/64 loss: 0.33813750743865967
Batch 5/64 loss: 0.34342700242996216
Batch 6/64 loss: 0.3434128165245056
Batch 7/64 loss: 0.3394327759742737
Batch 8/64 loss: 0.34092700481414795
Batch 9/64 loss: 0.34403401613235474
Batch 10/64 loss: 0.349046528339386
Batch 11/64 loss: 0.3381376266479492
Batch 12/64 loss: 0.34070074558258057
Batch 13/64 loss: 0.34365737438201904
Batch 14/64 loss: 0.3463578224182129
Batch 15/64 loss: 0.34088242053985596
Batch 16/64 loss: 0.34121090173721313
Batch 17/64 loss: 0.3407030701637268
Batch 18/64 loss: 0.34540295600891113
Batch 19/64 loss: 0.34283721446990967
Batch 20/64 loss: 0.34068262577056885
Batch 21/64 loss: 0.34669196605682373
Batch 22/64 loss: 0.3406848907470703
Batch 23/64 loss: 0.34867405891418457
Batch 24/64 loss: 0.3376215100288391
Batch 25/64 loss: 0.34328019618988037
Batch 26/64 loss: 0.34368896484375
Batch 27/64 loss: 0.3408825397491455
Batch 28/64 loss: 0.3427008390426636
Batch 29/64 loss: 0.34414225816726685
Batch 30/64 loss: 0.3374536633491516
Batch 31/64 loss: 0.34397292137145996
Batch 32/64 loss: 0.3421320915222168
Batch 33/64 loss: 0.34396207332611084
Batch 34/64 loss: 0.3430454730987549
Batch 35/64 loss: 0.3398147225379944
Batch 36/64 loss: 0.3393397331237793
Batch 37/64 loss: 0.34374016523361206
Batch 38/64 loss: 0.3479255437850952
Batch 39/64 loss: 0.34508275985717773
Batch 40/64 loss: 0.3453713655471802
Batch 41/64 loss: 0.34467172622680664
Batch 42/64 loss: 0.34282195568084717
Batch 43/64 loss: 0.3407963514328003
Batch 44/64 loss: 0.34191644191741943
Batch 45/64 loss: 0.34119659662246704
Batch 46/64 loss: 0.34447258710861206
Batch 47/64 loss: 0.340107798576355
Batch 48/64 loss: 0.3437596559524536
Batch 49/64 loss: 0.34072428941726685
Batch 50/64 loss: 0.34585368633270264
Batch 51/64 loss: 0.343487024307251
Batch 52/64 loss: 0.3411715030670166
Batch 53/64 loss: 0.34497249126434326
Batch 54/64 loss: 0.34229201078414917
Batch 55/64 loss: 0.3393852710723877
Batch 56/64 loss: 0.3411613702774048
Batch 57/64 loss: 0.34631776809692383
Batch 58/64 loss: 0.34443187713623047
Batch 59/64 loss: 0.34393274784088135
Batch 60/64 loss: 0.3409634828567505
Batch 61/64 loss: 0.3433288335800171
Batch 62/64 loss: 0.3376445770263672
Batch 63/64 loss: 0.3366681933403015
Batch 64/64 loss: 0.34954625368118286
Epoch 71  Train loss: 0.3425726785379298  Val loss: 0.3464799484436455
Saving best model, epoch: 71
Epoch 72
-------------------------------
Batch 1/64 loss: 0.3467061519622803
Batch 2/64 loss: 0.3429015278816223
Batch 3/64 loss: 0.3418481945991516
Batch 4/64 loss: 0.3430158495903015
Batch 5/64 loss: 0.33798766136169434
Batch 6/64 loss: 0.3458092212677002
Batch 7/64 loss: 0.3428415060043335
Batch 8/64 loss: 0.3409343957901001
Batch 9/64 loss: 0.3429476022720337
Batch 10/64 loss: 0.3435858488082886
Batch 11/64 loss: 0.3415420651435852
Batch 12/64 loss: 0.33896327018737793
Batch 13/64 loss: 0.34196990728378296
Batch 14/64 loss: 0.3459663391113281
Batch 15/64 loss: 0.33955949544906616
Batch 16/64 loss: 0.3449620008468628
Batch 17/64 loss: 0.3401224613189697
Batch 18/64 loss: 0.3407225012779236
Batch 19/64 loss: 0.3457832336425781
Batch 20/64 loss: 0.3427181839942932
Batch 21/64 loss: 0.3427279591560364
Batch 22/64 loss: 0.3365224599838257
Batch 23/64 loss: 0.3454376459121704
Batch 24/64 loss: 0.3396492004394531
Batch 25/64 loss: 0.33607274293899536
Batch 26/64 loss: 0.3423726558685303
Batch 27/64 loss: 0.3442577123641968
Batch 28/64 loss: 0.33964061737060547
Batch 29/64 loss: 0.350258469581604
Batch 30/64 loss: 0.3507951498031616
Batch 31/64 loss: 0.3442806005477905
Batch 32/64 loss: 0.34095656871795654
Batch 33/64 loss: 0.34117698669433594
Batch 34/64 loss: 0.34013426303863525
Batch 35/64 loss: 0.34059828519821167
Batch 36/64 loss: 0.34195804595947266
Batch 37/64 loss: 0.3449007272720337
Batch 38/64 loss: 0.3385244607925415
Batch 39/64 loss: 0.34516608715057373
Batch 40/64 loss: 0.34466326236724854
Batch 41/64 loss: 0.344002366065979
Batch 42/64 loss: 0.3475937843322754
Batch 43/64 loss: 0.34232795238494873
Batch 44/64 loss: 0.3386523723602295
Batch 45/64 loss: 0.3408638834953308
Batch 46/64 loss: 0.34262537956237793
Batch 47/64 loss: 0.3363487720489502
Batch 48/64 loss: 0.3441641330718994
Batch 49/64 loss: 0.3371063470840454
Batch 50/64 loss: 0.3440283536911011
Batch 51/64 loss: 0.3453199863433838
Batch 52/64 loss: 0.34546583890914917
Batch 53/64 loss: 0.3399233818054199
Batch 54/64 loss: 0.3404461145401001
Batch 55/64 loss: 0.3397035598754883
Batch 56/64 loss: 0.34263503551483154
Batch 57/64 loss: 0.33777332305908203
Batch 58/64 loss: 0.33997976779937744
Batch 59/64 loss: 0.33720433712005615
Batch 60/64 loss: 0.3394845724105835
Batch 61/64 loss: 0.3420224189758301
Batch 62/64 loss: 0.3448293209075928
Batch 63/64 loss: 0.3443934917449951
Batch 64/64 loss: 0.3424636125564575
Epoch 72  Train loss: 0.342191741513271  Val loss: 0.34615247519974857
Saving best model, epoch: 72
Epoch 73
-------------------------------
Batch 1/64 loss: 0.34971368312835693
Batch 2/64 loss: 0.33885496854782104
Batch 3/64 loss: 0.34176206588745117
Batch 4/64 loss: 0.3383537530899048
Batch 5/64 loss: 0.3375129699707031
Batch 6/64 loss: 0.3398836851119995
Batch 7/64 loss: 0.3430444002151489
Batch 8/64 loss: 0.3471222519874573
Batch 9/64 loss: 0.34062087535858154
Batch 10/64 loss: 0.3369632363319397
Batch 11/64 loss: 0.34053075313568115
Batch 12/64 loss: 0.34070920944213867
Batch 13/64 loss: 0.3397839665412903
Batch 14/64 loss: 0.3448945879936218
Batch 15/64 loss: 0.3393046259880066
Batch 16/64 loss: 0.3491014242172241
Batch 17/64 loss: 0.34128743410110474
Batch 18/64 loss: 0.3404655456542969
Batch 19/64 loss: 0.34588176012039185
Batch 20/64 loss: 0.34178996086120605
Batch 21/64 loss: 0.34050071239471436
Batch 22/64 loss: 0.3425754904747009
Batch 23/64 loss: 0.3431868553161621
Batch 24/64 loss: 0.3376682996749878
Batch 25/64 loss: 0.34101688861846924
Batch 26/64 loss: 0.34075552225112915
Batch 27/64 loss: 0.3417729139328003
Batch 28/64 loss: 0.3446890711784363
Batch 29/64 loss: 0.3414914608001709
Batch 30/64 loss: 0.3408762812614441
Batch 31/64 loss: 0.3419496417045593
Batch 32/64 loss: 0.3395915627479553
Batch 33/64 loss: 0.3415325880050659
Batch 34/64 loss: 0.34147000312805176
Batch 35/64 loss: 0.33698755502700806
Batch 36/64 loss: 0.34066861867904663
Batch 37/64 loss: 0.34515947103500366
Batch 38/64 loss: 0.34382861852645874
Batch 39/64 loss: 0.33903753757476807
Batch 40/64 loss: 0.3373528718948364
Batch 41/64 loss: 0.34066474437713623
Batch 42/64 loss: 0.34416067600250244
Batch 43/64 loss: 0.34036195278167725
Batch 44/64 loss: 0.343051552772522
Batch 45/64 loss: 0.3438915014266968
Batch 46/64 loss: 0.3460184335708618
Batch 47/64 loss: 0.3399679660797119
Batch 48/64 loss: 0.3393665552139282
Batch 49/64 loss: 0.34337520599365234
Batch 50/64 loss: 0.3425442576408386
Batch 51/64 loss: 0.33724623918533325
Batch 52/64 loss: 0.3424532413482666
Batch 53/64 loss: 0.33983153104782104
Batch 54/64 loss: 0.3407200574874878
Batch 55/64 loss: 0.34118497371673584
Batch 56/64 loss: 0.3363490104675293
Batch 57/64 loss: 0.3452985882759094
Batch 58/64 loss: 0.342368483543396
Batch 59/64 loss: 0.3395724892616272
Batch 60/64 loss: 0.3367272615432739
Batch 61/64 loss: 0.3422647714614868
Batch 62/64 loss: 0.3430819511413574
Batch 63/64 loss: 0.3395869731903076
Batch 64/64 loss: 0.34290802478790283
Epoch 73  Train loss: 0.3414425499298993  Val loss: 0.34520927983051314
Saving best model, epoch: 73
Epoch 74
-------------------------------
Batch 1/64 loss: 0.33952534198760986
Batch 2/64 loss: 0.33975446224212646
Batch 3/64 loss: 0.33917099237442017
Batch 4/64 loss: 0.3409475088119507
Batch 5/64 loss: 0.34252023696899414
Batch 6/64 loss: 0.34336352348327637
Batch 7/64 loss: 0.3350367546081543
Batch 8/64 loss: 0.3435373902320862
Batch 9/64 loss: 0.339057981967926
Batch 10/64 loss: 0.3438013195991516
Batch 11/64 loss: 0.3415539264678955
Batch 12/64 loss: 0.34147775173187256
Batch 13/64 loss: 0.3394012451171875
Batch 14/64 loss: 0.3421868085861206
Batch 15/64 loss: 0.3354155421257019
Batch 16/64 loss: 0.34059393405914307
Batch 17/64 loss: 0.34000593423843384
Batch 18/64 loss: 0.34378498792648315
Batch 19/64 loss: 0.3409789800643921
Batch 20/64 loss: 0.33999037742614746
Batch 21/64 loss: 0.34069305658340454
Batch 22/64 loss: 0.3382810354232788
Batch 23/64 loss: 0.3377152681350708
Batch 24/64 loss: 0.342021107673645
Batch 25/64 loss: 0.33707308769226074
Batch 26/64 loss: 0.340490460395813
Batch 27/64 loss: 0.3399660587310791
Batch 28/64 loss: 0.3412556052207947
Batch 29/64 loss: 0.34399300813674927
Batch 30/64 loss: 0.3396679759025574
Batch 31/64 loss: 0.33907610177993774
Batch 32/64 loss: 0.33733272552490234
Batch 33/64 loss: 0.3427606225013733
Batch 34/64 loss: 0.3372633457183838
Batch 35/64 loss: 0.34301018714904785
Batch 36/64 loss: 0.3402721881866455
Batch 37/64 loss: 0.34518158435821533
Batch 38/64 loss: 0.3441372513771057
Batch 39/64 loss: 0.34281712770462036
Batch 40/64 loss: 0.33885401487350464
Batch 41/64 loss: 0.3415961265563965
Batch 42/64 loss: 0.3410933017730713
Batch 43/64 loss: 0.33986032009124756
Batch 44/64 loss: 0.33738839626312256
Batch 45/64 loss: 0.3391575813293457
Batch 46/64 loss: 0.33907008171081543
Batch 47/64 loss: 0.3416978716850281
Batch 48/64 loss: 0.34007692337036133
Batch 49/64 loss: 0.33587372303009033
Batch 50/64 loss: 0.34223616123199463
Batch 51/64 loss: 0.34192657470703125
Batch 52/64 loss: 0.34215956926345825
Batch 53/64 loss: 0.33988404273986816
Batch 54/64 loss: 0.346390962600708
Batch 55/64 loss: 0.3443889617919922
Batch 56/64 loss: 0.3406696319580078
Batch 57/64 loss: 0.3441219925880432
Batch 58/64 loss: 0.33829712867736816
Batch 59/64 loss: 0.3451322317123413
Batch 60/64 loss: 0.33761918544769287
Batch 61/64 loss: 0.34168732166290283
Batch 62/64 loss: 0.3414521813392639
Batch 63/64 loss: 0.34207528829574585
Batch 64/64 loss: 0.34336763620376587
Epoch 74  Train loss: 0.3407897741186853  Val loss: 0.34561230779923113
Epoch 75
-------------------------------
Batch 1/64 loss: 0.33618927001953125
Batch 2/64 loss: 0.3433600664138794
Batch 3/64 loss: 0.34421682357788086
Batch 4/64 loss: 0.3396488428115845
Batch 5/64 loss: 0.33478033542633057
Batch 6/64 loss: 0.34033191204071045
Batch 7/64 loss: 0.34078335762023926
Batch 8/64 loss: 0.3347906470298767
Batch 9/64 loss: 0.33990585803985596
Batch 10/64 loss: 0.33674710988998413
Batch 11/64 loss: 0.34286439418792725
Batch 12/64 loss: 0.3406153917312622
Batch 13/64 loss: 0.339080274105072
Batch 14/64 loss: 0.3417813777923584
Batch 15/64 loss: 0.3375527858734131
Batch 16/64 loss: 0.34156662225723267
Batch 17/64 loss: 0.3444141149520874
Batch 18/64 loss: 0.3446493148803711
Batch 19/64 loss: 0.3420971632003784
Batch 20/64 loss: 0.33653223514556885
Batch 21/64 loss: 0.3400120139122009
Batch 22/64 loss: 0.3427097797393799
Batch 23/64 loss: 0.34244656562805176
Batch 24/64 loss: 0.34146934747695923
Batch 25/64 loss: 0.3416546583175659
Batch 26/64 loss: 0.3474280834197998
Batch 27/64 loss: 0.34325188398361206
Batch 28/64 loss: 0.34537410736083984
Batch 29/64 loss: 0.3403780460357666
Batch 30/64 loss: 0.3404929041862488
Batch 31/64 loss: 0.33792662620544434
Batch 32/64 loss: 0.33628910779953003
Batch 33/64 loss: 0.34009289741516113
Batch 34/64 loss: 0.33338844776153564
Batch 35/64 loss: 0.33952951431274414
Batch 36/64 loss: 0.3362448215484619
Batch 37/64 loss: 0.3380049467086792
Batch 38/64 loss: 0.3433549404144287
Batch 39/64 loss: 0.3409426808357239
Batch 40/64 loss: 0.33748066425323486
Batch 41/64 loss: 0.3378121852874756
Batch 42/64 loss: 0.3377547264099121
Batch 43/64 loss: 0.3401232361793518
Batch 44/64 loss: 0.3415040373802185
Batch 45/64 loss: 0.34413015842437744
Batch 46/64 loss: 0.3438487648963928
Batch 47/64 loss: 0.3432828187942505
Batch 48/64 loss: 0.3398853540420532
Batch 49/64 loss: 0.3467334508895874
Batch 50/64 loss: 0.33969932794570923
Batch 51/64 loss: 0.34597837924957275
Batch 52/64 loss: 0.3422166705131531
Batch 53/64 loss: 0.3434460759162903
Batch 54/64 loss: 0.3416711091995239
Batch 55/64 loss: 0.33944737911224365
Batch 56/64 loss: 0.33825647830963135
Batch 57/64 loss: 0.33921438455581665
Batch 58/64 loss: 0.34384334087371826
Batch 59/64 loss: 0.3362923860549927
Batch 60/64 loss: 0.34672069549560547
Batch 61/64 loss: 0.3423515558242798
Batch 62/64 loss: 0.34172242879867554
Batch 63/64 loss: 0.33847367763519287
Batch 64/64 loss: 0.34418898820877075
Epoch 75  Train loss: 0.34075184780008655  Val loss: 0.34533286217561704
Epoch 76
-------------------------------
Batch 1/64 loss: 0.3407136797904968
Batch 2/64 loss: 0.3426865339279175
Batch 3/64 loss: 0.3442084789276123
Batch 4/64 loss: 0.3374978303909302
Batch 5/64 loss: 0.3403558135032654
Batch 6/64 loss: 0.34114694595336914
Batch 7/64 loss: 0.3379642963409424
Batch 8/64 loss: 0.33581483364105225
Batch 9/64 loss: 0.3363937735557556
Batch 10/64 loss: 0.34006166458129883
Batch 11/64 loss: 0.3409832715988159
Batch 12/64 loss: 0.33887797594070435
Batch 13/64 loss: 0.34147948026657104
Batch 14/64 loss: 0.3356969356536865
Batch 15/64 loss: 0.3447989225387573
Batch 16/64 loss: 0.3477778434753418
Batch 17/64 loss: 0.3398878574371338
Batch 18/64 loss: 0.33607369661331177
Batch 19/64 loss: 0.33630406856536865
Batch 20/64 loss: 0.3417154550552368
Batch 21/64 loss: 0.3340376615524292
Batch 22/64 loss: 0.3405921459197998
Batch 23/64 loss: 0.3422834873199463
Batch 24/64 loss: 0.33796000480651855
Batch 25/64 loss: 0.336788535118103
Batch 26/64 loss: 0.339147686958313
Batch 27/64 loss: 0.3422784209251404
Batch 28/64 loss: 0.34604859352111816
Batch 29/64 loss: 0.33688390254974365
Batch 30/64 loss: 0.34126317501068115
Batch 31/64 loss: 0.34119611978530884
Batch 32/64 loss: 0.3387460708618164
Batch 33/64 loss: 0.3354431390762329
Batch 34/64 loss: 0.33629465103149414
Batch 35/64 loss: 0.3399338126182556
Batch 36/64 loss: 0.3374062180519104
Batch 37/64 loss: 0.3439010977745056
Batch 38/64 loss: 0.3414759635925293
Batch 39/64 loss: 0.34683698415756226
Batch 40/64 loss: 0.3374525308609009
Batch 41/64 loss: 0.3376421332359314
Batch 42/64 loss: 0.3415883779525757
Batch 43/64 loss: 0.34053367376327515
Batch 44/64 loss: 0.339094877243042
Batch 45/64 loss: 0.33888012170791626
Batch 46/64 loss: 0.3364468812942505
Batch 47/64 loss: 0.3451423645019531
Batch 48/64 loss: 0.3454095125198364
Batch 49/64 loss: 0.3394737243652344
Batch 50/64 loss: 0.33994925022125244
Batch 51/64 loss: 0.3400382995605469
Batch 52/64 loss: 0.33826780319213867
Batch 53/64 loss: 0.34160542488098145
Batch 54/64 loss: 0.33976471424102783
Batch 55/64 loss: 0.3412156105041504
Batch 56/64 loss: 0.34143900871276855
Batch 57/64 loss: 0.34506452083587646
Batch 58/64 loss: 0.3393637537956238
Batch 59/64 loss: 0.33729857206344604
Batch 60/64 loss: 0.34340810775756836
Batch 61/64 loss: 0.34448301792144775
Batch 62/64 loss: 0.33699488639831543
Batch 63/64 loss: 0.34225255250930786
Batch 64/64 loss: 0.3367878794670105
Epoch 76  Train loss: 0.3401467867926055  Val loss: 0.3444742169167168
Saving best model, epoch: 76
Epoch 77
-------------------------------
Batch 1/64 loss: 0.34041744470596313
Batch 2/64 loss: 0.34458237886428833
Batch 3/64 loss: 0.34735071659088135
Batch 4/64 loss: 0.3326277732849121
Batch 5/64 loss: 0.33944767713546753
Batch 6/64 loss: 0.33542609214782715
Batch 7/64 loss: 0.33861255645751953
Batch 8/64 loss: 0.3405897617340088
Batch 9/64 loss: 0.33765530586242676
Batch 10/64 loss: 0.3429710865020752
Batch 11/64 loss: 0.3415687680244446
Batch 12/64 loss: 0.33581048250198364
Batch 13/64 loss: 0.3384805917739868
Batch 14/64 loss: 0.3406625986099243
Batch 15/64 loss: 0.3397177457809448
Batch 16/64 loss: 0.3426249027252197
Batch 17/64 loss: 0.33856403827667236
Batch 18/64 loss: 0.3420908451080322
Batch 19/64 loss: 0.3360942602157593
Batch 20/64 loss: 0.3371279239654541
Batch 21/64 loss: 0.33899474143981934
Batch 22/64 loss: 0.3401832580566406
Batch 23/64 loss: 0.3431457281112671
Batch 24/64 loss: 0.3405650854110718
Batch 25/64 loss: 0.3386104702949524
Batch 26/64 loss: 0.339938759803772
Batch 27/64 loss: 0.3416939377784729
Batch 28/64 loss: 0.337618350982666
Batch 29/64 loss: 0.3400590419769287
Batch 30/64 loss: 0.33661240339279175
Batch 31/64 loss: 0.3426213264465332
Batch 32/64 loss: 0.3379770517349243
Batch 33/64 loss: 0.3415071368217468
Batch 34/64 loss: 0.3385190963745117
Batch 35/64 loss: 0.33606183528900146
Batch 36/64 loss: 0.3390634059906006
Batch 37/64 loss: 0.34471452236175537
Batch 38/64 loss: 0.33265531063079834
Batch 39/64 loss: 0.34542322158813477
Batch 40/64 loss: 0.3361012935638428
Batch 41/64 loss: 0.33870983123779297
Batch 42/64 loss: 0.33831334114074707
Batch 43/64 loss: 0.33642101287841797
Batch 44/64 loss: 0.3368881940841675
Batch 45/64 loss: 0.3372965455055237
Batch 46/64 loss: 0.336742639541626
Batch 47/64 loss: 0.3342588543891907
Batch 48/64 loss: 0.340920090675354
Batch 49/64 loss: 0.3331815004348755
Batch 50/64 loss: 0.3351894021034241
Batch 51/64 loss: 0.3393309712409973
Batch 52/64 loss: 0.34341293573379517
Batch 53/64 loss: 0.3346114158630371
Batch 54/64 loss: 0.3369187116622925
Batch 55/64 loss: 0.34019798040390015
Batch 56/64 loss: 0.34308087825775146
Batch 57/64 loss: 0.34045934677124023
Batch 58/64 loss: 0.33416688442230225
Batch 59/64 loss: 0.34079474210739136
Batch 60/64 loss: 0.340648889541626
Batch 61/64 loss: 0.3425161838531494
Batch 62/64 loss: 0.3397330045700073
Batch 63/64 loss: 0.33977311849594116
Batch 64/64 loss: 0.3344181776046753
Epoch 77  Train loss: 0.3391195142970366  Val loss: 0.3435757811536494
Saving best model, epoch: 77
Epoch 78
-------------------------------
Batch 1/64 loss: 0.33568572998046875
Batch 2/64 loss: 0.3441033363342285
Batch 3/64 loss: 0.3388683795928955
Batch 4/64 loss: 0.3387676477432251
Batch 5/64 loss: 0.3356606960296631
Batch 6/64 loss: 0.3380354642868042
Batch 7/64 loss: 0.33803677558898926
Batch 8/64 loss: 0.3414590358734131
Batch 9/64 loss: 0.33785200119018555
Batch 10/64 loss: 0.34165310859680176
Batch 11/64 loss: 0.33668971061706543
Batch 12/64 loss: 0.3395846486091614
Batch 13/64 loss: 0.34523868560791016
Batch 14/64 loss: 0.3368116021156311
Batch 15/64 loss: 0.3420870304107666
Batch 16/64 loss: 0.339131236076355
Batch 17/64 loss: 0.3455321192741394
Batch 18/64 loss: 0.33770012855529785
Batch 19/64 loss: 0.3400799036026001
Batch 20/64 loss: 0.3403280973434448
Batch 21/64 loss: 0.3339053988456726
Batch 22/64 loss: 0.33976566791534424
Batch 23/64 loss: 0.3373408317565918
Batch 24/64 loss: 0.340476393699646
Batch 25/64 loss: 0.3431044816970825
Batch 26/64 loss: 0.3360116481781006
Batch 27/64 loss: 0.3408963084220886
Batch 28/64 loss: 0.3418393135070801
Batch 29/64 loss: 0.34413111209869385
Batch 30/64 loss: 0.3341437578201294
Batch 31/64 loss: 0.3380357027053833
Batch 32/64 loss: 0.3412412405014038
Batch 33/64 loss: 0.3327910900115967
Batch 34/64 loss: 0.3364047408103943
Batch 35/64 loss: 0.34171921014785767
Batch 36/64 loss: 0.33455324172973633
Batch 37/64 loss: 0.3424193263053894
Batch 38/64 loss: 0.33370542526245117
Batch 39/64 loss: 0.33943939208984375
Batch 40/64 loss: 0.33778202533721924
Batch 41/64 loss: 0.333560585975647
Batch 42/64 loss: 0.33838826417922974
Batch 43/64 loss: 0.3394085764884949
Batch 44/64 loss: 0.3353230357170105
Batch 45/64 loss: 0.3390876054763794
Batch 46/64 loss: 0.3326525092124939
Batch 47/64 loss: 0.34707093238830566
Batch 48/64 loss: 0.3408699035644531
Batch 49/64 loss: 0.3395228981971741
Batch 50/64 loss: 0.34183692932128906
Batch 51/64 loss: 0.3419809937477112
Batch 52/64 loss: 0.3411368131637573
Batch 53/64 loss: 0.3457552194595337
Batch 54/64 loss: 0.3377479314804077
Batch 55/64 loss: 0.3416464328765869
Batch 56/64 loss: 0.33938872814178467
Batch 57/64 loss: 0.3392000198364258
Batch 58/64 loss: 0.33794116973876953
Batch 59/64 loss: 0.3424873948097229
Batch 60/64 loss: 0.33934056758880615
Batch 61/64 loss: 0.3379836082458496
Batch 62/64 loss: 0.33642578125
Batch 63/64 loss: 0.3363822102546692
Batch 64/64 loss: 0.33736681938171387
Epoch 78  Train loss: 0.3391556842654359  Val loss: 0.34485738752633843
Epoch 79
-------------------------------
Batch 1/64 loss: 0.33324289321899414
Batch 2/64 loss: 0.3429439067840576
Batch 3/64 loss: 0.34158921241760254
Batch 4/64 loss: 0.34011226892471313
Batch 5/64 loss: 0.33456170558929443
Batch 6/64 loss: 0.3375232219696045
Batch 7/64 loss: 0.3360048532485962
Batch 8/64 loss: 0.33782756328582764
Batch 9/64 loss: 0.33433425426483154
Batch 10/64 loss: 0.3377607464790344
Batch 11/64 loss: 0.3346364498138428
Batch 12/64 loss: 0.33620381355285645
Batch 13/64 loss: 0.344637930393219
Batch 14/64 loss: 0.3340819478034973
Batch 15/64 loss: 0.3340456485748291
Batch 16/64 loss: 0.344285786151886
Batch 17/64 loss: 0.34156954288482666
Batch 18/64 loss: 0.3377523422241211
Batch 19/64 loss: 0.33692246675491333
Batch 20/64 loss: 0.33569979667663574
Batch 21/64 loss: 0.33753740787506104
Batch 22/64 loss: 0.3409271836280823
Batch 23/64 loss: 0.3444904088973999
Batch 24/64 loss: 0.33611249923706055
Batch 25/64 loss: 0.3369176983833313
Batch 26/64 loss: 0.33636754751205444
Batch 27/64 loss: 0.34191399812698364
Batch 28/64 loss: 0.33751797676086426
Batch 29/64 loss: 0.3349623680114746
Batch 30/64 loss: 0.3411779999732971
Batch 31/64 loss: 0.3427092432975769
Batch 32/64 loss: 0.3383767604827881
Batch 33/64 loss: 0.33703041076660156
Batch 34/64 loss: 0.3331741690635681
Batch 35/64 loss: 0.33767348527908325
Batch 36/64 loss: 0.34130752086639404
Batch 37/64 loss: 0.3361409306526184
Batch 38/64 loss: 0.3368765711784363
Batch 39/64 loss: 0.33730238676071167
Batch 40/64 loss: 0.3362088203430176
Batch 41/64 loss: 0.33548492193222046
Batch 42/64 loss: 0.3349953889846802
Batch 43/64 loss: 0.34427034854888916
Batch 44/64 loss: 0.34189820289611816
Batch 45/64 loss: 0.3395758867263794
Batch 46/64 loss: 0.33422768115997314
Batch 47/64 loss: 0.33820730447769165
Batch 48/64 loss: 0.3363664746284485
Batch 49/64 loss: 0.33671969175338745
Batch 50/64 loss: 0.3393738269805908
Batch 51/64 loss: 0.3393794298171997
Batch 52/64 loss: 0.3340110182762146
Batch 53/64 loss: 0.3443172574043274
Batch 54/64 loss: 0.3363897204399109
Batch 55/64 loss: 0.3392025828361511
Batch 56/64 loss: 0.3393256664276123
Batch 57/64 loss: 0.3342288136482239
Batch 58/64 loss: 0.3401235342025757
Batch 59/64 loss: 0.344169020652771
Batch 60/64 loss: 0.34415221214294434
Batch 61/64 loss: 0.34080106019973755
Batch 62/64 loss: 0.3413159251213074
Batch 63/64 loss: 0.3362387418746948
Batch 64/64 loss: 0.34472179412841797
Epoch 79  Train loss: 0.33841220070334044  Val loss: 0.34331009805816964
Saving best model, epoch: 79
Epoch 80
-------------------------------
Batch 1/64 loss: 0.33411937952041626
Batch 2/64 loss: 0.3375172019004822
Batch 3/64 loss: 0.337455153465271
Batch 4/64 loss: 0.3363012671470642
Batch 5/64 loss: 0.33780479431152344
Batch 6/64 loss: 0.3455861806869507
Batch 7/64 loss: 0.33739304542541504
Batch 8/64 loss: 0.33850419521331787
Batch 9/64 loss: 0.33181798458099365
Batch 10/64 loss: 0.33637189865112305
Batch 11/64 loss: 0.33763808012008667
Batch 12/64 loss: 0.33814573287963867
Batch 13/64 loss: 0.33668386936187744
Batch 14/64 loss: 0.33589720726013184
Batch 15/64 loss: 0.33365070819854736
Batch 16/64 loss: 0.3398171663284302
Batch 17/64 loss: 0.3441837430000305
Batch 18/64 loss: 0.33734285831451416
Batch 19/64 loss: 0.33753108978271484
Batch 20/64 loss: 0.3386232852935791
Batch 21/64 loss: 0.3404834270477295
Batch 22/64 loss: 0.3359580636024475
Batch 23/64 loss: 0.33720946311950684
Batch 24/64 loss: 0.341899037361145
Batch 25/64 loss: 0.33687734603881836
Batch 26/64 loss: 0.3412954807281494
Batch 27/64 loss: 0.34808939695358276
Batch 28/64 loss: 0.3379315733909607
Batch 29/64 loss: 0.33680373430252075
Batch 30/64 loss: 0.3362717032432556
Batch 31/64 loss: 0.33958059549331665
Batch 32/64 loss: 0.3391309976577759
Batch 33/64 loss: 0.33718758821487427
Batch 34/64 loss: 0.33601832389831543
Batch 35/64 loss: 0.33751165866851807
Batch 36/64 loss: 0.34128546714782715
Batch 37/64 loss: 0.33365708589553833
Batch 38/64 loss: 0.3361549973487854
Batch 39/64 loss: 0.34150266647338867
Batch 40/64 loss: 0.343083918094635
Batch 41/64 loss: 0.3409559726715088
Batch 42/64 loss: 0.338570237159729
Batch 43/64 loss: 0.3363766670227051
Batch 44/64 loss: 0.3430039882659912
Batch 45/64 loss: 0.3352372646331787
Batch 46/64 loss: 0.3343127965927124
Batch 47/64 loss: 0.3402899503707886
Batch 48/64 loss: 0.33094507455825806
Batch 49/64 loss: 0.3309364914894104
Batch 50/64 loss: 0.33175480365753174
Batch 51/64 loss: 0.3348163962364197
Batch 52/64 loss: 0.3391611576080322
Batch 53/64 loss: 0.33420825004577637
Batch 54/64 loss: 0.3461538553237915
Batch 55/64 loss: 0.33757925033569336
Batch 56/64 loss: 0.3432773947715759
Batch 57/64 loss: 0.3375605344772339
Batch 58/64 loss: 0.3335200548171997
Batch 59/64 loss: 0.3341484069824219
Batch 60/64 loss: 0.335408091545105
Batch 61/64 loss: 0.33727025985717773
Batch 62/64 loss: 0.33949601650238037
Batch 63/64 loss: 0.336661696434021
Batch 64/64 loss: 0.3344094157218933
Epoch 80  Train loss: 0.33776892610624726  Val loss: 0.3426310745711179
Saving best model, epoch: 80
Epoch 81
-------------------------------
Batch 1/64 loss: 0.3338778614997864
Batch 2/64 loss: 0.3367028832435608
Batch 3/64 loss: 0.3454498052597046
Batch 4/64 loss: 0.3304453492164612
Batch 5/64 loss: 0.3371623158454895
Batch 6/64 loss: 0.3347390294075012
Batch 7/64 loss: 0.3314945101737976
Batch 8/64 loss: 0.3355509638786316
Batch 9/64 loss: 0.33463430404663086
Batch 10/64 loss: 0.3380492925643921
Batch 11/64 loss: 0.3389052748680115
Batch 12/64 loss: 0.335602343082428
Batch 13/64 loss: 0.3336412310600281
Batch 14/64 loss: 0.3353118896484375
Batch 15/64 loss: 0.3356442451477051
Batch 16/64 loss: 0.3354015350341797
Batch 17/64 loss: 0.33962559700012207
Batch 18/64 loss: 0.3314701318740845
Batch 19/64 loss: 0.3365902900695801
Batch 20/64 loss: 0.3392264246940613
Batch 21/64 loss: 0.3327127695083618
Batch 22/64 loss: 0.3401622772216797
Batch 23/64 loss: 0.33976298570632935
Batch 24/64 loss: 0.34026122093200684
Batch 25/64 loss: 0.34134042263031006
Batch 26/64 loss: 0.3353283405303955
Batch 27/64 loss: 0.3398110866546631
Batch 28/64 loss: 0.3364671468734741
Batch 29/64 loss: 0.33901989459991455
Batch 30/64 loss: 0.34046363830566406
Batch 31/64 loss: 0.33260565996170044
Batch 32/64 loss: 0.3381413221359253
Batch 33/64 loss: 0.33851736783981323
Batch 34/64 loss: 0.3370007276535034
Batch 35/64 loss: 0.33850574493408203
Batch 36/64 loss: 0.33484017848968506
Batch 37/64 loss: 0.3367992043495178
Batch 38/64 loss: 0.3421218991279602
Batch 39/64 loss: 0.34138500690460205
Batch 40/64 loss: 0.3409663438796997
Batch 41/64 loss: 0.33510708808898926
Batch 42/64 loss: 0.3343069553375244
Batch 43/64 loss: 0.33693408966064453
Batch 44/64 loss: 0.3452272415161133
Batch 45/64 loss: 0.3356195092201233
Batch 46/64 loss: 0.3398975133895874
Batch 47/64 loss: 0.3360990881919861
Batch 48/64 loss: 0.3402404189109802
Batch 49/64 loss: 0.33430016040802
Batch 50/64 loss: 0.3346935510635376
Batch 51/64 loss: 0.33564215898513794
Batch 52/64 loss: 0.3416401147842407
Batch 53/64 loss: 0.3315625786781311
Batch 54/64 loss: 0.3380957245826721
Batch 55/64 loss: 0.33707404136657715
Batch 56/64 loss: 0.3339775800704956
Batch 57/64 loss: 0.33578383922576904
Batch 58/64 loss: 0.33537352085113525
Batch 59/64 loss: 0.33621644973754883
Batch 60/64 loss: 0.3383144736289978
Batch 61/64 loss: 0.33512330055236816
Batch 62/64 loss: 0.3382972478866577
Batch 63/64 loss: 0.3352329730987549
Batch 64/64 loss: 0.34023261070251465
Epoch 81  Train loss: 0.33703015832340016  Val loss: 0.3415455957458601
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: 0.336822509765625
Batch 2/64 loss: 0.33474910259246826
Batch 3/64 loss: 0.34238672256469727
Batch 4/64 loss: 0.3351644277572632
Batch 5/64 loss: 0.3353385925292969
Batch 6/64 loss: 0.3331577777862549
Batch 7/64 loss: 0.33497917652130127
Batch 8/64 loss: 0.34072375297546387
Batch 9/64 loss: 0.33231526613235474
Batch 10/64 loss: 0.3314970135688782
Batch 11/64 loss: 0.3400002717971802
Batch 12/64 loss: 0.3370283842086792
Batch 13/64 loss: 0.3366525173187256
Batch 14/64 loss: 0.3361518383026123
Batch 15/64 loss: 0.3353259563446045
Batch 16/64 loss: 0.3456342816352844
Batch 17/64 loss: 0.33728837966918945
Batch 18/64 loss: 0.3364081382751465
Batch 19/64 loss: 0.335925817489624
Batch 20/64 loss: 0.33793962001800537
Batch 21/64 loss: 0.3396352529525757
Batch 22/64 loss: 0.33469974994659424
Batch 23/64 loss: 0.3462355136871338
Batch 24/64 loss: 0.3380296230316162
Batch 25/64 loss: 0.3401060700416565
Batch 26/64 loss: 0.33824586868286133
Batch 27/64 loss: 0.3379665017127991
Batch 28/64 loss: 0.3351900577545166
Batch 29/64 loss: 0.3352223038673401
Batch 30/64 loss: 0.33316361904144287
Batch 31/64 loss: 0.3336518406867981
Batch 32/64 loss: 0.33665138483047485
Batch 33/64 loss: 0.3330470323562622
Batch 34/64 loss: 0.33531099557876587
Batch 35/64 loss: 0.33741652965545654
Batch 36/64 loss: 0.3297703266143799
Batch 37/64 loss: 0.33819305896759033
Batch 38/64 loss: 0.33661413192749023
Batch 39/64 loss: 0.3356747627258301
Batch 40/64 loss: 0.3361220359802246
Batch 41/64 loss: 0.3345763683319092
Batch 42/64 loss: 0.338228702545166
Batch 43/64 loss: 0.3384368419647217
Batch 44/64 loss: 0.33605217933654785
Batch 45/64 loss: 0.3369019031524658
Batch 46/64 loss: 0.3408864736557007
Batch 47/64 loss: 0.3377419710159302
Batch 48/64 loss: 0.3334103226661682
Batch 49/64 loss: 0.33052778244018555
Batch 50/64 loss: 0.3344101905822754
Batch 51/64 loss: 0.3370785713195801
Batch 52/64 loss: 0.3377189636230469
Batch 53/64 loss: 0.3366365432739258
Batch 54/64 loss: 0.3390907645225525
Batch 55/64 loss: 0.3337627649307251
Batch 56/64 loss: 0.3372414708137512
Batch 57/64 loss: 0.33592188358306885
Batch 58/64 loss: 0.3369753360748291
Batch 59/64 loss: 0.3403432369232178
Batch 60/64 loss: 0.3327537178993225
Batch 61/64 loss: 0.3373366594314575
Batch 62/64 loss: 0.3399919271469116
Batch 63/64 loss: 0.33713841438293457
Batch 64/64 loss: 0.33782851696014404
Epoch 82  Train loss: 0.3366740483863681  Val loss: 0.3428939617786211
Epoch 83
-------------------------------
Batch 1/64 loss: 0.33654695749282837
Batch 2/64 loss: 0.3333975076675415
Batch 3/64 loss: 0.33650779724121094
Batch 4/64 loss: 0.33817529678344727
Batch 5/64 loss: 0.34270966053009033
Batch 6/64 loss: 0.3332301378250122
Batch 7/64 loss: 0.3401627540588379
Batch 8/64 loss: 0.3420788049697876
Batch 9/64 loss: 0.3317742347717285
Batch 10/64 loss: 0.3380480408668518
Batch 11/64 loss: 0.3278564214706421
Batch 12/64 loss: 0.33365392684936523
Batch 13/64 loss: 0.3358876705169678
Batch 14/64 loss: 0.3319718837738037
Batch 15/64 loss: 0.33810245990753174
Batch 16/64 loss: 0.34087610244750977
Batch 17/64 loss: 0.33473920822143555
Batch 18/64 loss: 0.33395683765411377
Batch 19/64 loss: 0.3369140625
Batch 20/64 loss: 0.3371281623840332
Batch 21/64 loss: 0.3331512212753296
Batch 22/64 loss: 0.33418411016464233
Batch 23/64 loss: 0.33975279331207275
Batch 24/64 loss: 0.337627649307251
Batch 25/64 loss: 0.3338056206703186
Batch 26/64 loss: 0.3374788165092468
Batch 27/64 loss: 0.33784496784210205
Batch 28/64 loss: 0.3346328139305115
Batch 29/64 loss: 0.3359103202819824
Batch 30/64 loss: 0.3444095849990845
Batch 31/64 loss: 0.3365545868873596
Batch 32/64 loss: 0.3392654061317444
Batch 33/64 loss: 0.33726441860198975
Batch 34/64 loss: 0.3339575529098511
Batch 35/64 loss: 0.3379570245742798
Batch 36/64 loss: 0.33544063568115234
Batch 37/64 loss: 0.33914804458618164
Batch 38/64 loss: 0.33508503437042236
Batch 39/64 loss: 0.3370387554168701
Batch 40/64 loss: 0.3356412649154663
Batch 41/64 loss: 0.3342524766921997
Batch 42/64 loss: 0.3352179527282715
Batch 43/64 loss: 0.33429867029190063
Batch 44/64 loss: 0.3363572955131531
Batch 45/64 loss: 0.33637821674346924
Batch 46/64 loss: 0.33110034465789795
Batch 47/64 loss: 0.3382699489593506
Batch 48/64 loss: 0.3310753107070923
Batch 49/64 loss: 0.33687782287597656
Batch 50/64 loss: 0.33297836780548096
Batch 51/64 loss: 0.3365129828453064
Batch 52/64 loss: 0.33959972858428955
Batch 53/64 loss: 0.3390272855758667
Batch 54/64 loss: 0.3357906937599182
Batch 55/64 loss: 0.3361014127731323
Batch 56/64 loss: 0.3380943536758423
Batch 57/64 loss: 0.338903546333313
Batch 58/64 loss: 0.33410942554473877
Batch 59/64 loss: 0.33654725551605225
Batch 60/64 loss: 0.3401654362678528
Batch 61/64 loss: 0.3375978469848633
Batch 62/64 loss: 0.33659225702285767
Batch 63/64 loss: 0.3347647190093994
Batch 64/64 loss: 0.3340247869491577
Epoch 83  Train loss: 0.3363294194726383  Val loss: 0.3420319796837482
Epoch 84
-------------------------------
Batch 1/64 loss: 0.3400787115097046
Batch 2/64 loss: 0.34322333335876465
Batch 3/64 loss: 0.3358626961708069
Batch 4/64 loss: 0.3340686559677124
Batch 5/64 loss: 0.33656907081604004
Batch 6/64 loss: 0.33874213695526123
Batch 7/64 loss: 0.3317835330963135
Batch 8/64 loss: 0.33191680908203125
Batch 9/64 loss: 0.3325026035308838
Batch 10/64 loss: 0.3375176191329956
Batch 11/64 loss: 0.33598780632019043
Batch 12/64 loss: 0.33780157566070557
Batch 13/64 loss: 0.33483147621154785
Batch 14/64 loss: 0.3296831250190735
Batch 15/64 loss: 0.33876359462738037
Batch 16/64 loss: 0.33880889415740967
Batch 17/64 loss: 0.3336225748062134
Batch 18/64 loss: 0.33532100915908813
Batch 19/64 loss: 0.3348257541656494
Batch 20/64 loss: 0.33000707626342773
Batch 21/64 loss: 0.3288351893424988
Batch 22/64 loss: 0.33563756942749023
Batch 23/64 loss: 0.33069610595703125
Batch 24/64 loss: 0.3385319709777832
Batch 25/64 loss: 0.3385540843009949
Batch 26/64 loss: 0.33624279499053955
Batch 27/64 loss: 0.33258485794067383
Batch 28/64 loss: 0.3344130516052246
Batch 29/64 loss: 0.33344727754592896
Batch 30/64 loss: 0.33242523670196533
Batch 31/64 loss: 0.33560431003570557
Batch 32/64 loss: 0.33756327629089355
Batch 33/64 loss: 0.33431482315063477
Batch 34/64 loss: 0.3333463668823242
Batch 35/64 loss: 0.34215080738067627
Batch 36/64 loss: 0.33484023809432983
Batch 37/64 loss: 0.33769965171813965
Batch 38/64 loss: 0.33854764699935913
Batch 39/64 loss: 0.342751145362854
Batch 40/64 loss: 0.33336973190307617
Batch 41/64 loss: 0.33423513174057007
Batch 42/64 loss: 0.33668529987335205
Batch 43/64 loss: 0.332372784614563
Batch 44/64 loss: 0.3346719741821289
Batch 45/64 loss: 0.33691930770874023
Batch 46/64 loss: 0.337657630443573
Batch 47/64 loss: 0.3341143727302551
Batch 48/64 loss: 0.3397842049598694
Batch 49/64 loss: 0.33796459436416626
Batch 50/64 loss: 0.33930492401123047
Batch 51/64 loss: 0.33978039026260376
Batch 52/64 loss: 0.33447450399398804
Batch 53/64 loss: 0.33573275804519653
Batch 54/64 loss: 0.3390110731124878
Batch 55/64 loss: 0.3396826982498169
Batch 56/64 loss: 0.33749425411224365
Batch 57/64 loss: 0.3351329565048218
Batch 58/64 loss: 0.33327823877334595
Batch 59/64 loss: 0.3330676555633545
Batch 60/64 loss: 0.33342307806015015
Batch 61/64 loss: 0.33563458919525146
Batch 62/64 loss: 0.3416118025779724
Batch 63/64 loss: 0.3351999521255493
Batch 64/64 loss: 0.33621805906295776
Epoch 84  Train loss: 0.3358881868568121  Val loss: 0.34287069568928985
Epoch 85
-------------------------------
Batch 1/64 loss: 0.33769941329956055
Batch 2/64 loss: 0.33639347553253174
Batch 3/64 loss: 0.3353155255317688
Batch 4/64 loss: 0.3368642330169678
Batch 5/64 loss: 0.34197235107421875
Batch 6/64 loss: 0.3394666910171509
Batch 7/64 loss: 0.33243680000305176
Batch 8/64 loss: 0.33408910036087036
Batch 9/64 loss: 0.335385799407959
Batch 10/64 loss: 0.3391405940055847
Batch 11/64 loss: 0.3397785425186157
Batch 12/64 loss: 0.33552634716033936
Batch 13/64 loss: 0.33167433738708496
Batch 14/64 loss: 0.3415451645851135
Batch 15/64 loss: 0.3340338468551636
Batch 16/64 loss: 0.3309658169746399
Batch 17/64 loss: 0.331104040145874
Batch 18/64 loss: 0.33450353145599365
Batch 19/64 loss: 0.3355211019515991
Batch 20/64 loss: 0.3323487639427185
Batch 21/64 loss: 0.33312010765075684
Batch 22/64 loss: 0.3344308137893677
Batch 23/64 loss: 0.3309323787689209
Batch 24/64 loss: 0.3372376561164856
Batch 25/64 loss: 0.337486207485199
Batch 26/64 loss: 0.33284950256347656
Batch 27/64 loss: 0.3324681520462036
Batch 28/64 loss: 0.3349810838699341
Batch 29/64 loss: 0.3395763039588928
Batch 30/64 loss: 0.33499765396118164
Batch 31/64 loss: 0.33239680528640747
Batch 32/64 loss: 0.33583056926727295
Batch 33/64 loss: 0.3359134793281555
Batch 34/64 loss: 0.33873695135116577
Batch 35/64 loss: 0.33562642335891724
Batch 36/64 loss: 0.33432042598724365
Batch 37/64 loss: 0.3344898819923401
Batch 38/64 loss: 0.33846932649612427
Batch 39/64 loss: 0.3361222743988037
Batch 40/64 loss: 0.33345913887023926
Batch 41/64 loss: 0.33875513076782227
Batch 42/64 loss: 0.3344871401786804
Batch 43/64 loss: 0.33412933349609375
Batch 44/64 loss: 0.3299844264984131
Batch 45/64 loss: 0.3311682343482971
Batch 46/64 loss: 0.3305513262748718
Batch 47/64 loss: 0.33242785930633545
Batch 48/64 loss: 0.34514713287353516
Batch 49/64 loss: 0.3395746946334839
Batch 50/64 loss: 0.3314693570137024
Batch 51/64 loss: 0.34145188331604004
Batch 52/64 loss: 0.33744215965270996
Batch 53/64 loss: 0.3342227339744568
Batch 54/64 loss: 0.33695411682128906
Batch 55/64 loss: 0.34306687116622925
Batch 56/64 loss: 0.33362436294555664
Batch 57/64 loss: 0.3343629837036133
Batch 58/64 loss: 0.3322222828865051
Batch 59/64 loss: 0.3349345922470093
Batch 60/64 loss: 0.33275049924850464
Batch 61/64 loss: 0.33478665351867676
Batch 62/64 loss: 0.33598458766937256
Batch 63/64 loss: 0.3325936794281006
Batch 64/64 loss: 0.33217382431030273
Epoch 85  Train loss: 0.3353793415368772  Val loss: 0.34040551906598804
Saving best model, epoch: 85
Epoch 86
-------------------------------
Batch 1/64 loss: 0.3297746181488037
Batch 2/64 loss: 0.339400053024292
Batch 3/64 loss: 0.3292471170425415
Batch 4/64 loss: 0.3288062810897827
Batch 5/64 loss: 0.33204716444015503
Batch 6/64 loss: 0.3327961564064026
Batch 7/64 loss: 0.3320169448852539
Batch 8/64 loss: 0.3298715353012085
Batch 9/64 loss: 0.3383212089538574
Batch 10/64 loss: 0.32942843437194824
Batch 11/64 loss: 0.339413583278656
Batch 12/64 loss: 0.3381463885307312
Batch 13/64 loss: 0.3314833641052246
Batch 14/64 loss: 0.335300087928772
Batch 15/64 loss: 0.33378922939300537
Batch 16/64 loss: 0.3358615040779114
Batch 17/64 loss: 0.33073365688323975
Batch 18/64 loss: 0.33586037158966064
Batch 19/64 loss: 0.33424508571624756
Batch 20/64 loss: 0.3348506689071655
Batch 21/64 loss: 0.33639973402023315
Batch 22/64 loss: 0.330627977848053
Batch 23/64 loss: 0.3319699764251709
Batch 24/64 loss: 0.3324289917945862
Batch 25/64 loss: 0.33296215534210205
Batch 26/64 loss: 0.3340480923652649
Batch 27/64 loss: 0.3330225944519043
Batch 28/64 loss: 0.32972609996795654
Batch 29/64 loss: 0.3367772102355957
Batch 30/64 loss: 0.33830952644348145
Batch 31/64 loss: 0.33730578422546387
Batch 32/64 loss: 0.3415476083755493
Batch 33/64 loss: 0.33417296409606934
Batch 34/64 loss: 0.3293735384941101
Batch 35/64 loss: 0.32944440841674805
Batch 36/64 loss: 0.33336877822875977
Batch 37/64 loss: 0.3389129638671875
Batch 38/64 loss: 0.32965677976608276
Batch 39/64 loss: 0.3332918882369995
Batch 40/64 loss: 0.3396637439727783
Batch 41/64 loss: 0.3338809013366699
Batch 42/64 loss: 0.3345388174057007
Batch 43/64 loss: 0.3388308882713318
Batch 44/64 loss: 0.33525747060775757
Batch 45/64 loss: 0.33331477642059326
Batch 46/64 loss: 0.33745306730270386
Batch 47/64 loss: 0.3314197063446045
Batch 48/64 loss: 0.3336513638496399
Batch 49/64 loss: 0.334875226020813
Batch 50/64 loss: 0.3373304605484009
Batch 51/64 loss: 0.33459198474884033
Batch 52/64 loss: 0.34524697065353394
Batch 53/64 loss: 0.3389403820037842
Batch 54/64 loss: 0.33277660608291626
Batch 55/64 loss: 0.3330204486846924
Batch 56/64 loss: 0.3322232961654663
Batch 57/64 loss: 0.339560866355896
Batch 58/64 loss: 0.3330800533294678
Batch 59/64 loss: 0.33528971672058105
Batch 60/64 loss: 0.33589810132980347
Batch 61/64 loss: 0.3310614824295044
Batch 62/64 loss: 0.3377707600593567
Batch 63/64 loss: 0.3383294939994812
Batch 64/64 loss: 0.34021449089050293
Epoch 86  Train loss: 0.3345554192860921  Val loss: 0.3415200847530693
Epoch 87
-------------------------------
Batch 1/64 loss: 0.3346918821334839
Batch 2/64 loss: 0.33655864000320435
Batch 3/64 loss: 0.3358672857284546
Batch 4/64 loss: 0.3301001787185669
Batch 5/64 loss: 0.3356856107711792
Batch 6/64 loss: 0.33456194400787354
Batch 7/64 loss: 0.333551287651062
Batch 8/64 loss: 0.32729148864746094
Batch 9/64 loss: 0.3351154327392578
Batch 10/64 loss: 0.33318978548049927
Batch 11/64 loss: 0.33654260635375977
Batch 12/64 loss: 0.3327600359916687
Batch 13/64 loss: 0.33309638500213623
Batch 14/64 loss: 0.3373138904571533
Batch 15/64 loss: 0.3312869071960449
Batch 16/64 loss: 0.3337132930755615
Batch 17/64 loss: 0.3277103900909424
Batch 18/64 loss: 0.33022820949554443
Batch 19/64 loss: 0.33367645740509033
Batch 20/64 loss: 0.33303678035736084
Batch 21/64 loss: 0.33455705642700195
Batch 22/64 loss: 0.3300173282623291
Batch 23/64 loss: 0.33385926485061646
Batch 24/64 loss: 0.3332540988922119
Batch 25/64 loss: 0.33556365966796875
Batch 26/64 loss: 0.3303014039993286
Batch 27/64 loss: 0.33431386947631836
Batch 28/64 loss: 0.3359019160270691
Batch 29/64 loss: 0.34071874618530273
Batch 30/64 loss: 0.33412855863571167
Batch 31/64 loss: 0.33495068550109863
Batch 32/64 loss: 0.3342595100402832
Batch 33/64 loss: 0.3339334726333618
Batch 34/64 loss: 0.3272017240524292
Batch 35/64 loss: 0.3356250524520874
Batch 36/64 loss: 0.33849096298217773
Batch 37/64 loss: 0.3319459557533264
Batch 38/64 loss: 0.333132803440094
Batch 39/64 loss: 0.33118224143981934
Batch 40/64 loss: 0.33477312326431274
Batch 41/64 loss: 0.3342822790145874
Batch 42/64 loss: 0.3385190963745117
Batch 43/64 loss: 0.337246298789978
Batch 44/64 loss: 0.3382912874221802
Batch 45/64 loss: 0.33144205808639526
Batch 46/64 loss: 0.33107662200927734
Batch 47/64 loss: 0.3288010358810425
Batch 48/64 loss: 0.33338963985443115
Batch 49/64 loss: 0.3422585129737854
Batch 50/64 loss: 0.3320213556289673
Batch 51/64 loss: 0.33590131998062134
Batch 52/64 loss: 0.331005334854126
Batch 53/64 loss: 0.3319648504257202
Batch 54/64 loss: 0.3359488844871521
Batch 55/64 loss: 0.3318873643875122
Batch 56/64 loss: 0.33546900749206543
Batch 57/64 loss: 0.3329426050186157
Batch 58/64 loss: 0.3369995951652527
Batch 59/64 loss: 0.33379966020584106
Batch 60/64 loss: 0.3334397077560425
Batch 61/64 loss: 0.3410056233406067
Batch 62/64 loss: 0.33827829360961914
Batch 63/64 loss: 0.3324655294418335
Batch 64/64 loss: 0.3337521553039551
Epoch 87  Train loss: 0.33400533339556526  Val loss: 0.3403104744416332
Saving best model, epoch: 87
Epoch 88
-------------------------------
Batch 1/64 loss: 0.33340418338775635
Batch 2/64 loss: 0.33507275581359863
Batch 3/64 loss: 0.33487826585769653
Batch 4/64 loss: 0.3348715305328369
Batch 5/64 loss: 0.3367668390274048
Batch 6/64 loss: 0.33723652362823486
Batch 7/64 loss: 0.33546048402786255
Batch 8/64 loss: 0.3350456953048706
Batch 9/64 loss: 0.33418595790863037
Batch 10/64 loss: 0.3324543237686157
Batch 11/64 loss: 0.33589446544647217
Batch 12/64 loss: 0.33674782514572144
Batch 13/64 loss: 0.3346560001373291
Batch 14/64 loss: 0.3338280916213989
Batch 15/64 loss: 0.33310526609420776
Batch 16/64 loss: 0.32963240146636963
Batch 17/64 loss: 0.3286275267601013
Batch 18/64 loss: 0.3369722366333008
Batch 19/64 loss: 0.33415377140045166
Batch 20/64 loss: 0.3323855996131897
Batch 21/64 loss: 0.32856833934783936
Batch 22/64 loss: 0.3294311761856079
Batch 23/64 loss: 0.33209097385406494
Batch 24/64 loss: 0.3315178155899048
Batch 25/64 loss: 0.32998549938201904
Batch 26/64 loss: 0.3353654146194458
Batch 27/64 loss: 0.33213019371032715
Batch 28/64 loss: 0.3322422504425049
Batch 29/64 loss: 0.3367389440536499
Batch 30/64 loss: 0.32959693670272827
Batch 31/64 loss: 0.33286792039871216
Batch 32/64 loss: 0.33557653427124023
Batch 33/64 loss: 0.3336217999458313
Batch 34/64 loss: 0.33370375633239746
Batch 35/64 loss: 0.32729965448379517
Batch 36/64 loss: 0.33443909883499146
Batch 37/64 loss: 0.34101271629333496
Batch 38/64 loss: 0.33604997396469116
Batch 39/64 loss: 0.33695048093795776
Batch 40/64 loss: 0.33137083053588867
Batch 41/64 loss: 0.3325346112251282
Batch 42/64 loss: 0.3364187479019165
Batch 43/64 loss: 0.33078277111053467
Batch 44/64 loss: 0.3325691223144531
Batch 45/64 loss: 0.33410507440567017
Batch 46/64 loss: 0.3344067335128784
Batch 47/64 loss: 0.33506453037261963
Batch 48/64 loss: 0.33190345764160156
Batch 49/64 loss: 0.33508503437042236
Batch 50/64 loss: 0.3381803631782532
Batch 51/64 loss: 0.3323569893836975
Batch 52/64 loss: 0.3367834687232971
Batch 53/64 loss: 0.32887303829193115
Batch 54/64 loss: 0.3350837230682373
Batch 55/64 loss: 0.33390355110168457
Batch 56/64 loss: 0.3323410749435425
Batch 57/64 loss: 0.33220696449279785
Batch 58/64 loss: 0.33218228816986084
Batch 59/64 loss: 0.33451908826828003
Batch 60/64 loss: 0.33125734329223633
Batch 61/64 loss: 0.3360922336578369
Batch 62/64 loss: 0.3331618905067444
Batch 63/64 loss: 0.3284849524497986
Batch 64/64 loss: 0.33976590633392334
Epoch 88  Train loss: 0.3336323378132839  Val loss: 0.3403101622853492
Saving best model, epoch: 88
Epoch 89
-------------------------------
Batch 1/64 loss: 0.3346019387245178
Batch 2/64 loss: 0.32821017503738403
Batch 3/64 loss: 0.33054399490356445
Batch 4/64 loss: 0.33162856101989746
Batch 5/64 loss: 0.33795785903930664
Batch 6/64 loss: 0.3339555263519287
Batch 7/64 loss: 0.33448219299316406
Batch 8/64 loss: 0.3345843553543091
Batch 9/64 loss: 0.33616793155670166
Batch 10/64 loss: 0.33579742908477783
Batch 11/64 loss: 0.33448004722595215
Batch 12/64 loss: 0.33508777618408203
Batch 13/64 loss: 0.33654022216796875
Batch 14/64 loss: 0.3343178629875183
Batch 15/64 loss: 0.3438979387283325
Batch 16/64 loss: 0.3315661549568176
Batch 17/64 loss: 0.33948779106140137
Batch 18/64 loss: 0.3336986303329468
Batch 19/64 loss: 0.33333438634872437
Batch 20/64 loss: 0.3367964029312134
Batch 21/64 loss: 0.3432663083076477
Batch 22/64 loss: 0.33552825450897217
Batch 23/64 loss: 0.3344038128852844
Batch 24/64 loss: 0.3353235125541687
Batch 25/64 loss: 0.3300495743751526
Batch 26/64 loss: 0.3321331739425659
Batch 27/64 loss: 0.3264455795288086
Batch 28/64 loss: 0.3376035690307617
Batch 29/64 loss: 0.33660757541656494
Batch 30/64 loss: 0.33129215240478516
Batch 31/64 loss: 0.33074015378952026
Batch 32/64 loss: 0.32481634616851807
Batch 33/64 loss: 0.33013105392456055
Batch 34/64 loss: 0.3356562852859497
Batch 35/64 loss: 0.32406413555145264
Batch 36/64 loss: 0.32982492446899414
Batch 37/64 loss: 0.33576250076293945
Batch 38/64 loss: 0.3304504156112671
Batch 39/64 loss: 0.3326464295387268
Batch 40/64 loss: 0.33531975746154785
Batch 41/64 loss: 0.3335365056991577
Batch 42/64 loss: 0.3308199644088745
Batch 43/64 loss: 0.33656734228134155
Batch 44/64 loss: 0.3293074369430542
Batch 45/64 loss: 0.33357226848602295
Batch 46/64 loss: 0.3362499475479126
Batch 47/64 loss: 0.3357807993888855
Batch 48/64 loss: 0.33376073837280273
Batch 49/64 loss: 0.33550047874450684
Batch 50/64 loss: 0.33264589309692383
Batch 51/64 loss: 0.32956522703170776
Batch 52/64 loss: 0.3346547484397888
Batch 53/64 loss: 0.33435285091400146
Batch 54/64 loss: 0.33559560775756836
Batch 55/64 loss: 0.3324403166770935
Batch 56/64 loss: 0.3262844681739807
Batch 57/64 loss: 0.33033251762390137
Batch 58/64 loss: 0.3354923725128174
Batch 59/64 loss: 0.3308422565460205
Batch 60/64 loss: 0.32825493812561035
Batch 61/64 loss: 0.3335458040237427
Batch 62/64 loss: 0.33238834142684937
Batch 63/64 loss: 0.33419477939605713
Batch 64/64 loss: 0.3279229402542114
Epoch 89  Train loss: 0.33334636080498786  Val loss: 0.33997117858572107
Saving best model, epoch: 89
Epoch 90
-------------------------------
Batch 1/64 loss: 0.32785874605178833
Batch 2/64 loss: 0.32726430892944336
Batch 3/64 loss: 0.3267483115196228
Batch 4/64 loss: 0.33150923252105713
Batch 5/64 loss: 0.33159422874450684
Batch 6/64 loss: 0.3305509090423584
Batch 7/64 loss: 0.33249324560165405
Batch 8/64 loss: 0.3269493579864502
Batch 9/64 loss: 0.3337462544441223
Batch 10/64 loss: 0.3379966616630554
Batch 11/64 loss: 0.32963991165161133
Batch 12/64 loss: 0.3340979218482971
Batch 13/64 loss: 0.3285226821899414
Batch 14/64 loss: 0.33129429817199707
Batch 15/64 loss: 0.3290458917617798
Batch 16/64 loss: 0.3344266414642334
Batch 17/64 loss: 0.3332369923591614
Batch 18/64 loss: 0.33422642946243286
Batch 19/64 loss: 0.3345820903778076
Batch 20/64 loss: 0.3384769558906555
Batch 21/64 loss: 0.33231282234191895
Batch 22/64 loss: 0.33101630210876465
Batch 23/64 loss: 0.33244574069976807
Batch 24/64 loss: 0.3367428779602051
Batch 25/64 loss: 0.335620641708374
Batch 26/64 loss: 0.3330845832824707
Batch 27/64 loss: 0.3333038091659546
Batch 28/64 loss: 0.33735233545303345
Batch 29/64 loss: 0.33023571968078613
Batch 30/64 loss: 0.3311171531677246
Batch 31/64 loss: 0.32944971323013306
Batch 32/64 loss: 0.33099788427352905
Batch 33/64 loss: 0.34014445543289185
Batch 34/64 loss: 0.3399171233177185
Batch 35/64 loss: 0.33635032176971436
Batch 36/64 loss: 0.3280794620513916
Batch 37/64 loss: 0.33435094356536865
Batch 38/64 loss: 0.33187198638916016
Batch 39/64 loss: 0.3297617435455322
Batch 40/64 loss: 0.3386317491531372
Batch 41/64 loss: 0.3362582325935364
Batch 42/64 loss: 0.3346198797225952
Batch 43/64 loss: 0.33483707904815674
Batch 44/64 loss: 0.3323765993118286
Batch 45/64 loss: 0.336448073387146
Batch 46/64 loss: 0.3372066617012024
Batch 47/64 loss: 0.3308413624763489
Batch 48/64 loss: 0.3301708698272705
Batch 49/64 loss: 0.3333786129951477
Batch 50/64 loss: 0.33668506145477295
Batch 51/64 loss: 0.3290536403656006
Batch 52/64 loss: 0.3297090530395508
Batch 53/64 loss: 0.33236587047576904
Batch 54/64 loss: 0.3331155776977539
Batch 55/64 loss: 0.33602583408355713
Batch 56/64 loss: 0.33252084255218506
Batch 57/64 loss: 0.3356276750564575
Batch 58/64 loss: 0.33341240882873535
Batch 59/64 loss: 0.33174097537994385
Batch 60/64 loss: 0.33656787872314453
Batch 61/64 loss: 0.33500635623931885
Batch 62/64 loss: 0.3301351070404053
Batch 63/64 loss: 0.3337230086326599
Batch 64/64 loss: 0.3318048119544983
Epoch 90  Train loss: 0.33298397975809435  Val loss: 0.3411868233041665
Epoch 91
-------------------------------
Batch 1/64 loss: 0.3244110941886902
Batch 2/64 loss: 0.3338150978088379
Batch 3/64 loss: 0.3317532539367676
Batch 4/64 loss: 0.3303982615470886
Batch 5/64 loss: 0.3355649709701538
Batch 6/64 loss: 0.3288477063179016
Batch 7/64 loss: 0.3347651958465576
Batch 8/64 loss: 0.3301699161529541
Batch 9/64 loss: 0.33500999212265015
Batch 10/64 loss: 0.3312916159629822
Batch 11/64 loss: 0.32998961210250854
Batch 12/64 loss: 0.3362385034561157
Batch 13/64 loss: 0.33263200521469116
Batch 14/64 loss: 0.33160102367401123
Batch 15/64 loss: 0.33168864250183105
Batch 16/64 loss: 0.33016955852508545
Batch 17/64 loss: 0.33287036418914795
Batch 18/64 loss: 0.3335321545600891
Batch 19/64 loss: 0.3365517854690552
Batch 20/64 loss: 0.3298112750053406
Batch 21/64 loss: 0.3251030445098877
Batch 22/64 loss: 0.33287763595581055
Batch 23/64 loss: 0.3321155905723572
Batch 24/64 loss: 0.337745726108551
Batch 25/64 loss: 0.32531094551086426
Batch 26/64 loss: 0.32978320121765137
Batch 27/64 loss: 0.3328820466995239
Batch 28/64 loss: 0.33526813983917236
Batch 29/64 loss: 0.3325237035751343
Batch 30/64 loss: 0.3301982879638672
Batch 31/64 loss: 0.3286358118057251
Batch 32/64 loss: 0.33356738090515137
Batch 33/64 loss: 0.3350503444671631
Batch 34/64 loss: 0.3369928002357483
Batch 35/64 loss: 0.34070539474487305
Batch 36/64 loss: 0.333223819732666
Batch 37/64 loss: 0.327117383480072
Batch 38/64 loss: 0.3351036310195923
Batch 39/64 loss: 0.33377307653427124
Batch 40/64 loss: 0.32592642307281494
Batch 41/64 loss: 0.3358389735221863
Batch 42/64 loss: 0.3289189338684082
Batch 43/64 loss: 0.33402860164642334
Batch 44/64 loss: 0.3297209143638611
Batch 45/64 loss: 0.33331298828125
Batch 46/64 loss: 0.3282756805419922
Batch 47/64 loss: 0.338703989982605
Batch 48/64 loss: 0.3375951051712036
Batch 49/64 loss: 0.3338003158569336
Batch 50/64 loss: 0.3319110870361328
Batch 51/64 loss: 0.3319035768508911
Batch 52/64 loss: 0.3315408229827881
Batch 53/64 loss: 0.3356373906135559
Batch 54/64 loss: 0.34430181980133057
Batch 55/64 loss: 0.3331385850906372
Batch 56/64 loss: 0.33107221126556396
Batch 57/64 loss: 0.3319270610809326
Batch 58/64 loss: 0.3268550634384155
Batch 59/64 loss: 0.33046483993530273
Batch 60/64 loss: 0.3272387981414795
Batch 61/64 loss: 0.33333319425582886
Batch 62/64 loss: 0.3408925533294678
Batch 63/64 loss: 0.3354964256286621
Batch 64/64 loss: 0.32994920015335083
Epoch 91  Train loss: 0.33252372157339954  Val loss: 0.3397657920404808
Saving best model, epoch: 91
Epoch 92
-------------------------------
Batch 1/64 loss: 0.33457791805267334
Batch 2/64 loss: 0.3394545316696167
Batch 3/64 loss: 0.33202672004699707
Batch 4/64 loss: 0.33034372329711914
Batch 5/64 loss: 0.3316277861595154
Batch 6/64 loss: 0.33568429946899414
Batch 7/64 loss: 0.33965039253234863
Batch 8/64 loss: 0.3361395001411438
Batch 9/64 loss: 0.3304940462112427
Batch 10/64 loss: 0.3354787826538086
Batch 11/64 loss: 0.3264615535736084
Batch 12/64 loss: 0.33142268657684326
Batch 13/64 loss: 0.33136147260665894
Batch 14/64 loss: 0.3372461795806885
Batch 15/64 loss: 0.3322422504425049
Batch 16/64 loss: 0.33494317531585693
Batch 17/64 loss: 0.32963621616363525
Batch 18/64 loss: 0.33359360694885254
Batch 19/64 loss: 0.3275638222694397
Batch 20/64 loss: 0.3341083526611328
Batch 21/64 loss: 0.3283873200416565
Batch 22/64 loss: 0.330869197845459
Batch 23/64 loss: 0.3310662508010864
Batch 24/64 loss: 0.3340206742286682
Batch 25/64 loss: 0.33602088689804077
Batch 26/64 loss: 0.3376867175102234
Batch 27/64 loss: 0.3294757008552551
Batch 28/64 loss: 0.33634209632873535
Batch 29/64 loss: 0.32801419496536255
Batch 30/64 loss: 0.3344278335571289
Batch 31/64 loss: 0.33695554733276367
Batch 32/64 loss: 0.32898104190826416
Batch 33/64 loss: 0.3283616304397583
Batch 34/64 loss: 0.32908886671066284
Batch 35/64 loss: 0.33292675018310547
Batch 36/64 loss: 0.33339911699295044
Batch 37/64 loss: 0.330944299697876
Batch 38/64 loss: 0.3300647735595703
Batch 39/64 loss: 0.33334606885910034
Batch 40/64 loss: 0.3310396671295166
Batch 41/64 loss: 0.32828330993652344
Batch 42/64 loss: 0.33484482765197754
Batch 43/64 loss: 0.3316439390182495
Batch 44/64 loss: 0.32950305938720703
Batch 45/64 loss: 0.3327574133872986
Batch 46/64 loss: 0.33196496963500977
Batch 47/64 loss: 0.3347194790840149
Batch 48/64 loss: 0.3313417434692383
Batch 49/64 loss: 0.3289934992790222
Batch 50/64 loss: 0.33684420585632324
Batch 51/64 loss: 0.3333621025085449
Batch 52/64 loss: 0.3308272361755371
Batch 53/64 loss: 0.33409035205841064
Batch 54/64 loss: 0.33058077096939087
Batch 55/64 loss: 0.328738808631897
Batch 56/64 loss: 0.3365582823753357
Batch 57/64 loss: 0.33606910705566406
Batch 58/64 loss: 0.33230286836624146
Batch 59/64 loss: 0.33196717500686646
Batch 60/64 loss: 0.33377373218536377
Batch 61/64 loss: 0.3319503664970398
Batch 62/64 loss: 0.33071964979171753
Batch 63/64 loss: 0.3293679356575012
Batch 64/64 loss: 0.33426177501678467
Epoch 92  Train loss: 0.33250787164650714  Val loss: 0.33935375311939986
Saving best model, epoch: 92
Epoch 93
-------------------------------
Batch 1/64 loss: 0.32748234272003174
Batch 2/64 loss: 0.33217471837997437
Batch 3/64 loss: 0.3303886651992798
Batch 4/64 loss: 0.33215248584747314
Batch 5/64 loss: 0.3262817859649658
Batch 6/64 loss: 0.33207762241363525
Batch 7/64 loss: 0.3285300135612488
Batch 8/64 loss: 0.33211421966552734
Batch 9/64 loss: 0.32698357105255127
Batch 10/64 loss: 0.3285660743713379
Batch 11/64 loss: 0.33111995458602905
Batch 12/64 loss: 0.33171844482421875
Batch 13/64 loss: 0.3313133716583252
Batch 14/64 loss: 0.33308929204940796
Batch 15/64 loss: 0.3336734175682068
Batch 16/64 loss: 0.32844483852386475
Batch 17/64 loss: 0.3337675929069519
Batch 18/64 loss: 0.3358806371688843
Batch 19/64 loss: 0.3285350799560547
Batch 20/64 loss: 0.3304656744003296
Batch 21/64 loss: 0.32712578773498535
Batch 22/64 loss: 0.3310050368309021
Batch 23/64 loss: 0.33400702476501465
Batch 24/64 loss: 0.32841384410858154
Batch 25/64 loss: 0.32864856719970703
Batch 26/64 loss: 0.3307523727416992
Batch 27/64 loss: 0.33265841007232666
Batch 28/64 loss: 0.3265568017959595
Batch 29/64 loss: 0.3273388743400574
Batch 30/64 loss: 0.32782334089279175
Batch 31/64 loss: 0.32924985885620117
Batch 32/64 loss: 0.3369455337524414
Batch 33/64 loss: 0.3347468376159668
Batch 34/64 loss: 0.33774685859680176
Batch 35/64 loss: 0.3380763530731201
Batch 36/64 loss: 0.32730889320373535
Batch 37/64 loss: 0.33858591318130493
Batch 38/64 loss: 0.3314516544342041
Batch 39/64 loss: 0.3333854079246521
Batch 40/64 loss: 0.3280341625213623
Batch 41/64 loss: 0.3341447710990906
Batch 42/64 loss: 0.33122289180755615
Batch 43/64 loss: 0.33172112703323364
Batch 44/64 loss: 0.3272587060928345
Batch 45/64 loss: 0.3309513330459595
Batch 46/64 loss: 0.3363165855407715
Batch 47/64 loss: 0.33484411239624023
Batch 48/64 loss: 0.33569836616516113
Batch 49/64 loss: 0.33686888217926025
Batch 50/64 loss: 0.3337143659591675
Batch 51/64 loss: 0.33565688133239746
Batch 52/64 loss: 0.3290818929672241
Batch 53/64 loss: 0.3284642696380615
Batch 54/64 loss: 0.3293355703353882
Batch 55/64 loss: 0.3310176134109497
Batch 56/64 loss: 0.3297961950302124
Batch 57/64 loss: 0.32850247621536255
Batch 58/64 loss: 0.3359385132789612
Batch 59/64 loss: 0.3330245614051819
Batch 60/64 loss: 0.3301457166671753
Batch 61/64 loss: 0.32628709077835083
Batch 62/64 loss: 0.3339604139328003
Batch 63/64 loss: 0.3277105689048767
Batch 64/64 loss: 0.3315376043319702
Epoch 93  Train loss: 0.33137156776353427  Val loss: 0.3377550676516241
Saving best model, epoch: 93
Epoch 94
-------------------------------
Batch 1/64 loss: 0.32084357738494873
Batch 2/64 loss: 0.3333621025085449
Batch 3/64 loss: 0.3288270831108093
Batch 4/64 loss: 0.33038395643234253
Batch 5/64 loss: 0.34050285816192627
Batch 6/64 loss: 0.33375537395477295
Batch 7/64 loss: 0.33888518810272217
Batch 8/64 loss: 0.3311339020729065
Batch 9/64 loss: 0.3262898921966553
Batch 10/64 loss: 0.337713360786438
Batch 11/64 loss: 0.3336735963821411
Batch 12/64 loss: 0.3278700113296509
Batch 13/64 loss: 0.3299599885940552
Batch 14/64 loss: 0.32993626594543457
Batch 15/64 loss: 0.3278377056121826
Batch 16/64 loss: 0.32867753505706787
Batch 17/64 loss: 0.33312827348709106
Batch 18/64 loss: 0.32856178283691406
Batch 19/64 loss: 0.3318166136741638
Batch 20/64 loss: 0.33190298080444336
Batch 21/64 loss: 0.3255265951156616
Batch 22/64 loss: 0.3270184397697449
Batch 23/64 loss: 0.3313736915588379
Batch 24/64 loss: 0.3289903402328491
Batch 25/64 loss: 0.32983100414276123
Batch 26/64 loss: 0.3300285339355469
Batch 27/64 loss: 0.332769513130188
Batch 28/64 loss: 0.3249169588088989
Batch 29/64 loss: 0.3315849304199219
Batch 30/64 loss: 0.3340388536453247
Batch 31/64 loss: 0.32879287004470825
Batch 32/64 loss: 0.3320385217666626
Batch 33/64 loss: 0.3229498267173767
Batch 34/64 loss: 0.334433913230896
Batch 35/64 loss: 0.33564549684524536
Batch 36/64 loss: 0.3276139497756958
Batch 37/64 loss: 0.3288741111755371
Batch 38/64 loss: 0.3305954933166504
Batch 39/64 loss: 0.3307301998138428
Batch 40/64 loss: 0.32998085021972656
Batch 41/64 loss: 0.33412134647369385
Batch 42/64 loss: 0.3289989233016968
Batch 43/64 loss: 0.32853609323501587
Batch 44/64 loss: 0.3307703733444214
Batch 45/64 loss: 0.3348068594932556
Batch 46/64 loss: 0.33323919773101807
Batch 47/64 loss: 0.3270161747932434
Batch 48/64 loss: 0.3303135633468628
Batch 49/64 loss: 0.33125364780426025
Batch 50/64 loss: 0.3272576332092285
Batch 51/64 loss: 0.32859039306640625
Batch 52/64 loss: 0.3320573568344116
Batch 53/64 loss: 0.3309338092803955
Batch 54/64 loss: 0.3331591486930847
Batch 55/64 loss: 0.328105092048645
Batch 56/64 loss: 0.3318936228752136
Batch 57/64 loss: 0.3286944627761841
Batch 58/64 loss: 0.3288000822067261
Batch 59/64 loss: 0.3357078433036804
Batch 60/64 loss: 0.33253413438796997
Batch 61/64 loss: 0.3276023864746094
Batch 62/64 loss: 0.32811129093170166
Batch 63/64 loss: 0.32801496982574463
Batch 64/64 loss: 0.3285025358200073
Epoch 94  Train loss: 0.3305049639122159  Val loss: 0.33732054569467235
Saving best model, epoch: 94
Epoch 95
-------------------------------
Batch 1/64 loss: 0.3348042964935303
Batch 2/64 loss: 0.3281242847442627
Batch 3/64 loss: 0.3292062282562256
Batch 4/64 loss: 0.33430004119873047
Batch 5/64 loss: 0.3289461135864258
Batch 6/64 loss: 0.3288118839263916
Batch 7/64 loss: 0.33413976430892944
Batch 8/64 loss: 0.33389711380004883
Batch 9/64 loss: 0.3274962306022644
Batch 10/64 loss: 0.3307526111602783
Batch 11/64 loss: 0.3317960500717163
Batch 12/64 loss: 0.325264036655426
Batch 13/64 loss: 0.33044499158859253
Batch 14/64 loss: 0.3301771879196167
Batch 15/64 loss: 0.32547175884246826
Batch 16/64 loss: 0.32741981744766235
Batch 17/64 loss: 0.34181225299835205
Batch 18/64 loss: 0.33528512716293335
Batch 19/64 loss: 0.32617032527923584
Batch 20/64 loss: 0.33584582805633545
Batch 21/64 loss: 0.3273831605911255
Batch 22/64 loss: 0.32970136404037476
Batch 23/64 loss: 0.3333989381790161
Batch 24/64 loss: 0.3297393321990967
Batch 25/64 loss: 0.3308815360069275
Batch 26/64 loss: 0.3286374807357788
Batch 27/64 loss: 0.34104788303375244
Batch 28/64 loss: 0.3281896114349365
Batch 29/64 loss: 0.3283799886703491
Batch 30/64 loss: 0.3264462947845459
Batch 31/64 loss: 0.3336188793182373
Batch 32/64 loss: 0.32700520753860474
Batch 33/64 loss: 0.33016437292099
Batch 34/64 loss: 0.3303757905960083
Batch 35/64 loss: 0.33220648765563965
Batch 36/64 loss: 0.3275226354598999
Batch 37/64 loss: 0.32545483112335205
Batch 38/64 loss: 0.32756978273391724
Batch 39/64 loss: 0.34096211194992065
Batch 40/64 loss: 0.3228680491447449
Batch 41/64 loss: 0.33176159858703613
Batch 42/64 loss: 0.32993102073669434
Batch 43/64 loss: 0.32761144638061523
Batch 44/64 loss: 0.332694947719574
Batch 45/64 loss: 0.3304590582847595
Batch 46/64 loss: 0.3317793607711792
Batch 47/64 loss: 0.32578200101852417
Batch 48/64 loss: 0.3295446038246155
Batch 49/64 loss: 0.3235803246498108
Batch 50/64 loss: 0.3313465118408203
Batch 51/64 loss: 0.32684916257858276
Batch 52/64 loss: 0.32969343662261963
Batch 53/64 loss: 0.32806622982025146
Batch 54/64 loss: 0.33090341091156006
Batch 55/64 loss: 0.33063507080078125
Batch 56/64 loss: 0.32864320278167725
Batch 57/64 loss: 0.32969415187835693
Batch 58/64 loss: 0.3255045413970947
Batch 59/64 loss: 0.3406095504760742
Batch 60/64 loss: 0.3302720785140991
Batch 61/64 loss: 0.33282697200775146
Batch 62/64 loss: 0.3332878351211548
Batch 63/64 loss: 0.32747507095336914
Batch 64/64 loss: 0.33010315895080566
Epoch 95  Train loss: 0.3303254688487333  Val loss: 0.3370405175431897
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: 0.32639259099960327
Batch 2/64 loss: 0.3322219252586365
Batch 3/64 loss: 0.32912254333496094
Batch 4/64 loss: 0.3297744393348694
Batch 5/64 loss: 0.3265475034713745
Batch 6/64 loss: 0.3283437490463257
Batch 7/64 loss: 0.33293163776397705
Batch 8/64 loss: 0.3367711305618286
Batch 9/64 loss: 0.33003175258636475
Batch 10/64 loss: 0.33076584339141846
Batch 11/64 loss: 0.3290914297103882
Batch 12/64 loss: 0.32893872261047363
Batch 13/64 loss: 0.33043110370635986
Batch 14/64 loss: 0.3266255855560303
Batch 15/64 loss: 0.330058217048645
Batch 16/64 loss: 0.32895898818969727
Batch 17/64 loss: 0.3354761004447937
Batch 18/64 loss: 0.32946598529815674
Batch 19/64 loss: 0.333845853805542
Batch 20/64 loss: 0.3313934803009033
Batch 21/64 loss: 0.33410000801086426
Batch 22/64 loss: 0.32826507091522217
Batch 23/64 loss: 0.32873499393463135
Batch 24/64 loss: 0.32844245433807373
Batch 25/64 loss: 0.33397185802459717
Batch 26/64 loss: 0.3287067413330078
Batch 27/64 loss: 0.3285713195800781
Batch 28/64 loss: 0.33313506841659546
Batch 29/64 loss: 0.32636046409606934
Batch 30/64 loss: 0.32916736602783203
Batch 31/64 loss: 0.32903730869293213
Batch 32/64 loss: 0.32599568367004395
Batch 33/64 loss: 0.3328569531440735
Batch 34/64 loss: 0.32611680030822754
Batch 35/64 loss: 0.3256027102470398
Batch 36/64 loss: 0.3305099606513977
Batch 37/64 loss: 0.33291923999786377
Batch 38/64 loss: 0.3307899236679077
Batch 39/64 loss: 0.33300137519836426
Batch 40/64 loss: 0.33142954111099243
Batch 41/64 loss: 0.3273550271987915
Batch 42/64 loss: 0.33568495512008667
Batch 43/64 loss: 0.3278566002845764
Batch 44/64 loss: 0.3290144205093384
Batch 45/64 loss: 0.3319084644317627
Batch 46/64 loss: 0.3294414281845093
Batch 47/64 loss: 0.3320753574371338
Batch 48/64 loss: 0.3327418565750122
Batch 49/64 loss: 0.32599419355392456
Batch 50/64 loss: 0.3297639489173889
Batch 51/64 loss: 0.33222830295562744
Batch 52/64 loss: 0.3312404155731201
Batch 53/64 loss: 0.33020782470703125
Batch 54/64 loss: 0.3282436728477478
Batch 55/64 loss: 0.330985426902771
Batch 56/64 loss: 0.3246716260910034
Batch 57/64 loss: 0.327009379863739
Batch 58/64 loss: 0.32842057943344116
Batch 59/64 loss: 0.33531761169433594
Batch 60/64 loss: 0.336628794670105
Batch 61/64 loss: 0.3286318778991699
Batch 62/64 loss: 0.33113694190979004
Batch 63/64 loss: 0.3334975242614746
Batch 64/64 loss: 0.32799094915390015
Epoch 96  Train loss: 0.33021102535958385  Val loss: 0.33803897788844156
Epoch 97
-------------------------------
Batch 1/64 loss: 0.3297077417373657
Batch 2/64 loss: 0.32747316360473633
Batch 3/64 loss: 0.33472251892089844
Batch 4/64 loss: 0.3360578417778015
Batch 5/64 loss: 0.329622745513916
Batch 6/64 loss: 0.3246196508407593
Batch 7/64 loss: 0.33093637228012085
Batch 8/64 loss: 0.3279660940170288
Batch 9/64 loss: 0.32783985137939453
Batch 10/64 loss: 0.3296806812286377
Batch 11/64 loss: 0.32584071159362793
Batch 12/64 loss: 0.32744526863098145
Batch 13/64 loss: 0.3249242305755615
Batch 14/64 loss: 0.32625341415405273
Batch 15/64 loss: 0.33240818977355957
Batch 16/64 loss: 0.3299586772918701
Batch 17/64 loss: 0.33236587047576904
Batch 18/64 loss: 0.3247029781341553
Batch 19/64 loss: 0.3282468318939209
Batch 20/64 loss: 0.3331117630004883
Batch 21/64 loss: 0.32847219705581665
Batch 22/64 loss: 0.330061674118042
Batch 23/64 loss: 0.33405637741088867
Batch 24/64 loss: 0.3271263837814331
Batch 25/64 loss: 0.3286975622177124
Batch 26/64 loss: 0.32829809188842773
Batch 27/64 loss: 0.32965147495269775
Batch 28/64 loss: 0.3304123282432556
Batch 29/64 loss: 0.32854771614074707
Batch 30/64 loss: 0.3247174024581909
Batch 31/64 loss: 0.33402425050735474
Batch 32/64 loss: 0.3285320997238159
Batch 33/64 loss: 0.32501888275146484
Batch 34/64 loss: 0.3350405693054199
Batch 35/64 loss: 0.3307323455810547
Batch 36/64 loss: 0.332144558429718
Batch 37/64 loss: 0.33433258533477783
Batch 38/64 loss: 0.32749831676483154
Batch 39/64 loss: 0.3325168490409851
Batch 40/64 loss: 0.3296705484390259
Batch 41/64 loss: 0.3297555446624756
Batch 42/64 loss: 0.33430469036102295
Batch 43/64 loss: 0.3357805609703064
Batch 44/64 loss: 0.334328293800354
Batch 45/64 loss: 0.3297830820083618
Batch 46/64 loss: 0.3308781385421753
Batch 47/64 loss: 0.3345588445663452
Batch 48/64 loss: 0.3310672640800476
Batch 49/64 loss: 0.3294692039489746
Batch 50/64 loss: 0.329311728477478
Batch 51/64 loss: 0.3287990093231201
Batch 52/64 loss: 0.33307337760925293
Batch 53/64 loss: 0.3315369486808777
Batch 54/64 loss: 0.32573211193084717
Batch 55/64 loss: 0.33171749114990234
Batch 56/64 loss: 0.327414870262146
Batch 57/64 loss: 0.3213422894477844
Batch 58/64 loss: 0.32686078548431396
Batch 59/64 loss: 0.3336554765701294
Batch 60/64 loss: 0.3281151056289673
Batch 61/64 loss: 0.3304292559623718
Batch 62/64 loss: 0.3299723267555237
Batch 63/64 loss: 0.3244067430496216
Batch 64/64 loss: 0.33215099573135376
Epoch 97  Train loss: 0.3298014619771172  Val loss: 0.335986126329481
Saving best model, epoch: 97
Epoch 98
-------------------------------
Batch 1/64 loss: 0.3345215916633606
Batch 2/64 loss: 0.32878005504608154
Batch 3/64 loss: 0.33776432275772095
Batch 4/64 loss: 0.32654064893722534
Batch 5/64 loss: 0.32536447048187256
Batch 6/64 loss: 0.3358396887779236
Batch 7/64 loss: 0.33324480056762695
Batch 8/64 loss: 0.3323867917060852
Batch 9/64 loss: 0.3295467495918274
Batch 10/64 loss: 0.3280363082885742
Batch 11/64 loss: 0.3334251642227173
Batch 12/64 loss: 0.3301118016242981
Batch 13/64 loss: 0.3240983486175537
Batch 14/64 loss: 0.3285309076309204
Batch 15/64 loss: 0.33027058839797974
Batch 16/64 loss: 0.3322591185569763
Batch 17/64 loss: 0.325167179107666
Batch 18/64 loss: 0.3311929702758789
Batch 19/64 loss: 0.326382040977478
Batch 20/64 loss: 0.32865744829177856
Batch 21/64 loss: 0.3358781337738037
Batch 22/64 loss: 0.3215986490249634
Batch 23/64 loss: 0.3267924189567566
Batch 24/64 loss: 0.32559525966644287
Batch 25/64 loss: 0.330249547958374
Batch 26/64 loss: 0.3252272605895996
Batch 27/64 loss: 0.3348415493965149
Batch 28/64 loss: 0.3267657160758972
Batch 29/64 loss: 0.3313325047492981
Batch 30/64 loss: 0.3280729651451111
Batch 31/64 loss: 0.3249988555908203
Batch 32/64 loss: 0.3281437158584595
Batch 33/64 loss: 0.32788074016571045
Batch 34/64 loss: 0.32739973068237305
Batch 35/64 loss: 0.33419179916381836
Batch 36/64 loss: 0.32687538862228394
Batch 37/64 loss: 0.32642996311187744
Batch 38/64 loss: 0.3316704034805298
Batch 39/64 loss: 0.32798731327056885
Batch 40/64 loss: 0.3291536569595337
Batch 41/64 loss: 0.32750487327575684
Batch 42/64 loss: 0.32716965675354004
Batch 43/64 loss: 0.32998520135879517
Batch 44/64 loss: 0.33093100786209106
Batch 45/64 loss: 0.32404226064682007
Batch 46/64 loss: 0.3270660638809204
Batch 47/64 loss: 0.32555603981018066
Batch 48/64 loss: 0.33247995376586914
Batch 49/64 loss: 0.3298013210296631
Batch 50/64 loss: 0.3236756920814514
Batch 51/64 loss: 0.32442569732666016
Batch 52/64 loss: 0.32820773124694824
Batch 53/64 loss: 0.3254782557487488
Batch 54/64 loss: 0.32960808277130127
Batch 55/64 loss: 0.32869160175323486
Batch 56/64 loss: 0.32685112953186035
Batch 57/64 loss: 0.33142900466918945
Batch 58/64 loss: 0.33391886949539185
Batch 59/64 loss: 0.3326847553253174
Batch 60/64 loss: 0.33226776123046875
Batch 61/64 loss: 0.3271440267562866
Batch 62/64 loss: 0.33314675092697144
Batch 63/64 loss: 0.33150482177734375
Batch 64/64 loss: 0.3262559175491333
Epoch 98  Train loss: 0.3291210833717795  Val loss: 0.3364953785827479
Epoch 99
-------------------------------
Batch 1/64 loss: 0.32789361476898193
Batch 2/64 loss: 0.3254694938659668
Batch 3/64 loss: 0.3284977674484253
Batch 4/64 loss: 0.33104658126831055
Batch 5/64 loss: 0.3239990472793579
Batch 6/64 loss: 0.3240671753883362
Batch 7/64 loss: 0.32984620332717896
Batch 8/64 loss: 0.3278106451034546
Batch 9/64 loss: 0.326834499835968
Batch 10/64 loss: 0.3273639678955078
Batch 11/64 loss: 0.3278926610946655
Batch 12/64 loss: 0.32906830310821533
Batch 13/64 loss: 0.3297957181930542
Batch 14/64 loss: 0.3276657462120056
Batch 15/64 loss: 0.32756561040878296
Batch 16/64 loss: 0.32790493965148926
Batch 17/64 loss: 0.32002103328704834
Batch 18/64 loss: 0.3308382034301758
Batch 19/64 loss: 0.32927262783050537
Batch 20/64 loss: 0.3296809196472168
Batch 21/64 loss: 0.3258157968521118
Batch 22/64 loss: 0.321216344833374
Batch 23/64 loss: 0.32970982789993286
Batch 24/64 loss: 0.33050936460494995
Batch 25/64 loss: 0.3291572332382202
Batch 26/64 loss: 0.3301260471343994
Batch 27/64 loss: 0.32552123069763184
Batch 28/64 loss: 0.3283631205558777
Batch 29/64 loss: 0.3285994529724121
Batch 30/64 loss: 0.3233409523963928
Batch 31/64 loss: 0.3266141414642334
Batch 32/64 loss: 0.32623231410980225
Batch 33/64 loss: 0.33190786838531494
Batch 34/64 loss: 0.3360210657119751
Batch 35/64 loss: 0.32419353723526
Batch 36/64 loss: 0.3305622339248657
Batch 37/64 loss: 0.3327707052230835
Batch 38/64 loss: 0.3290630578994751
Batch 39/64 loss: 0.32965660095214844
Batch 40/64 loss: 0.32879507541656494
Batch 41/64 loss: 0.32917189598083496
Batch 42/64 loss: 0.3339860439300537
Batch 43/64 loss: 0.33355677127838135
Batch 44/64 loss: 0.3331577181816101
Batch 45/64 loss: 0.33764857053756714
Batch 46/64 loss: 0.33129191398620605
Batch 47/64 loss: 0.32261884212493896
Batch 48/64 loss: 0.3241112232208252
Batch 49/64 loss: 0.328738808631897
Batch 50/64 loss: 0.32914698123931885
Batch 51/64 loss: 0.32857024669647217
Batch 52/64 loss: 0.32620757818222046
Batch 53/64 loss: 0.33055341243743896
Batch 54/64 loss: 0.329540491104126
Batch 55/64 loss: 0.3293043375015259
Batch 56/64 loss: 0.3288528323173523
Batch 57/64 loss: 0.3370646834373474
Batch 58/64 loss: 0.32799118757247925
Batch 59/64 loss: 0.3307398557662964
Batch 60/64 loss: 0.3330802917480469
Batch 61/64 loss: 0.3345644474029541
Batch 62/64 loss: 0.3325704336166382
Batch 63/64 loss: 0.3363717794418335
Batch 64/64 loss: 0.3237059712409973
Epoch 99  Train loss: 0.32897773420109466  Val loss: 0.33655509772579284
Epoch 100
-------------------------------
Batch 1/64 loss: 0.3256456255912781
Batch 2/64 loss: 0.33144915103912354
Batch 3/64 loss: 0.3243436813354492
Batch 4/64 loss: 0.32825154066085815
Batch 5/64 loss: 0.32475316524505615
Batch 6/64 loss: 0.3311852216720581
Batch 7/64 loss: 0.32286930084228516
Batch 8/64 loss: 0.3343356251716614
Batch 9/64 loss: 0.3303343653678894
Batch 10/64 loss: 0.3261312246322632
Batch 11/64 loss: 0.33013153076171875
Batch 12/64 loss: 0.3286060094833374
Batch 13/64 loss: 0.3285531997680664
Batch 14/64 loss: 0.3293389081954956
Batch 15/64 loss: 0.32601600885391235
Batch 16/64 loss: 0.32798588275909424
Batch 17/64 loss: 0.3275827169418335
Batch 18/64 loss: 0.3294943571090698
Batch 19/64 loss: 0.3277400732040405
Batch 20/64 loss: 0.32905495166778564
Batch 21/64 loss: 0.328768253326416
Batch 22/64 loss: 0.3226127624511719
Batch 23/64 loss: 0.3322288990020752
Batch 24/64 loss: 0.3220359683036804
Batch 25/64 loss: 0.33335793018341064
Batch 26/64 loss: 0.3276972770690918
Batch 27/64 loss: 0.33423441648483276
Batch 28/64 loss: 0.33096301555633545
Batch 29/64 loss: 0.32996535301208496
Batch 30/64 loss: 0.32852643728256226
Batch 31/64 loss: 0.3299170136451721
Batch 32/64 loss: 0.3318983316421509
Batch 33/64 loss: 0.32840919494628906
Batch 34/64 loss: 0.3278357982635498
Batch 35/64 loss: 0.33128106594085693
Batch 36/64 loss: 0.3273468017578125
Batch 37/64 loss: 0.3279460668563843
Batch 38/64 loss: 0.3255348205566406
Batch 39/64 loss: 0.33142316341400146
Batch 40/64 loss: 0.32371997833251953
Batch 41/64 loss: 0.3364163041114807
Batch 42/64 loss: 0.32649552822113037
Batch 43/64 loss: 0.3245270252227783
Batch 44/64 loss: 0.3243233561515808
Batch 45/64 loss: 0.33263909816741943
Batch 46/64 loss: 0.33148694038391113
Batch 47/64 loss: 0.32807719707489014
Batch 48/64 loss: 0.3312690258026123
Batch 49/64 loss: 0.32609158754348755
Batch 50/64 loss: 0.32087862491607666
Batch 51/64 loss: 0.3269180655479431
Batch 52/64 loss: 0.3309740424156189
Batch 53/64 loss: 0.3253653049468994
Batch 54/64 loss: 0.3251155614852905
Batch 55/64 loss: 0.3346858024597168
Batch 56/64 loss: 0.3303261995315552
Batch 57/64 loss: 0.3295915126800537
Batch 58/64 loss: 0.32612913846969604
Batch 59/64 loss: 0.329614520072937
Batch 60/64 loss: 0.3236325979232788
Batch 61/64 loss: 0.3279397487640381
Batch 62/64 loss: 0.32948267459869385
Batch 63/64 loss: 0.32844293117523193
Batch 64/64 loss: 0.328216552734375
Epoch 100  Train loss: 0.32840925945955163  Val loss: 0.3349372887939112
Saving best model, epoch: 100
Epoch 101
-------------------------------
Batch 1/64 loss: 0.32992076873779297
Batch 2/64 loss: 0.3286029100418091
Batch 3/64 loss: 0.32402604818344116
Batch 4/64 loss: 0.32547062635421753
Batch 5/64 loss: 0.3261873722076416
Batch 6/64 loss: 0.32420551776885986
Batch 7/64 loss: 0.32916098833084106
Batch 8/64 loss: 0.32681596279144287
Batch 9/64 loss: 0.33018970489501953
Batch 10/64 loss: 0.3252660036087036
Batch 11/64 loss: 0.3226717710494995
Batch 12/64 loss: 0.32820045948028564
Batch 13/64 loss: 0.32848072052001953
Batch 14/64 loss: 0.3241807222366333
Batch 15/64 loss: 0.3269857168197632
Batch 16/64 loss: 0.3309444189071655
Batch 17/64 loss: 0.331585168838501
Batch 18/64 loss: 0.32897764444351196
Batch 19/64 loss: 0.32501494884490967
Batch 20/64 loss: 0.3321695327758789
Batch 21/64 loss: 0.33236759901046753
Batch 22/64 loss: 0.3295915126800537
Batch 23/64 loss: 0.328826904296875
Batch 24/64 loss: 0.3236998915672302
Batch 25/64 loss: 0.3254774212837219
Batch 26/64 loss: 0.3254472613334656
Batch 27/64 loss: 0.3329576253890991
Batch 28/64 loss: 0.3289778232574463
Batch 29/64 loss: 0.3235829472541809
Batch 30/64 loss: 0.3231012225151062
Batch 31/64 loss: 0.3254547119140625
Batch 32/64 loss: 0.32955092191696167
Batch 33/64 loss: 0.3276810646057129
Batch 34/64 loss: 0.32646119594573975
Batch 35/64 loss: 0.3310188055038452
Batch 36/64 loss: 0.3312928080558777
Batch 37/64 loss: 0.32568734884262085
Batch 38/64 loss: 0.3211599588394165
Batch 39/64 loss: 0.33075201511383057
Batch 40/64 loss: 0.3276817798614502
Batch 41/64 loss: 0.32345396280288696
Batch 42/64 loss: 0.3215641379356384
Batch 43/64 loss: 0.32725077867507935
Batch 44/64 loss: 0.32066404819488525
Batch 45/64 loss: 0.32546621561050415
Batch 46/64 loss: 0.32916414737701416
Batch 47/64 loss: 0.3313138484954834
Batch 48/64 loss: 0.32766032218933105
Batch 49/64 loss: 0.33415114879608154
Batch 50/64 loss: 0.3265537619590759
Batch 51/64 loss: 0.3308669328689575
Batch 52/64 loss: 0.32599151134490967
Batch 53/64 loss: 0.3295143246650696
Batch 54/64 loss: 0.3265644311904907
Batch 55/64 loss: 0.32375144958496094
Batch 56/64 loss: 0.3268364667892456
Batch 57/64 loss: 0.33009207248687744
Batch 58/64 loss: 0.3261728882789612
Batch 59/64 loss: 0.33079755306243896
Batch 60/64 loss: 0.3263190984725952
Batch 61/64 loss: 0.32551759481430054
Batch 62/64 loss: 0.3311336636543274
Batch 63/64 loss: 0.3289807438850403
Batch 64/64 loss: 0.3233070373535156
Epoch 101  Train loss: 0.32740532089682184  Val loss: 0.3352314440655135
Epoch 102
-------------------------------
Batch 1/64 loss: 0.32696592807769775
Batch 2/64 loss: 0.32906103134155273
Batch 3/64 loss: 0.33156442642211914
Batch 4/64 loss: 0.3241972327232361
Batch 5/64 loss: 0.3303282856941223
Batch 6/64 loss: 0.32647204399108887
Batch 7/64 loss: 0.3248629570007324
Batch 8/64 loss: 0.3335282802581787
Batch 9/64 loss: 0.3282419443130493
Batch 10/64 loss: 0.32667481899261475
Batch 11/64 loss: 0.3253004550933838
Batch 12/64 loss: 0.3328375220298767
Batch 13/64 loss: 0.32278329133987427
Batch 14/64 loss: 0.3263190984725952
Batch 15/64 loss: 0.32208871841430664
Batch 16/64 loss: 0.32201123237609863
Batch 17/64 loss: 0.3305692672729492
Batch 18/64 loss: 0.328391432762146
Batch 19/64 loss: 0.32832348346710205
Batch 20/64 loss: 0.32438433170318604
Batch 21/64 loss: 0.32561081647872925
Batch 22/64 loss: 0.3229833245277405
Batch 23/64 loss: 0.327910840511322
Batch 24/64 loss: 0.3248307704925537
Batch 25/64 loss: 0.3286607265472412
Batch 26/64 loss: 0.32554948329925537
Batch 27/64 loss: 0.32508420944213867
Batch 28/64 loss: 0.3254111409187317
Batch 29/64 loss: 0.3216002583503723
Batch 30/64 loss: 0.3262002468109131
Batch 31/64 loss: 0.328200101852417
Batch 32/64 loss: 0.3328554630279541
Batch 33/64 loss: 0.3259492516517639
Batch 34/64 loss: 0.3299403190612793
Batch 35/64 loss: 0.3245288133621216
Batch 36/64 loss: 0.3220177888870239
Batch 37/64 loss: 0.3265238404273987
Batch 38/64 loss: 0.32939082384109497
Batch 39/64 loss: 0.3286384344100952
Batch 40/64 loss: 0.32484811544418335
Batch 41/64 loss: 0.3285828232765198
Batch 42/64 loss: 0.32970237731933594
Batch 43/64 loss: 0.3314540982246399
Batch 44/64 loss: 0.32613956928253174
Batch 45/64 loss: 0.32242411375045776
Batch 46/64 loss: 0.3303711414337158
Batch 47/64 loss: 0.33042144775390625
Batch 48/64 loss: 0.32887059450149536
Batch 49/64 loss: 0.3283928632736206
Batch 50/64 loss: 0.3213946223258972
Batch 51/64 loss: 0.32478904724121094
Batch 52/64 loss: 0.3250548839569092
Batch 53/64 loss: 0.3242911100387573
Batch 54/64 loss: 0.3219609260559082
Batch 55/64 loss: 0.32566720247268677
Batch 56/64 loss: 0.32959842681884766
Batch 57/64 loss: 0.32909929752349854
Batch 58/64 loss: 0.3316501975059509
Batch 59/64 loss: 0.32624173164367676
Batch 60/64 loss: 0.32917356491088867
Batch 61/64 loss: 0.3313385248184204
Batch 62/64 loss: 0.33224916458129883
Batch 63/64 loss: 0.3272683024406433
Batch 64/64 loss: 0.32636529207229614
Epoch 102  Train loss: 0.3270988321771809  Val loss: 0.33495564415692464
Epoch 103
-------------------------------
Batch 1/64 loss: 0.3275928497314453
Batch 2/64 loss: 0.32763755321502686
Batch 3/64 loss: 0.32775795459747314
Batch 4/64 loss: 0.32468605041503906
Batch 5/64 loss: 0.32960909605026245
Batch 6/64 loss: 0.3256937265396118
Batch 7/64 loss: 0.32575786113739014
Batch 8/64 loss: 0.3287534713745117
Batch 9/64 loss: 0.32128679752349854
Batch 10/64 loss: 0.33233368396759033
Batch 11/64 loss: 0.328705370426178
Batch 12/64 loss: 0.3322451114654541
Batch 13/64 loss: 0.3239250183105469
Batch 14/64 loss: 0.32799744606018066
Batch 15/64 loss: 0.3297419548034668
Batch 16/64 loss: 0.33369195461273193
Batch 17/64 loss: 0.32336854934692383
Batch 18/64 loss: 0.32734382152557373
Batch 19/64 loss: 0.32759004831314087
Batch 20/64 loss: 0.3265233039855957
Batch 21/64 loss: 0.3329329490661621
Batch 22/64 loss: 0.3222448229789734
Batch 23/64 loss: 0.32466840744018555
Batch 24/64 loss: 0.32874566316604614
Batch 25/64 loss: 0.32250094413757324
Batch 26/64 loss: 0.32675957679748535
Batch 27/64 loss: 0.32406699657440186
Batch 28/64 loss: 0.32161253690719604
Batch 29/64 loss: 0.3216479420661926
Batch 30/64 loss: 0.3280647397041321
Batch 31/64 loss: 0.3270677328109741
Batch 32/64 loss: 0.3238142728805542
Batch 33/64 loss: 0.333157479763031
Batch 34/64 loss: 0.3207816481590271
Batch 35/64 loss: 0.32928895950317383
Batch 36/64 loss: 0.32435905933380127
Batch 37/64 loss: 0.3252025842666626
Batch 38/64 loss: 0.32838690280914307
Batch 39/64 loss: 0.3298296332359314
Batch 40/64 loss: 0.33082735538482666
Batch 41/64 loss: 0.3290221691131592
Batch 42/64 loss: 0.3234431743621826
Batch 43/64 loss: 0.3279404044151306
Batch 44/64 loss: 0.3279019594192505
Batch 45/64 loss: 0.3290978670120239
Batch 46/64 loss: 0.32641327381134033
Batch 47/64 loss: 0.3306351900100708
Batch 48/64 loss: 0.3283320665359497
Batch 49/64 loss: 0.3216739892959595
Batch 50/64 loss: 0.32733601331710815
Batch 51/64 loss: 0.32613974809646606
Batch 52/64 loss: 0.3221479654312134
Batch 53/64 loss: 0.32755184173583984
Batch 54/64 loss: 0.3249690532684326
Batch 55/64 loss: 0.32576000690460205
Batch 56/64 loss: 0.3313693404197693
Batch 57/64 loss: 0.3239583373069763
Batch 58/64 loss: 0.3260250687599182
Batch 59/64 loss: 0.3258291482925415
Batch 60/64 loss: 0.3280731439590454
Batch 61/64 loss: 0.32176852226257324
Batch 62/64 loss: 0.328413188457489
Batch 63/64 loss: 0.32877278327941895
Batch 64/64 loss: 0.32729053497314453
Epoch 103  Train loss: 0.3268430429346421  Val loss: 0.33474541898445576
Saving best model, epoch: 103
Epoch 104
-------------------------------
Batch 1/64 loss: 0.3270066976547241
Batch 2/64 loss: 0.3233981132507324
Batch 3/64 loss: 0.32820868492126465
Batch 4/64 loss: 0.3219097852706909
Batch 5/64 loss: 0.32351839542388916
Batch 6/64 loss: 0.32810747623443604
Batch 7/64 loss: 0.32321059703826904
Batch 8/64 loss: 0.32709169387817383
Batch 9/64 loss: 0.3297615051269531
Batch 10/64 loss: 0.3231678009033203
Batch 11/64 loss: 0.3270267844200134
Batch 12/64 loss: 0.3254270553588867
Batch 13/64 loss: 0.3258063793182373
Batch 14/64 loss: 0.32556819915771484
Batch 15/64 loss: 0.3263547420501709
Batch 16/64 loss: 0.3230488896369934
Batch 17/64 loss: 0.32313960790634155
Batch 18/64 loss: 0.32694292068481445
Batch 19/64 loss: 0.33109235763549805
Batch 20/64 loss: 0.3253883719444275
Batch 21/64 loss: 0.32664597034454346
Batch 22/64 loss: 0.32424741983413696
Batch 23/64 loss: 0.3236105442047119
Batch 24/64 loss: 0.3231932520866394
Batch 25/64 loss: 0.3251678943634033
Batch 26/64 loss: 0.32533395290374756
Batch 27/64 loss: 0.32550275325775146
Batch 28/64 loss: 0.32550865411758423
Batch 29/64 loss: 0.3265111446380615
Batch 30/64 loss: 0.3269686698913574
Batch 31/64 loss: 0.32348114252090454
Batch 32/64 loss: 0.3302572965621948
Batch 33/64 loss: 0.3263135552406311
Batch 34/64 loss: 0.3310208320617676
Batch 35/64 loss: 0.327236533164978
Batch 36/64 loss: 0.3358665108680725
Batch 37/64 loss: 0.3331039547920227
Batch 38/64 loss: 0.32577741146087646
Batch 39/64 loss: 0.3302609920501709
Batch 40/64 loss: 0.3246241807937622
Batch 41/64 loss: 0.3280150294303894
Batch 42/64 loss: 0.32631707191467285
Batch 43/64 loss: 0.32270336151123047
Batch 44/64 loss: 0.3245540261268616
Batch 45/64 loss: 0.32662928104400635
Batch 46/64 loss: 0.3271811604499817
Batch 47/64 loss: 0.3265647888183594
Batch 48/64 loss: 0.3291747570037842
Batch 49/64 loss: 0.33043384552001953
Batch 50/64 loss: 0.319291353225708
Batch 51/64 loss: 0.328890323638916
Batch 52/64 loss: 0.3302053213119507
Batch 53/64 loss: 0.3214946985244751
Batch 54/64 loss: 0.32905399799346924
Batch 55/64 loss: 0.3273775577545166
Batch 56/64 loss: 0.3273046612739563
Batch 57/64 loss: 0.3273085951805115
Batch 58/64 loss: 0.3241124749183655
Batch 59/64 loss: 0.3277773857116699
Batch 60/64 loss: 0.3234230875968933
Batch 61/64 loss: 0.3291251063346863
Batch 62/64 loss: 0.3213357925415039
Batch 63/64 loss: 0.3293696641921997
Batch 64/64 loss: 0.32910966873168945
Epoch 104  Train loss: 0.32643583241631  Val loss: 0.3353666200260936
Epoch 105
-------------------------------
Batch 1/64 loss: 0.3341484069824219
Batch 2/64 loss: 0.3280179500579834
Batch 3/64 loss: 0.31967103481292725
Batch 4/64 loss: 0.3223017454147339
Batch 5/64 loss: 0.3251095414161682
Batch 6/64 loss: 0.3273569345474243
Batch 7/64 loss: 0.33298295736312866
Batch 8/64 loss: 0.3251349925994873
Batch 9/64 loss: 0.3255178928375244
Batch 10/64 loss: 0.32734203338623047
Batch 11/64 loss: 0.324964702129364
Batch 12/64 loss: 0.32507747411727905
Batch 13/64 loss: 0.3228687047958374
Batch 14/64 loss: 0.327100932598114
Batch 15/64 loss: 0.3210335969924927
Batch 16/64 loss: 0.3270336389541626
Batch 17/64 loss: 0.3253943920135498
Batch 18/64 loss: 0.32527005672454834
Batch 19/64 loss: 0.328616201877594
Batch 20/64 loss: 0.32545530796051025
Batch 21/64 loss: 0.32586562633514404
Batch 22/64 loss: 0.32541215419769287
Batch 23/64 loss: 0.326699435710907
Batch 24/64 loss: 0.326205849647522
Batch 25/64 loss: 0.32022571563720703
Batch 26/64 loss: 0.3223757743835449
Batch 27/64 loss: 0.32196736335754395
Batch 28/64 loss: 0.32326316833496094
Batch 29/64 loss: 0.3185902237892151
Batch 30/64 loss: 0.3259485363960266
Batch 31/64 loss: 0.3285468816757202
Batch 32/64 loss: 0.3259987235069275
Batch 33/64 loss: 0.32457810640335083
Batch 34/64 loss: 0.3280661702156067
Batch 35/64 loss: 0.32687461376190186
Batch 36/64 loss: 0.32041072845458984
Batch 37/64 loss: 0.3221771717071533
Batch 38/64 loss: 0.32972657680511475
Batch 39/64 loss: 0.32272446155548096
Batch 40/64 loss: 0.3292391300201416
Batch 41/64 loss: 0.3322821855545044
Batch 42/64 loss: 0.32717394828796387
Batch 43/64 loss: 0.3212789297103882
Batch 44/64 loss: 0.3260536193847656
Batch 45/64 loss: 0.32894647121429443
Batch 46/64 loss: 0.3308577537536621
Batch 47/64 loss: 0.3261798620223999
Batch 48/64 loss: 0.32803022861480713
Batch 49/64 loss: 0.32448089122772217
Batch 50/64 loss: 0.322975754737854
Batch 51/64 loss: 0.32900673151016235
Batch 52/64 loss: 0.32395488023757935
Batch 53/64 loss: 0.322650671005249
Batch 54/64 loss: 0.33162665367126465
Batch 55/64 loss: 0.32907605171203613
Batch 56/64 loss: 0.33205270767211914
Batch 57/64 loss: 0.32376670837402344
Batch 58/64 loss: 0.3251159191131592
Batch 59/64 loss: 0.32497358322143555
Batch 60/64 loss: 0.32762861251831055
Batch 61/64 loss: 0.32218605279922485
Batch 62/64 loss: 0.32545173168182373
Batch 63/64 loss: 0.32765722274780273
Batch 64/64 loss: 0.32737940549850464
Epoch 105  Train loss: 0.32587037857841045  Val loss: 0.3334666789602168
Saving best model, epoch: 105
Epoch 106
-------------------------------
Batch 1/64 loss: 0.3267946243286133
Batch 2/64 loss: 0.3285277485847473
Batch 3/64 loss: 0.31957823038101196
Batch 4/64 loss: 0.3222886323928833
Batch 5/64 loss: 0.3224865198135376
Batch 6/64 loss: 0.326244056224823
Batch 7/64 loss: 0.3267149329185486
Batch 8/64 loss: 0.32720720767974854
Batch 9/64 loss: 0.32005006074905396
Batch 10/64 loss: 0.3297613859176636
Batch 11/64 loss: 0.32741600275039673
Batch 12/64 loss: 0.3250854015350342
Batch 13/64 loss: 0.3249514698982239
Batch 14/64 loss: 0.33052152395248413
Batch 15/64 loss: 0.3207448124885559
Batch 16/64 loss: 0.33167850971221924
Batch 17/64 loss: 0.32257282733917236
Batch 18/64 loss: 0.3198203444480896
Batch 19/64 loss: 0.3302726149559021
Batch 20/64 loss: 0.325641930103302
Batch 21/64 loss: 0.3191952705383301
Batch 22/64 loss: 0.32158178091049194
Batch 23/64 loss: 0.32808107137680054
Batch 24/64 loss: 0.325325608253479
Batch 25/64 loss: 0.32562923431396484
Batch 26/64 loss: 0.32621240615844727
Batch 27/64 loss: 0.32393085956573486
Batch 28/64 loss: 0.32467222213745117
Batch 29/64 loss: 0.3259427547454834
Batch 30/64 loss: 0.33093947172164917
Batch 31/64 loss: 0.322567343711853
Batch 32/64 loss: 0.32826846837997437
Batch 33/64 loss: 0.32318931818008423
Batch 34/64 loss: 0.32969725131988525
Batch 35/64 loss: 0.32320666313171387
Batch 36/64 loss: 0.3239579200744629
Batch 37/64 loss: 0.32635927200317383
Batch 38/64 loss: 0.3314342498779297
Batch 39/64 loss: 0.32120996713638306
Batch 40/64 loss: 0.3219420909881592
Batch 41/64 loss: 0.32853925228118896
Batch 42/64 loss: 0.3292708396911621
Batch 43/64 loss: 0.32132381200790405
Batch 44/64 loss: 0.32741856575012207
Batch 45/64 loss: 0.3258023262023926
Batch 46/64 loss: 0.3235916495323181
Batch 47/64 loss: 0.32625120878219604
Batch 48/64 loss: 0.3237706422805786
Batch 49/64 loss: 0.3221796154975891
Batch 50/64 loss: 0.3271697759628296
Batch 51/64 loss: 0.32633572816848755
Batch 52/64 loss: 0.33364927768707275
Batch 53/64 loss: 0.33209681510925293
Batch 54/64 loss: 0.3248046636581421
Batch 55/64 loss: 0.32350635528564453
Batch 56/64 loss: 0.322873592376709
Batch 57/64 loss: 0.32339227199554443
Batch 58/64 loss: 0.3245563507080078
Batch 59/64 loss: 0.3210095763206482
Batch 60/64 loss: 0.3227623701095581
Batch 61/64 loss: 0.3181058168411255
Batch 62/64 loss: 0.32343554496765137
Batch 63/64 loss: 0.3311355710029602
Batch 64/64 loss: 0.3245687484741211
Epoch 106  Train loss: 0.32530369010626103  Val loss: 0.33221171893614676
Saving best model, epoch: 106
Epoch 107
-------------------------------
Batch 1/64 loss: 0.3261638879776001
Batch 2/64 loss: 0.3194695711135864
Batch 3/64 loss: 0.3231070041656494
Batch 4/64 loss: 0.3213757872581482
Batch 5/64 loss: 0.32046228647232056
Batch 6/64 loss: 0.3232179880142212
Batch 7/64 loss: 0.32996678352355957
Batch 8/64 loss: 0.3198593854904175
Batch 9/64 loss: 0.3255907893180847
Batch 10/64 loss: 0.323779821395874
Batch 11/64 loss: 0.32019925117492676
Batch 12/64 loss: 0.3250862956047058
Batch 13/64 loss: 0.32709622383117676
Batch 14/64 loss: 0.3214375972747803
Batch 15/64 loss: 0.32566916942596436
Batch 16/64 loss: 0.3290454149246216
Batch 17/64 loss: 0.3297441005706787
Batch 18/64 loss: 0.32543039321899414
Batch 19/64 loss: 0.32049840688705444
Batch 20/64 loss: 0.3268851041793823
Batch 21/64 loss: 0.3217804431915283
Batch 22/64 loss: 0.3232983350753784
Batch 23/64 loss: 0.32662057876586914
Batch 24/64 loss: 0.32846498489379883
Batch 25/64 loss: 0.3270884156227112
Batch 26/64 loss: 0.32494956254959106
Batch 27/64 loss: 0.3280179500579834
Batch 28/64 loss: 0.32802021503448486
Batch 29/64 loss: 0.3291580080986023
Batch 30/64 loss: 0.3215683698654175
Batch 31/64 loss: 0.32220613956451416
Batch 32/64 loss: 0.3227947950363159
Batch 33/64 loss: 0.3268657922744751
Batch 34/64 loss: 0.32460951805114746
Batch 35/64 loss: 0.3229222893714905
Batch 36/64 loss: 0.3236886262893677
Batch 37/64 loss: 0.31905627250671387
Batch 38/64 loss: 0.328424334526062
Batch 39/64 loss: 0.32836711406707764
Batch 40/64 loss: 0.32265299558639526
Batch 41/64 loss: 0.3252050280570984
Batch 42/64 loss: 0.32680821418762207
Batch 43/64 loss: 0.32354748249053955
Batch 44/64 loss: 0.326501727104187
Batch 45/64 loss: 0.3269941210746765
Batch 46/64 loss: 0.32253414392471313
Batch 47/64 loss: 0.32090961933135986
Batch 48/64 loss: 0.32740211486816406
Batch 49/64 loss: 0.32757270336151123
Batch 50/64 loss: 0.32808786630630493
Batch 51/64 loss: 0.324637770652771
Batch 52/64 loss: 0.3289724588394165
Batch 53/64 loss: 0.3205519914627075
Batch 54/64 loss: 0.32645440101623535
Batch 55/64 loss: 0.32424241304397583
Batch 56/64 loss: 0.32177042961120605
Batch 57/64 loss: 0.3301994800567627
Batch 58/64 loss: 0.3236734867095947
Batch 59/64 loss: 0.3243519067764282
Batch 60/64 loss: 0.3288152813911438
Batch 61/64 loss: 0.3284149765968323
Batch 62/64 loss: 0.3249815106391907
Batch 63/64 loss: 0.321860134601593
Batch 64/64 loss: 0.3253811001777649
Epoch 107  Train loss: 0.32491239356059654  Val loss: 0.332800801062502
Epoch 108
-------------------------------
Batch 1/64 loss: 0.32583701610565186
Batch 2/64 loss: 0.3234884738922119
Batch 3/64 loss: 0.3250786066055298
Batch 4/64 loss: 0.3281353712081909
Batch 5/64 loss: 0.32553791999816895
Batch 6/64 loss: 0.3299069404602051
Batch 7/64 loss: 0.3218475580215454
Batch 8/64 loss: 0.31848305463790894
Batch 9/64 loss: 0.3223109245300293
Batch 10/64 loss: 0.32440119981765747
Batch 11/64 loss: 0.32272857427597046
Batch 12/64 loss: 0.3249804973602295
Batch 13/64 loss: 0.3229660987854004
Batch 14/64 loss: 0.320684552192688
Batch 15/64 loss: 0.32422560453414917
Batch 16/64 loss: 0.33111071586608887
Batch 17/64 loss: 0.32125580310821533
Batch 18/64 loss: 0.31970763206481934
Batch 19/64 loss: 0.331423282623291
Batch 20/64 loss: 0.322582483291626
Batch 21/64 loss: 0.31672173738479614
Batch 22/64 loss: 0.3212989568710327
Batch 23/64 loss: 0.3215372562408447
Batch 24/64 loss: 0.3243195414543152
Batch 25/64 loss: 0.32810306549072266
Batch 26/64 loss: 0.32550716400146484
Batch 27/64 loss: 0.3242049813270569
Batch 28/64 loss: 0.3299199938774109
Batch 29/64 loss: 0.3256295919418335
Batch 30/64 loss: 0.3300014138221741
Batch 31/64 loss: 0.3247724771499634
Batch 32/64 loss: 0.3247934579849243
Batch 33/64 loss: 0.3233773708343506
Batch 34/64 loss: 0.3248547315597534
Batch 35/64 loss: 0.3209735155105591
Batch 36/64 loss: 0.3217717409133911
Batch 37/64 loss: 0.3239858150482178
Batch 38/64 loss: 0.32254886627197266
Batch 39/64 loss: 0.32334887981414795
Batch 40/64 loss: 0.3229095935821533
Batch 41/64 loss: 0.3269851803779602
Batch 42/64 loss: 0.3228205442428589
Batch 43/64 loss: 0.32928788661956787
Batch 44/64 loss: 0.33011043071746826
Batch 45/64 loss: 0.32189154624938965
Batch 46/64 loss: 0.3230154514312744
Batch 47/64 loss: 0.3303014039993286
Batch 48/64 loss: 0.3270798921585083
Batch 49/64 loss: 0.3191772699356079
Batch 50/64 loss: 0.32441258430480957
Batch 51/64 loss: 0.3230953812599182
Batch 52/64 loss: 0.3237249255180359
Batch 53/64 loss: 0.32273542881011963
Batch 54/64 loss: 0.32052892446517944
Batch 55/64 loss: 0.32610559463500977
Batch 56/64 loss: 0.32445967197418213
Batch 57/64 loss: 0.3254200220108032
Batch 58/64 loss: 0.32248997688293457
Batch 59/64 loss: 0.32886427640914917
Batch 60/64 loss: 0.3203096389770508
Batch 61/64 loss: 0.31972402334213257
Batch 62/64 loss: 0.32143330574035645
Batch 63/64 loss: 0.3259469270706177
Batch 64/64 loss: 0.3288382291793823
Epoch 108  Train loss: 0.32429523795258763  Val loss: 0.3317678724367594
Saving best model, epoch: 108
Epoch 109
-------------------------------
Batch 1/64 loss: 0.3213036060333252
Batch 2/64 loss: 0.3285670280456543
Batch 3/64 loss: 0.3229685425758362
Batch 4/64 loss: 0.32433927059173584
Batch 5/64 loss: 0.3311782479286194
Batch 6/64 loss: 0.31811875104904175
Batch 7/64 loss: 0.3290994167327881
Batch 8/64 loss: 0.3226817846298218
Batch 9/64 loss: 0.3237189054489136
Batch 10/64 loss: 0.32532602548599243
Batch 11/64 loss: 0.3233184814453125
Batch 12/64 loss: 0.3267977237701416
Batch 13/64 loss: 0.3236231803894043
Batch 14/64 loss: 0.3255225419998169
Batch 15/64 loss: 0.32276368141174316
Batch 16/64 loss: 0.32510530948638916
Batch 17/64 loss: 0.3169039487838745
Batch 18/64 loss: 0.3233751654624939
Batch 19/64 loss: 0.3238338232040405
Batch 20/64 loss: 0.32003819942474365
Batch 21/64 loss: 0.32397961616516113
Batch 22/64 loss: 0.32207053899765015
Batch 23/64 loss: 0.3280600309371948
Batch 24/64 loss: 0.3262742757797241
Batch 25/64 loss: 0.3250465989112854
Batch 26/64 loss: 0.31860196590423584
Batch 27/64 loss: 0.3267768621444702
Batch 28/64 loss: 0.32026559114456177
Batch 29/64 loss: 0.3196306824684143
Batch 30/64 loss: 0.32935649156570435
Batch 31/64 loss: 0.3224523067474365
Batch 32/64 loss: 0.32208508253097534
Batch 33/64 loss: 0.3213534355163574
Batch 34/64 loss: 0.3242539167404175
Batch 35/64 loss: 0.3217991590499878
Batch 36/64 loss: 0.3163144588470459
Batch 37/64 loss: 0.3185247778892517
Batch 38/64 loss: 0.31766390800476074
Batch 39/64 loss: 0.32045865058898926
Batch 40/64 loss: 0.31583571434020996
Batch 41/64 loss: 0.3242000341415405
Batch 42/64 loss: 0.32911670207977295
Batch 43/64 loss: 0.32881081104278564
Batch 44/64 loss: 0.3233335018157959
Batch 45/64 loss: 0.32128143310546875
Batch 46/64 loss: 0.32434260845184326
Batch 47/64 loss: 0.31459057331085205
Batch 48/64 loss: 0.32355886697769165
Batch 49/64 loss: 0.3270970582962036
Batch 50/64 loss: 0.3286401033401489
Batch 51/64 loss: 0.3212985396385193
Batch 52/64 loss: 0.330748975276947
Batch 53/64 loss: 0.3259682059288025
Batch 54/64 loss: 0.3246499300003052
Batch 55/64 loss: 0.32780539989471436
Batch 56/64 loss: 0.3221336603164673
Batch 57/64 loss: 0.32727348804473877
Batch 58/64 loss: 0.32184505462646484
Batch 59/64 loss: 0.329021692276001
Batch 60/64 loss: 0.32545411586761475
Batch 61/64 loss: 0.3257814645767212
Batch 62/64 loss: 0.3302205801010132
Batch 63/64 loss: 0.3249952793121338
Batch 64/64 loss: 0.3287045955657959
Epoch 109  Train loss: 0.3238915172277712  Val loss: 0.33359208713282423
Epoch 110
-------------------------------
Batch 1/64 loss: 0.3310922384262085
Batch 2/64 loss: 0.3267356753349304
Batch 3/64 loss: 0.32199400663375854
Batch 4/64 loss: 0.3216437101364136
Batch 5/64 loss: 0.3303561806678772
Batch 6/64 loss: 0.3240448236465454
Batch 7/64 loss: 0.3300730586051941
Batch 8/64 loss: 0.3287174105644226
Batch 9/64 loss: 0.324981689453125
Batch 10/64 loss: 0.3202848434448242
Batch 11/64 loss: 0.32793760299682617
Batch 12/64 loss: 0.326973557472229
Batch 13/64 loss: 0.3283578157424927
Batch 14/64 loss: 0.32385432720184326
Batch 15/64 loss: 0.32662248611450195
Batch 16/64 loss: 0.32014548778533936
Batch 17/64 loss: 0.32845842838287354
Batch 18/64 loss: 0.32231324911117554
Batch 19/64 loss: 0.32163912057876587
Batch 20/64 loss: 0.3204154968261719
Batch 21/64 loss: 0.32753145694732666
Batch 22/64 loss: 0.32605618238449097
Batch 23/64 loss: 0.333063006401062
Batch 24/64 loss: 0.31750357151031494
Batch 25/64 loss: 0.32210808992385864
Batch 26/64 loss: 0.32274580001831055
Batch 27/64 loss: 0.32657110691070557
Batch 28/64 loss: 0.3242051601409912
Batch 29/64 loss: 0.3217509984970093
Batch 30/64 loss: 0.3183533549308777
Batch 31/64 loss: 0.3230329751968384
Batch 32/64 loss: 0.3240894079208374
Batch 33/64 loss: 0.32413315773010254
Batch 34/64 loss: 0.32853007316589355
Batch 35/64 loss: 0.3204357624053955
Batch 36/64 loss: 0.32972830533981323
Batch 37/64 loss: 0.32231324911117554
Batch 38/64 loss: 0.3245564103126526
Batch 39/64 loss: 0.3185662031173706
Batch 40/64 loss: 0.32138365507125854
Batch 41/64 loss: 0.31974709033966064
Batch 42/64 loss: 0.32862162590026855
Batch 43/64 loss: 0.32740843296051025
Batch 44/64 loss: 0.3291066884994507
Batch 45/64 loss: 0.3253740072250366
Batch 46/64 loss: 0.32567083835601807
Batch 47/64 loss: 0.32103949785232544
Batch 48/64 loss: 0.3193991184234619
Batch 49/64 loss: 0.3218817114830017
Batch 50/64 loss: 0.3232312798500061
Batch 51/64 loss: 0.3231329917907715
Batch 52/64 loss: 0.3208669424057007
Batch 53/64 loss: 0.3204686641693115
Batch 54/64 loss: 0.3210117816925049
Batch 55/64 loss: 0.31746089458465576
Batch 56/64 loss: 0.33329451084136963
Batch 57/64 loss: 0.3249831795692444
Batch 58/64 loss: 0.3203768730163574
Batch 59/64 loss: 0.32445240020751953
Batch 60/64 loss: 0.32399529218673706
Batch 61/64 loss: 0.320030152797699
Batch 62/64 loss: 0.32422494888305664
Batch 63/64 loss: 0.32105159759521484
Batch 64/64 loss: 0.31749236583709717
Epoch 110  Train loss: 0.3240509636261884  Val loss: 0.33164430053783034
Saving best model, epoch: 110
Epoch 111
-------------------------------
Batch 1/64 loss: 0.32100623846054077
Batch 2/64 loss: 0.32291191816329956
Batch 3/64 loss: 0.3235989809036255
Batch 4/64 loss: 0.3262098431587219
Batch 5/64 loss: 0.3183388113975525
Batch 6/64 loss: 0.32198262214660645
Batch 7/64 loss: 0.33049869537353516
Batch 8/64 loss: 0.32351601123809814
Batch 9/64 loss: 0.3247707486152649
Batch 10/64 loss: 0.31490767002105713
Batch 11/64 loss: 0.3213006854057312
Batch 12/64 loss: 0.32801884412765503
Batch 13/64 loss: 0.31714534759521484
Batch 14/64 loss: 0.32075798511505127
Batch 15/64 loss: 0.3180135488510132
Batch 16/64 loss: 0.3174678087234497
Batch 17/64 loss: 0.31995826959609985
Batch 18/64 loss: 0.3187217712402344
Batch 19/64 loss: 0.32441747188568115
Batch 20/64 loss: 0.3197345733642578
Batch 21/64 loss: 0.32454556226730347
Batch 22/64 loss: 0.3206977844238281
Batch 23/64 loss: 0.3245999813079834
Batch 24/64 loss: 0.32050758600234985
Batch 25/64 loss: 0.3203972578048706
Batch 26/64 loss: 0.3251795768737793
Batch 27/64 loss: 0.3234924077987671
Batch 28/64 loss: 0.3237614631652832
Batch 29/64 loss: 0.32596492767333984
Batch 30/64 loss: 0.32545846700668335
Batch 31/64 loss: 0.33364492654800415
Batch 32/64 loss: 0.32334262132644653
Batch 33/64 loss: 0.3210795521736145
Batch 34/64 loss: 0.31988251209259033
Batch 35/64 loss: 0.3191787004470825
Batch 36/64 loss: 0.3228023648262024
Batch 37/64 loss: 0.32667696475982666
Batch 38/64 loss: 0.3289906978607178
Batch 39/64 loss: 0.3192014694213867
Batch 40/64 loss: 0.3264331817626953
Batch 41/64 loss: 0.3321383595466614
Batch 42/64 loss: 0.33016806840896606
Batch 43/64 loss: 0.3267069458961487
Batch 44/64 loss: 0.323840856552124
Batch 45/64 loss: 0.32232236862182617
Batch 46/64 loss: 0.32358211278915405
Batch 47/64 loss: 0.3210798501968384
Batch 48/64 loss: 0.3206590414047241
Batch 49/64 loss: 0.32055675983428955
Batch 50/64 loss: 0.31941354274749756
Batch 51/64 loss: 0.3190739154815674
Batch 52/64 loss: 0.32053059339523315
Batch 53/64 loss: 0.3245486617088318
Batch 54/64 loss: 0.31864845752716064
Batch 55/64 loss: 0.321180522441864
Batch 56/64 loss: 0.32133471965789795
Batch 57/64 loss: 0.32384347915649414
Batch 58/64 loss: 0.32156258821487427
Batch 59/64 loss: 0.3259965181350708
Batch 60/64 loss: 0.32525038719177246
Batch 61/64 loss: 0.3224499821662903
Batch 62/64 loss: 0.32498347759246826
Batch 63/64 loss: 0.3213160037994385
Batch 64/64 loss: 0.3220103979110718
Epoch 111  Train loss: 0.3228519350874658  Val loss: 0.33167801566959654
Epoch 112
-------------------------------
Batch 1/64 loss: 0.31873708963394165
Batch 2/64 loss: 0.3237217664718628
Batch 3/64 loss: 0.3263496160507202
Batch 4/64 loss: 0.3218461871147156
Batch 5/64 loss: 0.32167959213256836
Batch 6/64 loss: 0.3208775520324707
Batch 7/64 loss: 0.3186938762664795
Batch 8/64 loss: 0.3240774869918823
Batch 9/64 loss: 0.32436853647232056
Batch 10/64 loss: 0.3237789273262024
Batch 11/64 loss: 0.3183864951133728
Batch 12/64 loss: 0.3266962766647339
Batch 13/64 loss: 0.3248569965362549
Batch 14/64 loss: 0.3254142999649048
Batch 15/64 loss: 0.32636702060699463
Batch 16/64 loss: 0.3253597021102905
Batch 17/64 loss: 0.32588648796081543
Batch 18/64 loss: 0.3193110227584839
Batch 19/64 loss: 0.32188981771469116
Batch 20/64 loss: 0.3254051208496094
Batch 21/64 loss: 0.3221445083618164
Batch 22/64 loss: 0.32492882013320923
Batch 23/64 loss: 0.3238539695739746
Batch 24/64 loss: 0.32265204191207886
Batch 25/64 loss: 0.3211882710456848
Batch 26/64 loss: 0.32125723361968994
Batch 27/64 loss: 0.31950104236602783
Batch 28/64 loss: 0.3130366802215576
Batch 29/64 loss: 0.3182485103607178
Batch 30/64 loss: 0.32019805908203125
Batch 31/64 loss: 0.32127439975738525
Batch 32/64 loss: 0.32434648275375366
Batch 33/64 loss: 0.3179202079772949
Batch 34/64 loss: 0.32566821575164795
Batch 35/64 loss: 0.31785523891448975
Batch 36/64 loss: 0.3232378363609314
Batch 37/64 loss: 0.32281577587127686
Batch 38/64 loss: 0.32217466831207275
Batch 39/64 loss: 0.32187390327453613
Batch 40/64 loss: 0.32259517908096313
Batch 41/64 loss: 0.3235199451446533
Batch 42/64 loss: 0.32300955057144165
Batch 43/64 loss: 0.32467812299728394
Batch 44/64 loss: 0.3176621198654175
Batch 45/64 loss: 0.3248260021209717
Batch 46/64 loss: 0.32797789573669434
Batch 47/64 loss: 0.3184159994125366
Batch 48/64 loss: 0.3219407796859741
Batch 49/64 loss: 0.3247867822647095
Batch 50/64 loss: 0.3259519934654236
Batch 51/64 loss: 0.3180577754974365
Batch 52/64 loss: 0.3264496326446533
Batch 53/64 loss: 0.32040107250213623
Batch 54/64 loss: 0.3222123384475708
Batch 55/64 loss: 0.32571589946746826
Batch 56/64 loss: 0.3196682929992676
Batch 57/64 loss: 0.3191632032394409
Batch 58/64 loss: 0.32240134477615356
Batch 59/64 loss: 0.3268088698387146
Batch 60/64 loss: 0.3244399428367615
Batch 61/64 loss: 0.33105260133743286
Batch 62/64 loss: 0.32143449783325195
Batch 63/64 loss: 0.31783032417297363
Batch 64/64 loss: 0.3264458179473877
Epoch 112  Train loss: 0.32256806691487633  Val loss: 0.33072605309207825
Saving best model, epoch: 112
Epoch 113
-------------------------------
Batch 1/64 loss: 0.3177683353424072
Batch 2/64 loss: 0.31298965215682983
Batch 3/64 loss: 0.3249713182449341
Batch 4/64 loss: 0.3212580680847168
Batch 5/64 loss: 0.3263261318206787
Batch 6/64 loss: 0.3233158588409424
Batch 7/64 loss: 0.3251041769981384
Batch 8/64 loss: 0.3286043405532837
Batch 9/64 loss: 0.3291449546813965
Batch 10/64 loss: 0.3190157413482666
Batch 11/64 loss: 0.3244202136993408
Batch 12/64 loss: 0.32675981521606445
Batch 13/64 loss: 0.31715595722198486
Batch 14/64 loss: 0.3244733214378357
Batch 15/64 loss: 0.32654523849487305
Batch 16/64 loss: 0.32154977321624756
Batch 17/64 loss: 0.322692334651947
Batch 18/64 loss: 0.31941545009613037
Batch 19/64 loss: 0.3249194025993347
Batch 20/64 loss: 0.32411086559295654
Batch 21/64 loss: 0.32687366008758545
Batch 22/64 loss: 0.32462596893310547
Batch 23/64 loss: 0.3227880001068115
Batch 24/64 loss: 0.3241504430770874
Batch 25/64 loss: 0.3220983147621155
Batch 26/64 loss: 0.31940484046936035
Batch 27/64 loss: 0.32107675075531006
Batch 28/64 loss: 0.3214360475540161
Batch 29/64 loss: 0.3207756280899048
Batch 30/64 loss: 0.32571399211883545
Batch 31/64 loss: 0.32961714267730713
Batch 32/64 loss: 0.3236783742904663
Batch 33/64 loss: 0.3252856731414795
Batch 34/64 loss: 0.3250616788864136
Batch 35/64 loss: 0.32082533836364746
Batch 36/64 loss: 0.3199197053909302
Batch 37/64 loss: 0.3214772939682007
Batch 38/64 loss: 0.3243843913078308
Batch 39/64 loss: 0.3189483880996704
Batch 40/64 loss: 0.32039839029312134
Batch 41/64 loss: 0.32389092445373535
Batch 42/64 loss: 0.3170175552368164
Batch 43/64 loss: 0.3186647891998291
Batch 44/64 loss: 0.32422173023223877
Batch 45/64 loss: 0.3174148201942444
Batch 46/64 loss: 0.3202173709869385
Batch 47/64 loss: 0.3279322385787964
Batch 48/64 loss: 0.31994199752807617
Batch 49/64 loss: 0.3187098503112793
Batch 50/64 loss: 0.3178810477256775
Batch 51/64 loss: 0.3179721236228943
Batch 52/64 loss: 0.3236176371574402
Batch 53/64 loss: 0.32841944694519043
Batch 54/64 loss: 0.3215785026550293
Batch 55/64 loss: 0.3315819501876831
Batch 56/64 loss: 0.3198319673538208
Batch 57/64 loss: 0.33013927936553955
Batch 58/64 loss: 0.32437533140182495
Batch 59/64 loss: 0.327630877494812
Batch 60/64 loss: 0.32113945484161377
Batch 61/64 loss: 0.3217851519584656
Batch 62/64 loss: 0.32542794942855835
Batch 63/64 loss: 0.322268009185791
Batch 64/64 loss: 0.3288898468017578
Epoch 113  Train loss: 0.32293973904029993  Val loss: 0.33162093367363576
Epoch 114
-------------------------------
Batch 1/64 loss: 0.32571303844451904
Batch 2/64 loss: 0.32270896434783936
Batch 3/64 loss: 0.32308530807495117
Batch 4/64 loss: 0.31659162044525146
Batch 5/64 loss: 0.3192298412322998
Batch 6/64 loss: 0.32127881050109863
Batch 7/64 loss: 0.3267099857330322
Batch 8/64 loss: 0.3233618140220642
Batch 9/64 loss: 0.3288305997848511
Batch 10/64 loss: 0.3200547695159912
Batch 11/64 loss: 0.32382071018218994
Batch 12/64 loss: 0.3206409215927124
Batch 13/64 loss: 0.3216567039489746
Batch 14/64 loss: 0.31750619411468506
Batch 15/64 loss: 0.3237406611442566
Batch 16/64 loss: 0.3249005079269409
Batch 17/64 loss: 0.32477521896362305
Batch 18/64 loss: 0.3207993507385254
Batch 19/64 loss: 0.31949692964553833
Batch 20/64 loss: 0.3181227445602417
Batch 21/64 loss: 0.3294628858566284
Batch 22/64 loss: 0.32026374340057373
Batch 23/64 loss: 0.3228724002838135
Batch 24/64 loss: 0.31520265340805054
Batch 25/64 loss: 0.32420599460601807
Batch 26/64 loss: 0.32725512981414795
Batch 27/64 loss: 0.3209722638130188
Batch 28/64 loss: 0.3227541446685791
Batch 29/64 loss: 0.32018017768859863
Batch 30/64 loss: 0.3248276114463806
Batch 31/64 loss: 0.3179006576538086
Batch 32/64 loss: 0.32198822498321533
Batch 33/64 loss: 0.3263108730316162
Batch 34/64 loss: 0.3158830404281616
Batch 35/64 loss: 0.32224440574645996
Batch 36/64 loss: 0.32226383686065674
Batch 37/64 loss: 0.32339465618133545
Batch 38/64 loss: 0.32120615243911743
Batch 39/64 loss: 0.3251136541366577
Batch 40/64 loss: 0.31975656747817993
Batch 41/64 loss: 0.3241959810256958
Batch 42/64 loss: 0.32319867610931396
Batch 43/64 loss: 0.32220834493637085
Batch 44/64 loss: 0.3225579261779785
Batch 45/64 loss: 0.3224506378173828
Batch 46/64 loss: 0.3159467577934265
Batch 47/64 loss: 0.3281974792480469
Batch 48/64 loss: 0.3256797790527344
Batch 49/64 loss: 0.3179934024810791
Batch 50/64 loss: 0.3218420743942261
Batch 51/64 loss: 0.3281891942024231
Batch 52/64 loss: 0.3199000358581543
Batch 53/64 loss: 0.32024455070495605
Batch 54/64 loss: 0.3211911916732788
Batch 55/64 loss: 0.32563483715057373
Batch 56/64 loss: 0.3170873522758484
Batch 57/64 loss: 0.3214244842529297
Batch 58/64 loss: 0.3217430114746094
Batch 59/64 loss: 0.3240947723388672
Batch 60/64 loss: 0.3153422474861145
Batch 61/64 loss: 0.3240317106246948
Batch 62/64 loss: 0.31527137756347656
Batch 63/64 loss: 0.32787275314331055
Batch 64/64 loss: 0.3246094584465027
Epoch 114  Train loss: 0.32214650102690157  Val loss: 0.33041647189261575
Saving best model, epoch: 114
Epoch 115
-------------------------------
Batch 1/64 loss: 0.3210368752479553
Batch 2/64 loss: 0.3196569085121155
Batch 3/64 loss: 0.32359743118286133
Batch 4/64 loss: 0.31760919094085693
Batch 5/64 loss: 0.3218708038330078
Batch 6/64 loss: 0.3217170238494873
Batch 7/64 loss: 0.3222447633743286
Batch 8/64 loss: 0.32330113649368286
Batch 9/64 loss: 0.31987905502319336
Batch 10/64 loss: 0.31969738006591797
Batch 11/64 loss: 0.3236019015312195
Batch 12/64 loss: 0.3170703649520874
Batch 13/64 loss: 0.3217198848724365
Batch 14/64 loss: 0.3170906901359558
Batch 15/64 loss: 0.32030463218688965
Batch 16/64 loss: 0.3219202756881714
Batch 17/64 loss: 0.32189977169036865
Batch 18/64 loss: 0.32180434465408325
Batch 19/64 loss: 0.31866562366485596
Batch 20/64 loss: 0.3177560567855835
Batch 21/64 loss: 0.32110172510147095
Batch 22/64 loss: 0.3214147686958313
Batch 23/64 loss: 0.31819891929626465
Batch 24/64 loss: 0.32284659147262573
Batch 25/64 loss: 0.3163788318634033
Batch 26/64 loss: 0.3256523609161377
Batch 27/64 loss: 0.32616496086120605
Batch 28/64 loss: 0.3245217800140381
Batch 29/64 loss: 0.3278038501739502
Batch 30/64 loss: 0.3199845552444458
Batch 31/64 loss: 0.3220418095588684
Batch 32/64 loss: 0.3198055624961853
Batch 33/64 loss: 0.324216365814209
Batch 34/64 loss: 0.3196815252304077
Batch 35/64 loss: 0.3194500803947449
Batch 36/64 loss: 0.31852567195892334
Batch 37/64 loss: 0.3175586462020874
Batch 38/64 loss: 0.32413965463638306
Batch 39/64 loss: 0.3253902196884155
Batch 40/64 loss: 0.32217347621917725
Batch 41/64 loss: 0.3232482671737671
Batch 42/64 loss: 0.32251429557800293
Batch 43/64 loss: 0.3260415196418762
Batch 44/64 loss: 0.3126866817474365
Batch 45/64 loss: 0.3211713433265686
Batch 46/64 loss: 0.31505274772644043
Batch 47/64 loss: 0.3229539394378662
Batch 48/64 loss: 0.3208826780319214
Batch 49/64 loss: 0.3276712894439697
Batch 50/64 loss: 0.3196380138397217
Batch 51/64 loss: 0.31647080183029175
Batch 52/64 loss: 0.32053834199905396
Batch 53/64 loss: 0.3234783411026001
Batch 54/64 loss: 0.3261033296585083
Batch 55/64 loss: 0.32096534967422485
Batch 56/64 loss: 0.31952011585235596
Batch 57/64 loss: 0.3191789388656616
Batch 58/64 loss: 0.32014530897140503
Batch 59/64 loss: 0.3239274024963379
Batch 60/64 loss: 0.32280582189559937
Batch 61/64 loss: 0.3212582468986511
Batch 62/64 loss: 0.32269591093063354
Batch 63/64 loss: 0.3252423405647278
Batch 64/64 loss: 0.32320982217788696
Epoch 115  Train loss: 0.3213504919818803  Val loss: 0.3304518891364029
Epoch 116
-------------------------------
Batch 1/64 loss: 0.3155679702758789
Batch 2/64 loss: 0.32052528858184814
Batch 3/64 loss: 0.31646400690078735
Batch 4/64 loss: 0.3293722867965698
Batch 5/64 loss: 0.3149423599243164
Batch 6/64 loss: 0.31941473484039307
Batch 7/64 loss: 0.3177482485771179
Batch 8/64 loss: 0.3211066722869873
Batch 9/64 loss: 0.3186678886413574
Batch 10/64 loss: 0.31694817543029785
Batch 11/64 loss: 0.32082033157348633
Batch 12/64 loss: 0.32338857650756836
Batch 13/64 loss: 0.3164905309677124
Batch 14/64 loss: 0.32710230350494385
Batch 15/64 loss: 0.32327497005462646
Batch 16/64 loss: 0.32038652896881104
Batch 17/64 loss: 0.3243899941444397
Batch 18/64 loss: 0.32515794038772583
Batch 19/64 loss: 0.31631457805633545
Batch 20/64 loss: 0.32546526193618774
Batch 21/64 loss: 0.3226775527000427
Batch 22/64 loss: 0.32153189182281494
Batch 23/64 loss: 0.3179650902748108
Batch 24/64 loss: 0.32135534286499023
Batch 25/64 loss: 0.3218986392021179
Batch 26/64 loss: 0.31922709941864014
Batch 27/64 loss: 0.3252143859863281
Batch 28/64 loss: 0.32249534130096436
Batch 29/64 loss: 0.3252341151237488
Batch 30/64 loss: 0.31979548931121826
Batch 31/64 loss: 0.31931042671203613
Batch 32/64 loss: 0.31686604022979736
Batch 33/64 loss: 0.3249478340148926
Batch 34/64 loss: 0.3207970857620239
Batch 35/64 loss: 0.3235715627670288
Batch 36/64 loss: 0.3238248825073242
Batch 37/64 loss: 0.322345495223999
Batch 38/64 loss: 0.31976747512817383
Batch 39/64 loss: 0.3203607201576233
Batch 40/64 loss: 0.3153955936431885
Batch 41/64 loss: 0.3263413906097412
Batch 42/64 loss: 0.3194009065628052
Batch 43/64 loss: 0.3187427520751953
Batch 44/64 loss: 0.32345330715179443
Batch 45/64 loss: 0.320614755153656
Batch 46/64 loss: 0.33095550537109375
Batch 47/64 loss: 0.31720173358917236
Batch 48/64 loss: 0.3189922571182251
Batch 49/64 loss: 0.32706475257873535
Batch 50/64 loss: 0.319379985332489
Batch 51/64 loss: 0.32281792163848877
Batch 52/64 loss: 0.32263875007629395
Batch 53/64 loss: 0.3247830271720886
Batch 54/64 loss: 0.324581503868103
Batch 55/64 loss: 0.31631630659103394
Batch 56/64 loss: 0.3216763138771057
Batch 57/64 loss: 0.32502055168151855
Batch 58/64 loss: 0.3166504502296448
Batch 59/64 loss: 0.32640039920806885
Batch 60/64 loss: 0.31485456228256226
Batch 61/64 loss: 0.3219418525695801
Batch 62/64 loss: 0.32142478227615356
Batch 63/64 loss: 0.3218991756439209
Batch 64/64 loss: 0.31852835416793823
Epoch 116  Train loss: 0.32125772424772675  Val loss: 0.32955045409218964
Saving best model, epoch: 116
Epoch 117
-------------------------------
Batch 1/64 loss: 0.321533739566803
Batch 2/64 loss: 0.32438576221466064
Batch 3/64 loss: 0.3177297115325928
Batch 4/64 loss: 0.3157656788825989
Batch 5/64 loss: 0.3183889389038086
Batch 6/64 loss: 0.3239070177078247
Batch 7/64 loss: 0.32334911823272705
Batch 8/64 loss: 0.3175014853477478
Batch 9/64 loss: 0.31810474395751953
Batch 10/64 loss: 0.32352685928344727
Batch 11/64 loss: 0.3191096782684326
Batch 12/64 loss: 0.3191857933998108
Batch 13/64 loss: 0.3227682113647461
Batch 14/64 loss: 0.3292912244796753
Batch 15/64 loss: 0.32300621271133423
Batch 16/64 loss: 0.32357466220855713
Batch 17/64 loss: 0.3187514543533325
Batch 18/64 loss: 0.321865439414978
Batch 19/64 loss: 0.3234943151473999
Batch 20/64 loss: 0.3243793249130249
Batch 21/64 loss: 0.31827211380004883
Batch 22/64 loss: 0.3212556838989258
Batch 23/64 loss: 0.3179333209991455
Batch 24/64 loss: 0.32114875316619873
Batch 25/64 loss: 0.31950652599334717
Batch 26/64 loss: 0.31746792793273926
Batch 27/64 loss: 0.3226855397224426
Batch 28/64 loss: 0.320361852645874
Batch 29/64 loss: 0.32175230979919434
Batch 30/64 loss: 0.321492075920105
Batch 31/64 loss: 0.32539093494415283
Batch 32/64 loss: 0.31960970163345337
Batch 33/64 loss: 0.32740479707717896
Batch 34/64 loss: 0.3238140344619751
Batch 35/64 loss: 0.32322800159454346
Batch 36/64 loss: 0.3168296813964844
Batch 37/64 loss: 0.32117271423339844
Batch 38/64 loss: 0.3187386989593506
Batch 39/64 loss: 0.32234203815460205
Batch 40/64 loss: 0.3213064670562744
Batch 41/64 loss: 0.32171833515167236
Batch 42/64 loss: 0.3219696283340454
Batch 43/64 loss: 0.3246610164642334
Batch 44/64 loss: 0.3302520513534546
Batch 45/64 loss: 0.3200104236602783
Batch 46/64 loss: 0.3202243447303772
Batch 47/64 loss: 0.3280225992202759
Batch 48/64 loss: 0.32324278354644775
Batch 49/64 loss: 0.3273763656616211
Batch 50/64 loss: 0.31748849153518677
Batch 51/64 loss: 0.32045304775238037
Batch 52/64 loss: 0.31938159465789795
Batch 53/64 loss: 0.3156726360321045
Batch 54/64 loss: 0.32347774505615234
Batch 55/64 loss: 0.32537615299224854
Batch 56/64 loss: 0.3150289058685303
Batch 57/64 loss: 0.32388103008270264
Batch 58/64 loss: 0.32198262214660645
Batch 59/64 loss: 0.3169092535972595
Batch 60/64 loss: 0.3224300742149353
Batch 61/64 loss: 0.32388198375701904
Batch 62/64 loss: 0.31967902183532715
Batch 63/64 loss: 0.31219059228897095
Batch 64/64 loss: 0.32153499126434326
Epoch 117  Train loss: 0.32137716844970105  Val loss: 0.3296504237807493
Epoch 118
-------------------------------
Batch 1/64 loss: 0.32659828662872314
Batch 2/64 loss: 0.32055962085723877
Batch 3/64 loss: 0.3273952007293701
Batch 4/64 loss: 0.32431066036224365
Batch 5/64 loss: 0.31623947620391846
Batch 6/64 loss: 0.3176455497741699
Batch 7/64 loss: 0.3136906623840332
Batch 8/64 loss: 0.31914591789245605
Batch 9/64 loss: 0.3224727511405945
Batch 10/64 loss: 0.31639403104782104
Batch 11/64 loss: 0.3164844512939453
Batch 12/64 loss: 0.3234533667564392
Batch 13/64 loss: 0.3172738552093506
Batch 14/64 loss: 0.32005786895751953
Batch 15/64 loss: 0.3272154927253723
Batch 16/64 loss: 0.3169746398925781
Batch 17/64 loss: 0.32423579692840576
Batch 18/64 loss: 0.3185407519340515
Batch 19/64 loss: 0.3190162777900696
Batch 20/64 loss: 0.31855249404907227
Batch 21/64 loss: 0.32660776376724243
Batch 22/64 loss: 0.32256847620010376
Batch 23/64 loss: 0.3141211271286011
Batch 24/64 loss: 0.31758129596710205
Batch 25/64 loss: 0.31808769702911377
Batch 26/64 loss: 0.32300829887390137
Batch 27/64 loss: 0.32291626930236816
Batch 28/64 loss: 0.3189558982849121
Batch 29/64 loss: 0.31645405292510986
Batch 30/64 loss: 0.32478654384613037
Batch 31/64 loss: 0.3189365267753601
Batch 32/64 loss: 0.3207719326019287
Batch 33/64 loss: 0.32001233100891113
Batch 34/64 loss: 0.31842583417892456
Batch 35/64 loss: 0.3290126323699951
Batch 36/64 loss: 0.32643282413482666
Batch 37/64 loss: 0.3201504945755005
Batch 38/64 loss: 0.3134312033653259
Batch 39/64 loss: 0.32340550422668457
Batch 40/64 loss: 0.3233144283294678
Batch 41/64 loss: 0.3206895589828491
Batch 42/64 loss: 0.3178049325942993
Batch 43/64 loss: 0.32660460472106934
Batch 44/64 loss: 0.32197874784469604
Batch 45/64 loss: 0.3171290159225464
Batch 46/64 loss: 0.3224787712097168
Batch 47/64 loss: 0.32238733768463135
Batch 48/64 loss: 0.3247705101966858
Batch 49/64 loss: 0.32253825664520264
Batch 50/64 loss: 0.3225785493850708
Batch 51/64 loss: 0.32279282808303833
Batch 52/64 loss: 0.31565529108047485
Batch 53/64 loss: 0.31621038913726807
Batch 54/64 loss: 0.3195366859436035
Batch 55/64 loss: 0.3213508129119873
Batch 56/64 loss: 0.3206261396408081
Batch 57/64 loss: 0.31011319160461426
Batch 58/64 loss: 0.3203645348548889
Batch 59/64 loss: 0.31451278924942017
Batch 60/64 loss: 0.3230363130569458
Batch 61/64 loss: 0.3248683214187622
Batch 62/64 loss: 0.31809771060943604
Batch 63/64 loss: 0.31519508361816406
Batch 64/64 loss: 0.318073034286499
Epoch 118  Train loss: 0.32039393630682256  Val loss: 0.3286764728244637
Saving best model, epoch: 118
Epoch 119
-------------------------------
Batch 1/64 loss: 0.3177025318145752
Batch 2/64 loss: 0.320514440536499
Batch 3/64 loss: 0.31858837604522705
Batch 4/64 loss: 0.318758487701416
Batch 5/64 loss: 0.3143693208694458
Batch 6/64 loss: 0.32579749822616577
Batch 7/64 loss: 0.31983304023742676
Batch 8/64 loss: 0.3195902109146118
Batch 9/64 loss: 0.32349270582199097
Batch 10/64 loss: 0.3175966143608093
Batch 11/64 loss: 0.32508331537246704
Batch 12/64 loss: 0.31739360094070435
Batch 13/64 loss: 0.31949371099472046
Batch 14/64 loss: 0.3202078342437744
Batch 15/64 loss: 0.3194624185562134
Batch 16/64 loss: 0.320540189743042
Batch 17/64 loss: 0.3237098455429077
Batch 18/64 loss: 0.3264603614807129
Batch 19/64 loss: 0.3129093050956726
Batch 20/64 loss: 0.3205305337905884
Batch 21/64 loss: 0.3246879577636719
Batch 22/64 loss: 0.3181793689727783
Batch 23/64 loss: 0.31726205348968506
Batch 24/64 loss: 0.32342344522476196
Batch 25/64 loss: 0.3159674406051636
Batch 26/64 loss: 0.3178715705871582
Batch 27/64 loss: 0.3293479084968567
Batch 28/64 loss: 0.3229256868362427
Batch 29/64 loss: 0.31369203329086304
Batch 30/64 loss: 0.3269064426422119
Batch 31/64 loss: 0.3203011751174927
Batch 32/64 loss: 0.3198326826095581
Batch 33/64 loss: 0.3252143859863281
Batch 34/64 loss: 0.32256829738616943
Batch 35/64 loss: 0.31675010919570923
Batch 36/64 loss: 0.3202740550041199
Batch 37/64 loss: 0.3234327435493469
Batch 38/64 loss: 0.31961601972579956
Batch 39/64 loss: 0.3236086964607239
Batch 40/64 loss: 0.3194485902786255
Batch 41/64 loss: 0.3188931941986084
Batch 42/64 loss: 0.32115113735198975
Batch 43/64 loss: 0.3195856213569641
Batch 44/64 loss: 0.3204786777496338
Batch 45/64 loss: 0.31979262828826904
Batch 46/64 loss: 0.3164822459220886
Batch 47/64 loss: 0.3173096179962158
Batch 48/64 loss: 0.3117004632949829
Batch 49/64 loss: 0.3184812068939209
Batch 50/64 loss: 0.32447731494903564
Batch 51/64 loss: 0.3161431550979614
Batch 52/64 loss: 0.3198482394218445
Batch 53/64 loss: 0.31291520595550537
Batch 54/64 loss: 0.3210611343383789
Batch 55/64 loss: 0.3253719210624695
Batch 56/64 loss: 0.3304479122161865
Batch 57/64 loss: 0.31836146116256714
Batch 58/64 loss: 0.31460994482040405
Batch 59/64 loss: 0.3169609308242798
Batch 60/64 loss: 0.32360267639160156
Batch 61/64 loss: 0.3192073702812195
Batch 62/64 loss: 0.3201424479484558
Batch 63/64 loss: 0.3224866986274719
Batch 64/64 loss: 0.32157063484191895
Epoch 119  Train loss: 0.32022014412225464  Val loss: 0.3295602919309819
Epoch 120
-------------------------------
Batch 1/64 loss: 0.3163415193557739
Batch 2/64 loss: 0.3160248398780823
Batch 3/64 loss: 0.3313554525375366
Batch 4/64 loss: 0.3197660446166992
Batch 5/64 loss: 0.31697678565979004
Batch 6/64 loss: 0.32701730728149414
Batch 7/64 loss: 0.31957483291625977
Batch 8/64 loss: 0.3201742172241211
Batch 9/64 loss: 0.3159841299057007
Batch 10/64 loss: 0.3200002908706665
Batch 11/64 loss: 0.3185354471206665
Batch 12/64 loss: 0.3174862265586853
Batch 13/64 loss: 0.3187711238861084
Batch 14/64 loss: 0.3237568140029907
Batch 15/64 loss: 0.3208332061767578
Batch 16/64 loss: 0.3169877529144287
Batch 17/64 loss: 0.3203709125518799
Batch 18/64 loss: 0.3238312005996704
Batch 19/64 loss: 0.3208844065666199
Batch 20/64 loss: 0.3231596350669861
Batch 21/64 loss: 0.3192152976989746
Batch 22/64 loss: 0.3212730884552002
Batch 23/64 loss: 0.3181617259979248
Batch 24/64 loss: 0.3205777406692505
Batch 25/64 loss: 0.3229599595069885
Batch 26/64 loss: 0.3161521553993225
Batch 27/64 loss: 0.31097686290740967
Batch 28/64 loss: 0.3233391046524048
Batch 29/64 loss: 0.3140517473220825
Batch 30/64 loss: 0.31935644149780273
Batch 31/64 loss: 0.31890714168548584
Batch 32/64 loss: 0.32463502883911133
Batch 33/64 loss: 0.3236932158470154
Batch 34/64 loss: 0.3191324472427368
Batch 35/64 loss: 0.32497066259384155
Batch 36/64 loss: 0.31622767448425293
Batch 37/64 loss: 0.31985360383987427
Batch 38/64 loss: 0.3203560709953308
Batch 39/64 loss: 0.3331596851348877
Batch 40/64 loss: 0.3194756507873535
Batch 41/64 loss: 0.3183029890060425
Batch 42/64 loss: 0.31967997550964355
Batch 43/64 loss: 0.3250577449798584
Batch 44/64 loss: 0.3195195198059082
Batch 45/64 loss: 0.3207433819770813
Batch 46/64 loss: 0.31909680366516113
Batch 47/64 loss: 0.32226693630218506
Batch 48/64 loss: 0.31266164779663086
Batch 49/64 loss: 0.3149538040161133
Batch 50/64 loss: 0.3166958689689636
Batch 51/64 loss: 0.31461483240127563
Batch 52/64 loss: 0.3174806237220764
Batch 53/64 loss: 0.3212292194366455
Batch 54/64 loss: 0.31744128465652466
Batch 55/64 loss: 0.3192363381385803
Batch 56/64 loss: 0.31604498624801636
Batch 57/64 loss: 0.31912410259246826
Batch 58/64 loss: 0.3174390196800232
Batch 59/64 loss: 0.321260929107666
Batch 60/64 loss: 0.31711500883102417
Batch 61/64 loss: 0.32117581367492676
Batch 62/64 loss: 0.32241833209991455
Batch 63/64 loss: 0.32124364376068115
Batch 64/64 loss: 0.3139241337776184
Epoch 120  Train loss: 0.319757699732687  Val loss: 0.32926572188478975
Epoch 121
-------------------------------
Batch 1/64 loss: 0.31704050302505493
Batch 2/64 loss: 0.31904101371765137
Batch 3/64 loss: 0.3196980953216553
Batch 4/64 loss: 0.31966543197631836
Batch 5/64 loss: 0.3167811632156372
Batch 6/64 loss: 0.3285685181617737
Batch 7/64 loss: 0.3189293146133423
Batch 8/64 loss: 0.31731826066970825
Batch 9/64 loss: 0.321320116519928
Batch 10/64 loss: 0.31757378578186035
Batch 11/64 loss: 0.32903802394866943
Batch 12/64 loss: 0.32198256254196167
Batch 13/64 loss: 0.31947004795074463
Batch 14/64 loss: 0.3181254267692566
Batch 15/64 loss: 0.3211016058921814
Batch 16/64 loss: 0.3202855587005615
Batch 17/64 loss: 0.31587034463882446
Batch 18/64 loss: 0.3191075325012207
Batch 19/64 loss: 0.31370675563812256
Batch 20/64 loss: 0.32039523124694824
Batch 21/64 loss: 0.31525707244873047
Batch 22/64 loss: 0.31946635246276855
Batch 23/64 loss: 0.3153010606765747
Batch 24/64 loss: 0.3174173831939697
Batch 25/64 loss: 0.32005399465560913
Batch 26/64 loss: 0.3190586566925049
Batch 27/64 loss: 0.3083813190460205
Batch 28/64 loss: 0.31850308179855347
Batch 29/64 loss: 0.31202858686447144
Batch 30/64 loss: 0.3223402500152588
Batch 31/64 loss: 0.3176785707473755
Batch 32/64 loss: 0.3171052932739258
Batch 33/64 loss: 0.3193977475166321
Batch 34/64 loss: 0.3222927451133728
Batch 35/64 loss: 0.32043981552124023
Batch 36/64 loss: 0.3156420588493347
Batch 37/64 loss: 0.32368016242980957
Batch 38/64 loss: 0.3146752119064331
Batch 39/64 loss: 0.3210013508796692
Batch 40/64 loss: 0.3153649568557739
Batch 41/64 loss: 0.3172680139541626
Batch 42/64 loss: 0.32325106859207153
Batch 43/64 loss: 0.3249499797821045
Batch 44/64 loss: 0.31809431314468384
Batch 45/64 loss: 0.3169294595718384
Batch 46/64 loss: 0.32899296283721924
Batch 47/64 loss: 0.32430487871170044
Batch 48/64 loss: 0.31859833002090454
Batch 49/64 loss: 0.3201028108596802
Batch 50/64 loss: 0.315061092376709
Batch 51/64 loss: 0.32699906826019287
Batch 52/64 loss: 0.3251619338989258
Batch 53/64 loss: 0.31580930948257446
Batch 54/64 loss: 0.318156898021698
Batch 55/64 loss: 0.3218425512313843
Batch 56/64 loss: 0.318351149559021
Batch 57/64 loss: 0.32199281454086304
Batch 58/64 loss: 0.3159390091896057
Batch 59/64 loss: 0.3196679353713989
Batch 60/64 loss: 0.32273757457733154
Batch 61/64 loss: 0.32529544830322266
Batch 62/64 loss: 0.31564217805862427
Batch 63/64 loss: 0.3202400207519531
Batch 64/64 loss: 0.31947505474090576
Epoch 121  Train loss: 0.31945254989698824  Val loss: 0.32815946950945246
Saving best model, epoch: 121
Epoch 122
-------------------------------
Batch 1/64 loss: 0.3198888301849365
Batch 2/64 loss: 0.3177773952484131
Batch 3/64 loss: 0.3232400417327881
Batch 4/64 loss: 0.32218533754348755
Batch 5/64 loss: 0.3136420249938965
Batch 6/64 loss: 0.3160109519958496
Batch 7/64 loss: 0.3171613812446594
Batch 8/64 loss: 0.3204713463783264
Batch 9/64 loss: 0.32121992111206055
Batch 10/64 loss: 0.3126235008239746
Batch 11/64 loss: 0.31896328926086426
Batch 12/64 loss: 0.3180941343307495
Batch 13/64 loss: 0.3162093162536621
Batch 14/64 loss: 0.3161793351173401
Batch 15/64 loss: 0.32089781761169434
Batch 16/64 loss: 0.3127570152282715
Batch 17/64 loss: 0.31880319118499756
Batch 18/64 loss: 0.31853508949279785
Batch 19/64 loss: 0.3179807662963867
Batch 20/64 loss: 0.31901758909225464
Batch 21/64 loss: 0.32430434226989746
Batch 22/64 loss: 0.3189725875854492
Batch 23/64 loss: 0.3196178674697876
Batch 24/64 loss: 0.31035327911376953
Batch 25/64 loss: 0.3158857822418213
Batch 26/64 loss: 0.31695908308029175
Batch 27/64 loss: 0.3157657980918884
Batch 28/64 loss: 0.32066988945007324
Batch 29/64 loss: 0.31336498260498047
Batch 30/64 loss: 0.3182404041290283
Batch 31/64 loss: 0.3251476287841797
Batch 32/64 loss: 0.3165401220321655
Batch 33/64 loss: 0.31978750228881836
Batch 34/64 loss: 0.3202490210533142
Batch 35/64 loss: 0.31802213191986084
Batch 36/64 loss: 0.3228003978729248
Batch 37/64 loss: 0.32363367080688477
Batch 38/64 loss: 0.3186436891555786
Batch 39/64 loss: 0.31999677419662476
Batch 40/64 loss: 0.31925058364868164
Batch 41/64 loss: 0.3210798501968384
Batch 42/64 loss: 0.31226176023483276
Batch 43/64 loss: 0.31491464376449585
Batch 44/64 loss: 0.3204134702682495
Batch 45/64 loss: 0.3225820064544678
Batch 46/64 loss: 0.31688010692596436
Batch 47/64 loss: 0.31970542669296265
Batch 48/64 loss: 0.3181164264678955
Batch 49/64 loss: 0.31625640392303467
Batch 50/64 loss: 0.3132970333099365
Batch 51/64 loss: 0.3148927092552185
Batch 52/64 loss: 0.3247145414352417
Batch 53/64 loss: 0.31928348541259766
Batch 54/64 loss: 0.3178821802139282
Batch 55/64 loss: 0.32526272535324097
Batch 56/64 loss: 0.31992000341415405
Batch 57/64 loss: 0.32044434547424316
Batch 58/64 loss: 0.31888169050216675
Batch 59/64 loss: 0.3225623369216919
Batch 60/64 loss: 0.31973934173583984
Batch 61/64 loss: 0.3201693296432495
Batch 62/64 loss: 0.31444597244262695
Batch 63/64 loss: 0.32447147369384766
Batch 64/64 loss: 0.31530851125717163
Epoch 122  Train loss: 0.3186591758447535  Val loss: 0.32800899338476436
Saving best model, epoch: 122
Epoch 123
-------------------------------
Batch 1/64 loss: 0.31921613216400146
Batch 2/64 loss: 0.31688523292541504
Batch 3/64 loss: 0.31607985496520996
Batch 4/64 loss: 0.31407785415649414
Batch 5/64 loss: 0.321358323097229
Batch 6/64 loss: 0.32021862268447876
Batch 7/64 loss: 0.3146376609802246
Batch 8/64 loss: 0.31506597995758057
Batch 9/64 loss: 0.3201074004173279
Batch 10/64 loss: 0.3230364918708801
Batch 11/64 loss: 0.31496596336364746
Batch 12/64 loss: 0.3097118139266968
Batch 13/64 loss: 0.3241596817970276
Batch 14/64 loss: 0.31714391708374023
Batch 15/64 loss: 0.3163491487503052
Batch 16/64 loss: 0.31718140840530396
Batch 17/64 loss: 0.3112238645553589
Batch 18/64 loss: 0.3188273310661316
Batch 19/64 loss: 0.32081782817840576
Batch 20/64 loss: 0.3208202123641968
Batch 21/64 loss: 0.31617701053619385
Batch 22/64 loss: 0.3138771653175354
Batch 23/64 loss: 0.31963050365448
Batch 24/64 loss: 0.3210236430168152
Batch 25/64 loss: 0.3135873079299927
Batch 26/64 loss: 0.3176751136779785
Batch 27/64 loss: 0.3205077648162842
Batch 28/64 loss: 0.3147481679916382
Batch 29/64 loss: 0.32291674613952637
Batch 30/64 loss: 0.32102179527282715
Batch 31/64 loss: 0.31951355934143066
Batch 32/64 loss: 0.32219529151916504
Batch 33/64 loss: 0.3208455443382263
Batch 34/64 loss: 0.31773799657821655
Batch 35/64 loss: 0.3173081874847412
Batch 36/64 loss: 0.3255947232246399
Batch 37/64 loss: 0.31299352645874023
Batch 38/64 loss: 0.31446564197540283
Batch 39/64 loss: 0.31323516368865967
Batch 40/64 loss: 0.3176310062408447
Batch 41/64 loss: 0.3229343295097351
Batch 42/64 loss: 0.32227879762649536
Batch 43/64 loss: 0.3180321455001831
Batch 44/64 loss: 0.31504833698272705
Batch 45/64 loss: 0.3162105083465576
Batch 46/64 loss: 0.31935471296310425
Batch 47/64 loss: 0.32227981090545654
Batch 48/64 loss: 0.31705963611602783
Batch 49/64 loss: 0.3199520707130432
Batch 50/64 loss: 0.314511239528656
Batch 51/64 loss: 0.322085976600647
Batch 52/64 loss: 0.32439684867858887
Batch 53/64 loss: 0.31838440895080566
Batch 54/64 loss: 0.31687867641448975
Batch 55/64 loss: 0.3185752034187317
Batch 56/64 loss: 0.31705695390701294
Batch 57/64 loss: 0.318902850151062
Batch 58/64 loss: 0.3219090700149536
Batch 59/64 loss: 0.3183739185333252
Batch 60/64 loss: 0.32888972759246826
Batch 61/64 loss: 0.3151651620864868
Batch 62/64 loss: 0.31658458709716797
Batch 63/64 loss: 0.31128013134002686
Batch 64/64 loss: 0.31859004497528076
Epoch 123  Train loss: 0.3182691485274072  Val loss: 0.32795394081430335
Saving best model, epoch: 123
Epoch 124
-------------------------------
Batch 1/64 loss: 0.32009822130203247
Batch 2/64 loss: 0.3207853436470032
Batch 3/64 loss: 0.3204227089881897
Batch 4/64 loss: 0.3166186213493347
Batch 5/64 loss: 0.3194335699081421
Batch 6/64 loss: 0.3147552013397217
Batch 7/64 loss: 0.31653499603271484
Batch 8/64 loss: 0.3153733015060425
Batch 9/64 loss: 0.31981104612350464
Batch 10/64 loss: 0.32090336084365845
Batch 11/64 loss: 0.3190596103668213
Batch 12/64 loss: 0.3278580904006958
Batch 13/64 loss: 0.32399535179138184
Batch 14/64 loss: 0.3138514757156372
Batch 15/64 loss: 0.31301599740982056
Batch 16/64 loss: 0.3209567070007324
Batch 17/64 loss: 0.3142450451850891
Batch 18/64 loss: 0.3173006772994995
Batch 19/64 loss: 0.31418418884277344
Batch 20/64 loss: 0.3142191171646118
Batch 21/64 loss: 0.3193695545196533
Batch 22/64 loss: 0.3151669502258301
Batch 23/64 loss: 0.312738299369812
Batch 24/64 loss: 0.3154347538948059
Batch 25/64 loss: 0.3212074041366577
Batch 26/64 loss: 0.3167949914932251
Batch 27/64 loss: 0.3093695640563965
Batch 28/64 loss: 0.31735944747924805
Batch 29/64 loss: 0.3158966302871704
Batch 30/64 loss: 0.31596094369888306
Batch 31/64 loss: 0.31480687856674194
Batch 32/64 loss: 0.31776154041290283
Batch 33/64 loss: 0.3132922649383545
Batch 34/64 loss: 0.31626665592193604
Batch 35/64 loss: 0.31405407190322876
Batch 36/64 loss: 0.3209751844406128
Batch 37/64 loss: 0.31370747089385986
Batch 38/64 loss: 0.31951385736465454
Batch 39/64 loss: 0.3193843364715576
Batch 40/64 loss: 0.3115108609199524
Batch 41/64 loss: 0.31704938411712646
Batch 42/64 loss: 0.3174542784690857
Batch 43/64 loss: 0.31860846281051636
Batch 44/64 loss: 0.32065093517303467
Batch 45/64 loss: 0.3136770725250244
Batch 46/64 loss: 0.32042986154556274
Batch 47/64 loss: 0.3131372332572937
Batch 48/64 loss: 0.3152754306793213
Batch 49/64 loss: 0.31644606590270996
Batch 50/64 loss: 0.3146958351135254
Batch 51/64 loss: 0.3220556378364563
Batch 52/64 loss: 0.31609970331192017
Batch 53/64 loss: 0.316180944442749
Batch 54/64 loss: 0.32024234533309937
Batch 55/64 loss: 0.3166687488555908
Batch 56/64 loss: 0.322080135345459
Batch 57/64 loss: 0.32374370098114014
Batch 58/64 loss: 0.3185732960700989
Batch 59/64 loss: 0.31306374073028564
Batch 60/64 loss: 0.3249243497848511
Batch 61/64 loss: 0.3205339312553406
Batch 62/64 loss: 0.3150380849838257
Batch 63/64 loss: 0.317658007144928
Batch 64/64 loss: 0.32237493991851807
Epoch 124  Train loss: 0.3174911793540506  Val loss: 0.32760948577697335
Saving best model, epoch: 124
Epoch 125
-------------------------------
Batch 1/64 loss: 0.319236695766449
Batch 2/64 loss: 0.31572896242141724
Batch 3/64 loss: 0.32337361574172974
Batch 4/64 loss: 0.3149821162223816
Batch 5/64 loss: 0.3134390115737915
Batch 6/64 loss: 0.31494271755218506
Batch 7/64 loss: 0.32073843479156494
Batch 8/64 loss: 0.3197495937347412
Batch 9/64 loss: 0.3114287257194519
Batch 10/64 loss: 0.31441372632980347
Batch 11/64 loss: 0.3152427673339844
Batch 12/64 loss: 0.3220425844192505
Batch 13/64 loss: 0.3310898542404175
Batch 14/64 loss: 0.31939518451690674
Batch 15/64 loss: 0.3131561279296875
Batch 16/64 loss: 0.3094697594642639
Batch 17/64 loss: 0.31956005096435547
Batch 18/64 loss: 0.3159443140029907
Batch 19/64 loss: 0.3208613395690918
Batch 20/64 loss: 0.3160911798477173
Batch 21/64 loss: 0.3162703514099121
Batch 22/64 loss: 0.3197421431541443
Batch 23/64 loss: 0.31920796632766724
Batch 24/64 loss: 0.3186436891555786
Batch 25/64 loss: 0.31829750537872314
Batch 26/64 loss: 0.3192657232284546
Batch 27/64 loss: 0.3174154758453369
Batch 28/64 loss: 0.3168281316757202
Batch 29/64 loss: 0.31626468896865845
Batch 30/64 loss: 0.3199275732040405
Batch 31/64 loss: 0.3172435760498047
Batch 32/64 loss: 0.32338201999664307
Batch 33/64 loss: 0.31691479682922363
Batch 34/64 loss: 0.31741976737976074
Batch 35/64 loss: 0.31447547674179077
Batch 36/64 loss: 0.31479233503341675
Batch 37/64 loss: 0.31479352712631226
Batch 38/64 loss: 0.31701380014419556
Batch 39/64 loss: 0.3203413486480713
Batch 40/64 loss: 0.32260024547576904
Batch 41/64 loss: 0.31321078538894653
Batch 42/64 loss: 0.3167386054992676
Batch 43/64 loss: 0.3183051347732544
Batch 44/64 loss: 0.31668806076049805
Batch 45/64 loss: 0.31319284439086914
Batch 46/64 loss: 0.3201650381088257
Batch 47/64 loss: 0.31264281272888184
Batch 48/64 loss: 0.3159979581832886
Batch 49/64 loss: 0.3182005286216736
Batch 50/64 loss: 0.32236921787261963
Batch 51/64 loss: 0.31914108991622925
Batch 52/64 loss: 0.3136768341064453
Batch 53/64 loss: 0.3166678547859192
Batch 54/64 loss: 0.31928080320358276
Batch 55/64 loss: 0.31787562370300293
Batch 56/64 loss: 0.32065117359161377
Batch 57/64 loss: 0.31352412700653076
Batch 58/64 loss: 0.32054412364959717
Batch 59/64 loss: 0.31969165802001953
Batch 60/64 loss: 0.3230305314064026
Batch 61/64 loss: 0.31953608989715576
Batch 62/64 loss: 0.3288000822067261
Batch 63/64 loss: 0.3174649477005005
Batch 64/64 loss: 0.3163919448852539
Epoch 125  Train loss: 0.31790457706825404  Val loss: 0.327640638933149
Epoch 126
-------------------------------
Batch 1/64 loss: 0.31347763538360596
Batch 2/64 loss: 0.3146284818649292
Batch 3/64 loss: 0.3226742744445801
Batch 4/64 loss: 0.3187755346298218
Batch 5/64 loss: 0.31641554832458496
Batch 6/64 loss: 0.3131563663482666
Batch 7/64 loss: 0.31855684518814087
Batch 8/64 loss: 0.3142765164375305
Batch 9/64 loss: 0.3186495304107666
Batch 10/64 loss: 0.3167603015899658
Batch 11/64 loss: 0.3208659887313843
Batch 12/64 loss: 0.31946688890457153
Batch 13/64 loss: 0.3221815228462219
Batch 14/64 loss: 0.31922388076782227
Batch 15/64 loss: 0.32661861181259155
Batch 16/64 loss: 0.3186851143836975
Batch 17/64 loss: 0.3255549669265747
Batch 18/64 loss: 0.3138689398765564
Batch 19/64 loss: 0.3123921751976013
Batch 20/64 loss: 0.3150550127029419
Batch 21/64 loss: 0.31489747762680054
Batch 22/64 loss: 0.3212014436721802
Batch 23/64 loss: 0.3140849471092224
Batch 24/64 loss: 0.3180239200592041
Batch 25/64 loss: 0.3178670406341553
Batch 26/64 loss: 0.32048118114471436
Batch 27/64 loss: 0.3185596466064453
Batch 28/64 loss: 0.3194115161895752
Batch 29/64 loss: 0.3227274417877197
Batch 30/64 loss: 0.3218074440956116
Batch 31/64 loss: 0.3154750466346741
Batch 32/64 loss: 0.3222278952598572
Batch 33/64 loss: 0.31335127353668213
Batch 34/64 loss: 0.3184189796447754
Batch 35/64 loss: 0.3198206424713135
Batch 36/64 loss: 0.3146803379058838
Batch 37/64 loss: 0.31663978099823
Batch 38/64 loss: 0.3166615962982178
Batch 39/64 loss: 0.3137419819831848
Batch 40/64 loss: 0.31798607110977173
Batch 41/64 loss: 0.31841278076171875
Batch 42/64 loss: 0.31413590908050537
Batch 43/64 loss: 0.3118131160736084
Batch 44/64 loss: 0.3175816535949707
Batch 45/64 loss: 0.31641650199890137
Batch 46/64 loss: 0.3170156478881836
Batch 47/64 loss: 0.30929434299468994
Batch 48/64 loss: 0.3134756088256836
Batch 49/64 loss: 0.31377220153808594
Batch 50/64 loss: 0.31887221336364746
Batch 51/64 loss: 0.3208288550376892
Batch 52/64 loss: 0.3136940002441406
Batch 53/64 loss: 0.3160665035247803
Batch 54/64 loss: 0.3154102563858032
Batch 55/64 loss: 0.30708521604537964
Batch 56/64 loss: 0.31427884101867676
Batch 57/64 loss: 0.31417858600616455
Batch 58/64 loss: 0.3163052797317505
Batch 59/64 loss: 0.312755286693573
Batch 60/64 loss: 0.3141241669654846
Batch 61/64 loss: 0.3154783248901367
Batch 62/64 loss: 0.3221266269683838
Batch 63/64 loss: 0.31552809476852417
Batch 64/64 loss: 0.31858372688293457
Epoch 126  Train loss: 0.31697157037024404  Val loss: 0.326247844704238
Saving best model, epoch: 126
Epoch 127
-------------------------------
Batch 1/64 loss: 0.31422871351242065
Batch 2/64 loss: 0.3108590841293335
Batch 3/64 loss: 0.3136112689971924
Batch 4/64 loss: 0.3185161352157593
Batch 5/64 loss: 0.31627124547958374
Batch 6/64 loss: 0.32069844007492065
Batch 7/64 loss: 0.3163200616836548
Batch 8/64 loss: 0.3141719102859497
Batch 9/64 loss: 0.322812020778656
Batch 10/64 loss: 0.31945717334747314
Batch 11/64 loss: 0.32651400566101074
Batch 12/64 loss: 0.3148003816604614
Batch 13/64 loss: 0.3160439133644104
Batch 14/64 loss: 0.31944864988327026
Batch 15/64 loss: 0.31637126207351685
Batch 16/64 loss: 0.31331920623779297
Batch 17/64 loss: 0.3166968822479248
Batch 18/64 loss: 0.30933958292007446
Batch 19/64 loss: 0.31437957286834717
Batch 20/64 loss: 0.3185165524482727
Batch 21/64 loss: 0.3147547245025635
Batch 22/64 loss: 0.31472641229629517
Batch 23/64 loss: 0.31695663928985596
Batch 24/64 loss: 0.3143573999404907
Batch 25/64 loss: 0.31800055503845215
Batch 26/64 loss: 0.3190891146659851
Batch 27/64 loss: 0.31696271896362305
Batch 28/64 loss: 0.31126654148101807
Batch 29/64 loss: 0.31492453813552856
Batch 30/64 loss: 0.3127390742301941
Batch 31/64 loss: 0.3177782893180847
Batch 32/64 loss: 0.31792008876800537
Batch 33/64 loss: 0.3210170865058899
Batch 34/64 loss: 0.31724417209625244
Batch 35/64 loss: 0.31853652000427246
Batch 36/64 loss: 0.32049405574798584
Batch 37/64 loss: 0.3178832530975342
Batch 38/64 loss: 0.3147464990615845
Batch 39/64 loss: 0.32209551334381104
Batch 40/64 loss: 0.31608128547668457
Batch 41/64 loss: 0.31895577907562256
Batch 42/64 loss: 0.3108440041542053
Batch 43/64 loss: 0.3161237835884094
Batch 44/64 loss: 0.31652510166168213
Batch 45/64 loss: 0.32348954677581787
Batch 46/64 loss: 0.32160240411758423
Batch 47/64 loss: 0.3170543313026428
Batch 48/64 loss: 0.3142780661582947
Batch 49/64 loss: 0.3198556900024414
Batch 50/64 loss: 0.3150399923324585
Batch 51/64 loss: 0.313602089881897
Batch 52/64 loss: 0.31381523609161377
Batch 53/64 loss: 0.31375008821487427
Batch 54/64 loss: 0.3143136501312256
Batch 55/64 loss: 0.3127872943878174
Batch 56/64 loss: 0.31244516372680664
Batch 57/64 loss: 0.32108074426651
Batch 58/64 loss: 0.3129163980484009
Batch 59/64 loss: 0.31831157207489014
Batch 60/64 loss: 0.3186224699020386
Batch 61/64 loss: 0.3191087245941162
Batch 62/64 loss: 0.31189513206481934
Batch 63/64 loss: 0.32241642475128174
Batch 64/64 loss: 0.31691378355026245
Epoch 127  Train loss: 0.3166505030557221  Val loss: 0.32693408035330757
Epoch 128
-------------------------------
Batch 1/64 loss: 0.3104006052017212
Batch 2/64 loss: 0.3218287229537964
Batch 3/64 loss: 0.31622010469436646
Batch 4/64 loss: 0.3187945485115051
Batch 5/64 loss: 0.3107295632362366
Batch 6/64 loss: 0.31936752796173096
Batch 7/64 loss: 0.3165152072906494
Batch 8/64 loss: 0.31893354654312134
Batch 9/64 loss: 0.3122180700302124
Batch 10/64 loss: 0.3186337947845459
Batch 11/64 loss: 0.31845372915267944
Batch 12/64 loss: 0.3191758990287781
Batch 13/64 loss: 0.3143831491470337
Batch 14/64 loss: 0.31453025341033936
Batch 15/64 loss: 0.31357240676879883
Batch 16/64 loss: 0.31961584091186523
Batch 17/64 loss: 0.3130836486816406
Batch 18/64 loss: 0.3137744665145874
Batch 19/64 loss: 0.3165568709373474
Batch 20/64 loss: 0.31355130672454834
Batch 21/64 loss: 0.31652212142944336
Batch 22/64 loss: 0.3168862462043762
Batch 23/64 loss: 0.30939656496047974
Batch 24/64 loss: 0.31175607442855835
Batch 25/64 loss: 0.3159447908401489
Batch 26/64 loss: 0.3114124536514282
Batch 27/64 loss: 0.31555449962615967
Batch 28/64 loss: 0.31510448455810547
Batch 29/64 loss: 0.31787633895874023
Batch 30/64 loss: 0.32016241550445557
Batch 31/64 loss: 0.31271034479141235
Batch 32/64 loss: 0.30758535861968994
Batch 33/64 loss: 0.32356810569763184
Batch 34/64 loss: 0.3150111436843872
Batch 35/64 loss: 0.3139611482620239
Batch 36/64 loss: 0.3169471025466919
Batch 37/64 loss: 0.3179450035095215
Batch 38/64 loss: 0.3112809658050537
Batch 39/64 loss: 0.3163052201271057
Batch 40/64 loss: 0.3208073377609253
Batch 41/64 loss: 0.31683093309402466
Batch 42/64 loss: 0.31735479831695557
Batch 43/64 loss: 0.31544119119644165
Batch 44/64 loss: 0.32088756561279297
Batch 45/64 loss: 0.3160611391067505
Batch 46/64 loss: 0.31562745571136475
Batch 47/64 loss: 0.3140355348587036
Batch 48/64 loss: 0.3160918951034546
Batch 49/64 loss: 0.31269121170043945
Batch 50/64 loss: 0.32553625106811523
Batch 51/64 loss: 0.330089807510376
Batch 52/64 loss: 0.3179284334182739
Batch 53/64 loss: 0.30941617488861084
Batch 54/64 loss: 0.3177221417427063
Batch 55/64 loss: 0.3144739866256714
Batch 56/64 loss: 0.32036375999450684
Batch 57/64 loss: 0.3211996555328369
Batch 58/64 loss: 0.3199605941772461
Batch 59/64 loss: 0.31881725788116455
Batch 60/64 loss: 0.31401342153549194
Batch 61/64 loss: 0.3138391971588135
Batch 62/64 loss: 0.3207014799118042
Batch 63/64 loss: 0.31609606742858887
Batch 64/64 loss: 0.31670081615448
Epoch 128  Train loss: 0.31638874586890725  Val loss: 0.3278396416365896
Epoch 129
-------------------------------
Batch 1/64 loss: 0.31497812271118164
Batch 2/64 loss: 0.3192002773284912
Batch 3/64 loss: 0.31359076499938965
Batch 4/64 loss: 0.3132619261741638
Batch 5/64 loss: 0.31350117921829224
Batch 6/64 loss: 0.31631648540496826
Batch 7/64 loss: 0.3182758092880249
Batch 8/64 loss: 0.31508398056030273
Batch 9/64 loss: 0.3130527138710022
Batch 10/64 loss: 0.3183925151824951
Batch 11/64 loss: 0.32491207122802734
Batch 12/64 loss: 0.3133842945098877
Batch 13/64 loss: 0.31971001625061035
Batch 14/64 loss: 0.3181658387184143
Batch 15/64 loss: 0.31970036029815674
Batch 16/64 loss: 0.32188326120376587
Batch 17/64 loss: 0.32109004259109497
Batch 18/64 loss: 0.3241472840309143
Batch 19/64 loss: 0.31327366828918457
Batch 20/64 loss: 0.3133774399757385
Batch 21/64 loss: 0.32046008110046387
Batch 22/64 loss: 0.31440985202789307
Batch 23/64 loss: 0.3160552382469177
Batch 24/64 loss: 0.3219553828239441
Batch 25/64 loss: 0.31388014554977417
Batch 26/64 loss: 0.31754767894744873
Batch 27/64 loss: 0.31264984607696533
Batch 28/64 loss: 0.3182797431945801
Batch 29/64 loss: 0.3146066665649414
Batch 30/64 loss: 0.32094061374664307
Batch 31/64 loss: 0.3130218982696533
Batch 32/64 loss: 0.31777071952819824
Batch 33/64 loss: 0.32163166999816895
Batch 34/64 loss: 0.3103795051574707
Batch 35/64 loss: 0.3139324188232422
Batch 36/64 loss: 0.3187558650970459
Batch 37/64 loss: 0.31768369674682617
Batch 38/64 loss: 0.31399571895599365
Batch 39/64 loss: 0.3169372081756592
Batch 40/64 loss: 0.31592148542404175
Batch 41/64 loss: 0.3204224109649658
Batch 42/64 loss: 0.3161548376083374
Batch 43/64 loss: 0.3110371232032776
Batch 44/64 loss: 0.3140218257904053
Batch 45/64 loss: 0.314613938331604
Batch 46/64 loss: 0.31825971603393555
Batch 47/64 loss: 0.3160301446914673
Batch 48/64 loss: 0.32299935817718506
Batch 49/64 loss: 0.3132894039154053
Batch 50/64 loss: 0.3190029263496399
Batch 51/64 loss: 0.3108478784561157
Batch 52/64 loss: 0.31314152479171753
Batch 53/64 loss: 0.3188517093658447
Batch 54/64 loss: 0.30876874923706055
Batch 55/64 loss: 0.3159058690071106
Batch 56/64 loss: 0.3150227665901184
Batch 57/64 loss: 0.310921311378479
Batch 58/64 loss: 0.3205235004425049
Batch 59/64 loss: 0.31828200817108154
Batch 60/64 loss: 0.32077229022979736
Batch 61/64 loss: 0.3095088005065918
Batch 62/64 loss: 0.31946897506713867
Batch 63/64 loss: 0.3116675615310669
Batch 64/64 loss: 0.3126697540283203
Epoch 129  Train loss: 0.3163942028494442  Val loss: 0.32630451581732106
Epoch 130
-------------------------------
Batch 1/64 loss: 0.32207632064819336
Batch 2/64 loss: 0.3125149607658386
Batch 3/64 loss: 0.31281447410583496
Batch 4/64 loss: 0.3161088228225708
Batch 5/64 loss: 0.31875789165496826
Batch 6/64 loss: 0.3168318271636963
Batch 7/64 loss: 0.31243896484375
Batch 8/64 loss: 0.309314489364624
Batch 9/64 loss: 0.3203137516975403
Batch 10/64 loss: 0.31475144624710083
Batch 11/64 loss: 0.3196987509727478
Batch 12/64 loss: 0.31813663244247437
Batch 13/64 loss: 0.31578314304351807
Batch 14/64 loss: 0.3083459734916687
Batch 15/64 loss: 0.315218448638916
Batch 16/64 loss: 0.31778067350387573
Batch 17/64 loss: 0.3198891878128052
Batch 18/64 loss: 0.3210352659225464
Batch 19/64 loss: 0.31803756952285767
Batch 20/64 loss: 0.3184773921966553
Batch 21/64 loss: 0.3180772662162781
Batch 22/64 loss: 0.31213700771331787
Batch 23/64 loss: 0.31338441371917725
Batch 24/64 loss: 0.3174717426300049
Batch 25/64 loss: 0.3158414363861084
Batch 26/64 loss: 0.3195751905441284
Batch 27/64 loss: 0.312150776386261
Batch 28/64 loss: 0.3123600482940674
Batch 29/64 loss: 0.3123009204864502
Batch 30/64 loss: 0.3139113187789917
Batch 31/64 loss: 0.320210337638855
Batch 32/64 loss: 0.30717694759368896
Batch 33/64 loss: 0.314414381980896
Batch 34/64 loss: 0.3164605498313904
Batch 35/64 loss: 0.31356585025787354
Batch 36/64 loss: 0.3112902045249939
Batch 37/64 loss: 0.3147919178009033
Batch 38/64 loss: 0.31488943099975586
Batch 39/64 loss: 0.31592029333114624
Batch 40/64 loss: 0.31746023893356323
Batch 41/64 loss: 0.32041847705841064
Batch 42/64 loss: 0.3111926317214966
Batch 43/64 loss: 0.3214893937110901
Batch 44/64 loss: 0.3173779249191284
Batch 45/64 loss: 0.31756603717803955
Batch 46/64 loss: 0.3174550533294678
Batch 47/64 loss: 0.31458187103271484
Batch 48/64 loss: 0.3124382495880127
Batch 49/64 loss: 0.3175661563873291
Batch 50/64 loss: 0.3119703531265259
Batch 51/64 loss: 0.31575626134872437
Batch 52/64 loss: 0.3114113211631775
Batch 53/64 loss: 0.3125987648963928
Batch 54/64 loss: 0.31436365842819214
Batch 55/64 loss: 0.3140336871147156
Batch 56/64 loss: 0.3138735294342041
Batch 57/64 loss: 0.3127171993255615
Batch 58/64 loss: 0.3187044858932495
Batch 59/64 loss: 0.31907427310943604
Batch 60/64 loss: 0.30756187438964844
Batch 61/64 loss: 0.31161099672317505
Batch 62/64 loss: 0.31297117471694946
Batch 63/64 loss: 0.31393641233444214
Batch 64/64 loss: 0.3210066556930542
Epoch 130  Train loss: 0.31534338885662605  Val loss: 0.32619303751647266
Saving best model, epoch: 130
Epoch 131
-------------------------------
Batch 1/64 loss: 0.31462526321411133
Batch 2/64 loss: 0.3176560401916504
Batch 3/64 loss: 0.3195040822029114
Batch 4/64 loss: 0.31714141368865967
Batch 5/64 loss: 0.31216758489608765
Batch 6/64 loss: 0.3161115050315857
Batch 7/64 loss: 0.32110846042633057
Batch 8/64 loss: 0.3167007565498352
Batch 9/64 loss: 0.3109126091003418
Batch 10/64 loss: 0.3137052059173584
Batch 11/64 loss: 0.3136484622955322
Batch 12/64 loss: 0.3153870105743408
Batch 13/64 loss: 0.31776225566864014
Batch 14/64 loss: 0.3112506866455078
Batch 15/64 loss: 0.31102025508880615
Batch 16/64 loss: 0.3133065700531006
Batch 17/64 loss: 0.31552690267562866
Batch 18/64 loss: 0.3130374550819397
Batch 19/64 loss: 0.3161616325378418
Batch 20/64 loss: 0.3135862350463867
Batch 21/64 loss: 0.3143436312675476
Batch 22/64 loss: 0.3146003484725952
Batch 23/64 loss: 0.3118135333061218
Batch 24/64 loss: 0.31331300735473633
Batch 25/64 loss: 0.3194345235824585
Batch 26/64 loss: 0.3138517737388611
Batch 27/64 loss: 0.31373679637908936
Batch 28/64 loss: 0.31838297843933105
Batch 29/64 loss: 0.3222247362136841
Batch 30/64 loss: 0.32075977325439453
Batch 31/64 loss: 0.3155707120895386
Batch 32/64 loss: 0.3157716989517212
Batch 33/64 loss: 0.31738948822021484
Batch 34/64 loss: 0.31414318084716797
Batch 35/64 loss: 0.31359297037124634
Batch 36/64 loss: 0.3130526542663574
Batch 37/64 loss: 0.3122273087501526
Batch 38/64 loss: 0.323100209236145
Batch 39/64 loss: 0.31653308868408203
Batch 40/64 loss: 0.3089982867240906
Batch 41/64 loss: 0.3147827982902527
Batch 42/64 loss: 0.31743043661117554
Batch 43/64 loss: 0.30969172716140747
Batch 44/64 loss: 0.32331252098083496
Batch 45/64 loss: 0.3155796527862549
Batch 46/64 loss: 0.31456464529037476
Batch 47/64 loss: 0.31821489334106445
Batch 48/64 loss: 0.31558215618133545
Batch 49/64 loss: 0.3143002986907959
Batch 50/64 loss: 0.31168627738952637
Batch 51/64 loss: 0.32068389654159546
Batch 52/64 loss: 0.3194766044616699
Batch 53/64 loss: 0.30783921480178833
Batch 54/64 loss: 0.31751739978790283
Batch 55/64 loss: 0.31451189517974854
Batch 56/64 loss: 0.30953723192214966
Batch 57/64 loss: 0.31599199771881104
Batch 58/64 loss: 0.3140333294868469
Batch 59/64 loss: 0.3170579671859741
Batch 60/64 loss: 0.31349194049835205
Batch 61/64 loss: 0.31913554668426514
Batch 62/64 loss: 0.3160742521286011
Batch 63/64 loss: 0.3100866675376892
Batch 64/64 loss: 0.3132309913635254
Epoch 131  Train loss: 0.31527321852889717  Val loss: 0.32584752700582814
Saving best model, epoch: 131
Epoch 132
-------------------------------
Batch 1/64 loss: 0.3161516785621643
Batch 2/64 loss: 0.3142709732055664
Batch 3/64 loss: 0.31111299991607666
Batch 4/64 loss: 0.31607580184936523
Batch 5/64 loss: 0.31036996841430664
Batch 6/64 loss: 0.3100172281265259
Batch 7/64 loss: 0.3182471990585327
Batch 8/64 loss: 0.312099814414978
Batch 9/64 loss: 0.31626975536346436
Batch 10/64 loss: 0.31598377227783203
Batch 11/64 loss: 0.3194149136543274
Batch 12/64 loss: 0.3136623501777649
Batch 13/64 loss: 0.31384801864624023
Batch 14/64 loss: 0.31087827682495117
Batch 15/64 loss: 0.3141654133796692
Batch 16/64 loss: 0.3086991310119629
Batch 17/64 loss: 0.31555283069610596
Batch 18/64 loss: 0.31306910514831543
Batch 19/64 loss: 0.32418859004974365
Batch 20/64 loss: 0.3220934271812439
Batch 21/64 loss: 0.31502383947372437
Batch 22/64 loss: 0.30833423137664795
Batch 23/64 loss: 0.3132855296134949
Batch 24/64 loss: 0.3167310953140259
Batch 25/64 loss: 0.31454724073410034
Batch 26/64 loss: 0.31613653898239136
Batch 27/64 loss: 0.3172074556350708
Batch 28/64 loss: 0.31846141815185547
Batch 29/64 loss: 0.31067848205566406
Batch 30/64 loss: 0.3193473815917969
Batch 31/64 loss: 0.3100043535232544
Batch 32/64 loss: 0.315485417842865
Batch 33/64 loss: 0.31604278087615967
Batch 34/64 loss: 0.32034510374069214
Batch 35/64 loss: 0.3155388832092285
Batch 36/64 loss: 0.31960439682006836
Batch 37/64 loss: 0.31436097621917725
Batch 38/64 loss: 0.31295228004455566
Batch 39/64 loss: 0.32013893127441406
Batch 40/64 loss: 0.3150053024291992
Batch 41/64 loss: 0.31585168838500977
Batch 42/64 loss: 0.3111436367034912
Batch 43/64 loss: 0.3213120698928833
Batch 44/64 loss: 0.31609636545181274
Batch 45/64 loss: 0.3130069375038147
Batch 46/64 loss: 0.3141600489616394
Batch 47/64 loss: 0.3178812861442566
Batch 48/64 loss: 0.3175095319747925
Batch 49/64 loss: 0.31135332584381104
Batch 50/64 loss: 0.31206512451171875
Batch 51/64 loss: 0.32347458600997925
Batch 52/64 loss: 0.3122555613517761
Batch 53/64 loss: 0.3110315799713135
Batch 54/64 loss: 0.31594014167785645
Batch 55/64 loss: 0.31207358837127686
Batch 56/64 loss: 0.312003493309021
Batch 57/64 loss: 0.3196607828140259
Batch 58/64 loss: 0.312019944190979
Batch 59/64 loss: 0.31284213066101074
Batch 60/64 loss: 0.31204044818878174
Batch 61/64 loss: 0.3203882575035095
Batch 62/64 loss: 0.31883156299591064
Batch 63/64 loss: 0.3146991729736328
Batch 64/64 loss: 0.3237994909286499
Epoch 132  Train loss: 0.3152297062032363  Val loss: 0.3249614261269979
Saving best model, epoch: 132
Epoch 133
-------------------------------
Batch 1/64 loss: 0.31701338291168213
Batch 2/64 loss: 0.3171582818031311
Batch 3/64 loss: 0.31600421667099
Batch 4/64 loss: 0.31430041790008545
Batch 5/64 loss: 0.31305187940597534
Batch 6/64 loss: 0.3152182698249817
Batch 7/64 loss: 0.31615352630615234
Batch 8/64 loss: 0.31850606203079224
Batch 9/64 loss: 0.31531286239624023
Batch 10/64 loss: 0.31381356716156006
Batch 11/64 loss: 0.3131561875343323
Batch 12/64 loss: 0.31220412254333496
Batch 13/64 loss: 0.31331050395965576
Batch 14/64 loss: 0.3195502758026123
Batch 15/64 loss: 0.3173377513885498
Batch 16/64 loss: 0.30610138177871704
Batch 17/64 loss: 0.31298160552978516
Batch 18/64 loss: 0.3228228688240051
Batch 19/64 loss: 0.3115220069885254
Batch 20/64 loss: 0.3106495141983032
Batch 21/64 loss: 0.3174694776535034
Batch 22/64 loss: 0.30694836378097534
Batch 23/64 loss: 0.31536269187927246
Batch 24/64 loss: 0.314129114151001
Batch 25/64 loss: 0.30988240242004395
Batch 26/64 loss: 0.32023704051971436
Batch 27/64 loss: 0.3171080946922302
Batch 28/64 loss: 0.31396228075027466
Batch 29/64 loss: 0.307356595993042
Batch 30/64 loss: 0.3139604926109314
Batch 31/64 loss: 0.3142892122268677
Batch 32/64 loss: 0.31746166944503784
Batch 33/64 loss: 0.3219514489173889
Batch 34/64 loss: 0.31903624534606934
Batch 35/64 loss: 0.3139122724533081
Batch 36/64 loss: 0.3195911645889282
Batch 37/64 loss: 0.31044715642929077
Batch 38/64 loss: 0.31443047523498535
Batch 39/64 loss: 0.31196022033691406
Batch 40/64 loss: 0.32240909337997437
Batch 41/64 loss: 0.3163217306137085
Batch 42/64 loss: 0.31580519676208496
Batch 43/64 loss: 0.3139132857322693
Batch 44/64 loss: 0.3194088935852051
Batch 45/64 loss: 0.3176705241203308
Batch 46/64 loss: 0.3155999183654785
Batch 47/64 loss: 0.3098360300064087
Batch 48/64 loss: 0.31768810749053955
Batch 49/64 loss: 0.3182663321495056
Batch 50/64 loss: 0.3072390556335449
Batch 51/64 loss: 0.31759583950042725
Batch 52/64 loss: 0.3159942626953125
Batch 53/64 loss: 0.3120614290237427
Batch 54/64 loss: 0.31376218795776367
Batch 55/64 loss: 0.31557053327560425
Batch 56/64 loss: 0.3132663369178772
Batch 57/64 loss: 0.31197500228881836
Batch 58/64 loss: 0.315233051776886
Batch 59/64 loss: 0.32087385654449463
Batch 60/64 loss: 0.31383442878723145
Batch 61/64 loss: 0.3167877197265625
Batch 62/64 loss: 0.3099706172943115
Batch 63/64 loss: 0.3166462182998657
Batch 64/64 loss: 0.30728471279144287
Epoch 133  Train loss: 0.31488405162212896  Val loss: 0.32613874526367975
Epoch 134
-------------------------------
Batch 1/64 loss: 0.3178108334541321
Batch 2/64 loss: 0.31251245737075806
Batch 3/64 loss: 0.3129006028175354
Batch 4/64 loss: 0.3177393674850464
Batch 5/64 loss: 0.31481289863586426
Batch 6/64 loss: 0.3154040575027466
Batch 7/64 loss: 0.3153507709503174
Batch 8/64 loss: 0.31077146530151367
Batch 9/64 loss: 0.3115203380584717
Batch 10/64 loss: 0.32257455587387085
Batch 11/64 loss: 0.3155921697616577
Batch 12/64 loss: 0.30778801441192627
Batch 13/64 loss: 0.3119962215423584
Batch 14/64 loss: 0.31753623485565186
Batch 15/64 loss: 0.31248360872268677
Batch 16/64 loss: 0.31392812728881836
Batch 17/64 loss: 0.3093777894973755
Batch 18/64 loss: 0.3144530653953552
Batch 19/64 loss: 0.31503891944885254
Batch 20/64 loss: 0.3074708580970764
Batch 21/64 loss: 0.3171236515045166
Batch 22/64 loss: 0.3024986982345581
Batch 23/64 loss: 0.3079262971878052
Batch 24/64 loss: 0.3086124658584595
Batch 25/64 loss: 0.31288063526153564
Batch 26/64 loss: 0.3091791868209839
Batch 27/64 loss: 0.31062257289886475
Batch 28/64 loss: 0.31571757793426514
Batch 29/64 loss: 0.31584441661834717
Batch 30/64 loss: 0.3115178346633911
Batch 31/64 loss: 0.3143964409828186
Batch 32/64 loss: 0.31686681509017944
Batch 33/64 loss: 0.31751441955566406
Batch 34/64 loss: 0.31542158126831055
Batch 35/64 loss: 0.31678736209869385
Batch 36/64 loss: 0.31865549087524414
Batch 37/64 loss: 0.3150283694267273
Batch 38/64 loss: 0.3087928891181946
Batch 39/64 loss: 0.31255191564559937
Batch 40/64 loss: 0.31528401374816895
Batch 41/64 loss: 0.3132895231246948
Batch 42/64 loss: 0.3143059015274048
Batch 43/64 loss: 0.31827056407928467
Batch 44/64 loss: 0.31725817918777466
Batch 45/64 loss: 0.3118554353713989
Batch 46/64 loss: 0.3146570920944214
Batch 47/64 loss: 0.3124259114265442
Batch 48/64 loss: 0.3267742991447449
Batch 49/64 loss: 0.31920385360717773
Batch 50/64 loss: 0.31665968894958496
Batch 51/64 loss: 0.31789255142211914
Batch 52/64 loss: 0.3184596300125122
Batch 53/64 loss: 0.32680612802505493
Batch 54/64 loss: 0.31754791736602783
Batch 55/64 loss: 0.3231922388076782
Batch 56/64 loss: 0.3169679641723633
Batch 57/64 loss: 0.31633198261260986
Batch 58/64 loss: 0.30991554260253906
Batch 59/64 loss: 0.3102707266807556
Batch 60/64 loss: 0.31502920389175415
Batch 61/64 loss: 0.3160583972930908
Batch 62/64 loss: 0.31385475397109985
Batch 63/64 loss: 0.3109316825866699
Batch 64/64 loss: 0.31947195529937744
Epoch 134  Train loss: 0.3146329117756264  Val loss: 0.32524057270325335
Epoch 135
-------------------------------
Batch 1/64 loss: 0.31126439571380615
Batch 2/64 loss: 0.3102704882621765
Batch 3/64 loss: 0.3126509189605713
Batch 4/64 loss: 0.31819021701812744
Batch 5/64 loss: 0.32171130180358887
Batch 6/64 loss: 0.31240320205688477
Batch 7/64 loss: 0.31489598751068115
Batch 8/64 loss: 0.30898213386535645
Batch 9/64 loss: 0.3195009231567383
Batch 10/64 loss: 0.3157597780227661
Batch 11/64 loss: 0.31136560440063477
Batch 12/64 loss: 0.3161334991455078
Batch 13/64 loss: 0.31675171852111816
Batch 14/64 loss: 0.3182276487350464
Batch 15/64 loss: 0.30800044536590576
Batch 16/64 loss: 0.31172776222229004
Batch 17/64 loss: 0.3175743818283081
Batch 18/64 loss: 0.3111400008201599
Batch 19/64 loss: 0.32019591331481934
Batch 20/64 loss: 0.3070852756500244
Batch 21/64 loss: 0.3172287940979004
Batch 22/64 loss: 0.3119434714317322
Batch 23/64 loss: 0.30852246284484863
Batch 24/64 loss: 0.31308865547180176
Batch 25/64 loss: 0.31041985750198364
Batch 26/64 loss: 0.31119418144226074
Batch 27/64 loss: 0.3164703845977783
Batch 28/64 loss: 0.3156365156173706
Batch 29/64 loss: 0.32042384147644043
Batch 30/64 loss: 0.31320101022720337
Batch 31/64 loss: 0.31827443838119507
Batch 32/64 loss: 0.3082081079483032
Batch 33/64 loss: 0.31392866373062134
Batch 34/64 loss: 0.31566381454467773
Batch 35/64 loss: 0.3056983947753906
Batch 36/64 loss: 0.31356096267700195
Batch 37/64 loss: 0.31843405961990356
Batch 38/64 loss: 0.3089209198951721
Batch 39/64 loss: 0.3171720504760742
Batch 40/64 loss: 0.31602561473846436
Batch 41/64 loss: 0.32077300548553467
Batch 42/64 loss: 0.3163914680480957
Batch 43/64 loss: 0.3167344331741333
Batch 44/64 loss: 0.31169605255126953
Batch 45/64 loss: 0.314410924911499
Batch 46/64 loss: 0.320438027381897
Batch 47/64 loss: 0.31940990686416626
Batch 48/64 loss: 0.3139035701751709
Batch 49/64 loss: 0.3189733624458313
Batch 50/64 loss: 0.3107626438140869
Batch 51/64 loss: 0.3122849464416504
Batch 52/64 loss: 0.31530022621154785
Batch 53/64 loss: 0.31174343824386597
Batch 54/64 loss: 0.3111453056335449
Batch 55/64 loss: 0.3104836940765381
Batch 56/64 loss: 0.31086885929107666
Batch 57/64 loss: 0.3118317127227783
Batch 58/64 loss: 0.3116632103919983
Batch 59/64 loss: 0.3182068467140198
Batch 60/64 loss: 0.31695556640625
Batch 61/64 loss: 0.3175402879714966
Batch 62/64 loss: 0.3149682879447937
Batch 63/64 loss: 0.31590116024017334
Batch 64/64 loss: 0.312824010848999
Epoch 135  Train loss: 0.31427219989253025  Val loss: 0.3244043514900601
Saving best model, epoch: 135
Epoch 136
-------------------------------
Batch 1/64 loss: 0.3077179789543152
Batch 2/64 loss: 0.3112006187438965
Batch 3/64 loss: 0.3132273554801941
Batch 4/64 loss: 0.3191484212875366
Batch 5/64 loss: 0.3137078285217285
Batch 6/64 loss: 0.31614285707473755
Batch 7/64 loss: 0.3135983943939209
Batch 8/64 loss: 0.32730674743652344
Batch 9/64 loss: 0.3141951560974121
Batch 10/64 loss: 0.30893242359161377
Batch 11/64 loss: 0.31565535068511963
Batch 12/64 loss: 0.3137781620025635
Batch 13/64 loss: 0.3136606216430664
Batch 14/64 loss: 0.3186509609222412
Batch 15/64 loss: 0.31029433012008667
Batch 16/64 loss: 0.31262969970703125
Batch 17/64 loss: 0.31181687116622925
Batch 18/64 loss: 0.3101993799209595
Batch 19/64 loss: 0.31524717807769775
Batch 20/64 loss: 0.31689906120300293
Batch 21/64 loss: 0.3158772587776184
Batch 22/64 loss: 0.3160957098007202
Batch 23/64 loss: 0.313742995262146
Batch 24/64 loss: 0.30883651971817017
Batch 25/64 loss: 0.31694895029067993
Batch 26/64 loss: 0.3105522394180298
Batch 27/64 loss: 0.3141922354698181
Batch 28/64 loss: 0.31099146604537964
Batch 29/64 loss: 0.3187979459762573
Batch 30/64 loss: 0.30942440032958984
Batch 31/64 loss: 0.3199841380119324
Batch 32/64 loss: 0.3137817978858948
Batch 33/64 loss: 0.3128248453140259
Batch 34/64 loss: 0.3169945478439331
Batch 35/64 loss: 0.31870031356811523
Batch 36/64 loss: 0.31083762645721436
Batch 37/64 loss: 0.31681692600250244
Batch 38/64 loss: 0.31342440843582153
Batch 39/64 loss: 0.31108272075653076
Batch 40/64 loss: 0.31833791732788086
Batch 41/64 loss: 0.31283295154571533
Batch 42/64 loss: 0.31265169382095337
Batch 43/64 loss: 0.3127080202102661
Batch 44/64 loss: 0.3167147636413574
Batch 45/64 loss: 0.30997467041015625
Batch 46/64 loss: 0.31866025924682617
Batch 47/64 loss: 0.3096940517425537
Batch 48/64 loss: 0.31588923931121826
Batch 49/64 loss: 0.3062540888786316
Batch 50/64 loss: 0.32166147232055664
Batch 51/64 loss: 0.3099971413612366
Batch 52/64 loss: 0.3107987642288208
Batch 53/64 loss: 0.3183659315109253
Batch 54/64 loss: 0.3073878288269043
Batch 55/64 loss: 0.32033419609069824
Batch 56/64 loss: 0.3147673010826111
Batch 57/64 loss: 0.3189038038253784
Batch 58/64 loss: 0.3170529007911682
Batch 59/64 loss: 0.3124043345451355
Batch 60/64 loss: 0.3142479658126831
Batch 61/64 loss: 0.31064939498901367
Batch 62/64 loss: 0.31507575511932373
Batch 63/64 loss: 0.31785327196121216
Batch 64/64 loss: 0.3137301802635193
Epoch 136  Train loss: 0.31423422425400976  Val loss: 0.3250051134640409
Epoch 137
-------------------------------
Batch 1/64 loss: 0.3224567174911499
Batch 2/64 loss: 0.31444239616394043
Batch 3/64 loss: 0.31973397731781006
Batch 4/64 loss: 0.31182074546813965
Batch 5/64 loss: 0.31768232583999634
Batch 6/64 loss: 0.30898213386535645
Batch 7/64 loss: 0.3097810745239258
Batch 8/64 loss: 0.31090879440307617
Batch 9/64 loss: 0.31246310472488403
Batch 10/64 loss: 0.3162097930908203
Batch 11/64 loss: 0.3183673620223999
Batch 12/64 loss: 0.3087806701660156
Batch 13/64 loss: 0.3129597306251526
Batch 14/64 loss: 0.31330692768096924
Batch 15/64 loss: 0.3076106309890747
Batch 16/64 loss: 0.31291085481643677
Batch 17/64 loss: 0.31152045726776123
Batch 18/64 loss: 0.3120836019515991
Batch 19/64 loss: 0.3141310214996338
Batch 20/64 loss: 0.3088817596435547
Batch 21/64 loss: 0.30918288230895996
Batch 22/64 loss: 0.312247097492218
Batch 23/64 loss: 0.3130868077278137
Batch 24/64 loss: 0.3193719983100891
Batch 25/64 loss: 0.31395214796066284
Batch 26/64 loss: 0.30645012855529785
Batch 27/64 loss: 0.3148258924484253
Batch 28/64 loss: 0.318212628364563
Batch 29/64 loss: 0.3221750259399414
Batch 30/64 loss: 0.3142247200012207
Batch 31/64 loss: 0.32256489992141724
Batch 32/64 loss: 0.3089057207107544
Batch 33/64 loss: 0.316228449344635
Batch 34/64 loss: 0.31755560636520386
Batch 35/64 loss: 0.31104469299316406
Batch 36/64 loss: 0.31851881742477417
Batch 37/64 loss: 0.31776607036590576
Batch 38/64 loss: 0.32030189037323
Batch 39/64 loss: 0.31610357761383057
Batch 40/64 loss: 0.31120991706848145
Batch 41/64 loss: 0.3078377842903137
Batch 42/64 loss: 0.31001412868499756
Batch 43/64 loss: 0.31530308723449707
Batch 44/64 loss: 0.31858956813812256
Batch 45/64 loss: 0.3133518695831299
Batch 46/64 loss: 0.31234145164489746
Batch 47/64 loss: 0.3150479793548584
Batch 48/64 loss: 0.3060304522514343
Batch 49/64 loss: 0.31354665756225586
Batch 50/64 loss: 0.3149559497833252
Batch 51/64 loss: 0.30979037284851074
Batch 52/64 loss: 0.31117427349090576
Batch 53/64 loss: 0.3141500949859619
Batch 54/64 loss: 0.309525728225708
Batch 55/64 loss: 0.322027325630188
Batch 56/64 loss: 0.30675315856933594
Batch 57/64 loss: 0.3089684247970581
Batch 58/64 loss: 0.3128606677055359
Batch 59/64 loss: 0.31112802028656006
Batch 60/64 loss: 0.3167850971221924
Batch 61/64 loss: 0.31071925163269043
Batch 62/64 loss: 0.3124893307685852
Batch 63/64 loss: 0.314627468585968
Batch 64/64 loss: 0.31118106842041016
Epoch 137  Train loss: 0.3135743842405431  Val loss: 0.3238652168270649
Saving best model, epoch: 137
Epoch 138
-------------------------------
Batch 1/64 loss: 0.3069329261779785
Batch 2/64 loss: 0.3124508261680603
Batch 3/64 loss: 0.3120681047439575
Batch 4/64 loss: 0.3168644309043884
Batch 5/64 loss: 0.3132272958755493
Batch 6/64 loss: 0.3166753053665161
Batch 7/64 loss: 0.3121596574783325
Batch 8/64 loss: 0.3107631206512451
Batch 9/64 loss: 0.3152666687965393
Batch 10/64 loss: 0.3161548972129822
Batch 11/64 loss: 0.3121846914291382
Batch 12/64 loss: 0.31344717741012573
Batch 13/64 loss: 0.3135594129562378
Batch 14/64 loss: 0.3145642876625061
Batch 15/64 loss: 0.30985593795776367
Batch 16/64 loss: 0.3051798939704895
Batch 17/64 loss: 0.3153434991836548
Batch 18/64 loss: 0.31385278701782227
Batch 19/64 loss: 0.3114454746246338
Batch 20/64 loss: 0.3135802745819092
Batch 21/64 loss: 0.3098130226135254
Batch 22/64 loss: 0.313818097114563
Batch 23/64 loss: 0.31406521797180176
Batch 24/64 loss: 0.31693196296691895
Batch 25/64 loss: 0.3120700716972351
Batch 26/64 loss: 0.3117082715034485
Batch 27/64 loss: 0.31271493434906006
Batch 28/64 loss: 0.3129614591598511
Batch 29/64 loss: 0.3197317123413086
Batch 30/64 loss: 0.3125787377357483
Batch 31/64 loss: 0.3134392499923706
Batch 32/64 loss: 0.31775200366973877
Batch 33/64 loss: 0.31063956022262573
Batch 34/64 loss: 0.3108067512512207
Batch 35/64 loss: 0.3132612109184265
Batch 36/64 loss: 0.31335747241973877
Batch 37/64 loss: 0.3171687126159668
Batch 38/64 loss: 0.3155266046524048
Batch 39/64 loss: 0.31260859966278076
Batch 40/64 loss: 0.31349635124206543
Batch 41/64 loss: 0.31603628396987915
Batch 42/64 loss: 0.31460392475128174
Batch 43/64 loss: 0.3140982985496521
Batch 44/64 loss: 0.321378231048584
Batch 45/64 loss: 0.3174870014190674
Batch 46/64 loss: 0.31581902503967285
Batch 47/64 loss: 0.314919114112854
Batch 48/64 loss: 0.3067336082458496
Batch 49/64 loss: 0.3084786534309387
Batch 50/64 loss: 0.31195664405822754
Batch 51/64 loss: 0.316686749458313
Batch 52/64 loss: 0.3180946111679077
Batch 53/64 loss: 0.3096463084220886
Batch 54/64 loss: 0.31359750032424927
Batch 55/64 loss: 0.3150672912597656
Batch 56/64 loss: 0.31182771921157837
Batch 57/64 loss: 0.31227797269821167
Batch 58/64 loss: 0.3099384307861328
Batch 59/64 loss: 0.310832142829895
Batch 60/64 loss: 0.3199629783630371
Batch 61/64 loss: 0.3137134909629822
Batch 62/64 loss: 0.3083738684654236
Batch 63/64 loss: 0.3139526844024658
Batch 64/64 loss: 0.3142092227935791
Epoch 138  Train loss: 0.3134300568524529  Val loss: 0.32488855791255783
Epoch 139
-------------------------------
Batch 1/64 loss: 0.31155580282211304
Batch 2/64 loss: 0.31049633026123047
Batch 3/64 loss: 0.30530858039855957
Batch 4/64 loss: 0.3134412169456482
Batch 5/64 loss: 0.31244105100631714
Batch 6/64 loss: 0.3154585361480713
Batch 7/64 loss: 0.31260377168655396
Batch 8/64 loss: 0.31226539611816406
Batch 9/64 loss: 0.3099170923233032
Batch 10/64 loss: 0.3159121870994568
Batch 11/64 loss: 0.31197798252105713
Batch 12/64 loss: 0.31454241275787354
Batch 13/64 loss: 0.3134739398956299
Batch 14/64 loss: 0.30682772397994995
Batch 15/64 loss: 0.314386785030365
Batch 16/64 loss: 0.312560498714447
Batch 17/64 loss: 0.30679142475128174
Batch 18/64 loss: 0.31032705307006836
Batch 19/64 loss: 0.31732654571533203
Batch 20/64 loss: 0.3099362254142761
Batch 21/64 loss: 0.3196675181388855
Batch 22/64 loss: 0.3074001669883728
Batch 23/64 loss: 0.3184109926223755
Batch 24/64 loss: 0.3131698966026306
Batch 25/64 loss: 0.31367260217666626
Batch 26/64 loss: 0.31708550453186035
Batch 27/64 loss: 0.3211374282836914
Batch 28/64 loss: 0.3094925880432129
Batch 29/64 loss: 0.30841362476348877
Batch 30/64 loss: 0.3086373209953308
Batch 31/64 loss: 0.3110463619232178
Batch 32/64 loss: 0.319735050201416
Batch 33/64 loss: 0.3107954263687134
Batch 34/64 loss: 0.30940693616867065
Batch 35/64 loss: 0.3116936683654785
Batch 36/64 loss: 0.30682045221328735
Batch 37/64 loss: 0.3090434670448303
Batch 38/64 loss: 0.3134002685546875
Batch 39/64 loss: 0.3204905390739441
Batch 40/64 loss: 0.3143728971481323
Batch 41/64 loss: 0.3127027153968811
Batch 42/64 loss: 0.31922364234924316
Batch 43/64 loss: 0.3187739849090576
Batch 44/64 loss: 0.3186143636703491
Batch 45/64 loss: 0.3111480474472046
Batch 46/64 loss: 0.3161565065383911
Batch 47/64 loss: 0.3070729970932007
Batch 48/64 loss: 0.31322789192199707
Batch 49/64 loss: 0.305736780166626
Batch 50/64 loss: 0.32057470083236694
Batch 51/64 loss: 0.3147526979446411
Batch 52/64 loss: 0.31717705726623535
Batch 53/64 loss: 0.31163907051086426
Batch 54/64 loss: 0.31405413150787354
Batch 55/64 loss: 0.31325024366378784
Batch 56/64 loss: 0.31381911039352417
Batch 57/64 loss: 0.30934447050094604
Batch 58/64 loss: 0.31469428539276123
Batch 59/64 loss: 0.3087040185928345
Batch 60/64 loss: 0.3088327646255493
Batch 61/64 loss: 0.3184702396392822
Batch 62/64 loss: 0.31385350227355957
Batch 63/64 loss: 0.31336838006973267
Batch 64/64 loss: 0.3117208480834961
Epoch 139  Train loss: 0.31294785106883327  Val loss: 0.32592132779740796
Epoch 140
-------------------------------
Batch 1/64 loss: 0.31392741203308105
Batch 2/64 loss: 0.30856025218963623
Batch 3/64 loss: 0.3082271218299866
Batch 4/64 loss: 0.30994588136672974
Batch 5/64 loss: 0.3087301254272461
Batch 6/64 loss: 0.31113386154174805
Batch 7/64 loss: 0.31373322010040283
Batch 8/64 loss: 0.3157346844673157
Batch 9/64 loss: 0.3068026304244995
Batch 10/64 loss: 0.30799025297164917
Batch 11/64 loss: 0.3161962032318115
Batch 12/64 loss: 0.3101085424423218
Batch 13/64 loss: 0.31677377223968506
Batch 14/64 loss: 0.3172018527984619
Batch 15/64 loss: 0.3145074248313904
Batch 16/64 loss: 0.3091956377029419
Batch 17/64 loss: 0.31343281269073486
Batch 18/64 loss: 0.307873010635376
Batch 19/64 loss: 0.3087199926376343
Batch 20/64 loss: 0.31297391653060913
Batch 21/64 loss: 0.3110209107398987
Batch 22/64 loss: 0.3103722929954529
Batch 23/64 loss: 0.3155202269554138
Batch 24/64 loss: 0.31073951721191406
Batch 25/64 loss: 0.31436192989349365
Batch 26/64 loss: 0.3134148120880127
Batch 27/64 loss: 0.31141799688339233
Batch 28/64 loss: 0.3106480836868286
Batch 29/64 loss: 0.3205133080482483
Batch 30/64 loss: 0.3133864402770996
Batch 31/64 loss: 0.31046855449676514
Batch 32/64 loss: 0.3065577745437622
Batch 33/64 loss: 0.3128659725189209
Batch 34/64 loss: 0.3155962824821472
Batch 35/64 loss: 0.3092418313026428
Batch 36/64 loss: 0.30892038345336914
Batch 37/64 loss: 0.31872308254241943
Batch 38/64 loss: 0.3151744604110718
Batch 39/64 loss: 0.3185707926750183
Batch 40/64 loss: 0.31361961364746094
Batch 41/64 loss: 0.31605279445648193
Batch 42/64 loss: 0.3151205778121948
Batch 43/64 loss: 0.3091239929199219
Batch 44/64 loss: 0.3104836940765381
Batch 45/64 loss: 0.3106688857078552
Batch 46/64 loss: 0.3150343894958496
Batch 47/64 loss: 0.3196043372154236
Batch 48/64 loss: 0.3130526542663574
Batch 49/64 loss: 0.3114500045776367
Batch 50/64 loss: 0.3097829818725586
Batch 51/64 loss: 0.3127920627593994
Batch 52/64 loss: 0.31640803813934326
Batch 53/64 loss: 0.3144032955169678
Batch 54/64 loss: 0.3148428797721863
Batch 55/64 loss: 0.30708396434783936
Batch 56/64 loss: 0.3162928819656372
Batch 57/64 loss: 0.320972204208374
Batch 58/64 loss: 0.314020037651062
Batch 59/64 loss: 0.31402695178985596
Batch 60/64 loss: 0.3098600506782532
Batch 61/64 loss: 0.3152872323989868
Batch 62/64 loss: 0.3087441921234131
Batch 63/64 loss: 0.31059694290161133
Batch 64/64 loss: 0.3147121071815491
Epoch 140  Train loss: 0.3127002666978275  Val loss: 0.3232981845275643
Saving best model, epoch: 140
Epoch 141
-------------------------------
Batch 1/64 loss: 0.30983519554138184
Batch 2/64 loss: 0.31077444553375244
Batch 3/64 loss: 0.3128124475479126
Batch 4/64 loss: 0.303386926651001
Batch 5/64 loss: 0.3124005198478699
Batch 6/64 loss: 0.31322336196899414
Batch 7/64 loss: 0.30953216552734375
Batch 8/64 loss: 0.309967041015625
Batch 9/64 loss: 0.31657350063323975
Batch 10/64 loss: 0.3093792796134949
Batch 11/64 loss: 0.3158569931983948
Batch 12/64 loss: 0.3046666383743286
Batch 13/64 loss: 0.3118690252304077
Batch 14/64 loss: 0.3042351007461548
Batch 15/64 loss: 0.31378602981567383
Batch 16/64 loss: 0.31257355213165283
Batch 17/64 loss: 0.30803918838500977
Batch 18/64 loss: 0.30594396591186523
Batch 19/64 loss: 0.31397974491119385
Batch 20/64 loss: 0.30996406078338623
Batch 21/64 loss: 0.313665509223938
Batch 22/64 loss: 0.30793631076812744
Batch 23/64 loss: 0.31359922885894775
Batch 24/64 loss: 0.31331026554107666
Batch 25/64 loss: 0.31575727462768555
Batch 26/64 loss: 0.30998456478118896
Batch 27/64 loss: 0.3175700902938843
Batch 28/64 loss: 0.31104373931884766
Batch 29/64 loss: 0.310854434967041
Batch 30/64 loss: 0.30524933338165283
Batch 31/64 loss: 0.31172436475753784
Batch 32/64 loss: 0.31717395782470703
Batch 33/64 loss: 0.31674379110336304
Batch 34/64 loss: 0.3124849796295166
Batch 35/64 loss: 0.31686872243881226
Batch 36/64 loss: 0.3081578016281128
Batch 37/64 loss: 0.31609010696411133
Batch 38/64 loss: 0.3111163377761841
Batch 39/64 loss: 0.3108617067337036
Batch 40/64 loss: 0.30961620807647705
Batch 41/64 loss: 0.3119910955429077
Batch 42/64 loss: 0.3111675977706909
Batch 43/64 loss: 0.31280195713043213
Batch 44/64 loss: 0.32007652521133423
Batch 45/64 loss: 0.30976223945617676
Batch 46/64 loss: 0.31349682807922363
Batch 47/64 loss: 0.31636977195739746
Batch 48/64 loss: 0.31153446435928345
Batch 49/64 loss: 0.313903272151947
Batch 50/64 loss: 0.31140220165252686
Batch 51/64 loss: 0.3173654079437256
Batch 52/64 loss: 0.3093050718307495
Batch 53/64 loss: 0.30831193923950195
Batch 54/64 loss: 0.3193908929824829
Batch 55/64 loss: 0.3196789026260376
Batch 56/64 loss: 0.3172118663787842
Batch 57/64 loss: 0.3092881441116333
Batch 58/64 loss: 0.30721020698547363
Batch 59/64 loss: 0.3115990161895752
Batch 60/64 loss: 0.3097470998764038
Batch 61/64 loss: 0.31641948223114014
Batch 62/64 loss: 0.3114696145057678
Batch 63/64 loss: 0.31156980991363525
Batch 64/64 loss: 0.31466102600097656
Epoch 141  Train loss: 0.3120890523873123  Val loss: 0.3235714902582857
Epoch 142
-------------------------------
Batch 1/64 loss: 0.3126620054244995
Batch 2/64 loss: 0.3113964796066284
Batch 3/64 loss: 0.31020402908325195
Batch 4/64 loss: 0.31092584133148193
Batch 5/64 loss: 0.3151148557662964
Batch 6/64 loss: 0.3124347925186157
Batch 7/64 loss: 0.30976152420043945
Batch 8/64 loss: 0.3060338497161865
Batch 9/64 loss: 0.30785590410232544
Batch 10/64 loss: 0.3185548186302185
Batch 11/64 loss: 0.3075903654098511
Batch 12/64 loss: 0.3098524808883667
Batch 13/64 loss: 0.31030941009521484
Batch 14/64 loss: 0.312694787979126
Batch 15/64 loss: 0.3056870698928833
Batch 16/64 loss: 0.3058343529701233
Batch 17/64 loss: 0.31024622917175293
Batch 18/64 loss: 0.3075491189956665
Batch 19/64 loss: 0.3104013204574585
Batch 20/64 loss: 0.3195852041244507
Batch 21/64 loss: 0.3099955916404724
Batch 22/64 loss: 0.3124675750732422
Batch 23/64 loss: 0.31448596715927124
Batch 24/64 loss: 0.30905985832214355
Batch 25/64 loss: 0.31653523445129395
Batch 26/64 loss: 0.3145015835762024
Batch 27/64 loss: 0.31181371212005615
Batch 28/64 loss: 0.3160824775695801
Batch 29/64 loss: 0.31204813718795776
Batch 30/64 loss: 0.31175684928894043
Batch 31/64 loss: 0.3157663941383362
Batch 32/64 loss: 0.3141469955444336
Batch 33/64 loss: 0.30462926626205444
Batch 34/64 loss: 0.31276464462280273
Batch 35/64 loss: 0.3069188594818115
Batch 36/64 loss: 0.31468284130096436
Batch 37/64 loss: 0.30898767709732056
Batch 38/64 loss: 0.31443876028060913
Batch 39/64 loss: 0.30705392360687256
Batch 40/64 loss: 0.31148529052734375
Batch 41/64 loss: 0.30660271644592285
Batch 42/64 loss: 0.3109622597694397
Batch 43/64 loss: 0.3146951198577881
Batch 44/64 loss: 0.3176295757293701
Batch 45/64 loss: 0.3175860643386841
Batch 46/64 loss: 0.30746936798095703
Batch 47/64 loss: 0.3134509325027466
Batch 48/64 loss: 0.3170698881149292
Batch 49/64 loss: 0.3090660572052002
Batch 50/64 loss: 0.30976855754852295
Batch 51/64 loss: 0.30496227741241455
Batch 52/64 loss: 0.3089078664779663
Batch 53/64 loss: 0.3142904043197632
Batch 54/64 loss: 0.3096442222595215
Batch 55/64 loss: 0.3147991895675659
Batch 56/64 loss: 0.30736690759658813
Batch 57/64 loss: 0.31857287883758545
Batch 58/64 loss: 0.31714683771133423
Batch 59/64 loss: 0.31340843439102173
Batch 60/64 loss: 0.3148682713508606
Batch 61/64 loss: 0.3053847551345825
Batch 62/64 loss: 0.3185042142868042
Batch 63/64 loss: 0.31823182106018066
Batch 64/64 loss: 0.31090736389160156
Epoch 142  Train loss: 0.31180996427349017  Val loss: 0.32431760727335085
Epoch 143
-------------------------------
Batch 1/64 loss: 0.3134021759033203
Batch 2/64 loss: 0.3074861764907837
Batch 3/64 loss: 0.3083469867706299
Batch 4/64 loss: 0.31593263149261475
Batch 5/64 loss: 0.3045980930328369
Batch 6/64 loss: 0.3080023527145386
Batch 7/64 loss: 0.30891847610473633
Batch 8/64 loss: 0.3129901885986328
Batch 9/64 loss: 0.30565565824508667
Batch 10/64 loss: 0.31085193157196045
Batch 11/64 loss: 0.3119720220565796
Batch 12/64 loss: 0.3117790222167969
Batch 13/64 loss: 0.3093786835670471
Batch 14/64 loss: 0.31377655267715454
Batch 15/64 loss: 0.3110347390174866
Batch 16/64 loss: 0.31020694971084595
Batch 17/64 loss: 0.3147433400154114
Batch 18/64 loss: 0.3123304843902588
Batch 19/64 loss: 0.3117130994796753
Batch 20/64 loss: 0.3123703598976135
Batch 21/64 loss: 0.3136855363845825
Batch 22/64 loss: 0.31593215465545654
Batch 23/64 loss: 0.3139948844909668
Batch 24/64 loss: 0.3068053126335144
Batch 25/64 loss: 0.30826520919799805
Batch 26/64 loss: 0.31693387031555176
Batch 27/64 loss: 0.3152726888656616
Batch 28/64 loss: 0.3106039762496948
Batch 29/64 loss: 0.3130003809928894
Batch 30/64 loss: 0.3117494583129883
Batch 31/64 loss: 0.31862974166870117
Batch 32/64 loss: 0.3120565414428711
Batch 33/64 loss: 0.3054059147834778
Batch 34/64 loss: 0.31183600425720215
Batch 35/64 loss: 0.31614190340042114
Batch 36/64 loss: 0.31210553646087646
Batch 37/64 loss: 0.3058880567550659
Batch 38/64 loss: 0.3113318085670471
Batch 39/64 loss: 0.3065756559371948
Batch 40/64 loss: 0.3100726008415222
Batch 41/64 loss: 0.3117324113845825
Batch 42/64 loss: 0.3061062693595886
Batch 43/64 loss: 0.3106154203414917
Batch 44/64 loss: 0.3072981834411621
Batch 45/64 loss: 0.3161512613296509
Batch 46/64 loss: 0.3073781132698059
Batch 47/64 loss: 0.3110884428024292
Batch 48/64 loss: 0.31363213062286377
Batch 49/64 loss: 0.32584643363952637
Batch 50/64 loss: 0.31484973430633545
Batch 51/64 loss: 0.3074408769607544
Batch 52/64 loss: 0.30891668796539307
Batch 53/64 loss: 0.30925941467285156
Batch 54/64 loss: 0.3111351728439331
Batch 55/64 loss: 0.3102046251296997
Batch 56/64 loss: 0.31522881984710693
Batch 57/64 loss: 0.3196059465408325
Batch 58/64 loss: 0.3069571256637573
Batch 59/64 loss: 0.31015121936798096
Batch 60/64 loss: 0.31408458948135376
Batch 61/64 loss: 0.31089675426483154
Batch 62/64 loss: 0.31226658821105957
Batch 63/64 loss: 0.3162766695022583
Batch 64/64 loss: 0.31959211826324463
Epoch 143  Train loss: 0.31166422180100983  Val loss: 0.324250476876485
Epoch 144
-------------------------------
Batch 1/64 loss: 0.3125590682029724
Batch 2/64 loss: 0.3141181468963623
Batch 3/64 loss: 0.3060147166252136
Batch 4/64 loss: 0.3151739239692688
Batch 5/64 loss: 0.30593883991241455
Batch 6/64 loss: 0.3114279508590698
Batch 7/64 loss: 0.307489275932312
Batch 8/64 loss: 0.31390905380249023
Batch 9/64 loss: 0.3100975751876831
Batch 10/64 loss: 0.3169790506362915
Batch 11/64 loss: 0.3121998906135559
Batch 12/64 loss: 0.30959296226501465
Batch 13/64 loss: 0.313814640045166
Batch 14/64 loss: 0.3090928792953491
Batch 15/64 loss: 0.3114434480667114
Batch 16/64 loss: 0.3144263029098511
Batch 17/64 loss: 0.3072206974029541
Batch 18/64 loss: 0.31791508197784424
Batch 19/64 loss: 0.3050946593284607
Batch 20/64 loss: 0.31190526485443115
Batch 21/64 loss: 0.3078911304473877
Batch 22/64 loss: 0.31166160106658936
Batch 23/64 loss: 0.31685322523117065
Batch 24/64 loss: 0.30270957946777344
Batch 25/64 loss: 0.31094640493392944
Batch 26/64 loss: 0.31159090995788574
Batch 27/64 loss: 0.30543768405914307
Batch 28/64 loss: 0.3098159432411194
Batch 29/64 loss: 0.3081989288330078
Batch 30/64 loss: 0.31338584423065186
Batch 31/64 loss: 0.3083078861236572
Batch 32/64 loss: 0.3082302212715149
Batch 33/64 loss: 0.32263702154159546
Batch 34/64 loss: 0.30566704273223877
Batch 35/64 loss: 0.30916500091552734
Batch 36/64 loss: 0.3187059164047241
Batch 37/64 loss: 0.30857229232788086
Batch 38/64 loss: 0.3117251396179199
Batch 39/64 loss: 0.31190764904022217
Batch 40/64 loss: 0.3114778995513916
Batch 41/64 loss: 0.31134068965911865
Batch 42/64 loss: 0.3071276545524597
Batch 43/64 loss: 0.314167320728302
Batch 44/64 loss: 0.3102095127105713
Batch 45/64 loss: 0.3153306245803833
Batch 46/64 loss: 0.3074519634246826
Batch 47/64 loss: 0.3165009617805481
Batch 48/64 loss: 0.3092995285987854
Batch 49/64 loss: 0.3130706548690796
Batch 50/64 loss: 0.3136911392211914
Batch 51/64 loss: 0.3104276657104492
Batch 52/64 loss: 0.3110302686691284
Batch 53/64 loss: 0.30817151069641113
Batch 54/64 loss: 0.3059583306312561
Batch 55/64 loss: 0.31143879890441895
Batch 56/64 loss: 0.30838239192962646
Batch 57/64 loss: 0.3066840171813965
Batch 58/64 loss: 0.30449503660202026
Batch 59/64 loss: 0.30955636501312256
Batch 60/64 loss: 0.3113599419593811
Batch 61/64 loss: 0.3058008551597595
Batch 62/64 loss: 0.3088032007217407
Batch 63/64 loss: 0.311698317527771
Batch 64/64 loss: 0.3144350051879883
Epoch 144  Train loss: 0.3107313530117858  Val loss: 0.3229223172279568
Saving best model, epoch: 144
Epoch 145
-------------------------------
Batch 1/64 loss: 0.3111175298690796
Batch 2/64 loss: 0.3128805160522461
Batch 3/64 loss: 0.3145231008529663
Batch 4/64 loss: 0.31327229738235474
Batch 5/64 loss: 0.30899596214294434
Batch 6/64 loss: 0.31503134965896606
Batch 7/64 loss: 0.30756497383117676
Batch 8/64 loss: 0.3101685047149658
Batch 9/64 loss: 0.31422603130340576
Batch 10/64 loss: 0.30689728260040283
Batch 11/64 loss: 0.31118321418762207
Batch 12/64 loss: 0.30934059619903564
Batch 13/64 loss: 0.3188299536705017
Batch 14/64 loss: 0.30768340826034546
Batch 15/64 loss: 0.31140029430389404
Batch 16/64 loss: 0.3073234558105469
Batch 17/64 loss: 0.3104053735733032
Batch 18/64 loss: 0.3083024024963379
Batch 19/64 loss: 0.3103330731391907
Batch 20/64 loss: 0.30892395973205566
Batch 21/64 loss: 0.311784029006958
Batch 22/64 loss: 0.3144153952598572
Batch 23/64 loss: 0.3085106611251831
Batch 24/64 loss: 0.30809831619262695
Batch 25/64 loss: 0.31058061122894287
Batch 26/64 loss: 0.31156253814697266
Batch 27/64 loss: 0.31884944438934326
Batch 28/64 loss: 0.30974090099334717
Batch 29/64 loss: 0.3090660572052002
Batch 30/64 loss: 0.30882400274276733
Batch 31/64 loss: 0.3097517490386963
Batch 32/64 loss: 0.3096035122871399
Batch 33/64 loss: 0.30886197090148926
Batch 34/64 loss: 0.3088788390159607
Batch 35/64 loss: 0.3116580843925476
Batch 36/64 loss: 0.31168830394744873
Batch 37/64 loss: 0.30725955963134766
Batch 38/64 loss: 0.3072240352630615
Batch 39/64 loss: 0.31160712242126465
Batch 40/64 loss: 0.31025230884552
Batch 41/64 loss: 0.310147762298584
Batch 42/64 loss: 0.31133848428726196
Batch 43/64 loss: 0.3100138306617737
Batch 44/64 loss: 0.309301495552063
Batch 45/64 loss: 0.31684327125549316
Batch 46/64 loss: 0.3114205002784729
Batch 47/64 loss: 0.31132441759109497
Batch 48/64 loss: 0.3086353540420532
Batch 49/64 loss: 0.31306254863739014
Batch 50/64 loss: 0.3047139644622803
Batch 51/64 loss: 0.31139516830444336
Batch 52/64 loss: 0.3214423656463623
Batch 53/64 loss: 0.3082568645477295
Batch 54/64 loss: 0.31524771451950073
Batch 55/64 loss: 0.3091404438018799
Batch 56/64 loss: 0.307855486869812
Batch 57/64 loss: 0.30965715646743774
Batch 58/64 loss: 0.3057709336280823
Batch 59/64 loss: 0.3068619966506958
Batch 60/64 loss: 0.3118528127670288
Batch 61/64 loss: 0.31535935401916504
Batch 62/64 loss: 0.30585014820098877
Batch 63/64 loss: 0.3157805800437927
Batch 64/64 loss: 0.3037116527557373
Epoch 145  Train loss: 0.3106772880928189  Val loss: 0.322622415945702
Saving best model, epoch: 145
Epoch 146
-------------------------------
Batch 1/64 loss: 0.3121291399002075
Batch 2/64 loss: 0.3083636164665222
Batch 3/64 loss: 0.3110569715499878
Batch 4/64 loss: 0.3153640031814575
Batch 5/64 loss: 0.3084828853607178
Batch 6/64 loss: 0.3072356581687927
Batch 7/64 loss: 0.30622267723083496
Batch 8/64 loss: 0.3130391836166382
Batch 9/64 loss: 0.3100694417953491
Batch 10/64 loss: 0.31386637687683105
Batch 11/64 loss: 0.30696141719818115
Batch 12/64 loss: 0.3098422884941101
Batch 13/64 loss: 0.31017857789993286
Batch 14/64 loss: 0.3066663146018982
Batch 15/64 loss: 0.306199312210083
Batch 16/64 loss: 0.3196268081665039
Batch 17/64 loss: 0.306618332862854
Batch 18/64 loss: 0.3119456171989441
Batch 19/64 loss: 0.3085803985595703
Batch 20/64 loss: 0.3084512948989868
Batch 21/64 loss: 0.30920761823654175
Batch 22/64 loss: 0.30687201023101807
Batch 23/64 loss: 0.3094003200531006
Batch 24/64 loss: 0.30876123905181885
Batch 25/64 loss: 0.30830132961273193
Batch 26/64 loss: 0.31104564666748047
Batch 27/64 loss: 0.31595945358276367
Batch 28/64 loss: 0.31892693042755127
Batch 29/64 loss: 0.31004709005355835
Batch 30/64 loss: 0.3110753297805786
Batch 31/64 loss: 0.3100320100784302
Batch 32/64 loss: 0.3123645782470703
Batch 33/64 loss: 0.3082001805305481
Batch 34/64 loss: 0.3119872808456421
Batch 35/64 loss: 0.31330299377441406
Batch 36/64 loss: 0.3160826563835144
Batch 37/64 loss: 0.3107888102531433
Batch 38/64 loss: 0.30981963872909546
Batch 39/64 loss: 0.3091069459915161
Batch 40/64 loss: 0.31539273262023926
Batch 41/64 loss: 0.30850541591644287
Batch 42/64 loss: 0.3087979555130005
Batch 43/64 loss: 0.30803877115249634
Batch 44/64 loss: 0.312328577041626
Batch 45/64 loss: 0.30912840366363525
Batch 46/64 loss: 0.30256807804107666
Batch 47/64 loss: 0.30760419368743896
Batch 48/64 loss: 0.31033527851104736
Batch 49/64 loss: 0.30871129035949707
Batch 50/64 loss: 0.30748867988586426
Batch 51/64 loss: 0.307489275932312
Batch 52/64 loss: 0.3096112608909607
Batch 53/64 loss: 0.31088578701019287
Batch 54/64 loss: 0.31264859437942505
Batch 55/64 loss: 0.30623072385787964
Batch 56/64 loss: 0.31201332807540894
Batch 57/64 loss: 0.31288760900497437
Batch 58/64 loss: 0.3116632103919983
Batch 59/64 loss: 0.3104372024536133
Batch 60/64 loss: 0.3137671947479248
Batch 61/64 loss: 0.3081921339035034
Batch 62/64 loss: 0.31072813272476196
Batch 63/64 loss: 0.31424009799957275
Batch 64/64 loss: 0.31533294916152954
Epoch 146  Train loss: 0.3104058983279209  Val loss: 0.3221255741578197
Saving best model, epoch: 146
Epoch 147
-------------------------------
Batch 1/64 loss: 0.31314826011657715
Batch 2/64 loss: 0.30648916959762573
Batch 3/64 loss: 0.30156922340393066
Batch 4/64 loss: 0.307112455368042
Batch 5/64 loss: 0.3153817653656006
Batch 6/64 loss: 0.3087964653968811
Batch 7/64 loss: 0.3088502883911133
Batch 8/64 loss: 0.3185364603996277
Batch 9/64 loss: 0.309345006942749
Batch 10/64 loss: 0.3069339394569397
Batch 11/64 loss: 0.31015217304229736
Batch 12/64 loss: 0.31111305952072144
Batch 13/64 loss: 0.3060252070426941
Batch 14/64 loss: 0.3133963942527771
Batch 15/64 loss: 0.3051220178604126
Batch 16/64 loss: 0.30838602781295776
Batch 17/64 loss: 0.3036198616027832
Batch 18/64 loss: 0.3085066080093384
Batch 19/64 loss: 0.3080388903617859
Batch 20/64 loss: 0.30947673320770264
Batch 21/64 loss: 0.30937910079956055
Batch 22/64 loss: 0.3055838346481323
Batch 23/64 loss: 0.3190575838088989
Batch 24/64 loss: 0.3110179901123047
Batch 25/64 loss: 0.3038734197616577
Batch 26/64 loss: 0.3153890371322632
Batch 27/64 loss: 0.3080369830131531
Batch 28/64 loss: 0.3205493092536926
Batch 29/64 loss: 0.30832892656326294
Batch 30/64 loss: 0.306316614151001
Batch 31/64 loss: 0.30817967653274536
Batch 32/64 loss: 0.31503742933273315
Batch 33/64 loss: 0.3103230595588684
Batch 34/64 loss: 0.3111032247543335
Batch 35/64 loss: 0.30940747261047363
Batch 36/64 loss: 0.3136630058288574
Batch 37/64 loss: 0.3058087229728699
Batch 38/64 loss: 0.30907201766967773
Batch 39/64 loss: 0.30892258882522583
Batch 40/64 loss: 0.30849575996398926
Batch 41/64 loss: 0.31192219257354736
Batch 42/64 loss: 0.30698633193969727
Batch 43/64 loss: 0.3111153841018677
Batch 44/64 loss: 0.3150606155395508
Batch 45/64 loss: 0.3068718910217285
Batch 46/64 loss: 0.3145468831062317
Batch 47/64 loss: 0.30936336517333984
Batch 48/64 loss: 0.30457139015197754
Batch 49/64 loss: 0.3122117519378662
Batch 50/64 loss: 0.3151205778121948
Batch 51/64 loss: 0.3127596974372864
Batch 52/64 loss: 0.31404876708984375
Batch 53/64 loss: 0.306207537651062
Batch 54/64 loss: 0.3059830069541931
Batch 55/64 loss: 0.30930566787719727
Batch 56/64 loss: 0.30818092823028564
Batch 57/64 loss: 0.3068534731864929
Batch 58/64 loss: 0.3048000931739807
Batch 59/64 loss: 0.3058929443359375
Batch 60/64 loss: 0.3125509023666382
Batch 61/64 loss: 0.3145155906677246
Batch 62/64 loss: 0.30871886014938354
Batch 63/64 loss: 0.3099316358566284
Batch 64/64 loss: 0.3049960136413574
Epoch 147  Train loss: 0.30970685902763817  Val loss: 0.3225209682258134
Epoch 148
-------------------------------
Batch 1/64 loss: 0.3090953826904297
Batch 2/64 loss: 0.3034197688102722
Batch 3/64 loss: 0.3003655672073364
Batch 4/64 loss: 0.3049381971359253
Batch 5/64 loss: 0.30343151092529297
Batch 6/64 loss: 0.3079056739807129
Batch 7/64 loss: 0.3069953918457031
Batch 8/64 loss: 0.3174997568130493
Batch 9/64 loss: 0.31254124641418457
Batch 10/64 loss: 0.3055274486541748
Batch 11/64 loss: 0.3133612871170044
Batch 12/64 loss: 0.30911076068878174
Batch 13/64 loss: 0.3120955228805542
Batch 14/64 loss: 0.3047599196434021
Batch 15/64 loss: 0.3101263642311096
Batch 16/64 loss: 0.3152087926864624
Batch 17/64 loss: 0.30185723304748535
Batch 18/64 loss: 0.3054622411727905
Batch 19/64 loss: 0.3132001757621765
Batch 20/64 loss: 0.3072197437286377
Batch 21/64 loss: 0.3104771375656128
Batch 22/64 loss: 0.30550384521484375
Batch 23/64 loss: 0.3198155164718628
Batch 24/64 loss: 0.30696260929107666
Batch 25/64 loss: 0.31010258197784424
Batch 26/64 loss: 0.31215900182724
Batch 27/64 loss: 0.3116034269332886
Batch 28/64 loss: 0.30782341957092285
Batch 29/64 loss: 0.31261229515075684
Batch 30/64 loss: 0.3209107518196106
Batch 31/64 loss: 0.31061965227127075
Batch 32/64 loss: 0.30925190448760986
Batch 33/64 loss: 0.30607664585113525
Batch 34/64 loss: 0.3130350112915039
Batch 35/64 loss: 0.3098093271255493
Batch 36/64 loss: 0.3094899654388428
Batch 37/64 loss: 0.31528931856155396
Batch 38/64 loss: 0.30759209394454956
Batch 39/64 loss: 0.30561375617980957
Batch 40/64 loss: 0.30682289600372314
Batch 41/64 loss: 0.3167867660522461
Batch 42/64 loss: 0.3105030059814453
Batch 43/64 loss: 0.3134322166442871
Batch 44/64 loss: 0.309812068939209
Batch 45/64 loss: 0.31345856189727783
Batch 46/64 loss: 0.31219542026519775
Batch 47/64 loss: 0.31782060861587524
Batch 48/64 loss: 0.30722057819366455
Batch 49/64 loss: 0.31331396102905273
Batch 50/64 loss: 0.3123629093170166
Batch 51/64 loss: 0.3057316541671753
Batch 52/64 loss: 0.31199324131011963
Batch 53/64 loss: 0.31348323822021484
Batch 54/64 loss: 0.3103410601615906
Batch 55/64 loss: 0.3010020852088928
Batch 56/64 loss: 0.3031883239746094
Batch 57/64 loss: 0.309675395488739
Batch 58/64 loss: 0.3109562397003174
Batch 59/64 loss: 0.31556904315948486
Batch 60/64 loss: 0.30808305740356445
Batch 61/64 loss: 0.3082274794578552
Batch 62/64 loss: 0.3114306926727295
Batch 63/64 loss: 0.3100329637527466
Batch 64/64 loss: 0.3074348568916321
Epoch 148  Train loss: 0.30984925265405694  Val loss: 0.32322669582268626
Epoch 149
-------------------------------
Batch 1/64 loss: 0.3064306974411011
Batch 2/64 loss: 0.3173534870147705
Batch 3/64 loss: 0.3033139705657959
Batch 4/64 loss: 0.3050838112831116
Batch 5/64 loss: 0.3087161183357239
Batch 6/64 loss: 0.30721980333328247
Batch 7/64 loss: 0.3064320683479309
Batch 8/64 loss: 0.3057006597518921
Batch 9/64 loss: 0.3101869821548462
Batch 10/64 loss: 0.3137117624282837
Batch 11/64 loss: 0.30472779273986816
Batch 12/64 loss: 0.30552828311920166
Batch 13/64 loss: 0.3047468066215515
Batch 14/64 loss: 0.30952560901641846
Batch 15/64 loss: 0.30822622776031494
Batch 16/64 loss: 0.31048154830932617
Batch 17/64 loss: 0.30858927965164185
Batch 18/64 loss: 0.3047558069229126
Batch 19/64 loss: 0.3080780506134033
Batch 20/64 loss: 0.3077288866043091
Batch 21/64 loss: 0.3134877681732178
Batch 22/64 loss: 0.3107990026473999
Batch 23/64 loss: 0.30869412422180176
Batch 24/64 loss: 0.3081028461456299
Batch 25/64 loss: 0.3098309636116028
Batch 26/64 loss: 0.30777889490127563
Batch 27/64 loss: 0.3077976703643799
Batch 28/64 loss: 0.31217169761657715
Batch 29/64 loss: 0.3112197518348694
Batch 30/64 loss: 0.3164135813713074
Batch 31/64 loss: 0.3093080520629883
Batch 32/64 loss: 0.3116903305053711
Batch 33/64 loss: 0.30935585498809814
Batch 34/64 loss: 0.31282269954681396
Batch 35/64 loss: 0.3147547245025635
Batch 36/64 loss: 0.31619590520858765
Batch 37/64 loss: 0.31083106994628906
Batch 38/64 loss: 0.3030824661254883
Batch 39/64 loss: 0.3082643747329712
Batch 40/64 loss: 0.31303179264068604
Batch 41/64 loss: 0.3094635605812073
Batch 42/64 loss: 0.3100743293762207
Batch 43/64 loss: 0.30666399002075195
Batch 44/64 loss: 0.3146399259567261
Batch 45/64 loss: 0.31069356203079224
Batch 46/64 loss: 0.31375235319137573
Batch 47/64 loss: 0.3058040738105774
Batch 48/64 loss: 0.3105013370513916
Batch 49/64 loss: 0.3048620820045471
Batch 50/64 loss: 0.30805468559265137
Batch 51/64 loss: 0.30831241607666016
Batch 52/64 loss: 0.31151556968688965
Batch 53/64 loss: 0.31492406129837036
Batch 54/64 loss: 0.30839139223098755
Batch 55/64 loss: 0.3104480504989624
Batch 56/64 loss: 0.30804502964019775
Batch 57/64 loss: 0.3069130778312683
Batch 58/64 loss: 0.31075674295425415
Batch 59/64 loss: 0.31152045726776123
Batch 60/64 loss: 0.3062272071838379
Batch 61/64 loss: 0.3133677840232849
Batch 62/64 loss: 0.3138713836669922
Batch 63/64 loss: 0.300307035446167
Batch 64/64 loss: 0.31602364778518677
Epoch 149  Train loss: 0.3094635147674411  Val loss: 0.3224988626860261
Epoch 150
-------------------------------
Batch 1/64 loss: 0.31104427576065063
Batch 2/64 loss: 0.3079577088356018
Batch 3/64 loss: 0.30690741539001465
Batch 4/64 loss: 0.31245487928390503
Batch 5/64 loss: 0.3128533959388733
Batch 6/64 loss: 0.30541765689849854
Batch 7/64 loss: 0.3090226650238037
Batch 8/64 loss: 0.30594170093536377
Batch 9/64 loss: 0.3154792785644531
Batch 10/64 loss: 0.3189105987548828
Batch 11/64 loss: 0.30679386854171753
Batch 12/64 loss: 0.3084390163421631
Batch 13/64 loss: 0.30966752767562866
Batch 14/64 loss: 0.31323349475860596
Batch 15/64 loss: 0.30513787269592285
Batch 16/64 loss: 0.3115572929382324
Batch 17/64 loss: 0.3127434253692627
Batch 18/64 loss: 0.3127176761627197
Batch 19/64 loss: 0.3086130619049072
Batch 20/64 loss: 0.31054389476776123
Batch 21/64 loss: 0.31049323081970215
Batch 22/64 loss: 0.3096740245819092
Batch 23/64 loss: 0.30465149879455566
Batch 24/64 loss: 0.31149351596832275
Batch 25/64 loss: 0.30652427673339844
Batch 26/64 loss: 0.3101698160171509
Batch 27/64 loss: 0.30678844451904297
Batch 28/64 loss: 0.3080611228942871
Batch 29/64 loss: 0.31142449378967285
Batch 30/64 loss: 0.31234192848205566
Batch 31/64 loss: 0.3146398663520813
Batch 32/64 loss: 0.31433361768722534
Batch 33/64 loss: 0.3155149221420288
Batch 34/64 loss: 0.31483274698257446
Batch 35/64 loss: 0.31529760360717773
Batch 36/64 loss: 0.30217891931533813
Batch 37/64 loss: 0.3077549934387207
Batch 38/64 loss: 0.30749428272247314
Batch 39/64 loss: 0.3066974878311157
Batch 40/64 loss: 0.30814313888549805
Batch 41/64 loss: 0.3077573776245117
Batch 42/64 loss: 0.2997337579727173
Batch 43/64 loss: 0.30204951763153076
Batch 44/64 loss: 0.3135160207748413
Batch 45/64 loss: 0.3151822090148926
Batch 46/64 loss: 0.30834776163101196
Batch 47/64 loss: 0.309850811958313
Batch 48/64 loss: 0.3044087886810303
Batch 49/64 loss: 0.3177741765975952
Batch 50/64 loss: 0.3048396110534668
Batch 51/64 loss: 0.3102850914001465
Batch 52/64 loss: 0.3075838088989258
Batch 53/64 loss: 0.30717456340789795
Batch 54/64 loss: 0.3138469457626343
Batch 55/64 loss: 0.3011115789413452
Batch 56/64 loss: 0.31296879053115845
Batch 57/64 loss: 0.3160973787307739
Batch 58/64 loss: 0.30690157413482666
Batch 59/64 loss: 0.3107677698135376
Batch 60/64 loss: 0.3107110857963562
Batch 61/64 loss: 0.30742084980010986
Batch 62/64 loss: 0.30756282806396484
Batch 63/64 loss: 0.30740886926651
Batch 64/64 loss: 0.30841064453125
Epoch 150  Train loss: 0.30962440453323664  Val loss: 0.32186145757891466
Saving best model, epoch: 150
Epoch 151
-------------------------------
Batch 1/64 loss: 0.30690068006515503
Batch 2/64 loss: 0.31412720680236816
Batch 3/64 loss: 0.3009865880012512
Batch 4/64 loss: 0.30725109577178955
Batch 5/64 loss: 0.30867457389831543
Batch 6/64 loss: 0.30615532398223877
Batch 7/64 loss: 0.31085503101348877
Batch 8/64 loss: 0.30704963207244873
Batch 9/64 loss: 0.3024735450744629
Batch 10/64 loss: 0.3013803958892822
Batch 11/64 loss: 0.30806171894073486
Batch 12/64 loss: 0.30629682540893555
Batch 13/64 loss: 0.3159257769584656
Batch 14/64 loss: 0.3050399422645569
Batch 15/64 loss: 0.30542194843292236
Batch 16/64 loss: 0.3082766532897949
Batch 17/64 loss: 0.31530165672302246
Batch 18/64 loss: 0.3088432550430298
Batch 19/64 loss: 0.31089919805526733
Batch 20/64 loss: 0.3024120330810547
Batch 21/64 loss: 0.3092764616012573
Batch 22/64 loss: 0.30304789543151855
Batch 23/64 loss: 0.30972033739089966
Batch 24/64 loss: 0.3100614547729492
Batch 25/64 loss: 0.30959999561309814
Batch 26/64 loss: 0.32080113887786865
Batch 27/64 loss: 0.30926066637039185
Batch 28/64 loss: 0.3090296983718872
Batch 29/64 loss: 0.30422693490982056
Batch 30/64 loss: 0.3095061779022217
Batch 31/64 loss: 0.3046180009841919
Batch 32/64 loss: 0.30085957050323486
Batch 33/64 loss: 0.3128429651260376
Batch 34/64 loss: 0.305885374546051
Batch 35/64 loss: 0.30886369943618774
Batch 36/64 loss: 0.3134310245513916
Batch 37/64 loss: 0.30222171545028687
Batch 38/64 loss: 0.3079621195793152
Batch 39/64 loss: 0.30492502450942993
Batch 40/64 loss: 0.30377817153930664
Batch 41/64 loss: 0.3174370527267456
Batch 42/64 loss: 0.30930638313293457
Batch 43/64 loss: 0.30941617488861084
Batch 44/64 loss: 0.30785298347473145
Batch 45/64 loss: 0.3044698238372803
Batch 46/64 loss: 0.3092503547668457
Batch 47/64 loss: 0.31145918369293213
Batch 48/64 loss: 0.3073885440826416
Batch 49/64 loss: 0.3077964782714844
Batch 50/64 loss: 0.3133423328399658
Batch 51/64 loss: 0.31257063150405884
Batch 52/64 loss: 0.3124403953552246
Batch 53/64 loss: 0.3142143487930298
Batch 54/64 loss: 0.31054437160491943
Batch 55/64 loss: 0.3031434416770935
Batch 56/64 loss: 0.3086933493614197
Batch 57/64 loss: 0.3117099404335022
Batch 58/64 loss: 0.31669288873672485
Batch 59/64 loss: 0.31436610221862793
Batch 60/64 loss: 0.3180881142616272
Batch 61/64 loss: 0.3018413782119751
Batch 62/64 loss: 0.30684399604797363
Batch 63/64 loss: 0.31135308742523193
Batch 64/64 loss: 0.3071697950363159
Epoch 151  Train loss: 0.3087505915585686  Val loss: 0.32124598616177275
Saving best model, epoch: 151
Epoch 152
-------------------------------
Batch 1/64 loss: 0.3061308264732361
Batch 2/64 loss: 0.3103597164154053
Batch 3/64 loss: 0.30715566873550415
Batch 4/64 loss: 0.3104809522628784
Batch 5/64 loss: 0.312099814414978
Batch 6/64 loss: 0.3085193634033203
Batch 7/64 loss: 0.3100072145462036
Batch 8/64 loss: 0.3088796138763428
Batch 9/64 loss: 0.3064391613006592
Batch 10/64 loss: 0.30600857734680176
Batch 11/64 loss: 0.30913853645324707
Batch 12/64 loss: 0.30413830280303955
Batch 13/64 loss: 0.31629854440689087
Batch 14/64 loss: 0.3034718632698059
Batch 15/64 loss: 0.3120580315589905
Batch 16/64 loss: 0.3104069232940674
Batch 17/64 loss: 0.30902862548828125
Batch 18/64 loss: 0.3074147701263428
Batch 19/64 loss: 0.3096362352371216
Batch 20/64 loss: 0.30825817584991455
Batch 21/64 loss: 0.30622124671936035
Batch 22/64 loss: 0.3086567521095276
Batch 23/64 loss: 0.3064258098602295
Batch 24/64 loss: 0.30497074127197266
Batch 25/64 loss: 0.3122251033782959
Batch 26/64 loss: 0.3110255002975464
Batch 27/64 loss: 0.3115999102592468
Batch 28/64 loss: 0.30800801515579224
Batch 29/64 loss: 0.3075639605522156
Batch 30/64 loss: 0.306862473487854
Batch 31/64 loss: 0.30250078439712524
Batch 32/64 loss: 0.3091738820075989
Batch 33/64 loss: 0.31451737880706787
Batch 34/64 loss: 0.30429989099502563
Batch 35/64 loss: 0.3110320568084717
Batch 36/64 loss: 0.311140775680542
Batch 37/64 loss: 0.30848491191864014
Batch 38/64 loss: 0.3123660683631897
Batch 39/64 loss: 0.3049764633178711
Batch 40/64 loss: 0.30577147006988525
Batch 41/64 loss: 0.31547659635543823
Batch 42/64 loss: 0.30960988998413086
Batch 43/64 loss: 0.3091849684715271
Batch 44/64 loss: 0.307453989982605
Batch 45/64 loss: 0.31183433532714844
Batch 46/64 loss: 0.30483269691467285
Batch 47/64 loss: 0.3103235960006714
Batch 48/64 loss: 0.3099641799926758
Batch 49/64 loss: 0.3105379343032837
Batch 50/64 loss: 0.30989885330200195
Batch 51/64 loss: 0.3085620403289795
Batch 52/64 loss: 0.306050181388855
Batch 53/64 loss: 0.3045814633369446
Batch 54/64 loss: 0.3083679676055908
Batch 55/64 loss: 0.30772554874420166
Batch 56/64 loss: 0.3073585033416748
Batch 57/64 loss: 0.3129688501358032
Batch 58/64 loss: 0.31363558769226074
Batch 59/64 loss: 0.30768948793411255
Batch 60/64 loss: 0.3065195083618164
Batch 61/64 loss: 0.3044813871383667
Batch 62/64 loss: 0.3114948868751526
Batch 63/64 loss: 0.3075050115585327
Batch 64/64 loss: 0.29945307970046997
Epoch 152  Train loss: 0.3086180609815261  Val loss: 0.3209294084830792
Saving best model, epoch: 152
Epoch 153
-------------------------------
Batch 1/64 loss: 0.31059956550598145
Batch 2/64 loss: 0.30850791931152344
Batch 3/64 loss: 0.305273175239563
Batch 4/64 loss: 0.31024736166000366
Batch 5/64 loss: 0.30664634704589844
Batch 6/64 loss: 0.3076155185699463
Batch 7/64 loss: 0.3101373314857483
Batch 8/64 loss: 0.3024619221687317
Batch 9/64 loss: 0.30332958698272705
Batch 10/64 loss: 0.3094416856765747
Batch 11/64 loss: 0.3062461018562317
Batch 12/64 loss: 0.30951881408691406
Batch 13/64 loss: 0.31532466411590576
Batch 14/64 loss: 0.30947935581207275
Batch 15/64 loss: 0.31050992012023926
Batch 16/64 loss: 0.3091999292373657
Batch 17/64 loss: 0.3048328161239624
Batch 18/64 loss: 0.3064849376678467
Batch 19/64 loss: 0.30411672592163086
Batch 20/64 loss: 0.2997323274612427
Batch 21/64 loss: 0.3125191926956177
Batch 22/64 loss: 0.30869221687316895
Batch 23/64 loss: 0.30911409854888916
Batch 24/64 loss: 0.30193597078323364
Batch 25/64 loss: 0.308350145816803
Batch 26/64 loss: 0.3031611442565918
Batch 27/64 loss: 0.3067566156387329
Batch 28/64 loss: 0.3069385290145874
Batch 29/64 loss: 0.30534791946411133
Batch 30/64 loss: 0.3047165274620056
Batch 31/64 loss: 0.30802857875823975
Batch 32/64 loss: 0.30723297595977783
Batch 33/64 loss: 0.3039907217025757
Batch 34/64 loss: 0.31289923191070557
Batch 35/64 loss: 0.3096686601638794
Batch 36/64 loss: 0.31337428092956543
Batch 37/64 loss: 0.31233322620391846
Batch 38/64 loss: 0.3130810260772705
Batch 39/64 loss: 0.30857622623443604
Batch 40/64 loss: 0.30904674530029297
Batch 41/64 loss: 0.31752943992614746
Batch 42/64 loss: 0.3085120916366577
Batch 43/64 loss: 0.3023519515991211
Batch 44/64 loss: 0.30899345874786377
Batch 45/64 loss: 0.30670326948165894
Batch 46/64 loss: 0.30917251110076904
Batch 47/64 loss: 0.3007766604423523
Batch 48/64 loss: 0.30605196952819824
Batch 49/64 loss: 0.3143683075904846
Batch 50/64 loss: 0.31099510192871094
Batch 51/64 loss: 0.31073278188705444
Batch 52/64 loss: 0.30223554372787476
Batch 53/64 loss: 0.3133159875869751
Batch 54/64 loss: 0.3027440309524536
Batch 55/64 loss: 0.30230826139450073
Batch 56/64 loss: 0.3050772547721863
Batch 57/64 loss: 0.30252671241760254
Batch 58/64 loss: 0.30469661951065063
Batch 59/64 loss: 0.3085588216781616
Batch 60/64 loss: 0.3116918206214905
Batch 61/64 loss: 0.3137538433074951
Batch 62/64 loss: 0.3035242557525635
Batch 63/64 loss: 0.31459784507751465
Batch 64/64 loss: 0.31193220615386963
Epoch 153  Train loss: 0.30793157231573964  Val loss: 0.321110004002286
Epoch 154
-------------------------------
Batch 1/64 loss: 0.30623090267181396
Batch 2/64 loss: 0.30818748474121094
Batch 3/64 loss: 0.3057236075401306
Batch 4/64 loss: 0.31030142307281494
Batch 5/64 loss: 0.3028312921524048
Batch 6/64 loss: 0.30635619163513184
Batch 7/64 loss: 0.3061455488204956
Batch 8/64 loss: 0.31073296070098877
Batch 9/64 loss: 0.3123050928115845
Batch 10/64 loss: 0.30736029148101807
Batch 11/64 loss: 0.31185460090637207
Batch 12/64 loss: 0.3084896206855774
Batch 13/64 loss: 0.30420243740081787
Batch 14/64 loss: 0.3043440580368042
Batch 15/64 loss: 0.308590829372406
Batch 16/64 loss: 0.3107476234436035
Batch 17/64 loss: 0.31181126832962036
Batch 18/64 loss: 0.3075920343399048
Batch 19/64 loss: 0.30515730381011963
Batch 20/64 loss: 0.3078188896179199
Batch 21/64 loss: 0.30039381980895996
Batch 22/64 loss: 0.3106275200843811
Batch 23/64 loss: 0.3072105050086975
Batch 24/64 loss: 0.3111034631729126
Batch 25/64 loss: 0.30509912967681885
Batch 26/64 loss: 0.3049194812774658
Batch 27/64 loss: 0.3066622018814087
Batch 28/64 loss: 0.3088921308517456
Batch 29/64 loss: 0.3082873821258545
Batch 30/64 loss: 0.31204521656036377
Batch 31/64 loss: 0.30555808544158936
Batch 32/64 loss: 0.3052974343299866
Batch 33/64 loss: 0.30960899591445923
Batch 34/64 loss: 0.31059765815734863
Batch 35/64 loss: 0.3054373264312744
Batch 36/64 loss: 0.30630528926849365
Batch 37/64 loss: 0.30989861488342285
Batch 38/64 loss: 0.30575835704803467
Batch 39/64 loss: 0.3051552176475525
Batch 40/64 loss: 0.3023601174354553
Batch 41/64 loss: 0.30806291103363037
Batch 42/64 loss: 0.3089557886123657
Batch 43/64 loss: 0.3080689311027527
Batch 44/64 loss: 0.30848264694213867
Batch 45/64 loss: 0.3100442886352539
Batch 46/64 loss: 0.311592698097229
Batch 47/64 loss: 0.31297677755355835
Batch 48/64 loss: 0.3011057376861572
Batch 49/64 loss: 0.3062151074409485
Batch 50/64 loss: 0.311023473739624
Batch 51/64 loss: 0.30766844749450684
Batch 52/64 loss: 0.31001055240631104
Batch 53/64 loss: 0.31179118156433105
Batch 54/64 loss: 0.31616318225860596
Batch 55/64 loss: 0.30308234691619873
Batch 56/64 loss: 0.3115431070327759
Batch 57/64 loss: 0.3042048215866089
Batch 58/64 loss: 0.3065710663795471
Batch 59/64 loss: 0.31122350692749023
Batch 60/64 loss: 0.30673909187316895
Batch 61/64 loss: 0.30790138244628906
Batch 62/64 loss: 0.305198073387146
Batch 63/64 loss: 0.3069087862968445
Batch 64/64 loss: 0.30949485301971436
Epoch 154  Train loss: 0.3078534346000821  Val loss: 0.32134913742747095
Epoch 155
-------------------------------
Batch 1/64 loss: 0.307270884513855
Batch 2/64 loss: 0.30843794345855713
Batch 3/64 loss: 0.30877482891082764
Batch 4/64 loss: 0.3075416088104248
Batch 5/64 loss: 0.30677276849746704
Batch 6/64 loss: 0.31185436248779297
Batch 7/64 loss: 0.3092431426048279
Batch 8/64 loss: 0.3097275495529175
Batch 9/64 loss: 0.30846166610717773
Batch 10/64 loss: 0.3085615038871765
Batch 11/64 loss: 0.3029048442840576
Batch 12/64 loss: 0.30904698371887207
Batch 13/64 loss: 0.3112165927886963
Batch 14/64 loss: 0.30438756942749023
Batch 15/64 loss: 0.31683480739593506
Batch 16/64 loss: 0.3041926622390747
Batch 17/64 loss: 0.3084731101989746
Batch 18/64 loss: 0.308854341506958
Batch 19/64 loss: 0.3089916706085205
Batch 20/64 loss: 0.3078373074531555
Batch 21/64 loss: 0.30430692434310913
Batch 22/64 loss: 0.315668523311615
Batch 23/64 loss: 0.3077649474143982
Batch 24/64 loss: 0.30794352293014526
Batch 25/64 loss: 0.3083258867263794
Batch 26/64 loss: 0.31825363636016846
Batch 27/64 loss: 0.30785733461380005
Batch 28/64 loss: 0.3100959062576294
Batch 29/64 loss: 0.31133460998535156
Batch 30/64 loss: 0.30952584743499756
Batch 31/64 loss: 0.3107231855392456
Batch 32/64 loss: 0.3135138154029846
Batch 33/64 loss: 0.30792927742004395
Batch 34/64 loss: 0.30624115467071533
Batch 35/64 loss: 0.2987382411956787
Batch 36/64 loss: 0.31155288219451904
Batch 37/64 loss: 0.30773359537124634
Batch 38/64 loss: 0.30191004276275635
Batch 39/64 loss: 0.3059276342391968
Batch 40/64 loss: 0.30335068702697754
Batch 41/64 loss: 0.3054157495498657
Batch 42/64 loss: 0.31098681688308716
Batch 43/64 loss: 0.31010186672210693
Batch 44/64 loss: 0.2987380027770996
Batch 45/64 loss: 0.30620771646499634
Batch 46/64 loss: 0.31754040718078613
Batch 47/64 loss: 0.30716943740844727
Batch 48/64 loss: 0.308042049407959
Batch 49/64 loss: 0.31330883502960205
Batch 50/64 loss: 0.31110429763793945
Batch 51/64 loss: 0.30221521854400635
Batch 52/64 loss: 0.3097982406616211
Batch 53/64 loss: 0.30476367473602295
Batch 54/64 loss: 0.2974780797958374
Batch 55/64 loss: 0.3048255443572998
Batch 56/64 loss: 0.3140144348144531
Batch 57/64 loss: 0.3043990135192871
Batch 58/64 loss: 0.31265223026275635
Batch 59/64 loss: 0.3200201988220215
Batch 60/64 loss: 0.3055785298347473
Batch 61/64 loss: 0.3016924262046814
Batch 62/64 loss: 0.3071860074996948
Batch 63/64 loss: 0.3115135431289673
Batch 64/64 loss: 0.30587947368621826
Epoch 155  Train loss: 0.3082705212574379  Val loss: 0.32061264564081565
Saving best model, epoch: 155
Epoch 156
-------------------------------
Batch 1/64 loss: 0.3043559193611145
Batch 2/64 loss: 0.30388128757476807
Batch 3/64 loss: 0.3070889711380005
Batch 4/64 loss: 0.30198705196380615
Batch 5/64 loss: 0.30346351861953735
Batch 6/64 loss: 0.3080631494522095
Batch 7/64 loss: 0.30622756481170654
Batch 8/64 loss: 0.3099857568740845
Batch 9/64 loss: 0.30946218967437744
Batch 10/64 loss: 0.31048572063446045
Batch 11/64 loss: 0.3021862506866455
Batch 12/64 loss: 0.3088172674179077
Batch 13/64 loss: 0.3026801347732544
Batch 14/64 loss: 0.30457669496536255
Batch 15/64 loss: 0.30262553691864014
Batch 16/64 loss: 0.3016355037689209
Batch 17/64 loss: 0.3051885962486267
Batch 18/64 loss: 0.30631399154663086
Batch 19/64 loss: 0.31265008449554443
Batch 20/64 loss: 0.30012935400009155
Batch 21/64 loss: 0.3063856363296509
Batch 22/64 loss: 0.31223154067993164
Batch 23/64 loss: 0.30956315994262695
Batch 24/64 loss: 0.30832338333129883
Batch 25/64 loss: 0.3048515319824219
Batch 26/64 loss: 0.30482685565948486
Batch 27/64 loss: 0.3126736879348755
Batch 28/64 loss: 0.3062092065811157
Batch 29/64 loss: 0.3002849817276001
Batch 30/64 loss: 0.3113347291946411
Batch 31/64 loss: 0.31663763523101807
Batch 32/64 loss: 0.3051455020904541
Batch 33/64 loss: 0.3092450499534607
Batch 34/64 loss: 0.3034745454788208
Batch 35/64 loss: 0.30818819999694824
Batch 36/64 loss: 0.3132714033126831
Batch 37/64 loss: 0.30291759967803955
Batch 38/64 loss: 0.3039621114730835
Batch 39/64 loss: 0.3058381676673889
Batch 40/64 loss: 0.3061027526855469
Batch 41/64 loss: 0.3121621012687683
Batch 42/64 loss: 0.30442535877227783
Batch 43/64 loss: 0.31206417083740234
Batch 44/64 loss: 0.314039409160614
Batch 45/64 loss: 0.31025826930999756
Batch 46/64 loss: 0.3063775300979614
Batch 47/64 loss: 0.31182563304901123
Batch 48/64 loss: 0.31199008226394653
Batch 49/64 loss: 0.3067775368690491
Batch 50/64 loss: 0.30398881435394287
Batch 51/64 loss: 0.3072569966316223
Batch 52/64 loss: 0.3089263439178467
Batch 53/64 loss: 0.3046954870223999
Batch 54/64 loss: 0.3078843355178833
Batch 55/64 loss: 0.30153703689575195
Batch 56/64 loss: 0.31383204460144043
Batch 57/64 loss: 0.30411404371261597
Batch 58/64 loss: 0.3023732900619507
Batch 59/64 loss: 0.30571454763412476
Batch 60/64 loss: 0.30489349365234375
Batch 61/64 loss: 0.31305885314941406
Batch 62/64 loss: 0.30987703800201416
Batch 63/64 loss: 0.3118419647216797
Batch 64/64 loss: 0.30402708053588867
Epoch 156  Train loss: 0.3071561869452981  Val loss: 0.32102317478238923
Epoch 157
-------------------------------
Batch 1/64 loss: 0.31210076808929443
Batch 2/64 loss: 0.30785882472991943
Batch 3/64 loss: 0.31229114532470703
Batch 4/64 loss: 0.30348342657089233
Batch 5/64 loss: 0.3030189275741577
Batch 6/64 loss: 0.30752772092819214
Batch 7/64 loss: 0.30781251192092896
Batch 8/64 loss: 0.3037300109863281
Batch 9/64 loss: 0.3097112774848938
Batch 10/64 loss: 0.3109571933746338
Batch 11/64 loss: 0.29887640476226807
Batch 12/64 loss: 0.30964505672454834
Batch 13/64 loss: 0.30910056829452515
Batch 14/64 loss: 0.3026581406593323
Batch 15/64 loss: 0.3088417649269104
Batch 16/64 loss: 0.3130210041999817
Batch 17/64 loss: 0.32108986377716064
Batch 18/64 loss: 0.3085474967956543
Batch 19/64 loss: 0.30555254220962524
Batch 20/64 loss: 0.3067963123321533
Batch 21/64 loss: 0.3107638955116272
Batch 22/64 loss: 0.3040934205055237
Batch 23/64 loss: 0.31076526641845703
Batch 24/64 loss: 0.3074291944503784
Batch 25/64 loss: 0.3116757869720459
Batch 26/64 loss: 0.29995661973953247
Batch 27/64 loss: 0.30696338415145874
Batch 28/64 loss: 0.30260270833969116
Batch 29/64 loss: 0.3076196312904358
Batch 30/64 loss: 0.3042623996734619
Batch 31/64 loss: 0.3084423542022705
Batch 32/64 loss: 0.30431032180786133
Batch 33/64 loss: 0.3039257526397705
Batch 34/64 loss: 0.3058321475982666
Batch 35/64 loss: 0.3033323287963867
Batch 36/64 loss: 0.3060997724533081
Batch 37/64 loss: 0.3067125678062439
Batch 38/64 loss: 0.30327296257019043
Batch 39/64 loss: 0.311177134513855
Batch 40/64 loss: 0.3038283586502075
Batch 41/64 loss: 0.3045074939727783
Batch 42/64 loss: 0.30469977855682373
Batch 43/64 loss: 0.30569326877593994
Batch 44/64 loss: 0.31203508377075195
Batch 45/64 loss: 0.3088896870613098
Batch 46/64 loss: 0.31200700998306274
Batch 47/64 loss: 0.31056052446365356
Batch 48/64 loss: 0.30441951751708984
Batch 49/64 loss: 0.30721139907836914
Batch 50/64 loss: 0.3073907494544983
Batch 51/64 loss: 0.3088682293891907
Batch 52/64 loss: 0.3135707974433899
Batch 53/64 loss: 0.3016335368156433
Batch 54/64 loss: 0.30065256357192993
Batch 55/64 loss: 0.30324894189834595
Batch 56/64 loss: 0.30739617347717285
Batch 57/64 loss: 0.31136178970336914
Batch 58/64 loss: 0.3050658106803894
Batch 59/64 loss: 0.30984389781951904
Batch 60/64 loss: 0.3038570284843445
Batch 61/64 loss: 0.2984342575073242
Batch 62/64 loss: 0.3048520088195801
Batch 63/64 loss: 0.2999767065048218
Batch 64/64 loss: 0.3091300129890442
Epoch 157  Train loss: 0.3068817370078143  Val loss: 0.3213328545036185
Epoch 158
-------------------------------
Batch 1/64 loss: 0.30345189571380615
Batch 2/64 loss: 0.3055959939956665
Batch 3/64 loss: 0.3027256727218628
Batch 4/64 loss: 0.3067287802696228
Batch 5/64 loss: 0.30568253993988037
Batch 6/64 loss: 0.30963361263275146
Batch 7/64 loss: 0.3033829927444458
Batch 8/64 loss: 0.30755388736724854
Batch 9/64 loss: 0.2990865707397461
Batch 10/64 loss: 0.3058350682258606
Batch 11/64 loss: 0.30932319164276123
Batch 12/64 loss: 0.30158013105392456
Batch 13/64 loss: 0.30232512950897217
Batch 14/64 loss: 0.31209808588027954
Batch 15/64 loss: 0.3090798854827881
Batch 16/64 loss: 0.30412280559539795
Batch 17/64 loss: 0.3087039589881897
Batch 18/64 loss: 0.30153149366378784
Batch 19/64 loss: 0.30394136905670166
Batch 20/64 loss: 0.3068188428878784
Batch 21/64 loss: 0.30965161323547363
Batch 22/64 loss: 0.3079907298088074
Batch 23/64 loss: 0.29864823818206787
Batch 24/64 loss: 0.30714643001556396
Batch 25/64 loss: 0.30278968811035156
Batch 26/64 loss: 0.3032968044281006
Batch 27/64 loss: 0.30591845512390137
Batch 28/64 loss: 0.306204617023468
Batch 29/64 loss: 0.30770134925842285
Batch 30/64 loss: 0.3106762170791626
Batch 31/64 loss: 0.3149099349975586
Batch 32/64 loss: 0.31115567684173584
Batch 33/64 loss: 0.3036816716194153
Batch 34/64 loss: 0.30594784021377563
Batch 35/64 loss: 0.30044233798980713
Batch 36/64 loss: 0.3040955066680908
Batch 37/64 loss: 0.3092454671859741
Batch 38/64 loss: 0.3008580803871155
Batch 39/64 loss: 0.30821752548217773
Batch 40/64 loss: 0.30998140573501587
Batch 41/64 loss: 0.30270564556121826
Batch 42/64 loss: 0.3023642897605896
Batch 43/64 loss: 0.31139302253723145
Batch 44/64 loss: 0.3042910099029541
Batch 45/64 loss: 0.3048872947692871
Batch 46/64 loss: 0.30636847019195557
Batch 47/64 loss: 0.3147515654563904
Batch 48/64 loss: 0.30203789472579956
Batch 49/64 loss: 0.3069124221801758
Batch 50/64 loss: 0.3145899176597595
Batch 51/64 loss: 0.30809253454208374
Batch 52/64 loss: 0.30238664150238037
Batch 53/64 loss: 0.308584988117218
Batch 54/64 loss: 0.30849194526672363
Batch 55/64 loss: 0.31130897998809814
Batch 56/64 loss: 0.3100423216819763
Batch 57/64 loss: 0.30281686782836914
Batch 58/64 loss: 0.30555588006973267
Batch 59/64 loss: 0.31019771099090576
Batch 60/64 loss: 0.3045612573623657
Batch 61/64 loss: 0.310258150100708
Batch 62/64 loss: 0.3103904128074646
Batch 63/64 loss: 0.31044405698776245
Batch 64/64 loss: 0.31108182668685913
Epoch 158  Train loss: 0.30658048858829573  Val loss: 0.32196235882047936
Epoch 159
-------------------------------
Batch 1/64 loss: 0.296442449092865
Batch 2/64 loss: 0.29892241954803467
Batch 3/64 loss: 0.31516033411026
Batch 4/64 loss: 0.30380547046661377
Batch 5/64 loss: 0.31118351221084595
Batch 6/64 loss: 0.30227625370025635
Batch 7/64 loss: 0.30582940578460693
Batch 8/64 loss: 0.3026580810546875
Batch 9/64 loss: 0.3068166971206665
Batch 10/64 loss: 0.30871570110321045
Batch 11/64 loss: 0.30788230895996094
Batch 12/64 loss: 0.3055221438407898
Batch 13/64 loss: 0.2993311285972595
Batch 14/64 loss: 0.3115657567977905
Batch 15/64 loss: 0.3041735887527466
Batch 16/64 loss: 0.30506110191345215
Batch 17/64 loss: 0.3027287721633911
Batch 18/64 loss: 0.30579328536987305
Batch 19/64 loss: 0.30613017082214355
Batch 20/64 loss: 0.30980241298675537
Batch 21/64 loss: 0.30631744861602783
Batch 22/64 loss: 0.3116466999053955
Batch 23/64 loss: 0.30876386165618896
Batch 24/64 loss: 0.3144341707229614
Batch 25/64 loss: 0.3039674758911133
Batch 26/64 loss: 0.304246187210083
Batch 27/64 loss: 0.3028085231781006
Batch 28/64 loss: 0.30105137825012207
Batch 29/64 loss: 0.304599404335022
Batch 30/64 loss: 0.3055696487426758
Batch 31/64 loss: 0.3132527470588684
Batch 32/64 loss: 0.3085530996322632
Batch 33/64 loss: 0.3063788414001465
Batch 34/64 loss: 0.30619382858276367
Batch 35/64 loss: 0.30527234077453613
Batch 36/64 loss: 0.3082784414291382
Batch 37/64 loss: 0.3084002137184143
Batch 38/64 loss: 0.30490201711654663
Batch 39/64 loss: 0.31011998653411865
Batch 40/64 loss: 0.30707454681396484
Batch 41/64 loss: 0.30886244773864746
Batch 42/64 loss: 0.30824053287506104
Batch 43/64 loss: 0.3047020435333252
Batch 44/64 loss: 0.3062751293182373
Batch 45/64 loss: 0.3071487545967102
Batch 46/64 loss: 0.3075631856918335
Batch 47/64 loss: 0.30886733531951904
Batch 48/64 loss: 0.31096136569976807
Batch 49/64 loss: 0.30135130882263184
Batch 50/64 loss: 0.300362229347229
Batch 51/64 loss: 0.30973702669143677
Batch 52/64 loss: 0.30702412128448486
Batch 53/64 loss: 0.30946052074432373
Batch 54/64 loss: 0.315532922744751
Batch 55/64 loss: 0.30868470668792725
Batch 56/64 loss: 0.3090038299560547
Batch 57/64 loss: 0.3047104477882385
Batch 58/64 loss: 0.3051082491874695
Batch 59/64 loss: 0.30870503187179565
Batch 60/64 loss: 0.3066895008087158
Batch 61/64 loss: 0.2992227077484131
Batch 62/64 loss: 0.3080861568450928
Batch 63/64 loss: 0.3035612106323242
Batch 64/64 loss: 0.30933845043182373
Epoch 159  Train loss: 0.30656465034858854  Val loss: 0.32108248713909554
Epoch 160
-------------------------------
Batch 1/64 loss: 0.30135947465896606
Batch 2/64 loss: 0.3040759563446045
Batch 3/64 loss: 0.299884557723999
Batch 4/64 loss: 0.3055295944213867
Batch 5/64 loss: 0.3041226863861084
Batch 6/64 loss: 0.30178701877593994
Batch 7/64 loss: 0.31163787841796875
Batch 8/64 loss: 0.3062394857406616
Batch 9/64 loss: 0.30390381813049316
Batch 10/64 loss: 0.31157416105270386
Batch 11/64 loss: 0.30286580324172974
Batch 12/64 loss: 0.3030954599380493
Batch 13/64 loss: 0.30369794368743896
Batch 14/64 loss: 0.30325865745544434
Batch 15/64 loss: 0.3053489327430725
Batch 16/64 loss: 0.3114999532699585
Batch 17/64 loss: 0.304359495639801
Batch 18/64 loss: 0.30842697620391846
Batch 19/64 loss: 0.3075680732727051
Batch 20/64 loss: 0.3069652318954468
Batch 21/64 loss: 0.3026420474052429
Batch 22/64 loss: 0.30498695373535156
Batch 23/64 loss: 0.30682969093322754
Batch 24/64 loss: 0.30947941541671753
Batch 25/64 loss: 0.30241429805755615
Batch 26/64 loss: 0.3094853162765503
Batch 27/64 loss: 0.3025361895561218
Batch 28/64 loss: 0.30387282371520996
Batch 29/64 loss: 0.3017089366912842
Batch 30/64 loss: 0.2985306978225708
Batch 31/64 loss: 0.3054695129394531
Batch 32/64 loss: 0.30298757553100586
Batch 33/64 loss: 0.3036113381385803
Batch 34/64 loss: 0.3038155436515808
Batch 35/64 loss: 0.3051058053970337
Batch 36/64 loss: 0.3004307746887207
Batch 37/64 loss: 0.3156849145889282
Batch 38/64 loss: 0.30504417419433594
Batch 39/64 loss: 0.3082646131515503
Batch 40/64 loss: 0.3058043122291565
Batch 41/64 loss: 0.30539387464523315
Batch 42/64 loss: 0.3195117712020874
Batch 43/64 loss: 0.30109667778015137
Batch 44/64 loss: 0.30173230171203613
Batch 45/64 loss: 0.30674219131469727
Batch 46/64 loss: 0.31023842096328735
Batch 47/64 loss: 0.30968940258026123
Batch 48/64 loss: 0.30833858251571655
Batch 49/64 loss: 0.31251490116119385
Batch 50/64 loss: 0.30623680353164673
Batch 51/64 loss: 0.30019712448120117
Batch 52/64 loss: 0.3059026002883911
Batch 53/64 loss: 0.3110201954841614
Batch 54/64 loss: 0.31289201974868774
Batch 55/64 loss: 0.31069862842559814
Batch 56/64 loss: 0.3078077435493469
Batch 57/64 loss: 0.30793845653533936
Batch 58/64 loss: 0.30391305685043335
Batch 59/64 loss: 0.3093568682670593
Batch 60/64 loss: 0.304720401763916
Batch 61/64 loss: 0.30640971660614014
Batch 62/64 loss: 0.30242252349853516
Batch 63/64 loss: 0.3056429624557495
Batch 64/64 loss: 0.3088398575782776
Epoch 160  Train loss: 0.30600710920259067  Val loss: 0.3217456185121307
Epoch 161
-------------------------------
Batch 1/64 loss: 0.30902862548828125
Batch 2/64 loss: 0.2991163730621338
Batch 3/64 loss: 0.30499017238616943
Batch 4/64 loss: 0.3127608895301819
Batch 5/64 loss: 0.3008386492729187
Batch 6/64 loss: 0.3127281069755554
Batch 7/64 loss: 0.30430006980895996
Batch 8/64 loss: 0.31174522638320923
Batch 9/64 loss: 0.3022000789642334
Batch 10/64 loss: 0.30091392993927
Batch 11/64 loss: 0.30252277851104736
Batch 12/64 loss: 0.30799639225006104
Batch 13/64 loss: 0.30219483375549316
Batch 14/64 loss: 0.30588382482528687
Batch 15/64 loss: 0.3096134066581726
Batch 16/64 loss: 0.31310272216796875
Batch 17/64 loss: 0.302090585231781
Batch 18/64 loss: 0.3079338073730469
Batch 19/64 loss: 0.29566240310668945
Batch 20/64 loss: 0.3095776438713074
Batch 21/64 loss: 0.3098595142364502
Batch 22/64 loss: 0.3006599545478821
Batch 23/64 loss: 0.30021393299102783
Batch 24/64 loss: 0.3081936836242676
Batch 25/64 loss: 0.3105992078781128
Batch 26/64 loss: 0.3071824908256531
Batch 27/64 loss: 0.30623865127563477
Batch 28/64 loss: 0.3110255002975464
Batch 29/64 loss: 0.3058171272277832
Batch 30/64 loss: 0.30254948139190674
Batch 31/64 loss: 0.3052273988723755
Batch 32/64 loss: 0.31153881549835205
Batch 33/64 loss: 0.30158597230911255
Batch 34/64 loss: 0.30541694164276123
Batch 35/64 loss: 0.3010520935058594
Batch 36/64 loss: 0.3100047707557678
Batch 37/64 loss: 0.3074665069580078
Batch 38/64 loss: 0.308310866355896
Batch 39/64 loss: 0.30463266372680664
Batch 40/64 loss: 0.3053339123725891
Batch 41/64 loss: 0.3042372465133667
Batch 42/64 loss: 0.3093169331550598
Batch 43/64 loss: 0.3057368993759155
Batch 44/64 loss: 0.2983645796775818
Batch 45/64 loss: 0.30874955654144287
Batch 46/64 loss: 0.3081246614456177
Batch 47/64 loss: 0.30652523040771484
Batch 48/64 loss: 0.30494242906570435
Batch 49/64 loss: 0.30057889223098755
Batch 50/64 loss: 0.3057241439819336
Batch 51/64 loss: 0.3094278573989868
Batch 52/64 loss: 0.3094850778579712
Batch 53/64 loss: 0.3051922917366028
Batch 54/64 loss: 0.30260562896728516
Batch 55/64 loss: 0.30500054359436035
Batch 56/64 loss: 0.3011234998703003
Batch 57/64 loss: 0.3070422410964966
Batch 58/64 loss: 0.3019985556602478
Batch 59/64 loss: 0.3033548593521118
Batch 60/64 loss: 0.29785406589508057
Batch 61/64 loss: 0.3061627745628357
Batch 62/64 loss: 0.30222105979919434
Batch 63/64 loss: 0.30518877506256104
Batch 64/64 loss: 0.31130510568618774
Epoch 161  Train loss: 0.3055772021705029  Val loss: 0.32053863879331607
Saving best model, epoch: 161
Epoch 162
-------------------------------
Batch 1/64 loss: 0.3046152591705322
Batch 2/64 loss: 0.3095903992652893
Batch 3/64 loss: 0.3022308349609375
Batch 4/64 loss: 0.3012118339538574
Batch 5/64 loss: 0.3080682158470154
Batch 6/64 loss: 0.30318498611450195
Batch 7/64 loss: 0.30454856157302856
Batch 8/64 loss: 0.30845797061920166
Batch 9/64 loss: 0.3050041198730469
Batch 10/64 loss: 0.3017556071281433
Batch 11/64 loss: 0.31004488468170166
Batch 12/64 loss: 0.3030552864074707
Batch 13/64 loss: 0.30544614791870117
Batch 14/64 loss: 0.3039710521697998
Batch 15/64 loss: 0.3123123049736023
Batch 16/64 loss: 0.3012617826461792
Batch 17/64 loss: 0.30856984853744507
Batch 18/64 loss: 0.3067197799682617
Batch 19/64 loss: 0.30203449726104736
Batch 20/64 loss: 0.3026087284088135
Batch 21/64 loss: 0.3032236695289612
Batch 22/64 loss: 0.3063439130783081
Batch 23/64 loss: 0.30202722549438477
Batch 24/64 loss: 0.31000077724456787
Batch 25/64 loss: 0.30926430225372314
Batch 26/64 loss: 0.29988521337509155
Batch 27/64 loss: 0.3069738745689392
Batch 28/64 loss: 0.3077828884124756
Batch 29/64 loss: 0.310123085975647
Batch 30/64 loss: 0.30558645725250244
Batch 31/64 loss: 0.3113621473312378
Batch 32/64 loss: 0.3032180070877075
Batch 33/64 loss: 0.3060133457183838
Batch 34/64 loss: 0.3006628751754761
Batch 35/64 loss: 0.3050675392150879
Batch 36/64 loss: 0.3067195415496826
Batch 37/64 loss: 0.3064655065536499
Batch 38/64 loss: 0.3024277687072754
Batch 39/64 loss: 0.306634783744812
Batch 40/64 loss: 0.30174779891967773
Batch 41/64 loss: 0.3040584325790405
Batch 42/64 loss: 0.30757856369018555
Batch 43/64 loss: 0.30600690841674805
Batch 44/64 loss: 0.3099619150161743
Batch 45/64 loss: 0.30158305168151855
Batch 46/64 loss: 0.3093754053115845
Batch 47/64 loss: 0.30431902408599854
Batch 48/64 loss: 0.29720616340637207
Batch 49/64 loss: 0.3096911311149597
Batch 50/64 loss: 0.3006272315979004
Batch 51/64 loss: 0.3085829019546509
Batch 52/64 loss: 0.2984345555305481
Batch 53/64 loss: 0.30918073654174805
Batch 54/64 loss: 0.30464160442352295
Batch 55/64 loss: 0.3002185821533203
Batch 56/64 loss: 0.3072291612625122
Batch 57/64 loss: 0.29901212453842163
Batch 58/64 loss: 0.3012126684188843
Batch 59/64 loss: 0.30355560779571533
Batch 60/64 loss: 0.3064548373222351
Batch 61/64 loss: 0.3061015009880066
Batch 62/64 loss: 0.3012964725494385
Batch 63/64 loss: 0.3070552945137024
Batch 64/64 loss: 0.3031429052352905
Epoch 162  Train loss: 0.30505041374879727  Val loss: 0.3198890556994173
Saving best model, epoch: 162
Epoch 163
-------------------------------
Batch 1/64 loss: 0.3034716844558716
Batch 2/64 loss: 0.30493271350860596
Batch 3/64 loss: 0.3082919716835022
Batch 4/64 loss: 0.3032459020614624
Batch 5/64 loss: 0.311983585357666
Batch 6/64 loss: 0.3000841736793518
Batch 7/64 loss: 0.3070206642150879
Batch 8/64 loss: 0.29515278339385986
Batch 9/64 loss: 0.3067054748535156
Batch 10/64 loss: 0.3131970763206482
Batch 11/64 loss: 0.3024243116378784
Batch 12/64 loss: 0.3062920570373535
Batch 13/64 loss: 0.3028426170349121
Batch 14/64 loss: 0.3106081485748291
Batch 15/64 loss: 0.30700790882110596
Batch 16/64 loss: 0.3041011095046997
Batch 17/64 loss: 0.2989823818206787
Batch 18/64 loss: 0.30561840534210205
Batch 19/64 loss: 0.30289226770401
Batch 20/64 loss: 0.30949556827545166
Batch 21/64 loss: 0.3036001920700073
Batch 22/64 loss: 0.30621862411499023
Batch 23/64 loss: 0.30910617113113403
Batch 24/64 loss: 0.3085775375366211
Batch 25/64 loss: 0.300897479057312
Batch 26/64 loss: 0.3071790933609009
Batch 27/64 loss: 0.3054155111312866
Batch 28/64 loss: 0.30671942234039307
Batch 29/64 loss: 0.30503714084625244
Batch 30/64 loss: 0.30522245168685913
Batch 31/64 loss: 0.30668365955352783
Batch 32/64 loss: 0.2998506426811218
Batch 33/64 loss: 0.3046818971633911
Batch 34/64 loss: 0.3042299151420593
Batch 35/64 loss: 0.3047102689743042
Batch 36/64 loss: 0.3002760410308838
Batch 37/64 loss: 0.3075573444366455
Batch 38/64 loss: 0.3063015937805176
Batch 39/64 loss: 0.3078550100326538
Batch 40/64 loss: 0.3054453134536743
Batch 41/64 loss: 0.30718469619750977
Batch 42/64 loss: 0.3065178394317627
Batch 43/64 loss: 0.302650511264801
Batch 44/64 loss: 0.30889713764190674
Batch 45/64 loss: 0.30710554122924805
Batch 46/64 loss: 0.30810225009918213
Batch 47/64 loss: 0.30498749017715454
Batch 48/64 loss: 0.2975906729698181
Batch 49/64 loss: 0.30378782749176025
Batch 50/64 loss: 0.29934918880462646
Batch 51/64 loss: 0.3066254258155823
Batch 52/64 loss: 0.30210500955581665
Batch 53/64 loss: 0.3112967610359192
Batch 54/64 loss: 0.3042728900909424
Batch 55/64 loss: 0.3057692050933838
Batch 56/64 loss: 0.30532050132751465
Batch 57/64 loss: 0.30192285776138306
Batch 58/64 loss: 0.30596303939819336
Batch 59/64 loss: 0.29891788959503174
Batch 60/64 loss: 0.3037259578704834
Batch 61/64 loss: 0.3007546067237854
Batch 62/64 loss: 0.30715298652648926
Batch 63/64 loss: 0.3091428875923157
Batch 64/64 loss: 0.3055659532546997
Epoch 163  Train loss: 0.30507033338733747  Val loss: 0.3194261264964887
Saving best model, epoch: 163
Epoch 164
-------------------------------
Batch 1/64 loss: 0.30577385425567627
Batch 2/64 loss: 0.30696725845336914
Batch 3/64 loss: 0.30338019132614136
Batch 4/64 loss: 0.3082054853439331
Batch 5/64 loss: 0.3101705312728882
Batch 6/64 loss: 0.3045320510864258
Batch 7/64 loss: 0.30141276121139526
Batch 8/64 loss: 0.3020053505897522
Batch 9/64 loss: 0.3036191463470459
Batch 10/64 loss: 0.302931010723114
Batch 11/64 loss: 0.3001335859298706
Batch 12/64 loss: 0.3007161617279053
Batch 13/64 loss: 0.3092421889305115
Batch 14/64 loss: 0.31019604206085205
Batch 15/64 loss: 0.30295515060424805
Batch 16/64 loss: 0.3019218444824219
Batch 17/64 loss: 0.3067730665206909
Batch 18/64 loss: 0.3037976026535034
Batch 19/64 loss: 0.3023529648780823
Batch 20/64 loss: 0.3010444641113281
Batch 21/64 loss: 0.30287253856658936
Batch 22/64 loss: 0.2971869707107544
Batch 23/64 loss: 0.30358535051345825
Batch 24/64 loss: 0.3087632656097412
Batch 25/64 loss: 0.31270653009414673
Batch 26/64 loss: 0.30220508575439453
Batch 27/64 loss: 0.3094996213912964
Batch 28/64 loss: 0.30383384227752686
Batch 29/64 loss: 0.30349278450012207
Batch 30/64 loss: 0.30723899602890015
Batch 31/64 loss: 0.3152235746383667
Batch 32/64 loss: 0.3027181625366211
Batch 33/64 loss: 0.3034689426422119
Batch 34/64 loss: 0.302818238735199
Batch 35/64 loss: 0.30670422315597534
Batch 36/64 loss: 0.3048309087753296
Batch 37/64 loss: 0.304842472076416
Batch 38/64 loss: 0.32111990451812744
Batch 39/64 loss: 0.305378794670105
Batch 40/64 loss: 0.3138599395751953
Batch 41/64 loss: 0.30227017402648926
Batch 42/64 loss: 0.302243709564209
Batch 43/64 loss: 0.30573105812072754
Batch 44/64 loss: 0.30625665187835693
Batch 45/64 loss: 0.30266284942626953
Batch 46/64 loss: 0.3077760338783264
Batch 47/64 loss: 0.30257678031921387
Batch 48/64 loss: 0.30017638206481934
Batch 49/64 loss: 0.3043110966682434
Batch 50/64 loss: 0.299324631690979
Batch 51/64 loss: 0.3057052493095398
Batch 52/64 loss: 0.30050522089004517
Batch 53/64 loss: 0.30092477798461914
Batch 54/64 loss: 0.3063904047012329
Batch 55/64 loss: 0.30343353748321533
Batch 56/64 loss: 0.3153313398361206
Batch 57/64 loss: 0.30807197093963623
Batch 58/64 loss: 0.30871009826660156
Batch 59/64 loss: 0.30404698848724365
Batch 60/64 loss: 0.30680596828460693
Batch 61/64 loss: 0.2990686893463135
Batch 62/64 loss: 0.30323976278305054
Batch 63/64 loss: 0.3029513359069824
Batch 64/64 loss: 0.2976961135864258
Epoch 164  Train loss: 0.30497674755021636  Val loss: 0.32063081092441204
Epoch 165
-------------------------------
Batch 1/64 loss: 0.30336159467697144
Batch 2/64 loss: 0.3130645155906677
Batch 3/64 loss: 0.3083599805831909
Batch 4/64 loss: 0.30389928817749023
Batch 5/64 loss: 0.3037024736404419
Batch 6/64 loss: 0.30766916275024414
Batch 7/64 loss: 0.30487096309661865
Batch 8/64 loss: 0.3078805208206177
Batch 9/64 loss: 0.3092966079711914
Batch 10/64 loss: 0.3043612837791443
Batch 11/64 loss: 0.3039267063140869
Batch 12/64 loss: 0.30684876441955566
Batch 13/64 loss: 0.3056938648223877
Batch 14/64 loss: 0.30442893505096436
Batch 15/64 loss: 0.3042982816696167
Batch 16/64 loss: 0.30796051025390625
Batch 17/64 loss: 0.3038424253463745
Batch 18/64 loss: 0.3007354736328125
Batch 19/64 loss: 0.3033592104911804
Batch 20/64 loss: 0.3068550229072571
Batch 21/64 loss: 0.2970779538154602
Batch 22/64 loss: 0.29952532052993774
Batch 23/64 loss: 0.3024539351463318
Batch 24/64 loss: 0.3008812665939331
Batch 25/64 loss: 0.3017229437828064
Batch 26/64 loss: 0.30476081371307373
Batch 27/64 loss: 0.3056529760360718
Batch 28/64 loss: 0.30807411670684814
Batch 29/64 loss: 0.309171199798584
Batch 30/64 loss: 0.3070732355117798
Batch 31/64 loss: 0.3021286725997925
Batch 32/64 loss: 0.30695927143096924
Batch 33/64 loss: 0.31248778104782104
Batch 34/64 loss: 0.31344401836395264
Batch 35/64 loss: 0.307325541973114
Batch 36/64 loss: 0.3015674352645874
Batch 37/64 loss: 0.30104923248291016
Batch 38/64 loss: 0.3046935796737671
Batch 39/64 loss: 0.304679274559021
Batch 40/64 loss: 0.3063972592353821
Batch 41/64 loss: 0.3065913915634155
Batch 42/64 loss: 0.30316078662872314
Batch 43/64 loss: 0.2989029288291931
Batch 44/64 loss: 0.30753225088119507
Batch 45/64 loss: 0.3059045672416687
Batch 46/64 loss: 0.30606937408447266
Batch 47/64 loss: 0.30693161487579346
Batch 48/64 loss: 0.29992473125457764
Batch 49/64 loss: 0.30432605743408203
Batch 50/64 loss: 0.30581849813461304
Batch 51/64 loss: 0.3003346920013428
Batch 52/64 loss: 0.3060781955718994
Batch 53/64 loss: 0.30272501707077026
Batch 54/64 loss: 0.3051021695137024
Batch 55/64 loss: 0.3024439215660095
Batch 56/64 loss: 0.3084123134613037
Batch 57/64 loss: 0.3018101453781128
Batch 58/64 loss: 0.30740785598754883
Batch 59/64 loss: 0.3082208037376404
Batch 60/64 loss: 0.30552858114242554
Batch 61/64 loss: 0.30077528953552246
Batch 62/64 loss: 0.3059074282646179
Batch 63/64 loss: 0.2980010509490967
Batch 64/64 loss: 0.31076014041900635
Epoch 165  Train loss: 0.30498072446561325  Val loss: 0.32102465588612245
Epoch 166
-------------------------------
Batch 1/64 loss: 0.3055771589279175
Batch 2/64 loss: 0.29709887504577637
Batch 3/64 loss: 0.3056207299232483
Batch 4/64 loss: 0.3035249710083008
Batch 5/64 loss: 0.30876171588897705
Batch 6/64 loss: 0.30146539211273193
Batch 7/64 loss: 0.3048010468482971
Batch 8/64 loss: 0.304057240486145
Batch 9/64 loss: 0.299564003944397
Batch 10/64 loss: 0.30494987964630127
Batch 11/64 loss: 0.304195761680603
Batch 12/64 loss: 0.3083893060684204
Batch 13/64 loss: 0.30753910541534424
Batch 14/64 loss: 0.31545090675354004
Batch 15/64 loss: 0.30663561820983887
Batch 16/64 loss: 0.30481576919555664
Batch 17/64 loss: 0.3132340908050537
Batch 18/64 loss: 0.3045414090156555
Batch 19/64 loss: 0.3047468662261963
Batch 20/64 loss: 0.302890419960022
Batch 21/64 loss: 0.30797016620635986
Batch 22/64 loss: 0.30782651901245117
Batch 23/64 loss: 0.3018772006034851
Batch 24/64 loss: 0.3154968023300171
Batch 25/64 loss: 0.3019217252731323
Batch 26/64 loss: 0.30451464653015137
Batch 27/64 loss: 0.3029056787490845
Batch 28/64 loss: 0.30420899391174316
Batch 29/64 loss: 0.3022193908691406
Batch 30/64 loss: 0.30118227005004883
Batch 31/64 loss: 0.2999457120895386
Batch 32/64 loss: 0.3036472201347351
Batch 33/64 loss: 0.3035292625427246
Batch 34/64 loss: 0.306543231010437
Batch 35/64 loss: 0.3083251118659973
Batch 36/64 loss: 0.29798591136932373
Batch 37/64 loss: 0.30961740016937256
Batch 38/64 loss: 0.30015891790390015
Batch 39/64 loss: 0.29887908697128296
Batch 40/64 loss: 0.3046973943710327
Batch 41/64 loss: 0.30991417169570923
Batch 42/64 loss: 0.30341655015945435
Batch 43/64 loss: 0.3007587194442749
Batch 44/64 loss: 0.3023679256439209
Batch 45/64 loss: 0.3072410821914673
Batch 46/64 loss: 0.3070189356803894
Batch 47/64 loss: 0.30907273292541504
Batch 48/64 loss: 0.3102074861526489
Batch 49/64 loss: 0.30687785148620605
Batch 50/64 loss: 0.3074275255203247
Batch 51/64 loss: 0.3101133704185486
Batch 52/64 loss: 0.30411601066589355
Batch 53/64 loss: 0.30803394317626953
Batch 54/64 loss: 0.3081429600715637
Batch 55/64 loss: 0.3085640072822571
Batch 56/64 loss: 0.30328989028930664
Batch 57/64 loss: 0.300412654876709
Batch 58/64 loss: 0.29666125774383545
Batch 59/64 loss: 0.30443263053894043
Batch 60/64 loss: 0.3099926710128784
Batch 61/64 loss: 0.3016934394836426
Batch 62/64 loss: 0.3101102113723755
Batch 63/64 loss: 0.3008870482444763
Batch 64/64 loss: 0.30492228269577026
Epoch 166  Train loss: 0.30510992466234693  Val loss: 0.31964767184044485
Epoch 167
-------------------------------
Batch 1/64 loss: 0.3015413284301758
Batch 2/64 loss: 0.30757641792297363
Batch 3/64 loss: 0.2996253967285156
Batch 4/64 loss: 0.303436279296875
Batch 5/64 loss: 0.30278652906417847
Batch 6/64 loss: 0.30707335472106934
Batch 7/64 loss: 0.30205368995666504
Batch 8/64 loss: 0.3041679859161377
Batch 9/64 loss: 0.30004191398620605
Batch 10/64 loss: 0.3097631335258484
Batch 11/64 loss: 0.3005119562149048
Batch 12/64 loss: 0.3117075562477112
Batch 13/64 loss: 0.30883049964904785
Batch 14/64 loss: 0.29764360189437866
Batch 15/64 loss: 0.30685943365097046
Batch 16/64 loss: 0.29720765352249146
Batch 17/64 loss: 0.30506670475006104
Batch 18/64 loss: 0.30152302980422974
Batch 19/64 loss: 0.30215489864349365
Batch 20/64 loss: 0.3003120422363281
Batch 21/64 loss: 0.3057723045349121
Batch 22/64 loss: 0.30162227153778076
Batch 23/64 loss: 0.3147953152656555
Batch 24/64 loss: 0.31111907958984375
Batch 25/64 loss: 0.3076554536819458
Batch 26/64 loss: 0.3045724630355835
Batch 27/64 loss: 0.30193763971328735
Batch 28/64 loss: 0.3013228178024292
Batch 29/64 loss: 0.3084268569946289
Batch 30/64 loss: 0.30809950828552246
Batch 31/64 loss: 0.3123841881752014
Batch 32/64 loss: 0.3094334006309509
Batch 33/64 loss: 0.30057692527770996
Batch 34/64 loss: 0.3073670268058777
Batch 35/64 loss: 0.303688645362854
Batch 36/64 loss: 0.3054428696632385
Batch 37/64 loss: 0.29715073108673096
Batch 38/64 loss: 0.30137908458709717
Batch 39/64 loss: 0.3049197196960449
Batch 40/64 loss: 0.3052893280982971
Batch 41/64 loss: 0.30031394958496094
Batch 42/64 loss: 0.3053675889968872
Batch 43/64 loss: 0.30797505378723145
Batch 44/64 loss: 0.30556535720825195
Batch 45/64 loss: 0.29631584882736206
Batch 46/64 loss: 0.3047332167625427
Batch 47/64 loss: 0.3130762577056885
Batch 48/64 loss: 0.31031304597854614
Batch 49/64 loss: 0.3027435541152954
Batch 50/64 loss: 0.30953097343444824
Batch 51/64 loss: 0.30473923683166504
Batch 52/64 loss: 0.2982015013694763
Batch 53/64 loss: 0.30901360511779785
Batch 54/64 loss: 0.301932692527771
Batch 55/64 loss: 0.309444785118103
Batch 56/64 loss: 0.3021801710128784
Batch 57/64 loss: 0.2991889715194702
Batch 58/64 loss: 0.30563199520111084
Batch 59/64 loss: 0.307547390460968
Batch 60/64 loss: 0.3039160966873169
Batch 61/64 loss: 0.31294238567352295
Batch 62/64 loss: 0.3014857769012451
Batch 63/64 loss: 0.3044843077659607
Batch 64/64 loss: 0.30406826734542847
Epoch 167  Train loss: 0.30474563135820276  Val loss: 0.3191680660362506
Saving best model, epoch: 167
Epoch 168
-------------------------------
Batch 1/64 loss: 0.29776591062545776
Batch 2/64 loss: 0.3110736608505249
Batch 3/64 loss: 0.3032677173614502
Batch 4/64 loss: 0.30601006746292114
Batch 5/64 loss: 0.30640339851379395
Batch 6/64 loss: 0.3002118468284607
Batch 7/64 loss: 0.3049352169036865
Batch 8/64 loss: 0.29636573791503906
Batch 9/64 loss: 0.3016703724861145
Batch 10/64 loss: 0.3060271739959717
Batch 11/64 loss: 0.30370140075683594
Batch 12/64 loss: 0.2988775968551636
Batch 13/64 loss: 0.30237436294555664
Batch 14/64 loss: 0.2977832555770874
Batch 15/64 loss: 0.29817187786102295
Batch 16/64 loss: 0.30344951152801514
Batch 17/64 loss: 0.31031084060668945
Batch 18/64 loss: 0.3055304288864136
Batch 19/64 loss: 0.3060959577560425
Batch 20/64 loss: 0.31245100498199463
Batch 21/64 loss: 0.30110764503479004
Batch 22/64 loss: 0.3064808249473572
Batch 23/64 loss: 0.3043050765991211
Batch 24/64 loss: 0.31519943475723267
Batch 25/64 loss: 0.31116342544555664
Batch 26/64 loss: 0.3039919137954712
Batch 27/64 loss: 0.30153578519821167
Batch 28/64 loss: 0.3027609586715698
Batch 29/64 loss: 0.2997133731842041
Batch 30/64 loss: 0.2952883839607239
Batch 31/64 loss: 0.30049771070480347
Batch 32/64 loss: 0.2990823984146118
Batch 33/64 loss: 0.3026062250137329
Batch 34/64 loss: 0.30722367763519287
Batch 35/64 loss: 0.29946035146713257
Batch 36/64 loss: 0.31237661838531494
Batch 37/64 loss: 0.30452263355255127
Batch 38/64 loss: 0.30302417278289795
Batch 39/64 loss: 0.29973912239074707
Batch 40/64 loss: 0.2984468340873718
Batch 41/64 loss: 0.30378568172454834
Batch 42/64 loss: 0.3022059202194214
Batch 43/64 loss: 0.29861652851104736
Batch 44/64 loss: 0.31204473972320557
Batch 45/64 loss: 0.3085305094718933
Batch 46/64 loss: 0.31072235107421875
Batch 47/64 loss: 0.3010413646697998
Batch 48/64 loss: 0.30031365156173706
Batch 49/64 loss: 0.3019583821296692
Batch 50/64 loss: 0.30566054582595825
Batch 51/64 loss: 0.30182379484176636
Batch 52/64 loss: 0.3061823844909668
Batch 53/64 loss: 0.30658096075057983
Batch 54/64 loss: 0.3067433834075928
Batch 55/64 loss: 0.31185996532440186
Batch 56/64 loss: 0.3149460554122925
Batch 57/64 loss: 0.30602312088012695
Batch 58/64 loss: 0.30312448740005493
Batch 59/64 loss: 0.3060495853424072
Batch 60/64 loss: 0.2988761067390442
Batch 61/64 loss: 0.3075717091560364
Batch 62/64 loss: 0.2996608018875122
Batch 63/64 loss: 0.30576908588409424
Batch 64/64 loss: 0.2998563051223755
Epoch 168  Train loss: 0.30409391767838423  Val loss: 0.3196025812339127
Epoch 169
-------------------------------
Batch 1/64 loss: 0.30244743824005127
Batch 2/64 loss: 0.305905818939209
Batch 3/64 loss: 0.3046543002128601
Batch 4/64 loss: 0.30309444665908813
Batch 5/64 loss: 0.3056226968765259
Batch 6/64 loss: 0.3048347234725952
Batch 7/64 loss: 0.30027252435684204
Batch 8/64 loss: 0.3086940050125122
Batch 9/64 loss: 0.30419254302978516
Batch 10/64 loss: 0.3050609827041626
Batch 11/64 loss: 0.30526888370513916
Batch 12/64 loss: 0.30349087715148926
Batch 13/64 loss: 0.30073094367980957
Batch 14/64 loss: 0.3049715757369995
Batch 15/64 loss: 0.3022443652153015
Batch 16/64 loss: 0.30231696367263794
Batch 17/64 loss: 0.3078174591064453
Batch 18/64 loss: 0.298828125
Batch 19/64 loss: 0.31193017959594727
Batch 20/64 loss: 0.30340027809143066
Batch 21/64 loss: 0.3025967478752136
Batch 22/64 loss: 0.3039664030075073
Batch 23/64 loss: 0.30818331241607666
Batch 24/64 loss: 0.29828208684921265
Batch 25/64 loss: 0.29887068271636963
Batch 26/64 loss: 0.31182533502578735
Batch 27/64 loss: 0.2993088960647583
Batch 28/64 loss: 0.3032330870628357
Batch 29/64 loss: 0.30942678451538086
Batch 30/64 loss: 0.31141841411590576
Batch 31/64 loss: 0.3042721748352051
Batch 32/64 loss: 0.3035569190979004
Batch 33/64 loss: 0.3055633306503296
Batch 34/64 loss: 0.3089680075645447
Batch 35/64 loss: 0.29438310861587524
Batch 36/64 loss: 0.30062973499298096
Batch 37/64 loss: 0.3049314022064209
Batch 38/64 loss: 0.3067117929458618
Batch 39/64 loss: 0.30414891242980957
Batch 40/64 loss: 0.3017504811286926
Batch 41/64 loss: 0.30896151065826416
Batch 42/64 loss: 0.30098849534988403
Batch 43/64 loss: 0.302165687084198
Batch 44/64 loss: 0.3006291389465332
Batch 45/64 loss: 0.31287550926208496
Batch 46/64 loss: 0.298983633518219
Batch 47/64 loss: 0.3022688627243042
Batch 48/64 loss: 0.2990126609802246
Batch 49/64 loss: 0.2967907190322876
Batch 50/64 loss: 0.3031046390533447
Batch 51/64 loss: 0.30408746004104614
Batch 52/64 loss: 0.3002890944480896
Batch 53/64 loss: 0.30481934547424316
Batch 54/64 loss: 0.30084025859832764
Batch 55/64 loss: 0.3070499897003174
Batch 56/64 loss: 0.30185389518737793
Batch 57/64 loss: 0.3087714910507202
Batch 58/64 loss: 0.3020644783973694
Batch 59/64 loss: 0.3056197166442871
Batch 60/64 loss: 0.30813586711883545
Batch 61/64 loss: 0.30965912342071533
Batch 62/64 loss: 0.30920445919036865
Batch 63/64 loss: 0.30484235286712646
Batch 64/64 loss: 0.3079798221588135
Epoch 169  Train loss: 0.3041852549010632  Val loss: 0.3191041088186179
Saving best model, epoch: 169
Epoch 170
-------------------------------
Batch 1/64 loss: 0.3006168603897095
Batch 2/64 loss: 0.30258822441101074
Batch 3/64 loss: 0.30526578426361084
Batch 4/64 loss: 0.2976980209350586
Batch 5/64 loss: 0.2985454797744751
Batch 6/64 loss: 0.30794960260391235
Batch 7/64 loss: 0.3033512830734253
Batch 8/64 loss: 0.300542950630188
Batch 9/64 loss: 0.3023456931114197
Batch 10/64 loss: 0.29911792278289795
Batch 11/64 loss: 0.3033597469329834
Batch 12/64 loss: 0.302742600440979
Batch 13/64 loss: 0.30044710636138916
Batch 14/64 loss: 0.30032259225845337
Batch 15/64 loss: 0.29830724000930786
Batch 16/64 loss: 0.30451536178588867
Batch 17/64 loss: 0.30759525299072266
Batch 18/64 loss: 0.3014260530471802
Batch 19/64 loss: 0.31110918521881104
Batch 20/64 loss: 0.30085480213165283
Batch 21/64 loss: 0.2977944612503052
Batch 22/64 loss: 0.2971065044403076
Batch 23/64 loss: 0.3081529140472412
Batch 24/64 loss: 0.3056163787841797
Batch 25/64 loss: 0.3028308153152466
Batch 26/64 loss: 0.30222612619400024
Batch 27/64 loss: 0.3004223108291626
Batch 28/64 loss: 0.303791880607605
Batch 29/64 loss: 0.3081575632095337
Batch 30/64 loss: 0.30141717195510864
Batch 31/64 loss: 0.3025740385055542
Batch 32/64 loss: 0.3000922203063965
Batch 33/64 loss: 0.2992507219314575
Batch 34/64 loss: 0.30851221084594727
Batch 35/64 loss: 0.2993839979171753
Batch 36/64 loss: 0.304158091545105
Batch 37/64 loss: 0.31220710277557373
Batch 38/64 loss: 0.30789411067962646
Batch 39/64 loss: 0.3052859902381897
Batch 40/64 loss: 0.2946596145629883
Batch 41/64 loss: 0.3047608733177185
Batch 42/64 loss: 0.30124741792678833
Batch 43/64 loss: 0.30438709259033203
Batch 44/64 loss: 0.30590689182281494
Batch 45/64 loss: 0.2971106171607971
Batch 46/64 loss: 0.3125261068344116
Batch 47/64 loss: 0.3001859784126282
Batch 48/64 loss: 0.3040893077850342
Batch 49/64 loss: 0.3054025173187256
Batch 50/64 loss: 0.3009093403816223
Batch 51/64 loss: 0.3053405284881592
Batch 52/64 loss: 0.3104424476623535
Batch 53/64 loss: 0.3032320737838745
Batch 54/64 loss: 0.30299925804138184
Batch 55/64 loss: 0.30179500579833984
Batch 56/64 loss: 0.3020012378692627
Batch 57/64 loss: 0.3064711093902588
Batch 58/64 loss: 0.30071544647216797
Batch 59/64 loss: 0.3127748370170593
Batch 60/64 loss: 0.3018200993537903
Batch 61/64 loss: 0.30962520837783813
Batch 62/64 loss: 0.29844844341278076
Batch 63/64 loss: 0.3007485866546631
Batch 64/64 loss: 0.30273252725601196
Epoch 170  Train loss: 0.30321922839856613  Val loss: 0.31999897014644135
Epoch 171
-------------------------------
Batch 1/64 loss: 0.3005256652832031
Batch 2/64 loss: 0.3011319637298584
Batch 3/64 loss: 0.3003326654434204
Batch 4/64 loss: 0.3125010132789612
Batch 5/64 loss: 0.301072895526886
Batch 6/64 loss: 0.29878926277160645
Batch 7/64 loss: 0.3032954931259155
Batch 8/64 loss: 0.3085627555847168
Batch 9/64 loss: 0.29987412691116333
Batch 10/64 loss: 0.3029528856277466
Batch 11/64 loss: 0.30125582218170166
Batch 12/64 loss: 0.3030633330345154
Batch 13/64 loss: 0.30095934867858887
Batch 14/64 loss: 0.3080587387084961
Batch 15/64 loss: 0.29899829626083374
Batch 16/64 loss: 0.3010992407798767
Batch 17/64 loss: 0.2972813844680786
Batch 18/64 loss: 0.2952849864959717
Batch 19/64 loss: 0.30088549852371216
Batch 20/64 loss: 0.3035010099411011
Batch 21/64 loss: 0.3103938102722168
Batch 22/64 loss: 0.30309897661209106
Batch 23/64 loss: 0.3048335909843445
Batch 24/64 loss: 0.3031320571899414
Batch 25/64 loss: 0.2970597743988037
Batch 26/64 loss: 0.2993737459182739
Batch 27/64 loss: 0.30182647705078125
Batch 28/64 loss: 0.29613178968429565
Batch 29/64 loss: 0.30395305156707764
Batch 30/64 loss: 0.2980515956878662
Batch 31/64 loss: 0.3052821755409241
Batch 32/64 loss: 0.30518490076065063
Batch 33/64 loss: 0.2991914749145508
Batch 34/64 loss: 0.3023759126663208
Batch 35/64 loss: 0.30534952878952026
Batch 36/64 loss: 0.30720555782318115
Batch 37/64 loss: 0.30200159549713135
Batch 38/64 loss: 0.3036697506904602
Batch 39/64 loss: 0.302359402179718
Batch 40/64 loss: 0.311093807220459
Batch 41/64 loss: 0.30495017766952515
Batch 42/64 loss: 0.30338186025619507
Batch 43/64 loss: 0.30248767137527466
Batch 44/64 loss: 0.2990400791168213
Batch 45/64 loss: 0.3094550371170044
Batch 46/64 loss: 0.3023023009300232
Batch 47/64 loss: 0.3021090030670166
Batch 48/64 loss: 0.30404603481292725
Batch 49/64 loss: 0.3023533821105957
Batch 50/64 loss: 0.3043491840362549
Batch 51/64 loss: 0.307098388671875
Batch 52/64 loss: 0.30838215351104736
Batch 53/64 loss: 0.30183565616607666
Batch 54/64 loss: 0.3002629280090332
Batch 55/64 loss: 0.306640088558197
Batch 56/64 loss: 0.3112354278564453
Batch 57/64 loss: 0.30716776847839355
Batch 58/64 loss: 0.2998756170272827
Batch 59/64 loss: 0.3031306266784668
Batch 60/64 loss: 0.30695122480392456
Batch 61/64 loss: 0.30064040422439575
Batch 62/64 loss: 0.3036201000213623
Batch 63/64 loss: 0.2986411452293396
Batch 64/64 loss: 0.3048534393310547
Epoch 171  Train loss: 0.30305241883969775  Val loss: 0.3181717137700504
Saving best model, epoch: 171
Epoch 172
-------------------------------
Batch 1/64 loss: 0.30553579330444336
Batch 2/64 loss: 0.2982281446456909
Batch 3/64 loss: 0.3044576048851013
Batch 4/64 loss: 0.3071209192276001
Batch 5/64 loss: 0.29838770627975464
Batch 6/64 loss: 0.3050616383552551
Batch 7/64 loss: 0.30660194158554077
Batch 8/64 loss: 0.30275964736938477
Batch 9/64 loss: 0.29774290323257446
Batch 10/64 loss: 0.29852670431137085
Batch 11/64 loss: 0.3033895492553711
Batch 12/64 loss: 0.3007622957229614
Batch 13/64 loss: 0.3034592866897583
Batch 14/64 loss: 0.30192697048187256
Batch 15/64 loss: 0.30599117279052734
Batch 16/64 loss: 0.3012944459915161
Batch 17/64 loss: 0.2999413013458252
Batch 18/64 loss: 0.30665868520736694
Batch 19/64 loss: 0.29908329248428345
Batch 20/64 loss: 0.30498600006103516
Batch 21/64 loss: 0.3026666045188904
Batch 22/64 loss: 0.2952062487602234
Batch 23/64 loss: 0.29635751247406006
Batch 24/64 loss: 0.3045709729194641
Batch 25/64 loss: 0.29486215114593506
Batch 26/64 loss: 0.29945963621139526
Batch 27/64 loss: 0.30174171924591064
Batch 28/64 loss: 0.3012084364891052
Batch 29/64 loss: 0.3035343885421753
Batch 30/64 loss: 0.2963334321975708
Batch 31/64 loss: 0.3000229597091675
Batch 32/64 loss: 0.30044567584991455
Batch 33/64 loss: 0.30698782205581665
Batch 34/64 loss: 0.3130228519439697
Batch 35/64 loss: 0.30139946937561035
Batch 36/64 loss: 0.29715418815612793
Batch 37/64 loss: 0.3073842525482178
Batch 38/64 loss: 0.3006402254104614
Batch 39/64 loss: 0.3063199520111084
Batch 40/64 loss: 0.30387628078460693
Batch 41/64 loss: 0.30074095726013184
Batch 42/64 loss: 0.30163270235061646
Batch 43/64 loss: 0.3050897717475891
Batch 44/64 loss: 0.304479718208313
Batch 45/64 loss: 0.31067949533462524
Batch 46/64 loss: 0.30180859565734863
Batch 47/64 loss: 0.3023468255996704
Batch 48/64 loss: 0.30439066886901855
Batch 49/64 loss: 0.30895179510116577
Batch 50/64 loss: 0.3044590353965759
Batch 51/64 loss: 0.3034791946411133
Batch 52/64 loss: 0.3047053813934326
Batch 53/64 loss: 0.3072925806045532
Batch 54/64 loss: 0.3015810251235962
Batch 55/64 loss: 0.30349159240722656
Batch 56/64 loss: 0.30556511878967285
Batch 57/64 loss: 0.29694056510925293
Batch 58/64 loss: 0.3003571033477783
Batch 59/64 loss: 0.30334174633026123
Batch 60/64 loss: 0.30931806564331055
Batch 61/64 loss: 0.30564284324645996
Batch 62/64 loss: 0.306943416595459
Batch 63/64 loss: 0.29630064964294434
Batch 64/64 loss: 0.3022598624229431
Epoch 172  Train loss: 0.30276618868696925  Val loss: 0.3183616881108366
Epoch 173
-------------------------------
Batch 1/64 loss: 0.29682493209838867
Batch 2/64 loss: 0.304023802280426
Batch 3/64 loss: 0.30352139472961426
Batch 4/64 loss: 0.2988625764846802
Batch 5/64 loss: 0.29581117630004883
Batch 6/64 loss: 0.2983420491218567
Batch 7/64 loss: 0.2950744032859802
Batch 8/64 loss: 0.3016268014907837
Batch 9/64 loss: 0.30167919397354126
Batch 10/64 loss: 0.30040955543518066
Batch 11/64 loss: 0.3017873764038086
Batch 12/64 loss: 0.3000755310058594
Batch 13/64 loss: 0.3006989359855652
Batch 14/64 loss: 0.30513232946395874
Batch 15/64 loss: 0.29792165756225586
Batch 16/64 loss: 0.3075984716415405
Batch 17/64 loss: 0.30460935831069946
Batch 18/64 loss: 0.3075025677680969
Batch 19/64 loss: 0.3043009042739868
Batch 20/64 loss: 0.30210208892822266
Batch 21/64 loss: 0.31040722131729126
Batch 22/64 loss: 0.3035252094268799
Batch 23/64 loss: 0.30122804641723633
Batch 24/64 loss: 0.30476588010787964
Batch 25/64 loss: 0.29987603425979614
Batch 26/64 loss: 0.2956637144088745
Batch 27/64 loss: 0.3014552593231201
Batch 28/64 loss: 0.30079030990600586
Batch 29/64 loss: 0.3042013645172119
Batch 30/64 loss: 0.3029150366783142
Batch 31/64 loss: 0.3037679195404053
Batch 32/64 loss: 0.30807411670684814
Batch 33/64 loss: 0.30149805545806885
Batch 34/64 loss: 0.3020690679550171
Batch 35/64 loss: 0.3053208589553833
Batch 36/64 loss: 0.3020511865615845
Batch 37/64 loss: 0.305361270904541
Batch 38/64 loss: 0.30203717947006226
Batch 39/64 loss: 0.3091169595718384
Batch 40/64 loss: 0.30082613229751587
Batch 41/64 loss: 0.300459086894989
Batch 42/64 loss: 0.3019782304763794
Batch 43/64 loss: 0.2982175350189209
Batch 44/64 loss: 0.3049306869506836
Batch 45/64 loss: 0.301144003868103
Batch 46/64 loss: 0.29610157012939453
Batch 47/64 loss: 0.29914581775665283
Batch 48/64 loss: 0.3061774969100952
Batch 49/64 loss: 0.29908645153045654
Batch 50/64 loss: 0.30341482162475586
Batch 51/64 loss: 0.30312007665634155
Batch 52/64 loss: 0.30165737867355347
Batch 53/64 loss: 0.3043094873428345
Batch 54/64 loss: 0.3052111864089966
Batch 55/64 loss: 0.2990441918373108
Batch 56/64 loss: 0.3043506145477295
Batch 57/64 loss: 0.3035525679588318
Batch 58/64 loss: 0.297884464263916
Batch 59/64 loss: 0.30092597007751465
Batch 60/64 loss: 0.3146582841873169
Batch 61/64 loss: 0.3040594458580017
Batch 62/64 loss: 0.30845654010772705
Batch 63/64 loss: 0.2998957633972168
Batch 64/64 loss: 0.300950288772583
Epoch 173  Train loss: 0.3023741226570279  Val loss: 0.3189851111153147
Epoch 174
-------------------------------
Batch 1/64 loss: 0.2934145927429199
Batch 2/64 loss: 0.3063774108886719
Batch 3/64 loss: 0.303574800491333
Batch 4/64 loss: 0.2979452610015869
Batch 5/64 loss: 0.29730772972106934
Batch 6/64 loss: 0.3001585006713867
Batch 7/64 loss: 0.302959680557251
Batch 8/64 loss: 0.3033716082572937
Batch 9/64 loss: 0.2960801124572754
Batch 10/64 loss: 0.2985309362411499
Batch 11/64 loss: 0.2987353801727295
Batch 12/64 loss: 0.3075360655784607
Batch 13/64 loss: 0.30051112174987793
Batch 14/64 loss: 0.3089122772216797
Batch 15/64 loss: 0.3038719892501831
Batch 16/64 loss: 0.29989153146743774
Batch 17/64 loss: 0.2982673645019531
Batch 18/64 loss: 0.30411863327026367
Batch 19/64 loss: 0.30615854263305664
Batch 20/64 loss: 0.3034217357635498
Batch 21/64 loss: 0.2987164258956909
Batch 22/64 loss: 0.3032458424568176
Batch 23/64 loss: 0.3003895878791809
Batch 24/64 loss: 0.30118656158447266
Batch 25/64 loss: 0.2968329191207886
Batch 26/64 loss: 0.2993440628051758
Batch 27/64 loss: 0.31266653537750244
Batch 28/64 loss: 0.3033725619316101
Batch 29/64 loss: 0.30653154850006104
Batch 30/64 loss: 0.2978721261024475
Batch 31/64 loss: 0.29985344409942627
Batch 32/64 loss: 0.3111536502838135
Batch 33/64 loss: 0.29806697368621826
Batch 34/64 loss: 0.30657243728637695
Batch 35/64 loss: 0.3010141849517822
Batch 36/64 loss: 0.3076578378677368
Batch 37/64 loss: 0.299008309841156
Batch 38/64 loss: 0.3015553951263428
Batch 39/64 loss: 0.29727816581726074
Batch 40/64 loss: 0.30320578813552856
Batch 41/64 loss: 0.3051830530166626
Batch 42/64 loss: 0.30107635259628296
Batch 43/64 loss: 0.2980613708496094
Batch 44/64 loss: 0.3090885877609253
Batch 45/64 loss: 0.2985193729400635
Batch 46/64 loss: 0.3061494827270508
Batch 47/64 loss: 0.3070167303085327
Batch 48/64 loss: 0.3087419271469116
Batch 49/64 loss: 0.30053770542144775
Batch 50/64 loss: 0.30043232440948486
Batch 51/64 loss: 0.3003276586532593
Batch 52/64 loss: 0.3093891143798828
Batch 53/64 loss: 0.3022303581237793
Batch 54/64 loss: 0.30796825885772705
Batch 55/64 loss: 0.29731452465057373
Batch 56/64 loss: 0.3005989193916321
Batch 57/64 loss: 0.30051350593566895
Batch 58/64 loss: 0.3002445101737976
Batch 59/64 loss: 0.29778385162353516
Batch 60/64 loss: 0.3107619285583496
Batch 61/64 loss: 0.30058354139328003
Batch 62/64 loss: 0.2983955144882202
Batch 63/64 loss: 0.30585700273513794
Batch 64/64 loss: 0.30730587244033813
Epoch 174  Train loss: 0.3023360726880092  Val loss: 0.3182305806281231
Epoch 175
-------------------------------
Batch 1/64 loss: 0.3012332320213318
Batch 2/64 loss: 0.2972632646560669
Batch 3/64 loss: 0.30032098293304443
Batch 4/64 loss: 0.2986173629760742
Batch 5/64 loss: 0.3026507496833801
Batch 6/64 loss: 0.3042869567871094
Batch 7/64 loss: 0.30149877071380615
Batch 8/64 loss: 0.30705583095550537
Batch 9/64 loss: 0.29637670516967773
Batch 10/64 loss: 0.30030155181884766
Batch 11/64 loss: 0.2984030246734619
Batch 12/64 loss: 0.29988574981689453
Batch 13/64 loss: 0.30251652002334595
Batch 14/64 loss: 0.3102700710296631
Batch 15/64 loss: 0.30715787410736084
Batch 16/64 loss: 0.29836350679397583
Batch 17/64 loss: 0.296347975730896
Batch 18/64 loss: 0.29612553119659424
Batch 19/64 loss: 0.29695892333984375
Batch 20/64 loss: 0.30439233779907227
Batch 21/64 loss: 0.3050605058670044
Batch 22/64 loss: 0.3018019199371338
Batch 23/64 loss: 0.303455114364624
Batch 24/64 loss: 0.3041030168533325
Batch 25/64 loss: 0.29695677757263184
Batch 26/64 loss: 0.30680274963378906
Batch 27/64 loss: 0.2999814748764038
Batch 28/64 loss: 0.2994895577430725
Batch 29/64 loss: 0.29388463497161865
Batch 30/64 loss: 0.3083827495574951
Batch 31/64 loss: 0.30287349224090576
Batch 32/64 loss: 0.30977094173431396
Batch 33/64 loss: 0.3079919219017029
Batch 34/64 loss: 0.30459046363830566
Batch 35/64 loss: 0.2982008457183838
Batch 36/64 loss: 0.3060300350189209
Batch 37/64 loss: 0.30632948875427246
Batch 38/64 loss: 0.2968345880508423
Batch 39/64 loss: 0.3053838014602661
Batch 40/64 loss: 0.3030098080635071
Batch 41/64 loss: 0.29740166664123535
Batch 42/64 loss: 0.30487382411956787
Batch 43/64 loss: 0.30255699157714844
Batch 44/64 loss: 0.2974401116371155
Batch 45/64 loss: 0.30090421438217163
Batch 46/64 loss: 0.3015899658203125
Batch 47/64 loss: 0.29826945066452026
Batch 48/64 loss: 0.2985498905181885
Batch 49/64 loss: 0.3006983995437622
Batch 50/64 loss: 0.3004223108291626
Batch 51/64 loss: 0.30500298738479614
Batch 52/64 loss: 0.3016098737716675
Batch 53/64 loss: 0.2977715730667114
Batch 54/64 loss: 0.2983607053756714
Batch 55/64 loss: 0.29676079750061035
Batch 56/64 loss: 0.30679845809936523
Batch 57/64 loss: 0.3109862208366394
Batch 58/64 loss: 0.31329602003097534
Batch 59/64 loss: 0.3013650178909302
Batch 60/64 loss: 0.30268388986587524
Batch 61/64 loss: 0.301078736782074
Batch 62/64 loss: 0.301510751247406
Batch 63/64 loss: 0.3077812194824219
Batch 64/64 loss: 0.30161505937576294
Epoch 175  Train loss: 0.30203741461622946  Val loss: 0.31904522311646505
Epoch 176
-------------------------------
Batch 1/64 loss: 0.30580568313598633
Batch 2/64 loss: 0.3036123514175415
Batch 3/64 loss: 0.3018850088119507
Batch 4/64 loss: 0.3021577000617981
Batch 5/64 loss: 0.3026767373085022
Batch 6/64 loss: 0.29701435565948486
Batch 7/64 loss: 0.2969484329223633
Batch 8/64 loss: 0.3010108470916748
Batch 9/64 loss: 0.3029211163520813
Batch 10/64 loss: 0.30279040336608887
Batch 11/64 loss: 0.3042662739753723
Batch 12/64 loss: 0.3047548532485962
Batch 13/64 loss: 0.29898297786712646
Batch 14/64 loss: 0.3010009527206421
Batch 15/64 loss: 0.2970082759857178
Batch 16/64 loss: 0.3032521605491638
Batch 17/64 loss: 0.30164796113967896
Batch 18/64 loss: 0.30314791202545166
Batch 19/64 loss: 0.29958319664001465
Batch 20/64 loss: 0.30797863006591797
Batch 21/64 loss: 0.2987334728240967
Batch 22/64 loss: 0.3056509494781494
Batch 23/64 loss: 0.3006809949874878
Batch 24/64 loss: 0.3051289916038513
Batch 25/64 loss: 0.3039259910583496
Batch 26/64 loss: 0.30396270751953125
Batch 27/64 loss: 0.30463123321533203
Batch 28/64 loss: 0.30557310581207275
Batch 29/64 loss: 0.30179035663604736
Batch 30/64 loss: 0.2990354299545288
Batch 31/64 loss: 0.29933667182922363
Batch 32/64 loss: 0.30492663383483887
Batch 33/64 loss: 0.3067142963409424
Batch 34/64 loss: 0.3041834831237793
Batch 35/64 loss: 0.30618083477020264
Batch 36/64 loss: 0.29785865545272827
Batch 37/64 loss: 0.2967485189437866
Batch 38/64 loss: 0.295376718044281
Batch 39/64 loss: 0.2974216938018799
Batch 40/64 loss: 0.30039966106414795
Batch 41/64 loss: 0.30041444301605225
Batch 42/64 loss: 0.30326950550079346
Batch 43/64 loss: 0.3009911775588989
Batch 44/64 loss: 0.3021883964538574
Batch 45/64 loss: 0.29935580492019653
Batch 46/64 loss: 0.3038552403450012
Batch 47/64 loss: 0.3048298954963684
Batch 48/64 loss: 0.304034948348999
Batch 49/64 loss: 0.3077773451805115
Batch 50/64 loss: 0.30288630723953247
Batch 51/64 loss: 0.299007773399353
Batch 52/64 loss: 0.3063594698905945
Batch 53/64 loss: 0.3106551170349121
Batch 54/64 loss: 0.3085707426071167
Batch 55/64 loss: 0.30131995677948
Batch 56/64 loss: 0.3014167547225952
Batch 57/64 loss: 0.301088809967041
Batch 58/64 loss: 0.2972186803817749
Batch 59/64 loss: 0.30057471990585327
Batch 60/64 loss: 0.3055986166000366
Batch 61/64 loss: 0.299088716506958
Batch 62/64 loss: 0.3000585436820984
Batch 63/64 loss: 0.2981058359146118
Batch 64/64 loss: 0.2979891896247864
Epoch 176  Train loss: 0.30209984194998646  Val loss: 0.3189906871195921
Epoch 177
-------------------------------
Batch 1/64 loss: 0.3008451461791992
Batch 2/64 loss: 0.29897594451904297
Batch 3/64 loss: 0.3020033836364746
Batch 4/64 loss: 0.30031049251556396
Batch 5/64 loss: 0.2982102632522583
Batch 6/64 loss: 0.2999849319458008
Batch 7/64 loss: 0.29596734046936035
Batch 8/64 loss: 0.310882031917572
Batch 9/64 loss: 0.3046680688858032
Batch 10/64 loss: 0.30747663974761963
Batch 11/64 loss: 0.2966495752334595
Batch 12/64 loss: 0.3039344549179077
Batch 13/64 loss: 0.2996624708175659
Batch 14/64 loss: 0.3022722005844116
Batch 15/64 loss: 0.31084150075912476
Batch 16/64 loss: 0.29163968563079834
Batch 17/64 loss: 0.29572153091430664
Batch 18/64 loss: 0.3073688745498657
Batch 19/64 loss: 0.30084729194641113
Batch 20/64 loss: 0.30167603492736816
Batch 21/64 loss: 0.29761606454849243
Batch 22/64 loss: 0.298025906085968
Batch 23/64 loss: 0.2973911166191101
Batch 24/64 loss: 0.30172252655029297
Batch 25/64 loss: 0.2938878536224365
Batch 26/64 loss: 0.29774367809295654
Batch 27/64 loss: 0.3002500534057617
Batch 28/64 loss: 0.2974536418914795
Batch 29/64 loss: 0.301935076713562
Batch 30/64 loss: 0.29759538173675537
Batch 31/64 loss: 0.29776501655578613
Batch 32/64 loss: 0.3060588836669922
Batch 33/64 loss: 0.29576635360717773
Batch 34/64 loss: 0.29947328567504883
Batch 35/64 loss: 0.29944998025894165
Batch 36/64 loss: 0.30534911155700684
Batch 37/64 loss: 0.30284106731414795
Batch 38/64 loss: 0.2988154888153076
Batch 39/64 loss: 0.3083401322364807
Batch 40/64 loss: 0.3067052364349365
Batch 41/64 loss: 0.30317986011505127
Batch 42/64 loss: 0.30010557174682617
Batch 43/64 loss: 0.3016486167907715
Batch 44/64 loss: 0.3027997612953186
Batch 45/64 loss: 0.29799211025238037
Batch 46/64 loss: 0.29885202646255493
Batch 47/64 loss: 0.29733288288116455
Batch 48/64 loss: 0.3078595995903015
Batch 49/64 loss: 0.2990682125091553
Batch 50/64 loss: 0.2987549901008606
Batch 51/64 loss: 0.30621808767318726
Batch 52/64 loss: 0.3017460107803345
Batch 53/64 loss: 0.3029494285583496
Batch 54/64 loss: 0.29975318908691406
Batch 55/64 loss: 0.29894232749938965
Batch 56/64 loss: 0.3044320344924927
Batch 57/64 loss: 0.30418074131011963
Batch 58/64 loss: 0.30040597915649414
Batch 59/64 loss: 0.30732953548431396
Batch 60/64 loss: 0.30207139253616333
Batch 61/64 loss: 0.30111968517303467
Batch 62/64 loss: 0.3028392791748047
Batch 63/64 loss: 0.3019600510597229
Batch 64/64 loss: 0.3125709295272827
Epoch 177  Train loss: 0.3013347966998231  Val loss: 0.31784767957077814
Saving best model, epoch: 177
Epoch 178
-------------------------------
Batch 1/64 loss: 0.30522358417510986
Batch 2/64 loss: 0.29891741275787354
Batch 3/64 loss: 0.3018924593925476
Batch 4/64 loss: 0.30304205417633057
Batch 5/64 loss: 0.30433356761932373
Batch 6/64 loss: 0.3026895523071289
Batch 7/64 loss: 0.3036579489707947
Batch 8/64 loss: 0.3069765567779541
Batch 9/64 loss: 0.29486602544784546
Batch 10/64 loss: 0.2945295572280884
Batch 11/64 loss: 0.30554258823394775
Batch 12/64 loss: 0.3043147325515747
Batch 13/64 loss: 0.30271923542022705
Batch 14/64 loss: 0.2970907688140869
Batch 15/64 loss: 0.30636000633239746
Batch 16/64 loss: 0.2953365445137024
Batch 17/64 loss: 0.2970830202102661
Batch 18/64 loss: 0.30185234546661377
Batch 19/64 loss: 0.30464887619018555
Batch 20/64 loss: 0.30172431468963623
Batch 21/64 loss: 0.30248427391052246
Batch 22/64 loss: 0.30169516801834106
Batch 23/64 loss: 0.29900574684143066
Batch 24/64 loss: 0.3012683391571045
Batch 25/64 loss: 0.30364543199539185
Batch 26/64 loss: 0.2998194694519043
Batch 27/64 loss: 0.30300331115722656
Batch 28/64 loss: 0.2983520030975342
Batch 29/64 loss: 0.31027233600616455
Batch 30/64 loss: 0.29639899730682373
Batch 31/64 loss: 0.3029404878616333
Batch 32/64 loss: 0.30007505416870117
Batch 33/64 loss: 0.29509902000427246
Batch 34/64 loss: 0.29793596267700195
Batch 35/64 loss: 0.3008517026901245
Batch 36/64 loss: 0.2965942621231079
Batch 37/64 loss: 0.29693031311035156
Batch 38/64 loss: 0.3094191551208496
Batch 39/64 loss: 0.3033381700515747
Batch 40/64 loss: 0.2932039499282837
Batch 41/64 loss: 0.304315447807312
Batch 42/64 loss: 0.2991678714752197
Batch 43/64 loss: 0.30807745456695557
Batch 44/64 loss: 0.29432499408721924
Batch 45/64 loss: 0.29825127124786377
Batch 46/64 loss: 0.2948032021522522
Batch 47/64 loss: 0.3094133138656616
Batch 48/64 loss: 0.2984212040901184
Batch 49/64 loss: 0.3078627586364746
Batch 50/64 loss: 0.2989072799682617
Batch 51/64 loss: 0.30433374643325806
Batch 52/64 loss: 0.3026348352432251
Batch 53/64 loss: 0.30103206634521484
Batch 54/64 loss: 0.30177295207977295
Batch 55/64 loss: 0.29651665687561035
Batch 56/64 loss: 0.30866503715515137
Batch 57/64 loss: 0.2931811213493347
Batch 58/64 loss: 0.3039395213127136
Batch 59/64 loss: 0.30357658863067627
Batch 60/64 loss: 0.2989945411682129
Batch 61/64 loss: 0.3073895573616028
Batch 62/64 loss: 0.2989944815635681
Batch 63/64 loss: 0.309073805809021
Batch 64/64 loss: 0.30907607078552246
Epoch 178  Train loss: 0.30149946773753444  Val loss: 0.31897241573563145
Epoch 179
-------------------------------
Batch 1/64 loss: 0.31124985218048096
Batch 2/64 loss: 0.3063284158706665
Batch 3/64 loss: 0.29763734340667725
Batch 4/64 loss: 0.3018506169319153
Batch 5/64 loss: 0.30492788553237915
Batch 6/64 loss: 0.3056418299674988
Batch 7/64 loss: 0.29994940757751465
Batch 8/64 loss: 0.3033095598220825
Batch 9/64 loss: 0.3036705255508423
Batch 10/64 loss: 0.29916900396347046
Batch 11/64 loss: 0.3033684492111206
Batch 12/64 loss: 0.30036449432373047
Batch 13/64 loss: 0.2993716597557068
Batch 14/64 loss: 0.29831981658935547
Batch 15/64 loss: 0.29711830615997314
Batch 16/64 loss: 0.29518502950668335
Batch 17/64 loss: 0.29757726192474365
Batch 18/64 loss: 0.30142414569854736
Batch 19/64 loss: 0.30707085132598877
Batch 20/64 loss: 0.3062460422515869
Batch 21/64 loss: 0.3029515743255615
Batch 22/64 loss: 0.3006129264831543
Batch 23/64 loss: 0.3000637888908386
Batch 24/64 loss: 0.3010849952697754
Batch 25/64 loss: 0.3055459260940552
Batch 26/64 loss: 0.29838109016418457
Batch 27/64 loss: 0.29864394664764404
Batch 28/64 loss: 0.29791975021362305
Batch 29/64 loss: 0.30067020654678345
Batch 30/64 loss: 0.302057683467865
Batch 31/64 loss: 0.30571627616882324
Batch 32/64 loss: 0.3040902614593506
Batch 33/64 loss: 0.30861425399780273
Batch 34/64 loss: 0.29407799243927
Batch 35/64 loss: 0.29887092113494873
Batch 36/64 loss: 0.3018421530723572
Batch 37/64 loss: 0.2985551357269287
Batch 38/64 loss: 0.3028252124786377
Batch 39/64 loss: 0.305666983127594
Batch 40/64 loss: 0.30924344062805176
Batch 41/64 loss: 0.2996770143508911
Batch 42/64 loss: 0.3070366382598877
Batch 43/64 loss: 0.3006974458694458
Batch 44/64 loss: 0.2981923818588257
Batch 45/64 loss: 0.3031441569328308
Batch 46/64 loss: 0.2983478903770447
Batch 47/64 loss: 0.2958452105522156
Batch 48/64 loss: 0.30368149280548096
Batch 49/64 loss: 0.29545658826828003
Batch 50/64 loss: 0.300801157951355
Batch 51/64 loss: 0.301474928855896
Batch 52/64 loss: 0.303503155708313
Batch 53/64 loss: 0.30610525608062744
Batch 54/64 loss: 0.297898530960083
Batch 55/64 loss: 0.30353498458862305
Batch 56/64 loss: 0.2986624240875244
Batch 57/64 loss: 0.2996666431427002
Batch 58/64 loss: 0.3002864122390747
Batch 59/64 loss: 0.2966376543045044
Batch 60/64 loss: 0.3057974576950073
Batch 61/64 loss: 0.30239713191986084
Batch 62/64 loss: 0.3023335933685303
Batch 63/64 loss: 0.2974708080291748
Batch 64/64 loss: 0.3024141192436218
Epoch 179  Train loss: 0.3015321500161115  Val loss: 0.31810902627473026
Epoch 180
-------------------------------
Batch 1/64 loss: 0.2995545268058777
Batch 2/64 loss: 0.2999778985977173
Batch 3/64 loss: 0.303020715713501
Batch 4/64 loss: 0.2946970462799072
Batch 5/64 loss: 0.3009047508239746
Batch 6/64 loss: 0.29129332304000854
Batch 7/64 loss: 0.2995649576187134
Batch 8/64 loss: 0.29667818546295166
Batch 9/64 loss: 0.3007471561431885
Batch 10/64 loss: 0.3136395812034607
Batch 11/64 loss: 0.30457186698913574
Batch 12/64 loss: 0.2981727123260498
Batch 13/64 loss: 0.30762141942977905
Batch 14/64 loss: 0.2969058156013489
Batch 15/64 loss: 0.30691254138946533
Batch 16/64 loss: 0.3015251159667969
Batch 17/64 loss: 0.3002786636352539
Batch 18/64 loss: 0.30145031213760376
Batch 19/64 loss: 0.2953540086746216
Batch 20/64 loss: 0.3004755973815918
Batch 21/64 loss: 0.29938095808029175
Batch 22/64 loss: 0.3002239465713501
Batch 23/64 loss: 0.29761606454849243
Batch 24/64 loss: 0.3011484146118164
Batch 25/64 loss: 0.30420589447021484
Batch 26/64 loss: 0.2984626293182373
Batch 27/64 loss: 0.29911720752716064
Batch 28/64 loss: 0.30871903896331787
Batch 29/64 loss: 0.2971837520599365
Batch 30/64 loss: 0.2981787323951721
Batch 31/64 loss: 0.3059241771697998
Batch 32/64 loss: 0.30200088024139404
Batch 33/64 loss: 0.2983420491218567
Batch 34/64 loss: 0.30189353227615356
Batch 35/64 loss: 0.303047776222229
Batch 36/64 loss: 0.3020382523536682
Batch 37/64 loss: 0.3048776388168335
Batch 38/64 loss: 0.3099674582481384
Batch 39/64 loss: 0.29696786403656006
Batch 40/64 loss: 0.29700911045074463
Batch 41/64 loss: 0.3077324628829956
Batch 42/64 loss: 0.29808545112609863
Batch 43/64 loss: 0.30047833919525146
Batch 44/64 loss: 0.29527711868286133
Batch 45/64 loss: 0.29989802837371826
Batch 46/64 loss: 0.30184078216552734
Batch 47/64 loss: 0.30052661895751953
Batch 48/64 loss: 0.30692625045776367
Batch 49/64 loss: 0.2992302179336548
Batch 50/64 loss: 0.2932167649269104
Batch 51/64 loss: 0.29734277725219727
Batch 52/64 loss: 0.2966560125350952
Batch 53/64 loss: 0.30089592933654785
Batch 54/64 loss: 0.3021543622016907
Batch 55/64 loss: 0.30118072032928467
Batch 56/64 loss: 0.2971543073654175
Batch 57/64 loss: 0.3060704469680786
Batch 58/64 loss: 0.30447983741760254
Batch 59/64 loss: 0.30453211069107056
Batch 60/64 loss: 0.29579460620880127
Batch 61/64 loss: 0.2983666658401489
Batch 62/64 loss: 0.30172544717788696
Batch 63/64 loss: 0.3048518896102905
Batch 64/64 loss: 0.3042649030685425
Epoch 180  Train loss: 0.3008983121198766  Val loss: 0.31781344274474993
Saving best model, epoch: 180
Epoch 181
-------------------------------
Batch 1/64 loss: 0.30143213272094727
Batch 2/64 loss: 0.3034207820892334
Batch 3/64 loss: 0.29903578758239746
Batch 4/64 loss: 0.2987979054450989
Batch 5/64 loss: 0.30706310272216797
Batch 6/64 loss: 0.30204373598098755
Batch 7/64 loss: 0.30283862352371216
Batch 8/64 loss: 0.2971259355545044
Batch 9/64 loss: 0.30395638942718506
Batch 10/64 loss: 0.30242908000946045
Batch 11/64 loss: 0.30018550157546997
Batch 12/64 loss: 0.304638147354126
Batch 13/64 loss: 0.2991209030151367
Batch 14/64 loss: 0.29866528511047363
Batch 15/64 loss: 0.3022492527961731
Batch 16/64 loss: 0.2986276149749756
Batch 17/64 loss: 0.2962285876274109
Batch 18/64 loss: 0.2969120740890503
Batch 19/64 loss: 0.30481410026550293
Batch 20/64 loss: 0.29389137029647827
Batch 21/64 loss: 0.30171942710876465
Batch 22/64 loss: 0.2995738983154297
Batch 23/64 loss: 0.30839788913726807
Batch 24/64 loss: 0.30032527446746826
Batch 25/64 loss: 0.2970428466796875
Batch 26/64 loss: 0.2996152639389038
Batch 27/64 loss: 0.2955593466758728
Batch 28/64 loss: 0.296969473361969
Batch 29/64 loss: 0.3010947108268738
Batch 30/64 loss: 0.299746572971344
Batch 31/64 loss: 0.29901933670043945
Batch 32/64 loss: 0.3016672134399414
Batch 33/64 loss: 0.30278849601745605
Batch 34/64 loss: 0.29914391040802
Batch 35/64 loss: 0.2977260947227478
Batch 36/64 loss: 0.2967493534088135
Batch 37/64 loss: 0.3039097785949707
Batch 38/64 loss: 0.29301953315734863
Batch 39/64 loss: 0.3008333444595337
Batch 40/64 loss: 0.30570805072784424
Batch 41/64 loss: 0.29791224002838135
Batch 42/64 loss: 0.2988860011100769
Batch 43/64 loss: 0.3082627058029175
Batch 44/64 loss: 0.3001060485839844
Batch 45/64 loss: 0.311448335647583
Batch 46/64 loss: 0.2991296052932739
Batch 47/64 loss: 0.3041067123413086
Batch 48/64 loss: 0.2952197790145874
Batch 49/64 loss: 0.30281972885131836
Batch 50/64 loss: 0.2954399585723877
Batch 51/64 loss: 0.2955074906349182
Batch 52/64 loss: 0.3030744194984436
Batch 53/64 loss: 0.30333411693573
Batch 54/64 loss: 0.29611635208129883
Batch 55/64 loss: 0.3026164770126343
Batch 56/64 loss: 0.29824376106262207
Batch 57/64 loss: 0.30576634407043457
Batch 58/64 loss: 0.30244767665863037
Batch 59/64 loss: 0.2970144748687744
Batch 60/64 loss: 0.30182933807373047
Batch 61/64 loss: 0.2975071668624878
Batch 62/64 loss: 0.3042275905609131
Batch 63/64 loss: 0.296639621257782
Batch 64/64 loss: 0.3045004606246948
Epoch 181  Train loss: 0.30055086145214005  Val loss: 0.31768052315793904
Saving best model, epoch: 181
Epoch 182
-------------------------------
Batch 1/64 loss: 0.2908940315246582
Batch 2/64 loss: 0.2950279712677002
Batch 3/64 loss: 0.303963303565979
Batch 4/64 loss: 0.30046409368515015
Batch 5/64 loss: 0.29644548892974854
Batch 6/64 loss: 0.29823148250579834
Batch 7/64 loss: 0.29813480377197266
Batch 8/64 loss: 0.298661470413208
Batch 9/64 loss: 0.30816447734832764
Batch 10/64 loss: 0.298287570476532
Batch 11/64 loss: 0.2997715473175049
Batch 12/64 loss: 0.3021879196166992
Batch 13/64 loss: 0.2914016842842102
Batch 14/64 loss: 0.3018765449523926
Batch 15/64 loss: 0.3111487627029419
Batch 16/64 loss: 0.29247814416885376
Batch 17/64 loss: 0.3041057586669922
Batch 18/64 loss: 0.3017677664756775
Batch 19/64 loss: 0.29614388942718506
Batch 20/64 loss: 0.2990461587905884
Batch 21/64 loss: 0.3032582998275757
Batch 22/64 loss: 0.3000081777572632
Batch 23/64 loss: 0.2966364026069641
Batch 24/64 loss: 0.2969621419906616
Batch 25/64 loss: 0.30059629678726196
Batch 26/64 loss: 0.29810577630996704
Batch 27/64 loss: 0.3003002405166626
Batch 28/64 loss: 0.30084431171417236
Batch 29/64 loss: 0.30455923080444336
Batch 30/64 loss: 0.2939414381980896
Batch 31/64 loss: 0.29412931203842163
Batch 32/64 loss: 0.3056001663208008
Batch 33/64 loss: 0.3071906566619873
Batch 34/64 loss: 0.2956504821777344
Batch 35/64 loss: 0.31257712841033936
Batch 36/64 loss: 0.2991626262664795
Batch 37/64 loss: 0.30104637145996094
Batch 38/64 loss: 0.29881519079208374
Batch 39/64 loss: 0.3013855218887329
Batch 40/64 loss: 0.30432283878326416
Batch 41/64 loss: 0.2995651960372925
Batch 42/64 loss: 0.2985861897468567
Batch 43/64 loss: 0.30421602725982666
Batch 44/64 loss: 0.30114293098449707
Batch 45/64 loss: 0.30178844928741455
Batch 46/64 loss: 0.3026951551437378
Batch 47/64 loss: 0.3147413730621338
Batch 48/64 loss: 0.3025552034378052
Batch 49/64 loss: 0.30126142501831055
Batch 50/64 loss: 0.30218935012817383
Batch 51/64 loss: 0.30067265033721924
Batch 52/64 loss: 0.30032992362976074
Batch 53/64 loss: 0.30169677734375
Batch 54/64 loss: 0.3023536205291748
Batch 55/64 loss: 0.30833303928375244
Batch 56/64 loss: 0.3020372986793518
Batch 57/64 loss: 0.3008418083190918
Batch 58/64 loss: 0.30043327808380127
Batch 59/64 loss: 0.3012980818748474
Batch 60/64 loss: 0.29596662521362305
Batch 61/64 loss: 0.293049156665802
Batch 62/64 loss: 0.3134686350822449
Batch 63/64 loss: 0.30134308338165283
Batch 64/64 loss: 0.300775945186615
Epoch 182  Train loss: 0.3008540034294128  Val loss: 0.3190487164402336
Epoch 183
-------------------------------
Batch 1/64 loss: 0.3027818202972412
Batch 2/64 loss: 0.3117198348045349
Batch 3/64 loss: 0.2981952428817749
Batch 4/64 loss: 0.29995840787887573
Batch 5/64 loss: 0.2977273464202881
Batch 6/64 loss: 0.3051212430000305
Batch 7/64 loss: 0.2973926067352295
Batch 8/64 loss: 0.3013380765914917
Batch 9/64 loss: 0.29691529273986816
Batch 10/64 loss: 0.3065556287765503
Batch 11/64 loss: 0.29803895950317383
Batch 12/64 loss: 0.2975642681121826
Batch 13/64 loss: 0.29824185371398926
Batch 14/64 loss: 0.2998431921005249
Batch 15/64 loss: 0.3010880947113037
Batch 16/64 loss: 0.3010939359664917
Batch 17/64 loss: 0.3001757860183716
Batch 18/64 loss: 0.3006037473678589
Batch 19/64 loss: 0.3044953942298889
Batch 20/64 loss: 0.29810547828674316
Batch 21/64 loss: 0.2991238832473755
Batch 22/64 loss: 0.301403284072876
Batch 23/64 loss: 0.300862193107605
Batch 24/64 loss: 0.29973626136779785
Batch 25/64 loss: 0.29791104793548584
Batch 26/64 loss: 0.2963864207267761
Batch 27/64 loss: 0.3033345341682434
Batch 28/64 loss: 0.30493229627609253
Batch 29/64 loss: 0.30410540103912354
Batch 30/64 loss: 0.30670177936553955
Batch 31/64 loss: 0.2957956790924072
Batch 32/64 loss: 0.29402804374694824
Batch 33/64 loss: 0.30168330669403076
Batch 34/64 loss: 0.2947004437446594
Batch 35/64 loss: 0.3017941117286682
Batch 36/64 loss: 0.3017897605895996
Batch 37/64 loss: 0.30358004570007324
Batch 38/64 loss: 0.29856860637664795
Batch 39/64 loss: 0.2962307929992676
Batch 40/64 loss: 0.306268572807312
Batch 41/64 loss: 0.30127012729644775
Batch 42/64 loss: 0.30056554079055786
Batch 43/64 loss: 0.2997100353240967
Batch 44/64 loss: 0.30265259742736816
Batch 45/64 loss: 0.2963598966598511
Batch 46/64 loss: 0.3009125590324402
Batch 47/64 loss: 0.3061213493347168
Batch 48/64 loss: 0.3003663420677185
Batch 49/64 loss: 0.2973945140838623
Batch 50/64 loss: 0.30456799268722534
Batch 51/64 loss: 0.293546199798584
Batch 52/64 loss: 0.29664456844329834
Batch 53/64 loss: 0.2990072965621948
Batch 54/64 loss: 0.2936208248138428
Batch 55/64 loss: 0.29959410429000854
Batch 56/64 loss: 0.3045485019683838
Batch 57/64 loss: 0.2982366681098938
Batch 58/64 loss: 0.3007735013961792
Batch 59/64 loss: 0.2985406517982483
Batch 60/64 loss: 0.30104267597198486
Batch 61/64 loss: 0.2964487075805664
Batch 62/64 loss: 0.30232560634613037
Batch 63/64 loss: 0.29477882385253906
Batch 64/64 loss: 0.2938237190246582
Epoch 183  Train loss: 0.30016140470317765  Val loss: 0.3177020414588378
Epoch 184
-------------------------------
Batch 1/64 loss: 0.29581189155578613
Batch 2/64 loss: 0.29313015937805176
Batch 3/64 loss: 0.29514288902282715
Batch 4/64 loss: 0.2956087589263916
Batch 5/64 loss: 0.2996194362640381
Batch 6/64 loss: 0.29881060123443604
Batch 7/64 loss: 0.3001784086227417
Batch 8/64 loss: 0.2997097969055176
Batch 9/64 loss: 0.2982144355773926
Batch 10/64 loss: 0.2954748868942261
Batch 11/64 loss: 0.3077259063720703
Batch 12/64 loss: 0.3039133548736572
Batch 13/64 loss: 0.3018835783004761
Batch 14/64 loss: 0.3016066551208496
Batch 15/64 loss: 0.2992277145385742
Batch 16/64 loss: 0.2968395948410034
Batch 17/64 loss: 0.30127644538879395
Batch 18/64 loss: 0.3054763674736023
Batch 19/64 loss: 0.30100691318511963
Batch 20/64 loss: 0.2900072932243347
Batch 21/64 loss: 0.29910004138946533
Batch 22/64 loss: 0.29861581325531006
Batch 23/64 loss: 0.29532212018966675
Batch 24/64 loss: 0.298281192779541
Batch 25/64 loss: 0.3046536445617676
Batch 26/64 loss: 0.2921726703643799
Batch 27/64 loss: 0.30131447315216064
Batch 28/64 loss: 0.29878199100494385
Batch 29/64 loss: 0.3000156879425049
Batch 30/64 loss: 0.3069636821746826
Batch 31/64 loss: 0.30496639013290405
Batch 32/64 loss: 0.29966259002685547
Batch 33/64 loss: 0.2952800989151001
Batch 34/64 loss: 0.2996506690979004
Batch 35/64 loss: 0.307584285736084
Batch 36/64 loss: 0.2996652126312256
Batch 37/64 loss: 0.2969512939453125
Batch 38/64 loss: 0.3008204698562622
Batch 39/64 loss: 0.29835033416748047
Batch 40/64 loss: 0.3001352548599243
Batch 41/64 loss: 0.30434978008270264
Batch 42/64 loss: 0.3011664152145386
Batch 43/64 loss: 0.306465744972229
Batch 44/64 loss: 0.2961335778236389
Batch 45/64 loss: 0.30101585388183594
Batch 46/64 loss: 0.30083346366882324
Batch 47/64 loss: 0.2951161861419678
Batch 48/64 loss: 0.2994896173477173
Batch 49/64 loss: 0.3020930886268616
Batch 50/64 loss: 0.3018476963043213
Batch 51/64 loss: 0.29511672258377075
Batch 52/64 loss: 0.29732370376586914
Batch 53/64 loss: 0.29587042331695557
Batch 54/64 loss: 0.2974928617477417
Batch 55/64 loss: 0.2949952483177185
Batch 56/64 loss: 0.29374414682388306
Batch 57/64 loss: 0.2985798120498657
Batch 58/64 loss: 0.30536288022994995
Batch 59/64 loss: 0.2955814599990845
Batch 60/64 loss: 0.3034350275993347
Batch 61/64 loss: 0.299294114112854
Batch 62/64 loss: 0.30972009897232056
Batch 63/64 loss: 0.30467259883880615
Batch 64/64 loss: 0.29738056659698486
Epoch 184  Train loss: 0.2996343364902571  Val loss: 0.31754330220501037
Saving best model, epoch: 184
Epoch 185
-------------------------------
Batch 1/64 loss: 0.2948133945465088
Batch 2/64 loss: 0.2986266613006592
Batch 3/64 loss: 0.30409175157546997
Batch 4/64 loss: 0.30301082134246826
Batch 5/64 loss: 0.2981458902359009
Batch 6/64 loss: 0.2990304231643677
Batch 7/64 loss: 0.29135429859161377
Batch 8/64 loss: 0.3037313222885132
Batch 9/64 loss: 0.294668972492218
Batch 10/64 loss: 0.2969912886619568
Batch 11/64 loss: 0.29821085929870605
Batch 12/64 loss: 0.302942156791687
Batch 13/64 loss: 0.3034931421279907
Batch 14/64 loss: 0.2955451011657715
Batch 15/64 loss: 0.3011709451675415
Batch 16/64 loss: 0.2954075336456299
Batch 17/64 loss: 0.30014586448669434
Batch 18/64 loss: 0.2926398515701294
Batch 19/64 loss: 0.3036867380142212
Batch 20/64 loss: 0.295060396194458
Batch 21/64 loss: 0.29957181215286255
Batch 22/64 loss: 0.29921120405197144
Batch 23/64 loss: 0.30154699087142944
Batch 24/64 loss: 0.29910558462142944
Batch 25/64 loss: 0.30264705419540405
Batch 26/64 loss: 0.2907741069793701
Batch 27/64 loss: 0.30632907152175903
Batch 28/64 loss: 0.30731892585754395
Batch 29/64 loss: 0.3021916151046753
Batch 30/64 loss: 0.29949110746383667
Batch 31/64 loss: 0.2995709776878357
Batch 32/64 loss: 0.29700547456741333
Batch 33/64 loss: 0.2925722599029541
Batch 34/64 loss: 0.2981070280075073
Batch 35/64 loss: 0.2980937957763672
Batch 36/64 loss: 0.30022096633911133
Batch 37/64 loss: 0.2987253665924072
Batch 38/64 loss: 0.29651081562042236
Batch 39/64 loss: 0.3008098602294922
Batch 40/64 loss: 0.3003389835357666
Batch 41/64 loss: 0.30581969022750854
Batch 42/64 loss: 0.29743456840515137
Batch 43/64 loss: 0.3027627468109131
Batch 44/64 loss: 0.29737693071365356
Batch 45/64 loss: 0.30227404832839966
Batch 46/64 loss: 0.2967104911804199
Batch 47/64 loss: 0.30036717653274536
Batch 48/64 loss: 0.29799938201904297
Batch 49/64 loss: 0.30167460441589355
Batch 50/64 loss: 0.29977738857269287
Batch 51/64 loss: 0.29416823387145996
Batch 52/64 loss: 0.29914432764053345
Batch 53/64 loss: 0.2952421307563782
Batch 54/64 loss: 0.30399978160858154
Batch 55/64 loss: 0.29850804805755615
Batch 56/64 loss: 0.2982242703437805
Batch 57/64 loss: 0.3061348795890808
Batch 58/64 loss: 0.301554799079895
Batch 59/64 loss: 0.29877424240112305
Batch 60/64 loss: 0.29947543144226074
Batch 61/64 loss: 0.30232322216033936
Batch 62/64 loss: 0.30324238538742065
Batch 63/64 loss: 0.3005676865577698
Batch 64/64 loss: 0.297835111618042
Epoch 185  Train loss: 0.2994485209969913  Val loss: 0.31802803339417446
Epoch 186
-------------------------------
Batch 1/64 loss: 0.30431950092315674
Batch 2/64 loss: 0.3073328733444214
Batch 3/64 loss: 0.3048558235168457
Batch 4/64 loss: 0.2972538471221924
Batch 5/64 loss: 0.29981720447540283
Batch 6/64 loss: 0.29686903953552246
Batch 7/64 loss: 0.2962942123413086
Batch 8/64 loss: 0.3072713017463684
Batch 9/64 loss: 0.2953605651855469
Batch 10/64 loss: 0.30061662197113037
Batch 11/64 loss: 0.30541425943374634
Batch 12/64 loss: 0.2904307246208191
Batch 13/64 loss: 0.3000599145889282
Batch 14/64 loss: 0.3035600185394287
Batch 15/64 loss: 0.3036094903945923
Batch 16/64 loss: 0.29458087682724
Batch 17/64 loss: 0.29971253871917725
Batch 18/64 loss: 0.3029278516769409
Batch 19/64 loss: 0.2990483045578003
Batch 20/64 loss: 0.2987753748893738
Batch 21/64 loss: 0.295779824256897
Batch 22/64 loss: 0.2950934171676636
Batch 23/64 loss: 0.3003431558609009
Batch 24/64 loss: 0.2976245880126953
Batch 25/64 loss: 0.29176807403564453
Batch 26/64 loss: 0.2963780164718628
Batch 27/64 loss: 0.3018784523010254
Batch 28/64 loss: 0.2995911240577698
Batch 29/64 loss: 0.30254971981048584
Batch 30/64 loss: 0.3005140423774719
Batch 31/64 loss: 0.3000248670578003
Batch 32/64 loss: 0.2982715368270874
Batch 33/64 loss: 0.2970632314682007
Batch 34/64 loss: 0.2991700768470764
Batch 35/64 loss: 0.29128289222717285
Batch 36/64 loss: 0.29520612955093384
Batch 37/64 loss: 0.2996593713760376
Batch 38/64 loss: 0.3001657724380493
Batch 39/64 loss: 0.30192017555236816
Batch 40/64 loss: 0.29172736406326294
Batch 41/64 loss: 0.303641140460968
Batch 42/64 loss: 0.29847240447998047
Batch 43/64 loss: 0.2958972454071045
Batch 44/64 loss: 0.2975473403930664
Batch 45/64 loss: 0.31648051738739014
Batch 46/64 loss: 0.3044092059135437
Batch 47/64 loss: 0.29423069953918457
Batch 48/64 loss: 0.29537147283554077
Batch 49/64 loss: 0.3000486493110657
Batch 50/64 loss: 0.2994966506958008
Batch 51/64 loss: 0.31180238723754883
Batch 52/64 loss: 0.3007988929748535
Batch 53/64 loss: 0.2989037036895752
Batch 54/64 loss: 0.30155229568481445
Batch 55/64 loss: 0.29742109775543213
Batch 56/64 loss: 0.2969099283218384
Batch 57/64 loss: 0.30055999755859375
Batch 58/64 loss: 0.2928661108016968
Batch 59/64 loss: 0.2952519655227661
Batch 60/64 loss: 0.30274349451065063
Batch 61/64 loss: 0.3025912642478943
Batch 62/64 loss: 0.30484044551849365
Batch 63/64 loss: 0.2990579605102539
Batch 64/64 loss: 0.29571598768234253
Epoch 186  Train loss: 0.2995577103951398  Val loss: 0.3175267984776972
Saving best model, epoch: 186
Epoch 187
-------------------------------
Batch 1/64 loss: 0.30007457733154297
Batch 2/64 loss: 0.2977590560913086
Batch 3/64 loss: 0.2935352325439453
Batch 4/64 loss: 0.3057516813278198
Batch 5/64 loss: 0.300872802734375
Batch 6/64 loss: 0.30085694789886475
Batch 7/64 loss: 0.2930738925933838
Batch 8/64 loss: 0.29630619287490845
Batch 9/64 loss: 0.2972400188446045
Batch 10/64 loss: 0.3000478744506836
Batch 11/64 loss: 0.3030879497528076
Batch 12/64 loss: 0.3040310740470886
Batch 13/64 loss: 0.29139137268066406
Batch 14/64 loss: 0.30124783515930176
Batch 15/64 loss: 0.29492950439453125
Batch 16/64 loss: 0.30036497116088867
Batch 17/64 loss: 0.3065974712371826
Batch 18/64 loss: 0.29714858531951904
Batch 19/64 loss: 0.3004889488220215
Batch 20/64 loss: 0.2961512804031372
Batch 21/64 loss: 0.29736578464508057
Batch 22/64 loss: 0.29922664165496826
Batch 23/64 loss: 0.2989788055419922
Batch 24/64 loss: 0.29737794399261475
Batch 25/64 loss: 0.29630082845687866
Batch 26/64 loss: 0.2944583296775818
Batch 27/64 loss: 0.29801368713378906
Batch 28/64 loss: 0.2961374521255493
Batch 29/64 loss: 0.29419755935668945
Batch 30/64 loss: 0.306707501411438
Batch 31/64 loss: 0.3005186915397644
Batch 32/64 loss: 0.29815196990966797
Batch 33/64 loss: 0.30051088333129883
Batch 34/64 loss: 0.30835777521133423
Batch 35/64 loss: 0.3071081042289734
Batch 36/64 loss: 0.2961975336074829
Batch 37/64 loss: 0.29970788955688477
Batch 38/64 loss: 0.30180269479751587
Batch 39/64 loss: 0.29976922273635864
Batch 40/64 loss: 0.3055301904678345
Batch 41/64 loss: 0.3024331331253052
Batch 42/64 loss: 0.30170774459838867
Batch 43/64 loss: 0.3020309805870056
Batch 44/64 loss: 0.29810571670532227
Batch 45/64 loss: 0.2993907928466797
Batch 46/64 loss: 0.2992039918899536
Batch 47/64 loss: 0.296187162399292
Batch 48/64 loss: 0.29598701000213623
Batch 49/64 loss: 0.30068135261535645
Batch 50/64 loss: 0.30420422554016113
Batch 51/64 loss: 0.2987014651298523
Batch 52/64 loss: 0.3017212152481079
Batch 53/64 loss: 0.30107414722442627
Batch 54/64 loss: 0.30152273178100586
Batch 55/64 loss: 0.30064016580581665
Batch 56/64 loss: 0.300700306892395
Batch 57/64 loss: 0.30318546295166016
Batch 58/64 loss: 0.3000534176826477
Batch 59/64 loss: 0.2995353937149048
Batch 60/64 loss: 0.3007563352584839
Batch 61/64 loss: 0.29678815603256226
Batch 62/64 loss: 0.2934454679489136
Batch 63/64 loss: 0.2986963987350464
Batch 64/64 loss: 0.29149627685546875
Epoch 187  Train loss: 0.29949414496328314  Val loss: 0.3173663939807014
Saving best model, epoch: 187
Epoch 188
-------------------------------
Batch 1/64 loss: 0.2999229431152344
Batch 2/64 loss: 0.30193614959716797
Batch 3/64 loss: 0.29969465732574463
Batch 4/64 loss: 0.30135679244995117
Batch 5/64 loss: 0.2961922883987427
Batch 6/64 loss: 0.2992103099822998
Batch 7/64 loss: 0.2996586561203003
Batch 8/64 loss: 0.2955877184867859
Batch 9/64 loss: 0.2966752052307129
Batch 10/64 loss: 0.2923392057418823
Batch 11/64 loss: 0.29758334159851074
Batch 12/64 loss: 0.2939532399177551
Batch 13/64 loss: 0.2953873872756958
Batch 14/64 loss: 0.30980730056762695
Batch 15/64 loss: 0.2982445955276489
Batch 16/64 loss: 0.29709064960479736
Batch 17/64 loss: 0.2986903190612793
Batch 18/64 loss: 0.2913605570793152
Batch 19/64 loss: 0.2980412244796753
Batch 20/64 loss: 0.30254560708999634
Batch 21/64 loss: 0.30415213108062744
Batch 22/64 loss: 0.29764628410339355
Batch 23/64 loss: 0.3012317419052124
Batch 24/64 loss: 0.2942098379135132
Batch 25/64 loss: 0.3000108003616333
Batch 26/64 loss: 0.30226802825927734
Batch 27/64 loss: 0.3026137351989746
Batch 28/64 loss: 0.29316091537475586
Batch 29/64 loss: 0.30528581142425537
Batch 30/64 loss: 0.30233895778656006
Batch 31/64 loss: 0.29928112030029297
Batch 32/64 loss: 0.2934145927429199
Batch 33/64 loss: 0.29888975620269775
Batch 34/64 loss: 0.3004913330078125
Batch 35/64 loss: 0.3010219931602478
Batch 36/64 loss: 0.298733115196228
Batch 37/64 loss: 0.30010414123535156
Batch 38/64 loss: 0.3010450601577759
Batch 39/64 loss: 0.298933207988739
Batch 40/64 loss: 0.2981519103050232
Batch 41/64 loss: 0.30027979612350464
Batch 42/64 loss: 0.2981000542640686
Batch 43/64 loss: 0.2995772361755371
Batch 44/64 loss: 0.3008196949958801
Batch 45/64 loss: 0.2975963354110718
Batch 46/64 loss: 0.2976856231689453
Batch 47/64 loss: 0.2966078519821167
Batch 48/64 loss: 0.2982446551322937
Batch 49/64 loss: 0.2970709204673767
Batch 50/64 loss: 0.30435049533843994
Batch 51/64 loss: 0.3010149598121643
Batch 52/64 loss: 0.2995179295539856
Batch 53/64 loss: 0.2985635995864868
Batch 54/64 loss: 0.29978710412979126
Batch 55/64 loss: 0.301205575466156
Batch 56/64 loss: 0.30244719982147217
Batch 57/64 loss: 0.300078809261322
Batch 58/64 loss: 0.298239529132843
Batch 59/64 loss: 0.292885959148407
Batch 60/64 loss: 0.29909712076187134
Batch 61/64 loss: 0.2980034351348877
Batch 62/64 loss: 0.30123674869537354
Batch 63/64 loss: 0.2992200255393982
Batch 64/64 loss: 0.29873669147491455
Epoch 188  Train loss: 0.29904228705985875  Val loss: 0.3168318124161553
Saving best model, epoch: 188
Epoch 189
-------------------------------
Batch 1/64 loss: 0.2940402626991272
Batch 2/64 loss: 0.29658061265945435
Batch 3/64 loss: 0.29860180616378784
Batch 4/64 loss: 0.30160582065582275
Batch 5/64 loss: 0.29873746633529663
Batch 6/64 loss: 0.30343174934387207
Batch 7/64 loss: 0.2976853847503662
Batch 8/64 loss: 0.295199990272522
Batch 9/64 loss: 0.2974357604980469
Batch 10/64 loss: 0.30305516719818115
Batch 11/64 loss: 0.29689693450927734
Batch 12/64 loss: 0.2981376647949219
Batch 13/64 loss: 0.29925358295440674
Batch 14/64 loss: 0.3022729754447937
Batch 15/64 loss: 0.2960631847381592
Batch 16/64 loss: 0.2962879538536072
Batch 17/64 loss: 0.2929346561431885
Batch 18/64 loss: 0.2961312532424927
Batch 19/64 loss: 0.2977946996688843
Batch 20/64 loss: 0.2955514192581177
Batch 21/64 loss: 0.29685473442077637
Batch 22/64 loss: 0.3041069507598877
Batch 23/64 loss: 0.29677772521972656
Batch 24/64 loss: 0.2990073561668396
Batch 25/64 loss: 0.2954460382461548
Batch 26/64 loss: 0.29527586698532104
Batch 27/64 loss: 0.2962479591369629
Batch 28/64 loss: 0.30590546131134033
Batch 29/64 loss: 0.3044377565383911
Batch 30/64 loss: 0.29909461736679077
Batch 31/64 loss: 0.2965129613876343
Batch 32/64 loss: 0.3006221652030945
Batch 33/64 loss: 0.2995082139968872
Batch 34/64 loss: 0.2992525100708008
Batch 35/64 loss: 0.302303671836853
Batch 36/64 loss: 0.2997254729270935
Batch 37/64 loss: 0.2941686511039734
Batch 38/64 loss: 0.3012726306915283
Batch 39/64 loss: 0.3043326139450073
Batch 40/64 loss: 0.30188149213790894
Batch 41/64 loss: 0.28795838356018066
Batch 42/64 loss: 0.29765886068344116
Batch 43/64 loss: 0.30048781633377075
Batch 44/64 loss: 0.2939644455909729
Batch 45/64 loss: 0.2967160940170288
Batch 46/64 loss: 0.2973306179046631
Batch 47/64 loss: 0.2980954647064209
Batch 48/64 loss: 0.2993454933166504
Batch 49/64 loss: 0.2967393398284912
Batch 50/64 loss: 0.30096977949142456
Batch 51/64 loss: 0.2922694683074951
Batch 52/64 loss: 0.30376046895980835
Batch 53/64 loss: 0.2948174476623535
Batch 54/64 loss: 0.2980837821960449
Batch 55/64 loss: 0.29902350902557373
Batch 56/64 loss: 0.30004072189331055
Batch 57/64 loss: 0.30755501985549927
Batch 58/64 loss: 0.3017146587371826
Batch 59/64 loss: 0.2985197901725769
Batch 60/64 loss: 0.29802024364471436
Batch 61/64 loss: 0.30436980724334717
Batch 62/64 loss: 0.29925811290740967
Batch 63/64 loss: 0.30116790533065796
Batch 64/64 loss: 0.29640138149261475
Epoch 189  Train loss: 0.2986761013666789  Val loss: 0.3166529972528674
Saving best model, epoch: 189
Epoch 190
-------------------------------
Batch 1/64 loss: 0.2992327809333801
Batch 2/64 loss: 0.300148606300354
Batch 3/64 loss: 0.29791176319122314
Batch 4/64 loss: 0.29849040508270264
Batch 5/64 loss: 0.30251234769821167
Batch 6/64 loss: 0.2967817187309265
Batch 7/64 loss: 0.3036677837371826
Batch 8/64 loss: 0.29968714714050293
Batch 9/64 loss: 0.30055832862854004
Batch 10/64 loss: 0.29405826330184937
Batch 11/64 loss: 0.29782015085220337
Batch 12/64 loss: 0.3004124164581299
Batch 13/64 loss: 0.2968798875808716
Batch 14/64 loss: 0.29891014099121094
Batch 15/64 loss: 0.30359339714050293
Batch 16/64 loss: 0.2932182550430298
Batch 17/64 loss: 0.30287694931030273
Batch 18/64 loss: 0.29760676622390747
Batch 19/64 loss: 0.30050361156463623
Batch 20/64 loss: 0.298370361328125
Batch 21/64 loss: 0.2957836389541626
Batch 22/64 loss: 0.29697710275650024
Batch 23/64 loss: 0.29249346256256104
Batch 24/64 loss: 0.3072035312652588
Batch 25/64 loss: 0.297038197517395
Batch 26/64 loss: 0.3041183352470398
Batch 27/64 loss: 0.3000043034553528
Batch 28/64 loss: 0.29601919651031494
Batch 29/64 loss: 0.3013007640838623
Batch 30/64 loss: 0.30141448974609375
Batch 31/64 loss: 0.29628074169158936
Batch 32/64 loss: 0.2993108034133911
Batch 33/64 loss: 0.3015429973602295
Batch 34/64 loss: 0.29329848289489746
Batch 35/64 loss: 0.29974818229675293
Batch 36/64 loss: 0.2997630834579468
Batch 37/64 loss: 0.29353857040405273
Batch 38/64 loss: 0.2984459400177002
Batch 39/64 loss: 0.294189989566803
Batch 40/64 loss: 0.3012200593948364
Batch 41/64 loss: 0.2977374792098999
Batch 42/64 loss: 0.2968951463699341
Batch 43/64 loss: 0.3004014492034912
Batch 44/64 loss: 0.29270684719085693
Batch 45/64 loss: 0.29573261737823486
Batch 46/64 loss: 0.29549020528793335
Batch 47/64 loss: 0.2972812056541443
Batch 48/64 loss: 0.2886650562286377
Batch 49/64 loss: 0.29996371269226074
Batch 50/64 loss: 0.2910630702972412
Batch 51/64 loss: 0.29980576038360596
Batch 52/64 loss: 0.3085726499557495
Batch 53/64 loss: 0.30296754837036133
Batch 54/64 loss: 0.2978591322898865
Batch 55/64 loss: 0.30227476358413696
Batch 56/64 loss: 0.29910027980804443
Batch 57/64 loss: 0.29745614528656006
Batch 58/64 loss: 0.29587793350219727
Batch 59/64 loss: 0.2951533794403076
Batch 60/64 loss: 0.3016507625579834
Batch 61/64 loss: 0.30640125274658203
Batch 62/64 loss: 0.2986830472946167
Batch 63/64 loss: 0.3040822744369507
Batch 64/64 loss: 0.30163151025772095
Epoch 190  Train loss: 0.29874475773643044  Val loss: 0.31729209914649886
Epoch 191
-------------------------------
Batch 1/64 loss: 0.3004723787307739
Batch 2/64 loss: 0.2939267158508301
Batch 3/64 loss: 0.30242347717285156
Batch 4/64 loss: 0.3010978698730469
Batch 5/64 loss: 0.3027045726776123
Batch 6/64 loss: 0.30003446340560913
Batch 7/64 loss: 0.29912281036376953
Batch 8/64 loss: 0.30096209049224854
Batch 9/64 loss: 0.30267590284347534
Batch 10/64 loss: 0.3012903928756714
Batch 11/64 loss: 0.29801368713378906
Batch 12/64 loss: 0.30142903327941895
Batch 13/64 loss: 0.29691267013549805
Batch 14/64 loss: 0.295626163482666
Batch 15/64 loss: 0.2955571413040161
Batch 16/64 loss: 0.2972768545150757
Batch 17/64 loss: 0.28711414337158203
Batch 18/64 loss: 0.2950456142425537
Batch 19/64 loss: 0.2991183400154114
Batch 20/64 loss: 0.3005417585372925
Batch 21/64 loss: 0.30271703004837036
Batch 22/64 loss: 0.2980923652648926
Batch 23/64 loss: 0.3060086965560913
Batch 24/64 loss: 0.2955707311630249
Batch 25/64 loss: 0.2935665249824524
Batch 26/64 loss: 0.3015650510787964
Batch 27/64 loss: 0.30334317684173584
Batch 28/64 loss: 0.2959133982658386
Batch 29/64 loss: 0.30374228954315186
Batch 30/64 loss: 0.2965366840362549
Batch 31/64 loss: 0.29845184087753296
Batch 32/64 loss: 0.2946351170539856
Batch 33/64 loss: 0.30162519216537476
Batch 34/64 loss: 0.29909592866897583
Batch 35/64 loss: 0.29963982105255127
Batch 36/64 loss: 0.30239367485046387
Batch 37/64 loss: 0.29305630922317505
Batch 38/64 loss: 0.3038526773452759
Batch 39/64 loss: 0.2921714186668396
Batch 40/64 loss: 0.2922070622444153
Batch 41/64 loss: 0.2965570092201233
Batch 42/64 loss: 0.30673474073410034
Batch 43/64 loss: 0.2863656282424927
Batch 44/64 loss: 0.3013875484466553
Batch 45/64 loss: 0.2949184775352478
Batch 46/64 loss: 0.2919067144393921
Batch 47/64 loss: 0.2907496690750122
Batch 48/64 loss: 0.2975195646286011
Batch 49/64 loss: 0.30358362197875977
Batch 50/64 loss: 0.29582059383392334
Batch 51/64 loss: 0.2995738983154297
Batch 52/64 loss: 0.30107295513153076
Batch 53/64 loss: 0.2898365259170532
Batch 54/64 loss: 0.30316370725631714
Batch 55/64 loss: 0.2982092499732971
Batch 56/64 loss: 0.29763519763946533
Batch 57/64 loss: 0.2964155673980713
Batch 58/64 loss: 0.30236440896987915
Batch 59/64 loss: 0.2982129454612732
Batch 60/64 loss: 0.29400086402893066
Batch 61/64 loss: 0.30741584300994873
Batch 62/64 loss: 0.29652178287506104
Batch 63/64 loss: 0.29992246627807617
Batch 64/64 loss: 0.2945042848587036
Epoch 191  Train loss: 0.2982948747335696  Val loss: 0.3172291105555505
Epoch 192
-------------------------------
Batch 1/64 loss: 0.2974257469177246
Batch 2/64 loss: 0.3003302216529846
Batch 3/64 loss: 0.2948594093322754
Batch 4/64 loss: 0.30383843183517456
Batch 5/64 loss: 0.29749011993408203
Batch 6/64 loss: 0.29055482149124146
Batch 7/64 loss: 0.29759883880615234
Batch 8/64 loss: 0.296670138835907
Batch 9/64 loss: 0.2961006760597229
Batch 10/64 loss: 0.29624778032302856
Batch 11/64 loss: 0.30008870363235474
Batch 12/64 loss: 0.30335313081741333
Batch 13/64 loss: 0.29933619499206543
Batch 14/64 loss: 0.2971614599227905
Batch 15/64 loss: 0.29412364959716797
Batch 16/64 loss: 0.2962269186973572
Batch 17/64 loss: 0.30224084854125977
Batch 18/64 loss: 0.2883387804031372
Batch 19/64 loss: 0.3068159818649292
Batch 20/64 loss: 0.3028566837310791
Batch 21/64 loss: 0.2973520755767822
Batch 22/64 loss: 0.2930680513381958
Batch 23/64 loss: 0.2958105802536011
Batch 24/64 loss: 0.3017362356185913
Batch 25/64 loss: 0.3037792444229126
Batch 26/64 loss: 0.29976677894592285
Batch 27/64 loss: 0.2983577847480774
Batch 28/64 loss: 0.2922550439834595
Batch 29/64 loss: 0.2986573576927185
Batch 30/64 loss: 0.2946576476097107
Batch 31/64 loss: 0.291262686252594
Batch 32/64 loss: 0.2966959476470947
Batch 33/64 loss: 0.3018496036529541
Batch 34/64 loss: 0.29386693239212036
Batch 35/64 loss: 0.306856632232666
Batch 36/64 loss: 0.29646170139312744
Batch 37/64 loss: 0.3033798336982727
Batch 38/64 loss: 0.2965205907821655
Batch 39/64 loss: 0.29852867126464844
Batch 40/64 loss: 0.2976316213607788
Batch 41/64 loss: 0.3092731237411499
Batch 42/64 loss: 0.302493691444397
Batch 43/64 loss: 0.3038710951805115
Batch 44/64 loss: 0.30101650953292847
Batch 45/64 loss: 0.30173707008361816
Batch 46/64 loss: 0.2946655750274658
Batch 47/64 loss: 0.29644978046417236
Batch 48/64 loss: 0.29845476150512695
Batch 49/64 loss: 0.2915446162223816
Batch 50/64 loss: 0.2964550852775574
Batch 51/64 loss: 0.2975980043411255
Batch 52/64 loss: 0.28943145275115967
Batch 53/64 loss: 0.2982308864593506
Batch 54/64 loss: 0.3023863434791565
Batch 55/64 loss: 0.29572057723999023
Batch 56/64 loss: 0.2951585054397583
Batch 57/64 loss: 0.29962158203125
Batch 58/64 loss: 0.29822874069213867
Batch 59/64 loss: 0.3011901378631592
Batch 60/64 loss: 0.2951359748840332
Batch 61/64 loss: 0.3020230531692505
Batch 62/64 loss: 0.3013406991958618
Batch 63/64 loss: 0.2954763174057007
Batch 64/64 loss: 0.2950946092605591
Epoch 192  Train loss: 0.29818004860597497  Val loss: 0.31735830905101553
Epoch 193
-------------------------------
Batch 1/64 loss: 0.2995173931121826
Batch 2/64 loss: 0.2896996736526489
Batch 3/64 loss: 0.2926522493362427
Batch 4/64 loss: 0.29912251234054565
Batch 5/64 loss: 0.3007802367210388
Batch 6/64 loss: 0.3031339645385742
Batch 7/64 loss: 0.29523199796676636
Batch 8/64 loss: 0.29347968101501465
Batch 9/64 loss: 0.2940121293067932
Batch 10/64 loss: 0.29939985275268555
Batch 11/64 loss: 0.3023592233657837
Batch 12/64 loss: 0.2962902784347534
Batch 13/64 loss: 0.29854774475097656
Batch 14/64 loss: 0.29083549976348877
Batch 15/64 loss: 0.30207711458206177
Batch 16/64 loss: 0.3027452230453491
Batch 17/64 loss: 0.2984654903411865
Batch 18/64 loss: 0.30274176597595215
Batch 19/64 loss: 0.30443328619003296
Batch 20/64 loss: 0.30305415391921997
Batch 21/64 loss: 0.29620325565338135
Batch 22/64 loss: 0.29336774349212646
Batch 23/64 loss: 0.30087000131607056
Batch 24/64 loss: 0.3028276562690735
Batch 25/64 loss: 0.28959739208221436
Batch 26/64 loss: 0.3034858703613281
Batch 27/64 loss: 0.29430413246154785
Batch 28/64 loss: 0.301044762134552
Batch 29/64 loss: 0.2957388758659363
Batch 30/64 loss: 0.3022283911705017
Batch 31/64 loss: 0.30147987604141235
Batch 32/64 loss: 0.30122190713882446
Batch 33/64 loss: 0.29893308877944946
Batch 34/64 loss: 0.2930447459220886
Batch 35/64 loss: 0.29417121410369873
Batch 36/64 loss: 0.2950085997581482
Batch 37/64 loss: 0.2968025207519531
Batch 38/64 loss: 0.29478830099105835
Batch 39/64 loss: 0.2945476770401001
Batch 40/64 loss: 0.3016781806945801
Batch 41/64 loss: 0.2962160110473633
Batch 42/64 loss: 0.3005441427230835
Batch 43/64 loss: 0.30174511671066284
Batch 44/64 loss: 0.2959311604499817
Batch 45/64 loss: 0.29391682147979736
Batch 46/64 loss: 0.2961043119430542
Batch 47/64 loss: 0.2999303340911865
Batch 48/64 loss: 0.2984471917152405
Batch 49/64 loss: 0.2976952791213989
Batch 50/64 loss: 0.29896581172943115
Batch 51/64 loss: 0.2973707318305969
Batch 52/64 loss: 0.295071005821228
Batch 53/64 loss: 0.2967805862426758
Batch 54/64 loss: 0.3014816641807556
Batch 55/64 loss: 0.301352858543396
Batch 56/64 loss: 0.30000025033950806
Batch 57/64 loss: 0.2961825728416443
Batch 58/64 loss: 0.3078320026397705
Batch 59/64 loss: 0.29052674770355225
Batch 60/64 loss: 0.2941325306892395
Batch 61/64 loss: 0.2985076308250427
Batch 62/64 loss: 0.2929531931877136
Batch 63/64 loss: 0.29872846603393555
Batch 64/64 loss: 0.29532164335250854
Epoch 193  Train loss: 0.297911079490886  Val loss: 0.3163714031992909
Saving best model, epoch: 193
Epoch 194
-------------------------------
Batch 1/64 loss: 0.3030804395675659
Batch 2/64 loss: 0.3009852170944214
Batch 3/64 loss: 0.29474949836730957
Batch 4/64 loss: 0.2979123592376709
Batch 5/64 loss: 0.29379820823669434
Batch 6/64 loss: 0.2906917333602905
Batch 7/64 loss: 0.29261863231658936
Batch 8/64 loss: 0.2942739725112915
Batch 9/64 loss: 0.30739688873291016
Batch 10/64 loss: 0.29843074083328247
Batch 11/64 loss: 0.2851085662841797
Batch 12/64 loss: 0.3014334440231323
Batch 13/64 loss: 0.29613351821899414
Batch 14/64 loss: 0.2932390570640564
Batch 15/64 loss: 0.30093324184417725
Batch 16/64 loss: 0.3035653233528137
Batch 17/64 loss: 0.2927708625793457
Batch 18/64 loss: 0.29840564727783203
Batch 19/64 loss: 0.2969585061073303
Batch 20/64 loss: 0.3052787780761719
Batch 21/64 loss: 0.298511803150177
Batch 22/64 loss: 0.29703569412231445
Batch 23/64 loss: 0.2955150008201599
Batch 24/64 loss: 0.29307347536087036
Batch 25/64 loss: 0.29978257417678833
Batch 26/64 loss: 0.2996561527252197
Batch 27/64 loss: 0.2994018793106079
Batch 28/64 loss: 0.28950220346450806
Batch 29/64 loss: 0.2970009446144104
Batch 30/64 loss: 0.29531341791152954
Batch 31/64 loss: 0.29720598459243774
Batch 32/64 loss: 0.3010752201080322
Batch 33/64 loss: 0.2915974259376526
Batch 34/64 loss: 0.30225110054016113
Batch 35/64 loss: 0.29948222637176514
Batch 36/64 loss: 0.2978447675704956
Batch 37/64 loss: 0.30667078495025635
Batch 38/64 loss: 0.2993513345718384
Batch 39/64 loss: 0.29842865467071533
Batch 40/64 loss: 0.2959141731262207
Batch 41/64 loss: 0.30037540197372437
Batch 42/64 loss: 0.294119656085968
Batch 43/64 loss: 0.29730427265167236
Batch 44/64 loss: 0.2983086109161377
Batch 45/64 loss: 0.3017483949661255
Batch 46/64 loss: 0.3016781806945801
Batch 47/64 loss: 0.28752732276916504
Batch 48/64 loss: 0.29998183250427246
Batch 49/64 loss: 0.286946177482605
Batch 50/64 loss: 0.2986563444137573
Batch 51/64 loss: 0.29634225368499756
Batch 52/64 loss: 0.2992842197418213
Batch 53/64 loss: 0.2934298515319824
Batch 54/64 loss: 0.2950019836425781
Batch 55/64 loss: 0.2965053915977478
Batch 56/64 loss: 0.2991073727607727
Batch 57/64 loss: 0.29590415954589844
Batch 58/64 loss: 0.2979717254638672
Batch 59/64 loss: 0.29400908946990967
Batch 60/64 loss: 0.29329776763916016
Batch 61/64 loss: 0.29901158809661865
Batch 62/64 loss: 0.2997095584869385
Batch 63/64 loss: 0.2975112199783325
Batch 64/64 loss: 0.30288898944854736
Epoch 194  Train loss: 0.2973063305312512  Val loss: 0.3159107324184011
Saving best model, epoch: 194
Epoch 195
-------------------------------
Batch 1/64 loss: 0.29952991008758545
Batch 2/64 loss: 0.29755735397338867
Batch 3/64 loss: 0.2941105365753174
Batch 4/64 loss: 0.29848146438598633
Batch 5/64 loss: 0.29489028453826904
Batch 6/64 loss: 0.2949535846710205
Batch 7/64 loss: 0.2955065965652466
Batch 8/64 loss: 0.2904760241508484
Batch 9/64 loss: 0.2978847622871399
Batch 10/64 loss: 0.2956047058105469
Batch 11/64 loss: 0.29745519161224365
Batch 12/64 loss: 0.29849737882614136
Batch 13/64 loss: 0.29016822576522827
Batch 14/64 loss: 0.29934805631637573
Batch 15/64 loss: 0.29777997732162476
Batch 16/64 loss: 0.2923351526260376
Batch 17/64 loss: 0.29368269443511963
Batch 18/64 loss: 0.301519513130188
Batch 19/64 loss: 0.2962905168533325
Batch 20/64 loss: 0.30268394947052
Batch 21/64 loss: 0.28878509998321533
Batch 22/64 loss: 0.2916210889816284
Batch 23/64 loss: 0.30408358573913574
Batch 24/64 loss: 0.2942149043083191
Batch 25/64 loss: 0.302007794380188
Batch 26/64 loss: 0.29953765869140625
Batch 27/64 loss: 0.3005359172821045
Batch 28/64 loss: 0.3016902804374695
Batch 29/64 loss: 0.2935464382171631
Batch 30/64 loss: 0.29665637016296387
Batch 31/64 loss: 0.30137312412261963
Batch 32/64 loss: 0.29285240173339844
Batch 33/64 loss: 0.2990915775299072
Batch 34/64 loss: 0.3089776635169983
Batch 35/64 loss: 0.29653602838516235
Batch 36/64 loss: 0.3003920316696167
Batch 37/64 loss: 0.29469460248947144
Batch 38/64 loss: 0.30223244428634644
Batch 39/64 loss: 0.29643547534942627
Batch 40/64 loss: 0.30097436904907227
Batch 41/64 loss: 0.30130988359451294
Batch 42/64 loss: 0.2966678738594055
Batch 43/64 loss: 0.29883718490600586
Batch 44/64 loss: 0.29607248306274414
Batch 45/64 loss: 0.29725420475006104
Batch 46/64 loss: 0.2960667610168457
Batch 47/64 loss: 0.29765379428863525
Batch 48/64 loss: 0.30328601598739624
Batch 49/64 loss: 0.3042551279067993
Batch 50/64 loss: 0.3072711229324341
Batch 51/64 loss: 0.3042839765548706
Batch 52/64 loss: 0.2969260811805725
Batch 53/64 loss: 0.298128604888916
Batch 54/64 loss: 0.3029443025588989
Batch 55/64 loss: 0.2972961664199829
Batch 56/64 loss: 0.29176008701324463
Batch 57/64 loss: 0.298961877822876
Batch 58/64 loss: 0.29446935653686523
Batch 59/64 loss: 0.2969571352005005
Batch 60/64 loss: 0.2932538390159607
Batch 61/64 loss: 0.3032717704772949
Batch 62/64 loss: 0.29580938816070557
Batch 63/64 loss: 0.2961529493331909
Batch 64/64 loss: 0.2904388904571533
Epoch 195  Train loss: 0.29775237476124483  Val loss: 0.31601715046925233
Epoch 196
-------------------------------
Batch 1/64 loss: 0.2974920868873596
Batch 2/64 loss: 0.2867370843887329
Batch 3/64 loss: 0.2929641008377075
Batch 4/64 loss: 0.2971881628036499
Batch 5/64 loss: 0.2936665415763855
Batch 6/64 loss: 0.3031100630760193
Batch 7/64 loss: 0.3006526827812195
Batch 8/64 loss: 0.29256391525268555
Batch 9/64 loss: 0.2945138216018677
Batch 10/64 loss: 0.29985857009887695
Batch 11/64 loss: 0.29922664165496826
Batch 12/64 loss: 0.2951083183288574
Batch 13/64 loss: 0.2958486080169678
Batch 14/64 loss: 0.29212749004364014
Batch 15/64 loss: 0.2958158254623413
Batch 16/64 loss: 0.2971668243408203
Batch 17/64 loss: 0.2967238426208496
Batch 18/64 loss: 0.2943437099456787
Batch 19/64 loss: 0.3019539713859558
Batch 20/64 loss: 0.30739372968673706
Batch 21/64 loss: 0.30235230922698975
Batch 22/64 loss: 0.29876482486724854
Batch 23/64 loss: 0.2977856993675232
Batch 24/64 loss: 0.29157555103302
Batch 25/64 loss: 0.30360013246536255
Batch 26/64 loss: 0.29599475860595703
Batch 27/64 loss: 0.29855477809906006
Batch 28/64 loss: 0.2917202115058899
Batch 29/64 loss: 0.304956316947937
Batch 30/64 loss: 0.29443883895874023
Batch 31/64 loss: 0.29780322313308716
Batch 32/64 loss: 0.30519789457321167
Batch 33/64 loss: 0.29293423891067505
Batch 34/64 loss: 0.29737043380737305
Batch 35/64 loss: 0.29376542568206787
Batch 36/64 loss: 0.300156831741333
Batch 37/64 loss: 0.3017681837081909
Batch 38/64 loss: 0.2943928837776184
Batch 39/64 loss: 0.294614315032959
Batch 40/64 loss: 0.29412609338760376
Batch 41/64 loss: 0.2965942621231079
Batch 42/64 loss: 0.2978161573410034
Batch 43/64 loss: 0.304013729095459
Batch 44/64 loss: 0.2998087406158447
Batch 45/64 loss: 0.3001466989517212
Batch 46/64 loss: 0.2950470447540283
Batch 47/64 loss: 0.29600226879119873
Batch 48/64 loss: 0.29933786392211914
Batch 49/64 loss: 0.30082613229751587
Batch 50/64 loss: 0.2992703914642334
Batch 51/64 loss: 0.29065144062042236
Batch 52/64 loss: 0.3023384213447571
Batch 53/64 loss: 0.29346024990081787
Batch 54/64 loss: 0.30193573236465454
Batch 55/64 loss: 0.291901171207428
Batch 56/64 loss: 0.2986288070678711
Batch 57/64 loss: 0.3009653687477112
Batch 58/64 loss: 0.2997938394546509
Batch 59/64 loss: 0.30175554752349854
Batch 60/64 loss: 0.30281388759613037
Batch 61/64 loss: 0.29050374031066895
Batch 62/64 loss: 0.30116260051727295
Batch 63/64 loss: 0.29104334115982056
Batch 64/64 loss: 0.29615139961242676
Epoch 196  Train loss: 0.2974785870196773  Val loss: 0.3162457230164833
Epoch 197
-------------------------------
Batch 1/64 loss: 0.2977287769317627
Batch 2/64 loss: 0.2977740168571472
Batch 3/64 loss: 0.29248571395874023
Batch 4/64 loss: 0.29328423738479614
Batch 5/64 loss: 0.29315221309661865
Batch 6/64 loss: 0.2964355945587158
Batch 7/64 loss: 0.29425764083862305
Batch 8/64 loss: 0.2958296537399292
Batch 9/64 loss: 0.29974818229675293
Batch 10/64 loss: 0.2923680543899536
Batch 11/64 loss: 0.29083502292633057
Batch 12/64 loss: 0.294910192489624
Batch 13/64 loss: 0.2956879734992981
Batch 14/64 loss: 0.29168277978897095
Batch 15/64 loss: 0.29992222785949707
Batch 16/64 loss: 0.2898433804512024
Batch 17/64 loss: 0.29835474491119385
Batch 18/64 loss: 0.29154765605926514
Batch 19/64 loss: 0.2932136058807373
Batch 20/64 loss: 0.29959213733673096
Batch 21/64 loss: 0.29643678665161133
Batch 22/64 loss: 0.30395424365997314
Batch 23/64 loss: 0.2962161898612976
Batch 24/64 loss: 0.30216264724731445
Batch 25/64 loss: 0.2938659191131592
Batch 26/64 loss: 0.29479551315307617
Batch 27/64 loss: 0.29279541969299316
Batch 28/64 loss: 0.29544228315353394
Batch 29/64 loss: 0.29935210943222046
Batch 30/64 loss: 0.29829227924346924
Batch 31/64 loss: 0.2944236993789673
Batch 32/64 loss: 0.30087804794311523
Batch 33/64 loss: 0.2949639558792114
Batch 34/64 loss: 0.2911914587020874
Batch 35/64 loss: 0.29222726821899414
Batch 36/64 loss: 0.2985929250717163
Batch 37/64 loss: 0.28823399543762207
Batch 38/64 loss: 0.30385875701904297
Batch 39/64 loss: 0.30422085523605347
Batch 40/64 loss: 0.2982252240180969
Batch 41/64 loss: 0.293255090713501
Batch 42/64 loss: 0.3013750910758972
Batch 43/64 loss: 0.29534482955932617
Batch 44/64 loss: 0.30074894428253174
Batch 45/64 loss: 0.29416966438293457
Batch 46/64 loss: 0.3013409376144409
Batch 47/64 loss: 0.2991446256637573
Batch 48/64 loss: 0.2957721948623657
Batch 49/64 loss: 0.30445027351379395
Batch 50/64 loss: 0.3021389842033386
Batch 51/64 loss: 0.3033289909362793
Batch 52/64 loss: 0.29556143283843994
Batch 53/64 loss: 0.3023858070373535
Batch 54/64 loss: 0.2969013452529907
Batch 55/64 loss: 0.29654818773269653
Batch 56/64 loss: 0.2952902913093567
Batch 57/64 loss: 0.310260534286499
Batch 58/64 loss: 0.2941233515739441
Batch 59/64 loss: 0.2998771667480469
Batch 60/64 loss: 0.30313360691070557
Batch 61/64 loss: 0.3074050545692444
Batch 62/64 loss: 0.2946343421936035
Batch 63/64 loss: 0.2917906641960144
Batch 64/64 loss: 0.30039888620376587
Epoch 197  Train loss: 0.297146101325166  Val loss: 0.31696403722992467
Epoch 198
-------------------------------
Batch 1/64 loss: 0.29748833179473877
Batch 2/64 loss: 0.30099064111709595
Batch 3/64 loss: 0.2973514795303345
Batch 4/64 loss: 0.29150915145874023
Batch 5/64 loss: 0.2943023443222046
Batch 6/64 loss: 0.2909061312675476
Batch 7/64 loss: 0.304385244846344
Batch 8/64 loss: 0.29250961542129517
Batch 9/64 loss: 0.29992103576660156
Batch 10/64 loss: 0.2989533543586731
Batch 11/64 loss: 0.2913742661476135
Batch 12/64 loss: 0.2932330369949341
Batch 13/64 loss: 0.2936793565750122
Batch 14/64 loss: 0.30238407850265503
Batch 15/64 loss: 0.2958937883377075
Batch 16/64 loss: 0.3075685501098633
Batch 17/64 loss: 0.29047560691833496
Batch 18/64 loss: 0.2966797351837158
Batch 19/64 loss: 0.2941417694091797
Batch 20/64 loss: 0.2935619354248047
Batch 21/64 loss: 0.2947697043418884
Batch 22/64 loss: 0.2989710569381714
Batch 23/64 loss: 0.2949896454811096
Batch 24/64 loss: 0.29255402088165283
Batch 25/64 loss: 0.3031994700431824
Batch 26/64 loss: 0.29575204849243164
Batch 27/64 loss: 0.2978661060333252
Batch 28/64 loss: 0.2954637408256531
Batch 29/64 loss: 0.3077179193496704
Batch 30/64 loss: 0.30219101905822754
Batch 31/64 loss: 0.29428285360336304
Batch 32/64 loss: 0.2993115186691284
Batch 33/64 loss: 0.300315260887146
Batch 34/64 loss: 0.2986633777618408
Batch 35/64 loss: 0.3030824661254883
Batch 36/64 loss: 0.29495835304260254
Batch 37/64 loss: 0.2948130965232849
Batch 38/64 loss: 0.3054255247116089
Batch 39/64 loss: 0.29773521423339844
Batch 40/64 loss: 0.29185885190963745
Batch 41/64 loss: 0.30375295877456665
Batch 42/64 loss: 0.2991452217102051
Batch 43/64 loss: 0.2979816198348999
Batch 44/64 loss: 0.2943694591522217
Batch 45/64 loss: 0.29897642135620117
Batch 46/64 loss: 0.29867660999298096
Batch 47/64 loss: 0.2924611568450928
Batch 48/64 loss: 0.2956932783126831
Batch 49/64 loss: 0.2976452112197876
Batch 50/64 loss: 0.3009554147720337
Batch 51/64 loss: 0.2952522039413452
Batch 52/64 loss: 0.2945173978805542
Batch 53/64 loss: 0.2995545268058777
Batch 54/64 loss: 0.2987669110298157
Batch 55/64 loss: 0.2947748899459839
Batch 56/64 loss: 0.2921978235244751
Batch 57/64 loss: 0.2996906042098999
Batch 58/64 loss: 0.2953760623931885
Batch 59/64 loss: 0.295291543006897
Batch 60/64 loss: 0.2977970838546753
Batch 61/64 loss: 0.30106043815612793
Batch 62/64 loss: 0.2911919355392456
Batch 63/64 loss: 0.30124735832214355
Batch 64/64 loss: 0.3070324659347534
Epoch 198  Train loss: 0.2973785283518772  Val loss: 0.3164718366160835
Epoch 199
-------------------------------
Batch 1/64 loss: 0.2962350845336914
Batch 2/64 loss: 0.3006734848022461
Batch 3/64 loss: 0.2984546422958374
Batch 4/64 loss: 0.2912787199020386
Batch 5/64 loss: 0.286950945854187
Batch 6/64 loss: 0.29556751251220703
Batch 7/64 loss: 0.29679161310195923
Batch 8/64 loss: 0.2955514192581177
Batch 9/64 loss: 0.2991340160369873
Batch 10/64 loss: 0.2893108129501343
Batch 11/64 loss: 0.29310452938079834
Batch 12/64 loss: 0.29390740394592285
Batch 13/64 loss: 0.28952062129974365
Batch 14/64 loss: 0.30360710620880127
Batch 15/64 loss: 0.29255354404449463
Batch 16/64 loss: 0.29601752758026123
Batch 17/64 loss: 0.2995368242263794
Batch 18/64 loss: 0.2926177978515625
Batch 19/64 loss: 0.2923421859741211
Batch 20/64 loss: 0.30060601234436035
Batch 21/64 loss: 0.2971859574317932
Batch 22/64 loss: 0.29663777351379395
Batch 23/64 loss: 0.29471033811569214
Batch 24/64 loss: 0.2922569513320923
Batch 25/64 loss: 0.29792916774749756
Batch 26/64 loss: 0.29234230518341064
Batch 27/64 loss: 0.298944354057312
Batch 28/64 loss: 0.2978667616844177
Batch 29/64 loss: 0.3014710545539856
Batch 30/64 loss: 0.2965000867843628
Batch 31/64 loss: 0.2978929281234741
Batch 32/64 loss: 0.2917691469192505
Batch 33/64 loss: 0.2927201986312866
Batch 34/64 loss: 0.2969163656234741
Batch 35/64 loss: 0.2970982789993286
Batch 36/64 loss: 0.2969244718551636
Batch 37/64 loss: 0.297782838344574
Batch 38/64 loss: 0.29480212926864624
Batch 39/64 loss: 0.29670995473861694
Batch 40/64 loss: 0.29193115234375
Batch 41/64 loss: 0.2906882166862488
Batch 42/64 loss: 0.3005353808403015
Batch 43/64 loss: 0.2948188781738281
Batch 44/64 loss: 0.2961428165435791
Batch 45/64 loss: 0.2974323034286499
Batch 46/64 loss: 0.2969035506248474
Batch 47/64 loss: 0.29559326171875
Batch 48/64 loss: 0.2908030152320862
Batch 49/64 loss: 0.30010223388671875
Batch 50/64 loss: 0.3038409948348999
Batch 51/64 loss: 0.3010002374649048
Batch 52/64 loss: 0.2946304678916931
Batch 53/64 loss: 0.289611279964447
Batch 54/64 loss: 0.29213225841522217
Batch 55/64 loss: 0.30363166332244873
Batch 56/64 loss: 0.3035762310028076
Batch 57/64 loss: 0.2972870469093323
Batch 58/64 loss: 0.30786848068237305
Batch 59/64 loss: 0.2914295196533203
Batch 60/64 loss: 0.2923441529273987
Batch 61/64 loss: 0.30243897438049316
Batch 62/64 loss: 0.2994893789291382
Batch 63/64 loss: 0.2955072522163391
Batch 64/64 loss: 0.2969546914100647
Epoch 199  Train loss: 0.29623023739048077  Val loss: 0.31705422827468294
Epoch 200
-------------------------------
Batch 1/64 loss: 0.292871356010437
Batch 2/64 loss: 0.29659008979797363
Batch 3/64 loss: 0.2879810333251953
Batch 4/64 loss: 0.2935250401496887
Batch 5/64 loss: 0.2971758246421814
Batch 6/64 loss: 0.300703227519989
Batch 7/64 loss: 0.29447275400161743
Batch 8/64 loss: 0.29785382747650146
Batch 9/64 loss: 0.29544365406036377
Batch 10/64 loss: 0.2935664653778076
Batch 11/64 loss: 0.2981342077255249
Batch 12/64 loss: 0.28934091329574585
Batch 13/64 loss: 0.29490017890930176
Batch 14/64 loss: 0.302539587020874
Batch 15/64 loss: 0.2953214645385742
Batch 16/64 loss: 0.2991739511489868
Batch 17/64 loss: 0.2942090630531311
Batch 18/64 loss: 0.29695773124694824
Batch 19/64 loss: 0.30150824785232544
Batch 20/64 loss: 0.2996501922607422
Batch 21/64 loss: 0.2909426689147949
Batch 22/64 loss: 0.2985251545906067
Batch 23/64 loss: 0.297757625579834
Batch 24/64 loss: 0.2994955778121948
Batch 25/64 loss: 0.3022880554199219
Batch 26/64 loss: 0.295074462890625
Batch 27/64 loss: 0.29967665672302246
Batch 28/64 loss: 0.2996433973312378
Batch 29/64 loss: 0.30546116828918457
Batch 30/64 loss: 0.30056124925613403
Batch 31/64 loss: 0.29995834827423096
Batch 32/64 loss: 0.3026491403579712
Batch 33/64 loss: 0.2942758798599243
Batch 34/64 loss: 0.29651498794555664
Batch 35/64 loss: 0.29692673683166504
Batch 36/64 loss: 0.2994774580001831
Batch 37/64 loss: 0.2970355749130249
Batch 38/64 loss: 0.2979007959365845
Batch 39/64 loss: 0.29985976219177246
Batch 40/64 loss: 0.30260515213012695
Batch 41/64 loss: 0.29124629497528076
Batch 42/64 loss: 0.30003559589385986
Batch 43/64 loss: 0.29628342390060425
Batch 44/64 loss: 0.29578542709350586
Batch 45/64 loss: 0.29643070697784424
Batch 46/64 loss: 0.2936972379684448
Batch 47/64 loss: 0.29495590925216675
Batch 48/64 loss: 0.29214930534362793
Batch 49/64 loss: 0.292757511138916
Batch 50/64 loss: 0.294130802154541
Batch 51/64 loss: 0.2976030707359314
Batch 52/64 loss: 0.2922314405441284
Batch 53/64 loss: 0.29348868131637573
Batch 54/64 loss: 0.294397234916687
Batch 55/64 loss: 0.29739516973495483
Batch 56/64 loss: 0.29446423053741455
Batch 57/64 loss: 0.29737401008605957
Batch 58/64 loss: 0.3048630952835083
Batch 59/64 loss: 0.29045403003692627
Batch 60/64 loss: 0.2918088436126709
Batch 61/64 loss: 0.3008030652999878
Batch 62/64 loss: 0.29732728004455566
Batch 63/64 loss: 0.2970731258392334
Batch 64/64 loss: 0.2920926809310913
Epoch 200  Train loss: 0.2966960575066361  Val loss: 0.31600130444130126
Epoch 201
-------------------------------
Batch 1/64 loss: 0.2971738576889038
Batch 2/64 loss: 0.2966122627258301
Batch 3/64 loss: 0.2953758239746094
Batch 4/64 loss: 0.29318130016326904
Batch 5/64 loss: 0.29234540462493896
Batch 6/64 loss: 0.2957221269607544
Batch 7/64 loss: 0.29331040382385254
Batch 8/64 loss: 0.29966264963150024
Batch 9/64 loss: 0.2890423536300659
Batch 10/64 loss: 0.304640531539917
Batch 11/64 loss: 0.29233336448669434
Batch 12/64 loss: 0.3002920150756836
Batch 13/64 loss: 0.2947368621826172
Batch 14/64 loss: 0.30127817392349243
Batch 15/64 loss: 0.29009366035461426
Batch 16/64 loss: 0.2966918349266052
Batch 17/64 loss: 0.29972898960113525
Batch 18/64 loss: 0.3012526035308838
Batch 19/64 loss: 0.2927262783050537
Batch 20/64 loss: 0.29550737142562866
Batch 21/64 loss: 0.2938733696937561
Batch 22/64 loss: 0.284628689289093
Batch 23/64 loss: 0.29805564880371094
Batch 24/64 loss: 0.29440122842788696
Batch 25/64 loss: 0.29318249225616455
Batch 26/64 loss: 0.2915194034576416
Batch 27/64 loss: 0.296053409576416
Batch 28/64 loss: 0.29895490407943726
Batch 29/64 loss: 0.2950460910797119
Batch 30/64 loss: 0.29112768173217773
Batch 31/64 loss: 0.3015798330307007
Batch 32/64 loss: 0.3006777763366699
Batch 33/64 loss: 0.29637008905410767
Batch 34/64 loss: 0.2896162271499634
Batch 35/64 loss: 0.294950008392334
Batch 36/64 loss: 0.291719913482666
Batch 37/64 loss: 0.2966185212135315
Batch 38/64 loss: 0.30307722091674805
Batch 39/64 loss: 0.29472529888153076
Batch 40/64 loss: 0.2921304702758789
Batch 41/64 loss: 0.28881120681762695
Batch 42/64 loss: 0.2997424602508545
Batch 43/64 loss: 0.2922512888908386
Batch 44/64 loss: 0.30073314905166626
Batch 45/64 loss: 0.2982393503189087
Batch 46/64 loss: 0.29754483699798584
Batch 47/64 loss: 0.2938854694366455
Batch 48/64 loss: 0.29943835735321045
Batch 49/64 loss: 0.2985154390335083
Batch 50/64 loss: 0.2908814549446106
Batch 51/64 loss: 0.29769086837768555
Batch 52/64 loss: 0.29529356956481934
Batch 53/64 loss: 0.29477930068969727
Batch 54/64 loss: 0.2911530137062073
Batch 55/64 loss: 0.2960297465324402
Batch 56/64 loss: 0.29383838176727295
Batch 57/64 loss: 0.2974739670753479
Batch 58/64 loss: 0.3019943833351135
Batch 59/64 loss: 0.30057501792907715
Batch 60/64 loss: 0.2928469181060791
Batch 61/64 loss: 0.29617416858673096
Batch 62/64 loss: 0.28936630487442017
Batch 63/64 loss: 0.29307907819747925
Batch 64/64 loss: 0.3001006841659546
Epoch 201  Train loss: 0.29561457867715873  Val loss: 0.3157168442441016
Saving best model, epoch: 201
Epoch 202
-------------------------------
Batch 1/64 loss: 0.3024158477783203
Batch 2/64 loss: 0.29847121238708496
Batch 3/64 loss: 0.2967182397842407
Batch 4/64 loss: 0.29820412397384644
Batch 5/64 loss: 0.29630863666534424
Batch 6/64 loss: 0.2959555387496948
Batch 7/64 loss: 0.29467886686325073
Batch 8/64 loss: 0.2929821014404297
Batch 9/64 loss: 0.3002541661262512
Batch 10/64 loss: 0.29545968770980835
Batch 11/64 loss: 0.29363417625427246
Batch 12/64 loss: 0.29566341638565063
Batch 13/64 loss: 0.2935671806335449
Batch 14/64 loss: 0.2920030355453491
Batch 15/64 loss: 0.29311835765838623
Batch 16/64 loss: 0.29463911056518555
Batch 17/64 loss: 0.3089728355407715
Batch 18/64 loss: 0.2945828437805176
Batch 19/64 loss: 0.29425597190856934
Batch 20/64 loss: 0.2914997935295105
Batch 21/64 loss: 0.29832780361175537
Batch 22/64 loss: 0.29583752155303955
Batch 23/64 loss: 0.29606127738952637
Batch 24/64 loss: 0.2969251275062561
Batch 25/64 loss: 0.2954249978065491
Batch 26/64 loss: 0.28885960578918457
Batch 27/64 loss: 0.2997683882713318
Batch 28/64 loss: 0.2909095287322998
Batch 29/64 loss: 0.29833149909973145
Batch 30/64 loss: 0.28596049547195435
Batch 31/64 loss: 0.29490649700164795
Batch 32/64 loss: 0.2927042245864868
Batch 33/64 loss: 0.294223427772522
Batch 34/64 loss: 0.3010982275009155
Batch 35/64 loss: 0.2980794906616211
Batch 36/64 loss: 0.2913644313812256
Batch 37/64 loss: 0.29616981744766235
Batch 38/64 loss: 0.29672956466674805
Batch 39/64 loss: 0.29621899127960205
Batch 40/64 loss: 0.2951611280441284
Batch 41/64 loss: 0.2937967777252197
Batch 42/64 loss: 0.30098628997802734
Batch 43/64 loss: 0.29658687114715576
Batch 44/64 loss: 0.2949375510215759
Batch 45/64 loss: 0.2989015579223633
Batch 46/64 loss: 0.3003377318382263
Batch 47/64 loss: 0.2926757335662842
Batch 48/64 loss: 0.29423320293426514
Batch 49/64 loss: 0.2953663468360901
Batch 50/64 loss: 0.29629218578338623
Batch 51/64 loss: 0.2984733581542969
Batch 52/64 loss: 0.2995406985282898
Batch 53/64 loss: 0.29848265647888184
Batch 54/64 loss: 0.2906101942062378
Batch 55/64 loss: 0.29940342903137207
Batch 56/64 loss: 0.296262264251709
Batch 57/64 loss: 0.29101693630218506
Batch 58/64 loss: 0.29670190811157227
Batch 59/64 loss: 0.2969135046005249
Batch 60/64 loss: 0.2984233498573303
Batch 61/64 loss: 0.2926841974258423
Batch 62/64 loss: 0.2881784439086914
Batch 63/64 loss: 0.2928043007850647
Batch 64/64 loss: 0.2960217595100403
Epoch 202  Train loss: 0.2957187921393151  Val loss: 0.3157653398939834
Epoch 203
-------------------------------
Batch 1/64 loss: 0.2921150326728821
Batch 2/64 loss: 0.2938343286514282
Batch 3/64 loss: 0.2922627925872803
Batch 4/64 loss: 0.29641735553741455
Batch 5/64 loss: 0.2937697172164917
Batch 6/64 loss: 0.29479241371154785
Batch 7/64 loss: 0.29547232389450073
Batch 8/64 loss: 0.3010019063949585
Batch 9/64 loss: 0.2945317029953003
Batch 10/64 loss: 0.2957584857940674
Batch 11/64 loss: 0.2954339385032654
Batch 12/64 loss: 0.29490596055984497
Batch 13/64 loss: 0.28997117280960083
Batch 14/64 loss: 0.29957157373428345
Batch 15/64 loss: 0.2983921766281128
Batch 16/64 loss: 0.2914617657661438
Batch 17/64 loss: 0.29782021045684814
Batch 18/64 loss: 0.3015751242637634
Batch 19/64 loss: 0.2924243211746216
Batch 20/64 loss: 0.296730101108551
Batch 21/64 loss: 0.2921220064163208
Batch 22/64 loss: 0.29664599895477295
Batch 23/64 loss: 0.29800575971603394
Batch 24/64 loss: 0.3063575029373169
Batch 25/64 loss: 0.2945209741592407
Batch 26/64 loss: 0.3002309203147888
Batch 27/64 loss: 0.2940787076950073
Batch 28/64 loss: 0.2963108420372009
Batch 29/64 loss: 0.29468345642089844
Batch 30/64 loss: 0.30145907402038574
Batch 31/64 loss: 0.29738545417785645
Batch 32/64 loss: 0.29688775539398193
Batch 33/64 loss: 0.28927820920944214
Batch 34/64 loss: 0.2991577982902527
Batch 35/64 loss: 0.2935065031051636
Batch 36/64 loss: 0.29723668098449707
Batch 37/64 loss: 0.2976264953613281
Batch 38/64 loss: 0.29204869270324707
Batch 39/64 loss: 0.2972700595855713
Batch 40/64 loss: 0.295418381690979
Batch 41/64 loss: 0.30564624071121216
Batch 42/64 loss: 0.2910100817680359
Batch 43/64 loss: 0.2964833974838257
Batch 44/64 loss: 0.28920722007751465
Batch 45/64 loss: 0.2936067581176758
Batch 46/64 loss: 0.2977425456047058
Batch 47/64 loss: 0.28961753845214844
Batch 48/64 loss: 0.2985198497772217
Batch 49/64 loss: 0.29327887296676636
Batch 50/64 loss: 0.2936447858810425
Batch 51/64 loss: 0.2974323034286499
Batch 52/64 loss: 0.29597342014312744
Batch 53/64 loss: 0.29630428552627563
Batch 54/64 loss: 0.2909555435180664
Batch 55/64 loss: 0.2912471890449524
Batch 56/64 loss: 0.29062139987945557
Batch 57/64 loss: 0.29371947050094604
Batch 58/64 loss: 0.29603874683380127
Batch 59/64 loss: 0.29595112800598145
Batch 60/64 loss: 0.30413830280303955
Batch 61/64 loss: 0.29180461168289185
Batch 62/64 loss: 0.29423487186431885
Batch 63/64 loss: 0.2974342703819275
Batch 64/64 loss: 0.28751838207244873
Epoch 203  Train loss: 0.29550941644930373  Val loss: 0.31613679276299234
Epoch 204
-------------------------------
Batch 1/64 loss: 0.2931753396987915
Batch 2/64 loss: 0.28942036628723145
Batch 3/64 loss: 0.2852408289909363
Batch 4/64 loss: 0.2985474467277527
Batch 5/64 loss: 0.3007192015647888
Batch 6/64 loss: 0.30102288722991943
Batch 7/64 loss: 0.2953038811683655
Batch 8/64 loss: 0.2913275957107544
Batch 9/64 loss: 0.2971353530883789
Batch 10/64 loss: 0.2918964624404907
Batch 11/64 loss: 0.3000414967536926
Batch 12/64 loss: 0.2976544499397278
Batch 13/64 loss: 0.2880067825317383
Batch 14/64 loss: 0.28759080171585083
Batch 15/64 loss: 0.2980778217315674
Batch 16/64 loss: 0.296941876411438
Batch 17/64 loss: 0.2905311584472656
Batch 18/64 loss: 0.29326725006103516
Batch 19/64 loss: 0.2953515648841858
Batch 20/64 loss: 0.2910231947898865
Batch 21/64 loss: 0.2947465181350708
Batch 22/64 loss: 0.29764479398727417
Batch 23/64 loss: 0.29960930347442627
Batch 24/64 loss: 0.2987399101257324
Batch 25/64 loss: 0.28916555643081665
Batch 26/64 loss: 0.2950466275215149
Batch 27/64 loss: 0.2985236644744873
Batch 28/64 loss: 0.29601383209228516
Batch 29/64 loss: 0.29574233293533325
Batch 30/64 loss: 0.30118417739868164
Batch 31/64 loss: 0.30284619331359863
Batch 32/64 loss: 0.2921116352081299
Batch 33/64 loss: 0.2865000367164612
Batch 34/64 loss: 0.2970030903816223
Batch 35/64 loss: 0.29440706968307495
Batch 36/64 loss: 0.2956588864326477
Batch 37/64 loss: 0.29334986209869385
Batch 38/64 loss: 0.3015408515930176
Batch 39/64 loss: 0.29676246643066406
Batch 40/64 loss: 0.29562997817993164
Batch 41/64 loss: 0.29433250427246094
Batch 42/64 loss: 0.289875864982605
Batch 43/64 loss: 0.2916525602340698
Batch 44/64 loss: 0.2964774966239929
Batch 45/64 loss: 0.29360997676849365
Batch 46/64 loss: 0.29518556594848633
Batch 47/64 loss: 0.3022581934928894
Batch 48/64 loss: 0.2981073260307312
Batch 49/64 loss: 0.2951546311378479
Batch 50/64 loss: 0.29865962266921997
Batch 51/64 loss: 0.2951964735984802
Batch 52/64 loss: 0.29915767908096313
Batch 53/64 loss: 0.2942185401916504
Batch 54/64 loss: 0.29772067070007324
Batch 55/64 loss: 0.29759955406188965
Batch 56/64 loss: 0.2913036346435547
Batch 57/64 loss: 0.28954559564590454
Batch 58/64 loss: 0.3008437752723694
Batch 59/64 loss: 0.29434776306152344
Batch 60/64 loss: 0.2960531711578369
Batch 61/64 loss: 0.29866182804107666
Batch 62/64 loss: 0.28893256187438965
Batch 63/64 loss: 0.2993807792663574
Batch 64/64 loss: 0.29515135288238525
Epoch 204  Train loss: 0.2952806561600928  Val loss: 0.31652143648809583
Epoch 205
-------------------------------
Batch 1/64 loss: 0.29429465532302856
Batch 2/64 loss: 0.29913073778152466
Batch 3/64 loss: 0.2987562417984009
Batch 4/64 loss: 0.3002368211746216
Batch 5/64 loss: 0.29509174823760986
Batch 6/64 loss: 0.2958422303199768
Batch 7/64 loss: 0.28967559337615967
Batch 8/64 loss: 0.29528045654296875
Batch 9/64 loss: 0.2972731590270996
Batch 10/64 loss: 0.2974282503128052
Batch 11/64 loss: 0.30191469192504883
Batch 12/64 loss: 0.294846773147583
Batch 13/64 loss: 0.29685330390930176
Batch 14/64 loss: 0.29296720027923584
Batch 15/64 loss: 0.2950558662414551
Batch 16/64 loss: 0.29939842224121094
Batch 17/64 loss: 0.3073540925979614
Batch 18/64 loss: 0.2931017279624939
Batch 19/64 loss: 0.2947019934654236
Batch 20/64 loss: 0.295585036277771
Batch 21/64 loss: 0.29900455474853516
Batch 22/64 loss: 0.2965071201324463
Batch 23/64 loss: 0.29052722454071045
Batch 24/64 loss: 0.2956242561340332
Batch 25/64 loss: 0.29509562253952026
Batch 26/64 loss: 0.2922806739807129
Batch 27/64 loss: 0.2910439968109131
Batch 28/64 loss: 0.2912095785140991
Batch 29/64 loss: 0.29625147581100464
Batch 30/64 loss: 0.2886618375778198
Batch 31/64 loss: 0.2982090711593628
Batch 32/64 loss: 0.2910884618759155
Batch 33/64 loss: 0.2942237854003906
Batch 34/64 loss: 0.28780031204223633
Batch 35/64 loss: 0.29407799243927
Batch 36/64 loss: 0.29685354232788086
Batch 37/64 loss: 0.29572564363479614
Batch 38/64 loss: 0.29309725761413574
Batch 39/64 loss: 0.29794591665267944
Batch 40/64 loss: 0.304858922958374
Batch 41/64 loss: 0.2979753613471985
Batch 42/64 loss: 0.2932887077331543
Batch 43/64 loss: 0.28708040714263916
Batch 44/64 loss: 0.295243501663208
Batch 45/64 loss: 0.29801440238952637
Batch 46/64 loss: 0.2958608865737915
Batch 47/64 loss: 0.2966686487197876
Batch 48/64 loss: 0.2935878038406372
Batch 49/64 loss: 0.2977704405784607
Batch 50/64 loss: 0.3024783730506897
Batch 51/64 loss: 0.2943217158317566
Batch 52/64 loss: 0.28970444202423096
Batch 53/64 loss: 0.29854243993759155
Batch 54/64 loss: 0.2949739098548889
Batch 55/64 loss: 0.2934997081756592
Batch 56/64 loss: 0.3017593026161194
Batch 57/64 loss: 0.29345470666885376
Batch 58/64 loss: 0.29668939113616943
Batch 59/64 loss: 0.2908233404159546
Batch 60/64 loss: 0.29999613761901855
Batch 61/64 loss: 0.2918791174888611
Batch 62/64 loss: 0.2976186275482178
Batch 63/64 loss: 0.2934504747390747
Batch 64/64 loss: 0.2945259213447571
Epoch 205  Train loss: 0.2955365103833816  Val loss: 0.3155978494083759
Saving best model, epoch: 205
Epoch 206
-------------------------------
Batch 1/64 loss: 0.28912127017974854
Batch 2/64 loss: 0.2901499271392822
Batch 3/64 loss: 0.29489606618881226
Batch 4/64 loss: 0.29145026206970215
Batch 5/64 loss: 0.2980865240097046
Batch 6/64 loss: 0.2937180995941162
Batch 7/64 loss: 0.29658830165863037
Batch 8/64 loss: 0.2944016456604004
Batch 9/64 loss: 0.28891444206237793
Batch 10/64 loss: 0.29240620136260986
Batch 11/64 loss: 0.28930866718292236
Batch 12/64 loss: 0.28720641136169434
Batch 13/64 loss: 0.29565566778182983
Batch 14/64 loss: 0.29137372970581055
Batch 15/64 loss: 0.28760826587677
Batch 16/64 loss: 0.29495537281036377
Batch 17/64 loss: 0.30190855264663696
Batch 18/64 loss: 0.30045223236083984
Batch 19/64 loss: 0.2879277467727661
Batch 20/64 loss: 0.3024578094482422
Batch 21/64 loss: 0.3001822233200073
Batch 22/64 loss: 0.2942659854888916
Batch 23/64 loss: 0.2897961735725403
Batch 24/64 loss: 0.2910655736923218
Batch 25/64 loss: 0.2940332889556885
Batch 26/64 loss: 0.30490171909332275
Batch 27/64 loss: 0.2927796244621277
Batch 28/64 loss: 0.29186177253723145
Batch 29/64 loss: 0.2935258150100708
Batch 30/64 loss: 0.29069089889526367
Batch 31/64 loss: 0.297463595867157
Batch 32/64 loss: 0.290952205657959
Batch 33/64 loss: 0.29312145709991455
Batch 34/64 loss: 0.29449939727783203
Batch 35/64 loss: 0.2998601794242859
Batch 36/64 loss: 0.2940843105316162
Batch 37/64 loss: 0.2942063808441162
Batch 38/64 loss: 0.29020893573760986
Batch 39/64 loss: 0.2920837998390198
Batch 40/64 loss: 0.2939176559448242
Batch 41/64 loss: 0.30176544189453125
Batch 42/64 loss: 0.2989464998245239
Batch 43/64 loss: 0.29072248935699463
Batch 44/64 loss: 0.29734957218170166
Batch 45/64 loss: 0.3002169728279114
Batch 46/64 loss: 0.29498881101608276
Batch 47/64 loss: 0.30368661880493164
Batch 48/64 loss: 0.2916049361228943
Batch 49/64 loss: 0.29908180236816406
Batch 50/64 loss: 0.2924986481666565
Batch 51/64 loss: 0.2970544695854187
Batch 52/64 loss: 0.29798251390457153
Batch 53/64 loss: 0.29769599437713623
Batch 54/64 loss: 0.2863796353340149
Batch 55/64 loss: 0.299632728099823
Batch 56/64 loss: 0.2967104911804199
Batch 57/64 loss: 0.2962768077850342
Batch 58/64 loss: 0.30577534437179565
Batch 59/64 loss: 0.30483949184417725
Batch 60/64 loss: 0.29431140422821045
Batch 61/64 loss: 0.29057949781417847
Batch 62/64 loss: 0.2943350672721863
Batch 63/64 loss: 0.29999619722366333
Batch 64/64 loss: 0.2914283871650696
Epoch 206  Train loss: 0.29495044572680607  Val loss: 0.3159212267275938
Epoch 207
-------------------------------
Batch 1/64 loss: 0.29803359508514404
Batch 2/64 loss: 0.2971343994140625
Batch 3/64 loss: 0.2995559573173523
Batch 4/64 loss: 0.29587650299072266
Batch 5/64 loss: 0.2934516668319702
Batch 6/64 loss: 0.29479122161865234
Batch 7/64 loss: 0.2946069836616516
Batch 8/64 loss: 0.29727792739868164
Batch 9/64 loss: 0.29070013761520386
Batch 10/64 loss: 0.2940659523010254
Batch 11/64 loss: 0.291126012802124
Batch 12/64 loss: 0.2954801321029663
Batch 13/64 loss: 0.2929849624633789
Batch 14/64 loss: 0.2976996898651123
Batch 15/64 loss: 0.29237985610961914
Batch 16/64 loss: 0.29828405380249023
Batch 17/64 loss: 0.29803717136383057
Batch 18/64 loss: 0.303924024105072
Batch 19/64 loss: 0.2946423292160034
Batch 20/64 loss: 0.29717904329299927
Batch 21/64 loss: 0.29478156566619873
Batch 22/64 loss: 0.28927546739578247
Batch 23/64 loss: 0.2913667559623718
Batch 24/64 loss: 0.2893093228340149
Batch 25/64 loss: 0.29349660873413086
Batch 26/64 loss: 0.2918975353240967
Batch 27/64 loss: 0.29729974269866943
Batch 28/64 loss: 0.28653883934020996
Batch 29/64 loss: 0.2909318208694458
Batch 30/64 loss: 0.29494714736938477
Batch 31/64 loss: 0.29558753967285156
Batch 32/64 loss: 0.29052144289016724
Batch 33/64 loss: 0.2935062646865845
Batch 34/64 loss: 0.2966881990432739
Batch 35/64 loss: 0.290738582611084
Batch 36/64 loss: 0.2935226559638977
Batch 37/64 loss: 0.2958197593688965
Batch 38/64 loss: 0.29578399658203125
Batch 39/64 loss: 0.29105329513549805
Batch 40/64 loss: 0.2966562509536743
Batch 41/64 loss: 0.29580622911453247
Batch 42/64 loss: 0.29265856742858887
Batch 43/64 loss: 0.2983419895172119
Batch 44/64 loss: 0.3003910183906555
Batch 45/64 loss: 0.29399311542510986
Batch 46/64 loss: 0.2905234098434448
Batch 47/64 loss: 0.3010954260826111
Batch 48/64 loss: 0.29430389404296875
Batch 49/64 loss: 0.2988321781158447
Batch 50/64 loss: 0.29939836263656616
Batch 51/64 loss: 0.29125654697418213
Batch 52/64 loss: 0.2954642176628113
Batch 53/64 loss: 0.2940486669540405
Batch 54/64 loss: 0.29369258880615234
Batch 55/64 loss: 0.2953221797943115
Batch 56/64 loss: 0.28882086277008057
Batch 57/64 loss: 0.2930353283882141
Batch 58/64 loss: 0.29244959354400635
Batch 59/64 loss: 0.2975046634674072
Batch 60/64 loss: 0.28880345821380615
Batch 61/64 loss: 0.2926097512245178
Batch 62/64 loss: 0.29473990201950073
Batch 63/64 loss: 0.28907185792922974
Batch 64/64 loss: 0.30541884899139404
Epoch 207  Train loss: 0.2945597232556811  Val loss: 0.31598612430579065
Epoch 208
-------------------------------
Batch 1/64 loss: 0.2958998680114746
Batch 2/64 loss: 0.29162025451660156
Batch 3/64 loss: 0.287121057510376
Batch 4/64 loss: 0.3006078004837036
Batch 5/64 loss: 0.29118847846984863
Batch 6/64 loss: 0.2963157892227173
Batch 7/64 loss: 0.29582053422927856
Batch 8/64 loss: 0.2962297201156616
Batch 9/64 loss: 0.2965506315231323
Batch 10/64 loss: 0.29752957820892334
Batch 11/64 loss: 0.2896544337272644
Batch 12/64 loss: 0.28888529539108276
Batch 13/64 loss: 0.28858351707458496
Batch 14/64 loss: 0.2968183755874634
Batch 15/64 loss: 0.2895295023918152
Batch 16/64 loss: 0.29736995697021484
Batch 17/64 loss: 0.2890852093696594
Batch 18/64 loss: 0.29722458124160767
Batch 19/64 loss: 0.2940559387207031
Batch 20/64 loss: 0.2984488010406494
Batch 21/64 loss: 0.30049920082092285
Batch 22/64 loss: 0.28632181882858276
Batch 23/64 loss: 0.28991466760635376
Batch 24/64 loss: 0.3002883195877075
Batch 25/64 loss: 0.2947279214859009
Batch 26/64 loss: 0.292702317237854
Batch 27/64 loss: 0.29909467697143555
Batch 28/64 loss: 0.29901039600372314
Batch 29/64 loss: 0.296478271484375
Batch 30/64 loss: 0.28771018981933594
Batch 31/64 loss: 0.29306626319885254
Batch 32/64 loss: 0.2913423776626587
Batch 33/64 loss: 0.29236114025115967
Batch 34/64 loss: 0.29564547538757324
Batch 35/64 loss: 0.29430627822875977
Batch 36/64 loss: 0.29375123977661133
Batch 37/64 loss: 0.29807209968566895
Batch 38/64 loss: 0.29072093963623047
Batch 39/64 loss: 0.3009512424468994
Batch 40/64 loss: 0.2894389033317566
Batch 41/64 loss: 0.2862446904182434
Batch 42/64 loss: 0.2936353087425232
Batch 43/64 loss: 0.295703649520874
Batch 44/64 loss: 0.29941219091415405
Batch 45/64 loss: 0.28865164518356323
Batch 46/64 loss: 0.2962111234664917
Batch 47/64 loss: 0.2946305274963379
Batch 48/64 loss: 0.3011355400085449
Batch 49/64 loss: 0.30117130279541016
Batch 50/64 loss: 0.2906835675239563
Batch 51/64 loss: 0.2990388870239258
Batch 52/64 loss: 0.2899472713470459
Batch 53/64 loss: 0.2925921678543091
Batch 54/64 loss: 0.30261075496673584
Batch 55/64 loss: 0.2882291078567505
Batch 56/64 loss: 0.29715585708618164
Batch 57/64 loss: 0.30279970169067383
Batch 58/64 loss: 0.3024901747703552
Batch 59/64 loss: 0.29390084743499756
Batch 60/64 loss: 0.295354425907135
Batch 61/64 loss: 0.2987252473831177
Batch 62/64 loss: 0.28976303339004517
Batch 63/64 loss: 0.2891199588775635
Batch 64/64 loss: 0.29648125171661377
Epoch 208  Train loss: 0.2945335056267533  Val loss: 0.31536097174247923
Saving best model, epoch: 208
Epoch 209
-------------------------------
Batch 1/64 loss: 0.2928244471549988
Batch 2/64 loss: 0.2948824167251587
Batch 3/64 loss: 0.296026349067688
Batch 4/64 loss: 0.2966705560684204
Batch 5/64 loss: 0.2909029722213745
Batch 6/64 loss: 0.2920868396759033
Batch 7/64 loss: 0.2966611385345459
Batch 8/64 loss: 0.2927131652832031
Batch 9/64 loss: 0.29568785429000854
Batch 10/64 loss: 0.29416918754577637
Batch 11/64 loss: 0.2922379970550537
Batch 12/64 loss: 0.29329532384872437
Batch 13/64 loss: 0.2932894825935364
Batch 14/64 loss: 0.2889132499694824
Batch 15/64 loss: 0.2905501127243042
Batch 16/64 loss: 0.29245710372924805
Batch 17/64 loss: 0.3004240393638611
Batch 18/64 loss: 0.2974497079849243
Batch 19/64 loss: 0.2962920665740967
Batch 20/64 loss: 0.29175007343292236
Batch 21/64 loss: 0.29502975940704346
Batch 22/64 loss: 0.2912784218788147
Batch 23/64 loss: 0.2887764573097229
Batch 24/64 loss: 0.2975940704345703
Batch 25/64 loss: 0.294678270816803
Batch 26/64 loss: 0.2944300174713135
Batch 27/64 loss: 0.2994455099105835
Batch 28/64 loss: 0.28762978315353394
Batch 29/64 loss: 0.3047994375228882
Batch 30/64 loss: 0.28404247760772705
Batch 31/64 loss: 0.29472994804382324
Batch 32/64 loss: 0.2958104610443115
Batch 33/64 loss: 0.290671706199646
Batch 34/64 loss: 0.2954522967338562
Batch 35/64 loss: 0.30024826526641846
Batch 36/64 loss: 0.30035221576690674
Batch 37/64 loss: 0.29096174240112305
Batch 38/64 loss: 0.2989761233329773
Batch 39/64 loss: 0.2921818494796753
Batch 40/64 loss: 0.2872220277786255
Batch 41/64 loss: 0.2898867726325989
Batch 42/64 loss: 0.29113197326660156
Batch 43/64 loss: 0.2992423176765442
Batch 44/64 loss: 0.3036905527114868
Batch 45/64 loss: 0.28944456577301025
Batch 46/64 loss: 0.29885149002075195
Batch 47/64 loss: 0.2928236126899719
Batch 48/64 loss: 0.2957916855812073
Batch 49/64 loss: 0.2984600067138672
Batch 50/64 loss: 0.28604263067245483
Batch 51/64 loss: 0.29938292503356934
Batch 52/64 loss: 0.290088415145874
Batch 53/64 loss: 0.2908337712287903
Batch 54/64 loss: 0.29115498065948486
Batch 55/64 loss: 0.291628897190094
Batch 56/64 loss: 0.2940748929977417
Batch 57/64 loss: 0.2926023006439209
Batch 58/64 loss: 0.2948373556137085
Batch 59/64 loss: 0.29455918073654175
Batch 60/64 loss: 0.2916650176048279
Batch 61/64 loss: 0.29455679655075073
Batch 62/64 loss: 0.2924725413322449
Batch 63/64 loss: 0.2877311706542969
Batch 64/64 loss: 0.2972339391708374
Epoch 209  Train loss: 0.2939211644378363  Val loss: 0.31520070775677655
Saving best model, epoch: 209
Epoch 210
-------------------------------
Batch 1/64 loss: 0.29229772090911865
Batch 2/64 loss: 0.29223984479904175
Batch 3/64 loss: 0.2911546230316162
Batch 4/64 loss: 0.29196786880493164
Batch 5/64 loss: 0.30127060413360596
Batch 6/64 loss: 0.2946038246154785
Batch 7/64 loss: 0.28767454624176025
Batch 8/64 loss: 0.2951037883758545
Batch 9/64 loss: 0.2935757637023926
Batch 10/64 loss: 0.2897876501083374
Batch 11/64 loss: 0.29328685998916626
Batch 12/64 loss: 0.29740607738494873
Batch 13/64 loss: 0.29208582639694214
Batch 14/64 loss: 0.29042041301727295
Batch 15/64 loss: 0.2884117364883423
Batch 16/64 loss: 0.2880711555480957
Batch 17/64 loss: 0.29320311546325684
Batch 18/64 loss: 0.28873908519744873
Batch 19/64 loss: 0.29045671224594116
Batch 20/64 loss: 0.30523937940597534
Batch 21/64 loss: 0.29276615381240845
Batch 22/64 loss: 0.2915712594985962
Batch 23/64 loss: 0.288235604763031
Batch 24/64 loss: 0.2978188395500183
Batch 25/64 loss: 0.28823792934417725
Batch 26/64 loss: 0.29622411727905273
Batch 27/64 loss: 0.29679346084594727
Batch 28/64 loss: 0.2979004383087158
Batch 29/64 loss: 0.29594147205352783
Batch 30/64 loss: 0.29292869567871094
Batch 31/64 loss: 0.28880077600479126
Batch 32/64 loss: 0.2949675917625427
Batch 33/64 loss: 0.29211509227752686
Batch 34/64 loss: 0.29379963874816895
Batch 35/64 loss: 0.29217618703842163
Batch 36/64 loss: 0.2953166961669922
Batch 37/64 loss: 0.29733169078826904
Batch 38/64 loss: 0.29282426834106445
Batch 39/64 loss: 0.2988539934158325
Batch 40/64 loss: 0.29701781272888184
Batch 41/64 loss: 0.2969543933868408
Batch 42/64 loss: 0.2963070869445801
Batch 43/64 loss: 0.29362189769744873
Batch 44/64 loss: 0.2926841378211975
Batch 45/64 loss: 0.2897626757621765
Batch 46/64 loss: 0.2921009063720703
Batch 47/64 loss: 0.2922520637512207
Batch 48/64 loss: 0.2902107238769531
Batch 49/64 loss: 0.2889378070831299
Batch 50/64 loss: 0.2941422462463379
Batch 51/64 loss: 0.2888602614402771
Batch 52/64 loss: 0.2933467626571655
Batch 53/64 loss: 0.30226993560791016
Batch 54/64 loss: 0.29461562633514404
Batch 55/64 loss: 0.2962082028388977
Batch 56/64 loss: 0.29548585414886475
Batch 57/64 loss: 0.2890797257423401
Batch 58/64 loss: 0.3039203882217407
Batch 59/64 loss: 0.2896283268928528
Batch 60/64 loss: 0.2883113622665405
Batch 61/64 loss: 0.296403706073761
Batch 62/64 loss: 0.2974902391433716
Batch 63/64 loss: 0.296089768409729
Batch 64/64 loss: 0.292186439037323
Epoch 210  Train loss: 0.29359125085905485  Val loss: 0.31558131475219203
Epoch 211
-------------------------------
Batch 1/64 loss: 0.2975022792816162
Batch 2/64 loss: 0.2943716049194336
Batch 3/64 loss: 0.29069167375564575
Batch 4/64 loss: 0.2955542206764221
Batch 5/64 loss: 0.29924845695495605
Batch 6/64 loss: 0.30536770820617676
Batch 7/64 loss: 0.28863370418548584
Batch 8/64 loss: 0.2931026220321655
Batch 9/64 loss: 0.287143349647522
Batch 10/64 loss: 0.29460442066192627
Batch 11/64 loss: 0.2878892421722412
Batch 12/64 loss: 0.29930585622787476
Batch 13/64 loss: 0.29011213779449463
Batch 14/64 loss: 0.2903286814689636
Batch 15/64 loss: 0.2911175489425659
Batch 16/64 loss: 0.29744774103164673
Batch 17/64 loss: 0.2868666648864746
Batch 18/64 loss: 0.2928096652030945
Batch 19/64 loss: 0.29194045066833496
Batch 20/64 loss: 0.29455453157424927
Batch 21/64 loss: 0.29219233989715576
Batch 22/64 loss: 0.2989831566810608
Batch 23/64 loss: 0.2948591709136963
Batch 24/64 loss: 0.29956305027008057
Batch 25/64 loss: 0.2871260643005371
Batch 26/64 loss: 0.2959291338920593
Batch 27/64 loss: 0.29231518507003784
Batch 28/64 loss: 0.2912704348564148
Batch 29/64 loss: 0.2881966829299927
Batch 30/64 loss: 0.29528069496154785
Batch 31/64 loss: 0.2854061722755432
Batch 32/64 loss: 0.2876262068748474
Batch 33/64 loss: 0.2968326807022095
Batch 34/64 loss: 0.2907217741012573
Batch 35/64 loss: 0.29379016160964966
Batch 36/64 loss: 0.297107458114624
Batch 37/64 loss: 0.3023243546485901
Batch 38/64 loss: 0.29426634311676025
Batch 39/64 loss: 0.28912127017974854
Batch 40/64 loss: 0.2958674430847168
Batch 41/64 loss: 0.28589653968811035
Batch 42/64 loss: 0.28750038146972656
Batch 43/64 loss: 0.29372644424438477
Batch 44/64 loss: 0.29075169563293457
Batch 45/64 loss: 0.29245781898498535
Batch 46/64 loss: 0.2910665273666382
Batch 47/64 loss: 0.2980281710624695
Batch 48/64 loss: 0.291074275970459
Batch 49/64 loss: 0.29754209518432617
Batch 50/64 loss: 0.2984238862991333
Batch 51/64 loss: 0.2910572290420532
Batch 52/64 loss: 0.2927173376083374
Batch 53/64 loss: 0.29116690158843994
Batch 54/64 loss: 0.2908517122268677
Batch 55/64 loss: 0.29131627082824707
Batch 56/64 loss: 0.2960869073867798
Batch 57/64 loss: 0.28500938415527344
Batch 58/64 loss: 0.29377615451812744
Batch 59/64 loss: 0.2872748374938965
Batch 60/64 loss: 0.29548346996307373
Batch 61/64 loss: 0.29021358489990234
Batch 62/64 loss: 0.29599136114120483
Batch 63/64 loss: 0.3001883029937744
Batch 64/64 loss: 0.30399250984191895
Epoch 211  Train loss: 0.29322302762199853  Val loss: 0.3156820892058697
Epoch 212
-------------------------------
Batch 1/64 loss: 0.28933799266815186
Batch 2/64 loss: 0.2872757315635681
Batch 3/64 loss: 0.29177403450012207
Batch 4/64 loss: 0.29587405920028687
Batch 5/64 loss: 0.2865936756134033
Batch 6/64 loss: 0.2963855266571045
Batch 7/64 loss: 0.29392290115356445
Batch 8/64 loss: 0.291995644569397
Batch 9/64 loss: 0.2916874885559082
Batch 10/64 loss: 0.2900315523147583
Batch 11/64 loss: 0.29063451290130615
Batch 12/64 loss: 0.309819757938385
Batch 13/64 loss: 0.29222995042800903
Batch 14/64 loss: 0.2923448085784912
Batch 15/64 loss: 0.29546523094177246
Batch 16/64 loss: 0.2882247567176819
Batch 17/64 loss: 0.292550265789032
Batch 18/64 loss: 0.29282039403915405
Batch 19/64 loss: 0.3028084635734558
Batch 20/64 loss: 0.2942248582839966
Batch 21/64 loss: 0.2931499481201172
Batch 22/64 loss: 0.2958124876022339
Batch 23/64 loss: 0.29850172996520996
Batch 24/64 loss: 0.2910785675048828
Batch 25/64 loss: 0.2906975746154785
Batch 26/64 loss: 0.28711068630218506
Batch 27/64 loss: 0.29752862453460693
Batch 28/64 loss: 0.2941199541091919
Batch 29/64 loss: 0.29311537742614746
Batch 30/64 loss: 0.2882075309753418
Batch 31/64 loss: 0.2952479124069214
Batch 32/64 loss: 0.30026859045028687
Batch 33/64 loss: 0.29097920656204224
Batch 34/64 loss: 0.2974815368652344
Batch 35/64 loss: 0.29074978828430176
Batch 36/64 loss: 0.2901536822319031
Batch 37/64 loss: 0.28874969482421875
Batch 38/64 loss: 0.29630059003829956
Batch 39/64 loss: 0.30296480655670166
Batch 40/64 loss: 0.30026721954345703
Batch 41/64 loss: 0.28848421573638916
Batch 42/64 loss: 0.2945362329483032
Batch 43/64 loss: 0.2907296419143677
Batch 44/64 loss: 0.2923443913459778
Batch 45/64 loss: 0.29716312885284424
Batch 46/64 loss: 0.28867554664611816
Batch 47/64 loss: 0.29033613204956055
Batch 48/64 loss: 0.29601550102233887
Batch 49/64 loss: 0.29759836196899414
Batch 50/64 loss: 0.2943628430366516
Batch 51/64 loss: 0.2880876064300537
Batch 52/64 loss: 0.2884235382080078
Batch 53/64 loss: 0.2958192825317383
Batch 54/64 loss: 0.2985389828681946
Batch 55/64 loss: 0.2967402935028076
Batch 56/64 loss: 0.2928495407104492
Batch 57/64 loss: 0.29623377323150635
Batch 58/64 loss: 0.2921332120895386
Batch 59/64 loss: 0.29256218671798706
Batch 60/64 loss: 0.29214340448379517
Batch 61/64 loss: 0.2915579080581665
Batch 62/64 loss: 0.29509806632995605
Batch 63/64 loss: 0.29466867446899414
Batch 64/64 loss: 0.2967442274093628
Epoch 212  Train loss: 0.2935866313822129  Val loss: 0.31690832061046587
Epoch 213
-------------------------------
Batch 1/64 loss: 0.2953522801399231
Batch 2/64 loss: 0.298761248588562
Batch 3/64 loss: 0.28780078887939453
Batch 4/64 loss: 0.2904016971588135
Batch 5/64 loss: 0.2935725450515747
Batch 6/64 loss: 0.29552316665649414
Batch 7/64 loss: 0.2924150228500366
Batch 8/64 loss: 0.29103970527648926
Batch 9/64 loss: 0.29505109786987305
Batch 10/64 loss: 0.29580461978912354
Batch 11/64 loss: 0.291897177696228
Batch 12/64 loss: 0.29039233922958374
Batch 13/64 loss: 0.2988758683204651
Batch 14/64 loss: 0.29382622241973877
Batch 15/64 loss: 0.28994083404541016
Batch 16/64 loss: 0.2931811809539795
Batch 17/64 loss: 0.28823578357696533
Batch 18/64 loss: 0.29451918601989746
Batch 19/64 loss: 0.2892855405807495
Batch 20/64 loss: 0.2956025004386902
Batch 21/64 loss: 0.2895488739013672
Batch 22/64 loss: 0.2978940010070801
Batch 23/64 loss: 0.2869335412979126
Batch 24/64 loss: 0.29380249977111816
Batch 25/64 loss: 0.2953755259513855
Batch 26/64 loss: 0.2940981388092041
Batch 27/64 loss: 0.2984895706176758
Batch 28/64 loss: 0.29320091009140015
Batch 29/64 loss: 0.2937604784965515
Batch 30/64 loss: 0.29714107513427734
Batch 31/64 loss: 0.2950429320335388
Batch 32/64 loss: 0.29445791244506836
Batch 33/64 loss: 0.2974330186843872
Batch 34/64 loss: 0.2946131229400635
Batch 35/64 loss: 0.28990381956100464
Batch 36/64 loss: 0.2918452024459839
Batch 37/64 loss: 0.29386329650878906
Batch 38/64 loss: 0.29354041814804077
Batch 39/64 loss: 0.3019654154777527
Batch 40/64 loss: 0.28811168670654297
Batch 41/64 loss: 0.29670464992523193
Batch 42/64 loss: 0.29743528366088867
Batch 43/64 loss: 0.2970746159553528
Batch 44/64 loss: 0.296453595161438
Batch 45/64 loss: 0.2906174063682556
Batch 46/64 loss: 0.2896989583969116
Batch 47/64 loss: 0.2971566915512085
Batch 48/64 loss: 0.29353559017181396
Batch 49/64 loss: 0.2892008423805237
Batch 50/64 loss: 0.29164862632751465
Batch 51/64 loss: 0.29027026891708374
Batch 52/64 loss: 0.2923961281776428
Batch 53/64 loss: 0.2925231456756592
Batch 54/64 loss: 0.29257768392562866
Batch 55/64 loss: 0.29200923442840576
Batch 56/64 loss: 0.2966793179512024
Batch 57/64 loss: 0.29566991329193115
Batch 58/64 loss: 0.28932273387908936
Batch 59/64 loss: 0.2944432497024536
Batch 60/64 loss: 0.30254703760147095
Batch 61/64 loss: 0.2939596176147461
Batch 62/64 loss: 0.2902291417121887
Batch 63/64 loss: 0.2984577417373657
Batch 64/64 loss: 0.2915937304496765
Epoch 213  Train loss: 0.2936754042027043  Val loss: 0.3153920779932815
Epoch 214
-------------------------------
Batch 1/64 loss: 0.2883771061897278
Batch 2/64 loss: 0.29027605056762695
Batch 3/64 loss: 0.2930251359939575
Batch 4/64 loss: 0.29644858837127686
Batch 5/64 loss: 0.29074227809906006
Batch 6/64 loss: 0.29315245151519775
Batch 7/64 loss: 0.28686392307281494
Batch 8/64 loss: 0.2890147566795349
Batch 9/64 loss: 0.288970410823822
Batch 10/64 loss: 0.2914074659347534
Batch 11/64 loss: 0.29395169019699097
Batch 12/64 loss: 0.2939499616622925
Batch 13/64 loss: 0.2939556837081909
Batch 14/64 loss: 0.2947196960449219
Batch 15/64 loss: 0.2937018871307373
Batch 16/64 loss: 0.29363298416137695
Batch 17/64 loss: 0.2953200340270996
Batch 18/64 loss: 0.29379361867904663
Batch 19/64 loss: 0.2856147289276123
Batch 20/64 loss: 0.29096531867980957
Batch 21/64 loss: 0.2966783046722412
Batch 22/64 loss: 0.292056679725647
Batch 23/64 loss: 0.2946743965148926
Batch 24/64 loss: 0.29636722803115845
Batch 25/64 loss: 0.2963705062866211
Batch 26/64 loss: 0.2939489483833313
Batch 27/64 loss: 0.29559850692749023
Batch 28/64 loss: 0.30435270071029663
Batch 29/64 loss: 0.2911074161529541
Batch 30/64 loss: 0.2976338267326355
Batch 31/64 loss: 0.29530978202819824
Batch 32/64 loss: 0.2913779616355896
Batch 33/64 loss: 0.2857838273048401
Batch 34/64 loss: 0.29026418924331665
Batch 35/64 loss: 0.2947913408279419
Batch 36/64 loss: 0.2891383767127991
Batch 37/64 loss: 0.29416894912719727
Batch 38/64 loss: 0.28878480195999146
Batch 39/64 loss: 0.2975754737854004
Batch 40/64 loss: 0.29422974586486816
Batch 41/64 loss: 0.2922656536102295
Batch 42/64 loss: 0.2992011308670044
Batch 43/64 loss: 0.29396188259124756
Batch 44/64 loss: 0.29027265310287476
Batch 45/64 loss: 0.29239678382873535
Batch 46/64 loss: 0.29392337799072266
Batch 47/64 loss: 0.2934339642524719
Batch 48/64 loss: 0.29145628213882446
Batch 49/64 loss: 0.2958390712738037
Batch 50/64 loss: 0.299446702003479
Batch 51/64 loss: 0.2945025563240051
Batch 52/64 loss: 0.29564183950424194
Batch 53/64 loss: 0.2923225164413452
Batch 54/64 loss: 0.2931925654411316
Batch 55/64 loss: 0.29198992252349854
Batch 56/64 loss: 0.29933685064315796
Batch 57/64 loss: 0.2932334542274475
Batch 58/64 loss: 0.2979995012283325
Batch 59/64 loss: 0.29151415824890137
Batch 60/64 loss: 0.28707075119018555
Batch 61/64 loss: 0.30788367986679077
Batch 62/64 loss: 0.28890562057495117
Batch 63/64 loss: 0.2889859676361084
Batch 64/64 loss: 0.2903975248336792
Epoch 214  Train loss: 0.29334387078004726  Val loss: 0.31594972696500956
Epoch 215
-------------------------------
Batch 1/64 loss: 0.2948343753814697
Batch 2/64 loss: 0.29120802879333496
Batch 3/64 loss: 0.2958754301071167
Batch 4/64 loss: 0.29278266429901123
Batch 5/64 loss: 0.29258668422698975
Batch 6/64 loss: 0.2984102964401245
Batch 7/64 loss: 0.2900931239128113
Batch 8/64 loss: 0.2924925684928894
Batch 9/64 loss: 0.2913205623626709
Batch 10/64 loss: 0.29261285066604614
Batch 11/64 loss: 0.2970684766769409
Batch 12/64 loss: 0.2961007356643677
Batch 13/64 loss: 0.2950645089149475
Batch 14/64 loss: 0.29449427127838135
Batch 15/64 loss: 0.30160069465637207
Batch 16/64 loss: 0.2970232367515564
Batch 17/64 loss: 0.29186201095581055
Batch 18/64 loss: 0.29984694719314575
Batch 19/64 loss: 0.29588013887405396
Batch 20/64 loss: 0.2995902895927429
Batch 21/64 loss: 0.2850472927093506
Batch 22/64 loss: 0.29305499792099
Batch 23/64 loss: 0.2916971445083618
Batch 24/64 loss: 0.2846708297729492
Batch 25/64 loss: 0.296345055103302
Batch 26/64 loss: 0.2902944087982178
Batch 27/64 loss: 0.2975584864616394
Batch 28/64 loss: 0.28948521614074707
Batch 29/64 loss: 0.3009771704673767
Batch 30/64 loss: 0.29011619091033936
Batch 31/64 loss: 0.2860243320465088
Batch 32/64 loss: 0.2947819232940674
Batch 33/64 loss: 0.29528069496154785
Batch 34/64 loss: 0.2949591875076294
Batch 35/64 loss: 0.2943260073661804
Batch 36/64 loss: 0.2847294807434082
Batch 37/64 loss: 0.2977563738822937
Batch 38/64 loss: 0.29345065355300903
Batch 39/64 loss: 0.29091668128967285
Batch 40/64 loss: 0.29660528898239136
Batch 41/64 loss: 0.2891550064086914
Batch 42/64 loss: 0.288867712020874
Batch 43/64 loss: 0.2946815490722656
Batch 44/64 loss: 0.29222214221954346
Batch 45/64 loss: 0.28955888748168945
Batch 46/64 loss: 0.29790759086608887
Batch 47/64 loss: 0.29075002670288086
Batch 48/64 loss: 0.29255640506744385
Batch 49/64 loss: 0.2868756651878357
Batch 50/64 loss: 0.29367828369140625
Batch 51/64 loss: 0.29247045516967773
Batch 52/64 loss: 0.296639084815979
Batch 53/64 loss: 0.2937299609184265
Batch 54/64 loss: 0.29159921407699585
Batch 55/64 loss: 0.29110777378082275
Batch 56/64 loss: 0.28674471378326416
Batch 57/64 loss: 0.29336094856262207
Batch 58/64 loss: 0.29549717903137207
Batch 59/64 loss: 0.29295647144317627
Batch 60/64 loss: 0.28884661197662354
Batch 61/64 loss: 0.2899751663208008
Batch 62/64 loss: 0.2877522110939026
Batch 63/64 loss: 0.2980960011482239
Batch 64/64 loss: 0.2978065013885498
Epoch 215  Train loss: 0.2931326940947888  Val loss: 0.31534808812682164
Epoch 216
-------------------------------
Batch 1/64 loss: 0.29361534118652344
Batch 2/64 loss: 0.30137360095977783
Batch 3/64 loss: 0.2953859567642212
Batch 4/64 loss: 0.2948061227798462
Batch 5/64 loss: 0.297099769115448
Batch 6/64 loss: 0.2949044704437256
Batch 7/64 loss: 0.29303228855133057
Batch 8/64 loss: 0.2952694892883301
Batch 9/64 loss: 0.2937920093536377
Batch 10/64 loss: 0.2961772680282593
Batch 11/64 loss: 0.28857648372650146
Batch 12/64 loss: 0.2839720845222473
Batch 13/64 loss: 0.28636980056762695
Batch 14/64 loss: 0.29354238510131836
Batch 15/64 loss: 0.2973703145980835
Batch 16/64 loss: 0.29263049364089966
Batch 17/64 loss: 0.29148417711257935
Batch 18/64 loss: 0.288150429725647
Batch 19/64 loss: 0.2904500961303711
Batch 20/64 loss: 0.29295414686203003
Batch 21/64 loss: 0.29173707962036133
Batch 22/64 loss: 0.2846028804779053
Batch 23/64 loss: 0.2952287197113037
Batch 24/64 loss: 0.28716039657592773
Batch 25/64 loss: 0.2912452220916748
Batch 26/64 loss: 0.2949696183204651
Batch 27/64 loss: 0.2902066111564636
Batch 28/64 loss: 0.29525840282440186
Batch 29/64 loss: 0.2880650758743286
Batch 30/64 loss: 0.29272717237472534
Batch 31/64 loss: 0.2948007583618164
Batch 32/64 loss: 0.28863418102264404
Batch 33/64 loss: 0.28975462913513184
Batch 34/64 loss: 0.28265416622161865
Batch 35/64 loss: 0.2890784740447998
Batch 36/64 loss: 0.2993443012237549
Batch 37/64 loss: 0.2910448908805847
Batch 38/64 loss: 0.2918860912322998
Batch 39/64 loss: 0.29503345489501953
Batch 40/64 loss: 0.29864704608917236
Batch 41/64 loss: 0.2972458600997925
Batch 42/64 loss: 0.2889857292175293
Batch 43/64 loss: 0.29514724016189575
Batch 44/64 loss: 0.29007554054260254
Batch 45/64 loss: 0.28798937797546387
Batch 46/64 loss: 0.2887548804283142
Batch 47/64 loss: 0.2987281084060669
Batch 48/64 loss: 0.28903889656066895
Batch 49/64 loss: 0.29870861768722534
Batch 50/64 loss: 0.29138582944869995
Batch 51/64 loss: 0.30027836561203003
Batch 52/64 loss: 0.28910911083221436
Batch 53/64 loss: 0.2979346513748169
Batch 54/64 loss: 0.2966960668563843
Batch 55/64 loss: 0.2932502031326294
Batch 56/64 loss: 0.29060399532318115
Batch 57/64 loss: 0.29055410623550415
Batch 58/64 loss: 0.293703556060791
Batch 59/64 loss: 0.28620898723602295
Batch 60/64 loss: 0.29062747955322266
Batch 61/64 loss: 0.29376935958862305
Batch 62/64 loss: 0.2994479537010193
Batch 63/64 loss: 0.28888893127441406
Batch 64/64 loss: 0.28884971141815186
Epoch 216  Train loss: 0.2924989181406358  Val loss: 0.31583312860469226
Epoch 217
-------------------------------
Batch 1/64 loss: 0.28338950872421265
Batch 2/64 loss: 0.2964515686035156
Batch 3/64 loss: 0.28653454780578613
Batch 4/64 loss: 0.29249119758605957
Batch 5/64 loss: 0.28925585746765137
Batch 6/64 loss: 0.2943291664123535
Batch 7/64 loss: 0.29494088888168335
Batch 8/64 loss: 0.2891392111778259
Batch 9/64 loss: 0.28216326236724854
Batch 10/64 loss: 0.29152071475982666
Batch 11/64 loss: 0.29416126012802124
Batch 12/64 loss: 0.29127395153045654
Batch 13/64 loss: 0.30587148666381836
Batch 14/64 loss: 0.30088281631469727
Batch 15/64 loss: 0.29125845432281494
Batch 16/64 loss: 0.3033520579338074
Batch 17/64 loss: 0.29766857624053955
Batch 18/64 loss: 0.29700660705566406
Batch 19/64 loss: 0.29150885343551636
Batch 20/64 loss: 0.2962559461593628
Batch 21/64 loss: 0.2915545701980591
Batch 22/64 loss: 0.29092884063720703
Batch 23/64 loss: 0.29818862676620483
Batch 24/64 loss: 0.29283905029296875
Batch 25/64 loss: 0.2964087724685669
Batch 26/64 loss: 0.29589200019836426
Batch 27/64 loss: 0.29612720012664795
Batch 28/64 loss: 0.29505324363708496
Batch 29/64 loss: 0.2955816984176636
Batch 30/64 loss: 0.28907549381256104
Batch 31/64 loss: 0.2936972379684448
Batch 32/64 loss: 0.28921711444854736
Batch 33/64 loss: 0.2961750030517578
Batch 34/64 loss: 0.28957903385162354
Batch 35/64 loss: 0.292452335357666
Batch 36/64 loss: 0.2856924533843994
Batch 37/64 loss: 0.2951499819755554
Batch 38/64 loss: 0.2940215468406677
Batch 39/64 loss: 0.2887204885482788
Batch 40/64 loss: 0.28759002685546875
Batch 41/64 loss: 0.29462945461273193
Batch 42/64 loss: 0.28674745559692383
Batch 43/64 loss: 0.2920268774032593
Batch 44/64 loss: 0.28728294372558594
Batch 45/64 loss: 0.2951786518096924
Batch 46/64 loss: 0.29562807083129883
Batch 47/64 loss: 0.2961183786392212
Batch 48/64 loss: 0.2854886054992676
Batch 49/64 loss: 0.2937309741973877
Batch 50/64 loss: 0.2892330288887024
Batch 51/64 loss: 0.29511934518814087
Batch 52/64 loss: 0.2939709424972534
Batch 53/64 loss: 0.29593515396118164
Batch 54/64 loss: 0.2835804224014282
Batch 55/64 loss: 0.29640495777130127
Batch 56/64 loss: 0.3001234531402588
Batch 57/64 loss: 0.2880963683128357
Batch 58/64 loss: 0.29293203353881836
Batch 59/64 loss: 0.28715455532073975
Batch 60/64 loss: 0.2902168035507202
Batch 61/64 loss: 0.2940021753311157
Batch 62/64 loss: 0.28943848609924316
Batch 63/64 loss: 0.2938038110733032
Batch 64/64 loss: 0.29424214363098145
Epoch 217  Train loss: 0.2927203954434862  Val loss: 0.31458691018553536
Saving best model, epoch: 217
Epoch 218
-------------------------------
Batch 1/64 loss: 0.2907140851020813
Batch 2/64 loss: 0.29874885082244873
Batch 3/64 loss: 0.2913880944252014
Batch 4/64 loss: 0.2881854772567749
Batch 5/64 loss: 0.2883641719818115
Batch 6/64 loss: 0.29610615968704224
Batch 7/64 loss: 0.2919043302536011
Batch 8/64 loss: 0.29102736711502075
Batch 9/64 loss: 0.28628265857696533
Batch 10/64 loss: 0.2891484498977661
Batch 11/64 loss: 0.29462337493896484
Batch 12/64 loss: 0.2879752516746521
Batch 13/64 loss: 0.2941649556159973
Batch 14/64 loss: 0.28698503971099854
Batch 15/64 loss: 0.28785884380340576
Batch 16/64 loss: 0.2959432601928711
Batch 17/64 loss: 0.2902717590332031
Batch 18/64 loss: 0.2924717664718628
Batch 19/64 loss: 0.2939477562904358
Batch 20/64 loss: 0.29435819387435913
Batch 21/64 loss: 0.29313910007476807
Batch 22/64 loss: 0.2959461212158203
Batch 23/64 loss: 0.2896606922149658
Batch 24/64 loss: 0.2911227345466614
Batch 25/64 loss: 0.2898813486099243
Batch 26/64 loss: 0.30037903785705566
Batch 27/64 loss: 0.29121774435043335
Batch 28/64 loss: 0.2931897044181824
Batch 29/64 loss: 0.2968384623527527
Batch 30/64 loss: 0.28865939378738403
Batch 31/64 loss: 0.2936580181121826
Batch 32/64 loss: 0.29410260915756226
Batch 33/64 loss: 0.30120646953582764
Batch 34/64 loss: 0.2929983139038086
Batch 35/64 loss: 0.29887354373931885
Batch 36/64 loss: 0.29121261835098267
Batch 37/64 loss: 0.29495859146118164
Batch 38/64 loss: 0.29127031564712524
Batch 39/64 loss: 0.29215937852859497
Batch 40/64 loss: 0.2934408187866211
Batch 41/64 loss: 0.2885800004005432
Batch 42/64 loss: 0.28350913524627686
Batch 43/64 loss: 0.29990553855895996
Batch 44/64 loss: 0.3012024164199829
Batch 45/64 loss: 0.29265058040618896
Batch 46/64 loss: 0.29714035987854004
Batch 47/64 loss: 0.29191744327545166
Batch 48/64 loss: 0.2931842803955078
Batch 49/64 loss: 0.2909797430038452
Batch 50/64 loss: 0.2862359285354614
Batch 51/64 loss: 0.29367512464523315
Batch 52/64 loss: 0.2911587953567505
Batch 53/64 loss: 0.29020750522613525
Batch 54/64 loss: 0.2939344644546509
Batch 55/64 loss: 0.29204535484313965
Batch 56/64 loss: 0.2917160391807556
Batch 57/64 loss: 0.2925812005996704
Batch 58/64 loss: 0.2860225439071655
Batch 59/64 loss: 0.28952378034591675
Batch 60/64 loss: 0.2937186360359192
Batch 61/64 loss: 0.29132401943206787
Batch 62/64 loss: 0.28737032413482666
Batch 63/64 loss: 0.29374659061431885
Batch 64/64 loss: 0.29771411418914795
Epoch 218  Train loss: 0.2923921608457378  Val loss: 0.31508693969536483
Epoch 219
-------------------------------
Batch 1/64 loss: 0.29315245151519775
Batch 2/64 loss: 0.2903639078140259
Batch 3/64 loss: 0.29130691289901733
Batch 4/64 loss: 0.29534345865249634
Batch 5/64 loss: 0.2888501286506653
Batch 6/64 loss: 0.28739213943481445
Batch 7/64 loss: 0.2984510660171509
Batch 8/64 loss: 0.29035985469818115
Batch 9/64 loss: 0.292003870010376
Batch 10/64 loss: 0.28598129749298096
Batch 11/64 loss: 0.29387474060058594
Batch 12/64 loss: 0.28941816091537476
Batch 13/64 loss: 0.2898891568183899
Batch 14/64 loss: 0.30118119716644287
Batch 15/64 loss: 0.2870523929595947
Batch 16/64 loss: 0.2881770133972168
Batch 17/64 loss: 0.2934083938598633
Batch 18/64 loss: 0.29309916496276855
Batch 19/64 loss: 0.28941935300827026
Batch 20/64 loss: 0.28751426935195923
Batch 21/64 loss: 0.29458653926849365
Batch 22/64 loss: 0.28864550590515137
Batch 23/64 loss: 0.2901414632797241
Batch 24/64 loss: 0.2923053503036499
Batch 25/64 loss: 0.2892703413963318
Batch 26/64 loss: 0.2916746139526367
Batch 27/64 loss: 0.2886795997619629
Batch 28/64 loss: 0.29047340154647827
Batch 29/64 loss: 0.2876805067062378
Batch 30/64 loss: 0.28991013765335083
Batch 31/64 loss: 0.28487062454223633
Batch 32/64 loss: 0.293881356716156
Batch 33/64 loss: 0.29272985458374023
Batch 34/64 loss: 0.288227915763855
Batch 35/64 loss: 0.29825007915496826
Batch 36/64 loss: 0.29683297872543335
Batch 37/64 loss: 0.30295372009277344
Batch 38/64 loss: 0.29043668508529663
Batch 39/64 loss: 0.29174554347991943
Batch 40/64 loss: 0.2907923460006714
Batch 41/64 loss: 0.2940629720687866
Batch 42/64 loss: 0.294266939163208
Batch 43/64 loss: 0.2911878228187561
Batch 44/64 loss: 0.29077064990997314
Batch 45/64 loss: 0.2932267189025879
Batch 46/64 loss: 0.29453206062316895
Batch 47/64 loss: 0.30374574661254883
Batch 48/64 loss: 0.29560035467147827
Batch 49/64 loss: 0.292199969291687
Batch 50/64 loss: 0.295790433883667
Batch 51/64 loss: 0.29115039110183716
Batch 52/64 loss: 0.2849491834640503
Batch 53/64 loss: 0.2923484444618225
Batch 54/64 loss: 0.2863534688949585
Batch 55/64 loss: 0.2985111474990845
Batch 56/64 loss: 0.29075103998184204
Batch 57/64 loss: 0.294963002204895
Batch 58/64 loss: 0.29080939292907715
Batch 59/64 loss: 0.2884290814399719
Batch 60/64 loss: 0.288998544216156
Batch 61/64 loss: 0.30101752281188965
Batch 62/64 loss: 0.29332977533340454
Batch 63/64 loss: 0.28966474533081055
Batch 64/64 loss: 0.29157745838165283
Epoch 219  Train loss: 0.29201050973406023  Val loss: 0.3154338049315095
Epoch 220
-------------------------------
Batch 1/64 loss: 0.2869493365287781
Batch 2/64 loss: 0.29030275344848633
Batch 3/64 loss: 0.2843165397644043
Batch 4/64 loss: 0.2896544933319092
Batch 5/64 loss: 0.2877260446548462
Batch 6/64 loss: 0.2994910478591919
Batch 7/64 loss: 0.28559958934783936
Batch 8/64 loss: 0.2825390100479126
Batch 9/64 loss: 0.28860247135162354
Batch 10/64 loss: 0.2907830476760864
Batch 11/64 loss: 0.2882629632949829
Batch 12/64 loss: 0.2873355746269226
Batch 13/64 loss: 0.2911289930343628
Batch 14/64 loss: 0.29154419898986816
Batch 15/64 loss: 0.2933082580566406
Batch 16/64 loss: 0.287639856338501
Batch 17/64 loss: 0.28938961029052734
Batch 18/64 loss: 0.2893432378768921
Batch 19/64 loss: 0.2964411973953247
Batch 20/64 loss: 0.29676616191864014
Batch 21/64 loss: 0.28795504570007324
Batch 22/64 loss: 0.2890928387641907
Batch 23/64 loss: 0.2990986108779907
Batch 24/64 loss: 0.29426848888397217
Batch 25/64 loss: 0.2905620336532593
Batch 26/64 loss: 0.28558725118637085
Batch 27/64 loss: 0.2918245792388916
Batch 28/64 loss: 0.2914719581604004
Batch 29/64 loss: 0.2969721555709839
Batch 30/64 loss: 0.2929266095161438
Batch 31/64 loss: 0.2967391610145569
Batch 32/64 loss: 0.2948617935180664
Batch 33/64 loss: 0.2917114496231079
Batch 34/64 loss: 0.2916295528411865
Batch 35/64 loss: 0.29438650608062744
Batch 36/64 loss: 0.2868605852127075
Batch 37/64 loss: 0.2911337614059448
Batch 38/64 loss: 0.2918992042541504
Batch 39/64 loss: 0.2931061387062073
Batch 40/64 loss: 0.29499781131744385
Batch 41/64 loss: 0.29118216037750244
Batch 42/64 loss: 0.2926015853881836
Batch 43/64 loss: 0.28783249855041504
Batch 44/64 loss: 0.2936042547225952
Batch 45/64 loss: 0.2942273020744324
Batch 46/64 loss: 0.2929641604423523
Batch 47/64 loss: 0.28935706615448
Batch 48/64 loss: 0.286299467086792
Batch 49/64 loss: 0.2886849641799927
Batch 50/64 loss: 0.2951127290725708
Batch 51/64 loss: 0.3010949492454529
Batch 52/64 loss: 0.2910487651824951
Batch 53/64 loss: 0.29239851236343384
Batch 54/64 loss: 0.2944856882095337
Batch 55/64 loss: 0.2937428951263428
Batch 56/64 loss: 0.30132579803466797
Batch 57/64 loss: 0.2929753065109253
Batch 58/64 loss: 0.294913649559021
Batch 59/64 loss: 0.2932320833206177
Batch 60/64 loss: 0.2922501564025879
Batch 61/64 loss: 0.2958124876022339
Batch 62/64 loss: 0.2856789827346802
Batch 63/64 loss: 0.2930728793144226
Batch 64/64 loss: 0.3054487109184265
Epoch 220  Train loss: 0.29187756543065985  Val loss: 0.31503971520158436
Epoch 221
-------------------------------
Batch 1/64 loss: 0.2921912670135498
Batch 2/64 loss: 0.2873190641403198
Batch 3/64 loss: 0.2888067960739136
Batch 4/64 loss: 0.29797273874282837
Batch 5/64 loss: 0.2969832420349121
Batch 6/64 loss: 0.2870640754699707
Batch 7/64 loss: 0.28704243898391724
Batch 8/64 loss: 0.28836846351623535
Batch 9/64 loss: 0.28734588623046875
Batch 10/64 loss: 0.29491692781448364
Batch 11/64 loss: 0.2931840419769287
Batch 12/64 loss: 0.2987107038497925
Batch 13/64 loss: 0.29678547382354736
Batch 14/64 loss: 0.2910810708999634
Batch 15/64 loss: 0.28922760486602783
Batch 16/64 loss: 0.29219114780426025
Batch 17/64 loss: 0.29079824686050415
Batch 18/64 loss: 0.29442453384399414
Batch 19/64 loss: 0.29994767904281616
Batch 20/64 loss: 0.3023742437362671
Batch 21/64 loss: 0.2934111952781677
Batch 22/64 loss: 0.29187309741973877
Batch 23/64 loss: 0.28909462690353394
Batch 24/64 loss: 0.2910315990447998
Batch 25/64 loss: 0.28884637355804443
Batch 26/64 loss: 0.28704380989074707
Batch 27/64 loss: 0.29635369777679443
Batch 28/64 loss: 0.294913649559021
Batch 29/64 loss: 0.29387927055358887
Batch 30/64 loss: 0.293235719203949
Batch 31/64 loss: 0.28737813234329224
Batch 32/64 loss: 0.28919172286987305
Batch 33/64 loss: 0.294561505317688
Batch 34/64 loss: 0.29297369718551636
Batch 35/64 loss: 0.2911151647567749
Batch 36/64 loss: 0.29066038131713867
Batch 37/64 loss: 0.2845485210418701
Batch 38/64 loss: 0.2961485981941223
Batch 39/64 loss: 0.29112672805786133
Batch 40/64 loss: 0.29068058729171753
Batch 41/64 loss: 0.28447097539901733
Batch 42/64 loss: 0.3037647008895874
Batch 43/64 loss: 0.2875553369522095
Batch 44/64 loss: 0.29627734422683716
Batch 45/64 loss: 0.285459041595459
Batch 46/64 loss: 0.2894909381866455
Batch 47/64 loss: 0.2933024764060974
Batch 48/64 loss: 0.29643672704696655
Batch 49/64 loss: 0.2902300953865051
Batch 50/64 loss: 0.28777599334716797
Batch 51/64 loss: 0.29970991611480713
Batch 52/64 loss: 0.2944374084472656
Batch 53/64 loss: 0.2915686368942261
Batch 54/64 loss: 0.2935969829559326
Batch 55/64 loss: 0.2936442494392395
Batch 56/64 loss: 0.29411572217941284
Batch 57/64 loss: 0.2889530658721924
Batch 58/64 loss: 0.29209524393081665
Batch 59/64 loss: 0.3001539707183838
Batch 60/64 loss: 0.287730872631073
Batch 61/64 loss: 0.29437828063964844
Batch 62/64 loss: 0.2909773588180542
Batch 63/64 loss: 0.288646936416626
Batch 64/64 loss: 0.2948654294013977
Epoch 221  Train loss: 0.29224666777779074  Val loss: 0.31519318651087913
Epoch 222
-------------------------------
Batch 1/64 loss: 0.2869452238082886
Batch 2/64 loss: 0.2825990915298462
Batch 3/64 loss: 0.29282814264297485
Batch 4/64 loss: 0.2846420407295227
Batch 5/64 loss: 0.29423201084136963
Batch 6/64 loss: 0.2946539521217346
Batch 7/64 loss: 0.2845369577407837
Batch 8/64 loss: 0.2941092252731323
Batch 9/64 loss: 0.29503118991851807
Batch 10/64 loss: 0.2878824472427368
Batch 11/64 loss: 0.291515588760376
Batch 12/64 loss: 0.2887026071548462
Batch 13/64 loss: 0.2913735508918762
Batch 14/64 loss: 0.2914910316467285
Batch 15/64 loss: 0.2986370325088501
Batch 16/64 loss: 0.29067039489746094
Batch 17/64 loss: 0.28852522373199463
Batch 18/64 loss: 0.2957373261451721
Batch 19/64 loss: 0.29330629110336304
Batch 20/64 loss: 0.29396724700927734
Batch 21/64 loss: 0.2879059314727783
Batch 22/64 loss: 0.29199475049972534
Batch 23/64 loss: 0.29510533809661865
Batch 24/64 loss: 0.29466813802719116
Batch 25/64 loss: 0.2901444435119629
Batch 26/64 loss: 0.29548555612564087
Batch 27/64 loss: 0.2893884778022766
Batch 28/64 loss: 0.29218727350234985
Batch 29/64 loss: 0.28440648317337036
Batch 30/64 loss: 0.288196325302124
Batch 31/64 loss: 0.28390026092529297
Batch 32/64 loss: 0.2897990942001343
Batch 33/64 loss: 0.28536778688430786
Batch 34/64 loss: 0.2900012731552124
Batch 35/64 loss: 0.29242146015167236
Batch 36/64 loss: 0.29491907358169556
Batch 37/64 loss: 0.29285722970962524
Batch 38/64 loss: 0.2920975685119629
Batch 39/64 loss: 0.28679418563842773
Batch 40/64 loss: 0.29474306106567383
Batch 41/64 loss: 0.2890470027923584
Batch 42/64 loss: 0.3006053566932678
Batch 43/64 loss: 0.2875230312347412
Batch 44/64 loss: 0.2945369482040405
Batch 45/64 loss: 0.2949519157409668
Batch 46/64 loss: 0.2983909845352173
Batch 47/64 loss: 0.2846376299858093
Batch 48/64 loss: 0.29313570261001587
Batch 49/64 loss: 0.28725260496139526
Batch 50/64 loss: 0.2878762483596802
Batch 51/64 loss: 0.28804492950439453
Batch 52/64 loss: 0.2906845211982727
Batch 53/64 loss: 0.28807294368743896
Batch 54/64 loss: 0.2967313528060913
Batch 55/64 loss: 0.29301440715789795
Batch 56/64 loss: 0.2940821051597595
Batch 57/64 loss: 0.2889401912689209
Batch 58/64 loss: 0.28975909948349
Batch 59/64 loss: 0.2928661108016968
Batch 60/64 loss: 0.2879507541656494
Batch 61/64 loss: 0.2947508692741394
Batch 62/64 loss: 0.29522091150283813
Batch 63/64 loss: 0.3004212975502014
Batch 64/64 loss: 0.28714513778686523
Epoch 222  Train loss: 0.29125687935773065  Val loss: 0.31419969096626205
Saving best model, epoch: 222
Epoch 223
-------------------------------
Batch 1/64 loss: 0.28710031509399414
Batch 2/64 loss: 0.29270803928375244
Batch 3/64 loss: 0.29094696044921875
Batch 4/64 loss: 0.2978487014770508
Batch 5/64 loss: 0.2871208190917969
Batch 6/64 loss: 0.29680877923965454
Batch 7/64 loss: 0.2900722622871399
Batch 8/64 loss: 0.2872021198272705
Batch 9/64 loss: 0.2945430278778076
Batch 10/64 loss: 0.287203311920166
Batch 11/64 loss: 0.28935158252716064
Batch 12/64 loss: 0.2875133752822876
Batch 13/64 loss: 0.300187349319458
Batch 14/64 loss: 0.2907681465148926
Batch 15/64 loss: 0.2892073392868042
Batch 16/64 loss: 0.289691686630249
Batch 17/64 loss: 0.29064512252807617
Batch 18/64 loss: 0.2924621105194092
Batch 19/64 loss: 0.28885549306869507
Batch 20/64 loss: 0.29094958305358887
Batch 21/64 loss: 0.29488605260849
Batch 22/64 loss: 0.28874051570892334
Batch 23/64 loss: 0.2904949188232422
Batch 24/64 loss: 0.28967469930648804
Batch 25/64 loss: 0.286818265914917
Batch 26/64 loss: 0.29374825954437256
Batch 27/64 loss: 0.2830202579498291
Batch 28/64 loss: 0.29101765155792236
Batch 29/64 loss: 0.2917518615722656
Batch 30/64 loss: 0.2885575294494629
Batch 31/64 loss: 0.2909376621246338
Batch 32/64 loss: 0.29329007863998413
Batch 33/64 loss: 0.29105430841445923
Batch 34/64 loss: 0.2898736000061035
Batch 35/64 loss: 0.2920912504196167
Batch 36/64 loss: 0.28628355264663696
Batch 37/64 loss: 0.2894592881202698
Batch 38/64 loss: 0.28825438022613525
Batch 39/64 loss: 0.29070550203323364
Batch 40/64 loss: 0.2821660041809082
Batch 41/64 loss: 0.29980039596557617
Batch 42/64 loss: 0.2919555902481079
Batch 43/64 loss: 0.285519003868103
Batch 44/64 loss: 0.30066102743148804
Batch 45/64 loss: 0.2846408486366272
Batch 46/64 loss: 0.2942694425582886
Batch 47/64 loss: 0.2893725633621216
Batch 48/64 loss: 0.2964177131652832
Batch 49/64 loss: 0.29371047019958496
Batch 50/64 loss: 0.289900541305542
Batch 51/64 loss: 0.2962633967399597
Batch 52/64 loss: 0.2981448173522949
Batch 53/64 loss: 0.29034703969955444
Batch 54/64 loss: 0.2872610092163086
Batch 55/64 loss: 0.28883713483810425
Batch 56/64 loss: 0.2919854521751404
Batch 57/64 loss: 0.28966742753982544
Batch 58/64 loss: 0.2855750322341919
Batch 59/64 loss: 0.2889975905418396
Batch 60/64 loss: 0.29388129711151123
Batch 61/64 loss: 0.29377126693725586
Batch 62/64 loss: 0.29215168952941895
Batch 63/64 loss: 0.2938985824584961
Batch 64/64 loss: 0.2872745990753174
Epoch 223  Train loss: 0.29092544387368596  Val loss: 0.314850219131745
Epoch 224
-------------------------------
Batch 1/64 loss: 0.294014036655426
Batch 2/64 loss: 0.2905466556549072
Batch 3/64 loss: 0.2906731367111206
Batch 4/64 loss: 0.28392165899276733
Batch 5/64 loss: 0.2918251156806946
Batch 6/64 loss: 0.294228732585907
Batch 7/64 loss: 0.2872304916381836
Batch 8/64 loss: 0.2836694121360779
Batch 9/64 loss: 0.2950185537338257
Batch 10/64 loss: 0.2894275188446045
Batch 11/64 loss: 0.2950683832168579
Batch 12/64 loss: 0.2916390299797058
Batch 13/64 loss: 0.2910348176956177
Batch 14/64 loss: 0.2961198091506958
Batch 15/64 loss: 0.2955396771430969
Batch 16/64 loss: 0.28927546739578247
Batch 17/64 loss: 0.2822578549385071
Batch 18/64 loss: 0.28603261709213257
Batch 19/64 loss: 0.2847357392311096
Batch 20/64 loss: 0.2925344705581665
Batch 21/64 loss: 0.2895622253417969
Batch 22/64 loss: 0.29640722274780273
Batch 23/64 loss: 0.2896062135696411
Batch 24/64 loss: 0.29389381408691406
Batch 25/64 loss: 0.2848775386810303
Batch 26/64 loss: 0.2879391312599182
Batch 27/64 loss: 0.2899101972579956
Batch 28/64 loss: 0.29371654987335205
Batch 29/64 loss: 0.29352545738220215
Batch 30/64 loss: 0.29098618030548096
Batch 31/64 loss: 0.2945054769515991
Batch 32/64 loss: 0.2913053035736084
Batch 33/64 loss: 0.289323091506958
Batch 34/64 loss: 0.29940855503082275
Batch 35/64 loss: 0.28966373205184937
Batch 36/64 loss: 0.2979244589805603
Batch 37/64 loss: 0.2854127883911133
Batch 38/64 loss: 0.2865636348724365
Batch 39/64 loss: 0.29210859537124634
Batch 40/64 loss: 0.2883594036102295
Batch 41/64 loss: 0.2891693711280823
Batch 42/64 loss: 0.28761786222457886
Batch 43/64 loss: 0.2926260828971863
Batch 44/64 loss: 0.2858344316482544
Batch 45/64 loss: 0.2933105230331421
Batch 46/64 loss: 0.2889789938926697
Batch 47/64 loss: 0.2917096018791199
Batch 48/64 loss: 0.28749072551727295
Batch 49/64 loss: 0.28488945960998535
Batch 50/64 loss: 0.29867517948150635
Batch 51/64 loss: 0.29468607902526855
Batch 52/64 loss: 0.2926764488220215
Batch 53/64 loss: 0.2963884472846985
Batch 54/64 loss: 0.28316783905029297
Batch 55/64 loss: 0.29020822048187256
Batch 56/64 loss: 0.28523385524749756
Batch 57/64 loss: 0.28856033086776733
Batch 58/64 loss: 0.2903992533683777
Batch 59/64 loss: 0.28871357440948486
Batch 60/64 loss: 0.2878822088241577
Batch 61/64 loss: 0.3088206648826599
Batch 62/64 loss: 0.28804534673690796
Batch 63/64 loss: 0.2896997332572937
Batch 64/64 loss: 0.29057931900024414
Epoch 224  Train loss: 0.29070606231689455  Val loss: 0.3148047092444299
Epoch 225
-------------------------------
Batch 1/64 loss: 0.29487645626068115
Batch 2/64 loss: 0.2896881103515625
Batch 3/64 loss: 0.28790557384490967
Batch 4/64 loss: 0.29311758279800415
Batch 5/64 loss: 0.29538512229919434
Batch 6/64 loss: 0.2931675910949707
Batch 7/64 loss: 0.288457453250885
Batch 8/64 loss: 0.28552091121673584
Batch 9/64 loss: 0.2882503271102905
Batch 10/64 loss: 0.2883269786834717
Batch 11/64 loss: 0.28678345680236816
Batch 12/64 loss: 0.29572856426239014
Batch 13/64 loss: 0.2826618552207947
Batch 14/64 loss: 0.29177820682525635
Batch 15/64 loss: 0.30291712284088135
Batch 16/64 loss: 0.2958180904388428
Batch 17/64 loss: 0.28455841541290283
Batch 18/64 loss: 0.2889818549156189
Batch 19/64 loss: 0.29435837268829346
Batch 20/64 loss: 0.2862764596939087
Batch 21/64 loss: 0.29765546321868896
Batch 22/64 loss: 0.28608226776123047
Batch 23/64 loss: 0.28472626209259033
Batch 24/64 loss: 0.29013586044311523
Batch 25/64 loss: 0.283402681350708
Batch 26/64 loss: 0.2870524525642395
Batch 27/64 loss: 0.29054248332977295
Batch 28/64 loss: 0.2865322232246399
Batch 29/64 loss: 0.295082151889801
Batch 30/64 loss: 0.2861976623535156
Batch 31/64 loss: 0.2890866994857788
Batch 32/64 loss: 0.29052257537841797
Batch 33/64 loss: 0.2916826009750366
Batch 34/64 loss: 0.2905271649360657
Batch 35/64 loss: 0.2896864414215088
Batch 36/64 loss: 0.2917119860649109
Batch 37/64 loss: 0.29362785816192627
Batch 38/64 loss: 0.2900630235671997
Batch 39/64 loss: 0.2914116382598877
Batch 40/64 loss: 0.2896050214767456
Batch 41/64 loss: 0.29775261878967285
Batch 42/64 loss: 0.29114699363708496
Batch 43/64 loss: 0.2922148108482361
Batch 44/64 loss: 0.29010915756225586
Batch 45/64 loss: 0.29033660888671875
Batch 46/64 loss: 0.3022534251213074
Batch 47/64 loss: 0.2828991413116455
Batch 48/64 loss: 0.2886925935745239
Batch 49/64 loss: 0.2831343412399292
Batch 50/64 loss: 0.28509652614593506
Batch 51/64 loss: 0.2945491671562195
Batch 52/64 loss: 0.29260289669036865
Batch 53/64 loss: 0.30207574367523193
Batch 54/64 loss: 0.29068219661712646
Batch 55/64 loss: 0.2891275882720947
Batch 56/64 loss: 0.2918098568916321
Batch 57/64 loss: 0.29453587532043457
Batch 58/64 loss: 0.2953309416770935
Batch 59/64 loss: 0.2924414873123169
Batch 60/64 loss: 0.2889447808265686
Batch 61/64 loss: 0.2912067174911499
Batch 62/64 loss: 0.28767144680023193
Batch 63/64 loss: 0.2942028045654297
Batch 64/64 loss: 0.29171937704086304
Epoch 225  Train loss: 0.2907843180731231  Val loss: 0.3139356763911821
Saving best model, epoch: 225
Epoch 226
-------------------------------
Batch 1/64 loss: 0.2975442409515381
Batch 2/64 loss: 0.28979814052581787
Batch 3/64 loss: 0.29623842239379883
Batch 4/64 loss: 0.29037290811538696
Batch 5/64 loss: 0.2914390563964844
Batch 6/64 loss: 0.2849128246307373
Batch 7/64 loss: 0.298395574092865
Batch 8/64 loss: 0.28892838954925537
Batch 9/64 loss: 0.29503893852233887
Batch 10/64 loss: 0.2914402484893799
Batch 11/64 loss: 0.2856009006500244
Batch 12/64 loss: 0.2890208959579468
Batch 13/64 loss: 0.28766608238220215
Batch 14/64 loss: 0.28800177574157715
Batch 15/64 loss: 0.2903239130973816
Batch 16/64 loss: 0.2937896251678467
Batch 17/64 loss: 0.2906200885772705
Batch 18/64 loss: 0.28770768642425537
Batch 19/64 loss: 0.29519718885421753
Batch 20/64 loss: 0.2919462323188782
Batch 21/64 loss: 0.28437358140945435
Batch 22/64 loss: 0.28581488132476807
Batch 23/64 loss: 0.28742772340774536
Batch 24/64 loss: 0.2979309558868408
Batch 25/64 loss: 0.29062026739120483
Batch 26/64 loss: 0.2914338707923889
Batch 27/64 loss: 0.2828715443611145
Batch 28/64 loss: 0.2913864850997925
Batch 29/64 loss: 0.2853469252586365
Batch 30/64 loss: 0.29547882080078125
Batch 31/64 loss: 0.29856884479522705
Batch 32/64 loss: 0.28537416458129883
Batch 33/64 loss: 0.29639142751693726
Batch 34/64 loss: 0.2875235080718994
Batch 35/64 loss: 0.2896127700805664
Batch 36/64 loss: 0.291731595993042
Batch 37/64 loss: 0.2964608669281006
Batch 38/64 loss: 0.2902337908744812
Batch 39/64 loss: 0.2902919054031372
Batch 40/64 loss: 0.2903138995170593
Batch 41/64 loss: 0.289121150970459
Batch 42/64 loss: 0.28704798221588135
Batch 43/64 loss: 0.28729867935180664
Batch 44/64 loss: 0.2907073497772217
Batch 45/64 loss: 0.2860177755355835
Batch 46/64 loss: 0.2945813536643982
Batch 47/64 loss: 0.2911853790283203
Batch 48/64 loss: 0.2922435998916626
Batch 49/64 loss: 0.2921243906021118
Batch 50/64 loss: 0.29346179962158203
Batch 51/64 loss: 0.28943389654159546
Batch 52/64 loss: 0.29047083854675293
Batch 53/64 loss: 0.29102855920791626
Batch 54/64 loss: 0.2867646813392639
Batch 55/64 loss: 0.29673266410827637
Batch 56/64 loss: 0.29294800758361816
Batch 57/64 loss: 0.2902778387069702
Batch 58/64 loss: 0.28214168548583984
Batch 59/64 loss: 0.29548192024230957
Batch 60/64 loss: 0.2951503396034241
Batch 61/64 loss: 0.29133665561676025
Batch 62/64 loss: 0.2815818190574646
Batch 63/64 loss: 0.29190123081207275
Batch 64/64 loss: 0.2906319499015808
Epoch 226  Train loss: 0.2906695611336652  Val loss: 0.31422670456961665
Epoch 227
-------------------------------
Batch 1/64 loss: 0.29126036167144775
Batch 2/64 loss: 0.28281593322753906
Batch 3/64 loss: 0.2838205099105835
Batch 4/64 loss: 0.28885966539382935
Batch 5/64 loss: 0.294666051864624
Batch 6/64 loss: 0.2828965187072754
Batch 7/64 loss: 0.29213404655456543
Batch 8/64 loss: 0.29571962356567383
Batch 9/64 loss: 0.29313480854034424
Batch 10/64 loss: 0.2833597660064697
Batch 11/64 loss: 0.29265207052230835
Batch 12/64 loss: 0.28677886724472046
Batch 13/64 loss: 0.2854899764060974
Batch 14/64 loss: 0.2952733635902405
Batch 15/64 loss: 0.29109299182891846
Batch 16/64 loss: 0.2836422920227051
Batch 17/64 loss: 0.28826719522476196
Batch 18/64 loss: 0.28768742084503174
Batch 19/64 loss: 0.29012155532836914
Batch 20/64 loss: 0.29303205013275146
Batch 21/64 loss: 0.2919454574584961
Batch 22/64 loss: 0.2890951633453369
Batch 23/64 loss: 0.28441542387008667
Batch 24/64 loss: 0.2846139669418335
Batch 25/64 loss: 0.28540849685668945
Batch 26/64 loss: 0.2908756732940674
Batch 27/64 loss: 0.2862575054168701
Batch 28/64 loss: 0.29400503635406494
Batch 29/64 loss: 0.290549635887146
Batch 30/64 loss: 0.2867175340652466
Batch 31/64 loss: 0.28981631994247437
Batch 32/64 loss: 0.2913062572479248
Batch 33/64 loss: 0.2866978645324707
Batch 34/64 loss: 0.2999860644340515
Batch 35/64 loss: 0.2914576530456543
Batch 36/64 loss: 0.28930819034576416
Batch 37/64 loss: 0.2955288887023926
Batch 38/64 loss: 0.29628419876098633
Batch 39/64 loss: 0.29201602935791016
Batch 40/64 loss: 0.29203689098358154
Batch 41/64 loss: 0.29211920499801636
Batch 42/64 loss: 0.2907294034957886
Batch 43/64 loss: 0.29034489393234253
Batch 44/64 loss: 0.28781628608703613
Batch 45/64 loss: 0.2921849489212036
Batch 46/64 loss: 0.28513002395629883
Batch 47/64 loss: 0.2981208562850952
Batch 48/64 loss: 0.29860758781433105
Batch 49/64 loss: 0.2882370352745056
Batch 50/64 loss: 0.29746031761169434
Batch 51/64 loss: 0.2892719507217407
Batch 52/64 loss: 0.2893766760826111
Batch 53/64 loss: 0.28923630714416504
Batch 54/64 loss: 0.2885019779205322
Batch 55/64 loss: 0.30190467834472656
Batch 56/64 loss: 0.29088062047958374
Batch 57/64 loss: 0.2946794033050537
Batch 58/64 loss: 0.28649020195007324
Batch 59/64 loss: 0.28891628980636597
Batch 60/64 loss: 0.2887127995491028
Batch 61/64 loss: 0.2959868907928467
Batch 62/64 loss: 0.29150480031967163
Batch 63/64 loss: 0.2885642647743225
Batch 64/64 loss: 0.29245245456695557
Epoch 227  Train loss: 0.290433632626253  Val loss: 0.31491880380001264
Epoch 228
-------------------------------
Batch 1/64 loss: 0.29240596294403076
Batch 2/64 loss: 0.290649950504303
Batch 3/64 loss: 0.28902244567871094
Batch 4/64 loss: 0.28600776195526123
Batch 5/64 loss: 0.2876827120780945
Batch 6/64 loss: 0.29030150175094604
Batch 7/64 loss: 0.2960679531097412
Batch 8/64 loss: 0.28570252656936646
Batch 9/64 loss: 0.28496092557907104
Batch 10/64 loss: 0.2930111289024353
Batch 11/64 loss: 0.28835034370422363
Batch 12/64 loss: 0.2967686057090759
Batch 13/64 loss: 0.2947200536727905
Batch 14/64 loss: 0.2962833642959595
Batch 15/64 loss: 0.2898380160331726
Batch 16/64 loss: 0.2867625951766968
Batch 17/64 loss: 0.2856457233428955
Batch 18/64 loss: 0.2962483763694763
Batch 19/64 loss: 0.2889135479927063
Batch 20/64 loss: 0.29261070489883423
Batch 21/64 loss: 0.2902470827102661
Batch 22/64 loss: 0.28593987226486206
Batch 23/64 loss: 0.2871522307395935
Batch 24/64 loss: 0.30022990703582764
Batch 25/64 loss: 0.2917066812515259
Batch 26/64 loss: 0.28393083810806274
Batch 27/64 loss: 0.2837989926338196
Batch 28/64 loss: 0.2931397557258606
Batch 29/64 loss: 0.2847428321838379
Batch 30/64 loss: 0.29122745990753174
Batch 31/64 loss: 0.2987194061279297
Batch 32/64 loss: 0.2864925265312195
Batch 33/64 loss: 0.28142547607421875
Batch 34/64 loss: 0.289817214012146
Batch 35/64 loss: 0.28552258014678955
Batch 36/64 loss: 0.28302037715911865
Batch 37/64 loss: 0.2858930826187134
Batch 38/64 loss: 0.29029297828674316
Batch 39/64 loss: 0.28749412298202515
Batch 40/64 loss: 0.28446251153945923
Batch 41/64 loss: 0.2856564521789551
Batch 42/64 loss: 0.28750866651535034
Batch 43/64 loss: 0.28484272956848145
Batch 44/64 loss: 0.29605579376220703
Batch 45/64 loss: 0.2907238006591797
Batch 46/64 loss: 0.2913050651550293
Batch 47/64 loss: 0.2979689836502075
Batch 48/64 loss: 0.2904775142669678
Batch 49/64 loss: 0.284837543964386
Batch 50/64 loss: 0.2839844226837158
Batch 51/64 loss: 0.2828831672668457
Batch 52/64 loss: 0.29967087507247925
Batch 53/64 loss: 0.29403388500213623
Batch 54/64 loss: 0.29388654232025146
Batch 55/64 loss: 0.2879446744918823
Batch 56/64 loss: 0.2963446378707886
Batch 57/64 loss: 0.28919780254364014
Batch 58/64 loss: 0.30389660596847534
Batch 59/64 loss: 0.28920847177505493
Batch 60/64 loss: 0.29099392890930176
Batch 61/64 loss: 0.2865247130393982
Batch 62/64 loss: 0.2842259407043457
Batch 63/64 loss: 0.29585063457489014
Batch 64/64 loss: 0.2890179753303528
Epoch 228  Train loss: 0.2899136699882208  Val loss: 0.3155307319156083
Epoch 229
-------------------------------
Batch 1/64 loss: 0.28717219829559326
Batch 2/64 loss: 0.28744369745254517
Batch 3/64 loss: 0.2854236364364624
Batch 4/64 loss: 0.28708112239837646
Batch 5/64 loss: 0.2917998433113098
Batch 6/64 loss: 0.29814422130584717
Batch 7/64 loss: 0.2831073999404907
Batch 8/64 loss: 0.2848440408706665
Batch 9/64 loss: 0.2900708317756653
Batch 10/64 loss: 0.28781449794769287
Batch 11/64 loss: 0.28587567806243896
Batch 12/64 loss: 0.2904626131057739
Batch 13/64 loss: 0.29239553213119507
Batch 14/64 loss: 0.2892906665802002
Batch 15/64 loss: 0.29424548149108887
Batch 16/64 loss: 0.2902047634124756
Batch 17/64 loss: 0.2908969521522522
Batch 18/64 loss: 0.2861638069152832
Batch 19/64 loss: 0.29276371002197266
Batch 20/64 loss: 0.288105845451355
Batch 21/64 loss: 0.2858881950378418
Batch 22/64 loss: 0.28862881660461426
Batch 23/64 loss: 0.2906913161277771
Batch 24/64 loss: 0.2916980981826782
Batch 25/64 loss: 0.28780776262283325
Batch 26/64 loss: 0.2912166118621826
Batch 27/64 loss: 0.2960723638534546
Batch 28/64 loss: 0.28571760654449463
Batch 29/64 loss: 0.29017359018325806
Batch 30/64 loss: 0.28946030139923096
Batch 31/64 loss: 0.2974584102630615
Batch 32/64 loss: 0.2878389358520508
Batch 33/64 loss: 0.28670787811279297
Batch 34/64 loss: 0.29364538192749023
Batch 35/64 loss: 0.2969856262207031
Batch 36/64 loss: 0.2837916612625122
Batch 37/64 loss: 0.2908364534378052
Batch 38/64 loss: 0.28909945487976074
Batch 39/64 loss: 0.2922435402870178
Batch 40/64 loss: 0.2881741523742676
Batch 41/64 loss: 0.2907833456993103
Batch 42/64 loss: 0.28769445419311523
Batch 43/64 loss: 0.29722094535827637
Batch 44/64 loss: 0.28455644845962524
Batch 45/64 loss: 0.2969248294830322
Batch 46/64 loss: 0.28797852993011475
Batch 47/64 loss: 0.2928081750869751
Batch 48/64 loss: 0.2908651828765869
Batch 49/64 loss: 0.2886238694190979
Batch 50/64 loss: 0.3007950186729431
Batch 51/64 loss: 0.28449881076812744
Batch 52/64 loss: 0.28923022747039795
Batch 53/64 loss: 0.2961733937263489
Batch 54/64 loss: 0.290766179561615
Batch 55/64 loss: 0.2886132001876831
Batch 56/64 loss: 0.28915834426879883
Batch 57/64 loss: 0.29143035411834717
Batch 58/64 loss: 0.2947846055030823
Batch 59/64 loss: 0.2858656048774719
Batch 60/64 loss: 0.293973445892334
Batch 61/64 loss: 0.2918962240219116
Batch 62/64 loss: 0.28420448303222656
Batch 63/64 loss: 0.2961636781692505
Batch 64/64 loss: 0.29318952560424805
Epoch 229  Train loss: 0.2902328500560686  Val loss: 0.3166960080464681
Epoch 230
-------------------------------
Batch 1/64 loss: 0.2879824638366699
Batch 2/64 loss: 0.28305160999298096
Batch 3/64 loss: 0.28468024730682373
Batch 4/64 loss: 0.2905632257461548
Batch 5/64 loss: 0.28611046075820923
Batch 6/64 loss: 0.2915487289428711
Batch 7/64 loss: 0.2912529706954956
Batch 8/64 loss: 0.28764253854751587
Batch 9/64 loss: 0.27913451194763184
Batch 10/64 loss: 0.2864721417427063
Batch 11/64 loss: 0.2900490164756775
Batch 12/64 loss: 0.2906595468521118
Batch 13/64 loss: 0.2883187532424927
Batch 14/64 loss: 0.29018211364746094
Batch 15/64 loss: 0.2890424132347107
Batch 16/64 loss: 0.29719746112823486
Batch 17/64 loss: 0.28430402278900146
Batch 18/64 loss: 0.2920127511024475
Batch 19/64 loss: 0.2896465063095093
Batch 20/64 loss: 0.29224109649658203
Batch 21/64 loss: 0.2863911986351013
Batch 22/64 loss: 0.2842559814453125
Batch 23/64 loss: 0.29102492332458496
Batch 24/64 loss: 0.2946091890335083
Batch 25/64 loss: 0.2908766269683838
Batch 26/64 loss: 0.29261910915374756
Batch 27/64 loss: 0.2919684648513794
Batch 28/64 loss: 0.28843116760253906
Batch 29/64 loss: 0.28727030754089355
Batch 30/64 loss: 0.2924795150756836
Batch 31/64 loss: 0.28760695457458496
Batch 32/64 loss: 0.292077898979187
Batch 33/64 loss: 0.2861645221710205
Batch 34/64 loss: 0.29739630222320557
Batch 35/64 loss: 0.28919005393981934
Batch 36/64 loss: 0.2915862798690796
Batch 37/64 loss: 0.28251343965530396
Batch 38/64 loss: 0.28839898109436035
Batch 39/64 loss: 0.2819638252258301
Batch 40/64 loss: 0.2929553985595703
Batch 41/64 loss: 0.2889471650123596
Batch 42/64 loss: 0.2882384657859802
Batch 43/64 loss: 0.2950518727302551
Batch 44/64 loss: 0.28531819581985474
Batch 45/64 loss: 0.2857697010040283
Batch 46/64 loss: 0.2886843681335449
Batch 47/64 loss: 0.29224228858947754
Batch 48/64 loss: 0.28736603260040283
Batch 49/64 loss: 0.2947181463241577
Batch 50/64 loss: 0.2932159900665283
Batch 51/64 loss: 0.29170501232147217
Batch 52/64 loss: 0.304424524307251
Batch 53/64 loss: 0.2897801399230957
Batch 54/64 loss: 0.2954956889152527
Batch 55/64 loss: 0.2884645462036133
Batch 56/64 loss: 0.2886849641799927
Batch 57/64 loss: 0.300095796585083
Batch 58/64 loss: 0.2892264723777771
Batch 59/64 loss: 0.2897334694862366
Batch 60/64 loss: 0.28814804553985596
Batch 61/64 loss: 0.29297804832458496
Batch 62/64 loss: 0.28746938705444336
Batch 63/64 loss: 0.29056620597839355
Batch 64/64 loss: 0.29692918062210083
Epoch 230  Train loss: 0.2898963785638996  Val loss: 0.3150189279280987
Epoch 231
-------------------------------
Batch 1/64 loss: 0.28820371627807617
Batch 2/64 loss: 0.2842021584510803
Batch 3/64 loss: 0.2843797206878662
Batch 4/64 loss: 0.2970135807991028
Batch 5/64 loss: 0.2916356325149536
Batch 6/64 loss: 0.2959463596343994
Batch 7/64 loss: 0.2955208420753479
Batch 8/64 loss: 0.2920922040939331
Batch 9/64 loss: 0.28741025924682617
Batch 10/64 loss: 0.2909199595451355
Batch 11/64 loss: 0.2899075746536255
Batch 12/64 loss: 0.28807419538497925
Batch 13/64 loss: 0.2853999733924866
Batch 14/64 loss: 0.2936530113220215
Batch 15/64 loss: 0.2892051339149475
Batch 16/64 loss: 0.2900466322898865
Batch 17/64 loss: 0.2901008129119873
Batch 18/64 loss: 0.29076921939849854
Batch 19/64 loss: 0.29378437995910645
Batch 20/64 loss: 0.2873789072036743
Batch 21/64 loss: 0.2865222692489624
Batch 22/64 loss: 0.2929809093475342
Batch 23/64 loss: 0.2873600125312805
Batch 24/64 loss: 0.2900242805480957
Batch 25/64 loss: 0.29312872886657715
Batch 26/64 loss: 0.28739476203918457
Batch 27/64 loss: 0.28617632389068604
Batch 28/64 loss: 0.29579323530197144
Batch 29/64 loss: 0.28692901134490967
Batch 30/64 loss: 0.2858349084854126
Batch 31/64 loss: 0.2795235514640808
Batch 32/64 loss: 0.28753435611724854
Batch 33/64 loss: 0.29018425941467285
Batch 34/64 loss: 0.29173743724823
Batch 35/64 loss: 0.2880168557167053
Batch 36/64 loss: 0.284368634223938
Batch 37/64 loss: 0.28918153047561646
Batch 38/64 loss: 0.287689208984375
Batch 39/64 loss: 0.30220532417297363
Batch 40/64 loss: 0.29157209396362305
Batch 41/64 loss: 0.28845763206481934
Batch 42/64 loss: 0.2851041555404663
Batch 43/64 loss: 0.29079973697662354
Batch 44/64 loss: 0.28783392906188965
Batch 45/64 loss: 0.28854602575302124
Batch 46/64 loss: 0.2914621829986572
Batch 47/64 loss: 0.2849820852279663
Batch 48/64 loss: 0.287802517414093
Batch 49/64 loss: 0.2907729148864746
Batch 50/64 loss: 0.2941814064979553
Batch 51/64 loss: 0.2879682779312134
Batch 52/64 loss: 0.294735312461853
Batch 53/64 loss: 0.289181649684906
Batch 54/64 loss: 0.28551459312438965
Batch 55/64 loss: 0.2903980016708374
Batch 56/64 loss: 0.2852252721786499
Batch 57/64 loss: 0.2883647680282593
Batch 58/64 loss: 0.2842528820037842
Batch 59/64 loss: 0.2847769856452942
Batch 60/64 loss: 0.2903926968574524
Batch 61/64 loss: 0.28873372077941895
Batch 62/64 loss: 0.29506516456604004
Batch 63/64 loss: 0.29105114936828613
Batch 64/64 loss: 0.2918238639831543
Epoch 231  Train loss: 0.289478790993784  Val loss: 0.31380250998788684
Saving best model, epoch: 231
Epoch 232
-------------------------------
Batch 1/64 loss: 0.28983354568481445
Batch 2/64 loss: 0.2887028455734253
Batch 3/64 loss: 0.2889578342437744
Batch 4/64 loss: 0.28769028186798096
Batch 5/64 loss: 0.289772093296051
Batch 6/64 loss: 0.29183709621429443
Batch 7/64 loss: 0.28650355339050293
Batch 8/64 loss: 0.27879035472869873
Batch 9/64 loss: 0.3001190423965454
Batch 10/64 loss: 0.28303664922714233
Batch 11/64 loss: 0.2911120653152466
Batch 12/64 loss: 0.29059290885925293
Batch 13/64 loss: 0.2874410152435303
Batch 14/64 loss: 0.2863721251487732
Batch 15/64 loss: 0.2903504967689514
Batch 16/64 loss: 0.2961103916168213
Batch 17/64 loss: 0.28415346145629883
Batch 18/64 loss: 0.2969902753829956
Batch 19/64 loss: 0.286918580532074
Batch 20/64 loss: 0.2849760055541992
Batch 21/64 loss: 0.2851178050041199
Batch 22/64 loss: 0.2908325791358948
Batch 23/64 loss: 0.2910427451133728
Batch 24/64 loss: 0.28778135776519775
Batch 25/64 loss: 0.29243433475494385
Batch 26/64 loss: 0.28857922554016113
Batch 27/64 loss: 0.29593831300735474
Batch 28/64 loss: 0.3004347085952759
Batch 29/64 loss: 0.28871268033981323
Batch 30/64 loss: 0.28994786739349365
Batch 31/64 loss: 0.287234365940094
Batch 32/64 loss: 0.2923033833503723
Batch 33/64 loss: 0.2872833013534546
Batch 34/64 loss: 0.2953689694404602
Batch 35/64 loss: 0.29354989528656006
Batch 36/64 loss: 0.29339510202407837
Batch 37/64 loss: 0.2925676107406616
Batch 38/64 loss: 0.2927336096763611
Batch 39/64 loss: 0.28802764415740967
Batch 40/64 loss: 0.29520440101623535
Batch 41/64 loss: 0.2936646342277527
Batch 42/64 loss: 0.29013746976852417
Batch 43/64 loss: 0.2915019392967224
Batch 44/64 loss: 0.28907495737075806
Batch 45/64 loss: 0.28755271434783936
Batch 46/64 loss: 0.2855575680732727
Batch 47/64 loss: 0.2851971387863159
Batch 48/64 loss: 0.2903965711593628
Batch 49/64 loss: 0.2884174585342407
Batch 50/64 loss: 0.28296995162963867
Batch 51/64 loss: 0.2898743152618408
Batch 52/64 loss: 0.285741925239563
Batch 53/64 loss: 0.29707109928131104
Batch 54/64 loss: 0.2886791229248047
Batch 55/64 loss: 0.30088722705841064
Batch 56/64 loss: 0.28738415241241455
Batch 57/64 loss: 0.2841697931289673
Batch 58/64 loss: 0.2934167981147766
Batch 59/64 loss: 0.2897704839706421
Batch 60/64 loss: 0.2889043092727661
Batch 61/64 loss: 0.28656017780303955
Batch 62/64 loss: 0.2885788679122925
Batch 63/64 loss: 0.2953307032585144
Batch 64/64 loss: 0.2896472215652466
Epoch 232  Train loss: 0.2899894167395199  Val loss: 0.31531331793139483
Epoch 233
-------------------------------
Batch 1/64 loss: 0.2836974859237671
Batch 2/64 loss: 0.2815929055213928
Batch 3/64 loss: 0.2884629964828491
Batch 4/64 loss: 0.28985071182250977
Batch 5/64 loss: 0.28868842124938965
Batch 6/64 loss: 0.29858046770095825
Batch 7/64 loss: 0.2867920398712158
Batch 8/64 loss: 0.29141151905059814
Batch 9/64 loss: 0.2896796464920044
Batch 10/64 loss: 0.2922452688217163
Batch 11/64 loss: 0.2961132526397705
Batch 12/64 loss: 0.2935294508934021
Batch 13/64 loss: 0.28107136487960815
Batch 14/64 loss: 0.29000669717788696
Batch 15/64 loss: 0.28984034061431885
Batch 16/64 loss: 0.28694283962249756
Batch 17/64 loss: 0.28723669052124023
Batch 18/64 loss: 0.2865080237388611
Batch 19/64 loss: 0.2886970043182373
Batch 20/64 loss: 0.29096704721450806
Batch 21/64 loss: 0.290274977684021
Batch 22/64 loss: 0.2857481837272644
Batch 23/64 loss: 0.29381370544433594
Batch 24/64 loss: 0.2899099588394165
Batch 25/64 loss: 0.296464204788208
Batch 26/64 loss: 0.2924022674560547
Batch 27/64 loss: 0.28560739755630493
Batch 28/64 loss: 0.29201769828796387
Batch 29/64 loss: 0.2888500690460205
Batch 30/64 loss: 0.2982947826385498
Batch 31/64 loss: 0.28584617376327515
Batch 32/64 loss: 0.28691017627716064
Batch 33/64 loss: 0.2832406759262085
Batch 34/64 loss: 0.2875385284423828
Batch 35/64 loss: 0.28585004806518555
Batch 36/64 loss: 0.28051406145095825
Batch 37/64 loss: 0.2866092324256897
Batch 38/64 loss: 0.28773730993270874
Batch 39/64 loss: 0.2886636257171631
Batch 40/64 loss: 0.286601722240448
Batch 41/64 loss: 0.2835448980331421
Batch 42/64 loss: 0.29471755027770996
Batch 43/64 loss: 0.29453426599502563
Batch 44/64 loss: 0.2872394323348999
Batch 45/64 loss: 0.2903755307197571
Batch 46/64 loss: 0.3001534938812256
Batch 47/64 loss: 0.28368788957595825
Batch 48/64 loss: 0.28524887561798096
Batch 49/64 loss: 0.2944023609161377
Batch 50/64 loss: 0.2933565378189087
Batch 51/64 loss: 0.29026705026626587
Batch 52/64 loss: 0.2905031442642212
Batch 53/64 loss: 0.2840498089790344
Batch 54/64 loss: 0.2918732166290283
Batch 55/64 loss: 0.2917829155921936
Batch 56/64 loss: 0.28839510679244995
Batch 57/64 loss: 0.28309571743011475
Batch 58/64 loss: 0.29892194271087646
Batch 59/64 loss: 0.28679800033569336
Batch 60/64 loss: 0.29554611444473267
Batch 61/64 loss: 0.2864524722099304
Batch 62/64 loss: 0.29331815242767334
Batch 63/64 loss: 0.29004108905792236
Batch 64/64 loss: 0.29472416639328003
Epoch 233  Train loss: 0.2894769829862258  Val loss: 0.3135136531800339
Saving best model, epoch: 233
Epoch 234
-------------------------------
Batch 1/64 loss: 0.2824774980545044
Batch 2/64 loss: 0.28895455598831177
Batch 3/64 loss: 0.28645992279052734
Batch 4/64 loss: 0.2908288836479187
Batch 5/64 loss: 0.2951146960258484
Batch 6/64 loss: 0.28826576471328735
Batch 7/64 loss: 0.29187309741973877
Batch 8/64 loss: 0.28735774755477905
Batch 9/64 loss: 0.2834698557853699
Batch 10/64 loss: 0.2912895083427429
Batch 11/64 loss: 0.2838021516799927
Batch 12/64 loss: 0.28348225355148315
Batch 13/64 loss: 0.28653573989868164
Batch 14/64 loss: 0.2876836061477661
Batch 15/64 loss: 0.2898160219192505
Batch 16/64 loss: 0.2935972213745117
Batch 17/64 loss: 0.2858353853225708
Batch 18/64 loss: 0.28184837102890015
Batch 19/64 loss: 0.2955993413925171
Batch 20/64 loss: 0.2869945764541626
Batch 21/64 loss: 0.29282402992248535
Batch 22/64 loss: 0.2855316996574402
Batch 23/64 loss: 0.2914760112762451
Batch 24/64 loss: 0.28547394275665283
Batch 25/64 loss: 0.2838066816329956
Batch 26/64 loss: 0.28983843326568604
Batch 27/64 loss: 0.2914918065071106
Batch 28/64 loss: 0.28625166416168213
Batch 29/64 loss: 0.28820955753326416
Batch 30/64 loss: 0.2904622554779053
Batch 31/64 loss: 0.2861809730529785
Batch 32/64 loss: 0.29196202754974365
Batch 33/64 loss: 0.2920762896537781
Batch 34/64 loss: 0.29115432500839233
Batch 35/64 loss: 0.292364239692688
Batch 36/64 loss: 0.29069387912750244
Batch 37/64 loss: 0.2907818555831909
Batch 38/64 loss: 0.29051029682159424
Batch 39/64 loss: 0.2804778814315796
Batch 40/64 loss: 0.2976914644241333
Batch 41/64 loss: 0.29481810331344604
Batch 42/64 loss: 0.2915916442871094
Batch 43/64 loss: 0.3027723431587219
Batch 44/64 loss: 0.29051947593688965
Batch 45/64 loss: 0.28950566053390503
Batch 46/64 loss: 0.28697919845581055
Batch 47/64 loss: 0.2995169162750244
Batch 48/64 loss: 0.287797212600708
Batch 49/64 loss: 0.2861625552177429
Batch 50/64 loss: 0.2877899408340454
Batch 51/64 loss: 0.2869037389755249
Batch 52/64 loss: 0.28985148668289185
Batch 53/64 loss: 0.2930668592453003
Batch 54/64 loss: 0.29475438594818115
Batch 55/64 loss: 0.280580997467041
Batch 56/64 loss: 0.2937958240509033
Batch 57/64 loss: 0.28767454624176025
Batch 58/64 loss: 0.28454458713531494
Batch 59/64 loss: 0.2950984239578247
Batch 60/64 loss: 0.28985297679901123
Batch 61/64 loss: 0.29157400131225586
Batch 62/64 loss: 0.28925466537475586
Batch 63/64 loss: 0.285689115524292
Batch 64/64 loss: 0.2853098511695862
Epoch 234  Train loss: 0.2893274127268324  Val loss: 0.3138647949982345
Epoch 235
-------------------------------
Batch 1/64 loss: 0.2846772074699402
Batch 2/64 loss: 0.30118298530578613
Batch 3/64 loss: 0.2879725694656372
Batch 4/64 loss: 0.2884953022003174
Batch 5/64 loss: 0.29122763872146606
Batch 6/64 loss: 0.29064834117889404
Batch 7/64 loss: 0.29058271646499634
Batch 8/64 loss: 0.2856649160385132
Batch 9/64 loss: 0.2919386625289917
Batch 10/64 loss: 0.28834211826324463
Batch 11/64 loss: 0.28787606954574585
Batch 12/64 loss: 0.28617846965789795
Batch 13/64 loss: 0.28358662128448486
Batch 14/64 loss: 0.2843986749649048
Batch 15/64 loss: 0.2927283048629761
Batch 16/64 loss: 0.2900351285934448
Batch 17/64 loss: 0.2888661026954651
Batch 18/64 loss: 0.28667694330215454
Batch 19/64 loss: 0.2829451560974121
Batch 20/64 loss: 0.28252291679382324
Batch 21/64 loss: 0.29121625423431396
Batch 22/64 loss: 0.2906564474105835
Batch 23/64 loss: 0.2901303768157959
Batch 24/64 loss: 0.2887886166572571
Batch 25/64 loss: 0.2886788249015808
Batch 26/64 loss: 0.2953638434410095
Batch 27/64 loss: 0.2939338684082031
Batch 28/64 loss: 0.2853950262069702
Batch 29/64 loss: 0.28604161739349365
Batch 30/64 loss: 0.29657989740371704
Batch 31/64 loss: 0.2936593294143677
Batch 32/64 loss: 0.29440951347351074
Batch 33/64 loss: 0.28995025157928467
Batch 34/64 loss: 0.28629451990127563
Batch 35/64 loss: 0.2905181646347046
Batch 36/64 loss: 0.2901691198348999
Batch 37/64 loss: 0.28147363662719727
Batch 38/64 loss: 0.2841891050338745
Batch 39/64 loss: 0.2836015224456787
Batch 40/64 loss: 0.28779345750808716
Batch 41/64 loss: 0.28878432512283325
Batch 42/64 loss: 0.2877284288406372
Batch 43/64 loss: 0.284771203994751
Batch 44/64 loss: 0.287716269493103
Batch 45/64 loss: 0.28730231523513794
Batch 46/64 loss: 0.28993505239486694
Batch 47/64 loss: 0.28819769620895386
Batch 48/64 loss: 0.2928810715675354
Batch 49/64 loss: 0.2911190986633301
Batch 50/64 loss: 0.28940051794052124
Batch 51/64 loss: 0.2871180772781372
Batch 52/64 loss: 0.2841939926147461
Batch 53/64 loss: 0.2797779440879822
Batch 54/64 loss: 0.294897198677063
Batch 55/64 loss: 0.2756250500679016
Batch 56/64 loss: 0.28829389810562134
Batch 57/64 loss: 0.2857365012168884
Batch 58/64 loss: 0.29168498516082764
Batch 59/64 loss: 0.29040735960006714
Batch 60/64 loss: 0.2943078279495239
Batch 61/64 loss: 0.28614991903305054
Batch 62/64 loss: 0.294980525970459
Batch 63/64 loss: 0.2958347797393799
Batch 64/64 loss: 0.2866485118865967
Epoch 235  Train loss: 0.2887407162610222  Val loss: 0.3148795515810911
Epoch 236
-------------------------------
Batch 1/64 loss: 0.2877538204193115
Batch 2/64 loss: 0.29757893085479736
Batch 3/64 loss: 0.2925571799278259
Batch 4/64 loss: 0.2823702096939087
Batch 5/64 loss: 0.2947046160697937
Batch 6/64 loss: 0.2834504246711731
Batch 7/64 loss: 0.2886073589324951
Batch 8/64 loss: 0.29209983348846436
Batch 9/64 loss: 0.29091501235961914
Batch 10/64 loss: 0.28976404666900635
Batch 11/64 loss: 0.28606104850769043
Batch 12/64 loss: 0.28565460443496704
Batch 13/64 loss: 0.2816634178161621
Batch 14/64 loss: 0.28760194778442383
Batch 15/64 loss: 0.28733789920806885
Batch 16/64 loss: 0.2892270088195801
Batch 17/64 loss: 0.2895313501358032
Batch 18/64 loss: 0.2917778491973877
Batch 19/64 loss: 0.29337751865386963
Batch 20/64 loss: 0.2905782461166382
Batch 21/64 loss: 0.28670644760131836
Batch 22/64 loss: 0.29020917415618896
Batch 23/64 loss: 0.2962520122528076
Batch 24/64 loss: 0.284076988697052
Batch 25/64 loss: 0.28558361530303955
Batch 26/64 loss: 0.2825202941894531
Batch 27/64 loss: 0.28523075580596924
Batch 28/64 loss: 0.29181474447250366
Batch 29/64 loss: 0.2930014729499817
Batch 30/64 loss: 0.29908204078674316
Batch 31/64 loss: 0.291467547416687
Batch 32/64 loss: 0.2907513380050659
Batch 33/64 loss: 0.28995949029922485
Batch 34/64 loss: 0.2941291332244873
Batch 35/64 loss: 0.2923063635826111
Batch 36/64 loss: 0.2936643362045288
Batch 37/64 loss: 0.28150272369384766
Batch 38/64 loss: 0.2942044734954834
Batch 39/64 loss: 0.2868604063987732
Batch 40/64 loss: 0.28759366273880005
Batch 41/64 loss: 0.2888181805610657
Batch 42/64 loss: 0.2858710289001465
Batch 43/64 loss: 0.28774118423461914
Batch 44/64 loss: 0.28727293014526367
Batch 45/64 loss: 0.2896575927734375
Batch 46/64 loss: 0.28785407543182373
Batch 47/64 loss: 0.27823400497436523
Batch 48/64 loss: 0.2856578826904297
Batch 49/64 loss: 0.2908724546432495
Batch 50/64 loss: 0.2848151922225952
Batch 51/64 loss: 0.3025738596916199
Batch 52/64 loss: 0.2952195405960083
Batch 53/64 loss: 0.2825714349746704
Batch 54/64 loss: 0.28512293100357056
Batch 55/64 loss: 0.2887430191040039
Batch 56/64 loss: 0.28271031379699707
Batch 57/64 loss: 0.2910197973251343
Batch 58/64 loss: 0.28768736124038696
Batch 59/64 loss: 0.28608816862106323
Batch 60/64 loss: 0.28539133071899414
Batch 61/64 loss: 0.2867112159729004
Batch 62/64 loss: 0.2844955325126648
Batch 63/64 loss: 0.2849445939064026
Batch 64/64 loss: 0.28807932138442993
Epoch 236  Train loss: 0.28871627391553395  Val loss: 0.31416774267183545
Epoch 237
-------------------------------
Batch 1/64 loss: 0.2874634861946106
Batch 2/64 loss: 0.2846370339393616
Batch 3/64 loss: 0.2905329465866089
Batch 4/64 loss: 0.2890876531600952
Batch 5/64 loss: 0.2773158550262451
Batch 6/64 loss: 0.29080861806869507
Batch 7/64 loss: 0.284518837928772
Batch 8/64 loss: 0.28405213356018066
Batch 9/64 loss: 0.29548919200897217
Batch 10/64 loss: 0.28583645820617676
Batch 11/64 loss: 0.28315913677215576
Batch 12/64 loss: 0.28764939308166504
Batch 13/64 loss: 0.29141390323638916
Batch 14/64 loss: 0.29363536834716797
Batch 15/64 loss: 0.28890079259872437
Batch 16/64 loss: 0.2837311029434204
Batch 17/64 loss: 0.29864293336868286
Batch 18/64 loss: 0.28690803050994873
Batch 19/64 loss: 0.2907785177230835
Batch 20/64 loss: 0.28094732761383057
Batch 21/64 loss: 0.2931753993034363
Batch 22/64 loss: 0.29181718826293945
Batch 23/64 loss: 0.2949832081794739
Batch 24/64 loss: 0.2869065999984741
Batch 25/64 loss: 0.2882819175720215
Batch 26/64 loss: 0.2828863859176636
Batch 27/64 loss: 0.28849416971206665
Batch 28/64 loss: 0.28349870443344116
Batch 29/64 loss: 0.29205596446990967
Batch 30/64 loss: 0.28626465797424316
Batch 31/64 loss: 0.2920752763748169
Batch 32/64 loss: 0.28587067127227783
Batch 33/64 loss: 0.28901463747024536
Batch 34/64 loss: 0.2821180820465088
Batch 35/64 loss: 0.28592848777770996
Batch 36/64 loss: 0.2822458744049072
Batch 37/64 loss: 0.2873876094818115
Batch 38/64 loss: 0.29030293226242065
Batch 39/64 loss: 0.28912997245788574
Batch 40/64 loss: 0.2844119071960449
Batch 41/64 loss: 0.28333890438079834
Batch 42/64 loss: 0.2944496273994446
Batch 43/64 loss: 0.2894558310508728
Batch 44/64 loss: 0.28827500343322754
Batch 45/64 loss: 0.2933516502380371
Batch 46/64 loss: 0.2823904752731323
Batch 47/64 loss: 0.2916954755783081
Batch 48/64 loss: 0.2942826747894287
Batch 49/64 loss: 0.2992247939109802
Batch 50/64 loss: 0.28774428367614746
Batch 51/64 loss: 0.28878355026245117
Batch 52/64 loss: 0.2884632349014282
Batch 53/64 loss: 0.29170799255371094
Batch 54/64 loss: 0.2862124443054199
Batch 55/64 loss: 0.2872796058654785
Batch 56/64 loss: 0.2921154499053955
Batch 57/64 loss: 0.2878572940826416
Batch 58/64 loss: 0.2978179454803467
Batch 59/64 loss: 0.29508036375045776
Batch 60/64 loss: 0.29131799936294556
Batch 61/64 loss: 0.28802287578582764
Batch 62/64 loss: 0.29427552223205566
Batch 63/64 loss: 0.2942584753036499
Batch 64/64 loss: 0.28893423080444336
Epoch 237  Train loss: 0.28888565512264475  Val loss: 0.3142210095608767
Epoch 238
-------------------------------
Batch 1/64 loss: 0.2956124544143677
Batch 2/64 loss: 0.27892887592315674
Batch 3/64 loss: 0.2893603444099426
Batch 4/64 loss: 0.28419727087020874
Batch 5/64 loss: 0.28795623779296875
Batch 6/64 loss: 0.28544747829437256
Batch 7/64 loss: 0.2813377380371094
Batch 8/64 loss: 0.2884560823440552
Batch 9/64 loss: 0.2897740602493286
Batch 10/64 loss: 0.28337061405181885
Batch 11/64 loss: 0.2943682074546814
Batch 12/64 loss: 0.28947627544403076
Batch 13/64 loss: 0.2860482931137085
Batch 14/64 loss: 0.290307879447937
Batch 15/64 loss: 0.28781408071517944
Batch 16/64 loss: 0.2859628200531006
Batch 17/64 loss: 0.2790924310684204
Batch 18/64 loss: 0.28761547803878784
Batch 19/64 loss: 0.2863985300064087
Batch 20/64 loss: 0.29153120517730713
Batch 21/64 loss: 0.2854769229888916
Batch 22/64 loss: 0.2863342761993408
Batch 23/64 loss: 0.28985029458999634
Batch 24/64 loss: 0.29520130157470703
Batch 25/64 loss: 0.2905477285385132
Batch 26/64 loss: 0.2936154007911682
Batch 27/64 loss: 0.28948861360549927
Batch 28/64 loss: 0.2935553789138794
Batch 29/64 loss: 0.2840498685836792
Batch 30/64 loss: 0.28684407472610474
Batch 31/64 loss: 0.28333771228790283
Batch 32/64 loss: 0.2914707064628601
Batch 33/64 loss: 0.284060537815094
Batch 34/64 loss: 0.28605955839157104
Batch 35/64 loss: 0.2983359098434448
Batch 36/64 loss: 0.28536611795425415
Batch 37/64 loss: 0.2926003932952881
Batch 38/64 loss: 0.2840186357498169
Batch 39/64 loss: 0.29295724630355835
Batch 40/64 loss: 0.2842491865158081
Batch 41/64 loss: 0.2916108965873718
Batch 42/64 loss: 0.2955470681190491
Batch 43/64 loss: 0.28971630334854126
Batch 44/64 loss: 0.2872570753097534
Batch 45/64 loss: 0.2940504550933838
Batch 46/64 loss: 0.2796217203140259
Batch 47/64 loss: 0.28220319747924805
Batch 48/64 loss: 0.27732419967651367
Batch 49/64 loss: 0.288407564163208
Batch 50/64 loss: 0.29450827836990356
Batch 51/64 loss: 0.28888583183288574
Batch 52/64 loss: 0.2888929843902588
Batch 53/64 loss: 0.28583765029907227
Batch 54/64 loss: 0.28227758407592773
Batch 55/64 loss: 0.2986934781074524
Batch 56/64 loss: 0.29875439405441284
Batch 57/64 loss: 0.2897738218307495
Batch 58/64 loss: 0.2858579754829407
Batch 59/64 loss: 0.2933627963066101
Batch 60/64 loss: 0.28955012559890747
Batch 61/64 loss: 0.2903541326522827
Batch 62/64 loss: 0.2929905652999878
Batch 63/64 loss: 0.28785890340805054
Batch 64/64 loss: 0.2853425145149231
Epoch 238  Train loss: 0.2884363938780392  Val loss: 0.3138112239411606
Epoch 239
-------------------------------
Batch 1/64 loss: 0.2836918830871582
Batch 2/64 loss: 0.290241539478302
Batch 3/64 loss: 0.28452014923095703
Batch 4/64 loss: 0.28842413425445557
Batch 5/64 loss: 0.2842264175415039
Batch 6/64 loss: 0.28526169061660767
Batch 7/64 loss: 0.28222453594207764
Batch 8/64 loss: 0.29378825426101685
Batch 9/64 loss: 0.2887911796569824
Batch 10/64 loss: 0.2849646806716919
Batch 11/64 loss: 0.29465192556381226
Batch 12/64 loss: 0.28530973196029663
Batch 13/64 loss: 0.2895352244377136
Batch 14/64 loss: 0.28714942932128906
Batch 15/64 loss: 0.28662538528442383
Batch 16/64 loss: 0.2852848172187805
Batch 17/64 loss: 0.2879159450531006
Batch 18/64 loss: 0.2914944887161255
Batch 19/64 loss: 0.28559350967407227
Batch 20/64 loss: 0.2935553789138794
Batch 21/64 loss: 0.2910672426223755
Batch 22/64 loss: 0.2827754020690918
Batch 23/64 loss: 0.2884392738342285
Batch 24/64 loss: 0.28563380241394043
Batch 25/64 loss: 0.28659945726394653
Batch 26/64 loss: 0.2833271026611328
Batch 27/64 loss: 0.2895519733428955
Batch 28/64 loss: 0.2978947162628174
Batch 29/64 loss: 0.28359103202819824
Batch 30/64 loss: 0.28808677196502686
Batch 31/64 loss: 0.28298747539520264
Batch 32/64 loss: 0.28401386737823486
Batch 33/64 loss: 0.2838026285171509
Batch 34/64 loss: 0.2877688407897949
Batch 35/64 loss: 0.2866319417953491
Batch 36/64 loss: 0.29014503955841064
Batch 37/64 loss: 0.2833878993988037
Batch 38/64 loss: 0.2927209138870239
Batch 39/64 loss: 0.28997504711151123
Batch 40/64 loss: 0.28884005546569824
Batch 41/64 loss: 0.288044810295105
Batch 42/64 loss: 0.2893366813659668
Batch 43/64 loss: 0.2867414951324463
Batch 44/64 loss: 0.2881866693496704
Batch 45/64 loss: 0.28684329986572266
Batch 46/64 loss: 0.2940877676010132
Batch 47/64 loss: 0.2842109799385071
Batch 48/64 loss: 0.28376299142837524
Batch 49/64 loss: 0.29195213317871094
Batch 50/64 loss: 0.2938408851623535
Batch 51/64 loss: 0.2872692346572876
Batch 52/64 loss: 0.29551243782043457
Batch 53/64 loss: 0.28461015224456787
Batch 54/64 loss: 0.29420751333236694
Batch 55/64 loss: 0.2938903570175171
Batch 56/64 loss: 0.28757667541503906
Batch 57/64 loss: 0.2882799506187439
Batch 58/64 loss: 0.2907371520996094
Batch 59/64 loss: 0.28672266006469727
Batch 60/64 loss: 0.283649206161499
Batch 61/64 loss: 0.2879610061645508
Batch 62/64 loss: 0.2880047559738159
Batch 63/64 loss: 0.2859436273574829
Batch 64/64 loss: 0.2888830304145813
Epoch 239  Train loss: 0.2879768705835529  Val loss: 0.31516228467738094
Epoch 240
-------------------------------
Batch 1/64 loss: 0.27935951948165894
Batch 2/64 loss: 0.28287583589553833
Batch 3/64 loss: 0.2808845639228821
Batch 4/64 loss: 0.28686630725860596
Batch 5/64 loss: 0.2871053218841553
Batch 6/64 loss: 0.2856173515319824
Batch 7/64 loss: 0.2889990210533142
Batch 8/64 loss: 0.29140138626098633
Batch 9/64 loss: 0.29199063777923584
Batch 10/64 loss: 0.2955992817878723
Batch 11/64 loss: 0.2846120595932007
Batch 12/64 loss: 0.28653252124786377
Batch 13/64 loss: 0.28582966327667236
Batch 14/64 loss: 0.29642218351364136
Batch 15/64 loss: 0.2878156900405884
Batch 16/64 loss: 0.28705263137817383
Batch 17/64 loss: 0.2827035188674927
Batch 18/64 loss: 0.2813129425048828
Batch 19/64 loss: 0.28566956520080566
Batch 20/64 loss: 0.28417396545410156
Batch 21/64 loss: 0.2901158928871155
Batch 22/64 loss: 0.28511011600494385
Batch 23/64 loss: 0.2984522581100464
Batch 24/64 loss: 0.2854018211364746
Batch 25/64 loss: 0.28225958347320557
Batch 26/64 loss: 0.28342998027801514
Batch 27/64 loss: 0.2895320653915405
Batch 28/64 loss: 0.2887697219848633
Batch 29/64 loss: 0.28372251987457275
Batch 30/64 loss: 0.29103779792785645
Batch 31/64 loss: 0.28609490394592285
Batch 32/64 loss: 0.29281866550445557
Batch 33/64 loss: 0.2866111993789673
Batch 34/64 loss: 0.2839401364326477
Batch 35/64 loss: 0.28481554985046387
Batch 36/64 loss: 0.28078383207321167
Batch 37/64 loss: 0.29444026947021484
Batch 38/64 loss: 0.2932671308517456
Batch 39/64 loss: 0.29040205478668213
Batch 40/64 loss: 0.3018181324005127
Batch 41/64 loss: 0.28373920917510986
Batch 42/64 loss: 0.2888997197151184
Batch 43/64 loss: 0.28393304347991943
Batch 44/64 loss: 0.2899714708328247
Batch 45/64 loss: 0.2877103090286255
Batch 46/64 loss: 0.2930775284767151
Batch 47/64 loss: 0.28377819061279297
Batch 48/64 loss: 0.28906118869781494
Batch 49/64 loss: 0.28966963291168213
Batch 50/64 loss: 0.2927534580230713
Batch 51/64 loss: 0.2972148656845093
Batch 52/64 loss: 0.2844231128692627
Batch 53/64 loss: 0.2900961637496948
Batch 54/64 loss: 0.2849981188774109
Batch 55/64 loss: 0.29234856367111206
Batch 56/64 loss: 0.28710830211639404
Batch 57/64 loss: 0.2873806953430176
Batch 58/64 loss: 0.28570830821990967
Batch 59/64 loss: 0.2871634364128113
Batch 60/64 loss: 0.29017341136932373
Batch 61/64 loss: 0.2863486409187317
Batch 62/64 loss: 0.2849005460739136
Batch 63/64 loss: 0.2877429723739624
Batch 64/64 loss: 0.2872978448867798
Epoch 240  Train loss: 0.2878324999528773  Val loss: 0.31443911135401514
Epoch 241
-------------------------------
Batch 1/64 loss: 0.29062819480895996
Batch 2/64 loss: 0.29065144062042236
Batch 3/64 loss: 0.29666173458099365
Batch 4/64 loss: 0.2853682041168213
Batch 5/64 loss: 0.28663134574890137
Batch 6/64 loss: 0.2857859134674072
Batch 7/64 loss: 0.2821788191795349
Batch 8/64 loss: 0.2833283543586731
Batch 9/64 loss: 0.28642046451568604
Batch 10/64 loss: 0.2825314998626709
Batch 11/64 loss: 0.2858961820602417
Batch 12/64 loss: 0.28740906715393066
Batch 13/64 loss: 0.2956165671348572
Batch 14/64 loss: 0.2897707223892212
Batch 15/64 loss: 0.28857606649398804
Batch 16/64 loss: 0.2929458022117615
Batch 17/64 loss: 0.29144835472106934
Batch 18/64 loss: 0.2851790189743042
Batch 19/64 loss: 0.29407525062561035
Batch 20/64 loss: 0.2855478525161743
Batch 21/64 loss: 0.29255998134613037
Batch 22/64 loss: 0.2842165231704712
Batch 23/64 loss: 0.29137182235717773
Batch 24/64 loss: 0.2940481901168823
Batch 25/64 loss: 0.28379642963409424
Batch 26/64 loss: 0.2919166088104248
Batch 27/64 loss: 0.2907944917678833
Batch 28/64 loss: 0.2837637662887573
Batch 29/64 loss: 0.29130619764328003
Batch 30/64 loss: 0.2904773950576782
Batch 31/64 loss: 0.29481303691864014
Batch 32/64 loss: 0.2817232608795166
Batch 33/64 loss: 0.2880370616912842
Batch 34/64 loss: 0.2821009159088135
Batch 35/64 loss: 0.2873290181159973
Batch 36/64 loss: 0.28885310888290405
Batch 37/64 loss: 0.2884809970855713
Batch 38/64 loss: 0.2905347943305969
Batch 39/64 loss: 0.28344547748565674
Batch 40/64 loss: 0.2872929573059082
Batch 41/64 loss: 0.2790724039077759
Batch 42/64 loss: 0.300514817237854
Batch 43/64 loss: 0.280104398727417
Batch 44/64 loss: 0.28333449363708496
Batch 45/64 loss: 0.2857084274291992
Batch 46/64 loss: 0.2892838716506958
Batch 47/64 loss: 0.28397470712661743
Batch 48/64 loss: 0.2893901467323303
Batch 49/64 loss: 0.2821541428565979
Batch 50/64 loss: 0.29467570781707764
Batch 51/64 loss: 0.2900465726852417
Batch 52/64 loss: 0.2906222343444824
Batch 53/64 loss: 0.2851688861846924
Batch 54/64 loss: 0.2972294092178345
Batch 55/64 loss: 0.28797656297683716
Batch 56/64 loss: 0.28890591859817505
Batch 57/64 loss: 0.2892085313796997
Batch 58/64 loss: 0.2849833369255066
Batch 59/64 loss: 0.2868964672088623
Batch 60/64 loss: 0.2830694913864136
Batch 61/64 loss: 0.28612881898880005
Batch 62/64 loss: 0.29122471809387207
Batch 63/64 loss: 0.2849951982498169
Batch 64/64 loss: 0.29452788829803467
Epoch 241  Train loss: 0.28814240109686756  Val loss: 0.3143153542915161
Epoch 242
-------------------------------
Batch 1/64 loss: 0.2895365357398987
Batch 2/64 loss: 0.2846309542655945
Batch 3/64 loss: 0.28691422939300537
Batch 4/64 loss: 0.2927476167678833
Batch 5/64 loss: 0.2892681360244751
Batch 6/64 loss: 0.28352558612823486
Batch 7/64 loss: 0.28324443101882935
Batch 8/64 loss: 0.2795732617378235
Batch 9/64 loss: 0.28953611850738525
Batch 10/64 loss: 0.28508949279785156
Batch 11/64 loss: 0.28899067640304565
Batch 12/64 loss: 0.284501314163208
Batch 13/64 loss: 0.2834615707397461
Batch 14/64 loss: 0.28677237033843994
Batch 15/64 loss: 0.2859833240509033
Batch 16/64 loss: 0.28986257314682007
Batch 17/64 loss: 0.2948269248008728
Batch 18/64 loss: 0.2844836711883545
Batch 19/64 loss: 0.28332483768463135
Batch 20/64 loss: 0.294178307056427
Batch 21/64 loss: 0.284760057926178
Batch 22/64 loss: 0.29009878635406494
Batch 23/64 loss: 0.28357553482055664
Batch 24/64 loss: 0.28457677364349365
Batch 25/64 loss: 0.2892553210258484
Batch 26/64 loss: 0.28180205821990967
Batch 27/64 loss: 0.28901034593582153
Batch 28/64 loss: 0.2911692261695862
Batch 29/64 loss: 0.2876432538032532
Batch 30/64 loss: 0.28636449575424194
Batch 31/64 loss: 0.28600311279296875
Batch 32/64 loss: 0.2896386384963989
Batch 33/64 loss: 0.2942483425140381
Batch 34/64 loss: 0.29170703887939453
Batch 35/64 loss: 0.2858954668045044
Batch 36/64 loss: 0.2870877981185913
Batch 37/64 loss: 0.28445136547088623
Batch 38/64 loss: 0.2867952585220337
Batch 39/64 loss: 0.289966344833374
Batch 40/64 loss: 0.28165507316589355
Batch 41/64 loss: 0.2914184331893921
Batch 42/64 loss: 0.2825206518173218
Batch 43/64 loss: 0.2785853147506714
Batch 44/64 loss: 0.29435133934020996
Batch 45/64 loss: 0.29510653018951416
Batch 46/64 loss: 0.28457915782928467
Batch 47/64 loss: 0.2885059118270874
Batch 48/64 loss: 0.2884870767593384
Batch 49/64 loss: 0.2903987765312195
Batch 50/64 loss: 0.28344452381134033
Batch 51/64 loss: 0.28759175539016724
Batch 52/64 loss: 0.2920255661010742
Batch 53/64 loss: 0.2975654602050781
Batch 54/64 loss: 0.2867027521133423
Batch 55/64 loss: 0.29113292694091797
Batch 56/64 loss: 0.2867255210876465
Batch 57/64 loss: 0.2835119366645813
Batch 58/64 loss: 0.28372442722320557
Batch 59/64 loss: 0.2834995985031128
Batch 60/64 loss: 0.2957085371017456
Batch 61/64 loss: 0.29182106256484985
Batch 62/64 loss: 0.2854597568511963
Batch 63/64 loss: 0.2935382127761841
Batch 64/64 loss: 0.2829355001449585
Epoch 242  Train loss: 0.2876041267432419  Val loss: 0.31311313782360956
Saving best model, epoch: 242
Epoch 243
-------------------------------
Batch 1/64 loss: 0.28459441661834717
Batch 2/64 loss: 0.2882251739501953
Batch 3/64 loss: 0.2911617159843445
Batch 4/64 loss: 0.28409266471862793
Batch 5/64 loss: 0.2888960838317871
Batch 6/64 loss: 0.2964506149291992
Batch 7/64 loss: 0.28988856077194214
Batch 8/64 loss: 0.2793625593185425
Batch 9/64 loss: 0.2905033230781555
Batch 10/64 loss: 0.2840832471847534
Batch 11/64 loss: 0.29120302200317383
Batch 12/64 loss: 0.2898660898208618
Batch 13/64 loss: 0.28702378273010254
Batch 14/64 loss: 0.28629034757614136
Batch 15/64 loss: 0.2909981608390808
Batch 16/64 loss: 0.28425133228302
Batch 17/64 loss: 0.28933483362197876
Batch 18/64 loss: 0.28482377529144287
Batch 19/64 loss: 0.2911773920059204
Batch 20/64 loss: 0.285703182220459
Batch 21/64 loss: 0.28803253173828125
Batch 22/64 loss: 0.28731024265289307
Batch 23/64 loss: 0.2886124849319458
Batch 24/64 loss: 0.2889251708984375
Batch 25/64 loss: 0.2917670011520386
Batch 26/64 loss: 0.28609907627105713
Batch 27/64 loss: 0.2934192419052124
Batch 28/64 loss: 0.2852763533592224
Batch 29/64 loss: 0.28835010528564453
Batch 30/64 loss: 0.2952073812484741
Batch 31/64 loss: 0.2923312187194824
Batch 32/64 loss: 0.2833552360534668
Batch 33/64 loss: 0.2907562255859375
Batch 34/64 loss: 0.2888011932373047
Batch 35/64 loss: 0.28591275215148926
Batch 36/64 loss: 0.2905665636062622
Batch 37/64 loss: 0.2855268716812134
Batch 38/64 loss: 0.287150502204895
Batch 39/64 loss: 0.2844874858856201
Batch 40/64 loss: 0.2827443480491638
Batch 41/64 loss: 0.2951706647872925
Batch 42/64 loss: 0.2824033498764038
Batch 43/64 loss: 0.2898368239402771
Batch 44/64 loss: 0.29001694917678833
Batch 45/64 loss: 0.2893792390823364
Batch 46/64 loss: 0.2893085479736328
Batch 47/64 loss: 0.2894657850265503
Batch 48/64 loss: 0.2826097011566162
Batch 49/64 loss: 0.29011666774749756
Batch 50/64 loss: 0.29277366399765015
Batch 51/64 loss: 0.2925586700439453
Batch 52/64 loss: 0.2931874990463257
Batch 53/64 loss: 0.2906937599182129
Batch 54/64 loss: 0.28779172897338867
Batch 55/64 loss: 0.29385852813720703
Batch 56/64 loss: 0.2848491668701172
Batch 57/64 loss: 0.2831209897994995
Batch 58/64 loss: 0.28318774700164795
Batch 59/64 loss: 0.28501462936401367
Batch 60/64 loss: 0.292372465133667
Batch 61/64 loss: 0.2847289443016052
Batch 62/64 loss: 0.2820780277252197
Batch 63/64 loss: 0.2811795473098755
Batch 64/64 loss: 0.2953174114227295
Epoch 243  Train loss: 0.28815299482906565  Val loss: 0.31515829690133584
Epoch 244
-------------------------------
Batch 1/64 loss: 0.28692954778671265
Batch 2/64 loss: 0.28481101989746094
Batch 3/64 loss: 0.28037381172180176
Batch 4/64 loss: 0.28803467750549316
Batch 5/64 loss: 0.29137229919433594
Batch 6/64 loss: 0.2876908779144287
Batch 7/64 loss: 0.2875533699989319
Batch 8/64 loss: 0.2844264507293701
Batch 9/64 loss: 0.2834451198577881
Batch 10/64 loss: 0.2861766219139099
Batch 11/64 loss: 0.2959882616996765
Batch 12/64 loss: 0.29187726974487305
Batch 13/64 loss: 0.28131675720214844
Batch 14/64 loss: 0.28943586349487305
Batch 15/64 loss: 0.2887749671936035
Batch 16/64 loss: 0.28679782152175903
Batch 17/64 loss: 0.28236329555511475
Batch 18/64 loss: 0.2844851016998291
Batch 19/64 loss: 0.27789008617401123
Batch 20/64 loss: 0.28732365369796753
Batch 21/64 loss: 0.2851579189300537
Batch 22/64 loss: 0.29093778133392334
Batch 23/64 loss: 0.2806837558746338
Batch 24/64 loss: 0.29115939140319824
Batch 25/64 loss: 0.29059749841690063
Batch 26/64 loss: 0.28555047512054443
Batch 27/64 loss: 0.29124486446380615
Batch 28/64 loss: 0.2863956689834595
Batch 29/64 loss: 0.2939479351043701
Batch 30/64 loss: 0.28849923610687256
Batch 31/64 loss: 0.2910119295120239
Batch 32/64 loss: 0.28797096014022827
Batch 33/64 loss: 0.2872203588485718
Batch 34/64 loss: 0.28163111209869385
Batch 35/64 loss: 0.290352463722229
Batch 36/64 loss: 0.29055553674697876
Batch 37/64 loss: 0.2800593376159668
Batch 38/64 loss: 0.2937192916870117
Batch 39/64 loss: 0.28836560249328613
Batch 40/64 loss: 0.2958664894104004
Batch 41/64 loss: 0.2899796962738037
Batch 42/64 loss: 0.28785884380340576
Batch 43/64 loss: 0.28532999753952026
Batch 44/64 loss: 0.2881309390068054
Batch 45/64 loss: 0.28144198656082153
Batch 46/64 loss: 0.28340578079223633
Batch 47/64 loss: 0.29239606857299805
Batch 48/64 loss: 0.2851409912109375
Batch 49/64 loss: 0.29079604148864746
Batch 50/64 loss: 0.2897801995277405
Batch 51/64 loss: 0.28669261932373047
Batch 52/64 loss: 0.29238760471343994
Batch 53/64 loss: 0.28199613094329834
Batch 54/64 loss: 0.28918325901031494
Batch 55/64 loss: 0.2851235270500183
Batch 56/64 loss: 0.2815648317337036
Batch 57/64 loss: 0.28636378049850464
Batch 58/64 loss: 0.2852310538291931
Batch 59/64 loss: 0.28369367122650146
Batch 60/64 loss: 0.28753888607025146
Batch 61/64 loss: 0.28291064500808716
Batch 62/64 loss: 0.2960526943206787
Batch 63/64 loss: 0.2784199118614197
Batch 64/64 loss: 0.28418028354644775
Epoch 244  Train loss: 0.28709880557714723  Val loss: 0.31411641877131774
Epoch 245
-------------------------------
Batch 1/64 loss: 0.29336923360824585
Batch 2/64 loss: 0.2894671559333801
Batch 3/64 loss: 0.2866048812866211
Batch 4/64 loss: 0.28099095821380615
Batch 5/64 loss: 0.288881778717041
Batch 6/64 loss: 0.28566795587539673
Batch 7/64 loss: 0.2903822064399719
Batch 8/64 loss: 0.28233301639556885
Batch 9/64 loss: 0.28557586669921875
Batch 10/64 loss: 0.28146326541900635
Batch 11/64 loss: 0.28960108757019043
Batch 12/64 loss: 0.2900526523590088
Batch 13/64 loss: 0.293499231338501
Batch 14/64 loss: 0.28696566820144653
Batch 15/64 loss: 0.281538724899292
Batch 16/64 loss: 0.280553936958313
Batch 17/64 loss: 0.2833205461502075
Batch 18/64 loss: 0.28882908821105957
Batch 19/64 loss: 0.2843385934829712
Batch 20/64 loss: 0.28661948442459106
Batch 21/64 loss: 0.28180956840515137
Batch 22/64 loss: 0.27989763021469116
Batch 23/64 loss: 0.2863631248474121
Batch 24/64 loss: 0.2912503480911255
Batch 25/64 loss: 0.28854900598526
Batch 26/64 loss: 0.2942925691604614
Batch 27/64 loss: 0.2927395701408386
Batch 28/64 loss: 0.29263901710510254
Batch 29/64 loss: 0.2903851270675659
Batch 30/64 loss: 0.28934192657470703
Batch 31/64 loss: 0.2856931686401367
Batch 32/64 loss: 0.2850298285484314
Batch 33/64 loss: 0.28842681646347046
Batch 34/64 loss: 0.28474926948547363
Batch 35/64 loss: 0.28202903270721436
Batch 36/64 loss: 0.28975510597229004
Batch 37/64 loss: 0.29010939598083496
Batch 38/64 loss: 0.2805992364883423
Batch 39/64 loss: 0.2876383662223816
Batch 40/64 loss: 0.29076725244522095
Batch 41/64 loss: 0.2836947441101074
Batch 42/64 loss: 0.2856673002243042
Batch 43/64 loss: 0.2849682569503784
Batch 44/64 loss: 0.2845315933227539
Batch 45/64 loss: 0.28430306911468506
Batch 46/64 loss: 0.28874242305755615
Batch 47/64 loss: 0.2885105609893799
Batch 48/64 loss: 0.2877248525619507
Batch 49/64 loss: 0.2883889079093933
Batch 50/64 loss: 0.28573423624038696
Batch 51/64 loss: 0.2859187126159668
Batch 52/64 loss: 0.29133498668670654
Batch 53/64 loss: 0.2820966839790344
Batch 54/64 loss: 0.2885570526123047
Batch 55/64 loss: 0.2847253084182739
Batch 56/64 loss: 0.2932645082473755
Batch 57/64 loss: 0.2866268754005432
Batch 58/64 loss: 0.28980231285095215
Batch 59/64 loss: 0.28798049688339233
Batch 60/64 loss: 0.284915030002594
Batch 61/64 loss: 0.28949975967407227
Batch 62/64 loss: 0.2904278039932251
Batch 63/64 loss: 0.2922198176383972
Batch 64/64 loss: 0.2905914783477783
Epoch 245  Train loss: 0.28721097403881596  Val loss: 0.31410275046358405
Epoch 246
-------------------------------
Batch 1/64 loss: 0.28660404682159424
Batch 2/64 loss: 0.2897782325744629
Batch 3/64 loss: 0.28416943550109863
Batch 4/64 loss: 0.2858175039291382
Batch 5/64 loss: 0.28332245349884033
Batch 6/64 loss: 0.2814171314239502
Batch 7/64 loss: 0.28319525718688965
Batch 8/64 loss: 0.2829655408859253
Batch 9/64 loss: 0.2908515930175781
Batch 10/64 loss: 0.28794002532958984
Batch 11/64 loss: 0.2888248562812805
Batch 12/64 loss: 0.28890281915664673
Batch 13/64 loss: 0.28751397132873535
Batch 14/64 loss: 0.2835441827774048
Batch 15/64 loss: 0.29234808683395386
Batch 16/64 loss: 0.2807142734527588
Batch 17/64 loss: 0.2906794548034668
Batch 18/64 loss: 0.2836381196975708
Batch 19/64 loss: 0.2932058572769165
Batch 20/64 loss: 0.2941597104072571
Batch 21/64 loss: 0.287703275680542
Batch 22/64 loss: 0.2936803102493286
Batch 23/64 loss: 0.28115105628967285
Batch 24/64 loss: 0.2848321199417114
Batch 25/64 loss: 0.29182296991348267
Batch 26/64 loss: 0.29063141345977783
Batch 27/64 loss: 0.2842726707458496
Batch 28/64 loss: 0.2887073755264282
Batch 29/64 loss: 0.2904777526855469
Batch 30/64 loss: 0.29406070709228516
Batch 31/64 loss: 0.2820039987564087
Batch 32/64 loss: 0.28158700466156006
Batch 33/64 loss: 0.28659021854400635
Batch 34/64 loss: 0.2894376516342163
Batch 35/64 loss: 0.29486578702926636
Batch 36/64 loss: 0.2830488681793213
Batch 37/64 loss: 0.2878381013870239
Batch 38/64 loss: 0.2888977527618408
Batch 39/64 loss: 0.27985960245132446
Batch 40/64 loss: 0.2869446277618408
Batch 41/64 loss: 0.29824697971343994
Batch 42/64 loss: 0.2818167209625244
Batch 43/64 loss: 0.2871527671813965
Batch 44/64 loss: 0.2784717082977295
Batch 45/64 loss: 0.2989712953567505
Batch 46/64 loss: 0.2897917628288269
Batch 47/64 loss: 0.28708362579345703
Batch 48/64 loss: 0.28506237268447876
Batch 49/64 loss: 0.28058934211730957
Batch 50/64 loss: 0.2855565547943115
Batch 51/64 loss: 0.2823486328125
Batch 52/64 loss: 0.28606724739074707
Batch 53/64 loss: 0.2893350124359131
Batch 54/64 loss: 0.282756507396698
Batch 55/64 loss: 0.2967120409011841
Batch 56/64 loss: 0.28689253330230713
Batch 57/64 loss: 0.2817724943161011
Batch 58/64 loss: 0.28720009326934814
Batch 59/64 loss: 0.2860316038131714
Batch 60/64 loss: 0.2917637825012207
Batch 61/64 loss: 0.2889903783798218
Batch 62/64 loss: 0.28963279724121094
Batch 63/64 loss: 0.28920692205429077
Batch 64/64 loss: 0.2819356918334961
Epoch 246  Train loss: 0.2872299727271585  Val loss: 0.31415569700326296
Epoch 247
-------------------------------
Batch 1/64 loss: 0.2878437638282776
Batch 2/64 loss: 0.2789387106895447
Batch 3/64 loss: 0.2829136848449707
Batch 4/64 loss: 0.2861839532852173
Batch 5/64 loss: 0.28396475315093994
Batch 6/64 loss: 0.2910686731338501
Batch 7/64 loss: 0.2870802879333496
Batch 8/64 loss: 0.29168635606765747
Batch 9/64 loss: 0.2987711429595947
Batch 10/64 loss: 0.2792789340019226
Batch 11/64 loss: 0.2965826392173767
Batch 12/64 loss: 0.2864774465560913
Batch 13/64 loss: 0.2831365466117859
Batch 14/64 loss: 0.28340280055999756
Batch 15/64 loss: 0.2853795886039734
Batch 16/64 loss: 0.2881629467010498
Batch 17/64 loss: 0.2807716131210327
Batch 18/64 loss: 0.2844160795211792
Batch 19/64 loss: 0.2802344560623169
Batch 20/64 loss: 0.2860078811645508
Batch 21/64 loss: 0.2938598394393921
Batch 22/64 loss: 0.28015828132629395
Batch 23/64 loss: 0.2834164500236511
Batch 24/64 loss: 0.282978892326355
Batch 25/64 loss: 0.2909308671951294
Batch 26/64 loss: 0.2928640842437744
Batch 27/64 loss: 0.28893816471099854
Batch 28/64 loss: 0.2850121259689331
Batch 29/64 loss: 0.28848499059677124
Batch 30/64 loss: 0.2813152074813843
Batch 31/64 loss: 0.2873769998550415
Batch 32/64 loss: 0.2897152304649353
Batch 33/64 loss: 0.28080296516418457
Batch 34/64 loss: 0.2899777889251709
Batch 35/64 loss: 0.2882581949234009
Batch 36/64 loss: 0.28757917881011963
Batch 37/64 loss: 0.28431808948516846
Batch 38/64 loss: 0.292142391204834
Batch 39/64 loss: 0.28926897048950195
Batch 40/64 loss: 0.2935584783554077
Batch 41/64 loss: 0.28573107719421387
Batch 42/64 loss: 0.28528785705566406
Batch 43/64 loss: 0.2845209836959839
Batch 44/64 loss: 0.27865803241729736
Batch 45/64 loss: 0.28365981578826904
Batch 46/64 loss: 0.2949654459953308
Batch 47/64 loss: 0.2803953289985657
Batch 48/64 loss: 0.28778547048568726
Batch 49/64 loss: 0.2806622385978699
Batch 50/64 loss: 0.29356199502944946
Batch 51/64 loss: 0.2861383557319641
Batch 52/64 loss: 0.2954603433609009
Batch 53/64 loss: 0.28577184677124023
Batch 54/64 loss: 0.28847450017929077
Batch 55/64 loss: 0.28007644414901733
Batch 56/64 loss: 0.2881937026977539
Batch 57/64 loss: 0.28174805641174316
Batch 58/64 loss: 0.2820197343826294
Batch 59/64 loss: 0.2838033437728882
Batch 60/64 loss: 0.291204571723938
Batch 61/64 loss: 0.2862060070037842
Batch 62/64 loss: 0.28992605209350586
Batch 63/64 loss: 0.28431981801986694
Batch 64/64 loss: 0.28816890716552734
Epoch 247  Train loss: 0.28655619060291965  Val loss: 0.313379485377741
Epoch 248
-------------------------------
Batch 1/64 loss: 0.28096163272857666
Batch 2/64 loss: 0.27661919593811035
Batch 3/64 loss: 0.2832390069961548
Batch 4/64 loss: 0.285214900970459
Batch 5/64 loss: 0.28267890214920044
Batch 6/64 loss: 0.2816944122314453
Batch 7/64 loss: 0.2822313904762268
Batch 8/64 loss: 0.2852814197540283
Batch 9/64 loss: 0.2847369909286499
Batch 10/64 loss: 0.28775012493133545
Batch 11/64 loss: 0.28333580493927
Batch 12/64 loss: 0.2867739796638489
Batch 13/64 loss: 0.2870612144470215
Batch 14/64 loss: 0.2843276858329773
Batch 15/64 loss: 0.29395174980163574
Batch 16/64 loss: 0.28073740005493164
Batch 17/64 loss: 0.2868955135345459
Batch 18/64 loss: 0.28725361824035645
Batch 19/64 loss: 0.28336459398269653
Batch 20/64 loss: 0.28782522678375244
Batch 21/64 loss: 0.2812235951423645
Batch 22/64 loss: 0.28562551736831665
Batch 23/64 loss: 0.2833634614944458
Batch 24/64 loss: 0.28077054023742676
Batch 25/64 loss: 0.28738176822662354
Batch 26/64 loss: 0.2861135005950928
Batch 27/64 loss: 0.28855544328689575
Batch 28/64 loss: 0.2893472909927368
Batch 29/64 loss: 0.2868361473083496
Batch 30/64 loss: 0.28051233291625977
Batch 31/64 loss: 0.2909238934516907
Batch 32/64 loss: 0.2854677438735962
Batch 33/64 loss: 0.28208863735198975
Batch 34/64 loss: 0.29214179515838623
Batch 35/64 loss: 0.2919994592666626
Batch 36/64 loss: 0.29168176651000977
Batch 37/64 loss: 0.28653961420059204
Batch 38/64 loss: 0.2837172746658325
Batch 39/64 loss: 0.28861409425735474
Batch 40/64 loss: 0.2914208769798279
Batch 41/64 loss: 0.2932032346725464
Batch 42/64 loss: 0.2929328680038452
Batch 43/64 loss: 0.29646438360214233
Batch 44/64 loss: 0.2902776598930359
Batch 45/64 loss: 0.28269875049591064
Batch 46/64 loss: 0.28851503133773804
Batch 47/64 loss: 0.2837488651275635
Batch 48/64 loss: 0.28699791431427
Batch 49/64 loss: 0.2977794408798218
Batch 50/64 loss: 0.28961896896362305
Batch 51/64 loss: 0.2809585928916931
Batch 52/64 loss: 0.2912238836288452
Batch 53/64 loss: 0.29083937406539917
Batch 54/64 loss: 0.2912486791610718
Batch 55/64 loss: 0.2900415062904358
Batch 56/64 loss: 0.2844741940498352
Batch 57/64 loss: 0.28842294216156006
Batch 58/64 loss: 0.2854697108268738
Batch 59/64 loss: 0.2847357988357544
Batch 60/64 loss: 0.29511022567749023
Batch 61/64 loss: 0.2826923131942749
Batch 62/64 loss: 0.29509150981903076
Batch 63/64 loss: 0.2879488468170166
Batch 64/64 loss: 0.2825500965118408
Epoch 248  Train loss: 0.28688104760413075  Val loss: 0.31416781927711773
Epoch 249
-------------------------------
Batch 1/64 loss: 0.28392601013183594
Batch 2/64 loss: 0.2819962501525879
Batch 3/64 loss: 0.28832530975341797
Batch 4/64 loss: 0.28202569484710693
Batch 5/64 loss: 0.2864455580711365
Batch 6/64 loss: 0.2898769974708557
Batch 7/64 loss: 0.2849828004837036
Batch 8/64 loss: 0.2853984832763672
Batch 9/64 loss: 0.28060460090637207
Batch 10/64 loss: 0.2896025776863098
Batch 11/64 loss: 0.2836293578147888
Batch 12/64 loss: 0.2818485498428345
Batch 13/64 loss: 0.2880852222442627
Batch 14/64 loss: 0.2847566604614258
Batch 15/64 loss: 0.2859722375869751
Batch 16/64 loss: 0.287528932094574
Batch 17/64 loss: 0.28611671924591064
Batch 18/64 loss: 0.28045034408569336
Batch 19/64 loss: 0.2905144691467285
Batch 20/64 loss: 0.2886500358581543
Batch 21/64 loss: 0.2889578938484192
Batch 22/64 loss: 0.2852644920349121
Batch 23/64 loss: 0.28004735708236694
Batch 24/64 loss: 0.2876936197280884
Batch 25/64 loss: 0.2870262861251831
Batch 26/64 loss: 0.2899889349937439
Batch 27/64 loss: 0.2845269441604614
Batch 28/64 loss: 0.2916414737701416
Batch 29/64 loss: 0.28210896253585815
Batch 30/64 loss: 0.28560352325439453
Batch 31/64 loss: 0.2852872610092163
Batch 32/64 loss: 0.2888091206550598
Batch 33/64 loss: 0.2818238139152527
Batch 34/64 loss: 0.2862173914909363
Batch 35/64 loss: 0.2869220972061157
Batch 36/64 loss: 0.28895920515060425
Batch 37/64 loss: 0.28417694568634033
Batch 38/64 loss: 0.28222382068634033
Batch 39/64 loss: 0.2919423580169678
Batch 40/64 loss: 0.2892186641693115
Batch 41/64 loss: 0.2793514132499695
Batch 42/64 loss: 0.2799415588378906
Batch 43/64 loss: 0.2833869457244873
Batch 44/64 loss: 0.2793850898742676
Batch 45/64 loss: 0.28708022832870483
Batch 46/64 loss: 0.29193437099456787
Batch 47/64 loss: 0.2874371409416199
Batch 48/64 loss: 0.281136691570282
Batch 49/64 loss: 0.28653353452682495
Batch 50/64 loss: 0.29117488861083984
Batch 51/64 loss: 0.29307740926742554
Batch 52/64 loss: 0.2821314334869385
Batch 53/64 loss: 0.2956596612930298
Batch 54/64 loss: 0.2903701663017273
Batch 55/64 loss: 0.29619503021240234
Batch 56/64 loss: 0.28475356101989746
Batch 57/64 loss: 0.2934532165527344
Batch 58/64 loss: 0.2781788110733032
Batch 59/64 loss: 0.2870328426361084
Batch 60/64 loss: 0.29108119010925293
Batch 61/64 loss: 0.28646355867385864
Batch 62/64 loss: 0.28905177116394043
Batch 63/64 loss: 0.2905144691467285
Batch 64/64 loss: 0.2844676971435547
Epoch 249  Train loss: 0.2863976899315329  Val loss: 0.3145922025044759
Epoch 250
-------------------------------
Batch 1/64 loss: 0.2846553325653076
Batch 2/64 loss: 0.29151225090026855
Batch 3/64 loss: 0.28565382957458496
Batch 4/64 loss: 0.283993124961853
Batch 5/64 loss: 0.2886906862258911
Batch 6/64 loss: 0.2839839458465576
Batch 7/64 loss: 0.28115910291671753
Batch 8/64 loss: 0.29051482677459717
Batch 9/64 loss: 0.2843064069747925
Batch 10/64 loss: 0.282651424407959
Batch 11/64 loss: 0.2868027687072754
Batch 12/64 loss: 0.2810899019241333
Batch 13/64 loss: 0.28567391633987427
Batch 14/64 loss: 0.2842150330543518
Batch 15/64 loss: 0.28988826274871826
Batch 16/64 loss: 0.28736746311187744
Batch 17/64 loss: 0.28531813621520996
Batch 18/64 loss: 0.2851930856704712
Batch 19/64 loss: 0.2932390570640564
Batch 20/64 loss: 0.28689688444137573
Batch 21/64 loss: 0.29033607244491577
Batch 22/64 loss: 0.2844409942626953
Batch 23/64 loss: 0.28852570056915283
Batch 24/64 loss: 0.28944551944732666
Batch 25/64 loss: 0.2811349630355835
Batch 26/64 loss: 0.2897642254829407
Batch 27/64 loss: 0.28300827741622925
Batch 28/64 loss: 0.2941768765449524
Batch 29/64 loss: 0.2790428400039673
Batch 30/64 loss: 0.28176528215408325
Batch 31/64 loss: 0.278755247592926
Batch 32/64 loss: 0.28441447019577026
Batch 33/64 loss: 0.285284161567688
Batch 34/64 loss: 0.28223735094070435
Batch 35/64 loss: 0.2862303853034973
Batch 36/64 loss: 0.28988170623779297
Batch 37/64 loss: 0.2879362106323242
Batch 38/64 loss: 0.2828524112701416
Batch 39/64 loss: 0.28030329942703247
Batch 40/64 loss: 0.289447546005249
Batch 41/64 loss: 0.28597593307495117
Batch 42/64 loss: 0.2875272035598755
Batch 43/64 loss: 0.28216874599456787
Batch 44/64 loss: 0.2802780270576477
Batch 45/64 loss: 0.2851715087890625
Batch 46/64 loss: 0.28522956371307373
Batch 47/64 loss: 0.29287612438201904
Batch 48/64 loss: 0.2822597026824951
Batch 49/64 loss: 0.28891313076019287
Batch 50/64 loss: 0.28753066062927246
Batch 51/64 loss: 0.2884087562561035
Batch 52/64 loss: 0.2824805974960327
Batch 53/64 loss: 0.28623008728027344
Batch 54/64 loss: 0.27972203493118286
Batch 55/64 loss: 0.287994384765625
Batch 56/64 loss: 0.28697121143341064
Batch 57/64 loss: 0.29306113719940186
Batch 58/64 loss: 0.28351473808288574
Batch 59/64 loss: 0.28466343879699707
Batch 60/64 loss: 0.2912876605987549
Batch 61/64 loss: 0.2893558144569397
Batch 62/64 loss: 0.2903183698654175
Batch 63/64 loss: 0.293410062789917
Batch 64/64 loss: 0.29752683639526367
Epoch 250  Train loss: 0.28627894906436696  Val loss: 0.3131565183298694
Epoch 251
-------------------------------
Batch 1/64 loss: 0.28254014253616333
Batch 2/64 loss: 0.2829017639160156
Batch 3/64 loss: 0.2813681364059448
Batch 4/64 loss: 0.2844577431678772
Batch 5/64 loss: 0.28241968154907227
Batch 6/64 loss: 0.2780834436416626
Batch 7/64 loss: 0.2854611873626709
Batch 8/64 loss: 0.28355979919433594
Batch 9/64 loss: 0.2816692590713501
Batch 10/64 loss: 0.2871400713920593
Batch 11/64 loss: 0.2802950143814087
Batch 12/64 loss: 0.2788844108581543
Batch 13/64 loss: 0.2770651578903198
Batch 14/64 loss: 0.28539955615997314
Batch 15/64 loss: 0.28785961866378784
Batch 16/64 loss: 0.2799902558326721
Batch 17/64 loss: 0.29128825664520264
Batch 18/64 loss: 0.2856210470199585
Batch 19/64 loss: 0.2795403003692627
Batch 20/64 loss: 0.28783828020095825
Batch 21/64 loss: 0.2904730439186096
Batch 22/64 loss: 0.2801516056060791
Batch 23/64 loss: 0.2847146987915039
Batch 24/64 loss: 0.288432240486145
Batch 25/64 loss: 0.28045761585235596
Batch 26/64 loss: 0.28553617000579834
Batch 27/64 loss: 0.28199994564056396
Batch 28/64 loss: 0.2843618392944336
Batch 29/64 loss: 0.28746312856674194
Batch 30/64 loss: 0.2841634154319763
Batch 31/64 loss: 0.28846311569213867
Batch 32/64 loss: 0.28170549869537354
Batch 33/64 loss: 0.29082226753234863
Batch 34/64 loss: 0.2920072078704834
Batch 35/64 loss: 0.27787691354751587
Batch 36/64 loss: 0.2799569368362427
Batch 37/64 loss: 0.29318463802337646
Batch 38/64 loss: 0.28320813179016113
Batch 39/64 loss: 0.28492629528045654
Batch 40/64 loss: 0.2818201780319214
Batch 41/64 loss: 0.2855020761489868
Batch 42/64 loss: 0.2867281436920166
Batch 43/64 loss: 0.2987239956855774
Batch 44/64 loss: 0.29906415939331055
Batch 45/64 loss: 0.29139912128448486
Batch 46/64 loss: 0.28719067573547363
Batch 47/64 loss: 0.28814709186553955
Batch 48/64 loss: 0.27958476543426514
Batch 49/64 loss: 0.2844250798225403
Batch 50/64 loss: 0.2904832363128662
Batch 51/64 loss: 0.2911980152130127
Batch 52/64 loss: 0.2846839427947998
Batch 53/64 loss: 0.2877040505409241
Batch 54/64 loss: 0.28339946269989014
Batch 55/64 loss: 0.28738677501678467
Batch 56/64 loss: 0.28280186653137207
Batch 57/64 loss: 0.29230964183807373
Batch 58/64 loss: 0.29360175132751465
Batch 59/64 loss: 0.2814062833786011
Batch 60/64 loss: 0.2903571128845215
Batch 61/64 loss: 0.29071909189224243
Batch 62/64 loss: 0.28274309635162354
Batch 63/64 loss: 0.29082679748535156
Batch 64/64 loss: 0.2833824157714844
Epoch 251  Train loss: 0.2856161734637092  Val loss: 0.3136410086425309
Epoch 252
-------------------------------
Batch 1/64 loss: 0.2837944030761719
Batch 2/64 loss: 0.2833484411239624
Batch 3/64 loss: 0.28062212467193604
Batch 4/64 loss: 0.290428102016449
Batch 5/64 loss: 0.2893102765083313
Batch 6/64 loss: 0.2799755334854126
Batch 7/64 loss: 0.2811546325683594
Batch 8/64 loss: 0.2787911891937256
Batch 9/64 loss: 0.2987016439437866
Batch 10/64 loss: 0.29538869857788086
Batch 11/64 loss: 0.28145503997802734
Batch 12/64 loss: 0.2832380533218384
Batch 13/64 loss: 0.2777066230773926
Batch 14/64 loss: 0.29078471660614014
Batch 15/64 loss: 0.28394240140914917
Batch 16/64 loss: 0.28268611431121826
Batch 17/64 loss: 0.29153692722320557
Batch 18/64 loss: 0.29545271396636963
Batch 19/64 loss: 0.29227155447006226
Batch 20/64 loss: 0.2868262529373169
Batch 21/64 loss: 0.2896883487701416
Batch 22/64 loss: 0.2873023748397827
Batch 23/64 loss: 0.285910427570343
Batch 24/64 loss: 0.2845841646194458
Batch 25/64 loss: 0.28820931911468506
Batch 26/64 loss: 0.29374217987060547
Batch 27/64 loss: 0.2861659526824951
Batch 28/64 loss: 0.2834157943725586
Batch 29/64 loss: 0.28468233346939087
Batch 30/64 loss: 0.2920757532119751
Batch 31/64 loss: 0.2848585844039917
Batch 32/64 loss: 0.28480976819992065
Batch 33/64 loss: 0.2834441661834717
Batch 34/64 loss: 0.28301775455474854
Batch 35/64 loss: 0.29822129011154175
Batch 36/64 loss: 0.28523027896881104
Batch 37/64 loss: 0.28544139862060547
Batch 38/64 loss: 0.29228687286376953
Batch 39/64 loss: 0.28445589542388916
Batch 40/64 loss: 0.2910762429237366
Batch 41/64 loss: 0.28915977478027344
Batch 42/64 loss: 0.2891429662704468
Batch 43/64 loss: 0.28316599130630493
Batch 44/64 loss: 0.2943631410598755
Batch 45/64 loss: 0.2834441065788269
Batch 46/64 loss: 0.27965909242630005
Batch 47/64 loss: 0.28612220287323
Batch 48/64 loss: 0.2875549793243408
Batch 49/64 loss: 0.2880467176437378
Batch 50/64 loss: 0.2848259210586548
Batch 51/64 loss: 0.28090840578079224
Batch 52/64 loss: 0.29092496633529663
Batch 53/64 loss: 0.28552740812301636
Batch 54/64 loss: 0.28515708446502686
Batch 55/64 loss: 0.2823585271835327
Batch 56/64 loss: 0.28444790840148926
Batch 57/64 loss: 0.28658485412597656
Batch 58/64 loss: 0.28728342056274414
Batch 59/64 loss: 0.28379058837890625
Batch 60/64 loss: 0.285239577293396
Batch 61/64 loss: 0.2898062467575073
Batch 62/64 loss: 0.27904975414276123
Batch 63/64 loss: 0.2823774218559265
Batch 64/64 loss: 0.29418832063674927
Epoch 252  Train loss: 0.2865194767129188  Val loss: 0.31365699579625606
Epoch 253
-------------------------------
Batch 1/64 loss: 0.2814176082611084
Batch 2/64 loss: 0.28239738941192627
Batch 3/64 loss: 0.28567397594451904
Batch 4/64 loss: 0.28395330905914307
Batch 5/64 loss: 0.28033846616744995
Batch 6/64 loss: 0.2901727557182312
Batch 7/64 loss: 0.281363308429718
Batch 8/64 loss: 0.2810319662094116
Batch 9/64 loss: 0.2836191654205322
Batch 10/64 loss: 0.2902553677558899
Batch 11/64 loss: 0.27757859230041504
Batch 12/64 loss: 0.28846025466918945
Batch 13/64 loss: 0.2896983027458191
Batch 14/64 loss: 0.29236161708831787
Batch 15/64 loss: 0.2877814769744873
Batch 16/64 loss: 0.28524792194366455
Batch 17/64 loss: 0.2827983498573303
Batch 18/64 loss: 0.2841341495513916
Batch 19/64 loss: 0.28333085775375366
Batch 20/64 loss: 0.29096418619155884
Batch 21/64 loss: 0.2949129343032837
Batch 22/64 loss: 0.28695595264434814
Batch 23/64 loss: 0.28510451316833496
Batch 24/64 loss: 0.282687783241272
Batch 25/64 loss: 0.2854148745536804
Batch 26/64 loss: 0.28335362672805786
Batch 27/64 loss: 0.2854916453361511
Batch 28/64 loss: 0.2858262062072754
Batch 29/64 loss: 0.2807740569114685
Batch 30/64 loss: 0.29013437032699585
Batch 31/64 loss: 0.2889050841331482
Batch 32/64 loss: 0.28095048666000366
Batch 33/64 loss: 0.29475510120391846
Batch 34/64 loss: 0.28174781799316406
Batch 35/64 loss: 0.2848477363586426
Batch 36/64 loss: 0.2906564474105835
Batch 37/64 loss: 0.2814632058143616
Batch 38/64 loss: 0.2836182117462158
Batch 39/64 loss: 0.28859543800354004
Batch 40/64 loss: 0.28202182054519653
Batch 41/64 loss: 0.29197144508361816
Batch 42/64 loss: 0.2875518798828125
Batch 43/64 loss: 0.2875133752822876
Batch 44/64 loss: 0.28644680976867676
Batch 45/64 loss: 0.2898537516593933
Batch 46/64 loss: 0.27962058782577515
Batch 47/64 loss: 0.2893255949020386
Batch 48/64 loss: 0.2845200300216675
Batch 49/64 loss: 0.279276967048645
Batch 50/64 loss: 0.28905391693115234
Batch 51/64 loss: 0.2822459936141968
Batch 52/64 loss: 0.2836974859237671
Batch 53/64 loss: 0.2763819694519043
Batch 54/64 loss: 0.2886863946914673
Batch 55/64 loss: 0.291770339012146
Batch 56/64 loss: 0.2892765402793884
Batch 57/64 loss: 0.28901058435440063
Batch 58/64 loss: 0.28830575942993164
Batch 59/64 loss: 0.2835046648979187
Batch 60/64 loss: 0.28809571266174316
Batch 61/64 loss: 0.2830582857131958
Batch 62/64 loss: 0.28495633602142334
Batch 63/64 loss: 0.2954726219177246
Batch 64/64 loss: 0.2856398820877075
Epoch 253  Train loss: 0.28587644380681654  Val loss: 0.31391627026587415
Epoch 254
-------------------------------
Batch 1/64 loss: 0.28595519065856934
Batch 2/64 loss: 0.29354381561279297
Batch 3/64 loss: 0.28367555141448975
Batch 4/64 loss: 0.28235745429992676
Batch 5/64 loss: 0.28288698196411133
Batch 6/64 loss: 0.2799873948097229
Batch 7/64 loss: 0.28569698333740234
Batch 8/64 loss: 0.2789926528930664
Batch 9/64 loss: 0.2853855490684509
Batch 10/64 loss: 0.28420960903167725
Batch 11/64 loss: 0.2792319059371948
Batch 12/64 loss: 0.28015708923339844
Batch 13/64 loss: 0.281521201133728
Batch 14/64 loss: 0.2847867012023926
Batch 15/64 loss: 0.2929755449295044
Batch 16/64 loss: 0.2758064866065979
Batch 17/64 loss: 0.27787911891937256
Batch 18/64 loss: 0.2870129346847534
Batch 19/64 loss: 0.28716033697128296
Batch 20/64 loss: 0.2857320308685303
Batch 21/64 loss: 0.28444135189056396
Batch 22/64 loss: 0.2844061255455017
Batch 23/64 loss: 0.2907700538635254
Batch 24/64 loss: 0.28900355100631714
Batch 25/64 loss: 0.2840510606765747
Batch 26/64 loss: 0.2806265950202942
Batch 27/64 loss: 0.2782043218612671
Batch 28/64 loss: 0.29099607467651367
Batch 29/64 loss: 0.28941023349761963
Batch 30/64 loss: 0.28326380252838135
Batch 31/64 loss: 0.2805057764053345
Batch 32/64 loss: 0.29144763946533203
Batch 33/64 loss: 0.2847909927368164
Batch 34/64 loss: 0.2897219657897949
Batch 35/64 loss: 0.2809673547744751
Batch 36/64 loss: 0.28693175315856934
Batch 37/64 loss: 0.28724491596221924
Batch 38/64 loss: 0.2902963161468506
Batch 39/64 loss: 0.2915290594100952
Batch 40/64 loss: 0.29062217473983765
Batch 41/64 loss: 0.2924017906188965
Batch 42/64 loss: 0.2834623456001282
Batch 43/64 loss: 0.29343879222869873
Batch 44/64 loss: 0.28731846809387207
Batch 45/64 loss: 0.2910975217819214
Batch 46/64 loss: 0.2900865077972412
Batch 47/64 loss: 0.28469640016555786
Batch 48/64 loss: 0.2869654893875122
Batch 49/64 loss: 0.28069376945495605
Batch 50/64 loss: 0.28598785400390625
Batch 51/64 loss: 0.2824866771697998
Batch 52/64 loss: 0.28526413440704346
Batch 53/64 loss: 0.2885896563529968
Batch 54/64 loss: 0.28167057037353516
Batch 55/64 loss: 0.28431373834609985
Batch 56/64 loss: 0.2810612916946411
Batch 57/64 loss: 0.2881222367286682
Batch 58/64 loss: 0.2873046398162842
Batch 59/64 loss: 0.2784387469291687
Batch 60/64 loss: 0.2845773696899414
Batch 61/64 loss: 0.28947412967681885
Batch 62/64 loss: 0.29131901264190674
Batch 63/64 loss: 0.28375595808029175
Batch 64/64 loss: 0.28897029161453247
Epoch 254  Train loss: 0.2855441642742531  Val loss: 0.31294550969428625
Saving best model, epoch: 254
Epoch 255
-------------------------------
Batch 1/64 loss: 0.2826049327850342
Batch 2/64 loss: 0.2860932946205139
Batch 3/64 loss: 0.2847915291786194
Batch 4/64 loss: 0.2904065251350403
Batch 5/64 loss: 0.28205442428588867
Batch 6/64 loss: 0.27847981452941895
Batch 7/64 loss: 0.2961766719818115
Batch 8/64 loss: 0.2858450412750244
Batch 9/64 loss: 0.27805638313293457
Batch 10/64 loss: 0.28429675102233887
Batch 11/64 loss: 0.28862464427948
Batch 12/64 loss: 0.2914203405380249
Batch 13/64 loss: 0.28314363956451416
Batch 14/64 loss: 0.28497225046157837
Batch 15/64 loss: 0.28872740268707275
Batch 16/64 loss: 0.28569966554641724
Batch 17/64 loss: 0.29243338108062744
Batch 18/64 loss: 0.28355979919433594
Batch 19/64 loss: 0.2873314619064331
Batch 20/64 loss: 0.2814304828643799
Batch 21/64 loss: 0.2899073362350464
Batch 22/64 loss: 0.28683972358703613
Batch 23/64 loss: 0.28923821449279785
Batch 24/64 loss: 0.29124945402145386
Batch 25/64 loss: 0.28530794382095337
Batch 26/64 loss: 0.28302979469299316
Batch 27/64 loss: 0.28210145235061646
Batch 28/64 loss: 0.2837167978286743
Batch 29/64 loss: 0.28480589389801025
Batch 30/64 loss: 0.2954467535018921
Batch 31/64 loss: 0.28541791439056396
Batch 32/64 loss: 0.28565895557403564
Batch 33/64 loss: 0.2803056240081787
Batch 34/64 loss: 0.2813277244567871
Batch 35/64 loss: 0.28458118438720703
Batch 36/64 loss: 0.2880828380584717
Batch 37/64 loss: 0.2846863269805908
Batch 38/64 loss: 0.2828468084335327
Batch 39/64 loss: 0.28580808639526367
Batch 40/64 loss: 0.28724467754364014
Batch 41/64 loss: 0.2825617790222168
Batch 42/64 loss: 0.2871776819229126
Batch 43/64 loss: 0.2882431745529175
Batch 44/64 loss: 0.2844393253326416
Batch 45/64 loss: 0.2910022735595703
Batch 46/64 loss: 0.2854117751121521
Batch 47/64 loss: 0.29020488262176514
Batch 48/64 loss: 0.2861592769622803
Batch 49/64 loss: 0.28482282161712646
Batch 50/64 loss: 0.2885591387748718
Batch 51/64 loss: 0.2866072654724121
Batch 52/64 loss: 0.28277355432510376
Batch 53/64 loss: 0.2905834913253784
Batch 54/64 loss: 0.28324657678604126
Batch 55/64 loss: 0.28173601627349854
Batch 56/64 loss: 0.28583765029907227
Batch 57/64 loss: 0.28867876529693604
Batch 58/64 loss: 0.28363656997680664
Batch 59/64 loss: 0.2801215648651123
Batch 60/64 loss: 0.2841249704360962
Batch 61/64 loss: 0.2875366806983948
Batch 62/64 loss: 0.28918302059173584
Batch 63/64 loss: 0.2819368839263916
Batch 64/64 loss: 0.28510797023773193
Epoch 255  Train loss: 0.2858379303240309  Val loss: 0.31277928381031733
Saving best model, epoch: 255
Epoch 256
-------------------------------
Batch 1/64 loss: 0.27601325511932373
Batch 2/64 loss: 0.28482335805892944
Batch 3/64 loss: 0.2798025608062744
Batch 4/64 loss: 0.2784693241119385
Batch 5/64 loss: 0.28135013580322266
Batch 6/64 loss: 0.28419411182403564
Batch 7/64 loss: 0.2816739082336426
Batch 8/64 loss: 0.28245043754577637
Batch 9/64 loss: 0.28121238946914673
Batch 10/64 loss: 0.28108447790145874
Batch 11/64 loss: 0.2850766181945801
Batch 12/64 loss: 0.2854984998703003
Batch 13/64 loss: 0.28672027587890625
Batch 14/64 loss: 0.2866166830062866
Batch 15/64 loss: 0.2886604070663452
Batch 16/64 loss: 0.28078365325927734
Batch 17/64 loss: 0.28677940368652344
Batch 18/64 loss: 0.2894607186317444
Batch 19/64 loss: 0.2883702516555786
Batch 20/64 loss: 0.28125810623168945
Batch 21/64 loss: 0.28066563606262207
Batch 22/64 loss: 0.2804805040359497
Batch 23/64 loss: 0.2836695909500122
Batch 24/64 loss: 0.2892608642578125
Batch 25/64 loss: 0.2829548120498657
Batch 26/64 loss: 0.28569626808166504
Batch 27/64 loss: 0.28551602363586426
Batch 28/64 loss: 0.28544890880584717
Batch 29/64 loss: 0.28020715713500977
Batch 30/64 loss: 0.2817875146865845
Batch 31/64 loss: 0.2895618677139282
Batch 32/64 loss: 0.2834956645965576
Batch 33/64 loss: 0.2856266498565674
Batch 34/64 loss: 0.2886274456977844
Batch 35/64 loss: 0.28609609603881836
Batch 36/64 loss: 0.2942136526107788
Batch 37/64 loss: 0.27558112144470215
Batch 38/64 loss: 0.28398847579956055
Batch 39/64 loss: 0.282257080078125
Batch 40/64 loss: 0.28488796949386597
Batch 41/64 loss: 0.29315781593322754
Batch 42/64 loss: 0.2810490131378174
Batch 43/64 loss: 0.2848268747329712
Batch 44/64 loss: 0.29601895809173584
Batch 45/64 loss: 0.28157228231430054
Batch 46/64 loss: 0.2893478274345398
Batch 47/64 loss: 0.28737103939056396
Batch 48/64 loss: 0.28338998556137085
Batch 49/64 loss: 0.2857837677001953
Batch 50/64 loss: 0.2842441201210022
Batch 51/64 loss: 0.29413020610809326
Batch 52/64 loss: 0.28739047050476074
Batch 53/64 loss: 0.2885373830795288
Batch 54/64 loss: 0.28963184356689453
Batch 55/64 loss: 0.2918132543563843
Batch 56/64 loss: 0.2845403552055359
Batch 57/64 loss: 0.28701287508010864
Batch 58/64 loss: 0.2900250554084778
Batch 59/64 loss: 0.28120654821395874
Batch 60/64 loss: 0.2878025770187378
Batch 61/64 loss: 0.284260094165802
Batch 62/64 loss: 0.28693222999572754
Batch 63/64 loss: 0.2804812788963318
Batch 64/64 loss: 0.2824399471282959
Epoch 256  Train loss: 0.28506161091374416  Val loss: 0.3129333874204314
Epoch 257
-------------------------------
Batch 1/64 loss: 0.28237152099609375
Batch 2/64 loss: 0.2780860662460327
Batch 3/64 loss: 0.2830237150192261
Batch 4/64 loss: 0.2843594551086426
Batch 5/64 loss: 0.2838383913040161
Batch 6/64 loss: 0.28080642223358154
Batch 7/64 loss: 0.2836664915084839
Batch 8/64 loss: 0.28474974632263184
Batch 9/64 loss: 0.2796478271484375
Batch 10/64 loss: 0.28232020139694214
Batch 11/64 loss: 0.2818554639816284
Batch 12/64 loss: 0.2815205454826355
Batch 13/64 loss: 0.2829563617706299
Batch 14/64 loss: 0.287636399269104
Batch 15/64 loss: 0.28096961975097656
Batch 16/64 loss: 0.2795811891555786
Batch 17/64 loss: 0.2863318920135498
Batch 18/64 loss: 0.28415554761886597
Batch 19/64 loss: 0.2780325412750244
Batch 20/64 loss: 0.2899291515350342
Batch 21/64 loss: 0.2919062376022339
Batch 22/64 loss: 0.28256577253341675
Batch 23/64 loss: 0.29829347133636475
Batch 24/64 loss: 0.2794992923736572
Batch 25/64 loss: 0.2906315326690674
Batch 26/64 loss: 0.2925121784210205
Batch 27/64 loss: 0.2897074222564697
Batch 28/64 loss: 0.2835656404495239
Batch 29/64 loss: 0.2844090461730957
Batch 30/64 loss: 0.285566508769989
Batch 31/64 loss: 0.28587472438812256
Batch 32/64 loss: 0.2803371548652649
Batch 33/64 loss: 0.2935826778411865
Batch 34/64 loss: 0.27947044372558594
Batch 35/64 loss: 0.2824740409851074
Batch 36/64 loss: 0.2870357036590576
Batch 37/64 loss: 0.28173696994781494
Batch 38/64 loss: 0.28597164154052734
Batch 39/64 loss: 0.2884100079536438
Batch 40/64 loss: 0.2850697636604309
Batch 41/64 loss: 0.2915988564491272
Batch 42/64 loss: 0.28449881076812744
Batch 43/64 loss: 0.2830939292907715
Batch 44/64 loss: 0.2903033494949341
Batch 45/64 loss: 0.28854691982269287
Batch 46/64 loss: 0.2803347110748291
Batch 47/64 loss: 0.28635263442993164
Batch 48/64 loss: 0.29311060905456543
Batch 49/64 loss: 0.28048789501190186
Batch 50/64 loss: 0.2840464115142822
Batch 51/64 loss: 0.2844911217689514
Batch 52/64 loss: 0.28720664978027344
Batch 53/64 loss: 0.2782355546951294
Batch 54/64 loss: 0.27963441610336304
Batch 55/64 loss: 0.28915560245513916
Batch 56/64 loss: 0.28291618824005127
Batch 57/64 loss: 0.2902316451072693
Batch 58/64 loss: 0.2851533889770508
Batch 59/64 loss: 0.28377044200897217
Batch 60/64 loss: 0.289359450340271
Batch 61/64 loss: 0.2843506336212158
Batch 62/64 loss: 0.27462345361709595
Batch 63/64 loss: 0.2918344736099243
Batch 64/64 loss: 0.2914949059486389
Epoch 257  Train loss: 0.2849634055997811  Val loss: 0.31298966956712126
Epoch 258
-------------------------------
Batch 1/64 loss: 0.2788574695587158
Batch 2/64 loss: 0.290071964263916
Batch 3/64 loss: 0.2778671979904175
Batch 4/64 loss: 0.28170955181121826
Batch 5/64 loss: 0.28211677074432373
Batch 6/64 loss: 0.2854488492012024
Batch 7/64 loss: 0.2861889600753784
Batch 8/64 loss: 0.2869068384170532
Batch 9/64 loss: 0.28433680534362793
Batch 10/64 loss: 0.282029390335083
Batch 11/64 loss: 0.28208863735198975
Batch 12/64 loss: 0.2799350619316101
Batch 13/64 loss: 0.29048770666122437
Batch 14/64 loss: 0.28887754678726196
Batch 15/64 loss: 0.27987396717071533
Batch 16/64 loss: 0.2758065462112427
Batch 17/64 loss: 0.2807815670967102
Batch 18/64 loss: 0.2845689058303833
Batch 19/64 loss: 0.2849026918411255
Batch 20/64 loss: 0.28727394342422485
Batch 21/64 loss: 0.28689080476760864
Batch 22/64 loss: 0.28209006786346436
Batch 23/64 loss: 0.2812671661376953
Batch 24/64 loss: 0.2850903868675232
Batch 25/64 loss: 0.28277039527893066
Batch 26/64 loss: 0.2836564779281616
Batch 27/64 loss: 0.2897135019302368
Batch 28/64 loss: 0.2871825098991394
Batch 29/64 loss: 0.2826966643333435
Batch 30/64 loss: 0.28308409452438354
Batch 31/64 loss: 0.2770099639892578
Batch 32/64 loss: 0.2842077612876892
Batch 33/64 loss: 0.2840045690536499
Batch 34/64 loss: 0.29518455266952515
Batch 35/64 loss: 0.28329169750213623
Batch 36/64 loss: 0.28408336639404297
Batch 37/64 loss: 0.2877025604248047
Batch 38/64 loss: 0.2790437936782837
Batch 39/64 loss: 0.2895146608352661
Batch 40/64 loss: 0.28359150886535645
Batch 41/64 loss: 0.28184807300567627
Batch 42/64 loss: 0.2744007110595703
Batch 43/64 loss: 0.28346502780914307
Batch 44/64 loss: 0.29057538509368896
Batch 45/64 loss: 0.2869913578033447
Batch 46/64 loss: 0.2873777151107788
Batch 47/64 loss: 0.28727221488952637
Batch 48/64 loss: 0.2901623249053955
Batch 49/64 loss: 0.2912919521331787
Batch 50/64 loss: 0.2855346202850342
Batch 51/64 loss: 0.2821875810623169
Batch 52/64 loss: 0.28761404752731323
Batch 53/64 loss: 0.2819007635116577
Batch 54/64 loss: 0.27945005893707275
Batch 55/64 loss: 0.2790844440460205
Batch 56/64 loss: 0.27929234504699707
Batch 57/64 loss: 0.2885180115699768
Batch 58/64 loss: 0.2881721258163452
Batch 59/64 loss: 0.28343093395233154
Batch 60/64 loss: 0.2831975817680359
Batch 61/64 loss: 0.28472721576690674
Batch 62/64 loss: 0.28653228282928467
Batch 63/64 loss: 0.2799112796783447
Batch 64/64 loss: 0.27946263551712036
Epoch 258  Train loss: 0.2841528142199797  Val loss: 0.3131849395040794
Epoch 259
-------------------------------
Batch 1/64 loss: 0.281350314617157
Batch 2/64 loss: 0.289182186126709
Batch 3/64 loss: 0.2866208553314209
Batch 4/64 loss: 0.2858257293701172
Batch 5/64 loss: 0.28302085399627686
Batch 6/64 loss: 0.2831254005432129
Batch 7/64 loss: 0.28157711029052734
Batch 8/64 loss: 0.2743205428123474
Batch 9/64 loss: 0.2847273349761963
Batch 10/64 loss: 0.27818095684051514
Batch 11/64 loss: 0.28219902515411377
Batch 12/64 loss: 0.28539419174194336
Batch 13/64 loss: 0.28574395179748535
Batch 14/64 loss: 0.2840372323989868
Batch 15/64 loss: 0.28832268714904785
Batch 16/64 loss: 0.27577078342437744
Batch 17/64 loss: 0.2872864007949829
Batch 18/64 loss: 0.2887458801269531
Batch 19/64 loss: 0.2802860736846924
Batch 20/64 loss: 0.2829166650772095
Batch 21/64 loss: 0.2838192582130432
Batch 22/64 loss: 0.28952455520629883
Batch 23/64 loss: 0.2864370346069336
Batch 24/64 loss: 0.28509557247161865
Batch 25/64 loss: 0.2848794460296631
Batch 26/64 loss: 0.282947301864624
Batch 27/64 loss: 0.2843102812767029
Batch 28/64 loss: 0.28792691230773926
Batch 29/64 loss: 0.28565824031829834
Batch 30/64 loss: 0.28396713733673096
Batch 31/64 loss: 0.28448164463043213
Batch 32/64 loss: 0.2806486487388611
Batch 33/64 loss: 0.28619539737701416
Batch 34/64 loss: 0.28254079818725586
Batch 35/64 loss: 0.28609156608581543
Batch 36/64 loss: 0.2817162871360779
Batch 37/64 loss: 0.2831207513809204
Batch 38/64 loss: 0.2789970636367798
Batch 39/64 loss: 0.2785986661911011
Batch 40/64 loss: 0.2846488952636719
Batch 41/64 loss: 0.2776191234588623
Batch 42/64 loss: 0.28969693183898926
Batch 43/64 loss: 0.27812397480010986
Batch 44/64 loss: 0.2943640351295471
Batch 45/64 loss: 0.29261505603790283
Batch 46/64 loss: 0.29346275329589844
Batch 47/64 loss: 0.2799041271209717
Batch 48/64 loss: 0.28495627641677856
Batch 49/64 loss: 0.285433292388916
Batch 50/64 loss: 0.2915358543395996
Batch 51/64 loss: 0.2836400270462036
Batch 52/64 loss: 0.290218710899353
Batch 53/64 loss: 0.286297082901001
Batch 54/64 loss: 0.2856268286705017
Batch 55/64 loss: 0.2853814363479614
Batch 56/64 loss: 0.28431200981140137
Batch 57/64 loss: 0.27979421615600586
Batch 58/64 loss: 0.28086984157562256
Batch 59/64 loss: 0.2823120355606079
Batch 60/64 loss: 0.2852727174758911
Batch 61/64 loss: 0.287664532661438
Batch 62/64 loss: 0.28449976444244385
Batch 63/64 loss: 0.28258049488067627
Batch 64/64 loss: 0.28489720821380615
Epoch 259  Train loss: 0.28439362610087676  Val loss: 0.31360980755684714
Epoch 260
-------------------------------
Batch 1/64 loss: 0.28407520055770874
Batch 2/64 loss: 0.27998828887939453
Batch 3/64 loss: 0.28175318241119385
Batch 4/64 loss: 0.292452335357666
Batch 5/64 loss: 0.28857797384262085
Batch 6/64 loss: 0.2787558436393738
Batch 7/64 loss: 0.28042566776275635
Batch 8/64 loss: 0.2842949628829956
Batch 9/64 loss: 0.2861520051956177
Batch 10/64 loss: 0.2839193344116211
Batch 11/64 loss: 0.2818044424057007
Batch 12/64 loss: 0.28256046772003174
Batch 13/64 loss: 0.28448736667633057
Batch 14/64 loss: 0.2847801446914673
Batch 15/64 loss: 0.2824133038520813
Batch 16/64 loss: 0.2749781608581543
Batch 17/64 loss: 0.2841176390647888
Batch 18/64 loss: 0.2853574752807617
Batch 19/64 loss: 0.28913551568984985
Batch 20/64 loss: 0.287595272064209
Batch 21/64 loss: 0.28761911392211914
Batch 22/64 loss: 0.2895309329032898
Batch 23/64 loss: 0.28270798921585083
Batch 24/64 loss: 0.28454798460006714
Batch 25/64 loss: 0.28628939390182495
Batch 26/64 loss: 0.2825735807418823
Batch 27/64 loss: 0.27860403060913086
Batch 28/64 loss: 0.28301823139190674
Batch 29/64 loss: 0.2966187596321106
Batch 30/64 loss: 0.2809630036354065
Batch 31/64 loss: 0.2821112871170044
Batch 32/64 loss: 0.28341472148895264
Batch 33/64 loss: 0.28543317317962646
Batch 34/64 loss: 0.2859647274017334
Batch 35/64 loss: 0.2818447947502136
Batch 36/64 loss: 0.2845284342765808
Batch 37/64 loss: 0.2817314863204956
Batch 38/64 loss: 0.28980207443237305
Batch 39/64 loss: 0.2845628261566162
Batch 40/64 loss: 0.2853219509124756
Batch 41/64 loss: 0.28407466411590576
Batch 42/64 loss: 0.2847251296043396
Batch 43/64 loss: 0.28232836723327637
Batch 44/64 loss: 0.28422534465789795
Batch 45/64 loss: 0.28616148233413696
Batch 46/64 loss: 0.2921788692474365
Batch 47/64 loss: 0.27868521213531494
Batch 48/64 loss: 0.29210853576660156
Batch 49/64 loss: 0.2851012945175171
Batch 50/64 loss: 0.2836740016937256
Batch 51/64 loss: 0.2816726565361023
Batch 52/64 loss: 0.2777305245399475
Batch 53/64 loss: 0.2820425033569336
Batch 54/64 loss: 0.28785228729248047
Batch 55/64 loss: 0.2853713631629944
Batch 56/64 loss: 0.2833542227745056
Batch 57/64 loss: 0.28650522232055664
Batch 58/64 loss: 0.2852240800857544
Batch 59/64 loss: 0.28722047805786133
Batch 60/64 loss: 0.28309398889541626
Batch 61/64 loss: 0.28638768196105957
Batch 62/64 loss: 0.28617095947265625
Batch 63/64 loss: 0.28645455837249756
Batch 64/64 loss: 0.2791508436203003
Epoch 260  Train loss: 0.28449442573622163  Val loss: 0.31269554256163923
Saving best model, epoch: 260
Epoch 261
-------------------------------
Batch 1/64 loss: 0.2808520197868347
Batch 2/64 loss: 0.28661835193634033
Batch 3/64 loss: 0.28544020652770996
Batch 4/64 loss: 0.2832064628601074
Batch 5/64 loss: 0.2811875343322754
Batch 6/64 loss: 0.2848696708679199
Batch 7/64 loss: 0.28258609771728516
Batch 8/64 loss: 0.28389644622802734
Batch 9/64 loss: 0.28443074226379395
Batch 10/64 loss: 0.2832276225090027
Batch 11/64 loss: 0.2917231321334839
Batch 12/64 loss: 0.28620344400405884
Batch 13/64 loss: 0.2838454842567444
Batch 14/64 loss: 0.2837768793106079
Batch 15/64 loss: 0.2795935869216919
Batch 16/64 loss: 0.2830924987792969
Batch 17/64 loss: 0.27850812673568726
Batch 18/64 loss: 0.2813929319381714
Batch 19/64 loss: 0.27939295768737793
Batch 20/64 loss: 0.2904773950576782
Batch 21/64 loss: 0.28295499086380005
Batch 22/64 loss: 0.2822301387786865
Batch 23/64 loss: 0.2840759754180908
Batch 24/64 loss: 0.27967965602874756
Batch 25/64 loss: 0.27617132663726807
Batch 26/64 loss: 0.2832808494567871
Batch 27/64 loss: 0.2850128412246704
Batch 28/64 loss: 0.2809762954711914
Batch 29/64 loss: 0.2846323251724243
Batch 30/64 loss: 0.28029853105545044
Batch 31/64 loss: 0.28212690353393555
Batch 32/64 loss: 0.2912907600402832
Batch 33/64 loss: 0.2878837585449219
Batch 34/64 loss: 0.2842191457748413
Batch 35/64 loss: 0.2769072651863098
Batch 36/64 loss: 0.2848661541938782
Batch 37/64 loss: 0.29020339250564575
Batch 38/64 loss: 0.28657257556915283
Batch 39/64 loss: 0.28142988681793213
Batch 40/64 loss: 0.2857016324996948
Batch 41/64 loss: 0.28392136096954346
Batch 42/64 loss: 0.2833828926086426
Batch 43/64 loss: 0.27957379817962646
Batch 44/64 loss: 0.28248488903045654
Batch 45/64 loss: 0.2864035367965698
Batch 46/64 loss: 0.2852182388305664
Batch 47/64 loss: 0.2800202965736389
Batch 48/64 loss: 0.28609490394592285
Batch 49/64 loss: 0.2910165786743164
Batch 50/64 loss: 0.28624391555786133
Batch 51/64 loss: 0.28342270851135254
Batch 52/64 loss: 0.28854936361312866
Batch 53/64 loss: 0.2821539044380188
Batch 54/64 loss: 0.28473877906799316
Batch 55/64 loss: 0.2792835831642151
Batch 56/64 loss: 0.2879742980003357
Batch 57/64 loss: 0.2806311845779419
Batch 58/64 loss: 0.2870277762413025
Batch 59/64 loss: 0.2819252014160156
Batch 60/64 loss: 0.28341352939605713
Batch 61/64 loss: 0.2872488498687744
Batch 62/64 loss: 0.27484583854675293
Batch 63/64 loss: 0.2871350049972534
Batch 64/64 loss: 0.29577380418777466
Epoch 261  Train loss: 0.2839117926709792  Val loss: 0.3138751565795584
Epoch 262
-------------------------------
Batch 1/64 loss: 0.2887694835662842
Batch 2/64 loss: 0.2835531234741211
Batch 3/64 loss: 0.2854347229003906
Batch 4/64 loss: 0.2804720401763916
Batch 5/64 loss: 0.29244041442871094
Batch 6/64 loss: 0.2804715633392334
Batch 7/64 loss: 0.2926098108291626
Batch 8/64 loss: 0.28590983152389526
Batch 9/64 loss: 0.28075075149536133
Batch 10/64 loss: 0.2861316204071045
Batch 11/64 loss: 0.2804676294326782
Batch 12/64 loss: 0.2812920808792114
Batch 13/64 loss: 0.28138697147369385
Batch 14/64 loss: 0.2805979251861572
Batch 15/64 loss: 0.28556472063064575
Batch 16/64 loss: 0.27878624200820923
Batch 17/64 loss: 0.2829298973083496
Batch 18/64 loss: 0.281893253326416
Batch 19/64 loss: 0.2839488983154297
Batch 20/64 loss: 0.2909892201423645
Batch 21/64 loss: 0.28299832344055176
Batch 22/64 loss: 0.28324151039123535
Batch 23/64 loss: 0.28578460216522217
Batch 24/64 loss: 0.2880479097366333
Batch 25/64 loss: 0.28112733364105225
Batch 26/64 loss: 0.2908897399902344
Batch 27/64 loss: 0.2817240357398987
Batch 28/64 loss: 0.2778196930885315
Batch 29/64 loss: 0.28955399990081787
Batch 30/64 loss: 0.2881038188934326
Batch 31/64 loss: 0.288244366645813
Batch 32/64 loss: 0.28063857555389404
Batch 33/64 loss: 0.2826354503631592
Batch 34/64 loss: 0.28626441955566406
Batch 35/64 loss: 0.2865270972251892
Batch 36/64 loss: 0.2827572822570801
Batch 37/64 loss: 0.28910958766937256
Batch 38/64 loss: 0.287513792514801
Batch 39/64 loss: 0.2817382216453552
Batch 40/64 loss: 0.2881671190261841
Batch 41/64 loss: 0.288677453994751
Batch 42/64 loss: 0.2873760461807251
Batch 43/64 loss: 0.2862057089805603
Batch 44/64 loss: 0.2877984046936035
Batch 45/64 loss: 0.28267061710357666
Batch 46/64 loss: 0.28902435302734375
Batch 47/64 loss: 0.28987330198287964
Batch 48/64 loss: 0.2862344980239868
Batch 49/64 loss: 0.2874923348426819
Batch 50/64 loss: 0.28331100940704346
Batch 51/64 loss: 0.27683448791503906
Batch 52/64 loss: 0.27810806035995483
Batch 53/64 loss: 0.2853206992149353
Batch 54/64 loss: 0.28490763902664185
Batch 55/64 loss: 0.28545981645584106
Batch 56/64 loss: 0.2840859293937683
Batch 57/64 loss: 0.2841852903366089
Batch 58/64 loss: 0.279502272605896
Batch 59/64 loss: 0.2928704023361206
Batch 60/64 loss: 0.28413599729537964
Batch 61/64 loss: 0.2826851010322571
Batch 62/64 loss: 0.287333607673645
Batch 63/64 loss: 0.2956967353820801
Batch 64/64 loss: 0.28431397676467896
Epoch 262  Train loss: 0.2850245071392433  Val loss: 0.3134188658183383
Epoch 263
-------------------------------
Batch 1/64 loss: 0.28734290599823
Batch 2/64 loss: 0.28692758083343506
Batch 3/64 loss: 0.27591681480407715
Batch 4/64 loss: 0.2837923765182495
Batch 5/64 loss: 0.27641797065734863
Batch 6/64 loss: 0.2841062545776367
Batch 7/64 loss: 0.2808384895324707
Batch 8/64 loss: 0.27952778339385986
Batch 9/64 loss: 0.28642696142196655
Batch 10/64 loss: 0.2841697335243225
Batch 11/64 loss: 0.2849084734916687
Batch 12/64 loss: 0.28772997856140137
Batch 13/64 loss: 0.279154896736145
Batch 14/64 loss: 0.28281915187835693
Batch 15/64 loss: 0.2871490716934204
Batch 16/64 loss: 0.2865365743637085
Batch 17/64 loss: 0.2911115288734436
Batch 18/64 loss: 0.2849998474121094
Batch 19/64 loss: 0.2875160574913025
Batch 20/64 loss: 0.29595547914505005
Batch 21/64 loss: 0.2766264081001282
Batch 22/64 loss: 0.2886781692504883
Batch 23/64 loss: 0.2838415503501892
Batch 24/64 loss: 0.28936731815338135
Batch 25/64 loss: 0.28637832403182983
Batch 26/64 loss: 0.28392279148101807
Batch 27/64 loss: 0.2946650981903076
Batch 28/64 loss: 0.2911694049835205
Batch 29/64 loss: 0.28115350008010864
Batch 30/64 loss: 0.2804744243621826
Batch 31/64 loss: 0.2809770703315735
Batch 32/64 loss: 0.28272104263305664
Batch 33/64 loss: 0.2923905849456787
Batch 34/64 loss: 0.29034847021102905
Batch 35/64 loss: 0.2851179242134094
Batch 36/64 loss: 0.28125905990600586
Batch 37/64 loss: 0.2896357774734497
Batch 38/64 loss: 0.28703343868255615
Batch 39/64 loss: 0.28368330001831055
Batch 40/64 loss: 0.28954988718032837
Batch 41/64 loss: 0.28672146797180176
Batch 42/64 loss: 0.2841411828994751
Batch 43/64 loss: 0.2804785966873169
Batch 44/64 loss: 0.28250062465667725
Batch 45/64 loss: 0.2814447283744812
Batch 46/64 loss: 0.2781945466995239
Batch 47/64 loss: 0.2781878709793091
Batch 48/64 loss: 0.2839435338973999
Batch 49/64 loss: 0.2830599546432495
Batch 50/64 loss: 0.2824738025665283
Batch 51/64 loss: 0.2844403386116028
Batch 52/64 loss: 0.28875136375427246
Batch 53/64 loss: 0.2807976007461548
Batch 54/64 loss: 0.2830735445022583
Batch 55/64 loss: 0.28164535760879517
Batch 56/64 loss: 0.2837035655975342
Batch 57/64 loss: 0.2788430452346802
Batch 58/64 loss: 0.2898895740509033
Batch 59/64 loss: 0.28770339488983154
Batch 60/64 loss: 0.28035104274749756
Batch 61/64 loss: 0.2817206382751465
Batch 62/64 loss: 0.2874526381492615
Batch 63/64 loss: 0.28445911407470703
Batch 64/64 loss: 0.27723175287246704
Epoch 263  Train loss: 0.2844587108668159  Val loss: 0.31356018433456156
Epoch 264
-------------------------------
Batch 1/64 loss: 0.2863645553588867
Batch 2/64 loss: 0.3029029369354248
Batch 3/64 loss: 0.2806140184402466
Batch 4/64 loss: 0.2825894355773926
Batch 5/64 loss: 0.28641802072525024
Batch 6/64 loss: 0.2780616879463196
Batch 7/64 loss: 0.2845824360847473
Batch 8/64 loss: 0.28075873851776123
Batch 9/64 loss: 0.28060632944107056
Batch 10/64 loss: 0.2817245125770569
Batch 11/64 loss: 0.2913860082626343
Batch 12/64 loss: 0.28406548500061035
Batch 13/64 loss: 0.2791486978530884
Batch 14/64 loss: 0.2782440185546875
Batch 15/64 loss: 0.2890254259109497
Batch 16/64 loss: 0.28837013244628906
Batch 17/64 loss: 0.28067129850387573
Batch 18/64 loss: 0.2764246463775635
Batch 19/64 loss: 0.28001290559768677
Batch 20/64 loss: 0.2796875238418579
Batch 21/64 loss: 0.28216421604156494
Batch 22/64 loss: 0.2837563753128052
Batch 23/64 loss: 0.2849394679069519
Batch 24/64 loss: 0.2800557613372803
Batch 25/64 loss: 0.2861245274543762
Batch 26/64 loss: 0.27853572368621826
Batch 27/64 loss: 0.28897881507873535
Batch 28/64 loss: 0.2822198271751404
Batch 29/64 loss: 0.2793009281158447
Batch 30/64 loss: 0.2839967608451843
Batch 31/64 loss: 0.2786647081375122
Batch 32/64 loss: 0.28148555755615234
Batch 33/64 loss: 0.2852500081062317
Batch 34/64 loss: 0.2860499620437622
Batch 35/64 loss: 0.27719753980636597
Batch 36/64 loss: 0.2828406095504761
Batch 37/64 loss: 0.27872729301452637
Batch 38/64 loss: 0.28675878047943115
Batch 39/64 loss: 0.27916109561920166
Batch 40/64 loss: 0.2913782596588135
Batch 41/64 loss: 0.2976483106613159
Batch 42/64 loss: 0.28357869386672974
Batch 43/64 loss: 0.2887709140777588
Batch 44/64 loss: 0.2846999168395996
Batch 45/64 loss: 0.28579628467559814
Batch 46/64 loss: 0.2816203236579895
Batch 47/64 loss: 0.27631819248199463
Batch 48/64 loss: 0.2775465250015259
Batch 49/64 loss: 0.287039577960968
Batch 50/64 loss: 0.28517043590545654
Batch 51/64 loss: 0.29083627462387085
Batch 52/64 loss: 0.28215813636779785
Batch 53/64 loss: 0.2825716733932495
Batch 54/64 loss: 0.2835409641265869
Batch 55/64 loss: 0.28471994400024414
Batch 56/64 loss: 0.2803238034248352
Batch 57/64 loss: 0.2849709391593933
Batch 58/64 loss: 0.2860729694366455
Batch 59/64 loss: 0.2841694951057434
Batch 60/64 loss: 0.28289496898651123
Batch 61/64 loss: 0.2815440893173218
Batch 62/64 loss: 0.29002439975738525
Batch 63/64 loss: 0.2832667827606201
Batch 64/64 loss: 0.28213977813720703
Epoch 264  Train loss: 0.28370405458936504  Val loss: 0.31328288509264024
Epoch 265
-------------------------------
Batch 1/64 loss: 0.28139209747314453
Batch 2/64 loss: 0.282428503036499
Batch 3/64 loss: 0.2750058174133301
Batch 4/64 loss: 0.28393590450286865
Batch 5/64 loss: 0.2835737466812134
Batch 6/64 loss: 0.28771424293518066
Batch 7/64 loss: 0.28141629695892334
Batch 8/64 loss: 0.2878756523132324
Batch 9/64 loss: 0.2791374921798706
Batch 10/64 loss: 0.28277480602264404
Batch 11/64 loss: 0.2835143804550171
Batch 12/64 loss: 0.2831178903579712
Batch 13/64 loss: 0.28115153312683105
Batch 14/64 loss: 0.27931004762649536
Batch 15/64 loss: 0.28066128492355347
Batch 16/64 loss: 0.29025697708129883
Batch 17/64 loss: 0.27678948640823364
Batch 18/64 loss: 0.2830781936645508
Batch 19/64 loss: 0.2886013984680176
Batch 20/64 loss: 0.2831634283065796
Batch 21/64 loss: 0.2774825096130371
Batch 22/64 loss: 0.28735285997390747
Batch 23/64 loss: 0.2848629951477051
Batch 24/64 loss: 0.28123533725738525
Batch 25/64 loss: 0.28305792808532715
Batch 26/64 loss: 0.28684383630752563
Batch 27/64 loss: 0.2778223752975464
Batch 28/64 loss: 0.2884750962257385
Batch 29/64 loss: 0.282326877117157
Batch 30/64 loss: 0.28540748357772827
Batch 31/64 loss: 0.28240150213241577
Batch 32/64 loss: 0.2844586968421936
Batch 33/64 loss: 0.2892799973487854
Batch 34/64 loss: 0.28762149810791016
Batch 35/64 loss: 0.2870582342147827
Batch 36/64 loss: 0.2812528610229492
Batch 37/64 loss: 0.29729515314102173
Batch 38/64 loss: 0.28358548879623413
Batch 39/64 loss: 0.2825876474380493
Batch 40/64 loss: 0.28431427478790283
Batch 41/64 loss: 0.2824573516845703
Batch 42/64 loss: 0.2781131863594055
Batch 43/64 loss: 0.28752386569976807
Batch 44/64 loss: 0.2955605983734131
Batch 45/64 loss: 0.2830711603164673
Batch 46/64 loss: 0.29236090183258057
Batch 47/64 loss: 0.2740896940231323
Batch 48/64 loss: 0.28024405241012573
Batch 49/64 loss: 0.28178614377975464
Batch 50/64 loss: 0.28918004035949707
Batch 51/64 loss: 0.28654593229293823
Batch 52/64 loss: 0.2855672240257263
Batch 53/64 loss: 0.28578805923461914
Batch 54/64 loss: 0.28411930799484253
Batch 55/64 loss: 0.2845531702041626
Batch 56/64 loss: 0.28119611740112305
Batch 57/64 loss: 0.2867923378944397
Batch 58/64 loss: 0.2856484055519104
Batch 59/64 loss: 0.28226810693740845
Batch 60/64 loss: 0.2851220965385437
Batch 61/64 loss: 0.282093346118927
Batch 62/64 loss: 0.27772217988967896
Batch 63/64 loss: 0.27804386615753174
Batch 64/64 loss: 0.282942533493042
Epoch 265  Train loss: 0.28379099415797815  Val loss: 0.31214242763945327
Saving best model, epoch: 265
Epoch 266
-------------------------------
Batch 1/64 loss: 0.28020405769348145
Batch 2/64 loss: 0.28521955013275146
Batch 3/64 loss: 0.2822234630584717
Batch 4/64 loss: 0.28071606159210205
Batch 5/64 loss: 0.283108115196228
Batch 6/64 loss: 0.28392624855041504
Batch 7/64 loss: 0.2833373546600342
Batch 8/64 loss: 0.29134804010391235
Batch 9/64 loss: 0.29154229164123535
Batch 10/64 loss: 0.2837725877761841
Batch 11/64 loss: 0.28424072265625
Batch 12/64 loss: 0.283236026763916
Batch 13/64 loss: 0.27864938974380493
Batch 14/64 loss: 0.2810155749320984
Batch 15/64 loss: 0.2820424437522888
Batch 16/64 loss: 0.28953230381011963
Batch 17/64 loss: 0.2836878299713135
Batch 18/64 loss: 0.27941638231277466
Batch 19/64 loss: 0.2856895923614502
Batch 20/64 loss: 0.2782934904098511
Batch 21/64 loss: 0.2821442484855652
Batch 22/64 loss: 0.27622997760772705
Batch 23/64 loss: 0.29333555698394775
Batch 24/64 loss: 0.28731995820999146
Batch 25/64 loss: 0.2856072187423706
Batch 26/64 loss: 0.27856552600860596
Batch 27/64 loss: 0.281086802482605
Batch 28/64 loss: 0.2856457233428955
Batch 29/64 loss: 0.28412342071533203
Batch 30/64 loss: 0.28430449962615967
Batch 31/64 loss: 0.2803571820259094
Batch 32/64 loss: 0.2783210277557373
Batch 33/64 loss: 0.27900511026382446
Batch 34/64 loss: 0.2802908420562744
Batch 35/64 loss: 0.2803078889846802
Batch 36/64 loss: 0.27785277366638184
Batch 37/64 loss: 0.2788847088813782
Batch 38/64 loss: 0.28187423944473267
Batch 39/64 loss: 0.28648316860198975
Batch 40/64 loss: 0.28658032417297363
Batch 41/64 loss: 0.283211886882782
Batch 42/64 loss: 0.2780693769454956
Batch 43/64 loss: 0.28391391038894653
Batch 44/64 loss: 0.284604012966156
Batch 45/64 loss: 0.28964394330978394
Batch 46/64 loss: 0.2827155590057373
Batch 47/64 loss: 0.2854534387588501
Batch 48/64 loss: 0.28160667419433594
Batch 49/64 loss: 0.2850548028945923
Batch 50/64 loss: 0.28516149520874023
Batch 51/64 loss: 0.2834872603416443
Batch 52/64 loss: 0.2894556522369385
Batch 53/64 loss: 0.2950136661529541
Batch 54/64 loss: 0.28352153301239014
Batch 55/64 loss: 0.2868936061859131
Batch 56/64 loss: 0.2863185405731201
Batch 57/64 loss: 0.28078728914260864
Batch 58/64 loss: 0.28610920906066895
Batch 59/64 loss: 0.2830466628074646
Batch 60/64 loss: 0.2847839593887329
Batch 61/64 loss: 0.2801445722579956
Batch 62/64 loss: 0.2861902713775635
Batch 63/64 loss: 0.2863428592681885
Batch 64/64 loss: 0.2807435989379883
Epoch 266  Train loss: 0.2836330918704762  Val loss: 0.31371871056835265
Epoch 267
-------------------------------
Batch 1/64 loss: 0.2822992205619812
Batch 2/64 loss: 0.2847124934196472
Batch 3/64 loss: 0.288362979888916
Batch 4/64 loss: 0.27743154764175415
Batch 5/64 loss: 0.29063230752944946
Batch 6/64 loss: 0.27904266119003296
Batch 7/64 loss: 0.2843918800354004
Batch 8/64 loss: 0.2777257561683655
Batch 9/64 loss: 0.2840767502784729
Batch 10/64 loss: 0.28494638204574585
Batch 11/64 loss: 0.27637404203414917
Batch 12/64 loss: 0.2770124077796936
Batch 13/64 loss: 0.2839716672897339
Batch 14/64 loss: 0.28760021924972534
Batch 15/64 loss: 0.2836109399795532
Batch 16/64 loss: 0.2827838063240051
Batch 17/64 loss: 0.28410202264785767
Batch 18/64 loss: 0.2796980142593384
Batch 19/64 loss: 0.2886354923248291
Batch 20/64 loss: 0.2826322913169861
Batch 21/64 loss: 0.2819007635116577
Batch 22/64 loss: 0.276530385017395
Batch 23/64 loss: 0.2753477096557617
Batch 24/64 loss: 0.28209424018859863
Batch 25/64 loss: 0.2870006561279297
Batch 26/64 loss: 0.2829483151435852
Batch 27/64 loss: 0.27929866313934326
Batch 28/64 loss: 0.2813682556152344
Batch 29/64 loss: 0.2786107063293457
Batch 30/64 loss: 0.28502702713012695
Batch 31/64 loss: 0.28710687160491943
Batch 32/64 loss: 0.2758355140686035
Batch 33/64 loss: 0.2813733220100403
Batch 34/64 loss: 0.277743399143219
Batch 35/64 loss: 0.28068917989730835
Batch 36/64 loss: 0.286612868309021
Batch 37/64 loss: 0.2819347381591797
Batch 38/64 loss: 0.27922993898391724
Batch 39/64 loss: 0.288046658039093
Batch 40/64 loss: 0.2817169427871704
Batch 41/64 loss: 0.28274428844451904
Batch 42/64 loss: 0.2816562056541443
Batch 43/64 loss: 0.27657103538513184
Batch 44/64 loss: 0.2837003469467163
Batch 45/64 loss: 0.28069478273391724
Batch 46/64 loss: 0.28226733207702637
Batch 47/64 loss: 0.2836291790008545
Batch 48/64 loss: 0.2865462303161621
Batch 49/64 loss: 0.28092193603515625
Batch 50/64 loss: 0.276065468788147
Batch 51/64 loss: 0.2817597985267639
Batch 52/64 loss: 0.2869570255279541
Batch 53/64 loss: 0.2905718684196472
Batch 54/64 loss: 0.2883265018463135
Batch 55/64 loss: 0.2824251651763916
Batch 56/64 loss: 0.27804142236709595
Batch 57/64 loss: 0.28983283042907715
Batch 58/64 loss: 0.28336870670318604
Batch 59/64 loss: 0.2831268310546875
Batch 60/64 loss: 0.2819327712059021
Batch 61/64 loss: 0.28853970766067505
Batch 62/64 loss: 0.2848179340362549
Batch 63/64 loss: 0.28758418560028076
Batch 64/64 loss: 0.2881227135658264
Epoch 267  Train loss: 0.28280208040686217  Val loss: 0.31411947786193534
Epoch 268
-------------------------------
Batch 1/64 loss: 0.2773258090019226
Batch 2/64 loss: 0.27806270122528076
Batch 3/64 loss: 0.28411322832107544
Batch 4/64 loss: 0.2785285711288452
Batch 5/64 loss: 0.28046244382858276
Batch 6/64 loss: 0.28124117851257324
Batch 7/64 loss: 0.2823159694671631
Batch 8/64 loss: 0.2765611410140991
Batch 9/64 loss: 0.286080002784729
Batch 10/64 loss: 0.28082406520843506
Batch 11/64 loss: 0.2912972569465637
Batch 12/64 loss: 0.2899843454360962
Batch 13/64 loss: 0.28180938959121704
Batch 14/64 loss: 0.27629977464675903
Batch 15/64 loss: 0.28105735778808594
Batch 16/64 loss: 0.2787354588508606
Batch 17/64 loss: 0.29185330867767334
Batch 18/64 loss: 0.28355056047439575
Batch 19/64 loss: 0.2831403613090515
Batch 20/64 loss: 0.276625394821167
Batch 21/64 loss: 0.28781723976135254
Batch 22/64 loss: 0.29093754291534424
Batch 23/64 loss: 0.27605319023132324
Batch 24/64 loss: 0.28685784339904785
Batch 25/64 loss: 0.276752769947052
Batch 26/64 loss: 0.2855947017669678
Batch 27/64 loss: 0.2805129885673523
Batch 28/64 loss: 0.28286492824554443
Batch 29/64 loss: 0.28877806663513184
Batch 30/64 loss: 0.28282904624938965
Batch 31/64 loss: 0.2906566858291626
Batch 32/64 loss: 0.2789801359176636
Batch 33/64 loss: 0.2896196246147156
Batch 34/64 loss: 0.2781047821044922
Batch 35/64 loss: 0.2840454578399658
Batch 36/64 loss: 0.27706629037857056
Batch 37/64 loss: 0.28207337856292725
Batch 38/64 loss: 0.28933846950531006
Batch 39/64 loss: 0.2879297733306885
Batch 40/64 loss: 0.27556800842285156
Batch 41/64 loss: 0.28225040435791016
Batch 42/64 loss: 0.2866291403770447
Batch 43/64 loss: 0.2807108163833618
Batch 44/64 loss: 0.27568626403808594
Batch 45/64 loss: 0.28182023763656616
Batch 46/64 loss: 0.28957873582839966
Batch 47/64 loss: 0.2839111089706421
Batch 48/64 loss: 0.28458213806152344
Batch 49/64 loss: 0.2820243835449219
Batch 50/64 loss: 0.28449684381484985
Batch 51/64 loss: 0.28555142879486084
Batch 52/64 loss: 0.28068768978118896
Batch 53/64 loss: 0.2843003273010254
Batch 54/64 loss: 0.28597235679626465
Batch 55/64 loss: 0.2844594717025757
Batch 56/64 loss: 0.2861708402633667
Batch 57/64 loss: 0.2801353335380554
Batch 58/64 loss: 0.28683650493621826
Batch 59/64 loss: 0.28584617376327515
Batch 60/64 loss: 0.280661940574646
Batch 61/64 loss: 0.28395986557006836
Batch 62/64 loss: 0.28721439838409424
Batch 63/64 loss: 0.28330695629119873
Batch 64/64 loss: 0.2800426483154297
Epoch 268  Train loss: 0.28312273866990034  Val loss: 0.31355954568410654
Epoch 269
-------------------------------
Batch 1/64 loss: 0.27944254875183105
Batch 2/64 loss: 0.2876564860343933
Batch 3/64 loss: 0.290424108505249
Batch 4/64 loss: 0.2821800708770752
Batch 5/64 loss: 0.27712178230285645
Batch 6/64 loss: 0.29422831535339355
Batch 7/64 loss: 0.27857911586761475
Batch 8/64 loss: 0.28243952989578247
Batch 9/64 loss: 0.27617692947387695
Batch 10/64 loss: 0.28474581241607666
Batch 11/64 loss: 0.28378212451934814
Batch 12/64 loss: 0.2779591679573059
Batch 13/64 loss: 0.2830755114555359
Batch 14/64 loss: 0.28077733516693115
Batch 15/64 loss: 0.2775624990463257
Batch 16/64 loss: 0.2776528596878052
Batch 17/64 loss: 0.2786083221435547
Batch 18/64 loss: 0.2817188501358032
Batch 19/64 loss: 0.28435373306274414
Batch 20/64 loss: 0.2785123586654663
Batch 21/64 loss: 0.28031957149505615
Batch 22/64 loss: 0.28300487995147705
Batch 23/64 loss: 0.2829200029373169
Batch 24/64 loss: 0.2800004482269287
Batch 25/64 loss: 0.2761903405189514
Batch 26/64 loss: 0.2901571989059448
Batch 27/64 loss: 0.2806323170661926
Batch 28/64 loss: 0.2797013521194458
Batch 29/64 loss: 0.2874715328216553
Batch 30/64 loss: 0.28692352771759033
Batch 31/64 loss: 0.28936338424682617
Batch 32/64 loss: 0.2893024682998657
Batch 33/64 loss: 0.27879834175109863
Batch 34/64 loss: 0.2788347601890564
Batch 35/64 loss: 0.2780340909957886
Batch 36/64 loss: 0.2854243516921997
Batch 37/64 loss: 0.28864383697509766
Batch 38/64 loss: 0.2944079041481018
Batch 39/64 loss: 0.28504103422164917
Batch 40/64 loss: 0.2736607789993286
Batch 41/64 loss: 0.28869402408599854
Batch 42/64 loss: 0.28010261058807373
Batch 43/64 loss: 0.29148149490356445
Batch 44/64 loss: 0.28010094165802
Batch 45/64 loss: 0.28636491298675537
Batch 46/64 loss: 0.2813127636909485
Batch 47/64 loss: 0.28027814626693726
Batch 48/64 loss: 0.284218966960907
Batch 49/64 loss: 0.28208136558532715
Batch 50/64 loss: 0.2834433317184448
Batch 51/64 loss: 0.2873551845550537
Batch 52/64 loss: 0.28509438037872314
Batch 53/64 loss: 0.28557342290878296
Batch 54/64 loss: 0.2860415577888489
Batch 55/64 loss: 0.28047293424606323
Batch 56/64 loss: 0.28742051124572754
Batch 57/64 loss: 0.2821493148803711
Batch 58/64 loss: 0.2905452251434326
Batch 59/64 loss: 0.2833544611930847
Batch 60/64 loss: 0.2817307710647583
Batch 61/64 loss: 0.28266680240631104
Batch 62/64 loss: 0.2886940836906433
Batch 63/64 loss: 0.2772775888442993
Batch 64/64 loss: 0.2878166437149048
Epoch 269  Train loss: 0.2832650488498164  Val loss: 0.3126613081935345
Epoch 270
-------------------------------
Batch 1/64 loss: 0.2802058458328247
Batch 2/64 loss: 0.28827422857284546
Batch 3/64 loss: 0.2883811593055725
Batch 4/64 loss: 0.2805584669113159
Batch 5/64 loss: 0.2822239398956299
Batch 6/64 loss: 0.2793959975242615
Batch 7/64 loss: 0.2781538963317871
Batch 8/64 loss: 0.2823803424835205
Batch 9/64 loss: 0.27744388580322266
Batch 10/64 loss: 0.28168559074401855
Batch 11/64 loss: 0.28347069025039673
Batch 12/64 loss: 0.2830928564071655
Batch 13/64 loss: 0.27858424186706543
Batch 14/64 loss: 0.27561819553375244
Batch 15/64 loss: 0.27631938457489014
Batch 16/64 loss: 0.28261542320251465
Batch 17/64 loss: 0.2803850769996643
Batch 18/64 loss: 0.2819139361381531
Batch 19/64 loss: 0.2892206907272339
Batch 20/64 loss: 0.2764374613761902
Batch 21/64 loss: 0.28584933280944824
Batch 22/64 loss: 0.28392767906188965
Batch 23/64 loss: 0.28540122509002686
Batch 24/64 loss: 0.28531813621520996
Batch 25/64 loss: 0.2876945734024048
Batch 26/64 loss: 0.2818118929862976
Batch 27/64 loss: 0.2773151397705078
Batch 28/64 loss: 0.29028642177581787
Batch 29/64 loss: 0.2881932854652405
Batch 30/64 loss: 0.2860599756240845
Batch 31/64 loss: 0.28106582164764404
Batch 32/64 loss: 0.2808449864387512
Batch 33/64 loss: 0.28276097774505615
Batch 34/64 loss: 0.28592824935913086
Batch 35/64 loss: 0.28453248739242554
Batch 36/64 loss: 0.2835347652435303
Batch 37/64 loss: 0.2836308479309082
Batch 38/64 loss: 0.2772279977798462
Batch 39/64 loss: 0.27774202823638916
Batch 40/64 loss: 0.28703397512435913
Batch 41/64 loss: 0.2834514379501343
Batch 42/64 loss: 0.2869004011154175
Batch 43/64 loss: 0.2827794551849365
Batch 44/64 loss: 0.2851148843765259
Batch 45/64 loss: 0.2763310670852661
Batch 46/64 loss: 0.2782835364341736
Batch 47/64 loss: 0.2856375575065613
Batch 48/64 loss: 0.2877904176712036
Batch 49/64 loss: 0.28671157360076904
Batch 50/64 loss: 0.2781149744987488
Batch 51/64 loss: 0.277285099029541
Batch 52/64 loss: 0.279085636138916
Batch 53/64 loss: 0.2875920534133911
Batch 54/64 loss: 0.28099745512008667
Batch 55/64 loss: 0.2883697748184204
Batch 56/64 loss: 0.28588902950286865
Batch 57/64 loss: 0.2825789451599121
Batch 58/64 loss: 0.2783558964729309
Batch 59/64 loss: 0.2813316583633423
Batch 60/64 loss: 0.2815777659416199
Batch 61/64 loss: 0.28175508975982666
Batch 62/64 loss: 0.28647923469543457
Batch 63/64 loss: 0.27974629402160645
Batch 64/64 loss: 0.2905430793762207
Epoch 270  Train loss: 0.28270725736431046  Val loss: 0.31313354309481856
Epoch 271
-------------------------------
Batch 1/64 loss: 0.2851501703262329
Batch 2/64 loss: 0.2785499095916748
Batch 3/64 loss: 0.28217071294784546
Batch 4/64 loss: 0.2825307250022888
Batch 5/64 loss: 0.27976810932159424
Batch 6/64 loss: 0.2856696844100952
Batch 7/64 loss: 0.27664077281951904
Batch 8/64 loss: 0.2791590690612793
Batch 9/64 loss: 0.2802738547325134
Batch 10/64 loss: 0.29048097133636475
Batch 11/64 loss: 0.28943341970443726
Batch 12/64 loss: 0.27781355381011963
Batch 13/64 loss: 0.28229081630706787
Batch 14/64 loss: 0.2807043790817261
Batch 15/64 loss: 0.2821683883666992
Batch 16/64 loss: 0.27903807163238525
Batch 17/64 loss: 0.2750509977340698
Batch 18/64 loss: 0.2830086946487427
Batch 19/64 loss: 0.2854384779930115
Batch 20/64 loss: 0.28231334686279297
Batch 21/64 loss: 0.28081244230270386
Batch 22/64 loss: 0.28199732303619385
Batch 23/64 loss: 0.2765503525733948
Batch 24/64 loss: 0.285963237285614
Batch 25/64 loss: 0.28541815280914307
Batch 26/64 loss: 0.28796088695526123
Batch 27/64 loss: 0.28207534551620483
Batch 28/64 loss: 0.2764284014701843
Batch 29/64 loss: 0.2871701717376709
Batch 30/64 loss: 0.2890126705169678
Batch 31/64 loss: 0.28368186950683594
Batch 32/64 loss: 0.2786923050880432
Batch 33/64 loss: 0.28296059370040894
Batch 34/64 loss: 0.2815573811531067
Batch 35/64 loss: 0.27750247716903687
Batch 36/64 loss: 0.27992796897888184
Batch 37/64 loss: 0.2871127724647522
Batch 38/64 loss: 0.28481459617614746
Batch 39/64 loss: 0.28321385383605957
Batch 40/64 loss: 0.2873489260673523
Batch 41/64 loss: 0.2831130027770996
Batch 42/64 loss: 0.28095221519470215
Batch 43/64 loss: 0.2868109941482544
Batch 44/64 loss: 0.27998507022857666
Batch 45/64 loss: 0.2842891812324524
Batch 46/64 loss: 0.2826487421989441
Batch 47/64 loss: 0.2870509624481201
Batch 48/64 loss: 0.27844345569610596
Batch 49/64 loss: 0.2794113755226135
Batch 50/64 loss: 0.2849658131599426
Batch 51/64 loss: 0.2899748682975769
Batch 52/64 loss: 0.28604328632354736
Batch 53/64 loss: 0.28320837020874023
Batch 54/64 loss: 0.2886713147163391
Batch 55/64 loss: 0.2764999270439148
Batch 56/64 loss: 0.280293345451355
Batch 57/64 loss: 0.28889548778533936
Batch 58/64 loss: 0.27727723121643066
Batch 59/64 loss: 0.28729939460754395
Batch 60/64 loss: 0.2764459252357483
Batch 61/64 loss: 0.2757134437561035
Batch 62/64 loss: 0.28442132472991943
Batch 63/64 loss: 0.28367412090301514
Batch 64/64 loss: 0.281427800655365
Epoch 271  Train loss: 0.2825884793318954  Val loss: 0.3137699324650453
Epoch 272
-------------------------------
Batch 1/64 loss: 0.2782618999481201
Batch 2/64 loss: 0.2798767685890198
Batch 3/64 loss: 0.28881168365478516
Batch 4/64 loss: 0.2797946333885193
Batch 5/64 loss: 0.2811611294746399
Batch 6/64 loss: 0.2848549485206604
Batch 7/64 loss: 0.2794329524040222
Batch 8/64 loss: 0.28334975242614746
Batch 9/64 loss: 0.2815958261489868
Batch 10/64 loss: 0.2880302667617798
Batch 11/64 loss: 0.28264838457107544
Batch 12/64 loss: 0.28014642000198364
Batch 13/64 loss: 0.2807133197784424
Batch 14/64 loss: 0.2836799621582031
Batch 15/64 loss: 0.28814220428466797
Batch 16/64 loss: 0.2795026898384094
Batch 17/64 loss: 0.2782970666885376
Batch 18/64 loss: 0.2817564010620117
Batch 19/64 loss: 0.28508615493774414
Batch 20/64 loss: 0.28520339727401733
Batch 21/64 loss: 0.27322328090667725
Batch 22/64 loss: 0.2841833829879761
Batch 23/64 loss: 0.2866203188896179
Batch 24/64 loss: 0.27942955493927
Batch 25/64 loss: 0.2786974310874939
Batch 26/64 loss: 0.2878943681716919
Batch 27/64 loss: 0.2788565158843994
Batch 28/64 loss: 0.2857283353805542
Batch 29/64 loss: 0.281181275844574
Batch 30/64 loss: 0.28176432847976685
Batch 31/64 loss: 0.27933675050735474
Batch 32/64 loss: 0.28412002325057983
Batch 33/64 loss: 0.27488625049591064
Batch 34/64 loss: 0.28006064891815186
Batch 35/64 loss: 0.28456199169158936
Batch 36/64 loss: 0.28140127658843994
Batch 37/64 loss: 0.2800849676132202
Batch 38/64 loss: 0.2802116870880127
Batch 39/64 loss: 0.28310346603393555
Batch 40/64 loss: 0.2787362337112427
Batch 41/64 loss: 0.2805473804473877
Batch 42/64 loss: 0.27593815326690674
Batch 43/64 loss: 0.283657968044281
Batch 44/64 loss: 0.28194499015808105
Batch 45/64 loss: 0.2828238606452942
Batch 46/64 loss: 0.281033456325531
Batch 47/64 loss: 0.2753099203109741
Batch 48/64 loss: 0.2799144387245178
Batch 49/64 loss: 0.27563905715942383
Batch 50/64 loss: 0.2894866466522217
Batch 51/64 loss: 0.28114187717437744
Batch 52/64 loss: 0.28149592876434326
Batch 53/64 loss: 0.2840162515640259
Batch 54/64 loss: 0.2763955593109131
Batch 55/64 loss: 0.28602802753448486
Batch 56/64 loss: 0.2805292010307312
Batch 57/64 loss: 0.29158544540405273
Batch 58/64 loss: 0.28390491008758545
Batch 59/64 loss: 0.27666187286376953
Batch 60/64 loss: 0.27680373191833496
Batch 61/64 loss: 0.27827316522598267
Batch 62/64 loss: 0.2796778082847595
Batch 63/64 loss: 0.29644376039505005
Batch 64/64 loss: 0.29389339685440063
Epoch 272  Train loss: 0.2819466887735853  Val loss: 0.31320825126982227
Epoch 273
-------------------------------
Batch 1/64 loss: 0.2782813310623169
Batch 2/64 loss: 0.27721863985061646
Batch 3/64 loss: 0.275892436504364
Batch 4/64 loss: 0.2786257266998291
Batch 5/64 loss: 0.27839529514312744
Batch 6/64 loss: 0.27807867527008057
Batch 7/64 loss: 0.2920494079589844
Batch 8/64 loss: 0.2744632959365845
Batch 9/64 loss: 0.2827261686325073
Batch 10/64 loss: 0.27838635444641113
Batch 11/64 loss: 0.27929478883743286
Batch 12/64 loss: 0.28411877155303955
Batch 13/64 loss: 0.28095126152038574
Batch 14/64 loss: 0.2755613923072815
Batch 15/64 loss: 0.27064287662506104
Batch 16/64 loss: 0.28458237648010254
Batch 17/64 loss: 0.2835535407066345
Batch 18/64 loss: 0.27787238359451294
Batch 19/64 loss: 0.28213000297546387
Batch 20/64 loss: 0.281981885433197
Batch 21/64 loss: 0.2748410701751709
Batch 22/64 loss: 0.28249359130859375
Batch 23/64 loss: 0.28180575370788574
Batch 24/64 loss: 0.28376150131225586
Batch 25/64 loss: 0.2892169952392578
Batch 26/64 loss: 0.27557122707366943
Batch 27/64 loss: 0.2871999740600586
Batch 28/64 loss: 0.27562010288238525
Batch 29/64 loss: 0.2803763747215271
Batch 30/64 loss: 0.2858416438102722
Batch 31/64 loss: 0.283172607421875
Batch 32/64 loss: 0.2849726676940918
Batch 33/64 loss: 0.27833986282348633
Batch 34/64 loss: 0.2851170301437378
Batch 35/64 loss: 0.27660298347473145
Batch 36/64 loss: 0.27742719650268555
Batch 37/64 loss: 0.2787386178970337
Batch 38/64 loss: 0.2885291576385498
Batch 39/64 loss: 0.2810232639312744
Batch 40/64 loss: 0.2798994779586792
Batch 41/64 loss: 0.28386974334716797
Batch 42/64 loss: 0.2780684232711792
Batch 43/64 loss: 0.28273165225982666
Batch 44/64 loss: 0.2829461097717285
Batch 45/64 loss: 0.29684895277023315
Batch 46/64 loss: 0.28425168991088867
Batch 47/64 loss: 0.2815501093864441
Batch 48/64 loss: 0.28289520740509033
Batch 49/64 loss: 0.2867780923843384
Batch 50/64 loss: 0.28374171257019043
Batch 51/64 loss: 0.28980040550231934
Batch 52/64 loss: 0.28546518087387085
Batch 53/64 loss: 0.2848779559135437
Batch 54/64 loss: 0.2875661849975586
Batch 55/64 loss: 0.28604137897491455
Batch 56/64 loss: 0.28538745641708374
Batch 57/64 loss: 0.2840996980667114
Batch 58/64 loss: 0.27516984939575195
Batch 59/64 loss: 0.28167450428009033
Batch 60/64 loss: 0.2857065200805664
Batch 61/64 loss: 0.28015315532684326
Batch 62/64 loss: 0.2808876633644104
Batch 63/64 loss: 0.28175902366638184
Batch 64/64 loss: 0.289711058139801
Epoch 273  Train loss: 0.28195939882128845  Val loss: 0.3130457866232829
Epoch 274
-------------------------------
Batch 1/64 loss: 0.2823218107223511
Batch 2/64 loss: 0.27491194009780884
Batch 3/64 loss: 0.2845957279205322
Batch 4/64 loss: 0.28256750106811523
Batch 5/64 loss: 0.2804679870605469
Batch 6/64 loss: 0.2840689420700073
Batch 7/64 loss: 0.2812437415122986
Batch 8/64 loss: 0.28342771530151367
Batch 9/64 loss: 0.2858196496963501
Batch 10/64 loss: 0.289855420589447
Batch 11/64 loss: 0.2793560028076172
Batch 12/64 loss: 0.2732338309288025
Batch 13/64 loss: 0.2739464044570923
Batch 14/64 loss: 0.2837908864021301
Batch 15/64 loss: 0.28002119064331055
Batch 16/64 loss: 0.28344404697418213
Batch 17/64 loss: 0.27885109186172485
Batch 18/64 loss: 0.2821621894836426
Batch 19/64 loss: 0.28181028366088867
Batch 20/64 loss: 0.2790732979774475
Batch 21/64 loss: 0.2900087237358093
Batch 22/64 loss: 0.27952897548675537
Batch 23/64 loss: 0.2800835371017456
Batch 24/64 loss: 0.27468764781951904
Batch 25/64 loss: 0.2833622097969055
Batch 26/64 loss: 0.28256112337112427
Batch 27/64 loss: 0.28052568435668945
Batch 28/64 loss: 0.27857667207717896
Batch 29/64 loss: 0.28028225898742676
Batch 30/64 loss: 0.28854799270629883
Batch 31/64 loss: 0.28065890073776245
Batch 32/64 loss: 0.28392845392227173
Batch 33/64 loss: 0.2809908986091614
Batch 34/64 loss: 0.27911102771759033
Batch 35/64 loss: 0.2776344418525696
Batch 36/64 loss: 0.27594614028930664
Batch 37/64 loss: 0.2789720892906189
Batch 38/64 loss: 0.28311485052108765
Batch 39/64 loss: 0.29423224925994873
Batch 40/64 loss: 0.28514111042022705
Batch 41/64 loss: 0.28249168395996094
Batch 42/64 loss: 0.27713364362716675
Batch 43/64 loss: 0.2839648127555847
Batch 44/64 loss: 0.28952479362487793
Batch 45/64 loss: 0.2788141965866089
Batch 46/64 loss: 0.28076881170272827
Batch 47/64 loss: 0.284604549407959
Batch 48/64 loss: 0.27579957246780396
Batch 49/64 loss: 0.27902549505233765
Batch 50/64 loss: 0.28814828395843506
Batch 51/64 loss: 0.28442227840423584
Batch 52/64 loss: 0.2752689719200134
Batch 53/64 loss: 0.27473515272140503
Batch 54/64 loss: 0.28430604934692383
Batch 55/64 loss: 0.2865784168243408
Batch 56/64 loss: 0.2929058074951172
Batch 57/64 loss: 0.28183603286743164
Batch 58/64 loss: 0.2847369909286499
Batch 59/64 loss: 0.2850062847137451
Batch 60/64 loss: 0.28476762771606445
Batch 61/64 loss: 0.28176987171173096
Batch 62/64 loss: 0.28560489416122437
Batch 63/64 loss: 0.2782266139984131
Batch 64/64 loss: 0.2784111499786377
Epoch 274  Train loss: 0.28191551133698106  Val loss: 0.3135972207354516
Epoch 275
-------------------------------
Batch 1/64 loss: 0.28127431869506836
Batch 2/64 loss: 0.2905360460281372
Batch 3/64 loss: 0.27947330474853516
Batch 4/64 loss: 0.28076744079589844
Batch 5/64 loss: 0.2824976444244385
Batch 6/64 loss: 0.27997785806655884
Batch 7/64 loss: 0.28682661056518555
Batch 8/64 loss: 0.28093189001083374
Batch 9/64 loss: 0.2771660089492798
Batch 10/64 loss: 0.2803187966346741
Batch 11/64 loss: 0.27540212869644165
Batch 12/64 loss: 0.2767012119293213
Batch 13/64 loss: 0.2855379581451416
Batch 14/64 loss: 0.28211283683776855
Batch 15/64 loss: 0.28502845764160156
Batch 16/64 loss: 0.27456021308898926
Batch 17/64 loss: 0.27876585721969604
Batch 18/64 loss: 0.284801185131073
Batch 19/64 loss: 0.2835564613342285
Batch 20/64 loss: 0.28833508491516113
Batch 21/64 loss: 0.28484344482421875
Batch 22/64 loss: 0.28137803077697754
Batch 23/64 loss: 0.2826399803161621
Batch 24/64 loss: 0.28346002101898193
Batch 25/64 loss: 0.2795969843864441
Batch 26/64 loss: 0.2835383415222168
Batch 27/64 loss: 0.28076326847076416
Batch 28/64 loss: 0.2849006652832031
Batch 29/64 loss: 0.2776262164115906
Batch 30/64 loss: 0.2807965874671936
Batch 31/64 loss: 0.2868063449859619
Batch 32/64 loss: 0.2827513813972473
Batch 33/64 loss: 0.28124821186065674
Batch 34/64 loss: 0.2876046895980835
Batch 35/64 loss: 0.28671133518218994
Batch 36/64 loss: 0.29102468490600586
Batch 37/64 loss: 0.287103533744812
Batch 38/64 loss: 0.2800319790840149
Batch 39/64 loss: 0.28082001209259033
Batch 40/64 loss: 0.2797093391418457
Batch 41/64 loss: 0.278190553188324
Batch 42/64 loss: 0.28876954317092896
Batch 43/64 loss: 0.2827882170677185
Batch 44/64 loss: 0.2808467745780945
Batch 45/64 loss: 0.28660649061203003
Batch 46/64 loss: 0.2846672534942627
Batch 47/64 loss: 0.28371793031692505
Batch 48/64 loss: 0.2806689739227295
Batch 49/64 loss: 0.28204917907714844
Batch 50/64 loss: 0.2828718423843384
Batch 51/64 loss: 0.2844531536102295
Batch 52/64 loss: 0.27368617057800293
Batch 53/64 loss: 0.29023468494415283
Batch 54/64 loss: 0.2822355031967163
Batch 55/64 loss: 0.2755235433578491
Batch 56/64 loss: 0.281133234500885
Batch 57/64 loss: 0.2825496792793274
Batch 58/64 loss: 0.28122031688690186
Batch 59/64 loss: 0.2798205614089966
Batch 60/64 loss: 0.28638118505477905
Batch 61/64 loss: 0.2814065217971802
Batch 62/64 loss: 0.2862131595611572
Batch 63/64 loss: 0.2798197269439697
Batch 64/64 loss: 0.28348642587661743
Epoch 275  Train loss: 0.2824532609359891  Val loss: 0.31274379385296014
Epoch 276
-------------------------------
Batch 1/64 loss: 0.27934521436691284
Batch 2/64 loss: 0.28463220596313477
Batch 3/64 loss: 0.28272300958633423
Batch 4/64 loss: 0.2882087230682373
Batch 5/64 loss: 0.27886152267456055
Batch 6/64 loss: 0.2763825058937073
Batch 7/64 loss: 0.2858220338821411
Batch 8/64 loss: 0.2804431915283203
Batch 9/64 loss: 0.2771897315979004
Batch 10/64 loss: 0.2864150404930115
Batch 11/64 loss: 0.27456796169281006
Batch 12/64 loss: 0.27818530797958374
Batch 13/64 loss: 0.2818782329559326
Batch 14/64 loss: 0.27208083868026733
Batch 15/64 loss: 0.27817821502685547
Batch 16/64 loss: 0.28970569372177124
Batch 17/64 loss: 0.28247779607772827
Batch 18/64 loss: 0.2762913703918457
Batch 19/64 loss: 0.2743901014328003
Batch 20/64 loss: 0.2917276620864868
Batch 21/64 loss: 0.28678834438323975
Batch 22/64 loss: 0.2824416160583496
Batch 23/64 loss: 0.28491872549057007
Batch 24/64 loss: 0.27973443269729614
Batch 25/64 loss: 0.2829173803329468
Batch 26/64 loss: 0.28681546449661255
Batch 27/64 loss: 0.28299105167388916
Batch 28/64 loss: 0.2780534029006958
Batch 29/64 loss: 0.2787553071975708
Batch 30/64 loss: 0.2817380428314209
Batch 31/64 loss: 0.28815770149230957
Batch 32/64 loss: 0.2775421738624573
Batch 33/64 loss: 0.2832808494567871
Batch 34/64 loss: 0.2882521152496338
Batch 35/64 loss: 0.27908939123153687
Batch 36/64 loss: 0.27821916341781616
Batch 37/64 loss: 0.2842599153518677
Batch 38/64 loss: 0.27876436710357666
Batch 39/64 loss: 0.2802731394767761
Batch 40/64 loss: 0.2794182300567627
Batch 41/64 loss: 0.2798561453819275
Batch 42/64 loss: 0.2837800979614258
Batch 43/64 loss: 0.2800048589706421
Batch 44/64 loss: 0.277929425239563
Batch 45/64 loss: 0.28232645988464355
Batch 46/64 loss: 0.2900248169898987
Batch 47/64 loss: 0.28627967834472656
Batch 48/64 loss: 0.2890493869781494
Batch 49/64 loss: 0.28181707859039307
Batch 50/64 loss: 0.2907217741012573
Batch 51/64 loss: 0.2807515859603882
Batch 52/64 loss: 0.28648650646209717
Batch 53/64 loss: 0.2791534662246704
Batch 54/64 loss: 0.2784057855606079
Batch 55/64 loss: 0.2803921699523926
Batch 56/64 loss: 0.28198540210723877
Batch 57/64 loss: 0.27883434295654297
Batch 58/64 loss: 0.2898429036140442
Batch 59/64 loss: 0.28278422355651855
Batch 60/64 loss: 0.28255772590637207
Batch 61/64 loss: 0.2831863760948181
Batch 62/64 loss: 0.28695887327194214
Batch 63/64 loss: 0.2808265686035156
Batch 64/64 loss: 0.28463733196258545
Epoch 276  Train loss: 0.2821858953027164  Val loss: 0.3137442590444768
Epoch 277
-------------------------------
Batch 1/64 loss: 0.2831515073776245
Batch 2/64 loss: 0.2767428159713745
Batch 3/64 loss: 0.2887042760848999
Batch 4/64 loss: 0.27471238374710083
Batch 5/64 loss: 0.27981501817703247
Batch 6/64 loss: 0.2787817716598511
Batch 7/64 loss: 0.2814626693725586
Batch 8/64 loss: 0.28118884563446045
Batch 9/64 loss: 0.2801398038864136
Batch 10/64 loss: 0.27599596977233887
Batch 11/64 loss: 0.28528010845184326
Batch 12/64 loss: 0.2831188440322876
Batch 13/64 loss: 0.2831305265426636
Batch 14/64 loss: 0.2817491292953491
Batch 15/64 loss: 0.27378422021865845
Batch 16/64 loss: 0.2770969867706299
Batch 17/64 loss: 0.28242170810699463
Batch 18/64 loss: 0.2776818871498108
Batch 19/64 loss: 0.2823389768600464
Batch 20/64 loss: 0.27879858016967773
Batch 21/64 loss: 0.27385789155960083
Batch 22/64 loss: 0.2850085496902466
Batch 23/64 loss: 0.2778940200805664
Batch 24/64 loss: 0.285503625869751
Batch 25/64 loss: 0.274194598197937
Batch 26/64 loss: 0.2845221161842346
Batch 27/64 loss: 0.2754102945327759
Batch 28/64 loss: 0.27478736639022827
Batch 29/64 loss: 0.28163886070251465
Batch 30/64 loss: 0.28707408905029297
Batch 31/64 loss: 0.28219693899154663
Batch 32/64 loss: 0.2816329598426819
Batch 33/64 loss: 0.2833794355392456
Batch 34/64 loss: 0.2776428461074829
Batch 35/64 loss: 0.2805134057998657
Batch 36/64 loss: 0.2881585359573364
Batch 37/64 loss: 0.27698230743408203
Batch 38/64 loss: 0.27984070777893066
Batch 39/64 loss: 0.27962827682495117
Batch 40/64 loss: 0.27841877937316895
Batch 41/64 loss: 0.27746450901031494
Batch 42/64 loss: 0.28597450256347656
Batch 43/64 loss: 0.27876853942871094
Batch 44/64 loss: 0.2888975739479065
Batch 45/64 loss: 0.2815832495689392
Batch 46/64 loss: 0.2826197147369385
Batch 47/64 loss: 0.2930997610092163
Batch 48/64 loss: 0.28217363357543945
Batch 49/64 loss: 0.2835937738418579
Batch 50/64 loss: 0.2827572226524353
Batch 51/64 loss: 0.2827467918395996
Batch 52/64 loss: 0.2801053524017334
Batch 53/64 loss: 0.28060030937194824
Batch 54/64 loss: 0.279338002204895
Batch 55/64 loss: 0.28730273246765137
Batch 56/64 loss: 0.28722167015075684
Batch 57/64 loss: 0.285028874874115
Batch 58/64 loss: 0.27613914012908936
Batch 59/64 loss: 0.28278839588165283
Batch 60/64 loss: 0.2831476330757141
Batch 61/64 loss: 0.2809354066848755
Batch 62/64 loss: 0.285722017288208
Batch 63/64 loss: 0.2826470732688904
Batch 64/64 loss: 0.29102468490600586
Epoch 277  Train loss: 0.2814636239818498  Val loss: 0.3137403706095063
Epoch 278
-------------------------------
Batch 1/64 loss: 0.28459054231643677
Batch 2/64 loss: 0.27623558044433594
Batch 3/64 loss: 0.2770932912826538
Batch 4/64 loss: 0.2785347104072571
Batch 5/64 loss: 0.28388512134552
Batch 6/64 loss: 0.2795974016189575
Batch 7/64 loss: 0.2815931439399719
Batch 8/64 loss: 0.2795953154563904
Batch 9/64 loss: 0.27805089950561523
Batch 10/64 loss: 0.27680957317352295
Batch 11/64 loss: 0.2842189073562622
Batch 12/64 loss: 0.2786105275154114
Batch 13/64 loss: 0.2782238721847534
Batch 14/64 loss: 0.28057509660720825
Batch 15/64 loss: 0.2856752872467041
Batch 16/64 loss: 0.2818257212638855
Batch 17/64 loss: 0.2853565812110901
Batch 18/64 loss: 0.2870742678642273
Batch 19/64 loss: 0.2810016870498657
Batch 20/64 loss: 0.28369730710983276
Batch 21/64 loss: 0.28417283296585083
Batch 22/64 loss: 0.2805755138397217
Batch 23/64 loss: 0.2825472354888916
Batch 24/64 loss: 0.2815377712249756
Batch 25/64 loss: 0.28101450204849243
Batch 26/64 loss: 0.285631000995636
Batch 27/64 loss: 0.2753474712371826
Batch 28/64 loss: 0.2891809940338135
Batch 29/64 loss: 0.2797926068305969
Batch 30/64 loss: 0.28368330001831055
Batch 31/64 loss: 0.2754470109939575
Batch 32/64 loss: 0.2808271646499634
Batch 33/64 loss: 0.2774052023887634
Batch 34/64 loss: 0.274661660194397
Batch 35/64 loss: 0.2847015857696533
Batch 36/64 loss: 0.2836918830871582
Batch 37/64 loss: 0.2765651345252991
Batch 38/64 loss: 0.2771977186203003
Batch 39/64 loss: 0.2762998342514038
Batch 40/64 loss: 0.2730780839920044
Batch 41/64 loss: 0.2836255431175232
Batch 42/64 loss: 0.2781640291213989
Batch 43/64 loss: 0.28760242462158203
Batch 44/64 loss: 0.2848186492919922
Batch 45/64 loss: 0.2838236093521118
Batch 46/64 loss: 0.2805657386779785
Batch 47/64 loss: 0.28803694248199463
Batch 48/64 loss: 0.2858731150627136
Batch 49/64 loss: 0.2796471118927002
Batch 50/64 loss: 0.2774183750152588
Batch 51/64 loss: 0.2817680835723877
Batch 52/64 loss: 0.2799299955368042
Batch 53/64 loss: 0.2795894145965576
Batch 54/64 loss: 0.28325092792510986
Batch 55/64 loss: 0.2782772183418274
Batch 56/64 loss: 0.29039984941482544
Batch 57/64 loss: 0.2820405960083008
Batch 58/64 loss: 0.29578936100006104
Batch 59/64 loss: 0.2819065451622009
Batch 60/64 loss: 0.2788273096084595
Batch 61/64 loss: 0.28938794136047363
Batch 62/64 loss: 0.28293073177337646
Batch 63/64 loss: 0.2854544520378113
Batch 64/64 loss: 0.2802894711494446
Epoch 278  Train loss: 0.28164624957477347  Val loss: 0.3132929771216874
Epoch 279
-------------------------------
Batch 1/64 loss: 0.2768576145172119
Batch 2/64 loss: 0.2752702236175537
Batch 3/64 loss: 0.2789442539215088
Batch 4/64 loss: 0.2736903429031372
Batch 5/64 loss: 0.28083717823028564
Batch 6/64 loss: 0.27816057205200195
Batch 7/64 loss: 0.2769410014152527
Batch 8/64 loss: 0.27541208267211914
Batch 9/64 loss: 0.27933400869369507
Batch 10/64 loss: 0.2799556255340576
Batch 11/64 loss: 0.27628999948501587
Batch 12/64 loss: 0.2847168445587158
Batch 13/64 loss: 0.29151320457458496
Batch 14/64 loss: 0.284887433052063
Batch 15/64 loss: 0.282290518283844
Batch 16/64 loss: 0.2815214991569519
Batch 17/64 loss: 0.2809326648712158
Batch 18/64 loss: 0.275448739528656
Batch 19/64 loss: 0.2812688946723938
Batch 20/64 loss: 0.2784227132797241
Batch 21/64 loss: 0.28431618213653564
Batch 22/64 loss: 0.276619553565979
Batch 23/64 loss: 0.28211796283721924
Batch 24/64 loss: 0.28314411640167236
Batch 25/64 loss: 0.2812643051147461
Batch 26/64 loss: 0.2772502899169922
Batch 27/64 loss: 0.2888338565826416
Batch 28/64 loss: 0.2801421880722046
Batch 29/64 loss: 0.2755223512649536
Batch 30/64 loss: 0.28250229358673096
Batch 31/64 loss: 0.2721773386001587
Batch 32/64 loss: 0.2743052840232849
Batch 33/64 loss: 0.2785758376121521
Batch 34/64 loss: 0.2804175615310669
Batch 35/64 loss: 0.28199565410614014
Batch 36/64 loss: 0.28395241498947144
Batch 37/64 loss: 0.2842824459075928
Batch 38/64 loss: 0.2816566228866577
Batch 39/64 loss: 0.27732038497924805
Batch 40/64 loss: 0.27850639820098877
Batch 41/64 loss: 0.2865176796913147
Batch 42/64 loss: 0.2842380404472351
Batch 43/64 loss: 0.28490012884140015
Batch 44/64 loss: 0.28634291887283325
Batch 45/64 loss: 0.2818518877029419
Batch 46/64 loss: 0.28318119049072266
Batch 47/64 loss: 0.2882431745529175
Batch 48/64 loss: 0.2857624888420105
Batch 49/64 loss: 0.2754882574081421
Batch 50/64 loss: 0.2876279950141907
Batch 51/64 loss: 0.2842257022857666
Batch 52/64 loss: 0.2790113687515259
Batch 53/64 loss: 0.27888745069503784
Batch 54/64 loss: 0.2790951728820801
Batch 55/64 loss: 0.28367817401885986
Batch 56/64 loss: 0.28403568267822266
Batch 57/64 loss: 0.27982020378112793
Batch 58/64 loss: 0.2759166955947876
Batch 59/64 loss: 0.27762889862060547
Batch 60/64 loss: 0.2904071807861328
Batch 61/64 loss: 0.27744972705841064
Batch 62/64 loss: 0.28537464141845703
Batch 63/64 loss: 0.2860252857208252
Batch 64/64 loss: 0.2906259298324585
Epoch 279  Train loss: 0.2811180839351579  Val loss: 0.3137685773298912
Epoch 280
-------------------------------
Batch 1/64 loss: 0.27393823862075806
Batch 2/64 loss: 0.2892114520072937
Batch 3/64 loss: 0.2820718288421631
Batch 4/64 loss: 0.28585314750671387
Batch 5/64 loss: 0.28260141611099243
Batch 6/64 loss: 0.2824060320854187
Batch 7/64 loss: 0.2856147289276123
Batch 8/64 loss: 0.2783734202384949
Batch 9/64 loss: 0.289315402507782
Batch 10/64 loss: 0.28559815883636475
Batch 11/64 loss: 0.27677828073501587
Batch 12/64 loss: 0.28264176845550537
Batch 13/64 loss: 0.27890026569366455
Batch 14/64 loss: 0.28471410274505615
Batch 15/64 loss: 0.28173887729644775
Batch 16/64 loss: 0.28320807218551636
Batch 17/64 loss: 0.2930455207824707
Batch 18/64 loss: 0.2814640998840332
Batch 19/64 loss: 0.27699702978134155
Batch 20/64 loss: 0.28342151641845703
Batch 21/64 loss: 0.2779231667518616
Batch 22/64 loss: 0.28684496879577637
Batch 23/64 loss: 0.27974969148635864
Batch 24/64 loss: 0.28070783615112305
Batch 25/64 loss: 0.2769516706466675
Batch 26/64 loss: 0.28526628017425537
Batch 27/64 loss: 0.2779502272605896
Batch 28/64 loss: 0.2851588726043701
Batch 29/64 loss: 0.28231191635131836
Batch 30/64 loss: 0.28443682193756104
Batch 31/64 loss: 0.2751748561859131
Batch 32/64 loss: 0.2917789816856384
Batch 33/64 loss: 0.2778739333152771
Batch 34/64 loss: 0.2746983766555786
Batch 35/64 loss: 0.2798081636428833
Batch 36/64 loss: 0.28275132179260254
Batch 37/64 loss: 0.28058212995529175
Batch 38/64 loss: 0.2845747470855713
Batch 39/64 loss: 0.281485378742218
Batch 40/64 loss: 0.2931642532348633
Batch 41/64 loss: 0.2775811553001404
Batch 42/64 loss: 0.2808343172073364
Batch 43/64 loss: 0.2813255786895752
Batch 44/64 loss: 0.283069908618927
Batch 45/64 loss: 0.2861102819442749
Batch 46/64 loss: 0.2833406329154968
Batch 47/64 loss: 0.2814466953277588
Batch 48/64 loss: 0.2732727527618408
Batch 49/64 loss: 0.2745778560638428
Batch 50/64 loss: 0.2794010639190674
Batch 51/64 loss: 0.2840486764907837
Batch 52/64 loss: 0.27702558040618896
Batch 53/64 loss: 0.27486205101013184
Batch 54/64 loss: 0.28162622451782227
Batch 55/64 loss: 0.28406667709350586
Batch 56/64 loss: 0.28532564640045166
Batch 57/64 loss: 0.2781810164451599
Batch 58/64 loss: 0.281453013420105
Batch 59/64 loss: 0.28292226791381836
Batch 60/64 loss: 0.28335654735565186
Batch 61/64 loss: 0.28571832180023193
Batch 62/64 loss: 0.28287285566329956
Batch 63/64 loss: 0.29065489768981934
Batch 64/64 loss: 0.27497947216033936
Epoch 280  Train loss: 0.28198267572066366  Val loss: 0.31242266287099046
Epoch 281
-------------------------------
Batch 1/64 loss: 0.2799599766731262
Batch 2/64 loss: 0.2860872745513916
Batch 3/64 loss: 0.28089451789855957
Batch 4/64 loss: 0.28433477878570557
Batch 5/64 loss: 0.2768651843070984
Batch 6/64 loss: 0.28428584337234497
Batch 7/64 loss: 0.2852743864059448
Batch 8/64 loss: 0.27963078022003174
Batch 9/64 loss: 0.28246504068374634
Batch 10/64 loss: 0.27958595752716064
Batch 11/64 loss: 0.2821195721626282
Batch 12/64 loss: 0.28423869609832764
Batch 13/64 loss: 0.2851884365081787
Batch 14/64 loss: 0.28243207931518555
Batch 15/64 loss: 0.2859994173049927
Batch 16/64 loss: 0.27496540546417236
Batch 17/64 loss: 0.2811603546142578
Batch 18/64 loss: 0.28089678287506104
Batch 19/64 loss: 0.28769242763519287
Batch 20/64 loss: 0.277340292930603
Batch 21/64 loss: 0.273776113986969
Batch 22/64 loss: 0.2763754725456238
Batch 23/64 loss: 0.286967396736145
Batch 24/64 loss: 0.28069043159484863
Batch 25/64 loss: 0.2812485694885254
Batch 26/64 loss: 0.28530198335647583
Batch 27/64 loss: 0.2736227512359619
Batch 28/64 loss: 0.2802821397781372
Batch 29/64 loss: 0.28835296630859375
Batch 30/64 loss: 0.2780419588088989
Batch 31/64 loss: 0.27857381105422974
Batch 32/64 loss: 0.27741336822509766
Batch 33/64 loss: 0.28186100721359253
Batch 34/64 loss: 0.2865145802497864
Batch 35/64 loss: 0.2770545482635498
Batch 36/64 loss: 0.2766578197479248
Batch 37/64 loss: 0.28218376636505127
Batch 38/64 loss: 0.2816239595413208
Batch 39/64 loss: 0.27454620599746704
Batch 40/64 loss: 0.2812984585762024
Batch 41/64 loss: 0.2792278528213501
Batch 42/64 loss: 0.27387237548828125
Batch 43/64 loss: 0.28997087478637695
Batch 44/64 loss: 0.2739243507385254
Batch 45/64 loss: 0.2761285901069641
Batch 46/64 loss: 0.2760698199272156
Batch 47/64 loss: 0.2811155915260315
Batch 48/64 loss: 0.28265219926834106
Batch 49/64 loss: 0.28804123401641846
Batch 50/64 loss: 0.27781420946121216
Batch 51/64 loss: 0.2810053825378418
Batch 52/64 loss: 0.28230607509613037
Batch 53/64 loss: 0.2786388397216797
Batch 54/64 loss: 0.2862517237663269
Batch 55/64 loss: 0.2872350811958313
Batch 56/64 loss: 0.291256308555603
Batch 57/64 loss: 0.28546619415283203
Batch 58/64 loss: 0.28251439332962036
Batch 59/64 loss: 0.2779122591018677
Batch 60/64 loss: 0.2867361903190613
Batch 61/64 loss: 0.2776832580566406
Batch 62/64 loss: 0.2788369655609131
Batch 63/64 loss: 0.2811371088027954
Batch 64/64 loss: 0.28569161891937256
Epoch 281  Train loss: 0.2813156095205569  Val loss: 0.31306629082591264
Epoch 282
-------------------------------
Batch 1/64 loss: 0.28594696521759033
Batch 2/64 loss: 0.28388524055480957
Batch 3/64 loss: 0.27901750802993774
Batch 4/64 loss: 0.2901933193206787
Batch 5/64 loss: 0.2746623754501343
Batch 6/64 loss: 0.2815493941307068
Batch 7/64 loss: 0.2737281322479248
Batch 8/64 loss: 0.28127753734588623
Batch 9/64 loss: 0.2772061228752136
Batch 10/64 loss: 0.27187007665634155
Batch 11/64 loss: 0.2767770290374756
Batch 12/64 loss: 0.2804027199745178
Batch 13/64 loss: 0.2825220823287964
Batch 14/64 loss: 0.27582889795303345
Batch 15/64 loss: 0.28326475620269775
Batch 16/64 loss: 0.2871352434158325
Batch 17/64 loss: 0.27628421783447266
Batch 18/64 loss: 0.27955061197280884
Batch 19/64 loss: 0.2785411477088928
Batch 20/64 loss: 0.27505409717559814
Batch 21/64 loss: 0.2807161808013916
Batch 22/64 loss: 0.27982115745544434
Batch 23/64 loss: 0.28101277351379395
Batch 24/64 loss: 0.28521960973739624
Batch 25/64 loss: 0.28095149993896484
Batch 26/64 loss: 0.28238052129745483
Batch 27/64 loss: 0.28109633922576904
Batch 28/64 loss: 0.2807142734527588
Batch 29/64 loss: 0.2875463366508484
Batch 30/64 loss: 0.28487515449523926
Batch 31/64 loss: 0.2731451392173767
Batch 32/64 loss: 0.2843920588493347
Batch 33/64 loss: 0.2776273488998413
Batch 34/64 loss: 0.28058063983917236
Batch 35/64 loss: 0.2875291109085083
Batch 36/64 loss: 0.2801525592803955
Batch 37/64 loss: 0.2844022512435913
Batch 38/64 loss: 0.2745882272720337
Batch 39/64 loss: 0.2788415551185608
Batch 40/64 loss: 0.2785269021987915
Batch 41/64 loss: 0.28056854009628296
Batch 42/64 loss: 0.2772807478904724
Batch 43/64 loss: 0.2771710753440857
Batch 44/64 loss: 0.2891029119491577
Batch 45/64 loss: 0.2761859893798828
Batch 46/64 loss: 0.2828962206840515
Batch 47/64 loss: 0.2877047061920166
Batch 48/64 loss: 0.2791334390640259
Batch 49/64 loss: 0.27276062965393066
Batch 50/64 loss: 0.2830495238304138
Batch 51/64 loss: 0.27855920791625977
Batch 52/64 loss: 0.28451448678970337
Batch 53/64 loss: 0.27674198150634766
Batch 54/64 loss: 0.28018468618392944
Batch 55/64 loss: 0.283184289932251
Batch 56/64 loss: 0.2839089632034302
Batch 57/64 loss: 0.28355610370635986
Batch 58/64 loss: 0.2840121388435364
Batch 59/64 loss: 0.2808295488357544
Batch 60/64 loss: 0.2868412733078003
Batch 61/64 loss: 0.2823070287704468
Batch 62/64 loss: 0.28582763671875
Batch 63/64 loss: 0.28259527683258057
Batch 64/64 loss: 0.2775470018386841
Epoch 282  Train loss: 0.2808767650641647  Val loss: 0.3138851367730865
Epoch 283
-------------------------------
Batch 1/64 loss: 0.2848365306854248
Batch 2/64 loss: 0.2805102467536926
Batch 3/64 loss: 0.27953243255615234
Batch 4/64 loss: 0.2900269031524658
Batch 5/64 loss: 0.2779303789138794
Batch 6/64 loss: 0.2797509431838989
Batch 7/64 loss: 0.2796679735183716
Batch 8/64 loss: 0.282992959022522
Batch 9/64 loss: 0.2836226224899292
Batch 10/64 loss: 0.2730557918548584
Batch 11/64 loss: 0.2814981937408447
Batch 12/64 loss: 0.28498542308807373
Batch 13/64 loss: 0.27710747718811035
Batch 14/64 loss: 0.27764034271240234
Batch 15/64 loss: 0.2747281789779663
Batch 16/64 loss: 0.2760428786277771
Batch 17/64 loss: 0.2812279462814331
Batch 18/64 loss: 0.27863848209381104
Batch 19/64 loss: 0.2834377884864807
Batch 20/64 loss: 0.27778398990631104
Batch 21/64 loss: 0.28647005558013916
Batch 22/64 loss: 0.27692246437072754
Batch 23/64 loss: 0.2784472703933716
Batch 24/64 loss: 0.28617167472839355
Batch 25/64 loss: 0.2760632634162903
Batch 26/64 loss: 0.2861459255218506
Batch 27/64 loss: 0.2758256196975708
Batch 28/64 loss: 0.27861517667770386
Batch 29/64 loss: 0.2899895906448364
Batch 30/64 loss: 0.27939581871032715
Batch 31/64 loss: 0.2743719816207886
Batch 32/64 loss: 0.2758074998855591
Batch 33/64 loss: 0.2832646369934082
Batch 34/64 loss: 0.28557658195495605
Batch 35/64 loss: 0.2808910608291626
Batch 36/64 loss: 0.2824054956436157
Batch 37/64 loss: 0.281802237033844
Batch 38/64 loss: 0.2802882790565491
Batch 39/64 loss: 0.2758837938308716
Batch 40/64 loss: 0.27748072147369385
Batch 41/64 loss: 0.2786465883255005
Batch 42/64 loss: 0.2777642607688904
Batch 43/64 loss: 0.2821120619773865
Batch 44/64 loss: 0.28164029121398926
Batch 45/64 loss: 0.2842390537261963
Batch 46/64 loss: 0.2805291414260864
Batch 47/64 loss: 0.28176218271255493
Batch 48/64 loss: 0.2831321358680725
Batch 49/64 loss: 0.28377628326416016
Batch 50/64 loss: 0.28490960597991943
Batch 51/64 loss: 0.27847886085510254
Batch 52/64 loss: 0.27901244163513184
Batch 53/64 loss: 0.27492135763168335
Batch 54/64 loss: 0.2790573239326477
Batch 55/64 loss: 0.28318774700164795
Batch 56/64 loss: 0.2814132571220398
Batch 57/64 loss: 0.2805224657058716
Batch 58/64 loss: 0.2782691717147827
Batch 59/64 loss: 0.2838301658630371
Batch 60/64 loss: 0.28685617446899414
Batch 61/64 loss: 0.2839968204498291
Batch 62/64 loss: 0.27953243255615234
Batch 63/64 loss: 0.28344595432281494
Batch 64/64 loss: 0.2791990041732788
Epoch 283  Train loss: 0.28074151628157673  Val loss: 0.31314813373834405
Epoch 284
-------------------------------
Batch 1/64 loss: 0.27295148372650146
Batch 2/64 loss: 0.28154146671295166
Batch 3/64 loss: 0.280487596988678
Batch 4/64 loss: 0.2886342406272888
Batch 5/64 loss: 0.28105777502059937
Batch 6/64 loss: 0.2796623706817627
Batch 7/64 loss: 0.27809005975723267
Batch 8/64 loss: 0.27864742279052734
Batch 9/64 loss: 0.2786557674407959
Batch 10/64 loss: 0.2873743772506714
Batch 11/64 loss: 0.2839810252189636
Batch 12/64 loss: 0.28065240383148193
Batch 13/64 loss: 0.2748633027076721
Batch 14/64 loss: 0.2751346230506897
Batch 15/64 loss: 0.2791743874549866
Batch 16/64 loss: 0.2822442650794983
Batch 17/64 loss: 0.2857600450515747
Batch 18/64 loss: 0.27785319089889526
Batch 19/64 loss: 0.2785322666168213
Batch 20/64 loss: 0.2822970151901245
Batch 21/64 loss: 0.2801523804664612
Batch 22/64 loss: 0.27501344680786133
Batch 23/64 loss: 0.2860374450683594
Batch 24/64 loss: 0.2787867784500122
Batch 25/64 loss: 0.2697535753250122
Batch 26/64 loss: 0.2789297103881836
Batch 27/64 loss: 0.28397274017333984
Batch 28/64 loss: 0.283203661441803
Batch 29/64 loss: 0.2777867913246155
Batch 30/64 loss: 0.2897886633872986
Batch 31/64 loss: 0.285056471824646
Batch 32/64 loss: 0.27636146545410156
Batch 33/64 loss: 0.277323842048645
Batch 34/64 loss: 0.28316545486450195
Batch 35/64 loss: 0.28506678342819214
Batch 36/64 loss: 0.28935426473617554
Batch 37/64 loss: 0.27461040019989014
Batch 38/64 loss: 0.2806621789932251
Batch 39/64 loss: 0.2807527780532837
Batch 40/64 loss: 0.2847987413406372
Batch 41/64 loss: 0.2719957232475281
Batch 42/64 loss: 0.28432464599609375
Batch 43/64 loss: 0.2804971933364868
Batch 44/64 loss: 0.2840147018432617
Batch 45/64 loss: 0.27357470989227295
Batch 46/64 loss: 0.279956579208374
Batch 47/64 loss: 0.2785273790359497
Batch 48/64 loss: 0.2834206819534302
Batch 49/64 loss: 0.2785409688949585
Batch 50/64 loss: 0.2820826768875122
Batch 51/64 loss: 0.2811506986618042
Batch 52/64 loss: 0.2854839563369751
Batch 53/64 loss: 0.2734833359718323
Batch 54/64 loss: 0.2823176383972168
Batch 55/64 loss: 0.2844752073287964
Batch 56/64 loss: 0.27514398097991943
Batch 57/64 loss: 0.27820175886154175
Batch 58/64 loss: 0.28614139556884766
Batch 59/64 loss: 0.28366416692733765
Batch 60/64 loss: 0.2771250009536743
Batch 61/64 loss: 0.2842746376991272
Batch 62/64 loss: 0.27811920642852783
Batch 63/64 loss: 0.28391116857528687
Batch 64/64 loss: 0.2752394676208496
Epoch 284  Train loss: 0.28054948507570754  Val loss: 0.3131959055297563
Epoch 285
-------------------------------
Batch 1/64 loss: 0.27836525440216064
Batch 2/64 loss: 0.2806006669998169
Batch 3/64 loss: 0.2802382707595825
Batch 4/64 loss: 0.2771683931350708
Batch 5/64 loss: 0.2763305902481079
Batch 6/64 loss: 0.27817535400390625
Batch 7/64 loss: 0.27959704399108887
Batch 8/64 loss: 0.2734375
Batch 9/64 loss: 0.27399885654449463
Batch 10/64 loss: 0.2770315408706665
Batch 11/64 loss: 0.29078543186187744
Batch 12/64 loss: 0.27705395221710205
Batch 13/64 loss: 0.2817762494087219
Batch 14/64 loss: 0.2758713364601135
Batch 15/64 loss: 0.27904361486434937
Batch 16/64 loss: 0.2803300619125366
Batch 17/64 loss: 0.27983903884887695
Batch 18/64 loss: 0.2782095670700073
Batch 19/64 loss: 0.27417004108428955
Batch 20/64 loss: 0.28033536672592163
Batch 21/64 loss: 0.2770306468009949
Batch 22/64 loss: 0.27956581115722656
Batch 23/64 loss: 0.2801068425178528
Batch 24/64 loss: 0.2824968099594116
Batch 25/64 loss: 0.2909032106399536
Batch 26/64 loss: 0.27326762676239014
Batch 27/64 loss: 0.2874400019645691
Batch 28/64 loss: 0.2761901021003723
Batch 29/64 loss: 0.28203558921813965
Batch 30/64 loss: 0.28148412704467773
Batch 31/64 loss: 0.2831451892852783
Batch 32/64 loss: 0.2811874747276306
Batch 33/64 loss: 0.2829926013946533
Batch 34/64 loss: 0.28346383571624756
Batch 35/64 loss: 0.27998316287994385
Batch 36/64 loss: 0.2757531404495239
Batch 37/64 loss: 0.27744054794311523
Batch 38/64 loss: 0.28622812032699585
Batch 39/64 loss: 0.28096282482147217
Batch 40/64 loss: 0.2760251760482788
Batch 41/64 loss: 0.27657580375671387
Batch 42/64 loss: 0.2812843322753906
Batch 43/64 loss: 0.282726526260376
Batch 44/64 loss: 0.28219664096832275
Batch 45/64 loss: 0.27887028455734253
Batch 46/64 loss: 0.275512158870697
Batch 47/64 loss: 0.2859303951263428
Batch 48/64 loss: 0.283298134803772
Batch 49/64 loss: 0.2819623351097107
Batch 50/64 loss: 0.2791129946708679
Batch 51/64 loss: 0.28177130222320557
Batch 52/64 loss: 0.291279673576355
Batch 53/64 loss: 0.2762317657470703
Batch 54/64 loss: 0.2886916399002075
Batch 55/64 loss: 0.2784239649772644
Batch 56/64 loss: 0.2807978391647339
Batch 57/64 loss: 0.28332221508026123
Batch 58/64 loss: 0.2760040760040283
Batch 59/64 loss: 0.2795053720474243
Batch 60/64 loss: 0.28892356157302856
Batch 61/64 loss: 0.27823853492736816
Batch 62/64 loss: 0.2757725119590759
Batch 63/64 loss: 0.2811143398284912
Batch 64/64 loss: 0.2819467782974243
Epoch 285  Train loss: 0.28029909741644765  Val loss: 0.3129716746995539
Epoch 286
-------------------------------
Batch 1/64 loss: 0.27950334548950195
Batch 2/64 loss: 0.28014928102493286
Batch 3/64 loss: 0.27967286109924316
Batch 4/64 loss: 0.27586209774017334
Batch 5/64 loss: 0.275978684425354
Batch 6/64 loss: 0.27523040771484375
Batch 7/64 loss: 0.27714812755584717
Batch 8/64 loss: 0.28202497959136963
Batch 9/64 loss: 0.28839653730392456
Batch 10/64 loss: 0.2794307470321655
Batch 11/64 loss: 0.2794455885887146
Batch 12/64 loss: 0.27173924446105957
Batch 13/64 loss: 0.2833395004272461
Batch 14/64 loss: 0.2804657220840454
Batch 15/64 loss: 0.276262104511261
Batch 16/64 loss: 0.2744178771972656
Batch 17/64 loss: 0.2739066481590271
Batch 18/64 loss: 0.28544312715530396
Batch 19/64 loss: 0.28130096197128296
Batch 20/64 loss: 0.277676522731781
Batch 21/64 loss: 0.27799785137176514
Batch 22/64 loss: 0.28050482273101807
Batch 23/64 loss: 0.27877283096313477
Batch 24/64 loss: 0.28266018629074097
Batch 25/64 loss: 0.28132736682891846
Batch 26/64 loss: 0.2792412042617798
Batch 27/64 loss: 0.2798740863800049
Batch 28/64 loss: 0.2830730676651001
Batch 29/64 loss: 0.28641563653945923
Batch 30/64 loss: 0.28398728370666504
Batch 31/64 loss: 0.2853308916091919
Batch 32/64 loss: 0.2807280421257019
Batch 33/64 loss: 0.2750992178916931
Batch 34/64 loss: 0.2725660800933838
Batch 35/64 loss: 0.28068310022354126
Batch 36/64 loss: 0.282498836517334
Batch 37/64 loss: 0.27591264247894287
Batch 38/64 loss: 0.2844300866127014
Batch 39/64 loss: 0.28104162216186523
Batch 40/64 loss: 0.2879232168197632
Batch 41/64 loss: 0.28821003437042236
Batch 42/64 loss: 0.2841012477874756
Batch 43/64 loss: 0.2808104157447815
Batch 44/64 loss: 0.28608715534210205
Batch 45/64 loss: 0.27937960624694824
Batch 46/64 loss: 0.2840954065322876
Batch 47/64 loss: 0.2797846794128418
Batch 48/64 loss: 0.28125500679016113
Batch 49/64 loss: 0.2798476815223694
Batch 50/64 loss: 0.28475499153137207
Batch 51/64 loss: 0.2810820937156677
Batch 52/64 loss: 0.2823094129562378
Batch 53/64 loss: 0.28017473220825195
Batch 54/64 loss: 0.27351582050323486
Batch 55/64 loss: 0.28121912479400635
Batch 56/64 loss: 0.2757444381713867
Batch 57/64 loss: 0.2730635404586792
Batch 58/64 loss: 0.28890126943588257
Batch 59/64 loss: 0.2796708345413208
Batch 60/64 loss: 0.27616798877716064
Batch 61/64 loss: 0.28086328506469727
Batch 62/64 loss: 0.27878570556640625
Batch 63/64 loss: 0.27939367294311523
Batch 64/64 loss: 0.2787434458732605
Epoch 286  Train loss: 0.2802468732291577  Val loss: 0.31340758866051216
Epoch 287
-------------------------------
Batch 1/64 loss: 0.27676939964294434
Batch 2/64 loss: 0.27663516998291016
Batch 3/64 loss: 0.279705286026001
Batch 4/64 loss: 0.2801849842071533
Batch 5/64 loss: 0.2734677791595459
Batch 6/64 loss: 0.2829296588897705
Batch 7/64 loss: 0.2773442268371582
Batch 8/64 loss: 0.2841944098472595
Batch 9/64 loss: 0.2845316529273987
Batch 10/64 loss: 0.2789613604545593
Batch 11/64 loss: 0.27710193395614624
Batch 12/64 loss: 0.2805802822113037
Batch 13/64 loss: 0.287062406539917
Batch 14/64 loss: 0.28230392932891846
Batch 15/64 loss: 0.27844780683517456
Batch 16/64 loss: 0.28193163871765137
Batch 17/64 loss: 0.27943944931030273
Batch 18/64 loss: 0.27982097864151
Batch 19/64 loss: 0.2802216410636902
Batch 20/64 loss: 0.2749258279800415
Batch 21/64 loss: 0.2863694429397583
Batch 22/64 loss: 0.2828933596611023
Batch 23/64 loss: 0.28062868118286133
Batch 24/64 loss: 0.2731746435165405
Batch 25/64 loss: 0.2815591096878052
Batch 26/64 loss: 0.2756357192993164
Batch 27/64 loss: 0.27804070711135864
Batch 28/64 loss: 0.2736573815345764
Batch 29/64 loss: 0.2815340757369995
Batch 30/64 loss: 0.2801017761230469
Batch 31/64 loss: 0.29345810413360596
Batch 32/64 loss: 0.2784198522567749
Batch 33/64 loss: 0.27916061878204346
Batch 34/64 loss: 0.28340208530426025
Batch 35/64 loss: 0.28094756603240967
Batch 36/64 loss: 0.2733752727508545
Batch 37/64 loss: 0.27839046716690063
Batch 38/64 loss: 0.27661824226379395
Batch 39/64 loss: 0.2804480791091919
Batch 40/64 loss: 0.2760615944862366
Batch 41/64 loss: 0.28605931997299194
Batch 42/64 loss: 0.27395880222320557
Batch 43/64 loss: 0.2712150812149048
Batch 44/64 loss: 0.274192750453949
Batch 45/64 loss: 0.27872031927108765
Batch 46/64 loss: 0.2828848958015442
Batch 47/64 loss: 0.27965933084487915
Batch 48/64 loss: 0.28277409076690674
Batch 49/64 loss: 0.28274309635162354
Batch 50/64 loss: 0.281494677066803
Batch 51/64 loss: 0.27852892875671387
Batch 52/64 loss: 0.2798506021499634
Batch 53/64 loss: 0.2814061641693115
Batch 54/64 loss: 0.2785264253616333
Batch 55/64 loss: 0.283761203289032
Batch 56/64 loss: 0.27913665771484375
Batch 57/64 loss: 0.27733588218688965
Batch 58/64 loss: 0.2787054181098938
Batch 59/64 loss: 0.284545361995697
Batch 60/64 loss: 0.27698570489883423
Batch 61/64 loss: 0.2836637496948242
Batch 62/64 loss: 0.2830119729042053
Batch 63/64 loss: 0.2790108323097229
Batch 64/64 loss: 0.282454252243042
Epoch 287  Train loss: 0.2798501734640084  Val loss: 0.3133711564991482
Epoch 288
-------------------------------
Batch 1/64 loss: 0.2755739092826843
Batch 2/64 loss: 0.27825653553009033
Batch 3/64 loss: 0.2712284326553345
Batch 4/64 loss: 0.2754852771759033
Batch 5/64 loss: 0.2762443423271179
Batch 6/64 loss: 0.2868403196334839
Batch 7/64 loss: 0.27187204360961914
Batch 8/64 loss: 0.28025180101394653
Batch 9/64 loss: 0.27436763048171997
Batch 10/64 loss: 0.2779923677444458
Batch 11/64 loss: 0.27654266357421875
Batch 12/64 loss: 0.2829663157463074
Batch 13/64 loss: 0.28292006254196167
Batch 14/64 loss: 0.27594125270843506
Batch 15/64 loss: 0.28700852394104004
Batch 16/64 loss: 0.2741517424583435
Batch 17/64 loss: 0.2735797166824341
Batch 18/64 loss: 0.2748855948448181
Batch 19/64 loss: 0.2764955759048462
Batch 20/64 loss: 0.27741968631744385
Batch 21/64 loss: 0.2785416841506958
Batch 22/64 loss: 0.27396881580352783
Batch 23/64 loss: 0.2865694761276245
Batch 24/64 loss: 0.27724623680114746
Batch 25/64 loss: 0.27968382835388184
Batch 26/64 loss: 0.28581559658050537
Batch 27/64 loss: 0.2853834629058838
Batch 28/64 loss: 0.28352802991867065
Batch 29/64 loss: 0.2732977867126465
Batch 30/64 loss: 0.2827305793762207
Batch 31/64 loss: 0.2894423007965088
Batch 32/64 loss: 0.28502851724624634
Batch 33/64 loss: 0.2898678779602051
Batch 34/64 loss: 0.2907834053039551
Batch 35/64 loss: 0.2853085994720459
Batch 36/64 loss: 0.28196418285369873
Batch 37/64 loss: 0.28403234481811523
Batch 38/64 loss: 0.27662408351898193
Batch 39/64 loss: 0.28399163484573364
Batch 40/64 loss: 0.28489089012145996
Batch 41/64 loss: 0.2838563323020935
Batch 42/64 loss: 0.28151023387908936
Batch 43/64 loss: 0.2813516855239868
Batch 44/64 loss: 0.2729964256286621
Batch 45/64 loss: 0.28315722942352295
Batch 46/64 loss: 0.28258538246154785
Batch 47/64 loss: 0.2797648310661316
Batch 48/64 loss: 0.280204176902771
Batch 49/64 loss: 0.2782800793647766
Batch 50/64 loss: 0.28364014625549316
Batch 51/64 loss: 0.2791917324066162
Batch 52/64 loss: 0.2824941873550415
Batch 53/64 loss: 0.27695322036743164
Batch 54/64 loss: 0.28351354598999023
Batch 55/64 loss: 0.27411043643951416
Batch 56/64 loss: 0.2831742763519287
Batch 57/64 loss: 0.282201886177063
Batch 58/64 loss: 0.284055233001709
Batch 59/64 loss: 0.285539448261261
Batch 60/64 loss: 0.279258131980896
Batch 61/64 loss: 0.28487855195999146
Batch 62/64 loss: 0.28645431995391846
Batch 63/64 loss: 0.2849810719490051
Batch 64/64 loss: 0.2761044502258301
Epoch 288  Train loss: 0.280626729890412  Val loss: 0.3129386393884613
Epoch 289
-------------------------------
Batch 1/64 loss: 0.27627646923065186
Batch 2/64 loss: 0.2753435969352722
Batch 3/64 loss: 0.2757112979888916
Batch 4/64 loss: 0.28386372327804565
Batch 5/64 loss: 0.28186333179473877
Batch 6/64 loss: 0.2806849479675293
Batch 7/64 loss: 0.2742789387702942
Batch 8/64 loss: 0.27446967363357544
Batch 9/64 loss: 0.27914631366729736
Batch 10/64 loss: 0.2785158157348633
Batch 11/64 loss: 0.2726174592971802
Batch 12/64 loss: 0.2767949104309082
Batch 13/64 loss: 0.27660614252090454
Batch 14/64 loss: 0.28539228439331055
Batch 15/64 loss: 0.2722012996673584
Batch 16/64 loss: 0.27645909786224365
Batch 17/64 loss: 0.2777196168899536
Batch 18/64 loss: 0.2774921655654907
Batch 19/64 loss: 0.2883157730102539
Batch 20/64 loss: 0.2866302728652954
Batch 21/64 loss: 0.2764986753463745
Batch 22/64 loss: 0.2812504768371582
Batch 23/64 loss: 0.27539634704589844
Batch 24/64 loss: 0.28667008876800537
Batch 25/64 loss: 0.2763185501098633
Batch 26/64 loss: 0.28143107891082764
Batch 27/64 loss: 0.2875518202781677
Batch 28/64 loss: 0.27489781379699707
Batch 29/64 loss: 0.2827904224395752
Batch 30/64 loss: 0.2722209692001343
Batch 31/64 loss: 0.2788037657737732
Batch 32/64 loss: 0.2903147339820862
Batch 33/64 loss: 0.28965890407562256
Batch 34/64 loss: 0.27599555253982544
Batch 35/64 loss: 0.28617942333221436
Batch 36/64 loss: 0.2788417339324951
Batch 37/64 loss: 0.28659045696258545
Batch 38/64 loss: 0.28258180618286133
Batch 39/64 loss: 0.2788466215133667
Batch 40/64 loss: 0.2804325819015503
Batch 41/64 loss: 0.28353404998779297
Batch 42/64 loss: 0.2774469256401062
Batch 43/64 loss: 0.28050124645233154
Batch 44/64 loss: 0.2808935046195984
Batch 45/64 loss: 0.2780568599700928
Batch 46/64 loss: 0.27954065799713135
Batch 47/64 loss: 0.28148919343948364
Batch 48/64 loss: 0.2954446077346802
Batch 49/64 loss: 0.2830709218978882
Batch 50/64 loss: 0.2834707498550415
Batch 51/64 loss: 0.2793450951576233
Batch 52/64 loss: 0.2823066711425781
Batch 53/64 loss: 0.2830285429954529
Batch 54/64 loss: 0.27920347452163696
Batch 55/64 loss: 0.2757120132446289
Batch 56/64 loss: 0.2766863703727722
Batch 57/64 loss: 0.29010289907455444
Batch 58/64 loss: 0.2734562158584595
Batch 59/64 loss: 0.28628814220428467
Batch 60/64 loss: 0.27591466903686523
Batch 61/64 loss: 0.2815377712249756
Batch 62/64 loss: 0.27611416578292847
Batch 63/64 loss: 0.2757813334465027
Batch 64/64 loss: 0.28115588426589966
Epoch 289  Train loss: 0.2802109482241612  Val loss: 0.3121352654552132
Saving best model, epoch: 289
Epoch 290
-------------------------------
Batch 1/64 loss: 0.2771364450454712
Batch 2/64 loss: 0.2832651138305664
Batch 3/64 loss: 0.27955079078674316
Batch 4/64 loss: 0.28231900930404663
Batch 5/64 loss: 0.2758559584617615
Batch 6/64 loss: 0.2778160572052002
Batch 7/64 loss: 0.27978038787841797
Batch 8/64 loss: 0.27642548084259033
Batch 9/64 loss: 0.27310991287231445
Batch 10/64 loss: 0.2814490795135498
Batch 11/64 loss: 0.2757095694541931
Batch 12/64 loss: 0.2758336663246155
Batch 13/64 loss: 0.27181291580200195
Batch 14/64 loss: 0.28221774101257324
Batch 15/64 loss: 0.2828342914581299
Batch 16/64 loss: 0.2836841344833374
Batch 17/64 loss: 0.27793651819229126
Batch 18/64 loss: 0.28386372327804565
Batch 19/64 loss: 0.27444809675216675
Batch 20/64 loss: 0.2825047969818115
Batch 21/64 loss: 0.28366148471832275
Batch 22/64 loss: 0.27597737312316895
Batch 23/64 loss: 0.28120338916778564
Batch 24/64 loss: 0.27470701932907104
Batch 25/64 loss: 0.2782108783721924
Batch 26/64 loss: 0.28249597549438477
Batch 27/64 loss: 0.2736065983772278
Batch 28/64 loss: 0.27893006801605225
Batch 29/64 loss: 0.2848619818687439
Batch 30/64 loss: 0.283866286277771
Batch 31/64 loss: 0.27375757694244385
Batch 32/64 loss: 0.2756063938140869
Batch 33/64 loss: 0.2785550355911255
Batch 34/64 loss: 0.2847471833229065
Batch 35/64 loss: 0.27149802446365356
Batch 36/64 loss: 0.27620208263397217
Batch 37/64 loss: 0.27473461627960205
Batch 38/64 loss: 0.27296435832977295
Batch 39/64 loss: 0.28842198848724365
Batch 40/64 loss: 0.28066229820251465
Batch 41/64 loss: 0.27466875314712524
Batch 42/64 loss: 0.2750399112701416
Batch 43/64 loss: 0.28164535760879517
Batch 44/64 loss: 0.27597975730895996
Batch 45/64 loss: 0.2783459424972534
Batch 46/64 loss: 0.2800101041793823
Batch 47/64 loss: 0.2786807417869568
Batch 48/64 loss: 0.27633965015411377
Batch 49/64 loss: 0.27949023246765137
Batch 50/64 loss: 0.27927863597869873
Batch 51/64 loss: 0.2812492251396179
Batch 52/64 loss: 0.27600228786468506
Batch 53/64 loss: 0.2799309492111206
Batch 54/64 loss: 0.2818838357925415
Batch 55/64 loss: 0.2938575744628906
Batch 56/64 loss: 0.2813541889190674
Batch 57/64 loss: 0.2828899621963501
Batch 58/64 loss: 0.2762279510498047
Batch 59/64 loss: 0.28477537631988525
Batch 60/64 loss: 0.2793135643005371
Batch 61/64 loss: 0.2822815775871277
Batch 62/64 loss: 0.2800416946411133
Batch 63/64 loss: 0.2804139256477356
Batch 64/64 loss: 0.2791184186935425
Epoch 290  Train loss: 0.2792355186798993  Val loss: 0.31292577523136467
Epoch 291
-------------------------------
Batch 1/64 loss: 0.2770771384239197
Batch 2/64 loss: 0.278600811958313
Batch 3/64 loss: 0.27296245098114014
Batch 4/64 loss: 0.2740331292152405
Batch 5/64 loss: 0.2809444069862366
Batch 6/64 loss: 0.281203031539917
Batch 7/64 loss: 0.2800413966178894
Batch 8/64 loss: 0.27293992042541504
Batch 9/64 loss: 0.27274686098098755
Batch 10/64 loss: 0.2821389436721802
Batch 11/64 loss: 0.2740325927734375
Batch 12/64 loss: 0.2756396532058716
Batch 13/64 loss: 0.2728167772293091
Batch 14/64 loss: 0.28443461656570435
Batch 15/64 loss: 0.2772933840751648
Batch 16/64 loss: 0.2799626588821411
Batch 17/64 loss: 0.2834651470184326
Batch 18/64 loss: 0.2897721529006958
Batch 19/64 loss: 0.2729712724685669
Batch 20/64 loss: 0.2798612713813782
Batch 21/64 loss: 0.28427445888519287
Batch 22/64 loss: 0.2797586917877197
Batch 23/64 loss: 0.2811861038208008
Batch 24/64 loss: 0.27774131298065186
Batch 25/64 loss: 0.2800217866897583
Batch 26/64 loss: 0.2744297385215759
Batch 27/64 loss: 0.2802581191062927
Batch 28/64 loss: 0.27733075618743896
Batch 29/64 loss: 0.27284514904022217
Batch 30/64 loss: 0.2766105532646179
Batch 31/64 loss: 0.27616995573043823
Batch 32/64 loss: 0.28039807081222534
Batch 33/64 loss: 0.2791261672973633
Batch 34/64 loss: 0.28013622760772705
Batch 35/64 loss: 0.28018832206726074
Batch 36/64 loss: 0.2747441530227661
Batch 37/64 loss: 0.2788189649581909
Batch 38/64 loss: 0.2766490578651428
Batch 39/64 loss: 0.2790915369987488
Batch 40/64 loss: 0.2826964855194092
Batch 41/64 loss: 0.28050994873046875
Batch 42/64 loss: 0.2776988744735718
Batch 43/64 loss: 0.2845250368118286
Batch 44/64 loss: 0.2801477909088135
Batch 45/64 loss: 0.27485573291778564
Batch 46/64 loss: 0.27968263626098633
Batch 47/64 loss: 0.2868698835372925
Batch 48/64 loss: 0.2810754179954529
Batch 49/64 loss: 0.27830153703689575
Batch 50/64 loss: 0.2809697389602661
Batch 51/64 loss: 0.28143495321273804
Batch 52/64 loss: 0.2805759906768799
Batch 53/64 loss: 0.28511500358581543
Batch 54/64 loss: 0.28197944164276123
Batch 55/64 loss: 0.2765781879425049
Batch 56/64 loss: 0.29268205165863037
Batch 57/64 loss: 0.2819176912307739
Batch 58/64 loss: 0.275088369846344
Batch 59/64 loss: 0.2870482802391052
Batch 60/64 loss: 0.2799123525619507
Batch 61/64 loss: 0.2885779142379761
Batch 62/64 loss: 0.2845156192779541
Batch 63/64 loss: 0.27793681621551514
Batch 64/64 loss: 0.2842942476272583
Epoch 291  Train loss: 0.2796334617278155  Val loss: 0.3127438346135248
Epoch 292
-------------------------------
Batch 1/64 loss: 0.2760583162307739
Batch 2/64 loss: 0.2732938528060913
Batch 3/64 loss: 0.2763906717300415
Batch 4/64 loss: 0.27692103385925293
Batch 5/64 loss: 0.28136587142944336
Batch 6/64 loss: 0.27633798122406006
Batch 7/64 loss: 0.2843363285064697
Batch 8/64 loss: 0.27818310260772705
Batch 9/64 loss: 0.283463716506958
Batch 10/64 loss: 0.27991724014282227
Batch 11/64 loss: 0.2790037989616394
Batch 12/64 loss: 0.2768430709838867
Batch 13/64 loss: 0.2778477668762207
Batch 14/64 loss: 0.28327465057373047
Batch 15/64 loss: 0.2818804979324341
Batch 16/64 loss: 0.27564460039138794
Batch 17/64 loss: 0.28580451011657715
Batch 18/64 loss: 0.2785438299179077
Batch 19/64 loss: 0.28032636642456055
Batch 20/64 loss: 0.2749202251434326
Batch 21/64 loss: 0.2807732820510864
Batch 22/64 loss: 0.2834881544113159
Batch 23/64 loss: 0.2787504196166992
Batch 24/64 loss: 0.2805371880531311
Batch 25/64 loss: 0.272949755191803
Batch 26/64 loss: 0.27156615257263184
Batch 27/64 loss: 0.2803676128387451
Batch 28/64 loss: 0.2757100462913513
Batch 29/64 loss: 0.2903885841369629
Batch 30/64 loss: 0.27278196811676025
Batch 31/64 loss: 0.2896965742111206
Batch 32/64 loss: 0.2799381613731384
Batch 33/64 loss: 0.27409183979034424
Batch 34/64 loss: 0.27421247959136963
Batch 35/64 loss: 0.2723013162612915
Batch 36/64 loss: 0.2809152603149414
Batch 37/64 loss: 0.2759655714035034
Batch 38/64 loss: 0.2737259864807129
Batch 39/64 loss: 0.2809818387031555
Batch 40/64 loss: 0.2851285934448242
Batch 41/64 loss: 0.276808500289917
Batch 42/64 loss: 0.2816500663757324
Batch 43/64 loss: 0.286806583404541
Batch 44/64 loss: 0.2769874930381775
Batch 45/64 loss: 0.2757086753845215
Batch 46/64 loss: 0.28024327754974365
Batch 47/64 loss: 0.2800781726837158
Batch 48/64 loss: 0.2732623815536499
Batch 49/64 loss: 0.27027958631515503
Batch 50/64 loss: 0.2786392569541931
Batch 51/64 loss: 0.274270236492157
Batch 52/64 loss: 0.28653132915496826
Batch 53/64 loss: 0.2866901159286499
Batch 54/64 loss: 0.2778111696243286
Batch 55/64 loss: 0.281453013420105
Batch 56/64 loss: 0.2766597867012024
Batch 57/64 loss: 0.28512752056121826
Batch 58/64 loss: 0.28094130754470825
Batch 59/64 loss: 0.2786608338356018
Batch 60/64 loss: 0.28235745429992676
Batch 61/64 loss: 0.28110194206237793
Batch 62/64 loss: 0.27529871463775635
Batch 63/64 loss: 0.28526902198791504
Batch 64/64 loss: 0.2765704393386841
Epoch 292  Train loss: 0.2791324311611699  Val loss: 0.3130027043450739
Epoch 293
-------------------------------
Batch 1/64 loss: 0.2781246304512024
Batch 2/64 loss: 0.2764846086502075
Batch 3/64 loss: 0.27729713916778564
Batch 4/64 loss: 0.279419481754303
Batch 5/64 loss: 0.28478240966796875
Batch 6/64 loss: 0.28175389766693115
Batch 7/64 loss: 0.2709923982620239
Batch 8/64 loss: 0.2766982316970825
Batch 9/64 loss: 0.28076696395874023
Batch 10/64 loss: 0.2821882963180542
Batch 11/64 loss: 0.28284120559692383
Batch 12/64 loss: 0.27713698148727417
Batch 13/64 loss: 0.2794347405433655
Batch 14/64 loss: 0.2799168825149536
Batch 15/64 loss: 0.27560895681381226
Batch 16/64 loss: 0.27776038646698
Batch 17/64 loss: 0.2845114469528198
Batch 18/64 loss: 0.28451406955718994
Batch 19/64 loss: 0.27653372287750244
Batch 20/64 loss: 0.27842628955841064
Batch 21/64 loss: 0.2821272015571594
Batch 22/64 loss: 0.27836376428604126
Batch 23/64 loss: 0.2831917405128479
Batch 24/64 loss: 0.2761141061782837
Batch 25/64 loss: 0.27492839097976685
Batch 26/64 loss: 0.2785217761993408
Batch 27/64 loss: 0.27903783321380615
Batch 28/64 loss: 0.2823743224143982
Batch 29/64 loss: 0.27192044258117676
Batch 30/64 loss: 0.28217613697052
Batch 31/64 loss: 0.27880001068115234
Batch 32/64 loss: 0.2868639826774597
Batch 33/64 loss: 0.27548444271087646
Batch 34/64 loss: 0.28215765953063965
Batch 35/64 loss: 0.275132417678833
Batch 36/64 loss: 0.27975523471832275
Batch 37/64 loss: 0.27858448028564453
Batch 38/64 loss: 0.2777698040008545
Batch 39/64 loss: 0.28076136112213135
Batch 40/64 loss: 0.28373146057128906
Batch 41/64 loss: 0.27819108963012695
Batch 42/64 loss: 0.27863383293151855
Batch 43/64 loss: 0.28414905071258545
Batch 44/64 loss: 0.2734236717224121
Batch 45/64 loss: 0.2775334119796753
Batch 46/64 loss: 0.2744429111480713
Batch 47/64 loss: 0.2752636671066284
Batch 48/64 loss: 0.2773621082305908
Batch 49/64 loss: 0.28344494104385376
Batch 50/64 loss: 0.28114354610443115
Batch 51/64 loss: 0.27875828742980957
Batch 52/64 loss: 0.2803260087966919
Batch 53/64 loss: 0.2818830609321594
Batch 54/64 loss: 0.2776707410812378
Batch 55/64 loss: 0.28334879875183105
Batch 56/64 loss: 0.28151118755340576
Batch 57/64 loss: 0.27638357877731323
Batch 58/64 loss: 0.2803891897201538
Batch 59/64 loss: 0.27673816680908203
Batch 60/64 loss: 0.2782849669456482
Batch 61/64 loss: 0.27450257539749146
Batch 62/64 loss: 0.27733713388442993
Batch 63/64 loss: 0.2799956202507019
Batch 64/64 loss: 0.2796577215194702
Epoch 293  Train loss: 0.2791129434809965  Val loss: 0.31318908233413173
Epoch 294
-------------------------------
Batch 1/64 loss: 0.2751426696777344
Batch 2/64 loss: 0.2822192907333374
Batch 3/64 loss: 0.27691376209259033
Batch 4/64 loss: 0.277824342250824
Batch 5/64 loss: 0.27903610467910767
Batch 6/64 loss: 0.2782849669456482
Batch 7/64 loss: 0.27525854110717773
Batch 8/64 loss: 0.28441452980041504
Batch 9/64 loss: 0.27382510900497437
Batch 10/64 loss: 0.2775893211364746
Batch 11/64 loss: 0.27688711881637573
Batch 12/64 loss: 0.2729056477546692
Batch 13/64 loss: 0.27639472484588623
Batch 14/64 loss: 0.2787572145462036
Batch 15/64 loss: 0.27596497535705566
Batch 16/64 loss: 0.28103959560394287
Batch 17/64 loss: 0.2813990116119385
Batch 18/64 loss: 0.27932196855545044
Batch 19/64 loss: 0.2735753059387207
Batch 20/64 loss: 0.2777235507965088
Batch 21/64 loss: 0.27806735038757324
Batch 22/64 loss: 0.2722545266151428
Batch 23/64 loss: 0.2813473343849182
Batch 24/64 loss: 0.2740669846534729
Batch 25/64 loss: 0.28204816579818726
Batch 26/64 loss: 0.28529417514801025
Batch 27/64 loss: 0.2811436653137207
Batch 28/64 loss: 0.2845034599304199
Batch 29/64 loss: 0.27228105068206787
Batch 30/64 loss: 0.2817871570587158
Batch 31/64 loss: 0.27453911304473877
Batch 32/64 loss: 0.28160130977630615
Batch 33/64 loss: 0.27101361751556396
Batch 34/64 loss: 0.279904842376709
Batch 35/64 loss: 0.2799718379974365
Batch 36/64 loss: 0.28502923250198364
Batch 37/64 loss: 0.2808114290237427
Batch 38/64 loss: 0.2802954912185669
Batch 39/64 loss: 0.27390599250793457
Batch 40/64 loss: 0.27665936946868896
Batch 41/64 loss: 0.27898359298706055
Batch 42/64 loss: 0.27437806129455566
Batch 43/64 loss: 0.2796785831451416
Batch 44/64 loss: 0.28468501567840576
Batch 45/64 loss: 0.28001177310943604
Batch 46/64 loss: 0.2848244905471802
Batch 47/64 loss: 0.2812851667404175
Batch 48/64 loss: 0.27435749769210815
Batch 49/64 loss: 0.2793099284172058
Batch 50/64 loss: 0.2745358943939209
Batch 51/64 loss: 0.2723017930984497
Batch 52/64 loss: 0.272739052772522
Batch 53/64 loss: 0.27270030975341797
Batch 54/64 loss: 0.2811390161514282
Batch 55/64 loss: 0.2788581848144531
Batch 56/64 loss: 0.28526806831359863
Batch 57/64 loss: 0.2822348475456238
Batch 58/64 loss: 0.2801032066345215
Batch 59/64 loss: 0.2837398648262024
Batch 60/64 loss: 0.285952091217041
Batch 61/64 loss: 0.28106653690338135
Batch 62/64 loss: 0.27648603916168213
Batch 63/64 loss: 0.2784479856491089
Batch 64/64 loss: 0.2865031361579895
Epoch 294  Train loss: 0.27872891309214576  Val loss: 0.3120037106304234
Saving best model, epoch: 294
Epoch 295
-------------------------------
Batch 1/64 loss: 0.268601655960083
Batch 2/64 loss: 0.2799108028411865
Batch 3/64 loss: 0.26897692680358887
Batch 4/64 loss: 0.2911010980606079
Batch 5/64 loss: 0.2785111665725708
Batch 6/64 loss: 0.2767587900161743
Batch 7/64 loss: 0.2774559259414673
Batch 8/64 loss: 0.277748703956604
Batch 9/64 loss: 0.2770425081253052
Batch 10/64 loss: 0.27463316917419434
Batch 11/64 loss: 0.2843148708343506
Batch 12/64 loss: 0.2718803286552429
Batch 13/64 loss: 0.27307015657424927
Batch 14/64 loss: 0.27903568744659424
Batch 15/64 loss: 0.275138258934021
Batch 16/64 loss: 0.2804245352745056
Batch 17/64 loss: 0.2826744318008423
Batch 18/64 loss: 0.27625858783721924
Batch 19/64 loss: 0.2813934087753296
Batch 20/64 loss: 0.2733379602432251
Batch 21/64 loss: 0.2751242518424988
Batch 22/64 loss: 0.2841637134552002
Batch 23/64 loss: 0.2801662087440491
Batch 24/64 loss: 0.2763253450393677
Batch 25/64 loss: 0.28196364641189575
Batch 26/64 loss: 0.280185341835022
Batch 27/64 loss: 0.2859460115432739
Batch 28/64 loss: 0.27816110849380493
Batch 29/64 loss: 0.27806174755096436
Batch 30/64 loss: 0.2780311107635498
Batch 31/64 loss: 0.27651965618133545
Batch 32/64 loss: 0.27811700105667114
Batch 33/64 loss: 0.2776268720626831
Batch 34/64 loss: 0.2775956392288208
Batch 35/64 loss: 0.2795487642288208
Batch 36/64 loss: 0.29205697774887085
Batch 37/64 loss: 0.27648448944091797
Batch 38/64 loss: 0.2818494439125061
Batch 39/64 loss: 0.28494691848754883
Batch 40/64 loss: 0.2812333106994629
Batch 41/64 loss: 0.275601863861084
Batch 42/64 loss: 0.28532183170318604
Batch 43/64 loss: 0.28569626808166504
Batch 44/64 loss: 0.2811012268066406
Batch 45/64 loss: 0.2791138291358948
Batch 46/64 loss: 0.27709901332855225
Batch 47/64 loss: 0.2809833288192749
Batch 48/64 loss: 0.28320837020874023
Batch 49/64 loss: 0.2774997353553772
Batch 50/64 loss: 0.2767162322998047
Batch 51/64 loss: 0.27819597721099854
Batch 52/64 loss: 0.2859266996383667
Batch 53/64 loss: 0.2740286588668823
Batch 54/64 loss: 0.27986860275268555
Batch 55/64 loss: 0.27302783727645874
Batch 56/64 loss: 0.2841532230377197
Batch 57/64 loss: 0.27654707431793213
Batch 58/64 loss: 0.2823161482810974
Batch 59/64 loss: 0.2827063202857971
Batch 60/64 loss: 0.2879389524459839
Batch 61/64 loss: 0.2864845395088196
Batch 62/64 loss: 0.280539870262146
Batch 63/64 loss: 0.2816937565803528
Batch 64/64 loss: 0.27799880504608154
Epoch 295  Train loss: 0.2794767842573278  Val loss: 0.3128419809325044
Epoch 296
-------------------------------
Batch 1/64 loss: 0.2887859344482422
Batch 2/64 loss: 0.27974987030029297
Batch 3/64 loss: 0.28186100721359253
Batch 4/64 loss: 0.2791268229484558
Batch 5/64 loss: 0.27649474143981934
Batch 6/64 loss: 0.2796332836151123
Batch 7/64 loss: 0.2739417552947998
Batch 8/64 loss: 0.28138482570648193
Batch 9/64 loss: 0.2694111466407776
Batch 10/64 loss: 0.2845751643180847
Batch 11/64 loss: 0.27449703216552734
Batch 12/64 loss: 0.27789896726608276
Batch 13/64 loss: 0.2776908874511719
Batch 14/64 loss: 0.27449625730514526
Batch 15/64 loss: 0.2807924747467041
Batch 16/64 loss: 0.28304171562194824
Batch 17/64 loss: 0.27588045597076416
Batch 18/64 loss: 0.27687227725982666
Batch 19/64 loss: 0.2766644358634949
Batch 20/64 loss: 0.2771992087364197
Batch 21/64 loss: 0.2762634754180908
Batch 22/64 loss: 0.2800701856613159
Batch 23/64 loss: 0.27323615550994873
Batch 24/64 loss: 0.27960842847824097
Batch 25/64 loss: 0.276861310005188
Batch 26/64 loss: 0.2865396738052368
Batch 27/64 loss: 0.28242266178131104
Batch 28/64 loss: 0.27332544326782227
Batch 29/64 loss: 0.2820148468017578
Batch 30/64 loss: 0.27556490898132324
Batch 31/64 loss: 0.2727155089378357
Batch 32/64 loss: 0.27135956287384033
Batch 33/64 loss: 0.27525651454925537
Batch 34/64 loss: 0.27465784549713135
Batch 35/64 loss: 0.27720189094543457
Batch 36/64 loss: 0.2734109163284302
Batch 37/64 loss: 0.27747058868408203
Batch 38/64 loss: 0.2839164137840271
Batch 39/64 loss: 0.278026819229126
Batch 40/64 loss: 0.2804536819458008
Batch 41/64 loss: 0.28022241592407227
Batch 42/64 loss: 0.2824520468711853
Batch 43/64 loss: 0.2798123359680176
Batch 44/64 loss: 0.27740466594696045
Batch 45/64 loss: 0.27463221549987793
Batch 46/64 loss: 0.27848589420318604
Batch 47/64 loss: 0.2809387445449829
Batch 48/64 loss: 0.27663588523864746
Batch 49/64 loss: 0.2781982421875
Batch 50/64 loss: 0.28867048025131226
Batch 51/64 loss: 0.2818719148635864
Batch 52/64 loss: 0.2777734398841858
Batch 53/64 loss: 0.2720264196395874
Batch 54/64 loss: 0.2794700860977173
Batch 55/64 loss: 0.2796047329902649
Batch 56/64 loss: 0.27114105224609375
Batch 57/64 loss: 0.2870270609855652
Batch 58/64 loss: 0.28609246015548706
Batch 59/64 loss: 0.27501749992370605
Batch 60/64 loss: 0.28664958477020264
Batch 61/64 loss: 0.285253643989563
Batch 62/64 loss: 0.27597200870513916
Batch 63/64 loss: 0.27034246921539307
Batch 64/64 loss: 0.2830008268356323
Epoch 296  Train loss: 0.27856189830630435  Val loss: 0.31218685788387285
Epoch 297
-------------------------------
Batch 1/64 loss: 0.2792295217514038
Batch 2/64 loss: 0.28249168395996094
Batch 3/64 loss: 0.2806541323661804
Batch 4/64 loss: 0.2815762758255005
Batch 5/64 loss: 0.28223955631256104
Batch 6/64 loss: 0.287700355052948
Batch 7/64 loss: 0.28023308515548706
Batch 8/64 loss: 0.2818077802658081
Batch 9/64 loss: 0.2787085175514221
Batch 10/64 loss: 0.2762112021446228
Batch 11/64 loss: 0.27841806411743164
Batch 12/64 loss: 0.27987003326416016
Batch 13/64 loss: 0.2765312194824219
Batch 14/64 loss: 0.2782314419746399
Batch 15/64 loss: 0.2825589179992676
Batch 16/64 loss: 0.2759630084037781
Batch 17/64 loss: 0.2791358232498169
Batch 18/64 loss: 0.26862776279449463
Batch 19/64 loss: 0.27814579010009766
Batch 20/64 loss: 0.27297794818878174
Batch 21/64 loss: 0.28920191526412964
Batch 22/64 loss: 0.27887701988220215
Batch 23/64 loss: 0.2778933644294739
Batch 24/64 loss: 0.27935123443603516
Batch 25/64 loss: 0.27962255477905273
Batch 26/64 loss: 0.2799529433250427
Batch 27/64 loss: 0.27347540855407715
Batch 28/64 loss: 0.273686945438385
Batch 29/64 loss: 0.2776777744293213
Batch 30/64 loss: 0.2776561975479126
Batch 31/64 loss: 0.27402371168136597
Batch 32/64 loss: 0.2834591865539551
Batch 33/64 loss: 0.29071271419525146
Batch 34/64 loss: 0.27461594343185425
Batch 35/64 loss: 0.27289509773254395
Batch 36/64 loss: 0.2843226194381714
Batch 37/64 loss: 0.2796303629875183
Batch 38/64 loss: 0.28620707988739014
Batch 39/64 loss: 0.2820003032684326
Batch 40/64 loss: 0.27261972427368164
Batch 41/64 loss: 0.2794687747955322
Batch 42/64 loss: 0.27290719747543335
Batch 43/64 loss: 0.27411949634552
Batch 44/64 loss: 0.27965015172958374
Batch 45/64 loss: 0.281353235244751
Batch 46/64 loss: 0.27176928520202637
Batch 47/64 loss: 0.27869248390197754
Batch 48/64 loss: 0.28035056591033936
Batch 49/64 loss: 0.27420294284820557
Batch 50/64 loss: 0.27922725677490234
Batch 51/64 loss: 0.2728811502456665
Batch 52/64 loss: 0.2731991410255432
Batch 53/64 loss: 0.27551108598709106
Batch 54/64 loss: 0.2793459892272949
Batch 55/64 loss: 0.2807626724243164
Batch 56/64 loss: 0.27733683586120605
Batch 57/64 loss: 0.27423083782196045
Batch 58/64 loss: 0.2757920026779175
Batch 59/64 loss: 0.27520322799682617
Batch 60/64 loss: 0.2768094539642334
Batch 61/64 loss: 0.27866584062576294
Batch 62/64 loss: 0.28341442346572876
Batch 63/64 loss: 0.27266597747802734
Batch 64/64 loss: 0.28689271211624146
Epoch 297  Train loss: 0.2784615495625664  Val loss: 0.3134776652883418
Epoch 298
-------------------------------
Batch 1/64 loss: 0.27773940563201904
Batch 2/64 loss: 0.27764594554901123
Batch 3/64 loss: 0.274198055267334
Batch 4/64 loss: 0.2795504331588745
Batch 5/64 loss: 0.27181631326675415
Batch 6/64 loss: 0.2744772434234619
Batch 7/64 loss: 0.2783973217010498
Batch 8/64 loss: 0.27614498138427734
Batch 9/64 loss: 0.2721657156944275
Batch 10/64 loss: 0.2788217067718506
Batch 11/64 loss: 0.28371691703796387
Batch 12/64 loss: 0.27933692932128906
Batch 13/64 loss: 0.28357869386672974
Batch 14/64 loss: 0.27925288677215576
Batch 15/64 loss: 0.277671754360199
Batch 16/64 loss: 0.27996206283569336
Batch 17/64 loss: 0.27396225929260254
Batch 18/64 loss: 0.28040432929992676
Batch 19/64 loss: 0.27766311168670654
Batch 20/64 loss: 0.2827165722846985
Batch 21/64 loss: 0.2791707515716553
Batch 22/64 loss: 0.2748807668685913
Batch 23/64 loss: 0.2864207625389099
Batch 24/64 loss: 0.27859658002853394
Batch 25/64 loss: 0.28210896253585815
Batch 26/64 loss: 0.27527016401290894
Batch 27/64 loss: 0.2815796136856079
Batch 28/64 loss: 0.28417152166366577
Batch 29/64 loss: 0.2751964330673218
Batch 30/64 loss: 0.28422725200653076
Batch 31/64 loss: 0.2725027799606323
Batch 32/64 loss: 0.27249979972839355
Batch 33/64 loss: 0.273120641708374
Batch 34/64 loss: 0.2760888934135437
Batch 35/64 loss: 0.27724146842956543
Batch 36/64 loss: 0.2759629487991333
Batch 37/64 loss: 0.28394901752471924
Batch 38/64 loss: 0.2784475088119507
Batch 39/64 loss: 0.2780954837799072
Batch 40/64 loss: 0.27318274974823
Batch 41/64 loss: 0.2838466167449951
Batch 42/64 loss: 0.276417076587677
Batch 43/64 loss: 0.27735471725463867
Batch 44/64 loss: 0.275218665599823
Batch 45/64 loss: 0.28310292959213257
Batch 46/64 loss: 0.27659285068511963
Batch 47/64 loss: 0.27445530891418457
Batch 48/64 loss: 0.27983570098876953
Batch 49/64 loss: 0.27559894323349
Batch 50/64 loss: 0.2770344018936157
Batch 51/64 loss: 0.28158509731292725
Batch 52/64 loss: 0.2818976640701294
Batch 53/64 loss: 0.28346848487854004
Batch 54/64 loss: 0.27556419372558594
Batch 55/64 loss: 0.2758069634437561
Batch 56/64 loss: 0.2778404951095581
Batch 57/64 loss: 0.27442145347595215
Batch 58/64 loss: 0.27632325887680054
Batch 59/64 loss: 0.2763195037841797
Batch 60/64 loss: 0.27571892738342285
Batch 61/64 loss: 0.27765142917633057
Batch 62/64 loss: 0.28553563356399536
Batch 63/64 loss: 0.2864709496498108
Batch 64/64 loss: 0.28085654973983765
Epoch 298  Train loss: 0.2782845555567274  Val loss: 0.31297959658698116
Epoch 299
-------------------------------
Batch 1/64 loss: 0.27542805671691895
Batch 2/64 loss: 0.281976580619812
Batch 3/64 loss: 0.27419567108154297
Batch 4/64 loss: 0.27267199754714966
Batch 5/64 loss: 0.2723499536514282
Batch 6/64 loss: 0.2744901180267334
Batch 7/64 loss: 0.2726815938949585
Batch 8/64 loss: 0.27611106634140015
Batch 9/64 loss: 0.2758081555366516
Batch 10/64 loss: 0.28526562452316284
Batch 11/64 loss: 0.276065468788147
Batch 12/64 loss: 0.2725338935852051
Batch 13/64 loss: 0.27763235569000244
Batch 14/64 loss: 0.28013837337493896
Batch 15/64 loss: 0.27894163131713867
Batch 16/64 loss: 0.275923490524292
Batch 17/64 loss: 0.2756236791610718
Batch 18/64 loss: 0.28140461444854736
Batch 19/64 loss: 0.27845263481140137
Batch 20/64 loss: 0.27828794717788696
Batch 21/64 loss: 0.27616018056869507
Batch 22/64 loss: 0.2764164209365845
Batch 23/64 loss: 0.27585238218307495
Batch 24/64 loss: 0.28486138582229614
Batch 25/64 loss: 0.27954256534576416
Batch 26/64 loss: 0.27800703048706055
Batch 27/64 loss: 0.2843330502510071
Batch 28/64 loss: 0.281516432762146
Batch 29/64 loss: 0.2819330096244812
Batch 30/64 loss: 0.2782707214355469
Batch 31/64 loss: 0.2816546559333801
Batch 32/64 loss: 0.2787522077560425
Batch 33/64 loss: 0.27787840366363525
Batch 34/64 loss: 0.27202272415161133
Batch 35/64 loss: 0.27238404750823975
Batch 36/64 loss: 0.2812032699584961
Batch 37/64 loss: 0.2775952219963074
Batch 38/64 loss: 0.27480030059814453
Batch 39/64 loss: 0.2796640396118164
Batch 40/64 loss: 0.27808594703674316
Batch 41/64 loss: 0.28254860639572144
Batch 42/64 loss: 0.27590543031692505
Batch 43/64 loss: 0.27710533142089844
Batch 44/64 loss: 0.28415656089782715
Batch 45/64 loss: 0.2776980400085449
Batch 46/64 loss: 0.2744606137275696
Batch 47/64 loss: 0.2788902521133423
Batch 48/64 loss: 0.280326247215271
Batch 49/64 loss: 0.2790309190750122
Batch 50/64 loss: 0.27866387367248535
Batch 51/64 loss: 0.28027307987213135
Batch 52/64 loss: 0.2704981565475464
Batch 53/64 loss: 0.27912914752960205
Batch 54/64 loss: 0.27610349655151367
Batch 55/64 loss: 0.2771592140197754
Batch 56/64 loss: 0.28267228603363037
Batch 57/64 loss: 0.28097522258758545
Batch 58/64 loss: 0.275126576423645
Batch 59/64 loss: 0.27767372131347656
Batch 60/64 loss: 0.28353309631347656
Batch 61/64 loss: 0.27680522203445435
Batch 62/64 loss: 0.2766730785369873
Batch 63/64 loss: 0.28085148334503174
Batch 64/64 loss: 0.28391051292419434
Epoch 299  Train loss: 0.2780566187465892  Val loss: 0.31300500844352436
Epoch 300
-------------------------------
Batch 1/64 loss: 0.2798576354980469
Batch 2/64 loss: 0.2848595976829529
Batch 3/64 loss: 0.27971214056015015
Batch 4/64 loss: 0.2894878387451172
Batch 5/64 loss: 0.28215134143829346
Batch 6/64 loss: 0.2844177484512329
Batch 7/64 loss: 0.2752492427825928
Batch 8/64 loss: 0.2808108329772949
Batch 9/64 loss: 0.2782292366027832
Batch 10/64 loss: 0.28768497705459595
Batch 11/64 loss: 0.2810385227203369
Batch 12/64 loss: 0.2749009132385254
Batch 13/64 loss: 0.2792356014251709
Batch 14/64 loss: 0.2755018472671509
Batch 15/64 loss: 0.28007763624191284
Batch 16/64 loss: 0.2774815559387207
Batch 17/64 loss: 0.27845102548599243
Batch 18/64 loss: 0.27606165409088135
Batch 19/64 loss: 0.2819713354110718
Batch 20/64 loss: 0.2738202214241028
Batch 21/64 loss: 0.2762484550476074
Batch 22/64 loss: 0.27824413776397705
Batch 23/64 loss: 0.27549850940704346
Batch 24/64 loss: 0.27696478366851807
Batch 25/64 loss: 0.2793545126914978
Batch 26/64 loss: 0.27279871702194214
Batch 27/64 loss: 0.27209120988845825
Batch 28/64 loss: 0.2837703824043274
Batch 29/64 loss: 0.28597724437713623
Batch 30/64 loss: 0.2754063606262207
Batch 31/64 loss: 0.28206324577331543
Batch 32/64 loss: 0.2775353193283081
Batch 33/64 loss: 0.276458740234375
Batch 34/64 loss: 0.2729095220565796
Batch 35/64 loss: 0.2798786163330078
Batch 36/64 loss: 0.274308979511261
Batch 37/64 loss: 0.27848291397094727
Batch 38/64 loss: 0.27654385566711426
Batch 39/64 loss: 0.27733397483825684
Batch 40/64 loss: 0.2750675082206726
Batch 41/64 loss: 0.27934205532073975
Batch 42/64 loss: 0.2777249813079834
Batch 43/64 loss: 0.2922924757003784
Batch 44/64 loss: 0.28211498260498047
Batch 45/64 loss: 0.27497100830078125
Batch 46/64 loss: 0.2824786901473999
Batch 47/64 loss: 0.27938199043273926
Batch 48/64 loss: 0.27542340755462646
Batch 49/64 loss: 0.27833569049835205
Batch 50/64 loss: 0.2740074396133423
Batch 51/64 loss: 0.2707727551460266
Batch 52/64 loss: 0.27973473072052
Batch 53/64 loss: 0.28052252531051636
Batch 54/64 loss: 0.27708345651626587
Batch 55/64 loss: 0.27601706981658936
Batch 56/64 loss: 0.27335619926452637
Batch 57/64 loss: 0.279803991317749
Batch 58/64 loss: 0.2815924882888794
Batch 59/64 loss: 0.28128814697265625
Batch 60/64 loss: 0.27088499069213867
Batch 61/64 loss: 0.2788507342338562
Batch 62/64 loss: 0.27779650688171387
Batch 63/64 loss: 0.2755436897277832
Batch 64/64 loss: 0.2863668203353882
Epoch 300  Train loss: 0.27862012573316985  Val loss: 0.3123984533486907
Epoch 301
-------------------------------
Batch 1/64 loss: 0.2770167589187622
Batch 2/64 loss: 0.27178454399108887
Batch 3/64 loss: 0.2800987958908081
Batch 4/64 loss: 0.27890682220458984
Batch 5/64 loss: 0.2741774320602417
Batch 6/64 loss: 0.27130377292633057
Batch 7/64 loss: 0.2786475419998169
Batch 8/64 loss: 0.28341400623321533
Batch 9/64 loss: 0.2805325984954834
Batch 10/64 loss: 0.2820192575454712
Batch 11/64 loss: 0.2777788043022156
Batch 12/64 loss: 0.2735002040863037
Batch 13/64 loss: 0.2808246612548828
Batch 14/64 loss: 0.2816311717033386
Batch 15/64 loss: 0.2710610628128052
Batch 16/64 loss: 0.28008532524108887
Batch 17/64 loss: 0.2774968147277832
Batch 18/64 loss: 0.2758420705795288
Batch 19/64 loss: 0.28622424602508545
Batch 20/64 loss: 0.2819932699203491
Batch 21/64 loss: 0.27758580446243286
Batch 22/64 loss: 0.28391551971435547
Batch 23/64 loss: 0.2854037880897522
Batch 24/64 loss: 0.2754388451576233
Batch 25/64 loss: 0.28187310695648193
Batch 26/64 loss: 0.28200268745422363
Batch 27/64 loss: 0.2728433609008789
Batch 28/64 loss: 0.28153300285339355
Batch 29/64 loss: 0.27833282947540283
Batch 30/64 loss: 0.27978456020355225
Batch 31/64 loss: 0.2829345464706421
Batch 32/64 loss: 0.27447259426116943
Batch 33/64 loss: 0.27176737785339355
Batch 34/64 loss: 0.2765791416168213
Batch 35/64 loss: 0.28124362230300903
Batch 36/64 loss: 0.27915358543395996
Batch 37/64 loss: 0.2776057720184326
Batch 38/64 loss: 0.27868402004241943
Batch 39/64 loss: 0.2718850374221802
Batch 40/64 loss: 0.27719807624816895
Batch 41/64 loss: 0.27667272090911865
Batch 42/64 loss: 0.27972257137298584
Batch 43/64 loss: 0.2873181700706482
Batch 44/64 loss: 0.2776767611503601
Batch 45/64 loss: 0.2783607244491577
Batch 46/64 loss: 0.2813941240310669
Batch 47/64 loss: 0.2740901708602905
Batch 48/64 loss: 0.28075844049453735
Batch 49/64 loss: 0.28612804412841797
Batch 50/64 loss: 0.27686041593551636
Batch 51/64 loss: 0.2799699306488037
Batch 52/64 loss: 0.28376221656799316
Batch 53/64 loss: 0.28209102153778076
Batch 54/64 loss: 0.27292144298553467
Batch 55/64 loss: 0.279441237449646
Batch 56/64 loss: 0.28476881980895996
Batch 57/64 loss: 0.27509361505508423
Batch 58/64 loss: 0.2820005416870117
Batch 59/64 loss: 0.2797574996948242
Batch 60/64 loss: 0.27227699756622314
Batch 61/64 loss: 0.27488231658935547
Batch 62/64 loss: 0.27548718452453613
Batch 63/64 loss: 0.2766827940940857
Batch 64/64 loss: 0.27939027547836304
Epoch 301  Train loss: 0.2786233240482854  Val loss: 0.3122702550232615
Epoch 302
-------------------------------
Batch 1/64 loss: 0.27853482961654663
Batch 2/64 loss: 0.27962613105773926
Batch 3/64 loss: 0.2831435203552246
Batch 4/64 loss: 0.2782430052757263
Batch 5/64 loss: 0.27711665630340576
Batch 6/64 loss: 0.2737545967102051
Batch 7/64 loss: 0.2781480550765991
Batch 8/64 loss: 0.2720269560813904
Batch 9/64 loss: 0.2710844874382019
Batch 10/64 loss: 0.2823798656463623
Batch 11/64 loss: 0.2750413417816162
Batch 12/64 loss: 0.2729998826980591
Batch 13/64 loss: 0.2799183130264282
Batch 14/64 loss: 0.27555590867996216
Batch 15/64 loss: 0.27522313594818115
Batch 16/64 loss: 0.2745457887649536
Batch 17/64 loss: 0.28940820693969727
Batch 18/64 loss: 0.2789151072502136
Batch 19/64 loss: 0.2736660838127136
Batch 20/64 loss: 0.27214133739471436
Batch 21/64 loss: 0.27287042140960693
Batch 22/64 loss: 0.277148962020874
Batch 23/64 loss: 0.2811657190322876
Batch 24/64 loss: 0.2722989320755005
Batch 25/64 loss: 0.28246796131134033
Batch 26/64 loss: 0.27724897861480713
Batch 27/64 loss: 0.2792966365814209
Batch 28/64 loss: 0.2803881764411926
Batch 29/64 loss: 0.278641939163208
Batch 30/64 loss: 0.28691399097442627
Batch 31/64 loss: 0.27644962072372437
Batch 32/64 loss: 0.27187538146972656
Batch 33/64 loss: 0.2712589502334595
Batch 34/64 loss: 0.280375599861145
Batch 35/64 loss: 0.27437812089920044
Batch 36/64 loss: 0.27506375312805176
Batch 37/64 loss: 0.28420186042785645
Batch 38/64 loss: 0.27672815322875977
Batch 39/64 loss: 0.277878999710083
Batch 40/64 loss: 0.2816370725631714
Batch 41/64 loss: 0.2847212553024292
Batch 42/64 loss: 0.27383583784103394
Batch 43/64 loss: 0.2724834680557251
Batch 44/64 loss: 0.2780442237854004
Batch 45/64 loss: 0.2724076509475708
Batch 46/64 loss: 0.27304959297180176
Batch 47/64 loss: 0.27262020111083984
Batch 48/64 loss: 0.2814101576805115
Batch 49/64 loss: 0.2873806953430176
Batch 50/64 loss: 0.26962578296661377
Batch 51/64 loss: 0.2749350070953369
Batch 52/64 loss: 0.2838870882987976
Batch 53/64 loss: 0.27792888879776
Batch 54/64 loss: 0.2772108316421509
Batch 55/64 loss: 0.27345919609069824
Batch 56/64 loss: 0.27058911323547363
Batch 57/64 loss: 0.26780927181243896
Batch 58/64 loss: 0.27634698152542114
Batch 59/64 loss: 0.28776735067367554
Batch 60/64 loss: 0.27726054191589355
Batch 61/64 loss: 0.2791179418563843
Batch 62/64 loss: 0.27824246883392334
Batch 63/64 loss: 0.28042125701904297
Batch 64/64 loss: 0.2860525846481323
Epoch 302  Train loss: 0.2774095165963266  Val loss: 0.31289586045897705
Epoch 303
-------------------------------
Batch 1/64 loss: 0.28358757495880127
Batch 2/64 loss: 0.27453142404556274
Batch 3/64 loss: 0.281039834022522
Batch 4/64 loss: 0.2719493508338928
Batch 5/64 loss: 0.27763497829437256
Batch 6/64 loss: 0.278537392616272
Batch 7/64 loss: 0.2813526391983032
Batch 8/64 loss: 0.28090494871139526
Batch 9/64 loss: 0.2768280506134033
Batch 10/64 loss: 0.27491700649261475
Batch 11/64 loss: 0.2781628370285034
Batch 12/64 loss: 0.28310370445251465
Batch 13/64 loss: 0.28155529499053955
Batch 14/64 loss: 0.2720118761062622
Batch 15/64 loss: 0.28386765718460083
Batch 16/64 loss: 0.27902305126190186
Batch 17/64 loss: 0.2701050043106079
Batch 18/64 loss: 0.2746421694755554
Batch 19/64 loss: 0.27700042724609375
Batch 20/64 loss: 0.2814562916755676
Batch 21/64 loss: 0.2774081230163574
Batch 22/64 loss: 0.284365177154541
Batch 23/64 loss: 0.2777113914489746
Batch 24/64 loss: 0.2817614674568176
Batch 25/64 loss: 0.27106916904449463
Batch 26/64 loss: 0.28425467014312744
Batch 27/64 loss: 0.27056777477264404
Batch 28/64 loss: 0.27441859245300293
Batch 29/64 loss: 0.27123141288757324
Batch 30/64 loss: 0.2794189453125
Batch 31/64 loss: 0.2778512239456177
Batch 32/64 loss: 0.27267253398895264
Batch 33/64 loss: 0.27762681245803833
Batch 34/64 loss: 0.2738703489303589
Batch 35/64 loss: 0.2769113779067993
Batch 36/64 loss: 0.27482903003692627
Batch 37/64 loss: 0.272893488407135
Batch 38/64 loss: 0.2710508108139038
Batch 39/64 loss: 0.27634429931640625
Batch 40/64 loss: 0.2790539264678955
Batch 41/64 loss: 0.28005075454711914
Batch 42/64 loss: 0.28478699922561646
Batch 43/64 loss: 0.27325719594955444
Batch 44/64 loss: 0.28234386444091797
Batch 45/64 loss: 0.2805880308151245
Batch 46/64 loss: 0.2744309902191162
Batch 47/64 loss: 0.27979588508605957
Batch 48/64 loss: 0.2768697738647461
Batch 49/64 loss: 0.2786785960197449
Batch 50/64 loss: 0.2800867557525635
Batch 51/64 loss: 0.283430814743042
Batch 52/64 loss: 0.2772302031517029
Batch 53/64 loss: 0.2757812738418579
Batch 54/64 loss: 0.2819499969482422
Batch 55/64 loss: 0.2744176387786865
Batch 56/64 loss: 0.2745059132575989
Batch 57/64 loss: 0.2767322063446045
Batch 58/64 loss: 0.2771785259246826
Batch 59/64 loss: 0.27455830574035645
Batch 60/64 loss: 0.2739351987838745
Batch 61/64 loss: 0.2767798900604248
Batch 62/64 loss: 0.2765316963195801
Batch 63/64 loss: 0.28043460845947266
Batch 64/64 loss: 0.2860201597213745
Epoch 303  Train loss: 0.27759046788309133  Val loss: 0.31297774495128095
Epoch 304
-------------------------------
Batch 1/64 loss: 0.278359591960907
Batch 2/64 loss: 0.277191698551178
Batch 3/64 loss: 0.27485406398773193
Batch 4/64 loss: 0.27670997381210327
Batch 5/64 loss: 0.2842290997505188
Batch 6/64 loss: 0.27720266580581665
Batch 7/64 loss: 0.279404878616333
Batch 8/64 loss: 0.27483928203582764
Batch 9/64 loss: 0.28709733486175537
Batch 10/64 loss: 0.28280264139175415
Batch 11/64 loss: 0.2728196382522583
Batch 12/64 loss: 0.2748231887817383
Batch 13/64 loss: 0.2738122344017029
Batch 14/64 loss: 0.27920109033584595
Batch 15/64 loss: 0.27549779415130615
Batch 16/64 loss: 0.27364808320999146
Batch 17/64 loss: 0.2818605899810791
Batch 18/64 loss: 0.26938843727111816
Batch 19/64 loss: 0.2794126272201538
Batch 20/64 loss: 0.26905542612075806
Batch 21/64 loss: 0.2820242643356323
Batch 22/64 loss: 0.27210843563079834
Batch 23/64 loss: 0.27584290504455566
Batch 24/64 loss: 0.27991044521331787
Batch 25/64 loss: 0.2807421088218689
Batch 26/64 loss: 0.27684998512268066
Batch 27/64 loss: 0.2749735116958618
Batch 28/64 loss: 0.28016048669815063
Batch 29/64 loss: 0.2730974555015564
Batch 30/64 loss: 0.2813565135002136
Batch 31/64 loss: 0.27821457386016846
Batch 32/64 loss: 0.2866869568824768
Batch 33/64 loss: 0.2737710475921631
Batch 34/64 loss: 0.27644169330596924
Batch 35/64 loss: 0.27760088443756104
Batch 36/64 loss: 0.27694010734558105
Batch 37/64 loss: 0.2752268314361572
Batch 38/64 loss: 0.2842329740524292
Batch 39/64 loss: 0.27825629711151123
Batch 40/64 loss: 0.27244246006011963
Batch 41/64 loss: 0.28426092863082886
Batch 42/64 loss: 0.27921801805496216
Batch 43/64 loss: 0.2744947671890259
Batch 44/64 loss: 0.27808070182800293
Batch 45/64 loss: 0.28032124042510986
Batch 46/64 loss: 0.2700515389442444
Batch 47/64 loss: 0.2799133062362671
Batch 48/64 loss: 0.2836039662361145
Batch 49/64 loss: 0.27941644191741943
Batch 50/64 loss: 0.27857279777526855
Batch 51/64 loss: 0.2711290121078491
Batch 52/64 loss: 0.2769277095794678
Batch 53/64 loss: 0.2782512307167053
Batch 54/64 loss: 0.27785933017730713
Batch 55/64 loss: 0.2783677577972412
Batch 56/64 loss: 0.2712193727493286
Batch 57/64 loss: 0.27886104583740234
Batch 58/64 loss: 0.27096331119537354
Batch 59/64 loss: 0.2831280827522278
Batch 60/64 loss: 0.2805631756782532
Batch 61/64 loss: 0.28473854064941406
Batch 62/64 loss: 0.27545565366744995
Batch 63/64 loss: 0.2788724899291992
Batch 64/64 loss: 0.27743858098983765
Epoch 304  Train loss: 0.27766964131710575  Val loss: 0.31296855375119503
Epoch 305
-------------------------------
Batch 1/64 loss: 0.27664393186569214
Batch 2/64 loss: 0.27317118644714355
Batch 3/64 loss: 0.28120744228363037
Batch 4/64 loss: 0.277743935585022
Batch 5/64 loss: 0.281436562538147
Batch 6/64 loss: 0.2779936194419861
Batch 7/64 loss: 0.27358102798461914
Batch 8/64 loss: 0.27680081129074097
Batch 9/64 loss: 0.27622056007385254
Batch 10/64 loss: 0.2789563536643982
Batch 11/64 loss: 0.2760235071182251
Batch 12/64 loss: 0.274910569190979
Batch 13/64 loss: 0.2756967544555664
Batch 14/64 loss: 0.27942270040512085
Batch 15/64 loss: 0.2716323137283325
Batch 16/64 loss: 0.283965528011322
Batch 17/64 loss: 0.2714505195617676
Batch 18/64 loss: 0.2853369116783142
Batch 19/64 loss: 0.282002329826355
Batch 20/64 loss: 0.27906423807144165
Batch 21/64 loss: 0.2726539373397827
Batch 22/64 loss: 0.27453064918518066
Batch 23/64 loss: 0.2719952464103699
Batch 24/64 loss: 0.272774338722229
Batch 25/64 loss: 0.2759897708892822
Batch 26/64 loss: 0.27130329608917236
Batch 27/64 loss: 0.278563916683197
Batch 28/64 loss: 0.2840965986251831
Batch 29/64 loss: 0.27473682165145874
Batch 30/64 loss: 0.28242355585098267
Batch 31/64 loss: 0.2748539447784424
Batch 32/64 loss: 0.28046083450317383
Batch 33/64 loss: 0.27569806575775146
Batch 34/64 loss: 0.2777862548828125
Batch 35/64 loss: 0.2787383794784546
Batch 36/64 loss: 0.27898740768432617
Batch 37/64 loss: 0.2739201784133911
Batch 38/64 loss: 0.2798638343811035
Batch 39/64 loss: 0.2813605070114136
Batch 40/64 loss: 0.27940237522125244
Batch 41/64 loss: 0.2694287896156311
Batch 42/64 loss: 0.27829980850219727
Batch 43/64 loss: 0.2826232314109802
Batch 44/64 loss: 0.2808210253715515
Batch 45/64 loss: 0.2799478769302368
Batch 46/64 loss: 0.28529369831085205
Batch 47/64 loss: 0.27686548233032227
Batch 48/64 loss: 0.2753763198852539
Batch 49/64 loss: 0.27563077211380005
Batch 50/64 loss: 0.27724647521972656
Batch 51/64 loss: 0.27141034603118896
Batch 52/64 loss: 0.28088587522506714
Batch 53/64 loss: 0.2802329659461975
Batch 54/64 loss: 0.28224194049835205
Batch 55/64 loss: 0.27681243419647217
Batch 56/64 loss: 0.2739570140838623
Batch 57/64 loss: 0.27727609872817993
Batch 58/64 loss: 0.27703309059143066
Batch 59/64 loss: 0.2740704417228699
Batch 60/64 loss: 0.27272123098373413
Batch 61/64 loss: 0.2842171788215637
Batch 62/64 loss: 0.28371667861938477
Batch 63/64 loss: 0.27928245067596436
Batch 64/64 loss: 0.27067917585372925
Epoch 305  Train loss: 0.2775184521488115  Val loss: 0.3132948150339815
Epoch 306
-------------------------------
Batch 1/64 loss: 0.2723745107650757
Batch 2/64 loss: 0.2779698371887207
Batch 3/64 loss: 0.27172356843948364
Batch 4/64 loss: 0.27583837509155273
Batch 5/64 loss: 0.27701252698898315
Batch 6/64 loss: 0.2744770646095276
Batch 7/64 loss: 0.28082799911499023
Batch 8/64 loss: 0.2854539752006531
Batch 9/64 loss: 0.27167773246765137
Batch 10/64 loss: 0.2735486626625061
Batch 11/64 loss: 0.2697291970252991
Batch 12/64 loss: 0.28099942207336426
Batch 13/64 loss: 0.27389317750930786
Batch 14/64 loss: 0.27068132162094116
Batch 15/64 loss: 0.2761162519454956
Batch 16/64 loss: 0.27624398469924927
Batch 17/64 loss: 0.2697172164916992
Batch 18/64 loss: 0.2740589380264282
Batch 19/64 loss: 0.286893367767334
Batch 20/64 loss: 0.27179086208343506
Batch 21/64 loss: 0.27556562423706055
Batch 22/64 loss: 0.27572566270828247
Batch 23/64 loss: 0.277210533618927
Batch 24/64 loss: 0.2753766179084778
Batch 25/64 loss: 0.27837157249450684
Batch 26/64 loss: 0.27688586711883545
Batch 27/64 loss: 0.27252185344696045
Batch 28/64 loss: 0.2768297791481018
Batch 29/64 loss: 0.27337974309921265
Batch 30/64 loss: 0.2746158242225647
Batch 31/64 loss: 0.2806572914123535
Batch 32/64 loss: 0.2782765030860901
Batch 33/64 loss: 0.2763829827308655
Batch 34/64 loss: 0.2852856516838074
Batch 35/64 loss: 0.2773122787475586
Batch 36/64 loss: 0.27897435426712036
Batch 37/64 loss: 0.27928102016448975
Batch 38/64 loss: 0.2812703847885132
Batch 39/64 loss: 0.28269410133361816
Batch 40/64 loss: 0.2775781750679016
Batch 41/64 loss: 0.28283441066741943
Batch 42/64 loss: 0.278637170791626
Batch 43/64 loss: 0.27517247200012207
Batch 44/64 loss: 0.2831302881240845
Batch 45/64 loss: 0.27158212661743164
Batch 46/64 loss: 0.27047884464263916
Batch 47/64 loss: 0.2813183665275574
Batch 48/64 loss: 0.2729030251502991
Batch 49/64 loss: 0.27127552032470703
Batch 50/64 loss: 0.27564430236816406
Batch 51/64 loss: 0.28439611196517944
Batch 52/64 loss: 0.27924907207489014
Batch 53/64 loss: 0.27779871225357056
Batch 54/64 loss: 0.28355956077575684
Batch 55/64 loss: 0.2821670174598694
Batch 56/64 loss: 0.2733515501022339
Batch 57/64 loss: 0.2865135669708252
Batch 58/64 loss: 0.2746342420578003
Batch 59/64 loss: 0.2928866147994995
Batch 60/64 loss: 0.27987563610076904
Batch 61/64 loss: 0.2833508253097534
Batch 62/64 loss: 0.2780996561050415
Batch 63/64 loss: 0.27031219005584717
Batch 64/64 loss: 0.2796128988265991
Epoch 306  Train loss: 0.27739772188897227  Val loss: 0.31222093330625816
Epoch 307
-------------------------------
Batch 1/64 loss: 0.2797316312789917
Batch 2/64 loss: 0.2761240005493164
Batch 3/64 loss: 0.2735632658004761
Batch 4/64 loss: 0.2769421339035034
Batch 5/64 loss: 0.28110814094543457
Batch 6/64 loss: 0.2712785005569458
Batch 7/64 loss: 0.2810415029525757
Batch 8/64 loss: 0.27625012397766113
Batch 9/64 loss: 0.2747228741645813
Batch 10/64 loss: 0.27829253673553467
Batch 11/64 loss: 0.2758049964904785
Batch 12/64 loss: 0.27709120512008667
Batch 13/64 loss: 0.2744027376174927
Batch 14/64 loss: 0.27772027254104614
Batch 15/64 loss: 0.2706605792045593
Batch 16/64 loss: 0.2767144441604614
Batch 17/64 loss: 0.28456002473831177
Batch 18/64 loss: 0.28304338455200195
Batch 19/64 loss: 0.2781873345375061
Batch 20/64 loss: 0.27662205696105957
Batch 21/64 loss: 0.283419132232666
Batch 22/64 loss: 0.2759703993797302
Batch 23/64 loss: 0.2699943780899048
Batch 24/64 loss: 0.2758307456970215
Batch 25/64 loss: 0.28439831733703613
Batch 26/64 loss: 0.277987003326416
Batch 27/64 loss: 0.2718108296394348
Batch 28/64 loss: 0.27348750829696655
Batch 29/64 loss: 0.274208664894104
Batch 30/64 loss: 0.2722214460372925
Batch 31/64 loss: 0.2808687686920166
Batch 32/64 loss: 0.2751537561416626
Batch 33/64 loss: 0.2767750024795532
Batch 34/64 loss: 0.27401649951934814
Batch 35/64 loss: 0.2745843529701233
Batch 36/64 loss: 0.2730346918106079
Batch 37/64 loss: 0.2775533199310303
Batch 38/64 loss: 0.2786879539489746
Batch 39/64 loss: 0.27974069118499756
Batch 40/64 loss: 0.2777402400970459
Batch 41/64 loss: 0.27977705001831055
Batch 42/64 loss: 0.2791684865951538
Batch 43/64 loss: 0.2744675874710083
Batch 44/64 loss: 0.274869441986084
Batch 45/64 loss: 0.27613580226898193
Batch 46/64 loss: 0.2824620008468628
Batch 47/64 loss: 0.27215754985809326
Batch 48/64 loss: 0.27644962072372437
Batch 49/64 loss: 0.27365803718566895
Batch 50/64 loss: 0.27409493923187256
Batch 51/64 loss: 0.27789247035980225
Batch 52/64 loss: 0.2713158130645752
Batch 53/64 loss: 0.28069543838500977
Batch 54/64 loss: 0.2792983651161194
Batch 55/64 loss: 0.27409839630126953
Batch 56/64 loss: 0.2729756236076355
Batch 57/64 loss: 0.28804123401641846
Batch 58/64 loss: 0.27585381269454956
Batch 59/64 loss: 0.2773094177246094
Batch 60/64 loss: 0.27854543924331665
Batch 61/64 loss: 0.28390514850616455
Batch 62/64 loss: 0.2796560525894165
Batch 63/64 loss: 0.2758375406265259
Batch 64/64 loss: 0.2816205620765686
Epoch 307  Train loss: 0.2770388413878048  Val loss: 0.31170188930026443
Saving best model, epoch: 307
Epoch 308
-------------------------------
Batch 1/64 loss: 0.2766690254211426
Batch 2/64 loss: 0.27658456563949585
Batch 3/64 loss: 0.27287912368774414
Batch 4/64 loss: 0.27238500118255615
Batch 5/64 loss: 0.27140384912490845
Batch 6/64 loss: 0.28267282247543335
Batch 7/64 loss: 0.27835363149642944
Batch 8/64 loss: 0.27878206968307495
Batch 9/64 loss: 0.2805456519126892
Batch 10/64 loss: 0.2704676389694214
Batch 11/64 loss: 0.27646660804748535
Batch 12/64 loss: 0.27665627002716064
Batch 13/64 loss: 0.27731752395629883
Batch 14/64 loss: 0.27570903301239014
Batch 15/64 loss: 0.2775699496269226
Batch 16/64 loss: 0.2763790488243103
Batch 17/64 loss: 0.2741212844848633
Batch 18/64 loss: 0.27678382396698
Batch 19/64 loss: 0.2673952579498291
Batch 20/64 loss: 0.2792664170265198
Batch 21/64 loss: 0.27304553985595703
Batch 22/64 loss: 0.27524709701538086
Batch 23/64 loss: 0.27723610401153564
Batch 24/64 loss: 0.2811734080314636
Batch 25/64 loss: 0.2871010899543762
Batch 26/64 loss: 0.26969826221466064
Batch 27/64 loss: 0.2725871801376343
Batch 28/64 loss: 0.27602118253707886
Batch 29/64 loss: 0.27874451875686646
Batch 30/64 loss: 0.2764246463775635
Batch 31/64 loss: 0.26753783226013184
Batch 32/64 loss: 0.27509504556655884
Batch 33/64 loss: 0.2775809168815613
Batch 34/64 loss: 0.27380216121673584
Batch 35/64 loss: 0.284199059009552
Batch 36/64 loss: 0.27814340591430664
Batch 37/64 loss: 0.28502941131591797
Batch 38/64 loss: 0.27290797233581543
Batch 39/64 loss: 0.27781498432159424
Batch 40/64 loss: 0.27709150314331055
Batch 41/64 loss: 0.27745509147644043
Batch 42/64 loss: 0.2854604125022888
Batch 43/64 loss: 0.275943398475647
Batch 44/64 loss: 0.2755606174468994
Batch 45/64 loss: 0.2753397822380066
Batch 46/64 loss: 0.2807670831680298
Batch 47/64 loss: 0.27003538608551025
Batch 48/64 loss: 0.27268457412719727
Batch 49/64 loss: 0.27188634872436523
Batch 50/64 loss: 0.2795819044113159
Batch 51/64 loss: 0.2740401029586792
Batch 52/64 loss: 0.2773955464363098
Batch 53/64 loss: 0.27705293893814087
Batch 54/64 loss: 0.27724337577819824
Batch 55/64 loss: 0.2742565870285034
Batch 56/64 loss: 0.2731919288635254
Batch 57/64 loss: 0.273159921169281
Batch 58/64 loss: 0.2746332883834839
Batch 59/64 loss: 0.2751646637916565
Batch 60/64 loss: 0.2711610794067383
Batch 61/64 loss: 0.27856355905532837
Batch 62/64 loss: 0.2790840268135071
Batch 63/64 loss: 0.2825013995170593
Batch 64/64 loss: 0.2817003130912781
Epoch 308  Train loss: 0.27636593206256044  Val loss: 0.31291660697189805
Epoch 309
-------------------------------
Batch 1/64 loss: 0.27831095457077026
Batch 2/64 loss: 0.2851659655570984
Batch 3/64 loss: 0.270211398601532
Batch 4/64 loss: 0.27210450172424316
Batch 5/64 loss: 0.27909374237060547
Batch 6/64 loss: 0.26941603422164917
Batch 7/64 loss: 0.2734951972961426
Batch 8/64 loss: 0.27137911319732666
Batch 9/64 loss: 0.27467989921569824
Batch 10/64 loss: 0.2726045250892639
Batch 11/64 loss: 0.27990877628326416
Batch 12/64 loss: 0.27517521381378174
Batch 13/64 loss: 0.27695125341415405
Batch 14/64 loss: 0.2748866081237793
Batch 15/64 loss: 0.27713632583618164
Batch 16/64 loss: 0.2796633243560791
Batch 17/64 loss: 0.2762563228607178
Batch 18/64 loss: 0.27877336740493774
Batch 19/64 loss: 0.2695843577384949
Batch 20/64 loss: 0.2791152596473694
Batch 21/64 loss: 0.28228992223739624
Batch 22/64 loss: 0.27865731716156006
Batch 23/64 loss: 0.278286337852478
Batch 24/64 loss: 0.2744295597076416
Batch 25/64 loss: 0.2806941866874695
Batch 26/64 loss: 0.2728163003921509
Batch 27/64 loss: 0.2742539644241333
Batch 28/64 loss: 0.27634918689727783
Batch 29/64 loss: 0.26843464374542236
Batch 30/64 loss: 0.2777371406555176
Batch 31/64 loss: 0.2852790355682373
Batch 32/64 loss: 0.27562928199768066
Batch 33/64 loss: 0.2779301404953003
Batch 34/64 loss: 0.27250945568084717
Batch 35/64 loss: 0.27801692485809326
Batch 36/64 loss: 0.2798008322715759
Batch 37/64 loss: 0.2806926965713501
Batch 38/64 loss: 0.2716652750968933
Batch 39/64 loss: 0.27280163764953613
Batch 40/64 loss: 0.27411794662475586
Batch 41/64 loss: 0.2773662805557251
Batch 42/64 loss: 0.27732861042022705
Batch 43/64 loss: 0.2794121503829956
Batch 44/64 loss: 0.2767332196235657
Batch 45/64 loss: 0.2806210517883301
Batch 46/64 loss: 0.2781240940093994
Batch 47/64 loss: 0.27497196197509766
Batch 48/64 loss: 0.2829551100730896
Batch 49/64 loss: 0.2802528142929077
Batch 50/64 loss: 0.27332544326782227
Batch 51/64 loss: 0.28119075298309326
Batch 52/64 loss: 0.2746204733848572
Batch 53/64 loss: 0.2761498689651489
Batch 54/64 loss: 0.2788667678833008
Batch 55/64 loss: 0.2734612226486206
Batch 56/64 loss: 0.28143441677093506
Batch 57/64 loss: 0.2765880823135376
Batch 58/64 loss: 0.2863615155220032
Batch 59/64 loss: 0.27472758293151855
Batch 60/64 loss: 0.27995920181274414
Batch 61/64 loss: 0.28125137090682983
Batch 62/64 loss: 0.2710702419281006
Batch 63/64 loss: 0.278042733669281
Batch 64/64 loss: 0.28183650970458984
Epoch 309  Train loss: 0.276901902404486  Val loss: 0.31238111228877324
Epoch 310
-------------------------------
Batch 1/64 loss: 0.2830215096473694
Batch 2/64 loss: 0.28337860107421875
Batch 3/64 loss: 0.27673959732055664
Batch 4/64 loss: 0.2716379165649414
Batch 5/64 loss: 0.27541863918304443
Batch 6/64 loss: 0.2750670909881592
Batch 7/64 loss: 0.2849116921424866
Batch 8/64 loss: 0.2726789712905884
Batch 9/64 loss: 0.2704925537109375
Batch 10/64 loss: 0.2788006067276001
Batch 11/64 loss: 0.27216386795043945
Batch 12/64 loss: 0.27549517154693604
Batch 13/64 loss: 0.2804337739944458
Batch 14/64 loss: 0.28589779138565063
Batch 15/64 loss: 0.2781327962875366
Batch 16/64 loss: 0.27113109827041626
Batch 17/64 loss: 0.26925766468048096
Batch 18/64 loss: 0.27681785821914673
Batch 19/64 loss: 0.2760099172592163
Batch 20/64 loss: 0.27523666620254517
Batch 21/64 loss: 0.27296215295791626
Batch 22/64 loss: 0.277972936630249
Batch 23/64 loss: 0.27471625804901123
Batch 24/64 loss: 0.2804678678512573
Batch 25/64 loss: 0.27780818939208984
Batch 26/64 loss: 0.28098511695861816
Batch 27/64 loss: 0.2735387086868286
Batch 28/64 loss: 0.27384090423583984
Batch 29/64 loss: 0.27649402618408203
Batch 30/64 loss: 0.26681697368621826
Batch 31/64 loss: 0.27629220485687256
Batch 32/64 loss: 0.2810018062591553
Batch 33/64 loss: 0.27266454696655273
Batch 34/64 loss: 0.28024184703826904
Batch 35/64 loss: 0.28044629096984863
Batch 36/64 loss: 0.27172231674194336
Batch 37/64 loss: 0.2763195037841797
Batch 38/64 loss: 0.28178977966308594
Batch 39/64 loss: 0.28162306547164917
Batch 40/64 loss: 0.28269726037979126
Batch 41/64 loss: 0.27250802516937256
Batch 42/64 loss: 0.2749069929122925
Batch 43/64 loss: 0.2782543897628784
Batch 44/64 loss: 0.27019691467285156
Batch 45/64 loss: 0.2759380340576172
Batch 46/64 loss: 0.28166425228118896
Batch 47/64 loss: 0.2819310426712036
Batch 48/64 loss: 0.27491670846939087
Batch 49/64 loss: 0.2699615955352783
Batch 50/64 loss: 0.2728828191757202
Batch 51/64 loss: 0.26892125606536865
Batch 52/64 loss: 0.27699553966522217
Batch 53/64 loss: 0.27736514806747437
Batch 54/64 loss: 0.2769514322280884
Batch 55/64 loss: 0.28213435411453247
Batch 56/64 loss: 0.2801437973976135
Batch 57/64 loss: 0.28423261642456055
Batch 58/64 loss: 0.27520138025283813
Batch 59/64 loss: 0.2855968475341797
Batch 60/64 loss: 0.27637946605682373
Batch 61/64 loss: 0.27373045682907104
Batch 62/64 loss: 0.2790639400482178
Batch 63/64 loss: 0.27731525897979736
Batch 64/64 loss: 0.277296245098114
Epoch 310  Train loss: 0.2768359214651818  Val loss: 0.31250817382458557
Epoch 311
-------------------------------
Batch 1/64 loss: 0.27984416484832764
Batch 2/64 loss: 0.28175270557403564
Batch 3/64 loss: 0.2815272808074951
Batch 4/64 loss: 0.2766181230545044
Batch 5/64 loss: 0.2788550853729248
Batch 6/64 loss: 0.2699846029281616
Batch 7/64 loss: 0.2740987539291382
Batch 8/64 loss: 0.2704317569732666
Batch 9/64 loss: 0.2770671844482422
Batch 10/64 loss: 0.2804487943649292
Batch 11/64 loss: 0.2782217860221863
Batch 12/64 loss: 0.2754729986190796
Batch 13/64 loss: 0.27178502082824707
Batch 14/64 loss: 0.27670472860336304
Batch 15/64 loss: 0.26927733421325684
Batch 16/64 loss: 0.279837429523468
Batch 17/64 loss: 0.2791334390640259
Batch 18/64 loss: 0.27830928564071655
Batch 19/64 loss: 0.27289026975631714
Batch 20/64 loss: 0.2716856002807617
Batch 21/64 loss: 0.2739684581756592
Batch 22/64 loss: 0.28235340118408203
Batch 23/64 loss: 0.2825058102607727
Batch 24/64 loss: 0.28035807609558105
Batch 25/64 loss: 0.27752482891082764
Batch 26/64 loss: 0.2793104648590088
Batch 27/64 loss: 0.27722489833831787
Batch 28/64 loss: 0.2759893536567688
Batch 29/64 loss: 0.27523499727249146
Batch 30/64 loss: 0.2775934934616089
Batch 31/64 loss: 0.2770218849182129
Batch 32/64 loss: 0.2771156430244446
Batch 33/64 loss: 0.2795886993408203
Batch 34/64 loss: 0.28211748600006104
Batch 35/64 loss: 0.2724558115005493
Batch 36/64 loss: 0.27890169620513916
Batch 37/64 loss: 0.27480828762054443
Batch 38/64 loss: 0.27877742052078247
Batch 39/64 loss: 0.2771855592727661
Batch 40/64 loss: 0.28241628408432007
Batch 41/64 loss: 0.2801538109779358
Batch 42/64 loss: 0.2783793807029724
Batch 43/64 loss: 0.2819387912750244
Batch 44/64 loss: 0.2773953676223755
Batch 45/64 loss: 0.2741374373435974
Batch 46/64 loss: 0.27592945098876953
Batch 47/64 loss: 0.2827165126800537
Batch 48/64 loss: 0.2783859968185425
Batch 49/64 loss: 0.2737395167350769
Batch 50/64 loss: 0.28012168407440186
Batch 51/64 loss: 0.2833779454231262
Batch 52/64 loss: 0.2807074785232544
Batch 53/64 loss: 0.2824665904045105
Batch 54/64 loss: 0.2819233536720276
Batch 55/64 loss: 0.2793121933937073
Batch 56/64 loss: 0.27989423274993896
Batch 57/64 loss: 0.26996755599975586
Batch 58/64 loss: 0.2737649083137512
Batch 59/64 loss: 0.276674747467041
Batch 60/64 loss: 0.2737612724304199
Batch 61/64 loss: 0.27489638328552246
Batch 62/64 loss: 0.27356791496276855
Batch 63/64 loss: 0.2712058424949646
Batch 64/64 loss: 0.2809637188911438
Epoch 311  Train loss: 0.2773574910911859  Val loss: 0.3125731080668079
Epoch 312
-------------------------------
Batch 1/64 loss: 0.27897030115127563
Batch 2/64 loss: 0.2804030776023865
Batch 3/64 loss: 0.2752685546875
Batch 4/64 loss: 0.2813010811805725
Batch 5/64 loss: 0.284782350063324
Batch 6/64 loss: 0.27574265003204346
Batch 7/64 loss: 0.27438580989837646
Batch 8/64 loss: 0.27689146995544434
Batch 9/64 loss: 0.2798067331314087
Batch 10/64 loss: 0.28891730308532715
Batch 11/64 loss: 0.2759965658187866
Batch 12/64 loss: 0.27982866764068604
Batch 13/64 loss: 0.2775067090988159
Batch 14/64 loss: 0.2776731252670288
Batch 15/64 loss: 0.2754451036453247
Batch 16/64 loss: 0.2776275873184204
Batch 17/64 loss: 0.2717231512069702
Batch 18/64 loss: 0.27316415309906006
Batch 19/64 loss: 0.2799639105796814
Batch 20/64 loss: 0.2774546146392822
Batch 21/64 loss: 0.2778744697570801
Batch 22/64 loss: 0.270754337310791
Batch 23/64 loss: 0.2856484055519104
Batch 24/64 loss: 0.28184711933135986
Batch 25/64 loss: 0.2744462490081787
Batch 26/64 loss: 0.2706845998764038
Batch 27/64 loss: 0.28434181213378906
Batch 28/64 loss: 0.27624815702438354
Batch 29/64 loss: 0.2747185230255127
Batch 30/64 loss: 0.27411651611328125
Batch 31/64 loss: 0.27370685338974
Batch 32/64 loss: 0.27714991569519043
Batch 33/64 loss: 0.26947563886642456
Batch 34/64 loss: 0.2843429446220398
Batch 35/64 loss: 0.27686989307403564
Batch 36/64 loss: 0.2685481905937195
Batch 37/64 loss: 0.26953983306884766
Batch 38/64 loss: 0.2791469097137451
Batch 39/64 loss: 0.27319586277008057
Batch 40/64 loss: 0.2719932794570923
Batch 41/64 loss: 0.2786451578140259
Batch 42/64 loss: 0.27492159605026245
Batch 43/64 loss: 0.27306389808654785
Batch 44/64 loss: 0.2771185636520386
Batch 45/64 loss: 0.27648937702178955
Batch 46/64 loss: 0.2787288427352905
Batch 47/64 loss: 0.2700034976005554
Batch 48/64 loss: 0.27474749088287354
Batch 49/64 loss: 0.27382493019104004
Batch 50/64 loss: 0.27634990215301514
Batch 51/64 loss: 0.2769099473953247
Batch 52/64 loss: 0.2800397276878357
Batch 53/64 loss: 0.27834439277648926
Batch 54/64 loss: 0.2827967405319214
Batch 55/64 loss: 0.28221189975738525
Batch 56/64 loss: 0.278982937335968
Batch 57/64 loss: 0.27624863386154175
Batch 58/64 loss: 0.2836241126060486
Batch 59/64 loss: 0.27780717611312866
Batch 60/64 loss: 0.2783784866333008
Batch 61/64 loss: 0.2765513062477112
Batch 62/64 loss: 0.27676403522491455
Batch 63/64 loss: 0.28368741273880005
Batch 64/64 loss: 0.2811124324798584
Epoch 312  Train loss: 0.27724826382655726  Val loss: 0.3123027512298007
Epoch 313
-------------------------------
Batch 1/64 loss: 0.27289414405822754
Batch 2/64 loss: 0.2752830982208252
Batch 3/64 loss: 0.27493512630462646
Batch 4/64 loss: 0.27358508110046387
Batch 5/64 loss: 0.275271475315094
Batch 6/64 loss: 0.273356556892395
Batch 7/64 loss: 0.2776421308517456
Batch 8/64 loss: 0.2771337032318115
Batch 9/64 loss: 0.27476203441619873
Batch 10/64 loss: 0.2762221097946167
Batch 11/64 loss: 0.27167069911956787
Batch 12/64 loss: 0.275482177734375
Batch 13/64 loss: 0.2748411297798157
Batch 14/64 loss: 0.26844310760498047
Batch 15/64 loss: 0.27197468280792236
Batch 16/64 loss: 0.2773703336715698
Batch 17/64 loss: 0.27758824825286865
Batch 18/64 loss: 0.2706780433654785
Batch 19/64 loss: 0.2799663543701172
Batch 20/64 loss: 0.283266544342041
Batch 21/64 loss: 0.27217376232147217
Batch 22/64 loss: 0.2810947895050049
Batch 23/64 loss: 0.27524662017822266
Batch 24/64 loss: 0.274713933467865
Batch 25/64 loss: 0.2812343239784241
Batch 26/64 loss: 0.2764343023300171
Batch 27/64 loss: 0.2785210609436035
Batch 28/64 loss: 0.277057409286499
Batch 29/64 loss: 0.2787671685218811
Batch 30/64 loss: 0.2746872305870056
Batch 31/64 loss: 0.27306127548217773
Batch 32/64 loss: 0.27823418378829956
Batch 33/64 loss: 0.2705347537994385
Batch 34/64 loss: 0.27702629566192627
Batch 35/64 loss: 0.2740432620048523
Batch 36/64 loss: 0.2797040343284607
Batch 37/64 loss: 0.28180837631225586
Batch 38/64 loss: 0.2767949104309082
Batch 39/64 loss: 0.27203214168548584
Batch 40/64 loss: 0.27843719720840454
Batch 41/64 loss: 0.28179365396499634
Batch 42/64 loss: 0.2800597548484802
Batch 43/64 loss: 0.2766209840774536
Batch 44/64 loss: 0.2825585603713989
Batch 45/64 loss: 0.2742457985877991
Batch 46/64 loss: 0.2716388702392578
Batch 47/64 loss: 0.2742081880569458
Batch 48/64 loss: 0.273563027381897
Batch 49/64 loss: 0.2830957770347595
Batch 50/64 loss: 0.27685511112213135
Batch 51/64 loss: 0.2833314538002014
Batch 52/64 loss: 0.27977365255355835
Batch 53/64 loss: 0.2835577726364136
Batch 54/64 loss: 0.2726637125015259
Batch 55/64 loss: 0.27915799617767334
Batch 56/64 loss: 0.2751576900482178
Batch 57/64 loss: 0.2706543803215027
Batch 58/64 loss: 0.2751842737197876
Batch 59/64 loss: 0.2868356704711914
Batch 60/64 loss: 0.27856606245040894
Batch 61/64 loss: 0.2812578082084656
Batch 62/64 loss: 0.28448760509490967
Batch 63/64 loss: 0.27726423740386963
Batch 64/64 loss: 0.2789270877838135
Epoch 313  Train loss: 0.2767953124700808  Val loss: 0.3123066726419115
Epoch 314
-------------------------------
Batch 1/64 loss: 0.27090322971343994
Batch 2/64 loss: 0.2746039628982544
Batch 3/64 loss: 0.28209829330444336
Batch 4/64 loss: 0.27238744497299194
Batch 5/64 loss: 0.2863021492958069
Batch 6/64 loss: 0.2769879102706909
Batch 7/64 loss: 0.2734089493751526
Batch 8/64 loss: 0.2741932272911072
Batch 9/64 loss: 0.27609920501708984
Batch 10/64 loss: 0.2746637463569641
Batch 11/64 loss: 0.2709692716598511
Batch 12/64 loss: 0.2737694978713989
Batch 13/64 loss: 0.27845293283462524
Batch 14/64 loss: 0.2750990390777588
Batch 15/64 loss: 0.27927547693252563
Batch 16/64 loss: 0.28298306465148926
Batch 17/64 loss: 0.2757711410522461
Batch 18/64 loss: 0.2751278281211853
Batch 19/64 loss: 0.27386677265167236
Batch 20/64 loss: 0.27192699909210205
Batch 21/64 loss: 0.2834776043891907
Batch 22/64 loss: 0.27913498878479004
Batch 23/64 loss: 0.27653932571411133
Batch 24/64 loss: 0.2895263433456421
Batch 25/64 loss: 0.2808130383491516
Batch 26/64 loss: 0.27751266956329346
Batch 27/64 loss: 0.2748103737831116
Batch 28/64 loss: 0.27626848220825195
Batch 29/64 loss: 0.27367061376571655
Batch 30/64 loss: 0.2769273519515991
Batch 31/64 loss: 0.2748492956161499
Batch 32/64 loss: 0.2748298645019531
Batch 33/64 loss: 0.2781563997268677
Batch 34/64 loss: 0.2810570001602173
Batch 35/64 loss: 0.2764294147491455
Batch 36/64 loss: 0.2727994918823242
Batch 37/64 loss: 0.27589845657348633
Batch 38/64 loss: 0.27375364303588867
Batch 39/64 loss: 0.2736993432044983
Batch 40/64 loss: 0.28207486867904663
Batch 41/64 loss: 0.284853458404541
Batch 42/64 loss: 0.2759256958961487
Batch 43/64 loss: 0.28526896238327026
Batch 44/64 loss: 0.2743460536003113
Batch 45/64 loss: 0.27594470977783203
Batch 46/64 loss: 0.27728021144866943
Batch 47/64 loss: 0.2746950387954712
Batch 48/64 loss: 0.2782759666442871
Batch 49/64 loss: 0.2710897922515869
Batch 50/64 loss: 0.27067840099334717
Batch 51/64 loss: 0.2780756950378418
Batch 52/64 loss: 0.2768510580062866
Batch 53/64 loss: 0.2814525365829468
Batch 54/64 loss: 0.28067874908447266
Batch 55/64 loss: 0.2780846357345581
Batch 56/64 loss: 0.27275288105010986
Batch 57/64 loss: 0.27019500732421875
Batch 58/64 loss: 0.27292710542678833
Batch 59/64 loss: 0.2731797695159912
Batch 60/64 loss: 0.2820497751235962
Batch 61/64 loss: 0.2786712646484375
Batch 62/64 loss: 0.28056955337524414
Batch 63/64 loss: 0.2729833126068115
Batch 64/64 loss: 0.2714189887046814
Epoch 314  Train loss: 0.2767296092182982  Val loss: 0.3124009739492357
Epoch 315
-------------------------------
Batch 1/64 loss: 0.26786959171295166
Batch 2/64 loss: 0.2770049571990967
Batch 3/64 loss: 0.28152382373809814
Batch 4/64 loss: 0.27157437801361084
Batch 5/64 loss: 0.27722108364105225
Batch 6/64 loss: 0.2729458212852478
Batch 7/64 loss: 0.2717553377151489
Batch 8/64 loss: 0.28145456314086914
Batch 9/64 loss: 0.279329776763916
Batch 10/64 loss: 0.27443909645080566
Batch 11/64 loss: 0.2788892388343811
Batch 12/64 loss: 0.27818262577056885
Batch 13/64 loss: 0.2812608480453491
Batch 14/64 loss: 0.2730053663253784
Batch 15/64 loss: 0.2775222659111023
Batch 16/64 loss: 0.2779048681259155
Batch 17/64 loss: 0.27336734533309937
Batch 18/64 loss: 0.2742823362350464
Batch 19/64 loss: 0.2795450687408447
Batch 20/64 loss: 0.27544015645980835
Batch 21/64 loss: 0.27297621965408325
Batch 22/64 loss: 0.27611279487609863
Batch 23/64 loss: 0.2743791937828064
Batch 24/64 loss: 0.2837928533554077
Batch 25/64 loss: 0.27252197265625
Batch 26/64 loss: 0.27861320972442627
Batch 27/64 loss: 0.2806549072265625
Batch 28/64 loss: 0.26641398668289185
Batch 29/64 loss: 0.2716662883758545
Batch 30/64 loss: 0.27259743213653564
Batch 31/64 loss: 0.2777301073074341
Batch 32/64 loss: 0.2760465741157532
Batch 33/64 loss: 0.2707716226577759
Batch 34/64 loss: 0.2729724049568176
Batch 35/64 loss: 0.2764672636985779
Batch 36/64 loss: 0.267836332321167
Batch 37/64 loss: 0.2727489471435547
Batch 38/64 loss: 0.27756011486053467
Batch 39/64 loss: 0.2749388813972473
Batch 40/64 loss: 0.27572083473205566
Batch 41/64 loss: 0.273625910282135
Batch 42/64 loss: 0.2709587812423706
Batch 43/64 loss: 0.2682616710662842
Batch 44/64 loss: 0.2744859457015991
Batch 45/64 loss: 0.2697467803955078
Batch 46/64 loss: 0.2783334255218506
Batch 47/64 loss: 0.2845209836959839
Batch 48/64 loss: 0.28684866428375244
Batch 49/64 loss: 0.27701133489608765
Batch 50/64 loss: 0.2761381268501282
Batch 51/64 loss: 0.27839308977127075
Batch 52/64 loss: 0.2740856409072876
Batch 53/64 loss: 0.27332401275634766
Batch 54/64 loss: 0.2748907804489136
Batch 55/64 loss: 0.27079182863235474
Batch 56/64 loss: 0.273015558719635
Batch 57/64 loss: 0.2778550982475281
Batch 58/64 loss: 0.28863608837127686
Batch 59/64 loss: 0.2845025658607483
Batch 60/64 loss: 0.2727353572845459
Batch 61/64 loss: 0.2786579132080078
Batch 62/64 loss: 0.27320170402526855
Batch 63/64 loss: 0.28046679496765137
Batch 64/64 loss: 0.2807275056838989
Epoch 315  Train loss: 0.2758913596471151  Val loss: 0.31124884197392416
Saving best model, epoch: 315
Epoch 316
-------------------------------
Batch 1/64 loss: 0.27486592531204224
Batch 2/64 loss: 0.2778550386428833
Batch 3/64 loss: 0.269283652305603
Batch 4/64 loss: 0.27422845363616943
Batch 5/64 loss: 0.2772436738014221
Batch 6/64 loss: 0.2728203535079956
Batch 7/64 loss: 0.2809567451477051
Batch 8/64 loss: 0.27806293964385986
Batch 9/64 loss: 0.27808964252471924
Batch 10/64 loss: 0.2775520086288452
Batch 11/64 loss: 0.2713114619255066
Batch 12/64 loss: 0.28039872646331787
Batch 13/64 loss: 0.2696459889411926
Batch 14/64 loss: 0.2887231707572937
Batch 15/64 loss: 0.28552746772766113
Batch 16/64 loss: 0.27188706398010254
Batch 17/64 loss: 0.2792736887931824
Batch 18/64 loss: 0.28350841999053955
Batch 19/64 loss: 0.2751377820968628
Batch 20/64 loss: 0.28318512439727783
Batch 21/64 loss: 0.27066564559936523
Batch 22/64 loss: 0.27776020765304565
Batch 23/64 loss: 0.2754242420196533
Batch 24/64 loss: 0.26729023456573486
Batch 25/64 loss: 0.27255743741989136
Batch 26/64 loss: 0.27638185024261475
Batch 27/64 loss: 0.27596139907836914
Batch 28/64 loss: 0.27473217248916626
Batch 29/64 loss: 0.26703310012817383
Batch 30/64 loss: 0.27953851222991943
Batch 31/64 loss: 0.2716052532196045
Batch 32/64 loss: 0.273457407951355
Batch 33/64 loss: 0.2712745666503906
Batch 34/64 loss: 0.2736404538154602
Batch 35/64 loss: 0.2667825222015381
Batch 36/64 loss: 0.2711557149887085
Batch 37/64 loss: 0.275476336479187
Batch 38/64 loss: 0.2701141834259033
Batch 39/64 loss: 0.27502870559692383
Batch 40/64 loss: 0.2781682014465332
Batch 41/64 loss: 0.27152061462402344
Batch 42/64 loss: 0.28952479362487793
Batch 43/64 loss: 0.2804504632949829
Batch 44/64 loss: 0.27443552017211914
Batch 45/64 loss: 0.2823299765586853
Batch 46/64 loss: 0.2743925452232361
Batch 47/64 loss: 0.27613508701324463
Batch 48/64 loss: 0.2855168581008911
Batch 49/64 loss: 0.2768126130104065
Batch 50/64 loss: 0.2801148295402527
Batch 51/64 loss: 0.27976715564727783
Batch 52/64 loss: 0.2798893451690674
Batch 53/64 loss: 0.2788093090057373
Batch 54/64 loss: 0.2791846990585327
Batch 55/64 loss: 0.2808936834335327
Batch 56/64 loss: 0.283184289932251
Batch 57/64 loss: 0.278369665145874
Batch 58/64 loss: 0.2781583070755005
Batch 59/64 loss: 0.27550941705703735
Batch 60/64 loss: 0.2825843095779419
Batch 61/64 loss: 0.280414342880249
Batch 62/64 loss: 0.2798606753349304
Batch 63/64 loss: 0.2717045545578003
Batch 64/64 loss: 0.27425140142440796
Epoch 316  Train loss: 0.2766879542201173  Val loss: 0.3127816471037586
Epoch 317
-------------------------------
Batch 1/64 loss: 0.27936065196990967
Batch 2/64 loss: 0.27837586402893066
Batch 3/64 loss: 0.26816779375076294
Batch 4/64 loss: 0.27208375930786133
Batch 5/64 loss: 0.2748293876647949
Batch 6/64 loss: 0.26961350440979004
Batch 7/64 loss: 0.27452707290649414
Batch 8/64 loss: 0.274921715259552
Batch 9/64 loss: 0.2786601781845093
Batch 10/64 loss: 0.2698976993560791
Batch 11/64 loss: 0.2746645212173462
Batch 12/64 loss: 0.2707105875015259
Batch 13/64 loss: 0.27085429430007935
Batch 14/64 loss: 0.2763594388961792
Batch 15/64 loss: 0.2834232449531555
Batch 16/64 loss: 0.2818495035171509
Batch 17/64 loss: 0.2805522680282593
Batch 18/64 loss: 0.26866137981414795
Batch 19/64 loss: 0.27707386016845703
Batch 20/64 loss: 0.2724093198776245
Batch 21/64 loss: 0.2746947407722473
Batch 22/64 loss: 0.2732630968093872
Batch 23/64 loss: 0.26537179946899414
Batch 24/64 loss: 0.27508974075317383
Batch 25/64 loss: 0.28059637546539307
Batch 26/64 loss: 0.2705453634262085
Batch 27/64 loss: 0.2807609438896179
Batch 28/64 loss: 0.2698822021484375
Batch 29/64 loss: 0.2789508104324341
Batch 30/64 loss: 0.2835671901702881
Batch 31/64 loss: 0.273318350315094
Batch 32/64 loss: 0.27419352531433105
Batch 33/64 loss: 0.2775079011917114
Batch 34/64 loss: 0.27733755111694336
Batch 35/64 loss: 0.2737377882003784
Batch 36/64 loss: 0.26928162574768066
Batch 37/64 loss: 0.2849555015563965
Batch 38/64 loss: 0.26887446641921997
Batch 39/64 loss: 0.28038454055786133
Batch 40/64 loss: 0.27507615089416504
Batch 41/64 loss: 0.27963364124298096
Batch 42/64 loss: 0.27756285667419434
Batch 43/64 loss: 0.2775379419326782
Batch 44/64 loss: 0.2829386591911316
Batch 45/64 loss: 0.274333655834198
Batch 46/64 loss: 0.28170114755630493
Batch 47/64 loss: 0.2773456573486328
Batch 48/64 loss: 0.27593934535980225
Batch 49/64 loss: 0.27682191133499146
Batch 50/64 loss: 0.27757924795150757
Batch 51/64 loss: 0.28083622455596924
Batch 52/64 loss: 0.2754344940185547
Batch 53/64 loss: 0.27407097816467285
Batch 54/64 loss: 0.27138257026672363
Batch 55/64 loss: 0.2739276885986328
Batch 56/64 loss: 0.2699129581451416
Batch 57/64 loss: 0.27188020944595337
Batch 58/64 loss: 0.2685524821281433
Batch 59/64 loss: 0.2734970450401306
Batch 60/64 loss: 0.27525919675827026
Batch 61/64 loss: 0.27831292152404785
Batch 62/64 loss: 0.27301526069641113
Batch 63/64 loss: 0.28057634830474854
Batch 64/64 loss: 0.2784029245376587
Epoch 317  Train loss: 0.27547043678807276  Val loss: 0.3117373247736508
Epoch 318
-------------------------------
Batch 1/64 loss: 0.2714616060256958
Batch 2/64 loss: 0.27424192428588867
Batch 3/64 loss: 0.2691138982772827
Batch 4/64 loss: 0.2738025188446045
Batch 5/64 loss: 0.2710205912590027
Batch 6/64 loss: 0.2732475996017456
Batch 7/64 loss: 0.2786381244659424
Batch 8/64 loss: 0.2730065584182739
Batch 9/64 loss: 0.27126139402389526
Batch 10/64 loss: 0.2713303565979004
Batch 11/64 loss: 0.2762467861175537
Batch 12/64 loss: 0.2727357745170593
Batch 13/64 loss: 0.28292912244796753
Batch 14/64 loss: 0.2683029770851135
Batch 15/64 loss: 0.27321845293045044
Batch 16/64 loss: 0.27381908893585205
Batch 17/64 loss: 0.2671480178833008
Batch 18/64 loss: 0.27735912799835205
Batch 19/64 loss: 0.2821534276008606
Batch 20/64 loss: 0.26921647787094116
Batch 21/64 loss: 0.28866928815841675
Batch 22/64 loss: 0.2678748369216919
Batch 23/64 loss: 0.2797197103500366
Batch 24/64 loss: 0.2734133005142212
Batch 25/64 loss: 0.2729538083076477
Batch 26/64 loss: 0.28085362911224365
Batch 27/64 loss: 0.2743009924888611
Batch 28/64 loss: 0.279970645904541
Batch 29/64 loss: 0.27105796337127686
Batch 30/64 loss: 0.27318865060806274
Batch 31/64 loss: 0.2710219621658325
Batch 32/64 loss: 0.2753812074661255
Batch 33/64 loss: 0.2743328809738159
Batch 34/64 loss: 0.2764471173286438
Batch 35/64 loss: 0.2773045301437378
Batch 36/64 loss: 0.2762378454208374
Batch 37/64 loss: 0.27697867155075073
Batch 38/64 loss: 0.2755175232887268
Batch 39/64 loss: 0.2694462537765503
Batch 40/64 loss: 0.27505648136138916
Batch 41/64 loss: 0.2716022729873657
Batch 42/64 loss: 0.2746042013168335
Batch 43/64 loss: 0.276755690574646
Batch 44/64 loss: 0.280670702457428
Batch 45/64 loss: 0.27355462312698364
Batch 46/64 loss: 0.2761111259460449
Batch 47/64 loss: 0.28095436096191406
Batch 48/64 loss: 0.27538156509399414
Batch 49/64 loss: 0.2756977081298828
Batch 50/64 loss: 0.28121137619018555
Batch 51/64 loss: 0.2754667401313782
Batch 52/64 loss: 0.2685885429382324
Batch 53/64 loss: 0.2880357503890991
Batch 54/64 loss: 0.27840161323547363
Batch 55/64 loss: 0.27021682262420654
Batch 56/64 loss: 0.2787431478500366
Batch 57/64 loss: 0.27479130029678345
Batch 58/64 loss: 0.27542662620544434
Batch 59/64 loss: 0.27701693773269653
Batch 60/64 loss: 0.28222787380218506
Batch 61/64 loss: 0.2758416533470154
Batch 62/64 loss: 0.2772226333618164
Batch 63/64 loss: 0.27958810329437256
Batch 64/64 loss: 0.2740827202796936
Epoch 318  Train loss: 0.2753514437114491  Val loss: 0.31301944464752357
Epoch 319
-------------------------------
Batch 1/64 loss: 0.27424168586730957
Batch 2/64 loss: 0.27390605211257935
Batch 3/64 loss: 0.2715718746185303
Batch 4/64 loss: 0.27451157569885254
Batch 5/64 loss: 0.26941782236099243
Batch 6/64 loss: 0.27121222019195557
Batch 7/64 loss: 0.27339673042297363
Batch 8/64 loss: 0.27247053384780884
Batch 9/64 loss: 0.27798712253570557
Batch 10/64 loss: 0.2671654224395752
Batch 11/64 loss: 0.28382623195648193
Batch 12/64 loss: 0.2708074450492859
Batch 13/64 loss: 0.26968443393707275
Batch 14/64 loss: 0.28169894218444824
Batch 15/64 loss: 0.27359116077423096
Batch 16/64 loss: 0.2745751738548279
Batch 17/64 loss: 0.28098446130752563
Batch 18/64 loss: 0.2822027802467346
Batch 19/64 loss: 0.26710689067840576
Batch 20/64 loss: 0.280118465423584
Batch 21/64 loss: 0.2677266001701355
Batch 22/64 loss: 0.27756667137145996
Batch 23/64 loss: 0.27261388301849365
Batch 24/64 loss: 0.2754511833190918
Batch 25/64 loss: 0.2879139184951782
Batch 26/64 loss: 0.2733834385871887
Batch 27/64 loss: 0.27240943908691406
Batch 28/64 loss: 0.26883745193481445
Batch 29/64 loss: 0.2718835473060608
Batch 30/64 loss: 0.2756326198577881
Batch 31/64 loss: 0.2751566171646118
Batch 32/64 loss: 0.27336806058883667
Batch 33/64 loss: 0.27326518297195435
Batch 34/64 loss: 0.2913013696670532
Batch 35/64 loss: 0.282328724861145
Batch 36/64 loss: 0.27560508251190186
Batch 37/64 loss: 0.27649736404418945
Batch 38/64 loss: 0.27299076318740845
Batch 39/64 loss: 0.27785634994506836
Batch 40/64 loss: 0.26899635791778564
Batch 41/64 loss: 0.27765989303588867
Batch 42/64 loss: 0.2771497964859009
Batch 43/64 loss: 0.2769050598144531
Batch 44/64 loss: 0.2671661972999573
Batch 45/64 loss: 0.2806006669998169
Batch 46/64 loss: 0.27726954221725464
Batch 47/64 loss: 0.2681480050086975
Batch 48/64 loss: 0.2777858376502991
Batch 49/64 loss: 0.27501797676086426
Batch 50/64 loss: 0.2809431552886963
Batch 51/64 loss: 0.2764848470687866
Batch 52/64 loss: 0.27421051263809204
Batch 53/64 loss: 0.2725185751914978
Batch 54/64 loss: 0.276782751083374
Batch 55/64 loss: 0.2785242795944214
Batch 56/64 loss: 0.2871040105819702
Batch 57/64 loss: 0.2723369598388672
Batch 58/64 loss: 0.2773662805557251
Batch 59/64 loss: 0.274824321269989
Batch 60/64 loss: 0.28103357553482056
Batch 61/64 loss: 0.27911221981048584
Batch 62/64 loss: 0.27662014961242676
Batch 63/64 loss: 0.26976478099823
Batch 64/64 loss: 0.27094924449920654
Epoch 319  Train loss: 0.27544788987028834  Val loss: 0.3135065526487082
Epoch 320
-------------------------------
Batch 1/64 loss: 0.2707021236419678
Batch 2/64 loss: 0.2796170711517334
Batch 3/64 loss: 0.27444398403167725
Batch 4/64 loss: 0.27358341217041016
Batch 5/64 loss: 0.2676050662994385
Batch 6/64 loss: 0.27176403999328613
Batch 7/64 loss: 0.2789989709854126
Batch 8/64 loss: 0.2730182409286499
Batch 9/64 loss: 0.2775585651397705
Batch 10/64 loss: 0.27753859758377075
Batch 11/64 loss: 0.2772166132926941
Batch 12/64 loss: 0.2749624252319336
Batch 13/64 loss: 0.272019624710083
Batch 14/64 loss: 0.27183055877685547
Batch 15/64 loss: 0.2677547335624695
Batch 16/64 loss: 0.2775905132293701
Batch 17/64 loss: 0.2758792042732239
Batch 18/64 loss: 0.27383315563201904
Batch 19/64 loss: 0.28131937980651855
Batch 20/64 loss: 0.27688854932785034
Batch 21/64 loss: 0.27557599544525146
Batch 22/64 loss: 0.28366100788116455
Batch 23/64 loss: 0.2709604501724243
Batch 24/64 loss: 0.2696959972381592
Batch 25/64 loss: 0.27713775634765625
Batch 26/64 loss: 0.288049578666687
Batch 27/64 loss: 0.2801772356033325
Batch 28/64 loss: 0.2716042995452881
Batch 29/64 loss: 0.2756073474884033
Batch 30/64 loss: 0.27360886335372925
Batch 31/64 loss: 0.2718905210494995
Batch 32/64 loss: 0.27408939599990845
Batch 33/64 loss: 0.2735261917114258
Batch 34/64 loss: 0.2720106840133667
Batch 35/64 loss: 0.27534353733062744
Batch 36/64 loss: 0.2806708812713623
Batch 37/64 loss: 0.27610158920288086
Batch 38/64 loss: 0.28417420387268066
Batch 39/64 loss: 0.28042036294937134
Batch 40/64 loss: 0.2763150930404663
Batch 41/64 loss: 0.2783641815185547
Batch 42/64 loss: 0.28295665979385376
Batch 43/64 loss: 0.27335721254348755
Batch 44/64 loss: 0.27508115768432617
Batch 45/64 loss: 0.28384459018707275
Batch 46/64 loss: 0.270715594291687
Batch 47/64 loss: 0.27239668369293213
Batch 48/64 loss: 0.27670860290527344
Batch 49/64 loss: 0.27724117040634155
Batch 50/64 loss: 0.267269492149353
Batch 51/64 loss: 0.27142083644866943
Batch 52/64 loss: 0.27742213010787964
Batch 53/64 loss: 0.28450459241867065
Batch 54/64 loss: 0.2768656015396118
Batch 55/64 loss: 0.2725980281829834
Batch 56/64 loss: 0.26989006996154785
Batch 57/64 loss: 0.27489209175109863
Batch 58/64 loss: 0.2734614610671997
Batch 59/64 loss: 0.27116698026657104
Batch 60/64 loss: 0.28158748149871826
Batch 61/64 loss: 0.26985669136047363
Batch 62/64 loss: 0.2759290933609009
Batch 63/64 loss: 0.2713184952735901
Batch 64/64 loss: 0.28011322021484375
Epoch 320  Train loss: 0.2755087001650941  Val loss: 0.3121506368991026
Epoch 321
-------------------------------
Batch 1/64 loss: 0.27744150161743164
Batch 2/64 loss: 0.2791949510574341
Batch 3/64 loss: 0.2645530700683594
Batch 4/64 loss: 0.2790684700012207
Batch 5/64 loss: 0.2718605399131775
Batch 6/64 loss: 0.26884496212005615
Batch 7/64 loss: 0.2752223014831543
Batch 8/64 loss: 0.2778245806694031
Batch 9/64 loss: 0.27336281538009644
Batch 10/64 loss: 0.2759873867034912
Batch 11/64 loss: 0.2732800245285034
Batch 12/64 loss: 0.2805349826812744
Batch 13/64 loss: 0.2774507999420166
Batch 14/64 loss: 0.26603996753692627
Batch 15/64 loss: 0.26898425817489624
Batch 16/64 loss: 0.273465633392334
Batch 17/64 loss: 0.277695894241333
Batch 18/64 loss: 0.280582070350647
Batch 19/64 loss: 0.2736281156539917
Batch 20/64 loss: 0.28812986612319946
Batch 21/64 loss: 0.275213360786438
Batch 22/64 loss: 0.27538931369781494
Batch 23/64 loss: 0.2688533067703247
Batch 24/64 loss: 0.2711760997772217
Batch 25/64 loss: 0.27887213230133057
Batch 26/64 loss: 0.2758253216743469
Batch 27/64 loss: 0.2740969657897949
Batch 28/64 loss: 0.27662885189056396
Batch 29/64 loss: 0.2769632339477539
Batch 30/64 loss: 0.27380216121673584
Batch 31/64 loss: 0.27664220333099365
Batch 32/64 loss: 0.2817189693450928
Batch 33/64 loss: 0.2730085849761963
Batch 34/64 loss: 0.2784416675567627
Batch 35/64 loss: 0.283519983291626
Batch 36/64 loss: 0.27328038215637207
Batch 37/64 loss: 0.28354811668395996
Batch 38/64 loss: 0.27343571186065674
Batch 39/64 loss: 0.27643299102783203
Batch 40/64 loss: 0.2837138772010803
Batch 41/64 loss: 0.278545618057251
Batch 42/64 loss: 0.2705445885658264
Batch 43/64 loss: 0.2775343060493469
Batch 44/64 loss: 0.26741576194763184
Batch 45/64 loss: 0.27872204780578613
Batch 46/64 loss: 0.26964104175567627
Batch 47/64 loss: 0.27696657180786133
Batch 48/64 loss: 0.27242511510849
Batch 49/64 loss: 0.27505820989608765
Batch 50/64 loss: 0.278600811958313
Batch 51/64 loss: 0.2688584327697754
Batch 52/64 loss: 0.2751173973083496
Batch 53/64 loss: 0.2810688018798828
Batch 54/64 loss: 0.2719430923461914
Batch 55/64 loss: 0.27733826637268066
Batch 56/64 loss: 0.274152934551239
Batch 57/64 loss: 0.2775537967681885
Batch 58/64 loss: 0.27395498752593994
Batch 59/64 loss: 0.2809019088745117
Batch 60/64 loss: 0.2807741165161133
Batch 61/64 loss: 0.27535152435302734
Batch 62/64 loss: 0.2729983329772949
Batch 63/64 loss: 0.2748560309410095
Batch 64/64 loss: 0.27927863597869873
Epoch 321  Train loss: 0.27566271529478187  Val loss: 0.31234775027868267
Epoch 322
-------------------------------
Batch 1/64 loss: 0.27119922637939453
Batch 2/64 loss: 0.2758297920227051
Batch 3/64 loss: 0.27310502529144287
Batch 4/64 loss: 0.26730746030807495
Batch 5/64 loss: 0.2694736123085022
Batch 6/64 loss: 0.27076995372772217
Batch 7/64 loss: 0.2701241970062256
Batch 8/64 loss: 0.2711222171783447
Batch 9/64 loss: 0.27184534072875977
Batch 10/64 loss: 0.2777474522590637
Batch 11/64 loss: 0.2710265517234802
Batch 12/64 loss: 0.28068435192108154
Batch 13/64 loss: 0.2796117663383484
Batch 14/64 loss: 0.2785583734512329
Batch 15/64 loss: 0.27179402112960815
Batch 16/64 loss: 0.2702209949493408
Batch 17/64 loss: 0.2695542573928833
Batch 18/64 loss: 0.2703145742416382
Batch 19/64 loss: 0.27777206897735596
Batch 20/64 loss: 0.26818108558654785
Batch 21/64 loss: 0.27855122089385986
Batch 22/64 loss: 0.2746213674545288
Batch 23/64 loss: 0.2705368995666504
Batch 24/64 loss: 0.27072978019714355
Batch 25/64 loss: 0.2837156057357788
Batch 26/64 loss: 0.2707693576812744
Batch 27/64 loss: 0.2782621383666992
Batch 28/64 loss: 0.2795625925064087
Batch 29/64 loss: 0.2716313600540161
Batch 30/64 loss: 0.2762414216995239
Batch 31/64 loss: 0.2771488428115845
Batch 32/64 loss: 0.2752389907836914
Batch 33/64 loss: 0.2730712890625
Batch 34/64 loss: 0.28366219997406006
Batch 35/64 loss: 0.269919216632843
Batch 36/64 loss: 0.2730367183685303
Batch 37/64 loss: 0.27420032024383545
Batch 38/64 loss: 0.2737787961959839
Batch 39/64 loss: 0.2681601047515869
Batch 40/64 loss: 0.2805333137512207
Batch 41/64 loss: 0.2825796604156494
Batch 42/64 loss: 0.2753012776374817
Batch 43/64 loss: 0.28671205043792725
Batch 44/64 loss: 0.2715964913368225
Batch 45/64 loss: 0.2681022882461548
Batch 46/64 loss: 0.2716931104660034
Batch 47/64 loss: 0.2833724617958069
Batch 48/64 loss: 0.2723160982131958
Batch 49/64 loss: 0.275692880153656
Batch 50/64 loss: 0.27649492025375366
Batch 51/64 loss: 0.28513431549072266
Batch 52/64 loss: 0.27240633964538574
Batch 53/64 loss: 0.2752608060836792
Batch 54/64 loss: 0.27597904205322266
Batch 55/64 loss: 0.2862064242362976
Batch 56/64 loss: 0.2782898545265198
Batch 57/64 loss: 0.269104540348053
Batch 58/64 loss: 0.2757527828216553
Batch 59/64 loss: 0.2802466154098511
Batch 60/64 loss: 0.2802548408508301
Batch 61/64 loss: 0.27363163232803345
Batch 62/64 loss: 0.27294254302978516
Batch 63/64 loss: 0.2715650796890259
Batch 64/64 loss: 0.27416157722473145
Epoch 322  Train loss: 0.2749156250673182  Val loss: 0.3124438835583192
Epoch 323
-------------------------------
Batch 1/64 loss: 0.2728276252746582
Batch 2/64 loss: 0.270361065864563
Batch 3/64 loss: 0.27813589572906494
Batch 4/64 loss: 0.27444738149642944
Batch 5/64 loss: 0.2736341953277588
Batch 6/64 loss: 0.2730411887168884
Batch 7/64 loss: 0.2754039168357849
Batch 8/64 loss: 0.26848161220550537
Batch 9/64 loss: 0.2796984910964966
Batch 10/64 loss: 0.27110087871551514
Batch 11/64 loss: 0.27889108657836914
Batch 12/64 loss: 0.2746957540512085
Batch 13/64 loss: 0.27467870712280273
Batch 14/64 loss: 0.2719044089317322
Batch 15/64 loss: 0.27936089038848877
Batch 16/64 loss: 0.279974102973938
Batch 17/64 loss: 0.2696923017501831
Batch 18/64 loss: 0.27449285984039307
Batch 19/64 loss: 0.27474522590637207
Batch 20/64 loss: 0.2681475877761841
Batch 21/64 loss: 0.2769259214401245
Batch 22/64 loss: 0.2744525671005249
Batch 23/64 loss: 0.27947819232940674
Batch 24/64 loss: 0.2718465328216553
Batch 25/64 loss: 0.2722465395927429
Batch 26/64 loss: 0.2774782180786133
Batch 27/64 loss: 0.26840728521347046
Batch 28/64 loss: 0.2754232883453369
Batch 29/64 loss: 0.2734389901161194
Batch 30/64 loss: 0.27607977390289307
Batch 31/64 loss: 0.27696919441223145
Batch 32/64 loss: 0.2742260694503784
Batch 33/64 loss: 0.27442336082458496
Batch 34/64 loss: 0.2752835750579834
Batch 35/64 loss: 0.27677983045578003
Batch 36/64 loss: 0.27681106328964233
Batch 37/64 loss: 0.2765999436378479
Batch 38/64 loss: 0.2693585157394409
Batch 39/64 loss: 0.27468740940093994
Batch 40/64 loss: 0.28270721435546875
Batch 41/64 loss: 0.27413249015808105
Batch 42/64 loss: 0.26990175247192383
Batch 43/64 loss: 0.27233266830444336
Batch 44/64 loss: 0.27255022525787354
Batch 45/64 loss: 0.2765083312988281
Batch 46/64 loss: 0.2795493006706238
Batch 47/64 loss: 0.2745840549468994
Batch 48/64 loss: 0.2738249897956848
Batch 49/64 loss: 0.2775493860244751
Batch 50/64 loss: 0.2707154154777527
Batch 51/64 loss: 0.28198885917663574
Batch 52/64 loss: 0.27584517002105713
Batch 53/64 loss: 0.27108144760131836
Batch 54/64 loss: 0.2859742045402527
Batch 55/64 loss: 0.279419481754303
Batch 56/64 loss: 0.279580295085907
Batch 57/64 loss: 0.27756035327911377
Batch 58/64 loss: 0.2706897258758545
Batch 59/64 loss: 0.28056609630584717
Batch 60/64 loss: 0.28404200077056885
Batch 61/64 loss: 0.2770534157752991
Batch 62/64 loss: 0.2730252742767334
Batch 63/64 loss: 0.27052003145217896
Batch 64/64 loss: 0.28436577320098877
Epoch 323  Train loss: 0.2752879680371752  Val loss: 0.31242434306652683
Epoch 324
-------------------------------
Batch 1/64 loss: 0.27323371171951294
Batch 2/64 loss: 0.2731701135635376
Batch 3/64 loss: 0.278617262840271
Batch 4/64 loss: 0.27350831031799316
Batch 5/64 loss: 0.2839066982269287
Batch 6/64 loss: 0.2743762731552124
Batch 7/64 loss: 0.275740385055542
Batch 8/64 loss: 0.2836505174636841
Batch 9/64 loss: 0.27517247200012207
Batch 10/64 loss: 0.2793956995010376
Batch 11/64 loss: 0.27551424503326416
Batch 12/64 loss: 0.27827250957489014
Batch 13/64 loss: 0.2733731269836426
Batch 14/64 loss: 0.26941144466400146
Batch 15/64 loss: 0.273928165435791
Batch 16/64 loss: 0.27550941705703735
Batch 17/64 loss: 0.2773841619491577
Batch 18/64 loss: 0.2738224267959595
Batch 19/64 loss: 0.27403151988983154
Batch 20/64 loss: 0.2781226634979248
Batch 21/64 loss: 0.2800648808479309
Batch 22/64 loss: 0.27203476428985596
Batch 23/64 loss: 0.27596044540405273
Batch 24/64 loss: 0.28136515617370605
Batch 25/64 loss: 0.27814531326293945
Batch 26/64 loss: 0.2697824239730835
Batch 27/64 loss: 0.27948588132858276
Batch 28/64 loss: 0.27373337745666504
Batch 29/64 loss: 0.2749859094619751
Batch 30/64 loss: 0.27684521675109863
Batch 31/64 loss: 0.2727982997894287
Batch 32/64 loss: 0.2783393859863281
Batch 33/64 loss: 0.271584689617157
Batch 34/64 loss: 0.26651930809020996
Batch 35/64 loss: 0.2733396291732788
Batch 36/64 loss: 0.27337777614593506
Batch 37/64 loss: 0.2757605314254761
Batch 38/64 loss: 0.26525938510894775
Batch 39/64 loss: 0.2668784260749817
Batch 40/64 loss: 0.2804853320121765
Batch 41/64 loss: 0.27357494831085205
Batch 42/64 loss: 0.2729611396789551
Batch 43/64 loss: 0.2911224365234375
Batch 44/64 loss: 0.2720586061477661
Batch 45/64 loss: 0.26790642738342285
Batch 46/64 loss: 0.26683831214904785
Batch 47/64 loss: 0.27938419580459595
Batch 48/64 loss: 0.2702680826187134
Batch 49/64 loss: 0.2659873366355896
Batch 50/64 loss: 0.27649831771850586
Batch 51/64 loss: 0.2720683813095093
Batch 52/64 loss: 0.27524662017822266
Batch 53/64 loss: 0.27014678716659546
Batch 54/64 loss: 0.27511489391326904
Batch 55/64 loss: 0.2744241952896118
Batch 56/64 loss: 0.27866506576538086
Batch 57/64 loss: 0.27604448795318604
Batch 58/64 loss: 0.2772550582885742
Batch 59/64 loss: 0.27788615226745605
Batch 60/64 loss: 0.28085434436798096
Batch 61/64 loss: 0.2755693197250366
Batch 62/64 loss: 0.2712975740432739
Batch 63/64 loss: 0.27753937244415283
Batch 64/64 loss: 0.275272011756897
Epoch 324  Train loss: 0.27501260112313664  Val loss: 0.3133338489073658
Epoch 325
-------------------------------
Batch 1/64 loss: 0.2786247134208679
Batch 2/64 loss: 0.27290183305740356
Batch 3/64 loss: 0.277490496635437
Batch 4/64 loss: 0.2725785970687866
Batch 5/64 loss: 0.2785438299179077
Batch 6/64 loss: 0.280478835105896
Batch 7/64 loss: 0.26796525716781616
Batch 8/64 loss: 0.26991772651672363
Batch 9/64 loss: 0.2771463990211487
Batch 10/64 loss: 0.2756471633911133
Batch 11/64 loss: 0.2814849615097046
Batch 12/64 loss: 0.27143120765686035
Batch 13/64 loss: 0.2776472568511963
Batch 14/64 loss: 0.27952009439468384
Batch 15/64 loss: 0.2701874375343323
Batch 16/64 loss: 0.27336424589157104
Batch 17/64 loss: 0.2740182876586914
Batch 18/64 loss: 0.2800827622413635
Batch 19/64 loss: 0.2731165289878845
Batch 20/64 loss: 0.26669442653656006
Batch 21/64 loss: 0.2742474675178528
Batch 22/64 loss: 0.27665823698043823
Batch 23/64 loss: 0.2674752473831177
Batch 24/64 loss: 0.2738776206970215
Batch 25/64 loss: 0.2725411653518677
Batch 26/64 loss: 0.2758094072341919
Batch 27/64 loss: 0.27420222759246826
Batch 28/64 loss: 0.26993799209594727
Batch 29/64 loss: 0.2703566551208496
Batch 30/64 loss: 0.2777496576309204
Batch 31/64 loss: 0.2661963701248169
Batch 32/64 loss: 0.27070629596710205
Batch 33/64 loss: 0.28389739990234375
Batch 34/64 loss: 0.27313196659088135
Batch 35/64 loss: 0.27484363317489624
Batch 36/64 loss: 0.2791280746459961
Batch 37/64 loss: 0.27590513229370117
Batch 38/64 loss: 0.2762065529823303
Batch 39/64 loss: 0.26727867126464844
Batch 40/64 loss: 0.2778306007385254
Batch 41/64 loss: 0.2860804796218872
Batch 42/64 loss: 0.2762174606323242
Batch 43/64 loss: 0.2796425223350525
Batch 44/64 loss: 0.2789340019226074
Batch 45/64 loss: 0.27650535106658936
Batch 46/64 loss: 0.27372103929519653
Batch 47/64 loss: 0.27085959911346436
Batch 48/64 loss: 0.27329790592193604
Batch 49/64 loss: 0.27229249477386475
Batch 50/64 loss: 0.283544659614563
Batch 51/64 loss: 0.27446454763412476
Batch 52/64 loss: 0.2815013527870178
Batch 53/64 loss: 0.27054649591445923
Batch 54/64 loss: 0.2732120752334595
Batch 55/64 loss: 0.2781692147254944
Batch 56/64 loss: 0.2801738381385803
Batch 57/64 loss: 0.2846773862838745
Batch 58/64 loss: 0.27289438247680664
Batch 59/64 loss: 0.27424514293670654
Batch 60/64 loss: 0.27430057525634766
Batch 61/64 loss: 0.27178138494491577
Batch 62/64 loss: 0.27596306800842285
Batch 63/64 loss: 0.275496244430542
Batch 64/64 loss: 0.2762106657028198
Epoch 325  Train loss: 0.27517649659923477  Val loss: 0.31234953247804415
Epoch 326
-------------------------------
Batch 1/64 loss: 0.27284497022628784
Batch 2/64 loss: 0.27575141191482544
Batch 3/64 loss: 0.2804166078567505
Batch 4/64 loss: 0.2777978181838989
Batch 5/64 loss: 0.28361886739730835
Batch 6/64 loss: 0.276086688041687
Batch 7/64 loss: 0.2730712294578552
Batch 8/64 loss: 0.2732771039009094
Batch 9/64 loss: 0.2730148434638977
Batch 10/64 loss: 0.26809489727020264
Batch 11/64 loss: 0.26240062713623047
Batch 12/64 loss: 0.2783397436141968
Batch 13/64 loss: 0.2713760733604431
Batch 14/64 loss: 0.2784597873687744
Batch 15/64 loss: 0.2749674320220947
Batch 16/64 loss: 0.27300214767456055
Batch 17/64 loss: 0.27595019340515137
Batch 18/64 loss: 0.27845603227615356
Batch 19/64 loss: 0.2742695212364197
Batch 20/64 loss: 0.27002596855163574
Batch 21/64 loss: 0.26937639713287354
Batch 22/64 loss: 0.2719604969024658
Batch 23/64 loss: 0.27256226539611816
Batch 24/64 loss: 0.27444565296173096
Batch 25/64 loss: 0.2674541473388672
Batch 26/64 loss: 0.2679252624511719
Batch 27/64 loss: 0.27385658025741577
Batch 28/64 loss: 0.2733098864555359
Batch 29/64 loss: 0.2750203609466553
Batch 30/64 loss: 0.27205371856689453
Batch 31/64 loss: 0.27418816089630127
Batch 32/64 loss: 0.27068811655044556
Batch 33/64 loss: 0.27397364377975464
Batch 34/64 loss: 0.28076058626174927
Batch 35/64 loss: 0.273796021938324
Batch 36/64 loss: 0.27570080757141113
Batch 37/64 loss: 0.2749204635620117
Batch 38/64 loss: 0.28483378887176514
Batch 39/64 loss: 0.2764238119125366
Batch 40/64 loss: 0.2745492458343506
Batch 41/64 loss: 0.27195310592651367
Batch 42/64 loss: 0.2751026153564453
Batch 43/64 loss: 0.2794492840766907
Batch 44/64 loss: 0.2799462080001831
Batch 45/64 loss: 0.2769191265106201
Batch 46/64 loss: 0.27363651990890503
Batch 47/64 loss: 0.27894091606140137
Batch 48/64 loss: 0.27449268102645874
Batch 49/64 loss: 0.28070902824401855
Batch 50/64 loss: 0.28575241565704346
Batch 51/64 loss: 0.2738654613494873
Batch 52/64 loss: 0.2713167071342468
Batch 53/64 loss: 0.27757126092910767
Batch 54/64 loss: 0.27164602279663086
Batch 55/64 loss: 0.27575916051864624
Batch 56/64 loss: 0.2738526463508606
Batch 57/64 loss: 0.2743556499481201
Batch 58/64 loss: 0.27773183584213257
Batch 59/64 loss: 0.2720813751220703
Batch 60/64 loss: 0.27612829208374023
Batch 61/64 loss: 0.27935147285461426
Batch 62/64 loss: 0.2709822654724121
Batch 63/64 loss: 0.28259068727493286
Batch 64/64 loss: 0.2876356244087219
Epoch 326  Train loss: 0.27511973077175667  Val loss: 0.3134371007431004
Epoch 327
-------------------------------
Batch 1/64 loss: 0.2779616117477417
Batch 2/64 loss: 0.2801342010498047
Batch 3/64 loss: 0.2811793088912964
Batch 4/64 loss: 0.2714235782623291
Batch 5/64 loss: 0.2804757356643677
Batch 6/64 loss: 0.270221471786499
Batch 7/64 loss: 0.2800546884536743
Batch 8/64 loss: 0.27228522300720215
Batch 9/64 loss: 0.27613747119903564
Batch 10/64 loss: 0.2773975133895874
Batch 11/64 loss: 0.27979910373687744
Batch 12/64 loss: 0.27054738998413086
Batch 13/64 loss: 0.2721273899078369
Batch 14/64 loss: 0.2866746187210083
Batch 15/64 loss: 0.2714771032333374
Batch 16/64 loss: 0.26975297927856445
Batch 17/64 loss: 0.2713981866836548
Batch 18/64 loss: 0.2737230658531189
Batch 19/64 loss: 0.27683496475219727
Batch 20/64 loss: 0.27164220809936523
Batch 21/64 loss: 0.26776832342147827
Batch 22/64 loss: 0.28988295793533325
Batch 23/64 loss: 0.2763773202896118
Batch 24/64 loss: 0.2686448097229004
Batch 25/64 loss: 0.2748185992240906
Batch 26/64 loss: 0.27654922008514404
Batch 27/64 loss: 0.2775137424468994
Batch 28/64 loss: 0.2715265154838562
Batch 29/64 loss: 0.2777811288833618
Batch 30/64 loss: 0.28493034839630127
Batch 31/64 loss: 0.27482426166534424
Batch 32/64 loss: 0.2679089903831482
Batch 33/64 loss: 0.27548253536224365
Batch 34/64 loss: 0.2769578695297241
Batch 35/64 loss: 0.26902830600738525
Batch 36/64 loss: 0.2779073715209961
Batch 37/64 loss: 0.26866281032562256
Batch 38/64 loss: 0.28320014476776123
Batch 39/64 loss: 0.27283990383148193
Batch 40/64 loss: 0.27245253324508667
Batch 41/64 loss: 0.2814171314239502
Batch 42/64 loss: 0.27356600761413574
Batch 43/64 loss: 0.2769709825515747
Batch 44/64 loss: 0.2696237564086914
Batch 45/64 loss: 0.28391456604003906
Batch 46/64 loss: 0.27246999740600586
Batch 47/64 loss: 0.2713075876235962
Batch 48/64 loss: 0.2760515809059143
Batch 49/64 loss: 0.27395474910736084
Batch 50/64 loss: 0.27509260177612305
Batch 51/64 loss: 0.2707785964012146
Batch 52/64 loss: 0.2756408452987671
Batch 53/64 loss: 0.2771613597869873
Batch 54/64 loss: 0.27599096298217773
Batch 55/64 loss: 0.272247314453125
Batch 56/64 loss: 0.26746559143066406
Batch 57/64 loss: 0.27249008417129517
Batch 58/64 loss: 0.27612602710723877
Batch 59/64 loss: 0.2719513177871704
Batch 60/64 loss: 0.2744259834289551
Batch 61/64 loss: 0.27745485305786133
Batch 62/64 loss: 0.27846401929855347
Batch 63/64 loss: 0.27624332904815674
Batch 64/64 loss: 0.2811391353607178
Epoch 327  Train loss: 0.27526226043701174  Val loss: 0.312690463262735
Epoch 328
-------------------------------
Batch 1/64 loss: 0.2775866985321045
Batch 2/64 loss: 0.2827262878417969
Batch 3/64 loss: 0.2732044458389282
Batch 4/64 loss: 0.2702345848083496
Batch 5/64 loss: 0.27147507667541504
Batch 6/64 loss: 0.2748408317565918
Batch 7/64 loss: 0.2770795226097107
Batch 8/64 loss: 0.2796269655227661
Batch 9/64 loss: 0.276830792427063
Batch 10/64 loss: 0.2711977958679199
Batch 11/64 loss: 0.2696816921234131
Batch 12/64 loss: 0.27189791202545166
Batch 13/64 loss: 0.2694551944732666
Batch 14/64 loss: 0.272429883480072
Batch 15/64 loss: 0.2688456177711487
Batch 16/64 loss: 0.2780721187591553
Batch 17/64 loss: 0.2706908583641052
Batch 18/64 loss: 0.2770121693611145
Batch 19/64 loss: 0.2814443111419678
Batch 20/64 loss: 0.2722242474555969
Batch 21/64 loss: 0.2674188017845154
Batch 22/64 loss: 0.27621883153915405
Batch 23/64 loss: 0.27788448333740234
Batch 24/64 loss: 0.2801170349121094
Batch 25/64 loss: 0.27054649591445923
Batch 26/64 loss: 0.27027779817581177
Batch 27/64 loss: 0.2723191976547241
Batch 28/64 loss: 0.26725953817367554
Batch 29/64 loss: 0.2757088541984558
Batch 30/64 loss: 0.27310889959335327
Batch 31/64 loss: 0.26650261878967285
Batch 32/64 loss: 0.27734148502349854
Batch 33/64 loss: 0.2708285450935364
Batch 34/64 loss: 0.27309560775756836
Batch 35/64 loss: 0.28146445751190186
Batch 36/64 loss: 0.26582884788513184
Batch 37/64 loss: 0.26785778999328613
Batch 38/64 loss: 0.27675819396972656
Batch 39/64 loss: 0.2775614261627197
Batch 40/64 loss: 0.2771949768066406
Batch 41/64 loss: 0.2703518867492676
Batch 42/64 loss: 0.27546846866607666
Batch 43/64 loss: 0.28120529651641846
Batch 44/64 loss: 0.26761960983276367
Batch 45/64 loss: 0.26532381772994995
Batch 46/64 loss: 0.2795661687850952
Batch 47/64 loss: 0.26573026180267334
Batch 48/64 loss: 0.28835558891296387
Batch 49/64 loss: 0.2799872159957886
Batch 50/64 loss: 0.27552473545074463
Batch 51/64 loss: 0.27168166637420654
Batch 52/64 loss: 0.2834692597389221
Batch 53/64 loss: 0.2722761631011963
Batch 54/64 loss: 0.27303141355514526
Batch 55/64 loss: 0.2817484140396118
Batch 56/64 loss: 0.2781299352645874
Batch 57/64 loss: 0.2707977890968323
Batch 58/64 loss: 0.2799232602119446
Batch 59/64 loss: 0.2710888981819153
Batch 60/64 loss: 0.2693396210670471
Batch 61/64 loss: 0.27971577644348145
Batch 62/64 loss: 0.2703295946121216
Batch 63/64 loss: 0.2704355716705322
Batch 64/64 loss: 0.2759520411491394
Epoch 328  Train loss: 0.27419475036508895  Val loss: 0.31302705868003294
Epoch 329
-------------------------------
Batch 1/64 loss: 0.2697799801826477
Batch 2/64 loss: 0.27667635679244995
Batch 3/64 loss: 0.2773855924606323
Batch 4/64 loss: 0.27323925495147705
Batch 5/64 loss: 0.27580761909484863
Batch 6/64 loss: 0.2767554521560669
Batch 7/64 loss: 0.27187955379486084
Batch 8/64 loss: 0.27581143379211426
Batch 9/64 loss: 0.27875661849975586
Batch 10/64 loss: 0.27044677734375
Batch 11/64 loss: 0.2783632278442383
Batch 12/64 loss: 0.2714194655418396
Batch 13/64 loss: 0.28400468826293945
Batch 14/64 loss: 0.2755976915359497
Batch 15/64 loss: 0.26668286323547363
Batch 16/64 loss: 0.2749008536338806
Batch 17/64 loss: 0.27407366037368774
Batch 18/64 loss: 0.2780345678329468
Batch 19/64 loss: 0.2819950580596924
Batch 20/64 loss: 0.2657277584075928
Batch 21/64 loss: 0.2713243365287781
Batch 22/64 loss: 0.2746380567550659
Batch 23/64 loss: 0.2676970958709717
Batch 24/64 loss: 0.2781263589859009
Batch 25/64 loss: 0.2803916931152344
Batch 26/64 loss: 0.2759668827056885
Batch 27/64 loss: 0.27249735593795776
Batch 28/64 loss: 0.2780417203903198
Batch 29/64 loss: 0.27658355236053467
Batch 30/64 loss: 0.2755519151687622
Batch 31/64 loss: 0.27386629581451416
Batch 32/64 loss: 0.27578485012054443
Batch 33/64 loss: 0.2824743986129761
Batch 34/64 loss: 0.27046436071395874
Batch 35/64 loss: 0.2773284912109375
Batch 36/64 loss: 0.27386510372161865
Batch 37/64 loss: 0.27216804027557373
Batch 38/64 loss: 0.2729855179786682
Batch 39/64 loss: 0.2724642753601074
Batch 40/64 loss: 0.27566492557525635
Batch 41/64 loss: 0.2763078212738037
Batch 42/64 loss: 0.26484227180480957
Batch 43/64 loss: 0.2779930830001831
Batch 44/64 loss: 0.280738890171051
Batch 45/64 loss: 0.28136688470840454
Batch 46/64 loss: 0.2723691463470459
Batch 47/64 loss: 0.27275049686431885
Batch 48/64 loss: 0.2748265266418457
Batch 49/64 loss: 0.2772294878959656
Batch 50/64 loss: 0.27567899227142334
Batch 51/64 loss: 0.28866350650787354
Batch 52/64 loss: 0.27298688888549805
Batch 53/64 loss: 0.27336806058883667
Batch 54/64 loss: 0.2748643755912781
Batch 55/64 loss: 0.2707700729370117
Batch 56/64 loss: 0.27513056993484497
Batch 57/64 loss: 0.2739957571029663
Batch 58/64 loss: 0.2790858745574951
Batch 59/64 loss: 0.2758585214614868
Batch 60/64 loss: 0.27401411533355713
Batch 61/64 loss: 0.26636290550231934
Batch 62/64 loss: 0.2715243101119995
Batch 63/64 loss: 0.2746899127960205
Batch 64/64 loss: 0.27946311235427856
Epoch 329  Train loss: 0.27498414913813274  Val loss: 0.31324090806069654
Epoch 330
-------------------------------
Batch 1/64 loss: 0.27072328329086304
Batch 2/64 loss: 0.27245116233825684
Batch 3/64 loss: 0.27166903018951416
Batch 4/64 loss: 0.27247458696365356
Batch 5/64 loss: 0.27963030338287354
Batch 6/64 loss: 0.27630794048309326
Batch 7/64 loss: 0.2775070071220398
Batch 8/64 loss: 0.2681596279144287
Batch 9/64 loss: 0.28952956199645996
Batch 10/64 loss: 0.27874600887298584
Batch 11/64 loss: 0.2768077850341797
Batch 12/64 loss: 0.2809177041053772
Batch 13/64 loss: 0.27043914794921875
Batch 14/64 loss: 0.2777857780456543
Batch 15/64 loss: 0.27587807178497314
Batch 16/64 loss: 0.27811646461486816
Batch 17/64 loss: 0.26900196075439453
Batch 18/64 loss: 0.27021950483322144
Batch 19/64 loss: 0.27650558948516846
Batch 20/64 loss: 0.2767636179924011
Batch 21/64 loss: 0.2715963125228882
Batch 22/64 loss: 0.2876427173614502
Batch 23/64 loss: 0.2669244408607483
Batch 24/64 loss: 0.2770124673843384
Batch 25/64 loss: 0.2820169925689697
Batch 26/64 loss: 0.27158665657043457
Batch 27/64 loss: 0.2715632915496826
Batch 28/64 loss: 0.27332937717437744
Batch 29/64 loss: 0.26910245418548584
Batch 30/64 loss: 0.2727653980255127
Batch 31/64 loss: 0.2787347435951233
Batch 32/64 loss: 0.2729872465133667
Batch 33/64 loss: 0.26706522703170776
Batch 34/64 loss: 0.2742310166358948
Batch 35/64 loss: 0.2712109088897705
Batch 36/64 loss: 0.2742788791656494
Batch 37/64 loss: 0.2704433798789978
Batch 38/64 loss: 0.2726230025291443
Batch 39/64 loss: 0.2827540636062622
Batch 40/64 loss: 0.2821396589279175
Batch 41/64 loss: 0.2757127285003662
Batch 42/64 loss: 0.2699723243713379
Batch 43/64 loss: 0.2704685926437378
Batch 44/64 loss: 0.2705764174461365
Batch 45/64 loss: 0.2782388925552368
Batch 46/64 loss: 0.2717565894126892
Batch 47/64 loss: 0.27676618099212646
Batch 48/64 loss: 0.2775108814239502
Batch 49/64 loss: 0.27966123819351196
Batch 50/64 loss: 0.2795006036758423
Batch 51/64 loss: 0.2680519223213196
Batch 52/64 loss: 0.27280640602111816
Batch 53/64 loss: 0.27493011951446533
Batch 54/64 loss: 0.28048014640808105
Batch 55/64 loss: 0.27456414699554443
Batch 56/64 loss: 0.2723710536956787
Batch 57/64 loss: 0.2746123671531677
Batch 58/64 loss: 0.26951920986175537
Batch 59/64 loss: 0.27021825313568115
Batch 60/64 loss: 0.26549845933914185
Batch 61/64 loss: 0.2673143744468689
Batch 62/64 loss: 0.27837181091308594
Batch 63/64 loss: 0.2710978388786316
Batch 64/64 loss: 0.28641432523727417
Epoch 330  Train loss: 0.2745796654738632  Val loss: 0.31207669027072865
Epoch 331
-------------------------------
Batch 1/64 loss: 0.2763005495071411
Batch 2/64 loss: 0.2726452946662903
Batch 3/64 loss: 0.27321571111679077
Batch 4/64 loss: 0.27870500087738037
Batch 5/64 loss: 0.2771413326263428
Batch 6/64 loss: 0.27036482095718384
Batch 7/64 loss: 0.2763173580169678
Batch 8/64 loss: 0.27151191234588623
Batch 9/64 loss: 0.2666704058647156
Batch 10/64 loss: 0.27300310134887695
Batch 11/64 loss: 0.27151358127593994
Batch 12/64 loss: 0.26731061935424805
Batch 13/64 loss: 0.27421700954437256
Batch 14/64 loss: 0.27312779426574707
Batch 15/64 loss: 0.27247756719589233
Batch 16/64 loss: 0.27431172132492065
Batch 17/64 loss: 0.27134156227111816
Batch 18/64 loss: 0.27380478382110596
Batch 19/64 loss: 0.27824777364730835
Batch 20/64 loss: 0.2704583406448364
Batch 21/64 loss: 0.27436792850494385
Batch 22/64 loss: 0.26917338371276855
Batch 23/64 loss: 0.27512097358703613
Batch 24/64 loss: 0.2659701108932495
Batch 25/64 loss: 0.27434241771698
Batch 26/64 loss: 0.2670656442642212
Batch 27/64 loss: 0.2796960473060608
Batch 28/64 loss: 0.27365994453430176
Batch 29/64 loss: 0.27227216958999634
Batch 30/64 loss: 0.2860223054885864
Batch 31/64 loss: 0.27937883138656616
Batch 32/64 loss: 0.27425938844680786
Batch 33/64 loss: 0.2765389680862427
Batch 34/64 loss: 0.2722793221473694
Batch 35/64 loss: 0.27176761627197266
Batch 36/64 loss: 0.27289772033691406
Batch 37/64 loss: 0.27776038646698
Batch 38/64 loss: 0.2768048048019409
Batch 39/64 loss: 0.27573662996292114
Batch 40/64 loss: 0.2673525810241699
Batch 41/64 loss: 0.26271188259124756
Batch 42/64 loss: 0.26871395111083984
Batch 43/64 loss: 0.276597797870636
Batch 44/64 loss: 0.27848362922668457
Batch 45/64 loss: 0.2713005542755127
Batch 46/64 loss: 0.28203582763671875
Batch 47/64 loss: 0.2745130658149719
Batch 48/64 loss: 0.27438247203826904
Batch 49/64 loss: 0.27055734395980835
Batch 50/64 loss: 0.274619996547699
Batch 51/64 loss: 0.27908802032470703
Batch 52/64 loss: 0.2800881862640381
Batch 53/64 loss: 0.27515673637390137
Batch 54/64 loss: 0.2745856046676636
Batch 55/64 loss: 0.2797694802284241
Batch 56/64 loss: 0.269706130027771
Batch 57/64 loss: 0.2767406702041626
Batch 58/64 loss: 0.27422088384628296
Batch 59/64 loss: 0.2740354537963867
Batch 60/64 loss: 0.26867860555648804
Batch 61/64 loss: 0.27702784538269043
Batch 62/64 loss: 0.27719682455062866
Batch 63/64 loss: 0.2668624520301819
Batch 64/64 loss: 0.27630025148391724
Epoch 331  Train loss: 0.27387375714732154  Val loss: 0.3132185440292883
Epoch 332
-------------------------------
Batch 1/64 loss: 0.2735804319381714
Batch 2/64 loss: 0.27020263671875
Batch 3/64 loss: 0.27170705795288086
Batch 4/64 loss: 0.26661938428878784
Batch 5/64 loss: 0.27229392528533936
Batch 6/64 loss: 0.27628153562545776
Batch 7/64 loss: 0.2770273685455322
Batch 8/64 loss: 0.2772427797317505
Batch 9/64 loss: 0.27531707286834717
Batch 10/64 loss: 0.26987195014953613
Batch 11/64 loss: 0.27195096015930176
Batch 12/64 loss: 0.2762160897254944
Batch 13/64 loss: 0.27293574810028076
Batch 14/64 loss: 0.2763732671737671
Batch 15/64 loss: 0.26856184005737305
Batch 16/64 loss: 0.2697584629058838
Batch 17/64 loss: 0.2681680917739868
Batch 18/64 loss: 0.2731415033340454
Batch 19/64 loss: 0.2818520665168762
Batch 20/64 loss: 0.2758439779281616
Batch 21/64 loss: 0.27087539434432983
Batch 22/64 loss: 0.273557186126709
Batch 23/64 loss: 0.26760852336883545
Batch 24/64 loss: 0.27637410163879395
Batch 25/64 loss: 0.2758110761642456
Batch 26/64 loss: 0.27412861585617065
Batch 27/64 loss: 0.2694537043571472
Batch 28/64 loss: 0.2721462845802307
Batch 29/64 loss: 0.2720705270767212
Batch 30/64 loss: 0.2752452492713928
Batch 31/64 loss: 0.27699029445648193
Batch 32/64 loss: 0.2702711224555969
Batch 33/64 loss: 0.26847565174102783
Batch 34/64 loss: 0.2725008726119995
Batch 35/64 loss: 0.27357208728790283
Batch 36/64 loss: 0.27318787574768066
Batch 37/64 loss: 0.27828288078308105
Batch 38/64 loss: 0.2734636068344116
Batch 39/64 loss: 0.2712462544441223
Batch 40/64 loss: 0.272092342376709
Batch 41/64 loss: 0.2755270004272461
Batch 42/64 loss: 0.27496814727783203
Batch 43/64 loss: 0.2678241729736328
Batch 44/64 loss: 0.2732512950897217
Batch 45/64 loss: 0.271176278591156
Batch 46/64 loss: 0.2791300415992737
Batch 47/64 loss: 0.2766644358634949
Batch 48/64 loss: 0.26961445808410645
Batch 49/64 loss: 0.2907365560531616
Batch 50/64 loss: 0.2722741365432739
Batch 51/64 loss: 0.2781679034233093
Batch 52/64 loss: 0.27967607975006104
Batch 53/64 loss: 0.27884382009506226
Batch 54/64 loss: 0.2776247262954712
Batch 55/64 loss: 0.2846434712409973
Batch 56/64 loss: 0.27852678298950195
Batch 57/64 loss: 0.27794957160949707
Batch 58/64 loss: 0.27245283126831055
Batch 59/64 loss: 0.28254175186157227
Batch 60/64 loss: 0.2771114110946655
Batch 61/64 loss: 0.27608317136764526
Batch 62/64 loss: 0.2742900848388672
Batch 63/64 loss: 0.27751266956329346
Batch 64/64 loss: 0.26949095726013184
Epoch 332  Train loss: 0.27436876577489516  Val loss: 0.3119149105655369
Epoch 333
-------------------------------
Batch 1/64 loss: 0.27635204792022705
Batch 2/64 loss: 0.2747539281845093
Batch 3/64 loss: 0.2766304016113281
Batch 4/64 loss: 0.2779611349105835
Batch 5/64 loss: 0.2769637107849121
Batch 6/64 loss: 0.2707632780075073
Batch 7/64 loss: 0.266853928565979
Batch 8/64 loss: 0.27416104078292847
Batch 9/64 loss: 0.2673954963684082
Batch 10/64 loss: 0.27493447065353394
Batch 11/64 loss: 0.26736414432525635
Batch 12/64 loss: 0.266373872756958
Batch 13/64 loss: 0.2725914716720581
Batch 14/64 loss: 0.27185988426208496
Batch 15/64 loss: 0.2681637406349182
Batch 16/64 loss: 0.2657085657119751
Batch 17/64 loss: 0.2683957815170288
Batch 18/64 loss: 0.2696308493614197
Batch 19/64 loss: 0.2751044034957886
Batch 20/64 loss: 0.2661440968513489
Batch 21/64 loss: 0.27258962392807007
Batch 22/64 loss: 0.2694413661956787
Batch 23/64 loss: 0.276231586933136
Batch 24/64 loss: 0.28128254413604736
Batch 25/64 loss: 0.2751731872558594
Batch 26/64 loss: 0.2764686346054077
Batch 27/64 loss: 0.27850979566574097
Batch 28/64 loss: 0.2684937119483948
Batch 29/64 loss: 0.27628999948501587
Batch 30/64 loss: 0.26575398445129395
Batch 31/64 loss: 0.2724387049674988
Batch 32/64 loss: 0.27478909492492676
Batch 33/64 loss: 0.2741363048553467
Batch 34/64 loss: 0.2714698314666748
Batch 35/64 loss: 0.26602137088775635
Batch 36/64 loss: 0.27259141206741333
Batch 37/64 loss: 0.2766856551170349
Batch 38/64 loss: 0.2674243450164795
Batch 39/64 loss: 0.28205281496047974
Batch 40/64 loss: 0.2757158875465393
Batch 41/64 loss: 0.27124571800231934
Batch 42/64 loss: 0.27323341369628906
Batch 43/64 loss: 0.2753850221633911
Batch 44/64 loss: 0.2729964256286621
Batch 45/64 loss: 0.27245545387268066
Batch 46/64 loss: 0.2779656648635864
Batch 47/64 loss: 0.2714853286743164
Batch 48/64 loss: 0.2784532904624939
Batch 49/64 loss: 0.27560698986053467
Batch 50/64 loss: 0.2816748023033142
Batch 51/64 loss: 0.2755424976348877
Batch 52/64 loss: 0.27125394344329834
Batch 53/64 loss: 0.2679039239883423
Batch 54/64 loss: 0.28349483013153076
Batch 55/64 loss: 0.27633070945739746
Batch 56/64 loss: 0.27899032831192017
Batch 57/64 loss: 0.2772068977355957
Batch 58/64 loss: 0.27691376209259033
Batch 59/64 loss: 0.2702864408493042
Batch 60/64 loss: 0.27632635831832886
Batch 61/64 loss: 0.2767890691757202
Batch 62/64 loss: 0.27032262086868286
Batch 63/64 loss: 0.2816757559776306
Batch 64/64 loss: 0.2764577865600586
Epoch 333  Train loss: 0.2736086069368849  Val loss: 0.3127674462459341
Epoch 334
-------------------------------
Batch 1/64 loss: 0.2640969753265381
Batch 2/64 loss: 0.2716507911682129
Batch 3/64 loss: 0.27131688594818115
Batch 4/64 loss: 0.2743569612503052
Batch 5/64 loss: 0.26779937744140625
Batch 6/64 loss: 0.26964420080184937
Batch 7/64 loss: 0.2725467085838318
Batch 8/64 loss: 0.275363564491272
Batch 9/64 loss: 0.2779473066329956
Batch 10/64 loss: 0.2805739641189575
Batch 11/64 loss: 0.27571988105773926
Batch 12/64 loss: 0.27139031887054443
Batch 13/64 loss: 0.2722415328025818
Batch 14/64 loss: 0.2747765779495239
Batch 15/64 loss: 0.2735406160354614
Batch 16/64 loss: 0.2712705731391907
Batch 17/64 loss: 0.28847646713256836
Batch 18/64 loss: 0.2795630693435669
Batch 19/64 loss: 0.26756739616394043
Batch 20/64 loss: 0.26592159271240234
Batch 21/64 loss: 0.2760152816772461
Batch 22/64 loss: 0.27984851598739624
Batch 23/64 loss: 0.27462971210479736
Batch 24/64 loss: 0.27284950017929077
Batch 25/64 loss: 0.2719387412071228
Batch 26/64 loss: 0.2745057940483093
Batch 27/64 loss: 0.26927149295806885
Batch 28/64 loss: 0.27106744050979614
Batch 29/64 loss: 0.2692161202430725
Batch 30/64 loss: 0.27774912118911743
Batch 31/64 loss: 0.2749728560447693
Batch 32/64 loss: 0.2721050977706909
Batch 33/64 loss: 0.2710893154144287
Batch 34/64 loss: 0.27316486835479736
Batch 35/64 loss: 0.26571136713027954
Batch 36/64 loss: 0.273378849029541
Batch 37/64 loss: 0.2697840929031372
Batch 38/64 loss: 0.28107327222824097
Batch 39/64 loss: 0.2688480615615845
Batch 40/64 loss: 0.2814967632293701
Batch 41/64 loss: 0.27037256956100464
Batch 42/64 loss: 0.2818247079849243
Batch 43/64 loss: 0.27402031421661377
Batch 44/64 loss: 0.27286773920059204
Batch 45/64 loss: 0.2677608132362366
Batch 46/64 loss: 0.275901198387146
Batch 47/64 loss: 0.27973198890686035
Batch 48/64 loss: 0.2739361524581909
Batch 49/64 loss: 0.27761805057525635
Batch 50/64 loss: 0.26684504747390747
Batch 51/64 loss: 0.2726060152053833
Batch 52/64 loss: 0.2726248502731323
Batch 53/64 loss: 0.26989710330963135
Batch 54/64 loss: 0.27550816535949707
Batch 55/64 loss: 0.27220451831817627
Batch 56/64 loss: 0.277427077293396
Batch 57/64 loss: 0.27102184295654297
Batch 58/64 loss: 0.2735055685043335
Batch 59/64 loss: 0.2703027129173279
Batch 60/64 loss: 0.2733885645866394
Batch 61/64 loss: 0.2802560329437256
Batch 62/64 loss: 0.26875901222229004
Batch 63/64 loss: 0.27780240774154663
Batch 64/64 loss: 0.2697850465774536
Epoch 334  Train loss: 0.2734588590322756  Val loss: 0.3120694426736471
Epoch 335
-------------------------------
Batch 1/64 loss: 0.27208250761032104
Batch 2/64 loss: 0.27276837825775146
Batch 3/64 loss: 0.26444005966186523
Batch 4/64 loss: 0.2716197967529297
Batch 5/64 loss: 0.2780320644378662
Batch 6/64 loss: 0.2720538377761841
Batch 7/64 loss: 0.2814335823059082
Batch 8/64 loss: 0.27324557304382324
Batch 9/64 loss: 0.27175700664520264
Batch 10/64 loss: 0.2682724595069885
Batch 11/64 loss: 0.27199268341064453
Batch 12/64 loss: 0.2716296911239624
Batch 13/64 loss: 0.2796710729598999
Batch 14/64 loss: 0.2720606327056885
Batch 15/64 loss: 0.2781573534011841
Batch 16/64 loss: 0.27369916439056396
Batch 17/64 loss: 0.26815229654312134
Batch 18/64 loss: 0.27431821823120117
Batch 19/64 loss: 0.27000659704208374
Batch 20/64 loss: 0.26527857780456543
Batch 21/64 loss: 0.2722399830818176
Batch 22/64 loss: 0.28218042850494385
Batch 23/64 loss: 0.2754790782928467
Batch 24/64 loss: 0.2695049047470093
Batch 25/64 loss: 0.26511824131011963
Batch 26/64 loss: 0.27336931228637695
Batch 27/64 loss: 0.27176666259765625
Batch 28/64 loss: 0.2740277051925659
Batch 29/64 loss: 0.2747756242752075
Batch 30/64 loss: 0.2690551280975342
Batch 31/64 loss: 0.2742372751235962
Batch 32/64 loss: 0.2685568928718567
Batch 33/64 loss: 0.2809811234474182
Batch 34/64 loss: 0.2712153196334839
Batch 35/64 loss: 0.2655714154243469
Batch 36/64 loss: 0.2707812786102295
Batch 37/64 loss: 0.2849280834197998
Batch 38/64 loss: 0.2702690362930298
Batch 39/64 loss: 0.2718362808227539
Batch 40/64 loss: 0.2720581293106079
Batch 41/64 loss: 0.2755693197250366
Batch 42/64 loss: 0.2691947817802429
Batch 43/64 loss: 0.2732194662094116
Batch 44/64 loss: 0.2677941918373108
Batch 45/64 loss: 0.2707557678222656
Batch 46/64 loss: 0.27661770582199097
Batch 47/64 loss: 0.2737589478492737
Batch 48/64 loss: 0.27705520391464233
Batch 49/64 loss: 0.2708709239959717
Batch 50/64 loss: 0.2761971950531006
Batch 51/64 loss: 0.27428293228149414
Batch 52/64 loss: 0.275668740272522
Batch 53/64 loss: 0.2805632948875427
Batch 54/64 loss: 0.2679101228713989
Batch 55/64 loss: 0.2765427827835083
Batch 56/64 loss: 0.2740072011947632
Batch 57/64 loss: 0.27802038192749023
Batch 58/64 loss: 0.2815169095993042
Batch 59/64 loss: 0.27642619609832764
Batch 60/64 loss: 0.2733643054962158
Batch 61/64 loss: 0.2680274248123169
Batch 62/64 loss: 0.27583765983581543
Batch 63/64 loss: 0.28244197368621826
Batch 64/64 loss: 0.27673208713531494
Epoch 335  Train loss: 0.27344025022843305  Val loss: 0.31244187727826567
Epoch 336
-------------------------------
Batch 1/64 loss: 0.2709903120994568
Batch 2/64 loss: 0.27031856775283813
Batch 3/64 loss: 0.2721044421195984
Batch 4/64 loss: 0.27304673194885254
Batch 5/64 loss: 0.26552462577819824
Batch 6/64 loss: 0.27277183532714844
Batch 7/64 loss: 0.2756941318511963
Batch 8/64 loss: 0.2889419198036194
Batch 9/64 loss: 0.2722078561782837
Batch 10/64 loss: 0.26640355587005615
Batch 11/64 loss: 0.2760539650917053
Batch 12/64 loss: 0.274630606174469
Batch 13/64 loss: 0.2702709436416626
Batch 14/64 loss: 0.27519047260284424
Batch 15/64 loss: 0.2831418514251709
Batch 16/64 loss: 0.27338021993637085
Batch 17/64 loss: 0.2752586603164673
Batch 18/64 loss: 0.2647247314453125
Batch 19/64 loss: 0.26907891035079956
Batch 20/64 loss: 0.2695949077606201
Batch 21/64 loss: 0.27379393577575684
Batch 22/64 loss: 0.27411383390426636
Batch 23/64 loss: 0.27752262353897095
Batch 24/64 loss: 0.2745249271392822
Batch 25/64 loss: 0.2726765275001526
Batch 26/64 loss: 0.27773916721343994
Batch 27/64 loss: 0.2754710912704468
Batch 28/64 loss: 0.2830023765563965
Batch 29/64 loss: 0.2703005075454712
Batch 30/64 loss: 0.270768404006958
Batch 31/64 loss: 0.2749003767967224
Batch 32/64 loss: 0.26853811740875244
Batch 33/64 loss: 0.27113819122314453
Batch 34/64 loss: 0.2736325263977051
Batch 35/64 loss: 0.27076244354248047
Batch 36/64 loss: 0.2678096294403076
Batch 37/64 loss: 0.2701609134674072
Batch 38/64 loss: 0.27255910634994507
Batch 39/64 loss: 0.26568520069122314
Batch 40/64 loss: 0.271639347076416
Batch 41/64 loss: 0.26772165298461914
Batch 42/64 loss: 0.27433913946151733
Batch 43/64 loss: 0.27385246753692627
Batch 44/64 loss: 0.271554172039032
Batch 45/64 loss: 0.2830430269241333
Batch 46/64 loss: 0.2738754153251648
Batch 47/64 loss: 0.2728383541107178
Batch 48/64 loss: 0.27318906784057617
Batch 49/64 loss: 0.26706838607788086
Batch 50/64 loss: 0.2721736431121826
Batch 51/64 loss: 0.2790336012840271
Batch 52/64 loss: 0.2761119604110718
Batch 53/64 loss: 0.27726489305496216
Batch 54/64 loss: 0.27214300632476807
Batch 55/64 loss: 0.2712286114692688
Batch 56/64 loss: 0.27095818519592285
Batch 57/64 loss: 0.2729532718658447
Batch 58/64 loss: 0.28092336654663086
Batch 59/64 loss: 0.27163416147232056
Batch 60/64 loss: 0.27703678607940674
Batch 61/64 loss: 0.2735482454299927
Batch 62/64 loss: 0.27791810035705566
Batch 63/64 loss: 0.27654945850372314
Batch 64/64 loss: 0.26862168312072754
Epoch 336  Train loss: 0.2733253918442072  Val loss: 0.3125254989080003
Epoch 337
-------------------------------
Batch 1/64 loss: 0.28229522705078125
Batch 2/64 loss: 0.26660287380218506
Batch 3/64 loss: 0.2695910930633545
Batch 4/64 loss: 0.2706817388534546
Batch 5/64 loss: 0.2693564295768738
Batch 6/64 loss: 0.2702155113220215
Batch 7/64 loss: 0.27134573459625244
Batch 8/64 loss: 0.2679228186607361
Batch 9/64 loss: 0.2728169560432434
Batch 10/64 loss: 0.26686930656433105
Batch 11/64 loss: 0.26956480741500854
Batch 12/64 loss: 0.2734568119049072
Batch 13/64 loss: 0.2732442617416382
Batch 14/64 loss: 0.2802504897117615
Batch 15/64 loss: 0.27914345264434814
Batch 16/64 loss: 0.2691735029220581
Batch 17/64 loss: 0.28004127740859985
Batch 18/64 loss: 0.2724756598472595
Batch 19/64 loss: 0.2716827392578125
Batch 20/64 loss: 0.26670145988464355
Batch 21/64 loss: 0.27026963233947754
Batch 22/64 loss: 0.2677713632583618
Batch 23/64 loss: 0.27411240339279175
Batch 24/64 loss: 0.2779778242111206
Batch 25/64 loss: 0.2686835527420044
Batch 26/64 loss: 0.27750861644744873
Batch 27/64 loss: 0.27567601203918457
Batch 28/64 loss: 0.27325451374053955
Batch 29/64 loss: 0.2697732448577881
Batch 30/64 loss: 0.2722041606903076
Batch 31/64 loss: 0.2717139720916748
Batch 32/64 loss: 0.27628791332244873
Batch 33/64 loss: 0.2744786739349365
Batch 34/64 loss: 0.27202486991882324
Batch 35/64 loss: 0.27310556173324585
Batch 36/64 loss: 0.2684822082519531
Batch 37/64 loss: 0.272182822227478
Batch 38/64 loss: 0.2782576084136963
Batch 39/64 loss: 0.2726576328277588
Batch 40/64 loss: 0.2743024230003357
Batch 41/64 loss: 0.27791595458984375
Batch 42/64 loss: 0.2747874855995178
Batch 43/64 loss: 0.2664295434951782
Batch 44/64 loss: 0.2794186472892761
Batch 45/64 loss: 0.2699469327926636
Batch 46/64 loss: 0.27731525897979736
Batch 47/64 loss: 0.2807185649871826
Batch 48/64 loss: 0.27171170711517334
Batch 49/64 loss: 0.27180349826812744
Batch 50/64 loss: 0.2690289616584778
Batch 51/64 loss: 0.2742621898651123
Batch 52/64 loss: 0.2779589891433716
Batch 53/64 loss: 0.2755368947982788
Batch 54/64 loss: 0.2769775390625
Batch 55/64 loss: 0.2729123830795288
Batch 56/64 loss: 0.28054094314575195
Batch 57/64 loss: 0.2742997407913208
Batch 58/64 loss: 0.27417534589767456
Batch 59/64 loss: 0.27098894119262695
Batch 60/64 loss: 0.27093183994293213
Batch 61/64 loss: 0.26866579055786133
Batch 62/64 loss: 0.26809215545654297
Batch 63/64 loss: 0.2725611925125122
Batch 64/64 loss: 0.2749917507171631
Epoch 337  Train loss: 0.2730569643132827  Val loss: 0.31145017847572404
Epoch 338
-------------------------------
Batch 1/64 loss: 0.2732713222503662
Batch 2/64 loss: 0.2682464122772217
Batch 3/64 loss: 0.2695521116256714
Batch 4/64 loss: 0.2679157257080078
Batch 5/64 loss: 0.26771003007888794
Batch 6/64 loss: 0.27436304092407227
Batch 7/64 loss: 0.26433223485946655
Batch 8/64 loss: 0.2696748971939087
Batch 9/64 loss: 0.2718117833137512
Batch 10/64 loss: 0.27337646484375
Batch 11/64 loss: 0.273561954498291
Batch 12/64 loss: 0.268680214881897
Batch 13/64 loss: 0.28334081172943115
Batch 14/64 loss: 0.27270275354385376
Batch 15/64 loss: 0.2746455669403076
Batch 16/64 loss: 0.26736342906951904
Batch 17/64 loss: 0.27509284019470215
Batch 18/64 loss: 0.27255332469940186
Batch 19/64 loss: 0.2779867649078369
Batch 20/64 loss: 0.27343249320983887
Batch 21/64 loss: 0.2687041759490967
Batch 22/64 loss: 0.27147144079208374
Batch 23/64 loss: 0.27086496353149414
Batch 24/64 loss: 0.2731935977935791
Batch 25/64 loss: 0.27612388134002686
Batch 26/64 loss: 0.2783491611480713
Batch 27/64 loss: 0.27515995502471924
Batch 28/64 loss: 0.2766076326370239
Batch 29/64 loss: 0.27137088775634766
Batch 30/64 loss: 0.2799316644668579
Batch 31/64 loss: 0.26440542936325073
Batch 32/64 loss: 0.2747994661331177
Batch 33/64 loss: 0.2696605920791626
Batch 34/64 loss: 0.26984018087387085
Batch 35/64 loss: 0.27462589740753174
Batch 36/64 loss: 0.2775256633758545
Batch 37/64 loss: 0.2784386873245239
Batch 38/64 loss: 0.27078408002853394
Batch 39/64 loss: 0.26939523220062256
Batch 40/64 loss: 0.2719646692276001
Batch 41/64 loss: 0.27366870641708374
Batch 42/64 loss: 0.26645123958587646
Batch 43/64 loss: 0.2808246612548828
Batch 44/64 loss: 0.27361971139907837
Batch 45/64 loss: 0.2669469118118286
Batch 46/64 loss: 0.26941168308258057
Batch 47/64 loss: 0.266743540763855
Batch 48/64 loss: 0.2782120704650879
Batch 49/64 loss: 0.2706761360168457
Batch 50/64 loss: 0.27308452129364014
Batch 51/64 loss: 0.26980113983154297
Batch 52/64 loss: 0.28333306312561035
Batch 53/64 loss: 0.2708927392959595
Batch 54/64 loss: 0.27840179204940796
Batch 55/64 loss: 0.27067047357559204
Batch 56/64 loss: 0.2704780697822571
Batch 57/64 loss: 0.2719501256942749
Batch 58/64 loss: 0.2812965512275696
Batch 59/64 loss: 0.2751203775405884
Batch 60/64 loss: 0.27555859088897705
Batch 61/64 loss: 0.2728126049041748
Batch 62/64 loss: 0.2771643400192261
Batch 63/64 loss: 0.2659261226654053
Batch 64/64 loss: 0.27861452102661133
Epoch 338  Train loss: 0.27286019605748796  Val loss: 0.31212571949483603
Epoch 339
-------------------------------
Batch 1/64 loss: 0.2639566659927368
Batch 2/64 loss: 0.2768093943595886
Batch 3/64 loss: 0.28138625621795654
Batch 4/64 loss: 0.26814788579940796
Batch 5/64 loss: 0.26987791061401367
Batch 6/64 loss: 0.272491455078125
Batch 7/64 loss: 0.27028393745422363
Batch 8/64 loss: 0.2774580717086792
Batch 9/64 loss: 0.26175451278686523
Batch 10/64 loss: 0.26373571157455444
Batch 11/64 loss: 0.2685168385505676
Batch 12/64 loss: 0.27867698669433594
Batch 13/64 loss: 0.27290236949920654
Batch 14/64 loss: 0.27091550827026367
Batch 15/64 loss: 0.27412670850753784
Batch 16/64 loss: 0.2727482318878174
Batch 17/64 loss: 0.269517183303833
Batch 18/64 loss: 0.275958776473999
Batch 19/64 loss: 0.2687382698059082
Batch 20/64 loss: 0.2794668674468994
Batch 21/64 loss: 0.2700904607772827
Batch 22/64 loss: 0.27569591999053955
Batch 23/64 loss: 0.27201151847839355
Batch 24/64 loss: 0.2758655548095703
Batch 25/64 loss: 0.27207547426223755
Batch 26/64 loss: 0.27091503143310547
Batch 27/64 loss: 0.275665283203125
Batch 28/64 loss: 0.2741355895996094
Batch 29/64 loss: 0.27246618270874023
Batch 30/64 loss: 0.26779210567474365
Batch 31/64 loss: 0.2710118293762207
Batch 32/64 loss: 0.27721261978149414
Batch 33/64 loss: 0.2722107768058777
Batch 34/64 loss: 0.27134406566619873
Batch 35/64 loss: 0.27616971731185913
Batch 36/64 loss: 0.2720754146575928
Batch 37/64 loss: 0.28093773126602173
Batch 38/64 loss: 0.27168989181518555
Batch 39/64 loss: 0.2760493755340576
Batch 40/64 loss: 0.27774012088775635
Batch 41/64 loss: 0.2711353302001953
Batch 42/64 loss: 0.2780522108078003
Batch 43/64 loss: 0.2712223529815674
Batch 44/64 loss: 0.2888687252998352
Batch 45/64 loss: 0.2741798162460327
Batch 46/64 loss: 0.27182120084762573
Batch 47/64 loss: 0.2700955271720886
Batch 48/64 loss: 0.2703813314437866
Batch 49/64 loss: 0.27269446849823
Batch 50/64 loss: 0.2810349464416504
Batch 51/64 loss: 0.27058184146881104
Batch 52/64 loss: 0.2786276936531067
Batch 53/64 loss: 0.2781902551651001
Batch 54/64 loss: 0.27185893058776855
Batch 55/64 loss: 0.2682381868362427
Batch 56/64 loss: 0.2724609375
Batch 57/64 loss: 0.2791749835014343
Batch 58/64 loss: 0.2734718322753906
Batch 59/64 loss: 0.2774699926376343
Batch 60/64 loss: 0.2756291627883911
Batch 61/64 loss: 0.2706162929534912
Batch 62/64 loss: 0.2790170907974243
Batch 63/64 loss: 0.274161696434021
Batch 64/64 loss: 0.2726367115974426
Epoch 339  Train loss: 0.2734758673929701  Val loss: 0.3119243805351126
Epoch 340
-------------------------------
Batch 1/64 loss: 0.271206259727478
Batch 2/64 loss: 0.2778724431991577
Batch 3/64 loss: 0.2782144546508789
Batch 4/64 loss: 0.275191068649292
Batch 5/64 loss: 0.2655845284461975
Batch 6/64 loss: 0.2642132639884949
Batch 7/64 loss: 0.2765834331512451
Batch 8/64 loss: 0.2644500136375427
Batch 9/64 loss: 0.2694740891456604
Batch 10/64 loss: 0.27735328674316406
Batch 11/64 loss: 0.27990150451660156
Batch 12/64 loss: 0.27635955810546875
Batch 13/64 loss: 0.2750862240791321
Batch 14/64 loss: 0.26942551136016846
Batch 15/64 loss: 0.2759617567062378
Batch 16/64 loss: 0.27306127548217773
Batch 17/64 loss: 0.2741844654083252
Batch 18/64 loss: 0.271442174911499
Batch 19/64 loss: 0.2715100049972534
Batch 20/64 loss: 0.27528512477874756
Batch 21/64 loss: 0.2680833339691162
Batch 22/64 loss: 0.2738136053085327
Batch 23/64 loss: 0.2771029472351074
Batch 24/64 loss: 0.2768193483352661
Batch 25/64 loss: 0.2726420760154724
Batch 26/64 loss: 0.27374058961868286
Batch 27/64 loss: 0.272591233253479
Batch 28/64 loss: 0.26285475492477417
Batch 29/64 loss: 0.2719759941101074
Batch 30/64 loss: 0.2732921838760376
Batch 31/64 loss: 0.26788997650146484
Batch 32/64 loss: 0.27777183055877686
Batch 33/64 loss: 0.2701314687728882
Batch 34/64 loss: 0.2771024703979492
Batch 35/64 loss: 0.2766541838645935
Batch 36/64 loss: 0.26807451248168945
Batch 37/64 loss: 0.27619826793670654
Batch 38/64 loss: 0.27163076400756836
Batch 39/64 loss: 0.27088046073913574
Batch 40/64 loss: 0.27285486459732056
Batch 41/64 loss: 0.27212655544281006
Batch 42/64 loss: 0.2682187557220459
Batch 43/64 loss: 0.27069389820098877
Batch 44/64 loss: 0.27093344926834106
Batch 45/64 loss: 0.27078115940093994
Batch 46/64 loss: 0.27242302894592285
Batch 47/64 loss: 0.27461087703704834
Batch 48/64 loss: 0.2748357057571411
Batch 49/64 loss: 0.27050137519836426
Batch 50/64 loss: 0.27653688192367554
Batch 51/64 loss: 0.2753950357437134
Batch 52/64 loss: 0.2671854496002197
Batch 53/64 loss: 0.27749061584472656
Batch 54/64 loss: 0.2734994888305664
Batch 55/64 loss: 0.26930463314056396
Batch 56/64 loss: 0.2780734896659851
Batch 57/64 loss: 0.27950990200042725
Batch 58/64 loss: 0.2720937728881836
Batch 59/64 loss: 0.2741512656211853
Batch 60/64 loss: 0.27819347381591797
Batch 61/64 loss: 0.27363038063049316
Batch 62/64 loss: 0.27572906017303467
Batch 63/64 loss: 0.2673525810241699
Batch 64/64 loss: 0.2762303948402405
Epoch 340  Train loss: 0.2730181794540555  Val loss: 0.3126214089262526
Epoch 341
-------------------------------
Batch 1/64 loss: 0.2765967845916748
Batch 2/64 loss: 0.27343517541885376
Batch 3/64 loss: 0.2729358673095703
Batch 4/64 loss: 0.27462589740753174
Batch 5/64 loss: 0.27662962675094604
Batch 6/64 loss: 0.26925647258758545
Batch 7/64 loss: 0.270072340965271
Batch 8/64 loss: 0.26764190196990967
Batch 9/64 loss: 0.2658454179763794
Batch 10/64 loss: 0.2655731439590454
Batch 11/64 loss: 0.2704152464866638
Batch 12/64 loss: 0.2715286612510681
Batch 13/64 loss: 0.27119147777557373
Batch 14/64 loss: 0.27183783054351807
Batch 15/64 loss: 0.2736127972602844
Batch 16/64 loss: 0.26065266132354736
Batch 17/64 loss: 0.27208852767944336
Batch 18/64 loss: 0.2671217918395996
Batch 19/64 loss: 0.269970178604126
Batch 20/64 loss: 0.28056561946868896
Batch 21/64 loss: 0.26926976442337036
Batch 22/64 loss: 0.28040456771850586
Batch 23/64 loss: 0.28005993366241455
Batch 24/64 loss: 0.27306056022644043
Batch 25/64 loss: 0.2792952060699463
Batch 26/64 loss: 0.2746477723121643
Batch 27/64 loss: 0.27195894718170166
Batch 28/64 loss: 0.2771148681640625
Batch 29/64 loss: 0.2701246738433838
Batch 30/64 loss: 0.27298468351364136
Batch 31/64 loss: 0.2687091827392578
Batch 32/64 loss: 0.2688811421394348
Batch 33/64 loss: 0.27308428287506104
Batch 34/64 loss: 0.2757660150527954
Batch 35/64 loss: 0.27441632747650146
Batch 36/64 loss: 0.28169429302215576
Batch 37/64 loss: 0.2778981924057007
Batch 38/64 loss: 0.2764962315559387
Batch 39/64 loss: 0.26711505651474
Batch 40/64 loss: 0.28714513778686523
Batch 41/64 loss: 0.2758214473724365
Batch 42/64 loss: 0.27517086267471313
Batch 43/64 loss: 0.2698930501937866
Batch 44/64 loss: 0.27598512172698975
Batch 45/64 loss: 0.2729344367980957
Batch 46/64 loss: 0.2738873362541199
Batch 47/64 loss: 0.281264066696167
Batch 48/64 loss: 0.2737905979156494
Batch 49/64 loss: 0.2718937397003174
Batch 50/64 loss: 0.26911425590515137
Batch 51/64 loss: 0.268218457698822
Batch 52/64 loss: 0.277741014957428
Batch 53/64 loss: 0.27374130487442017
Batch 54/64 loss: 0.2745668888092041
Batch 55/64 loss: 0.2760186791419983
Batch 56/64 loss: 0.27627527713775635
Batch 57/64 loss: 0.2757021188735962
Batch 58/64 loss: 0.2674752473831177
Batch 59/64 loss: 0.26425766944885254
Batch 60/64 loss: 0.2816230058670044
Batch 61/64 loss: 0.27085793018341064
Batch 62/64 loss: 0.2752399444580078
Batch 63/64 loss: 0.27270615100860596
Batch 64/64 loss: 0.2657642960548401
Epoch 341  Train loss: 0.2731800170505748  Val loss: 0.31253392016355114
Epoch 342
-------------------------------
Batch 1/64 loss: 0.2801939845085144
Batch 2/64 loss: 0.2718241214752197
Batch 3/64 loss: 0.2689318060874939
Batch 4/64 loss: 0.2709251046180725
Batch 5/64 loss: 0.2696612477302551
Batch 6/64 loss: 0.2735384702682495
Batch 7/64 loss: 0.26836341619491577
Batch 8/64 loss: 0.272074818611145
Batch 9/64 loss: 0.2694437503814697
Batch 10/64 loss: 0.2709078788757324
Batch 11/64 loss: 0.27070778608322144
Batch 12/64 loss: 0.2723766565322876
Batch 13/64 loss: 0.27810031175613403
Batch 14/64 loss: 0.2851836085319519
Batch 15/64 loss: 0.2739083766937256
Batch 16/64 loss: 0.27043235301971436
Batch 17/64 loss: 0.28178250789642334
Batch 18/64 loss: 0.2715728282928467
Batch 19/64 loss: 0.2691762447357178
Batch 20/64 loss: 0.2722480297088623
Batch 21/64 loss: 0.26956188678741455
Batch 22/64 loss: 0.2745535373687744
Batch 23/64 loss: 0.27152711153030396
Batch 24/64 loss: 0.2738890051841736
Batch 25/64 loss: 0.27338385581970215
Batch 26/64 loss: 0.2691391706466675
Batch 27/64 loss: 0.2688335180282593
Batch 28/64 loss: 0.27220940589904785
Batch 29/64 loss: 0.2688542604446411
Batch 30/64 loss: 0.270114541053772
Batch 31/64 loss: 0.2731401324272156
Batch 32/64 loss: 0.2754480838775635
Batch 33/64 loss: 0.2729187607765198
Batch 34/64 loss: 0.27048051357269287
Batch 35/64 loss: 0.27010923624038696
Batch 36/64 loss: 0.27242159843444824
Batch 37/64 loss: 0.2857474684715271
Batch 38/64 loss: 0.2706564664840698
Batch 39/64 loss: 0.267958402633667
Batch 40/64 loss: 0.2684856057167053
Batch 41/64 loss: 0.2714940309524536
Batch 42/64 loss: 0.2691032290458679
Batch 43/64 loss: 0.27540159225463867
Batch 44/64 loss: 0.2745218276977539
Batch 45/64 loss: 0.27220022678375244
Batch 46/64 loss: 0.271040678024292
Batch 47/64 loss: 0.26433265209198
Batch 48/64 loss: 0.2671312093734741
Batch 49/64 loss: 0.26990652084350586
Batch 50/64 loss: 0.2650986909866333
Batch 51/64 loss: 0.2778431177139282
Batch 52/64 loss: 0.27411139011383057
Batch 53/64 loss: 0.2703925371170044
Batch 54/64 loss: 0.27254951000213623
Batch 55/64 loss: 0.26729774475097656
Batch 56/64 loss: 0.2719646692276001
Batch 57/64 loss: 0.268410325050354
Batch 58/64 loss: 0.2839242219924927
Batch 59/64 loss: 0.2746671438217163
Batch 60/64 loss: 0.2840592861175537
Batch 61/64 loss: 0.2760225534439087
Batch 62/64 loss: 0.27514874935150146
Batch 63/64 loss: 0.27218782901763916
Batch 64/64 loss: 0.27730894088745117
Epoch 342  Train loss: 0.2725894479190602  Val loss: 0.31302197077839644
Epoch 343
-------------------------------
Batch 1/64 loss: 0.2895691394805908
Batch 2/64 loss: 0.26902759075164795
Batch 3/64 loss: 0.2672234773635864
Batch 4/64 loss: 0.26764094829559326
Batch 5/64 loss: 0.27346789836883545
Batch 6/64 loss: 0.2644617557525635
Batch 7/64 loss: 0.2765604257583618
Batch 8/64 loss: 0.27409666776657104
Batch 9/64 loss: 0.27835196256637573
Batch 10/64 loss: 0.2739120125770569
Batch 11/64 loss: 0.26771652698516846
Batch 12/64 loss: 0.27208763360977173
Batch 13/64 loss: 0.26370763778686523
Batch 14/64 loss: 0.266790509223938
Batch 15/64 loss: 0.27284830808639526
Batch 16/64 loss: 0.26912152767181396
Batch 17/64 loss: 0.2643611431121826
Batch 18/64 loss: 0.2675921320915222
Batch 19/64 loss: 0.27097439765930176
Batch 20/64 loss: 0.2675647735595703
Batch 21/64 loss: 0.27309298515319824
Batch 22/64 loss: 0.27509719133377075
Batch 23/64 loss: 0.2762259840965271
Batch 24/64 loss: 0.27619653940200806
Batch 25/64 loss: 0.2797169089317322
Batch 26/64 loss: 0.2754131555557251
Batch 27/64 loss: 0.2684065103530884
Batch 28/64 loss: 0.27506351470947266
Batch 29/64 loss: 0.27085626125335693
Batch 30/64 loss: 0.27017533779144287
Batch 31/64 loss: 0.2703862190246582
Batch 32/64 loss: 0.27907317876815796
Batch 33/64 loss: 0.2772940397262573
Batch 34/64 loss: 0.2732071876525879
Batch 35/64 loss: 0.2702629566192627
Batch 36/64 loss: 0.27063536643981934
Batch 37/64 loss: 0.27343761920928955
Batch 38/64 loss: 0.2682819366455078
Batch 39/64 loss: 0.276836633682251
Batch 40/64 loss: 0.26782381534576416
Batch 41/64 loss: 0.27266478538513184
Batch 42/64 loss: 0.27368074655532837
Batch 43/64 loss: 0.2747206687927246
Batch 44/64 loss: 0.2810037136077881
Batch 45/64 loss: 0.27248722314834595
Batch 46/64 loss: 0.26699966192245483
Batch 47/64 loss: 0.2726498246192932
Batch 48/64 loss: 0.26509618759155273
Batch 49/64 loss: 0.26991164684295654
Batch 50/64 loss: 0.27332592010498047
Batch 51/64 loss: 0.28061068058013916
Batch 52/64 loss: 0.278720498085022
Batch 53/64 loss: 0.26956188678741455
Batch 54/64 loss: 0.27417564392089844
Batch 55/64 loss: 0.27181732654571533
Batch 56/64 loss: 0.27004945278167725
Batch 57/64 loss: 0.26213979721069336
Batch 58/64 loss: 0.27008867263793945
Batch 59/64 loss: 0.2775561809539795
Batch 60/64 loss: 0.2765132188796997
Batch 61/64 loss: 0.26844489574432373
Batch 62/64 loss: 0.2735046148300171
Batch 63/64 loss: 0.2720932960510254
Batch 64/64 loss: 0.2772790193557739
Epoch 343  Train loss: 0.2723189900903141  Val loss: 0.31318669384697456
Epoch 344
-------------------------------
Batch 1/64 loss: 0.27410888671875
Batch 2/64 loss: 0.27453911304473877
Batch 3/64 loss: 0.26952338218688965
Batch 4/64 loss: 0.27142560482025146
Batch 5/64 loss: 0.2707330584526062
Batch 6/64 loss: 0.270541250705719
Batch 7/64 loss: 0.26891136169433594
Batch 8/64 loss: 0.27154743671417236
Batch 9/64 loss: 0.2829253077507019
Batch 10/64 loss: 0.2685438394546509
Batch 11/64 loss: 0.26560986042022705
Batch 12/64 loss: 0.2768028974533081
Batch 13/64 loss: 0.26606595516204834
Batch 14/64 loss: 0.2677885890007019
Batch 15/64 loss: 0.28183430433273315
Batch 16/64 loss: 0.2817728519439697
Batch 17/64 loss: 0.272014856338501
Batch 18/64 loss: 0.2728848457336426
Batch 19/64 loss: 0.2689990997314453
Batch 20/64 loss: 0.2780468463897705
Batch 21/64 loss: 0.2728617191314697
Batch 22/64 loss: 0.27815043926239014
Batch 23/64 loss: 0.2744925618171692
Batch 24/64 loss: 0.27095121145248413
Batch 25/64 loss: 0.2695540189743042
Batch 26/64 loss: 0.26821064949035645
Batch 27/64 loss: 0.26700329780578613
Batch 28/64 loss: 0.2780781388282776
Batch 29/64 loss: 0.2728601098060608
Batch 30/64 loss: 0.2765466570854187
Batch 31/64 loss: 0.2689756155014038
Batch 32/64 loss: 0.2720121741294861
Batch 33/64 loss: 0.2731174826622009
Batch 34/64 loss: 0.2735294699668884
Batch 35/64 loss: 0.27769923210144043
Batch 36/64 loss: 0.26828277111053467
Batch 37/64 loss: 0.2716093063354492
Batch 38/64 loss: 0.265397310256958
Batch 39/64 loss: 0.27055996656417847
Batch 40/64 loss: 0.28163695335388184
Batch 41/64 loss: 0.27334094047546387
Batch 42/64 loss: 0.26843929290771484
Batch 43/64 loss: 0.2748580574989319
Batch 44/64 loss: 0.2688959240913391
Batch 45/64 loss: 0.27770018577575684
Batch 46/64 loss: 0.26614058017730713
Batch 47/64 loss: 0.26215362548828125
Batch 48/64 loss: 0.2687772512435913
Batch 49/64 loss: 0.2724490761756897
Batch 50/64 loss: 0.2761651277542114
Batch 51/64 loss: 0.27266132831573486
Batch 52/64 loss: 0.27294814586639404
Batch 53/64 loss: 0.27821099758148193
Batch 54/64 loss: 0.26698917150497437
Batch 55/64 loss: 0.27440643310546875
Batch 56/64 loss: 0.27575618028640747
Batch 57/64 loss: 0.2776085138320923
Batch 58/64 loss: 0.26658129692077637
Batch 59/64 loss: 0.2699623107910156
Batch 60/64 loss: 0.27375954389572144
Batch 61/64 loss: 0.2728137969970703
Batch 62/64 loss: 0.27397608757019043
Batch 63/64 loss: 0.2673509120941162
Batch 64/64 loss: 0.2690855860710144
Epoch 344  Train loss: 0.27231227299746347  Val loss: 0.3119717271057601
Epoch 345
-------------------------------
Batch 1/64 loss: 0.26824504137039185
Batch 2/64 loss: 0.2726038694381714
Batch 3/64 loss: 0.2735602855682373
Batch 4/64 loss: 0.26771819591522217
Batch 5/64 loss: 0.2699134349822998
Batch 6/64 loss: 0.26696693897247314
Batch 7/64 loss: 0.2712050676345825
Batch 8/64 loss: 0.2659505605697632
Batch 9/64 loss: 0.27412235736846924
Batch 10/64 loss: 0.2752711772918701
Batch 11/64 loss: 0.2703263759613037
Batch 12/64 loss: 0.2828945517539978
Batch 13/64 loss: 0.2690325379371643
Batch 14/64 loss: 0.2724762558937073
Batch 15/64 loss: 0.27592575550079346
Batch 16/64 loss: 0.27199769020080566
Batch 17/64 loss: 0.27235114574432373
Batch 18/64 loss: 0.26904523372650146
Batch 19/64 loss: 0.2706568241119385
Batch 20/64 loss: 0.27077603340148926
Batch 21/64 loss: 0.2749977111816406
Batch 22/64 loss: 0.2737162113189697
Batch 23/64 loss: 0.26957905292510986
Batch 24/64 loss: 0.28066837787628174
Batch 25/64 loss: 0.27159035205841064
Batch 26/64 loss: 0.27571743726730347
Batch 27/64 loss: 0.2711247205734253
Batch 28/64 loss: 0.27727025747299194
Batch 29/64 loss: 0.2737478017807007
Batch 30/64 loss: 0.2698606252670288
Batch 31/64 loss: 0.28113389015197754
Batch 32/64 loss: 0.26343220472335815
Batch 33/64 loss: 0.26772451400756836
Batch 34/64 loss: 0.26952219009399414
Batch 35/64 loss: 0.2736644744873047
Batch 36/64 loss: 0.28290581703186035
Batch 37/64 loss: 0.2736787796020508
Batch 38/64 loss: 0.27092933654785156
Batch 39/64 loss: 0.2695598006248474
Batch 40/64 loss: 0.2747185230255127
Batch 41/64 loss: 0.2707453966140747
Batch 42/64 loss: 0.27329349517822266
Batch 43/64 loss: 0.2696305513381958
Batch 44/64 loss: 0.26849430799484253
Batch 45/64 loss: 0.2690478563308716
Batch 46/64 loss: 0.2771795988082886
Batch 47/64 loss: 0.2746051549911499
Batch 48/64 loss: 0.27031785249710083
Batch 49/64 loss: 0.2733858823776245
Batch 50/64 loss: 0.2669679522514343
Batch 51/64 loss: 0.2723996639251709
Batch 52/64 loss: 0.2732729911804199
Batch 53/64 loss: 0.2708902359008789
Batch 54/64 loss: 0.2649136185646057
Batch 55/64 loss: 0.269162654876709
Batch 56/64 loss: 0.27433639764785767
Batch 57/64 loss: 0.2649879455566406
Batch 58/64 loss: 0.2735491394996643
Batch 59/64 loss: 0.2699354290962219
Batch 60/64 loss: 0.27164047956466675
Batch 61/64 loss: 0.27568209171295166
Batch 62/64 loss: 0.27970027923583984
Batch 63/64 loss: 0.2736274003982544
Batch 64/64 loss: 0.27399253845214844
Epoch 345  Train loss: 0.2721543873057646  Val loss: 0.311709176019295
Epoch 346
-------------------------------
Batch 1/64 loss: 0.26617497205734253
Batch 2/64 loss: 0.278531551361084
Batch 3/64 loss: 0.27327942848205566
Batch 4/64 loss: 0.26680731773376465
Batch 5/64 loss: 0.269217312335968
Batch 6/64 loss: 0.2706315517425537
Batch 7/64 loss: 0.27254366874694824
Batch 8/64 loss: 0.26523149013519287
Batch 9/64 loss: 0.27335071563720703
Batch 10/64 loss: 0.2659127116203308
Batch 11/64 loss: 0.2705853581428528
Batch 12/64 loss: 0.27040910720825195
Batch 13/64 loss: 0.2710658311843872
Batch 14/64 loss: 0.26616525650024414
Batch 15/64 loss: 0.2797648310661316
Batch 16/64 loss: 0.26917946338653564
Batch 17/64 loss: 0.2773396372795105
Batch 18/64 loss: 0.2721986770629883
Batch 19/64 loss: 0.26720094680786133
Batch 20/64 loss: 0.26767945289611816
Batch 21/64 loss: 0.2667832374572754
Batch 22/64 loss: 0.2754420042037964
Batch 23/64 loss: 0.2698829770088196
Batch 24/64 loss: 0.27660679817199707
Batch 25/64 loss: 0.2723982334136963
Batch 26/64 loss: 0.2697058320045471
Batch 27/64 loss: 0.27619773149490356
Batch 28/64 loss: 0.2746312618255615
Batch 29/64 loss: 0.2699803113937378
Batch 30/64 loss: 0.26997488737106323
Batch 31/64 loss: 0.2812257409095764
Batch 32/64 loss: 0.2708165645599365
Batch 33/64 loss: 0.2739097476005554
Batch 34/64 loss: 0.26849639415740967
Batch 35/64 loss: 0.27583110332489014
Batch 36/64 loss: 0.26880478858947754
Batch 37/64 loss: 0.27285945415496826
Batch 38/64 loss: 0.272805392742157
Batch 39/64 loss: 0.271589457988739
Batch 40/64 loss: 0.2735271453857422
Batch 41/64 loss: 0.26912248134613037
Batch 42/64 loss: 0.2770824432373047
Batch 43/64 loss: 0.27862608432769775
Batch 44/64 loss: 0.27312296628952026
Batch 45/64 loss: 0.2695220708847046
Batch 46/64 loss: 0.27149438858032227
Batch 47/64 loss: 0.2734109163284302
Batch 48/64 loss: 0.26621973514556885
Batch 49/64 loss: 0.26624876260757446
Batch 50/64 loss: 0.26926565170288086
Batch 51/64 loss: 0.26874232292175293
Batch 52/64 loss: 0.27099287509918213
Batch 53/64 loss: 0.28680819272994995
Batch 54/64 loss: 0.2730846405029297
Batch 55/64 loss: 0.2785813808441162
Batch 56/64 loss: 0.2747188210487366
Batch 57/64 loss: 0.26300048828125
Batch 58/64 loss: 0.2699328064918518
Batch 59/64 loss: 0.2812840938568115
Batch 60/64 loss: 0.26633405685424805
Batch 61/64 loss: 0.2744680643081665
Batch 62/64 loss: 0.2729741930961609
Batch 63/64 loss: 0.2714656591415405
Batch 64/64 loss: 0.2736133337020874
Epoch 346  Train loss: 0.27194433633018944  Val loss: 0.3125251789682919
Epoch 347
-------------------------------
Batch 1/64 loss: 0.26830148696899414
Batch 2/64 loss: 0.2751200199127197
Batch 3/64 loss: 0.26604342460632324
Batch 4/64 loss: 0.2726411819458008
Batch 5/64 loss: 0.2691967487335205
Batch 6/64 loss: 0.265458345413208
Batch 7/64 loss: 0.2711348533630371
Batch 8/64 loss: 0.2693202495574951
Batch 9/64 loss: 0.27388375997543335
Batch 10/64 loss: 0.2667994499206543
Batch 11/64 loss: 0.27649205923080444
Batch 12/64 loss: 0.2755758762359619
Batch 13/64 loss: 0.27671247720718384
Batch 14/64 loss: 0.269787073135376
Batch 15/64 loss: 0.279280424118042
Batch 16/64 loss: 0.27160704135894775
Batch 17/64 loss: 0.2736397385597229
Batch 18/64 loss: 0.2723658084869385
Batch 19/64 loss: 0.2666938304901123
Batch 20/64 loss: 0.2768828868865967
Batch 21/64 loss: 0.2695951461791992
Batch 22/64 loss: 0.28223133087158203
Batch 23/64 loss: 0.2727765440940857
Batch 24/64 loss: 0.2706751823425293
Batch 25/64 loss: 0.2753775119781494
Batch 26/64 loss: 0.27182263135910034
Batch 27/64 loss: 0.2805408239364624
Batch 28/64 loss: 0.26748621463775635
Batch 29/64 loss: 0.27227258682250977
Batch 30/64 loss: 0.2680346965789795
Batch 31/64 loss: 0.2758234739303589
Batch 32/64 loss: 0.26403629779815674
Batch 33/64 loss: 0.271200954914093
Batch 34/64 loss: 0.2745957374572754
Batch 35/64 loss: 0.276888906955719
Batch 36/64 loss: 0.27096372842788696
Batch 37/64 loss: 0.2777343988418579
Batch 38/64 loss: 0.27892857789993286
Batch 39/64 loss: 0.27370715141296387
Batch 40/64 loss: 0.2755213975906372
Batch 41/64 loss: 0.27195870876312256
Batch 42/64 loss: 0.27533483505249023
Batch 43/64 loss: 0.27243268489837646
Batch 44/64 loss: 0.2679564952850342
Batch 45/64 loss: 0.2705618143081665
Batch 46/64 loss: 0.26854825019836426
Batch 47/64 loss: 0.27373170852661133
Batch 48/64 loss: 0.27280759811401367
Batch 49/64 loss: 0.26802319288253784
Batch 50/64 loss: 0.26626527309417725
Batch 51/64 loss: 0.279840886592865
Batch 52/64 loss: 0.2705814838409424
Batch 53/64 loss: 0.2674676179885864
Batch 54/64 loss: 0.2727479934692383
Batch 55/64 loss: 0.2685145139694214
Batch 56/64 loss: 0.27236950397491455
Batch 57/64 loss: 0.267988920211792
Batch 58/64 loss: 0.27544158697128296
Batch 59/64 loss: 0.27333956956863403
Batch 60/64 loss: 0.2766813039779663
Batch 61/64 loss: 0.26948481798171997
Batch 62/64 loss: 0.2734769582748413
Batch 63/64 loss: 0.27510035037994385
Batch 64/64 loss: 0.2795301079750061
Epoch 347  Train loss: 0.27243064595203775  Val loss: 0.3129587368047524
Epoch 348
-------------------------------
Batch 1/64 loss: 0.2715878486633301
Batch 2/64 loss: 0.27067768573760986
Batch 3/64 loss: 0.26661527156829834
Batch 4/64 loss: 0.26929283142089844
Batch 5/64 loss: 0.2714484930038452
Batch 6/64 loss: 0.2738908529281616
Batch 7/64 loss: 0.267757773399353
Batch 8/64 loss: 0.2691913843154907
Batch 9/64 loss: 0.27330005168914795
Batch 10/64 loss: 0.26962387561798096
Batch 11/64 loss: 0.2642788887023926
Batch 12/64 loss: 0.26795482635498047
Batch 13/64 loss: 0.27098900079727173
Batch 14/64 loss: 0.2636526823043823
Batch 15/64 loss: 0.27020663022994995
Batch 16/64 loss: 0.2709086537361145
Batch 17/64 loss: 0.26760709285736084
Batch 18/64 loss: 0.26992905139923096
Batch 19/64 loss: 0.2772844433784485
Batch 20/64 loss: 0.2738569974899292
Batch 21/64 loss: 0.2684333324432373
Batch 22/64 loss: 0.26992857456207275
Batch 23/64 loss: 0.28010880947113037
Batch 24/64 loss: 0.2705548405647278
Batch 25/64 loss: 0.26997077465057373
Batch 26/64 loss: 0.27262425422668457
Batch 27/64 loss: 0.2736666202545166
Batch 28/64 loss: 0.26553815603256226
Batch 29/64 loss: 0.269084632396698
Batch 30/64 loss: 0.2703512907028198
Batch 31/64 loss: 0.2729419469833374
Batch 32/64 loss: 0.2671830654144287
Batch 33/64 loss: 0.269500732421875
Batch 34/64 loss: 0.27622079849243164
Batch 35/64 loss: 0.2708512544631958
Batch 36/64 loss: 0.2746572494506836
Batch 37/64 loss: 0.27565664052963257
Batch 38/64 loss: 0.2721109986305237
Batch 39/64 loss: 0.2744975686073303
Batch 40/64 loss: 0.2741677165031433
Batch 41/64 loss: 0.2704828977584839
Batch 42/64 loss: 0.2742905616760254
Batch 43/64 loss: 0.2656748294830322
Batch 44/64 loss: 0.26904165744781494
Batch 45/64 loss: 0.2751429080963135
Batch 46/64 loss: 0.2699704170227051
Batch 47/64 loss: 0.2644752860069275
Batch 48/64 loss: 0.27215373516082764
Batch 49/64 loss: 0.26955074071884155
Batch 50/64 loss: 0.2809523344039917
Batch 51/64 loss: 0.274389386177063
Batch 52/64 loss: 0.2785123586654663
Batch 53/64 loss: 0.2685413956642151
Batch 54/64 loss: 0.2640119791030884
Batch 55/64 loss: 0.26957881450653076
Batch 56/64 loss: 0.27270662784576416
Batch 57/64 loss: 0.2819458842277527
Batch 58/64 loss: 0.27410584688186646
Batch 59/64 loss: 0.27529406547546387
Batch 60/64 loss: 0.27763718366622925
Batch 61/64 loss: 0.27660322189331055
Batch 62/64 loss: 0.2787201404571533
Batch 63/64 loss: 0.27362513542175293
Batch 64/64 loss: 0.27910393476486206
Epoch 348  Train loss: 0.271762179627138  Val loss: 0.31226678382080447
Epoch 349
-------------------------------
Batch 1/64 loss: 0.2777673006057739
Batch 2/64 loss: 0.26960062980651855
Batch 3/64 loss: 0.2721594572067261
Batch 4/64 loss: 0.28024280071258545
Batch 5/64 loss: 0.2758370637893677
Batch 6/64 loss: 0.2725287675857544
Batch 7/64 loss: 0.2761685848236084
Batch 8/64 loss: 0.28826069831848145
Batch 9/64 loss: 0.2716277837753296
Batch 10/64 loss: 0.2713162899017334
Batch 11/64 loss: 0.2779475450515747
Batch 12/64 loss: 0.26831579208374023
Batch 13/64 loss: 0.28086888790130615
Batch 14/64 loss: 0.2664361000061035
Batch 15/64 loss: 0.26864171028137207
Batch 16/64 loss: 0.2758282423019409
Batch 17/64 loss: 0.27311474084854126
Batch 18/64 loss: 0.2678699493408203
Batch 19/64 loss: 0.26922428607940674
Batch 20/64 loss: 0.2700720429420471
Batch 21/64 loss: 0.2735021114349365
Batch 22/64 loss: 0.2693541646003723
Batch 23/64 loss: 0.2671603560447693
Batch 24/64 loss: 0.2755715847015381
Batch 25/64 loss: 0.2736177444458008
Batch 26/64 loss: 0.2748527526855469
Batch 27/64 loss: 0.2657279968261719
Batch 28/64 loss: 0.26811695098876953
Batch 29/64 loss: 0.27249956130981445
Batch 30/64 loss: 0.26947706937789917
Batch 31/64 loss: 0.27645593881607056
Batch 32/64 loss: 0.2716323137283325
Batch 33/64 loss: 0.27076220512390137
Batch 34/64 loss: 0.2662390470504761
Batch 35/64 loss: 0.2724142074584961
Batch 36/64 loss: 0.27238500118255615
Batch 37/64 loss: 0.27831101417541504
Batch 38/64 loss: 0.26886463165283203
Batch 39/64 loss: 0.2690979242324829
Batch 40/64 loss: 0.2676323652267456
Batch 41/64 loss: 0.2752758264541626
Batch 42/64 loss: 0.2687385082244873
Batch 43/64 loss: 0.2720956802368164
Batch 44/64 loss: 0.27232205867767334
Batch 45/64 loss: 0.27241766452789307
Batch 46/64 loss: 0.2785605192184448
Batch 47/64 loss: 0.27878230810165405
Batch 48/64 loss: 0.27107590436935425
Batch 49/64 loss: 0.27521979808807373
Batch 50/64 loss: 0.27432048320770264
Batch 51/64 loss: 0.2772093415260315
Batch 52/64 loss: 0.27387815713882446
Batch 53/64 loss: 0.2702755928039551
Batch 54/64 loss: 0.28203684091567993
Batch 55/64 loss: 0.27760815620422363
Batch 56/64 loss: 0.2653205394744873
Batch 57/64 loss: 0.27453482151031494
Batch 58/64 loss: 0.2795713543891907
Batch 59/64 loss: 0.275937020778656
Batch 60/64 loss: 0.2686139941215515
Batch 61/64 loss: 0.2761041522026062
Batch 62/64 loss: 0.269142210483551
Batch 63/64 loss: 0.27370214462280273
Batch 64/64 loss: 0.27331459522247314
Epoch 349  Train loss: 0.27302325706855923  Val loss: 0.3124457212657863
Epoch 350
-------------------------------
Batch 1/64 loss: 0.2766697406768799
Batch 2/64 loss: 0.269905149936676
Batch 3/64 loss: 0.2844874858856201
Batch 4/64 loss: 0.2754065990447998
Batch 5/64 loss: 0.2613905668258667
Batch 6/64 loss: 0.27804362773895264
Batch 7/64 loss: 0.26920878887176514
Batch 8/64 loss: 0.2703895568847656
Batch 9/64 loss: 0.27475792169570923
Batch 10/64 loss: 0.2676774859428406
Batch 11/64 loss: 0.2651265859603882
Batch 12/64 loss: 0.276419460773468
Batch 13/64 loss: 0.2679579257965088
Batch 14/64 loss: 0.2730861306190491
Batch 15/64 loss: 0.26988494396209717
Batch 16/64 loss: 0.2776632308959961
Batch 17/64 loss: 0.26487696170806885
Batch 18/64 loss: 0.2678961157798767
Batch 19/64 loss: 0.2754577398300171
Batch 20/64 loss: 0.2679044008255005
Batch 21/64 loss: 0.271142840385437
Batch 22/64 loss: 0.26964110136032104
Batch 23/64 loss: 0.2754654288291931
Batch 24/64 loss: 0.2764591574668884
Batch 25/64 loss: 0.2671177387237549
Batch 26/64 loss: 0.2741962671279907
Batch 27/64 loss: 0.2734646797180176
Batch 28/64 loss: 0.277535080909729
Batch 29/64 loss: 0.2665226459503174
Batch 30/64 loss: 0.27469170093536377
Batch 31/64 loss: 0.27148836851119995
Batch 32/64 loss: 0.26930612325668335
Batch 33/64 loss: 0.2647634744644165
Batch 34/64 loss: 0.27528882026672363
Batch 35/64 loss: 0.27134257555007935
Batch 36/64 loss: 0.25943052768707275
Batch 37/64 loss: 0.26840633153915405
Batch 38/64 loss: 0.2677116394042969
Batch 39/64 loss: 0.2719648480415344
Batch 40/64 loss: 0.265399694442749
Batch 41/64 loss: 0.2663285732269287
Batch 42/64 loss: 0.2744787931442261
Batch 43/64 loss: 0.27587878704071045
Batch 44/64 loss: 0.270904541015625
Batch 45/64 loss: 0.27123093605041504
Batch 46/64 loss: 0.27093982696533203
Batch 47/64 loss: 0.2730675935745239
Batch 48/64 loss: 0.27022016048431396
Batch 49/64 loss: 0.2779526710510254
Batch 50/64 loss: 0.2692713141441345
Batch 51/64 loss: 0.2802455425262451
Batch 52/64 loss: 0.2708374261856079
Batch 53/64 loss: 0.2711825370788574
Batch 54/64 loss: 0.283489465713501
Batch 55/64 loss: 0.2790171504020691
Batch 56/64 loss: 0.268429160118103
Batch 57/64 loss: 0.2789955139160156
Batch 58/64 loss: 0.2714627981185913
Batch 59/64 loss: 0.27601510286331177
Batch 60/64 loss: 0.2768678069114685
Batch 61/64 loss: 0.27147579193115234
Batch 62/64 loss: 0.2725057601928711
Batch 63/64 loss: 0.276708722114563
Batch 64/64 loss: 0.26899611949920654
Epoch 350  Train loss: 0.27207533378227083  Val loss: 0.31200602210264433
Epoch 351
-------------------------------
Batch 1/64 loss: 0.276078462600708
Batch 2/64 loss: 0.2674804925918579
Batch 3/64 loss: 0.26271355152130127
Batch 4/64 loss: 0.26406335830688477
Batch 5/64 loss: 0.2712057828903198
Batch 6/64 loss: 0.2703516483306885
Batch 7/64 loss: 0.2678235173225403
Batch 8/64 loss: 0.2745034098625183
Batch 9/64 loss: 0.27603012323379517
Batch 10/64 loss: 0.2806398868560791
Batch 11/64 loss: 0.2743145823478699
Batch 12/64 loss: 0.2649754285812378
Batch 13/64 loss: 0.2710549831390381
Batch 14/64 loss: 0.27233439683914185
Batch 15/64 loss: 0.2666682004928589
Batch 16/64 loss: 0.2706148624420166
Batch 17/64 loss: 0.26925981044769287
Batch 18/64 loss: 0.26983898878097534
Batch 19/64 loss: 0.2791147232055664
Batch 20/64 loss: 0.2657804489135742
Batch 21/64 loss: 0.2663952708244324
Batch 22/64 loss: 0.2754642963409424
Batch 23/64 loss: 0.27130448818206787
Batch 24/64 loss: 0.27383875846862793
Batch 25/64 loss: 0.2664257884025574
Batch 26/64 loss: 0.27319490909576416
Batch 27/64 loss: 0.2664823532104492
Batch 28/64 loss: 0.26921671628952026
Batch 29/64 loss: 0.27044057846069336
Batch 30/64 loss: 0.2667195796966553
Batch 31/64 loss: 0.27786874771118164
Batch 32/64 loss: 0.26794862747192383
Batch 33/64 loss: 0.2745630145072937
Batch 34/64 loss: 0.2707092761993408
Batch 35/64 loss: 0.272197961807251
Batch 36/64 loss: 0.26642048358917236
Batch 37/64 loss: 0.265952467918396
Batch 38/64 loss: 0.28057628870010376
Batch 39/64 loss: 0.27094119787216187
Batch 40/64 loss: 0.2735656499862671
Batch 41/64 loss: 0.27145713567733765
Batch 42/64 loss: 0.276688814163208
Batch 43/64 loss: 0.2761229872703552
Batch 44/64 loss: 0.2775261402130127
Batch 45/64 loss: 0.2783334255218506
Batch 46/64 loss: 0.26990199089050293
Batch 47/64 loss: 0.2707764506340027
Batch 48/64 loss: 0.27378159761428833
Batch 49/64 loss: 0.27110570669174194
Batch 50/64 loss: 0.2748173475265503
Batch 51/64 loss: 0.27748584747314453
Batch 52/64 loss: 0.27104073762893677
Batch 53/64 loss: 0.26844322681427
Batch 54/64 loss: 0.27489757537841797
Batch 55/64 loss: 0.26716285943984985
Batch 56/64 loss: 0.2678971290588379
Batch 57/64 loss: 0.26502370834350586
Batch 58/64 loss: 0.27374064922332764
Batch 59/64 loss: 0.26627016067504883
Batch 60/64 loss: 0.26758837699890137
Batch 61/64 loss: 0.27603214979171753
Batch 62/64 loss: 0.2751610279083252
Batch 63/64 loss: 0.27417731285095215
Batch 64/64 loss: 0.2695420980453491
Epoch 351  Train loss: 0.27141430658452653  Val loss: 0.31248610269572724
Epoch 352
-------------------------------
Batch 1/64 loss: 0.2681180238723755
Batch 2/64 loss: 0.2723116874694824
Batch 3/64 loss: 0.2724497318267822
Batch 4/64 loss: 0.270180344581604
Batch 5/64 loss: 0.27100056409835815
Batch 6/64 loss: 0.27403998374938965
Batch 7/64 loss: 0.2691582441329956
Batch 8/64 loss: 0.2696053981781006
Batch 9/64 loss: 0.2718239426612854
Batch 10/64 loss: 0.2701296806335449
Batch 11/64 loss: 0.2740393877029419
Batch 12/64 loss: 0.27758854627609253
Batch 13/64 loss: 0.26537948846817017
Batch 14/64 loss: 0.26857471466064453
Batch 15/64 loss: 0.26877790689468384
Batch 16/64 loss: 0.2697279453277588
Batch 17/64 loss: 0.27112072706222534
Batch 18/64 loss: 0.27491897344589233
Batch 19/64 loss: 0.2698749899864197
Batch 20/64 loss: 0.2702351212501526
Batch 21/64 loss: 0.270271360874176
Batch 22/64 loss: 0.26787734031677246
Batch 23/64 loss: 0.27357280254364014
Batch 24/64 loss: 0.2688414454460144
Batch 25/64 loss: 0.2607119679450989
Batch 26/64 loss: 0.2696031928062439
Batch 27/64 loss: 0.2730616331100464
Batch 28/64 loss: 0.2706695795059204
Batch 29/64 loss: 0.2657814025878906
Batch 30/64 loss: 0.27207422256469727
Batch 31/64 loss: 0.2626480460166931
Batch 32/64 loss: 0.2738809585571289
Batch 33/64 loss: 0.26526546478271484
Batch 34/64 loss: 0.2699580192565918
Batch 35/64 loss: 0.27332425117492676
Batch 36/64 loss: 0.2695217728614807
Batch 37/64 loss: 0.274654746055603
Batch 38/64 loss: 0.2727154493331909
Batch 39/64 loss: 0.273251473903656
Batch 40/64 loss: 0.2739294767379761
Batch 41/64 loss: 0.26563727855682373
Batch 42/64 loss: 0.27351510524749756
Batch 43/64 loss: 0.2711670398712158
Batch 44/64 loss: 0.27320611476898193
Batch 45/64 loss: 0.2762272357940674
Batch 46/64 loss: 0.2808215618133545
Batch 47/64 loss: 0.2736095190048218
Batch 48/64 loss: 0.27227866649627686
Batch 49/64 loss: 0.2750617265701294
Batch 50/64 loss: 0.2655109167098999
Batch 51/64 loss: 0.26664984226226807
Batch 52/64 loss: 0.268171489238739
Batch 53/64 loss: 0.27754783630371094
Batch 54/64 loss: 0.2726595997810364
Batch 55/64 loss: 0.2686539888381958
Batch 56/64 loss: 0.2686190605163574
Batch 57/64 loss: 0.27421194314956665
Batch 58/64 loss: 0.2773095369338989
Batch 59/64 loss: 0.2772291898727417
Batch 60/64 loss: 0.27280813455581665
Batch 61/64 loss: 0.27418243885040283
Batch 62/64 loss: 0.2730627655982971
Batch 63/64 loss: 0.2716178894042969
Batch 64/64 loss: 0.27222204208374023
Epoch 352  Train loss: 0.27128777129977355  Val loss: 0.3128357826639287
Epoch 353
-------------------------------
Batch 1/64 loss: 0.27002906799316406
Batch 2/64 loss: 0.2715778350830078
Batch 3/64 loss: 0.2773336172103882
Batch 4/64 loss: 0.2713806629180908
Batch 5/64 loss: 0.2689257264137268
Batch 6/64 loss: 0.2695356607437134
Batch 7/64 loss: 0.272940456867218
Batch 8/64 loss: 0.26687705516815186
Batch 9/64 loss: 0.27637457847595215
Batch 10/64 loss: 0.2677675485610962
Batch 11/64 loss: 0.2668790817260742
Batch 12/64 loss: 0.27045178413391113
Batch 13/64 loss: 0.271165132522583
Batch 14/64 loss: 0.26186633110046387
Batch 15/64 loss: 0.26842939853668213
Batch 16/64 loss: 0.2794700860977173
Batch 17/64 loss: 0.26713669300079346
Batch 18/64 loss: 0.28240662813186646
Batch 19/64 loss: 0.2658635973930359
Batch 20/64 loss: 0.27307063341140747
Batch 21/64 loss: 0.2739431858062744
Batch 22/64 loss: 0.2706104516983032
Batch 23/64 loss: 0.27397990226745605
Batch 24/64 loss: 0.27697181701660156
Batch 25/64 loss: 0.26965510845184326
Batch 26/64 loss: 0.26967567205429077
Batch 27/64 loss: 0.27162444591522217
Batch 28/64 loss: 0.26665401458740234
Batch 29/64 loss: 0.26854372024536133
Batch 30/64 loss: 0.26937174797058105
Batch 31/64 loss: 0.27216148376464844
Batch 32/64 loss: 0.2659204602241516
Batch 33/64 loss: 0.2685662508010864
Batch 34/64 loss: 0.2676306962966919
Batch 35/64 loss: 0.28004956245422363
Batch 36/64 loss: 0.2734711170196533
Batch 37/64 loss: 0.2651042938232422
Batch 38/64 loss: 0.2835683822631836
Batch 39/64 loss: 0.2650190591812134
Batch 40/64 loss: 0.26759302616119385
Batch 41/64 loss: 0.2744578719139099
Batch 42/64 loss: 0.27605748176574707
Batch 43/64 loss: 0.26595330238342285
Batch 44/64 loss: 0.26824188232421875
Batch 45/64 loss: 0.26714205741882324
Batch 46/64 loss: 0.2702763080596924
Batch 47/64 loss: 0.27322906255722046
Batch 48/64 loss: 0.27468347549438477
Batch 49/64 loss: 0.2741971015930176
Batch 50/64 loss: 0.2655736207962036
Batch 51/64 loss: 0.26674342155456543
Batch 52/64 loss: 0.2700958251953125
Batch 53/64 loss: 0.2735166549682617
Batch 54/64 loss: 0.2792200446128845
Batch 55/64 loss: 0.2689639925956726
Batch 56/64 loss: 0.2786291241645813
Batch 57/64 loss: 0.26394468545913696
Batch 58/64 loss: 0.2736441493034363
Batch 59/64 loss: 0.2757631540298462
Batch 60/64 loss: 0.26294195652008057
Batch 61/64 loss: 0.2698150873184204
Batch 62/64 loss: 0.27132052183151245
Batch 63/64 loss: 0.2723380923271179
Batch 64/64 loss: 0.2724536657333374
Epoch 353  Train loss: 0.27106957014869243  Val loss: 0.31170735572211933
Epoch 354
-------------------------------
Batch 1/64 loss: 0.26251649856567383
Batch 2/64 loss: 0.27346277236938477
Batch 3/64 loss: 0.26578569412231445
Batch 4/64 loss: 0.2711617350578308
Batch 5/64 loss: 0.2743989825248718
Batch 6/64 loss: 0.2634558081626892
Batch 7/64 loss: 0.2741921544075012
Batch 8/64 loss: 0.27212369441986084
Batch 9/64 loss: 0.2676392197608948
Batch 10/64 loss: 0.26886677742004395
Batch 11/64 loss: 0.26482272148132324
Batch 12/64 loss: 0.27311450242996216
Batch 13/64 loss: 0.2673414945602417
Batch 14/64 loss: 0.2669095993041992
Batch 15/64 loss: 0.2779339551925659
Batch 16/64 loss: 0.27404820919036865
Batch 17/64 loss: 0.2730761766433716
Batch 18/64 loss: 0.26574647426605225
Batch 19/64 loss: 0.2753334045410156
Batch 20/64 loss: 0.27499037981033325
Batch 21/64 loss: 0.26903945207595825
Batch 22/64 loss: 0.26954495906829834
Batch 23/64 loss: 0.2703409790992737
Batch 24/64 loss: 0.27336668968200684
Batch 25/64 loss: 0.2691831588745117
Batch 26/64 loss: 0.27673494815826416
Batch 27/64 loss: 0.27789998054504395
Batch 28/64 loss: 0.2669817805290222
Batch 29/64 loss: 0.27269822359085083
Batch 30/64 loss: 0.2743651866912842
Batch 31/64 loss: 0.26687759160995483
Batch 32/64 loss: 0.2697969675064087
Batch 33/64 loss: 0.2705526351928711
Batch 34/64 loss: 0.26651787757873535
Batch 35/64 loss: 0.2749602794647217
Batch 36/64 loss: 0.2650327682495117
Batch 37/64 loss: 0.2721361517906189
Batch 38/64 loss: 0.27028322219848633
Batch 39/64 loss: 0.2646857500076294
Batch 40/64 loss: 0.2741308808326721
Batch 41/64 loss: 0.2772369384765625
Batch 42/64 loss: 0.269928514957428
Batch 43/64 loss: 0.2650078535079956
Batch 44/64 loss: 0.26914554834365845
Batch 45/64 loss: 0.2759246230125427
Batch 46/64 loss: 0.26754146814346313
Batch 47/64 loss: 0.2643098831176758
Batch 48/64 loss: 0.27004432678222656
Batch 49/64 loss: 0.2683398723602295
Batch 50/64 loss: 0.28173625469207764
Batch 51/64 loss: 0.27325689792633057
Batch 52/64 loss: 0.2745656967163086
Batch 53/64 loss: 0.2745285630226135
Batch 54/64 loss: 0.2674204111099243
Batch 55/64 loss: 0.2681293487548828
Batch 56/64 loss: 0.27287745475769043
Batch 57/64 loss: 0.26835131645202637
Batch 58/64 loss: 0.28245478868484497
Batch 59/64 loss: 0.27041691541671753
Batch 60/64 loss: 0.26958370208740234
Batch 61/64 loss: 0.273343026638031
Batch 62/64 loss: 0.2697935104370117
Batch 63/64 loss: 0.274652361869812
Batch 64/64 loss: 0.28616100549697876
Epoch 354  Train loss: 0.2711413296998716  Val loss: 0.31256295704759685
Epoch 355
-------------------------------
Batch 1/64 loss: 0.2739158868789673
Batch 2/64 loss: 0.2673165798187256
Batch 3/64 loss: 0.27016061544418335
Batch 4/64 loss: 0.26341962814331055
Batch 5/64 loss: 0.26039087772369385
Batch 6/64 loss: 0.26983267068862915
Batch 7/64 loss: 0.27789199352264404
Batch 8/64 loss: 0.2714281678199768
Batch 9/64 loss: 0.2720506191253662
Batch 10/64 loss: 0.2784457206726074
Batch 11/64 loss: 0.2682178020477295
Batch 12/64 loss: 0.2827313542366028
Batch 13/64 loss: 0.27165329456329346
Batch 14/64 loss: 0.26806050539016724
Batch 15/64 loss: 0.26974213123321533
Batch 16/64 loss: 0.26912379264831543
Batch 17/64 loss: 0.2757350206375122
Batch 18/64 loss: 0.2719864845275879
Batch 19/64 loss: 0.2743568420410156
Batch 20/64 loss: 0.28455889225006104
Batch 21/64 loss: 0.2679187059402466
Batch 22/64 loss: 0.2684807777404785
Batch 23/64 loss: 0.27216988801956177
Batch 24/64 loss: 0.27244508266448975
Batch 25/64 loss: 0.2718871831893921
Batch 26/64 loss: 0.2660742998123169
Batch 27/64 loss: 0.2707822322845459
Batch 28/64 loss: 0.2726403474807739
Batch 29/64 loss: 0.2753875255584717
Batch 30/64 loss: 0.2766569256782532
Batch 31/64 loss: 0.2678799629211426
Batch 32/64 loss: 0.27248746156692505
Batch 33/64 loss: 0.2732924222946167
Batch 34/64 loss: 0.26976239681243896
Batch 35/64 loss: 0.27848172187805176
Batch 36/64 loss: 0.2660456895828247
Batch 37/64 loss: 0.2728571891784668
Batch 38/64 loss: 0.274833619594574
Batch 39/64 loss: 0.26967954635620117
Batch 40/64 loss: 0.2711408734321594
Batch 41/64 loss: 0.2646203637123108
Batch 42/64 loss: 0.27336740493774414
Batch 43/64 loss: 0.276092529296875
Batch 44/64 loss: 0.27165842056274414
Batch 45/64 loss: 0.2673066258430481
Batch 46/64 loss: 0.2697567343711853
Batch 47/64 loss: 0.2718891501426697
Batch 48/64 loss: 0.2716078758239746
Batch 49/64 loss: 0.27164340019226074
Batch 50/64 loss: 0.2745707035064697
Batch 51/64 loss: 0.268476665019989
Batch 52/64 loss: 0.2872595191001892
Batch 53/64 loss: 0.2730621099472046
Batch 54/64 loss: 0.26992565393447876
Batch 55/64 loss: 0.2709120512008667
Batch 56/64 loss: 0.280312716960907
Batch 57/64 loss: 0.26368939876556396
Batch 58/64 loss: 0.2705540060997009
Batch 59/64 loss: 0.26660358905792236
Batch 60/64 loss: 0.27236998081207275
Batch 61/64 loss: 0.2663651704788208
Batch 62/64 loss: 0.2630345821380615
Batch 63/64 loss: 0.2700563073158264
Batch 64/64 loss: 0.27161920070648193
Epoch 355  Train loss: 0.2715415229984358  Val loss: 0.3119811241569388
Epoch 356
-------------------------------
Batch 1/64 loss: 0.26830339431762695
Batch 2/64 loss: 0.27683526277542114
Batch 3/64 loss: 0.26509642601013184
Batch 4/64 loss: 0.277835488319397
Batch 5/64 loss: 0.2749747037887573
Batch 6/64 loss: 0.26692473888397217
Batch 7/64 loss: 0.26604002714157104
Batch 8/64 loss: 0.271889328956604
Batch 9/64 loss: 0.274924635887146
Batch 10/64 loss: 0.2694181203842163
Batch 11/64 loss: 0.2686834931373596
Batch 12/64 loss: 0.2631441354751587
Batch 13/64 loss: 0.26897430419921875
Batch 14/64 loss: 0.26593780517578125
Batch 15/64 loss: 0.27176833152770996
Batch 16/64 loss: 0.2697967290878296
Batch 17/64 loss: 0.2724195718765259
Batch 18/64 loss: 0.2622458338737488
Batch 19/64 loss: 0.2691822648048401
Batch 20/64 loss: 0.27066898345947266
Batch 21/64 loss: 0.27019762992858887
Batch 22/64 loss: 0.2706449627876282
Batch 23/64 loss: 0.26792263984680176
Batch 24/64 loss: 0.27529048919677734
Batch 25/64 loss: 0.2660562992095947
Batch 26/64 loss: 0.27335280179977417
Batch 27/64 loss: 0.26638638973236084
Batch 28/64 loss: 0.2766122817993164
Batch 29/64 loss: 0.27580487728118896
Batch 30/64 loss: 0.2643805742263794
Batch 31/64 loss: 0.2625002861022949
Batch 32/64 loss: 0.27010881900787354
Batch 33/64 loss: 0.27230799198150635
Batch 34/64 loss: 0.26457470655441284
Batch 35/64 loss: 0.26913946866989136
Batch 36/64 loss: 0.2722738981246948
Batch 37/64 loss: 0.2767218351364136
Batch 38/64 loss: 0.2712579369544983
Batch 39/64 loss: 0.27846866846084595
Batch 40/64 loss: 0.271048367023468
Batch 41/64 loss: 0.2718368172645569
Batch 42/64 loss: 0.2749190330505371
Batch 43/64 loss: 0.2673501968383789
Batch 44/64 loss: 0.27441632747650146
Batch 45/64 loss: 0.26986169815063477
Batch 46/64 loss: 0.27228355407714844
Batch 47/64 loss: 0.27054107189178467
Batch 48/64 loss: 0.2730175256729126
Batch 49/64 loss: 0.27265483140945435
Batch 50/64 loss: 0.2775711417198181
Batch 51/64 loss: 0.2678302526473999
Batch 52/64 loss: 0.27334630489349365
Batch 53/64 loss: 0.2703070640563965
Batch 54/64 loss: 0.27134597301483154
Batch 55/64 loss: 0.2661178708076477
Batch 56/64 loss: 0.26967859268188477
Batch 57/64 loss: 0.2786058783531189
Batch 58/64 loss: 0.2707570791244507
Batch 59/64 loss: 0.27150917053222656
Batch 60/64 loss: 0.27102237939834595
Batch 61/64 loss: 0.26439863443374634
Batch 62/64 loss: 0.2703615427017212
Batch 63/64 loss: 0.27115923166275024
Batch 64/64 loss: 0.2694993019104004
Epoch 356  Train loss: 0.2706373513913622  Val loss: 0.31226248429812925
Epoch 357
-------------------------------
Batch 1/64 loss: 0.2712440490722656
Batch 2/64 loss: 0.2759624123573303
Batch 3/64 loss: 0.2698381543159485
Batch 4/64 loss: 0.27158886194229126
Batch 5/64 loss: 0.27536094188690186
Batch 6/64 loss: 0.2692667245864868
Batch 7/64 loss: 0.26631391048431396
Batch 8/64 loss: 0.2701491117477417
Batch 9/64 loss: 0.26717376708984375
Batch 10/64 loss: 0.2732001543045044
Batch 11/64 loss: 0.2688979506492615
Batch 12/64 loss: 0.26770246028900146
Batch 13/64 loss: 0.2671900987625122
Batch 14/64 loss: 0.2648584842681885
Batch 15/64 loss: 0.269858717918396
Batch 16/64 loss: 0.2641887664794922
Batch 17/64 loss: 0.2715425491333008
Batch 18/64 loss: 0.27413952350616455
Batch 19/64 loss: 0.26478302478790283
Batch 20/64 loss: 0.26373594999313354
Batch 21/64 loss: 0.26337194442749023
Batch 22/64 loss: 0.272080659866333
Batch 23/64 loss: 0.2723008394241333
Batch 24/64 loss: 0.26600122451782227
Batch 25/64 loss: 0.2737334370613098
Batch 26/64 loss: 0.2682152986526489
Batch 27/64 loss: 0.2734043598175049
Batch 28/64 loss: 0.2698768377304077
Batch 29/64 loss: 0.2694035768508911
Batch 30/64 loss: 0.27488911151885986
Batch 31/64 loss: 0.26959091424942017
Batch 32/64 loss: 0.27673959732055664
Batch 33/64 loss: 0.27437424659729004
Batch 34/64 loss: 0.2827261686325073
Batch 35/64 loss: 0.2705182433128357
Batch 36/64 loss: 0.2676019072532654
Batch 37/64 loss: 0.2695150375366211
Batch 38/64 loss: 0.2719680070877075
Batch 39/64 loss: 0.2662086486816406
Batch 40/64 loss: 0.2737792134284973
Batch 41/64 loss: 0.26726245880126953
Batch 42/64 loss: 0.28182530403137207
Batch 43/64 loss: 0.27382564544677734
Batch 44/64 loss: 0.27770447731018066
Batch 45/64 loss: 0.28116101026535034
Batch 46/64 loss: 0.2700710892677307
Batch 47/64 loss: 0.27256226539611816
Batch 48/64 loss: 0.2712562084197998
Batch 49/64 loss: 0.2642221450805664
Batch 50/64 loss: 0.2683299779891968
Batch 51/64 loss: 0.267808198928833
Batch 52/64 loss: 0.27621549367904663
Batch 53/64 loss: 0.26789021492004395
Batch 54/64 loss: 0.27169597148895264
Batch 55/64 loss: 0.26934361457824707
Batch 56/64 loss: 0.27037179470062256
Batch 57/64 loss: 0.27251923084259033
Batch 58/64 loss: 0.2711547613143921
Batch 59/64 loss: 0.2695988416671753
Batch 60/64 loss: 0.2727206349372864
Batch 61/64 loss: 0.2699097990989685
Batch 62/64 loss: 0.2769606113433838
Batch 63/64 loss: 0.27673256397247314
Batch 64/64 loss: 0.27638381719589233
Epoch 357  Train loss: 0.2710858833556082  Val loss: 0.3130411098093511
Epoch 358
-------------------------------
Batch 1/64 loss: 0.27064192295074463
Batch 2/64 loss: 0.2630448341369629
Batch 3/64 loss: 0.2769928574562073
Batch 4/64 loss: 0.2724763751029968
Batch 5/64 loss: 0.26884496212005615
Batch 6/64 loss: 0.27468740940093994
Batch 7/64 loss: 0.2658666968345642
Batch 8/64 loss: 0.2689440846443176
Batch 9/64 loss: 0.2767722010612488
Batch 10/64 loss: 0.27551841735839844
Batch 11/64 loss: 0.27549248933792114
Batch 12/64 loss: 0.264553427696228
Batch 13/64 loss: 0.26720595359802246
Batch 14/64 loss: 0.26954346895217896
Batch 15/64 loss: 0.2778552174568176
Batch 16/64 loss: 0.2633082866668701
Batch 17/64 loss: 0.27548789978027344
Batch 18/64 loss: 0.27698683738708496
Batch 19/64 loss: 0.26784563064575195
Batch 20/64 loss: 0.2754424214363098
Batch 21/64 loss: 0.27373695373535156
Batch 22/64 loss: 0.27215778827667236
Batch 23/64 loss: 0.2703997492790222
Batch 24/64 loss: 0.2688705325126648
Batch 25/64 loss: 0.2682006359100342
Batch 26/64 loss: 0.2701714038848877
Batch 27/64 loss: 0.2643214464187622
Batch 28/64 loss: 0.2699570059776306
Batch 29/64 loss: 0.2676272988319397
Batch 30/64 loss: 0.2736748456954956
Batch 31/64 loss: 0.2643800973892212
Batch 32/64 loss: 0.2746759057044983
Batch 33/64 loss: 0.2795204520225525
Batch 34/64 loss: 0.26722031831741333
Batch 35/64 loss: 0.2827073335647583
Batch 36/64 loss: 0.2725551128387451
Batch 37/64 loss: 0.2726949453353882
Batch 38/64 loss: 0.26758384704589844
Batch 39/64 loss: 0.27482402324676514
Batch 40/64 loss: 0.2763349413871765
Batch 41/64 loss: 0.2710402011871338
Batch 42/64 loss: 0.2737276554107666
Batch 43/64 loss: 0.26912808418273926
Batch 44/64 loss: 0.2729675769805908
Batch 45/64 loss: 0.2794564962387085
Batch 46/64 loss: 0.26856881380081177
Batch 47/64 loss: 0.26513171195983887
Batch 48/64 loss: 0.27770382165908813
Batch 49/64 loss: 0.2688337564468384
Batch 50/64 loss: 0.2706584930419922
Batch 51/64 loss: 0.269944429397583
Batch 52/64 loss: 0.26741594076156616
Batch 53/64 loss: 0.2693249583244324
Batch 54/64 loss: 0.2679178714752197
Batch 55/64 loss: 0.27225011587142944
Batch 56/64 loss: 0.27612847089767456
Batch 57/64 loss: 0.2723337411880493
Batch 58/64 loss: 0.2673182487487793
Batch 59/64 loss: 0.26762837171554565
Batch 60/64 loss: 0.2737886905670166
Batch 61/64 loss: 0.269170880317688
Batch 62/64 loss: 0.2699018716812134
Batch 63/64 loss: 0.2705203890800476
Batch 64/64 loss: 0.2642221450805664
Epoch 358  Train loss: 0.2711867173512777  Val loss: 0.3115776560150881
Epoch 359
-------------------------------
Batch 1/64 loss: 0.2674768567085266
Batch 2/64 loss: 0.2682044506072998
Batch 3/64 loss: 0.26915204524993896
Batch 4/64 loss: 0.27298080921173096
Batch 5/64 loss: 0.26965171098709106
Batch 6/64 loss: 0.26835328340530396
Batch 7/64 loss: 0.2704881429672241
Batch 8/64 loss: 0.2657780647277832
Batch 9/64 loss: 0.26425957679748535
Batch 10/64 loss: 0.2671787738800049
Batch 11/64 loss: 0.27248865365982056
Batch 12/64 loss: 0.2778007984161377
Batch 13/64 loss: 0.27392709255218506
Batch 14/64 loss: 0.26557594537734985
Batch 15/64 loss: 0.276605486869812
Batch 16/64 loss: 0.2730882167816162
Batch 17/64 loss: 0.2800755500793457
Batch 18/64 loss: 0.27059221267700195
Batch 19/64 loss: 0.27088671922683716
Batch 20/64 loss: 0.2676657438278198
Batch 21/64 loss: 0.2736494541168213
Batch 22/64 loss: 0.27420973777770996
Batch 23/64 loss: 0.27132219076156616
Batch 24/64 loss: 0.26953840255737305
Batch 25/64 loss: 0.27087271213531494
Batch 26/64 loss: 0.2668408155441284
Batch 27/64 loss: 0.2692941427230835
Batch 28/64 loss: 0.27209705114364624
Batch 29/64 loss: 0.26675111055374146
Batch 30/64 loss: 0.27188539505004883
Batch 31/64 loss: 0.2695615291595459
Batch 32/64 loss: 0.27283573150634766
Batch 33/64 loss: 0.27702200412750244
Batch 34/64 loss: 0.2666487693786621
Batch 35/64 loss: 0.265819787979126
Batch 36/64 loss: 0.27143800258636475
Batch 37/64 loss: 0.27553629875183105
Batch 38/64 loss: 0.2680318355560303
Batch 39/64 loss: 0.28177982568740845
Batch 40/64 loss: 0.26904404163360596
Batch 41/64 loss: 0.2647054195404053
Batch 42/64 loss: 0.270538330078125
Batch 43/64 loss: 0.2684118151664734
Batch 44/64 loss: 0.27624809741973877
Batch 45/64 loss: 0.2815256714820862
Batch 46/64 loss: 0.2743377685546875
Batch 47/64 loss: 0.2690727710723877
Batch 48/64 loss: 0.26259154081344604
Batch 49/64 loss: 0.27386415004730225
Batch 50/64 loss: 0.27490103244781494
Batch 51/64 loss: 0.2705346345901489
Batch 52/64 loss: 0.2682846784591675
Batch 53/64 loss: 0.26613950729370117
Batch 54/64 loss: 0.27581048011779785
Batch 55/64 loss: 0.2627737522125244
Batch 56/64 loss: 0.28009259700775146
Batch 57/64 loss: 0.2690002918243408
Batch 58/64 loss: 0.266022264957428
Batch 59/64 loss: 0.2730558514595032
Batch 60/64 loss: 0.2625870108604431
Batch 61/64 loss: 0.2675973176956177
Batch 62/64 loss: 0.2736806869506836
Batch 63/64 loss: 0.28099435567855835
Batch 64/64 loss: 0.27494263648986816
Epoch 359  Train loss: 0.2709864466798072  Val loss: 0.3124248162167998
Epoch 360
-------------------------------
Batch 1/64 loss: 0.27498650550842285
Batch 2/64 loss: 0.2668635845184326
Batch 3/64 loss: 0.2725231647491455
Batch 4/64 loss: 0.27917659282684326
Batch 5/64 loss: 0.27853894233703613
Batch 6/64 loss: 0.27932167053222656
Batch 7/64 loss: 0.2669942378997803
Batch 8/64 loss: 0.2753413915634155
Batch 9/64 loss: 0.2690524458885193
Batch 10/64 loss: 0.2790129780769348
Batch 11/64 loss: 0.26573193073272705
Batch 12/64 loss: 0.28027719259262085
Batch 13/64 loss: 0.26251208782196045
Batch 14/64 loss: 0.2708277106285095
Batch 15/64 loss: 0.2681107521057129
Batch 16/64 loss: 0.2683119773864746
Batch 17/64 loss: 0.27197879552841187
Batch 18/64 loss: 0.26528167724609375
Batch 19/64 loss: 0.26693975925445557
Batch 20/64 loss: 0.2736983895301819
Batch 21/64 loss: 0.2671624422073364
Batch 22/64 loss: 0.27176129817962646
Batch 23/64 loss: 0.2719663381576538
Batch 24/64 loss: 0.26542556285858154
Batch 25/64 loss: 0.26717591285705566
Batch 26/64 loss: 0.2707192897796631
Batch 27/64 loss: 0.2750890851020813
Batch 28/64 loss: 0.27060621976852417
Batch 29/64 loss: 0.26701605319976807
Batch 30/64 loss: 0.26988130807876587
Batch 31/64 loss: 0.2641267776489258
Batch 32/64 loss: 0.2697354555130005
Batch 33/64 loss: 0.26839137077331543
Batch 34/64 loss: 0.26175230741500854
Batch 35/64 loss: 0.2668021321296692
Batch 36/64 loss: 0.27396225929260254
Batch 37/64 loss: 0.276231586933136
Batch 38/64 loss: 0.2684764266014099
Batch 39/64 loss: 0.26736968755722046
Batch 40/64 loss: 0.2645259499549866
Batch 41/64 loss: 0.2698415517807007
Batch 42/64 loss: 0.2713068723678589
Batch 43/64 loss: 0.26987868547439575
Batch 44/64 loss: 0.26858699321746826
Batch 45/64 loss: 0.2720884084701538
Batch 46/64 loss: 0.2703940272331238
Batch 47/64 loss: 0.26844125986099243
Batch 48/64 loss: 0.26779335737228394
Batch 49/64 loss: 0.2718616724014282
Batch 50/64 loss: 0.2654094696044922
Batch 51/64 loss: 0.26945173740386963
Batch 52/64 loss: 0.27136683464050293
Batch 53/64 loss: 0.27149081230163574
Batch 54/64 loss: 0.2712876796722412
Batch 55/64 loss: 0.2740929126739502
Batch 56/64 loss: 0.26504969596862793
Batch 57/64 loss: 0.27153313159942627
Batch 58/64 loss: 0.2735656499862671
Batch 59/64 loss: 0.2772587537765503
Batch 60/64 loss: 0.27169662714004517
Batch 61/64 loss: 0.26209163665771484
Batch 62/64 loss: 0.2697939872741699
Batch 63/64 loss: 0.2674938440322876
Batch 64/64 loss: 0.26927655935287476
Epoch 360  Train loss: 0.2702336042535071  Val loss: 0.31162643084411357
Epoch 361
-------------------------------
Batch 1/64 loss: 0.26251012086868286
Batch 2/64 loss: 0.2621554732322693
Batch 3/64 loss: 0.2748650312423706
Batch 4/64 loss: 0.2600781321525574
Batch 5/64 loss: 0.2696676254272461
Batch 6/64 loss: 0.27320343255996704
Batch 7/64 loss: 0.272937536239624
Batch 8/64 loss: 0.2704008221626282
Batch 9/64 loss: 0.27304375171661377
Batch 10/64 loss: 0.27417248487472534
Batch 11/64 loss: 0.2633824348449707
Batch 12/64 loss: 0.2672271728515625
Batch 13/64 loss: 0.26874232292175293
Batch 14/64 loss: 0.26930487155914307
Batch 15/64 loss: 0.2606865167617798
Batch 16/64 loss: 0.2692664861679077
Batch 17/64 loss: 0.2695624828338623
Batch 18/64 loss: 0.26933789253234863
Batch 19/64 loss: 0.2712504267692566
Batch 20/64 loss: 0.2668781280517578
Batch 21/64 loss: 0.2763698101043701
Batch 22/64 loss: 0.26876282691955566
Batch 23/64 loss: 0.26687854528427124
Batch 24/64 loss: 0.2720414400100708
Batch 25/64 loss: 0.27632349729537964
Batch 26/64 loss: 0.26786959171295166
Batch 27/64 loss: 0.2721989154815674
Batch 28/64 loss: 0.26582181453704834
Batch 29/64 loss: 0.27070075273513794
Batch 30/64 loss: 0.27026069164276123
Batch 31/64 loss: 0.271206259727478
Batch 32/64 loss: 0.2742581367492676
Batch 33/64 loss: 0.2722257375717163
Batch 34/64 loss: 0.2722851037979126
Batch 35/64 loss: 0.2724183201789856
Batch 36/64 loss: 0.2710035443305969
Batch 37/64 loss: 0.2738305330276489
Batch 38/64 loss: 0.2641729712486267
Batch 39/64 loss: 0.26540815830230713
Batch 40/64 loss: 0.2645634412765503
Batch 41/64 loss: 0.2677076458930969
Batch 42/64 loss: 0.27136707305908203
Batch 43/64 loss: 0.26634788513183594
Batch 44/64 loss: 0.26720213890075684
Batch 45/64 loss: 0.26798588037490845
Batch 46/64 loss: 0.2752038836479187
Batch 47/64 loss: 0.2740277647972107
Batch 48/64 loss: 0.26959383487701416
Batch 49/64 loss: 0.270129919052124
Batch 50/64 loss: 0.27025824785232544
Batch 51/64 loss: 0.2705148458480835
Batch 52/64 loss: 0.26639485359191895
Batch 53/64 loss: 0.26827937364578247
Batch 54/64 loss: 0.27349168062210083
Batch 55/64 loss: 0.26929885149002075
Batch 56/64 loss: 0.26357150077819824
Batch 57/64 loss: 0.26824069023132324
Batch 58/64 loss: 0.2736998200416565
Batch 59/64 loss: 0.27548694610595703
Batch 60/64 loss: 0.276777446269989
Batch 61/64 loss: 0.27050673961639404
Batch 62/64 loss: 0.2799485921859741
Batch 63/64 loss: 0.279119610786438
Batch 64/64 loss: 0.27282124757766724
Epoch 361  Train loss: 0.2700712846774681  Val loss: 0.3118624601167502
Epoch 362
-------------------------------
Batch 1/64 loss: 0.26638323068618774
Batch 2/64 loss: 0.2643166780471802
Batch 3/64 loss: 0.26888489723205566
Batch 4/64 loss: 0.2703254818916321
Batch 5/64 loss: 0.27138692140579224
Batch 6/64 loss: 0.27281153202056885
Batch 7/64 loss: 0.2739604115486145
Batch 8/64 loss: 0.2732703685760498
Batch 9/64 loss: 0.2621418833732605
Batch 10/64 loss: 0.27336299419403076
Batch 11/64 loss: 0.2717716693878174
Batch 12/64 loss: 0.2730661630630493
Batch 13/64 loss: 0.26555144786834717
Batch 14/64 loss: 0.2648470401763916
Batch 15/64 loss: 0.26531827449798584
Batch 16/64 loss: 0.26847875118255615
Batch 17/64 loss: 0.2716968059539795
Batch 18/64 loss: 0.2712315320968628
Batch 19/64 loss: 0.2809860110282898
Batch 20/64 loss: 0.265436053276062
Batch 21/64 loss: 0.27413296699523926
Batch 22/64 loss: 0.2663555145263672
Batch 23/64 loss: 0.2713826894760132
Batch 24/64 loss: 0.2676229476928711
Batch 25/64 loss: 0.2623257637023926
Batch 26/64 loss: 0.2757728099822998
Batch 27/64 loss: 0.27823811769485474
Batch 28/64 loss: 0.27203071117401123
Batch 29/64 loss: 0.2737775444984436
Batch 30/64 loss: 0.2716265916824341
Batch 31/64 loss: 0.2664341926574707
Batch 32/64 loss: 0.27149873971939087
Batch 33/64 loss: 0.2776482105255127
Batch 34/64 loss: 0.2744324803352356
Batch 35/64 loss: 0.2659933567047119
Batch 36/64 loss: 0.26958978176116943
Batch 37/64 loss: 0.2674669027328491
Batch 38/64 loss: 0.26695048809051514
Batch 39/64 loss: 0.2696726322174072
Batch 40/64 loss: 0.2775941491127014
Batch 41/64 loss: 0.2705639600753784
Batch 42/64 loss: 0.2736364006996155
Batch 43/64 loss: 0.26825255155563354
Batch 44/64 loss: 0.2664082646369934
Batch 45/64 loss: 0.2733393907546997
Batch 46/64 loss: 0.26923203468322754
Batch 47/64 loss: 0.2681918144226074
Batch 48/64 loss: 0.27778321504592896
Batch 49/64 loss: 0.2743801474571228
Batch 50/64 loss: 0.2721490263938904
Batch 51/64 loss: 0.2656059265136719
Batch 52/64 loss: 0.27411723136901855
Batch 53/64 loss: 0.280004620552063
Batch 54/64 loss: 0.2656543254852295
Batch 55/64 loss: 0.2706265449523926
Batch 56/64 loss: 0.27113038301467896
Batch 57/64 loss: 0.2756255865097046
Batch 58/64 loss: 0.26847386360168457
Batch 59/64 loss: 0.26554030179977417
Batch 60/64 loss: 0.2788926959037781
Batch 61/64 loss: 0.26723170280456543
Batch 62/64 loss: 0.26934826374053955
Batch 63/64 loss: 0.2670170068740845
Batch 64/64 loss: 0.2735365629196167
Epoch 362  Train loss: 0.2706530575658761  Val loss: 0.3117204896363196
Epoch 363
-------------------------------
Batch 1/64 loss: 0.27405500411987305
Batch 2/64 loss: 0.26666688919067383
Batch 3/64 loss: 0.2689588665962219
Batch 4/64 loss: 0.27142268419265747
Batch 5/64 loss: 0.273107647895813
Batch 6/64 loss: 0.27003347873687744
Batch 7/64 loss: 0.26522719860076904
Batch 8/64 loss: 0.2701706886291504
Batch 9/64 loss: 0.2723141312599182
Batch 10/64 loss: 0.27773594856262207
Batch 11/64 loss: 0.26778578758239746
Batch 12/64 loss: 0.2668764591217041
Batch 13/64 loss: 0.2691311836242676
Batch 14/64 loss: 0.26157426834106445
Batch 15/64 loss: 0.27461695671081543
Batch 16/64 loss: 0.27359819412231445
Batch 17/64 loss: 0.27555936574935913
Batch 18/64 loss: 0.2814178466796875
Batch 19/64 loss: 0.26520681381225586
Batch 20/64 loss: 0.26898813247680664
Batch 21/64 loss: 0.2654002904891968
Batch 22/64 loss: 0.275577187538147
Batch 23/64 loss: 0.2779373526573181
Batch 24/64 loss: 0.269462525844574
Batch 25/64 loss: 0.2674494981765747
Batch 26/64 loss: 0.2777214050292969
Batch 27/64 loss: 0.2669282555580139
Batch 28/64 loss: 0.26864099502563477
Batch 29/64 loss: 0.27760839462280273
Batch 30/64 loss: 0.2729068994522095
Batch 31/64 loss: 0.27307963371276855
Batch 32/64 loss: 0.2688749432563782
Batch 33/64 loss: 0.27464306354522705
Batch 34/64 loss: 0.26184046268463135
Batch 35/64 loss: 0.2662566900253296
Batch 36/64 loss: 0.26433050632476807
Batch 37/64 loss: 0.2634570598602295
Batch 38/64 loss: 0.2697751522064209
Batch 39/64 loss: 0.2719830274581909
Batch 40/64 loss: 0.272432804107666
Batch 41/64 loss: 0.2704448103904724
Batch 42/64 loss: 0.2668760418891907
Batch 43/64 loss: 0.2727980613708496
Batch 44/64 loss: 0.2730867862701416
Batch 45/64 loss: 0.27329325675964355
Batch 46/64 loss: 0.2644450068473816
Batch 47/64 loss: 0.26378726959228516
Batch 48/64 loss: 0.2781510353088379
Batch 49/64 loss: 0.27324235439300537
Batch 50/64 loss: 0.26849955320358276
Batch 51/64 loss: 0.2671467065811157
Batch 52/64 loss: 0.26960229873657227
Batch 53/64 loss: 0.2716984152793884
Batch 54/64 loss: 0.2740930914878845
Batch 55/64 loss: 0.27074360847473145
Batch 56/64 loss: 0.2705603837966919
Batch 57/64 loss: 0.2675563097000122
Batch 58/64 loss: 0.2662208080291748
Batch 59/64 loss: 0.28241074085235596
Batch 60/64 loss: 0.26580095291137695
Batch 61/64 loss: 0.26693111658096313
Batch 62/64 loss: 0.27065223455429077
Batch 63/64 loss: 0.2673276662826538
Batch 64/64 loss: 0.2685091495513916
Epoch 363  Train loss: 0.2703922206280278  Val loss: 0.3130149521778539
Epoch 364
-------------------------------
Batch 1/64 loss: 0.2721647024154663
Batch 2/64 loss: 0.2686038017272949
Batch 3/64 loss: 0.2644304037094116
Batch 4/64 loss: 0.2636982202529907
Batch 5/64 loss: 0.26674044132232666
Batch 6/64 loss: 0.27050572633743286
Batch 7/64 loss: 0.26316797733306885
Batch 8/64 loss: 0.25963306427001953
Batch 9/64 loss: 0.26709991693496704
Batch 10/64 loss: 0.2727147936820984
Batch 11/64 loss: 0.26250505447387695
Batch 12/64 loss: 0.2679658532142639
Batch 13/64 loss: 0.27385014295578003
Batch 14/64 loss: 0.27158308029174805
Batch 15/64 loss: 0.2711613178253174
Batch 16/64 loss: 0.2658729553222656
Batch 17/64 loss: 0.2735332250595093
Batch 18/64 loss: 0.27133017778396606
Batch 19/64 loss: 0.27364832162857056
Batch 20/64 loss: 0.26608705520629883
Batch 21/64 loss: 0.271975040435791
Batch 22/64 loss: 0.2872757911682129
Batch 23/64 loss: 0.26512324810028076
Batch 24/64 loss: 0.2730710506439209
Batch 25/64 loss: 0.27052438259124756
Batch 26/64 loss: 0.2700098156929016
Batch 27/64 loss: 0.2669832110404968
Batch 28/64 loss: 0.2680314779281616
Batch 29/64 loss: 0.27397000789642334
Batch 30/64 loss: 0.2698018550872803
Batch 31/64 loss: 0.26604974269866943
Batch 32/64 loss: 0.2765458822250366
Batch 33/64 loss: 0.27019381523132324
Batch 34/64 loss: 0.26161813735961914
Batch 35/64 loss: 0.2708418369293213
Batch 36/64 loss: 0.26283127069473267
Batch 37/64 loss: 0.26370835304260254
Batch 38/64 loss: 0.27283036708831787
Batch 39/64 loss: 0.2672576904296875
Batch 40/64 loss: 0.27435195446014404
Batch 41/64 loss: 0.2630510926246643
Batch 42/64 loss: 0.26535922288894653
Batch 43/64 loss: 0.2724924683570862
Batch 44/64 loss: 0.28162920475006104
Batch 45/64 loss: 0.2736663222312927
Batch 46/64 loss: 0.26313579082489014
Batch 47/64 loss: 0.2740623950958252
Batch 48/64 loss: 0.2747071385383606
Batch 49/64 loss: 0.26780855655670166
Batch 50/64 loss: 0.2730141878128052
Batch 51/64 loss: 0.26915228366851807
Batch 52/64 loss: 0.2693977952003479
Batch 53/64 loss: 0.26525604724884033
Batch 54/64 loss: 0.27312636375427246
Batch 55/64 loss: 0.26932597160339355
Batch 56/64 loss: 0.26897287368774414
Batch 57/64 loss: 0.27065569162368774
Batch 58/64 loss: 0.28266221284866333
Batch 59/64 loss: 0.2633742690086365
Batch 60/64 loss: 0.2664158344268799
Batch 61/64 loss: 0.2666897773742676
Batch 62/64 loss: 0.26517534255981445
Batch 63/64 loss: 0.26905715465545654
Batch 64/64 loss: 0.2668456435203552
Epoch 364  Train loss: 0.2694527590976042  Val loss: 0.31183719041011587
Epoch 365
-------------------------------
Batch 1/64 loss: 0.26827508211135864
Batch 2/64 loss: 0.2740267515182495
Batch 3/64 loss: 0.2654440999031067
Batch 4/64 loss: 0.2664375305175781
Batch 5/64 loss: 0.26805514097213745
Batch 6/64 loss: 0.2761634588241577
Batch 7/64 loss: 0.26510071754455566
Batch 8/64 loss: 0.27261966466903687
Batch 9/64 loss: 0.26597297191619873
Batch 10/64 loss: 0.26431143283843994
Batch 11/64 loss: 0.2740744948387146
Batch 12/64 loss: 0.2660124897956848
Batch 13/64 loss: 0.2690669298171997
Batch 14/64 loss: 0.27055907249450684
Batch 15/64 loss: 0.2668101191520691
Batch 16/64 loss: 0.26643145084381104
Batch 17/64 loss: 0.27315640449523926
Batch 18/64 loss: 0.27291983366012573
Batch 19/64 loss: 0.27020251750946045
Batch 20/64 loss: 0.26099783182144165
Batch 21/64 loss: 0.2703172564506531
Batch 22/64 loss: 0.26348036527633667
Batch 23/64 loss: 0.2670363187789917
Batch 24/64 loss: 0.27202945947647095
Batch 25/64 loss: 0.2694793939590454
Batch 26/64 loss: 0.26833856105804443
Batch 27/64 loss: 0.2716672420501709
Batch 28/64 loss: 0.2752761244773865
Batch 29/64 loss: 0.26374006271362305
Batch 30/64 loss: 0.27000147104263306
Batch 31/64 loss: 0.2659386396408081
Batch 32/64 loss: 0.2668728232383728
Batch 33/64 loss: 0.26495301723480225
Batch 34/64 loss: 0.26415014266967773
Batch 35/64 loss: 0.270715594291687
Batch 36/64 loss: 0.26920729875564575
Batch 37/64 loss: 0.2674481272697449
Batch 38/64 loss: 0.2684720754623413
Batch 39/64 loss: 0.2763636112213135
Batch 40/64 loss: 0.2682870626449585
Batch 41/64 loss: 0.2756200432777405
Batch 42/64 loss: 0.2692731022834778
Batch 43/64 loss: 0.2688945531845093
Batch 44/64 loss: 0.2678665518760681
Batch 45/64 loss: 0.2646200656890869
Batch 46/64 loss: 0.2741849422454834
Batch 47/64 loss: 0.2681618332862854
Batch 48/64 loss: 0.28160321712493896
Batch 49/64 loss: 0.26460617780685425
Batch 50/64 loss: 0.26943284273147583
Batch 51/64 loss: 0.26546651124954224
Batch 52/64 loss: 0.2676469087600708
Batch 53/64 loss: 0.27107763290405273
Batch 54/64 loss: 0.27874356508255005
Batch 55/64 loss: 0.27086639404296875
Batch 56/64 loss: 0.27123403549194336
Batch 57/64 loss: 0.2730256915092468
Batch 58/64 loss: 0.2735499143600464
Batch 59/64 loss: 0.2692922353744507
Batch 60/64 loss: 0.26427245140075684
Batch 61/64 loss: 0.27075886726379395
Batch 62/64 loss: 0.2763556241989136
Batch 63/64 loss: 0.2675110101699829
Batch 64/64 loss: 0.2717776298522949
Epoch 365  Train loss: 0.26946368684955674  Val loss: 0.31156190441236464
Epoch 366
-------------------------------
Batch 1/64 loss: 0.2678731679916382
Batch 2/64 loss: 0.27059412002563477
Batch 3/64 loss: 0.27125251293182373
Batch 4/64 loss: 0.2687644958496094
Batch 5/64 loss: 0.2727894186973572
Batch 6/64 loss: 0.2750328779220581
Batch 7/64 loss: 0.2628391981124878
Batch 8/64 loss: 0.2704044580459595
Batch 9/64 loss: 0.2677544355392456
Batch 10/64 loss: 0.2738204598426819
Batch 11/64 loss: 0.27169132232666016
Batch 12/64 loss: 0.2657622694969177
Batch 13/64 loss: 0.2651955485343933
Batch 14/64 loss: 0.27317821979522705
Batch 15/64 loss: 0.2746124267578125
Batch 16/64 loss: 0.2684798240661621
Batch 17/64 loss: 0.27359282970428467
Batch 18/64 loss: 0.2630155682563782
Batch 19/64 loss: 0.27638864517211914
Batch 20/64 loss: 0.27062904834747314
Batch 21/64 loss: 0.27198469638824463
Batch 22/64 loss: 0.27771544456481934
Batch 23/64 loss: 0.27300751209259033
Batch 24/64 loss: 0.2663711905479431
Batch 25/64 loss: 0.27213960886001587
Batch 26/64 loss: 0.2666838765144348
Batch 27/64 loss: 0.2675963044166565
Batch 28/64 loss: 0.2679632902145386
Batch 29/64 loss: 0.2661811113357544
Batch 30/64 loss: 0.27253949642181396
Batch 31/64 loss: 0.2668505907058716
Batch 32/64 loss: 0.2717869281768799
Batch 33/64 loss: 0.27207767963409424
Batch 34/64 loss: 0.2663435935974121
Batch 35/64 loss: 0.2721062898635864
Batch 36/64 loss: 0.2686738967895508
Batch 37/64 loss: 0.268979549407959
Batch 38/64 loss: 0.26867324113845825
Batch 39/64 loss: 0.2637670040130615
Batch 40/64 loss: 0.26624810695648193
Batch 41/64 loss: 0.26900315284729004
Batch 42/64 loss: 0.27135729789733887
Batch 43/64 loss: 0.2714243531227112
Batch 44/64 loss: 0.27226775884628296
Batch 45/64 loss: 0.26905715465545654
Batch 46/64 loss: 0.2687830924987793
Batch 47/64 loss: 0.2682034969329834
Batch 48/64 loss: 0.26584476232528687
Batch 49/64 loss: 0.26984935998916626
Batch 50/64 loss: 0.2758937478065491
Batch 51/64 loss: 0.2739454507827759
Batch 52/64 loss: 0.26535457372665405
Batch 53/64 loss: 0.2670323848724365
Batch 54/64 loss: 0.27018314599990845
Batch 55/64 loss: 0.2705885171890259
Batch 56/64 loss: 0.2721198797225952
Batch 57/64 loss: 0.2699602246284485
Batch 58/64 loss: 0.27363693714141846
Batch 59/64 loss: 0.27071189880371094
Batch 60/64 loss: 0.2740270495414734
Batch 61/64 loss: 0.26804572343826294
Batch 62/64 loss: 0.2724226117134094
Batch 63/64 loss: 0.2780498266220093
Batch 64/64 loss: 0.26464903354644775
Epoch 366  Train loss: 0.27008014800501806  Val loss: 0.3123928673078924
Epoch 367
-------------------------------
Batch 1/64 loss: 0.2756437659263611
Batch 2/64 loss: 0.2727283239364624
Batch 3/64 loss: 0.26651322841644287
Batch 4/64 loss: 0.2726001739501953
Batch 5/64 loss: 0.2628294825553894
Batch 6/64 loss: 0.2700360417366028
Batch 7/64 loss: 0.27095550298690796
Batch 8/64 loss: 0.2645472288131714
Batch 9/64 loss: 0.2778273820877075
Batch 10/64 loss: 0.26316726207733154
Batch 11/64 loss: 0.2663809657096863
Batch 12/64 loss: 0.27450501918792725
Batch 13/64 loss: 0.26796501874923706
Batch 14/64 loss: 0.2638283967971802
Batch 15/64 loss: 0.26625609397888184
Batch 16/64 loss: 0.2656558156013489
Batch 17/64 loss: 0.27596527338027954
Batch 18/64 loss: 0.2696183919906616
Batch 19/64 loss: 0.27318060398101807
Batch 20/64 loss: 0.2661600708961487
Batch 21/64 loss: 0.2644016742706299
Batch 22/64 loss: 0.27191877365112305
Batch 23/64 loss: 0.2687816023826599
Batch 24/64 loss: 0.2621479034423828
Batch 25/64 loss: 0.26472336053848267
Batch 26/64 loss: 0.26828593015670776
Batch 27/64 loss: 0.27082788944244385
Batch 28/64 loss: 0.2754665017127991
Batch 29/64 loss: 0.2717858552932739
Batch 30/64 loss: 0.27220630645751953
Batch 31/64 loss: 0.2740331292152405
Batch 32/64 loss: 0.26427024602890015
Batch 33/64 loss: 0.2680404782295227
Batch 34/64 loss: 0.2592899203300476
Batch 35/64 loss: 0.2689931392669678
Batch 36/64 loss: 0.26872360706329346
Batch 37/64 loss: 0.27024686336517334
Batch 38/64 loss: 0.2696061134338379
Batch 39/64 loss: 0.270541787147522
Batch 40/64 loss: 0.2747660279273987
Batch 41/64 loss: 0.26911628246307373
Batch 42/64 loss: 0.26852118968963623
Batch 43/64 loss: 0.26723188161849976
Batch 44/64 loss: 0.2698169946670532
Batch 45/64 loss: 0.2684673070907593
Batch 46/64 loss: 0.2680673599243164
Batch 47/64 loss: 0.2652010917663574
Batch 48/64 loss: 0.2724694013595581
Batch 49/64 loss: 0.2763148546218872
Batch 50/64 loss: 0.2648293375968933
Batch 51/64 loss: 0.27135151624679565
Batch 52/64 loss: 0.2730666399002075
Batch 53/64 loss: 0.2746458053588867
Batch 54/64 loss: 0.2704746723175049
Batch 55/64 loss: 0.2689945697784424
Batch 56/64 loss: 0.2659141421318054
Batch 57/64 loss: 0.274746298789978
Batch 58/64 loss: 0.2732717990875244
Batch 59/64 loss: 0.2674133777618408
Batch 60/64 loss: 0.2779492735862732
Batch 61/64 loss: 0.2724161148071289
Batch 62/64 loss: 0.2720072865486145
Batch 63/64 loss: 0.27021604776382446
Batch 64/64 loss: 0.2673231363296509
Epoch 367  Train loss: 0.269622223517474  Val loss: 0.3121974265452513
Epoch 368
-------------------------------
Batch 1/64 loss: 0.274544358253479
Batch 2/64 loss: 0.2744952440261841
Batch 3/64 loss: 0.27020514011383057
Batch 4/64 loss: 0.2700178623199463
Batch 5/64 loss: 0.2616770267486572
Batch 6/64 loss: 0.27436184883117676
Batch 7/64 loss: 0.27613723278045654
Batch 8/64 loss: 0.264518678188324
Batch 9/64 loss: 0.2643693685531616
Batch 10/64 loss: 0.266599178314209
Batch 11/64 loss: 0.26794886589050293
Batch 12/64 loss: 0.26734352111816406
Batch 13/64 loss: 0.2654038667678833
Batch 14/64 loss: 0.27281731367111206
Batch 15/64 loss: 0.2754284143447876
Batch 16/64 loss: 0.2715029716491699
Batch 17/64 loss: 0.2675991654396057
Batch 18/64 loss: 0.269328236579895
Batch 19/64 loss: 0.27566075325012207
Batch 20/64 loss: 0.2658698558807373
Batch 21/64 loss: 0.27297019958496094
Batch 22/64 loss: 0.27487295866012573
Batch 23/64 loss: 0.2690608501434326
Batch 24/64 loss: 0.27469682693481445
Batch 25/64 loss: 0.2690470218658447
Batch 26/64 loss: 0.2754453420639038
Batch 27/64 loss: 0.27071940898895264
Batch 28/64 loss: 0.2715628147125244
Batch 29/64 loss: 0.2748558521270752
Batch 30/64 loss: 0.2648351788520813
Batch 31/64 loss: 0.26168036460876465
Batch 32/64 loss: 0.27103209495544434
Batch 33/64 loss: 0.27041447162628174
Batch 34/64 loss: 0.2694755792617798
Batch 35/64 loss: 0.2646366357803345
Batch 36/64 loss: 0.26475030183792114
Batch 37/64 loss: 0.2711293697357178
Batch 38/64 loss: 0.2735101580619812
Batch 39/64 loss: 0.26611649990081787
Batch 40/64 loss: 0.2715669274330139
Batch 41/64 loss: 0.26173508167266846
Batch 42/64 loss: 0.27038824558258057
Batch 43/64 loss: 0.26930761337280273
Batch 44/64 loss: 0.26611053943634033
Batch 45/64 loss: 0.27250492572784424
Batch 46/64 loss: 0.26495182514190674
Batch 47/64 loss: 0.2612011432647705
Batch 48/64 loss: 0.2670382857322693
Batch 49/64 loss: 0.2697734236717224
Batch 50/64 loss: 0.2658965587615967
Batch 51/64 loss: 0.26982975006103516
Batch 52/64 loss: 0.27016836404800415
Batch 53/64 loss: 0.27036023139953613
Batch 54/64 loss: 0.273328959941864
Batch 55/64 loss: 0.2702767848968506
Batch 56/64 loss: 0.26675355434417725
Batch 57/64 loss: 0.2691483497619629
Batch 58/64 loss: 0.27224647998809814
Batch 59/64 loss: 0.26812630891799927
Batch 60/64 loss: 0.273026704788208
Batch 61/64 loss: 0.2770165801048279
Batch 62/64 loss: 0.26998138427734375
Batch 63/64 loss: 0.2687666416168213
Batch 64/64 loss: 0.26675182580947876
Epoch 368  Train loss: 0.2695875978937336  Val loss: 0.3137038704455923
Epoch 369
-------------------------------
Batch 1/64 loss: 0.2787502408027649
Batch 2/64 loss: 0.26834291219711304
Batch 3/64 loss: 0.2634959816932678
Batch 4/64 loss: 0.2581033706665039
Batch 5/64 loss: 0.2689440846443176
Batch 6/64 loss: 0.2705705761909485
Batch 7/64 loss: 0.2674063444137573
Batch 8/64 loss: 0.26674962043762207
Batch 9/64 loss: 0.2714698910713196
Batch 10/64 loss: 0.26736247539520264
Batch 11/64 loss: 0.2654695510864258
Batch 12/64 loss: 0.27258503437042236
Batch 13/64 loss: 0.2671459913253784
Batch 14/64 loss: 0.2667694091796875
Batch 15/64 loss: 0.269473671913147
Batch 16/64 loss: 0.2709752321243286
Batch 17/64 loss: 0.26581114530563354
Batch 18/64 loss: 0.27294278144836426
Batch 19/64 loss: 0.2703337073326111
Batch 20/64 loss: 0.26759588718414307
Batch 21/64 loss: 0.27121686935424805
Batch 22/64 loss: 0.26624321937561035
Batch 23/64 loss: 0.2726109027862549
Batch 24/64 loss: 0.2745969295501709
Batch 25/64 loss: 0.27023398876190186
Batch 26/64 loss: 0.27318477630615234
Batch 27/64 loss: 0.2726443409919739
Batch 28/64 loss: 0.26412057876586914
Batch 29/64 loss: 0.26697540283203125
Batch 30/64 loss: 0.2654847502708435
Batch 31/64 loss: 0.2726338505744934
Batch 32/64 loss: 0.26296907663345337
Batch 33/64 loss: 0.2702845335006714
Batch 34/64 loss: 0.2624666094779968
Batch 35/64 loss: 0.26752930879592896
Batch 36/64 loss: 0.268251895904541
Batch 37/64 loss: 0.2808568477630615
Batch 38/64 loss: 0.2685648202896118
Batch 39/64 loss: 0.27075207233428955
Batch 40/64 loss: 0.2680371403694153
Batch 41/64 loss: 0.26775139570236206
Batch 42/64 loss: 0.26705241203308105
Batch 43/64 loss: 0.26733267307281494
Batch 44/64 loss: 0.2785380482673645
Batch 45/64 loss: 0.2718777060508728
Batch 46/64 loss: 0.27016782760620117
Batch 47/64 loss: 0.2702975869178772
Batch 48/64 loss: 0.26581573486328125
Batch 49/64 loss: 0.26961594820022583
Batch 50/64 loss: 0.2783185839653015
Batch 51/64 loss: 0.26911795139312744
Batch 52/64 loss: 0.2660068869590759
Batch 53/64 loss: 0.27645617723464966
Batch 54/64 loss: 0.27851366996765137
Batch 55/64 loss: 0.28149569034576416
Batch 56/64 loss: 0.2720986604690552
Batch 57/64 loss: 0.27068519592285156
Batch 58/64 loss: 0.26375019550323486
Batch 59/64 loss: 0.2729056477546692
Batch 60/64 loss: 0.26834332942962646
Batch 61/64 loss: 0.2700093984603882
Batch 62/64 loss: 0.2722339630126953
Batch 63/64 loss: 0.27057570219039917
Batch 64/64 loss: 0.27012598514556885
Epoch 369  Train loss: 0.269827618785933  Val loss: 0.31239607284978493
Epoch 370
-------------------------------
Batch 1/64 loss: 0.2725405693054199
Batch 2/64 loss: 0.2687673568725586
Batch 3/64 loss: 0.26652437448501587
Batch 4/64 loss: 0.2795560359954834
Batch 5/64 loss: 0.2696671485900879
Batch 6/64 loss: 0.27734994888305664
Batch 7/64 loss: 0.2757711410522461
Batch 8/64 loss: 0.27134203910827637
Batch 9/64 loss: 0.2747492790222168
Batch 10/64 loss: 0.276889443397522
Batch 11/64 loss: 0.27920210361480713
Batch 12/64 loss: 0.27447062730789185
Batch 13/64 loss: 0.2734612822532654
Batch 14/64 loss: 0.2630118131637573
Batch 15/64 loss: 0.2733638286590576
Batch 16/64 loss: 0.26676827669143677
Batch 17/64 loss: 0.2674466371536255
Batch 18/64 loss: 0.2585192918777466
Batch 19/64 loss: 0.2691560983657837
Batch 20/64 loss: 0.2670133709907532
Batch 21/64 loss: 0.26697397232055664
Batch 22/64 loss: 0.26616913080215454
Batch 23/64 loss: 0.26811397075653076
Batch 24/64 loss: 0.26254117488861084
Batch 25/64 loss: 0.27278292179107666
Batch 26/64 loss: 0.2719992399215698
Batch 27/64 loss: 0.2700428366661072
Batch 28/64 loss: 0.26575803756713867
Batch 29/64 loss: 0.2706393003463745
Batch 30/64 loss: 0.2698885202407837
Batch 31/64 loss: 0.26891887187957764
Batch 32/64 loss: 0.2730832099914551
Batch 33/64 loss: 0.2669445276260376
Batch 34/64 loss: 0.26646888256073
Batch 35/64 loss: 0.27229344844818115
Batch 36/64 loss: 0.27209794521331787
Batch 37/64 loss: 0.27659040689468384
Batch 38/64 loss: 0.2770201563835144
Batch 39/64 loss: 0.2572600841522217
Batch 40/64 loss: 0.2791057229042053
Batch 41/64 loss: 0.2635444402694702
Batch 42/64 loss: 0.26596641540527344
Batch 43/64 loss: 0.26449692249298096
Batch 44/64 loss: 0.2690315842628479
Batch 45/64 loss: 0.2685009241104126
Batch 46/64 loss: 0.2671922445297241
Batch 47/64 loss: 0.2711501121520996
Batch 48/64 loss: 0.2657942771911621
Batch 49/64 loss: 0.2758241295814514
Batch 50/64 loss: 0.2696812152862549
Batch 51/64 loss: 0.2663342356681824
Batch 52/64 loss: 0.26398754119873047
Batch 53/64 loss: 0.2628999948501587
Batch 54/64 loss: 0.2786162495613098
Batch 55/64 loss: 0.27457743883132935
Batch 56/64 loss: 0.26777756214141846
Batch 57/64 loss: 0.2690922021865845
Batch 58/64 loss: 0.26840662956237793
Batch 59/64 loss: 0.2719169855117798
Batch 60/64 loss: 0.27141857147216797
Batch 61/64 loss: 0.2676735520362854
Batch 62/64 loss: 0.26985597610473633
Batch 63/64 loss: 0.26630622148513794
Batch 64/64 loss: 0.2690576910972595
Epoch 370  Train loss: 0.2698368897625044  Val loss: 0.3127901543866318
Epoch 371
-------------------------------
Batch 1/64 loss: 0.264384388923645
Batch 2/64 loss: 0.27239668369293213
Batch 3/64 loss: 0.27254927158355713
Batch 4/64 loss: 0.26213955879211426
Batch 5/64 loss: 0.2724447250366211
Batch 6/64 loss: 0.26898229122161865
Batch 7/64 loss: 0.2684708833694458
Batch 8/64 loss: 0.26240384578704834
Batch 9/64 loss: 0.27419090270996094
Batch 10/64 loss: 0.27002382278442383
Batch 11/64 loss: 0.2719496488571167
Batch 12/64 loss: 0.26481032371520996
Batch 13/64 loss: 0.26216018199920654
Batch 14/64 loss: 0.26759493350982666
Batch 15/64 loss: 0.2651902437210083
Batch 16/64 loss: 0.26790058612823486
Batch 17/64 loss: 0.26629000902175903
Batch 18/64 loss: 0.2812560200691223
Batch 19/64 loss: 0.28180932998657227
Batch 20/64 loss: 0.2716915011405945
Batch 21/64 loss: 0.27384114265441895
Batch 22/64 loss: 0.2634689211845398
Batch 23/64 loss: 0.26634442806243896
Batch 24/64 loss: 0.2670440673828125
Batch 25/64 loss: 0.26772069931030273
Batch 26/64 loss: 0.2816050052642822
Batch 27/64 loss: 0.26993227005004883
Batch 28/64 loss: 0.26743996143341064
Batch 29/64 loss: 0.26595133543014526
Batch 30/64 loss: 0.27650904655456543
Batch 31/64 loss: 0.27004802227020264
Batch 32/64 loss: 0.2622442841529846
Batch 33/64 loss: 0.2772510051727295
Batch 34/64 loss: 0.27118146419525146
Batch 35/64 loss: 0.2672422528266907
Batch 36/64 loss: 0.2763102054595947
Batch 37/64 loss: 0.26987260580062866
Batch 38/64 loss: 0.27110135555267334
Batch 39/64 loss: 0.2663710117340088
Batch 40/64 loss: 0.27186161279678345
Batch 41/64 loss: 0.2692444324493408
Batch 42/64 loss: 0.25999486446380615
Batch 43/64 loss: 0.2750535011291504
Batch 44/64 loss: 0.27327823638916016
Batch 45/64 loss: 0.27176713943481445
Batch 46/64 loss: 0.27538150548934937
Batch 47/64 loss: 0.2696087956428528
Batch 48/64 loss: 0.26499688625335693
Batch 49/64 loss: 0.2743208408355713
Batch 50/64 loss: 0.2698211669921875
Batch 51/64 loss: 0.26959478855133057
Batch 52/64 loss: 0.2612231969833374
Batch 53/64 loss: 0.2693188190460205
Batch 54/64 loss: 0.2683461904525757
Batch 55/64 loss: 0.26435965299606323
Batch 56/64 loss: 0.27899324893951416
Batch 57/64 loss: 0.2676656246185303
Batch 58/64 loss: 0.2689487338066101
Batch 59/64 loss: 0.2670341730117798
Batch 60/64 loss: 0.26762717962265015
Batch 61/64 loss: 0.26907140016555786
Batch 62/64 loss: 0.2670440077781677
Batch 63/64 loss: 0.27118486166000366
Batch 64/64 loss: 0.2704086899757385
Epoch 371  Train loss: 0.26962612727109125  Val loss: 0.3121388271911857
Epoch 372
-------------------------------
Batch 1/64 loss: 0.2642970085144043
Batch 2/64 loss: 0.2639029622077942
Batch 3/64 loss: 0.2681068181991577
Batch 4/64 loss: 0.2625240087509155
Batch 5/64 loss: 0.26947611570358276
Batch 6/64 loss: 0.2642272710800171
Batch 7/64 loss: 0.26648038625717163
Batch 8/64 loss: 0.2652900218963623
Batch 9/64 loss: 0.26873940229415894
Batch 10/64 loss: 0.269586980342865
Batch 11/64 loss: 0.2719583511352539
Batch 12/64 loss: 0.2649763822555542
Batch 13/64 loss: 0.26432597637176514
Batch 14/64 loss: 0.2669942378997803
Batch 15/64 loss: 0.26569390296936035
Batch 16/64 loss: 0.2614758014678955
Batch 17/64 loss: 0.26618629693984985
Batch 18/64 loss: 0.26964449882507324
Batch 19/64 loss: 0.27608340978622437
Batch 20/64 loss: 0.2697039842605591
Batch 21/64 loss: 0.2701897621154785
Batch 22/64 loss: 0.2706185579299927
Batch 23/64 loss: 0.27171945571899414
Batch 24/64 loss: 0.2710719704627991
Batch 25/64 loss: 0.27351176738739014
Batch 26/64 loss: 0.267680287361145
Batch 27/64 loss: 0.2647627592086792
Batch 28/64 loss: 0.27168309688568115
Batch 29/64 loss: 0.2633845806121826
Batch 30/64 loss: 0.273318886756897
Batch 31/64 loss: 0.27225011587142944
Batch 32/64 loss: 0.2678316831588745
Batch 33/64 loss: 0.26731133460998535
Batch 34/64 loss: 0.26706504821777344
Batch 35/64 loss: 0.2672111988067627
Batch 36/64 loss: 0.2651478052139282
Batch 37/64 loss: 0.2723044157028198
Batch 38/64 loss: 0.2714618444442749
Batch 39/64 loss: 0.2593902349472046
Batch 40/64 loss: 0.2725332975387573
Batch 41/64 loss: 0.2740720510482788
Batch 42/64 loss: 0.2717887759208679
Batch 43/64 loss: 0.26732897758483887
Batch 44/64 loss: 0.27274489402770996
Batch 45/64 loss: 0.2646036148071289
Batch 46/64 loss: 0.2760121822357178
Batch 47/64 loss: 0.2671695947647095
Batch 48/64 loss: 0.2667497396469116
Batch 49/64 loss: 0.2677258253097534
Batch 50/64 loss: 0.2642638683319092
Batch 51/64 loss: 0.2791656255722046
Batch 52/64 loss: 0.27386796474456787
Batch 53/64 loss: 0.26353538036346436
Batch 54/64 loss: 0.27025002241134644
Batch 55/64 loss: 0.279361367225647
Batch 56/64 loss: 0.26711225509643555
Batch 57/64 loss: 0.26768285036087036
Batch 58/64 loss: 0.27080631256103516
Batch 59/64 loss: 0.2668607234954834
Batch 60/64 loss: 0.27935826778411865
Batch 61/64 loss: 0.2685985565185547
Batch 62/64 loss: 0.27480995655059814
Batch 63/64 loss: 0.27245259284973145
Batch 64/64 loss: 0.27020376920700073
Epoch 372  Train loss: 0.26900542974472047  Val loss: 0.31383509816173016
Epoch 373
-------------------------------
Batch 1/64 loss: 0.27166324853897095
Batch 2/64 loss: 0.2662302255630493
Batch 3/64 loss: 0.2648842930793762
Batch 4/64 loss: 0.2707993984222412
Batch 5/64 loss: 0.2707129716873169
Batch 6/64 loss: 0.2727038860321045
Batch 7/64 loss: 0.2699406147003174
Batch 8/64 loss: 0.27098512649536133
Batch 9/64 loss: 0.2702406644821167
Batch 10/64 loss: 0.27488386631011963
Batch 11/64 loss: 0.2768378257751465
Batch 12/64 loss: 0.25839507579803467
Batch 13/64 loss: 0.26693403720855713
Batch 14/64 loss: 0.2615867853164673
Batch 15/64 loss: 0.2645760774612427
Batch 16/64 loss: 0.2716832756996155
Batch 17/64 loss: 0.27389639616012573
Batch 18/64 loss: 0.2694430351257324
Batch 19/64 loss: 0.265122652053833
Batch 20/64 loss: 0.26874852180480957
Batch 21/64 loss: 0.2680375576019287
Batch 22/64 loss: 0.2614278197288513
Batch 23/64 loss: 0.2695668935775757
Batch 24/64 loss: 0.2770882844924927
Batch 25/64 loss: 0.27231842279434204
Batch 26/64 loss: 0.2722012400627136
Batch 27/64 loss: 0.265316367149353
Batch 28/64 loss: 0.2681921720504761
Batch 29/64 loss: 0.2636760473251343
Batch 30/64 loss: 0.27421748638153076
Batch 31/64 loss: 0.2703510522842407
Batch 32/64 loss: 0.2759132385253906
Batch 33/64 loss: 0.2697474956512451
Batch 34/64 loss: 0.27030110359191895
Batch 35/64 loss: 0.274788498878479
Batch 36/64 loss: 0.2662331461906433
Batch 37/64 loss: 0.27321290969848633
Batch 38/64 loss: 0.27783286571502686
Batch 39/64 loss: 0.2798435688018799
Batch 40/64 loss: 0.2677825093269348
Batch 41/64 loss: 0.27362316846847534
Batch 42/64 loss: 0.27119410037994385
Batch 43/64 loss: 0.26962268352508545
Batch 44/64 loss: 0.2638075351715088
Batch 45/64 loss: 0.2660893201828003
Batch 46/64 loss: 0.27965807914733887
Batch 47/64 loss: 0.268854022026062
Batch 48/64 loss: 0.2726910710334778
Batch 49/64 loss: 0.2656298279762268
Batch 50/64 loss: 0.2619251012802124
Batch 51/64 loss: 0.26663029193878174
Batch 52/64 loss: 0.27398914098739624
Batch 53/64 loss: 0.2682073712348938
Batch 54/64 loss: 0.27138495445251465
Batch 55/64 loss: 0.26473867893218994
Batch 56/64 loss: 0.2737036943435669
Batch 57/64 loss: 0.2698761224746704
Batch 58/64 loss: 0.2727006673812866
Batch 59/64 loss: 0.2697979211807251
Batch 60/64 loss: 0.2704082727432251
Batch 61/64 loss: 0.2667410373687744
Batch 62/64 loss: 0.27463483810424805
Batch 63/64 loss: 0.269143283367157
Batch 64/64 loss: 0.2613881230354309
Epoch 373  Train loss: 0.2697946499375736  Val loss: 0.3118897445013433
Epoch 374
-------------------------------
Batch 1/64 loss: 0.26887834072113037
Batch 2/64 loss: 0.2641446590423584
Batch 3/64 loss: 0.2691493034362793
Batch 4/64 loss: 0.26897525787353516
Batch 5/64 loss: 0.26523345708847046
Batch 6/64 loss: 0.2586383819580078
Batch 7/64 loss: 0.2635080814361572
Batch 8/64 loss: 0.27065300941467285
Batch 9/64 loss: 0.2671542167663574
Batch 10/64 loss: 0.2697639465332031
Batch 11/64 loss: 0.26957905292510986
Batch 12/64 loss: 0.27219581604003906
Batch 13/64 loss: 0.2635742425918579
Batch 14/64 loss: 0.273837685585022
Batch 15/64 loss: 0.26603615283966064
Batch 16/64 loss: 0.27337515354156494
Batch 17/64 loss: 0.2631676197052002
Batch 18/64 loss: 0.27859073877334595
Batch 19/64 loss: 0.26744937896728516
Batch 20/64 loss: 0.26703351736068726
Batch 21/64 loss: 0.267042875289917
Batch 22/64 loss: 0.2689938545227051
Batch 23/64 loss: 0.2694077491760254
Batch 24/64 loss: 0.26833575963974
Batch 25/64 loss: 0.27197813987731934
Batch 26/64 loss: 0.2746700644493103
Batch 27/64 loss: 0.26140034198760986
Batch 28/64 loss: 0.2632037401199341
Batch 29/64 loss: 0.26501595973968506
Batch 30/64 loss: 0.26400911808013916
Batch 31/64 loss: 0.27065563201904297
Batch 32/64 loss: 0.27041828632354736
Batch 33/64 loss: 0.2727013826370239
Batch 34/64 loss: 0.2741224765777588
Batch 35/64 loss: 0.27361464500427246
Batch 36/64 loss: 0.27399641275405884
Batch 37/64 loss: 0.2624117136001587
Batch 38/64 loss: 0.27606987953186035
Batch 39/64 loss: 0.2670910358428955
Batch 40/64 loss: 0.2651158571243286
Batch 41/64 loss: 0.2737835645675659
Batch 42/64 loss: 0.2629610300064087
Batch 43/64 loss: 0.2708768844604492
Batch 44/64 loss: 0.272122323513031
Batch 45/64 loss: 0.2650654911994934
Batch 46/64 loss: 0.2637317180633545
Batch 47/64 loss: 0.26846301555633545
Batch 48/64 loss: 0.27224409580230713
Batch 49/64 loss: 0.2678983807563782
Batch 50/64 loss: 0.26994895935058594
Batch 51/64 loss: 0.2735503315925598
Batch 52/64 loss: 0.272574782371521
Batch 53/64 loss: 0.27247166633605957
Batch 54/64 loss: 0.27422940731048584
Batch 55/64 loss: 0.2696376442909241
Batch 56/64 loss: 0.27380824089050293
Batch 57/64 loss: 0.2673203945159912
Batch 58/64 loss: 0.26368415355682373
Batch 59/64 loss: 0.2642083168029785
Batch 60/64 loss: 0.26411187648773193
Batch 61/64 loss: 0.2724781632423401
Batch 62/64 loss: 0.2705342769622803
Batch 63/64 loss: 0.2725299000740051
Batch 64/64 loss: 0.2746179699897766
Epoch 374  Train loss: 0.2689473103074467  Val loss: 0.3118543073893413
Epoch 375
-------------------------------
Batch 1/64 loss: 0.2628828287124634
Batch 2/64 loss: 0.27374500036239624
Batch 3/64 loss: 0.2693617343902588
Batch 4/64 loss: 0.26680731773376465
Batch 5/64 loss: 0.27027320861816406
Batch 6/64 loss: 0.26492631435394287
Batch 7/64 loss: 0.26279813051223755
Batch 8/64 loss: 0.2643585205078125
Batch 9/64 loss: 0.2658756375312805
Batch 10/64 loss: 0.2660665512084961
Batch 11/64 loss: 0.2641085386276245
Batch 12/64 loss: 0.26143115758895874
Batch 13/64 loss: 0.2601684331893921
Batch 14/64 loss: 0.26914364099502563
Batch 15/64 loss: 0.2680274248123169
Batch 16/64 loss: 0.26936668157577515
Batch 17/64 loss: 0.26977968215942383
Batch 18/64 loss: 0.27280592918395996
Batch 19/64 loss: 0.27650612592697144
Batch 20/64 loss: 0.2724301815032959
Batch 21/64 loss: 0.26499199867248535
Batch 22/64 loss: 0.2706080675125122
Batch 23/64 loss: 0.26590681076049805
Batch 24/64 loss: 0.26934927701950073
Batch 25/64 loss: 0.2639159560203552
Batch 26/64 loss: 0.2802337408065796
Batch 27/64 loss: 0.2669408321380615
Batch 28/64 loss: 0.26000648736953735
Batch 29/64 loss: 0.2725280523300171
Batch 30/64 loss: 0.27017104625701904
Batch 31/64 loss: 0.27775609493255615
Batch 32/64 loss: 0.27254927158355713
Batch 33/64 loss: 0.2728798985481262
Batch 34/64 loss: 0.26985371112823486
Batch 35/64 loss: 0.2675687074661255
Batch 36/64 loss: 0.26349949836730957
Batch 37/64 loss: 0.26556891202926636
Batch 38/64 loss: 0.26592499017715454
Batch 39/64 loss: 0.2677614092826843
Batch 40/64 loss: 0.26160675287246704
Batch 41/64 loss: 0.2681180238723755
Batch 42/64 loss: 0.2657970190048218
Batch 43/64 loss: 0.2685971260070801
Batch 44/64 loss: 0.2655462622642517
Batch 45/64 loss: 0.2747623324394226
Batch 46/64 loss: 0.2658137083053589
Batch 47/64 loss: 0.2709372043609619
Batch 48/64 loss: 0.2679445147514343
Batch 49/64 loss: 0.2776753902435303
Batch 50/64 loss: 0.26441490650177
Batch 51/64 loss: 0.2678474187850952
Batch 52/64 loss: 0.26678889989852905
Batch 53/64 loss: 0.273406982421875
Batch 54/64 loss: 0.2705049514770508
Batch 55/64 loss: 0.2744191884994507
Batch 56/64 loss: 0.26667851209640503
Batch 57/64 loss: 0.2687414884567261
Batch 58/64 loss: 0.2751173973083496
Batch 59/64 loss: 0.2652701139450073
Batch 60/64 loss: 0.2769021987915039
Batch 61/64 loss: 0.264156699180603
Batch 62/64 loss: 0.27058255672454834
Batch 63/64 loss: 0.2645743489265442
Batch 64/64 loss: 0.2775684595108032
Epoch 375  Train loss: 0.2686001277437397  Val loss: 0.3138553899588044
Epoch 376
-------------------------------
Batch 1/64 loss: 0.27005481719970703
Batch 2/64 loss: 0.2691686749458313
Batch 3/64 loss: 0.2633664011955261
Batch 4/64 loss: 0.26558732986450195
Batch 5/64 loss: 0.2673364281654358
Batch 6/64 loss: 0.27130788564682007
Batch 7/64 loss: 0.26917564868927
Batch 8/64 loss: 0.26633721590042114
Batch 9/64 loss: 0.2672908306121826
Batch 10/64 loss: 0.27421140670776367
Batch 11/64 loss: 0.27501606941223145
Batch 12/64 loss: 0.26313328742980957
Batch 13/64 loss: 0.2640637755393982
Batch 14/64 loss: 0.27213388681411743
Batch 15/64 loss: 0.2617499828338623
Batch 16/64 loss: 0.26628053188323975
Batch 17/64 loss: 0.2700604796409607
Batch 18/64 loss: 0.26878708600997925
Batch 19/64 loss: 0.2729641795158386
Batch 20/64 loss: 0.26288723945617676
Batch 21/64 loss: 0.26615017652511597
Batch 22/64 loss: 0.27001088857650757
Batch 23/64 loss: 0.2707977890968323
Batch 24/64 loss: 0.27644670009613037
Batch 25/64 loss: 0.2725104093551636
Batch 26/64 loss: 0.26493048667907715
Batch 27/64 loss: 0.2703601121902466
Batch 28/64 loss: 0.2624276280403137
Batch 29/64 loss: 0.2733222246170044
Batch 30/64 loss: 0.26562291383743286
Batch 31/64 loss: 0.2716439366340637
Batch 32/64 loss: 0.27393853664398193
Batch 33/64 loss: 0.2659643888473511
Batch 34/64 loss: 0.2706485390663147
Batch 35/64 loss: 0.26508331298828125
Batch 36/64 loss: 0.2737475037574768
Batch 37/64 loss: 0.26956647634506226
Batch 38/64 loss: 0.26789021492004395
Batch 39/64 loss: 0.2669788599014282
Batch 40/64 loss: 0.2716791033744812
Batch 41/64 loss: 0.2680177688598633
Batch 42/64 loss: 0.2592083811759949
Batch 43/64 loss: 0.269734263420105
Batch 44/64 loss: 0.26882559061050415
Batch 45/64 loss: 0.26749753952026367
Batch 46/64 loss: 0.26550161838531494
Batch 47/64 loss: 0.27062034606933594
Batch 48/64 loss: 0.2731063961982727
Batch 49/64 loss: 0.26344454288482666
Batch 50/64 loss: 0.26945066452026367
Batch 51/64 loss: 0.2777385115623474
Batch 52/64 loss: 0.2624126076698303
Batch 53/64 loss: 0.2679104804992676
Batch 54/64 loss: 0.26442641019821167
Batch 55/64 loss: 0.2730447053909302
Batch 56/64 loss: 0.2700055241584778
Batch 57/64 loss: 0.27453863620758057
Batch 58/64 loss: 0.274122953414917
Batch 59/64 loss: 0.26400303840637207
Batch 60/64 loss: 0.259670615196228
Batch 61/64 loss: 0.2670780420303345
Batch 62/64 loss: 0.2766095995903015
Batch 63/64 loss: 0.261152982711792
Batch 64/64 loss: 0.27284783124923706
Epoch 376  Train loss: 0.26860220315409644  Val loss: 0.31221155735225614
Epoch 377
-------------------------------
Batch 1/64 loss: 0.27485984563827515
Batch 2/64 loss: 0.270366370677948
Batch 3/64 loss: 0.2664508819580078
Batch 4/64 loss: 0.26406610012054443
Batch 5/64 loss: 0.26084572076797485
Batch 6/64 loss: 0.2719041109085083
Batch 7/64 loss: 0.26857835054397583
Batch 8/64 loss: 0.2745387554168701
Batch 9/64 loss: 0.2756141424179077
Batch 10/64 loss: 0.25991129875183105
Batch 11/64 loss: 0.26100701093673706
Batch 12/64 loss: 0.26434409618377686
Batch 13/64 loss: 0.2663150429725647
Batch 14/64 loss: 0.26830899715423584
Batch 15/64 loss: 0.27806705236434937
Batch 16/64 loss: 0.2634143829345703
Batch 17/64 loss: 0.27078741788864136
Batch 18/64 loss: 0.26504743099212646
Batch 19/64 loss: 0.2661498785018921
Batch 20/64 loss: 0.26031816005706787
Batch 21/64 loss: 0.2685356140136719
Batch 22/64 loss: 0.2661789059638977
Batch 23/64 loss: 0.25708335638046265
Batch 24/64 loss: 0.273037314414978
Batch 25/64 loss: 0.26871711015701294
Batch 26/64 loss: 0.26699650287628174
Batch 27/64 loss: 0.26123106479644775
Batch 28/64 loss: 0.26965630054473877
Batch 29/64 loss: 0.26683735847473145
Batch 30/64 loss: 0.2618821859359741
Batch 31/64 loss: 0.25972723960876465
Batch 32/64 loss: 0.2595953941345215
Batch 33/64 loss: 0.2701690196990967
Batch 34/64 loss: 0.26622116565704346
Batch 35/64 loss: 0.2731168866157532
Batch 36/64 loss: 0.2674800157546997
Batch 37/64 loss: 0.275851845741272
Batch 38/64 loss: 0.2738802433013916
Batch 39/64 loss: 0.2753135561943054
Batch 40/64 loss: 0.2704634666442871
Batch 41/64 loss: 0.27106332778930664
Batch 42/64 loss: 0.26462626457214355
Batch 43/64 loss: 0.2660873532295227
Batch 44/64 loss: 0.2660568952560425
Batch 45/64 loss: 0.2700653672218323
Batch 46/64 loss: 0.2724941372871399
Batch 47/64 loss: 0.2760266065597534
Batch 48/64 loss: 0.27632325887680054
Batch 49/64 loss: 0.26789939403533936
Batch 50/64 loss: 0.2657420039176941
Batch 51/64 loss: 0.270547091960907
Batch 52/64 loss: 0.2675238847732544
Batch 53/64 loss: 0.2722850441932678
Batch 54/64 loss: 0.27066874504089355
Batch 55/64 loss: 0.2684657573699951
Batch 56/64 loss: 0.2755243182182312
Batch 57/64 loss: 0.2744567394256592
Batch 58/64 loss: 0.2758610248565674
Batch 59/64 loss: 0.2738228440284729
Batch 60/64 loss: 0.27288585901260376
Batch 61/64 loss: 0.2656795382499695
Batch 62/64 loss: 0.26287639141082764
Batch 63/64 loss: 0.2665085792541504
Batch 64/64 loss: 0.27431148290634155
Epoch 377  Train loss: 0.26858186090693753  Val loss: 0.3124110203018713
Epoch 378
-------------------------------
Batch 1/64 loss: 0.25891298055648804
Batch 2/64 loss: 0.2693336009979248
Batch 3/64 loss: 0.2665807008743286
Batch 4/64 loss: 0.2626599073410034
Batch 5/64 loss: 0.2700221538543701
Batch 6/64 loss: 0.25948649644851685
Batch 7/64 loss: 0.27036941051483154
Batch 8/64 loss: 0.26854515075683594
Batch 9/64 loss: 0.2711266279220581
Batch 10/64 loss: 0.266761839389801
Batch 11/64 loss: 0.2667025923728943
Batch 12/64 loss: 0.26657211780548096
Batch 13/64 loss: 0.2651708126068115
Batch 14/64 loss: 0.26761454343795776
Batch 15/64 loss: 0.2610783576965332
Batch 16/64 loss: 0.26383233070373535
Batch 17/64 loss: 0.26576030254364014
Batch 18/64 loss: 0.2561286687850952
Batch 19/64 loss: 0.2654879093170166
Batch 20/64 loss: 0.2719850540161133
Batch 21/64 loss: 0.2622913122177124
Batch 22/64 loss: 0.2694769501686096
Batch 23/64 loss: 0.26375532150268555
Batch 24/64 loss: 0.26915502548217773
Batch 25/64 loss: 0.2645559310913086
Batch 26/64 loss: 0.26837158203125
Batch 27/64 loss: 0.2807581424713135
Batch 28/64 loss: 0.27120161056518555
Batch 29/64 loss: 0.27120333909988403
Batch 30/64 loss: 0.2674430012702942
Batch 31/64 loss: 0.2656726837158203
Batch 32/64 loss: 0.27045369148254395
Batch 33/64 loss: 0.26129454374313354
Batch 34/64 loss: 0.25766444206237793
Batch 35/64 loss: 0.264190673828125
Batch 36/64 loss: 0.269075870513916
Batch 37/64 loss: 0.2672343850135803
Batch 38/64 loss: 0.2681502103805542
Batch 39/64 loss: 0.2747535705566406
Batch 40/64 loss: 0.2719694972038269
Batch 41/64 loss: 0.264426589012146
Batch 42/64 loss: 0.2766925096511841
Batch 43/64 loss: 0.2694803476333618
Batch 44/64 loss: 0.2707700729370117
Batch 45/64 loss: 0.270389199256897
Batch 46/64 loss: 0.27041637897491455
Batch 47/64 loss: 0.2779735326766968
Batch 48/64 loss: 0.2642979621887207
Batch 49/64 loss: 0.26265478134155273
Batch 50/64 loss: 0.27012550830841064
Batch 51/64 loss: 0.26436710357666016
Batch 52/64 loss: 0.2672621011734009
Batch 53/64 loss: 0.2691512107849121
Batch 54/64 loss: 0.2788975238800049
Batch 55/64 loss: 0.26408976316452026
Batch 56/64 loss: 0.2659510374069214
Batch 57/64 loss: 0.27450525760650635
Batch 58/64 loss: 0.2759777307510376
Batch 59/64 loss: 0.27083683013916016
Batch 60/64 loss: 0.27716630697250366
Batch 61/64 loss: 0.2596812844276428
Batch 62/64 loss: 0.2734311819076538
Batch 63/64 loss: 0.2791297435760498
Batch 64/64 loss: 0.274733304977417
Epoch 378  Train loss: 0.268180820053699  Val loss: 0.3118943019011586
Epoch 379
-------------------------------
Batch 1/64 loss: 0.2663402557373047
Batch 2/64 loss: 0.27254199981689453
Batch 3/64 loss: 0.26671361923217773
Batch 4/64 loss: 0.2670208811759949
Batch 5/64 loss: 0.27174508571624756
Batch 6/64 loss: 0.26140087842941284
Batch 7/64 loss: 0.26846182346343994
Batch 8/64 loss: 0.27414071559906006
Batch 9/64 loss: 0.26873111724853516
Batch 10/64 loss: 0.2656123638153076
Batch 11/64 loss: 0.2683572769165039
Batch 12/64 loss: 0.26757097244262695
Batch 13/64 loss: 0.2651594281196594
Batch 14/64 loss: 0.2688719630241394
Batch 15/64 loss: 0.2752264738082886
Batch 16/64 loss: 0.26418256759643555
Batch 17/64 loss: 0.26582062244415283
Batch 18/64 loss: 0.2744966745376587
Batch 19/64 loss: 0.27174079418182373
Batch 20/64 loss: 0.2669280171394348
Batch 21/64 loss: 0.2621915340423584
Batch 22/64 loss: 0.2677185535430908
Batch 23/64 loss: 0.26548075675964355
Batch 24/64 loss: 0.271786630153656
Batch 25/64 loss: 0.26187247037887573
Batch 26/64 loss: 0.26450562477111816
Batch 27/64 loss: 0.26444077491760254
Batch 28/64 loss: 0.26897096633911133
Batch 29/64 loss: 0.25949186086654663
Batch 30/64 loss: 0.27142834663391113
Batch 31/64 loss: 0.2759326696395874
Batch 32/64 loss: 0.2745278477668762
Batch 33/64 loss: 0.26485198736190796
Batch 34/64 loss: 0.27031874656677246
Batch 35/64 loss: 0.2696835994720459
Batch 36/64 loss: 0.26262927055358887
Batch 37/64 loss: 0.2666124105453491
Batch 38/64 loss: 0.26615917682647705
Batch 39/64 loss: 0.28139734268188477
Batch 40/64 loss: 0.271640419960022
Batch 41/64 loss: 0.2646052837371826
Batch 42/64 loss: 0.2780929207801819
Batch 43/64 loss: 0.26856786012649536
Batch 44/64 loss: 0.26900023221969604
Batch 45/64 loss: 0.2677781581878662
Batch 46/64 loss: 0.26948976516723633
Batch 47/64 loss: 0.2696911096572876
Batch 48/64 loss: 0.2599363327026367
Batch 49/64 loss: 0.26417064666748047
Batch 50/64 loss: 0.26949989795684814
Batch 51/64 loss: 0.27442026138305664
Batch 52/64 loss: 0.2606963515281677
Batch 53/64 loss: 0.26356619596481323
Batch 54/64 loss: 0.26795530319213867
Batch 55/64 loss: 0.271026074886322
Batch 56/64 loss: 0.26956498622894287
Batch 57/64 loss: 0.2670389413833618
Batch 58/64 loss: 0.27074408531188965
Batch 59/64 loss: 0.26851022243499756
Batch 60/64 loss: 0.2689815163612366
Batch 61/64 loss: 0.2675585150718689
Batch 62/64 loss: 0.27844882011413574
Batch 63/64 loss: 0.263918936252594
Batch 64/64 loss: 0.28091108798980713
Epoch 379  Train loss: 0.26849647456524417  Val loss: 0.3127346708602512
Epoch 380
-------------------------------
Batch 1/64 loss: 0.27673041820526123
Batch 2/64 loss: 0.26762688159942627
Batch 3/64 loss: 0.27010881900787354
Batch 4/64 loss: 0.2630777359008789
Batch 5/64 loss: 0.2696923017501831
Batch 6/64 loss: 0.2729068398475647
Batch 7/64 loss: 0.26909369230270386
Batch 8/64 loss: 0.28237587213516235
Batch 9/64 loss: 0.25996798276901245
Batch 10/64 loss: 0.27184784412384033
Batch 11/64 loss: 0.26839184761047363
Batch 12/64 loss: 0.261852502822876
Batch 13/64 loss: 0.27150702476501465
Batch 14/64 loss: 0.2751530408859253
Batch 15/64 loss: 0.26775848865509033
Batch 16/64 loss: 0.26347440481185913
Batch 17/64 loss: 0.2612658143043518
Batch 18/64 loss: 0.26524877548217773
Batch 19/64 loss: 0.2712165117263794
Batch 20/64 loss: 0.27461695671081543
Batch 21/64 loss: 0.26023173332214355
Batch 22/64 loss: 0.26805853843688965
Batch 23/64 loss: 0.27215754985809326
Batch 24/64 loss: 0.2630985975265503
Batch 25/64 loss: 0.27016681432724
Batch 26/64 loss: 0.276009202003479
Batch 27/64 loss: 0.2620120048522949
Batch 28/64 loss: 0.27220451831817627
Batch 29/64 loss: 0.26959484815597534
Batch 30/64 loss: 0.2752343416213989
Batch 31/64 loss: 0.27113020420074463
Batch 32/64 loss: 0.2611466646194458
Batch 33/64 loss: 0.2694582939147949
Batch 34/64 loss: 0.2633535861968994
Batch 35/64 loss: 0.26218700408935547
Batch 36/64 loss: 0.2643921375274658
Batch 37/64 loss: 0.2673836946487427
Batch 38/64 loss: 0.25995486974716187
Batch 39/64 loss: 0.26808375120162964
Batch 40/64 loss: 0.2677016258239746
Batch 41/64 loss: 0.26943159103393555
Batch 42/64 loss: 0.2695872187614441
Batch 43/64 loss: 0.2653006315231323
Batch 44/64 loss: 0.27057456970214844
Batch 45/64 loss: 0.2703278064727783
Batch 46/64 loss: 0.2688066363334656
Batch 47/64 loss: 0.2687462568283081
Batch 48/64 loss: 0.273537814617157
Batch 49/64 loss: 0.26432663202285767
Batch 50/64 loss: 0.2619600296020508
Batch 51/64 loss: 0.2710639238357544
Batch 52/64 loss: 0.27025270462036133
Batch 53/64 loss: 0.2644529342651367
Batch 54/64 loss: 0.26672911643981934
Batch 55/64 loss: 0.2668611407279968
Batch 56/64 loss: 0.26859772205352783
Batch 57/64 loss: 0.2704423666000366
Batch 58/64 loss: 0.2721126079559326
Batch 59/64 loss: 0.27250057458877563
Batch 60/64 loss: 0.2660515308380127
Batch 61/64 loss: 0.2645835876464844
Batch 62/64 loss: 0.2616342306137085
Batch 63/64 loss: 0.2726343274116516
Batch 64/64 loss: 0.2691681981086731
Epoch 380  Train loss: 0.26823318962957343  Val loss: 0.31271664588312104
Epoch 381
-------------------------------
Batch 1/64 loss: 0.2741360068321228
Batch 2/64 loss: 0.2610779404640198
Batch 3/64 loss: 0.267775297164917
Batch 4/64 loss: 0.25970351696014404
Batch 5/64 loss: 0.2657504081726074
Batch 6/64 loss: 0.26450294256210327
Batch 7/64 loss: 0.26657867431640625
Batch 8/64 loss: 0.27400004863739014
Batch 9/64 loss: 0.26595962047576904
Batch 10/64 loss: 0.26411545276641846
Batch 11/64 loss: 0.2631176710128784
Batch 12/64 loss: 0.27102160453796387
Batch 13/64 loss: 0.26621073484420776
Batch 14/64 loss: 0.26391637325286865
Batch 15/64 loss: 0.26364409923553467
Batch 16/64 loss: 0.2691968083381653
Batch 17/64 loss: 0.26245325803756714
Batch 18/64 loss: 0.26761579513549805
Batch 19/64 loss: 0.26509642601013184
Batch 20/64 loss: 0.2643517255783081
Batch 21/64 loss: 0.26511573791503906
Batch 22/64 loss: 0.26565778255462646
Batch 23/64 loss: 0.26392996311187744
Batch 24/64 loss: 0.26602232456207275
Batch 25/64 loss: 0.27725696563720703
Batch 26/64 loss: 0.2628544569015503
Batch 27/64 loss: 0.2636890411376953
Batch 28/64 loss: 0.26648420095443726
Batch 29/64 loss: 0.2682152986526489
Batch 30/64 loss: 0.2771514654159546
Batch 31/64 loss: 0.27743375301361084
Batch 32/64 loss: 0.2629331946372986
Batch 33/64 loss: 0.2645810842514038
Batch 34/64 loss: 0.2638857960700989
Batch 35/64 loss: 0.26575756072998047
Batch 36/64 loss: 0.2634180784225464
Batch 37/64 loss: 0.26827770471572876
Batch 38/64 loss: 0.27079761028289795
Batch 39/64 loss: 0.27016550302505493
Batch 40/64 loss: 0.2733075022697449
Batch 41/64 loss: 0.2634216547012329
Batch 42/64 loss: 0.2697446346282959
Batch 43/64 loss: 0.2625535726547241
Batch 44/64 loss: 0.26948267221450806
Batch 45/64 loss: 0.27103400230407715
Batch 46/64 loss: 0.26854902505874634
Batch 47/64 loss: 0.2655591368675232
Batch 48/64 loss: 0.26595473289489746
Batch 49/64 loss: 0.2685324549674988
Batch 50/64 loss: 0.2685049772262573
Batch 51/64 loss: 0.2782270312309265
Batch 52/64 loss: 0.27009403705596924
Batch 53/64 loss: 0.2651670575141907
Batch 54/64 loss: 0.27411365509033203
Batch 55/64 loss: 0.26743268966674805
Batch 56/64 loss: 0.2646244764328003
Batch 57/64 loss: 0.2628050446510315
Batch 58/64 loss: 0.2665550708770752
Batch 59/64 loss: 0.2716098427772522
Batch 60/64 loss: 0.2703104019165039
Batch 61/64 loss: 0.2684327960014343
Batch 62/64 loss: 0.27074944972991943
Batch 63/64 loss: 0.26945286989212036
Batch 64/64 loss: 0.26914721727371216
Epoch 381  Train loss: 0.2674812725946015  Val loss: 0.3124809515025608
Epoch 382
-------------------------------
Batch 1/64 loss: 0.2663905620574951
Batch 2/64 loss: 0.2693559527397156
Batch 3/64 loss: 0.2730703353881836
Batch 4/64 loss: 0.26145660877227783
Batch 5/64 loss: 0.26433444023132324
Batch 6/64 loss: 0.268424391746521
Batch 7/64 loss: 0.26361775398254395
Batch 8/64 loss: 0.2676658630371094
Batch 9/64 loss: 0.26824116706848145
Batch 10/64 loss: 0.2696074843406677
Batch 11/64 loss: 0.2648557424545288
Batch 12/64 loss: 0.2666022777557373
Batch 13/64 loss: 0.2684692144393921
Batch 14/64 loss: 0.2626572847366333
Batch 15/64 loss: 0.26638591289520264
Batch 16/64 loss: 0.2642127275466919
Batch 17/64 loss: 0.26602864265441895
Batch 18/64 loss: 0.2727460265159607
Batch 19/64 loss: 0.27043700218200684
Batch 20/64 loss: 0.2678598165512085
Batch 21/64 loss: 0.27121973037719727
Batch 22/64 loss: 0.26310843229293823
Batch 23/64 loss: 0.2761412262916565
Batch 24/64 loss: 0.2654768228530884
Batch 25/64 loss: 0.26224005222320557
Batch 26/64 loss: 0.2703966498374939
Batch 27/64 loss: 0.2763456702232361
Batch 28/64 loss: 0.27208268642425537
Batch 29/64 loss: 0.2639538645744324
Batch 30/64 loss: 0.2670961022377014
Batch 31/64 loss: 0.2657151222229004
Batch 32/64 loss: 0.2635318636894226
Batch 33/64 loss: 0.27628350257873535
Batch 34/64 loss: 0.27124297618865967
Batch 35/64 loss: 0.2695496082305908
Batch 36/64 loss: 0.26196181774139404
Batch 37/64 loss: 0.2715848684310913
Batch 38/64 loss: 0.2663297653198242
Batch 39/64 loss: 0.27605414390563965
Batch 40/64 loss: 0.27208036184310913
Batch 41/64 loss: 0.2670273780822754
Batch 42/64 loss: 0.2679250240325928
Batch 43/64 loss: 0.27667009830474854
Batch 44/64 loss: 0.26249849796295166
Batch 45/64 loss: 0.27854275703430176
Batch 46/64 loss: 0.2726042866706848
Batch 47/64 loss: 0.2613985538482666
Batch 48/64 loss: 0.27663540840148926
Batch 49/64 loss: 0.27248817682266235
Batch 50/64 loss: 0.25739502906799316
Batch 51/64 loss: 0.27327507734298706
Batch 52/64 loss: 0.2665637731552124
Batch 53/64 loss: 0.271781325340271
Batch 54/64 loss: 0.2666133642196655
Batch 55/64 loss: 0.27162617444992065
Batch 56/64 loss: 0.2661280632019043
Batch 57/64 loss: 0.26319921016693115
Batch 58/64 loss: 0.26352840662002563
Batch 59/64 loss: 0.267761766910553
Batch 60/64 loss: 0.2655642032623291
Batch 61/64 loss: 0.2683100700378418
Batch 62/64 loss: 0.2724273204803467
Batch 63/64 loss: 0.2692633867263794
Batch 64/64 loss: 0.2755470275878906
Epoch 382  Train loss: 0.2684031701555439  Val loss: 0.3119965418917207
Epoch 383
-------------------------------
Batch 1/64 loss: 0.2660505771636963
Batch 2/64 loss: 0.2658357620239258
Batch 3/64 loss: 0.2650023102760315
Batch 4/64 loss: 0.2697409391403198
Batch 5/64 loss: 0.27049732208251953
Batch 6/64 loss: 0.26217126846313477
Batch 7/64 loss: 0.26795494556427
Batch 8/64 loss: 0.27044427394866943
Batch 9/64 loss: 0.2610856294631958
Batch 10/64 loss: 0.2617349624633789
Batch 11/64 loss: 0.2742037773132324
Batch 12/64 loss: 0.2636139392852783
Batch 13/64 loss: 0.27002477645874023
Batch 14/64 loss: 0.26392436027526855
Batch 15/64 loss: 0.2639818787574768
Batch 16/64 loss: 0.2651723027229309
Batch 17/64 loss: 0.2725570797920227
Batch 18/64 loss: 0.2662349343299866
Batch 19/64 loss: 0.2739664316177368
Batch 20/64 loss: 0.2743697166442871
Batch 21/64 loss: 0.27344560623168945
Batch 22/64 loss: 0.2704963684082031
Batch 23/64 loss: 0.26932966709136963
Batch 24/64 loss: 0.2704106569290161
Batch 25/64 loss: 0.26745808124542236
Batch 26/64 loss: 0.2605013847351074
Batch 27/64 loss: 0.2613770365715027
Batch 28/64 loss: 0.2728307247161865
Batch 29/64 loss: 0.26403141021728516
Batch 30/64 loss: 0.26658332347869873
Batch 31/64 loss: 0.2708434462547302
Batch 32/64 loss: 0.2628138065338135
Batch 33/64 loss: 0.26249802112579346
Batch 34/64 loss: 0.26375168561935425
Batch 35/64 loss: 0.269085168838501
Batch 36/64 loss: 0.2632705569267273
Batch 37/64 loss: 0.2664377689361572
Batch 38/64 loss: 0.265647828578949
Batch 39/64 loss: 0.25963830947875977
Batch 40/64 loss: 0.26742011308670044
Batch 41/64 loss: 0.2787591218948364
Batch 42/64 loss: 0.2696681618690491
Batch 43/64 loss: 0.27473968267440796
Batch 44/64 loss: 0.2726290225982666
Batch 45/64 loss: 0.2668701410293579
Batch 46/64 loss: 0.26389968395233154
Batch 47/64 loss: 0.2750316858291626
Batch 48/64 loss: 0.27197957038879395
Batch 49/64 loss: 0.26109838485717773
Batch 50/64 loss: 0.2664766311645508
Batch 51/64 loss: 0.26655298471450806
Batch 52/64 loss: 0.2720969319343567
Batch 53/64 loss: 0.2656233310699463
Batch 54/64 loss: 0.2691608667373657
Batch 55/64 loss: 0.2633674740791321
Batch 56/64 loss: 0.2717324495315552
Batch 57/64 loss: 0.2726447582244873
Batch 58/64 loss: 0.271486759185791
Batch 59/64 loss: 0.2671126127243042
Batch 60/64 loss: 0.2721012830734253
Batch 61/64 loss: 0.2654934525489807
Batch 62/64 loss: 0.260714590549469
Batch 63/64 loss: 0.2772703766822815
Batch 64/64 loss: 0.27092087268829346
Epoch 383  Train loss: 0.2678610002293306  Val loss: 0.312067020185215
Epoch 384
-------------------------------
Batch 1/64 loss: 0.2642749547958374
Batch 2/64 loss: 0.2714000344276428
Batch 3/64 loss: 0.2609363794326782
Batch 4/64 loss: 0.2644615173339844
Batch 5/64 loss: 0.2629309296607971
Batch 6/64 loss: 0.2621943950653076
Batch 7/64 loss: 0.2614973783493042
Batch 8/64 loss: 0.26648855209350586
Batch 9/64 loss: 0.27090781927108765
Batch 10/64 loss: 0.2717793583869934
Batch 11/64 loss: 0.273404598236084
Batch 12/64 loss: 0.27565425634384155
Batch 13/64 loss: 0.26328057050704956
Batch 14/64 loss: 0.26210498809814453
Batch 15/64 loss: 0.27216649055480957
Batch 16/64 loss: 0.27514827251434326
Batch 17/64 loss: 0.26580655574798584
Batch 18/64 loss: 0.26517313718795776
Batch 19/64 loss: 0.2697334289550781
Batch 20/64 loss: 0.2611019015312195
Batch 21/64 loss: 0.2644188404083252
Batch 22/64 loss: 0.2630108594894409
Batch 23/64 loss: 0.26701271533966064
Batch 24/64 loss: 0.2622683048248291
Batch 25/64 loss: 0.2631453275680542
Batch 26/64 loss: 0.2721271514892578
Batch 27/64 loss: 0.26470744609832764
Batch 28/64 loss: 0.26285672187805176
Batch 29/64 loss: 0.262417197227478
Batch 30/64 loss: 0.26434993743896484
Batch 31/64 loss: 0.27863872051239014
Batch 32/64 loss: 0.2686131000518799
Batch 33/64 loss: 0.2669019103050232
Batch 34/64 loss: 0.27202993631362915
Batch 35/64 loss: 0.26861250400543213
Batch 36/64 loss: 0.26368051767349243
Batch 37/64 loss: 0.27324122190475464
Batch 38/64 loss: 0.2659299373626709
Batch 39/64 loss: 0.2646867632865906
Batch 40/64 loss: 0.27077364921569824
Batch 41/64 loss: 0.26422828435897827
Batch 42/64 loss: 0.26664668321609497
Batch 43/64 loss: 0.2682642340660095
Batch 44/64 loss: 0.2687876224517822
Batch 45/64 loss: 0.2704547047615051
Batch 46/64 loss: 0.26588505506515503
Batch 47/64 loss: 0.2679945230484009
Batch 48/64 loss: 0.26973772048950195
Batch 49/64 loss: 0.26798564195632935
Batch 50/64 loss: 0.27638787031173706
Batch 51/64 loss: 0.2714006304740906
Batch 52/64 loss: 0.26364076137542725
Batch 53/64 loss: 0.2689625024795532
Batch 54/64 loss: 0.2708827257156372
Batch 55/64 loss: 0.2642632722854614
Batch 56/64 loss: 0.2716093063354492
Batch 57/64 loss: 0.2775310277938843
Batch 58/64 loss: 0.28078150749206543
Batch 59/64 loss: 0.27285629510879517
Batch 60/64 loss: 0.2712153196334839
Batch 61/64 loss: 0.2646385431289673
Batch 62/64 loss: 0.26877903938293457
Batch 63/64 loss: 0.26160889863967896
Batch 64/64 loss: 0.26570063829421997
Epoch 384  Train loss: 0.26782252437928145  Val loss: 0.31325222659356816
Epoch 385
-------------------------------
Batch 1/64 loss: 0.2652885913848877
Batch 2/64 loss: 0.26859283447265625
Batch 3/64 loss: 0.26483863592147827
Batch 4/64 loss: 0.2763545513153076
Batch 5/64 loss: 0.27046406269073486
Batch 6/64 loss: 0.2643231153488159
Batch 7/64 loss: 0.27392518520355225
Batch 8/64 loss: 0.2673149108886719
Batch 9/64 loss: 0.25883030891418457
Batch 10/64 loss: 0.26393985748291016
Batch 11/64 loss: 0.26076042652130127
Batch 12/64 loss: 0.2615985870361328
Batch 13/64 loss: 0.27202749252319336
Batch 14/64 loss: 0.2630469799041748
Batch 15/64 loss: 0.26801031827926636
Batch 16/64 loss: 0.2814885377883911
Batch 17/64 loss: 0.2679182291030884
Batch 18/64 loss: 0.2640777826309204
Batch 19/64 loss: 0.2672843337059021
Batch 20/64 loss: 0.26867449283599854
Batch 21/64 loss: 0.27283787727355957
Batch 22/64 loss: 0.2675102949142456
Batch 23/64 loss: 0.26304250955581665
Batch 24/64 loss: 0.27703118324279785
Batch 25/64 loss: 0.2683783769607544
Batch 26/64 loss: 0.2656456232070923
Batch 27/64 loss: 0.26323509216308594
Batch 28/64 loss: 0.27075517177581787
Batch 29/64 loss: 0.2644427418708801
Batch 30/64 loss: 0.27256494760513306
Batch 31/64 loss: 0.2649308443069458
Batch 32/64 loss: 0.2696871757507324
Batch 33/64 loss: 0.2631080150604248
Batch 34/64 loss: 0.2681596279144287
Batch 35/64 loss: 0.268973708152771
Batch 36/64 loss: 0.2653292417526245
Batch 37/64 loss: 0.2688920497894287
Batch 38/64 loss: 0.2691289186477661
Batch 39/64 loss: 0.2709766626358032
Batch 40/64 loss: 0.26345038414001465
Batch 41/64 loss: 0.2658897638320923
Batch 42/64 loss: 0.26902562379837036
Batch 43/64 loss: 0.2663806676864624
Batch 44/64 loss: 0.2685965299606323
Batch 45/64 loss: 0.2667343020439148
Batch 46/64 loss: 0.27117598056793213
Batch 47/64 loss: 0.2650883197784424
Batch 48/64 loss: 0.2742481231689453
Batch 49/64 loss: 0.26730597019195557
Batch 50/64 loss: 0.27254801988601685
Batch 51/64 loss: 0.2676173448562622
Batch 52/64 loss: 0.26656776666641235
Batch 53/64 loss: 0.2691153287887573
Batch 54/64 loss: 0.27007412910461426
Batch 55/64 loss: 0.27070558071136475
Batch 56/64 loss: 0.26657772064208984
Batch 57/64 loss: 0.27099311351776123
Batch 58/64 loss: 0.27271032333374023
Batch 59/64 loss: 0.2698848247528076
Batch 60/64 loss: 0.26958972215652466
Batch 61/64 loss: 0.2680245637893677
Batch 62/64 loss: 0.27912020683288574
Batch 63/64 loss: 0.2715774178504944
Batch 64/64 loss: 0.2656360864639282
Epoch 385  Train loss: 0.26832342101078405  Val loss: 0.31268165918559965
Epoch 386
-------------------------------
Batch 1/64 loss: 0.26197201013565063
Batch 2/64 loss: 0.2660409212112427
Batch 3/64 loss: 0.2778932452201843
Batch 4/64 loss: 0.26009565591812134
Batch 5/64 loss: 0.2646098732948303
Batch 6/64 loss: 0.2725997567176819
Batch 7/64 loss: 0.2612244486808777
Batch 8/64 loss: 0.26841580867767334
Batch 9/64 loss: 0.27555906772613525
Batch 10/64 loss: 0.2623096704483032
Batch 11/64 loss: 0.2605056166648865
Batch 12/64 loss: 0.2674841284751892
Batch 13/64 loss: 0.2699946165084839
Batch 14/64 loss: 0.26357704401016235
Batch 15/64 loss: 0.26650679111480713
Batch 16/64 loss: 0.2632713317871094
Batch 17/64 loss: 0.27373361587524414
Batch 18/64 loss: 0.2672884464263916
Batch 19/64 loss: 0.2675563097000122
Batch 20/64 loss: 0.2662056088447571
Batch 21/64 loss: 0.2679727077484131
Batch 22/64 loss: 0.26096391677856445
Batch 23/64 loss: 0.26431804895401
Batch 24/64 loss: 0.262176513671875
Batch 25/64 loss: 0.27209389209747314
Batch 26/64 loss: 0.2744402289390564
Batch 27/64 loss: 0.26276862621307373
Batch 28/64 loss: 0.26841020584106445
Batch 29/64 loss: 0.2687196731567383
Batch 30/64 loss: 0.27106618881225586
Batch 31/64 loss: 0.26872462034225464
Batch 32/64 loss: 0.27903974056243896
Batch 33/64 loss: 0.2692148685455322
Batch 34/64 loss: 0.26274991035461426
Batch 35/64 loss: 0.2621946334838867
Batch 36/64 loss: 0.2735487222671509
Batch 37/64 loss: 0.27038609981536865
Batch 38/64 loss: 0.26416265964508057
Batch 39/64 loss: 0.2609449028968811
Batch 40/64 loss: 0.2656775712966919
Batch 41/64 loss: 0.2713165283203125
Batch 42/64 loss: 0.27070188522338867
Batch 43/64 loss: 0.266124963760376
Batch 44/64 loss: 0.26779258251190186
Batch 45/64 loss: 0.2646881341934204
Batch 46/64 loss: 0.26884597539901733
Batch 47/64 loss: 0.2695869207382202
Batch 48/64 loss: 0.2638465166091919
Batch 49/64 loss: 0.2682986259460449
Batch 50/64 loss: 0.2728821635246277
Batch 51/64 loss: 0.2601494789123535
Batch 52/64 loss: 0.26723891496658325
Batch 53/64 loss: 0.2652249336242676
Batch 54/64 loss: 0.27322232723236084
Batch 55/64 loss: 0.257820725440979
Batch 56/64 loss: 0.26568543910980225
Batch 57/64 loss: 0.2685322165489197
Batch 58/64 loss: 0.2691565752029419
Batch 59/64 loss: 0.2644418478012085
Batch 60/64 loss: 0.2699810862541199
Batch 61/64 loss: 0.26804226636886597
Batch 62/64 loss: 0.270662784576416
Batch 63/64 loss: 0.26858294010162354
Batch 64/64 loss: 0.26839691400527954
Epoch 386  Train loss: 0.2673026073212717  Val loss: 0.31310282212352425
Epoch 387
-------------------------------
Batch 1/64 loss: 0.27137434482574463
Batch 2/64 loss: 0.25917762517929077
Batch 3/64 loss: 0.27687227725982666
Batch 4/64 loss: 0.26561450958251953
Batch 5/64 loss: 0.2664341926574707
Batch 6/64 loss: 0.26443320512771606
Batch 7/64 loss: 0.26409220695495605
Batch 8/64 loss: 0.26160621643066406
Batch 9/64 loss: 0.26849818229675293
Batch 10/64 loss: 0.2649424076080322
Batch 11/64 loss: 0.25947850942611694
Batch 12/64 loss: 0.26950496435165405
Batch 13/64 loss: 0.27065783739089966
Batch 14/64 loss: 0.27165937423706055
Batch 15/64 loss: 0.2776104211807251
Batch 16/64 loss: 0.2612558603286743
Batch 17/64 loss: 0.26185619831085205
Batch 18/64 loss: 0.261253297328949
Batch 19/64 loss: 0.2705516815185547
Batch 20/64 loss: 0.2681776285171509
Batch 21/64 loss: 0.271700918674469
Batch 22/64 loss: 0.2665306329727173
Batch 23/64 loss: 0.26421040296554565
Batch 24/64 loss: 0.2688620090484619
Batch 25/64 loss: 0.2698894739151001
Batch 26/64 loss: 0.26431941986083984
Batch 27/64 loss: 0.2638735771179199
Batch 28/64 loss: 0.2639920115470886
Batch 29/64 loss: 0.2709730863571167
Batch 30/64 loss: 0.2750016450881958
Batch 31/64 loss: 0.26030945777893066
Batch 32/64 loss: 0.2710636854171753
Batch 33/64 loss: 0.27156054973602295
Batch 34/64 loss: 0.2642527222633362
Batch 35/64 loss: 0.2654435634613037
Batch 36/64 loss: 0.2707252502441406
Batch 37/64 loss: 0.26811522245407104
Batch 38/64 loss: 0.2729160785675049
Batch 39/64 loss: 0.2658219337463379
Batch 40/64 loss: 0.26640647649765015
Batch 41/64 loss: 0.2731128931045532
Batch 42/64 loss: 0.26439905166625977
Batch 43/64 loss: 0.26570457220077515
Batch 44/64 loss: 0.2703327536582947
Batch 45/64 loss: 0.27910351753234863
Batch 46/64 loss: 0.27332526445388794
Batch 47/64 loss: 0.2631244659423828
Batch 48/64 loss: 0.26605224609375
Batch 49/64 loss: 0.265647828578949
Batch 50/64 loss: 0.27170491218566895
Batch 51/64 loss: 0.25870954990386963
Batch 52/64 loss: 0.2705024480819702
Batch 53/64 loss: 0.27190738916397095
Batch 54/64 loss: 0.2682766914367676
Batch 55/64 loss: 0.27320611476898193
Batch 56/64 loss: 0.26391732692718506
Batch 57/64 loss: 0.2666049599647522
Batch 58/64 loss: 0.268821120262146
Batch 59/64 loss: 0.2663101553916931
Batch 60/64 loss: 0.26671653985977173
Batch 61/64 loss: 0.2695479393005371
Batch 62/64 loss: 0.2695472836494446
Batch 63/64 loss: 0.2664753198623657
Batch 64/64 loss: 0.2725980877876282
Epoch 387  Train loss: 0.26774145832248764  Val loss: 0.31173557821418
Epoch 388
-------------------------------
Batch 1/64 loss: 0.2649219036102295
Batch 2/64 loss: 0.2610035538673401
Batch 3/64 loss: 0.2635462284088135
Batch 4/64 loss: 0.27530455589294434
Batch 5/64 loss: 0.26555919647216797
Batch 6/64 loss: 0.26237356662750244
Batch 7/64 loss: 0.26295483112335205
Batch 8/64 loss: 0.2682594060897827
Batch 9/64 loss: 0.26691651344299316
Batch 10/64 loss: 0.2724282741546631
Batch 11/64 loss: 0.2692224383354187
Batch 12/64 loss: 0.25901126861572266
Batch 13/64 loss: 0.2628622055053711
Batch 14/64 loss: 0.2618016004562378
Batch 15/64 loss: 0.26525211334228516
Batch 16/64 loss: 0.265356183052063
Batch 17/64 loss: 0.2701870799064636
Batch 18/64 loss: 0.2596306800842285
Batch 19/64 loss: 0.2660644054412842
Batch 20/64 loss: 0.2689439058303833
Batch 21/64 loss: 0.2735782265663147
Batch 22/64 loss: 0.2662578821182251
Batch 23/64 loss: 0.266137957572937
Batch 24/64 loss: 0.26099491119384766
Batch 25/64 loss: 0.2696051001548767
Batch 26/64 loss: 0.26440322399139404
Batch 27/64 loss: 0.28054600954055786
Batch 28/64 loss: 0.26859718561172485
Batch 29/64 loss: 0.2647531032562256
Batch 30/64 loss: 0.2631312608718872
Batch 31/64 loss: 0.2693755626678467
Batch 32/64 loss: 0.26058661937713623
Batch 33/64 loss: 0.268929123878479
Batch 34/64 loss: 0.26849138736724854
Batch 35/64 loss: 0.26233989000320435
Batch 36/64 loss: 0.26860111951828003
Batch 37/64 loss: 0.2670419216156006
Batch 38/64 loss: 0.2728767395019531
Batch 39/64 loss: 0.27234095335006714
Batch 40/64 loss: 0.2729892134666443
Batch 41/64 loss: 0.26385241746902466
Batch 42/64 loss: 0.26700758934020996
Batch 43/64 loss: 0.27194106578826904
Batch 44/64 loss: 0.26524949073791504
Batch 45/64 loss: 0.2612999677658081
Batch 46/64 loss: 0.2599782943725586
Batch 47/64 loss: 0.26260167360305786
Batch 48/64 loss: 0.2692573070526123
Batch 49/64 loss: 0.2781531810760498
Batch 50/64 loss: 0.27033019065856934
Batch 51/64 loss: 0.2686735987663269
Batch 52/64 loss: 0.26784688234329224
Batch 53/64 loss: 0.2778095006942749
Batch 54/64 loss: 0.2655242681503296
Batch 55/64 loss: 0.26735061407089233
Batch 56/64 loss: 0.26503705978393555
Batch 57/64 loss: 0.2701253890991211
Batch 58/64 loss: 0.2655642032623291
Batch 59/64 loss: 0.2598613500595093
Batch 60/64 loss: 0.2695614695549011
Batch 61/64 loss: 0.2704564332962036
Batch 62/64 loss: 0.26925474405288696
Batch 63/64 loss: 0.2674846649169922
Batch 64/64 loss: 0.2723197340965271
Epoch 388  Train loss: 0.26716295620974373  Val loss: 0.31248778412022543
Epoch 389
-------------------------------
Batch 1/64 loss: 0.26717889308929443
Batch 2/64 loss: 0.26715898513793945
Batch 3/64 loss: 0.2695140838623047
Batch 4/64 loss: 0.2654038667678833
Batch 5/64 loss: 0.2675057053565979
Batch 6/64 loss: 0.26359063386917114
Batch 7/64 loss: 0.25737154483795166
Batch 8/64 loss: 0.2702024579048157
Batch 9/64 loss: 0.26633530855178833
Batch 10/64 loss: 0.26613521575927734
Batch 11/64 loss: 0.2684980630874634
Batch 12/64 loss: 0.2657622694969177
Batch 13/64 loss: 0.27262967824935913
Batch 14/64 loss: 0.27122604846954346
Batch 15/64 loss: 0.2717630863189697
Batch 16/64 loss: 0.2702944278717041
Batch 17/64 loss: 0.2675468921661377
Batch 18/64 loss: 0.2788161039352417
Batch 19/64 loss: 0.2655254006385803
Batch 20/64 loss: 0.2621305584907532
Batch 21/64 loss: 0.2708742618560791
Batch 22/64 loss: 0.2630612850189209
Batch 23/64 loss: 0.2619103789329529
Batch 24/64 loss: 0.266266405582428
Batch 25/64 loss: 0.266274094581604
Batch 26/64 loss: 0.2675067186355591
Batch 27/64 loss: 0.26394057273864746
Batch 28/64 loss: 0.26559239625930786
Batch 29/64 loss: 0.26579713821411133
Batch 30/64 loss: 0.26377880573272705
Batch 31/64 loss: 0.27246689796447754
Batch 32/64 loss: 0.25868916511535645
Batch 33/64 loss: 0.27465784549713135
Batch 34/64 loss: 0.2711188793182373
Batch 35/64 loss: 0.26554393768310547
Batch 36/64 loss: 0.27907007932662964
Batch 37/64 loss: 0.2691357731819153
Batch 38/64 loss: 0.26280248165130615
Batch 39/64 loss: 0.26608550548553467
Batch 40/64 loss: 0.2658291459083557
Batch 41/64 loss: 0.267667293548584
Batch 42/64 loss: 0.27401793003082275
Batch 43/64 loss: 0.2791731357574463
Batch 44/64 loss: 0.27352017164230347
Batch 45/64 loss: 0.26121044158935547
Batch 46/64 loss: 0.26567137241363525
Batch 47/64 loss: 0.26911401748657227
Batch 48/64 loss: 0.2618803381919861
Batch 49/64 loss: 0.26549941301345825
Batch 50/64 loss: 0.26156020164489746
Batch 51/64 loss: 0.274544358253479
Batch 52/64 loss: 0.26414209604263306
Batch 53/64 loss: 0.2601100206375122
Batch 54/64 loss: 0.2739596962928772
Batch 55/64 loss: 0.2760430574417114
Batch 56/64 loss: 0.258648157119751
Batch 57/64 loss: 0.2683650255203247
Batch 58/64 loss: 0.27392446994781494
Batch 59/64 loss: 0.2709934711456299
Batch 60/64 loss: 0.2755287289619446
Batch 61/64 loss: 0.2634338140487671
Batch 62/64 loss: 0.2604677081108093
Batch 63/64 loss: 0.26861637830734253
Batch 64/64 loss: 0.26759374141693115
Epoch 389  Train loss: 0.26766709954130885  Val loss: 0.31271460089077247
Epoch 390
-------------------------------
Batch 1/64 loss: 0.2648780941963196
Batch 2/64 loss: 0.274069607257843
Batch 3/64 loss: 0.263957679271698
Batch 4/64 loss: 0.2687636613845825
Batch 5/64 loss: 0.26937103271484375
Batch 6/64 loss: 0.265705943107605
Batch 7/64 loss: 0.263042688369751
Batch 8/64 loss: 0.2856062650680542
Batch 9/64 loss: 0.26777374744415283
Batch 10/64 loss: 0.2615719437599182
Batch 11/64 loss: 0.2663918137550354
Batch 12/64 loss: 0.2673149108886719
Batch 13/64 loss: 0.26358306407928467
Batch 14/64 loss: 0.26518869400024414
Batch 15/64 loss: 0.26346027851104736
Batch 16/64 loss: 0.2614309787750244
Batch 17/64 loss: 0.26539623737335205
Batch 18/64 loss: 0.2670084238052368
Batch 19/64 loss: 0.269661545753479
Batch 20/64 loss: 0.2631237506866455
Batch 21/64 loss: 0.2627781629562378
Batch 22/64 loss: 0.27191901206970215
Batch 23/64 loss: 0.2677817940711975
Batch 24/64 loss: 0.261258602142334
Batch 25/64 loss: 0.2661007046699524
Batch 26/64 loss: 0.26708340644836426
Batch 27/64 loss: 0.26464545726776123
Batch 28/64 loss: 0.27084773778915405
Batch 29/64 loss: 0.269189715385437
Batch 30/64 loss: 0.266900897026062
Batch 31/64 loss: 0.26759499311447144
Batch 32/64 loss: 0.2655760645866394
Batch 33/64 loss: 0.26366811990737915
Batch 34/64 loss: 0.26256757974624634
Batch 35/64 loss: 0.2710471749305725
Batch 36/64 loss: 0.2716261148452759
Batch 37/64 loss: 0.26664215326309204
Batch 38/64 loss: 0.2649569511413574
Batch 39/64 loss: 0.2696155309677124
Batch 40/64 loss: 0.2628311514854431
Batch 41/64 loss: 0.2643258571624756
Batch 42/64 loss: 0.2640024423599243
Batch 43/64 loss: 0.2656744718551636
Batch 44/64 loss: 0.2682173252105713
Batch 45/64 loss: 0.27571022510528564
Batch 46/64 loss: 0.26713454723358154
Batch 47/64 loss: 0.26615631580352783
Batch 48/64 loss: 0.2688143253326416
Batch 49/64 loss: 0.2690693140029907
Batch 50/64 loss: 0.2631855010986328
Batch 51/64 loss: 0.2665601968765259
Batch 52/64 loss: 0.27250969409942627
Batch 53/64 loss: 0.2732353210449219
Batch 54/64 loss: 0.2687206268310547
Batch 55/64 loss: 0.2655852437019348
Batch 56/64 loss: 0.2712230682373047
Batch 57/64 loss: 0.2642829418182373
Batch 58/64 loss: 0.27111315727233887
Batch 59/64 loss: 0.2708226442337036
Batch 60/64 loss: 0.26406359672546387
Batch 61/64 loss: 0.2661306858062744
Batch 62/64 loss: 0.2667505741119385
Batch 63/64 loss: 0.27257436513900757
Batch 64/64 loss: 0.26632052659988403
Epoch 390  Train loss: 0.2672554434514513  Val loss: 0.31166080490420367
Epoch 391
-------------------------------
Batch 1/64 loss: 0.26565849781036377
Batch 2/64 loss: 0.2633470892906189
Batch 3/64 loss: 0.2638603448867798
Batch 4/64 loss: 0.2630000710487366
Batch 5/64 loss: 0.27203619480133057
Batch 6/64 loss: 0.2638018727302551
Batch 7/64 loss: 0.262393057346344
Batch 8/64 loss: 0.2670018672943115
Batch 9/64 loss: 0.25959062576293945
Batch 10/64 loss: 0.26321613788604736
Batch 11/64 loss: 0.26256823539733887
Batch 12/64 loss: 0.2664644122123718
Batch 13/64 loss: 0.2682061195373535
Batch 14/64 loss: 0.2648391127586365
Batch 15/64 loss: 0.27320313453674316
Batch 16/64 loss: 0.2666701078414917
Batch 17/64 loss: 0.2713286876678467
Batch 18/64 loss: 0.26555120944976807
Batch 19/64 loss: 0.2727231979370117
Batch 20/64 loss: 0.2693074941635132
Batch 21/64 loss: 0.2717869281768799
Batch 22/64 loss: 0.2715872526168823
Batch 23/64 loss: 0.2659856081008911
Batch 24/64 loss: 0.2685694694519043
Batch 25/64 loss: 0.26681870222091675
Batch 26/64 loss: 0.27151501178741455
Batch 27/64 loss: 0.2719382047653198
Batch 28/64 loss: 0.262315571308136
Batch 29/64 loss: 0.26762497425079346
Batch 30/64 loss: 0.2686765789985657
Batch 31/64 loss: 0.26240670680999756
Batch 32/64 loss: 0.2607452869415283
Batch 33/64 loss: 0.2707411050796509
Batch 34/64 loss: 0.26941508054733276
Batch 35/64 loss: 0.26387906074523926
Batch 36/64 loss: 0.27200746536254883
Batch 37/64 loss: 0.2694317698478699
Batch 38/64 loss: 0.26507067680358887
Batch 39/64 loss: 0.26843059062957764
Batch 40/64 loss: 0.2625570297241211
Batch 41/64 loss: 0.27433639764785767
Batch 42/64 loss: 0.2636553645133972
Batch 43/64 loss: 0.2651411294937134
Batch 44/64 loss: 0.26663583517074585
Batch 45/64 loss: 0.26861751079559326
Batch 46/64 loss: 0.26473188400268555
Batch 47/64 loss: 0.27179384231567383
Batch 48/64 loss: 0.26974213123321533
Batch 49/64 loss: 0.27892839908599854
Batch 50/64 loss: 0.27249276638031006
Batch 51/64 loss: 0.2617940902709961
Batch 52/64 loss: 0.26875627040863037
Batch 53/64 loss: 0.26520925760269165
Batch 54/64 loss: 0.26052379608154297
Batch 55/64 loss: 0.2657756209373474
Batch 56/64 loss: 0.2677733302116394
Batch 57/64 loss: 0.27232325077056885
Batch 58/64 loss: 0.2687990665435791
Batch 59/64 loss: 0.2701549530029297
Batch 60/64 loss: 0.2703065276145935
Batch 61/64 loss: 0.26541590690612793
Batch 62/64 loss: 0.2679474353790283
Batch 63/64 loss: 0.26547473669052124
Batch 64/64 loss: 0.2673717141151428
Epoch 391  Train loss: 0.2673431973831326  Val loss: 0.3120033964258699
Epoch 392
-------------------------------
Batch 1/64 loss: 0.2720685601234436
Batch 2/64 loss: 0.26035594940185547
Batch 3/64 loss: 0.2671654224395752
Batch 4/64 loss: 0.26640450954437256
Batch 5/64 loss: 0.2662677764892578
Batch 6/64 loss: 0.26310789585113525
Batch 7/64 loss: 0.2688150405883789
Batch 8/64 loss: 0.26994478702545166
Batch 9/64 loss: 0.26883184909820557
Batch 10/64 loss: 0.2676997184753418
Batch 11/64 loss: 0.268593430519104
Batch 12/64 loss: 0.2663336992263794
Batch 13/64 loss: 0.2629481554031372
Batch 14/64 loss: 0.2715300917625427
Batch 15/64 loss: 0.26302945613861084
Batch 16/64 loss: 0.2697720527648926
Batch 17/64 loss: 0.265353798866272
Batch 18/64 loss: 0.265547513961792
Batch 19/64 loss: 0.2668273448944092
Batch 20/64 loss: 0.2633932828903198
Batch 21/64 loss: 0.2670629620552063
Batch 22/64 loss: 0.2715580463409424
Batch 23/64 loss: 0.2804051637649536
Batch 24/64 loss: 0.2600284814834595
Batch 25/64 loss: 0.26488304138183594
Batch 26/64 loss: 0.26558053493499756
Batch 27/64 loss: 0.2689749002456665
Batch 28/64 loss: 0.2693837285041809
Batch 29/64 loss: 0.2669394016265869
Batch 30/64 loss: 0.26428723335266113
Batch 31/64 loss: 0.265163779258728
Batch 32/64 loss: 0.2760549783706665
Batch 33/64 loss: 0.27084070444107056
Batch 34/64 loss: 0.26703381538391113
Batch 35/64 loss: 0.27249616384506226
Batch 36/64 loss: 0.2732572555541992
Batch 37/64 loss: 0.2592542767524719
Batch 38/64 loss: 0.2611626386642456
Batch 39/64 loss: 0.25993669033050537
Batch 40/64 loss: 0.27128303050994873
Batch 41/64 loss: 0.26588672399520874
Batch 42/64 loss: 0.26673030853271484
Batch 43/64 loss: 0.26629626750946045
Batch 44/64 loss: 0.2691652774810791
Batch 45/64 loss: 0.26539474725723267
Batch 46/64 loss: 0.2626579999923706
Batch 47/64 loss: 0.27174073457717896
Batch 48/64 loss: 0.26311421394348145
Batch 49/64 loss: 0.2621994614601135
Batch 50/64 loss: 0.2658989429473877
Batch 51/64 loss: 0.2666585445404053
Batch 52/64 loss: 0.26421940326690674
Batch 53/64 loss: 0.2645929455757141
Batch 54/64 loss: 0.26480215787887573
Batch 55/64 loss: 0.2656201124191284
Batch 56/64 loss: 0.2678205966949463
Batch 57/64 loss: 0.2673766613006592
Batch 58/64 loss: 0.2649868130683899
Batch 59/64 loss: 0.2760860323905945
Batch 60/64 loss: 0.26895564794540405
Batch 61/64 loss: 0.26577115058898926
Batch 62/64 loss: 0.26533710956573486
Batch 63/64 loss: 0.26726412773132324
Batch 64/64 loss: 0.2767854332923889
Epoch 392  Train loss: 0.26707046616311164  Val loss: 0.31225562955915315
Epoch 393
-------------------------------
Batch 1/64 loss: 0.2661532163619995
Batch 2/64 loss: 0.2638765573501587
Batch 3/64 loss: 0.2688053250312805
Batch 4/64 loss: 0.27009308338165283
Batch 5/64 loss: 0.26754212379455566
Batch 6/64 loss: 0.2653923034667969
Batch 7/64 loss: 0.27500486373901367
Batch 8/64 loss: 0.2618318796157837
Batch 9/64 loss: 0.26028579473495483
Batch 10/64 loss: 0.26758962869644165
Batch 11/64 loss: 0.2714855670928955
Batch 12/64 loss: 0.26303696632385254
Batch 13/64 loss: 0.2667273283004761
Batch 14/64 loss: 0.2641177177429199
Batch 15/64 loss: 0.2635578513145447
Batch 16/64 loss: 0.26310044527053833
Batch 17/64 loss: 0.2715892791748047
Batch 18/64 loss: 0.2715231776237488
Batch 19/64 loss: 0.2674792408943176
Batch 20/64 loss: 0.2633243203163147
Batch 21/64 loss: 0.27067530155181885
Batch 22/64 loss: 0.26548683643341064
Batch 23/64 loss: 0.2688902020454407
Batch 24/64 loss: 0.26573777198791504
Batch 25/64 loss: 0.26662933826446533
Batch 26/64 loss: 0.2675860524177551
Batch 27/64 loss: 0.2680011987686157
Batch 28/64 loss: 0.2682051658630371
Batch 29/64 loss: 0.2686576843261719
Batch 30/64 loss: 0.26585447788238525
Batch 31/64 loss: 0.261594295501709
Batch 32/64 loss: 0.2616614103317261
Batch 33/64 loss: 0.2607358694076538
Batch 34/64 loss: 0.26613932847976685
Batch 35/64 loss: 0.2654193043708801
Batch 36/64 loss: 0.26718032360076904
Batch 37/64 loss: 0.2666081190109253
Batch 38/64 loss: 0.27040839195251465
Batch 39/64 loss: 0.26672136783599854
Batch 40/64 loss: 0.26362061500549316
Batch 41/64 loss: 0.27103352546691895
Batch 42/64 loss: 0.263181209564209
Batch 43/64 loss: 0.2671339511871338
Batch 44/64 loss: 0.26413798332214355
Batch 45/64 loss: 0.2623816728591919
Batch 46/64 loss: 0.2732347846031189
Batch 47/64 loss: 0.2745283842086792
Batch 48/64 loss: 0.2629173994064331
Batch 49/64 loss: 0.2755781412124634
Batch 50/64 loss: 0.27323007583618164
Batch 51/64 loss: 0.26478832960128784
Batch 52/64 loss: 0.26109373569488525
Batch 53/64 loss: 0.2608850598335266
Batch 54/64 loss: 0.273395836353302
Batch 55/64 loss: 0.26811301708221436
Batch 56/64 loss: 0.2695222496986389
Batch 57/64 loss: 0.2692610025405884
Batch 58/64 loss: 0.2663074731826782
Batch 59/64 loss: 0.27154862880706787
Batch 60/64 loss: 0.2647136449813843
Batch 61/64 loss: 0.2643735408782959
Batch 62/64 loss: 0.2735423445701599
Batch 63/64 loss: 0.2629204988479614
Batch 64/64 loss: 0.26557832956314087
Epoch 393  Train loss: 0.26690723077923645  Val loss: 0.31238456874368936
Epoch 394
-------------------------------
Batch 1/64 loss: 0.26961731910705566
Batch 2/64 loss: 0.2673003673553467
Batch 3/64 loss: 0.26551175117492676
Batch 4/64 loss: 0.265031635761261
Batch 5/64 loss: 0.26679110527038574
Batch 6/64 loss: 0.2656938433647156
Batch 7/64 loss: 0.26235783100128174
Batch 8/64 loss: 0.26746702194213867
Batch 9/64 loss: 0.26663029193878174
Batch 10/64 loss: 0.26915717124938965
Batch 11/64 loss: 0.27275824546813965
Batch 12/64 loss: 0.26012474298477173
Batch 13/64 loss: 0.27545350790023804
Batch 14/64 loss: 0.26738858222961426
Batch 15/64 loss: 0.2639316916465759
Batch 16/64 loss: 0.2717386484146118
Batch 17/64 loss: 0.2622562646865845
Batch 18/64 loss: 0.27002429962158203
Batch 19/64 loss: 0.255628764629364
Batch 20/64 loss: 0.27463454008102417
Batch 21/64 loss: 0.2614712715148926
Batch 22/64 loss: 0.26825523376464844
Batch 23/64 loss: 0.2666323184967041
Batch 24/64 loss: 0.26838624477386475
Batch 25/64 loss: 0.2630060315132141
Batch 26/64 loss: 0.2643364667892456
Batch 27/64 loss: 0.2667430639266968
Batch 28/64 loss: 0.2639641761779785
Batch 29/64 loss: 0.26883208751678467
Batch 30/64 loss: 0.2736382484436035
Batch 31/64 loss: 0.2628215551376343
Batch 32/64 loss: 0.26687127351760864
Batch 33/64 loss: 0.2706301808357239
Batch 34/64 loss: 0.2624518871307373
Batch 35/64 loss: 0.2645171880722046
Batch 36/64 loss: 0.26310914754867554
Batch 37/64 loss: 0.2703969478607178
Batch 38/64 loss: 0.2646963596343994
Batch 39/64 loss: 0.2650781273841858
Batch 40/64 loss: 0.2695150375366211
Batch 41/64 loss: 0.263557493686676
Batch 42/64 loss: 0.26950037479400635
Batch 43/64 loss: 0.26541370153427124
Batch 44/64 loss: 0.26681745052337646
Batch 45/64 loss: 0.2699928283691406
Batch 46/64 loss: 0.26302069425582886
Batch 47/64 loss: 0.25710242986679077
Batch 48/64 loss: 0.26697516441345215
Batch 49/64 loss: 0.2667207717895508
Batch 50/64 loss: 0.2694140076637268
Batch 51/64 loss: 0.26401853561401367
Batch 52/64 loss: 0.2607162594795227
Batch 53/64 loss: 0.269287109375
Batch 54/64 loss: 0.26058924198150635
Batch 55/64 loss: 0.2678713798522949
Batch 56/64 loss: 0.2630953788757324
Batch 57/64 loss: 0.26920396089553833
Batch 58/64 loss: 0.2730250358581543
Batch 59/64 loss: 0.2693890333175659
Batch 60/64 loss: 0.2715621590614319
Batch 61/64 loss: 0.27397316694259644
Batch 62/64 loss: 0.27295494079589844
Batch 63/64 loss: 0.2658684253692627
Batch 64/64 loss: 0.26409196853637695
Epoch 394  Train loss: 0.26671355284896553  Val loss: 0.3130002550243102
Epoch 395
-------------------------------
Batch 1/64 loss: 0.25901055335998535
Batch 2/64 loss: 0.26589441299438477
Batch 3/64 loss: 0.26646339893341064
Batch 4/64 loss: 0.2630978226661682
Batch 5/64 loss: 0.26374220848083496
Batch 6/64 loss: 0.26861220598220825
Batch 7/64 loss: 0.2607002854347229
Batch 8/64 loss: 0.2599084973335266
Batch 9/64 loss: 0.2637042999267578
Batch 10/64 loss: 0.26083046197891235
Batch 11/64 loss: 0.2658116817474365
Batch 12/64 loss: 0.26323825120925903
Batch 13/64 loss: 0.2717086672782898
Batch 14/64 loss: 0.2613053321838379
Batch 15/64 loss: 0.2592025399208069
Batch 16/64 loss: 0.2704771161079407
Batch 17/64 loss: 0.2690584063529968
Batch 18/64 loss: 0.2679605484008789
Batch 19/64 loss: 0.27199095487594604
Batch 20/64 loss: 0.26124465465545654
Batch 21/64 loss: 0.2718759775161743
Batch 22/64 loss: 0.26558852195739746
Batch 23/64 loss: 0.26875442266464233
Batch 24/64 loss: 0.26924532651901245
Batch 25/64 loss: 0.26392537355422974
Batch 26/64 loss: 0.26924383640289307
Batch 27/64 loss: 0.2789521813392639
Batch 28/64 loss: 0.2673145532608032
Batch 29/64 loss: 0.26658445596694946
Batch 30/64 loss: 0.26492226123809814
Batch 31/64 loss: 0.2672843337059021
Batch 32/64 loss: 0.2726917862892151
Batch 33/64 loss: 0.27572405338287354
Batch 34/64 loss: 0.26885300874710083
Batch 35/64 loss: 0.2563234567642212
Batch 36/64 loss: 0.2623140215873718
Batch 37/64 loss: 0.27359819412231445
Batch 38/64 loss: 0.26445531845092773
Batch 39/64 loss: 0.2717666029930115
Batch 40/64 loss: 0.26455408334732056
Batch 41/64 loss: 0.2643236517906189
Batch 42/64 loss: 0.2715413570404053
Batch 43/64 loss: 0.258556604385376
Batch 44/64 loss: 0.25995194911956787
Batch 45/64 loss: 0.2667297124862671
Batch 46/64 loss: 0.2654567360877991
Batch 47/64 loss: 0.26763755083084106
Batch 48/64 loss: 0.27017104625701904
Batch 49/64 loss: 0.27496230602264404
Batch 50/64 loss: 0.2694293260574341
Batch 51/64 loss: 0.26527613401412964
Batch 52/64 loss: 0.2638254165649414
Batch 53/64 loss: 0.26853257417678833
Batch 54/64 loss: 0.2676142454147339
Batch 55/64 loss: 0.2631654739379883
Batch 56/64 loss: 0.2683548927307129
Batch 57/64 loss: 0.26561135053634644
Batch 58/64 loss: 0.2612965703010559
Batch 59/64 loss: 0.27258849143981934
Batch 60/64 loss: 0.2682002782821655
Batch 61/64 loss: 0.27596014738082886
Batch 62/64 loss: 0.265095591545105
Batch 63/64 loss: 0.26914525032043457
Batch 64/64 loss: 0.26535564661026
Epoch 395  Train loss: 0.2666725876284581  Val loss: 0.31266500962149235
Epoch 396
-------------------------------
Batch 1/64 loss: 0.2633482813835144
Batch 2/64 loss: 0.2627209424972534
Batch 3/64 loss: 0.25739896297454834
Batch 4/64 loss: 0.2675480246543884
Batch 5/64 loss: 0.26334571838378906
Batch 6/64 loss: 0.26387858390808105
Batch 7/64 loss: 0.26279568672180176
Batch 8/64 loss: 0.262725293636322
Batch 9/64 loss: 0.26975589990615845
Batch 10/64 loss: 0.26163673400878906
Batch 11/64 loss: 0.2652587890625
Batch 12/64 loss: 0.26596397161483765
Batch 13/64 loss: 0.25694406032562256
Batch 14/64 loss: 0.263077974319458
Batch 15/64 loss: 0.265580415725708
Batch 16/64 loss: 0.2641899585723877
Batch 17/64 loss: 0.2603502869606018
Batch 18/64 loss: 0.2712815999984741
Batch 19/64 loss: 0.2700456380844116
Batch 20/64 loss: 0.2634117603302002
Batch 21/64 loss: 0.26915502548217773
Batch 22/64 loss: 0.26193785667419434
Batch 23/64 loss: 0.2615966796875
Batch 24/64 loss: 0.26577723026275635
Batch 25/64 loss: 0.26668834686279297
Batch 26/64 loss: 0.2630953788757324
Batch 27/64 loss: 0.25905853509902954
Batch 28/64 loss: 0.26785731315612793
Batch 29/64 loss: 0.26457810401916504
Batch 30/64 loss: 0.2647036910057068
Batch 31/64 loss: 0.27260661125183105
Batch 32/64 loss: 0.2641032338142395
Batch 33/64 loss: 0.2675093412399292
Batch 34/64 loss: 0.26856040954589844
Batch 35/64 loss: 0.2684001922607422
Batch 36/64 loss: 0.2667074203491211
Batch 37/64 loss: 0.2711045742034912
Batch 38/64 loss: 0.26084721088409424
Batch 39/64 loss: 0.2718173861503601
Batch 40/64 loss: 0.2680037021636963
Batch 41/64 loss: 0.270832359790802
Batch 42/64 loss: 0.26659858226776123
Batch 43/64 loss: 0.2669416666030884
Batch 44/64 loss: 0.2716289758682251
Batch 45/64 loss: 0.2634730339050293
Batch 46/64 loss: 0.2724975347518921
Batch 47/64 loss: 0.2712770700454712
Batch 48/64 loss: 0.2644343376159668
Batch 49/64 loss: 0.2647818326950073
Batch 50/64 loss: 0.2716302275657654
Batch 51/64 loss: 0.275060772895813
Batch 52/64 loss: 0.27205920219421387
Batch 53/64 loss: 0.26851439476013184
Batch 54/64 loss: 0.2675654888153076
Batch 55/64 loss: 0.2654838562011719
Batch 56/64 loss: 0.26136481761932373
Batch 57/64 loss: 0.26798856258392334
Batch 58/64 loss: 0.27439022064208984
Batch 59/64 loss: 0.2721593379974365
Batch 60/64 loss: 0.26715344190597534
Batch 61/64 loss: 0.26335763931274414
Batch 62/64 loss: 0.26733195781707764
Batch 63/64 loss: 0.2699804902076721
Batch 64/64 loss: 0.2626488208770752
Epoch 396  Train loss: 0.2663350469925824  Val loss: 0.3123203792522863
Epoch 397
-------------------------------
Batch 1/64 loss: 0.26405084133148193
Batch 2/64 loss: 0.26697129011154175
Batch 3/64 loss: 0.26198065280914307
Batch 4/64 loss: 0.2649712562561035
Batch 5/64 loss: 0.2699335217475891
Batch 6/64 loss: 0.2611933946609497
Batch 7/64 loss: 0.2617100477218628
Batch 8/64 loss: 0.27166318893432617
Batch 9/64 loss: 0.2637695074081421
Batch 10/64 loss: 0.2683056592941284
Batch 11/64 loss: 0.2758280038833618
Batch 12/64 loss: 0.2634934186935425
Batch 13/64 loss: 0.266160249710083
Batch 14/64 loss: 0.2690037488937378
Batch 15/64 loss: 0.267278790473938
Batch 16/64 loss: 0.26725852489471436
Batch 17/64 loss: 0.2610219717025757
Batch 18/64 loss: 0.26950186491012573
Batch 19/64 loss: 0.2640899419784546
Batch 20/64 loss: 0.26852285861968994
Batch 21/64 loss: 0.2692462205886841
Batch 22/64 loss: 0.26780641078948975
Batch 23/64 loss: 0.25866031646728516
Batch 24/64 loss: 0.26283013820648193
Batch 25/64 loss: 0.26200366020202637
Batch 26/64 loss: 0.26608771085739136
Batch 27/64 loss: 0.2700865864753723
Batch 28/64 loss: 0.266700804233551
Batch 29/64 loss: 0.2635195255279541
Batch 30/64 loss: 0.2635232210159302
Batch 31/64 loss: 0.2600765824317932
Batch 32/64 loss: 0.26969170570373535
Batch 33/64 loss: 0.25990086793899536
Batch 34/64 loss: 0.26562607288360596
Batch 35/64 loss: 0.2653868794441223
Batch 36/64 loss: 0.27165651321411133
Batch 37/64 loss: 0.2615330219268799
Batch 38/64 loss: 0.2678184509277344
Batch 39/64 loss: 0.2654228210449219
Batch 40/64 loss: 0.266478955745697
Batch 41/64 loss: 0.27044397592544556
Batch 42/64 loss: 0.2705833315849304
Batch 43/64 loss: 0.26795196533203125
Batch 44/64 loss: 0.2715463638305664
Batch 45/64 loss: 0.2597867250442505
Batch 46/64 loss: 0.265313982963562
Batch 47/64 loss: 0.2657294273376465
Batch 48/64 loss: 0.26371073722839355
Batch 49/64 loss: 0.26537424325942993
Batch 50/64 loss: 0.26696252822875977
Batch 51/64 loss: 0.26902204751968384
Batch 52/64 loss: 0.27032357454299927
Batch 53/64 loss: 0.2710033655166626
Batch 54/64 loss: 0.27460843324661255
Batch 55/64 loss: 0.2722278833389282
Batch 56/64 loss: 0.26741641759872437
Batch 57/64 loss: 0.266414999961853
Batch 58/64 loss: 0.2638047933578491
Batch 59/64 loss: 0.26157569885253906
Batch 60/64 loss: 0.27173590660095215
Batch 61/64 loss: 0.2640036344528198
Batch 62/64 loss: 0.26861727237701416
Batch 63/64 loss: 0.27156633138656616
Batch 64/64 loss: 0.27212774753570557
Epoch 397  Train loss: 0.2665817199968824  Val loss: 0.312330259080605
Epoch 398
-------------------------------
Batch 1/64 loss: 0.2582364082336426
Batch 2/64 loss: 0.27293527126312256
Batch 3/64 loss: 0.27022647857666016
Batch 4/64 loss: 0.26034343242645264
Batch 5/64 loss: 0.26166993379592896
Batch 6/64 loss: 0.2623080015182495
Batch 7/64 loss: 0.2669430375099182
Batch 8/64 loss: 0.26190078258514404
Batch 9/64 loss: 0.2639806270599365
Batch 10/64 loss: 0.2678818702697754
Batch 11/64 loss: 0.25600922107696533
Batch 12/64 loss: 0.27086877822875977
Batch 13/64 loss: 0.25761544704437256
Batch 14/64 loss: 0.25847965478897095
Batch 15/64 loss: 0.27400118112564087
Batch 16/64 loss: 0.2699485421180725
Batch 17/64 loss: 0.2726736068725586
Batch 18/64 loss: 0.2655836343765259
Batch 19/64 loss: 0.2694578170776367
Batch 20/64 loss: 0.2657288908958435
Batch 21/64 loss: 0.2622244358062744
Batch 22/64 loss: 0.2634291648864746
Batch 23/64 loss: 0.27201569080352783
Batch 24/64 loss: 0.2679647207260132
Batch 25/64 loss: 0.2651636600494385
Batch 26/64 loss: 0.267753005027771
Batch 27/64 loss: 0.260892391204834
Batch 28/64 loss: 0.26311570405960083
Batch 29/64 loss: 0.2609751224517822
Batch 30/64 loss: 0.2647273540496826
Batch 31/64 loss: 0.26392102241516113
Batch 32/64 loss: 0.264085590839386
Batch 33/64 loss: 0.2643038034439087
Batch 34/64 loss: 0.2745548486709595
Batch 35/64 loss: 0.2601346969604492
Batch 36/64 loss: 0.2635791301727295
Batch 37/64 loss: 0.2612385153770447
Batch 38/64 loss: 0.2720026969909668
Batch 39/64 loss: 0.262023389339447
Batch 40/64 loss: 0.26893115043640137
Batch 41/64 loss: 0.2697823643684387
Batch 42/64 loss: 0.26951372623443604
Batch 43/64 loss: 0.266304612159729
Batch 44/64 loss: 0.2633192539215088
Batch 45/64 loss: 0.2690260410308838
Batch 46/64 loss: 0.25907135009765625
Batch 47/64 loss: 0.2570124864578247
Batch 48/64 loss: 0.26749664545059204
Batch 49/64 loss: 0.2654956579208374
Batch 50/64 loss: 0.26940637826919556
Batch 51/64 loss: 0.25832056999206543
Batch 52/64 loss: 0.2625781297683716
Batch 53/64 loss: 0.27113771438598633
Batch 54/64 loss: 0.26127374172210693
Batch 55/64 loss: 0.2623220682144165
Batch 56/64 loss: 0.2674657106399536
Batch 57/64 loss: 0.2656968832015991
Batch 58/64 loss: 0.2616615295410156
Batch 59/64 loss: 0.2736169695854187
Batch 60/64 loss: 0.26632869243621826
Batch 61/64 loss: 0.2753281593322754
Batch 62/64 loss: 0.27551186084747314
Batch 63/64 loss: 0.26394450664520264
Batch 64/64 loss: 0.26691633462905884
Epoch 398  Train loss: 0.26559421198040833  Val loss: 0.3123188834010121
Epoch 399
-------------------------------
Batch 1/64 loss: 0.2595212459564209
Batch 2/64 loss: 0.26972007751464844
Batch 3/64 loss: 0.2685074210166931
Batch 4/64 loss: 0.2665746212005615
Batch 5/64 loss: 0.26243454217910767
Batch 6/64 loss: 0.2676260471343994
Batch 7/64 loss: 0.2673535943031311
Batch 8/64 loss: 0.263519287109375
Batch 9/64 loss: 0.26884400844573975
Batch 10/64 loss: 0.2659605145454407
Batch 11/64 loss: 0.2665442228317261
Batch 12/64 loss: 0.26622307300567627
Batch 13/64 loss: 0.26661980152130127
Batch 14/64 loss: 0.2683298587799072
Batch 15/64 loss: 0.26815032958984375
Batch 16/64 loss: 0.2645387053489685
Batch 17/64 loss: 0.26647329330444336
Batch 18/64 loss: 0.26214098930358887
Batch 19/64 loss: 0.26569777727127075
Batch 20/64 loss: 0.26474547386169434
Batch 21/64 loss: 0.2659193277359009
Batch 22/64 loss: 0.2626223564147949
Batch 23/64 loss: 0.26340675354003906
Batch 24/64 loss: 0.2637988328933716
Batch 25/64 loss: 0.2635394334793091
Batch 26/64 loss: 0.2732487916946411
Batch 27/64 loss: 0.2681260108947754
Batch 28/64 loss: 0.266956090927124
Batch 29/64 loss: 0.26048964262008667
Batch 30/64 loss: 0.26583313941955566
Batch 31/64 loss: 0.2652709484100342
Batch 32/64 loss: 0.2673588991165161
Batch 33/64 loss: 0.2705889940261841
Batch 34/64 loss: 0.26660364866256714
Batch 35/64 loss: 0.271121621131897
Batch 36/64 loss: 0.2637801170349121
Batch 37/64 loss: 0.2584969997406006
Batch 38/64 loss: 0.25919318199157715
Batch 39/64 loss: 0.26904356479644775
Batch 40/64 loss: 0.2652285099029541
Batch 41/64 loss: 0.2742578387260437
Batch 42/64 loss: 0.2683917284011841
Batch 43/64 loss: 0.2646270990371704
Batch 44/64 loss: 0.26090049743652344
Batch 45/64 loss: 0.26870232820510864
Batch 46/64 loss: 0.26898157596588135
Batch 47/64 loss: 0.26308774948120117
Batch 48/64 loss: 0.26856422424316406
Batch 49/64 loss: 0.2568948268890381
Batch 50/64 loss: 0.266831636428833
Batch 51/64 loss: 0.25806230306625366
Batch 52/64 loss: 0.26519548892974854
Batch 53/64 loss: 0.2628134489059448
Batch 54/64 loss: 0.2645101547241211
Batch 55/64 loss: 0.26855313777923584
Batch 56/64 loss: 0.2669810652732849
Batch 57/64 loss: 0.26435911655426025
Batch 58/64 loss: 0.2696893811225891
Batch 59/64 loss: 0.2641194462776184
Batch 60/64 loss: 0.26223623752593994
Batch 61/64 loss: 0.2628488540649414
Batch 62/64 loss: 0.2696482539176941
Batch 63/64 loss: 0.26641255617141724
Batch 64/64 loss: 0.26567286252975464
Epoch 399  Train loss: 0.26566392697539987  Val loss: 0.3118832250640974
Epoch 400
-------------------------------
Batch 1/64 loss: 0.2673836946487427
Batch 2/64 loss: 0.2577477693557739
Batch 3/64 loss: 0.25705206394195557
Batch 4/64 loss: 0.2776833772659302
Batch 5/64 loss: 0.27719593048095703
Batch 6/64 loss: 0.25566256046295166
Batch 7/64 loss: 0.26215827465057373
Batch 8/64 loss: 0.2703339457511902
Batch 9/64 loss: 0.26874881982803345
Batch 10/64 loss: 0.2653007507324219
Batch 11/64 loss: 0.2713724374771118
Batch 12/64 loss: 0.26769304275512695
Batch 13/64 loss: 0.26672065258026123
Batch 14/64 loss: 0.2631934881210327
Batch 15/64 loss: 0.2638774514198303
Batch 16/64 loss: 0.26652252674102783
Batch 17/64 loss: 0.26940035820007324
Batch 18/64 loss: 0.2570674419403076
Batch 19/64 loss: 0.2660810947418213
Batch 20/64 loss: 0.2702608108520508
Batch 21/64 loss: 0.25783634185791016
Batch 22/64 loss: 0.2639616131782532
Batch 23/64 loss: 0.2668079137802124
Batch 24/64 loss: 0.26159244775772095
Batch 25/64 loss: 0.2700464129447937
Batch 26/64 loss: 0.26862967014312744
Batch 27/64 loss: 0.27044999599456787
Batch 28/64 loss: 0.2742655277252197
Batch 29/64 loss: 0.26713597774505615
Batch 30/64 loss: 0.2692250609397888
Batch 31/64 loss: 0.2626526355743408
Batch 32/64 loss: 0.2652497887611389
Batch 33/64 loss: 0.261507511138916
Batch 34/64 loss: 0.26245665550231934
Batch 35/64 loss: 0.2770489454269409
Batch 36/64 loss: 0.2646383047103882
Batch 37/64 loss: 0.267356812953949
Batch 38/64 loss: 0.2622617483139038
Batch 39/64 loss: 0.26135027408599854
Batch 40/64 loss: 0.260616660118103
Batch 41/64 loss: 0.26607227325439453
Batch 42/64 loss: 0.27796924114227295
Batch 43/64 loss: 0.2650901675224304
Batch 44/64 loss: 0.2638998031616211
Batch 45/64 loss: 0.2626316547393799
Batch 46/64 loss: 0.2660456895828247
Batch 47/64 loss: 0.2697420120239258
Batch 48/64 loss: 0.2632877826690674
Batch 49/64 loss: 0.2666473984718323
Batch 50/64 loss: 0.2587355375289917
Batch 51/64 loss: 0.2707796096801758
Batch 52/64 loss: 0.26985907554626465
Batch 53/64 loss: 0.2658478021621704
Batch 54/64 loss: 0.2664114236831665
Batch 55/64 loss: 0.2751539945602417
Batch 56/64 loss: 0.26042068004608154
Batch 57/64 loss: 0.2643704414367676
Batch 58/64 loss: 0.26964807510375977
Batch 59/64 loss: 0.26656949520111084
Batch 60/64 loss: 0.2647281885147095
Batch 61/64 loss: 0.2692353129386902
Batch 62/64 loss: 0.26981043815612793
Batch 63/64 loss: 0.25839763879776
Batch 64/64 loss: 0.2677794098854065
Epoch 400  Train loss: 0.2661762366107866  Val loss: 0.312283826857498
Epoch 401
-------------------------------
Batch 1/64 loss: 0.2637721300125122
Batch 2/64 loss: 0.2629002332687378
Batch 3/64 loss: 0.2642223834991455
Batch 4/64 loss: 0.2694143056869507
Batch 5/64 loss: 0.26250159740448
Batch 6/64 loss: 0.26701080799102783
Batch 7/64 loss: 0.2624131441116333
Batch 8/64 loss: 0.2706795334815979
Batch 9/64 loss: 0.2719923257827759
Batch 10/64 loss: 0.2629154920578003
Batch 11/64 loss: 0.2649409770965576
Batch 12/64 loss: 0.2613871097564697
Batch 13/64 loss: 0.2609570026397705
Batch 14/64 loss: 0.2743995189666748
Batch 15/64 loss: 0.2621361017227173
Batch 16/64 loss: 0.269459068775177
Batch 17/64 loss: 0.2590293884277344
Batch 18/64 loss: 0.2640588879585266
Batch 19/64 loss: 0.26465272903442383
Batch 20/64 loss: 0.2674252986907959
Batch 21/64 loss: 0.2740973234176636
Batch 22/64 loss: 0.2630051374435425
Batch 23/64 loss: 0.26591867208480835
Batch 24/64 loss: 0.26190823316574097
Batch 25/64 loss: 0.2708180546760559
Batch 26/64 loss: 0.26695144176483154
Batch 27/64 loss: 0.26057761907577515
Batch 28/64 loss: 0.2673065662384033
Batch 29/64 loss: 0.26541388034820557
Batch 30/64 loss: 0.26368188858032227
Batch 31/64 loss: 0.26248878240585327
Batch 32/64 loss: 0.26329100131988525
Batch 33/64 loss: 0.2623039484024048
Batch 34/64 loss: 0.27003413438796997
Batch 35/64 loss: 0.2650912404060364
Batch 36/64 loss: 0.27320003509521484
Batch 37/64 loss: 0.275659441947937
Batch 38/64 loss: 0.26143932342529297
Batch 39/64 loss: 0.2653242349624634
Batch 40/64 loss: 0.26055872440338135
Batch 41/64 loss: 0.27540338039398193
Batch 42/64 loss: 0.26121068000793457
Batch 43/64 loss: 0.2660437822341919
Batch 44/64 loss: 0.26295965909957886
Batch 45/64 loss: 0.2596268057823181
Batch 46/64 loss: 0.2789210081100464
Batch 47/64 loss: 0.25551456212997437
Batch 48/64 loss: 0.2646820545196533
Batch 49/64 loss: 0.2660455107688904
Batch 50/64 loss: 0.26709049940109253
Batch 51/64 loss: 0.2724071741104126
Batch 52/64 loss: 0.26883596181869507
Batch 53/64 loss: 0.2700324058532715
Batch 54/64 loss: 0.2662304639816284
Batch 55/64 loss: 0.2645840644836426
Batch 56/64 loss: 0.2639753818511963
Batch 57/64 loss: 0.2639845609664917
Batch 58/64 loss: 0.26404649019241333
Batch 59/64 loss: 0.2601683735847473
Batch 60/64 loss: 0.2679505944252014
Batch 61/64 loss: 0.26560187339782715
Batch 62/64 loss: 0.2689982056617737
Batch 63/64 loss: 0.27111101150512695
Batch 64/64 loss: 0.26579511165618896
Epoch 401  Train loss: 0.26588405581081614  Val loss: 0.31199604416221277
Epoch 402
-------------------------------
Batch 1/64 loss: 0.2645843029022217
Batch 2/64 loss: 0.2635182738304138
Batch 3/64 loss: 0.2639649510383606
Batch 4/64 loss: 0.26412779092788696
Batch 5/64 loss: 0.2691366672515869
Batch 6/64 loss: 0.2709686756134033
Batch 7/64 loss: 0.2643277645111084
Batch 8/64 loss: 0.26750946044921875
Batch 9/64 loss: 0.27183711528778076
Batch 10/64 loss: 0.2629348039627075
Batch 11/64 loss: 0.25677651166915894
Batch 12/64 loss: 0.2669786810874939
Batch 13/64 loss: 0.2748017907142639
Batch 14/64 loss: 0.2604944109916687
Batch 15/64 loss: 0.2664448022842407
Batch 16/64 loss: 0.26388728618621826
Batch 17/64 loss: 0.2672313451766968
Batch 18/64 loss: 0.2618395686149597
Batch 19/64 loss: 0.2598685622215271
Batch 20/64 loss: 0.27452361583709717
Batch 21/64 loss: 0.26402759552001953
Batch 22/64 loss: 0.2692321538925171
Batch 23/64 loss: 0.2669041156768799
Batch 24/64 loss: 0.2689162492752075
Batch 25/64 loss: 0.2699826955795288
Batch 26/64 loss: 0.26691800355911255
Batch 27/64 loss: 0.27150821685791016
Batch 28/64 loss: 0.26978600025177
Batch 29/64 loss: 0.267932653427124
Batch 30/64 loss: 0.26547515392303467
Batch 31/64 loss: 0.260003924369812
Batch 32/64 loss: 0.2696831226348877
Batch 33/64 loss: 0.2643914222717285
Batch 34/64 loss: 0.26259845495224
Batch 35/64 loss: 0.263774037361145
Batch 36/64 loss: 0.2672841548919678
Batch 37/64 loss: 0.2759250998497009
Batch 38/64 loss: 0.262951135635376
Batch 39/64 loss: 0.2703302502632141
Batch 40/64 loss: 0.2636452913284302
Batch 41/64 loss: 0.2696983814239502
Batch 42/64 loss: 0.26581865549087524
Batch 43/64 loss: 0.263486385345459
Batch 44/64 loss: 0.2700950503349304
Batch 45/64 loss: 0.2695925235748291
Batch 46/64 loss: 0.26557546854019165
Batch 47/64 loss: 0.2634716033935547
Batch 48/64 loss: 0.2620457410812378
Batch 49/64 loss: 0.2613440752029419
Batch 50/64 loss: 0.266587495803833
Batch 51/64 loss: 0.2579549551010132
Batch 52/64 loss: 0.2654964327812195
Batch 53/64 loss: 0.27026277780532837
Batch 54/64 loss: 0.2665318250656128
Batch 55/64 loss: 0.2619110345840454
Batch 56/64 loss: 0.2602193355560303
Batch 57/64 loss: 0.2697460651397705
Batch 58/64 loss: 0.2569081783294678
Batch 59/64 loss: 0.26985257863998413
Batch 60/64 loss: 0.2594500780105591
Batch 61/64 loss: 0.26941537857055664
Batch 62/64 loss: 0.2641223073005676
Batch 63/64 loss: 0.2675565481185913
Batch 64/64 loss: 0.2706877589225769
Epoch 402  Train loss: 0.26599505578770355  Val loss: 0.3124788430138552
Epoch 403
-------------------------------
Batch 1/64 loss: 0.25810009241104126
Batch 2/64 loss: 0.25880885124206543
Batch 3/64 loss: 0.2632738947868347
Batch 4/64 loss: 0.25941771268844604
Batch 5/64 loss: 0.27946048974990845
Batch 6/64 loss: 0.25854218006134033
Batch 7/64 loss: 0.2613416910171509
Batch 8/64 loss: 0.2631824016571045
Batch 9/64 loss: 0.26577889919281006
Batch 10/64 loss: 0.2647116780281067
Batch 11/64 loss: 0.2631518840789795
Batch 12/64 loss: 0.26615452766418457
Batch 13/64 loss: 0.2623560428619385
Batch 14/64 loss: 0.26690900325775146
Batch 15/64 loss: 0.26450449228286743
Batch 16/64 loss: 0.27024269104003906
Batch 17/64 loss: 0.2703855633735657
Batch 18/64 loss: 0.26476556062698364
Batch 19/64 loss: 0.2648847699165344
Batch 20/64 loss: 0.27248334884643555
Batch 21/64 loss: 0.2725546956062317
Batch 22/64 loss: 0.2658199667930603
Batch 23/64 loss: 0.26235222816467285
Batch 24/64 loss: 0.26592952013015747
Batch 25/64 loss: 0.26205146312713623
Batch 26/64 loss: 0.2712641954421997
Batch 27/64 loss: 0.2658146619796753
Batch 28/64 loss: 0.2638958692550659
Batch 29/64 loss: 0.26763176918029785
Batch 30/64 loss: 0.2700439691543579
Batch 31/64 loss: 0.2704143524169922
Batch 32/64 loss: 0.2696053385734558
Batch 33/64 loss: 0.26162290573120117
Batch 34/64 loss: 0.2649468183517456
Batch 35/64 loss: 0.2686445713043213
Batch 36/64 loss: 0.258858323097229
Batch 37/64 loss: 0.26278698444366455
Batch 38/64 loss: 0.27181923389434814
Batch 39/64 loss: 0.2685832977294922
Batch 40/64 loss: 0.26418614387512207
Batch 41/64 loss: 0.2710334062576294
Batch 42/64 loss: 0.26982367038726807
Batch 43/64 loss: 0.27299606800079346
Batch 44/64 loss: 0.2691466212272644
Batch 45/64 loss: 0.2661343216896057
Batch 46/64 loss: 0.2662525177001953
Batch 47/64 loss: 0.2658565640449524
Batch 48/64 loss: 0.2697896957397461
Batch 49/64 loss: 0.26722264289855957
Batch 50/64 loss: 0.26764845848083496
Batch 51/64 loss: 0.26311612129211426
Batch 52/64 loss: 0.26817601919174194
Batch 53/64 loss: 0.2636042833328247
Batch 54/64 loss: 0.27312058210372925
Batch 55/64 loss: 0.27330082654953003
Batch 56/64 loss: 0.25869905948638916
Batch 57/64 loss: 0.2603740692138672
Batch 58/64 loss: 0.2653440833091736
Batch 59/64 loss: 0.26310062408447266
Batch 60/64 loss: 0.2642076015472412
Batch 61/64 loss: 0.26903367042541504
Batch 62/64 loss: 0.26094770431518555
Batch 63/64 loss: 0.2652910351753235
Batch 64/64 loss: 0.26764172315597534
Epoch 403  Train loss: 0.266074243480084  Val loss: 0.31267383213305394
Epoch 404
-------------------------------
Batch 1/64 loss: 0.2732747197151184
Batch 2/64 loss: 0.25824570655822754
Batch 3/64 loss: 0.25914227962493896
Batch 4/64 loss: 0.25923770666122437
Batch 5/64 loss: 0.2682204246520996
Batch 6/64 loss: 0.26499587297439575
Batch 7/64 loss: 0.26352089643478394
Batch 8/64 loss: 0.26362961530685425
Batch 9/64 loss: 0.2630261182785034
Batch 10/64 loss: 0.2665235996246338
Batch 11/64 loss: 0.26313817501068115
Batch 12/64 loss: 0.2581542730331421
Batch 13/64 loss: 0.26276636123657227
Batch 14/64 loss: 0.26672136783599854
Batch 15/64 loss: 0.2691408395767212
Batch 16/64 loss: 0.26733243465423584
Batch 17/64 loss: 0.2683948278427124
Batch 18/64 loss: 0.26834356784820557
Batch 19/64 loss: 0.27162379026412964
Batch 20/64 loss: 0.26387977600097656
Batch 21/64 loss: 0.269206166267395
Batch 22/64 loss: 0.26348716020584106
Batch 23/64 loss: 0.26921677589416504
Batch 24/64 loss: 0.2658073306083679
Batch 25/64 loss: 0.26642167568206787
Batch 26/64 loss: 0.2618544101715088
Batch 27/64 loss: 0.2686907649040222
Batch 28/64 loss: 0.26757073402404785
Batch 29/64 loss: 0.270393967628479
Batch 30/64 loss: 0.2627086043357849
Batch 31/64 loss: 0.26718294620513916
Batch 32/64 loss: 0.26170969009399414
Batch 33/64 loss: 0.2595703601837158
Batch 34/64 loss: 0.27115488052368164
Batch 35/64 loss: 0.2704116702079773
Batch 36/64 loss: 0.2595996856689453
Batch 37/64 loss: 0.26332151889801025
Batch 38/64 loss: 0.2642507553100586
Batch 39/64 loss: 0.26014411449432373
Batch 40/64 loss: 0.2606397867202759
Batch 41/64 loss: 0.2730001211166382
Batch 42/64 loss: 0.26703178882598877
Batch 43/64 loss: 0.2680344581604004
Batch 44/64 loss: 0.2620493173599243
Batch 45/64 loss: 0.2776326537132263
Batch 46/64 loss: 0.26845240592956543
Batch 47/64 loss: 0.2636866569519043
Batch 48/64 loss: 0.2628772258758545
Batch 49/64 loss: 0.2664215564727783
Batch 50/64 loss: 0.26373159885406494
Batch 51/64 loss: 0.26656055450439453
Batch 52/64 loss: 0.2652164697647095
Batch 53/64 loss: 0.26396358013153076
Batch 54/64 loss: 0.2654239535331726
Batch 55/64 loss: 0.26790815591812134
Batch 56/64 loss: 0.27009302377700806
Batch 57/64 loss: 0.26586246490478516
Batch 58/64 loss: 0.2693732976913452
Batch 59/64 loss: 0.2672903537750244
Batch 60/64 loss: 0.26088130474090576
Batch 61/64 loss: 0.26078808307647705
Batch 62/64 loss: 0.2647125720977783
Batch 63/64 loss: 0.2651277780532837
Batch 64/64 loss: 0.2655223608016968
Epoch 404  Train loss: 0.26553594505085665  Val loss: 0.31276166439056396
Epoch 405
-------------------------------
Batch 1/64 loss: 0.26521921157836914
Batch 2/64 loss: 0.2711237072944641
Batch 3/64 loss: 0.26396310329437256
Batch 4/64 loss: 0.26842981576919556
Batch 5/64 loss: 0.2764366865158081
Batch 6/64 loss: 0.27342379093170166
Batch 7/64 loss: 0.2646588087081909
Batch 8/64 loss: 0.2659885287284851
Batch 9/64 loss: 0.2670484185218811
Batch 10/64 loss: 0.2570958137512207
Batch 11/64 loss: 0.2626858353614807
Batch 12/64 loss: 0.2648370862007141
Batch 13/64 loss: 0.2548114061355591
Batch 14/64 loss: 0.2613007426261902
Batch 15/64 loss: 0.27593642473220825
Batch 16/64 loss: 0.26051270961761475
Batch 17/64 loss: 0.26571977138519287
Batch 18/64 loss: 0.2641429901123047
Batch 19/64 loss: 0.26004040241241455
Batch 20/64 loss: 0.2603911757469177
Batch 21/64 loss: 0.2647998332977295
Batch 22/64 loss: 0.2751591205596924
Batch 23/64 loss: 0.2668845057487488
Batch 24/64 loss: 0.264290988445282
Batch 25/64 loss: 0.2734614610671997
Batch 26/64 loss: 0.26344168186187744
Batch 27/64 loss: 0.26559239625930786
Batch 28/64 loss: 0.26694953441619873
Batch 29/64 loss: 0.26486313343048096
Batch 30/64 loss: 0.2639588713645935
Batch 31/64 loss: 0.2698173522949219
Batch 32/64 loss: 0.2671980857849121
Batch 33/64 loss: 0.2612900733947754
Batch 34/64 loss: 0.26211583614349365
Batch 35/64 loss: 0.25930774211883545
Batch 36/64 loss: 0.2595239281654358
Batch 37/64 loss: 0.268609881401062
Batch 38/64 loss: 0.25812363624572754
Batch 39/64 loss: 0.2634526491165161
Batch 40/64 loss: 0.2719559669494629
Batch 41/64 loss: 0.2629082202911377
Batch 42/64 loss: 0.25934505462646484
Batch 43/64 loss: 0.2654740810394287
Batch 44/64 loss: 0.25965452194213867
Batch 45/64 loss: 0.2682998776435852
Batch 46/64 loss: 0.2654794454574585
Batch 47/64 loss: 0.26912981271743774
Batch 48/64 loss: 0.2610493302345276
Batch 49/64 loss: 0.26088231801986694
Batch 50/64 loss: 0.2690739631652832
Batch 51/64 loss: 0.2652716636657715
Batch 52/64 loss: 0.27144479751586914
Batch 53/64 loss: 0.2662614583969116
Batch 54/64 loss: 0.2673305869102478
Batch 55/64 loss: 0.26820194721221924
Batch 56/64 loss: 0.2672337293624878
Batch 57/64 loss: 0.2682607173919678
Batch 58/64 loss: 0.2772798538208008
Batch 59/64 loss: 0.26820147037506104
Batch 60/64 loss: 0.2650439143180847
Batch 61/64 loss: 0.2735551595687866
Batch 62/64 loss: 0.27243125438690186
Batch 63/64 loss: 0.26159751415252686
Batch 64/64 loss: 0.26407456398010254
Epoch 405  Train loss: 0.2658200740814209  Val loss: 0.3127243195202752
Epoch 406
-------------------------------
Batch 1/64 loss: 0.2680985927581787
Batch 2/64 loss: 0.26315104961395264
Batch 3/64 loss: 0.263324499130249
Batch 4/64 loss: 0.25680285692214966
Batch 5/64 loss: 0.2622041702270508
Batch 6/64 loss: 0.2621837854385376
Batch 7/64 loss: 0.26561617851257324
Batch 8/64 loss: 0.2613825798034668
Batch 9/64 loss: 0.2708563804626465
Batch 10/64 loss: 0.26652753353118896
Batch 11/64 loss: 0.2671512961387634
Batch 12/64 loss: 0.26065993309020996
Batch 13/64 loss: 0.26258814334869385
Batch 14/64 loss: 0.26326268911361694
Batch 15/64 loss: 0.2688625454902649
Batch 16/64 loss: 0.2615584135055542
Batch 17/64 loss: 0.27025771141052246
Batch 18/64 loss: 0.27283036708831787
Batch 19/64 loss: 0.26530981063842773
Batch 20/64 loss: 0.26162993907928467
Batch 21/64 loss: 0.26484382152557373
Batch 22/64 loss: 0.27278029918670654
Batch 23/64 loss: 0.27094566822052
Batch 24/64 loss: 0.2614794373512268
Batch 25/64 loss: 0.2654956579208374
Batch 26/64 loss: 0.2627145051956177
Batch 27/64 loss: 0.25907814502716064
Batch 28/64 loss: 0.26813459396362305
Batch 29/64 loss: 0.26751619577407837
Batch 30/64 loss: 0.2663605213165283
Batch 31/64 loss: 0.26722586154937744
Batch 32/64 loss: 0.27020835876464844
Batch 33/64 loss: 0.2671507000923157
Batch 34/64 loss: 0.2638772130012512
Batch 35/64 loss: 0.2630009651184082
Batch 36/64 loss: 0.2682896852493286
Batch 37/64 loss: 0.26049190759658813
Batch 38/64 loss: 0.2740398645401001
Batch 39/64 loss: 0.2711375951766968
Batch 40/64 loss: 0.26396477222442627
Batch 41/64 loss: 0.26428961753845215
Batch 42/64 loss: 0.2666935324668884
Batch 43/64 loss: 0.25996994972229004
Batch 44/64 loss: 0.268033504486084
Batch 45/64 loss: 0.26433616876602173
Batch 46/64 loss: 0.2669219970703125
Batch 47/64 loss: 0.2708550691604614
Batch 48/64 loss: 0.2652299404144287
Batch 49/64 loss: 0.2638331651687622
Batch 50/64 loss: 0.2708374261856079
Batch 51/64 loss: 0.2619349956512451
Batch 52/64 loss: 0.25811004638671875
Batch 53/64 loss: 0.27068907022476196
Batch 54/64 loss: 0.27268803119659424
Batch 55/64 loss: 0.2632257342338562
Batch 56/64 loss: 0.2654207944869995
Batch 57/64 loss: 0.26915067434310913
Batch 58/64 loss: 0.26454031467437744
Batch 59/64 loss: 0.26566123962402344
Batch 60/64 loss: 0.25839030742645264
Batch 61/64 loss: 0.26795637607574463
Batch 62/64 loss: 0.26815593242645264
Batch 63/64 loss: 0.2625586986541748
Batch 64/64 loss: 0.2672894597053528
Epoch 406  Train loss: 0.2656148066707686  Val loss: 0.31210736331251476
Epoch 407
-------------------------------
Batch 1/64 loss: 0.26381099224090576
Batch 2/64 loss: 0.25824564695358276
Batch 3/64 loss: 0.26751208305358887
Batch 4/64 loss: 0.2612103223800659
Batch 5/64 loss: 0.26527726650238037
Batch 6/64 loss: 0.25639599561691284
Batch 7/64 loss: 0.2675670385360718
Batch 8/64 loss: 0.25933682918548584
Batch 9/64 loss: 0.27339309453964233
Batch 10/64 loss: 0.2626887559890747
Batch 11/64 loss: 0.26533639430999756
Batch 12/64 loss: 0.27068352699279785
Batch 13/64 loss: 0.2738906741142273
Batch 14/64 loss: 0.2640998363494873
Batch 15/64 loss: 0.26910197734832764
Batch 16/64 loss: 0.26368576288223267
Batch 17/64 loss: 0.264016330242157
Batch 18/64 loss: 0.25852954387664795
Batch 19/64 loss: 0.2716304063796997
Batch 20/64 loss: 0.269763708114624
Batch 21/64 loss: 0.26369351148605347
Batch 22/64 loss: 0.2650074362754822
Batch 23/64 loss: 0.2636985182762146
Batch 24/64 loss: 0.25931358337402344
Batch 25/64 loss: 0.2608330249786377
Batch 26/64 loss: 0.25861817598342896
Batch 27/64 loss: 0.27418291568756104
Batch 28/64 loss: 0.26454806327819824
Batch 29/64 loss: 0.2610725164413452
Batch 30/64 loss: 0.26503586769104004
Batch 31/64 loss: 0.27060240507125854
Batch 32/64 loss: 0.2627682685852051
Batch 33/64 loss: 0.2722049951553345
Batch 34/64 loss: 0.2611527442932129
Batch 35/64 loss: 0.26976537704467773
Batch 36/64 loss: 0.266027569770813
Batch 37/64 loss: 0.26440346240997314
Batch 38/64 loss: 0.2645253539085388
Batch 39/64 loss: 0.2629930377006531
Batch 40/64 loss: 0.2608901858329773
Batch 41/64 loss: 0.26429951190948486
Batch 42/64 loss: 0.26610302925109863
Batch 43/64 loss: 0.2661762237548828
Batch 44/64 loss: 0.2694847583770752
Batch 45/64 loss: 0.2680153250694275
Batch 46/64 loss: 0.26180732250213623
Batch 47/64 loss: 0.25943273305892944
Batch 48/64 loss: 0.2690908908843994
Batch 49/64 loss: 0.27661192417144775
Batch 50/64 loss: 0.26349931955337524
Batch 51/64 loss: 0.2601271867752075
Batch 52/64 loss: 0.2690478563308716
Batch 53/64 loss: 0.2696988582611084
Batch 54/64 loss: 0.26851946115493774
Batch 55/64 loss: 0.2662268877029419
Batch 56/64 loss: 0.27256524562835693
Batch 57/64 loss: 0.2733933925628662
Batch 58/64 loss: 0.2665964365005493
Batch 59/64 loss: 0.27083873748779297
Batch 60/64 loss: 0.26668524742126465
Batch 61/64 loss: 0.2650969624519348
Batch 62/64 loss: 0.26545846462249756
Batch 63/64 loss: 0.26743006706237793
Batch 64/64 loss: 0.2590695023536682
Epoch 407  Train loss: 0.26569444969588635  Val loss: 0.3123541767244896
Epoch 408
-------------------------------
Batch 1/64 loss: 0.2676146626472473
Batch 2/64 loss: 0.2644107937812805
Batch 3/64 loss: 0.2654680013656616
Batch 4/64 loss: 0.2601959705352783
Batch 5/64 loss: 0.274445116519928
Batch 6/64 loss: 0.26099860668182373
Batch 7/64 loss: 0.27107298374176025
Batch 8/64 loss: 0.26232218742370605
Batch 9/64 loss: 0.2640116214752197
Batch 10/64 loss: 0.25976675748825073
Batch 11/64 loss: 0.2691793441772461
Batch 12/64 loss: 0.2645072937011719
Batch 13/64 loss: 0.26240915060043335
Batch 14/64 loss: 0.2628519535064697
Batch 15/64 loss: 0.2618882656097412
Batch 16/64 loss: 0.2667759656906128
Batch 17/64 loss: 0.26693034172058105
Batch 18/64 loss: 0.26414501667022705
Batch 19/64 loss: 0.26970529556274414
Batch 20/64 loss: 0.2652472257614136
Batch 21/64 loss: 0.2658712863922119
Batch 22/64 loss: 0.26197612285614014
Batch 23/64 loss: 0.2629058361053467
Batch 24/64 loss: 0.2735084891319275
Batch 25/64 loss: 0.26237326860427856
Batch 26/64 loss: 0.258891224861145
Batch 27/64 loss: 0.2610316276550293
Batch 28/64 loss: 0.26672524213790894
Batch 29/64 loss: 0.2760067582130432
Batch 30/64 loss: 0.2616179585456848
Batch 31/64 loss: 0.27047479152679443
Batch 32/64 loss: 0.26425445079803467
Batch 33/64 loss: 0.26207536458969116
Batch 34/64 loss: 0.26210200786590576
Batch 35/64 loss: 0.26297467947006226
Batch 36/64 loss: 0.2682870626449585
Batch 37/64 loss: 0.26003211736679077
Batch 38/64 loss: 0.2663235664367676
Batch 39/64 loss: 0.2688513994216919
Batch 40/64 loss: 0.26835834980010986
Batch 41/64 loss: 0.2608438730239868
Batch 42/64 loss: 0.27772819995880127
Batch 43/64 loss: 0.26140469312667847
Batch 44/64 loss: 0.25920289754867554
Batch 45/64 loss: 0.26916003227233887
Batch 46/64 loss: 0.2660033702850342
Batch 47/64 loss: 0.26495039463043213
Batch 48/64 loss: 0.26218199729919434
Batch 49/64 loss: 0.2616557478904724
Batch 50/64 loss: 0.26599860191345215
Batch 51/64 loss: 0.26560819149017334
Batch 52/64 loss: 0.26987308263778687
Batch 53/64 loss: 0.2627055048942566
Batch 54/64 loss: 0.26971548795700073
Batch 55/64 loss: 0.2642405033111572
Batch 56/64 loss: 0.26496267318725586
Batch 57/64 loss: 0.27114903926849365
Batch 58/64 loss: 0.2733471989631653
Batch 59/64 loss: 0.26042985916137695
Batch 60/64 loss: 0.26957428455352783
Batch 61/64 loss: 0.26397234201431274
Batch 62/64 loss: 0.26023876667022705
Batch 63/64 loss: 0.26404744386672974
Batch 64/64 loss: 0.2628667950630188
Epoch 408  Train loss: 0.26532913633421357  Val loss: 0.3131160559932801
Epoch 409
-------------------------------
Batch 1/64 loss: 0.27170324325561523
Batch 2/64 loss: 0.2612628936767578
Batch 3/64 loss: 0.26917481422424316
Batch 4/64 loss: 0.261974573135376
Batch 5/64 loss: 0.26817989349365234
Batch 6/64 loss: 0.2683607339859009
Batch 7/64 loss: 0.2633976936340332
Batch 8/64 loss: 0.2643318176269531
Batch 9/64 loss: 0.2676481008529663
Batch 10/64 loss: 0.2694607973098755
Batch 11/64 loss: 0.2691459655761719
Batch 12/64 loss: 0.2583965063095093
Batch 13/64 loss: 0.26172202825546265
Batch 14/64 loss: 0.26851534843444824
Batch 15/64 loss: 0.26290231943130493
Batch 16/64 loss: 0.2655237317085266
Batch 17/64 loss: 0.2645033597946167
Batch 18/64 loss: 0.2680327892303467
Batch 19/64 loss: 0.26318591833114624
Batch 20/64 loss: 0.2589867115020752
Batch 21/64 loss: 0.2607347369194031
Batch 22/64 loss: 0.26376521587371826
Batch 23/64 loss: 0.26338183879852295
Batch 24/64 loss: 0.26804304122924805
Batch 25/64 loss: 0.2597583532333374
Batch 26/64 loss: 0.26611584424972534
Batch 27/64 loss: 0.27055126428604126
Batch 28/64 loss: 0.2687435746192932
Batch 29/64 loss: 0.26531875133514404
Batch 30/64 loss: 0.26029038429260254
Batch 31/64 loss: 0.2636217474937439
Batch 32/64 loss: 0.26037847995758057
Batch 33/64 loss: 0.2671973705291748
Batch 34/64 loss: 0.26369714736938477
Batch 35/64 loss: 0.26918691396713257
Batch 36/64 loss: 0.2638678550720215
Batch 37/64 loss: 0.26423943042755127
Batch 38/64 loss: 0.2655392289161682
Batch 39/64 loss: 0.2650989890098572
Batch 40/64 loss: 0.2640910744667053
Batch 41/64 loss: 0.261059045791626
Batch 42/64 loss: 0.2633422613143921
Batch 43/64 loss: 0.26438480615615845
Batch 44/64 loss: 0.2720980644226074
Batch 45/64 loss: 0.26510393619537354
Batch 46/64 loss: 0.2648545503616333
Batch 47/64 loss: 0.2647469639778137
Batch 48/64 loss: 0.25732100009918213
Batch 49/64 loss: 0.27084851264953613
Batch 50/64 loss: 0.26409757137298584
Batch 51/64 loss: 0.26705098152160645
Batch 52/64 loss: 0.2619805335998535
Batch 53/64 loss: 0.27338874340057373
Batch 54/64 loss: 0.2625530958175659
Batch 55/64 loss: 0.2641749382019043
Batch 56/64 loss: 0.26195353269577026
Batch 57/64 loss: 0.26802003383636475
Batch 58/64 loss: 0.27331244945526123
Batch 59/64 loss: 0.260161817073822
Batch 60/64 loss: 0.26681381464004517
Batch 61/64 loss: 0.2656745910644531
Batch 62/64 loss: 0.26490479707717896
Batch 63/64 loss: 0.2670607566833496
Batch 64/64 loss: 0.26780033111572266
Epoch 409  Train loss: 0.26518882396174415  Val loss: 0.31231835986330747
Epoch 410
-------------------------------
Batch 1/64 loss: 0.2722536325454712
Batch 2/64 loss: 0.26818251609802246
Batch 3/64 loss: 0.26184964179992676
Batch 4/64 loss: 0.25954627990722656
Batch 5/64 loss: 0.2636144161224365
Batch 6/64 loss: 0.2642747163772583
Batch 7/64 loss: 0.26677465438842773
Batch 8/64 loss: 0.278112530708313
Batch 9/64 loss: 0.26395440101623535
Batch 10/64 loss: 0.26543116569519043
Batch 11/64 loss: 0.2645035982131958
Batch 12/64 loss: 0.2712867856025696
Batch 13/64 loss: 0.2626526355743408
Batch 14/64 loss: 0.25948387384414673
Batch 15/64 loss: 0.2737356424331665
Batch 16/64 loss: 0.2690250873565674
Batch 17/64 loss: 0.2620809078216553
Batch 18/64 loss: 0.2677004337310791
Batch 19/64 loss: 0.2632482051849365
Batch 20/64 loss: 0.2585775852203369
Batch 21/64 loss: 0.2591816782951355
Batch 22/64 loss: 0.26258623600006104
Batch 23/64 loss: 0.2596805691719055
Batch 24/64 loss: 0.26365041732788086
Batch 25/64 loss: 0.2719752788543701
Batch 26/64 loss: 0.2657815217971802
Batch 27/64 loss: 0.267897367477417
Batch 28/64 loss: 0.2657574415206909
Batch 29/64 loss: 0.26488351821899414
Batch 30/64 loss: 0.26377785205841064
Batch 31/64 loss: 0.2633253335952759
Batch 32/64 loss: 0.27095991373062134
Batch 33/64 loss: 0.2700890302658081
Batch 34/64 loss: 0.26689183712005615
Batch 35/64 loss: 0.2674935460090637
Batch 36/64 loss: 0.26291966438293457
Batch 37/64 loss: 0.26302075386047363
Batch 38/64 loss: 0.2612631320953369
Batch 39/64 loss: 0.2615779638290405
Batch 40/64 loss: 0.26170146465301514
Batch 41/64 loss: 0.26777100563049316
Batch 42/64 loss: 0.2621995210647583
Batch 43/64 loss: 0.2621653079986572
Batch 44/64 loss: 0.264648973941803
Batch 45/64 loss: 0.2649432420730591
Batch 46/64 loss: 0.2590789198875427
Batch 47/64 loss: 0.26508110761642456
Batch 48/64 loss: 0.27044498920440674
Batch 49/64 loss: 0.2711770534515381
Batch 50/64 loss: 0.26800572872161865
Batch 51/64 loss: 0.2611231803894043
Batch 52/64 loss: 0.26583147048950195
Batch 53/64 loss: 0.2687731981277466
Batch 54/64 loss: 0.2604261636734009
Batch 55/64 loss: 0.26138925552368164
Batch 56/64 loss: 0.25886070728302
Batch 57/64 loss: 0.2648821473121643
Batch 58/64 loss: 0.2696705460548401
Batch 59/64 loss: 0.2724863886833191
Batch 60/64 loss: 0.26438748836517334
Batch 61/64 loss: 0.2677692174911499
Batch 62/64 loss: 0.26670658588409424
Batch 63/64 loss: 0.26849937438964844
Batch 64/64 loss: 0.2640543580055237
Epoch 410  Train loss: 0.2653343619084826  Val loss: 0.3118154867408202
Epoch 411
-------------------------------
Batch 1/64 loss: 0.27415502071380615
Batch 2/64 loss: 0.26777172088623047
Batch 3/64 loss: 0.2659611105918884
Batch 4/64 loss: 0.26292920112609863
Batch 5/64 loss: 0.2656456232070923
Batch 6/64 loss: 0.26326847076416016
Batch 7/64 loss: 0.2617795467376709
Batch 8/64 loss: 0.26436853408813477
Batch 9/64 loss: 0.2593693137168884
Batch 10/64 loss: 0.2589908838272095
Batch 11/64 loss: 0.26469886302948
Batch 12/64 loss: 0.2608656883239746
Batch 13/64 loss: 0.2623708248138428
Batch 14/64 loss: 0.26474297046661377
Batch 15/64 loss: 0.2620564103126526
Batch 16/64 loss: 0.2689918279647827
Batch 17/64 loss: 0.25970035791397095
Batch 18/64 loss: 0.26742875576019287
Batch 19/64 loss: 0.260248601436615
Batch 20/64 loss: 0.26309192180633545
Batch 21/64 loss: 0.2708240747451782
Batch 22/64 loss: 0.25900083780288696
Batch 23/64 loss: 0.26605892181396484
Batch 24/64 loss: 0.2631993293762207
Batch 25/64 loss: 0.26243215799331665
Batch 26/64 loss: 0.27159297466278076
Batch 27/64 loss: 0.26456743478775024
Batch 28/64 loss: 0.2694512605667114
Batch 29/64 loss: 0.25949645042419434
Batch 30/64 loss: 0.26384246349334717
Batch 31/64 loss: 0.26370424032211304
Batch 32/64 loss: 0.2639155387878418
Batch 33/64 loss: 0.2744734287261963
Batch 34/64 loss: 0.2615293264389038
Batch 35/64 loss: 0.2666424512863159
Batch 36/64 loss: 0.26899850368499756
Batch 37/64 loss: 0.2641843557357788
Batch 38/64 loss: 0.2584472894668579
Batch 39/64 loss: 0.25716543197631836
Batch 40/64 loss: 0.26256120204925537
Batch 41/64 loss: 0.27975237369537354
Batch 42/64 loss: 0.271795392036438
Batch 43/64 loss: 0.26713645458221436
Batch 44/64 loss: 0.2586853504180908
Batch 45/64 loss: 0.2668079137802124
Batch 46/64 loss: 0.26139020919799805
Batch 47/64 loss: 0.2713314890861511
Batch 48/64 loss: 0.27214765548706055
Batch 49/64 loss: 0.2643996477127075
Batch 50/64 loss: 0.2672646641731262
Batch 51/64 loss: 0.2704271078109741
Batch 52/64 loss: 0.2643977403640747
Batch 53/64 loss: 0.26651620864868164
Batch 54/64 loss: 0.2629518508911133
Batch 55/64 loss: 0.2652033567428589
Batch 56/64 loss: 0.26045459508895874
Batch 57/64 loss: 0.2664753198623657
Batch 58/64 loss: 0.2763669490814209
Batch 59/64 loss: 0.2656037211418152
Batch 60/64 loss: 0.2637200355529785
Batch 61/64 loss: 0.2674025297164917
Batch 62/64 loss: 0.259939968585968
Batch 63/64 loss: 0.26975488662719727
Batch 64/64 loss: 0.26242685317993164
Epoch 411  Train loss: 0.26521206089094573  Val loss: 0.3123266916094777
Epoch 412
-------------------------------
Batch 1/64 loss: 0.2628927230834961
Batch 2/64 loss: 0.26875758171081543
Batch 3/64 loss: 0.2576756477355957
Batch 4/64 loss: 0.26019155979156494
Batch 5/64 loss: 0.26231056451797485
Batch 6/64 loss: 0.26295602321624756
Batch 7/64 loss: 0.2609120011329651
Batch 8/64 loss: 0.2675483226776123
Batch 9/64 loss: 0.26641637086868286
Batch 10/64 loss: 0.2694539427757263
Batch 11/64 loss: 0.265323281288147
Batch 12/64 loss: 0.25999003648757935
Batch 13/64 loss: 0.25883275270462036
Batch 14/64 loss: 0.2670465111732483
Batch 15/64 loss: 0.2625206708908081
Batch 16/64 loss: 0.26733458042144775
Batch 17/64 loss: 0.258877158164978
Batch 18/64 loss: 0.2666582465171814
Batch 19/64 loss: 0.26176130771636963
Batch 20/64 loss: 0.2633592486381531
Batch 21/64 loss: 0.2671055197715759
Batch 22/64 loss: 0.2671847343444824
Batch 23/64 loss: 0.2724263668060303
Batch 24/64 loss: 0.2599080801010132
Batch 25/64 loss: 0.2630274295806885
Batch 26/64 loss: 0.26880455017089844
Batch 27/64 loss: 0.2670259475708008
Batch 28/64 loss: 0.2664223909378052
Batch 29/64 loss: 0.265102744102478
Batch 30/64 loss: 0.2682511806488037
Batch 31/64 loss: 0.2635781764984131
Batch 32/64 loss: 0.2760772109031677
Batch 33/64 loss: 0.26227205991744995
Batch 34/64 loss: 0.25914740562438965
Batch 35/64 loss: 0.2653310298919678
Batch 36/64 loss: 0.26412105560302734
Batch 37/64 loss: 0.26341354846954346
Batch 38/64 loss: 0.2715529203414917
Batch 39/64 loss: 0.2599034309387207
Batch 40/64 loss: 0.27308446168899536
Batch 41/64 loss: 0.26150834560394287
Batch 42/64 loss: 0.2625364661216736
Batch 43/64 loss: 0.26125943660736084
Batch 44/64 loss: 0.26594078540802
Batch 45/64 loss: 0.2615889310836792
Batch 46/64 loss: 0.2600511312484741
Batch 47/64 loss: 0.2663767337799072
Batch 48/64 loss: 0.2604164481163025
Batch 49/64 loss: 0.2656543254852295
Batch 50/64 loss: 0.2602006196975708
Batch 51/64 loss: 0.2635316848754883
Batch 52/64 loss: 0.27023154497146606
Batch 53/64 loss: 0.26107919216156006
Batch 54/64 loss: 0.27220553159713745
Batch 55/64 loss: 0.2636253833770752
Batch 56/64 loss: 0.2609364986419678
Batch 57/64 loss: 0.26668381690979004
Batch 58/64 loss: 0.27134835720062256
Batch 59/64 loss: 0.26275748014450073
Batch 60/64 loss: 0.2682209014892578
Batch 61/64 loss: 0.26997488737106323
Batch 62/64 loss: 0.26986008882522583
Batch 63/64 loss: 0.2565551996231079
Batch 64/64 loss: 0.2673509120941162
Epoch 412  Train loss: 0.26474691372291714  Val loss: 0.31353103069914984
Epoch 413
-------------------------------
Batch 1/64 loss: 0.25969594717025757
Batch 2/64 loss: 0.26449573040008545
Batch 3/64 loss: 0.25781333446502686
Batch 4/64 loss: 0.26190853118896484
Batch 5/64 loss: 0.25795722007751465
Batch 6/64 loss: 0.2654378414154053
Batch 7/64 loss: 0.2604084014892578
Batch 8/64 loss: 0.26140904426574707
Batch 9/64 loss: 0.2690187096595764
Batch 10/64 loss: 0.25938570499420166
Batch 11/64 loss: 0.26256507635116577
Batch 12/64 loss: 0.2606204152107239
Batch 13/64 loss: 0.2627882957458496
Batch 14/64 loss: 0.2729341387748718
Batch 15/64 loss: 0.2648388743400574
Batch 16/64 loss: 0.27020156383514404
Batch 17/64 loss: 0.263582706451416
Batch 18/64 loss: 0.2713766098022461
Batch 19/64 loss: 0.25817954540252686
Batch 20/64 loss: 0.26719141006469727
Batch 21/64 loss: 0.2635205388069153
Batch 22/64 loss: 0.2636294364929199
Batch 23/64 loss: 0.2665894031524658
Batch 24/64 loss: 0.262271523475647
Batch 25/64 loss: 0.26528120040893555
Batch 26/64 loss: 0.2668275833129883
Batch 27/64 loss: 0.26906418800354004
Batch 28/64 loss: 0.2597827911376953
Batch 29/64 loss: 0.26478397846221924
Batch 30/64 loss: 0.2637787461280823
Batch 31/64 loss: 0.2594221830368042
Batch 32/64 loss: 0.25593674182891846
Batch 33/64 loss: 0.25867295265197754
Batch 34/64 loss: 0.26241064071655273
Batch 35/64 loss: 0.26262688636779785
Batch 36/64 loss: 0.2665966749191284
Batch 37/64 loss: 0.26060330867767334
Batch 38/64 loss: 0.27131545543670654
Batch 39/64 loss: 0.26139891147613525
Batch 40/64 loss: 0.2591440677642822
Batch 41/64 loss: 0.26729726791381836
Batch 42/64 loss: 0.25942742824554443
Batch 43/64 loss: 0.2690197229385376
Batch 44/64 loss: 0.26011788845062256
Batch 45/64 loss: 0.25821393728256226
Batch 46/64 loss: 0.26445430517196655
Batch 47/64 loss: 0.2672087550163269
Batch 48/64 loss: 0.2666475772857666
Batch 49/64 loss: 0.2609506845474243
Batch 50/64 loss: 0.2725942134857178
Batch 51/64 loss: 0.26807498931884766
Batch 52/64 loss: 0.2638360261917114
Batch 53/64 loss: 0.2612873315811157
Batch 54/64 loss: 0.270534873008728
Batch 55/64 loss: 0.262168288230896
Batch 56/64 loss: 0.26356935501098633
Batch 57/64 loss: 0.2643512487411499
Batch 58/64 loss: 0.265150785446167
Batch 59/64 loss: 0.26639091968536377
Batch 60/64 loss: 0.2696366310119629
Batch 61/64 loss: 0.2686575651168823
Batch 62/64 loss: 0.26329004764556885
Batch 63/64 loss: 0.2644122838973999
Batch 64/64 loss: 0.26854950189590454
Epoch 413  Train loss: 0.26406542062759397  Val loss: 0.31237847514168915
Epoch 414
-------------------------------
Batch 1/64 loss: 0.2617509961128235
Batch 2/64 loss: 0.2622537612915039
Batch 3/64 loss: 0.2633492946624756
Batch 4/64 loss: 0.26954108476638794
Batch 5/64 loss: 0.26069486141204834
Batch 6/64 loss: 0.2628386616706848
Batch 7/64 loss: 0.25556260347366333
Batch 8/64 loss: 0.26702243089675903
Batch 9/64 loss: 0.26357483863830566
Batch 10/64 loss: 0.2636369466781616
Batch 11/64 loss: 0.2611597776412964
Batch 12/64 loss: 0.2595200538635254
Batch 13/64 loss: 0.26762163639068604
Batch 14/64 loss: 0.26531022787094116
Batch 15/64 loss: 0.2635788917541504
Batch 16/64 loss: 0.2623172998428345
Batch 17/64 loss: 0.26297056674957275
Batch 18/64 loss: 0.26368749141693115
Batch 19/64 loss: 0.2677046060562134
Batch 20/64 loss: 0.2647373676300049
Batch 21/64 loss: 0.2643965482711792
Batch 22/64 loss: 0.2619365453720093
Batch 23/64 loss: 0.26107800006866455
Batch 24/64 loss: 0.26558917760849
Batch 25/64 loss: 0.26389849185943604
Batch 26/64 loss: 0.2638819217681885
Batch 27/64 loss: 0.2568325996398926
Batch 28/64 loss: 0.2651059031486511
Batch 29/64 loss: 0.26276350021362305
Batch 30/64 loss: 0.26570725440979004
Batch 31/64 loss: 0.26446449756622314
Batch 32/64 loss: 0.2650359869003296
Batch 33/64 loss: 0.26561594009399414
Batch 34/64 loss: 0.2618974447250366
Batch 35/64 loss: 0.2634126543998718
Batch 36/64 loss: 0.2628364562988281
Batch 37/64 loss: 0.26385390758514404
Batch 38/64 loss: 0.26908349990844727
Batch 39/64 loss: 0.2733418941497803
Batch 40/64 loss: 0.2667348384857178
Batch 41/64 loss: 0.26368236541748047
Batch 42/64 loss: 0.2653815746307373
Batch 43/64 loss: 0.26499122381210327
Batch 44/64 loss: 0.26237523555755615
Batch 45/64 loss: 0.2577701807022095
Batch 46/64 loss: 0.26537561416625977
Batch 47/64 loss: 0.2599160671234131
Batch 48/64 loss: 0.271770715713501
Batch 49/64 loss: 0.263671875
Batch 50/64 loss: 0.27039676904678345
Batch 51/64 loss: 0.26858413219451904
Batch 52/64 loss: 0.2754913568496704
Batch 53/64 loss: 0.2624824047088623
Batch 54/64 loss: 0.27060467004776
Batch 55/64 loss: 0.2637566328048706
Batch 56/64 loss: 0.25904834270477295
Batch 57/64 loss: 0.2659076452255249
Batch 58/64 loss: 0.25708603858947754
Batch 59/64 loss: 0.2681218981742859
Batch 60/64 loss: 0.26522552967071533
Batch 61/64 loss: 0.27148258686065674
Batch 62/64 loss: 0.26577287912368774
Batch 63/64 loss: 0.26382482051849365
Batch 64/64 loss: 0.26878392696380615
Epoch 414  Train loss: 0.2644801406299367  Val loss: 0.3122904001642339
Epoch 415
-------------------------------
Batch 1/64 loss: 0.26033735275268555
Batch 2/64 loss: 0.279161274433136
Batch 3/64 loss: 0.2662297487258911
Batch 4/64 loss: 0.2628709077835083
Batch 5/64 loss: 0.2677243947982788
Batch 6/64 loss: 0.25986623764038086
Batch 7/64 loss: 0.26557457447052
Batch 8/64 loss: 0.2603476643562317
Batch 9/64 loss: 0.2692047357559204
Batch 10/64 loss: 0.2684361934661865
Batch 11/64 loss: 0.2607465982437134
Batch 12/64 loss: 0.266648530960083
Batch 13/64 loss: 0.26154398918151855
Batch 14/64 loss: 0.2594304084777832
Batch 15/64 loss: 0.2695227265357971
Batch 16/64 loss: 0.2664589285850525
Batch 17/64 loss: 0.2651585340499878
Batch 18/64 loss: 0.2660526633262634
Batch 19/64 loss: 0.2697230577468872
Batch 20/64 loss: 0.26721370220184326
Batch 21/64 loss: 0.25551193952560425
Batch 22/64 loss: 0.26794421672821045
Batch 23/64 loss: 0.26515376567840576
Batch 24/64 loss: 0.2636125087738037
Batch 25/64 loss: 0.2652817368507385
Batch 26/64 loss: 0.2648584842681885
Batch 27/64 loss: 0.26672136783599854
Batch 28/64 loss: 0.26564204692840576
Batch 29/64 loss: 0.2619844079017639
Batch 30/64 loss: 0.25901126861572266
Batch 31/64 loss: 0.26789093017578125
Batch 32/64 loss: 0.2578366994857788
Batch 33/64 loss: 0.26490938663482666
Batch 34/64 loss: 0.2651301622390747
Batch 35/64 loss: 0.261228084564209
Batch 36/64 loss: 0.2591278553009033
Batch 37/64 loss: 0.26449596881866455
Batch 38/64 loss: 0.2619406580924988
Batch 39/64 loss: 0.26517003774642944
Batch 40/64 loss: 0.26707959175109863
Batch 41/64 loss: 0.265933096408844
Batch 42/64 loss: 0.2663891315460205
Batch 43/64 loss: 0.26365649700164795
Batch 44/64 loss: 0.2707401514053345
Batch 45/64 loss: 0.2642757296562195
Batch 46/64 loss: 0.2668405771255493
Batch 47/64 loss: 0.26745903491973877
Batch 48/64 loss: 0.2658200263977051
Batch 49/64 loss: 0.2710416316986084
Batch 50/64 loss: 0.2633277177810669
Batch 51/64 loss: 0.26491034030914307
Batch 52/64 loss: 0.2640780806541443
Batch 53/64 loss: 0.25863146781921387
Batch 54/64 loss: 0.2655062675476074
Batch 55/64 loss: 0.2655985355377197
Batch 56/64 loss: 0.2695559859275818
Batch 57/64 loss: 0.2565068006515503
Batch 58/64 loss: 0.26527708768844604
Batch 59/64 loss: 0.2622530460357666
Batch 60/64 loss: 0.27108001708984375
Batch 61/64 loss: 0.27040576934814453
Batch 62/64 loss: 0.2688247561454773
Batch 63/64 loss: 0.25955677032470703
Batch 64/64 loss: 0.27063143253326416
Epoch 415  Train loss: 0.26499490878161264  Val loss: 0.312738304285659
Epoch 416
-------------------------------
Batch 1/64 loss: 0.2542499899864197
Batch 2/64 loss: 0.2604638338088989
Batch 3/64 loss: 0.2631685137748718
Batch 4/64 loss: 0.26908910274505615
Batch 5/64 loss: 0.26005780696868896
Batch 6/64 loss: 0.2594280242919922
Batch 7/64 loss: 0.27328068017959595
Batch 8/64 loss: 0.27073562145233154
Batch 9/64 loss: 0.26094621419906616
Batch 10/64 loss: 0.25624048709869385
Batch 11/64 loss: 0.2637755870819092
Batch 12/64 loss: 0.263779878616333
Batch 13/64 loss: 0.2606499195098877
Batch 14/64 loss: 0.2622449994087219
Batch 15/64 loss: 0.26357531547546387
Batch 16/64 loss: 0.2667716145515442
Batch 17/64 loss: 0.27195465564727783
Batch 18/64 loss: 0.2551523447036743
Batch 19/64 loss: 0.26305580139160156
Batch 20/64 loss: 0.26580727100372314
Batch 21/64 loss: 0.2682386636734009
Batch 22/64 loss: 0.2612606883049011
Batch 23/64 loss: 0.25941091775894165
Batch 24/64 loss: 0.26607054471969604
Batch 25/64 loss: 0.26929688453674316
Batch 26/64 loss: 0.2598588466644287
Batch 27/64 loss: 0.27074527740478516
Batch 28/64 loss: 0.26957815885543823
Batch 29/64 loss: 0.26733869314193726
Batch 30/64 loss: 0.2626234292984009
Batch 31/64 loss: 0.2647923231124878
Batch 32/64 loss: 0.2647742033004761
Batch 33/64 loss: 0.2621272802352905
Batch 34/64 loss: 0.2689507007598877
Batch 35/64 loss: 0.2601272463798523
Batch 36/64 loss: 0.26451706886291504
Batch 37/64 loss: 0.2655786871910095
Batch 38/64 loss: 0.2705186605453491
Batch 39/64 loss: 0.25898003578186035
Batch 40/64 loss: 0.2604278326034546
Batch 41/64 loss: 0.26680582761764526
Batch 42/64 loss: 0.26798319816589355
Batch 43/64 loss: 0.27211296558380127
Batch 44/64 loss: 0.26230841875076294
Batch 45/64 loss: 0.2593241333961487
Batch 46/64 loss: 0.26594609022140503
Batch 47/64 loss: 0.2590736150741577
Batch 48/64 loss: 0.2624422311782837
Batch 49/64 loss: 0.26334941387176514
Batch 50/64 loss: 0.2691279649734497
Batch 51/64 loss: 0.2608163356781006
Batch 52/64 loss: 0.2664422392845154
Batch 53/64 loss: 0.26478075981140137
Batch 54/64 loss: 0.26700329780578613
Batch 55/64 loss: 0.26414239406585693
Batch 56/64 loss: 0.2616027593612671
Batch 57/64 loss: 0.2628364562988281
Batch 58/64 loss: 0.2661837935447693
Batch 59/64 loss: 0.26050543785095215
Batch 60/64 loss: 0.26159483194351196
Batch 61/64 loss: 0.2613147497177124
Batch 62/64 loss: 0.2724623680114746
Batch 63/64 loss: 0.2649574875831604
Batch 64/64 loss: 0.2771487832069397
Epoch 416  Train loss: 0.26432348489761354  Val loss: 0.3130404922560728
Epoch 417
-------------------------------
Batch 1/64 loss: 0.25769948959350586
Batch 2/64 loss: 0.26018840074539185
Batch 3/64 loss: 0.26456189155578613
Batch 4/64 loss: 0.26405858993530273
Batch 5/64 loss: 0.26051461696624756
Batch 6/64 loss: 0.26115667819976807
Batch 7/64 loss: 0.26615363359451294
Batch 8/64 loss: 0.2661742568016052
Batch 9/64 loss: 0.26296186447143555
Batch 10/64 loss: 0.2621939182281494
Batch 11/64 loss: 0.2636679410934448
Batch 12/64 loss: 0.2661682367324829
Batch 13/64 loss: 0.2629126310348511
Batch 14/64 loss: 0.2681676149368286
Batch 15/64 loss: 0.2575094699859619
Batch 16/64 loss: 0.2636769413948059
Batch 17/64 loss: 0.2568036913871765
Batch 18/64 loss: 0.26398831605911255
Batch 19/64 loss: 0.27901339530944824
Batch 20/64 loss: 0.26171350479125977
Batch 21/64 loss: 0.262265682220459
Batch 22/64 loss: 0.265439510345459
Batch 23/64 loss: 0.26454687118530273
Batch 24/64 loss: 0.2672286033630371
Batch 25/64 loss: 0.2587735652923584
Batch 26/64 loss: 0.2572537064552307
Batch 27/64 loss: 0.25877851247787476
Batch 28/64 loss: 0.2708832621574402
Batch 29/64 loss: 0.2686803936958313
Batch 30/64 loss: 0.26535236835479736
Batch 31/64 loss: 0.26734960079193115
Batch 32/64 loss: 0.26109564304351807
Batch 33/64 loss: 0.26685547828674316
Batch 34/64 loss: 0.26214897632598877
Batch 35/64 loss: 0.26952242851257324
Batch 36/64 loss: 0.270397424697876
Batch 37/64 loss: 0.2595100402832031
Batch 38/64 loss: 0.2718748450279236
Batch 39/64 loss: 0.26621490716934204
Batch 40/64 loss: 0.26146578788757324
Batch 41/64 loss: 0.26245808601379395
Batch 42/64 loss: 0.264801561832428
Batch 43/64 loss: 0.2654001712799072
Batch 44/64 loss: 0.26509153842926025
Batch 45/64 loss: 0.26677751541137695
Batch 46/64 loss: 0.2625436782836914
Batch 47/64 loss: 0.25764524936676025
Batch 48/64 loss: 0.2647097706794739
Batch 49/64 loss: 0.2659105658531189
Batch 50/64 loss: 0.270053505897522
Batch 51/64 loss: 0.26850277185440063
Batch 52/64 loss: 0.26679378747940063
Batch 53/64 loss: 0.2760447859764099
Batch 54/64 loss: 0.2659427523612976
Batch 55/64 loss: 0.26193368434906006
Batch 56/64 loss: 0.2595740556716919
Batch 57/64 loss: 0.25988030433654785
Batch 58/64 loss: 0.26498931646347046
Batch 59/64 loss: 0.2662264108657837
Batch 60/64 loss: 0.2654755115509033
Batch 61/64 loss: 0.26433438062667847
Batch 62/64 loss: 0.25871747732162476
Batch 63/64 loss: 0.2652972340583801
Batch 64/64 loss: 0.2715336084365845
Epoch 417  Train loss: 0.2644341492185406  Val loss: 0.3125038093717647
Epoch 418
-------------------------------
Batch 1/64 loss: 0.2570534348487854
Batch 2/64 loss: 0.2622417211532593
Batch 3/64 loss: 0.2705356478691101
Batch 4/64 loss: 0.25892823934555054
Batch 5/64 loss: 0.26654374599456787
Batch 6/64 loss: 0.26078277826309204
Batch 7/64 loss: 0.26195192337036133
Batch 8/64 loss: 0.2566186189651489
Batch 9/64 loss: 0.27002954483032227
Batch 10/64 loss: 0.26381468772888184
Batch 11/64 loss: 0.2664286494255066
Batch 12/64 loss: 0.27344727516174316
Batch 13/64 loss: 0.26551687717437744
Batch 14/64 loss: 0.2604069709777832
Batch 15/64 loss: 0.27170777320861816
Batch 16/64 loss: 0.2613924741744995
Batch 17/64 loss: 0.2595036029815674
Batch 18/64 loss: 0.2617793679237366
Batch 19/64 loss: 0.26636940240859985
Batch 20/64 loss: 0.2592962980270386
Batch 21/64 loss: 0.2588003873825073
Batch 22/64 loss: 0.25983238220214844
Batch 23/64 loss: 0.2631557583808899
Batch 24/64 loss: 0.2644805908203125
Batch 25/64 loss: 0.26593637466430664
Batch 26/64 loss: 0.25966548919677734
Batch 27/64 loss: 0.2654174566268921
Batch 28/64 loss: 0.260418176651001
Batch 29/64 loss: 0.2608657479286194
Batch 30/64 loss: 0.2588648796081543
Batch 31/64 loss: 0.26682424545288086
Batch 32/64 loss: 0.2621459364891052
Batch 33/64 loss: 0.26594871282577515
Batch 34/64 loss: 0.26502835750579834
Batch 35/64 loss: 0.26212477684020996
Batch 36/64 loss: 0.2587711811065674
Batch 37/64 loss: 0.2608938217163086
Batch 38/64 loss: 0.2604178786277771
Batch 39/64 loss: 0.26432549953460693
Batch 40/64 loss: 0.259182333946228
Batch 41/64 loss: 0.266848087310791
Batch 42/64 loss: 0.26288366317749023
Batch 43/64 loss: 0.2755204439163208
Batch 44/64 loss: 0.26477956771850586
Batch 45/64 loss: 0.2649511694908142
Batch 46/64 loss: 0.2745646834373474
Batch 47/64 loss: 0.26430433988571167
Batch 48/64 loss: 0.2704336643218994
Batch 49/64 loss: 0.2665168046951294
Batch 50/64 loss: 0.26976650953292847
Batch 51/64 loss: 0.2604180574417114
Batch 52/64 loss: 0.26978063583374023
Batch 53/64 loss: 0.261896014213562
Batch 54/64 loss: 0.2622554302215576
Batch 55/64 loss: 0.26753735542297363
Batch 56/64 loss: 0.27374017238616943
Batch 57/64 loss: 0.27360105514526367
Batch 58/64 loss: 0.27103424072265625
Batch 59/64 loss: 0.2747241258621216
Batch 60/64 loss: 0.26427924633026123
Batch 61/64 loss: 0.2654349207878113
Batch 62/64 loss: 0.2664210796356201
Batch 63/64 loss: 0.26387929916381836
Batch 64/64 loss: 0.2715715765953064
Epoch 418  Train loss: 0.2647325218892565  Val loss: 0.3130906166899245
Epoch 419
-------------------------------
Batch 1/64 loss: 0.26525938510894775
Batch 2/64 loss: 0.26867324113845825
Batch 3/64 loss: 0.26106905937194824
Batch 4/64 loss: 0.2715739607810974
Batch 5/64 loss: 0.26348549127578735
Batch 6/64 loss: 0.26162540912628174
Batch 7/64 loss: 0.2666977643966675
Batch 8/64 loss: 0.2626873254776001
Batch 9/64 loss: 0.2641347646713257
Batch 10/64 loss: 0.26324665546417236
Batch 11/64 loss: 0.2607913017272949
Batch 12/64 loss: 0.2774711847305298
Batch 13/64 loss: 0.2615451216697693
Batch 14/64 loss: 0.2622424364089966
Batch 15/64 loss: 0.27044618129730225
Batch 16/64 loss: 0.2575979232788086
Batch 17/64 loss: 0.2643579840660095
Batch 18/64 loss: 0.259649395942688
Batch 19/64 loss: 0.2635888457298279
Batch 20/64 loss: 0.2666754722595215
Batch 21/64 loss: 0.2696174383163452
Batch 22/64 loss: 0.25964272022247314
Batch 23/64 loss: 0.2643841505050659
Batch 24/64 loss: 0.25707685947418213
Batch 25/64 loss: 0.25693535804748535
Batch 26/64 loss: 0.26527857780456543
Batch 27/64 loss: 0.26513999700546265
Batch 28/64 loss: 0.26548707485198975
Batch 29/64 loss: 0.2579876780509949
Batch 30/64 loss: 0.26255059242248535
Batch 31/64 loss: 0.25814390182495117
Batch 32/64 loss: 0.26635879278182983
Batch 33/64 loss: 0.25971245765686035
Batch 34/64 loss: 0.27097201347351074
Batch 35/64 loss: 0.271306574344635
Batch 36/64 loss: 0.26344507932662964
Batch 37/64 loss: 0.2661568522453308
Batch 38/64 loss: 0.2583560347557068
Batch 39/64 loss: 0.2673766613006592
Batch 40/64 loss: 0.2651582360267639
Batch 41/64 loss: 0.26757538318634033
Batch 42/64 loss: 0.2559521198272705
Batch 43/64 loss: 0.2633589506149292
Batch 44/64 loss: 0.269467830657959
Batch 45/64 loss: 0.2581368684768677
Batch 46/64 loss: 0.2628549337387085
Batch 47/64 loss: 0.2579169273376465
Batch 48/64 loss: 0.26659977436065674
Batch 49/64 loss: 0.2586550712585449
Batch 50/64 loss: 0.25861936807632446
Batch 51/64 loss: 0.2663799524307251
Batch 52/64 loss: 0.26114511489868164
Batch 53/64 loss: 0.26711952686309814
Batch 54/64 loss: 0.27092164754867554
Batch 55/64 loss: 0.2661740183830261
Batch 56/64 loss: 0.26364409923553467
Batch 57/64 loss: 0.26577913761138916
Batch 58/64 loss: 0.264224112033844
Batch 59/64 loss: 0.27075761556625366
Batch 60/64 loss: 0.26454371213912964
Batch 61/64 loss: 0.2674393653869629
Batch 62/64 loss: 0.2626962661743164
Batch 63/64 loss: 0.2627255916595459
Batch 64/64 loss: 0.26177191734313965
Epoch 419  Train loss: 0.26404583968368234  Val loss: 0.3122131509059893
Epoch 420
-------------------------------
Batch 1/64 loss: 0.27283763885498047
Batch 2/64 loss: 0.2642502784729004
Batch 3/64 loss: 0.26176905632019043
Batch 4/64 loss: 0.2615032196044922
Batch 5/64 loss: 0.2735269069671631
Batch 6/64 loss: 0.26469993591308594
Batch 7/64 loss: 0.2607001066207886
Batch 8/64 loss: 0.2632814049720764
Batch 9/64 loss: 0.263965368270874
Batch 10/64 loss: 0.2616932988166809
Batch 11/64 loss: 0.26375436782836914
Batch 12/64 loss: 0.27178847789764404
Batch 13/64 loss: 0.26246559619903564
Batch 14/64 loss: 0.2663588523864746
Batch 15/64 loss: 0.25644195079803467
Batch 16/64 loss: 0.26024651527404785
Batch 17/64 loss: 0.2673865556716919
Batch 18/64 loss: 0.26875221729278564
Batch 19/64 loss: 0.2624894380569458
Batch 20/64 loss: 0.2634197473526001
Batch 21/64 loss: 0.2629666328430176
Batch 22/64 loss: 0.2694699764251709
Batch 23/64 loss: 0.2632397413253784
Batch 24/64 loss: 0.26949524879455566
Batch 25/64 loss: 0.2637648582458496
Batch 26/64 loss: 0.2726718783378601
Batch 27/64 loss: 0.26005637645721436
Batch 28/64 loss: 0.2626921534538269
Batch 29/64 loss: 0.26589733362197876
Batch 30/64 loss: 0.26584774255752563
Batch 31/64 loss: 0.2615642547607422
Batch 32/64 loss: 0.2654135823249817
Batch 33/64 loss: 0.26556074619293213
Batch 34/64 loss: 0.2655266523361206
Batch 35/64 loss: 0.2659856081008911
Batch 36/64 loss: 0.2617756128311157
Batch 37/64 loss: 0.2662980556488037
Batch 38/64 loss: 0.26320111751556396
Batch 39/64 loss: 0.2655976414680481
Batch 40/64 loss: 0.25659680366516113
Batch 41/64 loss: 0.2726328372955322
Batch 42/64 loss: 0.26282238960266113
Batch 43/64 loss: 0.26455193758010864
Batch 44/64 loss: 0.2647274136543274
Batch 45/64 loss: 0.26842617988586426
Batch 46/64 loss: 0.25932931900024414
Batch 47/64 loss: 0.26372969150543213
Batch 48/64 loss: 0.256500780582428
Batch 49/64 loss: 0.25792181491851807
Batch 50/64 loss: 0.2622230052947998
Batch 51/64 loss: 0.268987774848938
Batch 52/64 loss: 0.2605130672454834
Batch 53/64 loss: 0.25978946685791016
Batch 54/64 loss: 0.25649428367614746
Batch 55/64 loss: 0.2586946487426758
Batch 56/64 loss: 0.26939094066619873
Batch 57/64 loss: 0.26366496086120605
Batch 58/64 loss: 0.2639694809913635
Batch 59/64 loss: 0.25904643535614014
Batch 60/64 loss: 0.2647402882575989
Batch 61/64 loss: 0.2698267102241516
Batch 62/64 loss: 0.25805962085723877
Batch 63/64 loss: 0.26088714599609375
Batch 64/64 loss: 0.2569080591201782
Epoch 420  Train loss: 0.26391473237205954  Val loss: 0.3121981555243948
Epoch 421
-------------------------------
Batch 1/64 loss: 0.2635613679885864
Batch 2/64 loss: 0.2598775029182434
Batch 3/64 loss: 0.2616603970527649
Batch 4/64 loss: 0.2526909112930298
Batch 5/64 loss: 0.2645235061645508
Batch 6/64 loss: 0.2690752148628235
Batch 7/64 loss: 0.26150524616241455
Batch 8/64 loss: 0.25816279649734497
Batch 9/64 loss: 0.2625763416290283
Batch 10/64 loss: 0.2616997957229614
Batch 11/64 loss: 0.26107507944107056
Batch 12/64 loss: 0.26503127813339233
Batch 13/64 loss: 0.268405020236969
Batch 14/64 loss: 0.2610016465187073
Batch 15/64 loss: 0.26181989908218384
Batch 16/64 loss: 0.2668253183364868
Batch 17/64 loss: 0.26616305112838745
Batch 18/64 loss: 0.26086050271987915
Batch 19/64 loss: 0.26715803146362305
Batch 20/64 loss: 0.2661929726600647
Batch 21/64 loss: 0.25805819034576416
Batch 22/64 loss: 0.26298391819000244
Batch 23/64 loss: 0.261022686958313
Batch 24/64 loss: 0.26592445373535156
Batch 25/64 loss: 0.2622253894805908
Batch 26/64 loss: 0.2593042254447937
Batch 27/64 loss: 0.2624516487121582
Batch 28/64 loss: 0.2595674991607666
Batch 29/64 loss: 0.26952993869781494
Batch 30/64 loss: 0.27007120847702026
Batch 31/64 loss: 0.2622647285461426
Batch 32/64 loss: 0.2619408369064331
Batch 33/64 loss: 0.2751043438911438
Batch 34/64 loss: 0.26103079319000244
Batch 35/64 loss: 0.26744067668914795
Batch 36/64 loss: 0.26169353723526
Batch 37/64 loss: 0.2706214189529419
Batch 38/64 loss: 0.26203012466430664
Batch 39/64 loss: 0.26466238498687744
Batch 40/64 loss: 0.2717897295951843
Batch 41/64 loss: 0.25733983516693115
Batch 42/64 loss: 0.2665879726409912
Batch 43/64 loss: 0.2669156789779663
Batch 44/64 loss: 0.26928746700286865
Batch 45/64 loss: 0.2590264678001404
Batch 46/64 loss: 0.26339972019195557
Batch 47/64 loss: 0.26926422119140625
Batch 48/64 loss: 0.25713133811950684
Batch 49/64 loss: 0.26083874702453613
Batch 50/64 loss: 0.2588152289390564
Batch 51/64 loss: 0.26512742042541504
Batch 52/64 loss: 0.2718283534049988
Batch 53/64 loss: 0.2653399705886841
Batch 54/64 loss: 0.2628650665283203
Batch 55/64 loss: 0.2733559012413025
Batch 56/64 loss: 0.2589641809463501
Batch 57/64 loss: 0.26196569204330444
Batch 58/64 loss: 0.2706297039985657
Batch 59/64 loss: 0.26530009508132935
Batch 60/64 loss: 0.2658776640892029
Batch 61/64 loss: 0.2689579725265503
Batch 62/64 loss: 0.26783740520477295
Batch 63/64 loss: 0.2651282548904419
Batch 64/64 loss: 0.2596287727355957
Epoch 421  Train loss: 0.2640955223756678  Val loss: 0.3125309284610027
Epoch 422
-------------------------------
Batch 1/64 loss: 0.26014864444732666
Batch 2/64 loss: 0.2576107978820801
Batch 3/64 loss: 0.2605154514312744
Batch 4/64 loss: 0.26216650009155273
Batch 5/64 loss: 0.26131510734558105
Batch 6/64 loss: 0.26744258403778076
Batch 7/64 loss: 0.2663779854774475
Batch 8/64 loss: 0.2607513666152954
Batch 9/64 loss: 0.2559685707092285
Batch 10/64 loss: 0.26023364067077637
Batch 11/64 loss: 0.27224647998809814
Batch 12/64 loss: 0.26155388355255127
Batch 13/64 loss: 0.2716693878173828
Batch 14/64 loss: 0.26341915130615234
Batch 15/64 loss: 0.2730525732040405
Batch 16/64 loss: 0.2573004364967346
Batch 17/64 loss: 0.26226091384887695
Batch 18/64 loss: 0.2678980827331543
Batch 19/64 loss: 0.27113378047943115
Batch 20/64 loss: 0.26765888929367065
Batch 21/64 loss: 0.26181352138519287
Batch 22/64 loss: 0.26045072078704834
Batch 23/64 loss: 0.2620278596878052
Batch 24/64 loss: 0.2654237747192383
Batch 25/64 loss: 0.2695351839065552
Batch 26/64 loss: 0.2689826488494873
Batch 27/64 loss: 0.2644583582878113
Batch 28/64 loss: 0.256489634513855
Batch 29/64 loss: 0.26420819759368896
Batch 30/64 loss: 0.27061158418655396
Batch 31/64 loss: 0.25647878646850586
Batch 32/64 loss: 0.2622201442718506
Batch 33/64 loss: 0.26686006784439087
Batch 34/64 loss: 0.2580322027206421
Batch 35/64 loss: 0.2609751224517822
Batch 36/64 loss: 0.27156686782836914
Batch 37/64 loss: 0.25359243154525757
Batch 38/64 loss: 0.26043272018432617
Batch 39/64 loss: 0.2593579888343811
Batch 40/64 loss: 0.25830549001693726
Batch 41/64 loss: 0.2641727924346924
Batch 42/64 loss: 0.2631457448005676
Batch 43/64 loss: 0.2683388590812683
Batch 44/64 loss: 0.2697288990020752
Batch 45/64 loss: 0.25776535272598267
Batch 46/64 loss: 0.26344478130340576
Batch 47/64 loss: 0.26653075218200684
Batch 48/64 loss: 0.26629096269607544
Batch 49/64 loss: 0.2656956911087036
Batch 50/64 loss: 0.26436781883239746
Batch 51/64 loss: 0.26503974199295044
Batch 52/64 loss: 0.2602540850639343
Batch 53/64 loss: 0.26682353019714355
Batch 54/64 loss: 0.26249784231185913
Batch 55/64 loss: 0.26320505142211914
Batch 56/64 loss: 0.2703065276145935
Batch 57/64 loss: 0.2682584524154663
Batch 58/64 loss: 0.2721836566925049
Batch 59/64 loss: 0.2651084065437317
Batch 60/64 loss: 0.2637840509414673
Batch 61/64 loss: 0.27155792713165283
Batch 62/64 loss: 0.2646046280860901
Batch 63/64 loss: 0.2640186548233032
Batch 64/64 loss: 0.26603156328201294
Epoch 422  Train loss: 0.26414424180984497  Val loss: 0.3121732024802375
Epoch 423
-------------------------------
Batch 1/64 loss: 0.26234471797943115
Batch 2/64 loss: 0.26066815853118896
Batch 3/64 loss: 0.2631418704986572
Batch 4/64 loss: 0.2587054967880249
Batch 5/64 loss: 0.26004815101623535
Batch 6/64 loss: 0.2641978859901428
Batch 7/64 loss: 0.26678502559661865
Batch 8/64 loss: 0.26419317722320557
Batch 9/64 loss: 0.26510417461395264
Batch 10/64 loss: 0.267531156539917
Batch 11/64 loss: 0.2595134973526001
Batch 12/64 loss: 0.2574951648712158
Batch 13/64 loss: 0.2682880163192749
Batch 14/64 loss: 0.26459383964538574
Batch 15/64 loss: 0.2638130187988281
Batch 16/64 loss: 0.2659313678741455
Batch 17/64 loss: 0.2621828317642212
Batch 18/64 loss: 0.2670252323150635
Batch 19/64 loss: 0.26618891954421997
Batch 20/64 loss: 0.2652866840362549
Batch 21/64 loss: 0.26002049446105957
Batch 22/64 loss: 0.2675224542617798
Batch 23/64 loss: 0.2665269374847412
Batch 24/64 loss: 0.26227426528930664
Batch 25/64 loss: 0.2577219009399414
Batch 26/64 loss: 0.25972288846969604
Batch 27/64 loss: 0.2685438394546509
Batch 28/64 loss: 0.26589637994766235
Batch 29/64 loss: 0.2574293613433838
Batch 30/64 loss: 0.2620057463645935
Batch 31/64 loss: 0.2651323080062866
Batch 32/64 loss: 0.2613459825515747
Batch 33/64 loss: 0.2670835852622986
Batch 34/64 loss: 0.25698405504226685
Batch 35/64 loss: 0.273409903049469
Batch 36/64 loss: 0.2583025097846985
Batch 37/64 loss: 0.25730955600738525
Batch 38/64 loss: 0.2703428268432617
Batch 39/64 loss: 0.25741952657699585
Batch 40/64 loss: 0.266284704208374
Batch 41/64 loss: 0.2674906253814697
Batch 42/64 loss: 0.2660694718360901
Batch 43/64 loss: 0.2627542018890381
Batch 44/64 loss: 0.26494669914245605
Batch 45/64 loss: 0.2652853727340698
Batch 46/64 loss: 0.26763904094696045
Batch 47/64 loss: 0.2652484178543091
Batch 48/64 loss: 0.2686610221862793
Batch 49/64 loss: 0.2658572196960449
Batch 50/64 loss: 0.2651176452636719
Batch 51/64 loss: 0.2632331848144531
Batch 52/64 loss: 0.2614469528198242
Batch 53/64 loss: 0.26526719331741333
Batch 54/64 loss: 0.2600991725921631
Batch 55/64 loss: 0.26097190380096436
Batch 56/64 loss: 0.2682543396949768
Batch 57/64 loss: 0.2659578323364258
Batch 58/64 loss: 0.25784534215927124
Batch 59/64 loss: 0.2634214162826538
Batch 60/64 loss: 0.2747699022293091
Batch 61/64 loss: 0.2642812728881836
Batch 62/64 loss: 0.265835702419281
Batch 63/64 loss: 0.2624269723892212
Batch 64/64 loss: 0.2662825584411621
Epoch 423  Train loss: 0.26395153625338685  Val loss: 0.3118687589553623
Epoch 424
-------------------------------
Batch 1/64 loss: 0.26331090927124023
Batch 2/64 loss: 0.2634611129760742
Batch 3/64 loss: 0.2652702331542969
Batch 4/64 loss: 0.26260513067245483
Batch 5/64 loss: 0.26583153009414673
Batch 6/64 loss: 0.2687709331512451
Batch 7/64 loss: 0.2678406834602356
Batch 8/64 loss: 0.2655003070831299
Batch 9/64 loss: 0.2617366909980774
Batch 10/64 loss: 0.2629190683364868
Batch 11/64 loss: 0.26055824756622314
Batch 12/64 loss: 0.2545818090438843
Batch 13/64 loss: 0.2616947293281555
Batch 14/64 loss: 0.2584635019302368
Batch 15/64 loss: 0.25960707664489746
Batch 16/64 loss: 0.25782251358032227
Batch 17/64 loss: 0.2641592025756836
Batch 18/64 loss: 0.26121729612350464
Batch 19/64 loss: 0.2665902376174927
Batch 20/64 loss: 0.27201390266418457
Batch 21/64 loss: 0.2651776075363159
Batch 22/64 loss: 0.26098155975341797
Batch 23/64 loss: 0.25852102041244507
Batch 24/64 loss: 0.26318228244781494
Batch 25/64 loss: 0.25749433040618896
Batch 26/64 loss: 0.2781639099121094
Batch 27/64 loss: 0.26020413637161255
Batch 28/64 loss: 0.28177595138549805
Batch 29/64 loss: 0.259097695350647
Batch 30/64 loss: 0.2610344886779785
Batch 31/64 loss: 0.2626582384109497
Batch 32/64 loss: 0.26461923122406006
Batch 33/64 loss: 0.26276183128356934
Batch 34/64 loss: 0.25650739669799805
Batch 35/64 loss: 0.2687075138092041
Batch 36/64 loss: 0.25984954833984375
Batch 37/64 loss: 0.2558327317237854
Batch 38/64 loss: 0.25883495807647705
Batch 39/64 loss: 0.25829219818115234
Batch 40/64 loss: 0.26404744386672974
Batch 41/64 loss: 0.2595769166946411
Batch 42/64 loss: 0.26273083686828613
Batch 43/64 loss: 0.25334447622299194
Batch 44/64 loss: 0.2647588849067688
Batch 45/64 loss: 0.2650371789932251
Batch 46/64 loss: 0.26749587059020996
Batch 47/64 loss: 0.26420676708221436
Batch 48/64 loss: 0.2648259401321411
Batch 49/64 loss: 0.2651660442352295
Batch 50/64 loss: 0.2618485689163208
Batch 51/64 loss: 0.262326717376709
Batch 52/64 loss: 0.2576028108596802
Batch 53/64 loss: 0.26340121030807495
Batch 54/64 loss: 0.26619255542755127
Batch 55/64 loss: 0.26144564151763916
Batch 56/64 loss: 0.2628520727157593
Batch 57/64 loss: 0.26181381940841675
Batch 58/64 loss: 0.2610006332397461
Batch 59/64 loss: 0.2660714387893677
Batch 60/64 loss: 0.26187199354171753
Batch 61/64 loss: 0.2741663455963135
Batch 62/64 loss: 0.26152604818344116
Batch 63/64 loss: 0.2633345127105713
Batch 64/64 loss: 0.2797940969467163
Epoch 424  Train loss: 0.2632806595634012  Val loss: 0.31290381675733325
Epoch 425
-------------------------------
Batch 1/64 loss: 0.265694797039032
Batch 2/64 loss: 0.26401686668395996
Batch 3/64 loss: 0.2599957585334778
Batch 4/64 loss: 0.26658546924591064
Batch 5/64 loss: 0.26095157861709595
Batch 6/64 loss: 0.26412200927734375
Batch 7/64 loss: 0.26331132650375366
Batch 8/64 loss: 0.2631450295448303
Batch 9/64 loss: 0.26244062185287476
Batch 10/64 loss: 0.2586556673049927
Batch 11/64 loss: 0.2673497200012207
Batch 12/64 loss: 0.2564021944999695
Batch 13/64 loss: 0.2663635015487671
Batch 14/64 loss: 0.2610434293746948
Batch 15/64 loss: 0.26911747455596924
Batch 16/64 loss: 0.2651028633117676
Batch 17/64 loss: 0.2671748399734497
Batch 18/64 loss: 0.2584112882614136
Batch 19/64 loss: 0.26127076148986816
Batch 20/64 loss: 0.2648911476135254
Batch 21/64 loss: 0.2586759328842163
Batch 22/64 loss: 0.26266252994537354
Batch 23/64 loss: 0.27119606733322144
Batch 24/64 loss: 0.2578541040420532
Batch 25/64 loss: 0.26381492614746094
Batch 26/64 loss: 0.26013392210006714
Batch 27/64 loss: 0.2651212215423584
Batch 28/64 loss: 0.2690127491950989
Batch 29/64 loss: 0.260789155960083
Batch 30/64 loss: 0.2615429162979126
Batch 31/64 loss: 0.26332569122314453
Batch 32/64 loss: 0.26540982723236084
Batch 33/64 loss: 0.2618614435195923
Batch 34/64 loss: 0.26553666591644287
Batch 35/64 loss: 0.2577100992202759
Batch 36/64 loss: 0.2626500129699707
Batch 37/64 loss: 0.26667821407318115
Batch 38/64 loss: 0.2606302499771118
Batch 39/64 loss: 0.2612420320510864
Batch 40/64 loss: 0.2614248991012573
Batch 41/64 loss: 0.26440322399139404
Batch 42/64 loss: 0.26476526260375977
Batch 43/64 loss: 0.2660716772079468
Batch 44/64 loss: 0.26888084411621094
Batch 45/64 loss: 0.2639042139053345
Batch 46/64 loss: 0.2778499126434326
Batch 47/64 loss: 0.26095545291900635
Batch 48/64 loss: 0.26813721656799316
Batch 49/64 loss: 0.27010631561279297
Batch 50/64 loss: 0.2697669267654419
Batch 51/64 loss: 0.2589626908302307
Batch 52/64 loss: 0.26160264015197754
Batch 53/64 loss: 0.2630995512008667
Batch 54/64 loss: 0.26407212018966675
Batch 55/64 loss: 0.2604799270629883
Batch 56/64 loss: 0.25987160205841064
Batch 57/64 loss: 0.25788211822509766
Batch 58/64 loss: 0.25779592990875244
Batch 59/64 loss: 0.26450884342193604
Batch 60/64 loss: 0.2643965482711792
Batch 61/64 loss: 0.2696152925491333
Batch 62/64 loss: 0.2628612518310547
Batch 63/64 loss: 0.26399266719818115
Batch 64/64 loss: 0.2668728828430176
Epoch 425  Train loss: 0.2636463670169606  Val loss: 0.31233607411794234
Epoch 426
-------------------------------
Batch 1/64 loss: 0.27005016803741455
Batch 2/64 loss: 0.26111340522766113
Batch 3/64 loss: 0.2615621089935303
Batch 4/64 loss: 0.2635464072227478
Batch 5/64 loss: 0.2634168863296509
Batch 6/64 loss: 0.26696550846099854
Batch 7/64 loss: 0.2665623426437378
Batch 8/64 loss: 0.26285356283187866
Batch 9/64 loss: 0.2664715051651001
Batch 10/64 loss: 0.2669680118560791
Batch 11/64 loss: 0.26285529136657715
Batch 12/64 loss: 0.25961410999298096
Batch 13/64 loss: 0.2592306137084961
Batch 14/64 loss: 0.2587491273880005
Batch 15/64 loss: 0.2600417137145996
Batch 16/64 loss: 0.2705209255218506
Batch 17/64 loss: 0.2581132650375366
Batch 18/64 loss: 0.2577454447746277
Batch 19/64 loss: 0.2618408203125
Batch 20/64 loss: 0.2579801678657532
Batch 21/64 loss: 0.2664429545402527
Batch 22/64 loss: 0.2752543091773987
Batch 23/64 loss: 0.26628559827804565
Batch 24/64 loss: 0.2601301670074463
Batch 25/64 loss: 0.26188457012176514
Batch 26/64 loss: 0.2627423405647278
Batch 27/64 loss: 0.26405584812164307
Batch 28/64 loss: 0.2659369707107544
Batch 29/64 loss: 0.2628025412559509
Batch 30/64 loss: 0.26986342668533325
Batch 31/64 loss: 0.26434916257858276
Batch 32/64 loss: 0.26377975940704346
Batch 33/64 loss: 0.25977444648742676
Batch 34/64 loss: 0.27530694007873535
Batch 35/64 loss: 0.2623105049133301
Batch 36/64 loss: 0.2640727162361145
Batch 37/64 loss: 0.2712981700897217
Batch 38/64 loss: 0.2566532492637634
Batch 39/64 loss: 0.26343297958374023
Batch 40/64 loss: 0.2667921185493469
Batch 41/64 loss: 0.27085137367248535
Batch 42/64 loss: 0.2645484209060669
Batch 43/64 loss: 0.27176153659820557
Batch 44/64 loss: 0.2591942548751831
Batch 45/64 loss: 0.26452869176864624
Batch 46/64 loss: 0.2632172107696533
Batch 47/64 loss: 0.26393067836761475
Batch 48/64 loss: 0.2620773911476135
Batch 49/64 loss: 0.26669013500213623
Batch 50/64 loss: 0.2586245536804199
Batch 51/64 loss: 0.26337873935699463
Batch 52/64 loss: 0.26581573486328125
Batch 53/64 loss: 0.26157307624816895
Batch 54/64 loss: 0.2644392251968384
Batch 55/64 loss: 0.2619364261627197
Batch 56/64 loss: 0.26640748977661133
Batch 57/64 loss: 0.2574842572212219
Batch 58/64 loss: 0.26124274730682373
Batch 59/64 loss: 0.25759732723236084
Batch 60/64 loss: 0.2716197967529297
Batch 61/64 loss: 0.2632541060447693
Batch 62/64 loss: 0.2633925676345825
Batch 63/64 loss: 0.2598299980163574
Batch 64/64 loss: 0.2606784701347351
Epoch 426  Train loss: 0.2638160745302836  Val loss: 0.3128230352581981
Epoch 427
-------------------------------
Batch 1/64 loss: 0.26107048988342285
Batch 2/64 loss: 0.2678026556968689
Batch 3/64 loss: 0.25547289848327637
Batch 4/64 loss: 0.26332563161849976
Batch 5/64 loss: 0.26258111000061035
Batch 6/64 loss: 0.2626025080680847
Batch 7/64 loss: 0.25886571407318115
Batch 8/64 loss: 0.25381314754486084
Batch 9/64 loss: 0.2715977430343628
Batch 10/64 loss: 0.2534700632095337
Batch 11/64 loss: 0.25775909423828125
Batch 12/64 loss: 0.2648850083351135
Batch 13/64 loss: 0.2624068856239319
Batch 14/64 loss: 0.26487457752227783
Batch 15/64 loss: 0.2588094472885132
Batch 16/64 loss: 0.2598881125450134
Batch 17/64 loss: 0.2624095678329468
Batch 18/64 loss: 0.2658032774925232
Batch 19/64 loss: 0.2587684988975525
Batch 20/64 loss: 0.26422595977783203
Batch 21/64 loss: 0.25864481925964355
Batch 22/64 loss: 0.2675555348396301
Batch 23/64 loss: 0.2624911069869995
Batch 24/64 loss: 0.2580915689468384
Batch 25/64 loss: 0.2623331546783447
Batch 26/64 loss: 0.26522862911224365
Batch 27/64 loss: 0.26824212074279785
Batch 28/64 loss: 0.2564604878425598
Batch 29/64 loss: 0.26018303632736206
Batch 30/64 loss: 0.2651400566101074
Batch 31/64 loss: 0.2660291790962219
Batch 32/64 loss: 0.2595252990722656
Batch 33/64 loss: 0.26289284229278564
Batch 34/64 loss: 0.263397216796875
Batch 35/64 loss: 0.26156526803970337
Batch 36/64 loss: 0.2664984464645386
Batch 37/64 loss: 0.26698601245880127
Batch 38/64 loss: 0.26467806100845337
Batch 39/64 loss: 0.27554208040237427
Batch 40/64 loss: 0.26114845275878906
Batch 41/64 loss: 0.2708749771118164
Batch 42/64 loss: 0.2633686065673828
Batch 43/64 loss: 0.2565930485725403
Batch 44/64 loss: 0.26852667331695557
Batch 45/64 loss: 0.2652592062950134
Batch 46/64 loss: 0.2755528688430786
Batch 47/64 loss: 0.2718527317047119
Batch 48/64 loss: 0.2643904685974121
Batch 49/64 loss: 0.2605234384536743
Batch 50/64 loss: 0.26750481128692627
Batch 51/64 loss: 0.2684789299964905
Batch 52/64 loss: 0.26149362325668335
Batch 53/64 loss: 0.2621370553970337
Batch 54/64 loss: 0.26584339141845703
Batch 55/64 loss: 0.2669132947921753
Batch 56/64 loss: 0.2606104016304016
Batch 57/64 loss: 0.26712357997894287
Batch 58/64 loss: 0.26467305421829224
Batch 59/64 loss: 0.2567720413208008
Batch 60/64 loss: 0.2655959129333496
Batch 61/64 loss: 0.2649797201156616
Batch 62/64 loss: 0.2664549946784973
Batch 63/64 loss: 0.26102232933044434
Batch 64/64 loss: 0.26198577880859375
Epoch 427  Train loss: 0.2634682393541523  Val loss: 0.3125176642768571
Epoch 428
-------------------------------
Batch 1/64 loss: 0.2595794200897217
Batch 2/64 loss: 0.2529761791229248
Batch 3/64 loss: 0.275348961353302
Batch 4/64 loss: 0.2705632448196411
Batch 5/64 loss: 0.2537442445755005
Batch 6/64 loss: 0.2733972668647766
Batch 7/64 loss: 0.2557198405265808
Batch 8/64 loss: 0.26172107458114624
Batch 9/64 loss: 0.2633763551712036
Batch 10/64 loss: 0.26763665676116943
Batch 11/64 loss: 0.2655249834060669
Batch 12/64 loss: 0.2615361213684082
Batch 13/64 loss: 0.2611386775970459
Batch 14/64 loss: 0.2615445852279663
Batch 15/64 loss: 0.2631032466888428
Batch 16/64 loss: 0.2604924440383911
Batch 17/64 loss: 0.26223134994506836
Batch 18/64 loss: 0.26467180252075195
Batch 19/64 loss: 0.26728808879852295
Batch 20/64 loss: 0.264298677444458
Batch 21/64 loss: 0.25894808769226074
Batch 22/64 loss: 0.26883888244628906
Batch 23/64 loss: 0.2654184103012085
Batch 24/64 loss: 0.2618422508239746
Batch 25/64 loss: 0.269850492477417
Batch 26/64 loss: 0.270538330078125
Batch 27/64 loss: 0.2630143165588379
Batch 28/64 loss: 0.2559923529624939
Batch 29/64 loss: 0.2640507221221924
Batch 30/64 loss: 0.2664618492126465
Batch 31/64 loss: 0.26290440559387207
Batch 32/64 loss: 0.26022547483444214
Batch 33/64 loss: 0.2794042229652405
Batch 34/64 loss: 0.2628999948501587
Batch 35/64 loss: 0.25814855098724365
Batch 36/64 loss: 0.26497721672058105
Batch 37/64 loss: 0.26074618101119995
Batch 38/64 loss: 0.2624890208244324
Batch 39/64 loss: 0.2649698853492737
Batch 40/64 loss: 0.25939375162124634
Batch 41/64 loss: 0.2691192626953125
Batch 42/64 loss: 0.26579082012176514
Batch 43/64 loss: 0.27120840549468994
Batch 44/64 loss: 0.2599145174026489
Batch 45/64 loss: 0.26477760076522827
Batch 46/64 loss: 0.2585821747779846
Batch 47/64 loss: 0.26926904916763306
Batch 48/64 loss: 0.26487278938293457
Batch 49/64 loss: 0.262775182723999
Batch 50/64 loss: 0.25590789318084717
Batch 51/64 loss: 0.26734936237335205
Batch 52/64 loss: 0.25657200813293457
Batch 53/64 loss: 0.2582753300666809
Batch 54/64 loss: 0.26606887578964233
Batch 55/64 loss: 0.26531463861465454
Batch 56/64 loss: 0.2684783339500427
Batch 57/64 loss: 0.2681542634963989
Batch 58/64 loss: 0.25815045833587646
Batch 59/64 loss: 0.263502836227417
Batch 60/64 loss: 0.2657620906829834
Batch 61/64 loss: 0.26346254348754883
Batch 62/64 loss: 0.2570105791091919
Batch 63/64 loss: 0.26761335134506226
Batch 64/64 loss: 0.2656729221343994
Epoch 428  Train loss: 0.2637520734001608  Val loss: 0.31249376506739873
Epoch 429
-------------------------------
Batch 1/64 loss: 0.263425350189209
Batch 2/64 loss: 0.25814759731292725
Batch 3/64 loss: 0.26717472076416016
Batch 4/64 loss: 0.26916593313217163
Batch 5/64 loss: 0.2649684548377991
Batch 6/64 loss: 0.26171809434890747
Batch 7/64 loss: 0.2592114210128784
Batch 8/64 loss: 0.256003737449646
Batch 9/64 loss: 0.25598371028900146
Batch 10/64 loss: 0.2720131278038025
Batch 11/64 loss: 0.26848578453063965
Batch 12/64 loss: 0.2641245722770691
Batch 13/64 loss: 0.25767695903778076
Batch 14/64 loss: 0.2651975154876709
Batch 15/64 loss: 0.27125275135040283
Batch 16/64 loss: 0.2620731592178345
Batch 17/64 loss: 0.2648146152496338
Batch 18/64 loss: 0.2742486596107483
Batch 19/64 loss: 0.26524174213409424
Batch 20/64 loss: 0.25622689723968506
Batch 21/64 loss: 0.26842188835144043
Batch 22/64 loss: 0.26600778102874756
Batch 23/64 loss: 0.2568349838256836
Batch 24/64 loss: 0.27267348766326904
Batch 25/64 loss: 0.2611875534057617
Batch 26/64 loss: 0.25488269329071045
Batch 27/64 loss: 0.26641684770584106
Batch 28/64 loss: 0.2579847574234009
Batch 29/64 loss: 0.26766371726989746
Batch 30/64 loss: 0.2625904083251953
Batch 31/64 loss: 0.2585037350654602
Batch 32/64 loss: 0.2601088285446167
Batch 33/64 loss: 0.2705608606338501
Batch 34/64 loss: 0.26595669984817505
Batch 35/64 loss: 0.26014941930770874
Batch 36/64 loss: 0.255437433719635
Batch 37/64 loss: 0.2598007917404175
Batch 38/64 loss: 0.2618945240974426
Batch 39/64 loss: 0.2626526355743408
Batch 40/64 loss: 0.26698195934295654
Batch 41/64 loss: 0.26156777143478394
Batch 42/64 loss: 0.2633066177368164
Batch 43/64 loss: 0.25983595848083496
Batch 44/64 loss: 0.26209843158721924
Batch 45/64 loss: 0.26198363304138184
Batch 46/64 loss: 0.259613573551178
Batch 47/64 loss: 0.25857287645339966
Batch 48/64 loss: 0.2600412368774414
Batch 49/64 loss: 0.26911282539367676
Batch 50/64 loss: 0.26106584072113037
Batch 51/64 loss: 0.26054513454437256
Batch 52/64 loss: 0.26868999004364014
Batch 53/64 loss: 0.2566111087799072
Batch 54/64 loss: 0.2687387466430664
Batch 55/64 loss: 0.26334846019744873
Batch 56/64 loss: 0.2650521993637085
Batch 57/64 loss: 0.26131731271743774
Batch 58/64 loss: 0.25951147079467773
Batch 59/64 loss: 0.26714855432510376
Batch 60/64 loss: 0.25842124223709106
Batch 61/64 loss: 0.26306986808776855
Batch 62/64 loss: 0.26320600509643555
Batch 63/64 loss: 0.2659262418746948
Batch 64/64 loss: 0.263119101524353
Epoch 429  Train loss: 0.2630586703618368  Val loss: 0.3119297232414849
Epoch 430
-------------------------------
Batch 1/64 loss: 0.26901501417160034
Batch 2/64 loss: 0.26569390296936035
Batch 3/64 loss: 0.2579801678657532
Batch 4/64 loss: 0.26723915338516235
Batch 5/64 loss: 0.25529223680496216
Batch 6/64 loss: 0.2567319869995117
Batch 7/64 loss: 0.25577449798583984
Batch 8/64 loss: 0.2611161470413208
Batch 9/64 loss: 0.2660297751426697
Batch 10/64 loss: 0.2602783441543579
Batch 11/64 loss: 0.26482516527175903
Batch 12/64 loss: 0.2692633867263794
Batch 13/64 loss: 0.25756239891052246
Batch 14/64 loss: 0.26183027029037476
Batch 15/64 loss: 0.266589879989624
Batch 16/64 loss: 0.2598087787628174
Batch 17/64 loss: 0.2584274411201477
Batch 18/64 loss: 0.2587466239929199
Batch 19/64 loss: 0.2590155601501465
Batch 20/64 loss: 0.26437443494796753
Batch 21/64 loss: 0.26446855068206787
Batch 22/64 loss: 0.26555657386779785
Batch 23/64 loss: 0.2634319067001343
Batch 24/64 loss: 0.26085472106933594
Batch 25/64 loss: 0.25993525981903076
Batch 26/64 loss: 0.2689986228942871
Batch 27/64 loss: 0.2600604295730591
Batch 28/64 loss: 0.2629038095474243
Batch 29/64 loss: 0.2589315176010132
Batch 30/64 loss: 0.27000153064727783
Batch 31/64 loss: 0.2573915123939514
Batch 32/64 loss: 0.25693047046661377
Batch 33/64 loss: 0.26172494888305664
Batch 34/64 loss: 0.264973521232605
Batch 35/64 loss: 0.26347827911376953
Batch 36/64 loss: 0.2620255947113037
Batch 37/64 loss: 0.2617872357368469
Batch 38/64 loss: 0.27623605728149414
Batch 39/64 loss: 0.26578497886657715
Batch 40/64 loss: 0.2604871392250061
Batch 41/64 loss: 0.25761866569519043
Batch 42/64 loss: 0.26249176263809204
Batch 43/64 loss: 0.26735901832580566
Batch 44/64 loss: 0.26686978340148926
Batch 45/64 loss: 0.2572968006134033
Batch 46/64 loss: 0.26695716381073
Batch 47/64 loss: 0.26762938499450684
Batch 48/64 loss: 0.25924021005630493
Batch 49/64 loss: 0.2717171907424927
Batch 50/64 loss: 0.26614630222320557
Batch 51/64 loss: 0.26142817735671997
Batch 52/64 loss: 0.2614220976829529
Batch 53/64 loss: 0.26091259717941284
Batch 54/64 loss: 0.26452481746673584
Batch 55/64 loss: 0.2678593397140503
Batch 56/64 loss: 0.26156020164489746
Batch 57/64 loss: 0.2606062889099121
Batch 58/64 loss: 0.26795244216918945
Batch 59/64 loss: 0.26535719633102417
Batch 60/64 loss: 0.2641356587409973
Batch 61/64 loss: 0.26814430952072144
Batch 62/64 loss: 0.2627873420715332
Batch 63/64 loss: 0.26559674739837646
Batch 64/64 loss: 0.27177947759628296
Epoch 430  Train loss: 0.26323146562950284  Val loss: 0.31317228898149996
Epoch 431
-------------------------------
Batch 1/64 loss: 0.26244425773620605
Batch 2/64 loss: 0.2627667188644409
Batch 3/64 loss: 0.2585175037384033
Batch 4/64 loss: 0.26214736700057983
Batch 5/64 loss: 0.266859769821167
Batch 6/64 loss: 0.2573120594024658
Batch 7/64 loss: 0.261732816696167
Batch 8/64 loss: 0.26603007316589355
Batch 9/64 loss: 0.2562415599822998
Batch 10/64 loss: 0.26656073331832886
Batch 11/64 loss: 0.25624972581863403
Batch 12/64 loss: 0.2644292712211609
Batch 13/64 loss: 0.26169514656066895
Batch 14/64 loss: 0.262617826461792
Batch 15/64 loss: 0.26375317573547363
Batch 16/64 loss: 0.25808846950531006
Batch 17/64 loss: 0.26788997650146484
Batch 18/64 loss: 0.26464903354644775
Batch 19/64 loss: 0.27827221155166626
Batch 20/64 loss: 0.2650458812713623
Batch 21/64 loss: 0.26807689666748047
Batch 22/64 loss: 0.2623617649078369
Batch 23/64 loss: 0.25853973627090454
Batch 24/64 loss: 0.2588045001029968
Batch 25/64 loss: 0.2709641456604004
Batch 26/64 loss: 0.26582372188568115
Batch 27/64 loss: 0.2674283981323242
Batch 28/64 loss: 0.25697535276412964
Batch 29/64 loss: 0.26855456829071045
Batch 30/64 loss: 0.25861674547195435
Batch 31/64 loss: 0.26980793476104736
Batch 32/64 loss: 0.25912147760391235
Batch 33/64 loss: 0.2617347836494446
Batch 34/64 loss: 0.2667466998100281
Batch 35/64 loss: 0.26150596141815186
Batch 36/64 loss: 0.26713991165161133
Batch 37/64 loss: 0.2616877555847168
Batch 38/64 loss: 0.25861793756484985
Batch 39/64 loss: 0.26804453134536743
Batch 40/64 loss: 0.2607787251472473
Batch 41/64 loss: 0.26711195707321167
Batch 42/64 loss: 0.2584829330444336
Batch 43/64 loss: 0.2578393816947937
Batch 44/64 loss: 0.2620360851287842
Batch 45/64 loss: 0.2623596787452698
Batch 46/64 loss: 0.260303258895874
Batch 47/64 loss: 0.26387059688568115
Batch 48/64 loss: 0.2611714005470276
Batch 49/64 loss: 0.26104384660720825
Batch 50/64 loss: 0.26406675577163696
Batch 51/64 loss: 0.26543623208999634
Batch 52/64 loss: 0.2573174238204956
Batch 53/64 loss: 0.27200305461883545
Batch 54/64 loss: 0.26367175579071045
Batch 55/64 loss: 0.2644643187522888
Batch 56/64 loss: 0.2681052088737488
Batch 57/64 loss: 0.2652990221977234
Batch 58/64 loss: 0.2688955068588257
Batch 59/64 loss: 0.2657797336578369
Batch 60/64 loss: 0.2651776075363159
Batch 61/64 loss: 0.264835000038147
Batch 62/64 loss: 0.26307398080825806
Batch 63/64 loss: 0.2663635015487671
Batch 64/64 loss: 0.2599928379058838
Epoch 431  Train loss: 0.2635033411138198  Val loss: 0.31240756937728303
Epoch 432
-------------------------------
Batch 1/64 loss: 0.25674742460250854
Batch 2/64 loss: 0.2588573694229126
Batch 3/64 loss: 0.2650083303451538
Batch 4/64 loss: 0.256564199924469
Batch 5/64 loss: 0.26787471771240234
Batch 6/64 loss: 0.2659878134727478
Batch 7/64 loss: 0.26184797286987305
Batch 8/64 loss: 0.2634514570236206
Batch 9/64 loss: 0.26108992099761963
Batch 10/64 loss: 0.25976717472076416
Batch 11/64 loss: 0.26531821489334106
Batch 12/64 loss: 0.26168185472488403
Batch 13/64 loss: 0.2642472982406616
Batch 14/64 loss: 0.26118284463882446
Batch 15/64 loss: 0.2664559483528137
Batch 16/64 loss: 0.2629894018173218
Batch 17/64 loss: 0.2589433193206787
Batch 18/64 loss: 0.2590980529785156
Batch 19/64 loss: 0.26170939207077026
Batch 20/64 loss: 0.26360106468200684
Batch 21/64 loss: 0.2667415142059326
Batch 22/64 loss: 0.2669055461883545
Batch 23/64 loss: 0.26353323459625244
Batch 24/64 loss: 0.2622390389442444
Batch 25/64 loss: 0.26512062549591064
Batch 26/64 loss: 0.2615782618522644
Batch 27/64 loss: 0.2657625675201416
Batch 28/64 loss: 0.2704738974571228
Batch 29/64 loss: 0.26120901107788086
Batch 30/64 loss: 0.2663501501083374
Batch 31/64 loss: 0.2555239200592041
Batch 32/64 loss: 0.25729942321777344
Batch 33/64 loss: 0.2661222219467163
Batch 34/64 loss: 0.269115686416626
Batch 35/64 loss: 0.26006609201431274
Batch 36/64 loss: 0.2670968174934387
Batch 37/64 loss: 0.26501286029815674
Batch 38/64 loss: 0.2561377286911011
Batch 39/64 loss: 0.25693047046661377
Batch 40/64 loss: 0.25911128520965576
Batch 41/64 loss: 0.26401984691619873
Batch 42/64 loss: 0.266201376914978
Batch 43/64 loss: 0.2574962377548218
Batch 44/64 loss: 0.2586580514907837
Batch 45/64 loss: 0.26587438583374023
Batch 46/64 loss: 0.26466798782348633
Batch 47/64 loss: 0.2571016550064087
Batch 48/64 loss: 0.2649538516998291
Batch 49/64 loss: 0.262839674949646
Batch 50/64 loss: 0.2564260959625244
Batch 51/64 loss: 0.2600610852241516
Batch 52/64 loss: 0.26752638816833496
Batch 53/64 loss: 0.26415765285491943
Batch 54/64 loss: 0.26667869091033936
Batch 55/64 loss: 0.26528048515319824
Batch 56/64 loss: 0.2631971836090088
Batch 57/64 loss: 0.26022660732269287
Batch 58/64 loss: 0.2627556324005127
Batch 59/64 loss: 0.26946187019348145
Batch 60/64 loss: 0.2600415349006653
Batch 61/64 loss: 0.26619237661361694
Batch 62/64 loss: 0.26843953132629395
Batch 63/64 loss: 0.26090312004089355
Batch 64/64 loss: 0.26429253816604614
Epoch 432  Train loss: 0.2628413310237959  Val loss: 0.31293028736442224
Epoch 433
-------------------------------
Batch 1/64 loss: 0.26143115758895874
Batch 2/64 loss: 0.2662391662597656
Batch 3/64 loss: 0.26150381565093994
Batch 4/64 loss: 0.2602858543395996
Batch 5/64 loss: 0.26404595375061035
Batch 6/64 loss: 0.25996291637420654
Batch 7/64 loss: 0.26474088430404663
Batch 8/64 loss: 0.25980639457702637
Batch 9/64 loss: 0.2672569751739502
Batch 10/64 loss: 0.26659107208251953
Batch 11/64 loss: 0.26143109798431396
Batch 12/64 loss: 0.2660219669342041
Batch 13/64 loss: 0.2519509792327881
Batch 14/64 loss: 0.2577172517776489
Batch 15/64 loss: 0.2551795244216919
Batch 16/64 loss: 0.2657887935638428
Batch 17/64 loss: 0.26105058193206787
Batch 18/64 loss: 0.261618971824646
Batch 19/64 loss: 0.27832651138305664
Batch 20/64 loss: 0.26628679037094116
Batch 21/64 loss: 0.2715476155281067
Batch 22/64 loss: 0.26442837715148926
Batch 23/64 loss: 0.26360541582107544
Batch 24/64 loss: 0.262325644493103
Batch 25/64 loss: 0.2633490562438965
Batch 26/64 loss: 0.2560218572616577
Batch 27/64 loss: 0.26616668701171875
Batch 28/64 loss: 0.2608952522277832
Batch 29/64 loss: 0.2595757246017456
Batch 30/64 loss: 0.2584497928619385
Batch 31/64 loss: 0.26072120666503906
Batch 32/64 loss: 0.26178908348083496
Batch 33/64 loss: 0.25933992862701416
Batch 34/64 loss: 0.2647026777267456
Batch 35/64 loss: 0.2610679268836975
Batch 36/64 loss: 0.2560601234436035
Batch 37/64 loss: 0.2632676362991333
Batch 38/64 loss: 0.26073169708251953
Batch 39/64 loss: 0.2607051730155945
Batch 40/64 loss: 0.25898802280426025
Batch 41/64 loss: 0.25801920890808105
Batch 42/64 loss: 0.26192009449005127
Batch 43/64 loss: 0.2599416971206665
Batch 44/64 loss: 0.26040422916412354
Batch 45/64 loss: 0.258522629737854
Batch 46/64 loss: 0.26586270332336426
Batch 47/64 loss: 0.2589646577835083
Batch 48/64 loss: 0.27004945278167725
Batch 49/64 loss: 0.260617733001709
Batch 50/64 loss: 0.25972890853881836
Batch 51/64 loss: 0.2588069438934326
Batch 52/64 loss: 0.2630664110183716
Batch 53/64 loss: 0.261255145072937
Batch 54/64 loss: 0.2683887481689453
Batch 55/64 loss: 0.27013111114501953
Batch 56/64 loss: 0.2645862102508545
Batch 57/64 loss: 0.2662695050239563
Batch 58/64 loss: 0.2650820016860962
Batch 59/64 loss: 0.26563870906829834
Batch 60/64 loss: 0.2633665204048157
Batch 61/64 loss: 0.260870099067688
Batch 62/64 loss: 0.2638687491416931
Batch 63/64 loss: 0.2689175009727478
Batch 64/64 loss: 0.2676945924758911
Epoch 433  Train loss: 0.26268275251575546  Val loss: 0.3121712443345191
Epoch 434
-------------------------------
Batch 1/64 loss: 0.2623068690299988
Batch 2/64 loss: 0.26836031675338745
Batch 3/64 loss: 0.2624778747558594
Batch 4/64 loss: 0.2611527442932129
Batch 5/64 loss: 0.2642556428909302
Batch 6/64 loss: 0.27157914638519287
Batch 7/64 loss: 0.26217925548553467
Batch 8/64 loss: 0.26642000675201416
Batch 9/64 loss: 0.2653766870498657
Batch 10/64 loss: 0.2679979205131531
Batch 11/64 loss: 0.2596142292022705
Batch 12/64 loss: 0.2622554302215576
Batch 13/64 loss: 0.2661612033843994
Batch 14/64 loss: 0.26129233837127686
Batch 15/64 loss: 0.2598167657852173
Batch 16/64 loss: 0.2604713439941406
Batch 17/64 loss: 0.27122509479522705
Batch 18/64 loss: 0.2575165033340454
Batch 19/64 loss: 0.26306653022766113
Batch 20/64 loss: 0.2662355899810791
Batch 21/64 loss: 0.2592836618423462
Batch 22/64 loss: 0.2636326551437378
Batch 23/64 loss: 0.2609524726867676
Batch 24/64 loss: 0.2611713409423828
Batch 25/64 loss: 0.26938438415527344
Batch 26/64 loss: 0.2645685076713562
Batch 27/64 loss: 0.26292091608047485
Batch 28/64 loss: 0.2629936933517456
Batch 29/64 loss: 0.26123684644699097
Batch 30/64 loss: 0.26203054189682007
Batch 31/64 loss: 0.26482927799224854
Batch 32/64 loss: 0.26380401849746704
Batch 33/64 loss: 0.26172101497650146
Batch 34/64 loss: 0.26602649688720703
Batch 35/64 loss: 0.2588539719581604
Batch 36/64 loss: 0.26187944412231445
Batch 37/64 loss: 0.2597208619117737
Batch 38/64 loss: 0.2616591453552246
Batch 39/64 loss: 0.26354920864105225
Batch 40/64 loss: 0.26303160190582275
Batch 41/64 loss: 0.2614445686340332
Batch 42/64 loss: 0.2627207040786743
Batch 43/64 loss: 0.2592383027076721
Batch 44/64 loss: 0.2683447003364563
Batch 45/64 loss: 0.2595515847206116
Batch 46/64 loss: 0.2655310034751892
Batch 47/64 loss: 0.2654632329940796
Batch 48/64 loss: 0.2630230784416199
Batch 49/64 loss: 0.25790518522262573
Batch 50/64 loss: 0.25912749767303467
Batch 51/64 loss: 0.2604791522026062
Batch 52/64 loss: 0.25901567935943604
Batch 53/64 loss: 0.2632593512535095
Batch 54/64 loss: 0.262883722782135
Batch 55/64 loss: 0.2669767737388611
Batch 56/64 loss: 0.26095616817474365
Batch 57/64 loss: 0.26388490200042725
Batch 58/64 loss: 0.25675106048583984
Batch 59/64 loss: 0.2660336494445801
Batch 60/64 loss: 0.2574434280395508
Batch 61/64 loss: 0.26907211542129517
Batch 62/64 loss: 0.2608897089958191
Batch 63/64 loss: 0.26033318042755127
Batch 64/64 loss: 0.2589179277420044
Epoch 434  Train loss: 0.2628631961111929  Val loss: 0.3125614796307488
Epoch 435
-------------------------------
Batch 1/64 loss: 0.2595839500427246
Batch 2/64 loss: 0.2636457681655884
Batch 3/64 loss: 0.2597125768661499
Batch 4/64 loss: 0.274483323097229
Batch 5/64 loss: 0.25675052404403687
Batch 6/64 loss: 0.25800472497940063
Batch 7/64 loss: 0.26303422451019287
Batch 8/64 loss: 0.2573744058609009
Batch 9/64 loss: 0.25650477409362793
Batch 10/64 loss: 0.25881147384643555
Batch 11/64 loss: 0.2587137222290039
Batch 12/64 loss: 0.26466625928878784
Batch 13/64 loss: 0.2594106197357178
Batch 14/64 loss: 0.26192235946655273
Batch 15/64 loss: 0.26872676610946655
Batch 16/64 loss: 0.25983673334121704
Batch 17/64 loss: 0.26066505908966064
Batch 18/64 loss: 0.25907742977142334
Batch 19/64 loss: 0.2608731985092163
Batch 20/64 loss: 0.2609623670578003
Batch 21/64 loss: 0.26328885555267334
Batch 22/64 loss: 0.26286089420318604
Batch 23/64 loss: 0.26481884717941284
Batch 24/64 loss: 0.2677144408226013
Batch 25/64 loss: 0.264886736869812
Batch 26/64 loss: 0.2630115747451782
Batch 27/64 loss: 0.27194446325302124
Batch 28/64 loss: 0.26714134216308594
Batch 29/64 loss: 0.2666769027709961
Batch 30/64 loss: 0.26247620582580566
Batch 31/64 loss: 0.26044535636901855
Batch 32/64 loss: 0.26615309715270996
Batch 33/64 loss: 0.264448881149292
Batch 34/64 loss: 0.25618141889572144
Batch 35/64 loss: 0.2653372287750244
Batch 36/64 loss: 0.2591409683227539
Batch 37/64 loss: 0.26063328981399536
Batch 38/64 loss: 0.26622670888900757
Batch 39/64 loss: 0.256854772567749
Batch 40/64 loss: 0.264476478099823
Batch 41/64 loss: 0.25974392890930176
Batch 42/64 loss: 0.26441431045532227
Batch 43/64 loss: 0.25753867626190186
Batch 44/64 loss: 0.26833146810531616
Batch 45/64 loss: 0.2651631832122803
Batch 46/64 loss: 0.2588310241699219
Batch 47/64 loss: 0.2647169828414917
Batch 48/64 loss: 0.26255613565444946
Batch 49/64 loss: 0.26361405849456787
Batch 50/64 loss: 0.27051806449890137
Batch 51/64 loss: 0.2601274847984314
Batch 52/64 loss: 0.26206016540527344
Batch 53/64 loss: 0.2655792832374573
Batch 54/64 loss: 0.2625938653945923
Batch 55/64 loss: 0.2584587335586548
Batch 56/64 loss: 0.2557286024093628
Batch 57/64 loss: 0.25909650325775146
Batch 58/64 loss: 0.26183438301086426
Batch 59/64 loss: 0.2558377981185913
Batch 60/64 loss: 0.2624583840370178
Batch 61/64 loss: 0.2618499994277954
Batch 62/64 loss: 0.2634490132331848
Batch 63/64 loss: 0.2652519941329956
Batch 64/64 loss: 0.25739169120788574
Epoch 435  Train loss: 0.2622788476008995  Val loss: 0.3124655202491996
Epoch 436
-------------------------------
Batch 1/64 loss: 0.25456058979034424
Batch 2/64 loss: 0.25803911685943604
Batch 3/64 loss: 0.25896406173706055
Batch 4/64 loss: 0.2610121965408325
Batch 5/64 loss: 0.25954610109329224
Batch 6/64 loss: 0.2621145248413086
Batch 7/64 loss: 0.2674023509025574
Batch 8/64 loss: 0.25947582721710205
Batch 9/64 loss: 0.2617042660713196
Batch 10/64 loss: 0.26378583908081055
Batch 11/64 loss: 0.2601051926612854
Batch 12/64 loss: 0.2595728635787964
Batch 13/64 loss: 0.26599347591400146
Batch 14/64 loss: 0.2615465521812439
Batch 15/64 loss: 0.2729080319404602
Batch 16/64 loss: 0.2612454891204834
Batch 17/64 loss: 0.25860631465911865
Batch 18/64 loss: 0.25512319803237915
Batch 19/64 loss: 0.2640954256057739
Batch 20/64 loss: 0.26076215505599976
Batch 21/64 loss: 0.26024341583251953
Batch 22/64 loss: 0.2632167935371399
Batch 23/64 loss: 0.2638016939163208
Batch 24/64 loss: 0.26068955659866333
Batch 25/64 loss: 0.2630543112754822
Batch 26/64 loss: 0.26227158308029175
Batch 27/64 loss: 0.2624278664588928
Batch 28/64 loss: 0.25786274671554565
Batch 29/64 loss: 0.25562429428100586
Batch 30/64 loss: 0.2671024799346924
Batch 31/64 loss: 0.26192522048950195
Batch 32/64 loss: 0.26178139448165894
Batch 33/64 loss: 0.2645212411880493
Batch 34/64 loss: 0.2599576711654663
Batch 35/64 loss: 0.2609182596206665
Batch 36/64 loss: 0.2617257833480835
Batch 37/64 loss: 0.2571561336517334
Batch 38/64 loss: 0.2606388330459595
Batch 39/64 loss: 0.2612791657447815
Batch 40/64 loss: 0.26724720001220703
Batch 41/64 loss: 0.2617807388305664
Batch 42/64 loss: 0.2606561779975891
Batch 43/64 loss: 0.25941532850265503
Batch 44/64 loss: 0.261386513710022
Batch 45/64 loss: 0.25793778896331787
Batch 46/64 loss: 0.26370853185653687
Batch 47/64 loss: 0.2722434997558594
Batch 48/64 loss: 0.2684730291366577
Batch 49/64 loss: 0.2606409788131714
Batch 50/64 loss: 0.25746381282806396
Batch 51/64 loss: 0.26809537410736084
Batch 52/64 loss: 0.2719402313232422
Batch 53/64 loss: 0.26408374309539795
Batch 54/64 loss: 0.2638891339302063
Batch 55/64 loss: 0.2618192434310913
Batch 56/64 loss: 0.2651532292366028
Batch 57/64 loss: 0.26596832275390625
Batch 58/64 loss: 0.2635551691055298
Batch 59/64 loss: 0.2633148431777954
Batch 60/64 loss: 0.27237647771835327
Batch 61/64 loss: 0.26820433139801025
Batch 62/64 loss: 0.261837899684906
Batch 63/64 loss: 0.2645761966705322
Batch 64/64 loss: 0.25761038064956665
Epoch 436  Train loss: 0.26245862900042066  Val loss: 0.31350698749634
Epoch 437
-------------------------------
Batch 1/64 loss: 0.2608645558357239
Batch 2/64 loss: 0.2617984414100647
Batch 3/64 loss: 0.2645188570022583
Batch 4/64 loss: 0.25488102436065674
Batch 5/64 loss: 0.2612720727920532
Batch 6/64 loss: 0.2672605514526367
Batch 7/64 loss: 0.2654545307159424
Batch 8/64 loss: 0.27136075496673584
Batch 9/64 loss: 0.26365339756011963
Batch 10/64 loss: 0.25417232513427734
Batch 11/64 loss: 0.2668839693069458
Batch 12/64 loss: 0.26370179653167725
Batch 13/64 loss: 0.2589428424835205
Batch 14/64 loss: 0.2600330114364624
Batch 15/64 loss: 0.262813925743103
Batch 16/64 loss: 0.261121928691864
Batch 17/64 loss: 0.2557508945465088
Batch 18/64 loss: 0.2627739906311035
Batch 19/64 loss: 0.263419508934021
Batch 20/64 loss: 0.26128697395324707
Batch 21/64 loss: 0.26715999841690063
Batch 22/64 loss: 0.26008307933807373
Batch 23/64 loss: 0.2604961395263672
Batch 24/64 loss: 0.26547467708587646
Batch 25/64 loss: 0.2645711302757263
Batch 26/64 loss: 0.25760018825531006
Batch 27/64 loss: 0.2667352557182312
Batch 28/64 loss: 0.2549448013305664
Batch 29/64 loss: 0.25960278511047363
Batch 30/64 loss: 0.2592034339904785
Batch 31/64 loss: 0.255160927772522
Batch 32/64 loss: 0.2607424855232239
Batch 33/64 loss: 0.2611178159713745
Batch 34/64 loss: 0.2616347074508667
Batch 35/64 loss: 0.2615818381309509
Batch 36/64 loss: 0.2617306709289551
Batch 37/64 loss: 0.26871299743652344
Batch 38/64 loss: 0.2657428979873657
Batch 39/64 loss: 0.26131677627563477
Batch 40/64 loss: 0.25777876377105713
Batch 41/64 loss: 0.2631272077560425
Batch 42/64 loss: 0.2621667981147766
Batch 43/64 loss: 0.25964343547821045
Batch 44/64 loss: 0.27152466773986816
Batch 45/64 loss: 0.2657623291015625
Batch 46/64 loss: 0.2609320878982544
Batch 47/64 loss: 0.2675439119338989
Batch 48/64 loss: 0.2697817087173462
Batch 49/64 loss: 0.2643461227416992
Batch 50/64 loss: 0.261877179145813
Batch 51/64 loss: 0.26325786113739014
Batch 52/64 loss: 0.26511150598526
Batch 53/64 loss: 0.2646179795265198
Batch 54/64 loss: 0.262378990650177
Batch 55/64 loss: 0.26336461305618286
Batch 56/64 loss: 0.2697798013687134
Batch 57/64 loss: 0.26427197456359863
Batch 58/64 loss: 0.27269262075424194
Batch 59/64 loss: 0.2576349973678589
Batch 60/64 loss: 0.2616668939590454
Batch 61/64 loss: 0.2601998448371887
Batch 62/64 loss: 0.2633920907974243
Batch 63/64 loss: 0.2643107771873474
Batch 64/64 loss: 0.2600666284561157
Epoch 437  Train loss: 0.2627104642344456  Val loss: 0.3125735328779188
Epoch 438
-------------------------------
Batch 1/64 loss: 0.2620964050292969
Batch 2/64 loss: 0.2656397223472595
Batch 3/64 loss: 0.2616787552833557
Batch 4/64 loss: 0.2689858675003052
Batch 5/64 loss: 0.266940712928772
Batch 6/64 loss: 0.25860506296157837
Batch 7/64 loss: 0.26332253217697144
Batch 8/64 loss: 0.26228153705596924
Batch 9/64 loss: 0.27354001998901367
Batch 10/64 loss: 0.26011115312576294
Batch 11/64 loss: 0.26151859760284424
Batch 12/64 loss: 0.2642977237701416
Batch 13/64 loss: 0.2611149549484253
Batch 14/64 loss: 0.263217568397522
Batch 15/64 loss: 0.26490044593811035
Batch 16/64 loss: 0.26976585388183594
Batch 17/64 loss: 0.26344943046569824
Batch 18/64 loss: 0.26681745052337646
Batch 19/64 loss: 0.2737525701522827
Batch 20/64 loss: 0.25844883918762207
Batch 21/64 loss: 0.26210176944732666
Batch 22/64 loss: 0.258960485458374
Batch 23/64 loss: 0.26186054944992065
Batch 24/64 loss: 0.25701647996902466
Batch 25/64 loss: 0.2680627107620239
Batch 26/64 loss: 0.2590450048446655
Batch 27/64 loss: 0.25986480712890625
Batch 28/64 loss: 0.27001500129699707
Batch 29/64 loss: 0.25585752725601196
Batch 30/64 loss: 0.265480637550354
Batch 31/64 loss: 0.266603946685791
Batch 32/64 loss: 0.26898205280303955
Batch 33/64 loss: 0.26465415954589844
Batch 34/64 loss: 0.2583106756210327
Batch 35/64 loss: 0.2638888955116272
Batch 36/64 loss: 0.2573455572128296
Batch 37/64 loss: 0.2562439441680908
Batch 38/64 loss: 0.2614908218383789
Batch 39/64 loss: 0.25812864303588867
Batch 40/64 loss: 0.26439201831817627
Batch 41/64 loss: 0.26250940561294556
Batch 42/64 loss: 0.2515089511871338
Batch 43/64 loss: 0.2597423791885376
Batch 44/64 loss: 0.26983755826950073
Batch 45/64 loss: 0.25746017694473267
Batch 46/64 loss: 0.2640811800956726
Batch 47/64 loss: 0.26064014434814453
Batch 48/64 loss: 0.2678324580192566
Batch 49/64 loss: 0.25790727138519287
Batch 50/64 loss: 0.2592770457267761
Batch 51/64 loss: 0.2590477466583252
Batch 52/64 loss: 0.26209962368011475
Batch 53/64 loss: 0.2595915198326111
Batch 54/64 loss: 0.26178252696990967
Batch 55/64 loss: 0.26770591735839844
Batch 56/64 loss: 0.2578123211860657
Batch 57/64 loss: 0.2659902572631836
Batch 58/64 loss: 0.2559434771537781
Batch 59/64 loss: 0.2626394033432007
Batch 60/64 loss: 0.25688594579696655
Batch 61/64 loss: 0.2660505771636963
Batch 62/64 loss: 0.26539158821105957
Batch 63/64 loss: 0.26250195503234863
Batch 64/64 loss: 0.2733604907989502
Epoch 438  Train loss: 0.26271452062270223  Val loss: 0.3130099486649241
Epoch 439
-------------------------------
Batch 1/64 loss: 0.2593820095062256
Batch 2/64 loss: 0.26230037212371826
Batch 3/64 loss: 0.2636774778366089
Batch 4/64 loss: 0.2635214328765869
Batch 5/64 loss: 0.2580440640449524
Batch 6/64 loss: 0.2591804265975952
Batch 7/64 loss: 0.26685965061187744
Batch 8/64 loss: 0.26973605155944824
Batch 9/64 loss: 0.2682209610939026
Batch 10/64 loss: 0.2645411491394043
Batch 11/64 loss: 0.26233112812042236
Batch 12/64 loss: 0.2625836730003357
Batch 13/64 loss: 0.25487571954727173
Batch 14/64 loss: 0.26001060009002686
Batch 15/64 loss: 0.2644916772842407
Batch 16/64 loss: 0.2656668424606323
Batch 17/64 loss: 0.2614995837211609
Batch 18/64 loss: 0.25810450315475464
Batch 19/64 loss: 0.2587704658508301
Batch 20/64 loss: 0.26090002059936523
Batch 21/64 loss: 0.2625976800918579
Batch 22/64 loss: 0.26646095514297485
Batch 23/64 loss: 0.2619659900665283
Batch 24/64 loss: 0.26527565717697144
Batch 25/64 loss: 0.26751863956451416
Batch 26/64 loss: 0.2599942088127136
Batch 27/64 loss: 0.2640020251274109
Batch 28/64 loss: 0.26290541887283325
Batch 29/64 loss: 0.2612283229827881
Batch 30/64 loss: 0.25913912057876587
Batch 31/64 loss: 0.2617262005805969
Batch 32/64 loss: 0.2609800100326538
Batch 33/64 loss: 0.26066213846206665
Batch 34/64 loss: 0.2582172155380249
Batch 35/64 loss: 0.2575065493583679
Batch 36/64 loss: 0.2613459825515747
Batch 37/64 loss: 0.25993603467941284
Batch 38/64 loss: 0.26139432191848755
Batch 39/64 loss: 0.2702252268791199
Batch 40/64 loss: 0.2626550793647766
Batch 41/64 loss: 0.25886499881744385
Batch 42/64 loss: 0.25939399003982544
Batch 43/64 loss: 0.2667209506034851
Batch 44/64 loss: 0.2629232406616211
Batch 45/64 loss: 0.25740283727645874
Batch 46/64 loss: 0.2600135803222656
Batch 47/64 loss: 0.2668776512145996
Batch 48/64 loss: 0.2672489285469055
Batch 49/64 loss: 0.26949745416641235
Batch 50/64 loss: 0.2582106590270996
Batch 51/64 loss: 0.26097214221954346
Batch 52/64 loss: 0.27450746297836304
Batch 53/64 loss: 0.2667297124862671
Batch 54/64 loss: 0.26288294792175293
Batch 55/64 loss: 0.2613029479980469
Batch 56/64 loss: 0.27043241262435913
Batch 57/64 loss: 0.26119035482406616
Batch 58/64 loss: 0.26375555992126465
Batch 59/64 loss: 0.26603662967681885
Batch 60/64 loss: 0.2609381079673767
Batch 61/64 loss: 0.2583341598510742
Batch 62/64 loss: 0.25923287868499756
Batch 63/64 loss: 0.2586705684661865
Batch 64/64 loss: 0.2655378580093384
Epoch 439  Train loss: 0.26261534363615746  Val loss: 0.3134021175276373
Epoch 440
-------------------------------
Batch 1/64 loss: 0.26532304286956787
Batch 2/64 loss: 0.2656928300857544
Batch 3/64 loss: 0.2576233744621277
Batch 4/64 loss: 0.2535364627838135
Batch 5/64 loss: 0.2678871154785156
Batch 6/64 loss: 0.2571474313735962
Batch 7/64 loss: 0.25696998834609985
Batch 8/64 loss: 0.2568874955177307
Batch 9/64 loss: 0.26575803756713867
Batch 10/64 loss: 0.2567509412765503
Batch 11/64 loss: 0.25653958320617676
Batch 12/64 loss: 0.2595798373222351
Batch 13/64 loss: 0.25815248489379883
Batch 14/64 loss: 0.26264238357543945
Batch 15/64 loss: 0.2598137855529785
Batch 16/64 loss: 0.25546252727508545
Batch 17/64 loss: 0.26300525665283203
Batch 18/64 loss: 0.26029670238494873
Batch 19/64 loss: 0.2636074423789978
Batch 20/64 loss: 0.26690685749053955
Batch 21/64 loss: 0.26400232315063477
Batch 22/64 loss: 0.25995779037475586
Batch 23/64 loss: 0.26207923889160156
Batch 24/64 loss: 0.2589606046676636
Batch 25/64 loss: 0.2631695866584778
Batch 26/64 loss: 0.2703758478164673
Batch 27/64 loss: 0.26262080669403076
Batch 28/64 loss: 0.26685696840286255
Batch 29/64 loss: 0.25559544563293457
Batch 30/64 loss: 0.267073392868042
Batch 31/64 loss: 0.2662011384963989
Batch 32/64 loss: 0.26292115449905396
Batch 33/64 loss: 0.2677360773086548
Batch 34/64 loss: 0.2608564496040344
Batch 35/64 loss: 0.26158666610717773
Batch 36/64 loss: 0.27018117904663086
Batch 37/64 loss: 0.2708662152290344
Batch 38/64 loss: 0.2616192698478699
Batch 39/64 loss: 0.25804197788238525
Batch 40/64 loss: 0.2605762481689453
Batch 41/64 loss: 0.2591179609298706
Batch 42/64 loss: 0.2660800814628601
Batch 43/64 loss: 0.26435768604278564
Batch 44/64 loss: 0.2686272859573364
Batch 45/64 loss: 0.2577977776527405
Batch 46/64 loss: 0.26685595512390137
Batch 47/64 loss: 0.2633264660835266
Batch 48/64 loss: 0.258420467376709
Batch 49/64 loss: 0.267275869846344
Batch 50/64 loss: 0.2703918218612671
Batch 51/64 loss: 0.2599012851715088
Batch 52/64 loss: 0.26047074794769287
Batch 53/64 loss: 0.2633402347564697
Batch 54/64 loss: 0.2606452703475952
Batch 55/64 loss: 0.25552916526794434
Batch 56/64 loss: 0.26203322410583496
Batch 57/64 loss: 0.2563926577568054
Batch 58/64 loss: 0.2668464183807373
Batch 59/64 loss: 0.2656213641166687
Batch 60/64 loss: 0.264872670173645
Batch 61/64 loss: 0.26420581340789795
Batch 62/64 loss: 0.26607638597488403
Batch 63/64 loss: 0.27151620388031006
Batch 64/64 loss: 0.26703089475631714
Epoch 440  Train loss: 0.26260137955347695  Val loss: 0.3136174201555678
Epoch 441
-------------------------------
Batch 1/64 loss: 0.25818753242492676
Batch 2/64 loss: 0.2557007074356079
Batch 3/64 loss: 0.26935410499572754
Batch 4/64 loss: 0.26028919219970703
Batch 5/64 loss: 0.2584744691848755
Batch 6/64 loss: 0.259147584438324
Batch 7/64 loss: 0.25697898864746094
Batch 8/64 loss: 0.26726365089416504
Batch 9/64 loss: 0.26007795333862305
Batch 10/64 loss: 0.25417304039001465
Batch 11/64 loss: 0.25654715299606323
Batch 12/64 loss: 0.2686832547187805
Batch 13/64 loss: 0.25940918922424316
Batch 14/64 loss: 0.2617490291595459
Batch 15/64 loss: 0.26128673553466797
Batch 16/64 loss: 0.260342001914978
Batch 17/64 loss: 0.25764214992523193
Batch 18/64 loss: 0.25836479663848877
Batch 19/64 loss: 0.2555176615715027
Batch 20/64 loss: 0.2632783055305481
Batch 21/64 loss: 0.2726023197174072
Batch 22/64 loss: 0.26375722885131836
Batch 23/64 loss: 0.2564215660095215
Batch 24/64 loss: 0.26535964012145996
Batch 25/64 loss: 0.2638232707977295
Batch 26/64 loss: 0.2566034197807312
Batch 27/64 loss: 0.25986242294311523
Batch 28/64 loss: 0.2694789171218872
Batch 29/64 loss: 0.2656579613685608
Batch 30/64 loss: 0.2678126096725464
Batch 31/64 loss: 0.2615739107131958
Batch 32/64 loss: 0.2557438611984253
Batch 33/64 loss: 0.2589130401611328
Batch 34/64 loss: 0.2637685537338257
Batch 35/64 loss: 0.2583097815513611
Batch 36/64 loss: 0.2633439302444458
Batch 37/64 loss: 0.2643667459487915
Batch 38/64 loss: 0.26432740688323975
Batch 39/64 loss: 0.26505112648010254
Batch 40/64 loss: 0.2627546787261963
Batch 41/64 loss: 0.2620100975036621
Batch 42/64 loss: 0.2607957720756531
Batch 43/64 loss: 0.26215749979019165
Batch 44/64 loss: 0.2637102007865906
Batch 45/64 loss: 0.26126766204833984
Batch 46/64 loss: 0.2581756114959717
Batch 47/64 loss: 0.25980061292648315
Batch 48/64 loss: 0.26516103744506836
Batch 49/64 loss: 0.25904929637908936
Batch 50/64 loss: 0.26049792766571045
Batch 51/64 loss: 0.2657712697982788
Batch 52/64 loss: 0.26950550079345703
Batch 53/64 loss: 0.2614628076553345
Batch 54/64 loss: 0.2646024227142334
Batch 55/64 loss: 0.25521039962768555
Batch 56/64 loss: 0.2558555603027344
Batch 57/64 loss: 0.2684043049812317
Batch 58/64 loss: 0.26201164722442627
Batch 59/64 loss: 0.26372653245925903
Batch 60/64 loss: 0.2623041272163391
Batch 61/64 loss: 0.26416897773742676
Batch 62/64 loss: 0.26393163204193115
Batch 63/64 loss: 0.2612904906272888
Batch 64/64 loss: 0.2681516408920288
Epoch 441  Train loss: 0.261866431610257  Val loss: 0.31292906802954135
Epoch 442
-------------------------------
Batch 1/64 loss: 0.25822973251342773
Batch 2/64 loss: 0.26413142681121826
Batch 3/64 loss: 0.2581218481063843
Batch 4/64 loss: 0.2546718716621399
Batch 5/64 loss: 0.2612420320510864
Batch 6/64 loss: 0.25485795736312866
Batch 7/64 loss: 0.26063990592956543
Batch 8/64 loss: 0.2623118758201599
Batch 9/64 loss: 0.2582535743713379
Batch 10/64 loss: 0.2606889605522156
Batch 11/64 loss: 0.2675895690917969
Batch 12/64 loss: 0.256492555141449
Batch 13/64 loss: 0.25861024856567383
Batch 14/64 loss: 0.2611507773399353
Batch 15/64 loss: 0.2551851272583008
Batch 16/64 loss: 0.26868879795074463
Batch 17/64 loss: 0.267707884311676
Batch 18/64 loss: 0.2665223479270935
Batch 19/64 loss: 0.25485342741012573
Batch 20/64 loss: 0.25726938247680664
Batch 21/64 loss: 0.26518702507019043
Batch 22/64 loss: 0.2577347755432129
Batch 23/64 loss: 0.2661612629890442
Batch 24/64 loss: 0.2621147632598877
Batch 25/64 loss: 0.25840896368026733
Batch 26/64 loss: 0.2644556760787964
Batch 27/64 loss: 0.2635648846626282
Batch 28/64 loss: 0.25574588775634766
Batch 29/64 loss: 0.25985169410705566
Batch 30/64 loss: 0.2595100402832031
Batch 31/64 loss: 0.25490236282348633
Batch 32/64 loss: 0.25811463594436646
Batch 33/64 loss: 0.258633017539978
Batch 34/64 loss: 0.259030818939209
Batch 35/64 loss: 0.270222544670105
Batch 36/64 loss: 0.2636186480522156
Batch 37/64 loss: 0.26150089502334595
Batch 38/64 loss: 0.25280797481536865
Batch 39/64 loss: 0.26097404956817627
Batch 40/64 loss: 0.25688302516937256
Batch 41/64 loss: 0.2643128037452698
Batch 42/64 loss: 0.26273083686828613
Batch 43/64 loss: 0.26814115047454834
Batch 44/64 loss: 0.2622804641723633
Batch 45/64 loss: 0.27240705490112305
Batch 46/64 loss: 0.2603193521499634
Batch 47/64 loss: 0.26465004682540894
Batch 48/64 loss: 0.2583553194999695
Batch 49/64 loss: 0.2583518624305725
Batch 50/64 loss: 0.26264190673828125
Batch 51/64 loss: 0.2647526264190674
Batch 52/64 loss: 0.25929421186447144
Batch 53/64 loss: 0.26146942377090454
Batch 54/64 loss: 0.2667950391769409
Batch 55/64 loss: 0.27296340465545654
Batch 56/64 loss: 0.26455992460250854
Batch 57/64 loss: 0.26048189401626587
Batch 58/64 loss: 0.2662556767463684
Batch 59/64 loss: 0.27456116676330566
Batch 60/64 loss: 0.26459813117980957
Batch 61/64 loss: 0.2654989957809448
Batch 62/64 loss: 0.26807940006256104
Batch 63/64 loss: 0.2625401020050049
Batch 64/64 loss: 0.26321470737457275
Epoch 442  Train loss: 0.2619622599844839  Val loss: 0.31250814781156194
Epoch 443
-------------------------------
Batch 1/64 loss: 0.26254361867904663
Batch 2/64 loss: 0.25245898962020874
Batch 3/64 loss: 0.26284539699554443
Batch 4/64 loss: 0.2663590908050537
Batch 5/64 loss: 0.26634931564331055
Batch 6/64 loss: 0.2635304927825928
Batch 7/64 loss: 0.2610830068588257
Batch 8/64 loss: 0.26312994956970215
Batch 9/64 loss: 0.2516177296638489
Batch 10/64 loss: 0.26191699504852295
Batch 11/64 loss: 0.2556549310684204
Batch 12/64 loss: 0.26094794273376465
Batch 13/64 loss: 0.26189208030700684
Batch 14/64 loss: 0.2573434114456177
Batch 15/64 loss: 0.2629845142364502
Batch 16/64 loss: 0.2546508312225342
Batch 17/64 loss: 0.257940411567688
Batch 18/64 loss: 0.26677995920181274
Batch 19/64 loss: 0.2600356340408325
Batch 20/64 loss: 0.2624821066856384
Batch 21/64 loss: 0.2581390142440796
Batch 22/64 loss: 0.2583601474761963
Batch 23/64 loss: 0.2670416235923767
Batch 24/64 loss: 0.258447527885437
Batch 25/64 loss: 0.2687336206436157
Batch 26/64 loss: 0.2668544054031372
Batch 27/64 loss: 0.26776349544525146
Batch 28/64 loss: 0.26171445846557617
Batch 29/64 loss: 0.25682467222213745
Batch 30/64 loss: 0.25776147842407227
Batch 31/64 loss: 0.2627601623535156
Batch 32/64 loss: 0.26279252767562866
Batch 33/64 loss: 0.2609381675720215
Batch 34/64 loss: 0.2629472613334656
Batch 35/64 loss: 0.25858885049819946
Batch 36/64 loss: 0.2608811855316162
Batch 37/64 loss: 0.26309680938720703
Batch 38/64 loss: 0.2680619955062866
Batch 39/64 loss: 0.2637847661972046
Batch 40/64 loss: 0.26790159940719604
Batch 41/64 loss: 0.2632131576538086
Batch 42/64 loss: 0.26200443506240845
Batch 43/64 loss: 0.2659074068069458
Batch 44/64 loss: 0.2608526945114136
Batch 45/64 loss: 0.2663425803184509
Batch 46/64 loss: 0.2597154974937439
Batch 47/64 loss: 0.25936686992645264
Batch 48/64 loss: 0.2697335481643677
Batch 49/64 loss: 0.2683401107788086
Batch 50/64 loss: 0.2613719701766968
Batch 51/64 loss: 0.2597959041595459
Batch 52/64 loss: 0.25700193643569946
Batch 53/64 loss: 0.2589494585990906
Batch 54/64 loss: 0.2643263339996338
Batch 55/64 loss: 0.26053130626678467
Batch 56/64 loss: 0.25473839044570923
Batch 57/64 loss: 0.2665301561355591
Batch 58/64 loss: 0.2648036479949951
Batch 59/64 loss: 0.2641359567642212
Batch 60/64 loss: 0.26661908626556396
Batch 61/64 loss: 0.2705986499786377
Batch 62/64 loss: 0.2652832269668579
Batch 63/64 loss: 0.25947141647338867
Batch 64/64 loss: 0.25882184505462646
Epoch 443  Train loss: 0.26211278906055524  Val loss: 0.31287879120443285
Epoch 444
-------------------------------
Batch 1/64 loss: 0.2606280446052551
Batch 2/64 loss: 0.26065266132354736
Batch 3/64 loss: 0.2626394033432007
Batch 4/64 loss: 0.2622426748275757
Batch 5/64 loss: 0.26083171367645264
Batch 6/64 loss: 0.26290130615234375
Batch 7/64 loss: 0.2615510821342468
Batch 8/64 loss: 0.2601807117462158
Batch 9/64 loss: 0.25729817152023315
Batch 10/64 loss: 0.26142191886901855
Batch 11/64 loss: 0.26731276512145996
Batch 12/64 loss: 0.2612086534500122
Batch 13/64 loss: 0.2658933401107788
Batch 14/64 loss: 0.2642880082130432
Batch 15/64 loss: 0.25606006383895874
Batch 16/64 loss: 0.26323580741882324
Batch 17/64 loss: 0.2645610570907593
Batch 18/64 loss: 0.2617604732513428
Batch 19/64 loss: 0.2621725797653198
Batch 20/64 loss: 0.26482051610946655
Batch 21/64 loss: 0.2644123435020447
Batch 22/64 loss: 0.2689357399940491
Batch 23/64 loss: 0.25960445404052734
Batch 24/64 loss: 0.26196783781051636
Batch 25/64 loss: 0.2618502974510193
Batch 26/64 loss: 0.26264500617980957
Batch 27/64 loss: 0.2655869722366333
Batch 28/64 loss: 0.2574313282966614
Batch 29/64 loss: 0.26113003492355347
Batch 30/64 loss: 0.2670745849609375
Batch 31/64 loss: 0.26281964778900146
Batch 32/64 loss: 0.27106714248657227
Batch 33/64 loss: 0.2577641010284424
Batch 34/64 loss: 0.26020556688308716
Batch 35/64 loss: 0.2600504159927368
Batch 36/64 loss: 0.2544906735420227
Batch 37/64 loss: 0.2575211524963379
Batch 38/64 loss: 0.2616539001464844
Batch 39/64 loss: 0.25940126180648804
Batch 40/64 loss: 0.2538926601409912
Batch 41/64 loss: 0.26258206367492676
Batch 42/64 loss: 0.2577115297317505
Batch 43/64 loss: 0.263197124004364
Batch 44/64 loss: 0.26308727264404297
Batch 45/64 loss: 0.25886982679367065
Batch 46/64 loss: 0.26064813137054443
Batch 47/64 loss: 0.26278555393218994
Batch 48/64 loss: 0.25913071632385254
Batch 49/64 loss: 0.2740921378135681
Batch 50/64 loss: 0.2587491273880005
Batch 51/64 loss: 0.2652418613433838
Batch 52/64 loss: 0.2584207057952881
Batch 53/64 loss: 0.2561906576156616
Batch 54/64 loss: 0.27169346809387207
Batch 55/64 loss: 0.26713621616363525
Batch 56/64 loss: 0.269079327583313
Batch 57/64 loss: 0.2721788287162781
Batch 58/64 loss: 0.2641397714614868
Batch 59/64 loss: 0.2613452672958374
Batch 60/64 loss: 0.26035916805267334
Batch 61/64 loss: 0.25998950004577637
Batch 62/64 loss: 0.2643061876296997
Batch 63/64 loss: 0.2637532949447632
Batch 64/64 loss: 0.2557833790779114
Epoch 444  Train loss: 0.2622382956392625  Val loss: 0.31184461251976564
Epoch 445
-------------------------------
Batch 1/64 loss: 0.26073914766311646
Batch 2/64 loss: 0.268626868724823
Batch 3/64 loss: 0.267394483089447
Batch 4/64 loss: 0.2603450417518616
Batch 5/64 loss: 0.2608240842819214
Batch 6/64 loss: 0.26085495948791504
Batch 7/64 loss: 0.2547145485877991
Batch 8/64 loss: 0.2657337188720703
Batch 9/64 loss: 0.252987802028656
Batch 10/64 loss: 0.25912678241729736
Batch 11/64 loss: 0.2623249292373657
Batch 12/64 loss: 0.2603040933609009
Batch 13/64 loss: 0.25775599479675293
Batch 14/64 loss: 0.2674371004104614
Batch 15/64 loss: 0.2576014995574951
Batch 16/64 loss: 0.25500810146331787
Batch 17/64 loss: 0.2590278387069702
Batch 18/64 loss: 0.26255708932876587
Batch 19/64 loss: 0.2585688829421997
Batch 20/64 loss: 0.25625836849212646
Batch 21/64 loss: 0.26044100522994995
Batch 22/64 loss: 0.25852859020233154
Batch 23/64 loss: 0.2578813433647156
Batch 24/64 loss: 0.2568371891975403
Batch 25/64 loss: 0.26273441314697266
Batch 26/64 loss: 0.2636639475822449
Batch 27/64 loss: 0.25992560386657715
Batch 28/64 loss: 0.26293814182281494
Batch 29/64 loss: 0.2516132593154907
Batch 30/64 loss: 0.25512129068374634
Batch 31/64 loss: 0.26679742336273193
Batch 32/64 loss: 0.2615341544151306
Batch 33/64 loss: 0.26004189252853394
Batch 34/64 loss: 0.25611764192581177
Batch 35/64 loss: 0.2579195499420166
Batch 36/64 loss: 0.26985299587249756
Batch 37/64 loss: 0.26158857345581055
Batch 38/64 loss: 0.26073622703552246
Batch 39/64 loss: 0.25775933265686035
Batch 40/64 loss: 0.2603737711906433
Batch 41/64 loss: 0.2644544839859009
Batch 42/64 loss: 0.2605404853820801
Batch 43/64 loss: 0.259876012802124
Batch 44/64 loss: 0.2699291706085205
Batch 45/64 loss: 0.2654443383216858
Batch 46/64 loss: 0.25344210863113403
Batch 47/64 loss: 0.2688713073730469
Batch 48/64 loss: 0.26032352447509766
Batch 49/64 loss: 0.2612779140472412
Batch 50/64 loss: 0.264431357383728
Batch 51/64 loss: 0.2625344395637512
Batch 52/64 loss: 0.2660304307937622
Batch 53/64 loss: 0.27188175916671753
Batch 54/64 loss: 0.2571830749511719
Batch 55/64 loss: 0.2703592777252197
Batch 56/64 loss: 0.2610759735107422
Batch 57/64 loss: 0.26659345626831055
Batch 58/64 loss: 0.26306432485580444
Batch 59/64 loss: 0.26009881496429443
Batch 60/64 loss: 0.2661309242248535
Batch 61/64 loss: 0.2627550959587097
Batch 62/64 loss: 0.2638401985168457
Batch 63/64 loss: 0.2650502920150757
Batch 64/64 loss: 0.27566373348236084
Epoch 445  Train loss: 0.261686811727636  Val loss: 0.31283153701074345
Epoch 446
-------------------------------
Batch 1/64 loss: 0.26349377632141113
Batch 2/64 loss: 0.26046448945999146
Batch 3/64 loss: 0.26337307691574097
Batch 4/64 loss: 0.26370084285736084
Batch 5/64 loss: 0.2596142292022705
Batch 6/64 loss: 0.2570362091064453
Batch 7/64 loss: 0.2602890729904175
Batch 8/64 loss: 0.26493555307388306
Batch 9/64 loss: 0.2614006996154785
Batch 10/64 loss: 0.2583320140838623
Batch 11/64 loss: 0.26521313190460205
Batch 12/64 loss: 0.25686997175216675
Batch 13/64 loss: 0.2575640082359314
Batch 14/64 loss: 0.261987566947937
Batch 15/64 loss: 0.2570874094963074
Batch 16/64 loss: 0.25548678636550903
Batch 17/64 loss: 0.2527543306350708
Batch 18/64 loss: 0.2634909152984619
Batch 19/64 loss: 0.2568705081939697
Batch 20/64 loss: 0.25103557109832764
Batch 21/64 loss: 0.2609173059463501
Batch 22/64 loss: 0.25515133142471313
Batch 23/64 loss: 0.2656364440917969
Batch 24/64 loss: 0.26605701446533203
Batch 25/64 loss: 0.2565232515335083
Batch 26/64 loss: 0.2615690231323242
Batch 27/64 loss: 0.2611654996871948
Batch 28/64 loss: 0.2614895701408386
Batch 29/64 loss: 0.262302041053772
Batch 30/64 loss: 0.25757741928100586
Batch 31/64 loss: 0.2571294903755188
Batch 32/64 loss: 0.2636638879776001
Batch 33/64 loss: 0.26110410690307617
Batch 34/64 loss: 0.268455445766449
Batch 35/64 loss: 0.26338255405426025
Batch 36/64 loss: 0.2628347873687744
Batch 37/64 loss: 0.26106536388397217
Batch 38/64 loss: 0.2660810947418213
Batch 39/64 loss: 0.25934040546417236
Batch 40/64 loss: 0.2605486512184143
Batch 41/64 loss: 0.27100706100463867
Batch 42/64 loss: 0.26176929473876953
Batch 43/64 loss: 0.2622263431549072
Batch 44/64 loss: 0.2632104158401489
Batch 45/64 loss: 0.25765758752822876
Batch 46/64 loss: 0.25773340463638306
Batch 47/64 loss: 0.2654750347137451
Batch 48/64 loss: 0.2659192681312561
Batch 49/64 loss: 0.26363426446914673
Batch 50/64 loss: 0.25541675090789795
Batch 51/64 loss: 0.2619476318359375
Batch 52/64 loss: 0.25728535652160645
Batch 53/64 loss: 0.2639033794403076
Batch 54/64 loss: 0.2671234607696533
Batch 55/64 loss: 0.2624974250793457
Batch 56/64 loss: 0.26770126819610596
Batch 57/64 loss: 0.2588001489639282
Batch 58/64 loss: 0.2632235288619995
Batch 59/64 loss: 0.26612424850463867
Batch 60/64 loss: 0.2596176862716675
Batch 61/64 loss: 0.2613428831100464
Batch 62/64 loss: 0.2707780599594116
Batch 63/64 loss: 0.2567998170852661
Batch 64/64 loss: 0.2601594924926758
Epoch 446  Train loss: 0.26132249084173464  Val loss: 0.31225256739613116
Epoch 447
-------------------------------
Batch 1/64 loss: 0.2564605474472046
Batch 2/64 loss: 0.2646946310997009
Batch 3/64 loss: 0.26211440563201904
Batch 4/64 loss: 0.25153279304504395
Batch 5/64 loss: 0.26179349422454834
Batch 6/64 loss: 0.2628437280654907
Batch 7/64 loss: 0.2633165717124939
Batch 8/64 loss: 0.2551773190498352
Batch 9/64 loss: 0.26052576303482056
Batch 10/64 loss: 0.25403356552124023
Batch 11/64 loss: 0.2575944662094116
Batch 12/64 loss: 0.25689709186553955
Batch 13/64 loss: 0.25676608085632324
Batch 14/64 loss: 0.25826209783554077
Batch 15/64 loss: 0.25452929735183716
Batch 16/64 loss: 0.26866614818573
Batch 17/64 loss: 0.2653559446334839
Batch 18/64 loss: 0.26312851905822754
Batch 19/64 loss: 0.26235246658325195
Batch 20/64 loss: 0.2591850757598877
Batch 21/64 loss: 0.25616663694381714
Batch 22/64 loss: 0.2687785029411316
Batch 23/64 loss: 0.2651909589767456
Batch 24/64 loss: 0.25643301010131836
Batch 25/64 loss: 0.2563626170158386
Batch 26/64 loss: 0.2617416977882385
Batch 27/64 loss: 0.2586280107498169
Batch 28/64 loss: 0.26073598861694336
Batch 29/64 loss: 0.25494635105133057
Batch 30/64 loss: 0.2613677978515625
Batch 31/64 loss: 0.2621793746948242
Batch 32/64 loss: 0.2600041627883911
Batch 33/64 loss: 0.26074832677841187
Batch 34/64 loss: 0.25813400745391846
Batch 35/64 loss: 0.2529972791671753
Batch 36/64 loss: 0.2632783055305481
Batch 37/64 loss: 0.26681220531463623
Batch 38/64 loss: 0.26236212253570557
Batch 39/64 loss: 0.25924456119537354
Batch 40/64 loss: 0.2632105350494385
Batch 41/64 loss: 0.2576857805252075
Batch 42/64 loss: 0.2578461170196533
Batch 43/64 loss: 0.26921647787094116
Batch 44/64 loss: 0.2622753381729126
Batch 45/64 loss: 0.2631734013557434
Batch 46/64 loss: 0.25367963314056396
Batch 47/64 loss: 0.2612372636795044
Batch 48/64 loss: 0.26106488704681396
Batch 49/64 loss: 0.26362907886505127
Batch 50/64 loss: 0.26617515087127686
Batch 51/64 loss: 0.26130521297454834
Batch 52/64 loss: 0.2631882429122925
Batch 53/64 loss: 0.2611501216888428
Batch 54/64 loss: 0.2627730369567871
Batch 55/64 loss: 0.2620368003845215
Batch 56/64 loss: 0.25454485416412354
Batch 57/64 loss: 0.26630425453186035
Batch 58/64 loss: 0.27473515272140503
Batch 59/64 loss: 0.2639656066894531
Batch 60/64 loss: 0.2669614553451538
Batch 61/64 loss: 0.2597157955169678
Batch 62/64 loss: 0.26164209842681885
Batch 63/64 loss: 0.25856447219848633
Batch 64/64 loss: 0.26645421981811523
Epoch 447  Train loss: 0.2609766801198324  Val loss: 0.3123286237421724
Epoch 448
-------------------------------
Batch 1/64 loss: 0.25601959228515625
Batch 2/64 loss: 0.260270357131958
Batch 3/64 loss: 0.25353336334228516
Batch 4/64 loss: 0.264573335647583
Batch 5/64 loss: 0.26533347368240356
Batch 6/64 loss: 0.25538235902786255
Batch 7/64 loss: 0.2596784830093384
Batch 8/64 loss: 0.25274693965911865
Batch 9/64 loss: 0.2625111937522888
Batch 10/64 loss: 0.25565826892852783
Batch 11/64 loss: 0.26255810260772705
Batch 12/64 loss: 0.25911784172058105
Batch 13/64 loss: 0.2628040909767151
Batch 14/64 loss: 0.26665443181991577
Batch 15/64 loss: 0.26282787322998047
Batch 16/64 loss: 0.2598295211791992
Batch 17/64 loss: 0.2519545555114746
Batch 18/64 loss: 0.2712278366088867
Batch 19/64 loss: 0.2684842348098755
Batch 20/64 loss: 0.2590917944908142
Batch 21/64 loss: 0.25395774841308594
Batch 22/64 loss: 0.25654828548431396
Batch 23/64 loss: 0.26652878522872925
Batch 24/64 loss: 0.25785523653030396
Batch 25/64 loss: 0.27091044187545776
Batch 26/64 loss: 0.26102274656295776
Batch 27/64 loss: 0.2579476237297058
Batch 28/64 loss: 0.26081061363220215
Batch 29/64 loss: 0.2599771022796631
Batch 30/64 loss: 0.26028740406036377
Batch 31/64 loss: 0.2580870985984802
Batch 32/64 loss: 0.2607869505882263
Batch 33/64 loss: 0.2735326886177063
Batch 34/64 loss: 0.26424336433410645
Batch 35/64 loss: 0.2603887915611267
Batch 36/64 loss: 0.2615088224411011
Batch 37/64 loss: 0.26221418380737305
Batch 38/64 loss: 0.26443105936050415
Batch 39/64 loss: 0.2631721496582031
Batch 40/64 loss: 0.2606505751609802
Batch 41/64 loss: 0.2635590434074402
Batch 42/64 loss: 0.2577294707298279
Batch 43/64 loss: 0.2715269923210144
Batch 44/64 loss: 0.26287341117858887
Batch 45/64 loss: 0.2685660719871521
Batch 46/64 loss: 0.2662689685821533
Batch 47/64 loss: 0.2589319348335266
Batch 48/64 loss: 0.259438157081604
Batch 49/64 loss: 0.2629666328430176
Batch 50/64 loss: 0.2638000249862671
Batch 51/64 loss: 0.26811182498931885
Batch 52/64 loss: 0.26017993688583374
Batch 53/64 loss: 0.26394134759902954
Batch 54/64 loss: 0.257426381111145
Batch 55/64 loss: 0.2617853879928589
Batch 56/64 loss: 0.2564195394515991
Batch 57/64 loss: 0.2626681327819824
Batch 58/64 loss: 0.2594032287597656
Batch 59/64 loss: 0.2536352872848511
Batch 60/64 loss: 0.2567819356918335
Batch 61/64 loss: 0.26853471994400024
Batch 62/64 loss: 0.26435625553131104
Batch 63/64 loss: 0.2641819715499878
Batch 64/64 loss: 0.2569170594215393
Epoch 448  Train loss: 0.2615042160539066  Val loss: 0.3122396436343898
Epoch 449
-------------------------------
Batch 1/64 loss: 0.2620919942855835
Batch 2/64 loss: 0.2516271471977234
Batch 3/64 loss: 0.26476848125457764
Batch 4/64 loss: 0.25919437408447266
Batch 5/64 loss: 0.2572084069252014
Batch 6/64 loss: 0.2593954801559448
Batch 7/64 loss: 0.25915253162384033
Batch 8/64 loss: 0.25559234619140625
Batch 9/64 loss: 0.26272130012512207
Batch 10/64 loss: 0.25982940196990967
Batch 11/64 loss: 0.25945860147476196
Batch 12/64 loss: 0.2611355781555176
Batch 13/64 loss: 0.25782322883605957
Batch 14/64 loss: 0.2611757516860962
Batch 15/64 loss: 0.26540815830230713
Batch 16/64 loss: 0.2617100477218628
Batch 17/64 loss: 0.26375406980514526
Batch 18/64 loss: 0.2567029595375061
Batch 19/64 loss: 0.2566922903060913
Batch 20/64 loss: 0.2614050507545471
Batch 21/64 loss: 0.2626532316207886
Batch 22/64 loss: 0.25437217950820923
Batch 23/64 loss: 0.26330310106277466
Batch 24/64 loss: 0.2788776755332947
Batch 25/64 loss: 0.25432687997817993
Batch 26/64 loss: 0.2650371789932251
Batch 27/64 loss: 0.25676894187927246
Batch 28/64 loss: 0.2753716707229614
Batch 29/64 loss: 0.2603153586387634
Batch 30/64 loss: 0.26532846689224243
Batch 31/64 loss: 0.2601783275604248
Batch 32/64 loss: 0.2572571039199829
Batch 33/64 loss: 0.256486177444458
Batch 34/64 loss: 0.26490795612335205
Batch 35/64 loss: 0.268887996673584
Batch 36/64 loss: 0.25613558292388916
Batch 37/64 loss: 0.26197898387908936
Batch 38/64 loss: 0.25502729415893555
Batch 39/64 loss: 0.2651866674423218
Batch 40/64 loss: 0.2636570930480957
Batch 41/64 loss: 0.2621103525161743
Batch 42/64 loss: 0.2612419128417969
Batch 43/64 loss: 0.2642495632171631
Batch 44/64 loss: 0.26371508836746216
Batch 45/64 loss: 0.259474515914917
Batch 46/64 loss: 0.2637465000152588
Batch 47/64 loss: 0.260816752910614
Batch 48/64 loss: 0.2588917016983032
Batch 49/64 loss: 0.2664306163787842
Batch 50/64 loss: 0.2565518617630005
Batch 51/64 loss: 0.26067793369293213
Batch 52/64 loss: 0.2596776485443115
Batch 53/64 loss: 0.2621588110923767
Batch 54/64 loss: 0.272305428981781
Batch 55/64 loss: 0.26096653938293457
Batch 56/64 loss: 0.25770556926727295
Batch 57/64 loss: 0.2625192403793335
Batch 58/64 loss: 0.2579307556152344
Batch 59/64 loss: 0.2599015235900879
Batch 60/64 loss: 0.26324141025543213
Batch 61/64 loss: 0.2642696499824524
Batch 62/64 loss: 0.2634490728378296
Batch 63/64 loss: 0.25884443521499634
Batch 64/64 loss: 0.2654315233230591
Epoch 449  Train loss: 0.2613781269858865  Val loss: 0.3126775577305928
Epoch 450
-------------------------------
Batch 1/64 loss: 0.25262486934661865
Batch 2/64 loss: 0.2629997730255127
Batch 3/64 loss: 0.2527438998222351
Batch 4/64 loss: 0.25535261631011963
Batch 5/64 loss: 0.26035076379776
Batch 6/64 loss: 0.2577987313270569
Batch 7/64 loss: 0.25878584384918213
Batch 8/64 loss: 0.25593286752700806
Batch 9/64 loss: 0.26438820362091064
Batch 10/64 loss: 0.2614709138870239
Batch 11/64 loss: 0.25821155309677124
Batch 12/64 loss: 0.2639487385749817
Batch 13/64 loss: 0.2583392858505249
Batch 14/64 loss: 0.2569587826728821
Batch 15/64 loss: 0.2544252872467041
Batch 16/64 loss: 0.25374913215637207
Batch 17/64 loss: 0.2642616033554077
Batch 18/64 loss: 0.2725958824157715
Batch 19/64 loss: 0.2630453109741211
Batch 20/64 loss: 0.258983850479126
Batch 21/64 loss: 0.2637366056442261
Batch 22/64 loss: 0.25797200202941895
Batch 23/64 loss: 0.2557891607284546
Batch 24/64 loss: 0.262347936630249
Batch 25/64 loss: 0.257778525352478
Batch 26/64 loss: 0.2755579948425293
Batch 27/64 loss: 0.2595505714416504
Batch 28/64 loss: 0.2614310383796692
Batch 29/64 loss: 0.2596380114555359
Batch 30/64 loss: 0.266033411026001
Batch 31/64 loss: 0.2626103162765503
Batch 32/64 loss: 0.26238203048706055
Batch 33/64 loss: 0.2590269446372986
Batch 34/64 loss: 0.2595061659812927
Batch 35/64 loss: 0.26570916175842285
Batch 36/64 loss: 0.263907790184021
Batch 37/64 loss: 0.2610968351364136
Batch 38/64 loss: 0.26470720767974854
Batch 39/64 loss: 0.26222312450408936
Batch 40/64 loss: 0.2691965103149414
Batch 41/64 loss: 0.2755730152130127
Batch 42/64 loss: 0.27009332180023193
Batch 43/64 loss: 0.2606045603752136
Batch 44/64 loss: 0.2658735513687134
Batch 45/64 loss: 0.26016175746917725
Batch 46/64 loss: 0.2684289813041687
Batch 47/64 loss: 0.2585721015930176
Batch 48/64 loss: 0.26682162284851074
Batch 49/64 loss: 0.259468138217926
Batch 50/64 loss: 0.2631990909576416
Batch 51/64 loss: 0.26029300689697266
Batch 52/64 loss: 0.2560173273086548
Batch 53/64 loss: 0.2598819136619568
Batch 54/64 loss: 0.2615046501159668
Batch 55/64 loss: 0.25786054134368896
Batch 56/64 loss: 0.25861310958862305
Batch 57/64 loss: 0.26352667808532715
Batch 58/64 loss: 0.27064573764801025
Batch 59/64 loss: 0.2621026039123535
Batch 60/64 loss: 0.262972891330719
Batch 61/64 loss: 0.26930153369903564
Batch 62/64 loss: 0.26223206520080566
Batch 63/64 loss: 0.2613418698310852
Batch 64/64 loss: 0.2649725675582886
Epoch 450  Train loss: 0.26181943136103014  Val loss: 0.31313026811658723
Epoch 451
-------------------------------
Batch 1/64 loss: 0.2637597322463989
Batch 2/64 loss: 0.26107949018478394
Batch 3/64 loss: 0.25747203826904297
Batch 4/64 loss: 0.2616126537322998
Batch 5/64 loss: 0.26670801639556885
Batch 6/64 loss: 0.25742262601852417
Batch 7/64 loss: 0.25999146699905396
Batch 8/64 loss: 0.2580849528312683
Batch 9/64 loss: 0.26102912425994873
Batch 10/64 loss: 0.2650144696235657
Batch 11/64 loss: 0.2628447413444519
Batch 12/64 loss: 0.2620466351509094
Batch 13/64 loss: 0.2593104839324951
Batch 14/64 loss: 0.25774019956588745
Batch 15/64 loss: 0.25454437732696533
Batch 16/64 loss: 0.25792503356933594
Batch 17/64 loss: 0.27163779735565186
Batch 18/64 loss: 0.255332350730896
Batch 19/64 loss: 0.2628602981567383
Batch 20/64 loss: 0.2637190818786621
Batch 21/64 loss: 0.2578394412994385
Batch 22/64 loss: 0.26082950830459595
Batch 23/64 loss: 0.25888943672180176
Batch 24/64 loss: 0.25965631008148193
Batch 25/64 loss: 0.2631009817123413
Batch 26/64 loss: 0.2623758316040039
Batch 27/64 loss: 0.26191580295562744
Batch 28/64 loss: 0.2601262331008911
Batch 29/64 loss: 0.2603421211242676
Batch 30/64 loss: 0.26160728931427
Batch 31/64 loss: 0.26125746965408325
Batch 32/64 loss: 0.2578166723251343
Batch 33/64 loss: 0.25915026664733887
Batch 34/64 loss: 0.26182281970977783
Batch 35/64 loss: 0.2576003074645996
Batch 36/64 loss: 0.27480649948120117
Batch 37/64 loss: 0.2686939239501953
Batch 38/64 loss: 0.25751638412475586
Batch 39/64 loss: 0.26974016427993774
Batch 40/64 loss: 0.2689414620399475
Batch 41/64 loss: 0.26585644483566284
Batch 42/64 loss: 0.2647082805633545
Batch 43/64 loss: 0.27339524030685425
Batch 44/64 loss: 0.26186347007751465
Batch 45/64 loss: 0.2612764835357666
Batch 46/64 loss: 0.25921630859375
Batch 47/64 loss: 0.2560774087905884
Batch 48/64 loss: 0.26353901624679565
Batch 49/64 loss: 0.26961302757263184
Batch 50/64 loss: 0.26196926832199097
Batch 51/64 loss: 0.2697763442993164
Batch 52/64 loss: 0.26613616943359375
Batch 53/64 loss: 0.2585737705230713
Batch 54/64 loss: 0.2653796672821045
Batch 55/64 loss: 0.26017236709594727
Batch 56/64 loss: 0.2601562738418579
Batch 57/64 loss: 0.26344287395477295
Batch 58/64 loss: 0.262504518032074
Batch 59/64 loss: 0.26042407751083374
Batch 60/64 loss: 0.2592005133628845
Batch 61/64 loss: 0.25544995069503784
Batch 62/64 loss: 0.25814497470855713
Batch 63/64 loss: 0.26989424228668213
Batch 64/64 loss: 0.26989173889160156
Epoch 451  Train loss: 0.26217025869032917  Val loss: 0.312624478872699
Epoch 452
-------------------------------
Batch 1/64 loss: 0.26555144786834717
Batch 2/64 loss: 0.25601232051849365
Batch 3/64 loss: 0.26593875885009766
Batch 4/64 loss: 0.2517136335372925
Batch 5/64 loss: 0.2583274841308594
Batch 6/64 loss: 0.2551901340484619
Batch 7/64 loss: 0.26087474822998047
Batch 8/64 loss: 0.25964510440826416
Batch 9/64 loss: 0.27247893810272217
Batch 10/64 loss: 0.2555506229400635
Batch 11/64 loss: 0.2544820308685303
Batch 12/64 loss: 0.25812608003616333
Batch 13/64 loss: 0.26811397075653076
Batch 14/64 loss: 0.259723424911499
Batch 15/64 loss: 0.2595336437225342
Batch 16/64 loss: 0.2566487193107605
Batch 17/64 loss: 0.2584402561187744
Batch 18/64 loss: 0.2597736120223999
Batch 19/64 loss: 0.25860893726348877
Batch 20/64 loss: 0.2590426206588745
Batch 21/64 loss: 0.2730536460876465
Batch 22/64 loss: 0.2621093988418579
Batch 23/64 loss: 0.26953768730163574
Batch 24/64 loss: 0.26460617780685425
Batch 25/64 loss: 0.2572507858276367
Batch 26/64 loss: 0.2626161575317383
Batch 27/64 loss: 0.2602444887161255
Batch 28/64 loss: 0.25610411167144775
Batch 29/64 loss: 0.26279008388519287
Batch 30/64 loss: 0.2589118480682373
Batch 31/64 loss: 0.2621791362762451
Batch 32/64 loss: 0.26859617233276367
Batch 33/64 loss: 0.25951939821243286
Batch 34/64 loss: 0.2512580156326294
Batch 35/64 loss: 0.2649684548377991
Batch 36/64 loss: 0.259471595287323
Batch 37/64 loss: 0.2610975503921509
Batch 38/64 loss: 0.25702470541000366
Batch 39/64 loss: 0.25866854190826416
Batch 40/64 loss: 0.2611197233200073
Batch 41/64 loss: 0.26406383514404297
Batch 42/64 loss: 0.2588691711425781
Batch 43/64 loss: 0.2611328959465027
Batch 44/64 loss: 0.2645832300186157
Batch 45/64 loss: 0.26288503408432007
Batch 46/64 loss: 0.26027119159698486
Batch 47/64 loss: 0.26333582401275635
Batch 48/64 loss: 0.27237188816070557
Batch 49/64 loss: 0.25972115993499756
Batch 50/64 loss: 0.2586331367492676
Batch 51/64 loss: 0.25920820236206055
Batch 52/64 loss: 0.2591942548751831
Batch 53/64 loss: 0.2632136344909668
Batch 54/64 loss: 0.2617110013961792
Batch 55/64 loss: 0.26323533058166504
Batch 56/64 loss: 0.2571011781692505
Batch 57/64 loss: 0.2605164051055908
Batch 58/64 loss: 0.27057361602783203
Batch 59/64 loss: 0.259135365486145
Batch 60/64 loss: 0.2634291648864746
Batch 61/64 loss: 0.2757568955421448
Batch 62/64 loss: 0.25676846504211426
Batch 63/64 loss: 0.2634429335594177
Batch 64/64 loss: 0.26639246940612793
Epoch 452  Train loss: 0.2613937621023141  Val loss: 0.31275256126607
Epoch 453
-------------------------------
Batch 1/64 loss: 0.2589796781539917
Batch 2/64 loss: 0.25451725721359253
Batch 3/64 loss: 0.2623876929283142
Batch 4/64 loss: 0.26313042640686035
Batch 5/64 loss: 0.2624223232269287
Batch 6/64 loss: 0.258306622505188
Batch 7/64 loss: 0.26587235927581787
Batch 8/64 loss: 0.2581065893173218
Batch 9/64 loss: 0.2601875066757202
Batch 10/64 loss: 0.26228171586990356
Batch 11/64 loss: 0.2591400146484375
Batch 12/64 loss: 0.26035356521606445
Batch 13/64 loss: 0.2577449083328247
Batch 14/64 loss: 0.2620868682861328
Batch 15/64 loss: 0.26156747341156006
Batch 16/64 loss: 0.26430726051330566
Batch 17/64 loss: 0.2547328472137451
Batch 18/64 loss: 0.25927257537841797
Batch 19/64 loss: 0.25788044929504395
Batch 20/64 loss: 0.2652384042739868
Batch 21/64 loss: 0.26452529430389404
Batch 22/64 loss: 0.2631753087043762
Batch 23/64 loss: 0.26259487867355347
Batch 24/64 loss: 0.25714874267578125
Batch 25/64 loss: 0.26533401012420654
Batch 26/64 loss: 0.25734788179397583
Batch 27/64 loss: 0.2666128873825073
Batch 28/64 loss: 0.262654185295105
Batch 29/64 loss: 0.2637671232223511
Batch 30/64 loss: 0.26529961824417114
Batch 31/64 loss: 0.26274996995925903
Batch 32/64 loss: 0.26027458906173706
Batch 33/64 loss: 0.2617396116256714
Batch 34/64 loss: 0.2662373185157776
Batch 35/64 loss: 0.2615091800689697
Batch 36/64 loss: 0.2660142779350281
Batch 37/64 loss: 0.25924551486968994
Batch 38/64 loss: 0.2666478753089905
Batch 39/64 loss: 0.26618492603302
Batch 40/64 loss: 0.2586372494697571
Batch 41/64 loss: 0.2686294913291931
Batch 42/64 loss: 0.2586475610733032
Batch 43/64 loss: 0.26435887813568115
Batch 44/64 loss: 0.26560062170028687
Batch 45/64 loss: 0.2539886236190796
Batch 46/64 loss: 0.25997549295425415
Batch 47/64 loss: 0.25640666484832764
Batch 48/64 loss: 0.2638853192329407
Batch 49/64 loss: 0.25968754291534424
Batch 50/64 loss: 0.2708740234375
Batch 51/64 loss: 0.2506706714630127
Batch 52/64 loss: 0.25643855333328247
Batch 53/64 loss: 0.2652934193611145
Batch 54/64 loss: 0.2629808783531189
Batch 55/64 loss: 0.2642524242401123
Batch 56/64 loss: 0.2649726867675781
Batch 57/64 loss: 0.2672007083892822
Batch 58/64 loss: 0.2616235017776489
Batch 59/64 loss: 0.2635663151741028
Batch 60/64 loss: 0.2619096040725708
Batch 61/64 loss: 0.2569950819015503
Batch 62/64 loss: 0.2607308030128479
Batch 63/64 loss: 0.26167190074920654
Batch 64/64 loss: 0.2721827030181885
Epoch 453  Train loss: 0.26181513374926996  Val loss: 0.3131244629109438
Epoch 454
-------------------------------
Batch 1/64 loss: 0.2589597702026367
Batch 2/64 loss: 0.2580462098121643
Batch 3/64 loss: 0.2676982879638672
Batch 4/64 loss: 0.26600950956344604
Batch 5/64 loss: 0.2553849220275879
Batch 6/64 loss: 0.25897616147994995
Batch 7/64 loss: 0.2596457600593567
Batch 8/64 loss: 0.25750935077667236
Batch 9/64 loss: 0.2629571557044983
Batch 10/64 loss: 0.25808727741241455
Batch 11/64 loss: 0.25776052474975586
Batch 12/64 loss: 0.2597590684890747
Batch 13/64 loss: 0.26085495948791504
Batch 14/64 loss: 0.2563737630844116
Batch 15/64 loss: 0.25691771507263184
Batch 16/64 loss: 0.255703866481781
Batch 17/64 loss: 0.2573051452636719
Batch 18/64 loss: 0.25433290004730225
Batch 19/64 loss: 0.26107561588287354
Batch 20/64 loss: 0.255435049533844
Batch 21/64 loss: 0.25929152965545654
Batch 22/64 loss: 0.2626302242279053
Batch 23/64 loss: 0.25595760345458984
Batch 24/64 loss: 0.25822699069976807
Batch 25/64 loss: 0.25974035263061523
Batch 26/64 loss: 0.269869863986969
Batch 27/64 loss: 0.2658454179763794
Batch 28/64 loss: 0.25511103868484497
Batch 29/64 loss: 0.2527287006378174
Batch 30/64 loss: 0.26887524127960205
Batch 31/64 loss: 0.2655937075614929
Batch 32/64 loss: 0.2586338520050049
Batch 33/64 loss: 0.25165051221847534
Batch 34/64 loss: 0.25921159982681274
Batch 35/64 loss: 0.2544351816177368
Batch 36/64 loss: 0.25727373361587524
Batch 37/64 loss: 0.26943695545196533
Batch 38/64 loss: 0.2609333395957947
Batch 39/64 loss: 0.2642251253128052
Batch 40/64 loss: 0.26548075675964355
Batch 41/64 loss: 0.26407480239868164
Batch 42/64 loss: 0.26746922731399536
Batch 43/64 loss: 0.2769291400909424
Batch 44/64 loss: 0.2703186273574829
Batch 45/64 loss: 0.26667654514312744
Batch 46/64 loss: 0.26709556579589844
Batch 47/64 loss: 0.2638511657714844
Batch 48/64 loss: 0.26885563135147095
Batch 49/64 loss: 0.26470112800598145
Batch 50/64 loss: 0.26508063077926636
Batch 51/64 loss: 0.26484835147857666
Batch 52/64 loss: 0.2633100748062134
Batch 53/64 loss: 0.2627362608909607
Batch 54/64 loss: 0.2605621814727783
Batch 55/64 loss: 0.26440155506134033
Batch 56/64 loss: 0.27323418855667114
Batch 57/64 loss: 0.2548447251319885
Batch 58/64 loss: 0.26233363151550293
Batch 59/64 loss: 0.25754719972610474
Batch 60/64 loss: 0.25588154792785645
Batch 61/64 loss: 0.25505971908569336
Batch 62/64 loss: 0.26098012924194336
Batch 63/64 loss: 0.25641995668411255
Batch 64/64 loss: 0.26926982402801514
Epoch 454  Train loss: 0.26138210343379603  Val loss: 0.31256757282309516
Epoch 455
-------------------------------
Batch 1/64 loss: 0.25710904598236084
Batch 2/64 loss: 0.2676597237586975
Batch 3/64 loss: 0.2658270597457886
Batch 4/64 loss: 0.2618033289909363
Batch 5/64 loss: 0.25660496950149536
Batch 6/64 loss: 0.25877445936203003
Batch 7/64 loss: 0.25888657569885254
Batch 8/64 loss: 0.26903998851776123
Batch 9/64 loss: 0.26202547550201416
Batch 10/64 loss: 0.26294171810150146
Batch 11/64 loss: 0.2651485204696655
Batch 12/64 loss: 0.25844883918762207
Batch 13/64 loss: 0.26409459114074707
Batch 14/64 loss: 0.25837528705596924
Batch 15/64 loss: 0.2579130530357361
Batch 16/64 loss: 0.2530548572540283
Batch 17/64 loss: 0.2630770206451416
Batch 18/64 loss: 0.25820112228393555
Batch 19/64 loss: 0.26111793518066406
Batch 20/64 loss: 0.26493221521377563
Batch 21/64 loss: 0.2552955150604248
Batch 22/64 loss: 0.2722541093826294
Batch 23/64 loss: 0.26251113414764404
Batch 24/64 loss: 0.26408278942108154
Batch 25/64 loss: 0.26451992988586426
Batch 26/64 loss: 0.2626010775566101
Batch 27/64 loss: 0.2578113079071045
Batch 28/64 loss: 0.25812309980392456
Batch 29/64 loss: 0.25863444805145264
Batch 30/64 loss: 0.25894051790237427
Batch 31/64 loss: 0.252821683883667
Batch 32/64 loss: 0.2615926265716553
Batch 33/64 loss: 0.25305402278900146
Batch 34/64 loss: 0.26177072525024414
Batch 35/64 loss: 0.25601446628570557
Batch 36/64 loss: 0.26226168870925903
Batch 37/64 loss: 0.26438069343566895
Batch 38/64 loss: 0.2604525685310364
Batch 39/64 loss: 0.2601124048233032
Batch 40/64 loss: 0.2598024010658264
Batch 41/64 loss: 0.2678467035293579
Batch 42/64 loss: 0.26406335830688477
Batch 43/64 loss: 0.25562334060668945
Batch 44/64 loss: 0.261374831199646
Batch 45/64 loss: 0.25699305534362793
Batch 46/64 loss: 0.260237455368042
Batch 47/64 loss: 0.2545408010482788
Batch 48/64 loss: 0.25854432582855225
Batch 49/64 loss: 0.2607495188713074
Batch 50/64 loss: 0.27207857370376587
Batch 51/64 loss: 0.26052379608154297
Batch 52/64 loss: 0.2609700560569763
Batch 53/64 loss: 0.2664583921432495
Batch 54/64 loss: 0.2667473554611206
Batch 55/64 loss: 0.2616819143295288
Batch 56/64 loss: 0.25669705867767334
Batch 57/64 loss: 0.2581336498260498
Batch 58/64 loss: 0.252754807472229
Batch 59/64 loss: 0.26221537590026855
Batch 60/64 loss: 0.27075517177581787
Batch 61/64 loss: 0.2592322826385498
Batch 62/64 loss: 0.2586650848388672
Batch 63/64 loss: 0.26544541120529175
Batch 64/64 loss: 0.26417016983032227
Epoch 455  Train loss: 0.26105934030869427  Val loss: 0.3125338132438791
Epoch 456
-------------------------------
Batch 1/64 loss: 0.2609657049179077
Batch 2/64 loss: 0.2581150531768799
Batch 3/64 loss: 0.25999540090560913
Batch 4/64 loss: 0.25562959909439087
Batch 5/64 loss: 0.2673299312591553
Batch 6/64 loss: 0.25663697719573975
Batch 7/64 loss: 0.2572025656700134
Batch 8/64 loss: 0.259615421295166
Batch 9/64 loss: 0.2567785978317261
Batch 10/64 loss: 0.26548629999160767
Batch 11/64 loss: 0.2536904811859131
Batch 12/64 loss: 0.268000066280365
Batch 13/64 loss: 0.26456522941589355
Batch 14/64 loss: 0.2593960762023926
Batch 15/64 loss: 0.2626461386680603
Batch 16/64 loss: 0.2580857276916504
Batch 17/64 loss: 0.2613023519515991
Batch 18/64 loss: 0.2578026056289673
Batch 19/64 loss: 0.2580062747001648
Batch 20/64 loss: 0.26326656341552734
Batch 21/64 loss: 0.270227313041687
Batch 22/64 loss: 0.25360530614852905
Batch 23/64 loss: 0.26022928953170776
Batch 24/64 loss: 0.256361722946167
Batch 25/64 loss: 0.2526858448982239
Batch 26/64 loss: 0.2615979313850403
Batch 27/64 loss: 0.25982213020324707
Batch 28/64 loss: 0.26126861572265625
Batch 29/64 loss: 0.25993287563323975
Batch 30/64 loss: 0.27656078338623047
Batch 31/64 loss: 0.2669481635093689
Batch 32/64 loss: 0.26687461137771606
Batch 33/64 loss: 0.2613859176635742
Batch 34/64 loss: 0.2610572576522827
Batch 35/64 loss: 0.25650554895401
Batch 36/64 loss: 0.26455098390579224
Batch 37/64 loss: 0.266790509223938
Batch 38/64 loss: 0.2585963010787964
Batch 39/64 loss: 0.26318252086639404
Batch 40/64 loss: 0.2622596025466919
Batch 41/64 loss: 0.26537346839904785
Batch 42/64 loss: 0.2625539302825928
Batch 43/64 loss: 0.26101499795913696
Batch 44/64 loss: 0.2627721428871155
Batch 45/64 loss: 0.2561851143836975
Batch 46/64 loss: 0.25851017236709595
Batch 47/64 loss: 0.2617626190185547
Batch 48/64 loss: 0.258184552192688
Batch 49/64 loss: 0.27056097984313965
Batch 50/64 loss: 0.25994908809661865
Batch 51/64 loss: 0.25859659910202026
Batch 52/64 loss: 0.2587347626686096
Batch 53/64 loss: 0.26087653636932373
Batch 54/64 loss: 0.2563853859901428
Batch 55/64 loss: 0.2659587860107422
Batch 56/64 loss: 0.2618436813354492
Batch 57/64 loss: 0.2630918025970459
Batch 58/64 loss: 0.25800079107284546
Batch 59/64 loss: 0.25396835803985596
Batch 60/64 loss: 0.25467753410339355
Batch 61/64 loss: 0.2676793932914734
Batch 62/64 loss: 0.26178574562072754
Batch 63/64 loss: 0.253865122795105
Batch 64/64 loss: 0.2593916058540344
Epoch 456  Train loss: 0.2608915382740544  Val loss: 0.3121817337278648
Epoch 457
-------------------------------
Batch 1/64 loss: 0.2605912685394287
Batch 2/64 loss: 0.25969207286834717
Batch 3/64 loss: 0.2603102922439575
Batch 4/64 loss: 0.2579568028450012
Batch 5/64 loss: 0.2577265501022339
Batch 6/64 loss: 0.2611122131347656
Batch 7/64 loss: 0.26427972316741943
Batch 8/64 loss: 0.26533031463623047
Batch 9/64 loss: 0.25809627771377563
Batch 10/64 loss: 0.26107341051101685
Batch 11/64 loss: 0.26451826095581055
Batch 12/64 loss: 0.25824832916259766
Batch 13/64 loss: 0.26839423179626465
Batch 14/64 loss: 0.260736346244812
Batch 15/64 loss: 0.26950109004974365
Batch 16/64 loss: 0.26783764362335205
Batch 17/64 loss: 0.25930237770080566
Batch 18/64 loss: 0.26262545585632324
Batch 19/64 loss: 0.26221269369125366
Batch 20/64 loss: 0.25913310050964355
Batch 21/64 loss: 0.26183056831359863
Batch 22/64 loss: 0.2583957314491272
Batch 23/64 loss: 0.25938624143600464
Batch 24/64 loss: 0.2551915645599365
Batch 25/64 loss: 0.25924086570739746
Batch 26/64 loss: 0.2544063329696655
Batch 27/64 loss: 0.2584567070007324
Batch 28/64 loss: 0.2567771077156067
Batch 29/64 loss: 0.2610882520675659
Batch 30/64 loss: 0.2615410089492798
Batch 31/64 loss: 0.2660428285598755
Batch 32/64 loss: 0.2559487223625183
Batch 33/64 loss: 0.2598899006843567
Batch 34/64 loss: 0.26126062870025635
Batch 35/64 loss: 0.2619062662124634
Batch 36/64 loss: 0.26327013969421387
Batch 37/64 loss: 0.26018762588500977
Batch 38/64 loss: 0.25821739435195923
Batch 39/64 loss: 0.2615675926208496
Batch 40/64 loss: 0.25271767377853394
Batch 41/64 loss: 0.26333707571029663
Batch 42/64 loss: 0.2650066614151001
Batch 43/64 loss: 0.2712438106536865
Batch 44/64 loss: 0.26117652654647827
Batch 45/64 loss: 0.2591155767440796
Batch 46/64 loss: 0.26118719577789307
Batch 47/64 loss: 0.2588832378387451
Batch 48/64 loss: 0.25473475456237793
Batch 49/64 loss: 0.2552802562713623
Batch 50/64 loss: 0.255920946598053
Batch 51/64 loss: 0.25610071420669556
Batch 52/64 loss: 0.261760950088501
Batch 53/64 loss: 0.27112555503845215
Batch 54/64 loss: 0.26107341051101685
Batch 55/64 loss: 0.25574755668640137
Batch 56/64 loss: 0.2788194417953491
Batch 57/64 loss: 0.26215672492980957
Batch 58/64 loss: 0.2600269317626953
Batch 59/64 loss: 0.25910282135009766
Batch 60/64 loss: 0.2665560841560364
Batch 61/64 loss: 0.26607656478881836
Batch 62/64 loss: 0.2583385705947876
Batch 63/64 loss: 0.2597835063934326
Batch 64/64 loss: 0.2552114725112915
Epoch 457  Train loss: 0.2610190601909862  Val loss: 0.3127205730303866
Epoch 458
-------------------------------
Batch 1/64 loss: 0.256980299949646
Batch 2/64 loss: 0.2552837133407593
Batch 3/64 loss: 0.26492393016815186
Batch 4/64 loss: 0.2536020278930664
Batch 5/64 loss: 0.25939691066741943
Batch 6/64 loss: 0.2556499242782593
Batch 7/64 loss: 0.26121747493743896
Batch 8/64 loss: 0.2630956172943115
Batch 9/64 loss: 0.2580149173736572
Batch 10/64 loss: 0.2653416395187378
Batch 11/64 loss: 0.2590380907058716
Batch 12/64 loss: 0.2616196870803833
Batch 13/64 loss: 0.2629280090332031
Batch 14/64 loss: 0.2559032440185547
Batch 15/64 loss: 0.25617480278015137
Batch 16/64 loss: 0.2581290006637573
Batch 17/64 loss: 0.25326740741729736
Batch 18/64 loss: 0.2673053741455078
Batch 19/64 loss: 0.2612258791923523
Batch 20/64 loss: 0.2588900923728943
Batch 21/64 loss: 0.2594226598739624
Batch 22/64 loss: 0.26023316383361816
Batch 23/64 loss: 0.2624853849411011
Batch 24/64 loss: 0.2520633935928345
Batch 25/64 loss: 0.262178897857666
Batch 26/64 loss: 0.26014626026153564
Batch 27/64 loss: 0.26017647981643677
Batch 28/64 loss: 0.2574276328086853
Batch 29/64 loss: 0.264518141746521
Batch 30/64 loss: 0.2630349397659302
Batch 31/64 loss: 0.2723647356033325
Batch 32/64 loss: 0.2607496976852417
Batch 33/64 loss: 0.25917190313339233
Batch 34/64 loss: 0.2555972933769226
Batch 35/64 loss: 0.2700091004371643
Batch 36/64 loss: 0.26682066917419434
Batch 37/64 loss: 0.2621833086013794
Batch 38/64 loss: 0.2558377981185913
Batch 39/64 loss: 0.2560495138168335
Batch 40/64 loss: 0.2566649317741394
Batch 41/64 loss: 0.25851744413375854
Batch 42/64 loss: 0.25862258672714233
Batch 43/64 loss: 0.26056158542633057
Batch 44/64 loss: 0.26416462659835815
Batch 45/64 loss: 0.26464569568634033
Batch 46/64 loss: 0.2619248628616333
Batch 47/64 loss: 0.2631955146789551
Batch 48/64 loss: 0.2554645538330078
Batch 49/64 loss: 0.2554495334625244
Batch 50/64 loss: 0.2619854211807251
Batch 51/64 loss: 0.25711584091186523
Batch 52/64 loss: 0.26017051935195923
Batch 53/64 loss: 0.260769784450531
Batch 54/64 loss: 0.2593846321105957
Batch 55/64 loss: 0.25394517183303833
Batch 56/64 loss: 0.25380682945251465
Batch 57/64 loss: 0.26204943656921387
Batch 58/64 loss: 0.26921379566192627
Batch 59/64 loss: 0.2649444341659546
Batch 60/64 loss: 0.26305079460144043
Batch 61/64 loss: 0.2591991424560547
Batch 62/64 loss: 0.25814390182495117
Batch 63/64 loss: 0.26325565576553345
Batch 64/64 loss: 0.26045870780944824
Epoch 458  Train loss: 0.26023607441023283  Val loss: 0.313099132370703
Epoch 459
-------------------------------
Batch 1/64 loss: 0.26714134216308594
Batch 2/64 loss: 0.26336193084716797
Batch 3/64 loss: 0.2665126919746399
Batch 4/64 loss: 0.26055634021759033
Batch 5/64 loss: 0.26092469692230225
Batch 6/64 loss: 0.2568250894546509
Batch 7/64 loss: 0.25804567337036133
Batch 8/64 loss: 0.2585963010787964
Batch 9/64 loss: 0.2577638626098633
Batch 10/64 loss: 0.2568563222885132
Batch 11/64 loss: 0.2551391124725342
Batch 12/64 loss: 0.2656620740890503
Batch 13/64 loss: 0.2641454339027405
Batch 14/64 loss: 0.26423025131225586
Batch 15/64 loss: 0.26066887378692627
Batch 16/64 loss: 0.2608693838119507
Batch 17/64 loss: 0.2607017755508423
Batch 18/64 loss: 0.2565365433692932
Batch 19/64 loss: 0.26194238662719727
Batch 20/64 loss: 0.2605016231536865
Batch 21/64 loss: 0.26605820655822754
Batch 22/64 loss: 0.2625553607940674
Batch 23/64 loss: 0.2612913250923157
Batch 24/64 loss: 0.25423651933670044
Batch 25/64 loss: 0.26126766204833984
Batch 26/64 loss: 0.25337469577789307
Batch 27/64 loss: 0.25614213943481445
Batch 28/64 loss: 0.25781720876693726
Batch 29/64 loss: 0.26243656873703003
Batch 30/64 loss: 0.26428812742233276
Batch 31/64 loss: 0.26579952239990234
Batch 32/64 loss: 0.2619982957839966
Batch 33/64 loss: 0.25880932807922363
Batch 34/64 loss: 0.25451380014419556
Batch 35/64 loss: 0.26231539249420166
Batch 36/64 loss: 0.2641594409942627
Batch 37/64 loss: 0.2637630105018616
Batch 38/64 loss: 0.26073509454727173
Batch 39/64 loss: 0.2732226848602295
Batch 40/64 loss: 0.25698959827423096
Batch 41/64 loss: 0.25630486011505127
Batch 42/64 loss: 0.2553390860557556
Batch 43/64 loss: 0.2602465748786926
Batch 44/64 loss: 0.26587730646133423
Batch 45/64 loss: 0.27176254987716675
Batch 46/64 loss: 0.2638440728187561
Batch 47/64 loss: 0.2620387077331543
Batch 48/64 loss: 0.25747954845428467
Batch 49/64 loss: 0.24951457977294922
Batch 50/64 loss: 0.2575174570083618
Batch 51/64 loss: 0.26066720485687256
Batch 52/64 loss: 0.26416778564453125
Batch 53/64 loss: 0.2593744397163391
Batch 54/64 loss: 0.2619415521621704
Batch 55/64 loss: 0.2623777389526367
Batch 56/64 loss: 0.26195281744003296
Batch 57/64 loss: 0.2583165168762207
Batch 58/64 loss: 0.2644607424736023
Batch 59/64 loss: 0.26574885845184326
Batch 60/64 loss: 0.2599670886993408
Batch 61/64 loss: 0.2538442611694336
Batch 62/64 loss: 0.2542988657951355
Batch 63/64 loss: 0.26053762435913086
Batch 64/64 loss: 0.260898232460022
Epoch 459  Train loss: 0.26073740557128305  Val loss: 0.3128449494896066
Epoch 460
-------------------------------
Batch 1/64 loss: 0.258338987827301
Batch 2/64 loss: 0.2593505382537842
Batch 3/64 loss: 0.2616903781890869
Batch 4/64 loss: 0.2537424564361572
Batch 5/64 loss: 0.26271742582321167
Batch 6/64 loss: 0.2564753293991089
Batch 7/64 loss: 0.2519838809967041
Batch 8/64 loss: 0.2608029842376709
Batch 9/64 loss: 0.25052106380462646
Batch 10/64 loss: 0.25348037481307983
Batch 11/64 loss: 0.2641303539276123
Batch 12/64 loss: 0.2626667022705078
Batch 13/64 loss: 0.25386905670166016
Batch 14/64 loss: 0.2597758173942566
Batch 15/64 loss: 0.2634166479110718
Batch 16/64 loss: 0.2680753469467163
Batch 17/64 loss: 0.26573777198791504
Batch 18/64 loss: 0.25625061988830566
Batch 19/64 loss: 0.256991446018219
Batch 20/64 loss: 0.25345271825790405
Batch 21/64 loss: 0.2608528137207031
Batch 22/64 loss: 0.25380122661590576
Batch 23/64 loss: 0.2643764615058899
Batch 24/64 loss: 0.263097882270813
Batch 25/64 loss: 0.2626802921295166
Batch 26/64 loss: 0.2550469636917114
Batch 27/64 loss: 0.2624697685241699
Batch 28/64 loss: 0.26338303089141846
Batch 29/64 loss: 0.2575790286064148
Batch 30/64 loss: 0.25921744108200073
Batch 31/64 loss: 0.2612854242324829
Batch 32/64 loss: 0.2555693984031677
Batch 33/64 loss: 0.2628503441810608
Batch 34/64 loss: 0.25468873977661133
Batch 35/64 loss: 0.2628369927406311
Batch 36/64 loss: 0.2585682272911072
Batch 37/64 loss: 0.26796573400497437
Batch 38/64 loss: 0.2608516216278076
Batch 39/64 loss: 0.2633323669433594
Batch 40/64 loss: 0.2654705047607422
Batch 41/64 loss: 0.2710306644439697
Batch 42/64 loss: 0.2574828863143921
Batch 43/64 loss: 0.2642713785171509
Batch 44/64 loss: 0.2589343786239624
Batch 45/64 loss: 0.267497181892395
Batch 46/64 loss: 0.2624506950378418
Batch 47/64 loss: 0.25788450241088867
Batch 48/64 loss: 0.2596275806427002
Batch 49/64 loss: 0.26168179512023926
Batch 50/64 loss: 0.26146113872528076
Batch 51/64 loss: 0.2561072111129761
Batch 52/64 loss: 0.25535207986831665
Batch 53/64 loss: 0.257529616355896
Batch 54/64 loss: 0.2710689306259155
Batch 55/64 loss: 0.26459836959838867
Batch 56/64 loss: 0.2655290365219116
Batch 57/64 loss: 0.26088154315948486
Batch 58/64 loss: 0.26353007555007935
Batch 59/64 loss: 0.2641203999519348
Batch 60/64 loss: 0.2614539861679077
Batch 61/64 loss: 0.26445794105529785
Batch 62/64 loss: 0.2547343969345093
Batch 63/64 loss: 0.25636303424835205
Batch 64/64 loss: 0.25986993312835693
Epoch 460  Train loss: 0.2604289480284149  Val loss: 0.3130870270974857
Epoch 461
-------------------------------
Batch 1/64 loss: 0.2665224075317383
Batch 2/64 loss: 0.25661182403564453
Batch 3/64 loss: 0.26989203691482544
Batch 4/64 loss: 0.25946420431137085
Batch 5/64 loss: 0.2634164094924927
Batch 6/64 loss: 0.2605956196784973
Batch 7/64 loss: 0.2640191316604614
Batch 8/64 loss: 0.26170527935028076
Batch 9/64 loss: 0.26088976860046387
Batch 10/64 loss: 0.26671677827835083
Batch 11/64 loss: 0.25196772813796997
Batch 12/64 loss: 0.25115376710891724
Batch 13/64 loss: 0.25697946548461914
Batch 14/64 loss: 0.25609564781188965
Batch 15/64 loss: 0.254075825214386
Batch 16/64 loss: 0.2723724842071533
Batch 17/64 loss: 0.2563796639442444
Batch 18/64 loss: 0.2528817653656006
Batch 19/64 loss: 0.26309698820114136
Batch 20/64 loss: 0.2609989643096924
Batch 21/64 loss: 0.2625998258590698
Batch 22/64 loss: 0.26327383518218994
Batch 23/64 loss: 0.2622638940811157
Batch 24/64 loss: 0.26261699199676514
Batch 25/64 loss: 0.2687509059906006
Batch 26/64 loss: 0.25913941860198975
Batch 27/64 loss: 0.26855653524398804
Batch 28/64 loss: 0.2679346799850464
Batch 29/64 loss: 0.2583906054496765
Batch 30/64 loss: 0.2682352066040039
Batch 31/64 loss: 0.2610882520675659
Batch 32/64 loss: 0.26330065727233887
Batch 33/64 loss: 0.2576996088027954
Batch 34/64 loss: 0.2632485628128052
Batch 35/64 loss: 0.2575055956840515
Batch 36/64 loss: 0.2565433979034424
Batch 37/64 loss: 0.26384395360946655
Batch 38/64 loss: 0.26055318117141724
Batch 39/64 loss: 0.25814956426620483
Batch 40/64 loss: 0.2578166127204895
Batch 41/64 loss: 0.26382601261138916
Batch 42/64 loss: 0.2586393356323242
Batch 43/64 loss: 0.26337718963623047
Batch 44/64 loss: 0.258121132850647
Batch 45/64 loss: 0.25916916131973267
Batch 46/64 loss: 0.2550424337387085
Batch 47/64 loss: 0.26733505725860596
Batch 48/64 loss: 0.25441837310791016
Batch 49/64 loss: 0.2626314163208008
Batch 50/64 loss: 0.25951921939849854
Batch 51/64 loss: 0.2540431022644043
Batch 52/64 loss: 0.2626405954360962
Batch 53/64 loss: 0.26601529121398926
Batch 54/64 loss: 0.26598024368286133
Batch 55/64 loss: 0.26136618852615356
Batch 56/64 loss: 0.26195359230041504
Batch 57/64 loss: 0.2612723112106323
Batch 58/64 loss: 0.263078510761261
Batch 59/64 loss: 0.2690322995185852
Batch 60/64 loss: 0.25992918014526367
Batch 61/64 loss: 0.25107431411743164
Batch 62/64 loss: 0.26540452241897583
Batch 63/64 loss: 0.25391268730163574
Batch 64/64 loss: 0.2555619478225708
Epoch 461  Train loss: 0.2609694223777921  Val loss: 0.3129792215488211
Epoch 462
-------------------------------
Batch 1/64 loss: 0.26416224241256714
Batch 2/64 loss: 0.26517820358276367
Batch 3/64 loss: 0.25239408016204834
Batch 4/64 loss: 0.2566906213760376
Batch 5/64 loss: 0.25760066509246826
Batch 6/64 loss: 0.26669830083847046
Batch 7/64 loss: 0.2537558674812317
Batch 8/64 loss: 0.25951123237609863
Batch 9/64 loss: 0.2568054795265198
Batch 10/64 loss: 0.2605155110359192
Batch 11/64 loss: 0.2549096345901489
Batch 12/64 loss: 0.26763439178466797
Batch 13/64 loss: 0.25772595405578613
Batch 14/64 loss: 0.25118112564086914
Batch 15/64 loss: 0.2510507106781006
Batch 16/64 loss: 0.25771230459213257
Batch 17/64 loss: 0.2543814182281494
Batch 18/64 loss: 0.26103150844573975
Batch 19/64 loss: 0.2684996724128723
Batch 20/64 loss: 0.2526201605796814
Batch 21/64 loss: 0.2566356062889099
Batch 22/64 loss: 0.2625192403793335
Batch 23/64 loss: 0.26581692695617676
Batch 24/64 loss: 0.2604824900627136
Batch 25/64 loss: 0.25422048568725586
Batch 26/64 loss: 0.26214200258255005
Batch 27/64 loss: 0.2610085606575012
Batch 28/64 loss: 0.2645111083984375
Batch 29/64 loss: 0.26458144187927246
Batch 30/64 loss: 0.25860464572906494
Batch 31/64 loss: 0.25913339853286743
Batch 32/64 loss: 0.25751936435699463
Batch 33/64 loss: 0.25674182176589966
Batch 34/64 loss: 0.2673940658569336
Batch 35/64 loss: 0.2593533396720886
Batch 36/64 loss: 0.259151816368103
Batch 37/64 loss: 0.25656354427337646
Batch 38/64 loss: 0.2629662752151489
Batch 39/64 loss: 0.2608148455619812
Batch 40/64 loss: 0.2563589811325073
Batch 41/64 loss: 0.2645374536514282
Batch 42/64 loss: 0.25881028175354004
Batch 43/64 loss: 0.2628873586654663
Batch 44/64 loss: 0.2541213035583496
Batch 45/64 loss: 0.2596147060394287
Batch 46/64 loss: 0.25391602516174316
Batch 47/64 loss: 0.266388475894928
Batch 48/64 loss: 0.2544238567352295
Batch 49/64 loss: 0.258919358253479
Batch 50/64 loss: 0.26460009813308716
Batch 51/64 loss: 0.26448553800582886
Batch 52/64 loss: 0.2582393288612366
Batch 53/64 loss: 0.2597814202308655
Batch 54/64 loss: 0.2621345520019531
Batch 55/64 loss: 0.2612532377243042
Batch 56/64 loss: 0.26113951206207275
Batch 57/64 loss: 0.26539909839630127
Batch 58/64 loss: 0.25777584314346313
Batch 59/64 loss: 0.25351762771606445
Batch 60/64 loss: 0.25736820697784424
Batch 61/64 loss: 0.2579542398452759
Batch 62/64 loss: 0.26084256172180176
Batch 63/64 loss: 0.26944780349731445
Batch 64/64 loss: 0.26811516284942627
Epoch 462  Train loss: 0.2598466401006661  Val loss: 0.3127657779303613
Epoch 463
-------------------------------
Batch 1/64 loss: 0.26054954528808594
Batch 2/64 loss: 0.25471335649490356
Batch 3/64 loss: 0.2555491328239441
Batch 4/64 loss: 0.2593874931335449
Batch 5/64 loss: 0.26054084300994873
Batch 6/64 loss: 0.259330153465271
Batch 7/64 loss: 0.25868135690689087
Batch 8/64 loss: 0.26220571994781494
Batch 9/64 loss: 0.2648916244506836
Batch 10/64 loss: 0.25863564014434814
Batch 11/64 loss: 0.26270580291748047
Batch 12/64 loss: 0.26459914445877075
Batch 13/64 loss: 0.2611200213432312
Batch 14/64 loss: 0.25535279512405396
Batch 15/64 loss: 0.259002685546875
Batch 16/64 loss: 0.2597815990447998
Batch 17/64 loss: 0.2651721239089966
Batch 18/64 loss: 0.26194673776626587
Batch 19/64 loss: 0.2544702887535095
Batch 20/64 loss: 0.25400710105895996
Batch 21/64 loss: 0.26267778873443604
Batch 22/64 loss: 0.2566654682159424
Batch 23/64 loss: 0.25939661264419556
Batch 24/64 loss: 0.2631443738937378
Batch 25/64 loss: 0.2630547285079956
Batch 26/64 loss: 0.2589346766471863
Batch 27/64 loss: 0.2598379850387573
Batch 28/64 loss: 0.25656604766845703
Batch 29/64 loss: 0.26477545499801636
Batch 30/64 loss: 0.25515085458755493
Batch 31/64 loss: 0.25634098052978516
Batch 32/64 loss: 0.2627582550048828
Batch 33/64 loss: 0.2640024423599243
Batch 34/64 loss: 0.2563104033470154
Batch 35/64 loss: 0.2632373571395874
Batch 36/64 loss: 0.26869285106658936
Batch 37/64 loss: 0.25911378860473633
Batch 38/64 loss: 0.2596731185913086
Batch 39/64 loss: 0.2584816813468933
Batch 40/64 loss: 0.25911760330200195
Batch 41/64 loss: 0.25767719745635986
Batch 42/64 loss: 0.2609952688217163
Batch 43/64 loss: 0.2595301866531372
Batch 44/64 loss: 0.26025116443634033
Batch 45/64 loss: 0.25381290912628174
Batch 46/64 loss: 0.2632463574409485
Batch 47/64 loss: 0.2551407814025879
Batch 48/64 loss: 0.2568109631538391
Batch 49/64 loss: 0.2609274387359619
Batch 50/64 loss: 0.26723766326904297
Batch 51/64 loss: 0.2606462240219116
Batch 52/64 loss: 0.25338757038116455
Batch 53/64 loss: 0.2566571831703186
Batch 54/64 loss: 0.256191611289978
Batch 55/64 loss: 0.2637975811958313
Batch 56/64 loss: 0.26020586490631104
Batch 57/64 loss: 0.2568591833114624
Batch 58/64 loss: 0.257365345954895
Batch 59/64 loss: 0.25895893573760986
Batch 60/64 loss: 0.25643932819366455
Batch 61/64 loss: 0.26277023553848267
Batch 62/64 loss: 0.2688255310058594
Batch 63/64 loss: 0.2588064670562744
Batch 64/64 loss: 0.25705814361572266
Epoch 463  Train loss: 0.259763297847673  Val loss: 0.3129010935829267
Epoch 464
-------------------------------
Batch 1/64 loss: 0.24926364421844482
Batch 2/64 loss: 0.2604382038116455
Batch 3/64 loss: 0.25170665979385376
Batch 4/64 loss: 0.2524144649505615
Batch 5/64 loss: 0.26257872581481934
Batch 6/64 loss: 0.2574779987335205
Batch 7/64 loss: 0.2590376138687134
Batch 8/64 loss: 0.26212823390960693
Batch 9/64 loss: 0.26430022716522217
Batch 10/64 loss: 0.26606714725494385
Batch 11/64 loss: 0.2612881064414978
Batch 12/64 loss: 0.26460254192352295
Batch 13/64 loss: 0.253628671169281
Batch 14/64 loss: 0.26355504989624023
Batch 15/64 loss: 0.25784552097320557
Batch 16/64 loss: 0.2590600252151489
Batch 17/64 loss: 0.26562589406967163
Batch 18/64 loss: 0.253667414188385
Batch 19/64 loss: 0.26587438583374023
Batch 20/64 loss: 0.2527564764022827
Batch 21/64 loss: 0.2582012414932251
Batch 22/64 loss: 0.26566648483276367
Batch 23/64 loss: 0.2661973237991333
Batch 24/64 loss: 0.2641213536262512
Batch 25/64 loss: 0.2590641379356384
Batch 26/64 loss: 0.25442302227020264
Batch 27/64 loss: 0.2526538372039795
Batch 28/64 loss: 0.2679980993270874
Batch 29/64 loss: 0.25838619470596313
Batch 30/64 loss: 0.253856897354126
Batch 31/64 loss: 0.2528492212295532
Batch 32/64 loss: 0.2586497664451599
Batch 33/64 loss: 0.26010721921920776
Batch 34/64 loss: 0.2550698518753052
Batch 35/64 loss: 0.2548316717147827
Batch 36/64 loss: 0.26606249809265137
Batch 37/64 loss: 0.263690710067749
Batch 38/64 loss: 0.27644866704940796
Batch 39/64 loss: 0.2627803087234497
Batch 40/64 loss: 0.2570534348487854
Batch 41/64 loss: 0.2544705867767334
Batch 42/64 loss: 0.26011013984680176
Batch 43/64 loss: 0.267397940158844
Batch 44/64 loss: 0.2603381276130676
Batch 45/64 loss: 0.26548945903778076
Batch 46/64 loss: 0.26684141159057617
Batch 47/64 loss: 0.25900524854660034
Batch 48/64 loss: 0.2542383074760437
Batch 49/64 loss: 0.2647581100463867
Batch 50/64 loss: 0.2613098621368408
Batch 51/64 loss: 0.25963395833969116
Batch 52/64 loss: 0.2601662874221802
Batch 53/64 loss: 0.25664037466049194
Batch 54/64 loss: 0.2580031752586365
Batch 55/64 loss: 0.26049864292144775
Batch 56/64 loss: 0.26158785820007324
Batch 57/64 loss: 0.26460880041122437
Batch 58/64 loss: 0.26996225118637085
Batch 59/64 loss: 0.2636333703994751
Batch 60/64 loss: 0.2625710964202881
Batch 61/64 loss: 0.2586709260940552
Batch 62/64 loss: 0.2586801052093506
Batch 63/64 loss: 0.2592747211456299
Batch 64/64 loss: 0.2634239196777344
Epoch 464  Train loss: 0.26034333565655876  Val loss: 0.3127339652313809
Epoch 465
-------------------------------
Batch 1/64 loss: 0.26000696420669556
Batch 2/64 loss: 0.25799083709716797
Batch 3/64 loss: 0.26336508989334106
Batch 4/64 loss: 0.2576717138290405
Batch 5/64 loss: 0.25660860538482666
Batch 6/64 loss: 0.25941014289855957
Batch 7/64 loss: 0.26622432470321655
Batch 8/64 loss: 0.253604531288147
Batch 9/64 loss: 0.25566232204437256
Batch 10/64 loss: 0.26193392276763916
Batch 11/64 loss: 0.2592759132385254
Batch 12/64 loss: 0.25798147916793823
Batch 13/64 loss: 0.2623246908187866
Batch 14/64 loss: 0.25781869888305664
Batch 15/64 loss: 0.26723551750183105
Batch 16/64 loss: 0.25699329376220703
Batch 17/64 loss: 0.25333118438720703
Batch 18/64 loss: 0.25198596715927124
Batch 19/64 loss: 0.2569798231124878
Batch 20/64 loss: 0.26258260011672974
Batch 21/64 loss: 0.25768667459487915
Batch 22/64 loss: 0.24980664253234863
Batch 23/64 loss: 0.25695300102233887
Batch 24/64 loss: 0.256655752658844
Batch 25/64 loss: 0.2602333426475525
Batch 26/64 loss: 0.25928378105163574
Batch 27/64 loss: 0.2581363916397095
Batch 28/64 loss: 0.2578933835029602
Batch 29/64 loss: 0.26143932342529297
Batch 30/64 loss: 0.26803916692733765
Batch 31/64 loss: 0.26567554473876953
Batch 32/64 loss: 0.25464922189712524
Batch 33/64 loss: 0.2593749165534973
Batch 34/64 loss: 0.2619641423225403
Batch 35/64 loss: 0.2643080949783325
Batch 36/64 loss: 0.2572680711746216
Batch 37/64 loss: 0.2607172131538391
Batch 38/64 loss: 0.2556976079940796
Batch 39/64 loss: 0.25678372383117676
Batch 40/64 loss: 0.2646099328994751
Batch 41/64 loss: 0.25608038902282715
Batch 42/64 loss: 0.2593575716018677
Batch 43/64 loss: 0.2608243227005005
Batch 44/64 loss: 0.2577763795852661
Batch 45/64 loss: 0.2606923580169678
Batch 46/64 loss: 0.26349472999572754
Batch 47/64 loss: 0.2540438175201416
Batch 48/64 loss: 0.2557673454284668
Batch 49/64 loss: 0.2604447603225708
Batch 50/64 loss: 0.2613285779953003
Batch 51/64 loss: 0.2572329044342041
Batch 52/64 loss: 0.2626481056213379
Batch 53/64 loss: 0.2674417495727539
Batch 54/64 loss: 0.2584773302078247
Batch 55/64 loss: 0.26588231325149536
Batch 56/64 loss: 0.25644397735595703
Batch 57/64 loss: 0.2595428228378296
Batch 58/64 loss: 0.26347440481185913
Batch 59/64 loss: 0.26136958599090576
Batch 60/64 loss: 0.2732328176498413
Batch 61/64 loss: 0.25682055950164795
Batch 62/64 loss: 0.25844132900238037
Batch 63/64 loss: 0.26636308431625366
Batch 64/64 loss: 0.2574230432510376
Epoch 465  Train loss: 0.2597084246429743  Val loss: 0.3128260669020033
Epoch 466
-------------------------------
Batch 1/64 loss: 0.2621605396270752
Batch 2/64 loss: 0.2584553360939026
Batch 3/64 loss: 0.255639910697937
Batch 4/64 loss: 0.26189470291137695
Batch 5/64 loss: 0.258950412273407
Batch 6/64 loss: 0.2567012310028076
Batch 7/64 loss: 0.2632453441619873
Batch 8/64 loss: 0.2590656280517578
Batch 9/64 loss: 0.2679802179336548
Batch 10/64 loss: 0.25708115100860596
Batch 11/64 loss: 0.25517237186431885
Batch 12/64 loss: 0.2584378123283386
Batch 13/64 loss: 0.2560884952545166
Batch 14/64 loss: 0.2589070796966553
Batch 15/64 loss: 0.26541149616241455
Batch 16/64 loss: 0.25786828994750977
Batch 17/64 loss: 0.25588881969451904
Batch 18/64 loss: 0.2625006437301636
Batch 19/64 loss: 0.26165324449539185
Batch 20/64 loss: 0.26124662160873413
Batch 21/64 loss: 0.25321370363235474
Batch 22/64 loss: 0.2559652328491211
Batch 23/64 loss: 0.2533785104751587
Batch 24/64 loss: 0.2548494338989258
Batch 25/64 loss: 0.26072752475738525
Batch 26/64 loss: 0.2692331075668335
Batch 27/64 loss: 0.26668477058410645
Batch 28/64 loss: 0.26308465003967285
Batch 29/64 loss: 0.26056039333343506
Batch 30/64 loss: 0.26277780532836914
Batch 31/64 loss: 0.26262152194976807
Batch 32/64 loss: 0.264653742313385
Batch 33/64 loss: 0.2533379793167114
Batch 34/64 loss: 0.259358286857605
Batch 35/64 loss: 0.25703489780426025
Batch 36/64 loss: 0.2568528652191162
Batch 37/64 loss: 0.2568172812461853
Batch 38/64 loss: 0.25721895694732666
Batch 39/64 loss: 0.2637343406677246
Batch 40/64 loss: 0.25488877296447754
Batch 41/64 loss: 0.25503402948379517
Batch 42/64 loss: 0.2575021982192993
Batch 43/64 loss: 0.2575186491012573
Batch 44/64 loss: 0.263227641582489
Batch 45/64 loss: 0.2574619650840759
Batch 46/64 loss: 0.26781409978866577
Batch 47/64 loss: 0.26160097122192383
Batch 48/64 loss: 0.25788867473602295
Batch 49/64 loss: 0.26387470960617065
Batch 50/64 loss: 0.2652775049209595
Batch 51/64 loss: 0.26941776275634766
Batch 52/64 loss: 0.25611424446105957
Batch 53/64 loss: 0.26365387439727783
Batch 54/64 loss: 0.2614213228225708
Batch 55/64 loss: 0.2696710228919983
Batch 56/64 loss: 0.25946319103240967
Batch 57/64 loss: 0.2585405111312866
Batch 58/64 loss: 0.25709301233291626
Batch 59/64 loss: 0.26295900344848633
Batch 60/64 loss: 0.2610921859741211
Batch 61/64 loss: 0.25791674852371216
Batch 62/64 loss: 0.258327841758728
Batch 63/64 loss: 0.26009178161621094
Batch 64/64 loss: 0.26093268394470215
Epoch 466  Train loss: 0.26007851899838913  Val loss: 0.3132576205066799
Epoch 467
-------------------------------
Batch 1/64 loss: 0.25806915760040283
Batch 2/64 loss: 0.26251453161239624
Batch 3/64 loss: 0.26068973541259766
Batch 4/64 loss: 0.2617431879043579
Batch 5/64 loss: 0.2530297040939331
Batch 6/64 loss: 0.26122546195983887
Batch 7/64 loss: 0.26689577102661133
Batch 8/64 loss: 0.25455242395401
Batch 9/64 loss: 0.2646317481994629
Batch 10/64 loss: 0.2591787576675415
Batch 11/64 loss: 0.26732659339904785
Batch 12/64 loss: 0.2622273564338684
Batch 13/64 loss: 0.2598423957824707
Batch 14/64 loss: 0.2623908519744873
Batch 15/64 loss: 0.2516061067581177
Batch 16/64 loss: 0.2600369453430176
Batch 17/64 loss: 0.26136940717697144
Batch 18/64 loss: 0.26190686225891113
Batch 19/64 loss: 0.26203858852386475
Batch 20/64 loss: 0.2617194652557373
Batch 21/64 loss: 0.25828850269317627
Batch 22/64 loss: 0.26185858249664307
Batch 23/64 loss: 0.2590577006340027
Batch 24/64 loss: 0.25690728425979614
Batch 25/64 loss: 0.2668863534927368
Batch 26/64 loss: 0.2573687434196472
Batch 27/64 loss: 0.25871121883392334
Batch 28/64 loss: 0.2579493522644043
Batch 29/64 loss: 0.26931631565093994
Batch 30/64 loss: 0.26069796085357666
Batch 31/64 loss: 0.2615131139755249
Batch 32/64 loss: 0.2604742646217346
Batch 33/64 loss: 0.25734925270080566
Batch 34/64 loss: 0.2563741207122803
Batch 35/64 loss: 0.2599906921386719
Batch 36/64 loss: 0.25814056396484375
Batch 37/64 loss: 0.26690173149108887
Batch 38/64 loss: 0.2596774697303772
Batch 39/64 loss: 0.2632255554199219
Batch 40/64 loss: 0.2614903450012207
Batch 41/64 loss: 0.2596111297607422
Batch 42/64 loss: 0.2578704357147217
Batch 43/64 loss: 0.25726985931396484
Batch 44/64 loss: 0.25040000677108765
Batch 45/64 loss: 0.2600829601287842
Batch 46/64 loss: 0.26598453521728516
Batch 47/64 loss: 0.260980486869812
Batch 48/64 loss: 0.25648748874664307
Batch 49/64 loss: 0.2580244541168213
Batch 50/64 loss: 0.26165544986724854
Batch 51/64 loss: 0.2670525312423706
Batch 52/64 loss: 0.26023173332214355
Batch 53/64 loss: 0.2565374970436096
Batch 54/64 loss: 0.2628205418586731
Batch 55/64 loss: 0.2563866376876831
Batch 56/64 loss: 0.26516127586364746
Batch 57/64 loss: 0.2616026997566223
Batch 58/64 loss: 0.25561749935150146
Batch 59/64 loss: 0.26312947273254395
Batch 60/64 loss: 0.257831871509552
Batch 61/64 loss: 0.2530931234359741
Batch 62/64 loss: 0.25954335927963257
Batch 63/64 loss: 0.26863032579421997
Batch 64/64 loss: 0.2585815191268921
Epoch 467  Train loss: 0.2603155402576222  Val loss: 0.31288163174468625
Epoch 468
-------------------------------
Batch 1/64 loss: 0.2532629370689392
Batch 2/64 loss: 0.25692152976989746
Batch 3/64 loss: 0.25461459159851074
Batch 4/64 loss: 0.2587658762931824
Batch 5/64 loss: 0.2615915536880493
Batch 6/64 loss: 0.252490758895874
Batch 7/64 loss: 0.26165997982025146
Batch 8/64 loss: 0.2615163326263428
Batch 9/64 loss: 0.25718438625335693
Batch 10/64 loss: 0.25550276041030884
Batch 11/64 loss: 0.2517986297607422
Batch 12/64 loss: 0.2618710994720459
Batch 13/64 loss: 0.26302260160446167
Batch 14/64 loss: 0.261674165725708
Batch 15/64 loss: 0.2639349699020386
Batch 16/64 loss: 0.260662317276001
Batch 17/64 loss: 0.2662482261657715
Batch 18/64 loss: 0.252144455909729
Batch 19/64 loss: 0.2593103051185608
Batch 20/64 loss: 0.2584490180015564
Batch 21/64 loss: 0.27142834663391113
Batch 22/64 loss: 0.2575382590293884
Batch 23/64 loss: 0.26781463623046875
Batch 24/64 loss: 0.2564240097999573
Batch 25/64 loss: 0.26280319690704346
Batch 26/64 loss: 0.2575591802597046
Batch 27/64 loss: 0.26156526803970337
Batch 28/64 loss: 0.2706165313720703
Batch 29/64 loss: 0.2567662000656128
Batch 30/64 loss: 0.2646763324737549
Batch 31/64 loss: 0.25949275493621826
Batch 32/64 loss: 0.26317405700683594
Batch 33/64 loss: 0.2611715793609619
Batch 34/64 loss: 0.257943332195282
Batch 35/64 loss: 0.26098310947418213
Batch 36/64 loss: 0.25744056701660156
Batch 37/64 loss: 0.25758999586105347
Batch 38/64 loss: 0.25478696823120117
Batch 39/64 loss: 0.2589290142059326
Batch 40/64 loss: 0.26216381788253784
Batch 41/64 loss: 0.2644128203392029
Batch 42/64 loss: 0.26392704248428345
Batch 43/64 loss: 0.26207274198532104
Batch 44/64 loss: 0.2598443031311035
Batch 45/64 loss: 0.2584903836250305
Batch 46/64 loss: 0.25535839796066284
Batch 47/64 loss: 0.2570320963859558
Batch 48/64 loss: 0.2559685707092285
Batch 49/64 loss: 0.2591036558151245
Batch 50/64 loss: 0.26299959421157837
Batch 51/64 loss: 0.2578849196434021
Batch 52/64 loss: 0.25913095474243164
Batch 53/64 loss: 0.2622106671333313
Batch 54/64 loss: 0.25750523805618286
Batch 55/64 loss: 0.25940436124801636
Batch 56/64 loss: 0.26125770807266235
Batch 57/64 loss: 0.26334184408187866
Batch 58/64 loss: 0.26736557483673096
Batch 59/64 loss: 0.26860958337783813
Batch 60/64 loss: 0.26112234592437744
Batch 61/64 loss: 0.2580525875091553
Batch 62/64 loss: 0.25941306352615356
Batch 63/64 loss: 0.2629028558731079
Batch 64/64 loss: 0.2580174207687378
Epoch 468  Train loss: 0.26014773378185196  Val loss: 0.3126659991405264
Epoch 469
-------------------------------
Batch 1/64 loss: 0.2637104392051697
Batch 2/64 loss: 0.2594503164291382
Batch 3/64 loss: 0.2534816265106201
Batch 4/64 loss: 0.2662203907966614
Batch 5/64 loss: 0.25974124670028687
Batch 6/64 loss: 0.2675396203994751
Batch 7/64 loss: 0.2634267807006836
Batch 8/64 loss: 0.2643246650695801
Batch 9/64 loss: 0.2654486894607544
Batch 10/64 loss: 0.25235629081726074
Batch 11/64 loss: 0.2648630142211914
Batch 12/64 loss: 0.25758862495422363
Batch 13/64 loss: 0.26087862253189087
Batch 14/64 loss: 0.255168080329895
Batch 15/64 loss: 0.269523024559021
Batch 16/64 loss: 0.2552584409713745
Batch 17/64 loss: 0.2546694278717041
Batch 18/64 loss: 0.2536075711250305
Batch 19/64 loss: 0.2645133137702942
Batch 20/64 loss: 0.25980156660079956
Batch 21/64 loss: 0.25719064474105835
Batch 22/64 loss: 0.2575136423110962
Batch 23/64 loss: 0.261144757270813
Batch 24/64 loss: 0.26094818115234375
Batch 25/64 loss: 0.25667232275009155
Batch 26/64 loss: 0.24997693300247192
Batch 27/64 loss: 0.25617295503616333
Batch 28/64 loss: 0.25612539052963257
Batch 29/64 loss: 0.26548445224761963
Batch 30/64 loss: 0.26946473121643066
Batch 31/64 loss: 0.25907766819000244
Batch 32/64 loss: 0.2615945339202881
Batch 33/64 loss: 0.25405824184417725
Batch 34/64 loss: 0.26145410537719727
Batch 35/64 loss: 0.26092278957366943
Batch 36/64 loss: 0.25557345151901245
Batch 37/64 loss: 0.2532459497451782
Batch 38/64 loss: 0.25930261611938477
Batch 39/64 loss: 0.256985068321228
Batch 40/64 loss: 0.2570309638977051
Batch 41/64 loss: 0.2533758878707886
Batch 42/64 loss: 0.2588961720466614
Batch 43/64 loss: 0.2695580720901489
Batch 44/64 loss: 0.2612041234970093
Batch 45/64 loss: 0.2666112184524536
Batch 46/64 loss: 0.26471590995788574
Batch 47/64 loss: 0.25894927978515625
Batch 48/64 loss: 0.25633978843688965
Batch 49/64 loss: 0.26331764459609985
Batch 50/64 loss: 0.2599833011627197
Batch 51/64 loss: 0.26172125339508057
Batch 52/64 loss: 0.2537975311279297
Batch 53/64 loss: 0.2568700313568115
Batch 54/64 loss: 0.25675737857818604
Batch 55/64 loss: 0.26061058044433594
Batch 56/64 loss: 0.2571759819984436
Batch 57/64 loss: 0.25712519884109497
Batch 58/64 loss: 0.26239585876464844
Batch 59/64 loss: 0.2544538974761963
Batch 60/64 loss: 0.26377207040786743
Batch 61/64 loss: 0.25418561697006226
Batch 62/64 loss: 0.25515854358673096
Batch 63/64 loss: 0.25942134857177734
Batch 64/64 loss: 0.2684807777404785
Epoch 469  Train loss: 0.2595963674433091  Val loss: 0.3118708092732118
Epoch 470
-------------------------------
Batch 1/64 loss: 0.2530514597892761
Batch 2/64 loss: 0.2575358748435974
Batch 3/64 loss: 0.25025635957717896
Batch 4/64 loss: 0.2544759511947632
Batch 5/64 loss: 0.25421857833862305
Batch 6/64 loss: 0.2662820816040039
Batch 7/64 loss: 0.25613725185394287
Batch 8/64 loss: 0.251153826713562
Batch 9/64 loss: 0.2551947832107544
Batch 10/64 loss: 0.26060497760772705
Batch 11/64 loss: 0.25972819328308105
Batch 12/64 loss: 0.25632190704345703
Batch 13/64 loss: 0.2546008825302124
Batch 14/64 loss: 0.25701582431793213
Batch 15/64 loss: 0.25786012411117554
Batch 16/64 loss: 0.26429688930511475
Batch 17/64 loss: 0.25687551498413086
Batch 18/64 loss: 0.25372248888015747
Batch 19/64 loss: 0.2690724730491638
Batch 20/64 loss: 0.2597285509109497
Batch 21/64 loss: 0.26303309202194214
Batch 22/64 loss: 0.2557777762413025
Batch 23/64 loss: 0.2548859119415283
Batch 24/64 loss: 0.26292747259140015
Batch 25/64 loss: 0.2532607316970825
Batch 26/64 loss: 0.25668925046920776
Batch 27/64 loss: 0.2619359493255615
Batch 28/64 loss: 0.2655332684516907
Batch 29/64 loss: 0.25402021408081055
Batch 30/64 loss: 0.2651970386505127
Batch 31/64 loss: 0.2598804235458374
Batch 32/64 loss: 0.2578483819961548
Batch 33/64 loss: 0.25859856605529785
Batch 34/64 loss: 0.2644219398498535
Batch 35/64 loss: 0.26383185386657715
Batch 36/64 loss: 0.2575873136520386
Batch 37/64 loss: 0.26387667655944824
Batch 38/64 loss: 0.2522914409637451
Batch 39/64 loss: 0.25818657875061035
Batch 40/64 loss: 0.26679790019989014
Batch 41/64 loss: 0.2655661702156067
Batch 42/64 loss: 0.25540411472320557
Batch 43/64 loss: 0.2601529359817505
Batch 44/64 loss: 0.25569796562194824
Batch 45/64 loss: 0.2568401098251343
Batch 46/64 loss: 0.26511073112487793
Batch 47/64 loss: 0.2588156461715698
Batch 48/64 loss: 0.26154398918151855
Batch 49/64 loss: 0.26672351360321045
Batch 50/64 loss: 0.2579679489135742
Batch 51/64 loss: 0.2606583833694458
Batch 52/64 loss: 0.2645517587661743
Batch 53/64 loss: 0.265159547328949
Batch 54/64 loss: 0.25990694761276245
Batch 55/64 loss: 0.2556663155555725
Batch 56/64 loss: 0.2631089687347412
Batch 57/64 loss: 0.2650015950202942
Batch 58/64 loss: 0.2557021379470825
Batch 59/64 loss: 0.25596117973327637
Batch 60/64 loss: 0.26401615142822266
Batch 61/64 loss: 0.2650725841522217
Batch 62/64 loss: 0.2568826675415039
Batch 63/64 loss: 0.2577817440032959
Batch 64/64 loss: 0.2538333535194397
Epoch 470  Train loss: 0.2592687669922324  Val loss: 0.31287962362119015
Epoch 471
-------------------------------
Batch 1/64 loss: 0.25280582904815674
Batch 2/64 loss: 0.25758981704711914
Batch 3/64 loss: 0.2623217701911926
Batch 4/64 loss: 0.2622601389884949
Batch 5/64 loss: 0.2587396502494812
Batch 6/64 loss: 0.2559783458709717
Batch 7/64 loss: 0.26749908924102783
Batch 8/64 loss: 0.25772595405578613
Batch 9/64 loss: 0.26837730407714844
Batch 10/64 loss: 0.258622407913208
Batch 11/64 loss: 0.25594234466552734
Batch 12/64 loss: 0.26418715715408325
Batch 13/64 loss: 0.2587178945541382
Batch 14/64 loss: 0.2532484531402588
Batch 15/64 loss: 0.2574118375778198
Batch 16/64 loss: 0.2620130777359009
Batch 17/64 loss: 0.2606741189956665
Batch 18/64 loss: 0.259071946144104
Batch 19/64 loss: 0.256486177444458
Batch 20/64 loss: 0.26799845695495605
Batch 21/64 loss: 0.25526267290115356
Batch 22/64 loss: 0.25593435764312744
Batch 23/64 loss: 0.2591467499732971
Batch 24/64 loss: 0.2601062059402466
Batch 25/64 loss: 0.25865739583969116
Batch 26/64 loss: 0.2676190137863159
Batch 27/64 loss: 0.2652735114097595
Batch 28/64 loss: 0.2567685842514038
Batch 29/64 loss: 0.2552478313446045
Batch 30/64 loss: 0.2631952166557312
Batch 31/64 loss: 0.25662511587142944
Batch 32/64 loss: 0.25485360622406006
Batch 33/64 loss: 0.2629401683807373
Batch 34/64 loss: 0.25679731369018555
Batch 35/64 loss: 0.26175808906555176
Batch 36/64 loss: 0.25519251823425293
Batch 37/64 loss: 0.25731563568115234
Batch 38/64 loss: 0.2620886564254761
Batch 39/64 loss: 0.2618147134780884
Batch 40/64 loss: 0.2566136121749878
Batch 41/64 loss: 0.2578354477882385
Batch 42/64 loss: 0.25866448879241943
Batch 43/64 loss: 0.2557176351547241
Batch 44/64 loss: 0.2567092180252075
Batch 45/64 loss: 0.26129472255706787
Batch 46/64 loss: 0.25927460193634033
Batch 47/64 loss: 0.26113271713256836
Batch 48/64 loss: 0.25698840618133545
Batch 49/64 loss: 0.2588123083114624
Batch 50/64 loss: 0.2579338550567627
Batch 51/64 loss: 0.25605034828186035
Batch 52/64 loss: 0.2569546699523926
Batch 53/64 loss: 0.26294392347335815
Batch 54/64 loss: 0.26017314195632935
Batch 55/64 loss: 0.25779563188552856
Batch 56/64 loss: 0.2661803364753723
Batch 57/64 loss: 0.25479257106781006
Batch 58/64 loss: 0.2634134292602539
Batch 59/64 loss: 0.2656857967376709
Batch 60/64 loss: 0.2529696822166443
Batch 61/64 loss: 0.25525999069213867
Batch 62/64 loss: 0.25482290983200073
Batch 63/64 loss: 0.2700389623641968
Batch 64/64 loss: 0.26512444019317627
Epoch 471  Train loss: 0.2594693469066246  Val loss: 0.31356257425550743
Epoch 472
-------------------------------
Batch 1/64 loss: 0.25372469425201416
Batch 2/64 loss: 0.2623317241668701
Batch 3/64 loss: 0.2642291784286499
Batch 4/64 loss: 0.2521383762359619
Batch 5/64 loss: 0.2535194158554077
Batch 6/64 loss: 0.2594243884086609
Batch 7/64 loss: 0.2691442370414734
Batch 8/64 loss: 0.25434714555740356
Batch 9/64 loss: 0.2582273483276367
Batch 10/64 loss: 0.264251172542572
Batch 11/64 loss: 0.2573243975639343
Batch 12/64 loss: 0.2516215443611145
Batch 13/64 loss: 0.2562507390975952
Batch 14/64 loss: 0.26705408096313477
Batch 15/64 loss: 0.255068302154541
Batch 16/64 loss: 0.2572351098060608
Batch 17/64 loss: 0.2568007707595825
Batch 18/64 loss: 0.25578194856643677
Batch 19/64 loss: 0.2567671537399292
Batch 20/64 loss: 0.2573675513267517
Batch 21/64 loss: 0.25990450382232666
Batch 22/64 loss: 0.25818049907684326
Batch 23/64 loss: 0.25276172161102295
Batch 24/64 loss: 0.26349806785583496
Batch 25/64 loss: 0.2586594820022583
Batch 26/64 loss: 0.2557058334350586
Batch 27/64 loss: 0.2633069157600403
Batch 28/64 loss: 0.25729966163635254
Batch 29/64 loss: 0.2564791440963745
Batch 30/64 loss: 0.26234376430511475
Batch 31/64 loss: 0.2707415819168091
Batch 32/64 loss: 0.25503456592559814
Batch 33/64 loss: 0.26159900426864624
Batch 34/64 loss: 0.26031720638275146
Batch 35/64 loss: 0.2603450417518616
Batch 36/64 loss: 0.26286208629608154
Batch 37/64 loss: 0.2627384066581726
Batch 38/64 loss: 0.26092368364334106
Batch 39/64 loss: 0.25966209173202515
Batch 40/64 loss: 0.2582029104232788
Batch 41/64 loss: 0.2578502893447876
Batch 42/64 loss: 0.2568000555038452
Batch 43/64 loss: 0.2566153407096863
Batch 44/64 loss: 0.2583698034286499
Batch 45/64 loss: 0.2599982023239136
Batch 46/64 loss: 0.2507949471473694
Batch 47/64 loss: 0.2563467025756836
Batch 48/64 loss: 0.2662675380706787
Batch 49/64 loss: 0.2594704031944275
Batch 50/64 loss: 0.26991838216781616
Batch 51/64 loss: 0.25702905654907227
Batch 52/64 loss: 0.2549567222595215
Batch 53/64 loss: 0.2595752477645874
Batch 54/64 loss: 0.2600136995315552
Batch 55/64 loss: 0.26159512996673584
Batch 56/64 loss: 0.2554001808166504
Batch 57/64 loss: 0.26032590866088867
Batch 58/64 loss: 0.26679879426956177
Batch 59/64 loss: 0.25343406200408936
Batch 60/64 loss: 0.25701630115509033
Batch 61/64 loss: 0.2573692798614502
Batch 62/64 loss: 0.2696089744567871
Batch 63/64 loss: 0.26600563526153564
Batch 64/64 loss: 0.26493310928344727
Epoch 472  Train loss: 0.25934801475674496  Val loss: 0.31366506433978525
Epoch 473
-------------------------------
Batch 1/64 loss: 0.25879430770874023
Batch 2/64 loss: 0.2641099691390991
Batch 3/64 loss: 0.25455665588378906
Batch 4/64 loss: 0.25659143924713135
Batch 5/64 loss: 0.262823224067688
Batch 6/64 loss: 0.2567254304885864
Batch 7/64 loss: 0.2588087320327759
Batch 8/64 loss: 0.2627164125442505
Batch 9/64 loss: 0.26451194286346436
Batch 10/64 loss: 0.25686073303222656
Batch 11/64 loss: 0.25134801864624023
Batch 12/64 loss: 0.26301419734954834
Batch 13/64 loss: 0.2590749263763428
Batch 14/64 loss: 0.2576436996459961
Batch 15/64 loss: 0.2694474458694458
Batch 16/64 loss: 0.2601311206817627
Batch 17/64 loss: 0.26497554779052734
Batch 18/64 loss: 0.2586771845817566
Batch 19/64 loss: 0.2583496570587158
Batch 20/64 loss: 0.26728975772857666
Batch 21/64 loss: 0.2585880756378174
Batch 22/64 loss: 0.25647854804992676
Batch 23/64 loss: 0.25815248489379883
Batch 24/64 loss: 0.26393288373947144
Batch 25/64 loss: 0.2598280906677246
Batch 26/64 loss: 0.25831079483032227
Batch 27/64 loss: 0.2695333957672119
Batch 28/64 loss: 0.26461201906204224
Batch 29/64 loss: 0.26120585203170776
Batch 30/64 loss: 0.26535820960998535
Batch 31/64 loss: 0.25553464889526367
Batch 32/64 loss: 0.26211798191070557
Batch 33/64 loss: 0.257379949092865
Batch 34/64 loss: 0.26336175203323364
Batch 35/64 loss: 0.25713467597961426
Batch 36/64 loss: 0.2631678581237793
Batch 37/64 loss: 0.2664684057235718
Batch 38/64 loss: 0.25933778285980225
Batch 39/64 loss: 0.2672300934791565
Batch 40/64 loss: 0.25789785385131836
Batch 41/64 loss: 0.2655894160270691
Batch 42/64 loss: 0.2602497339248657
Batch 43/64 loss: 0.2588344216346741
Batch 44/64 loss: 0.261111855506897
Batch 45/64 loss: 0.25982409715652466
Batch 46/64 loss: 0.2587408423423767
Batch 47/64 loss: 0.2565929889678955
Batch 48/64 loss: 0.26075708866119385
Batch 49/64 loss: 0.25649845600128174
Batch 50/64 loss: 0.25291627645492554
Batch 51/64 loss: 0.2592761516571045
Batch 52/64 loss: 0.25980818271636963
Batch 53/64 loss: 0.25144457817077637
Batch 54/64 loss: 0.258242130279541
Batch 55/64 loss: 0.2544904947280884
Batch 56/64 loss: 0.2589409351348877
Batch 57/64 loss: 0.2588050365447998
Batch 58/64 loss: 0.2549459934234619
Batch 59/64 loss: 0.26596641540527344
Batch 60/64 loss: 0.26160526275634766
Batch 61/64 loss: 0.2534404993057251
Batch 62/64 loss: 0.26220184564590454
Batch 63/64 loss: 0.2599068880081177
Batch 64/64 loss: 0.25929415225982666
Epoch 473  Train loss: 0.2600273249196071  Val loss: 0.31297142194308775
Epoch 474
-------------------------------
Batch 1/64 loss: 0.2487121820449829
Batch 2/64 loss: 0.26785123348236084
Batch 3/64 loss: 0.25697392225265503
Batch 4/64 loss: 0.25997424125671387
Batch 5/64 loss: 0.25466740131378174
Batch 6/64 loss: 0.25985491275787354
Batch 7/64 loss: 0.26451778411865234
Batch 8/64 loss: 0.26159483194351196
Batch 9/64 loss: 0.26637113094329834
Batch 10/64 loss: 0.2680623531341553
Batch 11/64 loss: 0.2509647607803345
Batch 12/64 loss: 0.2588859796524048
Batch 13/64 loss: 0.2606092691421509
Batch 14/64 loss: 0.2620525360107422
Batch 15/64 loss: 0.2602997422218323
Batch 16/64 loss: 0.25887346267700195
Batch 17/64 loss: 0.25536131858825684
Batch 18/64 loss: 0.2523048520088196
Batch 19/64 loss: 0.2647385001182556
Batch 20/64 loss: 0.2552986741065979
Batch 21/64 loss: 0.2597582936286926
Batch 22/64 loss: 0.26335763931274414
Batch 23/64 loss: 0.2548997402191162
Batch 24/64 loss: 0.2591497302055359
Batch 25/64 loss: 0.2653944492340088
Batch 26/64 loss: 0.25789785385131836
Batch 27/64 loss: 0.2549259662628174
Batch 28/64 loss: 0.2525871992111206
Batch 29/64 loss: 0.2548530101776123
Batch 30/64 loss: 0.2689073085784912
Batch 31/64 loss: 0.253757119178772
Batch 32/64 loss: 0.2600787281990051
Batch 33/64 loss: 0.26021355390548706
Batch 34/64 loss: 0.2569348216056824
Batch 35/64 loss: 0.2588386535644531
Batch 36/64 loss: 0.252909779548645
Batch 37/64 loss: 0.2585930824279785
Batch 38/64 loss: 0.25395911931991577
Batch 39/64 loss: 0.256658673286438
Batch 40/64 loss: 0.25553184747695923
Batch 41/64 loss: 0.26288700103759766
Batch 42/64 loss: 0.2655148506164551
Batch 43/64 loss: 0.2487884759902954
Batch 44/64 loss: 0.2560023069381714
Batch 45/64 loss: 0.2704200744628906
Batch 46/64 loss: 0.26308339834213257
Batch 47/64 loss: 0.2612191438674927
Batch 48/64 loss: 0.2589685916900635
Batch 49/64 loss: 0.25492656230926514
Batch 50/64 loss: 0.26191437244415283
Batch 51/64 loss: 0.266477108001709
Batch 52/64 loss: 0.2574161887168884
Batch 53/64 loss: 0.26173675060272217
Batch 54/64 loss: 0.26470887660980225
Batch 55/64 loss: 0.2645500898361206
Batch 56/64 loss: 0.2590317726135254
Batch 57/64 loss: 0.25801849365234375
Batch 58/64 loss: 0.265610933303833
Batch 59/64 loss: 0.25424522161483765
Batch 60/64 loss: 0.26126253604888916
Batch 61/64 loss: 0.25668513774871826
Batch 62/64 loss: 0.2644622325897217
Batch 63/64 loss: 0.25854361057281494
Batch 64/64 loss: 0.2587173581123352
Epoch 474  Train loss: 0.2594147044069627  Val loss: 0.31200899393697784
Epoch 475
-------------------------------
Batch 1/64 loss: 0.25621187686920166
Batch 2/64 loss: 0.25892722606658936
Batch 3/64 loss: 0.2518582344055176
Batch 4/64 loss: 0.2519066333770752
Batch 5/64 loss: 0.2527902126312256
Batch 6/64 loss: 0.2550124526023865
Batch 7/64 loss: 0.2532919645309448
Batch 8/64 loss: 0.2579053044319153
Batch 9/64 loss: 0.2585675120353699
Batch 10/64 loss: 0.25456470251083374
Batch 11/64 loss: 0.25678473711013794
Batch 12/64 loss: 0.26338744163513184
Batch 13/64 loss: 0.2588176131248474
Batch 14/64 loss: 0.25399959087371826
Batch 15/64 loss: 0.25736135244369507
Batch 16/64 loss: 0.2593463063240051
Batch 17/64 loss: 0.25474047660827637
Batch 18/64 loss: 0.2524893283843994
Batch 19/64 loss: 0.26306939125061035
Batch 20/64 loss: 0.2556208372116089
Batch 21/64 loss: 0.26218974590301514
Batch 22/64 loss: 0.2526942491531372
Batch 23/64 loss: 0.2533038258552551
Batch 24/64 loss: 0.26351499557495117
Batch 25/64 loss: 0.25915950536727905
Batch 26/64 loss: 0.2585737705230713
Batch 27/64 loss: 0.26009005308151245
Batch 28/64 loss: 0.25410568714141846
Batch 29/64 loss: 0.26045334339141846
Batch 30/64 loss: 0.25895965099334717
Batch 31/64 loss: 0.2570570707321167
Batch 32/64 loss: 0.2645871639251709
Batch 33/64 loss: 0.26359277963638306
Batch 34/64 loss: 0.2595176100730896
Batch 35/64 loss: 0.26288485527038574
Batch 36/64 loss: 0.26140254735946655
Batch 37/64 loss: 0.2557591199874878
Batch 38/64 loss: 0.2622026801109314
Batch 39/64 loss: 0.258522629737854
Batch 40/64 loss: 0.2606809139251709
Batch 41/64 loss: 0.2605101466178894
Batch 42/64 loss: 0.26219654083251953
Batch 43/64 loss: 0.2536839246749878
Batch 44/64 loss: 0.2629086971282959
Batch 45/64 loss: 0.26309359073638916
Batch 46/64 loss: 0.2614580988883972
Batch 47/64 loss: 0.2562253475189209
Batch 48/64 loss: 0.255582332611084
Batch 49/64 loss: 0.26418840885162354
Batch 50/64 loss: 0.2554050087928772
Batch 51/64 loss: 0.2651492953300476
Batch 52/64 loss: 0.255779504776001
Batch 53/64 loss: 0.2549980878829956
Batch 54/64 loss: 0.24770879745483398
Batch 55/64 loss: 0.25906312465667725
Batch 56/64 loss: 0.2533087134361267
Batch 57/64 loss: 0.2675579786300659
Batch 58/64 loss: 0.2685507535934448
Batch 59/64 loss: 0.26549088954925537
Batch 60/64 loss: 0.25761139392852783
Batch 61/64 loss: 0.26506155729293823
Batch 62/64 loss: 0.26519227027893066
Batch 63/64 loss: 0.260087788105011
Batch 64/64 loss: 0.2623944878578186
Epoch 475  Train loss: 0.25872178054323386  Val loss: 0.31314195431384845
Epoch 476
-------------------------------
Batch 1/64 loss: 0.26246178150177
Batch 2/64 loss: 0.25877076387405396
Batch 3/64 loss: 0.2620798349380493
Batch 4/64 loss: 0.2582002878189087
Batch 5/64 loss: 0.25236988067626953
Batch 6/64 loss: 0.25713658332824707
Batch 7/64 loss: 0.2585958242416382
Batch 8/64 loss: 0.26604264974594116
Batch 9/64 loss: 0.2645992040634155
Batch 10/64 loss: 0.2559870481491089
Batch 11/64 loss: 0.254180371761322
Batch 12/64 loss: 0.26145458221435547
Batch 13/64 loss: 0.26124322414398193
Batch 14/64 loss: 0.2543875575065613
Batch 15/64 loss: 0.2628322243690491
Batch 16/64 loss: 0.26406359672546387
Batch 17/64 loss: 0.24799960851669312
Batch 18/64 loss: 0.2554897665977478
Batch 19/64 loss: 0.2547626495361328
Batch 20/64 loss: 0.2555159330368042
Batch 21/64 loss: 0.2550409436225891
Batch 22/64 loss: 0.2582710385322571
Batch 23/64 loss: 0.2596607208251953
Batch 24/64 loss: 0.25161659717559814
Batch 25/64 loss: 0.2523374557495117
Batch 26/64 loss: 0.2611352801322937
Batch 27/64 loss: 0.25616455078125
Batch 28/64 loss: 0.26080751419067383
Batch 29/64 loss: 0.2486628293991089
Batch 30/64 loss: 0.2519928216934204
Batch 31/64 loss: 0.25395262241363525
Batch 32/64 loss: 0.26397812366485596
Batch 33/64 loss: 0.2620130777359009
Batch 34/64 loss: 0.2565799951553345
Batch 35/64 loss: 0.26338690519332886
Batch 36/64 loss: 0.2660200595855713
Batch 37/64 loss: 0.25568294525146484
Batch 38/64 loss: 0.2628622055053711
Batch 39/64 loss: 0.26107072830200195
Batch 40/64 loss: 0.25631749629974365
Batch 41/64 loss: 0.25562137365341187
Batch 42/64 loss: 0.26881957054138184
Batch 43/64 loss: 0.2563702464103699
Batch 44/64 loss: 0.26248300075531006
Batch 45/64 loss: 0.2611243724822998
Batch 46/64 loss: 0.25383448600769043
Batch 47/64 loss: 0.2622494697570801
Batch 48/64 loss: 0.2640427350997925
Batch 49/64 loss: 0.26883798837661743
Batch 50/64 loss: 0.25585299730300903
Batch 51/64 loss: 0.26114189624786377
Batch 52/64 loss: 0.2600613832473755
Batch 53/64 loss: 0.2619832754135132
Batch 54/64 loss: 0.26196014881134033
Batch 55/64 loss: 0.25899332761764526
Batch 56/64 loss: 0.2654508352279663
Batch 57/64 loss: 0.25964611768722534
Batch 58/64 loss: 0.2632148861885071
Batch 59/64 loss: 0.2537151575088501
Batch 60/64 loss: 0.25439560413360596
Batch 61/64 loss: 0.25723040103912354
Batch 62/64 loss: 0.2594648003578186
Batch 63/64 loss: 0.25894439220428467
Batch 64/64 loss: 0.25952184200286865
Epoch 476  Train loss: 0.25891462167104085  Val loss: 0.3129377735849099
Epoch 477
-------------------------------
Batch 1/64 loss: 0.2568920850753784
Batch 2/64 loss: 0.26002854108810425
Batch 3/64 loss: 0.260415256023407
Batch 4/64 loss: 0.2551553249359131
Batch 5/64 loss: 0.2621241807937622
Batch 6/64 loss: 0.25729799270629883
Batch 7/64 loss: 0.24813735485076904
Batch 8/64 loss: 0.25617873668670654
Batch 9/64 loss: 0.2587970495223999
Batch 10/64 loss: 0.256503701210022
Batch 11/64 loss: 0.25996196269989014
Batch 12/64 loss: 0.25856685638427734
Batch 13/64 loss: 0.26275354623794556
Batch 14/64 loss: 0.2530254125595093
Batch 15/64 loss: 0.2636237144470215
Batch 16/64 loss: 0.2496606707572937
Batch 17/64 loss: 0.259452223777771
Batch 18/64 loss: 0.26474785804748535
Batch 19/64 loss: 0.2530238628387451
Batch 20/64 loss: 0.2614850401878357
Batch 21/64 loss: 0.2518312931060791
Batch 22/64 loss: 0.25195634365081787
Batch 23/64 loss: 0.25714194774627686
Batch 24/64 loss: 0.2621249556541443
Batch 25/64 loss: 0.258980393409729
Batch 26/64 loss: 0.25652027130126953
Batch 27/64 loss: 0.26049184799194336
Batch 28/64 loss: 0.2607690691947937
Batch 29/64 loss: 0.26516735553741455
Batch 30/64 loss: 0.26578933000564575
Batch 31/64 loss: 0.26232630014419556
Batch 32/64 loss: 0.25854432582855225
Batch 33/64 loss: 0.25595200061798096
Batch 34/64 loss: 0.2570432424545288
Batch 35/64 loss: 0.25966310501098633
Batch 36/64 loss: 0.2556425929069519
Batch 37/64 loss: 0.2624715566635132
Batch 38/64 loss: 0.26350951194763184
Batch 39/64 loss: 0.2559359073638916
Batch 40/64 loss: 0.26126527786254883
Batch 41/64 loss: 0.2686649560928345
Batch 42/64 loss: 0.2658424973487854
Batch 43/64 loss: 0.25970524549484253
Batch 44/64 loss: 0.26574522256851196
Batch 45/64 loss: 0.26246535778045654
Batch 46/64 loss: 0.2599576711654663
Batch 47/64 loss: 0.2660297751426697
Batch 48/64 loss: 0.2615904211997986
Batch 49/64 loss: 0.2575516104698181
Batch 50/64 loss: 0.25619709491729736
Batch 51/64 loss: 0.25799286365509033
Batch 52/64 loss: 0.2599092721939087
Batch 53/64 loss: 0.25707459449768066
Batch 54/64 loss: 0.2524750232696533
Batch 55/64 loss: 0.2603873610496521
Batch 56/64 loss: 0.2603864073753357
Batch 57/64 loss: 0.2589021921157837
Batch 58/64 loss: 0.2574077844619751
Batch 59/64 loss: 0.25629836320877075
Batch 60/64 loss: 0.26263129711151123
Batch 61/64 loss: 0.26040875911712646
Batch 62/64 loss: 0.26079052686691284
Batch 63/64 loss: 0.2577494978904724
Batch 64/64 loss: 0.25476521253585815
Epoch 477  Train loss: 0.25910895221373614  Val loss: 0.3138247060611895
Epoch 478
-------------------------------
Batch 1/64 loss: 0.2602913975715637
Batch 2/64 loss: 0.2570384740829468
Batch 3/64 loss: 0.2630283236503601
Batch 4/64 loss: 0.2571653723716736
Batch 5/64 loss: 0.25854265689849854
Batch 6/64 loss: 0.24993276596069336
Batch 7/64 loss: 0.2505607604980469
Batch 8/64 loss: 0.26205480098724365
Batch 9/64 loss: 0.25480473041534424
Batch 10/64 loss: 0.25849032402038574
Batch 11/64 loss: 0.26263219118118286
Batch 12/64 loss: 0.25484728813171387
Batch 13/64 loss: 0.2572225332260132
Batch 14/64 loss: 0.26168525218963623
Batch 15/64 loss: 0.26616013050079346
Batch 16/64 loss: 0.2572331428527832
Batch 17/64 loss: 0.2615931034088135
Batch 18/64 loss: 0.25849854946136475
Batch 19/64 loss: 0.25930988788604736
Batch 20/64 loss: 0.2594566345214844
Batch 21/64 loss: 0.25581204891204834
Batch 22/64 loss: 0.2612569332122803
Batch 23/64 loss: 0.2601439952850342
Batch 24/64 loss: 0.2633097171783447
Batch 25/64 loss: 0.2529919147491455
Batch 26/64 loss: 0.2585601210594177
Batch 27/64 loss: 0.25322872400283813
Batch 28/64 loss: 0.24924743175506592
Batch 29/64 loss: 0.2570973038673401
Batch 30/64 loss: 0.2680172920227051
Batch 31/64 loss: 0.25817620754241943
Batch 32/64 loss: 0.25775134563446045
Batch 33/64 loss: 0.25990134477615356
Batch 34/64 loss: 0.25086891651153564
Batch 35/64 loss: 0.26541560888290405
Batch 36/64 loss: 0.2590820789337158
Batch 37/64 loss: 0.2633711099624634
Batch 38/64 loss: 0.25700926780700684
Batch 39/64 loss: 0.26523661613464355
Batch 40/64 loss: 0.2591114640235901
Batch 41/64 loss: 0.25571298599243164
Batch 42/64 loss: 0.2686389684677124
Batch 43/64 loss: 0.2584303617477417
Batch 44/64 loss: 0.26504284143447876
Batch 45/64 loss: 0.25551629066467285
Batch 46/64 loss: 0.2611166834831238
Batch 47/64 loss: 0.2578503489494324
Batch 48/64 loss: 0.25977396965026855
Batch 49/64 loss: 0.25907838344573975
Batch 50/64 loss: 0.25945037603378296
Batch 51/64 loss: 0.2573423981666565
Batch 52/64 loss: 0.2605709433555603
Batch 53/64 loss: 0.25807976722717285
Batch 54/64 loss: 0.2639474868774414
Batch 55/64 loss: 0.2552187442779541
Batch 56/64 loss: 0.2619258165359497
Batch 57/64 loss: 0.2595427632331848
Batch 58/64 loss: 0.26166677474975586
Batch 59/64 loss: 0.2574710249900818
Batch 60/64 loss: 0.2588515281677246
Batch 61/64 loss: 0.2571818232536316
Batch 62/64 loss: 0.2553706169128418
Batch 63/64 loss: 0.2640778422355652
Batch 64/64 loss: 0.2662164568901062
Epoch 478  Train loss: 0.25910053089553237  Val loss: 0.3127617553337333
Epoch 479
-------------------------------
Batch 1/64 loss: 0.24960458278656006
Batch 2/64 loss: 0.2640776038169861
Batch 3/64 loss: 0.262592077255249
Batch 4/64 loss: 0.25330787897109985
Batch 5/64 loss: 0.25495749711990356
Batch 6/64 loss: 0.25546902418136597
Batch 7/64 loss: 0.2544729709625244
Batch 8/64 loss: 0.2519358992576599
Batch 9/64 loss: 0.2642064094543457
Batch 10/64 loss: 0.26604288816452026
Batch 11/64 loss: 0.26098430156707764
Batch 12/64 loss: 0.25470370054244995
Batch 13/64 loss: 0.256649911403656
Batch 14/64 loss: 0.2569834589958191
Batch 15/64 loss: 0.25917482376098633
Batch 16/64 loss: 0.26145482063293457
Batch 17/64 loss: 0.26310276985168457
Batch 18/64 loss: 0.2549229860305786
Batch 19/64 loss: 0.266709566116333
Batch 20/64 loss: 0.256061315536499
Batch 21/64 loss: 0.25600260496139526
Batch 22/64 loss: 0.2549472451210022
Batch 23/64 loss: 0.2542368769645691
Batch 24/64 loss: 0.2575763463973999
Batch 25/64 loss: 0.26611483097076416
Batch 26/64 loss: 0.2532837390899658
Batch 27/64 loss: 0.2617211937904358
Batch 28/64 loss: 0.25887537002563477
Batch 29/64 loss: 0.2609826326370239
Batch 30/64 loss: 0.25767993927001953
Batch 31/64 loss: 0.2489759922027588
Batch 32/64 loss: 0.25085341930389404
Batch 33/64 loss: 0.26131826639175415
Batch 34/64 loss: 0.26331770420074463
Batch 35/64 loss: 0.2553420066833496
Batch 36/64 loss: 0.2615997791290283
Batch 37/64 loss: 0.2561603784561157
Batch 38/64 loss: 0.2603483200073242
Batch 39/64 loss: 0.2677990198135376
Batch 40/64 loss: 0.2588014006614685
Batch 41/64 loss: 0.262498140335083
Batch 42/64 loss: 0.2584647536277771
Batch 43/64 loss: 0.264557421207428
Batch 44/64 loss: 0.25690609216690063
Batch 45/64 loss: 0.2558317184448242
Batch 46/64 loss: 0.260076642036438
Batch 47/64 loss: 0.2650960683822632
Batch 48/64 loss: 0.25774645805358887
Batch 49/64 loss: 0.25825035572052
Batch 50/64 loss: 0.2562521696090698
Batch 51/64 loss: 0.259219229221344
Batch 52/64 loss: 0.25778234004974365
Batch 53/64 loss: 0.25806325674057007
Batch 54/64 loss: 0.25884854793548584
Batch 55/64 loss: 0.25406670570373535
Batch 56/64 loss: 0.2641705870628357
Batch 57/64 loss: 0.25500714778900146
Batch 58/64 loss: 0.2536836266517639
Batch 59/64 loss: 0.2600516080856323
Batch 60/64 loss: 0.2612893581390381
Batch 61/64 loss: 0.2532937526702881
Batch 62/64 loss: 0.25727343559265137
Batch 63/64 loss: 0.25454890727996826
Batch 64/64 loss: 0.2651231288909912
Epoch 479  Train loss: 0.25843407406526453  Val loss: 0.31271028621090236
Epoch 480
-------------------------------
Batch 1/64 loss: 0.25635647773742676
Batch 2/64 loss: 0.2576946020126343
Batch 3/64 loss: 0.2705068588256836
Batch 4/64 loss: 0.2514212727546692
Batch 5/64 loss: 0.25461775064468384
Batch 6/64 loss: 0.2536623477935791
Batch 7/64 loss: 0.26370811462402344
Batch 8/64 loss: 0.2577272057533264
Batch 9/64 loss: 0.2633666396141052
Batch 10/64 loss: 0.2614661455154419
Batch 11/64 loss: 0.2570774555206299
Batch 12/64 loss: 0.25441408157348633
Batch 13/64 loss: 0.2622535228729248
Batch 14/64 loss: 0.25002968311309814
Batch 15/64 loss: 0.2584505081176758
Batch 16/64 loss: 0.26105761528015137
Batch 17/64 loss: 0.2508404850959778
Batch 18/64 loss: 0.25706958770751953
Batch 19/64 loss: 0.27129173278808594
Batch 20/64 loss: 0.25183743238449097
Batch 21/64 loss: 0.252682089805603
Batch 22/64 loss: 0.26519858837127686
Batch 23/64 loss: 0.2640867233276367
Batch 24/64 loss: 0.2519182562828064
Batch 25/64 loss: 0.26916635036468506
Batch 26/64 loss: 0.2573721408843994
Batch 27/64 loss: 0.25749772787094116
Batch 28/64 loss: 0.25803905725479126
Batch 29/64 loss: 0.25455379486083984
Batch 30/64 loss: 0.25725001096725464
Batch 31/64 loss: 0.2557443380355835
Batch 32/64 loss: 0.2566312551498413
Batch 33/64 loss: 0.26102304458618164
Batch 34/64 loss: 0.24617493152618408
Batch 35/64 loss: 0.25266802310943604
Batch 36/64 loss: 0.2598133087158203
Batch 37/64 loss: 0.2585008144378662
Batch 38/64 loss: 0.2610088586807251
Batch 39/64 loss: 0.2595313787460327
Batch 40/64 loss: 0.25854384899139404
Batch 41/64 loss: 0.26684439182281494
Batch 42/64 loss: 0.2654564380645752
Batch 43/64 loss: 0.26280272006988525
Batch 44/64 loss: 0.2594412565231323
Batch 45/64 loss: 0.2669265866279602
Batch 46/64 loss: 0.25496089458465576
Batch 47/64 loss: 0.2684483528137207
Batch 48/64 loss: 0.2673506736755371
Batch 49/64 loss: 0.2621266841888428
Batch 50/64 loss: 0.26647233963012695
Batch 51/64 loss: 0.2563471794128418
Batch 52/64 loss: 0.2635876536369324
Batch 53/64 loss: 0.2708805799484253
Batch 54/64 loss: 0.25985968112945557
Batch 55/64 loss: 0.2561841607093811
Batch 56/64 loss: 0.2540608048439026
Batch 57/64 loss: 0.25794851779937744
Batch 58/64 loss: 0.2610520124435425
Batch 59/64 loss: 0.2641550302505493
Batch 60/64 loss: 0.2606043815612793
Batch 61/64 loss: 0.2567417025566101
Batch 62/64 loss: 0.25646722316741943
Batch 63/64 loss: 0.26550787687301636
Batch 64/64 loss: 0.25740623474121094
Epoch 480  Train loss: 0.2594437000798244  Val loss: 0.31269535043395263
Epoch 481
-------------------------------
Batch 1/64 loss: 0.2657792568206787
Batch 2/64 loss: 0.256990909576416
Batch 3/64 loss: 0.2631111145019531
Batch 4/64 loss: 0.2650400400161743
Batch 5/64 loss: 0.254672110080719
Batch 6/64 loss: 0.2516189217567444
Batch 7/64 loss: 0.2554839849472046
Batch 8/64 loss: 0.25368595123291016
Batch 9/64 loss: 0.2572817802429199
Batch 10/64 loss: 0.2560921907424927
Batch 11/64 loss: 0.25308436155319214
Batch 12/64 loss: 0.2510315179824829
Batch 13/64 loss: 0.2614450454711914
Batch 14/64 loss: 0.2610928416252136
Batch 15/64 loss: 0.2597774267196655
Batch 16/64 loss: 0.25662726163864136
Batch 17/64 loss: 0.2639956474304199
Batch 18/64 loss: 0.24736571311950684
Batch 19/64 loss: 0.26036810874938965
Batch 20/64 loss: 0.25518369674682617
Batch 21/64 loss: 0.2633451223373413
Batch 22/64 loss: 0.251468300819397
Batch 23/64 loss: 0.2667665481567383
Batch 24/64 loss: 0.25325220823287964
Batch 25/64 loss: 0.26842743158340454
Batch 26/64 loss: 0.2546156644821167
Batch 27/64 loss: 0.2621326446533203
Batch 28/64 loss: 0.2555614709854126
Batch 29/64 loss: 0.25914913415908813
Batch 30/64 loss: 0.2568812370300293
Batch 31/64 loss: 0.262414813041687
Batch 32/64 loss: 0.25875622034072876
Batch 33/64 loss: 0.26117265224456787
Batch 34/64 loss: 0.25284886360168457
Batch 35/64 loss: 0.2569807171821594
Batch 36/64 loss: 0.25246280431747437
Batch 37/64 loss: 0.2603888511657715
Batch 38/64 loss: 0.2567976713180542
Batch 39/64 loss: 0.2636318802833557
Batch 40/64 loss: 0.2565889358520508
Batch 41/64 loss: 0.2600109577178955
Batch 42/64 loss: 0.2572147846221924
Batch 43/64 loss: 0.253167986869812
Batch 44/64 loss: 0.2609812617301941
Batch 45/64 loss: 0.2583746910095215
Batch 46/64 loss: 0.2591821551322937
Batch 47/64 loss: 0.2587789297103882
Batch 48/64 loss: 0.2574043869972229
Batch 49/64 loss: 0.2627337574958801
Batch 50/64 loss: 0.25505518913269043
Batch 51/64 loss: 0.2547266483306885
Batch 52/64 loss: 0.2609672546386719
Batch 53/64 loss: 0.2557133436203003
Batch 54/64 loss: 0.2600046396255493
Batch 55/64 loss: 0.25514161586761475
Batch 56/64 loss: 0.2595860958099365
Batch 57/64 loss: 0.25613224506378174
Batch 58/64 loss: 0.25496888160705566
Batch 59/64 loss: 0.2553049921989441
Batch 60/64 loss: 0.2695966958999634
Batch 61/64 loss: 0.2660343647003174
Batch 62/64 loss: 0.25996899604797363
Batch 63/64 loss: 0.25857919454574585
Batch 64/64 loss: 0.270172119140625
Epoch 481  Train loss: 0.2584412425172095  Val loss: 0.3134315702104077
Epoch 482
-------------------------------
Batch 1/64 loss: 0.25310301780700684
Batch 2/64 loss: 0.2762281894683838
Batch 3/64 loss: 0.2524765133857727
Batch 4/64 loss: 0.25579094886779785
Batch 5/64 loss: 0.25051718950271606
Batch 6/64 loss: 0.25351083278656006
Batch 7/64 loss: 0.25230956077575684
Batch 8/64 loss: 0.25897789001464844
Batch 9/64 loss: 0.2594946622848511
Batch 10/64 loss: 0.25574684143066406
Batch 11/64 loss: 0.2567686438560486
Batch 12/64 loss: 0.25943076610565186
Batch 13/64 loss: 0.25744736194610596
Batch 14/64 loss: 0.2590986490249634
Batch 15/64 loss: 0.25527215003967285
Batch 16/64 loss: 0.25565415620803833
Batch 17/64 loss: 0.26428842544555664
Batch 18/64 loss: 0.25660252571105957
Batch 19/64 loss: 0.25371772050857544
Batch 20/64 loss: 0.25500404834747314
Batch 21/64 loss: 0.26593899726867676
Batch 22/64 loss: 0.2602679133415222
Batch 23/64 loss: 0.2587815523147583
Batch 24/64 loss: 0.2594943046569824
Batch 25/64 loss: 0.2685670852661133
Batch 26/64 loss: 0.25245362520217896
Batch 27/64 loss: 0.26026350259780884
Batch 28/64 loss: 0.26175403594970703
Batch 29/64 loss: 0.2559320330619812
Batch 30/64 loss: 0.25389695167541504
Batch 31/64 loss: 0.2570487856864929
Batch 32/64 loss: 0.2577844262123108
Batch 33/64 loss: 0.2658900022506714
Batch 34/64 loss: 0.257432222366333
Batch 35/64 loss: 0.25618457794189453
Batch 36/64 loss: 0.2558053731918335
Batch 37/64 loss: 0.26220273971557617
Batch 38/64 loss: 0.2570955753326416
Batch 39/64 loss: 0.2552582621574402
Batch 40/64 loss: 0.26226210594177246
Batch 41/64 loss: 0.2661008834838867
Batch 42/64 loss: 0.2564049959182739
Batch 43/64 loss: 0.2606104016304016
Batch 44/64 loss: 0.2590160369873047
Batch 45/64 loss: 0.25472068786621094
Batch 46/64 loss: 0.26293468475341797
Batch 47/64 loss: 0.26074981689453125
Batch 48/64 loss: 0.2608071565628052
Batch 49/64 loss: 0.2570309638977051
Batch 50/64 loss: 0.2594486474990845
Batch 51/64 loss: 0.25472307205200195
Batch 52/64 loss: 0.26564979553222656
Batch 53/64 loss: 0.25535112619400024
Batch 54/64 loss: 0.25416100025177
Batch 55/64 loss: 0.2604485750198364
Batch 56/64 loss: 0.256838858127594
Batch 57/64 loss: 0.2741520404815674
Batch 58/64 loss: 0.25543856620788574
Batch 59/64 loss: 0.2585817575454712
Batch 60/64 loss: 0.25097692012786865
Batch 61/64 loss: 0.25438350439071655
Batch 62/64 loss: 0.2652956247329712
Batch 63/64 loss: 0.26070845127105713
Batch 64/64 loss: 0.26462066173553467
Epoch 482  Train loss: 0.25864710948046515  Val loss: 0.31354064855378927
Epoch 483
-------------------------------
Batch 1/64 loss: 0.26471006870269775
Batch 2/64 loss: 0.2599111795425415
Batch 3/64 loss: 0.2640625834465027
Batch 4/64 loss: 0.2597659230232239
Batch 5/64 loss: 0.2638077735900879
Batch 6/64 loss: 0.25629281997680664
Batch 7/64 loss: 0.2532828450202942
Batch 8/64 loss: 0.24967753887176514
Batch 9/64 loss: 0.26179999113082886
Batch 10/64 loss: 0.26262062788009644
Batch 11/64 loss: 0.25536155700683594
Batch 12/64 loss: 0.25711965560913086
Batch 13/64 loss: 0.2545279860496521
Batch 14/64 loss: 0.2600053548812866
Batch 15/64 loss: 0.24908500909805298
Batch 16/64 loss: 0.25939977169036865
Batch 17/64 loss: 0.2517157793045044
Batch 18/64 loss: 0.2688695788383484
Batch 19/64 loss: 0.26384586095809937
Batch 20/64 loss: 0.2549675703048706
Batch 21/64 loss: 0.2584989070892334
Batch 22/64 loss: 0.25617438554763794
Batch 23/64 loss: 0.2570997476577759
Batch 24/64 loss: 0.26040196418762207
Batch 25/64 loss: 0.26259690523147583
Batch 26/64 loss: 0.2548801302909851
Batch 27/64 loss: 0.2515076994895935
Batch 28/64 loss: 0.266120970249176
Batch 29/64 loss: 0.25575441122055054
Batch 30/64 loss: 0.26138967275619507
Batch 31/64 loss: 0.26061081886291504
Batch 32/64 loss: 0.25893545150756836
Batch 33/64 loss: 0.26114076375961304
Batch 34/64 loss: 0.2536187171936035
Batch 35/64 loss: 0.24883109331130981
Batch 36/64 loss: 0.25964659452438354
Batch 37/64 loss: 0.25912487506866455
Batch 38/64 loss: 0.25371086597442627
Batch 39/64 loss: 0.253324031829834
Batch 40/64 loss: 0.26512718200683594
Batch 41/64 loss: 0.2612290382385254
Batch 42/64 loss: 0.25793522596359253
Batch 43/64 loss: 0.2603175640106201
Batch 44/64 loss: 0.26264703273773193
Batch 45/64 loss: 0.26256614923477173
Batch 46/64 loss: 0.26075899600982666
Batch 47/64 loss: 0.2540077567100525
Batch 48/64 loss: 0.25981569290161133
Batch 49/64 loss: 0.2603934407234192
Batch 50/64 loss: 0.2556837797164917
Batch 51/64 loss: 0.25525224208831787
Batch 52/64 loss: 0.26136720180511475
Batch 53/64 loss: 0.2568431496620178
Batch 54/64 loss: 0.25456786155700684
Batch 55/64 loss: 0.256735622882843
Batch 56/64 loss: 0.25258684158325195
Batch 57/64 loss: 0.25976717472076416
Batch 58/64 loss: 0.26204514503479004
Batch 59/64 loss: 0.25783443450927734
Batch 60/64 loss: 0.2627711892127991
Batch 61/64 loss: 0.2591501474380493
Batch 62/64 loss: 0.25590431690216064
Batch 63/64 loss: 0.26371198892593384
Batch 64/64 loss: 0.2582312226295471
Epoch 483  Train loss: 0.25846102074080823  Val loss: 0.3129211461421141
Epoch 484
-------------------------------
Batch 1/64 loss: 0.25730347633361816
Batch 2/64 loss: 0.2529163360595703
Batch 3/64 loss: 0.2557554244995117
Batch 4/64 loss: 0.2593870162963867
Batch 5/64 loss: 0.2547348141670227
Batch 6/64 loss: 0.2599048614501953
Batch 7/64 loss: 0.2528984546661377
Batch 8/64 loss: 0.2595294713973999
Batch 9/64 loss: 0.2572925090789795
Batch 10/64 loss: 0.25732290744781494
Batch 11/64 loss: 0.2551698684692383
Batch 12/64 loss: 0.26326608657836914
Batch 13/64 loss: 0.25996410846710205
Batch 14/64 loss: 0.26421451568603516
Batch 15/64 loss: 0.2556971311569214
Batch 16/64 loss: 0.25740551948547363
Batch 17/64 loss: 0.25577235221862793
Batch 18/64 loss: 0.2542455792427063
Batch 19/64 loss: 0.25895625352859497
Batch 20/64 loss: 0.26387906074523926
Batch 21/64 loss: 0.2585946321487427
Batch 22/64 loss: 0.25018274784088135
Batch 23/64 loss: 0.2599602937698364
Batch 24/64 loss: 0.2640726566314697
Batch 25/64 loss: 0.25828927755355835
Batch 26/64 loss: 0.25518178939819336
Batch 27/64 loss: 0.2576415538787842
Batch 28/64 loss: 0.25883591175079346
Batch 29/64 loss: 0.25723862648010254
Batch 30/64 loss: 0.2638489007949829
Batch 31/64 loss: 0.26500678062438965
Batch 32/64 loss: 0.25254130363464355
Batch 33/64 loss: 0.26432377099990845
Batch 34/64 loss: 0.25826168060302734
Batch 35/64 loss: 0.2578522562980652
Batch 36/64 loss: 0.2621802091598511
Batch 37/64 loss: 0.25997740030288696
Batch 38/64 loss: 0.24962663650512695
Batch 39/64 loss: 0.2524057626724243
Batch 40/64 loss: 0.2708228826522827
Batch 41/64 loss: 0.25995445251464844
Batch 42/64 loss: 0.2612490653991699
Batch 43/64 loss: 0.2644284963607788
Batch 44/64 loss: 0.2549089789390564
Batch 45/64 loss: 0.26239752769470215
Batch 46/64 loss: 0.2615727186203003
Batch 47/64 loss: 0.2627560496330261
Batch 48/64 loss: 0.2546313405036926
Batch 49/64 loss: 0.25650906562805176
Batch 50/64 loss: 0.2541663646697998
Batch 51/64 loss: 0.2595531940460205
Batch 52/64 loss: 0.25614047050476074
Batch 53/64 loss: 0.25565946102142334
Batch 54/64 loss: 0.26309460401535034
Batch 55/64 loss: 0.2583301067352295
Batch 56/64 loss: 0.2528945803642273
Batch 57/64 loss: 0.26534414291381836
Batch 58/64 loss: 0.2570064663887024
Batch 59/64 loss: 0.25295960903167725
Batch 60/64 loss: 0.25412142276763916
Batch 61/64 loss: 0.26470762491226196
Batch 62/64 loss: 0.25555986166000366
Batch 63/64 loss: 0.25444698333740234
Batch 64/64 loss: 0.2576359510421753
Epoch 484  Train loss: 0.258322829358718  Val loss: 0.3124454027598666
Epoch 485
-------------------------------
Batch 1/64 loss: 0.2631450295448303
Batch 2/64 loss: 0.25780415534973145
Batch 3/64 loss: 0.25390899181365967
Batch 4/64 loss: 0.26161491870880127
Batch 5/64 loss: 0.2591475248336792
Batch 6/64 loss: 0.25542449951171875
Batch 7/64 loss: 0.25612789392471313
Batch 8/64 loss: 0.26018762588500977
Batch 9/64 loss: 0.2514611482620239
Batch 10/64 loss: 0.2588043808937073
Batch 11/64 loss: 0.2533113360404968
Batch 12/64 loss: 0.25476038455963135
Batch 13/64 loss: 0.25393354892730713
Batch 14/64 loss: 0.24843990802764893
Batch 15/64 loss: 0.2538778781890869
Batch 16/64 loss: 0.258447527885437
Batch 17/64 loss: 0.25650960206985474
Batch 18/64 loss: 0.26242339611053467
Batch 19/64 loss: 0.25425004959106445
Batch 20/64 loss: 0.24982768297195435
Batch 21/64 loss: 0.2662842273712158
Batch 22/64 loss: 0.2537897229194641
Batch 23/64 loss: 0.25601285696029663
Batch 24/64 loss: 0.25212323665618896
Batch 25/64 loss: 0.26162707805633545
Batch 26/64 loss: 0.25713443756103516
Batch 27/64 loss: 0.2605968713760376
Batch 28/64 loss: 0.2606997489929199
Batch 29/64 loss: 0.25606226921081543
Batch 30/64 loss: 0.2648143172264099
Batch 31/64 loss: 0.25610125064849854
Batch 32/64 loss: 0.26503121852874756
Batch 33/64 loss: 0.2592967748641968
Batch 34/64 loss: 0.2560388445854187
Batch 35/64 loss: 0.25694501399993896
Batch 36/64 loss: 0.25317734479904175
Batch 37/64 loss: 0.2551679015159607
Batch 38/64 loss: 0.2616856098175049
Batch 39/64 loss: 0.2537892460823059
Batch 40/64 loss: 0.2574586272239685
Batch 41/64 loss: 0.26022017002105713
Batch 42/64 loss: 0.26093602180480957
Batch 43/64 loss: 0.26176220178604126
Batch 44/64 loss: 0.2575054168701172
Batch 45/64 loss: 0.2643706798553467
Batch 46/64 loss: 0.24866652488708496
Batch 47/64 loss: 0.2537877559661865
Batch 48/64 loss: 0.25391262769699097
Batch 49/64 loss: 0.2572951912879944
Batch 50/64 loss: 0.2599179744720459
Batch 51/64 loss: 0.26196444034576416
Batch 52/64 loss: 0.2530796527862549
Batch 53/64 loss: 0.2580404281616211
Batch 54/64 loss: 0.25753140449523926
Batch 55/64 loss: 0.2535889148712158
Batch 56/64 loss: 0.26046979427337646
Batch 57/64 loss: 0.2583186626434326
Batch 58/64 loss: 0.25708407163619995
Batch 59/64 loss: 0.26286739110946655
Batch 60/64 loss: 0.26059532165527344
Batch 61/64 loss: 0.25410735607147217
Batch 62/64 loss: 0.26257050037384033
Batch 63/64 loss: 0.26765042543411255
Batch 64/64 loss: 0.26252150535583496
Epoch 485  Train loss: 0.25773142178853353  Val loss: 0.3138890290997692
Epoch 486
-------------------------------
Batch 1/64 loss: 0.25669294595718384
Batch 2/64 loss: 0.25974416732788086
Batch 3/64 loss: 0.2539828419685364
Batch 4/64 loss: 0.25215375423431396
Batch 5/64 loss: 0.26316583156585693
Batch 6/64 loss: 0.2560299038887024
Batch 7/64 loss: 0.25838834047317505
Batch 8/64 loss: 0.2583967447280884
Batch 9/64 loss: 0.2598796486854553
Batch 10/64 loss: 0.25469541549682617
Batch 11/64 loss: 0.2614043951034546
Batch 12/64 loss: 0.25732165575027466
Batch 13/64 loss: 0.25809454917907715
Batch 14/64 loss: 0.26080089807510376
Batch 15/64 loss: 0.2540055513381958
Batch 16/64 loss: 0.25585120916366577
Batch 17/64 loss: 0.2605958580970764
Batch 18/64 loss: 0.24941003322601318
Batch 19/64 loss: 0.2547893524169922
Batch 20/64 loss: 0.2568402886390686
Batch 21/64 loss: 0.257843017578125
Batch 22/64 loss: 0.25619208812713623
Batch 23/64 loss: 0.2517584562301636
Batch 24/64 loss: 0.25874418020248413
Batch 25/64 loss: 0.2547217607498169
Batch 26/64 loss: 0.2552805542945862
Batch 27/64 loss: 0.2575703263282776
Batch 28/64 loss: 0.254275918006897
Batch 29/64 loss: 0.26087498664855957
Batch 30/64 loss: 0.25752121210098267
Batch 31/64 loss: 0.260921835899353
Batch 32/64 loss: 0.26024478673934937
Batch 33/64 loss: 0.2623635530471802
Batch 34/64 loss: 0.2579573392868042
Batch 35/64 loss: 0.25615668296813965
Batch 36/64 loss: 0.25976938009262085
Batch 37/64 loss: 0.2565518617630005
Batch 38/64 loss: 0.25671231746673584
Batch 39/64 loss: 0.2566184401512146
Batch 40/64 loss: 0.2573699951171875
Batch 41/64 loss: 0.26076745986938477
Batch 42/64 loss: 0.257976770401001
Batch 43/64 loss: 0.256985068321228
Batch 44/64 loss: 0.25415390729904175
Batch 45/64 loss: 0.2607164978981018
Batch 46/64 loss: 0.25386476516723633
Batch 47/64 loss: 0.26509445905685425
Batch 48/64 loss: 0.2564495801925659
Batch 49/64 loss: 0.2639932632446289
Batch 50/64 loss: 0.26387131214141846
Batch 51/64 loss: 0.2517619729042053
Batch 52/64 loss: 0.267985463142395
Batch 53/64 loss: 0.25946176052093506
Batch 54/64 loss: 0.2553824186325073
Batch 55/64 loss: 0.26135241985321045
Batch 56/64 loss: 0.2532757520675659
Batch 57/64 loss: 0.25733816623687744
Batch 58/64 loss: 0.2552056312561035
Batch 59/64 loss: 0.25498807430267334
Batch 60/64 loss: 0.25114911794662476
Batch 61/64 loss: 0.2603384256362915
Batch 62/64 loss: 0.25401806831359863
Batch 63/64 loss: 0.2596745491027832
Batch 64/64 loss: 0.2686498165130615
Epoch 486  Train loss: 0.2577095583373425  Val loss: 0.31262541308845443
Epoch 487
-------------------------------
Batch 1/64 loss: 0.2536371350288391
Batch 2/64 loss: 0.2520129680633545
Batch 3/64 loss: 0.2523680329322815
Batch 4/64 loss: 0.2581518888473511
Batch 5/64 loss: 0.26065272092819214
Batch 6/64 loss: 0.25312674045562744
Batch 7/64 loss: 0.2564280033111572
Batch 8/64 loss: 0.26045769453048706
Batch 9/64 loss: 0.25712162256240845
Batch 10/64 loss: 0.25566738843917847
Batch 11/64 loss: 0.25982534885406494
Batch 12/64 loss: 0.26057273149490356
Batch 13/64 loss: 0.25899171829223633
Batch 14/64 loss: 0.2607980966567993
Batch 15/64 loss: 0.25483977794647217
Batch 16/64 loss: 0.25648820400238037
Batch 17/64 loss: 0.25696247816085815
Batch 18/64 loss: 0.2593833804130554
Batch 19/64 loss: 0.2563908100128174
Batch 20/64 loss: 0.25416767597198486
Batch 21/64 loss: 0.2558007836341858
Batch 22/64 loss: 0.2593930959701538
Batch 23/64 loss: 0.25178229808807373
Batch 24/64 loss: 0.2703399062156677
Batch 25/64 loss: 0.2618623971939087
Batch 26/64 loss: 0.25587892532348633
Batch 27/64 loss: 0.260270357131958
Batch 28/64 loss: 0.2524540424346924
Batch 29/64 loss: 0.2584076523780823
Batch 30/64 loss: 0.2508889436721802
Batch 31/64 loss: 0.24959534406661987
Batch 32/64 loss: 0.2552051544189453
Batch 33/64 loss: 0.25849229097366333
Batch 34/64 loss: 0.26011669635772705
Batch 35/64 loss: 0.25735342502593994
Batch 36/64 loss: 0.25778794288635254
Batch 37/64 loss: 0.2575300931930542
Batch 38/64 loss: 0.2694004774093628
Batch 39/64 loss: 0.2620841860771179
Batch 40/64 loss: 0.2505446672439575
Batch 41/64 loss: 0.2534902095794678
Batch 42/64 loss: 0.2582167387008667
Batch 43/64 loss: 0.2621338367462158
Batch 44/64 loss: 0.2621923089027405
Batch 45/64 loss: 0.2659757137298584
Batch 46/64 loss: 0.2607278823852539
Batch 47/64 loss: 0.2664217948913574
Batch 48/64 loss: 0.2553366422653198
Batch 49/64 loss: 0.2650068402290344
Batch 50/64 loss: 0.25796592235565186
Batch 51/64 loss: 0.25551551580429077
Batch 52/64 loss: 0.2547076344490051
Batch 53/64 loss: 0.2564358711242676
Batch 54/64 loss: 0.2528650164604187
Batch 55/64 loss: 0.2584981322288513
Batch 56/64 loss: 0.2640400528907776
Batch 57/64 loss: 0.255376398563385
Batch 58/64 loss: 0.2613864541053772
Batch 59/64 loss: 0.2592005133628845
Batch 60/64 loss: 0.2607380151748657
Batch 61/64 loss: 0.25819122791290283
Batch 62/64 loss: 0.2624666690826416
Batch 63/64 loss: 0.25967490673065186
Batch 64/64 loss: 0.2548542618751526
Epoch 487  Train loss: 0.2580539308342279  Val loss: 0.31304944339896396
Epoch 488
-------------------------------
Batch 1/64 loss: 0.26749157905578613
Batch 2/64 loss: 0.25463807582855225
Batch 3/64 loss: 0.2532147765159607
Batch 4/64 loss: 0.2614504098892212
Batch 5/64 loss: 0.25961118936538696
Batch 6/64 loss: 0.25623685121536255
Batch 7/64 loss: 0.2646412253379822
Batch 8/64 loss: 0.2628978490829468
Batch 9/64 loss: 0.25992071628570557
Batch 10/64 loss: 0.2523869276046753
Batch 11/64 loss: 0.25734424591064453
Batch 12/64 loss: 0.25515425205230713
Batch 13/64 loss: 0.2567417025566101
Batch 14/64 loss: 0.2642832398414612
Batch 15/64 loss: 0.2565845847129822
Batch 16/64 loss: 0.25313735008239746
Batch 17/64 loss: 0.2558481693267822
Batch 18/64 loss: 0.25838565826416016
Batch 19/64 loss: 0.2533766031265259
Batch 20/64 loss: 0.2515057921409607
Batch 21/64 loss: 0.2626161575317383
Batch 22/64 loss: 0.25379478931427
Batch 23/64 loss: 0.2541810870170593
Batch 24/64 loss: 0.25293397903442383
Batch 25/64 loss: 0.25403451919555664
Batch 26/64 loss: 0.2607910633087158
Batch 27/64 loss: 0.25564610958099365
Batch 28/64 loss: 0.2571266293525696
Batch 29/64 loss: 0.2539186477661133
Batch 30/64 loss: 0.2673243284225464
Batch 31/64 loss: 0.26243317127227783
Batch 32/64 loss: 0.2602771520614624
Batch 33/64 loss: 0.2564828395843506
Batch 34/64 loss: 0.2565253973007202
Batch 35/64 loss: 0.2596375346183777
Batch 36/64 loss: 0.25836795568466187
Batch 37/64 loss: 0.2548903226852417
Batch 38/64 loss: 0.2534092664718628
Batch 39/64 loss: 0.2606508135795593
Batch 40/64 loss: 0.2592710852622986
Batch 41/64 loss: 0.2503246068954468
Batch 42/64 loss: 0.25374603271484375
Batch 43/64 loss: 0.25461262464523315
Batch 44/64 loss: 0.2557125687599182
Batch 45/64 loss: 0.2593386173248291
Batch 46/64 loss: 0.26460254192352295
Batch 47/64 loss: 0.2551094889640808
Batch 48/64 loss: 0.25196337699890137
Batch 49/64 loss: 0.2533265948295593
Batch 50/64 loss: 0.24978935718536377
Batch 51/64 loss: 0.259385347366333
Batch 52/64 loss: 0.263122022151947
Batch 53/64 loss: 0.26299476623535156
Batch 54/64 loss: 0.2565042972564697
Batch 55/64 loss: 0.26176297664642334
Batch 56/64 loss: 0.2553265690803528
Batch 57/64 loss: 0.2557016611099243
Batch 58/64 loss: 0.2594515085220337
Batch 59/64 loss: 0.26372629404067993
Batch 60/64 loss: 0.25906944274902344
Batch 61/64 loss: 0.2534416913986206
Batch 62/64 loss: 0.25447243452072144
Batch 63/64 loss: 0.2574737071990967
Batch 64/64 loss: 0.2603604197502136
Epoch 488  Train loss: 0.25749635906780466  Val loss: 0.31344671327223894
Epoch 489
-------------------------------
Batch 1/64 loss: 0.25218695402145386
Batch 2/64 loss: 0.261451780796051
Batch 3/64 loss: 0.2591804265975952
Batch 4/64 loss: 0.2587233781814575
Batch 5/64 loss: 0.2649039030075073
Batch 6/64 loss: 0.25430047512054443
Batch 7/64 loss: 0.2590867280960083
Batch 8/64 loss: 0.2636191248893738
Batch 9/64 loss: 0.25706326961517334
Batch 10/64 loss: 0.24962222576141357
Batch 11/64 loss: 0.2702568769454956
Batch 12/64 loss: 0.26078492403030396
Batch 13/64 loss: 0.2541382908821106
Batch 14/64 loss: 0.26231586933135986
Batch 15/64 loss: 0.25556039810180664
Batch 16/64 loss: 0.2534409165382385
Batch 17/64 loss: 0.25573790073394775
Batch 18/64 loss: 0.24890875816345215
Batch 19/64 loss: 0.2550368309020996
Batch 20/64 loss: 0.25850778818130493
Batch 21/64 loss: 0.2582662105560303
Batch 22/64 loss: 0.25414156913757324
Batch 23/64 loss: 0.2614736557006836
Batch 24/64 loss: 0.25897932052612305
Batch 25/64 loss: 0.2557753324508667
Batch 26/64 loss: 0.25877439975738525
Batch 27/64 loss: 0.260303795337677
Batch 28/64 loss: 0.25595390796661377
Batch 29/64 loss: 0.2590988874435425
Batch 30/64 loss: 0.260337233543396
Batch 31/64 loss: 0.2552753686904907
Batch 32/64 loss: 0.25037431716918945
Batch 33/64 loss: 0.25195252895355225
Batch 34/64 loss: 0.2531132102012634
Batch 35/64 loss: 0.25949692726135254
Batch 36/64 loss: 0.2608129382133484
Batch 37/64 loss: 0.24869948625564575
Batch 38/64 loss: 0.26537859439849854
Batch 39/64 loss: 0.2615298628807068
Batch 40/64 loss: 0.2547798156738281
Batch 41/64 loss: 0.25378143787384033
Batch 42/64 loss: 0.2526198625564575
Batch 43/64 loss: 0.2516993284225464
Batch 44/64 loss: 0.25762051343917847
Batch 45/64 loss: 0.2614738941192627
Batch 46/64 loss: 0.2685512900352478
Batch 47/64 loss: 0.25485169887542725
Batch 48/64 loss: 0.26278090476989746
Batch 49/64 loss: 0.25351154804229736
Batch 50/64 loss: 0.2578279376029968
Batch 51/64 loss: 0.26311707496643066
Batch 52/64 loss: 0.2633765935897827
Batch 53/64 loss: 0.26547718048095703
Batch 54/64 loss: 0.25386571884155273
Batch 55/64 loss: 0.25953543186187744
Batch 56/64 loss: 0.2584031820297241
Batch 57/64 loss: 0.25843119621276855
Batch 58/64 loss: 0.25427573919296265
Batch 59/64 loss: 0.25484907627105713
Batch 60/64 loss: 0.2621909976005554
Batch 61/64 loss: 0.25643062591552734
Batch 62/64 loss: 0.2620103359222412
Batch 63/64 loss: 0.2611585259437561
Batch 64/64 loss: 0.2584555149078369
Epoch 489  Train loss: 0.2578984456903794  Val loss: 0.3123142444800675
Epoch 490
-------------------------------
Batch 1/64 loss: 0.25815528631210327
Batch 2/64 loss: 0.2593357563018799
Batch 3/64 loss: 0.2654445171356201
Batch 4/64 loss: 0.2574578523635864
Batch 5/64 loss: 0.2676060199737549
Batch 6/64 loss: 0.2584565281867981
Batch 7/64 loss: 0.2513759136199951
Batch 8/64 loss: 0.2537097930908203
Batch 9/64 loss: 0.25464320182800293
Batch 10/64 loss: 0.25345027446746826
Batch 11/64 loss: 0.25444644689559937
Batch 12/64 loss: 0.26494401693344116
Batch 13/64 loss: 0.2562105655670166
Batch 14/64 loss: 0.2593918442726135
Batch 15/64 loss: 0.25323057174682617
Batch 16/64 loss: 0.2536594867706299
Batch 17/64 loss: 0.26540911197662354
Batch 18/64 loss: 0.253084659576416
Batch 19/64 loss: 0.2601569890975952
Batch 20/64 loss: 0.2528839111328125
Batch 21/64 loss: 0.25279635190963745
Batch 22/64 loss: 0.25259673595428467
Batch 23/64 loss: 0.2674292325973511
Batch 24/64 loss: 0.26421403884887695
Batch 25/64 loss: 0.26169073581695557
Batch 26/64 loss: 0.25150883197784424
Batch 27/64 loss: 0.26495158672332764
Batch 28/64 loss: 0.25834953784942627
Batch 29/64 loss: 0.2588467001914978
Batch 30/64 loss: 0.26940011978149414
Batch 31/64 loss: 0.2636549472808838
Batch 32/64 loss: 0.2590651512145996
Batch 33/64 loss: 0.2559714913368225
Batch 34/64 loss: 0.2568977475166321
Batch 35/64 loss: 0.25443559885025024
Batch 36/64 loss: 0.2663768529891968
Batch 37/64 loss: 0.2614211440086365
Batch 38/64 loss: 0.25279903411865234
Batch 39/64 loss: 0.2504723072052002
Batch 40/64 loss: 0.2561313509941101
Batch 41/64 loss: 0.2524029016494751
Batch 42/64 loss: 0.25729161500930786
Batch 43/64 loss: 0.2572976350784302
Batch 44/64 loss: 0.253757119178772
Batch 45/64 loss: 0.25566697120666504
Batch 46/64 loss: 0.257546603679657
Batch 47/64 loss: 0.26205718517303467
Batch 48/64 loss: 0.26093626022338867
Batch 49/64 loss: 0.26155102252960205
Batch 50/64 loss: 0.25440067052841187
Batch 51/64 loss: 0.2562364339828491
Batch 52/64 loss: 0.25640201568603516
Batch 53/64 loss: 0.2491784691810608
Batch 54/64 loss: 0.26294463872909546
Batch 55/64 loss: 0.2654511332511902
Batch 56/64 loss: 0.26205968856811523
Batch 57/64 loss: 0.25849783420562744
Batch 58/64 loss: 0.2561689615249634
Batch 59/64 loss: 0.25282442569732666
Batch 60/64 loss: 0.26284199953079224
Batch 61/64 loss: 0.26147377490997314
Batch 62/64 loss: 0.25300025939941406
Batch 63/64 loss: 0.25177013874053955
Batch 64/64 loss: 0.2692650556564331
Epoch 490  Train loss: 0.25812970656974643  Val loss: 0.31289241567919757
Epoch 491
-------------------------------
Batch 1/64 loss: 0.2535492181777954
Batch 2/64 loss: 0.25829505920410156
Batch 3/64 loss: 0.25776493549346924
Batch 4/64 loss: 0.2537936568260193
Batch 5/64 loss: 0.2613072395324707
Batch 6/64 loss: 0.25007545948028564
Batch 7/64 loss: 0.25851118564605713
Batch 8/64 loss: 0.25799500942230225
Batch 9/64 loss: 0.25843346118927
Batch 10/64 loss: 0.251064658164978
Batch 11/64 loss: 0.26271843910217285
Batch 12/64 loss: 0.2570607662200928
Batch 13/64 loss: 0.25904780626296997
Batch 14/64 loss: 0.2574678063392639
Batch 15/64 loss: 0.2588491439819336
Batch 16/64 loss: 0.25699901580810547
Batch 17/64 loss: 0.26294732093811035
Batch 18/64 loss: 0.2519327402114868
Batch 19/64 loss: 0.25543510913848877
Batch 20/64 loss: 0.2568318843841553
Batch 21/64 loss: 0.2552714943885803
Batch 22/64 loss: 0.26176464557647705
Batch 23/64 loss: 0.2530325651168823
Batch 24/64 loss: 0.258573055267334
Batch 25/64 loss: 0.2589648365974426
Batch 26/64 loss: 0.2647162675857544
Batch 27/64 loss: 0.25213146209716797
Batch 28/64 loss: 0.26028144359588623
Batch 29/64 loss: 0.2687886953353882
Batch 30/64 loss: 0.25873005390167236
Batch 31/64 loss: 0.2578650712966919
Batch 32/64 loss: 0.25544077157974243
Batch 33/64 loss: 0.2547184228897095
Batch 34/64 loss: 0.25918257236480713
Batch 35/64 loss: 0.2683318853378296
Batch 36/64 loss: 0.2547246813774109
Batch 37/64 loss: 0.2552618384361267
Batch 38/64 loss: 0.2578698396682739
Batch 39/64 loss: 0.26723170280456543
Batch 40/64 loss: 0.2616894245147705
Batch 41/64 loss: 0.2542117238044739
Batch 42/64 loss: 0.25828778743743896
Batch 43/64 loss: 0.25659608840942383
Batch 44/64 loss: 0.256481409072876
Batch 45/64 loss: 0.25771039724349976
Batch 46/64 loss: 0.2573815584182739
Batch 47/64 loss: 0.2648390531539917
Batch 48/64 loss: 0.26378709077835083
Batch 49/64 loss: 0.2563539743423462
Batch 50/64 loss: 0.25202417373657227
Batch 51/64 loss: 0.26711606979370117
Batch 52/64 loss: 0.2555283308029175
Batch 53/64 loss: 0.2551478147506714
Batch 54/64 loss: 0.2586287260055542
Batch 55/64 loss: 0.25634390115737915
Batch 56/64 loss: 0.263413667678833
Batch 57/64 loss: 0.2751292586326599
Batch 58/64 loss: 0.2547018527984619
Batch 59/64 loss: 0.2617316246032715
Batch 60/64 loss: 0.2556094527244568
Batch 61/64 loss: 0.25888174772262573
Batch 62/64 loss: 0.2547258138656616
Batch 63/64 loss: 0.2647218704223633
Batch 64/64 loss: 0.2637453079223633
Epoch 491  Train loss: 0.2585382433498607  Val loss: 0.31243201567954626
Epoch 492
-------------------------------
Batch 1/64 loss: 0.2657116651535034
Batch 2/64 loss: 0.2637288570404053
Batch 3/64 loss: 0.2570754885673523
Batch 4/64 loss: 0.2695794701576233
Batch 5/64 loss: 0.25438833236694336
Batch 6/64 loss: 0.2567950487136841
Batch 7/64 loss: 0.25877177715301514
Batch 8/64 loss: 0.2509208917617798
Batch 9/64 loss: 0.258811891078949
Batch 10/64 loss: 0.25073957443237305
Batch 11/64 loss: 0.25227463245391846
Batch 12/64 loss: 0.25247544050216675
Batch 13/64 loss: 0.25682181119918823
Batch 14/64 loss: 0.2605031728744507
Batch 15/64 loss: 0.2553461790084839
Batch 16/64 loss: 0.25760984420776367
Batch 17/64 loss: 0.25757062435150146
Batch 18/64 loss: 0.24859803915023804
Batch 19/64 loss: 0.2580261826515198
Batch 20/64 loss: 0.25613486766815186
Batch 21/64 loss: 0.25238120555877686
Batch 22/64 loss: 0.2551145553588867
Batch 23/64 loss: 0.25081002712249756
Batch 24/64 loss: 0.2536274194717407
Batch 25/64 loss: 0.2533373236656189
Batch 26/64 loss: 0.25957024097442627
Batch 27/64 loss: 0.2555196285247803
Batch 28/64 loss: 0.2572367191314697
Batch 29/64 loss: 0.25021064281463623
Batch 30/64 loss: 0.2578628659248352
Batch 31/64 loss: 0.25922060012817383
Batch 32/64 loss: 0.2545134425163269
Batch 33/64 loss: 0.25343263149261475
Batch 34/64 loss: 0.25234222412109375
Batch 35/64 loss: 0.2514575719833374
Batch 36/64 loss: 0.2606912851333618
Batch 37/64 loss: 0.2642631530761719
Batch 38/64 loss: 0.25804245471954346
Batch 39/64 loss: 0.2578251361846924
Batch 40/64 loss: 0.2611842155456543
Batch 41/64 loss: 0.2599320411682129
Batch 42/64 loss: 0.26185572147369385
Batch 43/64 loss: 0.2569422721862793
Batch 44/64 loss: 0.25796425342559814
Batch 45/64 loss: 0.2583981156349182
Batch 46/64 loss: 0.25759583711624146
Batch 47/64 loss: 0.2604854702949524
Batch 48/64 loss: 0.25248193740844727
Batch 49/64 loss: 0.2627357244491577
Batch 50/64 loss: 0.2589837312698364
Batch 51/64 loss: 0.25715434551239014
Batch 52/64 loss: 0.2622959613800049
Batch 53/64 loss: 0.26515674591064453
Batch 54/64 loss: 0.2631641626358032
Batch 55/64 loss: 0.2557946443557739
Batch 56/64 loss: 0.2556138038635254
Batch 57/64 loss: 0.2570701837539673
Batch 58/64 loss: 0.26129651069641113
Batch 59/64 loss: 0.26370811462402344
Batch 60/64 loss: 0.26386380195617676
Batch 61/64 loss: 0.2608987092971802
Batch 62/64 loss: 0.2573390007019043
Batch 63/64 loss: 0.2593873143196106
Batch 64/64 loss: 0.26889562606811523
Epoch 492  Train loss: 0.2577618393243528  Val loss: 0.31325339533619045
Epoch 493
-------------------------------
Batch 1/64 loss: 0.27210527658462524
Batch 2/64 loss: 0.2621101140975952
Batch 3/64 loss: 0.25194013118743896
Batch 4/64 loss: 0.2505767345428467
Batch 5/64 loss: 0.2569462060928345
Batch 6/64 loss: 0.25598978996276855
Batch 7/64 loss: 0.2652919292449951
Batch 8/64 loss: 0.25830721855163574
Batch 9/64 loss: 0.2543494701385498
Batch 10/64 loss: 0.2575702667236328
Batch 11/64 loss: 0.25619304180145264
Batch 12/64 loss: 0.2580064535140991
Batch 13/64 loss: 0.25711381435394287
Batch 14/64 loss: 0.25724124908447266
Batch 15/64 loss: 0.260811448097229
Batch 16/64 loss: 0.2603968381881714
Batch 17/64 loss: 0.2651820182800293
Batch 18/64 loss: 0.2563706040382385
Batch 19/64 loss: 0.2601892352104187
Batch 20/64 loss: 0.257686972618103
Batch 21/64 loss: 0.2560238838195801
Batch 22/64 loss: 0.26138025522232056
Batch 23/64 loss: 0.25669968128204346
Batch 24/64 loss: 0.2566581964492798
Batch 25/64 loss: 0.25879013538360596
Batch 26/64 loss: 0.2573949694633484
Batch 27/64 loss: 0.26701343059539795
Batch 28/64 loss: 0.26091182231903076
Batch 29/64 loss: 0.265275239944458
Batch 30/64 loss: 0.2557491660118103
Batch 31/64 loss: 0.26370012760162354
Batch 32/64 loss: 0.25698739290237427
Batch 33/64 loss: 0.264981746673584
Batch 34/64 loss: 0.2536579370498657
Batch 35/64 loss: 0.26007580757141113
Batch 36/64 loss: 0.25924885272979736
Batch 37/64 loss: 0.2706104516983032
Batch 38/64 loss: 0.2563459873199463
Batch 39/64 loss: 0.25624901056289673
Batch 40/64 loss: 0.26664382219314575
Batch 41/64 loss: 0.253329873085022
Batch 42/64 loss: 0.2588611841201782
Batch 43/64 loss: 0.2558579444885254
Batch 44/64 loss: 0.2538452744483948
Batch 45/64 loss: 0.25300514698028564
Batch 46/64 loss: 0.2641260623931885
Batch 47/64 loss: 0.257099449634552
Batch 48/64 loss: 0.2557032108306885
Batch 49/64 loss: 0.26287275552749634
Batch 50/64 loss: 0.24936127662658691
Batch 51/64 loss: 0.25317996740341187
Batch 52/64 loss: 0.25616455078125
Batch 53/64 loss: 0.2647068500518799
Batch 54/64 loss: 0.2583049535751343
Batch 55/64 loss: 0.25316905975341797
Batch 56/64 loss: 0.2571471929550171
Batch 57/64 loss: 0.25321894884109497
Batch 58/64 loss: 0.25600767135620117
Batch 59/64 loss: 0.2595841884613037
Batch 60/64 loss: 0.25882089138031006
Batch 61/64 loss: 0.2584209442138672
Batch 62/64 loss: 0.26272428035736084
Batch 63/64 loss: 0.2583979368209839
Batch 64/64 loss: 0.26402604579925537
Epoch 493  Train loss: 0.2586777392555686  Val loss: 0.3134106481607837
Epoch 494
-------------------------------
Batch 1/64 loss: 0.25943946838378906
Batch 2/64 loss: 0.24894118309020996
Batch 3/64 loss: 0.2584684491157532
Batch 4/64 loss: 0.25519806146621704
Batch 5/64 loss: 0.2532886862754822
Batch 6/64 loss: 0.2574807405471802
Batch 7/64 loss: 0.2526642680168152
Batch 8/64 loss: 0.2574777603149414
Batch 9/64 loss: 0.25461137294769287
Batch 10/64 loss: 0.2608225345611572
Batch 11/64 loss: 0.24897003173828125
Batch 12/64 loss: 0.2542036771774292
Batch 13/64 loss: 0.25528281927108765
Batch 14/64 loss: 0.25497156381607056
Batch 15/64 loss: 0.2614203691482544
Batch 16/64 loss: 0.2563045024871826
Batch 17/64 loss: 0.24865186214447021
Batch 18/64 loss: 0.250943660736084
Batch 19/64 loss: 0.2543010711669922
Batch 20/64 loss: 0.2530854344367981
Batch 21/64 loss: 0.25622057914733887
Batch 22/64 loss: 0.2579984664916992
Batch 23/64 loss: 0.25490641593933105
Batch 24/64 loss: 0.26048052310943604
Batch 25/64 loss: 0.2519564628601074
Batch 26/64 loss: 0.2603718638420105
Batch 27/64 loss: 0.25820714235305786
Batch 28/64 loss: 0.26060938835144043
Batch 29/64 loss: 0.2520942687988281
Batch 30/64 loss: 0.25656354427337646
Batch 31/64 loss: 0.2561001777648926
Batch 32/64 loss: 0.25325167179107666
Batch 33/64 loss: 0.264914870262146
Batch 34/64 loss: 0.2558252811431885
Batch 35/64 loss: 0.26183223724365234
Batch 36/64 loss: 0.25676876306533813
Batch 37/64 loss: 0.2665809392929077
Batch 38/64 loss: 0.265730082988739
Batch 39/64 loss: 0.25977712869644165
Batch 40/64 loss: 0.2634655237197876
Batch 41/64 loss: 0.2587866187095642
Batch 42/64 loss: 0.25631582736968994
Batch 43/64 loss: 0.2535538673400879
Batch 44/64 loss: 0.26136505603790283
Batch 45/64 loss: 0.26764029264450073
Batch 46/64 loss: 0.25962090492248535
Batch 47/64 loss: 0.26821696758270264
Batch 48/64 loss: 0.2560298442840576
Batch 49/64 loss: 0.25245344638824463
Batch 50/64 loss: 0.25720810890197754
Batch 51/64 loss: 0.2670416831970215
Batch 52/64 loss: 0.2549191117286682
Batch 53/64 loss: 0.26171499490737915
Batch 54/64 loss: 0.2528584599494934
Batch 55/64 loss: 0.25946760177612305
Batch 56/64 loss: 0.2560963034629822
Batch 57/64 loss: 0.26153409481048584
Batch 58/64 loss: 0.26295894384384155
Batch 59/64 loss: 0.25650840997695923
Batch 60/64 loss: 0.26430338621139526
Batch 61/64 loss: 0.26017510890960693
Batch 62/64 loss: 0.2645103931427002
Batch 63/64 loss: 0.2608381509780884
Batch 64/64 loss: 0.26351457834243774
Epoch 494  Train loss: 0.2579127271970113  Val loss: 0.3124010833268313
Epoch 495
-------------------------------
Batch 1/64 loss: 0.26383841037750244
Batch 2/64 loss: 0.2540208697319031
Batch 3/64 loss: 0.25298410654067993
Batch 4/64 loss: 0.25671565532684326
Batch 5/64 loss: 0.2568807005882263
Batch 6/64 loss: 0.2556344270706177
Batch 7/64 loss: 0.2573710083961487
Batch 8/64 loss: 0.2545056939125061
Batch 9/64 loss: 0.24883127212524414
Batch 10/64 loss: 0.25930625200271606
Batch 11/64 loss: 0.25605452060699463
Batch 12/64 loss: 0.25530725717544556
Batch 13/64 loss: 0.25461745262145996
Batch 14/64 loss: 0.2633335590362549
Batch 15/64 loss: 0.2534991502761841
Batch 16/64 loss: 0.26452386379241943
Batch 17/64 loss: 0.2536982297897339
Batch 18/64 loss: 0.251328706741333
Batch 19/64 loss: 0.25359946489334106
Batch 20/64 loss: 0.2525137662887573
Batch 21/64 loss: 0.2506914734840393
Batch 22/64 loss: 0.25771450996398926
Batch 23/64 loss: 0.25482040643692017
Batch 24/64 loss: 0.25166356563568115
Batch 25/64 loss: 0.2514396905899048
Batch 26/64 loss: 0.2558401823043823
Batch 27/64 loss: 0.2607957124710083
Batch 28/64 loss: 0.25898468494415283
Batch 29/64 loss: 0.25886404514312744
Batch 30/64 loss: 0.257687509059906
Batch 31/64 loss: 0.2538202404975891
Batch 32/64 loss: 0.26163971424102783
Batch 33/64 loss: 0.2573636770248413
Batch 34/64 loss: 0.25838154554367065
Batch 35/64 loss: 0.2611040472984314
Batch 36/64 loss: 0.25806093215942383
Batch 37/64 loss: 0.2600630521774292
Batch 38/64 loss: 0.2573986053466797
Batch 39/64 loss: 0.2549143433570862
Batch 40/64 loss: 0.2556450366973877
Batch 41/64 loss: 0.2534274458885193
Batch 42/64 loss: 0.2543485164642334
Batch 43/64 loss: 0.2590002417564392
Batch 44/64 loss: 0.2602881193161011
Batch 45/64 loss: 0.2597630023956299
Batch 46/64 loss: 0.2742263078689575
Batch 47/64 loss: 0.25722360610961914
Batch 48/64 loss: 0.25825774669647217
Batch 49/64 loss: 0.261981725692749
Batch 50/64 loss: 0.258068323135376
Batch 51/64 loss: 0.25627994537353516
Batch 52/64 loss: 0.25475090742111206
Batch 53/64 loss: 0.2577363848686218
Batch 54/64 loss: 0.2540074586868286
Batch 55/64 loss: 0.26750433444976807
Batch 56/64 loss: 0.2519693374633789
Batch 57/64 loss: 0.26403486728668213
Batch 58/64 loss: 0.26161813735961914
Batch 59/64 loss: 0.2586720585823059
Batch 60/64 loss: 0.275134801864624
Batch 61/64 loss: 0.2532169818878174
Batch 62/64 loss: 0.26219844818115234
Batch 63/64 loss: 0.2509170174598694
Batch 64/64 loss: 0.2601321339607239
Epoch 495  Train loss: 0.25749305346432855  Val loss: 0.31306784136598464
Epoch 496
-------------------------------
Batch 1/64 loss: 0.26056522130966187
Batch 2/64 loss: 0.2580866813659668
Batch 3/64 loss: 0.2629508972167969
Batch 4/64 loss: 0.2530316710472107
Batch 5/64 loss: 0.2565878629684448
Batch 6/64 loss: 0.264484167098999
Batch 7/64 loss: 0.2536318302154541
Batch 8/64 loss: 0.25176262855529785
Batch 9/64 loss: 0.25527113676071167
Batch 10/64 loss: 0.25660276412963867
Batch 11/64 loss: 0.2520132064819336
Batch 12/64 loss: 0.25583982467651367
Batch 13/64 loss: 0.2595994472503662
Batch 14/64 loss: 0.2579900026321411
Batch 15/64 loss: 0.25485002994537354
Batch 16/64 loss: 0.2567833662033081
Batch 17/64 loss: 0.252510666847229
Batch 18/64 loss: 0.2631506323814392
Batch 19/64 loss: 0.2635396718978882
Batch 20/64 loss: 0.2657099962234497
Batch 21/64 loss: 0.2566492557525635
Batch 22/64 loss: 0.2514955997467041
Batch 23/64 loss: 0.2531944513320923
Batch 24/64 loss: 0.2621341347694397
Batch 25/64 loss: 0.2537965774536133
Batch 26/64 loss: 0.258217453956604
Batch 27/64 loss: 0.25505757331848145
Batch 28/64 loss: 0.2645794749259949
Batch 29/64 loss: 0.25535058975219727
Batch 30/64 loss: 0.256594181060791
Batch 31/64 loss: 0.2639303207397461
Batch 32/64 loss: 0.25774306058883667
Batch 33/64 loss: 0.25684529542922974
Batch 34/64 loss: 0.25608956813812256
Batch 35/64 loss: 0.2576158046722412
Batch 36/64 loss: 0.2530888319015503
Batch 37/64 loss: 0.256527304649353
Batch 38/64 loss: 0.2630615234375
Batch 39/64 loss: 0.2611658573150635
Batch 40/64 loss: 0.25372231006622314
Batch 41/64 loss: 0.25229400396347046
Batch 42/64 loss: 0.2563004493713379
Batch 43/64 loss: 0.2567213773727417
Batch 44/64 loss: 0.2567177414894104
Batch 45/64 loss: 0.24686288833618164
Batch 46/64 loss: 0.254711389541626
Batch 47/64 loss: 0.25949424505233765
Batch 48/64 loss: 0.25907909870147705
Batch 49/64 loss: 0.2545352578163147
Batch 50/64 loss: 0.25280457735061646
Batch 51/64 loss: 0.25852811336517334
Batch 52/64 loss: 0.2553843855857849
Batch 53/64 loss: 0.25260525941848755
Batch 54/64 loss: 0.2604215741157532
Batch 55/64 loss: 0.2562892436981201
Batch 56/64 loss: 0.25894927978515625
Batch 57/64 loss: 0.25838589668273926
Batch 58/64 loss: 0.24746906757354736
Batch 59/64 loss: 0.2550163269042969
Batch 60/64 loss: 0.2618955373764038
Batch 61/64 loss: 0.26544272899627686
Batch 62/64 loss: 0.2662045955657959
Batch 63/64 loss: 0.25622785091400146
Batch 64/64 loss: 0.2616059184074402
Epoch 496  Train loss: 0.25726064630583223  Val loss: 0.3138230395890593
Epoch 497
-------------------------------
Batch 1/64 loss: 0.2524818181991577
Batch 2/64 loss: 0.2523282766342163
Batch 3/64 loss: 0.2601358890533447
Batch 4/64 loss: 0.25520968437194824
Batch 5/64 loss: 0.2515157461166382
Batch 6/64 loss: 0.26178061962127686
Batch 7/64 loss: 0.25577300786972046
Batch 8/64 loss: 0.2553023099899292
Batch 9/64 loss: 0.24831688404083252
Batch 10/64 loss: 0.25176870822906494
Batch 11/64 loss: 0.2499704360961914
Batch 12/64 loss: 0.25262248516082764
Batch 13/64 loss: 0.2599526047706604
Batch 14/64 loss: 0.2608846426010132
Batch 15/64 loss: 0.2629891633987427
Batch 16/64 loss: 0.2601170539855957
Batch 17/64 loss: 0.26377975940704346
Batch 18/64 loss: 0.2532625198364258
Batch 19/64 loss: 0.25157594680786133
Batch 20/64 loss: 0.25733959674835205
Batch 21/64 loss: 0.2530907392501831
Batch 22/64 loss: 0.26213598251342773
Batch 23/64 loss: 0.24886208772659302
Batch 24/64 loss: 0.2558852434158325
Batch 25/64 loss: 0.2558436989784241
Batch 26/64 loss: 0.2501249313354492
Batch 27/64 loss: 0.2650250196456909
Batch 28/64 loss: 0.26145029067993164
Batch 29/64 loss: 0.2588281035423279
Batch 30/64 loss: 0.25082927942276
Batch 31/64 loss: 0.27054911851882935
Batch 32/64 loss: 0.2603335380554199
Batch 33/64 loss: 0.2624127268791199
Batch 34/64 loss: 0.26245641708374023
Batch 35/64 loss: 0.2670285701751709
Batch 36/64 loss: 0.2586778402328491
Batch 37/64 loss: 0.2640962600708008
Batch 38/64 loss: 0.25926148891448975
Batch 39/64 loss: 0.255195677280426
Batch 40/64 loss: 0.25578737258911133
Batch 41/64 loss: 0.2603576183319092
Batch 42/64 loss: 0.2558736801147461
Batch 43/64 loss: 0.26127225160598755
Batch 44/64 loss: 0.2613709568977356
Batch 45/64 loss: 0.2571913003921509
Batch 46/64 loss: 0.258697509765625
Batch 47/64 loss: 0.2528954744338989
Batch 48/64 loss: 0.2691304683685303
Batch 49/64 loss: 0.25741350650787354
Batch 50/64 loss: 0.2559375762939453
Batch 51/64 loss: 0.25865697860717773
Batch 52/64 loss: 0.2614155411720276
Batch 53/64 loss: 0.26386284828186035
Batch 54/64 loss: 0.2608468532562256
Batch 55/64 loss: 0.2563241720199585
Batch 56/64 loss: 0.25867128372192383
Batch 57/64 loss: 0.25918084383010864
Batch 58/64 loss: 0.2538936138153076
Batch 59/64 loss: 0.2534859776496887
Batch 60/64 loss: 0.25637710094451904
Batch 61/64 loss: 0.25604695081710815
Batch 62/64 loss: 0.24955254793167114
Batch 63/64 loss: 0.25957047939300537
Batch 64/64 loss: 0.25852423906326294
Epoch 497  Train loss: 0.2576768667090173  Val loss: 0.31282656278806864
Epoch 498
-------------------------------
Batch 1/64 loss: 0.2504425048828125
Batch 2/64 loss: 0.25460588932037354
Batch 3/64 loss: 0.25751185417175293
Batch 4/64 loss: 0.25406426191329956
Batch 5/64 loss: 0.2570255994796753
Batch 6/64 loss: 0.24908983707427979
Batch 7/64 loss: 0.2719850540161133
Batch 8/64 loss: 0.2629231810569763
Batch 9/64 loss: 0.2541792392730713
Batch 10/64 loss: 0.25845909118652344
Batch 11/64 loss: 0.2606806755065918
Batch 12/64 loss: 0.24942582845687866
Batch 13/64 loss: 0.25861263275146484
Batch 14/64 loss: 0.2635642886161804
Batch 15/64 loss: 0.24831891059875488
Batch 16/64 loss: 0.2615314722061157
Batch 17/64 loss: 0.2513558864593506
Batch 18/64 loss: 0.2560821771621704
Batch 19/64 loss: 0.2533832788467407
Batch 20/64 loss: 0.2553088665008545
Batch 21/64 loss: 0.25462937355041504
Batch 22/64 loss: 0.24768757820129395
Batch 23/64 loss: 0.25520384311676025
Batch 24/64 loss: 0.2579249143600464
Batch 25/64 loss: 0.2590227723121643
Batch 26/64 loss: 0.2590451240539551
Batch 27/64 loss: 0.2556854486465454
Batch 28/64 loss: 0.2539304494857788
Batch 29/64 loss: 0.2548826336860657
Batch 30/64 loss: 0.26067858934402466
Batch 31/64 loss: 0.260001540184021
Batch 32/64 loss: 0.2514704465866089
Batch 33/64 loss: 0.2581063508987427
Batch 34/64 loss: 0.25511860847473145
Batch 35/64 loss: 0.26411014795303345
Batch 36/64 loss: 0.2595473527908325
Batch 37/64 loss: 0.2523764371871948
Batch 38/64 loss: 0.25420892238616943
Batch 39/64 loss: 0.25987398624420166
Batch 40/64 loss: 0.26250284910202026
Batch 41/64 loss: 0.2547150254249573
Batch 42/64 loss: 0.25326573848724365
Batch 43/64 loss: 0.25741416215896606
Batch 44/64 loss: 0.26974964141845703
Batch 45/64 loss: 0.25736844539642334
Batch 46/64 loss: 0.2568424344062805
Batch 47/64 loss: 0.2524394392967224
Batch 48/64 loss: 0.2500429153442383
Batch 49/64 loss: 0.2568039894104004
Batch 50/64 loss: 0.266090989112854
Batch 51/64 loss: 0.25838232040405273
Batch 52/64 loss: 0.252618670463562
Batch 53/64 loss: 0.2653132677078247
Batch 54/64 loss: 0.25720179080963135
Batch 55/64 loss: 0.2499161958694458
Batch 56/64 loss: 0.2568739652633667
Batch 57/64 loss: 0.26984041929244995
Batch 58/64 loss: 0.25727057456970215
Batch 59/64 loss: 0.2561476230621338
Batch 60/64 loss: 0.2607388496398926
Batch 61/64 loss: 0.2627031207084656
Batch 62/64 loss: 0.2549036741256714
Batch 63/64 loss: 0.256818950176239
Batch 64/64 loss: 0.24754750728607178
Epoch 498  Train loss: 0.2569989134283627  Val loss: 0.3126935549208389
Epoch 499
-------------------------------
Batch 1/64 loss: 0.24968016147613525
Batch 2/64 loss: 0.2530086040496826
Batch 3/64 loss: 0.2597586512565613
Batch 4/64 loss: 0.2580934762954712
Batch 5/64 loss: 0.2577939033508301
Batch 6/64 loss: 0.2534249424934387
Batch 7/64 loss: 0.26027369499206543
Batch 8/64 loss: 0.26438188552856445
Batch 9/64 loss: 0.25769150257110596
Batch 10/64 loss: 0.2501382827758789
Batch 11/64 loss: 0.2589770555496216
Batch 12/64 loss: 0.25104665756225586
Batch 13/64 loss: 0.2524603009223938
Batch 14/64 loss: 0.26088714599609375
Batch 15/64 loss: 0.25279927253723145
Batch 16/64 loss: 0.2676403522491455
Batch 17/64 loss: 0.2629833221435547
Batch 18/64 loss: 0.25771111249923706
Batch 19/64 loss: 0.25078439712524414
Batch 20/64 loss: 0.25056302547454834
Batch 21/64 loss: 0.2620328664779663
Batch 22/64 loss: 0.2504235506057739
Batch 23/64 loss: 0.25506365299224854
Batch 24/64 loss: 0.25772202014923096
Batch 25/64 loss: 0.25040102005004883
Batch 26/64 loss: 0.2547389268875122
Batch 27/64 loss: 0.26179277896881104
Batch 28/64 loss: 0.2573133707046509
Batch 29/64 loss: 0.24883174896240234
Batch 30/64 loss: 0.25905168056488037
Batch 31/64 loss: 0.2518671751022339
Batch 32/64 loss: 0.2689697742462158
Batch 33/64 loss: 0.2652144432067871
Batch 34/64 loss: 0.27148520946502686
Batch 35/64 loss: 0.2548816204071045
Batch 36/64 loss: 0.25545644760131836
Batch 37/64 loss: 0.2531358003616333
Batch 38/64 loss: 0.25291013717651367
Batch 39/64 loss: 0.259613573551178
Batch 40/64 loss: 0.24953413009643555
Batch 41/64 loss: 0.25339508056640625
Batch 42/64 loss: 0.2517353892326355
Batch 43/64 loss: 0.25412166118621826
Batch 44/64 loss: 0.25049614906311035
Batch 45/64 loss: 0.25515687465667725
Batch 46/64 loss: 0.2618604898452759
Batch 47/64 loss: 0.2534198760986328
Batch 48/64 loss: 0.2546449899673462
Batch 49/64 loss: 0.26168549060821533
Batch 50/64 loss: 0.2573220729827881
Batch 51/64 loss: 0.2527996301651001
Batch 52/64 loss: 0.2612344026565552
Batch 53/64 loss: 0.2587977647781372
Batch 54/64 loss: 0.2540959119796753
Batch 55/64 loss: 0.25704050064086914
Batch 56/64 loss: 0.2649890184402466
Batch 57/64 loss: 0.2572505474090576
Batch 58/64 loss: 0.25688618421554565
Batch 59/64 loss: 0.2633262276649475
Batch 60/64 loss: 0.2678765654563904
Batch 61/64 loss: 0.2541438341140747
Batch 62/64 loss: 0.25631964206695557
Batch 63/64 loss: 0.2567638158798218
Batch 64/64 loss: 0.26197540760040283
Epoch 499  Train loss: 0.25697853097728657  Val loss: 0.3130427131947783
Epoch 500
-------------------------------
Batch 1/64 loss: 0.254403293132782
Batch 2/64 loss: 0.2590395212173462
Batch 3/64 loss: 0.25813615322113037
Batch 4/64 loss: 0.2588387727737427
Batch 5/64 loss: 0.25952690839767456
Batch 6/64 loss: 0.2534334659576416
Batch 7/64 loss: 0.2530401945114136
Batch 8/64 loss: 0.2546880841255188
Batch 9/64 loss: 0.25529515743255615
Batch 10/64 loss: 0.2565234899520874
Batch 11/64 loss: 0.26172780990600586
Batch 12/64 loss: 0.2539699673652649
Batch 13/64 loss: 0.2569432258605957
Batch 14/64 loss: 0.26410233974456787
Batch 15/64 loss: 0.26282691955566406
Batch 16/64 loss: 0.25838690996170044
Batch 17/64 loss: 0.26181161403656006
Batch 18/64 loss: 0.2569284439086914
Batch 19/64 loss: 0.2548251748085022
Batch 20/64 loss: 0.2546011209487915
Batch 21/64 loss: 0.2562195062637329
Batch 22/64 loss: 0.25030601024627686
Batch 23/64 loss: 0.26183533668518066
Batch 24/64 loss: 0.2529102563858032
Batch 25/64 loss: 0.2623136043548584
Batch 26/64 loss: 0.2582437992095947
Batch 27/64 loss: 0.25327056646347046
Batch 28/64 loss: 0.25317269563674927
Batch 29/64 loss: 0.2602273225784302
Batch 30/64 loss: 0.2576543688774109
Batch 31/64 loss: 0.25877153873443604
Batch 32/64 loss: 0.25029635429382324
Batch 33/64 loss: 0.2523695230484009
Batch 34/64 loss: 0.2514392137527466
Batch 35/64 loss: 0.25431567430496216
Batch 36/64 loss: 0.2571907639503479
Batch 37/64 loss: 0.2557793855667114
Batch 38/64 loss: 0.253004789352417
Batch 39/64 loss: 0.251356303691864
Batch 40/64 loss: 0.2625272274017334
Batch 41/64 loss: 0.25281965732574463
Batch 42/64 loss: 0.25920963287353516
Batch 43/64 loss: 0.25256335735321045
Batch 44/64 loss: 0.2514636516571045
Batch 45/64 loss: 0.2546122670173645
Batch 46/64 loss: 0.26440268754959106
Batch 47/64 loss: 0.258766233921051
Batch 48/64 loss: 0.2583891749382019
Batch 49/64 loss: 0.25401538610458374
Batch 50/64 loss: 0.2521986961364746
Batch 51/64 loss: 0.2554827332496643
Batch 52/64 loss: 0.2544783353805542
Batch 53/64 loss: 0.25071293115615845
Batch 54/64 loss: 0.2619262933731079
Batch 55/64 loss: 0.26806122064590454
Batch 56/64 loss: 0.25651615858078003
Batch 57/64 loss: 0.26137733459472656
Batch 58/64 loss: 0.2576882243156433
Batch 59/64 loss: 0.26022017002105713
Batch 60/64 loss: 0.2499409317970276
Batch 61/64 loss: 0.2596730589866638
Batch 62/64 loss: 0.26698094606399536
Batch 63/64 loss: 0.25898075103759766
Batch 64/64 loss: 0.25634318590164185
Epoch 500  Train loss: 0.2568625887235006  Val loss: 0.3126416734813415
SLIC undersegmentation error: 0.05417594501718215
SLIC inter-cluster variation: 0.024008214465620577
SLIC number of superpixels: 162874
SLIC superpixels per image: 559.7044673539519
Model loaded
Test metrics:
0.3087822637197488 0.15643436426116838 12.068800376383377 tensor(0.0931, dtype=torch.float64) 0.34078512592686283 1.5135412878847765 63251
Inference time: 0.005515790886895354 seconds
Relabeled undersegmentation error: 0.09275189003436425
Relabeled inter-cluster variation: 0.05410543572839113
Relabeled mean superpixels count: 328.9896907216495
Original mean superpixels count: 217.36426116838487
Done!
Job id: 420591
Job id: 422790
Job id: 422792
Job id: 422794
Job id: 422796
