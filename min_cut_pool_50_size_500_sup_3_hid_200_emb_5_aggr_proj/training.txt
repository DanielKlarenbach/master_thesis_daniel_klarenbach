Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 0.47633105516433716
Batch 2/64 loss: 0.4143238067626953
Batch 3/64 loss: 0.400230348110199
Batch 4/64 loss: 0.3932380676269531
Batch 5/64 loss: 0.38721299171447754
Batch 6/64 loss: 0.38680434226989746
Batch 7/64 loss: 0.38573604822158813
Batch 8/64 loss: 0.38414180278778076
Batch 9/64 loss: 0.38397055864334106
Batch 10/64 loss: 0.3839832544326782
Batch 11/64 loss: 0.3830866813659668
Batch 12/64 loss: 0.3834160566329956
Batch 13/64 loss: 0.38332676887512207
Batch 14/64 loss: 0.38190770149230957
Batch 15/64 loss: 0.38194525241851807
Batch 16/64 loss: 0.3811851739883423
Batch 17/64 loss: 0.3818535804748535
Batch 18/64 loss: 0.3825352191925049
Batch 19/64 loss: 0.38080906867980957
Batch 20/64 loss: 0.3816131353378296
Batch 21/64 loss: 0.38124626874923706
Batch 22/64 loss: 0.3809936046600342
Batch 23/64 loss: 0.3820074796676636
Batch 24/64 loss: 0.38078176975250244
Batch 25/64 loss: 0.38196396827697754
Batch 26/64 loss: 0.38079339265823364
Batch 27/64 loss: 0.38114166259765625
Batch 28/64 loss: 0.38064002990722656
Batch 29/64 loss: 0.37983477115631104
Batch 30/64 loss: 0.379965603351593
Batch 31/64 loss: 0.3805760145187378
Batch 32/64 loss: 0.38012051582336426
Batch 33/64 loss: 0.3807889223098755
Batch 34/64 loss: 0.3803645372390747
Batch 35/64 loss: 0.3790947198867798
Batch 36/64 loss: 0.3794708251953125
Batch 37/64 loss: 0.3801763653755188
Batch 38/64 loss: 0.37978947162628174
Batch 39/64 loss: 0.38006162643432617
Batch 40/64 loss: 0.37985825538635254
Batch 41/64 loss: 0.3792370557785034
Batch 42/64 loss: 0.37934762239456177
Batch 43/64 loss: 0.3793770670890808
Batch 44/64 loss: 0.38066744804382324
Batch 45/64 loss: 0.3794595003128052
Batch 46/64 loss: 0.37981468439102173
Batch 47/64 loss: 0.3806192874908447
Batch 48/64 loss: 0.37820184230804443
Batch 49/64 loss: 0.3802188038825989
Batch 50/64 loss: 0.37934839725494385
Batch 51/64 loss: 0.37921690940856934
Batch 52/64 loss: 0.3786123991012573
Batch 53/64 loss: 0.379854679107666
Batch 54/64 loss: 0.3785446882247925
Batch 55/64 loss: 0.37951093912124634
Batch 56/64 loss: 0.3800591230392456
Batch 57/64 loss: 0.37942612171173096
Batch 58/64 loss: 0.37985897064208984
Batch 59/64 loss: 0.3783964514732361
Batch 60/64 loss: 0.3789597749710083
Batch 61/64 loss: 0.37961190938949585
Batch 62/64 loss: 0.3774835467338562
Batch 63/64 loss: 0.3783695697784424
Batch 64/64 loss: 0.3780953884124756
Epoch 1  Train loss: 0.3832955145368389  Val loss: 0.3792699503734759
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 0.37893903255462646
Batch 2/64 loss: 0.3780120611190796
Batch 3/64 loss: 0.37912601232528687
Batch 4/64 loss: 0.37787431478500366
Batch 5/64 loss: 0.3792003393173218
Batch 6/64 loss: 0.3770434856414795
Batch 7/64 loss: 0.37869876623153687
Batch 8/64 loss: 0.3791523575782776
Batch 9/64 loss: 0.37812280654907227
Batch 10/64 loss: 0.3773876428604126
Batch 11/64 loss: 0.37779414653778076
Batch 12/64 loss: 0.3781747817993164
Batch 13/64 loss: 0.37698882818222046
Batch 14/64 loss: 0.37675559520721436
Batch 15/64 loss: 0.3775303363800049
Batch 16/64 loss: 0.37921327352523804
Batch 17/64 loss: 0.37726902961730957
Batch 18/64 loss: 0.37696975469589233
Batch 19/64 loss: 0.37638652324676514
Batch 20/64 loss: 0.37591421604156494
Batch 21/64 loss: 0.3773385286331177
Batch 22/64 loss: 0.37893515825271606
Batch 23/64 loss: 0.377063512802124
Batch 24/64 loss: 0.3772580623626709
Batch 25/64 loss: 0.3770962953567505
Batch 26/64 loss: 0.3781636953353882
Batch 27/64 loss: 0.37824535369873047
Batch 28/64 loss: 0.3773631453514099
Batch 29/64 loss: 0.37619805335998535
Batch 30/64 loss: 0.3768630027770996
Batch 31/64 loss: 0.37720680236816406
Batch 32/64 loss: 0.3769329786300659
Batch 33/64 loss: 0.3762221932411194
Batch 34/64 loss: 0.3777344226837158
Batch 35/64 loss: 0.3776521682739258
Batch 36/64 loss: 0.3770638704299927
Batch 37/64 loss: 0.37536799907684326
Batch 38/64 loss: 0.3765273094177246
Batch 39/64 loss: 0.3769569396972656
Batch 40/64 loss: 0.3759840130805969
Batch 41/64 loss: 0.3774658441543579
Batch 42/64 loss: 0.37660670280456543
Batch 43/64 loss: 0.3771789073944092
Batch 44/64 loss: 0.3759608268737793
Batch 45/64 loss: 0.37566518783569336
Batch 46/64 loss: 0.3754223585128784
Batch 47/64 loss: 0.3769276738166809
Batch 48/64 loss: 0.37626564502716064
Batch 49/64 loss: 0.3756980299949646
Batch 50/64 loss: 0.37565475702285767
Batch 51/64 loss: 0.37680143117904663
Batch 52/64 loss: 0.37799960374832153
Batch 53/64 loss: 0.37625229358673096
Batch 54/64 loss: 0.37360113859176636
Batch 55/64 loss: 0.3757147789001465
Batch 56/64 loss: 0.37597012519836426
Batch 57/64 loss: 0.3749576210975647
Batch 58/64 loss: 0.3762744665145874
Batch 59/64 loss: 0.37774884700775146
Batch 60/64 loss: 0.37584447860717773
Batch 61/64 loss: 0.3738946318626404
Batch 62/64 loss: 0.376228928565979
Batch 63/64 loss: 0.3767455816268921
Batch 64/64 loss: 0.3745102882385254
Epoch 2  Train loss: 0.3769488531000474  Val loss: 0.37528409785831096
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 0.37457144260406494
Batch 2/64 loss: 0.37361228466033936
Batch 3/64 loss: 0.3758434057235718
Batch 4/64 loss: 0.3755008578300476
Batch 5/64 loss: 0.3763277530670166
Batch 6/64 loss: 0.376592755317688
Batch 7/64 loss: 0.37444257736206055
Batch 8/64 loss: 0.37332606315612793
Batch 9/64 loss: 0.37529271841049194
Batch 10/64 loss: 0.37546730041503906
Batch 11/64 loss: 0.3764743208885193
Batch 12/64 loss: 0.37631189823150635
Batch 13/64 loss: 0.37464380264282227
Batch 14/64 loss: 0.3749115467071533
Batch 15/64 loss: 0.374878466129303
Batch 16/64 loss: 0.3740370273590088
Batch 17/64 loss: 0.3756241798400879
Batch 18/64 loss: 0.3754451274871826
Batch 19/64 loss: 0.3727095127105713
Batch 20/64 loss: 0.37532103061676025
Batch 21/64 loss: 0.37460851669311523
Batch 22/64 loss: 0.37528204917907715
Batch 23/64 loss: 0.37578284740448
Batch 24/64 loss: 0.37574923038482666
Batch 25/64 loss: 0.3735222816467285
Batch 26/64 loss: 0.37573105096817017
Batch 27/64 loss: 0.37383490800857544
Batch 28/64 loss: 0.37586236000061035
Batch 29/64 loss: 0.3750342130661011
Batch 30/64 loss: 0.37336623668670654
Batch 31/64 loss: 0.37356996536254883
Batch 32/64 loss: 0.3722952604293823
Batch 33/64 loss: 0.37518513202667236
Batch 34/64 loss: 0.37422990798950195
Batch 35/64 loss: 0.373013973236084
Batch 36/64 loss: 0.3740927577018738
Batch 37/64 loss: 0.3755345344543457
Batch 38/64 loss: 0.37315934896469116
Batch 39/64 loss: 0.3732506036758423
Batch 40/64 loss: 0.3727690577507019
Batch 41/64 loss: 0.3756183385848999
Batch 42/64 loss: 0.3735867738723755
Batch 43/64 loss: 0.3727942705154419
Batch 44/64 loss: 0.37288665771484375
Batch 45/64 loss: 0.3743756413459778
Batch 46/64 loss: 0.3759714365005493
Batch 47/64 loss: 0.37481653690338135
Batch 48/64 loss: 0.37369537353515625
Batch 49/64 loss: 0.37306392192840576
Batch 50/64 loss: 0.3745284080505371
Batch 51/64 loss: 0.3749169111251831
Batch 52/64 loss: 0.37399089336395264
Batch 53/64 loss: 0.3749338388442993
Batch 54/64 loss: 0.3750941753387451
Batch 55/64 loss: 0.3753904104232788
Batch 56/64 loss: 0.37166714668273926
Batch 57/64 loss: 0.3749518394470215
Batch 58/64 loss: 0.373540997505188
Batch 59/64 loss: 0.37350940704345703
Batch 60/64 loss: 0.3748282194137573
Batch 61/64 loss: 0.37475156784057617
Batch 62/64 loss: 0.37501728534698486
Batch 63/64 loss: 0.3740217685699463
Batch 64/64 loss: 0.3719923496246338
Epoch 3  Train loss: 0.3744965394337972  Val loss: 0.37360186285988983
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 0.3740350008010864
Batch 2/64 loss: 0.3728290796279907
Batch 3/64 loss: 0.3729810118675232
Batch 4/64 loss: 0.37152838706970215
Batch 5/64 loss: 0.37160158157348633
Batch 6/64 loss: 0.37342727184295654
Batch 7/64 loss: 0.37435251474380493
Batch 8/64 loss: 0.3720436692237854
Batch 9/64 loss: 0.37347012758255005
Batch 10/64 loss: 0.37419092655181885
Batch 11/64 loss: 0.37360507249832153
Batch 12/64 loss: 0.37187033891677856
Batch 13/64 loss: 0.3736989498138428
Batch 14/64 loss: 0.37303853034973145
Batch 15/64 loss: 0.3721507787704468
Batch 16/64 loss: 0.37265074253082275
Batch 17/64 loss: 0.3725093603134155
Batch 18/64 loss: 0.3726149797439575
Batch 19/64 loss: 0.37433505058288574
Batch 20/64 loss: 0.37219929695129395
Batch 21/64 loss: 0.3733861446380615
Batch 22/64 loss: 0.3728349208831787
Batch 23/64 loss: 0.3707929253578186
Batch 24/64 loss: 0.3725598454475403
Batch 25/64 loss: 0.3719174265861511
Batch 26/64 loss: 0.37310314178466797
Batch 27/64 loss: 0.37525784969329834
Batch 28/64 loss: 0.37063777446746826
Batch 29/64 loss: 0.37138593196868896
Batch 30/64 loss: 0.37283897399902344
Batch 31/64 loss: 0.3738154172897339
Batch 32/64 loss: 0.3721488118171692
Batch 33/64 loss: 0.371310830116272
Batch 34/64 loss: 0.37279701232910156
Batch 35/64 loss: 0.3740283250808716
Batch 36/64 loss: 0.3739011287689209
Batch 37/64 loss: 0.373653769493103
Batch 38/64 loss: 0.3718430995941162
Batch 39/64 loss: 0.37492525577545166
Batch 40/64 loss: 0.3743324279785156
Batch 41/64 loss: 0.373712420463562
Batch 42/64 loss: 0.373313307762146
Batch 43/64 loss: 0.37581968307495117
Batch 44/64 loss: 0.3735186457633972
Batch 45/64 loss: 0.3731273412704468
Batch 46/64 loss: 0.37332457304000854
Batch 47/64 loss: 0.37458670139312744
Batch 48/64 loss: 0.37282925844192505
Batch 49/64 loss: 0.3735119104385376
Batch 50/64 loss: 0.37324148416519165
Batch 51/64 loss: 0.37167680263519287
Batch 52/64 loss: 0.37333810329437256
Batch 53/64 loss: 0.3721742630004883
Batch 54/64 loss: 0.37228304147720337
Batch 55/64 loss: 0.3741670846939087
Batch 56/64 loss: 0.3722243905067444
Batch 57/64 loss: 0.3724697232246399
Batch 58/64 loss: 0.3717362880706787
Batch 59/64 loss: 0.3728404641151428
Batch 60/64 loss: 0.37242937088012695
Batch 61/64 loss: 0.3742786645889282
Batch 62/64 loss: 0.37488484382629395
Batch 63/64 loss: 0.3734930157661438
Batch 64/64 loss: 0.3713182806968689
Epoch 4  Train loss: 0.37302076512692023  Val loss: 0.37259320172247606
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 0.3718973398208618
Batch 2/64 loss: 0.37157881259918213
Batch 3/64 loss: 0.3737913966178894
Batch 4/64 loss: 0.3725243806838989
Batch 5/64 loss: 0.371248722076416
Batch 6/64 loss: 0.37236928939819336
Batch 7/64 loss: 0.3724137544631958
Batch 8/64 loss: 0.3730173707008362
Batch 9/64 loss: 0.3744015097618103
Batch 10/64 loss: 0.3717353940010071
Batch 11/64 loss: 0.3724329471588135
Batch 12/64 loss: 0.37172651290893555
Batch 13/64 loss: 0.3718918561935425
Batch 14/64 loss: 0.3712918758392334
Batch 15/64 loss: 0.374467134475708
Batch 16/64 loss: 0.37249696254730225
Batch 17/64 loss: 0.3691447377204895
Batch 18/64 loss: 0.37140363454818726
Batch 19/64 loss: 0.37252020835876465
Batch 20/64 loss: 0.37198764085769653
Batch 21/64 loss: 0.37241435050964355
Batch 22/64 loss: 0.3705253601074219
Batch 23/64 loss: 0.3725813627243042
Batch 24/64 loss: 0.3712599277496338
Batch 25/64 loss: 0.3690516948699951
Batch 26/64 loss: 0.373727023601532
Batch 27/64 loss: 0.37457114458084106
Batch 28/64 loss: 0.3722219467163086
Batch 29/64 loss: 0.37074553966522217
Batch 30/64 loss: 0.3708198666572571
Batch 31/64 loss: 0.3739084005355835
Batch 32/64 loss: 0.37249016761779785
Batch 33/64 loss: 0.3706258535385132
Batch 34/64 loss: 0.37181687355041504
Batch 35/64 loss: 0.37226414680480957
Batch 36/64 loss: 0.3700993061065674
Batch 37/64 loss: 0.3705621361732483
Batch 38/64 loss: 0.3707202672958374
Batch 39/64 loss: 0.36979931592941284
Batch 40/64 loss: 0.37251484394073486
Batch 41/64 loss: 0.36815643310546875
Batch 42/64 loss: 0.36967504024505615
Batch 43/64 loss: 0.37037408351898193
Batch 44/64 loss: 0.37189775705337524
Batch 45/64 loss: 0.37121158838272095
Batch 46/64 loss: 0.3706371784210205
Batch 47/64 loss: 0.370267391204834
Batch 48/64 loss: 0.3697168827056885
Batch 49/64 loss: 0.3721836805343628
Batch 50/64 loss: 0.37216120958328247
Batch 51/64 loss: 0.3717753291130066
Batch 52/64 loss: 0.37000107765197754
Batch 53/64 loss: 0.3692091107368469
Batch 54/64 loss: 0.3712425231933594
Batch 55/64 loss: 0.3702270984649658
Batch 56/64 loss: 0.3736211061477661
Batch 57/64 loss: 0.37239301204681396
Batch 58/64 loss: 0.37102603912353516
Batch 59/64 loss: 0.37166696786880493
Batch 60/64 loss: 0.37244486808776855
Batch 61/64 loss: 0.37039893865585327
Batch 62/64 loss: 0.37158310413360596
Batch 63/64 loss: 0.37186533212661743
Batch 64/64 loss: 0.37117379903793335
Epoch 5  Train loss: 0.3715949350712346  Val loss: 0.37101101342755083
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 0.36914902925491333
Batch 2/64 loss: 0.36864590644836426
Batch 3/64 loss: 0.37197554111480713
Batch 4/64 loss: 0.3697390556335449
Batch 5/64 loss: 0.37385666370391846
Batch 6/64 loss: 0.3709143400192261
Batch 7/64 loss: 0.37100332975387573
Batch 8/64 loss: 0.3727167844772339
Batch 9/64 loss: 0.3683648109436035
Batch 10/64 loss: 0.3726356029510498
Batch 11/64 loss: 0.37005388736724854
Batch 12/64 loss: 0.3701159954071045
Batch 13/64 loss: 0.3706643581390381
Batch 14/64 loss: 0.3698039650917053
Batch 15/64 loss: 0.370053231716156
Batch 16/64 loss: 0.370442271232605
Batch 17/64 loss: 0.37186717987060547
Batch 18/64 loss: 0.3675004839897156
Batch 19/64 loss: 0.3693554401397705
Batch 20/64 loss: 0.37116503715515137
Batch 21/64 loss: 0.37076568603515625
Batch 22/64 loss: 0.37240374088287354
Batch 23/64 loss: 0.37409698963165283
Batch 24/64 loss: 0.37137115001678467
Batch 25/64 loss: 0.37241727113723755
Batch 26/64 loss: 0.3708711266517639
Batch 27/64 loss: 0.3730922341346741
Batch 28/64 loss: 0.3709428310394287
Batch 29/64 loss: 0.37190860509872437
Batch 30/64 loss: 0.36973875761032104
Batch 31/64 loss: 0.3706318736076355
Batch 32/64 loss: 0.36832571029663086
Batch 33/64 loss: 0.37078505754470825
Batch 34/64 loss: 0.36786508560180664
Batch 35/64 loss: 0.37024450302124023
Batch 36/64 loss: 0.3713603615760803
Batch 37/64 loss: 0.370766818523407
Batch 38/64 loss: 0.36898618936538696
Batch 39/64 loss: 0.3708130121231079
Batch 40/64 loss: 0.36917126178741455
Batch 41/64 loss: 0.37127232551574707
Batch 42/64 loss: 0.3701804280281067
Batch 43/64 loss: 0.36929911375045776
Batch 44/64 loss: 0.3685761094093323
Batch 45/64 loss: 0.3684033155441284
Batch 46/64 loss: 0.3714600205421448
Batch 47/64 loss: 0.37106746435165405
Batch 48/64 loss: 0.3696807622909546
Batch 49/64 loss: 0.36861157417297363
Batch 50/64 loss: 0.36978745460510254
Batch 51/64 loss: 0.37379372119903564
Batch 52/64 loss: 0.37060391902923584
Batch 53/64 loss: 0.37053561210632324
Batch 54/64 loss: 0.37090837955474854
Batch 55/64 loss: 0.3702425956726074
Batch 56/64 loss: 0.37025392055511475
Batch 57/64 loss: 0.37257254123687744
Batch 58/64 loss: 0.36972320079803467
Batch 59/64 loss: 0.37365394830703735
Batch 60/64 loss: 0.3692668676376343
Batch 61/64 loss: 0.36860764026641846
Batch 62/64 loss: 0.3714856505393982
Batch 63/64 loss: 0.37079501152038574
Batch 64/64 loss: 0.3702648878097534
Epoch 6  Train loss: 0.37058919878566965  Val loss: 0.3698367232719238
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.3708221912384033
Batch 2/64 loss: 0.3702434301376343
Batch 3/64 loss: 0.3716992139816284
Batch 4/64 loss: 0.3685910701751709
Batch 5/64 loss: 0.3694779872894287
Batch 6/64 loss: 0.3701205253601074
Batch 7/64 loss: 0.36783695220947266
Batch 8/64 loss: 0.368829607963562
Batch 9/64 loss: 0.3719240427017212
Batch 10/64 loss: 0.3685307502746582
Batch 11/64 loss: 0.3708057403564453
Batch 12/64 loss: 0.37141644954681396
Batch 13/64 loss: 0.3684035539627075
Batch 14/64 loss: 0.37206488847732544
Batch 15/64 loss: 0.37255990505218506
Batch 16/64 loss: 0.3696242570877075
Batch 17/64 loss: 0.3733593821525574
Batch 18/64 loss: 0.3701202869415283
Batch 19/64 loss: 0.37062132358551025
Batch 20/64 loss: 0.3688781261444092
Batch 21/64 loss: 0.3674086332321167
Batch 22/64 loss: 0.3680642247200012
Batch 23/64 loss: 0.3705950975418091
Batch 24/64 loss: 0.37051475048065186
Batch 25/64 loss: 0.36920541524887085
Batch 26/64 loss: 0.3698059916496277
Batch 27/64 loss: 0.3706212639808655
Batch 28/64 loss: 0.37057119607925415
Batch 29/64 loss: 0.37028324604034424
Batch 30/64 loss: 0.36905765533447266
Batch 31/64 loss: 0.3713415861129761
Batch 32/64 loss: 0.3699181079864502
Batch 33/64 loss: 0.3698594570159912
Batch 34/64 loss: 0.3695448637008667
Batch 35/64 loss: 0.36941081285476685
Batch 36/64 loss: 0.37273573875427246
Batch 37/64 loss: 0.37142372131347656
Batch 38/64 loss: 0.3696690797805786
Batch 39/64 loss: 0.36952006816864014
Batch 40/64 loss: 0.3694307804107666
Batch 41/64 loss: 0.3682901859283447
Batch 42/64 loss: 0.3712589740753174
Batch 43/64 loss: 0.37111735343933105
Batch 44/64 loss: 0.3708302974700928
Batch 45/64 loss: 0.37119346857070923
Batch 46/64 loss: 0.36932116746902466
Batch 47/64 loss: 0.3666331171989441
Batch 48/64 loss: 0.36800235509872437
Batch 49/64 loss: 0.3691895604133606
Batch 50/64 loss: 0.3683485984802246
Batch 51/64 loss: 0.3701702356338501
Batch 52/64 loss: 0.3729712963104248
Batch 53/64 loss: 0.369254469871521
Batch 54/64 loss: 0.3704582452774048
Batch 55/64 loss: 0.3685598373413086
Batch 56/64 loss: 0.3691525459289551
Batch 57/64 loss: 0.3693976402282715
Batch 58/64 loss: 0.3669174909591675
Batch 59/64 loss: 0.3698977828025818
Batch 60/64 loss: 0.36921054124832153
Batch 61/64 loss: 0.3673918843269348
Batch 62/64 loss: 0.3676168918609619
Batch 63/64 loss: 0.3691433072090149
Batch 64/64 loss: 0.36787617206573486
Epoch 7  Train loss: 0.3698062078625548  Val loss: 0.36959264184191465
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 0.36855554580688477
Batch 2/64 loss: 0.3678715229034424
Batch 3/64 loss: 0.36553454399108887
Batch 4/64 loss: 0.36918795108795166
Batch 5/64 loss: 0.37053394317626953
Batch 6/64 loss: 0.3667241334915161
Batch 7/64 loss: 0.3682820796966553
Batch 8/64 loss: 0.36818283796310425
Batch 9/64 loss: 0.3691352605819702
Batch 10/64 loss: 0.36661386489868164
Batch 11/64 loss: 0.36707961559295654
Batch 12/64 loss: 0.36998820304870605
Batch 13/64 loss: 0.3697516918182373
Batch 14/64 loss: 0.3671630620956421
Batch 15/64 loss: 0.36878639459609985
Batch 16/64 loss: 0.3689335584640503
Batch 17/64 loss: 0.3673442006111145
Batch 18/64 loss: 0.3680703639984131
Batch 19/64 loss: 0.3695186376571655
Batch 20/64 loss: 0.36902499198913574
Batch 21/64 loss: 0.36877238750457764
Batch 22/64 loss: 0.3717600703239441
Batch 23/64 loss: 0.368503212928772
Batch 24/64 loss: 0.36812329292297363
Batch 25/64 loss: 0.37047427892684937
Batch 26/64 loss: 0.3661046028137207
Batch 27/64 loss: 0.37124598026275635
Batch 28/64 loss: 0.3711267113685608
Batch 29/64 loss: 0.3684828281402588
Batch 30/64 loss: 0.3685397505760193
Batch 31/64 loss: 0.3712639808654785
Batch 32/64 loss: 0.36948853731155396
Batch 33/64 loss: 0.3723350763320923
Batch 34/64 loss: 0.36740124225616455
Batch 35/64 loss: 0.36701637506484985
Batch 36/64 loss: 0.36760199069976807
Batch 37/64 loss: 0.36806631088256836
Batch 38/64 loss: 0.3686637878417969
Batch 39/64 loss: 0.36826252937316895
Batch 40/64 loss: 0.36657124757766724
Batch 41/64 loss: 0.3697417974472046
Batch 42/64 loss: 0.36993932723999023
Batch 43/64 loss: 0.3698068857192993
Batch 44/64 loss: 0.36943525075912476
Batch 45/64 loss: 0.3693455457687378
Batch 46/64 loss: 0.36821943521499634
Batch 47/64 loss: 0.3663902282714844
Batch 48/64 loss: 0.3677369952201843
Batch 49/64 loss: 0.36893516778945923
Batch 50/64 loss: 0.37318629026412964
Batch 51/64 loss: 0.3710756301879883
Batch 52/64 loss: 0.3684077262878418
Batch 53/64 loss: 0.36960333585739136
Batch 54/64 loss: 0.3700339198112488
Batch 55/64 loss: 0.3694785237312317
Batch 56/64 loss: 0.3664318919181824
Batch 57/64 loss: 0.36881351470947266
Batch 58/64 loss: 0.36830025911331177
Batch 59/64 loss: 0.3684547543525696
Batch 60/64 loss: 0.3688058853149414
Batch 61/64 loss: 0.3671257495880127
Batch 62/64 loss: 0.36901551485061646
Batch 63/64 loss: 0.36910581588745117
Batch 64/64 loss: 0.36735987663269043
Epoch 8  Train loss: 0.3687685639250512  Val loss: 0.36897677326530115
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 0.3688521385192871
Batch 2/64 loss: 0.36675065755844116
Batch 3/64 loss: 0.37028682231903076
Batch 4/64 loss: 0.37142711877822876
Batch 5/64 loss: 0.36764824390411377
Batch 6/64 loss: 0.36720842123031616
Batch 7/64 loss: 0.36622393131256104
Batch 8/64 loss: 0.36988240480422974
Batch 9/64 loss: 0.36945009231567383
Batch 10/64 loss: 0.3681561350822449
Batch 11/64 loss: 0.3711261749267578
Batch 12/64 loss: 0.3670858144760132
Batch 13/64 loss: 0.3696105480194092
Batch 14/64 loss: 0.3661344051361084
Batch 15/64 loss: 0.3668086528778076
Batch 16/64 loss: 0.36723244190216064
Batch 17/64 loss: 0.37006425857543945
Batch 18/64 loss: 0.36818528175354004
Batch 19/64 loss: 0.3681183457374573
Batch 20/64 loss: 0.37063169479370117
Batch 21/64 loss: 0.36930549144744873
Batch 22/64 loss: 0.36887460947036743
Batch 23/64 loss: 0.37001991271972656
Batch 24/64 loss: 0.3712383508682251
Batch 25/64 loss: 0.36747050285339355
Batch 26/64 loss: 0.36964499950408936
Batch 27/64 loss: 0.3693901300430298
Batch 28/64 loss: 0.3687058687210083
Batch 29/64 loss: 0.3649059534072876
Batch 30/64 loss: 0.36970770359039307
Batch 31/64 loss: 0.3698940873146057
Batch 32/64 loss: 0.36891335248947144
Batch 33/64 loss: 0.3648214340209961
Batch 34/64 loss: 0.3682478070259094
Batch 35/64 loss: 0.36873728036880493
Batch 36/64 loss: 0.36594313383102417
Batch 37/64 loss: 0.36920762062072754
Batch 38/64 loss: 0.3671135902404785
Batch 39/64 loss: 0.369848370552063
Batch 40/64 loss: 0.3680011034011841
Batch 41/64 loss: 0.36831480264663696
Batch 42/64 loss: 0.36850690841674805
Batch 43/64 loss: 0.3692793846130371
Batch 44/64 loss: 0.3672983646392822
Batch 45/64 loss: 0.36532580852508545
Batch 46/64 loss: 0.36300140619277954
Batch 47/64 loss: 0.370077908039093
Batch 48/64 loss: 0.3667795658111572
Batch 49/64 loss: 0.3695172071456909
Batch 50/64 loss: 0.36856400966644287
Batch 51/64 loss: 0.37011128664016724
Batch 52/64 loss: 0.3674260973930359
Batch 53/64 loss: 0.36881905794143677
Batch 54/64 loss: 0.36631274223327637
Batch 55/64 loss: 0.36571645736694336
Batch 56/64 loss: 0.36727988719940186
Batch 57/64 loss: 0.36851513385772705
Batch 58/64 loss: 0.36763250827789307
Batch 59/64 loss: 0.36624133586883545
Batch 60/64 loss: 0.36682403087615967
Batch 61/64 loss: 0.37180382013320923
Batch 62/64 loss: 0.3662198781967163
Batch 63/64 loss: 0.3707547187805176
Batch 64/64 loss: 0.365312397480011
Epoch 9  Train loss: 0.3682381412562202  Val loss: 0.36842118813000185
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: 0.368505597114563
Batch 2/64 loss: 0.36843955516815186
Batch 3/64 loss: 0.3670363426208496
Batch 4/64 loss: 0.36759477853775024
Batch 5/64 loss: 0.3686524033546448
Batch 6/64 loss: 0.36809074878692627
Batch 7/64 loss: 0.367218017578125
Batch 8/64 loss: 0.36964094638824463
Batch 9/64 loss: 0.36654818058013916
Batch 10/64 loss: 0.36909937858581543
Batch 11/64 loss: 0.3664131164550781
Batch 12/64 loss: 0.36452019214630127
Batch 13/64 loss: 0.3683055639266968
Batch 14/64 loss: 0.3660046458244324
Batch 15/64 loss: 0.3676762580871582
Batch 16/64 loss: 0.36551421880722046
Batch 17/64 loss: 0.3686105012893677
Batch 18/64 loss: 0.36639320850372314
Batch 19/64 loss: 0.36877089738845825
Batch 20/64 loss: 0.36939698457717896
Batch 21/64 loss: 0.36807548999786377
Batch 22/64 loss: 0.36623477935791016
Batch 23/64 loss: 0.372317373752594
Batch 24/64 loss: 0.3709735870361328
Batch 25/64 loss: 0.3702050447463989
Batch 26/64 loss: 0.36866092681884766
Batch 27/64 loss: 0.3662123680114746
Batch 28/64 loss: 0.3669145703315735
Batch 29/64 loss: 0.37039947509765625
Batch 30/64 loss: 0.3659936189651489
Batch 31/64 loss: 0.36285555362701416
Batch 32/64 loss: 0.36912137269973755
Batch 33/64 loss: 0.36575859785079956
Batch 34/64 loss: 0.3655032515525818
Batch 35/64 loss: 0.3697972297668457
Batch 36/64 loss: 0.37165528535842896
Batch 37/64 loss: 0.37058424949645996
Batch 38/64 loss: 0.36884361505508423
Batch 39/64 loss: 0.3683834671974182
Batch 40/64 loss: 0.36678075790405273
Batch 41/64 loss: 0.367401659488678
Batch 42/64 loss: 0.3654203414916992
Batch 43/64 loss: 0.3669750690460205
Batch 44/64 loss: 0.3685917854309082
Batch 45/64 loss: 0.3686937093734741
Batch 46/64 loss: 0.3698527216911316
Batch 47/64 loss: 0.36902761459350586
Batch 48/64 loss: 0.37062883377075195
Batch 49/64 loss: 0.36586034297943115
Batch 50/64 loss: 0.36626625061035156
Batch 51/64 loss: 0.3672151565551758
Batch 52/64 loss: 0.36657339334487915
Batch 53/64 loss: 0.367332398891449
Batch 54/64 loss: 0.36549997329711914
Batch 55/64 loss: 0.36866533756256104
Batch 56/64 loss: 0.3690314292907715
Batch 57/64 loss: 0.3684297800064087
Batch 58/64 loss: 0.36603260040283203
Batch 59/64 loss: 0.3656349182128906
Batch 60/64 loss: 0.36712169647216797
Batch 61/64 loss: 0.36969733238220215
Batch 62/64 loss: 0.36627793312072754
Batch 63/64 loss: 0.3685711622238159
Batch 64/64 loss: 0.3662666082382202
Epoch 10  Train loss: 0.36779927132176415  Val loss: 0.36792975418346446
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: 0.3655664920806885
Batch 2/64 loss: 0.3674408197402954
Batch 3/64 loss: 0.3668122887611389
Batch 4/64 loss: 0.3662116527557373
Batch 5/64 loss: 0.3683691620826721
Batch 6/64 loss: 0.3683595657348633
Batch 7/64 loss: 0.36855632066726685
Batch 8/64 loss: 0.3704078197479248
Batch 9/64 loss: 0.36952459812164307
Batch 10/64 loss: 0.3677965998649597
Batch 11/64 loss: 0.36764848232269287
Batch 12/64 loss: 0.36974042654037476
Batch 13/64 loss: 0.3667788505554199
Batch 14/64 loss: 0.3647710680961609
Batch 15/64 loss: 0.36609959602355957
Batch 16/64 loss: 0.36588752269744873
Batch 17/64 loss: 0.366549015045166
Batch 18/64 loss: 0.3685588240623474
Batch 19/64 loss: 0.36972057819366455
Batch 20/64 loss: 0.3626331686973572
Batch 21/64 loss: 0.3666703701019287
Batch 22/64 loss: 0.3709467053413391
Batch 23/64 loss: 0.3664630651473999
Batch 24/64 loss: 0.36722028255462646
Batch 25/64 loss: 0.3648550510406494
Batch 26/64 loss: 0.36577773094177246
Batch 27/64 loss: 0.36614811420440674
Batch 28/64 loss: 0.3669931888580322
Batch 29/64 loss: 0.3685908317565918
Batch 30/64 loss: 0.36945801973342896
Batch 31/64 loss: 0.3656323552131653
Batch 32/64 loss: 0.36757606267929077
Batch 33/64 loss: 0.366611123085022
Batch 34/64 loss: 0.36743783950805664
Batch 35/64 loss: 0.36827266216278076
Batch 36/64 loss: 0.3686841130256653
Batch 37/64 loss: 0.3647644519805908
Batch 38/64 loss: 0.3661707639694214
Batch 39/64 loss: 0.36737048625946045
Batch 40/64 loss: 0.36472582817077637
Batch 41/64 loss: 0.3660794496536255
Batch 42/64 loss: 0.36663758754730225
Batch 43/64 loss: 0.3663281202316284
Batch 44/64 loss: 0.3659861087799072
Batch 45/64 loss: 0.3674725890159607
Batch 46/64 loss: 0.369004487991333
Batch 47/64 loss: 0.3652951121330261
Batch 48/64 loss: 0.36787670850753784
Batch 49/64 loss: 0.3710528612136841
Batch 50/64 loss: 0.36614346504211426
Batch 51/64 loss: 0.3636056184768677
Batch 52/64 loss: 0.3699684143066406
Batch 53/64 loss: 0.363767147064209
Batch 54/64 loss: 0.3651267886161804
Batch 55/64 loss: 0.3665679693222046
Batch 56/64 loss: 0.3674059510231018
Batch 57/64 loss: 0.3673452138900757
Batch 58/64 loss: 0.3675200939178467
Batch 59/64 loss: 0.3691161870956421
Batch 60/64 loss: 0.36682093143463135
Batch 61/64 loss: 0.3690927028656006
Batch 62/64 loss: 0.36724853515625
Batch 63/64 loss: 0.36682718992233276
Batch 64/64 loss: 0.3672229051589966
Epoch 11  Train loss: 0.3671452283859253  Val loss: 0.3673798566831346
Saving best model, epoch: 11
Epoch 12
-------------------------------
Batch 1/64 loss: 0.3692466616630554
Batch 2/64 loss: 0.3694673776626587
Batch 3/64 loss: 0.3629233241081238
Batch 4/64 loss: 0.3647768497467041
Batch 5/64 loss: 0.36718493700027466
Batch 6/64 loss: 0.36463701725006104
Batch 7/64 loss: 0.3675640821456909
Batch 8/64 loss: 0.36724644899368286
Batch 9/64 loss: 0.368449330329895
Batch 10/64 loss: 0.3651285171508789
Batch 11/64 loss: 0.3657177686691284
Batch 12/64 loss: 0.3665870428085327
Batch 13/64 loss: 0.36736977100372314
Batch 14/64 loss: 0.3645438551902771
Batch 15/64 loss: 0.3667105436325073
Batch 16/64 loss: 0.36606866121292114
Batch 17/64 loss: 0.3682440519332886
Batch 18/64 loss: 0.36712372303009033
Batch 19/64 loss: 0.36618906259536743
Batch 20/64 loss: 0.36643922328948975
Batch 21/64 loss: 0.3670933246612549
Batch 22/64 loss: 0.3642573356628418
Batch 23/64 loss: 0.36723625659942627
Batch 24/64 loss: 0.3666282892227173
Batch 25/64 loss: 0.36873865127563477
Batch 26/64 loss: 0.36504554748535156
Batch 27/64 loss: 0.36879903078079224
Batch 28/64 loss: 0.36646854877471924
Batch 29/64 loss: 0.36894989013671875
Batch 30/64 loss: 0.3646364212036133
Batch 31/64 loss: 0.36700230836868286
Batch 32/64 loss: 0.367154598236084
Batch 33/64 loss: 0.3657805919647217
Batch 34/64 loss: 0.3685622215270996
Batch 35/64 loss: 0.3657679557800293
Batch 36/64 loss: 0.367556095123291
Batch 37/64 loss: 0.3673299551010132
Batch 38/64 loss: 0.3644249439239502
Batch 39/64 loss: 0.36525142192840576
Batch 40/64 loss: 0.36575746536254883
Batch 41/64 loss: 0.36766648292541504
Batch 42/64 loss: 0.3665289878845215
Batch 43/64 loss: 0.36766600608825684
Batch 44/64 loss: 0.36437177658081055
Batch 45/64 loss: 0.36610281467437744
Batch 46/64 loss: 0.3660500645637512
Batch 47/64 loss: 0.36563581228256226
Batch 48/64 loss: 0.36545330286026
Batch 49/64 loss: 0.36634671688079834
Batch 50/64 loss: 0.36499446630477905
Batch 51/64 loss: 0.3666072487831116
Batch 52/64 loss: 0.368571400642395
Batch 53/64 loss: 0.36719417572021484
Batch 54/64 loss: 0.3670971989631653
Batch 55/64 loss: 0.36725711822509766
Batch 56/64 loss: 0.36656713485717773
Batch 57/64 loss: 0.3687196969985962
Batch 58/64 loss: 0.3679429292678833
Batch 59/64 loss: 0.36837124824523926
Batch 60/64 loss: 0.36467432975769043
Batch 61/64 loss: 0.36487627029418945
Batch 62/64 loss: 0.3684661388397217
Batch 63/64 loss: 0.3658329248428345
Batch 64/64 loss: 0.37132978439331055
Epoch 12  Train loss: 0.3666753048990287  Val loss: 0.3671807206373444
Saving best model, epoch: 12
Epoch 13
-------------------------------
Batch 1/64 loss: 0.3669968843460083
Batch 2/64 loss: 0.36378026008605957
Batch 3/64 loss: 0.36626458168029785
Batch 4/64 loss: 0.36681926250457764
Batch 5/64 loss: 0.3654126524925232
Batch 6/64 loss: 0.3668830394744873
Batch 7/64 loss: 0.3671506643295288
Batch 8/64 loss: 0.36715424060821533
Batch 9/64 loss: 0.36357712745666504
Batch 10/64 loss: 0.36390483379364014
Batch 11/64 loss: 0.36585527658462524
Batch 12/64 loss: 0.3685306906700134
Batch 13/64 loss: 0.36479753255844116
Batch 14/64 loss: 0.36559945344924927
Batch 15/64 loss: 0.3658362030982971
Batch 16/64 loss: 0.366913378238678
Batch 17/64 loss: 0.36303967237472534
Batch 18/64 loss: 0.3676149845123291
Batch 19/64 loss: 0.36701762676239014
Batch 20/64 loss: 0.3667060136795044
Batch 21/64 loss: 0.3649720549583435
Batch 22/64 loss: 0.3664887547492981
Batch 23/64 loss: 0.3628880977630615
Batch 24/64 loss: 0.36747485399246216
Batch 25/64 loss: 0.36786872148513794
Batch 26/64 loss: 0.3660339117050171
Batch 27/64 loss: 0.3689858317375183
Batch 28/64 loss: 0.36486589908599854
Batch 29/64 loss: 0.36616629362106323
Batch 30/64 loss: 0.3639931082725525
Batch 31/64 loss: 0.3662576675415039
Batch 32/64 loss: 0.3681689500808716
Batch 33/64 loss: 0.3642423152923584
Batch 34/64 loss: 0.3622869849205017
Batch 35/64 loss: 0.36774611473083496
Batch 36/64 loss: 0.3653585910797119
Batch 37/64 loss: 0.36715054512023926
Batch 38/64 loss: 0.36426377296447754
Batch 39/64 loss: 0.36689698696136475
Batch 40/64 loss: 0.3685213327407837
Batch 41/64 loss: 0.3678428530693054
Batch 42/64 loss: 0.36967408657073975
Batch 43/64 loss: 0.3684353232383728
Batch 44/64 loss: 0.36641114950180054
Batch 45/64 loss: 0.3660275936126709
Batch 46/64 loss: 0.36736154556274414
Batch 47/64 loss: 0.36542296409606934
Batch 48/64 loss: 0.3673558235168457
Batch 49/64 loss: 0.3665081858634949
Batch 50/64 loss: 0.3680405616760254
Batch 51/64 loss: 0.36606478691101074
Batch 52/64 loss: 0.3660488724708557
Batch 53/64 loss: 0.3639981746673584
Batch 54/64 loss: 0.3662952780723572
Batch 55/64 loss: 0.36898601055145264
Batch 56/64 loss: 0.37152183055877686
Batch 57/64 loss: 0.3648378849029541
Batch 58/64 loss: 0.36524271965026855
Batch 59/64 loss: 0.3694937229156494
Batch 60/64 loss: 0.3657914400100708
Batch 61/64 loss: 0.3675222396850586
Batch 62/64 loss: 0.36364662647247314
Batch 63/64 loss: 0.36725759506225586
Batch 64/64 loss: 0.3652780055999756
Epoch 13  Train loss: 0.36634087749556  Val loss: 0.3675611260830332
Epoch 14
-------------------------------
Batch 1/64 loss: 0.36796748638153076
Batch 2/64 loss: 0.3686974048614502
Batch 3/64 loss: 0.36931729316711426
Batch 4/64 loss: 0.3647230863571167
Batch 5/64 loss: 0.36475133895874023
Batch 6/64 loss: 0.3660937547683716
Batch 7/64 loss: 0.36693084239959717
Batch 8/64 loss: 0.3675649166107178
Batch 9/64 loss: 0.3674784302711487
Batch 10/64 loss: 0.3660942316055298
Batch 11/64 loss: 0.3627951145172119
Batch 12/64 loss: 0.3677018880844116
Batch 13/64 loss: 0.3604445457458496
Batch 14/64 loss: 0.3678126335144043
Batch 15/64 loss: 0.3645048141479492
Batch 16/64 loss: 0.3659977912902832
Batch 17/64 loss: 0.36686044931411743
Batch 18/64 loss: 0.36433613300323486
Batch 19/64 loss: 0.36453449726104736
Batch 20/64 loss: 0.36406952142715454
Batch 21/64 loss: 0.36558210849761963
Batch 22/64 loss: 0.3667275905609131
Batch 23/64 loss: 0.3665369749069214
Batch 24/64 loss: 0.36875104904174805
Batch 25/64 loss: 0.3670426607131958
Batch 26/64 loss: 0.36545467376708984
Batch 27/64 loss: 0.3643420934677124
Batch 28/64 loss: 0.36775851249694824
Batch 29/64 loss: 0.36735475063323975
Batch 30/64 loss: 0.36882829666137695
Batch 31/64 loss: 0.3649561405181885
Batch 32/64 loss: 0.36664021015167236
Batch 33/64 loss: 0.36432212591171265
Batch 34/64 loss: 0.3682165741920471
Batch 35/64 loss: 0.3662335276603699
Batch 36/64 loss: 0.36580556631088257
Batch 37/64 loss: 0.36456298828125
Batch 38/64 loss: 0.3623531460762024
Batch 39/64 loss: 0.36908918619155884
Batch 40/64 loss: 0.3653087019920349
Batch 41/64 loss: 0.367694616317749
Batch 42/64 loss: 0.3650057315826416
Batch 43/64 loss: 0.3660620450973511
Batch 44/64 loss: 0.36451053619384766
Batch 45/64 loss: 0.36473512649536133
Batch 46/64 loss: 0.36516493558883667
Batch 47/64 loss: 0.3666501045227051
Batch 48/64 loss: 0.3663644790649414
Batch 49/64 loss: 0.3653148412704468
Batch 50/64 loss: 0.3663709759712219
Batch 51/64 loss: 0.36551499366760254
Batch 52/64 loss: 0.36634838581085205
Batch 53/64 loss: 0.3681575655937195
Batch 54/64 loss: 0.3688727617263794
Batch 55/64 loss: 0.3689141273498535
Batch 56/64 loss: 0.3638690710067749
Batch 57/64 loss: 0.36590033769607544
Batch 58/64 loss: 0.3707914352416992
Batch 59/64 loss: 0.3650624752044678
Batch 60/64 loss: 0.3666456937789917
Batch 61/64 loss: 0.36511099338531494
Batch 62/64 loss: 0.36308616399765015
Batch 63/64 loss: 0.36419928073883057
Batch 64/64 loss: 0.3675171136856079
Epoch 14  Train loss: 0.3661259225770539  Val loss: 0.3662910795293723
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: 0.36523348093032837
Batch 2/64 loss: 0.3652362823486328
Batch 3/64 loss: 0.3655407428741455
Batch 4/64 loss: 0.36465293169021606
Batch 5/64 loss: 0.36298316717147827
Batch 6/64 loss: 0.3650354743003845
Batch 7/64 loss: 0.3667895793914795
Batch 8/64 loss: 0.36467480659484863
Batch 9/64 loss: 0.3674384355545044
Batch 10/64 loss: 0.3683624863624573
Batch 11/64 loss: 0.36636537313461304
Batch 12/64 loss: 0.36627233028411865
Batch 13/64 loss: 0.3673689365386963
Batch 14/64 loss: 0.3689799904823303
Batch 15/64 loss: 0.3669372797012329
Batch 16/64 loss: 0.3668370246887207
Batch 17/64 loss: 0.36412954330444336
Batch 18/64 loss: 0.3667886257171631
Batch 19/64 loss: 0.3671203851699829
Batch 20/64 loss: 0.36511147022247314
Batch 21/64 loss: 0.36888813972473145
Batch 22/64 loss: 0.3637120723724365
Batch 23/64 loss: 0.36380892992019653
Batch 24/64 loss: 0.3697854280471802
Batch 25/64 loss: 0.3647620677947998
Batch 26/64 loss: 0.363705039024353
Batch 27/64 loss: 0.3652886152267456
Batch 28/64 loss: 0.3701884150505066
Batch 29/64 loss: 0.3656799793243408
Batch 30/64 loss: 0.36800217628479004
Batch 31/64 loss: 0.3662210702896118
Batch 32/64 loss: 0.36736786365509033
Batch 33/64 loss: 0.36266231536865234
Batch 34/64 loss: 0.3684767484664917
Batch 35/64 loss: 0.3633852005004883
Batch 36/64 loss: 0.36685842275619507
Batch 37/64 loss: 0.3633584976196289
Batch 38/64 loss: 0.3652719259262085
Batch 39/64 loss: 0.36329537630081177
Batch 40/64 loss: 0.364499568939209
Batch 41/64 loss: 0.3659553527832031
Batch 42/64 loss: 0.36259573698043823
Batch 43/64 loss: 0.3648090362548828
Batch 44/64 loss: 0.36827534437179565
Batch 45/64 loss: 0.3639090061187744
Batch 46/64 loss: 0.36624836921691895
Batch 47/64 loss: 0.36373138427734375
Batch 48/64 loss: 0.3669261932373047
Batch 49/64 loss: 0.36627286672592163
Batch 50/64 loss: 0.36379820108413696
Batch 51/64 loss: 0.3667142391204834
Batch 52/64 loss: 0.3685694932937622
Batch 53/64 loss: 0.3648719787597656
Batch 54/64 loss: 0.36773622035980225
Batch 55/64 loss: 0.3638262152671814
Batch 56/64 loss: 0.36419934034347534
Batch 57/64 loss: 0.3614771366119385
Batch 58/64 loss: 0.3639122247695923
Batch 59/64 loss: 0.36282896995544434
Batch 60/64 loss: 0.3661048412322998
Batch 61/64 loss: 0.3609316349029541
Batch 62/64 loss: 0.36483055353164673
Batch 63/64 loss: 0.36427509784698486
Batch 64/64 loss: 0.36596858501434326
Epoch 15  Train loss: 0.3655584639193965  Val loss: 0.366271299799693
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: 0.36290955543518066
Batch 2/64 loss: 0.36439085006713867
Batch 3/64 loss: 0.36390137672424316
Batch 4/64 loss: 0.36429208517074585
Batch 5/64 loss: 0.3656274080276489
Batch 6/64 loss: 0.3672352433204651
Batch 7/64 loss: 0.3657205104827881
Batch 8/64 loss: 0.3642166256904602
Batch 9/64 loss: 0.36435484886169434
Batch 10/64 loss: 0.3665769100189209
Batch 11/64 loss: 0.3680317997932434
Batch 12/64 loss: 0.3663017749786377
Batch 13/64 loss: 0.36377835273742676
Batch 14/64 loss: 0.36539226770401
Batch 15/64 loss: 0.36453086137771606
Batch 16/64 loss: 0.3651506304740906
Batch 17/64 loss: 0.36517763137817383
Batch 18/64 loss: 0.36584389209747314
Batch 19/64 loss: 0.36771219968795776
Batch 20/64 loss: 0.36811280250549316
Batch 21/64 loss: 0.36555689573287964
Batch 22/64 loss: 0.36600804328918457
Batch 23/64 loss: 0.3650401830673218
Batch 24/64 loss: 0.3641635775566101
Batch 25/64 loss: 0.36583656072616577
Batch 26/64 loss: 0.367063045501709
Batch 27/64 loss: 0.3664942979812622
Batch 28/64 loss: 0.3640249967575073
Batch 29/64 loss: 0.3673465847969055
Batch 30/64 loss: 0.36633723974227905
Batch 31/64 loss: 0.36777591705322266
Batch 32/64 loss: 0.36419248580932617
Batch 33/64 loss: 0.3665727376937866
Batch 34/64 loss: 0.3657786250114441
Batch 35/64 loss: 0.36407268047332764
Batch 36/64 loss: 0.36848628520965576
Batch 37/64 loss: 0.3651615381240845
Batch 38/64 loss: 0.36522358655929565
Batch 39/64 loss: 0.36718934774398804
Batch 40/64 loss: 0.3662436008453369
Batch 41/64 loss: 0.3655538558959961
Batch 42/64 loss: 0.3665427565574646
Batch 43/64 loss: 0.36295604705810547
Batch 44/64 loss: 0.3662664294242859
Batch 45/64 loss: 0.366117000579834
Batch 46/64 loss: 0.36330580711364746
Batch 47/64 loss: 0.3616943359375
Batch 48/64 loss: 0.36688750982284546
Batch 49/64 loss: 0.36526238918304443
Batch 50/64 loss: 0.36722278594970703
Batch 51/64 loss: 0.3628981113433838
Batch 52/64 loss: 0.3696630001068115
Batch 53/64 loss: 0.36716556549072266
Batch 54/64 loss: 0.36753857135772705
Batch 55/64 loss: 0.3659207820892334
Batch 56/64 loss: 0.3641279935836792
Batch 57/64 loss: 0.36828315258026123
Batch 58/64 loss: 0.36301398277282715
Batch 59/64 loss: 0.36449944972991943
Batch 60/64 loss: 0.36638450622558594
Batch 61/64 loss: 0.3653542995452881
Batch 62/64 loss: 0.3662448525428772
Batch 63/64 loss: 0.36810004711151123
Batch 64/64 loss: 0.3641018271446228
Epoch 16  Train loss: 0.3656769483697181  Val loss: 0.3667735721647125
Epoch 17
-------------------------------
Batch 1/64 loss: 0.36557066440582275
Batch 2/64 loss: 0.3641431927680969
Batch 3/64 loss: 0.3662629723548889
Batch 4/64 loss: 0.3664451837539673
Batch 5/64 loss: 0.3627506494522095
Batch 6/64 loss: 0.36661040782928467
Batch 7/64 loss: 0.3673397898674011
Batch 8/64 loss: 0.3648645877838135
Batch 9/64 loss: 0.3647584915161133
Batch 10/64 loss: 0.3651541471481323
Batch 11/64 loss: 0.36402374505996704
Batch 12/64 loss: 0.3655811548233032
Batch 13/64 loss: 0.36782407760620117
Batch 14/64 loss: 0.3689175844192505
Batch 15/64 loss: 0.3671414852142334
Batch 16/64 loss: 0.36522340774536133
Batch 17/64 loss: 0.3665538430213928
Batch 18/64 loss: 0.36321377754211426
Batch 19/64 loss: 0.36811357736587524
Batch 20/64 loss: 0.36708390712738037
Batch 21/64 loss: 0.3661900758743286
Batch 22/64 loss: 0.36304211616516113
Batch 23/64 loss: 0.36533915996551514
Batch 24/64 loss: 0.362762451171875
Batch 25/64 loss: 0.36712777614593506
Batch 26/64 loss: 0.3644399642944336
Batch 27/64 loss: 0.3646389842033386
Batch 28/64 loss: 0.36179041862487793
Batch 29/64 loss: 0.36479878425598145
Batch 30/64 loss: 0.36343055963516235
Batch 31/64 loss: 0.36453545093536377
Batch 32/64 loss: 0.36648404598236084
Batch 33/64 loss: 0.3681449890136719
Batch 34/64 loss: 0.3671202063560486
Batch 35/64 loss: 0.364208459854126
Batch 36/64 loss: 0.363275408744812
Batch 37/64 loss: 0.36418962478637695
Batch 38/64 loss: 0.3644365668296814
Batch 39/64 loss: 0.364590048789978
Batch 40/64 loss: 0.3640368580818176
Batch 41/64 loss: 0.36607956886291504
Batch 42/64 loss: 0.36346757411956787
Batch 43/64 loss: 0.3665347099304199
Batch 44/64 loss: 0.36912763118743896
Batch 45/64 loss: 0.36568689346313477
Batch 46/64 loss: 0.3664711117744446
Batch 47/64 loss: 0.36562931537628174
Batch 48/64 loss: 0.3639984726905823
Batch 49/64 loss: 0.3644421100616455
Batch 50/64 loss: 0.36367905139923096
Batch 51/64 loss: 0.36472952365875244
Batch 52/64 loss: 0.364632785320282
Batch 53/64 loss: 0.36663055419921875
Batch 54/64 loss: 0.36269962787628174
Batch 55/64 loss: 0.3640315532684326
Batch 56/64 loss: 0.3646206855773926
Batch 57/64 loss: 0.36847054958343506
Batch 58/64 loss: 0.36129337549209595
Batch 59/64 loss: 0.36669766902923584
Batch 60/64 loss: 0.3659283518791199
Batch 61/64 loss: 0.3658313751220703
Batch 62/64 loss: 0.36343204975128174
Batch 63/64 loss: 0.36413317918777466
Batch 64/64 loss: 0.3653092384338379
Epoch 17  Train loss: 0.3652453057906207  Val loss: 0.3659014751001732
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: 0.3625146150588989
Batch 2/64 loss: 0.36621910333633423
Batch 3/64 loss: 0.36363768577575684
Batch 4/64 loss: 0.36194944381713867
Batch 5/64 loss: 0.366815447807312
Batch 6/64 loss: 0.36472272872924805
Batch 7/64 loss: 0.36468857526779175
Batch 8/64 loss: 0.3627081513404846
Batch 9/64 loss: 0.36186647415161133
Batch 10/64 loss: 0.36654382944107056
Batch 11/64 loss: 0.3655555248260498
Batch 12/64 loss: 0.3662656545639038
Batch 13/64 loss: 0.36580365896224976
Batch 14/64 loss: 0.36914175748825073
Batch 15/64 loss: 0.36582672595977783
Batch 16/64 loss: 0.36194807291030884
Batch 17/64 loss: 0.36236369609832764
Batch 18/64 loss: 0.3651636838912964
Batch 19/64 loss: 0.3645322918891907
Batch 20/64 loss: 0.36495059728622437
Batch 21/64 loss: 0.36528122425079346
Batch 22/64 loss: 0.3655394911766052
Batch 23/64 loss: 0.36368799209594727
Batch 24/64 loss: 0.36594080924987793
Batch 25/64 loss: 0.363516628742218
Batch 26/64 loss: 0.3643380403518677
Batch 27/64 loss: 0.3634880781173706
Batch 28/64 loss: 0.3632820248603821
Batch 29/64 loss: 0.36420488357543945
Batch 30/64 loss: 0.36453717947006226
Batch 31/64 loss: 0.36546432971954346
Batch 32/64 loss: 0.36664891242980957
Batch 33/64 loss: 0.36509037017822266
Batch 34/64 loss: 0.365040123462677
Batch 35/64 loss: 0.36564862728118896
Batch 36/64 loss: 0.3648107051849365
Batch 37/64 loss: 0.36484962701797485
Batch 38/64 loss: 0.36768221855163574
Batch 39/64 loss: 0.36412787437438965
Batch 40/64 loss: 0.3683055639266968
Batch 41/64 loss: 0.3659834861755371
Batch 42/64 loss: 0.36396872997283936
Batch 43/64 loss: 0.3643617630004883
Batch 44/64 loss: 0.3654657006263733
Batch 45/64 loss: 0.36823570728302
Batch 46/64 loss: 0.36523306369781494
Batch 47/64 loss: 0.3634243607521057
Batch 48/64 loss: 0.3628271222114563
Batch 49/64 loss: 0.3638656735420227
Batch 50/64 loss: 0.363919734954834
Batch 51/64 loss: 0.36497271060943604
Batch 52/64 loss: 0.3654876947402954
Batch 53/64 loss: 0.3672487139701843
Batch 54/64 loss: 0.36653077602386475
Batch 55/64 loss: 0.36304253339767456
Batch 56/64 loss: 0.36552178859710693
Batch 57/64 loss: 0.36669355630874634
Batch 58/64 loss: 0.3662651777267456
Batch 59/64 loss: 0.36581921577453613
Batch 60/64 loss: 0.3642154932022095
Batch 61/64 loss: 0.3664546012878418
Batch 62/64 loss: 0.36603981256484985
Batch 63/64 loss: 0.37068474292755127
Batch 64/64 loss: 0.37024986743927
Epoch 18  Train loss: 0.36515532521640554  Val loss: 0.3661714087646851
Epoch 19
-------------------------------
Batch 1/64 loss: 0.36289680004119873
Batch 2/64 loss: 0.36355656385421753
Batch 3/64 loss: 0.36452627182006836
Batch 4/64 loss: 0.36407387256622314
Batch 5/64 loss: 0.36367297172546387
Batch 6/64 loss: 0.36693882942199707
Batch 7/64 loss: 0.3624523878097534
Batch 8/64 loss: 0.36551403999328613
Batch 9/64 loss: 0.3666062355041504
Batch 10/64 loss: 0.3605501651763916
Batch 11/64 loss: 0.36568379402160645
Batch 12/64 loss: 0.369361937046051
Batch 13/64 loss: 0.36514049768447876
Batch 14/64 loss: 0.3627117872238159
Batch 15/64 loss: 0.36697280406951904
Batch 16/64 loss: 0.3651517629623413
Batch 17/64 loss: 0.36786144971847534
Batch 18/64 loss: 0.3638317584991455
Batch 19/64 loss: 0.36453932523727417
Batch 20/64 loss: 0.365919828414917
Batch 21/64 loss: 0.3680698275566101
Batch 22/64 loss: 0.3665737509727478
Batch 23/64 loss: 0.3679499626159668
Batch 24/64 loss: 0.3637390732765198
Batch 25/64 loss: 0.36414897441864014
Batch 26/64 loss: 0.36463189125061035
Batch 27/64 loss: 0.3616926670074463
Batch 28/64 loss: 0.364760160446167
Batch 29/64 loss: 0.36417603492736816
Batch 30/64 loss: 0.36557531356811523
Batch 31/64 loss: 0.36160707473754883
Batch 32/64 loss: 0.3656640648841858
Batch 33/64 loss: 0.36556822061538696
Batch 34/64 loss: 0.3650325536727905
Batch 35/64 loss: 0.36431658267974854
Batch 36/64 loss: 0.36571335792541504
Batch 37/64 loss: 0.3674640655517578
Batch 38/64 loss: 0.36522793769836426
Batch 39/64 loss: 0.364132285118103
Batch 40/64 loss: 0.36454057693481445
Batch 41/64 loss: 0.3678544759750366
Batch 42/64 loss: 0.3652389645576477
Batch 43/64 loss: 0.364088773727417
Batch 44/64 loss: 0.36526238918304443
Batch 45/64 loss: 0.36349570751190186
Batch 46/64 loss: 0.361940860748291
Batch 47/64 loss: 0.36590027809143066
Batch 48/64 loss: 0.3665965795516968
Batch 49/64 loss: 0.36155450344085693
Batch 50/64 loss: 0.36692124605178833
Batch 51/64 loss: 0.3652387261390686
Batch 52/64 loss: 0.36582762002944946
Batch 53/64 loss: 0.3663712739944458
Batch 54/64 loss: 0.3637823462486267
Batch 55/64 loss: 0.36371850967407227
Batch 56/64 loss: 0.36588454246520996
Batch 57/64 loss: 0.36357706785202026
Batch 58/64 loss: 0.36355847120285034
Batch 59/64 loss: 0.36159980297088623
Batch 60/64 loss: 0.36559659242630005
Batch 61/64 loss: 0.3646448850631714
Batch 62/64 loss: 0.36481547355651855
Batch 63/64 loss: 0.3696776032447815
Batch 64/64 loss: 0.3649325966835022
Epoch 19  Train loss: 0.3649473505861619  Val loss: 0.3657555039395991
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 0.36389821767807007
Batch 2/64 loss: 0.3651936650276184
Batch 3/64 loss: 0.3656601905822754
Batch 4/64 loss: 0.36517781019210815
Batch 5/64 loss: 0.367557168006897
Batch 6/64 loss: 0.3656821846961975
Batch 7/64 loss: 0.36352992057800293
Batch 8/64 loss: 0.3641563653945923
Batch 9/64 loss: 0.36144590377807617
Batch 10/64 loss: 0.362915575504303
Batch 11/64 loss: 0.3643037676811218
Batch 12/64 loss: 0.3643031120300293
Batch 13/64 loss: 0.36398202180862427
Batch 14/64 loss: 0.36619967222213745
Batch 15/64 loss: 0.3616181015968323
Batch 16/64 loss: 0.3630465269088745
Batch 17/64 loss: 0.36505699157714844
Batch 18/64 loss: 0.36514800786972046
Batch 19/64 loss: 0.36305713653564453
Batch 20/64 loss: 0.3637099266052246
Batch 21/64 loss: 0.367179274559021
Batch 22/64 loss: 0.36522793769836426
Batch 23/64 loss: 0.364365816116333
Batch 24/64 loss: 0.3618239760398865
Batch 25/64 loss: 0.36476659774780273
Batch 26/64 loss: 0.36506545543670654
Batch 27/64 loss: 0.36142343282699585
Batch 28/64 loss: 0.36486274003982544
Batch 29/64 loss: 0.36470890045166016
Batch 30/64 loss: 0.3660951256752014
Batch 31/64 loss: 0.3670518398284912
Batch 32/64 loss: 0.3642004132270813
Batch 33/64 loss: 0.3639400601387024
Batch 34/64 loss: 0.3669295310974121
Batch 35/64 loss: 0.36492133140563965
Batch 36/64 loss: 0.3613845109939575
Batch 37/64 loss: 0.3650705814361572
Batch 38/64 loss: 0.36500251293182373
Batch 39/64 loss: 0.36300086975097656
Batch 40/64 loss: 0.3646223545074463
Batch 41/64 loss: 0.36512666940689087
Batch 42/64 loss: 0.36617976427078247
Batch 43/64 loss: 0.36397987604141235
Batch 44/64 loss: 0.3641875982284546
Batch 45/64 loss: 0.36284828186035156
Batch 46/64 loss: 0.3639298677444458
Batch 47/64 loss: 0.36816585063934326
Batch 48/64 loss: 0.368327260017395
Batch 49/64 loss: 0.36317527294158936
Batch 50/64 loss: 0.3673723340034485
Batch 51/64 loss: 0.36347413063049316
Batch 52/64 loss: 0.3656998872756958
Batch 53/64 loss: 0.3623279333114624
Batch 54/64 loss: 0.36487680673599243
Batch 55/64 loss: 0.36144280433654785
Batch 56/64 loss: 0.3601555824279785
Batch 57/64 loss: 0.3643171191215515
Batch 58/64 loss: 0.36389338970184326
Batch 59/64 loss: 0.36483311653137207
Batch 60/64 loss: 0.36666810512542725
Batch 61/64 loss: 0.36828798055648804
Batch 62/64 loss: 0.36551159620285034
Batch 63/64 loss: 0.36514461040496826
Batch 64/64 loss: 0.3632620573043823
Epoch 20  Train loss: 0.36454365346945966  Val loss: 0.3654038570181201
Saving best model, epoch: 20
Epoch 21
-------------------------------
Batch 1/64 loss: 0.3642975687980652
Batch 2/64 loss: 0.3671865463256836
Batch 3/64 loss: 0.36234796047210693
Batch 4/64 loss: 0.36061733961105347
Batch 5/64 loss: 0.3652520179748535
Batch 6/64 loss: 0.3638353943824768
Batch 7/64 loss: 0.3630892038345337
Batch 8/64 loss: 0.3634300231933594
Batch 9/64 loss: 0.3630228042602539
Batch 10/64 loss: 0.3665758967399597
Batch 11/64 loss: 0.36608588695526123
Batch 12/64 loss: 0.3648826479911804
Batch 13/64 loss: 0.36573827266693115
Batch 14/64 loss: 0.36333274841308594
Batch 15/64 loss: 0.36563146114349365
Batch 16/64 loss: 0.36338216066360474
Batch 17/64 loss: 0.36451709270477295
Batch 18/64 loss: 0.3611438274383545
Batch 19/64 loss: 0.3659321069717407
Batch 20/64 loss: 0.36905378103256226
Batch 21/64 loss: 0.3645353317260742
Batch 22/64 loss: 0.36106061935424805
Batch 23/64 loss: 0.3645588755607605
Batch 24/64 loss: 0.36071932315826416
Batch 25/64 loss: 0.36583590507507324
Batch 26/64 loss: 0.3649420142173767
Batch 27/64 loss: 0.36265426874160767
Batch 28/64 loss: 0.36379754543304443
Batch 29/64 loss: 0.3641742467880249
Batch 30/64 loss: 0.36299312114715576
Batch 31/64 loss: 0.36458325386047363
Batch 32/64 loss: 0.3630253076553345
Batch 33/64 loss: 0.36296749114990234
Batch 34/64 loss: 0.3642575144767761
Batch 35/64 loss: 0.36554914712905884
Batch 36/64 loss: 0.36496299505233765
Batch 37/64 loss: 0.3650120496749878
Batch 38/64 loss: 0.36391133069992065
Batch 39/64 loss: 0.36753028631210327
Batch 40/64 loss: 0.36280298233032227
Batch 41/64 loss: 0.3626399636268616
Batch 42/64 loss: 0.36389970779418945
Batch 43/64 loss: 0.3623388409614563
Batch 44/64 loss: 0.36520957946777344
Batch 45/64 loss: 0.3669617176055908
Batch 46/64 loss: 0.36507874727249146
Batch 47/64 loss: 0.36312854290008545
Batch 48/64 loss: 0.36604583263397217
Batch 49/64 loss: 0.36224204301834106
Batch 50/64 loss: 0.3634047508239746
Batch 51/64 loss: 0.3657994866371155
Batch 52/64 loss: 0.3652445077896118
Batch 53/64 loss: 0.36362898349761963
Batch 54/64 loss: 0.3650321364402771
Batch 55/64 loss: 0.36503875255584717
Batch 56/64 loss: 0.36544591188430786
Batch 57/64 loss: 0.35985851287841797
Batch 58/64 loss: 0.3674585223197937
Batch 59/64 loss: 0.36613255739212036
Batch 60/64 loss: 0.3661280870437622
Batch 61/64 loss: 0.3668951988220215
Batch 62/64 loss: 0.36163294315338135
Batch 63/64 loss: 0.3661990165710449
Batch 64/64 loss: 0.3630995750427246
Epoch 21  Train loss: 0.3643450568704044  Val loss: 0.36531083546962934
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 0.3614571690559387
Batch 2/64 loss: 0.36650729179382324
Batch 3/64 loss: 0.3625185489654541
Batch 4/64 loss: 0.3644235134124756
Batch 5/64 loss: 0.3626255989074707
Batch 6/64 loss: 0.3622342348098755
Batch 7/64 loss: 0.3650015592575073
Batch 8/64 loss: 0.36343497037887573
Batch 9/64 loss: 0.364423930644989
Batch 10/64 loss: 0.364665150642395
Batch 11/64 loss: 0.3653843402862549
Batch 12/64 loss: 0.3645210266113281
Batch 13/64 loss: 0.3593413233757019
Batch 14/64 loss: 0.36371952295303345
Batch 15/64 loss: 0.3655184507369995
Batch 16/64 loss: 0.3649026155471802
Batch 17/64 loss: 0.3675283193588257
Batch 18/64 loss: 0.36588436365127563
Batch 19/64 loss: 0.3637808561325073
Batch 20/64 loss: 0.3598601222038269
Batch 21/64 loss: 0.36077654361724854
Batch 22/64 loss: 0.3631293773651123
Batch 23/64 loss: 0.3670979142189026
Batch 24/64 loss: 0.3666788339614868
Batch 25/64 loss: 0.36392104625701904
Batch 26/64 loss: 0.3672165870666504
Batch 27/64 loss: 0.3642078638076782
Batch 28/64 loss: 0.36333727836608887
Batch 29/64 loss: 0.3631330132484436
Batch 30/64 loss: 0.36470669507980347
Batch 31/64 loss: 0.3643369674682617
Batch 32/64 loss: 0.36403870582580566
Batch 33/64 loss: 0.3683396577835083
Batch 34/64 loss: 0.3659794330596924
Batch 35/64 loss: 0.36151134967803955
Batch 36/64 loss: 0.3647211790084839
Batch 37/64 loss: 0.3634554147720337
Batch 38/64 loss: 0.3612881302833557
Batch 39/64 loss: 0.36317145824432373
Batch 40/64 loss: 0.36414003372192383
Batch 41/64 loss: 0.3614097237586975
Batch 42/64 loss: 0.36042070388793945
Batch 43/64 loss: 0.3629419803619385
Batch 44/64 loss: 0.36355704069137573
Batch 45/64 loss: 0.3650321960449219
Batch 46/64 loss: 0.3628827929496765
Batch 47/64 loss: 0.36272233724594116
Batch 48/64 loss: 0.365786075592041
Batch 49/64 loss: 0.36378467082977295
Batch 50/64 loss: 0.36279547214508057
Batch 51/64 loss: 0.3626708388328552
Batch 52/64 loss: 0.36817288398742676
Batch 53/64 loss: 0.36244750022888184
Batch 54/64 loss: 0.3617558479309082
Batch 55/64 loss: 0.3630868196487427
Batch 56/64 loss: 0.36667048931121826
Batch 57/64 loss: 0.364812970161438
Batch 58/64 loss: 0.36670076847076416
Batch 59/64 loss: 0.3658071756362915
Batch 60/64 loss: 0.36197561025619507
Batch 61/64 loss: 0.3633260726928711
Batch 62/64 loss: 0.3602207899093628
Batch 63/64 loss: 0.362163782119751
Batch 64/64 loss: 0.3677956461906433
Epoch 22  Train loss: 0.36392018304151647  Val loss: 0.36556400609589934
Epoch 23
-------------------------------
Batch 1/64 loss: 0.3645344376564026
Batch 2/64 loss: 0.3641083240509033
Batch 3/64 loss: 0.36477065086364746
Batch 4/64 loss: 0.36020517349243164
Batch 5/64 loss: 0.362546443939209
Batch 6/64 loss: 0.36411476135253906
Batch 7/64 loss: 0.3594810366630554
Batch 8/64 loss: 0.3643661141395569
Batch 9/64 loss: 0.36270081996917725
Batch 10/64 loss: 0.36485135555267334
Batch 11/64 loss: 0.36499249935150146
Batch 12/64 loss: 0.3644104599952698
Batch 13/64 loss: 0.36152398586273193
Batch 14/64 loss: 0.3638831377029419
Batch 15/64 loss: 0.36554455757141113
Batch 16/64 loss: 0.36326754093170166
Batch 17/64 loss: 0.36448562145233154
Batch 18/64 loss: 0.35988253355026245
Batch 19/64 loss: 0.36562401056289673
Batch 20/64 loss: 0.3659321069717407
Batch 21/64 loss: 0.3661365509033203
Batch 22/64 loss: 0.36685675382614136
Batch 23/64 loss: 0.36234307289123535
Batch 24/64 loss: 0.36426711082458496
Batch 25/64 loss: 0.3642701506614685
Batch 26/64 loss: 0.36389589309692383
Batch 27/64 loss: 0.3637155294418335
Batch 28/64 loss: 0.3636513352394104
Batch 29/64 loss: 0.3627142906188965
Batch 30/64 loss: 0.36600565910339355
Batch 31/64 loss: 0.3648935556411743
Batch 32/64 loss: 0.36091238260269165
Batch 33/64 loss: 0.36368536949157715
Batch 34/64 loss: 0.3644278645515442
Batch 35/64 loss: 0.36422574520111084
Batch 36/64 loss: 0.36688268184661865
Batch 37/64 loss: 0.36307525634765625
Batch 38/64 loss: 0.3646841049194336
Batch 39/64 loss: 0.3620678186416626
Batch 40/64 loss: 0.3625563383102417
Batch 41/64 loss: 0.3649047017097473
Batch 42/64 loss: 0.36411750316619873
Batch 43/64 loss: 0.36431944370269775
Batch 44/64 loss: 0.3623497486114502
Batch 45/64 loss: 0.3674105405807495
Batch 46/64 loss: 0.3641388416290283
Batch 47/64 loss: 0.36425358057022095
Batch 48/64 loss: 0.3646721839904785
Batch 49/64 loss: 0.36291730403900146
Batch 50/64 loss: 0.36594027280807495
Batch 51/64 loss: 0.3655524253845215
Batch 52/64 loss: 0.3644568920135498
Batch 53/64 loss: 0.36631572246551514
Batch 54/64 loss: 0.363528311252594
Batch 55/64 loss: 0.3650331497192383
Batch 56/64 loss: 0.3618306517601013
Batch 57/64 loss: 0.3634093999862671
Batch 58/64 loss: 0.3625187873840332
Batch 59/64 loss: 0.36324429512023926
Batch 60/64 loss: 0.3637484312057495
Batch 61/64 loss: 0.3627361059188843
Batch 62/64 loss: 0.3657074570655823
Batch 63/64 loss: 0.3614025115966797
Batch 64/64 loss: 0.36158859729766846
Epoch 23  Train loss: 0.363893219536426  Val loss: 0.36411620353915025
Saving best model, epoch: 23
Epoch 24
-------------------------------
Batch 1/64 loss: 0.36286747455596924
Batch 2/64 loss: 0.3639119863510132
Batch 3/64 loss: 0.36229366064071655
Batch 4/64 loss: 0.3610779643058777
Batch 5/64 loss: 0.3618975281715393
Batch 6/64 loss: 0.36337393522262573
Batch 7/64 loss: 0.365068256855011
Batch 8/64 loss: 0.3619809150695801
Batch 9/64 loss: 0.36394834518432617
Batch 10/64 loss: 0.36296117305755615
Batch 11/64 loss: 0.36533987522125244
Batch 12/64 loss: 0.36381304264068604
Batch 13/64 loss: 0.3645375967025757
Batch 14/64 loss: 0.36193978786468506
Batch 15/64 loss: 0.3641895055770874
Batch 16/64 loss: 0.3616049289703369
Batch 17/64 loss: 0.36746394634246826
Batch 18/64 loss: 0.36566054821014404
Batch 19/64 loss: 0.36360687017440796
Batch 20/64 loss: 0.3647823929786682
Batch 21/64 loss: 0.36488640308380127
Batch 22/64 loss: 0.3639185428619385
Batch 23/64 loss: 0.3623729944229126
Batch 24/64 loss: 0.36460089683532715
Batch 25/64 loss: 0.3613970875740051
Batch 26/64 loss: 0.36620646715164185
Batch 27/64 loss: 0.36525261402130127
Batch 28/64 loss: 0.3624364137649536
Batch 29/64 loss: 0.3626313805580139
Batch 30/64 loss: 0.3651818037033081
Batch 31/64 loss: 0.3615248203277588
Batch 32/64 loss: 0.3642350435256958
Batch 33/64 loss: 0.3630087971687317
Batch 34/64 loss: 0.36382317543029785
Batch 35/64 loss: 0.36409687995910645
Batch 36/64 loss: 0.3614475727081299
Batch 37/64 loss: 0.36660289764404297
Batch 38/64 loss: 0.36695796251296997
Batch 39/64 loss: 0.3617372512817383
Batch 40/64 loss: 0.36346983909606934
Batch 41/64 loss: 0.3653990626335144
Batch 42/64 loss: 0.36559146642684937
Batch 43/64 loss: 0.3620624542236328
Batch 44/64 loss: 0.36447417736053467
Batch 45/64 loss: 0.3668947219848633
Batch 46/64 loss: 0.3634951114654541
Batch 47/64 loss: 0.3641955852508545
Batch 48/64 loss: 0.3640073537826538
Batch 49/64 loss: 0.36441630125045776
Batch 50/64 loss: 0.3577911853790283
Batch 51/64 loss: 0.36056697368621826
Batch 52/64 loss: 0.3644559979438782
Batch 53/64 loss: 0.36357581615448
Batch 54/64 loss: 0.361153781414032
Batch 55/64 loss: 0.3650616407394409
Batch 56/64 loss: 0.364162802696228
Batch 57/64 loss: 0.3641808032989502
Batch 58/64 loss: 0.3672220706939697
Batch 59/64 loss: 0.36729490756988525
Batch 60/64 loss: 0.3629765510559082
Batch 61/64 loss: 0.3613342046737671
Batch 62/64 loss: 0.3621866703033447
Batch 63/64 loss: 0.3613342046737671
Batch 64/64 loss: 0.3610766530036926
Epoch 24  Train loss: 0.363650979014004  Val loss: 0.364065876941091
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 0.3639131784439087
Batch 2/64 loss: 0.3659409284591675
Batch 3/64 loss: 0.3621658682823181
Batch 4/64 loss: 0.36222827434539795
Batch 5/64 loss: 0.3646203875541687
Batch 6/64 loss: 0.3638826012611389
Batch 7/64 loss: 0.3659679889678955
Batch 8/64 loss: 0.365364134311676
Batch 9/64 loss: 0.3639237880706787
Batch 10/64 loss: 0.36292266845703125
Batch 11/64 loss: 0.3636265993118286
Batch 12/64 loss: 0.3639678359031677
Batch 13/64 loss: 0.3598853349685669
Batch 14/64 loss: 0.36404848098754883
Batch 15/64 loss: 0.3644537925720215
Batch 16/64 loss: 0.3623311519622803
Batch 17/64 loss: 0.36321544647216797
Batch 18/64 loss: 0.3617898225784302
Batch 19/64 loss: 0.3666653037071228
Batch 20/64 loss: 0.3664582371711731
Batch 21/64 loss: 0.36282074451446533
Batch 22/64 loss: 0.36266767978668213
Batch 23/64 loss: 0.3648342490196228
Batch 24/64 loss: 0.3640196919441223
Batch 25/64 loss: 0.3632740378379822
Batch 26/64 loss: 0.3630439043045044
Batch 27/64 loss: 0.3608648180961609
Batch 28/64 loss: 0.36470097303390503
Batch 29/64 loss: 0.3632621765136719
Batch 30/64 loss: 0.3652503490447998
Batch 31/64 loss: 0.36474335193634033
Batch 32/64 loss: 0.3640982508659363
Batch 33/64 loss: 0.3633262515068054
Batch 34/64 loss: 0.36220067739486694
Batch 35/64 loss: 0.36339181661605835
Batch 36/64 loss: 0.368503212928772
Batch 37/64 loss: 0.36298537254333496
Batch 38/64 loss: 0.36563342809677124
Batch 39/64 loss: 0.36314308643341064
Batch 40/64 loss: 0.3617708683013916
Batch 41/64 loss: 0.36328327655792236
Batch 42/64 loss: 0.3632820248603821
Batch 43/64 loss: 0.3644980788230896
Batch 44/64 loss: 0.3598148226737976
Batch 45/64 loss: 0.3606443405151367
Batch 46/64 loss: 0.36281073093414307
Batch 47/64 loss: 0.36130356788635254
Batch 48/64 loss: 0.36337316036224365
Batch 49/64 loss: 0.36084139347076416
Batch 50/64 loss: 0.36405301094055176
Batch 51/64 loss: 0.36300551891326904
Batch 52/64 loss: 0.3647080659866333
Batch 53/64 loss: 0.36601758003234863
Batch 54/64 loss: 0.36449140310287476
Batch 55/64 loss: 0.3641895651817322
Batch 56/64 loss: 0.36416125297546387
Batch 57/64 loss: 0.3613947629928589
Batch 58/64 loss: 0.36288440227508545
Batch 59/64 loss: 0.3615434169769287
Batch 60/64 loss: 0.36042851209640503
Batch 61/64 loss: 0.3622307777404785
Batch 62/64 loss: 0.3644161820411682
Batch 63/64 loss: 0.36082595586776733
Batch 64/64 loss: 0.3614358901977539
Epoch 25  Train loss: 0.36340683114294914  Val loss: 0.364345444846399
Epoch 26
-------------------------------
Batch 1/64 loss: 0.3592383861541748
Batch 2/64 loss: 0.3634100556373596
Batch 3/64 loss: 0.36178529262542725
Batch 4/64 loss: 0.3599206209182739
Batch 5/64 loss: 0.36351478099823
Batch 6/64 loss: 0.36062759160995483
Batch 7/64 loss: 0.3609139323234558
Batch 8/64 loss: 0.36415040493011475
Batch 9/64 loss: 0.3666061758995056
Batch 10/64 loss: 0.36256980895996094
Batch 11/64 loss: 0.36194151639938354
Batch 12/64 loss: 0.36199021339416504
Batch 13/64 loss: 0.3627133369445801
Batch 14/64 loss: 0.3604156970977783
Batch 15/64 loss: 0.3604103922843933
Batch 16/64 loss: 0.3644822835922241
Batch 17/64 loss: 0.36354559659957886
Batch 18/64 loss: 0.36290228366851807
Batch 19/64 loss: 0.363364040851593
Batch 20/64 loss: 0.36280298233032227
Batch 21/64 loss: 0.3642064332962036
Batch 22/64 loss: 0.3633360266685486
Batch 23/64 loss: 0.3658015727996826
Batch 24/64 loss: 0.3642939329147339
Batch 25/64 loss: 0.3625970482826233
Batch 26/64 loss: 0.36387044191360474
Batch 27/64 loss: 0.36457884311676025
Batch 28/64 loss: 0.3624849319458008
Batch 29/64 loss: 0.36734551191329956
Batch 30/64 loss: 0.3612957000732422
Batch 31/64 loss: 0.3642290234565735
Batch 32/64 loss: 0.364618182182312
Batch 33/64 loss: 0.3619511127471924
Batch 34/64 loss: 0.36449623107910156
Batch 35/64 loss: 0.36180436611175537
Batch 36/64 loss: 0.3633738160133362
Batch 37/64 loss: 0.36489206552505493
Batch 38/64 loss: 0.36524832248687744
Batch 39/64 loss: 0.36088240146636963
Batch 40/64 loss: 0.3595994710922241
Batch 41/64 loss: 0.3593398332595825
Batch 42/64 loss: 0.36403799057006836
Batch 43/64 loss: 0.36397039890289307
Batch 44/64 loss: 0.36040186882019043
Batch 45/64 loss: 0.36278414726257324
Batch 46/64 loss: 0.3657625913619995
Batch 47/64 loss: 0.3639480471611023
Batch 48/64 loss: 0.36571311950683594
Batch 49/64 loss: 0.3629494309425354
Batch 50/64 loss: 0.36691367626190186
Batch 51/64 loss: 0.3673957586288452
Batch 52/64 loss: 0.3647170066833496
Batch 53/64 loss: 0.36056065559387207
Batch 54/64 loss: 0.3623403310775757
Batch 55/64 loss: 0.36623942852020264
Batch 56/64 loss: 0.36237502098083496
Batch 57/64 loss: 0.3634117841720581
Batch 58/64 loss: 0.3629636764526367
Batch 59/64 loss: 0.36623555421829224
Batch 60/64 loss: 0.3617115616798401
Batch 61/64 loss: 0.3621193766593933
Batch 62/64 loss: 0.36643296480178833
Batch 63/64 loss: 0.36388230323791504
Batch 64/64 loss: 0.3635070323944092
Epoch 26  Train loss: 0.3632478059506884  Val loss: 0.36438614314364404
Epoch 27
-------------------------------
Batch 1/64 loss: 0.3627869486808777
Batch 2/64 loss: 0.36544716358184814
Batch 3/64 loss: 0.3630419969558716
Batch 4/64 loss: 0.36241263151168823
Batch 5/64 loss: 0.363170325756073
Batch 6/64 loss: 0.3646465539932251
Batch 7/64 loss: 0.3628714680671692
Batch 8/64 loss: 0.36425119638442993
Batch 9/64 loss: 0.3613886833190918
Batch 10/64 loss: 0.36379921436309814
Batch 11/64 loss: 0.3625389337539673
Batch 12/64 loss: 0.3664306402206421
Batch 13/64 loss: 0.362155556678772
Batch 14/64 loss: 0.36107587814331055
Batch 15/64 loss: 0.3580934405326843
Batch 16/64 loss: 0.36203908920288086
Batch 17/64 loss: 0.3656926155090332
Batch 18/64 loss: 0.36476659774780273
Batch 19/64 loss: 0.36497730016708374
Batch 20/64 loss: 0.3638140559196472
Batch 21/64 loss: 0.3620821237564087
Batch 22/64 loss: 0.36075258255004883
Batch 23/64 loss: 0.3602466583251953
Batch 24/64 loss: 0.3661496639251709
Batch 25/64 loss: 0.36311882734298706
Batch 26/64 loss: 0.36369943618774414
Batch 27/64 loss: 0.36336320638656616
Batch 28/64 loss: 0.36168575286865234
Batch 29/64 loss: 0.3632240295410156
Batch 30/64 loss: 0.36068201065063477
Batch 31/64 loss: 0.36271530389785767
Batch 32/64 loss: 0.3624401092529297
Batch 33/64 loss: 0.36456578969955444
Batch 34/64 loss: 0.3637368679046631
Batch 35/64 loss: 0.3624687194824219
Batch 36/64 loss: 0.363226056098938
Batch 37/64 loss: 0.36227428913116455
Batch 38/64 loss: 0.3637455105781555
Batch 39/64 loss: 0.3629624843597412
Batch 40/64 loss: 0.3618663549423218
Batch 41/64 loss: 0.3630492687225342
Batch 42/64 loss: 0.3631945252418518
Batch 43/64 loss: 0.36306846141815186
Batch 44/64 loss: 0.3620525598526001
Batch 45/64 loss: 0.35872238874435425
Batch 46/64 loss: 0.36128711700439453
Batch 47/64 loss: 0.3635857105255127
Batch 48/64 loss: 0.36141061782836914
Batch 49/64 loss: 0.3627561330795288
Batch 50/64 loss: 0.36569535732269287
Batch 51/64 loss: 0.36339980363845825
Batch 52/64 loss: 0.36455869674682617
Batch 53/64 loss: 0.36121487617492676
Batch 54/64 loss: 0.3646726608276367
Batch 55/64 loss: 0.36440378427505493
Batch 56/64 loss: 0.36366188526153564
Batch 57/64 loss: 0.36475861072540283
Batch 58/64 loss: 0.3623719811439514
Batch 59/64 loss: 0.3632434606552124
Batch 60/64 loss: 0.3644213080406189
Batch 61/64 loss: 0.36435824632644653
Batch 62/64 loss: 0.36511170864105225
Batch 63/64 loss: 0.36410248279571533
Batch 64/64 loss: 0.3647496700286865
Epoch 27  Train loss: 0.3631226661158543  Val loss: 0.3641198783396036
Epoch 28
-------------------------------
Batch 1/64 loss: 0.36313706636428833
Batch 2/64 loss: 0.3605731725692749
Batch 3/64 loss: 0.3625085949897766
Batch 4/64 loss: 0.3632582426071167
Batch 5/64 loss: 0.36157119274139404
Batch 6/64 loss: 0.36289888620376587
Batch 7/64 loss: 0.3652728796005249
Batch 8/64 loss: 0.3638613224029541
Batch 9/64 loss: 0.3622548580169678
Batch 10/64 loss: 0.36685943603515625
Batch 11/64 loss: 0.3639673590660095
Batch 12/64 loss: 0.3647226095199585
Batch 13/64 loss: 0.36442697048187256
Batch 14/64 loss: 0.3615819215774536
Batch 15/64 loss: 0.36177998781204224
Batch 16/64 loss: 0.36365848779678345
Batch 17/64 loss: 0.35986757278442383
Batch 18/64 loss: 0.36375874280929565
Batch 19/64 loss: 0.36424171924591064
Batch 20/64 loss: 0.36409229040145874
Batch 21/64 loss: 0.3642352819442749
Batch 22/64 loss: 0.3643479347229004
Batch 23/64 loss: 0.36482518911361694
Batch 24/64 loss: 0.36160290241241455
Batch 25/64 loss: 0.3624759912490845
Batch 26/64 loss: 0.3624454140663147
Batch 27/64 loss: 0.3635331988334656
Batch 28/64 loss: 0.36253422498703003
Batch 29/64 loss: 0.36603987216949463
Batch 30/64 loss: 0.3639177680015564
Batch 31/64 loss: 0.3606215715408325
Batch 32/64 loss: 0.3655424118041992
Batch 33/64 loss: 0.36422061920166016
Batch 34/64 loss: 0.36534255743026733
Batch 35/64 loss: 0.3634411096572876
Batch 36/64 loss: 0.3621011972427368
Batch 37/64 loss: 0.3620039224624634
Batch 38/64 loss: 0.361051082611084
Batch 39/64 loss: 0.3648214340209961
Batch 40/64 loss: 0.3634764552116394
Batch 41/64 loss: 0.36183595657348633
Batch 42/64 loss: 0.36891603469848633
Batch 43/64 loss: 0.36435890197753906
Batch 44/64 loss: 0.36315494775772095
Batch 45/64 loss: 0.3628210425376892
Batch 46/64 loss: 0.36144113540649414
Batch 47/64 loss: 0.36249542236328125
Batch 48/64 loss: 0.36077725887298584
Batch 49/64 loss: 0.36125171184539795
Batch 50/64 loss: 0.3629237413406372
Batch 51/64 loss: 0.36239832639694214
Batch 52/64 loss: 0.36224365234375
Batch 53/64 loss: 0.35957640409469604
Batch 54/64 loss: 0.3646671772003174
Batch 55/64 loss: 0.3617563247680664
Batch 56/64 loss: 0.3636515140533447
Batch 57/64 loss: 0.36065733432769775
Batch 58/64 loss: 0.36146724224090576
Batch 59/64 loss: 0.36201369762420654
Batch 60/64 loss: 0.3616304397583008
Batch 61/64 loss: 0.3658841848373413
Batch 62/64 loss: 0.36499422788619995
Batch 63/64 loss: 0.3627634048461914
Batch 64/64 loss: 0.36216485500335693
Epoch 28  Train loss: 0.36310866159551286  Val loss: 0.36427059595527517
Epoch 29
-------------------------------
Batch 1/64 loss: 0.36190712451934814
Batch 2/64 loss: 0.3618171215057373
Batch 3/64 loss: 0.36154234409332275
Batch 4/64 loss: 0.3641479015350342
Batch 5/64 loss: 0.36055290699005127
Batch 6/64 loss: 0.3632606267929077
Batch 7/64 loss: 0.3641601800918579
Batch 8/64 loss: 0.3633667230606079
Batch 9/64 loss: 0.3594696521759033
Batch 10/64 loss: 0.3661695718765259
Batch 11/64 loss: 0.36431968212127686
Batch 12/64 loss: 0.364229679107666
Batch 13/64 loss: 0.362682580947876
Batch 14/64 loss: 0.36424964666366577
Batch 15/64 loss: 0.3617391586303711
Batch 16/64 loss: 0.360787034034729
Batch 17/64 loss: 0.3661871552467346
Batch 18/64 loss: 0.36325764656066895
Batch 19/64 loss: 0.36179018020629883
Batch 20/64 loss: 0.36136800050735474
Batch 21/64 loss: 0.3620699644088745
Batch 22/64 loss: 0.36193037033081055
Batch 23/64 loss: 0.36226850748062134
Batch 24/64 loss: 0.3611617684364319
Batch 25/64 loss: 0.3588618040084839
Batch 26/64 loss: 0.363051176071167
Batch 27/64 loss: 0.36342155933380127
Batch 28/64 loss: 0.36286699771881104
Batch 29/64 loss: 0.3614335060119629
Batch 30/64 loss: 0.36350715160369873
Batch 31/64 loss: 0.36556416749954224
Batch 32/64 loss: 0.3653210401535034
Batch 33/64 loss: 0.3622483015060425
Batch 34/64 loss: 0.36297106742858887
Batch 35/64 loss: 0.36636972427368164
Batch 36/64 loss: 0.362435519695282
Batch 37/64 loss: 0.36104530096054077
Batch 38/64 loss: 0.36078256368637085
Batch 39/64 loss: 0.36152416467666626
Batch 40/64 loss: 0.35886991024017334
Batch 41/64 loss: 0.36351871490478516
Batch 42/64 loss: 0.36426907777786255
Batch 43/64 loss: 0.3646707534790039
Batch 44/64 loss: 0.3609275221824646
Batch 45/64 loss: 0.36011046171188354
Batch 46/64 loss: 0.3624545931816101
Batch 47/64 loss: 0.36183488368988037
Batch 48/64 loss: 0.3621267080307007
Batch 49/64 loss: 0.3639007806777954
Batch 50/64 loss: 0.3624153137207031
Batch 51/64 loss: 0.3621096611022949
Batch 52/64 loss: 0.3613814115524292
Batch 53/64 loss: 0.3657594919204712
Batch 54/64 loss: 0.36423563957214355
Batch 55/64 loss: 0.36299484968185425
Batch 56/64 loss: 0.3607609272003174
Batch 57/64 loss: 0.36143189668655396
Batch 58/64 loss: 0.36480939388275146
Batch 59/64 loss: 0.36351507902145386
Batch 60/64 loss: 0.36499929428100586
Batch 61/64 loss: 0.3573411703109741
Batch 62/64 loss: 0.364496648311615
Batch 63/64 loss: 0.36476582288742065
Batch 64/64 loss: 0.36192792654037476
Epoch 29  Train loss: 0.3626821258488823  Val loss: 0.36365556819332423
Saving best model, epoch: 29
Epoch 30
-------------------------------
Batch 1/64 loss: 0.364032506942749
Batch 2/64 loss: 0.3617980480194092
Batch 3/64 loss: 0.35996925830841064
Batch 4/64 loss: 0.36094748973846436
Batch 5/64 loss: 0.362731397151947
Batch 6/64 loss: 0.36339879035949707
Batch 7/64 loss: 0.3628077507019043
Batch 8/64 loss: 0.36358821392059326
Batch 9/64 loss: 0.36452949047088623
Batch 10/64 loss: 0.36259591579437256
Batch 11/64 loss: 0.357962965965271
Batch 12/64 loss: 0.3650398850440979
Batch 13/64 loss: 0.36332976818084717
Batch 14/64 loss: 0.36300039291381836
Batch 15/64 loss: 0.3650461435317993
Batch 16/64 loss: 0.36198413372039795
Batch 17/64 loss: 0.3633524179458618
Batch 18/64 loss: 0.36407214403152466
Batch 19/64 loss: 0.3597029447555542
Batch 20/64 loss: 0.36580848693847656
Batch 21/64 loss: 0.36453449726104736
Batch 22/64 loss: 0.3628368377685547
Batch 23/64 loss: 0.36416614055633545
Batch 24/64 loss: 0.36327672004699707
Batch 25/64 loss: 0.3601284623146057
Batch 26/64 loss: 0.36113959550857544
Batch 27/64 loss: 0.3648570775985718
Batch 28/64 loss: 0.36034226417541504
Batch 29/64 loss: 0.3629167675971985
Batch 30/64 loss: 0.36368829011917114
Batch 31/64 loss: 0.36329126358032227
Batch 32/64 loss: 0.363613486289978
Batch 33/64 loss: 0.3666667342185974
Batch 34/64 loss: 0.3632638454437256
Batch 35/64 loss: 0.36540061235427856
Batch 36/64 loss: 0.3636842966079712
Batch 37/64 loss: 0.36204415559768677
Batch 38/64 loss: 0.3597484230995178
Batch 39/64 loss: 0.3585372567176819
Batch 40/64 loss: 0.359027624130249
Batch 41/64 loss: 0.36225229501724243
Batch 42/64 loss: 0.35957247018814087
Batch 43/64 loss: 0.3597225546836853
Batch 44/64 loss: 0.36646199226379395
Batch 45/64 loss: 0.36396944522857666
Batch 46/64 loss: 0.36054348945617676
Batch 47/64 loss: 0.36086833477020264
Batch 48/64 loss: 0.35884958505630493
Batch 49/64 loss: 0.36513274908065796
Batch 50/64 loss: 0.3621635437011719
Batch 51/64 loss: 0.36426854133605957
Batch 52/64 loss: 0.3645317554473877
Batch 53/64 loss: 0.36501049995422363
Batch 54/64 loss: 0.36470627784729004
Batch 55/64 loss: 0.3607412576675415
Batch 56/64 loss: 0.36571693420410156
Batch 57/64 loss: 0.3667941093444824
Batch 58/64 loss: 0.3608575463294983
Batch 59/64 loss: 0.3625354766845703
Batch 60/64 loss: 0.3622095584869385
Batch 61/64 loss: 0.36259210109710693
Batch 62/64 loss: 0.3637734651565552
Batch 63/64 loss: 0.36312007904052734
Batch 64/64 loss: 0.35999107360839844
Epoch 30  Train loss: 0.36274901745366117  Val loss: 0.3646079555819534
Epoch 31
-------------------------------
Batch 1/64 loss: 0.36187589168548584
Batch 2/64 loss: 0.36428266763687134
Batch 3/64 loss: 0.3666502833366394
Batch 4/64 loss: 0.3605607748031616
Batch 5/64 loss: 0.3610607385635376
Batch 6/64 loss: 0.3597080707550049
Batch 7/64 loss: 0.36633074283599854
Batch 8/64 loss: 0.36038511991500854
Batch 9/64 loss: 0.3648475408554077
Batch 10/64 loss: 0.36608415842056274
Batch 11/64 loss: 0.3648557662963867
Batch 12/64 loss: 0.3644633889198303
Batch 13/64 loss: 0.3648262023925781
Batch 14/64 loss: 0.362048864364624
Batch 15/64 loss: 0.3611184358596802
Batch 16/64 loss: 0.36428338289260864
Batch 17/64 loss: 0.36115092039108276
Batch 18/64 loss: 0.3652280569076538
Batch 19/64 loss: 0.3649404048919678
Batch 20/64 loss: 0.36402297019958496
Batch 21/64 loss: 0.36427974700927734
Batch 22/64 loss: 0.3634410500526428
Batch 23/64 loss: 0.3643299341201782
Batch 24/64 loss: 0.36233800649642944
Batch 25/64 loss: 0.36435985565185547
Batch 26/64 loss: 0.3626059293746948
Batch 27/64 loss: 0.3635730743408203
Batch 28/64 loss: 0.3634932041168213
Batch 29/64 loss: 0.36370235681533813
Batch 30/64 loss: 0.3641042709350586
Batch 31/64 loss: 0.36239326000213623
Batch 32/64 loss: 0.36401569843292236
Batch 33/64 loss: 0.35986602306365967
Batch 34/64 loss: 0.3628702163696289
Batch 35/64 loss: 0.3643937110900879
Batch 36/64 loss: 0.36318695545196533
Batch 37/64 loss: 0.36177074909210205
Batch 38/64 loss: 0.3616597652435303
Batch 39/64 loss: 0.36060237884521484
Batch 40/64 loss: 0.36471718549728394
Batch 41/64 loss: 0.3640933036804199
Batch 42/64 loss: 0.36042487621307373
Batch 43/64 loss: 0.3630716800689697
Batch 44/64 loss: 0.36291855573654175
Batch 45/64 loss: 0.3674488663673401
Batch 46/64 loss: 0.36186838150024414
Batch 47/64 loss: 0.3616495132446289
Batch 48/64 loss: 0.3604651093482971
Batch 49/64 loss: 0.35894614458084106
Batch 50/64 loss: 0.36220037937164307
Batch 51/64 loss: 0.35785043239593506
Batch 52/64 loss: 0.3644979000091553
Batch 53/64 loss: 0.36140328645706177
Batch 54/64 loss: 0.3646998405456543
Batch 55/64 loss: 0.3658578395843506
Batch 56/64 loss: 0.363728404045105
Batch 57/64 loss: 0.35872066020965576
Batch 58/64 loss: 0.3635847568511963
Batch 59/64 loss: 0.36117660999298096
Batch 60/64 loss: 0.3612964153289795
Batch 61/64 loss: 0.36108553409576416
Batch 62/64 loss: 0.364729106426239
Batch 63/64 loss: 0.3601655960083008
Batch 64/64 loss: 0.3575860261917114
Epoch 31  Train loss: 0.3628313798530429  Val loss: 0.3632710094714083
Saving best model, epoch: 31
Epoch 32
-------------------------------
Batch 1/64 loss: 0.3626207709312439
Batch 2/64 loss: 0.35967421531677246
Batch 3/64 loss: 0.36322176456451416
Batch 4/64 loss: 0.36140018701553345
Batch 5/64 loss: 0.3597814440727234
Batch 6/64 loss: 0.360703706741333
Batch 7/64 loss: 0.36538493633270264
Batch 8/64 loss: 0.3642106056213379
Batch 9/64 loss: 0.36117589473724365
Batch 10/64 loss: 0.36272263526916504
Batch 11/64 loss: 0.3656649589538574
Batch 12/64 loss: 0.36503076553344727
Batch 13/64 loss: 0.3607906103134155
Batch 14/64 loss: 0.35944676399230957
Batch 15/64 loss: 0.3607800006866455
Batch 16/64 loss: 0.3610604405403137
Batch 17/64 loss: 0.3635125756263733
Batch 18/64 loss: 0.363089919090271
Batch 19/64 loss: 0.36112040281295776
Batch 20/64 loss: 0.3620278835296631
Batch 21/64 loss: 0.36612117290496826
Batch 22/64 loss: 0.3648245334625244
Batch 23/64 loss: 0.3621768355369568
Batch 24/64 loss: 0.3609699606895447
Batch 25/64 loss: 0.36215853691101074
Batch 26/64 loss: 0.3636312484741211
Batch 27/64 loss: 0.3622094392776489
Batch 28/64 loss: 0.36093366146087646
Batch 29/64 loss: 0.36548519134521484
Batch 30/64 loss: 0.3621382713317871
Batch 31/64 loss: 0.3619024157524109
Batch 32/64 loss: 0.36009514331817627
Batch 33/64 loss: 0.3639509677886963
Batch 34/64 loss: 0.3641356825828552
Batch 35/64 loss: 0.36399465799331665
Batch 36/64 loss: 0.35976171493530273
Batch 37/64 loss: 0.36122846603393555
Batch 38/64 loss: 0.36313438415527344
Batch 39/64 loss: 0.3621852993965149
Batch 40/64 loss: 0.3610602617263794
Batch 41/64 loss: 0.36319148540496826
Batch 42/64 loss: 0.3617035150527954
Batch 43/64 loss: 0.36362743377685547
Batch 44/64 loss: 0.3622010350227356
Batch 45/64 loss: 0.36314600706100464
Batch 46/64 loss: 0.3631443381309509
Batch 47/64 loss: 0.36499708890914917
Batch 48/64 loss: 0.3626515865325928
Batch 49/64 loss: 0.36149734258651733
Batch 50/64 loss: 0.361958384513855
Batch 51/64 loss: 0.365386426448822
Batch 52/64 loss: 0.36145269870758057
Batch 53/64 loss: 0.3617789149284363
Batch 54/64 loss: 0.35975420475006104
Batch 55/64 loss: 0.36459630727767944
Batch 56/64 loss: 0.36249619722366333
Batch 57/64 loss: 0.36751091480255127
Batch 58/64 loss: 0.363147497177124
Batch 59/64 loss: 0.3608516454696655
Batch 60/64 loss: 0.36380040645599365
Batch 61/64 loss: 0.36169004440307617
Batch 62/64 loss: 0.36407268047332764
Batch 63/64 loss: 0.35970360040664673
Batch 64/64 loss: 0.36069440841674805
Epoch 32  Train loss: 0.3625160609974581  Val loss: 0.36295637232331474
Saving best model, epoch: 32
Epoch 33
-------------------------------
Batch 1/64 loss: 0.36551010608673096
Batch 2/64 loss: 0.3583584427833557
Batch 3/64 loss: 0.3631567358970642
Batch 4/64 loss: 0.36529266834259033
Batch 5/64 loss: 0.3621692657470703
Batch 6/64 loss: 0.3614826202392578
Batch 7/64 loss: 0.36164379119873047
Batch 8/64 loss: 0.3614078760147095
Batch 9/64 loss: 0.36138319969177246
Batch 10/64 loss: 0.3641730546951294
Batch 11/64 loss: 0.3635828495025635
Batch 12/64 loss: 0.3612101674079895
Batch 13/64 loss: 0.36530423164367676
Batch 14/64 loss: 0.36238348484039307
Batch 15/64 loss: 0.36217570304870605
Batch 16/64 loss: 0.360628604888916
Batch 17/64 loss: 0.36336755752563477
Batch 18/64 loss: 0.3641486167907715
Batch 19/64 loss: 0.36312973499298096
Batch 20/64 loss: 0.3639744520187378
Batch 21/64 loss: 0.36104297637939453
Batch 22/64 loss: 0.3649587631225586
Batch 23/64 loss: 0.35976868867874146
Batch 24/64 loss: 0.36067265272140503
Batch 25/64 loss: 0.3656270503997803
Batch 26/64 loss: 0.3626263737678528
Batch 27/64 loss: 0.36100268363952637
Batch 28/64 loss: 0.3595130443572998
Batch 29/64 loss: 0.36401522159576416
Batch 30/64 loss: 0.3617286682128906
Batch 31/64 loss: 0.3635328412055969
Batch 32/64 loss: 0.36200225353240967
Batch 33/64 loss: 0.3624323606491089
Batch 34/64 loss: 0.36199748516082764
Batch 35/64 loss: 0.3621279001235962
Batch 36/64 loss: 0.36524856090545654
Batch 37/64 loss: 0.3627377152442932
Batch 38/64 loss: 0.3617669939994812
Batch 39/64 loss: 0.3613964915275574
Batch 40/64 loss: 0.3669053316116333
Batch 41/64 loss: 0.3634566068649292
Batch 42/64 loss: 0.3650212287902832
Batch 43/64 loss: 0.3603774309158325
Batch 44/64 loss: 0.3610832691192627
Batch 45/64 loss: 0.3605876564979553
Batch 46/64 loss: 0.3653184771537781
Batch 47/64 loss: 0.361164927482605
Batch 48/64 loss: 0.3635685443878174
Batch 49/64 loss: 0.36062490940093994
Batch 50/64 loss: 0.36547982692718506
Batch 51/64 loss: 0.3646284341812134
Batch 52/64 loss: 0.3618062734603882
Batch 53/64 loss: 0.3592243194580078
Batch 54/64 loss: 0.36011433601379395
Batch 55/64 loss: 0.3612633943557739
Batch 56/64 loss: 0.3605042099952698
Batch 57/64 loss: 0.3629170060157776
Batch 58/64 loss: 0.3597973585128784
Batch 59/64 loss: 0.36024391651153564
Batch 60/64 loss: 0.36145156621932983
Batch 61/64 loss: 0.3607950806617737
Batch 62/64 loss: 0.36032092571258545
Batch 63/64 loss: 0.3580951690673828
Batch 64/64 loss: 0.3610013723373413
Epoch 33  Train loss: 0.3622616959553139  Val loss: 0.3634105873681426
Epoch 34
-------------------------------
Batch 1/64 loss: 0.36026161909103394
Batch 2/64 loss: 0.36171066761016846
Batch 3/64 loss: 0.3645508885383606
Batch 4/64 loss: 0.357893168926239
Batch 5/64 loss: 0.36415398120880127
Batch 6/64 loss: 0.3624160885810852
Batch 7/64 loss: 0.3595767617225647
Batch 8/64 loss: 0.3635910749435425
Batch 9/64 loss: 0.36031007766723633
Batch 10/64 loss: 0.3592885732650757
Batch 11/64 loss: 0.35994142293930054
Batch 12/64 loss: 0.3656609058380127
Batch 13/64 loss: 0.36183828115463257
Batch 14/64 loss: 0.3580241799354553
Batch 15/64 loss: 0.3632591962814331
Batch 16/64 loss: 0.36215758323669434
Batch 17/64 loss: 0.3627117872238159
Batch 18/64 loss: 0.3625756502151489
Batch 19/64 loss: 0.3603048324584961
Batch 20/64 loss: 0.36037272214889526
Batch 21/64 loss: 0.3623710870742798
Batch 22/64 loss: 0.3634154796600342
Batch 23/64 loss: 0.3659929633140564
Batch 24/64 loss: 0.362332820892334
Batch 25/64 loss: 0.36360442638397217
Batch 26/64 loss: 0.3629103899002075
Batch 27/64 loss: 0.3616201877593994
Batch 28/64 loss: 0.36375802755355835
Batch 29/64 loss: 0.3642430305480957
Batch 30/64 loss: 0.36576974391937256
Batch 31/64 loss: 0.3628550171852112
Batch 32/64 loss: 0.36118781566619873
Batch 33/64 loss: 0.36399221420288086
Batch 34/64 loss: 0.3647029399871826
Batch 35/64 loss: 0.359106183052063
Batch 36/64 loss: 0.3625496029853821
Batch 37/64 loss: 0.3618006706237793
Batch 38/64 loss: 0.3649466633796692
Batch 39/64 loss: 0.3640825152397156
Batch 40/64 loss: 0.3612678647041321
Batch 41/64 loss: 0.3590724468231201
Batch 42/64 loss: 0.36196374893188477
Batch 43/64 loss: 0.3627815246582031
Batch 44/64 loss: 0.3614593744277954
Batch 45/64 loss: 0.3624451160430908
Batch 46/64 loss: 0.35955309867858887
Batch 47/64 loss: 0.36146998405456543
Batch 48/64 loss: 0.36287200450897217
Batch 49/64 loss: 0.3635239601135254
Batch 50/64 loss: 0.36358511447906494
Batch 51/64 loss: 0.3618866801261902
Batch 52/64 loss: 0.3641246557235718
Batch 53/64 loss: 0.3602592945098877
Batch 54/64 loss: 0.3651593327522278
Batch 55/64 loss: 0.3635717034339905
Batch 56/64 loss: 0.36168813705444336
Batch 57/64 loss: 0.3622314929962158
Batch 58/64 loss: 0.36147773265838623
Batch 59/64 loss: 0.3640015721321106
Batch 60/64 loss: 0.363653302192688
Batch 61/64 loss: 0.3605044484138489
Batch 62/64 loss: 0.36377912759780884
Batch 63/64 loss: 0.3609539270401001
Batch 64/64 loss: 0.3611217141151428
Epoch 34  Train loss: 0.36228969681496714  Val loss: 0.3627353558425641
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: 0.3647497892379761
Batch 2/64 loss: 0.3612334132194519
Batch 3/64 loss: 0.36279356479644775
Batch 4/64 loss: 0.36100614070892334
Batch 5/64 loss: 0.36243027448654175
Batch 6/64 loss: 0.3620409369468689
Batch 7/64 loss: 0.3618272542953491
Batch 8/64 loss: 0.36120176315307617
Batch 9/64 loss: 0.3609672784805298
Batch 10/64 loss: 0.365023136138916
Batch 11/64 loss: 0.3602546453475952
Batch 12/64 loss: 0.358970046043396
Batch 13/64 loss: 0.36117851734161377
Batch 14/64 loss: 0.36220067739486694
Batch 15/64 loss: 0.3628178834915161
Batch 16/64 loss: 0.3607370853424072
Batch 17/64 loss: 0.3631479740142822
Batch 18/64 loss: 0.36097395420074463
Batch 19/64 loss: 0.3616523742675781
Batch 20/64 loss: 0.36180996894836426
Batch 21/64 loss: 0.3609163761138916
Batch 22/64 loss: 0.360882043838501
Batch 23/64 loss: 0.36419278383255005
Batch 24/64 loss: 0.3618764877319336
Batch 25/64 loss: 0.3633975386619568
Batch 26/64 loss: 0.3598698377609253
Batch 27/64 loss: 0.3619546890258789
Batch 28/64 loss: 0.36192774772644043
Batch 29/64 loss: 0.3599469065666199
Batch 30/64 loss: 0.36454153060913086
Batch 31/64 loss: 0.36217474937438965
Batch 32/64 loss: 0.36347776651382446
Batch 33/64 loss: 0.3636523485183716
Batch 34/64 loss: 0.36180126667022705
Batch 35/64 loss: 0.3622199296951294
Batch 36/64 loss: 0.36393433809280396
Batch 37/64 loss: 0.3616971969604492
Batch 38/64 loss: 0.361367404460907
Batch 39/64 loss: 0.3608137369155884
Batch 40/64 loss: 0.3644222021102905
Batch 41/64 loss: 0.3636653423309326
Batch 42/64 loss: 0.363287091255188
Batch 43/64 loss: 0.36084264516830444
Batch 44/64 loss: 0.3628231883049011
Batch 45/64 loss: 0.35906267166137695
Batch 46/64 loss: 0.36068475246429443
Batch 47/64 loss: 0.3642827272415161
Batch 48/64 loss: 0.3628522753715515
Batch 49/64 loss: 0.360038697719574
Batch 50/64 loss: 0.3648698329925537
Batch 51/64 loss: 0.3620448112487793
Batch 52/64 loss: 0.3657108545303345
Batch 53/64 loss: 0.363437294960022
Batch 54/64 loss: 0.36023998260498047
Batch 55/64 loss: 0.36058932542800903
Batch 56/64 loss: 0.36147892475128174
Batch 57/64 loss: 0.360027551651001
Batch 58/64 loss: 0.3617299795150757
Batch 59/64 loss: 0.3609660863876343
Batch 60/64 loss: 0.3660007119178772
Batch 61/64 loss: 0.35981398820877075
Batch 62/64 loss: 0.3611893653869629
Batch 63/64 loss: 0.3596229553222656
Batch 64/64 loss: 0.3642261028289795
Epoch 35  Train loss: 0.36204728145225373  Val loss: 0.36324943320448044
Epoch 36
-------------------------------
Batch 1/64 loss: 0.3642962574958801
Batch 2/64 loss: 0.36462539434432983
Batch 3/64 loss: 0.36149096488952637
Batch 4/64 loss: 0.3642582893371582
Batch 5/64 loss: 0.36192286014556885
Batch 6/64 loss: 0.3590061664581299
Batch 7/64 loss: 0.36245858669281006
Batch 8/64 loss: 0.3620692491531372
Batch 9/64 loss: 0.3646540641784668
Batch 10/64 loss: 0.35699909925460815
Batch 11/64 loss: 0.361497163772583
Batch 12/64 loss: 0.3605054020881653
Batch 13/64 loss: 0.3636120557785034
Batch 14/64 loss: 0.3605457544326782
Batch 15/64 loss: 0.36270958185195923
Batch 16/64 loss: 0.3598991632461548
Batch 17/64 loss: 0.36236751079559326
Batch 18/64 loss: 0.36344337463378906
Batch 19/64 loss: 0.3627204895019531
Batch 20/64 loss: 0.3635825514793396
Batch 21/64 loss: 0.3608829975128174
Batch 22/64 loss: 0.3614436388015747
Batch 23/64 loss: 0.36149364709854126
Batch 24/64 loss: 0.36504173278808594
Batch 25/64 loss: 0.3582015633583069
Batch 26/64 loss: 0.3631531000137329
Batch 27/64 loss: 0.36315327882766724
Batch 28/64 loss: 0.3630492687225342
Batch 29/64 loss: 0.36336445808410645
Batch 30/64 loss: 0.3630078434944153
Batch 31/64 loss: 0.3616263270378113
Batch 32/64 loss: 0.3620801568031311
Batch 33/64 loss: 0.3610348105430603
Batch 34/64 loss: 0.3640049695968628
Batch 35/64 loss: 0.3647959232330322
Batch 36/64 loss: 0.36208975315093994
Batch 37/64 loss: 0.3633965849876404
Batch 38/64 loss: 0.36184072494506836
Batch 39/64 loss: 0.3593270778656006
Batch 40/64 loss: 0.36313092708587646
Batch 41/64 loss: 0.3639029264450073
Batch 42/64 loss: 0.3648108243942261
Batch 43/64 loss: 0.357867956161499
Batch 44/64 loss: 0.3630725145339966
Batch 45/64 loss: 0.362651526927948
Batch 46/64 loss: 0.3606237769126892
Batch 47/64 loss: 0.36008262634277344
Batch 48/64 loss: 0.3606959581375122
Batch 49/64 loss: 0.3650679588317871
Batch 50/64 loss: 0.3580578565597534
Batch 51/64 loss: 0.36233818531036377
Batch 52/64 loss: 0.35996830463409424
Batch 53/64 loss: 0.36284714937210083
Batch 54/64 loss: 0.36396360397338867
Batch 55/64 loss: 0.3634408116340637
Batch 56/64 loss: 0.3632620573043823
Batch 57/64 loss: 0.3626147508621216
Batch 58/64 loss: 0.3581916093826294
Batch 59/64 loss: 0.36375510692596436
Batch 60/64 loss: 0.36428964138031006
Batch 61/64 loss: 0.3641135096549988
Batch 62/64 loss: 0.3625447750091553
Batch 63/64 loss: 0.36280083656311035
Batch 64/64 loss: 0.3646026849746704
Epoch 36  Train loss: 0.36224625952103556  Val loss: 0.3626158712655818
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 0.3597937226295471
Batch 2/64 loss: 0.35893845558166504
Batch 3/64 loss: 0.3642115592956543
Batch 4/64 loss: 0.36016225814819336
Batch 5/64 loss: 0.36188995838165283
Batch 6/64 loss: 0.3619883060455322
Batch 7/64 loss: 0.3602719306945801
Batch 8/64 loss: 0.3587988615036011
Batch 9/64 loss: 0.36290061473846436
Batch 10/64 loss: 0.3623925447463989
Batch 11/64 loss: 0.36291491985321045
Batch 12/64 loss: 0.3620264530181885
Batch 13/64 loss: 0.362129271030426
Batch 14/64 loss: 0.356605589389801
Batch 15/64 loss: 0.36263418197631836
Batch 16/64 loss: 0.3611922264099121
Batch 17/64 loss: 0.36203324794769287
Batch 18/64 loss: 0.3626558184623718
Batch 19/64 loss: 0.3620191812515259
Batch 20/64 loss: 0.3621557354927063
Batch 21/64 loss: 0.3606607913970947
Batch 22/64 loss: 0.36291205883026123
Batch 23/64 loss: 0.3658407926559448
Batch 24/64 loss: 0.36084115505218506
Batch 25/64 loss: 0.3575270175933838
Batch 26/64 loss: 0.3619595766067505
Batch 27/64 loss: 0.3604799509048462
Batch 28/64 loss: 0.36358314752578735
Batch 29/64 loss: 0.3611953854560852
Batch 30/64 loss: 0.35972315073013306
Batch 31/64 loss: 0.36227190494537354
Batch 32/64 loss: 0.35958534479141235
Batch 33/64 loss: 0.36203962564468384
Batch 34/64 loss: 0.3628014326095581
Batch 35/64 loss: 0.3596017360687256
Batch 36/64 loss: 0.35934150218963623
Batch 37/64 loss: 0.36097532510757446
Batch 38/64 loss: 0.3615105152130127
Batch 39/64 loss: 0.3594478368759155
Batch 40/64 loss: 0.3629158139228821
Batch 41/64 loss: 0.35859811305999756
Batch 42/64 loss: 0.3638753890991211
Batch 43/64 loss: 0.3635140657424927
Batch 44/64 loss: 0.365996778011322
Batch 45/64 loss: 0.36105597019195557
Batch 46/64 loss: 0.3617486357688904
Batch 47/64 loss: 0.36169004440307617
Batch 48/64 loss: 0.36015933752059937
Batch 49/64 loss: 0.3654226064682007
Batch 50/64 loss: 0.3599756956100464
Batch 51/64 loss: 0.3633706569671631
Batch 52/64 loss: 0.36574459075927734
Batch 53/64 loss: 0.3600555658340454
Batch 54/64 loss: 0.36127328872680664
Batch 55/64 loss: 0.3638577461242676
Batch 56/64 loss: 0.3607196807861328
Batch 57/64 loss: 0.36206287145614624
Batch 58/64 loss: 0.3651777505874634
Batch 59/64 loss: 0.35978347063064575
Batch 60/64 loss: 0.3610195517539978
Batch 61/64 loss: 0.3601008653640747
Batch 62/64 loss: 0.3648386001586914
Batch 63/64 loss: 0.35858798027038574
Batch 64/64 loss: 0.36264848709106445
Epoch 37  Train loss: 0.36162422778559666  Val loss: 0.36296222361502367
Epoch 38
-------------------------------
Batch 1/64 loss: 0.36343085765838623
Batch 2/64 loss: 0.36126673221588135
Batch 3/64 loss: 0.36124080419540405
Batch 4/64 loss: 0.36192435026168823
Batch 5/64 loss: 0.3607724905014038
Batch 6/64 loss: 0.3550264239311218
Batch 7/64 loss: 0.3620449900627136
Batch 8/64 loss: 0.3607630729675293
Batch 9/64 loss: 0.3625677227973938
Batch 10/64 loss: 0.3621740937232971
Batch 11/64 loss: 0.36237984895706177
Batch 12/64 loss: 0.3618968725204468
Batch 13/64 loss: 0.3596285581588745
Batch 14/64 loss: 0.35999035835266113
Batch 15/64 loss: 0.36153721809387207
Batch 16/64 loss: 0.3635638356208801
Batch 17/64 loss: 0.36120080947875977
Batch 18/64 loss: 0.3617689609527588
Batch 19/64 loss: 0.3618386387825012
Batch 20/64 loss: 0.35982251167297363
Batch 21/64 loss: 0.3608931303024292
Batch 22/64 loss: 0.36185765266418457
Batch 23/64 loss: 0.35933661460876465
Batch 24/64 loss: 0.3613247871398926
Batch 25/64 loss: 0.36008352041244507
Batch 26/64 loss: 0.3609708547592163
Batch 27/64 loss: 0.360694944858551
Batch 28/64 loss: 0.3588600158691406
Batch 29/64 loss: 0.3586210012435913
Batch 30/64 loss: 0.35869646072387695
Batch 31/64 loss: 0.3618892431259155
Batch 32/64 loss: 0.36083734035491943
Batch 33/64 loss: 0.3620380759239197
Batch 34/64 loss: 0.36009180545806885
Batch 35/64 loss: 0.3642233610153198
Batch 36/64 loss: 0.3580353260040283
Batch 37/64 loss: 0.360565185546875
Batch 38/64 loss: 0.36451560258865356
Batch 39/64 loss: 0.3633818030357361
Batch 40/64 loss: 0.362932026386261
Batch 41/64 loss: 0.3606151342391968
Batch 42/64 loss: 0.3611459732055664
Batch 43/64 loss: 0.3668431043624878
Batch 44/64 loss: 0.36268699169158936
Batch 45/64 loss: 0.3645784854888916
Batch 46/64 loss: 0.36187517642974854
Batch 47/64 loss: 0.36195576190948486
Batch 48/64 loss: 0.3615708351135254
Batch 49/64 loss: 0.3621755838394165
Batch 50/64 loss: 0.3637170195579529
Batch 51/64 loss: 0.3604191541671753
Batch 52/64 loss: 0.3611612319946289
Batch 53/64 loss: 0.3647141456604004
Batch 54/64 loss: 0.35909003019332886
Batch 55/64 loss: 0.36263835430145264
Batch 56/64 loss: 0.36143654584884644
Batch 57/64 loss: 0.35942959785461426
Batch 58/64 loss: 0.3624458312988281
Batch 59/64 loss: 0.36299455165863037
Batch 60/64 loss: 0.3635241985321045
Batch 61/64 loss: 0.3632838726043701
Batch 62/64 loss: 0.3611357808113098
Batch 63/64 loss: 0.3596762418746948
Batch 64/64 loss: 0.3606971502304077
Epoch 38  Train loss: 0.36147959793315215  Val loss: 0.36239674800040383
Saving best model, epoch: 38
Epoch 39
-------------------------------
Batch 1/64 loss: 0.3581230640411377
Batch 2/64 loss: 0.3596217632293701
Batch 3/64 loss: 0.3621756434440613
Batch 4/64 loss: 0.36067742109298706
Batch 5/64 loss: 0.36070066690444946
Batch 6/64 loss: 0.3619392514228821
Batch 7/64 loss: 0.3606463670730591
Batch 8/64 loss: 0.36365991830825806
Batch 9/64 loss: 0.3597189784049988
Batch 10/64 loss: 0.3601928949356079
Batch 11/64 loss: 0.3595224618911743
Batch 12/64 loss: 0.36166882514953613
Batch 13/64 loss: 0.3607112169265747
Batch 14/64 loss: 0.36076319217681885
Batch 15/64 loss: 0.36337029933929443
Batch 16/64 loss: 0.3576154112815857
Batch 17/64 loss: 0.3628401756286621
Batch 18/64 loss: 0.35918962955474854
Batch 19/64 loss: 0.3629089593887329
Batch 20/64 loss: 0.36257338523864746
Batch 21/64 loss: 0.3617295026779175
Batch 22/64 loss: 0.3601694703102112
Batch 23/64 loss: 0.3593699336051941
Batch 24/64 loss: 0.36092013120651245
Batch 25/64 loss: 0.3605731725692749
Batch 26/64 loss: 0.3608473539352417
Batch 27/64 loss: 0.36116570234298706
Batch 28/64 loss: 0.3622649908065796
Batch 29/64 loss: 0.3609555959701538
Batch 30/64 loss: 0.35985493659973145
Batch 31/64 loss: 0.36648666858673096
Batch 32/64 loss: 0.362515926361084
Batch 33/64 loss: 0.3594290018081665
Batch 34/64 loss: 0.3604329228401184
Batch 35/64 loss: 0.36251741647720337
Batch 36/64 loss: 0.3618757724761963
Batch 37/64 loss: 0.35803937911987305
Batch 38/64 loss: 0.3624364137649536
Batch 39/64 loss: 0.36368632316589355
Batch 40/64 loss: 0.3605790138244629
Batch 41/64 loss: 0.3583953380584717
Batch 42/64 loss: 0.36190664768218994
Batch 43/64 loss: 0.3595699071884155
Batch 44/64 loss: 0.36028170585632324
Batch 45/64 loss: 0.3603454828262329
Batch 46/64 loss: 0.3597157597541809
Batch 47/64 loss: 0.36298877000808716
Batch 48/64 loss: 0.36340832710266113
Batch 49/64 loss: 0.36232733726501465
Batch 50/64 loss: 0.35941922664642334
Batch 51/64 loss: 0.3613154888153076
Batch 52/64 loss: 0.36170363426208496
Batch 53/64 loss: 0.36250972747802734
Batch 54/64 loss: 0.3615434169769287
Batch 55/64 loss: 0.36368000507354736
Batch 56/64 loss: 0.36182868480682373
Batch 57/64 loss: 0.3609834909439087
Batch 58/64 loss: 0.36650633811950684
Batch 59/64 loss: 0.3645414113998413
Batch 60/64 loss: 0.36065107583999634
Batch 61/64 loss: 0.3622009754180908
Batch 62/64 loss: 0.35943400859832764
Batch 63/64 loss: 0.3614497184753418
Batch 64/64 loss: 0.3616141080856323
Epoch 39  Train loss: 0.3612923327614279  Val loss: 0.3625896075337203
Epoch 40
-------------------------------
Batch 1/64 loss: 0.3595990538597107
Batch 2/64 loss: 0.35994184017181396
Batch 3/64 loss: 0.3589140772819519
Batch 4/64 loss: 0.3586617112159729
Batch 5/64 loss: 0.3622382879257202
Batch 6/64 loss: 0.3588868975639343
Batch 7/64 loss: 0.3608522415161133
Batch 8/64 loss: 0.361422598361969
Batch 9/64 loss: 0.36237573623657227
Batch 10/64 loss: 0.359977126121521
Batch 11/64 loss: 0.3589019775390625
Batch 12/64 loss: 0.3608713746070862
Batch 13/64 loss: 0.35809803009033203
Batch 14/64 loss: 0.3629084825515747
Batch 15/64 loss: 0.36047255992889404
Batch 16/64 loss: 0.3569037914276123
Batch 17/64 loss: 0.36183685064315796
Batch 18/64 loss: 0.36244291067123413
Batch 19/64 loss: 0.3615657091140747
Batch 20/64 loss: 0.3600834608078003
Batch 21/64 loss: 0.3605377674102783
Batch 22/64 loss: 0.3604259490966797
Batch 23/64 loss: 0.36164093017578125
Batch 24/64 loss: 0.35834020376205444
Batch 25/64 loss: 0.3616964817047119
Batch 26/64 loss: 0.36372852325439453
Batch 27/64 loss: 0.36101120710372925
Batch 28/64 loss: 0.3628894090652466
Batch 29/64 loss: 0.36115431785583496
Batch 30/64 loss: 0.3634105920791626
Batch 31/64 loss: 0.3630150556564331
Batch 32/64 loss: 0.36133652925491333
Batch 33/64 loss: 0.3609095811843872
Batch 34/64 loss: 0.36468052864074707
Batch 35/64 loss: 0.363405704498291
Batch 36/64 loss: 0.36091136932373047
Batch 37/64 loss: 0.3661251664161682
Batch 38/64 loss: 0.36454349756240845
Batch 39/64 loss: 0.362453818321228
Batch 40/64 loss: 0.3592420816421509
Batch 41/64 loss: 0.3611742854118347
Batch 42/64 loss: 0.35998058319091797
Batch 43/64 loss: 0.3618946075439453
Batch 44/64 loss: 0.3632187843322754
Batch 45/64 loss: 0.360079824924469
Batch 46/64 loss: 0.3613201379776001
Batch 47/64 loss: 0.35952746868133545
Batch 48/64 loss: 0.36344730854034424
Batch 49/64 loss: 0.36393940448760986
Batch 50/64 loss: 0.3646332025527954
Batch 51/64 loss: 0.3618984818458557
Batch 52/64 loss: 0.36149054765701294
Batch 53/64 loss: 0.35954052209854126
Batch 54/64 loss: 0.35983240604400635
Batch 55/64 loss: 0.36237043142318726
Batch 56/64 loss: 0.35949236154556274
Batch 57/64 loss: 0.36000293493270874
Batch 58/64 loss: 0.36379313468933105
Batch 59/64 loss: 0.3612363934516907
Batch 60/64 loss: 0.35946476459503174
Batch 61/64 loss: 0.35959649085998535
Batch 62/64 loss: 0.3583216667175293
Batch 63/64 loss: 0.3631713390350342
Batch 64/64 loss: 0.3592495918273926
Epoch 40  Train loss: 0.3612121993420171  Val loss: 0.36280069810008675
Epoch 41
-------------------------------
Batch 1/64 loss: 0.357421875
Batch 2/64 loss: 0.3570162057876587
Batch 3/64 loss: 0.3613150119781494
Batch 4/64 loss: 0.36202359199523926
Batch 5/64 loss: 0.36079907417297363
Batch 6/64 loss: 0.3625727891921997
Batch 7/64 loss: 0.3595079183578491
Batch 8/64 loss: 0.3621736168861389
Batch 9/64 loss: 0.3640643358230591
Batch 10/64 loss: 0.36193591356277466
Batch 11/64 loss: 0.36084115505218506
Batch 12/64 loss: 0.36236023902893066
Batch 13/64 loss: 0.3620021343231201
Batch 14/64 loss: 0.3597954511642456
Batch 15/64 loss: 0.3633040189743042
Batch 16/64 loss: 0.3607386350631714
Batch 17/64 loss: 0.3631134629249573
Batch 18/64 loss: 0.36339354515075684
Batch 19/64 loss: 0.36628258228302
Batch 20/64 loss: 0.36162781715393066
Batch 21/64 loss: 0.3629833459854126
Batch 22/64 loss: 0.36117517948150635
Batch 23/64 loss: 0.3587794899940491
Batch 24/64 loss: 0.3645545244216919
Batch 25/64 loss: 0.3628445267677307
Batch 26/64 loss: 0.36237138509750366
Batch 27/64 loss: 0.3564178943634033
Batch 28/64 loss: 0.3625766634941101
Batch 29/64 loss: 0.3619559407234192
Batch 30/64 loss: 0.3613773584365845
Batch 31/64 loss: 0.3595057725906372
Batch 32/64 loss: 0.3625131845474243
Batch 33/64 loss: 0.35942792892456055
Batch 34/64 loss: 0.35827356576919556
Batch 35/64 loss: 0.36195170879364014
Batch 36/64 loss: 0.36478161811828613
Batch 37/64 loss: 0.35738229751586914
Batch 38/64 loss: 0.36078715324401855
Batch 39/64 loss: 0.36112499237060547
Batch 40/64 loss: 0.36192774772644043
Batch 41/64 loss: 0.3629039525985718
Batch 42/64 loss: 0.36069798469543457
Batch 43/64 loss: 0.36175966262817383
Batch 44/64 loss: 0.35949236154556274
Batch 45/64 loss: 0.36160963773727417
Batch 46/64 loss: 0.35779911279678345
Batch 47/64 loss: 0.3594062328338623
Batch 48/64 loss: 0.3592797517776489
Batch 49/64 loss: 0.3592418432235718
Batch 50/64 loss: 0.3630169630050659
Batch 51/64 loss: 0.36232149600982666
Batch 52/64 loss: 0.35977935791015625
Batch 53/64 loss: 0.3586236834526062
Batch 54/64 loss: 0.36244434118270874
Batch 55/64 loss: 0.36093223094940186
Batch 56/64 loss: 0.35876965522766113
Batch 57/64 loss: 0.3582425117492676
Batch 58/64 loss: 0.3615734577178955
Batch 59/64 loss: 0.3643847703933716
Batch 60/64 loss: 0.3619431257247925
Batch 61/64 loss: 0.36105358600616455
Batch 62/64 loss: 0.3625248074531555
Batch 63/64 loss: 0.36136317253112793
Batch 64/64 loss: 0.36160123348236084
Epoch 41  Train loss: 0.36118221610200174  Val loss: 0.3626694109841311
Epoch 42
-------------------------------
Batch 1/64 loss: 0.36410874128341675
Batch 2/64 loss: 0.36361974477767944
Batch 3/64 loss: 0.3599392771720886
Batch 4/64 loss: 0.35692834854125977
Batch 5/64 loss: 0.3599018454551697
Batch 6/64 loss: 0.35942137241363525
Batch 7/64 loss: 0.35815131664276123
Batch 8/64 loss: 0.3581637144088745
Batch 9/64 loss: 0.3608516454696655
Batch 10/64 loss: 0.3610057830810547
Batch 11/64 loss: 0.3624368906021118
Batch 12/64 loss: 0.3617590069770813
Batch 13/64 loss: 0.36334770917892456
Batch 14/64 loss: 0.36223864555358887
Batch 15/64 loss: 0.35854923725128174
Batch 16/64 loss: 0.3566403388977051
Batch 17/64 loss: 0.3604174852371216
Batch 18/64 loss: 0.3626580834388733
Batch 19/64 loss: 0.3608552813529968
Batch 20/64 loss: 0.3624647855758667
Batch 21/64 loss: 0.3617120385169983
Batch 22/64 loss: 0.35908979177474976
Batch 23/64 loss: 0.3603519797325134
Batch 24/64 loss: 0.35847753286361694
Batch 25/64 loss: 0.36415863037109375
Batch 26/64 loss: 0.3617948293685913
Batch 27/64 loss: 0.36103469133377075
Batch 28/64 loss: 0.3619057536125183
Batch 29/64 loss: 0.36062324047088623
Batch 30/64 loss: 0.3632271885871887
Batch 31/64 loss: 0.3605678081512451
Batch 32/64 loss: 0.3610037565231323
Batch 33/64 loss: 0.36095595359802246
Batch 34/64 loss: 0.3635372519493103
Batch 35/64 loss: 0.3582250475883484
Batch 36/64 loss: 0.3656197190284729
Batch 37/64 loss: 0.36317217350006104
Batch 38/64 loss: 0.36080294847488403
Batch 39/64 loss: 0.35915470123291016
Batch 40/64 loss: 0.3590385913848877
Batch 41/64 loss: 0.3642071485519409
Batch 42/64 loss: 0.3621060848236084
Batch 43/64 loss: 0.3601885437965393
Batch 44/64 loss: 0.3624730706214905
Batch 45/64 loss: 0.3650188446044922
Batch 46/64 loss: 0.357516884803772
Batch 47/64 loss: 0.3600296974182129
Batch 48/64 loss: 0.3593485951423645
Batch 49/64 loss: 0.36211085319519043
Batch 50/64 loss: 0.3613817095756531
Batch 51/64 loss: 0.36115872859954834
Batch 52/64 loss: 0.36114054918289185
Batch 53/64 loss: 0.3592914342880249
Batch 54/64 loss: 0.3596634864807129
Batch 55/64 loss: 0.3631119728088379
Batch 56/64 loss: 0.3588804602622986
Batch 57/64 loss: 0.3641873598098755
Batch 58/64 loss: 0.3607449531555176
Batch 59/64 loss: 0.3660135269165039
Batch 60/64 loss: 0.35768258571624756
Batch 61/64 loss: 0.36112910509109497
Batch 62/64 loss: 0.36263322830200195
Batch 63/64 loss: 0.36004191637039185
Batch 64/64 loss: 0.36222392320632935
Epoch 42  Train loss: 0.3610924166791579  Val loss: 0.36224176711642864
Saving best model, epoch: 42
Epoch 43
-------------------------------
Batch 1/64 loss: 0.35865557193756104
Batch 2/64 loss: 0.360431969165802
Batch 3/64 loss: 0.3635830879211426
Batch 4/64 loss: 0.35917603969573975
Batch 5/64 loss: 0.36036384105682373
Batch 6/64 loss: 0.35978269577026367
Batch 7/64 loss: 0.3602304458618164
Batch 8/64 loss: 0.3614497184753418
Batch 9/64 loss: 0.36240941286087036
Batch 10/64 loss: 0.3607451319694519
Batch 11/64 loss: 0.3578305244445801
Batch 12/64 loss: 0.3614045977592468
Batch 13/64 loss: 0.3579018712043762
Batch 14/64 loss: 0.3610481023788452
Batch 15/64 loss: 0.36166858673095703
Batch 16/64 loss: 0.35641300678253174
Batch 17/64 loss: 0.36147671937942505
Batch 18/64 loss: 0.36154383420944214
Batch 19/64 loss: 0.3592236042022705
Batch 20/64 loss: 0.3595619797706604
Batch 21/64 loss: 0.36085808277130127
Batch 22/64 loss: 0.36317622661590576
Batch 23/64 loss: 0.36230963468551636
Batch 24/64 loss: 0.3643629550933838
Batch 25/64 loss: 0.35897547006607056
Batch 26/64 loss: 0.36045265197753906
Batch 27/64 loss: 0.35945749282836914
Batch 28/64 loss: 0.3631148934364319
Batch 29/64 loss: 0.36384332180023193
Batch 30/64 loss: 0.3634563088417053
Batch 31/64 loss: 0.36222314834594727
Batch 32/64 loss: 0.3589783310890198
Batch 33/64 loss: 0.3619149923324585
Batch 34/64 loss: 0.3596994876861572
Batch 35/64 loss: 0.35931241512298584
Batch 36/64 loss: 0.3654024600982666
Batch 37/64 loss: 0.3622041344642639
Batch 38/64 loss: 0.36258596181869507
Batch 39/64 loss: 0.36104071140289307
Batch 40/64 loss: 0.36295175552368164
Batch 41/64 loss: 0.3599419593811035
Batch 42/64 loss: 0.3631439208984375
Batch 43/64 loss: 0.3639146089553833
Batch 44/64 loss: 0.3634704351425171
Batch 45/64 loss: 0.36019647121429443
Batch 46/64 loss: 0.361484169960022
Batch 47/64 loss: 0.3604797124862671
Batch 48/64 loss: 0.36038076877593994
Batch 49/64 loss: 0.3603052496910095
Batch 50/64 loss: 0.3601795434951782
Batch 51/64 loss: 0.360507607460022
Batch 52/64 loss: 0.3592793941497803
Batch 53/64 loss: 0.36145323514938354
Batch 54/64 loss: 0.3592997193336487
Batch 55/64 loss: 0.3622063398361206
Batch 56/64 loss: 0.35919052362442017
Batch 57/64 loss: 0.36122143268585205
Batch 58/64 loss: 0.3555816411972046
Batch 59/64 loss: 0.36115825176239014
Batch 60/64 loss: 0.36108195781707764
Batch 61/64 loss: 0.36540329456329346
Batch 62/64 loss: 0.36230671405792236
Batch 63/64 loss: 0.35854530334472656
Batch 64/64 loss: 0.35861384868621826
Epoch 43  Train loss: 0.3609555108874452  Val loss: 0.3625577430135196
Epoch 44
-------------------------------
Batch 1/64 loss: 0.3623892664909363
Batch 2/64 loss: 0.35850369930267334
Batch 3/64 loss: 0.3594222068786621
Batch 4/64 loss: 0.3613095283508301
Batch 5/64 loss: 0.3610715866088867
Batch 6/64 loss: 0.35589897632598877
Batch 7/64 loss: 0.35887062549591064
Batch 8/64 loss: 0.3590357303619385
Batch 9/64 loss: 0.3631240725517273
Batch 10/64 loss: 0.36060261726379395
Batch 11/64 loss: 0.36057889461517334
Batch 12/64 loss: 0.3621053099632263
Batch 13/64 loss: 0.36263740062713623
Batch 14/64 loss: 0.3573380708694458
Batch 15/64 loss: 0.3600919246673584
Batch 16/64 loss: 0.35558825731277466
Batch 17/64 loss: 0.3592596650123596
Batch 18/64 loss: 0.35530853271484375
Batch 19/64 loss: 0.36323022842407227
Batch 20/64 loss: 0.36116939783096313
Batch 21/64 loss: 0.36063772439956665
Batch 22/64 loss: 0.3609609603881836
Batch 23/64 loss: 0.36471080780029297
Batch 24/64 loss: 0.356758713722229
Batch 25/64 loss: 0.36206841468811035
Batch 26/64 loss: 0.3617039918899536
Batch 27/64 loss: 0.3603512644767761
Batch 28/64 loss: 0.36338114738464355
Batch 29/64 loss: 0.3574736714363098
Batch 30/64 loss: 0.3615936040878296
Batch 31/64 loss: 0.36355847120285034
Batch 32/64 loss: 0.364219605922699
Batch 33/64 loss: 0.36067771911621094
Batch 34/64 loss: 0.36145275831222534
Batch 35/64 loss: 0.36340320110321045
Batch 36/64 loss: 0.3576333522796631
Batch 37/64 loss: 0.36324000358581543
Batch 38/64 loss: 0.36206960678100586
Batch 39/64 loss: 0.35991859436035156
Batch 40/64 loss: 0.3632161617279053
Batch 41/64 loss: 0.3582049012184143
Batch 42/64 loss: 0.3584887981414795
Batch 43/64 loss: 0.3609977960586548
Batch 44/64 loss: 0.3630748391151428
Batch 45/64 loss: 0.36307990550994873
Batch 46/64 loss: 0.3567948341369629
Batch 47/64 loss: 0.36299872398376465
Batch 48/64 loss: 0.35744452476501465
Batch 49/64 loss: 0.3608114719390869
Batch 50/64 loss: 0.36199772357940674
Batch 51/64 loss: 0.3618488311767578
Batch 52/64 loss: 0.35974645614624023
Batch 53/64 loss: 0.36356258392333984
Batch 54/64 loss: 0.3607911467552185
Batch 55/64 loss: 0.3623396158218384
Batch 56/64 loss: 0.3622041940689087
Batch 57/64 loss: 0.360603392124176
Batch 58/64 loss: 0.35886549949645996
Batch 59/64 loss: 0.3604056239128113
Batch 60/64 loss: 0.3580317497253418
Batch 61/64 loss: 0.3656180500984192
Batch 62/64 loss: 0.361136257648468
Batch 63/64 loss: 0.36073821783065796
Batch 64/64 loss: 0.3597560524940491
Epoch 44  Train loss: 0.3607242030255935  Val loss: 0.3618724645208247
Saving best model, epoch: 44
Epoch 45
-------------------------------
Batch 1/64 loss: 0.3610163927078247
Batch 2/64 loss: 0.3564903736114502
Batch 3/64 loss: 0.3606871962547302
Batch 4/64 loss: 0.3605964183807373
Batch 5/64 loss: 0.3601706624031067
Batch 6/64 loss: 0.3611980676651001
Batch 7/64 loss: 0.3602999448776245
Batch 8/64 loss: 0.3612571954727173
Batch 9/64 loss: 0.3567469120025635
Batch 10/64 loss: 0.3598155975341797
Batch 11/64 loss: 0.36306631565093994
Batch 12/64 loss: 0.36218124628067017
Batch 13/64 loss: 0.36157065629959106
Batch 14/64 loss: 0.36434197425842285
Batch 15/64 loss: 0.36006277799606323
Batch 16/64 loss: 0.35843122005462646
Batch 17/64 loss: 0.361987829208374
Batch 18/64 loss: 0.36039137840270996
Batch 19/64 loss: 0.3602182865142822
Batch 20/64 loss: 0.3614799380302429
Batch 21/64 loss: 0.3634170889854431
Batch 22/64 loss: 0.35686105489730835
Batch 23/64 loss: 0.3610646724700928
Batch 24/64 loss: 0.3574005365371704
Batch 25/64 loss: 0.361117959022522
Batch 26/64 loss: 0.35973894596099854
Batch 27/64 loss: 0.3618254065513611
Batch 28/64 loss: 0.36084216833114624
Batch 29/64 loss: 0.36502552032470703
Batch 30/64 loss: 0.36329030990600586
Batch 31/64 loss: 0.3581390976905823
Batch 32/64 loss: 0.3601168394088745
Batch 33/64 loss: 0.3598787784576416
Batch 34/64 loss: 0.362440824508667
Batch 35/64 loss: 0.3599083423614502
Batch 36/64 loss: 0.3599058985710144
Batch 37/64 loss: 0.36224067211151123
Batch 38/64 loss: 0.35944437980651855
Batch 39/64 loss: 0.3624528646469116
Batch 40/64 loss: 0.3581275939941406
Batch 41/64 loss: 0.3621606230735779
Batch 42/64 loss: 0.35819292068481445
Batch 43/64 loss: 0.3620784282684326
Batch 44/64 loss: 0.36124396324157715
Batch 45/64 loss: 0.3626582622528076
Batch 46/64 loss: 0.3597128391265869
Batch 47/64 loss: 0.36174440383911133
Batch 48/64 loss: 0.3583720326423645
Batch 49/64 loss: 0.3585621118545532
Batch 50/64 loss: 0.35596293210983276
Batch 51/64 loss: 0.36017078161239624
Batch 52/64 loss: 0.36223936080932617
Batch 53/64 loss: 0.3629281520843506
Batch 54/64 loss: 0.3595782518386841
Batch 55/64 loss: 0.35978126525878906
Batch 56/64 loss: 0.3639148473739624
Batch 57/64 loss: 0.3627029061317444
Batch 58/64 loss: 0.36435455083847046
Batch 59/64 loss: 0.36128664016723633
Batch 60/64 loss: 0.3630845546722412
Batch 61/64 loss: 0.3600379228591919
Batch 62/64 loss: 0.3588576316833496
Batch 63/64 loss: 0.36079901456832886
Batch 64/64 loss: 0.3626585006713867
Epoch 45  Train loss: 0.36074772722580856  Val loss: 0.36203408323202757
Epoch 46
-------------------------------
Batch 1/64 loss: 0.36447495222091675
Batch 2/64 loss: 0.36022841930389404
Batch 3/64 loss: 0.3625127077102661
Batch 4/64 loss: 0.3593379259109497
Batch 5/64 loss: 0.3659626841545105
Batch 6/64 loss: 0.36296719312667847
Batch 7/64 loss: 0.3587862253189087
Batch 8/64 loss: 0.36300432682037354
Batch 9/64 loss: 0.36162424087524414
Batch 10/64 loss: 0.3580831289291382
Batch 11/64 loss: 0.36199092864990234
Batch 12/64 loss: 0.3552359938621521
Batch 13/64 loss: 0.3613245487213135
Batch 14/64 loss: 0.36274033784866333
Batch 15/64 loss: 0.36315035820007324
Batch 16/64 loss: 0.36054325103759766
Batch 17/64 loss: 0.3602292537689209
Batch 18/64 loss: 0.3594951629638672
Batch 19/64 loss: 0.3585911989212036
Batch 20/64 loss: 0.3575977683067322
Batch 21/64 loss: 0.3581887483596802
Batch 22/64 loss: 0.360784649848938
Batch 23/64 loss: 0.3605386018753052
Batch 24/64 loss: 0.3604983687400818
Batch 25/64 loss: 0.3593871593475342
Batch 26/64 loss: 0.3617560863494873
Batch 27/64 loss: 0.3627051115036011
Batch 28/64 loss: 0.36141014099121094
Batch 29/64 loss: 0.36219847202301025
Batch 30/64 loss: 0.36091071367263794
Batch 31/64 loss: 0.36292290687561035
Batch 32/64 loss: 0.3604172468185425
Batch 33/64 loss: 0.3615860939025879
Batch 34/64 loss: 0.3622450828552246
Batch 35/64 loss: 0.3624076843261719
Batch 36/64 loss: 0.3591032028198242
Batch 37/64 loss: 0.36063694953918457
Batch 38/64 loss: 0.36071163415908813
Batch 39/64 loss: 0.3597322702407837
Batch 40/64 loss: 0.3657644987106323
Batch 41/64 loss: 0.3592334985733032
Batch 42/64 loss: 0.3632383346557617
Batch 43/64 loss: 0.36183685064315796
Batch 44/64 loss: 0.3615950345993042
Batch 45/64 loss: 0.3621656894683838
Batch 46/64 loss: 0.3633766174316406
Batch 47/64 loss: 0.3617342710494995
Batch 48/64 loss: 0.36281025409698486
Batch 49/64 loss: 0.3634726405143738
Batch 50/64 loss: 0.36206912994384766
Batch 51/64 loss: 0.3611360788345337
Batch 52/64 loss: 0.35663771629333496
Batch 53/64 loss: 0.3594820499420166
Batch 54/64 loss: 0.36086785793304443
Batch 55/64 loss: 0.3592437505722046
Batch 56/64 loss: 0.3608238697052002
Batch 57/64 loss: 0.35683000087738037
Batch 58/64 loss: 0.36031806468963623
Batch 59/64 loss: 0.35869020223617554
Batch 60/64 loss: 0.359350323677063
Batch 61/64 loss: 0.3621463179588318
Batch 62/64 loss: 0.3578594923019409
Batch 63/64 loss: 0.36161643266677856
Batch 64/64 loss: 0.35574638843536377
Epoch 46  Train loss: 0.3608647921506096  Val loss: 0.36233002111264523
Epoch 47
-------------------------------
Batch 1/64 loss: 0.3604493737220764
Batch 2/64 loss: 0.3604559302330017
Batch 3/64 loss: 0.3603283166885376
Batch 4/64 loss: 0.36245667934417725
Batch 5/64 loss: 0.3632405996322632
Batch 6/64 loss: 0.365189790725708
Batch 7/64 loss: 0.36305296421051025
Batch 8/64 loss: 0.36137139797210693
Batch 9/64 loss: 0.3586157560348511
Batch 10/64 loss: 0.3578094244003296
Batch 11/64 loss: 0.36167681217193604
Batch 12/64 loss: 0.36318278312683105
Batch 13/64 loss: 0.3589925765991211
Batch 14/64 loss: 0.3637183904647827
Batch 15/64 loss: 0.36164987087249756
Batch 16/64 loss: 0.36038780212402344
Batch 17/64 loss: 0.35840094089508057
Batch 18/64 loss: 0.3598496913909912
Batch 19/64 loss: 0.36035943031311035
Batch 20/64 loss: 0.36189472675323486
Batch 21/64 loss: 0.36176079511642456
Batch 22/64 loss: 0.36047589778900146
Batch 23/64 loss: 0.3596440553665161
Batch 24/64 loss: 0.3599615693092346
Batch 25/64 loss: 0.36069416999816895
Batch 26/64 loss: 0.3608633279800415
Batch 27/64 loss: 0.3610437512397766
Batch 28/64 loss: 0.35648977756500244
Batch 29/64 loss: 0.3622473478317261
Batch 30/64 loss: 0.36101460456848145
Batch 31/64 loss: 0.36331993341445923
Batch 32/64 loss: 0.36246246099472046
Batch 33/64 loss: 0.35941582918167114
Batch 34/64 loss: 0.35736000537872314
Batch 35/64 loss: 0.35932832956314087
Batch 36/64 loss: 0.3589751124382019
Batch 37/64 loss: 0.3620983958244324
Batch 38/64 loss: 0.3596411347389221
Batch 39/64 loss: 0.3589189052581787
Batch 40/64 loss: 0.36102306842803955
Batch 41/64 loss: 0.3569282293319702
Batch 42/64 loss: 0.3609555959701538
Batch 43/64 loss: 0.3617984652519226
Batch 44/64 loss: 0.3616948127746582
Batch 45/64 loss: 0.3568481206893921
Batch 46/64 loss: 0.35690760612487793
Batch 47/64 loss: 0.3596162796020508
Batch 48/64 loss: 0.3586444854736328
Batch 49/64 loss: 0.357632577419281
Batch 50/64 loss: 0.3560448884963989
Batch 51/64 loss: 0.3606245517730713
Batch 52/64 loss: 0.36012232303619385
Batch 53/64 loss: 0.36150407791137695
Batch 54/64 loss: 0.36088788509368896
Batch 55/64 loss: 0.3600165843963623
Batch 56/64 loss: 0.3632150888442993
Batch 57/64 loss: 0.36400771141052246
Batch 58/64 loss: 0.35981976985931396
Batch 59/64 loss: 0.35962581634521484
Batch 60/64 loss: 0.36104917526245117
Batch 61/64 loss: 0.35971856117248535
Batch 62/64 loss: 0.36257636547088623
Batch 63/64 loss: 0.3633957505226135
Batch 64/64 loss: 0.35602331161499023
Epoch 47  Train loss: 0.3604780225192799  Val loss: 0.36171899689841513
Saving best model, epoch: 47
Epoch 48
-------------------------------
Batch 1/64 loss: 0.3605988621711731
Batch 2/64 loss: 0.3605257272720337
Batch 3/64 loss: 0.3608425259590149
Batch 4/64 loss: 0.35983842611312866
Batch 5/64 loss: 0.357890248298645
Batch 6/64 loss: 0.3605612516403198
Batch 7/64 loss: 0.3594846725463867
Batch 8/64 loss: 0.36026549339294434
Batch 9/64 loss: 0.36125195026397705
Batch 10/64 loss: 0.3590296506881714
Batch 11/64 loss: 0.3621179461479187
Batch 12/64 loss: 0.3583502769470215
Batch 13/64 loss: 0.36176401376724243
Batch 14/64 loss: 0.3583022356033325
Batch 15/64 loss: 0.35728955268859863
Batch 16/64 loss: 0.36040258407592773
Batch 17/64 loss: 0.3587697744369507
Batch 18/64 loss: 0.3634084463119507
Batch 19/64 loss: 0.35918986797332764
Batch 20/64 loss: 0.35923951864242554
Batch 21/64 loss: 0.3621014356613159
Batch 22/64 loss: 0.36395108699798584
Batch 23/64 loss: 0.36092811822891235
Batch 24/64 loss: 0.3596169948577881
Batch 25/64 loss: 0.364315390586853
Batch 26/64 loss: 0.3596652150154114
Batch 27/64 loss: 0.356880784034729
Batch 28/64 loss: 0.36198168992996216
Batch 29/64 loss: 0.3577260375022888
Batch 30/64 loss: 0.36162257194519043
Batch 31/64 loss: 0.35884201526641846
Batch 32/64 loss: 0.36290550231933594
Batch 33/64 loss: 0.3631276488304138
Batch 34/64 loss: 0.362518310546875
Batch 35/64 loss: 0.3614024519920349
Batch 36/64 loss: 0.3617714047431946
Batch 37/64 loss: 0.36094093322753906
Batch 38/64 loss: 0.36123764514923096
Batch 39/64 loss: 0.3630805015563965
Batch 40/64 loss: 0.3595331907272339
Batch 41/64 loss: 0.3642091751098633
Batch 42/64 loss: 0.35805845260620117
Batch 43/64 loss: 0.36049044132232666
Batch 44/64 loss: 0.3579803705215454
Batch 45/64 loss: 0.3565002679824829
Batch 46/64 loss: 0.36089515686035156
Batch 47/64 loss: 0.360756516456604
Batch 48/64 loss: 0.36078184843063354
Batch 49/64 loss: 0.3605797290802002
Batch 50/64 loss: 0.35642993450164795
Batch 51/64 loss: 0.36156755685806274
Batch 52/64 loss: 0.3613828420639038
Batch 53/64 loss: 0.35779696702957153
Batch 54/64 loss: 0.36228662729263306
Batch 55/64 loss: 0.3594065308570862
Batch 56/64 loss: 0.3573834300041199
Batch 57/64 loss: 0.3591192960739136
Batch 58/64 loss: 0.35853636264801025
Batch 59/64 loss: 0.3620924949645996
Batch 60/64 loss: 0.35905444622039795
Batch 61/64 loss: 0.36137789487838745
Batch 62/64 loss: 0.3608226180076599
Batch 63/64 loss: 0.3632473945617676
Batch 64/64 loss: 0.36211729049682617
Epoch 48  Train loss: 0.3604018239413991  Val loss: 0.36194252066595856
Epoch 49
-------------------------------
Batch 1/64 loss: 0.3597695827484131
Batch 2/64 loss: 0.3555923104286194
Batch 3/64 loss: 0.36318498849868774
Batch 4/64 loss: 0.36076170206069946
Batch 5/64 loss: 0.35811150074005127
Batch 6/64 loss: 0.36300915479660034
Batch 7/64 loss: 0.3563861846923828
Batch 8/64 loss: 0.35860490798950195
Batch 9/64 loss: 0.3594942092895508
Batch 10/64 loss: 0.3599812388420105
Batch 11/64 loss: 0.3608546257019043
Batch 12/64 loss: 0.3600388765335083
Batch 13/64 loss: 0.3587545156478882
Batch 14/64 loss: 0.3576422929763794
Batch 15/64 loss: 0.36005526781082153
Batch 16/64 loss: 0.35389918088912964
Batch 17/64 loss: 0.35960906744003296
Batch 18/64 loss: 0.35882556438446045
Batch 19/64 loss: 0.3606603145599365
Batch 20/64 loss: 0.3592623472213745
Batch 21/64 loss: 0.3574833869934082
Batch 22/64 loss: 0.35839951038360596
Batch 23/64 loss: 0.3613814115524292
Batch 24/64 loss: 0.3601686954498291
Batch 25/64 loss: 0.3567148447036743
Batch 26/64 loss: 0.3581516146659851
Batch 27/64 loss: 0.3611157536506653
Batch 28/64 loss: 0.35515421628952026
Batch 29/64 loss: 0.3599545359611511
Batch 30/64 loss: 0.36034131050109863
Batch 31/64 loss: 0.3621918559074402
Batch 32/64 loss: 0.36162805557250977
Batch 33/64 loss: 0.36016392707824707
Batch 34/64 loss: 0.36252349615097046
Batch 35/64 loss: 0.35843217372894287
Batch 36/64 loss: 0.36038583517074585
Batch 37/64 loss: 0.3599439859390259
Batch 38/64 loss: 0.3629192113876343
Batch 39/64 loss: 0.3626518249511719
Batch 40/64 loss: 0.3629380464553833
Batch 41/64 loss: 0.361568808555603
Batch 42/64 loss: 0.3630989193916321
Batch 43/64 loss: 0.3656989336013794
Batch 44/64 loss: 0.36003923416137695
Batch 45/64 loss: 0.3613240718841553
Batch 46/64 loss: 0.3570680618286133
Batch 47/64 loss: 0.35948699712753296
Batch 48/64 loss: 0.35977327823638916
Batch 49/64 loss: 0.3629676103591919
Batch 50/64 loss: 0.3643803596496582
Batch 51/64 loss: 0.3637503981590271
Batch 52/64 loss: 0.36138254404067993
Batch 53/64 loss: 0.3575456142425537
Batch 54/64 loss: 0.3657824397087097
Batch 55/64 loss: 0.36226534843444824
Batch 56/64 loss: 0.35944998264312744
Batch 57/64 loss: 0.36108213663101196
Batch 58/64 loss: 0.36276763677597046
Batch 59/64 loss: 0.36204981803894043
Batch 60/64 loss: 0.35825496912002563
Batch 61/64 loss: 0.36249256134033203
Batch 62/64 loss: 0.35963600873947144
Batch 63/64 loss: 0.35620731115341187
Batch 64/64 loss: 0.3608388900756836
Epoch 49  Train loss: 0.36024852920981015  Val loss: 0.36226628490330015
Epoch 50
-------------------------------
Batch 1/64 loss: 0.36026227474212646
Batch 2/64 loss: 0.36206209659576416
Batch 3/64 loss: 0.36156702041625977
Batch 4/64 loss: 0.36092710494995117
Batch 5/64 loss: 0.3573979139328003
Batch 6/64 loss: 0.3597409725189209
Batch 7/64 loss: 0.36182641983032227
Batch 8/64 loss: 0.35840749740600586
Batch 9/64 loss: 0.356622576713562
Batch 10/64 loss: 0.36160552501678467
Batch 11/64 loss: 0.3580816984176636
Batch 12/64 loss: 0.3607829809188843
Batch 13/64 loss: 0.3593352437019348
Batch 14/64 loss: 0.3582378029823303
Batch 15/64 loss: 0.3607593774795532
Batch 16/64 loss: 0.36497974395751953
Batch 17/64 loss: 0.3609541058540344
Batch 18/64 loss: 0.35909461975097656
Batch 19/64 loss: 0.36090660095214844
Batch 20/64 loss: 0.3610464334487915
Batch 21/64 loss: 0.36059439182281494
Batch 22/64 loss: 0.36038148403167725
Batch 23/64 loss: 0.3613753318786621
Batch 24/64 loss: 0.3596203327178955
Batch 25/64 loss: 0.3601803779602051
Batch 26/64 loss: 0.36141711473464966
Batch 27/64 loss: 0.35513728857040405
Batch 28/64 loss: 0.3610341548919678
Batch 29/64 loss: 0.3578144311904907
Batch 30/64 loss: 0.36107397079467773
Batch 31/64 loss: 0.3634120225906372
Batch 32/64 loss: 0.35817861557006836
Batch 33/64 loss: 0.36409425735473633
Batch 34/64 loss: 0.35961484909057617
Batch 35/64 loss: 0.36037933826446533
Batch 36/64 loss: 0.3608096241950989
Batch 37/64 loss: 0.3560299873352051
Batch 38/64 loss: 0.35724449157714844
Batch 39/64 loss: 0.3617194890975952
Batch 40/64 loss: 0.35873544216156006
Batch 41/64 loss: 0.3614160418510437
Batch 42/64 loss: 0.36359721422195435
Batch 43/64 loss: 0.36409568786621094
Batch 44/64 loss: 0.3630174398422241
Batch 45/64 loss: 0.35739338397979736
Batch 46/64 loss: 0.35773253440856934
Batch 47/64 loss: 0.36049312353134155
Batch 48/64 loss: 0.35869157314300537
Batch 49/64 loss: 0.3561502695083618
Batch 50/64 loss: 0.3626214861869812
Batch 51/64 loss: 0.35780268907546997
Batch 52/64 loss: 0.3597923517227173
Batch 53/64 loss: 0.3637353777885437
Batch 54/64 loss: 0.3583873510360718
Batch 55/64 loss: 0.35479962825775146
Batch 56/64 loss: 0.35616642236709595
Batch 57/64 loss: 0.3577633500099182
Batch 58/64 loss: 0.3585703372955322
Batch 59/64 loss: 0.3631107211112976
Batch 60/64 loss: 0.36140263080596924
Batch 61/64 loss: 0.3582272529602051
Batch 62/64 loss: 0.35982632637023926
Batch 63/64 loss: 0.3601837158203125
Batch 64/64 loss: 0.35661375522613525
Epoch 50  Train loss: 0.3599354075450523  Val loss: 0.36186058865380044
Epoch 51
-------------------------------
Batch 1/64 loss: 0.3535348176956177
Batch 2/64 loss: 0.35850346088409424
Batch 3/64 loss: 0.3614922761917114
Batch 4/64 loss: 0.36089080572128296
Batch 5/64 loss: 0.35871636867523193
Batch 6/64 loss: 0.3622869849205017
Batch 7/64 loss: 0.36037182807922363
Batch 8/64 loss: 0.35715925693511963
Batch 9/64 loss: 0.3592414855957031
Batch 10/64 loss: 0.36071884632110596
Batch 11/64 loss: 0.3607032299041748
Batch 12/64 loss: 0.35670965909957886
Batch 13/64 loss: 0.3595488667488098
Batch 14/64 loss: 0.3609076738357544
Batch 15/64 loss: 0.3568965196609497
Batch 16/64 loss: 0.35899674892425537
Batch 17/64 loss: 0.357540488243103
Batch 18/64 loss: 0.35782456398010254
Batch 19/64 loss: 0.36020123958587646
Batch 20/64 loss: 0.36071962118148804
Batch 21/64 loss: 0.3599604368209839
Batch 22/64 loss: 0.3590368628501892
Batch 23/64 loss: 0.35873210430145264
Batch 24/64 loss: 0.35965341329574585
Batch 25/64 loss: 0.35625141859054565
Batch 26/64 loss: 0.35760581493377686
Batch 27/64 loss: 0.36096346378326416
Batch 28/64 loss: 0.358292818069458
Batch 29/64 loss: 0.3606933355331421
Batch 30/64 loss: 0.3579491376876831
Batch 31/64 loss: 0.3567471504211426
Batch 32/64 loss: 0.3586472272872925
Batch 33/64 loss: 0.3620234727859497
Batch 34/64 loss: 0.36271774768829346
Batch 35/64 loss: 0.35957956314086914
Batch 36/64 loss: 0.3608928918838501
Batch 37/64 loss: 0.3550127148628235
Batch 38/64 loss: 0.36295104026794434
Batch 39/64 loss: 0.36204802989959717
Batch 40/64 loss: 0.3625417947769165
Batch 41/64 loss: 0.3614790439605713
Batch 42/64 loss: 0.35996347665786743
Batch 43/64 loss: 0.3632427453994751
Batch 44/64 loss: 0.36063098907470703
Batch 45/64 loss: 0.35571587085723877
Batch 46/64 loss: 0.3605427145957947
Batch 47/64 loss: 0.36324942111968994
Batch 48/64 loss: 0.36040544509887695
Batch 49/64 loss: 0.3616860508918762
Batch 50/64 loss: 0.35983556509017944
Batch 51/64 loss: 0.35818564891815186
Batch 52/64 loss: 0.3626731038093567
Batch 53/64 loss: 0.35811400413513184
Batch 54/64 loss: 0.35650575160980225
Batch 55/64 loss: 0.3581928014755249
Batch 56/64 loss: 0.36112695932388306
Batch 57/64 loss: 0.3618202805519104
Batch 58/64 loss: 0.36141085624694824
Batch 59/64 loss: 0.3618040680885315
Batch 60/64 loss: 0.3610384464263916
Batch 61/64 loss: 0.35824906826019287
Batch 62/64 loss: 0.36628401279449463
Batch 63/64 loss: 0.36109650135040283
Batch 64/64 loss: 0.35655152797698975
Epoch 51  Train loss: 0.359779320043676  Val loss: 0.36157646683073535
Saving best model, epoch: 51
Epoch 52
-------------------------------
Batch 1/64 loss: 0.3589022159576416
Batch 2/64 loss: 0.3574204444885254
Batch 3/64 loss: 0.3592417240142822
Batch 4/64 loss: 0.36571967601776123
Batch 5/64 loss: 0.3623039126396179
Batch 6/64 loss: 0.361159086227417
Batch 7/64 loss: 0.35397207736968994
Batch 8/64 loss: 0.35656988620758057
Batch 9/64 loss: 0.36270642280578613
Batch 10/64 loss: 0.360012412071228
Batch 11/64 loss: 0.3577314615249634
Batch 12/64 loss: 0.36097240447998047
Batch 13/64 loss: 0.3579939007759094
Batch 14/64 loss: 0.35963761806488037
Batch 15/64 loss: 0.36085861921310425
Batch 16/64 loss: 0.35878098011016846
Batch 17/64 loss: 0.359450101852417
Batch 18/64 loss: 0.35868173837661743
Batch 19/64 loss: 0.3628894090652466
Batch 20/64 loss: 0.3612061142921448
Batch 21/64 loss: 0.3573493957519531
Batch 22/64 loss: 0.3567146062850952
Batch 23/64 loss: 0.3624873757362366
Batch 24/64 loss: 0.36173492670059204
Batch 25/64 loss: 0.3599610924720764
Batch 26/64 loss: 0.35897111892700195
Batch 27/64 loss: 0.3645886182785034
Batch 28/64 loss: 0.3611280918121338
Batch 29/64 loss: 0.36090362071990967
Batch 30/64 loss: 0.35955607891082764
Batch 31/64 loss: 0.35952210426330566
Batch 32/64 loss: 0.36152493953704834
Batch 33/64 loss: 0.35852885246276855
Batch 34/64 loss: 0.3612149953842163
Batch 35/64 loss: 0.3608599901199341
Batch 36/64 loss: 0.35946714878082275
Batch 37/64 loss: 0.3618263006210327
Batch 38/64 loss: 0.35718488693237305
Batch 39/64 loss: 0.3602631688117981
Batch 40/64 loss: 0.36057722568511963
Batch 41/64 loss: 0.35770463943481445
Batch 42/64 loss: 0.3612149953842163
Batch 43/64 loss: 0.3605310916900635
Batch 44/64 loss: 0.36142486333847046
Batch 45/64 loss: 0.35562652349472046
Batch 46/64 loss: 0.36060667037963867
Batch 47/64 loss: 0.35951560735702515
Batch 48/64 loss: 0.36175674200057983
Batch 49/64 loss: 0.3619649410247803
Batch 50/64 loss: 0.358852744102478
Batch 51/64 loss: 0.35879087448120117
Batch 52/64 loss: 0.3619477152824402
Batch 53/64 loss: 0.36058759689331055
Batch 54/64 loss: 0.3613319396972656
Batch 55/64 loss: 0.3597460389137268
Batch 56/64 loss: 0.3598361611366272
Batch 57/64 loss: 0.3590618371963501
Batch 58/64 loss: 0.36147522926330566
Batch 59/64 loss: 0.35847008228302
Batch 60/64 loss: 0.3611832857131958
Batch 61/64 loss: 0.3589286208152771
Batch 62/64 loss: 0.3610759377479553
Batch 63/64 loss: 0.35807907581329346
Batch 64/64 loss: 0.360568106174469
Epoch 52  Train loss: 0.360011200577605  Val loss: 0.36102298403933286
Saving best model, epoch: 52
Epoch 53
-------------------------------
Batch 1/64 loss: 0.3570972681045532
Batch 2/64 loss: 0.360534131526947
Batch 3/64 loss: 0.3575359582901001
Batch 4/64 loss: 0.3547130227088928
Batch 5/64 loss: 0.3600548505783081
Batch 6/64 loss: 0.3589491844177246
Batch 7/64 loss: 0.36465907096862793
Batch 8/64 loss: 0.35905539989471436
Batch 9/64 loss: 0.35814082622528076
Batch 10/64 loss: 0.35711586475372314
Batch 11/64 loss: 0.3571844696998596
Batch 12/64 loss: 0.3580085039138794
Batch 13/64 loss: 0.35923337936401367
Batch 14/64 loss: 0.35779035091400146
Batch 15/64 loss: 0.3607844114303589
Batch 16/64 loss: 0.3618013858795166
Batch 17/64 loss: 0.3591594696044922
Batch 18/64 loss: 0.36022913455963135
Batch 19/64 loss: 0.3621366620063782
Batch 20/64 loss: 0.3616012930870056
Batch 21/64 loss: 0.357477068901062
Batch 22/64 loss: 0.3602851629257202
Batch 23/64 loss: 0.3603063225746155
Batch 24/64 loss: 0.3615865707397461
Batch 25/64 loss: 0.3586972951889038
Batch 26/64 loss: 0.3573799133300781
Batch 27/64 loss: 0.3595868945121765
Batch 28/64 loss: 0.3563944697380066
Batch 29/64 loss: 0.36192822456359863
Batch 30/64 loss: 0.3610241413116455
Batch 31/64 loss: 0.3592239022254944
Batch 32/64 loss: 0.36250877380371094
Batch 33/64 loss: 0.35756057500839233
Batch 34/64 loss: 0.3560687303543091
Batch 35/64 loss: 0.3607296943664551
Batch 36/64 loss: 0.3610249161720276
Batch 37/64 loss: 0.357538104057312
Batch 38/64 loss: 0.36450016498565674
Batch 39/64 loss: 0.35480713844299316
Batch 40/64 loss: 0.362135648727417
Batch 41/64 loss: 0.3603426218032837
Batch 42/64 loss: 0.36259615421295166
Batch 43/64 loss: 0.3625384569168091
Batch 44/64 loss: 0.35522758960723877
Batch 45/64 loss: 0.3553524613380432
Batch 46/64 loss: 0.36530089378356934
Batch 47/64 loss: 0.36266738176345825
Batch 48/64 loss: 0.3620678186416626
Batch 49/64 loss: 0.3627644181251526
Batch 50/64 loss: 0.35978221893310547
Batch 51/64 loss: 0.35648268461227417
Batch 52/64 loss: 0.3581773042678833
Batch 53/64 loss: 0.3611370325088501
Batch 54/64 loss: 0.36148756742477417
Batch 55/64 loss: 0.3565216660499573
Batch 56/64 loss: 0.36166560649871826
Batch 57/64 loss: 0.3583282232284546
Batch 58/64 loss: 0.35983526706695557
Batch 59/64 loss: 0.36164534091949463
Batch 60/64 loss: 0.35792672634124756
Batch 61/64 loss: 0.3586219549179077
Batch 62/64 loss: 0.3635391592979431
Batch 63/64 loss: 0.35895681381225586
Batch 64/64 loss: 0.3599921464920044
Epoch 53  Train loss: 0.3596785540674247  Val loss: 0.36137506601327063
Epoch 54
-------------------------------
Batch 1/64 loss: 0.35850173234939575
Batch 2/64 loss: 0.3575814962387085
Batch 3/64 loss: 0.3610832095146179
Batch 4/64 loss: 0.3594244122505188
Batch 5/64 loss: 0.35940784215927124
Batch 6/64 loss: 0.3591470718383789
Batch 7/64 loss: 0.35933375358581543
Batch 8/64 loss: 0.3611145615577698
Batch 9/64 loss: 0.3608541488647461
Batch 10/64 loss: 0.35985076427459717
Batch 11/64 loss: 0.3582202196121216
Batch 12/64 loss: 0.35848379135131836
Batch 13/64 loss: 0.3582480549812317
Batch 14/64 loss: 0.35986441373825073
Batch 15/64 loss: 0.3604109287261963
Batch 16/64 loss: 0.3588041067123413
Batch 17/64 loss: 0.362445592880249
Batch 18/64 loss: 0.3589394688606262
Batch 19/64 loss: 0.3616577982902527
Batch 20/64 loss: 0.3621528148651123
Batch 21/64 loss: 0.3607833981513977
Batch 22/64 loss: 0.3584393858909607
Batch 23/64 loss: 0.36285853385925293
Batch 24/64 loss: 0.3603544235229492
Batch 25/64 loss: 0.35823869705200195
Batch 26/64 loss: 0.3587709665298462
Batch 27/64 loss: 0.3591402769088745
Batch 28/64 loss: 0.3588167428970337
Batch 29/64 loss: 0.3598262667655945
Batch 30/64 loss: 0.35631972551345825
Batch 31/64 loss: 0.3595404028892517
Batch 32/64 loss: 0.3606705665588379
Batch 33/64 loss: 0.35734260082244873
Batch 34/64 loss: 0.3576622009277344
Batch 35/64 loss: 0.3597313165664673
Batch 36/64 loss: 0.36157089471817017
Batch 37/64 loss: 0.3601149320602417
Batch 38/64 loss: 0.35817575454711914
Batch 39/64 loss: 0.36142921447753906
Batch 40/64 loss: 0.3595125675201416
Batch 41/64 loss: 0.3591979742050171
Batch 42/64 loss: 0.3584158420562744
Batch 43/64 loss: 0.35491836071014404
Batch 44/64 loss: 0.35907208919525146
Batch 45/64 loss: 0.3564249277114868
Batch 46/64 loss: 0.36054348945617676
Batch 47/64 loss: 0.3571207523345947
Batch 48/64 loss: 0.3576548099517822
Batch 49/64 loss: 0.3582206964492798
Batch 50/64 loss: 0.35984671115875244
Batch 51/64 loss: 0.36070650815963745
Batch 52/64 loss: 0.35876280069351196
Batch 53/64 loss: 0.3612910509109497
Batch 54/64 loss: 0.3586704730987549
Batch 55/64 loss: 0.3592292070388794
Batch 56/64 loss: 0.3593904972076416
Batch 57/64 loss: 0.3581099510192871
Batch 58/64 loss: 0.3614161014556885
Batch 59/64 loss: 0.35964691638946533
Batch 60/64 loss: 0.35833704471588135
Batch 61/64 loss: 0.36002618074417114
Batch 62/64 loss: 0.3548400402069092
Batch 63/64 loss: 0.35677599906921387
Batch 64/64 loss: 0.35917460918426514
Epoch 54  Train loss: 0.3592599910848281  Val loss: 0.36063967332807195
Saving best model, epoch: 54
Epoch 55
-------------------------------
Batch 1/64 loss: 0.36168909072875977
Batch 2/64 loss: 0.35318535566329956
Batch 3/64 loss: 0.3614193797111511
Batch 4/64 loss: 0.36163389682769775
Batch 5/64 loss: 0.35663360357284546
Batch 6/64 loss: 0.36127912998199463
Batch 7/64 loss: 0.3591940402984619
Batch 8/64 loss: 0.35662031173706055
Batch 9/64 loss: 0.3575175404548645
Batch 10/64 loss: 0.3577973246574402
Batch 11/64 loss: 0.3588411211967468
Batch 12/64 loss: 0.35929203033447266
Batch 13/64 loss: 0.359885036945343
Batch 14/64 loss: 0.3580276370048523
Batch 15/64 loss: 0.35945916175842285
Batch 16/64 loss: 0.3604750633239746
Batch 17/64 loss: 0.3575563430786133
Batch 18/64 loss: 0.3582553267478943
Batch 19/64 loss: 0.35719728469848633
Batch 20/64 loss: 0.357244610786438
Batch 21/64 loss: 0.35933375358581543
Batch 22/64 loss: 0.35959839820861816
Batch 23/64 loss: 0.3600318431854248
Batch 24/64 loss: 0.3610137701034546
Batch 25/64 loss: 0.3579733371734619
Batch 26/64 loss: 0.3576493263244629
Batch 27/64 loss: 0.3602446913719177
Batch 28/64 loss: 0.3578524589538574
Batch 29/64 loss: 0.36315083503723145
Batch 30/64 loss: 0.358600378036499
Batch 31/64 loss: 0.35469508171081543
Batch 32/64 loss: 0.3571106195449829
Batch 33/64 loss: 0.36112087965011597
Batch 34/64 loss: 0.3635830283164978
Batch 35/64 loss: 0.35735124349594116
Batch 36/64 loss: 0.359499990940094
Batch 37/64 loss: 0.3571711778640747
Batch 38/64 loss: 0.3598201870918274
Batch 39/64 loss: 0.35918325185775757
Batch 40/64 loss: 0.3588395118713379
Batch 41/64 loss: 0.3553274869918823
Batch 42/64 loss: 0.3562721014022827
Batch 43/64 loss: 0.3595099449157715
Batch 44/64 loss: 0.35846543312072754
Batch 45/64 loss: 0.36173903942108154
Batch 46/64 loss: 0.3599742650985718
Batch 47/64 loss: 0.358572781085968
Batch 48/64 loss: 0.36078327894210815
Batch 49/64 loss: 0.3566030263900757
Batch 50/64 loss: 0.35827720165252686
Batch 51/64 loss: 0.3583143353462219
Batch 52/64 loss: 0.36036938428878784
Batch 53/64 loss: 0.35865461826324463
Batch 54/64 loss: 0.36036741733551025
Batch 55/64 loss: 0.3617539405822754
Batch 56/64 loss: 0.36174941062927246
Batch 57/64 loss: 0.36142563819885254
Batch 58/64 loss: 0.35945236682891846
Batch 59/64 loss: 0.3611171245574951
Batch 60/64 loss: 0.36350178718566895
Batch 61/64 loss: 0.3627662658691406
Batch 62/64 loss: 0.35980868339538574
Batch 63/64 loss: 0.3585195541381836
Batch 64/64 loss: 0.36295223236083984
Epoch 55  Train loss: 0.3592559421763701  Val loss: 0.36041980080588165
Saving best model, epoch: 55
Epoch 56
-------------------------------
Batch 1/64 loss: 0.35532528162002563
Batch 2/64 loss: 0.36121898889541626
Batch 3/64 loss: 0.35862982273101807
Batch 4/64 loss: 0.3575476408004761
Batch 5/64 loss: 0.3588712215423584
Batch 6/64 loss: 0.35665130615234375
Batch 7/64 loss: 0.36586225032806396
Batch 8/64 loss: 0.3568933606147766
Batch 9/64 loss: 0.36116641759872437
Batch 10/64 loss: 0.36450129747390747
Batch 11/64 loss: 0.35612618923187256
Batch 12/64 loss: 0.36045825481414795
Batch 13/64 loss: 0.3569234609603882
Batch 14/64 loss: 0.3634549379348755
Batch 15/64 loss: 0.35730886459350586
Batch 16/64 loss: 0.35705411434173584
Batch 17/64 loss: 0.35628658533096313
Batch 18/64 loss: 0.3596450090408325
Batch 19/64 loss: 0.35723769664764404
Batch 20/64 loss: 0.35980749130249023
Batch 21/64 loss: 0.359330415725708
Batch 22/64 loss: 0.3612511157989502
Batch 23/64 loss: 0.3603403568267822
Batch 24/64 loss: 0.36497998237609863
Batch 25/64 loss: 0.3628055453300476
Batch 26/64 loss: 0.358317494392395
Batch 27/64 loss: 0.36066967248916626
Batch 28/64 loss: 0.35611701011657715
Batch 29/64 loss: 0.36059319972991943
Batch 30/64 loss: 0.3590806722640991
Batch 31/64 loss: 0.35789400339126587
Batch 32/64 loss: 0.3575558662414551
Batch 33/64 loss: 0.35635578632354736
Batch 34/64 loss: 0.3631455898284912
Batch 35/64 loss: 0.35997533798217773
Batch 36/64 loss: 0.3605109453201294
Batch 37/64 loss: 0.35710573196411133
Batch 38/64 loss: 0.3574655055999756
Batch 39/64 loss: 0.3575863838195801
Batch 40/64 loss: 0.35861289501190186
Batch 41/64 loss: 0.3599100112915039
Batch 42/64 loss: 0.3585766553878784
Batch 43/64 loss: 0.35750293731689453
Batch 44/64 loss: 0.3559304475784302
Batch 45/64 loss: 0.3606632947921753
Batch 46/64 loss: 0.3572872281074524
Batch 47/64 loss: 0.35536491870880127
Batch 48/64 loss: 0.36326897144317627
Batch 49/64 loss: 0.3610498905181885
Batch 50/64 loss: 0.3587489128112793
Batch 51/64 loss: 0.3620036840438843
Batch 52/64 loss: 0.3595050573348999
Batch 53/64 loss: 0.3540065288543701
Batch 54/64 loss: 0.3590630888938904
Batch 55/64 loss: 0.3586268424987793
Batch 56/64 loss: 0.3578953742980957
Batch 57/64 loss: 0.35768425464630127
Batch 58/64 loss: 0.361311674118042
Batch 59/64 loss: 0.358273983001709
Batch 60/64 loss: 0.3613557815551758
Batch 61/64 loss: 0.35696864128112793
Batch 62/64 loss: 0.3608768582344055
Batch 63/64 loss: 0.35668784379959106
Batch 64/64 loss: 0.35592854022979736
Epoch 56  Train loss: 0.3590615370694329  Val loss: 0.36018572967896345
Saving best model, epoch: 56
Epoch 57
-------------------------------
Batch 1/64 loss: 0.3585311770439148
Batch 2/64 loss: 0.35896414518356323
Batch 3/64 loss: 0.35975712537765503
Batch 4/64 loss: 0.3612666726112366
Batch 5/64 loss: 0.3594372868537903
Batch 6/64 loss: 0.3552602529525757
Batch 7/64 loss: 0.35448157787323
Batch 8/64 loss: 0.35876697301864624
Batch 9/64 loss: 0.3629382848739624
Batch 10/64 loss: 0.3618570566177368
Batch 11/64 loss: 0.3584625720977783
Batch 12/64 loss: 0.3574570417404175
Batch 13/64 loss: 0.36398959159851074
Batch 14/64 loss: 0.35856354236602783
Batch 15/64 loss: 0.3569979667663574
Batch 16/64 loss: 0.35836517810821533
Batch 17/64 loss: 0.3594907522201538
Batch 18/64 loss: 0.35850393772125244
Batch 19/64 loss: 0.35714757442474365
Batch 20/64 loss: 0.3551875948905945
Batch 21/64 loss: 0.3589857816696167
Batch 22/64 loss: 0.3591378927230835
Batch 23/64 loss: 0.35710763931274414
Batch 24/64 loss: 0.3578009605407715
Batch 25/64 loss: 0.3613400459289551
Batch 26/64 loss: 0.3628517985343933
Batch 27/64 loss: 0.35962527990341187
Batch 28/64 loss: 0.3579826354980469
Batch 29/64 loss: 0.35670024156570435
Batch 30/64 loss: 0.3597308397293091
Batch 31/64 loss: 0.3601401448249817
Batch 32/64 loss: 0.3595728874206543
Batch 33/64 loss: 0.3615204691886902
Batch 34/64 loss: 0.35829031467437744
Batch 35/64 loss: 0.3579472303390503
Batch 36/64 loss: 0.35974764823913574
Batch 37/64 loss: 0.3571149706840515
Batch 38/64 loss: 0.3613090515136719
Batch 39/64 loss: 0.3562164306640625
Batch 40/64 loss: 0.3589162826538086
Batch 41/64 loss: 0.359840452671051
Batch 42/64 loss: 0.36153316497802734
Batch 43/64 loss: 0.3604174852371216
Batch 44/64 loss: 0.3588813543319702
Batch 45/64 loss: 0.357616662979126
Batch 46/64 loss: 0.3601784110069275
Batch 47/64 loss: 0.36078232526779175
Batch 48/64 loss: 0.35499197244644165
Batch 49/64 loss: 0.36025428771972656
Batch 50/64 loss: 0.3586146831512451
Batch 51/64 loss: 0.3559677004814148
Batch 52/64 loss: 0.35843002796173096
Batch 53/64 loss: 0.35747063159942627
Batch 54/64 loss: 0.3547137975692749
Batch 55/64 loss: 0.36033356189727783
Batch 56/64 loss: 0.35876429080963135
Batch 57/64 loss: 0.3565971255302429
Batch 58/64 loss: 0.3578803539276123
Batch 59/64 loss: 0.35923928022384644
Batch 60/64 loss: 0.35929131507873535
Batch 61/64 loss: 0.3608736991882324
Batch 62/64 loss: 0.358275830745697
Batch 63/64 loss: 0.3609044551849365
Batch 64/64 loss: 0.3573613166809082
Epoch 57  Train loss: 0.3588602150187773  Val loss: 0.361199062714462
Epoch 58
-------------------------------
Batch 1/64 loss: 0.3606266975402832
Batch 2/64 loss: 0.3566330075263977
Batch 3/64 loss: 0.35712528228759766
Batch 4/64 loss: 0.3579382300376892
Batch 5/64 loss: 0.3614208698272705
Batch 6/64 loss: 0.3613206148147583
Batch 7/64 loss: 0.3585129380226135
Batch 8/64 loss: 0.35944002866744995
Batch 9/64 loss: 0.3577214479446411
Batch 10/64 loss: 0.36084842681884766
Batch 11/64 loss: 0.3631770610809326
Batch 12/64 loss: 0.36071979999542236
Batch 13/64 loss: 0.362085223197937
Batch 14/64 loss: 0.36126410961151123
Batch 15/64 loss: 0.36056745052337646
Batch 16/64 loss: 0.36408066749572754
Batch 17/64 loss: 0.3562014102935791
Batch 18/64 loss: 0.35635948181152344
Batch 19/64 loss: 0.3576425313949585
Batch 20/64 loss: 0.3586181402206421
Batch 21/64 loss: 0.35874509811401367
Batch 22/64 loss: 0.3612126111984253
Batch 23/64 loss: 0.3541322946548462
Batch 24/64 loss: 0.35869431495666504
Batch 25/64 loss: 0.35777080059051514
Batch 26/64 loss: 0.35832303762435913
Batch 27/64 loss: 0.3581501245498657
Batch 28/64 loss: 0.3570020794868469
Batch 29/64 loss: 0.35642707347869873
Batch 30/64 loss: 0.3591444492340088
Batch 31/64 loss: 0.358590304851532
Batch 32/64 loss: 0.35742056369781494
Batch 33/64 loss: 0.35697126388549805
Batch 34/64 loss: 0.3619232773780823
Batch 35/64 loss: 0.35621076822280884
Batch 36/64 loss: 0.3613010048866272
Batch 37/64 loss: 0.35781800746917725
Batch 38/64 loss: 0.3562718629837036
Batch 39/64 loss: 0.3619586229324341
Batch 40/64 loss: 0.36033451557159424
Batch 41/64 loss: 0.3615924119949341
Batch 42/64 loss: 0.3580557703971863
Batch 43/64 loss: 0.3596307039260864
Batch 44/64 loss: 0.36481380462646484
Batch 45/64 loss: 0.360113263130188
Batch 46/64 loss: 0.3618500828742981
Batch 47/64 loss: 0.35820674896240234
Batch 48/64 loss: 0.3606187701225281
Batch 49/64 loss: 0.361868679523468
Batch 50/64 loss: 0.3611757755279541
Batch 51/64 loss: 0.35976308584213257
Batch 52/64 loss: 0.3582642078399658
Batch 53/64 loss: 0.358683705329895
Batch 54/64 loss: 0.3569471836090088
Batch 55/64 loss: 0.3574955463409424
Batch 56/64 loss: 0.3610913157463074
Batch 57/64 loss: 0.3574230670928955
Batch 58/64 loss: 0.3588297367095947
Batch 59/64 loss: 0.3615536093711853
Batch 60/64 loss: 0.3596210479736328
Batch 61/64 loss: 0.3582611083984375
Batch 62/64 loss: 0.3577965497970581
Batch 63/64 loss: 0.3554728627204895
Batch 64/64 loss: 0.3548904061317444
Epoch 58  Train loss: 0.3591529778405732  Val loss: 0.36048694779373114
Epoch 59
-------------------------------
Batch 1/64 loss: 0.35663002729415894
Batch 2/64 loss: 0.36093664169311523
Batch 3/64 loss: 0.35521072149276733
Batch 4/64 loss: 0.3568156957626343
Batch 5/64 loss: 0.3577767610549927
Batch 6/64 loss: 0.3583259582519531
Batch 7/64 loss: 0.36239057779312134
Batch 8/64 loss: 0.3570248484611511
Batch 9/64 loss: 0.35768866539001465
Batch 10/64 loss: 0.35516250133514404
Batch 11/64 loss: 0.3588390350341797
Batch 12/64 loss: 0.35721516609191895
Batch 13/64 loss: 0.3590925931930542
Batch 14/64 loss: 0.36017006635665894
Batch 15/64 loss: 0.35721391439437866
Batch 16/64 loss: 0.3588968515396118
Batch 17/64 loss: 0.3571557402610779
Batch 18/64 loss: 0.3584163188934326
Batch 19/64 loss: 0.3599793314933777
Batch 20/64 loss: 0.3597162365913391
Batch 21/64 loss: 0.3603626489639282
Batch 22/64 loss: 0.360227108001709
Batch 23/64 loss: 0.35800135135650635
Batch 24/64 loss: 0.36107075214385986
Batch 25/64 loss: 0.3541524410247803
Batch 26/64 loss: 0.35943758487701416
Batch 27/64 loss: 0.3595905303955078
Batch 28/64 loss: 0.35530078411102295
Batch 29/64 loss: 0.3616565465927124
Batch 30/64 loss: 0.3592252731323242
Batch 31/64 loss: 0.35963118076324463
Batch 32/64 loss: 0.358551025390625
Batch 33/64 loss: 0.3604605197906494
Batch 34/64 loss: 0.36152637004852295
Batch 35/64 loss: 0.35682469606399536
Batch 36/64 loss: 0.3569847345352173
Batch 37/64 loss: 0.36096131801605225
Batch 38/64 loss: 0.3625715970993042
Batch 39/64 loss: 0.3586757183074951
Batch 40/64 loss: 0.3599194884300232
Batch 41/64 loss: 0.35945653915405273
Batch 42/64 loss: 0.3615860939025879
Batch 43/64 loss: 0.357896625995636
Batch 44/64 loss: 0.361929714679718
Batch 45/64 loss: 0.36024415493011475
Batch 46/64 loss: 0.3549560308456421
Batch 47/64 loss: 0.3593897819519043
Batch 48/64 loss: 0.36428260803222656
Batch 49/64 loss: 0.35829979181289673
Batch 50/64 loss: 0.3615942597389221
Batch 51/64 loss: 0.35953444242477417
Batch 52/64 loss: 0.3579557538032532
Batch 53/64 loss: 0.3611212968826294
Batch 54/64 loss: 0.3607659339904785
Batch 55/64 loss: 0.35795629024505615
Batch 56/64 loss: 0.3589717149734497
Batch 57/64 loss: 0.35644209384918213
Batch 58/64 loss: 0.3624197840690613
Batch 59/64 loss: 0.35916638374328613
Batch 60/64 loss: 0.35858428478240967
Batch 61/64 loss: 0.3612328767776489
Batch 62/64 loss: 0.3600679636001587
Batch 63/64 loss: 0.35789811611175537
Batch 64/64 loss: 0.3579437732696533
Epoch 59  Train loss: 0.3590588186301437  Val loss: 0.36008720996043936
Saving best model, epoch: 59
Epoch 60
-------------------------------
Batch 1/64 loss: 0.3577171564102173
Batch 2/64 loss: 0.3588547110557556
Batch 3/64 loss: 0.3543657064437866
Batch 4/64 loss: 0.3560890555381775
Batch 5/64 loss: 0.35970228910446167
Batch 6/64 loss: 0.3614027500152588
Batch 7/64 loss: 0.35654115676879883
Batch 8/64 loss: 0.3603784441947937
Batch 9/64 loss: 0.35961735248565674
Batch 10/64 loss: 0.3587266206741333
Batch 11/64 loss: 0.35716962814331055
Batch 12/64 loss: 0.3567314147949219
Batch 13/64 loss: 0.3575413227081299
Batch 14/64 loss: 0.35645198822021484
Batch 15/64 loss: 0.3564680218696594
Batch 16/64 loss: 0.35611850023269653
Batch 17/64 loss: 0.3583519458770752
Batch 18/64 loss: 0.3564929962158203
Batch 19/64 loss: 0.3564150929450989
Batch 20/64 loss: 0.355487585067749
Batch 21/64 loss: 0.35601723194122314
Batch 22/64 loss: 0.3580087423324585
Batch 23/64 loss: 0.3602890968322754
Batch 24/64 loss: 0.35360419750213623
Batch 25/64 loss: 0.3595987558364868
Batch 26/64 loss: 0.3587077260017395
Batch 27/64 loss: 0.35923510789871216
Batch 28/64 loss: 0.35625457763671875
Batch 29/64 loss: 0.35655152797698975
Batch 30/64 loss: 0.3614317774772644
Batch 31/64 loss: 0.36376339197158813
Batch 32/64 loss: 0.35764777660369873
Batch 33/64 loss: 0.35803931951522827
Batch 34/64 loss: 0.3592444062232971
Batch 35/64 loss: 0.3598077893257141
Batch 36/64 loss: 0.35790902376174927
Batch 37/64 loss: 0.35930657386779785
Batch 38/64 loss: 0.3538234233856201
Batch 39/64 loss: 0.3618971109390259
Batch 40/64 loss: 0.35867297649383545
Batch 41/64 loss: 0.35821038484573364
Batch 42/64 loss: 0.3628530502319336
Batch 43/64 loss: 0.3616321086883545
Batch 44/64 loss: 0.3600671887397766
Batch 45/64 loss: 0.3574591875076294
Batch 46/64 loss: 0.3604027032852173
Batch 47/64 loss: 0.3593304753303528
Batch 48/64 loss: 0.3610262870788574
Batch 49/64 loss: 0.36287569999694824
Batch 50/64 loss: 0.36031556129455566
Batch 51/64 loss: 0.3618934154510498
Batch 52/64 loss: 0.3581555485725403
Batch 53/64 loss: 0.35927844047546387
Batch 54/64 loss: 0.35895389318466187
Batch 55/64 loss: 0.3598287105560303
Batch 56/64 loss: 0.36024701595306396
Batch 57/64 loss: 0.3591804504394531
Batch 58/64 loss: 0.35852980613708496
Batch 59/64 loss: 0.35944879055023193
Batch 60/64 loss: 0.3569244146347046
Batch 61/64 loss: 0.35986411571502686
Batch 62/64 loss: 0.35753995180130005
Batch 63/64 loss: 0.35901939868927
Batch 64/64 loss: 0.3597414493560791
Epoch 60  Train loss: 0.3586396385641659  Val loss: 0.36120799808567744
Epoch 61
-------------------------------
Batch 1/64 loss: 0.3610440492630005
Batch 2/64 loss: 0.3581327199935913
Batch 3/64 loss: 0.3605707883834839
Batch 4/64 loss: 0.35692262649536133
Batch 5/64 loss: 0.3559701442718506
Batch 6/64 loss: 0.3584461808204651
Batch 7/64 loss: 0.35610783100128174
Batch 8/64 loss: 0.3574833869934082
Batch 9/64 loss: 0.35939639806747437
Batch 10/64 loss: 0.36084264516830444
Batch 11/64 loss: 0.3594592809677124
Batch 12/64 loss: 0.3572785258293152
Batch 13/64 loss: 0.3583228588104248
Batch 14/64 loss: 0.35502517223358154
Batch 15/64 loss: 0.3615117073059082
Batch 16/64 loss: 0.3589121103286743
Batch 17/64 loss: 0.3561250567436218
Batch 18/64 loss: 0.36079442501068115
Batch 19/64 loss: 0.35744041204452515
Batch 20/64 loss: 0.35553252696990967
Batch 21/64 loss: 0.3583405017852783
Batch 22/64 loss: 0.3583502769470215
Batch 23/64 loss: 0.3573349714279175
Batch 24/64 loss: 0.36080652475357056
Batch 25/64 loss: 0.35700976848602295
Batch 26/64 loss: 0.36108601093292236
Batch 27/64 loss: 0.3546960949897766
Batch 28/64 loss: 0.361835241317749
Batch 29/64 loss: 0.3582417368888855
Batch 30/64 loss: 0.3603074550628662
Batch 31/64 loss: 0.3598968982696533
Batch 32/64 loss: 0.3583293557167053
Batch 33/64 loss: 0.3585916757583618
Batch 34/64 loss: 0.35618478059768677
Batch 35/64 loss: 0.3619499206542969
Batch 36/64 loss: 0.3587544560432434
Batch 37/64 loss: 0.35831230878829956
Batch 38/64 loss: 0.3583833575248718
Batch 39/64 loss: 0.3569873571395874
Batch 40/64 loss: 0.35787808895111084
Batch 41/64 loss: 0.35815656185150146
Batch 42/64 loss: 0.356797993183136
Batch 43/64 loss: 0.3611849546432495
Batch 44/64 loss: 0.3573710322380066
Batch 45/64 loss: 0.3606761693954468
Batch 46/64 loss: 0.35990142822265625
Batch 47/64 loss: 0.3624083995819092
Batch 48/64 loss: 0.36165404319763184
Batch 49/64 loss: 0.36302828788757324
Batch 50/64 loss: 0.3571494221687317
Batch 51/64 loss: 0.3604123592376709
Batch 52/64 loss: 0.35924601554870605
Batch 53/64 loss: 0.3589378595352173
Batch 54/64 loss: 0.3595784306526184
Batch 55/64 loss: 0.3610116243362427
Batch 56/64 loss: 0.3571655750274658
Batch 57/64 loss: 0.3563845157623291
Batch 58/64 loss: 0.35807478427886963
Batch 59/64 loss: 0.3595520257949829
Batch 60/64 loss: 0.35844874382019043
Batch 61/64 loss: 0.3617757558822632
Batch 62/64 loss: 0.3580707311630249
Batch 63/64 loss: 0.35714805126190186
Batch 64/64 loss: 0.35600823163986206
Epoch 61  Train loss: 0.35874096575905295  Val loss: 0.3599574410218963
Saving best model, epoch: 61
Epoch 62
-------------------------------
Batch 1/64 loss: 0.354886531829834
Batch 2/64 loss: 0.35591936111450195
Batch 3/64 loss: 0.36006325483322144
Batch 4/64 loss: 0.36028146743774414
Batch 5/64 loss: 0.3584855794906616
Batch 6/64 loss: 0.35757070779800415
Batch 7/64 loss: 0.35998475551605225
Batch 8/64 loss: 0.361453652381897
Batch 9/64 loss: 0.3593682050704956
Batch 10/64 loss: 0.35881537199020386
Batch 11/64 loss: 0.36204320192337036
Batch 12/64 loss: 0.36134815216064453
Batch 13/64 loss: 0.3605402708053589
Batch 14/64 loss: 0.3600963354110718
Batch 15/64 loss: 0.35680830478668213
Batch 16/64 loss: 0.3581165075302124
Batch 17/64 loss: 0.35600781440734863
Batch 18/64 loss: 0.3572263717651367
Batch 19/64 loss: 0.35646486282348633
Batch 20/64 loss: 0.3586442470550537
Batch 21/64 loss: 0.3549532890319824
Batch 22/64 loss: 0.35938751697540283
Batch 23/64 loss: 0.3583771586418152
Batch 24/64 loss: 0.3564426898956299
Batch 25/64 loss: 0.3557240962982178
Batch 26/64 loss: 0.3571699261665344
Batch 27/64 loss: 0.35903334617614746
Batch 28/64 loss: 0.3592245578765869
Batch 29/64 loss: 0.36112767457962036
Batch 30/64 loss: 0.36066901683807373
Batch 31/64 loss: 0.3585822582244873
Batch 32/64 loss: 0.35756003856658936
Batch 33/64 loss: 0.35818052291870117
Batch 34/64 loss: 0.3579337000846863
Batch 35/64 loss: 0.3590846061706543
Batch 36/64 loss: 0.3611330986022949
Batch 37/64 loss: 0.35854023694992065
Batch 38/64 loss: 0.35646867752075195
Batch 39/64 loss: 0.3588021397590637
Batch 40/64 loss: 0.3584880232810974
Batch 41/64 loss: 0.35617268085479736
Batch 42/64 loss: 0.3572017550468445
Batch 43/64 loss: 0.3593136668205261
Batch 44/64 loss: 0.356173038482666
Batch 45/64 loss: 0.3561359643936157
Batch 46/64 loss: 0.35578399896621704
Batch 47/64 loss: 0.3557165265083313
Batch 48/64 loss: 0.3583136796951294
Batch 49/64 loss: 0.3608464002609253
Batch 50/64 loss: 0.35684746503829956
Batch 51/64 loss: 0.3558390140533447
Batch 52/64 loss: 0.3615323305130005
Batch 53/64 loss: 0.3581307530403137
Batch 54/64 loss: 0.3575732707977295
Batch 55/64 loss: 0.35818618535995483
Batch 56/64 loss: 0.36045676469802856
Batch 57/64 loss: 0.362743079662323
Batch 58/64 loss: 0.3584468960762024
Batch 59/64 loss: 0.35711872577667236
Batch 60/64 loss: 0.359218955039978
Batch 61/64 loss: 0.3562029004096985
Batch 62/64 loss: 0.35977017879486084
Batch 63/64 loss: 0.3579082489013672
Batch 64/64 loss: 0.3579440712928772
Epoch 62  Train loss: 0.3583544794250937  Val loss: 0.3606532349209605
Epoch 63
-------------------------------
Batch 1/64 loss: 0.3572092652320862
Batch 2/64 loss: 0.3603767156600952
Batch 3/64 loss: 0.36052197217941284
Batch 4/64 loss: 0.3613762855529785
Batch 5/64 loss: 0.3561767339706421
Batch 6/64 loss: 0.36109793186187744
Batch 7/64 loss: 0.359940767288208
Batch 8/64 loss: 0.35785698890686035
Batch 9/64 loss: 0.3567942976951599
Batch 10/64 loss: 0.35930734872817993
Batch 11/64 loss: 0.3570355772972107
Batch 12/64 loss: 0.3595235347747803
Batch 13/64 loss: 0.35407114028930664
Batch 14/64 loss: 0.35748958587646484
Batch 15/64 loss: 0.3587234616279602
Batch 16/64 loss: 0.3551851511001587
Batch 17/64 loss: 0.3630794286727905
Batch 18/64 loss: 0.3603275418281555
Batch 19/64 loss: 0.3596305847167969
Batch 20/64 loss: 0.35759806632995605
Batch 21/64 loss: 0.35903286933898926
Batch 22/64 loss: 0.3611581325531006
Batch 23/64 loss: 0.3581349849700928
Batch 24/64 loss: 0.36041367053985596
Batch 25/64 loss: 0.35836803913116455
Batch 26/64 loss: 0.35524845123291016
Batch 27/64 loss: 0.3584098219871521
Batch 28/64 loss: 0.3574146032333374
Batch 29/64 loss: 0.35504066944122314
Batch 30/64 loss: 0.3593127727508545
Batch 31/64 loss: 0.3596113324165344
Batch 32/64 loss: 0.361034631729126
Batch 33/64 loss: 0.3594231605529785
Batch 34/64 loss: 0.35979801416397095
Batch 35/64 loss: 0.3596649169921875
Batch 36/64 loss: 0.35685497522354126
Batch 37/64 loss: 0.35938769578933716
Batch 38/64 loss: 0.35461580753326416
Batch 39/64 loss: 0.3587280511856079
Batch 40/64 loss: 0.35812509059906006
Batch 41/64 loss: 0.3585546612739563
Batch 42/64 loss: 0.35432010889053345
Batch 43/64 loss: 0.358600914478302
Batch 44/64 loss: 0.3543548583984375
Batch 45/64 loss: 0.35824668407440186
Batch 46/64 loss: 0.3585435748100281
Batch 47/64 loss: 0.3588179349899292
Batch 48/64 loss: 0.3585238456726074
Batch 49/64 loss: 0.35779494047164917
Batch 50/64 loss: 0.3590947985649109
Batch 51/64 loss: 0.3588292598724365
Batch 52/64 loss: 0.3578237295150757
Batch 53/64 loss: 0.35687750577926636
Batch 54/64 loss: 0.36367785930633545
Batch 55/64 loss: 0.3619377017021179
Batch 56/64 loss: 0.35482072830200195
Batch 57/64 loss: 0.35722559690475464
Batch 58/64 loss: 0.3572930097579956
Batch 59/64 loss: 0.3618204593658447
Batch 60/64 loss: 0.35810399055480957
Batch 61/64 loss: 0.36219072341918945
Batch 62/64 loss: 0.3532927632331848
Batch 63/64 loss: 0.3548130989074707
Batch 64/64 loss: 0.35820209980010986
Epoch 63  Train loss: 0.3583891826517442  Val loss: 0.3603749283400598
Epoch 64
-------------------------------
Batch 1/64 loss: 0.35693836212158203
Batch 2/64 loss: 0.3614003658294678
Batch 3/64 loss: 0.3591362237930298
Batch 4/64 loss: 0.357818603515625
Batch 5/64 loss: 0.35533905029296875
Batch 6/64 loss: 0.3582160472869873
Batch 7/64 loss: 0.3578609228134155
Batch 8/64 loss: 0.35744357109069824
Batch 9/64 loss: 0.3569667339324951
Batch 10/64 loss: 0.3597506284713745
Batch 11/64 loss: 0.35503631830215454
Batch 12/64 loss: 0.3575515151023865
Batch 13/64 loss: 0.36010265350341797
Batch 14/64 loss: 0.3609994649887085
Batch 15/64 loss: 0.3584989309310913
Batch 16/64 loss: 0.35781335830688477
Batch 17/64 loss: 0.3571798801422119
Batch 18/64 loss: 0.35511302947998047
Batch 19/64 loss: 0.3601386547088623
Batch 20/64 loss: 0.3581259250640869
Batch 21/64 loss: 0.3588411211967468
Batch 22/64 loss: 0.35584068298339844
Batch 23/64 loss: 0.3541644811630249
Batch 24/64 loss: 0.35684800148010254
Batch 25/64 loss: 0.3627457022666931
Batch 26/64 loss: 0.35842591524124146
Batch 27/64 loss: 0.35853517055511475
Batch 28/64 loss: 0.3617241382598877
Batch 29/64 loss: 0.356414258480072
Batch 30/64 loss: 0.3561830520629883
Batch 31/64 loss: 0.3547405004501343
Batch 32/64 loss: 0.3597438335418701
Batch 33/64 loss: 0.357313871383667
Batch 34/64 loss: 0.3600447177886963
Batch 35/64 loss: 0.3571435213088989
Batch 36/64 loss: 0.35835886001586914
Batch 37/64 loss: 0.3584669232368469
Batch 38/64 loss: 0.3567277193069458
Batch 39/64 loss: 0.35902076959609985
Batch 40/64 loss: 0.3584185838699341
Batch 41/64 loss: 0.3569422960281372
Batch 42/64 loss: 0.35445618629455566
Batch 43/64 loss: 0.35659241676330566
Batch 44/64 loss: 0.3562164306640625
Batch 45/64 loss: 0.36000943183898926
Batch 46/64 loss: 0.3568688631057739
Batch 47/64 loss: 0.3581385612487793
Batch 48/64 loss: 0.35723817348480225
Batch 49/64 loss: 0.3601651191711426
Batch 50/64 loss: 0.35960519313812256
Batch 51/64 loss: 0.35513854026794434
Batch 52/64 loss: 0.3555474281311035
Batch 53/64 loss: 0.35699719190597534
Batch 54/64 loss: 0.3555337190628052
Batch 55/64 loss: 0.35845571756362915
Batch 56/64 loss: 0.35989511013031006
Batch 57/64 loss: 0.3497755527496338
Batch 58/64 loss: 0.3564828038215637
Batch 59/64 loss: 0.35725533962249756
Batch 60/64 loss: 0.35659825801849365
Batch 61/64 loss: 0.3593553304672241
Batch 62/64 loss: 0.36272764205932617
Batch 63/64 loss: 0.36053210496902466
Batch 64/64 loss: 0.3563591241836548
Epoch 64  Train loss: 0.3577871187060487  Val loss: 0.3597018315210375
Saving best model, epoch: 64
Epoch 65
-------------------------------
Batch 1/64 loss: 0.3576054573059082
Batch 2/64 loss: 0.3558494448661804
Batch 3/64 loss: 0.3568173050880432
Batch 4/64 loss: 0.35344094038009644
Batch 5/64 loss: 0.3582378625869751
Batch 6/64 loss: 0.35599005222320557
Batch 7/64 loss: 0.35566627979278564
Batch 8/64 loss: 0.35481345653533936
Batch 9/64 loss: 0.35705065727233887
Batch 10/64 loss: 0.3548198938369751
Batch 11/64 loss: 0.3576417565345764
Batch 12/64 loss: 0.3595525622367859
Batch 13/64 loss: 0.3550991415977478
Batch 14/64 loss: 0.359822154045105
Batch 15/64 loss: 0.3542519211769104
Batch 16/64 loss: 0.3589569330215454
Batch 17/64 loss: 0.3608751893043518
Batch 18/64 loss: 0.3559163808822632
Batch 19/64 loss: 0.3555062413215637
Batch 20/64 loss: 0.35679519176483154
Batch 21/64 loss: 0.35828697681427
Batch 22/64 loss: 0.36090558767318726
Batch 23/64 loss: 0.35652685165405273
Batch 24/64 loss: 0.35711729526519775
Batch 25/64 loss: 0.3630181550979614
Batch 26/64 loss: 0.35809266567230225
Batch 27/64 loss: 0.35905706882476807
Batch 28/64 loss: 0.361585795879364
Batch 29/64 loss: 0.3564414978027344
Batch 30/64 loss: 0.356215238571167
Batch 31/64 loss: 0.35908591747283936
Batch 32/64 loss: 0.3592529892921448
Batch 33/64 loss: 0.359285831451416
Batch 34/64 loss: 0.35555779933929443
Batch 35/64 loss: 0.36265748739242554
Batch 36/64 loss: 0.35592120885849
Batch 37/64 loss: 0.3634292483329773
Batch 38/64 loss: 0.3590332269668579
Batch 39/64 loss: 0.3591254949569702
Batch 40/64 loss: 0.362274169921875
Batch 41/64 loss: 0.3556244373321533
Batch 42/64 loss: 0.3612300753593445
Batch 43/64 loss: 0.3581700325012207
Batch 44/64 loss: 0.3586137890815735
Batch 45/64 loss: 0.3568558692932129
Batch 46/64 loss: 0.3575217127799988
Batch 47/64 loss: 0.35945791006088257
Batch 48/64 loss: 0.35843825340270996
Batch 49/64 loss: 0.35970818996429443
Batch 50/64 loss: 0.35594236850738525
Batch 51/64 loss: 0.3572070002555847
Batch 52/64 loss: 0.35719919204711914
Batch 53/64 loss: 0.3573669195175171
Batch 54/64 loss: 0.3558741807937622
Batch 55/64 loss: 0.3586422801017761
Batch 56/64 loss: 0.35725367069244385
Batch 57/64 loss: 0.35744357109069824
Batch 58/64 loss: 0.3550559878349304
Batch 59/64 loss: 0.3562518358230591
Batch 60/64 loss: 0.35755449533462524
Batch 61/64 loss: 0.3601006269454956
Batch 62/64 loss: 0.35548388957977295
Batch 63/64 loss: 0.3563787341117859
Batch 64/64 loss: 0.35518181324005127
Epoch 65  Train loss: 0.35776220723694446  Val loss: 0.35961261115123316
Saving best model, epoch: 65
Epoch 66
-------------------------------
Batch 1/64 loss: 0.353132426738739
Batch 2/64 loss: 0.35730236768722534
Batch 3/64 loss: 0.3591526746749878
Batch 4/64 loss: 0.3545798063278198
Batch 5/64 loss: 0.3553858995437622
Batch 6/64 loss: 0.3620845675468445
Batch 7/64 loss: 0.3593176603317261
Batch 8/64 loss: 0.3567962646484375
Batch 9/64 loss: 0.3549478054046631
Batch 10/64 loss: 0.3581913709640503
Batch 11/64 loss: 0.3582269549369812
Batch 12/64 loss: 0.35894834995269775
Batch 13/64 loss: 0.3611443042755127
Batch 14/64 loss: 0.3571420907974243
Batch 15/64 loss: 0.3605778217315674
Batch 16/64 loss: 0.35948455333709717
Batch 17/64 loss: 0.3533966541290283
Batch 18/64 loss: 0.3588358163833618
Batch 19/64 loss: 0.35604822635650635
Batch 20/64 loss: 0.3576620817184448
Batch 21/64 loss: 0.35545945167541504
Batch 22/64 loss: 0.3580958843231201
Batch 23/64 loss: 0.3559044599533081
Batch 24/64 loss: 0.3564502000808716
Batch 25/64 loss: 0.3590785264968872
Batch 26/64 loss: 0.35663485527038574
Batch 27/64 loss: 0.3570094108581543
Batch 28/64 loss: 0.3563939929008484
Batch 29/64 loss: 0.3573606610298157
Batch 30/64 loss: 0.3581850528717041
Batch 31/64 loss: 0.36024653911590576
Batch 32/64 loss: 0.3572161793708801
Batch 33/64 loss: 0.35660743713378906
Batch 34/64 loss: 0.35714125633239746
Batch 35/64 loss: 0.35919052362442017
Batch 36/64 loss: 0.3640202283859253
Batch 37/64 loss: 0.35687077045440674
Batch 38/64 loss: 0.3582010269165039
Batch 39/64 loss: 0.35802358388900757
Batch 40/64 loss: 0.35794758796691895
Batch 41/64 loss: 0.35910511016845703
Batch 42/64 loss: 0.3542930483818054
Batch 43/64 loss: 0.3585096597671509
Batch 44/64 loss: 0.36102330684661865
Batch 45/64 loss: 0.3613538146018982
Batch 46/64 loss: 0.36153292655944824
Batch 47/64 loss: 0.3601982593536377
Batch 48/64 loss: 0.35515761375427246
Batch 49/64 loss: 0.3562588691711426
Batch 50/64 loss: 0.35346150398254395
Batch 51/64 loss: 0.35991013050079346
Batch 52/64 loss: 0.35672318935394287
Batch 53/64 loss: 0.35721397399902344
Batch 54/64 loss: 0.35995298624038696
Batch 55/64 loss: 0.3579540252685547
Batch 56/64 loss: 0.3541417121887207
Batch 57/64 loss: 0.35528093576431274
Batch 58/64 loss: 0.3577190041542053
Batch 59/64 loss: 0.3589836359024048
Batch 60/64 loss: 0.35455870628356934
Batch 61/64 loss: 0.3545452952384949
Batch 62/64 loss: 0.357729971408844
Batch 63/64 loss: 0.36127251386642456
Batch 64/64 loss: 0.35765671730041504
Epoch 66  Train loss: 0.3577022440293256  Val loss: 0.3590697666623748
Saving best model, epoch: 66
Epoch 67
-------------------------------
Batch 1/64 loss: 0.35417449474334717
Batch 2/64 loss: 0.35723578929901123
Batch 3/64 loss: 0.35866600275039673
Batch 4/64 loss: 0.3572814464569092
Batch 5/64 loss: 0.35872960090637207
Batch 6/64 loss: 0.35694175958633423
Batch 7/64 loss: 0.35400891304016113
Batch 8/64 loss: 0.356456995010376
Batch 9/64 loss: 0.3575252294540405
Batch 10/64 loss: 0.3589431047439575
Batch 11/64 loss: 0.35992443561553955
Batch 12/64 loss: 0.356961190700531
Batch 13/64 loss: 0.3590098023414612
Batch 14/64 loss: 0.36042672395706177
Batch 15/64 loss: 0.35546958446502686
Batch 16/64 loss: 0.3577232360839844
Batch 17/64 loss: 0.35765671730041504
Batch 18/64 loss: 0.3562750816345215
Batch 19/64 loss: 0.3550605773925781
Batch 20/64 loss: 0.3597750663757324
Batch 21/64 loss: 0.35733360052108765
Batch 22/64 loss: 0.35632145404815674
Batch 23/64 loss: 0.3596150875091553
Batch 24/64 loss: 0.3590545058250427
Batch 25/64 loss: 0.3549773693084717
Batch 26/64 loss: 0.3556119203567505
Batch 27/64 loss: 0.36240947246551514
Batch 28/64 loss: 0.3579080104827881
Batch 29/64 loss: 0.3569985628128052
Batch 30/64 loss: 0.3564716577529907
Batch 31/64 loss: 0.3568597435951233
Batch 32/64 loss: 0.3591359853744507
Batch 33/64 loss: 0.36028528213500977
Batch 34/64 loss: 0.3588930368423462
Batch 35/64 loss: 0.35612791776657104
Batch 36/64 loss: 0.3579186797142029
Batch 37/64 loss: 0.352733314037323
Batch 38/64 loss: 0.3581138849258423
Batch 39/64 loss: 0.35478490591049194
Batch 40/64 loss: 0.3579574227333069
Batch 41/64 loss: 0.35700738430023193
Batch 42/64 loss: 0.36070144176483154
Batch 43/64 loss: 0.35746943950653076
Batch 44/64 loss: 0.35551488399505615
Batch 45/64 loss: 0.3591965436935425
Batch 46/64 loss: 0.3563803434371948
Batch 47/64 loss: 0.35440653562545776
Batch 48/64 loss: 0.3593664765357971
Batch 49/64 loss: 0.358290433883667
Batch 50/64 loss: 0.3589820861816406
Batch 51/64 loss: 0.3586246967315674
Batch 52/64 loss: 0.35721707344055176
Batch 53/64 loss: 0.3589290380477905
Batch 54/64 loss: 0.3614615201950073
Batch 55/64 loss: 0.36020946502685547
Batch 56/64 loss: 0.3554103374481201
Batch 57/64 loss: 0.35938072204589844
Batch 58/64 loss: 0.35933101177215576
Batch 59/64 loss: 0.3572664260864258
Batch 60/64 loss: 0.354981005191803
Batch 61/64 loss: 0.3559749126434326
Batch 62/64 loss: 0.35705244541168213
Batch 63/64 loss: 0.3599364757537842
Batch 64/64 loss: 0.35703784227371216
Epoch 67  Train loss: 0.3576255160219529  Val loss: 0.35947973744566086
Epoch 68
-------------------------------
Batch 1/64 loss: 0.35811710357666016
Batch 2/64 loss: 0.3583011031150818
Batch 3/64 loss: 0.358437180519104
Batch 4/64 loss: 0.35587871074676514
Batch 5/64 loss: 0.3539518117904663
Batch 6/64 loss: 0.3593301773071289
Batch 7/64 loss: 0.3541327118873596
Batch 8/64 loss: 0.3587031960487366
Batch 9/64 loss: 0.3589490056037903
Batch 10/64 loss: 0.359205961227417
Batch 11/64 loss: 0.35748445987701416
Batch 12/64 loss: 0.35731756687164307
Batch 13/64 loss: 0.35790979862213135
Batch 14/64 loss: 0.3563527464866638
Batch 15/64 loss: 0.3621658682823181
Batch 16/64 loss: 0.35783839225769043
Batch 17/64 loss: 0.3531559109687805
Batch 18/64 loss: 0.35514700412750244
Batch 19/64 loss: 0.3582974076271057
Batch 20/64 loss: 0.3528291583061218
Batch 21/64 loss: 0.3564385771751404
Batch 22/64 loss: 0.3619638681411743
Batch 23/64 loss: 0.3574618697166443
Batch 24/64 loss: 0.3596174120903015
Batch 25/64 loss: 0.35729753971099854
Batch 26/64 loss: 0.35772693157196045
Batch 27/64 loss: 0.35772907733917236
Batch 28/64 loss: 0.35745179653167725
Batch 29/64 loss: 0.3579012155532837
Batch 30/64 loss: 0.3564786911010742
Batch 31/64 loss: 0.35499417781829834
Batch 32/64 loss: 0.35494357347488403
Batch 33/64 loss: 0.35845494270324707
Batch 34/64 loss: 0.35904765129089355
Batch 35/64 loss: 0.35433894395828247
Batch 36/64 loss: 0.3554244041442871
Batch 37/64 loss: 0.36071157455444336
Batch 38/64 loss: 0.35708820819854736
Batch 39/64 loss: 0.36073970794677734
Batch 40/64 loss: 0.3591357469558716
Batch 41/64 loss: 0.35691171884536743
Batch 42/64 loss: 0.35694146156311035
Batch 43/64 loss: 0.357826828956604
Batch 44/64 loss: 0.3587998151779175
Batch 45/64 loss: 0.36161744594573975
Batch 46/64 loss: 0.36035704612731934
Batch 47/64 loss: 0.35767412185668945
Batch 48/64 loss: 0.3591785430908203
Batch 49/64 loss: 0.35981231927871704
Batch 50/64 loss: 0.36122065782546997
Batch 51/64 loss: 0.35641247034072876
Batch 52/64 loss: 0.35595810413360596
Batch 53/64 loss: 0.3582230806350708
Batch 54/64 loss: 0.35388827323913574
Batch 55/64 loss: 0.3578786849975586
Batch 56/64 loss: 0.3548746109008789
Batch 57/64 loss: 0.3544677495956421
Batch 58/64 loss: 0.35971808433532715
Batch 59/64 loss: 0.36131083965301514
Batch 60/64 loss: 0.35640281438827515
Batch 61/64 loss: 0.3568601608276367
Batch 62/64 loss: 0.35982370376586914
Batch 63/64 loss: 0.35756564140319824
Batch 64/64 loss: 0.35759639739990234
Epoch 68  Train loss: 0.35765290447309905  Val loss: 0.3602196936754836
Epoch 69
-------------------------------
Batch 1/64 loss: 0.3555351495742798
Batch 2/64 loss: 0.3549119830131531
Batch 3/64 loss: 0.35612952709198
Batch 4/64 loss: 0.35747992992401123
Batch 5/64 loss: 0.35658323764801025
Batch 6/64 loss: 0.3599311113357544
Batch 7/64 loss: 0.35354793071746826
Batch 8/64 loss: 0.35516196489334106
Batch 9/64 loss: 0.35782432556152344
Batch 10/64 loss: 0.3560549020767212
Batch 11/64 loss: 0.35542118549346924
Batch 12/64 loss: 0.3570437431335449
Batch 13/64 loss: 0.358726441860199
Batch 14/64 loss: 0.3587452173233032
Batch 15/64 loss: 0.35697734355926514
Batch 16/64 loss: 0.35981738567352295
Batch 17/64 loss: 0.3569311499595642
Batch 18/64 loss: 0.3559557795524597
Batch 19/64 loss: 0.3586454391479492
Batch 20/64 loss: 0.3622109889984131
Batch 21/64 loss: 0.3556816577911377
Batch 22/64 loss: 0.36010611057281494
Batch 23/64 loss: 0.3607179522514343
Batch 24/64 loss: 0.3548903465270996
Batch 25/64 loss: 0.3588799238204956
Batch 26/64 loss: 0.35929036140441895
Batch 27/64 loss: 0.3570407032966614
Batch 28/64 loss: 0.3543573021888733
Batch 29/64 loss: 0.35708796977996826
Batch 30/64 loss: 0.35824286937713623
Batch 31/64 loss: 0.36185336112976074
Batch 32/64 loss: 0.3604191541671753
Batch 33/64 loss: 0.35854846239089966
Batch 34/64 loss: 0.3585466146469116
Batch 35/64 loss: 0.35891973972320557
Batch 36/64 loss: 0.35654622316360474
Batch 37/64 loss: 0.35537129640579224
Batch 38/64 loss: 0.35867273807525635
Batch 39/64 loss: 0.3564440608024597
Batch 40/64 loss: 0.35790789127349854
Batch 41/64 loss: 0.3567226529121399
Batch 42/64 loss: 0.35562455654144287
Batch 43/64 loss: 0.36019784212112427
Batch 44/64 loss: 0.3576643466949463
Batch 45/64 loss: 0.358586847782135
Batch 46/64 loss: 0.35956668853759766
Batch 47/64 loss: 0.35778868198394775
Batch 48/64 loss: 0.3632258176803589
Batch 49/64 loss: 0.3583451509475708
Batch 50/64 loss: 0.358622670173645
Batch 51/64 loss: 0.35600370168685913
Batch 52/64 loss: 0.3577512502670288
Batch 53/64 loss: 0.35837113857269287
Batch 54/64 loss: 0.3555114269256592
Batch 55/64 loss: 0.3559643030166626
Batch 56/64 loss: 0.35645270347595215
Batch 57/64 loss: 0.3564082384109497
Batch 58/64 loss: 0.35604822635650635
Batch 59/64 loss: 0.3594643473625183
Batch 60/64 loss: 0.35647833347320557
Batch 61/64 loss: 0.35904985666275024
Batch 62/64 loss: 0.3545881509780884
Batch 63/64 loss: 0.361763596534729
Batch 64/64 loss: 0.35864782333374023
Epoch 69  Train loss: 0.35768385681451537  Val loss: 0.3593313120484762
Epoch 70
-------------------------------
Batch 1/64 loss: 0.35723215341567993
Batch 2/64 loss: 0.35810399055480957
Batch 3/64 loss: 0.35512471199035645
Batch 4/64 loss: 0.3540647029876709
Batch 5/64 loss: 0.3569720983505249
Batch 6/64 loss: 0.3584432601928711
Batch 7/64 loss: 0.3577989339828491
Batch 8/64 loss: 0.35909396409988403
Batch 9/64 loss: 0.35972511768341064
Batch 10/64 loss: 0.3557248115539551
Batch 11/64 loss: 0.3576090335845947
Batch 12/64 loss: 0.35628581047058105
Batch 13/64 loss: 0.35931718349456787
Batch 14/64 loss: 0.3500949740409851
Batch 15/64 loss: 0.35519111156463623
Batch 16/64 loss: 0.3557242155075073
Batch 17/64 loss: 0.35458433628082275
Batch 18/64 loss: 0.35535693168640137
Batch 19/64 loss: 0.3570209741592407
Batch 20/64 loss: 0.35894572734832764
Batch 21/64 loss: 0.3591653108596802
Batch 22/64 loss: 0.35854780673980713
Batch 23/64 loss: 0.3586663603782654
Batch 24/64 loss: 0.3572627305984497
Batch 25/64 loss: 0.3579777479171753
Batch 26/64 loss: 0.3549795150756836
Batch 27/64 loss: 0.3563106656074524
Batch 28/64 loss: 0.3578394651412964
Batch 29/64 loss: 0.3591252565383911
Batch 30/64 loss: 0.3537576198577881
Batch 31/64 loss: 0.35434943437576294
Batch 32/64 loss: 0.3544267416000366
Batch 33/64 loss: 0.35886502265930176
Batch 34/64 loss: 0.3580894470214844
Batch 35/64 loss: 0.35513293743133545
Batch 36/64 loss: 0.35648447275161743
Batch 37/64 loss: 0.3589271306991577
Batch 38/64 loss: 0.3602878451347351
Batch 39/64 loss: 0.3576892614364624
Batch 40/64 loss: 0.35943758487701416
Batch 41/64 loss: 0.35686570405960083
Batch 42/64 loss: 0.36258000135421753
Batch 43/64 loss: 0.3551473617553711
Batch 44/64 loss: 0.35652804374694824
Batch 45/64 loss: 0.3580033779144287
Batch 46/64 loss: 0.3588012456893921
Batch 47/64 loss: 0.3570343255996704
Batch 48/64 loss: 0.3561875820159912
Batch 49/64 loss: 0.35732191801071167
Batch 50/64 loss: 0.3586251735687256
Batch 51/64 loss: 0.3559107184410095
Batch 52/64 loss: 0.3572225570678711
Batch 53/64 loss: 0.3564620614051819
Batch 54/64 loss: 0.3576470613479614
Batch 55/64 loss: 0.35869723558425903
Batch 56/64 loss: 0.35803544521331787
Batch 57/64 loss: 0.35772961378097534
Batch 58/64 loss: 0.35472726821899414
Batch 59/64 loss: 0.36333853006362915
Batch 60/64 loss: 0.35735857486724854
Batch 61/64 loss: 0.3553587794303894
Batch 62/64 loss: 0.35667675733566284
Batch 63/64 loss: 0.35726213455200195
Batch 64/64 loss: 0.3571973443031311
Epoch 70  Train loss: 0.357194602021984  Val loss: 0.3594523920226343
Epoch 71
-------------------------------
Batch 1/64 loss: 0.3605008125305176
Batch 2/64 loss: 0.3569042682647705
Batch 3/64 loss: 0.3567606210708618
Batch 4/64 loss: 0.3571964502334595
Batch 5/64 loss: 0.3552076816558838
Batch 6/64 loss: 0.35603129863739014
Batch 7/64 loss: 0.3555389642715454
Batch 8/64 loss: 0.35309308767318726
Batch 9/64 loss: 0.35320818424224854
Batch 10/64 loss: 0.35783469676971436
Batch 11/64 loss: 0.3560373783111572
Batch 12/64 loss: 0.35765552520751953
Batch 13/64 loss: 0.3561559319496155
Batch 14/64 loss: 0.35747402906417847
Batch 15/64 loss: 0.3536421060562134
Batch 16/64 loss: 0.3542356491088867
Batch 17/64 loss: 0.3608322739601135
Batch 18/64 loss: 0.3555154800415039
Batch 19/64 loss: 0.3604177236557007
Batch 20/64 loss: 0.35416340827941895
Batch 21/64 loss: 0.3558197021484375
Batch 22/64 loss: 0.3580317497253418
Batch 23/64 loss: 0.3587632179260254
Batch 24/64 loss: 0.3580820560455322
Batch 25/64 loss: 0.35403043031692505
Batch 26/64 loss: 0.3545408844947815
Batch 27/64 loss: 0.3549689054489136
Batch 28/64 loss: 0.3561375141143799
Batch 29/64 loss: 0.3574913740158081
Batch 30/64 loss: 0.35851091146469116
Batch 31/64 loss: 0.35846763849258423
Batch 32/64 loss: 0.3573700189590454
Batch 33/64 loss: 0.35447245836257935
Batch 34/64 loss: 0.36334049701690674
Batch 35/64 loss: 0.3565342426300049
Batch 36/64 loss: 0.354636013507843
Batch 37/64 loss: 0.35722899436950684
Batch 38/64 loss: 0.3587126135826111
Batch 39/64 loss: 0.3540183901786804
Batch 40/64 loss: 0.35874056816101074
Batch 41/64 loss: 0.35585081577301025
Batch 42/64 loss: 0.3586348295211792
Batch 43/64 loss: 0.35900890827178955
Batch 44/64 loss: 0.35705864429473877
Batch 45/64 loss: 0.35772764682769775
Batch 46/64 loss: 0.35908782482147217
Batch 47/64 loss: 0.35708320140838623
Batch 48/64 loss: 0.355951189994812
Batch 49/64 loss: 0.35708796977996826
Batch 50/64 loss: 0.35532522201538086
Batch 51/64 loss: 0.35595089197158813
Batch 52/64 loss: 0.3567512631416321
Batch 53/64 loss: 0.35928797721862793
Batch 54/64 loss: 0.3518991470336914
Batch 55/64 loss: 0.35689204931259155
Batch 56/64 loss: 0.35875487327575684
Batch 57/64 loss: 0.35761845111846924
Batch 58/64 loss: 0.3580666780471802
Batch 59/64 loss: 0.35941946506500244
Batch 60/64 loss: 0.3580235242843628
Batch 61/64 loss: 0.36210834980010986
Batch 62/64 loss: 0.3587300777435303
Batch 63/64 loss: 0.35350990295410156
Batch 64/64 loss: 0.35538995265960693
Epoch 71  Train loss: 0.3569360803155338  Val loss: 0.3594204211972423
Epoch 72
-------------------------------
Batch 1/64 loss: 0.3571290969848633
Batch 2/64 loss: 0.3597681522369385
Batch 3/64 loss: 0.35633593797683716
Batch 4/64 loss: 0.3529052138328552
Batch 5/64 loss: 0.3571587800979614
Batch 6/64 loss: 0.36019474267959595
Batch 7/64 loss: 0.3577369451522827
Batch 8/64 loss: 0.3610262870788574
Batch 9/64 loss: 0.35552912950515747
Batch 10/64 loss: 0.3537536859512329
Batch 11/64 loss: 0.35514044761657715
Batch 12/64 loss: 0.35860925912857056
Batch 13/64 loss: 0.36083829402923584
Batch 14/64 loss: 0.35757148265838623
Batch 15/64 loss: 0.35989391803741455
Batch 16/64 loss: 0.35744988918304443
Batch 17/64 loss: 0.35332822799682617
Batch 18/64 loss: 0.3585153818130493
Batch 19/64 loss: 0.3590404987335205
Batch 20/64 loss: 0.3566969037055969
Batch 21/64 loss: 0.3580615520477295
Batch 22/64 loss: 0.3599840998649597
Batch 23/64 loss: 0.3545910120010376
Batch 24/64 loss: 0.35491859912872314
Batch 25/64 loss: 0.35801053047180176
Batch 26/64 loss: 0.35832083225250244
Batch 27/64 loss: 0.3554943799972534
Batch 28/64 loss: 0.3588661551475525
Batch 29/64 loss: 0.35601431131362915
Batch 30/64 loss: 0.3588230609893799
Batch 31/64 loss: 0.3570070266723633
Batch 32/64 loss: 0.3583762049674988
Batch 33/64 loss: 0.3576836585998535
Batch 34/64 loss: 0.35698163509368896
Batch 35/64 loss: 0.3572373390197754
Batch 36/64 loss: 0.3559161424636841
Batch 37/64 loss: 0.35464346408843994
Batch 38/64 loss: 0.3485220670700073
Batch 39/64 loss: 0.3602827787399292
Batch 40/64 loss: 0.35739409923553467
Batch 41/64 loss: 0.3561859726905823
Batch 42/64 loss: 0.3569275736808777
Batch 43/64 loss: 0.35220181941986084
Batch 44/64 loss: 0.35649824142456055
Batch 45/64 loss: 0.36214518547058105
Batch 46/64 loss: 0.35707956552505493
Batch 47/64 loss: 0.36208176612854004
Batch 48/64 loss: 0.35352563858032227
Batch 49/64 loss: 0.35643672943115234
Batch 50/64 loss: 0.35768377780914307
Batch 51/64 loss: 0.3598285913467407
Batch 52/64 loss: 0.3578454256057739
Batch 53/64 loss: 0.35437917709350586
Batch 54/64 loss: 0.3561687469482422
Batch 55/64 loss: 0.3593514561653137
Batch 56/64 loss: 0.35576438903808594
Batch 57/64 loss: 0.356769323348999
Batch 58/64 loss: 0.3561871647834778
Batch 59/64 loss: 0.35480761528015137
Batch 60/64 loss: 0.35802650451660156
Batch 61/64 loss: 0.35843992233276367
Batch 62/64 loss: 0.35686856508255005
Batch 63/64 loss: 0.3552980422973633
Batch 64/64 loss: 0.35819268226623535
Epoch 72  Train loss: 0.35709642241982853  Val loss: 0.3586710605424704
Saving best model, epoch: 72
Epoch 73
-------------------------------
Batch 1/64 loss: 0.3540748357772827
Batch 2/64 loss: 0.3531111478805542
Batch 3/64 loss: 0.35965442657470703
Batch 4/64 loss: 0.35779786109924316
Batch 5/64 loss: 0.35699522495269775
Batch 6/64 loss: 0.35635989904403687
Batch 7/64 loss: 0.35944950580596924
Batch 8/64 loss: 0.358320415019989
Batch 9/64 loss: 0.35742998123168945
Batch 10/64 loss: 0.3557245135307312
Batch 11/64 loss: 0.35876643657684326
Batch 12/64 loss: 0.35424983501434326
Batch 13/64 loss: 0.3570183515548706
Batch 14/64 loss: 0.35810422897338867
Batch 15/64 loss: 0.3546891212463379
Batch 16/64 loss: 0.35145485401153564
Batch 17/64 loss: 0.35620319843292236
Batch 18/64 loss: 0.35608363151550293
Batch 19/64 loss: 0.3618139624595642
Batch 20/64 loss: 0.3567920923233032
Batch 21/64 loss: 0.35935235023498535
Batch 22/64 loss: 0.35503822565078735
Batch 23/64 loss: 0.35482466220855713
Batch 24/64 loss: 0.3582272529602051
Batch 25/64 loss: 0.3523045778274536
Batch 26/64 loss: 0.3578248620033264
Batch 27/64 loss: 0.351745069026947
Batch 28/64 loss: 0.3586881160736084
Batch 29/64 loss: 0.3507882356643677
Batch 30/64 loss: 0.35772067308425903
Batch 31/64 loss: 0.3593454957008362
Batch 32/64 loss: 0.3558778762817383
Batch 33/64 loss: 0.3591196537017822
Batch 34/64 loss: 0.36038994789123535
Batch 35/64 loss: 0.3618165850639343
Batch 36/64 loss: 0.35536015033721924
Batch 37/64 loss: 0.35857945680618286
Batch 38/64 loss: 0.3589019775390625
Batch 39/64 loss: 0.3590295910835266
Batch 40/64 loss: 0.35586297512054443
Batch 41/64 loss: 0.35463446378707886
Batch 42/64 loss: 0.3578062057495117
Batch 43/64 loss: 0.36043500900268555
Batch 44/64 loss: 0.3573575019836426
Batch 45/64 loss: 0.35662245750427246
Batch 46/64 loss: 0.3533822298049927
Batch 47/64 loss: 0.3545953035354614
Batch 48/64 loss: 0.35602128505706787
Batch 49/64 loss: 0.3575175404548645
Batch 50/64 loss: 0.35737454891204834
Batch 51/64 loss: 0.35650771856307983
Batch 52/64 loss: 0.35433441400527954
Batch 53/64 loss: 0.35593223571777344
Batch 54/64 loss: 0.3547513484954834
Batch 55/64 loss: 0.3578492999076843
Batch 56/64 loss: 0.35573041439056396
Batch 57/64 loss: 0.3600825071334839
Batch 58/64 loss: 0.3557471036911011
Batch 59/64 loss: 0.35593748092651367
Batch 60/64 loss: 0.35517752170562744
Batch 61/64 loss: 0.35405653715133667
Batch 62/64 loss: 0.3551919460296631
Batch 63/64 loss: 0.3554346561431885
Batch 64/64 loss: 0.3541761636734009
Epoch 73  Train loss: 0.35659612721087885  Val loss: 0.3589469868292923
Epoch 74
-------------------------------
Batch 1/64 loss: 0.3542550802230835
Batch 2/64 loss: 0.35748934745788574
Batch 3/64 loss: 0.361719012260437
Batch 4/64 loss: 0.3626740574836731
Batch 5/64 loss: 0.35156363248825073
Batch 6/64 loss: 0.3593558073043823
Batch 7/64 loss: 0.35351502895355225
Batch 8/64 loss: 0.3569161295890808
Batch 9/64 loss: 0.3574908971786499
Batch 10/64 loss: 0.3553246855735779
Batch 11/64 loss: 0.35497236251831055
Batch 12/64 loss: 0.3587214946746826
Batch 13/64 loss: 0.3533405065536499
Batch 14/64 loss: 0.35925740003585815
Batch 15/64 loss: 0.35395342111587524
Batch 16/64 loss: 0.35978245735168457
Batch 17/64 loss: 0.3572646379470825
Batch 18/64 loss: 0.3553905487060547
Batch 19/64 loss: 0.35933196544647217
Batch 20/64 loss: 0.35557377338409424
Batch 21/64 loss: 0.36059683561325073
Batch 22/64 loss: 0.3519630432128906
Batch 23/64 loss: 0.35432755947113037
Batch 24/64 loss: 0.35701310634613037
Batch 25/64 loss: 0.3603360056877136
Batch 26/64 loss: 0.36000651121139526
Batch 27/64 loss: 0.3550404906272888
Batch 28/64 loss: 0.35491466522216797
Batch 29/64 loss: 0.35473453998565674
Batch 30/64 loss: 0.3514751195907593
Batch 31/64 loss: 0.354824423789978
Batch 32/64 loss: 0.3541904091835022
Batch 33/64 loss: 0.3564254641532898
Batch 34/64 loss: 0.3579811453819275
Batch 35/64 loss: 0.3585197329521179
Batch 36/64 loss: 0.3533616065979004
Batch 37/64 loss: 0.35858869552612305
Batch 38/64 loss: 0.3559318780899048
Batch 39/64 loss: 0.35834574699401855
Batch 40/64 loss: 0.3556852340698242
Batch 41/64 loss: 0.3569185137748718
Batch 42/64 loss: 0.3536243438720703
Batch 43/64 loss: 0.3602440357208252
Batch 44/64 loss: 0.3575395345687866
Batch 45/64 loss: 0.3580259084701538
Batch 46/64 loss: 0.3549541234970093
Batch 47/64 loss: 0.35629165172576904
Batch 48/64 loss: 0.3599787950515747
Batch 49/64 loss: 0.35666680335998535
Batch 50/64 loss: 0.355812132358551
Batch 51/64 loss: 0.3574725389480591
Batch 52/64 loss: 0.3573032021522522
Batch 53/64 loss: 0.3618048429489136
Batch 54/64 loss: 0.35342836380004883
Batch 55/64 loss: 0.355751097202301
Batch 56/64 loss: 0.3542162775993347
Batch 57/64 loss: 0.3561275005340576
Batch 58/64 loss: 0.35438698530197144
Batch 59/64 loss: 0.3558804392814636
Batch 60/64 loss: 0.3565617799758911
Batch 61/64 loss: 0.35663902759552
Batch 62/64 loss: 0.35728365182876587
Batch 63/64 loss: 0.3587069511413574
Batch 64/64 loss: 0.35672879219055176
Epoch 74  Train loss: 0.35663246360479617  Val loss: 0.3589967698166051
Epoch 75
-------------------------------
Batch 1/64 loss: 0.3596915006637573
Batch 2/64 loss: 0.3575683832168579
Batch 3/64 loss: 0.35755646228790283
Batch 4/64 loss: 0.3560607433319092
Batch 5/64 loss: 0.3549000024795532
Batch 6/64 loss: 0.35540151596069336
Batch 7/64 loss: 0.35744166374206543
Batch 8/64 loss: 0.3580724000930786
Batch 9/64 loss: 0.35825300216674805
Batch 10/64 loss: 0.3580322265625
Batch 11/64 loss: 0.36100053787231445
Batch 12/64 loss: 0.35428386926651
Batch 13/64 loss: 0.3516247868537903
Batch 14/64 loss: 0.3570009469985962
Batch 15/64 loss: 0.3595907688140869
Batch 16/64 loss: 0.35042572021484375
Batch 17/64 loss: 0.3577076196670532
Batch 18/64 loss: 0.3593785762786865
Batch 19/64 loss: 0.3535292148590088
Batch 20/64 loss: 0.3604803681373596
Batch 21/64 loss: 0.3558182120323181
Batch 22/64 loss: 0.3543682098388672
Batch 23/64 loss: 0.3573187589645386
Batch 24/64 loss: 0.35237109661102295
Batch 25/64 loss: 0.35655832290649414
Batch 26/64 loss: 0.35181915760040283
Batch 27/64 loss: 0.35703325271606445
Batch 28/64 loss: 0.35909736156463623
Batch 29/64 loss: 0.35944414138793945
Batch 30/64 loss: 0.3589118719100952
Batch 31/64 loss: 0.3594677448272705
Batch 32/64 loss: 0.3608114719390869
Batch 33/64 loss: 0.3543112277984619
Batch 34/64 loss: 0.3575310707092285
Batch 35/64 loss: 0.35666215419769287
Batch 36/64 loss: 0.3569786548614502
Batch 37/64 loss: 0.3536558151245117
Batch 38/64 loss: 0.35718703269958496
Batch 39/64 loss: 0.3608645796775818
Batch 40/64 loss: 0.35422784090042114
Batch 41/64 loss: 0.35464751720428467
Batch 42/64 loss: 0.3554460406303406
Batch 43/64 loss: 0.3564292788505554
Batch 44/64 loss: 0.3589498996734619
Batch 45/64 loss: 0.3595317602157593
Batch 46/64 loss: 0.35255861282348633
Batch 47/64 loss: 0.3591269254684448
Batch 48/64 loss: 0.3555169105529785
Batch 49/64 loss: 0.3571785092353821
Batch 50/64 loss: 0.35638999938964844
Batch 51/64 loss: 0.3530689477920532
Batch 52/64 loss: 0.35747647285461426
Batch 53/64 loss: 0.35145294666290283
Batch 54/64 loss: 0.3531952500343323
Batch 55/64 loss: 0.35257893800735474
Batch 56/64 loss: 0.36010247468948364
Batch 57/64 loss: 0.3589681386947632
Batch 58/64 loss: 0.35274356603622437
Batch 59/64 loss: 0.3555091619491577
Batch 60/64 loss: 0.3597901463508606
Batch 61/64 loss: 0.36031484603881836
Batch 62/64 loss: 0.35404396057128906
Batch 63/64 loss: 0.35601645708084106
Batch 64/64 loss: 0.3567199110984802
Epoch 75  Train loss: 0.35656494089201385  Val loss: 0.3589315541421425
Epoch 76
-------------------------------
Batch 1/64 loss: 0.35745084285736084
Batch 2/64 loss: 0.355541467666626
Batch 3/64 loss: 0.3579903244972229
Batch 4/64 loss: 0.35471874475479126
Batch 5/64 loss: 0.35327965021133423
Batch 6/64 loss: 0.35924339294433594
Batch 7/64 loss: 0.35807597637176514
Batch 8/64 loss: 0.3541722297668457
Batch 9/64 loss: 0.35613691806793213
Batch 10/64 loss: 0.35328662395477295
Batch 11/64 loss: 0.3526992201805115
Batch 12/64 loss: 0.35361993312835693
Batch 13/64 loss: 0.36020761728286743
Batch 14/64 loss: 0.3543459177017212
Batch 15/64 loss: 0.35107362270355225
Batch 16/64 loss: 0.35334861278533936
Batch 17/64 loss: 0.35577207803726196
Batch 18/64 loss: 0.3589155673980713
Batch 19/64 loss: 0.36088842153549194
Batch 20/64 loss: 0.3576868772506714
Batch 21/64 loss: 0.3582891821861267
Batch 22/64 loss: 0.35648322105407715
Batch 23/64 loss: 0.3563074469566345
Batch 24/64 loss: 0.35345369577407837
Batch 25/64 loss: 0.354350745677948
Batch 26/64 loss: 0.35612666606903076
Batch 27/64 loss: 0.35549086332321167
Batch 28/64 loss: 0.35444724559783936
Batch 29/64 loss: 0.3567788600921631
Batch 30/64 loss: 0.3561611771583557
Batch 31/64 loss: 0.35636305809020996
Batch 32/64 loss: 0.3537102937698364
Batch 33/64 loss: 0.3593571186065674
Batch 34/64 loss: 0.3571584224700928
Batch 35/64 loss: 0.3509669303894043
Batch 36/64 loss: 0.3573075532913208
Batch 37/64 loss: 0.35673975944519043
Batch 38/64 loss: 0.355588436126709
Batch 39/64 loss: 0.3579540252685547
Batch 40/64 loss: 0.3581186532974243
Batch 41/64 loss: 0.3556516170501709
Batch 42/64 loss: 0.3565542697906494
Batch 43/64 loss: 0.35764187574386597
Batch 44/64 loss: 0.35783910751342773
Batch 45/64 loss: 0.3576192855834961
Batch 46/64 loss: 0.3536956310272217
Batch 47/64 loss: 0.35888010263442993
Batch 48/64 loss: 0.3577662706375122
Batch 49/64 loss: 0.356056809425354
Batch 50/64 loss: 0.35455209016799927
Batch 51/64 loss: 0.35866236686706543
Batch 52/64 loss: 0.35907816886901855
Batch 53/64 loss: 0.3587755560874939
Batch 54/64 loss: 0.35629022121429443
Batch 55/64 loss: 0.3596402406692505
Batch 56/64 loss: 0.3582960367202759
Batch 57/64 loss: 0.35958564281463623
Batch 58/64 loss: 0.35719728469848633
Batch 59/64 loss: 0.35534948110580444
Batch 60/64 loss: 0.3577920198440552
Batch 61/64 loss: 0.3567695617675781
Batch 62/64 loss: 0.357124924659729
Batch 63/64 loss: 0.35942912101745605
Batch 64/64 loss: 0.3600708246231079
Epoch 76  Train loss: 0.35654757957832484  Val loss: 0.3592433771726602
Epoch 77
-------------------------------
Batch 1/64 loss: 0.3566164970397949
Batch 2/64 loss: 0.35861390829086304
Batch 3/64 loss: 0.3552848696708679
Batch 4/64 loss: 0.35196757316589355
Batch 5/64 loss: 0.353939414024353
Batch 6/64 loss: 0.35939228534698486
Batch 7/64 loss: 0.3533172607421875
Batch 8/64 loss: 0.35653066635131836
Batch 9/64 loss: 0.3545691967010498
Batch 10/64 loss: 0.3578416705131531
Batch 11/64 loss: 0.3589654564857483
Batch 12/64 loss: 0.35808873176574707
Batch 13/64 loss: 0.3590872883796692
Batch 14/64 loss: 0.35447633266448975
Batch 15/64 loss: 0.3531150221824646
Batch 16/64 loss: 0.3573179244995117
Batch 17/64 loss: 0.35501599311828613
Batch 18/64 loss: 0.3562147617340088
Batch 19/64 loss: 0.3549957275390625
Batch 20/64 loss: 0.35649049282073975
Batch 21/64 loss: 0.35585200786590576
Batch 22/64 loss: 0.3564569354057312
Batch 23/64 loss: 0.3591890335083008
Batch 24/64 loss: 0.3546558618545532
Batch 25/64 loss: 0.3578720688819885
Batch 26/64 loss: 0.3586500883102417
Batch 27/64 loss: 0.3567954897880554
Batch 28/64 loss: 0.3559591770172119
Batch 29/64 loss: 0.3577471971511841
Batch 30/64 loss: 0.35628432035446167
Batch 31/64 loss: 0.3532782793045044
Batch 32/64 loss: 0.3577234745025635
Batch 33/64 loss: 0.3539927005767822
Batch 34/64 loss: 0.3550093173980713
Batch 35/64 loss: 0.36002111434936523
Batch 36/64 loss: 0.35820770263671875
Batch 37/64 loss: 0.35461127758026123
Batch 38/64 loss: 0.35550200939178467
Batch 39/64 loss: 0.3531874418258667
Batch 40/64 loss: 0.3527182340621948
Batch 41/64 loss: 0.3561103343963623
Batch 42/64 loss: 0.3567901849746704
Batch 43/64 loss: 0.3568907380104065
Batch 44/64 loss: 0.35748201608657837
Batch 45/64 loss: 0.35433030128479004
Batch 46/64 loss: 0.35679948329925537
Batch 47/64 loss: 0.3544241786003113
Batch 48/64 loss: 0.3582538962364197
Batch 49/64 loss: 0.35708367824554443
Batch 50/64 loss: 0.36018896102905273
Batch 51/64 loss: 0.36197710037231445
Batch 52/64 loss: 0.3588751554489136
Batch 53/64 loss: 0.3569692373275757
Batch 54/64 loss: 0.35072416067123413
Batch 55/64 loss: 0.3558380603790283
Batch 56/64 loss: 0.36073553562164307
Batch 57/64 loss: 0.3542914390563965
Batch 58/64 loss: 0.3558056354522705
Batch 59/64 loss: 0.35840994119644165
Batch 60/64 loss: 0.3540040850639343
Batch 61/64 loss: 0.3558136224746704
Batch 62/64 loss: 0.3597543239593506
Batch 63/64 loss: 0.3568565249443054
Batch 64/64 loss: 0.3625413179397583
Epoch 77  Train loss: 0.35648422568452126  Val loss: 0.35894332554741826
Epoch 78
-------------------------------
Batch 1/64 loss: 0.3506326675415039
Batch 2/64 loss: 0.3540302515029907
Batch 3/64 loss: 0.3592270016670227
Batch 4/64 loss: 0.3551797866821289
Batch 5/64 loss: 0.35344600677490234
Batch 6/64 loss: 0.35659360885620117
Batch 7/64 loss: 0.35785937309265137
Batch 8/64 loss: 0.3549760580062866
Batch 9/64 loss: 0.3574784994125366
Batch 10/64 loss: 0.35678744316101074
Batch 11/64 loss: 0.35343337059020996
Batch 12/64 loss: 0.3584839105606079
Batch 13/64 loss: 0.36258554458618164
Batch 14/64 loss: 0.3558053970336914
Batch 15/64 loss: 0.3556186556816101
Batch 16/64 loss: 0.35785579681396484
Batch 17/64 loss: 0.35609930753707886
Batch 18/64 loss: 0.3548962473869324
Batch 19/64 loss: 0.3553592562675476
Batch 20/64 loss: 0.35720300674438477
Batch 21/64 loss: 0.3548600673675537
Batch 22/64 loss: 0.35746443271636963
Batch 23/64 loss: 0.35894227027893066
Batch 24/64 loss: 0.35685300827026367
Batch 25/64 loss: 0.3578189015388489
Batch 26/64 loss: 0.3581503629684448
Batch 27/64 loss: 0.3564683794975281
Batch 28/64 loss: 0.3593592047691345
Batch 29/64 loss: 0.3567219376564026
Batch 30/64 loss: 0.35616183280944824
Batch 31/64 loss: 0.3626578450202942
Batch 32/64 loss: 0.35806357860565186
Batch 33/64 loss: 0.3565525412559509
Batch 34/64 loss: 0.3595472574234009
Batch 35/64 loss: 0.35103678703308105
Batch 36/64 loss: 0.35501182079315186
Batch 37/64 loss: 0.3577084541320801
Batch 38/64 loss: 0.35384535789489746
Batch 39/64 loss: 0.3525756597518921
Batch 40/64 loss: 0.3517889976501465
Batch 41/64 loss: 0.3551909923553467
Batch 42/64 loss: 0.3552809953689575
Batch 43/64 loss: 0.35745370388031006
Batch 44/64 loss: 0.3564871549606323
Batch 45/64 loss: 0.3561776876449585
Batch 46/64 loss: 0.3567863702774048
Batch 47/64 loss: 0.3548913598060608
Batch 48/64 loss: 0.35322922468185425
Batch 49/64 loss: 0.355735182762146
Batch 50/64 loss: 0.35730695724487305
Batch 51/64 loss: 0.35739099979400635
Batch 52/64 loss: 0.36015188694000244
Batch 53/64 loss: 0.35294175148010254
Batch 54/64 loss: 0.3522410988807678
Batch 55/64 loss: 0.3565882444381714
Batch 56/64 loss: 0.3601785898208618
Batch 57/64 loss: 0.35639601945877075
Batch 58/64 loss: 0.35911619663238525
Batch 59/64 loss: 0.35527104139328003
Batch 60/64 loss: 0.35596615076065063
Batch 61/64 loss: 0.35401248931884766
Batch 62/64 loss: 0.3542553782463074
Batch 63/64 loss: 0.35200512409210205
Batch 64/64 loss: 0.3559831380844116
Epoch 78  Train loss: 0.3561910877040788  Val loss: 0.357927601771666
Saving best model, epoch: 78
Epoch 79
-------------------------------
Batch 1/64 loss: 0.3533427119255066
Batch 2/64 loss: 0.3531680703163147
Batch 3/64 loss: 0.3547908663749695
Batch 4/64 loss: 0.35667479038238525
Batch 5/64 loss: 0.35647475719451904
Batch 6/64 loss: 0.3561810851097107
Batch 7/64 loss: 0.3540780544281006
Batch 8/64 loss: 0.36186325550079346
Batch 9/64 loss: 0.35513395071029663
Batch 10/64 loss: 0.35444068908691406
Batch 11/64 loss: 0.3543654680252075
Batch 12/64 loss: 0.35184597969055176
Batch 13/64 loss: 0.3559163212776184
Batch 14/64 loss: 0.3567030429840088
Batch 15/64 loss: 0.3568427562713623
Batch 16/64 loss: 0.3536489009857178
Batch 17/64 loss: 0.3537682890892029
Batch 18/64 loss: 0.3591405153274536
Batch 19/64 loss: 0.35888993740081787
Batch 20/64 loss: 0.35713183879852295
Batch 21/64 loss: 0.35203635692596436
Batch 22/64 loss: 0.3579394221305847
Batch 23/64 loss: 0.3576263189315796
Batch 24/64 loss: 0.3571040630340576
Batch 25/64 loss: 0.35374873876571655
Batch 26/64 loss: 0.35829782485961914
Batch 27/64 loss: 0.35689210891723633
Batch 28/64 loss: 0.35501742362976074
Batch 29/64 loss: 0.3575204610824585
Batch 30/64 loss: 0.3559117913246155
Batch 31/64 loss: 0.35291290283203125
Batch 32/64 loss: 0.3567148447036743
Batch 33/64 loss: 0.35240286588668823
Batch 34/64 loss: 0.35369086265563965
Batch 35/64 loss: 0.3574369549751282
Batch 36/64 loss: 0.353307843208313
Batch 37/64 loss: 0.35344040393829346
Batch 38/64 loss: 0.3558494448661804
Batch 39/64 loss: 0.3567569851875305
Batch 40/64 loss: 0.3575195074081421
Batch 41/64 loss: 0.3535032272338867
Batch 42/64 loss: 0.35567808151245117
Batch 43/64 loss: 0.35943710803985596
Batch 44/64 loss: 0.35786426067352295
Batch 45/64 loss: 0.35354602336883545
Batch 46/64 loss: 0.35552656650543213
Batch 47/64 loss: 0.35429662466049194
Batch 48/64 loss: 0.35598742961883545
Batch 49/64 loss: 0.35729384422302246
Batch 50/64 loss: 0.3570413589477539
Batch 51/64 loss: 0.35471081733703613
Batch 52/64 loss: 0.35979723930358887
Batch 53/64 loss: 0.357890248298645
Batch 54/64 loss: 0.35727381706237793
Batch 55/64 loss: 0.35412585735321045
Batch 56/64 loss: 0.3543893098831177
Batch 57/64 loss: 0.35455119609832764
Batch 58/64 loss: 0.3545088768005371
Batch 59/64 loss: 0.358537495136261
Batch 60/64 loss: 0.35923272371292114
Batch 61/64 loss: 0.35355859994888306
Batch 62/64 loss: 0.35651302337646484
Batch 63/64 loss: 0.35856688022613525
Batch 64/64 loss: 0.3546243906021118
Epoch 79  Train loss: 0.35586395777908025  Val loss: 0.35862298110096724
Epoch 80
-------------------------------
Batch 1/64 loss: 0.35524076223373413
Batch 2/64 loss: 0.3589724898338318
Batch 3/64 loss: 0.3565285801887512
Batch 4/64 loss: 0.35699546337127686
Batch 5/64 loss: 0.3553832769393921
Batch 6/64 loss: 0.35912489891052246
Batch 7/64 loss: 0.3551045060157776
Batch 8/64 loss: 0.3545999526977539
Batch 9/64 loss: 0.35727500915527344
Batch 10/64 loss: 0.3572579622268677
Batch 11/64 loss: 0.3532527685165405
Batch 12/64 loss: 0.3536835312843323
Batch 13/64 loss: 0.3531901240348816
Batch 14/64 loss: 0.3547447919845581
Batch 15/64 loss: 0.3574029207229614
Batch 16/64 loss: 0.3521233797073364
Batch 17/64 loss: 0.3562222719192505
Batch 18/64 loss: 0.35822612047195435
Batch 19/64 loss: 0.3559468388557434
Batch 20/64 loss: 0.353515625
Batch 21/64 loss: 0.356329083442688
Batch 22/64 loss: 0.3527872562408447
Batch 23/64 loss: 0.3574602007865906
Batch 24/64 loss: 0.3522735834121704
Batch 25/64 loss: 0.3526381254196167
Batch 26/64 loss: 0.35474395751953125
Batch 27/64 loss: 0.3581033945083618
Batch 28/64 loss: 0.357869029045105
Batch 29/64 loss: 0.3538343906402588
Batch 30/64 loss: 0.3563547730445862
Batch 31/64 loss: 0.35729408264160156
Batch 32/64 loss: 0.35574209690093994
Batch 33/64 loss: 0.3532665967941284
Batch 34/64 loss: 0.3552931547164917
Batch 35/64 loss: 0.3545520305633545
Batch 36/64 loss: 0.35709428787231445
Batch 37/64 loss: 0.3553704023361206
Batch 38/64 loss: 0.35216188430786133
Batch 39/64 loss: 0.3528379797935486
Batch 40/64 loss: 0.3603329062461853
Batch 41/64 loss: 0.35709822177886963
Batch 42/64 loss: 0.35675400495529175
Batch 43/64 loss: 0.35691702365875244
Batch 44/64 loss: 0.3531418442726135
Batch 45/64 loss: 0.35775530338287354
Batch 46/64 loss: 0.3577507734298706
Batch 47/64 loss: 0.3548969626426697
Batch 48/64 loss: 0.3579857349395752
Batch 49/64 loss: 0.35683703422546387
Batch 50/64 loss: 0.3553965091705322
Batch 51/64 loss: 0.3566082715988159
Batch 52/64 loss: 0.35367071628570557
Batch 53/64 loss: 0.35436034202575684
Batch 54/64 loss: 0.3588137626647949
Batch 55/64 loss: 0.35552382469177246
Batch 56/64 loss: 0.3528406023979187
Batch 57/64 loss: 0.3526000380516052
Batch 58/64 loss: 0.3623673915863037
Batch 59/64 loss: 0.35930538177490234
Batch 60/64 loss: 0.35236936807632446
Batch 61/64 loss: 0.3573542833328247
Batch 62/64 loss: 0.35961973667144775
Batch 63/64 loss: 0.3571509122848511
Batch 64/64 loss: 0.3576340675354004
Epoch 80  Train loss: 0.3558662601545745  Val loss: 0.3585506036519185
Epoch 81
-------------------------------
Batch 1/64 loss: 0.3524433970451355
Batch 2/64 loss: 0.357211709022522
Batch 3/64 loss: 0.35779404640197754
Batch 4/64 loss: 0.3564625382423401
Batch 5/64 loss: 0.35242927074432373
Batch 6/64 loss: 0.3531135320663452
Batch 7/64 loss: 0.3541465997695923
Batch 8/64 loss: 0.35601240396499634
Batch 9/64 loss: 0.3543819189071655
Batch 10/64 loss: 0.35361623764038086
Batch 11/64 loss: 0.35463571548461914
Batch 12/64 loss: 0.35822391510009766
Batch 13/64 loss: 0.3576009273529053
Batch 14/64 loss: 0.3572272062301636
Batch 15/64 loss: 0.3564049005508423
Batch 16/64 loss: 0.356239914894104
Batch 17/64 loss: 0.35611164569854736
Batch 18/64 loss: 0.3565100431442261
Batch 19/64 loss: 0.35874319076538086
Batch 20/64 loss: 0.35632753372192383
Batch 21/64 loss: 0.35566335916519165
Batch 22/64 loss: 0.35587793588638306
Batch 23/64 loss: 0.35433459281921387
Batch 24/64 loss: 0.35485023260116577
Batch 25/64 loss: 0.35390692949295044
Batch 26/64 loss: 0.35790109634399414
Batch 27/64 loss: 0.35225367546081543
Batch 28/64 loss: 0.35509538650512695
Batch 29/64 loss: 0.35414087772369385
Batch 30/64 loss: 0.35395824909210205
Batch 31/64 loss: 0.35450875759124756
Batch 32/64 loss: 0.3608342409133911
Batch 33/64 loss: 0.36109423637390137
Batch 34/64 loss: 0.3570220470428467
Batch 35/64 loss: 0.35365527868270874
Batch 36/64 loss: 0.3546257019042969
Batch 37/64 loss: 0.36032307147979736
Batch 38/64 loss: 0.35471010208129883
Batch 39/64 loss: 0.3596135377883911
Batch 40/64 loss: 0.3576681613922119
Batch 41/64 loss: 0.3530835509300232
Batch 42/64 loss: 0.35670363903045654
Batch 43/64 loss: 0.35634732246398926
Batch 44/64 loss: 0.3551720380783081
Batch 45/64 loss: 0.3538782596588135
Batch 46/64 loss: 0.35302531719207764
Batch 47/64 loss: 0.3529910445213318
Batch 48/64 loss: 0.3550974130630493
Batch 49/64 loss: 0.35873138904571533
Batch 50/64 loss: 0.35042905807495117
Batch 51/64 loss: 0.3579840660095215
Batch 52/64 loss: 0.35891270637512207
Batch 53/64 loss: 0.3552660346031189
Batch 54/64 loss: 0.359083890914917
Batch 55/64 loss: 0.3551539182662964
Batch 56/64 loss: 0.3566533327102661
Batch 57/64 loss: 0.35685431957244873
Batch 58/64 loss: 0.3484865427017212
Batch 59/64 loss: 0.35257917642593384
Batch 60/64 loss: 0.35412800312042236
Batch 61/64 loss: 0.35172706842422485
Batch 62/64 loss: 0.35477566719055176
Batch 63/64 loss: 0.3550201654434204
Batch 64/64 loss: 0.3559436798095703
Epoch 81  Train loss: 0.3555563262864655  Val loss: 0.35722901771978005
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: 0.3549802899360657
Batch 2/64 loss: 0.3589091897010803
Batch 3/64 loss: 0.3530941605567932
Batch 4/64 loss: 0.353954017162323
Batch 5/64 loss: 0.3555651307106018
Batch 6/64 loss: 0.3564513325691223
Batch 7/64 loss: 0.3555033206939697
Batch 8/64 loss: 0.35826098918914795
Batch 9/64 loss: 0.3547382354736328
Batch 10/64 loss: 0.355155348777771
Batch 11/64 loss: 0.355554461479187
Batch 12/64 loss: 0.3525087833404541
Batch 13/64 loss: 0.35807740688323975
Batch 14/64 loss: 0.35417765378952026
Batch 15/64 loss: 0.3568000793457031
Batch 16/64 loss: 0.35520339012145996
Batch 17/64 loss: 0.35110580921173096
Batch 18/64 loss: 0.353582501411438
Batch 19/64 loss: 0.3583706021308899
Batch 20/64 loss: 0.3529106378555298
Batch 21/64 loss: 0.352276086807251
Batch 22/64 loss: 0.361117422580719
Batch 23/64 loss: 0.3529248833656311
Batch 24/64 loss: 0.3554795980453491
Batch 25/64 loss: 0.3556113839149475
Batch 26/64 loss: 0.35449427366256714
Batch 27/64 loss: 0.35339903831481934
Batch 28/64 loss: 0.35428404808044434
Batch 29/64 loss: 0.3524399399757385
Batch 30/64 loss: 0.3589818477630615
Batch 31/64 loss: 0.35373783111572266
Batch 32/64 loss: 0.35605770349502563
Batch 33/64 loss: 0.35164058208465576
Batch 34/64 loss: 0.3565729260444641
Batch 35/64 loss: 0.351684033870697
Batch 36/64 loss: 0.35626256465911865
Batch 37/64 loss: 0.3574082851409912
Batch 38/64 loss: 0.3564082384109497
Batch 39/64 loss: 0.35165196657180786
Batch 40/64 loss: 0.352600634098053
Batch 41/64 loss: 0.3580847978591919
Batch 42/64 loss: 0.35704267024993896
Batch 43/64 loss: 0.3543141484260559
Batch 44/64 loss: 0.3531472682952881
Batch 45/64 loss: 0.3543529510498047
Batch 46/64 loss: 0.3536348342895508
Batch 47/64 loss: 0.3596111536026001
Batch 48/64 loss: 0.3532401919364929
Batch 49/64 loss: 0.35420966148376465
Batch 50/64 loss: 0.35653436183929443
Batch 51/64 loss: 0.3520503640174866
Batch 52/64 loss: 0.35360705852508545
Batch 53/64 loss: 0.3566772937774658
Batch 54/64 loss: 0.3554597496986389
Batch 55/64 loss: 0.3573648929595947
Batch 56/64 loss: 0.35613685846328735
Batch 57/64 loss: 0.3583115339279175
Batch 58/64 loss: 0.3539750576019287
Batch 59/64 loss: 0.3518716096878052
Batch 60/64 loss: 0.36033034324645996
Batch 61/64 loss: 0.35613584518432617
Batch 62/64 loss: 0.356917142868042
Batch 63/64 loss: 0.3571920394897461
Batch 64/64 loss: 0.3535348176956177
Epoch 82  Train loss: 0.35522022855048085  Val loss: 0.35753001339247137
Epoch 83
-------------------------------
Batch 1/64 loss: 0.3527541756629944
Batch 2/64 loss: 0.3564645051956177
Batch 3/64 loss: 0.35278451442718506
Batch 4/64 loss: 0.35363245010375977
Batch 5/64 loss: 0.35615599155426025
Batch 6/64 loss: 0.3566070795059204
Batch 7/64 loss: 0.35493695735931396
Batch 8/64 loss: 0.3544504642486572
Batch 9/64 loss: 0.3526741862297058
Batch 10/64 loss: 0.36059069633483887
Batch 11/64 loss: 0.35697877407073975
Batch 12/64 loss: 0.3516649007797241
Batch 13/64 loss: 0.3562517762184143
Batch 14/64 loss: 0.3593330979347229
Batch 15/64 loss: 0.35191428661346436
Batch 16/64 loss: 0.35623687505722046
Batch 17/64 loss: 0.35258156061172485
Batch 18/64 loss: 0.35384202003479004
Batch 19/64 loss: 0.35337162017822266
Batch 20/64 loss: 0.35815519094467163
Batch 21/64 loss: 0.3573296070098877
Batch 22/64 loss: 0.3547765016555786
Batch 23/64 loss: 0.3565249443054199
Batch 24/64 loss: 0.3530835509300232
Batch 25/64 loss: 0.35785502195358276
Batch 26/64 loss: 0.3541582226753235
Batch 27/64 loss: 0.35786986351013184
Batch 28/64 loss: 0.3531736135482788
Batch 29/64 loss: 0.3539724349975586
Batch 30/64 loss: 0.35322046279907227
Batch 31/64 loss: 0.35651254653930664
Batch 32/64 loss: 0.35077768564224243
Batch 33/64 loss: 0.3521026372909546
Batch 34/64 loss: 0.35799920558929443
Batch 35/64 loss: 0.3601759672164917
Batch 36/64 loss: 0.3528999090194702
Batch 37/64 loss: 0.3567274808883667
Batch 38/64 loss: 0.3597550392150879
Batch 39/64 loss: 0.3561893105506897
Batch 40/64 loss: 0.35578030347824097
Batch 41/64 loss: 0.3585543632507324
Batch 42/64 loss: 0.3540443778038025
Batch 43/64 loss: 0.3559134006500244
Batch 44/64 loss: 0.3554072976112366
Batch 45/64 loss: 0.35557687282562256
Batch 46/64 loss: 0.35431623458862305
Batch 47/64 loss: 0.3535250425338745
Batch 48/64 loss: 0.3553951382637024
Batch 49/64 loss: 0.35621094703674316
Batch 50/64 loss: 0.35827451944351196
Batch 51/64 loss: 0.3572962284088135
Batch 52/64 loss: 0.35467374324798584
Batch 53/64 loss: 0.35369646549224854
Batch 54/64 loss: 0.3568626642227173
Batch 55/64 loss: 0.3565998077392578
Batch 56/64 loss: 0.35156941413879395
Batch 57/64 loss: 0.3505861163139343
Batch 58/64 loss: 0.35608983039855957
Batch 59/64 loss: 0.3534802794456482
Batch 60/64 loss: 0.3566497564315796
Batch 61/64 loss: 0.3544732928276062
Batch 62/64 loss: 0.3533880114555359
Batch 63/64 loss: 0.3565547466278076
Batch 64/64 loss: 0.3594425916671753
Epoch 83  Train loss: 0.35530958315905403  Val loss: 0.35749729105697053
Epoch 84
-------------------------------
Batch 1/64 loss: 0.3514251112937927
Batch 2/64 loss: 0.357425332069397
Batch 3/64 loss: 0.3548394441604614
Batch 4/64 loss: 0.3583161234855652
Batch 5/64 loss: 0.3546370267868042
Batch 6/64 loss: 0.34950315952301025
Batch 7/64 loss: 0.3552279472351074
Batch 8/64 loss: 0.35432350635528564
Batch 9/64 loss: 0.3502923250198364
Batch 10/64 loss: 0.35879361629486084
Batch 11/64 loss: 0.35706913471221924
Batch 12/64 loss: 0.35676413774490356
Batch 13/64 loss: 0.35595494508743286
Batch 14/64 loss: 0.3552279472351074
Batch 15/64 loss: 0.3517338037490845
Batch 16/64 loss: 0.3543272018432617
Batch 17/64 loss: 0.35270678997039795
Batch 18/64 loss: 0.3569187521934509
Batch 19/64 loss: 0.3547292947769165
Batch 20/64 loss: 0.3558272123336792
Batch 21/64 loss: 0.3545563220977783
Batch 22/64 loss: 0.35517334938049316
Batch 23/64 loss: 0.35540521144866943
Batch 24/64 loss: 0.35526204109191895
Batch 25/64 loss: 0.3560994267463684
Batch 26/64 loss: 0.35605406761169434
Batch 27/64 loss: 0.3596320152282715
Batch 28/64 loss: 0.35511577129364014
Batch 29/64 loss: 0.35594022274017334
Batch 30/64 loss: 0.35444921255111694
Batch 31/64 loss: 0.353093683719635
Batch 32/64 loss: 0.35704803466796875
Batch 33/64 loss: 0.36098015308380127
Batch 34/64 loss: 0.35806775093078613
Batch 35/64 loss: 0.3561326265335083
Batch 36/64 loss: 0.35672199726104736
Batch 37/64 loss: 0.3580840826034546
Batch 38/64 loss: 0.3568391799926758
Batch 39/64 loss: 0.3516545295715332
Batch 40/64 loss: 0.3575262427330017
Batch 41/64 loss: 0.3553192615509033
Batch 42/64 loss: 0.3529817461967468
Batch 43/64 loss: 0.35567784309387207
Batch 44/64 loss: 0.35991787910461426
Batch 45/64 loss: 0.35582637786865234
Batch 46/64 loss: 0.3576087951660156
Batch 47/64 loss: 0.353299081325531
Batch 48/64 loss: 0.35476624965667725
Batch 49/64 loss: 0.35260891914367676
Batch 50/64 loss: 0.35894203186035156
Batch 51/64 loss: 0.3540683388710022
Batch 52/64 loss: 0.35440701246261597
Batch 53/64 loss: 0.3545719385147095
Batch 54/64 loss: 0.3525936007499695
Batch 55/64 loss: 0.35622984170913696
Batch 56/64 loss: 0.3548521399497986
Batch 57/64 loss: 0.35265231132507324
Batch 58/64 loss: 0.3529065251350403
Batch 59/64 loss: 0.35633087158203125
Batch 60/64 loss: 0.3557368516921997
Batch 61/64 loss: 0.3560488224029541
Batch 62/64 loss: 0.3540087938308716
Batch 63/64 loss: 0.35490715503692627
Batch 64/64 loss: 0.3508039712905884
Epoch 84  Train loss: 0.35528226038988897  Val loss: 0.35800168501962093
Epoch 85
-------------------------------
Batch 1/64 loss: 0.3591933846473694
Batch 2/64 loss: 0.3545430302619934
Batch 3/64 loss: 0.3518750071525574
Batch 4/64 loss: 0.3513622283935547
Batch 5/64 loss: 0.35490643978118896
Batch 6/64 loss: 0.35992950201034546
Batch 7/64 loss: 0.35727381706237793
Batch 8/64 loss: 0.35273921489715576
Batch 9/64 loss: 0.3502211570739746
Batch 10/64 loss: 0.35350048542022705
Batch 11/64 loss: 0.3566286563873291
Batch 12/64 loss: 0.353851318359375
Batch 13/64 loss: 0.35443997383117676
Batch 14/64 loss: 0.36203545331954956
Batch 15/64 loss: 0.3582162857055664
Batch 16/64 loss: 0.354017972946167
Batch 17/64 loss: 0.35454273223876953
Batch 18/64 loss: 0.35144996643066406
Batch 19/64 loss: 0.3538970947265625
Batch 20/64 loss: 0.3541252613067627
Batch 21/64 loss: 0.35704314708709717
Batch 22/64 loss: 0.3530482053756714
Batch 23/64 loss: 0.352489709854126
Batch 24/64 loss: 0.3515479564666748
Batch 25/64 loss: 0.35512804985046387
Batch 26/64 loss: 0.35149556398391724
Batch 27/64 loss: 0.35638028383255005
Batch 28/64 loss: 0.3528115749359131
Batch 29/64 loss: 0.35196369886398315
Batch 30/64 loss: 0.3568146824836731
Batch 31/64 loss: 0.36121249198913574
Batch 32/64 loss: 0.3557567000389099
Batch 33/64 loss: 0.3552647829055786
Batch 34/64 loss: 0.3548215627670288
Batch 35/64 loss: 0.3526113033294678
Batch 36/64 loss: 0.35685622692108154
Batch 37/64 loss: 0.3587918281555176
Batch 38/64 loss: 0.3559666872024536
Batch 39/64 loss: 0.357699990272522
Batch 40/64 loss: 0.35887742042541504
Batch 41/64 loss: 0.3592544198036194
Batch 42/64 loss: 0.35513365268707275
Batch 43/64 loss: 0.3498460650444031
Batch 44/64 loss: 0.3544672727584839
Batch 45/64 loss: 0.3574017286300659
Batch 46/64 loss: 0.35716384649276733
Batch 47/64 loss: 0.35626596212387085
Batch 48/64 loss: 0.35793131589889526
Batch 49/64 loss: 0.35546648502349854
Batch 50/64 loss: 0.35221827030181885
Batch 51/64 loss: 0.3561972379684448
Batch 52/64 loss: 0.35201531648635864
Batch 53/64 loss: 0.35711896419525146
Batch 54/64 loss: 0.3539370894432068
Batch 55/64 loss: 0.35411810874938965
Batch 56/64 loss: 0.35357266664505005
Batch 57/64 loss: 0.3535342216491699
Batch 58/64 loss: 0.3542068600654602
Batch 59/64 loss: 0.3577066659927368
Batch 60/64 loss: 0.3559466004371643
Batch 61/64 loss: 0.3550090789794922
Batch 62/64 loss: 0.35710644721984863
Batch 63/64 loss: 0.3564649820327759
Batch 64/64 loss: 0.3531367778778076
Epoch 85  Train loss: 0.35517281083499685  Val loss: 0.3578239245103397
Epoch 86
-------------------------------
Batch 1/64 loss: 0.3494377136230469
Batch 2/64 loss: 0.35573893785476685
Batch 3/64 loss: 0.352736234664917
Batch 4/64 loss: 0.35580646991729736
Batch 5/64 loss: 0.3504784107208252
Batch 6/64 loss: 0.3575335741043091
Batch 7/64 loss: 0.3551623225212097
Batch 8/64 loss: 0.35448455810546875
Batch 9/64 loss: 0.35509932041168213
Batch 10/64 loss: 0.3539443612098694
Batch 11/64 loss: 0.3577888011932373
Batch 12/64 loss: 0.3528193235397339
Batch 13/64 loss: 0.3550998568534851
Batch 14/64 loss: 0.3541143536567688
Batch 15/64 loss: 0.3529326915740967
Batch 16/64 loss: 0.3535023331642151
Batch 17/64 loss: 0.35544466972351074
Batch 18/64 loss: 0.35508638620376587
Batch 19/64 loss: 0.35294783115386963
Batch 20/64 loss: 0.3540952801704407
Batch 21/64 loss: 0.3547214865684509
Batch 22/64 loss: 0.3548327684402466
Batch 23/64 loss: 0.35802412033081055
Batch 24/64 loss: 0.3524397611618042
Batch 25/64 loss: 0.35494542121887207
Batch 26/64 loss: 0.3574943542480469
Batch 27/64 loss: 0.35829901695251465
Batch 28/64 loss: 0.35756105184555054
Batch 29/64 loss: 0.35859787464141846
Batch 30/64 loss: 0.3548113703727722
Batch 31/64 loss: 0.35464680194854736
Batch 32/64 loss: 0.35525214672088623
Batch 33/64 loss: 0.3579217791557312
Batch 34/64 loss: 0.35950231552124023
Batch 35/64 loss: 0.3513568043708801
Batch 36/64 loss: 0.35283952951431274
Batch 37/64 loss: 0.3566223978996277
Batch 38/64 loss: 0.35572755336761475
Batch 39/64 loss: 0.3581686019897461
Batch 40/64 loss: 0.35543739795684814
Batch 41/64 loss: 0.35442304611206055
Batch 42/64 loss: 0.35520458221435547
Batch 43/64 loss: 0.35375332832336426
Batch 44/64 loss: 0.3547060489654541
Batch 45/64 loss: 0.3530956506729126
Batch 46/64 loss: 0.3512861728668213
Batch 47/64 loss: 0.35526764392852783
Batch 48/64 loss: 0.3548291325569153
Batch 49/64 loss: 0.35334277153015137
Batch 50/64 loss: 0.35199588537216187
Batch 51/64 loss: 0.35312700271606445
Batch 52/64 loss: 0.35308969020843506
Batch 53/64 loss: 0.3529984951019287
Batch 54/64 loss: 0.3537250757217407
Batch 55/64 loss: 0.35376644134521484
Batch 56/64 loss: 0.35552752017974854
Batch 57/64 loss: 0.361447274684906
Batch 58/64 loss: 0.36034059524536133
Batch 59/64 loss: 0.3517124652862549
Batch 60/64 loss: 0.3538588881492615
Batch 61/64 loss: 0.354450523853302
Batch 62/64 loss: 0.35439008474349976
Batch 63/64 loss: 0.3541538119316101
Batch 64/64 loss: 0.3575878143310547
Epoch 86  Train loss: 0.3548570819929534  Val loss: 0.35717210122400134
Saving best model, epoch: 86
Epoch 87
-------------------------------
Batch 1/64 loss: 0.35504889488220215
Batch 2/64 loss: 0.3556138277053833
Batch 3/64 loss: 0.3555490970611572
Batch 4/64 loss: 0.35414063930511475
Batch 5/64 loss: 0.35312700271606445
Batch 6/64 loss: 0.35194915533065796
Batch 7/64 loss: 0.3572136163711548
Batch 8/64 loss: 0.353479266166687
Batch 9/64 loss: 0.35343021154403687
Batch 10/64 loss: 0.35640275478363037
Batch 11/64 loss: 0.35635101795196533
Batch 12/64 loss: 0.3554953336715698
Batch 13/64 loss: 0.3554028272628784
Batch 14/64 loss: 0.3537323474884033
Batch 15/64 loss: 0.35276466608047485
Batch 16/64 loss: 0.3509630560874939
Batch 17/64 loss: 0.3471895456314087
Batch 18/64 loss: 0.3518666625022888
Batch 19/64 loss: 0.35748791694641113
Batch 20/64 loss: 0.3579840064048767
Batch 21/64 loss: 0.35148119926452637
Batch 22/64 loss: 0.35608720779418945
Batch 23/64 loss: 0.35299015045166016
Batch 24/64 loss: 0.3545989990234375
Batch 25/64 loss: 0.35346466302871704
Batch 26/64 loss: 0.3551740050315857
Batch 27/64 loss: 0.3542748689651489
Batch 28/64 loss: 0.3574727773666382
Batch 29/64 loss: 0.35480785369873047
Batch 30/64 loss: 0.3571596145629883
Batch 31/64 loss: 0.3529531955718994
Batch 32/64 loss: 0.3514448404312134
Batch 33/64 loss: 0.3545452356338501
Batch 34/64 loss: 0.3563956022262573
Batch 35/64 loss: 0.35547059774398804
Batch 36/64 loss: 0.353604257106781
Batch 37/64 loss: 0.35314810276031494
Batch 38/64 loss: 0.3579298257827759
Batch 39/64 loss: 0.3512430191040039
Batch 40/64 loss: 0.36046504974365234
Batch 41/64 loss: 0.3556233048439026
Batch 42/64 loss: 0.3527017831802368
Batch 43/64 loss: 0.35707247257232666
Batch 44/64 loss: 0.35375332832336426
Batch 45/64 loss: 0.3523576259613037
Batch 46/64 loss: 0.3553937077522278
Batch 47/64 loss: 0.35155999660491943
Batch 48/64 loss: 0.3573496341705322
Batch 49/64 loss: 0.3509863018989563
Batch 50/64 loss: 0.35294872522354126
Batch 51/64 loss: 0.3529937267303467
Batch 52/64 loss: 0.35054874420166016
Batch 53/64 loss: 0.35307174921035767
Batch 54/64 loss: 0.3561254143714905
Batch 55/64 loss: 0.35598546266555786
Batch 56/64 loss: 0.3566683530807495
Batch 57/64 loss: 0.3544272184371948
Batch 58/64 loss: 0.3582981824874878
Batch 59/64 loss: 0.35511159896850586
Batch 60/64 loss: 0.35408973693847656
Batch 61/64 loss: 0.35343241691589355
Batch 62/64 loss: 0.35402172803878784
Batch 63/64 loss: 0.35396242141723633
Batch 64/64 loss: 0.3603200316429138
Epoch 87  Train loss: 0.35448825990452487  Val loss: 0.3577378005096593
Epoch 88
-------------------------------
Batch 1/64 loss: 0.3545495271682739
Batch 2/64 loss: 0.3573157787322998
Batch 3/64 loss: 0.3536762595176697
Batch 4/64 loss: 0.35881590843200684
Batch 5/64 loss: 0.3548334836959839
Batch 6/64 loss: 0.35402148962020874
Batch 7/64 loss: 0.35374605655670166
Batch 8/64 loss: 0.3542677164077759
Batch 9/64 loss: 0.35335421562194824
Batch 10/64 loss: 0.35310661792755127
Batch 11/64 loss: 0.3541860580444336
Batch 12/64 loss: 0.35427361726760864
Batch 13/64 loss: 0.35033535957336426
Batch 14/64 loss: 0.3513883352279663
Batch 15/64 loss: 0.3547552824020386
Batch 16/64 loss: 0.3572129011154175
Batch 17/64 loss: 0.3534536361694336
Batch 18/64 loss: 0.35179442167282104
Batch 19/64 loss: 0.3511446714401245
Batch 20/64 loss: 0.35376298427581787
Batch 21/64 loss: 0.35712891817092896
Batch 22/64 loss: 0.35363298654556274
Batch 23/64 loss: 0.35175013542175293
Batch 24/64 loss: 0.3539785146713257
Batch 25/64 loss: 0.35495245456695557
Batch 26/64 loss: 0.3560997247695923
Batch 27/64 loss: 0.3550146818161011
Batch 28/64 loss: 0.35575252771377563
Batch 29/64 loss: 0.35198456048965454
Batch 30/64 loss: 0.3504750728607178
Batch 31/64 loss: 0.3553805351257324
Batch 32/64 loss: 0.35252273082733154
Batch 33/64 loss: 0.35978972911834717
Batch 34/64 loss: 0.35333675146102905
Batch 35/64 loss: 0.35666728019714355
Batch 36/64 loss: 0.351290762424469
Batch 37/64 loss: 0.35324251651763916
Batch 38/64 loss: 0.3522636890411377
Batch 39/64 loss: 0.35429608821868896
Batch 40/64 loss: 0.3573657274246216
Batch 41/64 loss: 0.3543528914451599
Batch 42/64 loss: 0.3520253896713257
Batch 43/64 loss: 0.3527461290359497
Batch 44/64 loss: 0.35294175148010254
Batch 45/64 loss: 0.3532930612564087
Batch 46/64 loss: 0.35601162910461426
Batch 47/64 loss: 0.3509328365325928
Batch 48/64 loss: 0.35436922311782837
Batch 49/64 loss: 0.3574596643447876
Batch 50/64 loss: 0.35008955001831055
Batch 51/64 loss: 0.3534172773361206
Batch 52/64 loss: 0.3543046712875366
Batch 53/64 loss: 0.3547627925872803
Batch 54/64 loss: 0.35907304286956787
Batch 55/64 loss: 0.3551971912384033
Batch 56/64 loss: 0.35197949409484863
Batch 57/64 loss: 0.35829055309295654
Batch 58/64 loss: 0.3520622253417969
Batch 59/64 loss: 0.35424351692199707
Batch 60/64 loss: 0.3583498001098633
Batch 61/64 loss: 0.3518579602241516
Batch 62/64 loss: 0.35334867238998413
Batch 63/64 loss: 0.35577189922332764
Batch 64/64 loss: 0.35505300760269165
Epoch 88  Train loss: 0.35419750096751196  Val loss: 0.3570518038936497
Saving best model, epoch: 88
Epoch 89
-------------------------------
Batch 1/64 loss: 0.3533642888069153
Batch 2/64 loss: 0.3540154695510864
Batch 3/64 loss: 0.3548116087913513
Batch 4/64 loss: 0.3522014617919922
Batch 5/64 loss: 0.35798537731170654
Batch 6/64 loss: 0.3550848960876465
Batch 7/64 loss: 0.34947991371154785
Batch 8/64 loss: 0.35402512550354004
Batch 9/64 loss: 0.35232043266296387
Batch 10/64 loss: 0.358950674533844
Batch 11/64 loss: 0.35396236181259155
Batch 12/64 loss: 0.3521299362182617
Batch 13/64 loss: 0.35026538372039795
Batch 14/64 loss: 0.3556516170501709
Batch 15/64 loss: 0.3564792275428772
Batch 16/64 loss: 0.354519248008728
Batch 17/64 loss: 0.3517860770225525
Batch 18/64 loss: 0.3555769920349121
Batch 19/64 loss: 0.35412997007369995
Batch 20/64 loss: 0.35319530963897705
Batch 21/64 loss: 0.35699737071990967
Batch 22/64 loss: 0.356015682220459
Batch 23/64 loss: 0.35635244846343994
Batch 24/64 loss: 0.35551130771636963
Batch 25/64 loss: 0.35746026039123535
Batch 26/64 loss: 0.3553600311279297
Batch 27/64 loss: 0.35600411891937256
Batch 28/64 loss: 0.35801732540130615
Batch 29/64 loss: 0.3580930233001709
Batch 30/64 loss: 0.3532007336616516
Batch 31/64 loss: 0.3554012179374695
Batch 32/64 loss: 0.3554369807243347
Batch 33/64 loss: 0.3501209020614624
Batch 34/64 loss: 0.35429179668426514
Batch 35/64 loss: 0.3611866235733032
Batch 36/64 loss: 0.3491395115852356
Batch 37/64 loss: 0.3561880588531494
Batch 38/64 loss: 0.3515925407409668
Batch 39/64 loss: 0.3510713577270508
Batch 40/64 loss: 0.35597431659698486
Batch 41/64 loss: 0.35395628213882446
Batch 42/64 loss: 0.3545912504196167
Batch 43/64 loss: 0.35255032777786255
Batch 44/64 loss: 0.3568289279937744
Batch 45/64 loss: 0.351839542388916
Batch 46/64 loss: 0.35396695137023926
Batch 47/64 loss: 0.3579910397529602
Batch 48/64 loss: 0.35320621728897095
Batch 49/64 loss: 0.3515208959579468
Batch 50/64 loss: 0.35572636127471924
Batch 51/64 loss: 0.355167031288147
Batch 52/64 loss: 0.356931209564209
Batch 53/64 loss: 0.3537725806236267
Batch 54/64 loss: 0.3524407148361206
Batch 55/64 loss: 0.3519643545150757
Batch 56/64 loss: 0.35307449102401733
Batch 57/64 loss: 0.36089229583740234
Batch 58/64 loss: 0.355834424495697
Batch 59/64 loss: 0.3554079532623291
Batch 60/64 loss: 0.3558427095413208
Batch 61/64 loss: 0.3569622039794922
Batch 62/64 loss: 0.35334038734436035
Batch 63/64 loss: 0.3546016216278076
Batch 64/64 loss: 0.3500879406929016
Epoch 89  Train loss: 0.3545776738839991  Val loss: 0.3574496294624617
Epoch 90
-------------------------------
Batch 1/64 loss: 0.357205867767334
Batch 2/64 loss: 0.3545939326286316
Batch 3/64 loss: 0.3529777526855469
Batch 4/64 loss: 0.35494720935821533
Batch 5/64 loss: 0.35524147748947144
Batch 6/64 loss: 0.35288292169570923
Batch 7/64 loss: 0.35318100452423096
Batch 8/64 loss: 0.35758209228515625
Batch 9/64 loss: 0.35088562965393066
Batch 10/64 loss: 0.35638701915740967
Batch 11/64 loss: 0.3479902744293213
Batch 12/64 loss: 0.3582381010055542
Batch 13/64 loss: 0.35554826259613037
Batch 14/64 loss: 0.35619908571243286
Batch 15/64 loss: 0.3523111343383789
Batch 16/64 loss: 0.34909868240356445
Batch 17/64 loss: 0.353576123714447
Batch 18/64 loss: 0.3511890172958374
Batch 19/64 loss: 0.35404372215270996
Batch 20/64 loss: 0.3556070923805237
Batch 21/64 loss: 0.3548148274421692
Batch 22/64 loss: 0.3575439453125
Batch 23/64 loss: 0.34854239225387573
Batch 24/64 loss: 0.3576727509498596
Batch 25/64 loss: 0.349936842918396
Batch 26/64 loss: 0.3567352294921875
Batch 27/64 loss: 0.35141921043395996
Batch 28/64 loss: 0.35125553607940674
Batch 29/64 loss: 0.35688233375549316
Batch 30/64 loss: 0.35371994972229004
Batch 31/64 loss: 0.353404700756073
Batch 32/64 loss: 0.3572876453399658
Batch 33/64 loss: 0.3552262783050537
Batch 34/64 loss: 0.34980082511901855
Batch 35/64 loss: 0.34928667545318604
Batch 36/64 loss: 0.3561217784881592
Batch 37/64 loss: 0.3526991605758667
Batch 38/64 loss: 0.3507305383682251
Batch 39/64 loss: 0.35920727252960205
Batch 40/64 loss: 0.355668842792511
Batch 41/64 loss: 0.35644984245300293
Batch 42/64 loss: 0.35600316524505615
Batch 43/64 loss: 0.35673969984054565
Batch 44/64 loss: 0.3525438904762268
Batch 45/64 loss: 0.3549749255180359
Batch 46/64 loss: 0.3516172170639038
Batch 47/64 loss: 0.3544778823852539
Batch 48/64 loss: 0.3553450107574463
Batch 49/64 loss: 0.35455644130706787
Batch 50/64 loss: 0.3578319549560547
Batch 51/64 loss: 0.35416537523269653
Batch 52/64 loss: 0.3561747074127197
Batch 53/64 loss: 0.35303133726119995
Batch 54/64 loss: 0.34983623027801514
Batch 55/64 loss: 0.35247015953063965
Batch 56/64 loss: 0.3554239273071289
Batch 57/64 loss: 0.3523108959197998
Batch 58/64 loss: 0.35534411668777466
Batch 59/64 loss: 0.3537842631340027
Batch 60/64 loss: 0.35483109951019287
Batch 61/64 loss: 0.35389941930770874
Batch 62/64 loss: 0.35384702682495117
Batch 63/64 loss: 0.35554397106170654
Batch 64/64 loss: 0.3553825616836548
Epoch 90  Train loss: 0.3541236489426856  Val loss: 0.3565348046751776
Saving best model, epoch: 90
Epoch 91
-------------------------------
Batch 1/64 loss: 0.3479527235031128
Batch 2/64 loss: 0.3564568758010864
Batch 3/64 loss: 0.3522205352783203
Batch 4/64 loss: 0.3588123321533203
Batch 5/64 loss: 0.35436534881591797
Batch 6/64 loss: 0.3588069677352905
Batch 7/64 loss: 0.35311704874038696
Batch 8/64 loss: 0.3509696125984192
Batch 9/64 loss: 0.35631418228149414
Batch 10/64 loss: 0.3565002679824829
Batch 11/64 loss: 0.35545098781585693
Batch 12/64 loss: 0.35437166690826416
Batch 13/64 loss: 0.3562828302383423
Batch 14/64 loss: 0.3538597822189331
Batch 15/64 loss: 0.3531649112701416
Batch 16/64 loss: 0.35115599632263184
Batch 17/64 loss: 0.3530403971672058
Batch 18/64 loss: 0.356722354888916
Batch 19/64 loss: 0.3518270254135132
Batch 20/64 loss: 0.35501420497894287
Batch 21/64 loss: 0.3545728921890259
Batch 22/64 loss: 0.35156381130218506
Batch 23/64 loss: 0.35801851749420166
Batch 24/64 loss: 0.3575109839439392
Batch 25/64 loss: 0.3494373559951782
Batch 26/64 loss: 0.35511988401412964
Batch 27/64 loss: 0.3538846969604492
Batch 28/64 loss: 0.3551443815231323
Batch 29/64 loss: 0.35299086570739746
Batch 30/64 loss: 0.3522672653198242
Batch 31/64 loss: 0.3526996374130249
Batch 32/64 loss: 0.3535906672477722
Batch 33/64 loss: 0.35064148902893066
Batch 34/64 loss: 0.35630160570144653
Batch 35/64 loss: 0.3553839921951294
Batch 36/64 loss: 0.35156363248825073
Batch 37/64 loss: 0.35541272163391113
Batch 38/64 loss: 0.3560744524002075
Batch 39/64 loss: 0.35158514976501465
Batch 40/64 loss: 0.35369670391082764
Batch 41/64 loss: 0.34873056411743164
Batch 42/64 loss: 0.3574560284614563
Batch 43/64 loss: 0.3547080159187317
Batch 44/64 loss: 0.35607731342315674
Batch 45/64 loss: 0.35372984409332275
Batch 46/64 loss: 0.3553239107131958
Batch 47/64 loss: 0.3532356023788452
Batch 48/64 loss: 0.35332727432250977
Batch 49/64 loss: 0.35151350498199463
Batch 50/64 loss: 0.3497311472892761
Batch 51/64 loss: 0.35099565982818604
Batch 52/64 loss: 0.35653358697891235
Batch 53/64 loss: 0.3565940856933594
Batch 54/64 loss: 0.35386115312576294
Batch 55/64 loss: 0.35566651821136475
Batch 56/64 loss: 0.35229063034057617
Batch 57/64 loss: 0.3524702787399292
Batch 58/64 loss: 0.35564708709716797
Batch 59/64 loss: 0.35312360525131226
Batch 60/64 loss: 0.35490310192108154
Batch 61/64 loss: 0.35251903533935547
Batch 62/64 loss: 0.3565581440925598
Batch 63/64 loss: 0.35624921321868896
Batch 64/64 loss: 0.3530358076095581
Epoch 91  Train loss: 0.35403747324850043  Val loss: 0.35789749589572656
Epoch 92
-------------------------------
Batch 1/64 loss: 0.35457098484039307
Batch 2/64 loss: 0.35467350482940674
Batch 3/64 loss: 0.3532973527908325
Batch 4/64 loss: 0.34713196754455566
Batch 5/64 loss: 0.3541642427444458
Batch 6/64 loss: 0.3517020344734192
Batch 7/64 loss: 0.35273945331573486
Batch 8/64 loss: 0.3553529381752014
Batch 9/64 loss: 0.3567451238632202
Batch 10/64 loss: 0.3544055223464966
Batch 11/64 loss: 0.3576710820198059
Batch 12/64 loss: 0.3547924757003784
Batch 13/64 loss: 0.35526907444000244
Batch 14/64 loss: 0.3540925979614258
Batch 15/64 loss: 0.3535768985748291
Batch 16/64 loss: 0.35238736867904663
Batch 17/64 loss: 0.35456597805023193
Batch 18/64 loss: 0.3535250425338745
Batch 19/64 loss: 0.35768556594848633
Batch 20/64 loss: 0.35331249237060547
Batch 21/64 loss: 0.353360652923584
Batch 22/64 loss: 0.36210501194000244
Batch 23/64 loss: 0.3505852222442627
Batch 24/64 loss: 0.35658109188079834
Batch 25/64 loss: 0.35443633794784546
Batch 26/64 loss: 0.35752594470977783
Batch 27/64 loss: 0.3525547385215759
Batch 28/64 loss: 0.3596540093421936
Batch 29/64 loss: 0.3583402633666992
Batch 30/64 loss: 0.3505316972732544
Batch 31/64 loss: 0.3539363145828247
Batch 32/64 loss: 0.35616838932037354
Batch 33/64 loss: 0.3525201678276062
Batch 34/64 loss: 0.35502392053604126
Batch 35/64 loss: 0.3525289297103882
Batch 36/64 loss: 0.35331249237060547
Batch 37/64 loss: 0.35075265169143677
Batch 38/64 loss: 0.359302282333374
Batch 39/64 loss: 0.35174310207366943
Batch 40/64 loss: 0.3526981472969055
Batch 41/64 loss: 0.3525547385215759
Batch 42/64 loss: 0.3534199595451355
Batch 43/64 loss: 0.34969520568847656
Batch 44/64 loss: 0.35317909717559814
Batch 45/64 loss: 0.3539275527000427
Batch 46/64 loss: 0.35452520847320557
Batch 47/64 loss: 0.3550354838371277
Batch 48/64 loss: 0.35566556453704834
Batch 49/64 loss: 0.35506004095077515
Batch 50/64 loss: 0.3523637056350708
Batch 51/64 loss: 0.352594792842865
Batch 52/64 loss: 0.35197460651397705
Batch 53/64 loss: 0.3571370840072632
Batch 54/64 loss: 0.3594706058502197
Batch 55/64 loss: 0.3502398729324341
Batch 56/64 loss: 0.35439133644104004
Batch 57/64 loss: 0.3547394275665283
Batch 58/64 loss: 0.3500206470489502
Batch 59/64 loss: 0.35009658336639404
Batch 60/64 loss: 0.35686951875686646
Batch 61/64 loss: 0.35610508918762207
Batch 62/64 loss: 0.3539283275604248
Batch 63/64 loss: 0.3578970432281494
Batch 64/64 loss: 0.3515664339065552
Epoch 92  Train loss: 0.35419434332380106  Val loss: 0.3570392563990301
Epoch 93
-------------------------------
Batch 1/64 loss: 0.35501348972320557
Batch 2/64 loss: 0.3560065031051636
Batch 3/64 loss: 0.35009729862213135
Batch 4/64 loss: 0.3529677987098694
Batch 5/64 loss: 0.3532997965812683
Batch 6/64 loss: 0.35336244106292725
Batch 7/64 loss: 0.34745657444000244
Batch 8/64 loss: 0.3545219302177429
Batch 9/64 loss: 0.3581380248069763
Batch 10/64 loss: 0.3550916910171509
Batch 11/64 loss: 0.3519095778465271
Batch 12/64 loss: 0.3542870283126831
Batch 13/64 loss: 0.3520137071609497
Batch 14/64 loss: 0.3538297414779663
Batch 15/64 loss: 0.3541012406349182
Batch 16/64 loss: 0.3533167839050293
Batch 17/64 loss: 0.3528591990470886
Batch 18/64 loss: 0.3536381721496582
Batch 19/64 loss: 0.35546207427978516
Batch 20/64 loss: 0.3553961515426636
Batch 21/64 loss: 0.3526723384857178
Batch 22/64 loss: 0.355340838432312
Batch 23/64 loss: 0.3516300916671753
Batch 24/64 loss: 0.3500688076019287
Batch 25/64 loss: 0.35692811012268066
Batch 26/64 loss: 0.3533918261528015
Batch 27/64 loss: 0.3523193597793579
Batch 28/64 loss: 0.359529972076416
Batch 29/64 loss: 0.3513965606689453
Batch 30/64 loss: 0.357008695602417
Batch 31/64 loss: 0.35722196102142334
Batch 32/64 loss: 0.3504452705383301
Batch 33/64 loss: 0.3580399751663208
Batch 34/64 loss: 0.35540008544921875
Batch 35/64 loss: 0.3542051911354065
Batch 36/64 loss: 0.3513014316558838
Batch 37/64 loss: 0.35693198442459106
Batch 38/64 loss: 0.35263824462890625
Batch 39/64 loss: 0.350791335105896
Batch 40/64 loss: 0.35331451892852783
Batch 41/64 loss: 0.3504892587661743
Batch 42/64 loss: 0.35542768239974976
Batch 43/64 loss: 0.35885918140411377
Batch 44/64 loss: 0.3493754267692566
Batch 45/64 loss: 0.35174793004989624
Batch 46/64 loss: 0.3548485040664673
Batch 47/64 loss: 0.3531385660171509
Batch 48/64 loss: 0.3567441701889038
Batch 49/64 loss: 0.35369551181793213
Batch 50/64 loss: 0.3514362573623657
Batch 51/64 loss: 0.34566640853881836
Batch 52/64 loss: 0.3546186089515686
Batch 53/64 loss: 0.35340237617492676
Batch 54/64 loss: 0.3531455993652344
Batch 55/64 loss: 0.3552088737487793
Batch 56/64 loss: 0.3552449941635132
Batch 57/64 loss: 0.35197919607162476
Batch 58/64 loss: 0.3554742932319641
Batch 59/64 loss: 0.35148072242736816
Batch 60/64 loss: 0.35055339336395264
Batch 61/64 loss: 0.3545650243759155
Batch 62/64 loss: 0.3563280701637268
Batch 63/64 loss: 0.35322844982147217
Batch 64/64 loss: 0.35739773511886597
Epoch 93  Train loss: 0.35369494311949784  Val loss: 0.3566931860963094
Epoch 94
-------------------------------
Batch 1/64 loss: 0.3536437153816223
Batch 2/64 loss: 0.3536997437477112
Batch 3/64 loss: 0.353047251701355
Batch 4/64 loss: 0.3517799973487854
Batch 5/64 loss: 0.3539772033691406
Batch 6/64 loss: 0.34796667098999023
Batch 7/64 loss: 0.3529624342918396
Batch 8/64 loss: 0.35744160413742065
Batch 9/64 loss: 0.3565477132797241
Batch 10/64 loss: 0.35076773166656494
Batch 11/64 loss: 0.3559519052505493
Batch 12/64 loss: 0.3573805093765259
Batch 13/64 loss: 0.3559713363647461
Batch 14/64 loss: 0.3517714738845825
Batch 15/64 loss: 0.3522263765335083
Batch 16/64 loss: 0.3494341969490051
Batch 17/64 loss: 0.35555458068847656
Batch 18/64 loss: 0.35236603021621704
Batch 19/64 loss: 0.35149216651916504
Batch 20/64 loss: 0.356174111366272
Batch 21/64 loss: 0.3551517724990845
Batch 22/64 loss: 0.35247159004211426
Batch 23/64 loss: 0.3532786965370178
Batch 24/64 loss: 0.35498499870300293
Batch 25/64 loss: 0.35213279724121094
Batch 26/64 loss: 0.3555002212524414
Batch 27/64 loss: 0.3572307825088501
Batch 28/64 loss: 0.3565295934677124
Batch 29/64 loss: 0.35316169261932373
Batch 30/64 loss: 0.3503342270851135
Batch 31/64 loss: 0.3505527377128601
Batch 32/64 loss: 0.359668493270874
Batch 33/64 loss: 0.35448944568634033
Batch 34/64 loss: 0.34864556789398193
Batch 35/64 loss: 0.34827518463134766
Batch 36/64 loss: 0.35335612297058105
Batch 37/64 loss: 0.35165655612945557
Batch 38/64 loss: 0.35473155975341797
Batch 39/64 loss: 0.3508807420730591
Batch 40/64 loss: 0.3505716323852539
Batch 41/64 loss: 0.352871298789978
Batch 42/64 loss: 0.35440582036972046
Batch 43/64 loss: 0.35699963569641113
Batch 44/64 loss: 0.35132932662963867
Batch 45/64 loss: 0.35031938552856445
Batch 46/64 loss: 0.35357606410980225
Batch 47/64 loss: 0.3545650839805603
Batch 48/64 loss: 0.3536030650138855
Batch 49/64 loss: 0.352508544921875
Batch 50/64 loss: 0.35695457458496094
Batch 51/64 loss: 0.352988064289093
Batch 52/64 loss: 0.35678625106811523
Batch 53/64 loss: 0.35761070251464844
Batch 54/64 loss: 0.35556113719940186
Batch 55/64 loss: 0.35493969917297363
Batch 56/64 loss: 0.3588297367095947
Batch 57/64 loss: 0.35495656728744507
Batch 58/64 loss: 0.35518157482147217
Batch 59/64 loss: 0.3539193868637085
Batch 60/64 loss: 0.3565765619277954
Batch 61/64 loss: 0.35567426681518555
Batch 62/64 loss: 0.3512251377105713
Batch 63/64 loss: 0.3558785915374756
Batch 64/64 loss: 0.35278618335723877
Epoch 94  Train loss: 0.353813510315091  Val loss: 0.3571128517491711
Epoch 95
-------------------------------
Batch 1/64 loss: 0.3472299575805664
Batch 2/64 loss: 0.35461270809173584
Batch 3/64 loss: 0.3533392548561096
Batch 4/64 loss: 0.3553023338317871
Batch 5/64 loss: 0.3554917573928833
Batch 6/64 loss: 0.3511849641799927
Batch 7/64 loss: 0.3540114164352417
Batch 8/64 loss: 0.3561025857925415
Batch 9/64 loss: 0.3524434566497803
Batch 10/64 loss: 0.3539896011352539
Batch 11/64 loss: 0.3545558452606201
Batch 12/64 loss: 0.3500061631202698
Batch 13/64 loss: 0.35132038593292236
Batch 14/64 loss: 0.34853363037109375
Batch 15/64 loss: 0.3504345417022705
Batch 16/64 loss: 0.35323822498321533
Batch 17/64 loss: 0.35216736793518066
Batch 18/64 loss: 0.3558523654937744
Batch 19/64 loss: 0.3530764579772949
Batch 20/64 loss: 0.3549383878707886
Batch 21/64 loss: 0.3501092791557312
Batch 22/64 loss: 0.3540855050086975
Batch 23/64 loss: 0.354248046875
Batch 24/64 loss: 0.3562081456184387
Batch 25/64 loss: 0.34847164154052734
Batch 26/64 loss: 0.35116028785705566
Batch 27/64 loss: 0.35162317752838135
Batch 28/64 loss: 0.3496209979057312
Batch 29/64 loss: 0.3560600280761719
Batch 30/64 loss: 0.3499094247817993
Batch 31/64 loss: 0.3571051359176636
Batch 32/64 loss: 0.35582536458969116
Batch 33/64 loss: 0.35201168060302734
Batch 34/64 loss: 0.3573082685470581
Batch 35/64 loss: 0.35540497303009033
Batch 36/64 loss: 0.35218918323516846
Batch 37/64 loss: 0.35416901111602783
Batch 38/64 loss: 0.35753679275512695
Batch 39/64 loss: 0.35252511501312256
Batch 40/64 loss: 0.3517965078353882
Batch 41/64 loss: 0.3540840744972229
Batch 42/64 loss: 0.3561406135559082
Batch 43/64 loss: 0.35566073656082153
Batch 44/64 loss: 0.3531225323677063
Batch 45/64 loss: 0.35415589809417725
Batch 46/64 loss: 0.3512922525405884
Batch 47/64 loss: 0.35464155673980713
Batch 48/64 loss: 0.35585153102874756
Batch 49/64 loss: 0.3538089394569397
Batch 50/64 loss: 0.35386788845062256
Batch 51/64 loss: 0.35533738136291504
Batch 52/64 loss: 0.35306280851364136
Batch 53/64 loss: 0.3567945957183838
Batch 54/64 loss: 0.35475850105285645
Batch 55/64 loss: 0.3526686429977417
Batch 56/64 loss: 0.3560466766357422
Batch 57/64 loss: 0.35672593116760254
Batch 58/64 loss: 0.352422833442688
Batch 59/64 loss: 0.35224050283432007
Batch 60/64 loss: 0.35185712575912476
Batch 61/64 loss: 0.35675668716430664
Batch 62/64 loss: 0.35341525077819824
Batch 63/64 loss: 0.3530709743499756
Batch 64/64 loss: 0.35762864351272583
Epoch 95  Train loss: 0.3535875355496126  Val loss: 0.35625663553316567
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: 0.35442787408828735
Batch 2/64 loss: 0.3545512557029724
Batch 3/64 loss: 0.3507411479949951
Batch 4/64 loss: 0.35384035110473633
Batch 5/64 loss: 0.35222315788269043
Batch 6/64 loss: 0.3574397563934326
Batch 7/64 loss: 0.35776185989379883
Batch 8/64 loss: 0.34901905059814453
Batch 9/64 loss: 0.348574161529541
Batch 10/64 loss: 0.353374183177948
Batch 11/64 loss: 0.3494935631752014
Batch 12/64 loss: 0.3551595211029053
Batch 13/64 loss: 0.3548172116279602
Batch 14/64 loss: 0.3505868911743164
Batch 15/64 loss: 0.3560726046562195
Batch 16/64 loss: 0.3547528386116028
Batch 17/64 loss: 0.34831446409225464
Batch 18/64 loss: 0.35650020837783813
Batch 19/64 loss: 0.35093963146209717
Batch 20/64 loss: 0.35550224781036377
Batch 21/64 loss: 0.34850358963012695
Batch 22/64 loss: 0.35363489389419556
Batch 23/64 loss: 0.3505808115005493
Batch 24/64 loss: 0.3527343273162842
Batch 25/64 loss: 0.35283583402633667
Batch 26/64 loss: 0.35065823793411255
Batch 27/64 loss: 0.35190850496292114
Batch 28/64 loss: 0.3518660068511963
Batch 29/64 loss: 0.35491710901260376
Batch 30/64 loss: 0.3536352515220642
Batch 31/64 loss: 0.3551652431488037
Batch 32/64 loss: 0.3583500385284424
Batch 33/64 loss: 0.3539402484893799
Batch 34/64 loss: 0.35339879989624023
Batch 35/64 loss: 0.3532758951187134
Batch 36/64 loss: 0.3499540686607361
Batch 37/64 loss: 0.3523426055908203
Batch 38/64 loss: 0.3521972894668579
Batch 39/64 loss: 0.3528296947479248
Batch 40/64 loss: 0.3558138608932495
Batch 41/64 loss: 0.35358041524887085
Batch 42/64 loss: 0.3567086458206177
Batch 43/64 loss: 0.3578580617904663
Batch 44/64 loss: 0.35327303409576416
Batch 45/64 loss: 0.35130012035369873
Batch 46/64 loss: 0.3540310859680176
Batch 47/64 loss: 0.35749363899230957
Batch 48/64 loss: 0.3575560450553894
Batch 49/64 loss: 0.3526672124862671
Batch 50/64 loss: 0.3510013222694397
Batch 51/64 loss: 0.35482490062713623
Batch 52/64 loss: 0.35308146476745605
Batch 53/64 loss: 0.3532146215438843
Batch 54/64 loss: 0.3544262647628784
Batch 55/64 loss: 0.3521595597267151
Batch 56/64 loss: 0.35193943977355957
Batch 57/64 loss: 0.35669493675231934
Batch 58/64 loss: 0.35235679149627686
Batch 59/64 loss: 0.35038506984710693
Batch 60/64 loss: 0.3527258634567261
Batch 61/64 loss: 0.355655312538147
Batch 62/64 loss: 0.35374343395233154
Batch 63/64 loss: 0.35412144660949707
Batch 64/64 loss: 0.3505363464355469
Epoch 96  Train loss: 0.35335427826526117  Val loss: 0.3556335115760462
Saving best model, epoch: 96
Epoch 97
-------------------------------
Batch 1/64 loss: 0.35054337978363037
Batch 2/64 loss: 0.3519836664199829
Batch 3/64 loss: 0.3530818819999695
Batch 4/64 loss: 0.3520359992980957
Batch 5/64 loss: 0.354158878326416
Batch 6/64 loss: 0.3515547513961792
Batch 7/64 loss: 0.3507065773010254
Batch 8/64 loss: 0.35167694091796875
Batch 9/64 loss: 0.35334694385528564
Batch 10/64 loss: 0.35698509216308594
Batch 11/64 loss: 0.3525887727737427
Batch 12/64 loss: 0.35002434253692627
Batch 13/64 loss: 0.35088276863098145
Batch 14/64 loss: 0.35564160346984863
Batch 15/64 loss: 0.35304248332977295
Batch 16/64 loss: 0.35510098934173584
Batch 17/64 loss: 0.35356366634368896
Batch 18/64 loss: 0.35777103900909424
Batch 19/64 loss: 0.35375839471817017
Batch 20/64 loss: 0.353354811668396
Batch 21/64 loss: 0.35415828227996826
Batch 22/64 loss: 0.35076606273651123
Batch 23/64 loss: 0.35559582710266113
Batch 24/64 loss: 0.35518360137939453
Batch 25/64 loss: 0.35618793964385986
Batch 26/64 loss: 0.358478844165802
Batch 27/64 loss: 0.3458029627799988
Batch 28/64 loss: 0.3496444821357727
Batch 29/64 loss: 0.349223256111145
Batch 30/64 loss: 0.34938013553619385
Batch 31/64 loss: 0.34990769624710083
Batch 32/64 loss: 0.35003674030303955
Batch 33/64 loss: 0.35006725788116455
Batch 34/64 loss: 0.35008740425109863
Batch 35/64 loss: 0.35384416580200195
Batch 36/64 loss: 0.353931188583374
Batch 37/64 loss: 0.35058414936065674
Batch 38/64 loss: 0.35372793674468994
Batch 39/64 loss: 0.3585958480834961
Batch 40/64 loss: 0.3545176386833191
Batch 41/64 loss: 0.35186898708343506
Batch 42/64 loss: 0.356021523475647
Batch 43/64 loss: 0.35217857360839844
Batch 44/64 loss: 0.35182905197143555
Batch 45/64 loss: 0.3564091920852661
Batch 46/64 loss: 0.351138710975647
Batch 47/64 loss: 0.3565143346786499
Batch 48/64 loss: 0.3521992564201355
Batch 49/64 loss: 0.3526861071586609
Batch 50/64 loss: 0.35047394037246704
Batch 51/64 loss: 0.3493138551712036
Batch 52/64 loss: 0.3520083427429199
Batch 53/64 loss: 0.3553513288497925
Batch 54/64 loss: 0.35140466690063477
Batch 55/64 loss: 0.3554854393005371
Batch 56/64 loss: 0.35563814640045166
Batch 57/64 loss: 0.35304558277130127
Batch 58/64 loss: 0.3558741807937622
Batch 59/64 loss: 0.35572272539138794
Batch 60/64 loss: 0.35500580072402954
Batch 61/64 loss: 0.3530864715576172
Batch 62/64 loss: 0.35011863708496094
Batch 63/64 loss: 0.3535919189453125
Batch 64/64 loss: 0.3552699089050293
Epoch 97  Train loss: 0.35301872328215955  Val loss: 0.3558866998174346
Epoch 98
-------------------------------
Batch 1/64 loss: 0.3588753938674927
Batch 2/64 loss: 0.3520146608352661
Batch 3/64 loss: 0.354087769985199
Batch 4/64 loss: 0.35696136951446533
Batch 5/64 loss: 0.3545615077018738
Batch 6/64 loss: 0.35567158460617065
Batch 7/64 loss: 0.3522130250930786
Batch 8/64 loss: 0.3508046269416809
Batch 9/64 loss: 0.35527467727661133
Batch 10/64 loss: 0.35728877782821655
Batch 11/64 loss: 0.34943175315856934
Batch 12/64 loss: 0.3538358211517334
Batch 13/64 loss: 0.3520030975341797
Batch 14/64 loss: 0.35292959213256836
Batch 15/64 loss: 0.35504674911499023
Batch 16/64 loss: 0.35363733768463135
Batch 17/64 loss: 0.3542800545692444
Batch 18/64 loss: 0.34518200159072876
Batch 19/64 loss: 0.3536694049835205
Batch 20/64 loss: 0.35378849506378174
Batch 21/64 loss: 0.35233891010284424
Batch 22/64 loss: 0.35123252868652344
Batch 23/64 loss: 0.3513820171356201
Batch 24/64 loss: 0.3546750545501709
Batch 25/64 loss: 0.35536569356918335
Batch 26/64 loss: 0.3523519039154053
Batch 27/64 loss: 0.34879690408706665
Batch 28/64 loss: 0.35255980491638184
Batch 29/64 loss: 0.35557615756988525
Batch 30/64 loss: 0.34892064332962036
Batch 31/64 loss: 0.3514041304588318
Batch 32/64 loss: 0.35082894563674927
Batch 33/64 loss: 0.3550841212272644
Batch 34/64 loss: 0.3507753610610962
Batch 35/64 loss: 0.35509955883026123
Batch 36/64 loss: 0.3521917462348938
Batch 37/64 loss: 0.3524594306945801
Batch 38/64 loss: 0.35478144884109497
Batch 39/64 loss: 0.35238027572631836
Batch 40/64 loss: 0.3584800362586975
Batch 41/64 loss: 0.3526507616043091
Batch 42/64 loss: 0.35035240650177
Batch 43/64 loss: 0.3523064851760864
Batch 44/64 loss: 0.34981244802474976
Batch 45/64 loss: 0.3510258197784424
Batch 46/64 loss: 0.35195326805114746
Batch 47/64 loss: 0.3542700409889221
Batch 48/64 loss: 0.3547884225845337
Batch 49/64 loss: 0.3525627851486206
Batch 50/64 loss: 0.3452618718147278
Batch 51/64 loss: 0.3501232862472534
Batch 52/64 loss: 0.35240602493286133
Batch 53/64 loss: 0.3487932085990906
Batch 54/64 loss: 0.3527083992958069
Batch 55/64 loss: 0.35209953784942627
Batch 56/64 loss: 0.35393381118774414
Batch 57/64 loss: 0.35489654541015625
Batch 58/64 loss: 0.3545113801956177
Batch 59/64 loss: 0.3539830446243286
Batch 60/64 loss: 0.35422438383102417
Batch 61/64 loss: 0.3536723852157593
Batch 62/64 loss: 0.3546236753463745
Batch 63/64 loss: 0.3553711175918579
Batch 64/64 loss: 0.3512986898422241
Epoch 98  Train loss: 0.3529105490329219  Val loss: 0.35623951384292024
Epoch 99
-------------------------------
Batch 1/64 loss: 0.3507235646247864
Batch 2/64 loss: 0.3514413833618164
Batch 3/64 loss: 0.3551884889602661
Batch 4/64 loss: 0.3473126292228699
Batch 5/64 loss: 0.3534301519393921
Batch 6/64 loss: 0.3518404960632324
Batch 7/64 loss: 0.3528866171836853
Batch 8/64 loss: 0.35018402338027954
Batch 9/64 loss: 0.35318195819854736
Batch 10/64 loss: 0.3548666834831238
Batch 11/64 loss: 0.351712703704834
Batch 12/64 loss: 0.3514460325241089
Batch 13/64 loss: 0.35285651683807373
Batch 14/64 loss: 0.354022741317749
Batch 15/64 loss: 0.3534669876098633
Batch 16/64 loss: 0.35685133934020996
Batch 17/64 loss: 0.35434824228286743
Batch 18/64 loss: 0.35290831327438354
Batch 19/64 loss: 0.34863466024398804
Batch 20/64 loss: 0.3521546721458435
Batch 21/64 loss: 0.3484730124473572
Batch 22/64 loss: 0.35352808237075806
Batch 23/64 loss: 0.3542652130126953
Batch 24/64 loss: 0.3567271828651428
Batch 25/64 loss: 0.3476465940475464
Batch 26/64 loss: 0.35165345668792725
Batch 27/64 loss: 0.35286813974380493
Batch 28/64 loss: 0.3504076600074768
Batch 29/64 loss: 0.3489949703216553
Batch 30/64 loss: 0.36152952909469604
Batch 31/64 loss: 0.3582679033279419
Batch 32/64 loss: 0.35177022218704224
Batch 33/64 loss: 0.35281670093536377
Batch 34/64 loss: 0.3571566343307495
Batch 35/64 loss: 0.3529406785964966
Batch 36/64 loss: 0.35414445400238037
Batch 37/64 loss: 0.3501209020614624
Batch 38/64 loss: 0.354814350605011
Batch 39/64 loss: 0.3499559164047241
Batch 40/64 loss: 0.3547224998474121
Batch 41/64 loss: 0.3505350351333618
Batch 42/64 loss: 0.3487992286682129
Batch 43/64 loss: 0.35744237899780273
Batch 44/64 loss: 0.3457682728767395
Batch 45/64 loss: 0.3508322238922119
Batch 46/64 loss: 0.35470473766326904
Batch 47/64 loss: 0.3548617362976074
Batch 48/64 loss: 0.3527733087539673
Batch 49/64 loss: 0.3551567792892456
Batch 50/64 loss: 0.35356879234313965
Batch 51/64 loss: 0.3532218933105469
Batch 52/64 loss: 0.3589766025543213
Batch 53/64 loss: 0.3540278673171997
Batch 54/64 loss: 0.3530222177505493
Batch 55/64 loss: 0.3555713891983032
Batch 56/64 loss: 0.35005539655685425
Batch 57/64 loss: 0.3549187183380127
Batch 58/64 loss: 0.35136890411376953
Batch 59/64 loss: 0.35087406635284424
Batch 60/64 loss: 0.3503298759460449
Batch 61/64 loss: 0.3485056757926941
Batch 62/64 loss: 0.3547579050064087
Batch 63/64 loss: 0.34878313541412354
Batch 64/64 loss: 0.35714566707611084
Epoch 99  Train loss: 0.35276827765446084  Val loss: 0.3561718095209181
Epoch 100
-------------------------------
Batch 1/64 loss: 0.353179395198822
Batch 2/64 loss: 0.34803199768066406
Batch 3/64 loss: 0.35662102699279785
Batch 4/64 loss: 0.35451948642730713
Batch 5/64 loss: 0.35283100605010986
Batch 6/64 loss: 0.35025614500045776
Batch 7/64 loss: 0.34624743461608887
Batch 8/64 loss: 0.3558109998703003
Batch 9/64 loss: 0.3534824848175049
Batch 10/64 loss: 0.3474693298339844
Batch 11/64 loss: 0.34701573848724365
Batch 12/64 loss: 0.348111629486084
Batch 13/64 loss: 0.351826548576355
Batch 14/64 loss: 0.35052967071533203
Batch 15/64 loss: 0.35079461336135864
Batch 16/64 loss: 0.35585856437683105
Batch 17/64 loss: 0.35606706142425537
Batch 18/64 loss: 0.3525291681289673
Batch 19/64 loss: 0.3572126626968384
Batch 20/64 loss: 0.3482513427734375
Batch 21/64 loss: 0.3565385937690735
Batch 22/64 loss: 0.352901816368103
Batch 23/64 loss: 0.3517680764198303
Batch 24/64 loss: 0.3540812134742737
Batch 25/64 loss: 0.3530852794647217
Batch 26/64 loss: 0.349467396736145
Batch 27/64 loss: 0.3490675687789917
Batch 28/64 loss: 0.35308074951171875
Batch 29/64 loss: 0.35454612970352173
Batch 30/64 loss: 0.354000449180603
Batch 31/64 loss: 0.3542299270629883
Batch 32/64 loss: 0.3562871217727661
Batch 33/64 loss: 0.35224008560180664
Batch 34/64 loss: 0.35232824087142944
Batch 35/64 loss: 0.35248029232025146
Batch 36/64 loss: 0.3521416187286377
Batch 37/64 loss: 0.35151195526123047
Batch 38/64 loss: 0.3552730083465576
Batch 39/64 loss: 0.3556683659553528
Batch 40/64 loss: 0.3529047966003418
Batch 41/64 loss: 0.3520628809928894
Batch 42/64 loss: 0.3566879630088806
Batch 43/64 loss: 0.3498936891555786
Batch 44/64 loss: 0.3572729229927063
Batch 45/64 loss: 0.3499891757965088
Batch 46/64 loss: 0.3515123724937439
Batch 47/64 loss: 0.3501766324043274
Batch 48/64 loss: 0.35071903467178345
Batch 49/64 loss: 0.35284674167633057
Batch 50/64 loss: 0.35674333572387695
Batch 51/64 loss: 0.35289084911346436
Batch 52/64 loss: 0.3524053692817688
Batch 53/64 loss: 0.35124194622039795
Batch 54/64 loss: 0.3554670810699463
Batch 55/64 loss: 0.3543829917907715
Batch 56/64 loss: 0.35195839405059814
Batch 57/64 loss: 0.35543978214263916
Batch 58/64 loss: 0.3531860113143921
Batch 59/64 loss: 0.3573096990585327
Batch 60/64 loss: 0.35168248414993286
Batch 61/64 loss: 0.353797972202301
Batch 62/64 loss: 0.3540211319923401
Batch 63/64 loss: 0.3534485697746277
Batch 64/64 loss: 0.35173100233078003
Epoch 100  Train loss: 0.35277151804344326  Val loss: 0.3562288927458406
Epoch 101
-------------------------------
Batch 1/64 loss: 0.35172557830810547
Batch 2/64 loss: 0.35187745094299316
Batch 3/64 loss: 0.35302698612213135
Batch 4/64 loss: 0.35261034965515137
Batch 5/64 loss: 0.3536888360977173
Batch 6/64 loss: 0.3468679189682007
Batch 7/64 loss: 0.3505293130874634
Batch 8/64 loss: 0.3525625467300415
Batch 9/64 loss: 0.35234004259109497
Batch 10/64 loss: 0.3511478304862976
Batch 11/64 loss: 0.35477787256240845
Batch 12/64 loss: 0.35328495502471924
Batch 13/64 loss: 0.3534529209136963
Batch 14/64 loss: 0.35679465532302856
Batch 15/64 loss: 0.34987926483154297
Batch 16/64 loss: 0.35018694400787354
Batch 17/64 loss: 0.352924644947052
Batch 18/64 loss: 0.3532178997993469
Batch 19/64 loss: 0.3479907512664795
Batch 20/64 loss: 0.35555601119995117
Batch 21/64 loss: 0.3580002784729004
Batch 22/64 loss: 0.3515474796295166
Batch 23/64 loss: 0.3576352000236511
Batch 24/64 loss: 0.35421431064605713
Batch 25/64 loss: 0.35136914253234863
Batch 26/64 loss: 0.35063958168029785
Batch 27/64 loss: 0.3475855588912964
Batch 28/64 loss: 0.34858238697052
Batch 29/64 loss: 0.35202908515930176
Batch 30/64 loss: 0.3541160225868225
Batch 31/64 loss: 0.3589421510696411
Batch 32/64 loss: 0.3531232476234436
Batch 33/64 loss: 0.34840261936187744
Batch 34/64 loss: 0.3568040728569031
Batch 35/64 loss: 0.34802043437957764
Batch 36/64 loss: 0.3529103994369507
Batch 37/64 loss: 0.35387134552001953
Batch 38/64 loss: 0.3515596389770508
Batch 39/64 loss: 0.3573366403579712
Batch 40/64 loss: 0.35596102476119995
Batch 41/64 loss: 0.3549220561981201
Batch 42/64 loss: 0.3518550395965576
Batch 43/64 loss: 0.3519328832626343
Batch 44/64 loss: 0.3545339107513428
Batch 45/64 loss: 0.3593800663948059
Batch 46/64 loss: 0.35126662254333496
Batch 47/64 loss: 0.3529953956604004
Batch 48/64 loss: 0.35234498977661133
Batch 49/64 loss: 0.3482314348220825
Batch 50/64 loss: 0.35660821199417114
Batch 51/64 loss: 0.35127705335617065
Batch 52/64 loss: 0.35115718841552734
Batch 53/64 loss: 0.35309475660324097
Batch 54/64 loss: 0.349780797958374
Batch 55/64 loss: 0.35031235218048096
Batch 56/64 loss: 0.3514837622642517
Batch 57/64 loss: 0.35231173038482666
Batch 58/64 loss: 0.35358482599258423
Batch 59/64 loss: 0.3533031940460205
Batch 60/64 loss: 0.35315680503845215
Batch 61/64 loss: 0.352675199508667
Batch 62/64 loss: 0.3547612428665161
Batch 63/64 loss: 0.3514517545700073
Batch 64/64 loss: 0.3486524224281311
Epoch 101  Train loss: 0.3526431997617086  Val loss: 0.3567995025529894
Epoch 102
-------------------------------
Batch 1/64 loss: 0.3545985221862793
Batch 2/64 loss: 0.35842907428741455
Batch 3/64 loss: 0.3485392928123474
Batch 4/64 loss: 0.3516080379486084
Batch 5/64 loss: 0.3478659391403198
Batch 6/64 loss: 0.3524172306060791
Batch 7/64 loss: 0.35347115993499756
Batch 8/64 loss: 0.34931671619415283
Batch 9/64 loss: 0.3570411205291748
Batch 10/64 loss: 0.3493533134460449
Batch 11/64 loss: 0.3509882688522339
Batch 12/64 loss: 0.35445553064346313
Batch 13/64 loss: 0.3560541868209839
Batch 14/64 loss: 0.35015320777893066
Batch 15/64 loss: 0.35091841220855713
Batch 16/64 loss: 0.35598480701446533
Batch 17/64 loss: 0.3482632637023926
Batch 18/64 loss: 0.3568456768989563
Batch 19/64 loss: 0.35931897163391113
Batch 20/64 loss: 0.3532257676124573
Batch 21/64 loss: 0.35047709941864014
Batch 22/64 loss: 0.3582942485809326
Batch 23/64 loss: 0.35732126235961914
Batch 24/64 loss: 0.3466078042984009
Batch 25/64 loss: 0.35436195135116577
Batch 26/64 loss: 0.3548564910888672
Batch 27/64 loss: 0.3542670011520386
Batch 28/64 loss: 0.35268938541412354
Batch 29/64 loss: 0.35613906383514404
Batch 30/64 loss: 0.3526962995529175
Batch 31/64 loss: 0.3543410897254944
Batch 32/64 loss: 0.35348832607269287
Batch 33/64 loss: 0.355965793132782
Batch 34/64 loss: 0.3519552946090698
Batch 35/64 loss: 0.35381215810775757
Batch 36/64 loss: 0.3503068685531616
Batch 37/64 loss: 0.35256683826446533
Batch 38/64 loss: 0.3506655693054199
Batch 39/64 loss: 0.34755074977874756
Batch 40/64 loss: 0.3529285192489624
Batch 41/64 loss: 0.3549000024795532
Batch 42/64 loss: 0.35415905714035034
Batch 43/64 loss: 0.35086846351623535
Batch 44/64 loss: 0.351648211479187
Batch 45/64 loss: 0.34992289543151855
Batch 46/64 loss: 0.3543860912322998
Batch 47/64 loss: 0.3515183925628662
Batch 48/64 loss: 0.3521449565887451
Batch 49/64 loss: 0.3493245840072632
Batch 50/64 loss: 0.35056978464126587
Batch 51/64 loss: 0.3548123836517334
Batch 52/64 loss: 0.3539857864379883
Batch 53/64 loss: 0.35217219591140747
Batch 54/64 loss: 0.3517007827758789
Batch 55/64 loss: 0.35214269161224365
Batch 56/64 loss: 0.3520932197570801
Batch 57/64 loss: 0.35303711891174316
Batch 58/64 loss: 0.3494507670402527
Batch 59/64 loss: 0.3525654077529907
Batch 60/64 loss: 0.3486180305480957
Batch 61/64 loss: 0.3548535704612732
Batch 62/64 loss: 0.35639870166778564
Batch 63/64 loss: 0.3509753942489624
Batch 64/64 loss: 0.3552607297897339
Epoch 102  Train loss: 0.3527660290400187  Val loss: 0.35645593646465706
Epoch 103
-------------------------------
Batch 1/64 loss: 0.35314393043518066
Batch 2/64 loss: 0.3539140224456787
Batch 3/64 loss: 0.349226176738739
Batch 4/64 loss: 0.3507380485534668
Batch 5/64 loss: 0.3475669026374817
Batch 6/64 loss: 0.3527848720550537
Batch 7/64 loss: 0.35259974002838135
Batch 8/64 loss: 0.3553297519683838
Batch 9/64 loss: 0.3466038107872009
Batch 10/64 loss: 0.3530558943748474
Batch 11/64 loss: 0.35584378242492676
Batch 12/64 loss: 0.3471803665161133
Batch 13/64 loss: 0.3543330430984497
Batch 14/64 loss: 0.35266590118408203
Batch 15/64 loss: 0.3471231460571289
Batch 16/64 loss: 0.34669554233551025
Batch 17/64 loss: 0.3502567410469055
Batch 18/64 loss: 0.3537519574165344
Batch 19/64 loss: 0.3491162657737732
Batch 20/64 loss: 0.35108035802841187
Batch 21/64 loss: 0.3499470353126526
Batch 22/64 loss: 0.3562120795249939
Batch 23/64 loss: 0.3532346487045288
Batch 24/64 loss: 0.349500834941864
Batch 25/64 loss: 0.3545548915863037
Batch 26/64 loss: 0.35248905420303345
Batch 27/64 loss: 0.35127294063568115
Batch 28/64 loss: 0.3513423204421997
Batch 29/64 loss: 0.355168879032135
Batch 30/64 loss: 0.34960830211639404
Batch 31/64 loss: 0.3543379306793213
Batch 32/64 loss: 0.34885358810424805
Batch 33/64 loss: 0.34768491983413696
Batch 34/64 loss: 0.35501980781555176
Batch 35/64 loss: 0.353212833404541
Batch 36/64 loss: 0.3484107255935669
Batch 37/64 loss: 0.3550300598144531
Batch 38/64 loss: 0.35727375745773315
Batch 39/64 loss: 0.35352230072021484
Batch 40/64 loss: 0.3495718836784363
Batch 41/64 loss: 0.34954726696014404
Batch 42/64 loss: 0.35356569290161133
Batch 43/64 loss: 0.35284411907196045
Batch 44/64 loss: 0.3510080575942993
Batch 45/64 loss: 0.35381555557250977
Batch 46/64 loss: 0.35433292388916016
Batch 47/64 loss: 0.3524174690246582
Batch 48/64 loss: 0.3498225212097168
Batch 49/64 loss: 0.3592942953109741
Batch 50/64 loss: 0.35382312536239624
Batch 51/64 loss: 0.35108280181884766
Batch 52/64 loss: 0.3498772978782654
Batch 53/64 loss: 0.3548547029495239
Batch 54/64 loss: 0.35595768690109253
Batch 55/64 loss: 0.3497285842895508
Batch 56/64 loss: 0.3569759130477905
Batch 57/64 loss: 0.3483842611312866
Batch 58/64 loss: 0.35500097274780273
Batch 59/64 loss: 0.3549067974090576
Batch 60/64 loss: 0.35505497455596924
Batch 61/64 loss: 0.3566296100616455
Batch 62/64 loss: 0.3504079580307007
Batch 63/64 loss: 0.3563743233680725
Batch 64/64 loss: 0.3520665168762207
Epoch 103  Train loss: 0.352298287784352  Val loss: 0.35537986984777287
Saving best model, epoch: 103
Epoch 104
-------------------------------
Batch 1/64 loss: 0.3523977994918823
Batch 2/64 loss: 0.354147732257843
Batch 3/64 loss: 0.35029304027557373
Batch 4/64 loss: 0.3506268262863159
Batch 5/64 loss: 0.353127121925354
Batch 6/64 loss: 0.352573037147522
Batch 7/64 loss: 0.35887110233306885
Batch 8/64 loss: 0.3524309992790222
Batch 9/64 loss: 0.35313236713409424
Batch 10/64 loss: 0.34852147102355957
Batch 11/64 loss: 0.35047417879104614
Batch 12/64 loss: 0.3546329736709595
Batch 13/64 loss: 0.35567736625671387
Batch 14/64 loss: 0.3537864685058594
Batch 15/64 loss: 0.35098809003829956
Batch 16/64 loss: 0.35586076974868774
Batch 17/64 loss: 0.3516642451286316
Batch 18/64 loss: 0.34492671489715576
Batch 19/64 loss: 0.34925055503845215
Batch 20/64 loss: 0.3473891019821167
Batch 21/64 loss: 0.35591351985931396
Batch 22/64 loss: 0.34912192821502686
Batch 23/64 loss: 0.349331259727478
Batch 24/64 loss: 0.3581048250198364
Batch 25/64 loss: 0.357339084148407
Batch 26/64 loss: 0.3535555601119995
Batch 27/64 loss: 0.3523569107055664
Batch 28/64 loss: 0.3551974892616272
Batch 29/64 loss: 0.3547934889793396
Batch 30/64 loss: 0.352469801902771
Batch 31/64 loss: 0.35104525089263916
Batch 32/64 loss: 0.34909021854400635
Batch 33/64 loss: 0.3560703992843628
Batch 34/64 loss: 0.3474773168563843
Batch 35/64 loss: 0.35206592082977295
Batch 36/64 loss: 0.3545492887496948
Batch 37/64 loss: 0.3553280830383301
Batch 38/64 loss: 0.3505181074142456
Batch 39/64 loss: 0.3542269468307495
Batch 40/64 loss: 0.35263383388519287
Batch 41/64 loss: 0.35292673110961914
Batch 42/64 loss: 0.3530251979827881
Batch 43/64 loss: 0.3489076495170593
Batch 44/64 loss: 0.3541618585586548
Batch 45/64 loss: 0.34574049711227417
Batch 46/64 loss: 0.3549158573150635
Batch 47/64 loss: 0.35267865657806396
Batch 48/64 loss: 0.35117900371551514
Batch 49/64 loss: 0.34828466176986694
Batch 50/64 loss: 0.3501967191696167
Batch 51/64 loss: 0.3482070565223694
Batch 52/64 loss: 0.3539695739746094
Batch 53/64 loss: 0.3507838249206543
Batch 54/64 loss: 0.35028207302093506
Batch 55/64 loss: 0.35133957862854004
Batch 56/64 loss: 0.34831732511520386
Batch 57/64 loss: 0.35149216651916504
Batch 58/64 loss: 0.3520978093147278
Batch 59/64 loss: 0.3469129204750061
Batch 60/64 loss: 0.3502427339553833
Batch 61/64 loss: 0.3516616225242615
Batch 62/64 loss: 0.3522009253501892
Batch 63/64 loss: 0.3584093451499939
Batch 64/64 loss: 0.34818482398986816
Epoch 104  Train loss: 0.35201621336095473  Val loss: 0.3557665059246968
Epoch 105
-------------------------------
Batch 1/64 loss: 0.35006439685821533
Batch 2/64 loss: 0.35518527030944824
Batch 3/64 loss: 0.3523533344268799
Batch 4/64 loss: 0.3556535840034485
Batch 5/64 loss: 0.3540242910385132
Batch 6/64 loss: 0.3526111841201782
Batch 7/64 loss: 0.3536250591278076
Batch 8/64 loss: 0.3521706461906433
Batch 9/64 loss: 0.35241907835006714
Batch 10/64 loss: 0.34851861000061035
Batch 11/64 loss: 0.35516786575317383
Batch 12/64 loss: 0.3538197875022888
Batch 13/64 loss: 0.3485446572303772
Batch 14/64 loss: 0.35395801067352295
Batch 15/64 loss: 0.3524829149246216
Batch 16/64 loss: 0.35331541299819946
Batch 17/64 loss: 0.3514683246612549
Batch 18/64 loss: 0.35360968112945557
Batch 19/64 loss: 0.3560163378715515
Batch 20/64 loss: 0.3500519394874573
Batch 21/64 loss: 0.35331594944000244
Batch 22/64 loss: 0.354852557182312
Batch 23/64 loss: 0.350994348526001
Batch 24/64 loss: 0.3524068593978882
Batch 25/64 loss: 0.34906673431396484
Batch 26/64 loss: 0.3512529134750366
Batch 27/64 loss: 0.3496849536895752
Batch 28/64 loss: 0.35314440727233887
Batch 29/64 loss: 0.3517777919769287
Batch 30/64 loss: 0.34667932987213135
Batch 31/64 loss: 0.35346561670303345
Batch 32/64 loss: 0.35302090644836426
Batch 33/64 loss: 0.3517646789550781
Batch 34/64 loss: 0.34876394271850586
Batch 35/64 loss: 0.3459322452545166
Batch 36/64 loss: 0.3497312068939209
Batch 37/64 loss: 0.35455071926116943
Batch 38/64 loss: 0.3506535291671753
Batch 39/64 loss: 0.35280585289001465
Batch 40/64 loss: 0.3506380319595337
Batch 41/64 loss: 0.35255497694015503
Batch 42/64 loss: 0.3499266505241394
Batch 43/64 loss: 0.35276973247528076
Batch 44/64 loss: 0.34858471155166626
Batch 45/64 loss: 0.3518146872520447
Batch 46/64 loss: 0.3560672998428345
Batch 47/64 loss: 0.34920936822891235
Batch 48/64 loss: 0.34923166036605835
Batch 49/64 loss: 0.3531970977783203
Batch 50/64 loss: 0.3539501428604126
Batch 51/64 loss: 0.3484029769897461
Batch 52/64 loss: 0.35553133487701416
Batch 53/64 loss: 0.3524322509765625
Batch 54/64 loss: 0.3564510941505432
Batch 55/64 loss: 0.35191792249679565
Batch 56/64 loss: 0.3555535674095154
Batch 57/64 loss: 0.3507583737373352
Batch 58/64 loss: 0.3527054786682129
Batch 59/64 loss: 0.35170793533325195
Batch 60/64 loss: 0.35237783193588257
Batch 61/64 loss: 0.3564821481704712
Batch 62/64 loss: 0.3529171943664551
Batch 63/64 loss: 0.35459673404693604
Batch 64/64 loss: 0.34913796186447144
Epoch 105  Train loss: 0.35216560948128794  Val loss: 0.3556688948185583
Epoch 106
-------------------------------
Batch 1/64 loss: 0.3570789098739624
Batch 2/64 loss: 0.35302895307540894
Batch 3/64 loss: 0.35671722888946533
Batch 4/64 loss: 0.35404419898986816
Batch 5/64 loss: 0.35096192359924316
Batch 6/64 loss: 0.35394275188446045
Batch 7/64 loss: 0.3540336489677429
Batch 8/64 loss: 0.34844374656677246
Batch 9/64 loss: 0.3465005159378052
Batch 10/64 loss: 0.34998494386672974
Batch 11/64 loss: 0.35107743740081787
Batch 12/64 loss: 0.34797370433807373
Batch 13/64 loss: 0.35138481855392456
Batch 14/64 loss: 0.350006639957428
Batch 15/64 loss: 0.354439377784729
Batch 16/64 loss: 0.3529256582260132
Batch 17/64 loss: 0.35609573125839233
Batch 18/64 loss: 0.35156863927841187
Batch 19/64 loss: 0.35830825567245483
Batch 20/64 loss: 0.34830009937286377
Batch 21/64 loss: 0.3525125980377197
Batch 22/64 loss: 0.34930408000946045
Batch 23/64 loss: 0.34771430492401123
Batch 24/64 loss: 0.3482130765914917
Batch 25/64 loss: 0.3497735261917114
Batch 26/64 loss: 0.3505589962005615
Batch 27/64 loss: 0.3557325601577759
Batch 28/64 loss: 0.35749852657318115
Batch 29/64 loss: 0.3509141206741333
Batch 30/64 loss: 0.3520098924636841
Batch 31/64 loss: 0.35235369205474854
Batch 32/64 loss: 0.354159414768219
Batch 33/64 loss: 0.35632050037384033
Batch 34/64 loss: 0.35234421491622925
Batch 35/64 loss: 0.35041314363479614
Batch 36/64 loss: 0.3521420955657959
Batch 37/64 loss: 0.3489304780960083
Batch 38/64 loss: 0.354819655418396
Batch 39/64 loss: 0.3554595708847046
Batch 40/64 loss: 0.35445892810821533
Batch 41/64 loss: 0.3489501476287842
Batch 42/64 loss: 0.3533915877342224
Batch 43/64 loss: 0.3531506061553955
Batch 44/64 loss: 0.3508923053741455
Batch 45/64 loss: 0.35052698850631714
Batch 46/64 loss: 0.3535701632499695
Batch 47/64 loss: 0.3528599143028259
Batch 48/64 loss: 0.3534330725669861
Batch 49/64 loss: 0.35115742683410645
Batch 50/64 loss: 0.34974008798599243
Batch 51/64 loss: 0.3444121479988098
Batch 52/64 loss: 0.3464280366897583
Batch 53/64 loss: 0.35404956340789795
Batch 54/64 loss: 0.35136735439300537
Batch 55/64 loss: 0.3532670736312866
Batch 56/64 loss: 0.35417068004608154
Batch 57/64 loss: 0.35445690155029297
Batch 58/64 loss: 0.3523826003074646
Batch 59/64 loss: 0.3540500998497009
Batch 60/64 loss: 0.35081374645233154
Batch 61/64 loss: 0.35572242736816406
Batch 62/64 loss: 0.35080504417419434
Batch 63/64 loss: 0.349861204624176
Batch 64/64 loss: 0.3467429280281067
Epoch 106  Train loss: 0.3520308538979175  Val loss: 0.35434801635873275
Saving best model, epoch: 106
Epoch 107
-------------------------------
Batch 1/64 loss: 0.35135114192962646
Batch 2/64 loss: 0.35168230533599854
Batch 3/64 loss: 0.3501189351081848
Batch 4/64 loss: 0.3565787076950073
Batch 5/64 loss: 0.3495721220970154
Batch 6/64 loss: 0.35415780544281006
Batch 7/64 loss: 0.3513706922531128
Batch 8/64 loss: 0.3472806215286255
Batch 9/64 loss: 0.34574127197265625
Batch 10/64 loss: 0.35208022594451904
Batch 11/64 loss: 0.3509640097618103
Batch 12/64 loss: 0.3541380763053894
Batch 13/64 loss: 0.35266101360321045
Batch 14/64 loss: 0.34769582748413086
Batch 15/64 loss: 0.35423707962036133
Batch 16/64 loss: 0.34698235988616943
Batch 17/64 loss: 0.3500349521636963
Batch 18/64 loss: 0.3508070707321167
Batch 19/64 loss: 0.3527633547782898
Batch 20/64 loss: 0.3543602228164673
Batch 21/64 loss: 0.3484055995941162
Batch 22/64 loss: 0.3499513268470764
Batch 23/64 loss: 0.3523317575454712
Batch 24/64 loss: 0.35112935304641724
Batch 25/64 loss: 0.35128188133239746
Batch 26/64 loss: 0.3526630401611328
Batch 27/64 loss: 0.3528801202774048
Batch 28/64 loss: 0.3511812686920166
Batch 29/64 loss: 0.3536565899848938
Batch 30/64 loss: 0.35496771335601807
Batch 31/64 loss: 0.3506659269332886
Batch 32/64 loss: 0.349848210811615
Batch 33/64 loss: 0.35286152362823486
Batch 34/64 loss: 0.35092371702194214
Batch 35/64 loss: 0.3528926372528076
Batch 36/64 loss: 0.35291075706481934
Batch 37/64 loss: 0.35037338733673096
Batch 38/64 loss: 0.35289466381073
Batch 39/64 loss: 0.35487931966781616
Batch 40/64 loss: 0.3505314588546753
Batch 41/64 loss: 0.3500223159790039
Batch 42/64 loss: 0.35491251945495605
Batch 43/64 loss: 0.34947365522384644
Batch 44/64 loss: 0.3502160310745239
Batch 45/64 loss: 0.3534742593765259
Batch 46/64 loss: 0.34865957498550415
Batch 47/64 loss: 0.34880685806274414
Batch 48/64 loss: 0.3521157503128052
Batch 49/64 loss: 0.3535945415496826
Batch 50/64 loss: 0.3520718812942505
Batch 51/64 loss: 0.34432846307754517
Batch 52/64 loss: 0.35057902336120605
Batch 53/64 loss: 0.3480503559112549
Batch 54/64 loss: 0.3540881872177124
Batch 55/64 loss: 0.3557356595993042
Batch 56/64 loss: 0.3497185707092285
Batch 57/64 loss: 0.35127484798431396
Batch 58/64 loss: 0.34589922428131104
Batch 59/64 loss: 0.35447633266448975
Batch 60/64 loss: 0.35015928745269775
Batch 61/64 loss: 0.35186147689819336
Batch 62/64 loss: 0.3531814217567444
Batch 63/64 loss: 0.35494327545166016
Batch 64/64 loss: 0.3502296209335327
Epoch 107  Train loss: 0.351405863200917  Val loss: 0.35530921233069035
Epoch 108
-------------------------------
Batch 1/64 loss: 0.35236817598342896
Batch 2/64 loss: 0.3511376976966858
Batch 3/64 loss: 0.346662700176239
Batch 4/64 loss: 0.3486338257789612
Batch 5/64 loss: 0.3565600514411926
Batch 6/64 loss: 0.3544018268585205
Batch 7/64 loss: 0.35354435443878174
Batch 8/64 loss: 0.3526022434234619
Batch 9/64 loss: 0.3533485531806946
Batch 10/64 loss: 0.3489275574684143
Batch 11/64 loss: 0.34907805919647217
Batch 12/64 loss: 0.3535887598991394
Batch 13/64 loss: 0.35273921489715576
Batch 14/64 loss: 0.35634946823120117
Batch 15/64 loss: 0.3480767607688904
Batch 16/64 loss: 0.3531794548034668
Batch 17/64 loss: 0.34703707695007324
Batch 18/64 loss: 0.34827542304992676
Batch 19/64 loss: 0.3465464115142822
Batch 20/64 loss: 0.3505949378013611
Batch 21/64 loss: 0.35211455821990967
Batch 22/64 loss: 0.3534454107284546
Batch 23/64 loss: 0.3479938507080078
Batch 24/64 loss: 0.353743314743042
Batch 25/64 loss: 0.3522182106971741
Batch 26/64 loss: 0.3522758483886719
Batch 27/64 loss: 0.3491617441177368
Batch 28/64 loss: 0.35195690393447876
Batch 29/64 loss: 0.34978151321411133
Batch 30/64 loss: 0.35342133045196533
Batch 31/64 loss: 0.3507659435272217
Batch 32/64 loss: 0.3487471342086792
Batch 33/64 loss: 0.3484930992126465
Batch 34/64 loss: 0.34960871934890747
Batch 35/64 loss: 0.3520205616950989
Batch 36/64 loss: 0.35139065980911255
Batch 37/64 loss: 0.3548797369003296
Batch 38/64 loss: 0.3503442406654358
Batch 39/64 loss: 0.35274451971054077
Batch 40/64 loss: 0.35556191205978394
Batch 41/64 loss: 0.3459988832473755
Batch 42/64 loss: 0.3485817313194275
Batch 43/64 loss: 0.3434322476387024
Batch 44/64 loss: 0.35592448711395264
Batch 45/64 loss: 0.34987545013427734
Batch 46/64 loss: 0.35154569149017334
Batch 47/64 loss: 0.3596358895301819
Batch 48/64 loss: 0.3530803918838501
Batch 49/64 loss: 0.3542346954345703
Batch 50/64 loss: 0.34905481338500977
Batch 51/64 loss: 0.35151779651641846
Batch 52/64 loss: 0.3546111583709717
Batch 53/64 loss: 0.3531985878944397
Batch 54/64 loss: 0.3521876931190491
Batch 55/64 loss: 0.3521672487258911
Batch 56/64 loss: 0.35032975673675537
Batch 57/64 loss: 0.35059356689453125
Batch 58/64 loss: 0.35011905431747437
Batch 59/64 loss: 0.3475475311279297
Batch 60/64 loss: 0.34869885444641113
Batch 61/64 loss: 0.35943371057510376
Batch 62/64 loss: 0.34891748428344727
Batch 63/64 loss: 0.3571006655693054
Batch 64/64 loss: 0.3466961979866028
Epoch 108  Train loss: 0.351405981241488  Val loss: 0.3552446912244423
Epoch 109
-------------------------------
Batch 1/64 loss: 0.3574635982513428
Batch 2/64 loss: 0.35199570655822754
Batch 3/64 loss: 0.35111743211746216
Batch 4/64 loss: 0.35186898708343506
Batch 5/64 loss: 0.34672701358795166
Batch 6/64 loss: 0.35099971294403076
Batch 7/64 loss: 0.34809309244155884
Batch 8/64 loss: 0.3525024652481079
Batch 9/64 loss: 0.35724496841430664
Batch 10/64 loss: 0.35534489154815674
Batch 11/64 loss: 0.3486672639846802
Batch 12/64 loss: 0.3501495122909546
Batch 13/64 loss: 0.35229432582855225
Batch 14/64 loss: 0.35345911979675293
Batch 15/64 loss: 0.3464844226837158
Batch 16/64 loss: 0.35092759132385254
Batch 17/64 loss: 0.3501962423324585
Batch 18/64 loss: 0.3549971580505371
Batch 19/64 loss: 0.35155415534973145
Batch 20/64 loss: 0.3496755361557007
Batch 21/64 loss: 0.35685116052627563
Batch 22/64 loss: 0.3511829376220703
Batch 23/64 loss: 0.35080665349960327
Batch 24/64 loss: 0.3481774926185608
Batch 25/64 loss: 0.3541490435600281
Batch 26/64 loss: 0.34970933198928833
Batch 27/64 loss: 0.3554829955101013
Batch 28/64 loss: 0.3497357964515686
Batch 29/64 loss: 0.35428744554519653
Batch 30/64 loss: 0.3526793122291565
Batch 31/64 loss: 0.35059356689453125
Batch 32/64 loss: 0.34774142503738403
Batch 33/64 loss: 0.3495367765426636
Batch 34/64 loss: 0.35277676582336426
Batch 35/64 loss: 0.34847748279571533
Batch 36/64 loss: 0.35200220346450806
Batch 37/64 loss: 0.35246580839157104
Batch 38/64 loss: 0.35367894172668457
Batch 39/64 loss: 0.353241503238678
Batch 40/64 loss: 0.34755194187164307
Batch 41/64 loss: 0.3489672541618347
Batch 42/64 loss: 0.3505028486251831
Batch 43/64 loss: 0.3514314889907837
Batch 44/64 loss: 0.3534301519393921
Batch 45/64 loss: 0.3513685464859009
Batch 46/64 loss: 0.3509766459465027
Batch 47/64 loss: 0.3506167531013489
Batch 48/64 loss: 0.35371822118759155
Batch 49/64 loss: 0.3531230688095093
Batch 50/64 loss: 0.3482259511947632
Batch 51/64 loss: 0.3479832410812378
Batch 52/64 loss: 0.35203123092651367
Batch 53/64 loss: 0.34798628091812134
Batch 54/64 loss: 0.3519926071166992
Batch 55/64 loss: 0.35060638189315796
Batch 56/64 loss: 0.350482702255249
Batch 57/64 loss: 0.3514746427536011
Batch 58/64 loss: 0.34954833984375
Batch 59/64 loss: 0.3482072353363037
Batch 60/64 loss: 0.3504701852798462
Batch 61/64 loss: 0.3484983444213867
Batch 62/64 loss: 0.34813767671585083
Batch 63/64 loss: 0.35694968700408936
Batch 64/64 loss: 0.34282630681991577
Epoch 109  Train loss: 0.35116456466562607  Val loss: 0.3547126935519713
Epoch 110
-------------------------------
Batch 1/64 loss: 0.3510795831680298
Batch 2/64 loss: 0.3536571264266968
Batch 3/64 loss: 0.34658849239349365
Batch 4/64 loss: 0.3538164496421814
Batch 5/64 loss: 0.35103678703308105
Batch 6/64 loss: 0.3512861132621765
Batch 7/64 loss: 0.34915244579315186
Batch 8/64 loss: 0.34586435556411743
Batch 9/64 loss: 0.34577155113220215
Batch 10/64 loss: 0.34952569007873535
Batch 11/64 loss: 0.347714364528656
Batch 12/64 loss: 0.3540610074996948
Batch 13/64 loss: 0.3514225482940674
Batch 14/64 loss: 0.3452831506729126
Batch 15/64 loss: 0.3533872961997986
Batch 16/64 loss: 0.35025954246520996
Batch 17/64 loss: 0.3512688875198364
Batch 18/64 loss: 0.3486367464065552
Batch 19/64 loss: 0.34443092346191406
Batch 20/64 loss: 0.34868478775024414
Batch 21/64 loss: 0.35642337799072266
Batch 22/64 loss: 0.3504108190536499
Batch 23/64 loss: 0.3490973711013794
Batch 24/64 loss: 0.35310059785842896
Batch 25/64 loss: 0.3460543751716614
Batch 26/64 loss: 0.34934884309768677
Batch 27/64 loss: 0.3474653959274292
Batch 28/64 loss: 0.35115379095077515
Batch 29/64 loss: 0.35603904724121094
Batch 30/64 loss: 0.3523426055908203
Batch 31/64 loss: 0.35334062576293945
Batch 32/64 loss: 0.3510197401046753
Batch 33/64 loss: 0.3504764437675476
Batch 34/64 loss: 0.35348695516586304
Batch 35/64 loss: 0.35254913568496704
Batch 36/64 loss: 0.35256171226501465
Batch 37/64 loss: 0.3520304560661316
Batch 38/64 loss: 0.35059213638305664
Batch 39/64 loss: 0.3464549779891968
Batch 40/64 loss: 0.35699671506881714
Batch 41/64 loss: 0.35502827167510986
Batch 42/64 loss: 0.3509711027145386
Batch 43/64 loss: 0.34889066219329834
Batch 44/64 loss: 0.3513554334640503
Batch 45/64 loss: 0.3504899740219116
Batch 46/64 loss: 0.35136115550994873
Batch 47/64 loss: 0.34810560941696167
Batch 48/64 loss: 0.3492181897163391
Batch 49/64 loss: 0.3541233539581299
Batch 50/64 loss: 0.34784770011901855
Batch 51/64 loss: 0.35140472650527954
Batch 52/64 loss: 0.3515758514404297
Batch 53/64 loss: 0.35205966234207153
Batch 54/64 loss: 0.3513437509536743
Batch 55/64 loss: 0.34889209270477295
Batch 56/64 loss: 0.3549521565437317
Batch 57/64 loss: 0.35236096382141113
Batch 58/64 loss: 0.35537683963775635
Batch 59/64 loss: 0.35536813735961914
Batch 60/64 loss: 0.3520849943161011
Batch 61/64 loss: 0.34672844409942627
Batch 62/64 loss: 0.35494834184646606
Batch 63/64 loss: 0.35643470287323
Batch 64/64 loss: 0.34914326667785645
Epoch 110  Train loss: 0.3510063143337474  Val loss: 0.35529033015274103
Epoch 111
-------------------------------
Batch 1/64 loss: 0.34794795513153076
Batch 2/64 loss: 0.34946209192276
Batch 3/64 loss: 0.35301733016967773
Batch 4/64 loss: 0.35478830337524414
Batch 5/64 loss: 0.3496372699737549
Batch 6/64 loss: 0.3553099036216736
Batch 7/64 loss: 0.35131388902664185
Batch 8/64 loss: 0.3505851626396179
Batch 9/64 loss: 0.35022103786468506
Batch 10/64 loss: 0.3550068736076355
Batch 11/64 loss: 0.3535006642341614
Batch 12/64 loss: 0.3545640707015991
Batch 13/64 loss: 0.3479161858558655
Batch 14/64 loss: 0.3528195023536682
Batch 15/64 loss: 0.34861069917678833
Batch 16/64 loss: 0.34606778621673584
Batch 17/64 loss: 0.3553788661956787
Batch 18/64 loss: 0.35041332244873047
Batch 19/64 loss: 0.34918034076690674
Batch 20/64 loss: 0.35695236921310425
Batch 21/64 loss: 0.3532866835594177
Batch 22/64 loss: 0.34794819355010986
Batch 23/64 loss: 0.3511083126068115
Batch 24/64 loss: 0.3525722026824951
Batch 25/64 loss: 0.34745198488235474
Batch 26/64 loss: 0.34757596254348755
Batch 27/64 loss: 0.35073816776275635
Batch 28/64 loss: 0.3544466495513916
Batch 29/64 loss: 0.3495389223098755
Batch 30/64 loss: 0.35111212730407715
Batch 31/64 loss: 0.3510286808013916
Batch 32/64 loss: 0.353043794631958
Batch 33/64 loss: 0.3525118827819824
Batch 34/64 loss: 0.34910857677459717
Batch 35/64 loss: 0.3484261631965637
Batch 36/64 loss: 0.346787691116333
Batch 37/64 loss: 0.3500993251800537
Batch 38/64 loss: 0.35186880826950073
Batch 39/64 loss: 0.351514995098114
Batch 40/64 loss: 0.35151827335357666
Batch 41/64 loss: 0.3532196879386902
Batch 42/64 loss: 0.3529726266860962
Batch 43/64 loss: 0.35207265615463257
Batch 44/64 loss: 0.35089194774627686
Batch 45/64 loss: 0.3513021469116211
Batch 46/64 loss: 0.35043275356292725
Batch 47/64 loss: 0.3474121689796448
Batch 48/64 loss: 0.3525955080986023
Batch 49/64 loss: 0.3531033992767334
Batch 50/64 loss: 0.3546227812767029
Batch 51/64 loss: 0.34779947996139526
Batch 52/64 loss: 0.352152943611145
Batch 53/64 loss: 0.348547101020813
Batch 54/64 loss: 0.3449639081954956
Batch 55/64 loss: 0.3532952070236206
Batch 56/64 loss: 0.34353935718536377
Batch 57/64 loss: 0.3502538204193115
Batch 58/64 loss: 0.3460742235183716
Batch 59/64 loss: 0.345389723777771
Batch 60/64 loss: 0.34710752964019775
Batch 61/64 loss: 0.3516072630882263
Batch 62/64 loss: 0.35165631771087646
Batch 63/64 loss: 0.3534400463104248
Batch 64/64 loss: 0.3465281128883362
Epoch 111  Train loss: 0.350725171846502  Val loss: 0.3544762515530144
Epoch 112
-------------------------------
Batch 1/64 loss: 0.34851592779159546
Batch 2/64 loss: 0.3515753746032715
Batch 3/64 loss: 0.3472646474838257
Batch 4/64 loss: 0.34811997413635254
Batch 5/64 loss: 0.35386836528778076
Batch 6/64 loss: 0.3509008288383484
Batch 7/64 loss: 0.34897398948669434
Batch 8/64 loss: 0.35020631551742554
Batch 9/64 loss: 0.3473166227340698
Batch 10/64 loss: 0.3522663116455078
Batch 11/64 loss: 0.3503442406654358
Batch 12/64 loss: 0.35001617670059204
Batch 13/64 loss: 0.35261863470077515
Batch 14/64 loss: 0.3454025387763977
Batch 15/64 loss: 0.34838759899139404
Batch 16/64 loss: 0.35146576166152954
Batch 17/64 loss: 0.3515514135360718
Batch 18/64 loss: 0.35163700580596924
Batch 19/64 loss: 0.35140347480773926
Batch 20/64 loss: 0.3504992127418518
Batch 21/64 loss: 0.3535398244857788
Batch 22/64 loss: 0.3461723327636719
Batch 23/64 loss: 0.3512154817581177
Batch 24/64 loss: 0.3510746955871582
Batch 25/64 loss: 0.3489450216293335
Batch 26/64 loss: 0.35181474685668945
Batch 27/64 loss: 0.34714818000793457
Batch 28/64 loss: 0.3504812717437744
Batch 29/64 loss: 0.35766786336898804
Batch 30/64 loss: 0.34729039669036865
Batch 31/64 loss: 0.35124003887176514
Batch 32/64 loss: 0.35047268867492676
Batch 33/64 loss: 0.35560786724090576
Batch 34/64 loss: 0.35043883323669434
Batch 35/64 loss: 0.35424840450286865
Batch 36/64 loss: 0.35189807415008545
Batch 37/64 loss: 0.34577280282974243
Batch 38/64 loss: 0.3581618666648865
Batch 39/64 loss: 0.34822654724121094
Batch 40/64 loss: 0.35128748416900635
Batch 41/64 loss: 0.35354483127593994
Batch 42/64 loss: 0.35427939891815186
Batch 43/64 loss: 0.3485459089279175
Batch 44/64 loss: 0.3545902371406555
Batch 45/64 loss: 0.350826621055603
Batch 46/64 loss: 0.35016095638275146
Batch 47/64 loss: 0.35032975673675537
Batch 48/64 loss: 0.3529551029205322
Batch 49/64 loss: 0.3512560725212097
Batch 50/64 loss: 0.34994596242904663
Batch 51/64 loss: 0.35338294506073
Batch 52/64 loss: 0.3458297848701477
Batch 53/64 loss: 0.3499603271484375
Batch 54/64 loss: 0.3530648946762085
Batch 55/64 loss: 0.35571932792663574
Batch 56/64 loss: 0.3475968837738037
Batch 57/64 loss: 0.352400541305542
Batch 58/64 loss: 0.3469201922416687
Batch 59/64 loss: 0.3523750901222229
Batch 60/64 loss: 0.3535020351409912
Batch 61/64 loss: 0.3492758870124817
Batch 62/64 loss: 0.3498499393463135
Batch 63/64 loss: 0.35157883167266846
Batch 64/64 loss: 0.346887469291687
Epoch 112  Train loss: 0.350793662258223  Val loss: 0.3548539254263914
Epoch 113
-------------------------------
Batch 1/64 loss: 0.3500623106956482
Batch 2/64 loss: 0.3530992865562439
Batch 3/64 loss: 0.35319215059280396
Batch 4/64 loss: 0.3493301272392273
Batch 5/64 loss: 0.3558390140533447
Batch 6/64 loss: 0.3513544797897339
Batch 7/64 loss: 0.3545631170272827
Batch 8/64 loss: 0.3525034189224243
Batch 9/64 loss: 0.35429251194000244
Batch 10/64 loss: 0.3582609295845032
Batch 11/64 loss: 0.34951627254486084
Batch 12/64 loss: 0.34647542238235474
Batch 13/64 loss: 0.35071009397506714
Batch 14/64 loss: 0.3509564995765686
Batch 15/64 loss: 0.3523314595222473
Batch 16/64 loss: 0.34939026832580566
Batch 17/64 loss: 0.3500746488571167
Batch 18/64 loss: 0.34901702404022217
Batch 19/64 loss: 0.34940987825393677
Batch 20/64 loss: 0.3455711007118225
Batch 21/64 loss: 0.3464052677154541
Batch 22/64 loss: 0.34941911697387695
Batch 23/64 loss: 0.3511769771575928
Batch 24/64 loss: 0.34819281101226807
Batch 25/64 loss: 0.3503687381744385
Batch 26/64 loss: 0.35146915912628174
Batch 27/64 loss: 0.35073697566986084
Batch 28/64 loss: 0.3541070222854614
Batch 29/64 loss: 0.35319364070892334
Batch 30/64 loss: 0.35009145736694336
Batch 31/64 loss: 0.35194486379623413
Batch 32/64 loss: 0.3477115035057068
Batch 33/64 loss: 0.3467749357223511
Batch 34/64 loss: 0.3477071523666382
Batch 35/64 loss: 0.3521868586540222
Batch 36/64 loss: 0.346316397190094
Batch 37/64 loss: 0.347493052482605
Batch 38/64 loss: 0.3532576560974121
Batch 39/64 loss: 0.35027581453323364
Batch 40/64 loss: 0.35045671463012695
Batch 41/64 loss: 0.34666335582733154
Batch 42/64 loss: 0.3550546169281006
Batch 43/64 loss: 0.3480599522590637
Batch 44/64 loss: 0.34737318754196167
Batch 45/64 loss: 0.35102134943008423
Batch 46/64 loss: 0.35056281089782715
Batch 47/64 loss: 0.3520790934562683
Batch 48/64 loss: 0.3485220670700073
Batch 49/64 loss: 0.34497952461242676
Batch 50/64 loss: 0.3534001111984253
Batch 51/64 loss: 0.3426426649093628
Batch 52/64 loss: 0.3505842089653015
Batch 53/64 loss: 0.34869909286499023
Batch 54/64 loss: 0.3483954668045044
Batch 55/64 loss: 0.3528491258621216
Batch 56/64 loss: 0.35152101516723633
Batch 57/64 loss: 0.3474534749984741
Batch 58/64 loss: 0.35000139474868774
Batch 59/64 loss: 0.3584582209587097
Batch 60/64 loss: 0.3531886339187622
Batch 61/64 loss: 0.35496121644973755
Batch 62/64 loss: 0.3522322177886963
Batch 63/64 loss: 0.34543514251708984
Batch 64/64 loss: 0.35516512393951416
Epoch 113  Train loss: 0.35052153596691055  Val loss: 0.35407222116116394
Saving best model, epoch: 113
Epoch 114
-------------------------------
Batch 1/64 loss: 0.3476652503013611
Batch 2/64 loss: 0.3481864333152771
Batch 3/64 loss: 0.3526039719581604
Batch 4/64 loss: 0.3522127866744995
Batch 5/64 loss: 0.34781861305236816
Batch 6/64 loss: 0.34906506538391113
Batch 7/64 loss: 0.35553622245788574
Batch 8/64 loss: 0.3569597005844116
Batch 9/64 loss: 0.3462766408920288
Batch 10/64 loss: 0.34568703174591064
Batch 11/64 loss: 0.34993165731430054
Batch 12/64 loss: 0.3524491786956787
Batch 13/64 loss: 0.3494570851325989
Batch 14/64 loss: 0.34834718704223633
Batch 15/64 loss: 0.35144561529159546
Batch 16/64 loss: 0.3441568613052368
Batch 17/64 loss: 0.34737855195999146
Batch 18/64 loss: 0.35236382484436035
Batch 19/64 loss: 0.3523753881454468
Batch 20/64 loss: 0.3469797372817993
Batch 21/64 loss: 0.35615110397338867
Batch 22/64 loss: 0.34991294145584106
Batch 23/64 loss: 0.3479210138320923
Batch 24/64 loss: 0.3460952639579773
Batch 25/64 loss: 0.3480027914047241
Batch 26/64 loss: 0.35121047496795654
Batch 27/64 loss: 0.350231409072876
Batch 28/64 loss: 0.36092329025268555
Batch 29/64 loss: 0.3488006591796875
Batch 30/64 loss: 0.3525122404098511
Batch 31/64 loss: 0.3494015336036682
Batch 32/64 loss: 0.34693819284439087
Batch 33/64 loss: 0.35485702753067017
Batch 34/64 loss: 0.3520752191543579
Batch 35/64 loss: 0.3559117317199707
Batch 36/64 loss: 0.34599244594573975
Batch 37/64 loss: 0.3519878387451172
Batch 38/64 loss: 0.3516577482223511
Batch 39/64 loss: 0.34881097078323364
Batch 40/64 loss: 0.35723066329956055
Batch 41/64 loss: 0.34816139936447144
Batch 42/64 loss: 0.34933769702911377
Batch 43/64 loss: 0.3510233759880066
Batch 44/64 loss: 0.34834545850753784
Batch 45/64 loss: 0.3499114513397217
Batch 46/64 loss: 0.35310858488082886
Batch 47/64 loss: 0.3491332530975342
Batch 48/64 loss: 0.35208916664123535
Batch 49/64 loss: 0.35087883472442627
Batch 50/64 loss: 0.3482705354690552
Batch 51/64 loss: 0.35661405324935913
Batch 52/64 loss: 0.35011428594589233
Batch 53/64 loss: 0.3514329791069031
Batch 54/64 loss: 0.34629297256469727
Batch 55/64 loss: 0.35082679986953735
Batch 56/64 loss: 0.35063648223876953
Batch 57/64 loss: 0.34991663694381714
Batch 58/64 loss: 0.3498595356941223
Batch 59/64 loss: 0.3514261245727539
Batch 60/64 loss: 0.3511385917663574
Batch 61/64 loss: 0.3489762544631958
Batch 62/64 loss: 0.3529236316680908
Batch 63/64 loss: 0.3515281677246094
Batch 64/64 loss: 0.3471689224243164
Epoch 114  Train loss: 0.3505230482886819  Val loss: 0.35407736170332865
Epoch 115
-------------------------------
Batch 1/64 loss: 0.34675174951553345
Batch 2/64 loss: 0.3470565676689148
Batch 3/64 loss: 0.3529711961746216
Batch 4/64 loss: 0.34873831272125244
Batch 5/64 loss: 0.3489075303077698
Batch 6/64 loss: 0.3483285903930664
Batch 7/64 loss: 0.35310834646224976
Batch 8/64 loss: 0.3508714437484741
Batch 9/64 loss: 0.3490709066390991
Batch 10/64 loss: 0.34939539432525635
Batch 11/64 loss: 0.3464568853378296
Batch 12/64 loss: 0.34837865829467773
Batch 13/64 loss: 0.34772026538848877
Batch 14/64 loss: 0.34939807653427124
Batch 15/64 loss: 0.3517107367515564
Batch 16/64 loss: 0.3463021516799927
Batch 17/64 loss: 0.3475102186203003
Batch 18/64 loss: 0.35427385568618774
Batch 19/64 loss: 0.346882700920105
Batch 20/64 loss: 0.3482402563095093
Batch 21/64 loss: 0.3511381149291992
Batch 22/64 loss: 0.35123056173324585
Batch 23/64 loss: 0.3504505157470703
Batch 24/64 loss: 0.3493068218231201
Batch 25/64 loss: 0.35350364446640015
Batch 26/64 loss: 0.35152387619018555
Batch 27/64 loss: 0.34810101985931396
Batch 28/64 loss: 0.35027003288269043
Batch 29/64 loss: 0.35211074352264404
Batch 30/64 loss: 0.351509690284729
Batch 31/64 loss: 0.3552802801132202
Batch 32/64 loss: 0.34932541847229004
Batch 33/64 loss: 0.3470872640609741
Batch 34/64 loss: 0.3539351224899292
Batch 35/64 loss: 0.35186976194381714
Batch 36/64 loss: 0.3543572425842285
Batch 37/64 loss: 0.35082292556762695
Batch 38/64 loss: 0.35214924812316895
Batch 39/64 loss: 0.3489186763763428
Batch 40/64 loss: 0.34722208976745605
Batch 41/64 loss: 0.35119056701660156
Batch 42/64 loss: 0.35308194160461426
Batch 43/64 loss: 0.35323232412338257
Batch 44/64 loss: 0.34971320629119873
Batch 45/64 loss: 0.3470062017440796
Batch 46/64 loss: 0.34766292572021484
Batch 47/64 loss: 0.3539468050003052
Batch 48/64 loss: 0.34927648305892944
Batch 49/64 loss: 0.35015249252319336
Batch 50/64 loss: 0.3537970781326294
Batch 51/64 loss: 0.34921693801879883
Batch 52/64 loss: 0.3488655686378479
Batch 53/64 loss: 0.3544352054595947
Batch 54/64 loss: 0.3477823734283447
Batch 55/64 loss: 0.3489377498626709
Batch 56/64 loss: 0.3530811071395874
Batch 57/64 loss: 0.3510946035385132
Batch 58/64 loss: 0.3483048677444458
Batch 59/64 loss: 0.35416698455810547
Batch 60/64 loss: 0.3478909134864807
Batch 61/64 loss: 0.3500252962112427
Batch 62/64 loss: 0.34946465492248535
Batch 63/64 loss: 0.3516472578048706
Batch 64/64 loss: 0.35203075408935547
Epoch 115  Train loss: 0.3502773883295994  Val loss: 0.3541757843338747
Epoch 116
-------------------------------
Batch 1/64 loss: 0.3509939908981323
Batch 2/64 loss: 0.34716475009918213
Batch 3/64 loss: 0.3518844246864319
Batch 4/64 loss: 0.35188621282577515
Batch 5/64 loss: 0.34971916675567627
Batch 6/64 loss: 0.35461270809173584
Batch 7/64 loss: 0.35336077213287354
Batch 8/64 loss: 0.34412288665771484
Batch 9/64 loss: 0.35141152143478394
Batch 10/64 loss: 0.34888583421707153
Batch 11/64 loss: 0.3542599678039551
Batch 12/64 loss: 0.347293496131897
Batch 13/64 loss: 0.34741127490997314
Batch 14/64 loss: 0.35436582565307617
Batch 15/64 loss: 0.3458855152130127
Batch 16/64 loss: 0.34462231397628784
Batch 17/64 loss: 0.34992218017578125
Batch 18/64 loss: 0.3561985492706299
Batch 19/64 loss: 0.35038214921951294
Batch 20/64 loss: 0.34319019317626953
Batch 21/64 loss: 0.3496958613395691
Batch 22/64 loss: 0.3484099507331848
Batch 23/64 loss: 0.35334205627441406
Batch 24/64 loss: 0.3425382375717163
Batch 25/64 loss: 0.347673237323761
Batch 26/64 loss: 0.34584343433380127
Batch 27/64 loss: 0.35197269916534424
Batch 28/64 loss: 0.34833788871765137
Batch 29/64 loss: 0.34991830587387085
Batch 30/64 loss: 0.34980571269989014
Batch 31/64 loss: 0.34648895263671875
Batch 32/64 loss: 0.34929168224334717
Batch 33/64 loss: 0.3501470685005188
Batch 34/64 loss: 0.34848856925964355
Batch 35/64 loss: 0.3524223566055298
Batch 36/64 loss: 0.34919631481170654
Batch 37/64 loss: 0.3520963191986084
Batch 38/64 loss: 0.35152626037597656
Batch 39/64 loss: 0.34666216373443604
Batch 40/64 loss: 0.3469350337982178
Batch 41/64 loss: 0.35133975744247437
Batch 42/64 loss: 0.3510885238647461
Batch 43/64 loss: 0.3491535186767578
Batch 44/64 loss: 0.35237443447113037
Batch 45/64 loss: 0.35102033615112305
Batch 46/64 loss: 0.35020947456359863
Batch 47/64 loss: 0.35351455211639404
Batch 48/64 loss: 0.34932613372802734
Batch 49/64 loss: 0.3485322594642639
Batch 50/64 loss: 0.3461994528770447
Batch 51/64 loss: 0.3543761968612671
Batch 52/64 loss: 0.3527470827102661
Batch 53/64 loss: 0.34883153438568115
Batch 54/64 loss: 0.3511248826980591
Batch 55/64 loss: 0.3513237237930298
Batch 56/64 loss: 0.3524091839790344
Batch 57/64 loss: 0.3540857434272766
Batch 58/64 loss: 0.3489401936531067
Batch 59/64 loss: 0.3552182912826538
Batch 60/64 loss: 0.34886300563812256
Batch 61/64 loss: 0.34917646646499634
Batch 62/64 loss: 0.3477792739868164
Batch 63/64 loss: 0.35168564319610596
Batch 64/64 loss: 0.34672367572784424
Epoch 116  Train loss: 0.3499251491883222  Val loss: 0.3540778450949495
Epoch 117
-------------------------------
Batch 1/64 loss: 0.3506507873535156
Batch 2/64 loss: 0.353118360042572
Batch 3/64 loss: 0.34877562522888184
Batch 4/64 loss: 0.3507399559020996
Batch 5/64 loss: 0.35034871101379395
Batch 6/64 loss: 0.3440742492675781
Batch 7/64 loss: 0.34498822689056396
Batch 8/64 loss: 0.3539068102836609
Batch 9/64 loss: 0.3526241183280945
Batch 10/64 loss: 0.3486461639404297
Batch 11/64 loss: 0.3441154360771179
Batch 12/64 loss: 0.3487086892127991
Batch 13/64 loss: 0.35028380155563354
Batch 14/64 loss: 0.35252606868743896
Batch 15/64 loss: 0.35323840379714966
Batch 16/64 loss: 0.3490196466445923
Batch 17/64 loss: 0.34886956214904785
Batch 18/64 loss: 0.34745854139328003
Batch 19/64 loss: 0.34904611110687256
Batch 20/64 loss: 0.34497177600860596
Batch 21/64 loss: 0.35153257846832275
Batch 22/64 loss: 0.35336625576019287
Batch 23/64 loss: 0.3506346344947815
Batch 24/64 loss: 0.3470141887664795
Batch 25/64 loss: 0.34653228521347046
Batch 26/64 loss: 0.35245829820632935
Batch 27/64 loss: 0.3535027503967285
Batch 28/64 loss: 0.3511009216308594
Batch 29/64 loss: 0.3529621362686157
Batch 30/64 loss: 0.347359299659729
Batch 31/64 loss: 0.3527621626853943
Batch 32/64 loss: 0.35065436363220215
Batch 33/64 loss: 0.3489081859588623
Batch 34/64 loss: 0.3491906523704529
Batch 35/64 loss: 0.34994685649871826
Batch 36/64 loss: 0.35551756620407104
Batch 37/64 loss: 0.3507561683654785
Batch 38/64 loss: 0.34267640113830566
Batch 39/64 loss: 0.3525598645210266
Batch 40/64 loss: 0.3496628403663635
Batch 41/64 loss: 0.35047972202301025
Batch 42/64 loss: 0.3461493253707886
Batch 43/64 loss: 0.3502205014228821
Batch 44/64 loss: 0.35286569595336914
Batch 45/64 loss: 0.3477403521537781
Batch 46/64 loss: 0.3485679626464844
Batch 47/64 loss: 0.34565842151641846
Batch 48/64 loss: 0.3529890179634094
Batch 49/64 loss: 0.3467257022857666
Batch 50/64 loss: 0.3558724522590637
Batch 51/64 loss: 0.3487739562988281
Batch 52/64 loss: 0.35364043712615967
Batch 53/64 loss: 0.35063087940216064
Batch 54/64 loss: 0.3488736152648926
Batch 55/64 loss: 0.35477709770202637
Batch 56/64 loss: 0.3524755835533142
Batch 57/64 loss: 0.35375863313674927
Batch 58/64 loss: 0.348699688911438
Batch 59/64 loss: 0.35147756338119507
Batch 60/64 loss: 0.34833163022994995
Batch 61/64 loss: 0.3458094596862793
Batch 62/64 loss: 0.3460236191749573
Batch 63/64 loss: 0.35688352584838867
Batch 64/64 loss: 0.35306596755981445
Epoch 117  Train loss: 0.350077392540726  Val loss: 0.3535504502938785
Saving best model, epoch: 117
Epoch 118
-------------------------------
Batch 1/64 loss: 0.3539174795150757
Batch 2/64 loss: 0.3535984754562378
Batch 3/64 loss: 0.3482201099395752
Batch 4/64 loss: 0.3472837209701538
Batch 5/64 loss: 0.3469196557998657
Batch 6/64 loss: 0.3492473363876343
Batch 7/64 loss: 0.3484278917312622
Batch 8/64 loss: 0.348585307598114
Batch 9/64 loss: 0.3501009941101074
Batch 10/64 loss: 0.34829580783843994
Batch 11/64 loss: 0.34390389919281006
Batch 12/64 loss: 0.3527188301086426
Batch 13/64 loss: 0.34761565923690796
Batch 14/64 loss: 0.3504565358161926
Batch 15/64 loss: 0.34125596284866333
Batch 16/64 loss: 0.34988319873809814
Batch 17/64 loss: 0.3490900993347168
Batch 18/64 loss: 0.34488213062286377
Batch 19/64 loss: 0.3523182272911072
Batch 20/64 loss: 0.354793906211853
Batch 21/64 loss: 0.3512918949127197
Batch 22/64 loss: 0.34886014461517334
Batch 23/64 loss: 0.35012537240982056
Batch 24/64 loss: 0.35217738151550293
Batch 25/64 loss: 0.35016244649887085
Batch 26/64 loss: 0.34697604179382324
Batch 27/64 loss: 0.35417044162750244
Batch 28/64 loss: 0.35318273305892944
Batch 29/64 loss: 0.34815770387649536
Batch 30/64 loss: 0.3502390384674072
Batch 31/64 loss: 0.3469266891479492
Batch 32/64 loss: 0.3463708162307739
Batch 33/64 loss: 0.3492776155471802
Batch 34/64 loss: 0.3478888273239136
Batch 35/64 loss: 0.3511737585067749
Batch 36/64 loss: 0.3528202772140503
Batch 37/64 loss: 0.3472062945365906
Batch 38/64 loss: 0.3474894165992737
Batch 39/64 loss: 0.35323214530944824
Batch 40/64 loss: 0.3518650531768799
Batch 41/64 loss: 0.34477168321609497
Batch 42/64 loss: 0.3490391969680786
Batch 43/64 loss: 0.3513715863227844
Batch 44/64 loss: 0.35169100761413574
Batch 45/64 loss: 0.352999210357666
Batch 46/64 loss: 0.3496090769767761
Batch 47/64 loss: 0.3525094985961914
Batch 48/64 loss: 0.35306715965270996
Batch 49/64 loss: 0.35056960582733154
Batch 50/64 loss: 0.3492511510848999
Batch 51/64 loss: 0.3519434928894043
Batch 52/64 loss: 0.34774941205978394
Batch 53/64 loss: 0.34600019454956055
Batch 54/64 loss: 0.35328614711761475
Batch 55/64 loss: 0.3482964038848877
Batch 56/64 loss: 0.3539034128189087
Batch 57/64 loss: 0.349348783493042
Batch 58/64 loss: 0.3492875099182129
Batch 59/64 loss: 0.35442280769348145
Batch 60/64 loss: 0.3538842797279358
Batch 61/64 loss: 0.34215426445007324
Batch 62/64 loss: 0.3459702730178833
Batch 63/64 loss: 0.35062479972839355
Batch 64/64 loss: 0.3501819372177124
Epoch 118  Train loss: 0.3497332820705339  Val loss: 0.3538696868313137
Epoch 119
-------------------------------
Batch 1/64 loss: 0.35164082050323486
Batch 2/64 loss: 0.34762686491012573
Batch 3/64 loss: 0.34713613986968994
Batch 4/64 loss: 0.348954439163208
Batch 5/64 loss: 0.3537200689315796
Batch 6/64 loss: 0.3503173589706421
Batch 7/64 loss: 0.3500290513038635
Batch 8/64 loss: 0.34653520584106445
Batch 9/64 loss: 0.34937000274658203
Batch 10/64 loss: 0.3475714921951294
Batch 11/64 loss: 0.3405640721321106
Batch 12/64 loss: 0.35004639625549316
Batch 13/64 loss: 0.3548768162727356
Batch 14/64 loss: 0.34980571269989014
Batch 15/64 loss: 0.3470790386199951
Batch 16/64 loss: 0.34276092052459717
Batch 17/64 loss: 0.34861189126968384
Batch 18/64 loss: 0.35246992111206055
Batch 19/64 loss: 0.34660303592681885
Batch 20/64 loss: 0.35138899087905884
Batch 21/64 loss: 0.35452353954315186
Batch 22/64 loss: 0.3487064838409424
Batch 23/64 loss: 0.34923607110977173
Batch 24/64 loss: 0.3488095998764038
Batch 25/64 loss: 0.3481988310813904
Batch 26/64 loss: 0.3485133647918701
Batch 27/64 loss: 0.3427232503890991
Batch 28/64 loss: 0.350848913192749
Batch 29/64 loss: 0.35136955976486206
Batch 30/64 loss: 0.34973978996276855
Batch 31/64 loss: 0.3448513150215149
Batch 32/64 loss: 0.3485807180404663
Batch 33/64 loss: 0.35130006074905396
Batch 34/64 loss: 0.34871530532836914
Batch 35/64 loss: 0.3479522466659546
Batch 36/64 loss: 0.348254919052124
Batch 37/64 loss: 0.35202139616012573
Batch 38/64 loss: 0.3463633060455322
Batch 39/64 loss: 0.35236644744873047
Batch 40/64 loss: 0.34915924072265625
Batch 41/64 loss: 0.3499842882156372
Batch 42/64 loss: 0.3545660376548767
Batch 43/64 loss: 0.34910112619400024
Batch 44/64 loss: 0.3519018888473511
Batch 45/64 loss: 0.35095083713531494
Batch 46/64 loss: 0.3538993000984192
Batch 47/64 loss: 0.35222458839416504
Batch 48/64 loss: 0.3473137617111206
Batch 49/64 loss: 0.3550611734390259
Batch 50/64 loss: 0.35183167457580566
Batch 51/64 loss: 0.3437936305999756
Batch 52/64 loss: 0.3481649160385132
Batch 53/64 loss: 0.35110700130462646
Batch 54/64 loss: 0.35252445936203003
Batch 55/64 loss: 0.35156410932540894
Batch 56/64 loss: 0.35037732124328613
Batch 57/64 loss: 0.3463454842567444
Batch 58/64 loss: 0.3497595191001892
Batch 59/64 loss: 0.34696102142333984
Batch 60/64 loss: 0.3484787344932556
Batch 61/64 loss: 0.3467225432395935
Batch 62/64 loss: 0.35210120677948
Batch 63/64 loss: 0.3536895513534546
Batch 64/64 loss: 0.35314804315567017
Epoch 119  Train loss: 0.3495314165657642  Val loss: 0.3540936946049589
Epoch 120
-------------------------------
Batch 1/64 loss: 0.34412264823913574
Batch 2/64 loss: 0.34762871265411377
Batch 3/64 loss: 0.3466290831565857
Batch 4/64 loss: 0.3517466187477112
Batch 5/64 loss: 0.35361766815185547
Batch 6/64 loss: 0.34625184535980225
Batch 7/64 loss: 0.35005778074264526
Batch 8/64 loss: 0.35439974069595337
Batch 9/64 loss: 0.3466857671737671
Batch 10/64 loss: 0.3529735803604126
Batch 11/64 loss: 0.3502810597419739
Batch 12/64 loss: 0.3519105315208435
Batch 13/64 loss: 0.34930509328842163
Batch 14/64 loss: 0.353168249130249
Batch 15/64 loss: 0.3473643660545349
Batch 16/64 loss: 0.345051646232605
Batch 17/64 loss: 0.3512081503868103
Batch 18/64 loss: 0.34460747241973877
Batch 19/64 loss: 0.3459378480911255
Batch 20/64 loss: 0.34588027000427246
Batch 21/64 loss: 0.34833669662475586
Batch 22/64 loss: 0.35109496116638184
Batch 23/64 loss: 0.34806567430496216
Batch 24/64 loss: 0.3535798192024231
Batch 25/64 loss: 0.3458471894264221
Batch 26/64 loss: 0.34961527585983276
Batch 27/64 loss: 0.345328688621521
Batch 28/64 loss: 0.35162603855133057
Batch 29/64 loss: 0.35294413566589355
Batch 30/64 loss: 0.3505074381828308
Batch 31/64 loss: 0.3517354130744934
Batch 32/64 loss: 0.34974420070648193
Batch 33/64 loss: 0.350508451461792
Batch 34/64 loss: 0.346743643283844
Batch 35/64 loss: 0.3540732264518738
Batch 36/64 loss: 0.3438849449157715
Batch 37/64 loss: 0.35171008110046387
Batch 38/64 loss: 0.3467916250228882
Batch 39/64 loss: 0.3520383834838867
Batch 40/64 loss: 0.3523103594779968
Batch 41/64 loss: 0.35234296321868896
Batch 42/64 loss: 0.3461948037147522
Batch 43/64 loss: 0.352556049823761
Batch 44/64 loss: 0.35369229316711426
Batch 45/64 loss: 0.3484131097793579
Batch 46/64 loss: 0.3480680584907532
Batch 47/64 loss: 0.3536781072616577
Batch 48/64 loss: 0.3503216505050659
Batch 49/64 loss: 0.3492218852043152
Batch 50/64 loss: 0.3451541066169739
Batch 51/64 loss: 0.3528714179992676
Batch 52/64 loss: 0.35151207447052
Batch 53/64 loss: 0.353157639503479
Batch 54/64 loss: 0.345889687538147
Batch 55/64 loss: 0.3448927402496338
Batch 56/64 loss: 0.34972083568573
Batch 57/64 loss: 0.3502700924873352
Batch 58/64 loss: 0.34865087270736694
Batch 59/64 loss: 0.3516042232513428
Batch 60/64 loss: 0.348935604095459
Batch 61/64 loss: 0.3504852056503296
Batch 62/64 loss: 0.34551846981048584
Batch 63/64 loss: 0.35328298807144165
Batch 64/64 loss: 0.3458864688873291
Epoch 120  Train loss: 0.349508456622853  Val loss: 0.3546275879509261
Epoch 121
-------------------------------
Batch 1/64 loss: 0.3547663688659668
Batch 2/64 loss: 0.3484340310096741
Batch 3/64 loss: 0.3484363555908203
Batch 4/64 loss: 0.3485543727874756
Batch 5/64 loss: 0.3497422933578491
Batch 6/64 loss: 0.34701448678970337
Batch 7/64 loss: 0.3453657031059265
Batch 8/64 loss: 0.34495997428894043
Batch 9/64 loss: 0.3488239645957947
Batch 10/64 loss: 0.34573864936828613
Batch 11/64 loss: 0.34926271438598633
Batch 12/64 loss: 0.35105687379837036
Batch 13/64 loss: 0.35255277156829834
Batch 14/64 loss: 0.3481414318084717
Batch 15/64 loss: 0.3505215048789978
Batch 16/64 loss: 0.34820353984832764
Batch 17/64 loss: 0.34820324182510376
Batch 18/64 loss: 0.34920185804367065
Batch 19/64 loss: 0.35261470079421997
Batch 20/64 loss: 0.34561485052108765
Batch 21/64 loss: 0.351163387298584
Batch 22/64 loss: 0.346602201461792
Batch 23/64 loss: 0.3527928590774536
Batch 24/64 loss: 0.3511303663253784
Batch 25/64 loss: 0.35100090503692627
Batch 26/64 loss: 0.34771108627319336
Batch 27/64 loss: 0.35291874408721924
Batch 28/64 loss: 0.349778413772583
Batch 29/64 loss: 0.3510439395904541
Batch 30/64 loss: 0.3465304374694824
Batch 31/64 loss: 0.3514893054962158
Batch 32/64 loss: 0.35448217391967773
Batch 33/64 loss: 0.35018521547317505
Batch 34/64 loss: 0.3472940921783447
Batch 35/64 loss: 0.3579104542732239
Batch 36/64 loss: 0.3483167290687561
Batch 37/64 loss: 0.35033291578292847
Batch 38/64 loss: 0.3443591594696045
Batch 39/64 loss: 0.349765419960022
Batch 40/64 loss: 0.3502908945083618
Batch 41/64 loss: 0.3493562936782837
Batch 42/64 loss: 0.3508085608482361
Batch 43/64 loss: 0.3486032485961914
Batch 44/64 loss: 0.3457116484642029
Batch 45/64 loss: 0.34956955909729004
Batch 46/64 loss: 0.3418971300125122
Batch 47/64 loss: 0.35072654485702515
Batch 48/64 loss: 0.34944677352905273
Batch 49/64 loss: 0.3489699959754944
Batch 50/64 loss: 0.3465731143951416
Batch 51/64 loss: 0.35042786598205566
Batch 52/64 loss: 0.3480638265609741
Batch 53/64 loss: 0.34892380237579346
Batch 54/64 loss: 0.3451768159866333
Batch 55/64 loss: 0.3467216491699219
Batch 56/64 loss: 0.3478749394416809
Batch 57/64 loss: 0.3478052616119385
Batch 58/64 loss: 0.3477778434753418
Batch 59/64 loss: 0.3478548526763916
Batch 60/64 loss: 0.3486582040786743
Batch 61/64 loss: 0.3489254117012024
Batch 62/64 loss: 0.3540140390396118
Batch 63/64 loss: 0.34309500455856323
Batch 64/64 loss: 0.3493916392326355
Epoch 121  Train loss: 0.34904054122812606  Val loss: 0.35336556836092187
Saving best model, epoch: 121
Epoch 122
-------------------------------
Batch 1/64 loss: 0.346396803855896
Batch 2/64 loss: 0.3491767644882202
Batch 3/64 loss: 0.35069823265075684
Batch 4/64 loss: 0.34820473194122314
Batch 5/64 loss: 0.3458535075187683
Batch 6/64 loss: 0.3489934206008911
Batch 7/64 loss: 0.3501530885696411
Batch 8/64 loss: 0.3495575189590454
Batch 9/64 loss: 0.3469851613044739
Batch 10/64 loss: 0.3538200855255127
Batch 11/64 loss: 0.3467925190925598
Batch 12/64 loss: 0.34690719842910767
Batch 13/64 loss: 0.3447366952896118
Batch 14/64 loss: 0.3502274751663208
Batch 15/64 loss: 0.34970468282699585
Batch 16/64 loss: 0.3467867374420166
Batch 17/64 loss: 0.3460726737976074
Batch 18/64 loss: 0.3517054319381714
Batch 19/64 loss: 0.34644460678100586
Batch 20/64 loss: 0.351095974445343
Batch 21/64 loss: 0.3484463095664978
Batch 22/64 loss: 0.3454933166503906
Batch 23/64 loss: 0.3517550826072693
Batch 24/64 loss: 0.34722524881362915
Batch 25/64 loss: 0.34906721115112305
Batch 26/64 loss: 0.3522721529006958
Batch 27/64 loss: 0.34484028816223145
Batch 28/64 loss: 0.352234423160553
Batch 29/64 loss: 0.35206806659698486
Batch 30/64 loss: 0.3508702516555786
Batch 31/64 loss: 0.3500303030014038
Batch 32/64 loss: 0.34990644454956055
Batch 33/64 loss: 0.35117489099502563
Batch 34/64 loss: 0.35094207525253296
Batch 35/64 loss: 0.34915590286254883
Batch 36/64 loss: 0.35205525159835815
Batch 37/64 loss: 0.3512234091758728
Batch 38/64 loss: 0.34093618392944336
Batch 39/64 loss: 0.34633708000183105
Batch 40/64 loss: 0.353324294090271
Batch 41/64 loss: 0.3481382727622986
Batch 42/64 loss: 0.3493952751159668
Batch 43/64 loss: 0.34742850065231323
Batch 44/64 loss: 0.3516261577606201
Batch 45/64 loss: 0.35344260931015015
Batch 46/64 loss: 0.34630465507507324
Batch 47/64 loss: 0.3459482192993164
Batch 48/64 loss: 0.350150465965271
Batch 49/64 loss: 0.34396958351135254
Batch 50/64 loss: 0.3473386764526367
Batch 51/64 loss: 0.3477616310119629
Batch 52/64 loss: 0.3484485149383545
Batch 53/64 loss: 0.34982651472091675
Batch 54/64 loss: 0.3481311798095703
Batch 55/64 loss: 0.34831702709198
Batch 56/64 loss: 0.35540562868118286
Batch 57/64 loss: 0.34623682498931885
Batch 58/64 loss: 0.35200583934783936
Batch 59/64 loss: 0.3448582887649536
Batch 60/64 loss: 0.35147911310195923
Batch 61/64 loss: 0.34840524196624756
Batch 62/64 loss: 0.3516782522201538
Batch 63/64 loss: 0.3497437834739685
Batch 64/64 loss: 0.34657740592956543
Epoch 122  Train loss: 0.34895129110298906  Val loss: 0.35332005294327884
Saving best model, epoch: 122
Epoch 123
-------------------------------
Batch 1/64 loss: 0.34655213356018066
Batch 2/64 loss: 0.3495466709136963
Batch 3/64 loss: 0.3418281674385071
Batch 4/64 loss: 0.34963834285736084
Batch 5/64 loss: 0.34698426723480225
Batch 6/64 loss: 0.3456668257713318
Batch 7/64 loss: 0.34860503673553467
Batch 8/64 loss: 0.34869319200515747
Batch 9/64 loss: 0.3476318120956421
Batch 10/64 loss: 0.3503262996673584
Batch 11/64 loss: 0.34562915563583374
Batch 12/64 loss: 0.35025638341903687
Batch 13/64 loss: 0.3492671251296997
Batch 14/64 loss: 0.3521624803543091
Batch 15/64 loss: 0.3532801866531372
Batch 16/64 loss: 0.3456014394760132
Batch 17/64 loss: 0.35069602727890015
Batch 18/64 loss: 0.34857118129730225
Batch 19/64 loss: 0.3502541780471802
Batch 20/64 loss: 0.34718525409698486
Batch 21/64 loss: 0.3549455404281616
Batch 22/64 loss: 0.3471860885620117
Batch 23/64 loss: 0.3509851098060608
Batch 24/64 loss: 0.35074329376220703
Batch 25/64 loss: 0.3524402379989624
Batch 26/64 loss: 0.3523077964782715
Batch 27/64 loss: 0.3507983088493347
Batch 28/64 loss: 0.35219907760620117
Batch 29/64 loss: 0.3498239517211914
Batch 30/64 loss: 0.349928617477417
Batch 31/64 loss: 0.3475762605667114
Batch 32/64 loss: 0.35171401500701904
Batch 33/64 loss: 0.345769464969635
Batch 34/64 loss: 0.3468475341796875
Batch 35/64 loss: 0.34114402532577515
Batch 36/64 loss: 0.3510516881942749
Batch 37/64 loss: 0.3439566493034363
Batch 38/64 loss: 0.35023272037506104
Batch 39/64 loss: 0.3415899872779846
Batch 40/64 loss: 0.34701889753341675
Batch 41/64 loss: 0.34430110454559326
Batch 42/64 loss: 0.3512493371963501
Batch 43/64 loss: 0.35018980503082275
Batch 44/64 loss: 0.34952855110168457
Batch 45/64 loss: 0.3472781181335449
Batch 46/64 loss: 0.3432759642601013
Batch 47/64 loss: 0.3526653051376343
Batch 48/64 loss: 0.3506009578704834
Batch 49/64 loss: 0.3418024182319641
Batch 50/64 loss: 0.3501444458961487
Batch 51/64 loss: 0.35144972801208496
Batch 52/64 loss: 0.3459402322769165
Batch 53/64 loss: 0.35026752948760986
Batch 54/64 loss: 0.3464723229408264
Batch 55/64 loss: 0.35002827644348145
Batch 56/64 loss: 0.35101765394210815
Batch 57/64 loss: 0.34867918491363525
Batch 58/64 loss: 0.3440283536911011
Batch 59/64 loss: 0.3498516082763672
Batch 60/64 loss: 0.34734034538269043
Batch 61/64 loss: 0.34955763816833496
Batch 62/64 loss: 0.34468257427215576
Batch 63/64 loss: 0.34575319290161133
Batch 64/64 loss: 0.35070639848709106
Epoch 123  Train loss: 0.3484826646599115  Val loss: 0.3534613554829994
Epoch 124
-------------------------------
Batch 1/64 loss: 0.35022252798080444
Batch 2/64 loss: 0.34692901372909546
Batch 3/64 loss: 0.33957695960998535
Batch 4/64 loss: 0.35049641132354736
Batch 5/64 loss: 0.3491947650909424
Batch 6/64 loss: 0.35187554359436035
Batch 7/64 loss: 0.3443986773490906
Batch 8/64 loss: 0.35010355710983276
Batch 9/64 loss: 0.34732258319854736
Batch 10/64 loss: 0.3515160083770752
Batch 11/64 loss: 0.3502713441848755
Batch 12/64 loss: 0.3472573757171631
Batch 13/64 loss: 0.3470498323440552
Batch 14/64 loss: 0.3520243167877197
Batch 15/64 loss: 0.34386229515075684
Batch 16/64 loss: 0.349511981010437
Batch 17/64 loss: 0.35117077827453613
Batch 18/64 loss: 0.3516228199005127
Batch 19/64 loss: 0.34398698806762695
Batch 20/64 loss: 0.35104864835739136
Batch 21/64 loss: 0.3427610993385315
Batch 22/64 loss: 0.34661608934402466
Batch 23/64 loss: 0.3483917713165283
Batch 24/64 loss: 0.347575306892395
Batch 25/64 loss: 0.3450217843055725
Batch 26/64 loss: 0.35233259201049805
Batch 27/64 loss: 0.345938503742218
Batch 28/64 loss: 0.35064220428466797
Batch 29/64 loss: 0.35136890411376953
Batch 30/64 loss: 0.349773108959198
Batch 31/64 loss: 0.34723615646362305
Batch 32/64 loss: 0.3506961464881897
Batch 33/64 loss: 0.3492143154144287
Batch 34/64 loss: 0.3523341417312622
Batch 35/64 loss: 0.35089755058288574
Batch 36/64 loss: 0.34981298446655273
Batch 37/64 loss: 0.34629714488983154
Batch 38/64 loss: 0.355010986328125
Batch 39/64 loss: 0.34393906593322754
Batch 40/64 loss: 0.3442111015319824
Batch 41/64 loss: 0.347528338432312
Batch 42/64 loss: 0.3510606288909912
Batch 43/64 loss: 0.3468276858329773
Batch 44/64 loss: 0.34940505027770996
Batch 45/64 loss: 0.35186684131622314
Batch 46/64 loss: 0.3502041697502136
Batch 47/64 loss: 0.3529844880104065
Batch 48/64 loss: 0.35040974617004395
Batch 49/64 loss: 0.34607285261154175
Batch 50/64 loss: 0.35367345809936523
Batch 51/64 loss: 0.35257816314697266
Batch 52/64 loss: 0.3467339277267456
Batch 53/64 loss: 0.3506341576576233
Batch 54/64 loss: 0.3452438712120056
Batch 55/64 loss: 0.342501163482666
Batch 56/64 loss: 0.34825921058654785
Batch 57/64 loss: 0.3453099727630615
Batch 58/64 loss: 0.34741777181625366
Batch 59/64 loss: 0.349578857421875
Batch 60/64 loss: 0.3488803505897522
Batch 61/64 loss: 0.35127270221710205
Batch 62/64 loss: 0.3480234146118164
Batch 63/64 loss: 0.3485332727432251
Batch 64/64 loss: 0.3502204418182373
Epoch 124  Train loss: 0.3486616284239526  Val loss: 0.3543161768274209
Epoch 125
-------------------------------
Batch 1/64 loss: 0.34467387199401855
Batch 2/64 loss: 0.34557420015335083
Batch 3/64 loss: 0.34700334072113037
Batch 4/64 loss: 0.3503938317298889
Batch 5/64 loss: 0.34525632858276367
Batch 6/64 loss: 0.3457404375076294
Batch 7/64 loss: 0.34747904539108276
Batch 8/64 loss: 0.34669071435928345
Batch 9/64 loss: 0.3497295379638672
Batch 10/64 loss: 0.3513273000717163
Batch 11/64 loss: 0.3530449867248535
Batch 12/64 loss: 0.3503216505050659
Batch 13/64 loss: 0.3486969470977783
Batch 14/64 loss: 0.34963905811309814
Batch 15/64 loss: 0.34892845153808594
Batch 16/64 loss: 0.3445485830307007
Batch 17/64 loss: 0.35034340620040894
Batch 18/64 loss: 0.3402581214904785
Batch 19/64 loss: 0.3500523567199707
Batch 20/64 loss: 0.3456214666366577
Batch 21/64 loss: 0.34488916397094727
Batch 22/64 loss: 0.35118567943573
Batch 23/64 loss: 0.35143303871154785
Batch 24/64 loss: 0.3488615155220032
Batch 25/64 loss: 0.3488645553588867
Batch 26/64 loss: 0.34525370597839355
Batch 27/64 loss: 0.3487446904182434
Batch 28/64 loss: 0.35046637058258057
Batch 29/64 loss: 0.3497661352157593
Batch 30/64 loss: 0.3488243818283081
Batch 31/64 loss: 0.345847487449646
Batch 32/64 loss: 0.34851908683776855
Batch 33/64 loss: 0.3440730571746826
Batch 34/64 loss: 0.35216134786605835
Batch 35/64 loss: 0.34960949420928955
Batch 36/64 loss: 0.3512299060821533
Batch 37/64 loss: 0.34942781925201416
Batch 38/64 loss: 0.3499950170516968
Batch 39/64 loss: 0.35096776485443115
Batch 40/64 loss: 0.35053741931915283
Batch 41/64 loss: 0.34687483310699463
Batch 42/64 loss: 0.3507228493690491
Batch 43/64 loss: 0.34812217950820923
Batch 44/64 loss: 0.35159939527511597
Batch 45/64 loss: 0.3425614833831787
Batch 46/64 loss: 0.3486509323120117
Batch 47/64 loss: 0.3492916226387024
Batch 48/64 loss: 0.35096418857574463
Batch 49/64 loss: 0.34826767444610596
Batch 50/64 loss: 0.3505840301513672
Batch 51/64 loss: 0.34932100772857666
Batch 52/64 loss: 0.35232532024383545
Batch 53/64 loss: 0.3515812158584595
Batch 54/64 loss: 0.3497142195701599
Batch 55/64 loss: 0.3493894338607788
Batch 56/64 loss: 0.35178327560424805
Batch 57/64 loss: 0.34724634885787964
Batch 58/64 loss: 0.3517046570777893
Batch 59/64 loss: 0.3455314636230469
Batch 60/64 loss: 0.34979212284088135
Batch 61/64 loss: 0.34918391704559326
Batch 62/64 loss: 0.3462926149368286
Batch 63/64 loss: 0.3481367230415344
Batch 64/64 loss: 0.3486759662628174
Epoch 125  Train loss: 0.34866085893967574  Val loss: 0.35293183765050884
Saving best model, epoch: 125
Epoch 126
-------------------------------
Batch 1/64 loss: 0.3503996729850769
Batch 2/64 loss: 0.341286301612854
Batch 3/64 loss: 0.35121405124664307
Batch 4/64 loss: 0.3444427251815796
Batch 5/64 loss: 0.3484189510345459
Batch 6/64 loss: 0.3460702896118164
Batch 7/64 loss: 0.34798765182495117
Batch 8/64 loss: 0.34614479541778564
Batch 9/64 loss: 0.34714895486831665
Batch 10/64 loss: 0.35199475288391113
Batch 11/64 loss: 0.3466808795928955
Batch 12/64 loss: 0.3459738492965698
Batch 13/64 loss: 0.3476794958114624
Batch 14/64 loss: 0.3472328186035156
Batch 15/64 loss: 0.3454377055168152
Batch 16/64 loss: 0.344262957572937
Batch 17/64 loss: 0.35248327255249023
Batch 18/64 loss: 0.34346306324005127
Batch 19/64 loss: 0.34681224822998047
Batch 20/64 loss: 0.3484448194503784
Batch 21/64 loss: 0.35147368907928467
Batch 22/64 loss: 0.34757792949676514
Batch 23/64 loss: 0.35096025466918945
Batch 24/64 loss: 0.35019534826278687
Batch 25/64 loss: 0.34605932235717773
Batch 26/64 loss: 0.3453378677368164
Batch 27/64 loss: 0.3520384430885315
Batch 28/64 loss: 0.3453810214996338
Batch 29/64 loss: 0.34872984886169434
Batch 30/64 loss: 0.35140860080718994
Batch 31/64 loss: 0.3475378751754761
Batch 32/64 loss: 0.3464308977127075
Batch 33/64 loss: 0.3503667116165161
Batch 34/64 loss: 0.34678375720977783
Batch 35/64 loss: 0.3515702486038208
Batch 36/64 loss: 0.34626930952072144
Batch 37/64 loss: 0.3490384817123413
Batch 38/64 loss: 0.3511847257614136
Batch 39/64 loss: 0.34591078758239746
Batch 40/64 loss: 0.3430790901184082
Batch 41/64 loss: 0.35553956031799316
Batch 42/64 loss: 0.3475630283355713
Batch 43/64 loss: 0.3475205898284912
Batch 44/64 loss: 0.3486076593399048
Batch 45/64 loss: 0.3474845886230469
Batch 46/64 loss: 0.34505695104599
Batch 47/64 loss: 0.3470761775970459
Batch 48/64 loss: 0.3477288484573364
Batch 49/64 loss: 0.34685975313186646
Batch 50/64 loss: 0.34923553466796875
Batch 51/64 loss: 0.3537951111793518
Batch 52/64 loss: 0.35088860988616943
Batch 53/64 loss: 0.34460562467575073
Batch 54/64 loss: 0.35060441493988037
Batch 55/64 loss: 0.35009074211120605
Batch 56/64 loss: 0.34365522861480713
Batch 57/64 loss: 0.34711289405822754
Batch 58/64 loss: 0.352186918258667
Batch 59/64 loss: 0.3445706367492676
Batch 60/64 loss: 0.34889400005340576
Batch 61/64 loss: 0.3535768985748291
Batch 62/64 loss: 0.3492755889892578
Batch 63/64 loss: 0.34848570823669434
Batch 64/64 loss: 0.35028308629989624
Epoch 126  Train loss: 0.34814181725184123  Val loss: 0.3531031305437645
Epoch 127
-------------------------------
Batch 1/64 loss: 0.34569478034973145
Batch 2/64 loss: 0.34539324045181274
Batch 3/64 loss: 0.35604745149612427
Batch 4/64 loss: 0.3449355363845825
Batch 5/64 loss: 0.3523613214492798
Batch 6/64 loss: 0.3456016778945923
Batch 7/64 loss: 0.34644991159439087
Batch 8/64 loss: 0.34847772121429443
Batch 9/64 loss: 0.34719979763031006
Batch 10/64 loss: 0.35070550441741943
Batch 11/64 loss: 0.3528566360473633
Batch 12/64 loss: 0.3452499508857727
Batch 13/64 loss: 0.34978294372558594
Batch 14/64 loss: 0.3465883731842041
Batch 15/64 loss: 0.3453162908554077
Batch 16/64 loss: 0.34985387325286865
Batch 17/64 loss: 0.34694695472717285
Batch 18/64 loss: 0.34744709730148315
Batch 19/64 loss: 0.347966730594635
Batch 20/64 loss: 0.35125285387039185
Batch 21/64 loss: 0.3501697778701782
Batch 22/64 loss: 0.34732580184936523
Batch 23/64 loss: 0.3472851514816284
Batch 24/64 loss: 0.3476690649986267
Batch 25/64 loss: 0.34890127182006836
Batch 26/64 loss: 0.348788321018219
Batch 27/64 loss: 0.3496917486190796
Batch 28/64 loss: 0.3485332727432251
Batch 29/64 loss: 0.33940351009368896
Batch 30/64 loss: 0.34575867652893066
Batch 31/64 loss: 0.3464089035987854
Batch 32/64 loss: 0.351887047290802
Batch 33/64 loss: 0.3437439203262329
Batch 34/64 loss: 0.350177526473999
Batch 35/64 loss: 0.3532613515853882
Batch 36/64 loss: 0.3428153991699219
Batch 37/64 loss: 0.34389305114746094
Batch 38/64 loss: 0.350028395652771
Batch 39/64 loss: 0.35192155838012695
Batch 40/64 loss: 0.35267913341522217
Batch 41/64 loss: 0.3492659330368042
Batch 42/64 loss: 0.34699511528015137
Batch 43/64 loss: 0.3483179807662964
Batch 44/64 loss: 0.3477334976196289
Batch 45/64 loss: 0.35404133796691895
Batch 46/64 loss: 0.34723854064941406
Batch 47/64 loss: 0.3442106246948242
Batch 48/64 loss: 0.3520001173019409
Batch 49/64 loss: 0.3483457565307617
Batch 50/64 loss: 0.3502996563911438
Batch 51/64 loss: 0.3481292724609375
Batch 52/64 loss: 0.3440648913383484
Batch 53/64 loss: 0.3488155007362366
Batch 54/64 loss: 0.34603720903396606
Batch 55/64 loss: 0.34456610679626465
Batch 56/64 loss: 0.3473973274230957
Batch 57/64 loss: 0.3425952196121216
Batch 58/64 loss: 0.3509858250617981
Batch 59/64 loss: 0.35124635696411133
Batch 60/64 loss: 0.35378265380859375
Batch 61/64 loss: 0.34892165660858154
Batch 62/64 loss: 0.3487814664840698
Batch 63/64 loss: 0.3541949987411499
Batch 64/64 loss: 0.3487536907196045
Epoch 127  Train loss: 0.3483294720743217  Val loss: 0.3535303913850555
Epoch 128
-------------------------------
Batch 1/64 loss: 0.3488723039627075
Batch 2/64 loss: 0.34924089908599854
Batch 3/64 loss: 0.34613966941833496
Batch 4/64 loss: 0.34887397289276123
Batch 5/64 loss: 0.3514299988746643
Batch 6/64 loss: 0.3469809293746948
Batch 7/64 loss: 0.34967291355133057
Batch 8/64 loss: 0.3469505310058594
Batch 9/64 loss: 0.3472144603729248
Batch 10/64 loss: 0.34843575954437256
Batch 11/64 loss: 0.34655535221099854
Batch 12/64 loss: 0.3463740348815918
Batch 13/64 loss: 0.3491118550300598
Batch 14/64 loss: 0.346439003944397
Batch 15/64 loss: 0.3476954698562622
Batch 16/64 loss: 0.3479294776916504
Batch 17/64 loss: 0.3487549424171448
Batch 18/64 loss: 0.34142088890075684
Batch 19/64 loss: 0.3491528034210205
Batch 20/64 loss: 0.3441338539123535
Batch 21/64 loss: 0.35285305976867676
Batch 22/64 loss: 0.3501657247543335
Batch 23/64 loss: 0.3487560749053955
Batch 24/64 loss: 0.34898269176483154
Batch 25/64 loss: 0.3512439727783203
Batch 26/64 loss: 0.3485785722732544
Batch 27/64 loss: 0.34787052869796753
Batch 28/64 loss: 0.3479645848274231
Batch 29/64 loss: 0.3451892137527466
Batch 30/64 loss: 0.34373360872268677
Batch 31/64 loss: 0.35165292024612427
Batch 32/64 loss: 0.3470345735549927
Batch 33/64 loss: 0.3480960726737976
Batch 34/64 loss: 0.34938478469848633
Batch 35/64 loss: 0.3515031337738037
Batch 36/64 loss: 0.3416692018508911
Batch 37/64 loss: 0.35009312629699707
Batch 38/64 loss: 0.3491808772087097
Batch 39/64 loss: 0.34354132413864136
Batch 40/64 loss: 0.3486403226852417
Batch 41/64 loss: 0.35507166385650635
Batch 42/64 loss: 0.35112643241882324
Batch 43/64 loss: 0.34976959228515625
Batch 44/64 loss: 0.3497222661972046
Batch 45/64 loss: 0.34914135932922363
Batch 46/64 loss: 0.34798383712768555
Batch 47/64 loss: 0.34427547454833984
Batch 48/64 loss: 0.3454725742340088
Batch 49/64 loss: 0.3454267978668213
Batch 50/64 loss: 0.3450462222099304
Batch 51/64 loss: 0.3505209684371948
Batch 52/64 loss: 0.34735846519470215
Batch 53/64 loss: 0.3486359119415283
Batch 54/64 loss: 0.3437286615371704
Batch 55/64 loss: 0.3487497568130493
Batch 56/64 loss: 0.346524715423584
Batch 57/64 loss: 0.3550497889518738
Batch 58/64 loss: 0.3445761203765869
Batch 59/64 loss: 0.3535749316215515
Batch 60/64 loss: 0.34157228469848633
Batch 61/64 loss: 0.3462660312652588
Batch 62/64 loss: 0.3532440662384033
Batch 63/64 loss: 0.353629469871521
Batch 64/64 loss: 0.3474092483520508
Epoch 128  Train loss: 0.3481496128381467  Val loss: 0.3532251238413283
Epoch 129
-------------------------------
Batch 1/64 loss: 0.34408038854599
Batch 2/64 loss: 0.3451664447784424
Batch 3/64 loss: 0.3468368649482727
Batch 4/64 loss: 0.35386228561401367
Batch 5/64 loss: 0.34889310598373413
Batch 6/64 loss: 0.34358227252960205
Batch 7/64 loss: 0.34639889001846313
Batch 8/64 loss: 0.3481658697128296
Batch 9/64 loss: 0.3468513488769531
Batch 10/64 loss: 0.3438570499420166
Batch 11/64 loss: 0.3474528193473816
Batch 12/64 loss: 0.3501560091972351
Batch 13/64 loss: 0.3429391384124756
Batch 14/64 loss: 0.3448110818862915
Batch 15/64 loss: 0.3501002788543701
Batch 16/64 loss: 0.3499412536621094
Batch 17/64 loss: 0.35304510593414307
Batch 18/64 loss: 0.35198843479156494
Batch 19/64 loss: 0.34714066982269287
Batch 20/64 loss: 0.35412561893463135
Batch 21/64 loss: 0.35214799642562866
Batch 22/64 loss: 0.34628331661224365
Batch 23/64 loss: 0.3471683859825134
Batch 24/64 loss: 0.34897923469543457
Batch 25/64 loss: 0.34629714488983154
Batch 26/64 loss: 0.342634916305542
Batch 27/64 loss: 0.3449209928512573
Batch 28/64 loss: 0.34500038623809814
Batch 29/64 loss: 0.3481781482696533
Batch 30/64 loss: 0.34825754165649414
Batch 31/64 loss: 0.34466981887817383
Batch 32/64 loss: 0.34512293338775635
Batch 33/64 loss: 0.3482329249382019
Batch 34/64 loss: 0.34742826223373413
Batch 35/64 loss: 0.35382962226867676
Batch 36/64 loss: 0.34399569034576416
Batch 37/64 loss: 0.34407055377960205
Batch 38/64 loss: 0.3513023853302002
Batch 39/64 loss: 0.3443882465362549
Batch 40/64 loss: 0.3459796905517578
Batch 41/64 loss: 0.3495398759841919
Batch 42/64 loss: 0.3486630916595459
Batch 43/64 loss: 0.34943902492523193
Batch 44/64 loss: 0.3451629877090454
Batch 45/64 loss: 0.34619569778442383
Batch 46/64 loss: 0.34825658798217773
Batch 47/64 loss: 0.3526798486709595
Batch 48/64 loss: 0.35393667221069336
Batch 49/64 loss: 0.34701061248779297
Batch 50/64 loss: 0.34778380393981934
Batch 51/64 loss: 0.34693801403045654
Batch 52/64 loss: 0.34468185901641846
Batch 53/64 loss: 0.34837621450424194
Batch 54/64 loss: 0.34735286235809326
Batch 55/64 loss: 0.3497741222381592
Batch 56/64 loss: 0.34789514541625977
Batch 57/64 loss: 0.349124550819397
Batch 58/64 loss: 0.35136228799819946
Batch 59/64 loss: 0.34884196519851685
Batch 60/64 loss: 0.34615373611450195
Batch 61/64 loss: 0.3503071069717407
Batch 62/64 loss: 0.3487616181373596
Batch 63/64 loss: 0.35289686918258667
Batch 64/64 loss: 0.3496335744857788
Epoch 129  Train loss: 0.34794733898312435  Val loss: 0.3527299833461591
Saving best model, epoch: 129
Epoch 130
-------------------------------
Batch 1/64 loss: 0.34577715396881104
Batch 2/64 loss: 0.3461887836456299
Batch 3/64 loss: 0.34778302907943726
Batch 4/64 loss: 0.33979761600494385
Batch 5/64 loss: 0.34864258766174316
Batch 6/64 loss: 0.3511408567428589
Batch 7/64 loss: 0.34375500679016113
Batch 8/64 loss: 0.3436828851699829
Batch 9/64 loss: 0.33967578411102295
Batch 10/64 loss: 0.3463468551635742
Batch 11/64 loss: 0.34382450580596924
Batch 12/64 loss: 0.3466634750366211
Batch 13/64 loss: 0.34403717517852783
Batch 14/64 loss: 0.344518780708313
Batch 15/64 loss: 0.3469550609588623
Batch 16/64 loss: 0.3494671583175659
Batch 17/64 loss: 0.3509875535964966
Batch 18/64 loss: 0.34232980012893677
Batch 19/64 loss: 0.3477135896682739
Batch 20/64 loss: 0.34749025106430054
Batch 21/64 loss: 0.34951186180114746
Batch 22/64 loss: 0.3480917811393738
Batch 23/64 loss: 0.35325169563293457
Batch 24/64 loss: 0.3440017104148865
Batch 25/64 loss: 0.3451938033103943
Batch 26/64 loss: 0.34529411792755127
Batch 27/64 loss: 0.34752345085144043
Batch 28/64 loss: 0.3536107540130615
Batch 29/64 loss: 0.3515748977661133
Batch 30/64 loss: 0.34599560499191284
Batch 31/64 loss: 0.3530094623565674
Batch 32/64 loss: 0.35039710998535156
Batch 33/64 loss: 0.3434720039367676
Batch 34/64 loss: 0.3506057858467102
Batch 35/64 loss: 0.3509148359298706
Batch 36/64 loss: 0.34560513496398926
Batch 37/64 loss: 0.346008837223053
Batch 38/64 loss: 0.3473441004753113
Batch 39/64 loss: 0.3525230884552002
Batch 40/64 loss: 0.3462417721748352
Batch 41/64 loss: 0.3495701551437378
Batch 42/64 loss: 0.34838026762008667
Batch 43/64 loss: 0.34899425506591797
Batch 44/64 loss: 0.34849095344543457
Batch 45/64 loss: 0.34406131505966187
Batch 46/64 loss: 0.34967732429504395
Batch 47/64 loss: 0.3541613221168518
Batch 48/64 loss: 0.3516653776168823
Batch 49/64 loss: 0.35410672426223755
Batch 50/64 loss: 0.34258830547332764
Batch 51/64 loss: 0.3491542339324951
Batch 52/64 loss: 0.34720736742019653
Batch 53/64 loss: 0.35253244638442993
Batch 54/64 loss: 0.344226598739624
Batch 55/64 loss: 0.34583616256713867
Batch 56/64 loss: 0.34853595495224
Batch 57/64 loss: 0.3405677080154419
Batch 58/64 loss: 0.3450000286102295
Batch 59/64 loss: 0.34600841999053955
Batch 60/64 loss: 0.3472253084182739
Batch 61/64 loss: 0.34453946352005005
Batch 62/64 loss: 0.34988927841186523
Batch 63/64 loss: 0.35150671005249023
Batch 64/64 loss: 0.34565675258636475
Epoch 130  Train loss: 0.3474528308008231  Val loss: 0.3519917919054064
Saving best model, epoch: 130
Epoch 131
-------------------------------
Batch 1/64 loss: 0.35026150941848755
Batch 2/64 loss: 0.3455091118812561
Batch 3/64 loss: 0.3441546559333801
Batch 4/64 loss: 0.3439685106277466
Batch 5/64 loss: 0.34452223777770996
Batch 6/64 loss: 0.3473655581474304
Batch 7/64 loss: 0.3435925245285034
Batch 8/64 loss: 0.34774279594421387
Batch 9/64 loss: 0.3462628126144409
Batch 10/64 loss: 0.3510366678237915
Batch 11/64 loss: 0.3455255627632141
Batch 12/64 loss: 0.34238266944885254
Batch 13/64 loss: 0.34872329235076904
Batch 14/64 loss: 0.3433365821838379
Batch 15/64 loss: 0.35309410095214844
Batch 16/64 loss: 0.33806347846984863
Batch 17/64 loss: 0.345386803150177
Batch 18/64 loss: 0.34774279594421387
Batch 19/64 loss: 0.34546220302581787
Batch 20/64 loss: 0.345211386680603
Batch 21/64 loss: 0.35073089599609375
Batch 22/64 loss: 0.34764301776885986
Batch 23/64 loss: 0.34861457347869873
Batch 24/64 loss: 0.3471938371658325
Batch 25/64 loss: 0.3451734185218811
Batch 26/64 loss: 0.35383331775665283
Batch 27/64 loss: 0.34914886951446533
Batch 28/64 loss: 0.3462582230567932
Batch 29/64 loss: 0.34404683113098145
Batch 30/64 loss: 0.34896981716156006
Batch 31/64 loss: 0.34636378288269043
Batch 32/64 loss: 0.34956830739974976
Batch 33/64 loss: 0.3444838523864746
Batch 34/64 loss: 0.3544089198112488
Batch 35/64 loss: 0.3505910038948059
Batch 36/64 loss: 0.3419376015663147
Batch 37/64 loss: 0.3459075093269348
Batch 38/64 loss: 0.3515719175338745
Batch 39/64 loss: 0.3514974117279053
Batch 40/64 loss: 0.35268735885620117
Batch 41/64 loss: 0.3516240119934082
Batch 42/64 loss: 0.348666787147522
Batch 43/64 loss: 0.3539245128631592
Batch 44/64 loss: 0.3509734869003296
Batch 45/64 loss: 0.34652310609817505
Batch 46/64 loss: 0.344632089138031
Batch 47/64 loss: 0.3431652784347534
Batch 48/64 loss: 0.34794050455093384
Batch 49/64 loss: 0.3434138298034668
Batch 50/64 loss: 0.3470640778541565
Batch 51/64 loss: 0.35083460807800293
Batch 52/64 loss: 0.34313368797302246
Batch 53/64 loss: 0.3437252640724182
Batch 54/64 loss: 0.3479173183441162
Batch 55/64 loss: 0.3466697931289673
Batch 56/64 loss: 0.346551775932312
Batch 57/64 loss: 0.35036641359329224
Batch 58/64 loss: 0.3498913645744324
Batch 59/64 loss: 0.3559664487838745
Batch 60/64 loss: 0.3399568796157837
Batch 61/64 loss: 0.3499187231063843
Batch 62/64 loss: 0.3440454602241516
Batch 63/64 loss: 0.35527682304382324
Batch 64/64 loss: 0.3435072898864746
Epoch 131  Train loss: 0.3474476617925307  Val loss: 0.353962666799932
Epoch 132
-------------------------------
Batch 1/64 loss: 0.3526279926300049
Batch 2/64 loss: 0.35057902336120605
Batch 3/64 loss: 0.3483770489692688
Batch 4/64 loss: 0.35126352310180664
Batch 5/64 loss: 0.34444141387939453
Batch 6/64 loss: 0.3424227237701416
Batch 7/64 loss: 0.3496757745742798
Batch 8/64 loss: 0.3495415449142456
Batch 9/64 loss: 0.348078191280365
Batch 10/64 loss: 0.35170578956604004
Batch 11/64 loss: 0.34025663137435913
Batch 12/64 loss: 0.3458425998687744
Batch 13/64 loss: 0.3415454626083374
Batch 14/64 loss: 0.3488723039627075
Batch 15/64 loss: 0.3474960923194885
Batch 16/64 loss: 0.3493785858154297
Batch 17/64 loss: 0.3450421094894409
Batch 18/64 loss: 0.34196603298187256
Batch 19/64 loss: 0.3490264415740967
Batch 20/64 loss: 0.34254956245422363
Batch 21/64 loss: 0.3437979221343994
Batch 22/64 loss: 0.3448445796966553
Batch 23/64 loss: 0.35234344005584717
Batch 24/64 loss: 0.347365140914917
Batch 25/64 loss: 0.35152220726013184
Batch 26/64 loss: 0.3485909700393677
Batch 27/64 loss: 0.34597426652908325
Batch 28/64 loss: 0.34909772872924805
Batch 29/64 loss: 0.3462274670600891
Batch 30/64 loss: 0.3426170349121094
Batch 31/64 loss: 0.3481484055519104
Batch 32/64 loss: 0.3486090898513794
Batch 33/64 loss: 0.3509707450866699
Batch 34/64 loss: 0.3492717742919922
Batch 35/64 loss: 0.3440302610397339
Batch 36/64 loss: 0.3464322090148926
Batch 37/64 loss: 0.35193920135498047
Batch 38/64 loss: 0.34781599044799805
Batch 39/64 loss: 0.34339648485183716
Batch 40/64 loss: 0.3394697904586792
Batch 41/64 loss: 0.34796857833862305
Batch 42/64 loss: 0.3462764024734497
Batch 43/64 loss: 0.34416067600250244
Batch 44/64 loss: 0.3507567048072815
Batch 45/64 loss: 0.35287654399871826
Batch 46/64 loss: 0.3493523597717285
Batch 47/64 loss: 0.34838199615478516
Batch 48/64 loss: 0.34738391637802124
Batch 49/64 loss: 0.3510018587112427
Batch 50/64 loss: 0.3467866778373718
Batch 51/64 loss: 0.344340443611145
Batch 52/64 loss: 0.35083043575286865
Batch 53/64 loss: 0.3499566316604614
Batch 54/64 loss: 0.34749889373779297
Batch 55/64 loss: 0.35260236263275146
Batch 56/64 loss: 0.34913361072540283
Batch 57/64 loss: 0.34563523530960083
Batch 58/64 loss: 0.34605371952056885
Batch 59/64 loss: 0.34809762239456177
Batch 60/64 loss: 0.3466223478317261
Batch 61/64 loss: 0.34665971994400024
Batch 62/64 loss: 0.3427128195762634
Batch 63/64 loss: 0.3439444303512573
Batch 64/64 loss: 0.3448639512062073
Epoch 132  Train loss: 0.347307223665948  Val loss: 0.35181565710769075
Saving best model, epoch: 132
Epoch 133
-------------------------------
Batch 1/64 loss: 0.3494434952735901
Batch 2/64 loss: 0.3496241569519043
Batch 3/64 loss: 0.3437073230743408
Batch 4/64 loss: 0.34280622005462646
Batch 5/64 loss: 0.3439842462539673
Batch 6/64 loss: 0.34013795852661133
Batch 7/64 loss: 0.3461565375328064
Batch 8/64 loss: 0.34300410747528076
Batch 9/64 loss: 0.3452642560005188
Batch 10/64 loss: 0.3431791663169861
Batch 11/64 loss: 0.34545981884002686
Batch 12/64 loss: 0.3471241593360901
Batch 13/64 loss: 0.34530186653137207
Batch 14/64 loss: 0.3440457582473755
Batch 15/64 loss: 0.3467562198638916
Batch 16/64 loss: 0.34894871711730957
Batch 17/64 loss: 0.3521096706390381
Batch 18/64 loss: 0.34776079654693604
Batch 19/64 loss: 0.34825026988983154
Batch 20/64 loss: 0.3435528874397278
Batch 21/64 loss: 0.3474528193473816
Batch 22/64 loss: 0.3509218692779541
Batch 23/64 loss: 0.34672367572784424
Batch 24/64 loss: 0.3478175401687622
Batch 25/64 loss: 0.34494441747665405
Batch 26/64 loss: 0.3458305597305298
Batch 27/64 loss: 0.3478342294692993
Batch 28/64 loss: 0.34941816329956055
Batch 29/64 loss: 0.34089648723602295
Batch 30/64 loss: 0.34794914722442627
Batch 31/64 loss: 0.35133683681488037
Batch 32/64 loss: 0.343999981880188
Batch 33/64 loss: 0.3491528034210205
Batch 34/64 loss: 0.35066795349121094
Batch 35/64 loss: 0.34801292419433594
Batch 36/64 loss: 0.3496962785720825
Batch 37/64 loss: 0.3443131446838379
Batch 38/64 loss: 0.34426242113113403
Batch 39/64 loss: 0.3428792953491211
Batch 40/64 loss: 0.3418225646018982
Batch 41/64 loss: 0.34623539447784424
Batch 42/64 loss: 0.3477630615234375
Batch 43/64 loss: 0.35026609897613525
Batch 44/64 loss: 0.35617536306381226
Batch 45/64 loss: 0.3470603823661804
Batch 46/64 loss: 0.35222744941711426
Batch 47/64 loss: 0.3450223207473755
Batch 48/64 loss: 0.3462711572647095
Batch 49/64 loss: 0.3439810276031494
Batch 50/64 loss: 0.3499178886413574
Batch 51/64 loss: 0.346588134765625
Batch 52/64 loss: 0.3454538583755493
Batch 53/64 loss: 0.34845733642578125
Batch 54/64 loss: 0.3462054133415222
Batch 55/64 loss: 0.3499103784561157
Batch 56/64 loss: 0.34858524799346924
Batch 57/64 loss: 0.35619133710861206
Batch 58/64 loss: 0.350805401802063
Batch 59/64 loss: 0.34880876541137695
Batch 60/64 loss: 0.3501368761062622
Batch 61/64 loss: 0.3468155860900879
Batch 62/64 loss: 0.3441516160964966
Batch 63/64 loss: 0.3502923250198364
Batch 64/64 loss: 0.34861695766448975
Epoch 133  Train loss: 0.3471582099503162  Val loss: 0.3522793914853912
Epoch 134
-------------------------------
Batch 1/64 loss: 0.349959135055542
Batch 2/64 loss: 0.34917503595352173
Batch 3/64 loss: 0.3443617820739746
Batch 4/64 loss: 0.34518498182296753
Batch 5/64 loss: 0.3499263525009155
Batch 6/64 loss: 0.34829914569854736
Batch 7/64 loss: 0.3434479236602783
Batch 8/64 loss: 0.35344094038009644
Batch 9/64 loss: 0.3464198112487793
Batch 10/64 loss: 0.34277045726776123
Batch 11/64 loss: 0.347176194190979
Batch 12/64 loss: 0.3445938229560852
Batch 13/64 loss: 0.34995317459106445
Batch 14/64 loss: 0.34911537170410156
Batch 15/64 loss: 0.35240936279296875
Batch 16/64 loss: 0.34739476442337036
Batch 17/64 loss: 0.34754931926727295
Batch 18/64 loss: 0.34793180227279663
Batch 19/64 loss: 0.3412081003189087
Batch 20/64 loss: 0.3436816930770874
Batch 21/64 loss: 0.34970933198928833
Batch 22/64 loss: 0.3437284231185913
Batch 23/64 loss: 0.3527600169181824
Batch 24/64 loss: 0.3497309684753418
Batch 25/64 loss: 0.3518843650817871
Batch 26/64 loss: 0.34349536895751953
Batch 27/64 loss: 0.3486452102661133
Batch 28/64 loss: 0.34253108501434326
Batch 29/64 loss: 0.34587377309799194
Batch 30/64 loss: 0.3443974256515503
Batch 31/64 loss: 0.3468019366264343
Batch 32/64 loss: 0.3485652804374695
Batch 33/64 loss: 0.3475073575973511
Batch 34/64 loss: 0.35395586490631104
Batch 35/64 loss: 0.3479684591293335
Batch 36/64 loss: 0.34567487239837646
Batch 37/64 loss: 0.3471837639808655
Batch 38/64 loss: 0.3457893133163452
Batch 39/64 loss: 0.3468729257583618
Batch 40/64 loss: 0.3477756977081299
Batch 41/64 loss: 0.34521520137786865
Batch 42/64 loss: 0.3460506200790405
Batch 43/64 loss: 0.3482670783996582
Batch 44/64 loss: 0.34934747219085693
Batch 45/64 loss: 0.3477827310562134
Batch 46/64 loss: 0.34574639797210693
Batch 47/64 loss: 0.3507292866706848
Batch 48/64 loss: 0.3420678377151489
Batch 49/64 loss: 0.34542959928512573
Batch 50/64 loss: 0.34899014234542847
Batch 51/64 loss: 0.3457984924316406
Batch 52/64 loss: 0.340706467628479
Batch 53/64 loss: 0.34854674339294434
Batch 54/64 loss: 0.34327882528305054
Batch 55/64 loss: 0.345891535282135
Batch 56/64 loss: 0.34147411584854126
Batch 57/64 loss: 0.34627068042755127
Batch 58/64 loss: 0.34468913078308105
Batch 59/64 loss: 0.34464263916015625
Batch 60/64 loss: 0.34944814443588257
Batch 61/64 loss: 0.34489595890045166
Batch 62/64 loss: 0.347450852394104
Batch 63/64 loss: 0.3436617851257324
Batch 64/64 loss: 0.3424953818321228
Epoch 134  Train loss: 0.34679378645092834  Val loss: 0.35154058351549494
Saving best model, epoch: 134
Epoch 135
-------------------------------
Batch 1/64 loss: 0.3469419479370117
Batch 2/64 loss: 0.3472362160682678
Batch 3/64 loss: 0.35194653272628784
Batch 4/64 loss: 0.34834063053131104
Batch 5/64 loss: 0.3498955965042114
Batch 6/64 loss: 0.34784579277038574
Batch 7/64 loss: 0.3465923070907593
Batch 8/64 loss: 0.346149206161499
Batch 9/64 loss: 0.3472142219543457
Batch 10/64 loss: 0.3461149334907532
Batch 11/64 loss: 0.3399391770362854
Batch 12/64 loss: 0.344845175743103
Batch 13/64 loss: 0.3481043577194214
Batch 14/64 loss: 0.3496897220611572
Batch 15/64 loss: 0.34561896324157715
Batch 16/64 loss: 0.3500855565071106
Batch 17/64 loss: 0.3531334400177002
Batch 18/64 loss: 0.3456209897994995
Batch 19/64 loss: 0.346423864364624
Batch 20/64 loss: 0.34580308198928833
Batch 21/64 loss: 0.34357064962387085
Batch 22/64 loss: 0.3448973298072815
Batch 23/64 loss: 0.345641553401947
Batch 24/64 loss: 0.34017622470855713
Batch 25/64 loss: 0.34562093019485474
Batch 26/64 loss: 0.3479177951812744
Batch 27/64 loss: 0.3488517999649048
Batch 28/64 loss: 0.34585750102996826
Batch 29/64 loss: 0.349017858505249
Batch 30/64 loss: 0.3453139066696167
Batch 31/64 loss: 0.35067009925842285
Batch 32/64 loss: 0.3476582169532776
Batch 33/64 loss: 0.34929710626602173
Batch 34/64 loss: 0.3456156849861145
Batch 35/64 loss: 0.35031771659851074
Batch 36/64 loss: 0.3458326458930969
Batch 37/64 loss: 0.3457742929458618
Batch 38/64 loss: 0.34502655267715454
Batch 39/64 loss: 0.34192347526550293
Batch 40/64 loss: 0.3481287360191345
Batch 41/64 loss: 0.3506091833114624
Batch 42/64 loss: 0.34564149379730225
Batch 43/64 loss: 0.34374749660491943
Batch 44/64 loss: 0.34867358207702637
Batch 45/64 loss: 0.34546422958374023
Batch 46/64 loss: 0.3516457676887512
Batch 47/64 loss: 0.3531452417373657
Batch 48/64 loss: 0.3436567783355713
Batch 49/64 loss: 0.34472936391830444
Batch 50/64 loss: 0.3452921509742737
Batch 51/64 loss: 0.34397339820861816
Batch 52/64 loss: 0.34680473804473877
Batch 53/64 loss: 0.343283474445343
Batch 54/64 loss: 0.34277117252349854
Batch 55/64 loss: 0.34619736671447754
Batch 56/64 loss: 0.3467212915420532
Batch 57/64 loss: 0.34758567810058594
Batch 58/64 loss: 0.3456608057022095
Batch 59/64 loss: 0.34801000356674194
Batch 60/64 loss: 0.3469497561454773
Batch 61/64 loss: 0.3418717384338379
Batch 62/64 loss: 0.34577107429504395
Batch 63/64 loss: 0.34529703855514526
Batch 64/64 loss: 0.3459436893463135
Epoch 135  Train loss: 0.3466292138193168  Val loss: 0.35119059589720264
Saving best model, epoch: 135
Epoch 136
-------------------------------
Batch 1/64 loss: 0.34868860244750977
Batch 2/64 loss: 0.3528978228569031
Batch 3/64 loss: 0.3399098515510559
Batch 4/64 loss: 0.348504900932312
Batch 5/64 loss: 0.34211546182632446
Batch 6/64 loss: 0.3513472080230713
Batch 7/64 loss: 0.3474087715148926
Batch 8/64 loss: 0.34044909477233887
Batch 9/64 loss: 0.34249937534332275
Batch 10/64 loss: 0.34225404262542725
Batch 11/64 loss: 0.34544306993484497
Batch 12/64 loss: 0.3472287654876709
Batch 13/64 loss: 0.34403395652770996
Batch 14/64 loss: 0.3493211269378662
Batch 15/64 loss: 0.345284104347229
Batch 16/64 loss: 0.34493666887283325
Batch 17/64 loss: 0.3466644287109375
Batch 18/64 loss: 0.3437381982803345
Batch 19/64 loss: 0.34464770555496216
Batch 20/64 loss: 0.3429901599884033
Batch 21/64 loss: 0.3397100567817688
Batch 22/64 loss: 0.34121382236480713
Batch 23/64 loss: 0.35367298126220703
Batch 24/64 loss: 0.34843724966049194
Batch 25/64 loss: 0.3501192331314087
Batch 26/64 loss: 0.3455479145050049
Batch 27/64 loss: 0.3469792604446411
Batch 28/64 loss: 0.3479093909263611
Batch 29/64 loss: 0.3441329002380371
Batch 30/64 loss: 0.3470422029495239
Batch 31/64 loss: 0.34415900707244873
Batch 32/64 loss: 0.34271419048309326
Batch 33/64 loss: 0.347439169883728
Batch 34/64 loss: 0.3440396785736084
Batch 35/64 loss: 0.3395634889602661
Batch 36/64 loss: 0.3446861505508423
Batch 37/64 loss: 0.34493404626846313
Batch 38/64 loss: 0.34744930267333984
Batch 39/64 loss: 0.3491210341453552
Batch 40/64 loss: 0.34288489818573
Batch 41/64 loss: 0.35390353202819824
Batch 42/64 loss: 0.34498441219329834
Batch 43/64 loss: 0.3496319651603699
Batch 44/64 loss: 0.3437795639038086
Batch 45/64 loss: 0.3483612537384033
Batch 46/64 loss: 0.3424004316329956
Batch 47/64 loss: 0.3459058403968811
Batch 48/64 loss: 0.3482697010040283
Batch 49/64 loss: 0.34616637229919434
Batch 50/64 loss: 0.34067243337631226
Batch 51/64 loss: 0.3435138463973999
Batch 52/64 loss: 0.3467833995819092
Batch 53/64 loss: 0.3482327461242676
Batch 54/64 loss: 0.3468829393386841
Batch 55/64 loss: 0.3490685224533081
Batch 56/64 loss: 0.350227952003479
Batch 57/64 loss: 0.34161829948425293
Batch 58/64 loss: 0.3500080108642578
Batch 59/64 loss: 0.3469923138618469
Batch 60/64 loss: 0.35053551197052
Batch 61/64 loss: 0.3413851857185364
Batch 62/64 loss: 0.35056251287460327
Batch 63/64 loss: 0.348061740398407
Batch 64/64 loss: 0.34711748361587524
Epoch 136  Train loss: 0.34604558266845403  Val loss: 0.3513544769221565
Epoch 137
-------------------------------
Batch 1/64 loss: 0.34018659591674805
Batch 2/64 loss: 0.3485979437828064
Batch 3/64 loss: 0.3467373847961426
Batch 4/64 loss: 0.3433957099914551
Batch 5/64 loss: 0.34061098098754883
Batch 6/64 loss: 0.3448857069015503
Batch 7/64 loss: 0.3473477363586426
Batch 8/64 loss: 0.34338903427124023
Batch 9/64 loss: 0.3445886969566345
Batch 10/64 loss: 0.34686094522476196
Batch 11/64 loss: 0.34413111209869385
Batch 12/64 loss: 0.3418382406234741
Batch 13/64 loss: 0.3402845859527588
Batch 14/64 loss: 0.34231507778167725
Batch 15/64 loss: 0.347248911857605
Batch 16/64 loss: 0.34607183933258057
Batch 17/64 loss: 0.3482961654663086
Batch 18/64 loss: 0.348585844039917
Batch 19/64 loss: 0.3507394790649414
Batch 20/64 loss: 0.3506036400794983
Batch 21/64 loss: 0.347329318523407
Batch 22/64 loss: 0.3468189239501953
Batch 23/64 loss: 0.34433507919311523
Batch 24/64 loss: 0.3399832248687744
Batch 25/64 loss: 0.3441042900085449
Batch 26/64 loss: 0.34796643257141113
Batch 27/64 loss: 0.34592509269714355
Batch 28/64 loss: 0.3514573574066162
Batch 29/64 loss: 0.3527260422706604
Batch 30/64 loss: 0.3410903215408325
Batch 31/64 loss: 0.3447449207305908
Batch 32/64 loss: 0.3440853953361511
Batch 33/64 loss: 0.3499178886413574
Batch 34/64 loss: 0.35312312841415405
Batch 35/64 loss: 0.34562182426452637
Batch 36/64 loss: 0.34466099739074707
Batch 37/64 loss: 0.34876662492752075
Batch 38/64 loss: 0.34564608335494995
Batch 39/64 loss: 0.3519945740699768
Batch 40/64 loss: 0.3422682285308838
Batch 41/64 loss: 0.34351933002471924
Batch 42/64 loss: 0.3427640199661255
Batch 43/64 loss: 0.3407527208328247
Batch 44/64 loss: 0.34803521633148193
Batch 45/64 loss: 0.34549176692962646
Batch 46/64 loss: 0.34787845611572266
Batch 47/64 loss: 0.34742987155914307
Batch 48/64 loss: 0.34392619132995605
Batch 49/64 loss: 0.34783482551574707
Batch 50/64 loss: 0.34657132625579834
Batch 51/64 loss: 0.34432196617126465
Batch 52/64 loss: 0.3401062488555908
Batch 53/64 loss: 0.34496915340423584
Batch 54/64 loss: 0.35052454471588135
Batch 55/64 loss: 0.35311657190322876
Batch 56/64 loss: 0.3469752073287964
Batch 57/64 loss: 0.3411322236061096
Batch 58/64 loss: 0.3542790412902832
Batch 59/64 loss: 0.34910881519317627
Batch 60/64 loss: 0.35417866706848145
Batch 61/64 loss: 0.3441861867904663
Batch 62/64 loss: 0.3436482548713684
Batch 63/64 loss: 0.3448063135147095
Batch 64/64 loss: 0.3455061912536621
Epoch 137  Train loss: 0.34610145793241615  Val loss: 0.3521159399825683
Epoch 138
-------------------------------
Batch 1/64 loss: 0.34371232986450195
Batch 2/64 loss: 0.348052978515625
Batch 3/64 loss: 0.3440760374069214
Batch 4/64 loss: 0.34352004528045654
Batch 5/64 loss: 0.34481942653656006
Batch 6/64 loss: 0.34069395065307617
Batch 7/64 loss: 0.34666889905929565
Batch 8/64 loss: 0.34808439016342163
Batch 9/64 loss: 0.34409213066101074
Batch 10/64 loss: 0.3467891216278076
Batch 11/64 loss: 0.3459932804107666
Batch 12/64 loss: 0.3435037136077881
Batch 13/64 loss: 0.34599459171295166
Batch 14/64 loss: 0.3450167775154114
Batch 15/64 loss: 0.34106016159057617
Batch 16/64 loss: 0.3471297025680542
Batch 17/64 loss: 0.3456538915634155
Batch 18/64 loss: 0.344294011592865
Batch 19/64 loss: 0.34601259231567383
Batch 20/64 loss: 0.3441706895828247
Batch 21/64 loss: 0.3464500308036804
Batch 22/64 loss: 0.3461872339248657
Batch 23/64 loss: 0.34402066469192505
Batch 24/64 loss: 0.3464285135269165
Batch 25/64 loss: 0.3468950390815735
Batch 26/64 loss: 0.34464502334594727
Batch 27/64 loss: 0.35071253776550293
Batch 28/64 loss: 0.3480544090270996
Batch 29/64 loss: 0.34197473526000977
Batch 30/64 loss: 0.3480170965194702
Batch 31/64 loss: 0.34703952074050903
Batch 32/64 loss: 0.34951698780059814
Batch 33/64 loss: 0.34615641832351685
Batch 34/64 loss: 0.34904158115386963
Batch 35/64 loss: 0.34968090057373047
Batch 36/64 loss: 0.3491262197494507
Batch 37/64 loss: 0.3488556742668152
Batch 38/64 loss: 0.3488657474517822
Batch 39/64 loss: 0.3432614803314209
Batch 40/64 loss: 0.3472059965133667
Batch 41/64 loss: 0.34080439805984497
Batch 42/64 loss: 0.34606051445007324
Batch 43/64 loss: 0.34803056716918945
Batch 44/64 loss: 0.34611403942108154
Batch 45/64 loss: 0.34891510009765625
Batch 46/64 loss: 0.34390223026275635
Batch 47/64 loss: 0.3466915488243103
Batch 48/64 loss: 0.3465524911880493
Batch 49/64 loss: 0.343719482421875
Batch 50/64 loss: 0.34394019842147827
Batch 51/64 loss: 0.34458887577056885
Batch 52/64 loss: 0.34388935565948486
Batch 53/64 loss: 0.34204185009002686
Batch 54/64 loss: 0.34744971990585327
Batch 55/64 loss: 0.3466266393661499
Batch 56/64 loss: 0.3449588418006897
Batch 57/64 loss: 0.3485724925994873
Batch 58/64 loss: 0.3514387607574463
Batch 59/64 loss: 0.3473614454269409
Batch 60/64 loss: 0.35182178020477295
Batch 61/64 loss: 0.3484271168708801
Batch 62/64 loss: 0.34641116857528687
Batch 63/64 loss: 0.3478025197982788
Batch 64/64 loss: 0.3479384183883667
Epoch 138  Train loss: 0.34617332523944333  Val loss: 0.3513568191184211
Epoch 139
-------------------------------
Batch 1/64 loss: 0.343447208404541
Batch 2/64 loss: 0.34669673442840576
Batch 3/64 loss: 0.3478289842605591
Batch 4/64 loss: 0.3412087559700012
Batch 5/64 loss: 0.3481897711753845
Batch 6/64 loss: 0.3430348038673401
Batch 7/64 loss: 0.34821033477783203
Batch 8/64 loss: 0.3421201705932617
Batch 9/64 loss: 0.34442901611328125
Batch 10/64 loss: 0.33966511487960815
Batch 11/64 loss: 0.34595924615859985
Batch 12/64 loss: 0.34953320026397705
Batch 13/64 loss: 0.33981800079345703
Batch 14/64 loss: 0.3427942395210266
Batch 15/64 loss: 0.34712278842926025
Batch 16/64 loss: 0.347930908203125
Batch 17/64 loss: 0.3467845320701599
Batch 18/64 loss: 0.3494166135787964
Batch 19/64 loss: 0.34179234504699707
Batch 20/64 loss: 0.3509787321090698
Batch 21/64 loss: 0.34144437313079834
Batch 22/64 loss: 0.3437856435775757
Batch 23/64 loss: 0.3494105339050293
Batch 24/64 loss: 0.3525211811065674
Batch 25/64 loss: 0.3440176844596863
Batch 26/64 loss: 0.34057527780532837
Batch 27/64 loss: 0.35158348083496094
Batch 28/64 loss: 0.34650754928588867
Batch 29/64 loss: 0.34136533737182617
Batch 30/64 loss: 0.3443061113357544
Batch 31/64 loss: 0.34406042098999023
Batch 32/64 loss: 0.3428335189819336
Batch 33/64 loss: 0.34980571269989014
Batch 34/64 loss: 0.3459256887435913
Batch 35/64 loss: 0.3451772928237915
Batch 36/64 loss: 0.34222716093063354
Batch 37/64 loss: 0.34344470500946045
Batch 38/64 loss: 0.3486953377723694
Batch 39/64 loss: 0.34363675117492676
Batch 40/64 loss: 0.34565848112106323
Batch 41/64 loss: 0.34449225664138794
Batch 42/64 loss: 0.34358644485473633
Batch 43/64 loss: 0.34927594661712646
Batch 44/64 loss: 0.3465862274169922
Batch 45/64 loss: 0.3438790440559387
Batch 46/64 loss: 0.3437231779098511
Batch 47/64 loss: 0.3486568331718445
Batch 48/64 loss: 0.35107356309890747
Batch 49/64 loss: 0.34681302309036255
Batch 50/64 loss: 0.34315210580825806
Batch 51/64 loss: 0.34716129302978516
Batch 52/64 loss: 0.3478584289550781
Batch 53/64 loss: 0.3466295003890991
Batch 54/64 loss: 0.3448900580406189
Batch 55/64 loss: 0.34555113315582275
Batch 56/64 loss: 0.3455854654312134
Batch 57/64 loss: 0.3394690752029419
Batch 58/64 loss: 0.3465151786804199
Batch 59/64 loss: 0.34856826066970825
Batch 60/64 loss: 0.3487483263015747
Batch 61/64 loss: 0.3478185534477234
Batch 62/64 loss: 0.341830849647522
Batch 63/64 loss: 0.3490143418312073
Batch 64/64 loss: 0.3457014560699463
Epoch 139  Train loss: 0.3456329242855895  Val loss: 0.3509631759112643
Saving best model, epoch: 139
Epoch 140
-------------------------------
Batch 1/64 loss: 0.33907508850097656
Batch 2/64 loss: 0.3442955017089844
Batch 3/64 loss: 0.34145158529281616
Batch 4/64 loss: 0.34139692783355713
Batch 5/64 loss: 0.34835147857666016
Batch 6/64 loss: 0.3464771509170532
Batch 7/64 loss: 0.34273117780685425
Batch 8/64 loss: 0.3516702651977539
Batch 9/64 loss: 0.3447611331939697
Batch 10/64 loss: 0.3451251983642578
Batch 11/64 loss: 0.34889936447143555
Batch 12/64 loss: 0.3408339023590088
Batch 13/64 loss: 0.35019516944885254
Batch 14/64 loss: 0.346990168094635
Batch 15/64 loss: 0.34703516960144043
Batch 16/64 loss: 0.34313440322875977
Batch 17/64 loss: 0.3415161371231079
Batch 18/64 loss: 0.3458930253982544
Batch 19/64 loss: 0.34708213806152344
Batch 20/64 loss: 0.3456493616104126
Batch 21/64 loss: 0.34961235523223877
Batch 22/64 loss: 0.3443487882614136
Batch 23/64 loss: 0.34922122955322266
Batch 24/64 loss: 0.34711968898773193
Batch 25/64 loss: 0.34666186571121216
Batch 26/64 loss: 0.3455824851989746
Batch 27/64 loss: 0.3440347909927368
Batch 28/64 loss: 0.3468785881996155
Batch 29/64 loss: 0.34121251106262207
Batch 30/64 loss: 0.34164851903915405
Batch 31/64 loss: 0.35124409198760986
Batch 32/64 loss: 0.34145134687423706
Batch 33/64 loss: 0.34640371799468994
Batch 34/64 loss: 0.34558558464050293
Batch 35/64 loss: 0.3478355407714844
Batch 36/64 loss: 0.3371487855911255
Batch 37/64 loss: 0.3435434103012085
Batch 38/64 loss: 0.3406769037246704
Batch 39/64 loss: 0.34586185216903687
Batch 40/64 loss: 0.3439903259277344
Batch 41/64 loss: 0.3429229259490967
Batch 42/64 loss: 0.35248494148254395
Batch 43/64 loss: 0.34296441078186035
Batch 44/64 loss: 0.34552717208862305
Batch 45/64 loss: 0.345883846282959
Batch 46/64 loss: 0.3479064702987671
Batch 47/64 loss: 0.33703023195266724
Batch 48/64 loss: 0.3514522910118103
Batch 49/64 loss: 0.3431278467178345
Batch 50/64 loss: 0.34693336486816406
Batch 51/64 loss: 0.35163605213165283
Batch 52/64 loss: 0.3460965156555176
Batch 53/64 loss: 0.3477928638458252
Batch 54/64 loss: 0.3458546996116638
Batch 55/64 loss: 0.34613001346588135
Batch 56/64 loss: 0.3454993963241577
Batch 57/64 loss: 0.3473389148712158
Batch 58/64 loss: 0.34267115592956543
Batch 59/64 loss: 0.34062880277633667
Batch 60/64 loss: 0.34509801864624023
Batch 61/64 loss: 0.34844350814819336
Batch 62/64 loss: 0.3465616703033447
Batch 63/64 loss: 0.3482849597930908
Batch 64/64 loss: 0.35116660594940186
Epoch 140  Train loss: 0.345478772649578  Val loss: 0.3507511273692154
Saving best model, epoch: 140
Epoch 141
-------------------------------
Batch 1/64 loss: 0.3412724733352661
Batch 2/64 loss: 0.34380853176116943
Batch 3/64 loss: 0.34505796432495117
Batch 4/64 loss: 0.33810895681381226
Batch 5/64 loss: 0.3409826159477234
Batch 6/64 loss: 0.3538666367530823
Batch 7/64 loss: 0.343927800655365
Batch 8/64 loss: 0.34975773096084595
Batch 9/64 loss: 0.34511077404022217
Batch 10/64 loss: 0.34229588508605957
Batch 11/64 loss: 0.34843194484710693
Batch 12/64 loss: 0.34414368867874146
Batch 13/64 loss: 0.3441786766052246
Batch 14/64 loss: 0.34698933362960815
Batch 15/64 loss: 0.3515118956565857
Batch 16/64 loss: 0.3434199094772339
Batch 17/64 loss: 0.3428140878677368
Batch 18/64 loss: 0.3449096083641052
Batch 19/64 loss: 0.3471033573150635
Batch 20/64 loss: 0.3403424024581909
Batch 21/64 loss: 0.3488612771034241
Batch 22/64 loss: 0.3452584743499756
Batch 23/64 loss: 0.3464086055755615
Batch 24/64 loss: 0.3532986640930176
Batch 25/64 loss: 0.3468490242958069
Batch 26/64 loss: 0.34757477045059204
Batch 27/64 loss: 0.3404805660247803
Batch 28/64 loss: 0.3496665954589844
Batch 29/64 loss: 0.34361279010772705
Batch 30/64 loss: 0.34438908100128174
Batch 31/64 loss: 0.344712495803833
Batch 32/64 loss: 0.3434712886810303
Batch 33/64 loss: 0.3410699963569641
Batch 34/64 loss: 0.34102725982666016
Batch 35/64 loss: 0.34560859203338623
Batch 36/64 loss: 0.3440406322479248
Batch 37/64 loss: 0.3455561399459839
Batch 38/64 loss: 0.35086381435394287
Batch 39/64 loss: 0.3470020890235901
Batch 40/64 loss: 0.3439517617225647
Batch 41/64 loss: 0.34655582904815674
Batch 42/64 loss: 0.3516385555267334
Batch 43/64 loss: 0.34603720903396606
Batch 44/64 loss: 0.34224969148635864
Batch 45/64 loss: 0.3445683717727661
Batch 46/64 loss: 0.3458881974220276
Batch 47/64 loss: 0.34293222427368164
Batch 48/64 loss: 0.3436020612716675
Batch 49/64 loss: 0.3420299291610718
Batch 50/64 loss: 0.34868377447128296
Batch 51/64 loss: 0.3500800132751465
Batch 52/64 loss: 0.3433910608291626
Batch 53/64 loss: 0.3463754653930664
Batch 54/64 loss: 0.34524309635162354
Batch 55/64 loss: 0.3420780897140503
Batch 56/64 loss: 0.34925317764282227
Batch 57/64 loss: 0.3475668430328369
Batch 58/64 loss: 0.3470016121864319
Batch 59/64 loss: 0.3449755907058716
Batch 60/64 loss: 0.3448988199234009
Batch 61/64 loss: 0.35082119703292847
Batch 62/64 loss: 0.34520524740219116
Batch 63/64 loss: 0.3448401689529419
Batch 64/64 loss: 0.35357844829559326
Epoch 141  Train loss: 0.34561314910065893  Val loss: 0.3510446026153171
Epoch 142
-------------------------------
Batch 1/64 loss: 0.3483654260635376
Batch 2/64 loss: 0.346310019493103
Batch 3/64 loss: 0.3424876928329468
Batch 4/64 loss: 0.3475080132484436
Batch 5/64 loss: 0.34612488746643066
Batch 6/64 loss: 0.34115415811538696
Batch 7/64 loss: 0.3362691402435303
Batch 8/64 loss: 0.34367674589157104
Batch 9/64 loss: 0.3428541421890259
Batch 10/64 loss: 0.3443664312362671
Batch 11/64 loss: 0.34474778175354004
Batch 12/64 loss: 0.3470417261123657
Batch 13/64 loss: 0.34664398431777954
Batch 14/64 loss: 0.3464962840080261
Batch 15/64 loss: 0.34922701120376587
Batch 16/64 loss: 0.34501171112060547
Batch 17/64 loss: 0.34447360038757324
Batch 18/64 loss: 0.3526039123535156
Batch 19/64 loss: 0.3466159701347351
Batch 20/64 loss: 0.35254204273223877
Batch 21/64 loss: 0.34124571084976196
Batch 22/64 loss: 0.34394896030426025
Batch 23/64 loss: 0.342077374458313
Batch 24/64 loss: 0.3422263264656067
Batch 25/64 loss: 0.3465479612350464
Batch 26/64 loss: 0.34427428245544434
Batch 27/64 loss: 0.34643542766571045
Batch 28/64 loss: 0.34358811378479004
Batch 29/64 loss: 0.33450478315353394
Batch 30/64 loss: 0.34288960695266724
Batch 31/64 loss: 0.346081018447876
Batch 32/64 loss: 0.34658610820770264
Batch 33/64 loss: 0.3463427424430847
Batch 34/64 loss: 0.3472949266433716
Batch 35/64 loss: 0.3527563214302063
Batch 36/64 loss: 0.34447431564331055
Batch 37/64 loss: 0.34606051445007324
Batch 38/64 loss: 0.34525078535079956
Batch 39/64 loss: 0.3440053462982178
Batch 40/64 loss: 0.3458065986633301
Batch 41/64 loss: 0.3471897840499878
Batch 42/64 loss: 0.3447178602218628
Batch 43/64 loss: 0.3477734327316284
Batch 44/64 loss: 0.34360021352767944
Batch 45/64 loss: 0.3436821699142456
Batch 46/64 loss: 0.3425332307815552
Batch 47/64 loss: 0.3416999578475952
Batch 48/64 loss: 0.3416903614997864
Batch 49/64 loss: 0.3427038788795471
Batch 50/64 loss: 0.3478972315788269
Batch 51/64 loss: 0.34697121381759644
Batch 52/64 loss: 0.34848421812057495
Batch 53/64 loss: 0.34410560131073
Batch 54/64 loss: 0.34378135204315186
Batch 55/64 loss: 0.34539246559143066
Batch 56/64 loss: 0.34175509214401245
Batch 57/64 loss: 0.34819912910461426
Batch 58/64 loss: 0.34539520740509033
Batch 59/64 loss: 0.34902846813201904
Batch 60/64 loss: 0.34442245960235596
Batch 61/64 loss: 0.3469926714897156
Batch 62/64 loss: 0.34353315830230713
Batch 63/64 loss: 0.34665781259536743
Batch 64/64 loss: 0.34385085105895996
Epoch 142  Train loss: 0.34514530219283757  Val loss: 0.3509040313078366
Epoch 143
-------------------------------
Batch 1/64 loss: 0.34210216999053955
Batch 2/64 loss: 0.3447709083557129
Batch 3/64 loss: 0.3404768705368042
Batch 4/64 loss: 0.342087984085083
Batch 5/64 loss: 0.3475456237792969
Batch 6/64 loss: 0.3476684093475342
Batch 7/64 loss: 0.34111452102661133
Batch 8/64 loss: 0.3424118757247925
Batch 9/64 loss: 0.34920984506607056
Batch 10/64 loss: 0.34721070528030396
Batch 11/64 loss: 0.34594935178756714
Batch 12/64 loss: 0.3444880247116089
Batch 13/64 loss: 0.34058183431625366
Batch 14/64 loss: 0.3469451665878296
Batch 15/64 loss: 0.3405163884162903
Batch 16/64 loss: 0.3381361961364746
Batch 17/64 loss: 0.34543776512145996
Batch 18/64 loss: 0.344957172870636
Batch 19/64 loss: 0.3500312566757202
Batch 20/64 loss: 0.3445892333984375
Batch 21/64 loss: 0.3437957763671875
Batch 22/64 loss: 0.3436014652252197
Batch 23/64 loss: 0.3476618528366089
Batch 24/64 loss: 0.35160428285598755
Batch 25/64 loss: 0.3424621820449829
Batch 26/64 loss: 0.34101182222366333
Batch 27/64 loss: 0.34092485904693604
Batch 28/64 loss: 0.34845471382141113
Batch 29/64 loss: 0.3454285264015198
Batch 30/64 loss: 0.3491230010986328
Batch 31/64 loss: 0.3478087782859802
Batch 32/64 loss: 0.34412825107574463
Batch 33/64 loss: 0.3407679796218872
Batch 34/64 loss: 0.3445831537246704
Batch 35/64 loss: 0.3508402109146118
Batch 36/64 loss: 0.34337007999420166
Batch 37/64 loss: 0.3496265411376953
Batch 38/64 loss: 0.34213554859161377
Batch 39/64 loss: 0.3526744842529297
Batch 40/64 loss: 0.3502795696258545
Batch 41/64 loss: 0.3464934229850769
Batch 42/64 loss: 0.3398970365524292
Batch 43/64 loss: 0.34322911500930786
Batch 44/64 loss: 0.3484361171722412
Batch 45/64 loss: 0.3443102240562439
Batch 46/64 loss: 0.3421071171760559
Batch 47/64 loss: 0.3417324423789978
Batch 48/64 loss: 0.3425920009613037
Batch 49/64 loss: 0.3538997769355774
Batch 50/64 loss: 0.349483847618103
Batch 51/64 loss: 0.347139835357666
Batch 52/64 loss: 0.34451401233673096
Batch 53/64 loss: 0.3408513069152832
Batch 54/64 loss: 0.3426229953765869
Batch 55/64 loss: 0.3458670973777771
Batch 56/64 loss: 0.3434036374092102
Batch 57/64 loss: 0.3412598967552185
Batch 58/64 loss: 0.35191458463668823
Batch 59/64 loss: 0.34980320930480957
Batch 60/64 loss: 0.3431732654571533
Batch 61/64 loss: 0.3453867435455322
Batch 62/64 loss: 0.33778172731399536
Batch 63/64 loss: 0.3463301658630371
Batch 64/64 loss: 0.3416142463684082
Epoch 143  Train loss: 0.3450188964020972  Val loss: 0.35095615075625913
Epoch 144
-------------------------------
Batch 1/64 loss: 0.3435367941856384
Batch 2/64 loss: 0.34578758478164673
Batch 3/64 loss: 0.3391411304473877
Batch 4/64 loss: 0.3446255922317505
Batch 5/64 loss: 0.34282219409942627
Batch 6/64 loss: 0.3441327214241028
Batch 7/64 loss: 0.3468729853630066
Batch 8/64 loss: 0.34472203254699707
Batch 9/64 loss: 0.34353774785995483
Batch 10/64 loss: 0.3439904451370239
Batch 11/64 loss: 0.3465431332588196
Batch 12/64 loss: 0.3460254669189453
Batch 13/64 loss: 0.3397902846336365
Batch 14/64 loss: 0.34678810834884644
Batch 15/64 loss: 0.3478918671607971
Batch 16/64 loss: 0.3456404209136963
Batch 17/64 loss: 0.34678858518600464
Batch 18/64 loss: 0.344541072845459
Batch 19/64 loss: 0.34982407093048096
Batch 20/64 loss: 0.35118240118026733
Batch 21/64 loss: 0.3422900438308716
Batch 22/64 loss: 0.3435136079788208
Batch 23/64 loss: 0.3456839323043823
Batch 24/64 loss: 0.3437769412994385
Batch 25/64 loss: 0.34435713291168213
Batch 26/64 loss: 0.34304553270339966
Batch 27/64 loss: 0.34693479537963867
Batch 28/64 loss: 0.34233832359313965
Batch 29/64 loss: 0.3441135287284851
Batch 30/64 loss: 0.3425285816192627
Batch 31/64 loss: 0.34842514991760254
Batch 32/64 loss: 0.34252822399139404
Batch 33/64 loss: 0.3400227427482605
Batch 34/64 loss: 0.3485039472579956
Batch 35/64 loss: 0.3465765118598938
Batch 36/64 loss: 0.33834582567214966
Batch 37/64 loss: 0.34268081188201904
Batch 38/64 loss: 0.34679722785949707
Batch 39/64 loss: 0.34231996536254883
Batch 40/64 loss: 0.34579724073410034
Batch 41/64 loss: 0.3501955270767212
Batch 42/64 loss: 0.34125375747680664
Batch 43/64 loss: 0.34570592641830444
Batch 44/64 loss: 0.34134912490844727
Batch 45/64 loss: 0.34556663036346436
Batch 46/64 loss: 0.35129261016845703
Batch 47/64 loss: 0.34470051527023315
Batch 48/64 loss: 0.3458549976348877
Batch 49/64 loss: 0.3424844741821289
Batch 50/64 loss: 0.34161096811294556
Batch 51/64 loss: 0.3455847501754761
Batch 52/64 loss: 0.3392072916030884
Batch 53/64 loss: 0.3378952741622925
Batch 54/64 loss: 0.3420144319534302
Batch 55/64 loss: 0.34234440326690674
Batch 56/64 loss: 0.3388887643814087
Batch 57/64 loss: 0.34843945503234863
Batch 58/64 loss: 0.3421729803085327
Batch 59/64 loss: 0.3452081084251404
Batch 60/64 loss: 0.3465818166732788
Batch 61/64 loss: 0.34496206045150757
Batch 62/64 loss: 0.34383726119995117
Batch 63/64 loss: 0.34308648109436035
Batch 64/64 loss: 0.34629690647125244
Epoch 144  Train loss: 0.34438784309462006  Val loss: 0.3496122802655721
Saving best model, epoch: 144
Epoch 145
-------------------------------
Batch 1/64 loss: 0.3405430316925049
Batch 2/64 loss: 0.34636497497558594
Batch 3/64 loss: 0.34156501293182373
Batch 4/64 loss: 0.3508124351501465
Batch 5/64 loss: 0.34290075302124023
Batch 6/64 loss: 0.3444002866744995
Batch 7/64 loss: 0.3409295082092285
Batch 8/64 loss: 0.34782958030700684
Batch 9/64 loss: 0.34875255823135376
Batch 10/64 loss: 0.3444831371307373
Batch 11/64 loss: 0.3455548882484436
Batch 12/64 loss: 0.34264075756073
Batch 13/64 loss: 0.34231698513031006
Batch 14/64 loss: 0.3407278060913086
Batch 15/64 loss: 0.3463791608810425
Batch 16/64 loss: 0.34521329402923584
Batch 17/64 loss: 0.3426213264465332
Batch 18/64 loss: 0.3418693542480469
Batch 19/64 loss: 0.3466983437538147
Batch 20/64 loss: 0.34098589420318604
Batch 21/64 loss: 0.3468644618988037
Batch 22/64 loss: 0.3471336364746094
Batch 23/64 loss: 0.34813976287841797
Batch 24/64 loss: 0.3406262993812561
Batch 25/64 loss: 0.34525346755981445
Batch 26/64 loss: 0.3447185754776001
Batch 27/64 loss: 0.34100908041000366
Batch 28/64 loss: 0.34219396114349365
Batch 29/64 loss: 0.34281206130981445
Batch 30/64 loss: 0.3446534276008606
Batch 31/64 loss: 0.33965766429901123
Batch 32/64 loss: 0.34621310234069824
Batch 33/64 loss: 0.347248911857605
Batch 34/64 loss: 0.34094738960266113
Batch 35/64 loss: 0.3471982479095459
Batch 36/64 loss: 0.3444358706474304
Batch 37/64 loss: 0.35031992197036743
Batch 38/64 loss: 0.3403967618942261
Batch 39/64 loss: 0.34887266159057617
Batch 40/64 loss: 0.34837424755096436
Batch 41/64 loss: 0.3473944067955017
Batch 42/64 loss: 0.3408578634262085
Batch 43/64 loss: 0.3444846272468567
Batch 44/64 loss: 0.3477916717529297
Batch 45/64 loss: 0.3457205295562744
Batch 46/64 loss: 0.3492892384529114
Batch 47/64 loss: 0.34382832050323486
Batch 48/64 loss: 0.34591221809387207
Batch 49/64 loss: 0.35016632080078125
Batch 50/64 loss: 0.34546470642089844
Batch 51/64 loss: 0.35142552852630615
Batch 52/64 loss: 0.35023605823516846
Batch 53/64 loss: 0.345534086227417
Batch 54/64 loss: 0.3429386615753174
Batch 55/64 loss: 0.3463782072067261
Batch 56/64 loss: 0.3452354669570923
Batch 57/64 loss: 0.3448810577392578
Batch 58/64 loss: 0.3415079116821289
Batch 59/64 loss: 0.35186564922332764
Batch 60/64 loss: 0.3433440923690796
Batch 61/64 loss: 0.34223198890686035
Batch 62/64 loss: 0.3448694944381714
Batch 63/64 loss: 0.3433757424354553
Batch 64/64 loss: 0.3453126549720764
Epoch 145  Train loss: 0.345009834392398  Val loss: 0.3503884089361761
Epoch 146
-------------------------------
Batch 1/64 loss: 0.3476375341415405
Batch 2/64 loss: 0.3464253544807434
Batch 3/64 loss: 0.3464289903640747
Batch 4/64 loss: 0.3446234464645386
Batch 5/64 loss: 0.34094536304473877
Batch 6/64 loss: 0.3486214876174927
Batch 7/64 loss: 0.34662169218063354
Batch 8/64 loss: 0.3446272611618042
Batch 9/64 loss: 0.3406018018722534
Batch 10/64 loss: 0.34590649604797363
Batch 11/64 loss: 0.344521164894104
Batch 12/64 loss: 0.336860716342926
Batch 13/64 loss: 0.345294713973999
Batch 14/64 loss: 0.3438384532928467
Batch 15/64 loss: 0.3429499864578247
Batch 16/64 loss: 0.34589123725891113
Batch 17/64 loss: 0.3488536477088928
Batch 18/64 loss: 0.34036797285079956
Batch 19/64 loss: 0.34199047088623047
Batch 20/64 loss: 0.3517566919326782
Batch 21/64 loss: 0.3385498523712158
Batch 22/64 loss: 0.3440707325935364
Batch 23/64 loss: 0.342706561088562
Batch 24/64 loss: 0.3444501757621765
Batch 25/64 loss: 0.3397669792175293
Batch 26/64 loss: 0.3493737578392029
Batch 27/64 loss: 0.34405481815338135
Batch 28/64 loss: 0.3425607681274414
Batch 29/64 loss: 0.34764933586120605
Batch 30/64 loss: 0.3454035520553589
Batch 31/64 loss: 0.34282612800598145
Batch 32/64 loss: 0.3416273593902588
Batch 33/64 loss: 0.3399370312690735
Batch 34/64 loss: 0.33973997831344604
Batch 35/64 loss: 0.3431951403617859
Batch 36/64 loss: 0.33986401557922363
Batch 37/64 loss: 0.3495948910713196
Batch 38/64 loss: 0.3452432155609131
Batch 39/64 loss: 0.34667277336120605
Batch 40/64 loss: 0.34665608406066895
Batch 41/64 loss: 0.3417118787765503
Batch 42/64 loss: 0.3425767421722412
Batch 43/64 loss: 0.3479962944984436
Batch 44/64 loss: 0.3476017117500305
Batch 45/64 loss: 0.34660226106643677
Batch 46/64 loss: 0.34332889318466187
Batch 47/64 loss: 0.3452552556991577
Batch 48/64 loss: 0.3462485074996948
Batch 49/64 loss: 0.34138739109039307
Batch 50/64 loss: 0.3504374027252197
Batch 51/64 loss: 0.3437681198120117
Batch 52/64 loss: 0.3445456027984619
Batch 53/64 loss: 0.34829699993133545
Batch 54/64 loss: 0.3415437936782837
Batch 55/64 loss: 0.3428918123245239
Batch 56/64 loss: 0.3446940779685974
Batch 57/64 loss: 0.3384246230125427
Batch 58/64 loss: 0.3412470817565918
Batch 59/64 loss: 0.35108184814453125
Batch 60/64 loss: 0.35179251432418823
Batch 61/64 loss: 0.3486347198486328
Batch 62/64 loss: 0.3450336456298828
Batch 63/64 loss: 0.34454667568206787
Batch 64/64 loss: 0.34347105026245117
Epoch 146  Train loss: 0.3445640592014088  Val loss: 0.3503977256951873
Epoch 147
-------------------------------
Batch 1/64 loss: 0.3422093987464905
Batch 2/64 loss: 0.33918631076812744
Batch 3/64 loss: 0.34727877378463745
Batch 4/64 loss: 0.34598177671432495
Batch 5/64 loss: 0.34420454502105713
Batch 6/64 loss: 0.348868727684021
Batch 7/64 loss: 0.34247303009033203
Batch 8/64 loss: 0.3405876159667969
Batch 9/64 loss: 0.34387338161468506
Batch 10/64 loss: 0.3408142328262329
Batch 11/64 loss: 0.341166615486145
Batch 12/64 loss: 0.33966416120529175
Batch 13/64 loss: 0.34439706802368164
Batch 14/64 loss: 0.3479611873626709
Batch 15/64 loss: 0.34058284759521484
Batch 16/64 loss: 0.33790773153305054
Batch 17/64 loss: 0.3433248996734619
Batch 18/64 loss: 0.34677910804748535
Batch 19/64 loss: 0.34226298332214355
Batch 20/64 loss: 0.3465367555618286
Batch 21/64 loss: 0.34269559383392334
Batch 22/64 loss: 0.33992451429367065
Batch 23/64 loss: 0.35159289836883545
Batch 24/64 loss: 0.335140585899353
Batch 25/64 loss: 0.3426947593688965
Batch 26/64 loss: 0.34775131940841675
Batch 27/64 loss: 0.3437177538871765
Batch 28/64 loss: 0.3485453128814697
Batch 29/64 loss: 0.33956456184387207
Batch 30/64 loss: 0.3459051847457886
Batch 31/64 loss: 0.3381258249282837
Batch 32/64 loss: 0.3426162600517273
Batch 33/64 loss: 0.3462015986442566
Batch 34/64 loss: 0.34546828269958496
Batch 35/64 loss: 0.34824317693710327
Batch 36/64 loss: 0.3432232141494751
Batch 37/64 loss: 0.34558045864105225
Batch 38/64 loss: 0.3494093418121338
Batch 39/64 loss: 0.350543737411499
Batch 40/64 loss: 0.34684574604034424
Batch 41/64 loss: 0.34386610984802246
Batch 42/64 loss: 0.34703826904296875
Batch 43/64 loss: 0.3422691822052002
Batch 44/64 loss: 0.35049962997436523
Batch 45/64 loss: 0.34220314025878906
Batch 46/64 loss: 0.3471618890762329
Batch 47/64 loss: 0.3447730541229248
Batch 48/64 loss: 0.3488174080848694
Batch 49/64 loss: 0.3419345021247864
Batch 50/64 loss: 0.3466382622718811
Batch 51/64 loss: 0.3408735990524292
Batch 52/64 loss: 0.34192025661468506
Batch 53/64 loss: 0.3440423011779785
Batch 54/64 loss: 0.3479628562927246
Batch 55/64 loss: 0.34387338161468506
Batch 56/64 loss: 0.34517204761505127
Batch 57/64 loss: 0.3430866003036499
Batch 58/64 loss: 0.34585040807724
Batch 59/64 loss: 0.34783291816711426
Batch 60/64 loss: 0.3420424461364746
Batch 61/64 loss: 0.3452037572860718
Batch 62/64 loss: 0.33639758825302124
Batch 63/64 loss: 0.3490699529647827
Batch 64/64 loss: 0.34023916721343994
Epoch 147  Train loss: 0.3442127092211854  Val loss: 0.3499586782914257
Epoch 148
-------------------------------
Batch 1/64 loss: 0.34847700595855713
Batch 2/64 loss: 0.34466344118118286
Batch 3/64 loss: 0.3474876284599304
Batch 4/64 loss: 0.33819007873535156
Batch 5/64 loss: 0.34328973293304443
Batch 6/64 loss: 0.34399574995040894
Batch 7/64 loss: 0.3501685857772827
Batch 8/64 loss: 0.3411499261856079
Batch 9/64 loss: 0.34646666049957275
Batch 10/64 loss: 0.345386803150177
Batch 11/64 loss: 0.3422567844390869
Batch 12/64 loss: 0.34716975688934326
Batch 13/64 loss: 0.3461037278175354
Batch 14/64 loss: 0.34562742710113525
Batch 15/64 loss: 0.34909969568252563
Batch 16/64 loss: 0.34270501136779785
Batch 17/64 loss: 0.34506356716156006
Batch 18/64 loss: 0.3470880389213562
Batch 19/64 loss: 0.34305262565612793
Batch 20/64 loss: 0.3445699214935303
Batch 21/64 loss: 0.3379932641983032
Batch 22/64 loss: 0.34107065200805664
Batch 23/64 loss: 0.34405064582824707
Batch 24/64 loss: 0.3393324613571167
Batch 25/64 loss: 0.3443588614463806
Batch 26/64 loss: 0.34574681520462036
Batch 27/64 loss: 0.34694820642471313
Batch 28/64 loss: 0.3451884388923645
Batch 29/64 loss: 0.3449549674987793
Batch 30/64 loss: 0.34110933542251587
Batch 31/64 loss: 0.344176709651947
Batch 32/64 loss: 0.3446100354194641
Batch 33/64 loss: 0.34709906578063965
Batch 34/64 loss: 0.3399806618690491
Batch 35/64 loss: 0.3408849239349365
Batch 36/64 loss: 0.3440678119659424
Batch 37/64 loss: 0.34586066007614136
Batch 38/64 loss: 0.34730756282806396
Batch 39/64 loss: 0.3450392484664917
Batch 40/64 loss: 0.34244275093078613
Batch 41/64 loss: 0.3452717065811157
Batch 42/64 loss: 0.3496636152267456
Batch 43/64 loss: 0.33648669719696045
Batch 44/64 loss: 0.3454301357269287
Batch 45/64 loss: 0.34680652618408203
Batch 46/64 loss: 0.3458881378173828
Batch 47/64 loss: 0.3439294099807739
Batch 48/64 loss: 0.34967249631881714
Batch 49/64 loss: 0.3479400873184204
Batch 50/64 loss: 0.34470272064208984
Batch 51/64 loss: 0.34220564365386963
Batch 52/64 loss: 0.34033554792404175
Batch 53/64 loss: 0.3420586585998535
Batch 54/64 loss: 0.344173789024353
Batch 55/64 loss: 0.3505210280418396
Batch 56/64 loss: 0.3422048091888428
Batch 57/64 loss: 0.34979480504989624
Batch 58/64 loss: 0.34323906898498535
Batch 59/64 loss: 0.34178268909454346
Batch 60/64 loss: 0.34092509746551514
Batch 61/64 loss: 0.35006099939346313
Batch 62/64 loss: 0.34031152725219727
Batch 63/64 loss: 0.33268606662750244
Batch 64/64 loss: 0.3433215618133545
Epoch 148  Train loss: 0.34427949307011624  Val loss: 0.35008851646148054
Epoch 149
-------------------------------
Batch 1/64 loss: 0.34429675340652466
Batch 2/64 loss: 0.34570544958114624
Batch 3/64 loss: 0.338600754737854
Batch 4/64 loss: 0.34401559829711914
Batch 5/64 loss: 0.34405624866485596
Batch 6/64 loss: 0.34612905979156494
Batch 7/64 loss: 0.34479260444641113
Batch 8/64 loss: 0.3480594754219055
Batch 9/64 loss: 0.3458710312843323
Batch 10/64 loss: 0.3434031009674072
Batch 11/64 loss: 0.3432871103286743
Batch 12/64 loss: 0.33806467056274414
Batch 13/64 loss: 0.3433955907821655
Batch 14/64 loss: 0.34530675411224365
Batch 15/64 loss: 0.33923280239105225
Batch 16/64 loss: 0.3473048806190491
Batch 17/64 loss: 0.3476836681365967
Batch 18/64 loss: 0.344828724861145
Batch 19/64 loss: 0.34350186586380005
Batch 20/64 loss: 0.34409433603286743
Batch 21/64 loss: 0.3464334011077881
Batch 22/64 loss: 0.3394978642463684
Batch 23/64 loss: 0.34363746643066406
Batch 24/64 loss: 0.3466910123825073
Batch 25/64 loss: 0.33613061904907227
Batch 26/64 loss: 0.34706610441207886
Batch 27/64 loss: 0.3440110683441162
Batch 28/64 loss: 0.3420736789703369
Batch 29/64 loss: 0.34583890438079834
Batch 30/64 loss: 0.3489187955856323
Batch 31/64 loss: 0.3443145751953125
Batch 32/64 loss: 0.33989471197128296
Batch 33/64 loss: 0.3495015501976013
Batch 34/64 loss: 0.34884023666381836
Batch 35/64 loss: 0.34269022941589355
Batch 36/64 loss: 0.34298408031463623
Batch 37/64 loss: 0.34535813331604004
Batch 38/64 loss: 0.34211045503616333
Batch 39/64 loss: 0.3410862684249878
Batch 40/64 loss: 0.34469592571258545
Batch 41/64 loss: 0.3485652804374695
Batch 42/64 loss: 0.3409339189529419
Batch 43/64 loss: 0.3459845781326294
Batch 44/64 loss: 0.33944153785705566
Batch 45/64 loss: 0.33947718143463135
Batch 46/64 loss: 0.34076988697052
Batch 47/64 loss: 0.3439502716064453
Batch 48/64 loss: 0.3441845178604126
Batch 49/64 loss: 0.3458361029624939
Batch 50/64 loss: 0.3365689516067505
Batch 51/64 loss: 0.3428722023963928
Batch 52/64 loss: 0.3380143642425537
Batch 53/64 loss: 0.34231096506118774
Batch 54/64 loss: 0.34583187103271484
Batch 55/64 loss: 0.34215372800827026
Batch 56/64 loss: 0.34308016300201416
Batch 57/64 loss: 0.3464120030403137
Batch 58/64 loss: 0.35128748416900635
Batch 59/64 loss: 0.34790337085723877
Batch 60/64 loss: 0.3445749282836914
Batch 61/64 loss: 0.3412832021713257
Batch 62/64 loss: 0.3466089367866516
Batch 63/64 loss: 0.3456081748008728
Batch 64/64 loss: 0.349651575088501
Epoch 149  Train loss: 0.3439889861088173  Val loss: 0.34981193452356607
Epoch 150
-------------------------------
Batch 1/64 loss: 0.34535109996795654
Batch 2/64 loss: 0.34853947162628174
Batch 3/64 loss: 0.34312039613723755
Batch 4/64 loss: 0.34057921171188354
Batch 5/64 loss: 0.3437209129333496
Batch 6/64 loss: 0.346355676651001
Batch 7/64 loss: 0.3408893346786499
Batch 8/64 loss: 0.347054123878479
Batch 9/64 loss: 0.3399466276168823
Batch 10/64 loss: 0.33736473321914673
Batch 11/64 loss: 0.33872461318969727
Batch 12/64 loss: 0.34274888038635254
Batch 13/64 loss: 0.342382550239563
Batch 14/64 loss: 0.34659475088119507
Batch 15/64 loss: 0.33780139684677124
Batch 16/64 loss: 0.34141868352890015
Batch 17/64 loss: 0.3402499556541443
Batch 18/64 loss: 0.3405773639678955
Batch 19/64 loss: 0.34416574239730835
Batch 20/64 loss: 0.3325009346008301
Batch 21/64 loss: 0.3481588363647461
Batch 22/64 loss: 0.33845698833465576
Batch 23/64 loss: 0.34900498390197754
Batch 24/64 loss: 0.34413790702819824
Batch 25/64 loss: 0.34400904178619385
Batch 26/64 loss: 0.3361746072769165
Batch 27/64 loss: 0.3464108109474182
Batch 28/64 loss: 0.3443930149078369
Batch 29/64 loss: 0.34772706031799316
Batch 30/64 loss: 0.34452980756759644
Batch 31/64 loss: 0.3385263681411743
Batch 32/64 loss: 0.3404887914657593
Batch 33/64 loss: 0.34317851066589355
Batch 34/64 loss: 0.34746992588043213
Batch 35/64 loss: 0.34163808822631836
Batch 36/64 loss: 0.3418757915496826
Batch 37/64 loss: 0.346917986869812
Batch 38/64 loss: 0.3479580879211426
Batch 39/64 loss: 0.3403126001358032
Batch 40/64 loss: 0.3418986201286316
Batch 41/64 loss: 0.34933167695999146
Batch 42/64 loss: 0.3417394161224365
Batch 43/64 loss: 0.347308874130249
Batch 44/64 loss: 0.34948790073394775
Batch 45/64 loss: 0.3455718755722046
Batch 46/64 loss: 0.3434380888938904
Batch 47/64 loss: 0.3404700756072998
Batch 48/64 loss: 0.34983396530151367
Batch 49/64 loss: 0.34499430656433105
Batch 50/64 loss: 0.342681884765625
Batch 51/64 loss: 0.34438711404800415
Batch 52/64 loss: 0.3397511839866638
Batch 53/64 loss: 0.349112331867218
Batch 54/64 loss: 0.34200721979141235
Batch 55/64 loss: 0.34285998344421387
Batch 56/64 loss: 0.3468342423439026
Batch 57/64 loss: 0.33780568838119507
Batch 58/64 loss: 0.3486199975013733
Batch 59/64 loss: 0.3424212336540222
Batch 60/64 loss: 0.3423343896865845
Batch 61/64 loss: 0.3448089361190796
Batch 62/64 loss: 0.34814631938934326
Batch 63/64 loss: 0.33921658992767334
Batch 64/64 loss: 0.3509984016418457
Epoch 150  Train loss: 0.3435257472243963  Val loss: 0.3492999861330511
Saving best model, epoch: 150
Epoch 151
-------------------------------
Batch 1/64 loss: 0.34322524070739746
Batch 2/64 loss: 0.34485018253326416
Batch 3/64 loss: 0.34247446060180664
Batch 4/64 loss: 0.34154748916625977
Batch 5/64 loss: 0.341644287109375
Batch 6/64 loss: 0.3381698727607727
Batch 7/64 loss: 0.3363003134727478
Batch 8/64 loss: 0.3437439799308777
Batch 9/64 loss: 0.3406559228897095
Batch 10/64 loss: 0.3437821865081787
Batch 11/64 loss: 0.34011030197143555
Batch 12/64 loss: 0.3395479917526245
Batch 13/64 loss: 0.34610188007354736
Batch 14/64 loss: 0.3442462682723999
Batch 15/64 loss: 0.3409687876701355
Batch 16/64 loss: 0.3438531160354614
Batch 17/64 loss: 0.3441452980041504
Batch 18/64 loss: 0.3359230160713196
Batch 19/64 loss: 0.33418571949005127
Batch 20/64 loss: 0.34274977445602417
Batch 21/64 loss: 0.34233254194259644
Batch 22/64 loss: 0.3397035002708435
Batch 23/64 loss: 0.3450443148612976
Batch 24/64 loss: 0.35069167613983154
Batch 25/64 loss: 0.3438253402709961
Batch 26/64 loss: 0.3446784019470215
Batch 27/64 loss: 0.3452029824256897
Batch 28/64 loss: 0.343619704246521
Batch 29/64 loss: 0.34518080949783325
Batch 30/64 loss: 0.3418450951576233
Batch 31/64 loss: 0.3408327102661133
Batch 32/64 loss: 0.340381383895874
Batch 33/64 loss: 0.3411756157875061
Batch 34/64 loss: 0.3436695337295532
Batch 35/64 loss: 0.340656042098999
Batch 36/64 loss: 0.34540897607803345
Batch 37/64 loss: 0.3440554141998291
Batch 38/64 loss: 0.3401082158088684
Batch 39/64 loss: 0.3436455726623535
Batch 40/64 loss: 0.34523147344589233
Batch 41/64 loss: 0.3399796485900879
Batch 42/64 loss: 0.3453519344329834
Batch 43/64 loss: 0.34724438190460205
Batch 44/64 loss: 0.35146307945251465
Batch 45/64 loss: 0.34342944622039795
Batch 46/64 loss: 0.3499211072921753
Batch 47/64 loss: 0.346211314201355
Batch 48/64 loss: 0.34400421380996704
Batch 49/64 loss: 0.34844064712524414
Batch 50/64 loss: 0.3402310013771057
Batch 51/64 loss: 0.34562253952026367
Batch 52/64 loss: 0.34367835521698
Batch 53/64 loss: 0.34406936168670654
Batch 54/64 loss: 0.3416174650192261
Batch 55/64 loss: 0.3424673080444336
Batch 56/64 loss: 0.34149765968322754
Batch 57/64 loss: 0.34435325860977173
Batch 58/64 loss: 0.3417084217071533
Batch 59/64 loss: 0.3357781171798706
Batch 60/64 loss: 0.34296417236328125
Batch 61/64 loss: 0.3410067558288574
Batch 62/64 loss: 0.3474382162094116
Batch 63/64 loss: 0.34342217445373535
Batch 64/64 loss: 0.34855443239212036
Epoch 151  Train loss: 0.34304049879896875  Val loss: 0.3503633274655162
Epoch 152
-------------------------------
Batch 1/64 loss: 0.3437747359275818
Batch 2/64 loss: 0.3382117748260498
Batch 3/64 loss: 0.3408012390136719
Batch 4/64 loss: 0.34838879108428955
Batch 5/64 loss: 0.34184515476226807
Batch 6/64 loss: 0.33704686164855957
Batch 7/64 loss: 0.348699688911438
Batch 8/64 loss: 0.34356629848480225
Batch 9/64 loss: 0.343402624130249
Batch 10/64 loss: 0.34050023555755615
Batch 11/64 loss: 0.34132200479507446
Batch 12/64 loss: 0.34291398525238037
Batch 13/64 loss: 0.3380817174911499
Batch 14/64 loss: 0.3442034125328064
Batch 15/64 loss: 0.33730000257492065
Batch 16/64 loss: 0.33918339014053345
Batch 17/64 loss: 0.341452419757843
Batch 18/64 loss: 0.3375251293182373
Batch 19/64 loss: 0.3413074016571045
Batch 20/64 loss: 0.34150075912475586
Batch 21/64 loss: 0.34441453218460083
Batch 22/64 loss: 0.34098243713378906
Batch 23/64 loss: 0.35037100315093994
Batch 24/64 loss: 0.34617215394973755
Batch 25/64 loss: 0.3427712917327881
Batch 26/64 loss: 0.33990514278411865
Batch 27/64 loss: 0.3397115468978882
Batch 28/64 loss: 0.3529703617095947
Batch 29/64 loss: 0.3395925760269165
Batch 30/64 loss: 0.34540748596191406
Batch 31/64 loss: 0.34648215770721436
Batch 32/64 loss: 0.3466838002204895
Batch 33/64 loss: 0.3420538902282715
Batch 34/64 loss: 0.3425050973892212
Batch 35/64 loss: 0.346843957901001
Batch 36/64 loss: 0.3377634882926941
Batch 37/64 loss: 0.3403109312057495
Batch 38/64 loss: 0.3398975133895874
Batch 39/64 loss: 0.3426159620285034
Batch 40/64 loss: 0.33681249618530273
Batch 41/64 loss: 0.34230756759643555
Batch 42/64 loss: 0.3429662585258484
Batch 43/64 loss: 0.33901798725128174
Batch 44/64 loss: 0.3405834436416626
Batch 45/64 loss: 0.3431018590927124
Batch 46/64 loss: 0.3387094736099243
Batch 47/64 loss: 0.338617742061615
Batch 48/64 loss: 0.34531456232070923
Batch 49/64 loss: 0.34387391805648804
Batch 50/64 loss: 0.3477460741996765
Batch 51/64 loss: 0.34261465072631836
Batch 52/64 loss: 0.34498971700668335
Batch 53/64 loss: 0.34130150079727173
Batch 54/64 loss: 0.34305524826049805
Batch 55/64 loss: 0.3407844305038452
Batch 56/64 loss: 0.3475008010864258
Batch 57/64 loss: 0.3479771018028259
Batch 58/64 loss: 0.34575045108795166
Batch 59/64 loss: 0.3437343239784241
Batch 60/64 loss: 0.3428196310997009
Batch 61/64 loss: 0.347229540348053
Batch 62/64 loss: 0.3452800512313843
Batch 63/64 loss: 0.34350526332855225
Batch 64/64 loss: 0.34424978494644165
Epoch 152  Train loss: 0.34278061787287395  Val loss: 0.3485968282951932
Saving best model, epoch: 152
Epoch 153
-------------------------------
Batch 1/64 loss: 0.3400987386703491
Batch 2/64 loss: 0.3378521800041199
Batch 3/64 loss: 0.33752763271331787
Batch 4/64 loss: 0.34340667724609375
Batch 5/64 loss: 0.3436635732650757
Batch 6/64 loss: 0.339380145072937
Batch 7/64 loss: 0.34496963024139404
Batch 8/64 loss: 0.34278005361557007
Batch 9/64 loss: 0.3374102711677551
Batch 10/64 loss: 0.34529417753219604
Batch 11/64 loss: 0.34460729360580444
Batch 12/64 loss: 0.34506744146347046
Batch 13/64 loss: 0.3438838720321655
Batch 14/64 loss: 0.3408689498901367
Batch 15/64 loss: 0.33957749605178833
Batch 16/64 loss: 0.34485387802124023
Batch 17/64 loss: 0.34742677211761475
Batch 18/64 loss: 0.3380661606788635
Batch 19/64 loss: 0.3439377546310425
Batch 20/64 loss: 0.34431594610214233
Batch 21/64 loss: 0.3429454565048218
Batch 22/64 loss: 0.3393722176551819
Batch 23/64 loss: 0.3438352346420288
Batch 24/64 loss: 0.3406878113746643
Batch 25/64 loss: 0.34217262268066406
Batch 26/64 loss: 0.3403162956237793
Batch 27/64 loss: 0.34529972076416016
Batch 28/64 loss: 0.33736181259155273
Batch 29/64 loss: 0.34131962060928345
Batch 30/64 loss: 0.3443429470062256
Batch 31/64 loss: 0.3388611674308777
Batch 32/64 loss: 0.34807658195495605
Batch 33/64 loss: 0.35095757246017456
Batch 34/64 loss: 0.34399640560150146
Batch 35/64 loss: 0.3406064510345459
Batch 36/64 loss: 0.3431447744369507
Batch 37/64 loss: 0.3456714153289795
Batch 38/64 loss: 0.34210634231567383
Batch 39/64 loss: 0.35097599029541016
Batch 40/64 loss: 0.3354130983352661
Batch 41/64 loss: 0.33704620599746704
Batch 42/64 loss: 0.3563990592956543
Batch 43/64 loss: 0.3386150002479553
Batch 44/64 loss: 0.3400532007217407
Batch 45/64 loss: 0.34097009897232056
Batch 46/64 loss: 0.3435598611831665
Batch 47/64 loss: 0.3375241160392761
Batch 48/64 loss: 0.343502938747406
Batch 49/64 loss: 0.3383721113204956
Batch 50/64 loss: 0.34682130813598633
Batch 51/64 loss: 0.34018635749816895
Batch 52/64 loss: 0.3465772867202759
Batch 53/64 loss: 0.33948105573654175
Batch 54/64 loss: 0.33876359462738037
Batch 55/64 loss: 0.3473259210586548
Batch 56/64 loss: 0.34711742401123047
Batch 57/64 loss: 0.3410918712615967
Batch 58/64 loss: 0.3424351215362549
Batch 59/64 loss: 0.346325159072876
Batch 60/64 loss: 0.34920382499694824
Batch 61/64 loss: 0.34359240531921387
Batch 62/64 loss: 0.33815670013427734
Batch 63/64 loss: 0.33946406841278076
Batch 64/64 loss: 0.341434121131897
Epoch 153  Train loss: 0.34260568572025674  Val loss: 0.3498442015287393
Epoch 154
-------------------------------
Batch 1/64 loss: 0.3412237763404846
Batch 2/64 loss: 0.33936941623687744
Batch 3/64 loss: 0.34412968158721924
Batch 4/64 loss: 0.34613192081451416
Batch 5/64 loss: 0.3475900888442993
Batch 6/64 loss: 0.34620189666748047
Batch 7/64 loss: 0.344651460647583
Batch 8/64 loss: 0.3383728265762329
Batch 9/64 loss: 0.3401455879211426
Batch 10/64 loss: 0.3388533592224121
Batch 11/64 loss: 0.3414428234100342
Batch 12/64 loss: 0.34895646572113037
Batch 13/64 loss: 0.3419846296310425
Batch 14/64 loss: 0.34752321243286133
Batch 15/64 loss: 0.34130799770355225
Batch 16/64 loss: 0.3390849232673645
Batch 17/64 loss: 0.33942943811416626
Batch 18/64 loss: 0.3430931568145752
Batch 19/64 loss: 0.3435448408126831
Batch 20/64 loss: 0.3380391001701355
Batch 21/64 loss: 0.3415300250053406
Batch 22/64 loss: 0.33490586280822754
Batch 23/64 loss: 0.34198224544525146
Batch 24/64 loss: 0.3504788875579834
Batch 25/64 loss: 0.34159696102142334
Batch 26/64 loss: 0.34018826484680176
Batch 27/64 loss: 0.3425034284591675
Batch 28/64 loss: 0.34079718589782715
Batch 29/64 loss: 0.3425655961036682
Batch 30/64 loss: 0.3378150463104248
Batch 31/64 loss: 0.3400559425354004
Batch 32/64 loss: 0.34564995765686035
Batch 33/64 loss: 0.33937329053878784
Batch 34/64 loss: 0.3409721851348877
Batch 35/64 loss: 0.33846336603164673
Batch 36/64 loss: 0.34240472316741943
Batch 37/64 loss: 0.3468320369720459
Batch 38/64 loss: 0.3413410186767578
Batch 39/64 loss: 0.3379722237586975
Batch 40/64 loss: 0.34048712253570557
Batch 41/64 loss: 0.35033977031707764
Batch 42/64 loss: 0.3365718126296997
Batch 43/64 loss: 0.3440285921096802
Batch 44/64 loss: 0.3422999978065491
Batch 45/64 loss: 0.3466178774833679
Batch 46/64 loss: 0.34674161672592163
Batch 47/64 loss: 0.34472447633743286
Batch 48/64 loss: 0.3482292890548706
Batch 49/64 loss: 0.33839094638824463
Batch 50/64 loss: 0.34417974948883057
Batch 51/64 loss: 0.3461393117904663
Batch 52/64 loss: 0.34343421459198
Batch 53/64 loss: 0.34347546100616455
Batch 54/64 loss: 0.33953559398651123
Batch 55/64 loss: 0.3427080512046814
Batch 56/64 loss: 0.33759868144989014
Batch 57/64 loss: 0.3497917652130127
Batch 58/64 loss: 0.3453914523124695
Batch 59/64 loss: 0.33945637941360474
Batch 60/64 loss: 0.3369258642196655
Batch 61/64 loss: 0.3408188819885254
Batch 62/64 loss: 0.3430233597755432
Batch 63/64 loss: 0.33778297901153564
Batch 64/64 loss: 0.3388429880142212
Epoch 154  Train loss: 0.3422953778622197  Val loss: 0.3492101424748136
Epoch 155
-------------------------------
Batch 1/64 loss: 0.33929145336151123
Batch 2/64 loss: 0.3453804850578308
Batch 3/64 loss: 0.34328627586364746
Batch 4/64 loss: 0.34204959869384766
Batch 5/64 loss: 0.3481331467628479
Batch 6/64 loss: 0.3403969407081604
Batch 7/64 loss: 0.3377089500427246
Batch 8/64 loss: 0.3384609818458557
Batch 9/64 loss: 0.34187906980514526
Batch 10/64 loss: 0.34191346168518066
Batch 11/64 loss: 0.33980250358581543
Batch 12/64 loss: 0.34248751401901245
Batch 13/64 loss: 0.34014928340911865
Batch 14/64 loss: 0.3418501615524292
Batch 15/64 loss: 0.3370002508163452
Batch 16/64 loss: 0.3483361005783081
Batch 17/64 loss: 0.342665433883667
Batch 18/64 loss: 0.340667724609375
Batch 19/64 loss: 0.3488001823425293
Batch 20/64 loss: 0.3431388735771179
Batch 21/64 loss: 0.34903484582901
Batch 22/64 loss: 0.34329724311828613
Batch 23/64 loss: 0.33872854709625244
Batch 24/64 loss: 0.34180188179016113
Batch 25/64 loss: 0.34129470586776733
Batch 26/64 loss: 0.35095882415771484
Batch 27/64 loss: 0.34415459632873535
Batch 28/64 loss: 0.34544074535369873
Batch 29/64 loss: 0.3428616523742676
Batch 30/64 loss: 0.3457742929458618
Batch 31/64 loss: 0.33825886249542236
Batch 32/64 loss: 0.3379843235015869
Batch 33/64 loss: 0.34138333797454834
Batch 34/64 loss: 0.3452841639518738
Batch 35/64 loss: 0.3434358239173889
Batch 36/64 loss: 0.34401440620422363
Batch 37/64 loss: 0.34110546112060547
Batch 38/64 loss: 0.34178978204727173
Batch 39/64 loss: 0.33873122930526733
Batch 40/64 loss: 0.341655433177948
Batch 41/64 loss: 0.344246506690979
Batch 42/64 loss: 0.34907209873199463
Batch 43/64 loss: 0.3476441502571106
Batch 44/64 loss: 0.3394728899002075
Batch 45/64 loss: 0.33833760023117065
Batch 46/64 loss: 0.3439429998397827
Batch 47/64 loss: 0.3402777910232544
Batch 48/64 loss: 0.34216833114624023
Batch 49/64 loss: 0.3473280668258667
Batch 50/64 loss: 0.34274792671203613
Batch 51/64 loss: 0.3410611152648926
Batch 52/64 loss: 0.343065083026886
Batch 53/64 loss: 0.3449101448059082
Batch 54/64 loss: 0.336902379989624
Batch 55/64 loss: 0.34174972772598267
Batch 56/64 loss: 0.3378487229347229
Batch 57/64 loss: 0.33900773525238037
Batch 58/64 loss: 0.3419535160064697
Batch 59/64 loss: 0.3440919518470764
Batch 60/64 loss: 0.3465763330459595
Batch 61/64 loss: 0.34606701135635376
Batch 62/64 loss: 0.3433159589767456
Batch 63/64 loss: 0.33721840381622314
Batch 64/64 loss: 0.3368222713470459
Epoch 155  Train loss: 0.3424629286223767  Val loss: 0.3491716565135418
Epoch 156
-------------------------------
Batch 1/64 loss: 0.3366227149963379
Batch 2/64 loss: 0.34145623445510864
Batch 3/64 loss: 0.3408961296081543
Batch 4/64 loss: 0.3440665006637573
Batch 5/64 loss: 0.343964159488678
Batch 6/64 loss: 0.3428652286529541
Batch 7/64 loss: 0.34072351455688477
Batch 8/64 loss: 0.34323012828826904
Batch 9/64 loss: 0.34273338317871094
Batch 10/64 loss: 0.3352281451225281
Batch 11/64 loss: 0.3445364832878113
Batch 12/64 loss: 0.33829939365386963
Batch 13/64 loss: 0.3434896469116211
Batch 14/64 loss: 0.3392648696899414
Batch 15/64 loss: 0.342390775680542
Batch 16/64 loss: 0.3392287492752075
Batch 17/64 loss: 0.34950804710388184
Batch 18/64 loss: 0.34572041034698486
Batch 19/64 loss: 0.3459395170211792
Batch 20/64 loss: 0.3378199338912964
Batch 21/64 loss: 0.340848445892334
Batch 22/64 loss: 0.34096741676330566
Batch 23/64 loss: 0.34603118896484375
Batch 24/64 loss: 0.3404388427734375
Batch 25/64 loss: 0.3427107334136963
Batch 26/64 loss: 0.341124951839447
Batch 27/64 loss: 0.3391494154930115
Batch 28/64 loss: 0.3472968339920044
Batch 29/64 loss: 0.34403789043426514
Batch 30/64 loss: 0.34550464153289795
Batch 31/64 loss: 0.34470224380493164
Batch 32/64 loss: 0.34169697761535645
Batch 33/64 loss: 0.3409299850463867
Batch 34/64 loss: 0.3437325358390808
Batch 35/64 loss: 0.3422228693962097
Batch 36/64 loss: 0.3411870002746582
Batch 37/64 loss: 0.34511834383010864
Batch 38/64 loss: 0.3434489369392395
Batch 39/64 loss: 0.33979296684265137
Batch 40/64 loss: 0.3452005982398987
Batch 41/64 loss: 0.3432902693748474
Batch 42/64 loss: 0.3474716544151306
Batch 43/64 loss: 0.3471987247467041
Batch 44/64 loss: 0.3455076217651367
Batch 45/64 loss: 0.3433912992477417
Batch 46/64 loss: 0.3393951654434204
Batch 47/64 loss: 0.3387488126754761
Batch 48/64 loss: 0.3413853645324707
Batch 49/64 loss: 0.34609532356262207
Batch 50/64 loss: 0.3335523009300232
Batch 51/64 loss: 0.33631956577301025
Batch 52/64 loss: 0.34585171937942505
Batch 53/64 loss: 0.3381085991859436
Batch 54/64 loss: 0.3473675847053528
Batch 55/64 loss: 0.34095442295074463
Batch 56/64 loss: 0.3401094675064087
Batch 57/64 loss: 0.34519970417022705
Batch 58/64 loss: 0.336566686630249
Batch 59/64 loss: 0.33864033222198486
Batch 60/64 loss: 0.34895479679107666
Batch 61/64 loss: 0.33757084608078003
Batch 62/64 loss: 0.34048402309417725
Batch 63/64 loss: 0.34381234645843506
Batch 64/64 loss: 0.348583459854126
Epoch 156  Train loss: 0.34229868253072104  Val loss: 0.35036964678682414
Epoch 157
-------------------------------
Batch 1/64 loss: 0.3388049602508545
Batch 2/64 loss: 0.34388506412506104
Batch 3/64 loss: 0.3374214172363281
Batch 4/64 loss: 0.34116941690444946
Batch 5/64 loss: 0.3486189842224121
Batch 6/64 loss: 0.33622199296951294
Batch 7/64 loss: 0.3416365385055542
Batch 8/64 loss: 0.33971595764160156
Batch 9/64 loss: 0.34605860710144043
Batch 10/64 loss: 0.340234637260437
Batch 11/64 loss: 0.34252119064331055
Batch 12/64 loss: 0.3397935628890991
Batch 13/64 loss: 0.343225359916687
Batch 14/64 loss: 0.34073972702026367
Batch 15/64 loss: 0.34117186069488525
Batch 16/64 loss: 0.3334232568740845
Batch 17/64 loss: 0.3366347551345825
Batch 18/64 loss: 0.33979105949401855
Batch 19/64 loss: 0.34111487865448
Batch 20/64 loss: 0.3530041575431824
Batch 21/64 loss: 0.3476097583770752
Batch 22/64 loss: 0.34129655361175537
Batch 23/64 loss: 0.3400135636329651
Batch 24/64 loss: 0.3421642780303955
Batch 25/64 loss: 0.3418949246406555
Batch 26/64 loss: 0.3448225259780884
Batch 27/64 loss: 0.34072184562683105
Batch 28/64 loss: 0.344745397567749
Batch 29/64 loss: 0.3479512333869934
Batch 30/64 loss: 0.34056901931762695
Batch 31/64 loss: 0.3466484546661377
Batch 32/64 loss: 0.3408123254776001
Batch 33/64 loss: 0.3453408479690552
Batch 34/64 loss: 0.34029507637023926
Batch 35/64 loss: 0.3387500047683716
Batch 36/64 loss: 0.34066450595855713
Batch 37/64 loss: 0.34739500284194946
Batch 38/64 loss: 0.3423137664794922
Batch 39/64 loss: 0.3432788848876953
Batch 40/64 loss: 0.34342479705810547
Batch 41/64 loss: 0.3430873155593872
Batch 42/64 loss: 0.338270902633667
Batch 43/64 loss: 0.3411167860031128
Batch 44/64 loss: 0.3430372476577759
Batch 45/64 loss: 0.3479706645011902
Batch 46/64 loss: 0.3434981107711792
Batch 47/64 loss: 0.34513235092163086
Batch 48/64 loss: 0.3444007635116577
Batch 49/64 loss: 0.3440071940422058
Batch 50/64 loss: 0.34134548902511597
Batch 51/64 loss: 0.3399128317832947
Batch 52/64 loss: 0.34304124116897583
Batch 53/64 loss: 0.3489832878112793
Batch 54/64 loss: 0.34437108039855957
Batch 55/64 loss: 0.3426032066345215
Batch 56/64 loss: 0.3483273983001709
Batch 57/64 loss: 0.3486825227737427
Batch 58/64 loss: 0.33727389574050903
Batch 59/64 loss: 0.3417487144470215
Batch 60/64 loss: 0.34483224153518677
Batch 61/64 loss: 0.3424554467201233
Batch 62/64 loss: 0.3384549617767334
Batch 63/64 loss: 0.3440113067626953
Batch 64/64 loss: 0.33897697925567627
Epoch 157  Train loss: 0.34253643681021295  Val loss: 0.3488462878666383
Epoch 158
-------------------------------
Batch 1/64 loss: 0.34323346614837646
Batch 2/64 loss: 0.3435782194137573
Batch 3/64 loss: 0.3453563451766968
Batch 4/64 loss: 0.34290289878845215
Batch 5/64 loss: 0.34472692012786865
Batch 6/64 loss: 0.35042887926101685
Batch 7/64 loss: 0.34357643127441406
Batch 8/64 loss: 0.3406332731246948
Batch 9/64 loss: 0.34279394149780273
Batch 10/64 loss: 0.3377618193626404
Batch 11/64 loss: 0.3425866365432739
Batch 12/64 loss: 0.34008532762527466
Batch 13/64 loss: 0.3428751230239868
Batch 14/64 loss: 0.3408939838409424
Batch 15/64 loss: 0.34158504009246826
Batch 16/64 loss: 0.3412632942199707
Batch 17/64 loss: 0.34142887592315674
Batch 18/64 loss: 0.3366791009902954
Batch 19/64 loss: 0.3434191942214966
Batch 20/64 loss: 0.34239476919174194
Batch 21/64 loss: 0.34457826614379883
Batch 22/64 loss: 0.3349487781524658
Batch 23/64 loss: 0.33948850631713867
Batch 24/64 loss: 0.335735559463501
Batch 25/64 loss: 0.3429563045501709
Batch 26/64 loss: 0.33973562717437744
Batch 27/64 loss: 0.34095239639282227
Batch 28/64 loss: 0.3417133688926697
Batch 29/64 loss: 0.34610867500305176
Batch 30/64 loss: 0.3422960042953491
Batch 31/64 loss: 0.3387869596481323
Batch 32/64 loss: 0.3441593647003174
Batch 33/64 loss: 0.34516584873199463
Batch 34/64 loss: 0.3392738103866577
Batch 35/64 loss: 0.34293311834335327
Batch 36/64 loss: 0.34343719482421875
Batch 37/64 loss: 0.3429598808288574
Batch 38/64 loss: 0.3433038592338562
Batch 39/64 loss: 0.3446452021598816
Batch 40/64 loss: 0.3420823812484741
Batch 41/64 loss: 0.3408852219581604
Batch 42/64 loss: 0.34513944387435913
Batch 43/64 loss: 0.3450586795806885
Batch 44/64 loss: 0.3444201946258545
Batch 45/64 loss: 0.34094077348709106
Batch 46/64 loss: 0.33743250370025635
Batch 47/64 loss: 0.34492093324661255
Batch 48/64 loss: 0.3387942314147949
Batch 49/64 loss: 0.3350059986114502
Batch 50/64 loss: 0.3390854001045227
Batch 51/64 loss: 0.3440169095993042
Batch 52/64 loss: 0.339385986328125
Batch 53/64 loss: 0.3468846082687378
Batch 54/64 loss: 0.33747434616088867
Batch 55/64 loss: 0.348655104637146
Batch 56/64 loss: 0.34176111221313477
Batch 57/64 loss: 0.3402346968650818
Batch 58/64 loss: 0.34466278553009033
Batch 59/64 loss: 0.3382387161254883
Batch 60/64 loss: 0.34085965156555176
Batch 61/64 loss: 0.33725303411483765
Batch 62/64 loss: 0.3436938524246216
Batch 63/64 loss: 0.33987241983413696
Batch 64/64 loss: 0.3432026505470276
Epoch 158  Train loss: 0.34189087432973525  Val loss: 0.3483065499882518
Saving best model, epoch: 158
Epoch 159
-------------------------------
Batch 1/64 loss: 0.34189319610595703
Batch 2/64 loss: 0.3392027020454407
Batch 3/64 loss: 0.33933836221694946
Batch 4/64 loss: 0.3442375659942627
Batch 5/64 loss: 0.3453020453453064
Batch 6/64 loss: 0.3447297215461731
Batch 7/64 loss: 0.33924078941345215
Batch 8/64 loss: 0.3416701555252075
Batch 9/64 loss: 0.3341858983039856
Batch 10/64 loss: 0.3351803421974182
Batch 11/64 loss: 0.33851373195648193
Batch 12/64 loss: 0.341422975063324
Batch 13/64 loss: 0.34237027168273926
Batch 14/64 loss: 0.3375234007835388
Batch 15/64 loss: 0.34221863746643066
Batch 16/64 loss: 0.3346415162086487
Batch 17/64 loss: 0.3373497724533081
Batch 18/64 loss: 0.33852219581604004
Batch 19/64 loss: 0.33838796615600586
Batch 20/64 loss: 0.3403729200363159
Batch 21/64 loss: 0.3399627208709717
Batch 22/64 loss: 0.346008837223053
Batch 23/64 loss: 0.3374166488647461
Batch 24/64 loss: 0.3435927629470825
Batch 25/64 loss: 0.3453143835067749
Batch 26/64 loss: 0.34198498725891113
Batch 27/64 loss: 0.33012616634368896
Batch 28/64 loss: 0.34953194856643677
Batch 29/64 loss: 0.3466503620147705
Batch 30/64 loss: 0.33790481090545654
Batch 31/64 loss: 0.3388538956642151
Batch 32/64 loss: 0.3456774353981018
Batch 33/64 loss: 0.34031927585601807
Batch 34/64 loss: 0.3501119613647461
Batch 35/64 loss: 0.34017181396484375
Batch 36/64 loss: 0.33709001541137695
Batch 37/64 loss: 0.3436715602874756
Batch 38/64 loss: 0.34461474418640137
Batch 39/64 loss: 0.34464895725250244
Batch 40/64 loss: 0.3445613384246826
Batch 41/64 loss: 0.3400852680206299
Batch 42/64 loss: 0.34686869382858276
Batch 43/64 loss: 0.34221822023391724
Batch 44/64 loss: 0.34136492013931274
Batch 45/64 loss: 0.3396158814430237
Batch 46/64 loss: 0.342634916305542
Batch 47/64 loss: 0.34959524869918823
Batch 48/64 loss: 0.34292304515838623
Batch 49/64 loss: 0.34385114908218384
Batch 50/64 loss: 0.34316539764404297
Batch 51/64 loss: 0.3362489938735962
Batch 52/64 loss: 0.3289393186569214
Batch 53/64 loss: 0.3436349630355835
Batch 54/64 loss: 0.33924466371536255
Batch 55/64 loss: 0.34289926290512085
Batch 56/64 loss: 0.3423879146575928
Batch 57/64 loss: 0.3440701961517334
Batch 58/64 loss: 0.34318774938583374
Batch 59/64 loss: 0.3467862010002136
Batch 60/64 loss: 0.3440079689025879
Batch 61/64 loss: 0.34329861402511597
Batch 62/64 loss: 0.34724289178848267
Batch 63/64 loss: 0.34026598930358887
Batch 64/64 loss: 0.3401346802711487
Epoch 159  Train loss: 0.3415554081692415  Val loss: 0.3482061294755575
Saving best model, epoch: 159
Epoch 160
-------------------------------
Batch 1/64 loss: 0.33957576751708984
Batch 2/64 loss: 0.34415167570114136
Batch 3/64 loss: 0.33311593532562256
Batch 4/64 loss: 0.3402498960494995
Batch 5/64 loss: 0.34190547466278076
Batch 6/64 loss: 0.3382962942123413
Batch 7/64 loss: 0.33896201848983765
Batch 8/64 loss: 0.3438655138015747
Batch 9/64 loss: 0.339943528175354
Batch 10/64 loss: 0.3449912667274475
Batch 11/64 loss: 0.3425447940826416
Batch 12/64 loss: 0.341785192489624
Batch 13/64 loss: 0.3317714333534241
Batch 14/64 loss: 0.3414405584335327
Batch 15/64 loss: 0.3437840938568115
Batch 16/64 loss: 0.3455244302749634
Batch 17/64 loss: 0.3375053405761719
Batch 18/64 loss: 0.33734434843063354
Batch 19/64 loss: 0.34640705585479736
Batch 20/64 loss: 0.34333598613739014
Batch 21/64 loss: 0.3460562229156494
Batch 22/64 loss: 0.3458288908004761
Batch 23/64 loss: 0.338998019695282
Batch 24/64 loss: 0.3404013514518738
Batch 25/64 loss: 0.342418372631073
Batch 26/64 loss: 0.34674155712127686
Batch 27/64 loss: 0.3376966714859009
Batch 28/64 loss: 0.3462435007095337
Batch 29/64 loss: 0.33538103103637695
Batch 30/64 loss: 0.33303213119506836
Batch 31/64 loss: 0.3415326476097107
Batch 32/64 loss: 0.338492751121521
Batch 33/64 loss: 0.3417479395866394
Batch 34/64 loss: 0.3353445529937744
Batch 35/64 loss: 0.34594249725341797
Batch 36/64 loss: 0.3366142511367798
Batch 37/64 loss: 0.34193795919418335
Batch 38/64 loss: 0.34889352321624756
Batch 39/64 loss: 0.34023165702819824
Batch 40/64 loss: 0.3442767858505249
Batch 41/64 loss: 0.3431950807571411
Batch 42/64 loss: 0.3424522876739502
Batch 43/64 loss: 0.3427776098251343
Batch 44/64 loss: 0.34110963344573975
Batch 45/64 loss: 0.34341132640838623
Batch 46/64 loss: 0.33713507652282715
Batch 47/64 loss: 0.3353196382522583
Batch 48/64 loss: 0.3431442379951477
Batch 49/64 loss: 0.3467801809310913
Batch 50/64 loss: 0.34099823236465454
Batch 51/64 loss: 0.3443373441696167
Batch 52/64 loss: 0.34577876329421997
Batch 53/64 loss: 0.33853626251220703
Batch 54/64 loss: 0.34283924102783203
Batch 55/64 loss: 0.3445778489112854
Batch 56/64 loss: 0.3407641649246216
Batch 57/64 loss: 0.34469175338745117
Batch 58/64 loss: 0.34825563430786133
Batch 59/64 loss: 0.3447694778442383
Batch 60/64 loss: 0.3398016095161438
Batch 61/64 loss: 0.33632659912109375
Batch 62/64 loss: 0.34441322088241577
Batch 63/64 loss: 0.3433701992034912
Batch 64/64 loss: 0.339391827583313
Epoch 160  Train loss: 0.34154732881807814  Val loss: 0.34866240630854445
Epoch 161
-------------------------------
Batch 1/64 loss: 0.3473951816558838
Batch 2/64 loss: 0.34247255325317383
Batch 3/64 loss: 0.3449169397354126
Batch 4/64 loss: 0.33961808681488037
Batch 5/64 loss: 0.33657902479171753
Batch 6/64 loss: 0.3386002779006958
Batch 7/64 loss: 0.3413127064704895
Batch 8/64 loss: 0.3417813777923584
Batch 9/64 loss: 0.34102702140808105
Batch 10/64 loss: 0.3403749465942383
Batch 11/64 loss: 0.34624427556991577
Batch 12/64 loss: 0.3435772657394409
Batch 13/64 loss: 0.33620965480804443
Batch 14/64 loss: 0.34563446044921875
Batch 15/64 loss: 0.34032142162323
Batch 16/64 loss: 0.3433406352996826
Batch 17/64 loss: 0.341222882270813
Batch 18/64 loss: 0.3422519564628601
Batch 19/64 loss: 0.3377577066421509
Batch 20/64 loss: 0.34257495403289795
Batch 21/64 loss: 0.3353196382522583
Batch 22/64 loss: 0.34183716773986816
Batch 23/64 loss: 0.33509397506713867
Batch 24/64 loss: 0.3387978672981262
Batch 25/64 loss: 0.33994340896606445
Batch 26/64 loss: 0.34190452098846436
Batch 27/64 loss: 0.3372269868850708
Batch 28/64 loss: 0.33629703521728516
Batch 29/64 loss: 0.3433980941772461
Batch 30/64 loss: 0.343100905418396
Batch 31/64 loss: 0.3377559781074524
Batch 32/64 loss: 0.3442307114601135
Batch 33/64 loss: 0.339763879776001
Batch 34/64 loss: 0.34512078762054443
Batch 35/64 loss: 0.3423919081687927
Batch 36/64 loss: 0.3397762179374695
Batch 37/64 loss: 0.34319114685058594
Batch 38/64 loss: 0.3419036269187927
Batch 39/64 loss: 0.3481414318084717
Batch 40/64 loss: 0.33676934242248535
Batch 41/64 loss: 0.34449565410614014
Batch 42/64 loss: 0.34221184253692627
Batch 43/64 loss: 0.33853888511657715
Batch 44/64 loss: 0.3469693064689636
Batch 45/64 loss: 0.339732825756073
Batch 46/64 loss: 0.34425854682922363
Batch 47/64 loss: 0.3377186059951782
Batch 48/64 loss: 0.341696560382843
Batch 49/64 loss: 0.33579176664352417
Batch 50/64 loss: 0.33830469846725464
Batch 51/64 loss: 0.3475191593170166
Batch 52/64 loss: 0.33903980255126953
Batch 53/64 loss: 0.34013354778289795
Batch 54/64 loss: 0.3418568968772888
Batch 55/64 loss: 0.34039175510406494
Batch 56/64 loss: 0.3374577760696411
Batch 57/64 loss: 0.3423275947570801
Batch 58/64 loss: 0.3417147397994995
Batch 59/64 loss: 0.3441060185432434
Batch 60/64 loss: 0.3383653163909912
Batch 61/64 loss: 0.3382143974304199
Batch 62/64 loss: 0.34375131130218506
Batch 63/64 loss: 0.3400067090988159
Batch 64/64 loss: 0.34543371200561523
Epoch 161  Train loss: 0.34115854057611206  Val loss: 0.3482293451774571
Epoch 162
-------------------------------
Batch 1/64 loss: 0.33859169483184814
Batch 2/64 loss: 0.3375281095504761
Batch 3/64 loss: 0.3398796319961548
Batch 4/64 loss: 0.34648382663726807
Batch 5/64 loss: 0.3457888960838318
Batch 6/64 loss: 0.3396040201187134
Batch 7/64 loss: 0.3408015966415405
Batch 8/64 loss: 0.34192341566085815
Batch 9/64 loss: 0.34057456254959106
Batch 10/64 loss: 0.3399312496185303
Batch 11/64 loss: 0.3412048816680908
Batch 12/64 loss: 0.3380597233772278
Batch 13/64 loss: 0.3436708450317383
Batch 14/64 loss: 0.339847207069397
Batch 15/64 loss: 0.3399829864501953
Batch 16/64 loss: 0.33950430154800415
Batch 17/64 loss: 0.3408021926879883
Batch 18/64 loss: 0.3495748043060303
Batch 19/64 loss: 0.3414720892906189
Batch 20/64 loss: 0.34133249521255493
Batch 21/64 loss: 0.33984869718551636
Batch 22/64 loss: 0.3389533758163452
Batch 23/64 loss: 0.34144943952560425
Batch 24/64 loss: 0.34312331676483154
Batch 25/64 loss: 0.3417550325393677
Batch 26/64 loss: 0.34000593423843384
Batch 27/64 loss: 0.34244346618652344
Batch 28/64 loss: 0.337291955947876
Batch 29/64 loss: 0.3363913893699646
Batch 30/64 loss: 0.33504223823547363
Batch 31/64 loss: 0.34364044666290283
Batch 32/64 loss: 0.3347073793411255
Batch 33/64 loss: 0.3413076400756836
Batch 34/64 loss: 0.33912432193756104
Batch 35/64 loss: 0.341495156288147
Batch 36/64 loss: 0.3340938687324524
Batch 37/64 loss: 0.3392968773841858
Batch 38/64 loss: 0.3373097777366638
Batch 39/64 loss: 0.34291207790374756
Batch 40/64 loss: 0.3468329906463623
Batch 41/64 loss: 0.3411900997161865
Batch 42/64 loss: 0.3444777727127075
Batch 43/64 loss: 0.3441004753112793
Batch 44/64 loss: 0.34140074253082275
Batch 45/64 loss: 0.3340117335319519
Batch 46/64 loss: 0.34163445234298706
Batch 47/64 loss: 0.34733325242996216
Batch 48/64 loss: 0.3512793779373169
Batch 49/64 loss: 0.3419407606124878
Batch 50/64 loss: 0.33892542123794556
Batch 51/64 loss: 0.34757792949676514
Batch 52/64 loss: 0.34525489807128906
Batch 53/64 loss: 0.343005895614624
Batch 54/64 loss: 0.3364538550376892
Batch 55/64 loss: 0.34512007236480713
Batch 56/64 loss: 0.3419053554534912
Batch 57/64 loss: 0.3437116742134094
Batch 58/64 loss: 0.34259653091430664
Batch 59/64 loss: 0.33507561683654785
Batch 60/64 loss: 0.34252703189849854
Batch 61/64 loss: 0.33378589153289795
Batch 62/64 loss: 0.3382972478866577
Batch 63/64 loss: 0.34401631355285645
Batch 64/64 loss: 0.3479212522506714
Epoch 162  Train loss: 0.3411787804435281  Val loss: 0.3483538322432344
Epoch 163
-------------------------------
Batch 1/64 loss: 0.3443043828010559
Batch 2/64 loss: 0.33781754970550537
Batch 3/64 loss: 0.34121596813201904
Batch 4/64 loss: 0.3452785015106201
Batch 5/64 loss: 0.33379995822906494
Batch 6/64 loss: 0.3404068946838379
Batch 7/64 loss: 0.3413357734680176
Batch 8/64 loss: 0.340573251247406
Batch 9/64 loss: 0.34027624130249023
Batch 10/64 loss: 0.3435003161430359
Batch 11/64 loss: 0.34118616580963135
Batch 12/64 loss: 0.3394041061401367
Batch 13/64 loss: 0.34867751598358154
Batch 14/64 loss: 0.3397729992866516
Batch 15/64 loss: 0.3364269733428955
Batch 16/64 loss: 0.3447420597076416
Batch 17/64 loss: 0.33650392293930054
Batch 18/64 loss: 0.33871597051620483
Batch 19/64 loss: 0.3419654369354248
Batch 20/64 loss: 0.33981752395629883
Batch 21/64 loss: 0.33777284622192383
Batch 22/64 loss: 0.34218621253967285
Batch 23/64 loss: 0.33698874711990356
Batch 24/64 loss: 0.3387528657913208
Batch 25/64 loss: 0.33936917781829834
Batch 26/64 loss: 0.3403959274291992
Batch 27/64 loss: 0.33634042739868164
Batch 28/64 loss: 0.3442842960357666
Batch 29/64 loss: 0.34639179706573486
Batch 30/64 loss: 0.3425290584564209
Batch 31/64 loss: 0.3444487452507019
Batch 32/64 loss: 0.3395121097564697
Batch 33/64 loss: 0.34973853826522827
Batch 34/64 loss: 0.3378415107727051
Batch 35/64 loss: 0.3426079750061035
Batch 36/64 loss: 0.3413604497909546
Batch 37/64 loss: 0.34803783893585205
Batch 38/64 loss: 0.3412296772003174
Batch 39/64 loss: 0.33876436948776245
Batch 40/64 loss: 0.33987975120544434
Batch 41/64 loss: 0.3359140157699585
Batch 42/64 loss: 0.3387441635131836
Batch 43/64 loss: 0.339985728263855
Batch 44/64 loss: 0.3421570658683777
Batch 45/64 loss: 0.3454440236091614
Batch 46/64 loss: 0.3455311059951782
Batch 47/64 loss: 0.3314495086669922
Batch 48/64 loss: 0.33781158924102783
Batch 49/64 loss: 0.34292423725128174
Batch 50/64 loss: 0.3397977352142334
Batch 51/64 loss: 0.34265434741973877
Batch 52/64 loss: 0.3328269124031067
Batch 53/64 loss: 0.34326183795928955
Batch 54/64 loss: 0.336584210395813
Batch 55/64 loss: 0.34524083137512207
Batch 56/64 loss: 0.3444565534591675
Batch 57/64 loss: 0.34023338556289673
Batch 58/64 loss: 0.3435213565826416
Batch 59/64 loss: 0.34091466665267944
Batch 60/64 loss: 0.3414924144744873
Batch 61/64 loss: 0.3398247957229614
Batch 62/64 loss: 0.34251075983047485
Batch 63/64 loss: 0.3480050563812256
Batch 64/64 loss: 0.3408568501472473
Epoch 163  Train loss: 0.34103659251156976  Val loss: 0.34831029340573605
Epoch 164
-------------------------------
Batch 1/64 loss: 0.34029436111450195
Batch 2/64 loss: 0.33907270431518555
Batch 3/64 loss: 0.3467939496040344
Batch 4/64 loss: 0.335097074508667
Batch 5/64 loss: 0.34056735038757324
Batch 6/64 loss: 0.3496619462966919
Batch 7/64 loss: 0.3384910821914673
Batch 8/64 loss: 0.3437080383300781
Batch 9/64 loss: 0.3389967083930969
Batch 10/64 loss: 0.34262561798095703
Batch 11/64 loss: 0.3408737778663635
Batch 12/64 loss: 0.33684277534484863
Batch 13/64 loss: 0.3370424509048462
Batch 14/64 loss: 0.3448033332824707
Batch 15/64 loss: 0.3406491279602051
Batch 16/64 loss: 0.34675145149230957
Batch 17/64 loss: 0.34695345163345337
Batch 18/64 loss: 0.33570396900177
Batch 19/64 loss: 0.3389551639556885
Batch 20/64 loss: 0.33835673332214355
Batch 21/64 loss: 0.3457905054092407
Batch 22/64 loss: 0.34330326318740845
Batch 23/64 loss: 0.33271098136901855
Batch 24/64 loss: 0.34102803468704224
Batch 25/64 loss: 0.3356406092643738
Batch 26/64 loss: 0.34202152490615845
Batch 27/64 loss: 0.3423725366592407
Batch 28/64 loss: 0.34082990884780884
Batch 29/64 loss: 0.3477134704589844
Batch 30/64 loss: 0.33882761001586914
Batch 31/64 loss: 0.343192994594574
Batch 32/64 loss: 0.33704042434692383
Batch 33/64 loss: 0.3397839069366455
Batch 34/64 loss: 0.33861297369003296
Batch 35/64 loss: 0.3416838049888611
Batch 36/64 loss: 0.34192973375320435
Batch 37/64 loss: 0.34436601400375366
Batch 38/64 loss: 0.3422842025756836
Batch 39/64 loss: 0.3398531675338745
Batch 40/64 loss: 0.3402705192565918
Batch 41/64 loss: 0.33763837814331055
Batch 42/64 loss: 0.3368796110153198
Batch 43/64 loss: 0.3455818295478821
Batch 44/64 loss: 0.3353031873703003
Batch 45/64 loss: 0.33628106117248535
Batch 46/64 loss: 0.34603673219680786
Batch 47/64 loss: 0.3398509621620178
Batch 48/64 loss: 0.34084105491638184
Batch 49/64 loss: 0.3406941890716553
Batch 50/64 loss: 0.3423265814781189
Batch 51/64 loss: 0.34358304738998413
Batch 52/64 loss: 0.3430020809173584
Batch 53/64 loss: 0.34120094776153564
Batch 54/64 loss: 0.3436695337295532
Batch 55/64 loss: 0.3416177034378052
Batch 56/64 loss: 0.33932042121887207
Batch 57/64 loss: 0.3400588035583496
Batch 58/64 loss: 0.33848345279693604
Batch 59/64 loss: 0.33445847034454346
Batch 60/64 loss: 0.33881938457489014
Batch 61/64 loss: 0.3414826989173889
Batch 62/64 loss: 0.3351116180419922
Batch 63/64 loss: 0.338901162147522
Batch 64/64 loss: 0.34055644273757935
Epoch 164  Train loss: 0.3406754117386014  Val loss: 0.34800365434069813
Saving best model, epoch: 164
Epoch 165
-------------------------------
Batch 1/64 loss: 0.33428847789764404
Batch 2/64 loss: 0.33908963203430176
Batch 3/64 loss: 0.34269917011260986
Batch 4/64 loss: 0.3446640968322754
Batch 5/64 loss: 0.3487555980682373
Batch 6/64 loss: 0.3386607766151428
Batch 7/64 loss: 0.33511996269226074
Batch 8/64 loss: 0.3405277132987976
Batch 9/64 loss: 0.3465001583099365
Batch 10/64 loss: 0.34123528003692627
Batch 11/64 loss: 0.34140336513519287
Batch 12/64 loss: 0.33503997325897217
Batch 13/64 loss: 0.3403245210647583
Batch 14/64 loss: 0.34348249435424805
Batch 15/64 loss: 0.33316731452941895
Batch 16/64 loss: 0.34043532609939575
Batch 17/64 loss: 0.3376416563987732
Batch 18/64 loss: 0.3388051986694336
Batch 19/64 loss: 0.33554697036743164
Batch 20/64 loss: 0.3357558846473694
Batch 21/64 loss: 0.34245073795318604
Batch 22/64 loss: 0.3398113250732422
Batch 23/64 loss: 0.34220242500305176
Batch 24/64 loss: 0.328654408454895
Batch 25/64 loss: 0.34045398235321045
Batch 26/64 loss: 0.33728551864624023
Batch 27/64 loss: 0.3438637852668762
Batch 28/64 loss: 0.34114205837249756
Batch 29/64 loss: 0.33779263496398926
Batch 30/64 loss: 0.3430076837539673
Batch 31/64 loss: 0.34162187576293945
Batch 32/64 loss: 0.3387507200241089
Batch 33/64 loss: 0.3408339023590088
Batch 34/64 loss: 0.3437952995300293
Batch 35/64 loss: 0.34001052379608154
Batch 36/64 loss: 0.34080004692077637
Batch 37/64 loss: 0.33717548847198486
Batch 38/64 loss: 0.34496086835861206
Batch 39/64 loss: 0.3412737250328064
Batch 40/64 loss: 0.34367090463638306
Batch 41/64 loss: 0.34381258487701416
Batch 42/64 loss: 0.3328043818473816
Batch 43/64 loss: 0.3449150323867798
Batch 44/64 loss: 0.339779257774353
Batch 45/64 loss: 0.3422873020172119
Batch 46/64 loss: 0.34316587448120117
Batch 47/64 loss: 0.34320181608200073
Batch 48/64 loss: 0.3347294330596924
Batch 49/64 loss: 0.33804500102996826
Batch 50/64 loss: 0.33809947967529297
Batch 51/64 loss: 0.3432004451751709
Batch 52/64 loss: 0.3353145718574524
Batch 53/64 loss: 0.33679068088531494
Batch 54/64 loss: 0.3428991436958313
Batch 55/64 loss: 0.34995102882385254
Batch 56/64 loss: 0.34067797660827637
Batch 57/64 loss: 0.3364420533180237
Batch 58/64 loss: 0.3431670069694519
Batch 59/64 loss: 0.34033071994781494
Batch 60/64 loss: 0.33968585729599
Batch 61/64 loss: 0.3443104028701782
Batch 62/64 loss: 0.34401994943618774
Batch 63/64 loss: 0.343064546585083
Batch 64/64 loss: 0.3323690891265869
Epoch 165  Train loss: 0.3402772211561016  Val loss: 0.34799194458833677
Saving best model, epoch: 165
Epoch 166
-------------------------------
Batch 1/64 loss: 0.34173059463500977
Batch 2/64 loss: 0.34437131881713867
Batch 3/64 loss: 0.3346988558769226
Batch 4/64 loss: 0.34105753898620605
Batch 5/64 loss: 0.34405583143234253
Batch 6/64 loss: 0.3480522632598877
Batch 7/64 loss: 0.33861058950424194
Batch 8/64 loss: 0.33451753854751587
Batch 9/64 loss: 0.34133875370025635
Batch 10/64 loss: 0.3369104266166687
Batch 11/64 loss: 0.3352372646331787
Batch 12/64 loss: 0.337401807308197
Batch 13/64 loss: 0.342836856842041
Batch 14/64 loss: 0.34059232473373413
Batch 15/64 loss: 0.3420615792274475
Batch 16/64 loss: 0.3382527828216553
Batch 17/64 loss: 0.33619797229766846
Batch 18/64 loss: 0.3421095609664917
Batch 19/64 loss: 0.34698647260665894
Batch 20/64 loss: 0.3356472849845886
Batch 21/64 loss: 0.3418845534324646
Batch 22/64 loss: 0.3435932397842407
Batch 23/64 loss: 0.34596753120422363
Batch 24/64 loss: 0.34250688552856445
Batch 25/64 loss: 0.3455553650856018
Batch 26/64 loss: 0.33728301525115967
Batch 27/64 loss: 0.3371913433074951
Batch 28/64 loss: 0.34619879722595215
Batch 29/64 loss: 0.34534287452697754
Batch 30/64 loss: 0.33838045597076416
Batch 31/64 loss: 0.3430051803588867
Batch 32/64 loss: 0.3413010835647583
Batch 33/64 loss: 0.33292925357818604
Batch 34/64 loss: 0.3403533697128296
Batch 35/64 loss: 0.33992958068847656
Batch 36/64 loss: 0.34663742780685425
Batch 37/64 loss: 0.3358415365219116
Batch 38/64 loss: 0.34458303451538086
Batch 39/64 loss: 0.3405236005783081
Batch 40/64 loss: 0.3390007019042969
Batch 41/64 loss: 0.33900147676467896
Batch 42/64 loss: 0.34263086318969727
Batch 43/64 loss: 0.3422868251800537
Batch 44/64 loss: 0.34101223945617676
Batch 45/64 loss: 0.3429182171821594
Batch 46/64 loss: 0.3347353935241699
Batch 47/64 loss: 0.3398396968841553
Batch 48/64 loss: 0.33834314346313477
Batch 49/64 loss: 0.34084975719451904
Batch 50/64 loss: 0.33871304988861084
Batch 51/64 loss: 0.3374716639518738
Batch 52/64 loss: 0.33798646926879883
Batch 53/64 loss: 0.3371431827545166
Batch 54/64 loss: 0.34436529874801636
Batch 55/64 loss: 0.3419945240020752
Batch 56/64 loss: 0.3400024175643921
Batch 57/64 loss: 0.33853286504745483
Batch 58/64 loss: 0.34403473138809204
Batch 59/64 loss: 0.34368330240249634
Batch 60/64 loss: 0.33811426162719727
Batch 61/64 loss: 0.33638477325439453
Batch 62/64 loss: 0.3462710380554199
Batch 63/64 loss: 0.338232159614563
Batch 64/64 loss: 0.33829617500305176
Epoch 166  Train loss: 0.3405324851765352  Val loss: 0.34792091059930547
Saving best model, epoch: 166
Epoch 167
-------------------------------
Batch 1/64 loss: 0.3435620069503784
Batch 2/64 loss: 0.3464416265487671
Batch 3/64 loss: 0.3408415913581848
Batch 4/64 loss: 0.3356630206108093
Batch 5/64 loss: 0.33854830265045166
Batch 6/64 loss: 0.3413419723510742
Batch 7/64 loss: 0.336773157119751
Batch 8/64 loss: 0.33685463666915894
Batch 9/64 loss: 0.34139907360076904
Batch 10/64 loss: 0.3402709364891052
Batch 11/64 loss: 0.340517520904541
Batch 12/64 loss: 0.33452075719833374
Batch 13/64 loss: 0.3381284475326538
Batch 14/64 loss: 0.33941012620925903
Batch 15/64 loss: 0.3383901119232178
Batch 16/64 loss: 0.33924031257629395
Batch 17/64 loss: 0.34060072898864746
Batch 18/64 loss: 0.33969855308532715
Batch 19/64 loss: 0.3436916470527649
Batch 20/64 loss: 0.3365703821182251
Batch 21/64 loss: 0.34333664178848267
Batch 22/64 loss: 0.3423590064048767
Batch 23/64 loss: 0.34788084030151367
Batch 24/64 loss: 0.337211549282074
Batch 25/64 loss: 0.34280240535736084
Batch 26/64 loss: 0.3435629606246948
Batch 27/64 loss: 0.33947890996932983
Batch 28/64 loss: 0.3415752649307251
Batch 29/64 loss: 0.3383857011795044
Batch 30/64 loss: 0.34690427780151367
Batch 31/64 loss: 0.3355310559272766
Batch 32/64 loss: 0.3375115394592285
Batch 33/64 loss: 0.34683549404144287
Batch 34/64 loss: 0.3402772545814514
Batch 35/64 loss: 0.34378254413604736
Batch 36/64 loss: 0.3367345333099365
Batch 37/64 loss: 0.33409643173217773
Batch 38/64 loss: 0.340457558631897
Batch 39/64 loss: 0.3438361883163452
Batch 40/64 loss: 0.3377307653427124
Batch 41/64 loss: 0.3430570363998413
Batch 42/64 loss: 0.3369327187538147
Batch 43/64 loss: 0.3442222476005554
Batch 44/64 loss: 0.34212398529052734
Batch 45/64 loss: 0.33884382247924805
Batch 46/64 loss: 0.33387166261672974
Batch 47/64 loss: 0.3416609764099121
Batch 48/64 loss: 0.34370023012161255
Batch 49/64 loss: 0.34019017219543457
Batch 50/64 loss: 0.3410140872001648
Batch 51/64 loss: 0.33401066064834595
Batch 52/64 loss: 0.3359827399253845
Batch 53/64 loss: 0.34047842025756836
Batch 54/64 loss: 0.33811694383621216
Batch 55/64 loss: 0.34551548957824707
Batch 56/64 loss: 0.34232795238494873
Batch 57/64 loss: 0.33742982149124146
Batch 58/64 loss: 0.3406565189361572
Batch 59/64 loss: 0.3354499340057373
Batch 60/64 loss: 0.34398573637008667
Batch 61/64 loss: 0.33632892370224
Batch 62/64 loss: 0.3409769535064697
Batch 63/64 loss: 0.3394346237182617
Batch 64/64 loss: 0.3368263244628906
Epoch 167  Train loss: 0.3401048978169759  Val loss: 0.34720245075389694
Saving best model, epoch: 167
Epoch 168
-------------------------------
Batch 1/64 loss: 0.3296860456466675
Batch 2/64 loss: 0.3319220542907715
Batch 3/64 loss: 0.34483981132507324
Batch 4/64 loss: 0.3475424647331238
Batch 5/64 loss: 0.33775073289871216
Batch 6/64 loss: 0.33470165729522705
Batch 7/64 loss: 0.3383714556694031
Batch 8/64 loss: 0.3403129577636719
Batch 9/64 loss: 0.3460956811904907
Batch 10/64 loss: 0.33621132373809814
Batch 11/64 loss: 0.33659815788269043
Batch 12/64 loss: 0.3402698040008545
Batch 13/64 loss: 0.33351683616638184
Batch 14/64 loss: 0.3407609462738037
Batch 15/64 loss: 0.3413922190666199
Batch 16/64 loss: 0.3441285490989685
Batch 17/64 loss: 0.33811426162719727
Batch 18/64 loss: 0.3366461992263794
Batch 19/64 loss: 0.3448922634124756
Batch 20/64 loss: 0.33963632583618164
Batch 21/64 loss: 0.3397655487060547
Batch 22/64 loss: 0.34108537435531616
Batch 23/64 loss: 0.3426307439804077
Batch 24/64 loss: 0.3365378975868225
Batch 25/64 loss: 0.345111608505249
Batch 26/64 loss: 0.3393493890762329
Batch 27/64 loss: 0.33378124237060547
Batch 28/64 loss: 0.3408423662185669
Batch 29/64 loss: 0.33784955739974976
Batch 30/64 loss: 0.33621156215667725
Batch 31/64 loss: 0.34197747707366943
Batch 32/64 loss: 0.34373223781585693
Batch 33/64 loss: 0.33463573455810547
Batch 34/64 loss: 0.3340747356414795
Batch 35/64 loss: 0.3370072841644287
Batch 36/64 loss: 0.33450645208358765
Batch 37/64 loss: 0.34014230966567993
Batch 38/64 loss: 0.3421087861061096
Batch 39/64 loss: 0.34561634063720703
Batch 40/64 loss: 0.3409914970397949
Batch 41/64 loss: 0.34202414751052856
Batch 42/64 loss: 0.3404735326766968
Batch 43/64 loss: 0.34404218196868896
Batch 44/64 loss: 0.34100157022476196
Batch 45/64 loss: 0.33609330654144287
Batch 46/64 loss: 0.3427513837814331
Batch 47/64 loss: 0.3368570804595947
Batch 48/64 loss: 0.3373974561691284
Batch 49/64 loss: 0.3446800708770752
Batch 50/64 loss: 0.34799569845199585
Batch 51/64 loss: 0.344799280166626
Batch 52/64 loss: 0.34025347232818604
Batch 53/64 loss: 0.33714425563812256
Batch 54/64 loss: 0.3389178514480591
Batch 55/64 loss: 0.34043073654174805
Batch 56/64 loss: 0.3401640057563782
Batch 57/64 loss: 0.3371126651763916
Batch 58/64 loss: 0.33693408966064453
Batch 59/64 loss: 0.3403017520904541
Batch 60/64 loss: 0.3451550602912903
Batch 61/64 loss: 0.3409051299095154
Batch 62/64 loss: 0.3372151255607605
Batch 63/64 loss: 0.3357377052307129
Batch 64/64 loss: 0.34077906608581543
Epoch 168  Train loss: 0.33969129020092537  Val loss: 0.3474359104723455
Epoch 169
-------------------------------
Batch 1/64 loss: 0.3412439227104187
Batch 2/64 loss: 0.34169691801071167
Batch 3/64 loss: 0.3455684185028076
Batch 4/64 loss: 0.3394596576690674
Batch 5/64 loss: 0.3382185697555542
Batch 6/64 loss: 0.3325197696685791
Batch 7/64 loss: 0.33373600244522095
Batch 8/64 loss: 0.34054142236709595
Batch 9/64 loss: 0.33450496196746826
Batch 10/64 loss: 0.34274691343307495
Batch 11/64 loss: 0.34191691875457764
Batch 12/64 loss: 0.3404914140701294
Batch 13/64 loss: 0.3437840938568115
Batch 14/64 loss: 0.3324624300003052
Batch 15/64 loss: 0.34182411432266235
Batch 16/64 loss: 0.34409284591674805
Batch 17/64 loss: 0.3429035544395447
Batch 18/64 loss: 0.33457720279693604
Batch 19/64 loss: 0.3393471837043762
Batch 20/64 loss: 0.33901315927505493
Batch 21/64 loss: 0.33782005310058594
Batch 22/64 loss: 0.3418983221054077
Batch 23/64 loss: 0.3342689871788025
Batch 24/64 loss: 0.34385842084884644
Batch 25/64 loss: 0.33648478984832764
Batch 26/64 loss: 0.34032243490219116
Batch 27/64 loss: 0.33836066722869873
Batch 28/64 loss: 0.34272778034210205
Batch 29/64 loss: 0.34430360794067383
Batch 30/64 loss: 0.33528488874435425
Batch 31/64 loss: 0.33275729417800903
Batch 32/64 loss: 0.33826446533203125
Batch 33/64 loss: 0.3443419933319092
Batch 34/64 loss: 0.3358890414237976
Batch 35/64 loss: 0.3440224528312683
Batch 36/64 loss: 0.34065377712249756
Batch 37/64 loss: 0.33477091789245605
Batch 38/64 loss: 0.34004145860671997
Batch 39/64 loss: 0.3397190570831299
Batch 40/64 loss: 0.33577239513397217
Batch 41/64 loss: 0.3466528654098511
Batch 42/64 loss: 0.3355673551559448
Batch 43/64 loss: 0.3451727628707886
Batch 44/64 loss: 0.34107768535614014
Batch 45/64 loss: 0.34091830253601074
Batch 46/64 loss: 0.3338050842285156
Batch 47/64 loss: 0.3414927124977112
Batch 48/64 loss: 0.3430476188659668
Batch 49/64 loss: 0.3443834185600281
Batch 50/64 loss: 0.34476208686828613
Batch 51/64 loss: 0.3321722149848938
Batch 52/64 loss: 0.34066295623779297
Batch 53/64 loss: 0.34895384311676025
Batch 54/64 loss: 0.33779633045196533
Batch 55/64 loss: 0.34292882680892944
Batch 56/64 loss: 0.33625495433807373
Batch 57/64 loss: 0.3400750756263733
Batch 58/64 loss: 0.33740025758743286
Batch 59/64 loss: 0.3401147723197937
Batch 60/64 loss: 0.3434986472129822
Batch 61/64 loss: 0.33639609813690186
Batch 62/64 loss: 0.3341480493545532
Batch 63/64 loss: 0.3336045742034912
Batch 64/64 loss: 0.33748990297317505
Epoch 169  Train loss: 0.33954848939297244  Val loss: 0.3468212184217787
Saving best model, epoch: 169
Epoch 170
-------------------------------
Batch 1/64 loss: 0.3394371271133423
Batch 2/64 loss: 0.339857816696167
Batch 3/64 loss: 0.34225893020629883
Batch 4/64 loss: 0.3352627754211426
Batch 5/64 loss: 0.34356755018234253
Batch 6/64 loss: 0.33876222372055054
Batch 7/64 loss: 0.33876800537109375
Batch 8/64 loss: 0.3442521095275879
Batch 9/64 loss: 0.3413870334625244
Batch 10/64 loss: 0.3353205919265747
Batch 11/64 loss: 0.3405790328979492
Batch 12/64 loss: 0.34131860733032227
Batch 13/64 loss: 0.34314846992492676
Batch 14/64 loss: 0.34242933988571167
Batch 15/64 loss: 0.34123218059539795
Batch 16/64 loss: 0.33487677574157715
Batch 17/64 loss: 0.33675718307495117
Batch 18/64 loss: 0.33860570192337036
Batch 19/64 loss: 0.33389711380004883
Batch 20/64 loss: 0.33043569326400757
Batch 21/64 loss: 0.33808982372283936
Batch 22/64 loss: 0.3274019956588745
Batch 23/64 loss: 0.3387981653213501
Batch 24/64 loss: 0.3426527976989746
Batch 25/64 loss: 0.3479599952697754
Batch 26/64 loss: 0.32880377769470215
Batch 27/64 loss: 0.3347841501235962
Batch 28/64 loss: 0.3408229947090149
Batch 29/64 loss: 0.34053683280944824
Batch 30/64 loss: 0.3338264226913452
Batch 31/64 loss: 0.3469047546386719
Batch 32/64 loss: 0.3428935408592224
Batch 33/64 loss: 0.33847576379776
Batch 34/64 loss: 0.33653461933135986
Batch 35/64 loss: 0.3375987410545349
Batch 36/64 loss: 0.34057438373565674
Batch 37/64 loss: 0.340495228767395
Batch 38/64 loss: 0.33885645866394043
Batch 39/64 loss: 0.33587563037872314
Batch 40/64 loss: 0.33343392610549927
Batch 41/64 loss: 0.33609098196029663
Batch 42/64 loss: 0.33404839038848877
Batch 43/64 loss: 0.3309732675552368
Batch 44/64 loss: 0.3438427448272705
Batch 45/64 loss: 0.3383694291114807
Batch 46/64 loss: 0.34060800075531006
Batch 47/64 loss: 0.339805006980896
Batch 48/64 loss: 0.34050530195236206
Batch 49/64 loss: 0.34556472301483154
Batch 50/64 loss: 0.34024298191070557
Batch 51/64 loss: 0.3404080867767334
Batch 52/64 loss: 0.332075834274292
Batch 53/64 loss: 0.34151411056518555
Batch 54/64 loss: 0.3346364498138428
Batch 55/64 loss: 0.341400146484375
Batch 56/64 loss: 0.33722686767578125
Batch 57/64 loss: 0.3423457145690918
Batch 58/64 loss: 0.3481013774871826
Batch 59/64 loss: 0.33300042152404785
Batch 60/64 loss: 0.3382332921028137
Batch 61/64 loss: 0.33582115173339844
Batch 62/64 loss: 0.34198498725891113
Batch 63/64 loss: 0.3419896364212036
Batch 64/64 loss: 0.3493824005126953
Epoch 170  Train loss: 0.3389537250294405  Val loss: 0.3464978161136719
Saving best model, epoch: 170
Epoch 171
-------------------------------
Batch 1/64 loss: 0.33014100790023804
Batch 2/64 loss: 0.333962082862854
Batch 3/64 loss: 0.3335239887237549
Batch 4/64 loss: 0.33944666385650635
Batch 5/64 loss: 0.3397878408432007
Batch 6/64 loss: 0.33359086513519287
Batch 7/64 loss: 0.3346555829048157
Batch 8/64 loss: 0.3425785303115845
Batch 9/64 loss: 0.34660804271698
Batch 10/64 loss: 0.33567482233047485
Batch 11/64 loss: 0.3391174077987671
Batch 12/64 loss: 0.33734560012817383
Batch 13/64 loss: 0.33954888582229614
Batch 14/64 loss: 0.33714717626571655
Batch 15/64 loss: 0.33475369215011597
Batch 16/64 loss: 0.3458998203277588
Batch 17/64 loss: 0.3370112180709839
Batch 18/64 loss: 0.33890825510025024
Batch 19/64 loss: 0.33969300985336304
Batch 20/64 loss: 0.3343287706375122
Batch 21/64 loss: 0.3394017219543457
Batch 22/64 loss: 0.33840060234069824
Batch 23/64 loss: 0.33543992042541504
Batch 24/64 loss: 0.33718109130859375
Batch 25/64 loss: 0.34273219108581543
Batch 26/64 loss: 0.3383227586746216
Batch 27/64 loss: 0.3397873640060425
Batch 28/64 loss: 0.34243929386138916
Batch 29/64 loss: 0.33600151538848877
Batch 30/64 loss: 0.33430129289627075
Batch 31/64 loss: 0.3450031280517578
Batch 32/64 loss: 0.3416314721107483
Batch 33/64 loss: 0.33902406692504883
Batch 34/64 loss: 0.3384278416633606
Batch 35/64 loss: 0.34489762783050537
Batch 36/64 loss: 0.33832699060440063
Batch 37/64 loss: 0.3352947235107422
Batch 38/64 loss: 0.33019912242889404
Batch 39/64 loss: 0.34450072050094604
Batch 40/64 loss: 0.33824825286865234
Batch 41/64 loss: 0.3433154821395874
Batch 42/64 loss: 0.3386753797531128
Batch 43/64 loss: 0.3388652205467224
Batch 44/64 loss: 0.3368910551071167
Batch 45/64 loss: 0.3438017964363098
Batch 46/64 loss: 0.34171104431152344
Batch 47/64 loss: 0.3383815884590149
Batch 48/64 loss: 0.3433852791786194
Batch 49/64 loss: 0.3427349925041199
Batch 50/64 loss: 0.3431657552719116
Batch 51/64 loss: 0.3386085033416748
Batch 52/64 loss: 0.33034276962280273
Batch 53/64 loss: 0.339455246925354
Batch 54/64 loss: 0.3440359830856323
Batch 55/64 loss: 0.3384529948234558
Batch 56/64 loss: 0.335408091545105
Batch 57/64 loss: 0.33549976348876953
Batch 58/64 loss: 0.3375508785247803
Batch 59/64 loss: 0.33761370182037354
Batch 60/64 loss: 0.3480006456375122
Batch 61/64 loss: 0.33965104818344116
Batch 62/64 loss: 0.3415415287017822
Batch 63/64 loss: 0.3308401107788086
Batch 64/64 loss: 0.347663938999176
Epoch 171  Train loss: 0.3388543023782618  Val loss: 0.34682738985802297
Epoch 172
-------------------------------
Batch 1/64 loss: 0.33616966009140015
Batch 2/64 loss: 0.33569425344467163
Batch 3/64 loss: 0.33052384853363037
Batch 4/64 loss: 0.3377034664154053
Batch 5/64 loss: 0.3395113945007324
Batch 6/64 loss: 0.3360931873321533
Batch 7/64 loss: 0.3440992832183838
Batch 8/64 loss: 0.340262770652771
Batch 9/64 loss: 0.3468881845474243
Batch 10/64 loss: 0.3351535201072693
Batch 11/64 loss: 0.34433603286743164
Batch 12/64 loss: 0.3410017490386963
Batch 13/64 loss: 0.33556413650512695
Batch 14/64 loss: 0.34533751010894775
Batch 15/64 loss: 0.3416275978088379
Batch 16/64 loss: 0.3428804278373718
Batch 17/64 loss: 0.3316318988800049
Batch 18/64 loss: 0.34051352739334106
Batch 19/64 loss: 0.34251832962036133
Batch 20/64 loss: 0.3395962119102478
Batch 21/64 loss: 0.3366837501525879
Batch 22/64 loss: 0.3458198308944702
Batch 23/64 loss: 0.34316694736480713
Batch 24/64 loss: 0.3366520404815674
Batch 25/64 loss: 0.3318732976913452
Batch 26/64 loss: 0.34301698207855225
Batch 27/64 loss: 0.33524632453918457
Batch 28/64 loss: 0.3415858745574951
Batch 29/64 loss: 0.3434346914291382
Batch 30/64 loss: 0.3410165309906006
Batch 31/64 loss: 0.3441201448440552
Batch 32/64 loss: 0.3458598256111145
Batch 33/64 loss: 0.33994412422180176
Batch 34/64 loss: 0.3371514081954956
Batch 35/64 loss: 0.3428889513015747
Batch 36/64 loss: 0.33612120151519775
Batch 37/64 loss: 0.32938718795776367
Batch 38/64 loss: 0.3415917158126831
Batch 39/64 loss: 0.33803999423980713
Batch 40/64 loss: 0.33792203664779663
Batch 41/64 loss: 0.336899995803833
Batch 42/64 loss: 0.3394680619239807
Batch 43/64 loss: 0.34053653478622437
Batch 44/64 loss: 0.34591352939605713
Batch 45/64 loss: 0.3374408483505249
Batch 46/64 loss: 0.33100461959838867
Batch 47/64 loss: 0.336762011051178
Batch 48/64 loss: 0.3417869806289673
Batch 49/64 loss: 0.3404674530029297
Batch 50/64 loss: 0.33674538135528564
Batch 51/64 loss: 0.3323618769645691
Batch 52/64 loss: 0.34289032220840454
Batch 53/64 loss: 0.34092622995376587
Batch 54/64 loss: 0.3469064235687256
Batch 55/64 loss: 0.3456505537033081
Batch 56/64 loss: 0.34340202808380127
Batch 57/64 loss: 0.3451279401779175
Batch 58/64 loss: 0.33762311935424805
Batch 59/64 loss: 0.3337004780769348
Batch 60/64 loss: 0.33475440740585327
Batch 61/64 loss: 0.33809852600097656
Batch 62/64 loss: 0.3326833248138428
Batch 63/64 loss: 0.3373373746871948
Batch 64/64 loss: 0.3427107334136963
Epoch 172  Train loss: 0.3393592301537009  Val loss: 0.34800116917521684
Epoch 173
-------------------------------
Batch 1/64 loss: 0.3333843946456909
Batch 2/64 loss: 0.3397167921066284
Batch 3/64 loss: 0.3416913151741028
Batch 4/64 loss: 0.34236669540405273
Batch 5/64 loss: 0.3362433910369873
Batch 6/64 loss: 0.3350752592086792
Batch 7/64 loss: 0.3455014228820801
Batch 8/64 loss: 0.3387754559516907
Batch 9/64 loss: 0.33656054735183716
Batch 10/64 loss: 0.3336620330810547
Batch 11/64 loss: 0.3410041332244873
Batch 12/64 loss: 0.3353263735771179
Batch 13/64 loss: 0.33248281478881836
Batch 14/64 loss: 0.34625446796417236
Batch 15/64 loss: 0.341424822807312
Batch 16/64 loss: 0.3361184597015381
Batch 17/64 loss: 0.3368113040924072
Batch 18/64 loss: 0.3454959988594055
Batch 19/64 loss: 0.33584511280059814
Batch 20/64 loss: 0.3380551338195801
Batch 21/64 loss: 0.332938551902771
Batch 22/64 loss: 0.34035634994506836
Batch 23/64 loss: 0.33671391010284424
Batch 24/64 loss: 0.3376045227050781
Batch 25/64 loss: 0.33721256256103516
Batch 26/64 loss: 0.3450005054473877
Batch 27/64 loss: 0.34974372386932373
Batch 28/64 loss: 0.33464837074279785
Batch 29/64 loss: 0.33853816986083984
Batch 30/64 loss: 0.3393425941467285
Batch 31/64 loss: 0.34096992015838623
Batch 32/64 loss: 0.34099578857421875
Batch 33/64 loss: 0.33838337659835815
Batch 34/64 loss: 0.3308037519454956
Batch 35/64 loss: 0.3345845937728882
Batch 36/64 loss: 0.33667606115341187
Batch 37/64 loss: 0.33907246589660645
Batch 38/64 loss: 0.33823031187057495
Batch 39/64 loss: 0.3386509418487549
Batch 40/64 loss: 0.34442138671875
Batch 41/64 loss: 0.3431764841079712
Batch 42/64 loss: 0.33990103006362915
Batch 43/64 loss: 0.33648693561553955
Batch 44/64 loss: 0.3426990509033203
Batch 45/64 loss: 0.3374300003051758
Batch 46/64 loss: 0.3406468629837036
Batch 47/64 loss: 0.3332242965698242
Batch 48/64 loss: 0.338009774684906
Batch 49/64 loss: 0.33640944957733154
Batch 50/64 loss: 0.3368034362792969
Batch 51/64 loss: 0.3395802974700928
Batch 52/64 loss: 0.3366142511367798
Batch 53/64 loss: 0.3322620391845703
Batch 54/64 loss: 0.33826780319213867
Batch 55/64 loss: 0.34567904472351074
Batch 56/64 loss: 0.33570361137390137
Batch 57/64 loss: 0.3361016511917114
Batch 58/64 loss: 0.3431391716003418
Batch 59/64 loss: 0.3361188769340515
Batch 60/64 loss: 0.3443986177444458
Batch 61/64 loss: 0.33895885944366455
Batch 62/64 loss: 0.341877818107605
Batch 63/64 loss: 0.3394932150840759
Batch 64/64 loss: 0.33796608448028564
Epoch 173  Train loss: 0.3387159361558802  Val loss: 0.34636131512750057
Saving best model, epoch: 173
Epoch 174
-------------------------------
Batch 1/64 loss: 0.3415888547897339
Batch 2/64 loss: 0.33562207221984863
Batch 3/64 loss: 0.33869779109954834
Batch 4/64 loss: 0.33812737464904785
Batch 5/64 loss: 0.3393567204475403
Batch 6/64 loss: 0.3369913697242737
Batch 7/64 loss: 0.33873188495635986
Batch 8/64 loss: 0.3437609076499939
Batch 9/64 loss: 0.33445215225219727
Batch 10/64 loss: 0.3446599245071411
Batch 11/64 loss: 0.33004581928253174
Batch 12/64 loss: 0.3380289077758789
Batch 13/64 loss: 0.3364560008049011
Batch 14/64 loss: 0.3331650495529175
Batch 15/64 loss: 0.340317964553833
Batch 16/64 loss: 0.3352818489074707
Batch 17/64 loss: 0.3320891857147217
Batch 18/64 loss: 0.33820605278015137
Batch 19/64 loss: 0.3359888792037964
Batch 20/64 loss: 0.3348596692085266
Batch 21/64 loss: 0.3394521474838257
Batch 22/64 loss: 0.33402514457702637
Batch 23/64 loss: 0.33779144287109375
Batch 24/64 loss: 0.3372330069541931
Batch 25/64 loss: 0.33857691287994385
Batch 26/64 loss: 0.3424454927444458
Batch 27/64 loss: 0.3429113030433655
Batch 28/64 loss: 0.33889997005462646
Batch 29/64 loss: 0.3428339958190918
Batch 30/64 loss: 0.3436827063560486
Batch 31/64 loss: 0.3357921838760376
Batch 32/64 loss: 0.33391404151916504
Batch 33/64 loss: 0.34048038721084595
Batch 34/64 loss: 0.339016318321228
Batch 35/64 loss: 0.3347620964050293
Batch 36/64 loss: 0.3395393490791321
Batch 37/64 loss: 0.33877867460250854
Batch 38/64 loss: 0.3404008150100708
Batch 39/64 loss: 0.3396255373954773
Batch 40/64 loss: 0.34286731481552124
Batch 41/64 loss: 0.3368765115737915
Batch 42/64 loss: 0.3430006504058838
Batch 43/64 loss: 0.3364158868789673
Batch 44/64 loss: 0.34174466133117676
Batch 45/64 loss: 0.3415767550468445
Batch 46/64 loss: 0.34332501888275146
Batch 47/64 loss: 0.34315794706344604
Batch 48/64 loss: 0.3368217349052429
Batch 49/64 loss: 0.3358007073402405
Batch 50/64 loss: 0.3354429602622986
Batch 51/64 loss: 0.3420587182044983
Batch 52/64 loss: 0.3374596834182739
Batch 53/64 loss: 0.336944580078125
Batch 54/64 loss: 0.33243119716644287
Batch 55/64 loss: 0.34045058488845825
Batch 56/64 loss: 0.33978271484375
Batch 57/64 loss: 0.34045159816741943
Batch 58/64 loss: 0.34103530645370483
Batch 59/64 loss: 0.34321707487106323
Batch 60/64 loss: 0.3441500663757324
Batch 61/64 loss: 0.33389270305633545
Batch 62/64 loss: 0.3325676918029785
Batch 63/64 loss: 0.3345486521720886
Batch 64/64 loss: 0.34533584117889404
Epoch 174  Train loss: 0.33853509893604355  Val loss: 0.3463521976651195
Saving best model, epoch: 174
Epoch 175
-------------------------------
Batch 1/64 loss: 0.33118224143981934
Batch 2/64 loss: 0.33765876293182373
Batch 3/64 loss: 0.34667181968688965
Batch 4/64 loss: 0.3330104947090149
Batch 5/64 loss: 0.33502721786499023
Batch 6/64 loss: 0.33013916015625
Batch 7/64 loss: 0.344649076461792
Batch 8/64 loss: 0.342338502407074
Batch 9/64 loss: 0.33663660287857056
Batch 10/64 loss: 0.34485721588134766
Batch 11/64 loss: 0.3345149755477905
Batch 12/64 loss: 0.3404695391654968
Batch 13/64 loss: 0.33871209621429443
Batch 14/64 loss: 0.34343934059143066
Batch 15/64 loss: 0.34028732776641846
Batch 16/64 loss: 0.3430798649787903
Batch 17/64 loss: 0.34417688846588135
Batch 18/64 loss: 0.3406361937522888
Batch 19/64 loss: 0.3331127166748047
Batch 20/64 loss: 0.3317630887031555
Batch 21/64 loss: 0.3356212377548218
Batch 22/64 loss: 0.3405991792678833
Batch 23/64 loss: 0.33576977252960205
Batch 24/64 loss: 0.33809494972229004
Batch 25/64 loss: 0.3350638747215271
Batch 26/64 loss: 0.3432401418685913
Batch 27/64 loss: 0.3322519063949585
Batch 28/64 loss: 0.33988893032073975
Batch 29/64 loss: 0.33331531286239624
Batch 30/64 loss: 0.3388451337814331
Batch 31/64 loss: 0.33554887771606445
Batch 32/64 loss: 0.330718994140625
Batch 33/64 loss: 0.3418790102005005
Batch 34/64 loss: 0.3384993076324463
Batch 35/64 loss: 0.34069812297821045
Batch 36/64 loss: 0.3389941453933716
Batch 37/64 loss: 0.3360203504562378
Batch 38/64 loss: 0.3367987871170044
Batch 39/64 loss: 0.33863455057144165
Batch 40/64 loss: 0.3346421718597412
Batch 41/64 loss: 0.34859931468963623
Batch 42/64 loss: 0.34500646591186523
Batch 43/64 loss: 0.3456815481185913
Batch 44/64 loss: 0.3343525528907776
Batch 45/64 loss: 0.3387134075164795
Batch 46/64 loss: 0.3267412781715393
Batch 47/64 loss: 0.34022045135498047
Batch 48/64 loss: 0.3389548063278198
Batch 49/64 loss: 0.33646368980407715
Batch 50/64 loss: 0.3365901708602905
Batch 51/64 loss: 0.3368547558784485
Batch 52/64 loss: 0.33493733406066895
Batch 53/64 loss: 0.34457963705062866
Batch 54/64 loss: 0.3368978500366211
Batch 55/64 loss: 0.33965373039245605
Batch 56/64 loss: 0.33598124980926514
Batch 57/64 loss: 0.3373551368713379
Batch 58/64 loss: 0.33503246307373047
Batch 59/64 loss: 0.33840394020080566
Batch 60/64 loss: 0.34809863567352295
Batch 61/64 loss: 0.3323483467102051
Batch 62/64 loss: 0.34816795587539673
Batch 63/64 loss: 0.340678870677948
Batch 64/64 loss: 0.3341590166091919
Epoch 175  Train loss: 0.33832816843893015  Val loss: 0.34672789454869796
Epoch 176
-------------------------------
Batch 1/64 loss: 0.33895599842071533
Batch 2/64 loss: 0.33557331562042236
Batch 3/64 loss: 0.33962464332580566
Batch 4/64 loss: 0.3297159671783447
Batch 5/64 loss: 0.33884096145629883
Batch 6/64 loss: 0.3359339237213135
Batch 7/64 loss: 0.3399665355682373
Batch 8/64 loss: 0.344213604927063
Batch 9/64 loss: 0.33329153060913086
Batch 10/64 loss: 0.3367694020271301
Batch 11/64 loss: 0.3337283134460449
Batch 12/64 loss: 0.3427507281303406
Batch 13/64 loss: 0.3309997320175171
Batch 14/64 loss: 0.3407433032989502
Batch 15/64 loss: 0.3327680826187134
Batch 16/64 loss: 0.3350043296813965
Batch 17/64 loss: 0.3434101343154907
Batch 18/64 loss: 0.3410773277282715
Batch 19/64 loss: 0.3397270441055298
Batch 20/64 loss: 0.3358948826789856
Batch 21/64 loss: 0.34235692024230957
Batch 22/64 loss: 0.34475481510162354
Batch 23/64 loss: 0.3339020013809204
Batch 24/64 loss: 0.3339512348175049
Batch 25/64 loss: 0.3384782671928406
Batch 26/64 loss: 0.338260293006897
Batch 27/64 loss: 0.3352314829826355
Batch 28/64 loss: 0.3397272229194641
Batch 29/64 loss: 0.33768558502197266
Batch 30/64 loss: 0.3361237645149231
Batch 31/64 loss: 0.33626508712768555
Batch 32/64 loss: 0.3422684669494629
Batch 33/64 loss: 0.33196961879730225
Batch 34/64 loss: 0.3360854387283325
Batch 35/64 loss: 0.3360886573791504
Batch 36/64 loss: 0.3363438844680786
Batch 37/64 loss: 0.3339664936065674
Batch 38/64 loss: 0.3409668803215027
Batch 39/64 loss: 0.3356524705886841
Batch 40/64 loss: 0.3415457010269165
Batch 41/64 loss: 0.3314615488052368
Batch 42/64 loss: 0.3386390805244446
Batch 43/64 loss: 0.34284448623657227
Batch 44/64 loss: 0.3355013132095337
Batch 45/64 loss: 0.34562885761260986
Batch 46/64 loss: 0.34174227714538574
Batch 47/64 loss: 0.3367272615432739
Batch 48/64 loss: 0.3339872360229492
Batch 49/64 loss: 0.3426409363746643
Batch 50/64 loss: 0.337557315826416
Batch 51/64 loss: 0.3421865701675415
Batch 52/64 loss: 0.33797192573547363
Batch 53/64 loss: 0.33319878578186035
Batch 54/64 loss: 0.3361653685569763
Batch 55/64 loss: 0.34137314558029175
Batch 56/64 loss: 0.3324081301689148
Batch 57/64 loss: 0.3367725610733032
Batch 58/64 loss: 0.3424607515335083
Batch 59/64 loss: 0.3375883102416992
Batch 60/64 loss: 0.33587443828582764
Batch 61/64 loss: 0.3407987356185913
Batch 62/64 loss: 0.33433908224105835
Batch 63/64 loss: 0.3363252878189087
Batch 64/64 loss: 0.3403557538986206
Epoch 176  Train loss: 0.33772665519340367  Val loss: 0.34628529462617696
Saving best model, epoch: 176
Epoch 177
-------------------------------
Batch 1/64 loss: 0.33745574951171875
Batch 2/64 loss: 0.3356471657752991
Batch 3/64 loss: 0.33476901054382324
Batch 4/64 loss: 0.33922135829925537
Batch 5/64 loss: 0.3438490629196167
Batch 6/64 loss: 0.33451467752456665
Batch 7/64 loss: 0.3440847396850586
Batch 8/64 loss: 0.3306608200073242
Batch 9/64 loss: 0.33922475576400757
Batch 10/64 loss: 0.33714818954467773
Batch 11/64 loss: 0.3402855396270752
Batch 12/64 loss: 0.33821314573287964
Batch 13/64 loss: 0.33942604064941406
Batch 14/64 loss: 0.3310873508453369
Batch 15/64 loss: 0.3394283652305603
Batch 16/64 loss: 0.33905112743377686
Batch 17/64 loss: 0.34191131591796875
Batch 18/64 loss: 0.33747953176498413
Batch 19/64 loss: 0.3388374447822571
Batch 20/64 loss: 0.33135080337524414
Batch 21/64 loss: 0.3366509675979614
Batch 22/64 loss: 0.33392536640167236
Batch 23/64 loss: 0.3318670392036438
Batch 24/64 loss: 0.3330550789833069
Batch 25/64 loss: 0.3354872465133667
Batch 26/64 loss: 0.32931315898895264
Batch 27/64 loss: 0.3349252939224243
Batch 28/64 loss: 0.33383309841156006
Batch 29/64 loss: 0.33513736724853516
Batch 30/64 loss: 0.33399784564971924
Batch 31/64 loss: 0.3403469920158386
Batch 32/64 loss: 0.339277982711792
Batch 33/64 loss: 0.33508169651031494
Batch 34/64 loss: 0.3379610776901245
Batch 35/64 loss: 0.34001415967941284
Batch 36/64 loss: 0.3405698537826538
Batch 37/64 loss: 0.3407198190689087
Batch 38/64 loss: 0.3347170352935791
Batch 39/64 loss: 0.33589833974838257
Batch 40/64 loss: 0.3470679521560669
Batch 41/64 loss: 0.3406541347503662
Batch 42/64 loss: 0.3456627130508423
Batch 43/64 loss: 0.3316335678100586
Batch 44/64 loss: 0.3353269100189209
Batch 45/64 loss: 0.3307642936706543
Batch 46/64 loss: 0.33400213718414307
Batch 47/64 loss: 0.3393080234527588
Batch 48/64 loss: 0.33822107315063477
Batch 49/64 loss: 0.33075010776519775
Batch 50/64 loss: 0.3390102982521057
Batch 51/64 loss: 0.3425527811050415
Batch 52/64 loss: 0.3430873155593872
Batch 53/64 loss: 0.33911848068237305
Batch 54/64 loss: 0.3425203561782837
Batch 55/64 loss: 0.3373221158981323
Batch 56/64 loss: 0.3424001932144165
Batch 57/64 loss: 0.33587437868118286
Batch 58/64 loss: 0.34177207946777344
Batch 59/64 loss: 0.3407779932022095
Batch 60/64 loss: 0.3410957455635071
Batch 61/64 loss: 0.34635668992996216
Batch 62/64 loss: 0.347247838973999
Batch 63/64 loss: 0.34435659646987915
Batch 64/64 loss: 0.34129858016967773
Epoch 177  Train loss: 0.3380279737360337  Val loss: 0.34698327013717073
Epoch 178
-------------------------------
Batch 1/64 loss: 0.3387030363082886
Batch 2/64 loss: 0.3356984257698059
Batch 3/64 loss: 0.3319227695465088
Batch 4/64 loss: 0.3411734104156494
Batch 5/64 loss: 0.3467148542404175
Batch 6/64 loss: 0.32544779777526855
Batch 7/64 loss: 0.330591082572937
Batch 8/64 loss: 0.33429765701293945
Batch 9/64 loss: 0.3483896255493164
Batch 10/64 loss: 0.3367079496383667
Batch 11/64 loss: 0.34386909008026123
Batch 12/64 loss: 0.33784425258636475
Batch 13/64 loss: 0.3376753330230713
Batch 14/64 loss: 0.3328596353530884
Batch 15/64 loss: 0.3355634808540344
Batch 16/64 loss: 0.33815711736679077
Batch 17/64 loss: 0.3395191431045532
Batch 18/64 loss: 0.33088576793670654
Batch 19/64 loss: 0.3490641713142395
Batch 20/64 loss: 0.3327895998954773
Batch 21/64 loss: 0.3396543264389038
Batch 22/64 loss: 0.3333635926246643
Batch 23/64 loss: 0.3393552303314209
Batch 24/64 loss: 0.3395513892173767
Batch 25/64 loss: 0.340496301651001
Batch 26/64 loss: 0.3396456241607666
Batch 27/64 loss: 0.3361588716506958
Batch 28/64 loss: 0.3386622667312622
Batch 29/64 loss: 0.33623433113098145
Batch 30/64 loss: 0.3357330560684204
Batch 31/64 loss: 0.346577525138855
Batch 32/64 loss: 0.33436036109924316
Batch 33/64 loss: 0.335060715675354
Batch 34/64 loss: 0.33994221687316895
Batch 35/64 loss: 0.3429090976715088
Batch 36/64 loss: 0.34341907501220703
Batch 37/64 loss: 0.3347475528717041
Batch 38/64 loss: 0.3380419611930847
Batch 39/64 loss: 0.33894169330596924
Batch 40/64 loss: 0.3370853662490845
Batch 41/64 loss: 0.34428805112838745
Batch 42/64 loss: 0.3367653489112854
Batch 43/64 loss: 0.3375430107116699
Batch 44/64 loss: 0.33313703536987305
Batch 45/64 loss: 0.3398752808570862
Batch 46/64 loss: 0.34062033891677856
Batch 47/64 loss: 0.3375113010406494
Batch 48/64 loss: 0.333390474319458
Batch 49/64 loss: 0.3283189535140991
Batch 50/64 loss: 0.3342169523239136
Batch 51/64 loss: 0.33534395694732666
Batch 52/64 loss: 0.33505284786224365
Batch 53/64 loss: 0.3383789658546448
Batch 54/64 loss: 0.3376591205596924
Batch 55/64 loss: 0.3432532548904419
Batch 56/64 loss: 0.34266984462738037
Batch 57/64 loss: 0.34040164947509766
Batch 58/64 loss: 0.34148019552230835
Batch 59/64 loss: 0.3447933793067932
Batch 60/64 loss: 0.33150923252105713
Batch 61/64 loss: 0.3420323133468628
Batch 62/64 loss: 0.3383760452270508
Batch 63/64 loss: 0.3397897481918335
Batch 64/64 loss: 0.3378247618675232
Epoch 178  Train loss: 0.3380014216198641  Val loss: 0.346673831702098
Epoch 179
-------------------------------
Batch 1/64 loss: 0.3354841470718384
Batch 2/64 loss: 0.34025490283966064
Batch 3/64 loss: 0.3399624824523926
Batch 4/64 loss: 0.3356444239616394
Batch 5/64 loss: 0.3308131694793701
Batch 6/64 loss: 0.33423179388046265
Batch 7/64 loss: 0.33425307273864746
Batch 8/64 loss: 0.33598875999450684
Batch 9/64 loss: 0.3323991298675537
Batch 10/64 loss: 0.3316357135772705
Batch 11/64 loss: 0.33230602741241455
Batch 12/64 loss: 0.33579230308532715
Batch 13/64 loss: 0.3350123167037964
Batch 14/64 loss: 0.3304558992385864
Batch 15/64 loss: 0.34054887294769287
Batch 16/64 loss: 0.3403967618942261
Batch 17/64 loss: 0.33389461040496826
Batch 18/64 loss: 0.34207582473754883
Batch 19/64 loss: 0.33965200185775757
Batch 20/64 loss: 0.3299598693847656
Batch 21/64 loss: 0.3362555503845215
Batch 22/64 loss: 0.33346641063690186
Batch 23/64 loss: 0.3395344018936157
Batch 24/64 loss: 0.3361431360244751
Batch 25/64 loss: 0.33926212787628174
Batch 26/64 loss: 0.3468666672706604
Batch 27/64 loss: 0.34021782875061035
Batch 28/64 loss: 0.32892143726348877
Batch 29/64 loss: 0.3446124196052551
Batch 30/64 loss: 0.3329538106918335
Batch 31/64 loss: 0.3372032642364502
Batch 32/64 loss: 0.3388622999191284
Batch 33/64 loss: 0.3380119800567627
Batch 34/64 loss: 0.3360831141471863
Batch 35/64 loss: 0.334682822227478
Batch 36/64 loss: 0.3354589343070984
Batch 37/64 loss: 0.330257773399353
Batch 38/64 loss: 0.3406546115875244
Batch 39/64 loss: 0.33659350872039795
Batch 40/64 loss: 0.34142863750457764
Batch 41/64 loss: 0.3413149118423462
Batch 42/64 loss: 0.3365274667739868
Batch 43/64 loss: 0.34435248374938965
Batch 44/64 loss: 0.33932197093963623
Batch 45/64 loss: 0.3386427164077759
Batch 46/64 loss: 0.3422442674636841
Batch 47/64 loss: 0.34629154205322266
Batch 48/64 loss: 0.3441038131713867
Batch 49/64 loss: 0.3368558883666992
Batch 50/64 loss: 0.33873987197875977
Batch 51/64 loss: 0.3352988362312317
Batch 52/64 loss: 0.3397519588470459
Batch 53/64 loss: 0.3384624123573303
Batch 54/64 loss: 0.33612823486328125
Batch 55/64 loss: 0.3362012505531311
Batch 56/64 loss: 0.3362008333206177
Batch 57/64 loss: 0.3407824635505676
Batch 58/64 loss: 0.33754676580429077
Batch 59/64 loss: 0.3386193513870239
Batch 60/64 loss: 0.32930058240890503
Batch 61/64 loss: 0.33785104751586914
Batch 62/64 loss: 0.33352988958358765
Batch 63/64 loss: 0.33624696731567383
Batch 64/64 loss: 0.3379770517349243
Epoch 179  Train loss: 0.337192645259932  Val loss: 0.3459603171987632
Saving best model, epoch: 179
Epoch 180
-------------------------------
Batch 1/64 loss: 0.3372765779495239
Batch 2/64 loss: 0.3324529528617859
Batch 3/64 loss: 0.33286499977111816
Batch 4/64 loss: 0.3353901505470276
Batch 5/64 loss: 0.3380920886993408
Batch 6/64 loss: 0.34372448921203613
Batch 7/64 loss: 0.3366054892539978
Batch 8/64 loss: 0.33505719900131226
Batch 9/64 loss: 0.34269869327545166
Batch 10/64 loss: 0.33807921409606934
Batch 11/64 loss: 0.3360682725906372
Batch 12/64 loss: 0.34316498041152954
Batch 13/64 loss: 0.3389919400215149
Batch 14/64 loss: 0.3418663740158081
Batch 15/64 loss: 0.33574366569519043
Batch 16/64 loss: 0.33553409576416016
Batch 17/64 loss: 0.339030385017395
Batch 18/64 loss: 0.3467198610305786
Batch 19/64 loss: 0.33259665966033936
Batch 20/64 loss: 0.3389105796813965
Batch 21/64 loss: 0.33838915824890137
Batch 22/64 loss: 0.33693742752075195
Batch 23/64 loss: 0.3396972417831421
Batch 24/64 loss: 0.33458203077316284
Batch 25/64 loss: 0.33262550830841064
Batch 26/64 loss: 0.33101022243499756
Batch 27/64 loss: 0.34264397621154785
Batch 28/64 loss: 0.3402802348136902
Batch 29/64 loss: 0.3334602117538452
Batch 30/64 loss: 0.33092498779296875
Batch 31/64 loss: 0.3359736204147339
Batch 32/64 loss: 0.33759045600891113
Batch 33/64 loss: 0.33762049674987793
Batch 34/64 loss: 0.32904982566833496
Batch 35/64 loss: 0.3423440456390381
Batch 36/64 loss: 0.3405710458755493
Batch 37/64 loss: 0.3455624580383301
Batch 38/64 loss: 0.3370710611343384
Batch 39/64 loss: 0.3363075852394104
Batch 40/64 loss: 0.3347620964050293
Batch 41/64 loss: 0.33897507190704346
Batch 42/64 loss: 0.3356832265853882
Batch 43/64 loss: 0.3378310203552246
Batch 44/64 loss: 0.338015615940094
Batch 45/64 loss: 0.3356732130050659
Batch 46/64 loss: 0.3338894844055176
Batch 47/64 loss: 0.33788102865219116
Batch 48/64 loss: 0.3380923271179199
Batch 49/64 loss: 0.33864569664001465
Batch 50/64 loss: 0.3403177857398987
Batch 51/64 loss: 0.32597994804382324
Batch 52/64 loss: 0.3415501117706299
Batch 53/64 loss: 0.3418160080909729
Batch 54/64 loss: 0.3343163728713989
Batch 55/64 loss: 0.33531761169433594
Batch 56/64 loss: 0.3422837257385254
Batch 57/64 loss: 0.33916175365448
Batch 58/64 loss: 0.32813793420791626
Batch 59/64 loss: 0.33944010734558105
Batch 60/64 loss: 0.34235668182373047
Batch 61/64 loss: 0.33547139167785645
Batch 62/64 loss: 0.33778899908065796
Batch 63/64 loss: 0.341671884059906
Batch 64/64 loss: 0.3421902060508728
Epoch 180  Train loss: 0.3374935217932159  Val loss: 0.3460714876446937
Epoch 181
-------------------------------
Batch 1/64 loss: 0.33522969484329224
Batch 2/64 loss: 0.33372652530670166
Batch 3/64 loss: 0.3298296332359314
Batch 4/64 loss: 0.34114766120910645
Batch 5/64 loss: 0.32813358306884766
Batch 6/64 loss: 0.33329635858535767
Batch 7/64 loss: 0.3344913125038147
Batch 8/64 loss: 0.336328387260437
Batch 9/64 loss: 0.33759188652038574
Batch 10/64 loss: 0.32776808738708496
Batch 11/64 loss: 0.3366193175315857
Batch 12/64 loss: 0.3348621129989624
Batch 13/64 loss: 0.333856999874115
Batch 14/64 loss: 0.33620280027389526
Batch 15/64 loss: 0.3363924026489258
Batch 16/64 loss: 0.34136927127838135
Batch 17/64 loss: 0.33942878246307373
Batch 18/64 loss: 0.33652710914611816
Batch 19/64 loss: 0.3343777656555176
Batch 20/64 loss: 0.33376723527908325
Batch 21/64 loss: 0.33840036392211914
Batch 22/64 loss: 0.3404688835144043
Batch 23/64 loss: 0.3348221778869629
Batch 24/64 loss: 0.33702850341796875
Batch 25/64 loss: 0.3397778272628784
Batch 26/64 loss: 0.3395916223526001
Batch 27/64 loss: 0.33350324630737305
Batch 28/64 loss: 0.3412327766418457
Batch 29/64 loss: 0.3421509265899658
Batch 30/64 loss: 0.3373345732688904
Batch 31/64 loss: 0.3334451913833618
Batch 32/64 loss: 0.3412524461746216
Batch 33/64 loss: 0.34594953060150146
Batch 34/64 loss: 0.3420736789703369
Batch 35/64 loss: 0.3321636915206909
Batch 36/64 loss: 0.3375117778778076
Batch 37/64 loss: 0.3388538360595703
Batch 38/64 loss: 0.334896445274353
Batch 39/64 loss: 0.338670015335083
Batch 40/64 loss: 0.33366429805755615
Batch 41/64 loss: 0.3363600969314575
Batch 42/64 loss: 0.34206080436706543
Batch 43/64 loss: 0.3409186601638794
Batch 44/64 loss: 0.3360633850097656
Batch 45/64 loss: 0.3309507966041565
Batch 46/64 loss: 0.34396588802337646
Batch 47/64 loss: 0.33264708518981934
Batch 48/64 loss: 0.3407388925552368
Batch 49/64 loss: 0.33841371536254883
Batch 50/64 loss: 0.33697938919067383
Batch 51/64 loss: 0.3368566036224365
Batch 52/64 loss: 0.336783766746521
Batch 53/64 loss: 0.33559197187423706
Batch 54/64 loss: 0.33971667289733887
Batch 55/64 loss: 0.3383060693740845
Batch 56/64 loss: 0.3345603942871094
Batch 57/64 loss: 0.3369447588920593
Batch 58/64 loss: 0.33455395698547363
Batch 59/64 loss: 0.334841251373291
Batch 60/64 loss: 0.34024184942245483
Batch 61/64 loss: 0.3362691402435303
Batch 62/64 loss: 0.3369148373603821
Batch 63/64 loss: 0.33500736951828003
Batch 64/64 loss: 0.3322707414627075
Epoch 181  Train loss: 0.3367628102209054  Val loss: 0.34563974477990794
Saving best model, epoch: 181
Epoch 182
-------------------------------
Batch 1/64 loss: 0.3293561339378357
Batch 2/64 loss: 0.33046722412109375
Batch 3/64 loss: 0.3389245867729187
Batch 4/64 loss: 0.33887189626693726
Batch 5/64 loss: 0.3358680009841919
Batch 6/64 loss: 0.3329591751098633
Batch 7/64 loss: 0.34033215045928955
Batch 8/64 loss: 0.3429989814758301
Batch 9/64 loss: 0.3417627811431885
Batch 10/64 loss: 0.34036654233932495
Batch 11/64 loss: 0.3309887647628784
Batch 12/64 loss: 0.3353198766708374
Batch 13/64 loss: 0.3357187509536743
Batch 14/64 loss: 0.3414801359176636
Batch 15/64 loss: 0.33121418952941895
Batch 16/64 loss: 0.3346995711326599
Batch 17/64 loss: 0.334377646446228
Batch 18/64 loss: 0.342251181602478
Batch 19/64 loss: 0.34245795011520386
Batch 20/64 loss: 0.3324422240257263
Batch 21/64 loss: 0.3347688913345337
Batch 22/64 loss: 0.3289092779159546
Batch 23/64 loss: 0.326076865196228
Batch 24/64 loss: 0.34369754791259766
Batch 25/64 loss: 0.3372079133987427
Batch 26/64 loss: 0.33425164222717285
Batch 27/64 loss: 0.33845484256744385
Batch 28/64 loss: 0.339067280292511
Batch 29/64 loss: 0.3369864225387573
Batch 30/64 loss: 0.3336569666862488
Batch 31/64 loss: 0.33750611543655396
Batch 32/64 loss: 0.3302423357963562
Batch 33/64 loss: 0.34122830629348755
Batch 34/64 loss: 0.343267560005188
Batch 35/64 loss: 0.3334377408027649
Batch 36/64 loss: 0.3414238691329956
Batch 37/64 loss: 0.335010290145874
Batch 38/64 loss: 0.3329252600669861
Batch 39/64 loss: 0.33520692586898804
Batch 40/64 loss: 0.3371872901916504
Batch 41/64 loss: 0.3355673551559448
Batch 42/64 loss: 0.33704185485839844
Batch 43/64 loss: 0.33997607231140137
Batch 44/64 loss: 0.33818674087524414
Batch 45/64 loss: 0.3343740701675415
Batch 46/64 loss: 0.33642899990081787
Batch 47/64 loss: 0.33968865871429443
Batch 48/64 loss: 0.3343256115913391
Batch 49/64 loss: 0.3366272449493408
Batch 50/64 loss: 0.34084486961364746
Batch 51/64 loss: 0.3356814384460449
Batch 52/64 loss: 0.336542010307312
Batch 53/64 loss: 0.336908221244812
Batch 54/64 loss: 0.3397582769393921
Batch 55/64 loss: 0.33863580226898193
Batch 56/64 loss: 0.33403873443603516
Batch 57/64 loss: 0.33635878562927246
Batch 58/64 loss: 0.34433263540267944
Batch 59/64 loss: 0.341220498085022
Batch 60/64 loss: 0.33603954315185547
Batch 61/64 loss: 0.3354455828666687
Batch 62/64 loss: 0.33145952224731445
Batch 63/64 loss: 0.3383353352546692
Batch 64/64 loss: 0.3344308137893677
Epoch 182  Train loss: 0.3366590130562876  Val loss: 0.3456007012796566
Saving best model, epoch: 182
Epoch 183
-------------------------------
Batch 1/64 loss: 0.3406517505645752
Batch 2/64 loss: 0.33839261531829834
Batch 3/64 loss: 0.3367258310317993
Batch 4/64 loss: 0.33418262004852295
Batch 5/64 loss: 0.33469706773757935
Batch 6/64 loss: 0.3392661213874817
Batch 7/64 loss: 0.33224350214004517
Batch 8/64 loss: 0.33092713356018066
Batch 9/64 loss: 0.34066998958587646
Batch 10/64 loss: 0.33649104833602905
Batch 11/64 loss: 0.33355021476745605
Batch 12/64 loss: 0.33277052640914917
Batch 13/64 loss: 0.3390963673591614
Batch 14/64 loss: 0.33991730213165283
Batch 15/64 loss: 0.3429265022277832
Batch 16/64 loss: 0.33632737398147583
Batch 17/64 loss: 0.34087252616882324
Batch 18/64 loss: 0.3450632095336914
Batch 19/64 loss: 0.3335302472114563
Batch 20/64 loss: 0.3396161198616028
Batch 21/64 loss: 0.33188652992248535
Batch 22/64 loss: 0.3274042010307312
Batch 23/64 loss: 0.3354771137237549
Batch 24/64 loss: 0.3356442451477051
Batch 25/64 loss: 0.338630735874176
Batch 26/64 loss: 0.3401855230331421
Batch 27/64 loss: 0.33538639545440674
Batch 28/64 loss: 0.3383311629295349
Batch 29/64 loss: 0.33622437715530396
Batch 30/64 loss: 0.33689260482788086
Batch 31/64 loss: 0.3323630094528198
Batch 32/64 loss: 0.3347705602645874
Batch 33/64 loss: 0.3383191227912903
Batch 34/64 loss: 0.3345423936843872
Batch 35/64 loss: 0.3378399610519409
Batch 36/64 loss: 0.333315372467041
Batch 37/64 loss: 0.335509717464447
Batch 38/64 loss: 0.3349968194961548
Batch 39/64 loss: 0.33844679594039917
Batch 40/64 loss: 0.32954829931259155
Batch 41/64 loss: 0.3354135751724243
Batch 42/64 loss: 0.34213030338287354
Batch 43/64 loss: 0.3288613557815552
Batch 44/64 loss: 0.33669841289520264
Batch 45/64 loss: 0.33582621812820435
Batch 46/64 loss: 0.3396270275115967
Batch 47/64 loss: 0.3356773257255554
Batch 48/64 loss: 0.3385469913482666
Batch 49/64 loss: 0.3415653705596924
Batch 50/64 loss: 0.33925139904022217
Batch 51/64 loss: 0.3351757526397705
Batch 52/64 loss: 0.3319462537765503
Batch 53/64 loss: 0.33801156282424927
Batch 54/64 loss: 0.3382083773612976
Batch 55/64 loss: 0.33213555812835693
Batch 56/64 loss: 0.3382300138473511
Batch 57/64 loss: 0.3381083607673645
Batch 58/64 loss: 0.33724403381347656
Batch 59/64 loss: 0.33132100105285645
Batch 60/64 loss: 0.34070175886154175
Batch 61/64 loss: 0.3321056365966797
Batch 62/64 loss: 0.3367631435394287
Batch 63/64 loss: 0.34140312671661377
Batch 64/64 loss: 0.33771848678588867
Epoch 183  Train loss: 0.3364999911364387  Val loss: 0.34532722820531053
Saving best model, epoch: 183
Epoch 184
-------------------------------
Batch 1/64 loss: 0.3352452516555786
Batch 2/64 loss: 0.33390045166015625
Batch 3/64 loss: 0.338161826133728
Batch 4/64 loss: 0.3410348892211914
Batch 5/64 loss: 0.3396376371383667
Batch 6/64 loss: 0.33971714973449707
Batch 7/64 loss: 0.34043121337890625
Batch 8/64 loss: 0.3371514081954956
Batch 9/64 loss: 0.34116804599761963
Batch 10/64 loss: 0.33377206325531006
Batch 11/64 loss: 0.3404043912887573
Batch 12/64 loss: 0.33553266525268555
Batch 13/64 loss: 0.3362092971801758
Batch 14/64 loss: 0.33164703845977783
Batch 15/64 loss: 0.33479177951812744
Batch 16/64 loss: 0.33595794439315796
Batch 17/64 loss: 0.3387987017631531
Batch 18/64 loss: 0.34028953313827515
Batch 19/64 loss: 0.3367907404899597
Batch 20/64 loss: 0.3347688913345337
Batch 21/64 loss: 0.33682000637054443
Batch 22/64 loss: 0.3348689079284668
Batch 23/64 loss: 0.33186405897140503
Batch 24/64 loss: 0.34747910499572754
Batch 25/64 loss: 0.3424261808395386
Batch 26/64 loss: 0.3257647156715393
Batch 27/64 loss: 0.337111234664917
Batch 28/64 loss: 0.33598458766937256
Batch 29/64 loss: 0.33315229415893555
Batch 30/64 loss: 0.33760982751846313
Batch 31/64 loss: 0.3379577398300171
Batch 32/64 loss: 0.3404395580291748
Batch 33/64 loss: 0.3319751024246216
Batch 34/64 loss: 0.34082674980163574
Batch 35/64 loss: 0.34430086612701416
Batch 36/64 loss: 0.333893358707428
Batch 37/64 loss: 0.3405745029449463
Batch 38/64 loss: 0.3384653329849243
Batch 39/64 loss: 0.33378708362579346
Batch 40/64 loss: 0.33682286739349365
Batch 41/64 loss: 0.33501899242401123
Batch 42/64 loss: 0.3270764946937561
Batch 43/64 loss: 0.3359033465385437
Batch 44/64 loss: 0.3362630605697632
Batch 45/64 loss: 0.32988083362579346
Batch 46/64 loss: 0.3316667079925537
Batch 47/64 loss: 0.33812063932418823
Batch 48/64 loss: 0.33781611919403076
Batch 49/64 loss: 0.3339487910270691
Batch 50/64 loss: 0.337288498878479
Batch 51/64 loss: 0.337832510471344
Batch 52/64 loss: 0.33684003353118896
Batch 53/64 loss: 0.3380000591278076
Batch 54/64 loss: 0.33372437953948975
Batch 55/64 loss: 0.336894690990448
Batch 56/64 loss: 0.3322957754135132
Batch 57/64 loss: 0.3316490054130554
Batch 58/64 loss: 0.34084367752075195
Batch 59/64 loss: 0.3454681634902954
Batch 60/64 loss: 0.3352653384208679
Batch 61/64 loss: 0.3354841470718384
Batch 62/64 loss: 0.3346176743507385
Batch 63/64 loss: 0.3348211646080017
Batch 64/64 loss: 0.33796268701553345
Epoch 184  Train loss: 0.33659179795022104  Val loss: 0.3454445592316565
Epoch 185
-------------------------------
Batch 1/64 loss: 0.3334031105041504
Batch 2/64 loss: 0.34228968620300293
Batch 3/64 loss: 0.33369481563568115
Batch 4/64 loss: 0.3419995903968811
Batch 5/64 loss: 0.338894248008728
Batch 6/64 loss: 0.33368730545043945
Batch 7/64 loss: 0.33605092763900757
Batch 8/64 loss: 0.3354998826980591
Batch 9/64 loss: 0.3269919157028198
Batch 10/64 loss: 0.3340967893600464
Batch 11/64 loss: 0.33413195610046387
Batch 12/64 loss: 0.3373982310295105
Batch 13/64 loss: 0.3285365700721741
Batch 14/64 loss: 0.3416544198989868
Batch 15/64 loss: 0.33315157890319824
Batch 16/64 loss: 0.3353445529937744
Batch 17/64 loss: 0.337103009223938
Batch 18/64 loss: 0.3371002674102783
Batch 19/64 loss: 0.3336217403411865
Batch 20/64 loss: 0.33708304166793823
Batch 21/64 loss: 0.339388906955719
Batch 22/64 loss: 0.3374263048171997
Batch 23/64 loss: 0.33385372161865234
Batch 24/64 loss: 0.3454436659812927
Batch 25/64 loss: 0.33575892448425293
Batch 26/64 loss: 0.33115315437316895
Batch 27/64 loss: 0.3307785391807556
Batch 28/64 loss: 0.33400100469589233
Batch 29/64 loss: 0.3447904586791992
Batch 30/64 loss: 0.32917630672454834
Batch 31/64 loss: 0.33555692434310913
Batch 32/64 loss: 0.339754581451416
Batch 33/64 loss: 0.33606040477752686
Batch 34/64 loss: 0.33819180727005005
Batch 35/64 loss: 0.3397015333175659
Batch 36/64 loss: 0.3279832601547241
Batch 37/64 loss: 0.3416978716850281
Batch 38/64 loss: 0.3414124846458435
Batch 39/64 loss: 0.3328547477722168
Batch 40/64 loss: 0.3291599750518799
Batch 41/64 loss: 0.3370625972747803
Batch 42/64 loss: 0.3400406837463379
Batch 43/64 loss: 0.3321305513381958
Batch 44/64 loss: 0.3317551016807556
Batch 45/64 loss: 0.33331942558288574
Batch 46/64 loss: 0.32939398288726807
Batch 47/64 loss: 0.3332834839820862
Batch 48/64 loss: 0.32789909839630127
Batch 49/64 loss: 0.34207963943481445
Batch 50/64 loss: 0.3347092866897583
Batch 51/64 loss: 0.33988088369369507
Batch 52/64 loss: 0.3345312476158142
Batch 53/64 loss: 0.33356690406799316
Batch 54/64 loss: 0.33166205883026123
Batch 55/64 loss: 0.3398003578186035
Batch 56/64 loss: 0.3316246271133423
Batch 57/64 loss: 0.3386033773422241
Batch 58/64 loss: 0.33845430612564087
Batch 59/64 loss: 0.3366891145706177
Batch 60/64 loss: 0.33220624923706055
Batch 61/64 loss: 0.3435649871826172
Batch 62/64 loss: 0.34217894077301025
Batch 63/64 loss: 0.33731573820114136
Batch 64/64 loss: 0.34068357944488525
Epoch 185  Train loss: 0.3358924477708106  Val loss: 0.3457157157131077
Epoch 186
-------------------------------
Batch 1/64 loss: 0.33822619915008545
Batch 2/64 loss: 0.33851295709609985
Batch 3/64 loss: 0.3364771008491516
Batch 4/64 loss: 0.3421207666397095
Batch 5/64 loss: 0.3393721580505371
Batch 6/64 loss: 0.33176785707473755
Batch 7/64 loss: 0.3289678692817688
Batch 8/64 loss: 0.33775603771209717
Batch 9/64 loss: 0.34138691425323486
Batch 10/64 loss: 0.33404481410980225
Batch 11/64 loss: 0.32815319299697876
Batch 12/64 loss: 0.3332580327987671
Batch 13/64 loss: 0.33255958557128906
Batch 14/64 loss: 0.33709585666656494
Batch 15/64 loss: 0.3394913077354431
Batch 16/64 loss: 0.3347012400627136
Batch 17/64 loss: 0.33159351348876953
Batch 18/64 loss: 0.3282734751701355
Batch 19/64 loss: 0.3293231725692749
Batch 20/64 loss: 0.3351086974143982
Batch 21/64 loss: 0.3347303867340088
Batch 22/64 loss: 0.34110593795776367
Batch 23/64 loss: 0.33562254905700684
Batch 24/64 loss: 0.33726298809051514
Batch 25/64 loss: 0.33360958099365234
Batch 26/64 loss: 0.3418532609939575
Batch 27/64 loss: 0.34026747941970825
Batch 28/64 loss: 0.33536356687545776
Batch 29/64 loss: 0.33812350034713745
Batch 30/64 loss: 0.3383389711380005
Batch 31/64 loss: 0.3382580280303955
Batch 32/64 loss: 0.33248913288116455
Batch 33/64 loss: 0.3361552357673645
Batch 34/64 loss: 0.3290576934814453
Batch 35/64 loss: 0.33943188190460205
Batch 36/64 loss: 0.33491742610931396
Batch 37/64 loss: 0.3344261050224304
Batch 38/64 loss: 0.3327915668487549
Batch 39/64 loss: 0.3315815329551697
Batch 40/64 loss: 0.33969658613204956
Batch 41/64 loss: 0.3385409712791443
Batch 42/64 loss: 0.33677685260772705
Batch 43/64 loss: 0.3397001028060913
Batch 44/64 loss: 0.3383413553237915
Batch 45/64 loss: 0.33561933040618896
Batch 46/64 loss: 0.33573007583618164
Batch 47/64 loss: 0.33633852005004883
Batch 48/64 loss: 0.340506374835968
Batch 49/64 loss: 0.33860671520233154
Batch 50/64 loss: 0.33329689502716064
Batch 51/64 loss: 0.33960938453674316
Batch 52/64 loss: 0.3348299264907837
Batch 53/64 loss: 0.33160632848739624
Batch 54/64 loss: 0.34076088666915894
Batch 55/64 loss: 0.33117157220840454
Batch 56/64 loss: 0.34414851665496826
Batch 57/64 loss: 0.33583974838256836
Batch 58/64 loss: 0.33875012397766113
Batch 59/64 loss: 0.33933335542678833
Batch 60/64 loss: 0.34219253063201904
Batch 61/64 loss: 0.3346409797668457
Batch 62/64 loss: 0.33476877212524414
Batch 63/64 loss: 0.33699971437454224
Batch 64/64 loss: 0.3381410837173462
Epoch 186  Train loss: 0.33623512165219177  Val loss: 0.3459575860361053
Epoch 187
-------------------------------
Batch 1/64 loss: 0.33575570583343506
Batch 2/64 loss: 0.33662664890289307
Batch 3/64 loss: 0.3347080945968628
Batch 4/64 loss: 0.33537769317626953
Batch 5/64 loss: 0.32950782775878906
Batch 6/64 loss: 0.34054625034332275
Batch 7/64 loss: 0.32920700311660767
Batch 8/64 loss: 0.33335721492767334
Batch 9/64 loss: 0.33743739128112793
Batch 10/64 loss: 0.3344869613647461
Batch 11/64 loss: 0.3266608715057373
Batch 12/64 loss: 0.3391679525375366
Batch 13/64 loss: 0.33588504791259766
Batch 14/64 loss: 0.3378574252128601
Batch 15/64 loss: 0.33323436975479126
Batch 16/64 loss: 0.33419859409332275
Batch 17/64 loss: 0.33011072874069214
Batch 18/64 loss: 0.3371983766555786
Batch 19/64 loss: 0.33332914113998413
Batch 20/64 loss: 0.34132301807403564
Batch 21/64 loss: 0.33026283979415894
Batch 22/64 loss: 0.34020811319351196
Batch 23/64 loss: 0.3343368172645569
Batch 24/64 loss: 0.33640217781066895
Batch 25/64 loss: 0.3388775587081909
Batch 26/64 loss: 0.3333677053451538
Batch 27/64 loss: 0.33730459213256836
Batch 28/64 loss: 0.33660292625427246
Batch 29/64 loss: 0.3419942855834961
Batch 30/64 loss: 0.32862699031829834
Batch 31/64 loss: 0.3364856243133545
Batch 32/64 loss: 0.3328593373298645
Batch 33/64 loss: 0.3338381052017212
Batch 34/64 loss: 0.33625292778015137
Batch 35/64 loss: 0.3427349328994751
Batch 36/64 loss: 0.33904969692230225
Batch 37/64 loss: 0.3375707268714905
Batch 38/64 loss: 0.32875239849090576
Batch 39/64 loss: 0.34277451038360596
Batch 40/64 loss: 0.33362919092178345
Batch 41/64 loss: 0.3342968225479126
Batch 42/64 loss: 0.3359651565551758
Batch 43/64 loss: 0.3356183171272278
Batch 44/64 loss: 0.33138877153396606
Batch 45/64 loss: 0.3421383500099182
Batch 46/64 loss: 0.339134156703949
Batch 47/64 loss: 0.33174896240234375
Batch 48/64 loss: 0.3355003595352173
Batch 49/64 loss: 0.3356918692588806
Batch 50/64 loss: 0.3336559534072876
Batch 51/64 loss: 0.3457942008972168
Batch 52/64 loss: 0.3382861018180847
Batch 53/64 loss: 0.33230865001678467
Batch 54/64 loss: 0.33735573291778564
Batch 55/64 loss: 0.3390979766845703
Batch 56/64 loss: 0.337834894657135
Batch 57/64 loss: 0.33690547943115234
Batch 58/64 loss: 0.34061551094055176
Batch 59/64 loss: 0.3308396339416504
Batch 60/64 loss: 0.3415325880050659
Batch 61/64 loss: 0.3337898254394531
Batch 62/64 loss: 0.3374704122543335
Batch 63/64 loss: 0.33788925409317017
Batch 64/64 loss: 0.3321581482887268
Epoch 187  Train loss: 0.3358727116210788  Val loss: 0.34491279567639854
Saving best model, epoch: 187
Epoch 188
-------------------------------
Batch 1/64 loss: 0.33792024850845337
Batch 2/64 loss: 0.33136653900146484
Batch 3/64 loss: 0.3338884711265564
Batch 4/64 loss: 0.3290637731552124
Batch 5/64 loss: 0.33826446533203125
Batch 6/64 loss: 0.33667755126953125
Batch 7/64 loss: 0.32703059911727905
Batch 8/64 loss: 0.3325193524360657
Batch 9/64 loss: 0.3388209342956543
Batch 10/64 loss: 0.3358628749847412
Batch 11/64 loss: 0.3279569149017334
Batch 12/64 loss: 0.33424198627471924
Batch 13/64 loss: 0.335361123085022
Batch 14/64 loss: 0.3346470594406128
Batch 15/64 loss: 0.3340719938278198
Batch 16/64 loss: 0.3374786376953125
Batch 17/64 loss: 0.33753758668899536
Batch 18/64 loss: 0.3314802646636963
Batch 19/64 loss: 0.33215945959091187
Batch 20/64 loss: 0.33850932121276855
Batch 21/64 loss: 0.33657288551330566
Batch 22/64 loss: 0.3357577323913574
Batch 23/64 loss: 0.3336097002029419
Batch 24/64 loss: 0.3372361660003662
Batch 25/64 loss: 0.3454005718231201
Batch 26/64 loss: 0.3290289640426636
Batch 27/64 loss: 0.3338223695755005
Batch 28/64 loss: 0.33654648065567017
Batch 29/64 loss: 0.3348872661590576
Batch 30/64 loss: 0.3333633542060852
Batch 31/64 loss: 0.33929014205932617
Batch 32/64 loss: 0.3392317295074463
Batch 33/64 loss: 0.3296968936920166
Batch 34/64 loss: 0.33198821544647217
Batch 35/64 loss: 0.3386974334716797
Batch 36/64 loss: 0.3309386968612671
Batch 37/64 loss: 0.3323780298233032
Batch 38/64 loss: 0.333382785320282
Batch 39/64 loss: 0.3316006660461426
Batch 40/64 loss: 0.34076881408691406
Batch 41/64 loss: 0.33593839406967163
Batch 42/64 loss: 0.33538174629211426
Batch 43/64 loss: 0.33618634939193726
Batch 44/64 loss: 0.3364105224609375
Batch 45/64 loss: 0.33199208974838257
Batch 46/64 loss: 0.3449869155883789
Batch 47/64 loss: 0.33832311630249023
Batch 48/64 loss: 0.339321494102478
Batch 49/64 loss: 0.3311934471130371
Batch 50/64 loss: 0.33609265089035034
Batch 51/64 loss: 0.3335002064704895
Batch 52/64 loss: 0.33351969718933105
Batch 53/64 loss: 0.3373450040817261
Batch 54/64 loss: 0.3430931568145752
Batch 55/64 loss: 0.33485889434814453
Batch 56/64 loss: 0.3441653251647949
Batch 57/64 loss: 0.3394300937652588
Batch 58/64 loss: 0.33653926849365234
Batch 59/64 loss: 0.333368182182312
Batch 60/64 loss: 0.3403560519218445
Batch 61/64 loss: 0.34375280141830444
Batch 62/64 loss: 0.3333803415298462
Batch 63/64 loss: 0.3349865674972534
Batch 64/64 loss: 0.3280099034309387
Epoch 188  Train loss: 0.33551667133967084  Val loss: 0.34459847928732124
Saving best model, epoch: 188
Epoch 189
-------------------------------
Batch 1/64 loss: 0.3357704281806946
Batch 2/64 loss: 0.3329295516014099
Batch 3/64 loss: 0.330480694770813
Batch 4/64 loss: 0.3390198349952698
Batch 5/64 loss: 0.33341526985168457
Batch 6/64 loss: 0.33500897884368896
Batch 7/64 loss: 0.33941566944122314
Batch 8/64 loss: 0.34118884801864624
Batch 9/64 loss: 0.33637869358062744
Batch 10/64 loss: 0.3352378010749817
Batch 11/64 loss: 0.3338510990142822
Batch 12/64 loss: 0.3346174955368042
Batch 13/64 loss: 0.330685019493103
Batch 14/64 loss: 0.32814955711364746
Batch 15/64 loss: 0.34227442741394043
Batch 16/64 loss: 0.33758819103240967
Batch 17/64 loss: 0.3286975622177124
Batch 18/64 loss: 0.3348395824432373
Batch 19/64 loss: 0.337604820728302
Batch 20/64 loss: 0.34407055377960205
Batch 21/64 loss: 0.3386986255645752
Batch 22/64 loss: 0.32894957065582275
Batch 23/64 loss: 0.32983875274658203
Batch 24/64 loss: 0.34011149406433105
Batch 25/64 loss: 0.3345698118209839
Batch 26/64 loss: 0.33736610412597656
Batch 27/64 loss: 0.33795154094696045
Batch 28/64 loss: 0.3297826051712036
Batch 29/64 loss: 0.3372068405151367
Batch 30/64 loss: 0.33499717712402344
Batch 31/64 loss: 0.33862900733947754
Batch 32/64 loss: 0.33550989627838135
Batch 33/64 loss: 0.3348248600959778
Batch 34/64 loss: 0.3387775421142578
Batch 35/64 loss: 0.3391769528388977
Batch 36/64 loss: 0.33520400524139404
Batch 37/64 loss: 0.3435179591178894
Batch 38/64 loss: 0.34150904417037964
Batch 39/64 loss: 0.32820212841033936
Batch 40/64 loss: 0.3390083312988281
Batch 41/64 loss: 0.33643728494644165
Batch 42/64 loss: 0.33078086376190186
Batch 43/64 loss: 0.3309541940689087
Batch 44/64 loss: 0.32468438148498535
Batch 45/64 loss: 0.33350682258605957
Batch 46/64 loss: 0.3372459411621094
Batch 47/64 loss: 0.3427448272705078
Batch 48/64 loss: 0.3258970379829407
Batch 49/64 loss: 0.3392377495765686
Batch 50/64 loss: 0.32853251695632935
Batch 51/64 loss: 0.33767980337142944
Batch 52/64 loss: 0.3367760181427002
Batch 53/64 loss: 0.33780360221862793
Batch 54/64 loss: 0.329404354095459
Batch 55/64 loss: 0.3327617645263672
Batch 56/64 loss: 0.334796667098999
Batch 57/64 loss: 0.3386240601539612
Batch 58/64 loss: 0.3376661539077759
Batch 59/64 loss: 0.3317229747772217
Batch 60/64 loss: 0.3346877694129944
Batch 61/64 loss: 0.33594846725463867
Batch 62/64 loss: 0.334883451461792
Batch 63/64 loss: 0.3444482684135437
Batch 64/64 loss: 0.3315415382385254
Epoch 189  Train loss: 0.3353872542287789  Val loss: 0.34533451390020625
Epoch 190
-------------------------------
Batch 1/64 loss: 0.33987849950790405
Batch 2/64 loss: 0.3288079500198364
Batch 3/64 loss: 0.3285568952560425
Batch 4/64 loss: 0.33609408140182495
Batch 5/64 loss: 0.33648598194122314
Batch 6/64 loss: 0.3368416428565979
Batch 7/64 loss: 0.3405224680900574
Batch 8/64 loss: 0.33893048763275146
Batch 9/64 loss: 0.3394710421562195
Batch 10/64 loss: 0.3348417282104492
Batch 11/64 loss: 0.3405047655105591
Batch 12/64 loss: 0.34258246421813965
Batch 13/64 loss: 0.33368515968322754
Batch 14/64 loss: 0.3340907692909241
Batch 15/64 loss: 0.33933496475219727
Batch 16/64 loss: 0.33441269397735596
Batch 17/64 loss: 0.33275699615478516
Batch 18/64 loss: 0.3328700661659241
Batch 19/64 loss: 0.3400079011917114
Batch 20/64 loss: 0.3408049941062927
Batch 21/64 loss: 0.32782411575317383
Batch 22/64 loss: 0.34164589643478394
Batch 23/64 loss: 0.33307981491088867
Batch 24/64 loss: 0.33867061138153076
Batch 25/64 loss: 0.3393465280532837
Batch 26/64 loss: 0.33307981491088867
Batch 27/64 loss: 0.33336639404296875
Batch 28/64 loss: 0.3323192000389099
Batch 29/64 loss: 0.3319054841995239
Batch 30/64 loss: 0.33518731594085693
Batch 31/64 loss: 0.3296750783920288
Batch 32/64 loss: 0.33540838956832886
Batch 33/64 loss: 0.3296318054199219
Batch 34/64 loss: 0.3277791738510132
Batch 35/64 loss: 0.3413494825363159
Batch 36/64 loss: 0.33590078353881836
Batch 37/64 loss: 0.3358132243156433
Batch 38/64 loss: 0.332206130027771
Batch 39/64 loss: 0.33784031867980957
Batch 40/64 loss: 0.33170533180236816
Batch 41/64 loss: 0.3405020236968994
Batch 42/64 loss: 0.33040666580200195
Batch 43/64 loss: 0.3338161110877991
Batch 44/64 loss: 0.32937192916870117
Batch 45/64 loss: 0.33008062839508057
Batch 46/64 loss: 0.33444082736968994
Batch 47/64 loss: 0.34627294540405273
Batch 48/64 loss: 0.33354437351226807
Batch 49/64 loss: 0.3376292586326599
Batch 50/64 loss: 0.33546119928359985
Batch 51/64 loss: 0.3380708694458008
Batch 52/64 loss: 0.3439675569534302
Batch 53/64 loss: 0.3372562527656555
Batch 54/64 loss: 0.33727413415908813
Batch 55/64 loss: 0.33040904998779297
Batch 56/64 loss: 0.3345014452934265
Batch 57/64 loss: 0.3340049982070923
Batch 58/64 loss: 0.33483779430389404
Batch 59/64 loss: 0.33349132537841797
Batch 60/64 loss: 0.33890682458877563
Batch 61/64 loss: 0.3299008011817932
Batch 62/64 loss: 0.33831703662872314
Batch 63/64 loss: 0.3328441381454468
Batch 64/64 loss: 0.3363807797431946
Epoch 190  Train loss: 0.3354166309038798  Val loss: 0.3449721307688972
Epoch 191
-------------------------------
Batch 1/64 loss: 0.33068132400512695
Batch 2/64 loss: 0.3314945697784424
Batch 3/64 loss: 0.33407068252563477
Batch 4/64 loss: 0.33635783195495605
Batch 5/64 loss: 0.33153921365737915
Batch 6/64 loss: 0.33788955211639404
Batch 7/64 loss: 0.3345606327056885
Batch 8/64 loss: 0.3396158218383789
Batch 9/64 loss: 0.33626699447631836
Batch 10/64 loss: 0.3357280492782593
Batch 11/64 loss: 0.3342363238334656
Batch 12/64 loss: 0.33410704135894775
Batch 13/64 loss: 0.33064430952072144
Batch 14/64 loss: 0.32992494106292725
Batch 15/64 loss: 0.3316965699195862
Batch 16/64 loss: 0.33447396755218506
Batch 17/64 loss: 0.3302573561668396
Batch 18/64 loss: 0.3359130024909973
Batch 19/64 loss: 0.3315798044204712
Batch 20/64 loss: 0.3407508134841919
Batch 21/64 loss: 0.34223341941833496
Batch 22/64 loss: 0.3393890857696533
Batch 23/64 loss: 0.33536970615386963
Batch 24/64 loss: 0.3370323181152344
Batch 25/64 loss: 0.3360114097595215
Batch 26/64 loss: 0.33140653371810913
Batch 27/64 loss: 0.3318027853965759
Batch 28/64 loss: 0.32624393701553345
Batch 29/64 loss: 0.3332740068435669
Batch 30/64 loss: 0.3365430235862732
Batch 31/64 loss: 0.3338104486465454
Batch 32/64 loss: 0.3374863862991333
Batch 33/64 loss: 0.3395904302597046
Batch 34/64 loss: 0.3332973122596741
Batch 35/64 loss: 0.3350105881690979
Batch 36/64 loss: 0.33015871047973633
Batch 37/64 loss: 0.33796221017837524
Batch 38/64 loss: 0.32982397079467773
Batch 39/64 loss: 0.33100426197052
Batch 40/64 loss: 0.3398165702819824
Batch 41/64 loss: 0.33543509244918823
Batch 42/64 loss: 0.3332868814468384
Batch 43/64 loss: 0.33508121967315674
Batch 44/64 loss: 0.336409330368042
Batch 45/64 loss: 0.33553099632263184
Batch 46/64 loss: 0.3328629732131958
Batch 47/64 loss: 0.33652687072753906
Batch 48/64 loss: 0.33309614658355713
Batch 49/64 loss: 0.33688884973526
Batch 50/64 loss: 0.3367804288864136
Batch 51/64 loss: 0.3448554277420044
Batch 52/64 loss: 0.32209300994873047
Batch 53/64 loss: 0.33877432346343994
Batch 54/64 loss: 0.32549428939819336
Batch 55/64 loss: 0.33930301666259766
Batch 56/64 loss: 0.33637893199920654
Batch 57/64 loss: 0.3394889831542969
Batch 58/64 loss: 0.33739376068115234
Batch 59/64 loss: 0.327454149723053
Batch 60/64 loss: 0.3347010612487793
Batch 61/64 loss: 0.3338174819946289
Batch 62/64 loss: 0.3289848566055298
Batch 63/64 loss: 0.3404806852340698
Batch 64/64 loss: 0.337560772895813
Epoch 191  Train loss: 0.3346407100266101  Val loss: 0.34471666874344814
Epoch 192
-------------------------------
Batch 1/64 loss: 0.33581066131591797
Batch 2/64 loss: 0.34188175201416016
Batch 3/64 loss: 0.3358317017555237
Batch 4/64 loss: 0.3339484930038452
Batch 5/64 loss: 0.33256375789642334
Batch 6/64 loss: 0.3319125771522522
Batch 7/64 loss: 0.3387870788574219
Batch 8/64 loss: 0.3392789959907532
Batch 9/64 loss: 0.32850730419158936
Batch 10/64 loss: 0.33332300186157227
Batch 11/64 loss: 0.33516228199005127
Batch 12/64 loss: 0.33480238914489746
Batch 13/64 loss: 0.33300846815109253
Batch 14/64 loss: 0.3285837769508362
Batch 15/64 loss: 0.3312537670135498
Batch 16/64 loss: 0.3335438370704651
Batch 17/64 loss: 0.34011948108673096
Batch 18/64 loss: 0.3306705355644226
Batch 19/64 loss: 0.32980990409851074
Batch 20/64 loss: 0.3394013047218323
Batch 21/64 loss: 0.3261629343032837
Batch 22/64 loss: 0.33779245615005493
Batch 23/64 loss: 0.3290826082229614
Batch 24/64 loss: 0.3328697681427002
Batch 25/64 loss: 0.3382704257965088
Batch 26/64 loss: 0.3315145969390869
Batch 27/64 loss: 0.3295419216156006
Batch 28/64 loss: 0.335889995098114
Batch 29/64 loss: 0.3361204266548157
Batch 30/64 loss: 0.32923781871795654
Batch 31/64 loss: 0.339724063873291
Batch 32/64 loss: 0.33442211151123047
Batch 33/64 loss: 0.330220103263855
Batch 34/64 loss: 0.33557432889938354
Batch 35/64 loss: 0.33104658126831055
Batch 36/64 loss: 0.3363437056541443
Batch 37/64 loss: 0.331426739692688
Batch 38/64 loss: 0.3377048373222351
Batch 39/64 loss: 0.33206409215927124
Batch 40/64 loss: 0.3362414240837097
Batch 41/64 loss: 0.3348950147628784
Batch 42/64 loss: 0.34092938899993896
Batch 43/64 loss: 0.334789514541626
Batch 44/64 loss: 0.3381913900375366
Batch 45/64 loss: 0.347780704498291
Batch 46/64 loss: 0.3340679407119751
Batch 47/64 loss: 0.34171855449676514
Batch 48/64 loss: 0.33119380474090576
Batch 49/64 loss: 0.3392624855041504
Batch 50/64 loss: 0.3321395516395569
Batch 51/64 loss: 0.3290567398071289
Batch 52/64 loss: 0.3280985951423645
Batch 53/64 loss: 0.3331161141395569
Batch 54/64 loss: 0.3278818130493164
Batch 55/64 loss: 0.3360772132873535
Batch 56/64 loss: 0.3357079029083252
Batch 57/64 loss: 0.33739662170410156
Batch 58/64 loss: 0.33494633436203003
Batch 59/64 loss: 0.3228328227996826
Batch 60/64 loss: 0.33514493703842163
Batch 61/64 loss: 0.3393667936325073
Batch 62/64 loss: 0.33873701095581055
Batch 63/64 loss: 0.3377547264099121
Batch 64/64 loss: 0.34668946266174316
Epoch 192  Train loss: 0.3345969424528234  Val loss: 0.3452152153061018
Epoch 193
-------------------------------
Batch 1/64 loss: 0.33934998512268066
Batch 2/64 loss: 0.3416321873664856
Batch 3/64 loss: 0.3366771936416626
Batch 4/64 loss: 0.33091461658477783
Batch 5/64 loss: 0.33193856477737427
Batch 6/64 loss: 0.33620935678482056
Batch 7/64 loss: 0.3348645567893982
Batch 8/64 loss: 0.3395090699195862
Batch 9/64 loss: 0.3314923048019409
Batch 10/64 loss: 0.3341400623321533
Batch 11/64 loss: 0.33057308197021484
Batch 12/64 loss: 0.3345520496368408
Batch 13/64 loss: 0.32807457447052
Batch 14/64 loss: 0.33027422428131104
Batch 15/64 loss: 0.3348413109779358
Batch 16/64 loss: 0.3358781933784485
Batch 17/64 loss: 0.3304089307785034
Batch 18/64 loss: 0.3256267309188843
Batch 19/64 loss: 0.3390163779258728
Batch 20/64 loss: 0.33639800548553467
Batch 21/64 loss: 0.34004688262939453
Batch 22/64 loss: 0.3292994499206543
Batch 23/64 loss: 0.33928799629211426
Batch 24/64 loss: 0.33952343463897705
Batch 25/64 loss: 0.3404313325881958
Batch 26/64 loss: 0.3337366580963135
Batch 27/64 loss: 0.3370676040649414
Batch 28/64 loss: 0.3334234952926636
Batch 29/64 loss: 0.33576399087905884
Batch 30/64 loss: 0.33273571729660034
Batch 31/64 loss: 0.3335496187210083
Batch 32/64 loss: 0.32947397232055664
Batch 33/64 loss: 0.3357628583908081
Batch 34/64 loss: 0.3309698700904846
Batch 35/64 loss: 0.3343324065208435
Batch 36/64 loss: 0.3317378759384155
Batch 37/64 loss: 0.33153510093688965
Batch 38/64 loss: 0.33168643712997437
Batch 39/64 loss: 0.33236801624298096
Batch 40/64 loss: 0.33981823921203613
Batch 41/64 loss: 0.3271353244781494
Batch 42/64 loss: 0.3314228057861328
Batch 43/64 loss: 0.33440685272216797
Batch 44/64 loss: 0.33243000507354736
Batch 45/64 loss: 0.3421461582183838
Batch 46/64 loss: 0.3361344337463379
Batch 47/64 loss: 0.33164703845977783
Batch 48/64 loss: 0.33893102407455444
Batch 49/64 loss: 0.33441680669784546
Batch 50/64 loss: 0.33768582344055176
Batch 51/64 loss: 0.33547383546829224
Batch 52/64 loss: 0.32800304889678955
Batch 53/64 loss: 0.3315201997756958
Batch 54/64 loss: 0.33651018142700195
Batch 55/64 loss: 0.3360084295272827
Batch 56/64 loss: 0.3331283926963806
Batch 57/64 loss: 0.33409881591796875
Batch 58/64 loss: 0.3275336027145386
Batch 59/64 loss: 0.33072882890701294
Batch 60/64 loss: 0.33589398860931396
Batch 61/64 loss: 0.3260437846183777
Batch 62/64 loss: 0.33026695251464844
Batch 63/64 loss: 0.3416491746902466
Batch 64/64 loss: 0.34200286865234375
Epoch 193  Train loss: 0.3341904312956567  Val loss: 0.34424735815664337
Saving best model, epoch: 193
Epoch 194
-------------------------------
Batch 1/64 loss: 0.32855725288391113
Batch 2/64 loss: 0.32764166593551636
Batch 3/64 loss: 0.33053386211395264
Batch 4/64 loss: 0.338881254196167
Batch 5/64 loss: 0.33202970027923584
Batch 6/64 loss: 0.33108794689178467
Batch 7/64 loss: 0.3327070474624634
Batch 8/64 loss: 0.3313583731651306
Batch 9/64 loss: 0.3369816541671753
Batch 10/64 loss: 0.33116430044174194
Batch 11/64 loss: 0.33091557025909424
Batch 12/64 loss: 0.32964587211608887
Batch 13/64 loss: 0.3352643847465515
Batch 14/64 loss: 0.3274846076965332
Batch 15/64 loss: 0.3302266597747803
Batch 16/64 loss: 0.32902705669403076
Batch 17/64 loss: 0.33679795265197754
Batch 18/64 loss: 0.33311593532562256
Batch 19/64 loss: 0.3256736993789673
Batch 20/64 loss: 0.3318394422531128
Batch 21/64 loss: 0.33717167377471924
Batch 22/64 loss: 0.33296823501586914
Batch 23/64 loss: 0.3341989517211914
Batch 24/64 loss: 0.33170151710510254
Batch 25/64 loss: 0.3343011736869812
Batch 26/64 loss: 0.3311094045639038
Batch 27/64 loss: 0.3370777368545532
Batch 28/64 loss: 0.33817750215530396
Batch 29/64 loss: 0.3297438621520996
Batch 30/64 loss: 0.34075939655303955
Batch 31/64 loss: 0.3394376039505005
Batch 32/64 loss: 0.3329995274543762
Batch 33/64 loss: 0.33762818574905396
Batch 34/64 loss: 0.3359057307243347
Batch 35/64 loss: 0.33189523220062256
Batch 36/64 loss: 0.3315168619155884
Batch 37/64 loss: 0.3299926519393921
Batch 38/64 loss: 0.3336261510848999
Batch 39/64 loss: 0.3363264799118042
Batch 40/64 loss: 0.33623671531677246
Batch 41/64 loss: 0.33798277378082275
Batch 42/64 loss: 0.3415837287902832
Batch 43/64 loss: 0.3306019902229309
Batch 44/64 loss: 0.3323131203651428
Batch 45/64 loss: 0.33027857542037964
Batch 46/64 loss: 0.33288323879241943
Batch 47/64 loss: 0.33024275302886963
Batch 48/64 loss: 0.3397862911224365
Batch 49/64 loss: 0.3335620164871216
Batch 50/64 loss: 0.3374365568161011
Batch 51/64 loss: 0.33625781536102295
Batch 52/64 loss: 0.32917487621307373
Batch 53/64 loss: 0.333379864692688
Batch 54/64 loss: 0.32390499114990234
Batch 55/64 loss: 0.3430808186531067
Batch 56/64 loss: 0.3385962247848511
Batch 57/64 loss: 0.335573673248291
Batch 58/64 loss: 0.3338000774383545
Batch 59/64 loss: 0.3385477066040039
Batch 60/64 loss: 0.3346039056777954
Batch 61/64 loss: 0.345503568649292
Batch 62/64 loss: 0.32795846462249756
Batch 63/64 loss: 0.33765602111816406
Batch 64/64 loss: 0.34148329496383667
Epoch 194  Train loss: 0.3338749859847274  Val loss: 0.3438589079273525
Saving best model, epoch: 194
Epoch 195
-------------------------------
Batch 1/64 loss: 0.33277904987335205
Batch 2/64 loss: 0.342037558555603
Batch 3/64 loss: 0.33552587032318115
Batch 4/64 loss: 0.3338419198989868
Batch 5/64 loss: 0.3357834815979004
Batch 6/64 loss: 0.3377726674079895
Batch 7/64 loss: 0.3265033960342407
Batch 8/64 loss: 0.34152913093566895
Batch 9/64 loss: 0.33545100688934326
Batch 10/64 loss: 0.32701873779296875
Batch 11/64 loss: 0.3355661630630493
Batch 12/64 loss: 0.341109037399292
Batch 13/64 loss: 0.3381633162498474
Batch 14/64 loss: 0.333881676197052
Batch 15/64 loss: 0.3306460976600647
Batch 16/64 loss: 0.33690857887268066
Batch 17/64 loss: 0.33463889360427856
Batch 18/64 loss: 0.33662867546081543
Batch 19/64 loss: 0.3307931423187256
Batch 20/64 loss: 0.34310662746429443
Batch 21/64 loss: 0.3366541862487793
Batch 22/64 loss: 0.34221935272216797
Batch 23/64 loss: 0.333609938621521
Batch 24/64 loss: 0.3367246389389038
Batch 25/64 loss: 0.3300292491912842
Batch 26/64 loss: 0.34174877405166626
Batch 27/64 loss: 0.33658528327941895
Batch 28/64 loss: 0.3317968249320984
Batch 29/64 loss: 0.33340024948120117
Batch 30/64 loss: 0.3318188190460205
Batch 31/64 loss: 0.3364632725715637
Batch 32/64 loss: 0.33105719089508057
Batch 33/64 loss: 0.33553147315979004
Batch 34/64 loss: 0.33714228868484497
Batch 35/64 loss: 0.33166325092315674
Batch 36/64 loss: 0.33482712507247925
Batch 37/64 loss: 0.32615143060684204
Batch 38/64 loss: 0.33537745475769043
Batch 39/64 loss: 0.33637040853500366
Batch 40/64 loss: 0.32873451709747314
Batch 41/64 loss: 0.3342849016189575
Batch 42/64 loss: 0.333728551864624
Batch 43/64 loss: 0.34095561504364014
Batch 44/64 loss: 0.33574604988098145
Batch 45/64 loss: 0.33704811334609985
Batch 46/64 loss: 0.33129608631134033
Batch 47/64 loss: 0.33691513538360596
Batch 48/64 loss: 0.331512451171875
Batch 49/64 loss: 0.33240365982055664
Batch 50/64 loss: 0.33416616916656494
Batch 51/64 loss: 0.3263337016105652
Batch 52/64 loss: 0.332236111164093
Batch 53/64 loss: 0.3324621915817261
Batch 54/64 loss: 0.33147722482681274
Batch 55/64 loss: 0.33080291748046875
Batch 56/64 loss: 0.3394908905029297
Batch 57/64 loss: 0.3388558626174927
Batch 58/64 loss: 0.33201873302459717
Batch 59/64 loss: 0.3266090154647827
Batch 60/64 loss: 0.3301805257797241
Batch 61/64 loss: 0.3311704397201538
Batch 62/64 loss: 0.33704715967178345
Batch 63/64 loss: 0.32473647594451904
Batch 64/64 loss: 0.32417601346969604
Epoch 195  Train loss: 0.33415216861986646  Val loss: 0.34472975452331334
Epoch 196
-------------------------------
Batch 1/64 loss: 0.3321133852005005
Batch 2/64 loss: 0.33218860626220703
Batch 3/64 loss: 0.3367037773132324
Batch 4/64 loss: 0.33726394176483154
Batch 5/64 loss: 0.333051860332489
Batch 6/64 loss: 0.33168041706085205
Batch 7/64 loss: 0.33452796936035156
Batch 8/64 loss: 0.3311094641685486
Batch 9/64 loss: 0.3372729420661926
Batch 10/64 loss: 0.33357012271881104
Batch 11/64 loss: 0.3351399898529053
Batch 12/64 loss: 0.34086060523986816
Batch 13/64 loss: 0.33921200037002563
Batch 14/64 loss: 0.328235387802124
Batch 15/64 loss: 0.33070915937423706
Batch 16/64 loss: 0.3372986912727356
Batch 17/64 loss: 0.32893794775009155
Batch 18/64 loss: 0.3325239419937134
Batch 19/64 loss: 0.33614885807037354
Batch 20/64 loss: 0.3436538577079773
Batch 21/64 loss: 0.33108294010162354
Batch 22/64 loss: 0.33357304334640503
Batch 23/64 loss: 0.3252052068710327
Batch 24/64 loss: 0.32906782627105713
Batch 25/64 loss: 0.32523828744888306
Batch 26/64 loss: 0.33003944158554077
Batch 27/64 loss: 0.3336212635040283
Batch 28/64 loss: 0.33608484268188477
Batch 29/64 loss: 0.33329057693481445
Batch 30/64 loss: 0.33636248111724854
Batch 31/64 loss: 0.3299978971481323
Batch 32/64 loss: 0.33204782009124756
Batch 33/64 loss: 0.3446052074432373
Batch 34/64 loss: 0.33417850732803345
Batch 35/64 loss: 0.3293492794036865
Batch 36/64 loss: 0.33589911460876465
Batch 37/64 loss: 0.3379969596862793
Batch 38/64 loss: 0.33333301544189453
Batch 39/64 loss: 0.33774131536483765
Batch 40/64 loss: 0.3341984152793884
Batch 41/64 loss: 0.3374488353729248
Batch 42/64 loss: 0.3321493864059448
Batch 43/64 loss: 0.33308684825897217
Batch 44/64 loss: 0.3326185941696167
Batch 45/64 loss: 0.33048760890960693
Batch 46/64 loss: 0.33393239974975586
Batch 47/64 loss: 0.3293551802635193
Batch 48/64 loss: 0.33447015285491943
Batch 49/64 loss: 0.33437061309814453
Batch 50/64 loss: 0.3292304277420044
Batch 51/64 loss: 0.34260261058807373
Batch 52/64 loss: 0.33143043518066406
Batch 53/64 loss: 0.33393585681915283
Batch 54/64 loss: 0.33942556381225586
Batch 55/64 loss: 0.33736610412597656
Batch 56/64 loss: 0.33864307403564453
Batch 57/64 loss: 0.33675944805145264
Batch 58/64 loss: 0.33261245489120483
Batch 59/64 loss: 0.3318074941635132
Batch 60/64 loss: 0.3334728479385376
Batch 61/64 loss: 0.33611488342285156
Batch 62/64 loss: 0.3295854330062866
Batch 63/64 loss: 0.328357994556427
Batch 64/64 loss: 0.3368067741394043
Epoch 196  Train loss: 0.3339135011037191  Val loss: 0.343966231518185
Epoch 197
-------------------------------
Batch 1/64 loss: 0.33322715759277344
Batch 2/64 loss: 0.32788610458374023
Batch 3/64 loss: 0.338952898979187
Batch 4/64 loss: 0.32790958881378174
Batch 5/64 loss: 0.32818853855133057
Batch 6/64 loss: 0.34243136644363403
Batch 7/64 loss: 0.3317641615867615
Batch 8/64 loss: 0.32950127124786377
Batch 9/64 loss: 0.331329882144928
Batch 10/64 loss: 0.3302563428878784
Batch 11/64 loss: 0.3275657296180725
Batch 12/64 loss: 0.33547234535217285
Batch 13/64 loss: 0.32352811098098755
Batch 14/64 loss: 0.3362729549407959
Batch 15/64 loss: 0.3335310220718384
Batch 16/64 loss: 0.3306335210800171
Batch 17/64 loss: 0.3356207609176636
Batch 18/64 loss: 0.3337942361831665
Batch 19/64 loss: 0.3387538194656372
Batch 20/64 loss: 0.3323953151702881
Batch 21/64 loss: 0.34354710578918457
Batch 22/64 loss: 0.33802396059036255
Batch 23/64 loss: 0.33995187282562256
Batch 24/64 loss: 0.3418238162994385
Batch 25/64 loss: 0.3367495536804199
Batch 26/64 loss: 0.3306899070739746
Batch 27/64 loss: 0.34135639667510986
Batch 28/64 loss: 0.33234095573425293
Batch 29/64 loss: 0.33535706996917725
Batch 30/64 loss: 0.33240628242492676
Batch 31/64 loss: 0.3373022675514221
Batch 32/64 loss: 0.3364914655685425
Batch 33/64 loss: 0.3350079655647278
Batch 34/64 loss: 0.3319087028503418
Batch 35/64 loss: 0.32765817642211914
Batch 36/64 loss: 0.32926642894744873
Batch 37/64 loss: 0.33051156997680664
Batch 38/64 loss: 0.32833361625671387
Batch 39/64 loss: 0.3347899913787842
Batch 40/64 loss: 0.33230161666870117
Batch 41/64 loss: 0.3330141305923462
Batch 42/64 loss: 0.3392537832260132
Batch 43/64 loss: 0.3328516483306885
Batch 44/64 loss: 0.33585405349731445
Batch 45/64 loss: 0.33255064487457275
Batch 46/64 loss: 0.3319249153137207
Batch 47/64 loss: 0.33537954092025757
Batch 48/64 loss: 0.32955068349838257
Batch 49/64 loss: 0.33714139461517334
Batch 50/64 loss: 0.33376896381378174
Batch 51/64 loss: 0.32775890827178955
Batch 52/64 loss: 0.3304519057273865
Batch 53/64 loss: 0.32984358072280884
Batch 54/64 loss: 0.3376295566558838
Batch 55/64 loss: 0.33368146419525146
Batch 56/64 loss: 0.340154767036438
Batch 57/64 loss: 0.3418515920639038
Batch 58/64 loss: 0.3343864679336548
Batch 59/64 loss: 0.33461833000183105
Batch 60/64 loss: 0.33332616090774536
Batch 61/64 loss: 0.33052146434783936
Batch 62/64 loss: 0.33641916513442993
Batch 63/64 loss: 0.3264509439468384
Batch 64/64 loss: 0.3317813277244568
Epoch 197  Train loss: 0.3336792770554038  Val loss: 0.34362642523349357
Saving best model, epoch: 197
Epoch 198
-------------------------------
Batch 1/64 loss: 0.33342838287353516
Batch 2/64 loss: 0.33378493785858154
Batch 3/64 loss: 0.33598434925079346
Batch 4/64 loss: 0.3393052816390991
Batch 5/64 loss: 0.33353328704833984
Batch 6/64 loss: 0.33209526538848877
Batch 7/64 loss: 0.3286358118057251
Batch 8/64 loss: 0.3328401446342468
Batch 9/64 loss: 0.3374064564704895
Batch 10/64 loss: 0.33378612995147705
Batch 11/64 loss: 0.3238152265548706
Batch 12/64 loss: 0.33547794818878174
Batch 13/64 loss: 0.3332585096359253
Batch 14/64 loss: 0.33131301403045654
Batch 15/64 loss: 0.3265339136123657
Batch 16/64 loss: 0.3377576470375061
Batch 17/64 loss: 0.3312762975692749
Batch 18/64 loss: 0.32916557788848877
Batch 19/64 loss: 0.3394407033920288
Batch 20/64 loss: 0.3338308334350586
Batch 21/64 loss: 0.33476489782333374
Batch 22/64 loss: 0.33238929510116577
Batch 23/64 loss: 0.3335953950881958
Batch 24/64 loss: 0.3445975184440613
Batch 25/64 loss: 0.3386339545249939
Batch 26/64 loss: 0.3351588249206543
Batch 27/64 loss: 0.33176136016845703
Batch 28/64 loss: 0.32879459857940674
Batch 29/64 loss: 0.32982707023620605
Batch 30/64 loss: 0.3316306471824646
Batch 31/64 loss: 0.336060106754303
Batch 32/64 loss: 0.33087772130966187
Batch 33/64 loss: 0.32930558919906616
Batch 34/64 loss: 0.33148860931396484
Batch 35/64 loss: 0.33226168155670166
Batch 36/64 loss: 0.3274351954460144
Batch 37/64 loss: 0.33563756942749023
Batch 38/64 loss: 0.3370565176010132
Batch 39/64 loss: 0.3304743766784668
Batch 40/64 loss: 0.3345792293548584
Batch 41/64 loss: 0.3303711414337158
Batch 42/64 loss: 0.3388627767562866
Batch 43/64 loss: 0.3329601287841797
Batch 44/64 loss: 0.3353998064994812
Batch 45/64 loss: 0.33094435930252075
Batch 46/64 loss: 0.3304153084754944
Batch 47/64 loss: 0.3258169889450073
Batch 48/64 loss: 0.3303951025009155
Batch 49/64 loss: 0.342476487159729
Batch 50/64 loss: 0.33171266317367554
Batch 51/64 loss: 0.3356884717941284
Batch 52/64 loss: 0.32521045207977295
Batch 53/64 loss: 0.3383316993713379
Batch 54/64 loss: 0.338079035282135
Batch 55/64 loss: 0.3346536159515381
Batch 56/64 loss: 0.3341470956802368
Batch 57/64 loss: 0.3303945064544678
Batch 58/64 loss: 0.3320959210395813
Batch 59/64 loss: 0.3396027684211731
Batch 60/64 loss: 0.3273061513900757
Batch 61/64 loss: 0.3374779224395752
Batch 62/64 loss: 0.32796967029571533
Batch 63/64 loss: 0.32822680473327637
Batch 64/64 loss: 0.3253147006034851
Epoch 198  Train loss: 0.3330435259669435  Val loss: 0.3441476977567902
Epoch 199
-------------------------------
Batch 1/64 loss: 0.3307604193687439
Batch 2/64 loss: 0.33589619398117065
Batch 3/64 loss: 0.3353496789932251
Batch 4/64 loss: 0.3275935649871826
Batch 5/64 loss: 0.32517528533935547
Batch 6/64 loss: 0.3272663354873657
Batch 7/64 loss: 0.32917165756225586
Batch 8/64 loss: 0.3300555348396301
Batch 9/64 loss: 0.3310334086418152
Batch 10/64 loss: 0.33063387870788574
Batch 11/64 loss: 0.3345022201538086
Batch 12/64 loss: 0.3311198949813843
Batch 13/64 loss: 0.33152085542678833
Batch 14/64 loss: 0.33384716510772705
Batch 15/64 loss: 0.3393327593803406
Batch 16/64 loss: 0.330930233001709
Batch 17/64 loss: 0.33743607997894287
Batch 18/64 loss: 0.3353452682495117
Batch 19/64 loss: 0.33459532260894775
Batch 20/64 loss: 0.33519458770751953
Batch 21/64 loss: 0.3297567367553711
Batch 22/64 loss: 0.32785165309906006
Batch 23/64 loss: 0.33561134338378906
Batch 24/64 loss: 0.33483827114105225
Batch 25/64 loss: 0.3281543254852295
Batch 26/64 loss: 0.3302915096282959
Batch 27/64 loss: 0.33451902866363525
Batch 28/64 loss: 0.3245064616203308
Batch 29/64 loss: 0.3318064212799072
Batch 30/64 loss: 0.32889634370803833
Batch 31/64 loss: 0.3293874263763428
Batch 32/64 loss: 0.3436659574508667
Batch 33/64 loss: 0.32853543758392334
Batch 34/64 loss: 0.32958024740219116
Batch 35/64 loss: 0.3329238295555115
Batch 36/64 loss: 0.334000825881958
Batch 37/64 loss: 0.33868342638015747
Batch 38/64 loss: 0.3250596523284912
Batch 39/64 loss: 0.3339938521385193
Batch 40/64 loss: 0.3292587995529175
Batch 41/64 loss: 0.3314502239227295
Batch 42/64 loss: 0.3408659100532532
Batch 43/64 loss: 0.3342641592025757
Batch 44/64 loss: 0.3363165855407715
Batch 45/64 loss: 0.334198534488678
Batch 46/64 loss: 0.3412665128707886
Batch 47/64 loss: 0.33312851190567017
Batch 48/64 loss: 0.33601295948028564
Batch 49/64 loss: 0.3373647928237915
Batch 50/64 loss: 0.3320913314819336
Batch 51/64 loss: 0.3339533805847168
Batch 52/64 loss: 0.33654236793518066
Batch 53/64 loss: 0.3287912607192993
Batch 54/64 loss: 0.32515937089920044
Batch 55/64 loss: 0.33864861726760864
Batch 56/64 loss: 0.3330942988395691
Batch 57/64 loss: 0.3270832300186157
Batch 58/64 loss: 0.3383903503417969
Batch 59/64 loss: 0.33324742317199707
Batch 60/64 loss: 0.33103060722351074
Batch 61/64 loss: 0.3279295563697815
Batch 62/64 loss: 0.33516746759414673
Batch 63/64 loss: 0.34069573879241943
Batch 64/64 loss: 0.3359254002571106
Epoch 199  Train loss: 0.332811280559091  Val loss: 0.34391084385082077
Epoch 200
-------------------------------
Batch 1/64 loss: 0.3325977921485901
Batch 2/64 loss: 0.3367983102798462
Batch 3/64 loss: 0.32774925231933594
Batch 4/64 loss: 0.33689355850219727
Batch 5/64 loss: 0.33513641357421875
Batch 6/64 loss: 0.3386894464492798
Batch 7/64 loss: 0.33387601375579834
Batch 8/64 loss: 0.33250892162323
Batch 9/64 loss: 0.33574265241622925
Batch 10/64 loss: 0.332796573638916
Batch 11/64 loss: 0.3279520273208618
Batch 12/64 loss: 0.33706212043762207
Batch 13/64 loss: 0.3323647975921631
Batch 14/64 loss: 0.33717966079711914
Batch 15/64 loss: 0.330441951751709
Batch 16/64 loss: 0.3291611075401306
Batch 17/64 loss: 0.3232992887496948
Batch 18/64 loss: 0.33145010471343994
Batch 19/64 loss: 0.32361364364624023
Batch 20/64 loss: 0.33735132217407227
Batch 21/64 loss: 0.33123570680618286
Batch 22/64 loss: 0.32604169845581055
Batch 23/64 loss: 0.33146387338638306
Batch 24/64 loss: 0.32915616035461426
Batch 25/64 loss: 0.3305751085281372
Batch 26/64 loss: 0.33234554529190063
Batch 27/64 loss: 0.3327762484550476
Batch 28/64 loss: 0.33534878492355347
Batch 29/64 loss: 0.3366430401802063
Batch 30/64 loss: 0.33383333683013916
Batch 31/64 loss: 0.32710278034210205
Batch 32/64 loss: 0.33422040939331055
Batch 33/64 loss: 0.3382570743560791
Batch 34/64 loss: 0.3369293212890625
Batch 35/64 loss: 0.3281551003456116
Batch 36/64 loss: 0.33012092113494873
Batch 37/64 loss: 0.3391093611717224
Batch 38/64 loss: 0.3377920389175415
Batch 39/64 loss: 0.33750760555267334
Batch 40/64 loss: 0.330890953540802
Batch 41/64 loss: 0.327228307723999
Batch 42/64 loss: 0.3357733488082886
Batch 43/64 loss: 0.331943154335022
Batch 44/64 loss: 0.33299076557159424
Batch 45/64 loss: 0.3350331783294678
Batch 46/64 loss: 0.3298453688621521
Batch 47/64 loss: 0.3306172490119934
Batch 48/64 loss: 0.3310673236846924
Batch 49/64 loss: 0.33861589431762695
Batch 50/64 loss: 0.3402599096298218
Batch 51/64 loss: 0.32965946197509766
Batch 52/64 loss: 0.32810938358306885
Batch 53/64 loss: 0.3360027074813843
Batch 54/64 loss: 0.3311449885368347
Batch 55/64 loss: 0.3313087224960327
Batch 56/64 loss: 0.32912373542785645
Batch 57/64 loss: 0.32978248596191406
Batch 58/64 loss: 0.33219993114471436
Batch 59/64 loss: 0.33409857749938965
Batch 60/64 loss: 0.334089994430542
Batch 61/64 loss: 0.33759838342666626
Batch 62/64 loss: 0.33740007877349854
Batch 63/64 loss: 0.33139050006866455
Batch 64/64 loss: 0.339414119720459
Epoch 200  Train loss: 0.33289433834599513  Val loss: 0.343426510640436
Saving best model, epoch: 200
Epoch 201
-------------------------------
Batch 1/64 loss: 0.3313732147216797
Batch 2/64 loss: 0.3210601210594177
Batch 3/64 loss: 0.32826530933380127
Batch 4/64 loss: 0.3298799991607666
Batch 5/64 loss: 0.3314218521118164
Batch 6/64 loss: 0.3337355852127075
Batch 7/64 loss: 0.3275604248046875
Batch 8/64 loss: 0.34603655338287354
Batch 9/64 loss: 0.3381500244140625
Batch 10/64 loss: 0.32767724990844727
Batch 11/64 loss: 0.33936214447021484
Batch 12/64 loss: 0.32982105016708374
Batch 13/64 loss: 0.3292975425720215
Batch 14/64 loss: 0.3361985683441162
Batch 15/64 loss: 0.3294239044189453
Batch 16/64 loss: 0.33911341428756714
Batch 17/64 loss: 0.32963627576828003
Batch 18/64 loss: 0.3412344455718994
Batch 19/64 loss: 0.339726984500885
Batch 20/64 loss: 0.33436572551727295
Batch 21/64 loss: 0.3296828269958496
Batch 22/64 loss: 0.3282383680343628
Batch 23/64 loss: 0.33060717582702637
Batch 24/64 loss: 0.3298574686050415
Batch 25/64 loss: 0.3345493674278259
Batch 26/64 loss: 0.3389921188354492
Batch 27/64 loss: 0.3411380648612976
Batch 28/64 loss: 0.3339031934738159
Batch 29/64 loss: 0.32478654384613037
Batch 30/64 loss: 0.33596616983413696
Batch 31/64 loss: 0.33318591117858887
Batch 32/64 loss: 0.32638657093048096
Batch 33/64 loss: 0.3370431065559387
Batch 34/64 loss: 0.33734118938446045
Batch 35/64 loss: 0.34165847301483154
Batch 36/64 loss: 0.3375133275985718
Batch 37/64 loss: 0.3246273398399353
Batch 38/64 loss: 0.3325749635696411
Batch 39/64 loss: 0.3237943649291992
Batch 40/64 loss: 0.33032989501953125
Batch 41/64 loss: 0.3382145166397095
Batch 42/64 loss: 0.335219144821167
Batch 43/64 loss: 0.33689266443252563
Batch 44/64 loss: 0.3289533853530884
Batch 45/64 loss: 0.3289639949798584
Batch 46/64 loss: 0.33269166946411133
Batch 47/64 loss: 0.32611268758773804
Batch 48/64 loss: 0.333099365234375
Batch 49/64 loss: 0.3323749303817749
Batch 50/64 loss: 0.3324471712112427
Batch 51/64 loss: 0.3403189778327942
Batch 52/64 loss: 0.3319243788719177
Batch 53/64 loss: 0.33454471826553345
Batch 54/64 loss: 0.340692400932312
Batch 55/64 loss: 0.3332778215408325
Batch 56/64 loss: 0.32969969511032104
Batch 57/64 loss: 0.331523597240448
Batch 58/64 loss: 0.3287656903266907
Batch 59/64 loss: 0.3238551616668701
Batch 60/64 loss: 0.3327937126159668
Batch 61/64 loss: 0.3323926329612732
Batch 62/64 loss: 0.32881712913513184
Batch 63/64 loss: 0.3287033438682556
Batch 64/64 loss: 0.3347620368003845
Epoch 201  Train loss: 0.3326881121186649  Val loss: 0.34443799183540735
Epoch 202
-------------------------------
Batch 1/64 loss: 0.33921200037002563
Batch 2/64 loss: 0.3306537866592407
Batch 3/64 loss: 0.32670748233795166
Batch 4/64 loss: 0.3261258006095886
Batch 5/64 loss: 0.3360402584075928
Batch 6/64 loss: 0.3349097967147827
Batch 7/64 loss: 0.3283998966217041
Batch 8/64 loss: 0.3282148241996765
Batch 9/64 loss: 0.33165013790130615
Batch 10/64 loss: 0.3263612985610962
Batch 11/64 loss: 0.3310391902923584
Batch 12/64 loss: 0.33001744747161865
Batch 13/64 loss: 0.3345978260040283
Batch 14/64 loss: 0.3344969153404236
Batch 15/64 loss: 0.328407883644104
Batch 16/64 loss: 0.33026123046875
Batch 17/64 loss: 0.3364705443382263
Batch 18/64 loss: 0.3332411050796509
Batch 19/64 loss: 0.3374992609024048
Batch 20/64 loss: 0.34105420112609863
Batch 21/64 loss: 0.32827603816986084
Batch 22/64 loss: 0.32423341274261475
Batch 23/64 loss: 0.33043789863586426
Batch 24/64 loss: 0.34049975872039795
Batch 25/64 loss: 0.3288905620574951
Batch 26/64 loss: 0.32368165254592896
Batch 27/64 loss: 0.3299318552017212
Batch 28/64 loss: 0.33517009019851685
Batch 29/64 loss: 0.33149266242980957
Batch 30/64 loss: 0.3296847939491272
Batch 31/64 loss: 0.3294076919555664
Batch 32/64 loss: 0.3307640552520752
Batch 33/64 loss: 0.3321871757507324
Batch 34/64 loss: 0.33394449949264526
Batch 35/64 loss: 0.3359527587890625
Batch 36/64 loss: 0.3320499658584595
Batch 37/64 loss: 0.339450478553772
Batch 38/64 loss: 0.33508509397506714
Batch 39/64 loss: 0.33286917209625244
Batch 40/64 loss: 0.3322106599807739
Batch 41/64 loss: 0.3364083170890808
Batch 42/64 loss: 0.3304387331008911
Batch 43/64 loss: 0.3335644006729126
Batch 44/64 loss: 0.3352168798446655
Batch 45/64 loss: 0.3323575258255005
Batch 46/64 loss: 0.3453667163848877
Batch 47/64 loss: 0.3359389305114746
Batch 48/64 loss: 0.33437907695770264
Batch 49/64 loss: 0.33618760108947754
Batch 50/64 loss: 0.3324233293533325
Batch 51/64 loss: 0.33828675746917725
Batch 52/64 loss: 0.33262574672698975
Batch 53/64 loss: 0.33438241481781006
Batch 54/64 loss: 0.3317970037460327
Batch 55/64 loss: 0.33391034603118896
Batch 56/64 loss: 0.3384706974029541
Batch 57/64 loss: 0.3293166160583496
Batch 58/64 loss: 0.3286874294281006
Batch 59/64 loss: 0.33203423023223877
Batch 60/64 loss: 0.32076162099838257
Batch 61/64 loss: 0.3232402801513672
Batch 62/64 loss: 0.331798791885376
Batch 63/64 loss: 0.3359975814819336
Batch 64/64 loss: 0.33500051498413086
Epoch 202  Train loss: 0.3324929031671262  Val loss: 0.3439937346579693
Epoch 203
-------------------------------
Batch 1/64 loss: 0.3288027048110962
Batch 2/64 loss: 0.337185263633728
Batch 3/64 loss: 0.329593300819397
Batch 4/64 loss: 0.3258579969406128
Batch 5/64 loss: 0.3273819088935852
Batch 6/64 loss: 0.3293781280517578
Batch 7/64 loss: 0.3322561979293823
Batch 8/64 loss: 0.3314182758331299
Batch 9/64 loss: 0.32982921600341797
Batch 10/64 loss: 0.33213329315185547
Batch 11/64 loss: 0.3332022428512573
Batch 12/64 loss: 0.33553314208984375
Batch 13/64 loss: 0.3282381296157837
Batch 14/64 loss: 0.3384225368499756
Batch 15/64 loss: 0.33239203691482544
Batch 16/64 loss: 0.3311508297920227
Batch 17/64 loss: 0.33407318592071533
Batch 18/64 loss: 0.32955771684646606
Batch 19/64 loss: 0.3311508893966675
Batch 20/64 loss: 0.3281378149986267
Batch 21/64 loss: 0.3364593982696533
Batch 22/64 loss: 0.33756113052368164
Batch 23/64 loss: 0.32429713010787964
Batch 24/64 loss: 0.32941746711730957
Batch 25/64 loss: 0.3327558636665344
Batch 26/64 loss: 0.3334578275680542
Batch 27/64 loss: 0.3358415365219116
Batch 28/64 loss: 0.32617366313934326
Batch 29/64 loss: 0.3307352662086487
Batch 30/64 loss: 0.3354206681251526
Batch 31/64 loss: 0.3334825038909912
Batch 32/64 loss: 0.32530665397644043
Batch 33/64 loss: 0.33850371837615967
Batch 34/64 loss: 0.3316882848739624
Batch 35/64 loss: 0.3273813724517822
Batch 36/64 loss: 0.33161163330078125
Batch 37/64 loss: 0.3366428017616272
Batch 38/64 loss: 0.3331146240234375
Batch 39/64 loss: 0.3329164385795593
Batch 40/64 loss: 0.32575613260269165
Batch 41/64 loss: 0.33069896697998047
Batch 42/64 loss: 0.3256211280822754
Batch 43/64 loss: 0.33426880836486816
Batch 44/64 loss: 0.3302459716796875
Batch 45/64 loss: 0.33201074600219727
Batch 46/64 loss: 0.33349549770355225
Batch 47/64 loss: 0.32854121923446655
Batch 48/64 loss: 0.33491581678390503
Batch 49/64 loss: 0.3276376724243164
Batch 50/64 loss: 0.33383798599243164
Batch 51/64 loss: 0.331074059009552
Batch 52/64 loss: 0.33388930559158325
Batch 53/64 loss: 0.3307623863220215
Batch 54/64 loss: 0.3267397880554199
Batch 55/64 loss: 0.3389594554901123
Batch 56/64 loss: 0.33491504192352295
Batch 57/64 loss: 0.32835161685943604
Batch 58/64 loss: 0.33703070878982544
Batch 59/64 loss: 0.33161282539367676
Batch 60/64 loss: 0.33254140615463257
Batch 61/64 loss: 0.33558106422424316
Batch 62/64 loss: 0.34086716175079346
Batch 63/64 loss: 0.33228474855422974
Batch 64/64 loss: 0.3357590436935425
Epoch 203  Train loss: 0.3319517112245747  Val loss: 0.34389600270392556
Epoch 204
-------------------------------
Batch 1/64 loss: 0.3291128873825073
Batch 2/64 loss: 0.336254358291626
Batch 3/64 loss: 0.3318760395050049
Batch 4/64 loss: 0.3384295105934143
Batch 5/64 loss: 0.3279842734336853
Batch 6/64 loss: 0.33287084102630615
Batch 7/64 loss: 0.3314399719238281
Batch 8/64 loss: 0.3316406011581421
Batch 9/64 loss: 0.3217869997024536
Batch 10/64 loss: 0.3313196897506714
Batch 11/64 loss: 0.329487681388855
Batch 12/64 loss: 0.3286793828010559
Batch 13/64 loss: 0.32412660121917725
Batch 14/64 loss: 0.3305004835128784
Batch 15/64 loss: 0.33581674098968506
Batch 16/64 loss: 0.3300475478172302
Batch 17/64 loss: 0.33564889430999756
Batch 18/64 loss: 0.33348220586776733
Batch 19/64 loss: 0.33594614267349243
Batch 20/64 loss: 0.32641804218292236
Batch 21/64 loss: 0.32580482959747314
Batch 22/64 loss: 0.33352524042129517
Batch 23/64 loss: 0.32891786098480225
Batch 24/64 loss: 0.33826935291290283
Batch 25/64 loss: 0.33503758907318115
Batch 26/64 loss: 0.33285510540008545
Batch 27/64 loss: 0.33237749338150024
Batch 28/64 loss: 0.33399683237075806
Batch 29/64 loss: 0.32413387298583984
Batch 30/64 loss: 0.3339126706123352
Batch 31/64 loss: 0.335233211517334
Batch 32/64 loss: 0.3298616409301758
Batch 33/64 loss: 0.33205461502075195
Batch 34/64 loss: 0.3286428451538086
Batch 35/64 loss: 0.3320610523223877
Batch 36/64 loss: 0.3364565372467041
Batch 37/64 loss: 0.33554089069366455
Batch 38/64 loss: 0.33789217472076416
Batch 39/64 loss: 0.33463525772094727
Batch 40/64 loss: 0.3349311351776123
Batch 41/64 loss: 0.32558757066726685
Batch 42/64 loss: 0.33905285596847534
Batch 43/64 loss: 0.33310335874557495
Batch 44/64 loss: 0.3363608121871948
Batch 45/64 loss: 0.33116137981414795
Batch 46/64 loss: 0.3305675983428955
Batch 47/64 loss: 0.32866716384887695
Batch 48/64 loss: 0.32720208168029785
Batch 49/64 loss: 0.33258193731307983
Batch 50/64 loss: 0.3306539058685303
Batch 51/64 loss: 0.3424384593963623
Batch 52/64 loss: 0.3349599838256836
Batch 53/64 loss: 0.32909637689590454
Batch 54/64 loss: 0.3347780704498291
Batch 55/64 loss: 0.33339810371398926
Batch 56/64 loss: 0.3253083825111389
Batch 57/64 loss: 0.33442437648773193
Batch 58/64 loss: 0.32752639055252075
Batch 59/64 loss: 0.33043551445007324
Batch 60/64 loss: 0.3353201150894165
Batch 61/64 loss: 0.32995152473449707
Batch 62/64 loss: 0.3331418037414551
Batch 63/64 loss: 0.3286822438240051
Batch 64/64 loss: 0.3343925476074219
Epoch 204  Train loss: 0.3319875062680712  Val loss: 0.34344392830563575
Epoch 205
-------------------------------
Batch 1/64 loss: 0.33392465114593506
Batch 2/64 loss: 0.33180272579193115
Batch 3/64 loss: 0.33048659563064575
Batch 4/64 loss: 0.3298109769821167
Batch 5/64 loss: 0.3357216715812683
Batch 6/64 loss: 0.33194470405578613
Batch 7/64 loss: 0.3410869836807251
Batch 8/64 loss: 0.33140677213668823
Batch 9/64 loss: 0.32964831590652466
Batch 10/64 loss: 0.33001643419265747
Batch 11/64 loss: 0.3318547010421753
Batch 12/64 loss: 0.3327257037162781
Batch 13/64 loss: 0.3273627758026123
Batch 14/64 loss: 0.32729005813598633
Batch 15/64 loss: 0.33098316192626953
Batch 16/64 loss: 0.3370096683502197
Batch 17/64 loss: 0.3298990726470947
Batch 18/64 loss: 0.3354454040527344
Batch 19/64 loss: 0.33647775650024414
Batch 20/64 loss: 0.3259938359260559
Batch 21/64 loss: 0.33081603050231934
Batch 22/64 loss: 0.3289339542388916
Batch 23/64 loss: 0.3290395736694336
Batch 24/64 loss: 0.3265484571456909
Batch 25/64 loss: 0.3362163305282593
Batch 26/64 loss: 0.3303675055503845
Batch 27/64 loss: 0.3310856223106384
Batch 28/64 loss: 0.332233190536499
Batch 29/64 loss: 0.3314485549926758
Batch 30/64 loss: 0.3257448673248291
Batch 31/64 loss: 0.3226360082626343
Batch 32/64 loss: 0.3289217948913574
Batch 33/64 loss: 0.33143091201782227
Batch 34/64 loss: 0.33144962787628174
Batch 35/64 loss: 0.33318573236465454
Batch 36/64 loss: 0.335079550743103
Batch 37/64 loss: 0.33172810077667236
Batch 38/64 loss: 0.3302110433578491
Batch 39/64 loss: 0.3296472430229187
Batch 40/64 loss: 0.3340013027191162
Batch 41/64 loss: 0.3386639952659607
Batch 42/64 loss: 0.3306117057800293
Batch 43/64 loss: 0.33182042837142944
Batch 44/64 loss: 0.3331245183944702
Batch 45/64 loss: 0.3309996724128723
Batch 46/64 loss: 0.33679336309432983
Batch 47/64 loss: 0.3319057822227478
Batch 48/64 loss: 0.3271838426589966
Batch 49/64 loss: 0.3307081460952759
Batch 50/64 loss: 0.3300178050994873
Batch 51/64 loss: 0.32687318325042725
Batch 52/64 loss: 0.33828556537628174
Batch 53/64 loss: 0.3269447088241577
Batch 54/64 loss: 0.33246421813964844
Batch 55/64 loss: 0.33480286598205566
Batch 56/64 loss: 0.3362538814544678
Batch 57/64 loss: 0.3309904932975769
Batch 58/64 loss: 0.3284640908241272
Batch 59/64 loss: 0.33510905504226685
Batch 60/64 loss: 0.3340623378753662
Batch 61/64 loss: 0.3340098261833191
Batch 62/64 loss: 0.3345937132835388
Batch 63/64 loss: 0.3311324715614319
Batch 64/64 loss: 0.325900137424469
Epoch 205  Train loss: 0.3316369905191309  Val loss: 0.34392611882121293
Epoch 206
-------------------------------
Batch 1/64 loss: 0.32369422912597656
Batch 2/64 loss: 0.3370918035507202
Batch 3/64 loss: 0.33215653896331787
Batch 4/64 loss: 0.33113622665405273
Batch 5/64 loss: 0.33565032482147217
Batch 6/64 loss: 0.3363531231880188
Batch 7/64 loss: 0.33136576414108276
Batch 8/64 loss: 0.32523226737976074
Batch 9/64 loss: 0.33147573471069336
Batch 10/64 loss: 0.33497393131256104
Batch 11/64 loss: 0.3289293646812439
Batch 12/64 loss: 0.33033573627471924
Batch 13/64 loss: 0.3313164710998535
Batch 14/64 loss: 0.33475780487060547
Batch 15/64 loss: 0.3348854184150696
Batch 16/64 loss: 0.3283350467681885
Batch 17/64 loss: 0.33162128925323486
Batch 18/64 loss: 0.32804566621780396
Batch 19/64 loss: 0.3300015926361084
Batch 20/64 loss: 0.32483184337615967
Batch 21/64 loss: 0.3299792408943176
Batch 22/64 loss: 0.3304118514060974
Batch 23/64 loss: 0.33040422201156616
Batch 24/64 loss: 0.3327404856681824
Batch 25/64 loss: 0.3287094235420227
Batch 26/64 loss: 0.33808714151382446
Batch 27/64 loss: 0.3260641098022461
Batch 28/64 loss: 0.33031409978866577
Batch 29/64 loss: 0.3323497772216797
Batch 30/64 loss: 0.3330744504928589
Batch 31/64 loss: 0.32660019397735596
Batch 32/64 loss: 0.33441561460494995
Batch 33/64 loss: 0.3400743007659912
Batch 34/64 loss: 0.3309863805770874
Batch 35/64 loss: 0.3275759816169739
Batch 36/64 loss: 0.338765025138855
Batch 37/64 loss: 0.3227541446685791
Batch 38/64 loss: 0.33044981956481934
Batch 39/64 loss: 0.3317028284072876
Batch 40/64 loss: 0.3302114009857178
Batch 41/64 loss: 0.3255921006202698
Batch 42/64 loss: 0.33577853441238403
Batch 43/64 loss: 0.32991474866867065
Batch 44/64 loss: 0.3383370637893677
Batch 45/64 loss: 0.3282347321510315
Batch 46/64 loss: 0.3458791971206665
Batch 47/64 loss: 0.3317561149597168
Batch 48/64 loss: 0.3306049108505249
Batch 49/64 loss: 0.3370252847671509
Batch 50/64 loss: 0.3373439311981201
Batch 51/64 loss: 0.3368939161300659
Batch 52/64 loss: 0.32640206813812256
Batch 53/64 loss: 0.3298793435096741
Batch 54/64 loss: 0.3356083631515503
Batch 55/64 loss: 0.3335426449775696
Batch 56/64 loss: 0.32931411266326904
Batch 57/64 loss: 0.34228694438934326
Batch 58/64 loss: 0.3349076509475708
Batch 59/64 loss: 0.3250819444656372
Batch 60/64 loss: 0.32467371225357056
Batch 61/64 loss: 0.3291299343109131
Batch 62/64 loss: 0.33035123348236084
Batch 63/64 loss: 0.3281214237213135
Batch 64/64 loss: 0.32527220249176025
Epoch 206  Train loss: 0.3315839173747044  Val loss: 0.3428860396863669
Saving best model, epoch: 206
Epoch 207
-------------------------------
Batch 1/64 loss: 0.3311876058578491
Batch 2/64 loss: 0.3301006555557251
Batch 3/64 loss: 0.33512985706329346
Batch 4/64 loss: 0.326198935508728
Batch 5/64 loss: 0.32806462049484253
Batch 6/64 loss: 0.32900404930114746
Batch 7/64 loss: 0.33310556411743164
Batch 8/64 loss: 0.3382608890533447
Batch 9/64 loss: 0.3327827453613281
Batch 10/64 loss: 0.33883267641067505
Batch 11/64 loss: 0.3299657106399536
Batch 12/64 loss: 0.32978224754333496
Batch 13/64 loss: 0.32463008165359497
Batch 14/64 loss: 0.3284093141555786
Batch 15/64 loss: 0.3357977867126465
Batch 16/64 loss: 0.32698726654052734
Batch 17/64 loss: 0.3275061845779419
Batch 18/64 loss: 0.3335578441619873
Batch 19/64 loss: 0.3369607925415039
Batch 20/64 loss: 0.32377469539642334
Batch 21/64 loss: 0.3373957872390747
Batch 22/64 loss: 0.3339892625808716
Batch 23/64 loss: 0.331052303314209
Batch 24/64 loss: 0.33188867568969727
Batch 25/64 loss: 0.3358725309371948
Batch 26/64 loss: 0.3353714942932129
Batch 27/64 loss: 0.3313736319541931
Batch 28/64 loss: 0.331251859664917
Batch 29/64 loss: 0.3281090259552002
Batch 30/64 loss: 0.3276057839393616
Batch 31/64 loss: 0.3258551359176636
Batch 32/64 loss: 0.3355962634086609
Batch 33/64 loss: 0.33481597900390625
Batch 34/64 loss: 0.32915836572647095
Batch 35/64 loss: 0.33297353982925415
Batch 36/64 loss: 0.32784563302993774
Batch 37/64 loss: 0.3290135860443115
Batch 38/64 loss: 0.32708656787872314
Batch 39/64 loss: 0.3314446210861206
Batch 40/64 loss: 0.329509437084198
Batch 41/64 loss: 0.33558201789855957
Batch 42/64 loss: 0.3421306014060974
Batch 43/64 loss: 0.32593834400177
Batch 44/64 loss: 0.3307502269744873
Batch 45/64 loss: 0.33735108375549316
Batch 46/64 loss: 0.3362451195716858
Batch 47/64 loss: 0.32745230197906494
Batch 48/64 loss: 0.3321383595466614
Batch 49/64 loss: 0.33158695697784424
Batch 50/64 loss: 0.3344268798828125
Batch 51/64 loss: 0.3323242664337158
Batch 52/64 loss: 0.32700300216674805
Batch 53/64 loss: 0.3332831859588623
Batch 54/64 loss: 0.3348489999771118
Batch 55/64 loss: 0.33132636547088623
Batch 56/64 loss: 0.33064818382263184
Batch 57/64 loss: 0.3346419930458069
Batch 58/64 loss: 0.3328639268875122
Batch 59/64 loss: 0.3339216113090515
Batch 60/64 loss: 0.3278433084487915
Batch 61/64 loss: 0.33583611249923706
Batch 62/64 loss: 0.3326038122177124
Batch 63/64 loss: 0.33425426483154297
Batch 64/64 loss: 0.34183865785598755
Epoch 207  Train loss: 0.3319000615793116  Val loss: 0.3427996512540837
Saving best model, epoch: 207
Epoch 208
-------------------------------
Batch 1/64 loss: 0.3306485414505005
Batch 2/64 loss: 0.3340410590171814
Batch 3/64 loss: 0.3296700716018677
Batch 4/64 loss: 0.33307474851608276
Batch 5/64 loss: 0.33365118503570557
Batch 6/64 loss: 0.33366572856903076
Batch 7/64 loss: 0.3306904435157776
Batch 8/64 loss: 0.32489192485809326
Batch 9/64 loss: 0.3317480683326721
Batch 10/64 loss: 0.3339489698410034
Batch 11/64 loss: 0.3327345848083496
Batch 12/64 loss: 0.3291088342666626
Batch 13/64 loss: 0.3355966806411743
Batch 14/64 loss: 0.32947027683258057
Batch 15/64 loss: 0.32651448249816895
Batch 16/64 loss: 0.3385184407234192
Batch 17/64 loss: 0.3371221423149109
Batch 18/64 loss: 0.3281365633010864
Batch 19/64 loss: 0.3303879499435425
Batch 20/64 loss: 0.32701021432876587
Batch 21/64 loss: 0.3348489999771118
Batch 22/64 loss: 0.3348878026008606
Batch 23/64 loss: 0.3289514183998108
Batch 24/64 loss: 0.3368107080459595
Batch 25/64 loss: 0.3316860795021057
Batch 26/64 loss: 0.3316531777381897
Batch 27/64 loss: 0.3228466510772705
Batch 28/64 loss: 0.32707279920578003
Batch 29/64 loss: 0.32650089263916016
Batch 30/64 loss: 0.33239245414733887
Batch 31/64 loss: 0.32864660024642944
Batch 32/64 loss: 0.3305262327194214
Batch 33/64 loss: 0.33867013454437256
Batch 34/64 loss: 0.3272221088409424
Batch 35/64 loss: 0.32386428117752075
Batch 36/64 loss: 0.3298107385635376
Batch 37/64 loss: 0.3322627544403076
Batch 38/64 loss: 0.33878880739212036
Batch 39/64 loss: 0.3290663957595825
Batch 40/64 loss: 0.32702362537384033
Batch 41/64 loss: 0.3264089822769165
Batch 42/64 loss: 0.33519887924194336
Batch 43/64 loss: 0.3383758068084717
Batch 44/64 loss: 0.33253252506256104
Batch 45/64 loss: 0.3295100927352905
Batch 46/64 loss: 0.3341239094734192
Batch 47/64 loss: 0.3286069631576538
Batch 48/64 loss: 0.33104783296585083
Batch 49/64 loss: 0.3280555009841919
Batch 50/64 loss: 0.34089338779449463
Batch 51/64 loss: 0.3261945843696594
Batch 52/64 loss: 0.3216400742530823
Batch 53/64 loss: 0.32426661252975464
Batch 54/64 loss: 0.3360157012939453
Batch 55/64 loss: 0.3302297592163086
Batch 56/64 loss: 0.3357100486755371
Batch 57/64 loss: 0.33218836784362793
Batch 58/64 loss: 0.33053624629974365
Batch 59/64 loss: 0.3290669918060303
Batch 60/64 loss: 0.32940953969955444
Batch 61/64 loss: 0.3370448350906372
Batch 62/64 loss: 0.3255559206008911
Batch 63/64 loss: 0.33000218868255615
Batch 64/64 loss: 0.3329158425331116
Epoch 208  Train loss: 0.33108180714588537  Val loss: 0.3433824894354515
Epoch 209
-------------------------------
Batch 1/64 loss: 0.321566641330719
Batch 2/64 loss: 0.32348716259002686
Batch 3/64 loss: 0.32721614837646484
Batch 4/64 loss: 0.33014869689941406
Batch 5/64 loss: 0.3332853317260742
Batch 6/64 loss: 0.3316279649734497
Batch 7/64 loss: 0.3293437361717224
Batch 8/64 loss: 0.32852381467819214
Batch 9/64 loss: 0.32284605503082275
Batch 10/64 loss: 0.3278923034667969
Batch 11/64 loss: 0.3318833112716675
Batch 12/64 loss: 0.3258158564567566
Batch 13/64 loss: 0.32639217376708984
Batch 14/64 loss: 0.330219030380249
Batch 15/64 loss: 0.3295527696609497
Batch 16/64 loss: 0.326677143573761
Batch 17/64 loss: 0.33199000358581543
Batch 18/64 loss: 0.32777559757232666
Batch 19/64 loss: 0.3313804864883423
Batch 20/64 loss: 0.3326796293258667
Batch 21/64 loss: 0.3343150019645691
Batch 22/64 loss: 0.32881927490234375
Batch 23/64 loss: 0.32431280612945557
Batch 24/64 loss: 0.3276209831237793
Batch 25/64 loss: 0.32886457443237305
Batch 26/64 loss: 0.3317837715148926
Batch 27/64 loss: 0.3305627107620239
Batch 28/64 loss: 0.33444714546203613
Batch 29/64 loss: 0.3340325355529785
Batch 30/64 loss: 0.32790589332580566
Batch 31/64 loss: 0.3372364044189453
Batch 32/64 loss: 0.33896124362945557
Batch 33/64 loss: 0.32750052213668823
Batch 34/64 loss: 0.3361054062843323
Batch 35/64 loss: 0.33034300804138184
Batch 36/64 loss: 0.33004361391067505
Batch 37/64 loss: 0.3380924463272095
Batch 38/64 loss: 0.34111499786376953
Batch 39/64 loss: 0.33560317754745483
Batch 40/64 loss: 0.33494657278060913
Batch 41/64 loss: 0.32946842908859253
Batch 42/64 loss: 0.3311350345611572
Batch 43/64 loss: 0.33082103729248047
Batch 44/64 loss: 0.3313164710998535
Batch 45/64 loss: 0.329853892326355
Batch 46/64 loss: 0.3355534076690674
Batch 47/64 loss: 0.33288729190826416
Batch 48/64 loss: 0.33779770135879517
Batch 49/64 loss: 0.33032500743865967
Batch 50/64 loss: 0.32976341247558594
Batch 51/64 loss: 0.3336033821105957
Batch 52/64 loss: 0.3285747170448303
Batch 53/64 loss: 0.3332374095916748
Batch 54/64 loss: 0.332161545753479
Batch 55/64 loss: 0.3285796642303467
Batch 56/64 loss: 0.33216893672943115
Batch 57/64 loss: 0.32380300760269165
Batch 58/64 loss: 0.3330116271972656
Batch 59/64 loss: 0.33275359869003296
Batch 60/64 loss: 0.32227623462677
Batch 61/64 loss: 0.3365703821182251
Batch 62/64 loss: 0.32650792598724365
Batch 63/64 loss: 0.33515703678131104
Batch 64/64 loss: 0.3376530408859253
Epoch 209  Train loss: 0.3308781628515206  Val loss: 0.34406149203015357
Epoch 210
-------------------------------
Batch 1/64 loss: 0.32063502073287964
Batch 2/64 loss: 0.33598077297210693
Batch 3/64 loss: 0.3214757442474365
Batch 4/64 loss: 0.3299156427383423
Batch 5/64 loss: 0.32614195346832275
Batch 6/64 loss: 0.3299142122268677
Batch 7/64 loss: 0.32472264766693115
Batch 8/64 loss: 0.3288756012916565
Batch 9/64 loss: 0.3313528299331665
Batch 10/64 loss: 0.33355408906936646
Batch 11/64 loss: 0.322778582572937
Batch 12/64 loss: 0.323345422744751
Batch 13/64 loss: 0.3286881446838379
Batch 14/64 loss: 0.33736246824264526
Batch 15/64 loss: 0.32957667112350464
Batch 16/64 loss: 0.32994651794433594
Batch 17/64 loss: 0.335416316986084
Batch 18/64 loss: 0.33046650886535645
Batch 19/64 loss: 0.3306547999382019
Batch 20/64 loss: 0.3301842212677002
Batch 21/64 loss: 0.33200061321258545
Batch 22/64 loss: 0.3291124105453491
Batch 23/64 loss: 0.3270663022994995
Batch 24/64 loss: 0.3337455987930298
Batch 25/64 loss: 0.33281588554382324
Batch 26/64 loss: 0.32762742042541504
Batch 27/64 loss: 0.33140432834625244
Batch 28/64 loss: 0.33009493350982666
Batch 29/64 loss: 0.3402950167655945
Batch 30/64 loss: 0.32886672019958496
Batch 31/64 loss: 0.32693415880203247
Batch 32/64 loss: 0.3301132917404175
Batch 33/64 loss: 0.3280569314956665
Batch 34/64 loss: 0.32130348682403564
Batch 35/64 loss: 0.3327139616012573
Batch 36/64 loss: 0.3318309187889099
Batch 37/64 loss: 0.3308514356613159
Batch 38/64 loss: 0.3287782669067383
Batch 39/64 loss: 0.3297499418258667
Batch 40/64 loss: 0.333351731300354
Batch 41/64 loss: 0.3327847719192505
Batch 42/64 loss: 0.32897692918777466
Batch 43/64 loss: 0.33321917057037354
Batch 44/64 loss: 0.32366377115249634
Batch 45/64 loss: 0.33206886053085327
Batch 46/64 loss: 0.3315364122390747
Batch 47/64 loss: 0.32925641536712646
Batch 48/64 loss: 0.3328871726989746
Batch 49/64 loss: 0.33268648386001587
Batch 50/64 loss: 0.3287261724472046
Batch 51/64 loss: 0.33081215620040894
Batch 52/64 loss: 0.3425161838531494
Batch 53/64 loss: 0.3298003077507019
Batch 54/64 loss: 0.3319765329360962
Batch 55/64 loss: 0.32847827672958374
Batch 56/64 loss: 0.33263468742370605
Batch 57/64 loss: 0.3327558636665344
Batch 58/64 loss: 0.3388051986694336
Batch 59/64 loss: 0.3409060835838318
Batch 60/64 loss: 0.33154070377349854
Batch 61/64 loss: 0.3360203504562378
Batch 62/64 loss: 0.32922422885894775
Batch 63/64 loss: 0.3328629732131958
Batch 64/64 loss: 0.3300672173500061
Epoch 210  Train loss: 0.330657123818117  Val loss: 0.3411992827231941
Saving best model, epoch: 210
Epoch 211
-------------------------------
Batch 1/64 loss: 0.3283480405807495
Batch 2/64 loss: 0.33240652084350586
Batch 3/64 loss: 0.3226637840270996
Batch 4/64 loss: 0.3283628225326538
Batch 5/64 loss: 0.3333083987236023
Batch 6/64 loss: 0.3355478048324585
Batch 7/64 loss: 0.32793664932250977
Batch 8/64 loss: 0.32999861240386963
Batch 9/64 loss: 0.3335984945297241
Batch 10/64 loss: 0.3307647705078125
Batch 11/64 loss: 0.33223068714141846
Batch 12/64 loss: 0.3245381712913513
Batch 13/64 loss: 0.3316381573677063
Batch 14/64 loss: 0.3270273804664612
Batch 15/64 loss: 0.34032750129699707
Batch 16/64 loss: 0.327602744102478
Batch 17/64 loss: 0.3388739824295044
Batch 18/64 loss: 0.33604520559310913
Batch 19/64 loss: 0.33669400215148926
Batch 20/64 loss: 0.3340598940849304
Batch 21/64 loss: 0.32143425941467285
Batch 22/64 loss: 0.3244415521621704
Batch 23/64 loss: 0.3255279064178467
Batch 24/64 loss: 0.32664549350738525
Batch 25/64 loss: 0.3284122943878174
Batch 26/64 loss: 0.32549577951431274
Batch 27/64 loss: 0.3302403688430786
Batch 28/64 loss: 0.3290632963180542
Batch 29/64 loss: 0.3323017358779907
Batch 30/64 loss: 0.3270658850669861
Batch 31/64 loss: 0.33046382665634155
Batch 32/64 loss: 0.3325691223144531
Batch 33/64 loss: 0.33194422721862793
Batch 34/64 loss: 0.326701283454895
Batch 35/64 loss: 0.33408457040786743
Batch 36/64 loss: 0.3233860731124878
Batch 37/64 loss: 0.3311602473258972
Batch 38/64 loss: 0.3326016664505005
Batch 39/64 loss: 0.3341895341873169
Batch 40/64 loss: 0.3410806655883789
Batch 41/64 loss: 0.3332022428512573
Batch 42/64 loss: 0.3262670040130615
Batch 43/64 loss: 0.33420121669769287
Batch 44/64 loss: 0.3350450396537781
Batch 45/64 loss: 0.3306153416633606
Batch 46/64 loss: 0.32950854301452637
Batch 47/64 loss: 0.33324134349823
Batch 48/64 loss: 0.3340952396392822
Batch 49/64 loss: 0.3283005952835083
Batch 50/64 loss: 0.33006197214126587
Batch 51/64 loss: 0.3295552730560303
Batch 52/64 loss: 0.33360224962234497
Batch 53/64 loss: 0.32639068365097046
Batch 54/64 loss: 0.33231258392333984
Batch 55/64 loss: 0.3245476484298706
Batch 56/64 loss: 0.33284008502960205
Batch 57/64 loss: 0.32474541664123535
Batch 58/64 loss: 0.3306558132171631
Batch 59/64 loss: 0.3345118761062622
Batch 60/64 loss: 0.3324424624443054
Batch 61/64 loss: 0.3277764320373535
Batch 62/64 loss: 0.3323845863342285
Batch 63/64 loss: 0.3324218988418579
Batch 64/64 loss: 0.3318495750427246
Epoch 211  Train loss: 0.330641508102417  Val loss: 0.3422167012371968
Epoch 212
-------------------------------
Batch 1/64 loss: 0.3330541253089905
Batch 2/64 loss: 0.323789119720459
Batch 3/64 loss: 0.3313530683517456
Batch 4/64 loss: 0.3315012454986572
Batch 5/64 loss: 0.3230036497116089
Batch 6/64 loss: 0.3291354775428772
Batch 7/64 loss: 0.32300853729248047
Batch 8/64 loss: 0.33071309328079224
Batch 9/64 loss: 0.3374176025390625
Batch 10/64 loss: 0.32105427980422974
Batch 11/64 loss: 0.3336401581764221
Batch 12/64 loss: 0.33245527744293213
Batch 13/64 loss: 0.33945345878601074
Batch 14/64 loss: 0.32973694801330566
Batch 15/64 loss: 0.332061767578125
Batch 16/64 loss: 0.33244627714157104
Batch 17/64 loss: 0.3369981050491333
Batch 18/64 loss: 0.32807689905166626
Batch 19/64 loss: 0.3351482152938843
Batch 20/64 loss: 0.33127254247665405
Batch 21/64 loss: 0.33347564935684204
Batch 22/64 loss: 0.33274948596954346
Batch 23/64 loss: 0.3234734535217285
Batch 24/64 loss: 0.3278930187225342
Batch 25/64 loss: 0.3260982036590576
Batch 26/64 loss: 0.3331350088119507
Batch 27/64 loss: 0.3300764560699463
Batch 28/64 loss: 0.3314305543899536
Batch 29/64 loss: 0.3287959098815918
Batch 30/64 loss: 0.332054078578949
Batch 31/64 loss: 0.3321310877799988
Batch 32/64 loss: 0.3321962356567383
Batch 33/64 loss: 0.329540491104126
Batch 34/64 loss: 0.32899904251098633
Batch 35/64 loss: 0.33212095499038696
Batch 36/64 loss: 0.33000826835632324
Batch 37/64 loss: 0.33134400844573975
Batch 38/64 loss: 0.32394200563430786
Batch 39/64 loss: 0.33024537563323975
Batch 40/64 loss: 0.32350754737854004
Batch 41/64 loss: 0.3243020176887512
Batch 42/64 loss: 0.3350152373313904
Batch 43/64 loss: 0.3260743021965027
Batch 44/64 loss: 0.3300197124481201
Batch 45/64 loss: 0.32918572425842285
Batch 46/64 loss: 0.3319432735443115
Batch 47/64 loss: 0.34237104654312134
Batch 48/64 loss: 0.33521854877471924
Batch 49/64 loss: 0.32772934436798096
Batch 50/64 loss: 0.33541131019592285
Batch 51/64 loss: 0.3285423517227173
Batch 52/64 loss: 0.32083845138549805
Batch 53/64 loss: 0.3327018618583679
Batch 54/64 loss: 0.33251523971557617
Batch 55/64 loss: 0.3281254768371582
Batch 56/64 loss: 0.32816195487976074
Batch 57/64 loss: 0.32801610231399536
Batch 58/64 loss: 0.32788902521133423
Batch 59/64 loss: 0.32761621475219727
Batch 60/64 loss: 0.3378802537918091
Batch 61/64 loss: 0.33024704456329346
Batch 62/64 loss: 0.3246554136276245
Batch 63/64 loss: 0.332747220993042
Batch 64/64 loss: 0.3335281014442444
Epoch 212  Train loss: 0.33028846885643753  Val loss: 0.34242197717587974
Epoch 213
-------------------------------
Batch 1/64 loss: 0.33141738176345825
Batch 2/64 loss: 0.3272084593772888
Batch 3/64 loss: 0.3305093050003052
Batch 4/64 loss: 0.33162569999694824
Batch 5/64 loss: 0.32280224561691284
Batch 6/64 loss: 0.32715338468551636
Batch 7/64 loss: 0.3315410614013672
Batch 8/64 loss: 0.32729852199554443
Batch 9/64 loss: 0.3267959952354431
Batch 10/64 loss: 0.3300133943557739
Batch 11/64 loss: 0.332233190536499
Batch 12/64 loss: 0.3293001055717468
Batch 13/64 loss: 0.33128076791763306
Batch 14/64 loss: 0.32869023084640503
Batch 15/64 loss: 0.3307284116744995
Batch 16/64 loss: 0.3295184373855591
Batch 17/64 loss: 0.33140993118286133
Batch 18/64 loss: 0.3383568525314331
Batch 19/64 loss: 0.33033251762390137
Batch 20/64 loss: 0.32824695110321045
Batch 21/64 loss: 0.32005834579467773
Batch 22/64 loss: 0.3343921899795532
Batch 23/64 loss: 0.3286259174346924
Batch 24/64 loss: 0.3250212073326111
Batch 25/64 loss: 0.3382152318954468
Batch 26/64 loss: 0.3336610794067383
Batch 27/64 loss: 0.3262448310852051
Batch 28/64 loss: 0.33179593086242676
Batch 29/64 loss: 0.3295203447341919
Batch 30/64 loss: 0.3305792808532715
Batch 31/64 loss: 0.3342254161834717
Batch 32/64 loss: 0.33715522289276123
Batch 33/64 loss: 0.32312941551208496
Batch 34/64 loss: 0.32921695709228516
Batch 35/64 loss: 0.32921910285949707
Batch 36/64 loss: 0.33183908462524414
Batch 37/64 loss: 0.3283430337905884
Batch 38/64 loss: 0.32117486000061035
Batch 39/64 loss: 0.3368053436279297
Batch 40/64 loss: 0.3315298557281494
Batch 41/64 loss: 0.33256685733795166
Batch 42/64 loss: 0.3330647349357605
Batch 43/64 loss: 0.33279716968536377
Batch 44/64 loss: 0.3260692358016968
Batch 45/64 loss: 0.32831335067749023
Batch 46/64 loss: 0.3291062116622925
Batch 47/64 loss: 0.33603787422180176
Batch 48/64 loss: 0.32495343685150146
Batch 49/64 loss: 0.3372233510017395
Batch 50/64 loss: 0.3288136124610901
Batch 51/64 loss: 0.331107497215271
Batch 52/64 loss: 0.3306807279586792
Batch 53/64 loss: 0.3353598117828369
Batch 54/64 loss: 0.33114612102508545
Batch 55/64 loss: 0.3309502601623535
Batch 56/64 loss: 0.3300046920776367
Batch 57/64 loss: 0.3310782313346863
Batch 58/64 loss: 0.3279680609703064
Batch 59/64 loss: 0.3319461941719055
Batch 60/64 loss: 0.3297891616821289
Batch 61/64 loss: 0.33142584562301636
Batch 62/64 loss: 0.32808995246887207
Batch 63/64 loss: 0.326554536819458
Batch 64/64 loss: 0.3322330117225647
Epoch 213  Train loss: 0.3302186224974838  Val loss: 0.34200006006509576
Epoch 214
-------------------------------
Batch 1/64 loss: 0.32758915424346924
Batch 2/64 loss: 0.3225094676017761
Batch 3/64 loss: 0.33685213327407837
Batch 4/64 loss: 0.3303121328353882
Batch 5/64 loss: 0.322992742061615
Batch 6/64 loss: 0.33396023511886597
Batch 7/64 loss: 0.32916897535324097
Batch 8/64 loss: 0.3170665502548218
Batch 9/64 loss: 0.32695382833480835
Batch 10/64 loss: 0.331856369972229
Batch 11/64 loss: 0.3269391655921936
Batch 12/64 loss: 0.32836079597473145
Batch 13/64 loss: 0.32429540157318115
Batch 14/64 loss: 0.33101677894592285
Batch 15/64 loss: 0.31999480724334717
Batch 16/64 loss: 0.3396626114845276
Batch 17/64 loss: 0.3255956172943115
Batch 18/64 loss: 0.3345409035682678
Batch 19/64 loss: 0.3332570791244507
Batch 20/64 loss: 0.3385300040245056
Batch 21/64 loss: 0.32930314540863037
Batch 22/64 loss: 0.3367680311203003
Batch 23/64 loss: 0.3250190019607544
Batch 24/64 loss: 0.33555710315704346
Batch 25/64 loss: 0.3248903155326843
Batch 26/64 loss: 0.33276355266571045
Batch 27/64 loss: 0.3290504217147827
Batch 28/64 loss: 0.3240196704864502
Batch 29/64 loss: 0.3338432312011719
Batch 30/64 loss: 0.32280707359313965
Batch 31/64 loss: 0.3294801712036133
Batch 32/64 loss: 0.34126806259155273
Batch 33/64 loss: 0.3289991617202759
Batch 34/64 loss: 0.33982139825820923
Batch 35/64 loss: 0.328952431678772
Batch 36/64 loss: 0.3254193067550659
Batch 37/64 loss: 0.33056187629699707
Batch 38/64 loss: 0.33655333518981934
Batch 39/64 loss: 0.32577794790267944
Batch 40/64 loss: 0.33202147483825684
Batch 41/64 loss: 0.3322408199310303
Batch 42/64 loss: 0.330893874168396
Batch 43/64 loss: 0.3347059488296509
Batch 44/64 loss: 0.3316967487335205
Batch 45/64 loss: 0.3296138048171997
Batch 46/64 loss: 0.330827534198761
Batch 47/64 loss: 0.33486270904541016
Batch 48/64 loss: 0.32930439710617065
Batch 49/64 loss: 0.3309483528137207
Batch 50/64 loss: 0.33147335052490234
Batch 51/64 loss: 0.34684503078460693
Batch 52/64 loss: 0.3354748487472534
Batch 53/64 loss: 0.3332477807998657
Batch 54/64 loss: 0.32318633794784546
Batch 55/64 loss: 0.3311377763748169
Batch 56/64 loss: 0.32444334030151367
Batch 57/64 loss: 0.33143293857574463
Batch 58/64 loss: 0.33462661504745483
Batch 59/64 loss: 0.33441853523254395
Batch 60/64 loss: 0.32982659339904785
Batch 61/64 loss: 0.323879599571228
Batch 62/64 loss: 0.32547497749328613
Batch 63/64 loss: 0.3231273889541626
Batch 64/64 loss: 0.3303879499435425
Epoch 214  Train loss: 0.3302872428707048  Val loss: 0.3413962318315539
Epoch 215
-------------------------------
Batch 1/64 loss: 0.33878016471862793
Batch 2/64 loss: 0.3347488045692444
Batch 3/64 loss: 0.3325626850128174
Batch 4/64 loss: 0.33165252208709717
Batch 5/64 loss: 0.3387792110443115
Batch 6/64 loss: 0.3368273973464966
Batch 7/64 loss: 0.32484108209609985
Batch 8/64 loss: 0.3396427035331726
Batch 9/64 loss: 0.32554757595062256
Batch 10/64 loss: 0.3308553099632263
Batch 11/64 loss: 0.33118486404418945
Batch 12/64 loss: 0.3259074091911316
Batch 13/64 loss: 0.33656489849090576
Batch 14/64 loss: 0.32762598991394043
Batch 15/64 loss: 0.32876336574554443
Batch 16/64 loss: 0.329401433467865
Batch 17/64 loss: 0.32994621992111206
Batch 18/64 loss: 0.33341872692108154
Batch 19/64 loss: 0.32628726959228516
Batch 20/64 loss: 0.33085477352142334
Batch 21/64 loss: 0.3292720317840576
Batch 22/64 loss: 0.32667744159698486
Batch 23/64 loss: 0.3226059675216675
Batch 24/64 loss: 0.32911550998687744
Batch 25/64 loss: 0.3276406526565552
Batch 26/64 loss: 0.3214150667190552
Batch 27/64 loss: 0.32309937477111816
Batch 28/64 loss: 0.322857141494751
Batch 29/64 loss: 0.32674044370651245
Batch 30/64 loss: 0.33227646350860596
Batch 31/64 loss: 0.32654619216918945
Batch 32/64 loss: 0.3328101634979248
Batch 33/64 loss: 0.33577579259872437
Batch 34/64 loss: 0.3381016254425049
Batch 35/64 loss: 0.3279271721839905
Batch 36/64 loss: 0.32564252614974976
Batch 37/64 loss: 0.3285496234893799
Batch 38/64 loss: 0.33200204372406006
Batch 39/64 loss: 0.3227909803390503
Batch 40/64 loss: 0.331856369972229
Batch 41/64 loss: 0.3219403028488159
Batch 42/64 loss: 0.3353314995765686
Batch 43/64 loss: 0.326671302318573
Batch 44/64 loss: 0.3265332579612732
Batch 45/64 loss: 0.3295021057128906
Batch 46/64 loss: 0.33143579959869385
Batch 47/64 loss: 0.3377830386161804
Batch 48/64 loss: 0.3289119005203247
Batch 49/64 loss: 0.3309350609779358
Batch 50/64 loss: 0.3378969430923462
Batch 51/64 loss: 0.32668566703796387
Batch 52/64 loss: 0.32932090759277344
Batch 53/64 loss: 0.3253908157348633
Batch 54/64 loss: 0.3189318776130676
Batch 55/64 loss: 0.3406031131744385
Batch 56/64 loss: 0.32307499647140503
Batch 57/64 loss: 0.32954883575439453
Batch 58/64 loss: 0.32119715213775635
Batch 59/64 loss: 0.3349640965461731
Batch 60/64 loss: 0.33322763442993164
Batch 61/64 loss: 0.3328583836555481
Batch 62/64 loss: 0.33456265926361084
Batch 63/64 loss: 0.33487313985824585
Batch 64/64 loss: 0.33563941717147827
Epoch 215  Train loss: 0.3300675300990834  Val loss: 0.3414715159799635
Epoch 216
-------------------------------
Batch 1/64 loss: 0.3286656141281128
Batch 2/64 loss: 0.332009494304657
Batch 3/64 loss: 0.32943499088287354
Batch 4/64 loss: 0.32968389987945557
Batch 5/64 loss: 0.32763534784317017
Batch 6/64 loss: 0.32472389936447144
Batch 7/64 loss: 0.33816730976104736
Batch 8/64 loss: 0.32667022943496704
Batch 9/64 loss: 0.32957589626312256
Batch 10/64 loss: 0.3272475600242615
Batch 11/64 loss: 0.3345135450363159
Batch 12/64 loss: 0.3306806683540344
Batch 13/64 loss: 0.32616889476776123
Batch 14/64 loss: 0.32959306240081787
Batch 15/64 loss: 0.3288142681121826
Batch 16/64 loss: 0.33410608768463135
Batch 17/64 loss: 0.3282495141029358
Batch 18/64 loss: 0.3394964933395386
Batch 19/64 loss: 0.32131701707839966
Batch 20/64 loss: 0.33625292778015137
Batch 21/64 loss: 0.3304595947265625
Batch 22/64 loss: 0.3284664750099182
Batch 23/64 loss: 0.3320479393005371
Batch 24/64 loss: 0.3331928849220276
Batch 25/64 loss: 0.3197251558303833
Batch 26/64 loss: 0.3255382180213928
Batch 27/64 loss: 0.3235355019569397
Batch 28/64 loss: 0.33322852849960327
Batch 29/64 loss: 0.32658278942108154
Batch 30/64 loss: 0.33185720443725586
Batch 31/64 loss: 0.32623744010925293
Batch 32/64 loss: 0.33282607793807983
Batch 33/64 loss: 0.3211778402328491
Batch 34/64 loss: 0.3293532133102417
Batch 35/64 loss: 0.33310258388519287
Batch 36/64 loss: 0.3267861008644104
Batch 37/64 loss: 0.3220251798629761
Batch 38/64 loss: 0.32755231857299805
Batch 39/64 loss: 0.33065104484558105
Batch 40/64 loss: 0.3287086486816406
Batch 41/64 loss: 0.34167468547821045
Batch 42/64 loss: 0.3361712694168091
Batch 43/64 loss: 0.33414483070373535
Batch 44/64 loss: 0.3307535648345947
Batch 45/64 loss: 0.3280617594718933
Batch 46/64 loss: 0.3332568407058716
Batch 47/64 loss: 0.3271726965904236
Batch 48/64 loss: 0.32813209295272827
Batch 49/64 loss: 0.32210397720336914
Batch 50/64 loss: 0.33218300342559814
Batch 51/64 loss: 0.3273559808731079
Batch 52/64 loss: 0.33343321084976196
Batch 53/64 loss: 0.3290889263153076
Batch 54/64 loss: 0.32520347833633423
Batch 55/64 loss: 0.32621240615844727
Batch 56/64 loss: 0.3279702663421631
Batch 57/64 loss: 0.3323970437049866
Batch 58/64 loss: 0.32465094327926636
Batch 59/64 loss: 0.33127886056900024
Batch 60/64 loss: 0.32343339920043945
Batch 61/64 loss: 0.3268706798553467
Batch 62/64 loss: 0.32589614391326904
Batch 63/64 loss: 0.3318406939506531
Batch 64/64 loss: 0.3275768756866455
Epoch 216  Train loss: 0.3292710724998923  Val loss: 0.3419617119523668
Epoch 217
-------------------------------
Batch 1/64 loss: 0.328843355178833
Batch 2/64 loss: 0.33338677883148193
Batch 3/64 loss: 0.3316715955734253
Batch 4/64 loss: 0.32438379526138306
Batch 5/64 loss: 0.3332328200340271
Batch 6/64 loss: 0.3276013135910034
Batch 7/64 loss: 0.33315879106521606
Batch 8/64 loss: 0.3316143751144409
Batch 9/64 loss: 0.33609122037887573
Batch 10/64 loss: 0.3306148052215576
Batch 11/64 loss: 0.3379690647125244
Batch 12/64 loss: 0.3274645209312439
Batch 13/64 loss: 0.3296707272529602
Batch 14/64 loss: 0.3267671465873718
Batch 15/64 loss: 0.33212828636169434
Batch 16/64 loss: 0.32470959424972534
Batch 17/64 loss: 0.3253830671310425
Batch 18/64 loss: 0.32503241300582886
Batch 19/64 loss: 0.32865428924560547
Batch 20/64 loss: 0.32402968406677246
Batch 21/64 loss: 0.3245166540145874
Batch 22/64 loss: 0.3272136449813843
Batch 23/64 loss: 0.3206617832183838
Batch 24/64 loss: 0.3255230188369751
Batch 25/64 loss: 0.33505141735076904
Batch 26/64 loss: 0.32534313201904297
Batch 27/64 loss: 0.32801252603530884
Batch 28/64 loss: 0.327317476272583
Batch 29/64 loss: 0.3244406580924988
Batch 30/64 loss: 0.3301955461502075
Batch 31/64 loss: 0.33393794298171997
Batch 32/64 loss: 0.33468902111053467
Batch 33/64 loss: 0.3346039056777954
Batch 34/64 loss: 0.329113245010376
Batch 35/64 loss: 0.3295344114303589
Batch 36/64 loss: 0.3281517028808594
Batch 37/64 loss: 0.3327382802963257
Batch 38/64 loss: 0.32749706506729126
Batch 39/64 loss: 0.33063220977783203
Batch 40/64 loss: 0.33531153202056885
Batch 41/64 loss: 0.3277224898338318
Batch 42/64 loss: 0.32275986671447754
Batch 43/64 loss: 0.3297501802444458
Batch 44/64 loss: 0.3267163038253784
Batch 45/64 loss: 0.3293532133102417
Batch 46/64 loss: 0.32928895950317383
Batch 47/64 loss: 0.3289555311203003
Batch 48/64 loss: 0.3287317752838135
Batch 49/64 loss: 0.3269071578979492
Batch 50/64 loss: 0.33227992057800293
Batch 51/64 loss: 0.33296555280685425
Batch 52/64 loss: 0.32878589630126953
Batch 53/64 loss: 0.327730655670166
Batch 54/64 loss: 0.3237815499305725
Batch 55/64 loss: 0.32625824213027954
Batch 56/64 loss: 0.3253064751625061
Batch 57/64 loss: 0.32875585556030273
Batch 58/64 loss: 0.33231478929519653
Batch 59/64 loss: 0.33266979455947876
Batch 60/64 loss: 0.3359020948410034
Batch 61/64 loss: 0.3279435634613037
Batch 62/64 loss: 0.3311593532562256
Batch 63/64 loss: 0.3304064869880676
Batch 64/64 loss: 0.32014453411102295
Epoch 217  Train loss: 0.3291521086412318  Val loss: 0.34217731977246474
Epoch 218
-------------------------------
Batch 1/64 loss: 0.33079206943511963
Batch 2/64 loss: 0.3318561315536499
Batch 3/64 loss: 0.32926177978515625
Batch 4/64 loss: 0.33457839488983154
Batch 5/64 loss: 0.32327187061309814
Batch 6/64 loss: 0.31900733709335327
Batch 7/64 loss: 0.3239182233810425
Batch 8/64 loss: 0.3389055132865906
Batch 9/64 loss: 0.33277982473373413
Batch 10/64 loss: 0.3216663599014282
Batch 11/64 loss: 0.31809425354003906
Batch 12/64 loss: 0.33250099420547485
Batch 13/64 loss: 0.3291324973106384
Batch 14/64 loss: 0.32269394397735596
Batch 15/64 loss: 0.32732951641082764
Batch 16/64 loss: 0.3277875781059265
Batch 17/64 loss: 0.32772886753082275
Batch 18/64 loss: 0.3267545700073242
Batch 19/64 loss: 0.3339518904685974
Batch 20/64 loss: 0.3350953459739685
Batch 21/64 loss: 0.32337188720703125
Batch 22/64 loss: 0.327786922454834
Batch 23/64 loss: 0.3351171612739563
Batch 24/64 loss: 0.3363991379737854
Batch 25/64 loss: 0.3273965120315552
Batch 26/64 loss: 0.33667171001434326
Batch 27/64 loss: 0.33092397451400757
Batch 28/64 loss: 0.32695329189300537
Batch 29/64 loss: 0.3241698741912842
Batch 30/64 loss: 0.3411470651626587
Batch 31/64 loss: 0.3326098322868347
Batch 32/64 loss: 0.3315223455429077
Batch 33/64 loss: 0.3409501314163208
Batch 34/64 loss: 0.3351534605026245
Batch 35/64 loss: 0.33531010150909424
Batch 36/64 loss: 0.3196481466293335
Batch 37/64 loss: 0.33304107189178467
Batch 38/64 loss: 0.3343273401260376
Batch 39/64 loss: 0.3359900116920471
Batch 40/64 loss: 0.32202088832855225
Batch 41/64 loss: 0.32361161708831787
Batch 42/64 loss: 0.3253077268600464
Batch 43/64 loss: 0.33020782470703125
Batch 44/64 loss: 0.3384397625923157
Batch 45/64 loss: 0.32223689556121826
Batch 46/64 loss: 0.32948893308639526
Batch 47/64 loss: 0.3182262182235718
Batch 48/64 loss: 0.3250907063484192
Batch 49/64 loss: 0.33018481731414795
Batch 50/64 loss: 0.32503896951675415
Batch 51/64 loss: 0.3267216086387634
Batch 52/64 loss: 0.3232548236846924
Batch 53/64 loss: 0.32790935039520264
Batch 54/64 loss: 0.32895320653915405
Batch 55/64 loss: 0.32698488235473633
Batch 56/64 loss: 0.3301224708557129
Batch 57/64 loss: 0.33292651176452637
Batch 58/64 loss: 0.3283654451370239
Batch 59/64 loss: 0.3333086371421814
Batch 60/64 loss: 0.32756853103637695
Batch 61/64 loss: 0.3257192373275757
Batch 62/64 loss: 0.32725071907043457
Batch 63/64 loss: 0.3332429528236389
Batch 64/64 loss: 0.3320571780204773
Epoch 218  Train loss: 0.32920505977144426  Val loss: 0.3427036375933906
Epoch 219
-------------------------------
Batch 1/64 loss: 0.33958572149276733
Batch 2/64 loss: 0.32923340797424316
Batch 3/64 loss: 0.3274441957473755
Batch 4/64 loss: 0.33315742015838623
Batch 5/64 loss: 0.32911980152130127
Batch 6/64 loss: 0.33165931701660156
Batch 7/64 loss: 0.32544374465942383
Batch 8/64 loss: 0.3311137557029724
Batch 9/64 loss: 0.3284764289855957
Batch 10/64 loss: 0.3200375437736511
Batch 11/64 loss: 0.3280773162841797
Batch 12/64 loss: 0.32917237281799316
Batch 13/64 loss: 0.3235565423965454
Batch 14/64 loss: 0.32728123664855957
Batch 15/64 loss: 0.3312988877296448
Batch 16/64 loss: 0.3264937400817871
Batch 17/64 loss: 0.3351757526397705
Batch 18/64 loss: 0.3224183917045593
Batch 19/64 loss: 0.32755279541015625
Batch 20/64 loss: 0.32947373390197754
Batch 21/64 loss: 0.32220911979675293
Batch 22/64 loss: 0.3244495391845703
Batch 23/64 loss: 0.3249320983886719
Batch 24/64 loss: 0.32363176345825195
Batch 25/64 loss: 0.3225860595703125
Batch 26/64 loss: 0.33113765716552734
Batch 27/64 loss: 0.32696443796157837
Batch 28/64 loss: 0.3342301845550537
Batch 29/64 loss: 0.33248043060302734
Batch 30/64 loss: 0.33385396003723145
Batch 31/64 loss: 0.32362937927246094
Batch 32/64 loss: 0.33049529790878296
Batch 33/64 loss: 0.3313314914703369
Batch 34/64 loss: 0.3317418098449707
Batch 35/64 loss: 0.3306646943092346
Batch 36/64 loss: 0.3256436586380005
Batch 37/64 loss: 0.3274252414703369
Batch 38/64 loss: 0.330064058303833
Batch 39/64 loss: 0.32692623138427734
Batch 40/64 loss: 0.329143226146698
Batch 41/64 loss: 0.3336832523345947
Batch 42/64 loss: 0.3295917510986328
Batch 43/64 loss: 0.3320697546005249
Batch 44/64 loss: 0.33860456943511963
Batch 45/64 loss: 0.3231280446052551
Batch 46/64 loss: 0.3292921781539917
Batch 47/64 loss: 0.3251751661300659
Batch 48/64 loss: 0.33852672576904297
Batch 49/64 loss: 0.32593488693237305
Batch 50/64 loss: 0.32333827018737793
Batch 51/64 loss: 0.33636558055877686
Batch 52/64 loss: 0.3252146244049072
Batch 53/64 loss: 0.32776302099227905
Batch 54/64 loss: 0.3333911895751953
Batch 55/64 loss: 0.32956165075302124
Batch 56/64 loss: 0.33501988649368286
Batch 57/64 loss: 0.32543396949768066
Batch 58/64 loss: 0.33510440587997437
Batch 59/64 loss: 0.3196462392807007
Batch 60/64 loss: 0.32710254192352295
Batch 61/64 loss: 0.322643518447876
Batch 62/64 loss: 0.32513153553009033
Batch 63/64 loss: 0.3301771879196167
Batch 64/64 loss: 0.3271371126174927
Epoch 219  Train loss: 0.328730434997409  Val loss: 0.3405227130630991
Saving best model, epoch: 219
Epoch 220
-------------------------------
Batch 1/64 loss: 0.31959688663482666
Batch 2/64 loss: 0.32977449893951416
Batch 3/64 loss: 0.32504332065582275
Batch 4/64 loss: 0.3291202187538147
Batch 5/64 loss: 0.3238382339477539
Batch 6/64 loss: 0.32437318563461304
Batch 7/64 loss: 0.33198869228363037
Batch 8/64 loss: 0.3351074457168579
Batch 9/64 loss: 0.33549684286117554
Batch 10/64 loss: 0.33385729789733887
Batch 11/64 loss: 0.3359518051147461
Batch 12/64 loss: 0.32763803005218506
Batch 13/64 loss: 0.3274938464164734
Batch 14/64 loss: 0.3203054666519165
Batch 15/64 loss: 0.3298753499984741
Batch 16/64 loss: 0.3296518325805664
Batch 17/64 loss: 0.32763803005218506
Batch 18/64 loss: 0.32997894287109375
Batch 19/64 loss: 0.3234076499938965
Batch 20/64 loss: 0.33282947540283203
Batch 21/64 loss: 0.3235360383987427
Batch 22/64 loss: 0.32978981733322144
Batch 23/64 loss: 0.3251187801361084
Batch 24/64 loss: 0.3322828412055969
Batch 25/64 loss: 0.33143937587738037
Batch 26/64 loss: 0.33080923557281494
Batch 27/64 loss: 0.33157050609588623
Batch 28/64 loss: 0.32485783100128174
Batch 29/64 loss: 0.3243284821510315
Batch 30/64 loss: 0.33484888076782227
Batch 31/64 loss: 0.3279682397842407
Batch 32/64 loss: 0.3305332660675049
Batch 33/64 loss: 0.3215982913970947
Batch 34/64 loss: 0.32090944051742554
Batch 35/64 loss: 0.3285309672355652
Batch 36/64 loss: 0.32436418533325195
Batch 37/64 loss: 0.3267800807952881
Batch 38/64 loss: 0.329181432723999
Batch 39/64 loss: 0.33063966035842896
Batch 40/64 loss: 0.3276571035385132
Batch 41/64 loss: 0.3273584246635437
Batch 42/64 loss: 0.3308899402618408
Batch 43/64 loss: 0.32690757513046265
Batch 44/64 loss: 0.3321930766105652
Batch 45/64 loss: 0.32172030210494995
Batch 46/64 loss: 0.32453954219818115
Batch 47/64 loss: 0.33241939544677734
Batch 48/64 loss: 0.326077938079834
Batch 49/64 loss: 0.3268836736679077
Batch 50/64 loss: 0.32828259468078613
Batch 51/64 loss: 0.3336089849472046
Batch 52/64 loss: 0.33523815870285034
Batch 53/64 loss: 0.324321985244751
Batch 54/64 loss: 0.334023654460907
Batch 55/64 loss: 0.327395498752594
Batch 56/64 loss: 0.338381290435791
Batch 57/64 loss: 0.3295562267303467
Batch 58/64 loss: 0.3300850987434387
Batch 59/64 loss: 0.33632081747055054
Batch 60/64 loss: 0.3276681900024414
Batch 61/64 loss: 0.3280230760574341
Batch 62/64 loss: 0.3208444118499756
Batch 63/64 loss: 0.3284362554550171
Batch 64/64 loss: 0.3319433927536011
Epoch 220  Train loss: 0.32862502219630224  Val loss: 0.3409720986979114
Epoch 221
-------------------------------
Batch 1/64 loss: 0.3296165466308594
Batch 2/64 loss: 0.33259034156799316
Batch 3/64 loss: 0.3315442204475403
Batch 4/64 loss: 0.3262298107147217
Batch 5/64 loss: 0.3276882767677307
Batch 6/64 loss: 0.32718348503112793
Batch 7/64 loss: 0.3277508020401001
Batch 8/64 loss: 0.33428025245666504
Batch 9/64 loss: 0.32038289308547974
Batch 10/64 loss: 0.3303430676460266
Batch 11/64 loss: 0.32880377769470215
Batch 12/64 loss: 0.32768869400024414
Batch 13/64 loss: 0.3286284804344177
Batch 14/64 loss: 0.3244905471801758
Batch 15/64 loss: 0.32627010345458984
Batch 16/64 loss: 0.3284516930580139
Batch 17/64 loss: 0.3257838487625122
Batch 18/64 loss: 0.3311920166015625
Batch 19/64 loss: 0.32653188705444336
Batch 20/64 loss: 0.32986980676651
Batch 21/64 loss: 0.32769739627838135
Batch 22/64 loss: 0.3266645669937134
Batch 23/64 loss: 0.3285846710205078
Batch 24/64 loss: 0.3272464871406555
Batch 25/64 loss: 0.32964348793029785
Batch 26/64 loss: 0.3264772891998291
Batch 27/64 loss: 0.3190705180168152
Batch 28/64 loss: 0.32311904430389404
Batch 29/64 loss: 0.32990187406539917
Batch 30/64 loss: 0.32210588455200195
Batch 31/64 loss: 0.32347023487091064
Batch 32/64 loss: 0.33071714639663696
Batch 33/64 loss: 0.3266802430152893
Batch 34/64 loss: 0.3206776976585388
Batch 35/64 loss: 0.33611708879470825
Batch 36/64 loss: 0.32578766345977783
Batch 37/64 loss: 0.3368598222732544
Batch 38/64 loss: 0.33448326587677
Batch 39/64 loss: 0.3260178565979004
Batch 40/64 loss: 0.32755380868911743
Batch 41/64 loss: 0.3270198106765747
Batch 42/64 loss: 0.32648879289627075
Batch 43/64 loss: 0.32410728931427
Batch 44/64 loss: 0.32972389459609985
Batch 45/64 loss: 0.33035504817962646
Batch 46/64 loss: 0.33337652683258057
Batch 47/64 loss: 0.33283495903015137
Batch 48/64 loss: 0.3311563730239868
Batch 49/64 loss: 0.3387985825538635
Batch 50/64 loss: 0.32764172554016113
Batch 51/64 loss: 0.3277474045753479
Batch 52/64 loss: 0.3315994143486023
Batch 53/64 loss: 0.328792929649353
Batch 54/64 loss: 0.3299674987792969
Batch 55/64 loss: 0.32489609718322754
Batch 56/64 loss: 0.32794851064682007
Batch 57/64 loss: 0.33151906728744507
Batch 58/64 loss: 0.3363356590270996
Batch 59/64 loss: 0.3301389217376709
Batch 60/64 loss: 0.33348989486694336
Batch 61/64 loss: 0.33341550827026367
Batch 62/64 loss: 0.33174872398376465
Batch 63/64 loss: 0.325325608253479
Batch 64/64 loss: 0.3303396701812744
Epoch 221  Train loss: 0.3287275230183321  Val loss: 0.3408784239562516
Epoch 222
-------------------------------
Batch 1/64 loss: 0.32407188415527344
Batch 2/64 loss: 0.3279222846031189
Batch 3/64 loss: 0.32982051372528076
Batch 4/64 loss: 0.33213168382644653
Batch 5/64 loss: 0.3126220703125
Batch 6/64 loss: 0.33133506774902344
Batch 7/64 loss: 0.3332477807998657
Batch 8/64 loss: 0.31923621892929077
Batch 9/64 loss: 0.3296957015991211
Batch 10/64 loss: 0.32332348823547363
Batch 11/64 loss: 0.331856906414032
Batch 12/64 loss: 0.3229752779006958
Batch 13/64 loss: 0.3227737545967102
Batch 14/64 loss: 0.33416813611984253
Batch 15/64 loss: 0.3244948387145996
Batch 16/64 loss: 0.3295367360115051
Batch 17/64 loss: 0.33747684955596924
Batch 18/64 loss: 0.3292217254638672
Batch 19/64 loss: 0.32337433099746704
Batch 20/64 loss: 0.3247537612915039
Batch 21/64 loss: 0.3378826975822449
Batch 22/64 loss: 0.32177412509918213
Batch 23/64 loss: 0.32386648654937744
Batch 24/64 loss: 0.33230698108673096
Batch 25/64 loss: 0.32311129570007324
Batch 26/64 loss: 0.3328912854194641
Batch 27/64 loss: 0.3197585344314575
Batch 28/64 loss: 0.3242220878601074
Batch 29/64 loss: 0.3360246419906616
Batch 30/64 loss: 0.3295830488204956
Batch 31/64 loss: 0.3265131115913391
Batch 32/64 loss: 0.3273271322250366
Batch 33/64 loss: 0.32869386672973633
Batch 34/64 loss: 0.3315063714981079
Batch 35/64 loss: 0.326974093914032
Batch 36/64 loss: 0.3327944874763489
Batch 37/64 loss: 0.33183753490448
Batch 38/64 loss: 0.33324116468429565
Batch 39/64 loss: 0.3306230306625366
Batch 40/64 loss: 0.3316642642021179
Batch 41/64 loss: 0.3266196846961975
Batch 42/64 loss: 0.33103466033935547
Batch 43/64 loss: 0.32950687408447266
Batch 44/64 loss: 0.33225488662719727
Batch 45/64 loss: 0.3233588933944702
Batch 46/64 loss: 0.32681703567504883
Batch 47/64 loss: 0.33146029710769653
Batch 48/64 loss: 0.32014894485473633
Batch 49/64 loss: 0.32811689376831055
Batch 50/64 loss: 0.33463025093078613
Batch 51/64 loss: 0.3259037733078003
Batch 52/64 loss: 0.33370691537857056
Batch 53/64 loss: 0.32901930809020996
Batch 54/64 loss: 0.33484750986099243
Batch 55/64 loss: 0.3316076993942261
Batch 56/64 loss: 0.3266567587852478
Batch 57/64 loss: 0.3337280750274658
Batch 58/64 loss: 0.33457982540130615
Batch 59/64 loss: 0.3290520906448364
Batch 60/64 loss: 0.3288388252258301
Batch 61/64 loss: 0.32458198070526123
Batch 62/64 loss: 0.3224044442176819
Batch 63/64 loss: 0.32674872875213623
Batch 64/64 loss: 0.33600693941116333
Epoch 222  Train loss: 0.3285374872824725  Val loss: 0.34075562077289595
Epoch 223
-------------------------------
Batch 1/64 loss: 0.32392579317092896
Batch 2/64 loss: 0.3245428800582886
Batch 3/64 loss: 0.33389103412628174
Batch 4/64 loss: 0.3222852945327759
Batch 5/64 loss: 0.33350956439971924
Batch 6/64 loss: 0.327062726020813
Batch 7/64 loss: 0.31929194927215576
Batch 8/64 loss: 0.3233206272125244
Batch 9/64 loss: 0.33291614055633545
Batch 10/64 loss: 0.32404088973999023
Batch 11/64 loss: 0.33297449350357056
Batch 12/64 loss: 0.32003092765808105
Batch 13/64 loss: 0.31926894187927246
Batch 14/64 loss: 0.32421261072158813
Batch 15/64 loss: 0.3395810127258301
Batch 16/64 loss: 0.3248622417449951
Batch 17/64 loss: 0.3294792175292969
Batch 18/64 loss: 0.3309398293495178
Batch 19/64 loss: 0.3374429941177368
Batch 20/64 loss: 0.32827669382095337
Batch 21/64 loss: 0.33056771755218506
Batch 22/64 loss: 0.3290258049964905
Batch 23/64 loss: 0.33957648277282715
Batch 24/64 loss: 0.3281906843185425
Batch 25/64 loss: 0.32375407218933105
Batch 26/64 loss: 0.32179415225982666
Batch 27/64 loss: 0.32983773946762085
Batch 28/64 loss: 0.32495737075805664
Batch 29/64 loss: 0.32335013151168823
Batch 30/64 loss: 0.3373638391494751
Batch 31/64 loss: 0.33550310134887695
Batch 32/64 loss: 0.33295738697052
Batch 33/64 loss: 0.3323896527290344
Batch 34/64 loss: 0.3247440457344055
Batch 35/64 loss: 0.3263556957244873
Batch 36/64 loss: 0.32273781299591064
Batch 37/64 loss: 0.3237724304199219
Batch 38/64 loss: 0.3310662508010864
Batch 39/64 loss: 0.3243434429168701
Batch 40/64 loss: 0.32758504152297974
Batch 41/64 loss: 0.3249572515487671
Batch 42/64 loss: 0.32524919509887695
Batch 43/64 loss: 0.3246757984161377
Batch 44/64 loss: 0.3304305076599121
Batch 45/64 loss: 0.3331012725830078
Batch 46/64 loss: 0.32769179344177246
Batch 47/64 loss: 0.33464860916137695
Batch 48/64 loss: 0.32663917541503906
Batch 49/64 loss: 0.3311110734939575
Batch 50/64 loss: 0.3293468952178955
Batch 51/64 loss: 0.3293875455856323
Batch 52/64 loss: 0.33000338077545166
Batch 53/64 loss: 0.3239837884902954
Batch 54/64 loss: 0.3240838646888733
Batch 55/64 loss: 0.3325461745262146
Batch 56/64 loss: 0.33157992362976074
Batch 57/64 loss: 0.3247182369232178
Batch 58/64 loss: 0.3347474932670593
Batch 59/64 loss: 0.33066344261169434
Batch 60/64 loss: 0.3294968008995056
Batch 61/64 loss: 0.33475691080093384
Batch 62/64 loss: 0.3266634941101074
Batch 63/64 loss: 0.32754504680633545
Batch 64/64 loss: 0.3185039162635803
Epoch 223  Train loss: 0.32829230322557335  Val loss: 0.3407746180635957
Epoch 224
-------------------------------
Batch 1/64 loss: 0.32907164096832275
Batch 2/64 loss: 0.3244086503982544
Batch 3/64 loss: 0.32762396335601807
Batch 4/64 loss: 0.3246268033981323
Batch 5/64 loss: 0.3226214647293091
Batch 6/64 loss: 0.3286052942276001
Batch 7/64 loss: 0.33034747838974
Batch 8/64 loss: 0.3232857584953308
Batch 9/64 loss: 0.32876497507095337
Batch 10/64 loss: 0.327677845954895
Batch 11/64 loss: 0.3237925171852112
Batch 12/64 loss: 0.3245229721069336
Batch 13/64 loss: 0.3309209942817688
Batch 14/64 loss: 0.33874309062957764
Batch 15/64 loss: 0.32964348793029785
Batch 16/64 loss: 0.3230741024017334
Batch 17/64 loss: 0.3236778974533081
Batch 18/64 loss: 0.340567409992218
Batch 19/64 loss: 0.33155643939971924
Batch 20/64 loss: 0.32365548610687256
Batch 21/64 loss: 0.3319939374923706
Batch 22/64 loss: 0.32618826627731323
Batch 23/64 loss: 0.32747310400009155
Batch 24/64 loss: 0.3204149007797241
Batch 25/64 loss: 0.3315852880477905
Batch 26/64 loss: 0.3252412676811218
Batch 27/64 loss: 0.3310110569000244
Batch 28/64 loss: 0.32524800300598145
Batch 29/64 loss: 0.32520896196365356
Batch 30/64 loss: 0.32696056365966797
Batch 31/64 loss: 0.3262608051300049
Batch 32/64 loss: 0.326759934425354
Batch 33/64 loss: 0.3259350061416626
Batch 34/64 loss: 0.32997840642929077
Batch 35/64 loss: 0.32731372117996216
Batch 36/64 loss: 0.3306582570075989
Batch 37/64 loss: 0.3232743740081787
Batch 38/64 loss: 0.32927072048187256
Batch 39/64 loss: 0.32531511783599854
Batch 40/64 loss: 0.3240910768508911
Batch 41/64 loss: 0.32657551765441895
Batch 42/64 loss: 0.32754743099212646
Batch 43/64 loss: 0.33051908016204834
Batch 44/64 loss: 0.3244435787200928
Batch 45/64 loss: 0.3263949751853943
Batch 46/64 loss: 0.3260877728462219
Batch 47/64 loss: 0.32743263244628906
Batch 48/64 loss: 0.33455324172973633
Batch 49/64 loss: 0.3226912021636963
Batch 50/64 loss: 0.3347088098526001
Batch 51/64 loss: 0.32966530323028564
Batch 52/64 loss: 0.32587993144989014
Batch 53/64 loss: 0.3284667730331421
Batch 54/64 loss: 0.33558738231658936
Batch 55/64 loss: 0.3335378170013428
Batch 56/64 loss: 0.32729673385620117
Batch 57/64 loss: 0.32523268461227417
Batch 58/64 loss: 0.3240797519683838
Batch 59/64 loss: 0.32851457595825195
Batch 60/64 loss: 0.32394689321517944
Batch 61/64 loss: 0.3249303698539734
Batch 62/64 loss: 0.32599884271621704
Batch 63/64 loss: 0.33638644218444824
Batch 64/64 loss: 0.3327862620353699
Epoch 224  Train loss: 0.327802956571766  Val loss: 0.3412673502033928
Epoch 225
-------------------------------
Batch 1/64 loss: 0.3199021816253662
Batch 2/64 loss: 0.32702869176864624
Batch 3/64 loss: 0.33471953868865967
Batch 4/64 loss: 0.33116477727890015
Batch 5/64 loss: 0.33198946714401245
Batch 6/64 loss: 0.3332241177558899
Batch 7/64 loss: 0.32107383012771606
Batch 8/64 loss: 0.3281869888305664
Batch 9/64 loss: 0.3201445937156677
Batch 10/64 loss: 0.3279224634170532
Batch 11/64 loss: 0.33800673484802246
Batch 12/64 loss: 0.32817959785461426
Batch 13/64 loss: 0.3283653259277344
Batch 14/64 loss: 0.3369896411895752
Batch 15/64 loss: 0.32879579067230225
Batch 16/64 loss: 0.33220410346984863
Batch 17/64 loss: 0.32607948780059814
Batch 18/64 loss: 0.3386826515197754
Batch 19/64 loss: 0.327972948551178
Batch 20/64 loss: 0.3303236961364746
Batch 21/64 loss: 0.32718145847320557
Batch 22/64 loss: 0.32688796520233154
Batch 23/64 loss: 0.3199760317802429
Batch 24/64 loss: 0.32622694969177246
Batch 25/64 loss: 0.3264751434326172
Batch 26/64 loss: 0.32257360219955444
Batch 27/64 loss: 0.3243434429168701
Batch 28/64 loss: 0.3261291980743408
Batch 29/64 loss: 0.32893019914627075
Batch 30/64 loss: 0.33634281158447266
Batch 31/64 loss: 0.33576685190200806
Batch 32/64 loss: 0.3274446725845337
Batch 33/64 loss: 0.3310842514038086
Batch 34/64 loss: 0.3319101929664612
Batch 35/64 loss: 0.3261646628379822
Batch 36/64 loss: 0.32228100299835205
Batch 37/64 loss: 0.3336210250854492
Batch 38/64 loss: 0.32441818714141846
Batch 39/64 loss: 0.31863701343536377
Batch 40/64 loss: 0.3266334533691406
Batch 41/64 loss: 0.33218979835510254
Batch 42/64 loss: 0.31911522150039673
Batch 43/64 loss: 0.33086538314819336
Batch 44/64 loss: 0.32093822956085205
Batch 45/64 loss: 0.32324492931365967
Batch 46/64 loss: 0.3307730555534363
Batch 47/64 loss: 0.32621681690216064
Batch 48/64 loss: 0.330172598361969
Batch 49/64 loss: 0.33238035440444946
Batch 50/64 loss: 0.3364750146865845
Batch 51/64 loss: 0.3242015242576599
Batch 52/64 loss: 0.3240852355957031
Batch 53/64 loss: 0.32224178314208984
Batch 54/64 loss: 0.3254632353782654
Batch 55/64 loss: 0.3348121643066406
Batch 56/64 loss: 0.32745230197906494
Batch 57/64 loss: 0.33357226848602295
Batch 58/64 loss: 0.3310880661010742
Batch 59/64 loss: 0.32536888122558594
Batch 60/64 loss: 0.3322228193283081
Batch 61/64 loss: 0.33087146282196045
Batch 62/64 loss: 0.3307971954345703
Batch 63/64 loss: 0.33072423934936523
Batch 64/64 loss: 0.33429938554763794
Epoch 225  Train loss: 0.32847030373180613  Val loss: 0.3404874705367072
Saving best model, epoch: 225
Epoch 226
-------------------------------
Batch 1/64 loss: 0.3274688124656677
Batch 2/64 loss: 0.3368416428565979
Batch 3/64 loss: 0.3282895088195801
Batch 4/64 loss: 0.3234752416610718
Batch 5/64 loss: 0.32407939434051514
Batch 6/64 loss: 0.32635563611984253
Batch 7/64 loss: 0.3268073797225952
Batch 8/64 loss: 0.3218359351158142
Batch 9/64 loss: 0.32971441745758057
Batch 10/64 loss: 0.32522547245025635
Batch 11/64 loss: 0.3243260383605957
Batch 12/64 loss: 0.33537590503692627
Batch 13/64 loss: 0.3254778981208801
Batch 14/64 loss: 0.32845795154571533
Batch 15/64 loss: 0.3345784544944763
Batch 16/64 loss: 0.3264353275299072
Batch 17/64 loss: 0.32555341720581055
Batch 18/64 loss: 0.3206479549407959
Batch 19/64 loss: 0.32798635959625244
Batch 20/64 loss: 0.3158736228942871
Batch 21/64 loss: 0.3205244541168213
Batch 22/64 loss: 0.3267509341239929
Batch 23/64 loss: 0.33317995071411133
Batch 24/64 loss: 0.3266031742095947
Batch 25/64 loss: 0.3277111053466797
Batch 26/64 loss: 0.32640939950942993
Batch 27/64 loss: 0.32476890087127686
Batch 28/64 loss: 0.32568657398223877
Batch 29/64 loss: 0.3234267830848694
Batch 30/64 loss: 0.32485926151275635
Batch 31/64 loss: 0.31927037239074707
Batch 32/64 loss: 0.32830727100372314
Batch 33/64 loss: 0.32925039529800415
Batch 34/64 loss: 0.3287672996520996
Batch 35/64 loss: 0.33399510383605957
Batch 36/64 loss: 0.3367680311203003
Batch 37/64 loss: 0.327210009098053
Batch 38/64 loss: 0.3265193700790405
Batch 39/64 loss: 0.32859891653060913
Batch 40/64 loss: 0.32980602979660034
Batch 41/64 loss: 0.3242497444152832
Batch 42/64 loss: 0.3281749486923218
Batch 43/64 loss: 0.32555556297302246
Batch 44/64 loss: 0.3225262761116028
Batch 45/64 loss: 0.32366156578063965
Batch 46/64 loss: 0.3337753415107727
Batch 47/64 loss: 0.3326641321182251
Batch 48/64 loss: 0.3404119610786438
Batch 49/64 loss: 0.3251081705093384
Batch 50/64 loss: 0.32363075017929077
Batch 51/64 loss: 0.33327001333236694
Batch 52/64 loss: 0.3253439664840698
Batch 53/64 loss: 0.32347285747528076
Batch 54/64 loss: 0.3312487006187439
Batch 55/64 loss: 0.3262776732444763
Batch 56/64 loss: 0.3262132406234741
Batch 57/64 loss: 0.33344459533691406
Batch 58/64 loss: 0.325617253780365
Batch 59/64 loss: 0.3229995369911194
Batch 60/64 loss: 0.33601146936416626
Batch 61/64 loss: 0.32865989208221436
Batch 62/64 loss: 0.32869410514831543
Batch 63/64 loss: 0.3247692584991455
Batch 64/64 loss: 0.32564079761505127
Epoch 226  Train loss: 0.3274232364168354  Val loss: 0.34011540195786255
Saving best model, epoch: 226
Epoch 227
-------------------------------
Batch 1/64 loss: 0.3266562223434448
Batch 2/64 loss: 0.3311648368835449
Batch 3/64 loss: 0.3343464136123657
Batch 4/64 loss: 0.324399471282959
Batch 5/64 loss: 0.32303309440612793
Batch 6/64 loss: 0.32572680711746216
Batch 7/64 loss: 0.3270190954208374
Batch 8/64 loss: 0.33123624324798584
Batch 9/64 loss: 0.33486413955688477
Batch 10/64 loss: 0.33203601837158203
Batch 11/64 loss: 0.3210660219192505
Batch 12/64 loss: 0.33016467094421387
Batch 13/64 loss: 0.324113130569458
Batch 14/64 loss: 0.33117735385894775
Batch 15/64 loss: 0.32550346851348877
Batch 16/64 loss: 0.3221666216850281
Batch 17/64 loss: 0.3224900960922241
Batch 18/64 loss: 0.3262450695037842
Batch 19/64 loss: 0.32614195346832275
Batch 20/64 loss: 0.32729101181030273
Batch 21/64 loss: 0.32679080963134766
Batch 22/64 loss: 0.32279419898986816
Batch 23/64 loss: 0.3263665437698364
Batch 24/64 loss: 0.32120585441589355
Batch 25/64 loss: 0.33365583419799805
Batch 26/64 loss: 0.3340604901313782
Batch 27/64 loss: 0.3272498846054077
Batch 28/64 loss: 0.3263516426086426
Batch 29/64 loss: 0.32641249895095825
Batch 30/64 loss: 0.32253968715667725
Batch 31/64 loss: 0.3342301845550537
Batch 32/64 loss: 0.3279415965080261
Batch 33/64 loss: 0.32214564085006714
Batch 34/64 loss: 0.3233906030654907
Batch 35/64 loss: 0.3204999566078186
Batch 36/64 loss: 0.32323014736175537
Batch 37/64 loss: 0.3290415406227112
Batch 38/64 loss: 0.33181852102279663
Batch 39/64 loss: 0.32276129722595215
Batch 40/64 loss: 0.3270770311355591
Batch 41/64 loss: 0.3238387703895569
Batch 42/64 loss: 0.34018218517303467
Batch 43/64 loss: 0.329456627368927
Batch 44/64 loss: 0.3269144296646118
Batch 45/64 loss: 0.32135337591171265
Batch 46/64 loss: 0.3284110426902771
Batch 47/64 loss: 0.32254624366760254
Batch 48/64 loss: 0.3235126733779907
Batch 49/64 loss: 0.3260002136230469
Batch 50/64 loss: 0.3285095691680908
Batch 51/64 loss: 0.32803577184677124
Batch 52/64 loss: 0.32241368293762207
Batch 53/64 loss: 0.3381882905960083
Batch 54/64 loss: 0.32737797498703003
Batch 55/64 loss: 0.3213357925415039
Batch 56/64 loss: 0.32701176404953003
Batch 57/64 loss: 0.32330214977264404
Batch 58/64 loss: 0.3247106075286865
Batch 59/64 loss: 0.32709670066833496
Batch 60/64 loss: 0.33884406089782715
Batch 61/64 loss: 0.33631014823913574
Batch 62/64 loss: 0.3285787105560303
Batch 63/64 loss: 0.33060920238494873
Batch 64/64 loss: 0.3195907473564148
Epoch 227  Train loss: 0.32722570592281863  Val loss: 0.341159394516568
Epoch 228
-------------------------------
Batch 1/64 loss: 0.3308180570602417
Batch 2/64 loss: 0.3238856792449951
Batch 3/64 loss: 0.32221150398254395
Batch 4/64 loss: 0.32126498222351074
Batch 5/64 loss: 0.3259977102279663
Batch 6/64 loss: 0.3233807682991028
Batch 7/64 loss: 0.3248939514160156
Batch 8/64 loss: 0.3244149684906006
Batch 9/64 loss: 0.3277142643928528
Batch 10/64 loss: 0.330652117729187
Batch 11/64 loss: 0.3333941102027893
Batch 12/64 loss: 0.3259732723236084
Batch 13/64 loss: 0.32933783531188965
Batch 14/64 loss: 0.32597553730010986
Batch 15/64 loss: 0.3245277404785156
Batch 16/64 loss: 0.3300061821937561
Batch 17/64 loss: 0.3245495557785034
Batch 18/64 loss: 0.32230621576309204
Batch 19/64 loss: 0.3246200680732727
Batch 20/64 loss: 0.32357561588287354
Batch 21/64 loss: 0.31965380907058716
Batch 22/64 loss: 0.32134318351745605
Batch 23/64 loss: 0.320062518119812
Batch 24/64 loss: 0.3281506299972534
Batch 25/64 loss: 0.32023370265960693
Batch 26/64 loss: 0.32082492113113403
Batch 27/64 loss: 0.32838958501815796
Batch 28/64 loss: 0.33228009939193726
Batch 29/64 loss: 0.3251166343688965
Batch 30/64 loss: 0.3321197032928467
Batch 31/64 loss: 0.329359769821167
Batch 32/64 loss: 0.3311814069747925
Batch 33/64 loss: 0.32700562477111816
Batch 34/64 loss: 0.3292628526687622
Batch 35/64 loss: 0.3314192295074463
Batch 36/64 loss: 0.3311762809753418
Batch 37/64 loss: 0.3236701488494873
Batch 38/64 loss: 0.3293781280517578
Batch 39/64 loss: 0.3337864279747009
Batch 40/64 loss: 0.3278352618217468
Batch 41/64 loss: 0.3184688687324524
Batch 42/64 loss: 0.3297296166419983
Batch 43/64 loss: 0.33596986532211304
Batch 44/64 loss: 0.3219287395477295
Batch 45/64 loss: 0.3311934471130371
Batch 46/64 loss: 0.3308236598968506
Batch 47/64 loss: 0.32733768224716187
Batch 48/64 loss: 0.33040595054626465
Batch 49/64 loss: 0.32941269874572754
Batch 50/64 loss: 0.3199707269668579
Batch 51/64 loss: 0.32786476612091064
Batch 52/64 loss: 0.33040690422058105
Batch 53/64 loss: 0.3239290714263916
Batch 54/64 loss: 0.3283594250679016
Batch 55/64 loss: 0.33325546979904175
Batch 56/64 loss: 0.3378238081932068
Batch 57/64 loss: 0.32956063747406006
Batch 58/64 loss: 0.3270145058631897
Batch 59/64 loss: 0.31917810440063477
Batch 60/64 loss: 0.3278179168701172
Batch 61/64 loss: 0.3250928521156311
Batch 62/64 loss: 0.3229266405105591
Batch 63/64 loss: 0.3339551091194153
Batch 64/64 loss: 0.3330473303794861
Epoch 228  Train loss: 0.327120972848406  Val loss: 0.3408895288546061
Epoch 229
-------------------------------
Batch 1/64 loss: 0.32580798864364624
Batch 2/64 loss: 0.3280273675918579
Batch 3/64 loss: 0.32215696573257446
Batch 4/64 loss: 0.31845569610595703
Batch 5/64 loss: 0.3313354253768921
Batch 6/64 loss: 0.3312956690788269
Batch 7/64 loss: 0.325944185256958
Batch 8/64 loss: 0.33134233951568604
Batch 9/64 loss: 0.3277914524078369
Batch 10/64 loss: 0.32385629415512085
Batch 11/64 loss: 0.3199041485786438
Batch 12/64 loss: 0.32113540172576904
Batch 13/64 loss: 0.32766425609588623
Batch 14/64 loss: 0.3176560401916504
Batch 15/64 loss: 0.33500003814697266
Batch 16/64 loss: 0.3234521746635437
Batch 17/64 loss: 0.32845592498779297
Batch 18/64 loss: 0.3279855251312256
Batch 19/64 loss: 0.3252286911010742
Batch 20/64 loss: 0.3242730498313904
Batch 21/64 loss: 0.33872097730636597
Batch 22/64 loss: 0.3178558349609375
Batch 23/64 loss: 0.3238811492919922
Batch 24/64 loss: 0.3241349458694458
Batch 25/64 loss: 0.32139503955841064
Batch 26/64 loss: 0.3351353406906128
Batch 27/64 loss: 0.32359760999679565
Batch 28/64 loss: 0.3218672275543213
Batch 29/64 loss: 0.32717132568359375
Batch 30/64 loss: 0.3332463502883911
Batch 31/64 loss: 0.3287040591239929
Batch 32/64 loss: 0.3257869482040405
Batch 33/64 loss: 0.32448768615722656
Batch 34/64 loss: 0.32569420337677
Batch 35/64 loss: 0.32947325706481934
Batch 36/64 loss: 0.3331877589225769
Batch 37/64 loss: 0.3233345150947571
Batch 38/64 loss: 0.3284417390823364
Batch 39/64 loss: 0.3340885043144226
Batch 40/64 loss: 0.33934760093688965
Batch 41/64 loss: 0.3304274082183838
Batch 42/64 loss: 0.3219064474105835
Batch 43/64 loss: 0.3237958550453186
Batch 44/64 loss: 0.3266749382019043
Batch 45/64 loss: 0.3259841203689575
Batch 46/64 loss: 0.3283050060272217
Batch 47/64 loss: 0.3226989507675171
Batch 48/64 loss: 0.33520787954330444
Batch 49/64 loss: 0.32298457622528076
Batch 50/64 loss: 0.3309705853462219
Batch 51/64 loss: 0.32676053047180176
Batch 52/64 loss: 0.33181875944137573
Batch 53/64 loss: 0.3255823850631714
Batch 54/64 loss: 0.32685887813568115
Batch 55/64 loss: 0.32438409328460693
Batch 56/64 loss: 0.3261260986328125
Batch 57/64 loss: 0.320903480052948
Batch 58/64 loss: 0.3331223726272583
Batch 59/64 loss: 0.3324720859527588
Batch 60/64 loss: 0.3370360732078552
Batch 61/64 loss: 0.33183544874191284
Batch 62/64 loss: 0.3323283791542053
Batch 63/64 loss: 0.3300974369049072
Batch 64/64 loss: 0.32270509004592896
Epoch 229  Train loss: 0.32731970688875983  Val loss: 0.3414978022427903
Epoch 230
-------------------------------
Batch 1/64 loss: 0.3221426010131836
Batch 2/64 loss: 0.32740604877471924
Batch 3/64 loss: 0.3146204948425293
Batch 4/64 loss: 0.32783043384552
Batch 5/64 loss: 0.32928407192230225
Batch 6/64 loss: 0.3222699761390686
Batch 7/64 loss: 0.31870120763778687
Batch 8/64 loss: 0.3259837031364441
Batch 9/64 loss: 0.3246660828590393
Batch 10/64 loss: 0.3294121026992798
Batch 11/64 loss: 0.3237312436103821
Batch 12/64 loss: 0.3283121585845947
Batch 13/64 loss: 0.325425386428833
Batch 14/64 loss: 0.3202016353607178
Batch 15/64 loss: 0.33886462450027466
Batch 16/64 loss: 0.3269471526145935
Batch 17/64 loss: 0.32294297218322754
Batch 18/64 loss: 0.3250221014022827
Batch 19/64 loss: 0.3218398094177246
Batch 20/64 loss: 0.32853662967681885
Batch 21/64 loss: 0.3304385542869568
Batch 22/64 loss: 0.33329570293426514
Batch 23/64 loss: 0.320621132850647
Batch 24/64 loss: 0.3291424512863159
Batch 25/64 loss: 0.33165764808654785
Batch 26/64 loss: 0.33280158042907715
Batch 27/64 loss: 0.32991814613342285
Batch 28/64 loss: 0.3253973722457886
Batch 29/64 loss: 0.3299828767776489
Batch 30/64 loss: 0.3278777003288269
Batch 31/64 loss: 0.330173134803772
Batch 32/64 loss: 0.3214280605316162
Batch 33/64 loss: 0.32471054792404175
Batch 34/64 loss: 0.32930755615234375
Batch 35/64 loss: 0.3256146311759949
Batch 36/64 loss: 0.33110344409942627
Batch 37/64 loss: 0.3276692032814026
Batch 38/64 loss: 0.3261604309082031
Batch 39/64 loss: 0.316497802734375
Batch 40/64 loss: 0.3206963539123535
Batch 41/64 loss: 0.3210095167160034
Batch 42/64 loss: 0.3363906145095825
Batch 43/64 loss: 0.3336992859840393
Batch 44/64 loss: 0.32306885719299316
Batch 45/64 loss: 0.3281530737876892
Batch 46/64 loss: 0.32747870683670044
Batch 47/64 loss: 0.32943397760391235
Batch 48/64 loss: 0.3224394917488098
Batch 49/64 loss: 0.33332109451293945
Batch 50/64 loss: 0.33324337005615234
Batch 51/64 loss: 0.32931268215179443
Batch 52/64 loss: 0.33231329917907715
Batch 53/64 loss: 0.32318663597106934
Batch 54/64 loss: 0.3219337463378906
Batch 55/64 loss: 0.32624566555023193
Batch 56/64 loss: 0.3239971995353699
Batch 57/64 loss: 0.3243236541748047
Batch 58/64 loss: 0.33380621671676636
Batch 59/64 loss: 0.3283292055130005
Batch 60/64 loss: 0.3259435296058655
Batch 61/64 loss: 0.3346306085586548
Batch 62/64 loss: 0.33527785539627075
Batch 63/64 loss: 0.3274195194244385
Batch 64/64 loss: 0.32957249879837036
Epoch 230  Train loss: 0.3270709325285519  Val loss: 0.34038466665752976
Epoch 231
-------------------------------
Batch 1/64 loss: 0.3290340304374695
Batch 2/64 loss: 0.3234926462173462
Batch 3/64 loss: 0.3240041732788086
Batch 4/64 loss: 0.3303263187408447
Batch 5/64 loss: 0.3297920823097229
Batch 6/64 loss: 0.3290649652481079
Batch 7/64 loss: 0.3226308226585388
Batch 8/64 loss: 0.32964563369750977
Batch 9/64 loss: 0.32216477394104004
Batch 10/64 loss: 0.32984161376953125
Batch 11/64 loss: 0.3219330906867981
Batch 12/64 loss: 0.33356940746307373
Batch 13/64 loss: 0.3299763798713684
Batch 14/64 loss: 0.3244800567626953
Batch 15/64 loss: 0.3224027752876282
Batch 16/64 loss: 0.32300108671188354
Batch 17/64 loss: 0.3235902786254883
Batch 18/64 loss: 0.32712000608444214
Batch 19/64 loss: 0.32439666986465454
Batch 20/64 loss: 0.3279905319213867
Batch 21/64 loss: 0.3188821077346802
Batch 22/64 loss: 0.3233351707458496
Batch 23/64 loss: 0.3269631862640381
Batch 24/64 loss: 0.3288884162902832
Batch 25/64 loss: 0.32235580682754517
Batch 26/64 loss: 0.31620079278945923
Batch 27/64 loss: 0.3263205289840698
Batch 28/64 loss: 0.3328653573989868
Batch 29/64 loss: 0.32801735401153564
Batch 30/64 loss: 0.3334907293319702
Batch 31/64 loss: 0.32670748233795166
Batch 32/64 loss: 0.3284280300140381
Batch 33/64 loss: 0.3259636163711548
Batch 34/64 loss: 0.32309114933013916
Batch 35/64 loss: 0.3342471122741699
Batch 36/64 loss: 0.32513827085494995
Batch 37/64 loss: 0.32701683044433594
Batch 38/64 loss: 0.33567333221435547
Batch 39/64 loss: 0.3239924907684326
Batch 40/64 loss: 0.33260172605514526
Batch 41/64 loss: 0.32958507537841797
Batch 42/64 loss: 0.3298265337944031
Batch 43/64 loss: 0.32677292823791504
Batch 44/64 loss: 0.33087658882141113
Batch 45/64 loss: 0.32806575298309326
Batch 46/64 loss: 0.3347254991531372
Batch 47/64 loss: 0.33142566680908203
Batch 48/64 loss: 0.33652806282043457
Batch 49/64 loss: 0.32987844944000244
Batch 50/64 loss: 0.3287774324417114
Batch 51/64 loss: 0.3277518153190613
Batch 52/64 loss: 0.3198094367980957
Batch 53/64 loss: 0.3237861394882202
Batch 54/64 loss: 0.31813621520996094
Batch 55/64 loss: 0.33121633529663086
Batch 56/64 loss: 0.32843017578125
Batch 57/64 loss: 0.3288174867630005
Batch 58/64 loss: 0.3227189779281616
Batch 59/64 loss: 0.3319370746612549
Batch 60/64 loss: 0.3259924650192261
Batch 61/64 loss: 0.3252984285354614
Batch 62/64 loss: 0.32063090801239014
Batch 63/64 loss: 0.32229936122894287
Batch 64/64 loss: 0.31849992275238037
Epoch 231  Train loss: 0.32691448763305064  Val loss: 0.33961080214411943
Saving best model, epoch: 231
Epoch 232
-------------------------------
Batch 1/64 loss: 0.3244282007217407
Batch 2/64 loss: 0.3198418617248535
Batch 3/64 loss: 0.31981760263442993
Batch 4/64 loss: 0.3287227153778076
Batch 5/64 loss: 0.32370924949645996
Batch 6/64 loss: 0.33039140701293945
Batch 7/64 loss: 0.31541967391967773
Batch 8/64 loss: 0.3281210660934448
Batch 9/64 loss: 0.33274614810943604
Batch 10/64 loss: 0.3168066143989563
Batch 11/64 loss: 0.32939356565475464
Batch 12/64 loss: 0.32842350006103516
Batch 13/64 loss: 0.32564306259155273
Batch 14/64 loss: 0.32567596435546875
Batch 15/64 loss: 0.32374507188796997
Batch 16/64 loss: 0.33247101306915283
Batch 17/64 loss: 0.32384252548217773
Batch 18/64 loss: 0.3234909176826477
Batch 19/64 loss: 0.32240307331085205
Batch 20/64 loss: 0.32929491996765137
Batch 21/64 loss: 0.32272660732269287
Batch 22/64 loss: 0.33033645153045654
Batch 23/64 loss: 0.32234692573547363
Batch 24/64 loss: 0.3315315246582031
Batch 25/64 loss: 0.32988548278808594
Batch 26/64 loss: 0.33467572927474976
Batch 27/64 loss: 0.3225926160812378
Batch 28/64 loss: 0.32109904289245605
Batch 29/64 loss: 0.3295746445655823
Batch 30/64 loss: 0.3230094313621521
Batch 31/64 loss: 0.32959020137786865
Batch 32/64 loss: 0.3310582637786865
Batch 33/64 loss: 0.3291763663291931
Batch 34/64 loss: 0.3269881010055542
Batch 35/64 loss: 0.3263533115386963
Batch 36/64 loss: 0.3252291679382324
Batch 37/64 loss: 0.3228166103363037
Batch 38/64 loss: 0.3278656601905823
Batch 39/64 loss: 0.3261602520942688
Batch 40/64 loss: 0.33204931020736694
Batch 41/64 loss: 0.3225816488265991
Batch 42/64 loss: 0.321022629737854
Batch 43/64 loss: 0.32649028301239014
Batch 44/64 loss: 0.32438725233078003
Batch 45/64 loss: 0.32533615827560425
Batch 46/64 loss: 0.3213357925415039
Batch 47/64 loss: 0.3247607946395874
Batch 48/64 loss: 0.32812929153442383
Batch 49/64 loss: 0.3247431516647339
Batch 50/64 loss: 0.3363605737686157
Batch 51/64 loss: 0.3227759599685669
Batch 52/64 loss: 0.32403117418289185
Batch 53/64 loss: 0.32052141427993774
Batch 54/64 loss: 0.3263200521469116
Batch 55/64 loss: 0.3197157382965088
Batch 56/64 loss: 0.31725573539733887
Batch 57/64 loss: 0.3304358124732971
Batch 58/64 loss: 0.3278599977493286
Batch 59/64 loss: 0.33554649353027344
Batch 60/64 loss: 0.3232995271682739
Batch 61/64 loss: 0.3288385272026062
Batch 62/64 loss: 0.33513689041137695
Batch 63/64 loss: 0.3335273265838623
Batch 64/64 loss: 0.3309861421585083
Epoch 232  Train loss: 0.3262447950886745  Val loss: 0.34036034570936485
Epoch 233
-------------------------------
Batch 1/64 loss: 0.3189765214920044
Batch 2/64 loss: 0.3217970132827759
Batch 3/64 loss: 0.319818913936615
Batch 4/64 loss: 0.32089734077453613
Batch 5/64 loss: 0.32051360607147217
Batch 6/64 loss: 0.3242102861404419
Batch 7/64 loss: 0.3256397247314453
Batch 8/64 loss: 0.323769211769104
Batch 9/64 loss: 0.3311793804168701
Batch 10/64 loss: 0.32014429569244385
Batch 11/64 loss: 0.31529128551483154
Batch 12/64 loss: 0.33458173274993896
Batch 13/64 loss: 0.3277926445007324
Batch 14/64 loss: 0.3103353977203369
Batch 15/64 loss: 0.3213099241256714
Batch 16/64 loss: 0.33396750688552856
Batch 17/64 loss: 0.325161337852478
Batch 18/64 loss: 0.3246256113052368
Batch 19/64 loss: 0.33046960830688477
Batch 20/64 loss: 0.31972599029541016
Batch 21/64 loss: 0.32563483715057373
Batch 22/64 loss: 0.32063865661621094
Batch 23/64 loss: 0.3227301239967346
Batch 24/64 loss: 0.3349452018737793
Batch 25/64 loss: 0.32739007472991943
Batch 26/64 loss: 0.32490408420562744
Batch 27/64 loss: 0.32142096757888794
Batch 28/64 loss: 0.32931220531463623
Batch 29/64 loss: 0.32848024368286133
Batch 30/64 loss: 0.34510350227355957
Batch 31/64 loss: 0.32674169540405273
Batch 32/64 loss: 0.32759106159210205
Batch 33/64 loss: 0.32724398374557495
Batch 34/64 loss: 0.3260113000869751
Batch 35/64 loss: 0.33545970916748047
Batch 36/64 loss: 0.32415449619293213
Batch 37/64 loss: 0.3376258611679077
Batch 38/64 loss: 0.32474350929260254
Batch 39/64 loss: 0.3234187364578247
Batch 40/64 loss: 0.3198503255844116
Batch 41/64 loss: 0.3247806429862976
Batch 42/64 loss: 0.33173543214797974
Batch 43/64 loss: 0.33263731002807617
Batch 44/64 loss: 0.325447678565979
Batch 45/64 loss: 0.3253765106201172
Batch 46/64 loss: 0.32581621408462524
Batch 47/64 loss: 0.3316265344619751
Batch 48/64 loss: 0.33304154872894287
Batch 49/64 loss: 0.32867878675460815
Batch 50/64 loss: 0.33200371265411377
Batch 51/64 loss: 0.3331489562988281
Batch 52/64 loss: 0.32552629709243774
Batch 53/64 loss: 0.322401762008667
Batch 54/64 loss: 0.33233392238616943
Batch 55/64 loss: 0.32904231548309326
Batch 56/64 loss: 0.3298789858818054
Batch 57/64 loss: 0.32845497131347656
Batch 58/64 loss: 0.3308178186416626
Batch 59/64 loss: 0.33178257942199707
Batch 60/64 loss: 0.3286975622177124
Batch 61/64 loss: 0.31883883476257324
Batch 62/64 loss: 0.325728178024292
Batch 63/64 loss: 0.32499319314956665
Batch 64/64 loss: 0.33323848247528076
Epoch 233  Train loss: 0.32668747481177834  Val loss: 0.3405382547181906
Epoch 234
-------------------------------
Batch 1/64 loss: 0.3251253366470337
Batch 2/64 loss: 0.3312646746635437
Batch 3/64 loss: 0.33094263076782227
Batch 4/64 loss: 0.33142316341400146
Batch 5/64 loss: 0.3288625478744507
Batch 6/64 loss: 0.33241987228393555
Batch 7/64 loss: 0.32881665229797363
Batch 8/64 loss: 0.3253939151763916
Batch 9/64 loss: 0.33378493785858154
Batch 10/64 loss: 0.3252394199371338
Batch 11/64 loss: 0.3192974328994751
Batch 12/64 loss: 0.32635772228240967
Batch 13/64 loss: 0.33192944526672363
Batch 14/64 loss: 0.3288481831550598
Batch 15/64 loss: 0.32918739318847656
Batch 16/64 loss: 0.32683229446411133
Batch 17/64 loss: 0.3253265619277954
Batch 18/64 loss: 0.3183205723762512
Batch 19/64 loss: 0.32701730728149414
Batch 20/64 loss: 0.3233265280723572
Batch 21/64 loss: 0.32252979278564453
Batch 22/64 loss: 0.3160538077354431
Batch 23/64 loss: 0.33358633518218994
Batch 24/64 loss: 0.3262173533439636
Batch 25/64 loss: 0.3259153366088867
Batch 26/64 loss: 0.3201526403427124
Batch 27/64 loss: 0.325832724571228
Batch 28/64 loss: 0.3197667598724365
Batch 29/64 loss: 0.3272368907928467
Batch 30/64 loss: 0.32121801376342773
Batch 31/64 loss: 0.32636356353759766
Batch 32/64 loss: 0.3234846591949463
Batch 33/64 loss: 0.33229660987854004
Batch 34/64 loss: 0.319918155670166
Batch 35/64 loss: 0.32978594303131104
Batch 36/64 loss: 0.32638680934906006
Batch 37/64 loss: 0.32459354400634766
Batch 38/64 loss: 0.3186570405960083
Batch 39/64 loss: 0.32801711559295654
Batch 40/64 loss: 0.3223055601119995
Batch 41/64 loss: 0.3314722776412964
Batch 42/64 loss: 0.3247479796409607
Batch 43/64 loss: 0.31574583053588867
Batch 44/64 loss: 0.32214415073394775
Batch 45/64 loss: 0.32772088050842285
Batch 46/64 loss: 0.32939112186431885
Batch 47/64 loss: 0.32302147150039673
Batch 48/64 loss: 0.32826948165893555
Batch 49/64 loss: 0.31841325759887695
Batch 50/64 loss: 0.3164730668067932
Batch 51/64 loss: 0.3228669762611389
Batch 52/64 loss: 0.32864677906036377
Batch 53/64 loss: 0.33332669734954834
Batch 54/64 loss: 0.33020299673080444
Batch 55/64 loss: 0.3267035484313965
Batch 56/64 loss: 0.328058660030365
Batch 57/64 loss: 0.3294113874435425
Batch 58/64 loss: 0.32903069257736206
Batch 59/64 loss: 0.329672634601593
Batch 60/64 loss: 0.31680285930633545
Batch 61/64 loss: 0.3209061622619629
Batch 62/64 loss: 0.32931363582611084
Batch 63/64 loss: 0.3273121118545532
Batch 64/64 loss: 0.3249490261077881
Epoch 234  Train loss: 0.32585728121738805  Val loss: 0.3407716882187886
Epoch 235
-------------------------------
Batch 1/64 loss: 0.32686489820480347
Batch 2/64 loss: 0.3180088996887207
Batch 3/64 loss: 0.32472217082977295
Batch 4/64 loss: 0.3339008092880249
Batch 5/64 loss: 0.3215210437774658
Batch 6/64 loss: 0.3193655014038086
Batch 7/64 loss: 0.3309807777404785
Batch 8/64 loss: 0.3268839120864868
Batch 9/64 loss: 0.33004724979400635
Batch 10/64 loss: 0.32324355840682983
Batch 11/64 loss: 0.334234356880188
Batch 12/64 loss: 0.32018738985061646
Batch 13/64 loss: 0.33014196157455444
Batch 14/64 loss: 0.3174976110458374
Batch 15/64 loss: 0.32324737310409546
Batch 16/64 loss: 0.3237597942352295
Batch 17/64 loss: 0.32781028747558594
Batch 18/64 loss: 0.33109813928604126
Batch 19/64 loss: 0.3342167139053345
Batch 20/64 loss: 0.3168284296989441
Batch 21/64 loss: 0.3235620856285095
Batch 22/64 loss: 0.31859850883483887
Batch 23/64 loss: 0.3247959613800049
Batch 24/64 loss: 0.3221924901008606
Batch 25/64 loss: 0.3256109952926636
Batch 26/64 loss: 0.3170173764228821
Batch 27/64 loss: 0.32268643379211426
Batch 28/64 loss: 0.32513242959976196
Batch 29/64 loss: 0.3285389542579651
Batch 30/64 loss: 0.3305007815361023
Batch 31/64 loss: 0.328859806060791
Batch 32/64 loss: 0.3253434896469116
Batch 33/64 loss: 0.3251999616622925
Batch 34/64 loss: 0.3205595016479492
Batch 35/64 loss: 0.3237262964248657
Batch 36/64 loss: 0.3287534713745117
Batch 37/64 loss: 0.32851356267929077
Batch 38/64 loss: 0.33835840225219727
Batch 39/64 loss: 0.3250429034233093
Batch 40/64 loss: 0.3316836357116699
Batch 41/64 loss: 0.32592928409576416
Batch 42/64 loss: 0.33147090673446655
Batch 43/64 loss: 0.32282090187072754
Batch 44/64 loss: 0.3182855248451233
Batch 45/64 loss: 0.3332241177558899
Batch 46/64 loss: 0.3224285840988159
Batch 47/64 loss: 0.31937944889068604
Batch 48/64 loss: 0.3241015076637268
Batch 49/64 loss: 0.32788383960723877
Batch 50/64 loss: 0.32559365034103394
Batch 51/64 loss: 0.32717859745025635
Batch 52/64 loss: 0.31511861085891724
Batch 53/64 loss: 0.330765962600708
Batch 54/64 loss: 0.3273988962173462
Batch 55/64 loss: 0.31837141513824463
Batch 56/64 loss: 0.33138346672058105
Batch 57/64 loss: 0.3206838369369507
Batch 58/64 loss: 0.3228009343147278
Batch 59/64 loss: 0.3251972198486328
Batch 60/64 loss: 0.3224155306816101
Batch 61/64 loss: 0.33014512062072754
Batch 62/64 loss: 0.32989609241485596
Batch 63/64 loss: 0.32958030700683594
Batch 64/64 loss: 0.33253467082977295
Epoch 235  Train loss: 0.32565792448380415  Val loss: 0.3406418176860744
Epoch 236
-------------------------------
Batch 1/64 loss: 0.32762378454208374
Batch 2/64 loss: 0.3250776529312134
Batch 3/64 loss: 0.32730990648269653
Batch 4/64 loss: 0.3321039080619812
Batch 5/64 loss: 0.3322907090187073
Batch 6/64 loss: 0.32112812995910645
Batch 7/64 loss: 0.324914813041687
Batch 8/64 loss: 0.33329397439956665
Batch 9/64 loss: 0.32065653800964355
Batch 10/64 loss: 0.3256673216819763
Batch 11/64 loss: 0.3249322175979614
Batch 12/64 loss: 0.32876908779144287
Batch 13/64 loss: 0.3272259831428528
Batch 14/64 loss: 0.3238687515258789
Batch 15/64 loss: 0.3211857080459595
Batch 16/64 loss: 0.32962334156036377
Batch 17/64 loss: 0.323125422000885
Batch 18/64 loss: 0.3333777189254761
Batch 19/64 loss: 0.3243613839149475
Batch 20/64 loss: 0.3287001848220825
Batch 21/64 loss: 0.3217354416847229
Batch 22/64 loss: 0.32931917905807495
Batch 23/64 loss: 0.3254474401473999
Batch 24/64 loss: 0.3209618330001831
Batch 25/64 loss: 0.3253077268600464
Batch 26/64 loss: 0.3199120759963989
Batch 27/64 loss: 0.33170902729034424
Batch 28/64 loss: 0.3221452236175537
Batch 29/64 loss: 0.3196720480918884
Batch 30/64 loss: 0.31717705726623535
Batch 31/64 loss: 0.32854562997817993
Batch 32/64 loss: 0.3252970576286316
Batch 33/64 loss: 0.32185137271881104
Batch 34/64 loss: 0.3274194002151489
Batch 35/64 loss: 0.3309202194213867
Batch 36/64 loss: 0.32921338081359863
Batch 37/64 loss: 0.32519400119781494
Batch 38/64 loss: 0.32726478576660156
Batch 39/64 loss: 0.32138264179229736
Batch 40/64 loss: 0.3280869126319885
Batch 41/64 loss: 0.33145177364349365
Batch 42/64 loss: 0.3283412456512451
Batch 43/64 loss: 0.32015180587768555
Batch 44/64 loss: 0.33376622200012207
Batch 45/64 loss: 0.3271288275718689
Batch 46/64 loss: 0.32534122467041016
Batch 47/64 loss: 0.32772743701934814
Batch 48/64 loss: 0.32014328241348267
Batch 49/64 loss: 0.3210374116897583
Batch 50/64 loss: 0.32405269145965576
Batch 51/64 loss: 0.33609384298324585
Batch 52/64 loss: 0.32311129570007324
Batch 53/64 loss: 0.3280942440032959
Batch 54/64 loss: 0.32424890995025635
Batch 55/64 loss: 0.3241824507713318
Batch 56/64 loss: 0.3294055461883545
Batch 57/64 loss: 0.3284602165222168
Batch 58/64 loss: 0.3285764455795288
Batch 59/64 loss: 0.31798791885375977
Batch 60/64 loss: 0.3264564871788025
Batch 61/64 loss: 0.32455843687057495
Batch 62/64 loss: 0.32408082485198975
Batch 63/64 loss: 0.32185280323028564
Batch 64/64 loss: 0.32746028900146484
Epoch 236  Train loss: 0.325892479279462  Val loss: 0.34022647449650717
Epoch 237
-------------------------------
Batch 1/64 loss: 0.33301782608032227
Batch 2/64 loss: 0.32729363441467285
Batch 3/64 loss: 0.31957292556762695
Batch 4/64 loss: 0.3185913562774658
Batch 5/64 loss: 0.33511829376220703
Batch 6/64 loss: 0.332561731338501
Batch 7/64 loss: 0.325209379196167
Batch 8/64 loss: 0.32278335094451904
Batch 9/64 loss: 0.3369405269622803
Batch 10/64 loss: 0.3272061347961426
Batch 11/64 loss: 0.3243539333343506
Batch 12/64 loss: 0.32699447870254517
Batch 13/64 loss: 0.3269425630569458
Batch 14/64 loss: 0.32554346323013306
Batch 15/64 loss: 0.32480180263519287
Batch 16/64 loss: 0.3285764455795288
Batch 17/64 loss: 0.32406318187713623
Batch 18/64 loss: 0.32403361797332764
Batch 19/64 loss: 0.3281574249267578
Batch 20/64 loss: 0.32345765829086304
Batch 21/64 loss: 0.33122706413269043
Batch 22/64 loss: 0.32806259393692017
Batch 23/64 loss: 0.3297983407974243
Batch 24/64 loss: 0.3179450035095215
Batch 25/64 loss: 0.32713377475738525
Batch 26/64 loss: 0.32061487436294556
Batch 27/64 loss: 0.32362544536590576
Batch 28/64 loss: 0.32503485679626465
Batch 29/64 loss: 0.3333219289779663
Batch 30/64 loss: 0.3252951502799988
Batch 31/64 loss: 0.32355403900146484
Batch 32/64 loss: 0.32251542806625366
Batch 33/64 loss: 0.3252473473548889
Batch 34/64 loss: 0.3275691270828247
Batch 35/64 loss: 0.317432701587677
Batch 36/64 loss: 0.3236026167869568
Batch 37/64 loss: 0.3262515068054199
Batch 38/64 loss: 0.3209371566772461
Batch 39/64 loss: 0.3288755416870117
Batch 40/64 loss: 0.3187476396560669
Batch 41/64 loss: 0.3225419521331787
Batch 42/64 loss: 0.3213355541229248
Batch 43/64 loss: 0.33152633905410767
Batch 44/64 loss: 0.3270638585090637
Batch 45/64 loss: 0.32717365026474
Batch 46/64 loss: 0.3230358362197876
Batch 47/64 loss: 0.33609724044799805
Batch 48/64 loss: 0.3246484398841858
Batch 49/64 loss: 0.3292914032936096
Batch 50/64 loss: 0.3203575611114502
Batch 51/64 loss: 0.3204614520072937
Batch 52/64 loss: 0.3250046968460083
Batch 53/64 loss: 0.3240455985069275
Batch 54/64 loss: 0.31805241107940674
Batch 55/64 loss: 0.32742995023727417
Batch 56/64 loss: 0.31684696674346924
Batch 57/64 loss: 0.334256649017334
Batch 58/64 loss: 0.32634228467941284
Batch 59/64 loss: 0.32620370388031006
Batch 60/64 loss: 0.33159124851226807
Batch 61/64 loss: 0.3251645565032959
Batch 62/64 loss: 0.3233565092086792
Batch 63/64 loss: 0.3230988383293152
Batch 64/64 loss: 0.32943201065063477
Epoch 237  Train loss: 0.32571000117881627  Val loss: 0.33961702683537276
Epoch 238
-------------------------------
Batch 1/64 loss: 0.3257251977920532
Batch 2/64 loss: 0.3214777708053589
Batch 3/64 loss: 0.33165693283081055
Batch 4/64 loss: 0.32307636737823486
Batch 5/64 loss: 0.3289527893066406
Batch 6/64 loss: 0.3221103549003601
Batch 7/64 loss: 0.3250906467437744
Batch 8/64 loss: 0.3211521506309509
Batch 9/64 loss: 0.3283027410507202
Batch 10/64 loss: 0.3228268027305603
Batch 11/64 loss: 0.32691168785095215
Batch 12/64 loss: 0.3292107582092285
Batch 13/64 loss: 0.3221583366394043
Batch 14/64 loss: 0.33165472745895386
Batch 15/64 loss: 0.32905280590057373
Batch 16/64 loss: 0.3224529027938843
Batch 17/64 loss: 0.3302861452102661
Batch 18/64 loss: 0.332271933555603
Batch 19/64 loss: 0.3343009948730469
Batch 20/64 loss: 0.31981849670410156
Batch 21/64 loss: 0.32840418815612793
Batch 22/64 loss: 0.32139474153518677
Batch 23/64 loss: 0.32985919713974
Batch 24/64 loss: 0.331210732460022
Batch 25/64 loss: 0.32422637939453125
Batch 26/64 loss: 0.322736918926239
Batch 27/64 loss: 0.32147252559661865
Batch 28/64 loss: 0.3174419403076172
Batch 29/64 loss: 0.32688724994659424
Batch 30/64 loss: 0.327923059463501
Batch 31/64 loss: 0.32665061950683594
Batch 32/64 loss: 0.3251919746398926
Batch 33/64 loss: 0.32309669256210327
Batch 34/64 loss: 0.32578861713409424
Batch 35/64 loss: 0.3277389407157898
Batch 36/64 loss: 0.3280484676361084
Batch 37/64 loss: 0.32900023460388184
Batch 38/64 loss: 0.32503002882003784
Batch 39/64 loss: 0.3276176452636719
Batch 40/64 loss: 0.320354163646698
Batch 41/64 loss: 0.32648980617523193
Batch 42/64 loss: 0.3228176236152649
Batch 43/64 loss: 0.3265637755393982
Batch 44/64 loss: 0.32061123847961426
Batch 45/64 loss: 0.3175427317619324
Batch 46/64 loss: 0.3161604404449463
Batch 47/64 loss: 0.32572925090789795
Batch 48/64 loss: 0.32665514945983887
Batch 49/64 loss: 0.31936395168304443
Batch 50/64 loss: 0.3163807988166809
Batch 51/64 loss: 0.3227514624595642
Batch 52/64 loss: 0.3231692910194397
Batch 53/64 loss: 0.32731807231903076
Batch 54/64 loss: 0.32772958278656006
Batch 55/64 loss: 0.32278668880462646
Batch 56/64 loss: 0.32274681329727173
Batch 57/64 loss: 0.32446038722991943
Batch 58/64 loss: 0.3302193284034729
Batch 59/64 loss: 0.3249253034591675
Batch 60/64 loss: 0.32210707664489746
Batch 61/64 loss: 0.332736074924469
Batch 62/64 loss: 0.3227412700653076
Batch 63/64 loss: 0.3263280391693115
Batch 64/64 loss: 0.3279229402542114
Epoch 238  Train loss: 0.32522103879965986  Val loss: 0.33935231482450084
Saving best model, epoch: 238
Epoch 239
-------------------------------
Batch 1/64 loss: 0.32393038272857666
Batch 2/64 loss: 0.32136207818984985
Batch 3/64 loss: 0.32670652866363525
Batch 4/64 loss: 0.3284111022949219
Batch 5/64 loss: 0.32167279720306396
Batch 6/64 loss: 0.3140592575073242
Batch 7/64 loss: 0.32819676399230957
Batch 8/64 loss: 0.326219379901886
Batch 9/64 loss: 0.32673823833465576
Batch 10/64 loss: 0.32509398460388184
Batch 11/64 loss: 0.3254084587097168
Batch 12/64 loss: 0.3237234354019165
Batch 13/64 loss: 0.3289121389389038
Batch 14/64 loss: 0.3214902877807617
Batch 15/64 loss: 0.3309704661369324
Batch 16/64 loss: 0.3287215232849121
Batch 17/64 loss: 0.32673180103302
Batch 18/64 loss: 0.3165363073348999
Batch 19/64 loss: 0.325705885887146
Batch 20/64 loss: 0.3240548372268677
Batch 21/64 loss: 0.33166325092315674
Batch 22/64 loss: 0.32232141494750977
Batch 23/64 loss: 0.3223654627799988
Batch 24/64 loss: 0.31840354204177856
Batch 25/64 loss: 0.3252849578857422
Batch 26/64 loss: 0.3115004301071167
Batch 27/64 loss: 0.3219449520111084
Batch 28/64 loss: 0.33231329917907715
Batch 29/64 loss: 0.3160620331764221
Batch 30/64 loss: 0.32773643732070923
Batch 31/64 loss: 0.3247540593147278
Batch 32/64 loss: 0.31836628913879395
Batch 33/64 loss: 0.3275998830795288
Batch 34/64 loss: 0.32220005989074707
Batch 35/64 loss: 0.32803404331207275
Batch 36/64 loss: 0.33772170543670654
Batch 37/64 loss: 0.3253645896911621
Batch 38/64 loss: 0.32865428924560547
Batch 39/64 loss: 0.3298835754394531
Batch 40/64 loss: 0.33195018768310547
Batch 41/64 loss: 0.3257967233657837
Batch 42/64 loss: 0.326224684715271
Batch 43/64 loss: 0.33186912536621094
Batch 44/64 loss: 0.32474976778030396
Batch 45/64 loss: 0.32982927560806274
Batch 46/64 loss: 0.32826662063598633
Batch 47/64 loss: 0.32573723793029785
Batch 48/64 loss: 0.33359307050704956
Batch 49/64 loss: 0.3164844512939453
Batch 50/64 loss: 0.32888704538345337
Batch 51/64 loss: 0.3234260082244873
Batch 52/64 loss: 0.32249701023101807
Batch 53/64 loss: 0.3261258602142334
Batch 54/64 loss: 0.3243042230606079
Batch 55/64 loss: 0.33305442333221436
Batch 56/64 loss: 0.31871795654296875
Batch 57/64 loss: 0.32099902629852295
Batch 58/64 loss: 0.3276215195655823
Batch 59/64 loss: 0.32008254528045654
Batch 60/64 loss: 0.32241523265838623
Batch 61/64 loss: 0.3308147192001343
Batch 62/64 loss: 0.3188232183456421
Batch 63/64 loss: 0.32613927125930786
Batch 64/64 loss: 0.3148479461669922
Epoch 239  Train loss: 0.32504102108525296  Val loss: 0.3401065263961189
Epoch 240
-------------------------------
Batch 1/64 loss: 0.3223857283592224
Batch 2/64 loss: 0.32654744386672974
Batch 3/64 loss: 0.32446134090423584
Batch 4/64 loss: 0.32644200325012207
Batch 5/64 loss: 0.3238929510116577
Batch 6/64 loss: 0.32382845878601074
Batch 7/64 loss: 0.32424384355545044
Batch 8/64 loss: 0.32544243335723877
Batch 9/64 loss: 0.3207758665084839
Batch 10/64 loss: 0.3237893581390381
Batch 11/64 loss: 0.3342515826225281
Batch 12/64 loss: 0.32188963890075684
Batch 13/64 loss: 0.3165055513381958
Batch 14/64 loss: 0.3204793930053711
Batch 15/64 loss: 0.3246380686759949
Batch 16/64 loss: 0.3300682306289673
Batch 17/64 loss: 0.31845998764038086
Batch 18/64 loss: 0.3259286880493164
Batch 19/64 loss: 0.3252732753753662
Batch 20/64 loss: 0.3288313150405884
Batch 21/64 loss: 0.3290836811065674
Batch 22/64 loss: 0.32410484552383423
Batch 23/64 loss: 0.32357412576675415
Batch 24/64 loss: 0.3248816728591919
Batch 25/64 loss: 0.3160051107406616
Batch 26/64 loss: 0.3207225799560547
Batch 27/64 loss: 0.3237512707710266
Batch 28/64 loss: 0.32253777980804443
Batch 29/64 loss: 0.3202468156814575
Batch 30/64 loss: 0.3224618434906006
Batch 31/64 loss: 0.32632219791412354
Batch 32/64 loss: 0.32694149017333984
Batch 33/64 loss: 0.32827723026275635
Batch 34/64 loss: 0.3366008996963501
Batch 35/64 loss: 0.32276880741119385
Batch 36/64 loss: 0.3240398168563843
Batch 37/64 loss: 0.3218654990196228
Batch 38/64 loss: 0.3241680860519409
Batch 39/64 loss: 0.31639033555984497
Batch 40/64 loss: 0.32709717750549316
Batch 41/64 loss: 0.32623302936553955
Batch 42/64 loss: 0.3217654824256897
Batch 43/64 loss: 0.32814866304397583
Batch 44/64 loss: 0.32917141914367676
Batch 45/64 loss: 0.3255784511566162
Batch 46/64 loss: 0.3183640241622925
Batch 47/64 loss: 0.32266998291015625
Batch 48/64 loss: 0.3267505168914795
Batch 49/64 loss: 0.32539618015289307
Batch 50/64 loss: 0.3352014422416687
Batch 51/64 loss: 0.3233962655067444
Batch 52/64 loss: 0.3202931880950928
Batch 53/64 loss: 0.327312707901001
Batch 54/64 loss: 0.3188793659210205
Batch 55/64 loss: 0.3271702527999878
Batch 56/64 loss: 0.3225744962692261
Batch 57/64 loss: 0.3255876302719116
Batch 58/64 loss: 0.32470548152923584
Batch 59/64 loss: 0.33345019817352295
Batch 60/64 loss: 0.3253514766693115
Batch 61/64 loss: 0.3226191997528076
Batch 62/64 loss: 0.33270174264907837
Batch 63/64 loss: 0.331129789352417
Batch 64/64 loss: 0.32829880714416504
Epoch 240  Train loss: 0.32487296497120577  Val loss: 0.3408185440240447
Epoch 241
-------------------------------
Batch 1/64 loss: 0.3253018856048584
Batch 2/64 loss: 0.32381874322891235
Batch 3/64 loss: 0.3168596625328064
Batch 4/64 loss: 0.3219074010848999
Batch 5/64 loss: 0.3319631814956665
Batch 6/64 loss: 0.32102876901626587
Batch 7/64 loss: 0.31899571418762207
Batch 8/64 loss: 0.32177960872650146
Batch 9/64 loss: 0.3152977228164673
Batch 10/64 loss: 0.33779776096343994
Batch 11/64 loss: 0.321064829826355
Batch 12/64 loss: 0.32630813121795654
Batch 13/64 loss: 0.3304492235183716
Batch 14/64 loss: 0.3287804126739502
Batch 15/64 loss: 0.32174354791641235
Batch 16/64 loss: 0.33312368392944336
Batch 17/64 loss: 0.3323882818222046
Batch 18/64 loss: 0.32274556159973145
Batch 19/64 loss: 0.3309752941131592
Batch 20/64 loss: 0.32534313201904297
Batch 21/64 loss: 0.3214545249938965
Batch 22/64 loss: 0.326151967048645
Batch 23/64 loss: 0.32689082622528076
Batch 24/64 loss: 0.321541428565979
Batch 25/64 loss: 0.325864315032959
Batch 26/64 loss: 0.32667219638824463
Batch 27/64 loss: 0.31977927684783936
Batch 28/64 loss: 0.3251389265060425
Batch 29/64 loss: 0.32801544666290283
Batch 30/64 loss: 0.3194006681442261
Batch 31/64 loss: 0.32978713512420654
Batch 32/64 loss: 0.3309870958328247
Batch 33/64 loss: 0.32602763175964355
Batch 34/64 loss: 0.31931591033935547
Batch 35/64 loss: 0.33017241954803467
Batch 36/64 loss: 0.32793742418289185
Batch 37/64 loss: 0.3265236020088196
Batch 38/64 loss: 0.32075685262680054
Batch 39/64 loss: 0.3259080648422241
Batch 40/64 loss: 0.32723504304885864
Batch 41/64 loss: 0.3190685510635376
Batch 42/64 loss: 0.3192518949508667
Batch 43/64 loss: 0.32860326766967773
Batch 44/64 loss: 0.32597625255584717
Batch 45/64 loss: 0.32732003927230835
Batch 46/64 loss: 0.32646918296813965
Batch 47/64 loss: 0.32545024156570435
Batch 48/64 loss: 0.323317289352417
Batch 49/64 loss: 0.32679295539855957
Batch 50/64 loss: 0.3210766315460205
Batch 51/64 loss: 0.32633471488952637
Batch 52/64 loss: 0.3197106122970581
Batch 53/64 loss: 0.3208131790161133
Batch 54/64 loss: 0.3268369436264038
Batch 55/64 loss: 0.3274257183074951
Batch 56/64 loss: 0.32780951261520386
Batch 57/64 loss: 0.3334946632385254
Batch 58/64 loss: 0.3273729085922241
Batch 59/64 loss: 0.3290741443634033
Batch 60/64 loss: 0.32119375467300415
Batch 61/64 loss: 0.3314945697784424
Batch 62/64 loss: 0.32473647594451904
Batch 63/64 loss: 0.3261256217956543
Batch 64/64 loss: 0.3266479969024658
Epoch 241  Train loss: 0.3253955831714705  Val loss: 0.3392992566541298
Saving best model, epoch: 241
Epoch 242
-------------------------------
Batch 1/64 loss: 0.32816779613494873
Batch 2/64 loss: 0.3105615973472595
Batch 3/64 loss: 0.3343106508255005
Batch 4/64 loss: 0.31648099422454834
Batch 5/64 loss: 0.31853365898132324
Batch 6/64 loss: 0.3221260905265808
Batch 7/64 loss: 0.3231019377708435
Batch 8/64 loss: 0.33057355880737305
Batch 9/64 loss: 0.3281711935997009
Batch 10/64 loss: 0.32846832275390625
Batch 11/64 loss: 0.317171573638916
Batch 12/64 loss: 0.3319951295852661
Batch 13/64 loss: 0.32453036308288574
Batch 14/64 loss: 0.3243224620819092
Batch 15/64 loss: 0.32449841499328613
Batch 16/64 loss: 0.3244973421096802
Batch 17/64 loss: 0.32542502880096436
Batch 18/64 loss: 0.3286511301994324
Batch 19/64 loss: 0.3249998688697815
Batch 20/64 loss: 0.3199371099472046
Batch 21/64 loss: 0.3319650888442993
Batch 22/64 loss: 0.3169800043106079
Batch 23/64 loss: 0.32292819023132324
Batch 24/64 loss: 0.3147440552711487
Batch 25/64 loss: 0.3220815062522888
Batch 26/64 loss: 0.3323020935058594
Batch 27/64 loss: 0.32665783166885376
Batch 28/64 loss: 0.3262180685997009
Batch 29/64 loss: 0.3181678056716919
Batch 30/64 loss: 0.3208146095275879
Batch 31/64 loss: 0.3286229372024536
Batch 32/64 loss: 0.33154332637786865
Batch 33/64 loss: 0.32824623584747314
Batch 34/64 loss: 0.32800668478012085
Batch 35/64 loss: 0.3291882276535034
Batch 36/64 loss: 0.330780565738678
Batch 37/64 loss: 0.32274407148361206
Batch 38/64 loss: 0.31353670358657837
Batch 39/64 loss: 0.32422029972076416
Batch 40/64 loss: 0.3276498317718506
Batch 41/64 loss: 0.33476507663726807
Batch 42/64 loss: 0.3225189447402954
Batch 43/64 loss: 0.3332865238189697
Batch 44/64 loss: 0.33214616775512695
Batch 45/64 loss: 0.32915061712265015
Batch 46/64 loss: 0.320639967918396
Batch 47/64 loss: 0.32474011182785034
Batch 48/64 loss: 0.3286097049713135
Batch 49/64 loss: 0.32192152738571167
Batch 50/64 loss: 0.33086204528808594
Batch 51/64 loss: 0.3248547911643982
Batch 52/64 loss: 0.3162275552749634
Batch 53/64 loss: 0.32237523794174194
Batch 54/64 loss: 0.3290429711341858
Batch 55/64 loss: 0.3287910223007202
Batch 56/64 loss: 0.32756173610687256
Batch 57/64 loss: 0.3211709260940552
Batch 58/64 loss: 0.3330376148223877
Batch 59/64 loss: 0.3220672607421875
Batch 60/64 loss: 0.32865190505981445
Batch 61/64 loss: 0.31710952520370483
Batch 62/64 loss: 0.3256293535232544
Batch 63/64 loss: 0.3191683292388916
Batch 64/64 loss: 0.3229271173477173
Epoch 242  Train loss: 0.32502661359076407  Val loss: 0.339454105834371
Epoch 243
-------------------------------
Batch 1/64 loss: 0.32154178619384766
Batch 2/64 loss: 0.32235658168792725
Batch 3/64 loss: 0.3188358545303345
Batch 4/64 loss: 0.3226003646850586
Batch 5/64 loss: 0.3266305923461914
Batch 6/64 loss: 0.3168734908103943
Batch 7/64 loss: 0.332200288772583
Batch 8/64 loss: 0.327633798122406
Batch 9/64 loss: 0.31496667861938477
Batch 10/64 loss: 0.32362085580825806
Batch 11/64 loss: 0.32418525218963623
Batch 12/64 loss: 0.32079267501831055
Batch 13/64 loss: 0.32424068450927734
Batch 14/64 loss: 0.32562410831451416
Batch 15/64 loss: 0.3184729814529419
Batch 16/64 loss: 0.3192408084869385
Batch 17/64 loss: 0.32544201612472534
Batch 18/64 loss: 0.3310089111328125
Batch 19/64 loss: 0.322526216506958
Batch 20/64 loss: 0.3239651918411255
Batch 21/64 loss: 0.3227955102920532
Batch 22/64 loss: 0.3286780118942261
Batch 23/64 loss: 0.31657838821411133
Batch 24/64 loss: 0.3259759545326233
Batch 25/64 loss: 0.31792038679122925
Batch 26/64 loss: 0.3271751403808594
Batch 27/64 loss: 0.3237130045890808
Batch 28/64 loss: 0.32569456100463867
Batch 29/64 loss: 0.3247891664505005
Batch 30/64 loss: 0.327359676361084
Batch 31/64 loss: 0.3317345976829529
Batch 32/64 loss: 0.3275257349014282
Batch 33/64 loss: 0.3260805010795593
Batch 34/64 loss: 0.3234272003173828
Batch 35/64 loss: 0.3274317979812622
Batch 36/64 loss: 0.3212067484855652
Batch 37/64 loss: 0.32122671604156494
Batch 38/64 loss: 0.3234668970108032
Batch 39/64 loss: 0.3214327096939087
Batch 40/64 loss: 0.32586467266082764
Batch 41/64 loss: 0.32731175422668457
Batch 42/64 loss: 0.32565122842788696
Batch 43/64 loss: 0.33228600025177
Batch 44/64 loss: 0.318240761756897
Batch 45/64 loss: 0.3242150545120239
Batch 46/64 loss: 0.32779407501220703
Batch 47/64 loss: 0.3273661732673645
Batch 48/64 loss: 0.33348357677459717
Batch 49/64 loss: 0.3254542350769043
Batch 50/64 loss: 0.3184627294540405
Batch 51/64 loss: 0.32832086086273193
Batch 52/64 loss: 0.32531511783599854
Batch 53/64 loss: 0.3257964849472046
Batch 54/64 loss: 0.324637770652771
Batch 55/64 loss: 0.31898045539855957
Batch 56/64 loss: 0.32449114322662354
Batch 57/64 loss: 0.3229020833969116
Batch 58/64 loss: 0.32969558238983154
Batch 59/64 loss: 0.32622087001800537
Batch 60/64 loss: 0.3238952159881592
Batch 61/64 loss: 0.33047807216644287
Batch 62/64 loss: 0.3297414183616638
Batch 63/64 loss: 0.3226581811904907
Batch 64/64 loss: 0.3288053274154663
Epoch 243  Train loss: 0.3245935584984574  Val loss: 0.338695003609477
Saving best model, epoch: 243
Epoch 244
-------------------------------
Batch 1/64 loss: 0.32919347286224365
Batch 2/64 loss: 0.3219943046569824
Batch 3/64 loss: 0.3350512981414795
Batch 4/64 loss: 0.3248870372772217
Batch 5/64 loss: 0.32316553592681885
Batch 6/64 loss: 0.32271766662597656
Batch 7/64 loss: 0.3196086883544922
Batch 8/64 loss: 0.3153388500213623
Batch 9/64 loss: 0.3288770914077759
Batch 10/64 loss: 0.32176411151885986
Batch 11/64 loss: 0.3213677406311035
Batch 12/64 loss: 0.32744085788726807
Batch 13/64 loss: 0.32149648666381836
Batch 14/64 loss: 0.3140357732772827
Batch 15/64 loss: 0.3304945230484009
Batch 16/64 loss: 0.31964898109436035
Batch 17/64 loss: 0.32997679710388184
Batch 18/64 loss: 0.317557156085968
Batch 19/64 loss: 0.3274651765823364
Batch 20/64 loss: 0.3202372193336487
Batch 21/64 loss: 0.3196966052055359
Batch 22/64 loss: 0.3192727565765381
Batch 23/64 loss: 0.31615662574768066
Batch 24/64 loss: 0.3216050863265991
Batch 25/64 loss: 0.3321019411087036
Batch 26/64 loss: 0.33140021562576294
Batch 27/64 loss: 0.3168560862541199
Batch 28/64 loss: 0.32078778743743896
Batch 29/64 loss: 0.323197603225708
Batch 30/64 loss: 0.32225310802459717
Batch 31/64 loss: 0.3234759569168091
Batch 32/64 loss: 0.32629746198654175
Batch 33/64 loss: 0.3261117935180664
Batch 34/64 loss: 0.3309047222137451
Batch 35/64 loss: 0.3355816602706909
Batch 36/64 loss: 0.31488895416259766
Batch 37/64 loss: 0.3306058645248413
Batch 38/64 loss: 0.32837986946105957
Batch 39/64 loss: 0.32238757610321045
Batch 40/64 loss: 0.3210946321487427
Batch 41/64 loss: 0.32584261894226074
Batch 42/64 loss: 0.3236738443374634
Batch 43/64 loss: 0.3184947371482849
Batch 44/64 loss: 0.3226816654205322
Batch 45/64 loss: 0.32975465059280396
Batch 46/64 loss: 0.3288862705230713
Batch 47/64 loss: 0.3224976658821106
Batch 48/64 loss: 0.3220484256744385
Batch 49/64 loss: 0.32033872604370117
Batch 50/64 loss: 0.3239642381668091
Batch 51/64 loss: 0.3146728277206421
Batch 52/64 loss: 0.3274648189544678
Batch 53/64 loss: 0.3236713409423828
Batch 54/64 loss: 0.3285576105117798
Batch 55/64 loss: 0.3276214599609375
Batch 56/64 loss: 0.3344637155532837
Batch 57/64 loss: 0.32553088665008545
Batch 58/64 loss: 0.32738882303237915
Batch 59/64 loss: 0.3328830599784851
Batch 60/64 loss: 0.3255254030227661
Batch 61/64 loss: 0.32680249214172363
Batch 62/64 loss: 0.32758045196533203
Batch 63/64 loss: 0.3221483826637268
Batch 64/64 loss: 0.3170642852783203
Epoch 244  Train loss: 0.32432419459025064  Val loss: 0.339634222672977
Epoch 245
-------------------------------
Batch 1/64 loss: 0.32177603244781494
Batch 2/64 loss: 0.33260267972946167
Batch 3/64 loss: 0.32060450315475464
Batch 4/64 loss: 0.3225643038749695
Batch 5/64 loss: 0.32461702823638916
Batch 6/64 loss: 0.3266092538833618
Batch 7/64 loss: 0.3237318992614746
Batch 8/64 loss: 0.31710952520370483
Batch 9/64 loss: 0.31671440601348877
Batch 10/64 loss: 0.3257651925086975
Batch 11/64 loss: 0.3224984407424927
Batch 12/64 loss: 0.31906867027282715
Batch 13/64 loss: 0.3254060745239258
Batch 14/64 loss: 0.324398398399353
Batch 15/64 loss: 0.3178306221961975
Batch 16/64 loss: 0.3241482377052307
Batch 17/64 loss: 0.3208268880844116
Batch 18/64 loss: 0.3269442319869995
Batch 19/64 loss: 0.3215494751930237
Batch 20/64 loss: 0.326488733291626
Batch 21/64 loss: 0.31968629360198975
Batch 22/64 loss: 0.32086408138275146
Batch 23/64 loss: 0.32245945930480957
Batch 24/64 loss: 0.3190734386444092
Batch 25/64 loss: 0.3266677260398865
Batch 26/64 loss: 0.32575690746307373
Batch 27/64 loss: 0.3322725296020508
Batch 28/64 loss: 0.3285750150680542
Batch 29/64 loss: 0.3239288926124573
Batch 30/64 loss: 0.32349276542663574
Batch 31/64 loss: 0.327799916267395
Batch 32/64 loss: 0.3243521451950073
Batch 33/64 loss: 0.32730114459991455
Batch 34/64 loss: 0.32381224632263184
Batch 35/64 loss: 0.32579708099365234
Batch 36/64 loss: 0.3243359327316284
Batch 37/64 loss: 0.31692445278167725
Batch 38/64 loss: 0.3285590410232544
Batch 39/64 loss: 0.3171843886375427
Batch 40/64 loss: 0.32300496101379395
Batch 41/64 loss: 0.3266615867614746
Batch 42/64 loss: 0.320842981338501
Batch 43/64 loss: 0.3204094171524048
Batch 44/64 loss: 0.3285946249961853
Batch 45/64 loss: 0.32889413833618164
Batch 46/64 loss: 0.32450222969055176
Batch 47/64 loss: 0.3175090551376343
Batch 48/64 loss: 0.3198847770690918
Batch 49/64 loss: 0.32098162174224854
Batch 50/64 loss: 0.32272088527679443
Batch 51/64 loss: 0.32637596130371094
Batch 52/64 loss: 0.31737804412841797
Batch 53/64 loss: 0.329326868057251
Batch 54/64 loss: 0.33030879497528076
Batch 55/64 loss: 0.33061790466308594
Batch 56/64 loss: 0.3295719623565674
Batch 57/64 loss: 0.3324047923088074
Batch 58/64 loss: 0.3326863646507263
Batch 59/64 loss: 0.324188232421875
Batch 60/64 loss: 0.32475948333740234
Batch 61/64 loss: 0.32164424657821655
Batch 62/64 loss: 0.33142518997192383
Batch 63/64 loss: 0.3268696069717407
Batch 64/64 loss: 0.32586199045181274
Epoch 245  Train loss: 0.32433032592137656  Val loss: 0.3394753224251606
Epoch 246
-------------------------------
Batch 1/64 loss: 0.33134323358535767
Batch 2/64 loss: 0.3231990933418274
Batch 3/64 loss: 0.32159698009490967
Batch 4/64 loss: 0.32244420051574707
Batch 5/64 loss: 0.3243434429168701
Batch 6/64 loss: 0.32355833053588867
Batch 7/64 loss: 0.325153112411499
Batch 8/64 loss: 0.31994128227233887
Batch 9/64 loss: 0.327705979347229
Batch 10/64 loss: 0.32455432415008545
Batch 11/64 loss: 0.32948148250579834
Batch 12/64 loss: 0.32130831480026245
Batch 13/64 loss: 0.3208937644958496
Batch 14/64 loss: 0.3144480586051941
Batch 15/64 loss: 0.3256570100784302
Batch 16/64 loss: 0.3271549940109253
Batch 17/64 loss: 0.3167441487312317
Batch 18/64 loss: 0.3183314800262451
Batch 19/64 loss: 0.3284578323364258
Batch 20/64 loss: 0.3304321765899658
Batch 21/64 loss: 0.3283419609069824
Batch 22/64 loss: 0.32924574613571167
Batch 23/64 loss: 0.32128089666366577
Batch 24/64 loss: 0.32018858194351196
Batch 25/64 loss: 0.3237185478210449
Batch 26/64 loss: 0.32819175720214844
Batch 27/64 loss: 0.3239598274230957
Batch 28/64 loss: 0.32659411430358887
Batch 29/64 loss: 0.321302592754364
Batch 30/64 loss: 0.31948697566986084
Batch 31/64 loss: 0.3153127431869507
Batch 32/64 loss: 0.32703232765197754
Batch 33/64 loss: 0.3213334083557129
Batch 34/64 loss: 0.32084953784942627
Batch 35/64 loss: 0.3220585584640503
Batch 36/64 loss: 0.32021522521972656
Batch 37/64 loss: 0.32726746797561646
Batch 38/64 loss: 0.327542781829834
Batch 39/64 loss: 0.3258136510848999
Batch 40/64 loss: 0.33374500274658203
Batch 41/64 loss: 0.32750749588012695
Batch 42/64 loss: 0.3278217911720276
Batch 43/64 loss: 0.32184791564941406
Batch 44/64 loss: 0.3244556188583374
Batch 45/64 loss: 0.31709784269332886
Batch 46/64 loss: 0.33163607120513916
Batch 47/64 loss: 0.3337825536727905
Batch 48/64 loss: 0.3206503987312317
Batch 49/64 loss: 0.31659501791000366
Batch 50/64 loss: 0.3187006711959839
Batch 51/64 loss: 0.31998932361602783
Batch 52/64 loss: 0.3253380060195923
Batch 53/64 loss: 0.3278845548629761
Batch 54/64 loss: 0.3282474875450134
Batch 55/64 loss: 0.31618356704711914
Batch 56/64 loss: 0.31838029623031616
Batch 57/64 loss: 0.3231459856033325
Batch 58/64 loss: 0.3221040368080139
Batch 59/64 loss: 0.3296705484390259
Batch 60/64 loss: 0.3216078281402588
Batch 61/64 loss: 0.3204200267791748
Batch 62/64 loss: 0.3307872414588928
Batch 63/64 loss: 0.32478582859039307
Batch 64/64 loss: 0.3147146701812744
Epoch 246  Train loss: 0.3238416793299656  Val loss: 0.3394154760845748
Epoch 247
-------------------------------
Batch 1/64 loss: 0.32798898220062256
Batch 2/64 loss: 0.32065069675445557
Batch 3/64 loss: 0.3312869071960449
Batch 4/64 loss: 0.3184858560562134
Batch 5/64 loss: 0.32585644721984863
Batch 6/64 loss: 0.3129676580429077
Batch 7/64 loss: 0.3247275948524475
Batch 8/64 loss: 0.32545310258865356
Batch 9/64 loss: 0.32615041732788086
Batch 10/64 loss: 0.32167571783065796
Batch 11/64 loss: 0.3243488073348999
Batch 12/64 loss: 0.32174986600875854
Batch 13/64 loss: 0.3225659728050232
Batch 14/64 loss: 0.32314562797546387
Batch 15/64 loss: 0.3098681569099426
Batch 16/64 loss: 0.3212921619415283
Batch 17/64 loss: 0.32330751419067383
Batch 18/64 loss: 0.32372432947158813
Batch 19/64 loss: 0.32453829050064087
Batch 20/64 loss: 0.3167012929916382
Batch 21/64 loss: 0.32809746265411377
Batch 22/64 loss: 0.31059902906417847
Batch 23/64 loss: 0.32363617420196533
Batch 24/64 loss: 0.3226044178009033
Batch 25/64 loss: 0.32501518726348877
Batch 26/64 loss: 0.32632458209991455
Batch 27/64 loss: 0.3311123847961426
Batch 28/64 loss: 0.329703688621521
Batch 29/64 loss: 0.3272433280944824
Batch 30/64 loss: 0.32392561435699463
Batch 31/64 loss: 0.3339086174964905
Batch 32/64 loss: 0.32293689250946045
Batch 33/64 loss: 0.32277238368988037
Batch 34/64 loss: 0.3193954825401306
Batch 35/64 loss: 0.3328341245651245
Batch 36/64 loss: 0.3293163776397705
Batch 37/64 loss: 0.32207542657852173
Batch 38/64 loss: 0.31775563955307007
Batch 39/64 loss: 0.3239405155181885
Batch 40/64 loss: 0.31854283809661865
Batch 41/64 loss: 0.3275628089904785
Batch 42/64 loss: 0.3319559693336487
Batch 43/64 loss: 0.32119154930114746
Batch 44/64 loss: 0.3166302442550659
Batch 45/64 loss: 0.31752896308898926
Batch 46/64 loss: 0.32086074352264404
Batch 47/64 loss: 0.32215917110443115
Batch 48/64 loss: 0.31808340549468994
Batch 49/64 loss: 0.32359588146209717
Batch 50/64 loss: 0.3297630548477173
Batch 51/64 loss: 0.32141101360321045
Batch 52/64 loss: 0.33222007751464844
Batch 53/64 loss: 0.32658833265304565
Batch 54/64 loss: 0.33014029264450073
Batch 55/64 loss: 0.31887638568878174
Batch 56/64 loss: 0.3308027982711792
Batch 57/64 loss: 0.3231911063194275
Batch 58/64 loss: 0.32997775077819824
Batch 59/64 loss: 0.3242654800415039
Batch 60/64 loss: 0.32292699813842773
Batch 61/64 loss: 0.31844043731689453
Batch 62/64 loss: 0.33415013551712036
Batch 63/64 loss: 0.32055020332336426
Batch 64/64 loss: 0.3289874196052551
Epoch 247  Train loss: 0.3238876695726432  Val loss: 0.3399002679025185
Epoch 248
-------------------------------
Batch 1/64 loss: 0.31766027212142944
Batch 2/64 loss: 0.3198615312576294
Batch 3/64 loss: 0.32673192024230957
Batch 4/64 loss: 0.3319089412689209
Batch 5/64 loss: 0.3200756311416626
Batch 6/64 loss: 0.32397282123565674
Batch 7/64 loss: 0.32241082191467285
Batch 8/64 loss: 0.32456767559051514
Batch 9/64 loss: 0.31856799125671387
Batch 10/64 loss: 0.3157700300216675
Batch 11/64 loss: 0.3295663595199585
Batch 12/64 loss: 0.3173190951347351
Batch 13/64 loss: 0.32224971055984497
Batch 14/64 loss: 0.31845855712890625
Batch 15/64 loss: 0.3186222314834595
Batch 16/64 loss: 0.3225339651107788
Batch 17/64 loss: 0.3206023573875427
Batch 18/64 loss: 0.3257136344909668
Batch 19/64 loss: 0.3258052468299866
Batch 20/64 loss: 0.33017897605895996
Batch 21/64 loss: 0.3175995349884033
Batch 22/64 loss: 0.32580482959747314
Batch 23/64 loss: 0.328050434589386
Batch 24/64 loss: 0.33420097827911377
Batch 25/64 loss: 0.3280680179595947
Batch 26/64 loss: 0.3301372528076172
Batch 27/64 loss: 0.3232501149177551
Batch 28/64 loss: 0.32268255949020386
Batch 29/64 loss: 0.318972647190094
Batch 30/64 loss: 0.3274274468421936
Batch 31/64 loss: 0.32219022512435913
Batch 32/64 loss: 0.3321026563644409
Batch 33/64 loss: 0.32659590244293213
Batch 34/64 loss: 0.32597780227661133
Batch 35/64 loss: 0.3218083381652832
Batch 36/64 loss: 0.32746028900146484
Batch 37/64 loss: 0.3207136392593384
Batch 38/64 loss: 0.3224565386772156
Batch 39/64 loss: 0.3174505829811096
Batch 40/64 loss: 0.32460451126098633
Batch 41/64 loss: 0.32807791233062744
Batch 42/64 loss: 0.3161890506744385
Batch 43/64 loss: 0.32301056385040283
Batch 44/64 loss: 0.3246426582336426
Batch 45/64 loss: 0.32000672817230225
Batch 46/64 loss: 0.32628822326660156
Batch 47/64 loss: 0.3203566074371338
Batch 48/64 loss: 0.3256419897079468
Batch 49/64 loss: 0.32923704385757446
Batch 50/64 loss: 0.3117009401321411
Batch 51/64 loss: 0.32730674743652344
Batch 52/64 loss: 0.3260740637779236
Batch 53/64 loss: 0.3330758213996887
Batch 54/64 loss: 0.32241106033325195
Batch 55/64 loss: 0.31898289918899536
Batch 56/64 loss: 0.3329406976699829
Batch 57/64 loss: 0.3151148557662964
Batch 58/64 loss: 0.32537412643432617
Batch 59/64 loss: 0.3293885588645935
Batch 60/64 loss: 0.3221779465675354
Batch 61/64 loss: 0.3252870440483093
Batch 62/64 loss: 0.32511770725250244
Batch 63/64 loss: 0.3248809576034546
Batch 64/64 loss: 0.3217015266418457
Epoch 248  Train loss: 0.32383831248563877  Val loss: 0.3397121146782157
Epoch 249
-------------------------------
Batch 1/64 loss: 0.32266855239868164
Batch 2/64 loss: 0.31212395429611206
Batch 3/64 loss: 0.32626259326934814
Batch 4/64 loss: 0.3225446939468384
Batch 5/64 loss: 0.31607580184936523
Batch 6/64 loss: 0.319555401802063
Batch 7/64 loss: 0.31750184297561646
Batch 8/64 loss: 0.3320496678352356
Batch 9/64 loss: 0.31910431385040283
Batch 10/64 loss: 0.31508904695510864
Batch 11/64 loss: 0.32607579231262207
Batch 12/64 loss: 0.31363415718078613
Batch 13/64 loss: 0.31462031602859497
Batch 14/64 loss: 0.3220611810684204
Batch 15/64 loss: 0.3299734592437744
Batch 16/64 loss: 0.33261436223983765
Batch 17/64 loss: 0.32861804962158203
Batch 18/64 loss: 0.3305729031562805
Batch 19/64 loss: 0.32016706466674805
Batch 20/64 loss: 0.323682963848114
Batch 21/64 loss: 0.3220839500427246
Batch 22/64 loss: 0.3168575167655945
Batch 23/64 loss: 0.32950305938720703
Batch 24/64 loss: 0.3240751028060913
Batch 25/64 loss: 0.32219183444976807
Batch 26/64 loss: 0.3201526403427124
Batch 27/64 loss: 0.3261106014251709
Batch 28/64 loss: 0.31777894496917725
Batch 29/64 loss: 0.3214183449745178
Batch 30/64 loss: 0.32611948251724243
Batch 31/64 loss: 0.31870853900909424
Batch 32/64 loss: 0.32117921113967896
Batch 33/64 loss: 0.31892073154449463
Batch 34/64 loss: 0.32539451122283936
Batch 35/64 loss: 0.3261803388595581
Batch 36/64 loss: 0.3282209634780884
Batch 37/64 loss: 0.3281353712081909
Batch 38/64 loss: 0.3219090700149536
Batch 39/64 loss: 0.32469266653060913
Batch 40/64 loss: 0.3300752639770508
Batch 41/64 loss: 0.319303035736084
Batch 42/64 loss: 0.318128764629364
Batch 43/64 loss: 0.32282257080078125
Batch 44/64 loss: 0.32529592514038086
Batch 45/64 loss: 0.317996621131897
Batch 46/64 loss: 0.32514750957489014
Batch 47/64 loss: 0.32119619846343994
Batch 48/64 loss: 0.3244647979736328
Batch 49/64 loss: 0.32170796394348145
Batch 50/64 loss: 0.32413923740386963
Batch 51/64 loss: 0.3268716335296631
Batch 52/64 loss: 0.32617801427841187
Batch 53/64 loss: 0.32521140575408936
Batch 54/64 loss: 0.32613861560821533
Batch 55/64 loss: 0.3255431652069092
Batch 56/64 loss: 0.3264014720916748
Batch 57/64 loss: 0.3354565501213074
Batch 58/64 loss: 0.32490140199661255
Batch 59/64 loss: 0.3230975866317749
Batch 60/64 loss: 0.3239520192146301
Batch 61/64 loss: 0.32744210958480835
Batch 62/64 loss: 0.31908541917800903
Batch 63/64 loss: 0.33303940296173096
Batch 64/64 loss: 0.33451735973358154
Epoch 249  Train loss: 0.32359394045437084  Val loss: 0.33805547280819553
Saving best model, epoch: 249
Epoch 250
-------------------------------
Batch 1/64 loss: 0.32744288444519043
Batch 2/64 loss: 0.31982529163360596
Batch 3/64 loss: 0.3246232867240906
Batch 4/64 loss: 0.3215485215187073
Batch 5/64 loss: 0.3214570879936218
Batch 6/64 loss: 0.31916725635528564
Batch 7/64 loss: 0.32534605264663696
Batch 8/64 loss: 0.32542264461517334
Batch 9/64 loss: 0.3232485055923462
Batch 10/64 loss: 0.3263084888458252
Batch 11/64 loss: 0.31944704055786133
Batch 12/64 loss: 0.3185774087905884
Batch 13/64 loss: 0.31044328212738037
Batch 14/64 loss: 0.32554692029953003
Batch 15/64 loss: 0.32029032707214355
Batch 16/64 loss: 0.3247509002685547
Batch 17/64 loss: 0.32772284746170044
Batch 18/64 loss: 0.32114648818969727
Batch 19/64 loss: 0.32059431076049805
Batch 20/64 loss: 0.3264784812927246
Batch 21/64 loss: 0.3243640065193176
Batch 22/64 loss: 0.3198254108428955
Batch 23/64 loss: 0.3231602907180786
Batch 24/64 loss: 0.3253973722457886
Batch 25/64 loss: 0.31818699836730957
Batch 26/64 loss: 0.32462215423583984
Batch 27/64 loss: 0.3168402910232544
Batch 28/64 loss: 0.31941932439804077
Batch 29/64 loss: 0.3161667585372925
Batch 30/64 loss: 0.3199307918548584
Batch 31/64 loss: 0.32333260774612427
Batch 32/64 loss: 0.319006085395813
Batch 33/64 loss: 0.32224929332733154
Batch 34/64 loss: 0.3316621780395508
Batch 35/64 loss: 0.3295248746871948
Batch 36/64 loss: 0.3100156784057617
Batch 37/64 loss: 0.32740676403045654
Batch 38/64 loss: 0.3211122751235962
Batch 39/64 loss: 0.32438749074935913
Batch 40/64 loss: 0.3302724361419678
Batch 41/64 loss: 0.32614028453826904
Batch 42/64 loss: 0.3242208957672119
Batch 43/64 loss: 0.3287259340286255
Batch 44/64 loss: 0.323544979095459
Batch 45/64 loss: 0.3225020170211792
Batch 46/64 loss: 0.32151180505752563
Batch 47/64 loss: 0.32180362939834595
Batch 48/64 loss: 0.3229331374168396
Batch 49/64 loss: 0.3230018615722656
Batch 50/64 loss: 0.3254181146621704
Batch 51/64 loss: 0.3166347146034241
Batch 52/64 loss: 0.3305116295814514
Batch 53/64 loss: 0.32651180028915405
Batch 54/64 loss: 0.3289092183113098
Batch 55/64 loss: 0.3232901096343994
Batch 56/64 loss: 0.32929420471191406
Batch 57/64 loss: 0.3243143558502197
Batch 58/64 loss: 0.32106757164001465
Batch 59/64 loss: 0.32817935943603516
Batch 60/64 loss: 0.3199678063392639
Batch 61/64 loss: 0.3285231590270996
Batch 62/64 loss: 0.3308079242706299
Batch 63/64 loss: 0.3302382230758667
Batch 64/64 loss: 0.32060909271240234
Epoch 250  Train loss: 0.3233691084618662  Val loss: 0.3379665035562417
Saving best model, epoch: 250
Epoch 251
-------------------------------
Batch 1/64 loss: 0.32294541597366333
Batch 2/64 loss: 0.3195784091949463
Batch 3/64 loss: 0.32312965393066406
Batch 4/64 loss: 0.33369624614715576
Batch 5/64 loss: 0.32799458503723145
Batch 6/64 loss: 0.3244873285293579
Batch 7/64 loss: 0.3248355984687805
Batch 8/64 loss: 0.3294191360473633
Batch 9/64 loss: 0.32283949851989746
Batch 10/64 loss: 0.32100558280944824
Batch 11/64 loss: 0.3223501443862915
Batch 12/64 loss: 0.3207458257675171
Batch 13/64 loss: 0.3261113166809082
Batch 14/64 loss: 0.3250734806060791
Batch 15/64 loss: 0.3350638747215271
Batch 16/64 loss: 0.317183256149292
Batch 17/64 loss: 0.32607996463775635
Batch 18/64 loss: 0.32508164644241333
Batch 19/64 loss: 0.32150936126708984
Batch 20/64 loss: 0.3218156695365906
Batch 21/64 loss: 0.3256053328514099
Batch 22/64 loss: 0.3243706226348877
Batch 23/64 loss: 0.31897592544555664
Batch 24/64 loss: 0.32946252822875977
Batch 25/64 loss: 0.32374751567840576
Batch 26/64 loss: 0.3215542435646057
Batch 27/64 loss: 0.3195508122444153
Batch 28/64 loss: 0.3232840299606323
Batch 29/64 loss: 0.3276364803314209
Batch 30/64 loss: 0.3222433924674988
Batch 31/64 loss: 0.32189613580703735
Batch 32/64 loss: 0.3206862807273865
Batch 33/64 loss: 0.3306252956390381
Batch 34/64 loss: 0.3194972276687622
Batch 35/64 loss: 0.33087873458862305
Batch 36/64 loss: 0.32178956270217896
Batch 37/64 loss: 0.31875181198120117
Batch 38/64 loss: 0.3244395852088928
Batch 39/64 loss: 0.30770784616470337
Batch 40/64 loss: 0.3327626585960388
Batch 41/64 loss: 0.32344555854797363
Batch 42/64 loss: 0.32326364517211914
Batch 43/64 loss: 0.31776392459869385
Batch 44/64 loss: 0.3321613669395447
Batch 45/64 loss: 0.32589828968048096
Batch 46/64 loss: 0.32591480016708374
Batch 47/64 loss: 0.3244894742965698
Batch 48/64 loss: 0.32239043712615967
Batch 49/64 loss: 0.3245037794113159
Batch 50/64 loss: 0.3137689232826233
Batch 51/64 loss: 0.32218796014785767
Batch 52/64 loss: 0.32418131828308105
Batch 53/64 loss: 0.32626307010650635
Batch 54/64 loss: 0.323323130607605
Batch 55/64 loss: 0.32501423358917236
Batch 56/64 loss: 0.3192631006240845
Batch 57/64 loss: 0.3199687600135803
Batch 58/64 loss: 0.3263179063796997
Batch 59/64 loss: 0.3276045322418213
Batch 60/64 loss: 0.3186420202255249
Batch 61/64 loss: 0.32583868503570557
Batch 62/64 loss: 0.3259871006011963
Batch 63/64 loss: 0.3192533254623413
Batch 64/64 loss: 0.32376766204833984
Epoch 251  Train loss: 0.32371267617917526  Val loss: 0.33831646413737554
Epoch 252
-------------------------------
Batch 1/64 loss: 0.3174632787704468
Batch 2/64 loss: 0.33052635192871094
Batch 3/64 loss: 0.320556640625
Batch 4/64 loss: 0.3244668245315552
Batch 5/64 loss: 0.3194524049758911
Batch 6/64 loss: 0.32617151737213135
Batch 7/64 loss: 0.316713809967041
Batch 8/64 loss: 0.329556941986084
Batch 9/64 loss: 0.3152599334716797
Batch 10/64 loss: 0.3183380365371704
Batch 11/64 loss: 0.32033616304397583
Batch 12/64 loss: 0.3166919946670532
Batch 13/64 loss: 0.3150842785835266
Batch 14/64 loss: 0.3270951509475708
Batch 15/64 loss: 0.31935346126556396
Batch 16/64 loss: 0.32377028465270996
Batch 17/64 loss: 0.3273967504501343
Batch 18/64 loss: 0.3162117600440979
Batch 19/64 loss: 0.32356029748916626
Batch 20/64 loss: 0.32378458976745605
Batch 21/64 loss: 0.3218775987625122
Batch 22/64 loss: 0.33307570219039917
Batch 23/64 loss: 0.32583701610565186
Batch 24/64 loss: 0.31821370124816895
Batch 25/64 loss: 0.31878596544265747
Batch 26/64 loss: 0.32144802808761597
Batch 27/64 loss: 0.31790482997894287
Batch 28/64 loss: 0.3300323486328125
Batch 29/64 loss: 0.3240742087364197
Batch 30/64 loss: 0.3312162160873413
Batch 31/64 loss: 0.32122933864593506
Batch 32/64 loss: 0.3212728500366211
Batch 33/64 loss: 0.3220885396003723
Batch 34/64 loss: 0.3194664716720581
Batch 35/64 loss: 0.3193051218986511
Batch 36/64 loss: 0.3308526277542114
Batch 37/64 loss: 0.3206247091293335
Batch 38/64 loss: 0.3160281777381897
Batch 39/64 loss: 0.31737470626831055
Batch 40/64 loss: 0.3160005807876587
Batch 41/64 loss: 0.3241661787033081
Batch 42/64 loss: 0.32649725675582886
Batch 43/64 loss: 0.3274984359741211
Batch 44/64 loss: 0.3254507780075073
Batch 45/64 loss: 0.32974690198898315
Batch 46/64 loss: 0.3207463026046753
Batch 47/64 loss: 0.3282228708267212
Batch 48/64 loss: 0.322007417678833
Batch 49/64 loss: 0.32365119457244873
Batch 50/64 loss: 0.32003074884414673
Batch 51/64 loss: 0.3170955181121826
Batch 52/64 loss: 0.32148343324661255
Batch 53/64 loss: 0.3242924213409424
Batch 54/64 loss: 0.32109534740448
Batch 55/64 loss: 0.32372915744781494
Batch 56/64 loss: 0.32095980644226074
Batch 57/64 loss: 0.32481634616851807
Batch 58/64 loss: 0.3249647617340088
Batch 59/64 loss: 0.33281373977661133
Batch 60/64 loss: 0.3238298296928406
Batch 61/64 loss: 0.32724833488464355
Batch 62/64 loss: 0.32416510581970215
Batch 63/64 loss: 0.32418930530548096
Batch 64/64 loss: 0.31999051570892334
Epoch 252  Train loss: 0.3227795025881599  Val loss: 0.3383518549584851
Epoch 253
-------------------------------
Batch 1/64 loss: 0.32054394483566284
Batch 2/64 loss: 0.316051721572876
Batch 3/64 loss: 0.3201913833618164
Batch 4/64 loss: 0.3241485357284546
Batch 5/64 loss: 0.3211023807525635
Batch 6/64 loss: 0.32136160135269165
Batch 7/64 loss: 0.32312262058258057
Batch 8/64 loss: 0.32105231285095215
Batch 9/64 loss: 0.3213462829589844
Batch 10/64 loss: 0.3233523368835449
Batch 11/64 loss: 0.3247249126434326
Batch 12/64 loss: 0.3197610378265381
Batch 13/64 loss: 0.3208991289138794
Batch 14/64 loss: 0.31757891178131104
Batch 15/64 loss: 0.32589221000671387
Batch 16/64 loss: 0.31930088996887207
Batch 17/64 loss: 0.3223366141319275
Batch 18/64 loss: 0.3134235739707947
Batch 19/64 loss: 0.32743656635284424
Batch 20/64 loss: 0.32683587074279785
Batch 21/64 loss: 0.3295442461967468
Batch 22/64 loss: 0.3251189589500427
Batch 23/64 loss: 0.31851083040237427
Batch 24/64 loss: 0.3202352523803711
Batch 25/64 loss: 0.31445664167404175
Batch 26/64 loss: 0.32350313663482666
Batch 27/64 loss: 0.32862329483032227
Batch 28/64 loss: 0.32144224643707275
Batch 29/64 loss: 0.32546430826187134
Batch 30/64 loss: 0.32718658447265625
Batch 31/64 loss: 0.32383573055267334
Batch 32/64 loss: 0.3343241810798645
Batch 33/64 loss: 0.33128422498703003
Batch 34/64 loss: 0.3264045715332031
Batch 35/64 loss: 0.3214470148086548
Batch 36/64 loss: 0.32351118326187134
Batch 37/64 loss: 0.3308268189430237
Batch 38/64 loss: 0.317468523979187
Batch 39/64 loss: 0.31721973419189453
Batch 40/64 loss: 0.31489938497543335
Batch 41/64 loss: 0.32302314043045044
Batch 42/64 loss: 0.3313196301460266
Batch 43/64 loss: 0.3273775577545166
Batch 44/64 loss: 0.3240405321121216
Batch 45/64 loss: 0.3246868848800659
Batch 46/64 loss: 0.3270784616470337
Batch 47/64 loss: 0.3242744207382202
Batch 48/64 loss: 0.32311099767684937
Batch 49/64 loss: 0.31875693798065186
Batch 50/64 loss: 0.3294236660003662
Batch 51/64 loss: 0.32079005241394043
Batch 52/64 loss: 0.3273271918296814
Batch 53/64 loss: 0.3304222822189331
Batch 54/64 loss: 0.31914228200912476
Batch 55/64 loss: 0.31958186626434326
Batch 56/64 loss: 0.329278826713562
Batch 57/64 loss: 0.32505154609680176
Batch 58/64 loss: 0.3256714344024658
Batch 59/64 loss: 0.31882429122924805
Batch 60/64 loss: 0.32754552364349365
Batch 61/64 loss: 0.3299981355667114
Batch 62/64 loss: 0.3294578790664673
Batch 63/64 loss: 0.32431167364120483
Batch 64/64 loss: 0.3302704691886902
Epoch 253  Train loss: 0.3236700827000188  Val loss: 0.33897116339903105
Epoch 254
-------------------------------
Batch 1/64 loss: 0.31678950786590576
Batch 2/64 loss: 0.322256863117218
Batch 3/64 loss: 0.3200814127922058
Batch 4/64 loss: 0.3207916021347046
Batch 5/64 loss: 0.32616138458251953
Batch 6/64 loss: 0.3241026997566223
Batch 7/64 loss: 0.32229989767074585
Batch 8/64 loss: 0.31995534896850586
Batch 9/64 loss: 0.32322943210601807
Batch 10/64 loss: 0.32214033603668213
Batch 11/64 loss: 0.3151094913482666
Batch 12/64 loss: 0.32157009840011597
Batch 13/64 loss: 0.3278113603591919
Batch 14/64 loss: 0.3223823308944702
Batch 15/64 loss: 0.3154067397117615
Batch 16/64 loss: 0.3258599042892456
Batch 17/64 loss: 0.3188493251800537
Batch 18/64 loss: 0.318259596824646
Batch 19/64 loss: 0.3252270221710205
Batch 20/64 loss: 0.3335515260696411
Batch 21/64 loss: 0.3136914372444153
Batch 22/64 loss: 0.3248790502548218
Batch 23/64 loss: 0.32418006658554077
Batch 24/64 loss: 0.32321393489837646
Batch 25/64 loss: 0.32486361265182495
Batch 26/64 loss: 0.3297218680381775
Batch 27/64 loss: 0.3197399377822876
Batch 28/64 loss: 0.32407325506210327
Batch 29/64 loss: 0.3264387845993042
Batch 30/64 loss: 0.3351860046386719
Batch 31/64 loss: 0.323078989982605
Batch 32/64 loss: 0.3252445459365845
Batch 33/64 loss: 0.3211120367050171
Batch 34/64 loss: 0.32185065746307373
Batch 35/64 loss: 0.3293159008026123
Batch 36/64 loss: 0.32033801078796387
Batch 37/64 loss: 0.32924985885620117
Batch 38/64 loss: 0.33381742238998413
Batch 39/64 loss: 0.32783156633377075
Batch 40/64 loss: 0.32706451416015625
Batch 41/64 loss: 0.32110685110092163
Batch 42/64 loss: 0.32684653997421265
Batch 43/64 loss: 0.3290296792984009
Batch 44/64 loss: 0.3160877227783203
Batch 45/64 loss: 0.3310598134994507
Batch 46/64 loss: 0.32311463356018066
Batch 47/64 loss: 0.32056766748428345
Batch 48/64 loss: 0.31878405809402466
Batch 49/64 loss: 0.32903921604156494
Batch 50/64 loss: 0.3223356008529663
Batch 51/64 loss: 0.32405757904052734
Batch 52/64 loss: 0.3250439167022705
Batch 53/64 loss: 0.31958848237991333
Batch 54/64 loss: 0.3235151171684265
Batch 55/64 loss: 0.318084716796875
Batch 56/64 loss: 0.3284544348716736
Batch 57/64 loss: 0.32570207118988037
Batch 58/64 loss: 0.3176308870315552
Batch 59/64 loss: 0.3249645233154297
Batch 60/64 loss: 0.32037967443466187
Batch 61/64 loss: 0.32245296239852905
Batch 62/64 loss: 0.3357756733894348
Batch 63/64 loss: 0.3255424499511719
Batch 64/64 loss: 0.31751567125320435
Epoch 254  Train loss: 0.3236710331019233  Val loss: 0.33901026629910025
Epoch 255
-------------------------------
Batch 1/64 loss: 0.31236499547958374
Batch 2/64 loss: 0.31432420015335083
Batch 3/64 loss: 0.32096827030181885
Batch 4/64 loss: 0.320975124835968
Batch 5/64 loss: 0.3242788314819336
Batch 6/64 loss: 0.3247952461242676
Batch 7/64 loss: 0.3294593095779419
Batch 8/64 loss: 0.32287585735321045
Batch 9/64 loss: 0.3210480213165283
Batch 10/64 loss: 0.32611048221588135
Batch 11/64 loss: 0.31848466396331787
Batch 12/64 loss: 0.324798583984375
Batch 13/64 loss: 0.3253210783004761
Batch 14/64 loss: 0.32510697841644287
Batch 15/64 loss: 0.3230399489402771
Batch 16/64 loss: 0.31988924741744995
Batch 17/64 loss: 0.3244962692260742
Batch 18/64 loss: 0.3235219717025757
Batch 19/64 loss: 0.31872034072875977
Batch 20/64 loss: 0.3254627585411072
Batch 21/64 loss: 0.31948554515838623
Batch 22/64 loss: 0.32297319173812866
Batch 23/64 loss: 0.32069045305252075
Batch 24/64 loss: 0.327387273311615
Batch 25/64 loss: 0.3262685537338257
Batch 26/64 loss: 0.3157097101211548
Batch 27/64 loss: 0.32357335090637207
Batch 28/64 loss: 0.320895791053772
Batch 29/64 loss: 0.3194587230682373
Batch 30/64 loss: 0.31958186626434326
Batch 31/64 loss: 0.3233604431152344
Batch 32/64 loss: 0.33077192306518555
Batch 33/64 loss: 0.3233480453491211
Batch 34/64 loss: 0.33773696422576904
Batch 35/64 loss: 0.3233916759490967
Batch 36/64 loss: 0.31933796405792236
Batch 37/64 loss: 0.33093297481536865
Batch 38/64 loss: 0.32308995723724365
Batch 39/64 loss: 0.32473140954971313
Batch 40/64 loss: 0.32253360748291016
Batch 41/64 loss: 0.3191181421279907
Batch 42/64 loss: 0.3187901973724365
Batch 43/64 loss: 0.3305829167366028
Batch 44/64 loss: 0.32073068618774414
Batch 45/64 loss: 0.3207293152809143
Batch 46/64 loss: 0.31308871507644653
Batch 47/64 loss: 0.32285016775131226
Batch 48/64 loss: 0.31947511434555054
Batch 49/64 loss: 0.32591354846954346
Batch 50/64 loss: 0.3249097466468811
Batch 51/64 loss: 0.3177225589752197
Batch 52/64 loss: 0.3258282542228699
Batch 53/64 loss: 0.3225442171096802
Batch 54/64 loss: 0.3205171823501587
Batch 55/64 loss: 0.32626330852508545
Batch 56/64 loss: 0.32001036405563354
Batch 57/64 loss: 0.3252624273300171
Batch 58/64 loss: 0.3240656852722168
Batch 59/64 loss: 0.3217015862464905
Batch 60/64 loss: 0.32735002040863037
Batch 61/64 loss: 0.3235456347465515
Batch 62/64 loss: 0.32588624954223633
Batch 63/64 loss: 0.32219111919403076
Batch 64/64 loss: 0.3199669122695923
Epoch 255  Train loss: 0.3228290814979404  Val loss: 0.3391971807299611
Epoch 256
-------------------------------
Batch 1/64 loss: 0.3178466558456421
Batch 2/64 loss: 0.33020681142807007
Batch 3/64 loss: 0.316778302192688
Batch 4/64 loss: 0.32021892070770264
Batch 5/64 loss: 0.3279407024383545
Batch 6/64 loss: 0.3243405818939209
Batch 7/64 loss: 0.3166351318359375
Batch 8/64 loss: 0.32897722721099854
Batch 9/64 loss: 0.3225743770599365
Batch 10/64 loss: 0.3275386095046997
Batch 11/64 loss: 0.317396879196167
Batch 12/64 loss: 0.3305608630180359
Batch 13/64 loss: 0.32561349868774414
Batch 14/64 loss: 0.3206794261932373
Batch 15/64 loss: 0.3276526927947998
Batch 16/64 loss: 0.3217666745185852
Batch 17/64 loss: 0.31820225715637207
Batch 18/64 loss: 0.3210723400115967
Batch 19/64 loss: 0.30856937170028687
Batch 20/64 loss: 0.3212118148803711
Batch 21/64 loss: 0.31021440029144287
Batch 22/64 loss: 0.3184121251106262
Batch 23/64 loss: 0.32194530963897705
Batch 24/64 loss: 0.32237333059310913
Batch 25/64 loss: 0.31629860401153564
Batch 26/64 loss: 0.32413482666015625
Batch 27/64 loss: 0.3191460371017456
Batch 28/64 loss: 0.32183003425598145
Batch 29/64 loss: 0.3210933208465576
Batch 30/64 loss: 0.3219457268714905
Batch 31/64 loss: 0.320658802986145
Batch 32/64 loss: 0.3153555393218994
Batch 33/64 loss: 0.31749117374420166
Batch 34/64 loss: 0.3160911202430725
Batch 35/64 loss: 0.3256824016571045
Batch 36/64 loss: 0.31566429138183594
Batch 37/64 loss: 0.32526183128356934
Batch 38/64 loss: 0.3243315815925598
Batch 39/64 loss: 0.32686173915863037
Batch 40/64 loss: 0.3226897716522217
Batch 41/64 loss: 0.327258825302124
Batch 42/64 loss: 0.3252713680267334
Batch 43/64 loss: 0.31539344787597656
Batch 44/64 loss: 0.32685136795043945
Batch 45/64 loss: 0.3279231786727905
Batch 46/64 loss: 0.31667715311050415
Batch 47/64 loss: 0.3177911043167114
Batch 48/64 loss: 0.31857752799987793
Batch 49/64 loss: 0.31750261783599854
Batch 50/64 loss: 0.31766510009765625
Batch 51/64 loss: 0.33038830757141113
Batch 52/64 loss: 0.3204646706581116
Batch 53/64 loss: 0.3270512819290161
Batch 54/64 loss: 0.3254019618034363
Batch 55/64 loss: 0.323938250541687
Batch 56/64 loss: 0.3274967074394226
Batch 57/64 loss: 0.3192775249481201
Batch 58/64 loss: 0.32741761207580566
Batch 59/64 loss: 0.32041895389556885
Batch 60/64 loss: 0.3285428285598755
Batch 61/64 loss: 0.3259357213973999
Batch 62/64 loss: 0.3215341567993164
Batch 63/64 loss: 0.32589733600616455
Batch 64/64 loss: 0.3322259187698364
Epoch 256  Train loss: 0.3221507694206986  Val loss: 0.3402357933037879
Epoch 257
-------------------------------
Batch 1/64 loss: 0.3298313021659851
Batch 2/64 loss: 0.32871341705322266
Batch 3/64 loss: 0.31802165508270264
Batch 4/64 loss: 0.32268452644348145
Batch 5/64 loss: 0.32035547494888306
Batch 6/64 loss: 0.32450586557388306
Batch 7/64 loss: 0.33843863010406494
Batch 8/64 loss: 0.3217537999153137
Batch 9/64 loss: 0.32043731212615967
Batch 10/64 loss: 0.3210596442222595
Batch 11/64 loss: 0.3269699811935425
Batch 12/64 loss: 0.3243492841720581
Batch 13/64 loss: 0.318850576877594
Batch 14/64 loss: 0.3285260796546936
Batch 15/64 loss: 0.3171643018722534
Batch 16/64 loss: 0.32029199600219727
Batch 17/64 loss: 0.3185749650001526
Batch 18/64 loss: 0.3261939287185669
Batch 19/64 loss: 0.3260502815246582
Batch 20/64 loss: 0.3156222105026245
Batch 21/64 loss: 0.3263990879058838
Batch 22/64 loss: 0.32082152366638184
Batch 23/64 loss: 0.32098329067230225
Batch 24/64 loss: 0.3209678530693054
Batch 25/64 loss: 0.32658112049102783
Batch 26/64 loss: 0.3310464024543762
Batch 27/64 loss: 0.3183579444885254
Batch 28/64 loss: 0.3268624544143677
Batch 29/64 loss: 0.3224342465400696
Batch 30/64 loss: 0.32027769088745117
Batch 31/64 loss: 0.32333266735076904
Batch 32/64 loss: 0.32382071018218994
Batch 33/64 loss: 0.3142390251159668
Batch 34/64 loss: 0.3201565146446228
Batch 35/64 loss: 0.3196134567260742
Batch 36/64 loss: 0.3234128952026367
Batch 37/64 loss: 0.3248412609100342
Batch 38/64 loss: 0.31585144996643066
Batch 39/64 loss: 0.3199352025985718
Batch 40/64 loss: 0.3229101896286011
Batch 41/64 loss: 0.32141005992889404
Batch 42/64 loss: 0.3206881880760193
Batch 43/64 loss: 0.3253186345100403
Batch 44/64 loss: 0.32551926374435425
Batch 45/64 loss: 0.3228991627693176
Batch 46/64 loss: 0.3133023977279663
Batch 47/64 loss: 0.3203568458557129
Batch 48/64 loss: 0.3171809911727905
Batch 49/64 loss: 0.3269686698913574
Batch 50/64 loss: 0.32255637645721436
Batch 51/64 loss: 0.318819522857666
Batch 52/64 loss: 0.32490813732147217
Batch 53/64 loss: 0.3176864981651306
Batch 54/64 loss: 0.32017695903778076
Batch 55/64 loss: 0.32465600967407227
Batch 56/64 loss: 0.31481242179870605
Batch 57/64 loss: 0.3182818293571472
Batch 58/64 loss: 0.3268868923187256
Batch 59/64 loss: 0.32661861181259155
Batch 60/64 loss: 0.322409987449646
Batch 61/64 loss: 0.32667893171310425
Batch 62/64 loss: 0.32452332973480225
Batch 63/64 loss: 0.32710808515548706
Batch 64/64 loss: 0.3216173052787781
Epoch 257  Train loss: 0.3225446432244544  Val loss: 0.33915585852980207
Epoch 258
-------------------------------
Batch 1/64 loss: 0.3269968032836914
Batch 2/64 loss: 0.326183557510376
Batch 3/64 loss: 0.32397210597991943
Batch 4/64 loss: 0.3246455788612366
Batch 5/64 loss: 0.3168203830718994
Batch 6/64 loss: 0.3175249695777893
Batch 7/64 loss: 0.31992191076278687
Batch 8/64 loss: 0.31431275606155396
Batch 9/64 loss: 0.33091819286346436
Batch 10/64 loss: 0.3143726587295532
Batch 11/64 loss: 0.31234169006347656
Batch 12/64 loss: 0.31517916917800903
Batch 13/64 loss: 0.32416045665740967
Batch 14/64 loss: 0.3265838623046875
Batch 15/64 loss: 0.32973676919937134
Batch 16/64 loss: 0.32483017444610596
Batch 17/64 loss: 0.32369768619537354
Batch 18/64 loss: 0.3171417713165283
Batch 19/64 loss: 0.316170334815979
Batch 20/64 loss: 0.3274163007736206
Batch 21/64 loss: 0.32901686429977417
Batch 22/64 loss: 0.3278771638870239
Batch 23/64 loss: 0.32749849557876587
Batch 24/64 loss: 0.3078799247741699
Batch 25/64 loss: 0.3184448480606079
Batch 26/64 loss: 0.32376861572265625
Batch 27/64 loss: 0.32198232412338257
Batch 28/64 loss: 0.32097941637039185
Batch 29/64 loss: 0.32980620861053467
Batch 30/64 loss: 0.3266369104385376
Batch 31/64 loss: 0.324499249458313
Batch 32/64 loss: 0.3212299942970276
Batch 33/64 loss: 0.31897133588790894
Batch 34/64 loss: 0.32018351554870605
Batch 35/64 loss: 0.31702399253845215
Batch 36/64 loss: 0.32346034049987793
Batch 37/64 loss: 0.31619060039520264
Batch 38/64 loss: 0.3207349181175232
Batch 39/64 loss: 0.32131266593933105
Batch 40/64 loss: 0.3108217716217041
Batch 41/64 loss: 0.3189903497695923
Batch 42/64 loss: 0.3202788233757019
Batch 43/64 loss: 0.3168001174926758
Batch 44/64 loss: 0.322298526763916
Batch 45/64 loss: 0.317812442779541
Batch 46/64 loss: 0.3195234537124634
Batch 47/64 loss: 0.3234901428222656
Batch 48/64 loss: 0.3208732604980469
Batch 49/64 loss: 0.33028078079223633
Batch 50/64 loss: 0.325201153755188
Batch 51/64 loss: 0.31990504264831543
Batch 52/64 loss: 0.3233526945114136
Batch 53/64 loss: 0.33265358209609985
Batch 54/64 loss: 0.3233489990234375
Batch 55/64 loss: 0.31590282917022705
Batch 56/64 loss: 0.3130505084991455
Batch 57/64 loss: 0.32436347007751465
Batch 58/64 loss: 0.32591086626052856
Batch 59/64 loss: 0.3233683705329895
Batch 60/64 loss: 0.32236504554748535
Batch 61/64 loss: 0.32935065031051636
Batch 62/64 loss: 0.32240551710128784
Batch 63/64 loss: 0.3249671459197998
Batch 64/64 loss: 0.3308032751083374
Epoch 258  Train loss: 0.32197400027630374  Val loss: 0.33815026201333376
Epoch 259
-------------------------------
Batch 1/64 loss: 0.32269173860549927
Batch 2/64 loss: 0.31507426500320435
Batch 3/64 loss: 0.3141465187072754
Batch 4/64 loss: 0.32248568534851074
Batch 5/64 loss: 0.32165461778640747
Batch 6/64 loss: 0.32505249977111816
Batch 7/64 loss: 0.3292083740234375
Batch 8/64 loss: 0.320392370223999
Batch 9/64 loss: 0.3221083879470825
Batch 10/64 loss: 0.31718909740448
Batch 11/64 loss: 0.32184910774230957
Batch 12/64 loss: 0.3347083330154419
Batch 13/64 loss: 0.3219919204711914
Batch 14/64 loss: 0.3257490396499634
Batch 15/64 loss: 0.31232547760009766
Batch 16/64 loss: 0.32629716396331787
Batch 17/64 loss: 0.3226364850997925
Batch 18/64 loss: 0.31863826513290405
Batch 19/64 loss: 0.3208755850791931
Batch 20/64 loss: 0.31868529319763184
Batch 21/64 loss: 0.3172338008880615
Batch 22/64 loss: 0.3165925145149231
Batch 23/64 loss: 0.3139876127243042
Batch 24/64 loss: 0.30669689178466797
Batch 25/64 loss: 0.32690340280532837
Batch 26/64 loss: 0.3224310874938965
Batch 27/64 loss: 0.32312601804733276
Batch 28/64 loss: 0.3256481885910034
Batch 29/64 loss: 0.32088321447372437
Batch 30/64 loss: 0.3189120292663574
Batch 31/64 loss: 0.31696510314941406
Batch 32/64 loss: 0.3265688419342041
Batch 33/64 loss: 0.3220541477203369
Batch 34/64 loss: 0.3178463578224182
Batch 35/64 loss: 0.32435286045074463
Batch 36/64 loss: 0.3179318904876709
Batch 37/64 loss: 0.32360005378723145
Batch 38/64 loss: 0.3287770748138428
Batch 39/64 loss: 0.3233848810195923
Batch 40/64 loss: 0.3155710697174072
Batch 41/64 loss: 0.32040172815322876
Batch 42/64 loss: 0.32835257053375244
Batch 43/64 loss: 0.31983399391174316
Batch 44/64 loss: 0.3186693787574768
Batch 45/64 loss: 0.3249220848083496
Batch 46/64 loss: 0.32355690002441406
Batch 47/64 loss: 0.3301936388015747
Batch 48/64 loss: 0.31999003887176514
Batch 49/64 loss: 0.3249559998512268
Batch 50/64 loss: 0.3233349323272705
Batch 51/64 loss: 0.3274068832397461
Batch 52/64 loss: 0.32681113481521606
Batch 53/64 loss: 0.3212001919746399
Batch 54/64 loss: 0.3171532154083252
Batch 55/64 loss: 0.3275737762451172
Batch 56/64 loss: 0.3347393870353699
Batch 57/64 loss: 0.3204168677330017
Batch 58/64 loss: 0.3256256580352783
Batch 59/64 loss: 0.3212554454803467
Batch 60/64 loss: 0.3201068639755249
Batch 61/64 loss: 0.31192880868911743
Batch 62/64 loss: 0.3243216276168823
Batch 63/64 loss: 0.32842445373535156
Batch 64/64 loss: 0.32036155462265015
Epoch 259  Train loss: 0.32195567079618864  Val loss: 0.3379151120628278
Saving best model, epoch: 259
Epoch 260
-------------------------------
Batch 1/64 loss: 0.3194705843925476
Batch 2/64 loss: 0.3237189054489136
Batch 3/64 loss: 0.32223600149154663
Batch 4/64 loss: 0.31937330961227417
Batch 5/64 loss: 0.32258790731430054
Batch 6/64 loss: 0.3326382040977478
Batch 7/64 loss: 0.32322579622268677
Batch 8/64 loss: 0.3170212507247925
Batch 9/64 loss: 0.3263283967971802
Batch 10/64 loss: 0.32635974884033203
Batch 11/64 loss: 0.31842511892318726
Batch 12/64 loss: 0.3283224105834961
Batch 13/64 loss: 0.319472074508667
Batch 14/64 loss: 0.32142025232315063
Batch 15/64 loss: 0.3173253536224365
Batch 16/64 loss: 0.31925880908966064
Batch 17/64 loss: 0.32293152809143066
Batch 18/64 loss: 0.3191533088684082
Batch 19/64 loss: 0.32527875900268555
Batch 20/64 loss: 0.3194514513015747
Batch 21/64 loss: 0.31497442722320557
Batch 22/64 loss: 0.3166190981864929
Batch 23/64 loss: 0.32802653312683105
Batch 24/64 loss: 0.31461668014526367
Batch 25/64 loss: 0.3171597719192505
Batch 26/64 loss: 0.31889599561691284
Batch 27/64 loss: 0.32075440883636475
Batch 28/64 loss: 0.3227471709251404
Batch 29/64 loss: 0.3195098638534546
Batch 30/64 loss: 0.32460445165634155
Batch 31/64 loss: 0.3254338502883911
Batch 32/64 loss: 0.3180462121963501
Batch 33/64 loss: 0.3190547227859497
Batch 34/64 loss: 0.3274555206298828
Batch 35/64 loss: 0.31860673427581787
Batch 36/64 loss: 0.32002049684524536
Batch 37/64 loss: 0.31927138566970825
Batch 38/64 loss: 0.3240196704864502
Batch 39/64 loss: 0.3181610107421875
Batch 40/64 loss: 0.32820165157318115
Batch 41/64 loss: 0.3163496255874634
Batch 42/64 loss: 0.3226034641265869
Batch 43/64 loss: 0.3171291947364807
Batch 44/64 loss: 0.32198333740234375
Batch 45/64 loss: 0.31891363859176636
Batch 46/64 loss: 0.3269731402397156
Batch 47/64 loss: 0.31856322288513184
Batch 48/64 loss: 0.31578803062438965
Batch 49/64 loss: 0.3261599540710449
Batch 50/64 loss: 0.3148495554924011
Batch 51/64 loss: 0.3269965648651123
Batch 52/64 loss: 0.3271368741989136
Batch 53/64 loss: 0.3244914412498474
Batch 54/64 loss: 0.3247177004814148
Batch 55/64 loss: 0.31949925422668457
Batch 56/64 loss: 0.32190418243408203
Batch 57/64 loss: 0.3145796060562134
Batch 58/64 loss: 0.3184366226196289
Batch 59/64 loss: 0.32832205295562744
Batch 60/64 loss: 0.3202940821647644
Batch 61/64 loss: 0.32327014207839966
Batch 62/64 loss: 0.3242223262786865
Batch 63/64 loss: 0.32794761657714844
Batch 64/64 loss: 0.3286359906196594
Epoch 260  Train loss: 0.32169078354742014  Val loss: 0.338360958492633
Epoch 261
-------------------------------
Batch 1/64 loss: 0.3230839967727661
Batch 2/64 loss: 0.3217211365699768
Batch 3/64 loss: 0.3237497806549072
Batch 4/64 loss: 0.32276713848114014
Batch 5/64 loss: 0.32095348834991455
Batch 6/64 loss: 0.3168627619743347
Batch 7/64 loss: 0.31462013721466064
Batch 8/64 loss: 0.3166428804397583
Batch 9/64 loss: 0.3234078288078308
Batch 10/64 loss: 0.3285958766937256
Batch 11/64 loss: 0.3250124454498291
Batch 12/64 loss: 0.323567271232605
Batch 13/64 loss: 0.3157374858856201
Batch 14/64 loss: 0.3159370422363281
Batch 15/64 loss: 0.32591259479522705
Batch 16/64 loss: 0.30601364374160767
Batch 17/64 loss: 0.3235408663749695
Batch 18/64 loss: 0.3315216898918152
Batch 19/64 loss: 0.3261539936065674
Batch 20/64 loss: 0.3249449133872986
Batch 21/64 loss: 0.32260191440582275
Batch 22/64 loss: 0.3162698745727539
Batch 23/64 loss: 0.322457492351532
Batch 24/64 loss: 0.31813907623291016
Batch 25/64 loss: 0.32091450691223145
Batch 26/64 loss: 0.3174437880516052
Batch 27/64 loss: 0.33233821392059326
Batch 28/64 loss: 0.3252295255661011
Batch 29/64 loss: 0.32418572902679443
Batch 30/64 loss: 0.3191108703613281
Batch 31/64 loss: 0.31961703300476074
Batch 32/64 loss: 0.3197792172431946
Batch 33/64 loss: 0.314098596572876
Batch 34/64 loss: 0.3251199722290039
Batch 35/64 loss: 0.3256431818008423
Batch 36/64 loss: 0.3187870979309082
Batch 37/64 loss: 0.32785266637802124
Batch 38/64 loss: 0.32405173778533936
Batch 39/64 loss: 0.3195997476577759
Batch 40/64 loss: 0.3263288736343384
Batch 41/64 loss: 0.3158615827560425
Batch 42/64 loss: 0.32518279552459717
Batch 43/64 loss: 0.32365942001342773
Batch 44/64 loss: 0.32721376419067383
Batch 45/64 loss: 0.31717920303344727
Batch 46/64 loss: 0.3196249008178711
Batch 47/64 loss: 0.3213369846343994
Batch 48/64 loss: 0.32121741771698
Batch 49/64 loss: 0.31965768337249756
Batch 50/64 loss: 0.31550729274749756
Batch 51/64 loss: 0.3159186840057373
Batch 52/64 loss: 0.3256094455718994
Batch 53/64 loss: 0.3244020938873291
Batch 54/64 loss: 0.320157527923584
Batch 55/64 loss: 0.3238699436187744
Batch 56/64 loss: 0.33154696226119995
Batch 57/64 loss: 0.3252685070037842
Batch 58/64 loss: 0.3318901062011719
Batch 59/64 loss: 0.31531280279159546
Batch 60/64 loss: 0.3148786425590515
Batch 61/64 loss: 0.3211817741394043
Batch 62/64 loss: 0.3242802619934082
Batch 63/64 loss: 0.3192654848098755
Batch 64/64 loss: 0.32325077056884766
Epoch 261  Train loss: 0.3217690580031451  Val loss: 0.33785004509273675
Saving best model, epoch: 261
Epoch 262
-------------------------------
Batch 1/64 loss: 0.32251691818237305
Batch 2/64 loss: 0.31864964962005615
Batch 3/64 loss: 0.3306102752685547
Batch 4/64 loss: 0.3183441162109375
Batch 5/64 loss: 0.3141225576400757
Batch 6/64 loss: 0.3159453272819519
Batch 7/64 loss: 0.3229500651359558
Batch 8/64 loss: 0.32241952419281006
Batch 9/64 loss: 0.32309579849243164
Batch 10/64 loss: 0.3164075016975403
Batch 11/64 loss: 0.32198452949523926
Batch 12/64 loss: 0.31978708505630493
Batch 13/64 loss: 0.32188618183135986
Batch 14/64 loss: 0.3173166513442993
Batch 15/64 loss: 0.3176249861717224
Batch 16/64 loss: 0.31434810161590576
Batch 17/64 loss: 0.3193439245223999
Batch 18/64 loss: 0.32009410858154297
Batch 19/64 loss: 0.325292706489563
Batch 20/64 loss: 0.32137757539749146
Batch 21/64 loss: 0.32204675674438477
Batch 22/64 loss: 0.31959593296051025
Batch 23/64 loss: 0.3149896264076233
Batch 24/64 loss: 0.3183104395866394
Batch 25/64 loss: 0.324421763420105
Batch 26/64 loss: 0.3253819942474365
Batch 27/64 loss: 0.3241680860519409
Batch 28/64 loss: 0.3188842535018921
Batch 29/64 loss: 0.3222004771232605
Batch 30/64 loss: 0.3170175552368164
Batch 31/64 loss: 0.31916534900665283
Batch 32/64 loss: 0.3192633390426636
Batch 33/64 loss: 0.3205462694168091
Batch 34/64 loss: 0.3240396976470947
Batch 35/64 loss: 0.3189767003059387
Batch 36/64 loss: 0.32291972637176514
Batch 37/64 loss: 0.3301854133605957
Batch 38/64 loss: 0.3253638744354248
Batch 39/64 loss: 0.32110607624053955
Batch 40/64 loss: 0.320217490196228
Batch 41/64 loss: 0.32431459426879883
Batch 42/64 loss: 0.31605517864227295
Batch 43/64 loss: 0.31563282012939453
Batch 44/64 loss: 0.3216646909713745
Batch 45/64 loss: 0.330547571182251
Batch 46/64 loss: 0.32421839237213135
Batch 47/64 loss: 0.3248283863067627
Batch 48/64 loss: 0.3396810293197632
Batch 49/64 loss: 0.31555110216140747
Batch 50/64 loss: 0.3237868547439575
Batch 51/64 loss: 0.3270190358161926
Batch 52/64 loss: 0.32596778869628906
Batch 53/64 loss: 0.32388389110565186
Batch 54/64 loss: 0.3194558024406433
Batch 55/64 loss: 0.32358646392822266
Batch 56/64 loss: 0.324129581451416
Batch 57/64 loss: 0.32135748863220215
Batch 58/64 loss: 0.3191995620727539
Batch 59/64 loss: 0.3254568576812744
Batch 60/64 loss: 0.32163339853286743
Batch 61/64 loss: 0.32227271795272827
Batch 62/64 loss: 0.3239057660102844
Batch 63/64 loss: 0.32300740480422974
Batch 64/64 loss: 0.32004064321517944
Epoch 262  Train loss: 0.3217271414457583  Val loss: 0.33890258446591826
Epoch 263
-------------------------------
Batch 1/64 loss: 0.31411147117614746
Batch 2/64 loss: 0.3249083161354065
Batch 3/64 loss: 0.3234175443649292
Batch 4/64 loss: 0.31985849142074585
Batch 5/64 loss: 0.32776814699172974
Batch 6/64 loss: 0.3270150423049927
Batch 7/64 loss: 0.3209361433982849
Batch 8/64 loss: 0.31697171926498413
Batch 9/64 loss: 0.31884968280792236
Batch 10/64 loss: 0.3228684663772583
Batch 11/64 loss: 0.32971251010894775
Batch 12/64 loss: 0.3245764970779419
Batch 13/64 loss: 0.32386893033981323
Batch 14/64 loss: 0.32099539041519165
Batch 15/64 loss: 0.3201137185096741
Batch 16/64 loss: 0.31964111328125
Batch 17/64 loss: 0.3214946389198303
Batch 18/64 loss: 0.3173750638961792
Batch 19/64 loss: 0.32378721237182617
Batch 20/64 loss: 0.3225768208503723
Batch 21/64 loss: 0.31640470027923584
Batch 22/64 loss: 0.3208799362182617
Batch 23/64 loss: 0.3273698091506958
Batch 24/64 loss: 0.32719218730926514
Batch 25/64 loss: 0.3246053457260132
Batch 26/64 loss: 0.3275226950645447
Batch 27/64 loss: 0.3237640857696533
Batch 28/64 loss: 0.3278212547302246
Batch 29/64 loss: 0.3131372928619385
Batch 30/64 loss: 0.3171611428260803
Batch 31/64 loss: 0.3228350281715393
Batch 32/64 loss: 0.33744215965270996
Batch 33/64 loss: 0.32168930768966675
Batch 34/64 loss: 0.3237462639808655
Batch 35/64 loss: 0.3248376250267029
Batch 36/64 loss: 0.318142294883728
Batch 37/64 loss: 0.3251320719718933
Batch 38/64 loss: 0.32808536291122437
Batch 39/64 loss: 0.32799673080444336
Batch 40/64 loss: 0.3171699047088623
Batch 41/64 loss: 0.3161557912826538
Batch 42/64 loss: 0.3258397579193115
Batch 43/64 loss: 0.31114673614501953
Batch 44/64 loss: 0.322109580039978
Batch 45/64 loss: 0.3245389461517334
Batch 46/64 loss: 0.3207284212112427
Batch 47/64 loss: 0.3201850652694702
Batch 48/64 loss: 0.31024736166000366
Batch 49/64 loss: 0.31635016202926636
Batch 50/64 loss: 0.31942230463027954
Batch 51/64 loss: 0.32520198822021484
Batch 52/64 loss: 0.3253679871559143
Batch 53/64 loss: 0.31829988956451416
Batch 54/64 loss: 0.31806981563568115
Batch 55/64 loss: 0.3229326605796814
Batch 56/64 loss: 0.3239416480064392
Batch 57/64 loss: 0.3277575373649597
Batch 58/64 loss: 0.3243842124938965
Batch 59/64 loss: 0.3260553479194641
Batch 60/64 loss: 0.32426464557647705
Batch 61/64 loss: 0.31659996509552
Batch 62/64 loss: 0.32589828968048096
Batch 63/64 loss: 0.3190388083457947
Batch 64/64 loss: 0.32282769680023193
Epoch 263  Train loss: 0.3222029774796729  Val loss: 0.3379770978209899
Epoch 264
-------------------------------
Batch 1/64 loss: 0.31833016872406006
Batch 2/64 loss: 0.3280693292617798
Batch 3/64 loss: 0.3148355484008789
Batch 4/64 loss: 0.3220679759979248
Batch 5/64 loss: 0.3132202625274658
Batch 6/64 loss: 0.3248981833457947
Batch 7/64 loss: 0.32233530282974243
Batch 8/64 loss: 0.326840877532959
Batch 9/64 loss: 0.32600247859954834
Batch 10/64 loss: 0.31932079792022705
Batch 11/64 loss: 0.324013352394104
Batch 12/64 loss: 0.32021862268447876
Batch 13/64 loss: 0.32254040241241455
Batch 14/64 loss: 0.32086896896362305
Batch 15/64 loss: 0.3271324634552002
Batch 16/64 loss: 0.323017954826355
Batch 17/64 loss: 0.3212442398071289
Batch 18/64 loss: 0.3216172456741333
Batch 19/64 loss: 0.32623279094696045
Batch 20/64 loss: 0.3253953456878662
Batch 21/64 loss: 0.312838077545166
Batch 22/64 loss: 0.321735143661499
Batch 23/64 loss: 0.3199983835220337
Batch 24/64 loss: 0.320306658744812
Batch 25/64 loss: 0.32647883892059326
Batch 26/64 loss: 0.3230583071708679
Batch 27/64 loss: 0.32314205169677734
Batch 28/64 loss: 0.3270726799964905
Batch 29/64 loss: 0.3169955611228943
Batch 30/64 loss: 0.325502872467041
Batch 31/64 loss: 0.3181324601173401
Batch 32/64 loss: 0.32194268703460693
Batch 33/64 loss: 0.32477879524230957
Batch 34/64 loss: 0.3207569122314453
Batch 35/64 loss: 0.3281869888305664
Batch 36/64 loss: 0.3234238028526306
Batch 37/64 loss: 0.3196582794189453
Batch 38/64 loss: 0.3188188076019287
Batch 39/64 loss: 0.32813483476638794
Batch 40/64 loss: 0.3191004991531372
Batch 41/64 loss: 0.3189049959182739
Batch 42/64 loss: 0.31243228912353516
Batch 43/64 loss: 0.32180196046829224
Batch 44/64 loss: 0.3168085217475891
Batch 45/64 loss: 0.3188951015472412
Batch 46/64 loss: 0.32560867071151733
Batch 47/64 loss: 0.31122326850891113
Batch 48/64 loss: 0.3233117461204529
Batch 49/64 loss: 0.3217470645904541
Batch 50/64 loss: 0.32380151748657227
Batch 51/64 loss: 0.31700849533081055
Batch 52/64 loss: 0.310526967048645
Batch 53/64 loss: 0.3183807134628296
Batch 54/64 loss: 0.32436299324035645
Batch 55/64 loss: 0.3179629445075989
Batch 56/64 loss: 0.3244406580924988
Batch 57/64 loss: 0.3246215581893921
Batch 58/64 loss: 0.3195136785507202
Batch 59/64 loss: 0.3273932933807373
Batch 60/64 loss: 0.3292723298072815
Batch 61/64 loss: 0.3178884983062744
Batch 62/64 loss: 0.3215066194534302
Batch 63/64 loss: 0.3237624764442444
Batch 64/64 loss: 0.32067763805389404
Epoch 264  Train loss: 0.32156783599479527  Val loss: 0.33773899774780797
Saving best model, epoch: 264
Epoch 265
-------------------------------
Batch 1/64 loss: 0.31706470251083374
Batch 2/64 loss: 0.3085271120071411
Batch 3/64 loss: 0.319909930229187
Batch 4/64 loss: 0.3277249336242676
Batch 5/64 loss: 0.3165295124053955
Batch 6/64 loss: 0.32382309436798096
Batch 7/64 loss: 0.32141464948654175
Batch 8/64 loss: 0.3214181661605835
Batch 9/64 loss: 0.32132184505462646
Batch 10/64 loss: 0.3184460401535034
Batch 11/64 loss: 0.32233238220214844
Batch 12/64 loss: 0.3203415870666504
Batch 13/64 loss: 0.33068621158599854
Batch 14/64 loss: 0.3182700276374817
Batch 15/64 loss: 0.323667049407959
Batch 16/64 loss: 0.32437098026275635
Batch 17/64 loss: 0.31914061307907104
Batch 18/64 loss: 0.31757813692092896
Batch 19/64 loss: 0.32419395446777344
Batch 20/64 loss: 0.324873149394989
Batch 21/64 loss: 0.3219892978668213
Batch 22/64 loss: 0.3185579180717468
Batch 23/64 loss: 0.3250386714935303
Batch 24/64 loss: 0.32271599769592285
Batch 25/64 loss: 0.3166646957397461
Batch 26/64 loss: 0.32167500257492065
Batch 27/64 loss: 0.3204464912414551
Batch 28/64 loss: 0.3094969391822815
Batch 29/64 loss: 0.31623953580856323
Batch 30/64 loss: 0.3212120532989502
Batch 31/64 loss: 0.32333076000213623
Batch 32/64 loss: 0.3246780037879944
Batch 33/64 loss: 0.3144637942314148
Batch 34/64 loss: 0.3213116526603699
Batch 35/64 loss: 0.3236844539642334
Batch 36/64 loss: 0.3232839107513428
Batch 37/64 loss: 0.324948787689209
Batch 38/64 loss: 0.3267432451248169
Batch 39/64 loss: 0.3144683837890625
Batch 40/64 loss: 0.3128805160522461
Batch 41/64 loss: 0.32723546028137207
Batch 42/64 loss: 0.311340868473053
Batch 43/64 loss: 0.32931065559387207
Batch 44/64 loss: 0.31737208366394043
Batch 45/64 loss: 0.33026182651519775
Batch 46/64 loss: 0.32467007637023926
Batch 47/64 loss: 0.32153892517089844
Batch 48/64 loss: 0.31576406955718994
Batch 49/64 loss: 0.318942666053772
Batch 50/64 loss: 0.31833934783935547
Batch 51/64 loss: 0.323215126991272
Batch 52/64 loss: 0.3232123851776123
Batch 53/64 loss: 0.3242943286895752
Batch 54/64 loss: 0.32518112659454346
Batch 55/64 loss: 0.31270289421081543
Batch 56/64 loss: 0.31146240234375
Batch 57/64 loss: 0.318153440952301
Batch 58/64 loss: 0.33032548427581787
Batch 59/64 loss: 0.3208566904067993
Batch 60/64 loss: 0.33435559272766113
Batch 61/64 loss: 0.32940566539764404
Batch 62/64 loss: 0.3197205662727356
Batch 63/64 loss: 0.3273831605911255
Batch 64/64 loss: 0.32724642753601074
Epoch 265  Train loss: 0.3213481388840021  Val loss: 0.3373540349023039
Saving best model, epoch: 265
Epoch 266
-------------------------------
Batch 1/64 loss: 0.32538068294525146
Batch 2/64 loss: 0.32738709449768066
Batch 3/64 loss: 0.3177608251571655
Batch 4/64 loss: 0.3151722550392151
Batch 5/64 loss: 0.322920024394989
Batch 6/64 loss: 0.32699209451675415
Batch 7/64 loss: 0.3218647241592407
Batch 8/64 loss: 0.3263688087463379
Batch 9/64 loss: 0.3173796534538269
Batch 10/64 loss: 0.327229380607605
Batch 11/64 loss: 0.3209341764450073
Batch 12/64 loss: 0.31657981872558594
Batch 13/64 loss: 0.32020264863967896
Batch 14/64 loss: 0.3235306739807129
Batch 15/64 loss: 0.32224273681640625
Batch 16/64 loss: 0.32539302110671997
Batch 17/64 loss: 0.32310688495635986
Batch 18/64 loss: 0.3200722932815552
Batch 19/64 loss: 0.3184725046157837
Batch 20/64 loss: 0.32213079929351807
Batch 21/64 loss: 0.31632351875305176
Batch 22/64 loss: 0.3186168670654297
Batch 23/64 loss: 0.3093719482421875
Batch 24/64 loss: 0.3240754008293152
Batch 25/64 loss: 0.3258713483810425
Batch 26/64 loss: 0.31964588165283203
Batch 27/64 loss: 0.3209189772605896
Batch 28/64 loss: 0.31795644760131836
Batch 29/64 loss: 0.30711913108825684
Batch 30/64 loss: 0.3234201669692993
Batch 31/64 loss: 0.3216937780380249
Batch 32/64 loss: 0.32045841217041016
Batch 33/64 loss: 0.3178476095199585
Batch 34/64 loss: 0.32679903507232666
Batch 35/64 loss: 0.32360756397247314
Batch 36/64 loss: 0.3268347978591919
Batch 37/64 loss: 0.31628966331481934
Batch 38/64 loss: 0.3217191696166992
Batch 39/64 loss: 0.3236485719680786
Batch 40/64 loss: 0.3217817544937134
Batch 41/64 loss: 0.32103586196899414
Batch 42/64 loss: 0.32997602224349976
Batch 43/64 loss: 0.32704412937164307
Batch 44/64 loss: 0.32523858547210693
Batch 45/64 loss: 0.3188464641571045
Batch 46/64 loss: 0.32524359226226807
Batch 47/64 loss: 0.31524527072906494
Batch 48/64 loss: 0.3213663101196289
Batch 49/64 loss: 0.3146165609359741
Batch 50/64 loss: 0.31865376234054565
Batch 51/64 loss: 0.31995218992233276
Batch 52/64 loss: 0.3139870762825012
Batch 53/64 loss: 0.3282160758972168
Batch 54/64 loss: 0.321370005607605
Batch 55/64 loss: 0.31794917583465576
Batch 56/64 loss: 0.3100399971008301
Batch 57/64 loss: 0.31662213802337646
Batch 58/64 loss: 0.3152729272842407
Batch 59/64 loss: 0.3229557275772095
Batch 60/64 loss: 0.31831586360931396
Batch 61/64 loss: 0.3173137307167053
Batch 62/64 loss: 0.3248802423477173
Batch 63/64 loss: 0.31979620456695557
Batch 64/64 loss: 0.31907832622528076
Epoch 266  Train loss: 0.3207587106555116  Val loss: 0.33708562289726285
Saving best model, epoch: 266
Epoch 267
-------------------------------
Batch 1/64 loss: 0.3248269557952881
Batch 2/64 loss: 0.3256711959838867
Batch 3/64 loss: 0.3216050863265991
Batch 4/64 loss: 0.319457471370697
Batch 5/64 loss: 0.3255627751350403
Batch 6/64 loss: 0.31802070140838623
Batch 7/64 loss: 0.32080012559890747
Batch 8/64 loss: 0.3210740089416504
Batch 9/64 loss: 0.3181135654449463
Batch 10/64 loss: 0.32596850395202637
Batch 11/64 loss: 0.32483601570129395
Batch 12/64 loss: 0.3122923970222473
Batch 13/64 loss: 0.32050859928131104
Batch 14/64 loss: 0.32261210680007935
Batch 15/64 loss: 0.31523776054382324
Batch 16/64 loss: 0.3243115544319153
Batch 17/64 loss: 0.31798064708709717
Batch 18/64 loss: 0.3227804899215698
Batch 19/64 loss: 0.31628990173339844
Batch 20/64 loss: 0.32789498567581177
Batch 21/64 loss: 0.31281566619873047
Batch 22/64 loss: 0.32300353050231934
Batch 23/64 loss: 0.31966471672058105
Batch 24/64 loss: 0.3105868101119995
Batch 25/64 loss: 0.32745790481567383
Batch 26/64 loss: 0.31571710109710693
Batch 27/64 loss: 0.32701849937438965
Batch 28/64 loss: 0.32302719354629517
Batch 29/64 loss: 0.32589662075042725
Batch 30/64 loss: 0.3246645927429199
Batch 31/64 loss: 0.3176330327987671
Batch 32/64 loss: 0.32498788833618164
Batch 33/64 loss: 0.3197777271270752
Batch 34/64 loss: 0.31799209117889404
Batch 35/64 loss: 0.32288748025894165
Batch 36/64 loss: 0.3207658529281616
Batch 37/64 loss: 0.32281577587127686
Batch 38/64 loss: 0.3094043731689453
Batch 39/64 loss: 0.31963998079299927
Batch 40/64 loss: 0.32138025760650635
Batch 41/64 loss: 0.3259897232055664
Batch 42/64 loss: 0.3178369402885437
Batch 43/64 loss: 0.3266807794570923
Batch 44/64 loss: 0.3187371492385864
Batch 45/64 loss: 0.3217043876647949
Batch 46/64 loss: 0.32343852519989014
Batch 47/64 loss: 0.32266855239868164
Batch 48/64 loss: 0.3171030879020691
Batch 49/64 loss: 0.315356969833374
Batch 50/64 loss: 0.31932610273361206
Batch 51/64 loss: 0.31806206703186035
Batch 52/64 loss: 0.315773606300354
Batch 53/64 loss: 0.3143690228462219
Batch 54/64 loss: 0.3277330994606018
Batch 55/64 loss: 0.31659847497940063
Batch 56/64 loss: 0.31833362579345703
Batch 57/64 loss: 0.3212522268295288
Batch 58/64 loss: 0.3168684244155884
Batch 59/64 loss: 0.3195452094078064
Batch 60/64 loss: 0.3165853023529053
Batch 61/64 loss: 0.32951819896698
Batch 62/64 loss: 0.3193289041519165
Batch 63/64 loss: 0.32291877269744873
Batch 64/64 loss: 0.32655787467956543
Epoch 267  Train loss: 0.3206843843647078  Val loss: 0.3382598071573526
Epoch 268
-------------------------------
Batch 1/64 loss: 0.318210244178772
Batch 2/64 loss: 0.32467424869537354
Batch 3/64 loss: 0.32015305757522583
Batch 4/64 loss: 0.31592071056365967
Batch 5/64 loss: 0.3174607753753662
Batch 6/64 loss: 0.3224971890449524
Batch 7/64 loss: 0.3207830786705017
Batch 8/64 loss: 0.3281654119491577
Batch 9/64 loss: 0.3201007843017578
Batch 10/64 loss: 0.3143552541732788
Batch 11/64 loss: 0.31437307596206665
Batch 12/64 loss: 0.3106900453567505
Batch 13/64 loss: 0.32104724645614624
Batch 14/64 loss: 0.32298576831817627
Batch 15/64 loss: 0.32078468799591064
Batch 16/64 loss: 0.31898927688598633
Batch 17/64 loss: 0.33013176918029785
Batch 18/64 loss: 0.329229474067688
Batch 19/64 loss: 0.3284309506416321
Batch 20/64 loss: 0.30938637256622314
Batch 21/64 loss: 0.3208259344100952
Batch 22/64 loss: 0.3187560439109802
Batch 23/64 loss: 0.3160829544067383
Batch 24/64 loss: 0.31819581985473633
Batch 25/64 loss: 0.32282090187072754
Batch 26/64 loss: 0.31753647327423096
Batch 27/64 loss: 0.32665467262268066
Batch 28/64 loss: 0.3195464611053467
Batch 29/64 loss: 0.32655060291290283
Batch 30/64 loss: 0.3242391347885132
Batch 31/64 loss: 0.317824125289917
Batch 32/64 loss: 0.3234999179840088
Batch 33/64 loss: 0.32802510261535645
Batch 34/64 loss: 0.3264691233634949
Batch 35/64 loss: 0.32295089960098267
Batch 36/64 loss: 0.32285332679748535
Batch 37/64 loss: 0.3231945037841797
Batch 38/64 loss: 0.3174843192100525
Batch 39/64 loss: 0.3175208568572998
Batch 40/64 loss: 0.31728339195251465
Batch 41/64 loss: 0.3277930021286011
Batch 42/64 loss: 0.3213030695915222
Batch 43/64 loss: 0.3302009701728821
Batch 44/64 loss: 0.3220590353012085
Batch 45/64 loss: 0.3144609332084656
Batch 46/64 loss: 0.3192737102508545
Batch 47/64 loss: 0.3149980902671814
Batch 48/64 loss: 0.32034873962402344
Batch 49/64 loss: 0.32570040225982666
Batch 50/64 loss: 0.31533145904541016
Batch 51/64 loss: 0.3260403275489807
Batch 52/64 loss: 0.31563448905944824
Batch 53/64 loss: 0.3155783414840698
Batch 54/64 loss: 0.317857563495636
Batch 55/64 loss: 0.32273125648498535
Batch 56/64 loss: 0.33049488067626953
Batch 57/64 loss: 0.3241884708404541
Batch 58/64 loss: 0.3110990524291992
Batch 59/64 loss: 0.312113881111145
Batch 60/64 loss: 0.33108460903167725
Batch 61/64 loss: 0.3177666664123535
Batch 62/64 loss: 0.3335874676704407
Batch 63/64 loss: 0.3208826780319214
Batch 64/64 loss: 0.31816625595092773
Epoch 268  Train loss: 0.32103274943781834  Val loss: 0.3365462791059435
Saving best model, epoch: 268
Epoch 269
-------------------------------
Batch 1/64 loss: 0.32061517238616943
Batch 2/64 loss: 0.32296979427337646
Batch 3/64 loss: 0.3240022659301758
Batch 4/64 loss: 0.32014644145965576
Batch 5/64 loss: 0.3198130130767822
Batch 6/64 loss: 0.32081139087677
Batch 7/64 loss: 0.3236358165740967
Batch 8/64 loss: 0.3286726474761963
Batch 9/64 loss: 0.3222959041595459
Batch 10/64 loss: 0.3213675022125244
Batch 11/64 loss: 0.3204209804534912
Batch 12/64 loss: 0.3269869089126587
Batch 13/64 loss: 0.32742494344711304
Batch 14/64 loss: 0.3096071481704712
Batch 15/64 loss: 0.30868852138519287
Batch 16/64 loss: 0.3235321640968323
Batch 17/64 loss: 0.3184751272201538
Batch 18/64 loss: 0.31342291831970215
Batch 19/64 loss: 0.31157243251800537
Batch 20/64 loss: 0.3236237168312073
Batch 21/64 loss: 0.33079612255096436
Batch 22/64 loss: 0.3215181231498718
Batch 23/64 loss: 0.3254218101501465
Batch 24/64 loss: 0.31457990407943726
Batch 25/64 loss: 0.3104034662246704
Batch 26/64 loss: 0.31573790311813354
Batch 27/64 loss: 0.3155168294906616
Batch 28/64 loss: 0.33128488063812256
Batch 29/64 loss: 0.3177497982978821
Batch 30/64 loss: 0.3170207142829895
Batch 31/64 loss: 0.314811646938324
Batch 32/64 loss: 0.32309210300445557
Batch 33/64 loss: 0.31503039598464966
Batch 34/64 loss: 0.3148574233055115
Batch 35/64 loss: 0.32104557752609253
Batch 36/64 loss: 0.3247773051261902
Batch 37/64 loss: 0.3228132128715515
Batch 38/64 loss: 0.31786680221557617
Batch 39/64 loss: 0.32022082805633545
Batch 40/64 loss: 0.3177482485771179
Batch 41/64 loss: 0.32100188732147217
Batch 42/64 loss: 0.32441914081573486
Batch 43/64 loss: 0.3206331729888916
Batch 44/64 loss: 0.3170751929283142
Batch 45/64 loss: 0.3289869427680969
Batch 46/64 loss: 0.3191213607788086
Batch 47/64 loss: 0.318010151386261
Batch 48/64 loss: 0.3245033025741577
Batch 49/64 loss: 0.3130837082862854
Batch 50/64 loss: 0.32666468620300293
Batch 51/64 loss: 0.3164416551589966
Batch 52/64 loss: 0.31945526599884033
Batch 53/64 loss: 0.33014875650405884
Batch 54/64 loss: 0.3227931261062622
Batch 55/64 loss: 0.305209755897522
Batch 56/64 loss: 0.3204003572463989
Batch 57/64 loss: 0.31668657064437866
Batch 58/64 loss: 0.3194420337677002
Batch 59/64 loss: 0.32317054271698
Batch 60/64 loss: 0.32428038120269775
Batch 61/64 loss: 0.31852614879608154
Batch 62/64 loss: 0.3244969844818115
Batch 63/64 loss: 0.3201730251312256
Batch 64/64 loss: 0.3282758593559265
Epoch 269  Train loss: 0.3203342580327801  Val loss: 0.33776484445198296
Epoch 270
-------------------------------
Batch 1/64 loss: 0.31806015968322754
Batch 2/64 loss: 0.31700241565704346
Batch 3/64 loss: 0.30909574031829834
Batch 4/64 loss: 0.3185538649559021
Batch 5/64 loss: 0.32471030950546265
Batch 6/64 loss: 0.315330445766449
Batch 7/64 loss: 0.31624847650527954
Batch 8/64 loss: 0.31904518604278564
Batch 9/64 loss: 0.3204127550125122
Batch 10/64 loss: 0.32199394702911377
Batch 11/64 loss: 0.31390315294265747
Batch 12/64 loss: 0.319238543510437
Batch 13/64 loss: 0.32464510202407837
Batch 14/64 loss: 0.31816577911376953
Batch 15/64 loss: 0.3176053762435913
Batch 16/64 loss: 0.31378108263015747
Batch 17/64 loss: 0.318217396736145
Batch 18/64 loss: 0.3240779638290405
Batch 19/64 loss: 0.3212965726852417
Batch 20/64 loss: 0.3162153363227844
Batch 21/64 loss: 0.3178183436393738
Batch 22/64 loss: 0.31762635707855225
Batch 23/64 loss: 0.32781982421875
Batch 24/64 loss: 0.3317173719406128
Batch 25/64 loss: 0.3123859167098999
Batch 26/64 loss: 0.3209993839263916
Batch 27/64 loss: 0.327394962310791
Batch 28/64 loss: 0.3204629421234131
Batch 29/64 loss: 0.31763654947280884
Batch 30/64 loss: 0.31910884380340576
Batch 31/64 loss: 0.31843453645706177
Batch 32/64 loss: 0.3318592309951782
Batch 33/64 loss: 0.324332594871521
Batch 34/64 loss: 0.318867564201355
Batch 35/64 loss: 0.32641398906707764
Batch 36/64 loss: 0.3176654577255249
Batch 37/64 loss: 0.32031911611557007
Batch 38/64 loss: 0.32258033752441406
Batch 39/64 loss: 0.32002460956573486
Batch 40/64 loss: 0.3276454210281372
Batch 41/64 loss: 0.32444679737091064
Batch 42/64 loss: 0.3196425437927246
Batch 43/64 loss: 0.32413697242736816
Batch 44/64 loss: 0.32486969232559204
Batch 45/64 loss: 0.31682682037353516
Batch 46/64 loss: 0.320586621761322
Batch 47/64 loss: 0.3079518675804138
Batch 48/64 loss: 0.3294588327407837
Batch 49/64 loss: 0.3266040086746216
Batch 50/64 loss: 0.31404823064804077
Batch 51/64 loss: 0.3096516728401184
Batch 52/64 loss: 0.32462525367736816
Batch 53/64 loss: 0.32176685333251953
Batch 54/64 loss: 0.3252834677696228
Batch 55/64 loss: 0.31669795513153076
Batch 56/64 loss: 0.3219437599182129
Batch 57/64 loss: 0.3147674798965454
Batch 58/64 loss: 0.323788583278656
Batch 59/64 loss: 0.3253147602081299
Batch 60/64 loss: 0.32525724172592163
Batch 61/64 loss: 0.3192816376686096
Batch 62/64 loss: 0.316614031791687
Batch 63/64 loss: 0.3262147903442383
Batch 64/64 loss: 0.31922709941864014
Epoch 270  Train loss: 0.32043785347658044  Val loss: 0.3383140469744443
Epoch 271
-------------------------------
Batch 1/64 loss: 0.31674444675445557
Batch 2/64 loss: 0.32211506366729736
Batch 3/64 loss: 0.3083547353744507
Batch 4/64 loss: 0.3199077248573303
Batch 5/64 loss: 0.3269689083099365
Batch 6/64 loss: 0.32020270824432373
Batch 7/64 loss: 0.32341837882995605
Batch 8/64 loss: 0.3154858946800232
Batch 9/64 loss: 0.31609976291656494
Batch 10/64 loss: 0.3205323815345764
Batch 11/64 loss: 0.3160707950592041
Batch 12/64 loss: 0.3257289528846741
Batch 13/64 loss: 0.31743907928466797
Batch 14/64 loss: 0.32251596450805664
Batch 15/64 loss: 0.3186214566230774
Batch 16/64 loss: 0.3148597478866577
Batch 17/64 loss: 0.3148379325866699
Batch 18/64 loss: 0.31630444526672363
Batch 19/64 loss: 0.3217517137527466
Batch 20/64 loss: 0.31371116638183594
Batch 21/64 loss: 0.31700682640075684
Batch 22/64 loss: 0.316192090511322
Batch 23/64 loss: 0.3168196678161621
Batch 24/64 loss: 0.3122631907463074
Batch 25/64 loss: 0.3264687657356262
Batch 26/64 loss: 0.320991575717926
Batch 27/64 loss: 0.31853240728378296
Batch 28/64 loss: 0.3208730220794678
Batch 29/64 loss: 0.31611931324005127
Batch 30/64 loss: 0.32002711296081543
Batch 31/64 loss: 0.318304181098938
Batch 32/64 loss: 0.3224027156829834
Batch 33/64 loss: 0.3207426071166992
Batch 34/64 loss: 0.31223422288894653
Batch 35/64 loss: 0.32090723514556885
Batch 36/64 loss: 0.32123154401779175
Batch 37/64 loss: 0.3227807283401489
Batch 38/64 loss: 0.31774890422821045
Batch 39/64 loss: 0.315778911113739
Batch 40/64 loss: 0.32862716913223267
Batch 41/64 loss: 0.31491661071777344
Batch 42/64 loss: 0.3294464945793152
Batch 43/64 loss: 0.32543128728866577
Batch 44/64 loss: 0.3227576017379761
Batch 45/64 loss: 0.3231680393218994
Batch 46/64 loss: 0.3289210796356201
Batch 47/64 loss: 0.3245329260826111
Batch 48/64 loss: 0.32233643531799316
Batch 49/64 loss: 0.3255823850631714
Batch 50/64 loss: 0.32380223274230957
Batch 51/64 loss: 0.3178534507751465
Batch 52/64 loss: 0.32647228240966797
Batch 53/64 loss: 0.3218909502029419
Batch 54/64 loss: 0.32160401344299316
Batch 55/64 loss: 0.3155895471572876
Batch 56/64 loss: 0.311920702457428
Batch 57/64 loss: 0.32718008756637573
Batch 58/64 loss: 0.31720638275146484
Batch 59/64 loss: 0.31489425897598267
Batch 60/64 loss: 0.3205353021621704
Batch 61/64 loss: 0.3216050863265991
Batch 62/64 loss: 0.320545494556427
Batch 63/64 loss: 0.3268851041793823
Batch 64/64 loss: 0.314186692237854
Epoch 271  Train loss: 0.31997554863200467  Val loss: 0.3377102576580244
Epoch 272
-------------------------------
Batch 1/64 loss: 0.32892096042633057
Batch 2/64 loss: 0.32385826110839844
Batch 3/64 loss: 0.3163679242134094
Batch 4/64 loss: 0.3171722888946533
Batch 5/64 loss: 0.31616759300231934
Batch 6/64 loss: 0.3266209363937378
Batch 7/64 loss: 0.32024192810058594
Batch 8/64 loss: 0.31675493717193604
Batch 9/64 loss: 0.32103681564331055
Batch 10/64 loss: 0.31292450428009033
Batch 11/64 loss: 0.32171088457107544
Batch 12/64 loss: 0.3261833190917969
Batch 13/64 loss: 0.31446659564971924
Batch 14/64 loss: 0.3147042989730835
Batch 15/64 loss: 0.3243597149848938
Batch 16/64 loss: 0.3211139440536499
Batch 17/64 loss: 0.32130932807922363
Batch 18/64 loss: 0.32010048627853394
Batch 19/64 loss: 0.3259388208389282
Batch 20/64 loss: 0.3160961866378784
Batch 21/64 loss: 0.31366533041000366
Batch 22/64 loss: 0.3212013840675354
Batch 23/64 loss: 0.3203524351119995
Batch 24/64 loss: 0.3191584348678589
Batch 25/64 loss: 0.31517505645751953
Batch 26/64 loss: 0.3199218511581421
Batch 27/64 loss: 0.32285892963409424
Batch 28/64 loss: 0.32630741596221924
Batch 29/64 loss: 0.3221402168273926
Batch 30/64 loss: 0.3224225640296936
Batch 31/64 loss: 0.317676305770874
Batch 32/64 loss: 0.3222689628601074
Batch 33/64 loss: 0.3151320219039917
Batch 34/64 loss: 0.3167227506637573
Batch 35/64 loss: 0.3205426335334778
Batch 36/64 loss: 0.31716668605804443
Batch 37/64 loss: 0.3146306276321411
Batch 38/64 loss: 0.3181764483451843
Batch 39/64 loss: 0.32015031576156616
Batch 40/64 loss: 0.317207932472229
Batch 41/64 loss: 0.3205481171607971
Batch 42/64 loss: 0.31636983156204224
Batch 43/64 loss: 0.32583779096603394
Batch 44/64 loss: 0.31827759742736816
Batch 45/64 loss: 0.3121058940887451
Batch 46/64 loss: 0.33331984281539917
Batch 47/64 loss: 0.32895565032958984
Batch 48/64 loss: 0.325972318649292
Batch 49/64 loss: 0.32443344593048096
Batch 50/64 loss: 0.3232901096343994
Batch 51/64 loss: 0.32123059034347534
Batch 52/64 loss: 0.3180530071258545
Batch 53/64 loss: 0.31339287757873535
Batch 54/64 loss: 0.3209880590438843
Batch 55/64 loss: 0.3156242370605469
Batch 56/64 loss: 0.3229386806488037
Batch 57/64 loss: 0.3192462921142578
Batch 58/64 loss: 0.3268013000488281
Batch 59/64 loss: 0.32200658321380615
Batch 60/64 loss: 0.31067585945129395
Batch 61/64 loss: 0.33000874519348145
Batch 62/64 loss: 0.32353729009628296
Batch 63/64 loss: 0.3216516971588135
Batch 64/64 loss: 0.32214027643203735
Epoch 272  Train loss: 0.32040469108843334  Val loss: 0.3365049130728155
Saving best model, epoch: 272
Epoch 273
-------------------------------
Batch 1/64 loss: 0.3237643241882324
Batch 2/64 loss: 0.31574535369873047
Batch 3/64 loss: 0.31724727153778076
Batch 4/64 loss: 0.3163655400276184
Batch 5/64 loss: 0.3107846975326538
Batch 6/64 loss: 0.31891709566116333
Batch 7/64 loss: 0.3165695071220398
Batch 8/64 loss: 0.3204672336578369
Batch 9/64 loss: 0.31988346576690674
Batch 10/64 loss: 0.3164461851119995
Batch 11/64 loss: 0.3192732334136963
Batch 12/64 loss: 0.32868480682373047
Batch 13/64 loss: 0.32942771911621094
Batch 14/64 loss: 0.3174804449081421
Batch 15/64 loss: 0.3166050910949707
Batch 16/64 loss: 0.31549572944641113
Batch 17/64 loss: 0.32061445713043213
Batch 18/64 loss: 0.32243263721466064
Batch 19/64 loss: 0.33191001415252686
Batch 20/64 loss: 0.3155639171600342
Batch 21/64 loss: 0.3219612240791321
Batch 22/64 loss: 0.32694077491760254
Batch 23/64 loss: 0.32291311025619507
Batch 24/64 loss: 0.3198344111442566
Batch 25/64 loss: 0.3204469680786133
Batch 26/64 loss: 0.3177671432495117
Batch 27/64 loss: 0.3188246488571167
Batch 28/64 loss: 0.31653648614883423
Batch 29/64 loss: 0.3337022066116333
Batch 30/64 loss: 0.3268970847129822
Batch 31/64 loss: 0.31399428844451904
Batch 32/64 loss: 0.3220255374908447
Batch 33/64 loss: 0.32273757457733154
Batch 34/64 loss: 0.30932551622390747
Batch 35/64 loss: 0.3132129907608032
Batch 36/64 loss: 0.31882596015930176
Batch 37/64 loss: 0.31819504499435425
Batch 38/64 loss: 0.31466954946517944
Batch 39/64 loss: 0.32660675048828125
Batch 40/64 loss: 0.32099002599716187
Batch 41/64 loss: 0.32156145572662354
Batch 42/64 loss: 0.32212889194488525
Batch 43/64 loss: 0.31833863258361816
Batch 44/64 loss: 0.3158549666404724
Batch 45/64 loss: 0.32422035932540894
Batch 46/64 loss: 0.31952881813049316
Batch 47/64 loss: 0.3178219795227051
Batch 48/64 loss: 0.32204174995422363
Batch 49/64 loss: 0.30649399757385254
Batch 50/64 loss: 0.31672531366348267
Batch 51/64 loss: 0.3188026547431946
Batch 52/64 loss: 0.3174755573272705
Batch 53/64 loss: 0.3240079879760742
Batch 54/64 loss: 0.3236936330795288
Batch 55/64 loss: 0.33012115955352783
Batch 56/64 loss: 0.3282409906387329
Batch 57/64 loss: 0.33238959312438965
Batch 58/64 loss: 0.3189449906349182
Batch 59/64 loss: 0.31902897357940674
Batch 60/64 loss: 0.32400500774383545
Batch 61/64 loss: 0.31465572118759155
Batch 62/64 loss: 0.31299149990081787
Batch 63/64 loss: 0.3225284814834595
Batch 64/64 loss: 0.31418800354003906
Epoch 273  Train loss: 0.3201149716096766  Val loss: 0.3393251385885416
Epoch 274
-------------------------------
Batch 1/64 loss: 0.3168010711669922
Batch 2/64 loss: 0.32427269220352173
Batch 3/64 loss: 0.32060039043426514
Batch 4/64 loss: 0.31519967317581177
Batch 5/64 loss: 0.3209361433982849
Batch 6/64 loss: 0.32948267459869385
Batch 7/64 loss: 0.32461780309677124
Batch 8/64 loss: 0.3272908926010132
Batch 9/64 loss: 0.3156924247741699
Batch 10/64 loss: 0.32094526290893555
Batch 11/64 loss: 0.3178021311759949
Batch 12/64 loss: 0.32621216773986816
Batch 13/64 loss: 0.32565194368362427
Batch 14/64 loss: 0.32015156745910645
Batch 15/64 loss: 0.3143678903579712
Batch 16/64 loss: 0.3120920658111572
Batch 17/64 loss: 0.3322709798812866
Batch 18/64 loss: 0.31847769021987915
Batch 19/64 loss: 0.31505072116851807
Batch 20/64 loss: 0.31595373153686523
Batch 21/64 loss: 0.3089413642883301
Batch 22/64 loss: 0.3189060688018799
Batch 23/64 loss: 0.3207000494003296
Batch 24/64 loss: 0.32110124826431274
Batch 25/64 loss: 0.315035343170166
Batch 26/64 loss: 0.31940752267837524
Batch 27/64 loss: 0.32539039850234985
Batch 28/64 loss: 0.31995177268981934
Batch 29/64 loss: 0.3242511749267578
Batch 30/64 loss: 0.3275889754295349
Batch 31/64 loss: 0.3157203197479248
Batch 32/64 loss: 0.31904637813568115
Batch 33/64 loss: 0.31442874670028687
Batch 34/64 loss: 0.310921311378479
Batch 35/64 loss: 0.32283270359039307
Batch 36/64 loss: 0.31642675399780273
Batch 37/64 loss: 0.3180181384086609
Batch 38/64 loss: 0.3181784749031067
Batch 39/64 loss: 0.3217651844024658
Batch 40/64 loss: 0.3303186893463135
Batch 41/64 loss: 0.32545703649520874
Batch 42/64 loss: 0.31510084867477417
Batch 43/64 loss: 0.3185093402862549
Batch 44/64 loss: 0.319582998752594
Batch 45/64 loss: 0.3224142789840698
Batch 46/64 loss: 0.31512337923049927
Batch 47/64 loss: 0.32027679681777954
Batch 48/64 loss: 0.32277166843414307
Batch 49/64 loss: 0.32083970308303833
Batch 50/64 loss: 0.321963369846344
Batch 51/64 loss: 0.3126358985900879
Batch 52/64 loss: 0.32067352533340454
Batch 53/64 loss: 0.3157540559768677
Batch 54/64 loss: 0.3328234553337097
Batch 55/64 loss: 0.32230740785598755
Batch 56/64 loss: 0.3230365514755249
Batch 57/64 loss: 0.31892311573028564
Batch 58/64 loss: 0.31917136907577515
Batch 59/64 loss: 0.3171936273574829
Batch 60/64 loss: 0.3212568759918213
Batch 61/64 loss: 0.3178682327270508
Batch 62/64 loss: 0.3182964324951172
Batch 63/64 loss: 0.3213096857070923
Batch 64/64 loss: 0.3127071261405945
Epoch 274  Train loss: 0.32000973388260484  Val loss: 0.3366136178118257
Epoch 275
-------------------------------
Batch 1/64 loss: 0.317233681678772
Batch 2/64 loss: 0.3161662220954895
Batch 3/64 loss: 0.32369744777679443
Batch 4/64 loss: 0.31361860036849976
Batch 5/64 loss: 0.3147023320198059
Batch 6/64 loss: 0.31165194511413574
Batch 7/64 loss: 0.32170742750167847
Batch 8/64 loss: 0.3215845823287964
Batch 9/64 loss: 0.3185621500015259
Batch 10/64 loss: 0.31675034761428833
Batch 11/64 loss: 0.32411229610443115
Batch 12/64 loss: 0.3124237060546875
Batch 13/64 loss: 0.3175179958343506
Batch 14/64 loss: 0.3100420832633972
Batch 15/64 loss: 0.31881141662597656
Batch 16/64 loss: 0.3259727954864502
Batch 17/64 loss: 0.3199126720428467
Batch 18/64 loss: 0.32172858715057373
Batch 19/64 loss: 0.3204311728477478
Batch 20/64 loss: 0.3160892128944397
Batch 21/64 loss: 0.31574440002441406
Batch 22/64 loss: 0.321089506149292
Batch 23/64 loss: 0.3185906410217285
Batch 24/64 loss: 0.32778072357177734
Batch 25/64 loss: 0.32065683603286743
Batch 26/64 loss: 0.32340317964553833
Batch 27/64 loss: 0.31949329376220703
Batch 28/64 loss: 0.32472264766693115
Batch 29/64 loss: 0.32840514183044434
Batch 30/64 loss: 0.3211325407028198
Batch 31/64 loss: 0.3257002830505371
Batch 32/64 loss: 0.32153141498565674
Batch 33/64 loss: 0.3175630569458008
Batch 34/64 loss: 0.3126739263534546
Batch 35/64 loss: 0.31384187936782837
Batch 36/64 loss: 0.3149452805519104
Batch 37/64 loss: 0.32004547119140625
Batch 38/64 loss: 0.31597447395324707
Batch 39/64 loss: 0.315456748008728
Batch 40/64 loss: 0.32193732261657715
Batch 41/64 loss: 0.3187885284423828
Batch 42/64 loss: 0.3186599016189575
Batch 43/64 loss: 0.32534074783325195
Batch 44/64 loss: 0.3119300603866577
Batch 45/64 loss: 0.31505656242370605
Batch 46/64 loss: 0.32565319538116455
Batch 47/64 loss: 0.3241121768951416
Batch 48/64 loss: 0.3183976411819458
Batch 49/64 loss: 0.31401628255844116
Batch 50/64 loss: 0.32896220684051514
Batch 51/64 loss: 0.32171857357025146
Batch 52/64 loss: 0.31463176012039185
Batch 53/64 loss: 0.3195813298225403
Batch 54/64 loss: 0.3119887113571167
Batch 55/64 loss: 0.32400602102279663
Batch 56/64 loss: 0.31051158905029297
Batch 57/64 loss: 0.32019656896591187
Batch 58/64 loss: 0.32445716857910156
Batch 59/64 loss: 0.3232576251029968
Batch 60/64 loss: 0.3186178207397461
Batch 61/64 loss: 0.32515424489974976
Batch 62/64 loss: 0.3208691477775574
Batch 63/64 loss: 0.3146495819091797
Batch 64/64 loss: 0.3225756883621216
Epoch 275  Train loss: 0.31930815145081165  Val loss: 0.33679298662238105
Epoch 276
-------------------------------
Batch 1/64 loss: 0.3126034736633301
Batch 2/64 loss: 0.31477105617523193
Batch 3/64 loss: 0.31901443004608154
Batch 4/64 loss: 0.3265857696533203
Batch 5/64 loss: 0.32705700397491455
Batch 6/64 loss: 0.3176276683807373
Batch 7/64 loss: 0.3225613832473755
Batch 8/64 loss: 0.32475340366363525
Batch 9/64 loss: 0.31860196590423584
Batch 10/64 loss: 0.32412970066070557
Batch 11/64 loss: 0.31708085536956787
Batch 12/64 loss: 0.31561803817749023
Batch 13/64 loss: 0.33378541469573975
Batch 14/64 loss: 0.31658369302749634
Batch 15/64 loss: 0.3168603181838989
Batch 16/64 loss: 0.3180612325668335
Batch 17/64 loss: 0.3257561922073364
Batch 18/64 loss: 0.321012020111084
Batch 19/64 loss: 0.32507985830307007
Batch 20/64 loss: 0.3190193772315979
Batch 21/64 loss: 0.31415122747421265
Batch 22/64 loss: 0.31880539655685425
Batch 23/64 loss: 0.3154093027114868
Batch 24/64 loss: 0.3227541446685791
Batch 25/64 loss: 0.31877660751342773
Batch 26/64 loss: 0.3178579807281494
Batch 27/64 loss: 0.3173028230667114
Batch 28/64 loss: 0.3153538703918457
Batch 29/64 loss: 0.32299864292144775
Batch 30/64 loss: 0.3236318826675415
Batch 31/64 loss: 0.3207986354827881
Batch 32/64 loss: 0.3242257833480835
Batch 33/64 loss: 0.3124629259109497
Batch 34/64 loss: 0.31772708892822266
Batch 35/64 loss: 0.3210599422454834
Batch 36/64 loss: 0.3169741630554199
Batch 37/64 loss: 0.3148341178894043
Batch 38/64 loss: 0.3145049810409546
Batch 39/64 loss: 0.3194643259048462
Batch 40/64 loss: 0.31244492530822754
Batch 41/64 loss: 0.3165452480316162
Batch 42/64 loss: 0.3173094391822815
Batch 43/64 loss: 0.3189457654953003
Batch 44/64 loss: 0.319089412689209
Batch 45/64 loss: 0.3161965608596802
Batch 46/64 loss: 0.3188049793243408
Batch 47/64 loss: 0.32284820079803467
Batch 48/64 loss: 0.31520378589630127
Batch 49/64 loss: 0.31864142417907715
Batch 50/64 loss: 0.3219713568687439
Batch 51/64 loss: 0.3149714469909668
Batch 52/64 loss: 0.3140925168991089
Batch 53/64 loss: 0.32388854026794434
Batch 54/64 loss: 0.32578301429748535
Batch 55/64 loss: 0.3117091655731201
Batch 56/64 loss: 0.3184702396392822
Batch 57/64 loss: 0.3269280195236206
Batch 58/64 loss: 0.325154185295105
Batch 59/64 loss: 0.3157501220703125
Batch 60/64 loss: 0.31897276639938354
Batch 61/64 loss: 0.3187648057937622
Batch 62/64 loss: 0.3206113576889038
Batch 63/64 loss: 0.32755452394485474
Batch 64/64 loss: 0.3169943690299988
Epoch 276  Train loss: 0.3194361455300275  Val loss: 0.33656362631066966
Epoch 277
-------------------------------
Batch 1/64 loss: 0.31982094049453735
Batch 2/64 loss: 0.32569897174835205
Batch 3/64 loss: 0.3142741918563843
Batch 4/64 loss: 0.31582486629486084
Batch 5/64 loss: 0.315671443939209
Batch 6/64 loss: 0.3151717185974121
Batch 7/64 loss: 0.32224005460739136
Batch 8/64 loss: 0.31755757331848145
Batch 9/64 loss: 0.3155395984649658
Batch 10/64 loss: 0.31263673305511475
Batch 11/64 loss: 0.31571608781814575
Batch 12/64 loss: 0.3216431736946106
Batch 13/64 loss: 0.3020695447921753
Batch 14/64 loss: 0.3102010488510132
Batch 15/64 loss: 0.32324016094207764
Batch 16/64 loss: 0.3221753239631653
Batch 17/64 loss: 0.32038092613220215
Batch 18/64 loss: 0.3185783624649048
Batch 19/64 loss: 0.32536840438842773
Batch 20/64 loss: 0.32166075706481934
Batch 21/64 loss: 0.3226833939552307
Batch 22/64 loss: 0.3200395107269287
Batch 23/64 loss: 0.32783132791519165
Batch 24/64 loss: 0.31551969051361084
Batch 25/64 loss: 0.31865835189819336
Batch 26/64 loss: 0.3243505358695984
Batch 27/64 loss: 0.3288915753364563
Batch 28/64 loss: 0.3152567744255066
Batch 29/64 loss: 0.31375443935394287
Batch 30/64 loss: 0.32467716932296753
Batch 31/64 loss: 0.31864088773727417
Batch 32/64 loss: 0.3108632564544678
Batch 33/64 loss: 0.3217167854309082
Batch 34/64 loss: 0.3166964054107666
Batch 35/64 loss: 0.3187040686607361
Batch 36/64 loss: 0.31650424003601074
Batch 37/64 loss: 0.32437896728515625
Batch 38/64 loss: 0.3195352554321289
Batch 39/64 loss: 0.32375842332839966
Batch 40/64 loss: 0.31438159942626953
Batch 41/64 loss: 0.31980669498443604
Batch 42/64 loss: 0.316257119178772
Batch 43/64 loss: 0.3265003561973572
Batch 44/64 loss: 0.31851625442504883
Batch 45/64 loss: 0.32267075777053833
Batch 46/64 loss: 0.319690465927124
Batch 47/64 loss: 0.3262116312980652
Batch 48/64 loss: 0.3199349641799927
Batch 49/64 loss: 0.32218360900878906
Batch 50/64 loss: 0.3241931200027466
Batch 51/64 loss: 0.32051122188568115
Batch 52/64 loss: 0.3188248872756958
Batch 53/64 loss: 0.3181537389755249
Batch 54/64 loss: 0.31330758333206177
Batch 55/64 loss: 0.3205520510673523
Batch 56/64 loss: 0.3212937116622925
Batch 57/64 loss: 0.32121574878692627
Batch 58/64 loss: 0.3163697123527527
Batch 59/64 loss: 0.31725752353668213
Batch 60/64 loss: 0.3287186026573181
Batch 61/64 loss: 0.32070302963256836
Batch 62/64 loss: 0.3275160789489746
Batch 63/64 loss: 0.32751548290252686
Batch 64/64 loss: 0.31197237968444824
Epoch 277  Train loss: 0.3195952340668323  Val loss: 0.33659683449571487
Epoch 278
-------------------------------
Batch 1/64 loss: 0.32182538509368896
Batch 2/64 loss: 0.3178144693374634
Batch 3/64 loss: 0.3194833993911743
Batch 4/64 loss: 0.31831884384155273
Batch 5/64 loss: 0.32685667276382446
Batch 6/64 loss: 0.31576621532440186
Batch 7/64 loss: 0.31197547912597656
Batch 8/64 loss: 0.3130428194999695
Batch 9/64 loss: 0.32200729846954346
Batch 10/64 loss: 0.31934309005737305
Batch 11/64 loss: 0.3254436254501343
Batch 12/64 loss: 0.32007431983947754
Batch 13/64 loss: 0.3298388123512268
Batch 14/64 loss: 0.314652681350708
Batch 15/64 loss: 0.3185439109802246
Batch 16/64 loss: 0.31495386362075806
Batch 17/64 loss: 0.32413923740386963
Batch 18/64 loss: 0.32332468032836914
Batch 19/64 loss: 0.32811522483825684
Batch 20/64 loss: 0.3212892413139343
Batch 21/64 loss: 0.32537931203842163
Batch 22/64 loss: 0.3228332996368408
Batch 23/64 loss: 0.3200778365135193
Batch 24/64 loss: 0.31146448850631714
Batch 25/64 loss: 0.3201943635940552
Batch 26/64 loss: 0.3213266134262085
Batch 27/64 loss: 0.31447654962539673
Batch 28/64 loss: 0.3144965171813965
Batch 29/64 loss: 0.3139916658401489
Batch 30/64 loss: 0.3189679980278015
Batch 31/64 loss: 0.3237878084182739
Batch 32/64 loss: 0.3144063949584961
Batch 33/64 loss: 0.3293355703353882
Batch 34/64 loss: 0.3188338279724121
Batch 35/64 loss: 0.3273977041244507
Batch 36/64 loss: 0.3190649747848511
Batch 37/64 loss: 0.3177284002304077
Batch 38/64 loss: 0.3110082149505615
Batch 39/64 loss: 0.32136648893356323
Batch 40/64 loss: 0.31191349029541016
Batch 41/64 loss: 0.3189767003059387
Batch 42/64 loss: 0.318212628364563
Batch 43/64 loss: 0.3246203660964966
Batch 44/64 loss: 0.32284897565841675
Batch 45/64 loss: 0.3141658306121826
Batch 46/64 loss: 0.31521356105804443
Batch 47/64 loss: 0.32199203968048096
Batch 48/64 loss: 0.31735360622406006
Batch 49/64 loss: 0.32103490829467773
Batch 50/64 loss: 0.3221941590309143
Batch 51/64 loss: 0.31503981351852417
Batch 52/64 loss: 0.318484902381897
Batch 53/64 loss: 0.31722283363342285
Batch 54/64 loss: 0.31550145149230957
Batch 55/64 loss: 0.3215162754058838
Batch 56/64 loss: 0.32949113845825195
Batch 57/64 loss: 0.3123428225517273
Batch 58/64 loss: 0.31605637073516846
Batch 59/64 loss: 0.322975218296051
Batch 60/64 loss: 0.3187074661254883
Batch 61/64 loss: 0.3161226511001587
Batch 62/64 loss: 0.3206998109817505
Batch 63/64 loss: 0.3230797052383423
Batch 64/64 loss: 0.32288098335266113
Epoch 278  Train loss: 0.3195431335299623  Val loss: 0.3378916987029138
Epoch 279
-------------------------------
Batch 1/64 loss: 0.3091139793395996
Batch 2/64 loss: 0.31890666484832764
Batch 3/64 loss: 0.3149258494377136
Batch 4/64 loss: 0.3166106939315796
Batch 5/64 loss: 0.3338429927825928
Batch 6/64 loss: 0.3181998133659363
Batch 7/64 loss: 0.32128190994262695
Batch 8/64 loss: 0.3180278539657593
Batch 9/64 loss: 0.3147349953651428
Batch 10/64 loss: 0.33052897453308105
Batch 11/64 loss: 0.3172261714935303
Batch 12/64 loss: 0.31795138120651245
Batch 13/64 loss: 0.31562989950180054
Batch 14/64 loss: 0.3162400722503662
Batch 15/64 loss: 0.3161690831184387
Batch 16/64 loss: 0.30841684341430664
Batch 17/64 loss: 0.33011388778686523
Batch 18/64 loss: 0.322231650352478
Batch 19/64 loss: 0.3196265697479248
Batch 20/64 loss: 0.3182886838912964
Batch 21/64 loss: 0.3203437328338623
Batch 22/64 loss: 0.3217233419418335
Batch 23/64 loss: 0.31230151653289795
Batch 24/64 loss: 0.3162745237350464
Batch 25/64 loss: 0.31198441982269287
Batch 26/64 loss: 0.320725679397583
Batch 27/64 loss: 0.32182013988494873
Batch 28/64 loss: 0.3243894577026367
Batch 29/64 loss: 0.3240087032318115
Batch 30/64 loss: 0.31742823123931885
Batch 31/64 loss: 0.33266711235046387
Batch 32/64 loss: 0.31825488805770874
Batch 33/64 loss: 0.32421720027923584
Batch 34/64 loss: 0.32150983810424805
Batch 35/64 loss: 0.3141029477119446
Batch 36/64 loss: 0.3166370391845703
Batch 37/64 loss: 0.3247009515762329
Batch 38/64 loss: 0.3127659559249878
Batch 39/64 loss: 0.3206576108932495
Batch 40/64 loss: 0.32156801223754883
Batch 41/64 loss: 0.31025922298431396
Batch 42/64 loss: 0.3163503408432007
Batch 43/64 loss: 0.32478445768356323
Batch 44/64 loss: 0.31760913133621216
Batch 45/64 loss: 0.3315671682357788
Batch 46/64 loss: 0.31938767433166504
Batch 47/64 loss: 0.3253892660140991
Batch 48/64 loss: 0.32317447662353516
Batch 49/64 loss: 0.320770263671875
Batch 50/64 loss: 0.3208202123641968
Batch 51/64 loss: 0.3203011751174927
Batch 52/64 loss: 0.3171386122703552
Batch 53/64 loss: 0.3134981393814087
Batch 54/64 loss: 0.31208986043930054
Batch 55/64 loss: 0.3187870979309082
Batch 56/64 loss: 0.322205126285553
Batch 57/64 loss: 0.31416749954223633
Batch 58/64 loss: 0.3191152811050415
Batch 59/64 loss: 0.3128472566604614
Batch 60/64 loss: 0.32250577211380005
Batch 61/64 loss: 0.3138076066970825
Batch 62/64 loss: 0.3130480647087097
Batch 63/64 loss: 0.3088688850402832
Batch 64/64 loss: 0.32485973834991455
Epoch 279  Train loss: 0.31903194773430915  Val loss: 0.3371631359726293
Epoch 280
-------------------------------
Batch 1/64 loss: 0.31847381591796875
Batch 2/64 loss: 0.3139811158180237
Batch 3/64 loss: 0.3204854726791382
Batch 4/64 loss: 0.316491961479187
Batch 5/64 loss: 0.31623411178588867
Batch 6/64 loss: 0.3196529150009155
Batch 7/64 loss: 0.3201436996459961
Batch 8/64 loss: 0.3161747455596924
Batch 9/64 loss: 0.31433749198913574
Batch 10/64 loss: 0.32599884271621704
Batch 11/64 loss: 0.3256548047065735
Batch 12/64 loss: 0.31859445571899414
Batch 13/64 loss: 0.3236531615257263
Batch 14/64 loss: 0.3270920515060425
Batch 15/64 loss: 0.32462644577026367
Batch 16/64 loss: 0.3226034641265869
Batch 17/64 loss: 0.3165830969810486
Batch 18/64 loss: 0.317827045917511
Batch 19/64 loss: 0.31926655769348145
Batch 20/64 loss: 0.32011401653289795
Batch 21/64 loss: 0.3260645866394043
Batch 22/64 loss: 0.3223494291305542
Batch 23/64 loss: 0.3175552487373352
Batch 24/64 loss: 0.3139955401420593
Batch 25/64 loss: 0.32012784481048584
Batch 26/64 loss: 0.314131498336792
Batch 27/64 loss: 0.3160899877548218
Batch 28/64 loss: 0.30780893564224243
Batch 29/64 loss: 0.31195926666259766
Batch 30/64 loss: 0.3194018602371216
Batch 31/64 loss: 0.31716084480285645
Batch 32/64 loss: 0.3142244815826416
Batch 33/64 loss: 0.313324511051178
Batch 34/64 loss: 0.32082676887512207
Batch 35/64 loss: 0.32858961820602417
Batch 36/64 loss: 0.31418919563293457
Batch 37/64 loss: 0.3113253116607666
Batch 38/64 loss: 0.3192788362503052
Batch 39/64 loss: 0.32311588525772095
Batch 40/64 loss: 0.3248203992843628
Batch 41/64 loss: 0.319699764251709
Batch 42/64 loss: 0.3128364086151123
Batch 43/64 loss: 0.31954634189605713
Batch 44/64 loss: 0.3267711400985718
Batch 45/64 loss: 0.3247460126876831
Batch 46/64 loss: 0.3197438716888428
Batch 47/64 loss: 0.3100261688232422
Batch 48/64 loss: 0.31635820865631104
Batch 49/64 loss: 0.31967759132385254
Batch 50/64 loss: 0.3185850977897644
Batch 51/64 loss: 0.32066845893859863
Batch 52/64 loss: 0.3198617100715637
Batch 53/64 loss: 0.3196355700492859
Batch 54/64 loss: 0.32916367053985596
Batch 55/64 loss: 0.32011330127716064
Batch 56/64 loss: 0.31243109703063965
Batch 57/64 loss: 0.3150210976600647
Batch 58/64 loss: 0.3088099956512451
Batch 59/64 loss: 0.31717145442962646
Batch 60/64 loss: 0.3201380968093872
Batch 61/64 loss: 0.3162751793861389
Batch 62/64 loss: 0.3130626082420349
Batch 63/64 loss: 0.32544535398483276
Batch 64/64 loss: 0.3198593854904175
Epoch 280  Train loss: 0.31874528725941975  Val loss: 0.3361016182145712
Saving best model, epoch: 280
Epoch 281
-------------------------------
Batch 1/64 loss: 0.31942999362945557
Batch 2/64 loss: 0.3198678493499756
Batch 3/64 loss: 0.3183733820915222
Batch 4/64 loss: 0.3117258548736572
Batch 5/64 loss: 0.31940388679504395
Batch 6/64 loss: 0.3231186866760254
Batch 7/64 loss: 0.31720656156539917
Batch 8/64 loss: 0.32315146923065186
Batch 9/64 loss: 0.3132314085960388
Batch 10/64 loss: 0.3275676965713501
Batch 11/64 loss: 0.31412047147750854
Batch 12/64 loss: 0.3179585337638855
Batch 13/64 loss: 0.3132639527320862
Batch 14/64 loss: 0.31430959701538086
Batch 15/64 loss: 0.3174161911010742
Batch 16/64 loss: 0.3160454034805298
Batch 17/64 loss: 0.313804030418396
Batch 18/64 loss: 0.32015860080718994
Batch 19/64 loss: 0.3196648359298706
Batch 20/64 loss: 0.3173300623893738
Batch 21/64 loss: 0.3123743534088135
Batch 22/64 loss: 0.3244847059249878
Batch 23/64 loss: 0.3175264596939087
Batch 24/64 loss: 0.32345128059387207
Batch 25/64 loss: 0.31824612617492676
Batch 26/64 loss: 0.32583510875701904
Batch 27/64 loss: 0.31725454330444336
Batch 28/64 loss: 0.31285643577575684
Batch 29/64 loss: 0.31802964210510254
Batch 30/64 loss: 0.3186883330345154
Batch 31/64 loss: 0.3204556703567505
Batch 32/64 loss: 0.316524863243103
Batch 33/64 loss: 0.31072646379470825
Batch 34/64 loss: 0.31294912099838257
Batch 35/64 loss: 0.32507389783859253
Batch 36/64 loss: 0.3209373950958252
Batch 37/64 loss: 0.3237884044647217
Batch 38/64 loss: 0.32096654176712036
Batch 39/64 loss: 0.3092923164367676
Batch 40/64 loss: 0.3168991804122925
Batch 41/64 loss: 0.3203660249710083
Batch 42/64 loss: 0.3153949975967407
Batch 43/64 loss: 0.32613861560821533
Batch 44/64 loss: 0.32090747356414795
Batch 45/64 loss: 0.31718337535858154
Batch 46/64 loss: 0.31696271896362305
Batch 47/64 loss: 0.3158743977546692
Batch 48/64 loss: 0.32031357288360596
Batch 49/64 loss: 0.32129162549972534
Batch 50/64 loss: 0.32049715518951416
Batch 51/64 loss: 0.3230733871459961
Batch 52/64 loss: 0.3261040449142456
Batch 53/64 loss: 0.318088173866272
Batch 54/64 loss: 0.3142983913421631
Batch 55/64 loss: 0.32023757696151733
Batch 56/64 loss: 0.31744933128356934
Batch 57/64 loss: 0.32695960998535156
Batch 58/64 loss: 0.31513166427612305
Batch 59/64 loss: 0.31817591190338135
Batch 60/64 loss: 0.32277119159698486
Batch 61/64 loss: 0.3193209171295166
Batch 62/64 loss: 0.3189772367477417
Batch 63/64 loss: 0.3224080801010132
Batch 64/64 loss: 0.3127515912055969
Epoch 281  Train loss: 0.3186823290937087  Val loss: 0.3364297602184859
Epoch 282
-------------------------------
Batch 1/64 loss: 0.32221484184265137
Batch 2/64 loss: 0.3116006851196289
Batch 3/64 loss: 0.31456565856933594
Batch 4/64 loss: 0.31534039974212646
Batch 5/64 loss: 0.3227485418319702
Batch 6/64 loss: 0.32468730211257935
Batch 7/64 loss: 0.3184393644332886
Batch 8/64 loss: 0.31964874267578125
Batch 9/64 loss: 0.31664061546325684
Batch 10/64 loss: 0.3270494341850281
Batch 11/64 loss: 0.320117712020874
Batch 12/64 loss: 0.32194602489471436
Batch 13/64 loss: 0.31976592540740967
Batch 14/64 loss: 0.3079296946525574
Batch 15/64 loss: 0.3233274221420288
Batch 16/64 loss: 0.3218157887458801
Batch 17/64 loss: 0.32665979862213135
Batch 18/64 loss: 0.3234522342681885
Batch 19/64 loss: 0.3135974407196045
Batch 20/64 loss: 0.3186643123626709
Batch 21/64 loss: 0.3178887367248535
Batch 22/64 loss: 0.3240073323249817
Batch 23/64 loss: 0.3195319175720215
Batch 24/64 loss: 0.31291472911834717
Batch 25/64 loss: 0.3190757632255554
Batch 26/64 loss: 0.3163537383079529
Batch 27/64 loss: 0.3106154203414917
Batch 28/64 loss: 0.3192816972732544
Batch 29/64 loss: 0.324168860912323
Batch 30/64 loss: 0.3155878782272339
Batch 31/64 loss: 0.3212165832519531
Batch 32/64 loss: 0.32004058361053467
Batch 33/64 loss: 0.3126455545425415
Batch 34/64 loss: 0.32612311840057373
Batch 35/64 loss: 0.32562923431396484
Batch 36/64 loss: 0.30891847610473633
Batch 37/64 loss: 0.31921857595443726
Batch 38/64 loss: 0.32784879207611084
Batch 39/64 loss: 0.32355254888534546
Batch 40/64 loss: 0.3120740056037903
Batch 41/64 loss: 0.31920480728149414
Batch 42/64 loss: 0.31845343112945557
Batch 43/64 loss: 0.3155655860900879
Batch 44/64 loss: 0.31573158502578735
Batch 45/64 loss: 0.3105456829071045
Batch 46/64 loss: 0.3201087713241577
Batch 47/64 loss: 0.3107302188873291
Batch 48/64 loss: 0.3144282102584839
Batch 49/64 loss: 0.32410889863967896
Batch 50/64 loss: 0.31751370429992676
Batch 51/64 loss: 0.32395684719085693
Batch 52/64 loss: 0.31836259365081787
Batch 53/64 loss: 0.3173564672470093
Batch 54/64 loss: 0.32261478900909424
Batch 55/64 loss: 0.32088756561279297
Batch 56/64 loss: 0.32170337438583374
Batch 57/64 loss: 0.3142857551574707
Batch 58/64 loss: 0.3203120827674866
Batch 59/64 loss: 0.31677448749542236
Batch 60/64 loss: 0.3181003928184509
Batch 61/64 loss: 0.31571030616760254
Batch 62/64 loss: 0.31557929515838623
Batch 63/64 loss: 0.3141438961029053
Batch 64/64 loss: 0.3099737763404846
Epoch 282  Train loss: 0.318518659881517  Val loss: 0.33733610476005527
Epoch 283
-------------------------------
Batch 1/64 loss: 0.3115957975387573
Batch 2/64 loss: 0.31735193729400635
Batch 3/64 loss: 0.30604100227355957
Batch 4/64 loss: 0.31120073795318604
Batch 5/64 loss: 0.321266770362854
Batch 6/64 loss: 0.3135122060775757
Batch 7/64 loss: 0.31816208362579346
Batch 8/64 loss: 0.31810081005096436
Batch 9/64 loss: 0.3181614875793457
Batch 10/64 loss: 0.31442975997924805
Batch 11/64 loss: 0.32522350549697876
Batch 12/64 loss: 0.3198509216308594
Batch 13/64 loss: 0.32611799240112305
Batch 14/64 loss: 0.3148929476737976
Batch 15/64 loss: 0.31376922130584717
Batch 16/64 loss: 0.32462549209594727
Batch 17/64 loss: 0.3172067403793335
Batch 18/64 loss: 0.3175394535064697
Batch 19/64 loss: 0.3163908123970032
Batch 20/64 loss: 0.3155743479728699
Batch 21/64 loss: 0.3299568295478821
Batch 22/64 loss: 0.32668209075927734
Batch 23/64 loss: 0.3167165517807007
Batch 24/64 loss: 0.3208701014518738
Batch 25/64 loss: 0.31859803199768066
Batch 26/64 loss: 0.31975507736206055
Batch 27/64 loss: 0.31845176219940186
Batch 28/64 loss: 0.32315075397491455
Batch 29/64 loss: 0.3171813488006592
Batch 30/64 loss: 0.3213331699371338
Batch 31/64 loss: 0.32329076528549194
Batch 32/64 loss: 0.32043373584747314
Batch 33/64 loss: 0.3177676200866699
Batch 34/64 loss: 0.3191651701927185
Batch 35/64 loss: 0.3106551766395569
Batch 36/64 loss: 0.3205811381340027
Batch 37/64 loss: 0.31535500288009644
Batch 38/64 loss: 0.31710284948349
Batch 39/64 loss: 0.3182145357131958
Batch 40/64 loss: 0.30956578254699707
Batch 41/64 loss: 0.3269991874694824
Batch 42/64 loss: 0.3269168734550476
Batch 43/64 loss: 0.32681804895401
Batch 44/64 loss: 0.32475578784942627
Batch 45/64 loss: 0.32105159759521484
Batch 46/64 loss: 0.3322809934616089
Batch 47/64 loss: 0.3191269040107727
Batch 48/64 loss: 0.3232489824295044
Batch 49/64 loss: 0.31560420989990234
Batch 50/64 loss: 0.3234691619873047
Batch 51/64 loss: 0.31404411792755127
Batch 52/64 loss: 0.31965935230255127
Batch 53/64 loss: 0.3110865354537964
Batch 54/64 loss: 0.31430089473724365
Batch 55/64 loss: 0.32120299339294434
Batch 56/64 loss: 0.31561315059661865
Batch 57/64 loss: 0.3288688659667969
Batch 58/64 loss: 0.30960971117019653
Batch 59/64 loss: 0.3109475374221802
Batch 60/64 loss: 0.32103848457336426
Batch 61/64 loss: 0.3119892477989197
Batch 62/64 loss: 0.31539130210876465
Batch 63/64 loss: 0.32349735498428345
Batch 64/64 loss: 0.31539803743362427
Epoch 283  Train loss: 0.31874370738571767  Val loss: 0.33638805540156935
Epoch 284
-------------------------------
Batch 1/64 loss: 0.32453346252441406
Batch 2/64 loss: 0.3201580047607422
Batch 3/64 loss: 0.32246798276901245
Batch 4/64 loss: 0.3137422204017639
Batch 5/64 loss: 0.32066625356674194
Batch 6/64 loss: 0.31956517696380615
Batch 7/64 loss: 0.31281208992004395
Batch 8/64 loss: 0.3204158544540405
Batch 9/64 loss: 0.31678134202957153
Batch 10/64 loss: 0.308418333530426
Batch 11/64 loss: 0.3176877498626709
Batch 12/64 loss: 0.32856523990631104
Batch 13/64 loss: 0.3238803744316101
Batch 14/64 loss: 0.3219674825668335
Batch 15/64 loss: 0.3157130479812622
Batch 16/64 loss: 0.31218135356903076
Batch 17/64 loss: 0.31677865982055664
Batch 18/64 loss: 0.312252402305603
Batch 19/64 loss: 0.32146215438842773
Batch 20/64 loss: 0.32016050815582275
Batch 21/64 loss: 0.31170332431793213
Batch 22/64 loss: 0.31816810369491577
Batch 23/64 loss: 0.3213422894477844
Batch 24/64 loss: 0.311415433883667
Batch 25/64 loss: 0.3164099454879761
Batch 26/64 loss: 0.3199007511138916
Batch 27/64 loss: 0.3177032470703125
Batch 28/64 loss: 0.31900113821029663
Batch 29/64 loss: 0.32419848442077637
Batch 30/64 loss: 0.3275620937347412
Batch 31/64 loss: 0.32007765769958496
Batch 32/64 loss: 0.32917213439941406
Batch 33/64 loss: 0.319063663482666
Batch 34/64 loss: 0.3206857442855835
Batch 35/64 loss: 0.3116162419319153
Batch 36/64 loss: 0.31286323070526123
Batch 37/64 loss: 0.315596342086792
Batch 38/64 loss: 0.3201199769973755
Batch 39/64 loss: 0.3295799493789673
Batch 40/64 loss: 0.31715500354766846
Batch 41/64 loss: 0.32602763175964355
Batch 42/64 loss: 0.32094866037368774
Batch 43/64 loss: 0.31450366973876953
Batch 44/64 loss: 0.3175218105316162
Batch 45/64 loss: 0.32217949628829956
Batch 46/64 loss: 0.3240194320678711
Batch 47/64 loss: 0.31814730167388916
Batch 48/64 loss: 0.3168931007385254
Batch 49/64 loss: 0.32297348976135254
Batch 50/64 loss: 0.3144351840019226
Batch 51/64 loss: 0.31737852096557617
Batch 52/64 loss: 0.31584787368774414
Batch 53/64 loss: 0.3198786973953247
Batch 54/64 loss: 0.32639503479003906
Batch 55/64 loss: 0.3301076889038086
Batch 56/64 loss: 0.3176998496055603
Batch 57/64 loss: 0.3168533444404602
Batch 58/64 loss: 0.316969633102417
Batch 59/64 loss: 0.318922221660614
Batch 60/64 loss: 0.32022619247436523
Batch 61/64 loss: 0.3185610771179199
Batch 62/64 loss: 0.31266921758651733
Batch 63/64 loss: 0.307661771774292
Batch 64/64 loss: 0.31690365076065063
Epoch 284  Train loss: 0.31887126413046146  Val loss: 0.3379852571028614
Epoch 285
-------------------------------
Batch 1/64 loss: 0.3242250680923462
Batch 2/64 loss: 0.32160496711730957
Batch 3/64 loss: 0.3218676447868347
Batch 4/64 loss: 0.3210873603820801
Batch 5/64 loss: 0.3190983533859253
Batch 6/64 loss: 0.31367766857147217
Batch 7/64 loss: 0.3194422721862793
Batch 8/64 loss: 0.32789379358291626
Batch 9/64 loss: 0.319888710975647
Batch 10/64 loss: 0.30993640422821045
Batch 11/64 loss: 0.307092547416687
Batch 12/64 loss: 0.31968116760253906
Batch 13/64 loss: 0.3184894323348999
Batch 14/64 loss: 0.322762131690979
Batch 15/64 loss: 0.3167473077774048
Batch 16/64 loss: 0.32137829065322876
Batch 17/64 loss: 0.3166048526763916
Batch 18/64 loss: 0.3095262050628662
Batch 19/64 loss: 0.32345259189605713
Batch 20/64 loss: 0.3154863119125366
Batch 21/64 loss: 0.31732869148254395
Batch 22/64 loss: 0.30959630012512207
Batch 23/64 loss: 0.3205831050872803
Batch 24/64 loss: 0.3160826563835144
Batch 25/64 loss: 0.31690698862075806
Batch 26/64 loss: 0.31474435329437256
Batch 27/64 loss: 0.31919801235198975
Batch 28/64 loss: 0.3197769522666931
Batch 29/64 loss: 0.3214890956878662
Batch 30/64 loss: 0.3202130198478699
Batch 31/64 loss: 0.31880784034729004
Batch 32/64 loss: 0.32338714599609375
Batch 33/64 loss: 0.31778496503829956
Batch 34/64 loss: 0.3212317228317261
Batch 35/64 loss: 0.31109148263931274
Batch 36/64 loss: 0.3188081979751587
Batch 37/64 loss: 0.320737361907959
Batch 38/64 loss: 0.3194825053215027
Batch 39/64 loss: 0.3043344020843506
Batch 40/64 loss: 0.3139159679412842
Batch 41/64 loss: 0.3236351013183594
Batch 42/64 loss: 0.3177528381347656
Batch 43/64 loss: 0.31122058629989624
Batch 44/64 loss: 0.3145120143890381
Batch 45/64 loss: 0.3184417486190796
Batch 46/64 loss: 0.3218345642089844
Batch 47/64 loss: 0.32068341970443726
Batch 48/64 loss: 0.3107219934463501
Batch 49/64 loss: 0.3185003995895386
Batch 50/64 loss: 0.32785314321517944
Batch 51/64 loss: 0.3144591450691223
Batch 52/64 loss: 0.32016122341156006
Batch 53/64 loss: 0.32907140254974365
Batch 54/64 loss: 0.3230983018875122
Batch 55/64 loss: 0.31706011295318604
Batch 56/64 loss: 0.3211662769317627
Batch 57/64 loss: 0.3290676474571228
Batch 58/64 loss: 0.32394444942474365
Batch 59/64 loss: 0.31867504119873047
Batch 60/64 loss: 0.3140522837638855
Batch 61/64 loss: 0.3217797875404358
Batch 62/64 loss: 0.31383949518203735
Batch 63/64 loss: 0.32346808910369873
Batch 64/64 loss: 0.31228482723236084
Epoch 285  Train loss: 0.31850441624136533  Val loss: 0.33629392635371674
Epoch 286
-------------------------------
Batch 1/64 loss: 0.3073912262916565
Batch 2/64 loss: 0.3203256130218506
Batch 3/64 loss: 0.3152279853820801
Batch 4/64 loss: 0.31891196966171265
Batch 5/64 loss: 0.3171178102493286
Batch 6/64 loss: 0.3246210217475891
Batch 7/64 loss: 0.32022446393966675
Batch 8/64 loss: 0.3234938383102417
Batch 9/64 loss: 0.3155384063720703
Batch 10/64 loss: 0.32413554191589355
Batch 11/64 loss: 0.3107489347457886
Batch 12/64 loss: 0.3240853548049927
Batch 13/64 loss: 0.31708890199661255
Batch 14/64 loss: 0.31217479705810547
Batch 15/64 loss: 0.31331348419189453
Batch 16/64 loss: 0.32125604152679443
Batch 17/64 loss: 0.3169390559196472
Batch 18/64 loss: 0.3115050792694092
Batch 19/64 loss: 0.31944429874420166
Batch 20/64 loss: 0.31901460886001587
Batch 21/64 loss: 0.31425154209136963
Batch 22/64 loss: 0.3061412572860718
Batch 23/64 loss: 0.3160977363586426
Batch 24/64 loss: 0.3176521062850952
Batch 25/64 loss: 0.31771188974380493
Batch 26/64 loss: 0.3169472813606262
Batch 27/64 loss: 0.32181626558303833
Batch 28/64 loss: 0.32306110858917236
Batch 29/64 loss: 0.320285439491272
Batch 30/64 loss: 0.325069785118103
Batch 31/64 loss: 0.3164218068122864
Batch 32/64 loss: 0.3206470012664795
Batch 33/64 loss: 0.31776171922683716
Batch 34/64 loss: 0.31122922897338867
Batch 35/64 loss: 0.3246755599975586
Batch 36/64 loss: 0.31601381301879883
Batch 37/64 loss: 0.31819260120391846
Batch 38/64 loss: 0.3090324401855469
Batch 39/64 loss: 0.3241327404975891
Batch 40/64 loss: 0.32081902027130127
Batch 41/64 loss: 0.3138793706893921
Batch 42/64 loss: 0.3116326928138733
Batch 43/64 loss: 0.32870960235595703
Batch 44/64 loss: 0.31512582302093506
Batch 45/64 loss: 0.3159749507904053
Batch 46/64 loss: 0.3191426992416382
Batch 47/64 loss: 0.3210357427597046
Batch 48/64 loss: 0.3242349624633789
Batch 49/64 loss: 0.32551854848861694
Batch 50/64 loss: 0.3265940546989441
Batch 51/64 loss: 0.3215029239654541
Batch 52/64 loss: 0.31749457120895386
Batch 53/64 loss: 0.3130671977996826
Batch 54/64 loss: 0.31146931648254395
Batch 55/64 loss: 0.31239545345306396
Batch 56/64 loss: 0.3188192844390869
Batch 57/64 loss: 0.3305727243423462
Batch 58/64 loss: 0.3129892945289612
Batch 59/64 loss: 0.3174670934677124
Batch 60/64 loss: 0.32670021057128906
Batch 61/64 loss: 0.32749736309051514
Batch 62/64 loss: 0.3174753189086914
Batch 63/64 loss: 0.32871752977371216
Batch 64/64 loss: 0.3173815608024597
Epoch 286  Train loss: 0.31853445768356325  Val loss: 0.3370390089926441
Epoch 287
-------------------------------
Batch 1/64 loss: 0.3110637664794922
Batch 2/64 loss: 0.31975221633911133
Batch 3/64 loss: 0.32184648513793945
Batch 4/64 loss: 0.31277239322662354
Batch 5/64 loss: 0.3186432123184204
Batch 6/64 loss: 0.3204256296157837
Batch 7/64 loss: 0.3093562722206116
Batch 8/64 loss: 0.3158313035964966
Batch 9/64 loss: 0.3180004358291626
Batch 10/64 loss: 0.3206961154937744
Batch 11/64 loss: 0.3168710470199585
Batch 12/64 loss: 0.32426202297210693
Batch 13/64 loss: 0.32764899730682373
Batch 14/64 loss: 0.3190479278564453
Batch 15/64 loss: 0.3109723925590515
Batch 16/64 loss: 0.3230816721916199
Batch 17/64 loss: 0.32126355171203613
Batch 18/64 loss: 0.31196892261505127
Batch 19/64 loss: 0.3176335096359253
Batch 20/64 loss: 0.3141767382621765
Batch 21/64 loss: 0.3145331144332886
Batch 22/64 loss: 0.31338071823120117
Batch 23/64 loss: 0.31946390867233276
Batch 24/64 loss: 0.3228722810745239
Batch 25/64 loss: 0.31894296407699585
Batch 26/64 loss: 0.3150339126586914
Batch 27/64 loss: 0.32341814041137695
Batch 28/64 loss: 0.3142881989479065
Batch 29/64 loss: 0.3207804560661316
Batch 30/64 loss: 0.31805670261383057
Batch 31/64 loss: 0.3156379461288452
Batch 32/64 loss: 0.3172250986099243
Batch 33/64 loss: 0.3202470541000366
Batch 34/64 loss: 0.3293749690055847
Batch 35/64 loss: 0.31791841983795166
Batch 36/64 loss: 0.31362438201904297
Batch 37/64 loss: 0.3128175139427185
Batch 38/64 loss: 0.32054245471954346
Batch 39/64 loss: 0.3189072608947754
Batch 40/64 loss: 0.32305479049682617
Batch 41/64 loss: 0.31512075662612915
Batch 42/64 loss: 0.31778132915496826
Batch 43/64 loss: 0.3187410831451416
Batch 44/64 loss: 0.3200451731681824
Batch 45/64 loss: 0.3195040822029114
Batch 46/64 loss: 0.31810134649276733
Batch 47/64 loss: 0.31860458850860596
Batch 48/64 loss: 0.32706308364868164
Batch 49/64 loss: 0.3200768232345581
Batch 50/64 loss: 0.3133470416069031
Batch 51/64 loss: 0.31296730041503906
Batch 52/64 loss: 0.3169909715652466
Batch 53/64 loss: 0.31952083110809326
Batch 54/64 loss: 0.3138035535812378
Batch 55/64 loss: 0.30873316526412964
Batch 56/64 loss: 0.31775420904159546
Batch 57/64 loss: 0.3175405263900757
Batch 58/64 loss: 0.3108961582183838
Batch 59/64 loss: 0.33176958560943604
Batch 60/64 loss: 0.3232165575027466
Batch 61/64 loss: 0.3215494155883789
Batch 62/64 loss: 0.3230956792831421
Batch 63/64 loss: 0.3216867446899414
Batch 64/64 loss: 0.31939399242401123
Epoch 287  Train loss: 0.31831984940697167  Val loss: 0.3357087365540442
Saving best model, epoch: 287
Epoch 288
-------------------------------
Batch 1/64 loss: 0.32013070583343506
Batch 2/64 loss: 0.309495747089386
Batch 3/64 loss: 0.31221771240234375
Batch 4/64 loss: 0.31136584281921387
Batch 5/64 loss: 0.31483060121536255
Batch 6/64 loss: 0.3226279020309448
Batch 7/64 loss: 0.3129764795303345
Batch 8/64 loss: 0.31209325790405273
Batch 9/64 loss: 0.32592272758483887
Batch 10/64 loss: 0.3170899748802185
Batch 11/64 loss: 0.32603633403778076
Batch 12/64 loss: 0.3133595585823059
Batch 13/64 loss: 0.3223998546600342
Batch 14/64 loss: 0.31561487913131714
Batch 15/64 loss: 0.3153728246688843
Batch 16/64 loss: 0.30903565883636475
Batch 17/64 loss: 0.31909024715423584
Batch 18/64 loss: 0.31642115116119385
Batch 19/64 loss: 0.3193354606628418
Batch 20/64 loss: 0.3232179880142212
Batch 21/64 loss: 0.33623194694519043
Batch 22/64 loss: 0.3205684423446655
Batch 23/64 loss: 0.317324161529541
Batch 24/64 loss: 0.3159046173095703
Batch 25/64 loss: 0.31419670581817627
Batch 26/64 loss: 0.3155691623687744
Batch 27/64 loss: 0.32228779792785645
Batch 28/64 loss: 0.326246440410614
Batch 29/64 loss: 0.31473398208618164
Batch 30/64 loss: 0.317150354385376
Batch 31/64 loss: 0.3210877776145935
Batch 32/64 loss: 0.318248987197876
Batch 33/64 loss: 0.310519814491272
Batch 34/64 loss: 0.321181058883667
Batch 35/64 loss: 0.3184388279914856
Batch 36/64 loss: 0.3162614107131958
Batch 37/64 loss: 0.3139573931694031
Batch 38/64 loss: 0.32289987802505493
Batch 39/64 loss: 0.3142869472503662
Batch 40/64 loss: 0.32257401943206787
Batch 41/64 loss: 0.3244050145149231
Batch 42/64 loss: 0.31708699464797974
Batch 43/64 loss: 0.31853628158569336
Batch 44/64 loss: 0.31704407930374146
Batch 45/64 loss: 0.32488858699798584
Batch 46/64 loss: 0.3153223991394043
Batch 47/64 loss: 0.31120896339416504
Batch 48/64 loss: 0.31461578607559204
Batch 49/64 loss: 0.3172495365142822
Batch 50/64 loss: 0.3198006749153137
Batch 51/64 loss: 0.30573320388793945
Batch 52/64 loss: 0.31975436210632324
Batch 53/64 loss: 0.3208850622177124
Batch 54/64 loss: 0.3281235694885254
Batch 55/64 loss: 0.327100932598114
Batch 56/64 loss: 0.3058372735977173
Batch 57/64 loss: 0.31804680824279785
Batch 58/64 loss: 0.3188193440437317
Batch 59/64 loss: 0.33033937215805054
Batch 60/64 loss: 0.3109400272369385
Batch 61/64 loss: 0.32136720418930054
Batch 62/64 loss: 0.3189985752105713
Batch 63/64 loss: 0.3183678388595581
Batch 64/64 loss: 0.31268036365509033
Epoch 288  Train loss: 0.31807508702371634  Val loss: 0.33576020752031777
Epoch 289
-------------------------------
Batch 1/64 loss: 0.32314932346343994
Batch 2/64 loss: 0.32447350025177
Batch 3/64 loss: 0.31075358390808105
Batch 4/64 loss: 0.3158237934112549
Batch 5/64 loss: 0.3123213052749634
Batch 6/64 loss: 0.31976252794265747
Batch 7/64 loss: 0.3104187250137329
Batch 8/64 loss: 0.31629401445388794
Batch 9/64 loss: 0.3218778371810913
Batch 10/64 loss: 0.3100935220718384
Batch 11/64 loss: 0.3093290328979492
Batch 12/64 loss: 0.3189550042152405
Batch 13/64 loss: 0.31343430280685425
Batch 14/64 loss: 0.31682276725769043
Batch 15/64 loss: 0.3268846273422241
Batch 16/64 loss: 0.31901586055755615
Batch 17/64 loss: 0.3167153596878052
Batch 18/64 loss: 0.31462591886520386
Batch 19/64 loss: 0.3201254606246948
Batch 20/64 loss: 0.3189566731452942
Batch 21/64 loss: 0.3272864818572998
Batch 22/64 loss: 0.30645596981048584
Batch 23/64 loss: 0.3251262307167053
Batch 24/64 loss: 0.31883394718170166
Batch 25/64 loss: 0.3218036890029907
Batch 26/64 loss: 0.3156583309173584
Batch 27/64 loss: 0.3169230818748474
Batch 28/64 loss: 0.31835246086120605
Batch 29/64 loss: 0.3227043151855469
Batch 30/64 loss: 0.32114070653915405
Batch 31/64 loss: 0.31962108612060547
Batch 32/64 loss: 0.32163137197494507
Batch 33/64 loss: 0.31328821182250977
Batch 34/64 loss: 0.3147106170654297
Batch 35/64 loss: 0.3212023973464966
Batch 36/64 loss: 0.3152221441268921
Batch 37/64 loss: 0.3183025121688843
Batch 38/64 loss: 0.32143425941467285
Batch 39/64 loss: 0.30581390857696533
Batch 40/64 loss: 0.3245328664779663
Batch 41/64 loss: 0.3116806745529175
Batch 42/64 loss: 0.3184664249420166
Batch 43/64 loss: 0.3109191656112671
Batch 44/64 loss: 0.3131147027015686
Batch 45/64 loss: 0.31681692600250244
Batch 46/64 loss: 0.31106507778167725
Batch 47/64 loss: 0.3107811212539673
Batch 48/64 loss: 0.31240570545196533
Batch 49/64 loss: 0.32596635818481445
Batch 50/64 loss: 0.31445831060409546
Batch 51/64 loss: 0.3177538514137268
Batch 52/64 loss: 0.31859123706817627
Batch 53/64 loss: 0.317757785320282
Batch 54/64 loss: 0.3171513080596924
Batch 55/64 loss: 0.3117802143096924
Batch 56/64 loss: 0.31715917587280273
Batch 57/64 loss: 0.31727010011672974
Batch 58/64 loss: 0.3261605501174927
Batch 59/64 loss: 0.32437610626220703
Batch 60/64 loss: 0.31539714336395264
Batch 61/64 loss: 0.3129333257675171
Batch 62/64 loss: 0.32473844289779663
Batch 63/64 loss: 0.31630998849868774
Batch 64/64 loss: 0.31215351819992065
Epoch 289  Train loss: 0.31728700492896283  Val loss: 0.3361981435330053
Epoch 290
-------------------------------
Batch 1/64 loss: 0.3177688717842102
Batch 2/64 loss: 0.3167991638183594
Batch 3/64 loss: 0.32613039016723633
Batch 4/64 loss: 0.3220304250717163
Batch 5/64 loss: 0.3265342712402344
Batch 6/64 loss: 0.32231926918029785
Batch 7/64 loss: 0.3101217746734619
Batch 8/64 loss: 0.3140498995780945
Batch 9/64 loss: 0.31587350368499756
Batch 10/64 loss: 0.31835317611694336
Batch 11/64 loss: 0.3190586566925049
Batch 12/64 loss: 0.3282175064086914
Batch 13/64 loss: 0.3167903423309326
Batch 14/64 loss: 0.31798601150512695
Batch 15/64 loss: 0.314813494682312
Batch 16/64 loss: 0.32553601264953613
Batch 17/64 loss: 0.3087586760520935
Batch 18/64 loss: 0.32437604665756226
Batch 19/64 loss: 0.3212573528289795
Batch 20/64 loss: 0.30964088439941406
Batch 21/64 loss: 0.31695520877838135
Batch 22/64 loss: 0.32609909772872925
Batch 23/64 loss: 0.30627816915512085
Batch 24/64 loss: 0.31198710203170776
Batch 25/64 loss: 0.31085675954818726
Batch 26/64 loss: 0.31405746936798096
Batch 27/64 loss: 0.31387484073638916
Batch 28/64 loss: 0.3118288516998291
Batch 29/64 loss: 0.31909269094467163
Batch 30/64 loss: 0.32076334953308105
Batch 31/64 loss: 0.31033921241760254
Batch 32/64 loss: 0.31566619873046875
Batch 33/64 loss: 0.328976571559906
Batch 34/64 loss: 0.32094359397888184
Batch 35/64 loss: 0.31569623947143555
Batch 36/64 loss: 0.3220266103744507
Batch 37/64 loss: 0.3150886297225952
Batch 38/64 loss: 0.32297229766845703
Batch 39/64 loss: 0.3189985752105713
Batch 40/64 loss: 0.3113812208175659
Batch 41/64 loss: 0.3209564685821533
Batch 42/64 loss: 0.31691229343414307
Batch 43/64 loss: 0.31417346000671387
Batch 44/64 loss: 0.3117610216140747
Batch 45/64 loss: 0.3138658404350281
Batch 46/64 loss: 0.3196794390678406
Batch 47/64 loss: 0.3192710876464844
Batch 48/64 loss: 0.3237500786781311
Batch 49/64 loss: 0.3189351558685303
Batch 50/64 loss: 0.3195534944534302
Batch 51/64 loss: 0.3147738575935364
Batch 52/64 loss: 0.31427788734436035
Batch 53/64 loss: 0.31712764501571655
Batch 54/64 loss: 0.31476032733917236
Batch 55/64 loss: 0.3178708553314209
Batch 56/64 loss: 0.3063492774963379
Batch 57/64 loss: 0.31404685974121094
Batch 58/64 loss: 0.3218100666999817
Batch 59/64 loss: 0.3155691623687744
Batch 60/64 loss: 0.31361091136932373
Batch 61/64 loss: 0.3126734495162964
Batch 62/64 loss: 0.3236933946609497
Batch 63/64 loss: 0.31389492750167847
Batch 64/64 loss: 0.32263433933258057
Epoch 290  Train loss: 0.31735829231785795  Val loss: 0.3361933001947567
Epoch 291
-------------------------------
Batch 1/64 loss: 0.30936700105667114
Batch 2/64 loss: 0.3225790858268738
Batch 3/64 loss: 0.32402652502059937
Batch 4/64 loss: 0.31853556632995605
Batch 5/64 loss: 0.3150097131729126
Batch 6/64 loss: 0.32221007347106934
Batch 7/64 loss: 0.3176017999649048
Batch 8/64 loss: 0.3145919442176819
Batch 9/64 loss: 0.31421756744384766
Batch 10/64 loss: 0.3064873218536377
Batch 11/64 loss: 0.315582275390625
Batch 12/64 loss: 0.32560431957244873
Batch 13/64 loss: 0.3117411136627197
Batch 14/64 loss: 0.3129110336303711
Batch 15/64 loss: 0.3162027597427368
Batch 16/64 loss: 0.3155008554458618
Batch 17/64 loss: 0.3269730806350708
Batch 18/64 loss: 0.3195093274116516
Batch 19/64 loss: 0.3150637149810791
Batch 20/64 loss: 0.30868732929229736
Batch 21/64 loss: 0.31528031826019287
Batch 22/64 loss: 0.31853365898132324
Batch 23/64 loss: 0.31448543071746826
Batch 24/64 loss: 0.31009697914123535
Batch 25/64 loss: 0.31973546743392944
Batch 26/64 loss: 0.31470680236816406
Batch 27/64 loss: 0.3099701404571533
Batch 28/64 loss: 0.31462275981903076
Batch 29/64 loss: 0.3163341283798218
Batch 30/64 loss: 0.3108154535293579
Batch 31/64 loss: 0.32084715366363525
Batch 32/64 loss: 0.3228556513786316
Batch 33/64 loss: 0.3189493417739868
Batch 34/64 loss: 0.32105064392089844
Batch 35/64 loss: 0.31231772899627686
Batch 36/64 loss: 0.3228178024291992
Batch 37/64 loss: 0.31450384855270386
Batch 38/64 loss: 0.31886816024780273
Batch 39/64 loss: 0.3149566054344177
Batch 40/64 loss: 0.31592321395874023
Batch 41/64 loss: 0.3142176866531372
Batch 42/64 loss: 0.3281790018081665
Batch 43/64 loss: 0.31898701190948486
Batch 44/64 loss: 0.3109564781188965
Batch 45/64 loss: 0.31747543811798096
Batch 46/64 loss: 0.3144516348838806
Batch 47/64 loss: 0.31907403469085693
Batch 48/64 loss: 0.319568395614624
Batch 49/64 loss: 0.31691205501556396
Batch 50/64 loss: 0.31419312953948975
Batch 51/64 loss: 0.3165183663368225
Batch 52/64 loss: 0.31550800800323486
Batch 53/64 loss: 0.31475627422332764
Batch 54/64 loss: 0.31835120916366577
Batch 55/64 loss: 0.3187364935874939
Batch 56/64 loss: 0.327100932598114
Batch 57/64 loss: 0.32094013690948486
Batch 58/64 loss: 0.329262375831604
Batch 59/64 loss: 0.3240088224411011
Batch 60/64 loss: 0.32028090953826904
Batch 61/64 loss: 0.32352423667907715
Batch 62/64 loss: 0.32213759422302246
Batch 63/64 loss: 0.32432425022125244
Batch 64/64 loss: 0.3132680058479309
Epoch 291  Train loss: 0.31756061455782725  Val loss: 0.33585264162509304
Epoch 292
-------------------------------
Batch 1/64 loss: 0.3117009997367859
Batch 2/64 loss: 0.3200567960739136
Batch 3/64 loss: 0.31739556789398193
Batch 4/64 loss: 0.31599801778793335
Batch 5/64 loss: 0.31641829013824463
Batch 6/64 loss: 0.32463014125823975
Batch 7/64 loss: 0.31959080696105957
Batch 8/64 loss: 0.3222261667251587
Batch 9/64 loss: 0.31739580631256104
Batch 10/64 loss: 0.3243381977081299
Batch 11/64 loss: 0.3169759511947632
Batch 12/64 loss: 0.32420098781585693
Batch 13/64 loss: 0.3158247470855713
Batch 14/64 loss: 0.31964242458343506
Batch 15/64 loss: 0.33740782737731934
Batch 16/64 loss: 0.31487929821014404
Batch 17/64 loss: 0.32016146183013916
Batch 18/64 loss: 0.31047797203063965
Batch 19/64 loss: 0.3221479654312134
Batch 20/64 loss: 0.31349068880081177
Batch 21/64 loss: 0.3082747459411621
Batch 22/64 loss: 0.30487656593322754
Batch 23/64 loss: 0.31540369987487793
Batch 24/64 loss: 0.3119850158691406
Batch 25/64 loss: 0.31805771589279175
Batch 26/64 loss: 0.31772124767303467
Batch 27/64 loss: 0.31230396032333374
Batch 28/64 loss: 0.31454896926879883
Batch 29/64 loss: 0.3144381642341614
Batch 30/64 loss: 0.31368905305862427
Batch 31/64 loss: 0.3230644464492798
Batch 32/64 loss: 0.3152909278869629
Batch 33/64 loss: 0.31662631034851074
Batch 34/64 loss: 0.32265734672546387
Batch 35/64 loss: 0.314405620098114
Batch 36/64 loss: 0.3142915964126587
Batch 37/64 loss: 0.31473708152770996
Batch 38/64 loss: 0.3104221820831299
Batch 39/64 loss: 0.3108031749725342
Batch 40/64 loss: 0.3156850337982178
Batch 41/64 loss: 0.3217485547065735
Batch 42/64 loss: 0.31405651569366455
Batch 43/64 loss: 0.31913191080093384
Batch 44/64 loss: 0.3158162832260132
Batch 45/64 loss: 0.3173912763595581
Batch 46/64 loss: 0.31973016262054443
Batch 47/64 loss: 0.3184637427330017
Batch 48/64 loss: 0.3180058002471924
Batch 49/64 loss: 0.315740704536438
Batch 50/64 loss: 0.31453680992126465
Batch 51/64 loss: 0.3103806972503662
Batch 52/64 loss: 0.31779617071151733
Batch 53/64 loss: 0.31165677309036255
Batch 54/64 loss: 0.31908583641052246
Batch 55/64 loss: 0.31971704959869385
Batch 56/64 loss: 0.3198143243789673
Batch 57/64 loss: 0.3202873468399048
Batch 58/64 loss: 0.32140547037124634
Batch 59/64 loss: 0.3200525641441345
Batch 60/64 loss: 0.3220856189727783
Batch 61/64 loss: 0.3225638270378113
Batch 62/64 loss: 0.3230157494544983
Batch 63/64 loss: 0.3257560729980469
Batch 64/64 loss: 0.32607465982437134
Epoch 292  Train loss: 0.3176005996909796  Val loss: 0.3369715250644487
Epoch 293
-------------------------------
Batch 1/64 loss: 0.31603264808654785
Batch 2/64 loss: 0.3238546848297119
Batch 3/64 loss: 0.3198237419128418
Batch 4/64 loss: 0.32112979888916016
Batch 5/64 loss: 0.3176867365837097
Batch 6/64 loss: 0.3119537830352783
Batch 7/64 loss: 0.31765246391296387
Batch 8/64 loss: 0.31734955310821533
Batch 9/64 loss: 0.3192046880722046
Batch 10/64 loss: 0.32014429569244385
Batch 11/64 loss: 0.32808059453964233
Batch 12/64 loss: 0.3258928060531616
Batch 13/64 loss: 0.3175850510597229
Batch 14/64 loss: 0.3121204376220703
Batch 15/64 loss: 0.31979238986968994
Batch 16/64 loss: 0.31351709365844727
Batch 17/64 loss: 0.31365054845809937
Batch 18/64 loss: 0.3105192184448242
Batch 19/64 loss: 0.32992494106292725
Batch 20/64 loss: 0.31304681301116943
Batch 21/64 loss: 0.31725412607192993
Batch 22/64 loss: 0.3146333694458008
Batch 23/64 loss: 0.315987229347229
Batch 24/64 loss: 0.3123512268066406
Batch 25/64 loss: 0.3081703186035156
Batch 26/64 loss: 0.3121826648712158
Batch 27/64 loss: 0.32070207595825195
Batch 28/64 loss: 0.3145374059677124
Batch 29/64 loss: 0.3145673871040344
Batch 30/64 loss: 0.3229373097419739
Batch 31/64 loss: 0.31002700328826904
Batch 32/64 loss: 0.31952333450317383
Batch 33/64 loss: 0.3089366555213928
Batch 34/64 loss: 0.32192879915237427
Batch 35/64 loss: 0.3201315999031067
Batch 36/64 loss: 0.3215392827987671
Batch 37/64 loss: 0.31913286447525024
Batch 38/64 loss: 0.3117745518684387
Batch 39/64 loss: 0.3150695562362671
Batch 40/64 loss: 0.30917584896087646
Batch 41/64 loss: 0.30762481689453125
Batch 42/64 loss: 0.311437726020813
Batch 43/64 loss: 0.31111574172973633
Batch 44/64 loss: 0.3124611973762512
Batch 45/64 loss: 0.3194649815559387
Batch 46/64 loss: 0.3198435306549072
Batch 47/64 loss: 0.31802302598953247
Batch 48/64 loss: 0.32872748374938965
Batch 49/64 loss: 0.327908992767334
Batch 50/64 loss: 0.32010185718536377
Batch 51/64 loss: 0.32056528329849243
Batch 52/64 loss: 0.31755703687667847
Batch 53/64 loss: 0.3180220127105713
Batch 54/64 loss: 0.3166816234588623
Batch 55/64 loss: 0.3145357370376587
Batch 56/64 loss: 0.3219132423400879
Batch 57/64 loss: 0.3149109482765198
Batch 58/64 loss: 0.32059967517852783
Batch 59/64 loss: 0.3110314607620239
Batch 60/64 loss: 0.32359087467193604
Batch 61/64 loss: 0.3114020824432373
Batch 62/64 loss: 0.3212442398071289
Batch 63/64 loss: 0.3230261206626892
Batch 64/64 loss: 0.325722873210907
Epoch 293  Train loss: 0.3174212822727129  Val loss: 0.33705363670984906
Epoch 294
-------------------------------
Batch 1/64 loss: 0.320673406124115
Batch 2/64 loss: 0.3141435384750366
Batch 3/64 loss: 0.31475329399108887
Batch 4/64 loss: 0.3153543472290039
Batch 5/64 loss: 0.32056933641433716
Batch 6/64 loss: 0.3213205337524414
Batch 7/64 loss: 0.31258851289749146
Batch 8/64 loss: 0.3170439600944519
Batch 9/64 loss: 0.3175175189971924
Batch 10/64 loss: 0.31974297761917114
Batch 11/64 loss: 0.32620078325271606
Batch 12/64 loss: 0.31720781326293945
Batch 13/64 loss: 0.3121255040168762
Batch 14/64 loss: 0.3215716481208801
Batch 15/64 loss: 0.3141893148422241
Batch 16/64 loss: 0.3259913921356201
Batch 17/64 loss: 0.3113235831260681
Batch 18/64 loss: 0.3220972418785095
Batch 19/64 loss: 0.3236567974090576
Batch 20/64 loss: 0.31095290184020996
Batch 21/64 loss: 0.31518614292144775
Batch 22/64 loss: 0.3148525357246399
Batch 23/64 loss: 0.30838680267333984
Batch 24/64 loss: 0.3179982304573059
Batch 25/64 loss: 0.31465280055999756
Batch 26/64 loss: 0.32155048847198486
Batch 27/64 loss: 0.320209264755249
Batch 28/64 loss: 0.3128512501716614
Batch 29/64 loss: 0.31866735219955444
Batch 30/64 loss: 0.31665050983428955
Batch 31/64 loss: 0.3114432096481323
Batch 32/64 loss: 0.3168463110923767
Batch 33/64 loss: 0.31232523918151855
Batch 34/64 loss: 0.3247809410095215
Batch 35/64 loss: 0.3139505386352539
Batch 36/64 loss: 0.3217400908470154
Batch 37/64 loss: 0.3244670629501343
Batch 38/64 loss: 0.3162655830383301
Batch 39/64 loss: 0.31634294986724854
Batch 40/64 loss: 0.31683099269866943
Batch 41/64 loss: 0.3270120620727539
Batch 42/64 loss: 0.32650405168533325
Batch 43/64 loss: 0.3101348876953125
Batch 44/64 loss: 0.3286244869232178
Batch 45/64 loss: 0.3109931945800781
Batch 46/64 loss: 0.3067528009414673
Batch 47/64 loss: 0.31668949127197266
Batch 48/64 loss: 0.3150119185447693
Batch 49/64 loss: 0.3363415598869324
Batch 50/64 loss: 0.3108252286911011
Batch 51/64 loss: 0.3240354061126709
Batch 52/64 loss: 0.3222901225090027
Batch 53/64 loss: 0.3194282650947571
Batch 54/64 loss: 0.3059951066970825
Batch 55/64 loss: 0.315420925617218
Batch 56/64 loss: 0.3163819909095764
Batch 57/64 loss: 0.3202178478240967
Batch 58/64 loss: 0.3149663209915161
Batch 59/64 loss: 0.31304222345352173
Batch 60/64 loss: 0.31827235221862793
Batch 61/64 loss: 0.313098669052124
Batch 62/64 loss: 0.31519603729248047
Batch 63/64 loss: 0.3102759122848511
Batch 64/64 loss: 0.3238763213157654
Epoch 294  Train loss: 0.317418679302814  Val loss: 0.3357335142663254
Epoch 295
-------------------------------
Batch 1/64 loss: 0.3167349100112915
Batch 2/64 loss: 0.3174002170562744
Batch 3/64 loss: 0.3180890679359436
Batch 4/64 loss: 0.31670308113098145
Batch 5/64 loss: 0.3125251531600952
Batch 6/64 loss: 0.3162837028503418
Batch 7/64 loss: 0.306931734085083
Batch 8/64 loss: 0.32384949922561646
Batch 9/64 loss: 0.31983184814453125
Batch 10/64 loss: 0.3165583610534668
Batch 11/64 loss: 0.32291436195373535
Batch 12/64 loss: 0.31879711151123047
Batch 13/64 loss: 0.30384600162506104
Batch 14/64 loss: 0.31662094593048096
Batch 15/64 loss: 0.31284332275390625
Batch 16/64 loss: 0.3109655976295471
Batch 17/64 loss: 0.31388920545578003
Batch 18/64 loss: 0.3242761492729187
Batch 19/64 loss: 0.3153970241546631
Batch 20/64 loss: 0.3241887092590332
Batch 21/64 loss: 0.32014548778533936
Batch 22/64 loss: 0.31863582134246826
Batch 23/64 loss: 0.3162381649017334
Batch 24/64 loss: 0.3212640881538391
Batch 25/64 loss: 0.3056601881980896
Batch 26/64 loss: 0.3036329746246338
Batch 27/64 loss: 0.3177891969680786
Batch 28/64 loss: 0.31804633140563965
Batch 29/64 loss: 0.3157925009727478
Batch 30/64 loss: 0.32451462745666504
Batch 31/64 loss: 0.3291497230529785
Batch 32/64 loss: 0.31252968311309814
Batch 33/64 loss: 0.32386207580566406
Batch 34/64 loss: 0.3156489133834839
Batch 35/64 loss: 0.3185499906539917
Batch 36/64 loss: 0.3101227879524231
Batch 37/64 loss: 0.31959813833236694
Batch 38/64 loss: 0.3159353733062744
Batch 39/64 loss: 0.31351417303085327
Batch 40/64 loss: 0.3192932605743408
Batch 41/64 loss: 0.3229285478591919
Batch 42/64 loss: 0.3196399211883545
Batch 43/64 loss: 0.31287282705307007
Batch 44/64 loss: 0.3090784549713135
Batch 45/64 loss: 0.3244616985321045
Batch 46/64 loss: 0.31352925300598145
Batch 47/64 loss: 0.3191322088241577
Batch 48/64 loss: 0.3159548044204712
Batch 49/64 loss: 0.3292362689971924
Batch 50/64 loss: 0.3129022717475891
Batch 51/64 loss: 0.322775661945343
Batch 52/64 loss: 0.31708669662475586
Batch 53/64 loss: 0.31887590885162354
Batch 54/64 loss: 0.3238571882247925
Batch 55/64 loss: 0.3168025016784668
Batch 56/64 loss: 0.3077472448348999
Batch 57/64 loss: 0.31643950939178467
Batch 58/64 loss: 0.3237960934638977
Batch 59/64 loss: 0.32024145126342773
Batch 60/64 loss: 0.31244999170303345
Batch 61/64 loss: 0.31765949726104736
Batch 62/64 loss: 0.3158959150314331
Batch 63/64 loss: 0.3120245337486267
Batch 64/64 loss: 0.3212493062019348
Epoch 295  Train loss: 0.3170963911449208  Val loss: 0.33611294780809853
Epoch 296
-------------------------------
Batch 1/64 loss: 0.31448644399642944
Batch 2/64 loss: 0.3187924027442932
Batch 3/64 loss: 0.3192397356033325
Batch 4/64 loss: 0.3128048777580261
Batch 5/64 loss: 0.31962621212005615
Batch 6/64 loss: 0.3166196942329407
Batch 7/64 loss: 0.3070753812789917
Batch 8/64 loss: 0.31493455171585083
Batch 9/64 loss: 0.31456953287124634
Batch 10/64 loss: 0.31331348419189453
Batch 11/64 loss: 0.30832958221435547
Batch 12/64 loss: 0.3162543773651123
Batch 13/64 loss: 0.3153877854347229
Batch 14/64 loss: 0.3271864652633667
Batch 15/64 loss: 0.3151516914367676
Batch 16/64 loss: 0.3194204568862915
Batch 17/64 loss: 0.31073248386383057
Batch 18/64 loss: 0.3143247365951538
Batch 19/64 loss: 0.3202424645423889
Batch 20/64 loss: 0.3134434223175049
Batch 21/64 loss: 0.3220278024673462
Batch 22/64 loss: 0.31851261854171753
Batch 23/64 loss: 0.31585681438446045
Batch 24/64 loss: 0.3228915333747864
Batch 25/64 loss: 0.3092750906944275
Batch 26/64 loss: 0.3193885087966919
Batch 27/64 loss: 0.31373369693756104
Batch 28/64 loss: 0.31864607334136963
Batch 29/64 loss: 0.31682443618774414
Batch 30/64 loss: 0.3176732063293457
Batch 31/64 loss: 0.31316983699798584
Batch 32/64 loss: 0.3116599917411804
Batch 33/64 loss: 0.3230288028717041
Batch 34/64 loss: 0.3247188329696655
Batch 35/64 loss: 0.31525659561157227
Batch 36/64 loss: 0.32280492782592773
Batch 37/64 loss: 0.3145361542701721
Batch 38/64 loss: 0.3281397819519043
Batch 39/64 loss: 0.319118857383728
Batch 40/64 loss: 0.31637221574783325
Batch 41/64 loss: 0.3171459436416626
Batch 42/64 loss: 0.3148367404937744
Batch 43/64 loss: 0.3021450638771057
Batch 44/64 loss: 0.3151847720146179
Batch 45/64 loss: 0.3328129053115845
Batch 46/64 loss: 0.32545506954193115
Batch 47/64 loss: 0.31476783752441406
Batch 48/64 loss: 0.3175778388977051
Batch 49/64 loss: 0.3172604441642761
Batch 50/64 loss: 0.31714576482772827
Batch 51/64 loss: 0.3207399249076843
Batch 52/64 loss: 0.3238886594772339
Batch 53/64 loss: 0.3176245093345642
Batch 54/64 loss: 0.30954837799072266
Batch 55/64 loss: 0.319128155708313
Batch 56/64 loss: 0.31932079792022705
Batch 57/64 loss: 0.3146909475326538
Batch 58/64 loss: 0.31102460622787476
Batch 59/64 loss: 0.3230319023132324
Batch 60/64 loss: 0.31231194734573364
Batch 61/64 loss: 0.31093263626098633
Batch 62/64 loss: 0.31282705068588257
Batch 63/64 loss: 0.3197002410888672
Batch 64/64 loss: 0.31606584787368774
Epoch 296  Train loss: 0.3168897738643721  Val loss: 0.335657263744328
Saving best model, epoch: 296
Epoch 297
-------------------------------
Batch 1/64 loss: 0.31371867656707764
Batch 2/64 loss: 0.3103400468826294
Batch 3/64 loss: 0.3209099769592285
Batch 4/64 loss: 0.3180274963378906
Batch 5/64 loss: 0.313184916973114
Batch 6/64 loss: 0.3141908645629883
Batch 7/64 loss: 0.313728928565979
Batch 8/64 loss: 0.3158529996871948
Batch 9/64 loss: 0.3196913003921509
Batch 10/64 loss: 0.32253122329711914
Batch 11/64 loss: 0.33131611347198486
Batch 12/64 loss: 0.3070019483566284
Batch 13/64 loss: 0.3127634525299072
Batch 14/64 loss: 0.31015652418136597
Batch 15/64 loss: 0.3173061013221741
Batch 16/64 loss: 0.31984496116638184
Batch 17/64 loss: 0.3072829842567444
Batch 18/64 loss: 0.31689006090164185
Batch 19/64 loss: 0.31800997257232666
Batch 20/64 loss: 0.31106293201446533
Batch 21/64 loss: 0.31039857864379883
Batch 22/64 loss: 0.3141469955444336
Batch 23/64 loss: 0.31730782985687256
Batch 24/64 loss: 0.3165726661682129
Batch 25/64 loss: 0.320080041885376
Batch 26/64 loss: 0.33641695976257324
Batch 27/64 loss: 0.31859517097473145
Batch 28/64 loss: 0.3162171244621277
Batch 29/64 loss: 0.30493438243865967
Batch 30/64 loss: 0.30754536390304565
Batch 31/64 loss: 0.30863672494888306
Batch 32/64 loss: 0.3193100690841675
Batch 33/64 loss: 0.3119802474975586
Batch 34/64 loss: 0.3217918872833252
Batch 35/64 loss: 0.31886088848114014
Batch 36/64 loss: 0.30987274646759033
Batch 37/64 loss: 0.31154561042785645
Batch 38/64 loss: 0.3180806636810303
Batch 39/64 loss: 0.3155438303947449
Batch 40/64 loss: 0.3101261854171753
Batch 41/64 loss: 0.3200169801712036
Batch 42/64 loss: 0.31933796405792236
Batch 43/64 loss: 0.3245115876197815
Batch 44/64 loss: 0.3234861493110657
Batch 45/64 loss: 0.3214340806007385
Batch 46/64 loss: 0.31260842084884644
Batch 47/64 loss: 0.3205060362815857
Batch 48/64 loss: 0.3205863833427429
Batch 49/64 loss: 0.31714868545532227
Batch 50/64 loss: 0.3050658702850342
Batch 51/64 loss: 0.32031381130218506
Batch 52/64 loss: 0.3131173849105835
Batch 53/64 loss: 0.31800299882888794
Batch 54/64 loss: 0.31393909454345703
Batch 55/64 loss: 0.3203660845756531
Batch 56/64 loss: 0.3161936402320862
Batch 57/64 loss: 0.3291815519332886
Batch 58/64 loss: 0.3228353261947632
Batch 59/64 loss: 0.32275718450546265
Batch 60/64 loss: 0.321902871131897
Batch 61/64 loss: 0.31646251678466797
Batch 62/64 loss: 0.32663393020629883
Batch 63/64 loss: 0.3191641569137573
Batch 64/64 loss: 0.3166764974594116
Epoch 297  Train loss: 0.316938910297319  Val loss: 0.33642067552841814
Epoch 298
-------------------------------
Batch 1/64 loss: 0.31538522243499756
Batch 2/64 loss: 0.316453218460083
Batch 3/64 loss: 0.31413495540618896
Batch 4/64 loss: 0.3140445947647095
Batch 5/64 loss: 0.32108014822006226
Batch 6/64 loss: 0.323816180229187
Batch 7/64 loss: 0.31321263313293457
Batch 8/64 loss: 0.3224254846572876
Batch 9/64 loss: 0.31489336490631104
Batch 10/64 loss: 0.3127715587615967
Batch 11/64 loss: 0.3147141933441162
Batch 12/64 loss: 0.3131001591682434
Batch 13/64 loss: 0.3097797632217407
Batch 14/64 loss: 0.32436686754226685
Batch 15/64 loss: 0.31379443407058716
Batch 16/64 loss: 0.3167358636856079
Batch 17/64 loss: 0.31612926721572876
Batch 18/64 loss: 0.3130895495414734
Batch 19/64 loss: 0.3206530809402466
Batch 20/64 loss: 0.3118557929992676
Batch 21/64 loss: 0.3236962556838989
Batch 22/64 loss: 0.3195962905883789
Batch 23/64 loss: 0.31797289848327637
Batch 24/64 loss: 0.3170289993286133
Batch 25/64 loss: 0.31195640563964844
Batch 26/64 loss: 0.3165050745010376
Batch 27/64 loss: 0.3245101571083069
Batch 28/64 loss: 0.31967413425445557
Batch 29/64 loss: 0.31821054220199585
Batch 30/64 loss: 0.3118715286254883
Batch 31/64 loss: 0.30791938304901123
Batch 32/64 loss: 0.31946510076522827
Batch 33/64 loss: 0.3218453526496887
Batch 34/64 loss: 0.3242749571800232
Batch 35/64 loss: 0.3134312629699707
Batch 36/64 loss: 0.31527602672576904
Batch 37/64 loss: 0.31471651792526245
Batch 38/64 loss: 0.3161005973815918
Batch 39/64 loss: 0.3240252137184143
Batch 40/64 loss: 0.33131879568099976
Batch 41/64 loss: 0.3252418041229248
Batch 42/64 loss: 0.30444222688674927
Batch 43/64 loss: 0.3225827217102051
Batch 44/64 loss: 0.3153477907180786
Batch 45/64 loss: 0.3186826705932617
Batch 46/64 loss: 0.3196457624435425
Batch 47/64 loss: 0.3170386552810669
Batch 48/64 loss: 0.31532227993011475
Batch 49/64 loss: 0.31820976734161377
Batch 50/64 loss: 0.3132491111755371
Batch 51/64 loss: 0.3148837089538574
Batch 52/64 loss: 0.3249708414077759
Batch 53/64 loss: 0.3203544616699219
Batch 54/64 loss: 0.3238561153411865
Batch 55/64 loss: 0.32709234952926636
Batch 56/64 loss: 0.3137292265892029
Batch 57/64 loss: 0.31808894872665405
Batch 58/64 loss: 0.3119141459465027
Batch 59/64 loss: 0.32175004482269287
Batch 60/64 loss: 0.30761396884918213
Batch 61/64 loss: 0.31138402223587036
Batch 62/64 loss: 0.3160109519958496
Batch 63/64 loss: 0.31911706924438477
Batch 64/64 loss: 0.31588852405548096
Epoch 298  Train loss: 0.31732199005052153  Val loss: 0.33610385594908726
Epoch 299
-------------------------------
Batch 1/64 loss: 0.3158283233642578
Batch 2/64 loss: 0.3153517246246338
Batch 3/64 loss: 0.3150268793106079
Batch 4/64 loss: 0.30783820152282715
Batch 5/64 loss: 0.29838043451309204
Batch 6/64 loss: 0.32371705770492554
Batch 7/64 loss: 0.31751739978790283
Batch 8/64 loss: 0.3224380612373352
Batch 9/64 loss: 0.3201946020126343
Batch 10/64 loss: 0.3128502368927002
Batch 11/64 loss: 0.3118661642074585
Batch 12/64 loss: 0.3128330707550049
Batch 13/64 loss: 0.31748783588409424
Batch 14/64 loss: 0.3182246685028076
Batch 15/64 loss: 0.3195136785507202
Batch 16/64 loss: 0.3187680244445801
Batch 17/64 loss: 0.31437718868255615
Batch 18/64 loss: 0.31144678592681885
Batch 19/64 loss: 0.3063039183616638
Batch 20/64 loss: 0.3106966018676758
Batch 21/64 loss: 0.3123807907104492
Batch 22/64 loss: 0.32503968477249146
Batch 23/64 loss: 0.3321967124938965
Batch 24/64 loss: 0.3172236680984497
Batch 25/64 loss: 0.3171013593673706
Batch 26/64 loss: 0.31370753049850464
Batch 27/64 loss: 0.31549006700515747
Batch 28/64 loss: 0.31592345237731934
Batch 29/64 loss: 0.3224639296531677
Batch 30/64 loss: 0.31416285037994385
Batch 31/64 loss: 0.3250970244407654
Batch 32/64 loss: 0.3184173107147217
Batch 33/64 loss: 0.3198585510253906
Batch 34/64 loss: 0.3220098614692688
Batch 35/64 loss: 0.31449341773986816
Batch 36/64 loss: 0.31905966997146606
Batch 37/64 loss: 0.30821502208709717
Batch 38/64 loss: 0.3165452480316162
Batch 39/64 loss: 0.3207225799560547
Batch 40/64 loss: 0.30939483642578125
Batch 41/64 loss: 0.3200117349624634
Batch 42/64 loss: 0.3148230314254761
Batch 43/64 loss: 0.32667672634124756
Batch 44/64 loss: 0.3161487579345703
Batch 45/64 loss: 0.31806182861328125
Batch 46/64 loss: 0.31487226486206055
Batch 47/64 loss: 0.31466972827911377
Batch 48/64 loss: 0.31705349683761597
Batch 49/64 loss: 0.31320619583129883
Batch 50/64 loss: 0.314003586769104
Batch 51/64 loss: 0.31736230850219727
Batch 52/64 loss: 0.3196955919265747
Batch 53/64 loss: 0.3247110843658447
Batch 54/64 loss: 0.3179672956466675
Batch 55/64 loss: 0.31222379207611084
Batch 56/64 loss: 0.31368541717529297
Batch 57/64 loss: 0.31172436475753784
Batch 58/64 loss: 0.3196486234664917
Batch 59/64 loss: 0.3211265802383423
Batch 60/64 loss: 0.31143462657928467
Batch 61/64 loss: 0.3105800151824951
Batch 62/64 loss: 0.32013213634490967
Batch 63/64 loss: 0.3145493268966675
Batch 64/64 loss: 0.32212531566619873
Epoch 299  Train loss: 0.3164882655237235  Val loss: 0.33556988886541517
Saving best model, epoch: 299
Epoch 300
-------------------------------
Batch 1/64 loss: 0.3218342661857605
Batch 2/64 loss: 0.3154144287109375
Batch 3/64 loss: 0.31828773021698
Batch 4/64 loss: 0.3121151924133301
Batch 5/64 loss: 0.31870728731155396
Batch 6/64 loss: 0.3192257881164551
Batch 7/64 loss: 0.3201308250427246
Batch 8/64 loss: 0.31359994411468506
Batch 9/64 loss: 0.32364386320114136
Batch 10/64 loss: 0.31813323497772217
Batch 11/64 loss: 0.31208890676498413
Batch 12/64 loss: 0.31655967235565186
Batch 13/64 loss: 0.30886006355285645
Batch 14/64 loss: 0.31437796354293823
Batch 15/64 loss: 0.3156996965408325
Batch 16/64 loss: 0.3153377175331116
Batch 17/64 loss: 0.3137331008911133
Batch 18/64 loss: 0.32130903005599976
Batch 19/64 loss: 0.3115174174308777
Batch 20/64 loss: 0.31324446201324463
Batch 21/64 loss: 0.3214779496192932
Batch 22/64 loss: 0.312511146068573
Batch 23/64 loss: 0.31678569316864014
Batch 24/64 loss: 0.3170647621154785
Batch 25/64 loss: 0.31316089630126953
Batch 26/64 loss: 0.3141508102416992
Batch 27/64 loss: 0.313220739364624
Batch 28/64 loss: 0.3080706000328064
Batch 29/64 loss: 0.31928300857543945
Batch 30/64 loss: 0.3133070468902588
Batch 31/64 loss: 0.30993926525115967
Batch 32/64 loss: 0.30640077590942383
Batch 33/64 loss: 0.31899499893188477
Batch 34/64 loss: 0.3237687945365906
Batch 35/64 loss: 0.3201477527618408
Batch 36/64 loss: 0.32296955585479736
Batch 37/64 loss: 0.3142971396446228
Batch 38/64 loss: 0.3183584213256836
Batch 39/64 loss: 0.3208731412887573
Batch 40/64 loss: 0.3286031484603882
Batch 41/64 loss: 0.3077041506767273
Batch 42/64 loss: 0.31964921951293945
Batch 43/64 loss: 0.3125978708267212
Batch 44/64 loss: 0.3160945177078247
Batch 45/64 loss: 0.32411402463912964
Batch 46/64 loss: 0.32317763566970825
Batch 47/64 loss: 0.31138181686401367
Batch 48/64 loss: 0.31918269395828247
Batch 49/64 loss: 0.3238039016723633
Batch 50/64 loss: 0.3112454414367676
Batch 51/64 loss: 0.3095729947090149
Batch 52/64 loss: 0.30780965089797974
Batch 53/64 loss: 0.3171510696411133
Batch 54/64 loss: 0.3221849203109741
Batch 55/64 loss: 0.3239589333534241
Batch 56/64 loss: 0.3204852342605591
Batch 57/64 loss: 0.31635695695877075
Batch 58/64 loss: 0.3200264573097229
Batch 59/64 loss: 0.30842483043670654
Batch 60/64 loss: 0.31376683712005615
Batch 61/64 loss: 0.31751883029937744
Batch 62/64 loss: 0.3138342499732971
Batch 63/64 loss: 0.31802964210510254
Batch 64/64 loss: 0.3237264156341553
Epoch 300  Train loss: 0.3165187910491345  Val loss: 0.3369572197448757
Epoch 301
-------------------------------
Batch 1/64 loss: 0.3199118375778198
Batch 2/64 loss: 0.3104866147041321
Batch 3/64 loss: 0.3252909183502197
Batch 4/64 loss: 0.31109482049942017
Batch 5/64 loss: 0.31136226654052734
Batch 6/64 loss: 0.31230902671813965
Batch 7/64 loss: 0.32019078731536865
Batch 8/64 loss: 0.302986741065979
Batch 9/64 loss: 0.31699198484420776
Batch 10/64 loss: 0.3186643123626709
Batch 11/64 loss: 0.31884634494781494
Batch 12/64 loss: 0.3053407669067383
Batch 13/64 loss: 0.31655752658843994
Batch 14/64 loss: 0.3179377317428589
Batch 15/64 loss: 0.3198767900466919
Batch 16/64 loss: 0.317393958568573
Batch 17/64 loss: 0.319993257522583
Batch 18/64 loss: 0.3071582317352295
Batch 19/64 loss: 0.312425434589386
Batch 20/64 loss: 0.3152100443840027
Batch 21/64 loss: 0.3199807405471802
Batch 22/64 loss: 0.3141123652458191
Batch 23/64 loss: 0.31410324573516846
Batch 24/64 loss: 0.313604474067688
Batch 25/64 loss: 0.32172584533691406
Batch 26/64 loss: 0.32225584983825684
Batch 27/64 loss: 0.31350457668304443
Batch 28/64 loss: 0.3185819387435913
Batch 29/64 loss: 0.3099637031555176
Batch 30/64 loss: 0.3073967695236206
Batch 31/64 loss: 0.3162575960159302
Batch 32/64 loss: 0.30619990825653076
Batch 33/64 loss: 0.3237825632095337
Batch 34/64 loss: 0.3186619281768799
Batch 35/64 loss: 0.3170464038848877
Batch 36/64 loss: 0.3190094232559204
Batch 37/64 loss: 0.31964999437332153
Batch 38/64 loss: 0.3187783360481262
Batch 39/64 loss: 0.323228120803833
Batch 40/64 loss: 0.3102548122406006
Batch 41/64 loss: 0.32072019577026367
Batch 42/64 loss: 0.3237212896347046
Batch 43/64 loss: 0.31033986806869507
Batch 44/64 loss: 0.3199009895324707
Batch 45/64 loss: 0.3181610107421875
Batch 46/64 loss: 0.31998753547668457
Batch 47/64 loss: 0.3199806213378906
Batch 48/64 loss: 0.3084714412689209
Batch 49/64 loss: 0.31320393085479736
Batch 50/64 loss: 0.3146090507507324
Batch 51/64 loss: 0.31163185834884644
Batch 52/64 loss: 0.3149263262748718
Batch 53/64 loss: 0.32059043645858765
Batch 54/64 loss: 0.31144750118255615
Batch 55/64 loss: 0.32442593574523926
Batch 56/64 loss: 0.3166165351867676
Batch 57/64 loss: 0.3105981945991516
Batch 58/64 loss: 0.31834709644317627
Batch 59/64 loss: 0.3183993697166443
Batch 60/64 loss: 0.3120232820510864
Batch 61/64 loss: 0.31621986627578735
Batch 62/64 loss: 0.32859277725219727
Batch 63/64 loss: 0.31246793270111084
Batch 64/64 loss: 0.3142222762107849
Epoch 301  Train loss: 0.3160655332546608  Val loss: 0.3359163643158588
Epoch 302
-------------------------------
Batch 1/64 loss: 0.3198865056037903
Batch 2/64 loss: 0.3205152750015259
Batch 3/64 loss: 0.31679558753967285
Batch 4/64 loss: 0.32148540019989014
Batch 5/64 loss: 0.31266170740127563
Batch 6/64 loss: 0.31782007217407227
Batch 7/64 loss: 0.3232687711715698
Batch 8/64 loss: 0.31471651792526245
Batch 9/64 loss: 0.3120056390762329
Batch 10/64 loss: 0.31681519746780396
Batch 11/64 loss: 0.31572407484054565
Batch 12/64 loss: 0.31940776109695435
Batch 13/64 loss: 0.32090115547180176
Batch 14/64 loss: 0.32175159454345703
Batch 15/64 loss: 0.30604809522628784
Batch 16/64 loss: 0.31653571128845215
Batch 17/64 loss: 0.3156777620315552
Batch 18/64 loss: 0.31658077239990234
Batch 19/64 loss: 0.31222379207611084
Batch 20/64 loss: 0.31625545024871826
Batch 21/64 loss: 0.31747013330459595
Batch 22/64 loss: 0.31547319889068604
Batch 23/64 loss: 0.3084264397621155
Batch 24/64 loss: 0.3158382177352905
Batch 25/64 loss: 0.3164651393890381
Batch 26/64 loss: 0.32113784551620483
Batch 27/64 loss: 0.31002283096313477
Batch 28/64 loss: 0.3175145387649536
Batch 29/64 loss: 0.3144487142562866
Batch 30/64 loss: 0.3186274766921997
Batch 31/64 loss: 0.3118264675140381
Batch 32/64 loss: 0.3208678960800171
Batch 33/64 loss: 0.3209235668182373
Batch 34/64 loss: 0.31944984197616577
Batch 35/64 loss: 0.32155585289001465
Batch 36/64 loss: 0.3084526062011719
Batch 37/64 loss: 0.3245624303817749
Batch 38/64 loss: 0.3264032006263733
Batch 39/64 loss: 0.3103989362716675
Batch 40/64 loss: 0.311659574508667
Batch 41/64 loss: 0.3136973977088928
Batch 42/64 loss: 0.31665587425231934
Batch 43/64 loss: 0.3099794387817383
Batch 44/64 loss: 0.31642282009124756
Batch 45/64 loss: 0.31285762786865234
Batch 46/64 loss: 0.3144184350967407
Batch 47/64 loss: 0.3105865716934204
Batch 48/64 loss: 0.3235621452331543
Batch 49/64 loss: 0.3095528483390808
Batch 50/64 loss: 0.3249647617340088
Batch 51/64 loss: 0.31679022312164307
Batch 52/64 loss: 0.3164583444595337
Batch 53/64 loss: 0.3148798942565918
Batch 54/64 loss: 0.3160059452056885
Batch 55/64 loss: 0.31310635805130005
Batch 56/64 loss: 0.3105851411819458
Batch 57/64 loss: 0.31040501594543457
Batch 58/64 loss: 0.32399582862854004
Batch 59/64 loss: 0.3133676052093506
Batch 60/64 loss: 0.31087934970855713
Batch 61/64 loss: 0.31803572177886963
Batch 62/64 loss: 0.3194793462753296
Batch 63/64 loss: 0.3206070065498352
Batch 64/64 loss: 0.3107476234436035
Epoch 302  Train loss: 0.3162189203150132  Val loss: 0.3352584222338044
Saving best model, epoch: 302
Epoch 303
-------------------------------
Batch 1/64 loss: 0.3052026629447937
Batch 2/64 loss: 0.3167930245399475
Batch 3/64 loss: 0.31158339977264404
Batch 4/64 loss: 0.31812453269958496
Batch 5/64 loss: 0.31128454208374023
Batch 6/64 loss: 0.31288909912109375
Batch 7/64 loss: 0.31948864459991455
Batch 8/64 loss: 0.3175215721130371
Batch 9/64 loss: 0.3236650228500366
Batch 10/64 loss: 0.32160985469818115
Batch 11/64 loss: 0.3180025815963745
Batch 12/64 loss: 0.3114646077156067
Batch 13/64 loss: 0.31989240646362305
Batch 14/64 loss: 0.31259024143218994
Batch 15/64 loss: 0.3102846145629883
Batch 16/64 loss: 0.30228114128112793
Batch 17/64 loss: 0.31234848499298096
Batch 18/64 loss: 0.3164505958557129
Batch 19/64 loss: 0.3096579313278198
Batch 20/64 loss: 0.31374114751815796
Batch 21/64 loss: 0.31171900033950806
Batch 22/64 loss: 0.32376617193222046
Batch 23/64 loss: 0.3194270133972168
Batch 24/64 loss: 0.3148256540298462
Batch 25/64 loss: 0.31896018981933594
Batch 26/64 loss: 0.31385767459869385
Batch 27/64 loss: 0.31893444061279297
Batch 28/64 loss: 0.3200615644454956
Batch 29/64 loss: 0.31243956089019775
Batch 30/64 loss: 0.3258025646209717
Batch 31/64 loss: 0.3098125457763672
Batch 32/64 loss: 0.32002222537994385
Batch 33/64 loss: 0.32544851303100586
Batch 34/64 loss: 0.3104468584060669
Batch 35/64 loss: 0.31324052810668945
Batch 36/64 loss: 0.3157997727394104
Batch 37/64 loss: 0.31676965951919556
Batch 38/64 loss: 0.3168509006500244
Batch 39/64 loss: 0.3117835521697998
Batch 40/64 loss: 0.31933683156967163
Batch 41/64 loss: 0.3207523226737976
Batch 42/64 loss: 0.31968045234680176
Batch 43/64 loss: 0.3084268569946289
Batch 44/64 loss: 0.3178091049194336
Batch 45/64 loss: 0.31903553009033203
Batch 46/64 loss: 0.3113034963607788
Batch 47/64 loss: 0.32493412494659424
Batch 48/64 loss: 0.3192406892776489
Batch 49/64 loss: 0.3153532147407532
Batch 50/64 loss: 0.3208881616592407
Batch 51/64 loss: 0.319172203540802
Batch 52/64 loss: 0.32481569051742554
Batch 53/64 loss: 0.30765628814697266
Batch 54/64 loss: 0.3207508325576782
Batch 55/64 loss: 0.31906378269195557
Batch 56/64 loss: 0.32101571559906006
Batch 57/64 loss: 0.31379884481430054
Batch 58/64 loss: 0.31535977125167847
Batch 59/64 loss: 0.3108757734298706
Batch 60/64 loss: 0.314223051071167
Batch 61/64 loss: 0.3140770196914673
Batch 62/64 loss: 0.31395065784454346
Batch 63/64 loss: 0.31416016817092896
Batch 64/64 loss: 0.3244239091873169
Epoch 303  Train loss: 0.3161387139675664  Val loss: 0.3362525623688583
Epoch 304
-------------------------------
Batch 1/64 loss: 0.31721222400665283
Batch 2/64 loss: 0.3143931031227112
Batch 3/64 loss: 0.31217312812805176
Batch 4/64 loss: 0.3171781897544861
Batch 5/64 loss: 0.3237283229827881
Batch 6/64 loss: 0.31095266342163086
Batch 7/64 loss: 0.3250068426132202
Batch 8/64 loss: 0.3051741123199463
Batch 9/64 loss: 0.308286190032959
Batch 10/64 loss: 0.3213038444519043
Batch 11/64 loss: 0.3137965202331543
Batch 12/64 loss: 0.314266562461853
Batch 13/64 loss: 0.31698668003082275
Batch 14/64 loss: 0.3154863119125366
Batch 15/64 loss: 0.31610286235809326
Batch 16/64 loss: 0.31463873386383057
Batch 17/64 loss: 0.30774742364883423
Batch 18/64 loss: 0.31762993335723877
Batch 19/64 loss: 0.3065067529678345
Batch 20/64 loss: 0.3105000853538513
Batch 21/64 loss: 0.3141859769821167
Batch 22/64 loss: 0.31965649127960205
Batch 23/64 loss: 0.3207833766937256
Batch 24/64 loss: 0.3066675066947937
Batch 25/64 loss: 0.31778496503829956
Batch 26/64 loss: 0.3171936273574829
Batch 27/64 loss: 0.31682926416397095
Batch 28/64 loss: 0.3171125054359436
Batch 29/64 loss: 0.3182358145713806
Batch 30/64 loss: 0.3094780445098877
Batch 31/64 loss: 0.32444775104522705
Batch 32/64 loss: 0.31870436668395996
Batch 33/64 loss: 0.3130173683166504
Batch 34/64 loss: 0.3170473575592041
Batch 35/64 loss: 0.3158680200576782
Batch 36/64 loss: 0.3155728578567505
Batch 37/64 loss: 0.31404566764831543
Batch 38/64 loss: 0.3134044408798218
Batch 39/64 loss: 0.3203791379928589
Batch 40/64 loss: 0.31905245780944824
Batch 41/64 loss: 0.3245636224746704
Batch 42/64 loss: 0.31846946477890015
Batch 43/64 loss: 0.31341707706451416
Batch 44/64 loss: 0.3146044611930847
Batch 45/64 loss: 0.32297730445861816
Batch 46/64 loss: 0.30978500843048096
Batch 47/64 loss: 0.3087576627731323
Batch 48/64 loss: 0.3138420581817627
Batch 49/64 loss: 0.3313031792640686
Batch 50/64 loss: 0.318281888961792
Batch 51/64 loss: 0.31248974800109863
Batch 52/64 loss: 0.329689085483551
Batch 53/64 loss: 0.3205348253250122
Batch 54/64 loss: 0.3080747127532959
Batch 55/64 loss: 0.3170586824417114
Batch 56/64 loss: 0.3138825297355652
Batch 57/64 loss: 0.3113689422607422
Batch 58/64 loss: 0.32085227966308594
Batch 59/64 loss: 0.3168060779571533
Batch 60/64 loss: 0.32291966676712036
Batch 61/64 loss: 0.32148492336273193
Batch 62/64 loss: 0.3142024278640747
Batch 63/64 loss: 0.31314975023269653
Batch 64/64 loss: 0.3157038688659668
Epoch 304  Train loss: 0.3161385218302409  Val loss: 0.33559782726248516
Epoch 305
-------------------------------
Batch 1/64 loss: 0.31963998079299927
Batch 2/64 loss: 0.3228977918624878
Batch 3/64 loss: 0.3208487033843994
Batch 4/64 loss: 0.313723087310791
Batch 5/64 loss: 0.3062784671783447
Batch 6/64 loss: 0.30818748474121094
Batch 7/64 loss: 0.31455516815185547
Batch 8/64 loss: 0.31466150283813477
Batch 9/64 loss: 0.30182647705078125
Batch 10/64 loss: 0.31133508682250977
Batch 11/64 loss: 0.32656461000442505
Batch 12/64 loss: 0.30886101722717285
Batch 13/64 loss: 0.3104463815689087
Batch 14/64 loss: 0.316617488861084
Batch 15/64 loss: 0.310078501701355
Batch 16/64 loss: 0.32754117250442505
Batch 17/64 loss: 0.3177834749221802
Batch 18/64 loss: 0.3053937554359436
Batch 19/64 loss: 0.30879831314086914
Batch 20/64 loss: 0.3278440833091736
Batch 21/64 loss: 0.3090607523918152
Batch 22/64 loss: 0.3105318546295166
Batch 23/64 loss: 0.3200843334197998
Batch 24/64 loss: 0.32093125581741333
Batch 25/64 loss: 0.31972283124923706
Batch 26/64 loss: 0.3212892413139343
Batch 27/64 loss: 0.31049656867980957
Batch 28/64 loss: 0.315885066986084
Batch 29/64 loss: 0.3123490810394287
Batch 30/64 loss: 0.3185892701148987
Batch 31/64 loss: 0.31599879264831543
Batch 32/64 loss: 0.318831205368042
Batch 33/64 loss: 0.3106623888015747
Batch 34/64 loss: 0.31257104873657227
Batch 35/64 loss: 0.3133203983306885
Batch 36/64 loss: 0.3106756806373596
Batch 37/64 loss: 0.31834667921066284
Batch 38/64 loss: 0.31163352727890015
Batch 39/64 loss: 0.31792306900024414
Batch 40/64 loss: 0.31819450855255127
Batch 41/64 loss: 0.30968326330184937
Batch 42/64 loss: 0.31210649013519287
Batch 43/64 loss: 0.31696999073028564
Batch 44/64 loss: 0.3223760724067688
Batch 45/64 loss: 0.32591915130615234
Batch 46/64 loss: 0.31619584560394287
Batch 47/64 loss: 0.3189401626586914
Batch 48/64 loss: 0.317596435546875
Batch 49/64 loss: 0.322674036026001
Batch 50/64 loss: 0.30182886123657227
Batch 51/64 loss: 0.3147488832473755
Batch 52/64 loss: 0.3092789649963379
Batch 53/64 loss: 0.31351596117019653
Batch 54/64 loss: 0.3115352392196655
Batch 55/64 loss: 0.31444263458251953
Batch 56/64 loss: 0.31856513023376465
Batch 57/64 loss: 0.32505637407302856
Batch 58/64 loss: 0.3240877389907837
Batch 59/64 loss: 0.31649959087371826
Batch 60/64 loss: 0.3142707347869873
Batch 61/64 loss: 0.3201291561126709
Batch 62/64 loss: 0.3208070993423462
Batch 63/64 loss: 0.3129773736000061
Batch 64/64 loss: 0.31138741970062256
Epoch 305  Train loss: 0.31552511149761725  Val loss: 0.3348061247789573
Saving best model, epoch: 305
Epoch 306
-------------------------------
Batch 1/64 loss: 0.30826693773269653
Batch 2/64 loss: 0.3224785327911377
Batch 3/64 loss: 0.31904053688049316
Batch 4/64 loss: 0.3070968985557556
Batch 5/64 loss: 0.3173631429672241
Batch 6/64 loss: 0.3182215690612793
Batch 7/64 loss: 0.32086294889450073
Batch 8/64 loss: 0.31425535678863525
Batch 9/64 loss: 0.315369188785553
Batch 10/64 loss: 0.30506598949432373
Batch 11/64 loss: 0.316081166267395
Batch 12/64 loss: 0.30975329875946045
Batch 13/64 loss: 0.3220794200897217
Batch 14/64 loss: 0.31946516036987305
Batch 15/64 loss: 0.3161400556564331
Batch 16/64 loss: 0.3167167901992798
Batch 17/64 loss: 0.3184239864349365
Batch 18/64 loss: 0.31728196144104004
Batch 19/64 loss: 0.31262749433517456
Batch 20/64 loss: 0.3103916049003601
Batch 21/64 loss: 0.31593161821365356
Batch 22/64 loss: 0.31367313861846924
Batch 23/64 loss: 0.313892662525177
Batch 24/64 loss: 0.31731486320495605
Batch 25/64 loss: 0.31345903873443604
Batch 26/64 loss: 0.30977749824523926
Batch 27/64 loss: 0.3191875219345093
Batch 28/64 loss: 0.31178009510040283
Batch 29/64 loss: 0.3173738718032837
Batch 30/64 loss: 0.31179559230804443
Batch 31/64 loss: 0.3132619261741638
Batch 32/64 loss: 0.30785393714904785
Batch 33/64 loss: 0.32354021072387695
Batch 34/64 loss: 0.3091418147087097
Batch 35/64 loss: 0.31409692764282227
Batch 36/64 loss: 0.3110325336456299
Batch 37/64 loss: 0.3104931116104126
Batch 38/64 loss: 0.32300734519958496
Batch 39/64 loss: 0.3148157596588135
Batch 40/64 loss: 0.3146798610687256
Batch 41/64 loss: 0.30869805812835693
Batch 42/64 loss: 0.3146698474884033
Batch 43/64 loss: 0.31600141525268555
Batch 44/64 loss: 0.311972975730896
Batch 45/64 loss: 0.32703250646591187
Batch 46/64 loss: 0.3094988465309143
Batch 47/64 loss: 0.3104720711708069
Batch 48/64 loss: 0.3197852373123169
Batch 49/64 loss: 0.3055875897407532
Batch 50/64 loss: 0.32504189014434814
Batch 51/64 loss: 0.3183845281600952
Batch 52/64 loss: 0.31009578704833984
Batch 53/64 loss: 0.3206467628479004
Batch 54/64 loss: 0.3138524293899536
Batch 55/64 loss: 0.30524981021881104
Batch 56/64 loss: 0.3198683261871338
Batch 57/64 loss: 0.31147658824920654
Batch 58/64 loss: 0.3074580430984497
Batch 59/64 loss: 0.3176136612892151
Batch 60/64 loss: 0.31843096017837524
Batch 61/64 loss: 0.32285189628601074
Batch 62/64 loss: 0.32418227195739746
Batch 63/64 loss: 0.31328535079956055
Batch 64/64 loss: 0.3268600106239319
Epoch 306  Train loss: 0.31514342322069056  Val loss: 0.3349790720595527
Epoch 307
-------------------------------
Batch 1/64 loss: 0.3146790862083435
Batch 2/64 loss: 0.31766945123672485
Batch 3/64 loss: 0.3201679587364197
Batch 4/64 loss: 0.31713706254959106
Batch 5/64 loss: 0.3152921199798584
Batch 6/64 loss: 0.32463961839675903
Batch 7/64 loss: 0.3175920248031616
Batch 8/64 loss: 0.3117644786834717
Batch 9/64 loss: 0.3117039203643799
Batch 10/64 loss: 0.32412242889404297
Batch 11/64 loss: 0.30998820066452026
Batch 12/64 loss: 0.3180677890777588
Batch 13/64 loss: 0.3193010091781616
Batch 14/64 loss: 0.31708312034606934
Batch 15/64 loss: 0.31317973136901855
Batch 16/64 loss: 0.31033843755722046
Batch 17/64 loss: 0.3283992409706116
Batch 18/64 loss: 0.3109058737754822
Batch 19/64 loss: 0.32016468048095703
Batch 20/64 loss: 0.30041050910949707
Batch 21/64 loss: 0.3117499351501465
Batch 22/64 loss: 0.31777822971343994
Batch 23/64 loss: 0.31225961446762085
Batch 24/64 loss: 0.31610822677612305
Batch 25/64 loss: 0.32058024406433105
Batch 26/64 loss: 0.3073312044143677
Batch 27/64 loss: 0.312514066696167
Batch 28/64 loss: 0.30495619773864746
Batch 29/64 loss: 0.3075314164161682
Batch 30/64 loss: 0.3194209933280945
Batch 31/64 loss: 0.3173457384109497
Batch 32/64 loss: 0.3114527463912964
Batch 33/64 loss: 0.32548779249191284
Batch 34/64 loss: 0.317608118057251
Batch 35/64 loss: 0.31592655181884766
Batch 36/64 loss: 0.3184441328048706
Batch 37/64 loss: 0.31430715322494507
Batch 38/64 loss: 0.3168562054634094
Batch 39/64 loss: 0.3115657567977905
Batch 40/64 loss: 0.31548434495925903
Batch 41/64 loss: 0.31637370586395264
Batch 42/64 loss: 0.3059842586517334
Batch 43/64 loss: 0.3198678493499756
Batch 44/64 loss: 0.32112234830856323
Batch 45/64 loss: 0.31404924392700195
Batch 46/64 loss: 0.3209947347640991
Batch 47/64 loss: 0.3143181800842285
Batch 48/64 loss: 0.31285589933395386
Batch 49/64 loss: 0.30698442459106445
Batch 50/64 loss: 0.3206872344017029
Batch 51/64 loss: 0.3210688829421997
Batch 52/64 loss: 0.31696200370788574
Batch 53/64 loss: 0.31057894229888916
Batch 54/64 loss: 0.31321442127227783
Batch 55/64 loss: 0.3089020252227783
Batch 56/64 loss: 0.31893956661224365
Batch 57/64 loss: 0.3190634250640869
Batch 58/64 loss: 0.32212555408477783
Batch 59/64 loss: 0.31858277320861816
Batch 60/64 loss: 0.3133081793785095
Batch 61/64 loss: 0.3214757442474365
Batch 62/64 loss: 0.31000638008117676
Batch 63/64 loss: 0.31456202268600464
Batch 64/64 loss: 0.32765138149261475
Epoch 307  Train loss: 0.31568755682776956  Val loss: 0.3371215350029804
Epoch 308
-------------------------------
Batch 1/64 loss: 0.3193896412849426
Batch 2/64 loss: 0.3155500292778015
Batch 3/64 loss: 0.31851720809936523
Batch 4/64 loss: 0.3167731761932373
Batch 5/64 loss: 0.32046806812286377
Batch 6/64 loss: 0.31082606315612793
Batch 7/64 loss: 0.30142515897750854
Batch 8/64 loss: 0.3227698802947998
Batch 9/64 loss: 0.3189213275909424
Batch 10/64 loss: 0.3150995373725891
Batch 11/64 loss: 0.3085264563560486
Batch 12/64 loss: 0.31272828578948975
Batch 13/64 loss: 0.317538857460022
Batch 14/64 loss: 0.31003767251968384
Batch 15/64 loss: 0.3121042251586914
Batch 16/64 loss: 0.32098913192749023
Batch 17/64 loss: 0.3114195466041565
Batch 18/64 loss: 0.31046199798583984
Batch 19/64 loss: 0.3077867031097412
Batch 20/64 loss: 0.31551456451416016
Batch 21/64 loss: 0.31767892837524414
Batch 22/64 loss: 0.3189607262611389
Batch 23/64 loss: 0.31740105152130127
Batch 24/64 loss: 0.31327784061431885
Batch 25/64 loss: 0.3152874708175659
Batch 26/64 loss: 0.3204843997955322
Batch 27/64 loss: 0.317063570022583
Batch 28/64 loss: 0.31819039583206177
Batch 29/64 loss: 0.3172121047973633
Batch 30/64 loss: 0.3154306411743164
Batch 31/64 loss: 0.3179742097854614
Batch 32/64 loss: 0.31654787063598633
Batch 33/64 loss: 0.3209359645843506
Batch 34/64 loss: 0.31453055143356323
Batch 35/64 loss: 0.3268568515777588
Batch 36/64 loss: 0.315104603767395
Batch 37/64 loss: 0.30571961402893066
Batch 38/64 loss: 0.32295215129852295
Batch 39/64 loss: 0.3193780183792114
Batch 40/64 loss: 0.3129478096961975
Batch 41/64 loss: 0.3128308653831482
Batch 42/64 loss: 0.3250364065170288
Batch 43/64 loss: 0.3233909606933594
Batch 44/64 loss: 0.31067967414855957
Batch 45/64 loss: 0.31893235445022583
Batch 46/64 loss: 0.30508333444595337
Batch 47/64 loss: 0.327825129032135
Batch 48/64 loss: 0.3114258050918579
Batch 49/64 loss: 0.32245326042175293
Batch 50/64 loss: 0.31937670707702637
Batch 51/64 loss: 0.31691014766693115
Batch 52/64 loss: 0.3063739538192749
Batch 53/64 loss: 0.31954312324523926
Batch 54/64 loss: 0.3017538785934448
Batch 55/64 loss: 0.3187069892883301
Batch 56/64 loss: 0.3204793334007263
Batch 57/64 loss: 0.3214263916015625
Batch 58/64 loss: 0.3105776906013489
Batch 59/64 loss: 0.30934274196624756
Batch 60/64 loss: 0.3125319480895996
Batch 61/64 loss: 0.3167349100112915
Batch 62/64 loss: 0.31588882207870483
Batch 63/64 loss: 0.3152262568473816
Batch 64/64 loss: 0.31902652978897095
Epoch 308  Train loss: 0.3158052217726614  Val loss: 0.3349298797931868
Epoch 309
-------------------------------
Batch 1/64 loss: 0.3102409839630127
Batch 2/64 loss: 0.32061469554901123
Batch 3/64 loss: 0.3175191283226013
Batch 4/64 loss: 0.30450308322906494
Batch 5/64 loss: 0.3073158860206604
Batch 6/64 loss: 0.31744384765625
Batch 7/64 loss: 0.3270120620727539
Batch 8/64 loss: 0.3132801055908203
Batch 9/64 loss: 0.316203236579895
Batch 10/64 loss: 0.31834566593170166
Batch 11/64 loss: 0.31470155715942383
Batch 12/64 loss: 0.3073103427886963
Batch 13/64 loss: 0.30794745683670044
Batch 14/64 loss: 0.30943483114242554
Batch 15/64 loss: 0.3093307614326477
Batch 16/64 loss: 0.3122554421424866
Batch 17/64 loss: 0.3171173930168152
Batch 18/64 loss: 0.31171613931655884
Batch 19/64 loss: 0.3129206895828247
Batch 20/64 loss: 0.31655240058898926
Batch 21/64 loss: 0.31970787048339844
Batch 22/64 loss: 0.3047587275505066
Batch 23/64 loss: 0.3229826092720032
Batch 24/64 loss: 0.30747509002685547
Batch 25/64 loss: 0.3075159788131714
Batch 26/64 loss: 0.32161176204681396
Batch 27/64 loss: 0.31602346897125244
Batch 28/64 loss: 0.31252235174179077
Batch 29/64 loss: 0.31501060724258423
Batch 30/64 loss: 0.31356561183929443
Batch 31/64 loss: 0.31242311000823975
Batch 32/64 loss: 0.3109208941459656
Batch 33/64 loss: 0.3034493923187256
Batch 34/64 loss: 0.32684803009033203
Batch 35/64 loss: 0.30855339765548706
Batch 36/64 loss: 0.31147223711013794
Batch 37/64 loss: 0.3185081481933594
Batch 38/64 loss: 0.32409965991973877
Batch 39/64 loss: 0.32851946353912354
Batch 40/64 loss: 0.3166940212249756
Batch 41/64 loss: 0.309634804725647
Batch 42/64 loss: 0.3196021318435669
Batch 43/64 loss: 0.31211769580841064
Batch 44/64 loss: 0.31671082973480225
Batch 45/64 loss: 0.3170393705368042
Batch 46/64 loss: 0.3111758828163147
Batch 47/64 loss: 0.3075585961341858
Batch 48/64 loss: 0.31681013107299805
Batch 49/64 loss: 0.3125748038291931
Batch 50/64 loss: 0.31693220138549805
Batch 51/64 loss: 0.3191096782684326
Batch 52/64 loss: 0.31513679027557373
Batch 53/64 loss: 0.31892716884613037
Batch 54/64 loss: 0.31123995780944824
Batch 55/64 loss: 0.31687843799591064
Batch 56/64 loss: 0.31892573833465576
Batch 57/64 loss: 0.3150959610939026
Batch 58/64 loss: 0.3211092948913574
Batch 59/64 loss: 0.31814730167388916
Batch 60/64 loss: 0.3054584860801697
Batch 61/64 loss: 0.31964588165283203
Batch 62/64 loss: 0.31300413608551025
Batch 63/64 loss: 0.315976619720459
Batch 64/64 loss: 0.32748115062713623
Epoch 309  Train loss: 0.3148055043875002  Val loss: 0.3348101846540916
Epoch 310
-------------------------------
Batch 1/64 loss: 0.30688726902008057
Batch 2/64 loss: 0.31842654943466187
Batch 3/64 loss: 0.3121350407600403
Batch 4/64 loss: 0.3089062571525574
Batch 5/64 loss: 0.31933701038360596
Batch 6/64 loss: 0.3125894069671631
Batch 7/64 loss: 0.31415027379989624
Batch 8/64 loss: 0.3120628595352173
Batch 9/64 loss: 0.3080287575721741
Batch 10/64 loss: 0.3104528784751892
Batch 11/64 loss: 0.31855326890945435
Batch 12/64 loss: 0.31517380475997925
Batch 13/64 loss: 0.3172307014465332
Batch 14/64 loss: 0.3178167939186096
Batch 15/64 loss: 0.3097325563430786
Batch 16/64 loss: 0.3147978186607361
Batch 17/64 loss: 0.315177857875824
Batch 18/64 loss: 0.30851078033447266
Batch 19/64 loss: 0.3133254647254944
Batch 20/64 loss: 0.30918240547180176
Batch 21/64 loss: 0.32199716567993164
Batch 22/64 loss: 0.3096122741699219
Batch 23/64 loss: 0.31478166580200195
Batch 24/64 loss: 0.31381499767303467
Batch 25/64 loss: 0.3184017539024353
Batch 26/64 loss: 0.3053048849105835
Batch 27/64 loss: 0.31863629817962646
Batch 28/64 loss: 0.31714266538619995
Batch 29/64 loss: 0.3210587501525879
Batch 30/64 loss: 0.3158137798309326
Batch 31/64 loss: 0.3234924077987671
Batch 32/64 loss: 0.317471444606781
Batch 33/64 loss: 0.3120691776275635
Batch 34/64 loss: 0.31887954473495483
Batch 35/64 loss: 0.31895339488983154
Batch 36/64 loss: 0.3167465925216675
Batch 37/64 loss: 0.31535184383392334
Batch 38/64 loss: 0.31119608879089355
Batch 39/64 loss: 0.31201171875
Batch 40/64 loss: 0.31038421392440796
Batch 41/64 loss: 0.31368744373321533
Batch 42/64 loss: 0.31682097911834717
Batch 43/64 loss: 0.31475675106048584
Batch 44/64 loss: 0.317429780960083
Batch 45/64 loss: 0.31214451789855957
Batch 46/64 loss: 0.31878411769866943
Batch 47/64 loss: 0.30862927436828613
Batch 48/64 loss: 0.3114580512046814
Batch 49/64 loss: 0.3221302032470703
Batch 50/64 loss: 0.3102165460586548
Batch 51/64 loss: 0.3150765299797058
Batch 52/64 loss: 0.324190616607666
Batch 53/64 loss: 0.31394290924072266
Batch 54/64 loss: 0.31288957595825195
Batch 55/64 loss: 0.3202471137046814
Batch 56/64 loss: 0.3112598657608032
Batch 57/64 loss: 0.3115267753601074
Batch 58/64 loss: 0.31332457065582275
Batch 59/64 loss: 0.31651318073272705
Batch 60/64 loss: 0.327333927154541
Batch 61/64 loss: 0.3162463903427124
Batch 62/64 loss: 0.31514376401901245
Batch 63/64 loss: 0.32060104608535767
Batch 64/64 loss: 0.3258488178253174
Epoch 310  Train loss: 0.31504845432206696  Val loss: 0.3350753993103185
Epoch 311
-------------------------------
Batch 1/64 loss: 0.3244417905807495
Batch 2/64 loss: 0.3139357566833496
Batch 3/64 loss: 0.3193437457084656
Batch 4/64 loss: 0.324820876121521
Batch 5/64 loss: 0.3040493130683899
Batch 6/64 loss: 0.3120541572570801
Batch 7/64 loss: 0.31811022758483887
Batch 8/64 loss: 0.3054218292236328
Batch 9/64 loss: 0.31755924224853516
Batch 10/64 loss: 0.3199808597564697
Batch 11/64 loss: 0.3240358233451843
Batch 12/64 loss: 0.3140919804573059
Batch 13/64 loss: 0.3190593719482422
Batch 14/64 loss: 0.3161599636077881
Batch 15/64 loss: 0.3234572410583496
Batch 16/64 loss: 0.31921303272247314
Batch 17/64 loss: 0.3103598952293396
Batch 18/64 loss: 0.3081105947494507
Batch 19/64 loss: 0.3057018518447876
Batch 20/64 loss: 0.31666767597198486
Batch 21/64 loss: 0.3210548758506775
Batch 22/64 loss: 0.32447755336761475
Batch 23/64 loss: 0.32428818941116333
Batch 24/64 loss: 0.3179546594619751
Batch 25/64 loss: 0.31222081184387207
Batch 26/64 loss: 0.3180891275405884
Batch 27/64 loss: 0.31118226051330566
Batch 28/64 loss: 0.30532515048980713
Batch 29/64 loss: 0.32879674434661865
Batch 30/64 loss: 0.31279420852661133
Batch 31/64 loss: 0.3130924105644226
Batch 32/64 loss: 0.3148101568222046
Batch 33/64 loss: 0.3081842064857483
Batch 34/64 loss: 0.3074990510940552
Batch 35/64 loss: 0.3091304302215576
Batch 36/64 loss: 0.31394779682159424
Batch 37/64 loss: 0.31872862577438354
Batch 38/64 loss: 0.31289589405059814
Batch 39/64 loss: 0.31100618839263916
Batch 40/64 loss: 0.3117300271987915
Batch 41/64 loss: 0.3191002607345581
Batch 42/64 loss: 0.3165910840034485
Batch 43/64 loss: 0.3041480779647827
Batch 44/64 loss: 0.3117377758026123
Batch 45/64 loss: 0.31711888313293457
Batch 46/64 loss: 0.31397008895874023
Batch 47/64 loss: 0.3077336549758911
Batch 48/64 loss: 0.3231658935546875
Batch 49/64 loss: 0.32183825969696045
Batch 50/64 loss: 0.3057900667190552
Batch 51/64 loss: 0.3246060013771057
Batch 52/64 loss: 0.3185875415802002
Batch 53/64 loss: 0.32778704166412354
Batch 54/64 loss: 0.31851834058761597
Batch 55/64 loss: 0.3100047707557678
Batch 56/64 loss: 0.31368911266326904
Batch 57/64 loss: 0.3068464994430542
Batch 58/64 loss: 0.31464505195617676
Batch 59/64 loss: 0.32276296615600586
Batch 60/64 loss: 0.309228777885437
Batch 61/64 loss: 0.31260085105895996
Batch 62/64 loss: 0.3246546983718872
Batch 63/64 loss: 0.3064422607421875
Batch 64/64 loss: 0.31296634674072266
Epoch 311  Train loss: 0.31529531478881834  Val loss: 0.3341977338200992
Saving best model, epoch: 311
Epoch 312
-------------------------------
Batch 1/64 loss: 0.3196750283241272
Batch 2/64 loss: 0.31058621406555176
Batch 3/64 loss: 0.3153494596481323
Batch 4/64 loss: 0.3157925605773926
Batch 5/64 loss: 0.31307339668273926
Batch 6/64 loss: 0.31823837757110596
Batch 7/64 loss: 0.32198822498321533
Batch 8/64 loss: 0.3163250684738159
Batch 9/64 loss: 0.31952548027038574
Batch 10/64 loss: 0.3218645453453064
Batch 11/64 loss: 0.3132168650627136
Batch 12/64 loss: 0.31730902194976807
Batch 13/64 loss: 0.3096665143966675
Batch 14/64 loss: 0.3130038380622864
Batch 15/64 loss: 0.31760168075561523
Batch 16/64 loss: 0.3092116713523865
Batch 17/64 loss: 0.31494760513305664
Batch 18/64 loss: 0.3121401071548462
Batch 19/64 loss: 0.3034917116165161
Batch 20/64 loss: 0.3172571659088135
Batch 21/64 loss: 0.3189854621887207
Batch 22/64 loss: 0.3116636276245117
Batch 23/64 loss: 0.30251675844192505
Batch 24/64 loss: 0.3095424175262451
Batch 25/64 loss: 0.309114933013916
Batch 26/64 loss: 0.31316983699798584
Batch 27/64 loss: 0.317474901676178
Batch 28/64 loss: 0.3186575174331665
Batch 29/64 loss: 0.3210012912750244
Batch 30/64 loss: 0.31521886587142944
Batch 31/64 loss: 0.3101472854614258
Batch 32/64 loss: 0.31157946586608887
Batch 33/64 loss: 0.31149256229400635
Batch 34/64 loss: 0.3126347064971924
Batch 35/64 loss: 0.3118162155151367
Batch 36/64 loss: 0.3080298900604248
Batch 37/64 loss: 0.3269619941711426
Batch 38/64 loss: 0.3211076855659485
Batch 39/64 loss: 0.3113131523132324
Batch 40/64 loss: 0.3142077326774597
Batch 41/64 loss: 0.3149465322494507
Batch 42/64 loss: 0.32413268089294434
Batch 43/64 loss: 0.3143749237060547
Batch 44/64 loss: 0.307031512260437
Batch 45/64 loss: 0.3223303556442261
Batch 46/64 loss: 0.3128446936607361
Batch 47/64 loss: 0.3179256319999695
Batch 48/64 loss: 0.32352733612060547
Batch 49/64 loss: 0.3152856230735779
Batch 50/64 loss: 0.3038330078125
Batch 51/64 loss: 0.31015920639038086
Batch 52/64 loss: 0.30811643600463867
Batch 53/64 loss: 0.3214818239212036
Batch 54/64 loss: 0.30934786796569824
Batch 55/64 loss: 0.3253225088119507
Batch 56/64 loss: 0.32411062717437744
Batch 57/64 loss: 0.3205608129501343
Batch 58/64 loss: 0.30989664793014526
Batch 59/64 loss: 0.3102365732192993
Batch 60/64 loss: 0.3030852675437927
Batch 61/64 loss: 0.3160904049873352
Batch 62/64 loss: 0.31913697719573975
Batch 63/64 loss: 0.31513845920562744
Batch 64/64 loss: 0.31782007217407227
Epoch 312  Train loss: 0.3147322636024625  Val loss: 0.3345550757503182
Epoch 313
-------------------------------
Batch 1/64 loss: 0.3050191402435303
Batch 2/64 loss: 0.3158538341522217
Batch 3/64 loss: 0.31039249897003174
Batch 4/64 loss: 0.3109322190284729
Batch 5/64 loss: 0.30869126319885254
Batch 6/64 loss: 0.31295883655548096
Batch 7/64 loss: 0.30361664295196533
Batch 8/64 loss: 0.30808913707733154
Batch 9/64 loss: 0.3102368116378784
Batch 10/64 loss: 0.3179404139518738
Batch 11/64 loss: 0.31190359592437744
Batch 12/64 loss: 0.3141123056411743
Batch 13/64 loss: 0.31532299518585205
Batch 14/64 loss: 0.31353145837783813
Batch 15/64 loss: 0.30758559703826904
Batch 16/64 loss: 0.3183022737503052
Batch 17/64 loss: 0.3097463846206665
Batch 18/64 loss: 0.31881916522979736
Batch 19/64 loss: 0.3177844285964966
Batch 20/64 loss: 0.30902528762817383
Batch 21/64 loss: 0.32134759426116943
Batch 22/64 loss: 0.31684231758117676
Batch 23/64 loss: 0.3135443925857544
Batch 24/64 loss: 0.3154855966567993
Batch 25/64 loss: 0.3143385648727417
Batch 26/64 loss: 0.3133084774017334
Batch 27/64 loss: 0.3242628574371338
Batch 28/64 loss: 0.3147367238998413
Batch 29/64 loss: 0.3213436007499695
Batch 30/64 loss: 0.3143342137336731
Batch 31/64 loss: 0.3100297451019287
Batch 32/64 loss: 0.3162168860435486
Batch 33/64 loss: 0.31748008728027344
Batch 34/64 loss: 0.31099098920822144
Batch 35/64 loss: 0.31993210315704346
Batch 36/64 loss: 0.31774938106536865
Batch 37/64 loss: 0.3180311918258667
Batch 38/64 loss: 0.31206798553466797
Batch 39/64 loss: 0.3111203908920288
Batch 40/64 loss: 0.3217013478279114
Batch 41/64 loss: 0.313681960105896
Batch 42/64 loss: 0.3220174312591553
Batch 43/64 loss: 0.3162851929664612
Batch 44/64 loss: 0.31083977222442627
Batch 45/64 loss: 0.3152307868003845
Batch 46/64 loss: 0.32282114028930664
Batch 47/64 loss: 0.3144361972808838
Batch 48/64 loss: 0.31288278102874756
Batch 49/64 loss: 0.31870412826538086
Batch 50/64 loss: 0.321530818939209
Batch 51/64 loss: 0.31474918127059937
Batch 52/64 loss: 0.31393659114837646
Batch 53/64 loss: 0.3182021379470825
Batch 54/64 loss: 0.3062993288040161
Batch 55/64 loss: 0.31526482105255127
Batch 56/64 loss: 0.32554125785827637
Batch 57/64 loss: 0.31368404626846313
Batch 58/64 loss: 0.3054853677749634
Batch 59/64 loss: 0.3187682628631592
Batch 60/64 loss: 0.31244784593582153
Batch 61/64 loss: 0.3131784200668335
Batch 62/64 loss: 0.3180171251296997
Batch 63/64 loss: 0.3148164749145508
Batch 64/64 loss: 0.308749258518219
Epoch 313  Train loss: 0.31458998825035844  Val loss: 0.33500209133239955
Epoch 314
-------------------------------
Batch 1/64 loss: 0.32294797897338867
Batch 2/64 loss: 0.3218206763267517
Batch 3/64 loss: 0.3113398551940918
Batch 4/64 loss: 0.31166166067123413
Batch 5/64 loss: 0.32186174392700195
Batch 6/64 loss: 0.3105211853981018
Batch 7/64 loss: 0.3180196285247803
Batch 8/64 loss: 0.3263920545578003
Batch 9/64 loss: 0.30463171005249023
Batch 10/64 loss: 0.30718034505844116
Batch 11/64 loss: 0.3199152946472168
Batch 12/64 loss: 0.3194155693054199
Batch 13/64 loss: 0.31922006607055664
Batch 14/64 loss: 0.310846209526062
Batch 15/64 loss: 0.3115561604499817
Batch 16/64 loss: 0.32680487632751465
Batch 17/64 loss: 0.3039710521697998
Batch 18/64 loss: 0.3108333349227905
Batch 19/64 loss: 0.3074738383293152
Batch 20/64 loss: 0.32080745697021484
Batch 21/64 loss: 0.3133736252784729
Batch 22/64 loss: 0.3135533928871155
Batch 23/64 loss: 0.31674641370773315
Batch 24/64 loss: 0.32295137643814087
Batch 25/64 loss: 0.3163032531738281
Batch 26/64 loss: 0.324948787689209
Batch 27/64 loss: 0.31491392850875854
Batch 28/64 loss: 0.3093743920326233
Batch 29/64 loss: 0.3225892186164856
Batch 30/64 loss: 0.3045767545700073
Batch 31/64 loss: 0.3140450119972229
Batch 32/64 loss: 0.3096892237663269
Batch 33/64 loss: 0.3103504180908203
Batch 34/64 loss: 0.31279730796813965
Batch 35/64 loss: 0.30180442333221436
Batch 36/64 loss: 0.3167613744735718
Batch 37/64 loss: 0.30996787548065186
Batch 38/64 loss: 0.31117725372314453
Batch 39/64 loss: 0.31419825553894043
Batch 40/64 loss: 0.31778043508529663
Batch 41/64 loss: 0.3130156993865967
Batch 42/64 loss: 0.31213003396987915
Batch 43/64 loss: 0.3087766170501709
Batch 44/64 loss: 0.31577301025390625
Batch 45/64 loss: 0.31197935342788696
Batch 46/64 loss: 0.3140754699707031
Batch 47/64 loss: 0.3221563696861267
Batch 48/64 loss: 0.3241785168647766
Batch 49/64 loss: 0.31061363220214844
Batch 50/64 loss: 0.3141239881515503
Batch 51/64 loss: 0.31216925382614136
Batch 52/64 loss: 0.3047487139701843
Batch 53/64 loss: 0.31214749813079834
Batch 54/64 loss: 0.3170289397239685
Batch 55/64 loss: 0.3136053681373596
Batch 56/64 loss: 0.3159450888633728
Batch 57/64 loss: 0.31089532375335693
Batch 58/64 loss: 0.3177686929702759
Batch 59/64 loss: 0.3292495608329773
Batch 60/64 loss: 0.3180760145187378
Batch 61/64 loss: 0.31244707107543945
Batch 62/64 loss: 0.3201611042022705
Batch 63/64 loss: 0.3183908462524414
Batch 64/64 loss: 0.3186231255531311
Epoch 314  Train loss: 0.31487916754741296  Val loss: 0.33501717315097035
Epoch 315
-------------------------------
Batch 1/64 loss: 0.31875622272491455
Batch 2/64 loss: 0.31308507919311523
Batch 3/64 loss: 0.30513620376586914
Batch 4/64 loss: 0.32353675365448
Batch 5/64 loss: 0.3166530132293701
Batch 6/64 loss: 0.30998337268829346
Batch 7/64 loss: 0.31934595108032227
Batch 8/64 loss: 0.3076871633529663
Batch 9/64 loss: 0.31296706199645996
Batch 10/64 loss: 0.31826770305633545
Batch 11/64 loss: 0.32210278511047363
Batch 12/64 loss: 0.32061177492141724
Batch 13/64 loss: 0.31957942247390747
Batch 14/64 loss: 0.31113964319229126
Batch 15/64 loss: 0.32072246074676514
Batch 16/64 loss: 0.3151133060455322
Batch 17/64 loss: 0.31938135623931885
Batch 18/64 loss: 0.31023097038269043
Batch 19/64 loss: 0.3105044364929199
Batch 20/64 loss: 0.30596691370010376
Batch 21/64 loss: 0.3088245391845703
Batch 22/64 loss: 0.32202816009521484
Batch 23/64 loss: 0.31403613090515137
Batch 24/64 loss: 0.30750274658203125
Batch 25/64 loss: 0.3093602657318115
Batch 26/64 loss: 0.31136417388916016
Batch 27/64 loss: 0.31699907779693604
Batch 28/64 loss: 0.3065166473388672
Batch 29/64 loss: 0.32190555334091187
Batch 30/64 loss: 0.32335907220840454
Batch 31/64 loss: 0.31628984212875366
Batch 32/64 loss: 0.31798481941223145
Batch 33/64 loss: 0.3099781274795532
Batch 34/64 loss: 0.31973034143447876
Batch 35/64 loss: 0.3152639865875244
Batch 36/64 loss: 0.3084307312965393
Batch 37/64 loss: 0.3210182189941406
Batch 38/64 loss: 0.3094518184661865
Batch 39/64 loss: 0.3152535557746887
Batch 40/64 loss: 0.31107407808303833
Batch 41/64 loss: 0.3185155987739563
Batch 42/64 loss: 0.30592823028564453
Batch 43/64 loss: 0.30543673038482666
Batch 44/64 loss: 0.31439030170440674
Batch 45/64 loss: 0.31952977180480957
Batch 46/64 loss: 0.31127846240997314
Batch 47/64 loss: 0.32090073823928833
Batch 48/64 loss: 0.30774784088134766
Batch 49/64 loss: 0.31347978115081787
Batch 50/64 loss: 0.3176444172859192
Batch 51/64 loss: 0.3197336196899414
Batch 52/64 loss: 0.31681185960769653
Batch 53/64 loss: 0.32243895530700684
Batch 54/64 loss: 0.3210638165473938
Batch 55/64 loss: 0.31953251361846924
Batch 56/64 loss: 0.3149397373199463
Batch 57/64 loss: 0.3187068700790405
Batch 58/64 loss: 0.3172283172607422
Batch 59/64 loss: 0.3113650679588318
Batch 60/64 loss: 0.31460320949554443
Batch 61/64 loss: 0.32033294439315796
Batch 62/64 loss: 0.31157761812210083
Batch 63/64 loss: 0.308577299118042
Batch 64/64 loss: 0.32375454902648926
Epoch 315  Train loss: 0.31500742108214136  Val loss: 0.3356351282998049
Epoch 316
-------------------------------
Batch 1/64 loss: 0.3177536725997925
Batch 2/64 loss: 0.3149474859237671
Batch 3/64 loss: 0.3100229501724243
Batch 4/64 loss: 0.3094010353088379
Batch 5/64 loss: 0.31126952171325684
Batch 6/64 loss: 0.3206947445869446
Batch 7/64 loss: 0.3091679811477661
Batch 8/64 loss: 0.32010936737060547
Batch 9/64 loss: 0.3090288043022156
Batch 10/64 loss: 0.31356602907180786
Batch 11/64 loss: 0.30597394704818726
Batch 12/64 loss: 0.31450653076171875
Batch 13/64 loss: 0.3213939666748047
Batch 14/64 loss: 0.31501251459121704
Batch 15/64 loss: 0.3052154779434204
Batch 16/64 loss: 0.31536757946014404
Batch 17/64 loss: 0.31011855602264404
Batch 18/64 loss: 0.3191078305244446
Batch 19/64 loss: 0.31150591373443604
Batch 20/64 loss: 0.3135393261909485
Batch 21/64 loss: 0.30922484397888184
Batch 22/64 loss: 0.31733644008636475
Batch 23/64 loss: 0.3145639896392822
Batch 24/64 loss: 0.3143671154975891
Batch 25/64 loss: 0.3013010025024414
Batch 26/64 loss: 0.30800551176071167
Batch 27/64 loss: 0.3118457794189453
Batch 28/64 loss: 0.30739903450012207
Batch 29/64 loss: 0.3068523406982422
Batch 30/64 loss: 0.3164799213409424
Batch 31/64 loss: 0.3221691846847534
Batch 32/64 loss: 0.31674623489379883
Batch 33/64 loss: 0.3082062005996704
Batch 34/64 loss: 0.31943726539611816
Batch 35/64 loss: 0.30983078479766846
Batch 36/64 loss: 0.31805115938186646
Batch 37/64 loss: 0.3130042552947998
Batch 38/64 loss: 0.31945574283599854
Batch 39/64 loss: 0.3148937225341797
Batch 40/64 loss: 0.3116023540496826
Batch 41/64 loss: 0.320854127407074
Batch 42/64 loss: 0.31771135330200195
Batch 43/64 loss: 0.3186758756637573
Batch 44/64 loss: 0.3218267560005188
Batch 45/64 loss: 0.31033360958099365
Batch 46/64 loss: 0.30828428268432617
Batch 47/64 loss: 0.3220807909965515
Batch 48/64 loss: 0.31692957878112793
Batch 49/64 loss: 0.32173681259155273
Batch 50/64 loss: 0.3220282793045044
Batch 51/64 loss: 0.30937349796295166
Batch 52/64 loss: 0.3151057958602905
Batch 53/64 loss: 0.32418274879455566
Batch 54/64 loss: 0.32330894470214844
Batch 55/64 loss: 0.3215925693511963
Batch 56/64 loss: 0.31827056407928467
Batch 57/64 loss: 0.3097207546234131
Batch 58/64 loss: 0.3062315583229065
Batch 59/64 loss: 0.31186723709106445
Batch 60/64 loss: 0.3211026191711426
Batch 61/64 loss: 0.31513893604278564
Batch 62/64 loss: 0.31343936920166016
Batch 63/64 loss: 0.31395506858825684
Batch 64/64 loss: 0.3150118589401245
Epoch 316  Train loss: 0.3144860571505977  Val loss: 0.33584651832318385
Epoch 317
-------------------------------
Batch 1/64 loss: 0.3143491744995117
Batch 2/64 loss: 0.30961811542510986
Batch 3/64 loss: 0.3104666471481323
Batch 4/64 loss: 0.32234907150268555
Batch 5/64 loss: 0.31743818521499634
Batch 6/64 loss: 0.31436312198638916
Batch 7/64 loss: 0.3212950825691223
Batch 8/64 loss: 0.3172646760940552
Batch 9/64 loss: 0.3134312629699707
Batch 10/64 loss: 0.31291621923446655
Batch 11/64 loss: 0.3108685612678528
Batch 12/64 loss: 0.31108027696609497
Batch 13/64 loss: 0.315354585647583
Batch 14/64 loss: 0.30785590410232544
Batch 15/64 loss: 0.3097569942474365
Batch 16/64 loss: 0.30853378772735596
Batch 17/64 loss: 0.3104010224342346
Batch 18/64 loss: 0.3206944465637207
Batch 19/64 loss: 0.31708967685699463
Batch 20/64 loss: 0.3141034245491028
Batch 21/64 loss: 0.310039222240448
Batch 22/64 loss: 0.3058357238769531
Batch 23/64 loss: 0.306241512298584
Batch 24/64 loss: 0.32454776763916016
Batch 25/64 loss: 0.3180761933326721
Batch 26/64 loss: 0.3084092140197754
Batch 27/64 loss: 0.31301772594451904
Batch 28/64 loss: 0.3182864189147949
Batch 29/64 loss: 0.31324952840805054
Batch 30/64 loss: 0.3155399560928345
Batch 31/64 loss: 0.3127440810203552
Batch 32/64 loss: 0.3200211524963379
Batch 33/64 loss: 0.310870885848999
Batch 34/64 loss: 0.3032638430595398
Batch 35/64 loss: 0.3199600577354431
Batch 36/64 loss: 0.31532394886016846
Batch 37/64 loss: 0.3141672611236572
Batch 38/64 loss: 0.3131622076034546
Batch 39/64 loss: 0.30911028385162354
Batch 40/64 loss: 0.3176865577697754
Batch 41/64 loss: 0.3141669034957886
Batch 42/64 loss: 0.3170456886291504
Batch 43/64 loss: 0.3265056610107422
Batch 44/64 loss: 0.3130245804786682
Batch 45/64 loss: 0.32186639308929443
Batch 46/64 loss: 0.31203728914260864
Batch 47/64 loss: 0.30820590257644653
Batch 48/64 loss: 0.3175729513168335
Batch 49/64 loss: 0.3199964761734009
Batch 50/64 loss: 0.31372570991516113
Batch 51/64 loss: 0.30652129650115967
Batch 52/64 loss: 0.3121379017829895
Batch 53/64 loss: 0.31887680292129517
Batch 54/64 loss: 0.32072776556015015
Batch 55/64 loss: 0.31902194023132324
Batch 56/64 loss: 0.31417328119277954
Batch 57/64 loss: 0.3117467164993286
Batch 58/64 loss: 0.3156851530075073
Batch 59/64 loss: 0.3230559229850769
Batch 60/64 loss: 0.30987560749053955
Batch 61/64 loss: 0.3147556185722351
Batch 62/64 loss: 0.31933891773223877
Batch 63/64 loss: 0.30970072746276855
Batch 64/64 loss: 0.3297227621078491
Epoch 317  Train loss: 0.31460142836851235  Val loss: 0.3345947251287113
Epoch 318
-------------------------------
Batch 1/64 loss: 0.3231589198112488
Batch 2/64 loss: 0.3149852752685547
Batch 3/64 loss: 0.30383604764938354
Batch 4/64 loss: 0.32756006717681885
Batch 5/64 loss: 0.3089253902435303
Batch 6/64 loss: 0.31604552268981934
Batch 7/64 loss: 0.3022327423095703
Batch 8/64 loss: 0.31602656841278076
Batch 9/64 loss: 0.3202402591705322
Batch 10/64 loss: 0.3191893696784973
Batch 11/64 loss: 0.31479907035827637
Batch 12/64 loss: 0.3219130039215088
Batch 13/64 loss: 0.2978900074958801
Batch 14/64 loss: 0.3121427893638611
Batch 15/64 loss: 0.3135000467300415
Batch 16/64 loss: 0.3105880618095398
Batch 17/64 loss: 0.31410765647888184
Batch 18/64 loss: 0.3126187324523926
Batch 19/64 loss: 0.32233572006225586
Batch 20/64 loss: 0.31163525581359863
Batch 21/64 loss: 0.3142557740211487
Batch 22/64 loss: 0.3196125030517578
Batch 23/64 loss: 0.3173360824584961
Batch 24/64 loss: 0.3165299892425537
Batch 25/64 loss: 0.31058311462402344
Batch 26/64 loss: 0.30409955978393555
Batch 27/64 loss: 0.3098781108856201
Batch 28/64 loss: 0.31624531745910645
Batch 29/64 loss: 0.3098980188369751
Batch 30/64 loss: 0.31497639417648315
Batch 31/64 loss: 0.310030460357666
Batch 32/64 loss: 0.3168625235557556
Batch 33/64 loss: 0.3194524049758911
Batch 34/64 loss: 0.30513256788253784
Batch 35/64 loss: 0.31224048137664795
Batch 36/64 loss: 0.3116273880004883
Batch 37/64 loss: 0.3199361562728882
Batch 38/64 loss: 0.31988900899887085
Batch 39/64 loss: 0.3181288242340088
Batch 40/64 loss: 0.31370800733566284
Batch 41/64 loss: 0.31966322660446167
Batch 42/64 loss: 0.3104288578033447
Batch 43/64 loss: 0.3208439350128174
Batch 44/64 loss: 0.3120364546775818
Batch 45/64 loss: 0.3159085512161255
Batch 46/64 loss: 0.30950772762298584
Batch 47/64 loss: 0.31619060039520264
Batch 48/64 loss: 0.3122665286064148
Batch 49/64 loss: 0.31128156185150146
Batch 50/64 loss: 0.32473355531692505
Batch 51/64 loss: 0.31770700216293335
Batch 52/64 loss: 0.3112602233886719
Batch 53/64 loss: 0.31878626346588135
Batch 54/64 loss: 0.3095756769180298
Batch 55/64 loss: 0.3131486177444458
Batch 56/64 loss: 0.3052207827568054
Batch 57/64 loss: 0.3167039752006531
Batch 58/64 loss: 0.3125162720680237
Batch 59/64 loss: 0.3145599365234375
Batch 60/64 loss: 0.30552852153778076
Batch 61/64 loss: 0.31791502237319946
Batch 62/64 loss: 0.3116784691810608
Batch 63/64 loss: 0.31289029121398926
Batch 64/64 loss: 0.32147878408432007
Epoch 318  Train loss: 0.31412728370404713  Val loss: 0.33426635965858537
Epoch 319
-------------------------------
Batch 1/64 loss: 0.3104492425918579
Batch 2/64 loss: 0.3092244267463684
Batch 3/64 loss: 0.3259626626968384
Batch 4/64 loss: 0.31192731857299805
Batch 5/64 loss: 0.31779128313064575
Batch 6/64 loss: 0.3148092031478882
Batch 7/64 loss: 0.3110275864601135
Batch 8/64 loss: 0.30895525217056274
Batch 9/64 loss: 0.3173900842666626
Batch 10/64 loss: 0.3143967390060425
Batch 11/64 loss: 0.31186944246292114
Batch 12/64 loss: 0.3162344694137573
Batch 13/64 loss: 0.3148854374885559
Batch 14/64 loss: 0.3058314323425293
Batch 15/64 loss: 0.31693148612976074
Batch 16/64 loss: 0.3094189167022705
Batch 17/64 loss: 0.3152029514312744
Batch 18/64 loss: 0.309426486492157
Batch 19/64 loss: 0.3120187520980835
Batch 20/64 loss: 0.30130207538604736
Batch 21/64 loss: 0.3170640468597412
Batch 22/64 loss: 0.3111858367919922
Batch 23/64 loss: 0.316839337348938
Batch 24/64 loss: 0.31458836793899536
Batch 25/64 loss: 0.3099495768547058
Batch 26/64 loss: 0.3043249845504761
Batch 27/64 loss: 0.3182774782180786
Batch 28/64 loss: 0.3080021142959595
Batch 29/64 loss: 0.310333251953125
Batch 30/64 loss: 0.3140270709991455
Batch 31/64 loss: 0.32318413257598877
Batch 32/64 loss: 0.30940449237823486
Batch 33/64 loss: 0.31556999683380127
Batch 34/64 loss: 0.32219934463500977
Batch 35/64 loss: 0.31422507762908936
Batch 36/64 loss: 0.3252715468406677
Batch 37/64 loss: 0.3187333345413208
Batch 38/64 loss: 0.3160886764526367
Batch 39/64 loss: 0.3183005452156067
Batch 40/64 loss: 0.31919586658477783
Batch 41/64 loss: 0.31039881706237793
Batch 42/64 loss: 0.31396448612213135
Batch 43/64 loss: 0.31452077627182007
Batch 44/64 loss: 0.31871533393859863
Batch 45/64 loss: 0.3117600679397583
Batch 46/64 loss: 0.3203526735305786
Batch 47/64 loss: 0.3175066113471985
Batch 48/64 loss: 0.3132041096687317
Batch 49/64 loss: 0.30301928520202637
Batch 50/64 loss: 0.3173854351043701
Batch 51/64 loss: 0.3029346466064453
Batch 52/64 loss: 0.32155656814575195
Batch 53/64 loss: 0.320742130279541
Batch 54/64 loss: 0.3119193911552429
Batch 55/64 loss: 0.3244725465774536
Batch 56/64 loss: 0.3118739128112793
Batch 57/64 loss: 0.31115758419036865
Batch 58/64 loss: 0.3136707544326782
Batch 59/64 loss: 0.3113151788711548
Batch 60/64 loss: 0.33186131715774536
Batch 61/64 loss: 0.3127911686897278
Batch 62/64 loss: 0.31555378437042236
Batch 63/64 loss: 0.3204389810562134
Batch 64/64 loss: 0.30759578943252563
Epoch 319  Train loss: 0.31440992518967276  Val loss: 0.33517279862538235
Epoch 320
-------------------------------
Batch 1/64 loss: 0.3004037141799927
Batch 2/64 loss: 0.32192420959472656
Batch 3/64 loss: 0.3217604160308838
Batch 4/64 loss: 0.3122224807739258
Batch 5/64 loss: 0.3140946626663208
Batch 6/64 loss: 0.3186843991279602
Batch 7/64 loss: 0.3120129108428955
Batch 8/64 loss: 0.31850165128707886
Batch 9/64 loss: 0.31620872020721436
Batch 10/64 loss: 0.30953502655029297
Batch 11/64 loss: 0.3182380199432373
Batch 12/64 loss: 0.3126116991043091
Batch 13/64 loss: 0.3195229172706604
Batch 14/64 loss: 0.30896639823913574
Batch 15/64 loss: 0.31701064109802246
Batch 16/64 loss: 0.31646400690078735
Batch 17/64 loss: 0.31396424770355225
Batch 18/64 loss: 0.3070453405380249
Batch 19/64 loss: 0.30486154556274414
Batch 20/64 loss: 0.30257225036621094
Batch 21/64 loss: 0.301517128944397
Batch 22/64 loss: 0.31222808361053467
Batch 23/64 loss: 0.30595242977142334
Batch 24/64 loss: 0.3129271864891052
Batch 25/64 loss: 0.31086838245391846
Batch 26/64 loss: 0.310916543006897
Batch 27/64 loss: 0.3245072364807129
Batch 28/64 loss: 0.3169569969177246
Batch 29/64 loss: 0.3120306730270386
Batch 30/64 loss: 0.31649184226989746
Batch 31/64 loss: 0.311503529548645
Batch 32/64 loss: 0.3140745162963867
Batch 33/64 loss: 0.32151859998703003
Batch 34/64 loss: 0.30594760179519653
Batch 35/64 loss: 0.3096351623535156
Batch 36/64 loss: 0.30725955963134766
Batch 37/64 loss: 0.32142430543899536
Batch 38/64 loss: 0.3179582357406616
Batch 39/64 loss: 0.3146587014198303
Batch 40/64 loss: 0.31283456087112427
Batch 41/64 loss: 0.30871129035949707
Batch 42/64 loss: 0.32516956329345703
Batch 43/64 loss: 0.32354867458343506
Batch 44/64 loss: 0.3075333833694458
Batch 45/64 loss: 0.32427912950515747
Batch 46/64 loss: 0.30643653869628906
Batch 47/64 loss: 0.3097109794616699
Batch 48/64 loss: 0.316439151763916
Batch 49/64 loss: 0.32311761379241943
Batch 50/64 loss: 0.3139135241508484
Batch 51/64 loss: 0.31048643589019775
Batch 52/64 loss: 0.31869274377822876
Batch 53/64 loss: 0.3157101273536682
Batch 54/64 loss: 0.3220701217651367
Batch 55/64 loss: 0.30628955364227295
Batch 56/64 loss: 0.31796449422836304
Batch 57/64 loss: 0.31259167194366455
Batch 58/64 loss: 0.3078904151916504
Batch 59/64 loss: 0.31531399488449097
Batch 60/64 loss: 0.3192130923271179
Batch 61/64 loss: 0.31262099742889404
Batch 62/64 loss: 0.3050805330276489
Batch 63/64 loss: 0.3169967532157898
Batch 64/64 loss: 0.3156815767288208
Epoch 320  Train loss: 0.31379385882732913  Val loss: 0.3342329755271833
Epoch 321
-------------------------------
Batch 1/64 loss: 0.31748515367507935
Batch 2/64 loss: 0.3045614957809448
Batch 3/64 loss: 0.31181013584136963
Batch 4/64 loss: 0.31593894958496094
Batch 5/64 loss: 0.305147647857666
Batch 6/64 loss: 0.3210163712501526
Batch 7/64 loss: 0.3047153949737549
Batch 8/64 loss: 0.31226086616516113
Batch 9/64 loss: 0.305228590965271
Batch 10/64 loss: 0.3198728561401367
Batch 11/64 loss: 0.3233300447463989
Batch 12/64 loss: 0.3136588931083679
Batch 13/64 loss: 0.31159985065460205
Batch 14/64 loss: 0.32157671451568604
Batch 15/64 loss: 0.3159862160682678
Batch 16/64 loss: 0.3118535280227661
Batch 17/64 loss: 0.30657970905303955
Batch 18/64 loss: 0.30966877937316895
Batch 19/64 loss: 0.3186250925064087
Batch 20/64 loss: 0.31359052658081055
Batch 21/64 loss: 0.3134211301803589
Batch 22/64 loss: 0.3105335235595703
Batch 23/64 loss: 0.3010076880455017
Batch 24/64 loss: 0.31161725521087646
Batch 25/64 loss: 0.3137247562408447
Batch 26/64 loss: 0.31552672386169434
Batch 27/64 loss: 0.3064143657684326
Batch 28/64 loss: 0.3141058683395386
Batch 29/64 loss: 0.3135855197906494
Batch 30/64 loss: 0.318253755569458
Batch 31/64 loss: 0.3111675977706909
Batch 32/64 loss: 0.31391680240631104
Batch 33/64 loss: 0.3045406937599182
Batch 34/64 loss: 0.31323015689849854
Batch 35/64 loss: 0.3119041919708252
Batch 36/64 loss: 0.32181525230407715
Batch 37/64 loss: 0.31251680850982666
Batch 38/64 loss: 0.30929481983184814
Batch 39/64 loss: 0.317851185798645
Batch 40/64 loss: 0.31611132621765137
Batch 41/64 loss: 0.3141542673110962
Batch 42/64 loss: 0.3117635250091553
Batch 43/64 loss: 0.3240775465965271
Batch 44/64 loss: 0.31176483631134033
Batch 45/64 loss: 0.31304770708084106
Batch 46/64 loss: 0.3217916488647461
Batch 47/64 loss: 0.3098716735839844
Batch 48/64 loss: 0.30989134311676025
Batch 49/64 loss: 0.3123309016227722
Batch 50/64 loss: 0.3192211985588074
Batch 51/64 loss: 0.3124741315841675
Batch 52/64 loss: 0.3156915307044983
Batch 53/64 loss: 0.31574445962905884
Batch 54/64 loss: 0.3173481822013855
Batch 55/64 loss: 0.32197368144989014
Batch 56/64 loss: 0.31827008724212646
Batch 57/64 loss: 0.30883967876434326
Batch 58/64 loss: 0.31720125675201416
Batch 59/64 loss: 0.3184970021247864
Batch 60/64 loss: 0.3146861791610718
Batch 61/64 loss: 0.31747007369995117
Batch 62/64 loss: 0.3128840923309326
Batch 63/64 loss: 0.3117709159851074
Batch 64/64 loss: 0.3196712136268616
Epoch 321  Train loss: 0.3138127932361528  Val loss: 0.3352789555218621
Epoch 322
-------------------------------
Batch 1/64 loss: 0.3178209066390991
Batch 2/64 loss: 0.3137282729148865
Batch 3/64 loss: 0.3049274682998657
Batch 4/64 loss: 0.3082616925239563
Batch 5/64 loss: 0.3173825144767761
Batch 6/64 loss: 0.3177446126937866
Batch 7/64 loss: 0.32037997245788574
Batch 8/64 loss: 0.31031274795532227
Batch 9/64 loss: 0.30890876054763794
Batch 10/64 loss: 0.30470430850982666
Batch 11/64 loss: 0.30410289764404297
Batch 12/64 loss: 0.3136855363845825
Batch 13/64 loss: 0.30889785289764404
Batch 14/64 loss: 0.30218976736068726
Batch 15/64 loss: 0.3100963830947876
Batch 16/64 loss: 0.3163517713546753
Batch 17/64 loss: 0.31849193572998047
Batch 18/64 loss: 0.32005858421325684
Batch 19/64 loss: 0.3159552812576294
Batch 20/64 loss: 0.3103141188621521
Batch 21/64 loss: 0.3027467727661133
Batch 22/64 loss: 0.31106603145599365
Batch 23/64 loss: 0.316219687461853
Batch 24/64 loss: 0.30753523111343384
Batch 25/64 loss: 0.3160790801048279
Batch 26/64 loss: 0.3095170259475708
Batch 27/64 loss: 0.3149322271347046
Batch 28/64 loss: 0.3256317377090454
Batch 29/64 loss: 0.31537044048309326
Batch 30/64 loss: 0.3128897547721863
Batch 31/64 loss: 0.31364333629608154
Batch 32/64 loss: 0.3188609480857849
Batch 33/64 loss: 0.30944275856018066
Batch 34/64 loss: 0.31420499086380005
Batch 35/64 loss: 0.318586528301239
Batch 36/64 loss: 0.3226194977760315
Batch 37/64 loss: 0.30462753772735596
Batch 38/64 loss: 0.3202548027038574
Batch 39/64 loss: 0.30920660495758057
Batch 40/64 loss: 0.3135404586791992
Batch 41/64 loss: 0.30904507637023926
Batch 42/64 loss: 0.3170267343521118
Batch 43/64 loss: 0.3071805238723755
Batch 44/64 loss: 0.31752151250839233
Batch 45/64 loss: 0.31295621395111084
Batch 46/64 loss: 0.3205082416534424
Batch 47/64 loss: 0.32831329107284546
Batch 48/64 loss: 0.31462734937667847
Batch 49/64 loss: 0.3125966787338257
Batch 50/64 loss: 0.3150399327278137
Batch 51/64 loss: 0.30935555696487427
Batch 52/64 loss: 0.31870508193969727
Batch 53/64 loss: 0.30787503719329834
Batch 54/64 loss: 0.31731247901916504
Batch 55/64 loss: 0.3095736503601074
Batch 56/64 loss: 0.31620877981185913
Batch 57/64 loss: 0.3158245086669922
Batch 58/64 loss: 0.31771427392959595
Batch 59/64 loss: 0.3187445402145386
Batch 60/64 loss: 0.3183790445327759
Batch 61/64 loss: 0.31896382570266724
Batch 62/64 loss: 0.3058208227157593
Batch 63/64 loss: 0.3179115653038025
Batch 64/64 loss: 0.31211233139038086
Epoch 322  Train loss: 0.31376595777623795  Val loss: 0.3340981645682423
Saving best model, epoch: 322
Epoch 323
-------------------------------
Batch 1/64 loss: 0.3103156089782715
Batch 2/64 loss: 0.30905693769454956
Batch 3/64 loss: 0.31454336643218994
Batch 4/64 loss: 0.31747186183929443
Batch 5/64 loss: 0.3119349479675293
Batch 6/64 loss: 0.3182159662246704
Batch 7/64 loss: 0.31280457973480225
Batch 8/64 loss: 0.3117164373397827
Batch 9/64 loss: 0.312267541885376
Batch 10/64 loss: 0.3148069381713867
Batch 11/64 loss: 0.320156455039978
Batch 12/64 loss: 0.3102986812591553
Batch 13/64 loss: 0.313629150390625
Batch 14/64 loss: 0.31576967239379883
Batch 15/64 loss: 0.30588865280151367
Batch 16/64 loss: 0.3151451349258423
Batch 17/64 loss: 0.31259799003601074
Batch 18/64 loss: 0.3156026005744934
Batch 19/64 loss: 0.31588590145111084
Batch 20/64 loss: 0.3106207251548767
Batch 21/64 loss: 0.30761563777923584
Batch 22/64 loss: 0.31380200386047363
Batch 23/64 loss: 0.32092905044555664
Batch 24/64 loss: 0.3165184259414673
Batch 25/64 loss: 0.3104062080383301
Batch 26/64 loss: 0.30494141578674316
Batch 27/64 loss: 0.31641876697540283
Batch 28/64 loss: 0.3181045651435852
Batch 29/64 loss: 0.3111536502838135
Batch 30/64 loss: 0.3188686966896057
Batch 31/64 loss: 0.31586170196533203
Batch 32/64 loss: 0.313820481300354
Batch 33/64 loss: 0.30920839309692383
Batch 34/64 loss: 0.31169748306274414
Batch 35/64 loss: 0.3140851855278015
Batch 36/64 loss: 0.31869375705718994
Batch 37/64 loss: 0.3201826810836792
Batch 38/64 loss: 0.3153963088989258
Batch 39/64 loss: 0.3132123351097107
Batch 40/64 loss: 0.3123033046722412
Batch 41/64 loss: 0.3002459406852722
Batch 42/64 loss: 0.3180760145187378
Batch 43/64 loss: 0.3072340488433838
Batch 44/64 loss: 0.3175320625305176
Batch 45/64 loss: 0.3074411153793335
Batch 46/64 loss: 0.3113909959793091
Batch 47/64 loss: 0.32027947902679443
Batch 48/64 loss: 0.30370795726776123
Batch 49/64 loss: 0.31235194206237793
Batch 50/64 loss: 0.32174110412597656
Batch 51/64 loss: 0.31072837114334106
Batch 52/64 loss: 0.308774471282959
Batch 53/64 loss: 0.31063389778137207
Batch 54/64 loss: 0.31382811069488525
Batch 55/64 loss: 0.31745976209640503
Batch 56/64 loss: 0.3137282133102417
Batch 57/64 loss: 0.31864821910858154
Batch 58/64 loss: 0.3214717507362366
Batch 59/64 loss: 0.32038676738739014
Batch 60/64 loss: 0.31452345848083496
Batch 61/64 loss: 0.3293522596359253
Batch 62/64 loss: 0.3060116767883301
Batch 63/64 loss: 0.29416579008102417
Batch 64/64 loss: 0.32105737924575806
Epoch 323  Train loss: 0.31360714739444207  Val loss: 0.33374296656179264
Saving best model, epoch: 323
Epoch 324
-------------------------------
Batch 1/64 loss: 0.3157966136932373
Batch 2/64 loss: 0.3144536018371582
Batch 3/64 loss: 0.31250518560409546
Batch 4/64 loss: 0.3097110390663147
Batch 5/64 loss: 0.3092358708381653
Batch 6/64 loss: 0.30529969930648804
Batch 7/64 loss: 0.31811267137527466
Batch 8/64 loss: 0.31144577264785767
Batch 9/64 loss: 0.30951988697052
Batch 10/64 loss: 0.3114800453186035
Batch 11/64 loss: 0.30392366647720337
Batch 12/64 loss: 0.30960899591445923
Batch 13/64 loss: 0.31291651725769043
Batch 14/64 loss: 0.30499929189682007
Batch 15/64 loss: 0.31600528955459595
Batch 16/64 loss: 0.30636537075042725
Batch 17/64 loss: 0.3132210373878479
Batch 18/64 loss: 0.31258201599121094
Batch 19/64 loss: 0.3176088333129883
Batch 20/64 loss: 0.3206651210784912
Batch 21/64 loss: 0.3095075488090515
Batch 22/64 loss: 0.31197744607925415
Batch 23/64 loss: 0.31521469354629517
Batch 24/64 loss: 0.3118552565574646
Batch 25/64 loss: 0.31230825185775757
Batch 26/64 loss: 0.3162649869918823
Batch 27/64 loss: 0.3161112070083618
Batch 28/64 loss: 0.3180326819419861
Batch 29/64 loss: 0.3117290735244751
Batch 30/64 loss: 0.31839853525161743
Batch 31/64 loss: 0.308866024017334
Batch 32/64 loss: 0.3090636730194092
Batch 33/64 loss: 0.3125845193862915
Batch 34/64 loss: 0.3145619034767151
Batch 35/64 loss: 0.3142203092575073
Batch 36/64 loss: 0.30880337953567505
Batch 37/64 loss: 0.3194732666015625
Batch 38/64 loss: 0.31559354066848755
Batch 39/64 loss: 0.3196083903312683
Batch 40/64 loss: 0.3146672248840332
Batch 41/64 loss: 0.3221101760864258
Batch 42/64 loss: 0.32062357664108276
Batch 43/64 loss: 0.3158031702041626
Batch 44/64 loss: 0.3114163279533386
Batch 45/64 loss: 0.2994764447212219
Batch 46/64 loss: 0.3124657869338989
Batch 47/64 loss: 0.3037673234939575
Batch 48/64 loss: 0.32699811458587646
Batch 49/64 loss: 0.3142678737640381
Batch 50/64 loss: 0.32019734382629395
Batch 51/64 loss: 0.3200749158859253
Batch 52/64 loss: 0.31851261854171753
Batch 53/64 loss: 0.31124937534332275
Batch 54/64 loss: 0.31470370292663574
Batch 55/64 loss: 0.31422144174575806
Batch 56/64 loss: 0.30568063259124756
Batch 57/64 loss: 0.31435275077819824
Batch 58/64 loss: 0.31588685512542725
Batch 59/64 loss: 0.3177555799484253
Batch 60/64 loss: 0.315313458442688
Batch 61/64 loss: 0.30972278118133545
Batch 62/64 loss: 0.3127250075340271
Batch 63/64 loss: 0.3122771978378296
Batch 64/64 loss: 0.3141506314277649
Epoch 324  Train loss: 0.3134041391166986  Val loss: 0.3348337946478854
Epoch 325
-------------------------------
Batch 1/64 loss: 0.3076390027999878
Batch 2/64 loss: 0.3082026243209839
Batch 3/64 loss: 0.3165740370750427
Batch 4/64 loss: 0.3102545142173767
Batch 5/64 loss: 0.31405067443847656
Batch 6/64 loss: 0.3113124966621399
Batch 7/64 loss: 0.3137296438217163
Batch 8/64 loss: 0.31219756603240967
Batch 9/64 loss: 0.317124605178833
Batch 10/64 loss: 0.30674076080322266
Batch 11/64 loss: 0.3106195330619812
Batch 12/64 loss: 0.31976062059402466
Batch 13/64 loss: 0.3161278963088989
Batch 14/64 loss: 0.3089085817337036
Batch 15/64 loss: 0.319533109664917
Batch 16/64 loss: 0.31939399242401123
Batch 17/64 loss: 0.3095892667770386
Batch 18/64 loss: 0.32808393239974976
Batch 19/64 loss: 0.31613218784332275
Batch 20/64 loss: 0.32165974378585815
Batch 21/64 loss: 0.31117409467697144
Batch 22/64 loss: 0.30798590183258057
Batch 23/64 loss: 0.308885395526886
Batch 24/64 loss: 0.31362056732177734
Batch 25/64 loss: 0.31291091442108154
Batch 26/64 loss: 0.31199610233306885
Batch 27/64 loss: 0.31084418296813965
Batch 28/64 loss: 0.31285881996154785
Batch 29/64 loss: 0.3164442777633667
Batch 30/64 loss: 0.31416910886764526
Batch 31/64 loss: 0.31069284677505493
Batch 32/64 loss: 0.31397902965545654
Batch 33/64 loss: 0.31657785177230835
Batch 34/64 loss: 0.30870920419692993
Batch 35/64 loss: 0.31000518798828125
Batch 36/64 loss: 0.3093831539154053
Batch 37/64 loss: 0.3157559037208557
Batch 38/64 loss: 0.3165104389190674
Batch 39/64 loss: 0.31462717056274414
Batch 40/64 loss: 0.3174670934677124
Batch 41/64 loss: 0.3159142732620239
Batch 42/64 loss: 0.3078101873397827
Batch 43/64 loss: 0.3088104724884033
Batch 44/64 loss: 0.3103266954421997
Batch 45/64 loss: 0.323026180267334
Batch 46/64 loss: 0.3211357593536377
Batch 47/64 loss: 0.30896806716918945
Batch 48/64 loss: 0.30629289150238037
Batch 49/64 loss: 0.31608760356903076
Batch 50/64 loss: 0.3065985441207886
Batch 51/64 loss: 0.31125104427337646
Batch 52/64 loss: 0.3172062635421753
Batch 53/64 loss: 0.3138160705566406
Batch 54/64 loss: 0.3200465440750122
Batch 55/64 loss: 0.31335216760635376
Batch 56/64 loss: 0.31426525115966797
Batch 57/64 loss: 0.31297874450683594
Batch 58/64 loss: 0.31137120723724365
Batch 59/64 loss: 0.3112487196922302
Batch 60/64 loss: 0.31104588508605957
Batch 61/64 loss: 0.31348252296447754
Batch 62/64 loss: 0.30847495794296265
Batch 63/64 loss: 0.310005784034729
Batch 64/64 loss: 0.3093491196632385
Epoch 325  Train loss: 0.3132197602122438  Val loss: 0.33550190188221096
Epoch 326
-------------------------------
Batch 1/64 loss: 0.31270498037338257
Batch 2/64 loss: 0.3223356008529663
Batch 3/64 loss: 0.31119847297668457
Batch 4/64 loss: 0.3175349831581116
Batch 5/64 loss: 0.30049633979797363
Batch 6/64 loss: 0.31527209281921387
Batch 7/64 loss: 0.3151944875717163
Batch 8/64 loss: 0.3128368854522705
Batch 9/64 loss: 0.31414318084716797
Batch 10/64 loss: 0.3064282536506653
Batch 11/64 loss: 0.3106340169906616
Batch 12/64 loss: 0.3158019781112671
Batch 13/64 loss: 0.31068623065948486
Batch 14/64 loss: 0.3145231008529663
Batch 15/64 loss: 0.312366247177124
Batch 16/64 loss: 0.3110087513923645
Batch 17/64 loss: 0.33273065090179443
Batch 18/64 loss: 0.32240933179855347
Batch 19/64 loss: 0.3155896067619324
Batch 20/64 loss: 0.3156171441078186
Batch 21/64 loss: 0.3178013563156128
Batch 22/64 loss: 0.30892765522003174
Batch 23/64 loss: 0.31026655435562134
Batch 24/64 loss: 0.32318711280822754
Batch 25/64 loss: 0.3191359043121338
Batch 26/64 loss: 0.3141591548919678
Batch 27/64 loss: 0.31099045276641846
Batch 28/64 loss: 0.3148841857910156
Batch 29/64 loss: 0.3166126608848572
Batch 30/64 loss: 0.30944371223449707
Batch 31/64 loss: 0.31105417013168335
Batch 32/64 loss: 0.31831443309783936
Batch 33/64 loss: 0.3168337345123291
Batch 34/64 loss: 0.31424760818481445
Batch 35/64 loss: 0.311370313167572
Batch 36/64 loss: 0.3146723508834839
Batch 37/64 loss: 0.3086535334587097
Batch 38/64 loss: 0.3120391368865967
Batch 39/64 loss: 0.31725621223449707
Batch 40/64 loss: 0.3149412274360657
Batch 41/64 loss: 0.312045156955719
Batch 42/64 loss: 0.309597373008728
Batch 43/64 loss: 0.3116067051887512
Batch 44/64 loss: 0.3052576780319214
Batch 45/64 loss: 0.30580151081085205
Batch 46/64 loss: 0.30289268493652344
Batch 47/64 loss: 0.3154839277267456
Batch 48/64 loss: 0.31233906745910645
Batch 49/64 loss: 0.3125367760658264
Batch 50/64 loss: 0.31898778676986694
Batch 51/64 loss: 0.305910587310791
Batch 52/64 loss: 0.31696927547454834
Batch 53/64 loss: 0.31351739168167114
Batch 54/64 loss: 0.3100128769874573
Batch 55/64 loss: 0.3266156315803528
Batch 56/64 loss: 0.3181501030921936
Batch 57/64 loss: 0.3102455139160156
Batch 58/64 loss: 0.30793297290802
Batch 59/64 loss: 0.30853646993637085
Batch 60/64 loss: 0.30146390199661255
Batch 61/64 loss: 0.31361639499664307
Batch 62/64 loss: 0.3199724555015564
Batch 63/64 loss: 0.30978918075561523
Batch 64/64 loss: 0.3124515414237976
Epoch 326  Train loss: 0.31337919819588755  Val loss: 0.3351055492240539
Epoch 327
-------------------------------
Batch 1/64 loss: 0.31525903940200806
Batch 2/64 loss: 0.3124193549156189
Batch 3/64 loss: 0.30975329875946045
Batch 4/64 loss: 0.3142528533935547
Batch 5/64 loss: 0.31653130054473877
Batch 6/64 loss: 0.30932921171188354
Batch 7/64 loss: 0.3112598657608032
Batch 8/64 loss: 0.3054879903793335
Batch 9/64 loss: 0.3136570453643799
Batch 10/64 loss: 0.30332595109939575
Batch 11/64 loss: 0.3066955804824829
Batch 12/64 loss: 0.323261022567749
Batch 13/64 loss: 0.3074635863304138
Batch 14/64 loss: 0.31005942821502686
Batch 15/64 loss: 0.30289405584335327
Batch 16/64 loss: 0.3124117851257324
Batch 17/64 loss: 0.3121078610420227
Batch 18/64 loss: 0.30560117959976196
Batch 19/64 loss: 0.3105790615081787
Batch 20/64 loss: 0.3074798583984375
Batch 21/64 loss: 0.32933127880096436
Batch 22/64 loss: 0.31403422355651855
Batch 23/64 loss: 0.30919963121414185
Batch 24/64 loss: 0.31230002641677856
Batch 25/64 loss: 0.32257080078125
Batch 26/64 loss: 0.3106895685195923
Batch 27/64 loss: 0.31260210275650024
Batch 28/64 loss: 0.3104000687599182
Batch 29/64 loss: 0.3159114122390747
Batch 30/64 loss: 0.3143770694732666
Batch 31/64 loss: 0.3133671283721924
Batch 32/64 loss: 0.3061094284057617
Batch 33/64 loss: 0.3135605454444885
Batch 34/64 loss: 0.3140089511871338
Batch 35/64 loss: 0.30615490674972534
Batch 36/64 loss: 0.3151182532310486
Batch 37/64 loss: 0.31869375705718994
Batch 38/64 loss: 0.3089895248413086
Batch 39/64 loss: 0.30999326705932617
Batch 40/64 loss: 0.3236122131347656
Batch 41/64 loss: 0.31153327226638794
Batch 42/64 loss: 0.3153897523880005
Batch 43/64 loss: 0.3147057294845581
Batch 44/64 loss: 0.313460111618042
Batch 45/64 loss: 0.3166050910949707
Batch 46/64 loss: 0.30652713775634766
Batch 47/64 loss: 0.3145788908004761
Batch 48/64 loss: 0.3002680540084839
Batch 49/64 loss: 0.322096586227417
Batch 50/64 loss: 0.32251524925231934
Batch 51/64 loss: 0.31502002477645874
Batch 52/64 loss: 0.3126952648162842
Batch 53/64 loss: 0.31009936332702637
Batch 54/64 loss: 0.3264859914779663
Batch 55/64 loss: 0.32085883617401123
Batch 56/64 loss: 0.3167520761489868
Batch 57/64 loss: 0.3110722303390503
Batch 58/64 loss: 0.315413236618042
Batch 59/64 loss: 0.32067418098449707
Batch 60/64 loss: 0.3077958822250366
Batch 61/64 loss: 0.31794488430023193
Batch 62/64 loss: 0.30687415599823
Batch 63/64 loss: 0.3192262649536133
Batch 64/64 loss: 0.3234097957611084
Epoch 327  Train loss: 0.31328632317337335  Val loss: 0.33469050528667227
Epoch 328
-------------------------------
Batch 1/64 loss: 0.3164710998535156
Batch 2/64 loss: 0.31497395038604736
Batch 3/64 loss: 0.3032047748565674
Batch 4/64 loss: 0.31227993965148926
Batch 5/64 loss: 0.3198375105857849
Batch 6/64 loss: 0.315898060798645
Batch 7/64 loss: 0.30588364601135254
Batch 8/64 loss: 0.3149980902671814
Batch 9/64 loss: 0.30979639291763306
Batch 10/64 loss: 0.31023508310317993
Batch 11/64 loss: 0.3177347183227539
Batch 12/64 loss: 0.31703317165374756
Batch 13/64 loss: 0.3091279864311218
Batch 14/64 loss: 0.32237380743026733
Batch 15/64 loss: 0.3049713969230652
Batch 16/64 loss: 0.31542670726776123
Batch 17/64 loss: 0.3044913411140442
Batch 18/64 loss: 0.3142685890197754
Batch 19/64 loss: 0.3215196132659912
Batch 20/64 loss: 0.31433558464050293
Batch 21/64 loss: 0.3043971061706543
Batch 22/64 loss: 0.31519854068756104
Batch 23/64 loss: 0.3096950054168701
Batch 24/64 loss: 0.30512523651123047
Batch 25/64 loss: 0.3225131034851074
Batch 26/64 loss: 0.3152815103530884
Batch 27/64 loss: 0.3178398609161377
Batch 28/64 loss: 0.3108581304550171
Batch 29/64 loss: 0.3161020278930664
Batch 30/64 loss: 0.3143773674964905
Batch 31/64 loss: 0.31458020210266113
Batch 32/64 loss: 0.3118041753768921
Batch 33/64 loss: 0.3161441683769226
Batch 34/64 loss: 0.3200857639312744
Batch 35/64 loss: 0.3075982332229614
Batch 36/64 loss: 0.3142961859703064
Batch 37/64 loss: 0.305026113986969
Batch 38/64 loss: 0.31111955642700195
Batch 39/64 loss: 0.3110951781272888
Batch 40/64 loss: 0.31610560417175293
Batch 41/64 loss: 0.3099913001060486
Batch 42/64 loss: 0.31722044944763184
Batch 43/64 loss: 0.31589996814727783
Batch 44/64 loss: 0.30858123302459717
Batch 45/64 loss: 0.3099440336227417
Batch 46/64 loss: 0.3084867000579834
Batch 47/64 loss: 0.31316208839416504
Batch 48/64 loss: 0.30843013525009155
Batch 49/64 loss: 0.31845200061798096
Batch 50/64 loss: 0.32460975646972656
Batch 51/64 loss: 0.31174635887145996
Batch 52/64 loss: 0.30943381786346436
Batch 53/64 loss: 0.3105607032775879
Batch 54/64 loss: 0.3167586326599121
Batch 55/64 loss: 0.31994903087615967
Batch 56/64 loss: 0.3136630654335022
Batch 57/64 loss: 0.3165450096130371
Batch 58/64 loss: 0.31942498683929443
Batch 59/64 loss: 0.30815643072128296
Batch 60/64 loss: 0.3182634115219116
Batch 61/64 loss: 0.3198833465576172
Batch 62/64 loss: 0.31332093477249146
Batch 63/64 loss: 0.31952905654907227
Batch 64/64 loss: 0.32421159744262695
Epoch 328  Train loss: 0.3137141283820657  Val loss: 0.3365642989623997
Epoch 329
-------------------------------
Batch 1/64 loss: 0.31315362453460693
Batch 2/64 loss: 0.3075956702232361
Batch 3/64 loss: 0.3124641180038452
Batch 4/64 loss: 0.3099455237388611
Batch 5/64 loss: 0.314103901386261
Batch 6/64 loss: 0.31194788217544556
Batch 7/64 loss: 0.31913042068481445
Batch 8/64 loss: 0.30449914932250977
Batch 9/64 loss: 0.3178432583808899
Batch 10/64 loss: 0.31373071670532227
Batch 11/64 loss: 0.3086774945259094
Batch 12/64 loss: 0.31646502017974854
Batch 13/64 loss: 0.31582361459732056
Batch 14/64 loss: 0.3104844093322754
Batch 15/64 loss: 0.3236597776412964
Batch 16/64 loss: 0.31544339656829834
Batch 17/64 loss: 0.3088145852088928
Batch 18/64 loss: 0.31793367862701416
Batch 19/64 loss: 0.31397533416748047
Batch 20/64 loss: 0.3063851594924927
Batch 21/64 loss: 0.313811719417572
Batch 22/64 loss: 0.30641061067581177
Batch 23/64 loss: 0.3156067132949829
Batch 24/64 loss: 0.3157074451446533
Batch 25/64 loss: 0.30494576692581177
Batch 26/64 loss: 0.31210196018218994
Batch 27/64 loss: 0.3051426410675049
Batch 28/64 loss: 0.3008549213409424
Batch 29/64 loss: 0.3085287809371948
Batch 30/64 loss: 0.310794472694397
Batch 31/64 loss: 0.30515968799591064
Batch 32/64 loss: 0.31406283378601074
Batch 33/64 loss: 0.3174617290496826
Batch 34/64 loss: 0.31039732694625854
Batch 35/64 loss: 0.3204193115234375
Batch 36/64 loss: 0.3105699419975281
Batch 37/64 loss: 0.3159794807434082
Batch 38/64 loss: 0.3162038326263428
Batch 39/64 loss: 0.3213311433792114
Batch 40/64 loss: 0.3136140704154968
Batch 41/64 loss: 0.3216245770454407
Batch 42/64 loss: 0.3116171360015869
Batch 43/64 loss: 0.3087702989578247
Batch 44/64 loss: 0.32061833143234253
Batch 45/64 loss: 0.3176952004432678
Batch 46/64 loss: 0.3109426498413086
Batch 47/64 loss: 0.3109191060066223
Batch 48/64 loss: 0.31121760606765747
Batch 49/64 loss: 0.31911057233810425
Batch 50/64 loss: 0.319655179977417
Batch 51/64 loss: 0.3107558488845825
Batch 52/64 loss: 0.3179565668106079
Batch 53/64 loss: 0.3087805509567261
Batch 54/64 loss: 0.3185814619064331
Batch 55/64 loss: 0.3131589889526367
Batch 56/64 loss: 0.3124237060546875
Batch 57/64 loss: 0.31548506021499634
Batch 58/64 loss: 0.3127337694168091
Batch 59/64 loss: 0.31481146812438965
Batch 60/64 loss: 0.3213762044906616
Batch 61/64 loss: 0.32241159677505493
Batch 62/64 loss: 0.3073766231536865
Batch 63/64 loss: 0.3068549633026123
Batch 64/64 loss: 0.33116626739501953
Epoch 329  Train loss: 0.3134813065622367  Val loss: 0.33482270756947624
Epoch 330
-------------------------------
Batch 1/64 loss: 0.30666589736938477
Batch 2/64 loss: 0.3189966678619385
Batch 3/64 loss: 0.31127142906188965
Batch 4/64 loss: 0.31532585620880127
Batch 5/64 loss: 0.3093167543411255
Batch 6/64 loss: 0.3053741455078125
Batch 7/64 loss: 0.3143618106842041
Batch 8/64 loss: 0.3037794232368469
Batch 9/64 loss: 0.32178443670272827
Batch 10/64 loss: 0.3074915409088135
Batch 11/64 loss: 0.31981098651885986
Batch 12/64 loss: 0.30944228172302246
Batch 13/64 loss: 0.3102380037307739
Batch 14/64 loss: 0.3138688802719116
Batch 15/64 loss: 0.31433117389678955
Batch 16/64 loss: 0.3165527582168579
Batch 17/64 loss: 0.3066215515136719
Batch 18/64 loss: 0.31768983602523804
Batch 19/64 loss: 0.30768120288848877
Batch 20/64 loss: 0.3115731477737427
Batch 21/64 loss: 0.31565552949905396
Batch 22/64 loss: 0.30925416946411133
Batch 23/64 loss: 0.30718958377838135
Batch 24/64 loss: 0.3224637508392334
Batch 25/64 loss: 0.3094344735145569
Batch 26/64 loss: 0.3013574481010437
Batch 27/64 loss: 0.3172350525856018
Batch 28/64 loss: 0.31390380859375
Batch 29/64 loss: 0.3183000087738037
Batch 30/64 loss: 0.3166782259941101
Batch 31/64 loss: 0.3157005310058594
Batch 32/64 loss: 0.3176978826522827
Batch 33/64 loss: 0.31275254487991333
Batch 34/64 loss: 0.3054698705673218
Batch 35/64 loss: 0.31470751762390137
Batch 36/64 loss: 0.3200117349624634
Batch 37/64 loss: 0.3145563006401062
Batch 38/64 loss: 0.3077116012573242
Batch 39/64 loss: 0.31386232376098633
Batch 40/64 loss: 0.30960601568222046
Batch 41/64 loss: 0.3157557249069214
Batch 42/64 loss: 0.312053918838501
Batch 43/64 loss: 0.3109705448150635
Batch 44/64 loss: 0.30535459518432617
Batch 45/64 loss: 0.31089305877685547
Batch 46/64 loss: 0.3104180097579956
Batch 47/64 loss: 0.3118440508842468
Batch 48/64 loss: 0.30887317657470703
Batch 49/64 loss: 0.311928391456604
Batch 50/64 loss: 0.31298428773880005
Batch 51/64 loss: 0.3197826147079468
Batch 52/64 loss: 0.3169991374015808
Batch 53/64 loss: 0.31298303604125977
Batch 54/64 loss: 0.30590319633483887
Batch 55/64 loss: 0.3140895366668701
Batch 56/64 loss: 0.31722867488861084
Batch 57/64 loss: 0.306843638420105
Batch 58/64 loss: 0.31894320249557495
Batch 59/64 loss: 0.3227059841156006
Batch 60/64 loss: 0.3121015429496765
Batch 61/64 loss: 0.3189459443092346
Batch 62/64 loss: 0.3172870874404907
Batch 63/64 loss: 0.32393133640289307
Batch 64/64 loss: 0.30737900733947754
Epoch 330  Train loss: 0.31302088008207435  Val loss: 0.33477023827660946
Epoch 331
-------------------------------
Batch 1/64 loss: 0.30674946308135986
Batch 2/64 loss: 0.31245625019073486
Batch 3/64 loss: 0.30275195837020874
Batch 4/64 loss: 0.3126661777496338
Batch 5/64 loss: 0.3187381625175476
Batch 6/64 loss: 0.31101149320602417
Batch 7/64 loss: 0.31739360094070435
Batch 8/64 loss: 0.3157802224159241
Batch 9/64 loss: 0.31174731254577637
Batch 10/64 loss: 0.3102589249610901
Batch 11/64 loss: 0.3056328296661377
Batch 12/64 loss: 0.3084566593170166
Batch 13/64 loss: 0.3117295503616333
Batch 14/64 loss: 0.3148106336593628
Batch 15/64 loss: 0.3181774616241455
Batch 16/64 loss: 0.31541430950164795
Batch 17/64 loss: 0.3138672113418579
Batch 18/64 loss: 0.3233298063278198
Batch 19/64 loss: 0.29692256450653076
Batch 20/64 loss: 0.3031843900680542
Batch 21/64 loss: 0.31408756971359253
Batch 22/64 loss: 0.30866873264312744
Batch 23/64 loss: 0.3131374716758728
Batch 24/64 loss: 0.31034034490585327
Batch 25/64 loss: 0.31170737743377686
Batch 26/64 loss: 0.3132842779159546
Batch 27/64 loss: 0.3140580654144287
Batch 28/64 loss: 0.31035125255584717
Batch 29/64 loss: 0.31888115406036377
Batch 30/64 loss: 0.32519716024398804
Batch 31/64 loss: 0.31524181365966797
Batch 32/64 loss: 0.3113255500793457
Batch 33/64 loss: 0.31101709604263306
Batch 34/64 loss: 0.3147350549697876
Batch 35/64 loss: 0.31141746044158936
Batch 36/64 loss: 0.30473971366882324
Batch 37/64 loss: 0.3161424398422241
Batch 38/64 loss: 0.30976998805999756
Batch 39/64 loss: 0.30609846115112305
Batch 40/64 loss: 0.31912529468536377
Batch 41/64 loss: 0.3157727122306824
Batch 42/64 loss: 0.31020522117614746
Batch 43/64 loss: 0.31263160705566406
Batch 44/64 loss: 0.3001338243484497
Batch 45/64 loss: 0.3201218843460083
Batch 46/64 loss: 0.31374311447143555
Batch 47/64 loss: 0.3127861022949219
Batch 48/64 loss: 0.31761980056762695
Batch 49/64 loss: 0.3128959536552429
Batch 50/64 loss: 0.3185514211654663
Batch 51/64 loss: 0.31530410051345825
Batch 52/64 loss: 0.3155285120010376
Batch 53/64 loss: 0.31158971786499023
Batch 54/64 loss: 0.31070607900619507
Batch 55/64 loss: 0.314852774143219
Batch 56/64 loss: 0.3148130178451538
Batch 57/64 loss: 0.3232285976409912
Batch 58/64 loss: 0.31922197341918945
Batch 59/64 loss: 0.3068476915359497
Batch 60/64 loss: 0.30424952507019043
Batch 61/64 loss: 0.31578385829925537
Batch 62/64 loss: 0.31187212467193604
Batch 63/64 loss: 0.32526731491088867
Batch 64/64 loss: 0.30825597047805786
Epoch 331  Train loss: 0.31286783008014457  Val loss: 0.3341582593639282
Epoch 332
-------------------------------
Batch 1/64 loss: 0.3094804286956787
Batch 2/64 loss: 0.3085489869117737
Batch 3/64 loss: 0.31112080812454224
Batch 4/64 loss: 0.3026003837585449
Batch 5/64 loss: 0.3166118264198303
Batch 6/64 loss: 0.3201531171798706
Batch 7/64 loss: 0.31655412912368774
Batch 8/64 loss: 0.30824339389801025
Batch 9/64 loss: 0.3116353154182434
Batch 10/64 loss: 0.31533342599868774
Batch 11/64 loss: 0.3101222515106201
Batch 12/64 loss: 0.3148064613342285
Batch 13/64 loss: 0.31314170360565186
Batch 14/64 loss: 0.31535208225250244
Batch 15/64 loss: 0.3118489384651184
Batch 16/64 loss: 0.3146623969078064
Batch 17/64 loss: 0.3157181739807129
Batch 18/64 loss: 0.31706273555755615
Batch 19/64 loss: 0.3187880516052246
Batch 20/64 loss: 0.313320517539978
Batch 21/64 loss: 0.3192301392555237
Batch 22/64 loss: 0.3090181350708008
Batch 23/64 loss: 0.31372350454330444
Batch 24/64 loss: 0.31060516834259033
Batch 25/64 loss: 0.3081423044204712
Batch 26/64 loss: 0.3113212585449219
Batch 27/64 loss: 0.3121154308319092
Batch 28/64 loss: 0.3157370686531067
Batch 29/64 loss: 0.31027883291244507
Batch 30/64 loss: 0.31796568632125854
Batch 31/64 loss: 0.3185993432998657
Batch 32/64 loss: 0.30556076765060425
Batch 33/64 loss: 0.31591475009918213
Batch 34/64 loss: 0.3143424391746521
Batch 35/64 loss: 0.3111313581466675
Batch 36/64 loss: 0.31504058837890625
Batch 37/64 loss: 0.3091784715652466
Batch 38/64 loss: 0.3154183626174927
Batch 39/64 loss: 0.31657665967941284
Batch 40/64 loss: 0.31153833866119385
Batch 41/64 loss: 0.3110002279281616
Batch 42/64 loss: 0.3089989423751831
Batch 43/64 loss: 0.31651973724365234
Batch 44/64 loss: 0.30931299924850464
Batch 45/64 loss: 0.3112531900405884
Batch 46/64 loss: 0.31501322984695435
Batch 47/64 loss: 0.3151366710662842
Batch 48/64 loss: 0.309894859790802
Batch 49/64 loss: 0.3093595504760742
Batch 50/64 loss: 0.3083764314651489
Batch 51/64 loss: 0.31321895122528076
Batch 52/64 loss: 0.3114040493965149
Batch 53/64 loss: 0.3144763708114624
Batch 54/64 loss: 0.31498515605926514
Batch 55/64 loss: 0.30762070417404175
Batch 56/64 loss: 0.31236040592193604
Batch 57/64 loss: 0.316963791847229
Batch 58/64 loss: 0.3197002410888672
Batch 59/64 loss: 0.31003624200820923
Batch 60/64 loss: 0.3036898374557495
Batch 61/64 loss: 0.3059256076812744
Batch 62/64 loss: 0.31725645065307617
Batch 63/64 loss: 0.3121674060821533
Batch 64/64 loss: 0.31388723850250244
Epoch 332  Train loss: 0.31273145441915473  Val loss: 0.33576180250783966
Epoch 333
-------------------------------
Batch 1/64 loss: 0.3123990297317505
Batch 2/64 loss: 0.3080559968948364
Batch 3/64 loss: 0.30830490589141846
Batch 4/64 loss: 0.3181600570678711
Batch 5/64 loss: 0.3139317035675049
Batch 6/64 loss: 0.3165348172187805
Batch 7/64 loss: 0.3196520209312439
Batch 8/64 loss: 0.30665361881256104
Batch 9/64 loss: 0.3115260601043701
Batch 10/64 loss: 0.3167368173599243
Batch 11/64 loss: 0.3121432065963745
Batch 12/64 loss: 0.2976284623146057
Batch 13/64 loss: 0.31316208839416504
Batch 14/64 loss: 0.3176649808883667
Batch 15/64 loss: 0.3064800500869751
Batch 16/64 loss: 0.3145965337753296
Batch 17/64 loss: 0.30686527490615845
Batch 18/64 loss: 0.3114217519760132
Batch 19/64 loss: 0.30958807468414307
Batch 20/64 loss: 0.3166968822479248
Batch 21/64 loss: 0.30985116958618164
Batch 22/64 loss: 0.31394994258880615
Batch 23/64 loss: 0.31275928020477295
Batch 24/64 loss: 0.31988704204559326
Batch 25/64 loss: 0.3085782527923584
Batch 26/64 loss: 0.31402909755706787
Batch 27/64 loss: 0.3096020817756653
Batch 28/64 loss: 0.3217204809188843
Batch 29/64 loss: 0.3045453429222107
Batch 30/64 loss: 0.3111457824707031
Batch 31/64 loss: 0.32097315788269043
Batch 32/64 loss: 0.3155355453491211
Batch 33/64 loss: 0.3101329207420349
Batch 34/64 loss: 0.3124523162841797
Batch 35/64 loss: 0.3173929452896118
Batch 36/64 loss: 0.31055277585983276
Batch 37/64 loss: 0.3182629346847534
Batch 38/64 loss: 0.3085644245147705
Batch 39/64 loss: 0.30580687522888184
Batch 40/64 loss: 0.3119494915008545
Batch 41/64 loss: 0.3115823268890381
Batch 42/64 loss: 0.32627296447753906
Batch 43/64 loss: 0.30986475944519043
Batch 44/64 loss: 0.3173186182975769
Batch 45/64 loss: 0.3193973898887634
Batch 46/64 loss: 0.31701815128326416
Batch 47/64 loss: 0.319053590297699
Batch 48/64 loss: 0.3263353705406189
Batch 49/64 loss: 0.31015729904174805
Batch 50/64 loss: 0.31685322523117065
Batch 51/64 loss: 0.31631457805633545
Batch 52/64 loss: 0.312701940536499
Batch 53/64 loss: 0.31425708532333374
Batch 54/64 loss: 0.3071255683898926
Batch 55/64 loss: 0.3187113404273987
Batch 56/64 loss: 0.29895490407943726
Batch 57/64 loss: 0.3069852590560913
Batch 58/64 loss: 0.3197981119155884
Batch 59/64 loss: 0.30964136123657227
Batch 60/64 loss: 0.3003319501876831
Batch 61/64 loss: 0.3129539489746094
Batch 62/64 loss: 0.31060099601745605
Batch 63/64 loss: 0.3214758038520813
Batch 64/64 loss: 0.31799739599227905
Epoch 333  Train loss: 0.31306821622100534  Val loss: 0.3349915214420594
Epoch 334
-------------------------------
Batch 1/64 loss: 0.31290721893310547
Batch 2/64 loss: 0.30251526832580566
Batch 3/64 loss: 0.3161534070968628
Batch 4/64 loss: 0.3084501028060913
Batch 5/64 loss: 0.30963134765625
Batch 6/64 loss: 0.31890255212783813
Batch 7/64 loss: 0.3193376660346985
Batch 8/64 loss: 0.3109182119369507
Batch 9/64 loss: 0.31485676765441895
Batch 10/64 loss: 0.31247395277023315
Batch 11/64 loss: 0.30449211597442627
Batch 12/64 loss: 0.3109363317489624
Batch 13/64 loss: 0.31179285049438477
Batch 14/64 loss: 0.3157830834388733
Batch 15/64 loss: 0.31458771228790283
Batch 16/64 loss: 0.31498634815216064
Batch 17/64 loss: 0.3069688081741333
Batch 18/64 loss: 0.31234484910964966
Batch 19/64 loss: 0.3083549737930298
Batch 20/64 loss: 0.31673282384872437
Batch 21/64 loss: 0.3055002689361572
Batch 22/64 loss: 0.3136831521987915
Batch 23/64 loss: 0.3112261891365051
Batch 24/64 loss: 0.30730998516082764
Batch 25/64 loss: 0.302578330039978
Batch 26/64 loss: 0.302388072013855
Batch 27/64 loss: 0.3151472210884094
Batch 28/64 loss: 0.32069480419158936
Batch 29/64 loss: 0.3117848038673401
Batch 30/64 loss: 0.3128970265388489
Batch 31/64 loss: 0.3153407573699951
Batch 32/64 loss: 0.30928683280944824
Batch 33/64 loss: 0.3056410551071167
Batch 34/64 loss: 0.30524951219558716
Batch 35/64 loss: 0.3163048028945923
Batch 36/64 loss: 0.3047538995742798
Batch 37/64 loss: 0.31953591108322144
Batch 38/64 loss: 0.3203747868537903
Batch 39/64 loss: 0.3216472864151001
Batch 40/64 loss: 0.31642723083496094
Batch 41/64 loss: 0.3091694116592407
Batch 42/64 loss: 0.3160034418106079
Batch 43/64 loss: 0.3146200180053711
Batch 44/64 loss: 0.3073776960372925
Batch 45/64 loss: 0.3240622282028198
Batch 46/64 loss: 0.3189605474472046
Batch 47/64 loss: 0.3159058094024658
Batch 48/64 loss: 0.3024812936782837
Batch 49/64 loss: 0.31867122650146484
Batch 50/64 loss: 0.31521403789520264
Batch 51/64 loss: 0.3078131079673767
Batch 52/64 loss: 0.3259127736091614
Batch 53/64 loss: 0.3117058277130127
Batch 54/64 loss: 0.3074326515197754
Batch 55/64 loss: 0.32069963216781616
Batch 56/64 loss: 0.3161168098449707
Batch 57/64 loss: 0.31172817945480347
Batch 58/64 loss: 0.31648123264312744
Batch 59/64 loss: 0.3087976574897766
Batch 60/64 loss: 0.3142859935760498
Batch 61/64 loss: 0.30484986305236816
Batch 62/64 loss: 0.31830930709838867
Batch 63/64 loss: 0.31082189083099365
Batch 64/64 loss: 0.3115466833114624
Epoch 334  Train loss: 0.31265849365907555  Val loss: 0.3349061692293567
Epoch 335
-------------------------------
Batch 1/64 loss: 0.3169870376586914
Batch 2/64 loss: 0.31384456157684326
Batch 3/64 loss: 0.30788344144821167
Batch 4/64 loss: 0.31284773349761963
Batch 5/64 loss: 0.31440412998199463
Batch 6/64 loss: 0.30909812450408936
Batch 7/64 loss: 0.30684638023376465
Batch 8/64 loss: 0.30776095390319824
Batch 9/64 loss: 0.3146606683731079
Batch 10/64 loss: 0.30895280838012695
Batch 11/64 loss: 0.3078322410583496
Batch 12/64 loss: 0.30582576990127563
Batch 13/64 loss: 0.3032621145248413
Batch 14/64 loss: 0.316448450088501
Batch 15/64 loss: 0.31798601150512695
Batch 16/64 loss: 0.30465686321258545
Batch 17/64 loss: 0.3183025121688843
Batch 18/64 loss: 0.31916195154190063
Batch 19/64 loss: 0.3190399408340454
Batch 20/64 loss: 0.3106006383895874
Batch 21/64 loss: 0.3121769428253174
Batch 22/64 loss: 0.317623496055603
Batch 23/64 loss: 0.3105506896972656
Batch 24/64 loss: 0.30465883016586304
Batch 25/64 loss: 0.32076364755630493
Batch 26/64 loss: 0.3104027509689331
Batch 27/64 loss: 0.310560405254364
Batch 28/64 loss: 0.3012860417366028
Batch 29/64 loss: 0.30392730236053467
Batch 30/64 loss: 0.3163570761680603
Batch 31/64 loss: 0.3176063299179077
Batch 32/64 loss: 0.31022143363952637
Batch 33/64 loss: 0.32320261001586914
Batch 34/64 loss: 0.3181517720222473
Batch 35/64 loss: 0.3178912401199341
Batch 36/64 loss: 0.3144683837890625
Batch 37/64 loss: 0.3158470392227173
Batch 38/64 loss: 0.3165258765220642
Batch 39/64 loss: 0.3129599094390869
Batch 40/64 loss: 0.31045496463775635
Batch 41/64 loss: 0.3112586736679077
Batch 42/64 loss: 0.31348299980163574
Batch 43/64 loss: 0.3090970516204834
Batch 44/64 loss: 0.30539411306381226
Batch 45/64 loss: 0.31101012229919434
Batch 46/64 loss: 0.32007747888565063
Batch 47/64 loss: 0.31541740894317627
Batch 48/64 loss: 0.3191724419593811
Batch 49/64 loss: 0.3107762932777405
Batch 50/64 loss: 0.30589473247528076
Batch 51/64 loss: 0.30890172719955444
Batch 52/64 loss: 0.3133510947227478
Batch 53/64 loss: 0.3199928402900696
Batch 54/64 loss: 0.3087199926376343
Batch 55/64 loss: 0.31256139278411865
Batch 56/64 loss: 0.3116873502731323
Batch 57/64 loss: 0.30494046211242676
Batch 58/64 loss: 0.3110012412071228
Batch 59/64 loss: 0.31550294160842896
Batch 60/64 loss: 0.3079262375831604
Batch 61/64 loss: 0.3050554394721985
Batch 62/64 loss: 0.3186509609222412
Batch 63/64 loss: 0.31252723932266235
Batch 64/64 loss: 0.31764715909957886
Epoch 335  Train loss: 0.31235568126042684  Val loss: 0.33491092776924475
Epoch 336
-------------------------------
Batch 1/64 loss: 0.3128941059112549
Batch 2/64 loss: 0.3108222484588623
Batch 3/64 loss: 0.30367445945739746
Batch 4/64 loss: 0.30438053607940674
Batch 5/64 loss: 0.30869537591934204
Batch 6/64 loss: 0.3043845295906067
Batch 7/64 loss: 0.30756670236587524
Batch 8/64 loss: 0.3161502480506897
Batch 9/64 loss: 0.3106999397277832
Batch 10/64 loss: 0.3192235827445984
Batch 11/64 loss: 0.3088049292564392
Batch 12/64 loss: 0.31172704696655273
Batch 13/64 loss: 0.3114331364631653
Batch 14/64 loss: 0.31423431634902954
Batch 15/64 loss: 0.310805082321167
Batch 16/64 loss: 0.3090043067932129
Batch 17/64 loss: 0.30748456716537476
Batch 18/64 loss: 0.30981123447418213
Batch 19/64 loss: 0.3032921552658081
Batch 20/64 loss: 0.3092454671859741
Batch 21/64 loss: 0.31037139892578125
Batch 22/64 loss: 0.3212432861328125
Batch 23/64 loss: 0.30439329147338867
Batch 24/64 loss: 0.32010984420776367
Batch 25/64 loss: 0.30694520473480225
Batch 26/64 loss: 0.3162931203842163
Batch 27/64 loss: 0.311681866645813
Batch 28/64 loss: 0.3116263151168823
Batch 29/64 loss: 0.3082238435745239
Batch 30/64 loss: 0.3113515377044678
Batch 31/64 loss: 0.32171130180358887
Batch 32/64 loss: 0.31431156396865845
Batch 33/64 loss: 0.31770747900009155
Batch 34/64 loss: 0.3170909285545349
Batch 35/64 loss: 0.313671350479126
Batch 36/64 loss: 0.3116506338119507
Batch 37/64 loss: 0.30724209547042847
Batch 38/64 loss: 0.30944931507110596
Batch 39/64 loss: 0.3222649097442627
Batch 40/64 loss: 0.32596731185913086
Batch 41/64 loss: 0.3170016407966614
Batch 42/64 loss: 0.3148014545440674
Batch 43/64 loss: 0.3151623606681824
Batch 44/64 loss: 0.3105134963989258
Batch 45/64 loss: 0.3097437024116516
Batch 46/64 loss: 0.3092283606529236
Batch 47/64 loss: 0.3142538070678711
Batch 48/64 loss: 0.31349891424179077
Batch 49/64 loss: 0.3187286853790283
Batch 50/64 loss: 0.32099467515945435
Batch 51/64 loss: 0.31550025939941406
Batch 52/64 loss: 0.30706870555877686
Batch 53/64 loss: 0.3098670244216919
Batch 54/64 loss: 0.31100380420684814
Batch 55/64 loss: 0.31145358085632324
Batch 56/64 loss: 0.319787859916687
Batch 57/64 loss: 0.3259057402610779
Batch 58/64 loss: 0.3127148151397705
Batch 59/64 loss: 0.3061062693595886
Batch 60/64 loss: 0.3066384792327881
Batch 61/64 loss: 0.31029748916625977
Batch 62/64 loss: 0.3108001947402954
Batch 63/64 loss: 0.3132615089416504
Batch 64/64 loss: 0.30474036931991577
Epoch 336  Train loss: 0.31232201842700735  Val loss: 0.3349353029965535
Epoch 337
-------------------------------
Batch 1/64 loss: 0.3149007558822632
Batch 2/64 loss: 0.3101077079772949
Batch 3/64 loss: 0.30141711235046387
Batch 4/64 loss: 0.3167511224746704
Batch 5/64 loss: 0.3162180185317993
Batch 6/64 loss: 0.32038646936416626
Batch 7/64 loss: 0.31458330154418945
Batch 8/64 loss: 0.3041670322418213
Batch 9/64 loss: 0.31728899478912354
Batch 10/64 loss: 0.3136577606201172
Batch 11/64 loss: 0.30483198165893555
Batch 12/64 loss: 0.3158320188522339
Batch 13/64 loss: 0.3175532817840576
Batch 14/64 loss: 0.32056230306625366
Batch 15/64 loss: 0.30738282203674316
Batch 16/64 loss: 0.3065221309661865
Batch 17/64 loss: 0.3115714192390442
Batch 18/64 loss: 0.3176282048225403
Batch 19/64 loss: 0.31136518716812134
Batch 20/64 loss: 0.30858170986175537
Batch 21/64 loss: 0.31536030769348145
Batch 22/64 loss: 0.3105893135070801
Batch 23/64 loss: 0.3147583603858948
Batch 24/64 loss: 0.31055474281311035
Batch 25/64 loss: 0.307087242603302
Batch 26/64 loss: 0.3073515295982361
Batch 27/64 loss: 0.31844770908355713
Batch 28/64 loss: 0.3242201805114746
Batch 29/64 loss: 0.31159424781799316
Batch 30/64 loss: 0.3152029514312744
Batch 31/64 loss: 0.3115497827529907
Batch 32/64 loss: 0.31036192178726196
Batch 33/64 loss: 0.30631786584854126
Batch 34/64 loss: 0.31410884857177734
Batch 35/64 loss: 0.3145080804824829
Batch 36/64 loss: 0.3135603666305542
Batch 37/64 loss: 0.31971514225006104
Batch 38/64 loss: 0.305747926235199
Batch 39/64 loss: 0.31583172082901
Batch 40/64 loss: 0.31076115369796753
Batch 41/64 loss: 0.3202834725379944
Batch 42/64 loss: 0.3069254159927368
Batch 43/64 loss: 0.31417691707611084
Batch 44/64 loss: 0.3092641830444336
Batch 45/64 loss: 0.3210849165916443
Batch 46/64 loss: 0.3095031976699829
Batch 47/64 loss: 0.32479727268218994
Batch 48/64 loss: 0.3108842372894287
Batch 49/64 loss: 0.3024834394454956
Batch 50/64 loss: 0.3097558617591858
Batch 51/64 loss: 0.30019623041152954
Batch 52/64 loss: 0.3153160810470581
Batch 53/64 loss: 0.3172495365142822
Batch 54/64 loss: 0.31511569023132324
Batch 55/64 loss: 0.3092408776283264
Batch 56/64 loss: 0.30755698680877686
Batch 57/64 loss: 0.310661256313324
Batch 58/64 loss: 0.31126493215560913
Batch 59/64 loss: 0.32017529010772705
Batch 60/64 loss: 0.3197070360183716
Batch 61/64 loss: 0.30359894037246704
Batch 62/64 loss: 0.31587648391723633
Batch 63/64 loss: 0.3138906955718994
Batch 64/64 loss: 0.31129592657089233
Epoch 337  Train loss: 0.3126497196216209  Val loss: 0.3344338689882731
Epoch 338
-------------------------------
Batch 1/64 loss: 0.3080930709838867
Batch 2/64 loss: 0.3235924243927002
Batch 3/64 loss: 0.316281259059906
Batch 4/64 loss: 0.3031163215637207
Batch 5/64 loss: 0.30794578790664673
Batch 6/64 loss: 0.31613975763320923
Batch 7/64 loss: 0.30723875761032104
Batch 8/64 loss: 0.31718385219573975
Batch 9/64 loss: 0.3132515549659729
Batch 10/64 loss: 0.31937092542648315
Batch 11/64 loss: 0.3024507164955139
Batch 12/64 loss: 0.3081096410751343
Batch 13/64 loss: 0.308200478553772
Batch 14/64 loss: 0.3106950521469116
Batch 15/64 loss: 0.31953221559524536
Batch 16/64 loss: 0.31321191787719727
Batch 17/64 loss: 0.31209123134613037
Batch 18/64 loss: 0.3181261420249939
Batch 19/64 loss: 0.3140397071838379
Batch 20/64 loss: 0.3142580986022949
Batch 21/64 loss: 0.3117944002151489
Batch 22/64 loss: 0.310552716255188
Batch 23/64 loss: 0.316555917263031
Batch 24/64 loss: 0.3034890294075012
Batch 25/64 loss: 0.31902599334716797
Batch 26/64 loss: 0.3140910863876343
Batch 27/64 loss: 0.3236702084541321
Batch 28/64 loss: 0.3088796138763428
Batch 29/64 loss: 0.3192199468612671
Batch 30/64 loss: 0.3131561279296875
Batch 31/64 loss: 0.309867262840271
Batch 32/64 loss: 0.31565946340560913
Batch 33/64 loss: 0.30684560537338257
Batch 34/64 loss: 0.3130255937576294
Batch 35/64 loss: 0.32250165939331055
Batch 36/64 loss: 0.3213260769844055
Batch 37/64 loss: 0.30599188804626465
Batch 38/64 loss: 0.31126582622528076
Batch 39/64 loss: 0.3101236820220947
Batch 40/64 loss: 0.303891658782959
Batch 41/64 loss: 0.31096315383911133
Batch 42/64 loss: 0.30649709701538086
Batch 43/64 loss: 0.31778842210769653
Batch 44/64 loss: 0.3071444034576416
Batch 45/64 loss: 0.3035174608230591
Batch 46/64 loss: 0.31028908491134644
Batch 47/64 loss: 0.3018529415130615
Batch 48/64 loss: 0.3134461045265198
Batch 49/64 loss: 0.30495673418045044
Batch 50/64 loss: 0.3041868209838867
Batch 51/64 loss: 0.31274718046188354
Batch 52/64 loss: 0.31570470333099365
Batch 53/64 loss: 0.30782485008239746
Batch 54/64 loss: 0.31642377376556396
Batch 55/64 loss: 0.3186451196670532
Batch 56/64 loss: 0.30447137355804443
Batch 57/64 loss: 0.299585223197937
Batch 58/64 loss: 0.3236388564109802
Batch 59/64 loss: 0.311967134475708
Batch 60/64 loss: 0.3146994709968567
Batch 61/64 loss: 0.30735671520233154
Batch 62/64 loss: 0.321882963180542
Batch 63/64 loss: 0.32169848680496216
Batch 64/64 loss: 0.3051643967628479
Epoch 338  Train loss: 0.3121572398671917  Val loss: 0.33603258886697773
Epoch 339
-------------------------------
Batch 1/64 loss: 0.3062281608581543
Batch 2/64 loss: 0.31355351209640503
Batch 3/64 loss: 0.31865859031677246
Batch 4/64 loss: 0.3113367557525635
Batch 5/64 loss: 0.31818801164627075
Batch 6/64 loss: 0.3204139471054077
Batch 7/64 loss: 0.30686354637145996
Batch 8/64 loss: 0.319815993309021
Batch 9/64 loss: 0.313141405582428
Batch 10/64 loss: 0.3080129027366638
Batch 11/64 loss: 0.31330281496047974
Batch 12/64 loss: 0.32008910179138184
Batch 13/64 loss: 0.3222365975379944
Batch 14/64 loss: 0.3168478012084961
Batch 15/64 loss: 0.31912171840667725
Batch 16/64 loss: 0.3097952604293823
Batch 17/64 loss: 0.3025318384170532
Batch 18/64 loss: 0.31182944774627686
Batch 19/64 loss: 0.3083237409591675
Batch 20/64 loss: 0.31334710121154785
Batch 21/64 loss: 0.30138474702835083
Batch 22/64 loss: 0.3032273054122925
Batch 23/64 loss: 0.3061387538909912
Batch 24/64 loss: 0.3196525573730469
Batch 25/64 loss: 0.31954824924468994
Batch 26/64 loss: 0.3119580149650574
Batch 27/64 loss: 0.31718116998672485
Batch 28/64 loss: 0.29843175411224365
Batch 29/64 loss: 0.31733131408691406
Batch 30/64 loss: 0.3112645745277405
Batch 31/64 loss: 0.3195056915283203
Batch 32/64 loss: 0.3056880235671997
Batch 33/64 loss: 0.31597840785980225
Batch 34/64 loss: 0.30457592010498047
Batch 35/64 loss: 0.31655561923980713
Batch 36/64 loss: 0.3175966143608093
Batch 37/64 loss: 0.3142002820968628
Batch 38/64 loss: 0.31519830226898193
Batch 39/64 loss: 0.3144116997718811
Batch 40/64 loss: 0.3271310329437256
Batch 41/64 loss: 0.31057488918304443
Batch 42/64 loss: 0.31182438135147095
Batch 43/64 loss: 0.3079599142074585
Batch 44/64 loss: 0.3133450746536255
Batch 45/64 loss: 0.3207852840423584
Batch 46/64 loss: 0.30241715908050537
Batch 47/64 loss: 0.303122341632843
Batch 48/64 loss: 0.3162252902984619
Batch 49/64 loss: 0.3098571300506592
Batch 50/64 loss: 0.30529725551605225
Batch 51/64 loss: 0.310052752494812
Batch 52/64 loss: 0.30985361337661743
Batch 53/64 loss: 0.30546218156814575
Batch 54/64 loss: 0.30680787563323975
Batch 55/64 loss: 0.3100459575653076
Batch 56/64 loss: 0.30696016550064087
Batch 57/64 loss: 0.30765652656555176
Batch 58/64 loss: 0.30560606718063354
Batch 59/64 loss: 0.31312841176986694
Batch 60/64 loss: 0.3143264055252075
Batch 61/64 loss: 0.3130532503128052
Batch 62/64 loss: 0.3108937740325928
Batch 63/64 loss: 0.31610041856765747
Batch 64/64 loss: 0.3116704225540161
Epoch 339  Train loss: 0.31208952501708387  Val loss: 0.33488286790978866
Epoch 340
-------------------------------
Batch 1/64 loss: 0.31512731313705444
Batch 2/64 loss: 0.3062574863433838
Batch 3/64 loss: 0.3144158124923706
Batch 4/64 loss: 0.3136534094810486
Batch 5/64 loss: 0.31345582008361816
Batch 6/64 loss: 0.31148427724838257
Batch 7/64 loss: 0.3128920793533325
Batch 8/64 loss: 0.31853920221328735
Batch 9/64 loss: 0.30497807264328003
Batch 10/64 loss: 0.3123890161514282
Batch 11/64 loss: 0.31169593334198
Batch 12/64 loss: 0.3129335641860962
Batch 13/64 loss: 0.3103216290473938
Batch 14/64 loss: 0.318720281124115
Batch 15/64 loss: 0.30921459197998047
Batch 16/64 loss: 0.3051031231880188
Batch 17/64 loss: 0.31771236658096313
Batch 18/64 loss: 0.31680959463119507
Batch 19/64 loss: 0.318295419216156
Batch 20/64 loss: 0.306643009185791
Batch 21/64 loss: 0.3131236433982849
Batch 22/64 loss: 0.3016853332519531
Batch 23/64 loss: 0.3097158670425415
Batch 24/64 loss: 0.31382715702056885
Batch 25/64 loss: 0.31552207469940186
Batch 26/64 loss: 0.3129456043243408
Batch 27/64 loss: 0.3089677095413208
Batch 28/64 loss: 0.31559038162231445
Batch 29/64 loss: 0.3131016492843628
Batch 30/64 loss: 0.3175944685935974
Batch 31/64 loss: 0.3094165325164795
Batch 32/64 loss: 0.31254225969314575
Batch 33/64 loss: 0.3096368908882141
Batch 34/64 loss: 0.3157510757446289
Batch 35/64 loss: 0.3084380626678467
Batch 36/64 loss: 0.3048139214515686
Batch 37/64 loss: 0.3117201328277588
Batch 38/64 loss: 0.31474918127059937
Batch 39/64 loss: 0.317166268825531
Batch 40/64 loss: 0.3015288710594177
Batch 41/64 loss: 0.30645954608917236
Batch 42/64 loss: 0.3080967664718628
Batch 43/64 loss: 0.3133677840232849
Batch 44/64 loss: 0.32246196269989014
Batch 45/64 loss: 0.30422288179397583
Batch 46/64 loss: 0.310547411441803
Batch 47/64 loss: 0.31505048274993896
Batch 48/64 loss: 0.315590500831604
Batch 49/64 loss: 0.3108387589454651
Batch 50/64 loss: 0.32018589973449707
Batch 51/64 loss: 0.3121548295021057
Batch 52/64 loss: 0.30799317359924316
Batch 53/64 loss: 0.3071668744087219
Batch 54/64 loss: 0.3088393807411194
Batch 55/64 loss: 0.30863749980926514
Batch 56/64 loss: 0.320462703704834
Batch 57/64 loss: 0.30460238456726074
Batch 58/64 loss: 0.30775535106658936
Batch 59/64 loss: 0.30009377002716064
Batch 60/64 loss: 0.30683112144470215
Batch 61/64 loss: 0.31143325567245483
Batch 62/64 loss: 0.31206631660461426
Batch 63/64 loss: 0.3266317844390869
Batch 64/64 loss: 0.31275469064712524
Epoch 340  Train loss: 0.31175742032481174  Val loss: 0.3339150416892009
Epoch 341
-------------------------------
Batch 1/64 loss: 0.3133434057235718
Batch 2/64 loss: 0.30923211574554443
Batch 3/64 loss: 0.307020902633667
Batch 4/64 loss: 0.3074103593826294
Batch 5/64 loss: 0.3107547163963318
Batch 6/64 loss: 0.3176814317703247
Batch 7/64 loss: 0.30102044343948364
Batch 8/64 loss: 0.3083634376525879
Batch 9/64 loss: 0.31667065620422363
Batch 10/64 loss: 0.3115682601928711
Batch 11/64 loss: 0.317108154296875
Batch 12/64 loss: 0.31977593898773193
Batch 13/64 loss: 0.3080112338066101
Batch 14/64 loss: 0.30418503284454346
Batch 15/64 loss: 0.30661553144454956
Batch 16/64 loss: 0.30527734756469727
Batch 17/64 loss: 0.3141688108444214
Batch 18/64 loss: 0.3080899715423584
Batch 19/64 loss: 0.3052452802658081
Batch 20/64 loss: 0.30746394395828247
Batch 21/64 loss: 0.31552380323410034
Batch 22/64 loss: 0.31471508741378784
Batch 23/64 loss: 0.31011962890625
Batch 24/64 loss: 0.3040553331375122
Batch 25/64 loss: 0.31680363416671753
Batch 26/64 loss: 0.31182587146759033
Batch 27/64 loss: 0.31806933879852295
Batch 28/64 loss: 0.321341872215271
Batch 29/64 loss: 0.3071674704551697
Batch 30/64 loss: 0.3152787685394287
Batch 31/64 loss: 0.30625808238983154
Batch 32/64 loss: 0.30871427059173584
Batch 33/64 loss: 0.3136446475982666
Batch 34/64 loss: 0.31592315435409546
Batch 35/64 loss: 0.3204055428504944
Batch 36/64 loss: 0.31109321117401123
Batch 37/64 loss: 0.317158043384552
Batch 38/64 loss: 0.31072908639907837
Batch 39/64 loss: 0.3129235506057739
Batch 40/64 loss: 0.3095940947532654
Batch 41/64 loss: 0.31698620319366455
Batch 42/64 loss: 0.3108018636703491
Batch 43/64 loss: 0.3105769157409668
Batch 44/64 loss: 0.31005704402923584
Batch 45/64 loss: 0.31492483615875244
Batch 46/64 loss: 0.31022387742996216
Batch 47/64 loss: 0.3108692169189453
Batch 48/64 loss: 0.31740880012512207
Batch 49/64 loss: 0.30851757526397705
Batch 50/64 loss: 0.31779587268829346
Batch 51/64 loss: 0.31885409355163574
Batch 52/64 loss: 0.31570351123809814
Batch 53/64 loss: 0.3164931535720825
Batch 54/64 loss: 0.31910502910614014
Batch 55/64 loss: 0.3126780390739441
Batch 56/64 loss: 0.3077763319015503
Batch 57/64 loss: 0.32333070039749146
Batch 58/64 loss: 0.30653971433639526
Batch 59/64 loss: 0.3050098419189453
Batch 60/64 loss: 0.3086034059524536
Batch 61/64 loss: 0.3197172284126282
Batch 62/64 loss: 0.30642569065093994
Batch 63/64 loss: 0.3146820664405823
Batch 64/64 loss: 0.3113105297088623
Epoch 341  Train loss: 0.312108476489198  Val loss: 0.33504809505751043
Epoch 342
-------------------------------
Batch 1/64 loss: 0.31288421154022217
Batch 2/64 loss: 0.31963682174682617
Batch 3/64 loss: 0.3105071783065796
Batch 4/64 loss: 0.3134922981262207
Batch 5/64 loss: 0.30544400215148926
Batch 6/64 loss: 0.3030748963356018
Batch 7/64 loss: 0.31464695930480957
Batch 8/64 loss: 0.31314677000045776
Batch 9/64 loss: 0.30193907022476196
Batch 10/64 loss: 0.3090771436691284
Batch 11/64 loss: 0.32262492179870605
Batch 12/64 loss: 0.31314271688461304
Batch 13/64 loss: 0.31054723262786865
Batch 14/64 loss: 0.3140525221824646
Batch 15/64 loss: 0.3152812719345093
Batch 16/64 loss: 0.31482213735580444
Batch 17/64 loss: 0.3086187243461609
Batch 18/64 loss: 0.3041136860847473
Batch 19/64 loss: 0.30474936962127686
Batch 20/64 loss: 0.30967313051223755
Batch 21/64 loss: 0.3280147910118103
Batch 22/64 loss: 0.3172576427459717
Batch 23/64 loss: 0.31317853927612305
Batch 24/64 loss: 0.3067325949668884
Batch 25/64 loss: 0.3114570379257202
Batch 26/64 loss: 0.3124678134918213
Batch 27/64 loss: 0.3098973035812378
Batch 28/64 loss: 0.31025195121765137
Batch 29/64 loss: 0.3117101192474365
Batch 30/64 loss: 0.3092060089111328
Batch 31/64 loss: 0.30902183055877686
Batch 32/64 loss: 0.3016180396080017
Batch 33/64 loss: 0.30810797214508057
Batch 34/64 loss: 0.3110343813896179
Batch 35/64 loss: 0.3064635992050171
Batch 36/64 loss: 0.31141138076782227
Batch 37/64 loss: 0.31168895959854126
Batch 38/64 loss: 0.31102877855300903
Batch 39/64 loss: 0.30855512619018555
Batch 40/64 loss: 0.308383047580719
Batch 41/64 loss: 0.3096487522125244
Batch 42/64 loss: 0.3158332109451294
Batch 43/64 loss: 0.31271445751190186
Batch 44/64 loss: 0.32214081287384033
Batch 45/64 loss: 0.3107425570487976
Batch 46/64 loss: 0.30779707431793213
Batch 47/64 loss: 0.3161296248435974
Batch 48/64 loss: 0.30661243200302124
Batch 49/64 loss: 0.3105384111404419
Batch 50/64 loss: 0.30944085121154785
Batch 51/64 loss: 0.3083378076553345
Batch 52/64 loss: 0.3086496591567993
Batch 53/64 loss: 0.3107374906539917
Batch 54/64 loss: 0.3160264492034912
Batch 55/64 loss: 0.31358802318573
Batch 56/64 loss: 0.3126944303512573
Batch 57/64 loss: 0.3137127757072449
Batch 58/64 loss: 0.3165016770362854
Batch 59/64 loss: 0.31311655044555664
Batch 60/64 loss: 0.3105098009109497
Batch 61/64 loss: 0.3214671015739441
Batch 62/64 loss: 0.322706937789917
Batch 63/64 loss: 0.3160274028778076
Batch 64/64 loss: 0.31477880477905273
Epoch 342  Train loss: 0.31185443728577855  Val loss: 0.33463741844052713
Epoch 343
-------------------------------
Batch 1/64 loss: 0.3089320659637451
Batch 2/64 loss: 0.2975778579711914
Batch 3/64 loss: 0.3052290678024292
Batch 4/64 loss: 0.3106626272201538
Batch 5/64 loss: 0.3013783097267151
Batch 6/64 loss: 0.3142201900482178
Batch 7/64 loss: 0.31647974252700806
Batch 8/64 loss: 0.31396985054016113
Batch 9/64 loss: 0.31212079524993896
Batch 10/64 loss: 0.30892837047576904
Batch 11/64 loss: 0.3129879832267761
Batch 12/64 loss: 0.3140367269515991
Batch 13/64 loss: 0.3114898204803467
Batch 14/64 loss: 0.3254389762878418
Batch 15/64 loss: 0.31317079067230225
Batch 16/64 loss: 0.320658802986145
Batch 17/64 loss: 0.3073134422302246
Batch 18/64 loss: 0.3066118359565735
Batch 19/64 loss: 0.31861889362335205
Batch 20/64 loss: 0.3136688470840454
Batch 21/64 loss: 0.3061666488647461
Batch 22/64 loss: 0.3056154251098633
Batch 23/64 loss: 0.3137667775154114
Batch 24/64 loss: 0.3131333589553833
Batch 25/64 loss: 0.31933581829071045
Batch 26/64 loss: 0.31236743927001953
Batch 27/64 loss: 0.30691754817962646
Batch 28/64 loss: 0.3115720748901367
Batch 29/64 loss: 0.3036307096481323
Batch 30/64 loss: 0.3158420920372009
Batch 31/64 loss: 0.32491207122802734
Batch 32/64 loss: 0.30837535858154297
Batch 33/64 loss: 0.3141477704048157
Batch 34/64 loss: 0.31276100873947144
Batch 35/64 loss: 0.31499648094177246
Batch 36/64 loss: 0.3110389709472656
Batch 37/64 loss: 0.3129402995109558
Batch 38/64 loss: 0.3134758472442627
Batch 39/64 loss: 0.3042464256286621
Batch 40/64 loss: 0.31155216693878174
Batch 41/64 loss: 0.31711840629577637
Batch 42/64 loss: 0.3082500100135803
Batch 43/64 loss: 0.31254255771636963
Batch 44/64 loss: 0.3120136260986328
Batch 45/64 loss: 0.3169012665748596
Batch 46/64 loss: 0.31855309009552
Batch 47/64 loss: 0.31720948219299316
Batch 48/64 loss: 0.3106670379638672
Batch 49/64 loss: 0.30664753913879395
Batch 50/64 loss: 0.31894075870513916
Batch 51/64 loss: 0.30461692810058594
Batch 52/64 loss: 0.3154318332672119
Batch 53/64 loss: 0.31717121601104736
Batch 54/64 loss: 0.3019534945487976
Batch 55/64 loss: 0.3100471496582031
Batch 56/64 loss: 0.3090876340866089
Batch 57/64 loss: 0.3179527521133423
Batch 58/64 loss: 0.31299012899398804
Batch 59/64 loss: 0.3131442070007324
Batch 60/64 loss: 0.30965912342071533
Batch 61/64 loss: 0.31252485513687134
Batch 62/64 loss: 0.3194134831428528
Batch 63/64 loss: 0.30249834060668945
Batch 64/64 loss: 0.309916615486145
Epoch 343  Train loss: 0.31196959486194686  Val loss: 0.33421625365915986
Epoch 344
-------------------------------
Batch 1/64 loss: 0.3002428412437439
Batch 2/64 loss: 0.3265237808227539
Batch 3/64 loss: 0.30449819564819336
Batch 4/64 loss: 0.3078329563140869
Batch 5/64 loss: 0.3067295551300049
Batch 6/64 loss: 0.3027360439300537
Batch 7/64 loss: 0.3074296712875366
Batch 8/64 loss: 0.3242911100387573
Batch 9/64 loss: 0.3197530508041382
Batch 10/64 loss: 0.30380427837371826
Batch 11/64 loss: 0.306624174118042
Batch 12/64 loss: 0.3160894513130188
Batch 13/64 loss: 0.30766814947128296
Batch 14/64 loss: 0.3009340167045593
Batch 15/64 loss: 0.3055177927017212
Batch 16/64 loss: 0.315915584564209
Batch 17/64 loss: 0.30886876583099365
Batch 18/64 loss: 0.3175313472747803
Batch 19/64 loss: 0.3149457573890686
Batch 20/64 loss: 0.3114970922470093
Batch 21/64 loss: 0.3127845525741577
Batch 22/64 loss: 0.3104124069213867
Batch 23/64 loss: 0.3079238533973694
Batch 24/64 loss: 0.30510687828063965
Batch 25/64 loss: 0.3098129630088806
Batch 26/64 loss: 0.30792665481567383
Batch 27/64 loss: 0.31261879205703735
Batch 28/64 loss: 0.30915749073028564
Batch 29/64 loss: 0.30889391899108887
Batch 30/64 loss: 0.3162216544151306
Batch 31/64 loss: 0.3144029378890991
Batch 32/64 loss: 0.31428366899490356
Batch 33/64 loss: 0.31715118885040283
Batch 34/64 loss: 0.31275421380996704
Batch 35/64 loss: 0.30704396963119507
Batch 36/64 loss: 0.30918753147125244
Batch 37/64 loss: 0.3135182857513428
Batch 38/64 loss: 0.31714892387390137
Batch 39/64 loss: 0.3152501583099365
Batch 40/64 loss: 0.31270962953567505
Batch 41/64 loss: 0.311448335647583
Batch 42/64 loss: 0.3144301176071167
Batch 43/64 loss: 0.3078126311302185
Batch 44/64 loss: 0.3170473575592041
Batch 45/64 loss: 0.3184318542480469
Batch 46/64 loss: 0.3047853708267212
Batch 47/64 loss: 0.3168812394142151
Batch 48/64 loss: 0.3129656910896301
Batch 49/64 loss: 0.3027094602584839
Batch 50/64 loss: 0.3104020357131958
Batch 51/64 loss: 0.31106066703796387
Batch 52/64 loss: 0.3062160015106201
Batch 53/64 loss: 0.3122592568397522
Batch 54/64 loss: 0.3103143572807312
Batch 55/64 loss: 0.3128591775894165
Batch 56/64 loss: 0.311814546585083
Batch 57/64 loss: 0.31000030040740967
Batch 58/64 loss: 0.30987823009490967
Batch 59/64 loss: 0.31466323137283325
Batch 60/64 loss: 0.31152546405792236
Batch 61/64 loss: 0.30596792697906494
Batch 62/64 loss: 0.31616997718811035
Batch 63/64 loss: 0.3124481439590454
Batch 64/64 loss: 0.30956077575683594
Epoch 344  Train loss: 0.31118439599579456  Val loss: 0.33381744758369997
Epoch 345
-------------------------------
Batch 1/64 loss: 0.3086237907409668
Batch 2/64 loss: 0.3029547929763794
Batch 3/64 loss: 0.30317962169647217
Batch 4/64 loss: 0.31192541122436523
Batch 5/64 loss: 0.3119351863861084
Batch 6/64 loss: 0.3113071322441101
Batch 7/64 loss: 0.31216150522232056
Batch 8/64 loss: 0.30856651067733765
Batch 9/64 loss: 0.3076198697090149
Batch 10/64 loss: 0.31299567222595215
Batch 11/64 loss: 0.3067737817764282
Batch 12/64 loss: 0.3171984553337097
Batch 13/64 loss: 0.30320489406585693
Batch 14/64 loss: 0.3135525584220886
Batch 15/64 loss: 0.308204710483551
Batch 16/64 loss: 0.3184962272644043
Batch 17/64 loss: 0.30443787574768066
Batch 18/64 loss: 0.3091607093811035
Batch 19/64 loss: 0.3087024688720703
Batch 20/64 loss: 0.3072075843811035
Batch 21/64 loss: 0.3140643835067749
Batch 22/64 loss: 0.30606889724731445
Batch 23/64 loss: 0.31669992208480835
Batch 24/64 loss: 0.3102957010269165
Batch 25/64 loss: 0.3197396993637085
Batch 26/64 loss: 0.31288862228393555
Batch 27/64 loss: 0.3142211437225342
Batch 28/64 loss: 0.3047521114349365
Batch 29/64 loss: 0.3229077458381653
Batch 30/64 loss: 0.3119170665740967
Batch 31/64 loss: 0.31036221981048584
Batch 32/64 loss: 0.31137192249298096
Batch 33/64 loss: 0.3029158115386963
Batch 34/64 loss: 0.30969423055648804
Batch 35/64 loss: 0.31623804569244385
Batch 36/64 loss: 0.3198286294937134
Batch 37/64 loss: 0.31856030225753784
Batch 38/64 loss: 0.318382203578949
Batch 39/64 loss: 0.30503249168395996
Batch 40/64 loss: 0.30212193727493286
Batch 41/64 loss: 0.3076741099357605
Batch 42/64 loss: 0.3041685223579407
Batch 43/64 loss: 0.30924296379089355
Batch 44/64 loss: 0.30710315704345703
Batch 45/64 loss: 0.3112971782684326
Batch 46/64 loss: 0.30607450008392334
Batch 47/64 loss: 0.31585973501205444
Batch 48/64 loss: 0.3114192485809326
Batch 49/64 loss: 0.3150228261947632
Batch 50/64 loss: 0.31445395946502686
Batch 51/64 loss: 0.3157513737678528
Batch 52/64 loss: 0.32077884674072266
Batch 53/64 loss: 0.30914175510406494
Batch 54/64 loss: 0.31990766525268555
Batch 55/64 loss: 0.3264658451080322
Batch 56/64 loss: 0.30654627084732056
Batch 57/64 loss: 0.30884605646133423
Batch 58/64 loss: 0.32123732566833496
Batch 59/64 loss: 0.31073176860809326
Batch 60/64 loss: 0.3098876476287842
Batch 61/64 loss: 0.3107858896255493
Batch 62/64 loss: 0.3148115873336792
Batch 63/64 loss: 0.3126456141471863
Batch 64/64 loss: 0.32103902101516724
Epoch 345  Train loss: 0.31163772484835456  Val loss: 0.3357458212940963
Epoch 346
-------------------------------
Batch 1/64 loss: 0.30833446979522705
Batch 2/64 loss: 0.3148999810218811
Batch 3/64 loss: 0.3172786235809326
Batch 4/64 loss: 0.3175163269042969
Batch 5/64 loss: 0.31289243698120117
Batch 6/64 loss: 0.3085925579071045
Batch 7/64 loss: 0.30862581729888916
Batch 8/64 loss: 0.3136146068572998
Batch 9/64 loss: 0.30722248554229736
Batch 10/64 loss: 0.3082200884819031
Batch 11/64 loss: 0.3051145076751709
Batch 12/64 loss: 0.31244516372680664
Batch 13/64 loss: 0.31281840801239014
Batch 14/64 loss: 0.3083496689796448
Batch 15/64 loss: 0.31319689750671387
Batch 16/64 loss: 0.31857526302337646
Batch 17/64 loss: 0.31361210346221924
Batch 18/64 loss: 0.3130667209625244
Batch 19/64 loss: 0.3124544620513916
Batch 20/64 loss: 0.32126545906066895
Batch 21/64 loss: 0.3091968297958374
Batch 22/64 loss: 0.31548523902893066
Batch 23/64 loss: 0.31348395347595215
Batch 24/64 loss: 0.31638509035110474
Batch 25/64 loss: 0.3122742176055908
Batch 26/64 loss: 0.31388378143310547
Batch 27/64 loss: 0.32003653049468994
Batch 28/64 loss: 0.30375969409942627
Batch 29/64 loss: 0.3182602524757385
Batch 30/64 loss: 0.31812363862991333
Batch 31/64 loss: 0.3076658844947815
Batch 32/64 loss: 0.3091356158256531
Batch 33/64 loss: 0.3141510486602783
Batch 34/64 loss: 0.311415433883667
Batch 35/64 loss: 0.3061954975128174
Batch 36/64 loss: 0.30858904123306274
Batch 37/64 loss: 0.3119915723800659
Batch 38/64 loss: 0.3063821792602539
Batch 39/64 loss: 0.30909979343414307
Batch 40/64 loss: 0.31136542558670044
Batch 41/64 loss: 0.31153321266174316
Batch 42/64 loss: 0.31148695945739746
Batch 43/64 loss: 0.30264556407928467
Batch 44/64 loss: 0.31175416707992554
Batch 45/64 loss: 0.30978894233703613
Batch 46/64 loss: 0.3261345624923706
Batch 47/64 loss: 0.31365513801574707
Batch 48/64 loss: 0.3149724006652832
Batch 49/64 loss: 0.30904459953308105
Batch 50/64 loss: 0.3065974712371826
Batch 51/64 loss: 0.3154304623603821
Batch 52/64 loss: 0.3059161305427551
Batch 53/64 loss: 0.3093501925468445
Batch 54/64 loss: 0.3187987804412842
Batch 55/64 loss: 0.3152347803115845
Batch 56/64 loss: 0.30993038415908813
Batch 57/64 loss: 0.31364715099334717
Batch 58/64 loss: 0.31204932928085327
Batch 59/64 loss: 0.30859118700027466
Batch 60/64 loss: 0.3097262382507324
Batch 61/64 loss: 0.3075867295265198
Batch 62/64 loss: 0.30840039253234863
Batch 63/64 loss: 0.307155966758728
Batch 64/64 loss: 0.3121166229248047
Epoch 346  Train loss: 0.3118195290658988  Val loss: 0.3343799294475018
Epoch 347
-------------------------------
Batch 1/64 loss: 0.30345332622528076
Batch 2/64 loss: 0.31014955043792725
Batch 3/64 loss: 0.31733226776123047
Batch 4/64 loss: 0.3030635714530945
Batch 5/64 loss: 0.308709979057312
Batch 6/64 loss: 0.31108784675598145
Batch 7/64 loss: 0.3053300380706787
Batch 8/64 loss: 0.3043702244758606
Batch 9/64 loss: 0.3115679621696472
Batch 10/64 loss: 0.3138609528541565
Batch 11/64 loss: 0.30457383394241333
Batch 12/64 loss: 0.3117058277130127
Batch 13/64 loss: 0.311626672744751
Batch 14/64 loss: 0.32251572608947754
Batch 15/64 loss: 0.3122497797012329
Batch 16/64 loss: 0.3132622241973877
Batch 17/64 loss: 0.319250226020813
Batch 18/64 loss: 0.3142016530036926
Batch 19/64 loss: 0.31665468215942383
Batch 20/64 loss: 0.3127099275588989
Batch 21/64 loss: 0.3124634027481079
Batch 22/64 loss: 0.3189845085144043
Batch 23/64 loss: 0.30116772651672363
Batch 24/64 loss: 0.30781126022338867
Batch 25/64 loss: 0.30391454696655273
Batch 26/64 loss: 0.31802910566329956
Batch 27/64 loss: 0.31648433208465576
Batch 28/64 loss: 0.31602805852890015
Batch 29/64 loss: 0.31562572717666626
Batch 30/64 loss: 0.30589473247528076
Batch 31/64 loss: 0.2998541593551636
Batch 32/64 loss: 0.30577552318573
Batch 33/64 loss: 0.3121868968009949
Batch 34/64 loss: 0.31475377082824707
Batch 35/64 loss: 0.3072148561477661
Batch 36/64 loss: 0.30903512239456177
Batch 37/64 loss: 0.31396299600601196
Batch 38/64 loss: 0.30989259481430054
Batch 39/64 loss: 0.31403857469558716
Batch 40/64 loss: 0.311881422996521
Batch 41/64 loss: 0.312261700630188
Batch 42/64 loss: 0.31948649883270264
Batch 43/64 loss: 0.3146629333496094
Batch 44/64 loss: 0.30655938386917114
Batch 45/64 loss: 0.3108428716659546
Batch 46/64 loss: 0.3180314302444458
Batch 47/64 loss: 0.3089689016342163
Batch 48/64 loss: 0.31127578020095825
Batch 49/64 loss: 0.31128251552581787
Batch 50/64 loss: 0.30556291341781616
Batch 51/64 loss: 0.3088960647583008
Batch 52/64 loss: 0.30817246437072754
Batch 53/64 loss: 0.30393868684768677
Batch 54/64 loss: 0.3069196939468384
Batch 55/64 loss: 0.3096417188644409
Batch 56/64 loss: 0.307390034198761
Batch 57/64 loss: 0.3148423433303833
Batch 58/64 loss: 0.31449389457702637
Batch 59/64 loss: 0.3152998685836792
Batch 60/64 loss: 0.3172924518585205
Batch 61/64 loss: 0.30323201417922974
Batch 62/64 loss: 0.3052409887313843
Batch 63/64 loss: 0.3159503936767578
Batch 64/64 loss: 0.3079468011856079
Epoch 347  Train loss: 0.31096284295998367  Val loss: 0.3339308684634179
Epoch 348
-------------------------------
Batch 1/64 loss: 0.308119535446167
Batch 2/64 loss: 0.30155181884765625
Batch 3/64 loss: 0.3169442415237427
Batch 4/64 loss: 0.30618715286254883
Batch 5/64 loss: 0.3060866594314575
Batch 6/64 loss: 0.3081684708595276
Batch 7/64 loss: 0.316020131111145
Batch 8/64 loss: 0.31014299392700195
Batch 9/64 loss: 0.3118661046028137
Batch 10/64 loss: 0.30845582485198975
Batch 11/64 loss: 0.3084827661514282
Batch 12/64 loss: 0.3035582900047302
Batch 13/64 loss: 0.3102070093154907
Batch 14/64 loss: 0.3145560026168823
Batch 15/64 loss: 0.3154451847076416
Batch 16/64 loss: 0.30240142345428467
Batch 17/64 loss: 0.2995225191116333
Batch 18/64 loss: 0.3203749656677246
Batch 19/64 loss: 0.30151093006134033
Batch 20/64 loss: 0.31334102153778076
Batch 21/64 loss: 0.3111612796783447
Batch 22/64 loss: 0.30569517612457275
Batch 23/64 loss: 0.30640673637390137
Batch 24/64 loss: 0.3135472536087036
Batch 25/64 loss: 0.32403576374053955
Batch 26/64 loss: 0.30884337425231934
Batch 27/64 loss: 0.3068186044692993
Batch 28/64 loss: 0.3075176477432251
Batch 29/64 loss: 0.31780797243118286
Batch 30/64 loss: 0.3072303533554077
Batch 31/64 loss: 0.31613314151763916
Batch 32/64 loss: 0.307575523853302
Batch 33/64 loss: 0.31259459257125854
Batch 34/64 loss: 0.32643985748291016
Batch 35/64 loss: 0.31788545846939087
Batch 36/64 loss: 0.30935561656951904
Batch 37/64 loss: 0.3127751350402832
Batch 38/64 loss: 0.30633729696273804
Batch 39/64 loss: 0.32124000787734985
Batch 40/64 loss: 0.31004875898361206
Batch 41/64 loss: 0.3132438659667969
Batch 42/64 loss: 0.30539071559906006
Batch 43/64 loss: 0.31420159339904785
Batch 44/64 loss: 0.31041228771209717
Batch 45/64 loss: 0.3221878409385681
Batch 46/64 loss: 0.30998021364212036
Batch 47/64 loss: 0.31325453519821167
Batch 48/64 loss: 0.3125051259994507
Batch 49/64 loss: 0.31937551498413086
Batch 50/64 loss: 0.3149297833442688
Batch 51/64 loss: 0.30922365188598633
Batch 52/64 loss: 0.3113924264907837
Batch 53/64 loss: 0.31323814392089844
Batch 54/64 loss: 0.3076784610748291
Batch 55/64 loss: 0.311007559299469
Batch 56/64 loss: 0.3127857446670532
Batch 57/64 loss: 0.3171082139015198
Batch 58/64 loss: 0.3061510920524597
Batch 59/64 loss: 0.3148665428161621
Batch 60/64 loss: 0.3005290627479553
Batch 61/64 loss: 0.3032684326171875
Batch 62/64 loss: 0.3156660795211792
Batch 63/64 loss: 0.307661771774292
Batch 64/64 loss: 0.3096911907196045
Epoch 348  Train loss: 0.3110701121535956  Val loss: 0.3325721963574387
Saving best model, epoch: 348
Epoch 349
-------------------------------
Batch 1/64 loss: 0.31044626235961914
Batch 2/64 loss: 0.31294965744018555
Batch 3/64 loss: 0.318553626537323
Batch 4/64 loss: 0.3021951913833618
Batch 5/64 loss: 0.3023427724838257
Batch 6/64 loss: 0.3075016140937805
Batch 7/64 loss: 0.3125554919242859
Batch 8/64 loss: 0.3085287809371948
Batch 9/64 loss: 0.3153207302093506
Batch 10/64 loss: 0.31500351428985596
Batch 11/64 loss: 0.3120487332344055
Batch 12/64 loss: 0.30748051404953003
Batch 13/64 loss: 0.3120453357696533
Batch 14/64 loss: 0.3054279088973999
Batch 15/64 loss: 0.3061915636062622
Batch 16/64 loss: 0.309628427028656
Batch 17/64 loss: 0.3102530241012573
Batch 18/64 loss: 0.3126429319381714
Batch 19/64 loss: 0.31549203395843506
Batch 20/64 loss: 0.31740128993988037
Batch 21/64 loss: 0.312542200088501
Batch 22/64 loss: 0.3100060224533081
Batch 23/64 loss: 0.30911678075790405
Batch 24/64 loss: 0.31055182218551636
Batch 25/64 loss: 0.3155166506767273
Batch 26/64 loss: 0.316003680229187
Batch 27/64 loss: 0.31594347953796387
Batch 28/64 loss: 0.3035554885864258
Batch 29/64 loss: 0.32234907150268555
Batch 30/64 loss: 0.3135262727737427
Batch 31/64 loss: 0.3131200671195984
Batch 32/64 loss: 0.32141536474227905
Batch 33/64 loss: 0.3141726851463318
Batch 34/64 loss: 0.31213247776031494
Batch 35/64 loss: 0.3106464147567749
Batch 36/64 loss: 0.3086448907852173
Batch 37/64 loss: 0.3071656823158264
Batch 38/64 loss: 0.3078470230102539
Batch 39/64 loss: 0.30429208278656006
Batch 40/64 loss: 0.31403297185897827
Batch 41/64 loss: 0.3026634454727173
Batch 42/64 loss: 0.2981387972831726
Batch 43/64 loss: 0.3063545823097229
Batch 44/64 loss: 0.3129692077636719
Batch 45/64 loss: 0.3103090524673462
Batch 46/64 loss: 0.31626760959625244
Batch 47/64 loss: 0.3220323920249939
Batch 48/64 loss: 0.31227362155914307
Batch 49/64 loss: 0.30800527334213257
Batch 50/64 loss: 0.3181314468383789
Batch 51/64 loss: 0.31136322021484375
Batch 52/64 loss: 0.3101675510406494
Batch 53/64 loss: 0.29847586154937744
Batch 54/64 loss: 0.30794644355773926
Batch 55/64 loss: 0.31042224168777466
Batch 56/64 loss: 0.3097950220108032
Batch 57/64 loss: 0.31097090244293213
Batch 58/64 loss: 0.31370484828948975
Batch 59/64 loss: 0.30969464778900146
Batch 60/64 loss: 0.31443142890930176
Batch 61/64 loss: 0.3081437349319458
Batch 62/64 loss: 0.31609857082366943
Batch 63/64 loss: 0.3040429353713989
Batch 64/64 loss: 0.3082458972930908
Epoch 349  Train loss: 0.3109047497020048  Val loss: 0.3344118838867371
Epoch 350
-------------------------------
Batch 1/64 loss: 0.30547094345092773
Batch 2/64 loss: 0.32019519805908203
Batch 3/64 loss: 0.3172943592071533
Batch 4/64 loss: 0.3043556809425354
Batch 5/64 loss: 0.30881285667419434
Batch 6/64 loss: 0.3069164752960205
Batch 7/64 loss: 0.31276583671569824
Batch 8/64 loss: 0.30010974407196045
Batch 9/64 loss: 0.3069939613342285
Batch 10/64 loss: 0.310763418674469
Batch 11/64 loss: 0.3169071674346924
Batch 12/64 loss: 0.3176041841506958
Batch 13/64 loss: 0.307947039604187
Batch 14/64 loss: 0.30835777521133423
Batch 15/64 loss: 0.3049055337905884
Batch 16/64 loss: 0.3062683939933777
Batch 17/64 loss: 0.30188655853271484
Batch 18/64 loss: 0.3027501702308655
Batch 19/64 loss: 0.3045656085014343
Batch 20/64 loss: 0.31601572036743164
Batch 21/64 loss: 0.31468522548675537
Batch 22/64 loss: 0.3122960329055786
Batch 23/64 loss: 0.3153500556945801
Batch 24/64 loss: 0.3090577721595764
Batch 25/64 loss: 0.30750203132629395
Batch 26/64 loss: 0.31616437435150146
Batch 27/64 loss: 0.30552756786346436
Batch 28/64 loss: 0.3114534020423889
Batch 29/64 loss: 0.30743634700775146
Batch 30/64 loss: 0.3214271068572998
Batch 31/64 loss: 0.3158895969390869
Batch 32/64 loss: 0.3104276657104492
Batch 33/64 loss: 0.3141857981681824
Batch 34/64 loss: 0.3125300407409668
Batch 35/64 loss: 0.30318570137023926
Batch 36/64 loss: 0.312557578086853
Batch 37/64 loss: 0.3025932312011719
Batch 38/64 loss: 0.31740379333496094
Batch 39/64 loss: 0.3142507076263428
Batch 40/64 loss: 0.3140087127685547
Batch 41/64 loss: 0.3095996379852295
Batch 42/64 loss: 0.3211291432380676
Batch 43/64 loss: 0.3156147003173828
Batch 44/64 loss: 0.31031787395477295
Batch 45/64 loss: 0.3066350221633911
Batch 46/64 loss: 0.30486512184143066
Batch 47/64 loss: 0.315926730632782
Batch 48/64 loss: 0.30727672576904297
Batch 49/64 loss: 0.3079749345779419
Batch 50/64 loss: 0.3082348704338074
Batch 51/64 loss: 0.3078421354293823
Batch 52/64 loss: 0.30849742889404297
Batch 53/64 loss: 0.30406904220581055
Batch 54/64 loss: 0.3143872618675232
Batch 55/64 loss: 0.31397366523742676
Batch 56/64 loss: 0.30202388763427734
Batch 57/64 loss: 0.32003605365753174
Batch 58/64 loss: 0.3241415023803711
Batch 59/64 loss: 0.3173030614852905
Batch 60/64 loss: 0.31478607654571533
Batch 61/64 loss: 0.3063002824783325
Batch 62/64 loss: 0.30871856212615967
Batch 63/64 loss: 0.31267809867858887
Batch 64/64 loss: 0.3117419481277466
Epoch 350  Train loss: 0.3108228650747561  Val loss: 0.33429124142296124
Epoch 351
-------------------------------
Batch 1/64 loss: 0.3248859643936157
Batch 2/64 loss: 0.30938851833343506
Batch 3/64 loss: 0.3136390447616577
Batch 4/64 loss: 0.30206698179244995
Batch 5/64 loss: 0.3010987639427185
Batch 6/64 loss: 0.3050917387008667
Batch 7/64 loss: 0.3078620433807373
Batch 8/64 loss: 0.30855870246887207
Batch 9/64 loss: 0.31233924627304077
Batch 10/64 loss: 0.3067328929901123
Batch 11/64 loss: 0.3125009536743164
Batch 12/64 loss: 0.3064596652984619
Batch 13/64 loss: 0.3075599670410156
Batch 14/64 loss: 0.31536394357681274
Batch 15/64 loss: 0.311168909072876
Batch 16/64 loss: 0.3071908950805664
Batch 17/64 loss: 0.3101968765258789
Batch 18/64 loss: 0.309268057346344
Batch 19/64 loss: 0.30942726135253906
Batch 20/64 loss: 0.31266969442367554
Batch 21/64 loss: 0.30632686614990234
Batch 22/64 loss: 0.3118545413017273
Batch 23/64 loss: 0.31771403551101685
Batch 24/64 loss: 0.3112071752548218
Batch 25/64 loss: 0.3122962713241577
Batch 26/64 loss: 0.31444889307022095
Batch 27/64 loss: 0.3059408664703369
Batch 28/64 loss: 0.3113228678703308
Batch 29/64 loss: 0.3057997226715088
Batch 30/64 loss: 0.3224436044692993
Batch 31/64 loss: 0.30672121047973633
Batch 32/64 loss: 0.3022441864013672
Batch 33/64 loss: 0.30794769525527954
Batch 34/64 loss: 0.32160359621047974
Batch 35/64 loss: 0.3049779534339905
Batch 36/64 loss: 0.3098667860031128
Batch 37/64 loss: 0.3072371482849121
Batch 38/64 loss: 0.3180961012840271
Batch 39/64 loss: 0.307320237159729
Batch 40/64 loss: 0.31138038635253906
Batch 41/64 loss: 0.31258314847946167
Batch 42/64 loss: 0.3062966465950012
Batch 43/64 loss: 0.30707263946533203
Batch 44/64 loss: 0.3065761923789978
Batch 45/64 loss: 0.3086267113685608
Batch 46/64 loss: 0.3079071044921875
Batch 47/64 loss: 0.3091484308242798
Batch 48/64 loss: 0.31556737422943115
Batch 49/64 loss: 0.3181215524673462
Batch 50/64 loss: 0.3224285840988159
Batch 51/64 loss: 0.3086731433868408
Batch 52/64 loss: 0.3173421621322632
Batch 53/64 loss: 0.3112884759902954
Batch 54/64 loss: 0.3130580186843872
Batch 55/64 loss: 0.30916666984558105
Batch 56/64 loss: 0.3036081790924072
Batch 57/64 loss: 0.3051844835281372
Batch 58/64 loss: 0.3134497404098511
Batch 59/64 loss: 0.30871134996414185
Batch 60/64 loss: 0.31316959857940674
Batch 61/64 loss: 0.31560027599334717
Batch 62/64 loss: 0.30806785821914673
Batch 63/64 loss: 0.31515228748321533
Batch 64/64 loss: 0.3074781894683838
Epoch 351  Train loss: 0.310551051532521  Val loss: 0.33423012372144717
Epoch 352
-------------------------------
Batch 1/64 loss: 0.3031497001647949
Batch 2/64 loss: 0.3096775412559509
Batch 3/64 loss: 0.3117142915725708
Batch 4/64 loss: 0.3129734396934509
Batch 5/64 loss: 0.31181418895721436
Batch 6/64 loss: 0.3111796975135803
Batch 7/64 loss: 0.31856799125671387
Batch 8/64 loss: 0.31105220317840576
Batch 9/64 loss: 0.31626302003860474
Batch 10/64 loss: 0.3141059875488281
Batch 11/64 loss: 0.3093681335449219
Batch 12/64 loss: 0.31111735105514526
Batch 13/64 loss: 0.3080458641052246
Batch 14/64 loss: 0.31687307357788086
Batch 15/64 loss: 0.3008996844291687
Batch 16/64 loss: 0.30424100160598755
Batch 17/64 loss: 0.3082444667816162
Batch 18/64 loss: 0.31078749895095825
Batch 19/64 loss: 0.31313204765319824
Batch 20/64 loss: 0.3114473819732666
Batch 21/64 loss: 0.318165123462677
Batch 22/64 loss: 0.2986796498298645
Batch 23/64 loss: 0.3150586485862732
Batch 24/64 loss: 0.30843889713287354
Batch 25/64 loss: 0.3084198236465454
Batch 26/64 loss: 0.30675286054611206
Batch 27/64 loss: 0.31645262241363525
Batch 28/64 loss: 0.30752915143966675
Batch 29/64 loss: 0.30657362937927246
Batch 30/64 loss: 0.31527453660964966
Batch 31/64 loss: 0.30155688524246216
Batch 32/64 loss: 0.30882805585861206
Batch 33/64 loss: 0.31188225746154785
Batch 34/64 loss: 0.3079761266708374
Batch 35/64 loss: 0.311767578125
Batch 36/64 loss: 0.3093146085739136
Batch 37/64 loss: 0.31183862686157227
Batch 38/64 loss: 0.30452144145965576
Batch 39/64 loss: 0.31186342239379883
Batch 40/64 loss: 0.3196309208869934
Batch 41/64 loss: 0.3081229329109192
Batch 42/64 loss: 0.30977749824523926
Batch 43/64 loss: 0.30629825592041016
Batch 44/64 loss: 0.3071777820587158
Batch 45/64 loss: 0.3039807081222534
Batch 46/64 loss: 0.32081353664398193
Batch 47/64 loss: 0.32320165634155273
Batch 48/64 loss: 0.3162934184074402
Batch 49/64 loss: 0.3112495541572571
Batch 50/64 loss: 0.3119799494743347
Batch 51/64 loss: 0.31292426586151123
Batch 52/64 loss: 0.3079369068145752
Batch 53/64 loss: 0.3155063986778259
Batch 54/64 loss: 0.3073996305465698
Batch 55/64 loss: 0.30887341499328613
Batch 56/64 loss: 0.30871498584747314
Batch 57/64 loss: 0.3092525005340576
Batch 58/64 loss: 0.31270551681518555
Batch 59/64 loss: 0.30511224269866943
Batch 60/64 loss: 0.3063511848449707
Batch 61/64 loss: 0.30740952491760254
Batch 62/64 loss: 0.3193798065185547
Batch 63/64 loss: 0.3123776316642761
Batch 64/64 loss: 0.3058898448944092
Epoch 352  Train loss: 0.31054801753923006  Val loss: 0.33430935549981816
Epoch 353
-------------------------------
Batch 1/64 loss: 0.3037450313568115
Batch 2/64 loss: 0.3156181573867798
Batch 3/64 loss: 0.3078913688659668
Batch 4/64 loss: 0.32320237159729004
Batch 5/64 loss: 0.30943793058395386
Batch 6/64 loss: 0.3171929121017456
Batch 7/64 loss: 0.3030821681022644
Batch 8/64 loss: 0.3138704299926758
Batch 9/64 loss: 0.31433069705963135
Batch 10/64 loss: 0.3037574291229248
Batch 11/64 loss: 0.3077806234359741
Batch 12/64 loss: 0.30793970823287964
Batch 13/64 loss: 0.30733752250671387
Batch 14/64 loss: 0.30938994884490967
Batch 15/64 loss: 0.316664457321167
Batch 16/64 loss: 0.31042420864105225
Batch 17/64 loss: 0.3232457637786865
Batch 18/64 loss: 0.3183724284172058
Batch 19/64 loss: 0.31499218940734863
Batch 20/64 loss: 0.31435179710388184
Batch 21/64 loss: 0.309287428855896
Batch 22/64 loss: 0.3052656054496765
Batch 23/64 loss: 0.3138996362686157
Batch 24/64 loss: 0.3031412363052368
Batch 25/64 loss: 0.30877166986465454
Batch 26/64 loss: 0.3143113851547241
Batch 27/64 loss: 0.31175661087036133
Batch 28/64 loss: 0.3053579330444336
Batch 29/64 loss: 0.31383246183395386
Batch 30/64 loss: 0.30315709114074707
Batch 31/64 loss: 0.31477487087249756
Batch 32/64 loss: 0.31089329719543457
Batch 33/64 loss: 0.3159322142601013
Batch 34/64 loss: 0.3106086254119873
Batch 35/64 loss: 0.3122561573982239
Batch 36/64 loss: 0.30824559926986694
Batch 37/64 loss: 0.302301287651062
Batch 38/64 loss: 0.30924201011657715
Batch 39/64 loss: 0.3055575489997864
Batch 40/64 loss: 0.30218255519866943
Batch 41/64 loss: 0.30596858263015747
Batch 42/64 loss: 0.3181549310684204
Batch 43/64 loss: 0.3093618154525757
Batch 44/64 loss: 0.3051372766494751
Batch 45/64 loss: 0.31758320331573486
Batch 46/64 loss: 0.30897748470306396
Batch 47/64 loss: 0.3104552626609802
Batch 48/64 loss: 0.3091362714767456
Batch 49/64 loss: 0.30844515562057495
Batch 50/64 loss: 0.30224132537841797
Batch 51/64 loss: 0.30682265758514404
Batch 52/64 loss: 0.3185168504714966
Batch 53/64 loss: 0.3233799934387207
Batch 54/64 loss: 0.31038087606430054
Batch 55/64 loss: 0.3124406337738037
Batch 56/64 loss: 0.3213188648223877
Batch 57/64 loss: 0.3059489130973816
Batch 58/64 loss: 0.3125239610671997
Batch 59/64 loss: 0.3120405673980713
Batch 60/64 loss: 0.3071356415748596
Batch 61/64 loss: 0.31302428245544434
Batch 62/64 loss: 0.30209559202194214
Batch 63/64 loss: 0.3180265426635742
Batch 64/64 loss: 0.30847954750061035
Epoch 353  Train loss: 0.3108059406280518  Val loss: 0.3346973850145373
Epoch 354
-------------------------------
Batch 1/64 loss: 0.3192901611328125
Batch 2/64 loss: 0.3095306158065796
Batch 3/64 loss: 0.30716705322265625
Batch 4/64 loss: 0.30856436491012573
Batch 5/64 loss: 0.3022589683532715
Batch 6/64 loss: 0.3069446086883545
Batch 7/64 loss: 0.315213143825531
Batch 8/64 loss: 0.3082631826400757
Batch 9/64 loss: 0.31536364555358887
Batch 10/64 loss: 0.307043194770813
Batch 11/64 loss: 0.31353116035461426
Batch 12/64 loss: 0.30477243661880493
Batch 13/64 loss: 0.31124091148376465
Batch 14/64 loss: 0.3137531280517578
Batch 15/64 loss: 0.3209410309791565
Batch 16/64 loss: 0.32386982440948486
Batch 17/64 loss: 0.3127009868621826
Batch 18/64 loss: 0.3093310594558716
Batch 19/64 loss: 0.3043593764305115
Batch 20/64 loss: 0.3203994631767273
Batch 21/64 loss: 0.30166125297546387
Batch 22/64 loss: 0.3134821653366089
Batch 23/64 loss: 0.3099346160888672
Batch 24/64 loss: 0.31829118728637695
Batch 25/64 loss: 0.3160988688468933
Batch 26/64 loss: 0.3107989430427551
Batch 27/64 loss: 0.30803602933883667
Batch 28/64 loss: 0.311481237411499
Batch 29/64 loss: 0.3101460933685303
Batch 30/64 loss: 0.30806177854537964
Batch 31/64 loss: 0.29499250650405884
Batch 32/64 loss: 0.305340051651001
Batch 33/64 loss: 0.3075578212738037
Batch 34/64 loss: 0.3198506832122803
Batch 35/64 loss: 0.3066922426223755
Batch 36/64 loss: 0.30847734212875366
Batch 37/64 loss: 0.3092712163925171
Batch 38/64 loss: 0.3056202530860901
Batch 39/64 loss: 0.3089480400085449
Batch 40/64 loss: 0.3093182444572449
Batch 41/64 loss: 0.3103601932525635
Batch 42/64 loss: 0.3123422861099243
Batch 43/64 loss: 0.296797513961792
Batch 44/64 loss: 0.3082071542739868
Batch 45/64 loss: 0.30603694915771484
Batch 46/64 loss: 0.31059032678604126
Batch 47/64 loss: 0.30543190240859985
Batch 48/64 loss: 0.32079625129699707
Batch 49/64 loss: 0.3181832432746887
Batch 50/64 loss: 0.30736613273620605
Batch 51/64 loss: 0.31752145290374756
Batch 52/64 loss: 0.30453306436538696
Batch 53/64 loss: 0.3047037124633789
Batch 54/64 loss: 0.3085721731185913
Batch 55/64 loss: 0.31820929050445557
Batch 56/64 loss: 0.3111860752105713
Batch 57/64 loss: 0.3179206848144531
Batch 58/64 loss: 0.3065143823623657
Batch 59/64 loss: 0.3143455386161804
Batch 60/64 loss: 0.3199661374092102
Batch 61/64 loss: 0.312486469745636
Batch 62/64 loss: 0.3055228590965271
Batch 63/64 loss: 0.31265515089035034
Batch 64/64 loss: 0.3090537190437317
Epoch 354  Train loss: 0.3105982450877919  Val loss: 0.3340756139394754
Epoch 355
-------------------------------
Batch 1/64 loss: 0.3090325593948364
Batch 2/64 loss: 0.31105607748031616
Batch 3/64 loss: 0.3053027391433716
Batch 4/64 loss: 0.3141809105873108
Batch 5/64 loss: 0.3093392848968506
Batch 6/64 loss: 0.3053649067878723
Batch 7/64 loss: 0.30292022228240967
Batch 8/64 loss: 0.30709296464920044
Batch 9/64 loss: 0.3138166666030884
Batch 10/64 loss: 0.31222736835479736
Batch 11/64 loss: 0.31302809715270996
Batch 12/64 loss: 0.3141639232635498
Batch 13/64 loss: 0.31577134132385254
Batch 14/64 loss: 0.29890239238739014
Batch 15/64 loss: 0.3144300580024719
Batch 16/64 loss: 0.31127071380615234
Batch 17/64 loss: 0.3170616626739502
Batch 18/64 loss: 0.3143043518066406
Batch 19/64 loss: 0.3084818124771118
Batch 20/64 loss: 0.3172222375869751
Batch 21/64 loss: 0.314547061920166
Batch 22/64 loss: 0.2954457998275757
Batch 23/64 loss: 0.3118222951889038
Batch 24/64 loss: 0.31344789266586304
Batch 25/64 loss: 0.3088195323944092
Batch 26/64 loss: 0.3146606683731079
Batch 27/64 loss: 0.317687451839447
Batch 28/64 loss: 0.3148645758628845
Batch 29/64 loss: 0.3018549680709839
Batch 30/64 loss: 0.31209349632263184
Batch 31/64 loss: 0.32104647159576416
Batch 32/64 loss: 0.3029268980026245
Batch 33/64 loss: 0.3204733729362488
Batch 34/64 loss: 0.3067585825920105
Batch 35/64 loss: 0.30207979679107666
Batch 36/64 loss: 0.31936609745025635
Batch 37/64 loss: 0.3130122423171997
Batch 38/64 loss: 0.3092074990272522
Batch 39/64 loss: 0.3056755065917969
Batch 40/64 loss: 0.3171123266220093
Batch 41/64 loss: 0.30708932876586914
Batch 42/64 loss: 0.31171542406082153
Batch 43/64 loss: 0.31691592931747437
Batch 44/64 loss: 0.31756991147994995
Batch 45/64 loss: 0.31516706943511963
Batch 46/64 loss: 0.3138551115989685
Batch 47/64 loss: 0.30544960498809814
Batch 48/64 loss: 0.30888354778289795
Batch 49/64 loss: 0.3005877733230591
Batch 50/64 loss: 0.31155192852020264
Batch 51/64 loss: 0.3042093515396118
Batch 52/64 loss: 0.3049614429473877
Batch 53/64 loss: 0.3044501543045044
Batch 54/64 loss: 0.3110058307647705
Batch 55/64 loss: 0.30944204330444336
Batch 56/64 loss: 0.3091769218444824
Batch 57/64 loss: 0.30266350507736206
Batch 58/64 loss: 0.3093423843383789
Batch 59/64 loss: 0.32090187072753906
Batch 60/64 loss: 0.30690985918045044
Batch 61/64 loss: 0.31979507207870483
Batch 62/64 loss: 0.3003251552581787
Batch 63/64 loss: 0.301954448223114
Batch 64/64 loss: 0.3082231283187866
Epoch 355  Train loss: 0.31032100144554586  Val loss: 0.334181922407904
Epoch 356
-------------------------------
Batch 1/64 loss: 0.30363696813583374
Batch 2/64 loss: 0.3077881336212158
Batch 3/64 loss: 0.3102017641067505
Batch 4/64 loss: 0.3085435628890991
Batch 5/64 loss: 0.30898869037628174
Batch 6/64 loss: 0.31273186206817627
Batch 7/64 loss: 0.3125162124633789
Batch 8/64 loss: 0.3054170608520508
Batch 9/64 loss: 0.3130839467048645
Batch 10/64 loss: 0.3145240545272827
Batch 11/64 loss: 0.30692291259765625
Batch 12/64 loss: 0.31609129905700684
Batch 13/64 loss: 0.31153732538223267
Batch 14/64 loss: 0.3077428936958313
Batch 15/64 loss: 0.31907546520233154
Batch 16/64 loss: 0.3091251850128174
Batch 17/64 loss: 0.30369889736175537
Batch 18/64 loss: 0.3053814768791199
Batch 19/64 loss: 0.3079845905303955
Batch 20/64 loss: 0.3143182396888733
Batch 21/64 loss: 0.3023083806037903
Batch 22/64 loss: 0.30534088611602783
Batch 23/64 loss: 0.30568885803222656
Batch 24/64 loss: 0.31370842456817627
Batch 25/64 loss: 0.3064846992492676
Batch 26/64 loss: 0.3086552023887634
Batch 27/64 loss: 0.3102181553840637
Batch 28/64 loss: 0.31463682651519775
Batch 29/64 loss: 0.32339370250701904
Batch 30/64 loss: 0.3108925223350525
Batch 31/64 loss: 0.31313759088516235
Batch 32/64 loss: 0.31213080883026123
Batch 33/64 loss: 0.3143896460533142
Batch 34/64 loss: 0.3123199939727783
Batch 35/64 loss: 0.30091243982315063
Batch 36/64 loss: 0.31663262844085693
Batch 37/64 loss: 0.3070734739303589
Batch 38/64 loss: 0.30351507663726807
Batch 39/64 loss: 0.3124803304672241
Batch 40/64 loss: 0.31331539154052734
Batch 41/64 loss: 0.30824506282806396
Batch 42/64 loss: 0.30579710006713867
Batch 43/64 loss: 0.3081153631210327
Batch 44/64 loss: 0.31215035915374756
Batch 45/64 loss: 0.3178163766860962
Batch 46/64 loss: 0.3021043539047241
Batch 47/64 loss: 0.3077695369720459
Batch 48/64 loss: 0.3068734407424927
Batch 49/64 loss: 0.31993740797042847
Batch 50/64 loss: 0.30958688259124756
Batch 51/64 loss: 0.3118748664855957
Batch 52/64 loss: 0.3232381343841553
Batch 53/64 loss: 0.31938230991363525
Batch 54/64 loss: 0.30151164531707764
Batch 55/64 loss: 0.3117508888244629
Batch 56/64 loss: 0.31343960762023926
Batch 57/64 loss: 0.3129713535308838
Batch 58/64 loss: 0.315771222114563
Batch 59/64 loss: 0.3062915802001953
Batch 60/64 loss: 0.30152344703674316
Batch 61/64 loss: 0.31058287620544434
Batch 62/64 loss: 0.3012427091598511
Batch 63/64 loss: 0.3093569278717041
Batch 64/64 loss: 0.30337196588516235
Epoch 356  Train loss: 0.3101397334360609  Val loss: 0.33408052876233235
Epoch 357
-------------------------------
Batch 1/64 loss: 0.31362301111221313
Batch 2/64 loss: 0.31656336784362793
Batch 3/64 loss: 0.31513500213623047
Batch 4/64 loss: 0.2994951605796814
Batch 5/64 loss: 0.3093448877334595
Batch 6/64 loss: 0.3039390444755554
Batch 7/64 loss: 0.30569058656692505
Batch 8/64 loss: 0.3108256459236145
Batch 9/64 loss: 0.31040728092193604
Batch 10/64 loss: 0.3199594020843506
Batch 11/64 loss: 0.31457406282424927
Batch 12/64 loss: 0.30771172046661377
Batch 13/64 loss: 0.310238242149353
Batch 14/64 loss: 0.3077331781387329
Batch 15/64 loss: 0.30739492177963257
Batch 16/64 loss: 0.31531786918640137
Batch 17/64 loss: 0.31192338466644287
Batch 18/64 loss: 0.3090047836303711
Batch 19/64 loss: 0.311187744140625
Batch 20/64 loss: 0.3133307695388794
Batch 21/64 loss: 0.3152894377708435
Batch 22/64 loss: 0.3124837875366211
Batch 23/64 loss: 0.3017246723175049
Batch 24/64 loss: 0.3124037981033325
Batch 25/64 loss: 0.3079909086227417
Batch 26/64 loss: 0.30323338508605957
Batch 27/64 loss: 0.3046776056289673
Batch 28/64 loss: 0.30884236097335815
Batch 29/64 loss: 0.31127142906188965
Batch 30/64 loss: 0.3082771301269531
Batch 31/64 loss: 0.30274856090545654
Batch 32/64 loss: 0.3119162321090698
Batch 33/64 loss: 0.30805504322052
Batch 34/64 loss: 0.3090834617614746
Batch 35/64 loss: 0.3018569350242615
Batch 36/64 loss: 0.3169260025024414
Batch 37/64 loss: 0.31673765182495117
Batch 38/64 loss: 0.3176877498626709
Batch 39/64 loss: 0.32231056690216064
Batch 40/64 loss: 0.3025915026664734
Batch 41/64 loss: 0.3122823238372803
Batch 42/64 loss: 0.30727624893188477
Batch 43/64 loss: 0.3069506287574768
Batch 44/64 loss: 0.31110262870788574
Batch 45/64 loss: 0.30911576747894287
Batch 46/64 loss: 0.3082789182662964
Batch 47/64 loss: 0.3146432638168335
Batch 48/64 loss: 0.31604820489883423
Batch 49/64 loss: 0.31171631813049316
Batch 50/64 loss: 0.31296300888061523
Batch 51/64 loss: 0.30464714765548706
Batch 52/64 loss: 0.30238181352615356
Batch 53/64 loss: 0.3125583529472351
Batch 54/64 loss: 0.30618584156036377
Batch 55/64 loss: 0.31600672006607056
Batch 56/64 loss: 0.3100566864013672
Batch 57/64 loss: 0.3087289333343506
Batch 58/64 loss: 0.3170945644378662
Batch 59/64 loss: 0.3111025094985962
Batch 60/64 loss: 0.30919069051742554
Batch 61/64 loss: 0.306182861328125
Batch 62/64 loss: 0.3051929473876953
Batch 63/64 loss: 0.3128396272659302
Batch 64/64 loss: 0.3057188391685486
Epoch 357  Train loss: 0.3101387203908434  Val loss: 0.3350380128601572
Epoch 358
-------------------------------
Batch 1/64 loss: 0.30008184909820557
Batch 2/64 loss: 0.3154498338699341
Batch 3/64 loss: 0.3113200068473816
Batch 4/64 loss: 0.31528961658477783
Batch 5/64 loss: 0.3011620044708252
Batch 6/64 loss: 0.30816930532455444
Batch 7/64 loss: 0.30463558435440063
Batch 8/64 loss: 0.3051496744155884
Batch 9/64 loss: 0.30690884590148926
Batch 10/64 loss: 0.3132336139678955
Batch 11/64 loss: 0.30495303869247437
Batch 12/64 loss: 0.30827927589416504
Batch 13/64 loss: 0.31405317783355713
Batch 14/64 loss: 0.3075423240661621
Batch 15/64 loss: 0.3016875982284546
Batch 16/64 loss: 0.3164496421813965
Batch 17/64 loss: 0.31787562370300293
Batch 18/64 loss: 0.3115032911300659
Batch 19/64 loss: 0.29992353916168213
Batch 20/64 loss: 0.3158479332923889
Batch 21/64 loss: 0.3018249273300171
Batch 22/64 loss: 0.309209942817688
Batch 23/64 loss: 0.3038966655731201
Batch 24/64 loss: 0.3119050860404968
Batch 25/64 loss: 0.3081655502319336
Batch 26/64 loss: 0.3088279962539673
Batch 27/64 loss: 0.3003128170967102
Batch 28/64 loss: 0.31198298931121826
Batch 29/64 loss: 0.312000036239624
Batch 30/64 loss: 0.3118281364440918
Batch 31/64 loss: 0.30965906381607056
Batch 32/64 loss: 0.3084850311279297
Batch 33/64 loss: 0.3092561960220337
Batch 34/64 loss: 0.31588006019592285
Batch 35/64 loss: 0.30296528339385986
Batch 36/64 loss: 0.3090391159057617
Batch 37/64 loss: 0.30246424674987793
Batch 38/64 loss: 0.3075127601623535
Batch 39/64 loss: 0.30893146991729736
Batch 40/64 loss: 0.3080568313598633
Batch 41/64 loss: 0.3224712610244751
Batch 42/64 loss: 0.3132307529449463
Batch 43/64 loss: 0.30921077728271484
Batch 44/64 loss: 0.3099013566970825
Batch 45/64 loss: 0.3120020627975464
Batch 46/64 loss: 0.3062194585800171
Batch 47/64 loss: 0.3139914274215698
Batch 48/64 loss: 0.31182360649108887
Batch 49/64 loss: 0.31138408184051514
Batch 50/64 loss: 0.30977463722229004
Batch 51/64 loss: 0.3084377646446228
Batch 52/64 loss: 0.31375980377197266
Batch 53/64 loss: 0.31334275007247925
Batch 54/64 loss: 0.31500184535980225
Batch 55/64 loss: 0.3148018717765808
Batch 56/64 loss: 0.30900996923446655
Batch 57/64 loss: 0.3088630437850952
Batch 58/64 loss: 0.3119635581970215
Batch 59/64 loss: 0.30468618869781494
Batch 60/64 loss: 0.3112086057662964
Batch 61/64 loss: 0.3070868253707886
Batch 62/64 loss: 0.3118859529495239
Batch 63/64 loss: 0.3233140707015991
Batch 64/64 loss: 0.31139642000198364
Epoch 358  Train loss: 0.3097825721198437  Val loss: 0.3347318850432065
Epoch 359
-------------------------------
Batch 1/64 loss: 0.31441807746887207
Batch 2/64 loss: 0.3170592784881592
Batch 3/64 loss: 0.30818772315979004
Batch 4/64 loss: 0.307716429233551
Batch 5/64 loss: 0.30638623237609863
Batch 6/64 loss: 0.3123666048049927
Batch 7/64 loss: 0.3140169382095337
Batch 8/64 loss: 0.30613017082214355
Batch 9/64 loss: 0.310860276222229
Batch 10/64 loss: 0.3124375343322754
Batch 11/64 loss: 0.3059765100479126
Batch 12/64 loss: 0.3077179193496704
Batch 13/64 loss: 0.3028758764266968
Batch 14/64 loss: 0.31721723079681396
Batch 15/64 loss: 0.3086143732070923
Batch 16/64 loss: 0.30488431453704834
Batch 17/64 loss: 0.31291186809539795
Batch 18/64 loss: 0.306659996509552
Batch 19/64 loss: 0.3077678680419922
Batch 20/64 loss: 0.30290520191192627
Batch 21/64 loss: 0.30881911516189575
Batch 22/64 loss: 0.30364322662353516
Batch 23/64 loss: 0.31172025203704834
Batch 24/64 loss: 0.3085562586784363
Batch 25/64 loss: 0.3155069351196289
Batch 26/64 loss: 0.31348133087158203
Batch 27/64 loss: 0.31646037101745605
Batch 28/64 loss: 0.31407344341278076
Batch 29/64 loss: 0.30628257989883423
Batch 30/64 loss: 0.30487060546875
Batch 31/64 loss: 0.3144649267196655
Batch 32/64 loss: 0.31026649475097656
Batch 33/64 loss: 0.3124285936355591
Batch 34/64 loss: 0.3051673173904419
Batch 35/64 loss: 0.30790233612060547
Batch 36/64 loss: 0.30717647075653076
Batch 37/64 loss: 0.3010922074317932
Batch 38/64 loss: 0.30597221851348877
Batch 39/64 loss: 0.3125990629196167
Batch 40/64 loss: 0.3101236820220947
Batch 41/64 loss: 0.3142514228820801
Batch 42/64 loss: 0.30801212787628174
Batch 43/64 loss: 0.30375099182128906
Batch 44/64 loss: 0.3208075761795044
Batch 45/64 loss: 0.31548237800598145
Batch 46/64 loss: 0.30557870864868164
Batch 47/64 loss: 0.31261277198791504
Batch 48/64 loss: 0.31087183952331543
Batch 49/64 loss: 0.3145468235015869
Batch 50/64 loss: 0.315226674079895
Batch 51/64 loss: 0.31372058391571045
Batch 52/64 loss: 0.3081287145614624
Batch 53/64 loss: 0.30496692657470703
Batch 54/64 loss: 0.32009994983673096
Batch 55/64 loss: 0.3020816445350647
Batch 56/64 loss: 0.3070725202560425
Batch 57/64 loss: 0.30866891145706177
Batch 58/64 loss: 0.3152804374694824
Batch 59/64 loss: 0.30330783128738403
Batch 60/64 loss: 0.31777358055114746
Batch 61/64 loss: 0.30657970905303955
Batch 62/64 loss: 0.3057168126106262
Batch 63/64 loss: 0.32740873098373413
Batch 64/64 loss: 0.2997075319290161
Epoch 359  Train loss: 0.3100305281433405  Val loss: 0.3349989300331299
Epoch 360
-------------------------------
Batch 1/64 loss: 0.30927330255508423
Batch 2/64 loss: 0.3052217364311218
Batch 3/64 loss: 0.3100414276123047
Batch 4/64 loss: 0.31140732765197754
Batch 5/64 loss: 0.3074758052825928
Batch 6/64 loss: 0.30249911546707153
Batch 7/64 loss: 0.31154322624206543
Batch 8/64 loss: 0.3137611746788025
Batch 9/64 loss: 0.30756640434265137
Batch 10/64 loss: 0.31399595737457275
Batch 11/64 loss: 0.3075910806655884
Batch 12/64 loss: 0.3135493993759155
Batch 13/64 loss: 0.31546103954315186
Batch 14/64 loss: 0.30726683139801025
Batch 15/64 loss: 0.3119220733642578
Batch 16/64 loss: 0.30582308769226074
Batch 17/64 loss: 0.3022470474243164
Batch 18/64 loss: 0.3113410472869873
Batch 19/64 loss: 0.31198740005493164
Batch 20/64 loss: 0.30125266313552856
Batch 21/64 loss: 0.3141205906867981
Batch 22/64 loss: 0.31680357456207275
Batch 23/64 loss: 0.3183259963989258
Batch 24/64 loss: 0.3070375323295593
Batch 25/64 loss: 0.30955445766448975
Batch 26/64 loss: 0.31738317012786865
Batch 27/64 loss: 0.30358684062957764
Batch 28/64 loss: 0.3124206066131592
Batch 29/64 loss: 0.3028361201286316
Batch 30/64 loss: 0.3068501949310303
Batch 31/64 loss: 0.3220665454864502
Batch 32/64 loss: 0.3134923577308655
Batch 33/64 loss: 0.30888164043426514
Batch 34/64 loss: 0.30586951971054077
Batch 35/64 loss: 0.30988919734954834
Batch 36/64 loss: 0.30724000930786133
Batch 37/64 loss: 0.31302928924560547
Batch 38/64 loss: 0.30954426527023315
Batch 39/64 loss: 0.3104098439216614
Batch 40/64 loss: 0.3139362335205078
Batch 41/64 loss: 0.30665504932403564
Batch 42/64 loss: 0.31147098541259766
Batch 43/64 loss: 0.3061707615852356
Batch 44/64 loss: 0.3126957416534424
Batch 45/64 loss: 0.3139486312866211
Batch 46/64 loss: 0.31802934408187866
Batch 47/64 loss: 0.3073905110359192
Batch 48/64 loss: 0.3127288222312927
Batch 49/64 loss: 0.3089318871498108
Batch 50/64 loss: 0.3103218674659729
Batch 51/64 loss: 0.308601438999176
Batch 52/64 loss: 0.3074769973754883
Batch 53/64 loss: 0.31709861755371094
Batch 54/64 loss: 0.30217719078063965
Batch 55/64 loss: 0.30964231491088867
Batch 56/64 loss: 0.3138667345046997
Batch 57/64 loss: 0.3133302927017212
Batch 58/64 loss: 0.30887526273727417
Batch 59/64 loss: 0.3109341859817505
Batch 60/64 loss: 0.31196993589401245
Batch 61/64 loss: 0.3005049228668213
Batch 62/64 loss: 0.3114159107208252
Batch 63/64 loss: 0.31276923418045044
Batch 64/64 loss: 0.3200731873512268
Epoch 360  Train loss: 0.3102990849345338  Val loss: 0.33328934776823954
Epoch 361
-------------------------------
Batch 1/64 loss: 0.307187557220459
Batch 2/64 loss: 0.3064747452735901
Batch 3/64 loss: 0.3006488084793091
Batch 4/64 loss: 0.3128995895385742
Batch 5/64 loss: 0.30512571334838867
Batch 6/64 loss: 0.2987443804740906
Batch 7/64 loss: 0.30440908670425415
Batch 8/64 loss: 0.30678021907806396
Batch 9/64 loss: 0.31297314167022705
Batch 10/64 loss: 0.30116528272628784
Batch 11/64 loss: 0.30088305473327637
Batch 12/64 loss: 0.2998228073120117
Batch 13/64 loss: 0.3130248188972473
Batch 14/64 loss: 0.30916792154312134
Batch 15/64 loss: 0.3066599369049072
Batch 16/64 loss: 0.31190747022628784
Batch 17/64 loss: 0.30487847328186035
Batch 18/64 loss: 0.31077462434768677
Batch 19/64 loss: 0.3096076250076294
Batch 20/64 loss: 0.3113290071487427
Batch 21/64 loss: 0.3135225772857666
Batch 22/64 loss: 0.3175503611564636
Batch 23/64 loss: 0.307823121547699
Batch 24/64 loss: 0.31116265058517456
Batch 25/64 loss: 0.3151315450668335
Batch 26/64 loss: 0.31585144996643066
Batch 27/64 loss: 0.3096083402633667
Batch 28/64 loss: 0.31739532947540283
Batch 29/64 loss: 0.30510449409484863
Batch 30/64 loss: 0.3128185272216797
Batch 31/64 loss: 0.30658596754074097
Batch 32/64 loss: 0.30480754375457764
Batch 33/64 loss: 0.3204296827316284
Batch 34/64 loss: 0.31270718574523926
Batch 35/64 loss: 0.30775415897369385
Batch 36/64 loss: 0.30688267946243286
Batch 37/64 loss: 0.3110359311103821
Batch 38/64 loss: 0.3093454837799072
Batch 39/64 loss: 0.31032150983810425
Batch 40/64 loss: 0.31549155712127686
Batch 41/64 loss: 0.30784112215042114
Batch 42/64 loss: 0.29841136932373047
Batch 43/64 loss: 0.30408549308776855
Batch 44/64 loss: 0.3076474070549011
Batch 45/64 loss: 0.29997003078460693
Batch 46/64 loss: 0.3063390254974365
Batch 47/64 loss: 0.31623655557632446
Batch 48/64 loss: 0.3166283369064331
Batch 49/64 loss: 0.3119990825653076
Batch 50/64 loss: 0.30692189931869507
Batch 51/64 loss: 0.30172473192214966
Batch 52/64 loss: 0.31598085165023804
Batch 53/64 loss: 0.3112492561340332
Batch 54/64 loss: 0.30599403381347656
Batch 55/64 loss: 0.3115973472595215
Batch 56/64 loss: 0.30718207359313965
Batch 57/64 loss: 0.31727224588394165
Batch 58/64 loss: 0.3155518174171448
Batch 59/64 loss: 0.3139488697052002
Batch 60/64 loss: 0.308508038520813
Batch 61/64 loss: 0.3131183385848999
Batch 62/64 loss: 0.3187941312789917
Batch 63/64 loss: 0.31625330448150635
Batch 64/64 loss: 0.3160404562950134
Epoch 361  Train loss: 0.30958556965285655  Val loss: 0.33350087010983337
Epoch 362
-------------------------------
Batch 1/64 loss: 0.32144832611083984
Batch 2/64 loss: 0.30606114864349365
Batch 3/64 loss: 0.3149951696395874
Batch 4/64 loss: 0.3077854514122009
Batch 5/64 loss: 0.3128989338874817
Batch 6/64 loss: 0.3002309799194336
Batch 7/64 loss: 0.3150535821914673
Batch 8/64 loss: 0.3138117790222168
Batch 9/64 loss: 0.3034015893936157
Batch 10/64 loss: 0.30551111698150635
Batch 11/64 loss: 0.3086735010147095
Batch 12/64 loss: 0.3169461488723755
Batch 13/64 loss: 0.3052135705947876
Batch 14/64 loss: 0.3070354461669922
Batch 15/64 loss: 0.31064504384994507
Batch 16/64 loss: 0.30551981925964355
Batch 17/64 loss: 0.30696630477905273
Batch 18/64 loss: 0.3091357350349426
Batch 19/64 loss: 0.29960042238235474
Batch 20/64 loss: 0.311217725276947
Batch 21/64 loss: 0.311424195766449
Batch 22/64 loss: 0.3075093626976013
Batch 23/64 loss: 0.3069162368774414
Batch 24/64 loss: 0.3101569414138794
Batch 25/64 loss: 0.30350637435913086
Batch 26/64 loss: 0.3100942373275757
Batch 27/64 loss: 0.313218355178833
Batch 28/64 loss: 0.304587721824646
Batch 29/64 loss: 0.30441856384277344
Batch 30/64 loss: 0.3082374334335327
Batch 31/64 loss: 0.3070368766784668
Batch 32/64 loss: 0.3120924234390259
Batch 33/64 loss: 0.3154951333999634
Batch 34/64 loss: 0.31214141845703125
Batch 35/64 loss: 0.3035839796066284
Batch 36/64 loss: 0.3155386447906494
Batch 37/64 loss: 0.31129711866378784
Batch 38/64 loss: 0.2983793020248413
Batch 39/64 loss: 0.3089056611061096
Batch 40/64 loss: 0.3203843832015991
Batch 41/64 loss: 0.3151733875274658
Batch 42/64 loss: 0.3163886070251465
Batch 43/64 loss: 0.30948078632354736
Batch 44/64 loss: 0.3124105930328369
Batch 45/64 loss: 0.30599653720855713
Batch 46/64 loss: 0.314275860786438
Batch 47/64 loss: 0.3092194199562073
Batch 48/64 loss: 0.3041905164718628
Batch 49/64 loss: 0.304629385471344
Batch 50/64 loss: 0.31886351108551025
Batch 51/64 loss: 0.3120468854904175
Batch 52/64 loss: 0.3195192813873291
Batch 53/64 loss: 0.30172574520111084
Batch 54/64 loss: 0.30885565280914307
Batch 55/64 loss: 0.31262993812561035
Batch 56/64 loss: 0.31076133251190186
Batch 57/64 loss: 0.31027185916900635
Batch 58/64 loss: 0.31866753101348877
Batch 59/64 loss: 0.3108236789703369
Batch 60/64 loss: 0.3097957372665405
Batch 61/64 loss: 0.30460578203201294
Batch 62/64 loss: 0.30901700258255005
Batch 63/64 loss: 0.3094172477722168
Batch 64/64 loss: 0.30183303356170654
Epoch 362  Train loss: 0.30968183863396737  Val loss: 0.3337489255924815
Epoch 363
-------------------------------
Batch 1/64 loss: 0.3119560480117798
Batch 2/64 loss: 0.3038606643676758
Batch 3/64 loss: 0.31145787239074707
Batch 4/64 loss: 0.3037149906158447
Batch 5/64 loss: 0.3077191114425659
Batch 6/64 loss: 0.30493438243865967
Batch 7/64 loss: 0.30386632680892944
Batch 8/64 loss: 0.30721235275268555
Batch 9/64 loss: 0.30562102794647217
Batch 10/64 loss: 0.31706702709198
Batch 11/64 loss: 0.3132131099700928
Batch 12/64 loss: 0.3075648546218872
Batch 13/64 loss: 0.30861222743988037
Batch 14/64 loss: 0.3018196225166321
Batch 15/64 loss: 0.3040142059326172
Batch 16/64 loss: 0.3130093812942505
Batch 17/64 loss: 0.31678545475006104
Batch 18/64 loss: 0.3019291162490845
Batch 19/64 loss: 0.3062668442726135
Batch 20/64 loss: 0.29984188079833984
Batch 21/64 loss: 0.3036454916000366
Batch 22/64 loss: 0.3110239505767822
Batch 23/64 loss: 0.3104285001754761
Batch 24/64 loss: 0.3055490255355835
Batch 25/64 loss: 0.3091927766799927
Batch 26/64 loss: 0.30982673168182373
Batch 27/64 loss: 0.3151613473892212
Batch 28/64 loss: 0.30474722385406494
Batch 29/64 loss: 0.30973196029663086
Batch 30/64 loss: 0.3094102144241333
Batch 31/64 loss: 0.30732667446136475
Batch 32/64 loss: 0.30563628673553467
Batch 33/64 loss: 0.31844478845596313
Batch 34/64 loss: 0.31445908546447754
Batch 35/64 loss: 0.31165528297424316
Batch 36/64 loss: 0.3178081512451172
Batch 37/64 loss: 0.30857956409454346
Batch 38/64 loss: 0.31807827949523926
Batch 39/64 loss: 0.3208998441696167
Batch 40/64 loss: 0.31641846895217896
Batch 41/64 loss: 0.32225871086120605
Batch 42/64 loss: 0.3121248483657837
Batch 43/64 loss: 0.30138593912124634
Batch 44/64 loss: 0.3135308027267456
Batch 45/64 loss: 0.3148588538169861
Batch 46/64 loss: 0.29846620559692383
Batch 47/64 loss: 0.3097960948944092
Batch 48/64 loss: 0.3066282272338867
Batch 49/64 loss: 0.3112586736679077
Batch 50/64 loss: 0.3120282292366028
Batch 51/64 loss: 0.3078799247741699
Batch 52/64 loss: 0.3119995594024658
Batch 53/64 loss: 0.3168168067932129
Batch 54/64 loss: 0.30635595321655273
Batch 55/64 loss: 0.30632948875427246
Batch 56/64 loss: 0.3006504774093628
Batch 57/64 loss: 0.3066643476486206
Batch 58/64 loss: 0.3018045425415039
Batch 59/64 loss: 0.32027143239974976
Batch 60/64 loss: 0.30273234844207764
Batch 61/64 loss: 0.3170713186264038
Batch 62/64 loss: 0.3042038679122925
Batch 63/64 loss: 0.3017866611480713
Batch 64/64 loss: 0.3023179769515991
Epoch 363  Train loss: 0.30920991289849376  Val loss: 0.3346957951476893
Epoch 364
-------------------------------
Batch 1/64 loss: 0.30993908643722534
Batch 2/64 loss: 0.3048641085624695
Batch 3/64 loss: 0.313148558139801
Batch 4/64 loss: 0.3077322244644165
Batch 5/64 loss: 0.307247519493103
Batch 6/64 loss: 0.30691373348236084
Batch 7/64 loss: 0.3128941059112549
Batch 8/64 loss: 0.3113299012184143
Batch 9/64 loss: 0.3040708303451538
Batch 10/64 loss: 0.30745792388916016
Batch 11/64 loss: 0.29819685220718384
Batch 12/64 loss: 0.3096234202384949
Batch 13/64 loss: 0.30478304624557495
Batch 14/64 loss: 0.3072153329849243
Batch 15/64 loss: 0.32305431365966797
Batch 16/64 loss: 0.3165286183357239
Batch 17/64 loss: 0.31417346000671387
Batch 18/64 loss: 0.3093531131744385
Batch 19/64 loss: 0.30305445194244385
Batch 20/64 loss: 0.3092780113220215
Batch 21/64 loss: 0.30411070585250854
Batch 22/64 loss: 0.30520230531692505
Batch 23/64 loss: 0.3182961940765381
Batch 24/64 loss: 0.32070064544677734
Batch 25/64 loss: 0.3111264705657959
Batch 26/64 loss: 0.31221044063568115
Batch 27/64 loss: 0.30206596851348877
Batch 28/64 loss: 0.30598974227905273
Batch 29/64 loss: 0.3110436201095581
Batch 30/64 loss: 0.30468273162841797
Batch 31/64 loss: 0.30908507108688354
Batch 32/64 loss: 0.30702996253967285
Batch 33/64 loss: 0.3070417642593384
Batch 34/64 loss: 0.2959507703781128
Batch 35/64 loss: 0.3136659264564514
Batch 36/64 loss: 0.3139073848724365
Batch 37/64 loss: 0.29856956005096436
Batch 38/64 loss: 0.3121224641799927
Batch 39/64 loss: 0.3060668706893921
Batch 40/64 loss: 0.31120264530181885
Batch 41/64 loss: 0.30594146251678467
Batch 42/64 loss: 0.30726689100265503
Batch 43/64 loss: 0.3084883689880371
Batch 44/64 loss: 0.30753254890441895
Batch 45/64 loss: 0.30685025453567505
Batch 46/64 loss: 0.30635303258895874
Batch 47/64 loss: 0.3108506202697754
Batch 48/64 loss: 0.31345999240875244
Batch 49/64 loss: 0.3177427053451538
Batch 50/64 loss: 0.31245899200439453
Batch 51/64 loss: 0.30537939071655273
Batch 52/64 loss: 0.3022817373275757
Batch 53/64 loss: 0.31572210788726807
Batch 54/64 loss: 0.3132140636444092
Batch 55/64 loss: 0.3009064793586731
Batch 56/64 loss: 0.32057487964630127
Batch 57/64 loss: 0.3085542321205139
Batch 58/64 loss: 0.3138498067855835
Batch 59/64 loss: 0.31117862462997437
Batch 60/64 loss: 0.3025054931640625
Batch 61/64 loss: 0.31133097410202026
Batch 62/64 loss: 0.3102307915687561
Batch 63/64 loss: 0.31214404106140137
Batch 64/64 loss: 0.3172396421432495
Epoch 364  Train loss: 0.3092341502507528  Val loss: 0.3333615687294924
Epoch 365
-------------------------------
Batch 1/64 loss: 0.3082655072212219
Batch 2/64 loss: 0.30416709184646606
Batch 3/64 loss: 0.30683833360671997
Batch 4/64 loss: 0.3148273229598999
Batch 5/64 loss: 0.3114849328994751
Batch 6/64 loss: 0.3010336756706238
Batch 7/64 loss: 0.31666409969329834
Batch 8/64 loss: 0.3119407892227173
Batch 9/64 loss: 0.3079953193664551
Batch 10/64 loss: 0.3119843006134033
Batch 11/64 loss: 0.31931179761886597
Batch 12/64 loss: 0.3028005361557007
Batch 13/64 loss: 0.3043100833892822
Batch 14/64 loss: 0.3068288564682007
Batch 15/64 loss: 0.3044080138206482
Batch 16/64 loss: 0.30444300174713135
Batch 17/64 loss: 0.3049215078353882
Batch 18/64 loss: 0.3035702109336853
Batch 19/64 loss: 0.3176720142364502
Batch 20/64 loss: 0.3103117346763611
Batch 21/64 loss: 0.3067111372947693
Batch 22/64 loss: 0.3099247217178345
Batch 23/64 loss: 0.31810009479522705
Batch 24/64 loss: 0.3095017671585083
Batch 25/64 loss: 0.30542099475860596
Batch 26/64 loss: 0.31352877616882324
Batch 27/64 loss: 0.30935966968536377
Batch 28/64 loss: 0.30450284481048584
Batch 29/64 loss: 0.30915528535842896
Batch 30/64 loss: 0.3172130584716797
Batch 31/64 loss: 0.3051561117172241
Batch 32/64 loss: 0.308663547039032
Batch 33/64 loss: 0.30625855922698975
Batch 34/64 loss: 0.3148201107978821
Batch 35/64 loss: 0.3130671977996826
Batch 36/64 loss: 0.3064238429069519
Batch 37/64 loss: 0.3131309747695923
Batch 38/64 loss: 0.3119383454322815
Batch 39/64 loss: 0.2954035997390747
Batch 40/64 loss: 0.3045152425765991
Batch 41/64 loss: 0.3096504211425781
Batch 42/64 loss: 0.31589841842651367
Batch 43/64 loss: 0.3047126531600952
Batch 44/64 loss: 0.3070407509803772
Batch 45/64 loss: 0.30128371715545654
Batch 46/64 loss: 0.30645865201950073
Batch 47/64 loss: 0.314406156539917
Batch 48/64 loss: 0.31029176712036133
Batch 49/64 loss: 0.3016952872276306
Batch 50/64 loss: 0.3053823709487915
Batch 51/64 loss: 0.3064699172973633
Batch 52/64 loss: 0.3099179267883301
Batch 53/64 loss: 0.3135685920715332
Batch 54/64 loss: 0.31352126598358154
Batch 55/64 loss: 0.31480610370635986
Batch 56/64 loss: 0.313681423664093
Batch 57/64 loss: 0.30701470375061035
Batch 58/64 loss: 0.3131225109100342
Batch 59/64 loss: 0.3178107738494873
Batch 60/64 loss: 0.3088874816894531
Batch 61/64 loss: 0.3143967390060425
Batch 62/64 loss: 0.3085830807685852
Batch 63/64 loss: 0.31646716594696045
Batch 64/64 loss: 0.31481099128723145
Epoch 365  Train loss: 0.3094549197776645  Val loss: 0.33439386997026266
Epoch 366
-------------------------------
Batch 1/64 loss: 0.31222259998321533
Batch 2/64 loss: 0.3030434846878052
Batch 3/64 loss: 0.30723726749420166
Batch 4/64 loss: 0.3123716115951538
Batch 5/64 loss: 0.3094751834869385
Batch 6/64 loss: 0.31109946966171265
Batch 7/64 loss: 0.30759698152542114
Batch 8/64 loss: 0.30698132514953613
Batch 9/64 loss: 0.31209826469421387
Batch 10/64 loss: 0.30652570724487305
Batch 11/64 loss: 0.31715071201324463
Batch 12/64 loss: 0.30947285890579224
Batch 13/64 loss: 0.30892205238342285
Batch 14/64 loss: 0.3073939085006714
Batch 15/64 loss: 0.3098413944244385
Batch 16/64 loss: 0.3090284466743469
Batch 17/64 loss: 0.3048962354660034
Batch 18/64 loss: 0.3041961193084717
Batch 19/64 loss: 0.30920201539993286
Batch 20/64 loss: 0.3114693760871887
Batch 21/64 loss: 0.3047982454299927
Batch 22/64 loss: 0.3116200566291809
Batch 23/64 loss: 0.30780959129333496
Batch 24/64 loss: 0.3049907088279724
Batch 25/64 loss: 0.31096041202545166
Batch 26/64 loss: 0.31477653980255127
Batch 27/64 loss: 0.3059196472167969
Batch 28/64 loss: 0.30980920791625977
Batch 29/64 loss: 0.3064401149749756
Batch 30/64 loss: 0.3062330484390259
Batch 31/64 loss: 0.3149254322052002
Batch 32/64 loss: 0.3156304359436035
Batch 33/64 loss: 0.3079877495765686
Batch 34/64 loss: 0.31313544511795044
Batch 35/64 loss: 0.3081502914428711
Batch 36/64 loss: 0.3080630898475647
Batch 37/64 loss: 0.3062870502471924
Batch 38/64 loss: 0.31223171949386597
Batch 39/64 loss: 0.3086852431297302
Batch 40/64 loss: 0.30977535247802734
Batch 41/64 loss: 0.30255037546157837
Batch 42/64 loss: 0.31078195571899414
Batch 43/64 loss: 0.3103046417236328
Batch 44/64 loss: 0.3159722685813904
Batch 45/64 loss: 0.31147336959838867
Batch 46/64 loss: 0.32036662101745605
Batch 47/64 loss: 0.30463707447052
Batch 48/64 loss: 0.31041187047958374
Batch 49/64 loss: 0.3173408508300781
Batch 50/64 loss: 0.32251590490341187
Batch 51/64 loss: 0.30907338857650757
Batch 52/64 loss: 0.3204439878463745
Batch 53/64 loss: 0.3021915555000305
Batch 54/64 loss: 0.30960917472839355
Batch 55/64 loss: 0.3073688745498657
Batch 56/64 loss: 0.3164325952529907
Batch 57/64 loss: 0.3173922300338745
Batch 58/64 loss: 0.31180083751678467
Batch 59/64 loss: 0.31036776304244995
Batch 60/64 loss: 0.3039286136627197
Batch 61/64 loss: 0.30867159366607666
Batch 62/64 loss: 0.3091611862182617
Batch 63/64 loss: 0.308485746383667
Batch 64/64 loss: 0.2991410493850708
Epoch 366  Train loss: 0.30986812021218096  Val loss: 0.3339692536498263
Epoch 367
-------------------------------
Batch 1/64 loss: 0.30944234132766724
Batch 2/64 loss: 0.303242564201355
Batch 3/64 loss: 0.30922985076904297
Batch 4/64 loss: 0.304892897605896
Batch 5/64 loss: 0.3106352686882019
Batch 6/64 loss: 0.31612884998321533
Batch 7/64 loss: 0.3161467909812927
Batch 8/64 loss: 0.31168752908706665
Batch 9/64 loss: 0.30811285972595215
Batch 10/64 loss: 0.3051391839981079
Batch 11/64 loss: 0.31153690814971924
Batch 12/64 loss: 0.30506277084350586
Batch 13/64 loss: 0.3096042275428772
Batch 14/64 loss: 0.307600200176239
Batch 15/64 loss: 0.30881428718566895
Batch 16/64 loss: 0.31070321798324585
Batch 17/64 loss: 0.31505298614501953
Batch 18/64 loss: 0.310680627822876
Batch 19/64 loss: 0.3013789653778076
Batch 20/64 loss: 0.3110595941543579
Batch 21/64 loss: 0.30332863330841064
Batch 22/64 loss: 0.3144594430923462
Batch 23/64 loss: 0.3152850270271301
Batch 24/64 loss: 0.30569350719451904
Batch 25/64 loss: 0.30984604358673096
Batch 26/64 loss: 0.3078223466873169
Batch 27/64 loss: 0.3066261410713196
Batch 28/64 loss: 0.30731523036956787
Batch 29/64 loss: 0.3049290180206299
Batch 30/64 loss: 0.30219709873199463
Batch 31/64 loss: 0.3025779724121094
Batch 32/64 loss: 0.3144270181655884
Batch 33/64 loss: 0.299426794052124
Batch 34/64 loss: 0.3100382089614868
Batch 35/64 loss: 0.3108886480331421
Batch 36/64 loss: 0.3126567602157593
Batch 37/64 loss: 0.3098421096801758
Batch 38/64 loss: 0.3120502829551697
Batch 39/64 loss: 0.30808019638061523
Batch 40/64 loss: 0.3140224814414978
Batch 41/64 loss: 0.3175886273384094
Batch 42/64 loss: 0.3015981912612915
Batch 43/64 loss: 0.3066732883453369
Batch 44/64 loss: 0.3044009208679199
Batch 45/64 loss: 0.3083268404006958
Batch 46/64 loss: 0.30933433771133423
Batch 47/64 loss: 0.3173638582229614
Batch 48/64 loss: 0.3122873306274414
Batch 49/64 loss: 0.30873388051986694
Batch 50/64 loss: 0.3143380880355835
Batch 51/64 loss: 0.3118816614151001
Batch 52/64 loss: 0.30194592475891113
Batch 53/64 loss: 0.30923140048980713
Batch 54/64 loss: 0.3023316264152527
Batch 55/64 loss: 0.3037136197090149
Batch 56/64 loss: 0.30830705165863037
Batch 57/64 loss: 0.3094801902770996
Batch 58/64 loss: 0.30570685863494873
Batch 59/64 loss: 0.3051825761795044
Batch 60/64 loss: 0.3084344267845154
Batch 61/64 loss: 0.3131321668624878
Batch 62/64 loss: 0.3076167106628418
Batch 63/64 loss: 0.3181546926498413
Batch 64/64 loss: 0.3160668611526489
Epoch 367  Train loss: 0.30902712625615736  Val loss: 0.3342778596681418
Epoch 368
-------------------------------
Batch 1/64 loss: 0.3108934164047241
Batch 2/64 loss: 0.3071070909500122
Batch 3/64 loss: 0.3049051761627197
Batch 4/64 loss: 0.30962514877319336
Batch 5/64 loss: 0.29958057403564453
Batch 6/64 loss: 0.30807507038116455
Batch 7/64 loss: 0.3191757798194885
Batch 8/64 loss: 0.3060927391052246
Batch 9/64 loss: 0.3039027452468872
Batch 10/64 loss: 0.3155454993247986
Batch 11/64 loss: 0.30374205112457275
Batch 12/64 loss: 0.31389665603637695
Batch 13/64 loss: 0.2954421043395996
Batch 14/64 loss: 0.3166694641113281
Batch 15/64 loss: 0.301044225692749
Batch 16/64 loss: 0.31003713607788086
Batch 17/64 loss: 0.31779050827026367
Batch 18/64 loss: 0.3166773319244385
Batch 19/64 loss: 0.3105250597000122
Batch 20/64 loss: 0.30206143856048584
Batch 21/64 loss: 0.2993752956390381
Batch 22/64 loss: 0.31541907787323
Batch 23/64 loss: 0.3158125877380371
Batch 24/64 loss: 0.31482553482055664
Batch 25/64 loss: 0.3006468415260315
Batch 26/64 loss: 0.312183141708374
Batch 27/64 loss: 0.3121100664138794
Batch 28/64 loss: 0.31850099563598633
Batch 29/64 loss: 0.3070129156112671
Batch 30/64 loss: 0.30701184272766113
Batch 31/64 loss: 0.30757641792297363
Batch 32/64 loss: 0.31333911418914795
Batch 33/64 loss: 0.31493985652923584
Batch 34/64 loss: 0.3086739182472229
Batch 35/64 loss: 0.3089860677719116
Batch 36/64 loss: 0.30203843116760254
Batch 37/64 loss: 0.3110949993133545
Batch 38/64 loss: 0.30924367904663086
Batch 39/64 loss: 0.3121616840362549
Batch 40/64 loss: 0.3090443015098572
Batch 41/64 loss: 0.30860191583633423
Batch 42/64 loss: 0.30777764320373535
Batch 43/64 loss: 0.30339741706848145
Batch 44/64 loss: 0.30210280418395996
Batch 45/64 loss: 0.314047634601593
Batch 46/64 loss: 0.2958507537841797
Batch 47/64 loss: 0.3075215220451355
Batch 48/64 loss: 0.30908966064453125
Batch 49/64 loss: 0.30734074115753174
Batch 50/64 loss: 0.31224942207336426
Batch 51/64 loss: 0.30842816829681396
Batch 52/64 loss: 0.31088846921920776
Batch 53/64 loss: 0.3169143795967102
Batch 54/64 loss: 0.31375640630722046
Batch 55/64 loss: 0.3080465793609619
Batch 56/64 loss: 0.2969754934310913
Batch 57/64 loss: 0.30734843015670776
Batch 58/64 loss: 0.3137306571006775
Batch 59/64 loss: 0.3115171790122986
Batch 60/64 loss: 0.31075960397720337
Batch 61/64 loss: 0.3143877387046814
Batch 62/64 loss: 0.31542694568634033
Batch 63/64 loss: 0.31106293201446533
Batch 64/64 loss: 0.31024712324142456
Epoch 368  Train loss: 0.30921872667237826  Val loss: 0.3352069621233596
Epoch 369
-------------------------------
Batch 1/64 loss: 0.3054850101470947
Batch 2/64 loss: 0.30180805921554565
Batch 3/64 loss: 0.31122463941574097
Batch 4/64 loss: 0.307023286819458
Batch 5/64 loss: 0.30503857135772705
Batch 6/64 loss: 0.2969014644622803
Batch 7/64 loss: 0.31124407052993774
Batch 8/64 loss: 0.3085711598396301
Batch 9/64 loss: 0.3166494369506836
Batch 10/64 loss: 0.3070840835571289
Batch 11/64 loss: 0.30406951904296875
Batch 12/64 loss: 0.3131985664367676
Batch 13/64 loss: 0.31251394748687744
Batch 14/64 loss: 0.3197721242904663
Batch 15/64 loss: 0.3078896403312683
Batch 16/64 loss: 0.3156120777130127
Batch 17/64 loss: 0.30682575702667236
Batch 18/64 loss: 0.30329227447509766
Batch 19/64 loss: 0.31009578704833984
Batch 20/64 loss: 0.3049101233482361
Batch 21/64 loss: 0.3092295527458191
Batch 22/64 loss: 0.3141489028930664
Batch 23/64 loss: 0.30852043628692627
Batch 24/64 loss: 0.31288570165634155
Batch 25/64 loss: 0.3138916492462158
Batch 26/64 loss: 0.3077206611633301
Batch 27/64 loss: 0.3124038577079773
Batch 28/64 loss: 0.30961573123931885
Batch 29/64 loss: 0.32075971364974976
Batch 30/64 loss: 0.3180004954338074
Batch 31/64 loss: 0.30974864959716797
Batch 32/64 loss: 0.31115978956222534
Batch 33/64 loss: 0.30711257457733154
Batch 34/64 loss: 0.30238813161849976
Batch 35/64 loss: 0.314957857131958
Batch 36/64 loss: 0.31244516372680664
Batch 37/64 loss: 0.31386494636535645
Batch 38/64 loss: 0.2978755235671997
Batch 39/64 loss: 0.3062182664871216
Batch 40/64 loss: 0.32353711128234863
Batch 41/64 loss: 0.30985748767852783
Batch 42/64 loss: 0.312780499458313
Batch 43/64 loss: 0.30054253339767456
Batch 44/64 loss: 0.3065594434738159
Batch 45/64 loss: 0.30667364597320557
Batch 46/64 loss: 0.31494593620300293
Batch 47/64 loss: 0.30798763036727905
Batch 48/64 loss: 0.30280137062072754
Batch 49/64 loss: 0.30999279022216797
Batch 50/64 loss: 0.317563533782959
Batch 51/64 loss: 0.30775827169418335
Batch 52/64 loss: 0.3047541379928589
Batch 53/64 loss: 0.31119275093078613
Batch 54/64 loss: 0.30549776554107666
Batch 55/64 loss: 0.307497501373291
Batch 56/64 loss: 0.30849647521972656
Batch 57/64 loss: 0.3150465488433838
Batch 58/64 loss: 0.303680419921875
Batch 59/64 loss: 0.3078446388244629
Batch 60/64 loss: 0.3042179346084595
Batch 61/64 loss: 0.3060779571533203
Batch 62/64 loss: 0.3125292658805847
Batch 63/64 loss: 0.3052716851234436
Batch 64/64 loss: 0.3127456307411194
Epoch 369  Train loss: 0.3093305688278348  Val loss: 0.33294094755887166
Epoch 370
-------------------------------
Batch 1/64 loss: 0.31157052516937256
Batch 2/64 loss: 0.2961087226867676
Batch 3/64 loss: 0.3054460883140564
Batch 4/64 loss: 0.3147503137588501
Batch 5/64 loss: 0.30532342195510864
Batch 6/64 loss: 0.2988571524620056
Batch 7/64 loss: 0.31042343378067017
Batch 8/64 loss: 0.3157217502593994
Batch 9/64 loss: 0.3008212447166443
Batch 10/64 loss: 0.3025558590888977
Batch 11/64 loss: 0.31728285551071167
Batch 12/64 loss: 0.3115178346633911
Batch 13/64 loss: 0.30360496044158936
Batch 14/64 loss: 0.3072107434272766
Batch 15/64 loss: 0.30230432748794556
Batch 16/64 loss: 0.3148599863052368
Batch 17/64 loss: 0.3210117220878601
Batch 18/64 loss: 0.31166982650756836
Batch 19/64 loss: 0.30609750747680664
Batch 20/64 loss: 0.31102412939071655
Batch 21/64 loss: 0.3071744441986084
Batch 22/64 loss: 0.30866265296936035
Batch 23/64 loss: 0.3183668851852417
Batch 24/64 loss: 0.29751139879226685
Batch 25/64 loss: 0.3052827715873718
Batch 26/64 loss: 0.31339287757873535
Batch 27/64 loss: 0.31225115060806274
Batch 28/64 loss: 0.3140099048614502
Batch 29/64 loss: 0.3006841540336609
Batch 30/64 loss: 0.30725526809692383
Batch 31/64 loss: 0.30579519271850586
Batch 32/64 loss: 0.31836652755737305
Batch 33/64 loss: 0.30310142040252686
Batch 34/64 loss: 0.303708016872406
Batch 35/64 loss: 0.309876024723053
Batch 36/64 loss: 0.30056220293045044
Batch 37/64 loss: 0.30325382947921753
Batch 38/64 loss: 0.30002856254577637
Batch 39/64 loss: 0.31296002864837646
Batch 40/64 loss: 0.30236029624938965
Batch 41/64 loss: 0.30749285221099854
Batch 42/64 loss: 0.31012624502182007
Batch 43/64 loss: 0.3090030550956726
Batch 44/64 loss: 0.3043319582939148
Batch 45/64 loss: 0.31910765171051025
Batch 46/64 loss: 0.31157588958740234
Batch 47/64 loss: 0.308652400970459
Batch 48/64 loss: 0.2988407015800476
Batch 49/64 loss: 0.3081016540527344
Batch 50/64 loss: 0.31738871335983276
Batch 51/64 loss: 0.3186982274055481
Batch 52/64 loss: 0.31688177585601807
Batch 53/64 loss: 0.3253801465034485
Batch 54/64 loss: 0.3103739023208618
Batch 55/64 loss: 0.31582313776016235
Batch 56/64 loss: 0.3166213035583496
Batch 57/64 loss: 0.3080798387527466
Batch 58/64 loss: 0.31707096099853516
Batch 59/64 loss: 0.3052304983139038
Batch 60/64 loss: 0.3049249053001404
Batch 61/64 loss: 0.3089444041252136
Batch 62/64 loss: 0.3075779676437378
Batch 63/64 loss: 0.31955093145370483
Batch 64/64 loss: 0.30420947074890137
Epoch 370  Train loss: 0.30918748612497365  Val loss: 0.3353327086701016
Epoch 371
-------------------------------
Batch 1/64 loss: 0.3124966621398926
Batch 2/64 loss: 0.30407822132110596
Batch 3/64 loss: 0.3105854392051697
Batch 4/64 loss: 0.3033599853515625
Batch 5/64 loss: 0.30758512020111084
Batch 6/64 loss: 0.2992825508117676
Batch 7/64 loss: 0.2979501485824585
Batch 8/64 loss: 0.31354373693466187
Batch 9/64 loss: 0.30894291400909424
Batch 10/64 loss: 0.30352306365966797
Batch 11/64 loss: 0.30376213788986206
Batch 12/64 loss: 0.30885541439056396
Batch 13/64 loss: 0.3139519691467285
Batch 14/64 loss: 0.3026009202003479
Batch 15/64 loss: 0.31666284799575806
Batch 16/64 loss: 0.3134687542915344
Batch 17/64 loss: 0.30760514736175537
Batch 18/64 loss: 0.3127783536911011
Batch 19/64 loss: 0.3058958053588867
Batch 20/64 loss: 0.3183465003967285
Batch 21/64 loss: 0.3088969588279724
Batch 22/64 loss: 0.3129311800003052
Batch 23/64 loss: 0.3097366690635681
Batch 24/64 loss: 0.31951403617858887
Batch 25/64 loss: 0.32007288932800293
Batch 26/64 loss: 0.30920445919036865
Batch 27/64 loss: 0.3070181608200073
Batch 28/64 loss: 0.3114727735519409
Batch 29/64 loss: 0.30732935667037964
Batch 30/64 loss: 0.3090147376060486
Batch 31/64 loss: 0.30449020862579346
Batch 32/64 loss: 0.3069725036621094
Batch 33/64 loss: 0.3285367488861084
Batch 34/64 loss: 0.30506473779678345
Batch 35/64 loss: 0.3067655563354492
Batch 36/64 loss: 0.3081892132759094
Batch 37/64 loss: 0.30814236402511597
Batch 38/64 loss: 0.3084491491317749
Batch 39/64 loss: 0.31087684631347656
Batch 40/64 loss: 0.3035588264465332
Batch 41/64 loss: 0.3017808198928833
Batch 42/64 loss: 0.303570032119751
Batch 43/64 loss: 0.31159287691116333
Batch 44/64 loss: 0.3061405420303345
Batch 45/64 loss: 0.3038907051086426
Batch 46/64 loss: 0.3024579882621765
Batch 47/64 loss: 0.3012710213661194
Batch 48/64 loss: 0.315437912940979
Batch 49/64 loss: 0.3033766746520996
Batch 50/64 loss: 0.31023192405700684
Batch 51/64 loss: 0.3113890290260315
Batch 52/64 loss: 0.30466896295547485
Batch 53/64 loss: 0.31606292724609375
Batch 54/64 loss: 0.30842888355255127
Batch 55/64 loss: 0.315825879573822
Batch 56/64 loss: 0.3106400966644287
Batch 57/64 loss: 0.30282461643218994
Batch 58/64 loss: 0.31748831272125244
Batch 59/64 loss: 0.31204289197921753
Batch 60/64 loss: 0.3083893656730652
Batch 61/64 loss: 0.30705803632736206
Batch 62/64 loss: 0.3108251094818115
Batch 63/64 loss: 0.31071215867996216
Batch 64/64 loss: 0.3040066957473755
Epoch 371  Train loss: 0.3089509781669168  Val loss: 0.3340863786202526
Epoch 372
-------------------------------
Batch 1/64 loss: 0.2999751567840576
Batch 2/64 loss: 0.30222171545028687
Batch 3/64 loss: 0.3164454698562622
Batch 4/64 loss: 0.31367528438568115
Batch 5/64 loss: 0.3102247714996338
Batch 6/64 loss: 0.3087773323059082
Batch 7/64 loss: 0.30570733547210693
Batch 8/64 loss: 0.30729126930236816
Batch 9/64 loss: 0.3103330135345459
Batch 10/64 loss: 0.3109419345855713
Batch 11/64 loss: 0.3196316957473755
Batch 12/64 loss: 0.308072030544281
Batch 13/64 loss: 0.30955320596694946
Batch 14/64 loss: 0.31481993198394775
Batch 15/64 loss: 0.3106198310852051
Batch 16/64 loss: 0.3048354387283325
Batch 17/64 loss: 0.3144153356552124
Batch 18/64 loss: 0.3068345785140991
Batch 19/64 loss: 0.30470800399780273
Batch 20/64 loss: 0.3051185607910156
Batch 21/64 loss: 0.3054431676864624
Batch 22/64 loss: 0.30481457710266113
Batch 23/64 loss: 0.3059001564979553
Batch 24/64 loss: 0.3121769428253174
Batch 25/64 loss: 0.2964162230491638
Batch 26/64 loss: 0.30999934673309326
Batch 27/64 loss: 0.30492520332336426
Batch 28/64 loss: 0.30991679430007935
Batch 29/64 loss: 0.31469017267227173
Batch 30/64 loss: 0.30075955390930176
Batch 31/64 loss: 0.3118172883987427
Batch 32/64 loss: 0.3143628239631653
Batch 33/64 loss: 0.3207055330276489
Batch 34/64 loss: 0.3062601089477539
Batch 35/64 loss: 0.3110572099685669
Batch 36/64 loss: 0.2985074520111084
Batch 37/64 loss: 0.3090144991874695
Batch 38/64 loss: 0.30587130784988403
Batch 39/64 loss: 0.3122999668121338
Batch 40/64 loss: 0.3124096989631653
Batch 41/64 loss: 0.31215012073516846
Batch 42/64 loss: 0.315537691116333
Batch 43/64 loss: 0.31708085536956787
Batch 44/64 loss: 0.3036816716194153
Batch 45/64 loss: 0.3043845295906067
Batch 46/64 loss: 0.3165239095687866
Batch 47/64 loss: 0.3141222596168518
Batch 48/64 loss: 0.3072776198387146
Batch 49/64 loss: 0.30453717708587646
Batch 50/64 loss: 0.31360185146331787
Batch 51/64 loss: 0.30631160736083984
Batch 52/64 loss: 0.3144484758377075
Batch 53/64 loss: 0.3123584985733032
Batch 54/64 loss: 0.31286370754241943
Batch 55/64 loss: 0.3073163628578186
Batch 56/64 loss: 0.31505417823791504
Batch 57/64 loss: 0.30088210105895996
Batch 58/64 loss: 0.3111933469772339
Batch 59/64 loss: 0.3074774742126465
Batch 60/64 loss: 0.31043314933776855
Batch 61/64 loss: 0.31120240688323975
Batch 62/64 loss: 0.3053421974182129
Batch 63/64 loss: 0.3029358983039856
Batch 64/64 loss: 0.3079019784927368
Epoch 372  Train loss: 0.3091638195748423  Val loss: 0.33403257631354316
Epoch 373
-------------------------------
Batch 1/64 loss: 0.31326866149902344
Batch 2/64 loss: 0.29706037044525146
Batch 3/64 loss: 0.30702871084213257
Batch 4/64 loss: 0.3111268877983093
Batch 5/64 loss: 0.3012440800666809
Batch 6/64 loss: 0.3081359267234802
Batch 7/64 loss: 0.3065120577812195
Batch 8/64 loss: 0.3005051612854004
Batch 9/64 loss: 0.3210551142692566
Batch 10/64 loss: 0.30322742462158203
Batch 11/64 loss: 0.31390655040740967
Batch 12/64 loss: 0.32408374547958374
Batch 13/64 loss: 0.31481683254241943
Batch 14/64 loss: 0.30780601501464844
Batch 15/64 loss: 0.29940271377563477
Batch 16/64 loss: 0.30972564220428467
Batch 17/64 loss: 0.30426716804504395
Batch 18/64 loss: 0.3020753860473633
Batch 19/64 loss: 0.31258636713027954
Batch 20/64 loss: 0.3117644190788269
Batch 21/64 loss: 0.3028146028518677
Batch 22/64 loss: 0.31017136573791504
Batch 23/64 loss: 0.3144548535346985
Batch 24/64 loss: 0.3115653991699219
Batch 25/64 loss: 0.3038419485092163
Batch 26/64 loss: 0.3078650236129761
Batch 27/64 loss: 0.3125941753387451
Batch 28/64 loss: 0.30888795852661133
Batch 29/64 loss: 0.30994391441345215
Batch 30/64 loss: 0.3059238791465759
Batch 31/64 loss: 0.3057515621185303
Batch 32/64 loss: 0.31492722034454346
Batch 33/64 loss: 0.3089172840118408
Batch 34/64 loss: 0.30883824825286865
Batch 35/64 loss: 0.3087416887283325
Batch 36/64 loss: 0.315144419670105
Batch 37/64 loss: 0.30290448665618896
Batch 38/64 loss: 0.30584293603897095
Batch 39/64 loss: 0.31894630193710327
Batch 40/64 loss: 0.30308496952056885
Batch 41/64 loss: 0.3182998299598694
Batch 42/64 loss: 0.2995033264160156
Batch 43/64 loss: 0.30840104818344116
Batch 44/64 loss: 0.3022986650466919
Batch 45/64 loss: 0.3210051655769348
Batch 46/64 loss: 0.3119572401046753
Batch 47/64 loss: 0.31109917163848877
Batch 48/64 loss: 0.3102147579193115
Batch 49/64 loss: 0.3091201186180115
Batch 50/64 loss: 0.30560582876205444
Batch 51/64 loss: 0.30547499656677246
Batch 52/64 loss: 0.31348538398742676
Batch 53/64 loss: 0.30266785621643066
Batch 54/64 loss: 0.3041759729385376
Batch 55/64 loss: 0.3107720613479614
Batch 56/64 loss: 0.31644606590270996
Batch 57/64 loss: 0.30473029613494873
Batch 58/64 loss: 0.3010539412498474
Batch 59/64 loss: 0.3028598427772522
Batch 60/64 loss: 0.30138957500457764
Batch 61/64 loss: 0.31120002269744873
Batch 62/64 loss: 0.3150409460067749
Batch 63/64 loss: 0.3050283193588257
Batch 64/64 loss: 0.3112977147102356
Epoch 373  Train loss: 0.30864415986865174  Val loss: 0.3338560308377767
Epoch 374
-------------------------------
Batch 1/64 loss: 0.3034696578979492
Batch 2/64 loss: 0.314969539642334
Batch 3/64 loss: 0.3065088987350464
Batch 4/64 loss: 0.2934544086456299
Batch 5/64 loss: 0.3103986978530884
Batch 6/64 loss: 0.3137325048446655
Batch 7/64 loss: 0.2981536388397217
Batch 8/64 loss: 0.3069554567337036
Batch 9/64 loss: 0.3159067630767822
Batch 10/64 loss: 0.3026973009109497
Batch 11/64 loss: 0.305170476436615
Batch 12/64 loss: 0.3033503293991089
Batch 13/64 loss: 0.29955124855041504
Batch 14/64 loss: 0.3112494945526123
Batch 15/64 loss: 0.3074749708175659
Batch 16/64 loss: 0.3050205707550049
Batch 17/64 loss: 0.30527210235595703
Batch 18/64 loss: 0.30626070499420166
Batch 19/64 loss: 0.3115847110748291
Batch 20/64 loss: 0.3007381558418274
Batch 21/64 loss: 0.30593764781951904
Batch 22/64 loss: 0.3059499263763428
Batch 23/64 loss: 0.3151177763938904
Batch 24/64 loss: 0.31754541397094727
Batch 25/64 loss: 0.31056058406829834
Batch 26/64 loss: 0.3099020719528198
Batch 27/64 loss: 0.30587905645370483
Batch 28/64 loss: 0.3160068988800049
Batch 29/64 loss: 0.29926323890686035
Batch 30/64 loss: 0.3122997283935547
Batch 31/64 loss: 0.3136258125305176
Batch 32/64 loss: 0.3059685230255127
Batch 33/64 loss: 0.3069445490837097
Batch 34/64 loss: 0.3108576536178589
Batch 35/64 loss: 0.31145012378692627
Batch 36/64 loss: 0.3137466311454773
Batch 37/64 loss: 0.30973201990127563
Batch 38/64 loss: 0.30270814895629883
Batch 39/64 loss: 0.31240302324295044
Batch 40/64 loss: 0.32404690980911255
Batch 41/64 loss: 0.31677961349487305
Batch 42/64 loss: 0.3122575283050537
Batch 43/64 loss: 0.31722402572631836
Batch 44/64 loss: 0.3123403787612915
Batch 45/64 loss: 0.3138233423233032
Batch 46/64 loss: 0.3109854459762573
Batch 47/64 loss: 0.30246251821517944
Batch 48/64 loss: 0.30850303173065186
Batch 49/64 loss: 0.31158268451690674
Batch 50/64 loss: 0.3049503564834595
Batch 51/64 loss: 0.3165276050567627
Batch 52/64 loss: 0.30202561616897583
Batch 53/64 loss: 0.3027114272117615
Batch 54/64 loss: 0.30719637870788574
Batch 55/64 loss: 0.3128073811531067
Batch 56/64 loss: 0.3132188320159912
Batch 57/64 loss: 0.3018617630004883
Batch 58/64 loss: 0.30806028842926025
Batch 59/64 loss: 0.3046419620513916
Batch 60/64 loss: 0.31271493434906006
Batch 61/64 loss: 0.30865949392318726
Batch 62/64 loss: 0.31583070755004883
Batch 63/64 loss: 0.3111114501953125
Batch 64/64 loss: 0.312497615814209
Epoch 374  Train loss: 0.30893357407812977  Val loss: 0.33617840845560293
Epoch 375
-------------------------------
Batch 1/64 loss: 0.312838077545166
Batch 2/64 loss: 0.30998748540878296
Batch 3/64 loss: 0.30768221616744995
Batch 4/64 loss: 0.3056800365447998
Batch 5/64 loss: 0.3091171979904175
Batch 6/64 loss: 0.3056291341781616
Batch 7/64 loss: 0.3124464750289917
Batch 8/64 loss: 0.3053569793701172
Batch 9/64 loss: 0.3181517720222473
Batch 10/64 loss: 0.310451865196228
Batch 11/64 loss: 0.29697680473327637
Batch 12/64 loss: 0.3183024525642395
Batch 13/64 loss: 0.3044586777687073
Batch 14/64 loss: 0.3115156888961792
Batch 15/64 loss: 0.3086598515510559
Batch 16/64 loss: 0.31199151277542114
Batch 17/64 loss: 0.3110523223876953
Batch 18/64 loss: 0.31311070919036865
Batch 19/64 loss: 0.30499207973480225
Batch 20/64 loss: 0.3078994154930115
Batch 21/64 loss: 0.3212472200393677
Batch 22/64 loss: 0.30969876050949097
Batch 23/64 loss: 0.3114936351776123
Batch 24/64 loss: 0.3080143332481384
Batch 25/64 loss: 0.308965802192688
Batch 26/64 loss: 0.3105018138885498
Batch 27/64 loss: 0.30957573652267456
Batch 28/64 loss: 0.3059554100036621
Batch 29/64 loss: 0.2997446060180664
Batch 30/64 loss: 0.31398940086364746
Batch 31/64 loss: 0.3148847222328186
Batch 32/64 loss: 0.30917084217071533
Batch 33/64 loss: 0.30449897050857544
Batch 34/64 loss: 0.31329160928726196
Batch 35/64 loss: 0.3163605332374573
Batch 36/64 loss: 0.30898815393447876
Batch 37/64 loss: 0.3160017728805542
Batch 38/64 loss: 0.3054918050765991
Batch 39/64 loss: 0.3022916316986084
Batch 40/64 loss: 0.304623007774353
Batch 41/64 loss: 0.30570435523986816
Batch 42/64 loss: 0.31676387786865234
Batch 43/64 loss: 0.29996979236602783
Batch 44/64 loss: 0.30072593688964844
Batch 45/64 loss: 0.31066960096359253
Batch 46/64 loss: 0.30755937099456787
Batch 47/64 loss: 0.30455243587493896
Batch 48/64 loss: 0.31135761737823486
Batch 49/64 loss: 0.3085061311721802
Batch 50/64 loss: 0.30649328231811523
Batch 51/64 loss: 0.30788397789001465
Batch 52/64 loss: 0.30562877655029297
Batch 53/64 loss: 0.30469536781311035
Batch 54/64 loss: 0.30963122844696045
Batch 55/64 loss: 0.30505287647247314
Batch 56/64 loss: 0.3043302297592163
Batch 57/64 loss: 0.31204450130462646
Batch 58/64 loss: 0.3080715537071228
Batch 59/64 loss: 0.31143879890441895
Batch 60/64 loss: 0.3122774362564087
Batch 61/64 loss: 0.3253435492515564
Batch 62/64 loss: 0.2979152202606201
Batch 63/64 loss: 0.30160462856292725
Batch 64/64 loss: 0.3006284236907959
Epoch 375  Train loss: 0.30878090016982135  Val loss: 0.3330622585778384
Epoch 376
-------------------------------
Batch 1/64 loss: 0.3069823980331421
Batch 2/64 loss: 0.3073892593383789
Batch 3/64 loss: 0.3133353590965271
Batch 4/64 loss: 0.31142616271972656
Batch 5/64 loss: 0.3204869031906128
Batch 6/64 loss: 0.29377424716949463
Batch 7/64 loss: 0.3082975149154663
Batch 8/64 loss: 0.3108741044998169
Batch 9/64 loss: 0.310968279838562
Batch 10/64 loss: 0.3077046871185303
Batch 11/64 loss: 0.304892897605896
Batch 12/64 loss: 0.3124988079071045
Batch 13/64 loss: 0.3056553602218628
Batch 14/64 loss: 0.30998873710632324
Batch 15/64 loss: 0.3136786222457886
Batch 16/64 loss: 0.3145715594291687
Batch 17/64 loss: 0.3065052628517151
Batch 18/64 loss: 0.30133283138275146
Batch 19/64 loss: 0.3025282621383667
Batch 20/64 loss: 0.3059846758842468
Batch 21/64 loss: 0.31129544973373413
Batch 22/64 loss: 0.3099987506866455
Batch 23/64 loss: 0.31211286783218384
Batch 24/64 loss: 0.3055047392845154
Batch 25/64 loss: 0.30979418754577637
Batch 26/64 loss: 0.3055201768875122
Batch 27/64 loss: 0.294466495513916
Batch 28/64 loss: 0.3107631802558899
Batch 29/64 loss: 0.31081289052963257
Batch 30/64 loss: 0.3103088140487671
Batch 31/64 loss: 0.30583488941192627
Batch 32/64 loss: 0.30539625883102417
Batch 33/64 loss: 0.3114331364631653
Batch 34/64 loss: 0.3205970525741577
Batch 35/64 loss: 0.30634385347366333
Batch 36/64 loss: 0.3072056174278259
Batch 37/64 loss: 0.2953643202781677
Batch 38/64 loss: 0.31202512979507446
Batch 39/64 loss: 0.3112376928329468
Batch 40/64 loss: 0.31087493896484375
Batch 41/64 loss: 0.31827884912490845
Batch 42/64 loss: 0.31958556175231934
Batch 43/64 loss: 0.3063279986381531
Batch 44/64 loss: 0.29956018924713135
Batch 45/64 loss: 0.30248719453811646
Batch 46/64 loss: 0.31172728538513184
Batch 47/64 loss: 0.3023505210876465
Batch 48/64 loss: 0.3127681016921997
Batch 49/64 loss: 0.3151843547821045
Batch 50/64 loss: 0.2991899251937866
Batch 51/64 loss: 0.3082055449485779
Batch 52/64 loss: 0.30439794063568115
Batch 53/64 loss: 0.31451350450515747
Batch 54/64 loss: 0.304828405380249
Batch 55/64 loss: 0.3050795793533325
Batch 56/64 loss: 0.30834680795669556
Batch 57/64 loss: 0.31353235244750977
Batch 58/64 loss: 0.31236541271209717
Batch 59/64 loss: 0.3055116534233093
Batch 60/64 loss: 0.30236876010894775
Batch 61/64 loss: 0.29973042011260986
Batch 62/64 loss: 0.30681777000427246
Batch 63/64 loss: 0.31259655952453613
Batch 64/64 loss: 0.3168628215789795
Epoch 376  Train loss: 0.30837910876554603  Val loss: 0.33312182573928045
Epoch 377
-------------------------------
Batch 1/64 loss: 0.3027121424674988
Batch 2/64 loss: 0.30873990058898926
Batch 3/64 loss: 0.3068509101867676
Batch 4/64 loss: 0.3032921552658081
Batch 5/64 loss: 0.3044981360435486
Batch 6/64 loss: 0.30348849296569824
Batch 7/64 loss: 0.3054817318916321
Batch 8/64 loss: 0.31063735485076904
Batch 9/64 loss: 0.29848766326904297
Batch 10/64 loss: 0.3129146695137024
Batch 11/64 loss: 0.3087936043739319
Batch 12/64 loss: 0.3101755380630493
Batch 13/64 loss: 0.3111463785171509
Batch 14/64 loss: 0.3091689348220825
Batch 15/64 loss: 0.29994291067123413
Batch 16/64 loss: 0.30210840702056885
Batch 17/64 loss: 0.3137058615684509
Batch 18/64 loss: 0.30728381872177124
Batch 19/64 loss: 0.31296151876449585
Batch 20/64 loss: 0.30321216583251953
Batch 21/64 loss: 0.3093074560165405
Batch 22/64 loss: 0.3152018189430237
Batch 23/64 loss: 0.312283992767334
Batch 24/64 loss: 0.2980204224586487
Batch 25/64 loss: 0.30690979957580566
Batch 26/64 loss: 0.30360162258148193
Batch 27/64 loss: 0.319088876247406
Batch 28/64 loss: 0.3096088171005249
Batch 29/64 loss: 0.30050432682037354
Batch 30/64 loss: 0.3099866509437561
Batch 31/64 loss: 0.310524582862854
Batch 32/64 loss: 0.300667405128479
Batch 33/64 loss: 0.31317663192749023
Batch 34/64 loss: 0.30320078134536743
Batch 35/64 loss: 0.3028320074081421
Batch 36/64 loss: 0.3068763017654419
Batch 37/64 loss: 0.3089364767074585
Batch 38/64 loss: 0.3073391914367676
Batch 39/64 loss: 0.3195618987083435
Batch 40/64 loss: 0.3097306489944458
Batch 41/64 loss: 0.3046722412109375
Batch 42/64 loss: 0.31182676553726196
Batch 43/64 loss: 0.3058825731277466
Batch 44/64 loss: 0.30816376209259033
Batch 45/64 loss: 0.30608946084976196
Batch 46/64 loss: 0.30914193391799927
Batch 47/64 loss: 0.30556631088256836
Batch 48/64 loss: 0.31446582078933716
Batch 49/64 loss: 0.31165188550949097
Batch 50/64 loss: 0.3116133213043213
Batch 51/64 loss: 0.30887144804000854
Batch 52/64 loss: 0.3106105923652649
Batch 53/64 loss: 0.3165719509124756
Batch 54/64 loss: 0.3144841194152832
Batch 55/64 loss: 0.30923891067504883
Batch 56/64 loss: 0.3079572319984436
Batch 57/64 loss: 0.3052380084991455
Batch 58/64 loss: 0.31081610918045044
Batch 59/64 loss: 0.3122110366821289
Batch 60/64 loss: 0.3034334182739258
Batch 61/64 loss: 0.3075220584869385
Batch 62/64 loss: 0.30156028270721436
Batch 63/64 loss: 0.3132011890411377
Batch 64/64 loss: 0.29435133934020996
Epoch 377  Train loss: 0.30799240691989077  Val loss: 0.33371168313567173
Epoch 378
-------------------------------
Batch 1/64 loss: 0.31193995475769043
Batch 2/64 loss: 0.314095675945282
Batch 3/64 loss: 0.3063989281654358
Batch 4/64 loss: 0.3006715774536133
Batch 5/64 loss: 0.3056052327156067
Batch 6/64 loss: 0.31241297721862793
Batch 7/64 loss: 0.30790913105010986
Batch 8/64 loss: 0.30186569690704346
Batch 9/64 loss: 0.3070812225341797
Batch 10/64 loss: 0.30969661474227905
Batch 11/64 loss: 0.30677998065948486
Batch 12/64 loss: 0.3165823817253113
Batch 13/64 loss: 0.311606764793396
Batch 14/64 loss: 0.3032805919647217
Batch 15/64 loss: 0.31805986166000366
Batch 16/64 loss: 0.3205885887145996
Batch 17/64 loss: 0.30764228105545044
Batch 18/64 loss: 0.30739831924438477
Batch 19/64 loss: 0.31082093715667725
Batch 20/64 loss: 0.3108111619949341
Batch 21/64 loss: 0.31149226427078247
Batch 22/64 loss: 0.30774855613708496
Batch 23/64 loss: 0.3047390580177307
Batch 24/64 loss: 0.3106895685195923
Batch 25/64 loss: 0.3039565682411194
Batch 26/64 loss: 0.3061099648475647
Batch 27/64 loss: 0.306427001953125
Batch 28/64 loss: 0.3084869980812073
Batch 29/64 loss: 0.30229949951171875
Batch 30/64 loss: 0.31314706802368164
Batch 31/64 loss: 0.30278629064559937
Batch 32/64 loss: 0.31436169147491455
Batch 33/64 loss: 0.3042186498641968
Batch 34/64 loss: 0.31365764141082764
Batch 35/64 loss: 0.31586968898773193
Batch 36/64 loss: 0.3072957992553711
Batch 37/64 loss: 0.3017135262489319
Batch 38/64 loss: 0.3067450523376465
Batch 39/64 loss: 0.3160554766654968
Batch 40/64 loss: 0.3126988410949707
Batch 41/64 loss: 0.3151031732559204
Batch 42/64 loss: 0.30811095237731934
Batch 43/64 loss: 0.31312263011932373
Batch 44/64 loss: 0.309734582901001
Batch 45/64 loss: 0.3080219030380249
Batch 46/64 loss: 0.3090847134590149
Batch 47/64 loss: 0.30639588832855225
Batch 48/64 loss: 0.3087918162345886
Batch 49/64 loss: 0.3080695867538452
Batch 50/64 loss: 0.30616724491119385
Batch 51/64 loss: 0.29591357707977295
Batch 52/64 loss: 0.3029664158821106
Batch 53/64 loss: 0.30184733867645264
Batch 54/64 loss: 0.31004029512405396
Batch 55/64 loss: 0.3024454116821289
Batch 56/64 loss: 0.3108351230621338
Batch 57/64 loss: 0.3149310350418091
Batch 58/64 loss: 0.31976819038391113
Batch 59/64 loss: 0.31214821338653564
Batch 60/64 loss: 0.31377482414245605
Batch 61/64 loss: 0.30065208673477173
Batch 62/64 loss: 0.30133306980133057
Batch 63/64 loss: 0.3075747489929199
Batch 64/64 loss: 0.30688655376434326
Epoch 378  Train loss: 0.30868619329789104  Val loss: 0.3346936852251951
Epoch 379
-------------------------------
Batch 1/64 loss: 0.3028165102005005
Batch 2/64 loss: 0.30659329891204834
Batch 3/64 loss: 0.3024095296859741
Batch 4/64 loss: 0.30425190925598145
Batch 5/64 loss: 0.30927324295043945
Batch 6/64 loss: 0.3003312349319458
Batch 7/64 loss: 0.30954527854919434
Batch 8/64 loss: 0.32357388734817505
Batch 9/64 loss: 0.30586421489715576
Batch 10/64 loss: 0.3097683787345886
Batch 11/64 loss: 0.3065483570098877
Batch 12/64 loss: 0.3136709928512573
Batch 13/64 loss: 0.3037140369415283
Batch 14/64 loss: 0.3024909496307373
Batch 15/64 loss: 0.31223881244659424
Batch 16/64 loss: 0.31178510189056396
Batch 17/64 loss: 0.30190056562423706
Batch 18/64 loss: 0.31205976009368896
Batch 19/64 loss: 0.3126007914543152
Batch 20/64 loss: 0.30335938930511475
Batch 21/64 loss: 0.3076016902923584
Batch 22/64 loss: 0.29825401306152344
Batch 23/64 loss: 0.3059084415435791
Batch 24/64 loss: 0.31013166904449463
Batch 25/64 loss: 0.30469799041748047
Batch 26/64 loss: 0.3022036552429199
Batch 27/64 loss: 0.30625003576278687
Batch 28/64 loss: 0.3161197900772095
Batch 29/64 loss: 0.3049243688583374
Batch 30/64 loss: 0.309847891330719
Batch 31/64 loss: 0.30806219577789307
Batch 32/64 loss: 0.29875701665878296
Batch 33/64 loss: 0.3140758275985718
Batch 34/64 loss: 0.3271315097808838
Batch 35/64 loss: 0.3070843815803528
Batch 36/64 loss: 0.30326902866363525
Batch 37/64 loss: 0.31427955627441406
Batch 38/64 loss: 0.30194634199142456
Batch 39/64 loss: 0.3068373203277588
Batch 40/64 loss: 0.3137202262878418
Batch 41/64 loss: 0.3190312385559082
Batch 42/64 loss: 0.3060568571090698
Batch 43/64 loss: 0.3147047758102417
Batch 44/64 loss: 0.3027588129043579
Batch 45/64 loss: 0.2978938817977905
Batch 46/64 loss: 0.30642616748809814
Batch 47/64 loss: 0.29661357402801514
Batch 48/64 loss: 0.30617618560791016
Batch 49/64 loss: 0.3127412796020508
Batch 50/64 loss: 0.30915331840515137
Batch 51/64 loss: 0.3058736324310303
Batch 52/64 loss: 0.3089616298675537
Batch 53/64 loss: 0.3126729726791382
Batch 54/64 loss: 0.3033638596534729
Batch 55/64 loss: 0.3057471513748169
Batch 56/64 loss: 0.3093419075012207
Batch 57/64 loss: 0.3070406913757324
Batch 58/64 loss: 0.3030928373336792
Batch 59/64 loss: 0.30316680669784546
Batch 60/64 loss: 0.31926870346069336
Batch 61/64 loss: 0.3205575942993164
Batch 62/64 loss: 0.2975621223449707
Batch 63/64 loss: 0.29956942796707153
Batch 64/64 loss: 0.3253145217895508
Epoch 379  Train loss: 0.30788487079096777  Val loss: 0.33398997066766534
Epoch 380
-------------------------------
Batch 1/64 loss: 0.30245691537857056
Batch 2/64 loss: 0.31085336208343506
Batch 3/64 loss: 0.31102657318115234
Batch 4/64 loss: 0.3042229413986206
Batch 5/64 loss: 0.3045876622200012
Batch 6/64 loss: 0.3082151412963867
Batch 7/64 loss: 0.30415868759155273
Batch 8/64 loss: 0.3115280866622925
Batch 9/64 loss: 0.3111734390258789
Batch 10/64 loss: 0.30809980630874634
Batch 11/64 loss: 0.3104122281074524
Batch 12/64 loss: 0.3087247610092163
Batch 13/64 loss: 0.3061369061470032
Batch 14/64 loss: 0.3064534664154053
Batch 15/64 loss: 0.31739234924316406
Batch 16/64 loss: 0.2962135076522827
Batch 17/64 loss: 0.31159746646881104
Batch 18/64 loss: 0.3016219139099121
Batch 19/64 loss: 0.3068523406982422
Batch 20/64 loss: 0.31209033727645874
Batch 21/64 loss: 0.304898738861084
Batch 22/64 loss: 0.2983483672142029
Batch 23/64 loss: 0.3053245544433594
Batch 24/64 loss: 0.31126582622528076
Batch 25/64 loss: 0.30147337913513184
Batch 26/64 loss: 0.3053932785987854
Batch 27/64 loss: 0.30843818187713623
Batch 28/64 loss: 0.3104710578918457
Batch 29/64 loss: 0.3012099862098694
Batch 30/64 loss: 0.30220144987106323
Batch 31/64 loss: 0.3144109845161438
Batch 32/64 loss: 0.30318593978881836
Batch 33/64 loss: 0.30543363094329834
Batch 34/64 loss: 0.3119337558746338
Batch 35/64 loss: 0.30685955286026
Batch 36/64 loss: 0.31291699409484863
Batch 37/64 loss: 0.30523061752319336
Batch 38/64 loss: 0.3022420406341553
Batch 39/64 loss: 0.30278587341308594
Batch 40/64 loss: 0.31594884395599365
Batch 41/64 loss: 0.31863218545913696
Batch 42/64 loss: 0.2988405227661133
Batch 43/64 loss: 0.3123331069946289
Batch 44/64 loss: 0.30256402492523193
Batch 45/64 loss: 0.3202958106994629
Batch 46/64 loss: 0.310777485370636
Batch 47/64 loss: 0.30829131603240967
Batch 48/64 loss: 0.3009378910064697
Batch 49/64 loss: 0.3065446615219116
Batch 50/64 loss: 0.31451189517974854
Batch 51/64 loss: 0.3052367568016052
Batch 52/64 loss: 0.3068852424621582
Batch 53/64 loss: 0.3067775368690491
Batch 54/64 loss: 0.3116089701652527
Batch 55/64 loss: 0.3047628402709961
Batch 56/64 loss: 0.3109566569328308
Batch 57/64 loss: 0.31274163722991943
Batch 58/64 loss: 0.31031715869903564
Batch 59/64 loss: 0.31004732847213745
Batch 60/64 loss: 0.30820053815841675
Batch 61/64 loss: 0.3021419048309326
Batch 62/64 loss: 0.3125482201576233
Batch 63/64 loss: 0.31168556213378906
Batch 64/64 loss: 0.31558090448379517
Epoch 380  Train loss: 0.30789201376484887  Val loss: 0.3333721545963353
Epoch 381
-------------------------------
Batch 1/64 loss: 0.30600881576538086
Batch 2/64 loss: 0.31252455711364746
Batch 3/64 loss: 0.30698782205581665
Batch 4/64 loss: 0.30230003595352173
Batch 5/64 loss: 0.3113787770271301
Batch 6/64 loss: 0.3022196292877197
Batch 7/64 loss: 0.30392688512802124
Batch 8/64 loss: 0.3109912872314453
Batch 9/64 loss: 0.305819571018219
Batch 10/64 loss: 0.3031954765319824
Batch 11/64 loss: 0.30697810649871826
Batch 12/64 loss: 0.30590200424194336
Batch 13/64 loss: 0.3186787962913513
Batch 14/64 loss: 0.30568647384643555
Batch 15/64 loss: 0.31165874004364014
Batch 16/64 loss: 0.32266509532928467
Batch 17/64 loss: 0.2958732843399048
Batch 18/64 loss: 0.31151914596557617
Batch 19/64 loss: 0.3033508062362671
Batch 20/64 loss: 0.3103010654449463
Batch 21/64 loss: 0.30821216106414795
Batch 22/64 loss: 0.3026443123817444
Batch 23/64 loss: 0.3060372471809387
Batch 24/64 loss: 0.309564471244812
Batch 25/64 loss: 0.29849672317504883
Batch 26/64 loss: 0.30621337890625
Batch 27/64 loss: 0.3128759264945984
Batch 28/64 loss: 0.3103334903717041
Batch 29/64 loss: 0.31382548809051514
Batch 30/64 loss: 0.30329984426498413
Batch 31/64 loss: 0.3150550127029419
Batch 32/64 loss: 0.3113057613372803
Batch 33/64 loss: 0.31049609184265137
Batch 34/64 loss: 0.3117648959159851
Batch 35/64 loss: 0.30876344442367554
Batch 36/64 loss: 0.309428334236145
Batch 37/64 loss: 0.30832457542419434
Batch 38/64 loss: 0.31491124629974365
Batch 39/64 loss: 0.3089331388473511
Batch 40/64 loss: 0.3093388080596924
Batch 41/64 loss: 0.3103595972061157
Batch 42/64 loss: 0.3044675588607788
Batch 43/64 loss: 0.30081605911254883
Batch 44/64 loss: 0.3019148111343384
Batch 45/64 loss: 0.3003923296928406
Batch 46/64 loss: 0.3078407049179077
Batch 47/64 loss: 0.3044232726097107
Batch 48/64 loss: 0.30563414096832275
Batch 49/64 loss: 0.3051677346229553
Batch 50/64 loss: 0.31124764680862427
Batch 51/64 loss: 0.3074464797973633
Batch 52/64 loss: 0.3103550672531128
Batch 53/64 loss: 0.3071103096008301
Batch 54/64 loss: 0.3063061237335205
Batch 55/64 loss: 0.3065692186355591
Batch 56/64 loss: 0.3064788579940796
Batch 57/64 loss: 0.31035059690475464
Batch 58/64 loss: 0.307448148727417
Batch 59/64 loss: 0.31557613611221313
Batch 60/64 loss: 0.3033909797668457
Batch 61/64 loss: 0.3045305609703064
Batch 62/64 loss: 0.31414639949798584
Batch 63/64 loss: 0.3110119700431824
Batch 64/64 loss: 0.30903029441833496
Epoch 381  Train loss: 0.30796153966118306  Val loss: 0.33314964124017565
Epoch 382
-------------------------------
Batch 1/64 loss: 0.2977474331855774
Batch 2/64 loss: 0.3091568946838379
Batch 3/64 loss: 0.3214137554168701
Batch 4/64 loss: 0.31577539443969727
Batch 5/64 loss: 0.31716471910476685
Batch 6/64 loss: 0.31162047386169434
Batch 7/64 loss: 0.30431902408599854
Batch 8/64 loss: 0.3076837658882141
Batch 9/64 loss: 0.3044624924659729
Batch 10/64 loss: 0.29869401454925537
Batch 11/64 loss: 0.30621445178985596
Batch 12/64 loss: 0.3079983592033386
Batch 13/64 loss: 0.31392180919647217
Batch 14/64 loss: 0.30203700065612793
Batch 15/64 loss: 0.3025318384170532
Batch 16/64 loss: 0.3024434447288513
Batch 17/64 loss: 0.30533450841903687
Batch 18/64 loss: 0.3046538829803467
Batch 19/64 loss: 0.3097938299179077
Batch 20/64 loss: 0.30413490533828735
Batch 21/64 loss: 0.3163343667984009
Batch 22/64 loss: 0.3018381595611572
Batch 23/64 loss: 0.31577932834625244
Batch 24/64 loss: 0.3101605176925659
Batch 25/64 loss: 0.303912878036499
Batch 26/64 loss: 0.30758213996887207
Batch 27/64 loss: 0.3028193712234497
Batch 28/64 loss: 0.30182886123657227
Batch 29/64 loss: 0.31163668632507324
Batch 30/64 loss: 0.3018353581428528
Batch 31/64 loss: 0.30655932426452637
Batch 32/64 loss: 0.3118591904640198
Batch 33/64 loss: 0.32102251052856445
Batch 34/64 loss: 0.3007832169532776
Batch 35/64 loss: 0.3201638460159302
Batch 36/64 loss: 0.3102080821990967
Batch 37/64 loss: 0.30596280097961426
Batch 38/64 loss: 0.30721527338027954
Batch 39/64 loss: 0.3042711615562439
Batch 40/64 loss: 0.30600327253341675
Batch 41/64 loss: 0.3101576566696167
Batch 42/64 loss: 0.3061937093734741
Batch 43/64 loss: 0.29928624629974365
Batch 44/64 loss: 0.30434370040893555
Batch 45/64 loss: 0.3098878860473633
Batch 46/64 loss: 0.3087090849876404
Batch 47/64 loss: 0.30766063928604126
Batch 48/64 loss: 0.30874931812286377
Batch 49/64 loss: 0.3099921941757202
Batch 50/64 loss: 0.3033113479614258
Batch 51/64 loss: 0.30360615253448486
Batch 52/64 loss: 0.31148457527160645
Batch 53/64 loss: 0.3061060905456543
Batch 54/64 loss: 0.30562543869018555
Batch 55/64 loss: 0.31065356731414795
Batch 56/64 loss: 0.3031957745552063
Batch 57/64 loss: 0.30570024251937866
Batch 58/64 loss: 0.3057360053062439
Batch 59/64 loss: 0.31192314624786377
Batch 60/64 loss: 0.3061889410018921
Batch 61/64 loss: 0.3015800714492798
Batch 62/64 loss: 0.30391252040863037
Batch 63/64 loss: 0.3108048439025879
Batch 64/64 loss: 0.30142152309417725
Epoch 382  Train loss: 0.3073843708225325  Val loss: 0.3335722959328353
Epoch 383
-------------------------------
Batch 1/64 loss: 0.30110371112823486
Batch 2/64 loss: 0.31756651401519775
Batch 3/64 loss: 0.29998427629470825
Batch 4/64 loss: 0.29210197925567627
Batch 5/64 loss: 0.30803531408309937
Batch 6/64 loss: 0.3108024001121521
Batch 7/64 loss: 0.2992059588432312
Batch 8/64 loss: 0.29978132247924805
Batch 9/64 loss: 0.3192850351333618
Batch 10/64 loss: 0.3028275966644287
Batch 11/64 loss: 0.3291677236557007
Batch 12/64 loss: 0.30391883850097656
Batch 13/64 loss: 0.30456340312957764
Batch 14/64 loss: 0.31519120931625366
Batch 15/64 loss: 0.30730336904525757
Batch 16/64 loss: 0.3108426332473755
Batch 17/64 loss: 0.3133365511894226
Batch 18/64 loss: 0.3118268847465515
Batch 19/64 loss: 0.30481308698654175
Batch 20/64 loss: 0.3046411871910095
Batch 21/64 loss: 0.31260645389556885
Batch 22/64 loss: 0.31543391942977905
Batch 23/64 loss: 0.3010389804840088
Batch 24/64 loss: 0.3029005527496338
Batch 25/64 loss: 0.3099238872528076
Batch 26/64 loss: 0.3063661456108093
Batch 27/64 loss: 0.3017195463180542
Batch 28/64 loss: 0.3037213087081909
Batch 29/64 loss: 0.3110409379005432
Batch 30/64 loss: 0.3101969361305237
Batch 31/64 loss: 0.299565851688385
Batch 32/64 loss: 0.3099602460861206
Batch 33/64 loss: 0.304018497467041
Batch 34/64 loss: 0.3082529902458191
Batch 35/64 loss: 0.30349647998809814
Batch 36/64 loss: 0.30395352840423584
Batch 37/64 loss: 0.31043410301208496
Batch 38/64 loss: 0.3123208284378052
Batch 39/64 loss: 0.3069611191749573
Batch 40/64 loss: 0.3024756908416748
Batch 41/64 loss: 0.31083428859710693
Batch 42/64 loss: 0.30312299728393555
Batch 43/64 loss: 0.3127347230911255
Batch 44/64 loss: 0.31690001487731934
Batch 45/64 loss: 0.307420551776886
Batch 46/64 loss: 0.3182869553565979
Batch 47/64 loss: 0.30727720260620117
Batch 48/64 loss: 0.31343573331832886
Batch 49/64 loss: 0.3012188673019409
Batch 50/64 loss: 0.3033943772315979
Batch 51/64 loss: 0.303460955619812
Batch 52/64 loss: 0.3034769296646118
Batch 53/64 loss: 0.29510992765426636
Batch 54/64 loss: 0.3071303963661194
Batch 55/64 loss: 0.30948901176452637
Batch 56/64 loss: 0.31260788440704346
Batch 57/64 loss: 0.3035116195678711
Batch 58/64 loss: 0.31466376781463623
Batch 59/64 loss: 0.30979830026626587
Batch 60/64 loss: 0.3055835962295532
Batch 61/64 loss: 0.30773138999938965
Batch 62/64 loss: 0.30764609575271606
Batch 63/64 loss: 0.31248635053634644
Batch 64/64 loss: 0.31055641174316406
Epoch 383  Train loss: 0.3076537450154622  Val loss: 0.33262850164957475
Epoch 384
-------------------------------
Batch 1/64 loss: 0.3172993063926697
Batch 2/64 loss: 0.3027360439300537
Batch 3/64 loss: 0.3098033666610718
Batch 4/64 loss: 0.3058950901031494
Batch 5/64 loss: 0.3053138852119446
Batch 6/64 loss: 0.3063339591026306
Batch 7/64 loss: 0.29507601261138916
Batch 8/64 loss: 0.3008469343185425
Batch 9/64 loss: 0.3082263469696045
Batch 10/64 loss: 0.30039751529693604
Batch 11/64 loss: 0.2945191264152527
Batch 12/64 loss: 0.30665940046310425
Batch 13/64 loss: 0.3204305171966553
Batch 14/64 loss: 0.29794561862945557
Batch 15/64 loss: 0.30394333600997925
Batch 16/64 loss: 0.30353468656539917
Batch 17/64 loss: 0.30511027574539185
Batch 18/64 loss: 0.31004559993743896
Batch 19/64 loss: 0.3088111877441406
Batch 20/64 loss: 0.30339497327804565
Batch 21/64 loss: 0.3016436696052551
Batch 22/64 loss: 0.31241029500961304
Batch 23/64 loss: 0.3132644295692444
Batch 24/64 loss: 0.30042219161987305
Batch 25/64 loss: 0.30971759557724
Batch 26/64 loss: 0.31327712535858154
Batch 27/64 loss: 0.306011438369751
Batch 28/64 loss: 0.29807937145233154
Batch 29/64 loss: 0.3089423179626465
Batch 30/64 loss: 0.30861151218414307
Batch 31/64 loss: 0.31581544876098633
Batch 32/64 loss: 0.3106374740600586
Batch 33/64 loss: 0.3096390962600708
Batch 34/64 loss: 0.3042945861816406
Batch 35/64 loss: 0.31155478954315186
Batch 36/64 loss: 0.3255068063735962
Batch 37/64 loss: 0.29858481884002686
Batch 38/64 loss: 0.3121104836463928
Batch 39/64 loss: 0.3023484945297241
Batch 40/64 loss: 0.3077395558357239
Batch 41/64 loss: 0.30111968517303467
Batch 42/64 loss: 0.32078075408935547
Batch 43/64 loss: 0.30032843351364136
Batch 44/64 loss: 0.3025624752044678
Batch 45/64 loss: 0.3112636208534241
Batch 46/64 loss: 0.3030291795730591
Batch 47/64 loss: 0.31490981578826904
Batch 48/64 loss: 0.31663578748703003
Batch 49/64 loss: 0.30576539039611816
Batch 50/64 loss: 0.31337684392929077
Batch 51/64 loss: 0.30454909801483154
Batch 52/64 loss: 0.302964448928833
Batch 53/64 loss: 0.31213319301605225
Batch 54/64 loss: 0.3134986162185669
Batch 55/64 loss: 0.3167104125022888
Batch 56/64 loss: 0.3138606548309326
Batch 57/64 loss: 0.2989974617958069
Batch 58/64 loss: 0.30588752031326294
Batch 59/64 loss: 0.31052374839782715
Batch 60/64 loss: 0.3104135990142822
Batch 61/64 loss: 0.31395065784454346
Batch 62/64 loss: 0.30636346340179443
Batch 63/64 loss: 0.31037700176239014
Batch 64/64 loss: 0.3187132477760315
Epoch 384  Train loss: 0.3078583761757495  Val loss: 0.3324282017770092
Saving best model, epoch: 384
Epoch 385
-------------------------------
Batch 1/64 loss: 0.31109410524368286
Batch 2/64 loss: 0.3062220811843872
Batch 3/64 loss: 0.30782169103622437
Batch 4/64 loss: 0.30931031703948975
Batch 5/64 loss: 0.3157252073287964
Batch 6/64 loss: 0.3048420548439026
Batch 7/64 loss: 0.31088340282440186
Batch 8/64 loss: 0.3053584694862366
Batch 9/64 loss: 0.30689167976379395
Batch 10/64 loss: 0.3006782531738281
Batch 11/64 loss: 0.3056172728538513
Batch 12/64 loss: 0.30302679538726807
Batch 13/64 loss: 0.30445367097854614
Batch 14/64 loss: 0.3057897090911865
Batch 15/64 loss: 0.3159058690071106
Batch 16/64 loss: 0.3064865469932556
Batch 17/64 loss: 0.30617833137512207
Batch 18/64 loss: 0.3005411624908447
Batch 19/64 loss: 0.29931384325027466
Batch 20/64 loss: 0.31789499521255493
Batch 21/64 loss: 0.3115556240081787
Batch 22/64 loss: 0.3020898103713989
Batch 23/64 loss: 0.30220597982406616
Batch 24/64 loss: 0.3099740147590637
Batch 25/64 loss: 0.30771076679229736
Batch 26/64 loss: 0.3016921877861023
Batch 27/64 loss: 0.31399011611938477
Batch 28/64 loss: 0.3100684881210327
Batch 29/64 loss: 0.30981457233428955
Batch 30/64 loss: 0.31266772747039795
Batch 31/64 loss: 0.30744147300720215
Batch 32/64 loss: 0.293914794921875
Batch 33/64 loss: 0.31306999921798706
Batch 34/64 loss: 0.310055136680603
Batch 35/64 loss: 0.31612062454223633
Batch 36/64 loss: 0.30655616521835327
Batch 37/64 loss: 0.3010790944099426
Batch 38/64 loss: 0.2954796552658081
Batch 39/64 loss: 0.30666863918304443
Batch 40/64 loss: 0.3062237501144409
Batch 41/64 loss: 0.3039153814315796
Batch 42/64 loss: 0.30465245246887207
Batch 43/64 loss: 0.3153647184371948
Batch 44/64 loss: 0.30855703353881836
Batch 45/64 loss: 0.30603480339050293
Batch 46/64 loss: 0.3096540570259094
Batch 47/64 loss: 0.30563604831695557
Batch 48/64 loss: 0.30594509840011597
Batch 49/64 loss: 0.30624258518218994
Batch 50/64 loss: 0.307555615901947
Batch 51/64 loss: 0.3072744607925415
Batch 52/64 loss: 0.31384795904159546
Batch 53/64 loss: 0.317513108253479
Batch 54/64 loss: 0.30560117959976196
Batch 55/64 loss: 0.3168409466743469
Batch 56/64 loss: 0.31868481636047363
Batch 57/64 loss: 0.30899447202682495
Batch 58/64 loss: 0.3091863989830017
Batch 59/64 loss: 0.30678510665893555
Batch 60/64 loss: 0.31897634267807007
Batch 61/64 loss: 0.3025898337364197
Batch 62/64 loss: 0.3076082468032837
Batch 63/64 loss: 0.30720728635787964
Batch 64/64 loss: 0.3014618158340454
Epoch 385  Train loss: 0.3078145630219403  Val loss: 0.33369128318996366
Epoch 386
-------------------------------
Batch 1/64 loss: 0.30536723136901855
Batch 2/64 loss: 0.31464827060699463
Batch 3/64 loss: 0.30674612522125244
Batch 4/64 loss: 0.3039219379425049
Batch 5/64 loss: 0.3047788739204407
Batch 6/64 loss: 0.29906153678894043
Batch 7/64 loss: 0.31422823667526245
Batch 8/64 loss: 0.3083794116973877
Batch 9/64 loss: 0.2968366742134094
Batch 10/64 loss: 0.305905818939209
Batch 11/64 loss: 0.309712290763855
Batch 12/64 loss: 0.3127135634422302
Batch 13/64 loss: 0.3051651120185852
Batch 14/64 loss: 0.30967462062835693
Batch 15/64 loss: 0.30019044876098633
Batch 16/64 loss: 0.29875457286834717
Batch 17/64 loss: 0.3063071370124817
Batch 18/64 loss: 0.30093634128570557
Batch 19/64 loss: 0.32625633478164673
Batch 20/64 loss: 0.3127562999725342
Batch 21/64 loss: 0.30485427379608154
Batch 22/64 loss: 0.30984288454055786
Batch 23/64 loss: 0.3129417896270752
Batch 24/64 loss: 0.3100771903991699
Batch 25/64 loss: 0.2947766184806824
Batch 26/64 loss: 0.3091168999671936
Batch 27/64 loss: 0.30552107095718384
Batch 28/64 loss: 0.3140910863876343
Batch 29/64 loss: 0.3016952872276306
Batch 30/64 loss: 0.3125743865966797
Batch 31/64 loss: 0.30286717414855957
Batch 32/64 loss: 0.3109477162361145
Batch 33/64 loss: 0.31400376558303833
Batch 34/64 loss: 0.30544042587280273
Batch 35/64 loss: 0.3030157685279846
Batch 36/64 loss: 0.30833864212036133
Batch 37/64 loss: 0.3140925168991089
Batch 38/64 loss: 0.31006038188934326
Batch 39/64 loss: 0.30518418550491333
Batch 40/64 loss: 0.31437939405441284
Batch 41/64 loss: 0.30728620290756226
Batch 42/64 loss: 0.3098366856575012
Batch 43/64 loss: 0.30368316173553467
Batch 44/64 loss: 0.30810368061065674
Batch 45/64 loss: 0.3033522367477417
Batch 46/64 loss: 0.30588364601135254
Batch 47/64 loss: 0.3093552589416504
Batch 48/64 loss: 0.3134726285934448
Batch 49/64 loss: 0.3179638385772705
Batch 50/64 loss: 0.3152134418487549
Batch 51/64 loss: 0.2960454225540161
Batch 52/64 loss: 0.30426180362701416
Batch 53/64 loss: 0.30145764350891113
Batch 54/64 loss: 0.30841779708862305
Batch 55/64 loss: 0.2997024655342102
Batch 56/64 loss: 0.3083004951477051
Batch 57/64 loss: 0.3095506429672241
Batch 58/64 loss: 0.3071465492248535
Batch 59/64 loss: 0.3112344741821289
Batch 60/64 loss: 0.3113675117492676
Batch 61/64 loss: 0.304054856300354
Batch 62/64 loss: 0.3017428517341614
Batch 63/64 loss: 0.3204537630081177
Batch 64/64 loss: 0.3121461868286133
Epoch 386  Train loss: 0.3077358273898854  Val loss: 0.333033888200714
Epoch 387
-------------------------------
Batch 1/64 loss: 0.3083764910697937
Batch 2/64 loss: 0.3074100613594055
Batch 3/64 loss: 0.3080253005027771
Batch 4/64 loss: 0.31192684173583984
Batch 5/64 loss: 0.30891382694244385
Batch 6/64 loss: 0.30828356742858887
Batch 7/64 loss: 0.3126218318939209
Batch 8/64 loss: 0.300900399684906
Batch 9/64 loss: 0.3046261668205261
Batch 10/64 loss: 0.30584514141082764
Batch 11/64 loss: 0.30579620599746704
Batch 12/64 loss: 0.30883288383483887
Batch 13/64 loss: 0.30635905265808105
Batch 14/64 loss: 0.30431652069091797
Batch 15/64 loss: 0.30207931995391846
Batch 16/64 loss: 0.3035874366760254
Batch 17/64 loss: 0.31223195791244507
Batch 18/64 loss: 0.31449103355407715
Batch 19/64 loss: 0.3157920837402344
Batch 20/64 loss: 0.3059375286102295
Batch 21/64 loss: 0.31089210510253906
Batch 22/64 loss: 0.31317275762557983
Batch 23/64 loss: 0.3088493347167969
Batch 24/64 loss: 0.30321550369262695
Batch 25/64 loss: 0.3114912509918213
Batch 26/64 loss: 0.3070968985557556
Batch 27/64 loss: 0.31073951721191406
Batch 28/64 loss: 0.3015865087509155
Batch 29/64 loss: 0.3011256456375122
Batch 30/64 loss: 0.31125152111053467
Batch 31/64 loss: 0.31199824810028076
Batch 32/64 loss: 0.3090168237686157
Batch 33/64 loss: 0.3108654022216797
Batch 34/64 loss: 0.3008660078048706
Batch 35/64 loss: 0.31224024295806885
Batch 36/64 loss: 0.2997395396232605
Batch 37/64 loss: 0.30472326278686523
Batch 38/64 loss: 0.30395931005477905
Batch 39/64 loss: 0.3065171241760254
Batch 40/64 loss: 0.31455713510513306
Batch 41/64 loss: 0.30425649881362915
Batch 42/64 loss: 0.29973554611206055
Batch 43/64 loss: 0.3145425319671631
Batch 44/64 loss: 0.30169475078582764
Batch 45/64 loss: 0.3061089515686035
Batch 46/64 loss: 0.3133091330528259
Batch 47/64 loss: 0.3050941228866577
Batch 48/64 loss: 0.30756181478500366
Batch 49/64 loss: 0.30870354175567627
Batch 50/64 loss: 0.30039942264556885
Batch 51/64 loss: 0.29959386587142944
Batch 52/64 loss: 0.30977386236190796
Batch 53/64 loss: 0.30332303047180176
Batch 54/64 loss: 0.313015878200531
Batch 55/64 loss: 0.3139230012893677
Batch 56/64 loss: 0.298800528049469
Batch 57/64 loss: 0.30419743061065674
Batch 58/64 loss: 0.3124288320541382
Batch 59/64 loss: 0.30967795848846436
Batch 60/64 loss: 0.3074548840522766
Batch 61/64 loss: 0.3144170641899109
Batch 62/64 loss: 0.2983500361442566
Batch 63/64 loss: 0.3087007999420166
Batch 64/64 loss: 0.3108874559402466
Epoch 387  Train loss: 0.3074272450278787  Val loss: 0.3355467913486704
Epoch 388
-------------------------------
Batch 1/64 loss: 0.3031644821166992
Batch 2/64 loss: 0.30748045444488525
Batch 3/64 loss: 0.2910528779029846
Batch 4/64 loss: 0.30186140537261963
Batch 5/64 loss: 0.3105745315551758
Batch 6/64 loss: 0.30905473232269287
Batch 7/64 loss: 0.3068845272064209
Batch 8/64 loss: 0.30450332164764404
Batch 9/64 loss: 0.30873334407806396
Batch 10/64 loss: 0.3111553192138672
Batch 11/64 loss: 0.31261909008026123
Batch 12/64 loss: 0.3034515380859375
Batch 13/64 loss: 0.309623122215271
Batch 14/64 loss: 0.3024568557739258
Batch 15/64 loss: 0.3179084062576294
Batch 16/64 loss: 0.306235671043396
Batch 17/64 loss: 0.30273741483688354
Batch 18/64 loss: 0.3024049401283264
Batch 19/64 loss: 0.30700182914733887
Batch 20/64 loss: 0.3086477518081665
Batch 21/64 loss: 0.3062098026275635
Batch 22/64 loss: 0.3113848567008972
Batch 23/64 loss: 0.30530261993408203
Batch 24/64 loss: 0.3062393069267273
Batch 25/64 loss: 0.3097110390663147
Batch 26/64 loss: 0.3085901737213135
Batch 27/64 loss: 0.30903542041778564
Batch 28/64 loss: 0.29499852657318115
Batch 29/64 loss: 0.3096294403076172
Batch 30/64 loss: 0.3029364347457886
Batch 31/64 loss: 0.30282723903656006
Batch 32/64 loss: 0.3060190677642822
Batch 33/64 loss: 0.29988694190979004
Batch 34/64 loss: 0.30293750762939453
Batch 35/64 loss: 0.3070964813232422
Batch 36/64 loss: 0.316058874130249
Batch 37/64 loss: 0.3087695837020874
Batch 38/64 loss: 0.3190699815750122
Batch 39/64 loss: 0.31602126359939575
Batch 40/64 loss: 0.3092028498649597
Batch 41/64 loss: 0.31003713607788086
Batch 42/64 loss: 0.3046022653579712
Batch 43/64 loss: 0.294363796710968
Batch 44/64 loss: 0.30449211597442627
Batch 45/64 loss: 0.31397461891174316
Batch 46/64 loss: 0.3113182783126831
Batch 47/64 loss: 0.30134570598602295
Batch 48/64 loss: 0.30616557598114014
Batch 49/64 loss: 0.31455767154693604
Batch 50/64 loss: 0.3042911887168884
Batch 51/64 loss: 0.316484272480011
Batch 52/64 loss: 0.3020111918449402
Batch 53/64 loss: 0.31676650047302246
Batch 54/64 loss: 0.30524110794067383
Batch 55/64 loss: 0.30428850650787354
Batch 56/64 loss: 0.3079988956451416
Batch 57/64 loss: 0.308294415473938
Batch 58/64 loss: 0.31159961223602295
Batch 59/64 loss: 0.31708407402038574
Batch 60/64 loss: 0.30802321434020996
Batch 61/64 loss: 0.3064308166503906
Batch 62/64 loss: 0.3139856457710266
Batch 63/64 loss: 0.3219905495643616
Batch 64/64 loss: 0.30152928829193115
Epoch 388  Train loss: 0.30762310822804767  Val loss: 0.3338190481015497
Epoch 389
-------------------------------
Batch 1/64 loss: 0.30976438522338867
Batch 2/64 loss: 0.30408382415771484
Batch 3/64 loss: 0.31169092655181885
Batch 4/64 loss: 0.30702388286590576
Batch 5/64 loss: 0.30936408042907715
Batch 6/64 loss: 0.32106292247772217
Batch 7/64 loss: 0.3060609698295593
Batch 8/64 loss: 0.3132215738296509
Batch 9/64 loss: 0.3028676509857178
Batch 10/64 loss: 0.3024817705154419
Batch 11/64 loss: 0.3089370131492615
Batch 12/64 loss: 0.31207275390625
Batch 13/64 loss: 0.3179647922515869
Batch 14/64 loss: 0.3110589385032654
Batch 15/64 loss: 0.3058706521987915
Batch 16/64 loss: 0.309914231300354
Batch 17/64 loss: 0.3051501512527466
Batch 18/64 loss: 0.30385875701904297
Batch 19/64 loss: 0.3065218925476074
Batch 20/64 loss: 0.29845869541168213
Batch 21/64 loss: 0.29727113246917725
Batch 22/64 loss: 0.30245161056518555
Batch 23/64 loss: 0.31402820348739624
Batch 24/64 loss: 0.30865252017974854
Batch 25/64 loss: 0.3015987277030945
Batch 26/64 loss: 0.30121487379074097
Batch 27/64 loss: 0.3113696575164795
Batch 28/64 loss: 0.3027724027633667
Batch 29/64 loss: 0.31313782930374146
Batch 30/64 loss: 0.3188321590423584
Batch 31/64 loss: 0.3010327219963074
Batch 32/64 loss: 0.302612841129303
Batch 33/64 loss: 0.30744314193725586
Batch 34/64 loss: 0.30588436126708984
Batch 35/64 loss: 0.29797762632369995
Batch 36/64 loss: 0.3041701316833496
Batch 37/64 loss: 0.30006372928619385
Batch 38/64 loss: 0.3013150095939636
Batch 39/64 loss: 0.3126016855239868
Batch 40/64 loss: 0.3008168339729309
Batch 41/64 loss: 0.30753612518310547
Batch 42/64 loss: 0.3007294535636902
Batch 43/64 loss: 0.30310797691345215
Batch 44/64 loss: 0.30474090576171875
Batch 45/64 loss: 0.31408780813217163
Batch 46/64 loss: 0.30767399072647095
Batch 47/64 loss: 0.3010523319244385
Batch 48/64 loss: 0.31153106689453125
Batch 49/64 loss: 0.29790419340133667
Batch 50/64 loss: 0.31631553173065186
Batch 51/64 loss: 0.3121294379234314
Batch 52/64 loss: 0.30436497926712036
Batch 53/64 loss: 0.30958473682403564
Batch 54/64 loss: 0.3067537546157837
Batch 55/64 loss: 0.30272024869918823
Batch 56/64 loss: 0.3058016896247864
Batch 57/64 loss: 0.3049405813217163
Batch 58/64 loss: 0.3172190189361572
Batch 59/64 loss: 0.3028007745742798
Batch 60/64 loss: 0.3088969588279724
Batch 61/64 loss: 0.30206847190856934
Batch 62/64 loss: 0.3115155100822449
Batch 63/64 loss: 0.3058079481124878
Batch 64/64 loss: 0.31022030115127563
Epoch 389  Train loss: 0.306896090741251  Val loss: 0.33285905774106683
Epoch 390
-------------------------------
Batch 1/64 loss: 0.3165956735610962
Batch 2/64 loss: 0.31023573875427246
Batch 3/64 loss: 0.29072320461273193
Batch 4/64 loss: 0.3031667470932007
Batch 5/64 loss: 0.31840699911117554
Batch 6/64 loss: 0.3117179870605469
Batch 7/64 loss: 0.3041400909423828
Batch 8/64 loss: 0.31023144721984863
Batch 9/64 loss: 0.30907416343688965
Batch 10/64 loss: 0.3053320646286011
Batch 11/64 loss: 0.3019331097602844
Batch 12/64 loss: 0.29956239461898804
Batch 13/64 loss: 0.3014209270477295
Batch 14/64 loss: 0.29867422580718994
Batch 15/64 loss: 0.30469071865081787
Batch 16/64 loss: 0.3144022226333618
Batch 17/64 loss: 0.309531569480896
Batch 18/64 loss: 0.3063187599182129
Batch 19/64 loss: 0.3025192618370056
Batch 20/64 loss: 0.3021138906478882
Batch 21/64 loss: 0.3072476387023926
Batch 22/64 loss: 0.30811142921447754
Batch 23/64 loss: 0.30144059658050537
Batch 24/64 loss: 0.3136633038520813
Batch 25/64 loss: 0.3214144706726074
Batch 26/64 loss: 0.3010462522506714
Batch 27/64 loss: 0.31183385848999023
Batch 28/64 loss: 0.29709625244140625
Batch 29/64 loss: 0.3076756000518799
Batch 30/64 loss: 0.3078038692474365
Batch 31/64 loss: 0.30764448642730713
Batch 32/64 loss: 0.30787909030914307
Batch 33/64 loss: 0.30529117584228516
Batch 34/64 loss: 0.3040536642074585
Batch 35/64 loss: 0.30258697271347046
Batch 36/64 loss: 0.3089698553085327
Batch 37/64 loss: 0.29966509342193604
Batch 38/64 loss: 0.31960535049438477
Batch 39/64 loss: 0.30082041025161743
Batch 40/64 loss: 0.306488037109375
Batch 41/64 loss: 0.3024033308029175
Batch 42/64 loss: 0.31156373023986816
Batch 43/64 loss: 0.3158684968948364
Batch 44/64 loss: 0.30762189626693726
Batch 45/64 loss: 0.31015515327453613
Batch 46/64 loss: 0.30250251293182373
Batch 47/64 loss: 0.3080260753631592
Batch 48/64 loss: 0.31394779682159424
Batch 49/64 loss: 0.3018307089805603
Batch 50/64 loss: 0.30568957328796387
Batch 51/64 loss: 0.3019585609436035
Batch 52/64 loss: 0.3085707426071167
Batch 53/64 loss: 0.30907273292541504
Batch 54/64 loss: 0.30010485649108887
Batch 55/64 loss: 0.31849217414855957
Batch 56/64 loss: 0.3028784990310669
Batch 57/64 loss: 0.31317126750946045
Batch 58/64 loss: 0.31107133626937866
Batch 59/64 loss: 0.30889952182769775
Batch 60/64 loss: 0.31315863132476807
Batch 61/64 loss: 0.30519092082977295
Batch 62/64 loss: 0.30492401123046875
Batch 63/64 loss: 0.31479716300964355
Batch 64/64 loss: 0.30226051807403564
Epoch 390  Train loss: 0.3071329205643897  Val loss: 0.3334939055836078
Epoch 391
-------------------------------
Batch 1/64 loss: 0.30786383152008057
Batch 2/64 loss: 0.3175245523452759
Batch 3/64 loss: 0.31003332138061523
Batch 4/64 loss: 0.3039308786392212
Batch 5/64 loss: 0.30009186267852783
Batch 6/64 loss: 0.29465359449386597
Batch 7/64 loss: 0.298677921295166
Batch 8/64 loss: 0.3111482858657837
Batch 9/64 loss: 0.3122285008430481
Batch 10/64 loss: 0.31226158142089844
Batch 11/64 loss: 0.3087012767791748
Batch 12/64 loss: 0.3023332953453064
Batch 13/64 loss: 0.3160451650619507
Batch 14/64 loss: 0.3096991181373596
Batch 15/64 loss: 0.30679851770401
Batch 16/64 loss: 0.32388222217559814
Batch 17/64 loss: 0.3139142394065857
Batch 18/64 loss: 0.30509132146835327
Batch 19/64 loss: 0.30252325534820557
Batch 20/64 loss: 0.29816770553588867
Batch 21/64 loss: 0.3109528422355652
Batch 22/64 loss: 0.3005025386810303
Batch 23/64 loss: 0.2964990735054016
Batch 24/64 loss: 0.30287420749664307
Batch 25/64 loss: 0.3078005313873291
Batch 26/64 loss: 0.30098748207092285
Batch 27/64 loss: 0.3126685619354248
Batch 28/64 loss: 0.30500149726867676
Batch 29/64 loss: 0.30935341119766235
Batch 30/64 loss: 0.30655544996261597
Batch 31/64 loss: 0.3051358461380005
Batch 32/64 loss: 0.3085622787475586
Batch 33/64 loss: 0.3056563138961792
Batch 34/64 loss: 0.30705809593200684
Batch 35/64 loss: 0.30088961124420166
Batch 36/64 loss: 0.30743247270584106
Batch 37/64 loss: 0.3162652254104614
Batch 38/64 loss: 0.30613261461257935
Batch 39/64 loss: 0.30858635902404785
Batch 40/64 loss: 0.30035579204559326
Batch 41/64 loss: 0.3114422559738159
Batch 42/64 loss: 0.297277569770813
Batch 43/64 loss: 0.3097040057182312
Batch 44/64 loss: 0.3155784606933594
Batch 45/64 loss: 0.3013838529586792
Batch 46/64 loss: 0.3074296712875366
Batch 47/64 loss: 0.3074144124984741
Batch 48/64 loss: 0.313584566116333
Batch 49/64 loss: 0.31060290336608887
Batch 50/64 loss: 0.3028217554092407
Batch 51/64 loss: 0.3049428462982178
Batch 52/64 loss: 0.3123067021369934
Batch 53/64 loss: 0.30990660190582275
Batch 54/64 loss: 0.3070192337036133
Batch 55/64 loss: 0.31913673877716064
Batch 56/64 loss: 0.302539587020874
Batch 57/64 loss: 0.31138521432876587
Batch 58/64 loss: 0.3040202856063843
Batch 59/64 loss: 0.3108406066894531
Batch 60/64 loss: 0.3115732669830322
Batch 61/64 loss: 0.3049302101135254
Batch 62/64 loss: 0.3107832670211792
Batch 63/64 loss: 0.3139711618423462
Batch 64/64 loss: 0.3049718141555786
Epoch 391  Train loss: 0.3075163088592828  Val loss: 0.33356510281972457
Epoch 392
-------------------------------
Batch 1/64 loss: 0.2919321060180664
Batch 2/64 loss: 0.3100731372833252
Batch 3/64 loss: 0.30470848083496094
Batch 4/64 loss: 0.30096471309661865
Batch 5/64 loss: 0.3053323030471802
Batch 6/64 loss: 0.30787837505340576
Batch 7/64 loss: 0.3058728575706482
Batch 8/64 loss: 0.31715089082717896
Batch 9/64 loss: 0.3066830039024353
Batch 10/64 loss: 0.3115701675415039
Batch 11/64 loss: 0.2978452444076538
Batch 12/64 loss: 0.30714738368988037
Batch 13/64 loss: 0.30663150548934937
Batch 14/64 loss: 0.30613553524017334
Batch 15/64 loss: 0.32194167375564575
Batch 16/64 loss: 0.30612099170684814
Batch 17/64 loss: 0.3102951645851135
Batch 18/64 loss: 0.3063207268714905
Batch 19/64 loss: 0.3051795959472656
Batch 20/64 loss: 0.29958200454711914
Batch 21/64 loss: 0.30863577127456665
Batch 22/64 loss: 0.30784380435943604
Batch 23/64 loss: 0.3026832938194275
Batch 24/64 loss: 0.31091535091400146
Batch 25/64 loss: 0.30322039127349854
Batch 26/64 loss: 0.30066269636154175
Batch 27/64 loss: 0.3027387857437134
Batch 28/64 loss: 0.2991209626197815
Batch 29/64 loss: 0.29954373836517334
Batch 30/64 loss: 0.2990339994430542
Batch 31/64 loss: 0.30541908740997314
Batch 32/64 loss: 0.2997891902923584
Batch 33/64 loss: 0.31073224544525146
Batch 34/64 loss: 0.30893445014953613
Batch 35/64 loss: 0.3058493137359619
Batch 36/64 loss: 0.3108712434768677
Batch 37/64 loss: 0.3098193407058716
Batch 38/64 loss: 0.3170137405395508
Batch 39/64 loss: 0.3198038339614868
Batch 40/64 loss: 0.30652278661727905
Batch 41/64 loss: 0.30667686462402344
Batch 42/64 loss: 0.30432426929473877
Batch 43/64 loss: 0.30516570806503296
Batch 44/64 loss: 0.3067331314086914
Batch 45/64 loss: 0.30247962474823
Batch 46/64 loss: 0.30798089504241943
Batch 47/64 loss: 0.3067359924316406
Batch 48/64 loss: 0.3048095107078552
Batch 49/64 loss: 0.3002586364746094
Batch 50/64 loss: 0.31023740768432617
Batch 51/64 loss: 0.31355881690979004
Batch 52/64 loss: 0.31574368476867676
Batch 53/64 loss: 0.3140244483947754
Batch 54/64 loss: 0.30781930685043335
Batch 55/64 loss: 0.316214919090271
Batch 56/64 loss: 0.31974899768829346
Batch 57/64 loss: 0.30819761753082275
Batch 58/64 loss: 0.29914307594299316
Batch 59/64 loss: 0.3002760410308838
Batch 60/64 loss: 0.3085330128669739
Batch 61/64 loss: 0.30742186307907104
Batch 62/64 loss: 0.3092012405395508
Batch 63/64 loss: 0.31470775604248047
Batch 64/64 loss: 0.30818164348602295
Epoch 392  Train loss: 0.3071317481059654  Val loss: 0.3322015081074639
Saving best model, epoch: 392
Epoch 393
-------------------------------
Batch 1/64 loss: 0.30823278427124023
Batch 2/64 loss: 0.312900185585022
Batch 3/64 loss: 0.30357658863067627
Batch 4/64 loss: 0.30261170864105225
Batch 5/64 loss: 0.3111931085586548
Batch 6/64 loss: 0.31395167112350464
Batch 7/64 loss: 0.306837260723114
Batch 8/64 loss: 0.30849015712738037
Batch 9/64 loss: 0.3033277988433838
Batch 10/64 loss: 0.3117642402648926
Batch 11/64 loss: 0.30318379402160645
Batch 12/64 loss: 0.31853508949279785
Batch 13/64 loss: 0.3062739372253418
Batch 14/64 loss: 0.3095768690109253
Batch 15/64 loss: 0.3034888505935669
Batch 16/64 loss: 0.3031138777732849
Batch 17/64 loss: 0.30766141414642334
Batch 18/64 loss: 0.29852360486984253
Batch 19/64 loss: 0.3074913024902344
Batch 20/64 loss: 0.3129689693450928
Batch 21/64 loss: 0.3113027811050415
Batch 22/64 loss: 0.3072432279586792
Batch 23/64 loss: 0.3071715235710144
Batch 24/64 loss: 0.3099334239959717
Batch 25/64 loss: 0.3010551929473877
Batch 26/64 loss: 0.30853062868118286
Batch 27/64 loss: 0.30946630239486694
Batch 28/64 loss: 0.30084502696990967
Batch 29/64 loss: 0.2932952642440796
Batch 30/64 loss: 0.3052023649215698
Batch 31/64 loss: 0.314056396484375
Batch 32/64 loss: 0.31535452604293823
Batch 33/64 loss: 0.3133772611618042
Batch 34/64 loss: 0.30681419372558594
Batch 35/64 loss: 0.305131196975708
Batch 36/64 loss: 0.3053186535835266
Batch 37/64 loss: 0.3000633120536804
Batch 38/64 loss: 0.3013639450073242
Batch 39/64 loss: 0.30833667516708374
Batch 40/64 loss: 0.3039008378982544
Batch 41/64 loss: 0.3065718412399292
Batch 42/64 loss: 0.29836761951446533
Batch 43/64 loss: 0.30694735050201416
Batch 44/64 loss: 0.3145170211791992
Batch 45/64 loss: 0.30657958984375
Batch 46/64 loss: 0.30607593059539795
Batch 47/64 loss: 0.307892382144928
Batch 48/64 loss: 0.2975963354110718
Batch 49/64 loss: 0.30941450595855713
Batch 50/64 loss: 0.3026511073112488
Batch 51/64 loss: 0.30763089656829834
Batch 52/64 loss: 0.31015336513519287
Batch 53/64 loss: 0.30646830797195435
Batch 54/64 loss: 0.3074401617050171
Batch 55/64 loss: 0.30536818504333496
Batch 56/64 loss: 0.31347179412841797
Batch 57/64 loss: 0.3042970299720764
Batch 58/64 loss: 0.3085249662399292
Batch 59/64 loss: 0.30694520473480225
Batch 60/64 loss: 0.3112700581550598
Batch 61/64 loss: 0.31287407875061035
Batch 62/64 loss: 0.31591343879699707
Batch 63/64 loss: 0.31577444076538086
Batch 64/64 loss: 0.30961060523986816
Epoch 393  Train loss: 0.3073948158937342  Val loss: 0.3334385418809976
Epoch 394
-------------------------------
Batch 1/64 loss: 0.30054736137390137
Batch 2/64 loss: 0.3083488941192627
Batch 3/64 loss: 0.3104149103164673
Batch 4/64 loss: 0.3003142476081848
Batch 5/64 loss: 0.3115183711051941
Batch 6/64 loss: 0.3116490840911865
Batch 7/64 loss: 0.3077990412712097
Batch 8/64 loss: 0.30621886253356934
Batch 9/64 loss: 0.3010650873184204
Batch 10/64 loss: 0.30990004539489746
Batch 11/64 loss: 0.30748629570007324
Batch 12/64 loss: 0.3118182420730591
Batch 13/64 loss: 0.30186259746551514
Batch 14/64 loss: 0.3110501766204834
Batch 15/64 loss: 0.3003123998641968
Batch 16/64 loss: 0.30145740509033203
Batch 17/64 loss: 0.30537259578704834
Batch 18/64 loss: 0.30433809757232666
Batch 19/64 loss: 0.29978513717651367
Batch 20/64 loss: 0.30898332595825195
Batch 21/64 loss: 0.305942177772522
Batch 22/64 loss: 0.3081205487251282
Batch 23/64 loss: 0.31388258934020996
Batch 24/64 loss: 0.3095921277999878
Batch 25/64 loss: 0.30907559394836426
Batch 26/64 loss: 0.3093085289001465
Batch 27/64 loss: 0.32329005002975464
Batch 28/64 loss: 0.29589641094207764
Batch 29/64 loss: 0.3069950342178345
Batch 30/64 loss: 0.31033802032470703
Batch 31/64 loss: 0.3164798617362976
Batch 32/64 loss: 0.31110167503356934
Batch 33/64 loss: 0.30973172187805176
Batch 34/64 loss: 0.30980050563812256
Batch 35/64 loss: 0.3120615482330322
Batch 36/64 loss: 0.30225998163223267
Batch 37/64 loss: 0.3127872347831726
Batch 38/64 loss: 0.3023231029510498
Batch 39/64 loss: 0.3086947202682495
Batch 40/64 loss: 0.3028573989868164
Batch 41/64 loss: 0.30088192224502563
Batch 42/64 loss: 0.3188624382019043
Batch 43/64 loss: 0.30385923385620117
Batch 44/64 loss: 0.3122372031211853
Batch 45/64 loss: 0.30778026580810547
Batch 46/64 loss: 0.29857736825942993
Batch 47/64 loss: 0.2979243993759155
Batch 48/64 loss: 0.31327468156814575
Batch 49/64 loss: 0.31346774101257324
Batch 50/64 loss: 0.29784929752349854
Batch 51/64 loss: 0.30963242053985596
Batch 52/64 loss: 0.3074950575828552
Batch 53/64 loss: 0.3146314024925232
Batch 54/64 loss: 0.30416983366012573
Batch 55/64 loss: 0.3025568127632141
Batch 56/64 loss: 0.29849374294281006
Batch 57/64 loss: 0.30246758460998535
Batch 58/64 loss: 0.31252461671829224
Batch 59/64 loss: 0.30766379833221436
Batch 60/64 loss: 0.3027500510215759
Batch 61/64 loss: 0.30192333459854126
Batch 62/64 loss: 0.3062185049057007
Batch 63/64 loss: 0.30886733531951904
Batch 64/64 loss: 0.2994832992553711
Epoch 394  Train loss: 0.306972588744818  Val loss: 0.3340011609788613
Epoch 395
-------------------------------
Batch 1/64 loss: 0.30880916118621826
Batch 2/64 loss: 0.30545753240585327
Batch 3/64 loss: 0.29823142290115356
Batch 4/64 loss: 0.3056949973106384
Batch 5/64 loss: 0.31306421756744385
Batch 6/64 loss: 0.3122078776359558
Batch 7/64 loss: 0.32085609436035156
Batch 8/64 loss: 0.31325554847717285
Batch 9/64 loss: 0.30090832710266113
Batch 10/64 loss: 0.2951219081878662
Batch 11/64 loss: 0.30556929111480713
Batch 12/64 loss: 0.29846322536468506
Batch 13/64 loss: 0.3209259510040283
Batch 14/64 loss: 0.30514824390411377
Batch 15/64 loss: 0.3128751516342163
Batch 16/64 loss: 0.30413657426834106
Batch 17/64 loss: 0.31344735622406006
Batch 18/64 loss: 0.30169379711151123
Batch 19/64 loss: 0.31417977809906006
Batch 20/64 loss: 0.30054032802581787
Batch 21/64 loss: 0.29235851764678955
Batch 22/64 loss: 0.30365973711013794
Batch 23/64 loss: 0.3037768602371216
Batch 24/64 loss: 0.3090822696685791
Batch 25/64 loss: 0.3080688714981079
Batch 26/64 loss: 0.30965763330459595
Batch 27/64 loss: 0.2932746410369873
Batch 28/64 loss: 0.30179059505462646
Batch 29/64 loss: 0.3108057975769043
Batch 30/64 loss: 0.30926012992858887
Batch 31/64 loss: 0.30934226512908936
Batch 32/64 loss: 0.29618215560913086
Batch 33/64 loss: 0.3231636881828308
Batch 34/64 loss: 0.3101879358291626
Batch 35/64 loss: 0.30316150188446045
Batch 36/64 loss: 0.3029239773750305
Batch 37/64 loss: 0.3181544542312622
Batch 38/64 loss: 0.31368428468704224
Batch 39/64 loss: 0.3133341073989868
Batch 40/64 loss: 0.3143898844718933
Batch 41/64 loss: 0.30374574661254883
Batch 42/64 loss: 0.31360214948654175
Batch 43/64 loss: 0.3068980574607849
Batch 44/64 loss: 0.3033630847930908
Batch 45/64 loss: 0.3098626732826233
Batch 46/64 loss: 0.3017852306365967
Batch 47/64 loss: 0.3029911518096924
Batch 48/64 loss: 0.3072581887245178
Batch 49/64 loss: 0.29529356956481934
Batch 50/64 loss: 0.3059120178222656
Batch 51/64 loss: 0.30610573291778564
Batch 52/64 loss: 0.3006083369255066
Batch 53/64 loss: 0.30321407318115234
Batch 54/64 loss: 0.30212223529815674
Batch 55/64 loss: 0.30228060483932495
Batch 56/64 loss: 0.30565595626831055
Batch 57/64 loss: 0.3058423399925232
Batch 58/64 loss: 0.2984158992767334
Batch 59/64 loss: 0.3136714696884155
Batch 60/64 loss: 0.3155064582824707
Batch 61/64 loss: 0.3011361360549927
Batch 62/64 loss: 0.3110417127609253
Batch 63/64 loss: 0.30778247117996216
Batch 64/64 loss: 0.30921339988708496
Epoch 395  Train loss: 0.3067113951140759  Val loss: 0.33268813374116246
Epoch 396
-------------------------------
Batch 1/64 loss: 0.2983391284942627
Batch 2/64 loss: 0.30312323570251465
Batch 3/64 loss: 0.30752551555633545
Batch 4/64 loss: 0.3165872097015381
Batch 5/64 loss: 0.3065950870513916
Batch 6/64 loss: 0.3099170923233032
Batch 7/64 loss: 0.30607467889785767
Batch 8/64 loss: 0.3152376413345337
Batch 9/64 loss: 0.29699158668518066
Batch 10/64 loss: 0.3091017007827759
Batch 11/64 loss: 0.30846333503723145
Batch 12/64 loss: 0.31312406063079834
Batch 13/64 loss: 0.3218414783477783
Batch 14/64 loss: 0.29777538776397705
Batch 15/64 loss: 0.3025897145271301
Batch 16/64 loss: 0.30567359924316406
Batch 17/64 loss: 0.30461353063583374
Batch 18/64 loss: 0.30283284187316895
Batch 19/64 loss: 0.29979896545410156
Batch 20/64 loss: 0.309978187084198
Batch 21/64 loss: 0.3027874827384949
Batch 22/64 loss: 0.31237393617630005
Batch 23/64 loss: 0.3013211488723755
Batch 24/64 loss: 0.31004416942596436
Batch 25/64 loss: 0.30657047033309937
Batch 26/64 loss: 0.2937983274459839
Batch 27/64 loss: 0.3025500774383545
Batch 28/64 loss: 0.30301254987716675
Batch 29/64 loss: 0.30163371562957764
Batch 30/64 loss: 0.304864764213562
Batch 31/64 loss: 0.3100225329399109
Batch 32/64 loss: 0.30383777618408203
Batch 33/64 loss: 0.30729615688323975
Batch 34/64 loss: 0.3105672597885132
Batch 35/64 loss: 0.3057165741920471
Batch 36/64 loss: 0.3088315725326538
Batch 37/64 loss: 0.31361818313598633
Batch 38/64 loss: 0.30345433950424194
Batch 39/64 loss: 0.3236805200576782
Batch 40/64 loss: 0.3129730224609375
Batch 41/64 loss: 0.3104438781738281
Batch 42/64 loss: 0.3094364404678345
Batch 43/64 loss: 0.2995980978012085
Batch 44/64 loss: 0.3061927556991577
Batch 45/64 loss: 0.3088189363479614
Batch 46/64 loss: 0.2947300672531128
Batch 47/64 loss: 0.3157886862754822
Batch 48/64 loss: 0.3134034276008606
Batch 49/64 loss: 0.3096768856048584
Batch 50/64 loss: 0.31484663486480713
Batch 51/64 loss: 0.3010907769203186
Batch 52/64 loss: 0.32034504413604736
Batch 53/64 loss: 0.31341272592544556
Batch 54/64 loss: 0.30675601959228516
Batch 55/64 loss: 0.3038438558578491
Batch 56/64 loss: 0.30553603172302246
Batch 57/64 loss: 0.3016151785850525
Batch 58/64 loss: 0.30232012271881104
Batch 59/64 loss: 0.29620277881622314
Batch 60/64 loss: 0.300997257232666
Batch 61/64 loss: 0.3116658926010132
Batch 62/64 loss: 0.3032020330429077
Batch 63/64 loss: 0.3047065734863281
Batch 64/64 loss: 0.3150784969329834
Epoch 396  Train loss: 0.3069188632217108  Val loss: 0.3331868392495355
Epoch 397
-------------------------------
Batch 1/64 loss: 0.3007075786590576
Batch 2/64 loss: 0.3181593418121338
Batch 3/64 loss: 0.30629539489746094
Batch 4/64 loss: 0.30054032802581787
Batch 5/64 loss: 0.30467307567596436
Batch 6/64 loss: 0.30974268913269043
Batch 7/64 loss: 0.30673110485076904
Batch 8/64 loss: 0.3045574426651001
Batch 9/64 loss: 0.30714738368988037
Batch 10/64 loss: 0.30466413497924805
Batch 11/64 loss: 0.30692219734191895
Batch 12/64 loss: 0.30863821506500244
Batch 13/64 loss: 0.3119989037513733
Batch 14/64 loss: 0.31486207246780396
Batch 15/64 loss: 0.3061635494232178
Batch 16/64 loss: 0.3080962896347046
Batch 17/64 loss: 0.29874950647354126
Batch 18/64 loss: 0.3110208511352539
Batch 19/64 loss: 0.30121910572052
Batch 20/64 loss: 0.30270838737487793
Batch 21/64 loss: 0.2985551357269287
Batch 22/64 loss: 0.3165382742881775
Batch 23/64 loss: 0.3018803596496582
Batch 24/64 loss: 0.31083112955093384
Batch 25/64 loss: 0.31361281871795654
Batch 26/64 loss: 0.31115615367889404
Batch 27/64 loss: 0.307674765586853
Batch 28/64 loss: 0.3163137435913086
Batch 29/64 loss: 0.30661141872406006
Batch 30/64 loss: 0.3113839626312256
Batch 31/64 loss: 0.3040454387664795
Batch 32/64 loss: 0.31002700328826904
Batch 33/64 loss: 0.30291295051574707
Batch 34/64 loss: 0.30752235651016235
Batch 35/64 loss: 0.30845963954925537
Batch 36/64 loss: 0.30388909578323364
Batch 37/64 loss: 0.31133443117141724
Batch 38/64 loss: 0.3171687126159668
Batch 39/64 loss: 0.2926054000854492
Batch 40/64 loss: 0.29665619134902954
Batch 41/64 loss: 0.2983328104019165
Batch 42/64 loss: 0.3117980360984802
Batch 43/64 loss: 0.3029996156692505
Batch 44/64 loss: 0.30559009313583374
Batch 45/64 loss: 0.30330121517181396
Batch 46/64 loss: 0.30784904956817627
Batch 47/64 loss: 0.30104929208755493
Batch 48/64 loss: 0.31163090467453003
Batch 49/64 loss: 0.3054320812225342
Batch 50/64 loss: 0.30706655979156494
Batch 51/64 loss: 0.30650055408477783
Batch 52/64 loss: 0.2976638078689575
Batch 53/64 loss: 0.3109859228134155
Batch 54/64 loss: 0.31455790996551514
Batch 55/64 loss: 0.3049924969673157
Batch 56/64 loss: 0.30886971950531006
Batch 57/64 loss: 0.30230391025543213
Batch 58/64 loss: 0.316292405128479
Batch 59/64 loss: 0.3073621988296509
Batch 60/64 loss: 0.30171048641204834
Batch 61/64 loss: 0.3115706443786621
Batch 62/64 loss: 0.3022735118865967
Batch 63/64 loss: 0.3035764694213867
Batch 64/64 loss: 0.3044705390930176
Epoch 397  Train loss: 0.3067425746543735  Val loss: 0.33269716189898985
Epoch 398
-------------------------------
Batch 1/64 loss: 0.29842543601989746
Batch 2/64 loss: 0.30100202560424805
Batch 3/64 loss: 0.30946242809295654
Batch 4/64 loss: 0.3044130802154541
Batch 5/64 loss: 0.30220139026641846
Batch 6/64 loss: 0.3078958988189697
Batch 7/64 loss: 0.31319963932037354
Batch 8/64 loss: 0.305314302444458
Batch 9/64 loss: 0.318351686000824
Batch 10/64 loss: 0.30153095722198486
Batch 11/64 loss: 0.307847261428833
Batch 12/64 loss: 0.3110630512237549
Batch 13/64 loss: 0.3078750967979431
Batch 14/64 loss: 0.298622727394104
Batch 15/64 loss: 0.3016141653060913
Batch 16/64 loss: 0.30965185165405273
Batch 17/64 loss: 0.3158237934112549
Batch 18/64 loss: 0.29788994789123535
Batch 19/64 loss: 0.3031430244445801
Batch 20/64 loss: 0.30452102422714233
Batch 21/64 loss: 0.3094489574432373
Batch 22/64 loss: 0.3024005889892578
Batch 23/64 loss: 0.3052119016647339
Batch 24/64 loss: 0.30478930473327637
Batch 25/64 loss: 0.3072875738143921
Batch 26/64 loss: 0.30247193574905396
Batch 27/64 loss: 0.3089551329612732
Batch 28/64 loss: 0.29975080490112305
Batch 29/64 loss: 0.30633413791656494
Batch 30/64 loss: 0.30324721336364746
Batch 31/64 loss: 0.3123511075973511
Batch 32/64 loss: 0.3023735284805298
Batch 33/64 loss: 0.31847745180130005
Batch 34/64 loss: 0.311023473739624
Batch 35/64 loss: 0.2989617586135864
Batch 36/64 loss: 0.309267520904541
Batch 37/64 loss: 0.3027878999710083
Batch 38/64 loss: 0.305580735206604
Batch 39/64 loss: 0.3026634454727173
Batch 40/64 loss: 0.30039119720458984
Batch 41/64 loss: 0.3068500757217407
Batch 42/64 loss: 0.31133562326431274
Batch 43/64 loss: 0.30197107791900635
Batch 44/64 loss: 0.3071284294128418
Batch 45/64 loss: 0.30059123039245605
Batch 46/64 loss: 0.3123968839645386
Batch 47/64 loss: 0.30111879110336304
Batch 48/64 loss: 0.30561167001724243
Batch 49/64 loss: 0.3180224895477295
Batch 50/64 loss: 0.31342172622680664
Batch 51/64 loss: 0.2985107898712158
Batch 52/64 loss: 0.3051457405090332
Batch 53/64 loss: 0.3080797791481018
Batch 54/64 loss: 0.30930715799331665
Batch 55/64 loss: 0.30733609199523926
Batch 56/64 loss: 0.3138102889060974
Batch 57/64 loss: 0.3163396716117859
Batch 58/64 loss: 0.29936379194259644
Batch 59/64 loss: 0.3039522171020508
Batch 60/64 loss: 0.29061710834503174
Batch 61/64 loss: 0.3055844306945801
Batch 62/64 loss: 0.3220677971839905
Batch 63/64 loss: 0.31084251403808594
Batch 64/64 loss: 0.31560736894607544
Epoch 398  Train loss: 0.30650565273621505  Val loss: 0.33317811792249125
Epoch 399
-------------------------------
Batch 1/64 loss: 0.30318373441696167
Batch 2/64 loss: 0.314589262008667
Batch 3/64 loss: 0.29851651191711426
Batch 4/64 loss: 0.29800283908843994
Batch 5/64 loss: 0.29878926277160645
Batch 6/64 loss: 0.31102555990219116
Batch 7/64 loss: 0.30215704441070557
Batch 8/64 loss: 0.3033156394958496
Batch 9/64 loss: 0.2982233166694641
Batch 10/64 loss: 0.30465900897979736
Batch 11/64 loss: 0.30952751636505127
Batch 12/64 loss: 0.30861949920654297
Batch 13/64 loss: 0.3112189769744873
Batch 14/64 loss: 0.31304872035980225
Batch 15/64 loss: 0.30900001525878906
Batch 16/64 loss: 0.3120323419570923
Batch 17/64 loss: 0.30917835235595703
Batch 18/64 loss: 0.3063965439796448
Batch 19/64 loss: 0.29842305183410645
Batch 20/64 loss: 0.30500632524490356
Batch 21/64 loss: 0.30973637104034424
Batch 22/64 loss: 0.3124213218688965
Batch 23/64 loss: 0.2990427017211914
Batch 24/64 loss: 0.3094590902328491
Batch 25/64 loss: 0.30765509605407715
Batch 26/64 loss: 0.31080567836761475
Batch 27/64 loss: 0.2993365526199341
Batch 28/64 loss: 0.31081080436706543
Batch 29/64 loss: 0.3079546093940735
Batch 30/64 loss: 0.30758994817733765
Batch 31/64 loss: 0.299774706363678
Batch 32/64 loss: 0.3097143769264221
Batch 33/64 loss: 0.3168529272079468
Batch 34/64 loss: 0.30487704277038574
Batch 35/64 loss: 0.31223565340042114
Batch 36/64 loss: 0.3125091791152954
Batch 37/64 loss: 0.30838513374328613
Batch 38/64 loss: 0.30973076820373535
Batch 39/64 loss: 0.3053058981895447
Batch 40/64 loss: 0.30155718326568604
Batch 41/64 loss: 0.29737889766693115
Batch 42/64 loss: 0.3010514974594116
Batch 43/64 loss: 0.3054535388946533
Batch 44/64 loss: 0.29800528287887573
Batch 45/64 loss: 0.3122205138206482
Batch 46/64 loss: 0.30543220043182373
Batch 47/64 loss: 0.3152594566345215
Batch 48/64 loss: 0.3054642677307129
Batch 49/64 loss: 0.30696654319763184
Batch 50/64 loss: 0.30370837450027466
Batch 51/64 loss: 0.30704647302627563
Batch 52/64 loss: 0.3033316731452942
Batch 53/64 loss: 0.30207788944244385
Batch 54/64 loss: 0.31156492233276367
Batch 55/64 loss: 0.3112049102783203
Batch 56/64 loss: 0.3094834089279175
Batch 57/64 loss: 0.31118887662887573
Batch 58/64 loss: 0.30355244874954224
Batch 59/64 loss: 0.3051258325576782
Batch 60/64 loss: 0.30173254013061523
Batch 61/64 loss: 0.29716092348098755
Batch 62/64 loss: 0.3056131601333618
Batch 63/64 loss: 0.30841755867004395
Batch 64/64 loss: 0.30507826805114746
Epoch 399  Train loss: 0.3063202895370184  Val loss: 0.3328508599517272
Epoch 400
-------------------------------
Batch 1/64 loss: 0.30725085735321045
Batch 2/64 loss: 0.30550897121429443
Batch 3/64 loss: 0.3106231093406677
Batch 4/64 loss: 0.3183995485305786
Batch 5/64 loss: 0.30600881576538086
Batch 6/64 loss: 0.314186692237854
Batch 7/64 loss: 0.30706822872161865
Batch 8/64 loss: 0.307746946811676
Batch 9/64 loss: 0.30823367834091187
Batch 10/64 loss: 0.30915260314941406
Batch 11/64 loss: 0.31145286560058594
Batch 12/64 loss: 0.3077539801597595
Batch 13/64 loss: 0.3015783429145813
Batch 14/64 loss: 0.2984866499900818
Batch 15/64 loss: 0.3110969066619873
Batch 16/64 loss: 0.306591272354126
Batch 17/64 loss: 0.307386577129364
Batch 18/64 loss: 0.2965317368507385
Batch 19/64 loss: 0.3148941993713379
Batch 20/64 loss: 0.30760693550109863
Batch 21/64 loss: 0.3049577474594116
Batch 22/64 loss: 0.3142460584640503
Batch 23/64 loss: 0.30993402004241943
Batch 24/64 loss: 0.30714619159698486
Batch 25/64 loss: 0.30605971813201904
Batch 26/64 loss: 0.3084620237350464
Batch 27/64 loss: 0.3094378709793091
Batch 28/64 loss: 0.29789209365844727
Batch 29/64 loss: 0.2959100008010864
Batch 30/64 loss: 0.2936631441116333
Batch 31/64 loss: 0.3016825318336487
Batch 32/64 loss: 0.30237776041030884
Batch 33/64 loss: 0.30648982524871826
Batch 34/64 loss: 0.30649077892303467
Batch 35/64 loss: 0.3114399313926697
Batch 36/64 loss: 0.3062814474105835
Batch 37/64 loss: 0.30356693267822266
Batch 38/64 loss: 0.3092702031135559
Batch 39/64 loss: 0.29973387718200684
Batch 40/64 loss: 0.30850040912628174
Batch 41/64 loss: 0.3054652214050293
Batch 42/64 loss: 0.30342423915863037
Batch 43/64 loss: 0.3013148307800293
Batch 44/64 loss: 0.3097001314163208
Batch 45/64 loss: 0.3074990510940552
Batch 46/64 loss: 0.30363261699676514
Batch 47/64 loss: 0.30260443687438965
Batch 48/64 loss: 0.30736297369003296
Batch 49/64 loss: 0.3091105818748474
Batch 50/64 loss: 0.3063950538635254
Batch 51/64 loss: 0.3050987124443054
Batch 52/64 loss: 0.3078848123550415
Batch 53/64 loss: 0.30813395977020264
Batch 54/64 loss: 0.3060417175292969
Batch 55/64 loss: 0.302715539932251
Batch 56/64 loss: 0.3043093681335449
Batch 57/64 loss: 0.30857568979263306
Batch 58/64 loss: 0.3030446767807007
Batch 59/64 loss: 0.2991701364517212
Batch 60/64 loss: 0.30512404441833496
Batch 61/64 loss: 0.31904882192611694
Batch 62/64 loss: 0.30189812183380127
Batch 63/64 loss: 0.3032127618789673
Batch 64/64 loss: 0.3003905415534973
Epoch 400  Train loss: 0.3061515590723823  Val loss: 0.3318697521367024
Saving best model, epoch: 400
Epoch 401
-------------------------------
Batch 1/64 loss: 0.2909086346626282
Batch 2/64 loss: 0.302523136138916
Batch 3/64 loss: 0.3066979646682739
Batch 4/64 loss: 0.30356478691101074
Batch 5/64 loss: 0.30988913774490356
Batch 6/64 loss: 0.3042086958885193
Batch 7/64 loss: 0.29887843132019043
Batch 8/64 loss: 0.30730462074279785
Batch 9/64 loss: 0.3029625415802002
Batch 10/64 loss: 0.306185245513916
Batch 11/64 loss: 0.30085521936416626
Batch 12/64 loss: 0.313943088054657
Batch 13/64 loss: 0.30840516090393066
Batch 14/64 loss: 0.3105267286300659
Batch 15/64 loss: 0.300733745098114
Batch 16/64 loss: 0.30604714155197144
Batch 17/64 loss: 0.3054375648498535
Batch 18/64 loss: 0.30237478017807007
Batch 19/64 loss: 0.303413987159729
Batch 20/64 loss: 0.3073236346244812
Batch 21/64 loss: 0.3046361207962036
Batch 22/64 loss: 0.29985880851745605
Batch 23/64 loss: 0.30302655696868896
Batch 24/64 loss: 0.3011516332626343
Batch 25/64 loss: 0.30273324251174927
Batch 26/64 loss: 0.30177807807922363
Batch 27/64 loss: 0.3002009391784668
Batch 28/64 loss: 0.30678921937942505
Batch 29/64 loss: 0.3088268041610718
Batch 30/64 loss: 0.3096886873245239
Batch 31/64 loss: 0.3082841634750366
Batch 32/64 loss: 0.3050408959388733
Batch 33/64 loss: 0.30873703956604004
Batch 34/64 loss: 0.31752824783325195
Batch 35/64 loss: 0.29859888553619385
Batch 36/64 loss: 0.303072988986969
Batch 37/64 loss: 0.3135298490524292
Batch 38/64 loss: 0.3064408302307129
Batch 39/64 loss: 0.3096165657043457
Batch 40/64 loss: 0.30347007513046265
Batch 41/64 loss: 0.3096824288368225
Batch 42/64 loss: 0.30730950832366943
Batch 43/64 loss: 0.30386555194854736
Batch 44/64 loss: 0.30547189712524414
Batch 45/64 loss: 0.3016970157623291
Batch 46/64 loss: 0.3052941560745239
Batch 47/64 loss: 0.312322199344635
Batch 48/64 loss: 0.3069206476211548
Batch 49/64 loss: 0.29936474561691284
Batch 50/64 loss: 0.3085542917251587
Batch 51/64 loss: 0.30182600021362305
Batch 52/64 loss: 0.2985285520553589
Batch 53/64 loss: 0.322751522064209
Batch 54/64 loss: 0.30518853664398193
Batch 55/64 loss: 0.3048896789550781
Batch 56/64 loss: 0.3096328377723694
Batch 57/64 loss: 0.3035151958465576
Batch 58/64 loss: 0.30319321155548096
Batch 59/64 loss: 0.3043217658996582
Batch 60/64 loss: 0.31176888942718506
Batch 61/64 loss: 0.3114212155342102
Batch 62/64 loss: 0.3250565528869629
Batch 63/64 loss: 0.3076469898223877
Batch 64/64 loss: 0.31254661083221436
Epoch 401  Train loss: 0.30603650551216277  Val loss: 0.3329817796081202
Epoch 402
-------------------------------
Batch 1/64 loss: 0.30415916442871094
Batch 2/64 loss: 0.30177998542785645
Batch 3/64 loss: 0.3005160093307495
Batch 4/64 loss: 0.29760658740997314
Batch 5/64 loss: 0.3091162443161011
Batch 6/64 loss: 0.3097989559173584
Batch 7/64 loss: 0.3111588954925537
Batch 8/64 loss: 0.31143903732299805
Batch 9/64 loss: 0.31680887937545776
Batch 10/64 loss: 0.32093942165374756
Batch 11/64 loss: 0.3042660355567932
Batch 12/64 loss: 0.3095989227294922
Batch 13/64 loss: 0.3088266849517822
Batch 14/64 loss: 0.2993687391281128
Batch 15/64 loss: 0.30996501445770264
Batch 16/64 loss: 0.298393189907074
Batch 17/64 loss: 0.2991044521331787
Batch 18/64 loss: 0.30292826890945435
Batch 19/64 loss: 0.3038523197174072
Batch 20/64 loss: 0.30348753929138184
Batch 21/64 loss: 0.303924024105072
Batch 22/64 loss: 0.2968420386314392
Batch 23/64 loss: 0.3139626979827881
Batch 24/64 loss: 0.3116793632507324
Batch 25/64 loss: 0.3134313225746155
Batch 26/64 loss: 0.30525869131088257
Batch 27/64 loss: 0.30829834938049316
Batch 28/64 loss: 0.30821192264556885
Batch 29/64 loss: 0.3125949501991272
Batch 30/64 loss: 0.3020135164260864
Batch 31/64 loss: 0.29702967405319214
Batch 32/64 loss: 0.3025704622268677
Batch 33/64 loss: 0.3037600517272949
Batch 34/64 loss: 0.3093451261520386
Batch 35/64 loss: 0.3029693365097046
Batch 36/64 loss: 0.3053511381149292
Batch 37/64 loss: 0.3133666515350342
Batch 38/64 loss: 0.3038860559463501
Batch 39/64 loss: 0.31222039461135864
Batch 40/64 loss: 0.307242751121521
Batch 41/64 loss: 0.2943921685218811
Batch 42/64 loss: 0.30164533853530884
Batch 43/64 loss: 0.31017327308654785
Batch 44/64 loss: 0.3023892641067505
Batch 45/64 loss: 0.30788445472717285
Batch 46/64 loss: 0.3164266347885132
Batch 47/64 loss: 0.30086082220077515
Batch 48/64 loss: 0.3082086443901062
Batch 49/64 loss: 0.3017169237136841
Batch 50/64 loss: 0.3107154369354248
Batch 51/64 loss: 0.29942041635513306
Batch 52/64 loss: 0.2978159189224243
Batch 53/64 loss: 0.31625527143478394
Batch 54/64 loss: 0.3175044059753418
Batch 55/64 loss: 0.3040156364440918
Batch 56/64 loss: 0.3054102063179016
Batch 57/64 loss: 0.31180375814437866
Batch 58/64 loss: 0.30984675884246826
Batch 59/64 loss: 0.300420880317688
Batch 60/64 loss: 0.29700767993927
Batch 61/64 loss: 0.30525290966033936
Batch 62/64 loss: 0.3102608919143677
Batch 63/64 loss: 0.30777615308761597
Batch 64/64 loss: 0.3026714324951172
Epoch 402  Train loss: 0.30621616139131436  Val loss: 0.3325298119246755
Epoch 403
-------------------------------
Batch 1/64 loss: 0.31424957513809204
Batch 2/64 loss: 0.3067466616630554
Batch 3/64 loss: 0.3062729835510254
Batch 4/64 loss: 0.3061789274215698
Batch 5/64 loss: 0.30479562282562256
Batch 6/64 loss: 0.30878984928131104
Batch 7/64 loss: 0.3064880967140198
Batch 8/64 loss: 0.297793984413147
Batch 9/64 loss: 0.3067237138748169
Batch 10/64 loss: 0.3076931834220886
Batch 11/64 loss: 0.3203386068344116
Batch 12/64 loss: 0.3053901791572571
Batch 13/64 loss: 0.29893916845321655
Batch 14/64 loss: 0.3040456771850586
Batch 15/64 loss: 0.294253945350647
Batch 16/64 loss: 0.3045623302459717
Batch 17/64 loss: 0.30005908012390137
Batch 18/64 loss: 0.3047301769256592
Batch 19/64 loss: 0.30764520168304443
Batch 20/64 loss: 0.30551767349243164
Batch 21/64 loss: 0.3059554100036621
Batch 22/64 loss: 0.3091502785682678
Batch 23/64 loss: 0.3157695531845093
Batch 24/64 loss: 0.30618059635162354
Batch 25/64 loss: 0.30890005826950073
Batch 26/64 loss: 0.299371600151062
Batch 27/64 loss: 0.30172133445739746
Batch 28/64 loss: 0.3064866065979004
Batch 29/64 loss: 0.30117613077163696
Batch 30/64 loss: 0.30540549755096436
Batch 31/64 loss: 0.30322420597076416
Batch 32/64 loss: 0.3057202100753784
Batch 33/64 loss: 0.30728721618652344
Batch 34/64 loss: 0.30818426609039307
Batch 35/64 loss: 0.305417537689209
Batch 36/64 loss: 0.30900299549102783
Batch 37/64 loss: 0.30226534605026245
Batch 38/64 loss: 0.2956128716468811
Batch 39/64 loss: 0.31014734506607056
Batch 40/64 loss: 0.3091120719909668
Batch 41/64 loss: 0.31050801277160645
Batch 42/64 loss: 0.30576205253601074
Batch 43/64 loss: 0.30076128244400024
Batch 44/64 loss: 0.3131222724914551
Batch 45/64 loss: 0.3062046766281128
Batch 46/64 loss: 0.3015737533569336
Batch 47/64 loss: 0.30813926458358765
Batch 48/64 loss: 0.3031045198440552
Batch 49/64 loss: 0.300123393535614
Batch 50/64 loss: 0.30372798442840576
Batch 51/64 loss: 0.2972026467323303
Batch 52/64 loss: 0.31464409828186035
Batch 53/64 loss: 0.29541265964508057
Batch 54/64 loss: 0.29446959495544434
Batch 55/64 loss: 0.30493950843811035
Batch 56/64 loss: 0.30724775791168213
Batch 57/64 loss: 0.31248152256011963
Batch 58/64 loss: 0.2987576723098755
Batch 59/64 loss: 0.31272566318511963
Batch 60/64 loss: 0.3015472888946533
Batch 61/64 loss: 0.314882755279541
Batch 62/64 loss: 0.3076682686805725
Batch 63/64 loss: 0.31160736083984375
Batch 64/64 loss: 0.3098893165588379
Epoch 403  Train loss: 0.30566802772821167  Val loss: 0.3336800109479845
Epoch 404
-------------------------------
Batch 1/64 loss: 0.312741219997406
Batch 2/64 loss: 0.3077399730682373
Batch 3/64 loss: 0.3154902458190918
Batch 4/64 loss: 0.3210447430610657
Batch 5/64 loss: 0.30736297369003296
Batch 6/64 loss: 0.29897695779800415
Batch 7/64 loss: 0.31449419260025024
Batch 8/64 loss: 0.3029618263244629
Batch 9/64 loss: 0.3186516761779785
Batch 10/64 loss: 0.30599820613861084
Batch 11/64 loss: 0.2987246513366699
Batch 12/64 loss: 0.300706148147583
Batch 13/64 loss: 0.30627351999282837
Batch 14/64 loss: 0.29855358600616455
Batch 15/64 loss: 0.2991957664489746
Batch 16/64 loss: 0.3055614233016968
Batch 17/64 loss: 0.31502294540405273
Batch 18/64 loss: 0.30902886390686035
Batch 19/64 loss: 0.3032689690589905
Batch 20/64 loss: 0.3027927875518799
Batch 21/64 loss: 0.29804831743240356
Batch 22/64 loss: 0.3066970109939575
Batch 23/64 loss: 0.29576194286346436
Batch 24/64 loss: 0.3088465929031372
Batch 25/64 loss: 0.3064110279083252
Batch 26/64 loss: 0.3108261227607727
Batch 27/64 loss: 0.300123929977417
Batch 28/64 loss: 0.3127497434616089
Batch 29/64 loss: 0.3103911876678467
Batch 30/64 loss: 0.3051544427871704
Batch 31/64 loss: 0.29735398292541504
Batch 32/64 loss: 0.3014103174209595
Batch 33/64 loss: 0.29823899269104004
Batch 34/64 loss: 0.2975039482116699
Batch 35/64 loss: 0.3131781816482544
Batch 36/64 loss: 0.3043978214263916
Batch 37/64 loss: 0.31257957220077515
Batch 38/64 loss: 0.31563639640808105
Batch 39/64 loss: 0.30230283737182617
Batch 40/64 loss: 0.29728883504867554
Batch 41/64 loss: 0.305866003036499
Batch 42/64 loss: 0.3010435104370117
Batch 43/64 loss: 0.30858278274536133
Batch 44/64 loss: 0.3073173761367798
Batch 45/64 loss: 0.3003149628639221
Batch 46/64 loss: 0.3099796772003174
Batch 47/64 loss: 0.2949695587158203
Batch 48/64 loss: 0.31175559759140015
Batch 49/64 loss: 0.3044842481613159
Batch 50/64 loss: 0.3040289878845215
Batch 51/64 loss: 0.3033829927444458
Batch 52/64 loss: 0.30919545888900757
Batch 53/64 loss: 0.3087470531463623
Batch 54/64 loss: 0.3051060438156128
Batch 55/64 loss: 0.3011534810066223
Batch 56/64 loss: 0.3058350682258606
Batch 57/64 loss: 0.3107717037200928
Batch 58/64 loss: 0.3065606355667114
Batch 59/64 loss: 0.29926443099975586
Batch 60/64 loss: 0.31130433082580566
Batch 61/64 loss: 0.31355154514312744
Batch 62/64 loss: 0.2983114719390869
Batch 63/64 loss: 0.3131924867630005
Batch 64/64 loss: 0.3089161515235901
Epoch 404  Train loss: 0.30597487688064573  Val loss: 0.3326672778506459
Epoch 405
-------------------------------
Batch 1/64 loss: 0.29912179708480835
Batch 2/64 loss: 0.31307417154312134
Batch 3/64 loss: 0.3042442798614502
Batch 4/64 loss: 0.30768531560897827
Batch 5/64 loss: 0.30658507347106934
Batch 6/64 loss: 0.30328452587127686
Batch 7/64 loss: 0.29899024963378906
Batch 8/64 loss: 0.3043478727340698
Batch 9/64 loss: 0.31460511684417725
Batch 10/64 loss: 0.30694204568862915
Batch 11/64 loss: 0.3095419406890869
Batch 12/64 loss: 0.30734044313430786
Batch 13/64 loss: 0.30557864904403687
Batch 14/64 loss: 0.2966214418411255
Batch 15/64 loss: 0.30619585514068604
Batch 16/64 loss: 0.3050117492675781
Batch 17/64 loss: 0.305123507976532
Batch 18/64 loss: 0.3086913824081421
Batch 19/64 loss: 0.3064308762550354
Batch 20/64 loss: 0.3072056174278259
Batch 21/64 loss: 0.3055846691131592
Batch 22/64 loss: 0.3051301836967468
Batch 23/64 loss: 0.30466270446777344
Batch 24/64 loss: 0.3131735324859619
Batch 25/64 loss: 0.30923938751220703
Batch 26/64 loss: 0.30939269065856934
Batch 27/64 loss: 0.3060716390609741
Batch 28/64 loss: 0.3057185411453247
Batch 29/64 loss: 0.30462872982025146
Batch 30/64 loss: 0.30454885959625244
Batch 31/64 loss: 0.2952786684036255
Batch 32/64 loss: 0.29664576053619385
Batch 33/64 loss: 0.30550575256347656
Batch 34/64 loss: 0.30734550952911377
Batch 35/64 loss: 0.3037971258163452
Batch 36/64 loss: 0.3110681176185608
Batch 37/64 loss: 0.3070410490036011
Batch 38/64 loss: 0.3025006055831909
Batch 39/64 loss: 0.2996847629547119
Batch 40/64 loss: 0.3118554353713989
Batch 41/64 loss: 0.30180031061172485
Batch 42/64 loss: 0.3085927963256836
Batch 43/64 loss: 0.30653464794158936
Batch 44/64 loss: 0.30585622787475586
Batch 45/64 loss: 0.3100231885910034
Batch 46/64 loss: 0.30933475494384766
Batch 47/64 loss: 0.3100442886352539
Batch 48/64 loss: 0.3059030771255493
Batch 49/64 loss: 0.3033560514450073
Batch 50/64 loss: 0.31830114126205444
Batch 51/64 loss: 0.30976545810699463
Batch 52/64 loss: 0.29899895191192627
Batch 53/64 loss: 0.3090037703514099
Batch 54/64 loss: 0.31365710496902466
Batch 55/64 loss: 0.30632615089416504
Batch 56/64 loss: 0.3010474443435669
Batch 57/64 loss: 0.2960714101791382
Batch 58/64 loss: 0.306699275970459
Batch 59/64 loss: 0.3005821704864502
Batch 60/64 loss: 0.31157374382019043
Batch 61/64 loss: 0.30167633295059204
Batch 62/64 loss: 0.30939680337905884
Batch 63/64 loss: 0.2981855273246765
Batch 64/64 loss: 0.30959707498550415
Epoch 405  Train loss: 0.3058890050532771  Val loss: 0.3327134167615491
Epoch 406
-------------------------------
Batch 1/64 loss: 0.3033161163330078
Batch 2/64 loss: 0.31030261516571045
Batch 3/64 loss: 0.29990124702453613
Batch 4/64 loss: 0.299968421459198
Batch 5/64 loss: 0.31398504972457886
Batch 6/64 loss: 0.3004692792892456
Batch 7/64 loss: 0.30601024627685547
Batch 8/64 loss: 0.30483222007751465
Batch 9/64 loss: 0.30867457389831543
Batch 10/64 loss: 0.30216848850250244
Batch 11/64 loss: 0.30999982357025146
Batch 12/64 loss: 0.30591291189193726
Batch 13/64 loss: 0.29775893688201904
Batch 14/64 loss: 0.303194522857666
Batch 15/64 loss: 0.2982351779937744
Batch 16/64 loss: 0.30248701572418213
Batch 17/64 loss: 0.3140104413032532
Batch 18/64 loss: 0.30940163135528564
Batch 19/64 loss: 0.3141847848892212
Batch 20/64 loss: 0.30931663513183594
Batch 21/64 loss: 0.3007625341415405
Batch 22/64 loss: 0.3047547936439514
Batch 23/64 loss: 0.3079487681388855
Batch 24/64 loss: 0.310221791267395
Batch 25/64 loss: 0.30224668979644775
Batch 26/64 loss: 0.3013058304786682
Batch 27/64 loss: 0.309039831161499
Batch 28/64 loss: 0.31530988216400146
Batch 29/64 loss: 0.30436551570892334
Batch 30/64 loss: 0.3089020848274231
Batch 31/64 loss: 0.3020641803741455
Batch 32/64 loss: 0.30599474906921387
Batch 33/64 loss: 0.31098008155822754
Batch 34/64 loss: 0.3044087886810303
Batch 35/64 loss: 0.30458271503448486
Batch 36/64 loss: 0.3046451807022095
Batch 37/64 loss: 0.3030991554260254
Batch 38/64 loss: 0.30677664279937744
Batch 39/64 loss: 0.30404865741729736
Batch 40/64 loss: 0.3027481436729431
Batch 41/64 loss: 0.3035891056060791
Batch 42/64 loss: 0.3110513687133789
Batch 43/64 loss: 0.3049205541610718
Batch 44/64 loss: 0.3080979585647583
Batch 45/64 loss: 0.30338412523269653
Batch 46/64 loss: 0.3087571859359741
Batch 47/64 loss: 0.3009141683578491
Batch 48/64 loss: 0.3029177188873291
Batch 49/64 loss: 0.30349457263946533
Batch 50/64 loss: 0.3122212886810303
Batch 51/64 loss: 0.29968464374542236
Batch 52/64 loss: 0.30788230895996094
Batch 53/64 loss: 0.30920541286468506
Batch 54/64 loss: 0.30006980895996094
Batch 55/64 loss: 0.3083040714263916
Batch 56/64 loss: 0.31462663412094116
Batch 57/64 loss: 0.3102942705154419
Batch 58/64 loss: 0.296106219291687
Batch 59/64 loss: 0.306943416595459
Batch 60/64 loss: 0.30874812602996826
Batch 61/64 loss: 0.3154882788658142
Batch 62/64 loss: 0.30327653884887695
Batch 63/64 loss: 0.3062509298324585
Batch 64/64 loss: 0.3056219220161438
Epoch 406  Train loss: 0.30594166751001395  Val loss: 0.33465404424470724
Epoch 407
-------------------------------
Batch 1/64 loss: 0.2979450225830078
Batch 2/64 loss: 0.30331045389175415
Batch 3/64 loss: 0.3246006965637207
Batch 4/64 loss: 0.3027586340904236
Batch 5/64 loss: 0.3047219514846802
Batch 6/64 loss: 0.3066176772117615
Batch 7/64 loss: 0.29577386379241943
Batch 8/64 loss: 0.2979440689086914
Batch 9/64 loss: 0.3096228837966919
Batch 10/64 loss: 0.30800890922546387
Batch 11/64 loss: 0.3144688606262207
Batch 12/64 loss: 0.3114365339279175
Batch 13/64 loss: 0.3018306493759155
Batch 14/64 loss: 0.3131653666496277
Batch 15/64 loss: 0.31467294692993164
Batch 16/64 loss: 0.3062670826911926
Batch 17/64 loss: 0.3094381093978882
Batch 18/64 loss: 0.3088568449020386
Batch 19/64 loss: 0.3160547614097595
Batch 20/64 loss: 0.30557483434677124
Batch 21/64 loss: 0.3039836287498474
Batch 22/64 loss: 0.3182319402694702
Batch 23/64 loss: 0.3006361722946167
Batch 24/64 loss: 0.3097541332244873
Batch 25/64 loss: 0.30937838554382324
Batch 26/64 loss: 0.30796146392822266
Batch 27/64 loss: 0.3120194673538208
Batch 28/64 loss: 0.3067625164985657
Batch 29/64 loss: 0.29181456565856934
Batch 30/64 loss: 0.30979835987091064
Batch 31/64 loss: 0.3047201633453369
Batch 32/64 loss: 0.29978132247924805
Batch 33/64 loss: 0.30135786533355713
Batch 34/64 loss: 0.3146522045135498
Batch 35/64 loss: 0.30635738372802734
Batch 36/64 loss: 0.3067796230316162
Batch 37/64 loss: 0.29385852813720703
Batch 38/64 loss: 0.30984312295913696
Batch 39/64 loss: 0.29598569869995117
Batch 40/64 loss: 0.30113232135772705
Batch 41/64 loss: 0.30035728216171265
Batch 42/64 loss: 0.300028920173645
Batch 43/64 loss: 0.31630319356918335
Batch 44/64 loss: 0.312028706073761
Batch 45/64 loss: 0.3091007471084595
Batch 46/64 loss: 0.29816490411758423
Batch 47/64 loss: 0.30910009145736694
Batch 48/64 loss: 0.31649601459503174
Batch 49/64 loss: 0.3101341724395752
Batch 50/64 loss: 0.30258476734161377
Batch 51/64 loss: 0.30010366439819336
Batch 52/64 loss: 0.30220550298690796
Batch 53/64 loss: 0.3033566474914551
Batch 54/64 loss: 0.3012167811393738
Batch 55/64 loss: 0.3130149841308594
Batch 56/64 loss: 0.3089083433151245
Batch 57/64 loss: 0.30447185039520264
Batch 58/64 loss: 0.3046073913574219
Batch 59/64 loss: 0.30401235818862915
Batch 60/64 loss: 0.2989526391029358
Batch 61/64 loss: 0.3051298260688782
Batch 62/64 loss: 0.31075263023376465
Batch 63/64 loss: 0.30655092000961304
Batch 64/64 loss: 0.30886250734329224
Epoch 407  Train loss: 0.3063075801905464  Val loss: 0.3325443583255781
Epoch 408
-------------------------------
Batch 1/64 loss: 0.30549532175064087
Batch 2/64 loss: 0.30398523807525635
Batch 3/64 loss: 0.3073354959487915
Batch 4/64 loss: 0.3010869026184082
Batch 5/64 loss: 0.3047640919685364
Batch 6/64 loss: 0.3014811873435974
Batch 7/64 loss: 0.299821138381958
Batch 8/64 loss: 0.3112654685974121
Batch 9/64 loss: 0.2976509928703308
Batch 10/64 loss: 0.3143202066421509
Batch 11/64 loss: 0.30492138862609863
Batch 12/64 loss: 0.30892127752304077
Batch 13/64 loss: 0.2947319746017456
Batch 14/64 loss: 0.3009302616119385
Batch 15/64 loss: 0.3076084852218628
Batch 16/64 loss: 0.3025658130645752
Batch 17/64 loss: 0.295884370803833
Batch 18/64 loss: 0.3067437410354614
Batch 19/64 loss: 0.3146902918815613
Batch 20/64 loss: 0.29750508069992065
Batch 21/64 loss: 0.3098817467689514
Batch 22/64 loss: 0.31432586908340454
Batch 23/64 loss: 0.3071172833442688
Batch 24/64 loss: 0.3172551393508911
Batch 25/64 loss: 0.30795472860336304
Batch 26/64 loss: 0.3002331256866455
Batch 27/64 loss: 0.3053377866744995
Batch 28/64 loss: 0.3094555139541626
Batch 29/64 loss: 0.2956240177154541
Batch 30/64 loss: 0.3120729923248291
Batch 31/64 loss: 0.30494701862335205
Batch 32/64 loss: 0.30323100090026855
Batch 33/64 loss: 0.312433660030365
Batch 34/64 loss: 0.30216485261917114
Batch 35/64 loss: 0.3082265257835388
Batch 36/64 loss: 0.31155383586883545
Batch 37/64 loss: 0.3104814887046814
Batch 38/64 loss: 0.30986952781677246
Batch 39/64 loss: 0.30249524116516113
Batch 40/64 loss: 0.3128882646560669
Batch 41/64 loss: 0.31242334842681885
Batch 42/64 loss: 0.3042111396789551
Batch 43/64 loss: 0.3188115954399109
Batch 44/64 loss: 0.30700647830963135
Batch 45/64 loss: 0.3149193525314331
Batch 46/64 loss: 0.3032088875770569
Batch 47/64 loss: 0.3057442903518677
Batch 48/64 loss: 0.30152809619903564
Batch 49/64 loss: 0.2990914583206177
Batch 50/64 loss: 0.3089582324028015
Batch 51/64 loss: 0.31478118896484375
Batch 52/64 loss: 0.3079373836517334
Batch 53/64 loss: 0.30497270822525024
Batch 54/64 loss: 0.30944132804870605
Batch 55/64 loss: 0.3085273504257202
Batch 56/64 loss: 0.3065534234046936
Batch 57/64 loss: 0.30167174339294434
Batch 58/64 loss: 0.30841249227523804
Batch 59/64 loss: 0.3009415864944458
Batch 60/64 loss: 0.30738401412963867
Batch 61/64 loss: 0.310924232006073
Batch 62/64 loss: 0.30849266052246094
Batch 63/64 loss: 0.31345391273498535
Batch 64/64 loss: 0.3014185428619385
Epoch 408  Train loss: 0.30658382995455874  Val loss: 0.33424615941916136
Epoch 409
-------------------------------
Batch 1/64 loss: 0.29654133319854736
Batch 2/64 loss: 0.3045341968536377
Batch 3/64 loss: 0.2957566976547241
Batch 4/64 loss: 0.31297415494918823
Batch 5/64 loss: 0.30155134201049805
Batch 6/64 loss: 0.29704880714416504
Batch 7/64 loss: 0.31123781204223633
Batch 8/64 loss: 0.31019526720046997
Batch 9/64 loss: 0.30419403314590454
Batch 10/64 loss: 0.2974703311920166
Batch 11/64 loss: 0.3131245970726013
Batch 12/64 loss: 0.3075864315032959
Batch 13/64 loss: 0.30861151218414307
Batch 14/64 loss: 0.3063245415687561
Batch 15/64 loss: 0.3100758194923401
Batch 16/64 loss: 0.2987360954284668
Batch 17/64 loss: 0.3023674488067627
Batch 18/64 loss: 0.30727601051330566
Batch 19/64 loss: 0.30947333574295044
Batch 20/64 loss: 0.3122180700302124
Batch 21/64 loss: 0.3033755421638489
Batch 22/64 loss: 0.3050500154495239
Batch 23/64 loss: 0.30390167236328125
Batch 24/64 loss: 0.30272555351257324
Batch 25/64 loss: 0.2999166250228882
Batch 26/64 loss: 0.308102011680603
Batch 27/64 loss: 0.31787562370300293
Batch 28/64 loss: 0.3091786503791809
Batch 29/64 loss: 0.30599695444107056
Batch 30/64 loss: 0.3106181025505066
Batch 31/64 loss: 0.3066406846046448
Batch 32/64 loss: 0.3000912666320801
Batch 33/64 loss: 0.30562543869018555
Batch 34/64 loss: 0.3129870295524597
Batch 35/64 loss: 0.29603326320648193
Batch 36/64 loss: 0.3076343536376953
Batch 37/64 loss: 0.3055691123008728
Batch 38/64 loss: 0.3079681396484375
Batch 39/64 loss: 0.3140772581100464
Batch 40/64 loss: 0.3081734776496887
Batch 41/64 loss: 0.3051719069480896
Batch 42/64 loss: 0.30336081981658936
Batch 43/64 loss: 0.30405348539352417
Batch 44/64 loss: 0.31077343225479126
Batch 45/64 loss: 0.3101189136505127
Batch 46/64 loss: 0.30708587169647217
Batch 47/64 loss: 0.3146040439605713
Batch 48/64 loss: 0.30294543504714966
Batch 49/64 loss: 0.31159263849258423
Batch 50/64 loss: 0.3020366430282593
Batch 51/64 loss: 0.30094271898269653
Batch 52/64 loss: 0.31197261810302734
Batch 53/64 loss: 0.2971007823944092
Batch 54/64 loss: 0.3091042637825012
Batch 55/64 loss: 0.32356905937194824
Batch 56/64 loss: 0.3038635849952698
Batch 57/64 loss: 0.30488431453704834
Batch 58/64 loss: 0.30961310863494873
Batch 59/64 loss: 0.3131653070449829
Batch 60/64 loss: 0.31030476093292236
Batch 61/64 loss: 0.2953699231147766
Batch 62/64 loss: 0.31567561626434326
Batch 63/64 loss: 0.30869829654693604
Batch 64/64 loss: 0.3030431270599365
Epoch 409  Train loss: 0.30654319220898196  Val loss: 0.3334668051336229
Epoch 410
-------------------------------
Batch 1/64 loss: 0.3044685125350952
Batch 2/64 loss: 0.3112220764160156
Batch 3/64 loss: 0.2995903491973877
Batch 4/64 loss: 0.30950242280960083
Batch 5/64 loss: 0.31728821992874146
Batch 6/64 loss: 0.30092906951904297
Batch 7/64 loss: 0.3058006167411804
Batch 8/64 loss: 0.30027830600738525
Batch 9/64 loss: 0.30877578258514404
Batch 10/64 loss: 0.30806559324264526
Batch 11/64 loss: 0.30716216564178467
Batch 12/64 loss: 0.31144994497299194
Batch 13/64 loss: 0.30459654331207275
Batch 14/64 loss: 0.304684579372406
Batch 15/64 loss: 0.3108988404273987
Batch 16/64 loss: 0.294092059135437
Batch 17/64 loss: 0.30734241008758545
Batch 18/64 loss: 0.30031561851501465
Batch 19/64 loss: 0.296050488948822
Batch 20/64 loss: 0.31333833932876587
Batch 21/64 loss: 0.30166709423065186
Batch 22/64 loss: 0.31133878231048584
Batch 23/64 loss: 0.29996347427368164
Batch 24/64 loss: 0.31590521335601807
Batch 25/64 loss: 0.30231761932373047
Batch 26/64 loss: 0.3064230680465698
Batch 27/64 loss: 0.30634450912475586
Batch 28/64 loss: 0.30158787965774536
Batch 29/64 loss: 0.31033915281295776
Batch 30/64 loss: 0.3118330240249634
Batch 31/64 loss: 0.2948135733604431
Batch 32/64 loss: 0.311623215675354
Batch 33/64 loss: 0.297939658164978
Batch 34/64 loss: 0.3077883720397949
Batch 35/64 loss: 0.3035648465156555
Batch 36/64 loss: 0.30294162034988403
Batch 37/64 loss: 0.3077141046524048
Batch 38/64 loss: 0.302975058555603
Batch 39/64 loss: 0.31107383966445923
Batch 40/64 loss: 0.3101525902748108
Batch 41/64 loss: 0.3058595657348633
Batch 42/64 loss: 0.29931169748306274
Batch 43/64 loss: 0.3012021780014038
Batch 44/64 loss: 0.3038022518157959
Batch 45/64 loss: 0.31163978576660156
Batch 46/64 loss: 0.31496739387512207
Batch 47/64 loss: 0.30639779567718506
Batch 48/64 loss: 0.30922579765319824
Batch 49/64 loss: 0.299116849899292
Batch 50/64 loss: 0.29510897397994995
Batch 51/64 loss: 0.3031499981880188
Batch 52/64 loss: 0.310103178024292
Batch 53/64 loss: 0.3053317070007324
Batch 54/64 loss: 0.30448710918426514
Batch 55/64 loss: 0.30914855003356934
Batch 56/64 loss: 0.29775941371917725
Batch 57/64 loss: 0.30185210704803467
Batch 58/64 loss: 0.31721383333206177
Batch 59/64 loss: 0.3022531270980835
Batch 60/64 loss: 0.3102961778640747
Batch 61/64 loss: 0.31060051918029785
Batch 62/64 loss: 0.29327821731567383
Batch 63/64 loss: 0.29519975185394287
Batch 64/64 loss: 0.3144419193267822
Epoch 410  Train loss: 0.30552621261746277  Val loss: 0.3338507549049928
Epoch 411
-------------------------------
Batch 1/64 loss: 0.3028453588485718
Batch 2/64 loss: 0.3038818836212158
Batch 3/64 loss: 0.3042382597923279
Batch 4/64 loss: 0.29453396797180176
Batch 5/64 loss: 0.31085360050201416
Batch 6/64 loss: 0.30932188034057617
Batch 7/64 loss: 0.3131323456764221
Batch 8/64 loss: 0.30229711532592773
Batch 9/64 loss: 0.3044344186782837
Batch 10/64 loss: 0.300373911857605
Batch 11/64 loss: 0.3143916726112366
Batch 12/64 loss: 0.3179788589477539
Batch 13/64 loss: 0.3020639419555664
Batch 14/64 loss: 0.30347371101379395
Batch 15/64 loss: 0.3076210021972656
Batch 16/64 loss: 0.30279403924942017
Batch 17/64 loss: 0.29934167861938477
Batch 18/64 loss: 0.3010547161102295
Batch 19/64 loss: 0.3101159334182739
Batch 20/64 loss: 0.296622633934021
Batch 21/64 loss: 0.3036230802536011
Batch 22/64 loss: 0.3047196865081787
Batch 23/64 loss: 0.3195609450340271
Batch 24/64 loss: 0.30715394020080566
Batch 25/64 loss: 0.30281955003738403
Batch 26/64 loss: 0.297885537147522
Batch 27/64 loss: 0.30649614334106445
Batch 28/64 loss: 0.3044279217720032
Batch 29/64 loss: 0.2944299578666687
Batch 30/64 loss: 0.3058331608772278
Batch 31/64 loss: 0.29387837648391724
Batch 32/64 loss: 0.3248854875564575
Batch 33/64 loss: 0.3043860197067261
Batch 34/64 loss: 0.3083610534667969
Batch 35/64 loss: 0.3102918863296509
Batch 36/64 loss: 0.3012058734893799
Batch 37/64 loss: 0.31296253204345703
Batch 38/64 loss: 0.3165853023529053
Batch 39/64 loss: 0.31327539682388306
Batch 40/64 loss: 0.30837202072143555
Batch 41/64 loss: 0.3104310631752014
Batch 42/64 loss: 0.30800318717956543
Batch 43/64 loss: 0.3018162250518799
Batch 44/64 loss: 0.30749034881591797
Batch 45/64 loss: 0.29953932762145996
Batch 46/64 loss: 0.3074820041656494
Batch 47/64 loss: 0.30055439472198486
Batch 48/64 loss: 0.3008437156677246
Batch 49/64 loss: 0.3032040596008301
Batch 50/64 loss: 0.30207574367523193
Batch 51/64 loss: 0.30577993392944336
Batch 52/64 loss: 0.2977876663208008
Batch 53/64 loss: 0.29922014474868774
Batch 54/64 loss: 0.2986167073249817
Batch 55/64 loss: 0.29841965436935425
Batch 56/64 loss: 0.3038173317909241
Batch 57/64 loss: 0.30680543184280396
Batch 58/64 loss: 0.3084597587585449
Batch 59/64 loss: 0.2995114326477051
Batch 60/64 loss: 0.3083186149597168
Batch 61/64 loss: 0.3084712028503418
Batch 62/64 loss: 0.30612504482269287
Batch 63/64 loss: 0.29668378829956055
Batch 64/64 loss: 0.3057640790939331
Epoch 411  Train loss: 0.305118504225039  Val loss: 0.33427066122953014
Epoch 412
-------------------------------
Batch 1/64 loss: 0.31454169750213623
Batch 2/64 loss: 0.3102318048477173
Batch 3/64 loss: 0.30092930793762207
Batch 4/64 loss: 0.30944859981536865
Batch 5/64 loss: 0.3041822910308838
Batch 6/64 loss: 0.30744093656539917
Batch 7/64 loss: 0.30921471118927
Batch 8/64 loss: 0.2987830638885498
Batch 9/64 loss: 0.2975403666496277
Batch 10/64 loss: 0.30397653579711914
Batch 11/64 loss: 0.3010607957839966
Batch 12/64 loss: 0.29235708713531494
Batch 13/64 loss: 0.29959386587142944
Batch 14/64 loss: 0.3242306709289551
Batch 15/64 loss: 0.29993754625320435
Batch 16/64 loss: 0.30718737840652466
Batch 17/64 loss: 0.3043091297149658
Batch 18/64 loss: 0.3119860291481018
Batch 19/64 loss: 0.30235397815704346
Batch 20/64 loss: 0.2995131015777588
Batch 21/64 loss: 0.3019242286682129
Batch 22/64 loss: 0.3030964136123657
Batch 23/64 loss: 0.31239789724349976
Batch 24/64 loss: 0.2976738214492798
Batch 25/64 loss: 0.3096116781234741
Batch 26/64 loss: 0.30064094066619873
Batch 27/64 loss: 0.3034653663635254
Batch 28/64 loss: 0.3164411783218384
Batch 29/64 loss: 0.3087615966796875
Batch 30/64 loss: 0.3004624843597412
Batch 31/64 loss: 0.3065059185028076
Batch 32/64 loss: 0.30787813663482666
Batch 33/64 loss: 0.3027089834213257
Batch 34/64 loss: 0.30390405654907227
Batch 35/64 loss: 0.29424864053726196
Batch 36/64 loss: 0.3205171823501587
Batch 37/64 loss: 0.3094838857650757
Batch 38/64 loss: 0.30690062046051025
Batch 39/64 loss: 0.3010580539703369
Batch 40/64 loss: 0.30283117294311523
Batch 41/64 loss: 0.31582748889923096
Batch 42/64 loss: 0.29770833253860474
Batch 43/64 loss: 0.3019055724143982
Batch 44/64 loss: 0.3069794178009033
Batch 45/64 loss: 0.30981552600860596
Batch 46/64 loss: 0.31109917163848877
Batch 47/64 loss: 0.31663644313812256
Batch 48/64 loss: 0.30892622470855713
Batch 49/64 loss: 0.3029036521911621
Batch 50/64 loss: 0.3057437539100647
Batch 51/64 loss: 0.30350732803344727
Batch 52/64 loss: 0.309314489364624
Batch 53/64 loss: 0.3059396743774414
Batch 54/64 loss: 0.30990755558013916
Batch 55/64 loss: 0.30373936891555786
Batch 56/64 loss: 0.3105054497718811
Batch 57/64 loss: 0.3016088008880615
Batch 58/64 loss: 0.306093692779541
Batch 59/64 loss: 0.3126220703125
Batch 60/64 loss: 0.30221307277679443
Batch 61/64 loss: 0.3035097122192383
Batch 62/64 loss: 0.2978825569152832
Batch 63/64 loss: 0.30991798639297485
Batch 64/64 loss: 0.2951703667640686
Epoch 412  Train loss: 0.30564731406230555  Val loss: 0.33239624651846605
Epoch 413
-------------------------------
Batch 1/64 loss: 0.299626886844635
Batch 2/64 loss: 0.303763747215271
Batch 3/64 loss: 0.30396175384521484
Batch 4/64 loss: 0.29732978343963623
Batch 5/64 loss: 0.30903851985931396
Batch 6/64 loss: 0.3014339208602905
Batch 7/64 loss: 0.29277825355529785
Batch 8/64 loss: 0.30245399475097656
Batch 9/64 loss: 0.30396580696105957
Batch 10/64 loss: 0.3013480305671692
Batch 11/64 loss: 0.29934442043304443
Batch 12/64 loss: 0.30675429105758667
Batch 13/64 loss: 0.3010101318359375
Batch 14/64 loss: 0.31592386960983276
Batch 15/64 loss: 0.3087678551673889
Batch 16/64 loss: 0.29887402057647705
Batch 17/64 loss: 0.3209790587425232
Batch 18/64 loss: 0.31011366844177246
Batch 19/64 loss: 0.29992401599884033
Batch 20/64 loss: 0.3014492988586426
Batch 21/64 loss: 0.30417513847351074
Batch 22/64 loss: 0.3052833080291748
Batch 23/64 loss: 0.2970537543296814
Batch 24/64 loss: 0.30555808544158936
Batch 25/64 loss: 0.3063396215438843
Batch 26/64 loss: 0.29959678649902344
Batch 27/64 loss: 0.29698532819747925
Batch 28/64 loss: 0.30516886711120605
Batch 29/64 loss: 0.30828386545181274
Batch 30/64 loss: 0.3022308945655823
Batch 31/64 loss: 0.3020223379135132
Batch 32/64 loss: 0.29931068420410156
Batch 33/64 loss: 0.31427496671676636
Batch 34/64 loss: 0.2970219850540161
Batch 35/64 loss: 0.3067796230316162
Batch 36/64 loss: 0.300384521484375
Batch 37/64 loss: 0.29625922441482544
Batch 38/64 loss: 0.30962538719177246
Batch 39/64 loss: 0.32130229473114014
Batch 40/64 loss: 0.31217604875564575
Batch 41/64 loss: 0.30970823764801025
Batch 42/64 loss: 0.3048408031463623
Batch 43/64 loss: 0.308826208114624
Batch 44/64 loss: 0.3105873465538025
Batch 45/64 loss: 0.31873786449432373
Batch 46/64 loss: 0.30919259786605835
Batch 47/64 loss: 0.2997792959213257
Batch 48/64 loss: 0.3122156858444214
Batch 49/64 loss: 0.303840696811676
Batch 50/64 loss: 0.2944021224975586
Batch 51/64 loss: 0.3123694658279419
Batch 52/64 loss: 0.3067401647567749
Batch 53/64 loss: 0.3097923994064331
Batch 54/64 loss: 0.3058500289916992
Batch 55/64 loss: 0.3045089840888977
Batch 56/64 loss: 0.29965728521347046
Batch 57/64 loss: 0.3048146963119507
Batch 58/64 loss: 0.30095648765563965
Batch 59/64 loss: 0.3086909055709839
Batch 60/64 loss: 0.30480527877807617
Batch 61/64 loss: 0.30193638801574707
Batch 62/64 loss: 0.32752013206481934
Batch 63/64 loss: 0.30902624130249023
Batch 64/64 loss: 0.3108007311820984
Epoch 413  Train loss: 0.305420767325981  Val loss: 0.3321674371912717
Epoch 414
-------------------------------
Batch 1/64 loss: 0.3124176263809204
Batch 2/64 loss: 0.30947935581207275
Batch 3/64 loss: 0.3015857934951782
Batch 4/64 loss: 0.3131674528121948
Batch 5/64 loss: 0.3098985552787781
Batch 6/64 loss: 0.3028677701950073
Batch 7/64 loss: 0.3015003204345703
Batch 8/64 loss: 0.30122506618499756
Batch 9/64 loss: 0.29892730712890625
Batch 10/64 loss: 0.31542766094207764
Batch 11/64 loss: 0.29620420932769775
Batch 12/64 loss: 0.30824458599090576
Batch 13/64 loss: 0.317477822303772
Batch 14/64 loss: 0.3092603087425232
Batch 15/64 loss: 0.301471471786499
Batch 16/64 loss: 0.30237877368927
Batch 17/64 loss: 0.30036985874176025
Batch 18/64 loss: 0.30820029973983765
Batch 19/64 loss: 0.3089175224304199
Batch 20/64 loss: 0.3038123846054077
Batch 21/64 loss: 0.3136409521102905
Batch 22/64 loss: 0.3101520538330078
Batch 23/64 loss: 0.30299341678619385
Batch 24/64 loss: 0.3038734197616577
Batch 25/64 loss: 0.30249619483947754
Batch 26/64 loss: 0.3067272901535034
Batch 27/64 loss: 0.3016669750213623
Batch 28/64 loss: 0.3062114715576172
Batch 29/64 loss: 0.30805504322052
Batch 30/64 loss: 0.30480408668518066
Batch 31/64 loss: 0.30868053436279297
Batch 32/64 loss: 0.29421114921569824
Batch 33/64 loss: 0.2996176481246948
Batch 34/64 loss: 0.3084336519241333
Batch 35/64 loss: 0.3047729730606079
Batch 36/64 loss: 0.2990579605102539
Batch 37/64 loss: 0.2938447594642639
Batch 38/64 loss: 0.30849337577819824
Batch 39/64 loss: 0.3079553246498108
Batch 40/64 loss: 0.30781543254852295
Batch 41/64 loss: 0.3048638105392456
Batch 42/64 loss: 0.2928192615509033
Batch 43/64 loss: 0.30518656969070435
Batch 44/64 loss: 0.30513638257980347
Batch 45/64 loss: 0.3120110034942627
Batch 46/64 loss: 0.2988879680633545
Batch 47/64 loss: 0.30916082859039307
Batch 48/64 loss: 0.2924652695655823
Batch 49/64 loss: 0.29871588945388794
Batch 50/64 loss: 0.30717211961746216
Batch 51/64 loss: 0.31172752380371094
Batch 52/64 loss: 0.30643224716186523
Batch 53/64 loss: 0.2982363700866699
Batch 54/64 loss: 0.30220741033554077
Batch 55/64 loss: 0.3052590489387512
Batch 56/64 loss: 0.30758726596832275
Batch 57/64 loss: 0.31648463010787964
Batch 58/64 loss: 0.31020456552505493
Batch 59/64 loss: 0.3054482936859131
Batch 60/64 loss: 0.3057803511619568
Batch 61/64 loss: 0.3153255581855774
Batch 62/64 loss: 0.31534695625305176
Batch 63/64 loss: 0.306901216506958
Batch 64/64 loss: 0.31177377700805664
Epoch 414  Train loss: 0.30562398012946634  Val loss: 0.3324962313642207
Epoch 415
-------------------------------
Batch 1/64 loss: 0.29938626289367676
Batch 2/64 loss: 0.31399476528167725
Batch 3/64 loss: 0.3060091733932495
Batch 4/64 loss: 0.31648170948028564
Batch 5/64 loss: 0.3042965531349182
Batch 6/64 loss: 0.31017279624938965
Batch 7/64 loss: 0.3051460385322571
Batch 8/64 loss: 0.30311572551727295
Batch 9/64 loss: 0.31024348735809326
Batch 10/64 loss: 0.3050506114959717
Batch 11/64 loss: 0.32143062353134155
Batch 12/64 loss: 0.3016488552093506
Batch 13/64 loss: 0.3051983118057251
Batch 14/64 loss: 0.31018489599227905
Batch 15/64 loss: 0.30800580978393555
Batch 16/64 loss: 0.29670417308807373
Batch 17/64 loss: 0.2988051176071167
Batch 18/64 loss: 0.3058452606201172
Batch 19/64 loss: 0.3051406145095825
Batch 20/64 loss: 0.3044360280036926
Batch 21/64 loss: 0.30531466007232666
Batch 22/64 loss: 0.30457139015197754
Batch 23/64 loss: 0.3075505495071411
Batch 24/64 loss: 0.30690211057662964
Batch 25/64 loss: 0.3013709783554077
Batch 26/64 loss: 0.29653358459472656
Batch 27/64 loss: 0.3011883497238159
Batch 28/64 loss: 0.30243659019470215
Batch 29/64 loss: 0.3053191900253296
Batch 30/64 loss: 0.3052980899810791
Batch 31/64 loss: 0.30327945947647095
Batch 32/64 loss: 0.2996861934661865
Batch 33/64 loss: 0.30493098497390747
Batch 34/64 loss: 0.3098485469818115
Batch 35/64 loss: 0.30913710594177246
Batch 36/64 loss: 0.31127631664276123
Batch 37/64 loss: 0.302059531211853
Batch 38/64 loss: 0.3081344962120056
Batch 39/64 loss: 0.29423123598098755
Batch 40/64 loss: 0.29924511909484863
Batch 41/64 loss: 0.2978905439376831
Batch 42/64 loss: 0.3101295232772827
Batch 43/64 loss: 0.3079584240913391
Batch 44/64 loss: 0.3114110231399536
Batch 45/64 loss: 0.3025166988372803
Batch 46/64 loss: 0.29968690872192383
Batch 47/64 loss: 0.3052961826324463
Batch 48/64 loss: 0.3174232840538025
Batch 49/64 loss: 0.31061744689941406
Batch 50/64 loss: 0.30896294116973877
Batch 51/64 loss: 0.297599732875824
Batch 52/64 loss: 0.3148883581161499
Batch 53/64 loss: 0.3035539388656616
Batch 54/64 loss: 0.3007948398590088
Batch 55/64 loss: 0.29912763833999634
Batch 56/64 loss: 0.30488264560699463
Batch 57/64 loss: 0.29852205514907837
Batch 58/64 loss: 0.3072778582572937
Batch 59/64 loss: 0.3061603307723999
Batch 60/64 loss: 0.30607104301452637
Batch 61/64 loss: 0.3076575994491577
Batch 62/64 loss: 0.306718111038208
Batch 63/64 loss: 0.3061888813972473
Batch 64/64 loss: 0.2959980368614197
Epoch 415  Train loss: 0.30530111111846625  Val loss: 0.33207696860598535
Epoch 416
-------------------------------
Batch 1/64 loss: 0.30338287353515625
Batch 2/64 loss: 0.30204635858535767
Batch 3/64 loss: 0.3066682815551758
Batch 4/64 loss: 0.3121277093887329
Batch 5/64 loss: 0.29173940420150757
Batch 6/64 loss: 0.30092525482177734
Batch 7/64 loss: 0.2987767457962036
Batch 8/64 loss: 0.3056067228317261
Batch 9/64 loss: 0.31069958209991455
Batch 10/64 loss: 0.31041932106018066
Batch 11/64 loss: 0.3121166229248047
Batch 12/64 loss: 0.29863882064819336
Batch 13/64 loss: 0.3054746389389038
Batch 14/64 loss: 0.30589401721954346
Batch 15/64 loss: 0.3052549362182617
Batch 16/64 loss: 0.30395007133483887
Batch 17/64 loss: 0.30083024501800537
Batch 18/64 loss: 0.2976650595664978
Batch 19/64 loss: 0.29910212755203247
Batch 20/64 loss: 0.30436182022094727
Batch 21/64 loss: 0.30161571502685547
Batch 22/64 loss: 0.30624085664749146
Batch 23/64 loss: 0.3044081926345825
Batch 24/64 loss: 0.30482369661331177
Batch 25/64 loss: 0.3123819828033447
Batch 26/64 loss: 0.3114018440246582
Batch 27/64 loss: 0.3183215856552124
Batch 28/64 loss: 0.31116974353790283
Batch 29/64 loss: 0.30712974071502686
Batch 30/64 loss: 0.2997891306877136
Batch 31/64 loss: 0.310685396194458
Batch 32/64 loss: 0.3066878914833069
Batch 33/64 loss: 0.2952078580856323
Batch 34/64 loss: 0.31290924549102783
Batch 35/64 loss: 0.29521095752716064
Batch 36/64 loss: 0.3059558868408203
Batch 37/64 loss: 0.3046959638595581
Batch 38/64 loss: 0.29750144481658936
Batch 39/64 loss: 0.30485033988952637
Batch 40/64 loss: 0.30980783700942993
Batch 41/64 loss: 0.300909161567688
Batch 42/64 loss: 0.30171215534210205
Batch 43/64 loss: 0.3058595657348633
Batch 44/64 loss: 0.3003004789352417
Batch 45/64 loss: 0.2985517382621765
Batch 46/64 loss: 0.29402607679367065
Batch 47/64 loss: 0.29907435178756714
Batch 48/64 loss: 0.3085128664970398
Batch 49/64 loss: 0.3041658401489258
Batch 50/64 loss: 0.31038737297058105
Batch 51/64 loss: 0.3113290071487427
Batch 52/64 loss: 0.30346858501434326
Batch 53/64 loss: 0.3086857199668884
Batch 54/64 loss: 0.30900275707244873
Batch 55/64 loss: 0.31905174255371094
Batch 56/64 loss: 0.3067740201950073
Batch 57/64 loss: 0.30285537242889404
Batch 58/64 loss: 0.3073576092720032
Batch 59/64 loss: 0.3102668523788452
Batch 60/64 loss: 0.29893815517425537
Batch 61/64 loss: 0.2980998754501343
Batch 62/64 loss: 0.30998384952545166
Batch 63/64 loss: 0.30773210525512695
Batch 64/64 loss: 0.3054485321044922
Epoch 416  Train loss: 0.3049820797116149  Val loss: 0.33267774901439234
Epoch 417
-------------------------------
Batch 1/64 loss: 0.30709099769592285
Batch 2/64 loss: 0.3152962327003479
Batch 3/64 loss: 0.305419385433197
Batch 4/64 loss: 0.3032186031341553
Batch 5/64 loss: 0.31215500831604004
Batch 6/64 loss: 0.3009721040725708
Batch 7/64 loss: 0.2990370988845825
Batch 8/64 loss: 0.30603086948394775
Batch 9/64 loss: 0.3062012195587158
Batch 10/64 loss: 0.30722522735595703
Batch 11/64 loss: 0.3003690242767334
Batch 12/64 loss: 0.2997169494628906
Batch 13/64 loss: 0.30722784996032715
Batch 14/64 loss: 0.3133108615875244
Batch 15/64 loss: 0.30346381664276123
Batch 16/64 loss: 0.3035464286804199
Batch 17/64 loss: 0.3080534338951111
Batch 18/64 loss: 0.31111109256744385
Batch 19/64 loss: 0.31186443567276
Batch 20/64 loss: 0.3055908679962158
Batch 21/64 loss: 0.30829548835754395
Batch 22/64 loss: 0.3118429183959961
Batch 23/64 loss: 0.3072813153266907
Batch 24/64 loss: 0.29366153478622437
Batch 25/64 loss: 0.304379403591156
Batch 26/64 loss: 0.3014504313468933
Batch 27/64 loss: 0.3002976179122925
Batch 28/64 loss: 0.30238163471221924
Batch 29/64 loss: 0.3050490617752075
Batch 30/64 loss: 0.30969154834747314
Batch 31/64 loss: 0.30253005027770996
Batch 32/64 loss: 0.3048970103263855
Batch 33/64 loss: 0.31026792526245117
Batch 34/64 loss: 0.29456979036331177
Batch 35/64 loss: 0.3000049591064453
Batch 36/64 loss: 0.2943819761276245
Batch 37/64 loss: 0.30675435066223145
Batch 38/64 loss: 0.3036602735519409
Batch 39/64 loss: 0.2915278673171997
Batch 40/64 loss: 0.3032875061035156
Batch 41/64 loss: 0.3118995428085327
Batch 42/64 loss: 0.3063039779663086
Batch 43/64 loss: 0.29764461517333984
Batch 44/64 loss: 0.31036221981048584
Batch 45/64 loss: 0.30473530292510986
Batch 46/64 loss: 0.3119593858718872
Batch 47/64 loss: 0.3150268793106079
Batch 48/64 loss: 0.3001521825790405
Batch 49/64 loss: 0.3047015070915222
Batch 50/64 loss: 0.2996939420700073
Batch 51/64 loss: 0.3065563440322876
Batch 52/64 loss: 0.30427461862564087
Batch 53/64 loss: 0.30712342262268066
Batch 54/64 loss: 0.2927795648574829
Batch 55/64 loss: 0.3021901845932007
Batch 56/64 loss: 0.31358373165130615
Batch 57/64 loss: 0.30233025550842285
Batch 58/64 loss: 0.30762457847595215
Batch 59/64 loss: 0.30585402250289917
Batch 60/64 loss: 0.30871427059173584
Batch 61/64 loss: 0.29652416706085205
Batch 62/64 loss: 0.314116895198822
Batch 63/64 loss: 0.29493749141693115
Batch 64/64 loss: 0.3029763102531433
Epoch 417  Train loss: 0.3047754589249106  Val loss: 0.33245063319648666
Epoch 418
-------------------------------
Batch 1/64 loss: 0.3012427091598511
Batch 2/64 loss: 0.3043833374977112
Batch 3/64 loss: 0.31233716011047363
Batch 4/64 loss: 0.3074214458465576
Batch 5/64 loss: 0.2953290343284607
Batch 6/64 loss: 0.3028683066368103
Batch 7/64 loss: 0.30109745264053345
Batch 8/64 loss: 0.30038005113601685
Batch 9/64 loss: 0.30591046810150146
Batch 10/64 loss: 0.30525076389312744
Batch 11/64 loss: 0.2994365692138672
Batch 12/64 loss: 0.2972155809402466
Batch 13/64 loss: 0.31001371145248413
Batch 14/64 loss: 0.3028392791748047
Batch 15/64 loss: 0.30348920822143555
Batch 16/64 loss: 0.3083314299583435
Batch 17/64 loss: 0.30806636810302734
Batch 18/64 loss: 0.30561167001724243
Batch 19/64 loss: 0.3048582077026367
Batch 20/64 loss: 0.30373865365982056
Batch 21/64 loss: 0.29310107231140137
Batch 22/64 loss: 0.29504841566085815
Batch 23/64 loss: 0.30320751667022705
Batch 24/64 loss: 0.30791914463043213
Batch 25/64 loss: 0.30060309171676636
Batch 26/64 loss: 0.30328458547592163
Batch 27/64 loss: 0.30945348739624023
Batch 28/64 loss: 0.3028815984725952
Batch 29/64 loss: 0.3182677626609802
Batch 30/64 loss: 0.30098628997802734
Batch 31/64 loss: 0.30313384532928467
Batch 32/64 loss: 0.29042911529541016
Batch 33/64 loss: 0.30540400743484497
Batch 34/64 loss: 0.30641698837280273
Batch 35/64 loss: 0.30122053623199463
Batch 36/64 loss: 0.30986231565475464
Batch 37/64 loss: 0.30588507652282715
Batch 38/64 loss: 0.30535364151000977
Batch 39/64 loss: 0.30239272117614746
Batch 40/64 loss: 0.3086773157119751
Batch 41/64 loss: 0.3045156002044678
Batch 42/64 loss: 0.30267298221588135
Batch 43/64 loss: 0.3080340623855591
Batch 44/64 loss: 0.3021426200866699
Batch 45/64 loss: 0.30947256088256836
Batch 46/64 loss: 0.3231872320175171
Batch 47/64 loss: 0.3041682839393616
Batch 48/64 loss: 0.3005017042160034
Batch 49/64 loss: 0.30881357192993164
Batch 50/64 loss: 0.31107205152511597
Batch 51/64 loss: 0.31207412481307983
Batch 52/64 loss: 0.3057374954223633
Batch 53/64 loss: 0.30418479442596436
Batch 54/64 loss: 0.3044092655181885
Batch 55/64 loss: 0.3085877299308777
Batch 56/64 loss: 0.30833661556243896
Batch 57/64 loss: 0.30337655544281006
Batch 58/64 loss: 0.2978501319885254
Batch 59/64 loss: 0.3090636730194092
Batch 60/64 loss: 0.30044442415237427
Batch 61/64 loss: 0.3031890392303467
Batch 62/64 loss: 0.30995917320251465
Batch 63/64 loss: 0.3091247081756592
Batch 64/64 loss: 0.31416571140289307
Epoch 418  Train loss: 0.304939492076051  Val loss: 0.3329690776739743
Epoch 419
-------------------------------
Batch 1/64 loss: 0.30546724796295166
Batch 2/64 loss: 0.3088223934173584
Batch 3/64 loss: 0.29638671875
Batch 4/64 loss: 0.29652392864227295
Batch 5/64 loss: 0.30920135974884033
Batch 6/64 loss: 0.3025627136230469
Batch 7/64 loss: 0.3018229007720947
Batch 8/64 loss: 0.3083086609840393
Batch 9/64 loss: 0.3065692186355591
Batch 10/64 loss: 0.29566776752471924
Batch 11/64 loss: 0.30537188053131104
Batch 12/64 loss: 0.3098997473716736
Batch 13/64 loss: 0.3097461462020874
Batch 14/64 loss: 0.3072074055671692
Batch 15/64 loss: 0.3087237477302551
Batch 16/64 loss: 0.3129233717918396
Batch 17/64 loss: 0.3052479028701782
Batch 18/64 loss: 0.2986278533935547
Batch 19/64 loss: 0.30457353591918945
Batch 20/64 loss: 0.3120756149291992
Batch 21/64 loss: 0.3085923194885254
Batch 22/64 loss: 0.3000413775444031
Batch 23/64 loss: 0.2931671738624573
Batch 24/64 loss: 0.30647122859954834
Batch 25/64 loss: 0.3113160729408264
Batch 26/64 loss: 0.3007051348686218
Batch 27/64 loss: 0.30004507303237915
Batch 28/64 loss: 0.2946956157684326
Batch 29/64 loss: 0.3061227798461914
Batch 30/64 loss: 0.31212443113327026
Batch 31/64 loss: 0.3004549741744995
Batch 32/64 loss: 0.31581127643585205
Batch 33/64 loss: 0.31157171726226807
Batch 34/64 loss: 0.30088841915130615
Batch 35/64 loss: 0.3039499521255493
Batch 36/64 loss: 0.3120577335357666
Batch 37/64 loss: 0.300986647605896
Batch 38/64 loss: 0.3068976402282715
Batch 39/64 loss: 0.30008310079574585
Batch 40/64 loss: 0.30816125869750977
Batch 41/64 loss: 0.3031454086303711
Batch 42/64 loss: 0.31083381175994873
Batch 43/64 loss: 0.3089665174484253
Batch 44/64 loss: 0.30447566509246826
Batch 45/64 loss: 0.29782599210739136
Batch 46/64 loss: 0.3014291524887085
Batch 47/64 loss: 0.29191070795059204
Batch 48/64 loss: 0.3076651096343994
Batch 49/64 loss: 0.29656660556793213
Batch 50/64 loss: 0.29936683177948
Batch 51/64 loss: 0.2986946105957031
Batch 52/64 loss: 0.3055327534675598
Batch 53/64 loss: 0.30447250604629517
Batch 54/64 loss: 0.3075951337814331
Batch 55/64 loss: 0.3011418581008911
Batch 56/64 loss: 0.3059816360473633
Batch 57/64 loss: 0.2940399646759033
Batch 58/64 loss: 0.30108749866485596
Batch 59/64 loss: 0.31042730808258057
Batch 60/64 loss: 0.296162486076355
Batch 61/64 loss: 0.3093603253364563
Batch 62/64 loss: 0.3011985421180725
Batch 63/64 loss: 0.3041088581085205
Batch 64/64 loss: 0.30576252937316895
Epoch 419  Train loss: 0.3041754544949999  Val loss: 0.33266703779345114
Epoch 420
-------------------------------
Batch 1/64 loss: 0.3060723543167114
Batch 2/64 loss: 0.2938680648803711
Batch 3/64 loss: 0.308097779750824
Batch 4/64 loss: 0.29925012588500977
Batch 5/64 loss: 0.31316739320755005
Batch 6/64 loss: 0.3084087371826172
Batch 7/64 loss: 0.3022078275680542
Batch 8/64 loss: 0.29747986793518066
Batch 9/64 loss: 0.307209849357605
Batch 10/64 loss: 0.30871152877807617
Batch 11/64 loss: 0.3082072138786316
Batch 12/64 loss: 0.29926466941833496
Batch 13/64 loss: 0.30472052097320557
Batch 14/64 loss: 0.3039291501045227
Batch 15/64 loss: 0.3033084273338318
Batch 16/64 loss: 0.30814146995544434
Batch 17/64 loss: 0.2895725965499878
Batch 18/64 loss: 0.297191858291626
Batch 19/64 loss: 0.30390089750289917
Batch 20/64 loss: 0.2966940402984619
Batch 21/64 loss: 0.3003276586532593
Batch 22/64 loss: 0.30480659008026123
Batch 23/64 loss: 0.29786330461502075
Batch 24/64 loss: 0.3045235276222229
Batch 25/64 loss: 0.3093080520629883
Batch 26/64 loss: 0.2952362298965454
Batch 27/64 loss: 0.301361083984375
Batch 28/64 loss: 0.3029114603996277
Batch 29/64 loss: 0.28978991508483887
Batch 30/64 loss: 0.30446577072143555
Batch 31/64 loss: 0.31268811225891113
Batch 32/64 loss: 0.3051424026489258
Batch 33/64 loss: 0.31030499935150146
Batch 34/64 loss: 0.3042771816253662
Batch 35/64 loss: 0.2983134984970093
Batch 36/64 loss: 0.3033619523048401
Batch 37/64 loss: 0.3042065501213074
Batch 38/64 loss: 0.3065450191497803
Batch 39/64 loss: 0.29780542850494385
Batch 40/64 loss: 0.3127180337905884
Batch 41/64 loss: 0.29826462268829346
Batch 42/64 loss: 0.30917757749557495
Batch 43/64 loss: 0.31098973751068115
Batch 44/64 loss: 0.31213879585266113
Batch 45/64 loss: 0.314328134059906
Batch 46/64 loss: 0.30635130405426025
Batch 47/64 loss: 0.3112119436264038
Batch 48/64 loss: 0.3061906695365906
Batch 49/64 loss: 0.30576032400131226
Batch 50/64 loss: 0.29939866065979004
Batch 51/64 loss: 0.29679691791534424
Batch 52/64 loss: 0.3030533790588379
Batch 53/64 loss: 0.3115804195404053
Batch 54/64 loss: 0.31068849563598633
Batch 55/64 loss: 0.31242799758911133
Batch 56/64 loss: 0.2974662780761719
Batch 57/64 loss: 0.3058488965034485
Batch 58/64 loss: 0.31152087450027466
Batch 59/64 loss: 0.2958294153213501
Batch 60/64 loss: 0.29962265491485596
Batch 61/64 loss: 0.30215561389923096
Batch 62/64 loss: 0.3137499690055847
Batch 63/64 loss: 0.30701929330825806
Batch 64/64 loss: 0.3144720196723938
Epoch 420  Train loss: 0.30435744524002073  Val loss: 0.33331342640611317
Epoch 421
-------------------------------
Batch 1/64 loss: 0.30369824171066284
Batch 2/64 loss: 0.30701422691345215
Batch 3/64 loss: 0.29356151819229126
Batch 4/64 loss: 0.3016321659088135
Batch 5/64 loss: 0.30378150939941406
Batch 6/64 loss: 0.31235337257385254
Batch 7/64 loss: 0.3063899278640747
Batch 8/64 loss: 0.3076915740966797
Batch 9/64 loss: 0.29677093029022217
Batch 10/64 loss: 0.3093177080154419
Batch 11/64 loss: 0.30406415462493896
Batch 12/64 loss: 0.3115503191947937
Batch 13/64 loss: 0.3078787326812744
Batch 14/64 loss: 0.30122172832489014
Batch 15/64 loss: 0.3111340403556824
Batch 16/64 loss: 0.3074536919593811
Batch 17/64 loss: 0.3003910779953003
Batch 18/64 loss: 0.3060987591743469
Batch 19/64 loss: 0.30779051780700684
Batch 20/64 loss: 0.3040691614151001
Batch 21/64 loss: 0.31055736541748047
Batch 22/64 loss: 0.30960196256637573
Batch 23/64 loss: 0.3039724826812744
Batch 24/64 loss: 0.2966586947441101
Batch 25/64 loss: 0.30130624771118164
Batch 26/64 loss: 0.301097571849823
Batch 27/64 loss: 0.31244713068008423
Batch 28/64 loss: 0.3146234154701233
Batch 29/64 loss: 0.30698472261428833
Batch 30/64 loss: 0.30180078744888306
Batch 31/64 loss: 0.3085915446281433
Batch 32/64 loss: 0.29999661445617676
Batch 33/64 loss: 0.3018571138381958
Batch 34/64 loss: 0.30080080032348633
Batch 35/64 loss: 0.299487829208374
Batch 36/64 loss: 0.3132646679878235
Batch 37/64 loss: 0.3114035129547119
Batch 38/64 loss: 0.30241042375564575
Batch 39/64 loss: 0.3231055736541748
Batch 40/64 loss: 0.3026254177093506
Batch 41/64 loss: 0.3050200343132019
Batch 42/64 loss: 0.2892115116119385
Batch 43/64 loss: 0.3059448003768921
Batch 44/64 loss: 0.3028586506843567
Batch 45/64 loss: 0.3085273504257202
Batch 46/64 loss: 0.3039041757583618
Batch 47/64 loss: 0.3096499443054199
Batch 48/64 loss: 0.3026587963104248
Batch 49/64 loss: 0.30769777297973633
Batch 50/64 loss: 0.305869460105896
Batch 51/64 loss: 0.2985496520996094
Batch 52/64 loss: 0.2990145683288574
Batch 53/64 loss: 0.31263166666030884
Batch 54/64 loss: 0.3053041696548462
Batch 55/64 loss: 0.30567896366119385
Batch 56/64 loss: 0.30327361822128296
Batch 57/64 loss: 0.3102306127548218
Batch 58/64 loss: 0.30778300762176514
Batch 59/64 loss: 0.3129216432571411
Batch 60/64 loss: 0.3088111877441406
Batch 61/64 loss: 0.3022714853286743
Batch 62/64 loss: 0.30136406421661377
Batch 63/64 loss: 0.2996901869773865
Batch 64/64 loss: 0.30367279052734375
Epoch 421  Train loss: 0.30530320242339487  Val loss: 0.3335909888506755
Epoch 422
-------------------------------
Batch 1/64 loss: 0.3038179874420166
Batch 2/64 loss: 0.2979051470756531
Batch 3/64 loss: 0.2967507839202881
Batch 4/64 loss: 0.30811190605163574
Batch 5/64 loss: 0.29762083292007446
Batch 6/64 loss: 0.29501867294311523
Batch 7/64 loss: 0.3107030391693115
Batch 8/64 loss: 0.3009151220321655
Batch 9/64 loss: 0.31387603282928467
Batch 10/64 loss: 0.29814255237579346
Batch 11/64 loss: 0.3111509084701538
Batch 12/64 loss: 0.3073122501373291
Batch 13/64 loss: 0.3047231435775757
Batch 14/64 loss: 0.30691033601760864
Batch 15/64 loss: 0.3011660575866699
Batch 16/64 loss: 0.3047334551811218
Batch 17/64 loss: 0.3107246160507202
Batch 18/64 loss: 0.29971081018447876
Batch 19/64 loss: 0.31016433238983154
Batch 20/64 loss: 0.3057032823562622
Batch 21/64 loss: 0.30550050735473633
Batch 22/64 loss: 0.2987358570098877
Batch 23/64 loss: 0.3072502613067627
Batch 24/64 loss: 0.30624186992645264
Batch 25/64 loss: 0.29667043685913086
Batch 26/64 loss: 0.297701895236969
Batch 27/64 loss: 0.30594104528427124
Batch 28/64 loss: 0.3038497567176819
Batch 29/64 loss: 0.30635982751846313
Batch 30/64 loss: 0.30064189434051514
Batch 31/64 loss: 0.3116762042045593
Batch 32/64 loss: 0.3058708906173706
Batch 33/64 loss: 0.31287968158721924
Batch 34/64 loss: 0.30480533838272095
Batch 35/64 loss: 0.3083277940750122
Batch 36/64 loss: 0.2957802414894104
Batch 37/64 loss: 0.31188255548477173
Batch 38/64 loss: 0.31133079528808594
Batch 39/64 loss: 0.30881190299987793
Batch 40/64 loss: 0.3006383180618286
Batch 41/64 loss: 0.3058255910873413
Batch 42/64 loss: 0.30646955966949463
Batch 43/64 loss: 0.304341197013855
Batch 44/64 loss: 0.3021728992462158
Batch 45/64 loss: 0.30478525161743164
Batch 46/64 loss: 0.30364954471588135
Batch 47/64 loss: 0.310217022895813
Batch 48/64 loss: 0.29944396018981934
Batch 49/64 loss: 0.3018103241920471
Batch 50/64 loss: 0.30837517976760864
Batch 51/64 loss: 0.3081313371658325
Batch 52/64 loss: 0.3038923740386963
Batch 53/64 loss: 0.302196204662323
Batch 54/64 loss: 0.29969966411590576
Batch 55/64 loss: 0.30452650785446167
Batch 56/64 loss: 0.29084181785583496
Batch 57/64 loss: 0.304723858833313
Batch 58/64 loss: 0.3001667857170105
Batch 59/64 loss: 0.3030794858932495
Batch 60/64 loss: 0.32446807622909546
Batch 61/64 loss: 0.3115430474281311
Batch 62/64 loss: 0.29954755306243896
Batch 63/64 loss: 0.30850595235824585
Batch 64/64 loss: 0.3089202046394348
Epoch 422  Train loss: 0.30472410496543434  Val loss: 0.33377734471842185
Epoch 423
-------------------------------
Batch 1/64 loss: 0.29626965522766113
Batch 2/64 loss: 0.3097224235534668
Batch 3/64 loss: 0.29795610904693604
Batch 4/64 loss: 0.30053484439849854
Batch 5/64 loss: 0.307613730430603
Batch 6/64 loss: 0.29342663288116455
Batch 7/64 loss: 0.29443836212158203
Batch 8/64 loss: 0.29993486404418945
Batch 9/64 loss: 0.3021562099456787
Batch 10/64 loss: 0.2994730472564697
Batch 11/64 loss: 0.31545490026474
Batch 12/64 loss: 0.3051760792732239
Batch 13/64 loss: 0.3005342483520508
Batch 14/64 loss: 0.3144548535346985
Batch 15/64 loss: 0.3065711259841919
Batch 16/64 loss: 0.29897356033325195
Batch 17/64 loss: 0.3143519163131714
Batch 18/64 loss: 0.3003861904144287
Batch 19/64 loss: 0.3001197576522827
Batch 20/64 loss: 0.3066748380661011
Batch 21/64 loss: 0.2983109951019287
Batch 22/64 loss: 0.3050943613052368
Batch 23/64 loss: 0.3039654493331909
Batch 24/64 loss: 0.3060828447341919
Batch 25/64 loss: 0.3029886484146118
Batch 26/64 loss: 0.3082806468009949
Batch 27/64 loss: 0.3046700954437256
Batch 28/64 loss: 0.29145872592926025
Batch 29/64 loss: 0.3153437376022339
Batch 30/64 loss: 0.30273646116256714
Batch 31/64 loss: 0.3031216859817505
Batch 32/64 loss: 0.30445873737335205
Batch 33/64 loss: 0.30769842863082886
Batch 34/64 loss: 0.2944055199623108
Batch 35/64 loss: 0.3005908131599426
Batch 36/64 loss: 0.3074014186859131
Batch 37/64 loss: 0.2980015277862549
Batch 38/64 loss: 0.30169612169265747
Batch 39/64 loss: 0.31264257431030273
Batch 40/64 loss: 0.30218881368637085
Batch 41/64 loss: 0.3022817373275757
Batch 42/64 loss: 0.30522650480270386
Batch 43/64 loss: 0.31069082021713257
Batch 44/64 loss: 0.30470454692840576
Batch 45/64 loss: 0.3064916729927063
Batch 46/64 loss: 0.31484484672546387
Batch 47/64 loss: 0.31303632259368896
Batch 48/64 loss: 0.3022008538246155
Batch 49/64 loss: 0.3089367151260376
Batch 50/64 loss: 0.3075163960456848
Batch 51/64 loss: 0.3183440566062927
Batch 52/64 loss: 0.3027123212814331
Batch 53/64 loss: 0.3010733723640442
Batch 54/64 loss: 0.3006594777107239
Batch 55/64 loss: 0.3060760498046875
Batch 56/64 loss: 0.29868125915527344
Batch 57/64 loss: 0.3012353777885437
Batch 58/64 loss: 0.297149121761322
Batch 59/64 loss: 0.3110361695289612
Batch 60/64 loss: 0.30537211894989014
Batch 61/64 loss: 0.3071845769882202
Batch 62/64 loss: 0.30052846670150757
Batch 63/64 loss: 0.3046085238456726
Batch 64/64 loss: 0.31463515758514404
Epoch 423  Train loss: 0.3043439785639445  Val loss: 0.33262329965932264
Epoch 424
-------------------------------
Batch 1/64 loss: 0.29803967475891113
Batch 2/64 loss: 0.3001590967178345
Batch 3/64 loss: 0.3035297393798828
Batch 4/64 loss: 0.3046131730079651
Batch 5/64 loss: 0.30390048027038574
Batch 6/64 loss: 0.29891860485076904
Batch 7/64 loss: 0.3108327388763428
Batch 8/64 loss: 0.29655176401138306
Batch 9/64 loss: 0.3061826229095459
Batch 10/64 loss: 0.3022516965866089
Batch 11/64 loss: 0.3018916845321655
Batch 12/64 loss: 0.3043299913406372
Batch 13/64 loss: 0.3125424385070801
Batch 14/64 loss: 0.30039137601852417
Batch 15/64 loss: 0.30739033222198486
Batch 16/64 loss: 0.31247830390930176
Batch 17/64 loss: 0.30559438467025757
Batch 18/64 loss: 0.2926725149154663
Batch 19/64 loss: 0.3106233477592468
Batch 20/64 loss: 0.3118633031845093
Batch 21/64 loss: 0.31111711263656616
Batch 22/64 loss: 0.3120179772377014
Batch 23/64 loss: 0.3010179400444031
Batch 24/64 loss: 0.3105239272117615
Batch 25/64 loss: 0.3022240996360779
Batch 26/64 loss: 0.31316322088241577
Batch 27/64 loss: 0.309018075466156
Batch 28/64 loss: 0.308779239654541
Batch 29/64 loss: 0.3110249638557434
Batch 30/64 loss: 0.31106317043304443
Batch 31/64 loss: 0.30602753162384033
Batch 32/64 loss: 0.30276036262512207
Batch 33/64 loss: 0.30418431758880615
Batch 34/64 loss: 0.3058447241783142
Batch 35/64 loss: 0.2928217649459839
Batch 36/64 loss: 0.30300700664520264
Batch 37/64 loss: 0.2962251901626587
Batch 38/64 loss: 0.3052358031272888
Batch 39/64 loss: 0.30448806285858154
Batch 40/64 loss: 0.29704517126083374
Batch 41/64 loss: 0.30765557289123535
Batch 42/64 loss: 0.3116685748100281
Batch 43/64 loss: 0.29807591438293457
Batch 44/64 loss: 0.29928791522979736
Batch 45/64 loss: 0.3099035620689392
Batch 46/64 loss: 0.29431939125061035
Batch 47/64 loss: 0.31583142280578613
Batch 48/64 loss: 0.29401832818984985
Batch 49/64 loss: 0.3087242841720581
Batch 50/64 loss: 0.2984312176704407
Batch 51/64 loss: 0.29774200916290283
Batch 52/64 loss: 0.3005373477935791
Batch 53/64 loss: 0.2969670295715332
Batch 54/64 loss: 0.3152695894241333
Batch 55/64 loss: 0.3051401376724243
Batch 56/64 loss: 0.30211782455444336
Batch 57/64 loss: 0.2998533248901367
Batch 58/64 loss: 0.30265283584594727
Batch 59/64 loss: 0.29993605613708496
Batch 60/64 loss: 0.2969977855682373
Batch 61/64 loss: 0.3033255338668823
Batch 62/64 loss: 0.29599452018737793
Batch 63/64 loss: 0.3070650100708008
Batch 64/64 loss: 0.3255690932273865
Epoch 424  Train loss: 0.30428296374339686  Val loss: 0.333574296682561
Epoch 425
-------------------------------
Batch 1/64 loss: 0.30188435316085815
Batch 2/64 loss: 0.3033003807067871
Batch 3/64 loss: 0.2949545383453369
Batch 4/64 loss: 0.29994314908981323
Batch 5/64 loss: 0.30016326904296875
Batch 6/64 loss: 0.31011897325515747
Batch 7/64 loss: 0.2988371253013611
Batch 8/64 loss: 0.3006344437599182
Batch 9/64 loss: 0.3029853105545044
Batch 10/64 loss: 0.30674052238464355
Batch 11/64 loss: 0.3082861304283142
Batch 12/64 loss: 0.2998915910720825
Batch 13/64 loss: 0.3090207576751709
Batch 14/64 loss: 0.29918527603149414
Batch 15/64 loss: 0.30209076404571533
Batch 16/64 loss: 0.3072859048843384
Batch 17/64 loss: 0.3028537631034851
Batch 18/64 loss: 0.3130412697792053
Batch 19/64 loss: 0.2965746521949768
Batch 20/64 loss: 0.301652193069458
Batch 21/64 loss: 0.29612743854522705
Batch 22/64 loss: 0.30115848779678345
Batch 23/64 loss: 0.2944002151489258
Batch 24/64 loss: 0.3031975030899048
Batch 25/64 loss: 0.3086857795715332
Batch 26/64 loss: 0.299552857875824
Batch 27/64 loss: 0.307308554649353
Batch 28/64 loss: 0.3025611639022827
Batch 29/64 loss: 0.3018606901168823
Batch 30/64 loss: 0.30749011039733887
Batch 31/64 loss: 0.3030502200126648
Batch 32/64 loss: 0.31546926498413086
Batch 33/64 loss: 0.30921387672424316
Batch 34/64 loss: 0.29698312282562256
Batch 35/64 loss: 0.31102854013442993
Batch 36/64 loss: 0.30318212509155273
Batch 37/64 loss: 0.30618560314178467
Batch 38/64 loss: 0.30473756790161133
Batch 39/64 loss: 0.29759645462036133
Batch 40/64 loss: 0.304010808467865
Batch 41/64 loss: 0.30114734172821045
Batch 42/64 loss: 0.3124750852584839
Batch 43/64 loss: 0.30227601528167725
Batch 44/64 loss: 0.2954038381576538
Batch 45/64 loss: 0.3091670870780945
Batch 46/64 loss: 0.3089752197265625
Batch 47/64 loss: 0.3102736473083496
Batch 48/64 loss: 0.2998170256614685
Batch 49/64 loss: 0.30776113271713257
Batch 50/64 loss: 0.310133159160614
Batch 51/64 loss: 0.30860984325408936
Batch 52/64 loss: 0.29975491762161255
Batch 53/64 loss: 0.30992066860198975
Batch 54/64 loss: 0.3040827512741089
Batch 55/64 loss: 0.30436575412750244
Batch 56/64 loss: 0.303189754486084
Batch 57/64 loss: 0.300037145614624
Batch 58/64 loss: 0.3059556484222412
Batch 59/64 loss: 0.30629682540893555
Batch 60/64 loss: 0.3139227628707886
Batch 61/64 loss: 0.2995588183403015
Batch 62/64 loss: 0.30268096923828125
Batch 63/64 loss: 0.29751670360565186
Batch 64/64 loss: 0.31317877769470215
Epoch 425  Train loss: 0.30402276001724543  Val loss: 0.3321243741667967
Epoch 426
-------------------------------
Batch 1/64 loss: 0.3021455407142639
Batch 2/64 loss: 0.29658353328704834
Batch 3/64 loss: 0.30123841762542725
Batch 4/64 loss: 0.30820345878601074
Batch 5/64 loss: 0.30654293298721313
Batch 6/64 loss: 0.2992909550666809
Batch 7/64 loss: 0.30984991788864136
Batch 8/64 loss: 0.3007696866989136
Batch 9/64 loss: 0.30219829082489014
Batch 10/64 loss: 0.3013054132461548
Batch 11/64 loss: 0.3028632402420044
Batch 12/64 loss: 0.3046680688858032
Batch 13/64 loss: 0.30826663970947266
Batch 14/64 loss: 0.3106215000152588
Batch 15/64 loss: 0.30131471157073975
Batch 16/64 loss: 0.2965424060821533
Batch 17/64 loss: 0.3001912832260132
Batch 18/64 loss: 0.3055877685546875
Batch 19/64 loss: 0.3002345561981201
Batch 20/64 loss: 0.3061222434043884
Batch 21/64 loss: 0.3037463426589966
Batch 22/64 loss: 0.30675578117370605
Batch 23/64 loss: 0.3047734498977661
Batch 24/64 loss: 0.3067307472229004
Batch 25/64 loss: 0.29361915588378906
Batch 26/64 loss: 0.31053149700164795
Batch 27/64 loss: 0.30476200580596924
Batch 28/64 loss: 0.3051835298538208
Batch 29/64 loss: 0.313152551651001
Batch 30/64 loss: 0.30326348543167114
Batch 31/64 loss: 0.30649852752685547
Batch 32/64 loss: 0.30607008934020996
Batch 33/64 loss: 0.3021196722984314
Batch 34/64 loss: 0.30455899238586426
Batch 35/64 loss: 0.29374897480010986
Batch 36/64 loss: 0.3024556636810303
Batch 37/64 loss: 0.30017000436782837
Batch 38/64 loss: 0.30115729570388794
Batch 39/64 loss: 0.2974874973297119
Batch 40/64 loss: 0.2953888177871704
Batch 41/64 loss: 0.30884718894958496
Batch 42/64 loss: 0.29411035776138306
Batch 43/64 loss: 0.30211395025253296
Batch 44/64 loss: 0.31255316734313965
Batch 45/64 loss: 0.3049476146697998
Batch 46/64 loss: 0.30723655223846436
Batch 47/64 loss: 0.30823248624801636
Batch 48/64 loss: 0.3041396141052246
Batch 49/64 loss: 0.30176007747650146
Batch 50/64 loss: 0.3039889335632324
Batch 51/64 loss: 0.3066415786743164
Batch 52/64 loss: 0.30019718408584595
Batch 53/64 loss: 0.30203866958618164
Batch 54/64 loss: 0.3199998140335083
Batch 55/64 loss: 0.3030802011489868
Batch 56/64 loss: 0.30968403816223145
Batch 57/64 loss: 0.3007296323776245
Batch 58/64 loss: 0.3058229684829712
Batch 59/64 loss: 0.2992696166038513
Batch 60/64 loss: 0.3024444580078125
Batch 61/64 loss: 0.3059941530227661
Batch 62/64 loss: 0.3001983165740967
Batch 63/64 loss: 0.3103482127189636
Batch 64/64 loss: 0.3085423707962036
Epoch 426  Train loss: 0.3038823562509873  Val loss: 0.33289882509978774
Epoch 427
-------------------------------
Batch 1/64 loss: 0.30526840686798096
Batch 2/64 loss: 0.3026353716850281
Batch 3/64 loss: 0.2948600649833679
Batch 4/64 loss: 0.3047151565551758
Batch 5/64 loss: 0.29926538467407227
Batch 6/64 loss: 0.3086131811141968
Batch 7/64 loss: 0.3070826530456543
Batch 8/64 loss: 0.3018451929092407
Batch 9/64 loss: 0.30632126331329346
Batch 10/64 loss: 0.2992234230041504
Batch 11/64 loss: 0.2989041805267334
Batch 12/64 loss: 0.3116565942764282
Batch 13/64 loss: 0.30963999032974243
Batch 14/64 loss: 0.30808335542678833
Batch 15/64 loss: 0.3061445355415344
Batch 16/64 loss: 0.307969331741333
Batch 17/64 loss: 0.30055153369903564
Batch 18/64 loss: 0.3056739568710327
Batch 19/64 loss: 0.30288851261138916
Batch 20/64 loss: 0.29649484157562256
Batch 21/64 loss: 0.3081592321395874
Batch 22/64 loss: 0.30227696895599365
Batch 23/64 loss: 0.3019798994064331
Batch 24/64 loss: 0.30757129192352295
Batch 25/64 loss: 0.3068349361419678
Batch 26/64 loss: 0.29534029960632324
Batch 27/64 loss: 0.31122976541519165
Batch 28/64 loss: 0.31236326694488525
Batch 29/64 loss: 0.31265580654144287
Batch 30/64 loss: 0.29941415786743164
Batch 31/64 loss: 0.30023062229156494
Batch 32/64 loss: 0.31125664710998535
Batch 33/64 loss: 0.30569183826446533
Batch 34/64 loss: 0.29566681385040283
Batch 35/64 loss: 0.3017367124557495
Batch 36/64 loss: 0.30876415967941284
Batch 37/64 loss: 0.30329620838165283
Batch 38/64 loss: 0.2887866497039795
Batch 39/64 loss: 0.3067159652709961
Batch 40/64 loss: 0.3024228811264038
Batch 41/64 loss: 0.3135758638381958
Batch 42/64 loss: 0.3078766465187073
Batch 43/64 loss: 0.2983018159866333
Batch 44/64 loss: 0.29611843824386597
Batch 45/64 loss: 0.30667030811309814
Batch 46/64 loss: 0.29751086235046387
Batch 47/64 loss: 0.30405372381210327
Batch 48/64 loss: 0.30864405632019043
Batch 49/64 loss: 0.30058038234710693
Batch 50/64 loss: 0.3089795708656311
Batch 51/64 loss: 0.2924814820289612
Batch 52/64 loss: 0.2989373803138733
Batch 53/64 loss: 0.30171388387680054
Batch 54/64 loss: 0.32201170921325684
Batch 55/64 loss: 0.3090784549713135
Batch 56/64 loss: 0.3010863661766052
Batch 57/64 loss: 0.3055151104927063
Batch 58/64 loss: 0.30346018075942993
Batch 59/64 loss: 0.30045217275619507
Batch 60/64 loss: 0.29993772506713867
Batch 61/64 loss: 0.3051803708076477
Batch 62/64 loss: 0.3120875954627991
Batch 63/64 loss: 0.29710638523101807
Batch 64/64 loss: 0.2960520386695862
Epoch 427  Train loss: 0.30390008734721763  Val loss: 0.3322867394722614
Epoch 428
-------------------------------
Batch 1/64 loss: 0.31040865182876587
Batch 2/64 loss: 0.30238455533981323
Batch 3/64 loss: 0.30819928646087646
Batch 4/64 loss: 0.3076775074005127
Batch 5/64 loss: 0.3099820017814636
Batch 6/64 loss: 0.29799050092697144
Batch 7/64 loss: 0.31016606092453003
Batch 8/64 loss: 0.30795496702194214
Batch 9/64 loss: 0.3060295581817627
Batch 10/64 loss: 0.31001877784729004
Batch 11/64 loss: 0.30196720361709595
Batch 12/64 loss: 0.3105708956718445
Batch 13/64 loss: 0.2975919246673584
Batch 14/64 loss: 0.30605846643447876
Batch 15/64 loss: 0.3052905797958374
Batch 16/64 loss: 0.29992246627807617
Batch 17/64 loss: 0.2997811436653137
Batch 18/64 loss: 0.30539870262145996
Batch 19/64 loss: 0.310352087020874
Batch 20/64 loss: 0.3015249967575073
Batch 21/64 loss: 0.306304931640625
Batch 22/64 loss: 0.29531097412109375
Batch 23/64 loss: 0.30774688720703125
Batch 24/64 loss: 0.2923635244369507
Batch 25/64 loss: 0.30638718605041504
Batch 26/64 loss: 0.3056659698486328
Batch 27/64 loss: 0.29666292667388916
Batch 28/64 loss: 0.31011730432510376
Batch 29/64 loss: 0.30058586597442627
Batch 30/64 loss: 0.30031120777130127
Batch 31/64 loss: 0.3011438846588135
Batch 32/64 loss: 0.29738539457321167
Batch 33/64 loss: 0.310772180557251
Batch 34/64 loss: 0.3063443899154663
Batch 35/64 loss: 0.29278069734573364
Batch 36/64 loss: 0.31638067960739136
Batch 37/64 loss: 0.3009220361709595
Batch 38/64 loss: 0.29945868253707886
Batch 39/64 loss: 0.3000051975250244
Batch 40/64 loss: 0.2944878339767456
Batch 41/64 loss: 0.30127495527267456
Batch 42/64 loss: 0.3068552017211914
Batch 43/64 loss: 0.30423063039779663
Batch 44/64 loss: 0.2969930171966553
Batch 45/64 loss: 0.30902671813964844
Batch 46/64 loss: 0.31042492389678955
Batch 47/64 loss: 0.31099069118499756
Batch 48/64 loss: 0.29991674423217773
Batch 49/64 loss: 0.3092461824417114
Batch 50/64 loss: 0.2981300354003906
Batch 51/64 loss: 0.30413973331451416
Batch 52/64 loss: 0.3020668029785156
Batch 53/64 loss: 0.2990577220916748
Batch 54/64 loss: 0.3014456033706665
Batch 55/64 loss: 0.30129826068878174
Batch 56/64 loss: 0.30237293243408203
Batch 57/64 loss: 0.3139204978942871
Batch 58/64 loss: 0.3081580400466919
Batch 59/64 loss: 0.30871903896331787
Batch 60/64 loss: 0.31164395809173584
Batch 61/64 loss: 0.29835963249206543
Batch 62/64 loss: 0.3060370683670044
Batch 63/64 loss: 0.30153095722198486
Batch 64/64 loss: 0.3073279857635498
Epoch 428  Train loss: 0.3041057792364382  Val loss: 0.3327602883384809
Epoch 429
-------------------------------
Batch 1/64 loss: 0.30395281314849854
Batch 2/64 loss: 0.3063889741897583
Batch 3/64 loss: 0.3105233907699585
Batch 4/64 loss: 0.30657052993774414
Batch 5/64 loss: 0.313670814037323
Batch 6/64 loss: 0.3141855001449585
Batch 7/64 loss: 0.3102131485939026
Batch 8/64 loss: 0.3034210801124573
Batch 9/64 loss: 0.3076760768890381
Batch 10/64 loss: 0.2987133264541626
Batch 11/64 loss: 0.2990606427192688
Batch 12/64 loss: 0.2921149730682373
Batch 13/64 loss: 0.30478596687316895
Batch 14/64 loss: 0.2984062433242798
Batch 15/64 loss: 0.30451178550720215
Batch 16/64 loss: 0.29627346992492676
Batch 17/64 loss: 0.2988731861114502
Batch 18/64 loss: 0.31232643127441406
Batch 19/64 loss: 0.303006649017334
Batch 20/64 loss: 0.2965936064720154
Batch 21/64 loss: 0.2924928665161133
Batch 22/64 loss: 0.3035404086112976
Batch 23/64 loss: 0.30839645862579346
Batch 24/64 loss: 0.29831600189208984
Batch 25/64 loss: 0.29971230030059814
Batch 26/64 loss: 0.3014092445373535
Batch 27/64 loss: 0.29550957679748535
Batch 28/64 loss: 0.301810622215271
Batch 29/64 loss: 0.3011513948440552
Batch 30/64 loss: 0.30269336700439453
Batch 31/64 loss: 0.31047964096069336
Batch 32/64 loss: 0.3103671669960022
Batch 33/64 loss: 0.30315595865249634
Batch 34/64 loss: 0.29392045736312866
Batch 35/64 loss: 0.3023506999015808
Batch 36/64 loss: 0.3059067726135254
Batch 37/64 loss: 0.30684083700180054
Batch 38/64 loss: 0.2967541813850403
Batch 39/64 loss: 0.30053550004959106
Batch 40/64 loss: 0.3102901577949524
Batch 41/64 loss: 0.3066980242729187
Batch 42/64 loss: 0.3090553283691406
Batch 43/64 loss: 0.3118107318878174
Batch 44/64 loss: 0.31547558307647705
Batch 45/64 loss: 0.3019184470176697
Batch 46/64 loss: 0.3144721984863281
Batch 47/64 loss: 0.3168572187423706
Batch 48/64 loss: 0.30166590213775635
Batch 49/64 loss: 0.3068532347679138
Batch 50/64 loss: 0.30630290508270264
Batch 51/64 loss: 0.2999606132507324
Batch 52/64 loss: 0.2978857755661011
Batch 53/64 loss: 0.30848944187164307
Batch 54/64 loss: 0.3041253089904785
Batch 55/64 loss: 0.30319952964782715
Batch 56/64 loss: 0.2927548289299011
Batch 57/64 loss: 0.3062306046485901
Batch 58/64 loss: 0.30103516578674316
Batch 59/64 loss: 0.29754316806793213
Batch 60/64 loss: 0.3017876148223877
Batch 61/64 loss: 0.3037894368171692
Batch 62/64 loss: 0.3101847767829895
Batch 63/64 loss: 0.3057006597518921
Batch 64/64 loss: 0.30728280544281006
Epoch 429  Train loss: 0.304018209027309  Val loss: 0.3324787424192396
Epoch 430
-------------------------------
Batch 1/64 loss: 0.2958730459213257
Batch 2/64 loss: 0.2944589853286743
Batch 3/64 loss: 0.2882293462753296
Batch 4/64 loss: 0.3018646836280823
Batch 5/64 loss: 0.3220909833908081
Batch 6/64 loss: 0.3174968957901001
Batch 7/64 loss: 0.3001910448074341
Batch 8/64 loss: 0.30977505445480347
Batch 9/64 loss: 0.29831963777542114
Batch 10/64 loss: 0.3135538101196289
Batch 11/64 loss: 0.3009887933731079
Batch 12/64 loss: 0.31087446212768555
Batch 13/64 loss: 0.29892802238464355
Batch 14/64 loss: 0.29712581634521484
Batch 15/64 loss: 0.3029665946960449
Batch 16/64 loss: 0.3085865378379822
Batch 17/64 loss: 0.3067781329154968
Batch 18/64 loss: 0.3019024729728699
Batch 19/64 loss: 0.2984458804130554
Batch 20/64 loss: 0.3038027286529541
Batch 21/64 loss: 0.31133174896240234
Batch 22/64 loss: 0.29732489585876465
Batch 23/64 loss: 0.3097512722015381
Batch 24/64 loss: 0.29247623682022095
Batch 25/64 loss: 0.30312925577163696
Batch 26/64 loss: 0.3063633441925049
Batch 27/64 loss: 0.30139631032943726
Batch 28/64 loss: 0.30582737922668457
Batch 29/64 loss: 0.3015439510345459
Batch 30/64 loss: 0.3089371919631958
Batch 31/64 loss: 0.30213212966918945
Batch 32/64 loss: 0.3020792603492737
Batch 33/64 loss: 0.31557953357696533
Batch 34/64 loss: 0.30664563179016113
Batch 35/64 loss: 0.3066747188568115
Batch 36/64 loss: 0.29938316345214844
Batch 37/64 loss: 0.30589759349823
Batch 38/64 loss: 0.2971035838127136
Batch 39/64 loss: 0.2984609603881836
Batch 40/64 loss: 0.3016219139099121
Batch 41/64 loss: 0.3044309616088867
Batch 42/64 loss: 0.3053724765777588
Batch 43/64 loss: 0.2985917329788208
Batch 44/64 loss: 0.31370145082473755
Batch 45/64 loss: 0.30629682540893555
Batch 46/64 loss: 0.2978706359863281
Batch 47/64 loss: 0.30930256843566895
Batch 48/64 loss: 0.31735682487487793
Batch 49/64 loss: 0.3072035312652588
Batch 50/64 loss: 0.3005191683769226
Batch 51/64 loss: 0.3047230839729309
Batch 52/64 loss: 0.3028935194015503
Batch 53/64 loss: 0.30035948753356934
Batch 54/64 loss: 0.3015328645706177
Batch 55/64 loss: 0.2984932065010071
Batch 56/64 loss: 0.2936364412307739
Batch 57/64 loss: 0.30874884128570557
Batch 58/64 loss: 0.2961575388908386
Batch 59/64 loss: 0.3137037754058838
Batch 60/64 loss: 0.3046969771385193
Batch 61/64 loss: 0.31179356575012207
Batch 62/64 loss: 0.30864107608795166
Batch 63/64 loss: 0.3080177307128906
Batch 64/64 loss: 0.307714581489563
Epoch 430  Train loss: 0.30416852118922216  Val loss: 0.3327960625956558
Epoch 431
-------------------------------
Batch 1/64 loss: 0.30082178115844727
Batch 2/64 loss: 0.2945706844329834
Batch 3/64 loss: 0.301807165145874
Batch 4/64 loss: 0.3043803572654724
Batch 5/64 loss: 0.29820334911346436
Batch 6/64 loss: 0.31131595373153687
Batch 7/64 loss: 0.2990517020225525
Batch 8/64 loss: 0.3052302598953247
Batch 9/64 loss: 0.3088868260383606
Batch 10/64 loss: 0.3128927946090698
Batch 11/64 loss: 0.31075286865234375
Batch 12/64 loss: 0.3039138913154602
Batch 13/64 loss: 0.3052576780319214
Batch 14/64 loss: 0.3015735149383545
Batch 15/64 loss: 0.31532609462738037
Batch 16/64 loss: 0.30599766969680786
Batch 17/64 loss: 0.30821073055267334
Batch 18/64 loss: 0.30655741691589355
Batch 19/64 loss: 0.30088508129119873
Batch 20/64 loss: 0.29638320207595825
Batch 21/64 loss: 0.2957039475440979
Batch 22/64 loss: 0.3023691177368164
Batch 23/64 loss: 0.3087276220321655
Batch 24/64 loss: 0.2909993529319763
Batch 25/64 loss: 0.3075913190841675
Batch 26/64 loss: 0.30601274967193604
Batch 27/64 loss: 0.29583853483200073
Batch 28/64 loss: 0.30801212787628174
Batch 29/64 loss: 0.3099384307861328
Batch 30/64 loss: 0.3031623363494873
Batch 31/64 loss: 0.314846932888031
Batch 32/64 loss: 0.3137620687484741
Batch 33/64 loss: 0.3025744557380676
Batch 34/64 loss: 0.30264973640441895
Batch 35/64 loss: 0.30330562591552734
Batch 36/64 loss: 0.30998504161834717
Batch 37/64 loss: 0.3083133101463318
Batch 38/64 loss: 0.2995160222053528
Batch 39/64 loss: 0.2981153726577759
Batch 40/64 loss: 0.3031914234161377
Batch 41/64 loss: 0.3112919330596924
Batch 42/64 loss: 0.29860085248947144
Batch 43/64 loss: 0.3023960590362549
Batch 44/64 loss: 0.311151921749115
Batch 45/64 loss: 0.30753010511398315
Batch 46/64 loss: 0.3022252917289734
Batch 47/64 loss: 0.3103570342063904
Batch 48/64 loss: 0.3011816740036011
Batch 49/64 loss: 0.3050013780593872
Batch 50/64 loss: 0.30494117736816406
Batch 51/64 loss: 0.2914186716079712
Batch 52/64 loss: 0.31264054775238037
Batch 53/64 loss: 0.29901981353759766
Batch 54/64 loss: 0.30315887928009033
Batch 55/64 loss: 0.2946953773498535
Batch 56/64 loss: 0.30684083700180054
Batch 57/64 loss: 0.30885934829711914
Batch 58/64 loss: 0.3106204867362976
Batch 59/64 loss: 0.30382776260375977
Batch 60/64 loss: 0.3048158288002014
Batch 61/64 loss: 0.2945324778556824
Batch 62/64 loss: 0.30415529012680054
Batch 63/64 loss: 0.2976815104484558
Batch 64/64 loss: 0.30835258960723877
Epoch 431  Train loss: 0.3042328353021659  Val loss: 0.3327562206799222
Epoch 432
-------------------------------
Batch 1/64 loss: 0.30343401432037354
Batch 2/64 loss: 0.2994033098220825
Batch 3/64 loss: 0.29950273036956787
Batch 4/64 loss: 0.3138524889945984
Batch 5/64 loss: 0.3040371537208557
Batch 6/64 loss: 0.29892945289611816
Batch 7/64 loss: 0.30069684982299805
Batch 8/64 loss: 0.31473076343536377
Batch 9/64 loss: 0.30341851711273193
Batch 10/64 loss: 0.3014962673187256
Batch 11/64 loss: 0.2977250814437866
Batch 12/64 loss: 0.30112576484680176
Batch 13/64 loss: 0.2965047359466553
Batch 14/64 loss: 0.307889461517334
Batch 15/64 loss: 0.3094695806503296
Batch 16/64 loss: 0.29894644021987915
Batch 17/64 loss: 0.29314517974853516
Batch 18/64 loss: 0.30106592178344727
Batch 19/64 loss: 0.31144285202026367
Batch 20/64 loss: 0.30984342098236084
Batch 21/64 loss: 0.30112504959106445
Batch 22/64 loss: 0.2972487211227417
Batch 23/64 loss: 0.31958866119384766
Batch 24/64 loss: 0.29011714458465576
Batch 25/64 loss: 0.3053727149963379
Batch 26/64 loss: 0.29900091886520386
Batch 27/64 loss: 0.298539400100708
Batch 28/64 loss: 0.3087843656539917
Batch 29/64 loss: 0.3117719292640686
Batch 30/64 loss: 0.3035299777984619
Batch 31/64 loss: 0.3096451759338379
Batch 32/64 loss: 0.3074800372123718
Batch 33/64 loss: 0.30950480699539185
Batch 34/64 loss: 0.3067309260368347
Batch 35/64 loss: 0.2958366870880127
Batch 36/64 loss: 0.30639052391052246
Batch 37/64 loss: 0.30163663625717163
Batch 38/64 loss: 0.3004946708679199
Batch 39/64 loss: 0.3094090223312378
Batch 40/64 loss: 0.30128228664398193
Batch 41/64 loss: 0.2987070083618164
Batch 42/64 loss: 0.30780720710754395
Batch 43/64 loss: 0.30541110038757324
Batch 44/64 loss: 0.30601346492767334
Batch 45/64 loss: 0.31045472621917725
Batch 46/64 loss: 0.3042609691619873
Batch 47/64 loss: 0.3061145544052124
Batch 48/64 loss: 0.30608367919921875
Batch 49/64 loss: 0.3017888069152832
Batch 50/64 loss: 0.3078347444534302
Batch 51/64 loss: 0.29383695125579834
Batch 52/64 loss: 0.30271708965301514
Batch 53/64 loss: 0.30336570739746094
Batch 54/64 loss: 0.3034799098968506
Batch 55/64 loss: 0.3038008213043213
Batch 56/64 loss: 0.3099817633628845
Batch 57/64 loss: 0.3035712242126465
Batch 58/64 loss: 0.29531192779541016
Batch 59/64 loss: 0.3005525469779968
Batch 60/64 loss: 0.30764520168304443
Batch 61/64 loss: 0.3103677034378052
Batch 62/64 loss: 0.30597805976867676
Batch 63/64 loss: 0.3115614056587219
Batch 64/64 loss: 0.3117436170578003
Epoch 432  Train loss: 0.3041663361530678  Val loss: 0.33467915746354565
Epoch 433
-------------------------------
Batch 1/64 loss: 0.3100740313529968
Batch 2/64 loss: 0.30889892578125
Batch 3/64 loss: 0.3097648620605469
Batch 4/64 loss: 0.3099788427352905
Batch 5/64 loss: 0.3093527555465698
Batch 6/64 loss: 0.29840153455734253
Batch 7/64 loss: 0.3013541102409363
Batch 8/64 loss: 0.3094520568847656
Batch 9/64 loss: 0.2992236614227295
Batch 10/64 loss: 0.299017071723938
Batch 11/64 loss: 0.3042266368865967
Batch 12/64 loss: 0.29845142364501953
Batch 13/64 loss: 0.3087886571884155
Batch 14/64 loss: 0.30783283710479736
Batch 15/64 loss: 0.2920770049095154
Batch 16/64 loss: 0.3133782744407654
Batch 17/64 loss: 0.2997775077819824
Batch 18/64 loss: 0.31299930810928345
Batch 19/64 loss: 0.30144423246383667
Batch 20/64 loss: 0.29870927333831787
Batch 21/64 loss: 0.29893553256988525
Batch 22/64 loss: 0.30176472663879395
Batch 23/64 loss: 0.3082212209701538
Batch 24/64 loss: 0.29762864112854004
Batch 25/64 loss: 0.29656982421875
Batch 26/64 loss: 0.3041950464248657
Batch 27/64 loss: 0.30437564849853516
Batch 28/64 loss: 0.31011754274368286
Batch 29/64 loss: 0.2945706844329834
Batch 30/64 loss: 0.31340932846069336
Batch 31/64 loss: 0.29648613929748535
Batch 32/64 loss: 0.305827260017395
Batch 33/64 loss: 0.2939770221710205
Batch 34/64 loss: 0.3180532455444336
Batch 35/64 loss: 0.29916703701019287
Batch 36/64 loss: 0.29294437170028687
Batch 37/64 loss: 0.30660712718963623
Batch 38/64 loss: 0.3158355951309204
Batch 39/64 loss: 0.2947503328323364
Batch 40/64 loss: 0.29889607429504395
Batch 41/64 loss: 0.3057183027267456
Batch 42/64 loss: 0.29997527599334717
Batch 43/64 loss: 0.30618810653686523
Batch 44/64 loss: 0.3020564913749695
Batch 45/64 loss: 0.3033626079559326
Batch 46/64 loss: 0.30444979667663574
Batch 47/64 loss: 0.2987338900566101
Batch 48/64 loss: 0.30552423000335693
Batch 49/64 loss: 0.30410677194595337
Batch 50/64 loss: 0.30758440494537354
Batch 51/64 loss: 0.3082772493362427
Batch 52/64 loss: 0.30521082878112793
Batch 53/64 loss: 0.3053460717201233
Batch 54/64 loss: 0.30322521924972534
Batch 55/64 loss: 0.3046365976333618
Batch 56/64 loss: 0.30210167169570923
Batch 57/64 loss: 0.3115065097808838
Batch 58/64 loss: 0.2972349524497986
Batch 59/64 loss: 0.2993050813674927
Batch 60/64 loss: 0.3017319440841675
Batch 61/64 loss: 0.3037010431289673
Batch 62/64 loss: 0.31110680103302
Batch 63/64 loss: 0.30825626850128174
Batch 64/64 loss: 0.31298136711120605
Epoch 433  Train loss: 0.30399390669430004  Val loss: 0.33153622031621505
Saving best model, epoch: 433
Epoch 434
-------------------------------
Batch 1/64 loss: 0.30576884746551514
Batch 2/64 loss: 0.2981196641921997
Batch 3/64 loss: 0.29684674739837646
Batch 4/64 loss: 0.3036116361618042
Batch 5/64 loss: 0.3011043071746826
Batch 6/64 loss: 0.3052530288696289
Batch 7/64 loss: 0.2971980571746826
Batch 8/64 loss: 0.30586540699005127
Batch 9/64 loss: 0.2914496660232544
Batch 10/64 loss: 0.2989004850387573
Batch 11/64 loss: 0.3060477375984192
Batch 12/64 loss: 0.3047827482223511
Batch 13/64 loss: 0.30520379543304443
Batch 14/64 loss: 0.2962677478790283
Batch 15/64 loss: 0.29575037956237793
Batch 16/64 loss: 0.3015667200088501
Batch 17/64 loss: 0.30820226669311523
Batch 18/64 loss: 0.3000808358192444
Batch 19/64 loss: 0.30689680576324463
Batch 20/64 loss: 0.3069153428077698
Batch 21/64 loss: 0.30965352058410645
Batch 22/64 loss: 0.29716384410858154
Batch 23/64 loss: 0.30361104011535645
Batch 24/64 loss: 0.3082062005996704
Batch 25/64 loss: 0.31045448780059814
Batch 26/64 loss: 0.2969270944595337
Batch 27/64 loss: 0.303358793258667
Batch 28/64 loss: 0.3111955523490906
Batch 29/64 loss: 0.2966846227645874
Batch 30/64 loss: 0.308954656124115
Batch 31/64 loss: 0.30487632751464844
Batch 32/64 loss: 0.29804837703704834
Batch 33/64 loss: 0.30754005908966064
Batch 34/64 loss: 0.30490386486053467
Batch 35/64 loss: 0.2998412251472473
Batch 36/64 loss: 0.2988722324371338
Batch 37/64 loss: 0.2997840642929077
Batch 38/64 loss: 0.3055468797683716
Batch 39/64 loss: 0.3111155033111572
Batch 40/64 loss: 0.3005479574203491
Batch 41/64 loss: 0.3004347085952759
Batch 42/64 loss: 0.31011784076690674
Batch 43/64 loss: 0.30551522970199585
Batch 44/64 loss: 0.30971699953079224
Batch 45/64 loss: 0.31020301580429077
Batch 46/64 loss: 0.30176055431365967
Batch 47/64 loss: 0.3034093976020813
Batch 48/64 loss: 0.30062246322631836
Batch 49/64 loss: 0.3023340702056885
Batch 50/64 loss: 0.31226468086242676
Batch 51/64 loss: 0.3044612407684326
Batch 52/64 loss: 0.3035989999771118
Batch 53/64 loss: 0.31112825870513916
Batch 54/64 loss: 0.3029558062553406
Batch 55/64 loss: 0.3110768795013428
Batch 56/64 loss: 0.30522775650024414
Batch 57/64 loss: 0.3069685697555542
Batch 58/64 loss: 0.3005920648574829
Batch 59/64 loss: 0.3113735318183899
Batch 60/64 loss: 0.3032594919204712
Batch 61/64 loss: 0.2913597822189331
Batch 62/64 loss: 0.3051069378852844
Batch 63/64 loss: 0.3031136989593506
Batch 64/64 loss: 0.30302369594573975
Epoch 434  Train loss: 0.3036390318590052  Val loss: 0.33240776025142865
Epoch 435
-------------------------------
Batch 1/64 loss: 0.30879509449005127
Batch 2/64 loss: 0.301207959651947
Batch 3/64 loss: 0.3049843907356262
Batch 4/64 loss: 0.3065946698188782
Batch 5/64 loss: 0.30892592668533325
Batch 6/64 loss: 0.29968637228012085
Batch 7/64 loss: 0.30843043327331543
Batch 8/64 loss: 0.30115532875061035
Batch 9/64 loss: 0.30107367038726807
Batch 10/64 loss: 0.3048865795135498
Batch 11/64 loss: 0.2957308888435364
Batch 12/64 loss: 0.299877405166626
Batch 13/64 loss: 0.31812429428100586
Batch 14/64 loss: 0.29730623960494995
Batch 15/64 loss: 0.3008025884628296
Batch 16/64 loss: 0.3057546615600586
Batch 17/64 loss: 0.305663526058197
Batch 18/64 loss: 0.2921547293663025
Batch 19/64 loss: 0.31077122688293457
Batch 20/64 loss: 0.301973819732666
Batch 21/64 loss: 0.29858332872390747
Batch 22/64 loss: 0.29690879583358765
Batch 23/64 loss: 0.3053179383277893
Batch 24/64 loss: 0.3044624328613281
Batch 25/64 loss: 0.3003140091896057
Batch 26/64 loss: 0.3066105246543884
Batch 27/64 loss: 0.30492103099823
Batch 28/64 loss: 0.3125538229942322
Batch 29/64 loss: 0.3037688136100769
Batch 30/64 loss: 0.30174577236175537
Batch 31/64 loss: 0.2964494824409485
Batch 32/64 loss: 0.3106677532196045
Batch 33/64 loss: 0.3026149272918701
Batch 34/64 loss: 0.30728214979171753
Batch 35/64 loss: 0.30472755432128906
Batch 36/64 loss: 0.31450533866882324
Batch 37/64 loss: 0.3004802465438843
Batch 38/64 loss: 0.30616629123687744
Batch 39/64 loss: 0.30488431453704834
Batch 40/64 loss: 0.30969202518463135
Batch 41/64 loss: 0.3000715970993042
Batch 42/64 loss: 0.30534863471984863
Batch 43/64 loss: 0.3089452385902405
Batch 44/64 loss: 0.30348122119903564
Batch 45/64 loss: 0.2987370491027832
Batch 46/64 loss: 0.3068959712982178
Batch 47/64 loss: 0.31240129470825195
Batch 48/64 loss: 0.29653578996658325
Batch 49/64 loss: 0.2961156368255615
Batch 50/64 loss: 0.29568904638290405
Batch 51/64 loss: 0.31081902980804443
Batch 52/64 loss: 0.3106074333190918
Batch 53/64 loss: 0.2974326014518738
Batch 54/64 loss: 0.30415332317352295
Batch 55/64 loss: 0.3069363832473755
Batch 56/64 loss: 0.3072669506072998
Batch 57/64 loss: 0.3095439672470093
Batch 58/64 loss: 0.2903708219528198
Batch 59/64 loss: 0.3018132448196411
Batch 60/64 loss: 0.3012726306915283
Batch 61/64 loss: 0.3015758991241455
Batch 62/64 loss: 0.3051645755767822
Batch 63/64 loss: 0.29753172397613525
Batch 64/64 loss: 0.308657169342041
Epoch 435  Train loss: 0.3037923027487362  Val loss: 0.3323483256130284
Epoch 436
-------------------------------
Batch 1/64 loss: 0.30118298530578613
Batch 2/64 loss: 0.2979196310043335
Batch 3/64 loss: 0.30247795581817627
Batch 4/64 loss: 0.292630672454834
Batch 5/64 loss: 0.30263686180114746
Batch 6/64 loss: 0.29944872856140137
Batch 7/64 loss: 0.30411863327026367
Batch 8/64 loss: 0.30266761779785156
Batch 9/64 loss: 0.2975941300392151
Batch 10/64 loss: 0.30235016345977783
Batch 11/64 loss: 0.29645633697509766
Batch 12/64 loss: 0.3158702850341797
Batch 13/64 loss: 0.3069906234741211
Batch 14/64 loss: 0.30392348766326904
Batch 15/64 loss: 0.3035280704498291
Batch 16/64 loss: 0.30870163440704346
Batch 17/64 loss: 0.3085095286369324
Batch 18/64 loss: 0.29971981048583984
Batch 19/64 loss: 0.31094205379486084
Batch 20/64 loss: 0.3031419515609741
Batch 21/64 loss: 0.29766136407852173
Batch 22/64 loss: 0.29921138286590576
Batch 23/64 loss: 0.2969820499420166
Batch 24/64 loss: 0.29811346530914307
Batch 25/64 loss: 0.29041314125061035
Batch 26/64 loss: 0.30682551860809326
Batch 27/64 loss: 0.2950620651245117
Batch 28/64 loss: 0.2996412515640259
Batch 29/64 loss: 0.3073321580886841
Batch 30/64 loss: 0.3119328022003174
Batch 31/64 loss: 0.2999724745750427
Batch 32/64 loss: 0.3077116012573242
Batch 33/64 loss: 0.30509209632873535
Batch 34/64 loss: 0.3030773401260376
Batch 35/64 loss: 0.3001142740249634
Batch 36/64 loss: 0.3073142170906067
Batch 37/64 loss: 0.3059864044189453
Batch 38/64 loss: 0.29797184467315674
Batch 39/64 loss: 0.2990809679031372
Batch 40/64 loss: 0.2937835454940796
Batch 41/64 loss: 0.30235838890075684
Batch 42/64 loss: 0.30425071716308594
Batch 43/64 loss: 0.30561959743499756
Batch 44/64 loss: 0.3004807233810425
Batch 45/64 loss: 0.3107590079307556
Batch 46/64 loss: 0.31578463315963745
Batch 47/64 loss: 0.2958793640136719
Batch 48/64 loss: 0.31188517808914185
Batch 49/64 loss: 0.31185686588287354
Batch 50/64 loss: 0.2992285490036011
Batch 51/64 loss: 0.31262707710266113
Batch 52/64 loss: 0.3132835030555725
Batch 53/64 loss: 0.29396283626556396
Batch 54/64 loss: 0.30352461338043213
Batch 55/64 loss: 0.29602622985839844
Batch 56/64 loss: 0.2981373071670532
Batch 57/64 loss: 0.3092588186264038
Batch 58/64 loss: 0.30254489183425903
Batch 59/64 loss: 0.3033059239387512
Batch 60/64 loss: 0.30564987659454346
Batch 61/64 loss: 0.3068092465400696
Batch 62/64 loss: 0.3041442632675171
Batch 63/64 loss: 0.2998847961425781
Batch 64/64 loss: 0.32249653339385986
Epoch 436  Train loss: 0.30326628918741266  Val loss: 0.3324086825872205
Epoch 437
-------------------------------
Batch 1/64 loss: 0.3060266375541687
Batch 2/64 loss: 0.3087313771247864
Batch 3/64 loss: 0.3080216646194458
Batch 4/64 loss: 0.2978098392486572
Batch 5/64 loss: 0.2966289520263672
Batch 6/64 loss: 0.2942304015159607
Batch 7/64 loss: 0.293073832988739
Batch 8/64 loss: 0.3061637878417969
Batch 9/64 loss: 0.29837948083877563
Batch 10/64 loss: 0.3005087971687317
Batch 11/64 loss: 0.3019431233406067
Batch 12/64 loss: 0.308118999004364
Batch 13/64 loss: 0.3128798007965088
Batch 14/64 loss: 0.30565178394317627
Batch 15/64 loss: 0.3087434768676758
Batch 16/64 loss: 0.3083701729774475
Batch 17/64 loss: 0.298578143119812
Batch 18/64 loss: 0.2967984080314636
Batch 19/64 loss: 0.3104398250579834
Batch 20/64 loss: 0.3006533980369568
Batch 21/64 loss: 0.3102661371231079
Batch 22/64 loss: 0.3074529767036438
Batch 23/64 loss: 0.3018474578857422
Batch 24/64 loss: 0.2947819232940674
Batch 25/64 loss: 0.30128777027130127
Batch 26/64 loss: 0.30140435695648193
Batch 27/64 loss: 0.3017650842666626
Batch 28/64 loss: 0.30589818954467773
Batch 29/64 loss: 0.3018355369567871
Batch 30/64 loss: 0.29779869318008423
Batch 31/64 loss: 0.2933884859085083
Batch 32/64 loss: 0.2969730496406555
Batch 33/64 loss: 0.3111741542816162
Batch 34/64 loss: 0.30109143257141113
Batch 35/64 loss: 0.3017095923423767
Batch 36/64 loss: 0.29925858974456787
Batch 37/64 loss: 0.29927945137023926
Batch 38/64 loss: 0.30309003591537476
Batch 39/64 loss: 0.2976146936416626
Batch 40/64 loss: 0.3144516944885254
Batch 41/64 loss: 0.3012428283691406
Batch 42/64 loss: 0.310757577419281
Batch 43/64 loss: 0.30751216411590576
Batch 44/64 loss: 0.3044790029525757
Batch 45/64 loss: 0.296342670917511
Batch 46/64 loss: 0.29832983016967773
Batch 47/64 loss: 0.30722832679748535
Batch 48/64 loss: 0.3039284944534302
Batch 49/64 loss: 0.30544114112854004
Batch 50/64 loss: 0.2987029552459717
Batch 51/64 loss: 0.3058655261993408
Batch 52/64 loss: 0.3089746832847595
Batch 53/64 loss: 0.3065516948699951
Batch 54/64 loss: 0.2923543453216553
Batch 55/64 loss: 0.3091961145401001
Batch 56/64 loss: 0.30698323249816895
Batch 57/64 loss: 0.30540037155151367
Batch 58/64 loss: 0.3045324683189392
Batch 59/64 loss: 0.30464816093444824
Batch 60/64 loss: 0.296245276927948
Batch 61/64 loss: 0.30275464057922363
Batch 62/64 loss: 0.2977588176727295
Batch 63/64 loss: 0.30410706996917725
Batch 64/64 loss: 0.3033285140991211
Epoch 437  Train loss: 0.30291694098827887  Val loss: 0.33229943403263684
Epoch 438
-------------------------------
Batch 1/64 loss: 0.3056037425994873
Batch 2/64 loss: 0.30236101150512695
Batch 3/64 loss: 0.3025675415992737
Batch 4/64 loss: 0.2988623380661011
Batch 5/64 loss: 0.3063738942146301
Batch 6/64 loss: 0.30481672286987305
Batch 7/64 loss: 0.2941805124282837
Batch 8/64 loss: 0.29823970794677734
Batch 9/64 loss: 0.30873727798461914
Batch 10/64 loss: 0.2945099472999573
Batch 11/64 loss: 0.3076452612876892
Batch 12/64 loss: 0.31309378147125244
Batch 13/64 loss: 0.2973078489303589
Batch 14/64 loss: 0.3102761507034302
Batch 15/64 loss: 0.30722570419311523
Batch 16/64 loss: 0.3035760521888733
Batch 17/64 loss: 0.30335795879364014
Batch 18/64 loss: 0.2964816093444824
Batch 19/64 loss: 0.30372190475463867
Batch 20/64 loss: 0.2975371479988098
Batch 21/64 loss: 0.30740880966186523
Batch 22/64 loss: 0.3077061176300049
Batch 23/64 loss: 0.3089778423309326
Batch 24/64 loss: 0.30132025480270386
Batch 25/64 loss: 0.2970384955406189
Batch 26/64 loss: 0.3071439266204834
Batch 27/64 loss: 0.2974891662597656
Batch 28/64 loss: 0.2958308458328247
Batch 29/64 loss: 0.29673707485198975
Batch 30/64 loss: 0.3184054493904114
Batch 31/64 loss: 0.30481910705566406
Batch 32/64 loss: 0.3045157790184021
Batch 33/64 loss: 0.3024030923843384
Batch 34/64 loss: 0.3065081238746643
Batch 35/64 loss: 0.2976266145706177
Batch 36/64 loss: 0.30275291204452515
Batch 37/64 loss: 0.31275707483291626
Batch 38/64 loss: 0.29543018341064453
Batch 39/64 loss: 0.29574453830718994
Batch 40/64 loss: 0.2991023063659668
Batch 41/64 loss: 0.29833704233169556
Batch 42/64 loss: 0.310868501663208
Batch 43/64 loss: 0.29700541496276855
Batch 44/64 loss: 0.2991851568222046
Batch 45/64 loss: 0.29105710983276367
Batch 46/64 loss: 0.304512619972229
Batch 47/64 loss: 0.2991642355918884
Batch 48/64 loss: 0.2979106903076172
Batch 49/64 loss: 0.310282826423645
Batch 50/64 loss: 0.3029264807701111
Batch 51/64 loss: 0.2974400520324707
Batch 52/64 loss: 0.3083186745643616
Batch 53/64 loss: 0.304670512676239
Batch 54/64 loss: 0.3029974699020386
Batch 55/64 loss: 0.3122178912162781
Batch 56/64 loss: 0.3103775978088379
Batch 57/64 loss: 0.293521523475647
Batch 58/64 loss: 0.30492550134658813
Batch 59/64 loss: 0.3104174733161926
Batch 60/64 loss: 0.2940821647644043
Batch 61/64 loss: 0.2966994047164917
Batch 62/64 loss: 0.31140315532684326
Batch 63/64 loss: 0.30782365798950195
Batch 64/64 loss: 0.3098665475845337
Epoch 438  Train loss: 0.3029762964622647  Val loss: 0.3320169522590244
Epoch 439
-------------------------------
Batch 1/64 loss: 0.29859888553619385
Batch 2/64 loss: 0.2971090078353882
Batch 3/64 loss: 0.3034728765487671
Batch 4/64 loss: 0.3053811192512512
Batch 5/64 loss: 0.30145883560180664
Batch 6/64 loss: 0.30842268466949463
Batch 7/64 loss: 0.29525554180145264
Batch 8/64 loss: 0.29696524143218994
Batch 9/64 loss: 0.30605411529541016
Batch 10/64 loss: 0.2963792085647583
Batch 11/64 loss: 0.3081604838371277
Batch 12/64 loss: 0.30339515209198
Batch 13/64 loss: 0.29326701164245605
Batch 14/64 loss: 0.3026352524757385
Batch 15/64 loss: 0.3033815622329712
Batch 16/64 loss: 0.3022923469543457
Batch 17/64 loss: 0.3014568090438843
Batch 18/64 loss: 0.3055812120437622
Batch 19/64 loss: 0.3035067915916443
Batch 20/64 loss: 0.296977162361145
Batch 21/64 loss: 0.3140503168106079
Batch 22/64 loss: 0.30406612157821655
Batch 23/64 loss: 0.30888092517852783
Batch 24/64 loss: 0.3024028539657593
Batch 25/64 loss: 0.30041778087615967
Batch 26/64 loss: 0.29784584045410156
Batch 27/64 loss: 0.30692601203918457
Batch 28/64 loss: 0.30292022228240967
Batch 29/64 loss: 0.30213987827301025
Batch 30/64 loss: 0.30897921323776245
Batch 31/64 loss: 0.2973679304122925
Batch 32/64 loss: 0.3040727376937866
Batch 33/64 loss: 0.31123554706573486
Batch 34/64 loss: 0.3019685745239258
Batch 35/64 loss: 0.29664117097854614
Batch 36/64 loss: 0.30012547969818115
Batch 37/64 loss: 0.2982177138328552
Batch 38/64 loss: 0.29459595680236816
Batch 39/64 loss: 0.2972531318664551
Batch 40/64 loss: 0.3101581335067749
Batch 41/64 loss: 0.29743051528930664
Batch 42/64 loss: 0.30317211151123047
Batch 43/64 loss: 0.3106992244720459
Batch 44/64 loss: 0.30202484130859375
Batch 45/64 loss: 0.3082658052444458
Batch 46/64 loss: 0.30496203899383545
Batch 47/64 loss: 0.2997109889984131
Batch 48/64 loss: 0.31511640548706055
Batch 49/64 loss: 0.30904293060302734
Batch 50/64 loss: 0.2985067367553711
Batch 51/64 loss: 0.30555593967437744
Batch 52/64 loss: 0.2967207431793213
Batch 53/64 loss: 0.299511194229126
Batch 54/64 loss: 0.3040977120399475
Batch 55/64 loss: 0.2998316287994385
Batch 56/64 loss: 0.30305445194244385
Batch 57/64 loss: 0.30630505084991455
Batch 58/64 loss: 0.29336225986480713
Batch 59/64 loss: 0.32347244024276733
Batch 60/64 loss: 0.30275261402130127
Batch 61/64 loss: 0.30265533924102783
Batch 62/64 loss: 0.30782246589660645
Batch 63/64 loss: 0.29690778255462646
Batch 64/64 loss: 0.29776543378829956
Epoch 439  Train loss: 0.3028128962890775  Val loss: 0.3319863552080397
Epoch 440
-------------------------------
Batch 1/64 loss: 0.30192244052886963
Batch 2/64 loss: 0.29531723260879517
Batch 3/64 loss: 0.28959864377975464
Batch 4/64 loss: 0.3040139675140381
Batch 5/64 loss: 0.29251593351364136
Batch 6/64 loss: 0.3017781972885132
Batch 7/64 loss: 0.30269157886505127
Batch 8/64 loss: 0.3052346110343933
Batch 9/64 loss: 0.3115910291671753
Batch 10/64 loss: 0.314012348651886
Batch 11/64 loss: 0.30116981267929077
Batch 12/64 loss: 0.2978404760360718
Batch 13/64 loss: 0.29957258701324463
Batch 14/64 loss: 0.30371761322021484
Batch 15/64 loss: 0.3027174472808838
Batch 16/64 loss: 0.3016587495803833
Batch 17/64 loss: 0.3024293780326843
Batch 18/64 loss: 0.3126406669616699
Batch 19/64 loss: 0.3008517026901245
Batch 20/64 loss: 0.29550623893737793
Batch 21/64 loss: 0.30623364448547363
Batch 22/64 loss: 0.2974286675453186
Batch 23/64 loss: 0.30193638801574707
Batch 24/64 loss: 0.2971290349960327
Batch 25/64 loss: 0.2953838109970093
Batch 26/64 loss: 0.30570197105407715
Batch 27/64 loss: 0.3000507950782776
Batch 28/64 loss: 0.3026231527328491
Batch 29/64 loss: 0.31375277042388916
Batch 30/64 loss: 0.3104812502861023
Batch 31/64 loss: 0.29946136474609375
Batch 32/64 loss: 0.3084152936935425
Batch 33/64 loss: 0.3046736717224121
Batch 34/64 loss: 0.2933052182197571
Batch 35/64 loss: 0.29515379667282104
Batch 36/64 loss: 0.30947184562683105
Batch 37/64 loss: 0.30009353160858154
Batch 38/64 loss: 0.30981993675231934
Batch 39/64 loss: 0.2996469736099243
Batch 40/64 loss: 0.3076932430267334
Batch 41/64 loss: 0.3125324249267578
Batch 42/64 loss: 0.3109722137451172
Batch 43/64 loss: 0.3005455732345581
Batch 44/64 loss: 0.303372859954834
Batch 45/64 loss: 0.31436216831207275
Batch 46/64 loss: 0.2979738116264343
Batch 47/64 loss: 0.3050358295440674
Batch 48/64 loss: 0.3030637502670288
Batch 49/64 loss: 0.3018551468849182
Batch 50/64 loss: 0.3042415380477905
Batch 51/64 loss: 0.29877692461013794
Batch 52/64 loss: 0.3112559914588928
Batch 53/64 loss: 0.3077554702758789
Batch 54/64 loss: 0.29298627376556396
Batch 55/64 loss: 0.2988321781158447
Batch 56/64 loss: 0.30562686920166016
Batch 57/64 loss: 0.2989063262939453
Batch 58/64 loss: 0.31257563829421997
Batch 59/64 loss: 0.31128787994384766
Batch 60/64 loss: 0.3046921491622925
Batch 61/64 loss: 0.30047088861465454
Batch 62/64 loss: 0.30861425399780273
Batch 63/64 loss: 0.30795228481292725
Batch 64/64 loss: 0.29811394214630127
Epoch 440  Train loss: 0.3032550732294718  Val loss: 0.33450082937876385
Epoch 441
-------------------------------
Batch 1/64 loss: 0.30706334114074707
Batch 2/64 loss: 0.31095874309539795
Batch 3/64 loss: 0.3107907772064209
Batch 4/64 loss: 0.2946140766143799
Batch 5/64 loss: 0.32069337368011475
Batch 6/64 loss: 0.30077338218688965
Batch 7/64 loss: 0.29803943634033203
Batch 8/64 loss: 0.31232190132141113
Batch 9/64 loss: 0.3007549047470093
Batch 10/64 loss: 0.29558104276657104
Batch 11/64 loss: 0.2984471321105957
Batch 12/64 loss: 0.2953437566757202
Batch 13/64 loss: 0.301247775554657
Batch 14/64 loss: 0.30963242053985596
Batch 15/64 loss: 0.3052196502685547
Batch 16/64 loss: 0.2933489680290222
Batch 17/64 loss: 0.29931408166885376
Batch 18/64 loss: 0.3143554925918579
Batch 19/64 loss: 0.3170672655105591
Batch 20/64 loss: 0.31257879734039307
Batch 21/64 loss: 0.31350821256637573
Batch 22/64 loss: 0.3037137985229492
Batch 23/64 loss: 0.2953561544418335
Batch 24/64 loss: 0.3023930788040161
Batch 25/64 loss: 0.30406028032302856
Batch 26/64 loss: 0.30947351455688477
Batch 27/64 loss: 0.3005583882331848
Batch 28/64 loss: 0.30212366580963135
Batch 29/64 loss: 0.30529069900512695
Batch 30/64 loss: 0.2970644235610962
Batch 31/64 loss: 0.29961448907852173
Batch 32/64 loss: 0.3052731156349182
Batch 33/64 loss: 0.3035259246826172
Batch 34/64 loss: 0.30951988697052
Batch 35/64 loss: 0.3101188540458679
Batch 36/64 loss: 0.30364686250686646
Batch 37/64 loss: 0.29596006870269775
Batch 38/64 loss: 0.29506373405456543
Batch 39/64 loss: 0.30191969871520996
Batch 40/64 loss: 0.30110251903533936
Batch 41/64 loss: 0.3143351078033447
Batch 42/64 loss: 0.31280165910720825
Batch 43/64 loss: 0.29866135120391846
Batch 44/64 loss: 0.29771625995635986
Batch 45/64 loss: 0.30021190643310547
Batch 46/64 loss: 0.30064356327056885
Batch 47/64 loss: 0.31476765871047974
Batch 48/64 loss: 0.29533326625823975
Batch 49/64 loss: 0.3019857406616211
Batch 50/64 loss: 0.31174707412719727
Batch 51/64 loss: 0.29979562759399414
Batch 52/64 loss: 0.2968931198120117
Batch 53/64 loss: 0.30052220821380615
Batch 54/64 loss: 0.3046060800552368
Batch 55/64 loss: 0.29808926582336426
Batch 56/64 loss: 0.29372739791870117
Batch 57/64 loss: 0.30802857875823975
Batch 58/64 loss: 0.2969602346420288
Batch 59/64 loss: 0.303915798664093
Batch 60/64 loss: 0.30498337745666504
Batch 61/64 loss: 0.3052394390106201
Batch 62/64 loss: 0.29613667726516724
Batch 63/64 loss: 0.3046150207519531
Batch 64/64 loss: 0.30565083026885986
Epoch 441  Train loss: 0.3035041290171006  Val loss: 0.3324043373881337
Epoch 442
-------------------------------
Batch 1/64 loss: 0.304388165473938
Batch 2/64 loss: 0.2958935499191284
Batch 3/64 loss: 0.30174022912979126
Batch 4/64 loss: 0.3003711700439453
Batch 5/64 loss: 0.29946887493133545
Batch 6/64 loss: 0.29843050241470337
Batch 7/64 loss: 0.3031308650970459
Batch 8/64 loss: 0.2939804792404175
Batch 9/64 loss: 0.29898250102996826
Batch 10/64 loss: 0.3059704303741455
Batch 11/64 loss: 0.3014858365058899
Batch 12/64 loss: 0.2910720705986023
Batch 13/64 loss: 0.3056678771972656
Batch 14/64 loss: 0.30420517921447754
Batch 15/64 loss: 0.2996464967727661
Batch 16/64 loss: 0.30587172508239746
Batch 17/64 loss: 0.2984344959259033
Batch 18/64 loss: 0.29639744758605957
Batch 19/64 loss: 0.31392812728881836
Batch 20/64 loss: 0.2942255735397339
Batch 21/64 loss: 0.29517459869384766
Batch 22/64 loss: 0.30121147632598877
Batch 23/64 loss: 0.31293296813964844
Batch 24/64 loss: 0.2958528399467468
Batch 25/64 loss: 0.3031885027885437
Batch 26/64 loss: 0.30436277389526367
Batch 27/64 loss: 0.2996646761894226
Batch 28/64 loss: 0.30502545833587646
Batch 29/64 loss: 0.3108450770378113
Batch 30/64 loss: 0.2972867488861084
Batch 31/64 loss: 0.3052877187728882
Batch 32/64 loss: 0.3059424161911011
Batch 33/64 loss: 0.3035784363746643
Batch 34/64 loss: 0.29625582695007324
Batch 35/64 loss: 0.3001183867454529
Batch 36/64 loss: 0.3018686771392822
Batch 37/64 loss: 0.30541372299194336
Batch 38/64 loss: 0.30654823780059814
Batch 39/64 loss: 0.313443124294281
Batch 40/64 loss: 0.3111231327056885
Batch 41/64 loss: 0.30405670404434204
Batch 42/64 loss: 0.3044925332069397
Batch 43/64 loss: 0.29508787393569946
Batch 44/64 loss: 0.3059500455856323
Batch 45/64 loss: 0.31118547916412354
Batch 46/64 loss: 0.30619490146636963
Batch 47/64 loss: 0.30179011821746826
Batch 48/64 loss: 0.31099069118499756
Batch 49/64 loss: 0.30177074670791626
Batch 50/64 loss: 0.3111116886138916
Batch 51/64 loss: 0.31007617712020874
Batch 52/64 loss: 0.3067016005516052
Batch 53/64 loss: 0.3062450885772705
Batch 54/64 loss: 0.2942749857902527
Batch 55/64 loss: 0.3058096170425415
Batch 56/64 loss: 0.30700260400772095
Batch 57/64 loss: 0.30892205238342285
Batch 58/64 loss: 0.3045235872268677
Batch 59/64 loss: 0.3013622760772705
Batch 60/64 loss: 0.30046534538269043
Batch 61/64 loss: 0.2962839603424072
Batch 62/64 loss: 0.2981601357460022
Batch 63/64 loss: 0.3023800253868103
Batch 64/64 loss: 0.30418092012405396
Epoch 442  Train loss: 0.30292376981062047  Val loss: 0.33189779499552097
Epoch 443
-------------------------------
Batch 1/64 loss: 0.3061518669128418
Batch 2/64 loss: 0.2960158586502075
Batch 3/64 loss: 0.3097778558731079
Batch 4/64 loss: 0.29891395568847656
Batch 5/64 loss: 0.3087400794029236
Batch 6/64 loss: 0.3067188262939453
Batch 7/64 loss: 0.30985069274902344
Batch 8/64 loss: 0.3015456199645996
Batch 9/64 loss: 0.3121017813682556
Batch 10/64 loss: 0.3023109436035156
Batch 11/64 loss: 0.2970151901245117
Batch 12/64 loss: 0.31002509593963623
Batch 13/64 loss: 0.2971998453140259
Batch 14/64 loss: 0.2960178852081299
Batch 15/64 loss: 0.2980484962463379
Batch 16/64 loss: 0.3043375015258789
Batch 17/64 loss: 0.2991034984588623
Batch 18/64 loss: 0.30458736419677734
Batch 19/64 loss: 0.2981598377227783
Batch 20/64 loss: 0.29568690061569214
Batch 21/64 loss: 0.29369044303894043
Batch 22/64 loss: 0.3015473484992981
Batch 23/64 loss: 0.29390472173690796
Batch 24/64 loss: 0.3091123104095459
Batch 25/64 loss: 0.30053919553756714
Batch 26/64 loss: 0.30521321296691895
Batch 27/64 loss: 0.30600041151046753
Batch 28/64 loss: 0.3016800284385681
Batch 29/64 loss: 0.2986847758293152
Batch 30/64 loss: 0.2944754362106323
Batch 31/64 loss: 0.30551713705062866
Batch 32/64 loss: 0.3094673156738281
Batch 33/64 loss: 0.3012935519218445
Batch 34/64 loss: 0.3109152317047119
Batch 35/64 loss: 0.3004024028778076
Batch 36/64 loss: 0.30281591415405273
Batch 37/64 loss: 0.30792856216430664
Batch 38/64 loss: 0.3042256236076355
Batch 39/64 loss: 0.29876840114593506
Batch 40/64 loss: 0.2995178699493408
Batch 41/64 loss: 0.3090716600418091
Batch 42/64 loss: 0.29981720447540283
Batch 43/64 loss: 0.310885488986969
Batch 44/64 loss: 0.3019464612007141
Batch 45/64 loss: 0.30381155014038086
Batch 46/64 loss: 0.30617284774780273
Batch 47/64 loss: 0.302604079246521
Batch 48/64 loss: 0.3021741509437561
Batch 49/64 loss: 0.30220407247543335
Batch 50/64 loss: 0.29906678199768066
Batch 51/64 loss: 0.300034761428833
Batch 52/64 loss: 0.3127991557121277
Batch 53/64 loss: 0.3099374771118164
Batch 54/64 loss: 0.3009933829307556
Batch 55/64 loss: 0.30226075649261475
Batch 56/64 loss: 0.3047845959663391
Batch 57/64 loss: 0.29255175590515137
Batch 58/64 loss: 0.30475491285324097
Batch 59/64 loss: 0.29994964599609375
Batch 60/64 loss: 0.3045656681060791
Batch 61/64 loss: 0.308573842048645
Batch 62/64 loss: 0.30580002069473267
Batch 63/64 loss: 0.3092312812805176
Batch 64/64 loss: 0.3083229660987854
Epoch 443  Train loss: 0.3031096904885535  Val loss: 0.332489350202567
Epoch 444
-------------------------------
Batch 1/64 loss: 0.2916090488433838
Batch 2/64 loss: 0.30613648891448975
Batch 3/64 loss: 0.30111122131347656
Batch 4/64 loss: 0.2963608503341675
Batch 5/64 loss: 0.311450719833374
Batch 6/64 loss: 0.298791766166687
Batch 7/64 loss: 0.3035467267036438
Batch 8/64 loss: 0.30664002895355225
Batch 9/64 loss: 0.29604578018188477
Batch 10/64 loss: 0.2983371615409851
Batch 11/64 loss: 0.3013317584991455
Batch 12/64 loss: 0.30743467807769775
Batch 13/64 loss: 0.30426090955734253
Batch 14/64 loss: 0.30689537525177
Batch 15/64 loss: 0.3019888401031494
Batch 16/64 loss: 0.29296886920928955
Batch 17/64 loss: 0.29696011543273926
Batch 18/64 loss: 0.3067513704299927
Batch 19/64 loss: 0.3065546751022339
Batch 20/64 loss: 0.2978404760360718
Batch 21/64 loss: 0.3096262812614441
Batch 22/64 loss: 0.3029310703277588
Batch 23/64 loss: 0.3028462529182434
Batch 24/64 loss: 0.30480337142944336
Batch 25/64 loss: 0.3002052307128906
Batch 26/64 loss: 0.3022651672363281
Batch 27/64 loss: 0.3049253225326538
Batch 28/64 loss: 0.3053462505340576
Batch 29/64 loss: 0.30916154384613037
Batch 30/64 loss: 0.3067359924316406
Batch 31/64 loss: 0.30481815338134766
Batch 32/64 loss: 0.304516077041626
Batch 33/64 loss: 0.30145496129989624
Batch 34/64 loss: 0.30569612979888916
Batch 35/64 loss: 0.2905961275100708
Batch 36/64 loss: 0.30598050355911255
Batch 37/64 loss: 0.31608039140701294
Batch 38/64 loss: 0.30063319206237793
Batch 39/64 loss: 0.3012579679489136
Batch 40/64 loss: 0.29500120878219604
Batch 41/64 loss: 0.3049626350402832
Batch 42/64 loss: 0.30694085359573364
Batch 43/64 loss: 0.3100670576095581
Batch 44/64 loss: 0.3073742389678955
Batch 45/64 loss: 0.294988751411438
Batch 46/64 loss: 0.29650819301605225
Batch 47/64 loss: 0.305966317653656
Batch 48/64 loss: 0.31425368785858154
Batch 49/64 loss: 0.2905047535896301
Batch 50/64 loss: 0.29762423038482666
Batch 51/64 loss: 0.30149972438812256
Batch 52/64 loss: 0.3048335313796997
Batch 53/64 loss: 0.30839288234710693
Batch 54/64 loss: 0.303303599357605
Batch 55/64 loss: 0.30562281608581543
Batch 56/64 loss: 0.2995457649230957
Batch 57/64 loss: 0.31460875272750854
Batch 58/64 loss: 0.30495113134384155
Batch 59/64 loss: 0.3051057457923889
Batch 60/64 loss: 0.3015204668045044
Batch 61/64 loss: 0.30320924520492554
Batch 62/64 loss: 0.3117596507072449
Batch 63/64 loss: 0.29857170581817627
Batch 64/64 loss: 0.2915973663330078
Epoch 444  Train loss: 0.3030386167414048  Val loss: 0.3320710833130014
Epoch 445
-------------------------------
Batch 1/64 loss: 0.2996625304222107
Batch 2/64 loss: 0.2978491187095642
Batch 3/64 loss: 0.30430877208709717
Batch 4/64 loss: 0.30521029233932495
Batch 5/64 loss: 0.3055471181869507
Batch 6/64 loss: 0.30248141288757324
Batch 7/64 loss: 0.299740731716156
Batch 8/64 loss: 0.30075740814208984
Batch 9/64 loss: 0.2948262691497803
Batch 10/64 loss: 0.2947426438331604
Batch 11/64 loss: 0.29983794689178467
Batch 12/64 loss: 0.3020240068435669
Batch 13/64 loss: 0.30375850200653076
Batch 14/64 loss: 0.30620795488357544
Batch 15/64 loss: 0.3051871061325073
Batch 16/64 loss: 0.303976833820343
Batch 17/64 loss: 0.3001757860183716
Batch 18/64 loss: 0.3060147762298584
Batch 19/64 loss: 0.29738569259643555
Batch 20/64 loss: 0.29707974195480347
Batch 21/64 loss: 0.299074649810791
Batch 22/64 loss: 0.29305028915405273
Batch 23/64 loss: 0.31075167655944824
Batch 24/64 loss: 0.29764461517333984
Batch 25/64 loss: 0.30551642179489136
Batch 26/64 loss: 0.29834669828414917
Batch 27/64 loss: 0.29573971033096313
Batch 28/64 loss: 0.3020099401473999
Batch 29/64 loss: 0.3068534731864929
Batch 30/64 loss: 0.3036028742790222
Batch 31/64 loss: 0.31223565340042114
Batch 32/64 loss: 0.3076721429824829
Batch 33/64 loss: 0.3059985041618347
Batch 34/64 loss: 0.3007683753967285
Batch 35/64 loss: 0.3043736219406128
Batch 36/64 loss: 0.31191229820251465
Batch 37/64 loss: 0.2971312403678894
Batch 38/64 loss: 0.3006587028503418
Batch 39/64 loss: 0.30740422010421753
Batch 40/64 loss: 0.29761815071105957
Batch 41/64 loss: 0.30040740966796875
Batch 42/64 loss: 0.30914306640625
Batch 43/64 loss: 0.30446094274520874
Batch 44/64 loss: 0.3109842538833618
Batch 45/64 loss: 0.2970707416534424
Batch 46/64 loss: 0.29664742946624756
Batch 47/64 loss: 0.3170925974845886
Batch 48/64 loss: 0.3089161515235901
Batch 49/64 loss: 0.297913134098053
Batch 50/64 loss: 0.3024669885635376
Batch 51/64 loss: 0.3093222975730896
Batch 52/64 loss: 0.29547119140625
Batch 53/64 loss: 0.29674404859542847
Batch 54/64 loss: 0.3096057176589966
Batch 55/64 loss: 0.3002828359603882
Batch 56/64 loss: 0.30154287815093994
Batch 57/64 loss: 0.3090634346008301
Batch 58/64 loss: 0.29997920989990234
Batch 59/64 loss: 0.3007042407989502
Batch 60/64 loss: 0.30485910177230835
Batch 61/64 loss: 0.30008769035339355
Batch 62/64 loss: 0.30438053607940674
Batch 63/64 loss: 0.300168514251709
Batch 64/64 loss: 0.3030455708503723
Epoch 445  Train loss: 0.3025841018732856  Val loss: 0.3330045096653024
Epoch 446
-------------------------------
Batch 1/64 loss: 0.3010115623474121
Batch 2/64 loss: 0.30245327949523926
Batch 3/64 loss: 0.3129572868347168
Batch 4/64 loss: 0.2959442138671875
Batch 5/64 loss: 0.3006458282470703
Batch 6/64 loss: 0.30492788553237915
Batch 7/64 loss: 0.3085336685180664
Batch 8/64 loss: 0.2995868921279907
Batch 9/64 loss: 0.30231165885925293
Batch 10/64 loss: 0.2968789339065552
Batch 11/64 loss: 0.29392027854919434
Batch 12/64 loss: 0.29593104124069214
Batch 13/64 loss: 0.3081173896789551
Batch 14/64 loss: 0.30227863788604736
Batch 15/64 loss: 0.3041454553604126
Batch 16/64 loss: 0.29163098335266113
Batch 17/64 loss: 0.30349767208099365
Batch 18/64 loss: 0.30130094289779663
Batch 19/64 loss: 0.3113718032836914
Batch 20/64 loss: 0.29958534240722656
Batch 21/64 loss: 0.2995584011077881
Batch 22/64 loss: 0.3004071116447449
Batch 23/64 loss: 0.3010568618774414
Batch 24/64 loss: 0.312311053276062
Batch 25/64 loss: 0.3009803295135498
Batch 26/64 loss: 0.29749584197998047
Batch 27/64 loss: 0.29810667037963867
Batch 28/64 loss: 0.2977036237716675
Batch 29/64 loss: 0.30693697929382324
Batch 30/64 loss: 0.2993319034576416
Batch 31/64 loss: 0.3028022050857544
Batch 32/64 loss: 0.3029567003250122
Batch 33/64 loss: 0.30861854553222656
Batch 34/64 loss: 0.2992144823074341
Batch 35/64 loss: 0.3094635605812073
Batch 36/64 loss: 0.2978990077972412
Batch 37/64 loss: 0.3021312952041626
Batch 38/64 loss: 0.3015052080154419
Batch 39/64 loss: 0.30363374948501587
Batch 40/64 loss: 0.29707372188568115
Batch 41/64 loss: 0.30235499143600464
Batch 42/64 loss: 0.3023644685745239
Batch 43/64 loss: 0.3035174608230591
Batch 44/64 loss: 0.29758673906326294
Batch 45/64 loss: 0.29727059602737427
Batch 46/64 loss: 0.29375600814819336
Batch 47/64 loss: 0.3055928945541382
Batch 48/64 loss: 0.30082666873931885
Batch 49/64 loss: 0.30244696140289307
Batch 50/64 loss: 0.3085871934890747
Batch 51/64 loss: 0.3031339645385742
Batch 52/64 loss: 0.29797065258026123
Batch 53/64 loss: 0.2982059717178345
Batch 54/64 loss: 0.30508261919021606
Batch 55/64 loss: 0.29784655570983887
Batch 56/64 loss: 0.3016016483306885
Batch 57/64 loss: 0.3159444332122803
Batch 58/64 loss: 0.31629037857055664
Batch 59/64 loss: 0.3149675130844116
Batch 60/64 loss: 0.30934107303619385
Batch 61/64 loss: 0.300134539604187
Batch 62/64 loss: 0.29688000679016113
Batch 63/64 loss: 0.29914987087249756
Batch 64/64 loss: 0.30774009227752686
Epoch 446  Train loss: 0.3023980594148823  Val loss: 0.33204966722075474
Epoch 447
-------------------------------
Batch 1/64 loss: 0.30222296714782715
Batch 2/64 loss: 0.30183303356170654
Batch 3/64 loss: 0.30599647760391235
Batch 4/64 loss: 0.2968880534172058
Batch 5/64 loss: 0.29845255613327026
Batch 6/64 loss: 0.30815380811691284
Batch 7/64 loss: 0.29810845851898193
Batch 8/64 loss: 0.3036315441131592
Batch 9/64 loss: 0.3071058392524719
Batch 10/64 loss: 0.312461793422699
Batch 11/64 loss: 0.3055136203765869
Batch 12/64 loss: 0.3038504719734192
Batch 13/64 loss: 0.3015638589859009
Batch 14/64 loss: 0.2975720167160034
Batch 15/64 loss: 0.3112744092941284
Batch 16/64 loss: 0.29708540439605713
Batch 17/64 loss: 0.3051321506500244
Batch 18/64 loss: 0.2963133454322815
Batch 19/64 loss: 0.29879117012023926
Batch 20/64 loss: 0.30474692583084106
Batch 21/64 loss: 0.3103495240211487
Batch 22/64 loss: 0.2956773042678833
Batch 23/64 loss: 0.299934983253479
Batch 24/64 loss: 0.3095470666885376
Batch 25/64 loss: 0.3052167296409607
Batch 26/64 loss: 0.29415637254714966
Batch 27/64 loss: 0.30477726459503174
Batch 28/64 loss: 0.30838334560394287
Batch 29/64 loss: 0.30344510078430176
Batch 30/64 loss: 0.3005339503288269
Batch 31/64 loss: 0.29850637912750244
Batch 32/64 loss: 0.30914193391799927
Batch 33/64 loss: 0.30932414531707764
Batch 34/64 loss: 0.30370402336120605
Batch 35/64 loss: 0.29781389236450195
Batch 36/64 loss: 0.3086268901824951
Batch 37/64 loss: 0.3052370548248291
Batch 38/64 loss: 0.2979811429977417
Batch 39/64 loss: 0.29801779985427856
Batch 40/64 loss: 0.297294020652771
Batch 41/64 loss: 0.30599868297576904
Batch 42/64 loss: 0.3066179156303406
Batch 43/64 loss: 0.29536598920822144
Batch 44/64 loss: 0.3079639673233032
Batch 45/64 loss: 0.30322062969207764
Batch 46/64 loss: 0.2973010540008545
Batch 47/64 loss: 0.29879361391067505
Batch 48/64 loss: 0.29603737592697144
Batch 49/64 loss: 0.3017241954803467
Batch 50/64 loss: 0.2976468801498413
Batch 51/64 loss: 0.30482542514801025
Batch 52/64 loss: 0.30560463666915894
Batch 53/64 loss: 0.307550311088562
Batch 54/64 loss: 0.30338943004608154
Batch 55/64 loss: 0.30199044942855835
Batch 56/64 loss: 0.2927395701408386
Batch 57/64 loss: 0.30678117275238037
Batch 58/64 loss: 0.2935330867767334
Batch 59/64 loss: 0.30694282054901123
Batch 60/64 loss: 0.2947819232940674
Batch 61/64 loss: 0.3008313775062561
Batch 62/64 loss: 0.3000723123550415
Batch 63/64 loss: 0.3070451021194458
Batch 64/64 loss: 0.3077431321144104
Epoch 447  Train loss: 0.3024616800102533  Val loss: 0.33239274151956094
Epoch 448
-------------------------------
Batch 1/64 loss: 0.3006523847579956
Batch 2/64 loss: 0.29132354259490967
Batch 3/64 loss: 0.30231624841690063
Batch 4/64 loss: 0.3084319829940796
Batch 5/64 loss: 0.30402547121047974
Batch 6/64 loss: 0.31847715377807617
Batch 7/64 loss: 0.3066713213920593
Batch 8/64 loss: 0.31060755252838135
Batch 9/64 loss: 0.30358874797821045
Batch 10/64 loss: 0.31366080045700073
Batch 11/64 loss: 0.30232542753219604
Batch 12/64 loss: 0.3037428855895996
Batch 13/64 loss: 0.31302815675735474
Batch 14/64 loss: 0.30071890354156494
Batch 15/64 loss: 0.3033151626586914
Batch 16/64 loss: 0.3017456531524658
Batch 17/64 loss: 0.3043210506439209
Batch 18/64 loss: 0.303472101688385
Batch 19/64 loss: 0.3037503957748413
Batch 20/64 loss: 0.3114999532699585
Batch 21/64 loss: 0.2972016930580139
Batch 22/64 loss: 0.30698323249816895
Batch 23/64 loss: 0.31151723861694336
Batch 24/64 loss: 0.2951638698577881
Batch 25/64 loss: 0.3095446825027466
Batch 26/64 loss: 0.3045957088470459
Batch 27/64 loss: 0.30486607551574707
Batch 28/64 loss: 0.31032514572143555
Batch 29/64 loss: 0.3004421591758728
Batch 30/64 loss: 0.29156625270843506
Batch 31/64 loss: 0.30473852157592773
Batch 32/64 loss: 0.3070768117904663
Batch 33/64 loss: 0.30851584672927856
Batch 34/64 loss: 0.31116968393325806
Batch 35/64 loss: 0.2860759496688843
Batch 36/64 loss: 0.2949303388595581
Batch 37/64 loss: 0.3005167245864868
Batch 38/64 loss: 0.3065747022628784
Batch 39/64 loss: 0.308097243309021
Batch 40/64 loss: 0.2903900146484375
Batch 41/64 loss: 0.3020976185798645
Batch 42/64 loss: 0.3108713626861572
Batch 43/64 loss: 0.2952893376350403
Batch 44/64 loss: 0.3021657466888428
Batch 45/64 loss: 0.3106546998023987
Batch 46/64 loss: 0.3056713938713074
Batch 47/64 loss: 0.295515239238739
Batch 48/64 loss: 0.30676281452178955
Batch 49/64 loss: 0.30551183223724365
Batch 50/64 loss: 0.29485273361206055
Batch 51/64 loss: 0.3013507127761841
Batch 52/64 loss: 0.3093736171722412
Batch 53/64 loss: 0.30358803272247314
Batch 54/64 loss: 0.3108283281326294
Batch 55/64 loss: 0.30457746982574463
Batch 56/64 loss: 0.2943885326385498
Batch 57/64 loss: 0.2933564782142639
Batch 58/64 loss: 0.301769495010376
Batch 59/64 loss: 0.3043767809867859
Batch 60/64 loss: 0.2924022674560547
Batch 61/64 loss: 0.299970805644989
Batch 62/64 loss: 0.3023790717124939
Batch 63/64 loss: 0.3016623258590698
Batch 64/64 loss: 0.3048670291900635
Epoch 448  Train loss: 0.3033103335137461  Val loss: 0.3327660994841061
Epoch 449
-------------------------------
Batch 1/64 loss: 0.31102919578552246
Batch 2/64 loss: 0.30182015895843506
Batch 3/64 loss: 0.30283451080322266
Batch 4/64 loss: 0.2915743589401245
Batch 5/64 loss: 0.30243170261383057
Batch 6/64 loss: 0.30364394187927246
Batch 7/64 loss: 0.30844128131866455
Batch 8/64 loss: 0.2993517518043518
Batch 9/64 loss: 0.319105863571167
Batch 10/64 loss: 0.30035173892974854
Batch 11/64 loss: 0.3033655881881714
Batch 12/64 loss: 0.3014826774597168
Batch 13/64 loss: 0.2978084683418274
Batch 14/64 loss: 0.29486751556396484
Batch 15/64 loss: 0.2959473133087158
Batch 16/64 loss: 0.30658888816833496
Batch 17/64 loss: 0.30447638034820557
Batch 18/64 loss: 0.29914331436157227
Batch 19/64 loss: 0.2998475432395935
Batch 20/64 loss: 0.29814594984054565
Batch 21/64 loss: 0.29993879795074463
Batch 22/64 loss: 0.3062658905982971
Batch 23/64 loss: 0.29860401153564453
Batch 24/64 loss: 0.307722806930542
Batch 25/64 loss: 0.30656659603118896
Batch 26/64 loss: 0.2991577386856079
Batch 27/64 loss: 0.28872036933898926
Batch 28/64 loss: 0.3026425838470459
Batch 29/64 loss: 0.3100425601005554
Batch 30/64 loss: 0.3006162643432617
Batch 31/64 loss: 0.3076053857803345
Batch 32/64 loss: 0.30532997846603394
Batch 33/64 loss: 0.3101283311843872
Batch 34/64 loss: 0.3017359972000122
Batch 35/64 loss: 0.30278658866882324
Batch 36/64 loss: 0.3144436478614807
Batch 37/64 loss: 0.29435181617736816
Batch 38/64 loss: 0.3031421899795532
Batch 39/64 loss: 0.31059539318084717
Batch 40/64 loss: 0.2972404360771179
Batch 41/64 loss: 0.30612826347351074
Batch 42/64 loss: 0.30174195766448975
Batch 43/64 loss: 0.30285966396331787
Batch 44/64 loss: 0.3054296374320984
Batch 45/64 loss: 0.29913055896759033
Batch 46/64 loss: 0.3004077076911926
Batch 47/64 loss: 0.3053867816925049
Batch 48/64 loss: 0.30384719371795654
Batch 49/64 loss: 0.3070826530456543
Batch 50/64 loss: 0.298370361328125
Batch 51/64 loss: 0.3018312454223633
Batch 52/64 loss: 0.29971301555633545
Batch 53/64 loss: 0.2995781898498535
Batch 54/64 loss: 0.29220765829086304
Batch 55/64 loss: 0.296921968460083
Batch 56/64 loss: 0.30432480573654175
Batch 57/64 loss: 0.3002668619155884
Batch 58/64 loss: 0.2995991110801697
Batch 59/64 loss: 0.3024744391441345
Batch 60/64 loss: 0.30138736963272095
Batch 61/64 loss: 0.30625253915786743
Batch 62/64 loss: 0.29967814683914185
Batch 63/64 loss: 0.3007015585899353
Batch 64/64 loss: 0.3008684515953064
Epoch 449  Train loss: 0.3022881341915505  Val loss: 0.3323124876546696
Epoch 450
-------------------------------
Batch 1/64 loss: 0.297771155834198
Batch 2/64 loss: 0.3052513599395752
Batch 3/64 loss: 0.3100283145904541
Batch 4/64 loss: 0.30642783641815186
Batch 5/64 loss: 0.29716384410858154
Batch 6/64 loss: 0.30923986434936523
Batch 7/64 loss: 0.2929658889770508
Batch 8/64 loss: 0.31286054849624634
Batch 9/64 loss: 0.2877326011657715
Batch 10/64 loss: 0.31413573026657104
Batch 11/64 loss: 0.29692864418029785
Batch 12/64 loss: 0.3041863441467285
Batch 13/64 loss: 0.3046180009841919
Batch 14/64 loss: 0.3062574863433838
Batch 15/64 loss: 0.3000138998031616
Batch 16/64 loss: 0.296905517578125
Batch 17/64 loss: 0.29687654972076416
Batch 18/64 loss: 0.2952549457550049
Batch 19/64 loss: 0.2962247133255005
Batch 20/64 loss: 0.3094055652618408
Batch 21/64 loss: 0.29713135957717896
Batch 22/64 loss: 0.30269062519073486
Batch 23/64 loss: 0.2990530729293823
Batch 24/64 loss: 0.3215787410736084
Batch 25/64 loss: 0.30408042669296265
Batch 26/64 loss: 0.2962297201156616
Batch 27/64 loss: 0.30840086936950684
Batch 28/64 loss: 0.3068404793739319
Batch 29/64 loss: 0.29369401931762695
Batch 30/64 loss: 0.29434752464294434
Batch 31/64 loss: 0.30592501163482666
Batch 32/64 loss: 0.3138743042945862
Batch 33/64 loss: 0.2985990047454834
Batch 34/64 loss: 0.309256911277771
Batch 35/64 loss: 0.304032564163208
Batch 36/64 loss: 0.31163209676742554
Batch 37/64 loss: 0.31191009283065796
Batch 38/64 loss: 0.298498272895813
Batch 39/64 loss: 0.3055306673049927
Batch 40/64 loss: 0.3011201024055481
Batch 41/64 loss: 0.29590821266174316
Batch 42/64 loss: 0.29778754711151123
Batch 43/64 loss: 0.2975228428840637
Batch 44/64 loss: 0.3047178387641907
Batch 45/64 loss: 0.3105670213699341
Batch 46/64 loss: 0.29892510175704956
Batch 47/64 loss: 0.30018842220306396
Batch 48/64 loss: 0.2959021329879761
Batch 49/64 loss: 0.3055037260055542
Batch 50/64 loss: 0.302951455116272
Batch 51/64 loss: 0.31787073612213135
Batch 52/64 loss: 0.3033152222633362
Batch 53/64 loss: 0.31599295139312744
Batch 54/64 loss: 0.3091202974319458
Batch 55/64 loss: 0.30101948976516724
Batch 56/64 loss: 0.3040693998336792
Batch 57/64 loss: 0.30137282609939575
Batch 58/64 loss: 0.3044614791870117
Batch 59/64 loss: 0.31407856941223145
Batch 60/64 loss: 0.3046913146972656
Batch 61/64 loss: 0.3010551929473877
Batch 62/64 loss: 0.3008970022201538
Batch 63/64 loss: 0.3064022660255432
Batch 64/64 loss: 0.2977942228317261
Epoch 450  Train loss: 0.3034092767565858  Val loss: 0.3324832617212407
Epoch 451
-------------------------------
Batch 1/64 loss: 0.299765408039093
Batch 2/64 loss: 0.30376362800598145
Batch 3/64 loss: 0.2996194362640381
Batch 4/64 loss: 0.30119162797927856
Batch 5/64 loss: 0.3051881790161133
Batch 6/64 loss: 0.29993677139282227
Batch 7/64 loss: 0.29826444387435913
Batch 8/64 loss: 0.30177175998687744
Batch 9/64 loss: 0.30665576457977295
Batch 10/64 loss: 0.3005845546722412
Batch 11/64 loss: 0.3138374090194702
Batch 12/64 loss: 0.30642592906951904
Batch 13/64 loss: 0.3022339344024658
Batch 14/64 loss: 0.2962779998779297
Batch 15/64 loss: 0.29879581928253174
Batch 16/64 loss: 0.2927919626235962
Batch 17/64 loss: 0.2932842969894409
Batch 18/64 loss: 0.29587888717651367
Batch 19/64 loss: 0.30202287435531616
Batch 20/64 loss: 0.29535436630249023
Batch 21/64 loss: 0.30649805068969727
Batch 22/64 loss: 0.3225281238555908
Batch 23/64 loss: 0.3026811480522156
Batch 24/64 loss: 0.2948184013366699
Batch 25/64 loss: 0.3072206974029541
Batch 26/64 loss: 0.2990037202835083
Batch 27/64 loss: 0.2956695556640625
Batch 28/64 loss: 0.2921323776245117
Batch 29/64 loss: 0.2968409061431885
Batch 30/64 loss: 0.29790031909942627
Batch 31/64 loss: 0.309525728225708
Batch 32/64 loss: 0.29894208908081055
Batch 33/64 loss: 0.2957397699356079
Batch 34/64 loss: 0.3009965419769287
Batch 35/64 loss: 0.2961909770965576
Batch 36/64 loss: 0.30637747049331665
Batch 37/64 loss: 0.3026086688041687
Batch 38/64 loss: 0.2974672317504883
Batch 39/64 loss: 0.29863089323043823
Batch 40/64 loss: 0.30258989334106445
Batch 41/64 loss: 0.3054007887840271
Batch 42/64 loss: 0.3039078712463379
Batch 43/64 loss: 0.304889440536499
Batch 44/64 loss: 0.30597007274627686
Batch 45/64 loss: 0.29365551471710205
Batch 46/64 loss: 0.3122631311416626
Batch 47/64 loss: 0.30630767345428467
Batch 48/64 loss: 0.3093428611755371
Batch 49/64 loss: 0.2895352840423584
Batch 50/64 loss: 0.3033275604248047
Batch 51/64 loss: 0.3048217296600342
Batch 52/64 loss: 0.3008338212966919
Batch 53/64 loss: 0.30213767290115356
Batch 54/64 loss: 0.3149634599685669
Batch 55/64 loss: 0.31705546379089355
Batch 56/64 loss: 0.30625855922698975
Batch 57/64 loss: 0.30299389362335205
Batch 58/64 loss: 0.29759061336517334
Batch 59/64 loss: 0.3099638819694519
Batch 60/64 loss: 0.30062735080718994
Batch 61/64 loss: 0.3089268207550049
Batch 62/64 loss: 0.3125416040420532
Batch 63/64 loss: 0.30614370107650757
Batch 64/64 loss: 0.3104408383369446
Epoch 451  Train loss: 0.30259289437649295  Val loss: 0.3332970879741551
Epoch 452
-------------------------------
Batch 1/64 loss: 0.3026941418647766
Batch 2/64 loss: 0.30758899450302124
Batch 3/64 loss: 0.3011946678161621
Batch 4/64 loss: 0.305991530418396
Batch 5/64 loss: 0.2960927486419678
Batch 6/64 loss: 0.3101232051849365
Batch 7/64 loss: 0.30247223377227783
Batch 8/64 loss: 0.3023238182067871
Batch 9/64 loss: 0.3071255683898926
Batch 10/64 loss: 0.28749674558639526
Batch 11/64 loss: 0.3063586354255676
Batch 12/64 loss: 0.30916494131088257
Batch 13/64 loss: 0.3145977854728699
Batch 14/64 loss: 0.29943913221359253
Batch 15/64 loss: 0.2937280535697937
Batch 16/64 loss: 0.3037340044975281
Batch 17/64 loss: 0.3110557794570923
Batch 18/64 loss: 0.30433034896850586
Batch 19/64 loss: 0.30071157217025757
Batch 20/64 loss: 0.3033386468887329
Batch 21/64 loss: 0.30181682109832764
Batch 22/64 loss: 0.2964518070220947
Batch 23/64 loss: 0.31367385387420654
Batch 24/64 loss: 0.3050811290740967
Batch 25/64 loss: 0.30201631784439087
Batch 26/64 loss: 0.3029062747955322
Batch 27/64 loss: 0.30911922454833984
Batch 28/64 loss: 0.3039248585700989
Batch 29/64 loss: 0.3060571551322937
Batch 30/64 loss: 0.30285394191741943
Batch 31/64 loss: 0.2951682209968567
Batch 32/64 loss: 0.3036462664604187
Batch 33/64 loss: 0.2987011671066284
Batch 34/64 loss: 0.297229528427124
Batch 35/64 loss: 0.29947996139526367
Batch 36/64 loss: 0.302074670791626
Batch 37/64 loss: 0.30212920904159546
Batch 38/64 loss: 0.30140769481658936
Batch 39/64 loss: 0.30319786071777344
Batch 40/64 loss: 0.29666662216186523
Batch 41/64 loss: 0.3102625012397766
Batch 42/64 loss: 0.315446138381958
Batch 43/64 loss: 0.30541616678237915
Batch 44/64 loss: 0.3025832176208496
Batch 45/64 loss: 0.2910882234573364
Batch 46/64 loss: 0.2997802495956421
Batch 47/64 loss: 0.30535048246383667
Batch 48/64 loss: 0.30341875553131104
Batch 49/64 loss: 0.30078375339508057
Batch 50/64 loss: 0.2888582944869995
Batch 51/64 loss: 0.305059015750885
Batch 52/64 loss: 0.29695719480514526
Batch 53/64 loss: 0.30163681507110596
Batch 54/64 loss: 0.3026443123817444
Batch 55/64 loss: 0.3086283206939697
Batch 56/64 loss: 0.3016117811203003
Batch 57/64 loss: 0.3093700408935547
Batch 58/64 loss: 0.3003619909286499
Batch 59/64 loss: 0.30077505111694336
Batch 60/64 loss: 0.3002716898918152
Batch 61/64 loss: 0.29589974880218506
Batch 62/64 loss: 0.30061113834381104
Batch 63/64 loss: 0.30921077728271484
Batch 64/64 loss: 0.29789650440216064
Epoch 452  Train loss: 0.30262922632927985  Val loss: 0.3320089394284278
Epoch 453
-------------------------------
Batch 1/64 loss: 0.3099818229675293
Batch 2/64 loss: 0.2967792749404907
Batch 3/64 loss: 0.306208074092865
Batch 4/64 loss: 0.30236518383026123
Batch 5/64 loss: 0.299770712852478
Batch 6/64 loss: 0.30483371019363403
Batch 7/64 loss: 0.3123044967651367
Batch 8/64 loss: 0.3044869899749756
Batch 9/64 loss: 0.29513561725616455
Batch 10/64 loss: 0.29496562480926514
Batch 11/64 loss: 0.3044501543045044
Batch 12/64 loss: 0.30183517932891846
Batch 13/64 loss: 0.2951453924179077
Batch 14/64 loss: 0.2969929575920105
Batch 15/64 loss: 0.30542242527008057
Batch 16/64 loss: 0.31286466121673584
Batch 17/64 loss: 0.30855458974838257
Batch 18/64 loss: 0.300952672958374
Batch 19/64 loss: 0.3061959743499756
Batch 20/64 loss: 0.306817889213562
Batch 21/64 loss: 0.30561602115631104
Batch 22/64 loss: 0.29390227794647217
Batch 23/64 loss: 0.30957627296447754
Batch 24/64 loss: 0.30304574966430664
Batch 25/64 loss: 0.29894983768463135
Batch 26/64 loss: 0.302390992641449
Batch 27/64 loss: 0.2948038578033447
Batch 28/64 loss: 0.2992779612541199
Batch 29/64 loss: 0.30357909202575684
Batch 30/64 loss: 0.3022245168685913
Batch 31/64 loss: 0.30393797159194946
Batch 32/64 loss: 0.3012149930000305
Batch 33/64 loss: 0.30870115756988525
Batch 34/64 loss: 0.3066539764404297
Batch 35/64 loss: 0.3066015839576721
Batch 36/64 loss: 0.3074239492416382
Batch 37/64 loss: 0.3048219084739685
Batch 38/64 loss: 0.3000270128250122
Batch 39/64 loss: 0.29873090982437134
Batch 40/64 loss: 0.29236292839050293
Batch 41/64 loss: 0.2925471067428589
Batch 42/64 loss: 0.2951069474220276
Batch 43/64 loss: 0.30707287788391113
Batch 44/64 loss: 0.2971346378326416
Batch 45/64 loss: 0.30302339792251587
Batch 46/64 loss: 0.3071763515472412
Batch 47/64 loss: 0.3016623854637146
Batch 48/64 loss: 0.29829269647598267
Batch 49/64 loss: 0.30900847911834717
Batch 50/64 loss: 0.30071312189102173
Batch 51/64 loss: 0.3029545545578003
Batch 52/64 loss: 0.30619698762893677
Batch 53/64 loss: 0.30612337589263916
Batch 54/64 loss: 0.307633638381958
Batch 55/64 loss: 0.3046538233757019
Batch 56/64 loss: 0.31058192253112793
Batch 57/64 loss: 0.29917412996292114
Batch 58/64 loss: 0.29973721504211426
Batch 59/64 loss: 0.2975466251373291
Batch 60/64 loss: 0.2984962463378906
Batch 61/64 loss: 0.3030891418457031
Batch 62/64 loss: 0.3011782169342041
Batch 63/64 loss: 0.31179410219192505
Batch 64/64 loss: 0.306784987449646
Epoch 453  Train loss: 0.3027591074214262  Val loss: 0.3329558485152386
Epoch 454
-------------------------------
Batch 1/64 loss: 0.3049963712692261
Batch 2/64 loss: 0.29957902431488037
Batch 3/64 loss: 0.30958324670791626
Batch 4/64 loss: 0.30894315242767334
Batch 5/64 loss: 0.29121434688568115
Batch 6/64 loss: 0.29805266857147217
Batch 7/64 loss: 0.2958076000213623
Batch 8/64 loss: 0.2987167239189148
Batch 9/64 loss: 0.3001739978790283
Batch 10/64 loss: 0.30642879009246826
Batch 11/64 loss: 0.31538575887680054
Batch 12/64 loss: 0.3060382604598999
Batch 13/64 loss: 0.30916929244995117
Batch 14/64 loss: 0.29903292655944824
Batch 15/64 loss: 0.3099878430366516
Batch 16/64 loss: 0.3061019778251648
Batch 17/64 loss: 0.301517128944397
Batch 18/64 loss: 0.30405426025390625
Batch 19/64 loss: 0.30484503507614136
Batch 20/64 loss: 0.30030357837677
Batch 21/64 loss: 0.28960394859313965
Batch 22/64 loss: 0.29665178060531616
Batch 23/64 loss: 0.3064725399017334
Batch 24/64 loss: 0.2986065149307251
Batch 25/64 loss: 0.30820465087890625
Batch 26/64 loss: 0.30387789011001587
Batch 27/64 loss: 0.30630290508270264
Batch 28/64 loss: 0.2945363521575928
Batch 29/64 loss: 0.290857195854187
Batch 30/64 loss: 0.2987744212150574
Batch 31/64 loss: 0.2972755432128906
Batch 32/64 loss: 0.3085100054740906
Batch 33/64 loss: 0.30343472957611084
Batch 34/64 loss: 0.2984316945075989
Batch 35/64 loss: 0.31018710136413574
Batch 36/64 loss: 0.3160414695739746
Batch 37/64 loss: 0.31092530488967896
Batch 38/64 loss: 0.3073028326034546
Batch 39/64 loss: 0.30712294578552246
Batch 40/64 loss: 0.3052831292152405
Batch 41/64 loss: 0.3192538619041443
Batch 42/64 loss: 0.30395305156707764
Batch 43/64 loss: 0.3047834634780884
Batch 44/64 loss: 0.30199503898620605
Batch 45/64 loss: 0.3009014129638672
Batch 46/64 loss: 0.2995944023132324
Batch 47/64 loss: 0.3058359622955322
Batch 48/64 loss: 0.3124518394470215
Batch 49/64 loss: 0.29493993520736694
Batch 50/64 loss: 0.3031798005104065
Batch 51/64 loss: 0.29917025566101074
Batch 52/64 loss: 0.30168044567108154
Batch 53/64 loss: 0.2997225522994995
Batch 54/64 loss: 0.29540860652923584
Batch 55/64 loss: 0.2999532222747803
Batch 56/64 loss: 0.3008955717086792
Batch 57/64 loss: 0.29335570335388184
Batch 58/64 loss: 0.3083770275115967
Batch 59/64 loss: 0.2959628105163574
Batch 60/64 loss: 0.3114044666290283
Batch 61/64 loss: 0.30081963539123535
Batch 62/64 loss: 0.3008188009262085
Batch 63/64 loss: 0.3000272512435913
Batch 64/64 loss: 0.29232555627822876
Epoch 454  Train loss: 0.3027774780404334  Val loss: 0.33282416792669656
Epoch 455
-------------------------------
Batch 1/64 loss: 0.30745935440063477
Batch 2/64 loss: 0.3061085343360901
Batch 3/64 loss: 0.29266607761383057
Batch 4/64 loss: 0.297979474067688
Batch 5/64 loss: 0.30739283561706543
Batch 6/64 loss: 0.30669569969177246
Batch 7/64 loss: 0.3030998110771179
Batch 8/64 loss: 0.31293344497680664
Batch 9/64 loss: 0.30679047107696533
Batch 10/64 loss: 0.2982807159423828
Batch 11/64 loss: 0.30494892597198486
Batch 12/64 loss: 0.2990155816078186
Batch 13/64 loss: 0.3063575029373169
Batch 14/64 loss: 0.30014145374298096
Batch 15/64 loss: 0.3014165163040161
Batch 16/64 loss: 0.29489290714263916
Batch 17/64 loss: 0.2969522476196289
Batch 18/64 loss: 0.2959182858467102
Batch 19/64 loss: 0.3047037720680237
Batch 20/64 loss: 0.3036853075027466
Batch 21/64 loss: 0.3036930561065674
Batch 22/64 loss: 0.3043099641799927
Batch 23/64 loss: 0.3152318000793457
Batch 24/64 loss: 0.3044952154159546
Batch 25/64 loss: 0.2999396324157715
Batch 26/64 loss: 0.3032117486000061
Batch 27/64 loss: 0.3043118715286255
Batch 28/64 loss: 0.30013811588287354
Batch 29/64 loss: 0.31397736072540283
Batch 30/64 loss: 0.30439186096191406
Batch 31/64 loss: 0.3033660054206848
Batch 32/64 loss: 0.3105158805847168
Batch 33/64 loss: 0.30322718620300293
Batch 34/64 loss: 0.2923710346221924
Batch 35/64 loss: 0.30176687240600586
Batch 36/64 loss: 0.2964383363723755
Batch 37/64 loss: 0.2953486442565918
Batch 38/64 loss: 0.29685699939727783
Batch 39/64 loss: 0.3117666244506836
Batch 40/64 loss: 0.30523133277893066
Batch 41/64 loss: 0.30522823333740234
Batch 42/64 loss: 0.30124688148498535
Batch 43/64 loss: 0.3039029836654663
Batch 44/64 loss: 0.3027610778808594
Batch 45/64 loss: 0.304640531539917
Batch 46/64 loss: 0.28816092014312744
Batch 47/64 loss: 0.31275516748428345
Batch 48/64 loss: 0.2997850179672241
Batch 49/64 loss: 0.3000168204307556
Batch 50/64 loss: 0.29876500368118286
Batch 51/64 loss: 0.2977769374847412
Batch 52/64 loss: 0.30492913722991943
Batch 53/64 loss: 0.30651772022247314
Batch 54/64 loss: 0.29975879192352295
Batch 55/64 loss: 0.2995174527168274
Batch 56/64 loss: 0.3089641332626343
Batch 57/64 loss: 0.3030861020088196
Batch 58/64 loss: 0.2903972864151001
Batch 59/64 loss: 0.30598878860473633
Batch 60/64 loss: 0.29376792907714844
Batch 61/64 loss: 0.30303704738616943
Batch 62/64 loss: 0.3013683557510376
Batch 63/64 loss: 0.2988972067832947
Batch 64/64 loss: 0.30966758728027344
Epoch 455  Train loss: 0.3024556655509799  Val loss: 0.3326460510185084
Epoch 456
-------------------------------
Batch 1/64 loss: 0.2922878861427307
Batch 2/64 loss: 0.30264371633529663
Batch 3/64 loss: 0.2971329092979431
Batch 4/64 loss: 0.29012560844421387
Batch 5/64 loss: 0.2962360382080078
Batch 6/64 loss: 0.2884814143180847
Batch 7/64 loss: 0.3046363592147827
Batch 8/64 loss: 0.30616796016693115
Batch 9/64 loss: 0.30626988410949707
Batch 10/64 loss: 0.30115067958831787
Batch 11/64 loss: 0.315032958984375
Batch 12/64 loss: 0.3007778525352478
Batch 13/64 loss: 0.2961544990539551
Batch 14/64 loss: 0.29394400119781494
Batch 15/64 loss: 0.30452609062194824
Batch 16/64 loss: 0.3013498783111572
Batch 17/64 loss: 0.303261935710907
Batch 18/64 loss: 0.29842519760131836
Batch 19/64 loss: 0.3012831211090088
Batch 20/64 loss: 0.3030150532722473
Batch 21/64 loss: 0.29845964908599854
Batch 22/64 loss: 0.30440545082092285
Batch 23/64 loss: 0.3013744354248047
Batch 24/64 loss: 0.3026762008666992
Batch 25/64 loss: 0.2974449396133423
Batch 26/64 loss: 0.3058133125305176
Batch 27/64 loss: 0.30631256103515625
Batch 28/64 loss: 0.3051173686981201
Batch 29/64 loss: 0.2944968342781067
Batch 30/64 loss: 0.3151557445526123
Batch 31/64 loss: 0.30177509784698486
Batch 32/64 loss: 0.3051224946975708
Batch 33/64 loss: 0.3039662837982178
Batch 34/64 loss: 0.29878807067871094
Batch 35/64 loss: 0.3031685948371887
Batch 36/64 loss: 0.2950315475463867
Batch 37/64 loss: 0.2939556837081909
Batch 38/64 loss: 0.3065226078033447
Batch 39/64 loss: 0.3009793758392334
Batch 40/64 loss: 0.3044039011001587
Batch 41/64 loss: 0.29888904094696045
Batch 42/64 loss: 0.29588067531585693
Batch 43/64 loss: 0.29470956325531006
Batch 44/64 loss: 0.30058586597442627
Batch 45/64 loss: 0.30929267406463623
Batch 46/64 loss: 0.2970634698867798
Batch 47/64 loss: 0.30584096908569336
Batch 48/64 loss: 0.31002098321914673
Batch 49/64 loss: 0.29818129539489746
Batch 50/64 loss: 0.2933264970779419
Batch 51/64 loss: 0.30356597900390625
Batch 52/64 loss: 0.2983142137527466
Batch 53/64 loss: 0.30079513788223267
Batch 54/64 loss: 0.3044470548629761
Batch 55/64 loss: 0.309009850025177
Batch 56/64 loss: 0.29611778259277344
Batch 57/64 loss: 0.310327410697937
Batch 58/64 loss: 0.31234920024871826
Batch 59/64 loss: 0.29958105087280273
Batch 60/64 loss: 0.30444347858428955
Batch 61/64 loss: 0.30787932872772217
Batch 62/64 loss: 0.3005841374397278
Batch 63/64 loss: 0.3012537956237793
Batch 64/64 loss: 0.30581533908843994
Epoch 456  Train loss: 0.3016422612994325  Val loss: 0.3328524393724002
Epoch 457
-------------------------------
Batch 1/64 loss: 0.2967708110809326
Batch 2/64 loss: 0.29558348655700684
Batch 3/64 loss: 0.295745849609375
Batch 4/64 loss: 0.29566311836242676
Batch 5/64 loss: 0.2986356019973755
Batch 6/64 loss: 0.305824875831604
Batch 7/64 loss: 0.301378071308136
Batch 8/64 loss: 0.29911500215530396
Batch 9/64 loss: 0.29398012161254883
Batch 10/64 loss: 0.29689788818359375
Batch 11/64 loss: 0.29557448625564575
Batch 12/64 loss: 0.2929481267929077
Batch 13/64 loss: 0.3056293725967407
Batch 14/64 loss: 0.29408133029937744
Batch 15/64 loss: 0.2931070327758789
Batch 16/64 loss: 0.30241405963897705
Batch 17/64 loss: 0.30399245023727417
Batch 18/64 loss: 0.30471909046173096
Batch 19/64 loss: 0.2963632345199585
Batch 20/64 loss: 0.3080183267593384
Batch 21/64 loss: 0.29744696617126465
Batch 22/64 loss: 0.3035409450531006
Batch 23/64 loss: 0.30082887411117554
Batch 24/64 loss: 0.30258214473724365
Batch 25/64 loss: 0.30121946334838867
Batch 26/64 loss: 0.30045628547668457
Batch 27/64 loss: 0.3100197911262512
Batch 28/64 loss: 0.3132929801940918
Batch 29/64 loss: 0.3078181743621826
Batch 30/64 loss: 0.3094680905342102
Batch 31/64 loss: 0.30605649948120117
Batch 32/64 loss: 0.2955551743507385
Batch 33/64 loss: 0.30687832832336426
Batch 34/64 loss: 0.2971467971801758
Batch 35/64 loss: 0.30606651306152344
Batch 36/64 loss: 0.30731189250946045
Batch 37/64 loss: 0.30338096618652344
Batch 38/64 loss: 0.3100407123565674
Batch 39/64 loss: 0.31722551584243774
Batch 40/64 loss: 0.30077409744262695
Batch 41/64 loss: 0.29371511936187744
Batch 42/64 loss: 0.30575263500213623
Batch 43/64 loss: 0.3054538369178772
Batch 44/64 loss: 0.28851473331451416
Batch 45/64 loss: 0.2994980812072754
Batch 46/64 loss: 0.2970895767211914
Batch 47/64 loss: 0.3031867742538452
Batch 48/64 loss: 0.30387192964553833
Batch 49/64 loss: 0.3002793788909912
Batch 50/64 loss: 0.3010716438293457
Batch 51/64 loss: 0.2975538372993469
Batch 52/64 loss: 0.2976799011230469
Batch 53/64 loss: 0.3017483949661255
Batch 54/64 loss: 0.2988593578338623
Batch 55/64 loss: 0.3099348545074463
Batch 56/64 loss: 0.30679190158843994
Batch 57/64 loss: 0.2937500476837158
Batch 58/64 loss: 0.3033345937728882
Batch 59/64 loss: 0.3107866644859314
Batch 60/64 loss: 0.30383485555648804
Batch 61/64 loss: 0.306205153465271
Batch 62/64 loss: 0.3055546283721924
Batch 63/64 loss: 0.31188881397247314
Batch 64/64 loss: 0.2979006767272949
Epoch 457  Train loss: 0.30185623168945314  Val loss: 0.33387657047547015
Epoch 458
-------------------------------
Batch 1/64 loss: 0.3024420738220215
Batch 2/64 loss: 0.3004601001739502
Batch 3/64 loss: 0.29909348487854004
Batch 4/64 loss: 0.302146852016449
Batch 5/64 loss: 0.29631316661834717
Batch 6/64 loss: 0.29877138137817383
Batch 7/64 loss: 0.30707991123199463
Batch 8/64 loss: 0.30021101236343384
Batch 9/64 loss: 0.29272931814193726
Batch 10/64 loss: 0.3000849485397339
Batch 11/64 loss: 0.30362367630004883
Batch 12/64 loss: 0.29402363300323486
Batch 13/64 loss: 0.3045766353607178
Batch 14/64 loss: 0.29236316680908203
Batch 15/64 loss: 0.3140319585800171
Batch 16/64 loss: 0.3004343509674072
Batch 17/64 loss: 0.30216503143310547
Batch 18/64 loss: 0.31157851219177246
Batch 19/64 loss: 0.29229700565338135
Batch 20/64 loss: 0.2978214621543884
Batch 21/64 loss: 0.30301666259765625
Batch 22/64 loss: 0.31205809116363525
Batch 23/64 loss: 0.30163657665252686
Batch 24/64 loss: 0.2947980761528015
Batch 25/64 loss: 0.30261826515197754
Batch 26/64 loss: 0.2935411334037781
Batch 27/64 loss: 0.29955601692199707
Batch 28/64 loss: 0.3016786575317383
Batch 29/64 loss: 0.30078351497650146
Batch 30/64 loss: 0.3039723038673401
Batch 31/64 loss: 0.29726648330688477
Batch 32/64 loss: 0.29773443937301636
Batch 33/64 loss: 0.3072015047073364
Batch 34/64 loss: 0.2987273931503296
Batch 35/64 loss: 0.29950499534606934
Batch 36/64 loss: 0.30528509616851807
Batch 37/64 loss: 0.30370938777923584
Batch 38/64 loss: 0.3109895586967468
Batch 39/64 loss: 0.2993117570877075
Batch 40/64 loss: 0.30125606060028076
Batch 41/64 loss: 0.3039667010307312
Batch 42/64 loss: 0.3036593198776245
Batch 43/64 loss: 0.3080439567565918
Batch 44/64 loss: 0.30388760566711426
Batch 45/64 loss: 0.30420172214508057
Batch 46/64 loss: 0.3028566241264343
Batch 47/64 loss: 0.302670955657959
Batch 48/64 loss: 0.29281002283096313
Batch 49/64 loss: 0.306174635887146
Batch 50/64 loss: 0.300447940826416
Batch 51/64 loss: 0.3095535635948181
Batch 52/64 loss: 0.3162307143211365
Batch 53/64 loss: 0.3164045214653015
Batch 54/64 loss: 0.2991204857826233
Batch 55/64 loss: 0.3076561689376831
Batch 56/64 loss: 0.2942788600921631
Batch 57/64 loss: 0.3094252943992615
Batch 58/64 loss: 0.3013433814048767
Batch 59/64 loss: 0.30152302980422974
Batch 60/64 loss: 0.2990686893463135
Batch 61/64 loss: 0.31008243560791016
Batch 62/64 loss: 0.29264122247695923
Batch 63/64 loss: 0.2956644296646118
Batch 64/64 loss: 0.30501437187194824
Epoch 458  Train loss: 0.3020763406566545  Val loss: 0.332131179337649
Epoch 459
-------------------------------
Batch 1/64 loss: 0.2948507070541382
Batch 2/64 loss: 0.3057764172554016
Batch 3/64 loss: 0.2936531901359558
Batch 4/64 loss: 0.29307007789611816
Batch 5/64 loss: 0.29432880878448486
Batch 6/64 loss: 0.31048721075057983
Batch 7/64 loss: 0.297322154045105
Batch 8/64 loss: 0.3067045211791992
Batch 9/64 loss: 0.30381935834884644
Batch 10/64 loss: 0.30216991901397705
Batch 11/64 loss: 0.30554038286209106
Batch 12/64 loss: 0.30039191246032715
Batch 13/64 loss: 0.29993826150894165
Batch 14/64 loss: 0.2997296452522278
Batch 15/64 loss: 0.2921789288520813
Batch 16/64 loss: 0.3004493713378906
Batch 17/64 loss: 0.3093533515930176
Batch 18/64 loss: 0.29995596408843994
Batch 19/64 loss: 0.2988213896751404
Batch 20/64 loss: 0.3003079891204834
Batch 21/64 loss: 0.300723671913147
Batch 22/64 loss: 0.3057091236114502
Batch 23/64 loss: 0.30293500423431396
Batch 24/64 loss: 0.309920072555542
Batch 25/64 loss: 0.2920948266983032
Batch 26/64 loss: 0.29793745279312134
Batch 27/64 loss: 0.3016310930252075
Batch 28/64 loss: 0.3143714666366577
Batch 29/64 loss: 0.30205583572387695
Batch 30/64 loss: 0.31440234184265137
Batch 31/64 loss: 0.3004080057144165
Batch 32/64 loss: 0.30140846967697144
Batch 33/64 loss: 0.29521644115448
Batch 34/64 loss: 0.30315887928009033
Batch 35/64 loss: 0.29358381032943726
Batch 36/64 loss: 0.3043191432952881
Batch 37/64 loss: 0.2944173812866211
Batch 38/64 loss: 0.2955136299133301
Batch 39/64 loss: 0.3091577887535095
Batch 40/64 loss: 0.30582934617996216
Batch 41/64 loss: 0.29988062381744385
Batch 42/64 loss: 0.2973814606666565
Batch 43/64 loss: 0.29640889167785645
Batch 44/64 loss: 0.2980015277862549
Batch 45/64 loss: 0.30293774604797363
Batch 46/64 loss: 0.29416370391845703
Batch 47/64 loss: 0.29328012466430664
Batch 48/64 loss: 0.29680150747299194
Batch 49/64 loss: 0.3080846071243286
Batch 50/64 loss: 0.30241817235946655
Batch 51/64 loss: 0.3043196201324463
Batch 52/64 loss: 0.3070791959762573
Batch 53/64 loss: 0.30153119564056396
Batch 54/64 loss: 0.30650806427001953
Batch 55/64 loss: 0.3069632649421692
Batch 56/64 loss: 0.3040844798088074
Batch 57/64 loss: 0.3058377504348755
Batch 58/64 loss: 0.30118829011917114
Batch 59/64 loss: 0.30216288566589355
Batch 60/64 loss: 0.3070020079612732
Batch 61/64 loss: 0.30158400535583496
Batch 62/64 loss: 0.3081321716308594
Batch 63/64 loss: 0.2983260154724121
Batch 64/64 loss: 0.30044203996658325
Epoch 459  Train loss: 0.30153807354908363  Val loss: 0.3320834694039781
Epoch 460
-------------------------------
Batch 1/64 loss: 0.29104387760162354
Batch 2/64 loss: 0.29778528213500977
Batch 3/64 loss: 0.30608487129211426
Batch 4/64 loss: 0.31380581855773926
Batch 5/64 loss: 0.3027306795120239
Batch 6/64 loss: 0.3016544580459595
Batch 7/64 loss: 0.3030624985694885
Batch 8/64 loss: 0.3037832975387573
Batch 9/64 loss: 0.2995463013648987
Batch 10/64 loss: 0.3000461459159851
Batch 11/64 loss: 0.30291903018951416
Batch 12/64 loss: 0.30574148893356323
Batch 13/64 loss: 0.30043327808380127
Batch 14/64 loss: 0.2867603302001953
Batch 15/64 loss: 0.3112139105796814
Batch 16/64 loss: 0.3060199022293091
Batch 17/64 loss: 0.3115302324295044
Batch 18/64 loss: 0.29490548372268677
Batch 19/64 loss: 0.3161134719848633
Batch 20/64 loss: 0.3016507029533386
Batch 21/64 loss: 0.29812461137771606
Batch 22/64 loss: 0.30369025468826294
Batch 23/64 loss: 0.29843246936798096
Batch 24/64 loss: 0.30607062578201294
Batch 25/64 loss: 0.30032920837402344
Batch 26/64 loss: 0.30547988414764404
Batch 27/64 loss: 0.30708855390548706
Batch 28/64 loss: 0.2888683080673218
Batch 29/64 loss: 0.30236512422561646
Batch 30/64 loss: 0.2950078248977661
Batch 31/64 loss: 0.3022364377975464
Batch 32/64 loss: 0.2975194454193115
Batch 33/64 loss: 0.30233311653137207
Batch 34/64 loss: 0.29206907749176025
Batch 35/64 loss: 0.31471550464630127
Batch 36/64 loss: 0.2928882837295532
Batch 37/64 loss: 0.3012477159500122
Batch 38/64 loss: 0.29625219106674194
Batch 39/64 loss: 0.2983444929122925
Batch 40/64 loss: 0.30885016918182373
Batch 41/64 loss: 0.30589962005615234
Batch 42/64 loss: 0.30528056621551514
Batch 43/64 loss: 0.29732275009155273
Batch 44/64 loss: 0.3046063184738159
Batch 45/64 loss: 0.3024559020996094
Batch 46/64 loss: 0.29522955417633057
Batch 47/64 loss: 0.30539458990097046
Batch 48/64 loss: 0.29946762323379517
Batch 49/64 loss: 0.297835111618042
Batch 50/64 loss: 0.29693377017974854
Batch 51/64 loss: 0.3001302480697632
Batch 52/64 loss: 0.2982800006866455
Batch 53/64 loss: 0.30821728706359863
Batch 54/64 loss: 0.3035329580307007
Batch 55/64 loss: 0.3057675361633301
Batch 56/64 loss: 0.2961939573287964
Batch 57/64 loss: 0.2970079183578491
Batch 58/64 loss: 0.30246371030807495
Batch 59/64 loss: 0.3052721619606018
Batch 60/64 loss: 0.30612242221832275
Batch 61/64 loss: 0.2939668893814087
Batch 62/64 loss: 0.2938636541366577
Batch 63/64 loss: 0.29764795303344727
Batch 64/64 loss: 0.3063316345214844
Epoch 460  Train loss: 0.3014491857266894  Val loss: 0.3326247817871906
Epoch 461
-------------------------------
Batch 1/64 loss: 0.30243492126464844
Batch 2/64 loss: 0.3085157871246338
Batch 3/64 loss: 0.2948492765426636
Batch 4/64 loss: 0.3008577823638916
Batch 5/64 loss: 0.30560195446014404
Batch 6/64 loss: 0.29637932777404785
Batch 7/64 loss: 0.29873621463775635
Batch 8/64 loss: 0.3044614791870117
Batch 9/64 loss: 0.3046731948852539
Batch 10/64 loss: 0.3053539991378784
Batch 11/64 loss: 0.30458545684814453
Batch 12/64 loss: 0.299726665019989
Batch 13/64 loss: 0.2981376647949219
Batch 14/64 loss: 0.3078986406326294
Batch 15/64 loss: 0.2979874610900879
Batch 16/64 loss: 0.2965072989463806
Batch 17/64 loss: 0.2929673194885254
Batch 18/64 loss: 0.3012033700942993
Batch 19/64 loss: 0.29722678661346436
Batch 20/64 loss: 0.3018774390220642
Batch 21/64 loss: 0.29907703399658203
Batch 22/64 loss: 0.2952633500099182
Batch 23/64 loss: 0.30541884899139404
Batch 24/64 loss: 0.2969505786895752
Batch 25/64 loss: 0.29393935203552246
Batch 26/64 loss: 0.3085663318634033
Batch 27/64 loss: 0.30508244037628174
Batch 28/64 loss: 0.29793083667755127
Batch 29/64 loss: 0.2864797115325928
Batch 30/64 loss: 0.30665314197540283
Batch 31/64 loss: 0.3131636381149292
Batch 32/64 loss: 0.30530381202697754
Batch 33/64 loss: 0.31091129779815674
Batch 34/64 loss: 0.3097165822982788
Batch 35/64 loss: 0.30169177055358887
Batch 36/64 loss: 0.3127162456512451
Batch 37/64 loss: 0.3030969500541687
Batch 38/64 loss: 0.30240076780319214
Batch 39/64 loss: 0.3119906783103943
Batch 40/64 loss: 0.29393458366394043
Batch 41/64 loss: 0.30233263969421387
Batch 42/64 loss: 0.3019809126853943
Batch 43/64 loss: 0.30219292640686035
Batch 44/64 loss: 0.30362367630004883
Batch 45/64 loss: 0.30496251583099365
Batch 46/64 loss: 0.3084561824798584
Batch 47/64 loss: 0.303411602973938
Batch 48/64 loss: 0.3056907057762146
Batch 49/64 loss: 0.3002278208732605
Batch 50/64 loss: 0.31086915731430054
Batch 51/64 loss: 0.30535662174224854
Batch 52/64 loss: 0.2988013029098511
Batch 53/64 loss: 0.292407751083374
Batch 54/64 loss: 0.29801374673843384
Batch 55/64 loss: 0.30009496212005615
Batch 56/64 loss: 0.29546308517456055
Batch 57/64 loss: 0.29563671350479126
Batch 58/64 loss: 0.3110972046852112
Batch 59/64 loss: 0.29520952701568604
Batch 60/64 loss: 0.29972130060195923
Batch 61/64 loss: 0.29771947860717773
Batch 62/64 loss: 0.2937455177307129
Batch 63/64 loss: 0.31651943922042847
Batch 64/64 loss: 0.29883885383605957
Epoch 461  Train loss: 0.3019283752815396  Val loss: 0.33254957178613986
Epoch 462
-------------------------------
Batch 1/64 loss: 0.2999765872955322
Batch 2/64 loss: 0.2996019721031189
Batch 3/64 loss: 0.2986688017845154
Batch 4/64 loss: 0.31757688522338867
Batch 5/64 loss: 0.3079339861869812
Batch 6/64 loss: 0.29787683486938477
Batch 7/64 loss: 0.30224108695983887
Batch 8/64 loss: 0.31286513805389404
Batch 9/64 loss: 0.2958855628967285
Batch 10/64 loss: 0.30063819885253906
Batch 11/64 loss: 0.3058602809906006
Batch 12/64 loss: 0.3041781187057495
Batch 13/64 loss: 0.29466044902801514
Batch 14/64 loss: 0.3022041320800781
Batch 15/64 loss: 0.2989857792854309
Batch 16/64 loss: 0.29954588413238525
Batch 17/64 loss: 0.2875717878341675
Batch 18/64 loss: 0.29659807682037354
Batch 19/64 loss: 0.297491192817688
Batch 20/64 loss: 0.296932578086853
Batch 21/64 loss: 0.29447072744369507
Batch 22/64 loss: 0.2988433837890625
Batch 23/64 loss: 0.2953881025314331
Batch 24/64 loss: 0.3012896776199341
Batch 25/64 loss: 0.310336172580719
Batch 26/64 loss: 0.30492401123046875
Batch 27/64 loss: 0.3175395131111145
Batch 28/64 loss: 0.3044627904891968
Batch 29/64 loss: 0.30518150329589844
Batch 30/64 loss: 0.29359251260757446
Batch 31/64 loss: 0.2938518524169922
Batch 32/64 loss: 0.3041842579841614
Batch 33/64 loss: 0.30693942308425903
Batch 34/64 loss: 0.30164504051208496
Batch 35/64 loss: 0.29943734407424927
Batch 36/64 loss: 0.30788683891296387
Batch 37/64 loss: 0.29960352182388306
Batch 38/64 loss: 0.3112504482269287
Batch 39/64 loss: 0.3014366030693054
Batch 40/64 loss: 0.3079608082771301
Batch 41/64 loss: 0.29148727655410767
Batch 42/64 loss: 0.2961622476577759
Batch 43/64 loss: 0.2962794303894043
Batch 44/64 loss: 0.30584096908569336
Batch 45/64 loss: 0.29329800605773926
Batch 46/64 loss: 0.3015148639678955
Batch 47/64 loss: 0.3009578585624695
Batch 48/64 loss: 0.2984192371368408
Batch 49/64 loss: 0.30704057216644287
Batch 50/64 loss: 0.30398738384246826
Batch 51/64 loss: 0.3004668951034546
Batch 52/64 loss: 0.30242806673049927
Batch 53/64 loss: 0.302659273147583
Batch 54/64 loss: 0.3016582727432251
Batch 55/64 loss: 0.29632532596588135
Batch 56/64 loss: 0.30012714862823486
Batch 57/64 loss: 0.2984434962272644
Batch 58/64 loss: 0.3025170564651489
Batch 59/64 loss: 0.30772316455841064
Batch 60/64 loss: 0.29996776580810547
Batch 61/64 loss: 0.3071998357772827
Batch 62/64 loss: 0.29032284021377563
Batch 63/64 loss: 0.30077242851257324
Batch 64/64 loss: 0.3001779317855835
Epoch 462  Train loss: 0.30130589382321227  Val loss: 0.3320782461117223
Epoch 463
-------------------------------
Batch 1/64 loss: 0.2897792458534241
Batch 2/64 loss: 0.3098353147506714
Batch 3/64 loss: 0.31255292892456055
Batch 4/64 loss: 0.30254632234573364
Batch 5/64 loss: 0.292876660823822
Batch 6/64 loss: 0.29445207118988037
Batch 7/64 loss: 0.3018534779548645
Batch 8/64 loss: 0.2998698949813843
Batch 9/64 loss: 0.29844772815704346
Batch 10/64 loss: 0.30029845237731934
Batch 11/64 loss: 0.3006688356399536
Batch 12/64 loss: 0.2957369089126587
Batch 13/64 loss: 0.2993605136871338
Batch 14/64 loss: 0.2986999750137329
Batch 15/64 loss: 0.3063056468963623
Batch 16/64 loss: 0.300997257232666
Batch 17/64 loss: 0.29859089851379395
Batch 18/64 loss: 0.309082567691803
Batch 19/64 loss: 0.31320619583129883
Batch 20/64 loss: 0.30218303203582764
Batch 21/64 loss: 0.30107396841049194
Batch 22/64 loss: 0.3084648847579956
Batch 23/64 loss: 0.29123103618621826
Batch 24/64 loss: 0.29535454511642456
Batch 25/64 loss: 0.30135828256607056
Batch 26/64 loss: 0.2996962070465088
Batch 27/64 loss: 0.3017507791519165
Batch 28/64 loss: 0.3000040054321289
Batch 29/64 loss: 0.3064488172531128
Batch 30/64 loss: 0.29722172021865845
Batch 31/64 loss: 0.3096598982810974
Batch 32/64 loss: 0.30624687671661377
Batch 33/64 loss: 0.2974637746810913
Batch 34/64 loss: 0.30630743503570557
Batch 35/64 loss: 0.3011462688446045
Batch 36/64 loss: 0.3120105266571045
Batch 37/64 loss: 0.3068304657936096
Batch 38/64 loss: 0.29028451442718506
Batch 39/64 loss: 0.3028554320335388
Batch 40/64 loss: 0.29996156692504883
Batch 41/64 loss: 0.3013884425163269
Batch 42/64 loss: 0.3135499954223633
Batch 43/64 loss: 0.30940526723861694
Batch 44/64 loss: 0.30353206396102905
Batch 45/64 loss: 0.3128129243850708
Batch 46/64 loss: 0.2979154586791992
Batch 47/64 loss: 0.31071674823760986
Batch 48/64 loss: 0.2963886260986328
Batch 49/64 loss: 0.29394829273223877
Batch 50/64 loss: 0.29770326614379883
Batch 51/64 loss: 0.29812318086624146
Batch 52/64 loss: 0.30292612314224243
Batch 53/64 loss: 0.3045703172683716
Batch 54/64 loss: 0.30561888217926025
Batch 55/64 loss: 0.29650628566741943
Batch 56/64 loss: 0.2970084547996521
Batch 57/64 loss: 0.29716384410858154
Batch 58/64 loss: 0.29459625482559204
Batch 59/64 loss: 0.29572367668151855
Batch 60/64 loss: 0.3030738830566406
Batch 61/64 loss: 0.301946222782135
Batch 62/64 loss: 0.3028387427330017
Batch 63/64 loss: 0.3048604726791382
Batch 64/64 loss: 0.29738759994506836
Epoch 463  Train loss: 0.3016168323217654  Val loss: 0.331452795730014
Saving best model, epoch: 463
Epoch 464
-------------------------------
Batch 1/64 loss: 0.293819785118103
Batch 2/64 loss: 0.31745755672454834
Batch 3/64 loss: 0.29738640785217285
Batch 4/64 loss: 0.28677380084991455
Batch 5/64 loss: 0.29937416315078735
Batch 6/64 loss: 0.3033753037452698
Batch 7/64 loss: 0.3035169243812561
Batch 8/64 loss: 0.30228590965270996
Batch 9/64 loss: 0.2901310920715332
Batch 10/64 loss: 0.30256593227386475
Batch 11/64 loss: 0.29788053035736084
Batch 12/64 loss: 0.30146777629852295
Batch 13/64 loss: 0.29721784591674805
Batch 14/64 loss: 0.3086061477661133
Batch 15/64 loss: 0.29470252990722656
Batch 16/64 loss: 0.3046809434890747
Batch 17/64 loss: 0.30209267139434814
Batch 18/64 loss: 0.29452037811279297
Batch 19/64 loss: 0.2958327531814575
Batch 20/64 loss: 0.2999667525291443
Batch 21/64 loss: 0.2998976707458496
Batch 22/64 loss: 0.3035616874694824
Batch 23/64 loss: 0.2905804514884949
Batch 24/64 loss: 0.30581820011138916
Batch 25/64 loss: 0.30864882469177246
Batch 26/64 loss: 0.29086142778396606
Batch 27/64 loss: 0.2987012267112732
Batch 28/64 loss: 0.30105477571487427
Batch 29/64 loss: 0.2903870940208435
Batch 30/64 loss: 0.29938310384750366
Batch 31/64 loss: 0.30679112672805786
Batch 32/64 loss: 0.2995182275772095
Batch 33/64 loss: 0.30561745166778564
Batch 34/64 loss: 0.30152177810668945
Batch 35/64 loss: 0.3045872449874878
Batch 36/64 loss: 0.3062204122543335
Batch 37/64 loss: 0.3016572594642639
Batch 38/64 loss: 0.3075578212738037
Batch 39/64 loss: 0.30797386169433594
Batch 40/64 loss: 0.2972990870475769
Batch 41/64 loss: 0.3040562868118286
Batch 42/64 loss: 0.3025625944137573
Batch 43/64 loss: 0.30110323429107666
Batch 44/64 loss: 0.2930961847305298
Batch 45/64 loss: 0.3082074522972107
Batch 46/64 loss: 0.3010399341583252
Batch 47/64 loss: 0.3037174940109253
Batch 48/64 loss: 0.2973349094390869
Batch 49/64 loss: 0.30270111560821533
Batch 50/64 loss: 0.30542993545532227
Batch 51/64 loss: 0.30480891466140747
Batch 52/64 loss: 0.3081777095794678
Batch 53/64 loss: 0.2984689474105835
Batch 54/64 loss: 0.30915701389312744
Batch 55/64 loss: 0.30015677213668823
Batch 56/64 loss: 0.2981210947036743
Batch 57/64 loss: 0.30680179595947266
Batch 58/64 loss: 0.3087432384490967
Batch 59/64 loss: 0.30541861057281494
Batch 60/64 loss: 0.3010144829750061
Batch 61/64 loss: 0.30071723461151123
Batch 62/64 loss: 0.2954601049423218
Batch 63/64 loss: 0.3102536201477051
Batch 64/64 loss: 0.2959420084953308
Epoch 464  Train loss: 0.3013301823653427  Val loss: 0.33359585103300426
Epoch 465
-------------------------------
Batch 1/64 loss: 0.29169631004333496
Batch 2/64 loss: 0.2907976508140564
Batch 3/64 loss: 0.30313313007354736
Batch 4/64 loss: 0.29636991024017334
Batch 5/64 loss: 0.3039454221725464
Batch 6/64 loss: 0.30291950702667236
Batch 7/64 loss: 0.29093611240386963
Batch 8/64 loss: 0.29799461364746094
Batch 9/64 loss: 0.30721908807754517
Batch 10/64 loss: 0.30587172508239746
Batch 11/64 loss: 0.3042307496070862
Batch 12/64 loss: 0.304283082485199
Batch 13/64 loss: 0.303219199180603
Batch 14/64 loss: 0.3033961057662964
Batch 15/64 loss: 0.2931232452392578
Batch 16/64 loss: 0.30295610427856445
Batch 17/64 loss: 0.30459821224212646
Batch 18/64 loss: 0.31546252965927124
Batch 19/64 loss: 0.31103551387786865
Batch 20/64 loss: 0.3031269907951355
Batch 21/64 loss: 0.3006097078323364
Batch 22/64 loss: 0.3042265772819519
Batch 23/64 loss: 0.29855167865753174
Batch 24/64 loss: 0.3025744557380676
Batch 25/64 loss: 0.30185115337371826
Batch 26/64 loss: 0.29954224824905396
Batch 27/64 loss: 0.296023964881897
Batch 28/64 loss: 0.29712140560150146
Batch 29/64 loss: 0.30630916357040405
Batch 30/64 loss: 0.3013651967048645
Batch 31/64 loss: 0.30272001028060913
Batch 32/64 loss: 0.29605621099472046
Batch 33/64 loss: 0.3038884401321411
Batch 34/64 loss: 0.3011547923088074
Batch 35/64 loss: 0.30438196659088135
Batch 36/64 loss: 0.2955295443534851
Batch 37/64 loss: 0.2924045920372009
Batch 38/64 loss: 0.30280160903930664
Batch 39/64 loss: 0.3090612292289734
Batch 40/64 loss: 0.3072105646133423
Batch 41/64 loss: 0.3055698871612549
Batch 42/64 loss: 0.3029431104660034
Batch 43/64 loss: 0.30092453956604004
Batch 44/64 loss: 0.2957126498222351
Batch 45/64 loss: 0.3058208227157593
Batch 46/64 loss: 0.308388352394104
Batch 47/64 loss: 0.29955077171325684
Batch 48/64 loss: 0.2973697781562805
Batch 49/64 loss: 0.3055917024612427
Batch 50/64 loss: 0.2977503538131714
Batch 51/64 loss: 0.3008815050125122
Batch 52/64 loss: 0.3009571433067322
Batch 53/64 loss: 0.2930978536605835
Batch 54/64 loss: 0.29797399044036865
Batch 55/64 loss: 0.2961912751197815
Batch 56/64 loss: 0.29912328720092773
Batch 57/64 loss: 0.30103886127471924
Batch 58/64 loss: 0.30443310737609863
Batch 59/64 loss: 0.30341291427612305
Batch 60/64 loss: 0.3049197196960449
Batch 61/64 loss: 0.3025885820388794
Batch 62/64 loss: 0.28992438316345215
Batch 63/64 loss: 0.3088468909263611
Batch 64/64 loss: 0.30175793170928955
Epoch 465  Train loss: 0.3013181120741601  Val loss: 0.33187652617385704
Epoch 466
-------------------------------
Batch 1/64 loss: 0.3042796850204468
Batch 2/64 loss: 0.304540753364563
Batch 3/64 loss: 0.29721277952194214
Batch 4/64 loss: 0.3058372139930725
Batch 5/64 loss: 0.29560816287994385
Batch 6/64 loss: 0.2980126738548279
Batch 7/64 loss: 0.2955362796783447
Batch 8/64 loss: 0.2968723773956299
Batch 9/64 loss: 0.2947169542312622
Batch 10/64 loss: 0.29297733306884766
Batch 11/64 loss: 0.3099521994590759
Batch 12/64 loss: 0.310421347618103
Batch 13/64 loss: 0.3014121651649475
Batch 14/64 loss: 0.3038506507873535
Batch 15/64 loss: 0.3004645109176636
Batch 16/64 loss: 0.2993035316467285
Batch 17/64 loss: 0.3056337237358093
Batch 18/64 loss: 0.3030431270599365
Batch 19/64 loss: 0.30557310581207275
Batch 20/64 loss: 0.2945364713668823
Batch 21/64 loss: 0.29185736179351807
Batch 22/64 loss: 0.29420405626296997
Batch 23/64 loss: 0.31223005056381226
Batch 24/64 loss: 0.2937203049659729
Batch 25/64 loss: 0.29187506437301636
Batch 26/64 loss: 0.29966527223587036
Batch 27/64 loss: 0.2963573932647705
Batch 28/64 loss: 0.3068798780441284
Batch 29/64 loss: 0.296023964881897
Batch 30/64 loss: 0.3020474910736084
Batch 31/64 loss: 0.3102099895477295
Batch 32/64 loss: 0.3005763292312622
Batch 33/64 loss: 0.3024158477783203
Batch 34/64 loss: 0.29591894149780273
Batch 35/64 loss: 0.31921887397766113
Batch 36/64 loss: 0.31426727771759033
Batch 37/64 loss: 0.3055480718612671
Batch 38/64 loss: 0.30160021781921387
Batch 39/64 loss: 0.3002047538757324
Batch 40/64 loss: 0.2981741428375244
Batch 41/64 loss: 0.3108811378479004
Batch 42/64 loss: 0.30865204334259033
Batch 43/64 loss: 0.2971835136413574
Batch 44/64 loss: 0.29429465532302856
Batch 45/64 loss: 0.3001241683959961
Batch 46/64 loss: 0.3018747568130493
Batch 47/64 loss: 0.2961137294769287
Batch 48/64 loss: 0.3087159991264343
Batch 49/64 loss: 0.30724984407424927
Batch 50/64 loss: 0.30368781089782715
Batch 51/64 loss: 0.2983437776565552
Batch 52/64 loss: 0.3059176206588745
Batch 53/64 loss: 0.3112863302230835
Batch 54/64 loss: 0.3075038194656372
Batch 55/64 loss: 0.2989017963409424
Batch 56/64 loss: 0.2944624423980713
Batch 57/64 loss: 0.3064422607421875
Batch 58/64 loss: 0.30403292179107666
Batch 59/64 loss: 0.2953519821166992
Batch 60/64 loss: 0.29993724822998047
Batch 61/64 loss: 0.29569780826568604
Batch 62/64 loss: 0.29275691509246826
Batch 63/64 loss: 0.3032480478286743
Batch 64/64 loss: 0.306416392326355
Epoch 466  Train loss: 0.30157260006549313  Val loss: 0.3328939135541621
Epoch 467
-------------------------------
Batch 1/64 loss: 0.2947887182235718
Batch 2/64 loss: 0.2968103885650635
Batch 3/64 loss: 0.29645872116088867
Batch 4/64 loss: 0.2919352054595947
Batch 5/64 loss: 0.2974001169204712
Batch 6/64 loss: 0.3008298873901367
Batch 7/64 loss: 0.3168811798095703
Batch 8/64 loss: 0.30986452102661133
Batch 9/64 loss: 0.30381929874420166
Batch 10/64 loss: 0.2966828942298889
Batch 11/64 loss: 0.2918887138366699
Batch 12/64 loss: 0.2991061210632324
Batch 13/64 loss: 0.2977954149246216
Batch 14/64 loss: 0.3122166395187378
Batch 15/64 loss: 0.2863854169845581
Batch 16/64 loss: 0.29421472549438477
Batch 17/64 loss: 0.30529308319091797
Batch 18/64 loss: 0.29226207733154297
Batch 19/64 loss: 0.30062246322631836
Batch 20/64 loss: 0.29783421754837036
Batch 21/64 loss: 0.2983964681625366
Batch 22/64 loss: 0.29942214488983154
Batch 23/64 loss: 0.3117908239364624
Batch 24/64 loss: 0.30367588996887207
Batch 25/64 loss: 0.30061376094818115
Batch 26/64 loss: 0.2964482307434082
Batch 27/64 loss: 0.29879987239837646
Batch 28/64 loss: 0.3066207766532898
Batch 29/64 loss: 0.30557364225387573
Batch 30/64 loss: 0.29853296279907227
Batch 31/64 loss: 0.303219199180603
Batch 32/64 loss: 0.29923683404922485
Batch 33/64 loss: 0.30585646629333496
Batch 34/64 loss: 0.29017961025238037
Batch 35/64 loss: 0.3133784532546997
Batch 36/64 loss: 0.30683112144470215
Batch 37/64 loss: 0.2982107400894165
Batch 38/64 loss: 0.2927675247192383
Batch 39/64 loss: 0.2959648370742798
Batch 40/64 loss: 0.2973504662513733
Batch 41/64 loss: 0.30191218852996826
Batch 42/64 loss: 0.3009297847747803
Batch 43/64 loss: 0.3001605272293091
Batch 44/64 loss: 0.2890687584877014
Batch 45/64 loss: 0.2973259687423706
Batch 46/64 loss: 0.30018216371536255
Batch 47/64 loss: 0.2972809672355652
Batch 48/64 loss: 0.30314379930496216
Batch 49/64 loss: 0.29852545261383057
Batch 50/64 loss: 0.3029382824897766
Batch 51/64 loss: 0.3204745650291443
Batch 52/64 loss: 0.30994653701782227
Batch 53/64 loss: 0.30010998249053955
Batch 54/64 loss: 0.29932624101638794
Batch 55/64 loss: 0.297035813331604
Batch 56/64 loss: 0.30983203649520874
Batch 57/64 loss: 0.2946227788925171
Batch 58/64 loss: 0.29552024602890015
Batch 59/64 loss: 0.30599331855773926
Batch 60/64 loss: 0.29994887113571167
Batch 61/64 loss: 0.3117644786834717
Batch 62/64 loss: 0.3058474063873291
Batch 63/64 loss: 0.2920339107513428
Batch 64/64 loss: 0.30970466136932373
Epoch 467  Train loss: 0.3007397992938173  Val loss: 0.33251476410737973
Epoch 468
-------------------------------
Batch 1/64 loss: 0.3013853430747986
Batch 2/64 loss: 0.2917470932006836
Batch 3/64 loss: 0.297874391078949
Batch 4/64 loss: 0.3024364113807678
Batch 5/64 loss: 0.30293238162994385
Batch 6/64 loss: 0.2997780442237854
Batch 7/64 loss: 0.29850512742996216
Batch 8/64 loss: 0.2950114607810974
Batch 9/64 loss: 0.3102238178253174
Batch 10/64 loss: 0.29429614543914795
Batch 11/64 loss: 0.3072064518928528
Batch 12/64 loss: 0.3040093183517456
Batch 13/64 loss: 0.30263060331344604
Batch 14/64 loss: 0.3012806177139282
Batch 15/64 loss: 0.3081626296043396
Batch 16/64 loss: 0.3070681691169739
Batch 17/64 loss: 0.30101120471954346
Batch 18/64 loss: 0.2984335422515869
Batch 19/64 loss: 0.29856908321380615
Batch 20/64 loss: 0.30673694610595703
Batch 21/64 loss: 0.30022019147872925
Batch 22/64 loss: 0.29642271995544434
Batch 23/64 loss: 0.30101174116134644
Batch 24/64 loss: 0.30137038230895996
Batch 25/64 loss: 0.30175673961639404
Batch 26/64 loss: 0.3037492036819458
Batch 27/64 loss: 0.29684746265411377
Batch 28/64 loss: 0.3095043897628784
Batch 29/64 loss: 0.3064050078392029
Batch 30/64 loss: 0.30100393295288086
Batch 31/64 loss: 0.3020852208137512
Batch 32/64 loss: 0.3130844831466675
Batch 33/64 loss: 0.2998192310333252
Batch 34/64 loss: 0.29628419876098633
Batch 35/64 loss: 0.3032405376434326
Batch 36/64 loss: 0.2999749779701233
Batch 37/64 loss: 0.30692440271377563
Batch 38/64 loss: 0.29660820960998535
Batch 39/64 loss: 0.29876279830932617
Batch 40/64 loss: 0.3081926107406616
Batch 41/64 loss: 0.29773348569869995
Batch 42/64 loss: 0.29624223709106445
Batch 43/64 loss: 0.29954397678375244
Batch 44/64 loss: 0.2920994758605957
Batch 45/64 loss: 0.3002285957336426
Batch 46/64 loss: 0.29474538564682007
Batch 47/64 loss: 0.30489516258239746
Batch 48/64 loss: 0.2927356958389282
Batch 49/64 loss: 0.3061162233352661
Batch 50/64 loss: 0.29973429441452026
Batch 51/64 loss: 0.31075912714004517
Batch 52/64 loss: 0.30004167556762695
Batch 53/64 loss: 0.30566108226776123
Batch 54/64 loss: 0.3001821041107178
Batch 55/64 loss: 0.3007287383079529
Batch 56/64 loss: 0.3021223545074463
Batch 57/64 loss: 0.3141505718231201
Batch 58/64 loss: 0.2926560044288635
Batch 59/64 loss: 0.30572205781936646
Batch 60/64 loss: 0.29545021057128906
Batch 61/64 loss: 0.30501788854599
Batch 62/64 loss: 0.29684871435165405
Batch 63/64 loss: 0.3056478500366211
Batch 64/64 loss: 0.29604870080947876
Epoch 468  Train loss: 0.30139084960900103  Val loss: 0.33255996491081524
Epoch 469
-------------------------------
Batch 1/64 loss: 0.2969202995300293
Batch 2/64 loss: 0.304443895816803
Batch 3/64 loss: 0.30026817321777344
Batch 4/64 loss: 0.2888273000717163
Batch 5/64 loss: 0.29807591438293457
Batch 6/64 loss: 0.30395740270614624
Batch 7/64 loss: 0.2945210337638855
Batch 8/64 loss: 0.3008577823638916
Batch 9/64 loss: 0.295803427696228
Batch 10/64 loss: 0.30306583642959595
Batch 11/64 loss: 0.2932647466659546
Batch 12/64 loss: 0.3006710410118103
Batch 13/64 loss: 0.29231828451156616
Batch 14/64 loss: 0.2944158911705017
Batch 15/64 loss: 0.30042487382888794
Batch 16/64 loss: 0.3007921576499939
Batch 17/64 loss: 0.311995267868042
Batch 18/64 loss: 0.2972753047943115
Batch 19/64 loss: 0.30203521251678467
Batch 20/64 loss: 0.3084014654159546
Batch 21/64 loss: 0.30090785026550293
Batch 22/64 loss: 0.3113429546356201
Batch 23/64 loss: 0.30530333518981934
Batch 24/64 loss: 0.31247562170028687
Batch 25/64 loss: 0.305248498916626
Batch 26/64 loss: 0.28941869735717773
Batch 27/64 loss: 0.2910052537918091
Batch 28/64 loss: 0.30798065662384033
Batch 29/64 loss: 0.29956066608428955
Batch 30/64 loss: 0.30361950397491455
Batch 31/64 loss: 0.30443936586380005
Batch 32/64 loss: 0.31617653369903564
Batch 33/64 loss: 0.29489874839782715
Batch 34/64 loss: 0.2977529764175415
Batch 35/64 loss: 0.30671775341033936
Batch 36/64 loss: 0.30672407150268555
Batch 37/64 loss: 0.29389578104019165
Batch 38/64 loss: 0.29901576042175293
Batch 39/64 loss: 0.3098183870315552
Batch 40/64 loss: 0.30198150873184204
Batch 41/64 loss: 0.30580270290374756
Batch 42/64 loss: 0.2992328405380249
Batch 43/64 loss: 0.3053826093673706
Batch 44/64 loss: 0.29724788665771484
Batch 45/64 loss: 0.2928043603897095
Batch 46/64 loss: 0.29622721672058105
Batch 47/64 loss: 0.30959558486938477
Batch 48/64 loss: 0.3048509359359741
Batch 49/64 loss: 0.29933589696884155
Batch 50/64 loss: 0.3010069727897644
Batch 51/64 loss: 0.3073941469192505
Batch 52/64 loss: 0.30358409881591797
Batch 53/64 loss: 0.3042086958885193
Batch 54/64 loss: 0.300897479057312
Batch 55/64 loss: 0.3037790060043335
Batch 56/64 loss: 0.3101200461387634
Batch 57/64 loss: 0.30657100677490234
Batch 58/64 loss: 0.29764896631240845
Batch 59/64 loss: 0.2971797585487366
Batch 60/64 loss: 0.3119295835494995
Batch 61/64 loss: 0.30148839950561523
Batch 62/64 loss: 0.29980963468551636
Batch 63/64 loss: 0.29619550704956055
Batch 64/64 loss: 0.29961884021759033
Epoch 469  Train loss: 0.30154708553763  Val loss: 0.3323851246194741
Epoch 470
-------------------------------
Batch 1/64 loss: 0.30570197105407715
Batch 2/64 loss: 0.292719304561615
Batch 3/64 loss: 0.3057212829589844
Batch 4/64 loss: 0.2982199192047119
Batch 5/64 loss: 0.30157673358917236
Batch 6/64 loss: 0.30777037143707275
Batch 7/64 loss: 0.30317866802215576
Batch 8/64 loss: 0.2939457893371582
Batch 9/64 loss: 0.29486626386642456
Batch 10/64 loss: 0.30079948902130127
Batch 11/64 loss: 0.30941706895828247
Batch 12/64 loss: 0.2920877933502197
Batch 13/64 loss: 0.2971358299255371
Batch 14/64 loss: 0.30011415481567383
Batch 15/64 loss: 0.29480743408203125
Batch 16/64 loss: 0.29617393016815186
Batch 17/64 loss: 0.30187004804611206
Batch 18/64 loss: 0.30199551582336426
Batch 19/64 loss: 0.29021161794662476
Batch 20/64 loss: 0.3025420904159546
Batch 21/64 loss: 0.29467880725860596
Batch 22/64 loss: 0.29899168014526367
Batch 23/64 loss: 0.2971043586730957
Batch 24/64 loss: 0.3018873929977417
Batch 25/64 loss: 0.30265361070632935
Batch 26/64 loss: 0.30188578367233276
Batch 27/64 loss: 0.29882699251174927
Batch 28/64 loss: 0.2951522469520569
Batch 29/64 loss: 0.29661285877227783
Batch 30/64 loss: 0.30333900451660156
Batch 31/64 loss: 0.3017385005950928
Batch 32/64 loss: 0.30500733852386475
Batch 33/64 loss: 0.30526721477508545
Batch 34/64 loss: 0.2956501841545105
Batch 35/64 loss: 0.3068609833717346
Batch 36/64 loss: 0.29697859287261963
Batch 37/64 loss: 0.2898365259170532
Batch 38/64 loss: 0.3056408762931824
Batch 39/64 loss: 0.2940438389778137
Batch 40/64 loss: 0.3112550973892212
Batch 41/64 loss: 0.3011256456375122
Batch 42/64 loss: 0.2935861349105835
Batch 43/64 loss: 0.301608681678772
Batch 44/64 loss: 0.3061434030532837
Batch 45/64 loss: 0.31321513652801514
Batch 46/64 loss: 0.3009306788444519
Batch 47/64 loss: 0.2909923791885376
Batch 48/64 loss: 0.3036283254623413
Batch 49/64 loss: 0.30019503831863403
Batch 50/64 loss: 0.31284278631210327
Batch 51/64 loss: 0.30579811334609985
Batch 52/64 loss: 0.301203191280365
Batch 53/64 loss: 0.2992379069328308
Batch 54/64 loss: 0.30773496627807617
Batch 55/64 loss: 0.30117517709732056
Batch 56/64 loss: 0.30175042152404785
Batch 57/64 loss: 0.30001574754714966
Batch 58/64 loss: 0.29882270097732544
Batch 59/64 loss: 0.30159610509872437
Batch 60/64 loss: 0.29765987396240234
Batch 61/64 loss: 0.31334173679351807
Batch 62/64 loss: 0.31013715267181396
Batch 63/64 loss: 0.29612845182418823
Batch 64/64 loss: 0.2983529567718506
Epoch 470  Train loss: 0.30081414334914264  Val loss: 0.33173040303168017
Epoch 471
-------------------------------
Batch 1/64 loss: 0.2942137122154236
Batch 2/64 loss: 0.29440462589263916
Batch 3/64 loss: 0.2935910224914551
Batch 4/64 loss: 0.2967710494995117
Batch 5/64 loss: 0.30180972814559937
Batch 6/64 loss: 0.2999730706214905
Batch 7/64 loss: 0.29104065895080566
Batch 8/64 loss: 0.29922062158584595
Batch 9/64 loss: 0.3014864921569824
Batch 10/64 loss: 0.29427570104599
Batch 11/64 loss: 0.2984796166419983
Batch 12/64 loss: 0.30510151386260986
Batch 13/64 loss: 0.30666762590408325
Batch 14/64 loss: 0.29945147037506104
Batch 15/64 loss: 0.30028021335601807
Batch 16/64 loss: 0.30324476957321167
Batch 17/64 loss: 0.2978249788284302
Batch 18/64 loss: 0.30264562368392944
Batch 19/64 loss: 0.3024519681930542
Batch 20/64 loss: 0.32533061504364014
Batch 21/64 loss: 0.30465996265411377
Batch 22/64 loss: 0.3023425340652466
Batch 23/64 loss: 0.2987595796585083
Batch 24/64 loss: 0.29030364751815796
Batch 25/64 loss: 0.29465150833129883
Batch 26/64 loss: 0.28947579860687256
Batch 27/64 loss: 0.30182528495788574
Batch 28/64 loss: 0.304556667804718
Batch 29/64 loss: 0.28828203678131104
Batch 30/64 loss: 0.2960941195487976
Batch 31/64 loss: 0.3003145456314087
Batch 32/64 loss: 0.3096325397491455
Batch 33/64 loss: 0.29239708185195923
Batch 34/64 loss: 0.3081979751586914
Batch 35/64 loss: 0.291695237159729
Batch 36/64 loss: 0.2978169918060303
Batch 37/64 loss: 0.2975078821182251
Batch 38/64 loss: 0.2926499843597412
Batch 39/64 loss: 0.2999706268310547
Batch 40/64 loss: 0.3083925247192383
Batch 41/64 loss: 0.312142014503479
Batch 42/64 loss: 0.2971367835998535
Batch 43/64 loss: 0.309769868850708
Batch 44/64 loss: 0.2955780029296875
Batch 45/64 loss: 0.29945051670074463
Batch 46/64 loss: 0.30188512802124023
Batch 47/64 loss: 0.3031144142150879
Batch 48/64 loss: 0.304948091506958
Batch 49/64 loss: 0.29744386672973633
Batch 50/64 loss: 0.3002358675003052
Batch 51/64 loss: 0.3107600212097168
Batch 52/64 loss: 0.3103567957878113
Batch 53/64 loss: 0.2978554964065552
Batch 54/64 loss: 0.31125402450561523
Batch 55/64 loss: 0.2938932180404663
Batch 56/64 loss: 0.3094034790992737
Batch 57/64 loss: 0.29640698432922363
Batch 58/64 loss: 0.30492889881134033
Batch 59/64 loss: 0.2988129258155823
Batch 60/64 loss: 0.30598950386047363
Batch 61/64 loss: 0.30706119537353516
Batch 62/64 loss: 0.2922303080558777
Batch 63/64 loss: 0.29800188541412354
Batch 64/64 loss: 0.3132551908493042
Epoch 471  Train loss: 0.30072772222406724  Val loss: 0.33289419314295976
Epoch 472
-------------------------------
Batch 1/64 loss: 0.31038451194763184
Batch 2/64 loss: 0.30406928062438965
Batch 3/64 loss: 0.3020581007003784
Batch 4/64 loss: 0.3016875386238098
Batch 5/64 loss: 0.30616021156311035
Batch 6/64 loss: 0.2994387149810791
Batch 7/64 loss: 0.30770599842071533
Batch 8/64 loss: 0.2990245819091797
Batch 9/64 loss: 0.29895102977752686
Batch 10/64 loss: 0.3001304864883423
Batch 11/64 loss: 0.30488795042037964
Batch 12/64 loss: 0.29757243394851685
Batch 13/64 loss: 0.29991281032562256
Batch 14/64 loss: 0.2957112789154053
Batch 15/64 loss: 0.3055381178855896
Batch 16/64 loss: 0.2968483567237854
Batch 17/64 loss: 0.3124750852584839
Batch 18/64 loss: 0.30238068103790283
Batch 19/64 loss: 0.300595760345459
Batch 20/64 loss: 0.31386613845825195
Batch 21/64 loss: 0.29447412490844727
Batch 22/64 loss: 0.3029444217681885
Batch 23/64 loss: 0.2955007553100586
Batch 24/64 loss: 0.29892152547836304
Batch 25/64 loss: 0.30316615104675293
Batch 26/64 loss: 0.3085213899612427
Batch 27/64 loss: 0.296830415725708
Batch 28/64 loss: 0.30608904361724854
Batch 29/64 loss: 0.3030942678451538
Batch 30/64 loss: 0.2948415279388428
Batch 31/64 loss: 0.2985886335372925
Batch 32/64 loss: 0.3005082607269287
Batch 33/64 loss: 0.29295462369918823
Batch 34/64 loss: 0.2915385961532593
Batch 35/64 loss: 0.29821765422821045
Batch 36/64 loss: 0.30255305767059326
Batch 37/64 loss: 0.3108752965927124
Batch 38/64 loss: 0.3072090744972229
Batch 39/64 loss: 0.30085843801498413
Batch 40/64 loss: 0.30145442485809326
Batch 41/64 loss: 0.28847330808639526
Batch 42/64 loss: 0.30520617961883545
Batch 43/64 loss: 0.296542763710022
Batch 44/64 loss: 0.3045937418937683
Batch 45/64 loss: 0.2923937439918518
Batch 46/64 loss: 0.2898433804512024
Batch 47/64 loss: 0.29644954204559326
Batch 48/64 loss: 0.30212295055389404
Batch 49/64 loss: 0.299136757850647
Batch 50/64 loss: 0.2936347723007202
Batch 51/64 loss: 0.29776519536972046
Batch 52/64 loss: 0.2996676564216614
Batch 53/64 loss: 0.3056793212890625
Batch 54/64 loss: 0.2956262230873108
Batch 55/64 loss: 0.31273794174194336
Batch 56/64 loss: 0.30932462215423584
Batch 57/64 loss: 0.3058253526687622
Batch 58/64 loss: 0.2982597351074219
Batch 59/64 loss: 0.2958461046218872
Batch 60/64 loss: 0.31734752655029297
Batch 61/64 loss: 0.31052708625793457
Batch 62/64 loss: 0.2946404814720154
Batch 63/64 loss: 0.2930942177772522
Batch 64/64 loss: 0.2926408052444458
Epoch 472  Train loss: 0.30106290134729125  Val loss: 0.33351987067776445
Epoch 473
-------------------------------
Batch 1/64 loss: 0.2986264228820801
Batch 2/64 loss: 0.30863386392593384
Batch 3/64 loss: 0.2947736978530884
Batch 4/64 loss: 0.2921661138534546
Batch 5/64 loss: 0.29807722568511963
Batch 6/64 loss: 0.3021669387817383
Batch 7/64 loss: 0.29928523302078247
Batch 8/64 loss: 0.2935100197792053
Batch 9/64 loss: 0.3038533329963684
Batch 10/64 loss: 0.3033452033996582
Batch 11/64 loss: 0.2955794334411621
Batch 12/64 loss: 0.30309247970581055
Batch 13/64 loss: 0.3027404546737671
Batch 14/64 loss: 0.29549145698547363
Batch 15/64 loss: 0.2999193072319031
Batch 16/64 loss: 0.29678237438201904
Batch 17/64 loss: 0.29734593629837036
Batch 18/64 loss: 0.30716395378112793
Batch 19/64 loss: 0.3014606237411499
Batch 20/64 loss: 0.29038989543914795
Batch 21/64 loss: 0.2998625636100769
Batch 22/64 loss: 0.3065871000289917
Batch 23/64 loss: 0.3097236156463623
Batch 24/64 loss: 0.2919923663139343
Batch 25/64 loss: 0.3022559881210327
Batch 26/64 loss: 0.29896044731140137
Batch 27/64 loss: 0.30361777544021606
Batch 28/64 loss: 0.294012188911438
Batch 29/64 loss: 0.29738062620162964
Batch 30/64 loss: 0.30936336517333984
Batch 31/64 loss: 0.29942643642425537
Batch 32/64 loss: 0.3083072900772095
Batch 33/64 loss: 0.2986241579055786
Batch 34/64 loss: 0.2978730797767639
Batch 35/64 loss: 0.3059883117675781
Batch 36/64 loss: 0.2939697504043579
Batch 37/64 loss: 0.30131006240844727
Batch 38/64 loss: 0.3140754699707031
Batch 39/64 loss: 0.30244386196136475
Batch 40/64 loss: 0.29608941078186035
Batch 41/64 loss: 0.2925630807876587
Batch 42/64 loss: 0.29647135734558105
Batch 43/64 loss: 0.2964887022972107
Batch 44/64 loss: 0.3015249967575073
Batch 45/64 loss: 0.3088405728340149
Batch 46/64 loss: 0.29863399267196655
Batch 47/64 loss: 0.3049527406692505
Batch 48/64 loss: 0.3051338195800781
Batch 49/64 loss: 0.2990683913230896
Batch 50/64 loss: 0.3030692934989929
Batch 51/64 loss: 0.30219244956970215
Batch 52/64 loss: 0.28816330432891846
Batch 53/64 loss: 0.3107496500015259
Batch 54/64 loss: 0.3087809085845947
Batch 55/64 loss: 0.292741060256958
Batch 56/64 loss: 0.3045615553855896
Batch 57/64 loss: 0.3070502281188965
Batch 58/64 loss: 0.29451680183410645
Batch 59/64 loss: 0.3046140670776367
Batch 60/64 loss: 0.296455979347229
Batch 61/64 loss: 0.30089855194091797
Batch 62/64 loss: 0.29854822158813477
Batch 63/64 loss: 0.3086814284324646
Batch 64/64 loss: 0.30866193771362305
Epoch 473  Train loss: 0.30074455597821403  Val loss: 0.3318614588980003
Epoch 474
-------------------------------
Batch 1/64 loss: 0.3005892038345337
Batch 2/64 loss: 0.30379557609558105
Batch 3/64 loss: 0.30298006534576416
Batch 4/64 loss: 0.3060814142227173
Batch 5/64 loss: 0.2955784797668457
Batch 6/64 loss: 0.29650425910949707
Batch 7/64 loss: 0.30001991987228394
Batch 8/64 loss: 0.2944491505622864
Batch 9/64 loss: 0.3068959712982178
Batch 10/64 loss: 0.30309104919433594
Batch 11/64 loss: 0.2995215654373169
Batch 12/64 loss: 0.2989538908004761
Batch 13/64 loss: 0.3027191758155823
Batch 14/64 loss: 0.29633116722106934
Batch 15/64 loss: 0.298819363117218
Batch 16/64 loss: 0.2998654842376709
Batch 17/64 loss: 0.29842352867126465
Batch 18/64 loss: 0.3043418526649475
Batch 19/64 loss: 0.30676913261413574
Batch 20/64 loss: 0.30553311109542847
Batch 21/64 loss: 0.29089677333831787
Batch 22/64 loss: 0.2892119884490967
Batch 23/64 loss: 0.3006519675254822
Batch 24/64 loss: 0.29708003997802734
Batch 25/64 loss: 0.2934279441833496
Batch 26/64 loss: 0.31012749671936035
Batch 27/64 loss: 0.29229599237442017
Batch 28/64 loss: 0.3044642210006714
Batch 29/64 loss: 0.302578330039978
Batch 30/64 loss: 0.3027383089065552
Batch 31/64 loss: 0.3030218482017517
Batch 32/64 loss: 0.30121612548828125
Batch 33/64 loss: 0.29605698585510254
Batch 34/64 loss: 0.29995429515838623
Batch 35/64 loss: 0.30090904235839844
Batch 36/64 loss: 0.30404067039489746
Batch 37/64 loss: 0.2991276979446411
Batch 38/64 loss: 0.31359267234802246
Batch 39/64 loss: 0.294322669506073
Batch 40/64 loss: 0.3018178939819336
Batch 41/64 loss: 0.3072807192802429
Batch 42/64 loss: 0.2920438051223755
Batch 43/64 loss: 0.31060004234313965
Batch 44/64 loss: 0.3029404878616333
Batch 45/64 loss: 0.29586660861968994
Batch 46/64 loss: 0.2981386184692383
Batch 47/64 loss: 0.2943704128265381
Batch 48/64 loss: 0.30702775716781616
Batch 49/64 loss: 0.29660940170288086
Batch 50/64 loss: 0.3054996728897095
Batch 51/64 loss: 0.30681443214416504
Batch 52/64 loss: 0.2910098433494568
Batch 53/64 loss: 0.2989456057548523
Batch 54/64 loss: 0.30414825677871704
Batch 55/64 loss: 0.3028547763824463
Batch 56/64 loss: 0.2981005907058716
Batch 57/64 loss: 0.30623090267181396
Batch 58/64 loss: 0.3064878582954407
Batch 59/64 loss: 0.29844093322753906
Batch 60/64 loss: 0.30435431003570557
Batch 61/64 loss: 0.30017006397247314
Batch 62/64 loss: 0.30149900913238525
Batch 63/64 loss: 0.29933059215545654
Batch 64/64 loss: 0.3048839569091797
Epoch 474  Train loss: 0.30080351362041396  Val loss: 0.33335225668150126
Epoch 475
-------------------------------
Batch 1/64 loss: 0.29546642303466797
Batch 2/64 loss: 0.2979356050491333
Batch 3/64 loss: 0.2975887060165405
Batch 4/64 loss: 0.297504186630249
Batch 5/64 loss: 0.31246769428253174
Batch 6/64 loss: 0.2998571991920471
Batch 7/64 loss: 0.29700422286987305
Batch 8/64 loss: 0.3033748269081116
Batch 9/64 loss: 0.30225372314453125
Batch 10/64 loss: 0.303827166557312
Batch 11/64 loss: 0.29507875442504883
Batch 12/64 loss: 0.30883967876434326
Batch 13/64 loss: 0.295731782913208
Batch 14/64 loss: 0.2976968288421631
Batch 15/64 loss: 0.29833757877349854
Batch 16/64 loss: 0.30144190788269043
Batch 17/64 loss: 0.2971705198287964
Batch 18/64 loss: 0.3007391691207886
Batch 19/64 loss: 0.30901145935058594
Batch 20/64 loss: 0.3028622269630432
Batch 21/64 loss: 0.2987172603607178
Batch 22/64 loss: 0.3021054267883301
Batch 23/64 loss: 0.3037375211715698
Batch 24/64 loss: 0.30853140354156494
Batch 25/64 loss: 0.30424344539642334
Batch 26/64 loss: 0.29676973819732666
Batch 27/64 loss: 0.29932403564453125
Batch 28/64 loss: 0.2954859733581543
Batch 29/64 loss: 0.30029284954071045
Batch 30/64 loss: 0.3008664846420288
Batch 31/64 loss: 0.2960782051086426
Batch 32/64 loss: 0.303097128868103
Batch 33/64 loss: 0.2965013384819031
Batch 34/64 loss: 0.29546743631362915
Batch 35/64 loss: 0.2967343330383301
Batch 36/64 loss: 0.3045731782913208
Batch 37/64 loss: 0.3103806972503662
Batch 38/64 loss: 0.2995893955230713
Batch 39/64 loss: 0.2929389476776123
Batch 40/64 loss: 0.3060685396194458
Batch 41/64 loss: 0.30980658531188965
Batch 42/64 loss: 0.29449546337127686
Batch 43/64 loss: 0.30988651514053345
Batch 44/64 loss: 0.3097127676010132
Batch 45/64 loss: 0.3013553023338318
Batch 46/64 loss: 0.3003777265548706
Batch 47/64 loss: 0.29994988441467285
Batch 48/64 loss: 0.30651259422302246
Batch 49/64 loss: 0.3016018867492676
Batch 50/64 loss: 0.2950000762939453
Batch 51/64 loss: 0.30109041929244995
Batch 52/64 loss: 0.3056694269180298
Batch 53/64 loss: 0.3030262589454651
Batch 54/64 loss: 0.307403564453125
Batch 55/64 loss: 0.29208219051361084
Batch 56/64 loss: 0.30232012271881104
Batch 57/64 loss: 0.30241310596466064
Batch 58/64 loss: 0.2916741371154785
Batch 59/64 loss: 0.2906615138053894
Batch 60/64 loss: 0.30257511138916016
Batch 61/64 loss: 0.30451714992523193
Batch 62/64 loss: 0.29858648777008057
Batch 63/64 loss: 0.30797237157821655
Batch 64/64 loss: 0.2986534833908081
Epoch 475  Train loss: 0.3009940984202366  Val loss: 0.331563120445435
Epoch 476
-------------------------------
Batch 1/64 loss: 0.29850322008132935
Batch 2/64 loss: 0.2990618944168091
Batch 3/64 loss: 0.29875820875167847
Batch 4/64 loss: 0.29451853036880493
Batch 5/64 loss: 0.29860925674438477
Batch 6/64 loss: 0.30296599864959717
Batch 7/64 loss: 0.298700749874115
Batch 8/64 loss: 0.29462409019470215
Batch 9/64 loss: 0.2958698272705078
Batch 10/64 loss: 0.29447758197784424
Batch 11/64 loss: 0.2909107208251953
Batch 12/64 loss: 0.29803466796875
Batch 13/64 loss: 0.304465651512146
Batch 14/64 loss: 0.2944561243057251
Batch 15/64 loss: 0.30651795864105225
Batch 16/64 loss: 0.3041348457336426
Batch 17/64 loss: 0.29638195037841797
Batch 18/64 loss: 0.30336034297943115
Batch 19/64 loss: 0.2929859161376953
Batch 20/64 loss: 0.3026413917541504
Batch 21/64 loss: 0.29868245124816895
Batch 22/64 loss: 0.2949068546295166
Batch 23/64 loss: 0.29247963428497314
Batch 24/64 loss: 0.29466116428375244
Batch 25/64 loss: 0.30400633811950684
Batch 26/64 loss: 0.2962374687194824
Batch 27/64 loss: 0.30158722400665283
Batch 28/64 loss: 0.299824595451355
Batch 29/64 loss: 0.29523688554763794
Batch 30/64 loss: 0.30355000495910645
Batch 31/64 loss: 0.2986401319503784
Batch 32/64 loss: 0.29976755380630493
Batch 33/64 loss: 0.3048090934753418
Batch 34/64 loss: 0.2954738140106201
Batch 35/64 loss: 0.3088045120239258
Batch 36/64 loss: 0.2986345887184143
Batch 37/64 loss: 0.30951541662216187
Batch 38/64 loss: 0.30609041452407837
Batch 39/64 loss: 0.30252182483673096
Batch 40/64 loss: 0.29261261224746704
Batch 41/64 loss: 0.3032635450363159
Batch 42/64 loss: 0.3045828938484192
Batch 43/64 loss: 0.3004413843154907
Batch 44/64 loss: 0.3113356828689575
Batch 45/64 loss: 0.3221527934074402
Batch 46/64 loss: 0.2946135997772217
Batch 47/64 loss: 0.3029991388320923
Batch 48/64 loss: 0.3060950040817261
Batch 49/64 loss: 0.3046610355377197
Batch 50/64 loss: 0.3038256764411926
Batch 51/64 loss: 0.296108603477478
Batch 52/64 loss: 0.30303001403808594
Batch 53/64 loss: 0.2975754737854004
Batch 54/64 loss: 0.2877006530761719
Batch 55/64 loss: 0.296431303024292
Batch 56/64 loss: 0.29605138301849365
Batch 57/64 loss: 0.3081969618797302
Batch 58/64 loss: 0.2981257438659668
Batch 59/64 loss: 0.2946128845214844
Batch 60/64 loss: 0.3104041814804077
Batch 61/64 loss: 0.30267035961151123
Batch 62/64 loss: 0.29378628730773926
Batch 63/64 loss: 0.3024612069129944
Batch 64/64 loss: 0.3181718587875366
Epoch 476  Train loss: 0.30035727398068296  Val loss: 0.3317555273111743
Epoch 477
-------------------------------
Batch 1/64 loss: 0.2942879796028137
Batch 2/64 loss: 0.3118375539779663
Batch 3/64 loss: 0.2952061891555786
Batch 4/64 loss: 0.2989270091056824
Batch 5/64 loss: 0.2995344400405884
Batch 6/64 loss: 0.2915126085281372
Batch 7/64 loss: 0.2941933870315552
Batch 8/64 loss: 0.30445003509521484
Batch 9/64 loss: 0.30412042140960693
Batch 10/64 loss: 0.2962149381637573
Batch 11/64 loss: 0.2946087121963501
Batch 12/64 loss: 0.29651278257369995
Batch 13/64 loss: 0.3016272783279419
Batch 14/64 loss: 0.3001821041107178
Batch 15/64 loss: 0.30434495210647583
Batch 16/64 loss: 0.31310296058654785
Batch 17/64 loss: 0.3012848496437073
Batch 18/64 loss: 0.29188358783721924
Batch 19/64 loss: 0.3041151165962219
Batch 20/64 loss: 0.2932189702987671
Batch 21/64 loss: 0.305855393409729
Batch 22/64 loss: 0.29512786865234375
Batch 23/64 loss: 0.2990879416465759
Batch 24/64 loss: 0.3076900839805603
Batch 25/64 loss: 0.30092060565948486
Batch 26/64 loss: 0.2994513511657715
Batch 27/64 loss: 0.2967183589935303
Batch 28/64 loss: 0.2901383638381958
Batch 29/64 loss: 0.2988883852958679
Batch 30/64 loss: 0.29072248935699463
Batch 31/64 loss: 0.30007946491241455
Batch 32/64 loss: 0.2983144521713257
Batch 33/64 loss: 0.2921963334083557
Batch 34/64 loss: 0.2994281053543091
Batch 35/64 loss: 0.2996975779533386
Batch 36/64 loss: 0.30793988704681396
Batch 37/64 loss: 0.2981523275375366
Batch 38/64 loss: 0.30105721950531006
Batch 39/64 loss: 0.3065711259841919
Batch 40/64 loss: 0.30111271142959595
Batch 41/64 loss: 0.303676962852478
Batch 42/64 loss: 0.29817652702331543
Batch 43/64 loss: 0.2898523807525635
Batch 44/64 loss: 0.2984292507171631
Batch 45/64 loss: 0.30188488960266113
Batch 46/64 loss: 0.29376792907714844
Batch 47/64 loss: 0.2996724247932434
Batch 48/64 loss: 0.3044853210449219
Batch 49/64 loss: 0.2934061288833618
Batch 50/64 loss: 0.30016660690307617
Batch 51/64 loss: 0.2969908118247986
Batch 52/64 loss: 0.3025895357131958
Batch 53/64 loss: 0.3005741834640503
Batch 54/64 loss: 0.2932255268096924
Batch 55/64 loss: 0.30101650953292847
Batch 56/64 loss: 0.3129604458808899
Batch 57/64 loss: 0.31156396865844727
Batch 58/64 loss: 0.31305038928985596
Batch 59/64 loss: 0.30109548568725586
Batch 60/64 loss: 0.3143080472946167
Batch 61/64 loss: 0.2938932776451111
Batch 62/64 loss: 0.3003126382827759
Batch 63/64 loss: 0.3117060661315918
Batch 64/64 loss: 0.30192410945892334
Epoch 477  Train loss: 0.30029120492000205  Val loss: 0.33280155748845786
Epoch 478
-------------------------------
Batch 1/64 loss: 0.29203009605407715
Batch 2/64 loss: 0.29594486951828003
Batch 3/64 loss: 0.3113424777984619
Batch 4/64 loss: 0.30012720823287964
Batch 5/64 loss: 0.2943308353424072
Batch 6/64 loss: 0.3063367009162903
Batch 7/64 loss: 0.3008847236633301
Batch 8/64 loss: 0.2979394197463989
Batch 9/64 loss: 0.3029712438583374
Batch 10/64 loss: 0.296225905418396
Batch 11/64 loss: 0.29300975799560547
Batch 12/64 loss: 0.29918038845062256
Batch 13/64 loss: 0.30277562141418457
Batch 14/64 loss: 0.30230993032455444
Batch 15/64 loss: 0.30053651332855225
Batch 16/64 loss: 0.2972595691680908
Batch 17/64 loss: 0.29617273807525635
Batch 18/64 loss: 0.2957693338394165
Batch 19/64 loss: 0.30433934926986694
Batch 20/64 loss: 0.29694032669067383
Batch 21/64 loss: 0.29846763610839844
Batch 22/64 loss: 0.29330700635910034
Batch 23/64 loss: 0.2928675413131714
Batch 24/64 loss: 0.3046942353248596
Batch 25/64 loss: 0.2998899221420288
Batch 26/64 loss: 0.2887808680534363
Batch 27/64 loss: 0.308435320854187
Batch 28/64 loss: 0.29462742805480957
Batch 29/64 loss: 0.3098773956298828
Batch 30/64 loss: 0.2936033606529236
Batch 31/64 loss: 0.30200111865997314
Batch 32/64 loss: 0.29985666275024414
Batch 33/64 loss: 0.29773885011672974
Batch 34/64 loss: 0.3085833787918091
Batch 35/64 loss: 0.3072780966758728
Batch 36/64 loss: 0.30361008644104004
Batch 37/64 loss: 0.3081156015396118
Batch 38/64 loss: 0.2994651198387146
Batch 39/64 loss: 0.2947894334793091
Batch 40/64 loss: 0.30409204959869385
Batch 41/64 loss: 0.30009138584136963
Batch 42/64 loss: 0.2971775531768799
Batch 43/64 loss: 0.30120033025741577
Batch 44/64 loss: 0.29030609130859375
Batch 45/64 loss: 0.2946070432662964
Batch 46/64 loss: 0.30478590726852417
Batch 47/64 loss: 0.3048930764198303
Batch 48/64 loss: 0.2980841398239136
Batch 49/64 loss: 0.305400013923645
Batch 50/64 loss: 0.3095979690551758
Batch 51/64 loss: 0.28973668813705444
Batch 52/64 loss: 0.2999058961868286
Batch 53/64 loss: 0.30724161863327026
Batch 54/64 loss: 0.3026057481765747
Batch 55/64 loss: 0.30378878116607666
Batch 56/64 loss: 0.2958354949951172
Batch 57/64 loss: 0.28261417150497437
Batch 58/64 loss: 0.3098769187927246
Batch 59/64 loss: 0.30433398485183716
Batch 60/64 loss: 0.29042088985443115
Batch 61/64 loss: 0.2979682683944702
Batch 62/64 loss: 0.29853928089141846
Batch 63/64 loss: 0.3020273447036743
Batch 64/64 loss: 0.3077266216278076
Epoch 478  Train loss: 0.29989555583280675  Val loss: 0.33334509060554895
Epoch 479
-------------------------------
Batch 1/64 loss: 0.3036390542984009
Batch 2/64 loss: 0.2950701117515564
Batch 3/64 loss: 0.2986670136451721
Batch 4/64 loss: 0.29636669158935547
Batch 5/64 loss: 0.2949841022491455
Batch 6/64 loss: 0.29659414291381836
Batch 7/64 loss: 0.29044830799102783
Batch 8/64 loss: 0.3003625273704529
Batch 9/64 loss: 0.313586950302124
Batch 10/64 loss: 0.304415762424469
Batch 11/64 loss: 0.30032050609588623
Batch 12/64 loss: 0.30166447162628174
Batch 13/64 loss: 0.2985050678253174
Batch 14/64 loss: 0.29707229137420654
Batch 15/64 loss: 0.3000182509422302
Batch 16/64 loss: 0.29180586338043213
Batch 17/64 loss: 0.2993704080581665
Batch 18/64 loss: 0.3003578186035156
Batch 19/64 loss: 0.3050704598426819
Batch 20/64 loss: 0.2841670513153076
Batch 21/64 loss: 0.2963104248046875
Batch 22/64 loss: 0.29923439025878906
Batch 23/64 loss: 0.30488038063049316
Batch 24/64 loss: 0.30256855487823486
Batch 25/64 loss: 0.30661118030548096
Batch 26/64 loss: 0.30456769466400146
Batch 27/64 loss: 0.30419784784317017
Batch 28/64 loss: 0.30286353826522827
Batch 29/64 loss: 0.300792396068573
Batch 30/64 loss: 0.30722886323928833
Batch 31/64 loss: 0.2983483672142029
Batch 32/64 loss: 0.3016996383666992
Batch 33/64 loss: 0.30515503883361816
Batch 34/64 loss: 0.2906343936920166
Batch 35/64 loss: 0.303583562374115
Batch 36/64 loss: 0.29773443937301636
Batch 37/64 loss: 0.28832852840423584
Batch 38/64 loss: 0.29991310834884644
Batch 39/64 loss: 0.29473793506622314
Batch 40/64 loss: 0.30797278881073
Batch 41/64 loss: 0.29817473888397217
Batch 42/64 loss: 0.30796873569488525
Batch 43/64 loss: 0.3000410795211792
Batch 44/64 loss: 0.310422420501709
Batch 45/64 loss: 0.3004247546195984
Batch 46/64 loss: 0.3053401708602905
Batch 47/64 loss: 0.3036006689071655
Batch 48/64 loss: 0.30725592374801636
Batch 49/64 loss: 0.29494524002075195
Batch 50/64 loss: 0.2993680238723755
Batch 51/64 loss: 0.30234014987945557
Batch 52/64 loss: 0.2997642755508423
Batch 53/64 loss: 0.30989861488342285
Batch 54/64 loss: 0.3002500534057617
Batch 55/64 loss: 0.29934000968933105
Batch 56/64 loss: 0.30568772554397583
Batch 57/64 loss: 0.3026354908943176
Batch 58/64 loss: 0.2986314296722412
Batch 59/64 loss: 0.29950976371765137
Batch 60/64 loss: 0.29357969760894775
Batch 61/64 loss: 0.30759215354919434
Batch 62/64 loss: 0.2984333038330078
Batch 63/64 loss: 0.2954617738723755
Batch 64/64 loss: 0.3062760829925537
Epoch 479  Train loss: 0.3005525205649582  Val loss: 0.3318787192560963
Epoch 480
-------------------------------
Batch 1/64 loss: 0.2999866008758545
Batch 2/64 loss: 0.30963045358657837
Batch 3/64 loss: 0.30854833126068115
Batch 4/64 loss: 0.3032928705215454
Batch 5/64 loss: 0.3040350675582886
Batch 6/64 loss: 0.30433136224746704
Batch 7/64 loss: 0.30646812915802
Batch 8/64 loss: 0.3034045696258545
Batch 9/64 loss: 0.30417507886886597
Batch 10/64 loss: 0.29861509799957275
Batch 11/64 loss: 0.3003731966018677
Batch 12/64 loss: 0.2952297329902649
Batch 13/64 loss: 0.2970590591430664
Batch 14/64 loss: 0.2994704842567444
Batch 15/64 loss: 0.2955148220062256
Batch 16/64 loss: 0.3012734055519104
Batch 17/64 loss: 0.3054894804954529
Batch 18/64 loss: 0.2965712547302246
Batch 19/64 loss: 0.30718982219696045
Batch 20/64 loss: 0.2954978942871094
Batch 21/64 loss: 0.3030601739883423
Batch 22/64 loss: 0.2901694178581238
Batch 23/64 loss: 0.29435068368911743
Batch 24/64 loss: 0.2954338788986206
Batch 25/64 loss: 0.3004797101020813
Batch 26/64 loss: 0.30153417587280273
Batch 27/64 loss: 0.294061541557312
Batch 28/64 loss: 0.30815863609313965
Batch 29/64 loss: 0.2993519902229309
Batch 30/64 loss: 0.30376964807510376
Batch 31/64 loss: 0.30235862731933594
Batch 32/64 loss: 0.3027174472808838
Batch 33/64 loss: 0.29651129245758057
Batch 34/64 loss: 0.2965455651283264
Batch 35/64 loss: 0.296358585357666
Batch 36/64 loss: 0.29902464151382446
Batch 37/64 loss: 0.30019611120224
Batch 38/64 loss: 0.2911911606788635
Batch 39/64 loss: 0.3005920648574829
Batch 40/64 loss: 0.30283617973327637
Batch 41/64 loss: 0.30229246616363525
Batch 42/64 loss: 0.3068811893463135
Batch 43/64 loss: 0.3089456558227539
Batch 44/64 loss: 0.30161815881729126
Batch 45/64 loss: 0.30699414014816284
Batch 46/64 loss: 0.2977027893066406
Batch 47/64 loss: 0.2945250868797302
Batch 48/64 loss: 0.2963641881942749
Batch 49/64 loss: 0.29798299074172974
Batch 50/64 loss: 0.30269891023635864
Batch 51/64 loss: 0.30312979221343994
Batch 52/64 loss: 0.29986149072647095
Batch 53/64 loss: 0.3011881709098816
Batch 54/64 loss: 0.305295467376709
Batch 55/64 loss: 0.30232536792755127
Batch 56/64 loss: 0.30703628063201904
Batch 57/64 loss: 0.28967583179473877
Batch 58/64 loss: 0.30729639530181885
Batch 59/64 loss: 0.2925102114677429
Batch 60/64 loss: 0.29702162742614746
Batch 61/64 loss: 0.30620384216308594
Batch 62/64 loss: 0.28939735889434814
Batch 63/64 loss: 0.29640865325927734
Batch 64/64 loss: 0.307087779045105
Epoch 480  Train loss: 0.3005259630726833  Val loss: 0.33242782428092565
Epoch 481
-------------------------------
Batch 1/64 loss: 0.30037039518356323
Batch 2/64 loss: 0.29514771699905396
Batch 3/64 loss: 0.3078094720840454
Batch 4/64 loss: 0.2975461483001709
Batch 5/64 loss: 0.3030408024787903
Batch 6/64 loss: 0.29882073402404785
Batch 7/64 loss: 0.30675768852233887
Batch 8/64 loss: 0.29175901412963867
Batch 9/64 loss: 0.297674298286438
Batch 10/64 loss: 0.28746020793914795
Batch 11/64 loss: 0.29716503620147705
Batch 12/64 loss: 0.30251365900039673
Batch 13/64 loss: 0.2969393730163574
Batch 14/64 loss: 0.3056504726409912
Batch 15/64 loss: 0.29648029804229736
Batch 16/64 loss: 0.2978419065475464
Batch 17/64 loss: 0.28964126110076904
Batch 18/64 loss: 0.30120915174484253
Batch 19/64 loss: 0.2935328483581543
Batch 20/64 loss: 0.30549156665802
Batch 21/64 loss: 0.3059293031692505
Batch 22/64 loss: 0.3096369504928589
Batch 23/64 loss: 0.3095576763153076
Batch 24/64 loss: 0.30587220191955566
Batch 25/64 loss: 0.29955577850341797
Batch 26/64 loss: 0.30433082580566406
Batch 27/64 loss: 0.2889004349708557
Batch 28/64 loss: 0.30642807483673096
Batch 29/64 loss: 0.3015255331993103
Batch 30/64 loss: 0.29890960454940796
Batch 31/64 loss: 0.3000199794769287
Batch 32/64 loss: 0.3027150630950928
Batch 33/64 loss: 0.2976137399673462
Batch 34/64 loss: 0.2990046739578247
Batch 35/64 loss: 0.2977343797683716
Batch 36/64 loss: 0.2964267134666443
Batch 37/64 loss: 0.2979637384414673
Batch 38/64 loss: 0.3054713010787964
Batch 39/64 loss: 0.2938065528869629
Batch 40/64 loss: 0.30004918575286865
Batch 41/64 loss: 0.30154919624328613
Batch 42/64 loss: 0.29729437828063965
Batch 43/64 loss: 0.30693018436431885
Batch 44/64 loss: 0.30002784729003906
Batch 45/64 loss: 0.2934027910232544
Batch 46/64 loss: 0.3113272786140442
Batch 47/64 loss: 0.2937750816345215
Batch 48/64 loss: 0.2903245687484741
Batch 49/64 loss: 0.3066394329071045
Batch 50/64 loss: 0.3032541871070862
Batch 51/64 loss: 0.2927919626235962
Batch 52/64 loss: 0.3027611970901489
Batch 53/64 loss: 0.2999361753463745
Batch 54/64 loss: 0.3038947582244873
Batch 55/64 loss: 0.2984921932220459
Batch 56/64 loss: 0.3011295795440674
Batch 57/64 loss: 0.3065650463104248
Batch 58/64 loss: 0.30699753761291504
Batch 59/64 loss: 0.31157201528549194
Batch 60/64 loss: 0.29734712839126587
Batch 61/64 loss: 0.30076295137405396
Batch 62/64 loss: 0.29724574089050293
Batch 63/64 loss: 0.29504287242889404
Batch 64/64 loss: 0.2970287799835205
Epoch 481  Train loss: 0.3001747365091361  Val loss: 0.33223302012046996
Epoch 482
-------------------------------
Batch 1/64 loss: 0.2934579849243164
Batch 2/64 loss: 0.3007718324661255
Batch 3/64 loss: 0.28973710536956787
Batch 4/64 loss: 0.2915950417518616
Batch 5/64 loss: 0.2932024598121643
Batch 6/64 loss: 0.3001077175140381
Batch 7/64 loss: 0.3026258945465088
Batch 8/64 loss: 0.29980552196502686
Batch 9/64 loss: 0.30964159965515137
Batch 10/64 loss: 0.30439507961273193
Batch 11/64 loss: 0.3005295991897583
Batch 12/64 loss: 0.3001211881637573
Batch 13/64 loss: 0.3010416030883789
Batch 14/64 loss: 0.28798699378967285
Batch 15/64 loss: 0.3068464994430542
Batch 16/64 loss: 0.3025552034378052
Batch 17/64 loss: 0.2995961904525757
Batch 18/64 loss: 0.30129730701446533
Batch 19/64 loss: 0.31192952394485474
Batch 20/64 loss: 0.29486918449401855
Batch 21/64 loss: 0.30058783292770386
Batch 22/64 loss: 0.2942017912864685
Batch 23/64 loss: 0.2942591905593872
Batch 24/64 loss: 0.3019371032714844
Batch 25/64 loss: 0.2890361547470093
Batch 26/64 loss: 0.30013537406921387
Batch 27/64 loss: 0.2995586395263672
Batch 28/64 loss: 0.2970240116119385
Batch 29/64 loss: 0.30121445655822754
Batch 30/64 loss: 0.30685269832611084
Batch 31/64 loss: 0.29738616943359375
Batch 32/64 loss: 0.2938103675842285
Batch 33/64 loss: 0.30056923627853394
Batch 34/64 loss: 0.29507219791412354
Batch 35/64 loss: 0.3025183081626892
Batch 36/64 loss: 0.29749155044555664
Batch 37/64 loss: 0.31745201349258423
Batch 38/64 loss: 0.2986868619918823
Batch 39/64 loss: 0.2937004566192627
Batch 40/64 loss: 0.29566967487335205
Batch 41/64 loss: 0.29979848861694336
Batch 42/64 loss: 0.30094826221466064
Batch 43/64 loss: 0.3056642413139343
Batch 44/64 loss: 0.30688905715942383
Batch 45/64 loss: 0.2991170287132263
Batch 46/64 loss: 0.30766886472702026
Batch 47/64 loss: 0.30432891845703125
Batch 48/64 loss: 0.29947900772094727
Batch 49/64 loss: 0.2941993474960327
Batch 50/64 loss: 0.30628836154937744
Batch 51/64 loss: 0.30118513107299805
Batch 52/64 loss: 0.296459436416626
Batch 53/64 loss: 0.3022674322128296
Batch 54/64 loss: 0.29528748989105225
Batch 55/64 loss: 0.292441725730896
Batch 56/64 loss: 0.29500436782836914
Batch 57/64 loss: 0.314957857131958
Batch 58/64 loss: 0.304119348526001
Batch 59/64 loss: 0.29599976539611816
Batch 60/64 loss: 0.3030388355255127
Batch 61/64 loss: 0.2948741316795349
Batch 62/64 loss: 0.28917431831359863
Batch 63/64 loss: 0.31293773651123047
Batch 64/64 loss: 0.293032169342041
Epoch 482  Train loss: 0.29978322982788086  Val loss: 0.3325799564315691
Epoch 483
-------------------------------
Batch 1/64 loss: 0.30011820793151855
Batch 2/64 loss: 0.3050422668457031
Batch 3/64 loss: 0.29428815841674805
Batch 4/64 loss: 0.29629606008529663
Batch 5/64 loss: 0.289228618144989
Batch 6/64 loss: 0.3002129793167114
Batch 7/64 loss: 0.29300904273986816
Batch 8/64 loss: 0.2990717887878418
Batch 9/64 loss: 0.30259597301483154
Batch 10/64 loss: 0.2964942455291748
Batch 11/64 loss: 0.2990533113479614
Batch 12/64 loss: 0.29664772748947144
Batch 13/64 loss: 0.296298623085022
Batch 14/64 loss: 0.29979586601257324
Batch 15/64 loss: 0.29481053352355957
Batch 16/64 loss: 0.29270219802856445
Batch 17/64 loss: 0.3011312484741211
Batch 18/64 loss: 0.30759871006011963
Batch 19/64 loss: 0.2986639738082886
Batch 20/64 loss: 0.29690825939178467
Batch 21/64 loss: 0.3113969564437866
Batch 22/64 loss: 0.29309308528900146
Batch 23/64 loss: 0.29427337646484375
Batch 24/64 loss: 0.294561505317688
Batch 25/64 loss: 0.2948971390724182
Batch 26/64 loss: 0.303608238697052
Batch 27/64 loss: 0.30584293603897095
Batch 28/64 loss: 0.3100755214691162
Batch 29/64 loss: 0.3013172745704651
Batch 30/64 loss: 0.30327659845352173
Batch 31/64 loss: 0.2973860502243042
Batch 32/64 loss: 0.30049753189086914
Batch 33/64 loss: 0.302756130695343
Batch 34/64 loss: 0.2916371822357178
Batch 35/64 loss: 0.29878365993499756
Batch 36/64 loss: 0.2973061800003052
Batch 37/64 loss: 0.30110418796539307
Batch 38/64 loss: 0.2930307388305664
Batch 39/64 loss: 0.31358814239501953
Batch 40/64 loss: 0.3006105422973633
Batch 41/64 loss: 0.3001917600631714
Batch 42/64 loss: 0.29499852657318115
Batch 43/64 loss: 0.3013300895690918
Batch 44/64 loss: 0.3045828342437744
Batch 45/64 loss: 0.30103689432144165
Batch 46/64 loss: 0.2954447865486145
Batch 47/64 loss: 0.30340421199798584
Batch 48/64 loss: 0.3006455898284912
Batch 49/64 loss: 0.30797386169433594
Batch 50/64 loss: 0.3026745319366455
Batch 51/64 loss: 0.2996809482574463
Batch 52/64 loss: 0.30611664056777954
Batch 53/64 loss: 0.2999314069747925
Batch 54/64 loss: 0.30307602882385254
Batch 55/64 loss: 0.31055915355682373
Batch 56/64 loss: 0.29035401344299316
Batch 57/64 loss: 0.29905903339385986
Batch 58/64 loss: 0.29568350315093994
Batch 59/64 loss: 0.3099263906478882
Batch 60/64 loss: 0.30241888761520386
Batch 61/64 loss: 0.2954660654067993
Batch 62/64 loss: 0.29870229959487915
Batch 63/64 loss: 0.30319881439208984
Batch 64/64 loss: 0.3019000291824341
Epoch 483  Train loss: 0.2999512480754478  Val loss: 0.3331768717552788
Epoch 484
-------------------------------
Batch 1/64 loss: 0.2965930104255676
Batch 2/64 loss: 0.29631078243255615
Batch 3/64 loss: 0.3032344579696655
Batch 4/64 loss: 0.2965347170829773
Batch 5/64 loss: 0.3058355450630188
Batch 6/64 loss: 0.29370731115341187
Batch 7/64 loss: 0.30000627040863037
Batch 8/64 loss: 0.2979949712753296
Batch 9/64 loss: 0.29623347520828247
Batch 10/64 loss: 0.3025878667831421
Batch 11/64 loss: 0.30843913555145264
Batch 12/64 loss: 0.28810763359069824
Batch 13/64 loss: 0.299330472946167
Batch 14/64 loss: 0.3003276586532593
Batch 15/64 loss: 0.2963627576828003
Batch 16/64 loss: 0.3051300048828125
Batch 17/64 loss: 0.296653687953949
Batch 18/64 loss: 0.2998400330543518
Batch 19/64 loss: 0.29786479473114014
Batch 20/64 loss: 0.2945629358291626
Batch 21/64 loss: 0.3158602714538574
Batch 22/64 loss: 0.3026288151741028
Batch 23/64 loss: 0.2969133257865906
Batch 24/64 loss: 0.2979828715324402
Batch 25/64 loss: 0.29264336824417114
Batch 26/64 loss: 0.2975061535835266
Batch 27/64 loss: 0.2985877990722656
Batch 28/64 loss: 0.31430721282958984
Batch 29/64 loss: 0.3008929491043091
Batch 30/64 loss: 0.2978919744491577
Batch 31/64 loss: 0.30029791593551636
Batch 32/64 loss: 0.30454695224761963
Batch 33/64 loss: 0.2979351282119751
Batch 34/64 loss: 0.2995690703392029
Batch 35/64 loss: 0.30439692735671997
Batch 36/64 loss: 0.29901885986328125
Batch 37/64 loss: 0.29331815242767334
Batch 38/64 loss: 0.2973785996437073
Batch 39/64 loss: 0.305478036403656
Batch 40/64 loss: 0.3018680214881897
Batch 41/64 loss: 0.2993720769882202
Batch 42/64 loss: 0.3088821768760681
Batch 43/64 loss: 0.31418901681900024
Batch 44/64 loss: 0.3005591630935669
Batch 45/64 loss: 0.29853570461273193
Batch 46/64 loss: 0.304510235786438
Batch 47/64 loss: 0.3065072298049927
Batch 48/64 loss: 0.2940059304237366
Batch 49/64 loss: 0.3063739538192749
Batch 50/64 loss: 0.29863083362579346
Batch 51/64 loss: 0.3033236861228943
Batch 52/64 loss: 0.30706214904785156
Batch 53/64 loss: 0.297768235206604
Batch 54/64 loss: 0.3003140687942505
Batch 55/64 loss: 0.29654181003570557
Batch 56/64 loss: 0.28686779737472534
Batch 57/64 loss: 0.2996021509170532
Batch 58/64 loss: 0.29926174879074097
Batch 59/64 loss: 0.3009054660797119
Batch 60/64 loss: 0.31170761585235596
Batch 61/64 loss: 0.3136441707611084
Batch 62/64 loss: 0.2929450273513794
Batch 63/64 loss: 0.2861868739128113
Batch 64/64 loss: 0.3004084825515747
Epoch 484  Train loss: 0.3003558182248882  Val loss: 0.33315090829973776
Epoch 485
-------------------------------
Batch 1/64 loss: 0.29776138067245483
Batch 2/64 loss: 0.3028779625892639
Batch 3/64 loss: 0.30895698070526123
Batch 4/64 loss: 0.3039337396621704
Batch 5/64 loss: 0.3000938892364502
Batch 6/64 loss: 0.31017690896987915
Batch 7/64 loss: 0.30382609367370605
Batch 8/64 loss: 0.2882899045944214
Batch 9/64 loss: 0.30390465259552
Batch 10/64 loss: 0.3038012981414795
Batch 11/64 loss: 0.29421019554138184
Batch 12/64 loss: 0.2895194888114929
Batch 13/64 loss: 0.3040250539779663
Batch 14/64 loss: 0.3057682514190674
Batch 15/64 loss: 0.2975165843963623
Batch 16/64 loss: 0.3024524450302124
Batch 17/64 loss: 0.29265880584716797
Batch 18/64 loss: 0.3023530840873718
Batch 19/64 loss: 0.2924083471298218
Batch 20/64 loss: 0.29981476068496704
Batch 21/64 loss: 0.29592442512512207
Batch 22/64 loss: 0.3095966577529907
Batch 23/64 loss: 0.30783283710479736
Batch 24/64 loss: 0.2940971255302429
Batch 25/64 loss: 0.3028442859649658
Batch 26/64 loss: 0.3018866777420044
Batch 27/64 loss: 0.30271023511886597
Batch 28/64 loss: 0.29547595977783203
Batch 29/64 loss: 0.2986600399017334
Batch 30/64 loss: 0.30286455154418945
Batch 31/64 loss: 0.2993687391281128
Batch 32/64 loss: 0.3006487488746643
Batch 33/64 loss: 0.2974449396133423
Batch 34/64 loss: 0.2920730710029602
Batch 35/64 loss: 0.2958498001098633
Batch 36/64 loss: 0.29592692852020264
Batch 37/64 loss: 0.3082844018936157
Batch 38/64 loss: 0.29900407791137695
Batch 39/64 loss: 0.30517226457595825
Batch 40/64 loss: 0.30130696296691895
Batch 41/64 loss: 0.2949511408805847
Batch 42/64 loss: 0.3027303218841553
Batch 43/64 loss: 0.30403566360473633
Batch 44/64 loss: 0.29899072647094727
Batch 45/64 loss: 0.3083571195602417
Batch 46/64 loss: 0.29799968004226685
Batch 47/64 loss: 0.2979159355163574
Batch 48/64 loss: 0.2924402952194214
Batch 49/64 loss: 0.2975444793701172
Batch 50/64 loss: 0.30844807624816895
Batch 51/64 loss: 0.2992326021194458
Batch 52/64 loss: 0.30118703842163086
Batch 53/64 loss: 0.304496705532074
Batch 54/64 loss: 0.29200851917266846
Batch 55/64 loss: 0.29821234941482544
Batch 56/64 loss: 0.3042362332344055
Batch 57/64 loss: 0.31714457273483276
Batch 58/64 loss: 0.2924576997756958
Batch 59/64 loss: 0.3004665970802307
Batch 60/64 loss: 0.29550886154174805
Batch 61/64 loss: 0.2981557846069336
Batch 62/64 loss: 0.2962799072265625
Batch 63/64 loss: 0.3027714490890503
Batch 64/64 loss: 0.29109859466552734
Epoch 485  Train loss: 0.3001602864732929  Val loss: 0.33307386059121985
Epoch 486
-------------------------------
Batch 1/64 loss: 0.2972368001937866
Batch 2/64 loss: 0.3026081323623657
Batch 3/64 loss: 0.3024066686630249
Batch 4/64 loss: 0.298447847366333
Batch 5/64 loss: 0.31264251470565796
Batch 6/64 loss: 0.30484652519226074
Batch 7/64 loss: 0.2943922281265259
Batch 8/64 loss: 0.3043628931045532
Batch 9/64 loss: 0.30592989921569824
Batch 10/64 loss: 0.3037642240524292
Batch 11/64 loss: 0.3007690906524658
Batch 12/64 loss: 0.30345505475997925
Batch 13/64 loss: 0.29578685760498047
Batch 14/64 loss: 0.3066825866699219
Batch 15/64 loss: 0.29812633991241455
Batch 16/64 loss: 0.3008885383605957
Batch 17/64 loss: 0.29742056131362915
Batch 18/64 loss: 0.28997528553009033
Batch 19/64 loss: 0.2960554361343384
Batch 20/64 loss: 0.293226420879364
Batch 21/64 loss: 0.29790496826171875
Batch 22/64 loss: 0.3092242479324341
Batch 23/64 loss: 0.2951923608779907
Batch 24/64 loss: 0.30562543869018555
Batch 25/64 loss: 0.2998969554901123
Batch 26/64 loss: 0.30232274532318115
Batch 27/64 loss: 0.3046652674674988
Batch 28/64 loss: 0.29894351959228516
Batch 29/64 loss: 0.3007394075393677
Batch 30/64 loss: 0.29467594623565674
Batch 31/64 loss: 0.2897297143936157
Batch 32/64 loss: 0.3027980327606201
Batch 33/64 loss: 0.29104411602020264
Batch 34/64 loss: 0.2980983853340149
Batch 35/64 loss: 0.3002973794937134
Batch 36/64 loss: 0.2903026342391968
Batch 37/64 loss: 0.2927684783935547
Batch 38/64 loss: 0.3074527978897095
Batch 39/64 loss: 0.29598093032836914
Batch 40/64 loss: 0.2903594970703125
Batch 41/64 loss: 0.30073630809783936
Batch 42/64 loss: 0.29880398511886597
Batch 43/64 loss: 0.28854095935821533
Batch 44/64 loss: 0.29876458644866943
Batch 45/64 loss: 0.3008922338485718
Batch 46/64 loss: 0.3043156862258911
Batch 47/64 loss: 0.2934637665748596
Batch 48/64 loss: 0.3034411668777466
Batch 49/64 loss: 0.3066294193267822
Batch 50/64 loss: 0.29711395502090454
Batch 51/64 loss: 0.3043203353881836
Batch 52/64 loss: 0.3064669370651245
Batch 53/64 loss: 0.29347193241119385
Batch 54/64 loss: 0.30093252658843994
Batch 55/64 loss: 0.30772626399993896
Batch 56/64 loss: 0.3016878366470337
Batch 57/64 loss: 0.3003963232040405
Batch 58/64 loss: 0.29195261001586914
Batch 59/64 loss: 0.2940526008605957
Batch 60/64 loss: 0.2977665662765503
Batch 61/64 loss: 0.30044347047805786
Batch 62/64 loss: 0.29619014263153076
Batch 63/64 loss: 0.3065522313117981
Batch 64/64 loss: 0.2929345369338989
Epoch 486  Train loss: 0.29947308979782405  Val loss: 0.3323827600970711
Epoch 487
-------------------------------
Batch 1/64 loss: 0.29733002185821533
Batch 2/64 loss: 0.3097003698348999
Batch 3/64 loss: 0.2966720461845398
Batch 4/64 loss: 0.29392480850219727
Batch 5/64 loss: 0.29308760166168213
Batch 6/64 loss: 0.3017420768737793
Batch 7/64 loss: 0.2994435429573059
Batch 8/64 loss: 0.30678731203079224
Batch 9/64 loss: 0.2974069118499756
Batch 10/64 loss: 0.3013983964920044
Batch 11/64 loss: 0.29494357109069824
Batch 12/64 loss: 0.29224836826324463
Batch 13/64 loss: 0.2984124422073364
Batch 14/64 loss: 0.30426251888275146
Batch 15/64 loss: 0.3004046678543091
Batch 16/64 loss: 0.3024178743362427
Batch 17/64 loss: 0.2963979244232178
Batch 18/64 loss: 0.2931697368621826
Batch 19/64 loss: 0.29549920558929443
Batch 20/64 loss: 0.29527997970581055
Batch 21/64 loss: 0.3043854832649231
Batch 22/64 loss: 0.3068103790283203
Batch 23/64 loss: 0.31033802032470703
Batch 24/64 loss: 0.2954123616218567
Batch 25/64 loss: 0.29668283462524414
Batch 26/64 loss: 0.2945820093154907
Batch 27/64 loss: 0.2970771789550781
Batch 28/64 loss: 0.2973135709762573
Batch 29/64 loss: 0.30282795429229736
Batch 30/64 loss: 0.2972424030303955
Batch 31/64 loss: 0.29551196098327637
Batch 32/64 loss: 0.30376166105270386
Batch 33/64 loss: 0.29184240102767944
Batch 34/64 loss: 0.2936040163040161
Batch 35/64 loss: 0.3015080690383911
Batch 36/64 loss: 0.29041802883148193
Batch 37/64 loss: 0.2909398078918457
Batch 38/64 loss: 0.29867398738861084
Batch 39/64 loss: 0.2928425073623657
Batch 40/64 loss: 0.29683923721313477
Batch 41/64 loss: 0.29622507095336914
Batch 42/64 loss: 0.302842915058136
Batch 43/64 loss: 0.307580828666687
Batch 44/64 loss: 0.3006622791290283
Batch 45/64 loss: 0.3100285530090332
Batch 46/64 loss: 0.30350685119628906
Batch 47/64 loss: 0.2981778383255005
Batch 48/64 loss: 0.3009430170059204
Batch 49/64 loss: 0.2861407995223999
Batch 50/64 loss: 0.3065459132194519
Batch 51/64 loss: 0.29541683197021484
Batch 52/64 loss: 0.3101050853729248
Batch 53/64 loss: 0.30672693252563477
Batch 54/64 loss: 0.29499733448028564
Batch 55/64 loss: 0.28955650329589844
Batch 56/64 loss: 0.29978787899017334
Batch 57/64 loss: 0.3105669617652893
Batch 58/64 loss: 0.30775928497314453
Batch 59/64 loss: 0.30589860677719116
Batch 60/64 loss: 0.3093279004096985
Batch 61/64 loss: 0.29671549797058105
Batch 62/64 loss: 0.30026012659072876
Batch 63/64 loss: 0.31253087520599365
Batch 64/64 loss: 0.30640625953674316
Epoch 487  Train loss: 0.2997843424479167  Val loss: 0.3343546062810315
Epoch 488
-------------------------------
Batch 1/64 loss: 0.3009694814682007
Batch 2/64 loss: 0.3082925081253052
Batch 3/64 loss: 0.2934612035751343
Batch 4/64 loss: 0.29500067234039307
Batch 5/64 loss: 0.2972683906555176
Batch 6/64 loss: 0.3019179105758667
Batch 7/64 loss: 0.3014014959335327
Batch 8/64 loss: 0.29958879947662354
Batch 9/64 loss: 0.3070155382156372
Batch 10/64 loss: 0.2969115376472473
Batch 11/64 loss: 0.3035694360733032
Batch 12/64 loss: 0.29632043838500977
Batch 13/64 loss: 0.30230093002319336
Batch 14/64 loss: 0.29408490657806396
Batch 15/64 loss: 0.2988346815109253
Batch 16/64 loss: 0.3033754229545593
Batch 17/64 loss: 0.29716193675994873
Batch 18/64 loss: 0.29829955101013184
Batch 19/64 loss: 0.29997169971466064
Batch 20/64 loss: 0.30054110288619995
Batch 21/64 loss: 0.2999289035797119
Batch 22/64 loss: 0.30826306343078613
Batch 23/64 loss: 0.3073198199272156
Batch 24/64 loss: 0.2997407913208008
Batch 25/64 loss: 0.2929058074951172
Batch 26/64 loss: 0.2981710433959961
Batch 27/64 loss: 0.29717063903808594
Batch 28/64 loss: 0.2886706590652466
Batch 29/64 loss: 0.2966741919517517
Batch 30/64 loss: 0.2917635440826416
Batch 31/64 loss: 0.2953014373779297
Batch 32/64 loss: 0.2917560338973999
Batch 33/64 loss: 0.2983672618865967
Batch 34/64 loss: 0.2982061505317688
Batch 35/64 loss: 0.30368471145629883
Batch 36/64 loss: 0.3023238778114319
Batch 37/64 loss: 0.30709826946258545
Batch 38/64 loss: 0.2919541597366333
Batch 39/64 loss: 0.3009592890739441
Batch 40/64 loss: 0.3048202395439148
Batch 41/64 loss: 0.3084448575973511
Batch 42/64 loss: 0.2978733777999878
Batch 43/64 loss: 0.312822163105011
Batch 44/64 loss: 0.2978346347808838
Batch 45/64 loss: 0.2906258702278137
Batch 46/64 loss: 0.3024313449859619
Batch 47/64 loss: 0.298745334148407
Batch 48/64 loss: 0.3000009059906006
Batch 49/64 loss: 0.31139516830444336
Batch 50/64 loss: 0.2921909689903259
Batch 51/64 loss: 0.29261571168899536
Batch 52/64 loss: 0.2980717420578003
Batch 53/64 loss: 0.30215662717819214
Batch 54/64 loss: 0.29963332414627075
Batch 55/64 loss: 0.30886751413345337
Batch 56/64 loss: 0.30227363109588623
Batch 57/64 loss: 0.2970019578933716
Batch 58/64 loss: 0.2958568334579468
Batch 59/64 loss: 0.29641079902648926
Batch 60/64 loss: 0.2984856963157654
Batch 61/64 loss: 0.30929815769195557
Batch 62/64 loss: 0.30321288108825684
Batch 63/64 loss: 0.3046383857727051
Batch 64/64 loss: 0.29290205240249634
Epoch 488  Train loss: 0.29979501121184404  Val loss: 0.3311747533758891
Saving best model, epoch: 488
Epoch 489
-------------------------------
Batch 1/64 loss: 0.2957249879837036
Batch 2/64 loss: 0.3008124828338623
Batch 3/64 loss: 0.3027517795562744
Batch 4/64 loss: 0.3139650821685791
Batch 5/64 loss: 0.2903742790222168
Batch 6/64 loss: 0.29729944467544556
Batch 7/64 loss: 0.2882503867149353
Batch 8/64 loss: 0.2991478443145752
Batch 9/64 loss: 0.29840701818466187
Batch 10/64 loss: 0.2970709800720215
Batch 11/64 loss: 0.30279016494750977
Batch 12/64 loss: 0.2936055660247803
Batch 13/64 loss: 0.29220128059387207
Batch 14/64 loss: 0.30009984970092773
Batch 15/64 loss: 0.28780102729797363
Batch 16/64 loss: 0.30463868379592896
Batch 17/64 loss: 0.2946460247039795
Batch 18/64 loss: 0.29859209060668945
Batch 19/64 loss: 0.30286574363708496
Batch 20/64 loss: 0.3000339865684509
Batch 21/64 loss: 0.2925528287887573
Batch 22/64 loss: 0.2997034788131714
Batch 23/64 loss: 0.3032228350639343
Batch 24/64 loss: 0.30309081077575684
Batch 25/64 loss: 0.294880211353302
Batch 26/64 loss: 0.3048049211502075
Batch 27/64 loss: 0.30509519577026367
Batch 28/64 loss: 0.2977270483970642
Batch 29/64 loss: 0.297080934047699
Batch 30/64 loss: 0.2946736216545105
Batch 31/64 loss: 0.2989606261253357
Batch 32/64 loss: 0.3046327829360962
Batch 33/64 loss: 0.2936466932296753
Batch 34/64 loss: 0.3004721999168396
Batch 35/64 loss: 0.3008473515510559
Batch 36/64 loss: 0.2971090078353882
Batch 37/64 loss: 0.29907846450805664
Batch 38/64 loss: 0.3021605610847473
Batch 39/64 loss: 0.3042803406715393
Batch 40/64 loss: 0.29593515396118164
Batch 41/64 loss: 0.3064016103744507
Batch 42/64 loss: 0.3061162233352661
Batch 43/64 loss: 0.2957938313484192
Batch 44/64 loss: 0.31042903661727905
Batch 45/64 loss: 0.30306410789489746
Batch 46/64 loss: 0.3097989559173584
Batch 47/64 loss: 0.28318333625793457
Batch 48/64 loss: 0.28835034370422363
Batch 49/64 loss: 0.31041520833969116
Batch 50/64 loss: 0.29257112741470337
Batch 51/64 loss: 0.307201623916626
Batch 52/64 loss: 0.2893275022506714
Batch 53/64 loss: 0.3109080195426941
Batch 54/64 loss: 0.2999054193496704
Batch 55/64 loss: 0.3096413016319275
Batch 56/64 loss: 0.29580461978912354
Batch 57/64 loss: 0.3075001835823059
Batch 58/64 loss: 0.2992563843727112
Batch 59/64 loss: 0.3051185607910156
Batch 60/64 loss: 0.30074751377105713
Batch 61/64 loss: 0.29585593938827515
Batch 62/64 loss: 0.2998993396759033
Batch 63/64 loss: 0.29714882373809814
Batch 64/64 loss: 0.3102000951766968
Epoch 489  Train loss: 0.299735260477253  Val loss: 0.33193539364641067
Epoch 490
-------------------------------
Batch 1/64 loss: 0.3003493547439575
Batch 2/64 loss: 0.2977057695388794
Batch 3/64 loss: 0.29763853549957275
Batch 4/64 loss: 0.3090033531188965
Batch 5/64 loss: 0.29593396186828613
Batch 6/64 loss: 0.29847586154937744
Batch 7/64 loss: 0.2932843565940857
Batch 8/64 loss: 0.29702723026275635
Batch 9/64 loss: 0.30564093589782715
Batch 10/64 loss: 0.29539954662323
Batch 11/64 loss: 0.2836351990699768
Batch 12/64 loss: 0.30763566493988037
Batch 13/64 loss: 0.2921379804611206
Batch 14/64 loss: 0.3028298616409302
Batch 15/64 loss: 0.29085803031921387
Batch 16/64 loss: 0.29900026321411133
Batch 17/64 loss: 0.29804491996765137
Batch 18/64 loss: 0.31633615493774414
Batch 19/64 loss: 0.3064643144607544
Batch 20/64 loss: 0.29919326305389404
Batch 21/64 loss: 0.29711830615997314
Batch 22/64 loss: 0.30570483207702637
Batch 23/64 loss: 0.2998494505882263
Batch 24/64 loss: 0.30580246448516846
Batch 25/64 loss: 0.2960573434829712
Batch 26/64 loss: 0.30351030826568604
Batch 27/64 loss: 0.29368019104003906
Batch 28/64 loss: 0.3093603849411011
Batch 29/64 loss: 0.30251550674438477
Batch 30/64 loss: 0.30070048570632935
Batch 31/64 loss: 0.2992246150970459
Batch 32/64 loss: 0.2955722212791443
Batch 33/64 loss: 0.30186206102371216
Batch 34/64 loss: 0.29713523387908936
Batch 35/64 loss: 0.29901134967803955
Batch 36/64 loss: 0.3004644513130188
Batch 37/64 loss: 0.30397480726242065
Batch 38/64 loss: 0.2912644147872925
Batch 39/64 loss: 0.29443132877349854
Batch 40/64 loss: 0.29850465059280396
Batch 41/64 loss: 0.30694401264190674
Batch 42/64 loss: 0.29444634914398193
Batch 43/64 loss: 0.2980961203575134
Batch 44/64 loss: 0.29767048358917236
Batch 45/64 loss: 0.30481207370758057
Batch 46/64 loss: 0.3191295862197876
Batch 47/64 loss: 0.2936692237854004
Batch 48/64 loss: 0.29484641551971436
Batch 49/64 loss: 0.3017217516899109
Batch 50/64 loss: 0.294169545173645
Batch 51/64 loss: 0.3116598129272461
Batch 52/64 loss: 0.30164170265197754
Batch 53/64 loss: 0.29711735248565674
Batch 54/64 loss: 0.30246806144714355
Batch 55/64 loss: 0.2975512742996216
Batch 56/64 loss: 0.30098408460617065
Batch 57/64 loss: 0.29597043991088867
Batch 58/64 loss: 0.2917577028274536
Batch 59/64 loss: 0.2898557186126709
Batch 60/64 loss: 0.2989141345024109
Batch 61/64 loss: 0.30108559131622314
Batch 62/64 loss: 0.29403847455978394
Batch 63/64 loss: 0.29657065868377686
Batch 64/64 loss: 0.298201322555542
Epoch 490  Train loss: 0.2994684004316143  Val loss: 0.3325676086432336
Epoch 491
-------------------------------
Batch 1/64 loss: 0.3039456605911255
Batch 2/64 loss: 0.3031803369522095
Batch 3/64 loss: 0.3140549659729004
Batch 4/64 loss: 0.2929997444152832
Batch 5/64 loss: 0.30299800634384155
Batch 6/64 loss: 0.29615354537963867
Batch 7/64 loss: 0.29675978422164917
Batch 8/64 loss: 0.2932518720626831
Batch 9/64 loss: 0.2969721555709839
Batch 10/64 loss: 0.2968621253967285
Batch 11/64 loss: 0.2966846227645874
Batch 12/64 loss: 0.29625725746154785
Batch 13/64 loss: 0.3106645345687866
Batch 14/64 loss: 0.29828137159347534
Batch 15/64 loss: 0.2982584238052368
Batch 16/64 loss: 0.3042057156562805
Batch 17/64 loss: 0.3060833215713501
Batch 18/64 loss: 0.2953329086303711
Batch 19/64 loss: 0.2962043285369873
Batch 20/64 loss: 0.3047996759414673
Batch 21/64 loss: 0.30269432067871094
Batch 22/64 loss: 0.2976890802383423
Batch 23/64 loss: 0.29520928859710693
Batch 24/64 loss: 0.30186188220977783
Batch 25/64 loss: 0.2977917790412903
Batch 26/64 loss: 0.2989072799682617
Batch 27/64 loss: 0.2937731146812439
Batch 28/64 loss: 0.29223936796188354
Batch 29/64 loss: 0.29474860429763794
Batch 30/64 loss: 0.29801779985427856
Batch 31/64 loss: 0.290264368057251
Batch 32/64 loss: 0.30187565088272095
Batch 33/64 loss: 0.3008195161819458
Batch 34/64 loss: 0.30088555812835693
Batch 35/64 loss: 0.3069707155227661
Batch 36/64 loss: 0.303316593170166
Batch 37/64 loss: 0.301174521446228
Batch 38/64 loss: 0.3125801086425781
Batch 39/64 loss: 0.3034746050834656
Batch 40/64 loss: 0.30112457275390625
Batch 41/64 loss: 0.29178500175476074
Batch 42/64 loss: 0.3111635446548462
Batch 43/64 loss: 0.301303505897522
Batch 44/64 loss: 0.29422682523727417
Batch 45/64 loss: 0.3016718626022339
Batch 46/64 loss: 0.29388725757598877
Batch 47/64 loss: 0.30579566955566406
Batch 48/64 loss: 0.3003894090652466
Batch 49/64 loss: 0.2930900454521179
Batch 50/64 loss: 0.29592329263687134
Batch 51/64 loss: 0.29325318336486816
Batch 52/64 loss: 0.2996843457221985
Batch 53/64 loss: 0.29695165157318115
Batch 54/64 loss: 0.29777050018310547
Batch 55/64 loss: 0.3033972978591919
Batch 56/64 loss: 0.29923200607299805
Batch 57/64 loss: 0.3044734001159668
Batch 58/64 loss: 0.30444008111953735
Batch 59/64 loss: 0.29574835300445557
Batch 60/64 loss: 0.2978658080101013
Batch 61/64 loss: 0.3033791780471802
Batch 62/64 loss: 0.30291128158569336
Batch 63/64 loss: 0.2934872508049011
Batch 64/64 loss: 0.30679851770401
Epoch 491  Train loss: 0.29978507803935633  Val loss: 0.3317060089602913
Epoch 492
-------------------------------
Batch 1/64 loss: 0.2953343391418457
Batch 2/64 loss: 0.30572736263275146
Batch 3/64 loss: 0.29626792669296265
Batch 4/64 loss: 0.2893393039703369
Batch 5/64 loss: 0.3054633140563965
Batch 6/64 loss: 0.3017202615737915
Batch 7/64 loss: 0.2858707904815674
Batch 8/64 loss: 0.29532361030578613
Batch 9/64 loss: 0.29587292671203613
Batch 10/64 loss: 0.2975071668624878
Batch 11/64 loss: 0.29381585121154785
Batch 12/64 loss: 0.30106377601623535
Batch 13/64 loss: 0.30393266677856445
Batch 14/64 loss: 0.2908843755722046
Batch 15/64 loss: 0.3016130328178406
Batch 16/64 loss: 0.29770374298095703
Batch 17/64 loss: 0.30311286449432373
Batch 18/64 loss: 0.2950137257575989
Batch 19/64 loss: 0.30276936292648315
Batch 20/64 loss: 0.3006325364112854
Batch 21/64 loss: 0.29667043685913086
Batch 22/64 loss: 0.29649412631988525
Batch 23/64 loss: 0.2938353419303894
Batch 24/64 loss: 0.301275372505188
Batch 25/64 loss: 0.30480748414993286
Batch 26/64 loss: 0.3073669672012329
Batch 27/64 loss: 0.2988091707229614
Batch 28/64 loss: 0.3017318844795227
Batch 29/64 loss: 0.3039429187774658
Batch 30/64 loss: 0.2950209975242615
Batch 31/64 loss: 0.29743707180023193
Batch 32/64 loss: 0.30482590198516846
Batch 33/64 loss: 0.3070484399795532
Batch 34/64 loss: 0.29744184017181396
Batch 35/64 loss: 0.2937503457069397
Batch 36/64 loss: 0.2980172634124756
Batch 37/64 loss: 0.29356837272644043
Batch 38/64 loss: 0.295646607875824
Batch 39/64 loss: 0.3013204336166382
Batch 40/64 loss: 0.29955363273620605
Batch 41/64 loss: 0.29064369201660156
Batch 42/64 loss: 0.30888891220092773
Batch 43/64 loss: 0.30826491117477417
Batch 44/64 loss: 0.3013339042663574
Batch 45/64 loss: 0.3000197410583496
Batch 46/64 loss: 0.2960212230682373
Batch 47/64 loss: 0.3101545572280884
Batch 48/64 loss: 0.29960423707962036
Batch 49/64 loss: 0.29937541484832764
Batch 50/64 loss: 0.3051285147666931
Batch 51/64 loss: 0.29387080669403076
Batch 52/64 loss: 0.30965548753738403
Batch 53/64 loss: 0.3013206124305725
Batch 54/64 loss: 0.30924373865127563
Batch 55/64 loss: 0.3038545846939087
Batch 56/64 loss: 0.302554190158844
Batch 57/64 loss: 0.2852017879486084
Batch 58/64 loss: 0.30304694175720215
Batch 59/64 loss: 0.2947566509246826
Batch 60/64 loss: 0.303261935710907
Batch 61/64 loss: 0.2937614321708679
Batch 62/64 loss: 0.2985957860946655
Batch 63/64 loss: 0.29942846298217773
Batch 64/64 loss: 0.3100619316101074
Epoch 492  Train loss: 0.2995775297576306  Val loss: 0.33210808284503895
Epoch 493
-------------------------------
Batch 1/64 loss: 0.29404646158218384
Batch 2/64 loss: 0.29863113164901733
Batch 3/64 loss: 0.2882120609283447
Batch 4/64 loss: 0.30128031969070435
Batch 5/64 loss: 0.29570817947387695
Batch 6/64 loss: 0.29003024101257324
Batch 7/64 loss: 0.29160284996032715
Batch 8/64 loss: 0.30156099796295166
Batch 9/64 loss: 0.29867541790008545
Batch 10/64 loss: 0.308308482170105
Batch 11/64 loss: 0.30440306663513184
Batch 12/64 loss: 0.29176342487335205
Batch 13/64 loss: 0.3022085428237915
Batch 14/64 loss: 0.29625260829925537
Batch 15/64 loss: 0.3015327453613281
Batch 16/64 loss: 0.2982443571090698
Batch 17/64 loss: 0.29985541105270386
Batch 18/64 loss: 0.29886412620544434
Batch 19/64 loss: 0.295945405960083
Batch 20/64 loss: 0.3073115348815918
Batch 21/64 loss: 0.2925851345062256
Batch 22/64 loss: 0.2965654134750366
Batch 23/64 loss: 0.29510360956192017
Batch 24/64 loss: 0.29904037714004517
Batch 25/64 loss: 0.2889751195907593
Batch 26/64 loss: 0.3008805513381958
Batch 27/64 loss: 0.30051565170288086
Batch 28/64 loss: 0.2981264591217041
Batch 29/64 loss: 0.2933356761932373
Batch 30/64 loss: 0.2948960065841675
Batch 31/64 loss: 0.2955120801925659
Batch 32/64 loss: 0.29581403732299805
Batch 33/64 loss: 0.2905222177505493
Batch 34/64 loss: 0.30525797605514526
Batch 35/64 loss: 0.298641562461853
Batch 36/64 loss: 0.30573898553848267
Batch 37/64 loss: 0.2970149517059326
Batch 38/64 loss: 0.3049873113632202
Batch 39/64 loss: 0.29323041439056396
Batch 40/64 loss: 0.2998334765434265
Batch 41/64 loss: 0.2976500988006592
Batch 42/64 loss: 0.3067162036895752
Batch 43/64 loss: 0.29409539699554443
Batch 44/64 loss: 0.3031628727912903
Batch 45/64 loss: 0.30520689487457275
Batch 46/64 loss: 0.30068933963775635
Batch 47/64 loss: 0.2955077290534973
Batch 48/64 loss: 0.31306320428848267
Batch 49/64 loss: 0.3015042543411255
Batch 50/64 loss: 0.3052023649215698
Batch 51/64 loss: 0.31347858905792236
Batch 52/64 loss: 0.2986716628074646
Batch 53/64 loss: 0.2972208261489868
Batch 54/64 loss: 0.3105429410934448
Batch 55/64 loss: 0.2955995798110962
Batch 56/64 loss: 0.2906677722930908
Batch 57/64 loss: 0.305420458316803
Batch 58/64 loss: 0.30705344676971436
Batch 59/64 loss: 0.30875927209854126
Batch 60/64 loss: 0.30777740478515625
Batch 61/64 loss: 0.29932260513305664
Batch 62/64 loss: 0.3040255308151245
Batch 63/64 loss: 0.30091220140457153
Batch 64/64 loss: 0.2983301877975464
Epoch 493  Train loss: 0.2995609830407535  Val loss: 0.3328447587711295
Epoch 494
-------------------------------
Batch 1/64 loss: 0.3002766966819763
Batch 2/64 loss: 0.2991163730621338
Batch 3/64 loss: 0.30408960580825806
Batch 4/64 loss: 0.30368226766586304
Batch 5/64 loss: 0.30028998851776123
Batch 6/64 loss: 0.2904402017593384
Batch 7/64 loss: 0.290111780166626
Batch 8/64 loss: 0.29113876819610596
Batch 9/64 loss: 0.30637097358703613
Batch 10/64 loss: 0.29498612880706787
Batch 11/64 loss: 0.30497968196868896
Batch 12/64 loss: 0.2972046136856079
Batch 13/64 loss: 0.2973092198371887
Batch 14/64 loss: 0.30047911405563354
Batch 15/64 loss: 0.29747194051742554
Batch 16/64 loss: 0.29888391494750977
Batch 17/64 loss: 0.3135179877281189
Batch 18/64 loss: 0.301851749420166
Batch 19/64 loss: 0.3095383644104004
Batch 20/64 loss: 0.3001159429550171
Batch 21/64 loss: 0.295900821685791
Batch 22/64 loss: 0.30041205883026123
Batch 23/64 loss: 0.3154984712600708
Batch 24/64 loss: 0.29364776611328125
Batch 25/64 loss: 0.30436551570892334
Batch 26/64 loss: 0.3013797402381897
Batch 27/64 loss: 0.2941223382949829
Batch 28/64 loss: 0.29901909828186035
Batch 29/64 loss: 0.2960208058357239
Batch 30/64 loss: 0.29253488779067993
Batch 31/64 loss: 0.3022403120994568
Batch 32/64 loss: 0.2988523840904236
Batch 33/64 loss: 0.31297212839126587
Batch 34/64 loss: 0.2967667579650879
Batch 35/64 loss: 0.2928640842437744
Batch 36/64 loss: 0.2978501319885254
Batch 37/64 loss: 0.2879865765571594
Batch 38/64 loss: 0.3021981716156006
Batch 39/64 loss: 0.2976924777030945
Batch 40/64 loss: 0.30065375566482544
Batch 41/64 loss: 0.28960978984832764
Batch 42/64 loss: 0.28368306159973145
Batch 43/64 loss: 0.2982613444328308
Batch 44/64 loss: 0.29405856132507324
Batch 45/64 loss: 0.2979925870895386
Batch 46/64 loss: 0.2996460199356079
Batch 47/64 loss: 0.2997528314590454
Batch 48/64 loss: 0.30492621660232544
Batch 49/64 loss: 0.2990422248840332
Batch 50/64 loss: 0.29530954360961914
Batch 51/64 loss: 0.303802490234375
Batch 52/64 loss: 0.3027747869491577
Batch 53/64 loss: 0.3000451326370239
Batch 54/64 loss: 0.2984299659729004
Batch 55/64 loss: 0.30472666025161743
Batch 56/64 loss: 0.2950986623764038
Batch 57/64 loss: 0.30496352910995483
Batch 58/64 loss: 0.30588269233703613
Batch 59/64 loss: 0.2968456745147705
Batch 60/64 loss: 0.29394662380218506
Batch 61/64 loss: 0.2963387966156006
Batch 62/64 loss: 0.3134080171585083
Batch 63/64 loss: 0.3017401099205017
Batch 64/64 loss: 0.3008633852005005
Epoch 494  Train loss: 0.2994630032894658  Val loss: 0.331536415516306
Epoch 495
-------------------------------
Batch 1/64 loss: 0.2971900701522827
Batch 2/64 loss: 0.290630578994751
Batch 3/64 loss: 0.2957192659378052
Batch 4/64 loss: 0.2892230749130249
Batch 5/64 loss: 0.29473239183425903
Batch 6/64 loss: 0.3018830418586731
Batch 7/64 loss: 0.3118633031845093
Batch 8/64 loss: 0.30333757400512695
Batch 9/64 loss: 0.2922525405883789
Batch 10/64 loss: 0.3034074306488037
Batch 11/64 loss: 0.30095207691192627
Batch 12/64 loss: 0.2984561324119568
Batch 13/64 loss: 0.29180264472961426
Batch 14/64 loss: 0.29229211807250977
Batch 15/64 loss: 0.30300021171569824
Batch 16/64 loss: 0.29880213737487793
Batch 17/64 loss: 0.30077147483825684
Batch 18/64 loss: 0.2989169955253601
Batch 19/64 loss: 0.2929975986480713
Batch 20/64 loss: 0.30007636547088623
Batch 21/64 loss: 0.29528093338012695
Batch 22/64 loss: 0.31340140104293823
Batch 23/64 loss: 0.3004717230796814
Batch 24/64 loss: 0.2965351343154907
Batch 25/64 loss: 0.30443525314331055
Batch 26/64 loss: 0.2998439073562622
Batch 27/64 loss: 0.29619866609573364
Batch 28/64 loss: 0.29723232984542847
Batch 29/64 loss: 0.30363714694976807
Batch 30/64 loss: 0.30282819271087646
Batch 31/64 loss: 0.30222487449645996
Batch 32/64 loss: 0.3021312952041626
Batch 33/64 loss: 0.3024175763130188
Batch 34/64 loss: 0.29786521196365356
Batch 35/64 loss: 0.2941676378250122
Batch 36/64 loss: 0.2918388247489929
Batch 37/64 loss: 0.2924485206604004
Batch 38/64 loss: 0.3027222156524658
Batch 39/64 loss: 0.3017817735671997
Batch 40/64 loss: 0.3067505955696106
Batch 41/64 loss: 0.2850226163864136
Batch 42/64 loss: 0.29959768056869507
Batch 43/64 loss: 0.29945552349090576
Batch 44/64 loss: 0.29100579023361206
Batch 45/64 loss: 0.3117361068725586
Batch 46/64 loss: 0.30127155780792236
Batch 47/64 loss: 0.3017308712005615
Batch 48/64 loss: 0.29549509286880493
Batch 49/64 loss: 0.3026413917541504
Batch 50/64 loss: 0.2898452877998352
Batch 51/64 loss: 0.31280070543289185
Batch 52/64 loss: 0.2885618209838867
Batch 53/64 loss: 0.3011256456375122
Batch 54/64 loss: 0.3039522171020508
Batch 55/64 loss: 0.3080565929412842
Batch 56/64 loss: 0.29888367652893066
Batch 57/64 loss: 0.3124315142631531
Batch 58/64 loss: 0.2944035530090332
Batch 59/64 loss: 0.28937840461730957
Batch 60/64 loss: 0.2932617664337158
Batch 61/64 loss: 0.29966211318969727
Batch 62/64 loss: 0.30255943536758423
Batch 63/64 loss: 0.30543071031570435
Batch 64/64 loss: 0.2915878891944885
Epoch 495  Train loss: 0.2991297448382658  Val loss: 0.33321603835653196
Epoch 496
-------------------------------
Batch 1/64 loss: 0.28908342123031616
Batch 2/64 loss: 0.31262147426605225
Batch 3/64 loss: 0.2913217544555664
Batch 4/64 loss: 0.2950935363769531
Batch 5/64 loss: 0.29878121614456177
Batch 6/64 loss: 0.29518890380859375
Batch 7/64 loss: 0.3008831739425659
Batch 8/64 loss: 0.2934027910232544
Batch 9/64 loss: 0.29550766944885254
Batch 10/64 loss: 0.29952430725097656
Batch 11/64 loss: 0.30118465423583984
Batch 12/64 loss: 0.2949739098548889
Batch 13/64 loss: 0.3080213665962219
Batch 14/64 loss: 0.30059897899627686
Batch 15/64 loss: 0.29787659645080566
Batch 16/64 loss: 0.3046702742576599
Batch 17/64 loss: 0.30506253242492676
Batch 18/64 loss: 0.2956496477127075
Batch 19/64 loss: 0.30112719535827637
Batch 20/64 loss: 0.3008054494857788
Batch 21/64 loss: 0.29132771492004395
Batch 22/64 loss: 0.29373592138290405
Batch 23/64 loss: 0.30097460746765137
Batch 24/64 loss: 0.3053426146507263
Batch 25/64 loss: 0.28863173723220825
Batch 26/64 loss: 0.2944514751434326
Batch 27/64 loss: 0.29787588119506836
Batch 28/64 loss: 0.2988850474357605
Batch 29/64 loss: 0.29951047897338867
Batch 30/64 loss: 0.3084133267402649
Batch 31/64 loss: 0.3081986904144287
Batch 32/64 loss: 0.3078920245170593
Batch 33/64 loss: 0.29747843742370605
Batch 34/64 loss: 0.3012145161628723
Batch 35/64 loss: 0.2944849729537964
Batch 36/64 loss: 0.30060791969299316
Batch 37/64 loss: 0.31889230012893677
Batch 38/64 loss: 0.29220348596572876
Batch 39/64 loss: 0.2966189384460449
Batch 40/64 loss: 0.2940422296524048
Batch 41/64 loss: 0.3007103204727173
Batch 42/64 loss: 0.29278069734573364
Batch 43/64 loss: 0.3045576810836792
Batch 44/64 loss: 0.2899206280708313
Batch 45/64 loss: 0.3022010326385498
Batch 46/64 loss: 0.30007684230804443
Batch 47/64 loss: 0.30041688680648804
Batch 48/64 loss: 0.2965095639228821
Batch 49/64 loss: 0.3032137155532837
Batch 50/64 loss: 0.3044729232788086
Batch 51/64 loss: 0.3098268508911133
Batch 52/64 loss: 0.2933642864227295
Batch 53/64 loss: 0.30284935235977173
Batch 54/64 loss: 0.29479002952575684
Batch 55/64 loss: 0.29707658290863037
Batch 56/64 loss: 0.3023265600204468
Batch 57/64 loss: 0.2956545948982239
Batch 58/64 loss: 0.2940511703491211
Batch 59/64 loss: 0.3012293577194214
Batch 60/64 loss: 0.30358022451400757
Batch 61/64 loss: 0.3038264513015747
Batch 62/64 loss: 0.30203819274902344
Batch 63/64 loss: 0.29117417335510254
Batch 64/64 loss: 0.3029840588569641
Epoch 496  Train loss: 0.29938897782681034  Val loss: 0.33240714351745815
Epoch 497
-------------------------------
Batch 1/64 loss: 0.30502402782440186
Batch 2/64 loss: 0.2939549684524536
Batch 3/64 loss: 0.2948983311653137
Batch 4/64 loss: 0.296220064163208
Batch 5/64 loss: 0.29498666524887085
Batch 6/64 loss: 0.30428826808929443
Batch 7/64 loss: 0.304998517036438
Batch 8/64 loss: 0.3005329370498657
Batch 9/64 loss: 0.2975350022315979
Batch 10/64 loss: 0.29733961820602417
Batch 11/64 loss: 0.30507606267929077
Batch 12/64 loss: 0.2909253239631653
Batch 13/64 loss: 0.3069535493850708
Batch 14/64 loss: 0.29502832889556885
Batch 15/64 loss: 0.30304014682769775
Batch 16/64 loss: 0.2981981635093689
Batch 17/64 loss: 0.30901575088500977
Batch 18/64 loss: 0.2982627749443054
Batch 19/64 loss: 0.2901902198791504
Batch 20/64 loss: 0.29932790994644165
Batch 21/64 loss: 0.30548858642578125
Batch 22/64 loss: 0.3010762929916382
Batch 23/64 loss: 0.30353569984436035
Batch 24/64 loss: 0.2996896505355835
Batch 25/64 loss: 0.28916192054748535
Batch 26/64 loss: 0.3039466142654419
Batch 27/64 loss: 0.3073839545249939
Batch 28/64 loss: 0.2969539761543274
Batch 29/64 loss: 0.29165875911712646
Batch 30/64 loss: 0.29883694648742676
Batch 31/64 loss: 0.29998159408569336
Batch 32/64 loss: 0.2958635091781616
Batch 33/64 loss: 0.30527639389038086
Batch 34/64 loss: 0.2998138666152954
Batch 35/64 loss: 0.3033924102783203
Batch 36/64 loss: 0.3060303330421448
Batch 37/64 loss: 0.295168399810791
Batch 38/64 loss: 0.30775225162506104
Batch 39/64 loss: 0.295712947845459
Batch 40/64 loss: 0.30063140392303467
Batch 41/64 loss: 0.2953587770462036
Batch 42/64 loss: 0.2957019805908203
Batch 43/64 loss: 0.3014291524887085
Batch 44/64 loss: 0.3006558418273926
Batch 45/64 loss: 0.30112195014953613
Batch 46/64 loss: 0.29255080223083496
Batch 47/64 loss: 0.29529058933258057
Batch 48/64 loss: 0.30804431438446045
Batch 49/64 loss: 0.29758399724960327
Batch 50/64 loss: 0.29618561267852783
Batch 51/64 loss: 0.2986460328102112
Batch 52/64 loss: 0.30574893951416016
Batch 53/64 loss: 0.2959081530570984
Batch 54/64 loss: 0.29944413900375366
Batch 55/64 loss: 0.2942623496055603
Batch 56/64 loss: 0.30265098810195923
Batch 57/64 loss: 0.2997654676437378
Batch 58/64 loss: 0.30376315116882324
Batch 59/64 loss: 0.3024928569793701
Batch 60/64 loss: 0.3007928133010864
Batch 61/64 loss: 0.2961384654045105
Batch 62/64 loss: 0.29472076892852783
Batch 63/64 loss: 0.3075103759765625
Batch 64/64 loss: 0.3097658157348633
Epoch 497  Train loss: 0.29978421996621524  Val loss: 0.3315907259986982
Epoch 498
-------------------------------
Batch 1/64 loss: 0.3040006756782532
Batch 2/64 loss: 0.29582202434539795
Batch 3/64 loss: 0.3005160093307495
Batch 4/64 loss: 0.29574429988861084
Batch 5/64 loss: 0.29155433177948
Batch 6/64 loss: 0.29653817415237427
Batch 7/64 loss: 0.300262451171875
Batch 8/64 loss: 0.2987624406814575
Batch 9/64 loss: 0.3049473762512207
Batch 10/64 loss: 0.30172479152679443
Batch 11/64 loss: 0.29848289489746094
Batch 12/64 loss: 0.28695547580718994
Batch 13/64 loss: 0.2885262966156006
Batch 14/64 loss: 0.3005034923553467
Batch 15/64 loss: 0.2998257875442505
Batch 16/64 loss: 0.2939397096633911
Batch 17/64 loss: 0.30270326137542725
Batch 18/64 loss: 0.31063783168792725
Batch 19/64 loss: 0.2928197383880615
Batch 20/64 loss: 0.2967715859413147
Batch 21/64 loss: 0.31659889221191406
Batch 22/64 loss: 0.29871439933776855
Batch 23/64 loss: 0.30300045013427734
Batch 24/64 loss: 0.2953857183456421
Batch 25/64 loss: 0.30453968048095703
Batch 26/64 loss: 0.2964978814125061
Batch 27/64 loss: 0.29572319984436035
Batch 28/64 loss: 0.2956581711769104
Batch 29/64 loss: 0.2933225631713867
Batch 30/64 loss: 0.3012899160385132
Batch 31/64 loss: 0.31074291467666626
Batch 32/64 loss: 0.3025343418121338
Batch 33/64 loss: 0.29783445596694946
Batch 34/64 loss: 0.30426788330078125
Batch 35/64 loss: 0.29671186208724976
Batch 36/64 loss: 0.29457712173461914
Batch 37/64 loss: 0.2928600311279297
Batch 38/64 loss: 0.30012691020965576
Batch 39/64 loss: 0.312553346157074
Batch 40/64 loss: 0.3015996217727661
Batch 41/64 loss: 0.3069140911102295
Batch 42/64 loss: 0.30207061767578125
Batch 43/64 loss: 0.2945792078971863
Batch 44/64 loss: 0.3005363345146179
Batch 45/64 loss: 0.2986464500427246
Batch 46/64 loss: 0.30992257595062256
Batch 47/64 loss: 0.2954317331314087
Batch 48/64 loss: 0.3058527708053589
Batch 49/64 loss: 0.30033349990844727
Batch 50/64 loss: 0.30151838064193726
Batch 51/64 loss: 0.3012148141860962
Batch 52/64 loss: 0.2938612699508667
Batch 53/64 loss: 0.2927478551864624
Batch 54/64 loss: 0.30037105083465576
Batch 55/64 loss: 0.29329681396484375
Batch 56/64 loss: 0.30419981479644775
Batch 57/64 loss: 0.3012394309043884
Batch 58/64 loss: 0.2940613627433777
Batch 59/64 loss: 0.29957473278045654
Batch 60/64 loss: 0.299405574798584
Batch 61/64 loss: 0.29724812507629395
Batch 62/64 loss: 0.29550474882125854
Batch 63/64 loss: 0.2976332902908325
Batch 64/64 loss: 0.3072878122329712
Epoch 498  Train loss: 0.2994856222003114  Val loss: 0.3325990092303745
Epoch 499
-------------------------------
Batch 1/64 loss: 0.2950577735900879
Batch 2/64 loss: 0.29460984468460083
Batch 3/64 loss: 0.2954751253128052
Batch 4/64 loss: 0.2955673336982727
Batch 5/64 loss: 0.29771149158477783
Batch 6/64 loss: 0.3036497235298157
Batch 7/64 loss: 0.29382026195526123
Batch 8/64 loss: 0.3076796531677246
Batch 9/64 loss: 0.29194700717926025
Batch 10/64 loss: 0.29704785346984863
Batch 11/64 loss: 0.3018535375595093
Batch 12/64 loss: 0.2930572032928467
Batch 13/64 loss: 0.2961912751197815
Batch 14/64 loss: 0.29713940620422363
Batch 15/64 loss: 0.2974868416786194
Batch 16/64 loss: 0.28991734981536865
Batch 17/64 loss: 0.2955296039581299
Batch 18/64 loss: 0.28655779361724854
Batch 19/64 loss: 0.2996124029159546
Batch 20/64 loss: 0.29973340034484863
Batch 21/64 loss: 0.30647897720336914
Batch 22/64 loss: 0.2971608638763428
Batch 23/64 loss: 0.29637885093688965
Batch 24/64 loss: 0.30263853073120117
Batch 25/64 loss: 0.2945252060890198
Batch 26/64 loss: 0.30152177810668945
Batch 27/64 loss: 0.30671191215515137
Batch 28/64 loss: 0.314106285572052
Batch 29/64 loss: 0.2960982322692871
Batch 30/64 loss: 0.2912389039993286
Batch 31/64 loss: 0.302107036113739
Batch 32/64 loss: 0.30205732583999634
Batch 33/64 loss: 0.2969213128089905
Batch 34/64 loss: 0.297532856464386
Batch 35/64 loss: 0.29866302013397217
Batch 36/64 loss: 0.2954312562942505
Batch 37/64 loss: 0.2914546728134155
Batch 38/64 loss: 0.30186545848846436
Batch 39/64 loss: 0.3104791045188904
Batch 40/64 loss: 0.3079094886779785
Batch 41/64 loss: 0.30085837841033936
Batch 42/64 loss: 0.2947275638580322
Batch 43/64 loss: 0.29175740480422974
Batch 44/64 loss: 0.29549455642700195
Batch 45/64 loss: 0.30608421564102173
Batch 46/64 loss: 0.2990657091140747
Batch 47/64 loss: 0.31330859661102295
Batch 48/64 loss: 0.29224884510040283
Batch 49/64 loss: 0.29473352432250977
Batch 50/64 loss: 0.29330456256866455
Batch 51/64 loss: 0.2913477420806885
Batch 52/64 loss: 0.3106590509414673
Batch 53/64 loss: 0.29038774967193604
Batch 54/64 loss: 0.30201125144958496
Batch 55/64 loss: 0.3105736970901489
Batch 56/64 loss: 0.3047674298286438
Batch 57/64 loss: 0.3045210838317871
Batch 58/64 loss: 0.30186927318573
Batch 59/64 loss: 0.30330950021743774
Batch 60/64 loss: 0.3146207332611084
Batch 61/64 loss: 0.30090558528900146
Batch 62/64 loss: 0.3027738332748413
Batch 63/64 loss: 0.2965015172958374
Batch 64/64 loss: 0.3178125023841858
Epoch 499  Train loss: 0.2995312492052714  Val loss: 0.33255485468304036
Epoch 500
-------------------------------
Batch 1/64 loss: 0.2951672077178955
Batch 2/64 loss: 0.30356407165527344
Batch 3/64 loss: 0.28889161348342896
Batch 4/64 loss: 0.29980605840682983
Batch 5/64 loss: 0.2997860908508301
Batch 6/64 loss: 0.2947643995285034
Batch 7/64 loss: 0.29343342781066895
Batch 8/64 loss: 0.2966012954711914
Batch 9/64 loss: 0.30071306228637695
Batch 10/64 loss: 0.2925560474395752
Batch 11/64 loss: 0.29784178733825684
Batch 12/64 loss: 0.31018054485321045
Batch 13/64 loss: 0.29743099212646484
Batch 14/64 loss: 0.2983020544052124
Batch 15/64 loss: 0.29870760440826416
Batch 16/64 loss: 0.28925180435180664
Batch 17/64 loss: 0.2902376055717468
Batch 18/64 loss: 0.2909989356994629
Batch 19/64 loss: 0.29987776279449463
Batch 20/64 loss: 0.30790191888809204
Batch 21/64 loss: 0.29489362239837646
Batch 22/64 loss: 0.29066038131713867
Batch 23/64 loss: 0.29603731632232666
Batch 24/64 loss: 0.29702329635620117
Batch 25/64 loss: 0.3040435314178467
Batch 26/64 loss: 0.30526459217071533
Batch 27/64 loss: 0.3081968426704407
Batch 28/64 loss: 0.30158841609954834
Batch 29/64 loss: 0.3124050498008728
Batch 30/64 loss: 0.3070073127746582
Batch 31/64 loss: 0.30080342292785645
Batch 32/64 loss: 0.2999436855316162
Batch 33/64 loss: 0.3030935525894165
Batch 34/64 loss: 0.29732203483581543
Batch 35/64 loss: 0.2931596040725708
Batch 36/64 loss: 0.29187971353530884
Batch 37/64 loss: 0.31632208824157715
Batch 38/64 loss: 0.30752813816070557
Batch 39/64 loss: 0.29770541191101074
Batch 40/64 loss: 0.30772650241851807
Batch 41/64 loss: 0.30065226554870605
Batch 42/64 loss: 0.30107080936431885
Batch 43/64 loss: 0.2935359477996826
Batch 44/64 loss: 0.2971683144569397
Batch 45/64 loss: 0.29617393016815186
Batch 46/64 loss: 0.30306488275527954
Batch 47/64 loss: 0.2911262512207031
Batch 48/64 loss: 0.29805445671081543
Batch 49/64 loss: 0.30702096223831177
Batch 50/64 loss: 0.3002643585205078
Batch 51/64 loss: 0.299515962600708
Batch 52/64 loss: 0.308413565158844
Batch 53/64 loss: 0.30806565284729004
Batch 54/64 loss: 0.30370932817459106
Batch 55/64 loss: 0.2949399948120117
Batch 56/64 loss: 0.297995388507843
Batch 57/64 loss: 0.29512548446655273
Batch 58/64 loss: 0.299533486366272
Batch 59/64 loss: 0.2954518795013428
Batch 60/64 loss: 0.2980935573577881
Batch 61/64 loss: 0.29456400871276855
Batch 62/64 loss: 0.30932849645614624
Batch 63/64 loss: 0.3091622591018677
Batch 64/64 loss: 0.3015096187591553
Epoch 500  Train loss: 0.2997142314910889  Val loss: 0.3329389707739001
SLIC undersegmentation error: 0.054052233676975946
SLIC inter-cluster variation: 0.02397972047789259
SLIC number of superpixels: 162588
SLIC superpixels per image: 558.7216494845361
Model loaded
Test metrics:
0.32881605133567887 0.16968247422680413 22.350651448458112 tensor(0.1223, dtype=torch.float64) 0.4564602960969044 1.8661956034096008 44580
Inference time: 0.003911107676135716 seconds
Relabeled undersegmentation error: 0.09391890034364266
Relabeled inter-cluster variation: 0.060785088901906786
Relabeled mean superpixels count: 285.893470790378
Original mean superpixels count: 153.19931271477662
Done!
Job id: 420583
Job id: 422811
Job id: 422895
