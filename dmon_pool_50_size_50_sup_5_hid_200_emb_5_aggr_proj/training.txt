Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 4.554407596588135
Batch 2/64 loss: 4.587394714355469
Batch 3/64 loss: 4.556407928466797
Batch 4/64 loss: 4.541653633117676
Batch 5/64 loss: 4.527004718780518
Batch 6/64 loss: 4.525717258453369
Batch 7/64 loss: 4.514603614807129
Batch 8/64 loss: 4.515312671661377
Batch 9/64 loss: 4.504226207733154
Batch 10/64 loss: 4.4883713722229
Batch 11/64 loss: 4.484706878662109
Batch 12/64 loss: 4.479480266571045
Batch 13/64 loss: 4.472744464874268
Batch 14/64 loss: 4.459510326385498
Batch 15/64 loss: 4.462519645690918
Batch 16/64 loss: 4.457731246948242
Batch 17/64 loss: 4.436284065246582
Batch 18/64 loss: 4.502269268035889
Batch 19/64 loss: 4.4481611251831055
Batch 20/64 loss: 4.428166389465332
Batch 21/64 loss: 4.429089069366455
Batch 22/64 loss: 4.405829429626465
Batch 23/64 loss: 4.418790340423584
Batch 24/64 loss: 4.400931358337402
Batch 25/64 loss: 4.370945930480957
Batch 26/64 loss: 4.339028835296631
Batch 27/64 loss: 4.350229740142822
Batch 28/64 loss: 4.334369659423828
Batch 29/64 loss: 4.291538238525391
Batch 30/64 loss: 4.305185794830322
Batch 31/64 loss: 4.276449680328369
Batch 32/64 loss: 4.2606611251831055
Batch 33/64 loss: 4.205154895782471
Batch 34/64 loss: 4.157138824462891
Batch 35/64 loss: 4.198393821716309
Batch 36/64 loss: 4.165984630584717
Batch 37/64 loss: 4.074079513549805
Batch 38/64 loss: 4.024566173553467
Batch 39/64 loss: 3.832761287689209
Batch 40/64 loss: 3.924903392791748
Batch 41/64 loss: 3.806196689605713
Batch 42/64 loss: 4.043364524841309
Batch 43/64 loss: 4.029134273529053
Batch 44/64 loss: 4.0085954666137695
Batch 45/64 loss: 3.8520820140838623
Batch 46/64 loss: 3.7614262104034424
Batch 47/64 loss: 3.8374876976013184
Batch 48/64 loss: 3.702195167541504
Batch 49/64 loss: 3.7520735263824463
Batch 50/64 loss: 3.527940511703491
Batch 51/64 loss: 3.6251025199890137
Batch 52/64 loss: 3.4456820487976074
Batch 53/64 loss: 3.3819751739501953
Batch 54/64 loss: 3.314718246459961
Batch 55/64 loss: 3.271406650543213
Batch 56/64 loss: 3.375032663345337
Batch 57/64 loss: 3.073822259902954
Batch 58/64 loss: 3.096653938293457
Batch 59/64 loss: 3.135438919067383
Batch 60/64 loss: 3.1607024669647217
Batch 61/64 loss: 2.920867681503296
Batch 62/64 loss: 3.060555934906006
Batch 63/64 loss: 3.0178468227386475
Batch 64/64 loss: 0.6756720542907715
Epoch 1  Train loss: 4.006584479762059  Val loss: 3.376117326139994
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 2.85009503364563
Batch 2/64 loss: 2.9306740760803223
Batch 3/64 loss: 3.00268816947937
Batch 4/64 loss: 2.7220518589019775
Batch 5/64 loss: 2.689314365386963
Batch 6/64 loss: 2.7636208534240723
Batch 7/64 loss: 2.6292004585266113
Batch 8/64 loss: 2.6307363510131836
Batch 9/64 loss: 2.9712281227111816
Batch 10/64 loss: 2.6953907012939453
Batch 11/64 loss: 2.463168144226074
Batch 12/64 loss: 2.50839900970459
Batch 13/64 loss: 2.47178316116333
Batch 14/64 loss: 2.120319366455078
Batch 15/64 loss: 3.1165666580200195
Batch 16/64 loss: 2.0758819580078125
Batch 17/64 loss: 2.4547924995422363
Batch 18/64 loss: 2.352329730987549
Batch 19/64 loss: 2.1999874114990234
Batch 20/64 loss: 2.2283310890197754
Batch 21/64 loss: 2.2721471786499023
Batch 22/64 loss: 2.0996665954589844
Batch 23/64 loss: 2.1830391883850098
Batch 24/64 loss: 2.152121067047119
Batch 25/64 loss: 2.2327685356140137
Batch 26/64 loss: 2.0170302391052246
Batch 27/64 loss: 1.9909777641296387
Batch 28/64 loss: 1.8008198738098145
Batch 29/64 loss: 2.035274028778076
Batch 30/64 loss: 1.705845832824707
Batch 31/64 loss: 2.029470920562744
Batch 32/64 loss: 1.8616104125976562
Batch 33/64 loss: 1.6154494285583496
Batch 34/64 loss: 1.6215181350708008
Batch 35/64 loss: 1.5718350410461426
Batch 36/64 loss: 1.410600185394287
Batch 37/64 loss: 1.484785556793213
Batch 38/64 loss: 1.7161836624145508
Batch 39/64 loss: 1.387742519378662
Batch 40/64 loss: 1.319359302520752
Batch 41/64 loss: 1.2881546020507812
Batch 42/64 loss: 1.2817721366882324
Batch 43/64 loss: 1.0288004875183105
Batch 44/64 loss: 1.3612899780273438
Batch 45/64 loss: 1.2284822463989258
Batch 46/64 loss: 1.3497838973999023
Batch 47/64 loss: 1.1091623306274414
Batch 48/64 loss: 1.3749661445617676
Batch 49/64 loss: 1.0083966255187988
Batch 50/64 loss: 0.9476227760314941
Batch 51/64 loss: 0.9762897491455078
Batch 52/64 loss: 1.3570303916931152
Batch 53/64 loss: 1.0606842041015625
Batch 54/64 loss: 1.1127934455871582
Batch 55/64 loss: 0.8754024505615234
Batch 56/64 loss: 0.7817988395690918
Batch 57/64 loss: 1.1483216285705566
Batch 58/64 loss: 0.7195825576782227
Batch 59/64 loss: 0.7134356498718262
Batch 60/64 loss: 0.8766756057739258
Batch 61/64 loss: 0.7180061340332031
Batch 62/64 loss: 0.7098431587219238
Batch 63/64 loss: 0.47469139099121094
Batch 64/64 loss: -3.024533271789551
Epoch 2  Train loss: 1.719519858266793  Val loss: 1.2362005620477945
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 1.0905885696411133
Batch 2/64 loss: 0.9151091575622559
Batch 3/64 loss: 0.6478409767150879
Batch 4/64 loss: 0.6099119186401367
Batch 5/64 loss: 2.0307388305664062
Batch 6/64 loss: 0.5974135398864746
Batch 7/64 loss: 2.311666965484619
Batch 8/64 loss: 0.770289421081543
Batch 9/64 loss: 1.1475329399108887
Batch 10/64 loss: 0.668541431427002
Batch 11/64 loss: 1.1556849479675293
Batch 12/64 loss: 0.891477108001709
Batch 13/64 loss: 1.394862174987793
Batch 14/64 loss: 1.1493687629699707
Batch 15/64 loss: 0.6808390617370605
Batch 16/64 loss: 0.7787351608276367
Batch 17/64 loss: 1.0186748504638672
Batch 18/64 loss: 0.7937421798706055
Batch 19/64 loss: 0.5509552955627441
Batch 20/64 loss: 0.8493466377258301
Batch 21/64 loss: 0.8816876411437988
Batch 22/64 loss: 0.543705940246582
Batch 23/64 loss: 0.45344114303588867
Batch 24/64 loss: 0.29157447814941406
Batch 25/64 loss: 0.2918558120727539
Batch 26/64 loss: 0.5119442939758301
Batch 27/64 loss: 0.7600059509277344
Batch 28/64 loss: 0.6092724800109863
Batch 29/64 loss: 0.22270679473876953
Batch 30/64 loss: 0.12799358367919922
Batch 31/64 loss: 0.7011604309082031
Batch 32/64 loss: 0.3788309097290039
Batch 33/64 loss: 0.46067094802856445
Batch 34/64 loss: 0.8696355819702148
Batch 35/64 loss: 0.4954719543457031
Batch 36/64 loss: 0.2976818084716797
Batch 37/64 loss: 0.6939172744750977
Batch 38/64 loss: 0.8064956665039062
Batch 39/64 loss: 0.272369384765625
Batch 40/64 loss: 0.3269228935241699
Batch 41/64 loss: 0.630681037902832
Batch 42/64 loss: 0.6236276626586914
Batch 43/64 loss: 0.20646429061889648
Batch 44/64 loss: 0.7250986099243164
Batch 45/64 loss: 1.054286003112793
Batch 46/64 loss: 0.2548713684082031
Batch 47/64 loss: 0.519770622253418
Batch 48/64 loss: 0.5327177047729492
Batch 49/64 loss: 0.5950503349304199
Batch 50/64 loss: 0.36890220642089844
Batch 51/64 loss: 0.39012575149536133
Batch 52/64 loss: 0.33722782135009766
Batch 53/64 loss: 0.11362648010253906
Batch 54/64 loss: 0.019768714904785156
Batch 55/64 loss: 0.04752826690673828
Batch 56/64 loss: 0.6126585006713867
Batch 57/64 loss: 0.23133087158203125
Batch 58/64 loss: 0.517669677734375
Batch 59/64 loss: 0.2329549789428711
Batch 60/64 loss: 0.07674312591552734
Batch 61/64 loss: 0.3619194030761719
Batch 62/64 loss: 0.27057743072509766
Batch 63/64 loss: 0.4525012969970703
Batch 64/64 loss: -3.6598329544067383
Epoch 3  Train loss: 0.5722649779974246  Val loss: -0.006229846338226213
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: -0.15876293182373047
Batch 2/64 loss: -0.014744758605957031
Batch 3/64 loss: 0.06764411926269531
Batch 4/64 loss: 0.15968036651611328
Batch 5/64 loss: 0.5539188385009766
Batch 6/64 loss: 0.1203765869140625
Batch 7/64 loss: -0.040802001953125
Batch 8/64 loss: 0.06685256958007812
Batch 9/64 loss: 0.24805164337158203
Batch 10/64 loss: -0.2664356231689453
Batch 11/64 loss: 0.717951774597168
Batch 12/64 loss: 0.9118642807006836
Batch 13/64 loss: 0.25554370880126953
Batch 14/64 loss: 0.07158946990966797
Batch 15/64 loss: 0.1452808380126953
Batch 16/64 loss: 0.29463672637939453
Batch 17/64 loss: 0.1204996109008789
Batch 18/64 loss: 0.45588207244873047
Batch 19/64 loss: 0.37644290924072266
Batch 20/64 loss: -0.1560659408569336
Batch 21/64 loss: 0.1025400161743164
Batch 22/64 loss: 0.5725126266479492
Batch 23/64 loss: 0.1677560806274414
Batch 24/64 loss: 0.20311737060546875
Batch 25/64 loss: 0.19310474395751953
Batch 26/64 loss: 0.0055255889892578125
Batch 27/64 loss: 0.5973577499389648
Batch 28/64 loss: 0.2812795639038086
Batch 29/64 loss: 0.24315357208251953
Batch 30/64 loss: 0.2913246154785156
Batch 31/64 loss: 0.0067081451416015625
Batch 32/64 loss: 0.023703575134277344
Batch 33/64 loss: 0.22104263305664062
Batch 34/64 loss: -0.20187950134277344
Batch 35/64 loss: 0.3578176498413086
Batch 36/64 loss: 0.41369152069091797
Batch 37/64 loss: 0.15780925750732422
Batch 38/64 loss: 0.2143564224243164
Batch 39/64 loss: 0.17075538635253906
Batch 40/64 loss: -0.021413803100585938
Batch 41/64 loss: 0.22319316864013672
Batch 42/64 loss: 0.5287046432495117
Batch 43/64 loss: 0.18696308135986328
Batch 44/64 loss: 0.2868690490722656
Batch 45/64 loss: 0.012121200561523438
Batch 46/64 loss: -0.20354366302490234
Batch 47/64 loss: 0.44278526306152344
Batch 48/64 loss: 0.06403446197509766
Batch 49/64 loss: -0.022223472595214844
Batch 50/64 loss: 0.03538036346435547
Batch 51/64 loss: -0.1392221450805664
Batch 52/64 loss: 0.12416839599609375
Batch 53/64 loss: -0.06534576416015625
Batch 54/64 loss: 0.2598543167114258
Batch 55/64 loss: -0.01819133758544922
Batch 56/64 loss: 0.19855213165283203
Batch 57/64 loss: 0.1495199203491211
Batch 58/64 loss: 0.675379753112793
Batch 59/64 loss: 0.08715343475341797
Batch 60/64 loss: 0.022469520568847656
Batch 61/64 loss: -0.21218490600585938
Batch 62/64 loss: 0.14381980895996094
Batch 63/64 loss: -0.19860267639160156
Batch 64/64 loss: -4.407715797424316
Epoch 4  Train loss: 0.11302800272025314  Val loss: 0.03142187111975811
Epoch 5
-------------------------------
Batch 1/64 loss: 0.30773067474365234
Batch 2/64 loss: 0.5135536193847656
Batch 3/64 loss: 0.009618759155273438
Batch 4/64 loss: -0.010671615600585938
Batch 5/64 loss: -0.017874717712402344
Batch 6/64 loss: -0.10372638702392578
Batch 7/64 loss: 0.05755043029785156
Batch 8/64 loss: 0.08584880828857422
Batch 9/64 loss: 0.025015830993652344
Batch 10/64 loss: -0.26993370056152344
Batch 11/64 loss: -0.1749267578125
Batch 12/64 loss: -0.2770977020263672
Batch 13/64 loss: -0.09264183044433594
Batch 14/64 loss: -0.2182941436767578
Batch 15/64 loss: 0.09615516662597656
Batch 16/64 loss: 0.2660665512084961
Batch 17/64 loss: 0.10745906829833984
Batch 18/64 loss: -0.24252796173095703
Batch 19/64 loss: -0.20258712768554688
Batch 20/64 loss: 0.3646707534790039
Batch 21/64 loss: 0.4318113327026367
Batch 22/64 loss: -0.1765117645263672
Batch 23/64 loss: -0.06345939636230469
Batch 24/64 loss: 0.14103984832763672
Batch 25/64 loss: -0.3894786834716797
Batch 26/64 loss: 0.2770872116088867
Batch 27/64 loss: -0.1265735626220703
Batch 28/64 loss: -0.26616764068603516
Batch 29/64 loss: 0.16698646545410156
Batch 30/64 loss: 0.0052928924560546875
Batch 31/64 loss: -0.10249710083007812
Batch 32/64 loss: 0.34442901611328125
Batch 33/64 loss: 0.017660140991210938
Batch 34/64 loss: -0.04198455810546875
Batch 35/64 loss: 0.2039480209350586
Batch 36/64 loss: 0.05651378631591797
Batch 37/64 loss: -0.21407413482666016
Batch 38/64 loss: 0.1813344955444336
Batch 39/64 loss: -0.41880226135253906
Batch 40/64 loss: 0.5215167999267578
Batch 41/64 loss: -0.2762765884399414
Batch 42/64 loss: -0.6307182312011719
Batch 43/64 loss: -0.28603363037109375
Batch 44/64 loss: -0.0957183837890625
Batch 45/64 loss: -0.3865823745727539
Batch 46/64 loss: -0.18500518798828125
Batch 47/64 loss: -0.16079330444335938
Batch 48/64 loss: -0.5360851287841797
Batch 49/64 loss: -0.24256324768066406
Batch 50/64 loss: -0.048488616943359375
Batch 51/64 loss: -0.1782989501953125
Batch 52/64 loss: -0.002338409423828125
Batch 53/64 loss: -0.03834819793701172
Batch 54/64 loss: -0.1221466064453125
Batch 55/64 loss: -0.34952449798583984
Batch 56/64 loss: -0.4474458694458008
Batch 57/64 loss: 0.04820442199707031
Batch 58/64 loss: -0.8863000869750977
Batch 59/64 loss: -0.46020984649658203
Batch 60/64 loss: -0.4607706069946289
Batch 61/64 loss: -0.32149791717529297
Batch 62/64 loss: -0.43275928497314453
Batch 63/64 loss: -0.1379690170288086
Batch 64/64 loss: -4.9602508544921875
Epoch 5  Train loss: -0.15037488750382966  Val loss: -0.3903303506857751
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 0.08604907989501953
Batch 2/64 loss: -0.3800182342529297
Batch 3/64 loss: -0.342071533203125
Batch 4/64 loss: -0.3208732604980469
Batch 5/64 loss: -0.42118072509765625
Batch 6/64 loss: -0.5399255752563477
Batch 7/64 loss: -0.1128683090209961
Batch 8/64 loss: -0.11000823974609375
Batch 9/64 loss: 0.059818267822265625
Batch 10/64 loss: 0.23425579071044922
Batch 11/64 loss: 0.29308128356933594
Batch 12/64 loss: 0.32150745391845703
Batch 13/64 loss: 0.23801231384277344
Batch 14/64 loss: 0.42656898498535156
Batch 15/64 loss: 0.2659568786621094
Batch 16/64 loss: 0.009059906005859375
Batch 17/64 loss: 0.6427526473999023
Batch 18/64 loss: 0.42139148712158203
Batch 19/64 loss: 0.3575725555419922
Batch 20/64 loss: -0.009770393371582031
Batch 21/64 loss: -0.055092811584472656
Batch 22/64 loss: 0.15846729278564453
Batch 23/64 loss: 0.16996288299560547
Batch 24/64 loss: -0.2593832015991211
Batch 25/64 loss: 0.7015018463134766
Batch 26/64 loss: 0.14347362518310547
Batch 27/64 loss: 0.19208812713623047
Batch 28/64 loss: 0.3616466522216797
Batch 29/64 loss: 0.24901676177978516
Batch 30/64 loss: 0.24726295471191406
Batch 31/64 loss: 0.42466068267822266
Batch 32/64 loss: 0.258087158203125
Batch 33/64 loss: 0.0018396377563476562
Batch 34/64 loss: 0.2009296417236328
Batch 35/64 loss: 0.37330055236816406
Batch 36/64 loss: -0.15189361572265625
Batch 37/64 loss: 0.1879100799560547
Batch 38/64 loss: -0.021964073181152344
Batch 39/64 loss: -0.054351806640625
Batch 40/64 loss: -0.09622478485107422
Batch 41/64 loss: 0.11774158477783203
Batch 42/64 loss: 0.15451717376708984
Batch 43/64 loss: 0.29699230194091797
Batch 44/64 loss: 0.04401111602783203
Batch 45/64 loss: -0.13598346710205078
Batch 46/64 loss: -0.09787178039550781
Batch 47/64 loss: -0.22786903381347656
Batch 48/64 loss: 0.01764202117919922
Batch 49/64 loss: 0.03756999969482422
Batch 50/64 loss: -0.2919921875
Batch 51/64 loss: -0.2338275909423828
Batch 52/64 loss: -0.2450103759765625
Batch 53/64 loss: -0.23861408233642578
Batch 54/64 loss: -0.17464065551757812
Batch 55/64 loss: -0.031342506408691406
Batch 56/64 loss: -0.16397857666015625
Batch 57/64 loss: 0.31058502197265625
Batch 58/64 loss: -0.22736644744873047
Batch 59/64 loss: -0.1354351043701172
Batch 60/64 loss: -0.36345958709716797
Batch 61/64 loss: -0.23273849487304688
Batch 62/64 loss: -0.2620391845703125
Batch 63/64 loss: -0.22973346710205078
Batch 64/64 loss: -4.138256072998047
Epoch 6  Train loss: -0.019858625823376226  Val loss: -0.599409686740731
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.07600212097167969
Batch 2/64 loss: -0.47170543670654297
Batch 3/64 loss: -0.16063308715820312
Batch 4/64 loss: -0.7282590866088867
Batch 5/64 loss: -0.2395038604736328
Batch 6/64 loss: -0.5580329895019531
Batch 7/64 loss: -0.18163204193115234
Batch 8/64 loss: -0.2227039337158203
Batch 9/64 loss: -0.10183429718017578
Batch 10/64 loss: -0.08043670654296875
Batch 11/64 loss: -0.7309446334838867
Batch 12/64 loss: -0.4133024215698242
Batch 13/64 loss: -0.2778949737548828
Batch 14/64 loss: -0.3498649597167969
Batch 15/64 loss: -0.5409688949584961
Batch 16/64 loss: -0.012010574340820312
Batch 17/64 loss: -0.31714630126953125
Batch 18/64 loss: -0.06177043914794922
Batch 19/64 loss: 0.05791187286376953
Batch 20/64 loss: -0.2093830108642578
Batch 21/64 loss: -0.6567564010620117
Batch 22/64 loss: -0.5743722915649414
Batch 23/64 loss: -0.32534313201904297
Batch 24/64 loss: -0.7635879516601562
Batch 25/64 loss: -0.6709804534912109
Batch 26/64 loss: -0.27905845642089844
Batch 27/64 loss: -0.012368202209472656
Batch 28/64 loss: -0.8448009490966797
Batch 29/64 loss: -0.25877857208251953
Batch 30/64 loss: -0.4949655532836914
Batch 31/64 loss: -0.23604774475097656
Batch 32/64 loss: -0.31928157806396484
Batch 33/64 loss: -0.11602020263671875
Batch 34/64 loss: -0.4857645034790039
Batch 35/64 loss: -0.6770658493041992
Batch 36/64 loss: -0.5833568572998047
Batch 37/64 loss: -0.41997432708740234
Batch 38/64 loss: -0.4873971939086914
Batch 39/64 loss: 0.05416297912597656
Batch 40/64 loss: -0.22481060028076172
Batch 41/64 loss: -0.17461109161376953
Batch 42/64 loss: -0.2873497009277344
Batch 43/64 loss: -0.5032491683959961
Batch 44/64 loss: -0.02591705322265625
Batch 45/64 loss: -0.40036678314208984
Batch 46/64 loss: -0.2556171417236328
Batch 47/64 loss: -0.5107183456420898
Batch 48/64 loss: 0.11181354522705078
Batch 49/64 loss: 1.5367765426635742
Batch 50/64 loss: -0.25270557403564453
Batch 51/64 loss: -0.7149143218994141
Batch 52/64 loss: -0.49023914337158203
Batch 53/64 loss: -0.5551052093505859
Batch 54/64 loss: 0.07223033905029297
Batch 55/64 loss: -0.14131736755371094
Batch 56/64 loss: -0.019179344177246094
Batch 57/64 loss: -0.363250732421875
Batch 58/64 loss: -0.08510589599609375
Batch 59/64 loss: 0.38078784942626953
Batch 60/64 loss: -0.42076873779296875
Batch 61/64 loss: 0.1404561996459961
Batch 62/64 loss: 0.34240150451660156
Batch 63/64 loss: 0.424041748046875
Batch 64/64 loss: -4.247407913208008
Epoch 7  Train loss: -0.3024022794237324  Val loss: 0.4139774886193554
Epoch 8
-------------------------------
Batch 1/64 loss: -0.11334419250488281
Batch 2/64 loss: 0.3450441360473633
Batch 3/64 loss: 0.2983283996582031
Batch 4/64 loss: 0.09491252899169922
Batch 5/64 loss: -0.18689537048339844
Batch 6/64 loss: 0.0898294448852539
Batch 7/64 loss: -0.014849662780761719
Batch 8/64 loss: 0.11665916442871094
Batch 9/64 loss: -0.011069297790527344
Batch 10/64 loss: 0.05767250061035156
Batch 11/64 loss: 0.028720855712890625
Batch 12/64 loss: -0.37404441833496094
Batch 13/64 loss: 0.04923248291015625
Batch 14/64 loss: -0.14064979553222656
Batch 15/64 loss: 0.014922142028808594
Batch 16/64 loss: 0.1945180892944336
Batch 17/64 loss: -0.4810476303100586
Batch 18/64 loss: -0.13226795196533203
Batch 19/64 loss: -0.5725326538085938
Batch 20/64 loss: -0.15112686157226562
Batch 21/64 loss: -0.3423633575439453
Batch 22/64 loss: -0.2242136001586914
Batch 23/64 loss: 0.15555381774902344
Batch 24/64 loss: -0.3435831069946289
Batch 25/64 loss: -0.5092840194702148
Batch 26/64 loss: 0.14779090881347656
Batch 27/64 loss: -0.5065126419067383
Batch 28/64 loss: -0.4649190902709961
Batch 29/64 loss: -0.062088966369628906
Batch 30/64 loss: -0.06992626190185547
Batch 31/64 loss: -0.7332830429077148
Batch 32/64 loss: -0.3375577926635742
Batch 33/64 loss: 0.023611068725585938
Batch 34/64 loss: -0.4192543029785156
Batch 35/64 loss: -0.5112009048461914
Batch 36/64 loss: -0.8225297927856445
Batch 37/64 loss: -0.3086233139038086
Batch 38/64 loss: -0.18550872802734375
Batch 39/64 loss: -0.5748805999755859
Batch 40/64 loss: -0.10759449005126953
Batch 41/64 loss: -0.5204105377197266
Batch 42/64 loss: -0.5757970809936523
Batch 43/64 loss: -0.3585786819458008
Batch 44/64 loss: -0.35097599029541016
Batch 45/64 loss: -0.3186607360839844
Batch 46/64 loss: -0.5205192565917969
Batch 47/64 loss: 0.17261123657226562
Batch 48/64 loss: -0.3993101119995117
Batch 49/64 loss: -0.46164798736572266
Batch 50/64 loss: -0.31560611724853516
Batch 51/64 loss: -0.15532493591308594
Batch 52/64 loss: 0.09130096435546875
Batch 53/64 loss: -0.3540382385253906
Batch 54/64 loss: -0.6291818618774414
Batch 55/64 loss: -0.2691478729248047
Batch 56/64 loss: -0.13562583923339844
Batch 57/64 loss: -0.46000194549560547
Batch 58/64 loss: -0.7003793716430664
Batch 59/64 loss: -0.4120492935180664
Batch 60/64 loss: -0.7431163787841797
Batch 61/64 loss: -0.1696300506591797
Batch 62/64 loss: -0.26192188262939453
Batch 63/64 loss: -0.36646461486816406
Batch 64/64 loss: -4.777706146240234
Epoch 8  Train loss: -0.2961900000478707  Val loss: -0.48469349444936644
Epoch 9
-------------------------------
Batch 1/64 loss: -0.37830066680908203
Batch 2/64 loss: -0.1711893081665039
Batch 3/64 loss: -0.9647178649902344
Batch 4/64 loss: -0.7440500259399414
Batch 5/64 loss: -0.34816932678222656
Batch 6/64 loss: -0.20094966888427734
Batch 7/64 loss: -0.47266292572021484
Batch 8/64 loss: -0.05479907989501953
Batch 9/64 loss: -0.4146432876586914
Batch 10/64 loss: -0.63800048828125
Batch 11/64 loss: -0.32550048828125
Batch 12/64 loss: -0.55029296875
Batch 13/64 loss: -0.9185857772827148
Batch 14/64 loss: -0.7865896224975586
Batch 15/64 loss: -0.41664886474609375
Batch 16/64 loss: -0.7852039337158203
Batch 17/64 loss: -0.31191349029541016
Batch 18/64 loss: -0.32806873321533203
Batch 19/64 loss: 0.02341938018798828
Batch 20/64 loss: -0.5986204147338867
Batch 21/64 loss: -0.4122591018676758
Batch 22/64 loss: -0.4641284942626953
Batch 23/64 loss: -1.0699262619018555
Batch 24/64 loss: -0.44003772735595703
Batch 25/64 loss: 0.07008838653564453
Batch 26/64 loss: -0.38187599182128906
Batch 27/64 loss: -0.3950319290161133
Batch 28/64 loss: -0.7067327499389648
Batch 29/64 loss: -0.5849943161010742
Batch 30/64 loss: -0.3234291076660156
Batch 31/64 loss: -0.40661144256591797
Batch 32/64 loss: -0.5709295272827148
Batch 33/64 loss: -0.9037904739379883
Batch 34/64 loss: -0.6332502365112305
Batch 35/64 loss: -0.3727989196777344
Batch 36/64 loss: -0.525507926940918
Batch 37/64 loss: -0.5366630554199219
Batch 38/64 loss: -0.5951747894287109
Batch 39/64 loss: -0.7820854187011719
Batch 40/64 loss: -0.8665542602539062
Batch 41/64 loss: -0.6576919555664062
Batch 42/64 loss: -0.29886913299560547
Batch 43/64 loss: -0.9801092147827148
Batch 44/64 loss: -0.6995792388916016
Batch 45/64 loss: -0.8289432525634766
Batch 46/64 loss: -0.5299758911132812
Batch 47/64 loss: -0.9384469985961914
Batch 48/64 loss: -0.9731721878051758
Batch 49/64 loss: -1.0228071212768555
Batch 50/64 loss: -0.47855663299560547
Batch 51/64 loss: -0.35872745513916016
Batch 52/64 loss: -0.4085664749145508
Batch 53/64 loss: -0.6176300048828125
Batch 54/64 loss: -0.6032209396362305
Batch 55/64 loss: -0.4353218078613281
Batch 56/64 loss: -0.71856689453125
Batch 57/64 loss: -0.43155384063720703
Batch 58/64 loss: -0.5786151885986328
Batch 59/64 loss: -0.877410888671875
Batch 60/64 loss: -0.898371696472168
Batch 61/64 loss: -0.017510414123535156
Batch 62/64 loss: -0.42780590057373047
Batch 63/64 loss: -0.12807178497314453
Batch 64/64 loss: -5.339545249938965
Epoch 9  Train loss: -0.5992370942059685  Val loss: -0.765975676861006
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: -0.6003293991088867
Batch 2/64 loss: -0.21428680419921875
Batch 3/64 loss: -0.7639179229736328
Batch 4/64 loss: -0.4383277893066406
Batch 5/64 loss: -0.929804801940918
Batch 6/64 loss: -0.8952121734619141
Batch 7/64 loss: -0.9193048477172852
Batch 8/64 loss: -0.42470264434814453
Batch 9/64 loss: -0.6533727645874023
Batch 10/64 loss: -1.1054439544677734
Batch 11/64 loss: -0.9463777542114258
Batch 12/64 loss: -0.48316287994384766
Batch 13/64 loss: -0.9179849624633789
Batch 14/64 loss: -0.6931848526000977
Batch 15/64 loss: -0.717463493347168
Batch 16/64 loss: -0.8584051132202148
Batch 17/64 loss: -0.7330102920532227
Batch 18/64 loss: -1.0328035354614258
Batch 19/64 loss: -0.6720266342163086
Batch 20/64 loss: -0.7434673309326172
Batch 21/64 loss: -0.5029611587524414
Batch 22/64 loss: -1.095041275024414
Batch 23/64 loss: -0.8956375122070312
Batch 24/64 loss: -0.6503353118896484
Batch 25/64 loss: -0.41153812408447266
Batch 26/64 loss: -0.7158870697021484
Batch 27/64 loss: 0.0811920166015625
Batch 28/64 loss: -0.7958412170410156
Batch 29/64 loss: -0.7596330642700195
Batch 30/64 loss: -1.0323848724365234
Batch 31/64 loss: -0.4163541793823242
Batch 32/64 loss: -0.7273349761962891
Batch 33/64 loss: -0.19956684112548828
Batch 34/64 loss: -0.7310523986816406
Batch 35/64 loss: -0.2551698684692383
Batch 36/64 loss: -0.8843069076538086
Batch 37/64 loss: -0.5761909484863281
Batch 38/64 loss: -0.8314657211303711
Batch 39/64 loss: -0.8136682510375977
Batch 40/64 loss: -1.1175785064697266
Batch 41/64 loss: 0.47229576110839844
Batch 42/64 loss: -0.5491666793823242
Batch 43/64 loss: -0.8630285263061523
Batch 44/64 loss: -0.44562244415283203
Batch 45/64 loss: -0.6768674850463867
Batch 46/64 loss: -0.7489385604858398
Batch 47/64 loss: -0.23202896118164062
Batch 48/64 loss: -0.9030294418334961
Batch 49/64 loss: -0.5409965515136719
Batch 50/64 loss: -0.7351751327514648
Batch 51/64 loss: -0.9754505157470703
Batch 52/64 loss: -0.5220756530761719
Batch 53/64 loss: -1.1864404678344727
Batch 54/64 loss: -0.44800567626953125
Batch 55/64 loss: -1.090285301208496
Batch 56/64 loss: -0.7282800674438477
Batch 57/64 loss: -0.6747016906738281
Batch 58/64 loss: -0.7064313888549805
Batch 59/64 loss: -0.3738584518432617
Batch 60/64 loss: -0.8563547134399414
Batch 61/64 loss: -0.8834686279296875
Batch 62/64 loss: -0.2689657211303711
Batch 63/64 loss: -0.3919944763183594
Batch 64/64 loss: -5.345905303955078
Epoch 10  Train loss: -0.7280258178710938  Val loss: -0.869812260788331
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: -0.5832910537719727
Batch 2/64 loss: -0.8754310607910156
Batch 3/64 loss: -0.5802059173583984
Batch 4/64 loss: -1.2040691375732422
Batch 5/64 loss: -0.7567300796508789
Batch 6/64 loss: -0.7384757995605469
Batch 7/64 loss: -0.6904106140136719
Batch 8/64 loss: -0.9867315292358398
Batch 9/64 loss: -0.19346046447753906
Batch 10/64 loss: -0.9067392349243164
Batch 11/64 loss: -1.0345020294189453
Batch 12/64 loss: -0.9649085998535156
Batch 13/64 loss: -0.6999902725219727
Batch 14/64 loss: -1.0163354873657227
Batch 15/64 loss: -0.7282724380493164
Batch 16/64 loss: -0.5137538909912109
Batch 17/64 loss: -0.3372840881347656
Batch 18/64 loss: 0.15154361724853516
Batch 19/64 loss: -0.5817356109619141
Batch 20/64 loss: -0.33789825439453125
Batch 21/64 loss: -0.6052179336547852
Batch 22/64 loss: -0.3299388885498047
Batch 23/64 loss: -0.6017189025878906
Batch 24/64 loss: -0.8599576950073242
Batch 25/64 loss: -0.6502017974853516
Batch 26/64 loss: -0.9834480285644531
Batch 27/64 loss: -0.8301992416381836
Batch 28/64 loss: -0.3857860565185547
Batch 29/64 loss: -0.913386344909668
Batch 30/64 loss: -0.6479701995849609
Batch 31/64 loss: -0.5612525939941406
Batch 32/64 loss: -0.7034406661987305
Batch 33/64 loss: -1.0928964614868164
Batch 34/64 loss: -0.5687875747680664
Batch 35/64 loss: -0.41445446014404297
Batch 36/64 loss: -0.7305135726928711
Batch 37/64 loss: -0.4595165252685547
Batch 38/64 loss: -0.30522632598876953
Batch 39/64 loss: -0.9450550079345703
Batch 40/64 loss: -0.3442955017089844
Batch 41/64 loss: -0.8024539947509766
Batch 42/64 loss: -0.8652019500732422
Batch 43/64 loss: -0.4037961959838867
Batch 44/64 loss: -0.3096761703491211
Batch 45/64 loss: -0.7022218704223633
Batch 46/64 loss: -1.0681934356689453
Batch 47/64 loss: -0.4960670471191406
Batch 48/64 loss: -0.882838249206543
Batch 49/64 loss: -0.4606962203979492
Batch 50/64 loss: -0.4229707717895508
Batch 51/64 loss: -0.8039684295654297
Batch 52/64 loss: -0.739964485168457
Batch 53/64 loss: -0.6415586471557617
Batch 54/64 loss: -0.8464698791503906
Batch 55/64 loss: -0.9953193664550781
Batch 56/64 loss: -1.099806785583496
Batch 57/64 loss: -0.7661399841308594
Batch 58/64 loss: -0.5212497711181641
Batch 59/64 loss: -1.1988763809204102
Batch 60/64 loss: -0.9874496459960938
Batch 61/64 loss: -0.6946725845336914
Batch 62/64 loss: -0.8687343597412109
Batch 63/64 loss: -0.6635408401489258
Batch 64/64 loss: -5.588539123535156
Epoch 11  Train loss: -0.7520818373736213  Val loss: -1.0215241736972456
Saving best model, epoch: 11
Epoch 12
-------------------------------
Batch 1/64 loss: -0.5876245498657227
Batch 2/64 loss: -0.7898473739624023
Batch 3/64 loss: -1.0087337493896484
Batch 4/64 loss: -0.3082609176635742
Batch 5/64 loss: -0.8515892028808594
Batch 6/64 loss: -0.8774423599243164
Batch 7/64 loss: -1.047043800354004
Batch 8/64 loss: -0.957056999206543
Batch 9/64 loss: -1.1455087661743164
Batch 10/64 loss: -0.8815317153930664
Batch 11/64 loss: -0.9584779739379883
Batch 12/64 loss: -0.4078998565673828
Batch 13/64 loss: -0.9259166717529297
Batch 14/64 loss: -0.9748392105102539
Batch 15/64 loss: -1.1038274765014648
Batch 16/64 loss: -0.6439943313598633
Batch 17/64 loss: -1.1549224853515625
Batch 18/64 loss: -1.0359811782836914
Batch 19/64 loss: -0.7591238021850586
Batch 20/64 loss: -0.7263364791870117
Batch 21/64 loss: -1.1384820938110352
Batch 22/64 loss: -0.7363986968994141
Batch 23/64 loss: -0.9122295379638672
Batch 24/64 loss: -0.9934291839599609
Batch 25/64 loss: -0.69000244140625
Batch 26/64 loss: -0.5093975067138672
Batch 27/64 loss: -0.9774990081787109
Batch 28/64 loss: -1.1014862060546875
Batch 29/64 loss: -1.1693801879882812
Batch 30/64 loss: -0.4208965301513672
Batch 31/64 loss: -0.8503217697143555
Batch 32/64 loss: -0.8577098846435547
Batch 33/64 loss: -0.8522453308105469
Batch 34/64 loss: -0.7971048355102539
Batch 35/64 loss: -0.8945598602294922
Batch 36/64 loss: -1.3095788955688477
Batch 37/64 loss: -1.0139350891113281
Batch 38/64 loss: -0.9903392791748047
Batch 39/64 loss: -0.7449569702148438
Batch 40/64 loss: -0.8593177795410156
Batch 41/64 loss: -1.2137422561645508
Batch 42/64 loss: -1.2638225555419922
Batch 43/64 loss: -0.4414653778076172
Batch 44/64 loss: -0.7951765060424805
Batch 45/64 loss: -0.9289112091064453
Batch 46/64 loss: -1.0217275619506836
Batch 47/64 loss: -0.9862146377563477
Batch 48/64 loss: -0.776026725769043
Batch 49/64 loss: -0.7594747543334961
Batch 50/64 loss: -1.139399528503418
Batch 51/64 loss: -0.3053245544433594
Batch 52/64 loss: -0.4241456985473633
Batch 53/64 loss: -0.9740619659423828
Batch 54/64 loss: -1.0004901885986328
Batch 55/64 loss: -0.1342926025390625
Batch 56/64 loss: -0.7243061065673828
Batch 57/64 loss: -1.1492443084716797
Batch 58/64 loss: -1.2250585556030273
Batch 59/64 loss: -0.9731206893920898
Batch 60/64 loss: -0.8522300720214844
Batch 61/64 loss: -0.7625818252563477
Batch 62/64 loss: -0.8021869659423828
Batch 63/64 loss: -1.1299543380737305
Batch 64/64 loss: -5.919891357421875
Epoch 12  Train loss: -0.9284409018123851  Val loss: -0.9697404186340541
Epoch 13
-------------------------------
Batch 1/64 loss: -0.3271198272705078
Batch 2/64 loss: -0.6734323501586914
Batch 3/64 loss: -1.002549171447754
Batch 4/64 loss: -0.7602167129516602
Batch 5/64 loss: -0.8932466506958008
Batch 6/64 loss: -0.594325065612793
Batch 7/64 loss: -0.9052858352661133
Batch 8/64 loss: -0.7565116882324219
Batch 9/64 loss: -0.5082206726074219
Batch 10/64 loss: -0.7279491424560547
Batch 11/64 loss: -1.0258712768554688
Batch 12/64 loss: -0.9588613510131836
Batch 13/64 loss: -0.5452041625976562
Batch 14/64 loss: -1.1547670364379883
Batch 15/64 loss: -1.0664901733398438
Batch 16/64 loss: -0.6726789474487305
Batch 17/64 loss: -0.7083473205566406
Batch 18/64 loss: -0.7908544540405273
Batch 19/64 loss: -1.015045166015625
Batch 20/64 loss: -1.2888507843017578
Batch 21/64 loss: -1.1234846115112305
Batch 22/64 loss: -0.9600372314453125
Batch 23/64 loss: -1.124527931213379
Batch 24/64 loss: -1.1199169158935547
Batch 25/64 loss: -0.9107532501220703
Batch 26/64 loss: -1.1348094940185547
Batch 27/64 loss: -1.1571664810180664
Batch 28/64 loss: -0.695286750793457
Batch 29/64 loss: -0.7136678695678711
Batch 30/64 loss: -0.7082767486572266
Batch 31/64 loss: -0.8937463760375977
Batch 32/64 loss: -1.0408439636230469
Batch 33/64 loss: -0.5175743103027344
Batch 34/64 loss: -0.9226274490356445
Batch 35/64 loss: -0.7969017028808594
Batch 36/64 loss: -1.3118829727172852
Batch 37/64 loss: -0.6916675567626953
Batch 38/64 loss: -1.4007978439331055
Batch 39/64 loss: -1.1666812896728516
Batch 40/64 loss: -1.1813335418701172
Batch 41/64 loss: -0.8832292556762695
Batch 42/64 loss: -1.0760917663574219
Batch 43/64 loss: -0.6797103881835938
Batch 44/64 loss: -0.9042186737060547
Batch 45/64 loss: -0.5154552459716797
Batch 46/64 loss: -0.8304967880249023
Batch 47/64 loss: -1.0926990509033203
Batch 48/64 loss: -1.231583595275879
Batch 49/64 loss: -1.3436203002929688
Batch 50/64 loss: -1.1679449081420898
Batch 51/64 loss: -1.1268501281738281
Batch 52/64 loss: -1.36529541015625
Batch 53/64 loss: -1.0403814315795898
Batch 54/64 loss: -1.3810663223266602
Batch 55/64 loss: -1.180398941040039
Batch 56/64 loss: -0.5564746856689453
Batch 57/64 loss: -0.7319555282592773
Batch 58/64 loss: -1.2158002853393555
Batch 59/64 loss: -0.8821115493774414
Batch 60/64 loss: -0.8188762664794922
Batch 61/64 loss: -0.8458089828491211
Batch 62/64 loss: -1.4037723541259766
Batch 63/64 loss: -1.2426681518554688
Batch 64/64 loss: -5.980746269226074
Epoch 13  Train loss: -1.0031354006598978  Val loss: -1.2030525862965797
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: -1.4484615325927734
Batch 2/64 loss: -1.1427392959594727
Batch 3/64 loss: -0.7934026718139648
Batch 4/64 loss: -0.794398307800293
Batch 5/64 loss: -0.7534904479980469
Batch 6/64 loss: -1.2615900039672852
Batch 7/64 loss: -1.281393051147461
Batch 8/64 loss: -1.0793771743774414
Batch 9/64 loss: -1.3425960540771484
Batch 10/64 loss: -0.9479646682739258
Batch 11/64 loss: -0.6563186645507812
Batch 12/64 loss: -1.0860719680786133
Batch 13/64 loss: -1.3789234161376953
Batch 14/64 loss: -0.6416301727294922
Batch 15/64 loss: -1.1935596466064453
Batch 16/64 loss: -1.1351232528686523
Batch 17/64 loss: -1.0682878494262695
Batch 18/64 loss: -1.0646047592163086
Batch 19/64 loss: -1.076420783996582
Batch 20/64 loss: -1.1998462677001953
Batch 21/64 loss: -1.3346710205078125
Batch 22/64 loss: -1.0209999084472656
Batch 23/64 loss: -0.6300935745239258
Batch 24/64 loss: -1.0407276153564453
Batch 25/64 loss: -1.0560331344604492
Batch 26/64 loss: -0.6726217269897461
Batch 27/64 loss: -0.6475982666015625
Batch 28/64 loss: -1.2269601821899414
Batch 29/64 loss: -1.1688146591186523
Batch 30/64 loss: -0.6299057006835938
Batch 31/64 loss: -0.9655122756958008
Batch 32/64 loss: -0.9307727813720703
Batch 33/64 loss: -1.584315299987793
Batch 34/64 loss: -1.154916763305664
Batch 35/64 loss: -1.2178363800048828
Batch 36/64 loss: -1.2420873641967773
Batch 37/64 loss: -1.3352880477905273
Batch 38/64 loss: -0.6292448043823242
Batch 39/64 loss: -1.2955055236816406
Batch 40/64 loss: -1.1315975189208984
Batch 41/64 loss: -0.8445224761962891
Batch 42/64 loss: -0.9545888900756836
Batch 43/64 loss: -1.230036735534668
Batch 44/64 loss: -0.8478689193725586
Batch 45/64 loss: -0.42571163177490234
Batch 46/64 loss: -1.219766616821289
Batch 47/64 loss: -1.171635627746582
Batch 48/64 loss: -1.3173847198486328
Batch 49/64 loss: -0.42002201080322266
Batch 50/64 loss: -1.3015003204345703
Batch 51/64 loss: -1.1062917709350586
Batch 52/64 loss: -1.272536277770996
Batch 53/64 loss: -0.8271055221557617
Batch 54/64 loss: -1.4370365142822266
Batch 55/64 loss: -1.2648115158081055
Batch 56/64 loss: -1.311060905456543
Batch 57/64 loss: -1.0712413787841797
Batch 58/64 loss: -0.5723428726196289
Batch 59/64 loss: -0.9681901931762695
Batch 60/64 loss: -1.133676528930664
Batch 61/64 loss: -0.5490322113037109
Batch 62/64 loss: -1.1914119720458984
Batch 63/64 loss: -0.9328432083129883
Batch 64/64 loss: -6.134860992431641
Epoch 14  Train loss: -1.1017014447380515  Val loss: -1.2939277203222321
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: -1.071023941040039
Batch 2/64 loss: -0.9071731567382812
Batch 3/64 loss: -1.1395950317382812
Batch 4/64 loss: -1.3580513000488281
Batch 5/64 loss: -1.264434814453125
Batch 6/64 loss: -1.487248420715332
Batch 7/64 loss: -0.8595170974731445
Batch 8/64 loss: -0.762847900390625
Batch 9/64 loss: -0.9763507843017578
Batch 10/64 loss: -0.5036783218383789
Batch 11/64 loss: -1.2792701721191406
Batch 12/64 loss: -0.6751489639282227
Batch 13/64 loss: -0.7353954315185547
Batch 14/64 loss: -0.9502859115600586
Batch 15/64 loss: -0.8388814926147461
Batch 16/64 loss: -0.9870691299438477
Batch 17/64 loss: -1.4314289093017578
Batch 18/64 loss: -0.8862476348876953
Batch 19/64 loss: -1.1015148162841797
Batch 20/64 loss: -1.262995719909668
Batch 21/64 loss: -1.12237548828125
Batch 22/64 loss: -0.8182497024536133
Batch 23/64 loss: -1.3213281631469727
Batch 24/64 loss: -1.3510704040527344
Batch 25/64 loss: -1.1910676956176758
Batch 26/64 loss: -0.9757499694824219
Batch 27/64 loss: -1.1844539642333984
Batch 28/64 loss: -1.6245574951171875
Batch 29/64 loss: -1.0466270446777344
Batch 30/64 loss: -1.284576416015625
Batch 31/64 loss: -1.075840950012207
Batch 32/64 loss: -1.0838117599487305
Batch 33/64 loss: -0.6646223068237305
Batch 34/64 loss: -1.3207521438598633
Batch 35/64 loss: -1.1001205444335938
Batch 36/64 loss: -1.1886749267578125
Batch 37/64 loss: -1.0023651123046875
Batch 38/64 loss: -1.0567255020141602
Batch 39/64 loss: -0.9146699905395508
Batch 40/64 loss: -0.9628763198852539
Batch 41/64 loss: -1.2860298156738281
Batch 42/64 loss: -0.8201456069946289
Batch 43/64 loss: -1.248002052307129
Batch 44/64 loss: -0.688481330871582
Batch 45/64 loss: -1.1552143096923828
Batch 46/64 loss: -0.8230314254760742
Batch 47/64 loss: -0.7200546264648438
Batch 48/64 loss: -1.284785270690918
Batch 49/64 loss: -0.9795207977294922
Batch 50/64 loss: -1.0215787887573242
Batch 51/64 loss: -1.094639778137207
Batch 52/64 loss: -1.4757566452026367
Batch 53/64 loss: -1.1823205947875977
Batch 54/64 loss: -1.3020687103271484
Batch 55/64 loss: -0.7476816177368164
Batch 56/64 loss: -0.7375831604003906
Batch 57/64 loss: -1.3302526473999023
Batch 58/64 loss: -0.8325376510620117
Batch 59/64 loss: -0.9819192886352539
Batch 60/64 loss: -0.9526329040527344
Batch 61/64 loss: -1.390085220336914
Batch 62/64 loss: -0.8884429931640625
Batch 63/64 loss: -1.1016130447387695
Batch 64/64 loss: -6.135990142822266
Epoch 15  Train loss: -1.120236011579925  Val loss: -1.2979931257844382
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: -1.291006088256836
Batch 2/64 loss: -1.3237953186035156
Batch 3/64 loss: -1.272806167602539
Batch 4/64 loss: -1.477651596069336
Batch 5/64 loss: -1.4258241653442383
Batch 6/64 loss: -0.9364967346191406
Batch 7/64 loss: -1.2047500610351562
Batch 8/64 loss: -0.7729148864746094
Batch 9/64 loss: -0.6649847030639648
Batch 10/64 loss: -1.521824836730957
Batch 11/64 loss: -1.2069034576416016
Batch 12/64 loss: -1.2722949981689453
Batch 13/64 loss: -1.2116584777832031
Batch 14/64 loss: -1.0335016250610352
Batch 15/64 loss: -1.2311763763427734
Batch 16/64 loss: -1.0775175094604492
Batch 17/64 loss: -0.9026193618774414
Batch 18/64 loss: -0.9339494705200195
Batch 19/64 loss: -0.9357461929321289
Batch 20/64 loss: -1.4314842224121094
Batch 21/64 loss: -1.3165092468261719
Batch 22/64 loss: -1.268080711364746
Batch 23/64 loss: -1.1038293838500977
Batch 24/64 loss: -1.535569190979004
Batch 25/64 loss: -1.463083267211914
Batch 26/64 loss: -1.6465349197387695
Batch 27/64 loss: -1.4198112487792969
Batch 28/64 loss: -0.8705587387084961
Batch 29/64 loss: -0.924992561340332
Batch 30/64 loss: -1.4484500885009766
Batch 31/64 loss: -1.2105846405029297
Batch 32/64 loss: -1.2660932540893555
Batch 33/64 loss: -1.4660940170288086
Batch 34/64 loss: -0.7077579498291016
Batch 35/64 loss: -0.8580493927001953
Batch 36/64 loss: -1.3095312118530273
Batch 37/64 loss: -1.4114618301391602
Batch 38/64 loss: -1.3318061828613281
Batch 39/64 loss: -1.0481185913085938
Batch 40/64 loss: -0.7242727279663086
Batch 41/64 loss: -1.1800012588500977
Batch 42/64 loss: -0.9717731475830078
Batch 43/64 loss: -1.4686851501464844
Batch 44/64 loss: -1.4159669876098633
Batch 45/64 loss: -0.9960708618164062
Batch 46/64 loss: -1.501561164855957
Batch 47/64 loss: -1.1508092880249023
Batch 48/64 loss: -1.0075616836547852
Batch 49/64 loss: -1.3724737167358398
Batch 50/64 loss: -1.003448486328125
Batch 51/64 loss: -1.1404075622558594
Batch 52/64 loss: -1.035696029663086
Batch 53/64 loss: -1.313155174255371
Batch 54/64 loss: -0.8587245941162109
Batch 55/64 loss: -1.5497636795043945
Batch 56/64 loss: -1.5552291870117188
Batch 57/64 loss: -1.1289558410644531
Batch 58/64 loss: -1.0998640060424805
Batch 59/64 loss: -1.22259521484375
Batch 60/64 loss: -1.2012214660644531
Batch 61/64 loss: -1.3203516006469727
Batch 62/64 loss: -1.5642776489257812
Batch 63/64 loss: -0.9321155548095703
Batch 64/64 loss: -5.972456932067871
Epoch 16  Train loss: -1.2538062338735543  Val loss: -1.4105166405746616
Saving best model, epoch: 16
Epoch 17
-------------------------------
Batch 1/64 loss: -1.4451360702514648
Batch 2/64 loss: -1.5527763366699219
Batch 3/64 loss: -1.1908330917358398
Batch 4/64 loss: -0.5459737777709961
Batch 5/64 loss: -1.2441787719726562
Batch 6/64 loss: -1.4724712371826172
Batch 7/64 loss: -1.556931495666504
Batch 8/64 loss: -0.6814737319946289
Batch 9/64 loss: -1.1924915313720703
Batch 10/64 loss: -0.8558206558227539
Batch 11/64 loss: -1.1530027389526367
Batch 12/64 loss: -1.0840778350830078
Batch 13/64 loss: -1.0006370544433594
Batch 14/64 loss: -1.650456428527832
Batch 15/64 loss: -0.7524385452270508
Batch 16/64 loss: -1.1876983642578125
Batch 17/64 loss: -1.4503583908081055
Batch 18/64 loss: -1.7336511611938477
Batch 19/64 loss: -1.5634088516235352
Batch 20/64 loss: -1.3580331802368164
Batch 21/64 loss: -1.6244182586669922
Batch 22/64 loss: -1.198317527770996
Batch 23/64 loss: -1.641495704650879
Batch 24/64 loss: -1.2449531555175781
Batch 25/64 loss: -1.24151611328125
Batch 26/64 loss: -1.4639997482299805
Batch 27/64 loss: -1.5140886306762695
Batch 28/64 loss: -1.2178173065185547
Batch 29/64 loss: -1.0258817672729492
Batch 30/64 loss: -1.5080766677856445
Batch 31/64 loss: -1.1884040832519531
Batch 32/64 loss: -1.1740589141845703
Batch 33/64 loss: -1.0209589004516602
Batch 34/64 loss: -1.2328300476074219
Batch 35/64 loss: -1.1049022674560547
Batch 36/64 loss: -1.1788206100463867
Batch 37/64 loss: -0.9251346588134766
Batch 38/64 loss: -0.9933996200561523
Batch 39/64 loss: -1.078369140625
Batch 40/64 loss: -0.9859647750854492
Batch 41/64 loss: -0.9573650360107422
Batch 42/64 loss: -1.2886810302734375
Batch 43/64 loss: -1.1245193481445312
Batch 44/64 loss: -1.4730710983276367
Batch 45/64 loss: -1.6645326614379883
Batch 46/64 loss: -1.0773811340332031
Batch 47/64 loss: -1.634354591369629
Batch 48/64 loss: -0.7581300735473633
Batch 49/64 loss: -1.2073945999145508
Batch 50/64 loss: -1.304464340209961
Batch 51/64 loss: -1.3873929977416992
Batch 52/64 loss: -1.5383014678955078
Batch 53/64 loss: -1.0911750793457031
Batch 54/64 loss: -1.4582462310791016
Batch 55/64 loss: -0.7915372848510742
Batch 56/64 loss: -1.387277603149414
Batch 57/64 loss: -1.4404525756835938
Batch 58/64 loss: -1.0736913681030273
Batch 59/64 loss: -1.5823287963867188
Batch 60/64 loss: -0.8262386322021484
Batch 61/64 loss: -0.6927022933959961
Batch 62/64 loss: -1.5213098526000977
Batch 63/64 loss: -1.3134765625
Batch 64/64 loss: -5.898003578186035
Epoch 17  Train loss: -1.2902397567150639  Val loss: -1.473913907185453
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: -1.5122737884521484
Batch 2/64 loss: -1.0773992538452148
Batch 3/64 loss: -1.6107044219970703
Batch 4/64 loss: -1.5085086822509766
Batch 5/64 loss: -1.2706727981567383
Batch 6/64 loss: -1.284444808959961
Batch 7/64 loss: -1.37677001953125
Batch 8/64 loss: -1.5109748840332031
Batch 9/64 loss: -0.914764404296875
Batch 10/64 loss: -1.6158456802368164
Batch 11/64 loss: -1.3533220291137695
Batch 12/64 loss: -1.4395055770874023
Batch 13/64 loss: -0.5637340545654297
Batch 14/64 loss: -1.5944757461547852
Batch 15/64 loss: -1.2095327377319336
Batch 16/64 loss: -1.2814693450927734
Batch 17/64 loss: -1.4845504760742188
Batch 18/64 loss: -1.480576515197754
Batch 19/64 loss: -1.2623825073242188
Batch 20/64 loss: -0.8424968719482422
Batch 21/64 loss: -0.3930530548095703
Batch 22/64 loss: -1.4936933517456055
Batch 23/64 loss: -0.08809661865234375
Batch 24/64 loss: -1.1511201858520508
Batch 25/64 loss: -0.5499229431152344
Batch 26/64 loss: -0.8806495666503906
Batch 27/64 loss: -0.9400539398193359
Batch 28/64 loss: -1.2145271301269531
Batch 29/64 loss: -0.7110099792480469
Batch 30/64 loss: -1.232748031616211
Batch 31/64 loss: -1.0301685333251953
Batch 32/64 loss: -0.8776845932006836
Batch 33/64 loss: -0.8188762664794922
Batch 34/64 loss: -1.076620101928711
Batch 35/64 loss: -1.1184425354003906
Batch 36/64 loss: -0.7286005020141602
Batch 37/64 loss: -0.8392324447631836
Batch 38/64 loss: -0.9392099380493164
Batch 39/64 loss: -0.8652372360229492
Batch 40/64 loss: -0.8744945526123047
Batch 41/64 loss: -1.423746109008789
Batch 42/64 loss: -1.420572280883789
Batch 43/64 loss: -0.7139396667480469
Batch 44/64 loss: -0.8750162124633789
Batch 45/64 loss: -1.5306158065795898
Batch 46/64 loss: -1.0702228546142578
Batch 47/64 loss: -1.3955068588256836
Batch 48/64 loss: -0.9251947402954102
Batch 49/64 loss: -1.4320707321166992
Batch 50/64 loss: -1.1673345565795898
Batch 51/64 loss: -1.0509157180786133
Batch 52/64 loss: -0.7124300003051758
Batch 53/64 loss: -1.2202033996582031
Batch 54/64 loss: -1.5239315032958984
Batch 55/64 loss: -1.2360992431640625
Batch 56/64 loss: -1.2559146881103516
Batch 57/64 loss: -1.5238780975341797
Batch 58/64 loss: -1.2426214218139648
Batch 59/64 loss: -1.2828655242919922
Batch 60/64 loss: -1.2478485107421875
Batch 61/64 loss: -1.0576181411743164
Batch 62/64 loss: -1.6229190826416016
Batch 63/64 loss: -1.1624422073364258
Batch 64/64 loss: -5.680316925048828
Epoch 18  Train loss: -1.1979920181573607  Val loss: -1.3026307751632638
Epoch 19
-------------------------------
Batch 1/64 loss: -1.648721694946289
Batch 2/64 loss: -1.6369552612304688
Batch 3/64 loss: -1.3406076431274414
Batch 4/64 loss: -0.8843917846679688
Batch 5/64 loss: -1.091444969177246
Batch 6/64 loss: -1.6346607208251953
Batch 7/64 loss: -1.001723289489746
Batch 8/64 loss: -1.2589569091796875
Batch 9/64 loss: -1.568324089050293
Batch 10/64 loss: -1.3801536560058594
Batch 11/64 loss: -1.1868524551391602
Batch 12/64 loss: -0.7317180633544922
Batch 13/64 loss: -0.8328924179077148
Batch 14/64 loss: -1.4936103820800781
Batch 15/64 loss: -1.5304698944091797
Batch 16/64 loss: -1.229386329650879
Batch 17/64 loss: -1.023529052734375
Batch 18/64 loss: -1.4597244262695312
Batch 19/64 loss: -1.582362174987793
Batch 20/64 loss: -1.605189323425293
Batch 21/64 loss: -1.1641674041748047
Batch 22/64 loss: -1.2370729446411133
Batch 23/64 loss: -1.2247505187988281
Batch 24/64 loss: -1.382216453552246
Batch 25/64 loss: -1.347151756286621
Batch 26/64 loss: -1.3260421752929688
Batch 27/64 loss: -1.3348236083984375
Batch 28/64 loss: -1.1901073455810547
Batch 29/64 loss: -1.3508272171020508
Batch 30/64 loss: -1.504155158996582
Batch 31/64 loss: -1.4639654159545898
Batch 32/64 loss: -1.1798219680786133
Batch 33/64 loss: -1.1544132232666016
Batch 34/64 loss: -1.1878948211669922
Batch 35/64 loss: -1.4839401245117188
Batch 36/64 loss: -1.7107648849487305
Batch 37/64 loss: -1.1653976440429688
Batch 38/64 loss: -0.1560955047607422
Batch 39/64 loss: -1.2319536209106445
Batch 40/64 loss: -1.3701839447021484
Batch 41/64 loss: -1.7042789459228516
Batch 42/64 loss: -1.1911487579345703
Batch 43/64 loss: -1.1519012451171875
Batch 44/64 loss: -1.4275646209716797
Batch 45/64 loss: -0.3879127502441406
Batch 46/64 loss: -1.4297313690185547
Batch 47/64 loss: -1.3443384170532227
Batch 48/64 loss: -1.1825695037841797
Batch 49/64 loss: -1.4203472137451172
Batch 50/64 loss: -1.7138843536376953
Batch 51/64 loss: -1.021672248840332
Batch 52/64 loss: -1.472386360168457
Batch 53/64 loss: -1.7412395477294922
Batch 54/64 loss: -1.4129924774169922
Batch 55/64 loss: -1.5766029357910156
Batch 56/64 loss: -1.4894390106201172
Batch 57/64 loss: -1.5444517135620117
Batch 58/64 loss: -1.1958951950073242
Batch 59/64 loss: -1.4383277893066406
Batch 60/64 loss: -0.8893394470214844
Batch 61/64 loss: -1.5470161437988281
Batch 62/64 loss: -1.4947185516357422
Batch 63/64 loss: -1.5495519638061523
Batch 64/64 loss: -6.074322700500488
Epoch 19  Train loss: -1.367379966436648  Val loss: -1.5611800492014671
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: -1.3635444641113281
Batch 2/64 loss: -1.2044658660888672
Batch 3/64 loss: -1.2802658081054688
Batch 4/64 loss: -1.7110815048217773
Batch 5/64 loss: -1.3710918426513672
Batch 6/64 loss: -1.2843818664550781
Batch 7/64 loss: -1.5579900741577148
Batch 8/64 loss: -1.2978248596191406
Batch 9/64 loss: -0.8179473876953125
Batch 10/64 loss: -1.7723941802978516
Batch 11/64 loss: -1.2379207611083984
Batch 12/64 loss: -1.418853759765625
Batch 13/64 loss: -1.5698890686035156
Batch 14/64 loss: -1.2322912216186523
Batch 15/64 loss: -1.687333106994629
Batch 16/64 loss: -1.3813114166259766
Batch 17/64 loss: -1.7274513244628906
Batch 18/64 loss: -0.8151063919067383
Batch 19/64 loss: -1.1591930389404297
Batch 20/64 loss: -1.6524181365966797
Batch 21/64 loss: -1.2762632369995117
Batch 22/64 loss: -1.1509714126586914
Batch 23/64 loss: -1.679865837097168
Batch 24/64 loss: -1.0946464538574219
Batch 25/64 loss: -0.06674671173095703
Batch 26/64 loss: -0.944911003112793
Batch 27/64 loss: -0.8494987487792969
Batch 28/64 loss: -1.3327569961547852
Batch 29/64 loss: -1.3161983489990234
Batch 30/64 loss: -1.3189725875854492
Batch 31/64 loss: -1.1851062774658203
Batch 32/64 loss: -0.5202102661132812
Batch 33/64 loss: -1.2058286666870117
Batch 34/64 loss: -1.409449577331543
Batch 35/64 loss: -1.5350818634033203
Batch 36/64 loss: -1.2035198211669922
Batch 37/64 loss: -1.3167037963867188
Batch 38/64 loss: -1.6292638778686523
Batch 39/64 loss: -1.179335594177246
Batch 40/64 loss: -1.235917091369629
Batch 41/64 loss: -1.4117860794067383
Batch 42/64 loss: -1.7398757934570312
Batch 43/64 loss: -1.204000473022461
Batch 44/64 loss: -0.8797836303710938
Batch 45/64 loss: -1.1941871643066406
Batch 46/64 loss: -1.3984222412109375
Batch 47/64 loss: -1.5004396438598633
Batch 48/64 loss: -1.4847278594970703
Batch 49/64 loss: -1.7382402420043945
Batch 50/64 loss: -1.6503534317016602
Batch 51/64 loss: -1.5313138961791992
Batch 52/64 loss: -1.3498516082763672
Batch 53/64 loss: -1.7141551971435547
Batch 54/64 loss: -1.6989517211914062
Batch 55/64 loss: -1.741286277770996
Batch 56/64 loss: -1.4963226318359375
Batch 57/64 loss: -1.7148027420043945
Batch 58/64 loss: -1.7306947708129883
Batch 59/64 loss: -1.7477741241455078
Batch 60/64 loss: -0.8148717880249023
Batch 61/64 loss: -1.9065675735473633
Batch 62/64 loss: -1.274026870727539
Batch 63/64 loss: -1.212510108947754
Batch 64/64 loss: -6.0869245529174805
Epoch 20  Train loss: -1.4069669573914771  Val loss: -1.38601221825249
Epoch 21
-------------------------------
Batch 1/64 loss: -1.5162544250488281
Batch 2/64 loss: -1.3854665756225586
Batch 3/64 loss: -1.5824518203735352
Batch 4/64 loss: -1.2806787490844727
Batch 5/64 loss: -1.3016853332519531
Batch 6/64 loss: -1.6095314025878906
Batch 7/64 loss: -1.8301935195922852
Batch 8/64 loss: -1.5242252349853516
Batch 9/64 loss: -1.602829933166504
Batch 10/64 loss: -1.4252958297729492
Batch 11/64 loss: -1.2698287963867188
Batch 12/64 loss: -1.307607650756836
Batch 13/64 loss: -1.4841527938842773
Batch 14/64 loss: -1.3405046463012695
Batch 15/64 loss: -1.6207351684570312
Batch 16/64 loss: -1.4340276718139648
Batch 17/64 loss: -1.0541715621948242
Batch 18/64 loss: -1.6940584182739258
Batch 19/64 loss: -1.6102943420410156
Batch 20/64 loss: -1.448399543762207
Batch 21/64 loss: -1.3895893096923828
Batch 22/64 loss: -1.2871809005737305
Batch 23/64 loss: -1.4469404220581055
Batch 24/64 loss: -1.5140867233276367
Batch 25/64 loss: -1.3725471496582031
Batch 26/64 loss: -1.5522832870483398
Batch 27/64 loss: -1.3017101287841797
Batch 28/64 loss: -1.682891845703125
Batch 29/64 loss: -0.8113498687744141
Batch 30/64 loss: -1.5585803985595703
Batch 31/64 loss: -1.4074411392211914
Batch 32/64 loss: -1.3751716613769531
Batch 33/64 loss: -0.9730558395385742
Batch 34/64 loss: -1.8443574905395508
Batch 35/64 loss: -1.4789619445800781
Batch 36/64 loss: -1.772343635559082
Batch 37/64 loss: -1.818857192993164
Batch 38/64 loss: -1.6839237213134766
Batch 39/64 loss: -1.4759588241577148
Batch 40/64 loss: -1.6681642532348633
Batch 41/64 loss: -1.4804191589355469
Batch 42/64 loss: -1.3704910278320312
Batch 43/64 loss: -1.5856256484985352
Batch 44/64 loss: -1.492502212524414
Batch 45/64 loss: -1.241379737854004
Batch 46/64 loss: -1.687295913696289
Batch 47/64 loss: -1.8758087158203125
Batch 48/64 loss: -0.8848495483398438
Batch 49/64 loss: -1.4918594360351562
Batch 50/64 loss: -1.765641212463379
Batch 51/64 loss: -1.600224494934082
Batch 52/64 loss: -1.6792783737182617
Batch 53/64 loss: -1.553659439086914
Batch 54/64 loss: -1.1737194061279297
Batch 55/64 loss: -1.6751375198364258
Batch 56/64 loss: -1.6819276809692383
Batch 57/64 loss: -1.206995964050293
Batch 58/64 loss: -1.3868904113769531
Batch 59/64 loss: -1.631113052368164
Batch 60/64 loss: -1.5122442245483398
Batch 61/64 loss: -1.1975383758544922
Batch 62/64 loss: -1.1887874603271484
Batch 63/64 loss: -1.525888442993164
Batch 64/64 loss: -5.5611114501953125
Epoch 21  Train loss: -1.5183984345080805  Val loss: -1.7354783651345373
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: -1.4422988891601562
Batch 2/64 loss: -1.4546594619750977
Batch 3/64 loss: -1.4672632217407227
Batch 4/64 loss: -1.7415637969970703
Batch 5/64 loss: -1.6266956329345703
Batch 6/64 loss: -1.5517425537109375
Batch 7/64 loss: -1.6323480606079102
Batch 8/64 loss: -1.5690555572509766
Batch 9/64 loss: -1.5840482711791992
Batch 10/64 loss: -1.3523502349853516
Batch 11/64 loss: -1.8033361434936523
Batch 12/64 loss: -1.7025642395019531
Batch 13/64 loss: -1.5860204696655273
Batch 14/64 loss: -1.6096878051757812
Batch 15/64 loss: -1.5241422653198242
Batch 16/64 loss: -0.2661094665527344
Batch 17/64 loss: -1.6222705841064453
Batch 18/64 loss: -1.3266468048095703
Batch 19/64 loss: -1.7617769241333008
Batch 20/64 loss: -1.6213397979736328
Batch 21/64 loss: -1.621464729309082
Batch 22/64 loss: -1.4534082412719727
Batch 23/64 loss: -1.731827735900879
Batch 24/64 loss: -1.6926202774047852
Batch 25/64 loss: -1.5843677520751953
Batch 26/64 loss: -1.0463180541992188
Batch 27/64 loss: -1.4790925979614258
Batch 28/64 loss: -1.5249309539794922
Batch 29/64 loss: -1.6076526641845703
Batch 30/64 loss: -1.0930871963500977
Batch 31/64 loss: -1.6525497436523438
Batch 32/64 loss: -1.2720985412597656
Batch 33/64 loss: -1.0749378204345703
Batch 34/64 loss: -1.32623291015625
Batch 35/64 loss: -1.533158302307129
Batch 36/64 loss: -1.446671485900879
Batch 37/64 loss: -1.491164207458496
Batch 38/64 loss: -0.7641620635986328
Batch 39/64 loss: -1.6139745712280273
Batch 40/64 loss: -1.3884801864624023
Batch 41/64 loss: -1.5712881088256836
Batch 42/64 loss: -1.529458999633789
Batch 43/64 loss: -1.871830940246582
Batch 44/64 loss: -1.8716087341308594
Batch 45/64 loss: -1.410593032836914
Batch 46/64 loss: -1.217055320739746
Batch 47/64 loss: -1.6243047714233398
Batch 48/64 loss: -1.3790245056152344
Batch 49/64 loss: -1.6476430892944336
Batch 50/64 loss: -1.5087080001831055
Batch 51/64 loss: -1.490407943725586
Batch 52/64 loss: -1.4615840911865234
Batch 53/64 loss: -1.5080108642578125
Batch 54/64 loss: -1.276723861694336
Batch 55/64 loss: -1.2731132507324219
Batch 56/64 loss: -1.7830133438110352
Batch 57/64 loss: -1.652256965637207
Batch 58/64 loss: -1.6793556213378906
Batch 59/64 loss: -1.517430305480957
Batch 60/64 loss: -1.8329639434814453
Batch 61/64 loss: -1.2999553680419922
Batch 62/64 loss: -1.696030616760254
Batch 63/64 loss: -1.4056596755981445
Batch 64/64 loss: -6.216259956359863
Epoch 22  Train loss: -1.550028808444154  Val loss: -1.5852425696513908
Epoch 23
-------------------------------
Batch 1/64 loss: -1.2784051895141602
Batch 2/64 loss: -1.3799943923950195
Batch 3/64 loss: -2.009488105773926
Batch 4/64 loss: -1.4557275772094727
Batch 5/64 loss: -1.7366580963134766
Batch 6/64 loss: -1.4004344940185547
Batch 7/64 loss: -1.2789888381958008
Batch 8/64 loss: -1.2451791763305664
Batch 9/64 loss: -1.4024724960327148
Batch 10/64 loss: -1.6893930435180664
Batch 11/64 loss: -1.4039373397827148
Batch 12/64 loss: -1.4421005249023438
Batch 13/64 loss: -1.3868694305419922
Batch 14/64 loss: -1.455810546875
Batch 15/64 loss: -1.3721389770507812
Batch 16/64 loss: -1.2808408737182617
Batch 17/64 loss: -1.5940971374511719
Batch 18/64 loss: -1.6538276672363281
Batch 19/64 loss: -1.9547414779663086
Batch 20/64 loss: -1.3203020095825195
Batch 21/64 loss: -1.690958023071289
Batch 22/64 loss: -1.926168441772461
Batch 23/64 loss: -1.8135852813720703
Batch 24/64 loss: -1.6446533203125
Batch 25/64 loss: -1.8723068237304688
Batch 26/64 loss: -1.4224166870117188
Batch 27/64 loss: -1.3868846893310547
Batch 28/64 loss: -1.7097129821777344
Batch 29/64 loss: -1.8936796188354492
Batch 30/64 loss: -0.8982486724853516
Batch 31/64 loss: -1.8111419677734375
Batch 32/64 loss: -1.3990707397460938
Batch 33/64 loss: -2.058718681335449
Batch 34/64 loss: -1.747385025024414
Batch 35/64 loss: -1.7223072052001953
Batch 36/64 loss: -1.3648557662963867
Batch 37/64 loss: -1.900437355041504
Batch 38/64 loss: -1.9169292449951172
Batch 39/64 loss: -1.8629961013793945
Batch 40/64 loss: -1.5028390884399414
Batch 41/64 loss: -1.2062950134277344
Batch 42/64 loss: -1.9630937576293945
Batch 43/64 loss: -1.7572212219238281
Batch 44/64 loss: -1.1300430297851562
Batch 45/64 loss: -1.590728759765625
Batch 46/64 loss: -1.6157331466674805
Batch 47/64 loss: -1.2030067443847656
Batch 48/64 loss: -1.5128898620605469
Batch 49/64 loss: -1.2672538757324219
Batch 50/64 loss: -0.7477636337280273
Batch 51/64 loss: -1.026505470275879
Batch 52/64 loss: -1.600874900817871
Batch 53/64 loss: -1.4109125137329102
Batch 54/64 loss: -1.5215396881103516
Batch 55/64 loss: -1.5108604431152344
Batch 56/64 loss: -1.4282646179199219
Batch 57/64 loss: -1.6699514389038086
Batch 58/64 loss: -1.756704330444336
Batch 59/64 loss: -1.5894365310668945
Batch 60/64 loss: -1.6092405319213867
Batch 61/64 loss: -1.8943548202514648
Batch 62/64 loss: -1.4928131103515625
Batch 63/64 loss: -1.5991439819335938
Batch 64/64 loss: -6.376165866851807
Epoch 23  Train loss: -1.6027209244522393  Val loss: -1.6822682279082097
Epoch 24
-------------------------------
Batch 1/64 loss: -1.8200674057006836
Batch 2/64 loss: -1.3176870346069336
Batch 3/64 loss: -1.6617193222045898
Batch 4/64 loss: -1.9258909225463867
Batch 5/64 loss: -1.2965326309204102
Batch 6/64 loss: -1.8195152282714844
Batch 7/64 loss: -1.6595239639282227
Batch 8/64 loss: -1.8115358352661133
Batch 9/64 loss: -1.5086517333984375
Batch 10/64 loss: -1.699148178100586
Batch 11/64 loss: -1.5299768447875977
Batch 12/64 loss: -1.2003746032714844
Batch 13/64 loss: -1.6698312759399414
Batch 14/64 loss: -1.1282882690429688
Batch 15/64 loss: -1.4074373245239258
Batch 16/64 loss: -1.458841323852539
Batch 17/64 loss: -1.7682514190673828
Batch 18/64 loss: -1.5031414031982422
Batch 19/64 loss: -1.6798582077026367
Batch 20/64 loss: -1.1086664199829102
Batch 21/64 loss: -1.373124122619629
Batch 22/64 loss: -1.5718822479248047
Batch 23/64 loss: -1.7607307434082031
Batch 24/64 loss: -1.888742446899414
Batch 25/64 loss: -1.554255485534668
Batch 26/64 loss: -1.937972068786621
Batch 27/64 loss: -1.1348085403442383
Batch 28/64 loss: -1.7460594177246094
Batch 29/64 loss: -2.0987491607666016
Batch 30/64 loss: -1.5162487030029297
Batch 31/64 loss: -1.7175922393798828
Batch 32/64 loss: -1.7183189392089844
Batch 33/64 loss: -1.9230499267578125
Batch 34/64 loss: -1.3259916305541992
Batch 35/64 loss: -1.4384098052978516
Batch 36/64 loss: -1.5767335891723633
Batch 37/64 loss: -2.0021514892578125
Batch 38/64 loss: -1.7177858352661133
Batch 39/64 loss: -1.845346450805664
Batch 40/64 loss: -1.670762062072754
Batch 41/64 loss: -1.6921672821044922
Batch 42/64 loss: -1.263167381286621
Batch 43/64 loss: -1.2049503326416016
Batch 44/64 loss: -1.4503326416015625
Batch 45/64 loss: -1.4883899688720703
Batch 46/64 loss: -1.892486572265625
Batch 47/64 loss: -1.9186620712280273
Batch 48/64 loss: -1.8182315826416016
Batch 49/64 loss: -1.7332916259765625
Batch 50/64 loss: -1.665816307067871
Batch 51/64 loss: -1.8312788009643555
Batch 52/64 loss: -1.8059167861938477
Batch 53/64 loss: -1.795607566833496
Batch 54/64 loss: -1.6738815307617188
Batch 55/64 loss: -1.7906723022460938
Batch 56/64 loss: -2.1132516860961914
Batch 57/64 loss: -1.995722770690918
Batch 58/64 loss: -1.2743854522705078
Batch 59/64 loss: -0.6889657974243164
Batch 60/64 loss: -2.0883522033691406
Batch 61/64 loss: -1.8178672790527344
Batch 62/64 loss: -2.1199140548706055
Batch 63/64 loss: -1.941035270690918
Batch 64/64 loss: -6.136155128479004
Epoch 24  Train loss: -1.6966292998370003  Val loss: -1.9510649454962348
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: -1.4533967971801758
Batch 2/64 loss: -1.9366893768310547
Batch 3/64 loss: -1.9571199417114258
Batch 4/64 loss: -2.1480207443237305
Batch 5/64 loss: -1.749624252319336
Batch 6/64 loss: -2.0845584869384766
Batch 7/64 loss: -1.802748680114746
Batch 8/64 loss: -1.7389822006225586
Batch 9/64 loss: -1.9893407821655273
Batch 10/64 loss: -1.726602554321289
Batch 11/64 loss: -1.7418174743652344
Batch 12/64 loss: -2.020482063293457
Batch 13/64 loss: -1.6525630950927734
Batch 14/64 loss: -1.2739906311035156
Batch 15/64 loss: -1.899658203125
Batch 16/64 loss: -1.5904321670532227
Batch 17/64 loss: -1.1984682083129883
Batch 18/64 loss: -1.725717544555664
Batch 19/64 loss: -1.7686662673950195
Batch 20/64 loss: -1.7651481628417969
Batch 21/64 loss: -1.9361076354980469
Batch 22/64 loss: -1.8873271942138672
Batch 23/64 loss: -1.7999401092529297
Batch 24/64 loss: -1.8783788681030273
Batch 25/64 loss: -2.0560178756713867
Batch 26/64 loss: -1.6792173385620117
Batch 27/64 loss: -2.0140161514282227
Batch 28/64 loss: -1.509566307067871
Batch 29/64 loss: -1.8151111602783203
Batch 30/64 loss: -1.911696434020996
Batch 31/64 loss: -0.9429082870483398
Batch 32/64 loss: -1.882537841796875
Batch 33/64 loss: -1.3549213409423828
Batch 34/64 loss: -2.019436836242676
Batch 35/64 loss: -1.5785093307495117
Batch 36/64 loss: -1.8928442001342773
Batch 37/64 loss: -1.7225666046142578
Batch 38/64 loss: -1.6624031066894531
Batch 39/64 loss: -1.8202934265136719
Batch 40/64 loss: -1.6192617416381836
Batch 41/64 loss: -1.414525032043457
Batch 42/64 loss: -1.946798324584961
Batch 43/64 loss: -1.6229782104492188
Batch 44/64 loss: -1.2249059677124023
Batch 45/64 loss: -1.2028799057006836
Batch 46/64 loss: -1.7234773635864258
Batch 47/64 loss: -1.7101259231567383
Batch 48/64 loss: -1.8783979415893555
Batch 49/64 loss: -1.6973867416381836
Batch 50/64 loss: -1.8427696228027344
Batch 51/64 loss: -1.879776954650879
Batch 52/64 loss: -1.3906164169311523
Batch 53/64 loss: -1.792459487915039
Batch 54/64 loss: -1.5557947158813477
Batch 55/64 loss: -1.7782707214355469
Batch 56/64 loss: -1.4736804962158203
Batch 57/64 loss: -1.6791906356811523
Batch 58/64 loss: -1.8184938430786133
Batch 59/64 loss: -1.754507064819336
Batch 60/64 loss: -2.120523452758789
Batch 61/64 loss: -1.594008445739746
Batch 62/64 loss: -1.6571779251098633
Batch 63/64 loss: -1.3718090057373047
Batch 64/64 loss: -6.134859085083008
Epoch 25  Train loss: -1.7715888303868912  Val loss: -1.9949785212880558
Saving best model, epoch: 25
Epoch 26
-------------------------------
Batch 1/64 loss: -1.771463394165039
Batch 2/64 loss: -2.000452995300293
Batch 3/64 loss: -2.0054025650024414
Batch 4/64 loss: -1.6349172592163086
Batch 5/64 loss: -1.9676752090454102
Batch 6/64 loss: -1.819453239440918
Batch 7/64 loss: -1.7999448776245117
Batch 8/64 loss: -2.0686025619506836
Batch 9/64 loss: -2.0840234756469727
Batch 10/64 loss: -1.8032188415527344
Batch 11/64 loss: -1.8309335708618164
Batch 12/64 loss: -2.1499061584472656
Batch 13/64 loss: -1.5768260955810547
Batch 14/64 loss: -1.6324520111083984
Batch 15/64 loss: -1.8899927139282227
Batch 16/64 loss: -1.4512348175048828
Batch 17/64 loss: -1.5816001892089844
Batch 18/64 loss: -1.7883930206298828
Batch 19/64 loss: -1.5409059524536133
Batch 20/64 loss: -1.9041471481323242
Batch 21/64 loss: -1.9738664627075195
Batch 22/64 loss: -1.9187211990356445
Batch 23/64 loss: -1.5137090682983398
Batch 24/64 loss: -1.5704412460327148
Batch 25/64 loss: -1.805893898010254
Batch 26/64 loss: -2.0775232315063477
Batch 27/64 loss: -1.9759559631347656
Batch 28/64 loss: -2.2115964889526367
Batch 29/64 loss: -1.847951889038086
Batch 30/64 loss: -1.671895980834961
Batch 31/64 loss: -2.0556249618530273
Batch 32/64 loss: -1.7199907302856445
Batch 33/64 loss: -1.2876577377319336
Batch 34/64 loss: -1.518385887145996
Batch 35/64 loss: -1.3519887924194336
Batch 36/64 loss: -1.4746589660644531
Batch 37/64 loss: -1.830240249633789
Batch 38/64 loss: -1.7864551544189453
Batch 39/64 loss: -1.6841516494750977
Batch 40/64 loss: -1.5501937866210938
Batch 41/64 loss: -1.506927490234375
Batch 42/64 loss: -1.5005102157592773
Batch 43/64 loss: -1.673187255859375
Batch 44/64 loss: -1.7771968841552734
Batch 45/64 loss: -1.8281116485595703
Batch 46/64 loss: -2.069272041320801
Batch 47/64 loss: -1.5804929733276367
Batch 48/64 loss: -2.245697021484375
Batch 49/64 loss: -1.9056835174560547
Batch 50/64 loss: -1.3671751022338867
Batch 51/64 loss: -1.9693708419799805
Batch 52/64 loss: -1.8499927520751953
Batch 53/64 loss: -1.8676872253417969
Batch 54/64 loss: -1.7110357284545898
Batch 55/64 loss: -2.2497215270996094
Batch 56/64 loss: -1.715616226196289
Batch 57/64 loss: -2.130059242248535
Batch 58/64 loss: -1.5773601531982422
Batch 59/64 loss: -1.4675540924072266
Batch 60/64 loss: -1.8701839447021484
Batch 61/64 loss: -1.9928827285766602
Batch 62/64 loss: -1.600046157836914
Batch 63/64 loss: -1.7073535919189453
Batch 64/64 loss: -6.7782816886901855
Epoch 26  Train loss: -1.8411808481403427  Val loss: -2.000137905894276
Saving best model, epoch: 26
Epoch 27
-------------------------------
Batch 1/64 loss: -1.6422529220581055
Batch 2/64 loss: -1.6945123672485352
Batch 3/64 loss: -1.4585819244384766
Batch 4/64 loss: -0.7643098831176758
Batch 5/64 loss: -1.8111333847045898
Batch 6/64 loss: -1.9078998565673828
Batch 7/64 loss: -2.0292539596557617
Batch 8/64 loss: -1.4384679794311523
Batch 9/64 loss: -1.4515228271484375
Batch 10/64 loss: -1.1214227676391602
Batch 11/64 loss: -1.5443229675292969
Batch 12/64 loss: -1.760965347290039
Batch 13/64 loss: -1.6187801361083984
Batch 14/64 loss: -1.4116191864013672
Batch 15/64 loss: -1.8441486358642578
Batch 16/64 loss: -1.5552453994750977
Batch 17/64 loss: -1.5618267059326172
Batch 18/64 loss: -1.446375846862793
Batch 19/64 loss: -1.8104982376098633
Batch 20/64 loss: -1.6694917678833008
Batch 21/64 loss: -1.189265251159668
Batch 22/64 loss: -1.9987764358520508
Batch 23/64 loss: -1.9397850036621094
Batch 24/64 loss: -1.910944938659668
Batch 25/64 loss: -1.6886224746704102
Batch 26/64 loss: -0.8649911880493164
Batch 27/64 loss: -1.4183406829833984
Batch 28/64 loss: -1.9605932235717773
Batch 29/64 loss: -1.938603401184082
Batch 30/64 loss: -1.6969804763793945
Batch 31/64 loss: -1.73052978515625
Batch 32/64 loss: -1.4892730712890625
Batch 33/64 loss: -2.0881423950195312
Batch 34/64 loss: -2.046675682067871
Batch 35/64 loss: -1.9730987548828125
Batch 36/64 loss: -1.5083236694335938
Batch 37/64 loss: -2.121109962463379
Batch 38/64 loss: -1.8978862762451172
Batch 39/64 loss: -1.7733306884765625
Batch 40/64 loss: -1.647745132446289
Batch 41/64 loss: -1.1948356628417969
Batch 42/64 loss: -2.0110416412353516
Batch 43/64 loss: -1.5213403701782227
Batch 44/64 loss: -2.0913524627685547
Batch 45/64 loss: -1.6930437088012695
Batch 46/64 loss: -1.6152677536010742
Batch 47/64 loss: -1.6096420288085938
Batch 48/64 loss: -1.8473272323608398
Batch 49/64 loss: -2.006516456604004
Batch 50/64 loss: -1.9677152633666992
Batch 51/64 loss: -2.002025604248047
Batch 52/64 loss: -2.060664176940918
Batch 53/64 loss: -1.471766471862793
Batch 54/64 loss: -1.930048942565918
Batch 55/64 loss: -1.9234199523925781
Batch 56/64 loss: -1.9897022247314453
Batch 57/64 loss: -1.1514081954956055
Batch 58/64 loss: -2.1235246658325195
Batch 59/64 loss: -2.1765384674072266
Batch 60/64 loss: -1.7010736465454102
Batch 61/64 loss: -2.1649551391601562
Batch 62/64 loss: -1.7003793716430664
Batch 63/64 loss: -1.7161483764648438
Batch 64/64 loss: -6.773901462554932
Epoch 27  Train loss: -1.7753068942649692  Val loss: -1.956040542969589
Epoch 28
-------------------------------
Batch 1/64 loss: -2.053624153137207
Batch 2/64 loss: -2.165135383605957
Batch 3/64 loss: -1.9247159957885742
Batch 4/64 loss: -1.8056564331054688
Batch 5/64 loss: -2.1389589309692383
Batch 6/64 loss: -1.7335176467895508
Batch 7/64 loss: -2.0453052520751953
Batch 8/64 loss: -1.0868339538574219
Batch 9/64 loss: -1.6527395248413086
Batch 10/64 loss: -2.0424795150756836
Batch 11/64 loss: -2.089792251586914
Batch 12/64 loss: -2.0370359420776367
Batch 13/64 loss: -1.7535295486450195
Batch 14/64 loss: -1.5425233840942383
Batch 15/64 loss: -1.9504499435424805
Batch 16/64 loss: -2.0644588470458984
Batch 17/64 loss: -1.415236473083496
Batch 18/64 loss: -1.575261116027832
Batch 19/64 loss: -1.6760454177856445
Batch 20/64 loss: -1.7271013259887695
Batch 21/64 loss: -2.031888961791992
Batch 22/64 loss: -2.1964406967163086
Batch 23/64 loss: -1.4988222122192383
Batch 24/64 loss: -2.1161575317382812
Batch 25/64 loss: -2.193028450012207
Batch 26/64 loss: -1.771066665649414
Batch 27/64 loss: -1.6798286437988281
Batch 28/64 loss: -1.493077278137207
Batch 29/64 loss: -1.9682207107543945
Batch 30/64 loss: -2.0632495880126953
Batch 31/64 loss: -1.7859258651733398
Batch 32/64 loss: -1.9588041305541992
Batch 33/64 loss: -2.152618408203125
Batch 34/64 loss: -2.307706832885742
Batch 35/64 loss: -1.2550621032714844
Batch 36/64 loss: -1.208024024963379
Batch 37/64 loss: -1.6706600189208984
Batch 38/64 loss: -2.03121280670166
Batch 39/64 loss: -1.6717815399169922
Batch 40/64 loss: -1.8952140808105469
Batch 41/64 loss: -2.1710472106933594
Batch 42/64 loss: -1.8540830612182617
Batch 43/64 loss: -1.7905359268188477
Batch 44/64 loss: -1.681382179260254
Batch 45/64 loss: -2.0119810104370117
Batch 46/64 loss: -2.1547555923461914
Batch 47/64 loss: -1.8693475723266602
Batch 48/64 loss: -1.7634811401367188
Batch 49/64 loss: -1.7016096115112305
Batch 50/64 loss: -1.0985908508300781
Batch 51/64 loss: -1.607213020324707
Batch 52/64 loss: -1.9539299011230469
Batch 53/64 loss: -1.8588752746582031
Batch 54/64 loss: -1.641326904296875
Batch 55/64 loss: -1.9400157928466797
Batch 56/64 loss: -2.064347267150879
Batch 57/64 loss: -1.2025165557861328
Batch 58/64 loss: -1.8908100128173828
Batch 59/64 loss: -1.309610366821289
Batch 60/64 loss: -2.210507392883301
Batch 61/64 loss: -1.9502277374267578
Batch 62/64 loss: -2.1961898803710938
Batch 63/64 loss: -1.8083810806274414
Batch 64/64 loss: -5.753645896911621
Epoch 28  Train loss: -1.8741206487019857  Val loss: -1.6553103653426022
Epoch 29
-------------------------------
Batch 1/64 loss: -1.7516231536865234
Batch 2/64 loss: -2.077198028564453
Batch 3/64 loss: -1.8624553680419922
Batch 4/64 loss: -1.3107004165649414
Batch 5/64 loss: -2.0484724044799805
Batch 6/64 loss: -1.6648941040039062
Batch 7/64 loss: -2.144993782043457
Batch 8/64 loss: -1.9967670440673828
Batch 9/64 loss: -1.7094249725341797
Batch 10/64 loss: -2.1259803771972656
Batch 11/64 loss: -2.2578296661376953
Batch 12/64 loss: -1.8033390045166016
Batch 13/64 loss: -1.8938751220703125
Batch 14/64 loss: -1.7010478973388672
Batch 15/64 loss: -1.915506362915039
Batch 16/64 loss: -1.9622678756713867
Batch 17/64 loss: -2.050386428833008
Batch 18/64 loss: -1.948516845703125
Batch 19/64 loss: -1.8306140899658203
Batch 20/64 loss: -1.8541898727416992
Batch 21/64 loss: -0.6825666427612305
Batch 22/64 loss: -2.0229015350341797
Batch 23/64 loss: -1.7311468124389648
Batch 24/64 loss: -1.6696500778198242
Batch 25/64 loss: -1.8824310302734375
Batch 26/64 loss: -2.171762466430664
Batch 27/64 loss: -1.7687702178955078
Batch 28/64 loss: -1.7125797271728516
Batch 29/64 loss: -2.0041961669921875
Batch 30/64 loss: -1.8930597305297852
Batch 31/64 loss: -1.7258806228637695
Batch 32/64 loss: -2.2089061737060547
Batch 33/64 loss: -2.07183837890625
Batch 34/64 loss: -1.8703107833862305
Batch 35/64 loss: -2.2354698181152344
Batch 36/64 loss: -1.987898826599121
Batch 37/64 loss: -1.7849750518798828
Batch 38/64 loss: -2.197885513305664
Batch 39/64 loss: -2.1953821182250977
Batch 40/64 loss: -1.97869873046875
Batch 41/64 loss: -1.4608783721923828
Batch 42/64 loss: -1.5970497131347656
Batch 43/64 loss: -1.8837318420410156
Batch 44/64 loss: -1.360748291015625
Batch 45/64 loss: -2.11529541015625
Batch 46/64 loss: -1.6005945205688477
Batch 47/64 loss: -1.460463523864746
Batch 48/64 loss: -1.9523706436157227
Batch 49/64 loss: -2.000380516052246
Batch 50/64 loss: -1.4981813430786133
Batch 51/64 loss: -1.6008825302124023
Batch 52/64 loss: -1.8696260452270508
Batch 53/64 loss: -1.9135494232177734
Batch 54/64 loss: -2.185659408569336
Batch 55/64 loss: -1.8494586944580078
Batch 56/64 loss: -1.6448192596435547
Batch 57/64 loss: -1.5301647186279297
Batch 58/64 loss: -1.4617424011230469
Batch 59/64 loss: -1.8625707626342773
Batch 60/64 loss: -2.122328758239746
Batch 61/64 loss: -1.4680118560791016
Batch 62/64 loss: -1.7618227005004883
Batch 63/64 loss: -1.8131866455078125
Batch 64/64 loss: -6.587255477905273
Epoch 29  Train loss: -1.8927114075305416  Val loss: -1.784538452567923
Epoch 30
-------------------------------
Batch 1/64 loss: -1.690455436706543
Batch 2/64 loss: -1.677016258239746
Batch 3/64 loss: -1.709202766418457
Batch 4/64 loss: -1.73175048828125
Batch 5/64 loss: -1.9907770156860352
Batch 6/64 loss: -1.9787359237670898
Batch 7/64 loss: -2.0421276092529297
Batch 8/64 loss: -1.7385978698730469
Batch 9/64 loss: -1.9942312240600586
Batch 10/64 loss: -1.586411476135254
Batch 11/64 loss: -1.8621082305908203
Batch 12/64 loss: -1.758030891418457
Batch 13/64 loss: -1.5956525802612305
Batch 14/64 loss: -2.1243858337402344
Batch 15/64 loss: -1.949758529663086
Batch 16/64 loss: -2.145099639892578
Batch 17/64 loss: -2.024868965148926
Batch 18/64 loss: -1.8672351837158203
Batch 19/64 loss: -1.5809612274169922
Batch 20/64 loss: -1.991196632385254
Batch 21/64 loss: -1.8952951431274414
Batch 22/64 loss: -1.747650146484375
Batch 23/64 loss: -2.074690818786621
Batch 24/64 loss: -1.8292465209960938
Batch 25/64 loss: -1.8372573852539062
Batch 26/64 loss: -1.5594768524169922
Batch 27/64 loss: -1.922511100769043
Batch 28/64 loss: -1.680220603942871
Batch 29/64 loss: -1.5789318084716797
Batch 30/64 loss: -1.7680768966674805
Batch 31/64 loss: -1.4151124954223633
Batch 32/64 loss: -2.119856834411621
Batch 33/64 loss: -2.026021957397461
Batch 34/64 loss: -1.7263269424438477
Batch 35/64 loss: -1.9735908508300781
Batch 36/64 loss: -1.504129409790039
Batch 37/64 loss: -1.8812074661254883
Batch 38/64 loss: -1.8036136627197266
Batch 39/64 loss: -2.1672258377075195
Batch 40/64 loss: -2.1377620697021484
Batch 41/64 loss: -1.8006668090820312
Batch 42/64 loss: -1.5520458221435547
Batch 43/64 loss: -2.0154380798339844
Batch 44/64 loss: -1.960026741027832
Batch 45/64 loss: -1.8587045669555664
Batch 46/64 loss: -1.732706069946289
Batch 47/64 loss: -1.0280895233154297
Batch 48/64 loss: -1.9158754348754883
Batch 49/64 loss: -1.9714221954345703
Batch 50/64 loss: -1.7841968536376953
Batch 51/64 loss: -1.790431022644043
Batch 52/64 loss: -2.1278181076049805
Batch 53/64 loss: -2.0324935913085938
Batch 54/64 loss: -1.9359636306762695
Batch 55/64 loss: -1.8343305587768555
Batch 56/64 loss: -1.94464111328125
Batch 57/64 loss: -1.809103012084961
Batch 58/64 loss: -2.168132781982422
Batch 59/64 loss: -2.076129913330078
Batch 60/64 loss: -1.8225669860839844
Batch 61/64 loss: -1.9069385528564453
Batch 62/64 loss: -1.6138792037963867
Batch 63/64 loss: -2.087801933288574
Batch 64/64 loss: -6.160453796386719
Epoch 30  Train loss: -1.899240022547105  Val loss: -2.042361387272471
Saving best model, epoch: 30
Epoch 31
-------------------------------
Batch 1/64 loss: -1.8145532608032227
Batch 2/64 loss: -1.9889583587646484
Batch 3/64 loss: -2.1543703079223633
Batch 4/64 loss: -1.5485620498657227
Batch 5/64 loss: -2.0536413192749023
Batch 6/64 loss: -2.1830530166625977
Batch 7/64 loss: -1.8999624252319336
Batch 8/64 loss: -1.303731918334961
Batch 9/64 loss: -1.9084863662719727
Batch 10/64 loss: -2.2515478134155273
Batch 11/64 loss: -2.032954216003418
Batch 12/64 loss: -2.175291061401367
Batch 13/64 loss: -2.0393571853637695
Batch 14/64 loss: -2.3561439514160156
Batch 15/64 loss: -1.9191999435424805
Batch 16/64 loss: -1.6404008865356445
Batch 17/64 loss: -1.9332380294799805
Batch 18/64 loss: -2.0645790100097656
Batch 19/64 loss: -1.6369953155517578
Batch 20/64 loss: -2.1911487579345703
Batch 21/64 loss: -2.0301856994628906
Batch 22/64 loss: -1.8975372314453125
Batch 23/64 loss: -2.1607446670532227
Batch 24/64 loss: -2.1451597213745117
Batch 25/64 loss: -2.233107566833496
Batch 26/64 loss: -1.6658697128295898
Batch 27/64 loss: -1.9772062301635742
Batch 28/64 loss: -1.8311967849731445
Batch 29/64 loss: -1.990616798400879
Batch 30/64 loss: -2.0275115966796875
Batch 31/64 loss: -2.0475120544433594
Batch 32/64 loss: -1.8124942779541016
Batch 33/64 loss: -1.7108955383300781
Batch 34/64 loss: -1.928788185119629
Batch 35/64 loss: -1.769211769104004
Batch 36/64 loss: -1.935072898864746
Batch 37/64 loss: -1.914076805114746
Batch 38/64 loss: -1.9704694747924805
Batch 39/64 loss: -0.7745580673217773
Batch 40/64 loss: -1.9658260345458984
Batch 41/64 loss: -1.2226905822753906
Batch 42/64 loss: -1.836578369140625
Batch 43/64 loss: -1.980128288269043
Batch 44/64 loss: -1.945723533630371
Batch 45/64 loss: -1.7172212600708008
Batch 46/64 loss: -1.5735979080200195
Batch 47/64 loss: -2.24298095703125
Batch 48/64 loss: -1.6244440078735352
Batch 49/64 loss: -2.061770439147949
Batch 50/64 loss: -1.9098701477050781
Batch 51/64 loss: -1.2300472259521484
Batch 52/64 loss: -2.190157890319824
Batch 53/64 loss: -1.8384037017822266
Batch 54/64 loss: -1.5249319076538086
Batch 55/64 loss: -1.9519405364990234
Batch 56/64 loss: -1.897207260131836
Batch 57/64 loss: -2.049015998840332
Batch 58/64 loss: -1.9532432556152344
Batch 59/64 loss: -2.2739334106445312
Batch 60/64 loss: -1.6862659454345703
Batch 61/64 loss: -1.4197072982788086
Batch 62/64 loss: -1.3917913436889648
Batch 63/64 loss: -1.9161252975463867
Batch 64/64 loss: -5.951316833496094
Epoch 31  Train loss: -1.9260467529296874  Val loss: -2.0628217454628435
Saving best model, epoch: 31
Epoch 32
-------------------------------
Batch 1/64 loss: -1.918686866760254
Batch 2/64 loss: -1.9893074035644531
Batch 3/64 loss: -1.7924814224243164
Batch 4/64 loss: -2.041995048522949
Batch 5/64 loss: -2.101202964782715
Batch 6/64 loss: -1.3437824249267578
Batch 7/64 loss: -2.2229957580566406
Batch 8/64 loss: -1.811640739440918
Batch 9/64 loss: -2.1024818420410156
Batch 10/64 loss: -1.9229793548583984
Batch 11/64 loss: -2.0278730392456055
Batch 12/64 loss: -2.1818790435791016
Batch 13/64 loss: -1.5289897918701172
Batch 14/64 loss: -2.060232162475586
Batch 15/64 loss: -2.201692581176758
Batch 16/64 loss: -2.425008773803711
Batch 17/64 loss: -2.030716896057129
Batch 18/64 loss: -1.9676361083984375
Batch 19/64 loss: -1.9447879791259766
Batch 20/64 loss: -2.117656707763672
Batch 21/64 loss: -1.1471900939941406
Batch 22/64 loss: -1.8440666198730469
Batch 23/64 loss: -2.2307281494140625
Batch 24/64 loss: -1.7781877517700195
Batch 25/64 loss: -1.8396720886230469
Batch 26/64 loss: -2.2033510208129883
Batch 27/64 loss: -1.7617692947387695
Batch 28/64 loss: -1.7563791275024414
Batch 29/64 loss: -1.7680273056030273
Batch 30/64 loss: -1.9869661331176758
Batch 31/64 loss: -1.672475814819336
Batch 32/64 loss: -1.5293970108032227
Batch 33/64 loss: -1.7246427536010742
Batch 34/64 loss: -2.102367401123047
Batch 35/64 loss: -2.036531448364258
Batch 36/64 loss: -1.9618072509765625
Batch 37/64 loss: -1.5020380020141602
Batch 38/64 loss: -1.9444236755371094
Batch 39/64 loss: -1.986800193786621
Batch 40/64 loss: -1.5858211517333984
Batch 41/64 loss: -2.0032596588134766
Batch 42/64 loss: -1.56634521484375
Batch 43/64 loss: -1.9060192108154297
Batch 44/64 loss: -2.173490524291992
Batch 45/64 loss: -1.7076988220214844
Batch 46/64 loss: -1.4137859344482422
Batch 47/64 loss: -1.8173933029174805
Batch 48/64 loss: -1.6470794677734375
Batch 49/64 loss: -1.7666130065917969
Batch 50/64 loss: -1.88726806640625
Batch 51/64 loss: -1.8822412490844727
Batch 52/64 loss: -1.8512983322143555
Batch 53/64 loss: -1.9687957763671875
Batch 54/64 loss: -2.1991357803344727
Batch 55/64 loss: -1.9685611724853516
Batch 56/64 loss: -2.0329017639160156
Batch 57/64 loss: -1.9424657821655273
Batch 58/64 loss: -2.080376625061035
Batch 59/64 loss: -1.4059762954711914
Batch 60/64 loss: -1.8485374450683594
Batch 61/64 loss: -1.5403680801391602
Batch 62/64 loss: -1.2005949020385742
Batch 63/64 loss: -1.515183448791504
Batch 64/64 loss: -6.951807975769043
Epoch 32  Train loss: -1.9237006280936446  Val loss: -1.3401296163342662
Epoch 33
-------------------------------
Batch 1/64 loss: -1.2428512573242188
Batch 2/64 loss: -0.43480491638183594
Batch 3/64 loss: -1.2963695526123047
Batch 4/64 loss: -1.580270767211914
Batch 5/64 loss: -1.9743080139160156
Batch 6/64 loss: -1.2683286666870117
Batch 7/64 loss: -1.6822700500488281
Batch 8/64 loss: -1.5112380981445312
Batch 9/64 loss: -1.8022537231445312
Batch 10/64 loss: -1.5043754577636719
Batch 11/64 loss: -1.7095832824707031
Batch 12/64 loss: -1.6324939727783203
Batch 13/64 loss: -2.085865020751953
Batch 14/64 loss: -2.136349678039551
Batch 15/64 loss: -2.1532840728759766
Batch 16/64 loss: -2.0623779296875
Batch 17/64 loss: -1.9605321884155273
Batch 18/64 loss: -1.3424205780029297
Batch 19/64 loss: -1.8103981018066406
Batch 20/64 loss: -2.070126533508301
Batch 21/64 loss: -1.9059762954711914
Batch 22/64 loss: -1.9244365692138672
Batch 23/64 loss: -1.8202524185180664
Batch 24/64 loss: -1.876500129699707
Batch 25/64 loss: -1.927840232849121
Batch 26/64 loss: -1.8209705352783203
Batch 27/64 loss: -2.0963621139526367
Batch 28/64 loss: -2.0925073623657227
Batch 29/64 loss: -1.846872329711914
Batch 30/64 loss: -1.5561895370483398
Batch 31/64 loss: -1.2996244430541992
Batch 32/64 loss: -1.7085857391357422
Batch 33/64 loss: -2.065288543701172
Batch 34/64 loss: -2.0002002716064453
Batch 35/64 loss: -2.110353469848633
Batch 36/64 loss: -2.008793830871582
Batch 37/64 loss: -1.6837711334228516
Batch 38/64 loss: -2.172971725463867
Batch 39/64 loss: -1.754145622253418
Batch 40/64 loss: -2.0003843307495117
Batch 41/64 loss: -2.3710765838623047
Batch 42/64 loss: -2.1063919067382812
Batch 43/64 loss: -1.5314054489135742
Batch 44/64 loss: -1.978287696838379
Batch 45/64 loss: -1.9745521545410156
Batch 46/64 loss: -1.5774288177490234
Batch 47/64 loss: -2.0825042724609375
Batch 48/64 loss: -2.1275100708007812
Batch 49/64 loss: -2.0632810592651367
Batch 50/64 loss: -1.9597043991088867
Batch 51/64 loss: -2.1404991149902344
Batch 52/64 loss: -2.004715919494629
Batch 53/64 loss: -1.596827507019043
Batch 54/64 loss: -1.6812515258789062
Batch 55/64 loss: -1.8848237991333008
Batch 56/64 loss: -1.9353456497192383
Batch 57/64 loss: -2.2632598876953125
Batch 58/64 loss: -1.759964942932129
Batch 59/64 loss: -2.3655338287353516
Batch 60/64 loss: -2.120114326477051
Batch 61/64 loss: -1.8939342498779297
Batch 62/64 loss: -1.7955236434936523
Batch 63/64 loss: -2.2048025131225586
Batch 64/64 loss: -6.644204139709473
Epoch 33  Train loss: -1.9032850340300915  Val loss: -2.2295259167648265
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: -2.0660133361816406
Batch 2/64 loss: -1.7505645751953125
Batch 3/64 loss: -1.7573280334472656
Batch 4/64 loss: -2.2354230880737305
Batch 5/64 loss: -1.7459373474121094
Batch 6/64 loss: -2.146974563598633
Batch 7/64 loss: -1.4335765838623047
Batch 8/64 loss: -2.479513168334961
Batch 9/64 loss: -1.9899616241455078
Batch 10/64 loss: -1.6054134368896484
Batch 11/64 loss: -2.2689857482910156
Batch 12/64 loss: -1.9942998886108398
Batch 13/64 loss: -2.0969038009643555
Batch 14/64 loss: -2.0358400344848633
Batch 15/64 loss: -1.9336090087890625
Batch 16/64 loss: -2.1090822219848633
Batch 17/64 loss: -1.9881744384765625
Batch 18/64 loss: -1.703073501586914
Batch 19/64 loss: -2.2093496322631836
Batch 20/64 loss: -2.1627197265625
Batch 21/64 loss: -2.119142532348633
Batch 22/64 loss: -1.9084396362304688
Batch 23/64 loss: -1.934823989868164
Batch 24/64 loss: -2.2978515625
Batch 25/64 loss: -2.1559925079345703
Batch 26/64 loss: -1.7542285919189453
Batch 27/64 loss: -2.2003250122070312
Batch 28/64 loss: -1.5381956100463867
Batch 29/64 loss: -2.2186975479125977
Batch 30/64 loss: -2.1778383255004883
Batch 31/64 loss: -1.8922204971313477
Batch 32/64 loss: -2.143588066101074
Batch 33/64 loss: -2.379885673522949
Batch 34/64 loss: -2.0300111770629883
Batch 35/64 loss: -2.1334104537963867
Batch 36/64 loss: -1.5753583908081055
Batch 37/64 loss: -2.2445602416992188
Batch 38/64 loss: -1.9068565368652344
Batch 39/64 loss: -2.135533332824707
Batch 40/64 loss: -1.6834373474121094
Batch 41/64 loss: -2.3238563537597656
Batch 42/64 loss: -2.358491897583008
Batch 43/64 loss: -2.1935243606567383
Batch 44/64 loss: -2.1094207763671875
Batch 45/64 loss: -2.157888412475586
Batch 46/64 loss: -2.1483659744262695
Batch 47/64 loss: -1.8574228286743164
Batch 48/64 loss: -2.100496292114258
Batch 49/64 loss: -1.9170446395874023
Batch 50/64 loss: -1.7273740768432617
Batch 51/64 loss: -1.9708337783813477
Batch 52/64 loss: -1.757659912109375
Batch 53/64 loss: -1.7342529296875
Batch 54/64 loss: -1.5869789123535156
Batch 55/64 loss: -2.2480201721191406
Batch 56/64 loss: -2.0675201416015625
Batch 57/64 loss: -1.601186752319336
Batch 58/64 loss: -2.141735076904297
Batch 59/64 loss: -1.9524822235107422
Batch 60/64 loss: -2.344935417175293
Batch 61/64 loss: -1.6451053619384766
Batch 62/64 loss: -2.2956790924072266
Batch 63/64 loss: -2.108738899230957
Batch 64/64 loss: -6.542489051818848
Epoch 34  Train loss: -2.0611611272774493  Val loss: -2.2277964693574153
Epoch 35
-------------------------------
Batch 1/64 loss: -1.6118965148925781
Batch 2/64 loss: -1.9452552795410156
Batch 3/64 loss: -1.8080377578735352
Batch 4/64 loss: -1.9832353591918945
Batch 5/64 loss: -2.0554428100585938
Batch 6/64 loss: -1.7872037887573242
Batch 7/64 loss: -1.894155502319336
Batch 8/64 loss: -2.02182674407959
Batch 9/64 loss: -2.212301254272461
Batch 10/64 loss: -2.3294296264648438
Batch 11/64 loss: -2.003049850463867
Batch 12/64 loss: -1.9748973846435547
Batch 13/64 loss: -2.218695640563965
Batch 14/64 loss: -1.9560184478759766
Batch 15/64 loss: -1.8853330612182617
Batch 16/64 loss: -1.991755485534668
Batch 17/64 loss: -1.8914880752563477
Batch 18/64 loss: -2.287980079650879
Batch 19/64 loss: -1.9149084091186523
Batch 20/64 loss: -2.0731639862060547
Batch 21/64 loss: -1.6533498764038086
Batch 22/64 loss: -2.073550224304199
Batch 23/64 loss: -1.845010757446289
Batch 24/64 loss: -2.0325307846069336
Batch 25/64 loss: -1.3863420486450195
Batch 26/64 loss: -1.9033231735229492
Batch 27/64 loss: -1.821502685546875
Batch 28/64 loss: -2.0620193481445312
Batch 29/64 loss: -2.176898956298828
Batch 30/64 loss: -2.2110891342163086
Batch 31/64 loss: -2.3620338439941406
Batch 32/64 loss: -1.9757080078125
Batch 33/64 loss: -2.0340776443481445
Batch 34/64 loss: -1.7275705337524414
Batch 35/64 loss: -2.475253105163574
Batch 36/64 loss: -2.195733070373535
Batch 37/64 loss: -1.8876161575317383
Batch 38/64 loss: -2.1725378036499023
Batch 39/64 loss: -1.730402946472168
Batch 40/64 loss: -1.7193479537963867
Batch 41/64 loss: -1.9240999221801758
Batch 42/64 loss: -2.2054271697998047
Batch 43/64 loss: -1.3927650451660156
Batch 44/64 loss: -2.134084701538086
Batch 45/64 loss: -2.0389528274536133
Batch 46/64 loss: -2.2020416259765625
Batch 47/64 loss: -1.9826240539550781
Batch 48/64 loss: -1.9495859146118164
Batch 49/64 loss: -1.9973125457763672
Batch 50/64 loss: -2.3109655380249023
Batch 51/64 loss: -2.2309446334838867
Batch 52/64 loss: -1.946096420288086
Batch 53/64 loss: -2.0396013259887695
Batch 54/64 loss: -2.3227386474609375
Batch 55/64 loss: -1.8725852966308594
Batch 56/64 loss: -1.940751075744629
Batch 57/64 loss: -2.205434799194336
Batch 58/64 loss: -2.3571672439575195
Batch 59/64 loss: -2.176976203918457
Batch 60/64 loss: -2.0950937271118164
Batch 61/64 loss: -2.1778793334960938
Batch 62/64 loss: -1.8573932647705078
Batch 63/64 loss: -1.8497705459594727
Batch 64/64 loss: -6.955806732177734
Epoch 35  Train loss: -2.066182274911918  Val loss: -2.22816795008289
Epoch 36
-------------------------------
Batch 1/64 loss: -1.9876737594604492
Batch 2/64 loss: -2.3244056701660156
Batch 3/64 loss: -2.130913734436035
Batch 4/64 loss: -2.3796377182006836
Batch 5/64 loss: -1.8740520477294922
Batch 6/64 loss: -2.2377099990844727
Batch 7/64 loss: -1.8049249649047852
Batch 8/64 loss: -2.2422685623168945
Batch 9/64 loss: -1.984609603881836
Batch 10/64 loss: -1.2680330276489258
Batch 11/64 loss: -2.188654899597168
Batch 12/64 loss: -2.1992244720458984
Batch 13/64 loss: -1.7486467361450195
Batch 14/64 loss: -2.0253257751464844
Batch 15/64 loss: -1.5249691009521484
Batch 16/64 loss: -2.3621416091918945
Batch 17/64 loss: -1.4373559951782227
Batch 18/64 loss: -1.9629993438720703
Batch 19/64 loss: -1.7775754928588867
Batch 20/64 loss: -1.999537467956543
Batch 21/64 loss: -1.6719064712524414
Batch 22/64 loss: -1.9258537292480469
Batch 23/64 loss: -2.238980293273926
Batch 24/64 loss: -1.9833393096923828
Batch 25/64 loss: -1.9842357635498047
Batch 26/64 loss: -2.267120361328125
Batch 27/64 loss: -1.3390750885009766
Batch 28/64 loss: -1.682662010192871
Batch 29/64 loss: -1.8522586822509766
Batch 30/64 loss: -1.961639404296875
Batch 31/64 loss: -1.6738567352294922
Batch 32/64 loss: -1.3404150009155273
Batch 33/64 loss: -1.7636909484863281
Batch 34/64 loss: -2.2457542419433594
Batch 35/64 loss: -2.2605199813842773
Batch 36/64 loss: -2.1497955322265625
Batch 37/64 loss: -2.134510040283203
Batch 38/64 loss: -1.5330123901367188
Batch 39/64 loss: -2.2100324630737305
Batch 40/64 loss: -1.300826072692871
Batch 41/64 loss: -1.748520851135254
Batch 42/64 loss: -2.0712900161743164
Batch 43/64 loss: -1.9451026916503906
Batch 44/64 loss: -1.9270381927490234
Batch 45/64 loss: -2.3553123474121094
Batch 46/64 loss: -1.6917839050292969
Batch 47/64 loss: -1.7225618362426758
Batch 48/64 loss: -2.312152862548828
Batch 49/64 loss: -2.097989082336426
Batch 50/64 loss: -1.6527214050292969
Batch 51/64 loss: -2.3437461853027344
Batch 52/64 loss: -2.350255012512207
Batch 53/64 loss: -1.5611639022827148
Batch 54/64 loss: -2.096390724182129
Batch 55/64 loss: -2.298280715942383
Batch 56/64 loss: -1.946364402770996
Batch 57/64 loss: -2.0195608139038086
Batch 58/64 loss: -2.0073022842407227
Batch 59/64 loss: -1.9195232391357422
Batch 60/64 loss: -1.8117027282714844
Batch 61/64 loss: -1.8049774169921875
Batch 62/64 loss: -1.8535890579223633
Batch 63/64 loss: -1.5273323059082031
Batch 64/64 loss: -6.618797302246094
Epoch 36  Train loss: -1.9922965405034083  Val loss: -2.1640953509668304
Epoch 37
-------------------------------
Batch 1/64 loss: -2.0863819122314453
Batch 2/64 loss: -1.8169851303100586
Batch 3/64 loss: -2.0954790115356445
Batch 4/64 loss: -1.8979711532592773
Batch 5/64 loss: -2.4783363342285156
Batch 6/64 loss: -2.050755500793457
Batch 7/64 loss: -2.3225669860839844
Batch 8/64 loss: -2.403286933898926
Batch 9/64 loss: -1.6740455627441406
Batch 10/64 loss: -2.144434928894043
Batch 11/64 loss: -2.0963611602783203
Batch 12/64 loss: -2.2340688705444336
Batch 13/64 loss: -2.1556262969970703
Batch 14/64 loss: -2.374936103820801
Batch 15/64 loss: -1.8143997192382812
Batch 16/64 loss: -1.3359642028808594
Batch 17/64 loss: -0.5778379440307617
Batch 18/64 loss: -2.025768280029297
Batch 19/64 loss: -2.6280832290649414
Batch 20/64 loss: -1.9081144332885742
Batch 21/64 loss: -1.4204330444335938
Batch 22/64 loss: -1.9799222946166992
Batch 23/64 loss: -2.169436454772949
Batch 24/64 loss: -2.1774282455444336
Batch 25/64 loss: -2.0276288986206055
Batch 26/64 loss: -1.747391700744629
Batch 27/64 loss: -2.2093420028686523
Batch 28/64 loss: -2.203488349914551
Batch 29/64 loss: -1.4584007263183594
Batch 30/64 loss: -1.9226417541503906
Batch 31/64 loss: -1.5566987991333008
Batch 32/64 loss: -1.8592748641967773
Batch 33/64 loss: -2.3799476623535156
Batch 34/64 loss: -1.7442655563354492
Batch 35/64 loss: -1.8635425567626953
Batch 36/64 loss: -1.9284629821777344
Batch 37/64 loss: -1.8903570175170898
Batch 38/64 loss: -1.8581361770629883
Batch 39/64 loss: -1.9278440475463867
Batch 40/64 loss: -1.3885583877563477
Batch 41/64 loss: -1.677114486694336
Batch 42/64 loss: -2.3492469787597656
Batch 43/64 loss: -1.5754384994506836
Batch 44/64 loss: -2.1913366317749023
Batch 45/64 loss: -2.1236495971679688
Batch 46/64 loss: -2.361196517944336
Batch 47/64 loss: -1.099924087524414
Batch 48/64 loss: -1.9959392547607422
Batch 49/64 loss: -1.8698158264160156
Batch 50/64 loss: -2.1447505950927734
Batch 51/64 loss: -1.443044662475586
Batch 52/64 loss: -1.914205551147461
Batch 53/64 loss: -1.7539892196655273
Batch 54/64 loss: -1.6143951416015625
Batch 55/64 loss: -1.9517107009887695
Batch 56/64 loss: -0.8057327270507812
Batch 57/64 loss: -2.2551841735839844
Batch 58/64 loss: -1.7458791732788086
Batch 59/64 loss: -2.126678466796875
Batch 60/64 loss: -1.2126188278198242
Batch 61/64 loss: -2.2847652435302734
Batch 62/64 loss: -1.6619091033935547
Batch 63/64 loss: -2.4682235717773438
Batch 64/64 loss: -7.153895378112793
Epoch 37  Train loss: -1.9737533457138958  Val loss: -1.4824548177293075
Epoch 38
-------------------------------
Batch 1/64 loss: -1.9715242385864258
Batch 2/64 loss: -2.250483512878418
Batch 3/64 loss: -1.6937932968139648
Batch 4/64 loss: -0.43877601623535156
Batch 5/64 loss: -2.252011299133301
Batch 6/64 loss: -1.7171440124511719
Batch 7/64 loss: -2.01605224609375
Batch 8/64 loss: -1.5871086120605469
Batch 9/64 loss: -2.043698310852051
Batch 10/64 loss: -1.369558334350586
Batch 11/64 loss: -2.0158987045288086
Batch 12/64 loss: -1.8603515625
Batch 13/64 loss: -1.3865280151367188
Batch 14/64 loss: -1.617753028869629
Batch 15/64 loss: -1.7097530364990234
Batch 16/64 loss: -2.112346649169922
Batch 17/64 loss: -1.0445623397827148
Batch 18/64 loss: -1.6333808898925781
Batch 19/64 loss: -1.4655570983886719
Batch 20/64 loss: -1.19384765625
Batch 21/64 loss: -2.1584272384643555
Batch 22/64 loss: -2.0097484588623047
Batch 23/64 loss: -2.0619068145751953
Batch 24/64 loss: -2.366861343383789
Batch 25/64 loss: -2.1507091522216797
Batch 26/64 loss: -2.1661548614501953
Batch 27/64 loss: -2.0427980422973633
Batch 28/64 loss: -2.000136375427246
Batch 29/64 loss: -1.6729097366333008
Batch 30/64 loss: -1.8748836517333984
Batch 31/64 loss: -2.3022470474243164
Batch 32/64 loss: -1.092757225036621
Batch 33/64 loss: -1.1489086151123047
Batch 34/64 loss: -0.9608860015869141
Batch 35/64 loss: -2.281993865966797
Batch 36/64 loss: -1.6635408401489258
Batch 37/64 loss: -2.0983009338378906
Batch 38/64 loss: -1.800562858581543
Batch 39/64 loss: -1.5552845001220703
Batch 40/64 loss: -2.1939306259155273
Batch 41/64 loss: -1.8928356170654297
Batch 42/64 loss: -2.023052215576172
Batch 43/64 loss: -2.2174577713012695
Batch 44/64 loss: -1.3430852890014648
Batch 45/64 loss: -1.2738103866577148
Batch 46/64 loss: -2.1138429641723633
Batch 47/64 loss: -1.9991188049316406
Batch 48/64 loss: -2.258620262145996
Batch 49/64 loss: -1.8426637649536133
Batch 50/64 loss: -2.19049072265625
Batch 51/64 loss: -2.2125930786132812
Batch 52/64 loss: -2.188505172729492
Batch 53/64 loss: -1.492635726928711
Batch 54/64 loss: -1.873885154724121
Batch 55/64 loss: -2.1092958450317383
Batch 56/64 loss: -1.8480720520019531
Batch 57/64 loss: -2.0038976669311523
Batch 58/64 loss: -1.5695915222167969
Batch 59/64 loss: -2.154193878173828
Batch 60/64 loss: -2.102921485900879
Batch 61/64 loss: -2.1734466552734375
Batch 62/64 loss: -2.1693620681762695
Batch 63/64 loss: -2.402634620666504
Batch 64/64 loss: -6.807307243347168
Epoch 38  Train loss: -1.9065814934524836  Val loss: -2.0420942535924747
Epoch 39
-------------------------------
Batch 1/64 loss: -2.035672187805176
Batch 2/64 loss: -1.9326353073120117
Batch 3/64 loss: -2.30203914642334
Batch 4/64 loss: -2.381193161010742
Batch 5/64 loss: -2.049509048461914
Batch 6/64 loss: -1.8252086639404297
Batch 7/64 loss: -2.0753517150878906
Batch 8/64 loss: -1.7493534088134766
Batch 9/64 loss: -1.8009881973266602
Batch 10/64 loss: -2.432461738586426
Batch 11/64 loss: -1.6945619583129883
Batch 12/64 loss: -2.207320213317871
Batch 13/64 loss: -1.529007911682129
Batch 14/64 loss: -1.858642578125
Batch 15/64 loss: -1.9359092712402344
Batch 16/64 loss: -2.4015722274780273
Batch 17/64 loss: -1.631831169128418
Batch 18/64 loss: -1.8767509460449219
Batch 19/64 loss: -2.0185890197753906
Batch 20/64 loss: -1.5795745849609375
Batch 21/64 loss: -1.976170539855957
Batch 22/64 loss: -2.1118011474609375
Batch 23/64 loss: -1.1760578155517578
Batch 24/64 loss: -1.436751365661621
Batch 25/64 loss: -1.8052606582641602
Batch 26/64 loss: -2.480680465698242
Batch 27/64 loss: -1.9580450057983398
Batch 28/64 loss: -2.101858139038086
Batch 29/64 loss: -1.5295448303222656
Batch 30/64 loss: -1.4018754959106445
Batch 31/64 loss: -1.883737564086914
Batch 32/64 loss: -2.2400007247924805
Batch 33/64 loss: -1.6639442443847656
Batch 34/64 loss: -1.9861030578613281
Batch 35/64 loss: -2.172600746154785
Batch 36/64 loss: -0.10052871704101562
Batch 37/64 loss: -1.4680261611938477
Batch 38/64 loss: -1.8247137069702148
Batch 39/64 loss: -2.370267868041992
Batch 40/64 loss: -2.1771841049194336
Batch 41/64 loss: -2.1778554916381836
Batch 42/64 loss: -2.062941551208496
Batch 43/64 loss: -1.9703254699707031
Batch 44/64 loss: -2.313220977783203
Batch 45/64 loss: -1.2972803115844727
Batch 46/64 loss: -1.4242725372314453
Batch 47/64 loss: -1.9534053802490234
Batch 48/64 loss: -1.1956872940063477
Batch 49/64 loss: -0.6948833465576172
Batch 50/64 loss: -2.3211545944213867
Batch 51/64 loss: -1.985025405883789
Batch 52/64 loss: -2.4684057235717773
Batch 53/64 loss: -1.9692001342773438
Batch 54/64 loss: -1.7776975631713867
Batch 55/64 loss: -2.253830909729004
Batch 56/64 loss: -1.7619543075561523
Batch 57/64 loss: -1.4197502136230469
Batch 58/64 loss: -2.415194511413574
Batch 59/64 loss: -2.295607566833496
Batch 60/64 loss: -1.8364763259887695
Batch 61/64 loss: -1.5594654083251953
Batch 62/64 loss: -1.7539520263671875
Batch 63/64 loss: -1.3022642135620117
Batch 64/64 loss: -7.072967529296875
Epoch 39  Train loss: -1.9246729682473576  Val loss: -2.0537857501367522
Epoch 40
-------------------------------
Batch 1/64 loss: -1.7201652526855469
Batch 2/64 loss: -1.8240118026733398
Batch 3/64 loss: -2.2674036026000977
Batch 4/64 loss: -2.1676177978515625
Batch 5/64 loss: -2.1199464797973633
Batch 6/64 loss: -1.7049274444580078
Batch 7/64 loss: -2.1733522415161133
Batch 8/64 loss: -1.8236217498779297
Batch 9/64 loss: -1.8717718124389648
Batch 10/64 loss: -1.6438884735107422
Batch 11/64 loss: -1.9478416442871094
Batch 12/64 loss: -1.6980628967285156
Batch 13/64 loss: -2.380300521850586
Batch 14/64 loss: -2.082813262939453
Batch 15/64 loss: -2.021855354309082
Batch 16/64 loss: -1.5161628723144531
Batch 17/64 loss: -1.860443115234375
Batch 18/64 loss: -2.218104362487793
Batch 19/64 loss: -2.1062698364257812
Batch 20/64 loss: -1.8191337585449219
Batch 21/64 loss: -1.8273630142211914
Batch 22/64 loss: -1.4426050186157227
Batch 23/64 loss: -2.299074172973633
Batch 24/64 loss: -2.3340091705322266
Batch 25/64 loss: -1.8606128692626953
Batch 26/64 loss: -1.5359630584716797
Batch 27/64 loss: -1.673701286315918
Batch 28/64 loss: -2.2112417221069336
Batch 29/64 loss: -2.3196287155151367
Batch 30/64 loss: -2.1334962844848633
Batch 31/64 loss: -2.2338953018188477
Batch 32/64 loss: -1.7216157913208008
Batch 33/64 loss: -1.630253791809082
Batch 34/64 loss: -2.248225212097168
Batch 35/64 loss: -0.47861194610595703
Batch 36/64 loss: -2.212583541870117
Batch 37/64 loss: -2.0697784423828125
Batch 38/64 loss: -1.3461990356445312
Batch 39/64 loss: -2.220576286315918
Batch 40/64 loss: -1.5111494064331055
Batch 41/64 loss: -2.1947317123413086
Batch 42/64 loss: -1.7599067687988281
Batch 43/64 loss: -2.1812829971313477
Batch 44/64 loss: -2.474980354309082
Batch 45/64 loss: -1.953603744506836
Batch 46/64 loss: -1.9285202026367188
Batch 47/64 loss: -2.272634506225586
Batch 48/64 loss: -1.6340970993041992
Batch 49/64 loss: -2.077906608581543
Batch 50/64 loss: -1.8417959213256836
Batch 51/64 loss: -2.1623620986938477
Batch 52/64 loss: -1.4394197463989258
Batch 53/64 loss: -1.8902168273925781
Batch 54/64 loss: -1.9314966201782227
Batch 55/64 loss: -2.05324649810791
Batch 56/64 loss: -2.002436637878418
Batch 57/64 loss: -2.2758941650390625
Batch 58/64 loss: -2.007650375366211
Batch 59/64 loss: -2.2442712783813477
Batch 60/64 loss: -1.657668113708496
Batch 61/64 loss: -2.136519432067871
Batch 62/64 loss: -2.103940963745117
Batch 63/64 loss: -2.2217864990234375
Batch 64/64 loss: -6.126582145690918
Epoch 40  Train loss: -1.997169947156719  Val loss: -2.287378632325897
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: -2.164320945739746
Batch 2/64 loss: -2.302811622619629
Batch 3/64 loss: -2.11348819732666
Batch 4/64 loss: -2.4614953994750977
Batch 5/64 loss: -2.3066883087158203
Batch 6/64 loss: -2.120577812194824
Batch 7/64 loss: -1.8671159744262695
Batch 8/64 loss: -1.9285249710083008
Batch 9/64 loss: -1.8204259872436523
Batch 10/64 loss: -2.47078800201416
Batch 11/64 loss: -1.548818588256836
Batch 12/64 loss: -1.9079008102416992
Batch 13/64 loss: -1.8765602111816406
Batch 14/64 loss: -2.070164680480957
Batch 15/64 loss: -2.2777252197265625
Batch 16/64 loss: -2.2308244705200195
Batch 17/64 loss: -2.2290992736816406
Batch 18/64 loss: -2.1798763275146484
Batch 19/64 loss: -1.6757259368896484
Batch 20/64 loss: -1.1525421142578125
Batch 21/64 loss: -1.827286720275879
Batch 22/64 loss: -2.225128173828125
Batch 23/64 loss: -2.133591651916504
Batch 24/64 loss: -2.085137367248535
Batch 25/64 loss: -1.8120994567871094
Batch 26/64 loss: -2.0245361328125
Batch 27/64 loss: -0.30792236328125
Batch 28/64 loss: -1.8002204895019531
Batch 29/64 loss: -1.6554203033447266
Batch 30/64 loss: -1.970749855041504
Batch 31/64 loss: -2.399195671081543
Batch 32/64 loss: -0.5699863433837891
Batch 33/64 loss: -1.9797744750976562
Batch 34/64 loss: -2.095738410949707
Batch 35/64 loss: -1.9018096923828125
Batch 36/64 loss: -1.7665338516235352
Batch 37/64 loss: -2.113703727722168
Batch 38/64 loss: -1.9068822860717773
Batch 39/64 loss: -1.975205421447754
Batch 40/64 loss: -1.3730039596557617
Batch 41/64 loss: -1.710740089416504
Batch 42/64 loss: -1.5593738555908203
Batch 43/64 loss: -2.038423538208008
Batch 44/64 loss: -2.1271486282348633
Batch 45/64 loss: -2.173604965209961
Batch 46/64 loss: -2.0583314895629883
Batch 47/64 loss: -1.3970975875854492
Batch 48/64 loss: -2.2691192626953125
Batch 49/64 loss: -2.177138328552246
Batch 50/64 loss: -1.9550247192382812
Batch 51/64 loss: -1.7488460540771484
Batch 52/64 loss: -2.4357643127441406
Batch 53/64 loss: -2.0847291946411133
Batch 54/64 loss: -1.6649980545043945
Batch 55/64 loss: -2.0305004119873047
Batch 56/64 loss: -1.787200927734375
Batch 57/64 loss: -2.347487449645996
Batch 58/64 loss: -1.941152572631836
Batch 59/64 loss: -1.5628166198730469
Batch 60/64 loss: -1.9891624450683594
Batch 61/64 loss: -1.9716129302978516
Batch 62/64 loss: -2.2186498641967773
Batch 63/64 loss: -2.254192352294922
Batch 64/64 loss: -6.847653388977051
Epoch 41  Train loss: -1.9963648141599168  Val loss: -2.027545496360543
Epoch 42
-------------------------------
Batch 1/64 loss: -1.8691864013671875
Batch 2/64 loss: -2.001100540161133
Batch 3/64 loss: -1.4173879623413086
Batch 4/64 loss: -1.9664888381958008
Batch 5/64 loss: -2.018277168273926
Batch 6/64 loss: -1.1784696578979492
Batch 7/64 loss: -1.8896360397338867
Batch 8/64 loss: -0.053315162658691406
Batch 9/64 loss: -1.9392967224121094
Batch 10/64 loss: -2.163884162902832
Batch 11/64 loss: -2.1942081451416016
Batch 12/64 loss: -2.2083702087402344
Batch 13/64 loss: -1.7708816528320312
Batch 14/64 loss: -1.4447994232177734
Batch 15/64 loss: -2.040201187133789
Batch 16/64 loss: -1.824249267578125
Batch 17/64 loss: -1.3550758361816406
Batch 18/64 loss: -2.2149391174316406
Batch 19/64 loss: -1.9778432846069336
Batch 20/64 loss: -1.6551637649536133
Batch 21/64 loss: -1.6092195510864258
Batch 22/64 loss: -1.9912223815917969
Batch 23/64 loss: -2.223647117614746
Batch 24/64 loss: -2.27703857421875
Batch 25/64 loss: -2.125417709350586
Batch 26/64 loss: -1.6992969512939453
Batch 27/64 loss: -1.547175407409668
Batch 28/64 loss: -2.267721176147461
Batch 29/64 loss: -1.865464210510254
Batch 30/64 loss: -2.3298778533935547
Batch 31/64 loss: -1.7249078750610352
Batch 32/64 loss: -2.1411943435668945
Batch 33/64 loss: -2.535538673400879
Batch 34/64 loss: -1.950387954711914
Batch 35/64 loss: -2.4816112518310547
Batch 36/64 loss: -2.353644371032715
Batch 37/64 loss: -2.0390138626098633
Batch 38/64 loss: -2.197866439819336
Batch 39/64 loss: -1.6697721481323242
Batch 40/64 loss: -1.5044708251953125
Batch 41/64 loss: -1.8824586868286133
Batch 42/64 loss: -1.9021797180175781
Batch 43/64 loss: -1.579432487487793
Batch 44/64 loss: -2.149460792541504
Batch 45/64 loss: -1.7800302505493164
Batch 46/64 loss: -2.1480331420898438
Batch 47/64 loss: -2.316957473754883
Batch 48/64 loss: -1.5123977661132812
Batch 49/64 loss: -2.6267757415771484
Batch 50/64 loss: -2.1969690322875977
Batch 51/64 loss: -2.2453556060791016
Batch 52/64 loss: -2.153900146484375
Batch 53/64 loss: -1.9434795379638672
Batch 54/64 loss: -2.192811965942383
Batch 55/64 loss: -0.8345584869384766
Batch 56/64 loss: -2.233938217163086
Batch 57/64 loss: -2.017636299133301
Batch 58/64 loss: -1.8851289749145508
Batch 59/64 loss: -1.5239334106445312
Batch 60/64 loss: -1.7098064422607422
Batch 61/64 loss: -2.4561309814453125
Batch 62/64 loss: -2.1967763900756836
Batch 63/64 loss: -2.3639020919799805
Batch 64/64 loss: -6.737621307373047
Epoch 42  Train loss: -1.9862358093261718  Val loss: -2.218936251610825
Epoch 43
-------------------------------
Batch 1/64 loss: -2.4552555084228516
Batch 2/64 loss: -1.6667795181274414
Batch 3/64 loss: -1.1667757034301758
Batch 4/64 loss: -2.2999305725097656
Batch 5/64 loss: -0.335662841796875
Batch 6/64 loss: -2.317427635192871
Batch 7/64 loss: -1.9774847030639648
Batch 8/64 loss: -1.6057767868041992
Batch 9/64 loss: -2.1813011169433594
Batch 10/64 loss: -1.925497055053711
Batch 11/64 loss: -2.0227184295654297
Batch 12/64 loss: -2.305337905883789
Batch 13/64 loss: -2.268866539001465
Batch 14/64 loss: -1.779667854309082
Batch 15/64 loss: -1.287898063659668
Batch 16/64 loss: -2.2878284454345703
Batch 17/64 loss: -2.1863670349121094
Batch 18/64 loss: -1.5446281433105469
Batch 19/64 loss: -2.196873664855957
Batch 20/64 loss: -1.290243148803711
Batch 21/64 loss: -1.6847553253173828
Batch 22/64 loss: -1.5111961364746094
Batch 23/64 loss: -2.369413375854492
Batch 24/64 loss: -2.1747398376464844
Batch 25/64 loss: -2.0918655395507812
Batch 26/64 loss: -2.220587730407715
Batch 27/64 loss: -2.243762969970703
Batch 28/64 loss: -2.1054153442382812
Batch 29/64 loss: -2.2796239852905273
Batch 30/64 loss: -1.8999910354614258
Batch 31/64 loss: -2.1929445266723633
Batch 32/64 loss: -1.9841575622558594
Batch 33/64 loss: -2.559844970703125
Batch 34/64 loss: -1.2548208236694336
Batch 35/64 loss: -2.0378150939941406
Batch 36/64 loss: -2.1995840072631836
Batch 37/64 loss: -2.1214733123779297
Batch 38/64 loss: -1.746830940246582
Batch 39/64 loss: -0.7398338317871094
Batch 40/64 loss: -2.2869272232055664
Batch 41/64 loss: -1.8053417205810547
Batch 42/64 loss: -1.554215431213379
Batch 43/64 loss: -2.100611686706543
Batch 44/64 loss: -1.2084236145019531
Batch 45/64 loss: -2.613615036010742
Batch 46/64 loss: -2.0350513458251953
Batch 47/64 loss: -2.0573434829711914
Batch 48/64 loss: -2.110881805419922
Batch 49/64 loss: -2.114119529724121
Batch 50/64 loss: -0.7406463623046875
Batch 51/64 loss: -2.1405019760131836
Batch 52/64 loss: -1.9731616973876953
Batch 53/64 loss: -2.081822395324707
Batch 54/64 loss: -1.786844253540039
Batch 55/64 loss: -1.642298698425293
Batch 56/64 loss: -1.696298599243164
Batch 57/64 loss: -1.7518291473388672
Batch 58/64 loss: -2.308683395385742
Batch 59/64 loss: -2.0306520462036133
Batch 60/64 loss: -1.4848060607910156
Batch 61/64 loss: -0.8090372085571289
Batch 62/64 loss: -1.1092948913574219
Batch 63/64 loss: -1.9523563385009766
Batch 64/64 loss: -6.778454780578613
Epoch 43  Train loss: -1.9294052086624445  Val loss: -1.6396158880384517
Epoch 44
-------------------------------
Batch 1/64 loss: -0.6340799331665039
Batch 2/64 loss: -1.6782560348510742
Batch 3/64 loss: -1.1660346984863281
Batch 4/64 loss: -1.868931770324707
Batch 5/64 loss: -1.3847312927246094
Batch 6/64 loss: -2.360687255859375
Batch 7/64 loss: -1.7158098220825195
Batch 8/64 loss: -1.9039154052734375
Batch 9/64 loss: -1.8139057159423828
Batch 10/64 loss: -2.108407974243164
Batch 11/64 loss: -2.3872432708740234
Batch 12/64 loss: -2.131850242614746
Batch 13/64 loss: -1.531656265258789
Batch 14/64 loss: -1.3367042541503906
Batch 15/64 loss: -2.1171340942382812
Batch 16/64 loss: -1.4849357604980469
Batch 17/64 loss: -1.0902509689331055
Batch 18/64 loss: -1.6443815231323242
Batch 19/64 loss: -1.7074356079101562
Batch 20/64 loss: -2.1669082641601562
Batch 21/64 loss: -1.2814970016479492
Batch 22/64 loss: -2.2001962661743164
Batch 23/64 loss: -1.7491321563720703
Batch 24/64 loss: -2.4028234481811523
Batch 25/64 loss: -1.9863500595092773
Batch 26/64 loss: -2.1857242584228516
Batch 27/64 loss: -1.8272294998168945
Batch 28/64 loss: -2.127666473388672
Batch 29/64 loss: -2.139641761779785
Batch 30/64 loss: -2.2011985778808594
Batch 31/64 loss: -2.1519775390625
Batch 32/64 loss: -2.012110710144043
Batch 33/64 loss: -2.241880416870117
Batch 34/64 loss: -1.4760990142822266
Batch 35/64 loss: -1.9209346771240234
Batch 36/64 loss: -2.1596689224243164
Batch 37/64 loss: -2.4225940704345703
Batch 38/64 loss: -1.813582420349121
Batch 39/64 loss: -2.4654159545898438
Batch 40/64 loss: -2.3628759384155273
Batch 41/64 loss: -2.086395263671875
Batch 42/64 loss: -2.343303680419922
Batch 43/64 loss: -2.06630802154541
Batch 44/64 loss: -1.9415864944458008
Batch 45/64 loss: -1.8357133865356445
Batch 46/64 loss: -1.842665672302246
Batch 47/64 loss: -1.932795524597168
Batch 48/64 loss: -1.4486446380615234
Batch 49/64 loss: -1.9219369888305664
Batch 50/64 loss: -1.535196304321289
Batch 51/64 loss: -1.3706474304199219
Batch 52/64 loss: -1.8432636260986328
Batch 53/64 loss: -2.3677825927734375
Batch 54/64 loss: -2.1556453704833984
Batch 55/64 loss: -2.1005897521972656
Batch 56/64 loss: -2.246562957763672
Batch 57/64 loss: -2.1940813064575195
Batch 58/64 loss: -1.8184146881103516
Batch 59/64 loss: -1.9706668853759766
Batch 60/64 loss: -1.035487174987793
Batch 61/64 loss: -2.0281906127929688
Batch 62/64 loss: -2.005786895751953
Batch 63/64 loss: -1.7742376327514648
Batch 64/64 loss: -7.031607627868652
Epoch 44  Train loss: -1.9529642030304553  Val loss: -2.164450393099965
Epoch 45
-------------------------------
Batch 1/64 loss: -2.096920967102051
Batch 2/64 loss: -1.038365364074707
Batch 3/64 loss: -1.9740381240844727
Batch 4/64 loss: -2.240447998046875
Batch 5/64 loss: -2.188741683959961
Batch 6/64 loss: -1.5926551818847656
Batch 7/64 loss: -1.7722034454345703
Batch 8/64 loss: -2.291769027709961
Batch 9/64 loss: -2.3034305572509766
Batch 10/64 loss: -2.0426721572875977
Batch 11/64 loss: -2.189803123474121
Batch 12/64 loss: -2.0660572052001953
Batch 13/64 loss: -2.1544618606567383
Batch 14/64 loss: -1.583683967590332
Batch 15/64 loss: -1.7458677291870117
Batch 16/64 loss: -2.0416574478149414
Batch 17/64 loss: -1.7451553344726562
Batch 18/64 loss: -2.1537647247314453
Batch 19/64 loss: -2.134812355041504
Batch 20/64 loss: -2.170506477355957
Batch 21/64 loss: -1.9091453552246094
Batch 22/64 loss: -1.5924406051635742
Batch 23/64 loss: -1.5556068420410156
Batch 24/64 loss: -1.8024320602416992
Batch 25/64 loss: -2.191089630126953
Batch 26/64 loss: -2.425267219543457
Batch 27/64 loss: -2.2116174697875977
Batch 28/64 loss: -2.001373291015625
Batch 29/64 loss: -1.9378328323364258
Batch 30/64 loss: -2.1993942260742188
Batch 31/64 loss: -2.178402900695801
Batch 32/64 loss: -1.5057125091552734
Batch 33/64 loss: -1.8646068572998047
Batch 34/64 loss: -2.4270553588867188
Batch 35/64 loss: -2.197951316833496
Batch 36/64 loss: -2.2881202697753906
Batch 37/64 loss: -1.043670654296875
Batch 38/64 loss: -2.2287673950195312
Batch 39/64 loss: -2.2468433380126953
Batch 40/64 loss: -2.111612319946289
Batch 41/64 loss: -2.103274345397949
Batch 42/64 loss: -2.132814407348633
Batch 43/64 loss: -2.1902198791503906
Batch 44/64 loss: -1.9070043563842773
Batch 45/64 loss: -2.066183090209961
Batch 46/64 loss: -2.225338935852051
Batch 47/64 loss: -2.031291961669922
Batch 48/64 loss: -2.6497106552124023
Batch 49/64 loss: -1.5385608673095703
Batch 50/64 loss: -2.433159828186035
Batch 51/64 loss: -2.1230010986328125
Batch 52/64 loss: -2.4393396377563477
Batch 53/64 loss: -1.8232593536376953
Batch 54/64 loss: -2.075932502746582
Batch 55/64 loss: -1.367971420288086
Batch 56/64 loss: -1.9267759323120117
Batch 57/64 loss: -1.6682844161987305
Batch 58/64 loss: -2.522068977355957
Batch 59/64 loss: -1.0541162490844727
Batch 60/64 loss: -2.00485897064209
Batch 61/64 loss: -2.325510025024414
Batch 62/64 loss: -2.3124189376831055
Batch 63/64 loss: -0.6408481597900391
Batch 64/64 loss: -6.6880645751953125
Epoch 45  Train loss: -2.0395913666369867  Val loss: -2.3500039274340234
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: -2.616307258605957
Batch 2/64 loss: -2.6454477310180664
Batch 3/64 loss: -2.3324031829833984
Batch 4/64 loss: -2.103102684020996
Batch 5/64 loss: -1.9775943756103516
Batch 6/64 loss: -2.3301753997802734
Batch 7/64 loss: -2.273495674133301
Batch 8/64 loss: -2.2056751251220703
Batch 9/64 loss: -1.5916070938110352
Batch 10/64 loss: -1.450425148010254
Batch 11/64 loss: -2.376938819885254
Batch 12/64 loss: -1.951432228088379
Batch 13/64 loss: -2.248936653137207
Batch 14/64 loss: -1.5130157470703125
Batch 15/64 loss: -2.222569465637207
Batch 16/64 loss: -0.8057403564453125
Batch 17/64 loss: -1.3682737350463867
Batch 18/64 loss: -2.2670469284057617
Batch 19/64 loss: -1.7078580856323242
Batch 20/64 loss: -2.4899396896362305
Batch 21/64 loss: -1.8972110748291016
Batch 22/64 loss: -2.1690235137939453
Batch 23/64 loss: -1.9472332000732422
Batch 24/64 loss: -1.861039161682129
Batch 25/64 loss: -2.034052848815918
Batch 26/64 loss: -2.3432235717773438
Batch 27/64 loss: -1.7945032119750977
Batch 28/64 loss: -1.6564159393310547
Batch 29/64 loss: -1.490835189819336
Batch 30/64 loss: -2.131258964538574
Batch 31/64 loss: -2.423543930053711
Batch 32/64 loss: -2.124004364013672
Batch 33/64 loss: -2.249333381652832
Batch 34/64 loss: -2.49920654296875
Batch 35/64 loss: -2.1519689559936523
Batch 36/64 loss: -2.1505603790283203
Batch 37/64 loss: -2.3676395416259766
Batch 38/64 loss: -2.5166330337524414
Batch 39/64 loss: -2.2012767791748047
Batch 40/64 loss: -2.1341123580932617
Batch 41/64 loss: -1.9506473541259766
Batch 42/64 loss: -2.3537025451660156
Batch 43/64 loss: -1.8113555908203125
Batch 44/64 loss: -2.0098085403442383
Batch 45/64 loss: -1.5370674133300781
Batch 46/64 loss: -1.9221210479736328
Batch 47/64 loss: -1.6384086608886719
Batch 48/64 loss: -1.9916419982910156
Batch 49/64 loss: -2.4255571365356445
Batch 50/64 loss: -1.9637107849121094
Batch 51/64 loss: -2.1166610717773438
Batch 52/64 loss: -2.40478515625
Batch 53/64 loss: -2.2371883392333984
Batch 54/64 loss: -1.4914703369140625
Batch 55/64 loss: -2.0205554962158203
Batch 56/64 loss: -1.8231477737426758
Batch 57/64 loss: -2.1361732482910156
Batch 58/64 loss: -2.4170656204223633
Batch 59/64 loss: -2.0081443786621094
Batch 60/64 loss: -2.03818416595459
Batch 61/64 loss: -2.5211572647094727
Batch 62/64 loss: -1.5790586471557617
Batch 63/64 loss: -1.909531593322754
Batch 64/64 loss: -6.734853744506836
Epoch 46  Train loss: -2.101636796839097  Val loss: -2.285333469561285
Epoch 47
-------------------------------
Batch 1/64 loss: -1.9507637023925781
Batch 2/64 loss: -2.3766183853149414
Batch 3/64 loss: -1.9463319778442383
Batch 4/64 loss: -2.224699020385742
Batch 5/64 loss: -2.6363525390625
Batch 6/64 loss: -1.747075080871582
Batch 7/64 loss: -2.189676284790039
Batch 8/64 loss: -2.591383934020996
Batch 9/64 loss: -1.3350095748901367
Batch 10/64 loss: -1.4903459548950195
Batch 11/64 loss: -2.319812774658203
Batch 12/64 loss: -1.8128156661987305
Batch 13/64 loss: -2.2360477447509766
Batch 14/64 loss: -1.9648723602294922
Batch 15/64 loss: -1.6858444213867188
Batch 16/64 loss: -2.0160446166992188
Batch 17/64 loss: -1.8043403625488281
Batch 18/64 loss: -2.1828880310058594
Batch 19/64 loss: -2.2669363021850586
Batch 20/64 loss: -1.8912019729614258
Batch 21/64 loss: -2.116395950317383
Batch 22/64 loss: -2.236241340637207
Batch 23/64 loss: -2.397706985473633
Batch 24/64 loss: -1.574955940246582
Batch 25/64 loss: -2.038928985595703
Batch 26/64 loss: -2.1820831298828125
Batch 27/64 loss: -1.952880859375
Batch 28/64 loss: -2.126803398132324
Batch 29/64 loss: -2.071038246154785
Batch 30/64 loss: -1.7828779220581055
Batch 31/64 loss: -1.2733564376831055
Batch 32/64 loss: -2.3592662811279297
Batch 33/64 loss: -2.039849281311035
Batch 34/64 loss: -2.228534698486328
Batch 35/64 loss: -2.350621223449707
Batch 36/64 loss: -2.399794578552246
Batch 37/64 loss: -2.0345382690429688
Batch 38/64 loss: -1.9322834014892578
Batch 39/64 loss: -2.518003463745117
Batch 40/64 loss: -2.2440996170043945
Batch 41/64 loss: -2.052718162536621
Batch 42/64 loss: -2.036050796508789
Batch 43/64 loss: -2.179096221923828
Batch 44/64 loss: -2.286874771118164
Batch 45/64 loss: -2.5674448013305664
Batch 46/64 loss: -2.224407196044922
Batch 47/64 loss: -1.7132673263549805
Batch 48/64 loss: -2.339566230773926
Batch 49/64 loss: -2.554828643798828
Batch 50/64 loss: -2.143991470336914
Batch 51/64 loss: -1.6378068923950195
Batch 52/64 loss: -2.2541275024414062
Batch 53/64 loss: -2.053821563720703
Batch 54/64 loss: -2.2149057388305664
Batch 55/64 loss: -1.3087968826293945
Batch 56/64 loss: -2.3871679306030273
Batch 57/64 loss: -2.127598762512207
Batch 58/64 loss: -2.317143440246582
Batch 59/64 loss: -1.7906770706176758
Batch 60/64 loss: -1.8187427520751953
Batch 61/64 loss: -2.0321578979492188
Batch 62/64 loss: -2.063021659851074
Batch 63/64 loss: -2.1179733276367188
Batch 64/64 loss: -7.018983840942383
Epoch 47  Train loss: -2.133580323761585  Val loss: -2.1821930744393994
Epoch 48
-------------------------------
Batch 1/64 loss: -1.6295366287231445
Batch 2/64 loss: -2.1135997772216797
Batch 3/64 loss: -2.4328060150146484
Batch 4/64 loss: -2.7409181594848633
Batch 5/64 loss: -1.9686918258666992
Batch 6/64 loss: -2.3387136459350586
Batch 7/64 loss: -1.995309829711914
Batch 8/64 loss: -2.6222667694091797
Batch 9/64 loss: -2.046407699584961
Batch 10/64 loss: -0.5380363464355469
Batch 11/64 loss: -2.4218626022338867
Batch 12/64 loss: -2.2821226119995117
Batch 13/64 loss: -2.3381166458129883
Batch 14/64 loss: -2.8107166290283203
Batch 15/64 loss: -2.6214418411254883
Batch 16/64 loss: -2.4386587142944336
Batch 17/64 loss: -1.8998956680297852
Batch 18/64 loss: -2.0132522583007812
Batch 19/64 loss: -2.394179344177246
Batch 20/64 loss: -2.3703136444091797
Batch 21/64 loss: -2.3167190551757812
Batch 22/64 loss: -1.0535554885864258
Batch 23/64 loss: -2.3379058837890625
Batch 24/64 loss: -1.1544380187988281
Batch 25/64 loss: -2.3863086700439453
Batch 26/64 loss: -1.715193748474121
Batch 27/64 loss: -1.8655595779418945
Batch 28/64 loss: -2.2457799911499023
Batch 29/64 loss: -1.891251564025879
Batch 30/64 loss: -1.9949111938476562
Batch 31/64 loss: -2.200695037841797
Batch 32/64 loss: -2.1185922622680664
Batch 33/64 loss: -2.301982879638672
Batch 34/64 loss: -2.2377471923828125
Batch 35/64 loss: -1.6777534484863281
Batch 36/64 loss: -2.416412353515625
Batch 37/64 loss: -2.048924446105957
Batch 38/64 loss: -1.7960004806518555
Batch 39/64 loss: -2.1036338806152344
Batch 40/64 loss: -1.6915044784545898
Batch 41/64 loss: -2.2461767196655273
Batch 42/64 loss: -2.2223081588745117
Batch 43/64 loss: -2.401620864868164
Batch 44/64 loss: -2.2768068313598633
Batch 45/64 loss: -2.399097442626953
Batch 46/64 loss: -2.149402618408203
Batch 47/64 loss: -2.4468307495117188
Batch 48/64 loss: -2.4991235733032227
Batch 49/64 loss: -1.315053939819336
Batch 50/64 loss: -2.4328432083129883
Batch 51/64 loss: -2.143281936645508
Batch 52/64 loss: -1.1276130676269531
Batch 53/64 loss: -2.406370162963867
Batch 54/64 loss: -2.144113540649414
Batch 55/64 loss: -2.4998903274536133
Batch 56/64 loss: -2.2928285598754883
Batch 57/64 loss: -2.6268491744995117
Batch 58/64 loss: -1.8604297637939453
Batch 59/64 loss: -1.9133119583129883
Batch 60/64 loss: -1.8273382186889648
Batch 61/64 loss: -2.1718311309814453
Batch 62/64 loss: -2.0856475830078125
Batch 63/64 loss: -2.38535213470459
Batch 64/64 loss: -6.755764007568359
Epoch 48  Train loss: -2.17274762321921  Val loss: -2.144891352178305
Epoch 49
-------------------------------
Batch 1/64 loss: -2.497410774230957
Batch 2/64 loss: -2.2620134353637695
Batch 3/64 loss: -2.3131580352783203
Batch 4/64 loss: -1.2613639831542969
Batch 5/64 loss: -1.7998628616333008
Batch 6/64 loss: -2.2915449142456055
Batch 7/64 loss: -2.250729560852051
Batch 8/64 loss: -2.3498640060424805
Batch 9/64 loss: -2.2181148529052734
Batch 10/64 loss: -2.4057655334472656
Batch 11/64 loss: -2.1714582443237305
Batch 12/64 loss: -2.474273681640625
Batch 13/64 loss: -2.285763740539551
Batch 14/64 loss: -2.6284894943237305
Batch 15/64 loss: -2.4652843475341797
Batch 16/64 loss: -2.606678009033203
Batch 17/64 loss: -2.2632341384887695
Batch 18/64 loss: -1.5716114044189453
Batch 19/64 loss: -2.4703521728515625
Batch 20/64 loss: -2.266770362854004
Batch 21/64 loss: -2.4832143783569336
Batch 22/64 loss: -2.4170093536376953
Batch 23/64 loss: -2.1396541595458984
Batch 24/64 loss: -2.4449663162231445
Batch 25/64 loss: -1.7744417190551758
Batch 26/64 loss: -2.7080373764038086
Batch 27/64 loss: -1.962355613708496
Batch 28/64 loss: -1.8137054443359375
Batch 29/64 loss: -0.6423673629760742
Batch 30/64 loss: -2.1607961654663086
Batch 31/64 loss: -2.0105276107788086
Batch 32/64 loss: -2.3125600814819336
Batch 33/64 loss: -1.9929828643798828
Batch 34/64 loss: -2.505692481994629
Batch 35/64 loss: -1.90447998046875
Batch 36/64 loss: -2.4092702865600586
Batch 37/64 loss: -1.0595207214355469
Batch 38/64 loss: -1.5736703872680664
Batch 39/64 loss: -2.4032115936279297
Batch 40/64 loss: -2.1710004806518555
Batch 41/64 loss: -2.3438072204589844
Batch 42/64 loss: -2.411897659301758
Batch 43/64 loss: -0.8870668411254883
Batch 44/64 loss: -1.0311574935913086
Batch 45/64 loss: -2.2129297256469727
Batch 46/64 loss: -1.5502452850341797
Batch 47/64 loss: -1.7796087265014648
Batch 48/64 loss: -2.1444549560546875
Batch 49/64 loss: -2.1764726638793945
Batch 50/64 loss: -2.0504302978515625
Batch 51/64 loss: -2.314883232116699
Batch 52/64 loss: -2.05145263671875
Batch 53/64 loss: -2.1298751831054688
Batch 54/64 loss: -1.6326189041137695
Batch 55/64 loss: -0.7104969024658203
Batch 56/64 loss: -2.464756965637207
Batch 57/64 loss: -0.7534456253051758
Batch 58/64 loss: -1.7097253799438477
Batch 59/64 loss: -1.9761066436767578
Batch 60/64 loss: -1.807826042175293
Batch 61/64 loss: -1.8380937576293945
Batch 62/64 loss: -1.8202362060546875
Batch 63/64 loss: -1.7475166320800781
Batch 64/64 loss: -6.897130012512207
Epoch 49  Train loss: -2.0778221242568073  Val loss: -1.8633936065988443
Epoch 50
-------------------------------
Batch 1/64 loss: -1.9553356170654297
Batch 2/64 loss: -1.2814435958862305
Batch 3/64 loss: -2.059267997741699
Batch 4/64 loss: -2.3220396041870117
Batch 5/64 loss: -2.1766061782836914
Batch 6/64 loss: -2.317638397216797
Batch 7/64 loss: -2.3592796325683594
Batch 8/64 loss: -2.068065643310547
Batch 9/64 loss: -0.9152259826660156
Batch 10/64 loss: -1.8021259307861328
Batch 11/64 loss: -2.063180923461914
Batch 12/64 loss: 0.3280458450317383
Batch 13/64 loss: -2.0477752685546875
Batch 14/64 loss: -2.04022216796875
Batch 15/64 loss: -2.144381523132324
Batch 16/64 loss: -1.9642953872680664
Batch 17/64 loss: -2.083308219909668
Batch 18/64 loss: -1.9825544357299805
Batch 19/64 loss: -2.1655235290527344
Batch 20/64 loss: -2.021219253540039
Batch 21/64 loss: -2.01309871673584
Batch 22/64 loss: -2.016129493713379
Batch 23/64 loss: -1.6808347702026367
Batch 24/64 loss: -1.8839035034179688
Batch 25/64 loss: -1.8645963668823242
Batch 26/64 loss: -1.6200237274169922
Batch 27/64 loss: -1.8525934219360352
Batch 28/64 loss: -2.3470849990844727
Batch 29/64 loss: -1.9648065567016602
Batch 30/64 loss: -1.8478784561157227
Batch 31/64 loss: -2.1697568893432617
Batch 32/64 loss: -2.407223701477051
Batch 33/64 loss: -2.16387939453125
Batch 34/64 loss: -2.465346336364746
Batch 35/64 loss: -2.1973209381103516
Batch 36/64 loss: -2.4682464599609375
Batch 37/64 loss: -1.394308090209961
Batch 38/64 loss: -2.601907730102539
Batch 39/64 loss: -2.318058967590332
Batch 40/64 loss: -1.6297330856323242
Batch 41/64 loss: -1.799454689025879
Batch 42/64 loss: -2.295535087585449
Batch 43/64 loss: -2.446629524230957
Batch 44/64 loss: -2.41617488861084
Batch 45/64 loss: -2.141007423400879
Batch 46/64 loss: -2.316944122314453
Batch 47/64 loss: -2.079207420349121
Batch 48/64 loss: -1.3964776992797852
Batch 49/64 loss: -1.5476016998291016
Batch 50/64 loss: -2.350621223449707
Batch 51/64 loss: -1.6190719604492188
Batch 52/64 loss: -2.503891944885254
Batch 53/64 loss: -1.6872930526733398
Batch 54/64 loss: -1.749053955078125
Batch 55/64 loss: -2.1339035034179688
Batch 56/64 loss: -2.5903425216674805
Batch 57/64 loss: -1.5554962158203125
Batch 58/64 loss: -2.5455713272094727
Batch 59/64 loss: -2.3471670150756836
Batch 60/64 loss: -2.309403419494629
Batch 61/64 loss: -1.6749582290649414
Batch 62/64 loss: -1.907090187072754
Batch 63/64 loss: -2.3048887252807617
Batch 64/64 loss: -6.871820449829102
Epoch 50  Train loss: -2.0583502152386832  Val loss: -2.38466122551882
Saving best model, epoch: 50
Epoch 51
-------------------------------
Batch 1/64 loss: -2.42130184173584
Batch 2/64 loss: -2.2109193801879883
Batch 3/64 loss: -2.062811851501465
Batch 4/64 loss: -2.4215822219848633
Batch 5/64 loss: -2.408432960510254
Batch 6/64 loss: -2.349363327026367
Batch 7/64 loss: -1.3889245986938477
Batch 8/64 loss: -2.189382553100586
Batch 9/64 loss: -2.142702102661133
Batch 10/64 loss: -2.4820261001586914
Batch 11/64 loss: -1.8232240676879883
Batch 12/64 loss: -2.319000244140625
Batch 13/64 loss: -2.275822639465332
Batch 14/64 loss: -2.613494873046875
Batch 15/64 loss: -1.5116491317749023
Batch 16/64 loss: -2.1059093475341797
Batch 17/64 loss: -2.6041765213012695
Batch 18/64 loss: -2.1015424728393555
Batch 19/64 loss: -1.2359447479248047
Batch 20/64 loss: -2.5170936584472656
Batch 21/64 loss: -1.7956914901733398
Batch 22/64 loss: -1.9086418151855469
Batch 23/64 loss: -2.4447383880615234
Batch 24/64 loss: -1.0029268264770508
Batch 25/64 loss: -2.2839536666870117
Batch 26/64 loss: -2.288569450378418
Batch 27/64 loss: -1.9471197128295898
Batch 28/64 loss: -2.429326057434082
Batch 29/64 loss: -2.0576162338256836
Batch 30/64 loss: -2.1158313751220703
Batch 31/64 loss: -2.0528831481933594
Batch 32/64 loss: -0.9827671051025391
Batch 33/64 loss: -2.040210723876953
Batch 34/64 loss: -1.0024499893188477
Batch 35/64 loss: -2.2002525329589844
Batch 36/64 loss: -1.7478303909301758
Batch 37/64 loss: -1.9565744400024414
Batch 38/64 loss: -1.8692598342895508
Batch 39/64 loss: -1.402181625366211
Batch 40/64 loss: -2.1959667205810547
Batch 41/64 loss: -2.5682573318481445
Batch 42/64 loss: -2.3426437377929688
Batch 43/64 loss: -2.390949249267578
Batch 44/64 loss: -1.9557037353515625
Batch 45/64 loss: -2.0424623489379883
Batch 46/64 loss: -2.34641170501709
Batch 47/64 loss: -2.1918325424194336
Batch 48/64 loss: -2.236072540283203
Batch 49/64 loss: -2.482020378112793
Batch 50/64 loss: -1.7853107452392578
Batch 51/64 loss: -2.405088424682617
Batch 52/64 loss: -2.400911331176758
Batch 53/64 loss: -2.2459678649902344
Batch 54/64 loss: -2.2221317291259766
Batch 55/64 loss: -2.366098403930664
Batch 56/64 loss: -1.3170967102050781
Batch 57/64 loss: -2.2039661407470703
Batch 58/64 loss: -1.8108110427856445
Batch 59/64 loss: -2.450066566467285
Batch 60/64 loss: -2.130599021911621
Batch 61/64 loss: -2.3951826095581055
Batch 62/64 loss: -2.5568294525146484
Batch 63/64 loss: -2.5653696060180664
Batch 64/64 loss: -7.377097129821777
Epoch 51  Train loss: -2.162426701714011  Val loss: -2.403073222366805
Saving best model, epoch: 51
Epoch 52
-------------------------------
Batch 1/64 loss: -2.3195695877075195
Batch 2/64 loss: -2.0956335067749023
Batch 3/64 loss: -1.9485607147216797
Batch 4/64 loss: -2.309248924255371
Batch 5/64 loss: -1.6809158325195312
Batch 6/64 loss: -2.390652656555176
Batch 7/64 loss: -2.318807601928711
Batch 8/64 loss: -2.214231491088867
Batch 9/64 loss: -1.82891845703125
Batch 10/64 loss: -1.6120471954345703
Batch 11/64 loss: -1.6356515884399414
Batch 12/64 loss: -2.446195602416992
Batch 13/64 loss: -2.4222469329833984
Batch 14/64 loss: -2.2807846069335938
Batch 15/64 loss: -2.3043556213378906
Batch 16/64 loss: -1.0388736724853516
Batch 17/64 loss: -1.6211261749267578
Batch 18/64 loss: -2.283143997192383
Batch 19/64 loss: -2.5685958862304688
Batch 20/64 loss: -2.281723976135254
Batch 21/64 loss: -2.463136672973633
Batch 22/64 loss: -2.6640796661376953
Batch 23/64 loss: -2.4054555892944336
Batch 24/64 loss: -2.432863235473633
Batch 25/64 loss: -1.7545318603515625
Batch 26/64 loss: -1.988785743713379
Batch 27/64 loss: -2.3191776275634766
Batch 28/64 loss: -2.272796630859375
Batch 29/64 loss: -2.5107812881469727
Batch 30/64 loss: -2.4740514755249023
Batch 31/64 loss: -2.1455554962158203
Batch 32/64 loss: -2.3866357803344727
Batch 33/64 loss: -2.225210189819336
Batch 34/64 loss: -2.2104969024658203
Batch 35/64 loss: -2.563775062561035
Batch 36/64 loss: -2.118014335632324
Batch 37/64 loss: -1.8437824249267578
Batch 38/64 loss: -1.119502067565918
Batch 39/64 loss: -2.2523937225341797
Batch 40/64 loss: -2.211536407470703
Batch 41/64 loss: -2.453916549682617
Batch 42/64 loss: -2.061333656311035
Batch 43/64 loss: -2.1350831985473633
Batch 44/64 loss: -2.459406852722168
Batch 45/64 loss: -2.4005861282348633
Batch 46/64 loss: -1.9049005508422852
Batch 47/64 loss: -2.3503732681274414
Batch 48/64 loss: -1.8577203750610352
Batch 49/64 loss: -1.9506940841674805
Batch 50/64 loss: -2.511563301086426
Batch 51/64 loss: -1.9023237228393555
Batch 52/64 loss: -1.9988431930541992
Batch 53/64 loss: -2.3863630294799805
Batch 54/64 loss: -1.6959657669067383
Batch 55/64 loss: -2.369013786315918
Batch 56/64 loss: -2.6231937408447266
Batch 57/64 loss: -2.0046424865722656
Batch 58/64 loss: -2.11031436920166
Batch 59/64 loss: -2.018949508666992
Batch 60/64 loss: -2.5262832641601562
Batch 61/64 loss: -2.5481815338134766
Batch 62/64 loss: -2.5460433959960938
Batch 63/64 loss: -2.3125219345092773
Batch 64/64 loss: -7.194581985473633
Epoch 52  Train loss: -2.235105888516295  Val loss: -2.3091158653862287
Epoch 53
-------------------------------
Batch 1/64 loss: -1.5036077499389648
Batch 2/64 loss: -2.096531867980957
Batch 3/64 loss: -2.188526153564453
Batch 4/64 loss: -2.2015695571899414
Batch 5/64 loss: -2.3149518966674805
Batch 6/64 loss: -2.007063865661621
Batch 7/64 loss: -2.310399055480957
Batch 8/64 loss: -2.2392215728759766
Batch 9/64 loss: -2.3898019790649414
Batch 10/64 loss: -2.4492368698120117
Batch 11/64 loss: -2.3651485443115234
Batch 12/64 loss: -2.463374137878418
Batch 13/64 loss: -2.4554080963134766
Batch 14/64 loss: -2.2608642578125
Batch 15/64 loss: -2.508572578430176
Batch 16/64 loss: -2.0711660385131836
Batch 17/64 loss: -2.566897392272949
Batch 18/64 loss: -2.1379165649414062
Batch 19/64 loss: -2.6771841049194336
Batch 20/64 loss: -2.320895195007324
Batch 21/64 loss: -2.3263120651245117
Batch 22/64 loss: -2.3269290924072266
Batch 23/64 loss: -2.081308364868164
Batch 24/64 loss: -2.515806198120117
Batch 25/64 loss: -2.477921485900879
Batch 26/64 loss: -1.872309684753418
Batch 27/64 loss: -2.297300338745117
Batch 28/64 loss: -2.3451900482177734
Batch 29/64 loss: -2.2988719940185547
Batch 30/64 loss: -2.463913917541504
Batch 31/64 loss: -2.666973114013672
Batch 32/64 loss: -1.69024658203125
Batch 33/64 loss: -2.363999366760254
Batch 34/64 loss: -1.4113855361938477
Batch 35/64 loss: -2.533344268798828
Batch 36/64 loss: -1.7557382583618164
Batch 37/64 loss: -1.9144210815429688
Batch 38/64 loss: -2.286540985107422
Batch 39/64 loss: -2.4327163696289062
Batch 40/64 loss: -2.1803464889526367
Batch 41/64 loss: -2.033100128173828
Batch 42/64 loss: -2.3132400512695312
Batch 43/64 loss: -1.5710744857788086
Batch 44/64 loss: -2.166942596435547
Batch 45/64 loss: -2.19522762298584
Batch 46/64 loss: -2.1146793365478516
Batch 47/64 loss: -2.4332494735717773
Batch 48/64 loss: -1.9147558212280273
Batch 49/64 loss: -2.6149282455444336
Batch 50/64 loss: -2.370288848876953
Batch 51/64 loss: -2.1569290161132812
Batch 52/64 loss: -2.327345848083496
Batch 53/64 loss: -1.5700817108154297
Batch 54/64 loss: -2.072232246398926
Batch 55/64 loss: -2.198099136352539
Batch 56/64 loss: -2.6446962356567383
Batch 57/64 loss: -2.6134986877441406
Batch 58/64 loss: -2.6769800186157227
Batch 59/64 loss: -2.005138397216797
Batch 60/64 loss: -2.498342514038086
Batch 61/64 loss: -1.6718225479125977
Batch 62/64 loss: -2.2000112533569336
Batch 63/64 loss: -2.516550064086914
Batch 64/64 loss: -7.256697177886963
Epoch 53  Train loss: -2.2916337237638587  Val loss: -2.5356166354569374
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: -2.337958335876465
Batch 2/64 loss: -2.240229606628418
Batch 3/64 loss: -1.6248321533203125
Batch 4/64 loss: -2.4625120162963867
Batch 5/64 loss: -2.392575263977051
Batch 6/64 loss: -2.452098846435547
Batch 7/64 loss: -2.344522476196289
Batch 8/64 loss: -1.8468313217163086
Batch 9/64 loss: -2.192262649536133
Batch 10/64 loss: -2.411346435546875
Batch 11/64 loss: -1.9675683975219727
Batch 12/64 loss: -2.1269149780273438
Batch 13/64 loss: -2.23514461517334
Batch 14/64 loss: -2.4992637634277344
Batch 15/64 loss: -2.2672061920166016
Batch 16/64 loss: -2.2090206146240234
Batch 17/64 loss: -2.391345977783203
Batch 18/64 loss: -2.373602867126465
Batch 19/64 loss: -2.020862579345703
Batch 20/64 loss: -2.4734230041503906
Batch 21/64 loss: -1.9808435440063477
Batch 22/64 loss: -2.307255744934082
Batch 23/64 loss: -2.350457191467285
Batch 24/64 loss: -2.4661121368408203
Batch 25/64 loss: -2.222243309020996
Batch 26/64 loss: -2.40008544921875
Batch 27/64 loss: -2.229914665222168
Batch 28/64 loss: -2.3106155395507812
Batch 29/64 loss: -2.390665054321289
Batch 30/64 loss: -2.5514793395996094
Batch 31/64 loss: -1.2558279037475586
Batch 32/64 loss: -2.6218795776367188
Batch 33/64 loss: -2.350466728210449
Batch 34/64 loss: -2.5381851196289062
Batch 35/64 loss: -2.3676109313964844
Batch 36/64 loss: -2.56149959564209
Batch 37/64 loss: -2.5216989517211914
Batch 38/64 loss: -2.199347496032715
Batch 39/64 loss: -2.5373668670654297
Batch 40/64 loss: -2.458279609680176
Batch 41/64 loss: -2.506053924560547
Batch 42/64 loss: -2.1094093322753906
Batch 43/64 loss: -2.40078067779541
Batch 44/64 loss: -2.3525123596191406
Batch 45/64 loss: -2.1644363403320312
Batch 46/64 loss: -1.6888389587402344
Batch 47/64 loss: -2.2735471725463867
Batch 48/64 loss: -2.718817710876465
Batch 49/64 loss: -1.8077688217163086
Batch 50/64 loss: -2.446700096130371
Batch 51/64 loss: -2.2269678115844727
Batch 52/64 loss: -2.179159164428711
Batch 53/64 loss: -2.0160303115844727
Batch 54/64 loss: -2.2262468338012695
Batch 55/64 loss: -2.174833297729492
Batch 56/64 loss: -2.122696876525879
Batch 57/64 loss: -2.050752639770508
Batch 58/64 loss: -2.2003278732299805
Batch 59/64 loss: -2.2885446548461914
Batch 60/64 loss: -2.1316490173339844
Batch 61/64 loss: -2.6834917068481445
Batch 62/64 loss: -2.14241886138916
Batch 63/64 loss: -1.9584674835205078
Batch 64/64 loss: -7.087076187133789
Epoch 54  Train loss: -2.3165037790934244  Val loss: -2.5436040478473676
Saving best model, epoch: 54
Epoch 55
-------------------------------
Batch 1/64 loss: -2.3957996368408203
Batch 2/64 loss: -2.2809019088745117
Batch 3/64 loss: -2.0124025344848633
Batch 4/64 loss: -2.1658973693847656
Batch 5/64 loss: -2.151242256164551
Batch 6/64 loss: -2.7711572647094727
Batch 7/64 loss: -2.1721878051757812
Batch 8/64 loss: -1.9044246673583984
Batch 9/64 loss: -2.025339126586914
Batch 10/64 loss: -2.4393815994262695
Batch 11/64 loss: -2.255202293395996
Batch 12/64 loss: -2.475029945373535
Batch 13/64 loss: -2.3053054809570312
Batch 14/64 loss: -2.415337562561035
Batch 15/64 loss: -2.2934160232543945
Batch 16/64 loss: -2.466501235961914
Batch 17/64 loss: -2.2302989959716797
Batch 18/64 loss: -2.426748275756836
Batch 19/64 loss: -2.672147750854492
Batch 20/64 loss: -2.1858272552490234
Batch 21/64 loss: -2.313610076904297
Batch 22/64 loss: -1.88616943359375
Batch 23/64 loss: -1.8856096267700195
Batch 24/64 loss: -2.5554094314575195
Batch 25/64 loss: -2.2061843872070312
Batch 26/64 loss: -2.627573013305664
Batch 27/64 loss: -2.370244026184082
Batch 28/64 loss: -2.4692649841308594
Batch 29/64 loss: -2.235647201538086
Batch 30/64 loss: -2.154285430908203
Batch 31/64 loss: -2.05117130279541
Batch 32/64 loss: -2.6103506088256836
Batch 33/64 loss: -2.600982666015625
Batch 34/64 loss: -2.186677932739258
Batch 35/64 loss: -1.9926977157592773
Batch 36/64 loss: -2.3623743057250977
Batch 37/64 loss: -1.6611404418945312
Batch 38/64 loss: -2.2812423706054688
Batch 39/64 loss: -2.0867185592651367
Batch 40/64 loss: -2.5218820571899414
Batch 41/64 loss: -2.430570602416992
Batch 42/64 loss: -2.29141902923584
Batch 43/64 loss: -2.271071434020996
Batch 44/64 loss: -2.0482358932495117
Batch 45/64 loss: -1.471177101135254
Batch 46/64 loss: -2.544832229614258
Batch 47/64 loss: -2.1179018020629883
Batch 48/64 loss: -1.9706001281738281
Batch 49/64 loss: -2.618143081665039
Batch 50/64 loss: -1.6133298873901367
Batch 51/64 loss: -2.546123504638672
Batch 52/64 loss: -2.6582231521606445
Batch 53/64 loss: -2.2986135482788086
Batch 54/64 loss: -2.62581729888916
Batch 55/64 loss: -2.5442991256713867
Batch 56/64 loss: -2.6343841552734375
Batch 57/64 loss: -2.4675827026367188
Batch 58/64 loss: -2.347869873046875
Batch 59/64 loss: -1.5149221420288086
Batch 60/64 loss: -2.1977624893188477
Batch 61/64 loss: -2.2992897033691406
Batch 62/64 loss: -2.4771041870117188
Batch 63/64 loss: -2.3151321411132812
Batch 64/64 loss: -7.170666217803955
Epoch 55  Train loss: -2.3339010107750986  Val loss: -2.6079088322485435
Saving best model, epoch: 55
Epoch 56
-------------------------------
Batch 1/64 loss: -1.9316644668579102
Batch 2/64 loss: -2.2957210540771484
Batch 3/64 loss: -2.4312639236450195
Batch 4/64 loss: -2.52962589263916
Batch 5/64 loss: -2.5347347259521484
Batch 6/64 loss: -2.6495180130004883
Batch 7/64 loss: -1.9567203521728516
Batch 8/64 loss: -2.197061538696289
Batch 9/64 loss: -2.0218629837036133
Batch 10/64 loss: -1.0189361572265625
Batch 11/64 loss: -2.2592391967773438
Batch 12/64 loss: -2.7314090728759766
Batch 13/64 loss: -2.2414913177490234
Batch 14/64 loss: -2.174777030944824
Batch 15/64 loss: -2.161336898803711
Batch 16/64 loss: -1.9710569381713867
Batch 17/64 loss: -2.2410364151000977
Batch 18/64 loss: -1.9775800704956055
Batch 19/64 loss: -2.150629997253418
Batch 20/64 loss: -2.2453527450561523
Batch 21/64 loss: -2.3060665130615234
Batch 22/64 loss: -1.8079900741577148
Batch 23/64 loss: -2.2408790588378906
Batch 24/64 loss: -2.48111629486084
Batch 25/64 loss: -2.5117645263671875
Batch 26/64 loss: -2.16129207611084
Batch 27/64 loss: -2.250204086303711
Batch 28/64 loss: -2.344285011291504
Batch 29/64 loss: -2.4821701049804688
Batch 30/64 loss: -2.3694286346435547
Batch 31/64 loss: -2.27341365814209
Batch 32/64 loss: -2.4210195541381836
Batch 33/64 loss: -1.8840045928955078
Batch 34/64 loss: -2.0017929077148438
Batch 35/64 loss: -2.048478126525879
Batch 36/64 loss: -2.398810386657715
Batch 37/64 loss: -2.21868896484375
Batch 38/64 loss: -2.522001266479492
Batch 39/64 loss: -2.467752456665039
Batch 40/64 loss: -2.287899971008301
Batch 41/64 loss: -2.31777286529541
Batch 42/64 loss: -1.5398750305175781
Batch 43/64 loss: -1.9016408920288086
Batch 44/64 loss: -2.018843650817871
Batch 45/64 loss: -2.4478893280029297
Batch 46/64 loss: -2.5082569122314453
Batch 47/64 loss: -2.351581573486328
Batch 48/64 loss: -2.3308143615722656
Batch 49/64 loss: -2.351822853088379
Batch 50/64 loss: -2.0799951553344727
Batch 51/64 loss: -2.2121925354003906
Batch 52/64 loss: -1.9427690505981445
Batch 53/64 loss: -2.084819793701172
Batch 54/64 loss: -2.5932798385620117
Batch 55/64 loss: -1.7837896347045898
Batch 56/64 loss: -2.4548521041870117
Batch 57/64 loss: -2.592951774597168
Batch 58/64 loss: -2.339419364929199
Batch 59/64 loss: -0.8621120452880859
Batch 60/64 loss: -2.4854230880737305
Batch 61/64 loss: -2.332188606262207
Batch 62/64 loss: -1.688760757446289
Batch 63/64 loss: -2.524637222290039
Batch 64/64 loss: -7.268177032470703
Epoch 56  Train loss: -2.2650493846220128  Val loss: -2.4554337177079977
Epoch 57
-------------------------------
Batch 1/64 loss: -2.384028434753418
Batch 2/64 loss: -2.0975704193115234
Batch 3/64 loss: -2.598902702331543
Batch 4/64 loss: -1.9173707962036133
Batch 5/64 loss: -2.2395992279052734
Batch 6/64 loss: -2.5579633712768555
Batch 7/64 loss: -2.2110557556152344
Batch 8/64 loss: -2.6618194580078125
Batch 9/64 loss: -2.5934295654296875
Batch 10/64 loss: -2.5109901428222656
Batch 11/64 loss: -2.3496246337890625
Batch 12/64 loss: -1.9469223022460938
Batch 13/64 loss: -1.3689079284667969
Batch 14/64 loss: -2.6195669174194336
Batch 15/64 loss: -2.6617040634155273
Batch 16/64 loss: -2.0632848739624023
Batch 17/64 loss: -2.0235462188720703
Batch 18/64 loss: -2.4857234954833984
Batch 19/64 loss: -2.4268264770507812
Batch 20/64 loss: -1.9262504577636719
Batch 21/64 loss: -2.5120086669921875
Batch 22/64 loss: -2.2125158309936523
Batch 23/64 loss: -2.4973812103271484
Batch 24/64 loss: -2.4865942001342773
Batch 25/64 loss: -2.504195213317871
Batch 26/64 loss: -2.7408056259155273
Batch 27/64 loss: -2.220428466796875
Batch 28/64 loss: -2.1357641220092773
Batch 29/64 loss: -2.3451356887817383
Batch 30/64 loss: -2.2475767135620117
Batch 31/64 loss: -2.281461715698242
Batch 32/64 loss: -2.387387275695801
Batch 33/64 loss: -1.5766077041625977
Batch 34/64 loss: -1.7460145950317383
Batch 35/64 loss: -2.153988838195801
Batch 36/64 loss: -2.1053543090820312
Batch 37/64 loss: -2.2941675186157227
Batch 38/64 loss: -1.5054140090942383
Batch 39/64 loss: -2.360896110534668
Batch 40/64 loss: -2.4149017333984375
Batch 41/64 loss: -1.5093021392822266
Batch 42/64 loss: -2.25681209564209
Batch 43/64 loss: -2.450057029724121
Batch 44/64 loss: -2.0535354614257812
Batch 45/64 loss: -2.6666765213012695
Batch 46/64 loss: -2.1978492736816406
Batch 47/64 loss: -1.2334012985229492
Batch 48/64 loss: -2.182649612426758
Batch 49/64 loss: -2.486985206604004
Batch 50/64 loss: -1.4778709411621094
Batch 51/64 loss: -2.552379608154297
Batch 52/64 loss: -2.58383846282959
Batch 53/64 loss: -2.3466644287109375
Batch 54/64 loss: -2.46258544921875
Batch 55/64 loss: -2.07601261138916
Batch 56/64 loss: -1.8762903213500977
Batch 57/64 loss: -1.8624267578125
Batch 58/64 loss: -2.498758316040039
Batch 59/64 loss: -1.821061134338379
Batch 60/64 loss: -2.378157615661621
Batch 61/64 loss: -2.277651786804199
Batch 62/64 loss: -2.123509407043457
Batch 63/64 loss: -1.7017707824707031
Batch 64/64 loss: -7.314136505126953
Epoch 57  Train loss: -2.2734985949946385  Val loss: -2.3172919414297413
Epoch 58
-------------------------------
Batch 1/64 loss: -2.436190605163574
Batch 2/64 loss: -2.199093818664551
Batch 3/64 loss: -2.106133460998535
Batch 4/64 loss: -1.9357452392578125
Batch 5/64 loss: -2.3904857635498047
Batch 6/64 loss: -1.9259891510009766
Batch 7/64 loss: -2.0785045623779297
Batch 8/64 loss: -2.190585136413574
Batch 9/64 loss: -2.3790836334228516
Batch 10/64 loss: -2.5933923721313477
Batch 11/64 loss: -2.597442626953125
Batch 12/64 loss: -2.213925361633301
Batch 13/64 loss: -1.4912910461425781
Batch 14/64 loss: -1.8954381942749023
Batch 15/64 loss: -2.1448326110839844
Batch 16/64 loss: -1.8883037567138672
Batch 17/64 loss: -2.2616024017333984
Batch 18/64 loss: -2.5257701873779297
Batch 19/64 loss: -2.425596237182617
Batch 20/64 loss: -2.3899803161621094
Batch 21/64 loss: -2.159775733947754
Batch 22/64 loss: -2.4064579010009766
Batch 23/64 loss: -2.2069168090820312
Batch 24/64 loss: -2.196603775024414
Batch 25/64 loss: -1.8529386520385742
Batch 26/64 loss: -1.9018306732177734
Batch 27/64 loss: -2.1962766647338867
Batch 28/64 loss: -2.315579414367676
Batch 29/64 loss: -2.438783645629883
Batch 30/64 loss: -2.2165307998657227
Batch 31/64 loss: -1.7776708602905273
Batch 32/64 loss: -2.3392648696899414
Batch 33/64 loss: -2.196560859680176
Batch 34/64 loss: -2.3777542114257812
Batch 35/64 loss: -1.9301872253417969
Batch 36/64 loss: -1.7401762008666992
Batch 37/64 loss: -1.9694280624389648
Batch 38/64 loss: -1.956984519958496
Batch 39/64 loss: -2.29660701751709
Batch 40/64 loss: -2.164332389831543
Batch 41/64 loss: -2.5532302856445312
Batch 42/64 loss: -2.7062931060791016
Batch 43/64 loss: -2.563614845275879
Batch 44/64 loss: -1.377232551574707
Batch 45/64 loss: -2.1889095306396484
Batch 46/64 loss: -2.245553970336914
Batch 47/64 loss: -2.561929702758789
Batch 48/64 loss: -2.362682342529297
Batch 49/64 loss: -2.403590202331543
Batch 50/64 loss: -1.7026844024658203
Batch 51/64 loss: -2.537867546081543
Batch 52/64 loss: -2.469344139099121
Batch 53/64 loss: -2.318828582763672
Batch 54/64 loss: -1.9879426956176758
Batch 55/64 loss: -2.3107433319091797
Batch 56/64 loss: -1.946986198425293
Batch 57/64 loss: -2.3552541732788086
Batch 58/64 loss: -1.552785873413086
Batch 59/64 loss: -2.3920345306396484
Batch 60/64 loss: -2.1308155059814453
Batch 61/64 loss: -1.8711910247802734
Batch 62/64 loss: -2.5778207778930664
Batch 63/64 loss: -2.3154239654541016
Batch 64/64 loss: -6.953664779663086
Epoch 58  Train loss: -2.248753798241709  Val loss: -2.5050663112365092
Epoch 59
-------------------------------
Batch 1/64 loss: -2.082052230834961
Batch 2/64 loss: -2.227532386779785
Batch 3/64 loss: -2.0817604064941406
Batch 4/64 loss: -1.958181381225586
Batch 5/64 loss: -2.457943916320801
Batch 6/64 loss: -2.4525365829467773
Batch 7/64 loss: -2.46359920501709
Batch 8/64 loss: -2.4301071166992188
Batch 9/64 loss: -2.363223075866699
Batch 10/64 loss: -2.4120969772338867
Batch 11/64 loss: -2.0411529541015625
Batch 12/64 loss: -2.2397146224975586
Batch 13/64 loss: -2.4047651290893555
Batch 14/64 loss: -1.660318374633789
Batch 15/64 loss: -1.972477912902832
Batch 16/64 loss: -2.041240692138672
Batch 17/64 loss: -2.440744400024414
Batch 18/64 loss: -2.2038822174072266
Batch 19/64 loss: -1.9846115112304688
Batch 20/64 loss: -2.2515506744384766
Batch 21/64 loss: -2.4681472778320312
Batch 22/64 loss: -2.2285356521606445
Batch 23/64 loss: -2.440784454345703
Batch 24/64 loss: -2.1534194946289062
Batch 25/64 loss: -2.3650684356689453
Batch 26/64 loss: -2.4515037536621094
Batch 27/64 loss: -2.724837303161621
Batch 28/64 loss: -2.433713912963867
Batch 29/64 loss: -2.4532041549682617
Batch 30/64 loss: -2.262910842895508
Batch 31/64 loss: -2.2495241165161133
Batch 32/64 loss: -2.561741828918457
Batch 33/64 loss: -2.404081344604492
Batch 34/64 loss: -2.272491455078125
Batch 35/64 loss: -2.293675422668457
Batch 36/64 loss: -2.490732192993164
Batch 37/64 loss: -1.9293088912963867
Batch 38/64 loss: -2.3972110748291016
Batch 39/64 loss: -2.7259445190429688
Batch 40/64 loss: -2.293839454650879
Batch 41/64 loss: -2.546417236328125
Batch 42/64 loss: -2.3109006881713867
Batch 43/64 loss: -2.4129066467285156
Batch 44/64 loss: -2.134799003601074
Batch 45/64 loss: -2.285917282104492
Batch 46/64 loss: -2.171346664428711
Batch 47/64 loss: -1.908707618713379
Batch 48/64 loss: -1.919081687927246
Batch 49/64 loss: -2.563717842102051
Batch 50/64 loss: -2.16780948638916
Batch 51/64 loss: -2.478213310241699
Batch 52/64 loss: -2.3458404541015625
Batch 53/64 loss: -2.2245607376098633
Batch 54/64 loss: -2.464846611022949
Batch 55/64 loss: -2.6780033111572266
Batch 56/64 loss: -2.1247034072875977
Batch 57/64 loss: -2.3923168182373047
Batch 58/64 loss: -2.4611148834228516
Batch 59/64 loss: -2.4459829330444336
Batch 60/64 loss: -2.463913917541504
Batch 61/64 loss: -1.8016633987426758
Batch 62/64 loss: -1.8956279754638672
Batch 63/64 loss: -2.009629249572754
Batch 64/64 loss: -6.947046279907227
Epoch 59  Train loss: -2.3402113447002337  Val loss: -2.5905390867252938
Epoch 60
-------------------------------
Batch 1/64 loss: -2.2526750564575195
Batch 2/64 loss: -2.242293357849121
Batch 3/64 loss: -2.0787477493286133
Batch 4/64 loss: -1.717982292175293
Batch 5/64 loss: -2.9161996841430664
Batch 6/64 loss: -2.0503578186035156
Batch 7/64 loss: -2.480647087097168
Batch 8/64 loss: -2.616809844970703
Batch 9/64 loss: -2.5049543380737305
Batch 10/64 loss: -2.2977046966552734
Batch 11/64 loss: -2.6637630462646484
Batch 12/64 loss: -2.4468584060668945
Batch 13/64 loss: -2.221968650817871
Batch 14/64 loss: -2.185413360595703
Batch 15/64 loss: -2.5808773040771484
Batch 16/64 loss: -2.3058080673217773
Batch 17/64 loss: -2.607452392578125
Batch 18/64 loss: -2.548445701599121
Batch 19/64 loss: -2.2427549362182617
Batch 20/64 loss: -2.1988601684570312
Batch 21/64 loss: -2.138739585876465
Batch 22/64 loss: -1.8316679000854492
Batch 23/64 loss: -2.300227165222168
Batch 24/64 loss: -1.5494709014892578
Batch 25/64 loss: -2.2406139373779297
Batch 26/64 loss: -2.62216854095459
Batch 27/64 loss: -2.299327850341797
Batch 28/64 loss: -2.1538352966308594
Batch 29/64 loss: -1.6668500900268555
Batch 30/64 loss: -2.530196189880371
Batch 31/64 loss: -1.3069782257080078
Batch 32/64 loss: -2.563467025756836
Batch 33/64 loss: -2.270709991455078
Batch 34/64 loss: -2.3247880935668945
Batch 35/64 loss: -2.1331796646118164
Batch 36/64 loss: -2.056581497192383
Batch 37/64 loss: -2.694687843322754
Batch 38/64 loss: -2.511416435241699
Batch 39/64 loss: -2.3428821563720703
Batch 40/64 loss: -2.4423274993896484
Batch 41/64 loss: -2.4100074768066406
Batch 42/64 loss: -2.3130407333374023
Batch 43/64 loss: -2.2380924224853516
Batch 44/64 loss: -2.5354928970336914
Batch 45/64 loss: -2.5634517669677734
Batch 46/64 loss: -2.2730207443237305
Batch 47/64 loss: -2.2443809509277344
Batch 48/64 loss: -2.1255407333374023
Batch 49/64 loss: -1.999654769897461
Batch 50/64 loss: -1.988236427307129
Batch 51/64 loss: -2.227457046508789
Batch 52/64 loss: -1.5796585083007812
Batch 53/64 loss: -2.2836999893188477
Batch 54/64 loss: -2.8071956634521484
Batch 55/64 loss: -2.470785140991211
Batch 56/64 loss: -2.4511098861694336
Batch 57/64 loss: -2.732858657836914
Batch 58/64 loss: -2.452228546142578
Batch 59/64 loss: -2.3639020919799805
Batch 60/64 loss: -1.5016603469848633
Batch 61/64 loss: -2.5306081771850586
Batch 62/64 loss: -2.5419397354125977
Batch 63/64 loss: -2.0539913177490234
Batch 64/64 loss: -6.3546142578125
Epoch 60  Train loss: -2.3308966991948146  Val loss: -2.4494378263598047
Epoch 61
-------------------------------
Batch 1/64 loss: -2.030074119567871
Batch 2/64 loss: -2.5479345321655273
Batch 3/64 loss: -2.557210922241211
Batch 4/64 loss: -2.608365058898926
Batch 5/64 loss: -2.7365102767944336
Batch 6/64 loss: -2.306065559387207
Batch 7/64 loss: -2.3244571685791016
Batch 8/64 loss: -2.3384313583374023
Batch 9/64 loss: -2.1099462509155273
Batch 10/64 loss: -2.446065902709961
Batch 11/64 loss: -2.2156057357788086
Batch 12/64 loss: -2.108011245727539
Batch 13/64 loss: -2.288701057434082
Batch 14/64 loss: -2.3475914001464844
Batch 15/64 loss: -2.3301401138305664
Batch 16/64 loss: -2.270125389099121
Batch 17/64 loss: -2.6874942779541016
Batch 18/64 loss: -2.668686866760254
Batch 19/64 loss: -2.1820077896118164
Batch 20/64 loss: -2.077259063720703
Batch 21/64 loss: -2.125682830810547
Batch 22/64 loss: -2.560214042663574
Batch 23/64 loss: -1.6854286193847656
Batch 24/64 loss: -2.4154129028320312
Batch 25/64 loss: -2.235081672668457
Batch 26/64 loss: -2.0112524032592773
Batch 27/64 loss: -2.6523351669311523
Batch 28/64 loss: -2.097097396850586
Batch 29/64 loss: -2.398200035095215
Batch 30/64 loss: -2.2450742721557617
Batch 31/64 loss: -2.4740753173828125
Batch 32/64 loss: -2.3469486236572266
Batch 33/64 loss: -2.6677064895629883
Batch 34/64 loss: -1.0801324844360352
Batch 35/64 loss: -2.741199493408203
Batch 36/64 loss: -2.3402814865112305
Batch 37/64 loss: -2.5824155807495117
Batch 38/64 loss: -2.3786191940307617
Batch 39/64 loss: -2.85662841796875
Batch 40/64 loss: -2.5121192932128906
Batch 41/64 loss: -2.5781164169311523
Batch 42/64 loss: -2.3163509368896484
Batch 43/64 loss: -2.6923208236694336
Batch 44/64 loss: -2.162569046020508
Batch 45/64 loss: -2.226578712463379
Batch 46/64 loss: -2.3413658142089844
Batch 47/64 loss: -2.471719741821289
Batch 48/64 loss: -2.6652650833129883
Batch 49/64 loss: -1.9548759460449219
Batch 50/64 loss: -2.471250534057617
Batch 51/64 loss: -2.3672704696655273
Batch 52/64 loss: -1.6744794845581055
Batch 53/64 loss: -2.3070926666259766
Batch 54/64 loss: -2.331052780151367
Batch 55/64 loss: -2.5438880920410156
Batch 56/64 loss: -2.490614891052246
Batch 57/64 loss: -1.6511116027832031
Batch 58/64 loss: -2.1504478454589844
Batch 59/64 loss: -2.7208986282348633
Batch 60/64 loss: -2.2428512573242188
Batch 61/64 loss: -2.486577033996582
Batch 62/64 loss: -2.0544815063476562
Batch 63/64 loss: -2.333444595336914
Batch 64/64 loss: -6.645218849182129
Epoch 61  Train loss: -2.3812569075939702  Val loss: -2.440216523265511
Epoch 62
-------------------------------
Batch 1/64 loss: -2.2215728759765625
Batch 2/64 loss: -2.728208541870117
Batch 3/64 loss: -1.9957599639892578
Batch 4/64 loss: -2.395083427429199
Batch 5/64 loss: -2.3561782836914062
Batch 6/64 loss: -2.5524654388427734
Batch 7/64 loss: -2.4736499786376953
Batch 8/64 loss: -2.5974483489990234
Batch 9/64 loss: -2.0811891555786133
Batch 10/64 loss: -2.4895505905151367
Batch 11/64 loss: -2.277284622192383
Batch 12/64 loss: -1.9037656784057617
Batch 13/64 loss: -2.596670150756836
Batch 14/64 loss: -2.505385398864746
Batch 15/64 loss: -2.3459062576293945
Batch 16/64 loss: -2.5824899673461914
Batch 17/64 loss: -2.303630828857422
Batch 18/64 loss: -2.7285289764404297
Batch 19/64 loss: -2.2822647094726562
Batch 20/64 loss: -1.8498029708862305
Batch 21/64 loss: -1.955327033996582
Batch 22/64 loss: -1.9775724411010742
Batch 23/64 loss: -2.5987205505371094
Batch 24/64 loss: -2.092073440551758
Batch 25/64 loss: -2.3473291397094727
Batch 26/64 loss: -2.344609260559082
Batch 27/64 loss: -2.3997669219970703
Batch 28/64 loss: -2.4703750610351562
Batch 29/64 loss: -2.555386543273926
Batch 30/64 loss: -1.763916015625
Batch 31/64 loss: -2.556065559387207
Batch 32/64 loss: -2.1515073776245117
Batch 33/64 loss: -2.3282995223999023
Batch 34/64 loss: -2.6883773803710938
Batch 35/64 loss: -2.6020917892456055
Batch 36/64 loss: -2.2939319610595703
Batch 37/64 loss: -2.2503862380981445
Batch 38/64 loss: -2.458047866821289
Batch 39/64 loss: -2.6251964569091797
Batch 40/64 loss: -2.188483238220215
Batch 41/64 loss: -2.3586606979370117
Batch 42/64 loss: -1.9045372009277344
Batch 43/64 loss: -2.516368865966797
Batch 44/64 loss: -2.8739099502563477
Batch 45/64 loss: -2.1616554260253906
Batch 46/64 loss: -1.0565071105957031
Batch 47/64 loss: -2.1846084594726562
Batch 48/64 loss: -2.3762598037719727
Batch 49/64 loss: -2.544147491455078
Batch 50/64 loss: -2.0576610565185547
Batch 51/64 loss: -2.484532356262207
Batch 52/64 loss: -2.5122642517089844
Batch 53/64 loss: -2.217604637145996
Batch 54/64 loss: -1.4599199295043945
Batch 55/64 loss: -2.39992618560791
Batch 56/64 loss: -2.099466323852539
Batch 57/64 loss: -2.4972686767578125
Batch 58/64 loss: -1.9229278564453125
Batch 59/64 loss: -2.543736457824707
Batch 60/64 loss: -2.131150245666504
Batch 61/64 loss: -2.08541202545166
Batch 62/64 loss: -2.134164810180664
Batch 63/64 loss: -1.4795913696289062
Batch 64/64 loss: -7.40392541885376
Epoch 62  Train loss: -2.344620003419764  Val loss: -2.353295106658411
Epoch 63
-------------------------------
Batch 1/64 loss: -1.7675848007202148
Batch 2/64 loss: -2.422970771789551
Batch 3/64 loss: -1.523324966430664
Batch 4/64 loss: -2.3620643615722656
Batch 5/64 loss: -2.1446447372436523
Batch 6/64 loss: -2.467958450317383
Batch 7/64 loss: -2.5007753372192383
Batch 8/64 loss: -2.731830596923828
Batch 9/64 loss: -2.1812782287597656
Batch 10/64 loss: -2.309321403503418
Batch 11/64 loss: -2.494379997253418
Batch 12/64 loss: -2.6735544204711914
Batch 13/64 loss: -2.3729629516601562
Batch 14/64 loss: -2.5999574661254883
Batch 15/64 loss: -2.0475664138793945
Batch 16/64 loss: -2.0893898010253906
Batch 17/64 loss: -2.18587589263916
Batch 18/64 loss: -2.167734146118164
Batch 19/64 loss: -2.3903026580810547
Batch 20/64 loss: -1.578566551208496
Batch 21/64 loss: -2.3192243576049805
Batch 22/64 loss: -1.7951679229736328
Batch 23/64 loss: -2.3618669509887695
Batch 24/64 loss: -2.3662424087524414
Batch 25/64 loss: -2.488741874694824
Batch 26/64 loss: -2.373520851135254
Batch 27/64 loss: -2.464292526245117
Batch 28/64 loss: -2.151078224182129
Batch 29/64 loss: -2.260279655456543
Batch 30/64 loss: -2.649641990661621
Batch 31/64 loss: -2.438596725463867
Batch 32/64 loss: -2.5854854583740234
Batch 33/64 loss: -1.9279212951660156
Batch 34/64 loss: -2.227583885192871
Batch 35/64 loss: -1.9969587326049805
Batch 36/64 loss: -2.610377311706543
Batch 37/64 loss: -2.4518394470214844
Batch 38/64 loss: -2.4146299362182617
Batch 39/64 loss: -2.6392459869384766
Batch 40/64 loss: -2.6045732498168945
Batch 41/64 loss: -2.3891048431396484
Batch 42/64 loss: -2.540140151977539
Batch 43/64 loss: -2.4181909561157227
Batch 44/64 loss: -1.6614980697631836
Batch 45/64 loss: -2.6880970001220703
Batch 46/64 loss: -2.483767509460449
Batch 47/64 loss: -2.5237817764282227
Batch 48/64 loss: -2.7565460205078125
Batch 49/64 loss: -2.175516128540039
Batch 50/64 loss: -2.2563180923461914
Batch 51/64 loss: -2.314608573913574
Batch 52/64 loss: -1.8655567169189453
Batch 53/64 loss: -2.2542295455932617
Batch 54/64 loss: -2.28267765045166
Batch 55/64 loss: -1.873861312866211
Batch 56/64 loss: -2.438286781311035
Batch 57/64 loss: -2.548555374145508
Batch 58/64 loss: -2.661982536315918
Batch 59/64 loss: -2.268712043762207
Batch 60/64 loss: -1.9758176803588867
Batch 61/64 loss: -2.1472110748291016
Batch 62/64 loss: -2.8991003036499023
Batch 63/64 loss: -2.29624080657959
Batch 64/64 loss: -6.804361343383789
Epoch 63  Train loss: -2.368037407070983  Val loss: -2.5755936665223635
Epoch 64
-------------------------------
Batch 1/64 loss: -2.3860206604003906
Batch 2/64 loss: -2.566387176513672
Batch 3/64 loss: -2.465648651123047
Batch 4/64 loss: -1.7443475723266602
Batch 5/64 loss: -2.489039421081543
Batch 6/64 loss: -2.3490943908691406
Batch 7/64 loss: -2.397843360900879
Batch 8/64 loss: -2.1261653900146484
Batch 9/64 loss: -2.529088020324707
Batch 10/64 loss: -2.292160987854004
Batch 11/64 loss: -2.295398712158203
Batch 12/64 loss: -2.435321807861328
Batch 13/64 loss: -2.144303321838379
Batch 14/64 loss: -1.7300176620483398
Batch 15/64 loss: -2.1737823486328125
Batch 16/64 loss: -2.506707191467285
Batch 17/64 loss: -2.4296655654907227
Batch 18/64 loss: -2.2398719787597656
Batch 19/64 loss: -2.545774459838867
Batch 20/64 loss: -2.383270263671875
Batch 21/64 loss: -2.568636894226074
Batch 22/64 loss: -2.3085174560546875
Batch 23/64 loss: -2.3125343322753906
Batch 24/64 loss: -2.591827392578125
Batch 25/64 loss: -2.718226432800293
Batch 26/64 loss: -2.332235336303711
Batch 27/64 loss: -2.389251708984375
Batch 28/64 loss: -2.6593189239501953
Batch 29/64 loss: -2.5073957443237305
Batch 30/64 loss: -1.8758134841918945
Batch 31/64 loss: -2.2288150787353516
Batch 32/64 loss: -2.5173349380493164
Batch 33/64 loss: -2.5713672637939453
Batch 34/64 loss: -2.3015851974487305
Batch 35/64 loss: -2.39052677154541
Batch 36/64 loss: -2.6385507583618164
Batch 37/64 loss: -1.6698007583618164
Batch 38/64 loss: -2.3911428451538086
Batch 39/64 loss: -2.468958854675293
Batch 40/64 loss: -2.6650609970092773
Batch 41/64 loss: -1.4262304306030273
Batch 42/64 loss: -2.119304656982422
Batch 43/64 loss: -2.412303924560547
Batch 44/64 loss: -2.2601194381713867
Batch 45/64 loss: -2.1702022552490234
Batch 46/64 loss: -2.228984832763672
Batch 47/64 loss: -2.475656509399414
Batch 48/64 loss: -2.6697072982788086
Batch 49/64 loss: -2.4178342819213867
Batch 50/64 loss: -2.3181076049804688
Batch 51/64 loss: -2.5300979614257812
Batch 52/64 loss: -2.2900896072387695
Batch 53/64 loss: -2.540299415588379
Batch 54/64 loss: -1.945547103881836
Batch 55/64 loss: -2.761157989501953
Batch 56/64 loss: -1.6881980895996094
Batch 57/64 loss: -1.7012996673583984
Batch 58/64 loss: -2.6218385696411133
Batch 59/64 loss: -2.514512062072754
Batch 60/64 loss: -2.3795900344848633
Batch 61/64 loss: -1.7806215286254883
Batch 62/64 loss: -2.6129817962646484
Batch 63/64 loss: -2.631527900695801
Batch 64/64 loss: -6.663080215454102
Epoch 64  Train loss: -2.3816522860059552  Val loss: -2.5354113103597844
Epoch 65
-------------------------------
Batch 1/64 loss: -2.72324275970459
Batch 2/64 loss: -2.277355194091797
Batch 3/64 loss: -2.53359317779541
Batch 4/64 loss: -2.261744499206543
Batch 5/64 loss: -2.40792179107666
Batch 6/64 loss: -2.2827682495117188
Batch 7/64 loss: -0.9154472351074219
Batch 8/64 loss: -2.738504409790039
Batch 9/64 loss: -1.9097013473510742
Batch 10/64 loss: -2.6354198455810547
Batch 11/64 loss: -2.3685302734375
Batch 12/64 loss: -1.9408416748046875
Batch 13/64 loss: -2.579350471496582
Batch 14/64 loss: -2.497572898864746
Batch 15/64 loss: -1.8019676208496094
Batch 16/64 loss: -2.488832473754883
Batch 17/64 loss: -2.549372673034668
Batch 18/64 loss: -2.187718391418457
Batch 19/64 loss: -1.5215015411376953
Batch 20/64 loss: -2.638601303100586
Batch 21/64 loss: -2.428091049194336
Batch 22/64 loss: -2.1396303176879883
Batch 23/64 loss: -2.4805517196655273
Batch 24/64 loss: -2.1653194427490234
Batch 25/64 loss: -2.08023738861084
Batch 26/64 loss: -2.798884391784668
Batch 27/64 loss: -1.8540334701538086
Batch 28/64 loss: -2.134579658508301
Batch 29/64 loss: -1.6493539810180664
Batch 30/64 loss: -2.612262725830078
Batch 31/64 loss: -1.950357437133789
Batch 32/64 loss: -2.505544662475586
Batch 33/64 loss: -2.017062187194824
Batch 34/64 loss: -2.1080102920532227
Batch 35/64 loss: -2.5751781463623047
Batch 36/64 loss: -2.2429819107055664
Batch 37/64 loss: -2.567641258239746
Batch 38/64 loss: -2.211392402648926
Batch 39/64 loss: -2.379977226257324
Batch 40/64 loss: -1.996525764465332
Batch 41/64 loss: -1.8694286346435547
Batch 42/64 loss: -2.315821647644043
Batch 43/64 loss: -2.666325569152832
Batch 44/64 loss: -2.517123222351074
Batch 45/64 loss: -2.4933834075927734
Batch 46/64 loss: -1.4610443115234375
Batch 47/64 loss: -2.179165840148926
Batch 48/64 loss: -2.383584976196289
Batch 49/64 loss: -2.8807592391967773
Batch 50/64 loss: -2.5434579849243164
Batch 51/64 loss: -2.529123306274414
Batch 52/64 loss: -2.074451446533203
Batch 53/64 loss: -1.9165639877319336
Batch 54/64 loss: -2.490447998046875
Batch 55/64 loss: -2.2367172241210938
Batch 56/64 loss: -2.463423728942871
Batch 57/64 loss: -2.0911340713500977
Batch 58/64 loss: -2.258551597595215
Batch 59/64 loss: -2.642165184020996
Batch 60/64 loss: -2.6013402938842773
Batch 61/64 loss: -2.361729621887207
Batch 62/64 loss: -2.3274831771850586
Batch 63/64 loss: -2.2236900329589844
Batch 64/64 loss: -7.360327243804932
Epoch 65  Train loss: -2.340466905107685  Val loss: -2.6215780068099295
Saving best model, epoch: 65
Epoch 66
-------------------------------
Batch 1/64 loss: -2.367523193359375
Batch 2/64 loss: -1.9999008178710938
Batch 3/64 loss: -2.5660390853881836
Batch 4/64 loss: -2.1842222213745117
Batch 5/64 loss: -2.0469884872436523
Batch 6/64 loss: -1.8996524810791016
Batch 7/64 loss: -2.214832305908203
Batch 8/64 loss: -2.762744903564453
Batch 9/64 loss: -2.2898788452148438
Batch 10/64 loss: -2.6148805618286133
Batch 11/64 loss: -2.767523765563965
Batch 12/64 loss: -2.706888198852539
Batch 13/64 loss: -2.513728141784668
Batch 14/64 loss: -2.5644397735595703
Batch 15/64 loss: -2.150485038757324
Batch 16/64 loss: -1.8884878158569336
Batch 17/64 loss: -2.7506561279296875
Batch 18/64 loss: -2.5866079330444336
Batch 19/64 loss: -2.28256893157959
Batch 20/64 loss: -2.6600513458251953
Batch 21/64 loss: -2.234524726867676
Batch 22/64 loss: -2.403696060180664
Batch 23/64 loss: -2.6568498611450195
Batch 24/64 loss: -2.380314826965332
Batch 25/64 loss: -2.340036392211914
Batch 26/64 loss: -2.0159425735473633
Batch 27/64 loss: -2.9552831649780273
Batch 28/64 loss: -2.1803789138793945
Batch 29/64 loss: -2.4283618927001953
Batch 30/64 loss: -2.442317008972168
Batch 31/64 loss: -2.209909439086914
Batch 32/64 loss: -2.582882881164551
Batch 33/64 loss: -2.0936832427978516
Batch 34/64 loss: -2.6593847274780273
Batch 35/64 loss: -2.48740291595459
Batch 36/64 loss: -2.6858110427856445
Batch 37/64 loss: -1.6766853332519531
Batch 38/64 loss: -2.200136184692383
Batch 39/64 loss: -2.53134822845459
Batch 40/64 loss: -2.1075057983398438
Batch 41/64 loss: -2.2369747161865234
Batch 42/64 loss: -2.172226905822754
Batch 43/64 loss: -2.3944664001464844
Batch 44/64 loss: -2.637373924255371
Batch 45/64 loss: -1.7863349914550781
Batch 46/64 loss: -2.514017105102539
Batch 47/64 loss: -2.462251663208008
Batch 48/64 loss: -1.5586109161376953
Batch 49/64 loss: -2.6489076614379883
Batch 50/64 loss: -1.8326177597045898
Batch 51/64 loss: -2.1059885025024414
Batch 52/64 loss: -2.185230255126953
Batch 53/64 loss: -2.2700395584106445
Batch 54/64 loss: -2.2548999786376953
Batch 55/64 loss: -2.1769838333129883
Batch 56/64 loss: -1.7676315307617188
Batch 57/64 loss: -2.6205806732177734
Batch 58/64 loss: -2.6680479049682617
Batch 59/64 loss: -2.3927106857299805
Batch 60/64 loss: -1.9486141204833984
Batch 61/64 loss: -2.4230594635009766
Batch 62/64 loss: -2.474064826965332
Batch 63/64 loss: -2.539051055908203
Batch 64/64 loss: -7.075314521789551
Epoch 66  Train loss: -2.3916505963194603  Val loss: -2.615338604065151
Epoch 67
-------------------------------
Batch 1/64 loss: -2.2057085037231445
Batch 2/64 loss: -2.6756677627563477
Batch 3/64 loss: -2.407355308532715
Batch 4/64 loss: -2.4041566848754883
Batch 5/64 loss: -2.561367988586426
Batch 6/64 loss: -2.4626026153564453
Batch 7/64 loss: -2.522994041442871
Batch 8/64 loss: -2.447360038757324
Batch 9/64 loss: -2.7576770782470703
Batch 10/64 loss: -2.53433895111084
Batch 11/64 loss: -2.3047428131103516
Batch 12/64 loss: -2.0611963272094727
Batch 13/64 loss: -1.7401723861694336
Batch 14/64 loss: -2.2270383834838867
Batch 15/64 loss: -2.54464054107666
Batch 16/64 loss: -2.35772705078125
Batch 17/64 loss: -1.863673210144043
Batch 18/64 loss: -1.6047859191894531
Batch 19/64 loss: -2.4864683151245117
Batch 20/64 loss: -2.480907440185547
Batch 21/64 loss: -1.989309310913086
Batch 22/64 loss: -2.585573196411133
Batch 23/64 loss: -2.709242820739746
Batch 24/64 loss: -1.8520374298095703
Batch 25/64 loss: -2.3338394165039062
Batch 26/64 loss: -1.7453556060791016
Batch 27/64 loss: -2.523946762084961
Batch 28/64 loss: -1.668288230895996
Batch 29/64 loss: -1.784193992614746
Batch 30/64 loss: -2.2007226943969727
Batch 31/64 loss: -2.4607601165771484
Batch 32/64 loss: -2.631497383117676
Batch 33/64 loss: -2.6409692764282227
Batch 34/64 loss: -2.004117965698242
Batch 35/64 loss: -2.5754690170288086
Batch 36/64 loss: -2.4036388397216797
Batch 37/64 loss: -2.4129762649536133
Batch 38/64 loss: -2.555190086364746
Batch 39/64 loss: -2.819666862487793
Batch 40/64 loss: -2.6095619201660156
Batch 41/64 loss: -2.518815040588379
Batch 42/64 loss: -2.4476938247680664
Batch 43/64 loss: -2.626662254333496
Batch 44/64 loss: -2.092158317565918
Batch 45/64 loss: -2.398838996887207
Batch 46/64 loss: -2.1587533950805664
Batch 47/64 loss: -2.6353940963745117
Batch 48/64 loss: -2.0957164764404297
Batch 49/64 loss: -2.4034910202026367
Batch 50/64 loss: -2.7350540161132812
Batch 51/64 loss: -2.480799674987793
Batch 52/64 loss: -2.71988582611084
Batch 53/64 loss: -2.756458282470703
Batch 54/64 loss: -2.5627565383911133
Batch 55/64 loss: -1.9947376251220703
Batch 56/64 loss: -2.3312482833862305
Batch 57/64 loss: -2.248910903930664
Batch 58/64 loss: -2.471345901489258
Batch 59/64 loss: -2.337010383605957
Batch 60/64 loss: -2.3932361602783203
Batch 61/64 loss: -1.800741195678711
Batch 62/64 loss: -2.56588077545166
Batch 63/64 loss: -2.312206268310547
Batch 64/64 loss: -7.409143924713135
Epoch 67  Train loss: -2.412573988297406  Val loss: -2.7020214120137322
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: -2.4423351287841797
Batch 2/64 loss: -2.191971778869629
Batch 3/64 loss: -2.465007781982422
Batch 4/64 loss: -2.3292922973632812
Batch 5/64 loss: -2.411862373352051
Batch 6/64 loss: -2.514695167541504
Batch 7/64 loss: -1.6145954132080078
Batch 8/64 loss: -2.355343818664551
Batch 9/64 loss: -2.542782783508301
Batch 10/64 loss: -2.136216163635254
Batch 11/64 loss: -2.364856719970703
Batch 12/64 loss: -2.453280448913574
Batch 13/64 loss: -2.618387222290039
Batch 14/64 loss: -2.1789112091064453
Batch 15/64 loss: -2.22198486328125
Batch 16/64 loss: -2.7039785385131836
Batch 17/64 loss: -2.4552879333496094
Batch 18/64 loss: -2.668276786804199
Batch 19/64 loss: -2.451411247253418
Batch 20/64 loss: -2.4621009826660156
Batch 21/64 loss: -2.2123069763183594
Batch 22/64 loss: -2.7186107635498047
Batch 23/64 loss: -2.7144107818603516
Batch 24/64 loss: -2.4328269958496094
Batch 25/64 loss: -2.5122156143188477
Batch 26/64 loss: -2.5243892669677734
Batch 27/64 loss: -2.4856882095336914
Batch 28/64 loss: -2.434366226196289
Batch 29/64 loss: -2.2562570571899414
Batch 30/64 loss: -2.340677261352539
Batch 31/64 loss: -2.6591176986694336
Batch 32/64 loss: -2.4084014892578125
Batch 33/64 loss: -2.2882165908813477
Batch 34/64 loss: -2.375473976135254
Batch 35/64 loss: -2.6113271713256836
Batch 36/64 loss: -2.4203271865844727
Batch 37/64 loss: -2.302591323852539
Batch 38/64 loss: -2.275686264038086
Batch 39/64 loss: -2.315082550048828
Batch 40/64 loss: -2.366665840148926
Batch 41/64 loss: -1.870265007019043
Batch 42/64 loss: -2.0106658935546875
Batch 43/64 loss: -2.1350831985473633
Batch 44/64 loss: -2.642202377319336
Batch 45/64 loss: -2.3581018447875977
Batch 46/64 loss: -2.644695281982422
Batch 47/64 loss: -1.7269668579101562
Batch 48/64 loss: -1.7316617965698242
Batch 49/64 loss: -2.263887405395508
Batch 50/64 loss: -2.546929359436035
Batch 51/64 loss: -2.4959888458251953
Batch 52/64 loss: -2.5363597869873047
Batch 53/64 loss: -2.540310859680176
Batch 54/64 loss: -2.1627655029296875
Batch 55/64 loss: -1.6191473007202148
Batch 56/64 loss: -2.076382637023926
Batch 57/64 loss: -2.6160459518432617
Batch 58/64 loss: -2.230099678039551
Batch 59/64 loss: -1.7860536575317383
Batch 60/64 loss: -2.0802316665649414
Batch 61/64 loss: -2.424044609069824
Batch 62/64 loss: -2.6649656295776367
Batch 63/64 loss: -2.2547922134399414
Batch 64/64 loss: -7.212918281555176
Epoch 68  Train loss: -2.4010126113891603  Val loss: -2.6779636501036967
Epoch 69
-------------------------------
Batch 1/64 loss: -2.120528221130371
Batch 2/64 loss: -1.9206790924072266
Batch 3/64 loss: -2.34207820892334
Batch 4/64 loss: -2.46649169921875
Batch 5/64 loss: -2.5538978576660156
Batch 6/64 loss: -2.2539472579956055
Batch 7/64 loss: -2.6518030166625977
Batch 8/64 loss: -1.818486213684082
Batch 9/64 loss: -2.5657949447631836
Batch 10/64 loss: -2.2571792602539062
Batch 11/64 loss: -1.9896984100341797
Batch 12/64 loss: -1.607743263244629
Batch 13/64 loss: -2.1543731689453125
Batch 14/64 loss: -2.409905433654785
Batch 15/64 loss: -2.2640161514282227
Batch 16/64 loss: -2.413895606994629
Batch 17/64 loss: -1.8652658462524414
Batch 18/64 loss: -2.0708656311035156
Batch 19/64 loss: -2.068182945251465
Batch 20/64 loss: -2.329054832458496
Batch 21/64 loss: -2.1981582641601562
Batch 22/64 loss: -2.4534454345703125
Batch 23/64 loss: -2.379876136779785
Batch 24/64 loss: -2.2478904724121094
Batch 25/64 loss: -2.1630306243896484
Batch 26/64 loss: -1.9976444244384766
Batch 27/64 loss: -2.372918128967285
Batch 28/64 loss: -2.4377994537353516
Batch 29/64 loss: -1.7702522277832031
Batch 30/64 loss: -2.6817092895507812
Batch 31/64 loss: -2.3319625854492188
Batch 32/64 loss: -2.5807533264160156
Batch 33/64 loss: -2.578261375427246
Batch 34/64 loss: -2.8501205444335938
Batch 35/64 loss: -1.8164939880371094
Batch 36/64 loss: -2.4376726150512695
Batch 37/64 loss: -2.1780128479003906
Batch 38/64 loss: -2.3041019439697266
Batch 39/64 loss: -2.3753585815429688
Batch 40/64 loss: -2.3558340072631836
Batch 41/64 loss: -2.4628868103027344
Batch 42/64 loss: -2.038987159729004
Batch 43/64 loss: -2.5123605728149414
Batch 44/64 loss: -2.1889047622680664
Batch 45/64 loss: -2.1962709426879883
Batch 46/64 loss: -2.491769790649414
Batch 47/64 loss: -2.3833131790161133
Batch 48/64 loss: -2.192220687866211
Batch 49/64 loss: -2.498671531677246
Batch 50/64 loss: -2.6836977005004883
Batch 51/64 loss: -2.5140342712402344
Batch 52/64 loss: -2.276921272277832
Batch 53/64 loss: -2.538912773132324
Batch 54/64 loss: -2.5589237213134766
Batch 55/64 loss: -2.106614112854004
Batch 56/64 loss: -1.8899736404418945
Batch 57/64 loss: -2.763382911682129
Batch 58/64 loss: -2.3769359588623047
Batch 59/64 loss: -2.3598804473876953
Batch 60/64 loss: -2.153151512145996
Batch 61/64 loss: -2.602048873901367
Batch 62/64 loss: -2.500446319580078
Batch 63/64 loss: -2.6431961059570312
Batch 64/64 loss: -7.043062210083008
Epoch 69  Train loss: -2.3662899615717867  Val loss: -2.7078642566589144
Saving best model, epoch: 69
Epoch 70
-------------------------------
Batch 1/64 loss: -2.2434005737304688
Batch 2/64 loss: -2.6563472747802734
Batch 3/64 loss: -2.579726219177246
Batch 4/64 loss: -2.536410331726074
Batch 5/64 loss: -2.487147331237793
Batch 6/64 loss: -2.4001922607421875
Batch 7/64 loss: -2.3953733444213867
Batch 8/64 loss: -2.479538917541504
Batch 9/64 loss: -2.326888084411621
Batch 10/64 loss: -2.5287961959838867
Batch 11/64 loss: -2.585688591003418
Batch 12/64 loss: -2.838320732116699
Batch 13/64 loss: -2.5971107482910156
Batch 14/64 loss: -2.500454902648926
Batch 15/64 loss: -1.6326923370361328
Batch 16/64 loss: -1.4069414138793945
Batch 17/64 loss: -2.6181106567382812
Batch 18/64 loss: -2.557321548461914
Batch 19/64 loss: -2.7143192291259766
Batch 20/64 loss: -2.6357955932617188
Batch 21/64 loss: -2.3779640197753906
Batch 22/64 loss: -2.8098506927490234
Batch 23/64 loss: -2.569244384765625
Batch 24/64 loss: -2.1771316528320312
Batch 25/64 loss: -1.5793123245239258
Batch 26/64 loss: -2.293060302734375
Batch 27/64 loss: -2.176173210144043
Batch 28/64 loss: -2.501450538635254
Batch 29/64 loss: -2.3971776962280273
Batch 30/64 loss: -2.5472288131713867
Batch 31/64 loss: -2.490070343017578
Batch 32/64 loss: -2.5417747497558594
Batch 33/64 loss: -2.249086380004883
Batch 34/64 loss: -1.207779884338379
Batch 35/64 loss: -2.5764389038085938
Batch 36/64 loss: -1.5407524108886719
Batch 37/64 loss: -2.4671897888183594
Batch 38/64 loss: -2.3466758728027344
Batch 39/64 loss: -2.4184885025024414
Batch 40/64 loss: -2.058396339416504
Batch 41/64 loss: -2.215449333190918
Batch 42/64 loss: -1.6436805725097656
Batch 43/64 loss: -2.234738349914551
Batch 44/64 loss: -2.2332916259765625
Batch 45/64 loss: -2.3601741790771484
Batch 46/64 loss: -1.639455795288086
Batch 47/64 loss: -2.0158424377441406
Batch 48/64 loss: -1.8845252990722656
Batch 49/64 loss: -2.192023277282715
Batch 50/64 loss: -1.2753686904907227
Batch 51/64 loss: -1.779963493347168
Batch 52/64 loss: -2.5512657165527344
Batch 53/64 loss: -2.5452327728271484
Batch 54/64 loss: -2.4465723037719727
Batch 55/64 loss: -2.4850568771362305
Batch 56/64 loss: -2.6402740478515625
Batch 57/64 loss: -2.456650733947754
Batch 58/64 loss: -2.277745246887207
Batch 59/64 loss: -2.784425735473633
Batch 60/64 loss: -2.413555145263672
Batch 61/64 loss: -2.3699378967285156
Batch 62/64 loss: -2.5233469009399414
Batch 63/64 loss: -2.5878477096557617
Batch 64/64 loss: -7.207211017608643
Epoch 70  Train loss: -2.3687475372763243  Val loss: -2.223749835876255
Epoch 71
-------------------------------
Batch 1/64 loss: -2.8006181716918945
Batch 2/64 loss: -2.1153087615966797
Batch 3/64 loss: -2.307199478149414
Batch 4/64 loss: -2.4626617431640625
Batch 5/64 loss: -2.5658531188964844
Batch 6/64 loss: -2.2477731704711914
Batch 7/64 loss: -2.247157096862793
Batch 8/64 loss: -2.598538398742676
Batch 9/64 loss: -2.5128469467163086
Batch 10/64 loss: -2.2020435333251953
Batch 11/64 loss: -2.3575210571289062
Batch 12/64 loss: -2.612908363342285
Batch 13/64 loss: -2.2765302658081055
Batch 14/64 loss: -2.1783390045166016
Batch 15/64 loss: -2.316256523132324
Batch 16/64 loss: -2.2961387634277344
Batch 17/64 loss: -2.6391353607177734
Batch 18/64 loss: -2.187389373779297
Batch 19/64 loss: -1.625260353088379
Batch 20/64 loss: -2.2096452713012695
Batch 21/64 loss: -2.045085906982422
Batch 22/64 loss: -2.2006168365478516
Batch 23/64 loss: -2.634397506713867
Batch 24/64 loss: -2.404921531677246
Batch 25/64 loss: -2.4263525009155273
Batch 26/64 loss: -2.245669364929199
Batch 27/64 loss: -2.6443967819213867
Batch 28/64 loss: -2.5004358291625977
Batch 29/64 loss: -2.5772790908813477
Batch 30/64 loss: -2.2923479080200195
Batch 31/64 loss: -2.4297142028808594
Batch 32/64 loss: -2.4467506408691406
Batch 33/64 loss: -2.4039344787597656
Batch 34/64 loss: -1.6821269989013672
Batch 35/64 loss: -2.702007293701172
Batch 36/64 loss: -2.2264223098754883
Batch 37/64 loss: -2.4207839965820312
Batch 38/64 loss: -1.8273706436157227
Batch 39/64 loss: -2.483027458190918
Batch 40/64 loss: -2.0800771713256836
Batch 41/64 loss: -2.5689258575439453
Batch 42/64 loss: -2.541628837585449
Batch 43/64 loss: -2.3705530166625977
Batch 44/64 loss: -2.070720672607422
Batch 45/64 loss: -1.993708610534668
Batch 46/64 loss: -2.804060935974121
Batch 47/64 loss: -1.5704565048217773
Batch 48/64 loss: -2.5032529830932617
Batch 49/64 loss: -2.247631072998047
Batch 50/64 loss: -1.2292156219482422
Batch 51/64 loss: -2.5041418075561523
Batch 52/64 loss: -2.455904960632324
Batch 53/64 loss: -2.8217315673828125
Batch 54/64 loss: -1.8921260833740234
Batch 55/64 loss: -2.5750322341918945
Batch 56/64 loss: -2.69901180267334
Batch 57/64 loss: -2.1031875610351562
Batch 58/64 loss: -1.841191291809082
Batch 59/64 loss: -1.8184795379638672
Batch 60/64 loss: -2.3913354873657227
Batch 61/64 loss: -2.318539619445801
Batch 62/64 loss: -2.4919309616088867
Batch 63/64 loss: -2.642763137817383
Batch 64/64 loss: -7.212010860443115
Epoch 71  Train loss: -2.3732922591415107  Val loss: -2.430313044806936
Epoch 72
-------------------------------
Batch 1/64 loss: -2.6301488876342773
Batch 2/64 loss: -2.7870445251464844
Batch 3/64 loss: -2.521517753601074
Batch 4/64 loss: -2.498847007751465
Batch 5/64 loss: -1.6864986419677734
Batch 6/64 loss: -2.579744338989258
Batch 7/64 loss: -2.610095977783203
Batch 8/64 loss: -2.1358842849731445
Batch 9/64 loss: -1.7252674102783203
Batch 10/64 loss: -2.322312355041504
Batch 11/64 loss: -2.518301010131836
Batch 12/64 loss: -2.49246883392334
Batch 13/64 loss: -2.2466182708740234
Batch 14/64 loss: -2.57327938079834
Batch 15/64 loss: -2.389232635498047
Batch 16/64 loss: -2.7481327056884766
Batch 17/64 loss: -1.500340461730957
Batch 18/64 loss: -2.1434803009033203
Batch 19/64 loss: -2.6593284606933594
Batch 20/64 loss: -1.7298669815063477
Batch 21/64 loss: -2.4352807998657227
Batch 22/64 loss: -2.0912084579467773
Batch 23/64 loss: -2.6692867279052734
Batch 24/64 loss: -2.3269386291503906
Batch 25/64 loss: -1.948995590209961
Batch 26/64 loss: -2.1811656951904297
Batch 27/64 loss: -2.6329469680786133
Batch 28/64 loss: -2.585751533508301
Batch 29/64 loss: -2.40041446685791
Batch 30/64 loss: -2.0318822860717773
Batch 31/64 loss: -2.3014135360717773
Batch 32/64 loss: -2.53963565826416
Batch 33/64 loss: -2.3286094665527344
Batch 34/64 loss: -2.2635202407836914
Batch 35/64 loss: -2.0663299560546875
Batch 36/64 loss: -2.11684513092041
Batch 37/64 loss: -1.7812995910644531
Batch 38/64 loss: -1.2269229888916016
Batch 39/64 loss: -2.1888084411621094
Batch 40/64 loss: -1.9132862091064453
Batch 41/64 loss: -2.359707832336426
Batch 42/64 loss: -2.230473518371582
Batch 43/64 loss: -1.760528564453125
Batch 44/64 loss: -1.7276802062988281
Batch 45/64 loss: -2.2658910751342773
Batch 46/64 loss: -2.109678268432617
Batch 47/64 loss: -2.6470584869384766
Batch 48/64 loss: -2.018259048461914
Batch 49/64 loss: -1.842423439025879
Batch 50/64 loss: -1.6702308654785156
Batch 51/64 loss: -2.040538787841797
Batch 52/64 loss: -2.041316032409668
Batch 53/64 loss: -2.335268974304199
Batch 54/64 loss: -2.249980926513672
Batch 55/64 loss: -2.1182422637939453
Batch 56/64 loss: -2.3408994674682617
Batch 57/64 loss: -2.66683292388916
Batch 58/64 loss: -2.7782583236694336
Batch 59/64 loss: -2.320650100708008
Batch 60/64 loss: -2.257826805114746
Batch 61/64 loss: -2.3619441986083984
Batch 62/64 loss: -1.8607330322265625
Batch 63/64 loss: -2.571521759033203
Batch 64/64 loss: -7.058511734008789
Epoch 72  Train loss: -2.2964514713661344  Val loss: -2.6381718743707716
Epoch 73
-------------------------------
Batch 1/64 loss: -2.392213821411133
Batch 2/64 loss: -2.130960464477539
Batch 3/64 loss: -2.4318103790283203
Batch 4/64 loss: -2.635117530822754
Batch 5/64 loss: -2.485025405883789
Batch 6/64 loss: -2.260256767272949
Batch 7/64 loss: -2.81742000579834
Batch 8/64 loss: -2.351944923400879
Batch 9/64 loss: -1.9590539932250977
Batch 10/64 loss: -1.8277091979980469
Batch 11/64 loss: -1.7487335205078125
Batch 12/64 loss: -2.1270370483398438
Batch 13/64 loss: -1.7386207580566406
Batch 14/64 loss: -2.4998016357421875
Batch 15/64 loss: -2.4351491928100586
Batch 16/64 loss: -2.1485061645507812
Batch 17/64 loss: -2.6291961669921875
Batch 18/64 loss: -1.9014081954956055
Batch 19/64 loss: -2.3442506790161133
Batch 20/64 loss: -2.4836673736572266
Batch 21/64 loss: -1.8297386169433594
Batch 22/64 loss: -2.1808624267578125
Batch 23/64 loss: -2.6558713912963867
Batch 24/64 loss: -2.3472728729248047
Batch 25/64 loss: -2.282649040222168
Batch 26/64 loss: -2.460576057434082
Batch 27/64 loss: -2.2307872772216797
Batch 28/64 loss: -2.497934341430664
Batch 29/64 loss: -2.228936195373535
Batch 30/64 loss: -2.4623842239379883
Batch 31/64 loss: -2.3313751220703125
Batch 32/64 loss: -2.261201858520508
Batch 33/64 loss: -1.7428503036499023
Batch 34/64 loss: -2.6546592712402344
Batch 35/64 loss: -2.7820959091186523
Batch 36/64 loss: -2.106095314025879
Batch 37/64 loss: -2.1918535232543945
Batch 38/64 loss: -2.4878501892089844
Batch 39/64 loss: -1.925431251525879
Batch 40/64 loss: -2.176873207092285
Batch 41/64 loss: -2.0800790786743164
Batch 42/64 loss: -2.531187057495117
Batch 43/64 loss: -2.642756462097168
Batch 44/64 loss: -2.5301170349121094
Batch 45/64 loss: -2.187986373901367
Batch 46/64 loss: -2.688035011291504
Batch 47/64 loss: -2.8190765380859375
Batch 48/64 loss: -2.5250024795532227
Batch 49/64 loss: -2.361215591430664
Batch 50/64 loss: -2.7521133422851562
Batch 51/64 loss: -2.8399877548217773
Batch 52/64 loss: -2.508490562438965
Batch 53/64 loss: -1.9081172943115234
Batch 54/64 loss: -2.6859188079833984
Batch 55/64 loss: -2.6191329956054688
Batch 56/64 loss: -2.3098249435424805
Batch 57/64 loss: -2.2052202224731445
Batch 58/64 loss: -1.4703388214111328
Batch 59/64 loss: -2.1523008346557617
Batch 60/64 loss: -2.452507972717285
Batch 61/64 loss: -2.0324316024780273
Batch 62/64 loss: -2.6374759674072266
Batch 63/64 loss: -2.5170392990112305
Batch 64/64 loss: -7.231976509094238
Epoch 73  Train loss: -2.3853414909512387  Val loss: -2.4913736061541893
Epoch 74
-------------------------------
Batch 1/64 loss: -2.509004592895508
Batch 2/64 loss: -2.736795425415039
Batch 3/64 loss: -2.0653305053710938
Batch 4/64 loss: -2.628323554992676
Batch 5/64 loss: -2.3497314453125
Batch 6/64 loss: -2.6330204010009766
Batch 7/64 loss: -1.8391361236572266
Batch 8/64 loss: -2.021653175354004
Batch 9/64 loss: -2.2409372329711914
Batch 10/64 loss: -2.5150318145751953
Batch 11/64 loss: -2.0585718154907227
Batch 12/64 loss: -2.080425262451172
Batch 13/64 loss: -2.6924753189086914
Batch 14/64 loss: -2.3892621994018555
Batch 15/64 loss: -2.218379020690918
Batch 16/64 loss: -1.9665803909301758
Batch 17/64 loss: -2.219449043273926
Batch 18/64 loss: -2.3479862213134766
Batch 19/64 loss: -2.32344913482666
Batch 20/64 loss: -2.481076240539551
Batch 21/64 loss: -2.528076171875
Batch 22/64 loss: -1.758859634399414
Batch 23/64 loss: -2.497220039367676
Batch 24/64 loss: -2.1680498123168945
Batch 25/64 loss: -2.3917369842529297
Batch 26/64 loss: -2.704676628112793
Batch 27/64 loss: -1.8295173645019531
Batch 28/64 loss: -2.676105499267578
Batch 29/64 loss: -2.3563003540039062
Batch 30/64 loss: -2.7346458435058594
Batch 31/64 loss: -2.492635726928711
Batch 32/64 loss: -1.9184741973876953
Batch 33/64 loss: -2.346281051635742
Batch 34/64 loss: -2.705554962158203
Batch 35/64 loss: -2.744717597961426
Batch 36/64 loss: -1.8836183547973633
Batch 37/64 loss: -2.2296142578125
Batch 38/64 loss: -2.399351119995117
Batch 39/64 loss: -2.510369300842285
Batch 40/64 loss: -2.385613441467285
Batch 41/64 loss: -2.6000537872314453
Batch 42/64 loss: -2.3668746948242188
Batch 43/64 loss: -2.3106279373168945
Batch 44/64 loss: -2.298734664916992
Batch 45/64 loss: -2.472787857055664
Batch 46/64 loss: -1.8800458908081055
Batch 47/64 loss: -1.8218116760253906
Batch 48/64 loss: -2.24204158782959
Batch 49/64 loss: -2.251667022705078
Batch 50/64 loss: -2.475597381591797
Batch 51/64 loss: -2.1488428115844727
Batch 52/64 loss: -2.73685359954834
Batch 53/64 loss: -2.3874378204345703
Batch 54/64 loss: -1.5895071029663086
Batch 55/64 loss: -3.0008888244628906
Batch 56/64 loss: -2.0788869857788086
Batch 57/64 loss: -2.572493553161621
Batch 58/64 loss: -2.5240249633789062
Batch 59/64 loss: -2.1995487213134766
Batch 60/64 loss: -2.81533145904541
Batch 61/64 loss: -2.612812042236328
Batch 62/64 loss: -2.6371564865112305
Batch 63/64 loss: -2.534478187561035
Batch 64/64 loss: -6.824556350708008
Epoch 74  Train loss: -2.403999366012274  Val loss: -2.7418776050056377
Saving best model, epoch: 74
Epoch 75
-------------------------------
Batch 1/64 loss: -2.738241195678711
Batch 2/64 loss: -2.6449966430664062
Batch 3/64 loss: -2.1332340240478516
Batch 4/64 loss: -2.301680564880371
Batch 5/64 loss: -2.60500431060791
Batch 6/64 loss: -2.742677688598633
Batch 7/64 loss: -2.2531051635742188
Batch 8/64 loss: -2.6146745681762695
Batch 9/64 loss: -2.699063301086426
Batch 10/64 loss: -2.6604843139648438
Batch 11/64 loss: -2.461406707763672
Batch 12/64 loss: -2.679194450378418
Batch 13/64 loss: -2.767397880554199
Batch 14/64 loss: -2.28879451751709
Batch 15/64 loss: -2.6364383697509766
Batch 16/64 loss: -2.682523727416992
Batch 17/64 loss: -2.269871711730957
Batch 18/64 loss: -2.13668155670166
Batch 19/64 loss: -2.6101694107055664
Batch 20/64 loss: -2.701568603515625
Batch 21/64 loss: -2.263115882873535
Batch 22/64 loss: -2.4255990982055664
Batch 23/64 loss: -2.728975296020508
Batch 24/64 loss: -1.737874984741211
Batch 25/64 loss: -2.59414005279541
Batch 26/64 loss: -1.9828271865844727
Batch 27/64 loss: -2.519073486328125
Batch 28/64 loss: -2.8597450256347656
Batch 29/64 loss: -2.3343210220336914
Batch 30/64 loss: -2.333157539367676
Batch 31/64 loss: -2.3637771606445312
Batch 32/64 loss: -2.6597909927368164
Batch 33/64 loss: -2.642230987548828
Batch 34/64 loss: -2.5897369384765625
Batch 35/64 loss: -1.7638301849365234
Batch 36/64 loss: -2.3294267654418945
Batch 37/64 loss: -1.7019157409667969
Batch 38/64 loss: -2.403071403503418
Batch 39/64 loss: -2.7246179580688477
Batch 40/64 loss: -2.8402347564697266
Batch 41/64 loss: -2.7133331298828125
Batch 42/64 loss: -2.2808895111083984
Batch 43/64 loss: -2.4946537017822266
Batch 44/64 loss: -2.8873586654663086
Batch 45/64 loss: -2.5078868865966797
Batch 46/64 loss: -2.425832748413086
Batch 47/64 loss: -2.476679801940918
Batch 48/64 loss: -1.4778814315795898
Batch 49/64 loss: -1.8255157470703125
Batch 50/64 loss: -2.235823631286621
Batch 51/64 loss: -2.476865768432617
Batch 52/64 loss: -2.573124885559082
Batch 53/64 loss: -2.460808753967285
Batch 54/64 loss: -2.3122425079345703
Batch 55/64 loss: -2.618971824645996
Batch 56/64 loss: -2.459613800048828
Batch 57/64 loss: -1.6029558181762695
Batch 58/64 loss: -2.431990623474121
Batch 59/64 loss: -2.5350637435913086
Batch 60/64 loss: -2.795172691345215
Batch 61/64 loss: -2.132411003112793
Batch 62/64 loss: -2.5839061737060547
Batch 63/64 loss: -2.4434194564819336
Batch 64/64 loss: -6.155882835388184
Epoch 75  Train loss: -2.475199774199841  Val loss: -2.664123797334756
Epoch 76
-------------------------------
Batch 1/64 loss: -2.752237319946289
Batch 2/64 loss: -2.4749183654785156
Batch 3/64 loss: -1.9239721298217773
Batch 4/64 loss: -2.5113296508789062
Batch 5/64 loss: -2.3363304138183594
Batch 6/64 loss: -2.432602882385254
Batch 7/64 loss: -1.9817161560058594
Batch 8/64 loss: -2.509516716003418
Batch 9/64 loss: -2.291147232055664
Batch 10/64 loss: -2.138575553894043
Batch 11/64 loss: -2.517740249633789
Batch 12/64 loss: -0.6969127655029297
Batch 13/64 loss: -2.1617555618286133
Batch 14/64 loss: -2.260652542114258
Batch 15/64 loss: -2.2259387969970703
Batch 16/64 loss: -2.064764976501465
Batch 17/64 loss: -2.2746734619140625
Batch 18/64 loss: -2.6809167861938477
Batch 19/64 loss: -2.3567628860473633
Batch 20/64 loss: -2.6549997329711914
Batch 21/64 loss: -2.803399085998535
Batch 22/64 loss: -2.462796211242676
Batch 23/64 loss: -2.5597476959228516
Batch 24/64 loss: -2.3790979385375977
Batch 25/64 loss: -2.6261510848999023
Batch 26/64 loss: -2.5166454315185547
Batch 27/64 loss: -2.1043882369995117
Batch 28/64 loss: -2.5864171981811523
Batch 29/64 loss: -2.403182029724121
Batch 30/64 loss: -2.696242332458496
Batch 31/64 loss: -2.589169502258301
Batch 32/64 loss: -2.358311653137207
Batch 33/64 loss: -2.6023387908935547
Batch 34/64 loss: -2.350496292114258
Batch 35/64 loss: -2.5671825408935547
Batch 36/64 loss: -2.568910598754883
Batch 37/64 loss: -2.1723575592041016
Batch 38/64 loss: -1.0005006790161133
Batch 39/64 loss: -2.430511474609375
Batch 40/64 loss: -2.635470390319824
Batch 41/64 loss: -2.080404281616211
Batch 42/64 loss: -2.5104551315307617
Batch 43/64 loss: -2.7257862091064453
Batch 44/64 loss: -2.5044326782226562
Batch 45/64 loss: -1.3995370864868164
Batch 46/64 loss: -2.542470932006836
Batch 47/64 loss: -2.412014961242676
Batch 48/64 loss: -2.587277412414551
Batch 49/64 loss: -2.632441520690918
Batch 50/64 loss: -2.5259056091308594
Batch 51/64 loss: -2.602200508117676
Batch 52/64 loss: -2.708089828491211
Batch 53/64 loss: -2.2715091705322266
Batch 54/64 loss: -2.1539134979248047
Batch 55/64 loss: -2.20723819732666
Batch 56/64 loss: -2.5936145782470703
Batch 57/64 loss: -2.449014663696289
Batch 58/64 loss: -2.113628387451172
Batch 59/64 loss: -2.079939842224121
Batch 60/64 loss: -1.8185234069824219
Batch 61/64 loss: -2.2913522720336914
Batch 62/64 loss: -1.8126983642578125
Batch 63/64 loss: -2.683041572570801
Batch 64/64 loss: -7.051735877990723
Epoch 76  Train loss: -2.3945893792545094  Val loss: -2.455533109579709
Epoch 77
-------------------------------
Batch 1/64 loss: -1.9504899978637695
Batch 2/64 loss: -2.407689094543457
Batch 3/64 loss: -2.399168014526367
Batch 4/64 loss: -2.525753974914551
Batch 5/64 loss: -2.485593795776367
Batch 6/64 loss: -2.6480064392089844
Batch 7/64 loss: -2.4955005645751953
Batch 8/64 loss: -1.9447336196899414
Batch 9/64 loss: -2.7338943481445312
Batch 10/64 loss: -2.639986991882324
Batch 11/64 loss: -2.4951171875
Batch 12/64 loss: -1.4441194534301758
Batch 13/64 loss: -2.4106063842773438
Batch 14/64 loss: -2.961833953857422
Batch 15/64 loss: -2.3677473068237305
Batch 16/64 loss: -2.1684751510620117
Batch 17/64 loss: -2.458463668823242
Batch 18/64 loss: -1.6698789596557617
Batch 19/64 loss: -2.575869560241699
Batch 20/64 loss: -2.569499969482422
Batch 21/64 loss: -2.5502729415893555
Batch 22/64 loss: -2.2472639083862305
Batch 23/64 loss: -2.6050891876220703
Batch 24/64 loss: -2.626866340637207
Batch 25/64 loss: -2.490725517272949
Batch 26/64 loss: -2.6416311264038086
Batch 27/64 loss: -2.2717084884643555
Batch 28/64 loss: -2.613570213317871
Batch 29/64 loss: -2.7965431213378906
Batch 30/64 loss: -2.4949750900268555
Batch 31/64 loss: -2.4642868041992188
Batch 32/64 loss: -2.434694290161133
Batch 33/64 loss: -2.6889657974243164
Batch 34/64 loss: -1.4785747528076172
Batch 35/64 loss: -2.133122444152832
Batch 36/64 loss: -2.771672248840332
Batch 37/64 loss: -2.3630666732788086
Batch 38/64 loss: -2.5534534454345703
Batch 39/64 loss: -2.2230052947998047
Batch 40/64 loss: -1.9928350448608398
Batch 41/64 loss: -2.636380195617676
Batch 42/64 loss: -2.478006362915039
Batch 43/64 loss: -2.0200729370117188
Batch 44/64 loss: -2.515377998352051
Batch 45/64 loss: -2.1572141647338867
Batch 46/64 loss: -2.505274772644043
Batch 47/64 loss: -1.8183231353759766
Batch 48/64 loss: -2.639134407043457
Batch 49/64 loss: -2.5407676696777344
Batch 50/64 loss: -2.045712471008301
Batch 51/64 loss: -2.438096046447754
Batch 52/64 loss: -2.4848690032958984
Batch 53/64 loss: -2.275979995727539
Batch 54/64 loss: -2.383260726928711
Batch 55/64 loss: -2.602328300476074
Batch 56/64 loss: -2.264751434326172
Batch 57/64 loss: -2.3034849166870117
Batch 58/64 loss: -2.380496025085449
Batch 59/64 loss: -2.7507753372192383
Batch 60/64 loss: -2.299243927001953
Batch 61/64 loss: -2.2933311462402344
Batch 62/64 loss: -2.5986013412475586
Batch 63/64 loss: -2.515986442565918
Batch 64/64 loss: -7.327168941497803
Epoch 77  Train loss: -2.4507858295066685  Val loss: -2.6108227759292446
Epoch 78
-------------------------------
Batch 1/64 loss: -1.4715404510498047
Batch 2/64 loss: -2.05741024017334
Batch 3/64 loss: -2.5440311431884766
Batch 4/64 loss: -2.4257211685180664
Batch 5/64 loss: -2.6533021926879883
Batch 6/64 loss: -2.106901168823242
Batch 7/64 loss: -2.259871482849121
Batch 8/64 loss: -2.580148696899414
Batch 9/64 loss: -2.3931407928466797
Batch 10/64 loss: -2.765223503112793
Batch 11/64 loss: -2.2656030654907227
Batch 12/64 loss: -1.6760530471801758
Batch 13/64 loss: -2.4274444580078125
Batch 14/64 loss: -2.0363988876342773
Batch 15/64 loss: -2.6936025619506836
Batch 16/64 loss: -2.2715682983398438
Batch 17/64 loss: -2.4612226486206055
Batch 18/64 loss: -2.618602752685547
Batch 19/64 loss: -2.476053237915039
Batch 20/64 loss: -2.6707286834716797
Batch 21/64 loss: -2.53338623046875
Batch 22/64 loss: -2.7174320220947266
Batch 23/64 loss: -2.0336198806762695
Batch 24/64 loss: -2.54754638671875
Batch 25/64 loss: -2.760434150695801
Batch 26/64 loss: -2.5419607162475586
Batch 27/64 loss: -2.3965702056884766
Batch 28/64 loss: -2.700136184692383
Batch 29/64 loss: -2.4325361251831055
Batch 30/64 loss: -2.072977066040039
Batch 31/64 loss: -2.5288658142089844
Batch 32/64 loss: -2.482529640197754
Batch 33/64 loss: -2.5694198608398438
Batch 34/64 loss: -2.4217729568481445
Batch 35/64 loss: -2.7412261962890625
Batch 36/64 loss: -2.4085474014282227
Batch 37/64 loss: -2.085564613342285
Batch 38/64 loss: -2.020829200744629
Batch 39/64 loss: -2.75238037109375
Batch 40/64 loss: -2.356837272644043
Batch 41/64 loss: -2.3369712829589844
Batch 42/64 loss: -2.7984352111816406
Batch 43/64 loss: -2.6276187896728516
Batch 44/64 loss: -2.6093931198120117
Batch 45/64 loss: -2.3048343658447266
Batch 46/64 loss: -2.710947036743164
Batch 47/64 loss: -2.818817138671875
Batch 48/64 loss: -2.511445999145508
Batch 49/64 loss: -2.960991859436035
Batch 50/64 loss: -2.6475276947021484
Batch 51/64 loss: -2.660501480102539
Batch 52/64 loss: -2.39510440826416
Batch 53/64 loss: -2.6049652099609375
Batch 54/64 loss: -2.871739387512207
Batch 55/64 loss: -2.287853240966797
Batch 56/64 loss: -1.8637866973876953
Batch 57/64 loss: -2.475405693054199
Batch 58/64 loss: -2.6865129470825195
Batch 59/64 loss: -2.6221580505371094
Batch 60/64 loss: -2.0489768981933594
Batch 61/64 loss: -2.1519432067871094
Batch 62/64 loss: -2.791309356689453
Batch 63/64 loss: -2.4182701110839844
Batch 64/64 loss: -7.453546524047852
Epoch 78  Train loss: -2.505957801669252  Val loss: -2.7046205841798554
Epoch 79
-------------------------------
Batch 1/64 loss: -2.5249500274658203
Batch 2/64 loss: -2.8597850799560547
Batch 3/64 loss: -2.589358329772949
Batch 4/64 loss: -2.792494773864746
Batch 5/64 loss: -2.6909828186035156
Batch 6/64 loss: -2.808734893798828
Batch 7/64 loss: -1.8317594528198242
Batch 8/64 loss: -2.8525142669677734
Batch 9/64 loss: -2.4492053985595703
Batch 10/64 loss: -2.582429885864258
Batch 11/64 loss: -2.368483543395996
Batch 12/64 loss: -1.8599185943603516
Batch 13/64 loss: -2.5008935928344727
Batch 14/64 loss: -2.2920541763305664
Batch 15/64 loss: -2.56134033203125
Batch 16/64 loss: -2.206148147583008
Batch 17/64 loss: -2.7058639526367188
Batch 18/64 loss: -2.64762020111084
Batch 19/64 loss: -2.2643604278564453
Batch 20/64 loss: -2.3835906982421875
Batch 21/64 loss: -1.9410772323608398
Batch 22/64 loss: -1.991959571838379
Batch 23/64 loss: -2.4283018112182617
Batch 24/64 loss: -2.5426855087280273
Batch 25/64 loss: -2.542247772216797
Batch 26/64 loss: -2.7433481216430664
Batch 27/64 loss: -2.6725082397460938
Batch 28/64 loss: -2.4542856216430664
Batch 29/64 loss: -2.6304502487182617
Batch 30/64 loss: -2.8543567657470703
Batch 31/64 loss: -2.407883644104004
Batch 32/64 loss: -2.481146812438965
Batch 33/64 loss: -2.6764450073242188
Batch 34/64 loss: -2.181729316711426
Batch 35/64 loss: -2.3166074752807617
Batch 36/64 loss: -2.3688735961914062
Batch 37/64 loss: -2.7299909591674805
Batch 38/64 loss: -2.112095832824707
Batch 39/64 loss: -2.413130760192871
Batch 40/64 loss: -2.611760139465332
Batch 41/64 loss: -2.79117488861084
Batch 42/64 loss: -2.66033935546875
Batch 43/64 loss: -2.538325309753418
Batch 44/64 loss: -2.567183494567871
Batch 45/64 loss: -2.175455093383789
Batch 46/64 loss: -1.961949348449707
Batch 47/64 loss: -2.580653190612793
Batch 48/64 loss: -2.789213180541992
Batch 49/64 loss: -2.5346298217773438
Batch 50/64 loss: -2.707749366760254
Batch 51/64 loss: -2.701608657836914
Batch 52/64 loss: -2.5723676681518555
Batch 53/64 loss: -2.4197235107421875
Batch 54/64 loss: -2.2614669799804688
Batch 55/64 loss: -2.5894594192504883
Batch 56/64 loss: -2.3728647232055664
Batch 57/64 loss: -1.7883691787719727
Batch 58/64 loss: -2.447660446166992
Batch 59/64 loss: -2.4496994018554688
Batch 60/64 loss: -2.540742874145508
Batch 61/64 loss: -2.863938331604004
Batch 62/64 loss: -2.2852001190185547
Batch 63/64 loss: -2.138528823852539
Batch 64/64 loss: -7.286701202392578
Epoch 79  Train loss: -2.5266933665556066  Val loss: -2.6755728574143243
Epoch 80
-------------------------------
Batch 1/64 loss: -2.5434532165527344
Batch 2/64 loss: -2.5131492614746094
Batch 3/64 loss: -2.2219457626342773
Batch 4/64 loss: -2.7083168029785156
Batch 5/64 loss: -2.676236152648926
Batch 6/64 loss: -1.192047119140625
Batch 7/64 loss: -2.462111473083496
Batch 8/64 loss: -2.4888858795166016
Batch 9/64 loss: -2.427915573120117
Batch 10/64 loss: -2.5386581420898438
Batch 11/64 loss: -2.396450996398926
Batch 12/64 loss: -2.4924755096435547
Batch 13/64 loss: -2.430990219116211
Batch 14/64 loss: -1.665353775024414
Batch 15/64 loss: -2.5254297256469727
Batch 16/64 loss: -2.40004825592041
Batch 17/64 loss: -2.4796762466430664
Batch 18/64 loss: -1.975693702697754
Batch 19/64 loss: -2.5887231826782227
Batch 20/64 loss: -2.562882423400879
Batch 21/64 loss: -2.687479019165039
Batch 22/64 loss: -2.3514404296875
Batch 23/64 loss: -2.845150947570801
Batch 24/64 loss: -2.142181396484375
Batch 25/64 loss: -2.834488868713379
Batch 26/64 loss: -2.8295984268188477
Batch 27/64 loss: -2.5786361694335938
Batch 28/64 loss: -2.5053653717041016
Batch 29/64 loss: -2.658627510070801
Batch 30/64 loss: -2.4898509979248047
Batch 31/64 loss: -2.3642587661743164
Batch 32/64 loss: -2.5434646606445312
Batch 33/64 loss: -2.479973793029785
Batch 34/64 loss: -1.9082679748535156
Batch 35/64 loss: -2.654214859008789
Batch 36/64 loss: -2.1245832443237305
Batch 37/64 loss: -2.7006473541259766
Batch 38/64 loss: -2.607637405395508
Batch 39/64 loss: -2.2062149047851562
Batch 40/64 loss: -2.344259262084961
Batch 41/64 loss: -2.278597831726074
Batch 42/64 loss: -2.317490577697754
Batch 43/64 loss: -2.704075813293457
Batch 44/64 loss: -2.5760316848754883
Batch 45/64 loss: -2.738370895385742
Batch 46/64 loss: -2.1077375411987305
Batch 47/64 loss: -2.518482208251953
Batch 48/64 loss: -2.7275733947753906
Batch 49/64 loss: -2.642306327819824
Batch 50/64 loss: -2.527371406555176
Batch 51/64 loss: -2.166637420654297
Batch 52/64 loss: -2.7926673889160156
Batch 53/64 loss: -2.311234474182129
Batch 54/64 loss: -2.653782844543457
Batch 55/64 loss: -2.395754814147949
Batch 56/64 loss: -2.8129472732543945
Batch 57/64 loss: -2.7378015518188477
Batch 58/64 loss: -2.772698402404785
Batch 59/64 loss: -2.183094024658203
Batch 60/64 loss: -1.7011899948120117
Batch 61/64 loss: -2.6753149032592773
Batch 62/64 loss: -2.558551788330078
Batch 63/64 loss: -2.8253908157348633
Batch 64/64 loss: -7.3279128074646
Epoch 80  Train loss: -2.5155736904518275  Val loss: -2.7225256588860476
Epoch 81
-------------------------------
Batch 1/64 loss: -1.9369335174560547
Batch 2/64 loss: -2.351381301879883
Batch 3/64 loss: -2.844710350036621
Batch 4/64 loss: -2.6111888885498047
Batch 5/64 loss: -2.6794395446777344
Batch 6/64 loss: -2.647846221923828
Batch 7/64 loss: -2.82138729095459
Batch 8/64 loss: -2.3371267318725586
Batch 9/64 loss: -2.611143112182617
Batch 10/64 loss: -2.4377670288085938
Batch 11/64 loss: -2.731821060180664
Batch 12/64 loss: -2.301894187927246
Batch 13/64 loss: -2.649778366088867
Batch 14/64 loss: -2.6532201766967773
Batch 15/64 loss: -2.686051368713379
Batch 16/64 loss: -2.5244550704956055
Batch 17/64 loss: -2.869312286376953
Batch 18/64 loss: -2.5703210830688477
Batch 19/64 loss: -2.370912551879883
Batch 20/64 loss: -2.7123031616210938
Batch 21/64 loss: -2.0573558807373047
Batch 22/64 loss: -2.6872129440307617
Batch 23/64 loss: -2.463242530822754
Batch 24/64 loss: -1.8533096313476562
Batch 25/64 loss: -2.3551902770996094
Batch 26/64 loss: -1.8565044403076172
Batch 27/64 loss: -2.6934003829956055
Batch 28/64 loss: -2.796689033508301
Batch 29/64 loss: -2.501932144165039
Batch 30/64 loss: -2.1007328033447266
Batch 31/64 loss: -2.434053421020508
Batch 32/64 loss: -2.4987964630126953
Batch 33/64 loss: -2.814556121826172
Batch 34/64 loss: -2.557572364807129
Batch 35/64 loss: -2.3518152236938477
Batch 36/64 loss: -2.56813907623291
Batch 37/64 loss: -2.3008031845092773
Batch 38/64 loss: -2.503286361694336
Batch 39/64 loss: -2.482823371887207
Batch 40/64 loss: -2.422710418701172
Batch 41/64 loss: -2.514759063720703
Batch 42/64 loss: -2.721867561340332
Batch 43/64 loss: -2.5543832778930664
Batch 44/64 loss: -2.592548370361328
Batch 45/64 loss: -2.497237205505371
Batch 46/64 loss: -2.3325862884521484
Batch 47/64 loss: -2.3673934936523438
Batch 48/64 loss: -2.630847930908203
Batch 49/64 loss: -2.2532119750976562
Batch 50/64 loss: -2.761460304260254
Batch 51/64 loss: -2.5830821990966797
Batch 52/64 loss: -1.4909086227416992
Batch 53/64 loss: -2.502321243286133
Batch 54/64 loss: -2.732304573059082
Batch 55/64 loss: -2.0793323516845703
Batch 56/64 loss: -2.5450868606567383
Batch 57/64 loss: -2.542909622192383
Batch 58/64 loss: -2.666762351989746
Batch 59/64 loss: -2.2918434143066406
Batch 60/64 loss: -2.4769906997680664
Batch 61/64 loss: -2.8531455993652344
Batch 62/64 loss: -1.5766897201538086
Batch 63/64 loss: -2.6417760848999023
Batch 64/64 loss: -7.231247901916504
Epoch 81  Train loss: -2.5299137900857365  Val loss: -2.6573617024110354
Epoch 82
-------------------------------
Batch 1/64 loss: -2.751619338989258
Batch 2/64 loss: -2.5297441482543945
Batch 3/64 loss: -2.5075645446777344
Batch 4/64 loss: -2.717618942260742
Batch 5/64 loss: -2.6273927688598633
Batch 6/64 loss: -2.326422691345215
Batch 7/64 loss: -2.351644515991211
Batch 8/64 loss: -2.552814483642578
Batch 9/64 loss: -2.2177934646606445
Batch 10/64 loss: -2.5016870498657227
Batch 11/64 loss: -2.252913475036621
Batch 12/64 loss: -2.4271631240844727
Batch 13/64 loss: -2.689486503601074
Batch 14/64 loss: -2.2157249450683594
Batch 15/64 loss: -1.9719486236572266
Batch 16/64 loss: -2.6745710372924805
Batch 17/64 loss: -2.661195755004883
Batch 18/64 loss: -2.628622055053711
Batch 19/64 loss: -2.748624801635742
Batch 20/64 loss: -2.5944089889526367
Batch 21/64 loss: -1.4593782424926758
Batch 22/64 loss: -2.6950464248657227
Batch 23/64 loss: -2.7050399780273438
Batch 24/64 loss: -2.1643733978271484
Batch 25/64 loss: -2.451000213623047
Batch 26/64 loss: -2.3183937072753906
Batch 27/64 loss: -2.014312744140625
Batch 28/64 loss: -2.130465507507324
Batch 29/64 loss: -1.9585180282592773
Batch 30/64 loss: -1.8128538131713867
Batch 31/64 loss: -2.4187698364257812
Batch 32/64 loss: -2.2216873168945312
Batch 33/64 loss: -2.314814567565918
Batch 34/64 loss: -2.2864694595336914
Batch 35/64 loss: -2.430919647216797
Batch 36/64 loss: -1.9144115447998047
Batch 37/64 loss: -2.296712875366211
Batch 38/64 loss: -2.3880128860473633
Batch 39/64 loss: -2.569037437438965
Batch 40/64 loss: -2.494826316833496
Batch 41/64 loss: -2.4698915481567383
Batch 42/64 loss: -2.503528594970703
Batch 43/64 loss: -2.425665855407715
Batch 44/64 loss: -2.3387699127197266
Batch 45/64 loss: -2.0848846435546875
Batch 46/64 loss: -2.6153783798217773
Batch 47/64 loss: -2.384248733520508
Batch 48/64 loss: -2.5721750259399414
Batch 49/64 loss: -2.6648902893066406
Batch 50/64 loss: -2.22342586517334
Batch 51/64 loss: -2.1167173385620117
Batch 52/64 loss: -2.53060245513916
Batch 53/64 loss: -1.7980403900146484
Batch 54/64 loss: -1.9232854843139648
Batch 55/64 loss: -2.488644599914551
Batch 56/64 loss: -2.3571300506591797
Batch 57/64 loss: -2.4431276321411133
Batch 58/64 loss: -2.7983341217041016
Batch 59/64 loss: -2.279420852661133
Batch 60/64 loss: -1.438131332397461
Batch 61/64 loss: -2.5132246017456055
Batch 62/64 loss: -2.656496047973633
Batch 63/64 loss: -2.0400819778442383
Batch 64/64 loss: -7.096309661865234
Epoch 82  Train loss: -2.415409147973154  Val loss: -2.6854191416317654
Epoch 83
-------------------------------
Batch 1/64 loss: -2.4228668212890625
Batch 2/64 loss: -2.5265064239501953
Batch 3/64 loss: -2.6970815658569336
Batch 4/64 loss: -2.2398319244384766
Batch 5/64 loss: -2.001995086669922
Batch 6/64 loss: -1.985896110534668
Batch 7/64 loss: -2.479619026184082
Batch 8/64 loss: -2.4516258239746094
Batch 9/64 loss: -2.5314178466796875
Batch 10/64 loss: -2.5400819778442383
Batch 11/64 loss: -2.519428253173828
Batch 12/64 loss: -2.5767641067504883
Batch 13/64 loss: -2.0763378143310547
Batch 14/64 loss: -2.6555423736572266
Batch 15/64 loss: -2.422321319580078
Batch 16/64 loss: -1.715092658996582
Batch 17/64 loss: -2.5520858764648438
Batch 18/64 loss: -2.3886165618896484
Batch 19/64 loss: -2.3003244400024414
Batch 20/64 loss: -2.3723268508911133
Batch 21/64 loss: -2.7274341583251953
Batch 22/64 loss: -2.582056999206543
Batch 23/64 loss: -2.7470836639404297
Batch 24/64 loss: -2.783270835876465
Batch 25/64 loss: -2.7314863204956055
Batch 26/64 loss: -2.069988250732422
Batch 27/64 loss: -2.3970937728881836
Batch 28/64 loss: -2.3207197189331055
Batch 29/64 loss: -2.1833152770996094
Batch 30/64 loss: -2.620088577270508
Batch 31/64 loss: -2.4633617401123047
Batch 32/64 loss: -2.6383581161499023
Batch 33/64 loss: -2.638871192932129
Batch 34/64 loss: -1.8281402587890625
Batch 35/64 loss: -2.0813331604003906
Batch 36/64 loss: -2.707456588745117
Batch 37/64 loss: -3.018312454223633
Batch 38/64 loss: -2.3788223266601562
Batch 39/64 loss: -1.898859977722168
Batch 40/64 loss: -2.4663867950439453
Batch 41/64 loss: -2.2691049575805664
Batch 42/64 loss: -2.5241079330444336
Batch 43/64 loss: -2.4171085357666016
Batch 44/64 loss: -2.6735897064208984
Batch 45/64 loss: -2.3910884857177734
Batch 46/64 loss: -2.416667938232422
Batch 47/64 loss: -2.8914031982421875
Batch 48/64 loss: -2.420355796813965
Batch 49/64 loss: -2.8176002502441406
Batch 50/64 loss: -2.1108999252319336
Batch 51/64 loss: -2.6226282119750977
Batch 52/64 loss: -2.332202911376953
Batch 53/64 loss: -2.4510602951049805
Batch 54/64 loss: -2.7594661712646484
Batch 55/64 loss: -2.397289276123047
Batch 56/64 loss: -2.543349266052246
Batch 57/64 loss: -2.4226322174072266
Batch 58/64 loss: -2.0405168533325195
Batch 59/64 loss: -2.571976661682129
Batch 60/64 loss: -2.301966667175293
Batch 61/64 loss: -2.4595985412597656
Batch 62/64 loss: -2.6997900009155273
Batch 63/64 loss: -2.5193395614624023
Batch 64/64 loss: -7.164259910583496
Epoch 83  Train loss: -2.4967080995148305  Val loss: -2.8204302574760725
Saving best model, epoch: 83
Epoch 84
-------------------------------
Batch 1/64 loss: -2.2689809799194336
Batch 2/64 loss: -2.615255355834961
Batch 3/64 loss: -2.6595821380615234
Batch 4/64 loss: -2.788919448852539
Batch 5/64 loss: -2.1914854049682617
Batch 6/64 loss: -2.396484375
Batch 7/64 loss: -2.338428497314453
Batch 8/64 loss: -2.6335601806640625
Batch 9/64 loss: -2.615182876586914
Batch 10/64 loss: -2.495565414428711
Batch 11/64 loss: -2.646121025085449
Batch 12/64 loss: -2.6787633895874023
Batch 13/64 loss: -2.5954036712646484
Batch 14/64 loss: -2.763895034790039
Batch 15/64 loss: -2.28397274017334
Batch 16/64 loss: -2.093059539794922
Batch 17/64 loss: -2.5713987350463867
Batch 18/64 loss: -2.849696159362793
Batch 19/64 loss: -2.397836685180664
Batch 20/64 loss: -2.578873634338379
Batch 21/64 loss: -2.4948244094848633
Batch 22/64 loss: -2.6439266204833984
Batch 23/64 loss: -1.6151399612426758
Batch 24/64 loss: -2.7679338455200195
Batch 25/64 loss: -2.384282112121582
Batch 26/64 loss: -2.2308425903320312
Batch 27/64 loss: -2.3399295806884766
Batch 28/64 loss: -2.1928186416625977
Batch 29/64 loss: -2.1713953018188477
Batch 30/64 loss: -2.7939977645874023
Batch 31/64 loss: -1.945796012878418
Batch 32/64 loss: -2.812784194946289
Batch 33/64 loss: -2.476095199584961
Batch 34/64 loss: -2.6685047149658203
Batch 35/64 loss: -2.37823486328125
Batch 36/64 loss: -2.600738525390625
Batch 37/64 loss: -2.7330570220947266
Batch 38/64 loss: -2.610383987426758
Batch 39/64 loss: -2.6694726943969727
Batch 40/64 loss: -2.645721435546875
Batch 41/64 loss: -2.9249496459960938
Batch 42/64 loss: -2.757516860961914
Batch 43/64 loss: -2.83062744140625
Batch 44/64 loss: -2.5343427658081055
Batch 45/64 loss: -2.708681106567383
Batch 46/64 loss: -2.7793197631835938
Batch 47/64 loss: -2.741824150085449
Batch 48/64 loss: -2.561727523803711
Batch 49/64 loss: -2.4791460037231445
Batch 50/64 loss: -2.175980567932129
Batch 51/64 loss: -2.2081336975097656
Batch 52/64 loss: -2.4211606979370117
Batch 53/64 loss: -2.665043830871582
Batch 54/64 loss: -2.8721303939819336
Batch 55/64 loss: -2.817768096923828
Batch 56/64 loss: -2.3757190704345703
Batch 57/64 loss: -2.697610855102539
Batch 58/64 loss: -2.320741653442383
Batch 59/64 loss: -2.3922252655029297
Batch 60/64 loss: -2.6071348190307617
Batch 61/64 loss: -2.719104766845703
Batch 62/64 loss: -1.3815946578979492
Batch 63/64 loss: -2.1495676040649414
Batch 64/64 loss: -7.446672439575195
Epoch 84  Train loss: -2.5622807895436006  Val loss: -2.962818945396397
Saving best model, epoch: 84
Epoch 85
-------------------------------
Batch 1/64 loss: -2.5076465606689453
Batch 2/64 loss: -2.4931106567382812
Batch 3/64 loss: -2.8257102966308594
Batch 4/64 loss: -2.4319028854370117
Batch 5/64 loss: -2.588067054748535
Batch 6/64 loss: -2.4774169921875
Batch 7/64 loss: -2.6868810653686523
Batch 8/64 loss: -2.557581901550293
Batch 9/64 loss: -2.269698143005371
Batch 10/64 loss: -2.4922237396240234
Batch 11/64 loss: -2.788784980773926
Batch 12/64 loss: -2.887457847595215
Batch 13/64 loss: -2.639078140258789
Batch 14/64 loss: -2.2663307189941406
Batch 15/64 loss: -2.646470069885254
Batch 16/64 loss: -2.5919857025146484
Batch 17/64 loss: -2.4920501708984375
Batch 18/64 loss: -2.837015151977539
Batch 19/64 loss: -2.907107353210449
Batch 20/64 loss: -2.713383674621582
Batch 21/64 loss: -2.7256479263305664
Batch 22/64 loss: -2.5659265518188477
Batch 23/64 loss: -2.5508317947387695
Batch 24/64 loss: -2.5019474029541016
Batch 25/64 loss: -2.881331443786621
Batch 26/64 loss: -2.6492795944213867
Batch 27/64 loss: -2.521221160888672
Batch 28/64 loss: -2.6701297760009766
Batch 29/64 loss: -2.5509490966796875
Batch 30/64 loss: -2.864975929260254
Batch 31/64 loss: -2.3591861724853516
Batch 32/64 loss: -2.710831642150879
Batch 33/64 loss: -2.5305309295654297
Batch 34/64 loss: -1.8823108673095703
Batch 35/64 loss: -2.6554298400878906
Batch 36/64 loss: -2.7617273330688477
Batch 37/64 loss: -2.5909433364868164
Batch 38/64 loss: -1.8771495819091797
Batch 39/64 loss: -2.4879579544067383
Batch 40/64 loss: -2.3712921142578125
Batch 41/64 loss: -2.3388872146606445
Batch 42/64 loss: -2.739116668701172
Batch 43/64 loss: -2.5955305099487305
Batch 44/64 loss: -2.1884422302246094
Batch 45/64 loss: -2.577540397644043
Batch 46/64 loss: -2.4596595764160156
Batch 47/64 loss: -2.6092653274536133
Batch 48/64 loss: -2.321232795715332
Batch 49/64 loss: -2.6569747924804688
Batch 50/64 loss: -2.573047637939453
Batch 51/64 loss: -2.7456607818603516
Batch 52/64 loss: -2.7042646408081055
Batch 53/64 loss: -1.9265623092651367
Batch 54/64 loss: -2.754939079284668
Batch 55/64 loss: -2.7824296951293945
Batch 56/64 loss: -1.9123210906982422
Batch 57/64 loss: -2.685145378112793
Batch 58/64 loss: -2.875870704650879
Batch 59/64 loss: -2.7834949493408203
Batch 60/64 loss: -2.593660354614258
Batch 61/64 loss: -2.4907121658325195
Batch 62/64 loss: -2.4743175506591797
Batch 63/64 loss: -2.5026168823242188
Batch 64/64 loss: -7.476672172546387
Epoch 85  Train loss: -2.6150384379368203  Val loss: -2.80888628877725
Epoch 86
-------------------------------
Batch 1/64 loss: -2.90053653717041
Batch 2/64 loss: -2.733457565307617
Batch 3/64 loss: -2.395641326904297
Batch 4/64 loss: -2.8314342498779297
Batch 5/64 loss: -2.8793516159057617
Batch 6/64 loss: -2.6944541931152344
Batch 7/64 loss: -2.6411705017089844
Batch 8/64 loss: -2.204418182373047
Batch 9/64 loss: -2.4734926223754883
Batch 10/64 loss: -2.4424476623535156
Batch 11/64 loss: -2.8751869201660156
Batch 12/64 loss: -2.6910476684570312
Batch 13/64 loss: -2.762698173522949
Batch 14/64 loss: -2.5326642990112305
Batch 15/64 loss: -2.284092903137207
Batch 16/64 loss: -2.408869743347168
Batch 17/64 loss: -2.7177934646606445
Batch 18/64 loss: -2.563283920288086
Batch 19/64 loss: -2.382661819458008
Batch 20/64 loss: -2.6384763717651367
Batch 21/64 loss: -2.8915672302246094
Batch 22/64 loss: -2.5036678314208984
Batch 23/64 loss: -2.1539831161499023
Batch 24/64 loss: -2.9572067260742188
Batch 25/64 loss: -2.8705692291259766
Batch 26/64 loss: -2.533473014831543
Batch 27/64 loss: -2.566873550415039
Batch 28/64 loss: -2.038151741027832
Batch 29/64 loss: -2.2033777236938477
Batch 30/64 loss: -2.687541961669922
Batch 31/64 loss: -2.5428333282470703
Batch 32/64 loss: -2.454564094543457
Batch 33/64 loss: -2.477494239807129
Batch 34/64 loss: -2.697216033935547
Batch 35/64 loss: -2.339986801147461
Batch 36/64 loss: -2.3363265991210938
Batch 37/64 loss: -2.2768173217773438
Batch 38/64 loss: -1.7546043395996094
Batch 39/64 loss: -2.1806697845458984
Batch 40/64 loss: -2.335963249206543
Batch 41/64 loss: -2.57828426361084
Batch 42/64 loss: -2.7322731018066406
Batch 43/64 loss: -2.3613853454589844
Batch 44/64 loss: -2.1993675231933594
Batch 45/64 loss: -1.794900894165039
Batch 46/64 loss: -2.5415000915527344
Batch 47/64 loss: -2.2749757766723633
Batch 48/64 loss: -2.266948699951172
Batch 49/64 loss: -2.5662384033203125
Batch 50/64 loss: -2.3908653259277344
Batch 51/64 loss: -2.620173454284668
Batch 52/64 loss: -2.520587921142578
Batch 53/64 loss: -2.7784547805786133
Batch 54/64 loss: -2.7176055908203125
Batch 55/64 loss: -2.706758499145508
Batch 56/64 loss: -2.4160356521606445
Batch 57/64 loss: -1.609623908996582
Batch 58/64 loss: -2.763896942138672
Batch 59/64 loss: -2.6491079330444336
Batch 60/64 loss: -1.5230703353881836
Batch 61/64 loss: -2.459958076477051
Batch 62/64 loss: -2.867563247680664
Batch 63/64 loss: -2.1438417434692383
Batch 64/64 loss: -7.261247634887695
Epoch 86  Train loss: -2.5378105238372206  Val loss: -2.4361805604495546
Epoch 87
-------------------------------
Batch 1/64 loss: -1.6812200546264648
Batch 2/64 loss: -2.4685401916503906
Batch 3/64 loss: -2.7508955001831055
Batch 4/64 loss: -2.2622737884521484
Batch 5/64 loss: -2.260195732116699
Batch 6/64 loss: -2.5309810638427734
Batch 7/64 loss: -2.5809459686279297
Batch 8/64 loss: -2.3006763458251953
Batch 9/64 loss: -2.309663772583008
Batch 10/64 loss: -2.175408363342285
Batch 11/64 loss: -2.090038299560547
Batch 12/64 loss: -2.10884952545166
Batch 13/64 loss: -2.3100528717041016
Batch 14/64 loss: -2.4137353897094727
Batch 15/64 loss: -2.276456832885742
Batch 16/64 loss: -2.169875144958496
Batch 17/64 loss: -2.3452367782592773
Batch 18/64 loss: -2.3406009674072266
Batch 19/64 loss: -1.8061952590942383
Batch 20/64 loss: -2.7185468673706055
Batch 21/64 loss: -2.254275321960449
Batch 22/64 loss: -2.5914907455444336
Batch 23/64 loss: -2.2269983291625977
Batch 24/64 loss: -2.7431468963623047
Batch 25/64 loss: -2.2505950927734375
Batch 26/64 loss: -2.6948165893554688
Batch 27/64 loss: -2.3596725463867188
Batch 28/64 loss: -2.0691843032836914
Batch 29/64 loss: -1.5315723419189453
Batch 30/64 loss: -2.7727270126342773
Batch 31/64 loss: -2.6228227615356445
Batch 32/64 loss: -2.215691566467285
Batch 33/64 loss: -2.415513038635254
Batch 34/64 loss: -2.1915435791015625
Batch 35/64 loss: -2.712984085083008
Batch 36/64 loss: -2.021543502807617
Batch 37/64 loss: -2.3186655044555664
Batch 38/64 loss: -2.425309181213379
Batch 39/64 loss: -2.456362724304199
Batch 40/64 loss: -2.6403255462646484
Batch 41/64 loss: -2.7077255249023438
Batch 42/64 loss: -2.7475709915161133
Batch 43/64 loss: -2.7619333267211914
Batch 44/64 loss: -2.7495126724243164
Batch 45/64 loss: -2.351663589477539
Batch 46/64 loss: -2.2229108810424805
Batch 47/64 loss: -2.166998863220215
Batch 48/64 loss: -2.5994768142700195
Batch 49/64 loss: -2.7070016860961914
Batch 50/64 loss: -2.6227779388427734
Batch 51/64 loss: -2.5121097564697266
Batch 52/64 loss: -1.9893875122070312
Batch 53/64 loss: -2.6386213302612305
Batch 54/64 loss: -2.738955497741699
Batch 55/64 loss: -2.750955581665039
Batch 56/64 loss: -2.7598791122436523
Batch 57/64 loss: -2.435152053833008
Batch 58/64 loss: -2.8959779739379883
Batch 59/64 loss: -2.5782203674316406
Batch 60/64 loss: -2.715383529663086
Batch 61/64 loss: -2.7548084259033203
Batch 62/64 loss: -2.38815975189209
Batch 63/64 loss: -2.4602584838867188
Batch 64/64 loss: -7.162282943725586
Epoch 87  Train loss: -2.479102482515223  Val loss: -2.776487068621973
Epoch 88
-------------------------------
Batch 1/64 loss: -2.16005802154541
Batch 2/64 loss: -2.711454391479492
Batch 3/64 loss: -2.6647777557373047
Batch 4/64 loss: -2.7870426177978516
Batch 5/64 loss: -2.476083755493164
Batch 6/64 loss: -2.6442947387695312
Batch 7/64 loss: -2.653860092163086
Batch 8/64 loss: -2.9079761505126953
Batch 9/64 loss: -3.0019149780273438
Batch 10/64 loss: -2.5958328247070312
Batch 11/64 loss: -2.123769760131836
Batch 12/64 loss: -2.042591094970703
Batch 13/64 loss: -2.626300811767578
Batch 14/64 loss: -2.2742958068847656
Batch 15/64 loss: -2.9181318283081055
Batch 16/64 loss: -2.7172794342041016
Batch 17/64 loss: -2.1792192459106445
Batch 18/64 loss: -2.385542869567871
Batch 19/64 loss: -2.498227119445801
Batch 20/64 loss: -2.2826452255249023
Batch 21/64 loss: -2.6809282302856445
Batch 22/64 loss: -2.050851821899414
Batch 23/64 loss: -2.8962650299072266
Batch 24/64 loss: -2.1264419555664062
Batch 25/64 loss: -1.7059125900268555
Batch 26/64 loss: -2.8264360427856445
Batch 27/64 loss: -2.659942626953125
Batch 28/64 loss: -2.55728816986084
Batch 29/64 loss: -2.7815370559692383
Batch 30/64 loss: -2.7160634994506836
Batch 31/64 loss: -2.3377647399902344
Batch 32/64 loss: -2.6038713455200195
Batch 33/64 loss: -2.712076187133789
Batch 34/64 loss: -2.779778480529785
Batch 35/64 loss: -2.8197193145751953
Batch 36/64 loss: -2.7941341400146484
Batch 37/64 loss: -2.659393310546875
Batch 38/64 loss: -2.7698450088500977
Batch 39/64 loss: -2.374203681945801
Batch 40/64 loss: -2.2255687713623047
Batch 41/64 loss: -2.782425880432129
Batch 42/64 loss: -2.530085563659668
Batch 43/64 loss: -2.628103256225586
Batch 44/64 loss: -2.5940933227539062
Batch 45/64 loss: -2.404481887817383
Batch 46/64 loss: -2.6650514602661133
Batch 47/64 loss: -2.43564510345459
Batch 48/64 loss: -2.3158206939697266
Batch 49/64 loss: -2.372875213623047
Batch 50/64 loss: -2.4015846252441406
Batch 51/64 loss: -2.538888931274414
Batch 52/64 loss: -2.1119089126586914
Batch 53/64 loss: -2.776869773864746
Batch 54/64 loss: -2.047758102416992
Batch 55/64 loss: -2.586700439453125
Batch 56/64 loss: -2.26483154296875
Batch 57/64 loss: -2.2791919708251953
Batch 58/64 loss: -2.5936899185180664
Batch 59/64 loss: -2.8301992416381836
Batch 60/64 loss: -2.2583208084106445
Batch 61/64 loss: -2.6103553771972656
Batch 62/64 loss: -2.5941991806030273
Batch 63/64 loss: -2.3245115280151367
Batch 64/64 loss: -7.3554863929748535
Epoch 88  Train loss: -2.575584753821878  Val loss: -2.6586350640890113
Epoch 89
-------------------------------
Batch 1/64 loss: -2.545564651489258
Batch 2/64 loss: -2.566255569458008
Batch 3/64 loss: -2.754518508911133
Batch 4/64 loss: -2.7768726348876953
Batch 5/64 loss: -2.1010875701904297
Batch 6/64 loss: -2.6482086181640625
Batch 7/64 loss: -2.4841699600219727
Batch 8/64 loss: -1.6558456420898438
Batch 9/64 loss: -2.582707405090332
Batch 10/64 loss: -2.6447010040283203
Batch 11/64 loss: -2.2870616912841797
Batch 12/64 loss: -2.567424774169922
Batch 13/64 loss: -2.7202043533325195
Batch 14/64 loss: -2.256758689880371
Batch 15/64 loss: -2.6391210556030273
Batch 16/64 loss: -1.9066524505615234
Batch 17/64 loss: -2.7684812545776367
Batch 18/64 loss: -2.6150054931640625
Batch 19/64 loss: -2.661360740661621
Batch 20/64 loss: -2.724980354309082
Batch 21/64 loss: -2.619706153869629
Batch 22/64 loss: -2.512221336364746
Batch 23/64 loss: -2.7770299911499023
Batch 24/64 loss: -2.7614946365356445
Batch 25/64 loss: -2.43430233001709
Batch 26/64 loss: -2.754880905151367
Batch 27/64 loss: -2.898188591003418
Batch 28/64 loss: -2.8090620040893555
Batch 29/64 loss: -2.5430822372436523
Batch 30/64 loss: -2.6075620651245117
Batch 31/64 loss: -2.7763519287109375
Batch 32/64 loss: -2.529844284057617
Batch 33/64 loss: -2.5182905197143555
Batch 34/64 loss: -2.652191162109375
Batch 35/64 loss: -3.134169578552246
Batch 36/64 loss: -2.5493221282958984
Batch 37/64 loss: -2.5684070587158203
Batch 38/64 loss: -3.02010440826416
Batch 39/64 loss: -2.3083229064941406
Batch 40/64 loss: -2.5220746994018555
Batch 41/64 loss: -2.7514610290527344
Batch 42/64 loss: -2.3342714309692383
Batch 43/64 loss: -2.5548925399780273
Batch 44/64 loss: -2.5152711868286133
Batch 45/64 loss: -2.654024124145508
Batch 46/64 loss: -2.5142459869384766
Batch 47/64 loss: -2.6140851974487305
Batch 48/64 loss: -2.6304521560668945
Batch 49/64 loss: -2.862628936767578
Batch 50/64 loss: -2.908596992492676
Batch 51/64 loss: -2.7398061752319336
Batch 52/64 loss: -2.858549118041992
Batch 53/64 loss: -2.431962013244629
Batch 54/64 loss: -2.4574060440063477
Batch 55/64 loss: -2.3510665893554688
Batch 56/64 loss: -2.519784927368164
Batch 57/64 loss: -2.718799591064453
Batch 58/64 loss: -2.4967870712280273
Batch 59/64 loss: -1.917083740234375
Batch 60/64 loss: -2.389193534851074
Batch 61/64 loss: -3.0467567443847656
Batch 62/64 loss: -2.72727108001709
Batch 63/64 loss: -2.6349706649780273
Batch 64/64 loss: -7.311595916748047
Epoch 89  Train loss: -2.6402612573960247  Val loss: -2.6136550772231057
Epoch 90
-------------------------------
Batch 1/64 loss: -2.6995887756347656
Batch 2/64 loss: -1.9419403076171875
Batch 3/64 loss: -2.7136945724487305
Batch 4/64 loss: -2.4504032135009766
Batch 5/64 loss: -2.278550148010254
Batch 6/64 loss: -2.307469367980957
Batch 7/64 loss: -1.9656105041503906
Batch 8/64 loss: -2.1282291412353516
Batch 9/64 loss: -2.6608409881591797
Batch 10/64 loss: -2.4966230392456055
Batch 11/64 loss: -2.6130847930908203
Batch 12/64 loss: -2.776881217956543
Batch 13/64 loss: -2.787844657897949
Batch 14/64 loss: -2.9604921340942383
Batch 15/64 loss: -2.751002311706543
Batch 16/64 loss: -2.6346168518066406
Batch 17/64 loss: -2.5546178817749023
Batch 18/64 loss: -2.134654998779297
Batch 19/64 loss: -2.2962160110473633
Batch 20/64 loss: -2.5140981674194336
Batch 21/64 loss: -2.8790597915649414
Batch 22/64 loss: -2.7280330657958984
Batch 23/64 loss: -2.575167655944824
Batch 24/64 loss: -2.769866943359375
Batch 25/64 loss: -2.5325927734375
Batch 26/64 loss: -2.7628355026245117
Batch 27/64 loss: -2.9001379013061523
Batch 28/64 loss: -2.4728469848632812
Batch 29/64 loss: -2.091233253479004
Batch 30/64 loss: -2.816134452819824
Batch 31/64 loss: -2.5303544998168945
Batch 32/64 loss: -2.6730117797851562
Batch 33/64 loss: -2.98046875
Batch 34/64 loss: -2.8485727310180664
Batch 35/64 loss: -2.3207197189331055
Batch 36/64 loss: -2.7185277938842773
Batch 37/64 loss: -2.417888641357422
Batch 38/64 loss: -2.3426647186279297
Batch 39/64 loss: -2.748387336730957
Batch 40/64 loss: -2.8988208770751953
Batch 41/64 loss: -2.833477020263672
Batch 42/64 loss: -1.921051025390625
Batch 43/64 loss: -2.5252294540405273
Batch 44/64 loss: -2.633477210998535
Batch 45/64 loss: -2.5067014694213867
Batch 46/64 loss: -2.6890296936035156
Batch 47/64 loss: -2.8841476440429688
Batch 48/64 loss: -2.748906135559082
Batch 49/64 loss: -2.3408069610595703
Batch 50/64 loss: -2.3774919509887695
Batch 51/64 loss: -2.7879562377929688
Batch 52/64 loss: -2.5534162521362305
Batch 53/64 loss: -2.428338050842285
Batch 54/64 loss: -2.875950813293457
Batch 55/64 loss: -2.811110496520996
Batch 56/64 loss: -2.4096717834472656
Batch 57/64 loss: -2.6996049880981445
Batch 58/64 loss: -2.5878639221191406
Batch 59/64 loss: -2.7232284545898438
Batch 60/64 loss: -2.4452877044677734
Batch 61/64 loss: -1.5201034545898438
Batch 62/64 loss: -2.5778703689575195
Batch 63/64 loss: -2.672178268432617
Batch 64/64 loss: -7.496401786804199
Epoch 90  Train loss: -2.6172389797135893  Val loss: -2.7857069821701836
Epoch 91
-------------------------------
Batch 1/64 loss: -2.8043603897094727
Batch 2/64 loss: -2.7586545944213867
Batch 3/64 loss: -2.477499008178711
Batch 4/64 loss: -2.82773494720459
Batch 5/64 loss: -2.6601743698120117
Batch 6/64 loss: -2.8092803955078125
Batch 7/64 loss: -1.390528678894043
Batch 8/64 loss: -2.7240562438964844
Batch 9/64 loss: -2.503629684448242
Batch 10/64 loss: -2.3751468658447266
Batch 11/64 loss: -2.625664710998535
Batch 12/64 loss: -2.5616512298583984
Batch 13/64 loss: -2.021613121032715
Batch 14/64 loss: -2.3746299743652344
Batch 15/64 loss: -2.852543830871582
Batch 16/64 loss: -2.267873764038086
Batch 17/64 loss: -2.7670717239379883
Batch 18/64 loss: -2.625551223754883
Batch 19/64 loss: -2.8253469467163086
Batch 20/64 loss: -2.5507850646972656
Batch 21/64 loss: -2.608231544494629
Batch 22/64 loss: -2.4253711700439453
Batch 23/64 loss: -2.6941452026367188
Batch 24/64 loss: -2.0868358612060547
Batch 25/64 loss: -2.7204885482788086
Batch 26/64 loss: -2.0006589889526367
Batch 27/64 loss: -2.6022138595581055
Batch 28/64 loss: -2.8510608673095703
Batch 29/64 loss: -2.847226142883301
Batch 30/64 loss: -2.36309814453125
Batch 31/64 loss: -2.6649656295776367
Batch 32/64 loss: -2.894632339477539
Batch 33/64 loss: -2.7697219848632812
Batch 34/64 loss: -2.667830467224121
Batch 35/64 loss: -2.055959701538086
Batch 36/64 loss: -2.5273332595825195
Batch 37/64 loss: -2.6283578872680664
Batch 38/64 loss: -2.6195526123046875
Batch 39/64 loss: -1.2462444305419922
Batch 40/64 loss: -3.007251739501953
Batch 41/64 loss: -2.7729930877685547
Batch 42/64 loss: -2.9695234298706055
Batch 43/64 loss: -2.940450668334961
Batch 44/64 loss: -1.619135856628418
Batch 45/64 loss: -2.575324058532715
Batch 46/64 loss: -2.122767448425293
Batch 47/64 loss: -2.5844812393188477
Batch 48/64 loss: -2.382810592651367
Batch 49/64 loss: -2.046206474304199
Batch 50/64 loss: -2.0107927322387695
Batch 51/64 loss: -2.7994441986083984
Batch 52/64 loss: -2.526021957397461
Batch 53/64 loss: -2.642338752746582
Batch 54/64 loss: -2.753824234008789
Batch 55/64 loss: -2.711301803588867
Batch 56/64 loss: -2.0008697509765625
Batch 57/64 loss: -2.5610122680664062
Batch 58/64 loss: -2.2825660705566406
Batch 59/64 loss: -2.748779296875
Batch 60/64 loss: -2.5645666122436523
Batch 61/64 loss: -2.86238956451416
Batch 62/64 loss: -2.1705236434936523
Batch 63/64 loss: -2.6261167526245117
Batch 64/64 loss: -7.5505805015563965
Epoch 91  Train loss: -2.5728965179592955  Val loss: -2.8330064884985435
Epoch 92
-------------------------------
Batch 1/64 loss: -2.5595130920410156
Batch 2/64 loss: -2.36226749420166
Batch 3/64 loss: -2.881296157836914
Batch 4/64 loss: -2.536837577819824
Batch 5/64 loss: -2.657259941101074
Batch 6/64 loss: -2.252248764038086
Batch 7/64 loss: -2.4527769088745117
Batch 8/64 loss: -2.947781562805176
Batch 9/64 loss: -2.697347640991211
Batch 10/64 loss: -2.13092041015625
Batch 11/64 loss: -2.819784164428711
Batch 12/64 loss: -2.578289031982422
Batch 13/64 loss: -2.5767059326171875
Batch 14/64 loss: -2.544650077819824
Batch 15/64 loss: -2.9777956008911133
Batch 16/64 loss: -1.4891958236694336
Batch 17/64 loss: -2.470208168029785
Batch 18/64 loss: -2.641641616821289
Batch 19/64 loss: -2.407258987426758
Batch 20/64 loss: -2.669342041015625
Batch 21/64 loss: -2.4464550018310547
Batch 22/64 loss: -2.6588821411132812
Batch 23/64 loss: -2.6595840454101562
Batch 24/64 loss: -2.889629364013672
Batch 25/64 loss: -2.0022544860839844
Batch 26/64 loss: -2.776876449584961
Batch 27/64 loss: -2.7634668350219727
Batch 28/64 loss: -2.095611572265625
Batch 29/64 loss: -2.37420654296875
Batch 30/64 loss: -2.640535354614258
Batch 31/64 loss: -2.349010467529297
Batch 32/64 loss: -2.3158302307128906
Batch 33/64 loss: -2.0761289596557617
Batch 34/64 loss: -2.3907432556152344
Batch 35/64 loss: -2.886256217956543
Batch 36/64 loss: -2.0374059677124023
Batch 37/64 loss: -2.845583915710449
Batch 38/64 loss: -0.8826408386230469
Batch 39/64 loss: -2.84084415435791
Batch 40/64 loss: -2.344066619873047
Batch 41/64 loss: -2.886183738708496
Batch 42/64 loss: -1.885152816772461
Batch 43/64 loss: -2.6960248947143555
Batch 44/64 loss: -2.6133670806884766
Batch 45/64 loss: -2.70004940032959
Batch 46/64 loss: -2.49794864654541
Batch 47/64 loss: -2.233572006225586
Batch 48/64 loss: -2.8038511276245117
Batch 49/64 loss: -2.8145837783813477
Batch 50/64 loss: -2.321290969848633
Batch 51/64 loss: -2.4530982971191406
Batch 52/64 loss: -2.858382225036621
Batch 53/64 loss: -2.469967842102051
Batch 54/64 loss: -2.7163190841674805
Batch 55/64 loss: -2.3801651000976562
Batch 56/64 loss: -2.6732683181762695
Batch 57/64 loss: -1.3696861267089844
Batch 58/64 loss: -2.1796159744262695
Batch 59/64 loss: -2.73343563079834
Batch 60/64 loss: -2.1331090927124023
Batch 61/64 loss: -2.257063865661621
Batch 62/64 loss: -2.3114194869995117
Batch 63/64 loss: -2.9124908447265625
Batch 64/64 loss: -6.856261253356934
Epoch 92  Train loss: -2.525041187510771  Val loss: -2.6571826869269826
Epoch 93
-------------------------------
Batch 1/64 loss: -2.373713493347168
Batch 2/64 loss: -2.367115020751953
Batch 3/64 loss: -2.039261817932129
Batch 4/64 loss: -2.3442134857177734
Batch 5/64 loss: -2.729846954345703
Batch 6/64 loss: -2.575155258178711
Batch 7/64 loss: -2.6755666732788086
Batch 8/64 loss: -2.7606773376464844
Batch 9/64 loss: -2.410824775695801
Batch 10/64 loss: -2.5445098876953125
Batch 11/64 loss: -2.5307531356811523
Batch 12/64 loss: -2.742154121398926
Batch 13/64 loss: -2.274744987487793
Batch 14/64 loss: -2.281682014465332
Batch 15/64 loss: -2.5352087020874023
Batch 16/64 loss: -2.7746877670288086
Batch 17/64 loss: -2.0779638290405273
Batch 18/64 loss: -2.653045654296875
Batch 19/64 loss: -2.6251468658447266
Batch 20/64 loss: -2.681396484375
Batch 21/64 loss: -2.3809938430786133
Batch 22/64 loss: -2.2677059173583984
Batch 23/64 loss: -2.6942367553710938
Batch 24/64 loss: -2.4356536865234375
Batch 25/64 loss: -2.4965696334838867
Batch 26/64 loss: -2.5122880935668945
Batch 27/64 loss: -2.4300079345703125
Batch 28/64 loss: -2.465078353881836
Batch 29/64 loss: -2.8026208877563477
Batch 30/64 loss: -2.3992300033569336
Batch 31/64 loss: -2.8949079513549805
Batch 32/64 loss: -2.3153505325317383
Batch 33/64 loss: -2.89821720123291
Batch 34/64 loss: -2.9126358032226562
Batch 35/64 loss: -2.8686046600341797
Batch 36/64 loss: -2.826321601867676
Batch 37/64 loss: -2.7228317260742188
Batch 38/64 loss: -2.565469741821289
Batch 39/64 loss: -2.211491584777832
Batch 40/64 loss: -2.8892908096313477
Batch 41/64 loss: -2.039431571960449
Batch 42/64 loss: -1.8964385986328125
Batch 43/64 loss: -2.2309961318969727
Batch 44/64 loss: -2.638566017150879
Batch 45/64 loss: -2.5464372634887695
Batch 46/64 loss: -2.4808149337768555
Batch 47/64 loss: -2.7412939071655273
Batch 48/64 loss: -2.2740440368652344
Batch 49/64 loss: -2.7117843627929688
Batch 50/64 loss: -2.6212358474731445
Batch 51/64 loss: -2.454440116882324
Batch 52/64 loss: -2.704984664916992
Batch 53/64 loss: -2.7201967239379883
Batch 54/64 loss: -2.751650810241699
Batch 55/64 loss: -2.2422828674316406
Batch 56/64 loss: -2.7780075073242188
Batch 57/64 loss: -2.9770097732543945
Batch 58/64 loss: -1.8459501266479492
Batch 59/64 loss: -1.9986238479614258
Batch 60/64 loss: -2.606416702270508
Batch 61/64 loss: -2.7074337005615234
Batch 62/64 loss: -2.2521543502807617
Batch 63/64 loss: -1.6854352951049805
Batch 64/64 loss: -6.785150527954102
Epoch 93  Train loss: -2.556575169282801  Val loss: -2.5199990944354393
Epoch 94
-------------------------------
Batch 1/64 loss: -2.661527633666992
Batch 2/64 loss: -2.2380552291870117
Batch 3/64 loss: -2.4257659912109375
Batch 4/64 loss: -2.472964286804199
Batch 5/64 loss: -2.167379379272461
Batch 6/64 loss: -2.5460205078125
Batch 7/64 loss: -2.5613813400268555
Batch 8/64 loss: -2.6863059997558594
Batch 9/64 loss: -2.9055843353271484
Batch 10/64 loss: -2.7545900344848633
Batch 11/64 loss: -2.768526077270508
Batch 12/64 loss: -2.3791685104370117
Batch 13/64 loss: -2.4091501235961914
Batch 14/64 loss: -2.4856033325195312
Batch 15/64 loss: -2.5703325271606445
Batch 16/64 loss: -2.3291168212890625
Batch 17/64 loss: -2.725421905517578
Batch 18/64 loss: -2.665456771850586
Batch 19/64 loss: -2.1432065963745117
Batch 20/64 loss: -2.788267135620117
Batch 21/64 loss: -2.341292381286621
Batch 22/64 loss: -2.625537872314453
Batch 23/64 loss: -2.692591667175293
Batch 24/64 loss: -2.879603385925293
Batch 25/64 loss: -1.9448156356811523
Batch 26/64 loss: -2.130436897277832
Batch 27/64 loss: -2.7203407287597656
Batch 28/64 loss: -2.7536020278930664
Batch 29/64 loss: -2.5394811630249023
Batch 30/64 loss: -2.161844253540039
Batch 31/64 loss: -2.8000364303588867
Batch 32/64 loss: -2.4065980911254883
Batch 33/64 loss: -2.6816301345825195
Batch 34/64 loss: -2.368989944458008
Batch 35/64 loss: -2.728947639465332
Batch 36/64 loss: -2.859602928161621
Batch 37/64 loss: -2.7258481979370117
Batch 38/64 loss: -2.3911895751953125
Batch 39/64 loss: -2.8666563034057617
Batch 40/64 loss: -2.8606033325195312
Batch 41/64 loss: -2.827019691467285
Batch 42/64 loss: -2.663853645324707
Batch 43/64 loss: -2.503293991088867
Batch 44/64 loss: -2.108358383178711
Batch 45/64 loss: -2.7371912002563477
Batch 46/64 loss: -2.233706474304199
Batch 47/64 loss: -2.7483301162719727
Batch 48/64 loss: -1.3413152694702148
Batch 49/64 loss: -2.5743885040283203
Batch 50/64 loss: -2.5274152755737305
Batch 51/64 loss: -2.046262741088867
Batch 52/64 loss: -2.579829216003418
Batch 53/64 loss: -2.6339426040649414
Batch 54/64 loss: -1.633955955505371
Batch 55/64 loss: -2.267745018005371
Batch 56/64 loss: -2.234792709350586
Batch 57/64 loss: -2.5818309783935547
Batch 58/64 loss: -2.7238645553588867
Batch 59/64 loss: -2.704652786254883
Batch 60/64 loss: -1.6304149627685547
Batch 61/64 loss: -2.827885627746582
Batch 62/64 loss: -2.004950523376465
Batch 63/64 loss: -2.008662223815918
Batch 64/64 loss: -7.389804363250732
Epoch 94  Train loss: -2.5388155114416984  Val loss: -2.6719718225223503
Epoch 95
-------------------------------
Batch 1/64 loss: -1.9820899963378906
Batch 2/64 loss: -2.4545536041259766
Batch 3/64 loss: -2.644418716430664
Batch 4/64 loss: -2.4781360626220703
Batch 5/64 loss: -2.531702995300293
Batch 6/64 loss: -2.769010543823242
Batch 7/64 loss: -2.213775634765625
Batch 8/64 loss: -2.5654354095458984
Batch 9/64 loss: -2.462675094604492
Batch 10/64 loss: -2.5398197174072266
Batch 11/64 loss: -2.575728416442871
Batch 12/64 loss: -2.3109636306762695
Batch 13/64 loss: -2.258157730102539
Batch 14/64 loss: -2.3505258560180664
Batch 15/64 loss: -2.8888635635375977
Batch 16/64 loss: -2.6147994995117188
Batch 17/64 loss: -2.537835121154785
Batch 18/64 loss: -2.4019336700439453
Batch 19/64 loss: -2.5615482330322266
Batch 20/64 loss: -2.689253807067871
Batch 21/64 loss: -2.5988311767578125
Batch 22/64 loss: -2.2718896865844727
Batch 23/64 loss: -2.4865055084228516
Batch 24/64 loss: -2.690201759338379
Batch 25/64 loss: -2.525266647338867
Batch 26/64 loss: -1.986647605895996
Batch 27/64 loss: -2.9117555618286133
Batch 28/64 loss: -2.145681381225586
Batch 29/64 loss: -2.6732168197631836
Batch 30/64 loss: -2.863051414489746
Batch 31/64 loss: -2.510128974914551
Batch 32/64 loss: -2.2209367752075195
Batch 33/64 loss: -2.891177177429199
Batch 34/64 loss: -2.35286808013916
Batch 35/64 loss: -2.513967514038086
Batch 36/64 loss: -2.856846809387207
Batch 37/64 loss: -1.9425086975097656
Batch 38/64 loss: -2.737765312194824
Batch 39/64 loss: -2.5234031677246094
Batch 40/64 loss: -2.788876533508301
Batch 41/64 loss: -2.4493579864501953
Batch 42/64 loss: -2.525393486022949
Batch 43/64 loss: -2.577855110168457
Batch 44/64 loss: -2.761920928955078
Batch 45/64 loss: -2.712495803833008
Batch 46/64 loss: -2.2923107147216797
Batch 47/64 loss: -1.629908561706543
Batch 48/64 loss: -2.99825382232666
Batch 49/64 loss: -2.788562774658203
Batch 50/64 loss: -2.9349002838134766
Batch 51/64 loss: -2.6616439819335938
Batch 52/64 loss: -2.764418601989746
Batch 53/64 loss: -2.794971466064453
Batch 54/64 loss: -2.6431798934936523
Batch 55/64 loss: -2.284306526184082
Batch 56/64 loss: -2.08758544921875
Batch 57/64 loss: -2.1141157150268555
Batch 58/64 loss: -1.9955291748046875
Batch 59/64 loss: -2.6125659942626953
Batch 60/64 loss: -2.1939830780029297
Batch 61/64 loss: -2.640082359313965
Batch 62/64 loss: -2.761859893798828
Batch 63/64 loss: -2.769106864929199
Batch 64/64 loss: -7.302941799163818
Epoch 95  Train loss: -2.5693218623890597  Val loss: -2.8968219822624706
Epoch 96
-------------------------------
Batch 1/64 loss: -2.1784229278564453
Batch 2/64 loss: -2.9055728912353516
Batch 3/64 loss: -2.2912769317626953
Batch 4/64 loss: -2.952117919921875
Batch 5/64 loss: -2.3641462326049805
Batch 6/64 loss: -2.5265274047851562
Batch 7/64 loss: -2.6965150833129883
Batch 8/64 loss: -2.0871734619140625
Batch 9/64 loss: -2.8408260345458984
Batch 10/64 loss: -2.654242515563965
Batch 11/64 loss: -2.6994476318359375
Batch 12/64 loss: -2.24066162109375
Batch 13/64 loss: -2.8264360427856445
Batch 14/64 loss: -2.801405906677246
Batch 15/64 loss: -2.2059335708618164
Batch 16/64 loss: -2.462477684020996
Batch 17/64 loss: -2.75388240814209
Batch 18/64 loss: -2.803624153137207
Batch 19/64 loss: -2.784104347229004
Batch 20/64 loss: -2.7074337005615234
Batch 21/64 loss: -2.3654184341430664
Batch 22/64 loss: -2.6577014923095703
Batch 23/64 loss: -2.977313995361328
Batch 24/64 loss: -2.688143730163574
Batch 25/64 loss: -2.7132606506347656
Batch 26/64 loss: -2.705122947692871
Batch 27/64 loss: -2.867550849914551
Batch 28/64 loss: -2.7032032012939453
Batch 29/64 loss: -1.5117912292480469
Batch 30/64 loss: -2.7013816833496094
Batch 31/64 loss: -2.688847541809082
Batch 32/64 loss: -2.8354549407958984
Batch 33/64 loss: -2.447908401489258
Batch 34/64 loss: -2.564242362976074
Batch 35/64 loss: -2.60500431060791
Batch 36/64 loss: -2.853170394897461
Batch 37/64 loss: -2.6925172805786133
Batch 38/64 loss: -2.2947378158569336
Batch 39/64 loss: -2.6080923080444336
Batch 40/64 loss: -2.073284149169922
Batch 41/64 loss: -2.878927230834961
Batch 42/64 loss: -2.182623863220215
Batch 43/64 loss: -2.7908382415771484
Batch 44/64 loss: -2.3067283630371094
Batch 45/64 loss: -2.281248092651367
Batch 46/64 loss: -2.2856950759887695
Batch 47/64 loss: -2.741811752319336
Batch 48/64 loss: -2.7754669189453125
Batch 49/64 loss: -2.6555843353271484
Batch 50/64 loss: -2.686716079711914
Batch 51/64 loss: -2.3876113891601562
Batch 52/64 loss: -1.9929656982421875
Batch 53/64 loss: -2.0362377166748047
Batch 54/64 loss: -2.0727310180664062
Batch 55/64 loss: -2.269528388977051
Batch 56/64 loss: -2.118851661682129
Batch 57/64 loss: -2.616683006286621
Batch 58/64 loss: -2.1205272674560547
Batch 59/64 loss: -2.4551782608032227
Batch 60/64 loss: -2.21378231048584
Batch 61/64 loss: -2.3780717849731445
Batch 62/64 loss: -2.54428768157959
Batch 63/64 loss: -2.5327672958374023
Batch 64/64 loss: -7.3063459396362305
Epoch 96  Train loss: -2.574760769862755  Val loss: -2.780699241611966
Epoch 97
-------------------------------
Batch 1/64 loss: -2.988898277282715
Batch 2/64 loss: -2.458314895629883
Batch 3/64 loss: -2.714482307434082
Batch 4/64 loss: -2.5371580123901367
Batch 5/64 loss: -2.1341934204101562
Batch 6/64 loss: -2.213995933532715
Batch 7/64 loss: -2.656599998474121
Batch 8/64 loss: -2.9468393325805664
Batch 9/64 loss: -2.6159534454345703
Batch 10/64 loss: -2.53934383392334
Batch 11/64 loss: -2.658435821533203
Batch 12/64 loss: -2.6450605392456055
Batch 13/64 loss: -2.341494560241699
Batch 14/64 loss: -2.8531837463378906
Batch 15/64 loss: -2.674295425415039
Batch 16/64 loss: -2.6662464141845703
Batch 17/64 loss: -2.7378931045532227
Batch 18/64 loss: -2.4900331497192383
Batch 19/64 loss: -1.6956443786621094
Batch 20/64 loss: -2.562978744506836
Batch 21/64 loss: -2.911318778991699
Batch 22/64 loss: -2.7204933166503906
Batch 23/64 loss: -2.140507698059082
Batch 24/64 loss: -2.9015254974365234
Batch 25/64 loss: -2.6476945877075195
Batch 26/64 loss: -2.2406530380249023
Batch 27/64 loss: -2.1931886672973633
Batch 28/64 loss: -2.004326820373535
Batch 29/64 loss: -1.037806510925293
Batch 30/64 loss: -2.609919548034668
Batch 31/64 loss: -2.531826972961426
Batch 32/64 loss: -2.5508556365966797
Batch 33/64 loss: -2.7809057235717773
Batch 34/64 loss: -2.5103206634521484
Batch 35/64 loss: -2.3025665283203125
Batch 36/64 loss: -2.695270538330078
Batch 37/64 loss: -2.6406946182250977
Batch 38/64 loss: -2.838271141052246
Batch 39/64 loss: -2.8329391479492188
Batch 40/64 loss: -2.8977041244506836
Batch 41/64 loss: -2.366413116455078
Batch 42/64 loss: -2.791248321533203
Batch 43/64 loss: -2.71950626373291
Batch 44/64 loss: -2.678889274597168
Batch 45/64 loss: -2.464816093444824
Batch 46/64 loss: -2.4096012115478516
Batch 47/64 loss: -2.924077033996582
Batch 48/64 loss: -2.661806106567383
Batch 49/64 loss: -2.656243324279785
Batch 50/64 loss: -2.3097105026245117
Batch 51/64 loss: -2.690265655517578
Batch 52/64 loss: -1.6547422409057617
Batch 53/64 loss: -2.6944360733032227
Batch 54/64 loss: -2.2500953674316406
Batch 55/64 loss: -2.6609935760498047
Batch 56/64 loss: -2.186882972717285
Batch 57/64 loss: -2.6822986602783203
Batch 58/64 loss: -2.554497718811035
Batch 59/64 loss: -2.8642425537109375
Batch 60/64 loss: -2.8026304244995117
Batch 61/64 loss: -2.355637550354004
Batch 62/64 loss: -2.461245536804199
Batch 63/64 loss: -2.531548500061035
Batch 64/64 loss: -6.999772071838379
Epoch 97  Train loss: -2.5841802671843883  Val loss: -2.5888550355262363
Epoch 98
-------------------------------
Batch 1/64 loss: -2.4987030029296875
Batch 2/64 loss: -2.5136709213256836
Batch 3/64 loss: -2.179666519165039
Batch 4/64 loss: -2.1742782592773438
Batch 5/64 loss: -2.7051305770874023
Batch 6/64 loss: -2.830080032348633
Batch 7/64 loss: -2.303542137145996
Batch 8/64 loss: -1.9449892044067383
Batch 9/64 loss: -2.3842945098876953
Batch 10/64 loss: -1.8757381439208984
Batch 11/64 loss: -1.9910163879394531
Batch 12/64 loss: -2.4666004180908203
Batch 13/64 loss: -2.2974462509155273
Batch 14/64 loss: -2.283970832824707
Batch 15/64 loss: -2.7440223693847656
Batch 16/64 loss: -2.7480411529541016
Batch 17/64 loss: -2.384553909301758
Batch 18/64 loss: -2.692654609680176
Batch 19/64 loss: -1.9146957397460938
Batch 20/64 loss: -2.8800430297851562
Batch 21/64 loss: -2.3418025970458984
Batch 22/64 loss: -2.4666175842285156
Batch 23/64 loss: -2.658045768737793
Batch 24/64 loss: -2.40285587310791
Batch 25/64 loss: -2.378498077392578
Batch 26/64 loss: -2.141800880432129
Batch 27/64 loss: -1.6328563690185547
Batch 28/64 loss: -2.8989524841308594
Batch 29/64 loss: -2.5625572204589844
Batch 30/64 loss: -2.826465606689453
Batch 31/64 loss: -2.9493236541748047
Batch 32/64 loss: -2.444281578063965
Batch 33/64 loss: -2.747572898864746
Batch 34/64 loss: -2.307720184326172
Batch 35/64 loss: -2.8567304611206055
Batch 36/64 loss: -2.3826122283935547
Batch 37/64 loss: -2.583186149597168
Batch 38/64 loss: -2.4933929443359375
Batch 39/64 loss: -2.616196632385254
Batch 40/64 loss: -2.7786483764648438
Batch 41/64 loss: -2.482142448425293
Batch 42/64 loss: -2.77288818359375
Batch 43/64 loss: -2.921724319458008
Batch 44/64 loss: -2.8360471725463867
Batch 45/64 loss: -2.5919361114501953
Batch 46/64 loss: -2.737407684326172
Batch 47/64 loss: -2.3927812576293945
Batch 48/64 loss: -2.934859275817871
Batch 49/64 loss: -2.445614814758301
Batch 50/64 loss: -2.543489456176758
Batch 51/64 loss: -2.9014768600463867
Batch 52/64 loss: -2.5572633743286133
Batch 53/64 loss: -2.3079404830932617
Batch 54/64 loss: -2.535550117492676
Batch 55/64 loss: -1.9374895095825195
Batch 56/64 loss: -2.8176088333129883
Batch 57/64 loss: -2.6398611068725586
Batch 58/64 loss: -2.861856460571289
Batch 59/64 loss: -2.224055290222168
Batch 60/64 loss: -2.5746660232543945
Batch 61/64 loss: -2.007298469543457
Batch 62/64 loss: -2.427788734436035
Batch 63/64 loss: -2.2096071243286133
Batch 64/64 loss: -7.67423677444458
Epoch 98  Train loss: -2.5521613532421634  Val loss: -2.906315964112167
Epoch 99
-------------------------------
Batch 1/64 loss: -2.6378536224365234
Batch 2/64 loss: -2.3795156478881836
Batch 3/64 loss: -2.474720001220703
Batch 4/64 loss: -2.796025276184082
Batch 5/64 loss: -2.8178977966308594
Batch 6/64 loss: -2.905278205871582
Batch 7/64 loss: -2.954906463623047
Batch 8/64 loss: -2.4660797119140625
Batch 9/64 loss: -2.7882766723632812
Batch 10/64 loss: -2.6747865676879883
Batch 11/64 loss: -2.8597021102905273
Batch 12/64 loss: -2.49898624420166
Batch 13/64 loss: -2.573611259460449
Batch 14/64 loss: -2.3329086303710938
Batch 15/64 loss: -2.6123247146606445
Batch 16/64 loss: -2.905834197998047
Batch 17/64 loss: -2.324172019958496
Batch 18/64 loss: -2.5445518493652344
Batch 19/64 loss: -2.990072250366211
Batch 20/64 loss: -2.527155876159668
Batch 21/64 loss: -2.3127565383911133
Batch 22/64 loss: -2.1145334243774414
Batch 23/64 loss: -2.6789379119873047
Batch 24/64 loss: -1.8719100952148438
Batch 25/64 loss: -2.5814075469970703
Batch 26/64 loss: -2.816192626953125
Batch 27/64 loss: -2.6120615005493164
Batch 28/64 loss: -2.267125129699707
Batch 29/64 loss: -2.6859254837036133
Batch 30/64 loss: -3.0093679428100586
Batch 31/64 loss: -2.874235153198242
Batch 32/64 loss: -2.4530258178710938
Batch 33/64 loss: -2.8536758422851562
Batch 34/64 loss: -1.8753576278686523
Batch 35/64 loss: -1.8574161529541016
Batch 36/64 loss: -2.7312793731689453
Batch 37/64 loss: -2.161479949951172
Batch 38/64 loss: -2.527865409851074
Batch 39/64 loss: -2.7168264389038086
Batch 40/64 loss: -2.7425413131713867
Batch 41/64 loss: -2.549038887023926
Batch 42/64 loss: -2.163998603820801
Batch 43/64 loss: -2.6772499084472656
Batch 44/64 loss: -2.405712127685547
Batch 45/64 loss: -2.7416114807128906
Batch 46/64 loss: -2.8491477966308594
Batch 47/64 loss: -2.8103809356689453
Batch 48/64 loss: -2.763486862182617
Batch 49/64 loss: -2.150631904602051
Batch 50/64 loss: -2.65848445892334
Batch 51/64 loss: -2.3813934326171875
Batch 52/64 loss: -2.3030948638916016
Batch 53/64 loss: -2.4301414489746094
Batch 54/64 loss: -2.7556562423706055
Batch 55/64 loss: -2.683317184448242
Batch 56/64 loss: -2.793776512145996
Batch 57/64 loss: -1.6062145233154297
Batch 58/64 loss: -2.361268997192383
Batch 59/64 loss: -2.462761878967285
Batch 60/64 loss: -2.4689159393310547
Batch 61/64 loss: -2.683839797973633
Batch 62/64 loss: -2.667146682739258
Batch 63/64 loss: -2.2215566635131836
Batch 64/64 loss: -7.505956649780273
Epoch 99  Train loss: -2.604343137554094  Val loss: -2.761560105785881
Epoch 100
-------------------------------
Batch 1/64 loss: -2.2721481323242188
Batch 2/64 loss: -2.536357879638672
Batch 3/64 loss: -2.771699905395508
Batch 4/64 loss: -2.5125560760498047
Batch 5/64 loss: -2.771334648132324
Batch 6/64 loss: -2.674687385559082
Batch 7/64 loss: -3.0772151947021484
Batch 8/64 loss: -2.18430233001709
Batch 9/64 loss: -2.6480331420898438
Batch 10/64 loss: -2.85306453704834
Batch 11/64 loss: -2.796253204345703
Batch 12/64 loss: -2.6019887924194336
Batch 13/64 loss: -2.3392248153686523
Batch 14/64 loss: -2.0841121673583984
Batch 15/64 loss: -2.627272605895996
Batch 16/64 loss: -2.317838668823242
Batch 17/64 loss: -2.9919662475585938
Batch 18/64 loss: -2.9065732955932617
Batch 19/64 loss: -2.846761703491211
Batch 20/64 loss: -2.2165727615356445
Batch 21/64 loss: -2.840975761413574
Batch 22/64 loss: -2.3823165893554688
Batch 23/64 loss: -2.9038658142089844
Batch 24/64 loss: -2.2287826538085938
Batch 25/64 loss: -2.6778030395507812
Batch 26/64 loss: -2.3253707885742188
Batch 27/64 loss: -2.622478485107422
Batch 28/64 loss: -2.660886764526367
Batch 29/64 loss: -2.4780168533325195
Batch 30/64 loss: -2.2741641998291016
Batch 31/64 loss: -2.5168323516845703
Batch 32/64 loss: -2.247756004333496
Batch 33/64 loss: -2.564234733581543
Batch 34/64 loss: -2.4412384033203125
Batch 35/64 loss: -2.619326591491699
Batch 36/64 loss: -2.599534034729004
Batch 37/64 loss: -2.3600502014160156
Batch 38/64 loss: -2.511089324951172
Batch 39/64 loss: -1.9373559951782227
Batch 40/64 loss: -2.6959495544433594
Batch 41/64 loss: -2.306138038635254
Batch 42/64 loss: -2.4621801376342773
Batch 43/64 loss: -2.6189260482788086
Batch 44/64 loss: -2.580132484436035
Batch 45/64 loss: -2.8402957916259766
Batch 46/64 loss: -2.633856773376465
Batch 47/64 loss: -2.801194190979004
Batch 48/64 loss: -2.8101415634155273
Batch 49/64 loss: -2.6312856674194336
Batch 50/64 loss: -2.475687026977539
Batch 51/64 loss: -2.194286346435547
Batch 52/64 loss: -2.9427013397216797
Batch 53/64 loss: -1.8454828262329102
Batch 54/64 loss: -2.312314033508301
Batch 55/64 loss: -2.440244674682617
Batch 56/64 loss: -2.649141311645508
Batch 57/64 loss: -2.9152116775512695
Batch 58/64 loss: -2.616755485534668
Batch 59/64 loss: -2.6215810775756836
Batch 60/64 loss: -2.5256757736206055
Batch 61/64 loss: -2.8211746215820312
Batch 62/64 loss: -2.6635303497314453
Batch 63/64 loss: -2.6080379486083984
Batch 64/64 loss: -7.490870952606201
Epoch 100  Train loss: -2.617288157519172  Val loss: -2.8649550631283893
Epoch 101
-------------------------------
Batch 1/64 loss: -2.738223075866699
Batch 2/64 loss: -3.059114456176758
Batch 3/64 loss: -2.1160430908203125
Batch 4/64 loss: -2.626157760620117
Batch 5/64 loss: -2.8330345153808594
Batch 6/64 loss: -2.683624267578125
Batch 7/64 loss: -2.202272415161133
Batch 8/64 loss: -2.9891672134399414
Batch 9/64 loss: -2.048297882080078
Batch 10/64 loss: -2.5432300567626953
Batch 11/64 loss: -2.6200904846191406
Batch 12/64 loss: -2.4049978256225586
Batch 13/64 loss: -2.332914352416992
Batch 14/64 loss: -2.1361236572265625
Batch 15/64 loss: -2.8079299926757812
Batch 16/64 loss: -2.147395133972168
Batch 17/64 loss: -3.024134635925293
Batch 18/64 loss: -2.501934051513672
Batch 19/64 loss: -2.699460983276367
Batch 20/64 loss: -2.4898977279663086
Batch 21/64 loss: -2.6989545822143555
Batch 22/64 loss: -2.8237876892089844
Batch 23/64 loss: -2.83059024810791
Batch 24/64 loss: -2.65317440032959
Batch 25/64 loss: -2.2655811309814453
Batch 26/64 loss: -2.7041492462158203
Batch 27/64 loss: -2.098647117614746
Batch 28/64 loss: -2.5290069580078125
Batch 29/64 loss: -2.745208740234375
Batch 30/64 loss: -2.7698965072631836
Batch 31/64 loss: -2.6398391723632812
Batch 32/64 loss: -2.1470470428466797
Batch 33/64 loss: -1.2916202545166016
Batch 34/64 loss: -2.329914093017578
Batch 35/64 loss: -2.6664180755615234
Batch 36/64 loss: -2.5336732864379883
Batch 37/64 loss: -2.7301483154296875
Batch 38/64 loss: -2.4760971069335938
Batch 39/64 loss: -2.687127113342285
Batch 40/64 loss: -2.4372024536132812
Batch 41/64 loss: -2.6202220916748047
Batch 42/64 loss: -2.387460708618164
Batch 43/64 loss: -2.3519392013549805
Batch 44/64 loss: -2.3871946334838867
Batch 45/64 loss: -2.643294334411621
Batch 46/64 loss: -2.538839340209961
Batch 47/64 loss: -2.6305160522460938
Batch 48/64 loss: -2.5867834091186523
Batch 49/64 loss: -2.671839714050293
Batch 50/64 loss: -2.5301895141601562
Batch 51/64 loss: -2.749786376953125
Batch 52/64 loss: -2.762833595275879
Batch 53/64 loss: -2.8840179443359375
Batch 54/64 loss: -2.7918872833251953
Batch 55/64 loss: -2.4568653106689453
Batch 56/64 loss: -1.853499412536621
Batch 57/64 loss: -2.6256303787231445
Batch 58/64 loss: -2.766786575317383
Batch 59/64 loss: -2.348186492919922
Batch 60/64 loss: -2.7387819290161133
Batch 61/64 loss: -2.790205955505371
Batch 62/64 loss: -2.976642608642578
Batch 63/64 loss: -2.3427200317382812
Batch 64/64 loss: -7.802251815795898
Epoch 101  Train loss: -2.609410805795707  Val loss: -2.8466226243481194
Epoch 102
-------------------------------
Batch 1/64 loss: -2.9798736572265625
Batch 2/64 loss: -2.0463733673095703
Batch 3/64 loss: -2.73445987701416
Batch 4/64 loss: -2.681943893432617
Batch 5/64 loss: -2.5631093978881836
Batch 6/64 loss: -2.3484811782836914
Batch 7/64 loss: -2.7805118560791016
Batch 8/64 loss: -2.3847484588623047
Batch 9/64 loss: -2.9268722534179688
Batch 10/64 loss: -2.641389846801758
Batch 11/64 loss: -2.5853404998779297
Batch 12/64 loss: -2.3744640350341797
Batch 13/64 loss: -2.1822385787963867
Batch 14/64 loss: -2.332547187805176
Batch 15/64 loss: -2.8201913833618164
Batch 16/64 loss: -2.836465835571289
Batch 17/64 loss: -2.6243667602539062
Batch 18/64 loss: -2.948798179626465
Batch 19/64 loss: -2.9436235427856445
Batch 20/64 loss: -2.166131019592285
Batch 21/64 loss: -2.7211990356445312
Batch 22/64 loss: -2.7454357147216797
Batch 23/64 loss: -2.7755537033081055
Batch 24/64 loss: -2.363739013671875
Batch 25/64 loss: -2.517765998840332
Batch 26/64 loss: -2.750596046447754
Batch 27/64 loss: -2.7841949462890625
Batch 28/64 loss: -2.943826675415039
Batch 29/64 loss: -2.4874887466430664
Batch 30/64 loss: -2.483574867248535
Batch 31/64 loss: -2.3105945587158203
Batch 32/64 loss: -2.9265613555908203
Batch 33/64 loss: -1.4582691192626953
Batch 34/64 loss: -2.977778434753418
Batch 35/64 loss: -2.6621665954589844
Batch 36/64 loss: -2.632431983947754
Batch 37/64 loss: -2.8524179458618164
Batch 38/64 loss: -2.4914321899414062
Batch 39/64 loss: -2.4843435287475586
Batch 40/64 loss: -2.255258560180664
Batch 41/64 loss: -2.750722885131836
Batch 42/64 loss: -2.3752212524414062
Batch 43/64 loss: -2.6086530685424805
Batch 44/64 loss: -2.343168258666992
Batch 45/64 loss: -2.38181209564209
Batch 46/64 loss: -2.453921318054199
Batch 47/64 loss: -2.3175506591796875
Batch 48/64 loss: -2.644041061401367
Batch 49/64 loss: -2.5839052200317383
Batch 50/64 loss: -2.4615230560302734
Batch 51/64 loss: -2.836134910583496
Batch 52/64 loss: -2.3935422897338867
Batch 53/64 loss: -2.7088871002197266
Batch 54/64 loss: -2.810688018798828
Batch 55/64 loss: -2.583918571472168
Batch 56/64 loss: -2.139799118041992
Batch 57/64 loss: -2.740507125854492
Batch 58/64 loss: -2.815265655517578
Batch 59/64 loss: -2.4678401947021484
Batch 60/64 loss: -2.3641958236694336
Batch 61/64 loss: -2.5934295654296875
Batch 62/64 loss: -2.298065185546875
Batch 63/64 loss: -2.585226058959961
Batch 64/64 loss: -7.562213897705078
Epoch 102  Train loss: -2.626764529359107  Val loss: -2.8566362308882356
Epoch 103
-------------------------------
Batch 1/64 loss: -2.736056327819824
Batch 2/64 loss: -2.7111473083496094
Batch 3/64 loss: -2.6444311141967773
Batch 4/64 loss: -2.5124406814575195
Batch 5/64 loss: -2.7220592498779297
Batch 6/64 loss: -2.781306266784668
Batch 7/64 loss: -2.9255714416503906
Batch 8/64 loss: -2.6747264862060547
Batch 9/64 loss: -2.731825828552246
Batch 10/64 loss: -2.173020362854004
Batch 11/64 loss: -2.0385942459106445
Batch 12/64 loss: -2.8011093139648438
Batch 13/64 loss: -2.424287796020508
Batch 14/64 loss: -2.602386474609375
Batch 15/64 loss: -2.3402223587036133
Batch 16/64 loss: -2.7416391372680664
Batch 17/64 loss: -2.882784843444824
Batch 18/64 loss: -2.8021421432495117
Batch 19/64 loss: -2.767012596130371
Batch 20/64 loss: -2.4945144653320312
Batch 21/64 loss: -2.2207460403442383
Batch 22/64 loss: -2.3432722091674805
Batch 23/64 loss: -2.9223155975341797
Batch 24/64 loss: -2.628019332885742
Batch 25/64 loss: -2.774683952331543
Batch 26/64 loss: -2.568913459777832
Batch 27/64 loss: -1.6753597259521484
Batch 28/64 loss: -2.852541923522949
Batch 29/64 loss: -2.8099231719970703
Batch 30/64 loss: -2.606405258178711
Batch 31/64 loss: -2.948122978210449
Batch 32/64 loss: -2.69466495513916
Batch 33/64 loss: -2.708498001098633
Batch 34/64 loss: -2.6087474822998047
Batch 35/64 loss: -2.988943099975586
Batch 36/64 loss: -2.4393014907836914
Batch 37/64 loss: -2.9637527465820312
Batch 38/64 loss: -2.76275634765625
Batch 39/64 loss: -2.6581125259399414
Batch 40/64 loss: -2.4122018814086914
Batch 41/64 loss: -2.286907196044922
Batch 42/64 loss: -2.1957998275756836
Batch 43/64 loss: -2.424226760864258
Batch 44/64 loss: -2.6486568450927734
Batch 45/64 loss: -2.941901206970215
Batch 46/64 loss: -2.765422821044922
Batch 47/64 loss: -2.429591178894043
Batch 48/64 loss: -1.9800891876220703
Batch 49/64 loss: -2.988022804260254
Batch 50/64 loss: -2.7555246353149414
Batch 51/64 loss: -2.1096487045288086
Batch 52/64 loss: -2.5403127670288086
Batch 53/64 loss: -2.6841211318969727
Batch 54/64 loss: -1.802088737487793
Batch 55/64 loss: -2.7945432662963867
Batch 56/64 loss: -2.545757293701172
Batch 57/64 loss: -2.8283042907714844
Batch 58/64 loss: -2.5727577209472656
Batch 59/64 loss: -1.887451171875
Batch 60/64 loss: -2.5237550735473633
Batch 61/64 loss: -2.2452516555786133
Batch 62/64 loss: -2.8002023696899414
Batch 63/64 loss: -2.8856449127197266
Batch 64/64 loss: -7.670158863067627
Epoch 103  Train loss: -2.64287311890546  Val loss: -2.941842383945111
Epoch 104
-------------------------------
Batch 1/64 loss: -2.7810544967651367
Batch 2/64 loss: -2.497565269470215
Batch 3/64 loss: -2.457094192504883
Batch 4/64 loss: -2.8367958068847656
Batch 5/64 loss: -1.8903083801269531
Batch 6/64 loss: -2.7695302963256836
Batch 7/64 loss: -2.4854393005371094
Batch 8/64 loss: -2.8320178985595703
Batch 9/64 loss: -2.695901870727539
Batch 10/64 loss: -2.72998046875
Batch 11/64 loss: -2.7545032501220703
Batch 12/64 loss: -3.0071849822998047
Batch 13/64 loss: -2.6673965454101562
Batch 14/64 loss: -2.4624834060668945
Batch 15/64 loss: -2.7761363983154297
Batch 16/64 loss: -2.878347396850586
Batch 17/64 loss: -2.938218116760254
Batch 18/64 loss: -2.844904899597168
Batch 19/64 loss: -2.866776466369629
Batch 20/64 loss: -2.200839042663574
Batch 21/64 loss: -2.8618831634521484
Batch 22/64 loss: -2.4049034118652344
Batch 23/64 loss: -2.8755455017089844
Batch 24/64 loss: -2.6970462799072266
Batch 25/64 loss: -2.59945011138916
Batch 26/64 loss: -2.708454132080078
Batch 27/64 loss: -2.332338333129883
Batch 28/64 loss: -2.6854629516601562
Batch 29/64 loss: -2.6469945907592773
Batch 30/64 loss: -2.759410858154297
Batch 31/64 loss: -2.775114059448242
Batch 32/64 loss: -2.367279052734375
Batch 33/64 loss: -2.7490148544311523
Batch 34/64 loss: -1.8364982604980469
Batch 35/64 loss: -2.657830238342285
Batch 36/64 loss: -2.4850664138793945
Batch 37/64 loss: -2.622262954711914
Batch 38/64 loss: -1.3466815948486328
Batch 39/64 loss: -2.54775333404541
Batch 40/64 loss: -2.6261539459228516
Batch 41/64 loss: -2.330291748046875
Batch 42/64 loss: -2.292247772216797
Batch 43/64 loss: -2.711711883544922
Batch 44/64 loss: -2.609072685241699
Batch 45/64 loss: -2.9794235229492188
Batch 46/64 loss: -2.8449668884277344
Batch 47/64 loss: -2.4947824478149414
Batch 48/64 loss: -2.200164794921875
Batch 49/64 loss: -1.8747367858886719
Batch 50/64 loss: -2.7120046615600586
Batch 51/64 loss: -2.7499637603759766
Batch 52/64 loss: -2.5865001678466797
Batch 53/64 loss: -2.962233543395996
Batch 54/64 loss: -2.268242835998535
Batch 55/64 loss: -2.404325485229492
Batch 56/64 loss: -2.159090042114258
Batch 57/64 loss: -2.2617969512939453
Batch 58/64 loss: -2.4878149032592773
Batch 59/64 loss: -2.273466110229492
Batch 60/64 loss: -2.233020782470703
Batch 61/64 loss: -2.637065887451172
Batch 62/64 loss: -2.6001081466674805
Batch 63/64 loss: -2.973391532897949
Batch 64/64 loss: -7.439408302307129
Epoch 104  Train loss: -2.622487875994514  Val loss: -2.8392361906385912
Epoch 105
-------------------------------
Batch 1/64 loss: -2.6287660598754883
Batch 2/64 loss: -2.6434545516967773
Batch 3/64 loss: -2.6368350982666016
Batch 4/64 loss: -2.0414485931396484
Batch 5/64 loss: -2.3856983184814453
Batch 6/64 loss: -2.6549997329711914
Batch 7/64 loss: -2.3893556594848633
Batch 8/64 loss: -2.519476890563965
Batch 9/64 loss: -2.9151525497436523
Batch 10/64 loss: -2.7745227813720703
Batch 11/64 loss: -2.8262691497802734
Batch 12/64 loss: -3.0061569213867188
Batch 13/64 loss: -2.767727851867676
Batch 14/64 loss: -2.760714530944824
Batch 15/64 loss: -2.8475475311279297
Batch 16/64 loss: -2.9615955352783203
Batch 17/64 loss: -2.2566375732421875
Batch 18/64 loss: -2.7229576110839844
Batch 19/64 loss: -2.7763586044311523
Batch 20/64 loss: -2.161396026611328
Batch 21/64 loss: -2.272891044616699
Batch 22/64 loss: -2.2127771377563477
Batch 23/64 loss: -2.412186622619629
Batch 24/64 loss: -2.577752113342285
Batch 25/64 loss: -2.4856653213500977
Batch 26/64 loss: -2.9406824111938477
Batch 27/64 loss: -2.414473533630371
Batch 28/64 loss: -2.6929636001586914
Batch 29/64 loss: -2.081244468688965
Batch 30/64 loss: -2.905853271484375
Batch 31/64 loss: -2.77559757232666
Batch 32/64 loss: -2.723827362060547
Batch 33/64 loss: -2.5531234741210938
Batch 34/64 loss: -2.904582977294922
Batch 35/64 loss: -2.8483381271362305
Batch 36/64 loss: -1.9022445678710938
Batch 37/64 loss: -2.5880002975463867
Batch 38/64 loss: -2.604630470275879
Batch 39/64 loss: -2.648747444152832
Batch 40/64 loss: -2.570650100708008
Batch 41/64 loss: -2.630704879760742
Batch 42/64 loss: -2.6913251876831055
Batch 43/64 loss: -2.644484519958496
Batch 44/64 loss: -2.662234306335449
Batch 45/64 loss: -2.896418571472168
Batch 46/64 loss: -2.9278564453125
Batch 47/64 loss: -2.4045495986938477
Batch 48/64 loss: -2.6000804901123047
Batch 49/64 loss: -2.7665443420410156
Batch 50/64 loss: -2.5427379608154297
Batch 51/64 loss: -2.4584760665893555
Batch 52/64 loss: -2.526604652404785
Batch 53/64 loss: -2.8059797286987305
Batch 54/64 loss: -2.7416439056396484
Batch 55/64 loss: -2.483430862426758
Batch 56/64 loss: -2.7888660430908203
Batch 57/64 loss: -2.338409423828125
Batch 58/64 loss: -2.8479881286621094
Batch 59/64 loss: -2.926180839538574
Batch 60/64 loss: -2.9212942123413086
Batch 61/64 loss: -2.8243141174316406
Batch 62/64 loss: -2.743824005126953
Batch 63/64 loss: -2.77938175201416
Batch 64/64 loss: -7.40966796875
Epoch 105  Train loss: -2.6871197569604015  Val loss: -2.890197203331387
Epoch 106
-------------------------------
Batch 1/64 loss: -2.6271018981933594
Batch 2/64 loss: -2.3424081802368164
Batch 3/64 loss: -2.808897018432617
Batch 4/64 loss: -2.6045169830322266
Batch 5/64 loss: -2.618570327758789
Batch 6/64 loss: -2.4843320846557617
Batch 7/64 loss: -2.5507984161376953
Batch 8/64 loss: -2.049715042114258
Batch 9/64 loss: -2.8427038192749023
Batch 10/64 loss: -2.933079719543457
Batch 11/64 loss: -2.8727149963378906
Batch 12/64 loss: -2.7300329208374023
Batch 13/64 loss: -2.047740936279297
Batch 14/64 loss: -2.695415496826172
Batch 15/64 loss: -2.645146369934082
Batch 16/64 loss: -2.7719650268554688
Batch 17/64 loss: -2.9625091552734375
Batch 18/64 loss: -2.8060102462768555
Batch 19/64 loss: -2.8842859268188477
Batch 20/64 loss: -2.7188167572021484
Batch 21/64 loss: -3.015965461730957
Batch 22/64 loss: -2.569676399230957
Batch 23/64 loss: -2.1886730194091797
Batch 24/64 loss: -2.159120559692383
Batch 25/64 loss: -1.3970346450805664
Batch 26/64 loss: -2.347177505493164
Batch 27/64 loss: -2.1581907272338867
Batch 28/64 loss: -2.6417922973632812
Batch 29/64 loss: -2.8836536407470703
Batch 30/64 loss: -2.4444808959960938
Batch 31/64 loss: -2.234342575073242
Batch 32/64 loss: -2.683338165283203
Batch 33/64 loss: -2.451791763305664
Batch 34/64 loss: -1.7412519454956055
Batch 35/64 loss: -2.5503129959106445
Batch 36/64 loss: -2.8531312942504883
Batch 37/64 loss: -2.81636905670166
Batch 38/64 loss: -2.656609535217285
Batch 39/64 loss: -2.0879268646240234
Batch 40/64 loss: -2.4397621154785156
Batch 41/64 loss: -2.8685903549194336
Batch 42/64 loss: -2.6275224685668945
Batch 43/64 loss: -2.64309024810791
Batch 44/64 loss: -2.505147933959961
Batch 45/64 loss: -3.0523605346679688
Batch 46/64 loss: -2.7845287322998047
Batch 47/64 loss: -2.748537063598633
Batch 48/64 loss: -2.8562259674072266
Batch 49/64 loss: -2.7277374267578125
Batch 50/64 loss: -2.957125663757324
Batch 51/64 loss: -2.6675949096679688
Batch 52/64 loss: -2.8585329055786133
Batch 53/64 loss: -2.721236228942871
Batch 54/64 loss: -2.8207263946533203
Batch 55/64 loss: -2.6338424682617188
Batch 56/64 loss: -2.635308265686035
Batch 57/64 loss: -2.266533851623535
Batch 58/64 loss: -2.746847152709961
Batch 59/64 loss: -2.616025924682617
Batch 60/64 loss: -2.9926490783691406
Batch 61/64 loss: -2.338871955871582
Batch 62/64 loss: -2.6708154678344727
Batch 63/64 loss: -2.962498664855957
Batch 64/64 loss: -7.509354591369629
Epoch 106  Train loss: -2.661203582614076  Val loss: -2.607108361942252
Epoch 107
-------------------------------
Batch 1/64 loss: -2.3275575637817383
Batch 2/64 loss: -2.540578842163086
Batch 3/64 loss: -2.675501823425293
Batch 4/64 loss: -2.407402992248535
Batch 5/64 loss: -2.1175336837768555
Batch 6/64 loss: -2.679745674133301
Batch 7/64 loss: -2.737661361694336
Batch 8/64 loss: -2.6387710571289062
Batch 9/64 loss: -2.333563804626465
Batch 10/64 loss: -2.6638755798339844
Batch 11/64 loss: -2.6547298431396484
Batch 12/64 loss: -2.377779960632324
Batch 13/64 loss: -2.559657096862793
Batch 14/64 loss: -2.33420467376709
Batch 15/64 loss: -2.742487907409668
Batch 16/64 loss: -2.509139060974121
Batch 17/64 loss: -2.4879322052001953
Batch 18/64 loss: -2.5924501419067383
Batch 19/64 loss: -1.733743667602539
Batch 20/64 loss: -2.246530532836914
Batch 21/64 loss: -2.3101730346679688
Batch 22/64 loss: -2.859701156616211
Batch 23/64 loss: -2.060201644897461
Batch 24/64 loss: -2.280550956726074
Batch 25/64 loss: -2.8287582397460938
Batch 26/64 loss: -2.7425174713134766
Batch 27/64 loss: -2.74245548248291
Batch 28/64 loss: -2.7280969619750977
Batch 29/64 loss: -2.6737680435180664
Batch 30/64 loss: -1.8480396270751953
Batch 31/64 loss: -2.467988967895508
Batch 32/64 loss: -2.1364364624023438
Batch 33/64 loss: -2.7868452072143555
Batch 34/64 loss: -1.4381294250488281
Batch 35/64 loss: -2.567070960998535
Batch 36/64 loss: -1.5055150985717773
Batch 37/64 loss: -2.9037952423095703
Batch 38/64 loss: -2.5435495376586914
Batch 39/64 loss: -2.4141616821289062
Batch 40/64 loss: -2.6281309127807617
Batch 41/64 loss: -1.886627197265625
Batch 42/64 loss: -0.8354864120483398
Batch 43/64 loss: -2.6028289794921875
Batch 44/64 loss: -2.6881465911865234
Batch 45/64 loss: -2.4520702362060547
Batch 46/64 loss: -2.5195083618164062
Batch 47/64 loss: -2.1788644790649414
Batch 48/64 loss: -2.6441164016723633
Batch 49/64 loss: -2.6976852416992188
Batch 50/64 loss: -2.468852996826172
Batch 51/64 loss: -2.792238235473633
Batch 52/64 loss: -2.4499988555908203
Batch 53/64 loss: -2.653903007507324
Batch 54/64 loss: -2.5730695724487305
Batch 55/64 loss: -2.835845947265625
Batch 56/64 loss: -2.3006372451782227
Batch 57/64 loss: -2.497537612915039
Batch 58/64 loss: -2.4635658264160156
Batch 59/64 loss: -2.910233497619629
Batch 60/64 loss: -2.7392797470092773
Batch 61/64 loss: -2.6587209701538086
Batch 62/64 loss: -2.760011672973633
Batch 63/64 loss: -2.7414894104003906
Batch 64/64 loss: -7.204745769500732
Epoch 107  Train loss: -2.5189178261102416  Val loss: -2.881251213886484
Epoch 108
-------------------------------
Batch 1/64 loss: -2.4514856338500977
Batch 2/64 loss: -2.9267730712890625
Batch 3/64 loss: -2.4133434295654297
Batch 4/64 loss: -2.712158203125
Batch 5/64 loss: -2.7524938583374023
Batch 6/64 loss: -2.7781410217285156
Batch 7/64 loss: -1.885650634765625
Batch 8/64 loss: -2.4277353286743164
Batch 9/64 loss: -2.7473983764648438
Batch 10/64 loss: -2.105027198791504
Batch 11/64 loss: -2.24295711517334
Batch 12/64 loss: -2.935744285583496
Batch 13/64 loss: -2.73099422454834
Batch 14/64 loss: -2.7909164428710938
Batch 15/64 loss: -2.808258056640625
Batch 16/64 loss: -2.894683837890625
Batch 17/64 loss: -2.787764549255371
Batch 18/64 loss: -2.772068977355957
Batch 19/64 loss: -2.8657541275024414
Batch 20/64 loss: -2.20430850982666
Batch 21/64 loss: -2.860330581665039
Batch 22/64 loss: -2.786196708679199
Batch 23/64 loss: -2.6245193481445312
Batch 24/64 loss: -2.6803178787231445
Batch 25/64 loss: -2.727548599243164
Batch 26/64 loss: -2.776373863220215
Batch 27/64 loss: -2.7546491622924805
Batch 28/64 loss: -2.389084815979004
Batch 29/64 loss: -2.205493927001953
Batch 30/64 loss: -2.3341245651245117
Batch 31/64 loss: -2.821499824523926
Batch 32/64 loss: -2.59710693359375
Batch 33/64 loss: -2.565153121948242
Batch 34/64 loss: -2.7699670791625977
Batch 35/64 loss: -2.7748327255249023
Batch 36/64 loss: -2.9448795318603516
Batch 37/64 loss: -1.9485607147216797
Batch 38/64 loss: -2.362961769104004
Batch 39/64 loss: -2.7435760498046875
Batch 40/64 loss: -2.7785959243774414
Batch 41/64 loss: -2.949432373046875
Batch 42/64 loss: -2.2715463638305664
Batch 43/64 loss: -2.7646007537841797
Batch 44/64 loss: -2.847789764404297
Batch 45/64 loss: -2.7069225311279297
Batch 46/64 loss: -3.019754409790039
Batch 47/64 loss: -2.2966785430908203
Batch 48/64 loss: -3.0006895065307617
Batch 49/64 loss: -2.7464427947998047
Batch 50/64 loss: -2.9436349868774414
Batch 51/64 loss: -2.5223512649536133
Batch 52/64 loss: -2.680133819580078
Batch 53/64 loss: -2.6092519760131836
Batch 54/64 loss: -2.1411428451538086
Batch 55/64 loss: -2.5778160095214844
Batch 56/64 loss: -2.4475622177124023
Batch 57/64 loss: -2.0395689010620117
Batch 58/64 loss: -2.798995018005371
Batch 59/64 loss: -2.7386245727539062
Batch 60/64 loss: -2.5751161575317383
Batch 61/64 loss: -2.6884069442749023
Batch 62/64 loss: -2.02683162689209
Batch 63/64 loss: -2.423553466796875
Batch 64/64 loss: -7.010622978210449
Epoch 108  Train loss: -2.6628116719862995  Val loss: -2.879681970655304
Epoch 109
-------------------------------
Batch 1/64 loss: -3.1447877883911133
Batch 2/64 loss: -2.3939294815063477
Batch 3/64 loss: -3.1133289337158203
Batch 4/64 loss: -2.819331169128418
Batch 5/64 loss: -2.7263383865356445
Batch 6/64 loss: -2.714491844177246
Batch 7/64 loss: -2.5181312561035156
Batch 8/64 loss: -2.8073501586914062
Batch 9/64 loss: -2.767794609069824
Batch 10/64 loss: -2.058566093444824
Batch 11/64 loss: -2.9702634811401367
Batch 12/64 loss: -2.9560394287109375
Batch 13/64 loss: -2.824810028076172
Batch 14/64 loss: -2.9007415771484375
Batch 15/64 loss: -2.4445505142211914
Batch 16/64 loss: -2.609837532043457
Batch 17/64 loss: -2.950742721557617
Batch 18/64 loss: -2.527346611022949
Batch 19/64 loss: -2.6308670043945312
Batch 20/64 loss: -2.417757987976074
Batch 21/64 loss: -2.48313045501709
Batch 22/64 loss: -2.860536575317383
Batch 23/64 loss: -2.95528507232666
Batch 24/64 loss: -2.3579912185668945
Batch 25/64 loss: -2.5593643188476562
Batch 26/64 loss: -2.50070858001709
Batch 27/64 loss: -2.965165138244629
Batch 28/64 loss: -2.0317764282226562
Batch 29/64 loss: -2.976654052734375
Batch 30/64 loss: -2.6428890228271484
Batch 31/64 loss: -2.6455583572387695
Batch 32/64 loss: -2.8813390731811523
Batch 33/64 loss: -2.1749820709228516
Batch 34/64 loss: -2.776185989379883
Batch 35/64 loss: -2.9584617614746094
Batch 36/64 loss: -2.5987043380737305
Batch 37/64 loss: -2.729684829711914
Batch 38/64 loss: -3.0381412506103516
Batch 39/64 loss: -2.3724422454833984
Batch 40/64 loss: -2.8724899291992188
Batch 41/64 loss: -2.869696617126465
Batch 42/64 loss: -2.5629215240478516
Batch 43/64 loss: -3.07485294342041
Batch 44/64 loss: -2.606307029724121
Batch 45/64 loss: -2.775082588195801
Batch 46/64 loss: -2.556406021118164
Batch 47/64 loss: -2.5542497634887695
Batch 48/64 loss: -2.9360170364379883
Batch 49/64 loss: -2.7391538619995117
Batch 50/64 loss: -2.9641408920288086
Batch 51/64 loss: -2.5899572372436523
Batch 52/64 loss: -3.1056480407714844
Batch 53/64 loss: -3.0421628952026367
Batch 54/64 loss: -2.8189563751220703
Batch 55/64 loss: -2.6304330825805664
Batch 56/64 loss: -2.7995080947875977
Batch 57/64 loss: -2.904402732849121
Batch 58/64 loss: -2.639073371887207
Batch 59/64 loss: -2.7125892639160156
Batch 60/64 loss: -2.0746841430664062
Batch 61/64 loss: -2.3989686965942383
Batch 62/64 loss: -2.761432647705078
Batch 63/64 loss: -2.8666610717773438
Batch 64/64 loss: -7.539450645446777
Epoch 109  Train loss: -2.7657473134059534  Val loss: -2.871935146371114
Epoch 110
-------------------------------
Batch 1/64 loss: -2.692474365234375
Batch 2/64 loss: -2.9366912841796875
Batch 3/64 loss: -2.7741289138793945
Batch 4/64 loss: -2.612349510192871
Batch 5/64 loss: -3.0505428314208984
Batch 6/64 loss: -2.823330879211426
Batch 7/64 loss: -2.80987548828125
Batch 8/64 loss: -2.8107919692993164
Batch 9/64 loss: -2.476408004760742
Batch 10/64 loss: -1.9976654052734375
Batch 11/64 loss: -2.7683467864990234
Batch 12/64 loss: -2.4481334686279297
Batch 13/64 loss: -2.559514045715332
Batch 14/64 loss: -2.2586708068847656
Batch 15/64 loss: -2.8499765396118164
Batch 16/64 loss: -2.5737409591674805
Batch 17/64 loss: -3.182095527648926
Batch 18/64 loss: -2.7399749755859375
Batch 19/64 loss: -2.359682083129883
Batch 20/64 loss: -2.307732582092285
Batch 21/64 loss: -2.9688339233398438
Batch 22/64 loss: -2.163510322570801
Batch 23/64 loss: -3.048651695251465
Batch 24/64 loss: -2.8545942306518555
Batch 25/64 loss: -2.3214588165283203
Batch 26/64 loss: -2.898998260498047
Batch 27/64 loss: -2.807565689086914
Batch 28/64 loss: -2.4655237197875977
Batch 29/64 loss: -2.419487953186035
Batch 30/64 loss: -2.819525718688965
Batch 31/64 loss: -3.0147266387939453
Batch 32/64 loss: -2.8391761779785156
Batch 33/64 loss: -2.027585983276367
Batch 34/64 loss: -2.87760066986084
Batch 35/64 loss: -2.8616771697998047
Batch 36/64 loss: -2.898676872253418
Batch 37/64 loss: -2.4246530532836914
Batch 38/64 loss: -2.427556037902832
Batch 39/64 loss: -2.827726364135742
Batch 40/64 loss: -3.1165008544921875
Batch 41/64 loss: -2.904871940612793
Batch 42/64 loss: -2.4302263259887695
Batch 43/64 loss: -2.9655590057373047
Batch 44/64 loss: -2.8054141998291016
Batch 45/64 loss: -2.9899044036865234
Batch 46/64 loss: -2.9246015548706055
Batch 47/64 loss: -2.2690067291259766
Batch 48/64 loss: -2.8634605407714844
Batch 49/64 loss: -2.7209978103637695
Batch 50/64 loss: -2.9672136306762695
Batch 51/64 loss: -2.6919069290161133
Batch 52/64 loss: -2.7300891876220703
Batch 53/64 loss: -2.74697208404541
Batch 54/64 loss: -2.802859306335449
Batch 55/64 loss: -2.767573356628418
Batch 56/64 loss: -2.9769954681396484
Batch 57/64 loss: -2.5570974349975586
Batch 58/64 loss: -2.9490766525268555
Batch 59/64 loss: -2.804414749145508
Batch 60/64 loss: -2.468878746032715
Batch 61/64 loss: -2.8706722259521484
Batch 62/64 loss: -2.7301998138427734
Batch 63/64 loss: -2.366152763366699
Batch 64/64 loss: -7.4349870681762695
Epoch 110  Train loss: -2.7607300664864334  Val loss: -3.0669696847188104
Saving best model, epoch: 110
Epoch 111
-------------------------------
Batch 1/64 loss: -2.8297338485717773
Batch 2/64 loss: -3.0353899002075195
Batch 3/64 loss: -2.5340442657470703
Batch 4/64 loss: -2.837395668029785
Batch 5/64 loss: -2.9926366806030273
Batch 6/64 loss: -2.8219738006591797
Batch 7/64 loss: -2.7689332962036133
Batch 8/64 loss: -3.0217208862304688
Batch 9/64 loss: -2.6704940795898438
Batch 10/64 loss: -2.436284065246582
Batch 11/64 loss: -2.503969192504883
Batch 12/64 loss: -2.681833267211914
Batch 13/64 loss: -2.713526725769043
Batch 14/64 loss: -3.0070409774780273
Batch 15/64 loss: -2.894444465637207
Batch 16/64 loss: -2.835024833679199
Batch 17/64 loss: -2.968092918395996
Batch 18/64 loss: -2.728093147277832
Batch 19/64 loss: -2.8777618408203125
Batch 20/64 loss: -2.679157257080078
Batch 21/64 loss: -2.3747386932373047
Batch 22/64 loss: -2.940781593322754
Batch 23/64 loss: -2.412716865539551
Batch 24/64 loss: -2.4994325637817383
Batch 25/64 loss: -2.831327438354492
Batch 26/64 loss: -2.5951595306396484
Batch 27/64 loss: -2.381636619567871
Batch 28/64 loss: -2.7558460235595703
Batch 29/64 loss: -2.255255699157715
Batch 30/64 loss: -2.568730354309082
Batch 31/64 loss: -2.776963233947754
Batch 32/64 loss: -2.756558418273926
Batch 33/64 loss: -2.9279651641845703
Batch 34/64 loss: -2.433666229248047
Batch 35/64 loss: -2.5983781814575195
Batch 36/64 loss: -2.340182304382324
Batch 37/64 loss: -2.4474563598632812
Batch 38/64 loss: -2.7885799407958984
Batch 39/64 loss: -2.915647506713867
Batch 40/64 loss: -2.849100112915039
Batch 41/64 loss: -2.5791702270507812
Batch 42/64 loss: -2.944070816040039
Batch 43/64 loss: -2.7901201248168945
Batch 44/64 loss: -2.0050315856933594
Batch 45/64 loss: -2.912324905395508
Batch 46/64 loss: -2.700662612915039
Batch 47/64 loss: -2.702045440673828
Batch 48/64 loss: -2.879322052001953
Batch 49/64 loss: -2.9229249954223633
Batch 50/64 loss: -2.752671241760254
Batch 51/64 loss: -2.6932592391967773
Batch 52/64 loss: -2.508138656616211
Batch 53/64 loss: -2.668992042541504
Batch 54/64 loss: -2.8151369094848633
Batch 55/64 loss: -2.6741552352905273
Batch 56/64 loss: -2.8385963439941406
Batch 57/64 loss: -2.875059127807617
Batch 58/64 loss: -2.5611801147460938
Batch 59/64 loss: -2.6921253204345703
Batch 60/64 loss: -2.780935287475586
Batch 61/64 loss: -2.658315658569336
Batch 62/64 loss: -2.816255569458008
Batch 63/64 loss: -2.8310422897338867
Batch 64/64 loss: -7.61605978012085
Epoch 111  Train loss: -2.770215758155374  Val loss: -2.946160883428305
Epoch 112
-------------------------------
Batch 1/64 loss: -2.8081045150756836
Batch 2/64 loss: -2.076803207397461
Batch 3/64 loss: -2.579591751098633
Batch 4/64 loss: -2.9379730224609375
Batch 5/64 loss: -2.501201629638672
Batch 6/64 loss: -2.944875717163086
Batch 7/64 loss: -2.3832101821899414
Batch 8/64 loss: -2.813900947570801
Batch 9/64 loss: -2.410099983215332
Batch 10/64 loss: -2.919844627380371
Batch 11/64 loss: -3.0598459243774414
Batch 12/64 loss: -2.7142982482910156
Batch 13/64 loss: -3.0088157653808594
Batch 14/64 loss: -2.7814760208129883
Batch 15/64 loss: -2.559457778930664
Batch 16/64 loss: -2.378293037414551
Batch 17/64 loss: -3.0249757766723633
Batch 18/64 loss: -2.7744407653808594
Batch 19/64 loss: -2.3982677459716797
Batch 20/64 loss: -2.6522064208984375
Batch 21/64 loss: -2.648876190185547
Batch 22/64 loss: -2.569608688354492
Batch 23/64 loss: -2.799605369567871
Batch 24/64 loss: -2.634347915649414
Batch 25/64 loss: -3.0604753494262695
Batch 26/64 loss: -2.6804981231689453
Batch 27/64 loss: -2.807610511779785
Batch 28/64 loss: -2.235367774963379
Batch 29/64 loss: -2.2888879776000977
Batch 30/64 loss: -2.9558982849121094
Batch 31/64 loss: -2.9444751739501953
Batch 32/64 loss: -2.909337043762207
Batch 33/64 loss: -2.458024024963379
Batch 34/64 loss: -2.8581247329711914
Batch 35/64 loss: -2.4975357055664062
Batch 36/64 loss: -2.551044464111328
Batch 37/64 loss: -2.9091405868530273
Batch 38/64 loss: -2.7362098693847656
Batch 39/64 loss: -2.6855554580688477
Batch 40/64 loss: -2.5498580932617188
Batch 41/64 loss: -2.952895164489746
Batch 42/64 loss: -2.886310577392578
Batch 43/64 loss: -2.7773685455322266
Batch 44/64 loss: -2.7260818481445312
Batch 45/64 loss: -2.723208427429199
Batch 46/64 loss: -2.9589662551879883
Batch 47/64 loss: -2.9917163848876953
Batch 48/64 loss: -2.7053756713867188
Batch 49/64 loss: -2.682122230529785
Batch 50/64 loss: -2.4111995697021484
Batch 51/64 loss: -3.100766181945801
Batch 52/64 loss: -2.684403419494629
Batch 53/64 loss: -2.753514289855957
Batch 54/64 loss: -2.931878089904785
Batch 55/64 loss: -2.790726661682129
Batch 56/64 loss: -2.8653011322021484
Batch 57/64 loss: -2.467487335205078
Batch 58/64 loss: -2.611884117126465
Batch 59/64 loss: -2.9198665618896484
Batch 60/64 loss: -2.4114198684692383
Batch 61/64 loss: -2.691431999206543
Batch 62/64 loss: -2.926210403442383
Batch 63/64 loss: -2.7675018310546875
Batch 64/64 loss: -7.475135803222656
Epoch 112  Train loss: -2.7741514168533623  Val loss: -3.041431833378638
Epoch 113
-------------------------------
Batch 1/64 loss: -2.9801025390625
Batch 2/64 loss: -2.546565055847168
Batch 3/64 loss: -2.2714996337890625
Batch 4/64 loss: -2.9391260147094727
Batch 5/64 loss: -2.8326416015625
Batch 6/64 loss: -2.7890071868896484
Batch 7/64 loss: -2.6454925537109375
Batch 8/64 loss: -2.7841148376464844
Batch 9/64 loss: -2.803007125854492
Batch 10/64 loss: -2.87845516204834
Batch 11/64 loss: -2.667917251586914
Batch 12/64 loss: -2.905733108520508
Batch 13/64 loss: -2.9287853240966797
Batch 14/64 loss: -2.440624237060547
Batch 15/64 loss: -2.8778247833251953
Batch 16/64 loss: -2.8811559677124023
Batch 17/64 loss: -2.5345993041992188
Batch 18/64 loss: -2.0782909393310547
Batch 19/64 loss: -2.693510055541992
Batch 20/64 loss: -2.83597469329834
Batch 21/64 loss: -2.4238481521606445
Batch 22/64 loss: -2.5357837677001953
Batch 23/64 loss: -2.9432363510131836
Batch 24/64 loss: -2.8257055282592773
Batch 25/64 loss: -2.7029123306274414
Batch 26/64 loss: -2.787825584411621
Batch 27/64 loss: -2.9891700744628906
Batch 28/64 loss: -2.6622161865234375
Batch 29/64 loss: -2.8293638229370117
Batch 30/64 loss: -2.730799674987793
Batch 31/64 loss: -2.5073156356811523
Batch 32/64 loss: -2.7858476638793945
Batch 33/64 loss: -2.757904052734375
Batch 34/64 loss: -2.9504098892211914
Batch 35/64 loss: -2.998406410217285
Batch 36/64 loss: -2.8025665283203125
Batch 37/64 loss: -2.6955251693725586
Batch 38/64 loss: -2.802279472351074
Batch 39/64 loss: -2.432234764099121
Batch 40/64 loss: -2.668102264404297
Batch 41/64 loss: -3.041367530822754
Batch 42/64 loss: -2.6634979248046875
Batch 43/64 loss: -2.205510139465332
Batch 44/64 loss: -2.7009363174438477
Batch 45/64 loss: -2.5257301330566406
Batch 46/64 loss: -2.6398658752441406
Batch 47/64 loss: -2.525299072265625
Batch 48/64 loss: -2.7994508743286133
Batch 49/64 loss: -2.9472875595092773
Batch 50/64 loss: -2.810807228088379
Batch 51/64 loss: -2.922435760498047
Batch 52/64 loss: -2.1131181716918945
Batch 53/64 loss: -2.5427064895629883
Batch 54/64 loss: -2.9315624237060547
Batch 55/64 loss: -2.740741729736328
Batch 56/64 loss: -2.7178001403808594
Batch 57/64 loss: -2.6996984481811523
Batch 58/64 loss: -2.6412267684936523
Batch 59/64 loss: -2.61929988861084
Batch 60/64 loss: -2.843132972717285
Batch 61/64 loss: -2.6436538696289062
Batch 62/64 loss: -2.9002256393432617
Batch 63/64 loss: -3.050551414489746
Batch 64/64 loss: -6.860343933105469
Epoch 113  Train loss: -2.7688948238597195  Val loss: -2.669336745009799
Epoch 114
-------------------------------
Batch 1/64 loss: -2.9396181106567383
Batch 2/64 loss: -2.8309555053710938
Batch 3/64 loss: -2.920848846435547
Batch 4/64 loss: -2.8598508834838867
Batch 5/64 loss: -2.674685478210449
Batch 6/64 loss: -2.93350887298584
Batch 7/64 loss: -2.755887031555176
Batch 8/64 loss: -2.807018280029297
Batch 9/64 loss: -2.932784080505371
Batch 10/64 loss: -2.42342472076416
Batch 11/64 loss: -2.6533517837524414
Batch 12/64 loss: -2.543811798095703
Batch 13/64 loss: -3.1184043884277344
Batch 14/64 loss: -2.1030778884887695
Batch 15/64 loss: -2.814181327819824
Batch 16/64 loss: -2.7145652770996094
Batch 17/64 loss: -2.906587600708008
Batch 18/64 loss: -2.851881980895996
Batch 19/64 loss: -3.0742874145507812
Batch 20/64 loss: -2.808980941772461
Batch 21/64 loss: -2.285104751586914
Batch 22/64 loss: -2.363558769226074
Batch 23/64 loss: -2.4515790939331055
Batch 24/64 loss: -2.981722831726074
Batch 25/64 loss: -3.06998348236084
Batch 26/64 loss: -2.8319435119628906
Batch 27/64 loss: -2.3987064361572266
Batch 28/64 loss: -2.833904266357422
Batch 29/64 loss: -2.9104232788085938
Batch 30/64 loss: -2.3389806747436523
Batch 31/64 loss: -2.571345329284668
Batch 32/64 loss: -2.4964284896850586
Batch 33/64 loss: -2.551671028137207
Batch 34/64 loss: -2.6920852661132812
Batch 35/64 loss: -2.762204170227051
Batch 36/64 loss: -3.0915822982788086
Batch 37/64 loss: -2.824019432067871
Batch 38/64 loss: -2.7501354217529297
Batch 39/64 loss: -2.862823486328125
Batch 40/64 loss: -2.7040605545043945
Batch 41/64 loss: -2.850186347961426
Batch 42/64 loss: -2.7415285110473633
Batch 43/64 loss: -2.5490503311157227
Batch 44/64 loss: -2.7555837631225586
Batch 45/64 loss: -2.6196813583374023
Batch 46/64 loss: -3.0550317764282227
Batch 47/64 loss: -2.883127212524414
Batch 48/64 loss: -2.401763916015625
Batch 49/64 loss: -2.936173439025879
Batch 50/64 loss: -3.0070838928222656
Batch 51/64 loss: -2.7652111053466797
Batch 52/64 loss: -2.912684440612793
Batch 53/64 loss: -2.5969715118408203
Batch 54/64 loss: -2.996096611022949
Batch 55/64 loss: -2.9936351776123047
Batch 56/64 loss: -2.8347091674804688
Batch 57/64 loss: -2.9992122650146484
Batch 58/64 loss: -2.5125856399536133
Batch 59/64 loss: -2.8958892822265625
Batch 60/64 loss: -2.8478031158447266
Batch 61/64 loss: -2.7197837829589844
Batch 62/64 loss: -2.864922523498535
Batch 63/64 loss: -2.888446807861328
Batch 64/64 loss: -7.752723693847656
Epoch 114  Train loss: -2.82167340446921  Val loss: -3.056573245123899
Epoch 115
-------------------------------
Batch 1/64 loss: -3.0658082962036133
Batch 2/64 loss: -2.91916561126709
Batch 3/64 loss: -2.9314804077148438
Batch 4/64 loss: -2.706747055053711
Batch 5/64 loss: -2.707209587097168
Batch 6/64 loss: -2.9129180908203125
Batch 7/64 loss: -2.5577878952026367
Batch 8/64 loss: -2.9335575103759766
Batch 9/64 loss: -2.711369514465332
Batch 10/64 loss: -2.844304084777832
Batch 11/64 loss: -2.8808155059814453
Batch 12/64 loss: -2.939028739929199
Batch 13/64 loss: -3.0786685943603516
Batch 14/64 loss: -2.690692901611328
Batch 15/64 loss: -2.536508560180664
Batch 16/64 loss: -2.929046630859375
Batch 17/64 loss: -2.723198890686035
Batch 18/64 loss: -2.742262840270996
Batch 19/64 loss: -2.710702896118164
Batch 20/64 loss: -2.562854766845703
Batch 21/64 loss: -2.3359146118164062
Batch 22/64 loss: -2.7918033599853516
Batch 23/64 loss: -2.723112106323242
Batch 24/64 loss: -2.9550390243530273
Batch 25/64 loss: -2.8386402130126953
Batch 26/64 loss: -2.68503475189209
Batch 27/64 loss: -2.7931623458862305
Batch 28/64 loss: -2.501673698425293
Batch 29/64 loss: -2.8837709426879883
Batch 30/64 loss: -2.7074012756347656
Batch 31/64 loss: -2.4944725036621094
Batch 32/64 loss: -2.372570037841797
Batch 33/64 loss: -2.367403984069824
Batch 34/64 loss: -2.8194942474365234
Batch 35/64 loss: -2.86167049407959
Batch 36/64 loss: -2.7207489013671875
Batch 37/64 loss: -2.6593093872070312
Batch 38/64 loss: -2.965245246887207
Batch 39/64 loss: -2.7441911697387695
Batch 40/64 loss: -2.952451705932617
Batch 41/64 loss: -2.5967864990234375
Batch 42/64 loss: -2.8324289321899414
Batch 43/64 loss: -2.770655632019043
Batch 44/64 loss: -1.844247817993164
Batch 45/64 loss: -2.742809295654297
Batch 46/64 loss: -2.64792537689209
Batch 47/64 loss: -2.9550352096557617
Batch 48/64 loss: -3.0600500106811523
Batch 49/64 loss: -2.5848312377929688
Batch 50/64 loss: -2.7829208374023438
Batch 51/64 loss: -2.941923141479492
Batch 52/64 loss: -2.381709098815918
Batch 53/64 loss: -2.808230400085449
Batch 54/64 loss: -2.9119157791137695
Batch 55/64 loss: -2.340139389038086
Batch 56/64 loss: -2.851840019226074
Batch 57/64 loss: -2.584928512573242
Batch 58/64 loss: -2.581984519958496
Batch 59/64 loss: -2.455831527709961
Batch 60/64 loss: -2.9988222122192383
Batch 61/64 loss: -2.697072982788086
Batch 62/64 loss: -2.6682281494140625
Batch 63/64 loss: -2.7395172119140625
Batch 64/64 loss: -7.596128940582275
Epoch 115  Train loss: -2.787986962935504  Val loss: -2.9066134973899604
Epoch 116
-------------------------------
Batch 1/64 loss: -2.8713436126708984
Batch 2/64 loss: -2.91660213470459
Batch 3/64 loss: -2.9011669158935547
Batch 4/64 loss: -3.147724151611328
Batch 5/64 loss: -2.9941587448120117
Batch 6/64 loss: -2.5749359130859375
Batch 7/64 loss: -3.1351537704467773
Batch 8/64 loss: -2.8927574157714844
Batch 9/64 loss: -2.881524085998535
Batch 10/64 loss: -2.570314407348633
Batch 11/64 loss: -2.6340389251708984
Batch 12/64 loss: -2.707242965698242
Batch 13/64 loss: -2.751349449157715
Batch 14/64 loss: -3.0454254150390625
Batch 15/64 loss: -2.7228355407714844
Batch 16/64 loss: -2.825596809387207
Batch 17/64 loss: -2.2519712448120117
Batch 18/64 loss: -2.73360538482666
Batch 19/64 loss: -2.7575292587280273
Batch 20/64 loss: -2.8019256591796875
Batch 21/64 loss: -3.084824562072754
Batch 22/64 loss: -2.923794746398926
Batch 23/64 loss: -2.404974937438965
Batch 24/64 loss: -3.026700973510742
Batch 25/64 loss: -2.9293527603149414
Batch 26/64 loss: -3.1762657165527344
Batch 27/64 loss: -2.761373519897461
Batch 28/64 loss: -3.002208709716797
Batch 29/64 loss: -2.8601369857788086
Batch 30/64 loss: -2.935784339904785
Batch 31/64 loss: -2.9362306594848633
Batch 32/64 loss: -3.238554000854492
Batch 33/64 loss: -2.8650150299072266
Batch 34/64 loss: -2.7790842056274414
Batch 35/64 loss: -2.8469018936157227
Batch 36/64 loss: -2.836374282836914
Batch 37/64 loss: -2.8999032974243164
Batch 38/64 loss: -2.776076316833496
Batch 39/64 loss: -3.0883960723876953
Batch 40/64 loss: -2.9603328704833984
Batch 41/64 loss: -2.8312034606933594
Batch 42/64 loss: -2.78302001953125
Batch 43/64 loss: -3.008340835571289
Batch 44/64 loss: -2.8979949951171875
Batch 45/64 loss: -2.910099983215332
Batch 46/64 loss: -3.0077743530273438
Batch 47/64 loss: -2.498745918273926
Batch 48/64 loss: -2.5661277770996094
Batch 49/64 loss: -2.985053062438965
Batch 50/64 loss: -2.8823957443237305
Batch 51/64 loss: -2.508133888244629
Batch 52/64 loss: -2.8848533630371094
Batch 53/64 loss: -2.748767852783203
Batch 54/64 loss: -3.02567195892334
Batch 55/64 loss: -2.9628162384033203
Batch 56/64 loss: -1.9722299575805664
Batch 57/64 loss: -2.947157859802246
Batch 58/64 loss: -2.249415397644043
Batch 59/64 loss: -3.042220115661621
Batch 60/64 loss: -2.608074188232422
Batch 61/64 loss: -2.5805511474609375
Batch 62/64 loss: -3.0522403717041016
Batch 63/64 loss: -2.9010305404663086
Batch 64/64 loss: -7.7247467041015625
Epoch 116  Train loss: -2.887795556760302  Val loss: -3.0877864614794754
Saving best model, epoch: 116
Epoch 117
-------------------------------
Batch 1/64 loss: -3.1749372482299805
Batch 2/64 loss: -2.822901725769043
Batch 3/64 loss: -2.816044807434082
Batch 4/64 loss: -2.2171897888183594
Batch 5/64 loss: -2.485823631286621
Batch 6/64 loss: -2.965622901916504
Batch 7/64 loss: -2.964933395385742
Batch 8/64 loss: -2.9070873260498047
Batch 9/64 loss: -2.7400312423706055
Batch 10/64 loss: -2.4647607803344727
Batch 11/64 loss: -2.5971527099609375
Batch 12/64 loss: -3.035799026489258
Batch 13/64 loss: -3.204220771789551
Batch 14/64 loss: -2.879962921142578
Batch 15/64 loss: -2.8715171813964844
Batch 16/64 loss: -2.9413089752197266
Batch 17/64 loss: -2.655445098876953
Batch 18/64 loss: -2.713038444519043
Batch 19/64 loss: -3.118986129760742
Batch 20/64 loss: -2.981846809387207
Batch 21/64 loss: -2.8115062713623047
Batch 22/64 loss: -2.673771858215332
Batch 23/64 loss: -3.121964454650879
Batch 24/64 loss: -2.7616806030273438
Batch 25/64 loss: -2.9202871322631836
Batch 26/64 loss: -2.7273921966552734
Batch 27/64 loss: -3.100801467895508
Batch 28/64 loss: -2.818115234375
Batch 29/64 loss: -2.7938060760498047
Batch 30/64 loss: -2.780817985534668
Batch 31/64 loss: -2.9287357330322266
Batch 32/64 loss: -2.90020751953125
Batch 33/64 loss: -3.0154056549072266
Batch 34/64 loss: -2.7081356048583984
Batch 35/64 loss: -2.7379655838012695
Batch 36/64 loss: -3.0159778594970703
Batch 37/64 loss: -3.005657196044922
Batch 38/64 loss: -2.8214168548583984
Batch 39/64 loss: -2.7509145736694336
Batch 40/64 loss: -2.891622543334961
Batch 41/64 loss: -2.5835084915161133
Batch 42/64 loss: -3.1232662200927734
Batch 43/64 loss: -3.1451892852783203
Batch 44/64 loss: -2.022122383117676
Batch 45/64 loss: -3.0920629501342773
Batch 46/64 loss: -2.914217948913574
Batch 47/64 loss: -2.5167932510375977
Batch 48/64 loss: -3.0031328201293945
Batch 49/64 loss: -2.6803970336914062
Batch 50/64 loss: -2.924065589904785
Batch 51/64 loss: -3.0274057388305664
Batch 52/64 loss: -2.613062858581543
Batch 53/64 loss: -2.703310966491699
Batch 54/64 loss: -2.9666051864624023
Batch 55/64 loss: -2.4273462295532227
Batch 56/64 loss: -3.0015077590942383
Batch 57/64 loss: -2.8721675872802734
Batch 58/64 loss: -3.115232467651367
Batch 59/64 loss: -3.1213560104370117
Batch 60/64 loss: -3.0980377197265625
Batch 61/64 loss: -2.8413991928100586
Batch 62/64 loss: -2.9363365173339844
Batch 63/64 loss: -2.926250457763672
Batch 64/64 loss: -7.325530529022217
Epoch 117  Train loss: -2.9018622099184523  Val loss: -2.854554651529109
Epoch 118
-------------------------------
Batch 1/64 loss: -3.158140182495117
Batch 2/64 loss: -3.0482559204101562
Batch 3/64 loss: -2.9888620376586914
Batch 4/64 loss: -2.8852615356445312
Batch 5/64 loss: -2.474123954772949
Batch 6/64 loss: -3.0699100494384766
Batch 7/64 loss: -2.893061637878418
Batch 8/64 loss: -2.666177749633789
Batch 9/64 loss: -2.8704843521118164
Batch 10/64 loss: -2.5897464752197266
Batch 11/64 loss: -2.600111961364746
Batch 12/64 loss: -2.7313718795776367
Batch 13/64 loss: -2.6398725509643555
Batch 14/64 loss: -3.0253171920776367
Batch 15/64 loss: -2.7455739974975586
Batch 16/64 loss: -2.668550491333008
Batch 17/64 loss: -2.4512252807617188
Batch 18/64 loss: -2.90960693359375
Batch 19/64 loss: -2.6285181045532227
Batch 20/64 loss: -3.1667098999023438
Batch 21/64 loss: -3.0249462127685547
Batch 22/64 loss: -3.100118637084961
Batch 23/64 loss: -2.841851234436035
Batch 24/64 loss: -2.938243865966797
Batch 25/64 loss: -2.746487617492676
Batch 26/64 loss: -2.8356075286865234
Batch 27/64 loss: -2.873523712158203
Batch 28/64 loss: -2.390378952026367
Batch 29/64 loss: -3.00693416595459
Batch 30/64 loss: -2.615589141845703
Batch 31/64 loss: -3.0970773696899414
Batch 32/64 loss: -2.898496627807617
Batch 33/64 loss: -3.0483198165893555
Batch 34/64 loss: -2.7691402435302734
Batch 35/64 loss: -3.0261354446411133
Batch 36/64 loss: -2.9582719802856445
Batch 37/64 loss: -3.2207069396972656
Batch 38/64 loss: -3.0076475143432617
Batch 39/64 loss: -3.015732765197754
Batch 40/64 loss: -2.5170907974243164
Batch 41/64 loss: -2.8296546936035156
Batch 42/64 loss: -3.1161069869995117
Batch 43/64 loss: -2.613006591796875
Batch 44/64 loss: -2.5927305221557617
Batch 45/64 loss: -2.8588314056396484
Batch 46/64 loss: -2.9757795333862305
Batch 47/64 loss: -2.5879878997802734
Batch 48/64 loss: -2.714406967163086
Batch 49/64 loss: -2.7028112411499023
Batch 50/64 loss: -2.4719009399414062
Batch 51/64 loss: -2.8454904556274414
Batch 52/64 loss: -2.725374221801758
Batch 53/64 loss: -2.5895872116088867
Batch 54/64 loss: -3.054387092590332
Batch 55/64 loss: -1.9634122848510742
Batch 56/64 loss: -2.5771474838256836
Batch 57/64 loss: -2.1499509811401367
Batch 58/64 loss: -3.001657485961914
Batch 59/64 loss: -2.6916933059692383
Batch 60/64 loss: -2.8598384857177734
Batch 61/64 loss: -3.015753746032715
Batch 62/64 loss: -2.878040313720703
Batch 63/64 loss: -2.818913459777832
Batch 64/64 loss: -7.490599632263184
Epoch 118  Train loss: -2.861107384924795  Val loss: -2.7018972835999584
Epoch 119
-------------------------------
Batch 1/64 loss: -3.01901912689209
Batch 2/64 loss: -2.615748405456543
Batch 3/64 loss: -3.012101173400879
Batch 4/64 loss: -2.829939842224121
Batch 5/64 loss: -2.955744743347168
Batch 6/64 loss: -2.8788833618164062
Batch 7/64 loss: -2.19619083404541
Batch 8/64 loss: -2.973787307739258
Batch 9/64 loss: -3.178800582885742
Batch 10/64 loss: -2.853817939758301
Batch 11/64 loss: -2.905280113220215
Batch 12/64 loss: -2.7627525329589844
Batch 13/64 loss: -3.010359764099121
Batch 14/64 loss: -2.259927749633789
Batch 15/64 loss: -2.496814727783203
Batch 16/64 loss: -2.3978748321533203
Batch 17/64 loss: -2.900857925415039
Batch 18/64 loss: -2.0615005493164062
Batch 19/64 loss: -2.5740842819213867
Batch 20/64 loss: -2.7104806900024414
Batch 21/64 loss: -2.9645252227783203
Batch 22/64 loss: -2.6609153747558594
Batch 23/64 loss: -2.660397529602051
Batch 24/64 loss: -2.915879249572754
Batch 25/64 loss: -2.5874881744384766
Batch 26/64 loss: -2.5765209197998047
Batch 27/64 loss: -2.998819351196289
Batch 28/64 loss: -2.983011245727539
Batch 29/64 loss: -2.741236686706543
Batch 30/64 loss: -2.854874610900879
Batch 31/64 loss: -2.6042585372924805
Batch 32/64 loss: -2.7212657928466797
Batch 33/64 loss: -3.021573066711426
Batch 34/64 loss: -2.8683977127075195
Batch 35/64 loss: -2.9576644897460938
Batch 36/64 loss: -2.9416465759277344
Batch 37/64 loss: -2.678206443786621
Batch 38/64 loss: -2.9471254348754883
Batch 39/64 loss: -2.783802032470703
Batch 40/64 loss: -2.769144058227539
Batch 41/64 loss: -3.012502670288086
Batch 42/64 loss: -2.6721506118774414
Batch 43/64 loss: -2.984426498413086
Batch 44/64 loss: -2.606121063232422
Batch 45/64 loss: -2.613210678100586
Batch 46/64 loss: -2.9386186599731445
Batch 47/64 loss: -2.7733688354492188
Batch 48/64 loss: -2.9395904541015625
Batch 49/64 loss: -3.172048568725586
Batch 50/64 loss: -2.884953498840332
Batch 51/64 loss: -2.682901382446289
Batch 52/64 loss: -2.9322738647460938
Batch 53/64 loss: -2.642146110534668
Batch 54/64 loss: -2.999147415161133
Batch 55/64 loss: -2.720733642578125
Batch 56/64 loss: -3.045137405395508
Batch 57/64 loss: -2.5262527465820312
Batch 58/64 loss: -2.31158447265625
Batch 59/64 loss: -2.9737768173217773
Batch 60/64 loss: -2.847487449645996
Batch 61/64 loss: -2.89522647857666
Batch 62/64 loss: -2.6715240478515625
Batch 63/64 loss: -2.981991767883301
Batch 64/64 loss: -7.530050754547119
Epoch 119  Train loss: -2.8440067796146167  Val loss: -2.741803696884732
Epoch 120
-------------------------------
Batch 1/64 loss: -2.7657175064086914
Batch 2/64 loss: -2.80849552154541
Batch 3/64 loss: -2.986875534057617
Batch 4/64 loss: -3.063399314880371
Batch 5/64 loss: -3.0506181716918945
Batch 6/64 loss: -2.974334716796875
Batch 7/64 loss: -2.5654592514038086
Batch 8/64 loss: -3.051276206970215
Batch 9/64 loss: -3.073500633239746
Batch 10/64 loss: -2.567122459411621
Batch 11/64 loss: -2.788454055786133
Batch 12/64 loss: -2.9317893981933594
Batch 13/64 loss: -3.109133720397949
Batch 14/64 loss: -2.7861804962158203
Batch 15/64 loss: -2.9738941192626953
Batch 16/64 loss: -2.9360694885253906
Batch 17/64 loss: -3.218031883239746
Batch 18/64 loss: -2.059903144836426
Batch 19/64 loss: -2.2855472564697266
Batch 20/64 loss: -2.9607982635498047
Batch 21/64 loss: -3.1310853958129883
Batch 22/64 loss: -2.818096160888672
Batch 23/64 loss: -2.9615859985351562
Batch 24/64 loss: -2.965970039367676
Batch 25/64 loss: -2.966189384460449
Batch 26/64 loss: -2.68707275390625
Batch 27/64 loss: -3.0302066802978516
Batch 28/64 loss: -2.6550426483154297
Batch 29/64 loss: -2.5275659561157227
Batch 30/64 loss: -3.054072380065918
Batch 31/64 loss: -2.540180206298828
Batch 32/64 loss: -2.731858253479004
Batch 33/64 loss: -3.052196502685547
Batch 34/64 loss: -2.673272132873535
Batch 35/64 loss: -2.978181838989258
Batch 36/64 loss: -2.6372337341308594
Batch 37/64 loss: -2.638657569885254
Batch 38/64 loss: -2.776529312133789
Batch 39/64 loss: -2.849431037902832
Batch 40/64 loss: -2.9400157928466797
Batch 41/64 loss: -2.7660961151123047
Batch 42/64 loss: -3.0432262420654297
Batch 43/64 loss: -3.017848014831543
Batch 44/64 loss: -2.2397756576538086
Batch 45/64 loss: -2.776219367980957
Batch 46/64 loss: -2.6672449111938477
Batch 47/64 loss: -2.934246063232422
Batch 48/64 loss: -2.3134336471557617
Batch 49/64 loss: -2.8766775131225586
Batch 50/64 loss: -2.7648706436157227
Batch 51/64 loss: -2.970210075378418
Batch 52/64 loss: -3.0994224548339844
Batch 53/64 loss: -2.5692062377929688
Batch 54/64 loss: -2.873896598815918
Batch 55/64 loss: -3.0864057540893555
Batch 56/64 loss: -2.2730064392089844
Batch 57/64 loss: -3.0177621841430664
Batch 58/64 loss: -2.9488048553466797
Batch 59/64 loss: -3.037118911743164
Batch 60/64 loss: -2.5810461044311523
Batch 61/64 loss: -2.478029251098633
Batch 62/64 loss: -3.0257434844970703
Batch 63/64 loss: -2.5519161224365234
Batch 64/64 loss: -7.578357696533203
Epoch 120  Train loss: -2.873208154416552  Val loss: -2.9886134170584664
Epoch 121
-------------------------------
Batch 1/64 loss: -2.8889236450195312
Batch 2/64 loss: -2.9826831817626953
Batch 3/64 loss: -2.1224708557128906
Batch 4/64 loss: -2.959808349609375
Batch 5/64 loss: -3.1149797439575195
Batch 6/64 loss: -2.500922203063965
Batch 7/64 loss: -2.461888313293457
Batch 8/64 loss: -2.624966621398926
Batch 9/64 loss: -2.583224296569824
Batch 10/64 loss: -2.736093521118164
Batch 11/64 loss: -2.9941482543945312
Batch 12/64 loss: -2.7403383255004883
Batch 13/64 loss: -3.0315933227539062
Batch 14/64 loss: -3.024507522583008
Batch 15/64 loss: -2.8664960861206055
Batch 16/64 loss: -2.92191219329834
Batch 17/64 loss: -2.76302433013916
Batch 18/64 loss: -2.599898338317871
Batch 19/64 loss: -3.0142269134521484
Batch 20/64 loss: -2.356149673461914
Batch 21/64 loss: -3.103865623474121
Batch 22/64 loss: -3.0725746154785156
Batch 23/64 loss: -2.368122100830078
Batch 24/64 loss: -3.0891265869140625
Batch 25/64 loss: -3.015552520751953
Batch 26/64 loss: -2.989950180053711
Batch 27/64 loss: -2.9120655059814453
Batch 28/64 loss: -3.1263742446899414
Batch 29/64 loss: -2.9645891189575195
Batch 30/64 loss: -2.8144044876098633
Batch 31/64 loss: -3.035421371459961
Batch 32/64 loss: -2.80802059173584
Batch 33/64 loss: -2.9648008346557617
Batch 34/64 loss: -2.5423154830932617
Batch 35/64 loss: -3.0715723037719727
Batch 36/64 loss: -2.6418590545654297
Batch 37/64 loss: -2.685318946838379
Batch 38/64 loss: -2.669485092163086
Batch 39/64 loss: -2.6246252059936523
Batch 40/64 loss: -3.0725250244140625
Batch 41/64 loss: -2.7722063064575195
Batch 42/64 loss: -2.6552419662475586
Batch 43/64 loss: -2.6972570419311523
Batch 44/64 loss: -2.7914037704467773
Batch 45/64 loss: -2.9649057388305664
Batch 46/64 loss: -2.727339744567871
Batch 47/64 loss: -2.829545021057129
Batch 48/64 loss: -3.0249061584472656
Batch 49/64 loss: -2.617337226867676
Batch 50/64 loss: -2.9304027557373047
Batch 51/64 loss: -2.934697151184082
Batch 52/64 loss: -2.8308963775634766
Batch 53/64 loss: -2.3431358337402344
Batch 54/64 loss: -3.2518234252929688
Batch 55/64 loss: -3.226024627685547
Batch 56/64 loss: -3.0995521545410156
Batch 57/64 loss: -2.6873226165771484
Batch 58/64 loss: -3.0138864517211914
Batch 59/64 loss: -2.475224494934082
Batch 60/64 loss: -3.201859474182129
Batch 61/64 loss: -2.6296768188476562
Batch 62/64 loss: -2.3689451217651367
Batch 63/64 loss: -2.94832706451416
Batch 64/64 loss: -7.363803386688232
Epoch 121  Train loss: -2.876950501460655  Val loss: -3.0197299157630946
Epoch 122
-------------------------------
Batch 1/64 loss: -3.098428726196289
Batch 2/64 loss: -2.688931465148926
Batch 3/64 loss: -2.63232421875
Batch 4/64 loss: -2.6169614791870117
Batch 5/64 loss: -2.838742256164551
Batch 6/64 loss: -2.8375606536865234
Batch 7/64 loss: -2.743104934692383
Batch 8/64 loss: -2.7317209243774414
Batch 9/64 loss: -2.925581932067871
Batch 10/64 loss: -2.9977455139160156
Batch 11/64 loss: -2.8255615234375
Batch 12/64 loss: -2.717829704284668
Batch 13/64 loss: -3.1122207641601562
Batch 14/64 loss: -2.627351760864258
Batch 15/64 loss: -2.9811267852783203
Batch 16/64 loss: -3.1546287536621094
Batch 17/64 loss: -2.5084667205810547
Batch 18/64 loss: -2.944565773010254
Batch 19/64 loss: -3.077484130859375
Batch 20/64 loss: -2.674727439880371
Batch 21/64 loss: -3.129958152770996
Batch 22/64 loss: -2.7689971923828125
Batch 23/64 loss: -2.469822883605957
Batch 24/64 loss: -2.202970504760742
Batch 25/64 loss: -2.7010374069213867
Batch 26/64 loss: -2.487394332885742
Batch 27/64 loss: -3.1869583129882812
Batch 28/64 loss: -3.14190673828125
Batch 29/64 loss: -2.6343164443969727
Batch 30/64 loss: -2.9090423583984375
Batch 31/64 loss: -2.8735828399658203
Batch 32/64 loss: -3.0958757400512695
Batch 33/64 loss: -2.898043632507324
Batch 34/64 loss: -3.0356950759887695
Batch 35/64 loss: -3.102052688598633
Batch 36/64 loss: -3.119961738586426
Batch 37/64 loss: -3.0121212005615234
Batch 38/64 loss: -2.990046501159668
Batch 39/64 loss: -3.1511573791503906
Batch 40/64 loss: -3.222898483276367
Batch 41/64 loss: -3.2596216201782227
Batch 42/64 loss: -3.136305809020996
Batch 43/64 loss: -2.9699583053588867
Batch 44/64 loss: -2.4096593856811523
Batch 45/64 loss: -3.1839895248413086
Batch 46/64 loss: -2.850827217102051
Batch 47/64 loss: -2.730147361755371
Batch 48/64 loss: -2.8090782165527344
Batch 49/64 loss: -2.6216468811035156
Batch 50/64 loss: -3.0034446716308594
Batch 51/64 loss: -3.0300798416137695
Batch 52/64 loss: -2.98349666595459
Batch 53/64 loss: -2.898092269897461
Batch 54/64 loss: -2.788522720336914
Batch 55/64 loss: -3.0102157592773438
Batch 56/64 loss: -1.8912372589111328
Batch 57/64 loss: -3.008237838745117
Batch 58/64 loss: -2.956173896789551
Batch 59/64 loss: -2.708682060241699
Batch 60/64 loss: -3.0568695068359375
Batch 61/64 loss: -3.292041778564453
Batch 62/64 loss: -2.8455638885498047
Batch 63/64 loss: -3.002206802368164
Batch 64/64 loss: -7.971499443054199
Epoch 122  Train loss: -2.937939277349734  Val loss: -2.7553761275773194
Epoch 123
-------------------------------
Batch 1/64 loss: -2.971432685852051
Batch 2/64 loss: -2.787515640258789
Batch 3/64 loss: -2.3977537155151367
Batch 4/64 loss: -3.0174102783203125
Batch 5/64 loss: -2.947786331176758
Batch 6/64 loss: -1.8994226455688477
Batch 7/64 loss: -2.9640398025512695
Batch 8/64 loss: -3.0064048767089844
Batch 9/64 loss: -2.9090452194213867
Batch 10/64 loss: -2.7985715866088867
Batch 11/64 loss: -3.0199108123779297
Batch 12/64 loss: -3.200406074523926
Batch 13/64 loss: -2.9633750915527344
Batch 14/64 loss: -3.045164108276367
Batch 15/64 loss: -2.748650550842285
Batch 16/64 loss: -2.9309892654418945
Batch 17/64 loss: -3.0156240463256836
Batch 18/64 loss: -2.926241874694824
Batch 19/64 loss: -3.0527944564819336
Batch 20/64 loss: -2.4927682876586914
Batch 21/64 loss: -3.018080711364746
Batch 22/64 loss: -2.9744300842285156
Batch 23/64 loss: -2.9011716842651367
Batch 24/64 loss: -2.81435489654541
Batch 25/64 loss: -2.8615875244140625
Batch 26/64 loss: -2.8976049423217773
Batch 27/64 loss: -2.7591285705566406
Batch 28/64 loss: -2.5171384811401367
Batch 29/64 loss: -2.6379919052124023
Batch 30/64 loss: -3.3017969131469727
Batch 31/64 loss: -2.585057258605957
Batch 32/64 loss: -2.3446521759033203
Batch 33/64 loss: -2.6176910400390625
Batch 34/64 loss: -3.039280891418457
Batch 35/64 loss: -2.8958702087402344
Batch 36/64 loss: -2.8932371139526367
Batch 37/64 loss: -2.904664993286133
Batch 38/64 loss: -2.670103073120117
Batch 39/64 loss: -2.7508296966552734
Batch 40/64 loss: -3.052231788635254
Batch 41/64 loss: -2.3104991912841797
Batch 42/64 loss: -3.1956377029418945
Batch 43/64 loss: -2.841428756713867
Batch 44/64 loss: -3.092723846435547
Batch 45/64 loss: -2.4215011596679688
Batch 46/64 loss: -3.1947412490844727
Batch 47/64 loss: -2.9409799575805664
Batch 48/64 loss: -2.8609113693237305
Batch 49/64 loss: -3.1617136001586914
Batch 50/64 loss: -3.1622800827026367
Batch 51/64 loss: -3.113234519958496
Batch 52/64 loss: -2.9391250610351562
Batch 53/64 loss: -2.9874935150146484
Batch 54/64 loss: -2.9637880325317383
Batch 55/64 loss: -3.1476974487304688
Batch 56/64 loss: -3.052145004272461
Batch 57/64 loss: -2.960259437561035
Batch 58/64 loss: -3.087129592895508
Batch 59/64 loss: -3.0408029556274414
Batch 60/64 loss: -3.0360097885131836
Batch 61/64 loss: -2.9583234786987305
Batch 62/64 loss: -2.431072235107422
Batch 63/64 loss: -2.4320859909057617
Batch 64/64 loss: -7.6483073234558105
Epoch 123  Train loss: -2.927059227812524  Val loss: -3.1042611951270875
Saving best model, epoch: 123
Epoch 124
-------------------------------
Batch 1/64 loss: -2.6874752044677734
Batch 2/64 loss: -3.125978469848633
Batch 3/64 loss: -2.7519044876098633
Batch 4/64 loss: -2.8101816177368164
Batch 5/64 loss: -1.6647491455078125
Batch 6/64 loss: -2.149160385131836
Batch 7/64 loss: -2.4305543899536133
Batch 8/64 loss: -3.047093391418457
Batch 9/64 loss: -2.948282241821289
Batch 10/64 loss: -2.4533700942993164
Batch 11/64 loss: -2.3801679611206055
Batch 12/64 loss: -2.830066680908203
Batch 13/64 loss: -2.576618194580078
Batch 14/64 loss: -3.047797203063965
Batch 15/64 loss: -2.8219242095947266
Batch 16/64 loss: -2.637969970703125
Batch 17/64 loss: -2.1401853561401367
Batch 18/64 loss: -2.929194450378418
Batch 19/64 loss: -2.6086835861206055
Batch 20/64 loss: -2.8737220764160156
Batch 21/64 loss: -3.0842714309692383
Batch 22/64 loss: -2.943746566772461
Batch 23/64 loss: -2.644824981689453
Batch 24/64 loss: -2.294698715209961
Batch 25/64 loss: -2.723238945007324
Batch 26/64 loss: -2.9432201385498047
Batch 27/64 loss: -2.6027307510375977
Batch 28/64 loss: -2.7736711502075195
Batch 29/64 loss: -2.777247428894043
Batch 30/64 loss: -2.805269241333008
Batch 31/64 loss: -3.0244970321655273
Batch 32/64 loss: -2.5997257232666016
Batch 33/64 loss: -2.990117073059082
Batch 34/64 loss: -3.0031509399414062
Batch 35/64 loss: -2.973208427429199
Batch 36/64 loss: -3.076228141784668
Batch 37/64 loss: -2.897658348083496
Batch 38/64 loss: -2.8798675537109375
Batch 39/64 loss: -3.1810665130615234
Batch 40/64 loss: -2.9669742584228516
Batch 41/64 loss: -2.847109794616699
Batch 42/64 loss: -3.076920509338379
Batch 43/64 loss: -3.0582799911499023
Batch 44/64 loss: -2.5302724838256836
Batch 45/64 loss: -2.562662124633789
Batch 46/64 loss: -3.07382869720459
Batch 47/64 loss: -2.887063980102539
Batch 48/64 loss: -2.874286651611328
Batch 49/64 loss: -3.0137853622436523
Batch 50/64 loss: -3.059353828430176
Batch 51/64 loss: -2.800760269165039
Batch 52/64 loss: -3.1005496978759766
Batch 53/64 loss: -2.517169952392578
Batch 54/64 loss: -3.054258346557617
Batch 55/64 loss: -2.897493362426758
Batch 56/64 loss: -3.267486572265625
Batch 57/64 loss: -2.7424745559692383
Batch 58/64 loss: -2.9010305404663086
Batch 59/64 loss: -2.458240509033203
Batch 60/64 loss: -3.029971122741699
Batch 61/64 loss: -2.891839027404785
Batch 62/64 loss: -2.965926170349121
Batch 63/64 loss: -3.10784912109375
Batch 64/64 loss: -7.6905927658081055
Epoch 124  Train loss: -2.864110583885043  Val loss: -3.0682260047938814
Epoch 125
-------------------------------
Batch 1/64 loss: -3.1060028076171875
Batch 2/64 loss: -2.794430732727051
Batch 3/64 loss: -2.9950408935546875
Batch 4/64 loss: -2.623074531555176
Batch 5/64 loss: -2.9245567321777344
Batch 6/64 loss: -2.908177375793457
Batch 7/64 loss: -3.0941057205200195
Batch 8/64 loss: -2.4403276443481445
Batch 9/64 loss: -2.926304817199707
Batch 10/64 loss: -2.860896110534668
Batch 11/64 loss: -2.891507148742676
Batch 12/64 loss: -2.4817380905151367
Batch 13/64 loss: -3.171672821044922
Batch 14/64 loss: -2.809232711791992
Batch 15/64 loss: -2.7986183166503906
Batch 16/64 loss: -3.0205631256103516
Batch 17/64 loss: -3.1447582244873047
Batch 18/64 loss: -2.806081771850586
Batch 19/64 loss: -2.9210243225097656
Batch 20/64 loss: -2.709803581237793
Batch 21/64 loss: -2.771160125732422
Batch 22/64 loss: -2.8566246032714844
Batch 23/64 loss: -2.7267065048217773
Batch 24/64 loss: -2.6723947525024414
Batch 25/64 loss: -2.8404273986816406
Batch 26/64 loss: -3.0894994735717773
Batch 27/64 loss: -2.8428592681884766
Batch 28/64 loss: -2.67340087890625
Batch 29/64 loss: -2.842714309692383
Batch 30/64 loss: -3.0854368209838867
Batch 31/64 loss: -2.851583480834961
Batch 32/64 loss: -2.5295562744140625
Batch 33/64 loss: -2.6984500885009766
Batch 34/64 loss: -2.197211265563965
Batch 35/64 loss: -2.5235795974731445
Batch 36/64 loss: -2.7442827224731445
Batch 37/64 loss: -2.7703943252563477
Batch 38/64 loss: -2.603510856628418
Batch 39/64 loss: -2.9134883880615234
Batch 40/64 loss: -2.581000328063965
Batch 41/64 loss: -3.1355409622192383
Batch 42/64 loss: -2.412435531616211
Batch 43/64 loss: -2.77500057220459
Batch 44/64 loss: -2.9389352798461914
Batch 45/64 loss: -2.823953628540039
Batch 46/64 loss: -2.6992149353027344
Batch 47/64 loss: -2.2561912536621094
Batch 48/64 loss: -2.3755369186401367
Batch 49/64 loss: -2.5339584350585938
Batch 50/64 loss: -2.834416389465332
Batch 51/64 loss: -3.144144058227539
Batch 52/64 loss: -2.671527862548828
Batch 53/64 loss: -3.170461654663086
Batch 54/64 loss: -2.9067630767822266
Batch 55/64 loss: -2.989670753479004
Batch 56/64 loss: -2.9931020736694336
Batch 57/64 loss: -2.994460105895996
Batch 58/64 loss: -2.453479766845703
Batch 59/64 loss: -2.78466796875
Batch 60/64 loss: -2.8900146484375
Batch 61/64 loss: -2.8679027557373047
Batch 62/64 loss: -3.101536750793457
Batch 63/64 loss: -2.1082277297973633
Batch 64/64 loss: -7.768824100494385
Epoch 125  Train loss: -2.85380329618267  Val loss: -3.0029043217295226
Epoch 126
-------------------------------
Batch 1/64 loss: -2.850955009460449
Batch 2/64 loss: -2.504484176635742
Batch 3/64 loss: -3.0286216735839844
Batch 4/64 loss: -2.9457855224609375
Batch 5/64 loss: -3.37939453125
Batch 6/64 loss: -3.1201820373535156
Batch 7/64 loss: -2.922029495239258
Batch 8/64 loss: -3.1051368713378906
Batch 9/64 loss: -2.8941211700439453
Batch 10/64 loss: -3.0029420852661133
Batch 11/64 loss: -2.713756561279297
Batch 12/64 loss: -3.2255468368530273
Batch 13/64 loss: -3.0406408309936523
Batch 14/64 loss: -2.1715002059936523
Batch 15/64 loss: -2.999880790710449
Batch 16/64 loss: -3.1878662109375
Batch 17/64 loss: -3.1476526260375977
Batch 18/64 loss: -3.039377212524414
Batch 19/64 loss: -2.9130773544311523
Batch 20/64 loss: -2.7637510299682617
Batch 21/64 loss: -2.874386787414551
Batch 22/64 loss: -3.163043975830078
Batch 23/64 loss: -2.9594058990478516
Batch 24/64 loss: -2.4627294540405273
Batch 25/64 loss: -2.435201644897461
Batch 26/64 loss: -3.2260665893554688
Batch 27/64 loss: -2.849374771118164
Batch 28/64 loss: -2.9842662811279297
Batch 29/64 loss: -2.8216638565063477
Batch 30/64 loss: -3.218954086303711
Batch 31/64 loss: -2.924692153930664
Batch 32/64 loss: -3.2244443893432617
Batch 33/64 loss: -3.1374311447143555
Batch 34/64 loss: -3.2018165588378906
Batch 35/64 loss: -2.8636884689331055
Batch 36/64 loss: -2.741957664489746
Batch 37/64 loss: -2.5389442443847656
Batch 38/64 loss: -3.1667404174804688
Batch 39/64 loss: -3.1952524185180664
Batch 40/64 loss: -3.321653366088867
Batch 41/64 loss: -3.3019676208496094
Batch 42/64 loss: -3.248000144958496
Batch 43/64 loss: -3.186159133911133
Batch 44/64 loss: -3.1791458129882812
Batch 45/64 loss: -2.6294803619384766
Batch 46/64 loss: -2.81296443939209
Batch 47/64 loss: -3.1037750244140625
Batch 48/64 loss: -2.0018157958984375
Batch 49/64 loss: -2.8061256408691406
Batch 50/64 loss: -3.0446176528930664
Batch 51/64 loss: -3.024195671081543
Batch 52/64 loss: -2.9041662216186523
Batch 53/64 loss: -3.1566505432128906
Batch 54/64 loss: -2.830385208129883
Batch 55/64 loss: -3.016582489013672
Batch 56/64 loss: -2.933736801147461
Batch 57/64 loss: -2.895740509033203
Batch 58/64 loss: -3.077239990234375
Batch 59/64 loss: -2.945523262023926
Batch 60/64 loss: -3.0463685989379883
Batch 61/64 loss: -3.06363582611084
Batch 62/64 loss: -2.809506416320801
Batch 63/64 loss: -2.4227895736694336
Batch 64/64 loss: -7.354734420776367
Epoch 126  Train loss: -2.9996084699443744  Val loss: -3.3084697264576284
Saving best model, epoch: 126
Epoch 127
-------------------------------
Batch 1/64 loss: -2.854008674621582
Batch 2/64 loss: -3.135284423828125
Batch 3/64 loss: -3.144289016723633
Batch 4/64 loss: -2.6251068115234375
Batch 5/64 loss: -3.0622682571411133
Batch 6/64 loss: -2.903529167175293
Batch 7/64 loss: -3.0093183517456055
Batch 8/64 loss: -2.9762954711914062
Batch 9/64 loss: -2.7363815307617188
Batch 10/64 loss: -3.2133302688598633
Batch 11/64 loss: -3.2077646255493164
Batch 12/64 loss: -3.2410364151000977
Batch 13/64 loss: -3.0552186965942383
Batch 14/64 loss: -2.920581817626953
Batch 15/64 loss: -2.811345100402832
Batch 16/64 loss: -2.472074508666992
Batch 17/64 loss: -3.3036394119262695
Batch 18/64 loss: -3.1637516021728516
Batch 19/64 loss: -3.218393325805664
Batch 20/64 loss: -2.5638256072998047
Batch 21/64 loss: -2.2925291061401367
Batch 22/64 loss: -3.122666358947754
Batch 23/64 loss: -3.135183334350586
Batch 24/64 loss: -2.668839454650879
Batch 25/64 loss: -3.305342674255371
Batch 26/64 loss: -2.9952173233032227
Batch 27/64 loss: -3.333761215209961
Batch 28/64 loss: -2.8384809494018555
Batch 29/64 loss: -3.020115852355957
Batch 30/64 loss: -3.116238594055176
Batch 31/64 loss: -3.1682186126708984
Batch 32/64 loss: -2.8907384872436523
Batch 33/64 loss: -2.656942367553711
Batch 34/64 loss: -3.033522605895996
Batch 35/64 loss: -2.4179420471191406
Batch 36/64 loss: -2.9337778091430664
Batch 37/64 loss: -2.420783042907715
Batch 38/64 loss: -3.241520881652832
Batch 39/64 loss: -3.146479606628418
Batch 40/64 loss: -2.98220157623291
Batch 41/64 loss: -3.1146602630615234
Batch 42/64 loss: -2.789271354675293
Batch 43/64 loss: -2.572598457336426
Batch 44/64 loss: -3.0370559692382812
Batch 45/64 loss: -3.1944942474365234
Batch 46/64 loss: -3.2379207611083984
Batch 47/64 loss: -3.131047248840332
Batch 48/64 loss: -3.1663599014282227
Batch 49/64 loss: -3.08260440826416
Batch 50/64 loss: -3.1165523529052734
Batch 51/64 loss: -3.0353450775146484
Batch 52/64 loss: -3.1118392944335938
Batch 53/64 loss: -2.8094425201416016
Batch 54/64 loss: -2.708380699157715
Batch 55/64 loss: -2.876328468322754
Batch 56/64 loss: -2.855729103088379
Batch 57/64 loss: -2.936307907104492
Batch 58/64 loss: -3.056753158569336
Batch 59/64 loss: -3.1182079315185547
Batch 60/64 loss: -3.022433280944824
Batch 61/64 loss: -3.2145681381225586
Batch 62/64 loss: -3.033527374267578
Batch 63/64 loss: -3.107661247253418
Batch 64/64 loss: -7.525491714477539
Epoch 127  Train loss: -3.0323318107455384  Val loss: -3.2302462653196145
Epoch 128
-------------------------------
Batch 1/64 loss: -3.0630016326904297
Batch 2/64 loss: -3.0942678451538086
Batch 3/64 loss: -3.152573585510254
Batch 4/64 loss: -2.900226593017578
Batch 5/64 loss: -3.2287445068359375
Batch 6/64 loss: -3.100590705871582
Batch 7/64 loss: -2.9382505416870117
Batch 8/64 loss: -3.0623226165771484
Batch 9/64 loss: -3.093351364135742
Batch 10/64 loss: -3.13057804107666
Batch 11/64 loss: -2.869272232055664
Batch 12/64 loss: -3.105149269104004
Batch 13/64 loss: -3.186406135559082
Batch 14/64 loss: -3.1485471725463867
Batch 15/64 loss: -2.932093620300293
Batch 16/64 loss: -2.282721519470215
Batch 17/64 loss: -3.183465003967285
Batch 18/64 loss: -3.0023317337036133
Batch 19/64 loss: -2.6982927322387695
Batch 20/64 loss: -2.341324806213379
Batch 21/64 loss: -2.9773759841918945
Batch 22/64 loss: -2.9346771240234375
Batch 23/64 loss: -2.6568241119384766
Batch 24/64 loss: -3.033651351928711
Batch 25/64 loss: -2.65228271484375
Batch 26/64 loss: -2.4695873260498047
Batch 27/64 loss: -2.5066585540771484
Batch 28/64 loss: -1.9273929595947266
Batch 29/64 loss: -3.0541610717773438
Batch 30/64 loss: -2.9021310806274414
Batch 31/64 loss: -2.920475959777832
Batch 32/64 loss: -2.367861747741699
Batch 33/64 loss: -2.79160213470459
Batch 34/64 loss: -3.02687931060791
Batch 35/64 loss: -2.8138017654418945
Batch 36/64 loss: -3.08236026763916
Batch 37/64 loss: -2.8994140625
Batch 38/64 loss: -2.693118095397949
Batch 39/64 loss: -3.0532941818237305
Batch 40/64 loss: -3.0502586364746094
Batch 41/64 loss: -2.909745216369629
Batch 42/64 loss: -2.9222850799560547
Batch 43/64 loss: -3.007878303527832
Batch 44/64 loss: -3.0956802368164062
Batch 45/64 loss: -3.013458251953125
Batch 46/64 loss: -3.0155811309814453
Batch 47/64 loss: -2.8168039321899414
Batch 48/64 loss: -2.893754005432129
Batch 49/64 loss: -3.252455711364746
Batch 50/64 loss: -2.432623863220215
Batch 51/64 loss: -3.1123409271240234
Batch 52/64 loss: -3.0506649017333984
Batch 53/64 loss: -3.055171012878418
Batch 54/64 loss: -2.1441993713378906
Batch 55/64 loss: -3.0384140014648438
Batch 56/64 loss: -2.9555740356445312
Batch 57/64 loss: -2.842313766479492
Batch 58/64 loss: -2.829075813293457
Batch 59/64 loss: -2.820751190185547
Batch 60/64 loss: -2.509817123413086
Batch 61/64 loss: -3.1221532821655273
Batch 62/64 loss: -2.840984344482422
Batch 63/64 loss: -3.0539655685424805
Batch 64/64 loss: -7.798849105834961
Epoch 128  Train loss: -2.9476415372362323  Val loss: -2.8581638008458508
Epoch 129
-------------------------------
Batch 1/64 loss: -3.014913558959961
Batch 2/64 loss: -2.756175994873047
Batch 3/64 loss: -2.9213876724243164
Batch 4/64 loss: -3.004608154296875
Batch 5/64 loss: -2.4743223190307617
Batch 6/64 loss: -2.9317760467529297
Batch 7/64 loss: -3.1153316497802734
Batch 8/64 loss: -2.862661361694336
Batch 9/64 loss: -2.6621809005737305
Batch 10/64 loss: -3.102381706237793
Batch 11/64 loss: -2.880133628845215
Batch 12/64 loss: -2.7933740615844727
Batch 13/64 loss: -3.032308578491211
Batch 14/64 loss: -2.9920215606689453
Batch 15/64 loss: -3.0020456314086914
Batch 16/64 loss: -2.609036445617676
Batch 17/64 loss: -3.052790641784668
Batch 18/64 loss: -3.0246639251708984
Batch 19/64 loss: -3.0820417404174805
Batch 20/64 loss: -2.953494071960449
Batch 21/64 loss: -2.9861793518066406
Batch 22/64 loss: -3.3312997817993164
Batch 23/64 loss: -2.949861526489258
Batch 24/64 loss: -3.3318309783935547
Batch 25/64 loss: -2.9974288940429688
Batch 26/64 loss: -3.2355499267578125
Batch 27/64 loss: -3.0645132064819336
Batch 28/64 loss: -3.184764862060547
Batch 29/64 loss: -3.012197494506836
Batch 30/64 loss: -3.2180957794189453
Batch 31/64 loss: -2.5049543380737305
Batch 32/64 loss: -2.9303207397460938
Batch 33/64 loss: -3.011432647705078
Batch 34/64 loss: -2.7299747467041016
Batch 35/64 loss: -2.9163990020751953
Batch 36/64 loss: -2.803797721862793
Batch 37/64 loss: -2.9663171768188477
Batch 38/64 loss: -2.9191036224365234
Batch 39/64 loss: -3.135531425476074
Batch 40/64 loss: -3.027594566345215
Batch 41/64 loss: -3.0280847549438477
Batch 42/64 loss: -2.9865283966064453
Batch 43/64 loss: -2.9920177459716797
Batch 44/64 loss: -2.6699581146240234
Batch 45/64 loss: -2.253894805908203
Batch 46/64 loss: -3.210712432861328
Batch 47/64 loss: -2.7702112197875977
Batch 48/64 loss: -3.1431169509887695
Batch 49/64 loss: -3.2881412506103516
Batch 50/64 loss: -2.841586112976074
Batch 51/64 loss: -3.0695791244506836
Batch 52/64 loss: -2.904189109802246
Batch 53/64 loss: -2.9980459213256836
Batch 54/64 loss: -2.8379507064819336
Batch 55/64 loss: -3.040350914001465
Batch 56/64 loss: -3.093256950378418
Batch 57/64 loss: -2.9310102462768555
Batch 58/64 loss: -2.886990547180176
Batch 59/64 loss: -2.688857078552246
Batch 60/64 loss: -3.1470584869384766
Batch 61/64 loss: -3.0756664276123047
Batch 62/64 loss: -3.191974639892578
Batch 63/64 loss: -3.1027135848999023
Batch 64/64 loss: -7.009910583496094
Epoch 129  Train loss: -3.010731386670879  Val loss: -3.1969980718343938
Epoch 130
-------------------------------
Batch 1/64 loss: -3.14615535736084
Batch 2/64 loss: -2.9135398864746094
Batch 3/64 loss: -3.200084686279297
Batch 4/64 loss: -2.7012014389038086
Batch 5/64 loss: -3.0406570434570312
Batch 6/64 loss: -3.0432281494140625
Batch 7/64 loss: -2.832852363586426
Batch 8/64 loss: -2.846752166748047
Batch 9/64 loss: -2.850217819213867
Batch 10/64 loss: -3.035860061645508
Batch 11/64 loss: -3.308950424194336
Batch 12/64 loss: -2.628291130065918
Batch 13/64 loss: -3.099246025085449
Batch 14/64 loss: -3.012216567993164
Batch 15/64 loss: -3.219658851623535
Batch 16/64 loss: -3.105386734008789
Batch 17/64 loss: -3.0693864822387695
Batch 18/64 loss: -3.1407699584960938
Batch 19/64 loss: -3.069622039794922
Batch 20/64 loss: -2.826603889465332
Batch 21/64 loss: -3.2697906494140625
Batch 22/64 loss: -3.14919376373291
Batch 23/64 loss: -3.066793441772461
Batch 24/64 loss: -3.243389129638672
Batch 25/64 loss: -2.6025047302246094
Batch 26/64 loss: -3.160888671875
Batch 27/64 loss: -2.8489990234375
Batch 28/64 loss: -3.031566619873047
Batch 29/64 loss: -2.571146011352539
Batch 30/64 loss: -3.2511377334594727
Batch 31/64 loss: -3.0926513671875
Batch 32/64 loss: -2.8789567947387695
Batch 33/64 loss: -2.876758575439453
Batch 34/64 loss: -2.764956474304199
Batch 35/64 loss: -3.1118040084838867
Batch 36/64 loss: -2.6350412368774414
Batch 37/64 loss: -3.1058292388916016
Batch 38/64 loss: -3.0084457397460938
Batch 39/64 loss: -3.0006494522094727
Batch 40/64 loss: -2.8001785278320312
Batch 41/64 loss: -3.030254364013672
Batch 42/64 loss: -2.3687973022460938
Batch 43/64 loss: -3.27447509765625
Batch 44/64 loss: -3.0018014907836914
Batch 45/64 loss: -2.9880733489990234
Batch 46/64 loss: -3.011150360107422
Batch 47/64 loss: -2.8436450958251953
Batch 48/64 loss: -3.0795955657958984
Batch 49/64 loss: -2.7192182540893555
Batch 50/64 loss: -2.848611831665039
Batch 51/64 loss: -2.956009864807129
Batch 52/64 loss: -2.56339168548584
Batch 53/64 loss: -2.570784568786621
Batch 54/64 loss: -3.160923957824707
Batch 55/64 loss: -3.0248584747314453
Batch 56/64 loss: -3.1898393630981445
Batch 57/64 loss: -2.796401023864746
Batch 58/64 loss: -2.6570558547973633
Batch 59/64 loss: -3.116469383239746
Batch 60/64 loss: -2.012714385986328
Batch 61/64 loss: -2.5952959060668945
Batch 62/64 loss: -2.815110206604004
Batch 63/64 loss: -2.5205764770507812
Batch 64/64 loss: -7.658963680267334
Epoch 130  Train loss: -2.9874610022002575  Val loss: -3.230062596167076
Epoch 131
-------------------------------
Batch 1/64 loss: -3.040678024291992
Batch 2/64 loss: -2.622910499572754
Batch 3/64 loss: -2.97589111328125
Batch 4/64 loss: -3.0580196380615234
Batch 5/64 loss: -2.2613744735717773
Batch 6/64 loss: -2.884322166442871
Batch 7/64 loss: -3.094407081604004
Batch 8/64 loss: -2.8950586318969727
Batch 9/64 loss: -3.1229257583618164
Batch 10/64 loss: -3.2295942306518555
Batch 11/64 loss: -3.092465400695801
Batch 12/64 loss: -3.012859344482422
Batch 13/64 loss: -3.1277503967285156
Batch 14/64 loss: -2.2996253967285156
Batch 15/64 loss: -2.9887733459472656
Batch 16/64 loss: -2.9493932723999023
Batch 17/64 loss: -2.372483253479004
Batch 18/64 loss: -2.3518505096435547
Batch 19/64 loss: -2.243623733520508
Batch 20/64 loss: -3.1609363555908203
Batch 21/64 loss: -3.284576416015625
Batch 22/64 loss: -2.9527587890625
Batch 23/64 loss: -2.9659643173217773
Batch 24/64 loss: -2.934886932373047
Batch 25/64 loss: -2.998866081237793
Batch 26/64 loss: -2.8080406188964844
Batch 27/64 loss: -2.71707820892334
Batch 28/64 loss: -2.5376062393188477
Batch 29/64 loss: -2.6445112228393555
Batch 30/64 loss: -2.5584945678710938
Batch 31/64 loss: -2.809377670288086
Batch 32/64 loss: -2.8565235137939453
Batch 33/64 loss: -3.0316171646118164
Batch 34/64 loss: -3.0643177032470703
Batch 35/64 loss: -2.759182929992676
Batch 36/64 loss: -3.0297470092773438
Batch 37/64 loss: -2.3795127868652344
Batch 38/64 loss: -2.952986717224121
Batch 39/64 loss: -2.895610809326172
Batch 40/64 loss: -2.6990060806274414
Batch 41/64 loss: -3.0798959732055664
Batch 42/64 loss: -3.1018619537353516
Batch 43/64 loss: -2.6991348266601562
Batch 44/64 loss: -3.0154943466186523
Batch 45/64 loss: -3.0566463470458984
Batch 46/64 loss: -2.850881576538086
Batch 47/64 loss: -2.8590517044067383
Batch 48/64 loss: -2.826296806335449
Batch 49/64 loss: -3.0217533111572266
Batch 50/64 loss: -2.6894798278808594
Batch 51/64 loss: -2.822784423828125
Batch 52/64 loss: -2.8531789779663086
Batch 53/64 loss: -2.815765380859375
Batch 54/64 loss: -2.6474313735961914
Batch 55/64 loss: -2.940676689147949
Batch 56/64 loss: -3.0260486602783203
Batch 57/64 loss: -2.95119571685791
Batch 58/64 loss: -2.5963315963745117
Batch 59/64 loss: -2.9788341522216797
Batch 60/64 loss: -2.7234153747558594
Batch 61/64 loss: -3.010453224182129
Batch 62/64 loss: -2.7811460494995117
Batch 63/64 loss: -2.934774398803711
Batch 64/64 loss: -7.359011650085449
Epoch 131  Train loss: -2.9092925464405734  Val loss: -3.20941561931597
Epoch 132
-------------------------------
Batch 1/64 loss: -3.081249237060547
Batch 2/64 loss: -2.893718719482422
Batch 3/64 loss: -2.7202224731445312
Batch 4/64 loss: -3.1370058059692383
Batch 5/64 loss: -2.8076791763305664
Batch 6/64 loss: -2.9903345108032227
Batch 7/64 loss: -2.979734420776367
Batch 8/64 loss: -2.965557098388672
Batch 9/64 loss: -2.8118362426757812
Batch 10/64 loss: -3.0386104583740234
Batch 11/64 loss: -2.438939094543457
Batch 12/64 loss: -2.9164819717407227
Batch 13/64 loss: -2.725332260131836
Batch 14/64 loss: -2.9377832412719727
Batch 15/64 loss: -3.2810840606689453
Batch 16/64 loss: -2.690300941467285
Batch 17/64 loss: -3.0491695404052734
Batch 18/64 loss: -3.0734329223632812
Batch 19/64 loss: -3.1489248275756836
Batch 20/64 loss: -2.7353649139404297
Batch 21/64 loss: -3.1061267852783203
Batch 22/64 loss: -1.9936132431030273
Batch 23/64 loss: -2.8515453338623047
Batch 24/64 loss: -3.0127973556518555
Batch 25/64 loss: -2.891604423522949
Batch 26/64 loss: -3.0252761840820312
Batch 27/64 loss: -2.9978151321411133
Batch 28/64 loss: -2.8184738159179688
Batch 29/64 loss: -3.132312774658203
Batch 30/64 loss: -2.8639984130859375
Batch 31/64 loss: -2.8381223678588867
Batch 32/64 loss: -2.157073974609375
Batch 33/64 loss: -2.616072654724121
Batch 34/64 loss: -2.706841468811035
Batch 35/64 loss: -2.9375133514404297
Batch 36/64 loss: -2.8883790969848633
Batch 37/64 loss: -2.9807538986206055
Batch 38/64 loss: -2.6014013290405273
Batch 39/64 loss: -3.0057802200317383
Batch 40/64 loss: -2.932610511779785
Batch 41/64 loss: -2.426009178161621
Batch 42/64 loss: -3.0228710174560547
Batch 43/64 loss: -2.7966394424438477
Batch 44/64 loss: -2.8732919692993164
Batch 45/64 loss: -2.8362865447998047
Batch 46/64 loss: -2.717113494873047
Batch 47/64 loss: -2.89711856842041
Batch 48/64 loss: -2.6495132446289062
Batch 49/64 loss: -2.882643699645996
Batch 50/64 loss: -3.0299901962280273
Batch 51/64 loss: -2.8365936279296875
Batch 52/64 loss: -3.0975990295410156
Batch 53/64 loss: -3.253223419189453
Batch 54/64 loss: -2.8023757934570312
Batch 55/64 loss: -3.0995826721191406
Batch 56/64 loss: -2.738614082336426
Batch 57/64 loss: -2.644083023071289
Batch 58/64 loss: -3.0472822189331055
Batch 59/64 loss: -2.9977922439575195
Batch 60/64 loss: -2.9550647735595703
Batch 61/64 loss: -2.9883365631103516
Batch 62/64 loss: -2.9497289657592773
Batch 63/64 loss: -2.988912582397461
Batch 64/64 loss: -7.322957992553711
Epoch 132  Train loss: -2.930255044675341  Val loss: -3.169027859402686
Epoch 133
-------------------------------
Batch 1/64 loss: -2.905355453491211
Batch 2/64 loss: -2.985157012939453
Batch 3/64 loss: -3.0835065841674805
Batch 4/64 loss: -2.9598684310913086
Batch 5/64 loss: -2.84005069732666
Batch 6/64 loss: -2.9867563247680664
Batch 7/64 loss: -2.846548080444336
Batch 8/64 loss: -3.0682783126831055
Batch 9/64 loss: -3.036775588989258
Batch 10/64 loss: -2.961215019226074
Batch 11/64 loss: -2.9838171005249023
Batch 12/64 loss: -3.194441795349121
Batch 13/64 loss: -2.915904998779297
Batch 14/64 loss: -3.046584129333496
Batch 15/64 loss: -3.083984375
Batch 16/64 loss: -2.3823776245117188
Batch 17/64 loss: -2.8695764541625977
Batch 18/64 loss: -3.0906295776367188
Batch 19/64 loss: -2.453444480895996
Batch 20/64 loss: -3.1447982788085938
Batch 21/64 loss: -3.045886993408203
Batch 22/64 loss: -3.037693977355957
Batch 23/64 loss: -3.1168365478515625
Batch 24/64 loss: -2.9340667724609375
Batch 25/64 loss: -2.7577295303344727
Batch 26/64 loss: -3.1553831100463867
Batch 27/64 loss: -2.9064149856567383
Batch 28/64 loss: -2.96319580078125
Batch 29/64 loss: -2.4145097732543945
Batch 30/64 loss: -3.0662460327148438
Batch 31/64 loss: -2.972233772277832
Batch 32/64 loss: -2.8783254623413086
Batch 33/64 loss: -2.850184440612793
Batch 34/64 loss: -2.8270397186279297
Batch 35/64 loss: -2.857659339904785
Batch 36/64 loss: -2.4540510177612305
Batch 37/64 loss: -2.9200878143310547
Batch 38/64 loss: -2.5241785049438477
Batch 39/64 loss: -3.037407875061035
Batch 40/64 loss: -2.7875776290893555
Batch 41/64 loss: -3.1458663940429688
Batch 42/64 loss: -3.075674057006836
Batch 43/64 loss: -2.967571258544922
Batch 44/64 loss: -2.848252296447754
Batch 45/64 loss: -3.101578712463379
Batch 46/64 loss: -2.978557586669922
Batch 47/64 loss: -2.9946041107177734
Batch 48/64 loss: -2.53635311126709
Batch 49/64 loss: -3.2464752197265625
Batch 50/64 loss: -2.723252296447754
Batch 51/64 loss: -3.246479034423828
Batch 52/64 loss: -3.028569221496582
Batch 53/64 loss: -3.108325958251953
Batch 54/64 loss: -2.963621139526367
Batch 55/64 loss: -3.0374250411987305
Batch 56/64 loss: -2.8620920181274414
Batch 57/64 loss: -3.0709657669067383
Batch 58/64 loss: -2.9878721237182617
Batch 59/64 loss: -2.465749740600586
Batch 60/64 loss: -2.7659168243408203
Batch 61/64 loss: -3.0750579833984375
Batch 62/64 loss: -3.070021629333496
Batch 63/64 loss: -2.5864810943603516
Batch 64/64 loss: -7.813248157501221
Epoch 133  Train loss: -2.98184279460533  Val loss: -3.1691010858594755
Epoch 134
-------------------------------
Batch 1/64 loss: -2.9816112518310547
Batch 2/64 loss: -1.725327491760254
Batch 3/64 loss: -2.926445960998535
Batch 4/64 loss: -3.014505386352539
Batch 5/64 loss: -3.029573440551758
Batch 6/64 loss: -2.9858531951904297
Batch 7/64 loss: -3.212252616882324
Batch 8/64 loss: -3.054553985595703
Batch 9/64 loss: -2.880758285522461
Batch 10/64 loss: -3.1540727615356445
Batch 11/64 loss: -3.3192195892333984
Batch 12/64 loss: -2.8445968627929688
Batch 13/64 loss: -3.1495094299316406
Batch 14/64 loss: -2.709329605102539
Batch 15/64 loss: -2.581563949584961
Batch 16/64 loss: -2.585073471069336
Batch 17/64 loss: -2.876431465148926
Batch 18/64 loss: -3.2462329864501953
Batch 19/64 loss: -2.312594413757324
Batch 20/64 loss: -3.226212501525879
Batch 21/64 loss: -2.4940805435180664
Batch 22/64 loss: -2.315699577331543
Batch 23/64 loss: -2.9996023178100586
Batch 24/64 loss: -3.0304641723632812
Batch 25/64 loss: -3.080430030822754
Batch 26/64 loss: -2.951791763305664
Batch 27/64 loss: -3.146453857421875
Batch 28/64 loss: -2.209444999694824
Batch 29/64 loss: -2.743739128112793
Batch 30/64 loss: -2.950789451599121
Batch 31/64 loss: -3.0033931732177734
Batch 32/64 loss: -2.477910041809082
Batch 33/64 loss: -2.765751838684082
Batch 34/64 loss: -3.0441083908081055
Batch 35/64 loss: -2.1926803588867188
Batch 36/64 loss: -2.8436098098754883
Batch 37/64 loss: -2.8121118545532227
Batch 38/64 loss: -3.0560693740844727
Batch 39/64 loss: -3.0099239349365234
Batch 40/64 loss: -2.714890480041504
Batch 41/64 loss: -3.3052940368652344
Batch 42/64 loss: -2.929323196411133
Batch 43/64 loss: -2.893291473388672
Batch 44/64 loss: -3.101644515991211
Batch 45/64 loss: -2.778779983520508
Batch 46/64 loss: -2.992422103881836
Batch 47/64 loss: -2.9489755630493164
Batch 48/64 loss: -2.9424734115600586
Batch 49/64 loss: -2.854762077331543
Batch 50/64 loss: -2.370847702026367
Batch 51/64 loss: -2.7031288146972656
Batch 52/64 loss: -3.168950080871582
Batch 53/64 loss: -2.8458690643310547
Batch 54/64 loss: -3.0126285552978516
Batch 55/64 loss: -2.630274772644043
Batch 56/64 loss: -2.9767942428588867
Batch 57/64 loss: -2.428976058959961
Batch 58/64 loss: -3.0800580978393555
Batch 59/64 loss: -3.0727148056030273
Batch 60/64 loss: -3.127880096435547
Batch 61/64 loss: -2.8979225158691406
Batch 62/64 loss: -2.8443822860717773
Batch 63/64 loss: -2.819699287414551
Batch 64/64 loss: -7.8016037940979
Epoch 134  Train loss: -2.9213640680500106  Val loss: -3.0843243811958025
Epoch 135
-------------------------------
Batch 1/64 loss: -2.8626394271850586
Batch 2/64 loss: -2.44039249420166
Batch 3/64 loss: -3.0124731063842773
Batch 4/64 loss: -3.2599754333496094
Batch 5/64 loss: -2.6509037017822266
Batch 6/64 loss: -2.9055795669555664
Batch 7/64 loss: -3.0661191940307617
Batch 8/64 loss: -2.7192087173461914
Batch 9/64 loss: -2.8025245666503906
Batch 10/64 loss: -2.843210220336914
Batch 11/64 loss: -2.7970008850097656
Batch 12/64 loss: -2.998501777648926
Batch 13/64 loss: -2.771730422973633
Batch 14/64 loss: -3.164057731628418
Batch 15/64 loss: -2.9022464752197266
Batch 16/64 loss: -2.696242332458496
Batch 17/64 loss: -2.913458824157715
Batch 18/64 loss: -2.7729387283325195
Batch 19/64 loss: -2.836030960083008
Batch 20/64 loss: -2.7629642486572266
Batch 21/64 loss: -2.9111948013305664
Batch 22/64 loss: -2.820131301879883
Batch 23/64 loss: -3.0806941986083984
Batch 24/64 loss: -2.356696128845215
Batch 25/64 loss: -2.9500808715820312
Batch 26/64 loss: -3.293790817260742
Batch 27/64 loss: -2.97702693939209
Batch 28/64 loss: -3.1220035552978516
Batch 29/64 loss: -2.92647647857666
Batch 30/64 loss: -2.8443822860717773
Batch 31/64 loss: -2.8130674362182617
Batch 32/64 loss: -3.118109703063965
Batch 33/64 loss: -2.9735403060913086
Batch 34/64 loss: -2.922473907470703
Batch 35/64 loss: -2.9617624282836914
Batch 36/64 loss: -2.795779228210449
Batch 37/64 loss: -2.507168769836426
Batch 38/64 loss: -2.580735206604004
Batch 39/64 loss: -2.898771286010742
Batch 40/64 loss: -2.9680938720703125
Batch 41/64 loss: -2.913553237915039
Batch 42/64 loss: -2.9713191986083984
Batch 43/64 loss: -3.0543432235717773
Batch 44/64 loss: -2.7789840698242188
Batch 45/64 loss: -2.6700305938720703
Batch 46/64 loss: -3.060715675354004
Batch 47/64 loss: -3.1503477096557617
Batch 48/64 loss: -2.9264631271362305
Batch 49/64 loss: -2.9390125274658203
Batch 50/64 loss: -3.132434844970703
Batch 51/64 loss: -3.2869653701782227
Batch 52/64 loss: -2.8275957107543945
Batch 53/64 loss: -2.5279064178466797
Batch 54/64 loss: -3.1014814376831055
Batch 55/64 loss: -2.682180404663086
Batch 56/64 loss: -2.7660083770751953
Batch 57/64 loss: -2.918360710144043
Batch 58/64 loss: -3.1259918212890625
Batch 59/64 loss: -2.8333749771118164
Batch 60/64 loss: -2.9878692626953125
Batch 61/64 loss: -2.7048263549804688
Batch 62/64 loss: -3.1516170501708984
Batch 63/64 loss: -3.15032958984375
Batch 64/64 loss: -7.380534648895264
Epoch 135  Train loss: -2.9521143688875084  Val loss: -3.085713822407411
Epoch 136
-------------------------------
Batch 1/64 loss: -3.0907325744628906
Batch 2/64 loss: -3.1046876907348633
Batch 3/64 loss: -2.5277175903320312
Batch 4/64 loss: -3.29679012298584
Batch 5/64 loss: -3.236819267272949
Batch 6/64 loss: -3.181727409362793
Batch 7/64 loss: -2.9787845611572266
Batch 8/64 loss: -3.2195777893066406
Batch 9/64 loss: -3.2670793533325195
Batch 10/64 loss: -2.446385383605957
Batch 11/64 loss: -2.998673439025879
Batch 12/64 loss: -3.0832347869873047
Batch 13/64 loss: -2.699398994445801
Batch 14/64 loss: -3.0656986236572266
Batch 15/64 loss: -2.915637969970703
Batch 16/64 loss: -3.0901918411254883
Batch 17/64 loss: -3.1342849731445312
Batch 18/64 loss: -2.8984556198120117
Batch 19/64 loss: -2.573275566101074
Batch 20/64 loss: -3.0329666137695312
Batch 21/64 loss: -2.9185705184936523
Batch 22/64 loss: -3.041470527648926
Batch 23/64 loss: -3.0615968704223633
Batch 24/64 loss: -2.6931257247924805
Batch 25/64 loss: -2.9533510208129883
Batch 26/64 loss: -3.143357276916504
Batch 27/64 loss: -2.475663185119629
Batch 28/64 loss: -2.5811939239501953
Batch 29/64 loss: -2.7139997482299805
Batch 30/64 loss: -3.045069694519043
Batch 31/64 loss: -3.054697036743164
Batch 32/64 loss: -3.055527687072754
Batch 33/64 loss: -2.577359199523926
Batch 34/64 loss: -3.0237207412719727
Batch 35/64 loss: -2.928464889526367
Batch 36/64 loss: -3.1170692443847656
Batch 37/64 loss: -3.211625099182129
Batch 38/64 loss: -2.639164924621582
Batch 39/64 loss: -3.002852439880371
Batch 40/64 loss: -2.8832950592041016
Batch 41/64 loss: -2.9131994247436523
Batch 42/64 loss: -2.9514522552490234
Batch 43/64 loss: -3.0474557876586914
Batch 44/64 loss: -2.581228256225586
Batch 45/64 loss: -2.89914608001709
Batch 46/64 loss: -2.468170166015625
Batch 47/64 loss: -2.68093204498291
Batch 48/64 loss: -2.998459815979004
Batch 49/64 loss: -3.0098438262939453
Batch 50/64 loss: -2.5640172958374023
Batch 51/64 loss: -3.0323610305786133
Batch 52/64 loss: -2.9979848861694336
Batch 53/64 loss: -3.1142520904541016
Batch 54/64 loss: -2.476752281188965
Batch 55/64 loss: -2.918149948120117
Batch 56/64 loss: -2.985403060913086
Batch 57/64 loss: -3.1213340759277344
Batch 58/64 loss: -3.061091423034668
Batch 59/64 loss: -3.0063133239746094
Batch 60/64 loss: -2.868960380554199
Batch 61/64 loss: -2.9617834091186523
Batch 62/64 loss: -1.7638568878173828
Batch 63/64 loss: -2.812704086303711
Batch 64/64 loss: -7.748990058898926
Epoch 136  Train loss: -2.9648610096351775  Val loss: -3.054752284308889
Epoch 137
-------------------------------
Batch 1/64 loss: -2.6096363067626953
Batch 2/64 loss: -3.1841907501220703
Batch 3/64 loss: -2.6557579040527344
Batch 4/64 loss: -2.4638118743896484
Batch 5/64 loss: -2.9855947494506836
Batch 6/64 loss: -2.6720829010009766
Batch 7/64 loss: -2.754209518432617
Batch 8/64 loss: -2.927692413330078
Batch 9/64 loss: -2.1985645294189453
Batch 10/64 loss: -3.1976099014282227
Batch 11/64 loss: -2.948418617248535
Batch 12/64 loss: -3.1038589477539062
Batch 13/64 loss: -3.109461784362793
Batch 14/64 loss: -2.739230155944824
Batch 15/64 loss: -3.162504196166992
Batch 16/64 loss: -3.2015438079833984
Batch 17/64 loss: -2.890188217163086
Batch 18/64 loss: -2.801786422729492
Batch 19/64 loss: -2.9464492797851562
Batch 20/64 loss: -3.069002151489258
Batch 21/64 loss: -2.635286331176758
Batch 22/64 loss: -3.1946287155151367
Batch 23/64 loss: -2.9780616760253906
Batch 24/64 loss: -3.222726821899414
Batch 25/64 loss: -2.865473747253418
Batch 26/64 loss: -3.069392204284668
Batch 27/64 loss: -2.8443965911865234
Batch 28/64 loss: -2.779531478881836
Batch 29/64 loss: -3.0964059829711914
Batch 30/64 loss: -3.0356321334838867
Batch 31/64 loss: -2.831644058227539
Batch 32/64 loss: -3.0097475051879883
Batch 33/64 loss: -2.979231834411621
Batch 34/64 loss: -2.9802818298339844
Batch 35/64 loss: -2.9054975509643555
Batch 36/64 loss: -3.015252113342285
Batch 37/64 loss: -2.8600053787231445
Batch 38/64 loss: -3.2506837844848633
Batch 39/64 loss: -2.599956512451172
Batch 40/64 loss: -3.09622859954834
Batch 41/64 loss: -2.691925048828125
Batch 42/64 loss: -3.2699804306030273
Batch 43/64 loss: -2.6116113662719727
Batch 44/64 loss: -2.7710189819335938
Batch 45/64 loss: -3.017305374145508
Batch 46/64 loss: -2.859302520751953
Batch 47/64 loss: -2.9556636810302734
Batch 48/64 loss: -3.0704803466796875
Batch 49/64 loss: -3.066638946533203
Batch 50/64 loss: -2.9161853790283203
Batch 51/64 loss: -2.866363525390625
Batch 52/64 loss: -3.0780391693115234
Batch 53/64 loss: -3.207986831665039
Batch 54/64 loss: -3.022245407104492
Batch 55/64 loss: -2.994997978210449
Batch 56/64 loss: -2.729776382446289
Batch 57/64 loss: -2.904478073120117
Batch 58/64 loss: -3.1184301376342773
Batch 59/64 loss: -3.017698287963867
Batch 60/64 loss: -3.194260597229004
Batch 61/64 loss: -2.8177289962768555
Batch 62/64 loss: -2.9559946060180664
Batch 63/64 loss: -3.0401878356933594
Batch 64/64 loss: -7.787539482116699
Epoch 137  Train loss: -2.994362569322773  Val loss: -3.109843106613946
Epoch 138
-------------------------------
Batch 1/64 loss: -3.1891727447509766
Batch 2/64 loss: -2.879378318786621
Batch 3/64 loss: -3.1172914505004883
Batch 4/64 loss: -2.8594980239868164
Batch 5/64 loss: -2.7104129791259766
Batch 6/64 loss: -3.1071348190307617
Batch 7/64 loss: -2.830289840698242
Batch 8/64 loss: -3.2150354385375977
Batch 9/64 loss: -3.0337696075439453
Batch 10/64 loss: -2.9264745712280273
Batch 11/64 loss: -2.7038841247558594
Batch 12/64 loss: -2.537569046020508
Batch 13/64 loss: -3.1905393600463867
Batch 14/64 loss: -2.712191581726074
Batch 15/64 loss: -2.923280715942383
Batch 16/64 loss: -3.0686044692993164
Batch 17/64 loss: -3.073261260986328
Batch 18/64 loss: -3.048938751220703
Batch 19/64 loss: -3.0173254013061523
Batch 20/64 loss: -3.208308219909668
Batch 21/64 loss: -3.012418746948242
Batch 22/64 loss: -3.063535690307617
Batch 23/64 loss: -2.960437774658203
Batch 24/64 loss: -2.945244789123535
Batch 25/64 loss: -2.922891616821289
Batch 26/64 loss: -3.0200977325439453
Batch 27/64 loss: -2.665194511413574
Batch 28/64 loss: -3.224578857421875
Batch 29/64 loss: -3.0423622131347656
Batch 30/64 loss: -2.4683427810668945
Batch 31/64 loss: -2.9785709381103516
Batch 32/64 loss: -2.7428503036499023
Batch 33/64 loss: -3.236295700073242
Batch 34/64 loss: -3.163768768310547
Batch 35/64 loss: -2.4442930221557617
Batch 36/64 loss: -3.0137710571289062
Batch 37/64 loss: -3.041226387023926
Batch 38/64 loss: -2.4982166290283203
Batch 39/64 loss: -3.0963430404663086
Batch 40/64 loss: -2.9023189544677734
Batch 41/64 loss: -2.6737403869628906
Batch 42/64 loss: -2.985398292541504
Batch 43/64 loss: -3.168656349182129
Batch 44/64 loss: -3.0860061645507812
Batch 45/64 loss: -2.991455078125
Batch 46/64 loss: -3.0442514419555664
Batch 47/64 loss: -2.8958492279052734
Batch 48/64 loss: -3.136929512023926
Batch 49/64 loss: -2.963329315185547
Batch 50/64 loss: -3.0511341094970703
Batch 51/64 loss: -2.224562644958496
Batch 52/64 loss: -2.8138227462768555
Batch 53/64 loss: -2.552112579345703
Batch 54/64 loss: -2.92559814453125
Batch 55/64 loss: -3.2292251586914062
Batch 56/64 loss: -3.0804052352905273
Batch 57/64 loss: -3.061361312866211
Batch 58/64 loss: -3.0846691131591797
Batch 59/64 loss: -2.6924009323120117
Batch 60/64 loss: -3.3958606719970703
Batch 61/64 loss: -3.026566505432129
Batch 62/64 loss: -3.241464614868164
Batch 63/64 loss: -3.060286521911621
Batch 64/64 loss: -7.811312675476074
Epoch 138  Train loss: -3.0123716204774147  Val loss: -3.1405536481195298
Epoch 139
-------------------------------
Batch 1/64 loss: -2.808504104614258
Batch 2/64 loss: -3.056428909301758
Batch 3/64 loss: -3.0072994232177734
Batch 4/64 loss: -3.250558853149414
Batch 5/64 loss: -3.0741519927978516
Batch 6/64 loss: -3.1345014572143555
Batch 7/64 loss: -3.034041404724121
Batch 8/64 loss: -3.1397743225097656
Batch 9/64 loss: -3.291459083557129
Batch 10/64 loss: -2.872065544128418
Batch 11/64 loss: -2.53507137298584
Batch 12/64 loss: -2.9399852752685547
Batch 13/64 loss: -3.127767562866211
Batch 14/64 loss: -2.650895118713379
Batch 15/64 loss: -2.9679441452026367
Batch 16/64 loss: -2.6456375122070312
Batch 17/64 loss: -3.1396799087524414
Batch 18/64 loss: -3.147782325744629
Batch 19/64 loss: -3.020817756652832
Batch 20/64 loss: -3.111870765686035
Batch 21/64 loss: -3.128207206726074
Batch 22/64 loss: -3.0350732803344727
Batch 23/64 loss: -3.1066884994506836
Batch 24/64 loss: -2.8395919799804688
Batch 25/64 loss: -3.1625518798828125
Batch 26/64 loss: -2.5533370971679688
Batch 27/64 loss: -3.0461864471435547
Batch 28/64 loss: -3.1157960891723633
Batch 29/64 loss: -2.7930030822753906
Batch 30/64 loss: -2.754606246948242
Batch 31/64 loss: -2.842618942260742
Batch 32/64 loss: -2.927617073059082
Batch 33/64 loss: -2.7496824264526367
Batch 34/64 loss: -3.402590751647949
Batch 35/64 loss: -2.8627500534057617
Batch 36/64 loss: -2.7623090744018555
Batch 37/64 loss: -3.0435562133789062
Batch 38/64 loss: -2.4675798416137695
Batch 39/64 loss: -2.736344337463379
Batch 40/64 loss: -3.0029497146606445
Batch 41/64 loss: -2.655731201171875
Batch 42/64 loss: -2.9088134765625
Batch 43/64 loss: -3.0274858474731445
Batch 44/64 loss: -2.8815221786499023
Batch 45/64 loss: -3.0898895263671875
Batch 46/64 loss: -2.9158525466918945
Batch 47/64 loss: -3.1216115951538086
Batch 48/64 loss: -3.0651302337646484
Batch 49/64 loss: -2.8277225494384766
Batch 50/64 loss: -2.9128503799438477
Batch 51/64 loss: -2.9651832580566406
Batch 52/64 loss: -3.060664176940918
Batch 53/64 loss: -3.011514663696289
Batch 54/64 loss: -2.9168739318847656
Batch 55/64 loss: -3.155426025390625
Batch 56/64 loss: -2.7432327270507812
Batch 57/64 loss: -2.917560577392578
Batch 58/64 loss: -3.266725540161133
Batch 59/64 loss: -2.815654754638672
Batch 60/64 loss: -3.017331123352051
Batch 61/64 loss: -3.306682586669922
Batch 62/64 loss: -3.161653518676758
Batch 63/64 loss: -2.9148406982421875
Batch 64/64 loss: -7.914706707000732
Epoch 139  Train loss: -3.0256511407739977  Val loss: -3.2368753570871256
Epoch 140
-------------------------------
Batch 1/64 loss: -2.9896411895751953
Batch 2/64 loss: -3.1324901580810547
Batch 3/64 loss: -2.9715356826782227
Batch 4/64 loss: -3.2068471908569336
Batch 5/64 loss: -3.275712013244629
Batch 6/64 loss: -3.02353572845459
Batch 7/64 loss: -3.184833526611328
Batch 8/64 loss: -1.881485939025879
Batch 9/64 loss: -2.454824447631836
Batch 10/64 loss: -3.1200761795043945
Batch 11/64 loss: -3.081793785095215
Batch 12/64 loss: -3.0226192474365234
Batch 13/64 loss: -2.965768814086914
Batch 14/64 loss: -2.5627613067626953
Batch 15/64 loss: -2.975703239440918
Batch 16/64 loss: -2.828110694885254
Batch 17/64 loss: -3.096308708190918
Batch 18/64 loss: -3.0590877532958984
Batch 19/64 loss: -2.975092887878418
Batch 20/64 loss: -2.4683008193969727
Batch 21/64 loss: -3.187006950378418
Batch 22/64 loss: -3.1532421112060547
Batch 23/64 loss: -3.0253562927246094
Batch 24/64 loss: -3.2247848510742188
Batch 25/64 loss: -3.181643486022949
Batch 26/64 loss: -3.1407947540283203
Batch 27/64 loss: -3.223404884338379
Batch 28/64 loss: -3.0159788131713867
Batch 29/64 loss: -3.0756664276123047
Batch 30/64 loss: -2.897310256958008
Batch 31/64 loss: -2.961747169494629
Batch 32/64 loss: -2.638216018676758
Batch 33/64 loss: -2.8892030715942383
Batch 34/64 loss: -2.997255325317383
Batch 35/64 loss: -2.879179000854492
Batch 36/64 loss: -3.093128204345703
Batch 37/64 loss: -3.3434314727783203
Batch 38/64 loss: -3.141542434692383
Batch 39/64 loss: -3.045027732849121
Batch 40/64 loss: -3.211663246154785
Batch 41/64 loss: -2.885618209838867
Batch 42/64 loss: -3.332204818725586
Batch 43/64 loss: -2.833346366882324
Batch 44/64 loss: -2.902463912963867
Batch 45/64 loss: -2.856363296508789
Batch 46/64 loss: -3.265289306640625
Batch 47/64 loss: -3.3262271881103516
Batch 48/64 loss: -3.181241035461426
Batch 49/64 loss: -3.0990238189697266
Batch 50/64 loss: -3.172304153442383
Batch 51/64 loss: -2.9593582153320312
Batch 52/64 loss: -2.754110336303711
Batch 53/64 loss: -3.2114505767822266
Batch 54/64 loss: -3.1932926177978516
Batch 55/64 loss: -2.8356447219848633
Batch 56/64 loss: -2.926547050476074
Batch 57/64 loss: -3.155829429626465
Batch 58/64 loss: -2.708603858947754
Batch 59/64 loss: -3.2527246475219727
Batch 60/64 loss: -3.1704721450805664
Batch 61/64 loss: -3.2414560317993164
Batch 62/64 loss: -3.1082048416137695
Batch 63/64 loss: -2.2598886489868164
Batch 64/64 loss: -7.734738349914551
Epoch 140  Train loss: -3.0593698950374826  Val loss: -3.3485954913896383
Saving best model, epoch: 140
Epoch 141
-------------------------------
Batch 1/64 loss: -3.2414960861206055
Batch 2/64 loss: -2.724410057067871
Batch 3/64 loss: -2.888254165649414
Batch 4/64 loss: -3.0587730407714844
Batch 5/64 loss: -2.8632984161376953
Batch 6/64 loss: -3.0674352645874023
Batch 7/64 loss: -3.036264419555664
Batch 8/64 loss: -2.6766319274902344
Batch 9/64 loss: -3.2384986877441406
Batch 10/64 loss: -2.732649803161621
Batch 11/64 loss: -3.044282913208008
Batch 12/64 loss: -3.1444005966186523
Batch 13/64 loss: -3.199087142944336
Batch 14/64 loss: -3.0650386810302734
Batch 15/64 loss: -3.062664031982422
Batch 16/64 loss: -2.9091644287109375
Batch 17/64 loss: -3.2415904998779297
Batch 18/64 loss: -3.104494094848633
Batch 19/64 loss: -3.1731948852539062
Batch 20/64 loss: -2.8628454208374023
Batch 21/64 loss: -3.3123950958251953
Batch 22/64 loss: -3.2912511825561523
Batch 23/64 loss: -2.6807861328125
Batch 24/64 loss: -3.0846548080444336
Batch 25/64 loss: -2.708897590637207
Batch 26/64 loss: -2.9395227432250977
Batch 27/64 loss: -3.0903453826904297
Batch 28/64 loss: -2.8585472106933594
Batch 29/64 loss: -2.911314010620117
Batch 30/64 loss: -3.0366220474243164
Batch 31/64 loss: -3.3202524185180664
Batch 32/64 loss: -2.923227310180664
Batch 33/64 loss: -3.104104995727539
Batch 34/64 loss: -2.9352293014526367
Batch 35/64 loss: -3.2004384994506836
Batch 36/64 loss: -3.001455307006836
Batch 37/64 loss: -2.768589973449707
Batch 38/64 loss: -3.0286731719970703
Batch 39/64 loss: -2.8570737838745117
Batch 40/64 loss: -2.973970413208008
Batch 41/64 loss: -2.892528533935547
Batch 42/64 loss: -2.494813919067383
Batch 43/64 loss: -3.0292224884033203
Batch 44/64 loss: -2.620560646057129
Batch 45/64 loss: -2.0156688690185547
Batch 46/64 loss: -2.8121280670166016
Batch 47/64 loss: -2.875918388366699
Batch 48/64 loss: -3.1985368728637695
Batch 49/64 loss: -2.809032440185547
Batch 50/64 loss: -2.9468202590942383
Batch 51/64 loss: -2.9610557556152344
Batch 52/64 loss: -2.787907600402832
Batch 53/64 loss: -2.998446464538574
Batch 54/64 loss: -1.9496040344238281
Batch 55/64 loss: -2.6345558166503906
Batch 56/64 loss: -2.5283737182617188
Batch 57/64 loss: -2.9835872650146484
Batch 58/64 loss: -2.9404754638671875
Batch 59/64 loss: -3.000629425048828
Batch 60/64 loss: -2.829376220703125
Batch 61/64 loss: -2.7509822845458984
Batch 62/64 loss: -2.7471847534179688
Batch 63/64 loss: -2.9484615325927734
Batch 64/64 loss: -7.426395893096924
Epoch 141  Train loss: -2.9754900969711007  Val loss: -2.9789937468328835
Epoch 142
-------------------------------
Batch 1/64 loss: -2.919404983520508
Batch 2/64 loss: -2.1694459915161133
Batch 3/64 loss: -2.8832578659057617
Batch 4/64 loss: -3.144746780395508
Batch 5/64 loss: -2.270583152770996
Batch 6/64 loss: -2.3607940673828125
Batch 7/64 loss: -2.7880544662475586
Batch 8/64 loss: -2.781916618347168
Batch 9/64 loss: -2.8169727325439453
Batch 10/64 loss: -2.797804832458496
Batch 11/64 loss: -3.2203941345214844
Batch 12/64 loss: -2.7893857955932617
Batch 13/64 loss: -3.1825618743896484
Batch 14/64 loss: -3.0704545974731445
Batch 15/64 loss: -2.7674922943115234
Batch 16/64 loss: -3.097269058227539
Batch 17/64 loss: -2.7456111907958984
Batch 18/64 loss: -2.866708755493164
Batch 19/64 loss: -2.812455177307129
Batch 20/64 loss: -2.8346166610717773
Batch 21/64 loss: -2.5809173583984375
Batch 22/64 loss: -2.726308822631836
Batch 23/64 loss: -2.5212554931640625
Batch 24/64 loss: -2.503171920776367
Batch 25/64 loss: -2.4207916259765625
Batch 26/64 loss: -2.739773750305176
Batch 27/64 loss: -2.670316696166992
Batch 28/64 loss: -2.259463310241699
Batch 29/64 loss: -2.2070436477661133
Batch 30/64 loss: -2.361330986022949
Batch 31/64 loss: -2.3087892532348633
Batch 32/64 loss: -2.9194698333740234
Batch 33/64 loss: -2.8139848709106445
Batch 34/64 loss: -2.6985340118408203
Batch 35/64 loss: -2.080484390258789
Batch 36/64 loss: -2.6791229248046875
Batch 37/64 loss: -3.022152900695801
Batch 38/64 loss: -3.0551843643188477
Batch 39/64 loss: -2.8563690185546875
Batch 40/64 loss: -2.852031707763672
Batch 41/64 loss: -2.894587516784668
Batch 42/64 loss: -2.7927980422973633
Batch 43/64 loss: -2.4672136306762695
Batch 44/64 loss: -2.6259727478027344
Batch 45/64 loss: -2.7498960494995117
Batch 46/64 loss: -3.102694511413574
Batch 47/64 loss: -2.361276626586914
Batch 48/64 loss: -3.003310203552246
Batch 49/64 loss: -2.6568708419799805
Batch 50/64 loss: -2.805209159851074
Batch 51/64 loss: -2.7519683837890625
Batch 52/64 loss: -3.07159423828125
Batch 53/64 loss: -2.3453283309936523
Batch 54/64 loss: -2.835611343383789
Batch 55/64 loss: -3.0056896209716797
Batch 56/64 loss: -3.1533851623535156
Batch 57/64 loss: -3.1215457916259766
Batch 58/64 loss: -2.7597875595092773
Batch 59/64 loss: -2.9920644760131836
Batch 60/64 loss: -2.939824104309082
Batch 61/64 loss: -2.8967552185058594
Batch 62/64 loss: -2.9163875579833984
Batch 63/64 loss: -3.0275392532348633
Batch 64/64 loss: -7.755865097045898
Epoch 142  Train loss: -2.8186766605751186  Val loss: -3.043889075210414
Epoch 143
-------------------------------
Batch 1/64 loss: -2.715700149536133
Batch 2/64 loss: -2.8032360076904297
Batch 3/64 loss: -2.814255714416504
Batch 4/64 loss: -2.8516807556152344
Batch 5/64 loss: -2.715640068054199
Batch 6/64 loss: -2.9876842498779297
Batch 7/64 loss: -3.2597265243530273
Batch 8/64 loss: -3.0440073013305664
Batch 9/64 loss: -2.720090866088867
Batch 10/64 loss: -2.9855804443359375
Batch 11/64 loss: -2.914158821105957
Batch 12/64 loss: -2.8746776580810547
Batch 13/64 loss: -2.7359628677368164
Batch 14/64 loss: -3.0029335021972656
Batch 15/64 loss: -3.0471887588500977
Batch 16/64 loss: -2.8530492782592773
Batch 17/64 loss: -2.65700626373291
Batch 18/64 loss: -3.227998733520508
Batch 19/64 loss: -3.111886978149414
Batch 20/64 loss: -2.8228912353515625
Batch 21/64 loss: -3.2628955841064453
Batch 22/64 loss: -3.032334327697754
Batch 23/64 loss: -2.985353469848633
Batch 24/64 loss: -3.1296234130859375
Batch 25/64 loss: -3.18267822265625
Batch 26/64 loss: -3.22562313079834
Batch 27/64 loss: -3.218576431274414
Batch 28/64 loss: -2.990732192993164
Batch 29/64 loss: -3.1262149810791016
Batch 30/64 loss: -2.6733598709106445
Batch 31/64 loss: -2.773104667663574
Batch 32/64 loss: -3.0166587829589844
Batch 33/64 loss: -3.267679214477539
Batch 34/64 loss: -2.9029035568237305
Batch 35/64 loss: -2.984866142272949
Batch 36/64 loss: -3.0168724060058594
Batch 37/64 loss: -2.9134864807128906
Batch 38/64 loss: -2.2530202865600586
Batch 39/64 loss: -2.632451057434082
Batch 40/64 loss: -2.455233573913574
Batch 41/64 loss: -2.593327522277832
Batch 42/64 loss: -3.055116653442383
Batch 43/64 loss: -2.7127561569213867
Batch 44/64 loss: -2.8065357208251953
Batch 45/64 loss: -2.908550262451172
Batch 46/64 loss: -3.1222991943359375
Batch 47/64 loss: -2.5659542083740234
Batch 48/64 loss: -2.8761186599731445
Batch 49/64 loss: -2.8338193893432617
Batch 50/64 loss: -3.2145776748657227
Batch 51/64 loss: -3.0483570098876953
Batch 52/64 loss: -2.9877967834472656
Batch 53/64 loss: -2.198596954345703
Batch 54/64 loss: -2.998779296875
Batch 55/64 loss: -3.179989814758301
Batch 56/64 loss: -2.3603219985961914
Batch 57/64 loss: -3.233053207397461
Batch 58/64 loss: -2.6953535079956055
Batch 59/64 loss: -2.8940582275390625
Batch 60/64 loss: -3.041910171508789
Batch 61/64 loss: -3.213709831237793
Batch 62/64 loss: -2.8722972869873047
Batch 63/64 loss: -2.6287012100219727
Batch 64/64 loss: -7.600450038909912
Epoch 143  Train loss: -2.9636288979474235  Val loss: -3.0651088072262267
Epoch 144
-------------------------------
Batch 1/64 loss: -2.837800979614258
Batch 2/64 loss: -2.9461793899536133
Batch 3/64 loss: -3.1331300735473633
Batch 4/64 loss: -2.5968446731567383
Batch 5/64 loss: -3.19625186920166
Batch 6/64 loss: -2.974628448486328
Batch 7/64 loss: -2.5762853622436523
Batch 8/64 loss: -2.954226493835449
Batch 9/64 loss: -3.2409772872924805
Batch 10/64 loss: -3.001026153564453
Batch 11/64 loss: -2.8394975662231445
Batch 12/64 loss: -2.441891670227051
Batch 13/64 loss: -2.8035945892333984
Batch 14/64 loss: -2.9223642349243164
Batch 15/64 loss: -3.2184743881225586
Batch 16/64 loss: -3.04581356048584
Batch 17/64 loss: -2.9511070251464844
Batch 18/64 loss: -2.950711250305176
Batch 19/64 loss: -2.6599111557006836
Batch 20/64 loss: -2.937631607055664
Batch 21/64 loss: -3.0379228591918945
Batch 22/64 loss: -3.329151153564453
Batch 23/64 loss: -3.2142791748046875
Batch 24/64 loss: -3.0818967819213867
Batch 25/64 loss: -3.2517614364624023
Batch 26/64 loss: -2.9363107681274414
Batch 27/64 loss: -3.015902519226074
Batch 28/64 loss: -2.827962875366211
Batch 29/64 loss: -3.1514902114868164
Batch 30/64 loss: -3.323042869567871
Batch 31/64 loss: -2.234649658203125
Batch 32/64 loss: -3.155200958251953
Batch 33/64 loss: -2.954620361328125
Batch 34/64 loss: -3.2738075256347656
Batch 35/64 loss: -2.4718236923217773
Batch 36/64 loss: -2.9895858764648438
Batch 37/64 loss: -3.1429901123046875
Batch 38/64 loss: -2.6669368743896484
Batch 39/64 loss: -3.0419864654541016
Batch 40/64 loss: -2.550710678100586
Batch 41/64 loss: -2.925760269165039
Batch 42/64 loss: -3.0355987548828125
Batch 43/64 loss: -2.565126419067383
Batch 44/64 loss: -2.932663917541504
Batch 45/64 loss: -3.0941162109375
Batch 46/64 loss: -3.160663604736328
Batch 47/64 loss: -2.851390838623047
Batch 48/64 loss: -3.0449018478393555
Batch 49/64 loss: -2.9469385147094727
Batch 50/64 loss: -3.1115293502807617
Batch 51/64 loss: -3.2221202850341797
Batch 52/64 loss: -3.0876054763793945
Batch 53/64 loss: -3.041356086730957
Batch 54/64 loss: -2.7497339248657227
Batch 55/64 loss: -3.301772117614746
Batch 56/64 loss: -3.008946418762207
Batch 57/64 loss: -2.877920150756836
Batch 58/64 loss: -3.0393829345703125
Batch 59/64 loss: -3.1505308151245117
Batch 60/64 loss: -2.982097625732422
Batch 61/64 loss: -3.4182472229003906
Batch 62/64 loss: -3.264556884765625
Batch 63/64 loss: -2.891265869140625
Batch 64/64 loss: -7.784496784210205
Epoch 144  Train loss: -3.0340859413146974  Val loss: -3.389360303321655
Saving best model, epoch: 144
Epoch 145
-------------------------------
Batch 1/64 loss: -3.1285085678100586
Batch 2/64 loss: -2.6958694458007812
Batch 3/64 loss: -3.116687774658203
Batch 4/64 loss: -3.2104949951171875
Batch 5/64 loss: -3.113222122192383
Batch 6/64 loss: -3.130962371826172
Batch 7/64 loss: -3.2606401443481445
Batch 8/64 loss: -2.9256038665771484
Batch 9/64 loss: -3.24948787689209
Batch 10/64 loss: -2.990912437438965
Batch 11/64 loss: -3.0277023315429688
Batch 12/64 loss: -3.1876630783081055
Batch 13/64 loss: -2.82651424407959
Batch 14/64 loss: -3.1415224075317383
Batch 15/64 loss: -3.0936279296875
Batch 16/64 loss: -2.700237274169922
Batch 17/64 loss: -2.6052894592285156
Batch 18/64 loss: -3.431192398071289
Batch 19/64 loss: -3.155282974243164
Batch 20/64 loss: -2.929384231567383
Batch 21/64 loss: -3.0723342895507812
Batch 22/64 loss: -2.7744827270507812
Batch 23/64 loss: -2.3171024322509766
Batch 24/64 loss: -3.0729894638061523
Batch 25/64 loss: -3.059208869934082
Batch 26/64 loss: -2.74007511138916
Batch 27/64 loss: -2.976377487182617
Batch 28/64 loss: -2.8522329330444336
Batch 29/64 loss: -3.2693376541137695
Batch 30/64 loss: -2.908757209777832
Batch 31/64 loss: -3.175252914428711
Batch 32/64 loss: -3.289968490600586
Batch 33/64 loss: -3.0366573333740234
Batch 34/64 loss: -3.01959228515625
Batch 35/64 loss: -3.3099536895751953
Batch 36/64 loss: -3.4426698684692383
Batch 37/64 loss: -2.9852046966552734
Batch 38/64 loss: -2.6312828063964844
Batch 39/64 loss: -2.7039432525634766
Batch 40/64 loss: -3.215576171875
Batch 41/64 loss: -3.202418327331543
Batch 42/64 loss: -2.7725324630737305
Batch 43/64 loss: -2.509164810180664
Batch 44/64 loss: -3.1333675384521484
Batch 45/64 loss: -2.9720611572265625
Batch 46/64 loss: -3.1466121673583984
Batch 47/64 loss: -3.0866870880126953
Batch 48/64 loss: -3.0041446685791016
Batch 49/64 loss: -3.228208541870117
Batch 50/64 loss: -2.191253662109375
Batch 51/64 loss: -3.054658889770508
Batch 52/64 loss: -2.9783830642700195
Batch 53/64 loss: -2.8371152877807617
Batch 54/64 loss: -2.730757713317871
Batch 55/64 loss: -3.1255264282226562
Batch 56/64 loss: -3.0732040405273438
Batch 57/64 loss: -3.3470630645751953
Batch 58/64 loss: -2.8524551391601562
Batch 59/64 loss: -2.816213607788086
Batch 60/64 loss: -2.908672332763672
Batch 61/64 loss: -2.76717472076416
Batch 62/64 loss: -2.706035614013672
Batch 63/64 loss: -2.756589889526367
Batch 64/64 loss: -7.944473743438721
Epoch 145  Train loss: -3.0420778218437645  Val loss: -3.320474342791895
Epoch 146
-------------------------------
Batch 1/64 loss: -2.7091188430786133
Batch 2/64 loss: -3.114704132080078
Batch 3/64 loss: -3.0397796630859375
Batch 4/64 loss: -2.9634132385253906
Batch 5/64 loss: -3.1288156509399414
Batch 6/64 loss: -3.199578285217285
Batch 7/64 loss: -3.253978729248047
Batch 8/64 loss: -3.068845748901367
Batch 9/64 loss: -3.014841079711914
Batch 10/64 loss: -3.091947555541992
Batch 11/64 loss: -3.1133337020874023
Batch 12/64 loss: -3.1698131561279297
Batch 13/64 loss: -3.126729965209961
Batch 14/64 loss: -3.079831123352051
Batch 15/64 loss: -2.9904727935791016
Batch 16/64 loss: -3.237569808959961
Batch 17/64 loss: -1.9226760864257812
Batch 18/64 loss: -2.784531593322754
Batch 19/64 loss: -3.1091079711914062
Batch 20/64 loss: -3.158662796020508
Batch 21/64 loss: -2.7716522216796875
Batch 22/64 loss: -2.824443817138672
Batch 23/64 loss: -2.7901992797851562
Batch 24/64 loss: -2.350015640258789
Batch 25/64 loss: -2.8136510848999023
Batch 26/64 loss: -2.883382797241211
Batch 27/64 loss: -3.0413856506347656
Batch 28/64 loss: -2.8429784774780273
Batch 29/64 loss: -2.777040481567383
Batch 30/64 loss: -2.6110239028930664
Batch 31/64 loss: -2.945873260498047
Batch 32/64 loss: -3.1277694702148438
Batch 33/64 loss: -2.770310401916504
Batch 34/64 loss: -3.1186561584472656
Batch 35/64 loss: -3.046945571899414
Batch 36/64 loss: -2.8604917526245117
Batch 37/64 loss: -3.053288459777832
Batch 38/64 loss: -3.0566368103027344
Batch 39/64 loss: -3.0575790405273438
Batch 40/64 loss: -3.076528549194336
Batch 41/64 loss: -3.1826019287109375
Batch 42/64 loss: -2.854252815246582
Batch 43/64 loss: -3.244137763977051
Batch 44/64 loss: -3.2255067825317383
Batch 45/64 loss: -2.8832778930664062
Batch 46/64 loss: -3.157949447631836
Batch 47/64 loss: -3.005250930786133
Batch 48/64 loss: -2.8530960083007812
Batch 49/64 loss: -3.0178585052490234
Batch 50/64 loss: -3.121919631958008
Batch 51/64 loss: -2.9072694778442383
Batch 52/64 loss: -2.874760627746582
Batch 53/64 loss: -3.258607864379883
Batch 54/64 loss: -3.4110050201416016
Batch 55/64 loss: -2.826505661010742
Batch 56/64 loss: -2.8147716522216797
Batch 57/64 loss: -3.224459648132324
Batch 58/64 loss: -3.16912841796875
Batch 59/64 loss: -2.5854949951171875
Batch 60/64 loss: -3.1487369537353516
Batch 61/64 loss: -3.294440269470215
Batch 62/64 loss: -3.245377540588379
Batch 63/64 loss: -3.064141273498535
Batch 64/64 loss: -7.724215507507324
Epoch 146  Train loss: -3.0472363528083353  Val loss: -3.416581917464528
Saving best model, epoch: 146
Epoch 147
-------------------------------
Batch 1/64 loss: -2.7217540740966797
Batch 2/64 loss: -3.0990028381347656
Batch 3/64 loss: -2.8338212966918945
Batch 4/64 loss: -3.1614885330200195
Batch 5/64 loss: -2.783095359802246
Batch 6/64 loss: -3.223173141479492
Batch 7/64 loss: -2.9631729125976562
Batch 8/64 loss: -3.0214672088623047
Batch 9/64 loss: -3.288163185119629
Batch 10/64 loss: -3.257601737976074
Batch 11/64 loss: -2.9642019271850586
Batch 12/64 loss: -2.8678770065307617
Batch 13/64 loss: -2.8909168243408203
Batch 14/64 loss: -3.0138702392578125
Batch 15/64 loss: -3.1646108627319336
Batch 16/64 loss: -3.0893354415893555
Batch 17/64 loss: -3.1542978286743164
Batch 18/64 loss: -3.2568540573120117
Batch 19/64 loss: -2.7659835815429688
Batch 20/64 loss: -3.126741409301758
Batch 21/64 loss: -3.030503273010254
Batch 22/64 loss: -2.884428024291992
Batch 23/64 loss: -3.25247859954834
Batch 24/64 loss: -3.0001630783081055
Batch 25/64 loss: -3.1896591186523438
Batch 26/64 loss: -2.887944221496582
Batch 27/64 loss: -2.923583984375
Batch 28/64 loss: -3.4541139602661133
Batch 29/64 loss: -3.285323143005371
Batch 30/64 loss: -3.019547462463379
Batch 31/64 loss: -3.2555742263793945
Batch 32/64 loss: -3.1791677474975586
Batch 33/64 loss: -3.253525733947754
Batch 34/64 loss: -2.9083166122436523
Batch 35/64 loss: -2.9532508850097656
Batch 36/64 loss: -3.367504119873047
Batch 37/64 loss: -2.9355735778808594
Batch 38/64 loss: -2.6024484634399414
Batch 39/64 loss: -3.16092586517334
Batch 40/64 loss: -3.421137809753418
Batch 41/64 loss: -3.0927162170410156
Batch 42/64 loss: -3.2822561264038086
Batch 43/64 loss: -3.3539886474609375
Batch 44/64 loss: -3.173893928527832
Batch 45/64 loss: -3.058481216430664
Batch 46/64 loss: -2.687930107116699
Batch 47/64 loss: -3.3275890350341797
Batch 48/64 loss: -2.9695358276367188
Batch 49/64 loss: -3.205166816711426
Batch 50/64 loss: -3.1929798126220703
Batch 51/64 loss: -3.284576416015625
Batch 52/64 loss: -2.8000802993774414
Batch 53/64 loss: -3.1896305084228516
Batch 54/64 loss: -3.2325010299682617
Batch 55/64 loss: -2.6564865112304688
Batch 56/64 loss: -3.1972808837890625
Batch 57/64 loss: -3.1076889038085938
Batch 58/64 loss: -3.082124710083008
Batch 59/64 loss: -2.810171127319336
Batch 60/64 loss: -3.1058883666992188
Batch 61/64 loss: -3.32503604888916
Batch 62/64 loss: -3.455784797668457
Batch 63/64 loss: -3.1572866439819336
Batch 64/64 loss: -7.724548816680908
Epoch 147  Train loss: -3.139687607335109  Val loss: -3.32030156715629
Epoch 148
-------------------------------
Batch 1/64 loss: -3.0863113403320312
Batch 2/64 loss: -2.9261178970336914
Batch 3/64 loss: -2.9475021362304688
Batch 4/64 loss: -3.175149917602539
Batch 5/64 loss: -3.282939910888672
Batch 6/64 loss: -3.2237672805786133
Batch 7/64 loss: -3.1620731353759766
Batch 8/64 loss: -3.4158668518066406
Batch 9/64 loss: -2.97676944732666
Batch 10/64 loss: -2.632558822631836
Batch 11/64 loss: -3.171079635620117
Batch 12/64 loss: -3.0915374755859375
Batch 13/64 loss: -2.64945125579834
Batch 14/64 loss: -3.05361270904541
Batch 15/64 loss: -3.161849021911621
Batch 16/64 loss: -2.976869583129883
Batch 17/64 loss: -3.0612564086914062
Batch 18/64 loss: -2.8235177993774414
Batch 19/64 loss: -3.0522842407226562
Batch 20/64 loss: -2.972665786743164
Batch 21/64 loss: -3.00579833984375
Batch 22/64 loss: -2.960892677307129
Batch 23/64 loss: -3.157414436340332
Batch 24/64 loss: -3.1003952026367188
Batch 25/64 loss: -2.947568893432617
Batch 26/64 loss: -2.816089630126953
Batch 27/64 loss: -2.804658889770508
Batch 28/64 loss: -3.1502113342285156
Batch 29/64 loss: -3.0648460388183594
Batch 30/64 loss: -2.948801040649414
Batch 31/64 loss: -3.039379119873047
Batch 32/64 loss: -3.0190935134887695
Batch 33/64 loss: -3.221695899963379
Batch 34/64 loss: -2.8489227294921875
Batch 35/64 loss: -3.253009796142578
Batch 36/64 loss: -3.12001895904541
Batch 37/64 loss: -3.05655574798584
Batch 38/64 loss: -3.0119705200195312
Batch 39/64 loss: -3.290090560913086
Batch 40/64 loss: -2.900480270385742
Batch 41/64 loss: -2.843966484069824
Batch 42/64 loss: -3.115304946899414
Batch 43/64 loss: -3.2111997604370117
Batch 44/64 loss: -3.169513702392578
Batch 45/64 loss: -3.0628299713134766
Batch 46/64 loss: -3.2239742279052734
Batch 47/64 loss: -3.1026391983032227
Batch 48/64 loss: -2.5890445709228516
Batch 49/64 loss: -3.20218563079834
Batch 50/64 loss: -3.2516345977783203
Batch 51/64 loss: -2.881037712097168
Batch 52/64 loss: -2.452023506164551
Batch 53/64 loss: -3.246692657470703
Batch 54/64 loss: -2.8333511352539062
Batch 55/64 loss: -2.989957809448242
Batch 56/64 loss: -2.8542613983154297
Batch 57/64 loss: -3.2369956970214844
Batch 58/64 loss: -3.0186767578125
Batch 59/64 loss: -3.1715316772460938
Batch 60/64 loss: -2.5639867782592773
Batch 61/64 loss: -2.973522186279297
Batch 62/64 loss: -3.1236066818237305
Batch 63/64 loss: -2.6516809463500977
Batch 64/64 loss: -7.775010108947754
Epoch 148  Train loss: -3.077050194085813  Val loss: -3.297934122511611
Epoch 149
-------------------------------
Batch 1/64 loss: -2.6285104751586914
Batch 2/64 loss: -3.256331443786621
Batch 3/64 loss: -3.1562681198120117
Batch 4/64 loss: -2.62827205657959
Batch 5/64 loss: -3.064723014831543
Batch 6/64 loss: -2.9342823028564453
Batch 7/64 loss: -3.428708076477051
Batch 8/64 loss: -3.0101633071899414
Batch 9/64 loss: -2.942445755004883
Batch 10/64 loss: -3.4054946899414062
Batch 11/64 loss: -2.5730533599853516
Batch 12/64 loss: -3.369875907897949
Batch 13/64 loss: -2.938582420349121
Batch 14/64 loss: -3.1378374099731445
Batch 15/64 loss: -2.639188766479492
Batch 16/64 loss: -3.1903209686279297
Batch 17/64 loss: -3.4606332778930664
Batch 18/64 loss: -3.2578983306884766
Batch 19/64 loss: -3.157258987426758
Batch 20/64 loss: -3.1768999099731445
Batch 21/64 loss: -3.218024253845215
Batch 22/64 loss: -2.9747791290283203
Batch 23/64 loss: -3.0486183166503906
Batch 24/64 loss: -3.130502700805664
Batch 25/64 loss: -2.6580610275268555
Batch 26/64 loss: -3.0938634872436523
Batch 27/64 loss: -2.580145835876465
Batch 28/64 loss: -3.0670394897460938
Batch 29/64 loss: -3.035069465637207
Batch 30/64 loss: -2.835171699523926
Batch 31/64 loss: -3.2571535110473633
Batch 32/64 loss: -2.9521560668945312
Batch 33/64 loss: -3.0025558471679688
Batch 34/64 loss: -3.223447799682617
Batch 35/64 loss: -3.125432014465332
Batch 36/64 loss: -3.010561943054199
Batch 37/64 loss: -3.349315643310547
Batch 38/64 loss: -3.2846689224243164
Batch 39/64 loss: -2.4655961990356445
Batch 40/64 loss: -3.1523656845092773
Batch 41/64 loss: -3.1732091903686523
Batch 42/64 loss: -3.18538761138916
Batch 43/64 loss: -3.157700538635254
Batch 44/64 loss: -3.0803518295288086
Batch 45/64 loss: -2.7021751403808594
Batch 46/64 loss: -3.2357559204101562
Batch 47/64 loss: -3.248103141784668
Batch 48/64 loss: -3.150421142578125
Batch 49/64 loss: -3.074355125427246
Batch 50/64 loss: -3.154324531555176
Batch 51/64 loss: -3.274479866027832
Batch 52/64 loss: -3.2824201583862305
Batch 53/64 loss: -3.416118621826172
Batch 54/64 loss: -3.3208398818969727
Batch 55/64 loss: -2.9612226486206055
Batch 56/64 loss: -3.2443771362304688
Batch 57/64 loss: -3.208786964416504
Batch 58/64 loss: -3.019521713256836
Batch 59/64 loss: -3.3277759552001953
Batch 60/64 loss: -2.92926025390625
Batch 61/64 loss: -3.258840560913086
Batch 62/64 loss: -2.9713706970214844
Batch 63/64 loss: -3.0954084396362305
Batch 64/64 loss: -7.467079162597656
Epoch 149  Train loss: -3.1355889264275048  Val loss: -3.313926578797016
Epoch 150
-------------------------------
Batch 1/64 loss: -2.97359561920166
Batch 2/64 loss: -2.8872509002685547
Batch 3/64 loss: -2.3286094665527344
Batch 4/64 loss: -2.899294853210449
Batch 5/64 loss: -3.1189441680908203
Batch 6/64 loss: -2.8380203247070312
Batch 7/64 loss: -2.845301628112793
Batch 8/64 loss: -3.1050939559936523
Batch 9/64 loss: -3.241398811340332
Batch 10/64 loss: -2.9617300033569336
Batch 11/64 loss: -3.045535087585449
Batch 12/64 loss: -2.8284835815429688
Batch 13/64 loss: -2.968893051147461
Batch 14/64 loss: -3.1422605514526367
Batch 15/64 loss: -3.2889909744262695
Batch 16/64 loss: -3.0249576568603516
Batch 17/64 loss: -2.896085739135742
Batch 18/64 loss: -3.1866540908813477
Batch 19/64 loss: -3.111081123352051
Batch 20/64 loss: -2.844888687133789
Batch 21/64 loss: -2.8101205825805664
Batch 22/64 loss: -3.142838478088379
Batch 23/64 loss: -3.0918874740600586
Batch 24/64 loss: -3.107405662536621
Batch 25/64 loss: -3.1847915649414062
Batch 26/64 loss: -3.219700813293457
Batch 27/64 loss: -3.066279411315918
Batch 28/64 loss: -3.2852354049682617
Batch 29/64 loss: -2.8621034622192383
Batch 30/64 loss: -3.3435096740722656
Batch 31/64 loss: -3.249178886413574
Batch 32/64 loss: -3.0556421279907227
Batch 33/64 loss: -3.1036720275878906
Batch 34/64 loss: -3.12972354888916
Batch 35/64 loss: -3.0060205459594727
Batch 36/64 loss: -3.166293144226074
Batch 37/64 loss: -3.2871932983398438
Batch 38/64 loss: -3.0168590545654297
Batch 39/64 loss: -3.162459373474121
Batch 40/64 loss: -2.8423500061035156
Batch 41/64 loss: -3.136960983276367
Batch 42/64 loss: -2.7702741622924805
Batch 43/64 loss: -3.09139347076416
Batch 44/64 loss: -3.1645069122314453
Batch 45/64 loss: -3.0980758666992188
Batch 46/64 loss: -3.177328109741211
Batch 47/64 loss: -2.8639955520629883
Batch 48/64 loss: -2.893580436706543
Batch 49/64 loss: -3.087209701538086
Batch 50/64 loss: -3.158219337463379
Batch 51/64 loss: -3.1193971633911133
Batch 52/64 loss: -3.10085391998291
Batch 53/64 loss: -3.330672264099121
Batch 54/64 loss: -3.2191362380981445
Batch 55/64 loss: -3.1212635040283203
Batch 56/64 loss: -3.1784706115722656
Batch 57/64 loss: -2.4621667861938477
Batch 58/64 loss: -3.254129409790039
Batch 59/64 loss: -2.9930248260498047
Batch 60/64 loss: -3.0047225952148438
Batch 61/64 loss: -3.0323305130004883
Batch 62/64 loss: -3.18387508392334
Batch 63/64 loss: -2.8229875564575195
Batch 64/64 loss: -8.097200393676758
Epoch 150  Train loss: -3.1060048645617915  Val loss: -3.4074522457581615
Epoch 151
-------------------------------
Batch 1/64 loss: -2.345590591430664
Batch 2/64 loss: -3.191431999206543
Batch 3/64 loss: -3.2286949157714844
Batch 4/64 loss: -3.1586313247680664
Batch 5/64 loss: -3.29280948638916
Batch 6/64 loss: -3.330291748046875
Batch 7/64 loss: -3.1098642349243164
Batch 8/64 loss: -2.4055185317993164
Batch 9/64 loss: -3.1700496673583984
Batch 10/64 loss: -2.562678337097168
Batch 11/64 loss: -3.0108108520507812
Batch 12/64 loss: -3.0448455810546875
Batch 13/64 loss: -3.3070316314697266
Batch 14/64 loss: -2.872241973876953
Batch 15/64 loss: -3.0825557708740234
Batch 16/64 loss: -2.951549530029297
Batch 17/64 loss: -3.403799057006836
Batch 18/64 loss: -3.044407844543457
Batch 19/64 loss: -3.251919746398926
Batch 20/64 loss: -3.2174205780029297
Batch 21/64 loss: -3.0059356689453125
Batch 22/64 loss: -3.3293533325195312
Batch 23/64 loss: -3.1129703521728516
Batch 24/64 loss: -2.826784133911133
Batch 25/64 loss: -3.394808769226074
Batch 26/64 loss: -3.1469650268554688
Batch 27/64 loss: -3.0635480880737305
Batch 28/64 loss: -3.2536516189575195
Batch 29/64 loss: -3.0068254470825195
Batch 30/64 loss: -3.126357078552246
Batch 31/64 loss: -3.0415096282958984
Batch 32/64 loss: -3.1555967330932617
Batch 33/64 loss: -2.6763362884521484
Batch 34/64 loss: -2.750765800476074
Batch 35/64 loss: -3.286810874938965
Batch 36/64 loss: -3.3583011627197266
Batch 37/64 loss: -2.6700801849365234
Batch 38/64 loss: -3.093778610229492
Batch 39/64 loss: -3.2921581268310547
Batch 40/64 loss: -3.339082717895508
Batch 41/64 loss: -2.8663864135742188
Batch 42/64 loss: -2.770364761352539
Batch 43/64 loss: -3.003347396850586
Batch 44/64 loss: -3.046454429626465
Batch 45/64 loss: -3.1135969161987305
Batch 46/64 loss: -3.3476457595825195
Batch 47/64 loss: -3.2873611450195312
Batch 48/64 loss: -3.251572608947754
Batch 49/64 loss: -2.9103822708129883
Batch 50/64 loss: -3.3343324661254883
Batch 51/64 loss: -2.7120819091796875
Batch 52/64 loss: -3.2715768814086914
Batch 53/64 loss: -3.403029441833496
Batch 54/64 loss: -3.3314390182495117
Batch 55/64 loss: -3.310185432434082
Batch 56/64 loss: -2.984622001647949
Batch 57/64 loss: -3.111173629760742
Batch 58/64 loss: -3.2310829162597656
Batch 59/64 loss: -2.8472299575805664
Batch 60/64 loss: -2.9175586700439453
Batch 61/64 loss: -3.29617977142334
Batch 62/64 loss: -3.141474723815918
Batch 63/64 loss: -3.048090934753418
Batch 64/64 loss: -7.811285018920898
Epoch 151  Train loss: -3.142108176736271  Val loss: -3.3705670464899122
Epoch 152
-------------------------------
Batch 1/64 loss: -3.026980400085449
Batch 2/64 loss: -3.271040916442871
Batch 3/64 loss: -2.7076263427734375
Batch 4/64 loss: -3.146243095397949
Batch 5/64 loss: -3.091703414916992
Batch 6/64 loss: -3.4749794006347656
Batch 7/64 loss: -3.386312484741211
Batch 8/64 loss: -3.3725948333740234
Batch 9/64 loss: -3.095226287841797
Batch 10/64 loss: -3.077897071838379
Batch 11/64 loss: -3.410763740539551
Batch 12/64 loss: -2.6045751571655273
Batch 13/64 loss: -3.05303955078125
Batch 14/64 loss: -3.229686737060547
Batch 15/64 loss: -2.84445858001709
Batch 16/64 loss: -2.9177770614624023
Batch 17/64 loss: -3.1369619369506836
Batch 18/64 loss: -3.148143768310547
Batch 19/64 loss: -2.7325363159179688
Batch 20/64 loss: -2.933976173400879
Batch 21/64 loss: -3.1475791931152344
Batch 22/64 loss: -3.0251598358154297
Batch 23/64 loss: -3.010056495666504
Batch 24/64 loss: -3.2624635696411133
Batch 25/64 loss: -2.8431148529052734
Batch 26/64 loss: -2.488504409790039
Batch 27/64 loss: -2.3651037216186523
Batch 28/64 loss: -2.577442169189453
Batch 29/64 loss: -2.7631969451904297
Batch 30/64 loss: -3.050053596496582
Batch 31/64 loss: -3.032085418701172
Batch 32/64 loss: -2.830470085144043
Batch 33/64 loss: -2.9599380493164062
Batch 34/64 loss: -3.142824172973633
Batch 35/64 loss: -3.168416976928711
Batch 36/64 loss: -2.702676773071289
Batch 37/64 loss: -3.151028633117676
Batch 38/64 loss: -2.863248825073242
Batch 39/64 loss: -2.9154930114746094
Batch 40/64 loss: -3.122321128845215
Batch 41/64 loss: -2.930483818054199
Batch 42/64 loss: -2.6633987426757812
Batch 43/64 loss: -3.182223320007324
Batch 44/64 loss: -3.0139970779418945
Batch 45/64 loss: -2.8744983673095703
Batch 46/64 loss: -2.7833375930786133
Batch 47/64 loss: -3.2881879806518555
Batch 48/64 loss: -3.238985061645508
Batch 49/64 loss: -3.0035924911499023
Batch 50/64 loss: -3.0762529373168945
Batch 51/64 loss: -3.193286895751953
Batch 52/64 loss: -2.550654411315918
Batch 53/64 loss: -2.7587995529174805
Batch 54/64 loss: -3.127068519592285
Batch 55/64 loss: -3.006275177001953
Batch 56/64 loss: -3.1162872314453125
Batch 57/64 loss: -3.1423559188842773
Batch 58/64 loss: -2.952808380126953
Batch 59/64 loss: -3.357572555541992
Batch 60/64 loss: -3.239821434020996
Batch 61/64 loss: -3.107534408569336
Batch 62/64 loss: -3.2359628677368164
Batch 63/64 loss: -3.28342342376709
Batch 64/64 loss: -7.932185173034668
Epoch 152  Train loss: -3.0770140890981637  Val loss: -3.4095242949285867
Epoch 153
-------------------------------
Batch 1/64 loss: -3.0113525390625
Batch 2/64 loss: -3.053616523742676
Batch 3/64 loss: -3.283329963684082
Batch 4/64 loss: -3.017460823059082
Batch 5/64 loss: -3.0582475662231445
Batch 6/64 loss: -2.8809986114501953
Batch 7/64 loss: -2.8955202102661133
Batch 8/64 loss: -3.452699661254883
Batch 9/64 loss: -3.196767807006836
Batch 10/64 loss: -3.000155448913574
Batch 11/64 loss: -3.1087818145751953
Batch 12/64 loss: -3.059575080871582
Batch 13/64 loss: -3.0849456787109375
Batch 14/64 loss: -3.163637161254883
Batch 15/64 loss: -3.2920141220092773
Batch 16/64 loss: -3.1399412155151367
Batch 17/64 loss: -3.040957450866699
Batch 18/64 loss: -2.7315006256103516
Batch 19/64 loss: -3.1543798446655273
Batch 20/64 loss: -3.1377906799316406
Batch 21/64 loss: -2.9059858322143555
Batch 22/64 loss: -3.1576805114746094
Batch 23/64 loss: -3.218332290649414
Batch 24/64 loss: -3.3326244354248047
Batch 25/64 loss: -2.7826738357543945
Batch 26/64 loss: -2.8162145614624023
Batch 27/64 loss: -3.0843591690063477
Batch 28/64 loss: -2.8112382888793945
Batch 29/64 loss: -3.2508583068847656
Batch 30/64 loss: -3.299687385559082
Batch 31/64 loss: -2.9985265731811523
Batch 32/64 loss: -2.885586738586426
Batch 33/64 loss: -3.1367292404174805
Batch 34/64 loss: -3.3179931640625
Batch 35/64 loss: -3.1818103790283203
Batch 36/64 loss: -3.1963424682617188
Batch 37/64 loss: -3.3040666580200195
Batch 38/64 loss: -3.0825557708740234
Batch 39/64 loss: -3.1239261627197266
Batch 40/64 loss: -3.307497978210449
Batch 41/64 loss: -2.9474105834960938
Batch 42/64 loss: -3.045339584350586
Batch 43/64 loss: -3.220852851867676
Batch 44/64 loss: -3.2853622436523438
Batch 45/64 loss: -3.252534866333008
Batch 46/64 loss: -3.4129819869995117
Batch 47/64 loss: -3.161665916442871
Batch 48/64 loss: -3.2979869842529297
Batch 49/64 loss: -2.972597122192383
Batch 50/64 loss: -3.297901153564453
Batch 51/64 loss: -3.190670967102051
Batch 52/64 loss: -3.3885011672973633
Batch 53/64 loss: -2.9634180068969727
Batch 54/64 loss: -3.301743507385254
Batch 55/64 loss: -3.141993522644043
Batch 56/64 loss: -3.014523506164551
Batch 57/64 loss: -3.365139961242676
Batch 58/64 loss: -2.3453311920166016
Batch 59/64 loss: -3.0284042358398438
Batch 60/64 loss: -3.122060775756836
Batch 61/64 loss: -2.959136962890625
Batch 62/64 loss: -2.990663528442383
Batch 63/64 loss: -3.4005517959594727
Batch 64/64 loss: -7.960897445678711
Epoch 153  Train loss: -3.169189146453259  Val loss: -3.359650457847569
Epoch 154
-------------------------------
Batch 1/64 loss: -3.2161617279052734
Batch 2/64 loss: -3.150822639465332
Batch 3/64 loss: -2.823575019836426
Batch 4/64 loss: -2.762356758117676
Batch 5/64 loss: -2.921398162841797
Batch 6/64 loss: -2.876401901245117
Batch 7/64 loss: -3.0543785095214844
Batch 8/64 loss: -2.753392219543457
Batch 9/64 loss: -3.1573190689086914
Batch 10/64 loss: -3.2245302200317383
Batch 11/64 loss: -2.756720542907715
Batch 12/64 loss: -3.1338014602661133
Batch 13/64 loss: -3.301485061645508
Batch 14/64 loss: -2.7896013259887695
Batch 15/64 loss: -3.256436347961426
Batch 16/64 loss: -3.044501304626465
Batch 17/64 loss: -3.0062026977539062
Batch 18/64 loss: -3.329099655151367
Batch 19/64 loss: -3.1883420944213867
Batch 20/64 loss: -3.274531364440918
Batch 21/64 loss: -2.831536293029785
Batch 22/64 loss: -3.3862228393554688
Batch 23/64 loss: -3.2004623413085938
Batch 24/64 loss: -3.064082145690918
Batch 25/64 loss: -3.2980470657348633
Batch 26/64 loss: -3.202874183654785
Batch 27/64 loss: -3.365966796875
Batch 28/64 loss: -3.4475631713867188
Batch 29/64 loss: -3.033339500427246
Batch 30/64 loss: -3.249197006225586
Batch 31/64 loss: -3.406815528869629
Batch 32/64 loss: -2.982961654663086
Batch 33/64 loss: -3.417593002319336
Batch 34/64 loss: -3.130350112915039
Batch 35/64 loss: -3.191046714782715
Batch 36/64 loss: -3.112285614013672
Batch 37/64 loss: -3.172835350036621
Batch 38/64 loss: -3.035140037536621
Batch 39/64 loss: -3.1831483840942383
Batch 40/64 loss: -3.144634246826172
Batch 41/64 loss: -3.0860595703125
Batch 42/64 loss: -3.0240983963012695
Batch 43/64 loss: -3.2848901748657227
Batch 44/64 loss: -2.1760568618774414
Batch 45/64 loss: -3.111055374145508
Batch 46/64 loss: -3.238652229309082
Batch 47/64 loss: -3.1048927307128906
Batch 48/64 loss: -3.088613510131836
Batch 49/64 loss: -3.3504180908203125
Batch 50/64 loss: -3.3078041076660156
Batch 51/64 loss: -2.9446678161621094
Batch 52/64 loss: -3.246293067932129
Batch 53/64 loss: -3.348308563232422
Batch 54/64 loss: -3.3925561904907227
Batch 55/64 loss: -3.3073959350585938
Batch 56/64 loss: -3.0758609771728516
Batch 57/64 loss: -3.3457727432250977
Batch 58/64 loss: -2.9037656784057617
Batch 59/64 loss: -3.11873722076416
Batch 60/64 loss: -3.307016372680664
Batch 61/64 loss: -2.697970390319824
Batch 62/64 loss: -2.614224433898926
Batch 63/64 loss: -2.697066307067871
Batch 64/64 loss: -7.659130573272705
Epoch 154  Train loss: -3.1591166234483907  Val loss: -3.17443363936906
Epoch 155
-------------------------------
Batch 1/64 loss: -3.2579994201660156
Batch 2/64 loss: -3.0662622451782227
Batch 3/64 loss: -3.0107545852661133
Batch 4/64 loss: -3.2589187622070312
Batch 5/64 loss: -3.240171432495117
Batch 6/64 loss: -3.198513984680176
Batch 7/64 loss: -3.313447952270508
Batch 8/64 loss: -3.3659000396728516
Batch 9/64 loss: -3.190584182739258
Batch 10/64 loss: -3.3335647583007812
Batch 11/64 loss: -3.256344795227051
Batch 12/64 loss: -2.8618078231811523
Batch 13/64 loss: -2.972651481628418
Batch 14/64 loss: -3.3747739791870117
Batch 15/64 loss: -3.3332862854003906
Batch 16/64 loss: -2.9299793243408203
Batch 17/64 loss: -3.195075035095215
Batch 18/64 loss: -3.140231132507324
Batch 19/64 loss: -3.4310197830200195
Batch 20/64 loss: -3.3115625381469727
Batch 21/64 loss: -2.916775703430176
Batch 22/64 loss: -2.8751955032348633
Batch 23/64 loss: -2.6428680419921875
Batch 24/64 loss: -3.3160324096679688
Batch 25/64 loss: -3.181215286254883
Batch 26/64 loss: -2.8963661193847656
Batch 27/64 loss: -3.031116485595703
Batch 28/64 loss: -3.309112548828125
Batch 29/64 loss: -3.089679718017578
Batch 30/64 loss: -3.2334041595458984
Batch 31/64 loss: -2.9160385131835938
Batch 32/64 loss: -3.0514755249023438
Batch 33/64 loss: -3.0939712524414062
Batch 34/64 loss: -3.299776077270508
Batch 35/64 loss: -2.713472366333008
Batch 36/64 loss: -2.8853797912597656
Batch 37/64 loss: -3.1832523345947266
Batch 38/64 loss: -3.098163604736328
Batch 39/64 loss: -3.2279014587402344
Batch 40/64 loss: -2.7733144760131836
Batch 41/64 loss: -2.744378089904785
Batch 42/64 loss: -2.94509220123291
Batch 43/64 loss: -3.174009323120117
Batch 44/64 loss: -3.182196617126465
Batch 45/64 loss: -3.2448501586914062
Batch 46/64 loss: -2.99282169342041
Batch 47/64 loss: -3.3076467514038086
Batch 48/64 loss: -3.0331382751464844
Batch 49/64 loss: -3.4024171829223633
Batch 50/64 loss: -2.9684200286865234
Batch 51/64 loss: -2.359013557434082
Batch 52/64 loss: -2.8491334915161133
Batch 53/64 loss: -3.158482551574707
Batch 54/64 loss: -2.782505989074707
Batch 55/64 loss: -3.0677661895751953
Batch 56/64 loss: -3.005141258239746
Batch 57/64 loss: -3.2628583908081055
Batch 58/64 loss: -2.2955551147460938
Batch 59/64 loss: -3.1846389770507812
Batch 60/64 loss: -2.9786882400512695
Batch 61/64 loss: -3.106830596923828
Batch 62/64 loss: -2.92667293548584
Batch 63/64 loss: -3.1116819381713867
Batch 64/64 loss: -7.2748894691467285
Epoch 155  Train loss: -3.1265485109067432  Val loss: -3.3385008716910973
Epoch 156
-------------------------------
Batch 1/64 loss: -3.2345638275146484
Batch 2/64 loss: -3.190134048461914
Batch 3/64 loss: -2.652277946472168
Batch 4/64 loss: -2.9693470001220703
Batch 5/64 loss: -3.093700408935547
Batch 6/64 loss: -3.164508819580078
Batch 7/64 loss: -3.1450700759887695
Batch 8/64 loss: -3.074751853942871
Batch 9/64 loss: -2.906355857849121
Batch 10/64 loss: -3.05755615234375
Batch 11/64 loss: -2.902120590209961
Batch 12/64 loss: -3.469296455383301
Batch 13/64 loss: -3.240537643432617
Batch 14/64 loss: -2.558950424194336
Batch 15/64 loss: -3.1656179428100586
Batch 16/64 loss: -3.1145429611206055
Batch 17/64 loss: -3.1209726333618164
Batch 18/64 loss: -3.1252851486206055
Batch 19/64 loss: -3.342461585998535
Batch 20/64 loss: -2.733138084411621
Batch 21/64 loss: -3.2169342041015625
Batch 22/64 loss: -3.0381288528442383
Batch 23/64 loss: -3.490550994873047
Batch 24/64 loss: -3.225010871887207
Batch 25/64 loss: -3.0290145874023438
Batch 26/64 loss: -3.0527210235595703
Batch 27/64 loss: -2.6239356994628906
Batch 28/64 loss: -3.2626867294311523
Batch 29/64 loss: -2.9503955841064453
Batch 30/64 loss: -2.879147529602051
Batch 31/64 loss: -3.162796974182129
Batch 32/64 loss: -2.7955780029296875
Batch 33/64 loss: -3.3432788848876953
Batch 34/64 loss: -3.2545995712280273
Batch 35/64 loss: -3.1795778274536133
Batch 36/64 loss: -3.244935989379883
Batch 37/64 loss: -2.997934341430664
Batch 38/64 loss: -3.1741151809692383
Batch 39/64 loss: -2.6402368545532227
Batch 40/64 loss: -3.0589399337768555
Batch 41/64 loss: -3.2371063232421875
Batch 42/64 loss: -3.1863937377929688
Batch 43/64 loss: -2.9034509658813477
Batch 44/64 loss: -2.6922826766967773
Batch 45/64 loss: -3.171377182006836
Batch 46/64 loss: -3.211907386779785
Batch 47/64 loss: -3.068418502807617
Batch 48/64 loss: -3.04227352142334
Batch 49/64 loss: -3.251382827758789
Batch 50/64 loss: -3.275212287902832
Batch 51/64 loss: -2.776531219482422
Batch 52/64 loss: -3.0247879028320312
Batch 53/64 loss: -3.044032096862793
Batch 54/64 loss: -3.1897830963134766
Batch 55/64 loss: -3.0788936614990234
Batch 56/64 loss: -2.6894044876098633
Batch 57/64 loss: -2.8350744247436523
Batch 58/64 loss: -3.2339096069335938
Batch 59/64 loss: -3.0856542587280273
Batch 60/64 loss: -2.934088706970215
Batch 61/64 loss: -3.1101150512695312
Batch 62/64 loss: -2.9994821548461914
Batch 63/64 loss: -2.8370771408081055
Batch 64/64 loss: -7.7179412841796875
Epoch 156  Train loss: -3.1144910475786993  Val loss: -3.5256068829408624
Saving best model, epoch: 156
Epoch 157
-------------------------------
Batch 1/64 loss: -3.221529006958008
Batch 2/64 loss: -3.230600357055664
Batch 3/64 loss: -3.1750926971435547
Batch 4/64 loss: -2.562946319580078
Batch 5/64 loss: -3.12526798248291
Batch 6/64 loss: -2.927541732788086
Batch 7/64 loss: -3.3368072509765625
Batch 8/64 loss: -3.3319921493530273
Batch 9/64 loss: -3.0400209426879883
Batch 10/64 loss: -2.938204765319824
Batch 11/64 loss: -3.0130786895751953
Batch 12/64 loss: -2.830714225769043
Batch 13/64 loss: -3.179274559020996
Batch 14/64 loss: -3.2238054275512695
Batch 15/64 loss: -3.0324487686157227
Batch 16/64 loss: -3.1502017974853516
Batch 17/64 loss: -3.376471519470215
Batch 18/64 loss: -2.6519641876220703
Batch 19/64 loss: -2.9873781204223633
Batch 20/64 loss: -2.963430404663086
Batch 21/64 loss: -3.0868988037109375
Batch 22/64 loss: -3.104620933532715
Batch 23/64 loss: -3.428586006164551
Batch 24/64 loss: -2.896683692932129
Batch 25/64 loss: -3.1073503494262695
Batch 26/64 loss: -3.0125598907470703
Batch 27/64 loss: -3.2349605560302734
Batch 28/64 loss: -3.316622734069824
Batch 29/64 loss: -3.2017412185668945
Batch 30/64 loss: -2.67258358001709
Batch 31/64 loss: -3.1452627182006836
Batch 32/64 loss: -2.660734176635742
Batch 33/64 loss: -3.225081443786621
Batch 34/64 loss: -2.753103256225586
Batch 35/64 loss: -3.2016029357910156
Batch 36/64 loss: -3.3499956130981445
Batch 37/64 loss: -2.5050716400146484
Batch 38/64 loss: -3.4007110595703125
Batch 39/64 loss: -3.1038055419921875
Batch 40/64 loss: -3.196845054626465
Batch 41/64 loss: -3.134061813354492
Batch 42/64 loss: -2.918454170227051
Batch 43/64 loss: -3.046194076538086
Batch 44/64 loss: -3.1898880004882812
Batch 45/64 loss: -3.203089714050293
Batch 46/64 loss: -3.0960693359375
Batch 47/64 loss: -3.002422332763672
Batch 48/64 loss: -3.1625680923461914
Batch 49/64 loss: -2.793031692504883
Batch 50/64 loss: -3.041073799133301
Batch 51/64 loss: -3.3126134872436523
Batch 52/64 loss: -3.2680110931396484
Batch 53/64 loss: -3.2200546264648438
Batch 54/64 loss: -2.9322338104248047
Batch 55/64 loss: -3.089719772338867
Batch 56/64 loss: -3.154695510864258
Batch 57/64 loss: -3.5404253005981445
Batch 58/64 loss: -3.1117773056030273
Batch 59/64 loss: -3.434906005859375
Batch 60/64 loss: -3.347468376159668
Batch 61/64 loss: -3.094489097595215
Batch 62/64 loss: -3.180727958679199
Batch 63/64 loss: -3.1313657760620117
Batch 64/64 loss: -7.8639960289001465
Epoch 157  Train loss: -3.156187141642851  Val loss: -3.408555152080313
Epoch 158
-------------------------------
Batch 1/64 loss: -3.03505802154541
Batch 2/64 loss: -3.3360118865966797
Batch 3/64 loss: -3.146007537841797
Batch 4/64 loss: -3.3677845001220703
Batch 5/64 loss: -3.0639848709106445
Batch 6/64 loss: -3.1931848526000977
Batch 7/64 loss: -2.9804840087890625
Batch 8/64 loss: -2.864591598510742
Batch 9/64 loss: -3.199957847595215
Batch 10/64 loss: -3.1757001876831055
Batch 11/64 loss: -3.3966665267944336
Batch 12/64 loss: -2.667665481567383
Batch 13/64 loss: -3.4399213790893555
Batch 14/64 loss: -3.084477424621582
Batch 15/64 loss: -3.3985719680786133
Batch 16/64 loss: -3.1668577194213867
Batch 17/64 loss: -2.866349220275879
Batch 18/64 loss: -3.0882740020751953
Batch 19/64 loss: -3.043699264526367
Batch 20/64 loss: -3.0632057189941406
Batch 21/64 loss: -3.207517623901367
Batch 22/64 loss: -2.9216127395629883
Batch 23/64 loss: -2.9525375366210938
Batch 24/64 loss: -3.0016441345214844
Batch 25/64 loss: -3.334986686706543
Batch 26/64 loss: -2.865232467651367
Batch 27/64 loss: -2.708584785461426
Batch 28/64 loss: -2.770658493041992
Batch 29/64 loss: -2.6947221755981445
Batch 30/64 loss: -2.364903450012207
Batch 31/64 loss: -2.690256118774414
Batch 32/64 loss: -3.189800262451172
Batch 33/64 loss: -2.983363151550293
Batch 34/64 loss: -3.04349422454834
Batch 35/64 loss: -2.849850654602051
Batch 36/64 loss: -3.138357162475586
Batch 37/64 loss: -3.0880041122436523
Batch 38/64 loss: -3.297719955444336
Batch 39/64 loss: -3.1666336059570312
Batch 40/64 loss: -2.9729747772216797
Batch 41/64 loss: -3.077667236328125
Batch 42/64 loss: -3.1130714416503906
Batch 43/64 loss: -3.148326873779297
Batch 44/64 loss: -3.23043155670166
Batch 45/64 loss: -3.2462940216064453
Batch 46/64 loss: -2.961174964904785
Batch 47/64 loss: -3.056962013244629
Batch 48/64 loss: -3.1562509536743164
Batch 49/64 loss: -3.129532814025879
Batch 50/64 loss: -2.522336959838867
Batch 51/64 loss: -3.072312355041504
Batch 52/64 loss: -3.2448034286499023
Batch 53/64 loss: -2.7094688415527344
Batch 54/64 loss: -3.1635360717773438
Batch 55/64 loss: -3.178177833557129
Batch 56/64 loss: -3.237224578857422
Batch 57/64 loss: -2.906783103942871
Batch 58/64 loss: -2.9232120513916016
Batch 59/64 loss: -3.0338611602783203
Batch 60/64 loss: -3.0617427825927734
Batch 61/64 loss: -3.2446117401123047
Batch 62/64 loss: -3.0666561126708984
Batch 63/64 loss: -2.993105888366699
Batch 64/64 loss: -7.681970596313477
Epoch 158  Train loss: -3.1068287194943895  Val loss: -3.114427337122127
Epoch 159
-------------------------------
Batch 1/64 loss: -3.200190544128418
Batch 2/64 loss: -3.0601539611816406
Batch 3/64 loss: -3.2896013259887695
Batch 4/64 loss: -3.0237979888916016
Batch 5/64 loss: -2.591379165649414
Batch 6/64 loss: -3.0855884552001953
Batch 7/64 loss: -3.0108489990234375
Batch 8/64 loss: -3.283217430114746
Batch 9/64 loss: -3.108920097351074
Batch 10/64 loss: -2.9249353408813477
Batch 11/64 loss: -3.2090253829956055
Batch 12/64 loss: -2.7552146911621094
Batch 13/64 loss: -3.1124534606933594
Batch 14/64 loss: -3.2557449340820312
Batch 15/64 loss: -3.0279617309570312
Batch 16/64 loss: -3.067927360534668
Batch 17/64 loss: -2.953521728515625
Batch 18/64 loss: -2.731588363647461
Batch 19/64 loss: -3.2588577270507812
Batch 20/64 loss: -3.025631904602051
Batch 21/64 loss: -2.5186691284179688
Batch 22/64 loss: -3.254100799560547
Batch 23/64 loss: -2.684453010559082
Batch 24/64 loss: -3.1262741088867188
Batch 25/64 loss: -2.6325788497924805
Batch 26/64 loss: -3.2311172485351562
Batch 27/64 loss: -3.036747932434082
Batch 28/64 loss: -3.039936065673828
Batch 29/64 loss: -2.534113883972168
Batch 30/64 loss: -3.021059036254883
Batch 31/64 loss: -3.149277687072754
Batch 32/64 loss: -2.9073705673217773
Batch 33/64 loss: -2.2824039459228516
Batch 34/64 loss: -3.122058868408203
Batch 35/64 loss: -3.382976531982422
Batch 36/64 loss: -2.990537643432617
Batch 37/64 loss: -2.1593446731567383
Batch 38/64 loss: -2.787907600402832
Batch 39/64 loss: -3.211268424987793
Batch 40/64 loss: -2.9622268676757812
Batch 41/64 loss: -3.0597362518310547
Batch 42/64 loss: -2.984391212463379
Batch 43/64 loss: -3.0209760665893555
Batch 44/64 loss: -3.0592966079711914
Batch 45/64 loss: -3.070652961730957
Batch 46/64 loss: -3.446383476257324
Batch 47/64 loss: -2.637303352355957
Batch 48/64 loss: -3.14786434173584
Batch 49/64 loss: -3.198849678039551
Batch 50/64 loss: -3.0966567993164062
Batch 51/64 loss: -3.031017303466797
Batch 52/64 loss: -2.9255571365356445
Batch 53/64 loss: -2.6112489700317383
Batch 54/64 loss: -3.1494522094726562
Batch 55/64 loss: -3.004261016845703
Batch 56/64 loss: -3.475858688354492
Batch 57/64 loss: -3.093295097351074
Batch 58/64 loss: -3.2677459716796875
Batch 59/64 loss: -3.03878116607666
Batch 60/64 loss: -3.154036521911621
Batch 61/64 loss: -3.134690284729004
Batch 62/64 loss: -3.1341638565063477
Batch 63/64 loss: -3.040989875793457
Batch 64/64 loss: -7.56463098526001
Epoch 159  Train loss: -3.06615945965636  Val loss: -3.3871823471436384
Epoch 160
-------------------------------
Batch 1/64 loss: -3.153445243835449
Batch 2/64 loss: -2.9975461959838867
Batch 3/64 loss: -3.2783260345458984
Batch 4/64 loss: -3.234971046447754
Batch 5/64 loss: -3.0177793502807617
Batch 6/64 loss: -3.066650390625
Batch 7/64 loss: -3.313939094543457
Batch 8/64 loss: -3.296194076538086
Batch 9/64 loss: -3.1465940475463867
Batch 10/64 loss: -2.8099069595336914
Batch 11/64 loss: -2.9979991912841797
Batch 12/64 loss: -3.1219348907470703
Batch 13/64 loss: -3.080312728881836
Batch 14/64 loss: -2.799854278564453
Batch 15/64 loss: -3.2013626098632812
Batch 16/64 loss: -3.0467758178710938
Batch 17/64 loss: -2.9403810501098633
Batch 18/64 loss: -3.2061405181884766
Batch 19/64 loss: -3.0437211990356445
Batch 20/64 loss: -3.1078977584838867
Batch 21/64 loss: -3.184965133666992
Batch 22/64 loss: -2.91763973236084
Batch 23/64 loss: -3.060670852661133
Batch 24/64 loss: -2.9100379943847656
Batch 25/64 loss: -2.9722728729248047
Batch 26/64 loss: -3.3238515853881836
Batch 27/64 loss: -3.0270090103149414
Batch 28/64 loss: -3.006197929382324
Batch 29/64 loss: -3.0790319442749023
Batch 30/64 loss: -2.9358673095703125
Batch 31/64 loss: -3.3149499893188477
Batch 32/64 loss: -3.1943931579589844
Batch 33/64 loss: -3.1273117065429688
Batch 34/64 loss: -2.9972286224365234
Batch 35/64 loss: -3.167943000793457
Batch 36/64 loss: -3.095736503601074
Batch 37/64 loss: -3.1396265029907227
Batch 38/64 loss: -3.2198143005371094
Batch 39/64 loss: -2.9985971450805664
Batch 40/64 loss: -2.507208824157715
Batch 41/64 loss: -2.8478736877441406
Batch 42/64 loss: -3.3138427734375
Batch 43/64 loss: -2.688754081726074
Batch 44/64 loss: -2.926546096801758
Batch 45/64 loss: -2.8709259033203125
Batch 46/64 loss: -2.8895368576049805
Batch 47/64 loss: -2.859992027282715
Batch 48/64 loss: -2.852421760559082
Batch 49/64 loss: -2.8236074447631836
Batch 50/64 loss: -2.99810791015625
Batch 51/64 loss: -2.904451370239258
Batch 52/64 loss: -2.9127702713012695
Batch 53/64 loss: -3.0464487075805664
Batch 54/64 loss: -3.2701406478881836
Batch 55/64 loss: -3.1403141021728516
Batch 56/64 loss: -3.0279388427734375
Batch 57/64 loss: -2.950037956237793
Batch 58/64 loss: -3.031111717224121
Batch 59/64 loss: -3.4286727905273438
Batch 60/64 loss: -3.237741470336914
Batch 61/64 loss: -3.0425233840942383
Batch 62/64 loss: -3.2681617736816406
Batch 63/64 loss: -3.1678905487060547
Batch 64/64 loss: -7.804656982421875
Epoch 160  Train loss: -3.112084571987975  Val loss: -3.3882760641091467
Epoch 161
-------------------------------
Batch 1/64 loss: -3.446643829345703
Batch 2/64 loss: -3.0639266967773438
Batch 3/64 loss: -3.2674379348754883
Batch 4/64 loss: -2.9565744400024414
Batch 5/64 loss: -3.238801956176758
Batch 6/64 loss: -3.4140138626098633
Batch 7/64 loss: -2.988827705383301
Batch 8/64 loss: -2.7770462036132812
Batch 9/64 loss: -3.262608528137207
Batch 10/64 loss: -3.2784671783447266
Batch 11/64 loss: -2.8234615325927734
Batch 12/64 loss: -3.441234588623047
Batch 13/64 loss: -3.19588565826416
Batch 14/64 loss: -3.2093143463134766
Batch 15/64 loss: -2.9033193588256836
Batch 16/64 loss: -3.3084230422973633
Batch 17/64 loss: -3.217405319213867
Batch 18/64 loss: -2.9385604858398438
Batch 19/64 loss: -3.2948503494262695
Batch 20/64 loss: -3.339611053466797
Batch 21/64 loss: -2.7468109130859375
Batch 22/64 loss: -3.2991085052490234
Batch 23/64 loss: -3.2705259323120117
Batch 24/64 loss: -3.298813819885254
Batch 25/64 loss: -2.7399463653564453
Batch 26/64 loss: -2.905557632446289
Batch 27/64 loss: -3.206366539001465
Batch 28/64 loss: -3.36447811126709
Batch 29/64 loss: -2.946187973022461
Batch 30/64 loss: -3.1357603073120117
Batch 31/64 loss: -3.146336555480957
Batch 32/64 loss: -3.0489253997802734
Batch 33/64 loss: -3.142213821411133
Batch 34/64 loss: -3.145115852355957
Batch 35/64 loss: -3.3336734771728516
Batch 36/64 loss: -3.3088464736938477
Batch 37/64 loss: -2.749011993408203
Batch 38/64 loss: -2.9397029876708984
Batch 39/64 loss: -2.876814842224121
Batch 40/64 loss: -2.654599189758301
Batch 41/64 loss: -2.9389686584472656
Batch 42/64 loss: -2.890814781188965
Batch 43/64 loss: -2.9986228942871094
Batch 44/64 loss: -2.8283300399780273
Batch 45/64 loss: -2.937790870666504
Batch 46/64 loss: -2.9267702102661133
Batch 47/64 loss: -3.033766746520996
Batch 48/64 loss: -2.937967300415039
Batch 49/64 loss: -2.882038116455078
Batch 50/64 loss: -2.8578968048095703
Batch 51/64 loss: -3.1817989349365234
Batch 52/64 loss: -3.1598711013793945
Batch 53/64 loss: -3.0768232345581055
Batch 54/64 loss: -2.902337074279785
Batch 55/64 loss: -3.267329216003418
Batch 56/64 loss: -3.3445653915405273
Batch 57/64 loss: -3.0330028533935547
Batch 58/64 loss: -3.156595230102539
Batch 59/64 loss: -3.0426511764526367
Batch 60/64 loss: -3.124696731567383
Batch 61/64 loss: -2.870389938354492
Batch 62/64 loss: -2.772533416748047
Batch 63/64 loss: -3.0028181076049805
Batch 64/64 loss: -7.48803186416626
Epoch 161  Train loss: -3.127993937099681  Val loss: -3.296242625442977
Epoch 162
-------------------------------
Batch 1/64 loss: -3.028204917907715
Batch 2/64 loss: -3.346806526184082
Batch 3/64 loss: -3.0970458984375
Batch 4/64 loss: -3.1046810150146484
Batch 5/64 loss: -3.1672258377075195
Batch 6/64 loss: -3.290003776550293
Batch 7/64 loss: -3.3074216842651367
Batch 8/64 loss: -2.8497562408447266
Batch 9/64 loss: -3.180352210998535
Batch 10/64 loss: -2.9406261444091797
Batch 11/64 loss: -3.4290523529052734
Batch 12/64 loss: -3.026932716369629
Batch 13/64 loss: -3.3279991149902344
Batch 14/64 loss: -3.3096704483032227
Batch 15/64 loss: -3.2975873947143555
Batch 16/64 loss: -2.892446517944336
Batch 17/64 loss: -3.2971115112304688
Batch 18/64 loss: -2.8452463150024414
Batch 19/64 loss: -2.7378320693969727
Batch 20/64 loss: -2.872969627380371
Batch 21/64 loss: -2.916476249694824
Batch 22/64 loss: -2.9504518508911133
Batch 23/64 loss: -3.307941436767578
Batch 24/64 loss: -3.259039878845215
Batch 25/64 loss: -3.0166425704956055
Batch 26/64 loss: -3.1901512145996094
Batch 27/64 loss: -3.1218557357788086
Batch 28/64 loss: -2.4980382919311523
Batch 29/64 loss: -2.914152145385742
Batch 30/64 loss: -2.85634708404541
Batch 31/64 loss: -2.8333187103271484
Batch 32/64 loss: -2.7096452713012695
Batch 33/64 loss: -2.7093868255615234
Batch 34/64 loss: -3.240079879760742
Batch 35/64 loss: -3.218221664428711
Batch 36/64 loss: -3.1932716369628906
Batch 37/64 loss: -3.069756507873535
Batch 38/64 loss: -3.0796680450439453
Batch 39/64 loss: -3.1879959106445312
Batch 40/64 loss: -2.7622995376586914
Batch 41/64 loss: -3.169668197631836
Batch 42/64 loss: -3.2675600051879883
Batch 43/64 loss: -2.9081478118896484
Batch 44/64 loss: -3.0461387634277344
Batch 45/64 loss: -3.076883316040039
Batch 46/64 loss: -3.0117273330688477
Batch 47/64 loss: -2.6035728454589844
Batch 48/64 loss: -2.9856462478637695
Batch 49/64 loss: -3.3382787704467773
Batch 50/64 loss: -3.102999687194824
Batch 51/64 loss: -3.053595542907715
Batch 52/64 loss: -3.247738838195801
Batch 53/64 loss: -2.99654483795166
Batch 54/64 loss: -2.497051239013672
Batch 55/64 loss: -3.376286506652832
Batch 56/64 loss: -3.071751594543457
Batch 57/64 loss: -3.008265495300293
Batch 58/64 loss: -3.0138673782348633
Batch 59/64 loss: -3.2623777389526367
Batch 60/64 loss: -2.942307472229004
Batch 61/64 loss: -3.312314033508301
Batch 62/64 loss: -3.069601058959961
Batch 63/64 loss: -3.27239990234375
Batch 64/64 loss: -7.491344451904297
Epoch 162  Train loss: -3.11587365842333  Val loss: -3.490278027721287
Epoch 163
-------------------------------
Batch 1/64 loss: -3.2860641479492188
Batch 2/64 loss: -3.141707420349121
Batch 3/64 loss: -3.14963436126709
Batch 4/64 loss: -3.19644832611084
Batch 5/64 loss: -3.0929012298583984
Batch 6/64 loss: -3.2945756912231445
Batch 7/64 loss: -2.8360090255737305
Batch 8/64 loss: -2.9186220169067383
Batch 9/64 loss: -2.704792022705078
Batch 10/64 loss: -3.2192564010620117
Batch 11/64 loss: -2.9004831314086914
Batch 12/64 loss: -2.695404052734375
Batch 13/64 loss: -3.43560791015625
Batch 14/64 loss: -3.2282581329345703
Batch 15/64 loss: -2.689742088317871
Batch 16/64 loss: -3.1367416381835938
Batch 17/64 loss: -3.0867128372192383
Batch 18/64 loss: -3.2011489868164062
Batch 19/64 loss: -3.204850196838379
Batch 20/64 loss: -2.7979040145874023
Batch 21/64 loss: -3.4112625122070312
Batch 22/64 loss: -3.1004858016967773
Batch 23/64 loss: -3.3443899154663086
Batch 24/64 loss: -3.1262950897216797
Batch 25/64 loss: -3.0981435775756836
Batch 26/64 loss: -3.201054573059082
Batch 27/64 loss: -2.4628639221191406
Batch 28/64 loss: -3.321709632873535
Batch 29/64 loss: -3.102206230163574
Batch 30/64 loss: -2.923630714416504
Batch 31/64 loss: -3.428333282470703
Batch 32/64 loss: -3.2764596939086914
Batch 33/64 loss: -3.3981189727783203
Batch 34/64 loss: -3.2887401580810547
Batch 35/64 loss: -3.2000789642333984
Batch 36/64 loss: -3.166935920715332
Batch 37/64 loss: -2.9270973205566406
Batch 38/64 loss: -3.3762283325195312
Batch 39/64 loss: -3.224977493286133
Batch 40/64 loss: -3.1558618545532227
Batch 41/64 loss: -2.858154296875
Batch 42/64 loss: -3.314335823059082
Batch 43/64 loss: -3.094601631164551
Batch 44/64 loss: -2.816460609436035
Batch 45/64 loss: -3.2291440963745117
Batch 46/64 loss: -2.8753957748413086
Batch 47/64 loss: -2.4910764694213867
Batch 48/64 loss: -3.2084884643554688
Batch 49/64 loss: -2.8813915252685547
Batch 50/64 loss: -3.154094696044922
Batch 51/64 loss: -3.1127490997314453
Batch 52/64 loss: -2.886049270629883
Batch 53/64 loss: -2.8880977630615234
Batch 54/64 loss: -2.890972137451172
Batch 55/64 loss: -3.335603713989258
Batch 56/64 loss: -3.0612916946411133
Batch 57/64 loss: -2.870922088623047
Batch 58/64 loss: -2.8388967514038086
Batch 59/64 loss: -3.0504579544067383
Batch 60/64 loss: -2.900383949279785
Batch 61/64 loss: -3.0503053665161133
Batch 62/64 loss: -3.3630800247192383
Batch 63/64 loss: -3.218465805053711
Batch 64/64 loss: -7.704561233520508
Epoch 163  Train loss: -3.136009059232824  Val loss: -3.218286638817017
Epoch 164
-------------------------------
Batch 1/64 loss: -3.047313690185547
Batch 2/64 loss: -2.707728385925293
Batch 3/64 loss: -3.0524511337280273
Batch 4/64 loss: -2.9610862731933594
Batch 5/64 loss: -2.815889358520508
Batch 6/64 loss: -3.217439651489258
Batch 7/64 loss: -2.967047691345215
Batch 8/64 loss: -3.2671852111816406
Batch 9/64 loss: -3.2747621536254883
Batch 10/64 loss: -3.1985292434692383
Batch 11/64 loss: -3.075336456298828
Batch 12/64 loss: -2.3140153884887695
Batch 13/64 loss: -3.0965194702148438
Batch 14/64 loss: -3.2350234985351562
Batch 15/64 loss: -2.972135543823242
Batch 16/64 loss: -3.2649850845336914
Batch 17/64 loss: -2.9587154388427734
Batch 18/64 loss: -2.798018455505371
Batch 19/64 loss: -3.2176103591918945
Batch 20/64 loss: -3.048233985900879
Batch 21/64 loss: -2.7210540771484375
Batch 22/64 loss: -3.2384958267211914
Batch 23/64 loss: -3.2583141326904297
Batch 24/64 loss: -2.4046688079833984
Batch 25/64 loss: -3.202075958251953
Batch 26/64 loss: -3.118896484375
Batch 27/64 loss: -2.859813690185547
Batch 28/64 loss: -2.9387283325195312
Batch 29/64 loss: -3.1349830627441406
Batch 30/64 loss: -2.987447738647461
Batch 31/64 loss: -3.2971134185791016
Batch 32/64 loss: -3.131969451904297
Batch 33/64 loss: -3.416769027709961
Batch 34/64 loss: -2.8060340881347656
Batch 35/64 loss: -3.1644821166992188
Batch 36/64 loss: -3.0944766998291016
Batch 37/64 loss: -2.3339033126831055
Batch 38/64 loss: -3.146111488342285
Batch 39/64 loss: -2.971597671508789
Batch 40/64 loss: -3.2794551849365234
Batch 41/64 loss: -3.1353769302368164
Batch 42/64 loss: -3.162013053894043
Batch 43/64 loss: -2.9483327865600586
Batch 44/64 loss: -2.610264778137207
Batch 45/64 loss: -2.445211410522461
Batch 46/64 loss: -3.1627111434936523
Batch 47/64 loss: -2.8720102310180664
Batch 48/64 loss: -3.152581214904785
Batch 49/64 loss: -3.3200511932373047
Batch 50/64 loss: -2.623411178588867
Batch 51/64 loss: -3.1898488998413086
Batch 52/64 loss: -3.1979427337646484
Batch 53/64 loss: -3.2148590087890625
Batch 54/64 loss: -2.921811103820801
Batch 55/64 loss: -3.305837631225586
Batch 56/64 loss: -3.3165969848632812
Batch 57/64 loss: -2.6600961685180664
Batch 58/64 loss: -2.941415786743164
Batch 59/64 loss: -3.1875085830688477
Batch 60/64 loss: -2.9999446868896484
Batch 61/64 loss: -3.310148239135742
Batch 62/64 loss: -3.1492300033569336
Batch 63/64 loss: -3.242831230163574
Batch 64/64 loss: -8.108098030090332
Epoch 164  Train loss: -3.0925102046891753  Val loss: -3.483379914588535
Epoch 165
-------------------------------
Batch 1/64 loss: -3.274677276611328
Batch 2/64 loss: -3.487677574157715
Batch 3/64 loss: -3.133615493774414
Batch 4/64 loss: -2.8211803436279297
Batch 5/64 loss: -3.3678665161132812
Batch 6/64 loss: -3.0239877700805664
Batch 7/64 loss: -3.201756477355957
Batch 8/64 loss: -3.0281829833984375
Batch 9/64 loss: -3.285572052001953
Batch 10/64 loss: -3.2569150924682617
Batch 11/64 loss: -3.0171194076538086
Batch 12/64 loss: -3.0857810974121094
Batch 13/64 loss: -3.2464780807495117
Batch 14/64 loss: -3.4515867233276367
Batch 15/64 loss: -3.0370054244995117
Batch 16/64 loss: -3.0061378479003906
Batch 17/64 loss: -3.1734399795532227
Batch 18/64 loss: -2.7286014556884766
Batch 19/64 loss: -3.1188879013061523
Batch 20/64 loss: -3.1835412979125977
Batch 21/64 loss: -3.0891361236572266
Batch 22/64 loss: -2.8159427642822266
Batch 23/64 loss: -3.424571990966797
Batch 24/64 loss: -3.0741119384765625
Batch 25/64 loss: -3.1598901748657227
Batch 26/64 loss: -2.9970779418945312
Batch 27/64 loss: -2.888957977294922
Batch 28/64 loss: -3.008699417114258
Batch 29/64 loss: -3.0968332290649414
Batch 30/64 loss: -3.1149253845214844
Batch 31/64 loss: -3.1557979583740234
Batch 32/64 loss: -3.1540775299072266
Batch 33/64 loss: -3.3463478088378906
Batch 34/64 loss: -3.3248424530029297
Batch 35/64 loss: -2.9454269409179688
Batch 36/64 loss: -3.282968521118164
Batch 37/64 loss: -2.603325843811035
Batch 38/64 loss: -3.1753110885620117
Batch 39/64 loss: -2.9664058685302734
Batch 40/64 loss: -2.524380683898926
Batch 41/64 loss: -3.309530258178711
Batch 42/64 loss: -3.260867118835449
Batch 43/64 loss: -2.8983278274536133
Batch 44/64 loss: -3.1680212020874023
Batch 45/64 loss: -3.188591957092285
Batch 46/64 loss: -2.708850860595703
Batch 47/64 loss: -3.4001693725585938
Batch 48/64 loss: -3.164133071899414
Batch 49/64 loss: -3.0895872116088867
Batch 50/64 loss: -2.9747304916381836
Batch 51/64 loss: -3.1295366287231445
Batch 52/64 loss: -3.069962501525879
Batch 53/64 loss: -3.3875980377197266
Batch 54/64 loss: -3.3196630477905273
Batch 55/64 loss: -3.225536346435547
Batch 56/64 loss: -3.327885627746582
Batch 57/64 loss: -2.5100135803222656
Batch 58/64 loss: -3.212308883666992
Batch 59/64 loss: -3.386702537536621
Batch 60/64 loss: -3.393073081970215
Batch 61/64 loss: -3.350536346435547
Batch 62/64 loss: -2.9992408752441406
Batch 63/64 loss: -3.2472591400146484
Batch 64/64 loss: -7.830416679382324
Epoch 165  Train loss: -3.1791997011970072  Val loss: -3.4149830611710694
Epoch 166
-------------------------------
Batch 1/64 loss: -3.431096076965332
Batch 2/64 loss: -3.4811134338378906
Batch 3/64 loss: -3.1539840698242188
Batch 4/64 loss: -3.135857582092285
Batch 5/64 loss: -3.278193473815918
Batch 6/64 loss: -2.5561742782592773
Batch 7/64 loss: -2.777851104736328
Batch 8/64 loss: -3.30233097076416
Batch 9/64 loss: -3.317974090576172
Batch 10/64 loss: -3.2689085006713867
Batch 11/64 loss: -2.530856132507324
Batch 12/64 loss: -3.2052431106567383
Batch 13/64 loss: -3.385331153869629
Batch 14/64 loss: -3.259516716003418
Batch 15/64 loss: -3.3681488037109375
Batch 16/64 loss: -3.454442024230957
Batch 17/64 loss: -3.492431640625
Batch 18/64 loss: -3.270352363586426
Batch 19/64 loss: -3.468081474304199
Batch 20/64 loss: -3.068704605102539
Batch 21/64 loss: -3.096888542175293
Batch 22/64 loss: -3.157011032104492
Batch 23/64 loss: -3.3233728408813477
Batch 24/64 loss: -2.4772205352783203
Batch 25/64 loss: -3.314652442932129
Batch 26/64 loss: -2.932424545288086
Batch 27/64 loss: -2.466092109680176
Batch 28/64 loss: -2.7432918548583984
Batch 29/64 loss: -3.123833656311035
Batch 30/64 loss: -3.363724708557129
Batch 31/64 loss: -2.8336181640625
Batch 32/64 loss: -3.324397087097168
Batch 33/64 loss: -3.220949172973633
Batch 34/64 loss: -3.2946271896362305
Batch 35/64 loss: -3.3382225036621094
Batch 36/64 loss: -3.0983619689941406
Batch 37/64 loss: -3.425084114074707
Batch 38/64 loss: -3.2063217163085938
Batch 39/64 loss: -3.1883792877197266
Batch 40/64 loss: -3.260312080383301
Batch 41/64 loss: -3.2661266326904297
Batch 42/64 loss: -3.3129472732543945
Batch 43/64 loss: -3.397810935974121
Batch 44/64 loss: -3.444310188293457
Batch 45/64 loss: -2.9839401245117188
Batch 46/64 loss: -3.368785858154297
Batch 47/64 loss: -2.868983268737793
Batch 48/64 loss: -2.76992130279541
Batch 49/64 loss: -2.9372215270996094
Batch 50/64 loss: -3.2190399169921875
Batch 51/64 loss: -2.8719892501831055
Batch 52/64 loss: -2.560492515563965
Batch 53/64 loss: -3.2515382766723633
Batch 54/64 loss: -2.6182689666748047
Batch 55/64 loss: -3.088459014892578
Batch 56/64 loss: -2.7902088165283203
Batch 57/64 loss: -3.313861846923828
Batch 58/64 loss: -2.734105110168457
Batch 59/64 loss: -2.974705696105957
Batch 60/64 loss: -3.081340789794922
Batch 61/64 loss: -3.2593917846679688
Batch 62/64 loss: -3.193314552307129
Batch 63/64 loss: -3.1484689712524414
Batch 64/64 loss: -7.946174621582031
Epoch 166  Train loss: -3.1813371097340304  Val loss: -3.4296583588590326
Epoch 167
-------------------------------
Batch 1/64 loss: -3.224400520324707
Batch 2/64 loss: -3.2781553268432617
Batch 3/64 loss: -3.2554359436035156
Batch 4/64 loss: -3.2567405700683594
Batch 5/64 loss: -3.1243534088134766
Batch 6/64 loss: -3.59840726852417
Batch 7/64 loss: -3.2358856201171875
Batch 8/64 loss: -3.2071189880371094
Batch 9/64 loss: -2.538616180419922
Batch 10/64 loss: -2.940121650695801
Batch 11/64 loss: -3.187563896179199
Batch 12/64 loss: -3.100616455078125
Batch 13/64 loss: -2.884492874145508
Batch 14/64 loss: -3.309337615966797
Batch 15/64 loss: -2.4762163162231445
Batch 16/64 loss: -2.855508804321289
Batch 17/64 loss: -3.3176889419555664
Batch 18/64 loss: -3.42996883392334
Batch 19/64 loss: -3.282729148864746
Batch 20/64 loss: -2.991806983947754
Batch 21/64 loss: -3.251828193664551
Batch 22/64 loss: -2.993223190307617
Batch 23/64 loss: -3.0013952255249023
Batch 24/64 loss: -3.0644235610961914
Batch 25/64 loss: -3.419833183288574
Batch 26/64 loss: -3.198627471923828
Batch 27/64 loss: -3.0463037490844727
Batch 28/64 loss: -3.016129493713379
Batch 29/64 loss: -3.1982364654541016
Batch 30/64 loss: -3.084073066711426
Batch 31/64 loss: -3.2699718475341797
Batch 32/64 loss: -3.433156967163086
Batch 33/64 loss: -3.5261850357055664
Batch 34/64 loss: -2.857344627380371
Batch 35/64 loss: -2.7694692611694336
Batch 36/64 loss: -3.227893829345703
Batch 37/64 loss: -3.3467798233032227
Batch 38/64 loss: -2.7532529830932617
Batch 39/64 loss: -3.3792123794555664
Batch 40/64 loss: -3.238504409790039
Batch 41/64 loss: -3.250429153442383
Batch 42/64 loss: -2.982579231262207
Batch 43/64 loss: -3.2898120880126953
Batch 44/64 loss: -3.3127212524414062
Batch 45/64 loss: -3.3991260528564453
Batch 46/64 loss: -3.118472099304199
Batch 47/64 loss: -3.438723564147949
Batch 48/64 loss: -3.120577812194824
Batch 49/64 loss: -3.50949764251709
Batch 50/64 loss: -3.3509740829467773
Batch 51/64 loss: -3.3728017807006836
Batch 52/64 loss: -2.9682435989379883
Batch 53/64 loss: -3.227433204650879
Batch 54/64 loss: -3.1584224700927734
Batch 55/64 loss: -3.3276634216308594
Batch 56/64 loss: -3.08221435546875
Batch 57/64 loss: -3.282229423522949
Batch 58/64 loss: -3.264163017272949
Batch 59/64 loss: -3.0058765411376953
Batch 60/64 loss: -3.2246885299682617
Batch 61/64 loss: -3.2596006393432617
Batch 62/64 loss: -3.224148750305176
Batch 63/64 loss: -2.9661598205566406
Batch 64/64 loss: -7.937761306762695
Epoch 167  Train loss: -3.226053170596852  Val loss: -3.5234785702630007
Epoch 168
-------------------------------
Batch 1/64 loss: -3.101377487182617
Batch 2/64 loss: -3.1856307983398438
Batch 3/64 loss: -3.077421188354492
Batch 4/64 loss: -2.815211296081543
Batch 5/64 loss: -3.107614517211914
Batch 6/64 loss: -3.2983388900756836
Batch 7/64 loss: -3.3763933181762695
Batch 8/64 loss: -2.851003646850586
Batch 9/64 loss: -2.7805919647216797
Batch 10/64 loss: -2.899759292602539
Batch 11/64 loss: -3.317572593688965
Batch 12/64 loss: -3.452556610107422
Batch 13/64 loss: -3.1685714721679688
Batch 14/64 loss: -3.2444992065429688
Batch 15/64 loss: -3.4319849014282227
Batch 16/64 loss: -2.9986391067504883
Batch 17/64 loss: -3.1942996978759766
Batch 18/64 loss: -3.4016923904418945
Batch 19/64 loss: -3.4446020126342773
Batch 20/64 loss: -3.0177383422851562
Batch 21/64 loss: -3.3244543075561523
Batch 22/64 loss: -3.1578760147094727
Batch 23/64 loss: -3.162785530090332
Batch 24/64 loss: -2.9247589111328125
Batch 25/64 loss: -3.051321029663086
Batch 26/64 loss: -3.427906036376953
Batch 27/64 loss: -3.252835273742676
Batch 28/64 loss: -3.3035526275634766
Batch 29/64 loss: -3.0489578247070312
Batch 30/64 loss: -3.2567577362060547
Batch 31/64 loss: -3.424285888671875
Batch 32/64 loss: -3.4829368591308594
Batch 33/64 loss: -2.8928890228271484
Batch 34/64 loss: -3.2808446884155273
Batch 35/64 loss: -3.506471633911133
Batch 36/64 loss: -3.183182716369629
Batch 37/64 loss: -3.3492002487182617
Batch 38/64 loss: -3.2109994888305664
Batch 39/64 loss: -3.477285385131836
Batch 40/64 loss: -3.1732892990112305
Batch 41/64 loss: -2.852924346923828
Batch 42/64 loss: -3.260727882385254
Batch 43/64 loss: -2.7671260833740234
Batch 44/64 loss: -2.6508827209472656
Batch 45/64 loss: -2.9526262283325195
Batch 46/64 loss: -2.7310876846313477
Batch 47/64 loss: -3.026487350463867
Batch 48/64 loss: -2.9774274826049805
Batch 49/64 loss: -2.9520559310913086
Batch 50/64 loss: -3.290487289428711
Batch 51/64 loss: -3.2514429092407227
Batch 52/64 loss: -3.2910146713256836
Batch 53/64 loss: -3.306924819946289
Batch 54/64 loss: -3.3360986709594727
Batch 55/64 loss: -3.2056455612182617
Batch 56/64 loss: -2.948131561279297
Batch 57/64 loss: -3.491541862487793
Batch 58/64 loss: -3.3848772048950195
Batch 59/64 loss: -3.3582725524902344
Batch 60/64 loss: -3.4913530349731445
Batch 61/64 loss: -3.0986814498901367
Batch 62/64 loss: -3.0307703018188477
Batch 63/64 loss: -3.152247428894043
Batch 64/64 loss: -7.970007419586182
Epoch 168  Train loss: -3.228932232950248  Val loss: -3.386902392934688
Epoch 169
-------------------------------
Batch 1/64 loss: -3.3706235885620117
Batch 2/64 loss: -3.248899459838867
Batch 3/64 loss: -3.394284248352051
Batch 4/64 loss: -3.172520637512207
Batch 5/64 loss: -3.3862075805664062
Batch 6/64 loss: -3.2736825942993164
Batch 7/64 loss: -3.145528793334961
Batch 8/64 loss: -2.8757858276367188
Batch 9/64 loss: -3.2743310928344727
Batch 10/64 loss: -3.4088172912597656
Batch 11/64 loss: -3.463987350463867
Batch 12/64 loss: -3.0208654403686523
Batch 13/64 loss: -3.1778173446655273
Batch 14/64 loss: -3.384415626525879
Batch 15/64 loss: -3.377054214477539
Batch 16/64 loss: -3.425715446472168
Batch 17/64 loss: -3.412456512451172
Batch 18/64 loss: -3.290848731994629
Batch 19/64 loss: -3.219257354736328
Batch 20/64 loss: -3.1944284439086914
Batch 21/64 loss: -3.2412338256835938
Batch 22/64 loss: -3.1882524490356445
Batch 23/64 loss: -2.8751096725463867
Batch 24/64 loss: -3.259471893310547
Batch 25/64 loss: -3.1679840087890625
Batch 26/64 loss: -3.529132843017578
Batch 27/64 loss: -3.391143798828125
Batch 28/64 loss: -3.3618593215942383
Batch 29/64 loss: -3.124985694885254
Batch 30/64 loss: -2.9585933685302734
Batch 31/64 loss: -3.239182472229004
Batch 32/64 loss: -2.869810104370117
Batch 33/64 loss: -3.5145034790039062
Batch 34/64 loss: -3.3994550704956055
Batch 35/64 loss: -3.1882524490356445
Batch 36/64 loss: -3.3614273071289062
Batch 37/64 loss: -3.4535036087036133
Batch 38/64 loss: -3.272176742553711
Batch 39/64 loss: -3.1274280548095703
Batch 40/64 loss: -2.8308658599853516
Batch 41/64 loss: -3.3295154571533203
Batch 42/64 loss: -3.5024003982543945
Batch 43/64 loss: -3.313884735107422
Batch 44/64 loss: -3.452688217163086
Batch 45/64 loss: -3.557863235473633
Batch 46/64 loss: -2.6683597564697266
Batch 47/64 loss: -3.3266515731811523
Batch 48/64 loss: -3.1800308227539062
Batch 49/64 loss: -3.4716110229492188
Batch 50/64 loss: -3.43923282623291
Batch 51/64 loss: -3.362834930419922
Batch 52/64 loss: -3.2707719802856445
Batch 53/64 loss: -3.1305246353149414
Batch 54/64 loss: -3.221367835998535
Batch 55/64 loss: -3.0700578689575195
Batch 56/64 loss: -3.0641956329345703
Batch 57/64 loss: -2.8741636276245117
Batch 58/64 loss: -2.9918479919433594
Batch 59/64 loss: -3.233976364135742
Batch 60/64 loss: -3.243910789489746
Batch 61/64 loss: -3.3550844192504883
Batch 62/64 loss: -3.051333427429199
Batch 63/64 loss: -2.8698902130126953
Batch 64/64 loss: -8.031270980834961
Epoch 169  Train loss: -3.2921968721875956  Val loss: -3.5959317446574315
Saving best model, epoch: 169
Epoch 170
-------------------------------
Batch 1/64 loss: -3.32161808013916
Batch 2/64 loss: -3.3494977951049805
Batch 3/64 loss: -3.2712268829345703
Batch 4/64 loss: -3.3133296966552734
Batch 5/64 loss: -3.422732353210449
Batch 6/64 loss: -3.086441993713379
Batch 7/64 loss: -3.1920089721679688
Batch 8/64 loss: -3.267960548400879
Batch 9/64 loss: -3.44476318359375
Batch 10/64 loss: -3.3876218795776367
Batch 11/64 loss: -3.368391990661621
Batch 12/64 loss: -3.0564756393432617
Batch 13/64 loss: -2.966507911682129
Batch 14/64 loss: -3.3217248916625977
Batch 15/64 loss: -3.1071910858154297
Batch 16/64 loss: -3.4349212646484375
Batch 17/64 loss: -3.5108184814453125
Batch 18/64 loss: -3.1966686248779297
Batch 19/64 loss: -3.250441551208496
Batch 20/64 loss: -3.3710975646972656
Batch 21/64 loss: -3.5742616653442383
Batch 22/64 loss: -3.4036388397216797
Batch 23/64 loss: -3.212820053100586
Batch 24/64 loss: -3.457606315612793
Batch 25/64 loss: -3.3884477615356445
Batch 26/64 loss: -3.2367258071899414
Batch 27/64 loss: -3.136765480041504
Batch 28/64 loss: -2.9667720794677734
Batch 29/64 loss: -3.5255517959594727
Batch 30/64 loss: -3.1118812561035156
Batch 31/64 loss: -2.727017402648926
Batch 32/64 loss: -3.04831600189209
Batch 33/64 loss: -3.256866455078125
Batch 34/64 loss: -3.3368988037109375
Batch 35/64 loss: -2.7146339416503906
Batch 36/64 loss: -3.069352149963379
Batch 37/64 loss: -3.0571117401123047
Batch 38/64 loss: -3.107797622680664
Batch 39/64 loss: -3.3954639434814453
Batch 40/64 loss: -3.226029396057129
Batch 41/64 loss: -3.236598014831543
Batch 42/64 loss: -3.2147445678710938
Batch 43/64 loss: -2.754283905029297
Batch 44/64 loss: -3.4155101776123047
Batch 45/64 loss: -3.072660446166992
Batch 46/64 loss: -3.251530647277832
Batch 47/64 loss: -3.118867874145508
Batch 48/64 loss: -3.2397375106811523
Batch 49/64 loss: -2.894651412963867
Batch 50/64 loss: -3.182305335998535
Batch 51/64 loss: -3.4957571029663086
Batch 52/64 loss: -3.172697067260742
Batch 53/64 loss: -3.424318313598633
Batch 54/64 loss: -3.411886215209961
Batch 55/64 loss: -3.105677604675293
Batch 56/64 loss: -3.5073442459106445
Batch 57/64 loss: -3.2925405502319336
Batch 58/64 loss: -2.8699722290039062
Batch 59/64 loss: -3.372868537902832
Batch 60/64 loss: -3.109922409057617
Batch 61/64 loss: -3.4081716537475586
Batch 62/64 loss: -3.2567949295043945
Batch 63/64 loss: -3.386532783508301
Batch 64/64 loss: -8.057676315307617
Epoch 170  Train loss: -3.29151419097302  Val loss: -3.579183716134927
Epoch 171
-------------------------------
Batch 1/64 loss: -3.315688133239746
Batch 2/64 loss: -3.217087745666504
Batch 3/64 loss: -3.425037384033203
Batch 4/64 loss: -3.2683820724487305
Batch 5/64 loss: -3.5374393463134766
Batch 6/64 loss: -3.234219551086426
Batch 7/64 loss: -3.34619140625
Batch 8/64 loss: -3.4990386962890625
Batch 9/64 loss: -3.260761260986328
Batch 10/64 loss: -2.7732419967651367
Batch 11/64 loss: -3.1186084747314453
Batch 12/64 loss: -3.420586585998535
Batch 13/64 loss: -3.307096481323242
Batch 14/64 loss: -3.286956787109375
Batch 15/64 loss: -3.2238855361938477
Batch 16/64 loss: -3.4190425872802734
Batch 17/64 loss: -3.4360523223876953
Batch 18/64 loss: -3.440004348754883
Batch 19/64 loss: -3.229928970336914
Batch 20/64 loss: -3.3107357025146484
Batch 21/64 loss: -3.2762928009033203
Batch 22/64 loss: -3.037074089050293
Batch 23/64 loss: -3.1611833572387695
Batch 24/64 loss: -3.443974494934082
Batch 25/64 loss: -3.389810562133789
Batch 26/64 loss: -3.081439971923828
Batch 27/64 loss: -3.367506980895996
Batch 28/64 loss: -2.6894922256469727
Batch 29/64 loss: -3.1585988998413086
Batch 30/64 loss: -3.229391098022461
Batch 31/64 loss: -3.432040214538574
Batch 32/64 loss: -3.0767593383789062
Batch 33/64 loss: -3.0950794219970703
Batch 34/64 loss: -2.959209442138672
Batch 35/64 loss: -3.114100456237793
Batch 36/64 loss: -3.308889389038086
Batch 37/64 loss: -3.335979461669922
Batch 38/64 loss: -3.295106887817383
Batch 39/64 loss: -3.3357744216918945
Batch 40/64 loss: -3.492359161376953
Batch 41/64 loss: -3.558529853820801
Batch 42/64 loss: -2.7821922302246094
Batch 43/64 loss: -2.672682762145996
Batch 44/64 loss: -3.305471420288086
Batch 45/64 loss: -3.1949691772460938
Batch 46/64 loss: -3.2231626510620117
Batch 47/64 loss: -2.981830596923828
Batch 48/64 loss: -3.369670867919922
Batch 49/64 loss: -3.381824493408203
Batch 50/64 loss: -3.3753175735473633
Batch 51/64 loss: -3.2119932174682617
Batch 52/64 loss: -3.269533157348633
Batch 53/64 loss: -3.2522506713867188
Batch 54/64 loss: -3.074850082397461
Batch 55/64 loss: -2.8328676223754883
Batch 56/64 loss: -3.4716224670410156
Batch 57/64 loss: -3.201653480529785
Batch 58/64 loss: -3.4523134231567383
Batch 59/64 loss: -3.3767805099487305
Batch 60/64 loss: -2.8433380126953125
Batch 61/64 loss: -3.413435935974121
Batch 62/64 loss: -3.347994804382324
Batch 63/64 loss: -2.8714752197265625
Batch 64/64 loss: -7.95775032043457
Epoch 171  Train loss: -3.290731310376934  Val loss: -3.5536238549091563
Epoch 172
-------------------------------
Batch 1/64 loss: -3.147775650024414
Batch 2/64 loss: -3.271256446838379
Batch 3/64 loss: -3.0761566162109375
Batch 4/64 loss: -3.3103885650634766
Batch 5/64 loss: -3.2276487350463867
Batch 6/64 loss: -2.8920469284057617
Batch 7/64 loss: -3.3782196044921875
Batch 8/64 loss: -3.4486570358276367
Batch 9/64 loss: -2.5893564224243164
Batch 10/64 loss: -3.1820077896118164
Batch 11/64 loss: -3.549854278564453
Batch 12/64 loss: -3.403095245361328
Batch 13/64 loss: -3.2733373641967773
Batch 14/64 loss: -3.5141220092773438
Batch 15/64 loss: -2.8322458267211914
Batch 16/64 loss: -3.0382394790649414
Batch 17/64 loss: -3.3545751571655273
Batch 18/64 loss: -3.09420108795166
Batch 19/64 loss: -3.5014381408691406
Batch 20/64 loss: -3.3055543899536133
Batch 21/64 loss: -3.4504785537719727
Batch 22/64 loss: -3.2406787872314453
Batch 23/64 loss: -3.4268245697021484
Batch 24/64 loss: -3.424197196960449
Batch 25/64 loss: -3.130075454711914
Batch 26/64 loss: -3.348112106323242
Batch 27/64 loss: -3.525320053100586
Batch 28/64 loss: -2.9599342346191406
Batch 29/64 loss: -3.359555244445801
Batch 30/64 loss: -2.623147964477539
Batch 31/64 loss: -3.579713821411133
Batch 32/64 loss: -3.4090070724487305
Batch 33/64 loss: -3.3757829666137695
Batch 34/64 loss: -3.284942626953125
Batch 35/64 loss: -3.323361396789551
Batch 36/64 loss: -2.9684858322143555
Batch 37/64 loss: -2.900235176086426
Batch 38/64 loss: -3.267719268798828
Batch 39/64 loss: -3.3669862747192383
Batch 40/64 loss: -3.2563514709472656
Batch 41/64 loss: -3.487905502319336
Batch 42/64 loss: -2.9822025299072266
Batch 43/64 loss: -3.005120277404785
Batch 44/64 loss: -3.507035255432129
Batch 45/64 loss: -3.4551687240600586
Batch 46/64 loss: -3.375516891479492
Batch 47/64 loss: -3.023509979248047
Batch 48/64 loss: -3.2280101776123047
Batch 49/64 loss: -3.5233678817749023
Batch 50/64 loss: -3.2501487731933594
Batch 51/64 loss: -3.1308326721191406
Batch 52/64 loss: -3.087127685546875
Batch 53/64 loss: -3.239286422729492
Batch 54/64 loss: -3.2411108016967773
Batch 55/64 loss: -3.28759765625
Batch 56/64 loss: -3.4637575149536133
Batch 57/64 loss: -2.870110511779785
Batch 58/64 loss: -3.3228759765625
Batch 59/64 loss: -2.898862838745117
Batch 60/64 loss: -3.1023054122924805
Batch 61/64 loss: -3.255618095397949
Batch 62/64 loss: -3.094925880432129
Batch 63/64 loss: -3.2523937225341797
Batch 64/64 loss: -7.919854164123535
Epoch 172  Train loss: -3.2884042141484278  Val loss: -3.6055687842090514
Saving best model, epoch: 172
Epoch 173
-------------------------------
Batch 1/64 loss: -3.263880729675293
Batch 2/64 loss: -3.5911331176757812
Batch 3/64 loss: -3.502547264099121
Batch 4/64 loss: -3.3040904998779297
Batch 5/64 loss: -3.268125534057617
Batch 6/64 loss: -3.3772621154785156
Batch 7/64 loss: -3.0879364013671875
Batch 8/64 loss: -3.2936391830444336
Batch 9/64 loss: -3.2853946685791016
Batch 10/64 loss: -3.50040340423584
Batch 11/64 loss: -3.1889028549194336
Batch 12/64 loss: -3.400239944458008
Batch 13/64 loss: -3.197446823120117
Batch 14/64 loss: -3.3442678451538086
Batch 15/64 loss: -3.483029365539551
Batch 16/64 loss: -3.4366989135742188
Batch 17/64 loss: -3.3646974563598633
Batch 18/64 loss: -2.931966781616211
Batch 19/64 loss: -3.3659372329711914
Batch 20/64 loss: -3.1070938110351562
Batch 21/64 loss: -3.237009048461914
Batch 22/64 loss: -3.1716156005859375
Batch 23/64 loss: -3.3266515731811523
Batch 24/64 loss: -2.909792900085449
Batch 25/64 loss: -3.5688486099243164
Batch 26/64 loss: -3.325357437133789
Batch 27/64 loss: -3.3259458541870117
Batch 28/64 loss: -2.773477554321289
Batch 29/64 loss: -2.9170751571655273
Batch 30/64 loss: -3.290060043334961
Batch 31/64 loss: -3.492145538330078
Batch 32/64 loss: -3.227585792541504
Batch 33/64 loss: -3.4208831787109375
Batch 34/64 loss: -3.528079032897949
Batch 35/64 loss: -2.8770713806152344
Batch 36/64 loss: -2.868196487426758
Batch 37/64 loss: -3.2933216094970703
Batch 38/64 loss: -3.390592575073242
Batch 39/64 loss: -3.3032665252685547
Batch 40/64 loss: -3.152268409729004
Batch 41/64 loss: -3.229959487915039
Batch 42/64 loss: -3.436147689819336
Batch 43/64 loss: -2.649820327758789
Batch 44/64 loss: -3.233445167541504
Batch 45/64 loss: -3.1878480911254883
Batch 46/64 loss: -3.316629409790039
Batch 47/64 loss: -3.3441781997680664
Batch 48/64 loss: -3.509976387023926
Batch 49/64 loss: -2.756960868835449
Batch 50/64 loss: -2.8342199325561523
Batch 51/64 loss: -3.2226600646972656
Batch 52/64 loss: -3.140172004699707
Batch 53/64 loss: -2.941770553588867
Batch 54/64 loss: -3.2004823684692383
Batch 55/64 loss: -2.9487390518188477
Batch 56/64 loss: -2.871932029724121
Batch 57/64 loss: -3.219027519226074
Batch 58/64 loss: -3.244879722595215
Batch 59/64 loss: -3.0563602447509766
Batch 60/64 loss: -3.3737878799438477
Batch 61/64 loss: -3.457672119140625
Batch 62/64 loss: -3.053791046142578
Batch 63/64 loss: -3.3551158905029297
Batch 64/64 loss: -7.457369804382324
Epoch 173  Train loss: -3.2764320261338176  Val loss: -3.269559119575212
Epoch 174
-------------------------------
Batch 1/64 loss: -3.3414039611816406
Batch 2/64 loss: -2.8556928634643555
Batch 3/64 loss: -2.615626335144043
Batch 4/64 loss: -3.3640270233154297
Batch 5/64 loss: -3.2209291458129883
Batch 6/64 loss: -3.0807533264160156
Batch 7/64 loss: -3.5064382553100586
Batch 8/64 loss: -3.527545928955078
Batch 9/64 loss: -2.8879623413085938
Batch 10/64 loss: -3.20639705657959
Batch 11/64 loss: -3.1232423782348633
Batch 12/64 loss: -3.0455102920532227
Batch 13/64 loss: -3.0216407775878906
Batch 14/64 loss: -3.0789480209350586
Batch 15/64 loss: -3.3373966217041016
Batch 16/64 loss: -3.031665802001953
Batch 17/64 loss: -3.30075740814209
Batch 18/64 loss: -3.224869728088379
Batch 19/64 loss: -3.1725759506225586
Batch 20/64 loss: -3.387515068054199
Batch 21/64 loss: -2.889235496520996
Batch 22/64 loss: -3.3436899185180664
Batch 23/64 loss: -3.365048408508301
Batch 24/64 loss: -3.280137062072754
Batch 25/64 loss: -3.1992502212524414
Batch 26/64 loss: -2.8926820755004883
Batch 27/64 loss: -3.2667036056518555
Batch 28/64 loss: -3.050670623779297
Batch 29/64 loss: -3.327467918395996
Batch 30/64 loss: -2.9626026153564453
Batch 31/64 loss: -3.495197296142578
Batch 32/64 loss: -3.4416141510009766
Batch 33/64 loss: -3.1888084411621094
Batch 34/64 loss: -3.2457876205444336
Batch 35/64 loss: -3.1164350509643555
Batch 36/64 loss: -3.140979766845703
Batch 37/64 loss: -3.2866172790527344
Batch 38/64 loss: -3.2735538482666016
Batch 39/64 loss: -2.990689277648926
Batch 40/64 loss: -2.8188600540161133
Batch 41/64 loss: -3.216597557067871
Batch 42/64 loss: -3.187906265258789
Batch 43/64 loss: -3.3649864196777344
Batch 44/64 loss: -2.921168327331543
Batch 45/64 loss: -3.516293525695801
Batch 46/64 loss: -3.1918325424194336
Batch 47/64 loss: -3.0779733657836914
Batch 48/64 loss: -3.0068559646606445
Batch 49/64 loss: -2.940967559814453
Batch 50/64 loss: -3.249527931213379
Batch 51/64 loss: -3.3578929901123047
Batch 52/64 loss: -2.777745246887207
Batch 53/64 loss: -3.3564271926879883
Batch 54/64 loss: -3.1032638549804688
Batch 55/64 loss: -3.2773704528808594
Batch 56/64 loss: -3.188878059387207
Batch 57/64 loss: -3.0781774520874023
Batch 58/64 loss: -3.1170034408569336
Batch 59/64 loss: -3.09674072265625
Batch 60/64 loss: -1.8930091857910156
Batch 61/64 loss: -2.508236885070801
Batch 62/64 loss: -3.254291534423828
Batch 63/64 loss: -2.5043582916259766
Batch 64/64 loss: -7.746288776397705
Epoch 174  Train loss: -3.1828102018318924  Val loss: -3.0187207906926212
Epoch 175
-------------------------------
Batch 1/64 loss: -2.832582473754883
Batch 2/64 loss: -2.3518714904785156
Batch 3/64 loss: -2.9744815826416016
Batch 4/64 loss: -3.050933837890625
Batch 5/64 loss: -3.1556196212768555
Batch 6/64 loss: -3.237025260925293
Batch 7/64 loss: -2.6084461212158203
Batch 8/64 loss: -2.6945953369140625
Batch 9/64 loss: -2.769526481628418
Batch 10/64 loss: -3.0296449661254883
Batch 11/64 loss: -3.2510786056518555
Batch 12/64 loss: -3.2669525146484375
Batch 13/64 loss: -3.090608596801758
Batch 14/64 loss: -2.9977779388427734
Batch 15/64 loss: -2.7822227478027344
Batch 16/64 loss: -3.3078651428222656
Batch 17/64 loss: -3.0728254318237305
Batch 18/64 loss: -3.017237663269043
Batch 19/64 loss: -3.38442325592041
Batch 20/64 loss: -3.116286277770996
Batch 21/64 loss: -2.7724876403808594
Batch 22/64 loss: -3.266238212585449
Batch 23/64 loss: -3.0295963287353516
Batch 24/64 loss: -3.2212390899658203
Batch 25/64 loss: -2.688380241394043
Batch 26/64 loss: -3.119349479675293
Batch 27/64 loss: -2.833991050720215
Batch 28/64 loss: -3.2468204498291016
Batch 29/64 loss: -2.989633560180664
Batch 30/64 loss: -3.10018253326416
Batch 31/64 loss: -3.288092613220215
Batch 32/64 loss: -2.9281139373779297
Batch 33/64 loss: -2.8293371200561523
Batch 34/64 loss: -3.323258399963379
Batch 35/64 loss: -3.2764434814453125
Batch 36/64 loss: -3.0179033279418945
Batch 37/64 loss: -3.2436561584472656
Batch 38/64 loss: -3.2385120391845703
Batch 39/64 loss: -2.9719696044921875
Batch 40/64 loss: -3.1166152954101562
Batch 41/64 loss: -2.9388980865478516
Batch 42/64 loss: -2.835460662841797
Batch 43/64 loss: -3.3315439224243164
Batch 44/64 loss: -3.335259437561035
Batch 45/64 loss: -3.0227813720703125
Batch 46/64 loss: -2.894587516784668
Batch 47/64 loss: -2.826000213623047
Batch 48/64 loss: -3.2081594467163086
Batch 49/64 loss: -2.606686592102051
Batch 50/64 loss: -2.9127283096313477
Batch 51/64 loss: -3.351809501647949
Batch 52/64 loss: -2.589827537536621
Batch 53/64 loss: -2.3771896362304688
Batch 54/64 loss: -2.849860191345215
Batch 55/64 loss: -3.0017290115356445
Batch 56/64 loss: -2.3933544158935547
Batch 57/64 loss: -2.706838607788086
Batch 58/64 loss: -2.8314571380615234
Batch 59/64 loss: -2.7061195373535156
Batch 60/64 loss: -3.217947006225586
Batch 61/64 loss: -3.1920576095581055
Batch 62/64 loss: -2.912534713745117
Batch 63/64 loss: -3.0460824966430664
Batch 64/64 loss: -7.457465171813965
Epoch 175  Train loss: -3.0458954941992666  Val loss: -3.195552471986751
Epoch 176
-------------------------------
Batch 1/64 loss: -2.940089225769043
Batch 2/64 loss: -1.5149717330932617
Batch 3/64 loss: -3.1817474365234375
Batch 4/64 loss: -3.142965316772461
Batch 5/64 loss: -2.7383174896240234
Batch 6/64 loss: -3.062074661254883
Batch 7/64 loss: -2.570277214050293
Batch 8/64 loss: -2.383530616760254
Batch 9/64 loss: -3.2766151428222656
Batch 10/64 loss: -3.227290153503418
Batch 11/64 loss: -3.0514402389526367
Batch 12/64 loss: -2.398381233215332
Batch 13/64 loss: -3.1805591583251953
Batch 14/64 loss: -3.287032127380371
Batch 15/64 loss: -3.1046199798583984
Batch 16/64 loss: -3.1550722122192383
Batch 17/64 loss: -3.1107959747314453
Batch 18/64 loss: -3.203059196472168
Batch 19/64 loss: -3.0323638916015625
Batch 20/64 loss: -2.411318778991699
Batch 21/64 loss: -3.27622127532959
Batch 22/64 loss: -3.386956214904785
Batch 23/64 loss: -3.3104753494262695
Batch 24/64 loss: -3.2812376022338867
Batch 25/64 loss: -3.0439014434814453
Batch 26/64 loss: -3.029006004333496
Batch 27/64 loss: -3.3754310607910156
Batch 28/64 loss: -3.4155616760253906
Batch 29/64 loss: -3.304572105407715
Batch 30/64 loss: -3.2417774200439453
Batch 31/64 loss: -3.471957206726074
Batch 32/64 loss: -2.767947196960449
Batch 33/64 loss: -2.684290885925293
Batch 34/64 loss: -3.334859848022461
Batch 35/64 loss: -3.2225141525268555
Batch 36/64 loss: -3.260624885559082
Batch 37/64 loss: -3.317561149597168
Batch 38/64 loss: -3.42995548248291
Batch 39/64 loss: -3.4650821685791016
Batch 40/64 loss: -3.2205801010131836
Batch 41/64 loss: -2.8652753829956055
Batch 42/64 loss: -2.9921207427978516
Batch 43/64 loss: -3.087259292602539
Batch 44/64 loss: -3.4287023544311523
Batch 45/64 loss: -3.1492815017700195
Batch 46/64 loss: -2.937129020690918
Batch 47/64 loss: -3.3670883178710938
Batch 48/64 loss: -3.284027099609375
Batch 49/64 loss: -3.317546844482422
Batch 50/64 loss: -3.086949348449707
Batch 51/64 loss: -3.4753618240356445
Batch 52/64 loss: -3.275484085083008
Batch 53/64 loss: -3.160712242126465
Batch 54/64 loss: -3.424837112426758
Batch 55/64 loss: -2.980900764465332
Batch 56/64 loss: -3.362051010131836
Batch 57/64 loss: -3.137521743774414
Batch 58/64 loss: -2.8471736907958984
Batch 59/64 loss: -3.435403823852539
Batch 60/64 loss: -3.478562355041504
Batch 61/64 loss: -3.2449607849121094
Batch 62/64 loss: -3.470688819885254
Batch 63/64 loss: -3.2708816528320312
Batch 64/64 loss: -7.423142433166504
Epoch 176  Train loss: -3.175848025901645  Val loss: -3.4978109012354692
Epoch 177
-------------------------------
Batch 1/64 loss: -3.3384218215942383
Batch 2/64 loss: -3.0641374588012695
Batch 3/64 loss: -3.0832910537719727
Batch 4/64 loss: -3.2775650024414062
Batch 5/64 loss: -3.0603771209716797
Batch 6/64 loss: -3.364790916442871
Batch 7/64 loss: -3.4791336059570312
Batch 8/64 loss: -2.619281768798828
Batch 9/64 loss: -3.1251068115234375
Batch 10/64 loss: -3.4804258346557617
Batch 11/64 loss: -2.914034843444824
Batch 12/64 loss: -3.344827651977539
Batch 13/64 loss: -3.09902286529541
Batch 14/64 loss: -3.1409826278686523
Batch 15/64 loss: -3.391127586364746
Batch 16/64 loss: -3.0471677780151367
Batch 17/64 loss: -3.219302177429199
Batch 18/64 loss: -3.374837875366211
Batch 19/64 loss: -3.4400901794433594
Batch 20/64 loss: -3.0968217849731445
Batch 21/64 loss: -3.3858203887939453
Batch 22/64 loss: -3.350346565246582
Batch 23/64 loss: -2.7601146697998047
Batch 24/64 loss: -2.7996673583984375
Batch 25/64 loss: -3.155938148498535
Batch 26/64 loss: -3.0108022689819336
Batch 27/64 loss: -3.032212257385254
Batch 28/64 loss: -3.2828359603881836
Batch 29/64 loss: -2.995577812194824
Batch 30/64 loss: -3.3198890686035156
Batch 31/64 loss: -3.019306182861328
Batch 32/64 loss: -3.1571216583251953
Batch 33/64 loss: -3.2359542846679688
Batch 34/64 loss: -2.928694725036621
Batch 35/64 loss: -3.4807586669921875
Batch 36/64 loss: -3.1520395278930664
Batch 37/64 loss: -3.2077388763427734
Batch 38/64 loss: -3.4133033752441406
Batch 39/64 loss: -3.0813589096069336
Batch 40/64 loss: -3.078810691833496
Batch 41/64 loss: -3.356111526489258
Batch 42/64 loss: -3.09548282623291
Batch 43/64 loss: -3.2657508850097656
Batch 44/64 loss: -3.34210205078125
Batch 45/64 loss: -3.3612070083618164
Batch 46/64 loss: -3.158940315246582
Batch 47/64 loss: -2.6634092330932617
Batch 48/64 loss: -3.313021659851074
Batch 49/64 loss: -3.11007022857666
Batch 50/64 loss: -2.878758430480957
Batch 51/64 loss: -3.384467124938965
Batch 52/64 loss: -2.659341812133789
Batch 53/64 loss: -3.3242006301879883
Batch 54/64 loss: -2.9674625396728516
Batch 55/64 loss: -3.248197555541992
Batch 56/64 loss: -3.1919355392456055
Batch 57/64 loss: -3.0577688217163086
Batch 58/64 loss: -3.321321487426758
Batch 59/64 loss: -3.435580253601074
Batch 60/64 loss: -2.9654722213745117
Batch 61/64 loss: -3.005467414855957
Batch 62/64 loss: -3.28707218170166
Batch 63/64 loss: -3.0104503631591797
Batch 64/64 loss: -7.951674461364746
Epoch 177  Train loss: -3.218453115575454  Val loss: -3.48744149224455
Epoch 178
-------------------------------
Batch 1/64 loss: -2.903911590576172
Batch 2/64 loss: -3.180466651916504
Batch 3/64 loss: -3.3773155212402344
Batch 4/64 loss: -3.318099021911621
Batch 5/64 loss: -3.2088727951049805
Batch 6/64 loss: -2.7261829376220703
Batch 7/64 loss: -3.3604507446289062
Batch 8/64 loss: -3.3963184356689453
Batch 9/64 loss: -3.139789581298828
Batch 10/64 loss: -2.968111991882324
Batch 11/64 loss: -2.8196535110473633
Batch 12/64 loss: -2.5510292053222656
Batch 13/64 loss: -3.4796981811523438
Batch 14/64 loss: -2.009502410888672
Batch 15/64 loss: -3.1028671264648438
Batch 16/64 loss: -3.1529035568237305
Batch 17/64 loss: -3.5140609741210938
Batch 18/64 loss: -3.2691850662231445
Batch 19/64 loss: -3.0464258193969727
Batch 20/64 loss: -2.42751407623291
Batch 21/64 loss: -2.692758560180664
Batch 22/64 loss: -3.337285041809082
Batch 23/64 loss: -3.32373046875
Batch 24/64 loss: -3.1931915283203125
Batch 25/64 loss: -3.402829170227051
Batch 26/64 loss: -3.161776542663574
Batch 27/64 loss: -3.3091201782226562
Batch 28/64 loss: -3.2767629623413086
Batch 29/64 loss: -3.2720947265625
Batch 30/64 loss: -3.329784393310547
Batch 31/64 loss: -3.417294502258301
Batch 32/64 loss: -3.3112478256225586
Batch 33/64 loss: -3.104212760925293
Batch 34/64 loss: -2.750441551208496
Batch 35/64 loss: -3.357309341430664
Batch 36/64 loss: -3.2092533111572266
Batch 37/64 loss: -3.241206169128418
Batch 38/64 loss: -3.315340042114258
Batch 39/64 loss: -3.442042350769043
Batch 40/64 loss: -3.4489994049072266
Batch 41/64 loss: -2.787820816040039
Batch 42/64 loss: -3.1197614669799805
Batch 43/64 loss: -2.9511117935180664
Batch 44/64 loss: -3.3648452758789062
Batch 45/64 loss: -3.073971748352051
Batch 46/64 loss: -3.163018226623535
Batch 47/64 loss: -3.2090330123901367
Batch 48/64 loss: -3.498255729675293
Batch 49/64 loss: -2.7892446517944336
Batch 50/64 loss: -2.670199394226074
Batch 51/64 loss: -3.119731903076172
Batch 52/64 loss: -3.221341133117676
Batch 53/64 loss: -3.25140380859375
Batch 54/64 loss: -3.261795997619629
Batch 55/64 loss: -3.163445472717285
Batch 56/64 loss: -3.0996618270874023
Batch 57/64 loss: -3.309575080871582
Batch 58/64 loss: -2.6930789947509766
Batch 59/64 loss: -3.3807506561279297
Batch 60/64 loss: -3.381516456604004
Batch 61/64 loss: -3.1012191772460938
Batch 62/64 loss: -3.2383689880371094
Batch 63/64 loss: -3.145258903503418
Batch 64/64 loss: -8.03521728515625
Epoch 178  Train loss: -3.1979586432961855  Val loss: -3.5555270217947945
Epoch 179
-------------------------------
Batch 1/64 loss: -3.206608772277832
Batch 2/64 loss: -3.1203765869140625
Batch 3/64 loss: -3.002800941467285
Batch 4/64 loss: -3.5062742233276367
Batch 5/64 loss: -2.7849836349487305
Batch 6/64 loss: -3.1371612548828125
Batch 7/64 loss: -3.318857192993164
Batch 8/64 loss: -3.295734405517578
Batch 9/64 loss: -2.803323745727539
Batch 10/64 loss: -3.177912712097168
Batch 11/64 loss: -3.2806396484375
Batch 12/64 loss: -2.7508678436279297
Batch 13/64 loss: -3.172697067260742
Batch 14/64 loss: -3.1653385162353516
Batch 15/64 loss: -2.99337100982666
Batch 16/64 loss: -3.178605079650879
Batch 17/64 loss: -3.123991012573242
Batch 18/64 loss: -3.097142219543457
Batch 19/64 loss: -2.9593706130981445
Batch 20/64 loss: -3.3480148315429688
Batch 21/64 loss: -3.3449487686157227
Batch 22/64 loss: -3.120025634765625
Batch 23/64 loss: -3.2073745727539062
Batch 24/64 loss: -3.1229047775268555
Batch 25/64 loss: -3.276261329650879
Batch 26/64 loss: -3.4837217330932617
Batch 27/64 loss: -3.2287216186523438
Batch 28/64 loss: -3.4022226333618164
Batch 29/64 loss: -3.3275842666625977
Batch 30/64 loss: -3.1646575927734375
Batch 31/64 loss: -3.4329748153686523
Batch 32/64 loss: -3.2926511764526367
Batch 33/64 loss: -3.2740964889526367
Batch 34/64 loss: -2.9233999252319336
Batch 35/64 loss: -3.3249387741088867
Batch 36/64 loss: -3.4828872680664062
Batch 37/64 loss: -3.2617311477661133
Batch 38/64 loss: -3.3141937255859375
Batch 39/64 loss: -3.3102550506591797
Batch 40/64 loss: -3.551279067993164
Batch 41/64 loss: -3.2192201614379883
Batch 42/64 loss: -3.23883056640625
Batch 43/64 loss: -3.0943212509155273
Batch 44/64 loss: -3.609414577484131
Batch 45/64 loss: -2.8357839584350586
Batch 46/64 loss: -3.518582344055176
Batch 47/64 loss: -2.6789817810058594
Batch 48/64 loss: -3.3112869262695312
Batch 49/64 loss: -3.2616987228393555
Batch 50/64 loss: -3.2926855087280273
Batch 51/64 loss: -3.2695999145507812
Batch 52/64 loss: -3.3318872451782227
Batch 53/64 loss: -3.3425636291503906
Batch 54/64 loss: -3.47238826751709
Batch 55/64 loss: -2.9978036880493164
Batch 56/64 loss: -3.399812698364258
Batch 57/64 loss: -3.397815704345703
Batch 58/64 loss: -3.4248886108398438
Batch 59/64 loss: -3.4273557662963867
Batch 60/64 loss: -3.454090118408203
Batch 61/64 loss: -3.3337631225585938
Batch 62/64 loss: -3.4000701904296875
Batch 63/64 loss: -3.00384521484375
Batch 64/64 loss: -7.403445243835449
Epoch 179  Train loss: -3.280630205191818  Val loss: -3.4673487476466858
Epoch 180
-------------------------------
Batch 1/64 loss: -3.547555923461914
Batch 2/64 loss: -2.975399971008301
Batch 3/64 loss: -3.400606155395508
Batch 4/64 loss: -2.9501590728759766
Batch 5/64 loss: -3.5365772247314453
Batch 6/64 loss: -3.169452667236328
Batch 7/64 loss: -3.249447822570801
Batch 8/64 loss: -3.1305370330810547
Batch 9/64 loss: -3.1913509368896484
Batch 10/64 loss: -2.9967241287231445
Batch 11/64 loss: -3.37100887298584
Batch 12/64 loss: -3.0890979766845703
Batch 13/64 loss: -3.1987714767456055
Batch 14/64 loss: -3.108470916748047
Batch 15/64 loss: -3.094860076904297
Batch 16/64 loss: -3.0700807571411133
Batch 17/64 loss: -3.0748844146728516
Batch 18/64 loss: -3.0494518280029297
Batch 19/64 loss: -3.0824546813964844
Batch 20/64 loss: -3.4474287033081055
Batch 21/64 loss: -2.683640480041504
Batch 22/64 loss: -3.2563066482543945
Batch 23/64 loss: -3.164423942565918
Batch 24/64 loss: -3.380457878112793
Batch 25/64 loss: -3.2005414962768555
Batch 26/64 loss: -3.14040470123291
Batch 27/64 loss: -2.96929931640625
Batch 28/64 loss: -3.3826122283935547
Batch 29/64 loss: -3.1519269943237305
Batch 30/64 loss: -3.5038042068481445
Batch 31/64 loss: -3.3541250228881836
Batch 32/64 loss: -3.22208309173584
Batch 33/64 loss: -3.4508485794067383
Batch 34/64 loss: -3.5000810623168945
Batch 35/64 loss: -3.226106643676758
Batch 36/64 loss: -3.2566537857055664
Batch 37/64 loss: -3.424647331237793
Batch 38/64 loss: -3.567716598510742
Batch 39/64 loss: -3.373490333557129
Batch 40/64 loss: -3.495454788208008
Batch 41/64 loss: -3.4295949935913086
Batch 42/64 loss: -3.3563222885131836
Batch 43/64 loss: -3.4937849044799805
Batch 44/64 loss: -3.227682113647461
Batch 45/64 loss: -3.173177719116211
Batch 46/64 loss: -3.440251350402832
Batch 47/64 loss: -3.1435537338256836
Batch 48/64 loss: -3.4206275939941406
Batch 49/64 loss: -3.358151435852051
Batch 50/64 loss: -2.9840078353881836
Batch 51/64 loss: -3.1004343032836914
Batch 52/64 loss: -3.46549129486084
Batch 53/64 loss: -3.2579345703125
Batch 54/64 loss: -3.3895692825317383
Batch 55/64 loss: -3.3456296920776367
Batch 56/64 loss: -3.280697822570801
Batch 57/64 loss: -3.0987415313720703
Batch 58/64 loss: -3.5655784606933594
Batch 59/64 loss: -3.2036476135253906
Batch 60/64 loss: -3.2264280319213867
Batch 61/64 loss: -3.410651206970215
Batch 62/64 loss: -3.27945613861084
Batch 63/64 loss: -3.2460241317749023
Batch 64/64 loss: -7.581056118011475
Epoch 180  Train loss: -3.3101517789504107  Val loss: -3.54871069524706
Epoch 181
-------------------------------
Batch 1/64 loss: -3.327167510986328
Batch 2/64 loss: -3.439258575439453
Batch 3/64 loss: -3.1018848419189453
Batch 4/64 loss: -3.3730087280273438
Batch 5/64 loss: -3.509566307067871
Batch 6/64 loss: -3.331465721130371
Batch 7/64 loss: -3.343669891357422
Batch 8/64 loss: -3.3154525756835938
Batch 9/64 loss: -2.99798583984375
Batch 10/64 loss: -3.49893856048584
Batch 11/64 loss: -3.6157498359680176
Batch 12/64 loss: -3.395909309387207
Batch 13/64 loss: -3.2907114028930664
Batch 14/64 loss: -3.3642044067382812
Batch 15/64 loss: -3.2946348190307617
Batch 16/64 loss: -3.402440071105957
Batch 17/64 loss: -3.3570556640625
Batch 18/64 loss: -3.540109634399414
Batch 19/64 loss: -3.3737106323242188
Batch 20/64 loss: -3.1219472885131836
Batch 21/64 loss: -2.8980274200439453
Batch 22/64 loss: -3.266399383544922
Batch 23/64 loss: -3.177157402038574
Batch 24/64 loss: -3.6222620010375977
Batch 25/64 loss: -3.218778610229492
Batch 26/64 loss: -2.8526878356933594
Batch 27/64 loss: -3.351715087890625
Batch 28/64 loss: -3.3409881591796875
Batch 29/64 loss: -3.1290502548217773
Batch 30/64 loss: -3.323887825012207
Batch 31/64 loss: -3.3724746704101562
Batch 32/64 loss: -3.600743293762207
Batch 33/64 loss: -3.5193004608154297
Batch 34/64 loss: -3.2155303955078125
Batch 35/64 loss: -3.278538703918457
Batch 36/64 loss: -3.4347763061523438
Batch 37/64 loss: -3.198126792907715
Batch 38/64 loss: -3.2601194381713867
Batch 39/64 loss: -3.2843713760375977
Batch 40/64 loss: -3.434041976928711
Batch 41/64 loss: -3.4121265411376953
Batch 42/64 loss: -2.5866498947143555
Batch 43/64 loss: -2.855672836303711
Batch 44/64 loss: -3.163210868835449
Batch 45/64 loss: -3.385171890258789
Batch 46/64 loss: -2.8180103302001953
Batch 47/64 loss: -3.3749818801879883
Batch 48/64 loss: -3.1647729873657227
Batch 49/64 loss: -3.207477569580078
Batch 50/64 loss: -3.468897819519043
Batch 51/64 loss: -3.2729721069335938
Batch 52/64 loss: -3.4037046432495117
Batch 53/64 loss: -3.340059280395508
Batch 54/64 loss: -3.284008026123047
Batch 55/64 loss: -3.243213653564453
Batch 56/64 loss: -3.4702301025390625
Batch 57/64 loss: -3.5227527618408203
Batch 58/64 loss: -3.4354143142700195
Batch 59/64 loss: -3.260641098022461
Batch 60/64 loss: -3.09578800201416
Batch 61/64 loss: -3.483186721801758
Batch 62/64 loss: -3.034961700439453
Batch 63/64 loss: -3.2144899368286133
Batch 64/64 loss: -8.005741119384766
Epoch 181  Train loss: -3.345514506919711  Val loss: -3.6434112103124665
Saving best model, epoch: 181
Epoch 182
-------------------------------
Batch 1/64 loss: -3.267091751098633
Batch 2/64 loss: -3.117568016052246
Batch 3/64 loss: -3.420620918273926
Batch 4/64 loss: -3.398723602294922
Batch 5/64 loss: -3.5596799850463867
Batch 6/64 loss: -3.300675392150879
Batch 7/64 loss: -3.453251838684082
Batch 8/64 loss: -3.5697479248046875
Batch 9/64 loss: -3.232473373413086
Batch 10/64 loss: -3.2841453552246094
Batch 11/64 loss: -3.244259834289551
Batch 12/64 loss: -3.0621490478515625
Batch 13/64 loss: -3.3144350051879883
Batch 14/64 loss: -3.4194021224975586
Batch 15/64 loss: -3.3338747024536133
Batch 16/64 loss: -3.4320335388183594
Batch 17/64 loss: -3.439671516418457
Batch 18/64 loss: -3.0831680297851562
Batch 19/64 loss: -3.5161876678466797
Batch 20/64 loss: -3.188126564025879
Batch 21/64 loss: -3.354252815246582
Batch 22/64 loss: -3.416855812072754
Batch 23/64 loss: -3.5241622924804688
Batch 24/64 loss: -2.8719701766967773
Batch 25/64 loss: -2.663724899291992
Batch 26/64 loss: -3.401839256286621
Batch 27/64 loss: -3.189657211303711
Batch 28/64 loss: -2.7711238861083984
Batch 29/64 loss: -3.4793577194213867
Batch 30/64 loss: -3.3140077590942383
Batch 31/64 loss: -3.2639474868774414
Batch 32/64 loss: -3.4800214767456055
Batch 33/64 loss: -3.3009414672851562
Batch 34/64 loss: -3.2329931259155273
Batch 35/64 loss: -3.3669605255126953
Batch 36/64 loss: -3.2146759033203125
Batch 37/64 loss: -3.1842079162597656
Batch 38/64 loss: -3.3276920318603516
Batch 39/64 loss: -3.4161148071289062
Batch 40/64 loss: -3.241281509399414
Batch 41/64 loss: -3.432680130004883
Batch 42/64 loss: -3.2356204986572266
Batch 43/64 loss: -3.3135995864868164
Batch 44/64 loss: -3.4942712783813477
Batch 45/64 loss: -2.877617835998535
Batch 46/64 loss: -3.2226076126098633
Batch 47/64 loss: -3.058137893676758
Batch 48/64 loss: -3.3719377517700195
Batch 49/64 loss: -2.6388845443725586
Batch 50/64 loss: -3.324093818664551
Batch 51/64 loss: -3.229933738708496
Batch 52/64 loss: -2.7872657775878906
Batch 53/64 loss: -2.959440231323242
Batch 54/64 loss: -3.3599605560302734
Batch 55/64 loss: -3.289137840270996
Batch 56/64 loss: -3.1904964447021484
Batch 57/64 loss: -3.2963428497314453
Batch 58/64 loss: -3.008760452270508
Batch 59/64 loss: -2.7421627044677734
Batch 60/64 loss: -3.1330718994140625
Batch 61/64 loss: -3.2615585327148438
Batch 62/64 loss: -3.5089426040649414
Batch 63/64 loss: -3.2967567443847656
Batch 64/64 loss: -7.853686809539795
Epoch 182  Train loss: -3.3031626776152967  Val loss: -3.589394441584951
Epoch 183
-------------------------------
Batch 1/64 loss: -3.209524154663086
Batch 2/64 loss: -3.515833854675293
Batch 3/64 loss: -3.21328067779541
Batch 4/64 loss: -3.1741933822631836
Batch 5/64 loss: -3.1886825561523438
Batch 6/64 loss: -3.274886131286621
Batch 7/64 loss: -3.241567611694336
Batch 8/64 loss: -3.085803985595703
Batch 9/64 loss: -3.284088134765625
Batch 10/64 loss: -3.3741025924682617
Batch 11/64 loss: -3.4875431060791016
Batch 12/64 loss: -3.131495475769043
Batch 13/64 loss: -3.1273746490478516
Batch 14/64 loss: -2.7742137908935547
Batch 15/64 loss: -3.15883731842041
Batch 16/64 loss: -3.149989128112793
Batch 17/64 loss: -3.260875701904297
Batch 18/64 loss: -3.192384719848633
Batch 19/64 loss: -3.0663156509399414
Batch 20/64 loss: -3.645082473754883
Batch 21/64 loss: -3.3054189682006836
Batch 22/64 loss: -3.472825050354004
Batch 23/64 loss: -3.441216468811035
Batch 24/64 loss: -3.412576675415039
Batch 25/64 loss: -2.9012451171875
Batch 26/64 loss: -3.4255924224853516
Batch 27/64 loss: -2.997882843017578
Batch 28/64 loss: -2.8478431701660156
Batch 29/64 loss: -2.514824867248535
Batch 30/64 loss: -2.9473657608032227
Batch 31/64 loss: -3.3902587890625
Batch 32/64 loss: -3.438563346862793
Batch 33/64 loss: -3.244892120361328
Batch 34/64 loss: -3.215184211730957
Batch 35/64 loss: -3.002788543701172
Batch 36/64 loss: -2.950458526611328
Batch 37/64 loss: -3.3423423767089844
Batch 38/64 loss: -3.467784881591797
Batch 39/64 loss: -3.1895103454589844
Batch 40/64 loss: -3.0482215881347656
Batch 41/64 loss: -3.4343061447143555
Batch 42/64 loss: -2.097463607788086
Batch 43/64 loss: -3.4177932739257812
Batch 44/64 loss: -3.4030017852783203
Batch 45/64 loss: -3.338289260864258
Batch 46/64 loss: -3.5124216079711914
Batch 47/64 loss: -3.214761734008789
Batch 48/64 loss: -3.349109649658203
Batch 49/64 loss: -3.1157283782958984
Batch 50/64 loss: -3.138944625854492
Batch 51/64 loss: -2.9988927841186523
Batch 52/64 loss: -3.2527246475219727
Batch 53/64 loss: -3.492368698120117
Batch 54/64 loss: -3.356858253479004
Batch 55/64 loss: -3.020427703857422
Batch 56/64 loss: -3.417666435241699
Batch 57/64 loss: -3.4531383514404297
Batch 58/64 loss: -3.415848731994629
Batch 59/64 loss: -3.0097522735595703
Batch 60/64 loss: -3.254606246948242
Batch 61/64 loss: -3.170726776123047
Batch 62/64 loss: -3.344010353088379
Batch 63/64 loss: -3.227105140686035
Batch 64/64 loss: -8.109990119934082
Epoch 183  Train loss: -3.2726480035220877  Val loss: -3.5148482306306716
Epoch 184
-------------------------------
Batch 1/64 loss: -3.1135940551757812
Batch 2/64 loss: -3.4402284622192383
Batch 3/64 loss: -3.074068069458008
Batch 4/64 loss: -3.4509143829345703
Batch 5/64 loss: -3.072906494140625
Batch 6/64 loss: -3.1543197631835938
Batch 7/64 loss: -3.1840896606445312
Batch 8/64 loss: -3.3345909118652344
Batch 9/64 loss: -3.196518898010254
Batch 10/64 loss: -3.2392845153808594
Batch 11/64 loss: -3.3392486572265625
Batch 12/64 loss: -3.2148609161376953
Batch 13/64 loss: -3.3189077377319336
Batch 14/64 loss: -3.171091079711914
Batch 15/64 loss: -3.343142509460449
Batch 16/64 loss: -3.212797164916992
Batch 17/64 loss: -2.684741973876953
Batch 18/64 loss: -3.3389110565185547
Batch 19/64 loss: -2.9977169036865234
Batch 20/64 loss: -3.01906681060791
Batch 21/64 loss: -3.181431770324707
Batch 22/64 loss: -3.4562835693359375
Batch 23/64 loss: -3.4029054641723633
Batch 24/64 loss: -3.14540958404541
Batch 25/64 loss: -3.0779590606689453
Batch 26/64 loss: -3.184520721435547
Batch 27/64 loss: -3.0510969161987305
Batch 28/64 loss: -3.184170722961426
Batch 29/64 loss: -3.0646743774414062
Batch 30/64 loss: -3.2622604370117188
Batch 31/64 loss: -3.396162986755371
Batch 32/64 loss: -3.310342788696289
Batch 33/64 loss: -3.1156463623046875
Batch 34/64 loss: -3.385326385498047
Batch 35/64 loss: -3.5519776344299316
Batch 36/64 loss: -3.286025047302246
Batch 37/64 loss: -3.35726261138916
Batch 38/64 loss: -3.355602264404297
Batch 39/64 loss: -3.2709903717041016
Batch 40/64 loss: -3.080524444580078
Batch 41/64 loss: -2.8986196517944336
Batch 42/64 loss: -3.3813629150390625
Batch 43/64 loss: -2.9222002029418945
Batch 44/64 loss: -2.7834625244140625
Batch 45/64 loss: -3.2792892456054688
Batch 46/64 loss: -3.4495677947998047
Batch 47/64 loss: -3.2867050170898438
Batch 48/64 loss: -3.368032455444336
Batch 49/64 loss: -3.1888866424560547
Batch 50/64 loss: -3.0364980697631836
Batch 51/64 loss: -3.2743072509765625
Batch 52/64 loss: -3.106438636779785
Batch 53/64 loss: -3.317302703857422
Batch 54/64 loss: -3.245992660522461
Batch 55/64 loss: -3.4310989379882812
Batch 56/64 loss: -3.0980358123779297
Batch 57/64 loss: -2.9108924865722656
Batch 58/64 loss: -3.274974822998047
Batch 59/64 loss: -3.1551055908203125
Batch 60/64 loss: -3.050103187561035
Batch 61/64 loss: -3.331669807434082
Batch 62/64 loss: -3.4587316513061523
Batch 63/64 loss: -3.0975160598754883
Batch 64/64 loss: -7.973458290100098
Epoch 184  Train loss: -3.268211159051633  Val loss: -3.5885458353049158
Epoch 185
-------------------------------
Batch 1/64 loss: -3.3759765625
Batch 2/64 loss: -3.352977752685547
Batch 3/64 loss: -3.2514467239379883
Batch 4/64 loss: -3.2344913482666016
Batch 5/64 loss: -3.212169647216797
Batch 6/64 loss: -3.332148551940918
Batch 7/64 loss: -3.1868667602539062
Batch 8/64 loss: -2.909602165222168
Batch 9/64 loss: -3.1778221130371094
Batch 10/64 loss: -3.1876935958862305
Batch 11/64 loss: -3.5828609466552734
Batch 12/64 loss: -3.0498485565185547
Batch 13/64 loss: -3.138669013977051
Batch 14/64 loss: -3.344858169555664
Batch 15/64 loss: -3.1767959594726562
Batch 16/64 loss: -2.9475278854370117
Batch 17/64 loss: -3.0084638595581055
Batch 18/64 loss: -3.202672004699707
Batch 19/64 loss: -2.984236717224121
Batch 20/64 loss: -2.937159538269043
Batch 21/64 loss: -3.171274185180664
Batch 22/64 loss: -2.6865882873535156
Batch 23/64 loss: -3.041874885559082
Batch 24/64 loss: -3.265315055847168
Batch 25/64 loss: -3.501453399658203
Batch 26/64 loss: -3.2449913024902344
Batch 27/64 loss: -2.8710689544677734
Batch 28/64 loss: -3.266566276550293
Batch 29/64 loss: -3.284102439880371
Batch 30/64 loss: -3.2161903381347656
Batch 31/64 loss: -3.102445602416992
Batch 32/64 loss: -3.1805877685546875
Batch 33/64 loss: -2.7323122024536133
Batch 34/64 loss: -3.3260860443115234
Batch 35/64 loss: -3.319643974304199
Batch 36/64 loss: -3.390787124633789
Batch 37/64 loss: -3.0846099853515625
Batch 38/64 loss: -2.88525390625
Batch 39/64 loss: -3.1343231201171875
Batch 40/64 loss: -3.298053741455078
Batch 41/64 loss: -3.1128997802734375
Batch 42/64 loss: -3.3684377670288086
Batch 43/64 loss: -3.436586380004883
Batch 44/64 loss: -3.4531946182250977
Batch 45/64 loss: -2.8595237731933594
Batch 46/64 loss: -2.9251346588134766
Batch 47/64 loss: -3.2217159271240234
Batch 48/64 loss: -3.1175880432128906
Batch 49/64 loss: -3.2941436767578125
Batch 50/64 loss: -3.195908546447754
Batch 51/64 loss: -3.435393810272217
Batch 52/64 loss: -3.3881187438964844
Batch 53/64 loss: -3.4564971923828125
Batch 54/64 loss: -3.165067672729492
Batch 55/64 loss: -3.116403579711914
Batch 56/64 loss: -3.3588314056396484
Batch 57/64 loss: -3.4127893447875977
Batch 58/64 loss: -2.858335494995117
Batch 59/64 loss: -3.22418212890625
Batch 60/64 loss: -3.2289905548095703
Batch 61/64 loss: -2.8469161987304688
Batch 62/64 loss: -3.297457695007324
Batch 63/64 loss: -3.342221260070801
Batch 64/64 loss: -7.930726051330566
Epoch 185  Train loss: -3.241759988373401  Val loss: -3.3275004776892385
Epoch 186
-------------------------------
Batch 1/64 loss: -3.177335739135742
Batch 2/64 loss: -3.4096908569335938
Batch 3/64 loss: -3.5013809204101562
Batch 4/64 loss: -3.3303604125976562
Batch 5/64 loss: -3.3137073516845703
Batch 6/64 loss: -2.675729751586914
Batch 7/64 loss: -3.452524185180664
Batch 8/64 loss: -2.8424816131591797
Batch 9/64 loss: -3.324965476989746
Batch 10/64 loss: -3.418267250061035
Batch 11/64 loss: -3.073775291442871
Batch 12/64 loss: -2.7611656188964844
Batch 13/64 loss: -3.1646175384521484
Batch 14/64 loss: -3.3386077880859375
Batch 15/64 loss: -3.3983983993530273
Batch 16/64 loss: -3.3725881576538086
Batch 17/64 loss: -3.07553768157959
Batch 18/64 loss: -3.1389589309692383
Batch 19/64 loss: -3.103102684020996
Batch 20/64 loss: -3.5535736083984375
Batch 21/64 loss: -3.0454444885253906
Batch 22/64 loss: -3.4395055770874023
Batch 23/64 loss: -3.144894599914551
Batch 24/64 loss: -3.606538772583008
Batch 25/64 loss: -3.132923126220703
Batch 26/64 loss: -3.3407058715820312
Batch 27/64 loss: -3.2378463745117188
Batch 28/64 loss: -3.2543296813964844
Batch 29/64 loss: -3.0013656616210938
Batch 30/64 loss: -3.27773380279541
Batch 31/64 loss: -3.4222402572631836
Batch 32/64 loss: -3.64406681060791
Batch 33/64 loss: -3.4990291595458984
Batch 34/64 loss: -3.169489860534668
Batch 35/64 loss: -3.255478858947754
Batch 36/64 loss: -2.9171924591064453
Batch 37/64 loss: -3.1890869140625
Batch 38/64 loss: -3.2725610733032227
Batch 39/64 loss: -3.3186283111572266
Batch 40/64 loss: -3.0022201538085938
Batch 41/64 loss: -3.435274124145508
Batch 42/64 loss: -3.4696168899536133
Batch 43/64 loss: -3.3782081604003906
Batch 44/64 loss: -3.368122100830078
Batch 45/64 loss: -3.145608901977539
Batch 46/64 loss: -3.422588348388672
Batch 47/64 loss: -2.71420955657959
Batch 48/64 loss: -3.4606218338012695
Batch 49/64 loss: -3.1752023696899414
Batch 50/64 loss: -3.217665672302246
Batch 51/64 loss: -3.2362518310546875
Batch 52/64 loss: -3.09342098236084
Batch 53/64 loss: -3.4277305603027344
Batch 54/64 loss: -3.368124008178711
Batch 55/64 loss: -3.123263359069824
Batch 56/64 loss: -3.0805931091308594
Batch 57/64 loss: -3.3970108032226562
Batch 58/64 loss: -3.170351982116699
Batch 59/64 loss: -3.065699577331543
Batch 60/64 loss: -3.2105140686035156
Batch 61/64 loss: -3.3307676315307617
Batch 62/64 loss: -3.3793487548828125
Batch 63/64 loss: -3.2455625534057617
Batch 64/64 loss: -7.867169380187988
Epoch 186  Train loss: -3.3006146711461684  Val loss: -3.4771256332135283
Epoch 187
-------------------------------
Batch 1/64 loss: -3.3121681213378906
Batch 2/64 loss: -3.369922637939453
Batch 3/64 loss: -2.4857425689697266
Batch 4/64 loss: -3.460818290710449
Batch 5/64 loss: -3.0763540267944336
Batch 6/64 loss: -3.1949281692504883
Batch 7/64 loss: -3.245551109313965
Batch 8/64 loss: -3.4484024047851562
Batch 9/64 loss: -3.423501968383789
Batch 10/64 loss: -3.5180110931396484
Batch 11/64 loss: -3.2436704635620117
Batch 12/64 loss: -3.3043174743652344
Batch 13/64 loss: -3.1114625930786133
Batch 14/64 loss: -3.466435432434082
Batch 15/64 loss: -3.5636892318725586
Batch 16/64 loss: -3.5288591384887695
Batch 17/64 loss: -3.215357780456543
Batch 18/64 loss: -3.263607978820801
Batch 19/64 loss: -3.381096839904785
Batch 20/64 loss: -3.2402915954589844
Batch 21/64 loss: -3.049893379211426
Batch 22/64 loss: -3.0641069412231445
Batch 23/64 loss: -3.2592525482177734
Batch 24/64 loss: -3.2531356811523438
Batch 25/64 loss: -3.031064987182617
Batch 26/64 loss: -3.426290512084961
Batch 27/64 loss: -3.415347099304199
Batch 28/64 loss: -3.550577163696289
Batch 29/64 loss: -3.6429991722106934
Batch 30/64 loss: -3.402463912963867
Batch 31/64 loss: -3.4558191299438477
Batch 32/64 loss: -3.10660457611084
Batch 33/64 loss: -3.396529197692871
Batch 34/64 loss: -3.161853790283203
Batch 35/64 loss: -3.352717399597168
Batch 36/64 loss: -3.520732879638672
Batch 37/64 loss: -3.289546012878418
Batch 38/64 loss: -2.9346694946289062
Batch 39/64 loss: -3.412289619445801
Batch 40/64 loss: -3.1350746154785156
Batch 41/64 loss: -3.2833433151245117
Batch 42/64 loss: -3.56817626953125
Batch 43/64 loss: -3.4140625
Batch 44/64 loss: -3.095444679260254
Batch 45/64 loss: -3.2640533447265625
Batch 46/64 loss: -3.323287010192871
Batch 47/64 loss: -3.5394859313964844
Batch 48/64 loss: -3.424679756164551
Batch 49/64 loss: -3.3730554580688477
Batch 50/64 loss: -3.224355697631836
Batch 51/64 loss: -3.2312726974487305
Batch 52/64 loss: -3.3969459533691406
Batch 53/64 loss: -3.2414093017578125
Batch 54/64 loss: -3.345752716064453
Batch 55/64 loss: -3.234220504760742
Batch 56/64 loss: -3.3863067626953125
Batch 57/64 loss: -3.0670156478881836
Batch 58/64 loss: -3.2229719161987305
Batch 59/64 loss: -3.2797908782958984
Batch 60/64 loss: -3.48968505859375
Batch 61/64 loss: -2.9060497283935547
Batch 62/64 loss: -3.348421096801758
Batch 63/64 loss: -3.1843252182006836
Batch 64/64 loss: -7.712471961975098
Epoch 187  Train loss: -3.3465666266048655  Val loss: -3.03481931129272
Epoch 188
-------------------------------
Batch 1/64 loss: -2.9659957885742188
Batch 2/64 loss: -3.26444149017334
Batch 3/64 loss: -3.4312591552734375
Batch 4/64 loss: -2.728860855102539
Batch 5/64 loss: -3.3092384338378906
Batch 6/64 loss: -3.3041162490844727
Batch 7/64 loss: -3.4077110290527344
Batch 8/64 loss: -3.4185876846313477
Batch 9/64 loss: -3.1806983947753906
Batch 10/64 loss: -2.830169677734375
Batch 11/64 loss: -3.5156450271606445
Batch 12/64 loss: -3.227212905883789
Batch 13/64 loss: -3.368133544921875
Batch 14/64 loss: -3.118350028991699
Batch 15/64 loss: -2.605038642883301
Batch 16/64 loss: -3.3533010482788086
Batch 17/64 loss: -3.4201717376708984
Batch 18/64 loss: -3.3331117630004883
Batch 19/64 loss: -3.484494209289551
Batch 20/64 loss: -2.8190536499023438
Batch 21/64 loss: -3.260207176208496
Batch 22/64 loss: -2.8252182006835938
Batch 23/64 loss: -3.264767646789551
Batch 24/64 loss: -3.5922842025756836
Batch 25/64 loss: -2.9422645568847656
Batch 26/64 loss: -3.260930061340332
Batch 27/64 loss: -3.547729969024658
Batch 28/64 loss: -3.246185302734375
Batch 29/64 loss: -3.422419548034668
Batch 30/64 loss: -3.1693830490112305
Batch 31/64 loss: -3.1335926055908203
Batch 32/64 loss: -2.890432357788086
Batch 33/64 loss: -3.369593620300293
Batch 34/64 loss: -3.024622917175293
Batch 35/64 loss: -2.9805173873901367
Batch 36/64 loss: -3.3614397048950195
Batch 37/64 loss: -3.3185853958129883
Batch 38/64 loss: -2.891864776611328
Batch 39/64 loss: -3.399123191833496
Batch 40/64 loss: -3.444790840148926
Batch 41/64 loss: -3.355278968811035
Batch 42/64 loss: -3.15041446685791
Batch 43/64 loss: -3.524784564971924
Batch 44/64 loss: -3.2706298828125
Batch 45/64 loss: -3.3385467529296875
Batch 46/64 loss: -3.261425018310547
Batch 47/64 loss: -3.001614570617676
Batch 48/64 loss: -2.926030158996582
Batch 49/64 loss: -3.428492546081543
Batch 50/64 loss: -3.0703659057617188
Batch 51/64 loss: -3.13362979888916
Batch 52/64 loss: -3.1232833862304688
Batch 53/64 loss: -2.8877668380737305
Batch 54/64 loss: -3.250049591064453
Batch 55/64 loss: -3.1254119873046875
Batch 56/64 loss: -3.3627214431762695
Batch 57/64 loss: -3.1690540313720703
Batch 58/64 loss: -3.198575019836426
Batch 59/64 loss: -3.0320281982421875
Batch 60/64 loss: -2.7409276962280273
Batch 61/64 loss: -3.2415103912353516
Batch 62/64 loss: -3.253169059753418
Batch 63/64 loss: -3.561039924621582
Batch 64/64 loss: -7.6402082443237305
Epoch 188  Train loss: -3.255975689607508  Val loss: -3.5867723550173833
Epoch 189
-------------------------------
Batch 1/64 loss: -3.0682716369628906
Batch 2/64 loss: -3.255735397338867
Batch 3/64 loss: -3.0888404846191406
Batch 4/64 loss: -2.66298770904541
Batch 5/64 loss: -3.141669273376465
Batch 6/64 loss: -3.3120908737182617
Batch 7/64 loss: -3.43135929107666
Batch 8/64 loss: -3.3496179580688477
Batch 9/64 loss: -3.2899274826049805
Batch 10/64 loss: -3.248387336730957
Batch 11/64 loss: -3.361757278442383
Batch 12/64 loss: -3.0674142837524414
Batch 13/64 loss: -3.2723045349121094
Batch 14/64 loss: -3.267780303955078
Batch 15/64 loss: -3.155233383178711
Batch 16/64 loss: -3.454404830932617
Batch 17/64 loss: -3.381511688232422
Batch 18/64 loss: -3.2756576538085938
Batch 19/64 loss: -3.487438201904297
Batch 20/64 loss: -3.320340156555176
Batch 21/64 loss: -3.067990303039551
Batch 22/64 loss: -2.9997806549072266
Batch 23/64 loss: -2.885883331298828
Batch 24/64 loss: -3.168694496154785
Batch 25/64 loss: -3.2263498306274414
Batch 26/64 loss: -2.831655502319336
Batch 27/64 loss: -3.2791690826416016
Batch 28/64 loss: -3.422539710998535
Batch 29/64 loss: -3.4956436157226562
Batch 30/64 loss: -3.4204883575439453
Batch 31/64 loss: -3.440275192260742
Batch 32/64 loss: -3.406536102294922
Batch 33/64 loss: -3.294811248779297
Batch 34/64 loss: -3.503218650817871
Batch 35/64 loss: -3.2942018508911133
Batch 36/64 loss: -3.3748960494995117
Batch 37/64 loss: -2.897242546081543
Batch 38/64 loss: -2.60943603515625
Batch 39/64 loss: -3.6093735694885254
Batch 40/64 loss: -3.276106834411621
Batch 41/64 loss: -3.401823043823242
Batch 42/64 loss: -3.3677778244018555
Batch 43/64 loss: -2.836085319519043
Batch 44/64 loss: -3.0185470581054688
Batch 45/64 loss: -2.984957695007324
Batch 46/64 loss: -3.2219791412353516
Batch 47/64 loss: -3.0334014892578125
Batch 48/64 loss: -3.276315689086914
Batch 49/64 loss: -2.9839906692504883
Batch 50/64 loss: -3.014431953430176
Batch 51/64 loss: -3.4053564071655273
Batch 52/64 loss: -3.117732048034668
Batch 53/64 loss: -3.4453582763671875
Batch 54/64 loss: -3.451359748840332
Batch 55/64 loss: -3.38413143157959
Batch 56/64 loss: -3.2373361587524414
Batch 57/64 loss: -3.126530647277832
Batch 58/64 loss: -3.37369441986084
Batch 59/64 loss: -3.2488489151000977
Batch 60/64 loss: -2.8759288787841797
Batch 61/64 loss: -3.024374008178711
Batch 62/64 loss: -3.1326169967651367
Batch 63/64 loss: -3.2888431549072266
Batch 64/64 loss: -8.048571586608887
Epoch 189  Train loss: -3.2734881943347407  Val loss: -3.5023619661626126
Epoch 190
-------------------------------
Batch 1/64 loss: -3.5114688873291016
Batch 2/64 loss: -3.1575002670288086
Batch 3/64 loss: -3.0284318923950195
Batch 4/64 loss: -2.2012996673583984
Batch 5/64 loss: -2.9216556549072266
Batch 6/64 loss: -2.612699508666992
Batch 7/64 loss: -3.51261043548584
Batch 8/64 loss: -3.1578826904296875
Batch 9/64 loss: -3.47219181060791
Batch 10/64 loss: -3.551258087158203
Batch 11/64 loss: -3.4734268188476562
Batch 12/64 loss: -2.925238609313965
Batch 13/64 loss: -3.215656280517578
Batch 14/64 loss: -2.895040512084961
Batch 15/64 loss: -3.2461891174316406
Batch 16/64 loss: -3.4085607528686523
Batch 17/64 loss: -3.143731117248535
Batch 18/64 loss: -3.340208053588867
Batch 19/64 loss: -3.2010269165039062
Batch 20/64 loss: -3.265866279602051
Batch 21/64 loss: -3.306485176086426
Batch 22/64 loss: -3.0507097244262695
Batch 23/64 loss: -2.830796241760254
Batch 24/64 loss: -3.4204750061035156
Batch 25/64 loss: -3.39461612701416
Batch 26/64 loss: -3.4116039276123047
Batch 27/64 loss: -3.4038734436035156
Batch 28/64 loss: -3.5011940002441406
Batch 29/64 loss: -3.2092418670654297
Batch 30/64 loss: -2.978194236755371
Batch 31/64 loss: -3.420289993286133
Batch 32/64 loss: -3.521376609802246
Batch 33/64 loss: -2.868912696838379
Batch 34/64 loss: -3.221707344055176
Batch 35/64 loss: -3.322922706604004
Batch 36/64 loss: -2.837308883666992
Batch 37/64 loss: -2.9098377227783203
Batch 38/64 loss: -3.099545478820801
Batch 39/64 loss: -3.4056053161621094
Batch 40/64 loss: -3.1056880950927734
Batch 41/64 loss: -3.3408689498901367
Batch 42/64 loss: -2.986170768737793
Batch 43/64 loss: -3.1898345947265625
Batch 44/64 loss: -3.4307737350463867
Batch 45/64 loss: -3.1762142181396484
Batch 46/64 loss: -3.164083480834961
Batch 47/64 loss: -3.3356456756591797
Batch 48/64 loss: -3.260089874267578
Batch 49/64 loss: -3.1254987716674805
Batch 50/64 loss: -3.5910263061523438
Batch 51/64 loss: -3.1163902282714844
Batch 52/64 loss: -3.44936466217041
Batch 53/64 loss: -3.482799530029297
Batch 54/64 loss: -3.3277664184570312
Batch 55/64 loss: -3.400308609008789
Batch 56/64 loss: -3.1740007400512695
Batch 57/64 loss: -3.27193546295166
Batch 58/64 loss: -3.0343093872070312
Batch 59/64 loss: -3.550185203552246
Batch 60/64 loss: -3.331557273864746
Batch 61/64 loss: -3.58443546295166
Batch 62/64 loss: -3.447096824645996
Batch 63/64 loss: -3.30527400970459
Batch 64/64 loss: -7.920948028564453
Epoch 190  Train loss: -3.2859399084951364  Val loss: -3.352889542727126
Epoch 191
-------------------------------
Batch 1/64 loss: -3.100412368774414
Batch 2/64 loss: -3.5226736068725586
Batch 3/64 loss: -3.425111770629883
Batch 4/64 loss: -3.3544492721557617
Batch 5/64 loss: -3.425569534301758
Batch 6/64 loss: -3.4732561111450195
Batch 7/64 loss: -3.59915828704834
Batch 8/64 loss: -3.5594377517700195
Batch 9/64 loss: -2.941375732421875
Batch 10/64 loss: -2.9728174209594727
Batch 11/64 loss: -3.513395309448242
Batch 12/64 loss: -3.397982597351074
Batch 13/64 loss: -3.1903810501098633
Batch 14/64 loss: -3.1916465759277344
Batch 15/64 loss: -3.2562007904052734
Batch 16/64 loss: -3.1095199584960938
Batch 17/64 loss: -2.8615283966064453
Batch 18/64 loss: -3.4586381912231445
Batch 19/64 loss: -3.1213579177856445
Batch 20/64 loss: -3.455698013305664
Batch 21/64 loss: -3.1805505752563477
Batch 22/64 loss: -3.246514320373535
Batch 23/64 loss: -3.226761817932129
Batch 24/64 loss: -2.9999256134033203
Batch 25/64 loss: -2.7537755966186523
Batch 26/64 loss: -3.449838638305664
Batch 27/64 loss: -3.2898988723754883
Batch 28/64 loss: -3.459430694580078
Batch 29/64 loss: -3.491189956665039
Batch 30/64 loss: -3.429922103881836
Batch 31/64 loss: -3.5203285217285156
Batch 32/64 loss: -3.1368093490600586
Batch 33/64 loss: -3.1058502197265625
Batch 34/64 loss: -3.5010995864868164
Batch 35/64 loss: -3.515854835510254
Batch 36/64 loss: -3.230365753173828
Batch 37/64 loss: -3.465733528137207
Batch 38/64 loss: -3.3605995178222656
Batch 39/64 loss: -3.5766477584838867
Batch 40/64 loss: -3.338129997253418
Batch 41/64 loss: -3.1616525650024414
Batch 42/64 loss: -3.4643144607543945
Batch 43/64 loss: -3.132267951965332
Batch 44/64 loss: -3.475187301635742
Batch 45/64 loss: -2.943282127380371
Batch 46/64 loss: -3.3556385040283203
Batch 47/64 loss: -3.260866165161133
Batch 48/64 loss: -2.7906322479248047
Batch 49/64 loss: -3.40598201751709
Batch 50/64 loss: -3.371830940246582
Batch 51/64 loss: -3.514871597290039
Batch 52/64 loss: -3.236696243286133
Batch 53/64 loss: -2.8671340942382812
Batch 54/64 loss: -3.4182844161987305
Batch 55/64 loss: -3.6191883087158203
Batch 56/64 loss: -3.300290107727051
Batch 57/64 loss: -3.253063201904297
Batch 58/64 loss: -3.257065773010254
Batch 59/64 loss: -2.9837493896484375
Batch 60/64 loss: -3.3313493728637695
Batch 61/64 loss: -3.279128074645996
Batch 62/64 loss: -3.0894718170166016
Batch 63/64 loss: -3.4078617095947266
Batch 64/64 loss: -8.04496955871582
Epoch 191  Train loss: -3.3437391916910806  Val loss: -3.68959602539482
Saving best model, epoch: 191
Epoch 192
-------------------------------
Batch 1/64 loss: -3.3048667907714844
Batch 2/64 loss: -3.380889892578125
Batch 3/64 loss: -3.4027652740478516
Batch 4/64 loss: -3.1697750091552734
Batch 5/64 loss: -3.2471208572387695
Batch 6/64 loss: -3.3623485565185547
Batch 7/64 loss: -3.4182090759277344
Batch 8/64 loss: -3.2574892044067383
Batch 9/64 loss: -3.40543270111084
Batch 10/64 loss: -3.274890899658203
Batch 11/64 loss: -3.0212936401367188
Batch 12/64 loss: -3.5186843872070312
Batch 13/64 loss: -3.502434730529785
Batch 14/64 loss: -2.747706413269043
Batch 15/64 loss: -3.566250801086426
Batch 16/64 loss: -3.2508296966552734
Batch 17/64 loss: -3.1522130966186523
Batch 18/64 loss: -3.518782615661621
Batch 19/64 loss: -3.4045448303222656
Batch 20/64 loss: -3.537318229675293
Batch 21/64 loss: -2.9583635330200195
Batch 22/64 loss: -3.3074140548706055
Batch 23/64 loss: -3.379911422729492
Batch 24/64 loss: -3.3448495864868164
Batch 25/64 loss: -2.981924057006836
Batch 26/64 loss: -3.50510311126709
Batch 27/64 loss: -3.6768999099731445
Batch 28/64 loss: -3.3645143508911133
Batch 29/64 loss: -3.325924873352051
Batch 30/64 loss: -3.152189254760742
Batch 31/64 loss: -3.3667964935302734
Batch 32/64 loss: -3.1479244232177734
Batch 33/64 loss: -3.308884620666504
Batch 34/64 loss: -3.45548152923584
Batch 35/64 loss: -3.5654497146606445
Batch 36/64 loss: -2.662252426147461
Batch 37/64 loss: -3.1343889236450195
Batch 38/64 loss: -3.436333656311035
Batch 39/64 loss: -3.3644466400146484
Batch 40/64 loss: -3.0049076080322266
Batch 41/64 loss: -3.315720558166504
Batch 42/64 loss: -3.4395370483398438
Batch 43/64 loss: -3.4136457443237305
Batch 44/64 loss: -3.419412612915039
Batch 45/64 loss: -3.1517601013183594
Batch 46/64 loss: -3.545290946960449
Batch 47/64 loss: -3.1733627319335938
Batch 48/64 loss: -3.50223445892334
Batch 49/64 loss: -3.603342056274414
Batch 50/64 loss: -3.4345006942749023
Batch 51/64 loss: -3.523980140686035
Batch 52/64 loss: -3.4698562622070312
Batch 53/64 loss: -3.208939552307129
Batch 54/64 loss: -3.18631649017334
Batch 55/64 loss: -3.279404640197754
Batch 56/64 loss: -3.247694969177246
Batch 57/64 loss: -3.316753387451172
Batch 58/64 loss: -3.337736129760742
Batch 59/64 loss: -3.4566049575805664
Batch 60/64 loss: -3.4015636444091797
Batch 61/64 loss: -3.3163061141967773
Batch 62/64 loss: -2.9983577728271484
Batch 63/64 loss: -2.818063735961914
Batch 64/64 loss: -7.970112323760986
Epoch 192  Train loss: -3.3635415825189328  Val loss: -3.0314392666636465
Epoch 193
-------------------------------
Batch 1/64 loss: -3.376124382019043
Batch 2/64 loss: -3.3876609802246094
Batch 3/64 loss: -3.2750606536865234
Batch 4/64 loss: -3.1930723190307617
Batch 5/64 loss: -2.8929176330566406
Batch 6/64 loss: -3.0700998306274414
Batch 7/64 loss: -2.470775604248047
Batch 8/64 loss: -3.1775455474853516
Batch 9/64 loss: -2.3273773193359375
Batch 10/64 loss: -3.0871829986572266
Batch 11/64 loss: -3.0556297302246094
Batch 12/64 loss: -2.472867965698242
Batch 13/64 loss: -3.1730966567993164
Batch 14/64 loss: -2.885165214538574
Batch 15/64 loss: -2.360422134399414
Batch 16/64 loss: -1.741032600402832
Batch 17/64 loss: -2.9846487045288086
Batch 18/64 loss: -2.9331274032592773
Batch 19/64 loss: -2.9259891510009766
Batch 20/64 loss: -2.9389514923095703
Batch 21/64 loss: -2.468629837036133
Batch 22/64 loss: -2.6099424362182617
Batch 23/64 loss: -2.932318687438965
Batch 24/64 loss: -2.8132848739624023
Batch 25/64 loss: -2.4085769653320312
Batch 26/64 loss: -2.387197494506836
Batch 27/64 loss: -1.6894922256469727
Batch 28/64 loss: -3.163911819458008
Batch 29/64 loss: -2.916433334350586
Batch 30/64 loss: -2.256251335144043
Batch 31/64 loss: -2.8316736221313477
Batch 32/64 loss: -2.5719499588012695
Batch 33/64 loss: -3.0072126388549805
Batch 34/64 loss: -3.0151052474975586
Batch 35/64 loss: -0.9383335113525391
Batch 36/64 loss: -2.8868961334228516
Batch 37/64 loss: -3.0724716186523438
Batch 38/64 loss: -3.0990514755249023
Batch 39/64 loss: -2.5705556869506836
Batch 40/64 loss: -3.0810041427612305
Batch 41/64 loss: -3.1692914962768555
Batch 42/64 loss: -3.1536340713500977
Batch 43/64 loss: -2.942315101623535
Batch 44/64 loss: -2.9604501724243164
Batch 45/64 loss: -2.4677486419677734
Batch 46/64 loss: -3.266132354736328
Batch 47/64 loss: -2.594191551208496
Batch 48/64 loss: -2.9761085510253906
Batch 49/64 loss: -3.0466814041137695
Batch 50/64 loss: -3.0388622283935547
Batch 51/64 loss: -3.234811782836914
Batch 52/64 loss: -2.612786293029785
Batch 53/64 loss: -2.423654556274414
Batch 54/64 loss: -2.9051952362060547
Batch 55/64 loss: -2.358220100402832
Batch 56/64 loss: -2.871593475341797
Batch 57/64 loss: -2.7740039825439453
Batch 58/64 loss: -2.9778566360473633
Batch 59/64 loss: -2.9752159118652344
Batch 60/64 loss: -3.2713022232055664
Batch 61/64 loss: -3.2125015258789062
Batch 62/64 loss: -2.33829402923584
Batch 63/64 loss: -2.9534597396850586
Batch 64/64 loss: -7.544192790985107
Epoch 193  Train loss: -2.8648077964782717  Val loss: -3.139745797488288
Epoch 194
-------------------------------
Batch 1/64 loss: -3.21490478515625
Batch 2/64 loss: -2.9915342330932617
Batch 3/64 loss: -2.338850975036621
Batch 4/64 loss: -2.5342655181884766
Batch 5/64 loss: -2.244645118713379
Batch 6/64 loss: -3.119396209716797
Batch 7/64 loss: -3.1553421020507812
Batch 8/64 loss: -3.050518035888672
Batch 9/64 loss: -2.9510498046875
Batch 10/64 loss: -2.206223487854004
Batch 11/64 loss: -2.793519973754883
Batch 12/64 loss: -2.804781913757324
Batch 13/64 loss: -3.015622138977051
Batch 14/64 loss: -3.3332080841064453
Batch 15/64 loss: -3.3079261779785156
Batch 16/64 loss: -2.3486289978027344
Batch 17/64 loss: -3.218276023864746
Batch 18/64 loss: -3.14266300201416
Batch 19/64 loss: -3.1659278869628906
Batch 20/64 loss: -2.5969762802124023
Batch 21/64 loss: -2.7538089752197266
Batch 22/64 loss: -3.050869941711426
Batch 23/64 loss: -3.038015365600586
Batch 24/64 loss: -3.1332435607910156
Batch 25/64 loss: -3.0264997482299805
Batch 26/64 loss: -2.8343677520751953
Batch 27/64 loss: -2.914303779602051
Batch 28/64 loss: -2.839095115661621
Batch 29/64 loss: -2.7334680557250977
Batch 30/64 loss: -2.4670181274414062
Batch 31/64 loss: -2.9720096588134766
Batch 32/64 loss: -3.1896772384643555
Batch 33/64 loss: -1.745469093322754
Batch 34/64 loss: -3.154787063598633
Batch 35/64 loss: -2.983292579650879
Batch 36/64 loss: -2.8171396255493164
Batch 37/64 loss: -2.6542978286743164
Batch 38/64 loss: -2.999082565307617
Batch 39/64 loss: -3.0264930725097656
Batch 40/64 loss: -3.232508659362793
Batch 41/64 loss: -3.0853214263916016
Batch 42/64 loss: -3.077442169189453
Batch 43/64 loss: -2.9071531295776367
Batch 44/64 loss: -2.8954544067382812
Batch 45/64 loss: -2.80643367767334
Batch 46/64 loss: -2.817479133605957
Batch 47/64 loss: -3.020575523376465
Batch 48/64 loss: -3.125844955444336
Batch 49/64 loss: -2.838743209838867
Batch 50/64 loss: -3.1016759872436523
Batch 51/64 loss: -2.8579092025756836
Batch 52/64 loss: -3.1090621948242188
Batch 53/64 loss: -3.018160820007324
Batch 54/64 loss: -3.0810117721557617
Batch 55/64 loss: -1.741084098815918
Batch 56/64 loss: -2.826824188232422
Batch 57/64 loss: -3.21337890625
Batch 58/64 loss: -3.3075733184814453
Batch 59/64 loss: -2.4435272216796875
Batch 60/64 loss: -3.0388708114624023
Batch 61/64 loss: -2.219862937927246
Batch 62/64 loss: -2.7810192108154297
Batch 63/64 loss: -2.9455718994140625
Batch 64/64 loss: -7.636938571929932
Epoch 194  Train loss: -2.9347041990242753  Val loss: -3.1319509158839067
Epoch 195
-------------------------------
Batch 1/64 loss: -2.8182830810546875
Batch 2/64 loss: -2.9632959365844727
Batch 3/64 loss: -3.2100276947021484
Batch 4/64 loss: -1.577042579650879
Batch 5/64 loss: -3.063727378845215
Batch 6/64 loss: -3.0927181243896484
Batch 7/64 loss: -3.1130247116088867
Batch 8/64 loss: -3.038355827331543
Batch 9/64 loss: -3.034219741821289
Batch 10/64 loss: -3.1917104721069336
Batch 11/64 loss: -2.9717273712158203
Batch 12/64 loss: -2.8249311447143555
Batch 13/64 loss: -3.1918020248413086
Batch 14/64 loss: -2.8124008178710938
Batch 15/64 loss: -3.309112548828125
Batch 16/64 loss: -3.140072822570801
Batch 17/64 loss: -3.1124181747436523
Batch 18/64 loss: -2.9788427352905273
Batch 19/64 loss: -3.0739574432373047
Batch 20/64 loss: -3.037449836730957
Batch 21/64 loss: -2.769740104675293
Batch 22/64 loss: -3.107701301574707
Batch 23/64 loss: -3.1073102951049805
Batch 24/64 loss: -3.185586929321289
Batch 25/64 loss: -3.2316131591796875
Batch 26/64 loss: -2.3064184188842773
Batch 27/64 loss: -3.37308406829834
Batch 28/64 loss: -1.7008848190307617
Batch 29/64 loss: -3.301919937133789
Batch 30/64 loss: -2.9607534408569336
Batch 31/64 loss: -3.291764259338379
Batch 32/64 loss: -3.15948486328125
Batch 33/64 loss: -3.19891357421875
Batch 34/64 loss: -3.228750228881836
Batch 35/64 loss: -2.917595863342285
Batch 36/64 loss: -3.2422256469726562
Batch 37/64 loss: -2.2808027267456055
Batch 38/64 loss: -3.2189245223999023
Batch 39/64 loss: -3.2020606994628906
Batch 40/64 loss: -3.0162954330444336
Batch 41/64 loss: -2.6228246688842773
Batch 42/64 loss: -2.8632402420043945
Batch 43/64 loss: -3.1881933212280273
Batch 44/64 loss: -3.276866912841797
Batch 45/64 loss: -2.365896224975586
Batch 46/64 loss: -2.9213781356811523
Batch 47/64 loss: -2.9014902114868164
Batch 48/64 loss: -2.9280738830566406
Batch 49/64 loss: -3.25244140625
Batch 50/64 loss: -2.8193912506103516
Batch 51/64 loss: -3.3119001388549805
Batch 52/64 loss: -3.474982261657715
Batch 53/64 loss: -3.0080337524414062
Batch 54/64 loss: -3.0685501098632812
Batch 55/64 loss: -3.28173828125
Batch 56/64 loss: -3.187535285949707
Batch 57/64 loss: -3.2612714767456055
Batch 58/64 loss: -3.01479434967041
Batch 59/64 loss: -2.8760948181152344
Batch 60/64 loss: -2.5842151641845703
Batch 61/64 loss: -3.2309980392456055
Batch 62/64 loss: -2.6551332473754883
Batch 63/64 loss: -3.266551971435547
Batch 64/64 loss: -7.961947917938232
Epoch 195  Train loss: -3.0539608917984307  Val loss: -3.3303342734005854
Epoch 196
-------------------------------
Batch 1/64 loss: -2.5087852478027344
Batch 2/64 loss: -3.1942195892333984
Batch 3/64 loss: -3.234677314758301
Batch 4/64 loss: -2.7947235107421875
Batch 5/64 loss: -3.2717666625976562
Batch 6/64 loss: -3.2062816619873047
Batch 7/64 loss: -3.0982275009155273
Batch 8/64 loss: -3.070293426513672
Batch 9/64 loss: -2.331298828125
Batch 10/64 loss: -2.96012020111084
Batch 11/64 loss: -2.9641504287719727
Batch 12/64 loss: -2.8349409103393555
Batch 13/64 loss: -3.2136802673339844
Batch 14/64 loss: -3.474703788757324
Batch 15/64 loss: -3.2888593673706055
Batch 16/64 loss: -2.7848405838012695
Batch 17/64 loss: -3.0902700424194336
Batch 18/64 loss: -3.067685127258301
Batch 19/64 loss: -3.043848991394043
Batch 20/64 loss: -3.300858497619629
Batch 21/64 loss: -3.0946273803710938
Batch 22/64 loss: -3.422452926635742
Batch 23/64 loss: -3.1579246520996094
Batch 24/64 loss: -3.3599748611450195
Batch 25/64 loss: -2.9765357971191406
Batch 26/64 loss: -3.1562089920043945
Batch 27/64 loss: -3.4291934967041016
Batch 28/64 loss: -2.764566421508789
Batch 29/64 loss: -3.1606454849243164
Batch 30/64 loss: -2.880046844482422
Batch 31/64 loss: -3.2537240982055664
Batch 32/64 loss: -2.956602096557617
Batch 33/64 loss: -2.3207054138183594
Batch 34/64 loss: -3.139598846435547
Batch 35/64 loss: -2.855691909790039
Batch 36/64 loss: -3.0833921432495117
Batch 37/64 loss: -2.9730606079101562
Batch 38/64 loss: -2.8527345657348633
Batch 39/64 loss: -2.996211051940918
Batch 40/64 loss: -3.0653276443481445
Batch 41/64 loss: -3.0724172592163086
Batch 42/64 loss: -3.0839757919311523
Batch 43/64 loss: -3.0832643508911133
Batch 44/64 loss: -3.248476982116699
Batch 45/64 loss: -3.175246238708496
Batch 46/64 loss: -2.2461891174316406
Batch 47/64 loss: -2.214151382446289
Batch 48/64 loss: -3.2165307998657227
Batch 49/64 loss: -3.346158981323242
Batch 50/64 loss: -2.88729190826416
Batch 51/64 loss: -3.200704574584961
Batch 52/64 loss: -3.0028839111328125
Batch 53/64 loss: -3.054509162902832
Batch 54/64 loss: -3.0891151428222656
Batch 55/64 loss: -3.096630096435547
Batch 56/64 loss: -3.2065277099609375
Batch 57/64 loss: -3.118722915649414
Batch 58/64 loss: -2.903672218322754
Batch 59/64 loss: -2.437795639038086
Batch 60/64 loss: -3.4748353958129883
Batch 61/64 loss: -3.2250022888183594
Batch 62/64 loss: -2.766368865966797
Batch 63/64 loss: -3.292734146118164
Batch 64/64 loss: -7.584907531738281
Epoch 196  Train loss: -3.0865151798023898  Val loss: -3.375613392833172
Epoch 197
-------------------------------
Batch 1/64 loss: -3.0575714111328125
Batch 2/64 loss: -3.233621597290039
Batch 3/64 loss: -3.5187673568725586
Batch 4/64 loss: -2.6861515045166016
Batch 5/64 loss: -3.088250160217285
Batch 6/64 loss: -3.39951229095459
Batch 7/64 loss: -3.0555591583251953
Batch 8/64 loss: -3.364896774291992
Batch 9/64 loss: -3.291046142578125
Batch 10/64 loss: -2.696080207824707
Batch 11/64 loss: -3.040018081665039
Batch 12/64 loss: -2.130748748779297
Batch 13/64 loss: -2.9886980056762695
Batch 14/64 loss: -3.293527603149414
Batch 15/64 loss: -2.925837516784668
Batch 16/64 loss: -2.991072654724121
Batch 17/64 loss: -3.199887275695801
Batch 18/64 loss: -3.1752519607543945
Batch 19/64 loss: -3.211073875427246
Batch 20/64 loss: -3.5566930770874023
Batch 21/64 loss: -2.9820919036865234
Batch 22/64 loss: -3.1829118728637695
Batch 23/64 loss: -2.908473014831543
Batch 24/64 loss: -2.3701581954956055
Batch 25/64 loss: -3.0091114044189453
Batch 26/64 loss: -3.1579160690307617
Batch 27/64 loss: -2.7963361740112305
Batch 28/64 loss: -2.9258317947387695
Batch 29/64 loss: -3.188523292541504
Batch 30/64 loss: -2.819202423095703
Batch 31/64 loss: -2.9026031494140625
Batch 32/64 loss: -3.1665496826171875
Batch 33/64 loss: -2.9964284896850586
Batch 34/64 loss: -3.093430519104004
Batch 35/64 loss: -3.0894460678100586
Batch 36/64 loss: -3.2679214477539062
Batch 37/64 loss: -3.0149478912353516
Batch 38/64 loss: -3.2237253189086914
Batch 39/64 loss: -3.21829891204834
Batch 40/64 loss: -3.2244873046875
Batch 41/64 loss: -2.917963981628418
Batch 42/64 loss: -3.2486696243286133
Batch 43/64 loss: -3.3046131134033203
Batch 44/64 loss: -2.9004440307617188
Batch 45/64 loss: -3.235835075378418
Batch 46/64 loss: -3.0688886642456055
Batch 47/64 loss: -3.3183937072753906
Batch 48/64 loss: -2.478276252746582
Batch 49/64 loss: -2.7351369857788086
Batch 50/64 loss: -3.3689212799072266
Batch 51/64 loss: -2.8055124282836914
Batch 52/64 loss: -3.089292526245117
Batch 53/64 loss: -3.248316764831543
Batch 54/64 loss: -3.2253055572509766
Batch 55/64 loss: -3.2903966903686523
Batch 56/64 loss: -3.2691659927368164
Batch 57/64 loss: -2.938605308532715
Batch 58/64 loss: -3.306386947631836
Batch 59/64 loss: -3.3092269897460938
Batch 60/64 loss: -3.065784454345703
Batch 61/64 loss: -3.244004249572754
Batch 62/64 loss: -3.3242616653442383
Batch 63/64 loss: -3.2911338806152344
Batch 64/64 loss: -7.851772785186768
Epoch 197  Train loss: -3.1422121739855  Val loss: -3.4781194601681635
Epoch 198
-------------------------------
Batch 1/64 loss: -2.9723501205444336
Batch 2/64 loss: -3.562685012817383
Batch 3/64 loss: -3.3637781143188477
Batch 4/64 loss: -3.2758798599243164
Batch 5/64 loss: -3.2474746704101562
Batch 6/64 loss: -2.5146045684814453
Batch 7/64 loss: -2.759524345397949
Batch 8/64 loss: -3.251065254211426
Batch 9/64 loss: -3.2749061584472656
Batch 10/64 loss: -2.2036943435668945
Batch 11/64 loss: -3.277111053466797
Batch 12/64 loss: -3.2237892150878906
Batch 13/64 loss: -2.9572219848632812
Batch 14/64 loss: -2.9982872009277344
Batch 15/64 loss: -3.242373466491699
Batch 16/64 loss: -3.363626480102539
Batch 17/64 loss: -3.0101499557495117
Batch 18/64 loss: -3.0308847427368164
Batch 19/64 loss: -3.128035545349121
Batch 20/64 loss: -3.3414430618286133
Batch 21/64 loss: -2.907588005065918
Batch 22/64 loss: -3.1294631958007812
Batch 23/64 loss: -2.8062076568603516
Batch 24/64 loss: -2.7977771759033203
Batch 25/64 loss: -3.1525468826293945
Batch 26/64 loss: -3.315119743347168
Batch 27/64 loss: -2.877361297607422
Batch 28/64 loss: -3.26168155670166
Batch 29/64 loss: -3.380952835083008
Batch 30/64 loss: -3.2965831756591797
Batch 31/64 loss: -2.987372398376465
Batch 32/64 loss: -3.206467628479004
Batch 33/64 loss: -2.9364261627197266
Batch 34/64 loss: -2.8254308700561523
Batch 35/64 loss: -3.2977294921875
Batch 36/64 loss: -3.047290802001953
Batch 37/64 loss: -3.3529462814331055
Batch 38/64 loss: -3.027414321899414
Batch 39/64 loss: -3.352357864379883
Batch 40/64 loss: -3.16391658782959
Batch 41/64 loss: -3.2580394744873047
Batch 42/64 loss: -3.2377967834472656
Batch 43/64 loss: -3.330145835876465
Batch 44/64 loss: -3.248016357421875
Batch 45/64 loss: -3.2546472549438477
Batch 46/64 loss: -3.2369937896728516
Batch 47/64 loss: -3.3147783279418945
Batch 48/64 loss: -3.2316646575927734
Batch 49/64 loss: -3.3670530319213867
Batch 50/64 loss: -3.1257638931274414
Batch 51/64 loss: -3.1579599380493164
Batch 52/64 loss: -3.141472816467285
Batch 53/64 loss: -3.1154251098632812
Batch 54/64 loss: -3.4862051010131836
Batch 55/64 loss: -2.9834680557250977
Batch 56/64 loss: -3.443897247314453
Batch 57/64 loss: -3.2999773025512695
Batch 58/64 loss: -3.51235294342041
Batch 59/64 loss: -3.023082733154297
Batch 60/64 loss: -3.2878990173339844
Batch 61/64 loss: -2.9417896270751953
Batch 62/64 loss: -3.1386804580688477
Batch 63/64 loss: -3.2187623977661133
Batch 64/64 loss: -7.22587251663208
Epoch 198  Train loss: -3.1983811079287063  Val loss: -3.4201949208053115
Epoch 199
-------------------------------
Batch 1/64 loss: -3.3748226165771484
Batch 2/64 loss: -3.2683935165405273
Batch 3/64 loss: -2.8172388076782227
Batch 4/64 loss: -3.2197751998901367
Batch 5/64 loss: -2.943735122680664
Batch 6/64 loss: -3.1298160552978516
Batch 7/64 loss: -2.7436294555664062
Batch 8/64 loss: -2.5494298934936523
Batch 9/64 loss: -3.1016712188720703
Batch 10/64 loss: -2.3473663330078125
Batch 11/64 loss: -3.0933713912963867
Batch 12/64 loss: -2.792941093444824
Batch 13/64 loss: -3.041750907897949
Batch 14/64 loss: -2.719419479370117
Batch 15/64 loss: -3.323666572570801
Batch 16/64 loss: -3.2774152755737305
Batch 17/64 loss: -3.1555604934692383
Batch 18/64 loss: -3.2365283966064453
Batch 19/64 loss: -3.1316967010498047
Batch 20/64 loss: -3.0780162811279297
Batch 21/64 loss: -2.6172494888305664
Batch 22/64 loss: -3.2216100692749023
Batch 23/64 loss: -3.1009092330932617
Batch 24/64 loss: -3.0993499755859375
Batch 25/64 loss: -2.8489303588867188
Batch 26/64 loss: -3.3879594802856445
Batch 27/64 loss: -3.2241106033325195
Batch 28/64 loss: -3.016336441040039
Batch 29/64 loss: -3.3290786743164062
Batch 30/64 loss: -2.8401145935058594
Batch 31/64 loss: -2.9870567321777344
Batch 32/64 loss: -3.2974395751953125
Batch 33/64 loss: -3.3123607635498047
Batch 34/64 loss: -3.5458617210388184
Batch 35/64 loss: -2.664801597595215
Batch 36/64 loss: -3.3400707244873047
Batch 37/64 loss: -3.1765031814575195
Batch 38/64 loss: -3.2426538467407227
Batch 39/64 loss: -3.218240737915039
Batch 40/64 loss: -3.5102758407592773
Batch 41/64 loss: -2.8290023803710938
Batch 42/64 loss: -3.0618581771850586
Batch 43/64 loss: -3.080134391784668
Batch 44/64 loss: -3.3380041122436523
Batch 45/64 loss: -2.7057409286499023
Batch 46/64 loss: -2.7991199493408203
Batch 47/64 loss: -3.3651132583618164
Batch 48/64 loss: -1.892960548400879
Batch 49/64 loss: -2.8201980590820312
Batch 50/64 loss: -3.099292755126953
Batch 51/64 loss: -3.4962568283081055
Batch 52/64 loss: -3.3269004821777344
Batch 53/64 loss: -3.461627960205078
Batch 54/64 loss: -3.268270492553711
Batch 55/64 loss: -3.112520217895508
Batch 56/64 loss: -3.1980361938476562
Batch 57/64 loss: -3.1786279678344727
Batch 58/64 loss: -3.2013025283813477
Batch 59/64 loss: -2.6668949127197266
Batch 60/64 loss: -3.1941633224487305
Batch 61/64 loss: -2.9128026962280273
Batch 62/64 loss: -3.015347480773926
Batch 63/64 loss: -2.8623056411743164
Batch 64/64 loss: -7.6575093269348145
Epoch 199  Train loss: -3.120890536962771  Val loss: -3.497112995160814
Epoch 200
-------------------------------
Batch 1/64 loss: -2.709774971008301
Batch 2/64 loss: -3.353915214538574
Batch 3/64 loss: -3.3869237899780273
Batch 4/64 loss: -3.3687734603881836
Batch 5/64 loss: -3.373910903930664
Batch 6/64 loss: -3.3504953384399414
Batch 7/64 loss: -3.093221664428711
Batch 8/64 loss: -3.374098777770996
Batch 9/64 loss: -3.24725341796875
Batch 10/64 loss: -2.6393661499023438
Batch 11/64 loss: -3.2628517150878906
Batch 12/64 loss: -3.2666845321655273
Batch 13/64 loss: -3.3365859985351562
Batch 14/64 loss: -3.135347366333008
Batch 15/64 loss: -3.5779294967651367
Batch 16/64 loss: -3.4285221099853516
Batch 17/64 loss: -3.3261022567749023
Batch 18/64 loss: -2.7983522415161133
Batch 19/64 loss: -3.0411596298217773
Batch 20/64 loss: -2.9021434783935547
Batch 21/64 loss: -3.010836601257324
Batch 22/64 loss: -2.988581657409668
Batch 23/64 loss: -2.6789302825927734
Batch 24/64 loss: -2.7135934829711914
Batch 25/64 loss: -2.8960533142089844
Batch 26/64 loss: -2.910233497619629
Batch 27/64 loss: -3.044651985168457
Batch 28/64 loss: -2.550008773803711
Batch 29/64 loss: -3.464993476867676
Batch 30/64 loss: -3.024934768676758
Batch 31/64 loss: -3.2758913040161133
Batch 32/64 loss: -3.314851760864258
Batch 33/64 loss: -2.9873485565185547
Batch 34/64 loss: -3.1119918823242188
Batch 35/64 loss: -3.214066505432129
Batch 36/64 loss: -3.2862863540649414
Batch 37/64 loss: -3.208958625793457
Batch 38/64 loss: -2.9586172103881836
Batch 39/64 loss: -3.481572151184082
Batch 40/64 loss: -3.2315759658813477
Batch 41/64 loss: -2.895113945007324
Batch 42/64 loss: -3.192030906677246
Batch 43/64 loss: -3.0313844680786133
Batch 44/64 loss: -3.3591814041137695
Batch 45/64 loss: -3.3918275833129883
Batch 46/64 loss: -2.709259033203125
Batch 47/64 loss: -2.832118034362793
Batch 48/64 loss: -3.304410934448242
Batch 49/64 loss: -2.7198963165283203
Batch 50/64 loss: -3.497262954711914
Batch 51/64 loss: -3.3077754974365234
Batch 52/64 loss: -3.5102615356445312
Batch 53/64 loss: -3.2362890243530273
Batch 54/64 loss: -3.352269172668457
Batch 55/64 loss: -3.132523536682129
Batch 56/64 loss: -2.5447397232055664
Batch 57/64 loss: -3.20473575592041
Batch 58/64 loss: -3.0243921279907227
Batch 59/64 loss: -3.2540111541748047
Batch 60/64 loss: -3.3630170822143555
Batch 61/64 loss: -3.171847343444824
Batch 62/64 loss: -2.979452133178711
Batch 63/64 loss: -3.1345481872558594
Batch 64/64 loss: -7.811886310577393
Epoch 200  Train loss: -3.1895631883658613  Val loss: -3.4051362263787652
Epoch 201
-------------------------------
Batch 1/64 loss: -3.0648231506347656
Batch 2/64 loss: -3.3510208129882812
Batch 3/64 loss: -3.27547550201416
Batch 4/64 loss: -3.079479217529297
Batch 5/64 loss: -3.335113525390625
Batch 6/64 loss: -3.107205390930176
Batch 7/64 loss: -3.137221336364746
Batch 8/64 loss: -3.2078590393066406
Batch 9/64 loss: -3.255599021911621
Batch 10/64 loss: -3.0757551193237305
Batch 11/64 loss: -3.4552793502807617
Batch 12/64 loss: -3.116217613220215
Batch 13/64 loss: -3.356377601623535
Batch 14/64 loss: -3.1939878463745117
Batch 15/64 loss: -3.2326717376708984
Batch 16/64 loss: -3.19913387298584
Batch 17/64 loss: -3.200211524963379
Batch 18/64 loss: -3.1809892654418945
Batch 19/64 loss: -3.2547121047973633
Batch 20/64 loss: -2.920398712158203
Batch 21/64 loss: -3.013378143310547
Batch 22/64 loss: -2.469355583190918
Batch 23/64 loss: -3.014690399169922
Batch 24/64 loss: -3.2491455078125
Batch 25/64 loss: -3.2802553176879883
Batch 26/64 loss: -3.111128807067871
Batch 27/64 loss: -3.2413482666015625
Batch 28/64 loss: -3.1304855346679688
Batch 29/64 loss: -3.2032222747802734
Batch 30/64 loss: -3.1674089431762695
Batch 31/64 loss: -3.0406570434570312
Batch 32/64 loss: -3.00020694732666
Batch 33/64 loss: -3.145109176635742
Batch 34/64 loss: -3.3345718383789062
Batch 35/64 loss: -2.734823226928711
Batch 36/64 loss: -3.0643787384033203
Batch 37/64 loss: -3.329151153564453
Batch 38/64 loss: -2.9012088775634766
Batch 39/64 loss: -3.2972850799560547
Batch 40/64 loss: -3.225102424621582
Batch 41/64 loss: -2.9804258346557617
Batch 42/64 loss: -3.3934497833251953
Batch 43/64 loss: -3.115035057067871
Batch 44/64 loss: -3.257387161254883
Batch 45/64 loss: -3.2727508544921875
Batch 46/64 loss: -3.2136287689208984
Batch 47/64 loss: -3.261079788208008
Batch 48/64 loss: -3.3642568588256836
Batch 49/64 loss: -3.3055105209350586
Batch 50/64 loss: -2.9855690002441406
Batch 51/64 loss: -3.2356653213500977
Batch 52/64 loss: -3.3980579376220703
Batch 53/64 loss: -3.3005619049072266
Batch 54/64 loss: -3.3721485137939453
Batch 55/64 loss: -3.2643747329711914
Batch 56/64 loss: -3.306757926940918
Batch 57/64 loss: -3.2403717041015625
Batch 58/64 loss: -3.2226200103759766
Batch 59/64 loss: -3.259005546569824
Batch 60/64 loss: -3.048214912414551
Batch 61/64 loss: -2.5554046630859375
Batch 62/64 loss: -3.5414676666259766
Batch 63/64 loss: -3.2512006759643555
Batch 64/64 loss: -7.5153093338012695
Epoch 201  Train loss: -3.2271979949053597  Val loss: -3.4817526119271505
Epoch 202
-------------------------------
Batch 1/64 loss: -3.2238426208496094
Batch 2/64 loss: -3.2381505966186523
Batch 3/64 loss: -3.155949592590332
Batch 4/64 loss: -3.1900787353515625
Batch 5/64 loss: -3.3469934463500977
Batch 6/64 loss: -3.353114128112793
Batch 7/64 loss: -3.4121437072753906
Batch 8/64 loss: -2.423189163208008
Batch 9/64 loss: -3.3406763076782227
Batch 10/64 loss: -3.042269706726074
Batch 11/64 loss: -3.163167953491211
Batch 12/64 loss: -3.5438709259033203
Batch 13/64 loss: -3.4320201873779297
Batch 14/64 loss: -3.357666015625
Batch 15/64 loss: -3.112339973449707
Batch 16/64 loss: -3.149306297302246
Batch 17/64 loss: -2.6292924880981445
Batch 18/64 loss: -3.1892452239990234
Batch 19/64 loss: -3.470456123352051
Batch 20/64 loss: -3.0819740295410156
Batch 21/64 loss: -3.3774166107177734
Batch 22/64 loss: -3.038270950317383
Batch 23/64 loss: -3.1902875900268555
Batch 24/64 loss: -3.047842025756836
Batch 25/64 loss: -3.25946044921875
Batch 26/64 loss: -2.869922637939453
Batch 27/64 loss: -3.3853931427001953
Batch 28/64 loss: -3.364419937133789
Batch 29/64 loss: -3.53115177154541
Batch 30/64 loss: -3.1247663497924805
Batch 31/64 loss: -3.093923568725586
Batch 32/64 loss: -3.3106460571289062
Batch 33/64 loss: -3.4282970428466797
Batch 34/64 loss: -3.236872673034668
Batch 35/64 loss: -3.5439319610595703
Batch 36/64 loss: -3.023996353149414
Batch 37/64 loss: -3.2708778381347656
Batch 38/64 loss: -3.3730621337890625
Batch 39/64 loss: -2.9336585998535156
Batch 40/64 loss: -3.0170297622680664
Batch 41/64 loss: -3.3751115798950195
Batch 42/64 loss: -3.4817934036254883
Batch 43/64 loss: -3.0215797424316406
Batch 44/64 loss: -3.370438575744629
Batch 45/64 loss: -3.181253433227539
Batch 46/64 loss: -3.105112075805664
Batch 47/64 loss: -3.2527341842651367
Batch 48/64 loss: -3.285027503967285
Batch 49/64 loss: -3.5774455070495605
Batch 50/64 loss: -3.3136396408081055
Batch 51/64 loss: -2.8538818359375
Batch 52/64 loss: -3.495725631713867
Batch 53/64 loss: -3.4359560012817383
Batch 54/64 loss: -3.412485122680664
Batch 55/64 loss: -3.2661333084106445
Batch 56/64 loss: -3.35659122467041
Batch 57/64 loss: -3.4279212951660156
Batch 58/64 loss: -3.3118743896484375
Batch 59/64 loss: -3.205228805541992
Batch 60/64 loss: -2.8615713119506836
Batch 61/64 loss: -3.426182746887207
Batch 62/64 loss: -3.5025529861450195
Batch 63/64 loss: -3.469733238220215
Batch 64/64 loss: -8.168535232543945
Epoch 202  Train loss: -3.3002878376081877  Val loss: -3.57233739636608
Epoch 203
-------------------------------
Batch 1/64 loss: -3.2852230072021484
Batch 2/64 loss: -3.568370819091797
Batch 3/64 loss: -3.151577949523926
Batch 4/64 loss: -3.2666702270507812
Batch 5/64 loss: -3.3549041748046875
Batch 6/64 loss: -3.1005382537841797
Batch 7/64 loss: -3.33553409576416
Batch 8/64 loss: -3.1599435806274414
Batch 9/64 loss: -3.1957597732543945
Batch 10/64 loss: -3.148501396179199
Batch 11/64 loss: -3.4869871139526367
Batch 12/64 loss: -3.376215934753418
Batch 13/64 loss: -3.44189453125
Batch 14/64 loss: -2.9362335205078125
Batch 15/64 loss: -3.178402900695801
Batch 16/64 loss: -3.2644872665405273
Batch 17/64 loss: -2.3525094985961914
Batch 18/64 loss: -3.4767627716064453
Batch 19/64 loss: -3.418752670288086
Batch 20/64 loss: -2.871976852416992
Batch 21/64 loss: -3.432400703430176
Batch 22/64 loss: -3.095592498779297
Batch 23/64 loss: -3.4176511764526367
Batch 24/64 loss: -2.892458915710449
Batch 25/64 loss: -3.066089630126953
Batch 26/64 loss: -3.3358516693115234
Batch 27/64 loss: -3.0061569213867188
Batch 28/64 loss: -3.188264846801758
Batch 29/64 loss: -3.380852699279785
Batch 30/64 loss: -3.0635290145874023
Batch 31/64 loss: -3.4487972259521484
Batch 32/64 loss: -3.2312135696411133
Batch 33/64 loss: -3.3531970977783203
Batch 34/64 loss: -3.4092283248901367
Batch 35/64 loss: -2.814639091491699
Batch 36/64 loss: -3.5961318016052246
Batch 37/64 loss: -3.566014289855957
Batch 38/64 loss: -3.335947036743164
Batch 39/64 loss: -3.277811050415039
Batch 40/64 loss: -3.3295650482177734
Batch 41/64 loss: -3.150322914123535
Batch 42/64 loss: -2.8813629150390625
Batch 43/64 loss: -3.045443534851074
Batch 44/64 loss: -3.3689279556274414
Batch 45/64 loss: -3.4645490646362305
Batch 46/64 loss: -3.0373525619506836
Batch 47/64 loss: -3.093311309814453
Batch 48/64 loss: -3.3013391494750977
Batch 49/64 loss: -3.119678497314453
Batch 50/64 loss: -3.2159109115600586
Batch 51/64 loss: -3.4544010162353516
Batch 52/64 loss: -3.363581657409668
Batch 53/64 loss: -2.4615859985351562
Batch 54/64 loss: -3.458258628845215
Batch 55/64 loss: -3.370901107788086
Batch 56/64 loss: -3.3878860473632812
Batch 57/64 loss: -2.9799041748046875
Batch 58/64 loss: -3.459792137145996
Batch 59/64 loss: -3.2549896240234375
Batch 60/64 loss: -3.142758369445801
Batch 61/64 loss: -3.149136543273926
Batch 62/64 loss: -3.4415740966796875
Batch 63/64 loss: -3.1441822052001953
Batch 64/64 loss: -7.448449611663818
Epoch 203  Train loss: -3.277586299297856  Val loss: -3.4759744073926786
Epoch 204
-------------------------------
Batch 1/64 loss: -3.4536619186401367
Batch 2/64 loss: -3.367640495300293
Batch 3/64 loss: -3.434398651123047
Batch 4/64 loss: -2.6189651489257812
Batch 5/64 loss: -3.2342004776000977
Batch 6/64 loss: -3.2091026306152344
Batch 7/64 loss: -3.146700859069824
Batch 8/64 loss: -3.213446617126465
Batch 9/64 loss: -2.1373395919799805
Batch 10/64 loss: -3.2800159454345703
Batch 11/64 loss: -3.446765899658203
Batch 12/64 loss: -3.4633874893188477
Batch 13/64 loss: -3.130953788757324
Batch 14/64 loss: -3.099750518798828
Batch 15/64 loss: -3.307797431945801
Batch 16/64 loss: -2.7913818359375
Batch 17/64 loss: -3.6179370880126953
Batch 18/64 loss: -2.8262319564819336
Batch 19/64 loss: -2.6485748291015625
Batch 20/64 loss: -3.024472236633301
Batch 21/64 loss: -3.240748405456543
Batch 22/64 loss: -3.2409706115722656
Batch 23/64 loss: -3.0909194946289062
Batch 24/64 loss: -2.847315788269043
Batch 25/64 loss: -3.213799476623535
Batch 26/64 loss: -3.5105319023132324
Batch 27/64 loss: -2.7390480041503906
Batch 28/64 loss: -3.325979232788086
Batch 29/64 loss: -3.0240211486816406
Batch 30/64 loss: -3.268984794616699
Batch 31/64 loss: -3.145236015319824
Batch 32/64 loss: -3.4345693588256836
Batch 33/64 loss: -3.506011486053467
Batch 34/64 loss: -3.4970245361328125
Batch 35/64 loss: -3.1775550842285156
Batch 36/64 loss: -2.9444141387939453
Batch 37/64 loss: -3.413156509399414
Batch 38/64 loss: -3.2631921768188477
Batch 39/64 loss: -3.337334632873535
Batch 40/64 loss: -3.310694694519043
Batch 41/64 loss: -3.1892099380493164
Batch 42/64 loss: -3.061182975769043
Batch 43/64 loss: -3.2718982696533203
Batch 44/64 loss: -2.7547006607055664
Batch 45/64 loss: -3.187197685241699
Batch 46/64 loss: -2.998933792114258
Batch 47/64 loss: -3.331960678100586
Batch 48/64 loss: -2.972683906555176
Batch 49/64 loss: -2.8965024948120117
Batch 50/64 loss: -3.216301918029785
Batch 51/64 loss: -3.1251487731933594
Batch 52/64 loss: -3.267104148864746
Batch 53/64 loss: -3.4872331619262695
Batch 54/64 loss: -3.26456356048584
Batch 55/64 loss: -3.2592391967773438
Batch 56/64 loss: -3.3639068603515625
Batch 57/64 loss: -3.426150321960449
Batch 58/64 loss: -2.9274110794067383
Batch 59/64 loss: -3.091710090637207
Batch 60/64 loss: -2.6325998306274414
Batch 61/64 loss: -3.2840824127197266
Batch 62/64 loss: -3.1900453567504883
Batch 63/64 loss: -3.213498115539551
Batch 64/64 loss: -8.213980674743652
Epoch 204  Train loss: -3.224438959009507  Val loss: -3.568394493810909
Epoch 205
-------------------------------
Batch 1/64 loss: -3.206109046936035
Batch 2/64 loss: -3.2597856521606445
Batch 3/64 loss: -3.2914609909057617
Batch 4/64 loss: -3.4033260345458984
Batch 5/64 loss: -3.1483116149902344
Batch 6/64 loss: -3.4213762283325195
Batch 7/64 loss: -3.112569808959961
Batch 8/64 loss: -3.090513229370117
Batch 9/64 loss: -3.251032829284668
Batch 10/64 loss: -3.2865962982177734
Batch 11/64 loss: -3.308058738708496
Batch 12/64 loss: -3.399320602416992
Batch 13/64 loss: -3.064603805541992
Batch 14/64 loss: -3.4749507904052734
Batch 15/64 loss: -3.1396074295043945
Batch 16/64 loss: -3.114750862121582
Batch 17/64 loss: -2.9185667037963867
Batch 18/64 loss: -2.954059600830078
Batch 19/64 loss: -2.798595428466797
Batch 20/64 loss: -3.4306421279907227
Batch 21/64 loss: -3.3872509002685547
Batch 22/64 loss: -3.1349878311157227
Batch 23/64 loss: -3.504335880279541
Batch 24/64 loss: -2.7811241149902344
Batch 25/64 loss: -3.4946274757385254
Batch 26/64 loss: -3.0237855911254883
Batch 27/64 loss: -3.3611230850219727
Batch 28/64 loss: -3.374736785888672
Batch 29/64 loss: -3.1607227325439453
Batch 30/64 loss: -3.1771774291992188
Batch 31/64 loss: -2.6899633407592773
Batch 32/64 loss: -3.4627742767333984
Batch 33/64 loss: -3.4634199142456055
Batch 34/64 loss: -3.172085762023926
Batch 35/64 loss: -3.0333003997802734
Batch 36/64 loss: -3.112201690673828
Batch 37/64 loss: -3.5020065307617188
Batch 38/64 loss: -3.3115339279174805
Batch 39/64 loss: -3.313844680786133
Batch 40/64 loss: -3.320241928100586
Batch 41/64 loss: -3.369723320007324
Batch 42/64 loss: -3.5392508506774902
Batch 43/64 loss: -2.877068519592285
Batch 44/64 loss: -3.020064353942871
Batch 45/64 loss: -3.124527931213379
Batch 46/64 loss: -3.376171112060547
Batch 47/64 loss: -3.5493335723876953
Batch 48/64 loss: -2.954784393310547
Batch 49/64 loss: -3.3514928817749023
Batch 50/64 loss: -3.309539794921875
Batch 51/64 loss: -3.3384323120117188
Batch 52/64 loss: -3.118422508239746
Batch 53/64 loss: -3.191941261291504
Batch 54/64 loss: -3.3175697326660156
Batch 55/64 loss: -2.9122724533081055
Batch 56/64 loss: -3.1730127334594727
Batch 57/64 loss: -2.3767127990722656
Batch 58/64 loss: -3.369442939758301
Batch 59/64 loss: -3.1359481811523438
Batch 60/64 loss: -3.3614816665649414
Batch 61/64 loss: -3.378464698791504
Batch 62/64 loss: -3.3906641006469727
Batch 63/64 loss: -2.776216506958008
Batch 64/64 loss: -7.800985336303711
Epoch 205  Train loss: -3.263039368274165  Val loss: -3.3327402462254683
Epoch 206
-------------------------------
Batch 1/64 loss: -3.103034019470215
Batch 2/64 loss: -3.229254722595215
Batch 3/64 loss: -2.7950668334960938
Batch 4/64 loss: -2.8406906127929688
Batch 5/64 loss: -3.2493419647216797
Batch 6/64 loss: -3.1941137313842773
Batch 7/64 loss: -3.078883171081543
Batch 8/64 loss: -3.2135848999023438
Batch 9/64 loss: -3.132838249206543
Batch 10/64 loss: -3.1455116271972656
Batch 11/64 loss: -3.1206130981445312
Batch 12/64 loss: -3.1144065856933594
Batch 13/64 loss: -3.411439895629883
Batch 14/64 loss: -3.5898184776306152
Batch 15/64 loss: -3.2844982147216797
Batch 16/64 loss: -3.566159725189209
Batch 17/64 loss: -3.3185081481933594
Batch 18/64 loss: -3.1734142303466797
Batch 19/64 loss: -3.553116798400879
Batch 20/64 loss: -3.2923383712768555
Batch 21/64 loss: -2.779341697692871
Batch 22/64 loss: -3.1207780838012695
Batch 23/64 loss: -3.256161689758301
Batch 24/64 loss: -3.496249198913574
Batch 25/64 loss: -3.307985305786133
Batch 26/64 loss: -3.0595197677612305
Batch 27/64 loss: -3.35980224609375
Batch 28/64 loss: -3.2117481231689453
Batch 29/64 loss: -3.348025321960449
Batch 30/64 loss: -3.4326562881469727
Batch 31/64 loss: -3.3881216049194336
Batch 32/64 loss: -3.285097122192383
Batch 33/64 loss: -3.586897373199463
Batch 34/64 loss: -3.2444725036621094
Batch 35/64 loss: -3.430201530456543
Batch 36/64 loss: -3.2447948455810547
Batch 37/64 loss: -3.0598363876342773
Batch 38/64 loss: -3.526780605316162
Batch 39/64 loss: -3.3484067916870117
Batch 40/64 loss: -2.721524238586426
Batch 41/64 loss: -2.9860658645629883
Batch 42/64 loss: -3.1058263778686523
Batch 43/64 loss: -3.236077308654785
Batch 44/64 loss: -3.2690439224243164
Batch 45/64 loss: -3.3724937438964844
Batch 46/64 loss: -3.273609161376953
Batch 47/64 loss: -3.296492576599121
Batch 48/64 loss: -3.2436256408691406
Batch 49/64 loss: -3.4633331298828125
Batch 50/64 loss: -1.9833183288574219
Batch 51/64 loss: -3.428023338317871
Batch 52/64 loss: -2.6758041381835938
Batch 53/64 loss: -2.898731231689453
Batch 54/64 loss: -3.082418441772461
Batch 55/64 loss: -3.105813980102539
Batch 56/64 loss: -3.238102912902832
Batch 57/64 loss: -3.140565872192383
Batch 58/64 loss: -3.2291908264160156
Batch 59/64 loss: -3.331212043762207
Batch 60/64 loss: -3.2955312728881836
Batch 61/64 loss: -3.4299697875976562
Batch 62/64 loss: -3.4194717407226562
Batch 63/64 loss: -3.30007266998291
Batch 64/64 loss: -8.173173904418945
Epoch 206  Train loss: -3.271367981854607  Val loss: -3.529493862820655
Epoch 207
-------------------------------
Batch 1/64 loss: -3.4057998657226562
Batch 2/64 loss: -3.5985074043273926
Batch 3/64 loss: -2.0638885498046875
Batch 4/64 loss: -3.3610992431640625
Batch 5/64 loss: -3.3175582885742188
Batch 6/64 loss: -3.3407726287841797
Batch 7/64 loss: -3.4852609634399414
Batch 8/64 loss: -2.8465776443481445
Batch 9/64 loss: -3.538933753967285
Batch 10/64 loss: -3.4456710815429688
Batch 11/64 loss: -2.7482337951660156
Batch 12/64 loss: -3.349720001220703
Batch 13/64 loss: -3.1333465576171875
Batch 14/64 loss: -3.144704818725586
Batch 15/64 loss: -3.388176918029785
Batch 16/64 loss: -3.4669570922851562
Batch 17/64 loss: -3.167776107788086
Batch 18/64 loss: -3.0462818145751953
Batch 19/64 loss: -3.2224197387695312
Batch 20/64 loss: -3.163914680480957
Batch 21/64 loss: -3.4975509643554688
Batch 22/64 loss: -3.4315061569213867
Batch 23/64 loss: -3.0161962509155273
Batch 24/64 loss: -3.190340042114258
Batch 25/64 loss: -2.964435577392578
Batch 26/64 loss: -3.276913642883301
Batch 27/64 loss: -3.496601104736328
Batch 28/64 loss: -3.3459205627441406
Batch 29/64 loss: -3.3291969299316406
Batch 30/64 loss: -3.1378421783447266
Batch 31/64 loss: -3.2147531509399414
Batch 32/64 loss: -3.339710235595703
Batch 33/64 loss: -3.288151741027832
Batch 34/64 loss: -3.1778650283813477
Batch 35/64 loss: -3.2363624572753906
Batch 36/64 loss: -3.3674230575561523
Batch 37/64 loss: -3.4554786682128906
Batch 38/64 loss: -3.3523311614990234
Batch 39/64 loss: -3.423579216003418
Batch 40/64 loss: -3.164968490600586
Batch 41/64 loss: -3.305953025817871
Batch 42/64 loss: -3.401644706726074
Batch 43/64 loss: -3.3120737075805664
Batch 44/64 loss: -3.330796241760254
Batch 45/64 loss: -3.3477210998535156
Batch 46/64 loss: -3.203763008117676
Batch 47/64 loss: -3.4216060638427734
Batch 48/64 loss: -3.153230667114258
Batch 49/64 loss: -3.2062902450561523
Batch 50/64 loss: -3.3338699340820312
Batch 51/64 loss: -3.222804069519043
Batch 52/64 loss: -3.583397388458252
Batch 53/64 loss: -3.288081169128418
Batch 54/64 loss: -3.3530845642089844
Batch 55/64 loss: -3.345224380493164
Batch 56/64 loss: -3.5140442848205566
Batch 57/64 loss: -3.1575889587402344
Batch 58/64 loss: -3.0768375396728516
Batch 59/64 loss: -3.394972801208496
Batch 60/64 loss: -3.4318723678588867
Batch 61/64 loss: -3.26979923248291
Batch 62/64 loss: -3.009754180908203
Batch 63/64 loss: -3.375295639038086
Batch 64/64 loss: -7.8699493408203125
Epoch 207  Train loss: -3.3236846250646255  Val loss: -3.5654058292559334
Epoch 208
-------------------------------
Batch 1/64 loss: -3.2623538970947266
Batch 2/64 loss: -3.5664749145507812
Batch 3/64 loss: -3.240415573120117
Batch 4/64 loss: -3.5111122131347656
Batch 5/64 loss: -3.4003829956054688
Batch 6/64 loss: -3.505256175994873
Batch 7/64 loss: -3.329707145690918
Batch 8/64 loss: -3.018329620361328
Batch 9/64 loss: -3.6248159408569336
Batch 10/64 loss: -3.4033966064453125
Batch 11/64 loss: -3.4600305557250977
Batch 12/64 loss: -3.058651924133301
Batch 13/64 loss: -3.4290084838867188
Batch 14/64 loss: -3.4571714401245117
Batch 15/64 loss: -3.584266185760498
Batch 16/64 loss: -3.0161256790161133
Batch 17/64 loss: -3.2892799377441406
Batch 18/64 loss: -3.555853843688965
Batch 19/64 loss: -3.231818199157715
Batch 20/64 loss: -2.7247514724731445
Batch 21/64 loss: -3.4170284271240234
Batch 22/64 loss: -3.36098575592041
Batch 23/64 loss: -3.273024559020996
Batch 24/64 loss: -3.4669322967529297
Batch 25/64 loss: -3.0956315994262695
Batch 26/64 loss: -2.672480583190918
Batch 27/64 loss: -3.2751169204711914
Batch 28/64 loss: -3.4480037689208984
Batch 29/64 loss: -3.497617721557617
Batch 30/64 loss: -3.4578285217285156
Batch 31/64 loss: -3.651014804840088
Batch 32/64 loss: -3.4639663696289062
Batch 33/64 loss: -3.1714277267456055
Batch 34/64 loss: -3.4448328018188477
Batch 35/64 loss: -3.0449113845825195
Batch 36/64 loss: -3.378345489501953
Batch 37/64 loss: -3.465277671813965
Batch 38/64 loss: -3.4414587020874023
Batch 39/64 loss: -3.4627466201782227
Batch 40/64 loss: -3.465608596801758
Batch 41/64 loss: -3.32607364654541
Batch 42/64 loss: -3.465306282043457
Batch 43/64 loss: -3.312528610229492
Batch 44/64 loss: -3.363389015197754
Batch 45/64 loss: -3.5303754806518555
Batch 46/64 loss: -3.3185997009277344
Batch 47/64 loss: -3.3890209197998047
Batch 48/64 loss: -3.375152587890625
Batch 49/64 loss: -3.0728158950805664
Batch 50/64 loss: -2.7238903045654297
Batch 51/64 loss: -3.1644420623779297
Batch 52/64 loss: -3.729177474975586
Batch 53/64 loss: -3.508136749267578
Batch 54/64 loss: -3.4603805541992188
Batch 55/64 loss: -3.375094413757324
Batch 56/64 loss: -3.445815086364746
Batch 57/64 loss: -3.088226318359375
Batch 58/64 loss: -3.4864768981933594
Batch 59/64 loss: -3.5946922302246094
Batch 60/64 loss: -3.4108686447143555
Batch 61/64 loss: -2.940035820007324
Batch 62/64 loss: -3.3856515884399414
Batch 63/64 loss: -3.1501007080078125
Batch 64/64 loss: -8.048360824584961
Epoch 208  Train loss: -3.39256415273629  Val loss: -3.5597044430237865
Epoch 209
-------------------------------
Batch 1/64 loss: -3.1439437866210938
Batch 2/64 loss: -3.4719676971435547
Batch 3/64 loss: -3.4664440155029297
Batch 4/64 loss: -3.45540714263916
Batch 5/64 loss: -3.0331544876098633
Batch 6/64 loss: -3.2027273178100586
Batch 7/64 loss: -3.417146682739258
Batch 8/64 loss: -3.136075019836426
Batch 9/64 loss: -3.2256507873535156
Batch 10/64 loss: -2.6802406311035156
Batch 11/64 loss: -3.005599021911621
Batch 12/64 loss: -3.306309700012207
Batch 13/64 loss: -3.283860206604004
Batch 14/64 loss: -3.425673484802246
Batch 15/64 loss: -3.132815361022949
Batch 16/64 loss: -3.334689140319824
Batch 17/64 loss: -3.172182083129883
Batch 18/64 loss: -3.2403125762939453
Batch 19/64 loss: -3.1518821716308594
Batch 20/64 loss: -3.141566276550293
Batch 21/64 loss: -2.6517887115478516
Batch 22/64 loss: -3.466109275817871
Batch 23/64 loss: -2.954692840576172
Batch 24/64 loss: -3.370182991027832
Batch 25/64 loss: -3.007716178894043
Batch 26/64 loss: -3.1704092025756836
Batch 27/64 loss: -3.4440059661865234
Batch 28/64 loss: -2.9076976776123047
Batch 29/64 loss: -2.6847448348999023
Batch 30/64 loss: -3.3634328842163086
Batch 31/64 loss: -2.9678449630737305
Batch 32/64 loss: -3.280379295349121
Batch 33/64 loss: -3.2423830032348633
Batch 34/64 loss: -3.29819393157959
Batch 35/64 loss: -3.160872459411621
Batch 36/64 loss: -3.157414436340332
Batch 37/64 loss: -3.161457061767578
Batch 38/64 loss: -3.080869674682617
Batch 39/64 loss: -3.32968807220459
Batch 40/64 loss: -2.7698488235473633
Batch 41/64 loss: -3.30924129486084
Batch 42/64 loss: -2.616419792175293
Batch 43/64 loss: -3.4473886489868164
Batch 44/64 loss: -3.304079055786133
Batch 45/64 loss: -3.1943893432617188
Batch 46/64 loss: -3.1591358184814453
Batch 47/64 loss: -3.473849296569824
Batch 48/64 loss: -3.494800567626953
Batch 49/64 loss: -3.224119186401367
Batch 50/64 loss: -3.2854976654052734
Batch 51/64 loss: -3.103971481323242
Batch 52/64 loss: -3.4763245582580566
Batch 53/64 loss: -2.9451866149902344
Batch 54/64 loss: -3.350205421447754
Batch 55/64 loss: -3.444451332092285
Batch 56/64 loss: -3.2136688232421875
Batch 57/64 loss: -3.500239372253418
Batch 58/64 loss: -3.529024124145508
Batch 59/64 loss: -2.475078582763672
Batch 60/64 loss: -3.3029346466064453
Batch 61/64 loss: -3.045933723449707
Batch 62/64 loss: -2.592998504638672
Batch 63/64 loss: -3.409123420715332
Batch 64/64 loss: -8.04524040222168
Epoch 209  Train loss: -3.2443822972914753  Val loss: -3.4526893379762003
Epoch 210
-------------------------------
Batch 1/64 loss: -3.224879264831543
Batch 2/64 loss: -3.5789895057678223
Batch 3/64 loss: -3.2378034591674805
Batch 4/64 loss: -3.357206344604492
Batch 5/64 loss: -3.367635726928711
Batch 6/64 loss: -3.280405044555664
Batch 7/64 loss: -3.3732500076293945
Batch 8/64 loss: -3.4299964904785156
Batch 9/64 loss: -3.0653276443481445
Batch 10/64 loss: -3.2369441986083984
Batch 11/64 loss: -3.4467391967773438
Batch 12/64 loss: -3.5355348587036133
Batch 13/64 loss: -3.548297882080078
Batch 14/64 loss: -2.422985076904297
Batch 15/64 loss: -3.199075698852539
Batch 16/64 loss: -3.2245407104492188
Batch 17/64 loss: -3.576955795288086
Batch 18/64 loss: -3.492910385131836
Batch 19/64 loss: -3.463089942932129
Batch 20/64 loss: -3.2224817276000977
Batch 21/64 loss: -3.472078323364258
Batch 22/64 loss: -3.3458938598632812
Batch 23/64 loss: -3.561919689178467
Batch 24/64 loss: -3.452585220336914
Batch 25/64 loss: -3.439112663269043
Batch 26/64 loss: -3.072052001953125
Batch 27/64 loss: -3.0994882583618164
Batch 28/64 loss: -3.192429542541504
Batch 29/64 loss: -3.193812370300293
Batch 30/64 loss: -3.429605484008789
Batch 31/64 loss: -3.4390954971313477
Batch 32/64 loss: -3.4112548828125
Batch 33/64 loss: -2.962183952331543
Batch 34/64 loss: -3.200998306274414
Batch 35/64 loss: -3.448284149169922
Batch 36/64 loss: -3.3346996307373047
Batch 37/64 loss: -2.5799245834350586
Batch 38/64 loss: -3.2645063400268555
Batch 39/64 loss: -3.3603458404541016
Batch 40/64 loss: -2.696253776550293
Batch 41/64 loss: -2.970611572265625
Batch 42/64 loss: -3.2363176345825195
Batch 43/64 loss: -3.5713510513305664
Batch 44/64 loss: -3.3192758560180664
Batch 45/64 loss: -3.1660242080688477
Batch 46/64 loss: -3.525498390197754
Batch 47/64 loss: -3.0810060501098633
Batch 48/64 loss: -3.2082996368408203
Batch 49/64 loss: -3.032266616821289
Batch 50/64 loss: -3.4792728424072266
Batch 51/64 loss: -3.1016550064086914
Batch 52/64 loss: -2.8905954360961914
Batch 53/64 loss: -3.2660884857177734
Batch 54/64 loss: -3.3552093505859375
Batch 55/64 loss: -3.244020462036133
Batch 56/64 loss: -3.4504947662353516
Batch 57/64 loss: -3.1933374404907227
Batch 58/64 loss: -3.5137147903442383
Batch 59/64 loss: -3.292753219604492
Batch 60/64 loss: -3.525150775909424
Batch 61/64 loss: -3.350499153137207
Batch 62/64 loss: -3.52217960357666
Batch 63/64 loss: -2.990950584411621
Batch 64/64 loss: -7.859869480133057
Epoch 210  Train loss: -3.3321262490515617  Val loss: -3.667210896809896
Epoch 211
-------------------------------
Batch 1/64 loss: -3.2306814193725586
Batch 2/64 loss: -3.3888750076293945
Batch 3/64 loss: -3.5635862350463867
Batch 4/64 loss: -3.3141698837280273
Batch 5/64 loss: -3.3510751724243164
Batch 6/64 loss: -3.3384456634521484
Batch 7/64 loss: -3.4679784774780273
Batch 8/64 loss: -3.6077747344970703
Batch 9/64 loss: -3.5172929763793945
Batch 10/64 loss: -3.4497690200805664
Batch 11/64 loss: -3.463698387145996
Batch 12/64 loss: -3.0297183990478516
Batch 13/64 loss: -3.3319740295410156
Batch 14/64 loss: -3.3802709579467773
Batch 15/64 loss: -3.2481698989868164
Batch 16/64 loss: -3.505178451538086
Batch 17/64 loss: -3.399944305419922
Batch 18/64 loss: -3.622150421142578
Batch 19/64 loss: -3.464059829711914
Batch 20/64 loss: -3.3294219970703125
Batch 21/64 loss: -3.2738380432128906
Batch 22/64 loss: -3.3967838287353516
Batch 23/64 loss: -3.413583755493164
Batch 24/64 loss: -3.514434814453125
Batch 25/64 loss: -3.2070436477661133
Batch 26/64 loss: -3.1171436309814453
Batch 27/64 loss: -2.9539623260498047
Batch 28/64 loss: -3.6075387001037598
Batch 29/64 loss: -3.4062700271606445
Batch 30/64 loss: -2.887147903442383
Batch 31/64 loss: -3.058407783508301
Batch 32/64 loss: -2.991999626159668
Batch 33/64 loss: -3.0873794555664062
Batch 34/64 loss: -3.165884017944336
Batch 35/64 loss: -3.5184144973754883
Batch 36/64 loss: -3.287334442138672
Batch 37/64 loss: -3.6189322471618652
Batch 38/64 loss: -3.116666793823242
Batch 39/64 loss: -3.417332649230957
Batch 40/64 loss: -2.7617807388305664
Batch 41/64 loss: -3.4330291748046875
Batch 42/64 loss: -3.342371940612793
Batch 43/64 loss: -3.59049654006958
Batch 44/64 loss: -3.0523929595947266
Batch 45/64 loss: -2.768649101257324
Batch 46/64 loss: -3.220871925354004
Batch 47/64 loss: -3.5684127807617188
Batch 48/64 loss: -3.423964500427246
Batch 49/64 loss: -3.3974533081054688
Batch 50/64 loss: -3.4574642181396484
Batch 51/64 loss: -3.241948127746582
Batch 52/64 loss: -3.398061752319336
Batch 53/64 loss: -3.487060546875
Batch 54/64 loss: -3.2041587829589844
Batch 55/64 loss: -3.1289682388305664
Batch 56/64 loss: -3.4968509674072266
Batch 57/64 loss: -3.4186763763427734
Batch 58/64 loss: -3.062366485595703
Batch 59/64 loss: -3.1048107147216797
Batch 60/64 loss: -3.2587718963623047
Batch 61/64 loss: -3.3990049362182617
Batch 62/64 loss: -3.301894187927246
Batch 63/64 loss: -3.364015579223633
Batch 64/64 loss: -8.006864547729492
Epoch 211  Train loss: -3.3714973748898975  Val loss: -3.5267712570137992
Epoch 212
-------------------------------
Batch 1/64 loss: -3.0914173126220703
Batch 2/64 loss: -3.700066089630127
Batch 3/64 loss: -3.4104156494140625
Batch 4/64 loss: -2.8848876953125
Batch 5/64 loss: -2.8773880004882812
Batch 6/64 loss: -3.1348953247070312
Batch 7/64 loss: -3.4734506607055664
Batch 8/64 loss: -3.353764533996582
Batch 9/64 loss: -3.463290214538574
Batch 10/64 loss: -3.2152042388916016
Batch 11/64 loss: -3.2799015045166016
Batch 12/64 loss: -3.097723960876465
Batch 13/64 loss: -3.4485626220703125
Batch 14/64 loss: -3.456820487976074
Batch 15/64 loss: -3.188081741333008
Batch 16/64 loss: -3.1737213134765625
Batch 17/64 loss: -3.289517402648926
Batch 18/64 loss: -3.12351131439209
Batch 19/64 loss: -3.380425453186035
Batch 20/64 loss: -2.9734745025634766
Batch 21/64 loss: -3.2718868255615234
Batch 22/64 loss: -3.260159492492676
Batch 23/64 loss: -3.456223487854004
Batch 24/64 loss: -3.109469413757324
Batch 25/64 loss: -2.8509864807128906
Batch 26/64 loss: -3.5276732444763184
Batch 27/64 loss: -3.418428421020508
Batch 28/64 loss: -2.970022201538086
Batch 29/64 loss: -3.375777244567871
Batch 30/64 loss: -3.4189577102661133
Batch 31/64 loss: -3.321803092956543
Batch 32/64 loss: -3.172178268432617
Batch 33/64 loss: -3.3699798583984375
Batch 34/64 loss: -3.290517807006836
Batch 35/64 loss: -2.7743167877197266
Batch 36/64 loss: -3.377842903137207
Batch 37/64 loss: -3.3926572799682617
Batch 38/64 loss: -3.212794303894043
Batch 39/64 loss: -2.6928110122680664
Batch 40/64 loss: -3.3128786087036133
Batch 41/64 loss: -3.402682304382324
Batch 42/64 loss: -3.2808303833007812
Batch 43/64 loss: -3.420741081237793
Batch 44/64 loss: -3.0302181243896484
Batch 45/64 loss: -3.549633026123047
Batch 46/64 loss: -3.2340831756591797
Batch 47/64 loss: -3.479297637939453
Batch 48/64 loss: -3.375197410583496
Batch 49/64 loss: -3.2475481033325195
Batch 50/64 loss: -3.347105026245117
Batch 51/64 loss: -3.413022994995117
Batch 52/64 loss: -3.611896514892578
Batch 53/64 loss: -2.884685516357422
Batch 54/64 loss: -3.3133974075317383
Batch 55/64 loss: -3.331191062927246
Batch 56/64 loss: -3.550792694091797
Batch 57/64 loss: -3.3166732788085938
Batch 58/64 loss: -3.3288211822509766
Batch 59/64 loss: -3.3810863494873047
Batch 60/64 loss: -3.402311325073242
Batch 61/64 loss: -3.229940414428711
Batch 62/64 loss: -3.4106788635253906
Batch 63/64 loss: -3.469719886779785
Batch 64/64 loss: -8.242490768432617
Epoch 212  Train loss: -3.337840098960727  Val loss: -3.4737690011250604
Epoch 213
-------------------------------
Batch 1/64 loss: -3.558669090270996
Batch 2/64 loss: -3.4018259048461914
Batch 3/64 loss: -3.3038883209228516
Batch 4/64 loss: -3.2784366607666016
Batch 5/64 loss: -3.372757911682129
Batch 6/64 loss: -3.333311080932617
Batch 7/64 loss: -3.370438575744629
Batch 8/64 loss: -3.3348217010498047
Batch 9/64 loss: -3.5126399993896484
Batch 10/64 loss: -3.409238815307617
Batch 11/64 loss: -3.4498910903930664
Batch 12/64 loss: -3.5246334075927734
Batch 13/64 loss: -3.4878177642822266
Batch 14/64 loss: -3.394327163696289
Batch 15/64 loss: -3.3281641006469727
Batch 16/64 loss: -3.4221982955932617
Batch 17/64 loss: -3.5108604431152344
Batch 18/64 loss: -3.5308380126953125
Batch 19/64 loss: -3.4597578048706055
Batch 20/64 loss: -3.03707218170166
Batch 21/64 loss: -3.317233085632324
Batch 22/64 loss: -3.407036781311035
Batch 23/64 loss: -3.355292320251465
Batch 24/64 loss: -3.3961143493652344
Batch 25/64 loss: -3.115931510925293
Batch 26/64 loss: -3.549551010131836
Batch 27/64 loss: -2.8368091583251953
Batch 28/64 loss: -3.4206418991088867
Batch 29/64 loss: -3.284883499145508
Batch 30/64 loss: -3.3870038986206055
Batch 31/64 loss: -3.4720258712768555
Batch 32/64 loss: -3.1556777954101562
Batch 33/64 loss: -3.4038782119750977
Batch 34/64 loss: -3.4531984329223633
Batch 35/64 loss: -3.433377265930176
Batch 36/64 loss: -3.423306465148926
Batch 37/64 loss: -3.5538177490234375
Batch 38/64 loss: -3.6269631385803223
Batch 39/64 loss: -3.120223045349121
Batch 40/64 loss: -3.2567596435546875
Batch 41/64 loss: -3.668501853942871
Batch 42/64 loss: -3.4125585556030273
Batch 43/64 loss: -3.580233573913574
Batch 44/64 loss: -3.6152830123901367
Batch 45/64 loss: -3.576242446899414
Batch 46/64 loss: -3.246443748474121
Batch 47/64 loss: -2.874396324157715
Batch 48/64 loss: -3.4947128295898438
Batch 49/64 loss: -3.0116729736328125
Batch 50/64 loss: -3.237765312194824
Batch 51/64 loss: -3.162782669067383
Batch 52/64 loss: -2.5362749099731445
Batch 53/64 loss: -3.367417335510254
Batch 54/64 loss: -3.23150634765625
Batch 55/64 loss: -3.44228458404541
Batch 56/64 loss: -3.675797462463379
Batch 57/64 loss: -3.390827178955078
Batch 58/64 loss: -3.3209915161132812
Batch 59/64 loss: -2.6668014526367188
Batch 60/64 loss: -2.851144790649414
Batch 61/64 loss: -3.3810949325561523
Batch 62/64 loss: -3.408310890197754
Batch 63/64 loss: -3.368875503540039
Batch 64/64 loss: -7.879779815673828
Epoch 213  Train loss: -3.394871663112266  Val loss: -3.337443007636316
Epoch 214
-------------------------------
Batch 1/64 loss: -3.462728500366211
Batch 2/64 loss: -2.9260406494140625
Batch 3/64 loss: -3.4092750549316406
Batch 4/64 loss: -3.102663993835449
Batch 5/64 loss: -3.3601608276367188
Batch 6/64 loss: -3.6663990020751953
Batch 7/64 loss: -3.236821174621582
Batch 8/64 loss: -3.2667036056518555
Batch 9/64 loss: -3.484858512878418
Batch 10/64 loss: -3.460052490234375
Batch 11/64 loss: -3.216851234436035
Batch 12/64 loss: -3.1980466842651367
Batch 13/64 loss: -3.360506057739258
Batch 14/64 loss: -2.874049186706543
Batch 15/64 loss: -3.485136032104492
Batch 16/64 loss: -3.4916553497314453
Batch 17/64 loss: -3.062776565551758
Batch 18/64 loss: -3.061642646789551
Batch 19/64 loss: -3.114840507507324
Batch 20/64 loss: -3.292269706726074
Batch 21/64 loss: -3.2249765396118164
Batch 22/64 loss: -3.2163171768188477
Batch 23/64 loss: -3.077005386352539
Batch 24/64 loss: -3.390862464904785
Batch 25/64 loss: -3.21779727935791
Batch 26/64 loss: -3.039247512817383
Batch 27/64 loss: -3.2588233947753906
Batch 28/64 loss: -3.349302291870117
Batch 29/64 loss: -3.3059158325195312
Batch 30/64 loss: -3.3410511016845703
Batch 31/64 loss: -3.437668800354004
Batch 32/64 loss: -3.47552490234375
Batch 33/64 loss: -3.2915287017822266
Batch 34/64 loss: -3.380870819091797
Batch 35/64 loss: -3.410907745361328
Batch 36/64 loss: -3.446038246154785
Batch 37/64 loss: -3.36899471282959
Batch 38/64 loss: -3.432558059692383
Batch 39/64 loss: -2.9841537475585938
Batch 40/64 loss: -3.3382644653320312
Batch 41/64 loss: -3.199268341064453
Batch 42/64 loss: -3.5059099197387695
Batch 43/64 loss: -3.4274826049804688
Batch 44/64 loss: -3.3944692611694336
Batch 45/64 loss: -3.244314193725586
Batch 46/64 loss: -3.5330381393432617
Batch 47/64 loss: -3.319601058959961
Batch 48/64 loss: -3.6066017150878906
Batch 49/64 loss: -3.531386375427246
Batch 50/64 loss: -2.623037338256836
Batch 51/64 loss: -3.577277183532715
Batch 52/64 loss: -3.3209829330444336
Batch 53/64 loss: -3.2711315155029297
Batch 54/64 loss: -2.447972297668457
Batch 55/64 loss: -3.095553398132324
Batch 56/64 loss: -2.2391700744628906
Batch 57/64 loss: -3.231964111328125
Batch 58/64 loss: -3.3155412673950195
Batch 59/64 loss: -3.34035587310791
Batch 60/64 loss: -2.8579931259155273
Batch 61/64 loss: -2.063157081604004
Batch 62/64 loss: -3.186142921447754
Batch 63/64 loss: -3.1654481887817383
Batch 64/64 loss: -7.959423542022705
Epoch 214  Train loss: -3.2939396633821376  Val loss: -3.140712724928184
Epoch 215
-------------------------------
Batch 1/64 loss: -3.0994224548339844
Batch 2/64 loss: -2.554976463317871
Batch 3/64 loss: -3.3325510025024414
Batch 4/64 loss: -2.370616912841797
Batch 5/64 loss: -2.9993629455566406
Batch 6/64 loss: -2.7403993606567383
Batch 7/64 loss: -3.2690820693969727
Batch 8/64 loss: -3.254633903503418
Batch 9/64 loss: -3.5627636909484863
Batch 10/64 loss: -3.0388927459716797
Batch 11/64 loss: -3.291177749633789
Batch 12/64 loss: -3.1945228576660156
Batch 13/64 loss: -3.2429723739624023
Batch 14/64 loss: -3.587124824523926
Batch 15/64 loss: -3.5436019897460938
Batch 16/64 loss: -3.1625776290893555
Batch 17/64 loss: -3.3800201416015625
Batch 18/64 loss: -3.456228256225586
Batch 19/64 loss: -3.201298713684082
Batch 20/64 loss: -3.5502538681030273
Batch 21/64 loss: -3.255655288696289
Batch 22/64 loss: -3.160759925842285
Batch 23/64 loss: -3.566925048828125
Batch 24/64 loss: -2.9203872680664062
Batch 25/64 loss: -3.4480762481689453
Batch 26/64 loss: -3.262235641479492
Batch 27/64 loss: -3.10202693939209
Batch 28/64 loss: -3.269911766052246
Batch 29/64 loss: -2.387472152709961
Batch 30/64 loss: -3.531092643737793
Batch 31/64 loss: -3.283365249633789
Batch 32/64 loss: -3.0238704681396484
Batch 33/64 loss: -3.5563411712646484
Batch 34/64 loss: -3.35146427154541
Batch 35/64 loss: -3.249544143676758
Batch 36/64 loss: -2.908599853515625
Batch 37/64 loss: -3.39266300201416
Batch 38/64 loss: -3.3646249771118164
Batch 39/64 loss: -3.364912986755371
Batch 40/64 loss: -3.1323413848876953
Batch 41/64 loss: -3.336939811706543
Batch 42/64 loss: -3.3328609466552734
Batch 43/64 loss: -3.379243850708008
Batch 44/64 loss: -3.249357223510742
Batch 45/64 loss: -3.5471792221069336
Batch 46/64 loss: -3.3564319610595703
Batch 47/64 loss: -3.366823196411133
Batch 48/64 loss: -3.4339332580566406
Batch 49/64 loss: -3.203824043273926
Batch 50/64 loss: -3.1999588012695312
Batch 51/64 loss: -3.376467704772949
Batch 52/64 loss: -3.0003137588500977
Batch 53/64 loss: -3.4645824432373047
Batch 54/64 loss: -3.3910999298095703
Batch 55/64 loss: -3.4543237686157227
Batch 56/64 loss: -3.232717514038086
Batch 57/64 loss: -3.4726524353027344
Batch 58/64 loss: -3.50917911529541
Batch 59/64 loss: -3.4559621810913086
Batch 60/64 loss: -3.299208641052246
Batch 61/64 loss: -3.3457727432250977
Batch 62/64 loss: -3.287412643432617
Batch 63/64 loss: -2.8917770385742188
Batch 64/64 loss: -7.833405017852783
Epoch 215  Train loss: -3.3071031589134066  Val loss: -3.5268522832811495
Epoch 216
-------------------------------
Batch 1/64 loss: -3.2084217071533203
Batch 2/64 loss: -3.131901741027832
Batch 3/64 loss: -3.2848005294799805
Batch 4/64 loss: -2.766429901123047
Batch 5/64 loss: -3.5334291458129883
Batch 6/64 loss: -3.328251838684082
Batch 7/64 loss: -3.50571346282959
Batch 8/64 loss: -3.290827751159668
Batch 9/64 loss: -3.2441530227661133
Batch 10/64 loss: -3.23342227935791
Batch 11/64 loss: -3.30715274810791
Batch 12/64 loss: -3.314289093017578
Batch 13/64 loss: -3.2320871353149414
Batch 14/64 loss: -3.524202346801758
Batch 15/64 loss: -3.4752864837646484
Batch 16/64 loss: -3.7035927772521973
Batch 17/64 loss: -3.218989372253418
Batch 18/64 loss: -3.3788070678710938
Batch 19/64 loss: -3.2191762924194336
Batch 20/64 loss: -3.227023124694824
Batch 21/64 loss: -3.437685012817383
Batch 22/64 loss: -3.5102062225341797
Batch 23/64 loss: -3.1305599212646484
Batch 24/64 loss: -3.3503990173339844
Batch 25/64 loss: -3.4322404861450195
Batch 26/64 loss: -3.0477209091186523
Batch 27/64 loss: -3.1489295959472656
Batch 28/64 loss: -3.3741512298583984
Batch 29/64 loss: -3.6702651977539062
Batch 30/64 loss: -3.3629674911499023
Batch 31/64 loss: -3.4035491943359375
Batch 32/64 loss: -3.2564687728881836
Batch 33/64 loss: -3.5579233169555664
Batch 34/64 loss: -2.741262435913086
Batch 35/64 loss: -3.610919952392578
Batch 36/64 loss: -3.080228805541992
Batch 37/64 loss: -3.431985855102539
Batch 38/64 loss: -3.490452766418457
Batch 39/64 loss: -3.452082633972168
Batch 40/64 loss: -3.373044967651367
Batch 41/64 loss: -3.615354537963867
Batch 42/64 loss: -3.527764320373535
Batch 43/64 loss: -3.394510269165039
Batch 44/64 loss: -3.3486499786376953
Batch 45/64 loss: -3.553114891052246
Batch 46/64 loss: -3.3760461807250977
Batch 47/64 loss: -2.8706579208374023
Batch 48/64 loss: -3.4509029388427734
Batch 49/64 loss: -3.200471878051758
Batch 50/64 loss: -3.512269973754883
Batch 51/64 loss: -3.332301139831543
Batch 52/64 loss: -3.078354835510254
Batch 53/64 loss: -2.5594234466552734
Batch 54/64 loss: -3.3505868911743164
Batch 55/64 loss: -3.032499313354492
Batch 56/64 loss: -2.818023681640625
Batch 57/64 loss: -3.355417251586914
Batch 58/64 loss: -3.2501516342163086
Batch 59/64 loss: -3.0165767669677734
Batch 60/64 loss: -3.31815242767334
Batch 61/64 loss: -2.6332130432128906
Batch 62/64 loss: -2.9830551147460938
Batch 63/64 loss: -3.322490692138672
Batch 64/64 loss: -7.885049343109131
Epoch 216  Train loss: -3.3381141606499165  Val loss: -3.519108093890947
Epoch 217
-------------------------------
Batch 1/64 loss: -2.9933767318725586
Batch 2/64 loss: -3.5289926528930664
Batch 3/64 loss: -3.076871871948242
Batch 4/64 loss: -3.503891944885254
Batch 5/64 loss: -2.5123844146728516
Batch 6/64 loss: -3.108938217163086
Batch 7/64 loss: -3.1630353927612305
Batch 8/64 loss: -2.777094841003418
Batch 9/64 loss: -3.134174346923828
Batch 10/64 loss: -3.304941177368164
Batch 11/64 loss: -3.433267593383789
Batch 12/64 loss: -3.381175994873047
Batch 13/64 loss: -3.3712053298950195
Batch 14/64 loss: -3.4143829345703125
Batch 15/64 loss: -3.07425594329834
Batch 16/64 loss: -3.3219423294067383
Batch 17/64 loss: -3.352508544921875
Batch 18/64 loss: -3.277520179748535
Batch 19/64 loss: -3.05560302734375
Batch 20/64 loss: -3.525120258331299
Batch 21/64 loss: -3.234442710876465
Batch 22/64 loss: -3.267087936401367
Batch 23/64 loss: -2.750271797180176
Batch 24/64 loss: -2.5052366256713867
Batch 25/64 loss: -3.3605737686157227
Batch 26/64 loss: -3.215913772583008
Batch 27/64 loss: -2.8256053924560547
Batch 28/64 loss: -2.6295337677001953
Batch 29/64 loss: -3.3247365951538086
Batch 30/64 loss: -2.4157609939575195
Batch 31/64 loss: -3.412221908569336
Batch 32/64 loss: -3.0039491653442383
Batch 33/64 loss: -3.29290771484375
Batch 34/64 loss: -3.12052059173584
Batch 35/64 loss: -3.139216423034668
Batch 36/64 loss: -2.9786367416381836
Batch 37/64 loss: -2.8286447525024414
Batch 38/64 loss: -3.4440793991088867
Batch 39/64 loss: -3.3052778244018555
Batch 40/64 loss: -3.2906503677368164
Batch 41/64 loss: -3.4692306518554688
Batch 42/64 loss: -3.1542415618896484
Batch 43/64 loss: -3.302427291870117
Batch 44/64 loss: -3.242403030395508
Batch 45/64 loss: -3.431171417236328
Batch 46/64 loss: -3.482297897338867
Batch 47/64 loss: -3.0238447189331055
Batch 48/64 loss: -3.2393980026245117
Batch 49/64 loss: -3.1448097229003906
Batch 50/64 loss: -3.174213409423828
Batch 51/64 loss: -3.090545654296875
Batch 52/64 loss: -3.2239208221435547
Batch 53/64 loss: -3.574336051940918
Batch 54/64 loss: -3.499551773071289
Batch 55/64 loss: -2.9358530044555664
Batch 56/64 loss: -3.1729745864868164
Batch 57/64 loss: -2.9889020919799805
Batch 58/64 loss: -2.8564271926879883
Batch 59/64 loss: -3.2398271560668945
Batch 60/64 loss: -3.000767707824707
Batch 61/64 loss: -3.286839485168457
Batch 62/64 loss: -3.291934013366699
Batch 63/64 loss: -2.935605049133301
Batch 64/64 loss: -7.299990653991699
Epoch 217  Train loss: -3.213999486437031  Val loss: -3.383484397966837
Epoch 218
-------------------------------
Batch 1/64 loss: -3.1003761291503906
Batch 2/64 loss: -3.498774528503418
Batch 3/64 loss: -3.3119821548461914
Batch 4/64 loss: -3.3079967498779297
Batch 5/64 loss: -3.2739477157592773
Batch 6/64 loss: -3.272603988647461
Batch 7/64 loss: -3.3663206100463867
Batch 8/64 loss: -3.4811763763427734
Batch 9/64 loss: -2.827263832092285
Batch 10/64 loss: -3.544919490814209
Batch 11/64 loss: -3.1263484954833984
Batch 12/64 loss: -3.2553443908691406
Batch 13/64 loss: -3.380845069885254
Batch 14/64 loss: -3.070467948913574
Batch 15/64 loss: -2.9254398345947266
Batch 16/64 loss: -3.1114749908447266
Batch 17/64 loss: -3.2351884841918945
Batch 18/64 loss: -3.6218700408935547
Batch 19/64 loss: -3.3733749389648438
Batch 20/64 loss: -3.5245094299316406
Batch 21/64 loss: -3.5443835258483887
Batch 22/64 loss: -3.0584144592285156
Batch 23/64 loss: -3.594968795776367
Batch 24/64 loss: -3.490811347961426
Batch 25/64 loss: -3.131540298461914
Batch 26/64 loss: -3.4053497314453125
Batch 27/64 loss: -3.3224964141845703
Batch 28/64 loss: -3.2415733337402344
Batch 29/64 loss: -2.6411514282226562
Batch 30/64 loss: -2.726655960083008
Batch 31/64 loss: -2.8183250427246094
Batch 32/64 loss: -3.398801803588867
Batch 33/64 loss: -3.2025022506713867
Batch 34/64 loss: -3.3522729873657227
Batch 35/64 loss: -3.3670225143432617
Batch 36/64 loss: -3.494272232055664
Batch 37/64 loss: -3.416762351989746
Batch 38/64 loss: -3.5085878372192383
Batch 39/64 loss: -3.173847198486328
Batch 40/64 loss: -3.2299747467041016
Batch 41/64 loss: -3.2100906372070312
Batch 42/64 loss: -3.2395496368408203
Batch 43/64 loss: -3.216951370239258
Batch 44/64 loss: -3.294121742248535
Batch 45/64 loss: -2.9216766357421875
Batch 46/64 loss: -2.5901975631713867
Batch 47/64 loss: -2.7733497619628906
Batch 48/64 loss: -3.414022445678711
Batch 49/64 loss: -3.249500274658203
Batch 50/64 loss: -2.9176769256591797
Batch 51/64 loss: -3.4649248123168945
Batch 52/64 loss: -3.506688117980957
Batch 53/64 loss: -3.3508834838867188
Batch 54/64 loss: -3.1195335388183594
Batch 55/64 loss: -3.342665672302246
Batch 56/64 loss: -3.3692197799682617
Batch 57/64 loss: -3.3934412002563477
Batch 58/64 loss: -2.679722785949707
Batch 59/64 loss: -3.3494739532470703
Batch 60/64 loss: -3.2667903900146484
Batch 61/64 loss: -3.2797040939331055
Batch 62/64 loss: -3.435173988342285
Batch 63/64 loss: -3.4498109817504883
Batch 64/64 loss: -7.9286017417907715
Epoch 218  Train loss: -3.302142126419965  Val loss: -3.3647602513893364
Epoch 219
-------------------------------
Batch 1/64 loss: -3.550793170928955
Batch 2/64 loss: -3.4422121047973633
Batch 3/64 loss: -2.993762969970703
Batch 4/64 loss: -3.270051956176758
Batch 5/64 loss: -3.521885871887207
Batch 6/64 loss: -3.5922794342041016
Batch 7/64 loss: -3.255059242248535
Batch 8/64 loss: -3.38185977935791
Batch 9/64 loss: -2.594982147216797
Batch 10/64 loss: -3.372014045715332
Batch 11/64 loss: -3.4617929458618164
Batch 12/64 loss: -3.222105026245117
Batch 13/64 loss: -3.4192943572998047
Batch 14/64 loss: -3.653026580810547
Batch 15/64 loss: -3.586230754852295
Batch 16/64 loss: -3.3287439346313477
Batch 17/64 loss: -3.05203914642334
Batch 18/64 loss: -3.4018898010253906
Batch 19/64 loss: -3.46591854095459
Batch 20/64 loss: -3.2701148986816406
Batch 21/64 loss: -3.3976850509643555
Batch 22/64 loss: -3.200078010559082
Batch 23/64 loss: -3.1527299880981445
Batch 24/64 loss: -3.3778820037841797
Batch 25/64 loss: -3.644778251647949
Batch 26/64 loss: -3.517075538635254
Batch 27/64 loss: -3.5252227783203125
Batch 28/64 loss: -3.3664979934692383
Batch 29/64 loss: -3.258869171142578
Batch 30/64 loss: -3.5902161598205566
Batch 31/64 loss: -3.6101632118225098
Batch 32/64 loss: -3.484128952026367
Batch 33/64 loss: -3.042104721069336
Batch 34/64 loss: -3.525509834289551
Batch 35/64 loss: -3.298018455505371
Batch 36/64 loss: -3.219980239868164
Batch 37/64 loss: -3.590552806854248
Batch 38/64 loss: -3.068178176879883
Batch 39/64 loss: -3.076967239379883
Batch 40/64 loss: -3.6122255325317383
Batch 41/64 loss: -3.318819999694824
Batch 42/64 loss: -3.0268449783325195
Batch 43/64 loss: -3.471846580505371
Batch 44/64 loss: -2.8944387435913086
Batch 45/64 loss: -3.363125801086426
Batch 46/64 loss: -3.5445070266723633
Batch 47/64 loss: -3.192845344543457
Batch 48/64 loss: -3.5701842308044434
Batch 49/64 loss: -3.3418636322021484
Batch 50/64 loss: -3.5506906509399414
Batch 51/64 loss: -3.518453598022461
Batch 52/64 loss: -3.4474239349365234
Batch 53/64 loss: -3.2900466918945312
Batch 54/64 loss: -3.351602554321289
Batch 55/64 loss: -3.4412918090820312
Batch 56/64 loss: -3.0770978927612305
Batch 57/64 loss: -3.4639182090759277
Batch 58/64 loss: -3.678194046020508
Batch 59/64 loss: -3.254622459411621
Batch 60/64 loss: -3.559730052947998
Batch 61/64 loss: -3.4882383346557617
Batch 62/64 loss: -3.41049861907959
Batch 63/64 loss: -3.509084701538086
Batch 64/64 loss: -7.291365146636963
Epoch 219  Train loss: -3.413785326714609  Val loss: -3.6636469208497773
Epoch 220
-------------------------------
Batch 1/64 loss: -3.551985740661621
Batch 2/64 loss: -3.4564266204833984
Batch 3/64 loss: -3.5645837783813477
Batch 4/64 loss: -3.364044189453125
Batch 5/64 loss: -3.6762800216674805
Batch 6/64 loss: -3.4300832748413086
Batch 7/64 loss: -3.4086341857910156
Batch 8/64 loss: -3.481032371520996
Batch 9/64 loss: -3.2271652221679688
Batch 10/64 loss: -3.3769750595092773
Batch 11/64 loss: -3.568920135498047
Batch 12/64 loss: -3.5452795028686523
Batch 13/64 loss: -3.480510711669922
Batch 14/64 loss: -3.347386360168457
Batch 15/64 loss: -3.279449462890625
Batch 16/64 loss: -3.4075441360473633
Batch 17/64 loss: -3.0871925354003906
Batch 18/64 loss: -2.818155288696289
Batch 19/64 loss: -3.3478565216064453
Batch 20/64 loss: -3.3378143310546875
Batch 21/64 loss: -3.433612823486328
Batch 22/64 loss: -3.276247978210449
Batch 23/64 loss: -3.6040406227111816
Batch 24/64 loss: -3.2742252349853516
Batch 25/64 loss: -3.553025245666504
Batch 26/64 loss: -3.4701709747314453
Batch 27/64 loss: -3.2857208251953125
Batch 28/64 loss: -3.3265743255615234
Batch 29/64 loss: -3.499980926513672
Batch 30/64 loss: -3.3613080978393555
Batch 31/64 loss: -3.4693689346313477
Batch 32/64 loss: -3.59226131439209
Batch 33/64 loss: -3.540803909301758
Batch 34/64 loss: -3.451411247253418
Batch 35/64 loss: -2.862870216369629
Batch 36/64 loss: -3.620598316192627
Batch 37/64 loss: -3.0704212188720703
Batch 38/64 loss: -3.6323318481445312
Batch 39/64 loss: -3.558924674987793
Batch 40/64 loss: -3.6609621047973633
Batch 41/64 loss: -3.0158729553222656
Batch 42/64 loss: -3.570514678955078
Batch 43/64 loss: -3.7499985694885254
Batch 44/64 loss: -3.591920852661133
Batch 45/64 loss: -3.048874855041504
Batch 46/64 loss: -3.415827751159668
Batch 47/64 loss: -3.4534406661987305
Batch 48/64 loss: -3.5323400497436523
Batch 49/64 loss: -3.326138496398926
Batch 50/64 loss: -3.574584484100342
Batch 51/64 loss: -2.936298370361328
Batch 52/64 loss: -3.2334089279174805
Batch 53/64 loss: -3.241708755493164
Batch 54/64 loss: -3.418333053588867
Batch 55/64 loss: -3.3012866973876953
Batch 56/64 loss: -3.462883949279785
Batch 57/64 loss: -3.3922061920166016
Batch 58/64 loss: -3.499361991882324
Batch 59/64 loss: -3.451045036315918
Batch 60/64 loss: -3.7314982414245605
Batch 61/64 loss: -3.563591957092285
Batch 62/64 loss: -3.548773765563965
Batch 63/64 loss: -3.4977684020996094
Batch 64/64 loss: -8.10328197479248
Epoch 220  Train loss: -3.465683458365646  Val loss: -3.7000986079579774
Saving best model, epoch: 220
Epoch 221
-------------------------------
Batch 1/64 loss: -3.226925849914551
Batch 2/64 loss: -3.411900520324707
Batch 3/64 loss: -3.636859893798828
Batch 4/64 loss: -3.2392807006835938
Batch 5/64 loss: -3.5878958702087402
Batch 6/64 loss: -3.7161922454833984
Batch 7/64 loss: -3.2906885147094727
Batch 8/64 loss: -3.455803871154785
Batch 9/64 loss: -3.400721549987793
Batch 10/64 loss: -3.2092933654785156
Batch 11/64 loss: -3.390401840209961
Batch 12/64 loss: -3.4575424194335938
Batch 13/64 loss: -3.5983099937438965
Batch 14/64 loss: -3.2432174682617188
Batch 15/64 loss: -3.196012496948242
Batch 16/64 loss: -3.522207260131836
Batch 17/64 loss: -3.3713979721069336
Batch 18/64 loss: -3.1400089263916016
Batch 19/64 loss: -2.9288578033447266
Batch 20/64 loss: -3.412755012512207
Batch 21/64 loss: -2.8333168029785156
Batch 22/64 loss: -3.462045669555664
Batch 23/64 loss: -3.5761775970458984
Batch 24/64 loss: -3.296480178833008
Batch 25/64 loss: -3.3792781829833984
Batch 26/64 loss: -3.53835391998291
Batch 27/64 loss: -3.420307159423828
Batch 28/64 loss: -3.300522804260254
Batch 29/64 loss: -3.550523281097412
Batch 30/64 loss: -2.960005760192871
Batch 31/64 loss: -3.3416213989257812
Batch 32/64 loss: -3.4431352615356445
Batch 33/64 loss: -3.6025891304016113
Batch 34/64 loss: -3.6234993934631348
Batch 35/64 loss: -3.2432727813720703
Batch 36/64 loss: -3.590460777282715
Batch 37/64 loss: -3.05690860748291
Batch 38/64 loss: -3.355881690979004
Batch 39/64 loss: -3.5654282569885254
Batch 40/64 loss: -3.365921974182129
Batch 41/64 loss: -3.705207347869873
Batch 42/64 loss: -3.2675466537475586
Batch 43/64 loss: -3.1840505599975586
Batch 44/64 loss: -3.6544346809387207
Batch 45/64 loss: -3.081653594970703
Batch 46/64 loss: -3.1643943786621094
Batch 47/64 loss: -3.5499472618103027
Batch 48/64 loss: -3.4253835678100586
Batch 49/64 loss: -3.42352294921875
Batch 50/64 loss: -3.490475654602051
Batch 51/64 loss: -3.1073904037475586
Batch 52/64 loss: -3.5942530632019043
Batch 53/64 loss: -3.538205623626709
Batch 54/64 loss: -3.515775680541992
Batch 55/64 loss: -3.426280975341797
Batch 56/64 loss: -3.6461429595947266
Batch 57/64 loss: -3.2673091888427734
Batch 58/64 loss: -3.378228187561035
Batch 59/64 loss: -3.1558074951171875
Batch 60/64 loss: -3.55718994140625
Batch 61/64 loss: -3.330036163330078
Batch 62/64 loss: -3.5849266052246094
Batch 63/64 loss: -3.5042295455932617
Batch 64/64 loss: -7.770889759063721
Epoch 221  Train loss: -3.4403539451898313  Val loss: -3.6910898660876086
Epoch 222
-------------------------------
Batch 1/64 loss: -3.578824043273926
Batch 2/64 loss: -3.2952232360839844
Batch 3/64 loss: -3.308070182800293
Batch 4/64 loss: -2.859323501586914
Batch 5/64 loss: -3.481292724609375
Batch 6/64 loss: -3.2841796875
Batch 7/64 loss: -3.4602298736572266
Batch 8/64 loss: -3.2647037506103516
Batch 9/64 loss: -3.190485954284668
Batch 10/64 loss: -3.310793876647949
Batch 11/64 loss: -3.5509114265441895
Batch 12/64 loss: -3.3362035751342773
Batch 13/64 loss: -3.3825082778930664
Batch 14/64 loss: -3.5134925842285156
Batch 15/64 loss: -3.416388511657715
Batch 16/64 loss: -3.5257954597473145
Batch 17/64 loss: -3.691256046295166
Batch 18/64 loss: -3.2934389114379883
Batch 19/64 loss: -3.2436485290527344
Batch 20/64 loss: -3.584834575653076
Batch 21/64 loss: -3.6810011863708496
Batch 22/64 loss: -3.1030139923095703
Batch 23/64 loss: -3.632913589477539
Batch 24/64 loss: -3.7572708129882812
Batch 25/64 loss: -3.246737480163574
Batch 26/64 loss: -3.2745113372802734
Batch 27/64 loss: -3.1783018112182617
Batch 28/64 loss: -3.5848164558410645
Batch 29/64 loss: -3.3184967041015625
Batch 30/64 loss: -2.903545379638672
Batch 31/64 loss: -3.144839286804199
Batch 32/64 loss: -3.5532937049865723
Batch 33/64 loss: -3.165414810180664
Batch 34/64 loss: -3.2877016067504883
Batch 35/64 loss: -3.129837989807129
Batch 36/64 loss: -3.5326528549194336
Batch 37/64 loss: -3.360316276550293
Batch 38/64 loss: -2.990133285522461
Batch 39/64 loss: -2.8091068267822266
Batch 40/64 loss: -3.1449155807495117
Batch 41/64 loss: -3.264328956604004
Batch 42/64 loss: -2.676053047180176
Batch 43/64 loss: -3.127523422241211
Batch 44/64 loss: -3.289224624633789
Batch 45/64 loss: -3.184586524963379
Batch 46/64 loss: -3.1202449798583984
Batch 47/64 loss: -2.9067935943603516
Batch 48/64 loss: -3.1779556274414062
Batch 49/64 loss: -3.3700551986694336
Batch 50/64 loss: -3.0138425827026367
Batch 51/64 loss: -3.2461957931518555
Batch 52/64 loss: -3.6516571044921875
Batch 53/64 loss: -2.9840192794799805
Batch 54/64 loss: -3.6195664405822754
Batch 55/64 loss: -3.3498783111572266
Batch 56/64 loss: -3.575259208679199
Batch 57/64 loss: -3.3434085845947266
Batch 58/64 loss: -3.3132619857788086
Batch 59/64 loss: -3.5262136459350586
Batch 60/64 loss: -3.1455535888671875
Batch 61/64 loss: -2.955598831176758
Batch 62/64 loss: -3.4368581771850586
Batch 63/64 loss: -2.676382064819336
Batch 64/64 loss: -8.195406913757324
Epoch 222  Train loss: -3.348571646447275  Val loss: -3.5303974741512967
Epoch 223
-------------------------------
Batch 1/64 loss: -3.3554153442382812
Batch 2/64 loss: -3.3487377166748047
Batch 3/64 loss: -3.2991809844970703
Batch 4/64 loss: -3.0630197525024414
Batch 5/64 loss: -3.5841760635375977
Batch 6/64 loss: -2.670016288757324
Batch 7/64 loss: -3.692753314971924
Batch 8/64 loss: -3.14687442779541
Batch 9/64 loss: -3.487738609313965
Batch 10/64 loss: -3.113823890686035
Batch 11/64 loss: -3.3030567169189453
Batch 12/64 loss: -3.548518180847168
Batch 13/64 loss: -3.106574058532715
Batch 14/64 loss: -3.3317441940307617
Batch 15/64 loss: -3.431184768676758
Batch 16/64 loss: -3.3307857513427734
Batch 17/64 loss: -3.240220069885254
Batch 18/64 loss: -3.5495223999023438
Batch 19/64 loss: -2.957028388977051
Batch 20/64 loss: -3.5069475173950195
Batch 21/64 loss: -3.22237491607666
Batch 22/64 loss: -3.4110517501831055
Batch 23/64 loss: -3.5108156204223633
Batch 24/64 loss: -3.566236972808838
Batch 25/64 loss: -3.4890851974487305
Batch 26/64 loss: -3.227964401245117
Batch 27/64 loss: -3.4160547256469727
Batch 28/64 loss: -3.0728893280029297
Batch 29/64 loss: -3.53597354888916
Batch 30/64 loss: -3.4528369903564453
Batch 31/64 loss: -3.4202890396118164
Batch 32/64 loss: -3.4439706802368164
Batch 33/64 loss: -3.4824256896972656
Batch 34/64 loss: -3.6459555625915527
Batch 35/64 loss: -3.464940071105957
Batch 36/64 loss: -3.4995546340942383
Batch 37/64 loss: -3.4207983016967773
Batch 38/64 loss: -3.5222649574279785
Batch 39/64 loss: -3.6301703453063965
Batch 40/64 loss: -3.4127655029296875
Batch 41/64 loss: -3.035414695739746
Batch 42/64 loss: -2.7083826065063477
Batch 43/64 loss: -2.863128662109375
Batch 44/64 loss: -3.3897924423217773
Batch 45/64 loss: -3.327406883239746
Batch 46/64 loss: -3.518341064453125
Batch 47/64 loss: -3.195150375366211
Batch 48/64 loss: -3.488422393798828
Batch 49/64 loss: -3.4265613555908203
Batch 50/64 loss: -3.626284599304199
Batch 51/64 loss: -3.6169838905334473
Batch 52/64 loss: -2.953219413757324
Batch 53/64 loss: -3.1336402893066406
Batch 54/64 loss: -3.507017135620117
Batch 55/64 loss: -3.184138298034668
Batch 56/64 loss: -3.439608573913574
Batch 57/64 loss: -3.5273733139038086
Batch 58/64 loss: -3.090869903564453
Batch 59/64 loss: -3.461056709289551
Batch 60/64 loss: -3.5351972579956055
Batch 61/64 loss: -3.2111873626708984
Batch 62/64 loss: -3.5411834716796875
Batch 63/64 loss: -3.1999616622924805
Batch 64/64 loss: -7.348206043243408
Epoch 223  Train loss: -3.394622957940195  Val loss: -3.702718675751047
Saving best model, epoch: 223
Epoch 224
-------------------------------
Batch 1/64 loss: -3.6776742935180664
Batch 2/64 loss: -3.1074037551879883
Batch 3/64 loss: -3.5028457641601562
Batch 4/64 loss: -3.593809127807617
Batch 5/64 loss: -3.545623779296875
Batch 6/64 loss: -3.2785911560058594
Batch 7/64 loss: -3.301804542541504
Batch 8/64 loss: -3.606545925140381
Batch 9/64 loss: -3.2562456130981445
Batch 10/64 loss: -3.5889711380004883
Batch 11/64 loss: -3.5712413787841797
Batch 12/64 loss: -3.663736343383789
Batch 13/64 loss: -2.847532272338867
Batch 14/64 loss: -3.3379039764404297
Batch 15/64 loss: -3.0559377670288086
Batch 16/64 loss: -3.672933578491211
Batch 17/64 loss: -3.2511892318725586
Batch 18/64 loss: -3.6455259323120117
Batch 19/64 loss: -3.710416793823242
Batch 20/64 loss: -3.368043899536133
Batch 21/64 loss: -3.7551169395446777
Batch 22/64 loss: -3.4574317932128906
Batch 23/64 loss: -3.2104053497314453
Batch 24/64 loss: -3.4603872299194336
Batch 25/64 loss: -3.477823257446289
Batch 26/64 loss: -2.730684280395508
Batch 27/64 loss: -3.504488945007324
Batch 28/64 loss: -3.611212730407715
Batch 29/64 loss: -3.1130266189575195
Batch 30/64 loss: -3.763345241546631
Batch 31/64 loss: -3.4515914916992188
Batch 32/64 loss: -3.695958137512207
Batch 33/64 loss: -2.7471237182617188
Batch 34/64 loss: -3.303098678588867
Batch 35/64 loss: -3.630290985107422
Batch 36/64 loss: -3.45223331451416
Batch 37/64 loss: -3.1941051483154297
Batch 38/64 loss: -3.648447036743164
Batch 39/64 loss: -3.3231544494628906
Batch 40/64 loss: -3.365924835205078
Batch 41/64 loss: -3.671663761138916
Batch 42/64 loss: -3.37445068359375
Batch 43/64 loss: -3.7362236976623535
Batch 44/64 loss: -3.626685619354248
Batch 45/64 loss: -3.551185131072998
Batch 46/64 loss: -3.255716323852539
Batch 47/64 loss: -3.710480213165283
Batch 48/64 loss: -3.6297311782836914
Batch 49/64 loss: -3.489720344543457
Batch 50/64 loss: -3.4619884490966797
Batch 51/64 loss: -3.5822577476501465
Batch 52/64 loss: -2.9745969772338867
Batch 53/64 loss: -3.147672653198242
Batch 54/64 loss: -3.4495468139648438
Batch 55/64 loss: -3.3188858032226562
Batch 56/64 loss: -3.657510757446289
Batch 57/64 loss: -3.195995330810547
Batch 58/64 loss: -3.5682053565979004
Batch 59/64 loss: -3.3590660095214844
Batch 60/64 loss: -3.085333824157715
Batch 61/64 loss: -3.4388465881347656
Batch 62/64 loss: -3.4274396896362305
Batch 63/64 loss: -3.738018035888672
Batch 64/64 loss: -7.85149621963501
Epoch 224  Train loss: -3.479524229087082  Val loss: -3.7980821353873027
Saving best model, epoch: 224
Epoch 225
-------------------------------
Batch 1/64 loss: -3.3090896606445312
Batch 2/64 loss: -3.6160502433776855
Batch 3/64 loss: -3.5472145080566406
Batch 4/64 loss: -3.2728872299194336
Batch 5/64 loss: -3.454747200012207
Batch 6/64 loss: -3.4943008422851562
Batch 7/64 loss: -3.469515800476074
Batch 8/64 loss: -3.5663557052612305
Batch 9/64 loss: -3.4728097915649414
Batch 10/64 loss: -3.2063236236572266
Batch 11/64 loss: -3.4929046630859375
Batch 12/64 loss: -3.3977108001708984
Batch 13/64 loss: -3.4023046493530273
Batch 14/64 loss: -3.390019416809082
Batch 15/64 loss: -3.247807502746582
Batch 16/64 loss: -3.4431591033935547
Batch 17/64 loss: -3.6463255882263184
Batch 18/64 loss: -3.4963951110839844
Batch 19/64 loss: -3.5767807960510254
Batch 20/64 loss: -3.4866132736206055
Batch 21/64 loss: -3.5037479400634766
Batch 22/64 loss: -3.531588554382324
Batch 23/64 loss: -3.2882261276245117
Batch 24/64 loss: -3.3242549896240234
Batch 25/64 loss: -3.6063790321350098
Batch 26/64 loss: -3.3079824447631836
Batch 27/64 loss: -3.2756433486938477
Batch 28/64 loss: -2.581003189086914
Batch 29/64 loss: -3.4511194229125977
Batch 30/64 loss: -3.441037178039551
Batch 31/64 loss: -3.608041763305664
Batch 32/64 loss: -3.287337303161621
Batch 33/64 loss: -3.3925037384033203
Batch 34/64 loss: -3.4989404678344727
Batch 35/64 loss: -3.15261173248291
Batch 36/64 loss: -3.547914981842041
Batch 37/64 loss: -3.613351345062256
Batch 38/64 loss: -3.165041923522949
Batch 39/64 loss: -3.7070794105529785
Batch 40/64 loss: -3.355009078979492
Batch 41/64 loss: -3.4007740020751953
Batch 42/64 loss: -3.1063318252563477
Batch 43/64 loss: -3.618831157684326
Batch 44/64 loss: -3.1578807830810547
Batch 45/64 loss: -3.326491355895996
Batch 46/64 loss: -3.711301803588867
Batch 47/64 loss: -2.6053895950317383
Batch 48/64 loss: -3.345661163330078
Batch 49/64 loss: -3.5309858322143555
Batch 50/64 loss: -3.6208696365356445
Batch 51/64 loss: -3.2618494033813477
Batch 52/64 loss: -3.5780692100524902
Batch 53/64 loss: -3.498011589050293
Batch 54/64 loss: -3.454721450805664
Batch 55/64 loss: -3.521678924560547
Batch 56/64 loss: -3.639331817626953
Batch 57/64 loss: -3.556288242340088
Batch 58/64 loss: -3.5448555946350098
Batch 59/64 loss: -3.0159120559692383
Batch 60/64 loss: -3.122509002685547
Batch 61/64 loss: -3.662984848022461
Batch 62/64 loss: -3.241880416870117
Batch 63/64 loss: -3.235745429992676
Batch 64/64 loss: -8.040306091308594
Epoch 225  Train loss: -3.457517085355871  Val loss: -3.7649512930014697
Epoch 226
-------------------------------
Batch 1/64 loss: -3.677370548248291
Batch 2/64 loss: -3.2760324478149414
Batch 3/64 loss: -3.414804458618164
Batch 4/64 loss: -3.552633285522461
Batch 5/64 loss: -3.6149678230285645
Batch 6/64 loss: -3.1126346588134766
Batch 7/64 loss: -3.186285972595215
Batch 8/64 loss: -3.199324607849121
Batch 9/64 loss: -3.5845870971679688
Batch 10/64 loss: -3.471658706665039
Batch 11/64 loss: -3.500581741333008
Batch 12/64 loss: -3.4817323684692383
Batch 13/64 loss: -3.4573583602905273
Batch 14/64 loss: -3.016848564147949
Batch 15/64 loss: -3.506547451019287
Batch 16/64 loss: -3.1527748107910156
Batch 17/64 loss: -3.089559555053711
Batch 18/64 loss: -3.3457822799682617
Batch 19/64 loss: -3.257284164428711
Batch 20/64 loss: -3.118790626525879
Batch 21/64 loss: -3.108107566833496
Batch 22/64 loss: -3.250800132751465
Batch 23/64 loss: -3.4137229919433594
Batch 24/64 loss: -3.219172477722168
Batch 25/64 loss: -3.058797836303711
Batch 26/64 loss: -3.558542251586914
Batch 27/64 loss: -3.5092315673828125
Batch 28/64 loss: -3.555614948272705
Batch 29/64 loss: -3.2578296661376953
Batch 30/64 loss: -3.316277503967285
Batch 31/64 loss: -3.46063232421875
Batch 32/64 loss: -3.40975284576416
Batch 33/64 loss: -3.4495229721069336
Batch 34/64 loss: -3.581650733947754
Batch 35/64 loss: -3.295696258544922
Batch 36/64 loss: -3.394502639770508
Batch 37/64 loss: -3.5217437744140625
Batch 38/64 loss: -3.241558074951172
Batch 39/64 loss: -3.570244789123535
Batch 40/64 loss: -3.215958595275879
Batch 41/64 loss: -3.3679141998291016
Batch 42/64 loss: -3.0689144134521484
Batch 43/64 loss: -3.4241552352905273
Batch 44/64 loss: -3.4781713485717773
Batch 45/64 loss: -3.3333215713500977
Batch 46/64 loss: -3.2010345458984375
Batch 47/64 loss: -3.1463499069213867
Batch 48/64 loss: -3.5558762550354004
Batch 49/64 loss: -3.5244216918945312
Batch 50/64 loss: -3.4244699478149414
Batch 51/64 loss: -3.4361000061035156
Batch 52/64 loss: -3.4871530532836914
Batch 53/64 loss: -3.6626410484313965
Batch 54/64 loss: -3.613480567932129
Batch 55/64 loss: -3.5273866653442383
Batch 56/64 loss: -3.210524559020996
Batch 57/64 loss: -3.713472843170166
Batch 58/64 loss: -3.152867317199707
Batch 59/64 loss: -3.7028112411499023
Batch 60/64 loss: -3.371048927307129
Batch 61/64 loss: -3.4413623809814453
Batch 62/64 loss: -3.4206113815307617
Batch 63/64 loss: -3.442641258239746
Batch 64/64 loss: -7.845957279205322
Epoch 226  Train loss: -3.435264593012193  Val loss: -3.789156097726724
Epoch 227
-------------------------------
Batch 1/64 loss: -3.3036155700683594
Batch 2/64 loss: -3.1469039916992188
Batch 3/64 loss: -3.1395864486694336
Batch 4/64 loss: -3.6197404861450195
Batch 5/64 loss: -3.178696632385254
Batch 6/64 loss: -3.3776206970214844
Batch 7/64 loss: -3.6030492782592773
Batch 8/64 loss: -3.267953872680664
Batch 9/64 loss: -3.419783592224121
Batch 10/64 loss: -3.175779342651367
Batch 11/64 loss: -3.6124038696289062
Batch 12/64 loss: -3.399372100830078
Batch 13/64 loss: -3.5759072303771973
Batch 14/64 loss: -3.36948299407959
Batch 15/64 loss: -3.631747245788574
Batch 16/64 loss: -3.602200984954834
Batch 17/64 loss: -3.647416114807129
Batch 18/64 loss: -3.446291923522949
Batch 19/64 loss: -3.556596279144287
Batch 20/64 loss: -3.5248756408691406
Batch 21/64 loss: -3.4984869956970215
Batch 22/64 loss: -2.7187442779541016
Batch 23/64 loss: -3.1954994201660156
Batch 24/64 loss: -3.4641971588134766
Batch 25/64 loss: -3.0047168731689453
Batch 26/64 loss: -3.588240146636963
Batch 27/64 loss: -3.1408348083496094
Batch 28/64 loss: -3.5076441764831543
Batch 29/64 loss: -3.427980422973633
Batch 30/64 loss: -3.3305788040161133
Batch 31/64 loss: -3.4547653198242188
Batch 32/64 loss: -3.3934688568115234
Batch 33/64 loss: -3.4882688522338867
Batch 34/64 loss: -3.427474021911621
Batch 35/64 loss: -3.438656806945801
Batch 36/64 loss: -3.4314746856689453
Batch 37/64 loss: -3.1275558471679688
Batch 38/64 loss: -3.4166955947875977
Batch 39/64 loss: -3.190816879272461
Batch 40/64 loss: -3.379667282104492
Batch 41/64 loss: -3.5952939987182617
Batch 42/64 loss: -3.554318428039551
Batch 43/64 loss: -3.261138916015625
Batch 44/64 loss: -3.29168701171875
Batch 45/64 loss: -3.5212974548339844
Batch 46/64 loss: -3.528940200805664
Batch 47/64 loss: -3.1100940704345703
Batch 48/64 loss: -3.4075489044189453
Batch 49/64 loss: -3.4399499893188477
Batch 50/64 loss: -3.3898706436157227
Batch 51/64 loss: -3.299941062927246
Batch 52/64 loss: -3.5907435417175293
Batch 53/64 loss: -3.4432077407836914
Batch 54/64 loss: -3.451322555541992
Batch 55/64 loss: -3.491694450378418
Batch 56/64 loss: -3.4313621520996094
Batch 57/64 loss: -3.3267946243286133
Batch 58/64 loss: -3.2437877655029297
Batch 59/64 loss: -3.2613344192504883
Batch 60/64 loss: -3.3677797317504883
Batch 61/64 loss: -3.63950777053833
Batch 62/64 loss: -3.2277050018310547
Batch 63/64 loss: -3.7156505584716797
Batch 64/64 loss: -7.930022716522217
Epoch 227  Train loss: -3.44726713030946  Val loss: -3.7080507966660963
Epoch 228
-------------------------------
Batch 1/64 loss: -3.094217300415039
Batch 2/64 loss: -3.467134475708008
Batch 3/64 loss: -3.4675817489624023
Batch 4/64 loss: -3.39837646484375
Batch 5/64 loss: -3.596414566040039
Batch 6/64 loss: -3.455000877380371
Batch 7/64 loss: -3.6297826766967773
Batch 8/64 loss: -3.332550048828125
Batch 9/64 loss: -3.2640199661254883
Batch 10/64 loss: -3.4408349990844727
Batch 11/64 loss: -3.2810745239257812
Batch 12/64 loss: -3.281381607055664
Batch 13/64 loss: -3.153186798095703
Batch 14/64 loss: -3.537106990814209
Batch 15/64 loss: -3.2478103637695312
Batch 16/64 loss: -3.478057861328125
Batch 17/64 loss: -3.4836854934692383
Batch 18/64 loss: -3.063706398010254
Batch 19/64 loss: -3.613008975982666
Batch 20/64 loss: -3.3205337524414062
Batch 21/64 loss: -3.3312740325927734
Batch 22/64 loss: -3.404721260070801
Batch 23/64 loss: -3.4062604904174805
Batch 24/64 loss: -3.6568422317504883
Batch 25/64 loss: -3.5149755477905273
Batch 26/64 loss: -3.25887393951416
Batch 27/64 loss: -3.2947378158569336
Batch 28/64 loss: -3.6499075889587402
Batch 29/64 loss: -3.3343982696533203
Batch 30/64 loss: -3.45242977142334
Batch 31/64 loss: -3.3496875762939453
Batch 32/64 loss: -3.43160343170166
Batch 33/64 loss: -3.431382179260254
Batch 34/64 loss: -3.1366395950317383
Batch 35/64 loss: -3.42935848236084
Batch 36/64 loss: -3.4510841369628906
Batch 37/64 loss: -3.126959800720215
Batch 38/64 loss: -3.621924877166748
Batch 39/64 loss: -3.511199951171875
Batch 40/64 loss: -3.427109718322754
Batch 41/64 loss: -3.2292070388793945
Batch 42/64 loss: -3.4801902770996094
Batch 43/64 loss: -3.4028749465942383
Batch 44/64 loss: -3.456456184387207
Batch 45/64 loss: -3.242365837097168
Batch 46/64 loss: -3.319988250732422
Batch 47/64 loss: -3.681389808654785
Batch 48/64 loss: -3.3980846405029297
Batch 49/64 loss: -3.420774459838867
Batch 50/64 loss: -3.4637975692749023
Batch 51/64 loss: -3.529214382171631
Batch 52/64 loss: -3.51324462890625
Batch 53/64 loss: -3.260441780090332
Batch 54/64 loss: -3.366654396057129
Batch 55/64 loss: -3.4807310104370117
Batch 56/64 loss: -3.493760108947754
Batch 57/64 loss: -3.657930850982666
Batch 58/64 loss: -3.5939693450927734
Batch 59/64 loss: -3.433635711669922
Batch 60/64 loss: -3.646672248840332
Batch 61/64 loss: -3.3518810272216797
Batch 62/64 loss: -3.217238426208496
Batch 63/64 loss: -3.583980083465576
Batch 64/64 loss: -8.325418472290039
Epoch 228  Train loss: -3.471300132601869  Val loss: -3.8333419852240387
Saving best model, epoch: 228
Epoch 229
-------------------------------
Batch 1/64 loss: -3.3769569396972656
Batch 2/64 loss: -3.565080165863037
Batch 3/64 loss: -3.3580827713012695
Batch 4/64 loss: -3.424222946166992
Batch 5/64 loss: -3.4276771545410156
Batch 6/64 loss: -3.4755821228027344
Batch 7/64 loss: -3.613590717315674
Batch 8/64 loss: -3.022221565246582
Batch 9/64 loss: -3.3318052291870117
Batch 10/64 loss: -3.183945655822754
Batch 11/64 loss: -3.4780168533325195
Batch 12/64 loss: -3.394192695617676
Batch 13/64 loss: -3.5940966606140137
Batch 14/64 loss: -3.571682929992676
Batch 15/64 loss: -3.4429454803466797
Batch 16/64 loss: -3.574978828430176
Batch 17/64 loss: -3.489413261413574
Batch 18/64 loss: -3.542140007019043
Batch 19/64 loss: -3.358942985534668
Batch 20/64 loss: -3.6314845085144043
Batch 21/64 loss: -3.602571964263916
Batch 22/64 loss: -3.475738525390625
Batch 23/64 loss: -3.4530372619628906
Batch 24/64 loss: -3.7932252883911133
Batch 25/64 loss: -3.5450596809387207
Batch 26/64 loss: -3.5868077278137207
Batch 27/64 loss: -3.6882457733154297
Batch 28/64 loss: -3.537970542907715
Batch 29/64 loss: -3.7143640518188477
Batch 30/64 loss: -3.5160837173461914
Batch 31/64 loss: -3.3015031814575195
Batch 32/64 loss: -3.4952077865600586
Batch 33/64 loss: -3.5554656982421875
Batch 34/64 loss: -3.5217857360839844
Batch 35/64 loss: -3.5613789558410645
Batch 36/64 loss: -3.569204807281494
Batch 37/64 loss: -3.676039695739746
Batch 38/64 loss: -3.199979782104492
Batch 39/64 loss: -3.3244094848632812
Batch 40/64 loss: -3.5642104148864746
Batch 41/64 loss: -3.5485973358154297
Batch 42/64 loss: -3.5691323280334473
Batch 43/64 loss: -3.339205741882324
Batch 44/64 loss: -3.6356863975524902
Batch 45/64 loss: -3.421645164489746
Batch 46/64 loss: -3.5555429458618164
Batch 47/64 loss: -3.524970054626465
Batch 48/64 loss: -3.535458564758301
Batch 49/64 loss: -3.233017921447754
Batch 50/64 loss: -3.397096633911133
Batch 51/64 loss: -3.541311264038086
Batch 52/64 loss: -3.479681968688965
Batch 53/64 loss: -3.3408632278442383
Batch 54/64 loss: -3.65395450592041
Batch 55/64 loss: -3.5914125442504883
Batch 56/64 loss: -3.1462554931640625
Batch 57/64 loss: -3.7070326805114746
Batch 58/64 loss: -3.5896477699279785
Batch 59/64 loss: -3.473377227783203
Batch 60/64 loss: -3.395504951477051
Batch 61/64 loss: -3.1730051040649414
Batch 62/64 loss: -3.420370101928711
Batch 63/64 loss: -3.540799140930176
Batch 64/64 loss: -6.785033226013184
Epoch 229  Train loss: -3.520654016382554  Val loss: -3.8190935010352907
Epoch 230
-------------------------------
Batch 1/64 loss: -3.490907669067383
Batch 2/64 loss: -3.560257911682129
Batch 3/64 loss: -3.764894485473633
Batch 4/64 loss: -3.507659912109375
Batch 5/64 loss: -3.4583187103271484
Batch 6/64 loss: -3.5697154998779297
Batch 7/64 loss: -3.5678043365478516
Batch 8/64 loss: -3.550138473510742
Batch 9/64 loss: -3.579543113708496
Batch 10/64 loss: -3.553831100463867
Batch 11/64 loss: -3.7319154739379883
Batch 12/64 loss: -3.601363182067871
Batch 13/64 loss: -3.503737449645996
Batch 14/64 loss: -3.546147346496582
Batch 15/64 loss: -3.4452857971191406
Batch 16/64 loss: -3.3231163024902344
Batch 17/64 loss: -3.399740219116211
Batch 18/64 loss: -3.068160057067871
Batch 19/64 loss: -3.6113228797912598
Batch 20/64 loss: -3.5123682022094727
Batch 21/64 loss: -3.6215548515319824
Batch 22/64 loss: -3.473165512084961
Batch 23/64 loss: -3.333230972290039
Batch 24/64 loss: -3.5273046493530273
Batch 25/64 loss: -3.5185585021972656
Batch 26/64 loss: -2.7141027450561523
Batch 27/64 loss: -3.285747528076172
Batch 28/64 loss: -3.122683525085449
Batch 29/64 loss: -3.5113630294799805
Batch 30/64 loss: -3.327299118041992
Batch 31/64 loss: -3.6035966873168945
Batch 32/64 loss: -3.108592987060547
Batch 33/64 loss: -3.299954414367676
Batch 34/64 loss: -3.492011070251465
Batch 35/64 loss: -2.9971446990966797
Batch 36/64 loss: -3.5688581466674805
Batch 37/64 loss: -3.3111534118652344
Batch 38/64 loss: -3.485849380493164
Batch 39/64 loss: -3.314803123474121
Batch 40/64 loss: -3.4250669479370117
Batch 41/64 loss: -3.0005245208740234
Batch 42/64 loss: -3.574711322784424
Batch 43/64 loss: -3.4288597106933594
Batch 44/64 loss: -3.363300323486328
Batch 45/64 loss: -3.325839042663574
Batch 46/64 loss: -3.4138011932373047
Batch 47/64 loss: -3.4682674407958984
Batch 48/64 loss: -3.0514039993286133
Batch 49/64 loss: -3.6575207710266113
Batch 50/64 loss: -3.2889671325683594
Batch 51/64 loss: -3.677509307861328
Batch 52/64 loss: -3.6025142669677734
Batch 53/64 loss: -3.5064382553100586
Batch 54/64 loss: -3.1977386474609375
Batch 55/64 loss: -3.486051559448242
Batch 56/64 loss: -3.227543830871582
Batch 57/64 loss: -3.1070451736450195
Batch 58/64 loss: -3.3155946731567383
Batch 59/64 loss: -3.2114944458007812
Batch 60/64 loss: -3.178722381591797
Batch 61/64 loss: -3.40966796875
Batch 62/64 loss: -3.5404396057128906
Batch 63/64 loss: -2.9334630966186523
Batch 64/64 loss: -7.582357406616211
Epoch 230  Train loss: -3.451646370981254  Val loss: -3.603251860313809
Epoch 231
-------------------------------
Batch 1/64 loss: -3.2327041625976562
Batch 2/64 loss: -3.548666477203369
Batch 3/64 loss: -3.2315750122070312
Batch 4/64 loss: -3.557844638824463
Batch 5/64 loss: -2.976517677307129
Batch 6/64 loss: -2.907979965209961
Batch 7/64 loss: -2.9011898040771484
Batch 8/64 loss: -3.526278495788574
Batch 9/64 loss: -3.337228775024414
Batch 10/64 loss: -3.3931140899658203
Batch 11/64 loss: -3.5079193115234375
Batch 12/64 loss: -3.2472572326660156
Batch 13/64 loss: -3.2983531951904297
Batch 14/64 loss: -3.4305992126464844
Batch 15/64 loss: -3.2943172454833984
Batch 16/64 loss: -3.231691360473633
Batch 17/64 loss: -2.8424062728881836
Batch 18/64 loss: -3.3439273834228516
Batch 19/64 loss: -3.582822799682617
Batch 20/64 loss: -3.636340618133545
Batch 21/64 loss: -3.685774803161621
Batch 22/64 loss: -3.418015480041504
Batch 23/64 loss: -3.5541582107543945
Batch 24/64 loss: -3.669205665588379
Batch 25/64 loss: -3.418858528137207
Batch 26/64 loss: -3.3902740478515625
Batch 27/64 loss: -3.2837724685668945
Batch 28/64 loss: -3.219120979309082
Batch 29/64 loss: -3.439176559448242
Batch 30/64 loss: -3.280467987060547
Batch 31/64 loss: -3.5899577140808105
Batch 32/64 loss: -3.4787673950195312
Batch 33/64 loss: -2.47867488861084
Batch 34/64 loss: -3.138364791870117
Batch 35/64 loss: -2.8622570037841797
Batch 36/64 loss: -3.1484804153442383
Batch 37/64 loss: -3.34576416015625
Batch 38/64 loss: -3.3053407669067383
Batch 39/64 loss: -3.6059303283691406
Batch 40/64 loss: -2.647191047668457
Batch 41/64 loss: -3.326436996459961
Batch 42/64 loss: -3.2839536666870117
Batch 43/64 loss: -3.230833053588867
Batch 44/64 loss: -2.9024715423583984
Batch 45/64 loss: -3.293649673461914
Batch 46/64 loss: -3.3616695404052734
Batch 47/64 loss: -3.533461093902588
Batch 48/64 loss: -3.304375648498535
Batch 49/64 loss: -3.1727466583251953
Batch 50/64 loss: -3.068089485168457
Batch 51/64 loss: -3.4981465339660645
Batch 52/64 loss: -3.3656835556030273
Batch 53/64 loss: -3.4230480194091797
Batch 54/64 loss: -3.1849498748779297
Batch 55/64 loss: -2.692997932434082
Batch 56/64 loss: -3.4122066497802734
Batch 57/64 loss: -3.533687114715576
Batch 58/64 loss: -3.455416679382324
Batch 59/64 loss: -3.549734115600586
Batch 60/64 loss: -3.6029305458068848
Batch 61/64 loss: -3.3039779663085938
Batch 62/64 loss: -3.296304702758789
Batch 63/64 loss: -3.457333564758301
Batch 64/64 loss: -8.005624771118164
Epoch 231  Train loss: -3.360731139837527  Val loss: -3.6994925823408304
Epoch 232
-------------------------------
Batch 1/64 loss: -3.530050277709961
Batch 2/64 loss: -3.572671413421631
Batch 3/64 loss: -2.894930839538574
Batch 4/64 loss: -3.281984329223633
Batch 5/64 loss: -3.2659616470336914
Batch 6/64 loss: -3.6135334968566895
Batch 7/64 loss: -3.0514068603515625
Batch 8/64 loss: -3.4087533950805664
Batch 9/64 loss: -3.395627021789551
Batch 10/64 loss: -3.095736503601074
Batch 11/64 loss: -3.3736886978149414
Batch 12/64 loss: -3.5451412200927734
Batch 13/64 loss: -3.2043333053588867
Batch 14/64 loss: -3.55619478225708
Batch 15/64 loss: -3.68674898147583
Batch 16/64 loss: -3.2290334701538086
Batch 17/64 loss: -3.5314464569091797
Batch 18/64 loss: -3.496260643005371
Batch 19/64 loss: -3.291327476501465
Batch 20/64 loss: -3.5522823333740234
Batch 21/64 loss: -3.6330795288085938
Batch 22/64 loss: -3.100950241088867
Batch 23/64 loss: -3.1324453353881836
Batch 24/64 loss: -3.569429397583008
Batch 25/64 loss: -3.240161895751953
Batch 26/64 loss: -2.8921937942504883
Batch 27/64 loss: -3.296931266784668
Batch 28/64 loss: -3.2181005477905273
Batch 29/64 loss: -3.239781379699707
Batch 30/64 loss: -3.2257509231567383
Batch 31/64 loss: -3.7164201736450195
Batch 32/64 loss: -3.22676944732666
Batch 33/64 loss: -2.96877384185791
Batch 34/64 loss: -3.5169625282287598
Batch 35/64 loss: -3.2341136932373047
Batch 36/64 loss: -3.2197885513305664
Batch 37/64 loss: -3.500579833984375
Batch 38/64 loss: -3.291659355163574
Batch 39/64 loss: -3.026449203491211
Batch 40/64 loss: -3.504484176635742
Batch 41/64 loss: -2.9349937438964844
Batch 42/64 loss: -3.366400718688965
Batch 43/64 loss: -2.6350526809692383
Batch 44/64 loss: -3.3519763946533203
Batch 45/64 loss: -2.891002655029297
Batch 46/64 loss: -2.9709386825561523
Batch 47/64 loss: -3.6241989135742188
Batch 48/64 loss: -2.7867860794067383
Batch 49/64 loss: -3.283658981323242
Batch 50/64 loss: -3.0804128646850586
Batch 51/64 loss: -3.1864013671875
Batch 52/64 loss: -2.9932289123535156
Batch 53/64 loss: -3.09835147857666
Batch 54/64 loss: -3.2089433670043945
Batch 55/64 loss: -1.8122501373291016
Batch 56/64 loss: -3.1175289154052734
Batch 57/64 loss: -3.0711803436279297
Batch 58/64 loss: -2.776200294494629
Batch 59/64 loss: -3.1948461532592773
Batch 60/64 loss: -3.4460296630859375
Batch 61/64 loss: -3.315871238708496
Batch 62/64 loss: -2.9406471252441406
Batch 63/64 loss: -3.102273941040039
Batch 64/64 loss: -8.078072547912598
Epoch 232  Train loss: -3.2875241934084425  Val loss: -3.5504825893546297
Epoch 233
-------------------------------
Batch 1/64 loss: -3.039745330810547
Batch 2/64 loss: -3.3445510864257812
Batch 3/64 loss: -3.0998153686523438
Batch 4/64 loss: -3.2406435012817383
Batch 5/64 loss: -3.438115119934082
Batch 6/64 loss: -3.5719447135925293
Batch 7/64 loss: -2.7966527938842773
Batch 8/64 loss: -3.5755772590637207
Batch 9/64 loss: -3.102799415588379
Batch 10/64 loss: -3.1904096603393555
Batch 11/64 loss: -3.41855525970459
Batch 12/64 loss: -3.5662412643432617
Batch 13/64 loss: -2.800198554992676
Batch 14/64 loss: -3.548433303833008
Batch 15/64 loss: -3.3870973587036133
Batch 16/64 loss: -3.1301755905151367
Batch 17/64 loss: -3.4022979736328125
Batch 18/64 loss: -3.0533218383789062
Batch 19/64 loss: -3.1240615844726562
Batch 20/64 loss: -3.435605049133301
Batch 21/64 loss: -3.536837577819824
Batch 22/64 loss: -3.0010480880737305
Batch 23/64 loss: -3.23907470703125
Batch 24/64 loss: -3.3480043411254883
Batch 25/64 loss: -3.6348934173583984
Batch 26/64 loss: -3.266948699951172
Batch 27/64 loss: -3.6298136711120605
Batch 28/64 loss: -3.1549434661865234
Batch 29/64 loss: -3.1264724731445312
Batch 30/64 loss: -3.3991518020629883
Batch 31/64 loss: -3.619459629058838
Batch 32/64 loss: -3.463120460510254
Batch 33/64 loss: -3.173532485961914
Batch 34/64 loss: -3.6877055168151855
Batch 35/64 loss: -3.3780746459960938
Batch 36/64 loss: -3.6048097610473633
Batch 37/64 loss: -3.5228800773620605
Batch 38/64 loss: -3.5721211433410645
Batch 39/64 loss: -3.480916976928711
Batch 40/64 loss: -3.770350456237793
Batch 41/64 loss: -3.562817096710205
Batch 42/64 loss: -3.4924745559692383
Batch 43/64 loss: -3.5327959060668945
Batch 44/64 loss: -3.6305980682373047
Batch 45/64 loss: -3.166240692138672
Batch 46/64 loss: -3.4588241577148438
Batch 47/64 loss: -3.386937141418457
Batch 48/64 loss: -3.332357406616211
Batch 49/64 loss: -3.518850326538086
Batch 50/64 loss: -3.421926498413086
Batch 51/64 loss: -3.5899763107299805
Batch 52/64 loss: -3.6868157386779785
Batch 53/64 loss: -3.5640931129455566
Batch 54/64 loss: -3.3349599838256836
Batch 55/64 loss: -2.9855222702026367
Batch 56/64 loss: -3.4927854537963867
Batch 57/64 loss: -2.9344215393066406
Batch 58/64 loss: -3.164318084716797
Batch 59/64 loss: -3.6680283546447754
Batch 60/64 loss: -3.2607421875
Batch 61/64 loss: -3.222506523132324
Batch 62/64 loss: -3.6204662322998047
Batch 63/64 loss: -3.5397181510925293
Batch 64/64 loss: -8.062129974365234
Epoch 233  Train loss: -3.4273125442804075  Val loss: -3.821559630718428
Epoch 234
-------------------------------
Batch 1/64 loss: -3.4557323455810547
Batch 2/64 loss: -3.5803370475769043
Batch 3/64 loss: -3.4566287994384766
Batch 4/64 loss: -3.6152782440185547
Batch 5/64 loss: -3.3147096633911133
Batch 6/64 loss: -3.423391342163086
Batch 7/64 loss: -3.1733388900756836
Batch 8/64 loss: -3.2156105041503906
Batch 9/64 loss: -3.5753016471862793
Batch 10/64 loss: -3.2757740020751953
Batch 11/64 loss: -3.5870985984802246
Batch 12/64 loss: -3.6053624153137207
Batch 13/64 loss: -3.399052619934082
Batch 14/64 loss: -3.4807395935058594
Batch 15/64 loss: -3.4503250122070312
Batch 16/64 loss: -3.328885078430176
Batch 17/64 loss: -3.3767776489257812
Batch 18/64 loss: -3.4702224731445312
Batch 19/64 loss: -3.2139930725097656
Batch 20/64 loss: -3.4466733932495117
Batch 21/64 loss: -3.7010788917541504
Batch 22/64 loss: -3.5216917991638184
Batch 23/64 loss: -2.8577966690063477
Batch 24/64 loss: -3.596132755279541
Batch 25/64 loss: -3.409252166748047
Batch 26/64 loss: -3.368408203125
Batch 27/64 loss: -3.1935338973999023
Batch 28/64 loss: -2.8774709701538086
Batch 29/64 loss: -3.5793919563293457
Batch 30/64 loss: -3.089726448059082
Batch 31/64 loss: -3.5420637130737305
Batch 32/64 loss: -3.5731663703918457
Batch 33/64 loss: -3.7540717124938965
Batch 34/64 loss: -3.558429718017578
Batch 35/64 loss: -3.4492292404174805
Batch 36/64 loss: -3.4858322143554688
Batch 37/64 loss: -3.566131591796875
Batch 38/64 loss: -3.6653237342834473
Batch 39/64 loss: -3.4324636459350586
Batch 40/64 loss: -3.6804323196411133
Batch 41/64 loss: -3.5836048126220703
Batch 42/64 loss: -3.7237772941589355
Batch 43/64 loss: -3.705169200897217
Batch 44/64 loss: -3.580747604370117
Batch 45/64 loss: -3.7069149017333984
Batch 46/64 loss: -3.281416893005371
Batch 47/64 loss: -3.5062808990478516
Batch 48/64 loss: -3.55525541305542
Batch 49/64 loss: -3.5536727905273438
Batch 50/64 loss: -3.415268898010254
Batch 51/64 loss: -2.9425153732299805
Batch 52/64 loss: -3.5993528366088867
Batch 53/64 loss: -3.494015693664551
Batch 54/64 loss: -3.513730049133301
Batch 55/64 loss: -3.499709129333496
Batch 56/64 loss: -3.6277284622192383
Batch 57/64 loss: -2.8625478744506836
Batch 58/64 loss: -3.2561426162719727
Batch 59/64 loss: -3.4132566452026367
Batch 60/64 loss: -3.5555214881896973
Batch 61/64 loss: -3.507842540740967
Batch 62/64 loss: -3.3210344314575195
Batch 63/64 loss: -3.5617032051086426
Batch 64/64 loss: -7.878379821777344
Epoch 234  Train loss: -3.498397714951459  Val loss: -3.7450477495226253
Epoch 235
-------------------------------
Batch 1/64 loss: -3.4087181091308594
Batch 2/64 loss: -2.907459259033203
Batch 3/64 loss: -3.2249507904052734
Batch 4/64 loss: -3.2076053619384766
Batch 5/64 loss: -3.7574377059936523
Batch 6/64 loss: -3.5241546630859375
Batch 7/64 loss: -3.2880754470825195
Batch 8/64 loss: -3.478078842163086
Batch 9/64 loss: -3.584754467010498
Batch 10/64 loss: -3.6274003982543945
Batch 11/64 loss: -2.9849491119384766
Batch 12/64 loss: -3.5457358360290527
Batch 13/64 loss: -3.5043439865112305
Batch 14/64 loss: -3.44268798828125
Batch 15/64 loss: -3.332797050476074
Batch 16/64 loss: -3.085428237915039
Batch 17/64 loss: -3.3760719299316406
Batch 18/64 loss: -3.009662628173828
Batch 19/64 loss: -3.158466339111328
Batch 20/64 loss: -2.879131317138672
Batch 21/64 loss: -2.909327507019043
Batch 22/64 loss: -3.3433027267456055
Batch 23/64 loss: -3.344318389892578
Batch 24/64 loss: -3.367877960205078
Batch 25/64 loss: -3.371026039123535
Batch 26/64 loss: -3.5315213203430176
Batch 27/64 loss: -3.6547389030456543
Batch 28/64 loss: -3.482211112976074
Batch 29/64 loss: -3.5274925231933594
Batch 30/64 loss: -3.233553886413574
Batch 31/64 loss: -3.472482681274414
Batch 32/64 loss: -3.3500213623046875
Batch 33/64 loss: -3.6736674308776855
Batch 34/64 loss: -3.6970138549804688
Batch 35/64 loss: -3.504261016845703
Batch 36/64 loss: -3.3497838973999023
Batch 37/64 loss: -3.1998233795166016
Batch 38/64 loss: -3.599423885345459
Batch 39/64 loss: -3.2148971557617188
Batch 40/64 loss: -3.38791561126709
Batch 41/64 loss: -3.7321667671203613
Batch 42/64 loss: -3.563676357269287
Batch 43/64 loss: -3.5582399368286133
Batch 44/64 loss: -3.433224678039551
Batch 45/64 loss: -3.3821487426757812
Batch 46/64 loss: -3.5489211082458496
Batch 47/64 loss: -3.512765407562256
Batch 48/64 loss: -3.67596435546875
Batch 49/64 loss: -3.5221385955810547
Batch 50/64 loss: -3.5208449363708496
Batch 51/64 loss: -3.51361083984375
Batch 52/64 loss: -3.459305763244629
Batch 53/64 loss: -3.4280014038085938
Batch 54/64 loss: -3.0969696044921875
Batch 55/64 loss: -3.5548906326293945
Batch 56/64 loss: -3.0864105224609375
Batch 57/64 loss: -3.5360541343688965
Batch 58/64 loss: -3.682065963745117
Batch 59/64 loss: -3.547645092010498
Batch 60/64 loss: -3.4338550567626953
Batch 61/64 loss: -3.435192108154297
Batch 62/64 loss: -3.303847312927246
Batch 63/64 loss: -3.0841569900512695
Batch 64/64 loss: -8.472211837768555
Epoch 235  Train loss: -3.458961965523514  Val loss: -3.860296216617335
Saving best model, epoch: 235
Epoch 236
-------------------------------
Batch 1/64 loss: -3.405874252319336
Batch 2/64 loss: -3.4802703857421875
Batch 3/64 loss: -3.4077234268188477
Batch 4/64 loss: -3.5326881408691406
Batch 5/64 loss: -3.4174861907958984
Batch 6/64 loss: -3.691922664642334
Batch 7/64 loss: -3.5040206909179688
Batch 8/64 loss: -3.0122642517089844
Batch 9/64 loss: -3.4415283203125
Batch 10/64 loss: -3.635377883911133
Batch 11/64 loss: -3.3752307891845703
Batch 12/64 loss: -3.7426986694335938
Batch 13/64 loss: -3.5250205993652344
Batch 14/64 loss: -3.3312606811523438
Batch 15/64 loss: -3.664780616760254
Batch 16/64 loss: -3.285325050354004
Batch 17/64 loss: -3.605757236480713
Batch 18/64 loss: -3.4849376678466797
Batch 19/64 loss: -3.191676139831543
Batch 20/64 loss: -3.7094454765319824
Batch 21/64 loss: -3.1306467056274414
Batch 22/64 loss: -3.1433048248291016
Batch 23/64 loss: -3.426565170288086
Batch 24/64 loss: -3.5022411346435547
Batch 25/64 loss: -3.5986571311950684
Batch 26/64 loss: -3.613463878631592
Batch 27/64 loss: -3.4423675537109375
Batch 28/64 loss: -3.6103687286376953
Batch 29/64 loss: -3.405917167663574
Batch 30/64 loss: -3.3844566345214844
Batch 31/64 loss: -3.659731864929199
Batch 32/64 loss: -3.364851951599121
Batch 33/64 loss: -3.280801773071289
Batch 34/64 loss: -3.4669923782348633
Batch 35/64 loss: -3.5417118072509766
Batch 36/64 loss: -3.1703147888183594
Batch 37/64 loss: -3.3567934036254883
Batch 38/64 loss: -3.38582706451416
Batch 39/64 loss: -3.3354530334472656
Batch 40/64 loss: -3.4552431106567383
Batch 41/64 loss: -3.358523368835449
Batch 42/64 loss: -3.1714296340942383
Batch 43/64 loss: -3.4335107803344727
Batch 44/64 loss: -3.5913524627685547
Batch 45/64 loss: -3.4163360595703125
Batch 46/64 loss: -3.747109889984131
Batch 47/64 loss: -3.5286550521850586
Batch 48/64 loss: -3.502420425415039
Batch 49/64 loss: -3.6302247047424316
Batch 50/64 loss: -3.49606990814209
Batch 51/64 loss: -3.5504770278930664
Batch 52/64 loss: -3.3888254165649414
Batch 53/64 loss: -3.4093799591064453
Batch 54/64 loss: -3.5289535522460938
Batch 55/64 loss: -3.5720720291137695
Batch 56/64 loss: -3.2630233764648438
Batch 57/64 loss: -3.717973232269287
Batch 58/64 loss: -3.272991180419922
Batch 59/64 loss: -3.5989036560058594
Batch 60/64 loss: -3.469365119934082
Batch 61/64 loss: -3.5880846977233887
Batch 62/64 loss: -3.490788459777832
Batch 63/64 loss: -3.5099258422851562
Batch 64/64 loss: -8.0628080368042
Epoch 236  Train loss: -3.513796095754586  Val loss: -3.812873001360811
Epoch 237
-------------------------------
Batch 1/64 loss: -3.726337432861328
Batch 2/64 loss: -3.520559310913086
Batch 3/64 loss: -3.4800310134887695
Batch 4/64 loss: -3.4971561431884766
Batch 5/64 loss: -3.310941696166992
Batch 6/64 loss: -3.575930118560791
Batch 7/64 loss: -3.7768020629882812
Batch 8/64 loss: -3.603752613067627
Batch 9/64 loss: -3.7195677757263184
Batch 10/64 loss: -3.5080184936523438
Batch 11/64 loss: -3.333451271057129
Batch 12/64 loss: -3.6522226333618164
Batch 13/64 loss: -3.506732940673828
Batch 14/64 loss: -3.6545519828796387
Batch 15/64 loss: -3.700911045074463
Batch 16/64 loss: -2.8397960662841797
Batch 17/64 loss: -3.4388999938964844
Batch 18/64 loss: -3.661306858062744
Batch 19/64 loss: -3.6353540420532227
Batch 20/64 loss: -3.643096923828125
Batch 21/64 loss: -3.742152690887451
Batch 22/64 loss: -3.549071788787842
Batch 23/64 loss: -3.8024344444274902
Batch 24/64 loss: -3.6162939071655273
Batch 25/64 loss: -3.4737415313720703
Batch 26/64 loss: -3.6452279090881348
Batch 27/64 loss: -3.1672000885009766
Batch 28/64 loss: -3.6852216720581055
Batch 29/64 loss: -3.6366567611694336
Batch 30/64 loss: -3.504453659057617
Batch 31/64 loss: -3.4863243103027344
Batch 32/64 loss: -3.653613567352295
Batch 33/64 loss: -3.4689674377441406
Batch 34/64 loss: -3.6200881004333496
Batch 35/64 loss: -3.4182958602905273
Batch 36/64 loss: -3.790802001953125
Batch 37/64 loss: -3.5833373069763184
Batch 38/64 loss: -3.420477867126465
Batch 39/64 loss: -2.8621606826782227
Batch 40/64 loss: -3.6737141609191895
Batch 41/64 loss: -3.765932083129883
Batch 42/64 loss: -3.4671545028686523
Batch 43/64 loss: -3.2236948013305664
Batch 44/64 loss: -3.4390869140625
Batch 45/64 loss: -3.6886558532714844
Batch 46/64 loss: -3.394455909729004
Batch 47/64 loss: -3.5927224159240723
Batch 48/64 loss: -3.328573226928711
Batch 49/64 loss: -3.201779365539551
Batch 50/64 loss: -3.706973075866699
Batch 51/64 loss: -3.4764232635498047
Batch 52/64 loss: -3.4146251678466797
Batch 53/64 loss: -3.697075366973877
Batch 54/64 loss: -3.3904266357421875
Batch 55/64 loss: -3.141233444213867
Batch 56/64 loss: -3.273221969604492
Batch 57/64 loss: -3.317143440246582
Batch 58/64 loss: -3.518307685852051
Batch 59/64 loss: -3.4657649993896484
Batch 60/64 loss: -3.4249820709228516
Batch 61/64 loss: -3.4989004135131836
Batch 62/64 loss: -3.154958724975586
Batch 63/64 loss: -3.640838146209717
Batch 64/64 loss: -8.063508987426758
Epoch 237  Train loss: -3.5585289001464844  Val loss: -3.8110027116598544
Epoch 238
-------------------------------
Batch 1/64 loss: -3.463820457458496
Batch 2/64 loss: -3.412713050842285
Batch 3/64 loss: -2.976365089416504
Batch 4/64 loss: -3.5680971145629883
Batch 5/64 loss: -3.557583808898926
Batch 6/64 loss: -3.4199705123901367
Batch 7/64 loss: -3.5306620597839355
Batch 8/64 loss: -3.682159423828125
Batch 9/64 loss: -3.4908504486083984
Batch 10/64 loss: -3.187795639038086
Batch 11/64 loss: -3.1803789138793945
Batch 12/64 loss: -3.330622673034668
Batch 13/64 loss: -3.5670838356018066
Batch 14/64 loss: -3.1112356185913086
Batch 15/64 loss: -3.0433435440063477
Batch 16/64 loss: -2.8537235260009766
Batch 17/64 loss: -3.7198281288146973
Batch 18/64 loss: -3.2043800354003906
Batch 19/64 loss: -3.3486461639404297
Batch 20/64 loss: -3.5459203720092773
Batch 21/64 loss: -3.4329538345336914
Batch 22/64 loss: -3.5653786659240723
Batch 23/64 loss: -3.2690935134887695
Batch 24/64 loss: -3.4042654037475586
Batch 25/64 loss: -3.372316360473633
Batch 26/64 loss: -3.518503189086914
Batch 27/64 loss: -3.8117990493774414
Batch 28/64 loss: -3.648266315460205
Batch 29/64 loss: -3.3386077880859375
Batch 30/64 loss: -3.406477928161621
Batch 31/64 loss: -3.7234888076782227
Batch 32/64 loss: -3.4981021881103516
Batch 33/64 loss: -3.311587333679199
Batch 34/64 loss: -3.122004508972168
Batch 35/64 loss: -3.5114994049072266
Batch 36/64 loss: -3.202402114868164
Batch 37/64 loss: -3.4818410873413086
Batch 38/64 loss: -3.625319004058838
Batch 39/64 loss: -3.3458242416381836
Batch 40/64 loss: -3.4303817749023438
Batch 41/64 loss: -3.0165014266967773
Batch 42/64 loss: -3.140530586242676
Batch 43/64 loss: -3.573075294494629
Batch 44/64 loss: -3.481215476989746
Batch 45/64 loss: -3.6229281425476074
Batch 46/64 loss: -3.5419907569885254
Batch 47/64 loss: -3.333202362060547
Batch 48/64 loss: -3.609856128692627
Batch 49/64 loss: -3.63621187210083
Batch 50/64 loss: -3.2232770919799805
Batch 51/64 loss: -3.5871410369873047
Batch 52/64 loss: -3.5069146156311035
Batch 53/64 loss: -3.7205400466918945
Batch 54/64 loss: -3.256134033203125
Batch 55/64 loss: -3.69240665435791
Batch 56/64 loss: -3.453794002532959
Batch 57/64 loss: -3.163210868835449
Batch 58/64 loss: -3.3073129653930664
Batch 59/64 loss: -3.609245777130127
Batch 60/64 loss: -3.557776927947998
Batch 61/64 loss: -3.3384809494018555
Batch 62/64 loss: -3.451035499572754
Batch 63/64 loss: -3.6397757530212402
Batch 64/64 loss: -7.989480018615723
Epoch 238  Train loss: -3.4771758621814204  Val loss: -3.6715395426012805
Epoch 239
-------------------------------
Batch 1/64 loss: -3.3842411041259766
Batch 2/64 loss: -3.4948596954345703
Batch 3/64 loss: -3.4425411224365234
Batch 4/64 loss: -3.2887144088745117
Batch 5/64 loss: -3.426455497741699
Batch 6/64 loss: -3.5481576919555664
Batch 7/64 loss: -3.6117091178894043
Batch 8/64 loss: -3.5272903442382812
Batch 9/64 loss: -3.5469160079956055
Batch 10/64 loss: -3.5256476402282715
Batch 11/64 loss: -3.5573277473449707
Batch 12/64 loss: -3.4679460525512695
Batch 13/64 loss: -3.5322442054748535
Batch 14/64 loss: -3.454648971557617
Batch 15/64 loss: -3.5126123428344727
Batch 16/64 loss: -3.5794835090637207
Batch 17/64 loss: -3.568027973175049
Batch 18/64 loss: -3.5844807624816895
Batch 19/64 loss: -3.0148773193359375
Batch 20/64 loss: -2.6171445846557617
Batch 21/64 loss: -3.4956698417663574
Batch 22/64 loss: -3.6078033447265625
Batch 23/64 loss: -3.7085680961608887
Batch 24/64 loss: -3.5011796951293945
Batch 25/64 loss: -3.4933156967163086
Batch 26/64 loss: -3.241999626159668
Batch 27/64 loss: -3.4375877380371094
Batch 28/64 loss: -3.6259098052978516
Batch 29/64 loss: -3.404104232788086
Batch 30/64 loss: -3.642577648162842
Batch 31/64 loss: -3.6029882431030273
Batch 32/64 loss: -3.467527389526367
Batch 33/64 loss: -3.4656991958618164
Batch 34/64 loss: -3.395465850830078
Batch 35/64 loss: -3.566128730773926
Batch 36/64 loss: -3.4789648056030273
Batch 37/64 loss: -3.7041854858398438
Batch 38/64 loss: -3.665587902069092
Batch 39/64 loss: -3.4175453186035156
Batch 40/64 loss: -3.736269474029541
Batch 41/64 loss: -3.7624216079711914
Batch 42/64 loss: -3.7947826385498047
Batch 43/64 loss: -3.568436622619629
Batch 44/64 loss: -3.63845157623291
Batch 45/64 loss: -3.4268436431884766
Batch 46/64 loss: -3.76959228515625
Batch 47/64 loss: -3.596712589263916
Batch 48/64 loss: -3.638700008392334
Batch 49/64 loss: -3.7338199615478516
Batch 50/64 loss: -3.2377071380615234
Batch 51/64 loss: -3.5688796043395996
Batch 52/64 loss: -3.7370872497558594
Batch 53/64 loss: -2.986104965209961
Batch 54/64 loss: -3.490449905395508
Batch 55/64 loss: -3.4595155715942383
Batch 56/64 loss: -3.6121373176574707
Batch 57/64 loss: -3.6666793823242188
Batch 58/64 loss: -3.643941879272461
Batch 59/64 loss: -3.539290428161621
Batch 60/64 loss: -3.4594621658325195
Batch 61/64 loss: -3.6513571739196777
Batch 62/64 loss: -3.6141347885131836
Batch 63/64 loss: -3.350353240966797
Batch 64/64 loss: -8.218276977539062
Epoch 239  Train loss: -3.5679211560417623  Val loss: -3.865065715566943
Saving best model, epoch: 239
Epoch 240
-------------------------------
Batch 1/64 loss: -2.9935531616210938
Batch 2/64 loss: -3.60268497467041
Batch 3/64 loss: -3.7860875129699707
Batch 4/64 loss: -3.08975887298584
Batch 5/64 loss: -3.520444869995117
Batch 6/64 loss: -3.4500951766967773
Batch 7/64 loss: -3.586771011352539
Batch 8/64 loss: -3.450716018676758
Batch 9/64 loss: -3.3020448684692383
Batch 10/64 loss: -3.2661075592041016
Batch 11/64 loss: -3.4180688858032227
Batch 12/64 loss: -3.735954761505127
Batch 13/64 loss: -3.5609607696533203
Batch 14/64 loss: -3.7135863304138184
Batch 15/64 loss: -3.515138626098633
Batch 16/64 loss: -3.320077896118164
Batch 17/64 loss: -3.506725311279297
Batch 18/64 loss: -3.568296432495117
Batch 19/64 loss: -3.5838003158569336
Batch 20/64 loss: -3.6490488052368164
Batch 21/64 loss: -3.8012070655822754
Batch 22/64 loss: -3.58724308013916
Batch 23/64 loss: -3.472249984741211
Batch 24/64 loss: -3.601675033569336
Batch 25/64 loss: -3.5156326293945312
Batch 26/64 loss: -3.6570630073547363
Batch 27/64 loss: -3.3974685668945312
Batch 28/64 loss: -3.506594657897949
Batch 29/64 loss: -3.270998001098633
Batch 30/64 loss: -3.531266212463379
Batch 31/64 loss: -3.6685667037963867
Batch 32/64 loss: -3.6307144165039062
Batch 33/64 loss: -3.678173065185547
Batch 34/64 loss: -3.4145545959472656
Batch 35/64 loss: -3.5430517196655273
Batch 36/64 loss: -3.4089527130126953
Batch 37/64 loss: -3.2049970626831055
Batch 38/64 loss: -3.395444869995117
Batch 39/64 loss: -3.3187694549560547
Batch 40/64 loss: -3.3603038787841797
Batch 41/64 loss: -3.615029811859131
Batch 42/64 loss: -3.668752670288086
Batch 43/64 loss: -3.6026229858398438
Batch 44/64 loss: -3.4116058349609375
Batch 45/64 loss: -3.6988329887390137
Batch 46/64 loss: -3.5283074378967285
Batch 47/64 loss: -3.222780227661133
Batch 48/64 loss: -3.4815921783447266
Batch 49/64 loss: -3.724091053009033
Batch 50/64 loss: -3.490192413330078
Batch 51/64 loss: -3.5717735290527344
Batch 52/64 loss: -3.674753189086914
Batch 53/64 loss: -3.6336007118225098
Batch 54/64 loss: -3.390772819519043
Batch 55/64 loss: -3.571277141571045
Batch 56/64 loss: -3.8245959281921387
Batch 57/64 loss: -3.488522529602051
Batch 58/64 loss: -3.698702335357666
Batch 59/64 loss: -3.685275077819824
Batch 60/64 loss: -3.073627471923828
Batch 61/64 loss: -3.482463836669922
Batch 62/64 loss: -3.61643123626709
Batch 63/64 loss: -3.7121262550354004
Batch 64/64 loss: -8.216033935546875
Epoch 240  Train loss: -3.5704251607259114  Val loss: -3.85073157766021
Epoch 241
-------------------------------
Batch 1/64 loss: -3.362210273742676
Batch 2/64 loss: -3.645601749420166
Batch 3/64 loss: -3.632835865020752
Batch 4/64 loss: -3.5672616958618164
Batch 5/64 loss: -3.471774101257324
Batch 6/64 loss: -3.6110992431640625
Batch 7/64 loss: -3.377656936645508
Batch 8/64 loss: -3.4754409790039062
Batch 9/64 loss: -3.6501455307006836
Batch 10/64 loss: -3.4494619369506836
Batch 11/64 loss: -3.606362819671631
Batch 12/64 loss: -3.4939050674438477
Batch 13/64 loss: -3.5115346908569336
Batch 14/64 loss: -3.914492130279541
Batch 15/64 loss: -3.6724729537963867
Batch 16/64 loss: -3.4066057205200195
Batch 17/64 loss: -3.39273738861084
Batch 18/64 loss: -3.769580364227295
Batch 19/64 loss: -3.478133201599121
Batch 20/64 loss: -3.6447553634643555
Batch 21/64 loss: -3.5676279067993164
Batch 22/64 loss: -3.535834312438965
Batch 23/64 loss: -3.325023651123047
Batch 24/64 loss: -3.608798027038574
Batch 25/64 loss: -3.554929733276367
Batch 26/64 loss: -3.649655342102051
Batch 27/64 loss: -3.91298246383667
Batch 28/64 loss: -3.615816116333008
Batch 29/64 loss: -3.236598014831543
Batch 30/64 loss: -3.5035438537597656
Batch 31/64 loss: -3.7573232650756836
Batch 32/64 loss: -3.2093305587768555
Batch 33/64 loss: -2.7500104904174805
Batch 34/64 loss: -3.467153549194336
Batch 35/64 loss: -3.7187061309814453
Batch 36/64 loss: -3.691751480102539
Batch 37/64 loss: -3.4913110733032227
Batch 38/64 loss: -3.6439170837402344
Batch 39/64 loss: -3.8164095878601074
Batch 40/64 loss: -3.610401153564453
Batch 41/64 loss: -3.633810043334961
Batch 42/64 loss: -3.6352357864379883
Batch 43/64 loss: -3.303473472595215
Batch 44/64 loss: -3.708916187286377
Batch 45/64 loss: -3.7752866744995117
Batch 46/64 loss: -3.727567195892334
Batch 47/64 loss: -3.5012617111206055
Batch 48/64 loss: -3.4382848739624023
Batch 49/64 loss: -3.760632038116455
Batch 50/64 loss: -3.5196409225463867
Batch 51/64 loss: -3.589601993560791
Batch 52/64 loss: -3.3287038803100586
Batch 53/64 loss: -3.629242420196533
Batch 54/64 loss: -3.6345386505126953
Batch 55/64 loss: -3.59354829788208
Batch 56/64 loss: -3.8120174407958984
Batch 57/64 loss: -3.3327598571777344
Batch 58/64 loss: -3.5570831298828125
Batch 59/64 loss: -3.461909294128418
Batch 60/64 loss: -3.7938098907470703
Batch 61/64 loss: -3.3804073333740234
Batch 62/64 loss: -3.517319679260254
Batch 63/64 loss: -3.745516777038574
Batch 64/64 loss: -8.159202575683594
Epoch 241  Train loss: -3.6125672359092564  Val loss: -3.9894318859192106
Saving best model, epoch: 241
Epoch 242
-------------------------------
Batch 1/64 loss: -3.8451290130615234
Batch 2/64 loss: -3.304671287536621
Batch 3/64 loss: -3.720791816711426
Batch 4/64 loss: -3.5925559997558594
Batch 5/64 loss: -3.7092719078063965
Batch 6/64 loss: -3.5623416900634766
Batch 7/64 loss: -3.7412729263305664
Batch 8/64 loss: -3.632781982421875
Batch 9/64 loss: -3.543238639831543
Batch 10/64 loss: -3.721698760986328
Batch 11/64 loss: -3.2898941040039062
Batch 12/64 loss: -3.4967079162597656
Batch 13/64 loss: -3.71566104888916
Batch 14/64 loss: -3.5908851623535156
Batch 15/64 loss: -3.746588706970215
Batch 16/64 loss: -3.7589292526245117
Batch 17/64 loss: -3.732459545135498
Batch 18/64 loss: -3.348109245300293
Batch 19/64 loss: -3.5472331047058105
Batch 20/64 loss: -3.2961435317993164
Batch 21/64 loss: -3.544985294342041
Batch 22/64 loss: -3.6839704513549805
Batch 23/64 loss: -3.581951141357422
Batch 24/64 loss: -3.694084644317627
Batch 25/64 loss: -3.4789581298828125
Batch 26/64 loss: -3.5971474647521973
Batch 27/64 loss: -2.9522953033447266
Batch 28/64 loss: -3.5030784606933594
Batch 29/64 loss: -3.628814220428467
Batch 30/64 loss: -3.463179588317871
Batch 31/64 loss: -3.6327123641967773
Batch 32/64 loss: -3.2817697525024414
Batch 33/64 loss: -3.4160757064819336
Batch 34/64 loss: -3.7153573036193848
Batch 35/64 loss: -3.491379737854004
Batch 36/64 loss: -3.4251832962036133
Batch 37/64 loss: -3.5226221084594727
Batch 38/64 loss: -3.1957740783691406
Batch 39/64 loss: -3.5181198120117188
Batch 40/64 loss: -3.5118513107299805
Batch 41/64 loss: -3.7261900901794434
Batch 42/64 loss: -3.5436086654663086
Batch 43/64 loss: -3.6928305625915527
Batch 44/64 loss: -3.2513484954833984
Batch 45/64 loss: -3.669466495513916
Batch 46/64 loss: -3.7336459159851074
Batch 47/64 loss: -3.7060232162475586
Batch 48/64 loss: -3.686556339263916
Batch 49/64 loss: -3.5524978637695312
Batch 50/64 loss: -3.611514091491699
Batch 51/64 loss: -3.6180315017700195
Batch 52/64 loss: -3.567474365234375
Batch 53/64 loss: -3.5905776023864746
Batch 54/64 loss: -3.191286087036133
Batch 55/64 loss: -3.327784538269043
Batch 56/64 loss: -3.2250165939331055
Batch 57/64 loss: -3.337268829345703
Batch 58/64 loss: -3.143829345703125
Batch 59/64 loss: -3.209054946899414
Batch 60/64 loss: -3.6842613220214844
Batch 61/64 loss: -3.773033618927002
Batch 62/64 loss: -3.701063632965088
Batch 63/64 loss: -3.5598597526550293
Batch 64/64 loss: -8.2415771484375
Epoch 242  Train loss: -3.592456196803673  Val loss: -3.702876808717079
Epoch 243
-------------------------------
Batch 1/64 loss: -3.48367977142334
Batch 2/64 loss: -3.709782600402832
Batch 3/64 loss: -3.5566511154174805
Batch 4/64 loss: -3.634317398071289
Batch 5/64 loss: -3.4189462661743164
Batch 6/64 loss: -3.447751998901367
Batch 7/64 loss: -3.5490074157714844
Batch 8/64 loss: -3.747602939605713
Batch 9/64 loss: -3.3560495376586914
Batch 10/64 loss: -3.616213798522949
Batch 11/64 loss: -3.4098405838012695
Batch 12/64 loss: -3.317007064819336
Batch 13/64 loss: -3.534895896911621
Batch 14/64 loss: -3.291219711303711
Batch 15/64 loss: -3.6671581268310547
Batch 16/64 loss: -3.460132598876953
Batch 17/64 loss: -3.454500198364258
Batch 18/64 loss: -3.3870849609375
Batch 19/64 loss: -3.6685566902160645
Batch 20/64 loss: -3.394968032836914
Batch 21/64 loss: -3.670152187347412
Batch 22/64 loss: -3.503873825073242
Batch 23/64 loss: -3.399813652038574
Batch 24/64 loss: -3.618521213531494
Batch 25/64 loss: -3.257965087890625
Batch 26/64 loss: -3.5788254737854004
Batch 27/64 loss: -3.375913619995117
Batch 28/64 loss: -3.6965761184692383
Batch 29/64 loss: -3.596580982208252
Batch 30/64 loss: -3.539659023284912
Batch 31/64 loss: -3.524256706237793
Batch 32/64 loss: -3.774378776550293
Batch 33/64 loss: -3.293804168701172
Batch 34/64 loss: -3.6439924240112305
Batch 35/64 loss: -3.8146538734436035
Batch 36/64 loss: -3.6087493896484375
Batch 37/64 loss: -3.6199541091918945
Batch 38/64 loss: -3.4619693756103516
Batch 39/64 loss: -3.4507408142089844
Batch 40/64 loss: -3.526535987854004
Batch 41/64 loss: -3.42464542388916
Batch 42/64 loss: -3.441042900085449
Batch 43/64 loss: -3.4866886138916016
Batch 44/64 loss: -3.2279319763183594
Batch 45/64 loss: -3.466085433959961
Batch 46/64 loss: -3.554370403289795
Batch 47/64 loss: -3.557840347290039
Batch 48/64 loss: -3.54034423828125
Batch 49/64 loss: -3.770568370819092
Batch 50/64 loss: -3.5208892822265625
Batch 51/64 loss: -3.5922107696533203
Batch 52/64 loss: -3.768160820007324
Batch 53/64 loss: -3.255575180053711
Batch 54/64 loss: -3.7163777351379395
Batch 55/64 loss: -3.582808017730713
Batch 56/64 loss: -3.4029836654663086
Batch 57/64 loss: -3.3630971908569336
Batch 58/64 loss: -3.3472137451171875
Batch 59/64 loss: -3.039562225341797
Batch 60/64 loss: -3.6269054412841797
Batch 61/64 loss: -3.455167770385742
Batch 62/64 loss: -3.7816739082336426
Batch 63/64 loss: -3.6978507041931152
Batch 64/64 loss: -8.197370529174805
Epoch 243  Train loss: -3.5738087149227367  Val loss: -3.9376524436924467
Epoch 244
-------------------------------
Batch 1/64 loss: -3.7450509071350098
Batch 2/64 loss: -3.4327192306518555
Batch 3/64 loss: -3.5122108459472656
Batch 4/64 loss: -3.3436689376831055
Batch 5/64 loss: -3.5959129333496094
Batch 6/64 loss: -3.5654497146606445
Batch 7/64 loss: -3.195087432861328
Batch 8/64 loss: -3.4226884841918945
Batch 9/64 loss: -3.268195152282715
Batch 10/64 loss: -3.0098705291748047
Batch 11/64 loss: -3.6670403480529785
Batch 12/64 loss: -3.68324613571167
Batch 13/64 loss: -3.3712081909179688
Batch 14/64 loss: -3.67364501953125
Batch 15/64 loss: -3.600728988647461
Batch 16/64 loss: -3.3541765213012695
Batch 17/64 loss: -3.6965627670288086
Batch 18/64 loss: -3.657029628753662
Batch 19/64 loss: -3.540358066558838
Batch 20/64 loss: -3.4299182891845703
Batch 21/64 loss: -3.4934282302856445
Batch 22/64 loss: -3.5116653442382812
Batch 23/64 loss: -3.654630661010742
Batch 24/64 loss: -3.6100072860717773
Batch 25/64 loss: -3.3454513549804688
Batch 26/64 loss: -3.4460220336914062
Batch 27/64 loss: -2.7602853775024414
Batch 28/64 loss: -3.4724645614624023
Batch 29/64 loss: -3.845571517944336
Batch 30/64 loss: -3.2169132232666016
Batch 31/64 loss: -3.6732354164123535
Batch 32/64 loss: -3.4827308654785156
Batch 33/64 loss: -3.4579334259033203
Batch 34/64 loss: -3.5264406204223633
Batch 35/64 loss: -3.5595436096191406
Batch 36/64 loss: -3.540036201477051
Batch 37/64 loss: -3.4550819396972656
Batch 38/64 loss: -3.587311267852783
Batch 39/64 loss: -3.526064872741699
Batch 40/64 loss: -3.724668025970459
Batch 41/64 loss: -3.8021645545959473
Batch 42/64 loss: -3.5960302352905273
Batch 43/64 loss: -3.8004612922668457
Batch 44/64 loss: -3.6844992637634277
Batch 45/64 loss: -3.4760026931762695
Batch 46/64 loss: -3.5860276222229004
Batch 47/64 loss: -3.603105068206787
Batch 48/64 loss: -3.3951005935668945
Batch 49/64 loss: -3.4097585678100586
Batch 50/64 loss: -3.8228273391723633
Batch 51/64 loss: -3.852046489715576
Batch 52/64 loss: -3.598306655883789
Batch 53/64 loss: -3.6452713012695312
Batch 54/64 loss: -3.7237415313720703
Batch 55/64 loss: -3.5460357666015625
Batch 56/64 loss: -3.6223950386047363
Batch 57/64 loss: -3.6316165924072266
Batch 58/64 loss: -3.741591453552246
Batch 59/64 loss: -3.6129860877990723
Batch 60/64 loss: -3.511490821838379
Batch 61/64 loss: -3.597869396209717
Batch 62/64 loss: -3.610307216644287
Batch 63/64 loss: -3.6219143867492676
Batch 64/64 loss: -8.242351531982422
Epoch 244  Train loss: -3.597295177684111  Val loss: -3.9613621243086876
Epoch 245
-------------------------------
Batch 1/64 loss: -3.6548500061035156
Batch 2/64 loss: -3.7131552696228027
Batch 3/64 loss: -3.2954702377319336
Batch 4/64 loss: -3.5795016288757324
Batch 5/64 loss: -3.6101274490356445
Batch 6/64 loss: -3.616786003112793
Batch 7/64 loss: -3.683994770050049
Batch 8/64 loss: -3.495253562927246
Batch 9/64 loss: -3.5440587997436523
Batch 10/64 loss: -3.4386816024780273
Batch 11/64 loss: -3.3947763442993164
Batch 12/64 loss: -3.220736503601074
Batch 13/64 loss: -3.5690994262695312
Batch 14/64 loss: -3.451230049133301
Batch 15/64 loss: -3.3026123046875
Batch 16/64 loss: -3.7821578979492188
Batch 17/64 loss: -3.7781763076782227
Batch 18/64 loss: -3.4315290451049805
Batch 19/64 loss: -3.5876684188842773
Batch 20/64 loss: -3.413991928100586
Batch 21/64 loss: -3.451190948486328
Batch 22/64 loss: -3.3992576599121094
Batch 23/64 loss: -3.6832528114318848
Batch 24/64 loss: -3.627124309539795
Batch 25/64 loss: -3.216032028198242
Batch 26/64 loss: -3.7272701263427734
Batch 27/64 loss: -3.5771918296813965
Batch 28/64 loss: -3.706784725189209
Batch 29/64 loss: -3.3155555725097656
Batch 30/64 loss: -3.4946022033691406
Batch 31/64 loss: -3.4822568893432617
Batch 32/64 loss: -3.7595605850219727
Batch 33/64 loss: -3.583962917327881
Batch 34/64 loss: -3.621094226837158
Batch 35/64 loss: -3.6385397911071777
Batch 36/64 loss: -3.5674705505371094
Batch 37/64 loss: -3.614377975463867
Batch 38/64 loss: -3.7017860412597656
Batch 39/64 loss: -3.587007999420166
Batch 40/64 loss: -3.5254688262939453
Batch 41/64 loss: -3.4290246963500977
Batch 42/64 loss: -3.0751914978027344
Batch 43/64 loss: -3.4820995330810547
Batch 44/64 loss: -3.6397924423217773
Batch 45/64 loss: -3.4522600173950195
Batch 46/64 loss: -3.355654716491699
Batch 47/64 loss: -3.5342187881469727
Batch 48/64 loss: -3.7538390159606934
Batch 49/64 loss: -3.7608094215393066
Batch 50/64 loss: -3.8271965980529785
Batch 51/64 loss: -3.1047439575195312
Batch 52/64 loss: -3.4976768493652344
Batch 53/64 loss: -3.555037498474121
Batch 54/64 loss: -3.525303840637207
Batch 55/64 loss: -3.31735897064209
Batch 56/64 loss: -3.555478096008301
Batch 57/64 loss: -3.3158817291259766
Batch 58/64 loss: -3.7546300888061523
Batch 59/64 loss: -3.186105728149414
Batch 60/64 loss: -3.7747864723205566
Batch 61/64 loss: -3.7353525161743164
Batch 62/64 loss: -3.556840419769287
Batch 63/64 loss: -3.4861011505126953
Batch 64/64 loss: -8.180246353149414
Epoch 245  Train loss: -3.5867327746223  Val loss: -3.8882285180370424
Epoch 246
-------------------------------
Batch 1/64 loss: -3.263779640197754
Batch 2/64 loss: -3.475283622741699
Batch 3/64 loss: -3.4397449493408203
Batch 4/64 loss: -3.4449100494384766
Batch 5/64 loss: -3.3099918365478516
Batch 6/64 loss: -3.4544572830200195
Batch 7/64 loss: -3.4962615966796875
Batch 8/64 loss: -3.6005091667175293
Batch 9/64 loss: -3.7034029960632324
Batch 10/64 loss: -3.5881853103637695
Batch 11/64 loss: -2.966000556945801
Batch 12/64 loss: -3.6463680267333984
Batch 13/64 loss: -3.162260055541992
Batch 14/64 loss: -3.5115156173706055
Batch 15/64 loss: -3.101572036743164
Batch 16/64 loss: -3.5038089752197266
Batch 17/64 loss: -3.2905826568603516
Batch 18/64 loss: -3.6622748374938965
Batch 19/64 loss: -3.3519678115844727
Batch 20/64 loss: -3.420294761657715
Batch 21/64 loss: -3.535323143005371
Batch 22/64 loss: -3.430813789367676
Batch 23/64 loss: -3.701478958129883
Batch 24/64 loss: -3.2459259033203125
Batch 25/64 loss: -3.239990234375
Batch 26/64 loss: -3.407299041748047
Batch 27/64 loss: -3.4785003662109375
Batch 28/64 loss: -3.6340904235839844
Batch 29/64 loss: -3.184358596801758
Batch 30/64 loss: -3.283196449279785
Batch 31/64 loss: -3.7268619537353516
Batch 32/64 loss: -3.7608261108398438
Batch 33/64 loss: -3.6209988594055176
Batch 34/64 loss: -3.8742337226867676
Batch 35/64 loss: -3.5879931449890137
Batch 36/64 loss: -3.428110122680664
Batch 37/64 loss: -3.3244380950927734
Batch 38/64 loss: -3.713897228240967
Batch 39/64 loss: -3.4368057250976562
Batch 40/64 loss: -3.4264955520629883
Batch 41/64 loss: -3.6907448768615723
Batch 42/64 loss: -3.5954575538635254
Batch 43/64 loss: -3.455310821533203
Batch 44/64 loss: -3.559330940246582
Batch 45/64 loss: -3.3869266510009766
Batch 46/64 loss: -3.4591732025146484
Batch 47/64 loss: -3.7057886123657227
Batch 48/64 loss: -3.573094367980957
Batch 49/64 loss: -3.4112672805786133
Batch 50/64 loss: -3.7014970779418945
Batch 51/64 loss: -3.065945625305176
Batch 52/64 loss: -3.2967071533203125
Batch 53/64 loss: -3.305387496948242
Batch 54/64 loss: -3.5985655784606934
Batch 55/64 loss: -2.7627267837524414
Batch 56/64 loss: -3.6130266189575195
Batch 57/64 loss: -3.760619640350342
Batch 58/64 loss: -3.382078170776367
Batch 59/64 loss: -3.7436656951904297
Batch 60/64 loss: -3.681581497192383
Batch 61/64 loss: -3.5744643211364746
Batch 62/64 loss: -3.6500377655029297
Batch 63/64 loss: -3.639878749847412
Batch 64/64 loss: -8.345499038696289
Epoch 246  Train loss: -3.534230744604971  Val loss: -3.809611264782673
Epoch 247
-------------------------------
Batch 1/64 loss: -3.664414405822754
Batch 2/64 loss: -3.645186424255371
Batch 3/64 loss: -3.8292136192321777
Batch 4/64 loss: -3.4692373275756836
Batch 5/64 loss: -3.3768558502197266
Batch 6/64 loss: -3.1510162353515625
Batch 7/64 loss: -3.3512401580810547
Batch 8/64 loss: -3.5683884620666504
Batch 9/64 loss: -3.5400009155273438
Batch 10/64 loss: -3.6130833625793457
Batch 11/64 loss: -3.3809452056884766
Batch 12/64 loss: -3.7040047645568848
Batch 13/64 loss: -3.130526542663574
Batch 14/64 loss: -3.5768680572509766
Batch 15/64 loss: -3.3311052322387695
Batch 16/64 loss: -3.5278825759887695
Batch 17/64 loss: -3.628376007080078
Batch 18/64 loss: -3.700922966003418
Batch 19/64 loss: -3.6955666542053223
Batch 20/64 loss: -3.6144280433654785
Batch 21/64 loss: -3.3875350952148438
Batch 22/64 loss: -3.5234084129333496
Batch 23/64 loss: -3.7927517890930176
Batch 24/64 loss: -3.6506190299987793
Batch 25/64 loss: -3.701916217803955
Batch 26/64 loss: -3.5936241149902344
Batch 27/64 loss: -3.6772918701171875
Batch 28/64 loss: -3.610238552093506
Batch 29/64 loss: -3.6719131469726562
Batch 30/64 loss: -3.5583338737487793
Batch 31/64 loss: -3.229733467102051
Batch 32/64 loss: -3.617396831512451
Batch 33/64 loss: -3.3675918579101562
Batch 34/64 loss: -3.6943039894104004
Batch 35/64 loss: -3.6438803672790527
Batch 36/64 loss: -3.520841598510742
Batch 37/64 loss: -3.3506879806518555
Batch 38/64 loss: -3.6193604469299316
Batch 39/64 loss: -3.603036403656006
Batch 40/64 loss: -3.3815507888793945
Batch 41/64 loss: -3.5177106857299805
Batch 42/64 loss: -3.669046401977539
Batch 43/64 loss: -3.482429027557373
Batch 44/64 loss: -3.5025696754455566
Batch 45/64 loss: -3.5395960807800293
Batch 46/64 loss: -3.5783839225769043
Batch 47/64 loss: -3.5044751167297363
Batch 48/64 loss: -3.71146297454834
Batch 49/64 loss: -3.6318211555480957
Batch 50/64 loss: -3.614961624145508
Batch 51/64 loss: -3.5631918907165527
Batch 52/64 loss: -3.692091464996338
Batch 53/64 loss: -3.685720920562744
Batch 54/64 loss: -3.5109710693359375
Batch 55/64 loss: -3.487041473388672
Batch 56/64 loss: -3.6026434898376465
Batch 57/64 loss: -3.1612815856933594
Batch 58/64 loss: -3.578395366668701
Batch 59/64 loss: -3.583693027496338
Batch 60/64 loss: -3.414149284362793
Batch 61/64 loss: -3.7406258583068848
Batch 62/64 loss: -3.550502300262451
Batch 63/64 loss: -3.650413990020752
Batch 64/64 loss: -8.04146957397461
Epoch 247  Train loss: -3.603130340576172  Val loss: -3.9660853487519465
Epoch 248
-------------------------------
Batch 1/64 loss: -3.6326088905334473
Batch 2/64 loss: -3.7194976806640625
Batch 3/64 loss: -3.5242419242858887
Batch 4/64 loss: -3.6614084243774414
Batch 5/64 loss: -3.6562819480895996
Batch 6/64 loss: -3.698357582092285
Batch 7/64 loss: -3.7753024101257324
Batch 8/64 loss: -3.5826401710510254
Batch 9/64 loss: -3.672698974609375
Batch 10/64 loss: -3.659097671508789
Batch 11/64 loss: -3.3863019943237305
Batch 12/64 loss: -3.49853515625
Batch 13/64 loss: -3.5786385536193848
Batch 14/64 loss: -3.6752352714538574
Batch 15/64 loss: -3.519944190979004
Batch 16/64 loss: -3.7411155700683594
Batch 17/64 loss: -3.5286221504211426
Batch 18/64 loss: -3.204684257507324
Batch 19/64 loss: -3.5702362060546875
Batch 20/64 loss: -3.6652441024780273
Batch 21/64 loss: -3.7634100914001465
Batch 22/64 loss: -3.7614264488220215
Batch 23/64 loss: -3.3993072509765625
Batch 24/64 loss: -3.5695133209228516
Batch 25/64 loss: -3.700246810913086
Batch 26/64 loss: -3.4557409286499023
Batch 27/64 loss: -3.9028968811035156
Batch 28/64 loss: -3.721827983856201
Batch 29/64 loss: -3.7205939292907715
Batch 30/64 loss: -3.689070701599121
Batch 31/64 loss: -3.80631685256958
Batch 32/64 loss: -3.7295751571655273
Batch 33/64 loss: -3.799304962158203
Batch 34/64 loss: -3.635620594024658
Batch 35/64 loss: -3.5670061111450195
Batch 36/64 loss: -3.631291389465332
Batch 37/64 loss: -2.9215593338012695
Batch 38/64 loss: -3.533496379852295
Batch 39/64 loss: -3.4791460037231445
Batch 40/64 loss: -3.4195261001586914
Batch 41/64 loss: -3.825343608856201
Batch 42/64 loss: -3.673680305480957
Batch 43/64 loss: -3.6745924949645996
Batch 44/64 loss: -3.6907567977905273
Batch 45/64 loss: -3.3841896057128906
Batch 46/64 loss: -3.598264217376709
Batch 47/64 loss: -3.593204975128174
Batch 48/64 loss: -3.794621467590332
Batch 49/64 loss: -3.676206588745117
Batch 50/64 loss: -3.538057804107666
Batch 51/64 loss: -3.731583595275879
Batch 52/64 loss: -3.4167490005493164
Batch 53/64 loss: -3.52105712890625
Batch 54/64 loss: -3.7311816215515137
Batch 55/64 loss: -3.7853989601135254
Batch 56/64 loss: -3.652000904083252
Batch 57/64 loss: -3.747901439666748
Batch 58/64 loss: -3.699659824371338
Batch 59/64 loss: -3.497457504272461
Batch 60/64 loss: -3.477725028991699
Batch 61/64 loss: -3.379213333129883
Batch 62/64 loss: -3.704458713531494
Batch 63/64 loss: -3.3210182189941406
Batch 64/64 loss: -7.884298324584961
Epoch 248  Train loss: -3.6578057607014975  Val loss: -3.9817962646484375
Epoch 249
-------------------------------
Batch 1/64 loss: -3.681638240814209
Batch 2/64 loss: -3.3669376373291016
Batch 3/64 loss: -3.7344818115234375
Batch 4/64 loss: -3.649458408355713
Batch 5/64 loss: -3.6302175521850586
Batch 6/64 loss: -3.770599842071533
Batch 7/64 loss: -3.5247044563293457
Batch 8/64 loss: -3.4899978637695312
Batch 9/64 loss: -3.611225128173828
Batch 10/64 loss: -3.7180843353271484
Batch 11/64 loss: -3.4215574264526367
Batch 12/64 loss: -3.600062370300293
Batch 13/64 loss: -3.6690497398376465
Batch 14/64 loss: -3.5053939819335938
Batch 15/64 loss: -3.8165931701660156
Batch 16/64 loss: -3.6182093620300293
Batch 17/64 loss: -3.2466955184936523
Batch 18/64 loss: -3.3726730346679688
Batch 19/64 loss: -3.6430821418762207
Batch 20/64 loss: -3.4222021102905273
Batch 21/64 loss: -2.840883255004883
Batch 22/64 loss: -3.302943229675293
Batch 23/64 loss: -3.610872745513916
Batch 24/64 loss: -3.6567206382751465
Batch 25/64 loss: -3.741507053375244
Batch 26/64 loss: -3.637869358062744
Batch 27/64 loss: -3.7207913398742676
Batch 28/64 loss: -3.6801538467407227
Batch 29/64 loss: -3.466005325317383
Batch 30/64 loss: -3.775906562805176
Batch 31/64 loss: -3.6430630683898926
Batch 32/64 loss: -3.422377586364746
Batch 33/64 loss: -3.7047581672668457
Batch 34/64 loss: -3.577439785003662
Batch 35/64 loss: -3.7790889739990234
Batch 36/64 loss: -3.640254020690918
Batch 37/64 loss: -3.694620132446289
Batch 38/64 loss: -3.6807003021240234
Batch 39/64 loss: -3.309865951538086
Batch 40/64 loss: -3.518308639526367
Batch 41/64 loss: -3.54150390625
Batch 42/64 loss: -3.597231388092041
Batch 43/64 loss: -3.673029899597168
Batch 44/64 loss: -3.493929386138916
Batch 45/64 loss: -3.6117706298828125
Batch 46/64 loss: -3.602480888366699
Batch 47/64 loss: -3.3569583892822266
Batch 48/64 loss: -3.7132034301757812
Batch 49/64 loss: -3.6832056045532227
Batch 50/64 loss: -3.71162748336792
Batch 51/64 loss: -3.637857437133789
Batch 52/64 loss: -3.657297134399414
Batch 53/64 loss: -3.4774417877197266
Batch 54/64 loss: -3.3304548263549805
Batch 55/64 loss: -3.5277042388916016
Batch 56/64 loss: -3.5239477157592773
Batch 57/64 loss: -3.4599075317382812
Batch 58/64 loss: -3.755697250366211
Batch 59/64 loss: -3.440009593963623
Batch 60/64 loss: -3.7113208770751953
Batch 61/64 loss: -3.28472900390625
Batch 62/64 loss: -3.4349584579467773
Batch 63/64 loss: -3.353984832763672
Batch 64/64 loss: -8.18525505065918
Epoch 249  Train loss: -3.6175088171865424  Val loss: -3.8732820360111617
Epoch 250
-------------------------------
Batch 1/64 loss: -3.5744032859802246
Batch 2/64 loss: -3.505682945251465
Batch 3/64 loss: -3.6795663833618164
Batch 4/64 loss: -3.8736071586608887
Batch 5/64 loss: -3.1670570373535156
Batch 6/64 loss: -3.220400810241699
Batch 7/64 loss: -3.3867597579956055
Batch 8/64 loss: -3.10504150390625
Batch 9/64 loss: -3.5279951095581055
Batch 10/64 loss: -3.6079983711242676
Batch 11/64 loss: -3.451136589050293
Batch 12/64 loss: -3.5923728942871094
Batch 13/64 loss: -3.5672426223754883
Batch 14/64 loss: -3.481337547302246
Batch 15/64 loss: -3.431138038635254
Batch 16/64 loss: -3.4490890502929688
Batch 17/64 loss: -3.5357561111450195
Batch 18/64 loss: -3.368284225463867
Batch 19/64 loss: -3.4030303955078125
Batch 20/64 loss: -3.5524210929870605
Batch 21/64 loss: -3.4075613021850586
Batch 22/64 loss: -3.685490608215332
Batch 23/64 loss: -3.4827346801757812
Batch 24/64 loss: -3.5978856086730957
Batch 25/64 loss: -3.574554443359375
Batch 26/64 loss: -3.6604537963867188
Batch 27/64 loss: -3.5196456909179688
Batch 28/64 loss: -3.6384997367858887
Batch 29/64 loss: -3.706501007080078
Batch 30/64 loss: -3.6399550437927246
Batch 31/64 loss: -3.6450090408325195
Batch 32/64 loss: -3.4740991592407227
Batch 33/64 loss: -3.1819868087768555
Batch 34/64 loss: -3.518770217895508
Batch 35/64 loss: -3.5331621170043945
Batch 36/64 loss: -3.4410762786865234
Batch 37/64 loss: -3.275946617126465
Batch 38/64 loss: -3.5928759574890137
Batch 39/64 loss: -3.5561304092407227
Batch 40/64 loss: -2.839430809020996
Batch 41/64 loss: -3.726949691772461
Batch 42/64 loss: -3.671417713165283
Batch 43/64 loss: -3.213179588317871
Batch 44/64 loss: -3.4434118270874023
Batch 45/64 loss: -3.157700538635254
Batch 46/64 loss: -3.6850762367248535
Batch 47/64 loss: -3.117776870727539
Batch 48/64 loss: -3.373149871826172
Batch 49/64 loss: -3.3402252197265625
Batch 50/64 loss: -3.3713865280151367
Batch 51/64 loss: -3.361300468444824
Batch 52/64 loss: -3.540114402770996
Batch 53/64 loss: -3.5032434463500977
Batch 54/64 loss: -3.4996838569641113
Batch 55/64 loss: -3.059192657470703
Batch 56/64 loss: -3.4933834075927734
Batch 57/64 loss: -3.084031105041504
Batch 58/64 loss: -3.34940242767334
Batch 59/64 loss: -3.2496566772460938
Batch 60/64 loss: -3.6890296936035156
Batch 61/64 loss: -3.4578051567077637
Batch 62/64 loss: -3.466257095336914
Batch 63/64 loss: -3.7395386695861816
Batch 64/64 loss: -7.69774866104126
Epoch 250  Train loss: -3.5108755279989805  Val loss: -3.655871505999483
Epoch 251
-------------------------------
Batch 1/64 loss: -3.6082377433776855
Batch 2/64 loss: -3.4510793685913086
Batch 3/64 loss: -3.2100353240966797
Batch 4/64 loss: -3.593562126159668
Batch 5/64 loss: -3.6316428184509277
Batch 6/64 loss: -2.924102783203125
Batch 7/64 loss: -3.479832649230957
Batch 8/64 loss: -3.1754140853881836
Batch 9/64 loss: -3.3969478607177734
Batch 10/64 loss: -3.6391587257385254
Batch 11/64 loss: -3.700817584991455
Batch 12/64 loss: -3.3916969299316406
Batch 13/64 loss: -3.4130859375
Batch 14/64 loss: -3.2028751373291016
Batch 15/64 loss: -3.671621322631836
Batch 16/64 loss: -3.590268611907959
Batch 17/64 loss: -3.4647216796875
Batch 18/64 loss: -3.6172561645507812
Batch 19/64 loss: -3.771261692047119
Batch 20/64 loss: -3.495809555053711
Batch 21/64 loss: -3.2790346145629883
Batch 22/64 loss: -3.5365161895751953
Batch 23/64 loss: -3.525644302368164
Batch 24/64 loss: -3.6666975021362305
Batch 25/64 loss: -3.3205795288085938
Batch 26/64 loss: -3.7036099433898926
Batch 27/64 loss: -3.388150215148926
Batch 28/64 loss: -3.6212100982666016
Batch 29/64 loss: -3.568490505218506
Batch 30/64 loss: -3.6331658363342285
Batch 31/64 loss: -3.4655418395996094
Batch 32/64 loss: -3.6674628257751465
Batch 33/64 loss: -3.5028133392333984
Batch 34/64 loss: -3.8282179832458496
Batch 35/64 loss: -3.530820369720459
Batch 36/64 loss: -3.710875988006592
Batch 37/64 loss: -3.8105058670043945
Batch 38/64 loss: -3.604130268096924
Batch 39/64 loss: -3.0977258682250977
Batch 40/64 loss: -3.657052993774414
Batch 41/64 loss: -3.326831817626953
Batch 42/64 loss: -3.7336134910583496
Batch 43/64 loss: -3.467921257019043
Batch 44/64 loss: -3.1861066818237305
Batch 45/64 loss: -3.2522525787353516
Batch 46/64 loss: -3.449615478515625
Batch 47/64 loss: -3.455259323120117
Batch 48/64 loss: -3.5877532958984375
Batch 49/64 loss: -3.3951473236083984
Batch 50/64 loss: -3.5254693031311035
Batch 51/64 loss: -3.425039291381836
Batch 52/64 loss: -3.6521105766296387
Batch 53/64 loss: -3.5722241401672363
Batch 54/64 loss: -3.536548614501953
Batch 55/64 loss: -3.6830267906188965
Batch 56/64 loss: -3.4039993286132812
Batch 57/64 loss: -3.622311592102051
Batch 58/64 loss: -3.4418678283691406
Batch 59/64 loss: -3.540947437286377
Batch 60/64 loss: -3.503897190093994
Batch 61/64 loss: -2.9874839782714844
Batch 62/64 loss: -3.6135525703430176
Batch 63/64 loss: -3.3707799911499023
Batch 64/64 loss: -8.172863006591797
Epoch 251  Train loss: -3.5515463735543045  Val loss: -3.9288266893104997
Epoch 252
-------------------------------
Batch 1/64 loss: -3.4691543579101562
Batch 2/64 loss: -3.572720527648926
Batch 3/64 loss: -3.6265196800231934
Batch 4/64 loss: -3.573406219482422
Batch 5/64 loss: -3.6470961570739746
Batch 6/64 loss: -3.807952404022217
Batch 7/64 loss: -3.6534037590026855
Batch 8/64 loss: -3.6045970916748047
Batch 9/64 loss: -3.4587182998657227
Batch 10/64 loss: -3.605109214782715
Batch 11/64 loss: -3.52530574798584
Batch 12/64 loss: -3.501683235168457
Batch 13/64 loss: -3.767618179321289
Batch 14/64 loss: -3.5317697525024414
Batch 15/64 loss: -3.401453971862793
Batch 16/64 loss: -3.7235465049743652
Batch 17/64 loss: -3.803926467895508
Batch 18/64 loss: -3.3183040618896484
Batch 19/64 loss: -3.476241111755371
Batch 20/64 loss: -3.56076717376709
Batch 21/64 loss: -3.7022271156311035
Batch 22/64 loss: -3.5051746368408203
Batch 23/64 loss: -3.5885300636291504
Batch 24/64 loss: -3.644446849822998
Batch 25/64 loss: -3.7550840377807617
Batch 26/64 loss: -3.6474318504333496
Batch 27/64 loss: -3.165961265563965
Batch 28/64 loss: -3.7297840118408203
Batch 29/64 loss: -3.709597110748291
Batch 30/64 loss: -3.6842150688171387
Batch 31/64 loss: -3.3098058700561523
Batch 32/64 loss: -3.4227724075317383
Batch 33/64 loss: -3.7144932746887207
Batch 34/64 loss: -3.231053352355957
Batch 35/64 loss: -3.6371259689331055
Batch 36/64 loss: -3.5133256912231445
Batch 37/64 loss: -3.633826732635498
Batch 38/64 loss: -3.585693359375
Batch 39/64 loss: -3.3489627838134766
Batch 40/64 loss: -3.6156182289123535
Batch 41/64 loss: -3.2100086212158203
Batch 42/64 loss: -3.665574073791504
Batch 43/64 loss: -3.7006921768188477
Batch 44/64 loss: -3.6590776443481445
Batch 45/64 loss: -3.450860023498535
Batch 46/64 loss: -3.6883139610290527
Batch 47/64 loss: -3.6524763107299805
Batch 48/64 loss: -3.425708770751953
Batch 49/64 loss: -3.87863826751709
Batch 50/64 loss: -3.7506136894226074
Batch 51/64 loss: -3.461277961730957
Batch 52/64 loss: -3.5079822540283203
Batch 53/64 loss: -3.694181442260742
Batch 54/64 loss: -3.6539902687072754
Batch 55/64 loss: -3.4917373657226562
Batch 56/64 loss: -3.4877185821533203
Batch 57/64 loss: -3.4735498428344727
Batch 58/64 loss: -3.7875137329101562
Batch 59/64 loss: -3.651618480682373
Batch 60/64 loss: -3.844599723815918
Batch 61/64 loss: -3.81718111038208
Batch 62/64 loss: -3.3502607345581055
Batch 63/64 loss: -3.5130529403686523
Batch 64/64 loss: -8.389240264892578
Epoch 252  Train loss: -3.637380106308881  Val loss: -3.971690135313473
Epoch 253
-------------------------------
Batch 1/64 loss: -3.2324047088623047
Batch 2/64 loss: -3.986793041229248
Batch 3/64 loss: -3.56772518157959
Batch 4/64 loss: -3.585857391357422
Batch 5/64 loss: -3.6597652435302734
Batch 6/64 loss: -3.1025543212890625
Batch 7/64 loss: -3.878262996673584
Batch 8/64 loss: -3.6148672103881836
Batch 9/64 loss: -3.6873788833618164
Batch 10/64 loss: -3.436894416809082
Batch 11/64 loss: -3.4382495880126953
Batch 12/64 loss: -3.481795310974121
Batch 13/64 loss: -3.3008737564086914
Batch 14/64 loss: -3.2310914993286133
Batch 15/64 loss: -3.405167579650879
Batch 16/64 loss: -3.6835618019104004
Batch 17/64 loss: -3.313234329223633
Batch 18/64 loss: -3.5737571716308594
Batch 19/64 loss: -3.664337158203125
Batch 20/64 loss: -3.4308547973632812
Batch 21/64 loss: -3.5006189346313477
Batch 22/64 loss: -3.5951008796691895
Batch 23/64 loss: -3.6692471504211426
Batch 24/64 loss: -3.593973159790039
Batch 25/64 loss: -3.3937559127807617
Batch 26/64 loss: -3.4999818801879883
Batch 27/64 loss: -3.7173357009887695
Batch 28/64 loss: -3.4409122467041016
Batch 29/64 loss: -3.7118401527404785
Batch 30/64 loss: -3.631092071533203
Batch 31/64 loss: -3.5846195220947266
Batch 32/64 loss: -3.6348700523376465
Batch 33/64 loss: -3.6554818153381348
Batch 34/64 loss: -3.8719310760498047
Batch 35/64 loss: -3.8432393074035645
Batch 36/64 loss: -3.549478054046631
Batch 37/64 loss: -3.4818830490112305
Batch 38/64 loss: -3.6220717430114746
Batch 39/64 loss: -3.6173152923583984
Batch 40/64 loss: -3.433074951171875
Batch 41/64 loss: -3.4802560806274414
Batch 42/64 loss: -3.6402435302734375
Batch 43/64 loss: -3.613887310028076
Batch 44/64 loss: -3.3752870559692383
Batch 45/64 loss: -3.5992136001586914
Batch 46/64 loss: -3.22955322265625
Batch 47/64 loss: -3.551070213317871
Batch 48/64 loss: -3.281980514526367
Batch 49/64 loss: -3.5019540786743164
Batch 50/64 loss: -3.6606760025024414
Batch 51/64 loss: -3.29196834564209
Batch 52/64 loss: -3.2382259368896484
Batch 53/64 loss: -3.4915666580200195
Batch 54/64 loss: -3.77731990814209
Batch 55/64 loss: -3.3270816802978516
Batch 56/64 loss: -3.359713554382324
Batch 57/64 loss: -3.551316261291504
Batch 58/64 loss: -3.3254337310791016
Batch 59/64 loss: -3.4846296310424805
Batch 60/64 loss: -3.5719995498657227
Batch 61/64 loss: -3.419679641723633
Batch 62/64 loss: -3.202747344970703
Batch 63/64 loss: -3.605574131011963
Batch 64/64 loss: -8.374794006347656
Epoch 253  Train loss: -3.579383887496649  Val loss: -3.593248295210481
Epoch 254
-------------------------------
Batch 1/64 loss: -3.632859230041504
Batch 2/64 loss: -3.347346305847168
Batch 3/64 loss: -3.6004366874694824
Batch 4/64 loss: -3.3242530822753906
Batch 5/64 loss: -3.3194198608398438
Batch 6/64 loss: -3.320492744445801
Batch 7/64 loss: -3.710689067840576
Batch 8/64 loss: -3.4649457931518555
Batch 9/64 loss: -3.2615489959716797
Batch 10/64 loss: -3.56010103225708
Batch 11/64 loss: -3.479564666748047
Batch 12/64 loss: -3.141350746154785
Batch 13/64 loss: -3.340762138366699
Batch 14/64 loss: -3.3395605087280273
Batch 15/64 loss: -3.5628795623779297
Batch 16/64 loss: -3.315155029296875
Batch 17/64 loss: -3.406174659729004
Batch 18/64 loss: -3.4818553924560547
Batch 19/64 loss: -2.06856632232666
Batch 20/64 loss: -3.174528121948242
Batch 21/64 loss: -3.620108127593994
Batch 22/64 loss: -3.5785908699035645
Batch 23/64 loss: -3.360079765319824
Batch 24/64 loss: -3.2375564575195312
Batch 25/64 loss: -3.560302734375
Batch 26/64 loss: -2.637584686279297
Batch 27/64 loss: -3.4670848846435547
Batch 28/64 loss: -3.4741010665893555
Batch 29/64 loss: -3.563457489013672
Batch 30/64 loss: -3.2092580795288086
Batch 31/64 loss: -3.4199981689453125
Batch 32/64 loss: -3.0726842880249023
Batch 33/64 loss: -3.4135818481445312
Batch 34/64 loss: -3.343775749206543
Batch 35/64 loss: -3.227977752685547
Batch 36/64 loss: -3.1899261474609375
Batch 37/64 loss: -3.1356124877929688
Batch 38/64 loss: -3.2396936416625977
Batch 39/64 loss: -3.0235300064086914
Batch 40/64 loss: -3.21547794342041
Batch 41/64 loss: -3.0862321853637695
Batch 42/64 loss: -2.953871726989746
Batch 43/64 loss: -2.703597068786621
Batch 44/64 loss: -3.5328617095947266
Batch 45/64 loss: -3.4267749786376953
Batch 46/64 loss: -2.9427738189697266
Batch 47/64 loss: -3.2487220764160156
Batch 48/64 loss: -2.7035818099975586
Batch 49/64 loss: -3.544391632080078
Batch 50/64 loss: -3.1943817138671875
Batch 51/64 loss: -3.4110336303710938
Batch 52/64 loss: -3.190591812133789
Batch 53/64 loss: -3.5362777709960938
Batch 54/64 loss: -3.248514175415039
Batch 55/64 loss: -3.555447578430176
Batch 56/64 loss: -3.4191980361938477
Batch 57/64 loss: -3.439753532409668
Batch 58/64 loss: -3.564913272857666
Batch 59/64 loss: -3.471503257751465
Batch 60/64 loss: -3.6264381408691406
Batch 61/64 loss: -3.02120304107666
Batch 62/64 loss: -3.357786178588867
Batch 63/64 loss: -3.3027210235595703
Batch 64/64 loss: -8.313955307006836
Epoch 254  Train loss: -3.365661314422009  Val loss: -3.536935917700279
Epoch 255
-------------------------------
Batch 1/64 loss: -2.376850128173828
Batch 2/64 loss: -3.2197484970092773
Batch 3/64 loss: -2.988337516784668
Batch 4/64 loss: -3.344564437866211
Batch 5/64 loss: -3.2193307876586914
Batch 6/64 loss: -3.451669692993164
Batch 7/64 loss: -3.638371467590332
Batch 8/64 loss: -3.5178585052490234
Batch 9/64 loss: -3.473996162414551
Batch 10/64 loss: -3.241199493408203
Batch 11/64 loss: -3.318948745727539
Batch 12/64 loss: -3.551666259765625
Batch 13/64 loss: -3.334840774536133
Batch 14/64 loss: -3.355666160583496
Batch 15/64 loss: -3.0589513778686523
Batch 16/64 loss: -3.410673141479492
Batch 17/64 loss: -3.4825868606567383
Batch 18/64 loss: -3.2477455139160156
Batch 19/64 loss: -3.428995132446289
Batch 20/64 loss: -3.4301137924194336
Batch 21/64 loss: -3.3782548904418945
Batch 22/64 loss: -3.3971080780029297
Batch 23/64 loss: -3.4916539192199707
Batch 24/64 loss: -3.233160972595215
Batch 25/64 loss: -3.525271415710449
Batch 26/64 loss: -3.516697883605957
Batch 27/64 loss: -3.5310306549072266
Batch 28/64 loss: -3.327127456665039
Batch 29/64 loss: -3.6447691917419434
Batch 30/64 loss: -3.547149658203125
Batch 31/64 loss: -3.351806640625
Batch 32/64 loss: -3.4830150604248047
Batch 33/64 loss: -3.549504280090332
Batch 34/64 loss: -3.5123443603515625
Batch 35/64 loss: -3.401515007019043
Batch 36/64 loss: -3.15557861328125
Batch 37/64 loss: -3.377741813659668
Batch 38/64 loss: -3.3746156692504883
Batch 39/64 loss: -3.53940486907959
Batch 40/64 loss: -3.4164371490478516
Batch 41/64 loss: -3.6318564414978027
Batch 42/64 loss: -3.7635860443115234
Batch 43/64 loss: -3.7139687538146973
Batch 44/64 loss: -3.6423416137695312
Batch 45/64 loss: -3.497258186340332
Batch 46/64 loss: -3.462162971496582
Batch 47/64 loss: -3.4542617797851562
Batch 48/64 loss: -3.7268056869506836
Batch 49/64 loss: -3.4940929412841797
Batch 50/64 loss: -3.7135000228881836
Batch 51/64 loss: -3.8035964965820312
Batch 52/64 loss: -3.139927864074707
Batch 53/64 loss: -3.2352676391601562
Batch 54/64 loss: -3.7474637031555176
Batch 55/64 loss: -3.4405136108398438
Batch 56/64 loss: -3.5063953399658203
Batch 57/64 loss: -3.4895858764648438
Batch 58/64 loss: -3.4116601943969727
Batch 59/64 loss: -3.6026129722595215
Batch 60/64 loss: -3.2666711807250977
Batch 61/64 loss: -3.309107780456543
Batch 62/64 loss: -3.618309497833252
Batch 63/64 loss: -3.2230300903320312
Batch 64/64 loss: -8.270784378051758
Epoch 255  Train loss: -3.4814645804610906  Val loss: -3.760074536824964
Epoch 256
-------------------------------
Batch 1/64 loss: -3.5291576385498047
Batch 2/64 loss: -3.4366350173950195
Batch 3/64 loss: -3.386362075805664
Batch 4/64 loss: -3.394454002380371
Batch 5/64 loss: -3.466798782348633
Batch 6/64 loss: -3.4471168518066406
Batch 7/64 loss: -3.4100255966186523
Batch 8/64 loss: -3.232560157775879
Batch 9/64 loss: -3.547701835632324
Batch 10/64 loss: -3.506442070007324
Batch 11/64 loss: -3.5950093269348145
Batch 12/64 loss: -2.925107002258301
Batch 13/64 loss: -3.545299530029297
Batch 14/64 loss: -3.323246955871582
Batch 15/64 loss: -3.6493210792541504
Batch 16/64 loss: -3.519679069519043
Batch 17/64 loss: -3.3620052337646484
Batch 18/64 loss: -3.236649513244629
Batch 19/64 loss: -3.5036163330078125
Batch 20/64 loss: -3.3385143280029297
Batch 21/64 loss: -3.2248239517211914
Batch 22/64 loss: -3.447885513305664
Batch 23/64 loss: -3.415532112121582
Batch 24/64 loss: -3.3502674102783203
Batch 25/64 loss: -3.3642587661743164
Batch 26/64 loss: -3.5445566177368164
Batch 27/64 loss: -3.0796804428100586
Batch 28/64 loss: -3.5942955017089844
Batch 29/64 loss: -3.4024391174316406
Batch 30/64 loss: -3.3799057006835938
Batch 31/64 loss: -3.3318538665771484
Batch 32/64 loss: -3.015753746032715
Batch 33/64 loss: -3.5550832748413086
Batch 34/64 loss: -3.632646083831787
Batch 35/64 loss: -3.0487451553344727
Batch 36/64 loss: -3.1632184982299805
Batch 37/64 loss: -3.4189224243164062
Batch 38/64 loss: -3.7460131645202637
Batch 39/64 loss: -3.591433048248291
Batch 40/64 loss: -3.140275001525879
Batch 41/64 loss: -3.371443748474121
Batch 42/64 loss: -3.5515871047973633
Batch 43/64 loss: -3.5388917922973633
Batch 44/64 loss: -3.187519073486328
Batch 45/64 loss: -3.445925712585449
Batch 46/64 loss: -3.476870536804199
Batch 47/64 loss: -2.8206567764282227
Batch 48/64 loss: -3.653247356414795
Batch 49/64 loss: -3.869137763977051
Batch 50/64 loss: -3.532541275024414
Batch 51/64 loss: -3.4694318771362305
Batch 52/64 loss: -3.615908145904541
Batch 53/64 loss: -3.652721881866455
Batch 54/64 loss: -3.4452619552612305
Batch 55/64 loss: -3.289134979248047
Batch 56/64 loss: -3.548978805541992
Batch 57/64 loss: -3.4409914016723633
Batch 58/64 loss: -3.4158859252929688
Batch 59/64 loss: -3.33978271484375
Batch 60/64 loss: -3.7484169006347656
Batch 61/64 loss: -3.124845504760742
Batch 62/64 loss: -3.161214828491211
Batch 63/64 loss: -3.206162452697754
Batch 64/64 loss: -7.822637557983398
Epoch 256  Train loss: -3.4600286820355586  Val loss: -3.531957344500879
Epoch 257
-------------------------------
Batch 1/64 loss: -3.1803512573242188
Batch 2/64 loss: -2.970944404602051
Batch 3/64 loss: -3.2003746032714844
Batch 4/64 loss: -3.2925310134887695
Batch 5/64 loss: -3.4067535400390625
Batch 6/64 loss: -3.24639892578125
Batch 7/64 loss: -3.3352041244506836
Batch 8/64 loss: -3.496479034423828
Batch 9/64 loss: -3.6253514289855957
Batch 10/64 loss: -3.3026180267333984
Batch 11/64 loss: -3.208889961242676
Batch 12/64 loss: -3.3038692474365234
Batch 13/64 loss: -3.12252140045166
Batch 14/64 loss: -3.5156431198120117
Batch 15/64 loss: -3.2068042755126953
Batch 16/64 loss: -3.264044761657715
Batch 17/64 loss: -3.470396041870117
Batch 18/64 loss: -3.70396089553833
Batch 19/64 loss: -3.4134960174560547
Batch 20/64 loss: -2.8461647033691406
Batch 21/64 loss: -3.3845949172973633
Batch 22/64 loss: -3.1468982696533203
Batch 23/64 loss: -3.663123607635498
Batch 24/64 loss: -3.4970827102661133
Batch 25/64 loss: -3.2035484313964844
Batch 26/64 loss: -3.129807472229004
Batch 27/64 loss: -3.309061050415039
Batch 28/64 loss: -3.775970458984375
Batch 29/64 loss: -3.667837619781494
Batch 30/64 loss: -3.446976661682129
Batch 31/64 loss: -3.4647626876831055
Batch 32/64 loss: -3.056283950805664
Batch 33/64 loss: -3.594508171081543
Batch 34/64 loss: -3.4895830154418945
Batch 35/64 loss: -3.472105026245117
Batch 36/64 loss: -3.3214597702026367
Batch 37/64 loss: -2.9852027893066406
Batch 38/64 loss: -3.3949127197265625
Batch 39/64 loss: -3.3399858474731445
Batch 40/64 loss: -3.3929624557495117
Batch 41/64 loss: -3.535922050476074
Batch 42/64 loss: -3.4997310638427734
Batch 43/64 loss: -3.6099939346313477
Batch 44/64 loss: -3.674811363220215
Batch 45/64 loss: -3.5987420082092285
Batch 46/64 loss: -3.4354124069213867
Batch 47/64 loss: -3.481490135192871
Batch 48/64 loss: -3.1522769927978516
Batch 49/64 loss: -3.6528992652893066
Batch 50/64 loss: -3.5794243812561035
Batch 51/64 loss: -3.472524642944336
Batch 52/64 loss: -3.657726287841797
Batch 53/64 loss: -3.5830607414245605
Batch 54/64 loss: -3.695655345916748
Batch 55/64 loss: -3.565335750579834
Batch 56/64 loss: -3.577007293701172
Batch 57/64 loss: -3.6069092750549316
Batch 58/64 loss: -3.4449472427368164
Batch 59/64 loss: -3.2534875869750977
Batch 60/64 loss: -3.6475701332092285
Batch 61/64 loss: -3.8256640434265137
Batch 62/64 loss: -3.489442825317383
Batch 63/64 loss: -3.733304977416992
Batch 64/64 loss: -8.410455703735352
Epoch 257  Train loss: -3.4812650343951055  Val loss: -3.820037461638041
Epoch 258
-------------------------------
Batch 1/64 loss: -3.6757588386535645
Batch 2/64 loss: -3.4511327743530273
Batch 3/64 loss: -3.599501609802246
Batch 4/64 loss: -3.3592119216918945
Batch 5/64 loss: -3.3071022033691406
Batch 6/64 loss: -3.4784584045410156
Batch 7/64 loss: -3.772078037261963
Batch 8/64 loss: -3.441987991333008
Batch 9/64 loss: -3.361334800720215
Batch 10/64 loss: -3.668332099914551
Batch 11/64 loss: -3.590430736541748
Batch 12/64 loss: -3.2030258178710938
Batch 13/64 loss: -3.6697897911071777
Batch 14/64 loss: -3.6819100379943848
Batch 15/64 loss: -3.480719566345215
Batch 16/64 loss: -3.521307945251465
Batch 17/64 loss: -3.73360538482666
Batch 18/64 loss: -3.401251792907715
Batch 19/64 loss: -3.5497403144836426
Batch 20/64 loss: -3.4333553314208984
Batch 21/64 loss: -3.576079845428467
Batch 22/64 loss: -3.474259376525879
Batch 23/64 loss: -3.090362548828125
Batch 24/64 loss: -3.4733428955078125
Batch 25/64 loss: -3.766355037689209
Batch 26/64 loss: -3.596552848815918
Batch 27/64 loss: -3.5392379760742188
Batch 28/64 loss: -3.4662389755249023
Batch 29/64 loss: -3.4758472442626953
Batch 30/64 loss: -3.446049690246582
Batch 31/64 loss: -3.3376121520996094
Batch 32/64 loss: -3.098978042602539
Batch 33/64 loss: -2.9899349212646484
Batch 34/64 loss: -3.39919376373291
Batch 35/64 loss: -2.9980878829956055
Batch 36/64 loss: -3.4427614212036133
Batch 37/64 loss: -3.336024284362793
Batch 38/64 loss: -3.6337928771972656
Batch 39/64 loss: -3.441403388977051
Batch 40/64 loss: -3.5060253143310547
Batch 41/64 loss: -3.5676097869873047
Batch 42/64 loss: -3.0987234115600586
Batch 43/64 loss: -3.0864744186401367
Batch 44/64 loss: -3.3038902282714844
Batch 45/64 loss: -3.340548515319824
Batch 46/64 loss: -3.3064041137695312
Batch 47/64 loss: -3.6040802001953125
Batch 48/64 loss: -3.623556613922119
Batch 49/64 loss: -3.866086959838867
Batch 50/64 loss: -3.5268306732177734
Batch 51/64 loss: -3.5140819549560547
Batch 52/64 loss: -3.443075180053711
Batch 53/64 loss: -3.6186227798461914
Batch 54/64 loss: -3.3411550521850586
Batch 55/64 loss: -3.4986658096313477
Batch 56/64 loss: -3.6447911262512207
Batch 57/64 loss: -3.5592732429504395
Batch 58/64 loss: -3.506556987762451
Batch 59/64 loss: -3.498650550842285
Batch 60/64 loss: -3.2736740112304688
Batch 61/64 loss: -3.3755130767822266
Batch 62/64 loss: -3.2974672317504883
Batch 63/64 loss: -3.2833633422851562
Batch 64/64 loss: -8.171826362609863
Epoch 258  Train loss: -3.5102139753453874  Val loss: -3.9082954904877445
Epoch 259
-------------------------------
Batch 1/64 loss: -3.6669297218322754
Batch 2/64 loss: -3.34403133392334
Batch 3/64 loss: -3.5544090270996094
Batch 4/64 loss: -3.5311574935913086
Batch 5/64 loss: -3.6851024627685547
Batch 6/64 loss: -3.6946630477905273
Batch 7/64 loss: -3.384955406188965
Batch 8/64 loss: -3.3145265579223633
Batch 9/64 loss: -3.3639049530029297
Batch 10/64 loss: -3.6115365028381348
Batch 11/64 loss: -3.5282974243164062
Batch 12/64 loss: -3.5907511711120605
Batch 13/64 loss: -3.474667549133301
Batch 14/64 loss: -3.407001495361328
Batch 15/64 loss: -3.505779266357422
Batch 16/64 loss: -3.690080165863037
Batch 17/64 loss: -3.2745866775512695
Batch 18/64 loss: -3.394322395324707
Batch 19/64 loss: -3.0407276153564453
Batch 20/64 loss: -3.6844701766967773
Batch 21/64 loss: -3.5501251220703125
Batch 22/64 loss: -3.6874923706054688
Batch 23/64 loss: -3.40948486328125
Batch 24/64 loss: -3.597750663757324
Batch 25/64 loss: -3.4148521423339844
Batch 26/64 loss: -3.3160409927368164
Batch 27/64 loss: -3.487947463989258
Batch 28/64 loss: -3.5182437896728516
Batch 29/64 loss: -3.2099552154541016
Batch 30/64 loss: -3.5512800216674805
Batch 31/64 loss: -3.640749454498291
Batch 32/64 loss: -3.6823887825012207
Batch 33/64 loss: -3.608694553375244
Batch 34/64 loss: -3.305638313293457
Batch 35/64 loss: -3.2956295013427734
Batch 36/64 loss: -3.51092529296875
Batch 37/64 loss: -3.6820554733276367
Batch 38/64 loss: -3.5724844932556152
Batch 39/64 loss: -3.6008033752441406
Batch 40/64 loss: -3.626539707183838
Batch 41/64 loss: -3.6631360054016113
Batch 42/64 loss: -3.5911388397216797
Batch 43/64 loss: -3.410655975341797
Batch 44/64 loss: -3.5399346351623535
Batch 45/64 loss: -3.711212158203125
Batch 46/64 loss: -3.570319652557373
Batch 47/64 loss: -3.613037586212158
Batch 48/64 loss: -3.627814769744873
Batch 49/64 loss: -3.818188190460205
Batch 50/64 loss: -3.2919464111328125
Batch 51/64 loss: -3.447235107421875
Batch 52/64 loss: -3.433403968811035
Batch 53/64 loss: -3.1974620819091797
Batch 54/64 loss: -3.5330238342285156
Batch 55/64 loss: -3.6678361892700195
Batch 56/64 loss: -3.4745912551879883
Batch 57/64 loss: -3.521376609802246
Batch 58/64 loss: -3.5124711990356445
Batch 59/64 loss: -3.401158332824707
Batch 60/64 loss: -3.342264175415039
Batch 61/64 loss: -3.6615114212036133
Batch 62/64 loss: -3.722653388977051
Batch 63/64 loss: -3.634225845336914
Batch 64/64 loss: -8.17457389831543
Epoch 259  Train loss: -3.5690746681362975  Val loss: -3.769380392487516
Epoch 260
-------------------------------
Batch 1/64 loss: -3.4305810928344727
Batch 2/64 loss: -3.217839241027832
Batch 3/64 loss: -3.833631992340088
Batch 4/64 loss: -3.764976978302002
Batch 5/64 loss: -3.684734344482422
Batch 6/64 loss: -3.464077949523926
Batch 7/64 loss: -3.7669386863708496
Batch 8/64 loss: -3.7844748497009277
Batch 9/64 loss: -3.6091928482055664
Batch 10/64 loss: -3.5770773887634277
Batch 11/64 loss: -3.4205732345581055
Batch 12/64 loss: -3.562326431274414
Batch 13/64 loss: -3.684084892272949
Batch 14/64 loss: -3.573458671569824
Batch 15/64 loss: -3.4521493911743164
Batch 16/64 loss: -3.5415401458740234
Batch 17/64 loss: -3.790097713470459
Batch 18/64 loss: -3.6652989387512207
Batch 19/64 loss: -3.5467185974121094
Batch 20/64 loss: -3.5848960876464844
Batch 21/64 loss: -3.412175178527832
Batch 22/64 loss: -3.708159923553467
Batch 23/64 loss: -3.604494094848633
Batch 24/64 loss: -3.3981895446777344
Batch 25/64 loss: -3.098443031311035
Batch 26/64 loss: -3.4382591247558594
Batch 27/64 loss: -3.6450119018554688
Batch 28/64 loss: -3.4626855850219727
Batch 29/64 loss: -3.4795446395874023
Batch 30/64 loss: -3.594623565673828
Batch 31/64 loss: -3.7696027755737305
Batch 32/64 loss: -3.571105480194092
Batch 33/64 loss: -3.8789806365966797
Batch 34/64 loss: -3.659292221069336
Batch 35/64 loss: -3.6828227043151855
Batch 36/64 loss: -3.4128923416137695
Batch 37/64 loss: -3.4665145874023438
Batch 38/64 loss: -3.4278087615966797
Batch 39/64 loss: -3.489089012145996
Batch 40/64 loss: -3.096175193786621
Batch 41/64 loss: -3.7739105224609375
Batch 42/64 loss: -3.4771041870117188
Batch 43/64 loss: -3.3665666580200195
Batch 44/64 loss: -3.7445831298828125
Batch 45/64 loss: -3.438121795654297
Batch 46/64 loss: -3.7159814834594727
Batch 47/64 loss: -3.6498751640319824
Batch 48/64 loss: -3.638869285583496
Batch 49/64 loss: -3.6901988983154297
Batch 50/64 loss: -3.709016799926758
Batch 51/64 loss: -3.7222723960876465
Batch 52/64 loss: -3.621180534362793
Batch 53/64 loss: -3.569556713104248
Batch 54/64 loss: -3.8226428031921387
Batch 55/64 loss: -3.530567169189453
Batch 56/64 loss: -3.353687286376953
Batch 57/64 loss: -3.6829986572265625
Batch 58/64 loss: -3.2529525756835938
Batch 59/64 loss: -3.4182939529418945
Batch 60/64 loss: -3.7162251472473145
Batch 61/64 loss: -3.3939027786254883
Batch 62/64 loss: -3.5927557945251465
Batch 63/64 loss: -3.4679489135742188
Batch 64/64 loss: -8.017965316772461
Epoch 260  Train loss: -3.617462375117283  Val loss: -3.942941672203877
Epoch 261
-------------------------------
Batch 1/64 loss: -3.396601676940918
Batch 2/64 loss: -3.6702141761779785
Batch 3/64 loss: -3.400174140930176
Batch 4/64 loss: -3.7138190269470215
Batch 5/64 loss: -3.5875673294067383
Batch 6/64 loss: -3.444951057434082
Batch 7/64 loss: -3.597174644470215
Batch 8/64 loss: -3.6795082092285156
Batch 9/64 loss: -3.629495620727539
Batch 10/64 loss: -3.3909177780151367
Batch 11/64 loss: -3.25655460357666
Batch 12/64 loss: -3.6223959922790527
Batch 13/64 loss: -3.6248574256896973
Batch 14/64 loss: -3.434328079223633
Batch 15/64 loss: -3.3398380279541016
Batch 16/64 loss: -3.697648048400879
Batch 17/64 loss: -3.644624710083008
Batch 18/64 loss: -3.4138193130493164
Batch 19/64 loss: -3.5233612060546875
Batch 20/64 loss: -3.6393942832946777
Batch 21/64 loss: -3.618100643157959
Batch 22/64 loss: -3.603109836578369
Batch 23/64 loss: -3.561796188354492
Batch 24/64 loss: -3.766099452972412
Batch 25/64 loss: -3.693571090698242
Batch 26/64 loss: -3.752610206604004
Batch 27/64 loss: -3.615955352783203
Batch 28/64 loss: -3.6912312507629395
Batch 29/64 loss: -3.619375705718994
Batch 30/64 loss: -3.7693471908569336
Batch 31/64 loss: -3.610255718231201
Batch 32/64 loss: -3.5877113342285156
Batch 33/64 loss: -3.917630672454834
Batch 34/64 loss: -3.5295639038085938
Batch 35/64 loss: -3.7263131141662598
Batch 36/64 loss: -3.5181708335876465
Batch 37/64 loss: -3.4062318801879883
Batch 38/64 loss: -3.6942453384399414
Batch 39/64 loss: -3.6012277603149414
Batch 40/64 loss: -3.7320122718811035
Batch 41/64 loss: -3.713839530944824
Batch 42/64 loss: -3.75732421875
Batch 43/64 loss: -3.519782543182373
Batch 44/64 loss: -3.8400378227233887
Batch 45/64 loss: -3.627566337585449
Batch 46/64 loss: -3.4891796112060547
Batch 47/64 loss: -3.551090717315674
Batch 48/64 loss: -3.5873498916625977
Batch 49/64 loss: -3.4106950759887695
Batch 50/64 loss: -3.6813931465148926
Batch 51/64 loss: -3.7132492065429688
Batch 52/64 loss: -3.6959352493286133
Batch 53/64 loss: -3.805422306060791
Batch 54/64 loss: -3.3142213821411133
Batch 55/64 loss: -3.40334415435791
Batch 56/64 loss: -3.8109803199768066
Batch 57/64 loss: -3.3342885971069336
Batch 58/64 loss: -3.5849404335021973
Batch 59/64 loss: -3.626850128173828
Batch 60/64 loss: -3.883394718170166
Batch 61/64 loss: -3.5352096557617188
Batch 62/64 loss: -3.5564041137695312
Batch 63/64 loss: -3.075695037841797
Batch 64/64 loss: -8.425981521606445
Epoch 261  Train loss: -3.6479919283997777  Val loss: -3.975155846769457
Epoch 262
-------------------------------
Batch 1/64 loss: -3.4714059829711914
Batch 2/64 loss: -3.793626308441162
Batch 3/64 loss: -3.5665626525878906
Batch 4/64 loss: -3.7906436920166016
Batch 5/64 loss: -3.67448091506958
Batch 6/64 loss: -3.781409740447998
Batch 7/64 loss: -3.675436496734619
Batch 8/64 loss: -3.5864830017089844
Batch 9/64 loss: -3.605113983154297
Batch 10/64 loss: -3.720628261566162
Batch 11/64 loss: -3.482245445251465
Batch 12/64 loss: -3.3949508666992188
Batch 13/64 loss: -3.698293685913086
Batch 14/64 loss: -3.4113025665283203
Batch 15/64 loss: -3.722297191619873
Batch 16/64 loss: -3.83538818359375
Batch 17/64 loss: -3.289883613586426
Batch 18/64 loss: -3.621037483215332
Batch 19/64 loss: -3.6486945152282715
Batch 20/64 loss: -3.6548900604248047
Batch 21/64 loss: -3.485736846923828
Batch 22/64 loss: -3.4116945266723633
Batch 23/64 loss: -3.4723243713378906
Batch 24/64 loss: -3.5251331329345703
Batch 25/64 loss: -3.681778907775879
Batch 26/64 loss: -3.605854034423828
Batch 27/64 loss: -3.7008066177368164
Batch 28/64 loss: -3.5564370155334473
Batch 29/64 loss: -3.484323501586914
Batch 30/64 loss: -3.49526309967041
Batch 31/64 loss: -3.684256076812744
Batch 32/64 loss: -3.7194204330444336
Batch 33/64 loss: -3.4110097885131836
Batch 34/64 loss: -3.2249679565429688
Batch 35/64 loss: -3.5620245933532715
Batch 36/64 loss: -3.537914276123047
Batch 37/64 loss: -3.2069969177246094
Batch 38/64 loss: -3.0943307876586914
Batch 39/64 loss: -3.5738754272460938
Batch 40/64 loss: -3.46309757232666
Batch 41/64 loss: -3.6056036949157715
Batch 42/64 loss: -3.293527603149414
Batch 43/64 loss: -3.8931307792663574
Batch 44/64 loss: -3.7831153869628906
Batch 45/64 loss: -3.514084815979004
Batch 46/64 loss: -3.5523877143859863
Batch 47/64 loss: -3.4007129669189453
Batch 48/64 loss: -3.646611213684082
Batch 49/64 loss: -3.7003817558288574
Batch 50/64 loss: -3.840160369873047
Batch 51/64 loss: -3.773773670196533
Batch 52/64 loss: -2.9993152618408203
Batch 53/64 loss: -3.6180200576782227
Batch 54/64 loss: -3.6872353553771973
Batch 55/64 loss: -3.7308545112609863
Batch 56/64 loss: -3.749711036682129
Batch 57/64 loss: -3.3915529251098633
Batch 58/64 loss: -3.5430240631103516
Batch 59/64 loss: -3.5872206687927246
Batch 60/64 loss: -3.4021520614624023
Batch 61/64 loss: -3.6848483085632324
Batch 62/64 loss: -3.258631706237793
Batch 63/64 loss: -3.5726613998413086
Batch 64/64 loss: -8.191954612731934
Epoch 262  Train loss: -3.6187404520371382  Val loss: -3.933448057404089
Epoch 263
-------------------------------
Batch 1/64 loss: -3.339728355407715
Batch 2/64 loss: -3.355863571166992
Batch 3/64 loss: -3.6230058670043945
Batch 4/64 loss: -3.6645522117614746
Batch 5/64 loss: -3.7565555572509766
Batch 6/64 loss: -3.6277847290039062
Batch 7/64 loss: -3.432206153869629
Batch 8/64 loss: -3.2360219955444336
Batch 9/64 loss: -3.599109172821045
Batch 10/64 loss: -3.4733657836914062
Batch 11/64 loss: -3.48468017578125
Batch 12/64 loss: -3.5029096603393555
Batch 13/64 loss: -3.7214016914367676
Batch 14/64 loss: -3.7621326446533203
Batch 15/64 loss: -3.81005859375
Batch 16/64 loss: -3.787320613861084
Batch 17/64 loss: -3.755300998687744
Batch 18/64 loss: -3.748474597930908
Batch 19/64 loss: -3.6618494987487793
Batch 20/64 loss: -3.7880778312683105
Batch 21/64 loss: -3.6258039474487305
Batch 22/64 loss: -3.5784435272216797
Batch 23/64 loss: -3.6049156188964844
Batch 24/64 loss: -3.573485851287842
Batch 25/64 loss: -3.7060294151306152
Batch 26/64 loss: -3.7329068183898926
Batch 27/64 loss: -3.7609167098999023
Batch 28/64 loss: -3.689816474914551
Batch 29/64 loss: -3.62913179397583
Batch 30/64 loss: -3.447983741760254
Batch 31/64 loss: -3.6035990715026855
Batch 32/64 loss: -3.788095474243164
Batch 33/64 loss: -3.583169937133789
Batch 34/64 loss: -3.2032814025878906
Batch 35/64 loss: -3.459761619567871
Batch 36/64 loss: -3.623439311981201
Batch 37/64 loss: -3.4710264205932617
Batch 38/64 loss: -3.321713447570801
Batch 39/64 loss: -3.709522247314453
Batch 40/64 loss: -3.4476327896118164
Batch 41/64 loss: -3.4622621536254883
Batch 42/64 loss: -2.5730857849121094
Batch 43/64 loss: -3.6614232063293457
Batch 44/64 loss: -3.6848645210266113
Batch 45/64 loss: -3.577568531036377
Batch 46/64 loss: -3.774176597595215
Batch 47/64 loss: -3.7573909759521484
Batch 48/64 loss: -3.4616737365722656
Batch 49/64 loss: -3.787726879119873
Batch 50/64 loss: -3.5264487266540527
Batch 51/64 loss: -3.7330551147460938
Batch 52/64 loss: -3.67805814743042
Batch 53/64 loss: -3.582613945007324
Batch 54/64 loss: -3.5252485275268555
Batch 55/64 loss: -3.641702175140381
Batch 56/64 loss: -3.454756736755371
Batch 57/64 loss: -3.4215831756591797
Batch 58/64 loss: -3.5869898796081543
Batch 59/64 loss: -3.5230236053466797
Batch 60/64 loss: -3.789435386657715
Batch 61/64 loss: -3.44290828704834
Batch 62/64 loss: -3.816772937774658
Batch 63/64 loss: -3.664656639099121
Batch 64/64 loss: -8.178525924682617
Epoch 263  Train loss: -3.638468948065066  Val loss: -4.001087201829629
Saving best model, epoch: 263
Epoch 264
-------------------------------
Batch 1/64 loss: -3.574467182159424
Batch 2/64 loss: -3.3506364822387695
Batch 3/64 loss: -3.7856907844543457
Batch 4/64 loss: -3.78751802444458
Batch 5/64 loss: -3.763275623321533
Batch 6/64 loss: -3.6969704627990723
Batch 7/64 loss: -3.6908459663391113
Batch 8/64 loss: -3.614224910736084
Batch 9/64 loss: -3.7162885665893555
Batch 10/64 loss: -3.586047649383545
Batch 11/64 loss: -3.80319881439209
Batch 12/64 loss: -3.577101230621338
Batch 13/64 loss: -3.8048906326293945
Batch 14/64 loss: -3.8469748497009277
Batch 15/64 loss: -3.5859451293945312
Batch 16/64 loss: -3.7363991737365723
Batch 17/64 loss: -3.6594486236572266
Batch 18/64 loss: -3.6062841415405273
Batch 19/64 loss: -3.6794142723083496
Batch 20/64 loss: -3.612368106842041
Batch 21/64 loss: -3.319995880126953
Batch 22/64 loss: -3.5208826065063477
Batch 23/64 loss: -3.383951187133789
Batch 24/64 loss: -3.5659680366516113
Batch 25/64 loss: -3.534395217895508
Batch 26/64 loss: -3.6225852966308594
Batch 27/64 loss: -3.682161808013916
Batch 28/64 loss: -3.6553492546081543
Batch 29/64 loss: -3.525949001312256
Batch 30/64 loss: -3.5658631324768066
Batch 31/64 loss: -3.851047992706299
Batch 32/64 loss: -3.482651710510254
Batch 33/64 loss: -3.0693912506103516
Batch 34/64 loss: -3.7882299423217773
Batch 35/64 loss: -3.2615737915039062
Batch 36/64 loss: -3.2176876068115234
Batch 37/64 loss: -3.5967612266540527
Batch 38/64 loss: -3.5735092163085938
Batch 39/64 loss: -3.714508056640625
Batch 40/64 loss: -3.7165374755859375
Batch 41/64 loss: -3.3611412048339844
Batch 42/64 loss: -3.1503419876098633
Batch 43/64 loss: -3.7688069343566895
Batch 44/64 loss: -3.494204044342041
Batch 45/64 loss: -3.554685592651367
Batch 46/64 loss: -3.7374258041381836
Batch 47/64 loss: -3.591370105743408
Batch 48/64 loss: -3.7000908851623535
Batch 49/64 loss: -3.3006935119628906
Batch 50/64 loss: -3.4754180908203125
Batch 51/64 loss: -3.4068145751953125
Batch 52/64 loss: -3.7328362464904785
Batch 53/64 loss: -3.679715156555176
Batch 54/64 loss: -3.618241310119629
Batch 55/64 loss: -3.3463563919067383
Batch 56/64 loss: -3.7685112953186035
Batch 57/64 loss: -3.498488426208496
Batch 58/64 loss: -3.491246223449707
Batch 59/64 loss: -2.898073196411133
Batch 60/64 loss: -3.6824488639831543
Batch 61/64 loss: -3.89920711517334
Batch 62/64 loss: -3.6229777336120605
Batch 63/64 loss: -3.596336841583252
Batch 64/64 loss: -8.225204467773438
Epoch 264  Train loss: -3.6340600032432406  Val loss: -3.899436754049714
Epoch 265
-------------------------------
Batch 1/64 loss: -3.4954605102539062
Batch 2/64 loss: -3.6254639625549316
Batch 3/64 loss: -3.548063278198242
Batch 4/64 loss: -3.4455833435058594
Batch 5/64 loss: -3.724010467529297
Batch 6/64 loss: -3.8222079277038574
Batch 7/64 loss: -3.498734474182129
Batch 8/64 loss: -3.554001808166504
Batch 9/64 loss: -3.5446014404296875
Batch 10/64 loss: -3.6411166191101074
Batch 11/64 loss: -3.1655454635620117
Batch 12/64 loss: -3.480545997619629
Batch 13/64 loss: -3.5655269622802734
Batch 14/64 loss: -3.5285110473632812
Batch 15/64 loss: -3.7517285346984863
Batch 16/64 loss: -3.6428651809692383
Batch 17/64 loss: -3.888782024383545
Batch 18/64 loss: -3.599607467651367
Batch 19/64 loss: -3.7863988876342773
Batch 20/64 loss: -3.607142925262451
Batch 21/64 loss: -3.6263790130615234
Batch 22/64 loss: -3.0582656860351562
Batch 23/64 loss: -3.3370180130004883
Batch 24/64 loss: -3.7134366035461426
Batch 25/64 loss: -3.7290005683898926
Batch 26/64 loss: -3.833743095397949
Batch 27/64 loss: -3.3109941482543945
Batch 28/64 loss: -3.8013553619384766
Batch 29/64 loss: -3.7383809089660645
Batch 30/64 loss: -3.7219467163085938
Batch 31/64 loss: -3.737156391143799
Batch 32/64 loss: -3.6667275428771973
Batch 33/64 loss: -3.717116355895996
Batch 34/64 loss: -3.6647815704345703
Batch 35/64 loss: -3.3766698837280273
Batch 36/64 loss: -3.4824132919311523
Batch 37/64 loss: -3.6199002265930176
Batch 38/64 loss: -3.5515546798706055
Batch 39/64 loss: -3.577256679534912
Batch 40/64 loss: -3.543691635131836
Batch 41/64 loss: -3.18746280670166
Batch 42/64 loss: -3.193903923034668
Batch 43/64 loss: -3.6568989753723145
Batch 44/64 loss: -3.6571130752563477
Batch 45/64 loss: -3.64803409576416
Batch 46/64 loss: -3.413564682006836
Batch 47/64 loss: -3.476559638977051
Batch 48/64 loss: -3.7116641998291016
Batch 49/64 loss: -3.551703453063965
Batch 50/64 loss: -3.0965356826782227
Batch 51/64 loss: -3.623689651489258
Batch 52/64 loss: -3.7031140327453613
Batch 53/64 loss: -3.5029802322387695
Batch 54/64 loss: -3.4672536849975586
Batch 55/64 loss: -3.6733899116516113
Batch 56/64 loss: -3.4619932174682617
Batch 57/64 loss: -3.6234850883483887
Batch 58/64 loss: -3.6204447746276855
Batch 59/64 loss: -3.543694019317627
Batch 60/64 loss: -3.5652098655700684
Batch 61/64 loss: -3.669278144836426
Batch 62/64 loss: -3.7273483276367188
Batch 63/64 loss: -3.263914108276367
Batch 64/64 loss: -8.379514694213867
Epoch 265  Train loss: -3.6242754244336894  Val loss: -3.9450038634624676
Epoch 266
-------------------------------
Batch 1/64 loss: -3.570024013519287
Batch 2/64 loss: -3.5548105239868164
Batch 3/64 loss: -3.6286635398864746
Batch 4/64 loss: -3.7791991233825684
Batch 5/64 loss: -3.3446130752563477
Batch 6/64 loss: -3.291934013366699
Batch 7/64 loss: -3.5021257400512695
Batch 8/64 loss: -3.5143041610717773
Batch 9/64 loss: -3.589874744415283
Batch 10/64 loss: -3.3491573333740234
Batch 11/64 loss: -3.486302375793457
Batch 12/64 loss: -3.7130980491638184
Batch 13/64 loss: -3.7291998863220215
Batch 14/64 loss: -3.5498485565185547
Batch 15/64 loss: -3.662020206451416
Batch 16/64 loss: -3.643404960632324
Batch 17/64 loss: -3.763805866241455
Batch 18/64 loss: -3.6429333686828613
Batch 19/64 loss: -3.6928811073303223
Batch 20/64 loss: -3.42434024810791
Batch 21/64 loss: -3.420363426208496
Batch 22/64 loss: -3.4533185958862305
Batch 23/64 loss: -3.6183271408081055
Batch 24/64 loss: -3.6643476486206055
Batch 25/64 loss: -3.5671701431274414
Batch 26/64 loss: -3.5908660888671875
Batch 27/64 loss: -3.771819591522217
Batch 28/64 loss: -3.4898929595947266
Batch 29/64 loss: -3.6504950523376465
Batch 30/64 loss: -3.596996784210205
Batch 31/64 loss: -3.710892677307129
Batch 32/64 loss: -3.923100471496582
Batch 33/64 loss: -3.486281394958496
Batch 34/64 loss: -3.691133975982666
Batch 35/64 loss: -3.726314067840576
Batch 36/64 loss: -3.526402473449707
Batch 37/64 loss: -3.1957712173461914
Batch 38/64 loss: -3.700300693511963
Batch 39/64 loss: -3.560514450073242
Batch 40/64 loss: -3.7942471504211426
Batch 41/64 loss: -3.5788698196411133
Batch 42/64 loss: -3.577755928039551
Batch 43/64 loss: -3.5143938064575195
Batch 44/64 loss: -3.277562141418457
Batch 45/64 loss: -3.733614921569824
Batch 46/64 loss: -3.547701835632324
Batch 47/64 loss: -3.8363022804260254
Batch 48/64 loss: -3.633749485015869
Batch 49/64 loss: -3.323701858520508
Batch 50/64 loss: -3.839153289794922
Batch 51/64 loss: -3.544245719909668
Batch 52/64 loss: -3.8165435791015625
Batch 53/64 loss: -3.7500319480895996
Batch 54/64 loss: -3.6988577842712402
Batch 55/64 loss: -3.8340139389038086
Batch 56/64 loss: -3.8777852058410645
Batch 57/64 loss: -3.423219680786133
Batch 58/64 loss: -3.4200973510742188
Batch 59/64 loss: -3.7778568267822266
Batch 60/64 loss: -3.597001075744629
Batch 61/64 loss: -3.7371206283569336
Batch 62/64 loss: -3.4167118072509766
Batch 63/64 loss: -3.696709156036377
Batch 64/64 loss: -8.22403335571289
Epoch 266  Train loss: -3.6579156389423444  Val loss: -3.9744849319720186
Epoch 267
-------------------------------
Batch 1/64 loss: -3.598463535308838
Batch 2/64 loss: -3.527468204498291
Batch 3/64 loss: -3.719442844390869
Batch 4/64 loss: -3.597627639770508
Batch 5/64 loss: -3.4693603515625
Batch 6/64 loss: -3.6907052993774414
Batch 7/64 loss: -3.7046284675598145
Batch 8/64 loss: -3.377504348754883
Batch 9/64 loss: -3.707080364227295
Batch 10/64 loss: -3.689784049987793
Batch 11/64 loss: -3.6362357139587402
Batch 12/64 loss: -3.6493186950683594
Batch 13/64 loss: -3.56247615814209
Batch 14/64 loss: -3.5074987411499023
Batch 15/64 loss: -3.7797694206237793
Batch 16/64 loss: -3.5074281692504883
Batch 17/64 loss: -3.513439178466797
Batch 18/64 loss: -3.5938868522644043
Batch 19/64 loss: -3.4337100982666016
Batch 20/64 loss: -3.437209129333496
Batch 21/64 loss: -3.506588935852051
Batch 22/64 loss: -3.689340114593506
Batch 23/64 loss: -3.1754350662231445
Batch 24/64 loss: -3.087855339050293
Batch 25/64 loss: -3.7316946983337402
Batch 26/64 loss: -3.247910499572754
Batch 27/64 loss: -3.534923553466797
Batch 28/64 loss: -3.5647454261779785
Batch 29/64 loss: -3.1693296432495117
Batch 30/64 loss: -3.1655502319335938
Batch 31/64 loss: -3.6802425384521484
Batch 32/64 loss: -3.8076748847961426
Batch 33/64 loss: -3.4864726066589355
Batch 34/64 loss: -3.3056535720825195
Batch 35/64 loss: -3.5877437591552734
Batch 36/64 loss: -3.5973286628723145
Batch 37/64 loss: -3.621140956878662
Batch 38/64 loss: -3.507904529571533
Batch 39/64 loss: -3.6221537590026855
Batch 40/64 loss: -3.5052576065063477
Batch 41/64 loss: -3.2654800415039062
Batch 42/64 loss: -3.6312108039855957
Batch 43/64 loss: -3.5401697158813477
Batch 44/64 loss: -3.584885597229004
Batch 45/64 loss: -3.496321678161621
Batch 46/64 loss: -3.474551200866699
Batch 47/64 loss: -3.790682315826416
Batch 48/64 loss: -3.546236991882324
Batch 49/64 loss: -3.493387222290039
Batch 50/64 loss: -3.6755619049072266
Batch 51/64 loss: -3.724008560180664
Batch 52/64 loss: -3.5370945930480957
Batch 53/64 loss: -3.550431251525879
Batch 54/64 loss: -3.7695083618164062
Batch 55/64 loss: -3.70467472076416
Batch 56/64 loss: -3.6219124794006348
Batch 57/64 loss: -3.6111297607421875
Batch 58/64 loss: -3.6680803298950195
Batch 59/64 loss: -3.245861053466797
Batch 60/64 loss: -3.5896244049072266
Batch 61/64 loss: -3.480213165283203
Batch 62/64 loss: -3.55979061126709
Batch 63/64 loss: -3.268834114074707
Batch 64/64 loss: -7.919477939605713
Epoch 267  Train loss: -3.593211654588288  Val loss: -3.8553164767235826
Epoch 268
-------------------------------
Batch 1/64 loss: -3.5650205612182617
Batch 2/64 loss: -3.389462471008301
Batch 3/64 loss: -3.392571449279785
Batch 4/64 loss: -3.423604965209961
Batch 5/64 loss: -3.6315813064575195
Batch 6/64 loss: -3.7195701599121094
Batch 7/64 loss: -3.717287540435791
Batch 8/64 loss: -3.537930488586426
Batch 9/64 loss: -3.4712963104248047
Batch 10/64 loss: -3.452434539794922
Batch 11/64 loss: -3.6863064765930176
Batch 12/64 loss: -3.5580949783325195
Batch 13/64 loss: -3.4023618698120117
Batch 14/64 loss: -3.533322334289551
Batch 15/64 loss: -3.550023078918457
Batch 16/64 loss: -3.7125887870788574
Batch 17/64 loss: -3.7884387969970703
Batch 18/64 loss: -3.587231159210205
Batch 19/64 loss: -3.6081457138061523
Batch 20/64 loss: -3.752009868621826
Batch 21/64 loss: -3.3441123962402344
Batch 22/64 loss: -3.831313133239746
Batch 23/64 loss: -3.735842227935791
Batch 24/64 loss: -3.503689765930176
Batch 25/64 loss: -3.6128835678100586
Batch 26/64 loss: -3.833820343017578
Batch 27/64 loss: -3.74580717086792
Batch 28/64 loss: -3.551778793334961
Batch 29/64 loss: -3.717573642730713
Batch 30/64 loss: -3.8233532905578613
Batch 31/64 loss: -3.7146401405334473
Batch 32/64 loss: -3.741018772125244
Batch 33/64 loss: -3.7891697883605957
Batch 34/64 loss: -3.8093347549438477
Batch 35/64 loss: -3.534176826477051
Batch 36/64 loss: -3.59891414642334
Batch 37/64 loss: -3.3568220138549805
Batch 38/64 loss: -3.1292152404785156
Batch 39/64 loss: -3.725309371948242
Batch 40/64 loss: -3.298581123352051
Batch 41/64 loss: -3.7527594566345215
Batch 42/64 loss: -3.75827693939209
Batch 43/64 loss: -3.2826833724975586
Batch 44/64 loss: -3.149158477783203
Batch 45/64 loss: -3.5148563385009766
Batch 46/64 loss: -3.5214996337890625
Batch 47/64 loss: -3.620771884918213
Batch 48/64 loss: -3.7750396728515625
Batch 49/64 loss: -3.740825653076172
Batch 50/64 loss: -3.5686583518981934
Batch 51/64 loss: -3.777095317840576
Batch 52/64 loss: -3.1826744079589844
Batch 53/64 loss: -3.662917137145996
Batch 54/64 loss: -3.403402328491211
Batch 55/64 loss: -3.65167236328125
Batch 56/64 loss: -3.79121732711792
Batch 57/64 loss: -3.578801155090332
Batch 58/64 loss: -3.6100497245788574
Batch 59/64 loss: -3.68874454498291
Batch 60/64 loss: -3.6074934005737305
Batch 61/64 loss: -3.653897762298584
Batch 62/64 loss: -3.639650821685791
Batch 63/64 loss: -3.7009353637695312
Batch 64/64 loss: -8.246810913085938
Epoch 268  Train loss: -3.6501149645038677  Val loss: -3.9268559065881052
Epoch 269
-------------------------------
Batch 1/64 loss: -3.326509475708008
Batch 2/64 loss: -3.5566349029541016
Batch 3/64 loss: -3.5533666610717773
Batch 4/64 loss: -3.6273512840270996
Batch 5/64 loss: -3.677638053894043
Batch 6/64 loss: -3.735184669494629
Batch 7/64 loss: -3.849795341491699
Batch 8/64 loss: -3.510565757751465
Batch 9/64 loss: -3.7791948318481445
Batch 10/64 loss: -3.5997986793518066
Batch 11/64 loss: -3.5317068099975586
Batch 12/64 loss: -3.4257774353027344
Batch 13/64 loss: -3.42104434967041
Batch 14/64 loss: -3.2526063919067383
Batch 15/64 loss: -3.579904556274414
Batch 16/64 loss: -3.7374658584594727
Batch 17/64 loss: -3.664557456970215
Batch 18/64 loss: -3.69193172454834
Batch 19/64 loss: -3.6233463287353516
Batch 20/64 loss: -3.6492786407470703
Batch 21/64 loss: -3.2087278366088867
Batch 22/64 loss: -3.623587131500244
Batch 23/64 loss: -3.7565054893493652
Batch 24/64 loss: -3.752333641052246
Batch 25/64 loss: -3.548520565032959
Batch 26/64 loss: -3.7513585090637207
Batch 27/64 loss: -3.6451072692871094
Batch 28/64 loss: -3.522716522216797
Batch 29/64 loss: -3.6584177017211914
Batch 30/64 loss: -3.676116943359375
Batch 31/64 loss: -3.808676242828369
Batch 32/64 loss: -3.4652819633483887
Batch 33/64 loss: -3.620062828063965
Batch 34/64 loss: -3.674239158630371
Batch 35/64 loss: -3.753389358520508
Batch 36/64 loss: -3.595579147338867
Batch 37/64 loss: -3.7722620964050293
Batch 38/64 loss: -3.2437286376953125
Batch 39/64 loss: -3.611011505126953
Batch 40/64 loss: -3.4506258964538574
Batch 41/64 loss: -3.762237071990967
Batch 42/64 loss: -3.7531027793884277
Batch 43/64 loss: -3.4566707611083984
Batch 44/64 loss: -3.5466127395629883
Batch 45/64 loss: -3.8411865234375
Batch 46/64 loss: -3.601724624633789
Batch 47/64 loss: -3.805863857269287
Batch 48/64 loss: -3.6243958473205566
Batch 49/64 loss: -3.671555519104004
Batch 50/64 loss: -3.736392021179199
Batch 51/64 loss: -3.409510612487793
Batch 52/64 loss: -3.806452751159668
Batch 53/64 loss: -3.209379196166992
Batch 54/64 loss: -3.420217514038086
Batch 55/64 loss: -3.5480823516845703
Batch 56/64 loss: -3.6371254920959473
Batch 57/64 loss: -3.762946605682373
Batch 58/64 loss: -3.8478527069091797
Batch 59/64 loss: -3.5763721466064453
Batch 60/64 loss: -3.6522884368896484
Batch 61/64 loss: -3.7159619331359863
Batch 62/64 loss: -3.47383975982666
Batch 63/64 loss: -3.683781147003174
Batch 64/64 loss: -8.170856475830078
Epoch 269  Train loss: -3.6643702338723574  Val loss: -4.063082311571259
Saving best model, epoch: 269
Epoch 270
-------------------------------
Batch 1/64 loss: -3.8348488807678223
Batch 2/64 loss: -3.8354973793029785
Batch 3/64 loss: -3.745197296142578
Batch 4/64 loss: -3.8322091102600098
Batch 5/64 loss: -3.287687301635742
Batch 6/64 loss: -3.764326572418213
Batch 7/64 loss: -3.699387550354004
Batch 8/64 loss: -3.5508604049682617
Batch 9/64 loss: -3.757528305053711
Batch 10/64 loss: -3.7987351417541504
Batch 11/64 loss: -3.687204360961914
Batch 12/64 loss: -3.551274299621582
Batch 13/64 loss: -3.8602681159973145
Batch 14/64 loss: -3.7961854934692383
Batch 15/64 loss: -3.627589225769043
Batch 16/64 loss: -3.464590072631836
Batch 17/64 loss: -3.7763710021972656
Batch 18/64 loss: -2.9451684951782227
Batch 19/64 loss: -3.6150102615356445
Batch 20/64 loss: -3.759530544281006
Batch 21/64 loss: -3.5491514205932617
Batch 22/64 loss: -3.533388614654541
Batch 23/64 loss: -3.5093936920166016
Batch 24/64 loss: -3.7172985076904297
Batch 25/64 loss: -3.784529685974121
Batch 26/64 loss: -3.4499340057373047
Batch 27/64 loss: -3.723881721496582
Batch 28/64 loss: -3.1776533126831055
Batch 29/64 loss: -3.5475645065307617
Batch 30/64 loss: -3.4618797302246094
Batch 31/64 loss: -3.5042171478271484
Batch 32/64 loss: -3.281217575073242
Batch 33/64 loss: -3.691530227661133
Batch 34/64 loss: -3.6400818824768066
Batch 35/64 loss: -3.4971847534179688
Batch 36/64 loss: -3.646876811981201
Batch 37/64 loss: -3.7300662994384766
Batch 38/64 loss: -3.465841293334961
Batch 39/64 loss: -3.776559352874756
Batch 40/64 loss: -3.5522990226745605
Batch 41/64 loss: -3.5443673133850098
Batch 42/64 loss: -3.7687439918518066
Batch 43/64 loss: -3.02993106842041
Batch 44/64 loss: -3.552277088165283
Batch 45/64 loss: -3.5999536514282227
Batch 46/64 loss: -3.518893241882324
Batch 47/64 loss: -3.512805461883545
Batch 48/64 loss: -3.827275276184082
Batch 49/64 loss: -3.5756773948669434
Batch 50/64 loss: -3.27675724029541
Batch 51/64 loss: -3.332225799560547
Batch 52/64 loss: -3.2077856063842773
Batch 53/64 loss: -3.6751770973205566
Batch 54/64 loss: -3.4640426635742188
Batch 55/64 loss: -3.704023838043213
Batch 56/64 loss: -3.568912982940674
Batch 57/64 loss: -3.714932918548584
Batch 58/64 loss: -3.508045196533203
Batch 59/64 loss: -3.5506935119628906
Batch 60/64 loss: -3.6657309532165527
Batch 61/64 loss: -3.4935827255249023
Batch 62/64 loss: -3.5797672271728516
Batch 63/64 loss: -3.612351417541504
Batch 64/64 loss: -8.067062377929688
Epoch 270  Train loss: -3.6355179580987667  Val loss: -3.94705011426788
Epoch 271
-------------------------------
Batch 1/64 loss: -3.538339614868164
Batch 2/64 loss: -3.4308109283447266
Batch 3/64 loss: -3.3439550399780273
Batch 4/64 loss: -3.6764731407165527
Batch 5/64 loss: -3.760763645172119
Batch 6/64 loss: -3.7886085510253906
Batch 7/64 loss: -3.6256093978881836
Batch 8/64 loss: -3.693032741546631
Batch 9/64 loss: -3.5415000915527344
Batch 10/64 loss: -3.6490135192871094
Batch 11/64 loss: -3.6487011909484863
Batch 12/64 loss: -3.820549488067627
Batch 13/64 loss: -3.6245484352111816
Batch 14/64 loss: -3.6334285736083984
Batch 15/64 loss: -3.819368362426758
Batch 16/64 loss: -3.5128660202026367
Batch 17/64 loss: -3.576765537261963
Batch 18/64 loss: -3.7594165802001953
Batch 19/64 loss: -3.682143211364746
Batch 20/64 loss: -3.4739599227905273
Batch 21/64 loss: -3.600245952606201
Batch 22/64 loss: -3.7760472297668457
Batch 23/64 loss: -3.5248899459838867
Batch 24/64 loss: -3.7599081993103027
Batch 25/64 loss: -3.6537909507751465
Batch 26/64 loss: -3.730597496032715
Batch 27/64 loss: -3.5202083587646484
Batch 28/64 loss: -3.614041805267334
Batch 29/64 loss: -3.5675392150878906
Batch 30/64 loss: -3.6513094902038574
Batch 31/64 loss: -3.4543962478637695
Batch 32/64 loss: -3.8572068214416504
Batch 33/64 loss: -3.5032129287719727
Batch 34/64 loss: -3.5322937965393066
Batch 35/64 loss: -3.6969356536865234
Batch 36/64 loss: -3.3822879791259766
Batch 37/64 loss: -3.56024169921875
Batch 38/64 loss: -3.543707847595215
Batch 39/64 loss: -3.604948043823242
Batch 40/64 loss: -3.6765236854553223
Batch 41/64 loss: -3.2605438232421875
Batch 42/64 loss: -3.662696361541748
Batch 43/64 loss: -3.571937084197998
Batch 44/64 loss: -3.7946696281433105
Batch 45/64 loss: -3.55830717086792
Batch 46/64 loss: -3.702805519104004
Batch 47/64 loss: -3.669628143310547
Batch 48/64 loss: -3.5151028633117676
Batch 49/64 loss: -3.5497841835021973
Batch 50/64 loss: -3.4872875213623047
Batch 51/64 loss: -3.8220863342285156
Batch 52/64 loss: -3.5325183868408203
Batch 53/64 loss: -2.73923397064209
Batch 54/64 loss: -3.5204358100891113
Batch 55/64 loss: -3.841773509979248
Batch 56/64 loss: -3.7460827827453613
Batch 57/64 loss: -3.7051658630371094
Batch 58/64 loss: -3.271836280822754
Batch 59/64 loss: -3.746823787689209
Batch 60/64 loss: -3.6216230392456055
Batch 61/64 loss: -3.512356758117676
Batch 62/64 loss: -3.621732711791992
Batch 63/64 loss: -3.759446620941162
Batch 64/64 loss: -7.722518444061279
Epoch 271  Train loss: -3.652014969844444  Val loss: -3.8950124393214067
Epoch 272
-------------------------------
Batch 1/64 loss: -3.575096607208252
Batch 2/64 loss: -3.2500476837158203
Batch 3/64 loss: -3.5354256629943848
Batch 4/64 loss: -3.6367101669311523
Batch 5/64 loss: -3.2876434326171875
Batch 6/64 loss: -3.2202329635620117
Batch 7/64 loss: -3.658787727355957
Batch 8/64 loss: -3.374396324157715
Batch 9/64 loss: -3.797445297241211
Batch 10/64 loss: -3.610849380493164
Batch 11/64 loss: -3.8004603385925293
Batch 12/64 loss: -3.1918210983276367
Batch 13/64 loss: -3.251432418823242
Batch 14/64 loss: -3.535414218902588
Batch 15/64 loss: -2.943619728088379
Batch 16/64 loss: -3.4847564697265625
Batch 17/64 loss: -3.467020034790039
Batch 18/64 loss: -3.4597177505493164
Batch 19/64 loss: -3.592283248901367
Batch 20/64 loss: -3.8126707077026367
Batch 21/64 loss: -3.64990234375
Batch 22/64 loss: -3.682507038116455
Batch 23/64 loss: -3.679279327392578
Batch 24/64 loss: -3.5302844047546387
Batch 25/64 loss: -3.3339109420776367
Batch 26/64 loss: -3.5302367210388184
Batch 27/64 loss: -3.513988971710205
Batch 28/64 loss: -3.403773307800293
Batch 29/64 loss: -3.7406959533691406
Batch 30/64 loss: -3.610978603363037
Batch 31/64 loss: -3.4888973236083984
Batch 32/64 loss: -3.4240541458129883
Batch 33/64 loss: -3.5947442054748535
Batch 34/64 loss: -3.456310272216797
Batch 35/64 loss: -3.7333908081054688
Batch 36/64 loss: -3.664910316467285
Batch 37/64 loss: -3.60530948638916
Batch 38/64 loss: -3.701404094696045
Batch 39/64 loss: -3.615077495574951
Batch 40/64 loss: -3.4514293670654297
Batch 41/64 loss: -3.5825600624084473
Batch 42/64 loss: -3.7279610633850098
Batch 43/64 loss: -3.572364330291748
Batch 44/64 loss: -3.6328625679016113
Batch 45/64 loss: -3.673525810241699
Batch 46/64 loss: -3.7689623832702637
Batch 47/64 loss: -3.6105971336364746
Batch 48/64 loss: -3.7905426025390625
Batch 49/64 loss: -3.734625816345215
Batch 50/64 loss: -3.4973998069763184
Batch 51/64 loss: -3.6933279037475586
Batch 52/64 loss: -3.5193819999694824
Batch 53/64 loss: -3.7619848251342773
Batch 54/64 loss: -3.71290922164917
Batch 55/64 loss: -3.6282243728637695
Batch 56/64 loss: -3.7186851501464844
Batch 57/64 loss: -3.6482467651367188
Batch 58/64 loss: -3.5608620643615723
Batch 59/64 loss: -3.67098331451416
Batch 60/64 loss: -3.658163547515869
Batch 61/64 loss: -3.6675620079040527
Batch 62/64 loss: -3.709331512451172
Batch 63/64 loss: -3.684619903564453
Batch 64/64 loss: -8.299759864807129
Epoch 272  Train loss: -3.628979144376867  Val loss: -3.9860311160792192
Epoch 273
-------------------------------
Batch 1/64 loss: -3.5026750564575195
Batch 2/64 loss: -3.8670196533203125
Batch 3/64 loss: -3.7466468811035156
Batch 4/64 loss: -3.710484504699707
Batch 5/64 loss: -3.6627650260925293
Batch 6/64 loss: -3.7157235145568848
Batch 7/64 loss: -3.6286401748657227
Batch 8/64 loss: -3.744906425476074
Batch 9/64 loss: -3.8821773529052734
Batch 10/64 loss: -3.777132987976074
Batch 11/64 loss: -3.550365447998047
Batch 12/64 loss: -3.6852312088012695
Batch 13/64 loss: -3.554203510284424
Batch 14/64 loss: -3.66391658782959
Batch 15/64 loss: -3.5482592582702637
Batch 16/64 loss: -3.291921615600586
Batch 17/64 loss: -3.8603200912475586
Batch 18/64 loss: -3.6390795707702637
Batch 19/64 loss: -3.813434600830078
Batch 20/64 loss: -3.5338382720947266
Batch 21/64 loss: -3.3854808807373047
Batch 22/64 loss: -3.767963409423828
Batch 23/64 loss: -3.637155532836914
Batch 24/64 loss: -3.441669464111328
Batch 25/64 loss: -3.6961288452148438
Batch 26/64 loss: -3.403585433959961
Batch 27/64 loss: -3.7440314292907715
Batch 28/64 loss: -3.5502634048461914
Batch 29/64 loss: -3.680936336517334
Batch 30/64 loss: -3.16538143157959
Batch 31/64 loss: -3.6358394622802734
Batch 32/64 loss: -3.7567386627197266
Batch 33/64 loss: -3.6516013145446777
Batch 34/64 loss: -3.65472412109375
Batch 35/64 loss: -3.4685001373291016
Batch 36/64 loss: -3.4594969749450684
Batch 37/64 loss: -3.3978042602539062
Batch 38/64 loss: -3.733940601348877
Batch 39/64 loss: -3.56699800491333
Batch 40/64 loss: -3.548966407775879
Batch 41/64 loss: -3.303420066833496
Batch 42/64 loss: -3.7392735481262207
Batch 43/64 loss: -3.5244884490966797
Batch 44/64 loss: -3.574484348297119
Batch 45/64 loss: -3.5422396659851074
Batch 46/64 loss: -3.336679458618164
Batch 47/64 loss: -3.598759174346924
Batch 48/64 loss: -3.477785587310791
Batch 49/64 loss: -3.5238451957702637
Batch 50/64 loss: -3.6601643562316895
Batch 51/64 loss: -3.770047664642334
Batch 52/64 loss: -3.4875078201293945
Batch 53/64 loss: -3.7421512603759766
Batch 54/64 loss: -3.784593105316162
Batch 55/64 loss: -3.697844982147217
Batch 56/64 loss: -3.845567226409912
Batch 57/64 loss: -3.748472213745117
Batch 58/64 loss: -3.682187080383301
Batch 59/64 loss: -3.4332733154296875
Batch 60/64 loss: -3.7744789123535156
Batch 61/64 loss: -3.581381320953369
Batch 62/64 loss: -3.6172704696655273
Batch 63/64 loss: -3.47971248626709
Batch 64/64 loss: -8.244117736816406
Epoch 273  Train loss: -3.667994727340399  Val loss: -3.9730351503772017
Epoch 274
-------------------------------
Batch 1/64 loss: -3.749936580657959
Batch 2/64 loss: -3.029292106628418
Batch 3/64 loss: -3.6233062744140625
Batch 4/64 loss: -3.7353906631469727
Batch 5/64 loss: -3.8138375282287598
Batch 6/64 loss: -3.5684032440185547
Batch 7/64 loss: -3.714839458465576
Batch 8/64 loss: -3.748973846435547
Batch 9/64 loss: -3.6031060218811035
Batch 10/64 loss: -3.8354177474975586
Batch 11/64 loss: -3.763258457183838
Batch 12/64 loss: -3.437220573425293
Batch 13/64 loss: -3.6881284713745117
Batch 14/64 loss: -3.4306483268737793
Batch 15/64 loss: -3.641127586364746
Batch 16/64 loss: -3.5152230262756348
Batch 17/64 loss: -3.7545299530029297
Batch 18/64 loss: -3.4870829582214355
Batch 19/64 loss: -3.732231616973877
Batch 20/64 loss: -3.3983154296875
Batch 21/64 loss: -3.6033554077148438
Batch 22/64 loss: -3.696742534637451
Batch 23/64 loss: -3.7208027839660645
Batch 24/64 loss: -3.4618449211120605
Batch 25/64 loss: -3.2897682189941406
Batch 26/64 loss: -3.3195323944091797
Batch 27/64 loss: -3.6841864585876465
Batch 28/64 loss: -3.6526055335998535
Batch 29/64 loss: -3.7619643211364746
Batch 30/64 loss: -3.5619993209838867
Batch 31/64 loss: -3.379500389099121
Batch 32/64 loss: -3.340017318725586
Batch 33/64 loss: -3.5792369842529297
Batch 34/64 loss: -3.7069826126098633
Batch 35/64 loss: -3.494983673095703
Batch 36/64 loss: -3.5915260314941406
Batch 37/64 loss: -3.6404166221618652
Batch 38/64 loss: -3.64443302154541
Batch 39/64 loss: -3.7023348808288574
Batch 40/64 loss: -3.60538387298584
Batch 41/64 loss: -3.534310817718506
Batch 42/64 loss: -3.722500801086426
Batch 43/64 loss: -3.5461063385009766
Batch 44/64 loss: -3.6964406967163086
Batch 45/64 loss: -3.4935197830200195
Batch 46/64 loss: -2.4173202514648438
Batch 47/64 loss: -3.531208038330078
Batch 48/64 loss: -3.5239057540893555
Batch 49/64 loss: -3.6549086570739746
Batch 50/64 loss: -3.5227861404418945
Batch 51/64 loss: -3.4797987937927246
Batch 52/64 loss: -3.5230207443237305
Batch 53/64 loss: -2.852886199951172
Batch 54/64 loss: -3.7286767959594727
Batch 55/64 loss: -3.7487478256225586
Batch 56/64 loss: -3.5900635719299316
Batch 57/64 loss: -3.342963218688965
Batch 58/64 loss: -3.6847238540649414
Batch 59/64 loss: -3.7178659439086914
Batch 60/64 loss: -3.9926562309265137
Batch 61/64 loss: -3.718547821044922
Batch 62/64 loss: -3.5861520767211914
Batch 63/64 loss: -3.7504043579101562
Batch 64/64 loss: -8.092008590698242
Epoch 274  Train loss: -3.6256691502589806  Val loss: -3.9538828269722535
Epoch 275
-------------------------------
Batch 1/64 loss: -3.415652275085449
Batch 2/64 loss: -3.767009735107422
Batch 3/64 loss: -3.697782039642334
Batch 4/64 loss: -3.54525089263916
Batch 5/64 loss: -3.4354772567749023
Batch 6/64 loss: -3.8556714057922363
Batch 7/64 loss: -3.741257667541504
Batch 8/64 loss: -3.513734817504883
Batch 9/64 loss: -3.5407156944274902
Batch 10/64 loss: -3.6684279441833496
Batch 11/64 loss: -3.7526674270629883
Batch 12/64 loss: -3.6927618980407715
Batch 13/64 loss: -3.9587206840515137
Batch 14/64 loss: -3.5988707542419434
Batch 15/64 loss: -3.473684310913086
Batch 16/64 loss: -3.558962345123291
Batch 17/64 loss: -3.503671646118164
Batch 18/64 loss: -3.710665702819824
Batch 19/64 loss: -3.6248350143432617
Batch 20/64 loss: -3.4176859855651855
Batch 21/64 loss: -3.4925355911254883
Batch 22/64 loss: -3.864284038543701
Batch 23/64 loss: -3.773858070373535
Batch 24/64 loss: -3.7440314292907715
Batch 25/64 loss: -3.5768370628356934
Batch 26/64 loss: -3.820354461669922
Batch 27/64 loss: -3.7860894203186035
Batch 28/64 loss: -3.5691490173339844
Batch 29/64 loss: -3.63346529006958
Batch 30/64 loss: -3.6598358154296875
Batch 31/64 loss: -3.365410804748535
Batch 32/64 loss: -3.7766075134277344
Batch 33/64 loss: -3.788998603820801
Batch 34/64 loss: -3.5242671966552734
Batch 35/64 loss: -3.770357608795166
Batch 36/64 loss: -3.430272102355957
Batch 37/64 loss: -3.4160919189453125
Batch 38/64 loss: -3.6317601203918457
Batch 39/64 loss: -3.502028465270996
Batch 40/64 loss: -3.5782012939453125
Batch 41/64 loss: -3.5052413940429688
Batch 42/64 loss: -3.736508369445801
Batch 43/64 loss: -3.5629830360412598
Batch 44/64 loss: -3.491722583770752
Batch 45/64 loss: -3.763711929321289
Batch 46/64 loss: -3.4424800872802734
Batch 47/64 loss: -3.447544574737549
Batch 48/64 loss: -3.6887941360473633
Batch 49/64 loss: -3.4655709266662598
Batch 50/64 loss: -3.7062902450561523
Batch 51/64 loss: -3.8678412437438965
Batch 52/64 loss: -3.691128730773926
Batch 53/64 loss: -3.7631468772888184
Batch 54/64 loss: -3.8023834228515625
Batch 55/64 loss: -3.683488368988037
Batch 56/64 loss: -3.8974804878234863
Batch 57/64 loss: -3.5544514656066895
Batch 58/64 loss: -3.7853612899780273
Batch 59/64 loss: -3.680655002593994
Batch 60/64 loss: -3.432210922241211
Batch 61/64 loss: -3.5913333892822266
Batch 62/64 loss: -3.527646541595459
Batch 63/64 loss: -3.5883736610412598
Batch 64/64 loss: -8.208784103393555
Epoch 275  Train loss: -3.686445146448472  Val loss: -4.023719630290553
Epoch 276
-------------------------------
Batch 1/64 loss: -3.5823616981506348
Batch 2/64 loss: -3.651427745819092
Batch 3/64 loss: -3.843137741088867
Batch 4/64 loss: -3.644298553466797
Batch 5/64 loss: -3.9638915061950684
Batch 6/64 loss: -3.447564125061035
Batch 7/64 loss: -3.5424957275390625
Batch 8/64 loss: -3.8415727615356445
Batch 9/64 loss: -3.6010074615478516
Batch 10/64 loss: -3.797408103942871
Batch 11/64 loss: -3.4798107147216797
Batch 12/64 loss: -3.811375141143799
Batch 13/64 loss: -3.892941474914551
Batch 14/64 loss: -3.6767630577087402
Batch 15/64 loss: -3.81427001953125
Batch 16/64 loss: -3.774538040161133
Batch 17/64 loss: -3.9007253646850586
Batch 18/64 loss: -3.7307381629943848
Batch 19/64 loss: -3.748293876647949
Batch 20/64 loss: -3.749650001525879
Batch 21/64 loss: -3.7137250900268555
Batch 22/64 loss: -3.255054473876953
Batch 23/64 loss: -3.8630151748657227
Batch 24/64 loss: -3.777914047241211
Batch 25/64 loss: -3.5436182022094727
Batch 26/64 loss: -3.922959804534912
Batch 27/64 loss: -3.7787599563598633
Batch 28/64 loss: -3.842276096343994
Batch 29/64 loss: -3.951416492462158
Batch 30/64 loss: -3.8430514335632324
Batch 31/64 loss: -3.777637481689453
Batch 32/64 loss: -3.6985526084899902
Batch 33/64 loss: -3.5989484786987305
Batch 34/64 loss: -3.8294944763183594
Batch 35/64 loss: -3.8994140625
Batch 36/64 loss: -3.6907029151916504
Batch 37/64 loss: -3.939697742462158
Batch 38/64 loss: -3.657957077026367
Batch 39/64 loss: -3.7303390502929688
Batch 40/64 loss: -3.3815155029296875
Batch 41/64 loss: -3.855989456176758
Batch 42/64 loss: -3.836564064025879
Batch 43/64 loss: -3.9275827407836914
Batch 44/64 loss: -3.6931071281433105
Batch 45/64 loss: -3.5504374504089355
Batch 46/64 loss: -3.7179346084594727
Batch 47/64 loss: -3.8641061782836914
Batch 48/64 loss: -3.8747239112854004
Batch 49/64 loss: -3.8692140579223633
Batch 50/64 loss: -3.7814273834228516
Batch 51/64 loss: -3.303098678588867
Batch 52/64 loss: -3.774756908416748
Batch 53/64 loss: -3.8358778953552246
Batch 54/64 loss: -3.8307700157165527
Batch 55/64 loss: -3.4709043502807617
Batch 56/64 loss: -3.511228561401367
Batch 57/64 loss: -3.8231358528137207
Batch 58/64 loss: -3.6127939224243164
Batch 59/64 loss: -3.870634078979492
Batch 60/64 loss: -3.637974262237549
Batch 61/64 loss: -3.600526809692383
Batch 62/64 loss: -3.755582809448242
Batch 63/64 loss: -3.5894455909729004
Batch 64/64 loss: -8.258304595947266
Epoch 276  Train loss: -3.7799508487477023  Val loss: -4.121985799258518
Saving best model, epoch: 276
Epoch 277
-------------------------------
Batch 1/64 loss: -3.6769800186157227
Batch 2/64 loss: -3.810086727142334
Batch 3/64 loss: -3.6153717041015625
Batch 4/64 loss: -3.8571128845214844
Batch 5/64 loss: -3.8082103729248047
Batch 6/64 loss: -3.6323699951171875
Batch 7/64 loss: -3.373472213745117
Batch 8/64 loss: -3.7476725578308105
Batch 9/64 loss: -3.789335250854492
Batch 10/64 loss: -3.6203675270080566
Batch 11/64 loss: -3.803689479827881
Batch 12/64 loss: -3.647487163543701
Batch 13/64 loss: -3.736452102661133
Batch 14/64 loss: -3.823535442352295
Batch 15/64 loss: -3.164165496826172
Batch 16/64 loss: -3.6682868003845215
Batch 17/64 loss: -3.759037494659424
Batch 18/64 loss: -3.7613015174865723
Batch 19/64 loss: -3.813831329345703
Batch 20/64 loss: -3.684861183166504
Batch 21/64 loss: -3.7176222801208496
Batch 22/64 loss: -3.7099485397338867
Batch 23/64 loss: -3.861151695251465
Batch 24/64 loss: -3.6254563331604004
Batch 25/64 loss: -3.775279998779297
Batch 26/64 loss: -3.627185821533203
Batch 27/64 loss: -3.5191431045532227
Batch 28/64 loss: -3.59694766998291
Batch 29/64 loss: -3.6467466354370117
Batch 30/64 loss: -3.6736230850219727
Batch 31/64 loss: -3.757279396057129
Batch 32/64 loss: -3.798546314239502
Batch 33/64 loss: -2.735976219177246
Batch 34/64 loss: -3.8561534881591797
Batch 35/64 loss: -3.6858930587768555
Batch 36/64 loss: -3.7906885147094727
Batch 37/64 loss: -3.9453511238098145
Batch 38/64 loss: -3.773486614227295
Batch 39/64 loss: -3.4094953536987305
Batch 40/64 loss: -3.954721450805664
Batch 41/64 loss: -3.692193031311035
Batch 42/64 loss: -3.625202178955078
Batch 43/64 loss: -3.538609027862549
Batch 44/64 loss: -3.8135457038879395
Batch 45/64 loss: -3.8320298194885254
Batch 46/64 loss: -3.957489013671875
Batch 47/64 loss: -3.6740474700927734
Batch 48/64 loss: -3.612964630126953
Batch 49/64 loss: -3.4485931396484375
Batch 50/64 loss: -3.9083776473999023
Batch 51/64 loss: -3.8620471954345703
Batch 52/64 loss: -3.7147254943847656
Batch 53/64 loss: -3.9187841415405273
Batch 54/64 loss: -3.7401976585388184
Batch 55/64 loss: -3.487894058227539
Batch 56/64 loss: -3.7223153114318848
Batch 57/64 loss: -3.665485382080078
Batch 58/64 loss: -3.741304397583008
Batch 59/64 loss: -3.9096055030822754
Batch 60/64 loss: -3.7506399154663086
Batch 61/64 loss: -3.6553125381469727
Batch 62/64 loss: -3.6878981590270996
Batch 63/64 loss: -3.7435035705566406
Batch 64/64 loss: -8.419303894042969
Epoch 277  Train loss: -3.7532794802796605  Val loss: -4.032454552929016
Epoch 278
-------------------------------
Batch 1/64 loss: -3.7695932388305664
Batch 2/64 loss: -3.568913459777832
Batch 3/64 loss: -3.6485133171081543
Batch 4/64 loss: -3.770339012145996
Batch 5/64 loss: -3.6184616088867188
Batch 6/64 loss: -3.6235885620117188
Batch 7/64 loss: -3.594933032989502
Batch 8/64 loss: -3.7909817695617676
Batch 9/64 loss: -3.8681225776672363
Batch 10/64 loss: -3.399242401123047
Batch 11/64 loss: -3.7408266067504883
Batch 12/64 loss: -3.8055524826049805
Batch 13/64 loss: -3.352935791015625
Batch 14/64 loss: -3.8456921577453613
Batch 15/64 loss: -3.748718738555908
Batch 16/64 loss: -3.571086883544922
Batch 17/64 loss: -3.645740509033203
Batch 18/64 loss: -3.976119041442871
Batch 19/64 loss: -3.7466955184936523
Batch 20/64 loss: -3.7344260215759277
Batch 21/64 loss: -3.455965995788574
Batch 22/64 loss: -3.578385829925537
Batch 23/64 loss: -3.8503527641296387
Batch 24/64 loss: -3.8064475059509277
Batch 25/64 loss: -3.7843756675720215
Batch 26/64 loss: -3.8917646408081055
Batch 27/64 loss: -3.7951626777648926
Batch 28/64 loss: -3.5519890785217285
Batch 29/64 loss: -3.681854248046875
Batch 30/64 loss: -3.573777198791504
Batch 31/64 loss: -3.580474376678467
Batch 32/64 loss: -3.8306078910827637
Batch 33/64 loss: -3.72251033782959
Batch 34/64 loss: -3.8618907928466797
Batch 35/64 loss: -3.712040424346924
Batch 36/64 loss: -3.832645893096924
Batch 37/64 loss: -3.9061646461486816
Batch 38/64 loss: -3.552424430847168
Batch 39/64 loss: -3.2875852584838867
Batch 40/64 loss: -3.6179885864257812
Batch 41/64 loss: -3.5568013191223145
Batch 42/64 loss: -3.854012966156006
Batch 43/64 loss: -3.72965669631958
Batch 44/64 loss: -3.728787899017334
Batch 45/64 loss: -3.8012032508850098
Batch 46/64 loss: -3.5723228454589844
Batch 47/64 loss: -3.7803382873535156
Batch 48/64 loss: -3.7212324142456055
Batch 49/64 loss: -3.8277125358581543
Batch 50/64 loss: -3.78810977935791
Batch 51/64 loss: -3.869567394256592
Batch 52/64 loss: -3.584611415863037
Batch 53/64 loss: -3.7571511268615723
Batch 54/64 loss: -3.7976226806640625
Batch 55/64 loss: -3.639721393585205
Batch 56/64 loss: -3.8324341773986816
Batch 57/64 loss: -3.6726856231689453
Batch 58/64 loss: -3.769893169403076
Batch 59/64 loss: -3.7349700927734375
Batch 60/64 loss: -3.6414756774902344
Batch 61/64 loss: -3.7300400733947754
Batch 62/64 loss: -3.132944107055664
Batch 63/64 loss: -3.6602163314819336
Batch 64/64 loss: -8.220733642578125
Epoch 278  Train loss: -3.7497090582754096  Val loss: -4.068866034963286
Epoch 279
-------------------------------
Batch 1/64 loss: -3.722055435180664
Batch 2/64 loss: -3.5225391387939453
Batch 3/64 loss: -3.5925722122192383
Batch 4/64 loss: -3.937199115753174
Batch 5/64 loss: -3.6691102981567383
Batch 6/64 loss: -3.8929357528686523
Batch 7/64 loss: -3.8236727714538574
Batch 8/64 loss: -3.673520565032959
Batch 9/64 loss: -3.7081241607666016
Batch 10/64 loss: -3.7500877380371094
Batch 11/64 loss: -3.440394401550293
Batch 12/64 loss: -3.8682045936584473
Batch 13/64 loss: -3.748322010040283
Batch 14/64 loss: -3.710857391357422
Batch 15/64 loss: -3.9442644119262695
Batch 16/64 loss: -3.5510635375976562
Batch 17/64 loss: -3.7831873893737793
Batch 18/64 loss: -3.6908674240112305
Batch 19/64 loss: -3.7241291999816895
Batch 20/64 loss: -3.8098196983337402
Batch 21/64 loss: -3.469813346862793
Batch 22/64 loss: -3.817904472351074
Batch 23/64 loss: -3.6604413986206055
Batch 24/64 loss: -3.786149501800537
Batch 25/64 loss: -3.8758225440979004
Batch 26/64 loss: -3.7827372550964355
Batch 27/64 loss: -3.7027530670166016
Batch 28/64 loss: -3.460818290710449
Batch 29/64 loss: -3.8295974731445312
Batch 30/64 loss: -3.579150676727295
Batch 31/64 loss: -3.7227916717529297
Batch 32/64 loss: -3.7531485557556152
Batch 33/64 loss: -3.8127660751342773
Batch 34/64 loss: -3.863142490386963
Batch 35/64 loss: -3.4745054244995117
Batch 36/64 loss: -4.037351131439209
Batch 37/64 loss: -3.8515987396240234
Batch 38/64 loss: -3.8574209213256836
Batch 39/64 loss: -3.7227773666381836
Batch 40/64 loss: -3.9343719482421875
Batch 41/64 loss: -3.7722091674804688
Batch 42/64 loss: -3.843611240386963
Batch 43/64 loss: -3.8424339294433594
Batch 44/64 loss: -3.748448371887207
Batch 45/64 loss: -3.435626983642578
Batch 46/64 loss: -3.9551496505737305
Batch 47/64 loss: -3.8900680541992188
Batch 48/64 loss: -3.4803600311279297
Batch 49/64 loss: -3.8128552436828613
Batch 50/64 loss: -3.644601821899414
Batch 51/64 loss: -3.9621658325195312
Batch 52/64 loss: -3.83134126663208
Batch 53/64 loss: -3.7097835540771484
Batch 54/64 loss: -3.8970084190368652
Batch 55/64 loss: -3.580531120300293
Batch 56/64 loss: -3.7200350761413574
Batch 57/64 loss: -3.7649497985839844
Batch 58/64 loss: -4.072080612182617
Batch 59/64 loss: -3.599234104156494
Batch 60/64 loss: -3.964979648590088
Batch 61/64 loss: -3.670989990234375
Batch 62/64 loss: -3.4249868392944336
Batch 63/64 loss: -3.6032752990722656
Batch 64/64 loss: -8.32703971862793
Epoch 279  Train loss: -3.796548948100969  Val loss: -4.034551967869919
Epoch 280
-------------------------------
Batch 1/64 loss: -3.940739154815674
Batch 2/64 loss: -3.446929931640625
Batch 3/64 loss: -3.734713077545166
Batch 4/64 loss: -3.4698424339294434
Batch 5/64 loss: -3.606627941131592
Batch 6/64 loss: -3.893458366394043
Batch 7/64 loss: -3.8922863006591797
Batch 8/64 loss: -3.709540367126465
Batch 9/64 loss: -3.774139404296875
Batch 10/64 loss: -3.8630857467651367
Batch 11/64 loss: -3.8668723106384277
Batch 12/64 loss: -3.452061653137207
Batch 13/64 loss: -3.8350863456726074
Batch 14/64 loss: -3.496427059173584
Batch 15/64 loss: -3.489014148712158
Batch 16/64 loss: -3.5962014198303223
Batch 17/64 loss: -3.579049587249756
Batch 18/64 loss: -3.7974772453308105
Batch 19/64 loss: -3.6700286865234375
Batch 20/64 loss: -3.942455768585205
Batch 21/64 loss: -3.8836140632629395
Batch 22/64 loss: -3.6493024826049805
Batch 23/64 loss: -3.769451141357422
Batch 24/64 loss: -3.732309341430664
Batch 25/64 loss: -3.828613758087158
Batch 26/64 loss: -3.4497318267822266
Batch 27/64 loss: -3.5111827850341797
Batch 28/64 loss: -3.6623072624206543
Batch 29/64 loss: -3.981048107147217
Batch 30/64 loss: -3.8850488662719727
Batch 31/64 loss: -3.7635598182678223
Batch 32/64 loss: -3.911616802215576
Batch 33/64 loss: -3.9089179039001465
Batch 34/64 loss: -3.660393238067627
Batch 35/64 loss: -3.8222241401672363
Batch 36/64 loss: -3.7806549072265625
Batch 37/64 loss: -3.776233673095703
Batch 38/64 loss: -3.8770952224731445
Batch 39/64 loss: -3.8647899627685547
Batch 40/64 loss: -3.8618946075439453
Batch 41/64 loss: -3.6393775939941406
Batch 42/64 loss: -3.493053436279297
Batch 43/64 loss: -3.4425106048583984
Batch 44/64 loss: -3.613140106201172
Batch 45/64 loss: -3.8153247833251953
Batch 46/64 loss: -3.5429792404174805
Batch 47/64 loss: -4.037047863006592
Batch 48/64 loss: -3.827972888946533
Batch 49/64 loss: -3.7585253715515137
Batch 50/64 loss: -3.3426456451416016
Batch 51/64 loss: -3.8729400634765625
Batch 52/64 loss: -3.8344664573669434
Batch 53/64 loss: -3.72676420211792
Batch 54/64 loss: -3.857945442199707
Batch 55/64 loss: -3.7928967475891113
Batch 56/64 loss: -3.728516101837158
Batch 57/64 loss: -3.7500052452087402
Batch 58/64 loss: -3.6463613510131836
Batch 59/64 loss: -3.497464179992676
Batch 60/64 loss: -3.896970272064209
Batch 61/64 loss: -3.609065055847168
Batch 62/64 loss: -3.843174934387207
Batch 63/64 loss: -3.6648292541503906
Batch 64/64 loss: -8.228799819946289
Epoch 280  Train loss: -3.7810447618073106  Val loss: -4.1255629496885735
Saving best model, epoch: 280
Epoch 281
-------------------------------
Batch 1/64 loss: -3.9824981689453125
Batch 2/64 loss: -3.3460426330566406
Batch 3/64 loss: -3.536410331726074
Batch 4/64 loss: -3.639327049255371
Batch 5/64 loss: -3.5627670288085938
Batch 6/64 loss: -3.964080810546875
Batch 7/64 loss: -3.9015722274780273
Batch 8/64 loss: -3.7045912742614746
Batch 9/64 loss: -3.675589084625244
Batch 10/64 loss: -4.06605339050293
Batch 11/64 loss: -3.801912307739258
Batch 12/64 loss: -3.697721481323242
Batch 13/64 loss: -3.807865619659424
Batch 14/64 loss: -3.804777145385742
Batch 15/64 loss: -3.534224510192871
Batch 16/64 loss: -3.6251912117004395
Batch 17/64 loss: -3.8258962631225586
Batch 18/64 loss: -3.8778457641601562
Batch 19/64 loss: -3.4458560943603516
Batch 20/64 loss: -3.961254596710205
Batch 21/64 loss: -3.896811008453369
Batch 22/64 loss: -3.8017630577087402
Batch 23/64 loss: -3.765158176422119
Batch 24/64 loss: -3.81512451171875
Batch 25/64 loss: -3.7188076972961426
Batch 26/64 loss: -3.786498546600342
Batch 27/64 loss: -3.763606071472168
Batch 28/64 loss: -3.8000192642211914
Batch 29/64 loss: -3.875458240509033
Batch 30/64 loss: -3.9478564262390137
Batch 31/64 loss: -3.778841018676758
Batch 32/64 loss: -3.8736190795898438
Batch 33/64 loss: -3.69199800491333
Batch 34/64 loss: -3.884927272796631
Batch 35/64 loss: -3.715432643890381
Batch 36/64 loss: -3.7985029220581055
Batch 37/64 loss: -3.9686927795410156
Batch 38/64 loss: -3.457273483276367
Batch 39/64 loss: -3.78218412399292
Batch 40/64 loss: -3.5515785217285156
Batch 41/64 loss: -3.827603816986084
Batch 42/64 loss: -3.6519360542297363
Batch 43/64 loss: -3.816826820373535
Batch 44/64 loss: -3.8104476928710938
Batch 45/64 loss: -3.6953344345092773
Batch 46/64 loss: -3.7454824447631836
Batch 47/64 loss: -3.6801962852478027
Batch 48/64 loss: -3.7168169021606445
Batch 49/64 loss: -3.7276077270507812
Batch 50/64 loss: -3.65444278717041
Batch 51/64 loss: -3.7899584770202637
Batch 52/64 loss: -3.6752867698669434
Batch 53/64 loss: -3.7093262672424316
Batch 54/64 loss: -3.3736572265625
Batch 55/64 loss: -3.8435721397399902
Batch 56/64 loss: -3.5772881507873535
Batch 57/64 loss: -3.6411075592041016
Batch 58/64 loss: -3.4538373947143555
Batch 59/64 loss: -3.9038124084472656
Batch 60/64 loss: -3.6811275482177734
Batch 61/64 loss: -3.6825428009033203
Batch 62/64 loss: -3.661344051361084
Batch 63/64 loss: -3.7317280769348145
Batch 64/64 loss: -8.443506240844727
Epoch 281  Train loss: -3.793247739006491  Val loss: -4.016089108391726
Epoch 282
-------------------------------
Batch 1/64 loss: -3.862649917602539
Batch 2/64 loss: -3.6982851028442383
Batch 3/64 loss: -3.6289844512939453
Batch 4/64 loss: -3.7408409118652344
Batch 5/64 loss: -3.6839847564697266
Batch 6/64 loss: -3.3993844985961914
Batch 7/64 loss: -3.709366798400879
Batch 8/64 loss: -3.6512203216552734
Batch 9/64 loss: -3.5070548057556152
Batch 10/64 loss: -3.777513027191162
Batch 11/64 loss: -3.4687538146972656
Batch 12/64 loss: -3.6632680892944336
Batch 13/64 loss: -3.873722553253174
Batch 14/64 loss: -3.9118871688842773
Batch 15/64 loss: -3.7185726165771484
Batch 16/64 loss: -3.604384422302246
Batch 17/64 loss: -3.339564323425293
Batch 18/64 loss: -3.6248836517333984
Batch 19/64 loss: -3.89794921875
Batch 20/64 loss: -3.989597797393799
Batch 21/64 loss: -3.0465431213378906
Batch 22/64 loss: -3.7716140747070312
Batch 23/64 loss: -3.7540555000305176
Batch 24/64 loss: -3.9319405555725098
Batch 25/64 loss: -3.9933810234069824
Batch 26/64 loss: -3.8689794540405273
Batch 27/64 loss: -3.814465045928955
Batch 28/64 loss: -3.682833671569824
Batch 29/64 loss: -3.9518628120422363
Batch 30/64 loss: -3.8924946784973145
Batch 31/64 loss: -3.491802215576172
Batch 32/64 loss: -3.8209457397460938
Batch 33/64 loss: -3.8789591789245605
Batch 34/64 loss: -3.964930534362793
Batch 35/64 loss: -3.7239527702331543
Batch 36/64 loss: -3.8037919998168945
Batch 37/64 loss: -4.021692752838135
Batch 38/64 loss: -3.8858280181884766
Batch 39/64 loss: -3.788752555847168
Batch 40/64 loss: -3.678192615509033
Batch 41/64 loss: -3.730696201324463
Batch 42/64 loss: -3.8634867668151855
Batch 43/64 loss: -3.784003257751465
Batch 44/64 loss: -3.606910228729248
Batch 45/64 loss: -3.643761157989502
Batch 46/64 loss: -3.603241443634033
Batch 47/64 loss: -3.7181711196899414
Batch 48/64 loss: -3.77730655670166
Batch 49/64 loss: -3.76123046875
Batch 50/64 loss: -3.8707051277160645
Batch 51/64 loss: -3.873326301574707
Batch 52/64 loss: -3.603794574737549
Batch 53/64 loss: -3.495645523071289
Batch 54/64 loss: -3.853349208831787
Batch 55/64 loss: -3.701791286468506
Batch 56/64 loss: -3.7677125930786133
Batch 57/64 loss: -3.662858486175537
Batch 58/64 loss: -3.769620418548584
Batch 59/64 loss: -3.927938461303711
Batch 60/64 loss: -3.759561538696289
Batch 61/64 loss: -3.8418173789978027
Batch 62/64 loss: -3.7808876037597656
Batch 63/64 loss: -3.55824613571167
Batch 64/64 loss: -8.317192077636719
Epoch 282  Train loss: -3.7915739994423063  Val loss: -4.072941704714012
Epoch 283
-------------------------------
Batch 1/64 loss: -3.8442602157592773
Batch 2/64 loss: -3.803157329559326
Batch 3/64 loss: -3.9269371032714844
Batch 4/64 loss: -3.3651485443115234
Batch 5/64 loss: -3.705427646636963
Batch 6/64 loss: -3.8428845405578613
Batch 7/64 loss: -3.6676554679870605
Batch 8/64 loss: -3.624760627746582
Batch 9/64 loss: -3.572044849395752
Batch 10/64 loss: -3.804014205932617
Batch 11/64 loss: -3.6215410232543945
Batch 12/64 loss: -3.684469223022461
Batch 13/64 loss: -3.8508505821228027
Batch 14/64 loss: -3.7621231079101562
Batch 15/64 loss: -3.601738452911377
Batch 16/64 loss: -3.622591972351074
Batch 17/64 loss: -3.854670524597168
Batch 18/64 loss: -3.8032827377319336
Batch 19/64 loss: -3.859321117401123
Batch 20/64 loss: -3.7431740760803223
Batch 21/64 loss: -3.8053536415100098
Batch 22/64 loss: -3.9777474403381348
Batch 23/64 loss: -3.828294277191162
Batch 24/64 loss: -3.8181676864624023
Batch 25/64 loss: -3.801884651184082
Batch 26/64 loss: -3.827572822570801
Batch 27/64 loss: -3.7733592987060547
Batch 28/64 loss: -3.7612485885620117
Batch 29/64 loss: -3.5740389823913574
Batch 30/64 loss: -3.813575267791748
Batch 31/64 loss: -3.7472872734069824
Batch 32/64 loss: -3.7903871536254883
Batch 33/64 loss: -3.7037439346313477
Batch 34/64 loss: -3.520813465118408
Batch 35/64 loss: -3.6855554580688477
Batch 36/64 loss: -3.6010794639587402
Batch 37/64 loss: -3.5807275772094727
Batch 38/64 loss: -3.1595592498779297
Batch 39/64 loss: -3.6477198600769043
Batch 40/64 loss: -3.6098012924194336
Batch 41/64 loss: -3.897982120513916
Batch 42/64 loss: -3.6547765731811523
Batch 43/64 loss: -3.6434121131896973
Batch 44/64 loss: -3.590104103088379
Batch 45/64 loss: -3.222182273864746
Batch 46/64 loss: -3.6166229248046875
Batch 47/64 loss: -3.608981132507324
Batch 48/64 loss: -3.77390193939209
Batch 49/64 loss: -3.9792933464050293
Batch 50/64 loss: -3.2945642471313477
Batch 51/64 loss: -3.6697778701782227
Batch 52/64 loss: -3.1438331604003906
Batch 53/64 loss: -3.6849842071533203
Batch 54/64 loss: -3.755995750427246
Batch 55/64 loss: -3.820974826812744
Batch 56/64 loss: -3.675415515899658
Batch 57/64 loss: -3.802633285522461
Batch 58/64 loss: -3.6957955360412598
Batch 59/64 loss: -3.480924606323242
Batch 60/64 loss: -3.451671600341797
Batch 61/64 loss: -3.723310947418213
Batch 62/64 loss: -3.643223762512207
Batch 63/64 loss: -3.7140345573425293
Batch 64/64 loss: -8.307279586791992
Epoch 283  Train loss: -3.7390247344970704  Val loss: -4.103184231368127
Epoch 284
-------------------------------
Batch 1/64 loss: -3.6905126571655273
Batch 2/64 loss: -3.653275966644287
Batch 3/64 loss: -3.6800589561462402
Batch 4/64 loss: -3.7366504669189453
Batch 5/64 loss: -3.642355442047119
Batch 6/64 loss: -3.636033058166504
Batch 7/64 loss: -3.491830825805664
Batch 8/64 loss: -3.170109748840332
Batch 9/64 loss: -3.5339808464050293
Batch 10/64 loss: -3.6207356452941895
Batch 11/64 loss: -3.8021206855773926
Batch 12/64 loss: -3.950770378112793
Batch 13/64 loss: -3.663790702819824
Batch 14/64 loss: -3.7450475692749023
Batch 15/64 loss: -3.4845314025878906
Batch 16/64 loss: -3.759577751159668
Batch 17/64 loss: -3.4192676544189453
Batch 18/64 loss: -3.7237935066223145
Batch 19/64 loss: -3.3509960174560547
Batch 20/64 loss: -3.3528480529785156
Batch 21/64 loss: -3.745340347290039
Batch 22/64 loss: -3.7838211059570312
Batch 23/64 loss: -3.4314498901367188
Batch 24/64 loss: -3.7674760818481445
Batch 25/64 loss: -3.616262435913086
Batch 26/64 loss: -3.83060884475708
Batch 27/64 loss: -3.2911338806152344
Batch 28/64 loss: -3.531991958618164
Batch 29/64 loss: -3.713740825653076
Batch 30/64 loss: -3.7184300422668457
Batch 31/64 loss: -3.8586020469665527
Batch 32/64 loss: -3.677401065826416
Batch 33/64 loss: -3.6874265670776367
Batch 34/64 loss: -3.765089988708496
Batch 35/64 loss: -3.6654415130615234
Batch 36/64 loss: -3.91534423828125
Batch 37/64 loss: -3.738846778869629
Batch 38/64 loss: -3.775240421295166
Batch 39/64 loss: -3.6971001625061035
Batch 40/64 loss: -3.4386043548583984
Batch 41/64 loss: -3.7992773056030273
Batch 42/64 loss: -3.6726832389831543
Batch 43/64 loss: -3.824828624725342
Batch 44/64 loss: -3.6547417640686035
Batch 45/64 loss: -3.5889062881469727
Batch 46/64 loss: -3.7599735260009766
Batch 47/64 loss: -3.606753349304199
Batch 48/64 loss: -3.786041736602783
Batch 49/64 loss: -3.528627872467041
Batch 50/64 loss: -3.709129810333252
Batch 51/64 loss: -3.7442374229431152
Batch 52/64 loss: -3.836329460144043
Batch 53/64 loss: -3.481870651245117
Batch 54/64 loss: -3.4407119750976562
Batch 55/64 loss: -3.7583446502685547
Batch 56/64 loss: -3.867002010345459
Batch 57/64 loss: -3.850686550140381
Batch 58/64 loss: -3.855046272277832
Batch 59/64 loss: -3.81003999710083
Batch 60/64 loss: -3.8420467376708984
Batch 61/64 loss: -3.7179532051086426
Batch 62/64 loss: -3.4629135131835938
Batch 63/64 loss: -3.8785367012023926
Batch 64/64 loss: -8.220623016357422
Epoch 284  Train loss: -3.723918271532246  Val loss: -4.129356567802298
Saving best model, epoch: 284
Epoch 285
-------------------------------
Batch 1/64 loss: -3.8366217613220215
Batch 2/64 loss: -3.8516640663146973
Batch 3/64 loss: -3.9249138832092285
Batch 4/64 loss: -3.772861957550049
Batch 5/64 loss: -3.7193875312805176
Batch 6/64 loss: -3.796164035797119
Batch 7/64 loss: -3.576415538787842
Batch 8/64 loss: -3.842606544494629
Batch 9/64 loss: -3.9586739540100098
Batch 10/64 loss: -3.512197494506836
Batch 11/64 loss: -3.7449684143066406
Batch 12/64 loss: -3.6137161254882812
Batch 13/64 loss: -3.5696682929992676
Batch 14/64 loss: -3.8564252853393555
Batch 15/64 loss: -3.8685145378112793
Batch 16/64 loss: -3.7877488136291504
Batch 17/64 loss: -3.9393672943115234
Batch 18/64 loss: -3.643700122833252
Batch 19/64 loss: -3.8743295669555664
Batch 20/64 loss: -3.570364475250244
Batch 21/64 loss: -3.6881279945373535
Batch 22/64 loss: -3.8483972549438477
Batch 23/64 loss: -3.8651113510131836
Batch 24/64 loss: -3.683526039123535
Batch 25/64 loss: -3.8539981842041016
Batch 26/64 loss: -3.7212095260620117
Batch 27/64 loss: -3.590167999267578
Batch 28/64 loss: -3.3729400634765625
Batch 29/64 loss: -3.7691121101379395
Batch 30/64 loss: -3.868053436279297
Batch 31/64 loss: -3.674069404602051
Batch 32/64 loss: -3.6622323989868164
Batch 33/64 loss: -3.9277291297912598
Batch 34/64 loss: -3.5017809867858887
Batch 35/64 loss: -3.6640095710754395
Batch 36/64 loss: -3.678384780883789
Batch 37/64 loss: -3.844536304473877
Batch 38/64 loss: -3.8053765296936035
Batch 39/64 loss: -3.804636001586914
Batch 40/64 loss: -3.6389307975769043
Batch 41/64 loss: -3.6513381004333496
Batch 42/64 loss: -3.7357778549194336
Batch 43/64 loss: -3.67623233795166
Batch 44/64 loss: -3.651132583618164
Batch 45/64 loss: -3.9381051063537598
Batch 46/64 loss: -3.708369731903076
Batch 47/64 loss: -3.916499614715576
Batch 48/64 loss: -3.549234390258789
Batch 49/64 loss: -3.8407511711120605
Batch 50/64 loss: -3.5772719383239746
Batch 51/64 loss: -3.8229165077209473
Batch 52/64 loss: -3.256542205810547
Batch 53/64 loss: -3.8417439460754395
Batch 54/64 loss: -3.6345081329345703
Batch 55/64 loss: -3.9722728729248047
Batch 56/64 loss: -3.859334945678711
Batch 57/64 loss: -3.764253616333008
Batch 58/64 loss: -3.537776470184326
Batch 59/64 loss: -3.6227526664733887
Batch 60/64 loss: -3.629838466644287
Batch 61/64 loss: -3.539188861846924
Batch 62/64 loss: -3.831636428833008
Batch 63/64 loss: -3.8610644340515137
Batch 64/64 loss: -7.94264554977417
Epoch 285  Train loss: -3.7819320173824535  Val loss: -4.039500941115966
Epoch 286
-------------------------------
Batch 1/64 loss: -3.7931160926818848
Batch 2/64 loss: -3.835282325744629
Batch 3/64 loss: -3.734091281890869
Batch 4/64 loss: -3.817385196685791
Batch 5/64 loss: -3.84586763381958
Batch 6/64 loss: -3.926786422729492
Batch 7/64 loss: -3.631706714630127
Batch 8/64 loss: -3.779348850250244
Batch 9/64 loss: -3.735109329223633
Batch 10/64 loss: -3.4327049255371094
Batch 11/64 loss: -3.5551743507385254
Batch 12/64 loss: -3.934753894805908
Batch 13/64 loss: -3.8620615005493164
Batch 14/64 loss: -3.8291478157043457
Batch 15/64 loss: -3.7487239837646484
Batch 16/64 loss: -3.5795297622680664
Batch 17/64 loss: -3.829220771789551
Batch 18/64 loss: -3.5713248252868652
Batch 19/64 loss: -3.6787009239196777
Batch 20/64 loss: -3.826462745666504
Batch 21/64 loss: -3.843441963195801
Batch 22/64 loss: -3.758456230163574
Batch 23/64 loss: -3.9396185874938965
Batch 24/64 loss: -3.5675783157348633
Batch 25/64 loss: -3.725241184234619
Batch 26/64 loss: -3.3412742614746094
Batch 27/64 loss: -3.856600761413574
Batch 28/64 loss: -3.7792253494262695
Batch 29/64 loss: -3.626511573791504
Batch 30/64 loss: -3.85618257522583
Batch 31/64 loss: -3.4311399459838867
Batch 32/64 loss: -3.697282314300537
Batch 33/64 loss: -3.6988892555236816
Batch 34/64 loss: -3.570927619934082
Batch 35/64 loss: -3.9567055702209473
Batch 36/64 loss: -3.3756275177001953
Batch 37/64 loss: -3.724384307861328
Batch 38/64 loss: -3.899829864501953
Batch 39/64 loss: -3.550879955291748
Batch 40/64 loss: -3.857633113861084
Batch 41/64 loss: -3.7769970893859863
Batch 42/64 loss: -3.743684768676758
Batch 43/64 loss: -3.794520378112793
Batch 44/64 loss: -3.9106807708740234
Batch 45/64 loss: -3.8314785957336426
Batch 46/64 loss: -3.9588913917541504
Batch 47/64 loss: -3.530506134033203
Batch 48/64 loss: -3.874873161315918
Batch 49/64 loss: -3.7597174644470215
Batch 50/64 loss: -3.6509757041931152
Batch 51/64 loss: -3.867159843444824
Batch 52/64 loss: -3.644315719604492
Batch 53/64 loss: -3.753079414367676
Batch 54/64 loss: -3.6784839630126953
Batch 55/64 loss: -3.585343360900879
Batch 56/64 loss: -3.8889527320861816
Batch 57/64 loss: -3.5792441368103027
Batch 58/64 loss: -3.756807327270508
Batch 59/64 loss: -3.582012176513672
Batch 60/64 loss: -3.334074020385742
Batch 61/64 loss: -3.8570823669433594
Batch 62/64 loss: -3.6377482414245605
Batch 63/64 loss: -3.647636890411377
Batch 64/64 loss: -8.277618408203125
Epoch 286  Train loss: -3.7781397501627603  Val loss: -4.039606861232483
Epoch 287
-------------------------------
Batch 1/64 loss: -3.4301891326904297
Batch 2/64 loss: -3.563549518585205
Batch 3/64 loss: -3.813328742980957
Batch 4/64 loss: -3.9332447052001953
Batch 5/64 loss: -3.4547042846679688
Batch 6/64 loss: -3.4709835052490234
Batch 7/64 loss: -3.531416416168213
Batch 8/64 loss: -3.892423629760742
Batch 9/64 loss: -3.7811131477355957
Batch 10/64 loss: -3.7683892250061035
Batch 11/64 loss: -3.7777771949768066
Batch 12/64 loss: -3.7687387466430664
Batch 13/64 loss: -3.6517906188964844
Batch 14/64 loss: -3.6752142906188965
Batch 15/64 loss: -3.757054328918457
Batch 16/64 loss: -3.726820468902588
Batch 17/64 loss: -3.5110669136047363
Batch 18/64 loss: -3.813401222229004
Batch 19/64 loss: -3.8326549530029297
Batch 20/64 loss: -3.5717315673828125
Batch 21/64 loss: -3.6728949546813965
Batch 22/64 loss: -3.696744918823242
Batch 23/64 loss: -3.598163604736328
Batch 24/64 loss: -3.695814609527588
Batch 25/64 loss: -3.9803695678710938
Batch 26/64 loss: -3.7037343978881836
Batch 27/64 loss: -3.620737075805664
Batch 28/64 loss: -3.7538528442382812
Batch 29/64 loss: -3.7649011611938477
Batch 30/64 loss: -3.5031967163085938
Batch 31/64 loss: -3.654543399810791
Batch 32/64 loss: -3.7705798149108887
Batch 33/64 loss: -3.966958999633789
Batch 34/64 loss: -3.8761191368103027
Batch 35/64 loss: -3.702670097351074
Batch 36/64 loss: -3.6649532318115234
Batch 37/64 loss: -3.844637393951416
Batch 38/64 loss: -3.741641044616699
Batch 39/64 loss: -4.02576208114624
Batch 40/64 loss: -3.951037883758545
Batch 41/64 loss: -3.6797823905944824
Batch 42/64 loss: -3.7151222229003906
Batch 43/64 loss: -3.956371307373047
Batch 44/64 loss: -3.768235206604004
Batch 45/64 loss: -3.686208724975586
Batch 46/64 loss: -3.6225552558898926
Batch 47/64 loss: -3.7461233139038086
Batch 48/64 loss: -3.9268994331359863
Batch 49/64 loss: -3.4905014038085938
Batch 50/64 loss: -3.8190555572509766
Batch 51/64 loss: -3.889885902404785
Batch 52/64 loss: -3.74544095993042
Batch 53/64 loss: -3.799302101135254
Batch 54/64 loss: -3.886444568634033
Batch 55/64 loss: -3.9603633880615234
Batch 56/64 loss: -3.86403226852417
Batch 57/64 loss: -3.770845413208008
Batch 58/64 loss: -3.6631951332092285
Batch 59/64 loss: -3.4432907104492188
Batch 60/64 loss: -3.67659330368042
Batch 61/64 loss: -3.6289429664611816
Batch 62/64 loss: -3.8360395431518555
Batch 63/64 loss: -3.7694997787475586
Batch 64/64 loss: -8.033407211303711
Epoch 287  Train loss: -3.784857910754634  Val loss: -4.021274632195017
Epoch 288
-------------------------------
Batch 1/64 loss: -3.5953359603881836
Batch 2/64 loss: -3.7475247383117676
Batch 3/64 loss: -3.486055850982666
Batch 4/64 loss: -3.918710708618164
Batch 5/64 loss: -3.754383087158203
Batch 6/64 loss: -3.8447771072387695
Batch 7/64 loss: -3.737623691558838
Batch 8/64 loss: -3.8226966857910156
Batch 9/64 loss: -3.584127902984619
Batch 10/64 loss: -3.639169216156006
Batch 11/64 loss: -3.7602343559265137
Batch 12/64 loss: -3.562608242034912
Batch 13/64 loss: -3.8809890747070312
Batch 14/64 loss: -3.8101096153259277
Batch 15/64 loss: -3.7342867851257324
Batch 16/64 loss: -3.7384071350097656
Batch 17/64 loss: -3.801316261291504
Batch 18/64 loss: -3.4285430908203125
Batch 19/64 loss: -3.688758373260498
Batch 20/64 loss: -3.007932662963867
Batch 21/64 loss: -3.57521915435791
Batch 22/64 loss: -3.8375449180603027
Batch 23/64 loss: -3.7986207008361816
Batch 24/64 loss: -2.579554557800293
Batch 25/64 loss: -3.61295747756958
Batch 26/64 loss: -3.2888965606689453
Batch 27/64 loss: -3.657155990600586
Batch 28/64 loss: -3.6704416275024414
Batch 29/64 loss: -3.718667984008789
Batch 30/64 loss: -3.58109712600708
Batch 31/64 loss: -3.615396022796631
Batch 32/64 loss: -3.700796604156494
Batch 33/64 loss: -3.2335805892944336
Batch 34/64 loss: -3.488522529602051
Batch 35/64 loss: -3.540159225463867
Batch 36/64 loss: -3.7457404136657715
Batch 37/64 loss: -3.6110024452209473
Batch 38/64 loss: -3.6548900604248047
Batch 39/64 loss: -3.2656173706054688
Batch 40/64 loss: -3.506448745727539
Batch 41/64 loss: -3.5806450843811035
Batch 42/64 loss: -3.9061269760131836
Batch 43/64 loss: -3.6837987899780273
Batch 44/64 loss: -3.769808769226074
Batch 45/64 loss: -3.533369541168213
Batch 46/64 loss: -3.589416027069092
Batch 47/64 loss: -3.667229175567627
Batch 48/64 loss: -3.139254570007324
Batch 49/64 loss: -3.37249755859375
Batch 50/64 loss: -3.1583127975463867
Batch 51/64 loss: -3.5942068099975586
Batch 52/64 loss: -3.769662857055664
Batch 53/64 loss: -3.693601131439209
Batch 54/64 loss: -3.6701931953430176
Batch 55/64 loss: -3.44049072265625
Batch 56/64 loss: -3.653751850128174
Batch 57/64 loss: -3.651897430419922
Batch 58/64 loss: -3.5896730422973633
Batch 59/64 loss: -3.3938961029052734
Batch 60/64 loss: -3.4748001098632812
Batch 61/64 loss: -3.5799288749694824
Batch 62/64 loss: -3.390899658203125
Batch 63/64 loss: -3.804205894470215
Batch 64/64 loss: -8.341684341430664
Epoch 288  Train loss: -3.648467935300341  Val loss: -4.009736431423331
Epoch 289
-------------------------------
Batch 1/64 loss: -3.3599681854248047
Batch 2/64 loss: -3.78049373626709
Batch 3/64 loss: -3.5519156455993652
Batch 4/64 loss: -3.7819132804870605
Batch 5/64 loss: -3.6643309593200684
Batch 6/64 loss: -3.516055107116699
Batch 7/64 loss: -3.795172691345215
Batch 8/64 loss: -3.840622901916504
Batch 9/64 loss: -3.3987913131713867
Batch 10/64 loss: -3.4556961059570312
Batch 11/64 loss: -3.9315695762634277
Batch 12/64 loss: -3.8093771934509277
Batch 13/64 loss: -3.500600814819336
Batch 14/64 loss: -3.780275344848633
Batch 15/64 loss: -3.968231678009033
Batch 16/64 loss: -3.767693519592285
Batch 17/64 loss: -3.7282233238220215
Batch 18/64 loss: -3.595479965209961
Batch 19/64 loss: -3.8259902000427246
Batch 20/64 loss: -3.753298282623291
Batch 21/64 loss: -3.7578415870666504
Batch 22/64 loss: -3.760976791381836
Batch 23/64 loss: -3.5858373641967773
Batch 24/64 loss: -3.7153544425964355
Batch 25/64 loss: -3.8601889610290527
Batch 26/64 loss: -3.7420263290405273
Batch 27/64 loss: -3.4931116104125977
Batch 28/64 loss: -3.5298662185668945
Batch 29/64 loss: -3.8501062393188477
Batch 30/64 loss: -3.9417409896850586
Batch 31/64 loss: -3.779987335205078
Batch 32/64 loss: -3.946127414703369
Batch 33/64 loss: -3.7525010108947754
Batch 34/64 loss: -3.2359695434570312
Batch 35/64 loss: -3.627143383026123
Batch 36/64 loss: -3.9185104370117188
Batch 37/64 loss: -3.7742414474487305
Batch 38/64 loss: -3.551577568054199
Batch 39/64 loss: -3.7620019912719727
Batch 40/64 loss: -3.123912811279297
Batch 41/64 loss: -3.8443546295166016
Batch 42/64 loss: -3.5453057289123535
Batch 43/64 loss: -3.621148109436035
Batch 44/64 loss: -3.6713175773620605
Batch 45/64 loss: -3.404399871826172
Batch 46/64 loss: -3.481691360473633
Batch 47/64 loss: -3.731983184814453
Batch 48/64 loss: -3.4870471954345703
Batch 49/64 loss: -3.426603317260742
Batch 50/64 loss: -3.5423755645751953
Batch 51/64 loss: -3.7488675117492676
Batch 52/64 loss: -3.662630558013916
Batch 53/64 loss: -3.5914244651794434
Batch 54/64 loss: -3.6508803367614746
Batch 55/64 loss: -3.7037229537963867
Batch 56/64 loss: -3.892909049987793
Batch 57/64 loss: -3.6190671920776367
Batch 58/64 loss: -3.535914421081543
Batch 59/64 loss: -3.6043405532836914
Batch 60/64 loss: -3.6032166481018066
Batch 61/64 loss: -3.6422104835510254
Batch 62/64 loss: -3.2740869522094727
Batch 63/64 loss: -3.370859146118164
Batch 64/64 loss: -8.287843704223633
Epoch 289  Train loss: -3.7080307904411764  Val loss: -3.9119842896346784
Epoch 290
-------------------------------
Batch 1/64 loss: -3.7248950004577637
Batch 2/64 loss: -3.4166488647460938
Batch 3/64 loss: -3.430400848388672
Batch 4/64 loss: -3.3405637741088867
Batch 5/64 loss: -3.631380081176758
Batch 6/64 loss: -3.429943084716797
Batch 7/64 loss: -3.8503618240356445
Batch 8/64 loss: -3.744682788848877
Batch 9/64 loss: -3.857778549194336
Batch 10/64 loss: -3.93861722946167
Batch 11/64 loss: -3.373772621154785
Batch 12/64 loss: -3.746978759765625
Batch 13/64 loss: -3.636776924133301
Batch 14/64 loss: -3.7778921127319336
Batch 15/64 loss: -3.5840978622436523
Batch 16/64 loss: -3.54775333404541
Batch 17/64 loss: -3.45003604888916
Batch 18/64 loss: -3.8504104614257812
Batch 19/64 loss: -3.633047580718994
Batch 20/64 loss: -3.9140625
Batch 21/64 loss: -3.2835092544555664
Batch 22/64 loss: -3.7373666763305664
Batch 23/64 loss: -3.550900936126709
Batch 24/64 loss: -3.8880395889282227
Batch 25/64 loss: -3.749100685119629
Batch 26/64 loss: -3.5347819328308105
Batch 27/64 loss: -3.785325050354004
Batch 28/64 loss: -3.8856053352355957
Batch 29/64 loss: -3.31270694732666
Batch 30/64 loss: -3.7881522178649902
Batch 31/64 loss: -3.8183560371398926
Batch 32/64 loss: -3.5957226753234863
Batch 33/64 loss: -3.600369453430176
Batch 34/64 loss: -3.7632193565368652
Batch 35/64 loss: -3.6606569290161133
Batch 36/64 loss: -3.3927173614501953
Batch 37/64 loss: -3.5543155670166016
Batch 38/64 loss: -3.2822694778442383
Batch 39/64 loss: -3.8883628845214844
Batch 40/64 loss: -3.555633068084717
Batch 41/64 loss: -3.6720595359802246
Batch 42/64 loss: -3.836740493774414
Batch 43/64 loss: -3.733191967010498
Batch 44/64 loss: -3.7476162910461426
Batch 45/64 loss: -3.7539610862731934
Batch 46/64 loss: -3.894857406616211
Batch 47/64 loss: -3.762874126434326
Batch 48/64 loss: -3.7609119415283203
Batch 49/64 loss: -3.609825611114502
Batch 50/64 loss: -3.7457237243652344
Batch 51/64 loss: -3.8442459106445312
Batch 52/64 loss: -3.8833045959472656
Batch 53/64 loss: -3.6057310104370117
Batch 54/64 loss: -3.771592140197754
Batch 55/64 loss: -3.6829490661621094
Batch 56/64 loss: -3.849705696105957
Batch 57/64 loss: -3.92018461227417
Batch 58/64 loss: -3.9595885276794434
Batch 59/64 loss: -3.810316562652588
Batch 60/64 loss: -3.6996231079101562
Batch 61/64 loss: -3.639244556427002
Batch 62/64 loss: -3.6423730850219727
Batch 63/64 loss: -3.675964832305908
Batch 64/64 loss: -8.199846267700195
Epoch 290  Train loss: -3.7358381533155254  Val loss: -3.8577943520037987
Epoch 291
-------------------------------
Batch 1/64 loss: -3.9588842391967773
Batch 2/64 loss: -3.798778533935547
Batch 3/64 loss: -3.704277515411377
Batch 4/64 loss: -3.459493637084961
Batch 5/64 loss: -3.5655393600463867
Batch 6/64 loss: -3.4220409393310547
Batch 7/64 loss: -3.8811826705932617
Batch 8/64 loss: -3.733577251434326
Batch 9/64 loss: -3.7628846168518066
Batch 10/64 loss: -3.7634754180908203
Batch 11/64 loss: -3.710521697998047
Batch 12/64 loss: -3.702167510986328
Batch 13/64 loss: -3.511324882507324
Batch 14/64 loss: -3.689128875732422
Batch 15/64 loss: -3.832852363586426
Batch 16/64 loss: -3.691831111907959
Batch 17/64 loss: -3.8082237243652344
Batch 18/64 loss: -3.694042682647705
Batch 19/64 loss: -3.864532947540283
Batch 20/64 loss: -3.6836166381835938
Batch 21/64 loss: -3.8559417724609375
Batch 22/64 loss: -3.722041130065918
Batch 23/64 loss: -3.861473560333252
Batch 24/64 loss: -3.746492862701416
Batch 25/64 loss: -3.3233280181884766
Batch 26/64 loss: -3.591588020324707
Batch 27/64 loss: -3.8736538887023926
Batch 28/64 loss: -3.944079875946045
Batch 29/64 loss: -3.3987960815429688
Batch 30/64 loss: -3.678257942199707
Batch 31/64 loss: -3.7163968086242676
Batch 32/64 loss: -3.7031917572021484
Batch 33/64 loss: -3.6728343963623047
Batch 34/64 loss: -3.6553940773010254
Batch 35/64 loss: -3.9729323387145996
Batch 36/64 loss: -3.7069406509399414
Batch 37/64 loss: -3.8055825233459473
Batch 38/64 loss: -3.7486343383789062
Batch 39/64 loss: -3.796870708465576
Batch 40/64 loss: -3.6173343658447266
Batch 41/64 loss: -3.631089210510254
Batch 42/64 loss: -3.677076816558838
Batch 43/64 loss: -3.668654441833496
Batch 44/64 loss: -3.783031463623047
Batch 45/64 loss: -3.6236886978149414
Batch 46/64 loss: -3.646099090576172
Batch 47/64 loss: -3.6748147010803223
Batch 48/64 loss: -3.7885942459106445
Batch 49/64 loss: -3.7568583488464355
Batch 50/64 loss: -3.7550878524780273
Batch 51/64 loss: -3.6779088973999023
Batch 52/64 loss: -3.75900936126709
Batch 53/64 loss: -3.6675381660461426
Batch 54/64 loss: -3.458637237548828
Batch 55/64 loss: -3.5577001571655273
Batch 56/64 loss: -3.7491793632507324
Batch 57/64 loss: -3.5091915130615234
Batch 58/64 loss: -3.754744052886963
Batch 59/64 loss: -3.636441230773926
Batch 60/64 loss: -3.490394115447998
Batch 61/64 loss: -3.5737409591674805
Batch 62/64 loss: -3.222945213317871
Batch 63/64 loss: -3.528916835784912
Batch 64/64 loss: -8.346240997314453
Epoch 291  Train loss: -3.740881011065315  Val loss: -3.952317110041982
Epoch 292
-------------------------------
Batch 1/64 loss: -3.8900527954101562
Batch 2/64 loss: -3.6920061111450195
Batch 3/64 loss: -3.70463228225708
Batch 4/64 loss: -3.6104650497436523
Batch 5/64 loss: -3.8215208053588867
Batch 6/64 loss: -3.6813764572143555
Batch 7/64 loss: -3.61452579498291
Batch 8/64 loss: -3.5326414108276367
Batch 9/64 loss: -3.516357421875
Batch 10/64 loss: -3.8725266456604004
Batch 11/64 loss: -3.770151138305664
Batch 12/64 loss: -3.831976890563965
Batch 13/64 loss: -3.6513218879699707
Batch 14/64 loss: -3.516575813293457
Batch 15/64 loss: -3.2137956619262695
Batch 16/64 loss: -3.662532329559326
Batch 17/64 loss: -3.269272804260254
Batch 18/64 loss: -3.769411563873291
Batch 19/64 loss: -3.635417938232422
Batch 20/64 loss: -3.6989364624023438
Batch 21/64 loss: -3.8615126609802246
Batch 22/64 loss: -3.6572041511535645
Batch 23/64 loss: -3.711015224456787
Batch 24/64 loss: -3.3195972442626953
Batch 25/64 loss: -3.899230480194092
Batch 26/64 loss: -3.038982391357422
Batch 27/64 loss: -3.752383232116699
Batch 28/64 loss: -3.8221774101257324
Batch 29/64 loss: -3.7679290771484375
Batch 30/64 loss: -3.890122413635254
Batch 31/64 loss: -3.7481136322021484
Batch 32/64 loss: -3.612156391143799
Batch 33/64 loss: -3.752012252807617
Batch 34/64 loss: -3.6825661659240723
Batch 35/64 loss: -3.788961887359619
Batch 36/64 loss: -3.659438133239746
Batch 37/64 loss: -3.8548989295959473
Batch 38/64 loss: -3.4475231170654297
Batch 39/64 loss: -3.892165184020996
Batch 40/64 loss: -3.816986083984375
Batch 41/64 loss: -3.681997299194336
Batch 42/64 loss: -3.8659138679504395
Batch 43/64 loss: -3.717073440551758
Batch 44/64 loss: -3.728665828704834
Batch 45/64 loss: -3.7180538177490234
Batch 46/64 loss: -3.598865509033203
Batch 47/64 loss: -3.844242572784424
Batch 48/64 loss: -3.740443706512451
Batch 49/64 loss: -3.4831247329711914
Batch 50/64 loss: -3.9764976501464844
Batch 51/64 loss: -3.6154236793518066
Batch 52/64 loss: -3.8506484031677246
Batch 53/64 loss: -3.694396495819092
Batch 54/64 loss: -3.864443302154541
Batch 55/64 loss: -3.7154526710510254
Batch 56/64 loss: -3.7284717559814453
Batch 57/64 loss: -3.673786163330078
Batch 58/64 loss: -3.794114112854004
Batch 59/64 loss: -3.5007991790771484
Batch 60/64 loss: -3.7215423583984375
Batch 61/64 loss: -3.6261677742004395
Batch 62/64 loss: -3.7057676315307617
Batch 63/64 loss: -3.327378273010254
Batch 64/64 loss: -8.185523986816406
Epoch 292  Train loss: -3.7371433183258653  Val loss: -4.08601052982291
Epoch 293
-------------------------------
Batch 1/64 loss: -3.878660202026367
Batch 2/64 loss: -3.7870583534240723
Batch 3/64 loss: -3.6779003143310547
Batch 4/64 loss: -3.517484664916992
Batch 5/64 loss: -3.843179225921631
Batch 6/64 loss: -3.6880693435668945
Batch 7/64 loss: -3.7137088775634766
Batch 8/64 loss: -3.738509178161621
Batch 9/64 loss: -3.6751270294189453
Batch 10/64 loss: -3.8604679107666016
Batch 11/64 loss: -3.847362995147705
Batch 12/64 loss: -3.5644803047180176
Batch 13/64 loss: -3.7446675300598145
Batch 14/64 loss: -3.577998161315918
Batch 15/64 loss: -3.875006675720215
Batch 16/64 loss: -3.9449472427368164
Batch 17/64 loss: -3.833634376525879
Batch 18/64 loss: -3.7891077995300293
Batch 19/64 loss: -3.872485637664795
Batch 20/64 loss: -3.7278175354003906
Batch 21/64 loss: -3.6048717498779297
Batch 22/64 loss: -3.775097370147705
Batch 23/64 loss: -3.8428592681884766
Batch 24/64 loss: -3.66898250579834
Batch 25/64 loss: -3.807290554046631
Batch 26/64 loss: -3.7906079292297363
Batch 27/64 loss: -3.66196870803833
Batch 28/64 loss: -3.671873092651367
Batch 29/64 loss: -3.823148727416992
Batch 30/64 loss: -3.578667640686035
Batch 31/64 loss: -3.576751232147217
Batch 32/64 loss: -3.9335765838623047
Batch 33/64 loss: -3.7826061248779297
Batch 34/64 loss: -3.846691608428955
Batch 35/64 loss: -3.6890268325805664
Batch 36/64 loss: -3.3372983932495117
Batch 37/64 loss: -3.689344882965088
Batch 38/64 loss: -3.295328140258789
Batch 39/64 loss: -3.7046213150024414
Batch 40/64 loss: -3.8549294471740723
Batch 41/64 loss: -3.2797889709472656
Batch 42/64 loss: -3.5125503540039062
Batch 43/64 loss: -3.534609794616699
Batch 44/64 loss: -3.4253530502319336
Batch 45/64 loss: -3.568227767944336
Batch 46/64 loss: -3.6982598304748535
Batch 47/64 loss: -3.680426597595215
Batch 48/64 loss: -3.662181854248047
Batch 49/64 loss: -3.775893211364746
Batch 50/64 loss: -3.843018054962158
Batch 51/64 loss: -3.686573028564453
Batch 52/64 loss: -4.008932113647461
Batch 53/64 loss: -3.7617297172546387
Batch 54/64 loss: -3.6468939781188965
Batch 55/64 loss: -3.478989601135254
Batch 56/64 loss: -3.830636978149414
Batch 57/64 loss: -3.7008328437805176
Batch 58/64 loss: -3.67417049407959
Batch 59/64 loss: -3.322695732116699
Batch 60/64 loss: -3.8055429458618164
Batch 61/64 loss: -3.5992960929870605
Batch 62/64 loss: -3.6561946868896484
Batch 63/64 loss: -3.7520689964294434
Batch 64/64 loss: -8.325786590576172
Epoch 293  Train loss: -3.752822307511872  Val loss: -3.967628007082595
Epoch 294
-------------------------------
Batch 1/64 loss: -3.633054256439209
Batch 2/64 loss: -3.696402072906494
Batch 3/64 loss: -3.9290595054626465
Batch 4/64 loss: -3.7692599296569824
Batch 5/64 loss: -3.8644566535949707
Batch 6/64 loss: -3.781345844268799
Batch 7/64 loss: -3.844231128692627
Batch 8/64 loss: -3.720649242401123
Batch 9/64 loss: -3.9592723846435547
Batch 10/64 loss: -3.648296356201172
Batch 11/64 loss: -3.669694423675537
Batch 12/64 loss: -3.6875743865966797
Batch 13/64 loss: -3.197460174560547
Batch 14/64 loss: -3.756211280822754
Batch 15/64 loss: -3.746514320373535
Batch 16/64 loss: -3.6485886573791504
Batch 17/64 loss: -3.6637368202209473
Batch 18/64 loss: -3.8652215003967285
Batch 19/64 loss: -3.642152786254883
Batch 20/64 loss: -3.802973747253418
Batch 21/64 loss: -3.68107271194458
Batch 22/64 loss: -3.8694348335266113
Batch 23/64 loss: -3.710080623626709
Batch 24/64 loss: -3.850172996520996
Batch 25/64 loss: -3.726688861846924
Batch 26/64 loss: -3.9386610984802246
Batch 27/64 loss: -3.700300693511963
Batch 28/64 loss: -3.3861169815063477
Batch 29/64 loss: -3.845294952392578
Batch 30/64 loss: -3.9363584518432617
Batch 31/64 loss: -3.7014660835266113
Batch 32/64 loss: -3.873566150665283
Batch 33/64 loss: -3.978313446044922
Batch 34/64 loss: -3.70322847366333
Batch 35/64 loss: -3.825878143310547
Batch 36/64 loss: -3.5993800163269043
Batch 37/64 loss: -3.595456600189209
Batch 38/64 loss: -3.9052019119262695
Batch 39/64 loss: -3.7021660804748535
Batch 40/64 loss: -3.5954928398132324
Batch 41/64 loss: -3.585860252380371
Batch 42/64 loss: -3.8576650619506836
Batch 43/64 loss: -3.5984277725219727
Batch 44/64 loss: -3.6190600395202637
Batch 45/64 loss: -3.709906578063965
Batch 46/64 loss: -3.689387321472168
Batch 47/64 loss: -3.7501583099365234
Batch 48/64 loss: -3.6097803115844727
Batch 49/64 loss: -3.5972471237182617
Batch 50/64 loss: -3.7927165031433105
Batch 51/64 loss: -3.9195384979248047
Batch 52/64 loss: -3.7281994819641113
Batch 53/64 loss: -3.5268611907958984
Batch 54/64 loss: -3.825549602508545
Batch 55/64 loss: -3.6734886169433594
Batch 56/64 loss: -3.629460334777832
Batch 57/64 loss: -4.025016784667969
Batch 58/64 loss: -3.4561195373535156
Batch 59/64 loss: -3.5766148567199707
Batch 60/64 loss: -3.714534282684326
Batch 61/64 loss: -3.7362141609191895
Batch 62/64 loss: -3.7954773902893066
Batch 63/64 loss: -3.4368696212768555
Batch 64/64 loss: -8.234174728393555
Epoch 294  Train loss: -3.7753768172918583  Val loss: -3.9591044527558528
Epoch 295
-------------------------------
Batch 1/64 loss: -3.765036106109619
Batch 2/64 loss: -3.760098934173584
Batch 3/64 loss: -3.817668914794922
Batch 4/64 loss: -3.8339343070983887
Batch 5/64 loss: -3.782935619354248
Batch 6/64 loss: -3.857351303100586
Batch 7/64 loss: -3.9023585319519043
Batch 8/64 loss: -3.7946319580078125
Batch 9/64 loss: -3.931736946105957
Batch 10/64 loss: -3.821892261505127
Batch 11/64 loss: -3.377230644226074
Batch 12/64 loss: -3.672750473022461
Batch 13/64 loss: -3.7331442832946777
Batch 14/64 loss: -3.9164962768554688
Batch 15/64 loss: -3.7465548515319824
Batch 16/64 loss: -3.860243797302246
Batch 17/64 loss: -3.845673084259033
Batch 18/64 loss: -3.637866973876953
Batch 19/64 loss: -3.7828407287597656
Batch 20/64 loss: -3.8190150260925293
Batch 21/64 loss: -3.7621402740478516
Batch 22/64 loss: -3.6757211685180664
Batch 23/64 loss: -3.7181482315063477
Batch 24/64 loss: -3.7753114700317383
Batch 25/64 loss: -3.726566791534424
Batch 26/64 loss: -3.7468433380126953
Batch 27/64 loss: -3.741365432739258
Batch 28/64 loss: -3.7215442657470703
Batch 29/64 loss: -3.6797447204589844
Batch 30/64 loss: -3.191387176513672
Batch 31/64 loss: -3.5231003761291504
Batch 32/64 loss: -3.960719108581543
Batch 33/64 loss: -3.7401046752929688
Batch 34/64 loss: -3.7423315048217773
Batch 35/64 loss: -3.7670936584472656
Batch 36/64 loss: -3.790442943572998
Batch 37/64 loss: -3.82078218460083
Batch 38/64 loss: -3.7644829750061035
Batch 39/64 loss: -3.8116097450256348
Batch 40/64 loss: -3.830270290374756
Batch 41/64 loss: -3.9329476356506348
Batch 42/64 loss: -3.8187947273254395
Batch 43/64 loss: -3.7841458320617676
Batch 44/64 loss: -3.8259615898132324
Batch 45/64 loss: -3.8447437286376953
Batch 46/64 loss: -3.6241235733032227
Batch 47/64 loss: -3.6658854484558105
Batch 48/64 loss: -3.749594211578369
Batch 49/64 loss: -3.654529094696045
Batch 50/64 loss: -3.846673011779785
Batch 51/64 loss: -3.6831412315368652
Batch 52/64 loss: -3.693284034729004
Batch 53/64 loss: -3.6448421478271484
Batch 54/64 loss: -3.942077159881592
Batch 55/64 loss: -4.047068119049072
Batch 56/64 loss: -3.860581398010254
Batch 57/64 loss: -3.8283796310424805
Batch 58/64 loss: -3.7583513259887695
Batch 59/64 loss: -3.8763885498046875
Batch 60/64 loss: -3.7376785278320312
Batch 61/64 loss: -3.5812859535217285
Batch 62/64 loss: -3.6044039726257324
Batch 63/64 loss: -4.015255451202393
Batch 64/64 loss: -8.289138793945312
Epoch 295  Train loss: -3.817822145948223  Val loss: -4.154943446523135
Saving best model, epoch: 295
Epoch 296
-------------------------------
Batch 1/64 loss: -4.044781684875488
Batch 2/64 loss: -3.8278818130493164
Batch 3/64 loss: -3.8784022331237793
Batch 4/64 loss: -3.783172130584717
Batch 5/64 loss: -3.8254690170288086
Batch 6/64 loss: -3.852928638458252
Batch 7/64 loss: -3.4384756088256836
Batch 8/64 loss: -3.7883224487304688
Batch 9/64 loss: -3.879343032836914
Batch 10/64 loss: -3.549839973449707
Batch 11/64 loss: -3.8735947608947754
Batch 12/64 loss: -3.9195733070373535
Batch 13/64 loss: -3.687889575958252
Batch 14/64 loss: -3.808887004852295
Batch 15/64 loss: -3.6677966117858887
Batch 16/64 loss: -3.746706485748291
Batch 17/64 loss: -3.8338704109191895
Batch 18/64 loss: -3.8874049186706543
Batch 19/64 loss: -4.061247825622559
Batch 20/64 loss: -3.913105010986328
Batch 21/64 loss: -3.824068069458008
Batch 22/64 loss: -3.7059407234191895
Batch 23/64 loss: -3.7566561698913574
Batch 24/64 loss: -3.814845561981201
Batch 25/64 loss: -3.8727288246154785
Batch 26/64 loss: -3.85841703414917
Batch 27/64 loss: -3.882040023803711
Batch 28/64 loss: -3.4678964614868164
Batch 29/64 loss: -3.9906725883483887
Batch 30/64 loss: -3.6050353050231934
Batch 31/64 loss: -3.7998414039611816
Batch 32/64 loss: -3.6619129180908203
Batch 33/64 loss: -3.7130022048950195
Batch 34/64 loss: -3.483365535736084
Batch 35/64 loss: -3.8723912239074707
Batch 36/64 loss: -3.7293076515197754
Batch 37/64 loss: -3.617518901824951
Batch 38/64 loss: -3.8244776725769043
Batch 39/64 loss: -3.8207321166992188
Batch 40/64 loss: -3.8430628776550293
Batch 41/64 loss: -3.521366596221924
Batch 42/64 loss: -3.8881640434265137
Batch 43/64 loss: -3.8949990272521973
Batch 44/64 loss: -3.8558292388916016
Batch 45/64 loss: -3.8734030723571777
Batch 46/64 loss: -3.7990756034851074
Batch 47/64 loss: -3.708812713623047
Batch 48/64 loss: -4.021673679351807
Batch 49/64 loss: -3.766582489013672
Batch 50/64 loss: -3.7582454681396484
Batch 51/64 loss: -3.73887300491333
Batch 52/64 loss: -3.730790138244629
Batch 53/64 loss: -3.823470115661621
Batch 54/64 loss: -3.915015697479248
Batch 55/64 loss: -3.838693618774414
Batch 56/64 loss: -3.9931674003601074
Batch 57/64 loss: -3.7835912704467773
Batch 58/64 loss: -3.7719006538391113
Batch 59/64 loss: -3.946230888366699
Batch 60/64 loss: -3.7368412017822266
Batch 61/64 loss: -3.863513946533203
Batch 62/64 loss: -3.8911867141723633
Batch 63/64 loss: -3.917367935180664
Batch 64/64 loss: -8.389703750610352
Epoch 296  Train loss: -3.8548027936150047  Val loss: -4.196160713012276
Saving best model, epoch: 296
Epoch 297
-------------------------------
Batch 1/64 loss: -3.9120421409606934
Batch 2/64 loss: -3.8169240951538086
Batch 3/64 loss: -3.9185924530029297
Batch 4/64 loss: -3.809492588043213
Batch 5/64 loss: -3.8218722343444824
Batch 6/64 loss: -3.5579447746276855
Batch 7/64 loss: -3.6378307342529297
Batch 8/64 loss: -3.9258556365966797
Batch 9/64 loss: -3.749828338623047
Batch 10/64 loss: -3.4884252548217773
Batch 11/64 loss: -3.832827568054199
Batch 12/64 loss: -3.694653034210205
Batch 13/64 loss: -4.0004096031188965
Batch 14/64 loss: -3.7734718322753906
Batch 15/64 loss: -3.8855223655700684
Batch 16/64 loss: -3.875293731689453
Batch 17/64 loss: -3.533663272857666
Batch 18/64 loss: -3.7762880325317383
Batch 19/64 loss: -3.6945858001708984
Batch 20/64 loss: -3.913247585296631
Batch 21/64 loss: -3.968503952026367
Batch 22/64 loss: -3.6871814727783203
Batch 23/64 loss: -3.64485502243042
Batch 24/64 loss: -3.942971706390381
Batch 25/64 loss: -3.6583657264709473
Batch 26/64 loss: -3.765674114227295
Batch 27/64 loss: -3.318939208984375
Batch 28/64 loss: -3.7667360305786133
Batch 29/64 loss: -3.6681337356567383
Batch 30/64 loss: -3.9323835372924805
Batch 31/64 loss: -3.7646961212158203
Batch 32/64 loss: -3.6742143630981445
Batch 33/64 loss: -4.021597385406494
Batch 34/64 loss: -3.944713592529297
Batch 35/64 loss: -3.553562641143799
Batch 36/64 loss: -3.932109832763672
Batch 37/64 loss: -3.7841897010803223
Batch 38/64 loss: -3.9071455001831055
Batch 39/64 loss: -3.878091335296631
Batch 40/64 loss: -3.943763256072998
Batch 41/64 loss: -4.021224021911621
Batch 42/64 loss: -3.935922145843506
Batch 43/64 loss: -3.9604125022888184
Batch 44/64 loss: -3.7736663818359375
Batch 45/64 loss: -4.018911838531494
Batch 46/64 loss: -3.6597204208374023
Batch 47/64 loss: -4.0639472007751465
Batch 48/64 loss: -3.692917823791504
Batch 49/64 loss: -3.969259738922119
Batch 50/64 loss: -3.8769140243530273
Batch 51/64 loss: -3.8447909355163574
Batch 52/64 loss: -3.9896316528320312
Batch 53/64 loss: -3.9187450408935547
Batch 54/64 loss: -4.02545690536499
Batch 55/64 loss: -3.7983198165893555
Batch 56/64 loss: -3.930086135864258
Batch 57/64 loss: -3.942505359649658
Batch 58/64 loss: -3.878580093383789
Batch 59/64 loss: -3.893371105194092
Batch 60/64 loss: -3.856266975402832
Batch 61/64 loss: -3.807234764099121
Batch 62/64 loss: -3.713449478149414
Batch 63/64 loss: -3.807586193084717
Batch 64/64 loss: -8.378381729125977
Epoch 297  Train loss: -3.875126371196672  Val loss: -4.169222094349025
Epoch 298
-------------------------------
Batch 1/64 loss: -3.6514620780944824
Batch 2/64 loss: -3.805326461791992
Batch 3/64 loss: -3.8759708404541016
Batch 4/64 loss: -3.830935478210449
Batch 5/64 loss: -3.9134392738342285
Batch 6/64 loss: -3.9335408210754395
Batch 7/64 loss: -3.8777618408203125
Batch 8/64 loss: -3.72312068939209
Batch 9/64 loss: -3.9599337577819824
Batch 10/64 loss: -3.8532614707946777
Batch 11/64 loss: -3.864070415496826
Batch 12/64 loss: -3.7413153648376465
Batch 13/64 loss: -3.7905001640319824
Batch 14/64 loss: -3.8344125747680664
Batch 15/64 loss: -3.94685697555542
Batch 16/64 loss: -3.826129913330078
Batch 17/64 loss: -3.627908706665039
Batch 18/64 loss: -3.844714641571045
Batch 19/64 loss: -3.8207082748413086
Batch 20/64 loss: -3.989816665649414
Batch 21/64 loss: -3.811522960662842
Batch 22/64 loss: -3.9180831909179688
Batch 23/64 loss: -3.8570384979248047
Batch 24/64 loss: -3.829599380493164
Batch 25/64 loss: -3.508486747741699
Batch 26/64 loss: -3.4916725158691406
Batch 27/64 loss: -3.5703773498535156
Batch 28/64 loss: -3.9330954551696777
Batch 29/64 loss: -3.83065128326416
Batch 30/64 loss: -3.920356273651123
Batch 31/64 loss: -3.9237027168273926
Batch 32/64 loss: -3.898238182067871
Batch 33/64 loss: -3.4743895530700684
Batch 34/64 loss: -3.9506664276123047
Batch 35/64 loss: -3.873230457305908
Batch 36/64 loss: -3.7731127738952637
Batch 37/64 loss: -3.7730188369750977
Batch 38/64 loss: -3.669229030609131
Batch 39/64 loss: -3.6270618438720703
Batch 40/64 loss: -3.7661166191101074
Batch 41/64 loss: -3.942107677459717
Batch 42/64 loss: -3.6892480850219727
Batch 43/64 loss: -3.906041145324707
Batch 44/64 loss: -4.062492370605469
Batch 45/64 loss: -3.6674718856811523
Batch 46/64 loss: -3.955679416656494
Batch 47/64 loss: -3.7084012031555176
Batch 48/64 loss: -3.9428420066833496
Batch 49/64 loss: -3.9415884017944336
Batch 50/64 loss: -3.8168139457702637
Batch 51/64 loss: -3.7429585456848145
Batch 52/64 loss: -3.8659262657165527
Batch 53/64 loss: -3.7408857345581055
Batch 54/64 loss: -3.8808937072753906
Batch 55/64 loss: -3.878416061401367
Batch 56/64 loss: -3.982295513153076
Batch 57/64 loss: -3.810948371887207
Batch 58/64 loss: -3.8884897232055664
Batch 59/64 loss: -3.849459171295166
Batch 60/64 loss: -3.871939182281494
Batch 61/64 loss: -3.9523110389709473
Batch 62/64 loss: -3.740708351135254
Batch 63/64 loss: -3.8364014625549316
Batch 64/64 loss: -8.370803833007812
Epoch 298  Train loss: -3.8755020964379403  Val loss: -4.165121124372449
Epoch 299
-------------------------------
Batch 1/64 loss: -3.586738109588623
Batch 2/64 loss: -3.733067035675049
Batch 3/64 loss: -3.8015084266662598
Batch 4/64 loss: -3.9059109687805176
Batch 5/64 loss: -3.9621944427490234
Batch 6/64 loss: -3.7064552307128906
Batch 7/64 loss: -3.787862777709961
Batch 8/64 loss: -3.7750539779663086
Batch 9/64 loss: -3.7015910148620605
Batch 10/64 loss: -3.597431182861328
Batch 11/64 loss: -3.859656810760498
Batch 12/64 loss: -3.665823459625244
Batch 13/64 loss: -3.572065830230713
Batch 14/64 loss: -3.6544408798217773
Batch 15/64 loss: -3.988267421722412
Batch 16/64 loss: -3.827450752258301
Batch 17/64 loss: -3.852877140045166
Batch 18/64 loss: -3.5747461318969727
Batch 19/64 loss: -3.812619209289551
Batch 20/64 loss: -3.7869338989257812
Batch 21/64 loss: -3.7976021766662598
Batch 22/64 loss: -3.8571338653564453
Batch 23/64 loss: -3.9439315795898438
Batch 24/64 loss: -3.828740119934082
Batch 25/64 loss: -3.8185625076293945
Batch 26/64 loss: -3.8654303550720215
Batch 27/64 loss: -3.850346088409424
Batch 28/64 loss: -3.757923126220703
Batch 29/64 loss: -3.7792530059814453
Batch 30/64 loss: -3.7989039421081543
Batch 31/64 loss: -3.7074484825134277
Batch 32/64 loss: -3.7882604598999023
Batch 33/64 loss: -3.9805126190185547
Batch 34/64 loss: -3.809837818145752
Batch 35/64 loss: -3.7785887718200684
Batch 36/64 loss: -3.8199429512023926
Batch 37/64 loss: -3.9114131927490234
Batch 38/64 loss: -3.8048200607299805
Batch 39/64 loss: -3.8549680709838867
Batch 40/64 loss: -3.85587739944458
Batch 41/64 loss: -3.801718235015869
Batch 42/64 loss: -3.9228568077087402
Batch 43/64 loss: -3.7144370079040527
Batch 44/64 loss: -3.9855313301086426
Batch 45/64 loss: -3.7482051849365234
Batch 46/64 loss: -3.3176698684692383
Batch 47/64 loss: -3.6679177284240723
Batch 48/64 loss: -3.9063782691955566
Batch 49/64 loss: -3.871856689453125
Batch 50/64 loss: -3.790433883666992
Batch 51/64 loss: -3.591156005859375
Batch 52/64 loss: -3.8025050163269043
Batch 53/64 loss: -3.7999649047851562
Batch 54/64 loss: -3.669564723968506
Batch 55/64 loss: -3.6888279914855957
Batch 56/64 loss: -3.4527759552001953
Batch 57/64 loss: -3.8339738845825195
Batch 58/64 loss: -3.8820013999938965
Batch 59/64 loss: -3.583831310272217
Batch 60/64 loss: -3.6877684593200684
Batch 61/64 loss: -3.8233814239501953
Batch 62/64 loss: -3.8340821266174316
Batch 63/64 loss: -3.737915515899658
Batch 64/64 loss: -8.49856185913086
Epoch 299  Train loss: -3.8313861398135916  Val loss: -4.0807304775591975
Epoch 300
-------------------------------
Batch 1/64 loss: -4.032009124755859
Batch 2/64 loss: -3.859626293182373
Batch 3/64 loss: -3.808584690093994
Batch 4/64 loss: -3.5396065711975098
Batch 5/64 loss: -3.762073516845703
Batch 6/64 loss: -3.82354736328125
Batch 7/64 loss: -3.529813766479492
Batch 8/64 loss: -3.7704381942749023
Batch 9/64 loss: -3.9856362342834473
Batch 10/64 loss: -3.742978572845459
Batch 11/64 loss: -3.8735036849975586
Batch 12/64 loss: -3.7967681884765625
Batch 13/64 loss: -3.6273093223571777
Batch 14/64 loss: -3.94863224029541
Batch 15/64 loss: -3.6939868927001953
Batch 16/64 loss: -3.920557975769043
Batch 17/64 loss: -3.746781349182129
Batch 18/64 loss: -3.7884116172790527
Batch 19/64 loss: -3.598672389984131
Batch 20/64 loss: -3.777406692504883
Batch 21/64 loss: -3.7645106315612793
Batch 22/64 loss: -3.823190689086914
Batch 23/64 loss: -3.9066901206970215
Batch 24/64 loss: -3.772517204284668
Batch 25/64 loss: -3.662240982055664
Batch 26/64 loss: -3.5634517669677734
Batch 27/64 loss: -3.705589771270752
Batch 28/64 loss: -3.838676929473877
Batch 29/64 loss: -3.5344290733337402
Batch 30/64 loss: -3.9972586631774902
Batch 31/64 loss: -3.3312206268310547
Batch 32/64 loss: -3.8737149238586426
Batch 33/64 loss: -3.8191065788269043
Batch 34/64 loss: -3.940377712249756
Batch 35/64 loss: -3.51124906539917
Batch 36/64 loss: -3.7783336639404297
Batch 37/64 loss: -3.662400245666504
Batch 38/64 loss: -3.7188687324523926
Batch 39/64 loss: -3.9394302368164062
Batch 40/64 loss: -3.975165367126465
Batch 41/64 loss: -3.742906093597412
Batch 42/64 loss: -3.7466306686401367
Batch 43/64 loss: -3.9236369132995605
Batch 44/64 loss: -3.849762439727783
Batch 45/64 loss: -3.8188648223876953
Batch 46/64 loss: -3.7264208793640137
Batch 47/64 loss: -3.7227606773376465
Batch 48/64 loss: -3.912952423095703
Batch 49/64 loss: -4.005063533782959
Batch 50/64 loss: -3.8023786544799805
Batch 51/64 loss: -3.996640205383301
Batch 52/64 loss: -4.111728668212891
Batch 53/64 loss: -3.910257339477539
Batch 54/64 loss: -3.851905345916748
Batch 55/64 loss: -3.6594347953796387
Batch 56/64 loss: -3.813966751098633
Batch 57/64 loss: -3.7924180030822754
Batch 58/64 loss: -3.874971866607666
Batch 59/64 loss: -3.412050247192383
Batch 60/64 loss: -3.860170841217041
Batch 61/64 loss: -3.7448410987854004
Batch 62/64 loss: -3.6464505195617676
Batch 63/64 loss: -3.963282585144043
Batch 64/64 loss: -8.413812637329102
Epoch 300  Train loss: -3.8422685884961894  Val loss: -4.2200426711249595
Saving best model, epoch: 300
Epoch 301
-------------------------------
Batch 1/64 loss: -3.5332136154174805
Batch 2/64 loss: -3.806619644165039
Batch 3/64 loss: -3.748081684112549
Batch 4/64 loss: -3.7037744522094727
Batch 5/64 loss: -3.8925209045410156
Batch 6/64 loss: -3.896833896636963
Batch 7/64 loss: -3.8627114295959473
Batch 8/64 loss: -3.873445987701416
Batch 9/64 loss: -3.9453558921813965
Batch 10/64 loss: -3.8382840156555176
Batch 11/64 loss: -3.498506546020508
Batch 12/64 loss: -3.9519081115722656
Batch 13/64 loss: -3.915900230407715
Batch 14/64 loss: -3.8723926544189453
Batch 15/64 loss: -3.6051926612854004
Batch 16/64 loss: -3.8237671852111816
Batch 17/64 loss: -3.932692050933838
Batch 18/64 loss: -3.7941431999206543
Batch 19/64 loss: -3.902003288269043
Batch 20/64 loss: -3.775662422180176
Batch 21/64 loss: -3.843094825744629
Batch 22/64 loss: -3.9163923263549805
Batch 23/64 loss: -3.8255276679992676
Batch 24/64 loss: -3.5390539169311523
Batch 25/64 loss: -3.7446751594543457
Batch 26/64 loss: -3.8874473571777344
Batch 27/64 loss: -3.7878994941711426
Batch 28/64 loss: -3.597102165222168
Batch 29/64 loss: -3.8858704566955566
Batch 30/64 loss: -3.6888203620910645
Batch 31/64 loss: -3.717874526977539
Batch 32/64 loss: -4.0160627365112305
Batch 33/64 loss: -3.627138137817383
Batch 34/64 loss: -3.807361125946045
Batch 35/64 loss: -3.812901496887207
Batch 36/64 loss: -3.731013298034668
Batch 37/64 loss: -3.231348991394043
Batch 38/64 loss: -4.030457019805908
Batch 39/64 loss: -3.8357138633728027
Batch 40/64 loss: -3.7210044860839844
Batch 41/64 loss: -3.85577392578125
Batch 42/64 loss: -3.802670478820801
Batch 43/64 loss: -3.7103095054626465
Batch 44/64 loss: -3.6747326850891113
Batch 45/64 loss: -3.8682150840759277
Batch 46/64 loss: -4.009521484375
Batch 47/64 loss: -3.9384665489196777
Batch 48/64 loss: -3.769102096557617
Batch 49/64 loss: -3.7781190872192383
Batch 50/64 loss: -3.98342227935791
Batch 51/64 loss: -3.556274890899658
Batch 52/64 loss: -3.6708993911743164
Batch 53/64 loss: -3.6989617347717285
Batch 54/64 loss: -3.994835376739502
Batch 55/64 loss: -3.6486454010009766
Batch 56/64 loss: -3.891946792602539
Batch 57/64 loss: -4.052701950073242
Batch 58/64 loss: -3.8683791160583496
Batch 59/64 loss: -3.8743557929992676
Batch 60/64 loss: -3.6996326446533203
Batch 61/64 loss: -3.865840435028076
Batch 62/64 loss: -4.004115581512451
Batch 63/64 loss: -3.9789490699768066
Batch 64/64 loss: -8.163612365722656
Epoch 301  Train loss: -3.8547192143458946  Val loss: -4.144254192863543
Epoch 302
-------------------------------
Batch 1/64 loss: -3.865354537963867
Batch 2/64 loss: -3.842419147491455
Batch 3/64 loss: -3.8079962730407715
Batch 4/64 loss: -3.8769617080688477
Batch 5/64 loss: -3.8681459426879883
Batch 6/64 loss: -3.9087986946105957
Batch 7/64 loss: -3.6614937782287598
Batch 8/64 loss: -3.5949134826660156
Batch 9/64 loss: -3.628645420074463
Batch 10/64 loss: -3.7109827995300293
Batch 11/64 loss: -4.010368347167969
Batch 12/64 loss: -3.8997764587402344
Batch 13/64 loss: -3.800142765045166
Batch 14/64 loss: -3.8754568099975586
Batch 15/64 loss: -3.7702465057373047
Batch 16/64 loss: -3.5106449127197266
Batch 17/64 loss: -3.746530055999756
Batch 18/64 loss: -3.759145736694336
Batch 19/64 loss: -3.6806411743164062
Batch 20/64 loss: -3.8170485496520996
Batch 21/64 loss: -3.805685043334961
Batch 22/64 loss: -3.4949913024902344
Batch 23/64 loss: -3.8456602096557617
Batch 24/64 loss: -3.849307060241699
Batch 25/64 loss: -3.825397491455078
Batch 26/64 loss: -3.8625893592834473
Batch 27/64 loss: -3.78080415725708
Batch 28/64 loss: -3.736684799194336
Batch 29/64 loss: -3.422299385070801
Batch 30/64 loss: -3.8263869285583496
Batch 31/64 loss: -3.835374355316162
Batch 32/64 loss: -3.929190158843994
Batch 33/64 loss: -3.7302680015563965
Batch 34/64 loss: -3.981006145477295
Batch 35/64 loss: -3.503541946411133
Batch 36/64 loss: -3.919898509979248
Batch 37/64 loss: -3.9666433334350586
Batch 38/64 loss: -3.8063278198242188
Batch 39/64 loss: -3.894674777984619
Batch 40/64 loss: -3.8453807830810547
Batch 41/64 loss: -3.959526538848877
Batch 42/64 loss: -3.938727855682373
Batch 43/64 loss: -3.5009827613830566
Batch 44/64 loss: -3.907796859741211
Batch 45/64 loss: -3.9383931159973145
Batch 46/64 loss: -3.9925403594970703
Batch 47/64 loss: -3.823967456817627
Batch 48/64 loss: -3.7424306869506836
Batch 49/64 loss: -3.7670445442199707
Batch 50/64 loss: -3.8782477378845215
Batch 51/64 loss: -3.8955788612365723
Batch 52/64 loss: -3.8098678588867188
Batch 53/64 loss: -3.859588146209717
Batch 54/64 loss: -3.7023420333862305
Batch 55/64 loss: -3.7083077430725098
Batch 56/64 loss: -4.002387523651123
Batch 57/64 loss: -3.7316322326660156
Batch 58/64 loss: -3.793854236602783
Batch 59/64 loss: -3.576568126678467
Batch 60/64 loss: -3.806748867034912
Batch 61/64 loss: -3.772493362426758
Batch 62/64 loss: -3.9499425888061523
Batch 63/64 loss: -3.884350299835205
Batch 64/64 loss: -8.350931167602539
Epoch 302  Train loss: -3.854185770072189  Val loss: -3.9175087053751207
Epoch 303
-------------------------------
Batch 1/64 loss: -3.729555606842041
Batch 2/64 loss: -3.88370943069458
Batch 3/64 loss: -3.7568511962890625
Batch 4/64 loss: -3.8464913368225098
Batch 5/64 loss: -3.9439034461975098
Batch 6/64 loss: -3.7332849502563477
Batch 7/64 loss: -4.030872821807861
Batch 8/64 loss: -3.7764105796813965
Batch 9/64 loss: -3.861575126647949
Batch 10/64 loss: -3.965318202972412
Batch 11/64 loss: -3.5755743980407715
Batch 12/64 loss: -3.908092975616455
Batch 13/64 loss: -3.857799530029297
Batch 14/64 loss: -3.768049716949463
Batch 15/64 loss: -3.8228936195373535
Batch 16/64 loss: -3.6204724311828613
Batch 17/64 loss: -3.7779541015625
Batch 18/64 loss: -3.8122291564941406
Batch 19/64 loss: -3.808925151824951
Batch 20/64 loss: -3.9079031944274902
Batch 21/64 loss: -3.802443504333496
Batch 22/64 loss: -3.5793046951293945
Batch 23/64 loss: -3.6994738578796387
Batch 24/64 loss: -4.091659069061279
Batch 25/64 loss: -3.91603422164917
Batch 26/64 loss: -3.5724730491638184
Batch 27/64 loss: -3.8965554237365723
Batch 28/64 loss: -3.952305793762207
Batch 29/64 loss: -3.8906826972961426
Batch 30/64 loss: -3.829347610473633
Batch 31/64 loss: -3.752018451690674
Batch 32/64 loss: -3.7954182624816895
Batch 33/64 loss: -3.795264720916748
Batch 34/64 loss: -3.911174774169922
Batch 35/64 loss: -3.888791561126709
Batch 36/64 loss: -3.796813488006592
Batch 37/64 loss: -3.9824533462524414
Batch 38/64 loss: -4.038144588470459
Batch 39/64 loss: -3.748579978942871
Batch 40/64 loss: -3.6912217140197754
Batch 41/64 loss: -3.7254180908203125
Batch 42/64 loss: -3.931788921356201
Batch 43/64 loss: -3.5611095428466797
Batch 44/64 loss: -3.7047672271728516
Batch 45/64 loss: -3.5439467430114746
Batch 46/64 loss: -3.9215316772460938
Batch 47/64 loss: -3.6832566261291504
Batch 48/64 loss: -3.5927629470825195
Batch 49/64 loss: -3.790261745452881
Batch 50/64 loss: -3.603573799133301
Batch 51/64 loss: -3.785355567932129
Batch 52/64 loss: -3.4384803771972656
Batch 53/64 loss: -3.601433277130127
Batch 54/64 loss: -3.781022548675537
Batch 55/64 loss: -3.784205436706543
Batch 56/64 loss: -3.672463893890381
Batch 57/64 loss: -3.8590283393859863
Batch 58/64 loss: -3.8839807510375977
Batch 59/64 loss: -3.8531670570373535
Batch 60/64 loss: -3.7083826065063477
Batch 61/64 loss: -3.831432342529297
Batch 62/64 loss: -3.5768938064575195
Batch 63/64 loss: -3.8183155059814453
Batch 64/64 loss: -8.241714477539062
Epoch 303  Train loss: -3.8408139995500155  Val loss: -4.117226918538411
Epoch 304
-------------------------------
Batch 1/64 loss: -3.936575412750244
Batch 2/64 loss: -3.8237862586975098
Batch 3/64 loss: -3.9615092277526855
Batch 4/64 loss: -3.579629898071289
Batch 5/64 loss: -3.679934501647949
Batch 6/64 loss: -3.75709867477417
Batch 7/64 loss: -3.8691253662109375
Batch 8/64 loss: -3.871415615081787
Batch 9/64 loss: -3.8078489303588867
Batch 10/64 loss: -3.8212671279907227
Batch 11/64 loss: -3.790599822998047
Batch 12/64 loss: -3.761392593383789
Batch 13/64 loss: -3.9134230613708496
Batch 14/64 loss: -3.702530860900879
Batch 15/64 loss: -3.7948412895202637
Batch 16/64 loss: -3.613154411315918
Batch 17/64 loss: -3.897644519805908
Batch 18/64 loss: -3.7377052307128906
Batch 19/64 loss: -3.647538185119629
Batch 20/64 loss: -3.9686145782470703
Batch 21/64 loss: -3.924741268157959
Batch 22/64 loss: -3.8959546089172363
Batch 23/64 loss: -3.976799964904785
Batch 24/64 loss: -3.8929495811462402
Batch 25/64 loss: -3.634467601776123
Batch 26/64 loss: -3.9849324226379395
Batch 27/64 loss: -3.8710832595825195
Batch 28/64 loss: -3.6986441612243652
Batch 29/64 loss: -3.9878787994384766
Batch 30/64 loss: -3.1396026611328125
Batch 31/64 loss: -3.755934715270996
Batch 32/64 loss: -3.79410457611084
Batch 33/64 loss: -3.4896326065063477
Batch 34/64 loss: -3.2156333923339844
Batch 35/64 loss: -3.850594997406006
Batch 36/64 loss: -3.6246790885925293
Batch 37/64 loss: -3.880091667175293
Batch 38/64 loss: -3.7321677207946777
Batch 39/64 loss: -3.649512767791748
Batch 40/64 loss: -3.8335351943969727
Batch 41/64 loss: -3.841370105743408
Batch 42/64 loss: -3.782071590423584
Batch 43/64 loss: -3.3833236694335938
Batch 44/64 loss: -3.726351261138916
Batch 45/64 loss: -3.7720789909362793
Batch 46/64 loss: -3.774169445037842
Batch 47/64 loss: -3.908857822418213
Batch 48/64 loss: -3.7434725761413574
Batch 49/64 loss: -3.6463804244995117
Batch 50/64 loss: -3.8766350746154785
Batch 51/64 loss: -3.9901866912841797
Batch 52/64 loss: -3.966379165649414
Batch 53/64 loss: -3.789215087890625
Batch 54/64 loss: -3.799757480621338
Batch 55/64 loss: -3.700821876525879
Batch 56/64 loss: -3.338606834411621
Batch 57/64 loss: -3.5730772018432617
Batch 58/64 loss: -3.7058444023132324
Batch 59/64 loss: -3.905007839202881
Batch 60/64 loss: -3.7003211975097656
Batch 61/64 loss: -3.9232635498046875
Batch 62/64 loss: -3.7731423377990723
Batch 63/64 loss: -3.5773887634277344
Batch 64/64 loss: -8.3255033493042
Epoch 304  Train loss: -3.815065529767205  Val loss: -4.015192720078931
Epoch 305
-------------------------------
Batch 1/64 loss: -3.819688320159912
Batch 2/64 loss: -3.8030247688293457
Batch 3/64 loss: -3.833543300628662
Batch 4/64 loss: -3.4227399826049805
Batch 5/64 loss: -3.4718284606933594
Batch 6/64 loss: -3.746730327606201
Batch 7/64 loss: -3.4994430541992188
Batch 8/64 loss: -3.953723907470703
Batch 9/64 loss: -3.4756908416748047
Batch 10/64 loss: -3.7903828620910645
Batch 11/64 loss: -3.840364933013916
Batch 12/64 loss: -3.8758926391601562
Batch 13/64 loss: -3.874148368835449
Batch 14/64 loss: -3.7536230087280273
Batch 15/64 loss: -3.6700234413146973
Batch 16/64 loss: -3.969489097595215
Batch 17/64 loss: -3.8513364791870117
Batch 18/64 loss: -3.9400386810302734
Batch 19/64 loss: -3.7440195083618164
Batch 20/64 loss: -3.987734317779541
Batch 21/64 loss: -3.6910762786865234
Batch 22/64 loss: -3.964175224304199
Batch 23/64 loss: -3.7610278129577637
Batch 24/64 loss: -3.877596378326416
Batch 25/64 loss: -3.70448637008667
Batch 26/64 loss: -3.6918864250183105
Batch 27/64 loss: -3.906832218170166
Batch 28/64 loss: -3.9097752571105957
Batch 29/64 loss: -3.9563894271850586
Batch 30/64 loss: -3.741316795349121
Batch 31/64 loss: -3.8161778450012207
Batch 32/64 loss: -3.9093847274780273
Batch 33/64 loss: -3.944735527038574
Batch 34/64 loss: -3.7527594566345215
Batch 35/64 loss: -3.561643600463867
Batch 36/64 loss: -3.782839775085449
Batch 37/64 loss: -3.6834187507629395
Batch 38/64 loss: -3.6363744735717773
Batch 39/64 loss: -3.745091438293457
Batch 40/64 loss: -3.7409791946411133
Batch 41/64 loss: -3.843578815460205
Batch 42/64 loss: -3.673577308654785
Batch 43/64 loss: -3.708611011505127
Batch 44/64 loss: -3.7739338874816895
Batch 45/64 loss: -3.4366416931152344
Batch 46/64 loss: -3.582892894744873
Batch 47/64 loss: -3.906876564025879
Batch 48/64 loss: -3.893730640411377
Batch 49/64 loss: -3.8852005004882812
Batch 50/64 loss: -3.910694122314453
Batch 51/64 loss: -3.833026885986328
Batch 52/64 loss: -3.8665108680725098
Batch 53/64 loss: -3.7406492233276367
Batch 54/64 loss: -3.6697959899902344
Batch 55/64 loss: -3.8688650131225586
Batch 56/64 loss: -3.8609046936035156
Batch 57/64 loss: -3.9855270385742188
Batch 58/64 loss: -3.5236616134643555
Batch 59/64 loss: -3.822482109069824
Batch 60/64 loss: -3.783082962036133
Batch 61/64 loss: -3.7652463912963867
Batch 62/64 loss: -3.884720802307129
Batch 63/64 loss: -3.8926515579223633
Batch 64/64 loss: -8.500713348388672
Epoch 305  Train loss: -3.8367032294179877  Val loss: -4.185641403460421
Epoch 306
-------------------------------
Batch 1/64 loss: -3.937122344970703
Batch 2/64 loss: -3.906742572784424
Batch 3/64 loss: -3.3400039672851562
Batch 4/64 loss: -3.736691951751709
Batch 5/64 loss: -3.850221633911133
Batch 6/64 loss: -3.738858699798584
Batch 7/64 loss: -3.8031859397888184
Batch 8/64 loss: -3.8945679664611816
Batch 9/64 loss: -3.985322952270508
Batch 10/64 loss: -3.5524206161499023
Batch 11/64 loss: -3.6978559494018555
Batch 12/64 loss: -3.7098679542541504
Batch 13/64 loss: -3.868257999420166
Batch 14/64 loss: -3.5902791023254395
Batch 15/64 loss: -3.9006385803222656
Batch 16/64 loss: -3.7041711807250977
Batch 17/64 loss: -3.8059120178222656
Batch 18/64 loss: -3.599611759185791
Batch 19/64 loss: -3.9133739471435547
Batch 20/64 loss: -3.798002243041992
Batch 21/64 loss: -3.8554434776306152
Batch 22/64 loss: -3.947720527648926
Batch 23/64 loss: -3.8658347129821777
Batch 24/64 loss: -4.037026405334473
Batch 25/64 loss: -3.8780250549316406
Batch 26/64 loss: -3.694899559020996
Batch 27/64 loss: -3.9145255088806152
Batch 28/64 loss: -3.5083398818969727
Batch 29/64 loss: -3.691977024078369
Batch 30/64 loss: -3.431309700012207
Batch 31/64 loss: -3.759671688079834
Batch 32/64 loss: -3.9153218269348145
Batch 33/64 loss: -3.7763195037841797
Batch 34/64 loss: -3.6969761848449707
Batch 35/64 loss: -3.9545865058898926
Batch 36/64 loss: -3.746619701385498
Batch 37/64 loss: -3.740333080291748
Batch 38/64 loss: -3.9221043586730957
Batch 39/64 loss: -3.859065055847168
Batch 40/64 loss: -3.800095558166504
Batch 41/64 loss: -3.4221038818359375
Batch 42/64 loss: -3.7369461059570312
Batch 43/64 loss: -3.9639835357666016
Batch 44/64 loss: -3.8289194107055664
Batch 45/64 loss: -3.38913631439209
Batch 46/64 loss: -3.9994988441467285
Batch 47/64 loss: -3.93192195892334
Batch 48/64 loss: -3.493462085723877
Batch 49/64 loss: -3.556063175201416
Batch 50/64 loss: -3.6272077560424805
Batch 51/64 loss: -3.935458183288574
Batch 52/64 loss: -3.933957099914551
Batch 53/64 loss: -3.9880852699279785
Batch 54/64 loss: -4.0231170654296875
Batch 55/64 loss: -3.846693515777588
Batch 56/64 loss: -3.860358238220215
Batch 57/64 loss: -4.0134477615356445
Batch 58/64 loss: -3.7448654174804688
Batch 59/64 loss: -3.9860877990722656
Batch 60/64 loss: -3.710456371307373
Batch 61/64 loss: -3.945669651031494
Batch 62/64 loss: -4.026027679443359
Batch 63/64 loss: -3.917189598083496
Batch 64/64 loss: -8.32275390625
Epoch 306  Train loss: -3.8502278720631318  Val loss: -4.172421969908619
Epoch 307
-------------------------------
Batch 1/64 loss: -3.6876111030578613
Batch 2/64 loss: -3.9494309425354004
Batch 3/64 loss: -3.739509105682373
Batch 4/64 loss: -3.9557957649230957
Batch 5/64 loss: -3.9521336555480957
Batch 6/64 loss: -3.897698402404785
Batch 7/64 loss: -3.906893253326416
Batch 8/64 loss: -3.917947769165039
Batch 9/64 loss: -3.9124808311462402
Batch 10/64 loss: -3.7727699279785156
Batch 11/64 loss: -3.9407644271850586
Batch 12/64 loss: -3.5424795150756836
Batch 13/64 loss: -4.011311054229736
Batch 14/64 loss: -3.969940662384033
Batch 15/64 loss: -3.9593605995178223
Batch 16/64 loss: -3.9583420753479004
Batch 17/64 loss: -3.9693832397460938
Batch 18/64 loss: -3.887814521789551
Batch 19/64 loss: -3.9199576377868652
Batch 20/64 loss: -3.6312150955200195
Batch 21/64 loss: -3.9061198234558105
Batch 22/64 loss: -3.9595818519592285
Batch 23/64 loss: -3.841580867767334
Batch 24/64 loss: -3.904791831970215
Batch 25/64 loss: -3.970841407775879
Batch 26/64 loss: -3.987055778503418
Batch 27/64 loss: -3.8345561027526855
Batch 28/64 loss: -3.850377082824707
Batch 29/64 loss: -3.900359630584717
Batch 30/64 loss: -3.478809356689453
Batch 31/64 loss: -3.8969593048095703
Batch 32/64 loss: -3.799807548522949
Batch 33/64 loss: -4.058106422424316
Batch 34/64 loss: -3.6954617500305176
Batch 35/64 loss: -3.5488171577453613
Batch 36/64 loss: -3.64835786819458
Batch 37/64 loss: -3.5363783836364746
Batch 38/64 loss: -3.976945400238037
Batch 39/64 loss: -4.02201509475708
Batch 40/64 loss: -3.954916477203369
Batch 41/64 loss: -3.913194179534912
Batch 42/64 loss: -3.492208957672119
Batch 43/64 loss: -3.8896713256835938
Batch 44/64 loss: -4.061964511871338
Batch 45/64 loss: -3.6749348640441895
Batch 46/64 loss: -3.846055030822754
Batch 47/64 loss: -3.9044666290283203
Batch 48/64 loss: -3.8972840309143066
Batch 49/64 loss: -3.4157609939575195
Batch 50/64 loss: -3.9819698333740234
Batch 51/64 loss: -3.8469762802124023
Batch 52/64 loss: -3.7690248489379883
Batch 53/64 loss: -3.9664149284362793
Batch 54/64 loss: -3.8657655715942383
Batch 55/64 loss: -3.6682491302490234
Batch 56/64 loss: -3.935391902923584
Batch 57/64 loss: -3.5796146392822266
Batch 58/64 loss: -3.6724448204040527
Batch 59/64 loss: -3.739114284515381
Batch 60/64 loss: -3.9057393074035645
Batch 61/64 loss: -3.791536808013916
Batch 62/64 loss: -3.401871681213379
Batch 63/64 loss: -3.7564830780029297
Batch 64/64 loss: -8.421875
Epoch 307  Train loss: -3.8830936880672677  Val loss: -4.1716231251090665
Epoch 308
-------------------------------
Batch 1/64 loss: -3.922187328338623
Batch 2/64 loss: -3.8510007858276367
Batch 3/64 loss: -3.9994397163391113
Batch 4/64 loss: -3.8207578659057617
Batch 5/64 loss: -3.8351588249206543
Batch 6/64 loss: -3.906602382659912
Batch 7/64 loss: -3.925015449523926
Batch 8/64 loss: -3.82820987701416
Batch 9/64 loss: -3.8737878799438477
Batch 10/64 loss: -3.776414394378662
Batch 11/64 loss: -3.7589921951293945
Batch 12/64 loss: -3.927267074584961
Batch 13/64 loss: -3.540513515472412
Batch 14/64 loss: -3.9437079429626465
Batch 15/64 loss: -3.8727712631225586
Batch 16/64 loss: -3.914299488067627
Batch 17/64 loss: -3.8327932357788086
Batch 18/64 loss: -3.6058430671691895
Batch 19/64 loss: -3.994145393371582
Batch 20/64 loss: -3.837075710296631
Batch 21/64 loss: -3.5070128440856934
Batch 22/64 loss: -3.560290813446045
Batch 23/64 loss: -3.8932905197143555
Batch 24/64 loss: -3.8011960983276367
Batch 25/64 loss: -3.7465224266052246
Batch 26/64 loss: -3.82320499420166
Batch 27/64 loss: -3.8657174110412598
Batch 28/64 loss: -3.727707862854004
Batch 29/64 loss: -3.8312888145446777
Batch 30/64 loss: -3.8743982315063477
Batch 31/64 loss: -3.7422475814819336
Batch 32/64 loss: -3.8520145416259766
Batch 33/64 loss: -3.851870536804199
Batch 34/64 loss: -3.9049320220947266
Batch 35/64 loss: -3.9742531776428223
Batch 36/64 loss: -3.977808952331543
Batch 37/64 loss: -3.7813076972961426
Batch 38/64 loss: -3.902092456817627
Batch 39/64 loss: -3.8685693740844727
Batch 40/64 loss: -3.6765127182006836
Batch 41/64 loss: -3.823002815246582
Batch 42/64 loss: -3.3472728729248047
Batch 43/64 loss: -3.7533555030822754
Batch 44/64 loss: -3.945919990539551
Batch 45/64 loss: -3.832672119140625
Batch 46/64 loss: -3.7693066596984863
Batch 47/64 loss: -3.9548048973083496
Batch 48/64 loss: -3.6967406272888184
Batch 49/64 loss: -3.9165096282958984
Batch 50/64 loss: -3.9709372520446777
Batch 51/64 loss: -3.9316511154174805
Batch 52/64 loss: -3.4728779792785645
Batch 53/64 loss: -3.8908581733703613
Batch 54/64 loss: -3.9257164001464844
Batch 55/64 loss: -3.7035298347473145
Batch 56/64 loss: -3.8025031089782715
Batch 57/64 loss: -3.8601460456848145
Batch 58/64 loss: -3.933732509613037
Batch 59/64 loss: -3.820279598236084
Batch 60/64 loss: -3.761687755584717
Batch 61/64 loss: -3.75357723236084
Batch 62/64 loss: -3.914400577545166
Batch 63/64 loss: -3.703174591064453
Batch 64/64 loss: -8.114333152770996
Epoch 308  Train loss: -3.8697824253755457  Val loss: -4.040225445200078
Epoch 309
-------------------------------
Batch 1/64 loss: -3.6439175605773926
Batch 2/64 loss: -3.7263364791870117
Batch 3/64 loss: -3.9836931228637695
Batch 4/64 loss: -3.6684842109680176
Batch 5/64 loss: -3.600399971008301
Batch 6/64 loss: -3.69852352142334
Batch 7/64 loss: -3.8475141525268555
Batch 8/64 loss: -3.7209372520446777
Batch 9/64 loss: -3.747321605682373
Batch 10/64 loss: -3.6401777267456055
Batch 11/64 loss: -3.674345016479492
Batch 12/64 loss: -3.726266384124756
Batch 13/64 loss: -3.7587361335754395
Batch 14/64 loss: -3.0088815689086914
Batch 15/64 loss: -3.723633289337158
Batch 16/64 loss: -3.788005828857422
Batch 17/64 loss: -3.6509194374084473
Batch 18/64 loss: -3.810123920440674
Batch 19/64 loss: -3.6351208686828613
Batch 20/64 loss: -2.941089630126953
Batch 21/64 loss: -3.7996273040771484
Batch 22/64 loss: -3.658071517944336
Batch 23/64 loss: -3.809782028198242
Batch 24/64 loss: -3.701836585998535
Batch 25/64 loss: -3.6201539039611816
Batch 26/64 loss: -3.6689162254333496
Batch 27/64 loss: -3.8009209632873535
Batch 28/64 loss: -3.7131266593933105
Batch 29/64 loss: -3.8891334533691406
Batch 30/64 loss: -3.85933780670166
Batch 31/64 loss: -3.9452967643737793
Batch 32/64 loss: -3.3406410217285156
Batch 33/64 loss: -3.841771125793457
Batch 34/64 loss: -3.7916011810302734
Batch 35/64 loss: -3.4313125610351562
Batch 36/64 loss: -3.799290180206299
Batch 37/64 loss: -3.8208465576171875
Batch 38/64 loss: -3.651884078979492
Batch 39/64 loss: -3.607408046722412
Batch 40/64 loss: -3.981858730316162
Batch 41/64 loss: -3.9270877838134766
Batch 42/64 loss: -3.6830954551696777
Batch 43/64 loss: -3.7708210945129395
Batch 44/64 loss: -3.763979434967041
Batch 45/64 loss: -3.68221378326416
Batch 46/64 loss: -3.641611099243164
Batch 47/64 loss: -3.951756000518799
Batch 48/64 loss: -3.721864700317383
Batch 49/64 loss: -3.700942039489746
Batch 50/64 loss: -3.806993007659912
Batch 51/64 loss: -3.6923279762268066
Batch 52/64 loss: -3.8391451835632324
Batch 53/64 loss: -3.640427589416504
Batch 54/64 loss: -3.8236918449401855
Batch 55/64 loss: -3.8292198181152344
Batch 56/64 loss: -3.918598175048828
Batch 57/64 loss: -3.6209959983825684
Batch 58/64 loss: -3.836005210876465
Batch 59/64 loss: -3.8237133026123047
Batch 60/64 loss: -3.9399185180664062
Batch 61/64 loss: -3.5615720748901367
Batch 62/64 loss: -3.7722291946411133
Batch 63/64 loss: -3.960188388824463
Batch 64/64 loss: -8.448184967041016
Epoch 309  Train loss: -3.7799495023839613  Val loss: -4.185413714536686
Epoch 310
-------------------------------
Batch 1/64 loss: -3.624913215637207
Batch 2/64 loss: -3.800318717956543
Batch 3/64 loss: -3.938150405883789
Batch 4/64 loss: -3.8630380630493164
Batch 5/64 loss: -3.875422954559326
Batch 6/64 loss: -4.0164408683776855
Batch 7/64 loss: -3.4922051429748535
Batch 8/64 loss: -3.7893619537353516
Batch 9/64 loss: -3.7747750282287598
Batch 10/64 loss: -3.9466519355773926
Batch 11/64 loss: -3.6782264709472656
Batch 12/64 loss: -3.585632801055908
Batch 13/64 loss: -3.838879108428955
Batch 14/64 loss: -3.820167064666748
Batch 15/64 loss: -3.910017490386963
Batch 16/64 loss: -3.8723387718200684
Batch 17/64 loss: -3.7376456260681152
Batch 18/64 loss: -3.8520874977111816
Batch 19/64 loss: -3.656423568725586
Batch 20/64 loss: -3.836550712585449
Batch 21/64 loss: -3.9780783653259277
Batch 22/64 loss: -3.8313541412353516
Batch 23/64 loss: -3.9836673736572266
Batch 24/64 loss: -3.797147274017334
Batch 25/64 loss: -3.8422093391418457
Batch 26/64 loss: -3.783107280731201
Batch 27/64 loss: -3.5657591819763184
Batch 28/64 loss: -3.89909029006958
Batch 29/64 loss: -3.6498684883117676
Batch 30/64 loss: -3.739891529083252
Batch 31/64 loss: -3.807445526123047
Batch 32/64 loss: -3.8979811668395996
Batch 33/64 loss: -3.905935764312744
Batch 34/64 loss: -3.851245403289795
Batch 35/64 loss: -3.910390853881836
Batch 36/64 loss: -3.7748193740844727
Batch 37/64 loss: -3.739957332611084
Batch 38/64 loss: -3.7707409858703613
Batch 39/64 loss: -3.8384714126586914
Batch 40/64 loss: -4.06916618347168
Batch 41/64 loss: -3.9994068145751953
Batch 42/64 loss: -3.966663360595703
Batch 43/64 loss: -4.081059455871582
Batch 44/64 loss: -3.738462448120117
Batch 45/64 loss: -3.6006007194519043
Batch 46/64 loss: -3.9653077125549316
Batch 47/64 loss: -3.992983818054199
Batch 48/64 loss: -3.668306350708008
Batch 49/64 loss: -3.882598876953125
Batch 50/64 loss: -3.7084946632385254
Batch 51/64 loss: -3.703211784362793
Batch 52/64 loss: -3.813697338104248
Batch 53/64 loss: -4.003172874450684
Batch 54/64 loss: -3.3963842391967773
Batch 55/64 loss: -3.8309316635131836
Batch 56/64 loss: -3.826855182647705
Batch 57/64 loss: -3.818596839904785
Batch 58/64 loss: -3.760812759399414
Batch 59/64 loss: -3.7441787719726562
Batch 60/64 loss: -3.8407864570617676
Batch 61/64 loss: -4.097336769104004
Batch 62/64 loss: -3.7717161178588867
Batch 63/64 loss: -3.7589211463928223
Batch 64/64 loss: -8.502344131469727
Epoch 310  Train loss: -3.872828532200234  Val loss: -4.161626533954005
Epoch 311
-------------------------------
Batch 1/64 loss: -4.034527778625488
Batch 2/64 loss: -3.47428035736084
Batch 3/64 loss: -3.8612403869628906
Batch 4/64 loss: -3.804896831512451
Batch 5/64 loss: -3.3773794174194336
Batch 6/64 loss: -3.9641289710998535
Batch 7/64 loss: -3.9531960487365723
Batch 8/64 loss: -3.878814697265625
Batch 9/64 loss: -3.8962011337280273
Batch 10/64 loss: -3.630429267883301
Batch 11/64 loss: -3.8095240592956543
Batch 12/64 loss: -3.6156649589538574
Batch 13/64 loss: -3.6547460556030273
Batch 14/64 loss: -3.931901454925537
Batch 15/64 loss: -3.990330696105957
Batch 16/64 loss: -3.893592357635498
Batch 17/64 loss: -3.8645830154418945
Batch 18/64 loss: -3.895984172821045
Batch 19/64 loss: -3.56195068359375
Batch 20/64 loss: -4.046929836273193
Batch 21/64 loss: -3.754955768585205
Batch 22/64 loss: -3.8501639366149902
Batch 23/64 loss: -3.8877601623535156
Batch 24/64 loss: -3.6816983222961426
Batch 25/64 loss: -3.688441753387451
Batch 26/64 loss: -3.6545209884643555
Batch 27/64 loss: -3.805941104888916
Batch 28/64 loss: -3.92667818069458
Batch 29/64 loss: -3.8281354904174805
Batch 30/64 loss: -3.7171425819396973
Batch 31/64 loss: -3.724806308746338
Batch 32/64 loss: -3.4349536895751953
Batch 33/64 loss: -3.838733673095703
Batch 34/64 loss: -3.9344429969787598
Batch 35/64 loss: -3.788773536682129
Batch 36/64 loss: -3.9525041580200195
Batch 37/64 loss: -3.9128360748291016
Batch 38/64 loss: -3.641200542449951
Batch 39/64 loss: -3.9216504096984863
Batch 40/64 loss: -3.9586434364318848
Batch 41/64 loss: -3.6947898864746094
Batch 42/64 loss: -3.6547112464904785
Batch 43/64 loss: -4.012557029724121
Batch 44/64 loss: -3.932504653930664
Batch 45/64 loss: -3.8494434356689453
Batch 46/64 loss: -4.045877933502197
Batch 47/64 loss: -3.9560604095458984
Batch 48/64 loss: -3.8642306327819824
Batch 49/64 loss: -4.050209045410156
Batch 50/64 loss: -3.9247303009033203
Batch 51/64 loss: -3.7400360107421875
Batch 52/64 loss: -3.933774948120117
Batch 53/64 loss: -3.985538959503174
Batch 54/64 loss: -3.9624242782592773
Batch 55/64 loss: -3.9936866760253906
Batch 56/64 loss: -3.796398639678955
Batch 57/64 loss: -3.7062296867370605
Batch 58/64 loss: -3.9094204902648926
Batch 59/64 loss: -4.052768707275391
Batch 60/64 loss: -4.040842533111572
Batch 61/64 loss: -3.665034294128418
Batch 62/64 loss: -4.058665752410889
Batch 63/64 loss: -3.9876251220703125
Batch 64/64 loss: -8.337655067443848
Epoch 311  Train loss: -3.8920013689527324  Val loss: -4.192942983096408
Epoch 312
-------------------------------
Batch 1/64 loss: -3.7430553436279297
Batch 2/64 loss: -3.642824649810791
Batch 3/64 loss: -3.9932289123535156
Batch 4/64 loss: -3.7308034896850586
Batch 5/64 loss: -3.6902060508728027
Batch 6/64 loss: -3.817945957183838
Batch 7/64 loss: -3.7592267990112305
Batch 8/64 loss: -3.8998665809631348
Batch 9/64 loss: -3.879601001739502
Batch 10/64 loss: -3.5678019523620605
Batch 11/64 loss: -3.776028633117676
Batch 12/64 loss: -3.6663994789123535
Batch 13/64 loss: -3.836721420288086
Batch 14/64 loss: -3.6351327896118164
Batch 15/64 loss: -3.78395938873291
Batch 16/64 loss: -3.729362964630127
Batch 17/64 loss: -3.8864383697509766
Batch 18/64 loss: -3.6829299926757812
Batch 19/64 loss: -3.422091484069824
Batch 20/64 loss: -3.864055633544922
Batch 21/64 loss: -3.9451680183410645
Batch 22/64 loss: -3.980165958404541
Batch 23/64 loss: -3.9247074127197266
Batch 24/64 loss: -3.950763702392578
Batch 25/64 loss: -3.9401588439941406
Batch 26/64 loss: -3.9182825088500977
Batch 27/64 loss: -3.7872467041015625
Batch 28/64 loss: -3.904839038848877
Batch 29/64 loss: -3.9068307876586914
Batch 30/64 loss: -4.04341983795166
Batch 31/64 loss: -3.8330864906311035
Batch 32/64 loss: -3.9582719802856445
Batch 33/64 loss: -4.015063762664795
Batch 34/64 loss: -4.031882286071777
Batch 35/64 loss: -3.8787317276000977
Batch 36/64 loss: -3.5417447090148926
Batch 37/64 loss: -4.071490287780762
Batch 38/64 loss: -3.916663646697998
Batch 39/64 loss: -3.963796615600586
Batch 40/64 loss: -3.7775583267211914
Batch 41/64 loss: -3.9498238563537598
Batch 42/64 loss: -3.8926639556884766
Batch 43/64 loss: -3.951785087585449
Batch 44/64 loss: -3.8694639205932617
Batch 45/64 loss: -3.8448352813720703
Batch 46/64 loss: -3.917329788208008
Batch 47/64 loss: -3.7686004638671875
Batch 48/64 loss: -3.836195945739746
Batch 49/64 loss: -3.847287178039551
Batch 50/64 loss: -3.8967151641845703
Batch 51/64 loss: -3.9580488204956055
Batch 52/64 loss: -3.947998523712158
Batch 53/64 loss: -3.9836974143981934
Batch 54/64 loss: -4.079568862915039
Batch 55/64 loss: -3.861095905303955
Batch 56/64 loss: -3.9640560150146484
Batch 57/64 loss: -3.9077348709106445
Batch 58/64 loss: -3.942490577697754
Batch 59/64 loss: -3.8917441368103027
Batch 60/64 loss: -3.7239418029785156
Batch 61/64 loss: -3.774470329284668
Batch 62/64 loss: -3.9089174270629883
Batch 63/64 loss: -3.940951347351074
Batch 64/64 loss: -8.303495407104492
Epoch 312  Train loss: -3.908777910120347  Val loss: -4.165998426089992
Epoch 313
-------------------------------
Batch 1/64 loss: -3.8403539657592773
Batch 2/64 loss: -3.915760040283203
Batch 3/64 loss: -3.9489989280700684
Batch 4/64 loss: -3.8863654136657715
Batch 5/64 loss: -3.803969383239746
Batch 6/64 loss: -3.6295289993286133
Batch 7/64 loss: -3.7587695121765137
Batch 8/64 loss: -3.791375160217285
Batch 9/64 loss: -3.967766761779785
Batch 10/64 loss: -3.705225944519043
Batch 11/64 loss: -3.7186217308044434
Batch 12/64 loss: -3.8988394737243652
Batch 13/64 loss: -3.825197219848633
Batch 14/64 loss: -3.8309731483459473
Batch 15/64 loss: -3.8399806022644043
Batch 16/64 loss: -3.9544506072998047
Batch 17/64 loss: -3.8777308464050293
Batch 18/64 loss: -3.5809688568115234
Batch 19/64 loss: -3.766808032989502
Batch 20/64 loss: -3.8335719108581543
Batch 21/64 loss: -3.813999652862549
Batch 22/64 loss: -3.881727695465088
Batch 23/64 loss: -3.5946483612060547
Batch 24/64 loss: -3.9462404251098633
Batch 25/64 loss: -3.850224494934082
Batch 26/64 loss: -3.853449821472168
Batch 27/64 loss: -3.9295921325683594
Batch 28/64 loss: -3.7538881301879883
Batch 29/64 loss: -3.733642578125
Batch 30/64 loss: -3.6655025482177734
Batch 31/64 loss: -4.054526329040527
Batch 32/64 loss: -3.276796340942383
Batch 33/64 loss: -3.7937607765197754
Batch 34/64 loss: -3.595308303833008
Batch 35/64 loss: -3.8436222076416016
Batch 36/64 loss: -3.7911839485168457
Batch 37/64 loss: -3.973559856414795
Batch 38/64 loss: -3.8642706871032715
Batch 39/64 loss: -3.268291473388672
Batch 40/64 loss: -3.899099349975586
Batch 41/64 loss: -3.639965057373047
Batch 42/64 loss: -3.824716091156006
Batch 43/64 loss: -3.7819299697875977
Batch 44/64 loss: -3.853572368621826
Batch 45/64 loss: -3.723544120788574
Batch 46/64 loss: -3.9927115440368652
Batch 47/64 loss: -3.7754197120666504
Batch 48/64 loss: -4.018382549285889
Batch 49/64 loss: -3.8569798469543457
Batch 50/64 loss: -3.6488165855407715
Batch 51/64 loss: -3.8762855529785156
Batch 52/64 loss: -3.847477436065674
Batch 53/64 loss: -3.684971809387207
Batch 54/64 loss: -3.9578747749328613
Batch 55/64 loss: -3.7534356117248535
Batch 56/64 loss: -3.8839025497436523
Batch 57/64 loss: -3.8973588943481445
Batch 58/64 loss: -3.864748954772949
Batch 59/64 loss: -3.444901466369629
Batch 60/64 loss: -3.592371940612793
Batch 61/64 loss: -3.958517074584961
Batch 62/64 loss: -3.6370906829833984
Batch 63/64 loss: -3.9835309982299805
Batch 64/64 loss: -8.166224479675293
Epoch 313  Train loss: -3.8491257349650065  Val loss: -4.251031410243503
Saving best model, epoch: 313
Epoch 314
-------------------------------
Batch 1/64 loss: -3.8945999145507812
Batch 2/64 loss: -3.8350749015808105
Batch 3/64 loss: -3.931734561920166
Batch 4/64 loss: -3.3048830032348633
Batch 5/64 loss: -3.8681387901306152
Batch 6/64 loss: -4.026264190673828
Batch 7/64 loss: -3.917644500732422
Batch 8/64 loss: -3.7999773025512695
Batch 9/64 loss: -3.799797534942627
Batch 10/64 loss: -3.7649788856506348
Batch 11/64 loss: -3.867814064025879
Batch 12/64 loss: -3.6473922729492188
Batch 13/64 loss: -3.933109760284424
Batch 14/64 loss: -3.901407241821289
Batch 15/64 loss: -3.8228158950805664
Batch 16/64 loss: -3.8267154693603516
Batch 17/64 loss: -4.0124006271362305
Batch 18/64 loss: -3.9537158012390137
Batch 19/64 loss: -3.973832130432129
Batch 20/64 loss: -3.869117259979248
Batch 21/64 loss: -3.8629703521728516
Batch 22/64 loss: -3.9500961303710938
Batch 23/64 loss: -3.9208288192749023
Batch 24/64 loss: -3.9725046157836914
Batch 25/64 loss: -3.7830090522766113
Batch 26/64 loss: -3.7091565132141113
Batch 27/64 loss: -3.900242328643799
Batch 28/64 loss: -3.935959815979004
Batch 29/64 loss: -3.998197078704834
Batch 30/64 loss: -3.957329273223877
Batch 31/64 loss: -3.7237696647644043
Batch 32/64 loss: -4.05397891998291
Batch 33/64 loss: -3.9771761894226074
Batch 34/64 loss: -3.860136032104492
Batch 35/64 loss: -4.0311455726623535
Batch 36/64 loss: -3.962486743927002
Batch 37/64 loss: -3.9523367881774902
Batch 38/64 loss: -3.871495246887207
Batch 39/64 loss: -4.042459487915039
Batch 40/64 loss: -3.8944907188415527
Batch 41/64 loss: -4.039957523345947
Batch 42/64 loss: -3.885805606842041
Batch 43/64 loss: -3.387711524963379
Batch 44/64 loss: -3.99696683883667
Batch 45/64 loss: -3.942446231842041
Batch 46/64 loss: -3.9428224563598633
Batch 47/64 loss: -3.8390755653381348
Batch 48/64 loss: -3.860776424407959
Batch 49/64 loss: -3.8319849967956543
Batch 50/64 loss: -3.8586478233337402
Batch 51/64 loss: -3.8259363174438477
Batch 52/64 loss: -3.959930419921875
Batch 53/64 loss: -3.675304889678955
Batch 54/64 loss: -3.916414737701416
Batch 55/64 loss: -3.7840847969055176
Batch 56/64 loss: -3.799236297607422
Batch 57/64 loss: -3.693361282348633
Batch 58/64 loss: -4.039251327514648
Batch 59/64 loss: -3.6263785362243652
Batch 60/64 loss: -3.87786865234375
Batch 61/64 loss: -3.8038454055786133
Batch 62/64 loss: -3.9017200469970703
Batch 63/64 loss: -3.9984288215637207
Batch 64/64 loss: -8.54109001159668
Epoch 314  Train loss: -3.9247836468266506  Val loss: -4.264999874678674
Saving best model, epoch: 314
Epoch 315
-------------------------------
Batch 1/64 loss: -3.541377067565918
Batch 2/64 loss: -3.8734030723571777
Batch 3/64 loss: -3.996981143951416
Batch 4/64 loss: -3.861757278442383
Batch 5/64 loss: -3.9986624717712402
Batch 6/64 loss: -3.8554978370666504
Batch 7/64 loss: -3.6290431022644043
Batch 8/64 loss: -3.946530818939209
Batch 9/64 loss: -3.9668707847595215
Batch 10/64 loss: -3.684302806854248
Batch 11/64 loss: -3.9884209632873535
Batch 12/64 loss: -4.028416156768799
Batch 13/64 loss: -3.798943519592285
Batch 14/64 loss: -3.862187385559082
Batch 15/64 loss: -3.912755012512207
Batch 16/64 loss: -3.876948356628418
Batch 17/64 loss: -3.79691219329834
Batch 18/64 loss: -3.932973861694336
Batch 19/64 loss: -3.9380173683166504
Batch 20/64 loss: -4.024035930633545
Batch 21/64 loss: -3.9181346893310547
Batch 22/64 loss: -3.921098232269287
Batch 23/64 loss: -3.9465084075927734
Batch 24/64 loss: -3.9163756370544434
Batch 25/64 loss: -3.811863422393799
Batch 26/64 loss: -3.8836827278137207
Batch 27/64 loss: -3.8960814476013184
Batch 28/64 loss: -3.8260488510131836
Batch 29/64 loss: -3.859714984893799
Batch 30/64 loss: -3.8826751708984375
Batch 31/64 loss: -3.817452907562256
Batch 32/64 loss: -3.964531421661377
Batch 33/64 loss: -3.878361225128174
Batch 34/64 loss: -3.503115653991699
Batch 35/64 loss: -3.8318324089050293
Batch 36/64 loss: -3.5776829719543457
Batch 37/64 loss: -3.954094409942627
Batch 38/64 loss: -3.8836984634399414
Batch 39/64 loss: -3.9777445793151855
Batch 40/64 loss: -3.861558437347412
Batch 41/64 loss: -3.807178497314453
Batch 42/64 loss: -3.9635748863220215
Batch 43/64 loss: -3.7052230834960938
Batch 44/64 loss: -3.846482276916504
Batch 45/64 loss: -3.7983245849609375
Batch 46/64 loss: -3.776101589202881
Batch 47/64 loss: -3.797614097595215
Batch 48/64 loss: -3.7934956550598145
Batch 49/64 loss: -3.8430724143981934
Batch 50/64 loss: -3.9883289337158203
Batch 51/64 loss: -4.032101631164551
Batch 52/64 loss: -3.8062291145324707
Batch 53/64 loss: -3.9058361053466797
Batch 54/64 loss: -3.8372225761413574
Batch 55/64 loss: -3.853912830352783
Batch 56/64 loss: -3.6795525550842285
Batch 57/64 loss: -3.9179749488830566
Batch 58/64 loss: -3.946877956390381
Batch 59/64 loss: -3.878647804260254
Batch 60/64 loss: -3.6597681045532227
Batch 61/64 loss: -3.7941298484802246
Batch 62/64 loss: -3.587878704071045
Batch 63/64 loss: -3.932427406311035
Batch 64/64 loss: -8.250067710876465
Epoch 315  Train loss: -3.9053458756091546  Val loss: -4.112424686602301
Epoch 316
-------------------------------
Batch 1/64 loss: -3.757843017578125
Batch 2/64 loss: -3.682845115661621
Batch 3/64 loss: -3.954312324523926
Batch 4/64 loss: -3.913978099822998
Batch 5/64 loss: -3.9292640686035156
Batch 6/64 loss: -3.8768534660339355
Batch 7/64 loss: -3.645026206970215
Batch 8/64 loss: -3.878891944885254
Batch 9/64 loss: -3.5435538291931152
Batch 10/64 loss: -3.8789010047912598
Batch 11/64 loss: -3.316237449645996
Batch 12/64 loss: -3.909731388092041
Batch 13/64 loss: -3.6919589042663574
Batch 14/64 loss: -3.800574779510498
Batch 15/64 loss: -3.624147891998291
Batch 16/64 loss: -3.4341087341308594
Batch 17/64 loss: -3.7783193588256836
Batch 18/64 loss: -3.815502643585205
Batch 19/64 loss: -4.0144782066345215
Batch 20/64 loss: -3.7925705909729004
Batch 21/64 loss: -3.566579818725586
Batch 22/64 loss: -3.9091973304748535
Batch 23/64 loss: -3.653656005859375
Batch 24/64 loss: -3.8916192054748535
Batch 25/64 loss: -3.7131104469299316
Batch 26/64 loss: -3.8783836364746094
Batch 27/64 loss: -3.8127212524414062
Batch 28/64 loss: -3.9531211853027344
Batch 29/64 loss: -3.878098964691162
Batch 30/64 loss: -3.5654520988464355
Batch 31/64 loss: -3.8389554023742676
Batch 32/64 loss: -3.8518433570861816
Batch 33/64 loss: -3.8749585151672363
Batch 34/64 loss: -3.7539830207824707
Batch 35/64 loss: -3.9761533737182617
Batch 36/64 loss: -3.8648862838745117
Batch 37/64 loss: -3.9660286903381348
Batch 38/64 loss: -3.760491371154785
Batch 39/64 loss: -3.5225048065185547
Batch 40/64 loss: -3.9056448936462402
Batch 41/64 loss: -3.9077959060668945
Batch 42/64 loss: -3.788221836090088
Batch 43/64 loss: -3.9749417304992676
Batch 44/64 loss: -3.991053581237793
Batch 45/64 loss: -3.855081081390381
Batch 46/64 loss: -3.8354110717773438
Batch 47/64 loss: -3.5922608375549316
Batch 48/64 loss: -3.748476982116699
Batch 49/64 loss: -3.83872652053833
Batch 50/64 loss: -3.691195011138916
Batch 51/64 loss: -3.833186626434326
Batch 52/64 loss: -3.8383569717407227
Batch 53/64 loss: -3.788940906524658
Batch 54/64 loss: -3.9067745208740234
Batch 55/64 loss: -3.3748950958251953
Batch 56/64 loss: -3.948190689086914
Batch 57/64 loss: -3.733614444732666
Batch 58/64 loss: -3.910964012145996
Batch 59/64 loss: -3.8901777267456055
Batch 60/64 loss: -3.932009696960449
Batch 61/64 loss: -3.372555732727051
Batch 62/64 loss: -3.858736991882324
Batch 63/64 loss: -3.9419565200805664
Batch 64/64 loss: -8.317249298095703
Epoch 316  Train loss: -3.8457717671113856  Val loss: -4.167428137920157
Epoch 317
-------------------------------
Batch 1/64 loss: -3.814073085784912
Batch 2/64 loss: -3.672262191772461
Batch 3/64 loss: -3.4022626876831055
Batch 4/64 loss: -3.6269445419311523
Batch 5/64 loss: -3.936276435852051
Batch 6/64 loss: -3.7922191619873047
Batch 7/64 loss: -3.805229663848877
Batch 8/64 loss: -3.935000419616699
Batch 9/64 loss: -3.8382301330566406
Batch 10/64 loss: -4.060794830322266
Batch 11/64 loss: -3.9857592582702637
Batch 12/64 loss: -3.986085891723633
Batch 13/64 loss: -3.854081153869629
Batch 14/64 loss: -3.992349147796631
Batch 15/64 loss: -3.8882322311401367
Batch 16/64 loss: -3.9468183517456055
Batch 17/64 loss: -3.841810703277588
Batch 18/64 loss: -3.8477158546447754
Batch 19/64 loss: -3.7966156005859375
Batch 20/64 loss: -3.791146755218506
Batch 21/64 loss: -3.752192974090576
Batch 22/64 loss: -3.809950828552246
Batch 23/64 loss: -3.776186943054199
Batch 24/64 loss: -3.781531810760498
Batch 25/64 loss: -3.814243793487549
Batch 26/64 loss: -3.7109694480895996
Batch 27/64 loss: -3.80775785446167
Batch 28/64 loss: -3.8959274291992188
Batch 29/64 loss: -3.8416738510131836
Batch 30/64 loss: -3.8252172470092773
Batch 31/64 loss: -3.861689567565918
Batch 32/64 loss: -3.8088126182556152
Batch 33/64 loss: -3.975207805633545
Batch 34/64 loss: -3.631378650665283
Batch 35/64 loss: -3.8561816215515137
Batch 36/64 loss: -3.5790367126464844
Batch 37/64 loss: -3.740921974182129
Batch 38/64 loss: -3.9451489448547363
Batch 39/64 loss: -3.966822624206543
Batch 40/64 loss: -3.859860897064209
Batch 41/64 loss: -3.867452621459961
Batch 42/64 loss: -3.7336649894714355
Batch 43/64 loss: -3.870311737060547
Batch 44/64 loss: -3.805978298187256
Batch 45/64 loss: -3.842907428741455
Batch 46/64 loss: -3.8586416244506836
Batch 47/64 loss: -3.66404390335083
Batch 48/64 loss: -3.5274829864501953
Batch 49/64 loss: -3.823093891143799
Batch 50/64 loss: -3.725348472595215
Batch 51/64 loss: -3.6728172302246094
Batch 52/64 loss: -3.748689651489258
Batch 53/64 loss: -3.6994900703430176
Batch 54/64 loss: -3.936826229095459
Batch 55/64 loss: -3.6257243156433105
Batch 56/64 loss: -3.5898332595825195
Batch 57/64 loss: -3.8985204696655273
Batch 58/64 loss: -3.9022293090820312
Batch 59/64 loss: -3.6372361183166504
Batch 60/64 loss: -3.4219722747802734
Batch 61/64 loss: -3.825277328491211
Batch 62/64 loss: -3.751840114593506
Batch 63/64 loss: -3.724771499633789
Batch 64/64 loss: -8.272272109985352
Epoch 317  Train loss: -3.8496153663186465  Val loss: -4.0051863758834365
Epoch 318
-------------------------------
Batch 1/64 loss: -3.7056288719177246
Batch 2/64 loss: -3.6576900482177734
Batch 3/64 loss: -3.804819107055664
Batch 4/64 loss: -3.5679941177368164
Batch 5/64 loss: -3.620978355407715
Batch 6/64 loss: -3.626211643218994
Batch 7/64 loss: -3.6879773139953613
Batch 8/64 loss: -3.778977394104004
Batch 9/64 loss: -4.049718379974365
Batch 10/64 loss: -3.8734054565429688
Batch 11/64 loss: -3.7827773094177246
Batch 12/64 loss: -3.8683152198791504
Batch 13/64 loss: -3.900503635406494
Batch 14/64 loss: -3.8360648155212402
Batch 15/64 loss: -3.070939064025879
Batch 16/64 loss: -3.4608688354492188
Batch 17/64 loss: -3.72170352935791
Batch 18/64 loss: -3.6093802452087402
Batch 19/64 loss: -3.613931179046631
Batch 20/64 loss: -3.8339319229125977
Batch 21/64 loss: -3.579089641571045
Batch 22/64 loss: -2.8820343017578125
Batch 23/64 loss: -3.65045166015625
Batch 24/64 loss: -3.8025407791137695
Batch 25/64 loss: -3.7541213035583496
Batch 26/64 loss: -3.590909481048584
Batch 27/64 loss: -3.4961700439453125
Batch 28/64 loss: -3.3916311264038086
Batch 29/64 loss: -3.284365653991699
Batch 30/64 loss: -3.763676166534424
Batch 31/64 loss: -3.7482757568359375
Batch 32/64 loss: -3.410273551940918
Batch 33/64 loss: -3.6696882247924805
Batch 34/64 loss: -3.594613552093506
Batch 35/64 loss: -3.9405479431152344
Batch 36/64 loss: -3.361112594604492
Batch 37/64 loss: -4.018139362335205
Batch 38/64 loss: -3.323115348815918
Batch 39/64 loss: -3.5657458305358887
Batch 40/64 loss: -3.847510814666748
Batch 41/64 loss: -3.8942008018493652
Batch 42/64 loss: -3.8636207580566406
Batch 43/64 loss: -3.62929630279541
Batch 44/64 loss: -3.5370044708251953
Batch 45/64 loss: -3.826320171356201
Batch 46/64 loss: -3.625911235809326
Batch 47/64 loss: -3.768728256225586
Batch 48/64 loss: -3.7855377197265625
Batch 49/64 loss: -3.823319911956787
Batch 50/64 loss: -3.830827236175537
Batch 51/64 loss: -3.747432231903076
Batch 52/64 loss: -3.6314644813537598
Batch 53/64 loss: -3.5712432861328125
Batch 54/64 loss: -3.478020668029785
Batch 55/64 loss: -3.7223501205444336
Batch 56/64 loss: -3.3582592010498047
Batch 57/64 loss: -3.4819483757019043
Batch 58/64 loss: -3.855740547180176
Batch 59/64 loss: -3.400040626525879
Batch 60/64 loss: -3.6664633750915527
Batch 61/64 loss: -3.6302475929260254
Batch 62/64 loss: -3.9391837120056152
Batch 63/64 loss: -3.64430570602417
Batch 64/64 loss: -8.365599632263184
Epoch 318  Train loss: -3.7134352328730564  Val loss: -4.118948920076246
Epoch 319
-------------------------------
Batch 1/64 loss: -3.626347541809082
Batch 2/64 loss: -3.862034797668457
Batch 3/64 loss: -3.7670645713806152
Batch 4/64 loss: -3.7625179290771484
Batch 5/64 loss: -3.420177459716797
Batch 6/64 loss: -3.7980289459228516
Batch 7/64 loss: -3.206462860107422
Batch 8/64 loss: -3.590794563293457
Batch 9/64 loss: -3.6329493522644043
Batch 10/64 loss: -3.877847671508789
Batch 11/64 loss: -3.8799519538879395
Batch 12/64 loss: -3.9586710929870605
Batch 13/64 loss: -3.9490981101989746
Batch 14/64 loss: -3.707946300506592
Batch 15/64 loss: -3.814704418182373
Batch 16/64 loss: -3.9217844009399414
Batch 17/64 loss: -3.843329906463623
Batch 18/64 loss: -3.873586654663086
Batch 19/64 loss: -3.278529167175293
Batch 20/64 loss: -3.882965564727783
Batch 21/64 loss: -3.916548728942871
Batch 22/64 loss: -3.85660982131958
Batch 23/64 loss: -3.7427115440368652
Batch 24/64 loss: -3.895069122314453
Batch 25/64 loss: -3.8277993202209473
Batch 26/64 loss: -3.9610958099365234
Batch 27/64 loss: -4.0634918212890625
Batch 28/64 loss: -3.8674750328063965
Batch 29/64 loss: -3.7341370582580566
Batch 30/64 loss: -3.940141201019287
Batch 31/64 loss: -3.7776575088500977
Batch 32/64 loss: -3.809199333190918
Batch 33/64 loss: -3.924233913421631
Batch 34/64 loss: -3.853111743927002
Batch 35/64 loss: -2.987009048461914
Batch 36/64 loss: -3.8933753967285156
Batch 37/64 loss: -3.8242907524108887
Batch 38/64 loss: -3.808323860168457
Batch 39/64 loss: -3.802934169769287
Batch 40/64 loss: -3.983381748199463
Batch 41/64 loss: -3.658736228942871
Batch 42/64 loss: -3.928406238555908
Batch 43/64 loss: -3.845114231109619
Batch 44/64 loss: -3.7858548164367676
Batch 45/64 loss: -3.82822322845459
Batch 46/64 loss: -4.055517673492432
Batch 47/64 loss: -3.968642234802246
Batch 48/64 loss: -3.9897427558898926
Batch 49/64 loss: -3.9121899604797363
Batch 50/64 loss: -3.9883546829223633
Batch 51/64 loss: -3.6549882888793945
Batch 52/64 loss: -3.6083855628967285
Batch 53/64 loss: -4.068917274475098
Batch 54/64 loss: -3.7008275985717773
Batch 55/64 loss: -3.929629325866699
Batch 56/64 loss: -3.991115093231201
Batch 57/64 loss: -3.906728744506836
Batch 58/64 loss: -3.628232955932617
Batch 59/64 loss: -3.717008113861084
Batch 60/64 loss: -3.825429916381836
Batch 61/64 loss: -3.797931671142578
Batch 62/64 loss: -3.8127994537353516
Batch 63/64 loss: -3.6969637870788574
Batch 64/64 loss: -8.503410339355469
Epoch 319  Train loss: -3.855697063371247  Val loss: -4.166581117820084
Epoch 320
-------------------------------
Batch 1/64 loss: -3.92020845413208
Batch 2/64 loss: -3.9590697288513184
Batch 3/64 loss: -3.9961962699890137
Batch 4/64 loss: -4.046355724334717
Batch 5/64 loss: -3.9173388481140137
Batch 6/64 loss: -3.8956894874572754
Batch 7/64 loss: -3.5882439613342285
Batch 8/64 loss: -3.615705966949463
Batch 9/64 loss: -3.7137913703918457
Batch 10/64 loss: -3.7339205741882324
Batch 11/64 loss: -3.801492691040039
Batch 12/64 loss: -3.834139347076416
Batch 13/64 loss: -3.681094169616699
Batch 14/64 loss: -3.9821929931640625
Batch 15/64 loss: -3.8460378646850586
Batch 16/64 loss: -3.8503074645996094
Batch 17/64 loss: -3.8497910499572754
Batch 18/64 loss: -3.938507556915283
Batch 19/64 loss: -3.698366641998291
Batch 20/64 loss: -3.816469669342041
Batch 21/64 loss: -3.25522518157959
Batch 22/64 loss: -3.888610363006592
Batch 23/64 loss: -3.7470483779907227
Batch 24/64 loss: -4.018765926361084
Batch 25/64 loss: -3.6646718978881836
Batch 26/64 loss: -3.868724822998047
Batch 27/64 loss: -3.9975132942199707
Batch 28/64 loss: -3.8482961654663086
Batch 29/64 loss: -3.3814001083374023
Batch 30/64 loss: -3.8120222091674805
Batch 31/64 loss: -3.8842639923095703
Batch 32/64 loss: -3.961090564727783
Batch 33/64 loss: -4.108516216278076
Batch 34/64 loss: -3.6092491149902344
Batch 35/64 loss: -3.7953357696533203
Batch 36/64 loss: -3.816692352294922
Batch 37/64 loss: -4.100687026977539
Batch 38/64 loss: -4.060795307159424
Batch 39/64 loss: -4.083587169647217
Batch 40/64 loss: -3.9794845581054688
Batch 41/64 loss: -4.030241966247559
Batch 42/64 loss: -3.8975558280944824
Batch 43/64 loss: -3.903862476348877
Batch 44/64 loss: -3.8967270851135254
Batch 45/64 loss: -3.8590173721313477
Batch 46/64 loss: -3.7748589515686035
Batch 47/64 loss: -4.061107158660889
Batch 48/64 loss: -3.868321418762207
Batch 49/64 loss: -3.8663763999938965
Batch 50/64 loss: -4.07904052734375
Batch 51/64 loss: -3.7877607345581055
Batch 52/64 loss: -3.641158103942871
Batch 53/64 loss: -3.857710361480713
Batch 54/64 loss: -3.886699676513672
Batch 55/64 loss: -4.037387371063232
Batch 56/64 loss: -3.8910326957702637
Batch 57/64 loss: -4.069064140319824
Batch 58/64 loss: -4.057396411895752
Batch 59/64 loss: -4.043675422668457
Batch 60/64 loss: -3.9662656784057617
Batch 61/64 loss: -3.937924385070801
Batch 62/64 loss: -4.081807613372803
Batch 63/64 loss: -3.9659485816955566
Batch 64/64 loss: -8.525117874145508
Epoch 320  Train loss: -3.9281832003125956  Val loss: -4.358413342348079
Saving best model, epoch: 320
Epoch 321
-------------------------------
Batch 1/64 loss: -4.12938928604126
Batch 2/64 loss: -4.090043067932129
Batch 3/64 loss: -3.945525646209717
Batch 4/64 loss: -3.4711856842041016
Batch 5/64 loss: -4.051537990570068
Batch 6/64 loss: -3.584949493408203
Batch 7/64 loss: -3.9814505577087402
Batch 8/64 loss: -3.9496312141418457
Batch 9/64 loss: -3.858227252960205
Batch 10/64 loss: -3.674427032470703
Batch 11/64 loss: -3.965843677520752
Batch 12/64 loss: -3.9078269004821777
Batch 13/64 loss: -3.822619915008545
Batch 14/64 loss: -3.677938461303711
Batch 15/64 loss: -3.8543362617492676
Batch 16/64 loss: -3.8847742080688477
Batch 17/64 loss: -3.7741050720214844
Batch 18/64 loss: -3.8866629600524902
Batch 19/64 loss: -3.923981189727783
Batch 20/64 loss: -3.966097831726074
Batch 21/64 loss: -3.759570598602295
Batch 22/64 loss: -4.022198677062988
Batch 23/64 loss: -3.8947224617004395
Batch 24/64 loss: -3.9768781661987305
Batch 25/64 loss: -3.680361747741699
Batch 26/64 loss: -4.0004048347473145
Batch 27/64 loss: -3.7859349250793457
Batch 28/64 loss: -3.9174280166625977
Batch 29/64 loss: -3.687685489654541
Batch 30/64 loss: -3.9613113403320312
Batch 31/64 loss: -3.8971686363220215
Batch 32/64 loss: -3.6522274017333984
Batch 33/64 loss: -3.9023637771606445
Batch 34/64 loss: -4.019524097442627
Batch 35/64 loss: -4.0481977462768555
Batch 36/64 loss: -4.018862247467041
Batch 37/64 loss: -3.9709620475769043
Batch 38/64 loss: -3.863765239715576
Batch 39/64 loss: -3.8205013275146484
Batch 40/64 loss: -3.899630069732666
Batch 41/64 loss: -3.9710488319396973
Batch 42/64 loss: -3.7859725952148438
Batch 43/64 loss: -4.010025501251221
Batch 44/64 loss: -3.7536306381225586
Batch 45/64 loss: -3.914477825164795
Batch 46/64 loss: -3.8743162155151367
Batch 47/64 loss: -3.9622554779052734
Batch 48/64 loss: -3.876931667327881
Batch 49/64 loss: -3.8830509185791016
Batch 50/64 loss: -3.5191917419433594
Batch 51/64 loss: -3.9195051193237305
Batch 52/64 loss: -3.634936809539795
Batch 53/64 loss: -4.016107559204102
Batch 54/64 loss: -3.9160032272338867
Batch 55/64 loss: -3.7696094512939453
Batch 56/64 loss: -3.9937515258789062
Batch 57/64 loss: -3.8477091789245605
Batch 58/64 loss: -3.8734335899353027
Batch 59/64 loss: -3.9980530738830566
Batch 60/64 loss: -3.9739270210266113
Batch 61/64 loss: -3.8749446868896484
Batch 62/64 loss: -3.7784619331359863
Batch 63/64 loss: -4.036057949066162
Batch 64/64 loss: -8.27946662902832
Epoch 321  Train loss: -3.930560863719267  Val loss: -4.36117068680701
Saving best model, epoch: 321
Epoch 322
-------------------------------
Batch 1/64 loss: -3.93472957611084
Batch 2/64 loss: -4.121594429016113
Batch 3/64 loss: -3.8302268981933594
Batch 4/64 loss: -3.7531704902648926
Batch 5/64 loss: -3.998908042907715
Batch 6/64 loss: -3.971158027648926
Batch 7/64 loss: -3.8102269172668457
Batch 8/64 loss: -3.9926676750183105
Batch 9/64 loss: -3.9985008239746094
Batch 10/64 loss: -3.9609761238098145
Batch 11/64 loss: -3.836691379547119
Batch 12/64 loss: -3.7936348915100098
Batch 13/64 loss: -4.037771224975586
Batch 14/64 loss: -3.8908281326293945
Batch 15/64 loss: -3.6660385131835938
Batch 16/64 loss: -3.5883283615112305
Batch 17/64 loss: -3.7874197959899902
Batch 18/64 loss: -3.9862513542175293
Batch 19/64 loss: -3.7546873092651367
Batch 20/64 loss: -3.6937403678894043
Batch 21/64 loss: -3.829637050628662
Batch 22/64 loss: -3.972109317779541
Batch 23/64 loss: -3.7859349250793457
Batch 24/64 loss: -3.998467445373535
Batch 25/64 loss: -3.810019016265869
Batch 26/64 loss: -3.8573174476623535
Batch 27/64 loss: -3.8597989082336426
Batch 28/64 loss: -4.003761291503906
Batch 29/64 loss: -3.914867877960205
Batch 30/64 loss: -3.9860072135925293
Batch 31/64 loss: -3.6798081398010254
Batch 32/64 loss: -4.014040470123291
Batch 33/64 loss: -3.9150657653808594
Batch 34/64 loss: -3.921135902404785
Batch 35/64 loss: -4.026943683624268
Batch 36/64 loss: -3.850339412689209
Batch 37/64 loss: -3.9241251945495605
Batch 38/64 loss: -3.588900566101074
Batch 39/64 loss: -3.8253870010375977
Batch 40/64 loss: -3.8702006340026855
Batch 41/64 loss: -3.9804234504699707
Batch 42/64 loss: -3.997750759124756
Batch 43/64 loss: -4.004582405090332
Batch 44/64 loss: -3.904693126678467
Batch 45/64 loss: -3.841219425201416
Batch 46/64 loss: -3.874342918395996
Batch 47/64 loss: -3.7771267890930176
Batch 48/64 loss: -4.01498556137085
Batch 49/64 loss: -3.948845863342285
Batch 50/64 loss: -4.029932498931885
Batch 51/64 loss: -3.9410171508789062
Batch 52/64 loss: -3.8122005462646484
Batch 53/64 loss: -3.8578763008117676
Batch 54/64 loss: -3.703643321990967
Batch 55/64 loss: -3.8547182083129883
Batch 56/64 loss: -3.733839511871338
Batch 57/64 loss: -3.8667736053466797
Batch 58/64 loss: -3.8914332389831543
Batch 59/64 loss: -3.7930212020874023
Batch 60/64 loss: -3.756936550140381
Batch 61/64 loss: -3.9140095710754395
Batch 62/64 loss: -3.9946846961975098
Batch 63/64 loss: -3.9892430305480957
Batch 64/64 loss: -8.36063003540039
Epoch 322  Train loss: -3.934042193842869  Val loss: -4.2377889574188545
Epoch 323
-------------------------------
Batch 1/64 loss: -3.9546079635620117
Batch 2/64 loss: -3.86690616607666
Batch 3/64 loss: -3.556385040283203
Batch 4/64 loss: -3.925489902496338
Batch 5/64 loss: -3.8010454177856445
Batch 6/64 loss: -3.713810443878174
Batch 7/64 loss: -3.855215549468994
Batch 8/64 loss: -3.8639864921569824
Batch 9/64 loss: -3.868382453918457
Batch 10/64 loss: -3.132284164428711
Batch 11/64 loss: -3.8026442527770996
Batch 12/64 loss: -3.88801908493042
Batch 13/64 loss: -3.9541587829589844
Batch 14/64 loss: -4.032351493835449
Batch 15/64 loss: -3.837080955505371
Batch 16/64 loss: -3.750044345855713
Batch 17/64 loss: -3.8769984245300293
Batch 18/64 loss: -3.8688015937805176
Batch 19/64 loss: -3.452688217163086
Batch 20/64 loss: -3.7122998237609863
Batch 21/64 loss: -3.4770889282226562
Batch 22/64 loss: -3.8415894508361816
Batch 23/64 loss: -3.669950485229492
Batch 24/64 loss: -3.7449893951416016
Batch 25/64 loss: -3.8779654502868652
Batch 26/64 loss: -3.7553353309631348
Batch 27/64 loss: -3.9976582527160645
Batch 28/64 loss: -3.7270731925964355
Batch 29/64 loss: -3.415904998779297
Batch 30/64 loss: -3.879195213317871
Batch 31/64 loss: -3.732905864715576
Batch 32/64 loss: -3.666581630706787
Batch 33/64 loss: -3.95266056060791
Batch 34/64 loss: -3.762207508087158
Batch 35/64 loss: -3.8214945793151855
Batch 36/64 loss: -3.7589144706726074
Batch 37/64 loss: -3.8540048599243164
Batch 38/64 loss: -4.045557022094727
Batch 39/64 loss: -3.404308319091797
Batch 40/64 loss: -3.8122076988220215
Batch 41/64 loss: -3.874842643737793
Batch 42/64 loss: -3.804841995239258
Batch 43/64 loss: -3.9791274070739746
Batch 44/64 loss: -3.675344944000244
Batch 45/64 loss: -3.9075469970703125
Batch 46/64 loss: -3.950777053833008
Batch 47/64 loss: -3.6768789291381836
Batch 48/64 loss: -3.8160972595214844
Batch 49/64 loss: -3.5218467712402344
Batch 50/64 loss: -3.5971837043762207
Batch 51/64 loss: -3.7505812644958496
Batch 52/64 loss: -3.872274875640869
Batch 53/64 loss: -3.780519962310791
Batch 54/64 loss: -3.856685161590576
Batch 55/64 loss: -3.7342381477355957
Batch 56/64 loss: -3.880539894104004
Batch 57/64 loss: -3.8782081604003906
Batch 58/64 loss: -3.8584213256835938
Batch 59/64 loss: -3.7712368965148926
Batch 60/64 loss: -3.728851795196533
Batch 61/64 loss: -3.4885854721069336
Batch 62/64 loss: -3.7490859031677246
Batch 63/64 loss: -4.020384788513184
Batch 64/64 loss: -8.475692749023438
Epoch 323  Train loss: -3.8343790540508196  Val loss: -4.07277219320081
Epoch 324
-------------------------------
Batch 1/64 loss: -3.936288833618164
Batch 2/64 loss: -3.723818302154541
Batch 3/64 loss: -3.7201809883117676
Batch 4/64 loss: -3.8343873023986816
Batch 5/64 loss: -3.6066641807556152
Batch 6/64 loss: -3.818138599395752
Batch 7/64 loss: -3.7839999198913574
Batch 8/64 loss: -3.7259607315063477
Batch 9/64 loss: -3.5429701805114746
Batch 10/64 loss: -4.049378871917725
Batch 11/64 loss: -3.8042750358581543
Batch 12/64 loss: -3.9842171669006348
Batch 13/64 loss: -3.5508508682250977
Batch 14/64 loss: -3.943908214569092
Batch 15/64 loss: -3.784430503845215
Batch 16/64 loss: -3.784633159637451
Batch 17/64 loss: -3.849245071411133
Batch 18/64 loss: -3.797386646270752
Batch 19/64 loss: -3.9223122596740723
Batch 20/64 loss: -3.897655487060547
Batch 21/64 loss: -3.3885717391967773
Batch 22/64 loss: -3.731492042541504
Batch 23/64 loss: -3.8481979370117188
Batch 24/64 loss: -3.819040298461914
Batch 25/64 loss: -3.9704551696777344
Batch 26/64 loss: -3.819272994995117
Batch 27/64 loss: -3.7007994651794434
Batch 28/64 loss: -3.694521427154541
Batch 29/64 loss: -3.7771105766296387
Batch 30/64 loss: -3.782258987426758
Batch 31/64 loss: -3.8892555236816406
Batch 32/64 loss: -3.808877944946289
Batch 33/64 loss: -3.958792209625244
Batch 34/64 loss: -3.6622228622436523
Batch 35/64 loss: -3.632662773132324
Batch 36/64 loss: -3.961489200592041
Batch 37/64 loss: -3.8783793449401855
Batch 38/64 loss: -3.91011381149292
Batch 39/64 loss: -4.026416778564453
Batch 40/64 loss: -3.9113264083862305
Batch 41/64 loss: -3.8439111709594727
Batch 42/64 loss: -3.988405704498291
Batch 43/64 loss: -3.976571559906006
Batch 44/64 loss: -3.8574585914611816
Batch 45/64 loss: -3.737006187438965
Batch 46/64 loss: -3.888845920562744
Batch 47/64 loss: -3.9422168731689453
Batch 48/64 loss: -3.6318912506103516
Batch 49/64 loss: -3.9175357818603516
Batch 50/64 loss: -3.996947765350342
Batch 51/64 loss: -3.967705726623535
Batch 52/64 loss: -3.6784229278564453
Batch 53/64 loss: -3.823958396911621
Batch 54/64 loss: -4.036570072174072
Batch 55/64 loss: -3.6537952423095703
Batch 56/64 loss: -3.8492627143859863
Batch 57/64 loss: -3.630034923553467
Batch 58/64 loss: -3.9370765686035156
Batch 59/64 loss: -3.9287562370300293
Batch 60/64 loss: -4.143028736114502
Batch 61/64 loss: -3.9159183502197266
Batch 62/64 loss: -3.758549690246582
Batch 63/64 loss: -3.8900365829467773
Batch 64/64 loss: -8.319543838500977
Epoch 324  Train loss: -3.8818121517405793  Val loss: -4.082855159064748
Epoch 325
-------------------------------
Batch 1/64 loss: -3.8889737129211426
Batch 2/64 loss: -3.846917152404785
Batch 3/64 loss: -3.927950382232666
Batch 4/64 loss: -3.967802047729492
Batch 5/64 loss: -3.9106760025024414
Batch 6/64 loss: -4.118017196655273
Batch 7/64 loss: -3.947192668914795
Batch 8/64 loss: -3.873809337615967
Batch 9/64 loss: -3.899132251739502
Batch 10/64 loss: -3.9202723503112793
Batch 11/64 loss: -3.892605781555176
Batch 12/64 loss: -4.006057262420654
Batch 13/64 loss: -3.8453969955444336
Batch 14/64 loss: -3.5976672172546387
Batch 15/64 loss: -3.4326066970825195
Batch 16/64 loss: -3.6930179595947266
Batch 17/64 loss: -3.8770689964294434
Batch 18/64 loss: -4.0670952796936035
Batch 19/64 loss: -3.9962315559387207
Batch 20/64 loss: -3.8392553329467773
Batch 21/64 loss: -3.875199794769287
Batch 22/64 loss: -3.604860782623291
Batch 23/64 loss: -4.008368492126465
Batch 24/64 loss: -3.7514615058898926
Batch 25/64 loss: -3.623777389526367
Batch 26/64 loss: -3.9064908027648926
Batch 27/64 loss: -3.905975818634033
Batch 28/64 loss: -3.685537815093994
Batch 29/64 loss: -3.9352355003356934
Batch 30/64 loss: -3.743142604827881
Batch 31/64 loss: -3.969000816345215
Batch 32/64 loss: -3.7855634689331055
Batch 33/64 loss: -3.911668300628662
Batch 34/64 loss: -3.8439087867736816
Batch 35/64 loss: -3.7457003593444824
Batch 36/64 loss: -3.753554344177246
Batch 37/64 loss: -3.983518123626709
Batch 38/64 loss: -3.8026537895202637
Batch 39/64 loss: -3.7959675788879395
Batch 40/64 loss: -4.120478630065918
Batch 41/64 loss: -3.8139357566833496
Batch 42/64 loss: -3.8797826766967773
Batch 43/64 loss: -3.791656017303467
Batch 44/64 loss: -3.7264533042907715
Batch 45/64 loss: -4.069034099578857
Batch 46/64 loss: -3.697831630706787
Batch 47/64 loss: -3.426730155944824
Batch 48/64 loss: -3.8702516555786133
Batch 49/64 loss: -3.905153274536133
Batch 50/64 loss: -4.027406215667725
Batch 51/64 loss: -3.683318614959717
Batch 52/64 loss: -3.858938694000244
Batch 53/64 loss: -3.749906063079834
Batch 54/64 loss: -3.5389881134033203
Batch 55/64 loss: -3.823533535003662
Batch 56/64 loss: -3.7284364700317383
Batch 57/64 loss: -3.8596529960632324
Batch 58/64 loss: -4.064716815948486
Batch 59/64 loss: -4.008974552154541
Batch 60/64 loss: -3.6499271392822266
Batch 61/64 loss: -4.007974624633789
Batch 62/64 loss: -3.711142063140869
Batch 63/64 loss: -3.5632200241088867
Batch 64/64 loss: -8.414981842041016
Epoch 325  Train loss: -3.8912629295797907  Val loss: -4.207522375886793
Epoch 326
-------------------------------
Batch 1/64 loss: -3.964632987976074
Batch 2/64 loss: -4.049016952514648
Batch 3/64 loss: -3.7099947929382324
Batch 4/64 loss: -3.61106538772583
Batch 5/64 loss: -3.8331971168518066
Batch 6/64 loss: -3.9869327545166016
Batch 7/64 loss: -3.1044464111328125
Batch 8/64 loss: -3.83591890335083
Batch 9/64 loss: -3.830913543701172
Batch 10/64 loss: -3.717416763305664
Batch 11/64 loss: -4.1076340675354
Batch 12/64 loss: -3.866873264312744
Batch 13/64 loss: -3.796830177307129
Batch 14/64 loss: -3.9467825889587402
Batch 15/64 loss: -4.151898384094238
Batch 16/64 loss: -4.0855512619018555
Batch 17/64 loss: -3.9923672676086426
Batch 18/64 loss: -3.4484920501708984
Batch 19/64 loss: -3.860440254211426
Batch 20/64 loss: -3.582648277282715
Batch 21/64 loss: -3.9691686630249023
Batch 22/64 loss: -3.7713727951049805
Batch 23/64 loss: -3.8537750244140625
Batch 24/64 loss: -3.9435181617736816
Batch 25/64 loss: -3.8456549644470215
Batch 26/64 loss: -3.9051012992858887
Batch 27/64 loss: -3.97398042678833
Batch 28/64 loss: -3.985729217529297
Batch 29/64 loss: -3.974766254425049
Batch 30/64 loss: -3.9342780113220215
Batch 31/64 loss: -3.9661331176757812
Batch 32/64 loss: -3.912102699279785
Batch 33/64 loss: -3.6778106689453125
Batch 34/64 loss: -3.5701823234558105
Batch 35/64 loss: -3.9791488647460938
Batch 36/64 loss: -4.0668439865112305
Batch 37/64 loss: -4.01121711730957
Batch 38/64 loss: -3.9132981300354004
Batch 39/64 loss: -4.0145583152771
Batch 40/64 loss: -3.944260597229004
Batch 41/64 loss: -3.9743242263793945
Batch 42/64 loss: -3.9447250366210938
Batch 43/64 loss: -3.662086009979248
Batch 44/64 loss: -3.9623231887817383
Batch 45/64 loss: -3.6303000450134277
Batch 46/64 loss: -3.9588918685913086
Batch 47/64 loss: -3.839552879333496
Batch 48/64 loss: -3.711881637573242
Batch 49/64 loss: -4.013892650604248
Batch 50/64 loss: -3.7980055809020996
Batch 51/64 loss: -4.010302543640137
Batch 52/64 loss: -4.0335001945495605
Batch 53/64 loss: -3.8896450996398926
Batch 54/64 loss: -3.632129669189453
Batch 55/64 loss: -3.5591821670532227
Batch 56/64 loss: -3.9496188163757324
Batch 57/64 loss: -4.009762287139893
Batch 58/64 loss: -3.8878870010375977
Batch 59/64 loss: -3.874044418334961
Batch 60/64 loss: -3.899977207183838
Batch 61/64 loss: -3.8224053382873535
Batch 62/64 loss: -3.9524569511413574
Batch 63/64 loss: -4.1403021812438965
Batch 64/64 loss: -7.954780578613281
Epoch 326  Train loss: -3.91873311809465  Val loss: -3.970723155437876
Epoch 327
-------------------------------
Batch 1/64 loss: -3.8124585151672363
Batch 2/64 loss: -4.045932769775391
Batch 3/64 loss: -3.8948678970336914
Batch 4/64 loss: -3.8199987411499023
Batch 5/64 loss: -3.8704538345336914
Batch 6/64 loss: -3.8616480827331543
Batch 7/64 loss: -3.864811420440674
Batch 8/64 loss: -4.028465270996094
Batch 9/64 loss: -3.8947181701660156
Batch 10/64 loss: -3.6219544410705566
Batch 11/64 loss: -3.997502326965332
Batch 12/64 loss: -4.043275356292725
Batch 13/64 loss: -3.673534393310547
Batch 14/64 loss: -3.918748378753662
Batch 15/64 loss: -3.949479103088379
Batch 16/64 loss: -3.922123908996582
Batch 17/64 loss: -3.854921817779541
Batch 18/64 loss: -3.8733773231506348
Batch 19/64 loss: -3.7747817039489746
Batch 20/64 loss: -3.8488306999206543
Batch 21/64 loss: -3.7563133239746094
Batch 22/64 loss: -3.7306113243103027
Batch 23/64 loss: -3.621771812438965
Batch 24/64 loss: -3.8893074989318848
Batch 25/64 loss: -3.952221393585205
Batch 26/64 loss: -3.8811111450195312
Batch 27/64 loss: -3.9577488899230957
Batch 28/64 loss: -3.9818859100341797
Batch 29/64 loss: -3.716343402862549
Batch 30/64 loss: -3.7535758018493652
Batch 31/64 loss: -3.915534019470215
Batch 32/64 loss: -3.8852343559265137
Batch 33/64 loss: -3.848629951477051
Batch 34/64 loss: -3.7459311485290527
Batch 35/64 loss: -4.064166069030762
Batch 36/64 loss: -3.9218907356262207
Batch 37/64 loss: -3.8640952110290527
Batch 38/64 loss: -3.997652053833008
Batch 39/64 loss: -3.9791269302368164
Batch 40/64 loss: -3.8617520332336426
Batch 41/64 loss: -4.035322666168213
Batch 42/64 loss: -4.044616222381592
Batch 43/64 loss: -4.0621771812438965
Batch 44/64 loss: -3.9083251953125
Batch 45/64 loss: -4.088001251220703
Batch 46/64 loss: -3.520578384399414
Batch 47/64 loss: -3.861459255218506
Batch 48/64 loss: -3.925659656524658
Batch 49/64 loss: -3.982036590576172
Batch 50/64 loss: -4.019306182861328
Batch 51/64 loss: -4.060965538024902
Batch 52/64 loss: -4.152431488037109
Batch 53/64 loss: -3.9738640785217285
Batch 54/64 loss: -3.9623661041259766
Batch 55/64 loss: -3.8254857063293457
Batch 56/64 loss: -4.056362628936768
Batch 57/64 loss: -3.8837366104125977
Batch 58/64 loss: -3.677515983581543
Batch 59/64 loss: -3.7992968559265137
Batch 60/64 loss: -4.053673267364502
Batch 61/64 loss: -3.8730435371398926
Batch 62/64 loss: -4.046162128448486
Batch 63/64 loss: -3.825995922088623
Batch 64/64 loss: -8.656505584716797
Epoch 327  Train loss: -3.9533733143525964  Val loss: -4.240905473322393
Epoch 328
-------------------------------
Batch 1/64 loss: -3.905022621154785
Batch 2/64 loss: -3.89473819732666
Batch 3/64 loss: -3.942509651184082
Batch 4/64 loss: -3.98665714263916
Batch 5/64 loss: -3.412398338317871
Batch 6/64 loss: -4.005594253540039
Batch 7/64 loss: -4.055386543273926
Batch 8/64 loss: -3.9303908348083496
Batch 9/64 loss: -4.122741222381592
Batch 10/64 loss: -3.941263198852539
Batch 11/64 loss: -4.011202812194824
Batch 12/64 loss: -3.7998952865600586
Batch 13/64 loss: -3.9901227951049805
Batch 14/64 loss: -3.822005271911621
Batch 15/64 loss: -3.968863010406494
Batch 16/64 loss: -3.915583610534668
Batch 17/64 loss: -3.852450370788574
Batch 18/64 loss: -4.0000810623168945
Batch 19/64 loss: -3.8374390602111816
Batch 20/64 loss: -3.715054988861084
Batch 21/64 loss: -3.9599690437316895
Batch 22/64 loss: -4.0047221183776855
Batch 23/64 loss: -3.992422580718994
Batch 24/64 loss: -3.9868879318237305
Batch 25/64 loss: -4.1036458015441895
Batch 26/64 loss: -3.995783805847168
Batch 27/64 loss: -4.101306438446045
Batch 28/64 loss: -3.9907350540161133
Batch 29/64 loss: -4.032824516296387
Batch 30/64 loss: -3.7489914894104004
Batch 31/64 loss: -3.7920103073120117
Batch 32/64 loss: -3.888986587524414
Batch 33/64 loss: -4.131903171539307
Batch 34/64 loss: -3.8800954818725586
Batch 35/64 loss: -3.8068575859069824
Batch 36/64 loss: -4.014551162719727
Batch 37/64 loss: -3.835594654083252
Batch 38/64 loss: -3.94907283782959
Batch 39/64 loss: -3.8337759971618652
Batch 40/64 loss: -3.584035873413086
Batch 41/64 loss: -3.8694982528686523
Batch 42/64 loss: -3.9409351348876953
Batch 43/64 loss: -3.782409191131592
Batch 44/64 loss: -3.722074508666992
Batch 45/64 loss: -3.960493564605713
Batch 46/64 loss: -4.009373188018799
Batch 47/64 loss: -3.3884239196777344
Batch 48/64 loss: -4.043129920959473
Batch 49/64 loss: -4.0612263679504395
Batch 50/64 loss: -3.970643997192383
Batch 51/64 loss: -3.819931983947754
Batch 52/64 loss: -3.6864309310913086
Batch 53/64 loss: -4.052290916442871
Batch 54/64 loss: -3.4436655044555664
Batch 55/64 loss: -3.983154773712158
Batch 56/64 loss: -4.065698146820068
Batch 57/64 loss: -4.027462482452393
Batch 58/64 loss: -4.033504009246826
Batch 59/64 loss: -3.79777193069458
Batch 60/64 loss: -4.05532693862915
Batch 61/64 loss: -3.921349048614502
Batch 62/64 loss: -3.9849438667297363
Batch 63/64 loss: -3.8860373497009277
Batch 64/64 loss: -8.30807113647461
Epoch 328  Train loss: -3.9604768940046724  Val loss: -4.286745602322608
Epoch 329
-------------------------------
Batch 1/64 loss: -3.9957776069641113
Batch 2/64 loss: -4.034801959991455
Batch 3/64 loss: -3.775247097015381
Batch 4/64 loss: -3.995211601257324
Batch 5/64 loss: -3.9596948623657227
Batch 6/64 loss: -4.009929180145264
Batch 7/64 loss: -4.057323455810547
Batch 8/64 loss: -3.843392848968506
Batch 9/64 loss: -3.9989161491394043
Batch 10/64 loss: -4.02444314956665
Batch 11/64 loss: -3.9928412437438965
Batch 12/64 loss: -3.8996658325195312
Batch 13/64 loss: -3.918541431427002
Batch 14/64 loss: -4.012451648712158
Batch 15/64 loss: -3.884875774383545
Batch 16/64 loss: -4.174436092376709
Batch 17/64 loss: -3.9068408012390137
Batch 18/64 loss: -3.883723258972168
Batch 19/64 loss: -3.726134777069092
Batch 20/64 loss: -3.888918399810791
Batch 21/64 loss: -4.023542881011963
Batch 22/64 loss: -4.074702262878418
Batch 23/64 loss: -3.6710081100463867
Batch 24/64 loss: -3.9268603324890137
Batch 25/64 loss: -4.0395355224609375
Batch 26/64 loss: -4.137371063232422
Batch 27/64 loss: -3.971836566925049
Batch 28/64 loss: -3.800126552581787
Batch 29/64 loss: -4.0285563468933105
Batch 30/64 loss: -4.0015668869018555
Batch 31/64 loss: -4.106982707977295
Batch 32/64 loss: -4.002445220947266
Batch 33/64 loss: -4.001776218414307
Batch 34/64 loss: -3.9331016540527344
Batch 35/64 loss: -3.7953543663024902
Batch 36/64 loss: -3.7567853927612305
Batch 37/64 loss: -3.861724376678467
Batch 38/64 loss: -4.021971702575684
Batch 39/64 loss: -3.9888339042663574
Batch 40/64 loss: -3.9634451866149902
Batch 41/64 loss: -4.121093273162842
Batch 42/64 loss: -3.741133689880371
Batch 43/64 loss: -3.969616413116455
Batch 44/64 loss: -4.104333400726318
Batch 45/64 loss: -3.8433213233947754
Batch 46/64 loss: -3.9524035453796387
Batch 47/64 loss: -3.821361541748047
Batch 48/64 loss: -4.023135185241699
Batch 49/64 loss: -4.112133026123047
Batch 50/64 loss: -3.9604249000549316
Batch 51/64 loss: -4.169070243835449
Batch 52/64 loss: -3.864780902862549
Batch 53/64 loss: -4.170995712280273
Batch 54/64 loss: -3.9232864379882812
Batch 55/64 loss: -3.9927310943603516
Batch 56/64 loss: -3.6097936630249023
Batch 57/64 loss: -4.1898579597473145
Batch 58/64 loss: -3.9970569610595703
Batch 59/64 loss: -3.994851589202881
Batch 60/64 loss: -4.158411502838135
Batch 61/64 loss: -3.93564510345459
Batch 62/64 loss: -3.9510154724121094
Batch 63/64 loss: -3.859771728515625
Batch 64/64 loss: -8.408304214477539
Epoch 329  Train loss: -4.0135395648432715  Val loss: -4.381338781507564
Saving best model, epoch: 329
Epoch 330
-------------------------------
Batch 1/64 loss: -3.7952771186828613
Batch 2/64 loss: -4.04155158996582
Batch 3/64 loss: -4.0299835205078125
Batch 4/64 loss: -3.9214043617248535
Batch 5/64 loss: -3.969728469848633
Batch 6/64 loss: -4.1266560554504395
Batch 7/64 loss: -3.9660725593566895
Batch 8/64 loss: -4.082150459289551
Batch 9/64 loss: -3.6717939376831055
Batch 10/64 loss: -4.034350872039795
Batch 11/64 loss: -3.949277400970459
Batch 12/64 loss: -3.8266749382019043
Batch 13/64 loss: -4.045061111450195
Batch 14/64 loss: -3.8160452842712402
Batch 15/64 loss: -4.005857467651367
Batch 16/64 loss: -3.815067768096924
Batch 17/64 loss: -3.8230252265930176
Batch 18/64 loss: -3.8533730506896973
Batch 19/64 loss: -3.90693998336792
Batch 20/64 loss: -4.1983513832092285
Batch 21/64 loss: -4.082682132720947
Batch 22/64 loss: -3.8602476119995117
Batch 23/64 loss: -3.998783588409424
Batch 24/64 loss: -3.4449844360351562
Batch 25/64 loss: -3.9431939125061035
Batch 26/64 loss: -4.11924934387207
Batch 27/64 loss: -4.062923431396484
Batch 28/64 loss: -3.9781203269958496
Batch 29/64 loss: -4.0822529792785645
Batch 30/64 loss: -4.0514044761657715
Batch 31/64 loss: -4.076988697052002
Batch 32/64 loss: -3.8615522384643555
Batch 33/64 loss: -3.9213948249816895
Batch 34/64 loss: -3.9381566047668457
Batch 35/64 loss: -3.9777326583862305
Batch 36/64 loss: -4.030416488647461
Batch 37/64 loss: -4.017810821533203
Batch 38/64 loss: -4.1229658126831055
Batch 39/64 loss: -3.984344959259033
Batch 40/64 loss: -4.10734748840332
Batch 41/64 loss: -4.0968828201293945
Batch 42/64 loss: -3.9096808433532715
Batch 43/64 loss: -4.1752400398254395
Batch 44/64 loss: -4.1892266273498535
Batch 45/64 loss: -4.086207389831543
Batch 46/64 loss: -4.015883445739746
Batch 47/64 loss: -3.814370632171631
Batch 48/64 loss: -4.000488758087158
Batch 49/64 loss: -3.7727560997009277
Batch 50/64 loss: -4.013609409332275
Batch 51/64 loss: -4.1902666091918945
Batch 52/64 loss: -3.987664222717285
Batch 53/64 loss: -3.898526668548584
Batch 54/64 loss: -4.046856880187988
Batch 55/64 loss: -4.046540260314941
Batch 56/64 loss: -3.8905720710754395
Batch 57/64 loss: -3.66762638092041
Batch 58/64 loss: -4.038592338562012
Batch 59/64 loss: -4.0999860763549805
Batch 60/64 loss: -4.094747066497803
Batch 61/64 loss: -3.9705333709716797
Batch 62/64 loss: -3.96148681640625
Batch 63/64 loss: -3.581141948699951
Batch 64/64 loss: -8.461957931518555
Epoch 330  Train loss: -4.02253412732891  Val loss: -4.079899817397914
Epoch 331
-------------------------------
Batch 1/64 loss: -3.897176742553711
Batch 2/64 loss: -3.6381425857543945
Batch 3/64 loss: -4.013019561767578
Batch 4/64 loss: -3.6055173873901367
Batch 5/64 loss: -3.5161733627319336
Batch 6/64 loss: -3.84228515625
Batch 7/64 loss: -3.7167983055114746
Batch 8/64 loss: -3.785163402557373
Batch 9/64 loss: -3.6597886085510254
Batch 10/64 loss: -3.815511703491211
Batch 11/64 loss: -3.9429402351379395
Batch 12/64 loss: -3.970714569091797
Batch 13/64 loss: -3.8756446838378906
Batch 14/64 loss: -3.839824676513672
Batch 15/64 loss: -4.005399227142334
Batch 16/64 loss: -3.6104583740234375
Batch 17/64 loss: -3.8381896018981934
Batch 18/64 loss: -3.872070789337158
Batch 19/64 loss: -3.8850183486938477
Batch 20/64 loss: -3.872718334197998
Batch 21/64 loss: -3.7797789573669434
Batch 22/64 loss: -3.763105869293213
Batch 23/64 loss: -4.013516902923584
Batch 24/64 loss: -3.73258638381958
Batch 25/64 loss: -3.7787227630615234
Batch 26/64 loss: -3.7113728523254395
Batch 27/64 loss: -3.997450351715088
Batch 28/64 loss: -3.971924304962158
Batch 29/64 loss: -3.588817596435547
Batch 30/64 loss: -3.823225975036621
Batch 31/64 loss: -3.9897022247314453
Batch 32/64 loss: -3.9083123207092285
Batch 33/64 loss: -3.8489747047424316
Batch 34/64 loss: -3.877326488494873
Batch 35/64 loss: -3.9331860542297363
Batch 36/64 loss: -4.114372253417969
Batch 37/64 loss: -3.9250969886779785
Batch 38/64 loss: -4.048604488372803
Batch 39/64 loss: -4.012988567352295
Batch 40/64 loss: -3.8585267066955566
Batch 41/64 loss: -3.9627389907836914
Batch 42/64 loss: -3.7182631492614746
Batch 43/64 loss: -4.036184310913086
Batch 44/64 loss: -4.050689220428467
Batch 45/64 loss: -3.635195255279541
Batch 46/64 loss: -3.948796272277832
Batch 47/64 loss: -4.050271034240723
Batch 48/64 loss: -3.9881625175476074
Batch 49/64 loss: -3.8370261192321777
Batch 50/64 loss: -3.9928197860717773
Batch 51/64 loss: -3.855483055114746
Batch 52/64 loss: -3.884608268737793
Batch 53/64 loss: -3.9040331840515137
Batch 54/64 loss: -3.893815517425537
Batch 55/64 loss: -4.046150207519531
Batch 56/64 loss: -4.002246856689453
Batch 57/64 loss: -3.813948154449463
Batch 58/64 loss: -3.8770856857299805
Batch 59/64 loss: -3.911637306213379
Batch 60/64 loss: -3.964728832244873
Batch 61/64 loss: -3.976353645324707
Batch 62/64 loss: -3.884181499481201
Batch 63/64 loss: -4.0487380027771
Batch 64/64 loss: -8.528125762939453
Epoch 331  Train loss: -3.9303435232125077  Val loss: -4.341759055750477
Epoch 332
-------------------------------
Batch 1/64 loss: -4.112122058868408
Batch 2/64 loss: -3.9950766563415527
Batch 3/64 loss: -3.7471818923950195
Batch 4/64 loss: -3.930461883544922
Batch 5/64 loss: -3.869192123413086
Batch 6/64 loss: -3.6850457191467285
Batch 7/64 loss: -4.087006092071533
Batch 8/64 loss: -4.034778594970703
Batch 9/64 loss: -3.8793959617614746
Batch 10/64 loss: -3.7706851959228516
Batch 11/64 loss: -3.9741034507751465
Batch 12/64 loss: -4.131082057952881
Batch 13/64 loss: -3.9888672828674316
Batch 14/64 loss: -3.8109960556030273
Batch 15/64 loss: -4.243267059326172
Batch 16/64 loss: -3.96990966796875
Batch 17/64 loss: -3.5187854766845703
Batch 18/64 loss: -3.759678363800049
Batch 19/64 loss: -4.020913124084473
Batch 20/64 loss: -4.157077789306641
Batch 21/64 loss: -3.72175931930542
Batch 22/64 loss: -3.8734946250915527
Batch 23/64 loss: -4.004072666168213
Batch 24/64 loss: -3.4972639083862305
Batch 25/64 loss: -3.843257427215576
Batch 26/64 loss: -3.8185296058654785
Batch 27/64 loss: -4.116806983947754
Batch 28/64 loss: -3.9982566833496094
Batch 29/64 loss: -3.9905247688293457
Batch 30/64 loss: -3.90553617477417
Batch 31/64 loss: -4.065042972564697
Batch 32/64 loss: -3.727613925933838
Batch 33/64 loss: -4.06787633895874
Batch 34/64 loss: -3.768907070159912
Batch 35/64 loss: -3.8346433639526367
Batch 36/64 loss: -3.9860358238220215
Batch 37/64 loss: -4.196056842803955
Batch 38/64 loss: -4.050711631774902
Batch 39/64 loss: -3.831902503967285
Batch 40/64 loss: -3.9787392616271973
Batch 41/64 loss: -4.174617290496826
Batch 42/64 loss: -3.9748263359069824
Batch 43/64 loss: -3.8352770805358887
Batch 44/64 loss: -3.9756669998168945
Batch 45/64 loss: -4.095279216766357
Batch 46/64 loss: -4.150975704193115
Batch 47/64 loss: -3.9210166931152344
Batch 48/64 loss: -4.01992654800415
Batch 49/64 loss: -4.04379415512085
Batch 50/64 loss: -3.996499538421631
Batch 51/64 loss: -3.9836506843566895
Batch 52/64 loss: -4.103078365325928
Batch 53/64 loss: -3.7132558822631836
Batch 54/64 loss: -4.009100914001465
Batch 55/64 loss: -3.8602781295776367
Batch 56/64 loss: -4.037418842315674
Batch 57/64 loss: -4.00490140914917
Batch 58/64 loss: -3.8521170616149902
Batch 59/64 loss: -3.974325656890869
Batch 60/64 loss: -3.830937385559082
Batch 61/64 loss: -4.027178764343262
Batch 62/64 loss: -4.069015979766846
Batch 63/64 loss: -3.8326525688171387
Batch 64/64 loss: -8.464761734008789
Epoch 332  Train loss: -3.9968160143085556  Val loss: -4.260159430225281
Epoch 333
-------------------------------
Batch 1/64 loss: -3.9533729553222656
Batch 2/64 loss: -3.9029431343078613
Batch 3/64 loss: -4.006860733032227
Batch 4/64 loss: -3.9554219245910645
Batch 5/64 loss: -4.027149677276611
Batch 6/64 loss: -3.969027042388916
Batch 7/64 loss: -3.9224367141723633
Batch 8/64 loss: -4.0131449699401855
Batch 9/64 loss: -3.773470401763916
Batch 10/64 loss: -4.104024887084961
Batch 11/64 loss: -3.9860973358154297
Batch 12/64 loss: -3.8307085037231445
Batch 13/64 loss: -4.033679485321045
Batch 14/64 loss: -4.03170108795166
Batch 15/64 loss: -3.873565673828125
Batch 16/64 loss: -3.9173407554626465
Batch 17/64 loss: -3.878620147705078
Batch 18/64 loss: -3.9647011756896973
Batch 19/64 loss: -3.9109487533569336
Batch 20/64 loss: -4.185238838195801
Batch 21/64 loss: -3.867858409881592
Batch 22/64 loss: -3.7197113037109375
Batch 23/64 loss: -4.039302349090576
Batch 24/64 loss: -3.862992286682129
Batch 25/64 loss: -3.979367733001709
Batch 26/64 loss: -3.8859095573425293
Batch 27/64 loss: -3.8324694633483887
Batch 28/64 loss: -3.8427882194519043
Batch 29/64 loss: -3.917092800140381
Batch 30/64 loss: -4.1071929931640625
Batch 31/64 loss: -4.028987884521484
Batch 32/64 loss: -4.075058460235596
Batch 33/64 loss: -3.9587860107421875
Batch 34/64 loss: -3.770571231842041
Batch 35/64 loss: -4.089089870452881
Batch 36/64 loss: -4.0206499099731445
Batch 37/64 loss: -3.6497063636779785
Batch 38/64 loss: -3.9021806716918945
Batch 39/64 loss: -3.9877538681030273
Batch 40/64 loss: -4.004670143127441
Batch 41/64 loss: -3.9195337295532227
Batch 42/64 loss: -3.974386215209961
Batch 43/64 loss: -3.7341041564941406
Batch 44/64 loss: -4.078627586364746
Batch 45/64 loss: -3.479806900024414
Batch 46/64 loss: -3.9032516479492188
Batch 47/64 loss: -4.022823333740234
Batch 48/64 loss: -3.7755942344665527
Batch 49/64 loss: -4.073540687561035
Batch 50/64 loss: -3.965299129486084
Batch 51/64 loss: -4.124998569488525
Batch 52/64 loss: -3.9050803184509277
Batch 53/64 loss: -4.080810546875
Batch 54/64 loss: -3.8909354209899902
Batch 55/64 loss: -3.868892192840576
Batch 56/64 loss: -3.8442611694335938
Batch 57/64 loss: -4.178565502166748
Batch 58/64 loss: -3.7869696617126465
Batch 59/64 loss: -3.8961968421936035
Batch 60/64 loss: -3.8196945190429688
Batch 61/64 loss: -4.091265678405762
Batch 62/64 loss: -3.9838991165161133
Batch 63/64 loss: -3.634315013885498
Batch 64/64 loss: -8.612144470214844
Epoch 333  Train loss: -3.9886204588646983  Val loss: -4.213126756071635
Epoch 334
-------------------------------
Batch 1/64 loss: -4.237312316894531
Batch 2/64 loss: -3.714632511138916
Batch 3/64 loss: -3.904256820678711
Batch 4/64 loss: -3.9518637657165527
Batch 5/64 loss: -3.8550562858581543
Batch 6/64 loss: -4.012624740600586
Batch 7/64 loss: -3.6359591484069824
Batch 8/64 loss: -4.061986446380615
Batch 9/64 loss: -3.9369497299194336
Batch 10/64 loss: -4.027655124664307
Batch 11/64 loss: -3.6451010704040527
Batch 12/64 loss: -3.740513324737549
Batch 13/64 loss: -3.6942834854125977
Batch 14/64 loss: -3.976073741912842
Batch 15/64 loss: -3.691364288330078
Batch 16/64 loss: -4.017808437347412
Batch 17/64 loss: -4.011151313781738
Batch 18/64 loss: -3.9070606231689453
Batch 19/64 loss: -4.120931148529053
Batch 20/64 loss: -3.9907331466674805
Batch 21/64 loss: -3.8480496406555176
Batch 22/64 loss: -4.116518497467041
Batch 23/64 loss: -4.010931015014648
Batch 24/64 loss: -3.929854393005371
Batch 25/64 loss: -4.090173721313477
Batch 26/64 loss: -3.9576854705810547
Batch 27/64 loss: -3.90354585647583
Batch 28/64 loss: -3.8449583053588867
Batch 29/64 loss: -4.092382907867432
Batch 30/64 loss: -4.037486553192139
Batch 31/64 loss: -3.8036651611328125
Batch 32/64 loss: -3.8379931449890137
Batch 33/64 loss: -4.013143539428711
Batch 34/64 loss: -4.081295490264893
Batch 35/64 loss: -3.9338507652282715
Batch 36/64 loss: -3.854325294494629
Batch 37/64 loss: -3.87882661819458
Batch 38/64 loss: -3.6178364753723145
Batch 39/64 loss: -4.046782493591309
Batch 40/64 loss: -3.8891754150390625
Batch 41/64 loss: -3.9373011589050293
Batch 42/64 loss: -3.9139633178710938
Batch 43/64 loss: -3.9271974563598633
Batch 44/64 loss: -4.086814880371094
Batch 45/64 loss: -3.825442314147949
Batch 46/64 loss: -3.990086555480957
Batch 47/64 loss: -4.042803764343262
Batch 48/64 loss: -3.8176016807556152
Batch 49/64 loss: -4.135512828826904
Batch 50/64 loss: -3.9266414642333984
Batch 51/64 loss: -3.9657363891601562
Batch 52/64 loss: -4.083882808685303
Batch 53/64 loss: -3.981550693511963
Batch 54/64 loss: -4.102429389953613
Batch 55/64 loss: -3.941913604736328
Batch 56/64 loss: -3.5600790977478027
Batch 57/64 loss: -4.145420551300049
Batch 58/64 loss: -3.891831874847412
Batch 59/64 loss: -3.655184745788574
Batch 60/64 loss: -4.042325019836426
Batch 61/64 loss: -3.9819107055664062
Batch 62/64 loss: -4.038330554962158
Batch 63/64 loss: -4.000917434692383
Batch 64/64 loss: -8.393951416015625
Epoch 334  Train loss: -3.9876414130715765  Val loss: -4.258759292130618
Epoch 335
-------------------------------
Batch 1/64 loss: -3.924001693725586
Batch 2/64 loss: -3.8782668113708496
Batch 3/64 loss: -4.107715606689453
Batch 4/64 loss: -4.088146209716797
Batch 5/64 loss: -4.120308876037598
Batch 6/64 loss: -4.0505900382995605
Batch 7/64 loss: -4.0477070808410645
Batch 8/64 loss: -4.084248065948486
Batch 9/64 loss: -3.998411178588867
Batch 10/64 loss: -3.859321117401123
Batch 11/64 loss: -4.096150875091553
Batch 12/64 loss: -3.9805750846862793
Batch 13/64 loss: -4.003430366516113
Batch 14/64 loss: -3.812215805053711
Batch 15/64 loss: -3.909524917602539
Batch 16/64 loss: -3.9910240173339844
Batch 17/64 loss: -4.046099662780762
Batch 18/64 loss: -4.060840129852295
Batch 19/64 loss: -4.047029495239258
Batch 20/64 loss: -3.9710588455200195
Batch 21/64 loss: -4.213940620422363
Batch 22/64 loss: -4.031296730041504
Batch 23/64 loss: -3.7387943267822266
Batch 24/64 loss: -3.669017791748047
Batch 25/64 loss: -4.055934906005859
Batch 26/64 loss: -3.862537384033203
Batch 27/64 loss: -3.9445924758911133
Batch 28/64 loss: -3.935070514678955
Batch 29/64 loss: -3.7977166175842285
Batch 30/64 loss: -3.588672637939453
Batch 31/64 loss: -4.017002582550049
Batch 32/64 loss: -3.9023404121398926
Batch 33/64 loss: -3.943943500518799
Batch 34/64 loss: -3.6801843643188477
Batch 35/64 loss: -3.9693946838378906
Batch 36/64 loss: -3.9805455207824707
Batch 37/64 loss: -4.202226161956787
Batch 38/64 loss: -4.035015106201172
Batch 39/64 loss: -4.017333984375
Batch 40/64 loss: -4.019241809844971
Batch 41/64 loss: -3.9203310012817383
Batch 42/64 loss: -4.014941692352295
Batch 43/64 loss: -3.8517322540283203
Batch 44/64 loss: -3.9210238456726074
Batch 45/64 loss: -3.9921116828918457
Batch 46/64 loss: -3.8574376106262207
Batch 47/64 loss: -4.0683441162109375
Batch 48/64 loss: -4.1963958740234375
Batch 49/64 loss: -3.972202777862549
Batch 50/64 loss: -4.1852569580078125
Batch 51/64 loss: -3.9345593452453613
Batch 52/64 loss: -3.902165412902832
Batch 53/64 loss: -3.943732261657715
Batch 54/64 loss: -4.0458760261535645
Batch 55/64 loss: -4.111758708953857
Batch 56/64 loss: -4.020289897918701
Batch 57/64 loss: -3.9932680130004883
Batch 58/64 loss: -3.9854159355163574
Batch 59/64 loss: -4.023358345031738
Batch 60/64 loss: -3.9208436012268066
Batch 61/64 loss: -4.046242713928223
Batch 62/64 loss: -4.087403774261475
Batch 63/64 loss: -3.947312831878662
Batch 64/64 loss: -8.679708480834961
Epoch 335  Train loss: -4.033462808646408  Val loss: -4.3702515933112185
Epoch 336
-------------------------------
Batch 1/64 loss: -3.6557703018188477
Batch 2/64 loss: -4.114657878875732
Batch 3/64 loss: -3.9983043670654297
Batch 4/64 loss: -3.98091983795166
Batch 5/64 loss: -3.8256421089172363
Batch 6/64 loss: -3.905149459838867
Batch 7/64 loss: -4.047573566436768
Batch 8/64 loss: -4.120029449462891
Batch 9/64 loss: -3.709048271179199
Batch 10/64 loss: -3.845609664916992
Batch 11/64 loss: -4.192761421203613
Batch 12/64 loss: -4.075764179229736
Batch 13/64 loss: -4.077162265777588
Batch 14/64 loss: -3.8806447982788086
Batch 15/64 loss: -4.056297779083252
Batch 16/64 loss: -4.071879863739014
Batch 17/64 loss: -3.8833818435668945
Batch 18/64 loss: -4.007272243499756
Batch 19/64 loss: -3.9024739265441895
Batch 20/64 loss: -3.9759387969970703
Batch 21/64 loss: -3.791524887084961
Batch 22/64 loss: -3.8139100074768066
Batch 23/64 loss: -4.0269904136657715
Batch 24/64 loss: -3.941257953643799
Batch 25/64 loss: -3.909912586212158
Batch 26/64 loss: -4.0334858894348145
Batch 27/64 loss: -4.039719581604004
Batch 28/64 loss: -4.09965705871582
Batch 29/64 loss: -3.7641067504882812
Batch 30/64 loss: -3.7906742095947266
Batch 31/64 loss: -3.9764018058776855
Batch 32/64 loss: -4.0354084968566895
Batch 33/64 loss: -3.8682103157043457
Batch 34/64 loss: -3.966993808746338
Batch 35/64 loss: -4.029692649841309
Batch 36/64 loss: -4.024997711181641
Batch 37/64 loss: -4.138552665710449
Batch 38/64 loss: -4.042678356170654
Batch 39/64 loss: -3.9960379600524902
Batch 40/64 loss: -3.948172092437744
Batch 41/64 loss: -3.9050331115722656
Batch 42/64 loss: -4.104085445404053
Batch 43/64 loss: -3.944930076599121
Batch 44/64 loss: -3.879310131072998
Batch 45/64 loss: -3.895608425140381
Batch 46/64 loss: -4.011634826660156
Batch 47/64 loss: -3.733250617980957
Batch 48/64 loss: -4.092075347900391
Batch 49/64 loss: -4.033073425292969
Batch 50/64 loss: -3.9099693298339844
Batch 51/64 loss: -4.146515369415283
Batch 52/64 loss: -4.195384502410889
Batch 53/64 loss: -4.112786293029785
Batch 54/64 loss: -3.980958938598633
Batch 55/64 loss: -4.006315231323242
Batch 56/64 loss: -4.011432647705078
Batch 57/64 loss: -3.92718505859375
Batch 58/64 loss: -3.999948024749756
Batch 59/64 loss: -3.9228382110595703
Batch 60/64 loss: -4.0439653396606445
Batch 61/64 loss: -3.9833264350891113
Batch 62/64 loss: -3.7850399017333984
Batch 63/64 loss: -3.9150848388671875
Batch 64/64 loss: -8.498440742492676
Epoch 336  Train loss: -4.023188224493288  Val loss: -4.236388386729657
Epoch 337
-------------------------------
Batch 1/64 loss: -4.115185737609863
Batch 2/64 loss: -3.9206771850585938
Batch 3/64 loss: -4.051633358001709
Batch 4/64 loss: -4.035675048828125
Batch 5/64 loss: -4.0143890380859375
Batch 6/64 loss: -4.065601348876953
Batch 7/64 loss: -3.8500523567199707
Batch 8/64 loss: -4.041620254516602
Batch 9/64 loss: -3.8548359870910645
Batch 10/64 loss: -3.918461322784424
Batch 11/64 loss: -4.026900291442871
Batch 12/64 loss: -3.6986684799194336
Batch 13/64 loss: -3.9208550453186035
Batch 14/64 loss: -4.0282511711120605
Batch 15/64 loss: -4.027393817901611
Batch 16/64 loss: -4.1151814460754395
Batch 17/64 loss: -3.991617202758789
Batch 18/64 loss: -3.928835391998291
Batch 19/64 loss: -3.955075740814209
Batch 20/64 loss: -3.802867889404297
Batch 21/64 loss: -4.106771945953369
Batch 22/64 loss: -4.121789932250977
Batch 23/64 loss: -4.073265552520752
Batch 24/64 loss: -3.6088929176330566
Batch 25/64 loss: -4.079279899597168
Batch 26/64 loss: -4.004759788513184
Batch 27/64 loss: -4.117007255554199
Batch 28/64 loss: -3.779097557067871
Batch 29/64 loss: -3.7305502891540527
Batch 30/64 loss: -4.075259685516357
Batch 31/64 loss: -4.029638767242432
Batch 32/64 loss: -3.975574493408203
Batch 33/64 loss: -3.865438938140869
Batch 34/64 loss: -3.911001682281494
Batch 35/64 loss: -4.1645283699035645
Batch 36/64 loss: -3.5333690643310547
Batch 37/64 loss: -3.8199830055236816
Batch 38/64 loss: -3.9880385398864746
Batch 39/64 loss: -3.596808910369873
Batch 40/64 loss: -3.944852352142334
Batch 41/64 loss: -3.9934654235839844
Batch 42/64 loss: -3.9553966522216797
Batch 43/64 loss: -4.046871185302734
Batch 44/64 loss: -3.9452877044677734
Batch 45/64 loss: -3.8726630210876465
Batch 46/64 loss: -3.97969388961792
Batch 47/64 loss: -3.980696678161621
Batch 48/64 loss: -3.908813953399658
Batch 49/64 loss: -3.8104891777038574
Batch 50/64 loss: -4.049388408660889
Batch 51/64 loss: -3.9086055755615234
Batch 52/64 loss: -3.9638209342956543
Batch 53/64 loss: -3.950206756591797
Batch 54/64 loss: -3.9597697257995605
Batch 55/64 loss: -3.9410386085510254
Batch 56/64 loss: -4.033788204193115
Batch 57/64 loss: -3.9560060501098633
Batch 58/64 loss: -3.8686914443969727
Batch 59/64 loss: -4.095102787017822
Batch 60/64 loss: -4.038213729858398
Batch 61/64 loss: -4.008096218109131
Batch 62/64 loss: -3.7083988189697266
Batch 63/64 loss: -3.678403854370117
Batch 64/64 loss: -8.153681755065918
Epoch 337  Train loss: -3.9946330537983017  Val loss: -4.41318234053674
Saving best model, epoch: 337
Epoch 338
-------------------------------
Batch 1/64 loss: -4.090429306030273
Batch 2/64 loss: -3.980340003967285
Batch 3/64 loss: -4.001014232635498
Batch 4/64 loss: -3.991189956665039
Batch 5/64 loss: -4.015975475311279
Batch 6/64 loss: -3.940549850463867
Batch 7/64 loss: -3.836958885192871
Batch 8/64 loss: -3.9582247734069824
Batch 9/64 loss: -4.015050411224365
Batch 10/64 loss: -3.9793624877929688
Batch 11/64 loss: -4.106194496154785
Batch 12/64 loss: -4.0482258796691895
Batch 13/64 loss: -3.8305373191833496
Batch 14/64 loss: -3.958923816680908
Batch 15/64 loss: -4.036316394805908
Batch 16/64 loss: -4.202767848968506
Batch 17/64 loss: -4.042813301086426
Batch 18/64 loss: -3.9541354179382324
Batch 19/64 loss: -3.5692381858825684
Batch 20/64 loss: -3.8622493743896484
Batch 21/64 loss: -4.031705856323242
Batch 22/64 loss: -3.911688804626465
Batch 23/64 loss: -3.7476625442504883
Batch 24/64 loss: -3.472606658935547
Batch 25/64 loss: -3.61635160446167
Batch 26/64 loss: -4.035229206085205
Batch 27/64 loss: -4.0885114669799805
Batch 28/64 loss: -4.044484615325928
Batch 29/64 loss: -3.759244918823242
Batch 30/64 loss: -4.1446428298950195
Batch 31/64 loss: -3.9416322708129883
Batch 32/64 loss: -4.043420314788818
Batch 33/64 loss: -3.864915370941162
Batch 34/64 loss: -4.074456691741943
Batch 35/64 loss: -4.094480037689209
Batch 36/64 loss: -4.094794273376465
Batch 37/64 loss: -4.040985584259033
Batch 38/64 loss: -4.073383808135986
Batch 39/64 loss: -4.1179938316345215
Batch 40/64 loss: -4.063559532165527
Batch 41/64 loss: -4.012434005737305
Batch 42/64 loss: -4.012713432312012
Batch 43/64 loss: -3.8793063163757324
Batch 44/64 loss: -3.901303291320801
Batch 45/64 loss: -4.061980724334717
Batch 46/64 loss: -3.935055732727051
Batch 47/64 loss: -4.1559882164001465
Batch 48/64 loss: -3.7931089401245117
Batch 49/64 loss: -4.0491108894348145
Batch 50/64 loss: -4.108078956604004
Batch 51/64 loss: -3.9906463623046875
Batch 52/64 loss: -3.8563175201416016
Batch 53/64 loss: -3.9721503257751465
Batch 54/64 loss: -3.7987565994262695
Batch 55/64 loss: -3.9640021324157715
Batch 56/64 loss: -4.045621395111084
Batch 57/64 loss: -3.7545924186706543
Batch 58/64 loss: -3.858602523803711
Batch 59/64 loss: -4.046223163604736
Batch 60/64 loss: -3.7574119567871094
Batch 61/64 loss: -3.8417959213256836
Batch 62/64 loss: -3.8018007278442383
Batch 63/64 loss: -4.088865280151367
Batch 64/64 loss: -8.363885879516602
Epoch 338  Train loss: -4.010055354997223  Val loss: -4.337804053657243
Epoch 339
-------------------------------
Batch 1/64 loss: -3.8779778480529785
Batch 2/64 loss: -4.072222709655762
Batch 3/64 loss: -3.835113048553467
Batch 4/64 loss: -4.058897495269775
Batch 5/64 loss: -3.9538869857788086
Batch 6/64 loss: -4.063053607940674
Batch 7/64 loss: -3.9787797927856445
Batch 8/64 loss: -3.7598509788513184
Batch 9/64 loss: -4.033395290374756
Batch 10/64 loss: -3.950105667114258
Batch 11/64 loss: -4.0049591064453125
Batch 12/64 loss: -3.9818902015686035
Batch 13/64 loss: -4.127317428588867
Batch 14/64 loss: -4.032092571258545
Batch 15/64 loss: -3.943063735961914
Batch 16/64 loss: -3.9786415100097656
Batch 17/64 loss: -4.04529333114624
Batch 18/64 loss: -3.820666790008545
Batch 19/64 loss: -3.9129867553710938
Batch 20/64 loss: -3.927428722381592
Batch 21/64 loss: -3.9120588302612305
Batch 22/64 loss: -3.979191303253174
Batch 23/64 loss: -4.0744309425354
Batch 24/64 loss: -3.937798023223877
Batch 25/64 loss: -3.838357448577881
Batch 26/64 loss: -3.735586166381836
Batch 27/64 loss: -3.62027645111084
Batch 28/64 loss: -4.022085666656494
Batch 29/64 loss: -3.9901132583618164
Batch 30/64 loss: -3.944187641143799
Batch 31/64 loss: -3.9706239700317383
Batch 32/64 loss: -4.025984764099121
Batch 33/64 loss: -4.019262790679932
Batch 34/64 loss: -3.9523582458496094
Batch 35/64 loss: -4.062426567077637
Batch 36/64 loss: -3.888401508331299
Batch 37/64 loss: -4.029932975769043
Batch 38/64 loss: -3.924258232116699
Batch 39/64 loss: -4.07223653793335
Batch 40/64 loss: -3.8770394325256348
Batch 41/64 loss: -3.8761963844299316
Batch 42/64 loss: -4.121607303619385
Batch 43/64 loss: -3.8923306465148926
Batch 44/64 loss: -3.9776692390441895
Batch 45/64 loss: -3.9963183403015137
Batch 46/64 loss: -3.908588409423828
Batch 47/64 loss: -3.940464973449707
Batch 48/64 loss: -3.770951747894287
Batch 49/64 loss: -3.985602378845215
Batch 50/64 loss: -3.4829483032226562
Batch 51/64 loss: -3.486544609069824
Batch 52/64 loss: -3.88584566116333
Batch 53/64 loss: -3.8844709396362305
Batch 54/64 loss: -3.9163284301757812
Batch 55/64 loss: -3.996696949005127
Batch 56/64 loss: -3.7985663414001465
Batch 57/64 loss: -3.742844581604004
Batch 58/64 loss: -3.9539542198181152
Batch 59/64 loss: -3.9984283447265625
Batch 60/64 loss: -3.7130913734436035
Batch 61/64 loss: -3.8588685989379883
Batch 62/64 loss: -3.7474122047424316
Batch 63/64 loss: -3.9996395111083984
Batch 64/64 loss: -8.406036376953125
Epoch 339  Train loss: -3.976064801683613  Val loss: -4.26594404502423
Epoch 340
-------------------------------
Batch 1/64 loss: -3.791037082672119
Batch 2/64 loss: -3.752218723297119
Batch 3/64 loss: -3.9965004920959473
Batch 4/64 loss: -3.9849228858947754
Batch 5/64 loss: -3.970393180847168
Batch 6/64 loss: -3.7402706146240234
Batch 7/64 loss: -4.066039085388184
Batch 8/64 loss: -4.108332633972168
Batch 9/64 loss: -3.887516498565674
Batch 10/64 loss: -3.811581611633301
Batch 11/64 loss: -3.8974227905273438
Batch 12/64 loss: -3.9545669555664062
Batch 13/64 loss: -3.8766064643859863
Batch 14/64 loss: -3.8853673934936523
Batch 15/64 loss: -3.8525853157043457
Batch 16/64 loss: -3.9607019424438477
Batch 17/64 loss: -3.8182568550109863
Batch 18/64 loss: -3.884006977081299
Batch 19/64 loss: -3.9893836975097656
Batch 20/64 loss: -3.9673075675964355
Batch 21/64 loss: -4.010175704956055
Batch 22/64 loss: -3.9252052307128906
Batch 23/64 loss: -3.8294878005981445
Batch 24/64 loss: -3.704179286956787
Batch 25/64 loss: -3.6976370811462402
Batch 26/64 loss: -3.906902313232422
Batch 27/64 loss: -4.063846111297607
Batch 28/64 loss: -3.8677821159362793
Batch 29/64 loss: -4.03132963180542
Batch 30/64 loss: -4.077019691467285
Batch 31/64 loss: -3.921825408935547
Batch 32/64 loss: -3.9943809509277344
Batch 33/64 loss: -4.042425632476807
Batch 34/64 loss: -3.955782890319824
Batch 35/64 loss: -4.013476848602295
Batch 36/64 loss: -3.8677144050598145
Batch 37/64 loss: -3.8235740661621094
Batch 38/64 loss: -4.051692008972168
Batch 39/64 loss: -4.098091125488281
Batch 40/64 loss: -4.050191879272461
Batch 41/64 loss: -3.8811779022216797
Batch 42/64 loss: -3.8991198539733887
Batch 43/64 loss: -3.9257702827453613
Batch 44/64 loss: -3.9586801528930664
Batch 45/64 loss: -3.9125375747680664
Batch 46/64 loss: -3.778714656829834
Batch 47/64 loss: -3.9546656608581543
Batch 48/64 loss: -3.896109104156494
Batch 49/64 loss: -4.0956010818481445
Batch 50/64 loss: -3.8154664039611816
Batch 51/64 loss: -3.7286977767944336
Batch 52/64 loss: -3.819119930267334
Batch 53/64 loss: -3.479503631591797
Batch 54/64 loss: -3.997483253479004
Batch 55/64 loss: -3.46859073638916
Batch 56/64 loss: -3.745408535003662
Batch 57/64 loss: -3.891077995300293
Batch 58/64 loss: -3.6725473403930664
Batch 59/64 loss: -3.6404600143432617
Batch 60/64 loss: -3.8461761474609375
Batch 61/64 loss: -3.7785491943359375
Batch 62/64 loss: -3.9478821754455566
Batch 63/64 loss: -3.910330295562744
Batch 64/64 loss: -8.249424934387207
Epoch 340  Train loss: -3.9428780761419557  Val loss: -4.171747935186956
Epoch 341
-------------------------------
Batch 1/64 loss: -3.9091997146606445
Batch 2/64 loss: -3.9174184799194336
Batch 3/64 loss: -3.9426708221435547
Batch 4/64 loss: -3.8670454025268555
Batch 5/64 loss: -3.7976479530334473
Batch 6/64 loss: -3.8771157264709473
Batch 7/64 loss: -3.861961841583252
Batch 8/64 loss: -3.905634880065918
Batch 9/64 loss: -3.7098588943481445
Batch 10/64 loss: -3.7885379791259766
Batch 11/64 loss: -3.849432945251465
Batch 12/64 loss: -3.8793511390686035
Batch 13/64 loss: -3.848987102508545
Batch 14/64 loss: -3.675079345703125
Batch 15/64 loss: -4.015115737915039
Batch 16/64 loss: -3.7440185546875
Batch 17/64 loss: -3.610898494720459
Batch 18/64 loss: -3.7952475547790527
Batch 19/64 loss: -3.854128360748291
Batch 20/64 loss: -3.942413330078125
Batch 21/64 loss: -3.809514045715332
Batch 22/64 loss: -4.219828128814697
Batch 23/64 loss: -3.891043186187744
Batch 24/64 loss: -3.929117202758789
Batch 25/64 loss: -3.955014705657959
Batch 26/64 loss: -3.9520106315612793
Batch 27/64 loss: -3.917901039123535
Batch 28/64 loss: -3.977104663848877
Batch 29/64 loss: -3.7768611907958984
Batch 30/64 loss: -3.8017520904541016
Batch 31/64 loss: -3.916259765625
Batch 32/64 loss: -3.904745101928711
Batch 33/64 loss: -3.8629074096679688
Batch 34/64 loss: -3.8058266639709473
Batch 35/64 loss: -3.6763415336608887
Batch 36/64 loss: -4.0427727699279785
Batch 37/64 loss: -3.744871139526367
Batch 38/64 loss: -3.8821277618408203
Batch 39/64 loss: -4.026756286621094
Batch 40/64 loss: -3.799771308898926
Batch 41/64 loss: -3.942779064178467
Batch 42/64 loss: -3.8440704345703125
Batch 43/64 loss: -3.8850507736206055
Batch 44/64 loss: -3.9764580726623535
Batch 45/64 loss: -3.779508113861084
Batch 46/64 loss: -4.054079055786133
Batch 47/64 loss: -3.881455898284912
Batch 48/64 loss: -4.032737731933594
Batch 49/64 loss: -3.993326187133789
Batch 50/64 loss: -4.046908855438232
Batch 51/64 loss: -3.8041296005249023
Batch 52/64 loss: -3.8691210746765137
Batch 53/64 loss: -3.700989246368408
Batch 54/64 loss: -3.3867130279541016
Batch 55/64 loss: -3.923631191253662
Batch 56/64 loss: -3.7975258827209473
Batch 57/64 loss: -3.802988052368164
Batch 58/64 loss: -3.959827423095703
Batch 59/64 loss: -4.122541427612305
Batch 60/64 loss: -3.796717643737793
Batch 61/64 loss: -3.944718360900879
Batch 62/64 loss: -4.0264892578125
Batch 63/64 loss: -3.876871109008789
Batch 64/64 loss: -8.36560344696045
Epoch 341  Train loss: -3.927954995398428  Val loss: -4.288860098193192
Epoch 342
-------------------------------
Batch 1/64 loss: -3.996737003326416
Batch 2/64 loss: -4.070263862609863
Batch 3/64 loss: -4.014472484588623
Batch 4/64 loss: -4.050668239593506
Batch 5/64 loss: -4.09205961227417
Batch 6/64 loss: -3.8556084632873535
Batch 7/64 loss: -3.9369029998779297
Batch 8/64 loss: -3.9024505615234375
Batch 9/64 loss: -4.077057838439941
Batch 10/64 loss: -3.9931225776672363
Batch 11/64 loss: -3.8617544174194336
Batch 12/64 loss: -3.8929481506347656
Batch 13/64 loss: -4.18497371673584
Batch 14/64 loss: -3.890611171722412
Batch 15/64 loss: -4.04961633682251
Batch 16/64 loss: -3.831810474395752
Batch 17/64 loss: -4.04574728012085
Batch 18/64 loss: -3.9530534744262695
Batch 19/64 loss: -4.008941173553467
Batch 20/64 loss: -3.9823665618896484
Batch 21/64 loss: -3.7493896484375
Batch 22/64 loss: -3.950967311859131
Batch 23/64 loss: -3.756610870361328
Batch 24/64 loss: -4.052321434020996
Batch 25/64 loss: -3.9964442253112793
Batch 26/64 loss: -3.8295135498046875
Batch 27/64 loss: -3.906745433807373
Batch 28/64 loss: -4.0245680809021
Batch 29/64 loss: -3.9839606285095215
Batch 30/64 loss: -4.017395973205566
Batch 31/64 loss: -3.7712087631225586
Batch 32/64 loss: -4.034837245941162
Batch 33/64 loss: -3.998293876647949
Batch 34/64 loss: -3.995335578918457
Batch 35/64 loss: -3.873392105102539
Batch 36/64 loss: -3.959671974182129
Batch 37/64 loss: -3.9022741317749023
Batch 38/64 loss: -3.9042258262634277
Batch 39/64 loss: -3.9398193359375
Batch 40/64 loss: -4.117339134216309
Batch 41/64 loss: -3.82828426361084
Batch 42/64 loss: -3.974274158477783
Batch 43/64 loss: -4.002294540405273
Batch 44/64 loss: -4.032000541687012
Batch 45/64 loss: -3.8090529441833496
Batch 46/64 loss: -3.550157070159912
Batch 47/64 loss: -4.077131271362305
Batch 48/64 loss: -3.8201117515563965
Batch 49/64 loss: -3.985945224761963
Batch 50/64 loss: -3.7713851928710938
Batch 51/64 loss: -4.1288862228393555
Batch 52/64 loss: -4.154165744781494
Batch 53/64 loss: -4.017104625701904
Batch 54/64 loss: -3.8719019889831543
Batch 55/64 loss: -4.03350830078125
Batch 56/64 loss: -3.888835906982422
Batch 57/64 loss: -3.982293128967285
Batch 58/64 loss: -3.948568820953369
Batch 59/64 loss: -3.980006694793701
Batch 60/64 loss: -3.870814800262451
Batch 61/64 loss: -3.9175519943237305
Batch 62/64 loss: -3.776045322418213
Batch 63/64 loss: -4.14572286605835
Batch 64/64 loss: -8.601485252380371
Epoch 342  Train loss: -4.007413942673627  Val loss: -4.332883749630852
Epoch 343
-------------------------------
Batch 1/64 loss: -3.868917465209961
Batch 2/64 loss: -3.9078259468078613
Batch 3/64 loss: -4.176479816436768
Batch 4/64 loss: -4.096187591552734
Batch 5/64 loss: -3.875274181365967
Batch 6/64 loss: -4.077309608459473
Batch 7/64 loss: -4.013925552368164
Batch 8/64 loss: -3.913478374481201
Batch 9/64 loss: -3.986701488494873
Batch 10/64 loss: -3.948060989379883
Batch 11/64 loss: -4.167016506195068
Batch 12/64 loss: -4.145162105560303
Batch 13/64 loss: -3.8728156089782715
Batch 14/64 loss: -4.085975646972656
Batch 15/64 loss: -4.154799461364746
Batch 16/64 loss: -4.175256252288818
Batch 17/64 loss: -4.011204719543457
Batch 18/64 loss: -3.9554595947265625
Batch 19/64 loss: -4.074528217315674
Batch 20/64 loss: -3.807814121246338
Batch 21/64 loss: -3.9871201515197754
Batch 22/64 loss: -3.8341126441955566
Batch 23/64 loss: -3.7629761695861816
Batch 24/64 loss: -4.169491291046143
Batch 25/64 loss: -4.156496047973633
Batch 26/64 loss: -3.8246288299560547
Batch 27/64 loss: -4.122249603271484
Batch 28/64 loss: -4.137165546417236
Batch 29/64 loss: -4.050117492675781
Batch 30/64 loss: -3.883456230163574
Batch 31/64 loss: -4.169142723083496
Batch 32/64 loss: -3.9853477478027344
Batch 33/64 loss: -3.862196445465088
Batch 34/64 loss: -3.6052474975585938
Batch 35/64 loss: -4.023149490356445
Batch 36/64 loss: -4.093293190002441
Batch 37/64 loss: -3.9531474113464355
Batch 38/64 loss: -3.792539596557617
Batch 39/64 loss: -3.921294689178467
Batch 40/64 loss: -4.029393196105957
Batch 41/64 loss: -4.19390869140625
Batch 42/64 loss: -3.7969183921813965
Batch 43/64 loss: -3.5758724212646484
Batch 44/64 loss: -4.112243175506592
Batch 45/64 loss: -4.148798942565918
Batch 46/64 loss: -4.058807373046875
Batch 47/64 loss: -4.015987873077393
Batch 48/64 loss: -3.7557711601257324
Batch 49/64 loss: -3.830678939819336
Batch 50/64 loss: -3.997018337249756
Batch 51/64 loss: -3.997744083404541
Batch 52/64 loss: -4.005731105804443
Batch 53/64 loss: -4.028948783874512
Batch 54/64 loss: -4.112955093383789
Batch 55/64 loss: -3.9900131225585938
Batch 56/64 loss: -4.0516743659973145
Batch 57/64 loss: -4.001462936401367
Batch 58/64 loss: -4.100021839141846
Batch 59/64 loss: -4.097995758056641
Batch 60/64 loss: -3.922268867492676
Batch 61/64 loss: -3.867093086242676
Batch 62/64 loss: -4.096166610717773
Batch 63/64 loss: -3.986781120300293
Batch 64/64 loss: -8.4541015625
Epoch 343  Train loss: -4.0433285881491265  Val loss: -4.368373097423016
Epoch 344
-------------------------------
Batch 1/64 loss: -4.114648342132568
Batch 2/64 loss: -3.939159393310547
Batch 3/64 loss: -3.9668984413146973
Batch 4/64 loss: -3.933290958404541
Batch 5/64 loss: -3.9844508171081543
Batch 6/64 loss: -3.9617233276367188
Batch 7/64 loss: -4.118008136749268
Batch 8/64 loss: -4.0390944480896
Batch 9/64 loss: -4.058704376220703
Batch 10/64 loss: -3.739774703979492
Batch 11/64 loss: -4.04992151260376
Batch 12/64 loss: -4.028677463531494
Batch 13/64 loss: -4.084515571594238
Batch 14/64 loss: -3.5733189582824707
Batch 15/64 loss: -3.9347033500671387
Batch 16/64 loss: -4.131103992462158
Batch 17/64 loss: -3.955902099609375
Batch 18/64 loss: -3.905369281768799
Batch 19/64 loss: -4.021796703338623
Batch 20/64 loss: -4.088261127471924
Batch 21/64 loss: -4.023629188537598
Batch 22/64 loss: -3.966463565826416
Batch 23/64 loss: -3.768893241882324
Batch 24/64 loss: -4.07056188583374
Batch 25/64 loss: -3.9961671829223633
Batch 26/64 loss: -4.043819904327393
Batch 27/64 loss: -3.802967071533203
Batch 28/64 loss: -3.602212905883789
Batch 29/64 loss: -3.95135498046875
Batch 30/64 loss: -4.077517032623291
Batch 31/64 loss: -4.099465370178223
Batch 32/64 loss: -4.091894626617432
Batch 33/64 loss: -3.9870710372924805
Batch 34/64 loss: -4.006050109863281
Batch 35/64 loss: -4.018578052520752
Batch 36/64 loss: -3.9944796562194824
Batch 37/64 loss: -3.9112138748168945
Batch 38/64 loss: -4.010847091674805
Batch 39/64 loss: -3.9562759399414062
Batch 40/64 loss: -3.8590946197509766
Batch 41/64 loss: -4.046571731567383
Batch 42/64 loss: -4.0682053565979
Batch 43/64 loss: -3.957123279571533
Batch 44/64 loss: -3.805419445037842
Batch 45/64 loss: -4.034635543823242
Batch 46/64 loss: -4.001089572906494
Batch 47/64 loss: -3.9487862586975098
Batch 48/64 loss: -3.923311710357666
Batch 49/64 loss: -3.913072109222412
Batch 50/64 loss: -3.881063938140869
Batch 51/64 loss: -4.014557838439941
Batch 52/64 loss: -4.012484073638916
Batch 53/64 loss: -3.9854183197021484
Batch 54/64 loss: -4.1071858406066895
Batch 55/64 loss: -3.9955224990844727
Batch 56/64 loss: -4.076234817504883
Batch 57/64 loss: -4.081355571746826
Batch 58/64 loss: -4.081592559814453
Batch 59/64 loss: -3.8980612754821777
Batch 60/64 loss: -3.953467845916748
Batch 61/64 loss: -4.069576740264893
Batch 62/64 loss: -3.9907336235046387
Batch 63/64 loss: -4.016742706298828
Batch 64/64 loss: -8.118797302246094
Epoch 344  Train loss: -4.0285363290824145  Val loss: -4.137378810607281
Epoch 345
-------------------------------
Batch 1/64 loss: -3.946296215057373
Batch 2/64 loss: -3.987844944000244
Batch 3/64 loss: -3.7675304412841797
Batch 4/64 loss: -3.7687783241271973
Batch 5/64 loss: -3.9059948921203613
Batch 6/64 loss: -3.8965234756469727
Batch 7/64 loss: -3.7326507568359375
Batch 8/64 loss: -4.0604777336120605
Batch 9/64 loss: -3.595040798187256
Batch 10/64 loss: -3.8174304962158203
Batch 11/64 loss: -4.043947696685791
Batch 12/64 loss: -3.9996867179870605
Batch 13/64 loss: -4.01915168762207
Batch 14/64 loss: -4.021577835083008
Batch 15/64 loss: -3.7154011726379395
Batch 16/64 loss: -4.017062664031982
Batch 17/64 loss: -4.012688636779785
Batch 18/64 loss: -4.013335227966309
Batch 19/64 loss: -4.006576061248779
Batch 20/64 loss: -4.005166053771973
Batch 21/64 loss: -3.6601877212524414
Batch 22/64 loss: -3.9821834564208984
Batch 23/64 loss: -3.976386547088623
Batch 24/64 loss: -4.050782680511475
Batch 25/64 loss: -3.895221710205078
Batch 26/64 loss: -3.9915385246276855
Batch 27/64 loss: -3.9133920669555664
Batch 28/64 loss: -4.001606464385986
Batch 29/64 loss: -3.928856372833252
Batch 30/64 loss: -3.9435863494873047
Batch 31/64 loss: -4.0230302810668945
Batch 32/64 loss: -4.024295806884766
Batch 33/64 loss: -3.7851128578186035
Batch 34/64 loss: -4.1610894203186035
Batch 35/64 loss: -3.9009957313537598
Batch 36/64 loss: -3.9065752029418945
Batch 37/64 loss: -4.022739410400391
Batch 38/64 loss: -3.9482693672180176
Batch 39/64 loss: -3.829288959503174
Batch 40/64 loss: -4.030974388122559
Batch 41/64 loss: -3.858181953430176
Batch 42/64 loss: -4.06243371963501
Batch 43/64 loss: -4.080348491668701
Batch 44/64 loss: -4.008487224578857
Batch 45/64 loss: -3.9580860137939453
Batch 46/64 loss: -3.891475200653076
Batch 47/64 loss: -4.023037910461426
Batch 48/64 loss: -4.01273250579834
Batch 49/64 loss: -3.9580302238464355
Batch 50/64 loss: -4.142467498779297
Batch 51/64 loss: -4.147579193115234
Batch 52/64 loss: -3.7221169471740723
Batch 53/64 loss: -3.9337844848632812
Batch 54/64 loss: -3.799692153930664
Batch 55/64 loss: -3.9640583992004395
Batch 56/64 loss: -4.0148539543151855
Batch 57/64 loss: -3.467754364013672
Batch 58/64 loss: -4.0946784019470215
Batch 59/64 loss: -4.062065601348877
Batch 60/64 loss: -4.010733127593994
Batch 61/64 loss: -3.767575263977051
Batch 62/64 loss: -4.1577301025390625
Batch 63/64 loss: -4.037250995635986
Batch 64/64 loss: -8.249774932861328
Epoch 345  Train loss: -3.994851138545018  Val loss: -4.243935614517055
Epoch 346
-------------------------------
Batch 1/64 loss: -3.923954963684082
Batch 2/64 loss: -3.802618980407715
Batch 3/64 loss: -3.880725860595703
Batch 4/64 loss: -3.614797592163086
Batch 5/64 loss: -3.787947177886963
Batch 6/64 loss: -3.76755428314209
Batch 7/64 loss: -3.8949356079101562
Batch 8/64 loss: -4.123836040496826
Batch 9/64 loss: -3.954587936401367
Batch 10/64 loss: -3.9472594261169434
Batch 11/64 loss: -3.978618621826172
Batch 12/64 loss: -3.8889999389648438
Batch 13/64 loss: -3.564209461212158
Batch 14/64 loss: -3.8707995414733887
Batch 15/64 loss: -3.951024055480957
Batch 16/64 loss: -3.9442596435546875
Batch 17/64 loss: -3.9048876762390137
Batch 18/64 loss: -3.931734561920166
Batch 19/64 loss: -3.9600448608398438
Batch 20/64 loss: -3.9773001670837402
Batch 21/64 loss: -3.820072650909424
Batch 22/64 loss: -4.0135884284973145
Batch 23/64 loss: -3.8372459411621094
Batch 24/64 loss: -4.049201965332031
Batch 25/64 loss: -4.060575485229492
Batch 26/64 loss: -3.988877773284912
Batch 27/64 loss: -3.9433798789978027
Batch 28/64 loss: -3.938889503479004
Batch 29/64 loss: -4.028883934020996
Batch 30/64 loss: -4.018527030944824
Batch 31/64 loss: -3.935213088989258
Batch 32/64 loss: -4.080161094665527
Batch 33/64 loss: -3.94627046585083
Batch 34/64 loss: -3.856154441833496
Batch 35/64 loss: -3.7547106742858887
Batch 36/64 loss: -3.924286365509033
Batch 37/64 loss: -3.483938694000244
Batch 38/64 loss: -3.9044461250305176
Batch 39/64 loss: -4.020435810089111
Batch 40/64 loss: -3.711055278778076
Batch 41/64 loss: -3.7651963233947754
Batch 42/64 loss: -4.141916751861572
Batch 43/64 loss: -3.878452777862549
Batch 44/64 loss: -4.036100387573242
Batch 45/64 loss: -3.9884185791015625
Batch 46/64 loss: -3.8448925018310547
Batch 47/64 loss: -3.8237242698669434
Batch 48/64 loss: -3.7989625930786133
Batch 49/64 loss: -3.959146022796631
Batch 50/64 loss: -3.8135457038879395
Batch 51/64 loss: -3.846904754638672
Batch 52/64 loss: -3.946132183074951
Batch 53/64 loss: -4.083649635314941
Batch 54/64 loss: -3.8029026985168457
Batch 55/64 loss: -3.938215732574463
Batch 56/64 loss: -4.040350437164307
Batch 57/64 loss: -4.0203351974487305
Batch 58/64 loss: -3.8298745155334473
Batch 59/64 loss: -3.909092903137207
Batch 60/64 loss: -3.9457359313964844
Batch 61/64 loss: -4.0157790184021
Batch 62/64 loss: -3.8380894660949707
Batch 63/64 loss: -3.6016602516174316
Batch 64/64 loss: -8.219243049621582
Epoch 346  Train loss: -3.953247403163536  Val loss: -4.096372361854999
Epoch 347
-------------------------------
Batch 1/64 loss: -3.7978806495666504
Batch 2/64 loss: -3.9497780799865723
Batch 3/64 loss: -3.683487892150879
Batch 4/64 loss: -3.8302693367004395
Batch 5/64 loss: -3.7047266960144043
Batch 6/64 loss: -3.745370388031006
Batch 7/64 loss: -3.6459646224975586
Batch 8/64 loss: -3.8312578201293945
Batch 9/64 loss: -3.810579776763916
Batch 10/64 loss: -3.759687900543213
Batch 11/64 loss: -3.707282543182373
Batch 12/64 loss: -3.8190712928771973
Batch 13/64 loss: -3.997610569000244
Batch 14/64 loss: -3.7907447814941406
Batch 15/64 loss: -3.901642322540283
Batch 16/64 loss: -4.0924072265625
Batch 17/64 loss: -3.9342756271362305
Batch 18/64 loss: -3.8728389739990234
Batch 19/64 loss: -3.927855968475342
Batch 20/64 loss: -3.720724582672119
Batch 21/64 loss: -3.78389310836792
Batch 22/64 loss: -4.004963397979736
Batch 23/64 loss: -3.869800567626953
Batch 24/64 loss: -4.017791271209717
Batch 25/64 loss: -3.9038233757019043
Batch 26/64 loss: -3.836994171142578
Batch 27/64 loss: -3.9958014488220215
Batch 28/64 loss: -4.069411754608154
Batch 29/64 loss: -3.946871757507324
Batch 30/64 loss: -4.033910274505615
Batch 31/64 loss: -3.9158005714416504
Batch 32/64 loss: -3.7195258140563965
Batch 33/64 loss: -3.998053550720215
Batch 34/64 loss: -3.975584030151367
Batch 35/64 loss: -3.8745336532592773
Batch 36/64 loss: -3.934452533721924
Batch 37/64 loss: -3.9050755500793457
Batch 38/64 loss: -4.127089500427246
Batch 39/64 loss: -4.030922889709473
Batch 40/64 loss: -3.738391876220703
Batch 41/64 loss: -3.9348959922790527
Batch 42/64 loss: -3.8018107414245605
Batch 43/64 loss: -3.8767342567443848
Batch 44/64 loss: -4.050559997558594
Batch 45/64 loss: -3.891535758972168
Batch 46/64 loss: -4.064630031585693
Batch 47/64 loss: -3.87441349029541
Batch 48/64 loss: -3.795905113220215
Batch 49/64 loss: -3.974170684814453
Batch 50/64 loss: -3.661500930786133
Batch 51/64 loss: -4.019208908081055
Batch 52/64 loss: -4.100998401641846
Batch 53/64 loss: -3.9662084579467773
Batch 54/64 loss: -3.6804428100585938
Batch 55/64 loss: -4.075037956237793
Batch 56/64 loss: -3.876939296722412
Batch 57/64 loss: -3.8787670135498047
Batch 58/64 loss: -3.8478798866271973
Batch 59/64 loss: -4.050136566162109
Batch 60/64 loss: -3.9964723587036133
Batch 61/64 loss: -4.127992630004883
Batch 62/64 loss: -3.930331230163574
Batch 63/64 loss: -4.106735706329346
Batch 64/64 loss: -8.487332344055176
Epoch 347  Train loss: -3.9553718529495536  Val loss: -4.333186342953816
Epoch 348
-------------------------------
Batch 1/64 loss: -3.886436939239502
Batch 2/64 loss: -4.055155277252197
Batch 3/64 loss: -4.01514196395874
Batch 4/64 loss: -4.01025390625
Batch 5/64 loss: -3.930314064025879
Batch 6/64 loss: -3.909064769744873
Batch 7/64 loss: -3.6340537071228027
Batch 8/64 loss: -3.9493532180786133
Batch 9/64 loss: -4.136424541473389
Batch 10/64 loss: -3.9563732147216797
Batch 11/64 loss: -3.9214348793029785
Batch 12/64 loss: -4.071615219116211
Batch 13/64 loss: -4.114026069641113
Batch 14/64 loss: -4.079532623291016
Batch 15/64 loss: -3.914578437805176
Batch 16/64 loss: -4.062352180480957
Batch 17/64 loss: -4.090046405792236
Batch 18/64 loss: -3.8530077934265137
Batch 19/64 loss: -3.9963173866271973
Batch 20/64 loss: -4.053454399108887
Batch 21/64 loss: -3.9761691093444824
Batch 22/64 loss: -3.669318675994873
Batch 23/64 loss: -4.037265777587891
Batch 24/64 loss: -3.7682042121887207
Batch 25/64 loss: -4.027315616607666
Batch 26/64 loss: -4.014476299285889
Batch 27/64 loss: -4.112330913543701
Batch 28/64 loss: -3.836915969848633
Batch 29/64 loss: -4.043951034545898
Batch 30/64 loss: -3.949079990386963
Batch 31/64 loss: -4.153986930847168
Batch 32/64 loss: -3.963078498840332
Batch 33/64 loss: -4.025645732879639
Batch 34/64 loss: -4.13267183303833
Batch 35/64 loss: -4.01962947845459
Batch 36/64 loss: -3.7263946533203125
Batch 37/64 loss: -3.786088466644287
Batch 38/64 loss: -4.0186381340026855
Batch 39/64 loss: -3.985772132873535
Batch 40/64 loss: -4.055749416351318
Batch 41/64 loss: -4.15866231918335
Batch 42/64 loss: -3.9959640502929688
Batch 43/64 loss: -4.0793256759643555
Batch 44/64 loss: -4.066654682159424
Batch 45/64 loss: -4.0076165199279785
Batch 46/64 loss: -3.9319467544555664
Batch 47/64 loss: -4.088386058807373
Batch 48/64 loss: -3.9332990646362305
Batch 49/64 loss: -3.878676414489746
Batch 50/64 loss: -3.960533618927002
Batch 51/64 loss: -4.011821746826172
Batch 52/64 loss: -3.9617652893066406
Batch 53/64 loss: -3.927884578704834
Batch 54/64 loss: -4.016096591949463
Batch 55/64 loss: -3.9587931632995605
Batch 56/64 loss: -3.7516837120056152
Batch 57/64 loss: -4.132976531982422
Batch 58/64 loss: -4.0284600257873535
Batch 59/64 loss: -3.9944381713867188
Batch 60/64 loss: -3.8254427909851074
Batch 61/64 loss: -3.9505233764648438
Batch 62/64 loss: -3.798656463623047
Batch 63/64 loss: -3.9300107955932617
Batch 64/64 loss: -8.523704528808594
Epoch 348  Train loss: -4.027043398688821  Val loss: -4.271594830804674
Epoch 349
-------------------------------
Batch 1/64 loss: -3.8576173782348633
Batch 2/64 loss: -4.040579795837402
Batch 3/64 loss: -3.989119052886963
Batch 4/64 loss: -4.064037322998047
Batch 5/64 loss: -4.025973320007324
Batch 6/64 loss: -3.80546236038208
Batch 7/64 loss: -3.738725185394287
Batch 8/64 loss: -4.163549423217773
Batch 9/64 loss: -3.898102283477783
Batch 10/64 loss: -4.125175952911377
Batch 11/64 loss: -3.8225150108337402
Batch 12/64 loss: -3.851499557495117
Batch 13/64 loss: -4.123472690582275
Batch 14/64 loss: -4.055452346801758
Batch 15/64 loss: -4.0191330909729
Batch 16/64 loss: -3.7739672660827637
Batch 17/64 loss: -3.904191017150879
Batch 18/64 loss: -3.6128597259521484
Batch 19/64 loss: -4.019474029541016
Batch 20/64 loss: -3.9639806747436523
Batch 21/64 loss: -3.819335460662842
Batch 22/64 loss: -3.710296630859375
Batch 23/64 loss: -3.924370288848877
Batch 24/64 loss: -3.8635082244873047
Batch 25/64 loss: -3.9257044792175293
Batch 26/64 loss: -4.028914451599121
Batch 27/64 loss: -3.7349319458007812
Batch 28/64 loss: -3.9443359375
Batch 29/64 loss: -3.767259120941162
Batch 30/64 loss: -3.893016815185547
Batch 31/64 loss: -3.7531051635742188
Batch 32/64 loss: -3.849522113800049
Batch 33/64 loss: -3.7890267372131348
Batch 34/64 loss: -4.15510892868042
Batch 35/64 loss: -3.9626474380493164
Batch 36/64 loss: -3.9932847023010254
Batch 37/64 loss: -3.595688819885254
Batch 38/64 loss: -3.9470443725585938
Batch 39/64 loss: -3.9252676963806152
Batch 40/64 loss: -3.3466577529907227
Batch 41/64 loss: -3.959791660308838
Batch 42/64 loss: -3.8293867111206055
Batch 43/64 loss: -3.936574935913086
Batch 44/64 loss: -3.781428813934326
Batch 45/64 loss: -3.9848551750183105
Batch 46/64 loss: -3.822944164276123
Batch 47/64 loss: -3.7865090370178223
Batch 48/64 loss: -4.091930389404297
Batch 49/64 loss: -3.858344078063965
Batch 50/64 loss: -3.857269287109375
Batch 51/64 loss: -3.991342544555664
Batch 52/64 loss: -3.906216621398926
Batch 53/64 loss: -3.884429454803467
Batch 54/64 loss: -4.111494064331055
Batch 55/64 loss: -3.5913615226745605
Batch 56/64 loss: -3.9214353561401367
Batch 57/64 loss: -3.9824471473693848
Batch 58/64 loss: -3.942230224609375
Batch 59/64 loss: -4.136791706085205
Batch 60/64 loss: -3.9691109657287598
Batch 61/64 loss: -3.9576940536499023
Batch 62/64 loss: -3.929487705230713
Batch 63/64 loss: -3.9330239295959473
Batch 64/64 loss: -8.634191513061523
Epoch 349  Train loss: -3.9596181607713885  Val loss: -4.311421633586032
Epoch 350
-------------------------------
Batch 1/64 loss: -3.936279773712158
Batch 2/64 loss: -4.065622329711914
Batch 3/64 loss: -3.8907647132873535
Batch 4/64 loss: -3.7212729454040527
Batch 5/64 loss: -3.807583808898926
Batch 6/64 loss: -4.0106306076049805
Batch 7/64 loss: -3.917844295501709
Batch 8/64 loss: -4.011213779449463
Batch 9/64 loss: -3.921738624572754
Batch 10/64 loss: -4.00750732421875
Batch 11/64 loss: -4.024301528930664
Batch 12/64 loss: -4.128255367279053
Batch 13/64 loss: -4.0691633224487305
Batch 14/64 loss: -3.8020853996276855
Batch 15/64 loss: -3.883206367492676
Batch 16/64 loss: -3.948245048522949
Batch 17/64 loss: -3.970324993133545
Batch 18/64 loss: -3.854006767272949
Batch 19/64 loss: -4.047565460205078
Batch 20/64 loss: -4.063509941101074
Batch 21/64 loss: -3.985813617706299
Batch 22/64 loss: -3.9028635025024414
Batch 23/64 loss: -4.003490447998047
Batch 24/64 loss: -4.0955939292907715
Batch 25/64 loss: -3.84141206741333
Batch 26/64 loss: -3.816483497619629
Batch 27/64 loss: -3.730536937713623
Batch 28/64 loss: -3.844064712524414
Batch 29/64 loss: -3.9582767486572266
Batch 30/64 loss: -4.006103515625
Batch 31/64 loss: -4.0955352783203125
Batch 32/64 loss: -4.039402484893799
Batch 33/64 loss: -4.133450508117676
Batch 34/64 loss: -3.9346418380737305
Batch 35/64 loss: -3.676621437072754
Batch 36/64 loss: -4.138914108276367
Batch 37/64 loss: -4.021368503570557
Batch 38/64 loss: -3.8401074409484863
Batch 39/64 loss: -3.8588318824768066
Batch 40/64 loss: -3.9925150871276855
Batch 41/64 loss: -3.735276222229004
Batch 42/64 loss: -3.812595844268799
Batch 43/64 loss: -4.134538650512695
Batch 44/64 loss: -3.771693229675293
Batch 45/64 loss: -3.8595943450927734
Batch 46/64 loss: -3.952517509460449
Batch 47/64 loss: -3.8322439193725586
Batch 48/64 loss: -4.043952941894531
Batch 49/64 loss: -4.0266547203063965
Batch 50/64 loss: -4.09044885635376
Batch 51/64 loss: -3.9097180366516113
Batch 52/64 loss: -4.08807373046875
Batch 53/64 loss: -4.060909748077393
Batch 54/64 loss: -4.158165454864502
Batch 55/64 loss: -3.96101713180542
Batch 56/64 loss: -4.2350544929504395
Batch 57/64 loss: -3.7821717262268066
Batch 58/64 loss: -4.1330156326293945
Batch 59/64 loss: -4.062363147735596
Batch 60/64 loss: -4.1130146980285645
Batch 61/64 loss: -3.990995407104492
Batch 62/64 loss: -3.85740327835083
Batch 63/64 loss: -4.110006332397461
Batch 64/64 loss: -8.5594482421875
Epoch 350  Train loss: -4.017853508743586  Val loss: -4.37788590368946
Epoch 351
-------------------------------
Batch 1/64 loss: -3.965421676635742
Batch 2/64 loss: -4.0165557861328125
Batch 3/64 loss: -4.169981956481934
Batch 4/64 loss: -3.8952255249023438
Batch 5/64 loss: -4.094460964202881
Batch 6/64 loss: -4.106508255004883
Batch 7/64 loss: -4.049039840698242
Batch 8/64 loss: -3.9736576080322266
Batch 9/64 loss: -4.149216175079346
Batch 10/64 loss: -4.070707321166992
Batch 11/64 loss: -4.055808067321777
Batch 12/64 loss: -3.4912548065185547
Batch 13/64 loss: -4.0707526206970215
Batch 14/64 loss: -4.103916645050049
Batch 15/64 loss: -4.141268253326416
Batch 16/64 loss: -4.226590633392334
Batch 17/64 loss: -3.948692798614502
Batch 18/64 loss: -3.760234832763672
Batch 19/64 loss: -4.0774006843566895
Batch 20/64 loss: -3.777581214904785
Batch 21/64 loss: -4.010071277618408
Batch 22/64 loss: -4.053410053253174
Batch 23/64 loss: -4.0584516525268555
Batch 24/64 loss: -3.924309253692627
Batch 25/64 loss: -4.0445332527160645
Batch 26/64 loss: -4.031660079956055
Batch 27/64 loss: -4.090062141418457
Batch 28/64 loss: -3.91151762008667
Batch 29/64 loss: -3.5183515548706055
Batch 30/64 loss: -4.03966760635376
Batch 31/64 loss: -3.9585704803466797
Batch 32/64 loss: -4.0263671875
Batch 33/64 loss: -3.7366409301757812
Batch 34/64 loss: -3.9832329750061035
Batch 35/64 loss: -3.9938035011291504
Batch 36/64 loss: -3.878662109375
Batch 37/64 loss: -3.680741310119629
Batch 38/64 loss: -3.937006950378418
Batch 39/64 loss: -3.9566245079040527
Batch 40/64 loss: -3.979687213897705
Batch 41/64 loss: -3.9759392738342285
Batch 42/64 loss: -3.990060329437256
Batch 43/64 loss: -4.006627559661865
Batch 44/64 loss: -3.946920394897461
Batch 45/64 loss: -4.072057723999023
Batch 46/64 loss: -3.919273853302002
Batch 47/64 loss: -3.9186272621154785
Batch 48/64 loss: -4.031064987182617
Batch 49/64 loss: -3.9760851860046387
Batch 50/64 loss: -3.9041481018066406
Batch 51/64 loss: -4.006344318389893
Batch 52/64 loss: -3.967594623565674
Batch 53/64 loss: -3.9990010261535645
Batch 54/64 loss: -3.9274868965148926
Batch 55/64 loss: -3.9616503715515137
Batch 56/64 loss: -4.093362331390381
Batch 57/64 loss: -4.024474620819092
Batch 58/64 loss: -4.042220592498779
Batch 59/64 loss: -3.916004180908203
Batch 60/64 loss: -3.9931716918945312
Batch 61/64 loss: -4.159359931945801
Batch 62/64 loss: -4.159948825836182
Batch 63/64 loss: -3.9637622833251953
Batch 64/64 loss: -8.56711483001709
Epoch 351  Train loss: -4.036677173539704  Val loss: -4.438573319477723
Saving best model, epoch: 351
Epoch 352
-------------------------------
Batch 1/64 loss: -4.134674072265625
Batch 2/64 loss: -4.092889308929443
Batch 3/64 loss: -4.012193202972412
Batch 4/64 loss: -3.9068045616149902
Batch 5/64 loss: -3.9724273681640625
Batch 6/64 loss: -3.9914708137512207
Batch 7/64 loss: -3.8655762672424316
Batch 8/64 loss: -4.0934014320373535
Batch 9/64 loss: -3.9668827056884766
Batch 10/64 loss: -3.917855739593506
Batch 11/64 loss: -4.057670593261719
Batch 12/64 loss: -3.93483304977417
Batch 13/64 loss: -3.9777321815490723
Batch 14/64 loss: -3.86338472366333
Batch 15/64 loss: -4.083437442779541
Batch 16/64 loss: -3.9325318336486816
Batch 17/64 loss: -3.973026752471924
Batch 18/64 loss: -3.978428363800049
Batch 19/64 loss: -3.9957146644592285
Batch 20/64 loss: -3.9870338439941406
Batch 21/64 loss: -4.1411919593811035
Batch 22/64 loss: -3.6552138328552246
Batch 23/64 loss: -3.927368640899658
Batch 24/64 loss: -3.9375925064086914
Batch 25/64 loss: -3.966167449951172
Batch 26/64 loss: -4.013393878936768
Batch 27/64 loss: -4.084304332733154
Batch 28/64 loss: -4.174239158630371
Batch 29/64 loss: -3.9743566513061523
Batch 30/64 loss: -4.089587688446045
Batch 31/64 loss: -3.625328540802002
Batch 32/64 loss: -4.1284966468811035
Batch 33/64 loss: -4.2076897621154785
Batch 34/64 loss: -4.146690368652344
Batch 35/64 loss: -4.114706516265869
Batch 36/64 loss: -4.028158664703369
Batch 37/64 loss: -4.0251665115356445
Batch 38/64 loss: -4.08350944519043
Batch 39/64 loss: -3.839099884033203
Batch 40/64 loss: -4.041355609893799
Batch 41/64 loss: -3.7332444190979004
Batch 42/64 loss: -3.9104666709899902
Batch 43/64 loss: -4.06591796875
Batch 44/64 loss: -3.9632554054260254
Batch 45/64 loss: -3.9330716133117676
Batch 46/64 loss: -4.087457180023193
Batch 47/64 loss: -3.896683692932129
Batch 48/64 loss: -4.006819725036621
Batch 49/64 loss: -4.019232749938965
Batch 50/64 loss: -4.134486675262451
Batch 51/64 loss: -4.07844877243042
Batch 52/64 loss: -3.961613655090332
Batch 53/64 loss: -4.138508319854736
Batch 54/64 loss: -3.992859363555908
Batch 55/64 loss: -4.118064880371094
Batch 56/64 loss: -3.735823154449463
Batch 57/64 loss: -3.8740944862365723
Batch 58/64 loss: -3.9780168533325195
Batch 59/64 loss: -4.090628623962402
Batch 60/64 loss: -4.085420608520508
Batch 61/64 loss: -4.018670558929443
Batch 62/64 loss: -4.027869701385498
Batch 63/64 loss: -4.052516460418701
Batch 64/64 loss: -8.42015266418457
Epoch 352  Train loss: -4.049566635431028  Val loss: -4.375534477102797
Epoch 353
-------------------------------
Batch 1/64 loss: -4.150686264038086
Batch 2/64 loss: -3.821438789367676
Batch 3/64 loss: -4.038954257965088
Batch 4/64 loss: -3.6589035987854004
Batch 5/64 loss: -3.930161476135254
Batch 6/64 loss: -3.999392509460449
Batch 7/64 loss: -3.9890356063842773
Batch 8/64 loss: -3.9694485664367676
Batch 9/64 loss: -3.9676971435546875
Batch 10/64 loss: -4.025283336639404
Batch 11/64 loss: -3.953909397125244
Batch 12/64 loss: -4.090090751647949
Batch 13/64 loss: -3.840114116668701
Batch 14/64 loss: -3.949802875518799
Batch 15/64 loss: -3.842802047729492
Batch 16/64 loss: -4.007630348205566
Batch 17/64 loss: -4.013576984405518
Batch 18/64 loss: -3.951911449432373
Batch 19/64 loss: -3.9941539764404297
Batch 20/64 loss: -3.745180130004883
Batch 21/64 loss: -3.8359713554382324
Batch 22/64 loss: -3.8735408782958984
Batch 23/64 loss: -4.120386600494385
Batch 24/64 loss: -3.6074366569519043
Batch 25/64 loss: -3.9899001121520996
Batch 26/64 loss: -3.923429489135742
Batch 27/64 loss: -4.003605365753174
Batch 28/64 loss: -3.998297691345215
Batch 29/64 loss: -4.01596212387085
Batch 30/64 loss: -3.937560558319092
Batch 31/64 loss: -3.9101510047912598
Batch 32/64 loss: -4.067290306091309
Batch 33/64 loss: -3.760551929473877
Batch 34/64 loss: -3.9389233589172363
Batch 35/64 loss: -4.028160095214844
Batch 36/64 loss: -3.856476306915283
Batch 37/64 loss: -4.111271381378174
Batch 38/64 loss: -3.983166217803955
Batch 39/64 loss: -4.118621349334717
Batch 40/64 loss: -3.9390735626220703
Batch 41/64 loss: -4.056412220001221
Batch 42/64 loss: -3.752117156982422
Batch 43/64 loss: -4.05903959274292
Batch 44/64 loss: -3.786465644836426
Batch 45/64 loss: -4.024226188659668
Batch 46/64 loss: -4.0079779624938965
Batch 47/64 loss: -3.8462891578674316
Batch 48/64 loss: -3.9731998443603516
Batch 49/64 loss: -3.8639674186706543
Batch 50/64 loss: -4.044735431671143
Batch 51/64 loss: -3.8325743675231934
Batch 52/64 loss: -3.9483695030212402
Batch 53/64 loss: -3.964895248413086
Batch 54/64 loss: -4.051896572113037
Batch 55/64 loss: -4.124360084533691
Batch 56/64 loss: -3.8742237091064453
Batch 57/64 loss: -4.032476425170898
Batch 58/64 loss: -3.8618664741516113
Batch 59/64 loss: -3.9538421630859375
Batch 60/64 loss: -3.995487689971924
Batch 61/64 loss: -3.9620676040649414
Batch 62/64 loss: -4.051547527313232
Batch 63/64 loss: -4.119231700897217
Batch 64/64 loss: -8.606976509094238
Epoch 353  Train loss: -4.009450228074018  Val loss: -4.335874734465609
Epoch 354
-------------------------------
Batch 1/64 loss: -3.956389904022217
Batch 2/64 loss: -3.88273286819458
Batch 3/64 loss: -4.063467502593994
Batch 4/64 loss: -3.985525131225586
Batch 5/64 loss: -4.068985462188721
Batch 6/64 loss: -3.9368786811828613
Batch 7/64 loss: -3.9049911499023438
Batch 8/64 loss: -3.993007183074951
Batch 9/64 loss: -4.033648490905762
Batch 10/64 loss: -4.0467047691345215
Batch 11/64 loss: -4.148948669433594
Batch 12/64 loss: -4.074841499328613
Batch 13/64 loss: -4.124893665313721
Batch 14/64 loss: -3.7838878631591797
Batch 15/64 loss: -4.107122898101807
Batch 16/64 loss: -4.118422508239746
Batch 17/64 loss: -4.0751190185546875
Batch 18/64 loss: -4.152557849884033
Batch 19/64 loss: -4.0219316482543945
Batch 20/64 loss: -3.9641060829162598
Batch 21/64 loss: -3.522829055786133
Batch 22/64 loss: -3.947267532348633
Batch 23/64 loss: -4.08567476272583
Batch 24/64 loss: -4.039928436279297
Batch 25/64 loss: -3.794018268585205
Batch 26/64 loss: -4.095592498779297
Batch 27/64 loss: -3.966320037841797
Batch 28/64 loss: -3.985283851623535
Batch 29/64 loss: -4.073639392852783
Batch 30/64 loss: -4.053977966308594
Batch 31/64 loss: -4.078603267669678
Batch 32/64 loss: -4.070353031158447
Batch 33/64 loss: -3.9191627502441406
Batch 34/64 loss: -4.068872928619385
Batch 35/64 loss: -4.008593559265137
Batch 36/64 loss: -4.086586952209473
Batch 37/64 loss: -3.883270263671875
Batch 38/64 loss: -4.013843059539795
Batch 39/64 loss: -3.7825207710266113
Batch 40/64 loss: -4.07891321182251
Batch 41/64 loss: -4.037929534912109
Batch 42/64 loss: -4.00918436050415
Batch 43/64 loss: -4.0922465324401855
Batch 44/64 loss: -4.196404933929443
Batch 45/64 loss: -3.854255199432373
Batch 46/64 loss: -4.11611795425415
Batch 47/64 loss: -4.045767784118652
Batch 48/64 loss: -3.973996639251709
Batch 49/64 loss: -4.156037330627441
Batch 50/64 loss: -4.097573757171631
Batch 51/64 loss: -4.155324459075928
Batch 52/64 loss: -4.151416778564453
Batch 53/64 loss: -4.105587959289551
Batch 54/64 loss: -4.093503475189209
Batch 55/64 loss: -4.02483606338501
Batch 56/64 loss: -3.8227014541625977
Batch 57/64 loss: -3.6231026649475098
Batch 58/64 loss: -3.6794075965881348
Batch 59/64 loss: -3.793461799621582
Batch 60/64 loss: -4.148686408996582
Batch 61/64 loss: -4.1174492835998535
Batch 62/64 loss: -3.950740337371826
Batch 63/64 loss: -4.032878398895264
Batch 64/64 loss: -8.666656494140625
Epoch 354  Train loss: -4.0592630199357576  Val loss: -4.399903693969307
Epoch 355
-------------------------------
Batch 1/64 loss: -4.0202484130859375
Batch 2/64 loss: -3.8897390365600586
Batch 3/64 loss: -4.140639781951904
Batch 4/64 loss: -4.0765061378479
Batch 5/64 loss: -4.206515312194824
Batch 6/64 loss: -4.058213233947754
Batch 7/64 loss: -3.954751491546631
Batch 8/64 loss: -4.048349857330322
Batch 9/64 loss: -4.181356430053711
Batch 10/64 loss: -4.17108678817749
Batch 11/64 loss: -4.048558235168457
Batch 12/64 loss: -3.948336124420166
Batch 13/64 loss: -4.046916961669922
Batch 14/64 loss: -4.228906631469727
Batch 15/64 loss: -4.013340950012207
Batch 16/64 loss: -4.040990829467773
Batch 17/64 loss: -4.093817234039307
Batch 18/64 loss: -3.959179401397705
Batch 19/64 loss: -3.988798141479492
Batch 20/64 loss: -4.145133972167969
Batch 21/64 loss: -3.8538336753845215
Batch 22/64 loss: -4.105119705200195
Batch 23/64 loss: -4.13184928894043
Batch 24/64 loss: -4.050822734832764
Batch 25/64 loss: -3.640872001647949
Batch 26/64 loss: -4.05972146987915
Batch 27/64 loss: -4.015654563903809
Batch 28/64 loss: -4.188920974731445
Batch 29/64 loss: -4.095772743225098
Batch 30/64 loss: -4.095724582672119
Batch 31/64 loss: -3.7124524116516113
Batch 32/64 loss: -3.9165210723876953
Batch 33/64 loss: -3.916901111602783
Batch 34/64 loss: -3.97609806060791
Batch 35/64 loss: -3.6693930625915527
Batch 36/64 loss: -3.7493600845336914
Batch 37/64 loss: -4.1340203285217285
Batch 38/64 loss: -3.613375663757324
Batch 39/64 loss: -3.982957363128662
Batch 40/64 loss: -4.161514759063721
Batch 41/64 loss: -3.96168851852417
Batch 42/64 loss: -3.344712257385254
Batch 43/64 loss: -4.158631324768066
Batch 44/64 loss: -4.113026142120361
Batch 45/64 loss: -4.072717189788818
Batch 46/64 loss: -4.037093639373779
Batch 47/64 loss: -3.8798093795776367
Batch 48/64 loss: -4.11640739440918
Batch 49/64 loss: -3.8872885704040527
Batch 50/64 loss: -3.6758484840393066
Batch 51/64 loss: -4.077853202819824
Batch 52/64 loss: -3.7987804412841797
Batch 53/64 loss: -3.8297324180603027
Batch 54/64 loss: -4.007020473480225
Batch 55/64 loss: -3.898560047149658
Batch 56/64 loss: -4.012942790985107
Batch 57/64 loss: -4.154876232147217
Batch 58/64 loss: -4.122767448425293
Batch 59/64 loss: -4.188742160797119
Batch 60/64 loss: -3.9370455741882324
Batch 61/64 loss: -4.129810333251953
Batch 62/64 loss: -4.056771278381348
Batch 63/64 loss: -3.9839744567871094
Batch 64/64 loss: -8.631174087524414
Epoch 355  Train loss: -4.051007857977175  Val loss: -4.3473366412919825
Epoch 356
-------------------------------
Batch 1/64 loss: -4.034849166870117
Batch 2/64 loss: -3.785217761993408
Batch 3/64 loss: -4.0653862953186035
Batch 4/64 loss: -3.756145477294922
Batch 5/64 loss: -3.9276375770568848
Batch 6/64 loss: -4.041334629058838
Batch 7/64 loss: -4.172823905944824
Batch 8/64 loss: -3.9318923950195312
Batch 9/64 loss: -3.801271438598633
Batch 10/64 loss: -3.996553421020508
Batch 11/64 loss: -4.11270809173584
Batch 12/64 loss: -4.048377513885498
Batch 13/64 loss: -3.8466787338256836
Batch 14/64 loss: -3.8500099182128906
Batch 15/64 loss: -4.050975799560547
Batch 16/64 loss: -4.101420879364014
Batch 17/64 loss: -4.015247344970703
Batch 18/64 loss: -4.13707971572876
Batch 19/64 loss: -4.038666248321533
Batch 20/64 loss: -4.0693230628967285
Batch 21/64 loss: -3.978450298309326
Batch 22/64 loss: -3.88145112991333
Batch 23/64 loss: -3.955681324005127
Batch 24/64 loss: -4.212324142456055
Batch 25/64 loss: -4.101554870605469
Batch 26/64 loss: -4.091109752655029
Batch 27/64 loss: -4.118098735809326
Batch 28/64 loss: -3.91062593460083
Batch 29/64 loss: -3.965023994445801
Batch 30/64 loss: -3.2297277450561523
Batch 31/64 loss: -3.9268527030944824
Batch 32/64 loss: -4.0983076095581055
Batch 33/64 loss: -3.7908568382263184
Batch 34/64 loss: -4.071106433868408
Batch 35/64 loss: -4.016822814941406
Batch 36/64 loss: -4.078883171081543
Batch 37/64 loss: -4.053783893585205
Batch 38/64 loss: -4.035903453826904
Batch 39/64 loss: -4.044833660125732
Batch 40/64 loss: -3.9207897186279297
Batch 41/64 loss: -4.003106117248535
Batch 42/64 loss: -4.021109580993652
Batch 43/64 loss: -4.20587682723999
Batch 44/64 loss: -3.89670467376709
Batch 45/64 loss: -4.125234603881836
Batch 46/64 loss: -4.006888389587402
Batch 47/64 loss: -4.091777801513672
Batch 48/64 loss: -3.73691987991333
Batch 49/64 loss: -4.075038433074951
Batch 50/64 loss: -4.1246442794799805
Batch 51/64 loss: -3.749995231628418
Batch 52/64 loss: -4.130962371826172
Batch 53/64 loss: -3.8965578079223633
Batch 54/64 loss: -4.1484198570251465
Batch 55/64 loss: -4.217523574829102
Batch 56/64 loss: -4.072454929351807
Batch 57/64 loss: -3.835834503173828
Batch 58/64 loss: -4.044121742248535
Batch 59/64 loss: -4.195194244384766
Batch 60/64 loss: -3.870877742767334
Batch 61/64 loss: -4.179931163787842
Batch 62/64 loss: -3.9626641273498535
Batch 63/64 loss: -4.0314717292785645
Batch 64/64 loss: -8.633938789367676
Epoch 356  Train loss: -4.052777275384641  Val loss: -4.41534065954464
Epoch 357
-------------------------------
Batch 1/64 loss: -4.170961856842041
Batch 2/64 loss: -4.236412525177002
Batch 3/64 loss: -3.977123260498047
Batch 4/64 loss: -4.077431678771973
Batch 5/64 loss: -4.084469318389893
Batch 6/64 loss: -4.044867038726807
Batch 7/64 loss: -3.904338836669922
Batch 8/64 loss: -3.831332206726074
Batch 9/64 loss: -3.944936752319336
Batch 10/64 loss: -4.073413848876953
Batch 11/64 loss: -4.150362491607666
Batch 12/64 loss: -4.0046067237854
Batch 13/64 loss: -4.092684745788574
Batch 14/64 loss: -4.133936405181885
Batch 15/64 loss: -4.0787553787231445
Batch 16/64 loss: -3.9573750495910645
Batch 17/64 loss: -4.101285934448242
Batch 18/64 loss: -3.495467185974121
Batch 19/64 loss: -3.9801597595214844
Batch 20/64 loss: -3.9520363807678223
Batch 21/64 loss: -4.0517168045043945
Batch 22/64 loss: -4.06492805480957
Batch 23/64 loss: -4.108340263366699
Batch 24/64 loss: -3.7113022804260254
Batch 25/64 loss: -4.041789531707764
Batch 26/64 loss: -4.066102504730225
Batch 27/64 loss: -4.189603328704834
Batch 28/64 loss: -4.031864643096924
Batch 29/64 loss: -4.237921714782715
Batch 30/64 loss: -4.074260711669922
Batch 31/64 loss: -4.065582752227783
Batch 32/64 loss: -4.067518711090088
Batch 33/64 loss: -3.9736480712890625
Batch 34/64 loss: -4.160562038421631
Batch 35/64 loss: -4.038972854614258
Batch 36/64 loss: -3.9629616737365723
Batch 37/64 loss: -4.01514196395874
Batch 38/64 loss: -3.836930274963379
Batch 39/64 loss: -3.734175682067871
Batch 40/64 loss: -3.9607887268066406
Batch 41/64 loss: -4.139190673828125
Batch 42/64 loss: -4.1775994300842285
Batch 43/64 loss: -3.9361443519592285
Batch 44/64 loss: -4.299261093139648
Batch 45/64 loss: -4.113253593444824
Batch 46/64 loss: -4.008233547210693
Batch 47/64 loss: -4.049226760864258
Batch 48/64 loss: -4.07345724105835
Batch 49/64 loss: -4.111669063568115
Batch 50/64 loss: -3.974266529083252
Batch 51/64 loss: -3.7437047958374023
Batch 52/64 loss: -4.0000529289245605
Batch 53/64 loss: -4.0415940284729
Batch 54/64 loss: -4.044621467590332
Batch 55/64 loss: -4.011375904083252
Batch 56/64 loss: -3.9375367164611816
Batch 57/64 loss: -4.004113674163818
Batch 58/64 loss: -3.5505576133728027
Batch 59/64 loss: -4.028907775878906
Batch 60/64 loss: -4.092639446258545
Batch 61/64 loss: -3.9742674827575684
Batch 62/64 loss: -4.084206581115723
Batch 63/64 loss: -3.9350976943969727
Batch 64/64 loss: -8.62636947631836
Epoch 357  Train loss: -4.070381575939702  Val loss: -4.406096533811379
Epoch 358
-------------------------------
Batch 1/64 loss: -4.132519245147705
Batch 2/64 loss: -4.028015613555908
Batch 3/64 loss: -3.934648036956787
Batch 4/64 loss: -4.035471439361572
Batch 5/64 loss: -3.814260482788086
Batch 6/64 loss: -3.9958291053771973
Batch 7/64 loss: -3.8365392684936523
Batch 8/64 loss: -4.097724437713623
Batch 9/64 loss: -4.132859706878662
Batch 10/64 loss: -3.906546115875244
Batch 11/64 loss: -4.03959321975708
Batch 12/64 loss: -4.118636608123779
Batch 13/64 loss: -4.123485565185547
Batch 14/64 loss: -4.035259246826172
Batch 15/64 loss: -3.967289924621582
Batch 16/64 loss: -4.073732376098633
Batch 17/64 loss: -3.826352596282959
Batch 18/64 loss: -3.950674533843994
Batch 19/64 loss: -3.86928129196167
Batch 20/64 loss: -3.862198829650879
Batch 21/64 loss: -3.9548850059509277
Batch 22/64 loss: -4.079883098602295
Batch 23/64 loss: -4.193925857543945
Batch 24/64 loss: -3.8601861000061035
Batch 25/64 loss: -3.910749912261963
Batch 26/64 loss: -4.078032970428467
Batch 27/64 loss: -3.6964340209960938
Batch 28/64 loss: -4.098021030426025
Batch 29/64 loss: -3.954704761505127
Batch 30/64 loss: -4.003471851348877
Batch 31/64 loss: -3.9751477241516113
Batch 32/64 loss: -3.9334020614624023
Batch 33/64 loss: -4.195723056793213
Batch 34/64 loss: -3.924710750579834
Batch 35/64 loss: -4.1248779296875
Batch 36/64 loss: -3.913003921508789
Batch 37/64 loss: -3.97220516204834
Batch 38/64 loss: -4.159793853759766
Batch 39/64 loss: -3.9591994285583496
Batch 40/64 loss: -3.9244723320007324
Batch 41/64 loss: -3.7037863731384277
Batch 42/64 loss: -3.9803028106689453
Batch 43/64 loss: -3.970120429992676
Batch 44/64 loss: -4.002528190612793
Batch 45/64 loss: -4.011745929718018
Batch 46/64 loss: -3.789200782775879
Batch 47/64 loss: -4.107041835784912
Batch 48/64 loss: -3.755087375640869
Batch 49/64 loss: -4.072364807128906
Batch 50/64 loss: -4.09487771987915
Batch 51/64 loss: -4.014807224273682
Batch 52/64 loss: -4.257999420166016
Batch 53/64 loss: -4.0741047859191895
Batch 54/64 loss: -3.99977445602417
Batch 55/64 loss: -4.188583850860596
Batch 56/64 loss: -4.150547981262207
Batch 57/64 loss: -3.9660563468933105
Batch 58/64 loss: -4.151106834411621
Batch 59/64 loss: -4.110052585601807
Batch 60/64 loss: -4.08876895904541
Batch 61/64 loss: -3.7423830032348633
Batch 62/64 loss: -4.0017523765563965
Batch 63/64 loss: -3.7687864303588867
Batch 64/64 loss: -8.31457805633545
Epoch 358  Train loss: -4.045983725903081  Val loss: -4.344614454970737
Epoch 359
-------------------------------
Batch 1/64 loss: -3.8985037803649902
Batch 2/64 loss: -3.780066967010498
Batch 3/64 loss: -3.947765350341797
Batch 4/64 loss: -4.071624279022217
Batch 5/64 loss: -4.040635108947754
Batch 6/64 loss: -3.844202995300293
Batch 7/64 loss: -3.982546806335449
Batch 8/64 loss: -3.9869813919067383
Batch 9/64 loss: -4.027681827545166
Batch 10/64 loss: -4.03294563293457
Batch 11/64 loss: -4.007532596588135
Batch 12/64 loss: -3.9172353744506836
Batch 13/64 loss: -3.8467001914978027
Batch 14/64 loss: -3.984435558319092
Batch 15/64 loss: -3.8836092948913574
Batch 16/64 loss: -3.986786365509033
Batch 17/64 loss: -3.987766742706299
Batch 18/64 loss: -3.955202579498291
Batch 19/64 loss: -3.764110565185547
Batch 20/64 loss: -3.916538715362549
Batch 21/64 loss: -3.4495697021484375
Batch 22/64 loss: -3.8360977172851562
Batch 23/64 loss: -3.9385924339294434
Batch 24/64 loss: -3.9272570610046387
Batch 25/64 loss: -4.114279270172119
Batch 26/64 loss: -4.124118804931641
Batch 27/64 loss: -4.01706075668335
Batch 28/64 loss: -3.8977017402648926
Batch 29/64 loss: -4.127875804901123
Batch 30/64 loss: -3.629542350769043
Batch 31/64 loss: -3.816943645477295
Batch 32/64 loss: -4.031376838684082
Batch 33/64 loss: -3.8227791786193848
Batch 34/64 loss: -3.973282814025879
Batch 35/64 loss: -3.995133399963379
Batch 36/64 loss: -4.115213394165039
Batch 37/64 loss: -4.0331549644470215
Batch 38/64 loss: -4.065334796905518
Batch 39/64 loss: -3.6375041007995605
Batch 40/64 loss: -3.8655905723571777
Batch 41/64 loss: -3.9190988540649414
Batch 42/64 loss: -4.03083610534668
Batch 43/64 loss: -3.86643648147583
Batch 44/64 loss: -4.014611721038818
Batch 45/64 loss: -4.07579231262207
Batch 46/64 loss: -3.9915428161621094
Batch 47/64 loss: -4.1239728927612305
Batch 48/64 loss: -4.041083335876465
Batch 49/64 loss: -4.022735595703125
Batch 50/64 loss: -4.075621128082275
Batch 51/64 loss: -3.9031448364257812
Batch 52/64 loss: -4.037985324859619
Batch 53/64 loss: -3.97965145111084
Batch 54/64 loss: -4.082814693450928
Batch 55/64 loss: -4.136597633361816
Batch 56/64 loss: -3.983595848083496
Batch 57/64 loss: -3.869785785675049
Batch 58/64 loss: -4.0902485847473145
Batch 59/64 loss: -4.040675163269043
Batch 60/64 loss: -3.889155387878418
Batch 61/64 loss: -3.9742813110351562
Batch 62/64 loss: -3.6923394203186035
Batch 63/64 loss: -4.088622093200684
Batch 64/64 loss: -8.202836036682129
Epoch 359  Train loss: -4.005710388632382  Val loss: -4.342448100191621
Epoch 360
-------------------------------
Batch 1/64 loss: -4.091414451599121
Batch 2/64 loss: -3.9606237411499023
Batch 3/64 loss: -3.8235230445861816
Batch 4/64 loss: -4.020295143127441
Batch 5/64 loss: -3.8574843406677246
Batch 6/64 loss: -3.954129219055176
Batch 7/64 loss: -3.8491458892822266
Batch 8/64 loss: -3.9106526374816895
Batch 9/64 loss: -3.965792655944824
Batch 10/64 loss: -4.099983215332031
Batch 11/64 loss: -4.005102157592773
Batch 12/64 loss: -3.93392276763916
Batch 13/64 loss: -3.7343978881835938
Batch 14/64 loss: -3.9405593872070312
Batch 15/64 loss: -4.089261054992676
Batch 16/64 loss: -4.027799129486084
Batch 17/64 loss: -3.884359359741211
Batch 18/64 loss: -3.9894914627075195
Batch 19/64 loss: -3.7406845092773438
Batch 20/64 loss: -4.1149821281433105
Batch 21/64 loss: -3.7931394577026367
Batch 22/64 loss: -3.844137191772461
Batch 23/64 loss: -4.098759651184082
Batch 24/64 loss: -3.943620204925537
Batch 25/64 loss: -3.9899253845214844
Batch 26/64 loss: -3.9480576515197754
Batch 27/64 loss: -4.018029689788818
Batch 28/64 loss: -3.7998242378234863
Batch 29/64 loss: -3.853280544281006
Batch 30/64 loss: -3.393439292907715
Batch 31/64 loss: -3.894649028778076
Batch 32/64 loss: -3.846052646636963
Batch 33/64 loss: -3.7289857864379883
Batch 34/64 loss: -3.4968905448913574
Batch 35/64 loss: -3.9764437675476074
Batch 36/64 loss: -3.9746060371398926
Batch 37/64 loss: -3.9533467292785645
Batch 38/64 loss: -3.7730369567871094
Batch 39/64 loss: -3.9061126708984375
Batch 40/64 loss: -3.7075672149658203
Batch 41/64 loss: -3.906352996826172
Batch 42/64 loss: -3.7568745613098145
Batch 43/64 loss: -3.8299312591552734
Batch 44/64 loss: -3.972255229949951
Batch 45/64 loss: -3.9750328063964844
Batch 46/64 loss: -3.8919525146484375
Batch 47/64 loss: -3.732056140899658
Batch 48/64 loss: -4.071240425109863
Batch 49/64 loss: -3.8825020790100098
Batch 50/64 loss: -3.728508949279785
Batch 51/64 loss: -3.590693473815918
Batch 52/64 loss: -3.494351863861084
Batch 53/64 loss: -3.763408660888672
Batch 54/64 loss: -3.775613307952881
Batch 55/64 loss: -3.7015886306762695
Batch 56/64 loss: -3.9384069442749023
Batch 57/64 loss: -3.8657398223876953
Batch 58/64 loss: -3.3344898223876953
Batch 59/64 loss: -4.055941581726074
Batch 60/64 loss: -3.484273910522461
Batch 61/64 loss: -3.8920044898986816
Batch 62/64 loss: -3.9887843132019043
Batch 63/64 loss: -3.9829182624816895
Batch 64/64 loss: -8.480920791625977
Epoch 360  Train loss: -3.920143082562615  Val loss: -4.190203296359872
Epoch 361
-------------------------------
Batch 1/64 loss: -3.9399452209472656
Batch 2/64 loss: -3.6493210792541504
Batch 3/64 loss: -4.064458847045898
Batch 4/64 loss: -3.9491281509399414
Batch 5/64 loss: -3.851747989654541
Batch 6/64 loss: -4.0392608642578125
Batch 7/64 loss: -3.911130905151367
Batch 8/64 loss: -4.071962833404541
Batch 9/64 loss: -3.9084997177124023
Batch 10/64 loss: -3.6571106910705566
Batch 11/64 loss: -3.9401111602783203
Batch 12/64 loss: -4.120396137237549
Batch 13/64 loss: -3.8352251052856445
Batch 14/64 loss: -3.805065631866455
Batch 15/64 loss: -3.9060163497924805
Batch 16/64 loss: -3.6647186279296875
Batch 17/64 loss: -3.977628707885742
Batch 18/64 loss: -3.8402647972106934
Batch 19/64 loss: -3.998863697052002
Batch 20/64 loss: -3.6488523483276367
Batch 21/64 loss: -3.8356471061706543
Batch 22/64 loss: -3.568329334259033
Batch 23/64 loss: -3.8124165534973145
Batch 24/64 loss: -4.019073963165283
Batch 25/64 loss: -4.007847309112549
Batch 26/64 loss: -4.038372993469238
Batch 27/64 loss: -3.978022575378418
Batch 28/64 loss: -3.882964611053467
Batch 29/64 loss: -3.9707069396972656
Batch 30/64 loss: -3.892284393310547
Batch 31/64 loss: -4.102311134338379
Batch 32/64 loss: -3.9894118309020996
Batch 33/64 loss: -3.685391426086426
Batch 34/64 loss: -3.7404627799987793
Batch 35/64 loss: -3.863503932952881
Batch 36/64 loss: -4.110113620758057
Batch 37/64 loss: -3.9111509323120117
Batch 38/64 loss: -3.976316452026367
Batch 39/64 loss: -4.001840114593506
Batch 40/64 loss: -4.011424541473389
Batch 41/64 loss: -3.8826961517333984
Batch 42/64 loss: -4.0715250968933105
Batch 43/64 loss: -3.9272093772888184
Batch 44/64 loss: -3.8408279418945312
Batch 45/64 loss: -4.007797718048096
Batch 46/64 loss: -4.072748184204102
Batch 47/64 loss: -4.0351386070251465
Batch 48/64 loss: -3.6883745193481445
Batch 49/64 loss: -3.891355037689209
Batch 50/64 loss: -4.055630683898926
Batch 51/64 loss: -4.090969562530518
Batch 52/64 loss: -3.649282455444336
Batch 53/64 loss: -3.7437758445739746
Batch 54/64 loss: -3.987443447113037
Batch 55/64 loss: -4.0216779708862305
Batch 56/64 loss: -3.9247093200683594
Batch 57/64 loss: -4.1101484298706055
Batch 58/64 loss: -4.150081157684326
Batch 59/64 loss: -4.104554176330566
Batch 60/64 loss: -4.174076557159424
Batch 61/64 loss: -4.066895484924316
Batch 62/64 loss: -4.045315742492676
Batch 63/64 loss: -3.979034423828125
Batch 64/64 loss: -8.507406234741211
Epoch 361  Train loss: -3.985554885864258  Val loss: -4.365281960398881
Epoch 362
-------------------------------
Batch 1/64 loss: -4.1857476234436035
Batch 2/64 loss: -3.9578661918640137
Batch 3/64 loss: -3.991178035736084
Batch 4/64 loss: -4.0045976638793945
Batch 5/64 loss: -4.1304097175598145
Batch 6/64 loss: -3.6890740394592285
Batch 7/64 loss: -4.12337064743042
Batch 8/64 loss: -3.8971471786499023
Batch 9/64 loss: -3.757567882537842
Batch 10/64 loss: -4.158696174621582
Batch 11/64 loss: -4.093818664550781
Batch 12/64 loss: -4.127127170562744
Batch 13/64 loss: -3.9565954208374023
Batch 14/64 loss: -4.056288719177246
Batch 15/64 loss: -3.9944658279418945
Batch 16/64 loss: -3.9803876876831055
Batch 17/64 loss: -4.155674934387207
Batch 18/64 loss: -4.113641738891602
Batch 19/64 loss: -4.194882392883301
Batch 20/64 loss: -3.9484987258911133
Batch 21/64 loss: -4.181423187255859
Batch 22/64 loss: -3.8525443077087402
Batch 23/64 loss: -4.08659553527832
Batch 24/64 loss: -3.962066173553467
Batch 25/64 loss: -4.185593128204346
Batch 26/64 loss: -3.917762279510498
Batch 27/64 loss: -4.082465648651123
Batch 28/64 loss: -3.9196977615356445
Batch 29/64 loss: -3.9024477005004883
Batch 30/64 loss: -3.6694183349609375
Batch 31/64 loss: -4.051703929901123
Batch 32/64 loss: -3.935582160949707
Batch 33/64 loss: -4.083364009857178
Batch 34/64 loss: -4.121112823486328
Batch 35/64 loss: -4.095270156860352
Batch 36/64 loss: -4.041172981262207
Batch 37/64 loss: -3.931147575378418
Batch 38/64 loss: -4.1955060958862305
Batch 39/64 loss: -4.140472888946533
Batch 40/64 loss: -4.163642406463623
Batch 41/64 loss: -4.2169389724731445
Batch 42/64 loss: -3.7960100173950195
Batch 43/64 loss: -4.03821325302124
Batch 44/64 loss: -4.011139869689941
Batch 45/64 loss: -4.076432704925537
Batch 46/64 loss: -4.178496360778809
Batch 47/64 loss: -3.7678937911987305
Batch 48/64 loss: -4.052859783172607
Batch 49/64 loss: -4.026638507843018
Batch 50/64 loss: -4.0604376792907715
Batch 51/64 loss: -4.063789367675781
Batch 52/64 loss: -3.985778331756592
Batch 53/64 loss: -4.001778602600098
Batch 54/64 loss: -4.1666998863220215
Batch 55/64 loss: -4.176337718963623
Batch 56/64 loss: -4.053762912750244
Batch 57/64 loss: -4.079765319824219
Batch 58/64 loss: -4.077866077423096
Batch 59/64 loss: -4.025365829467773
Batch 60/64 loss: -4.022744178771973
Batch 61/64 loss: -4.004724502563477
Batch 62/64 loss: -4.057710647583008
Batch 63/64 loss: -4.132201194763184
Batch 64/64 loss: -8.627824783325195
Epoch 362  Train loss: -4.087536935245289  Val loss: -4.362909284244289
Epoch 363
-------------------------------
Batch 1/64 loss: -4.016191005706787
Batch 2/64 loss: -3.8835787773132324
Batch 3/64 loss: -4.063015460968018
Batch 4/64 loss: -3.9488611221313477
Batch 5/64 loss: -3.6108031272888184
Batch 6/64 loss: -3.946840763092041
Batch 7/64 loss: -4.0389533042907715
Batch 8/64 loss: -3.942241668701172
Batch 9/64 loss: -3.936760425567627
Batch 10/64 loss: -4.102353096008301
Batch 11/64 loss: -4.133696556091309
Batch 12/64 loss: -4.134543418884277
Batch 13/64 loss: -4.12777042388916
Batch 14/64 loss: -4.029067516326904
Batch 15/64 loss: -3.790714740753174
Batch 16/64 loss: -4.220423221588135
Batch 17/64 loss: -3.6948070526123047
Batch 18/64 loss: -4.079462051391602
Batch 19/64 loss: -3.8535189628601074
Batch 20/64 loss: -4.062132835388184
Batch 21/64 loss: -3.930356502532959
Batch 22/64 loss: -3.8322701454162598
Batch 23/64 loss: -3.8089356422424316
Batch 24/64 loss: -4.18400239944458
Batch 25/64 loss: -4.032597541809082
Batch 26/64 loss: -4.017038822174072
Batch 27/64 loss: -3.7064132690429688
Batch 28/64 loss: -3.9268975257873535
Batch 29/64 loss: -4.180086135864258
Batch 30/64 loss: -4.00935173034668
Batch 31/64 loss: -4.12544059753418
Batch 32/64 loss: -3.9735283851623535
Batch 33/64 loss: -4.080824851989746
Batch 34/64 loss: -4.043426513671875
Batch 35/64 loss: -4.155698299407959
Batch 36/64 loss: -4.04811954498291
Batch 37/64 loss: -3.9191908836364746
Batch 38/64 loss: -4.157302379608154
Batch 39/64 loss: -4.059850692749023
Batch 40/64 loss: -4.118779182434082
Batch 41/64 loss: -4.0375895500183105
Batch 42/64 loss: -4.0215959548950195
Batch 43/64 loss: -3.794437885284424
Batch 44/64 loss: -3.9910855293273926
Batch 45/64 loss: -4.084673881530762
Batch 46/64 loss: -3.8204174041748047
Batch 47/64 loss: -3.9753479957580566
Batch 48/64 loss: -3.8837718963623047
Batch 49/64 loss: -3.995260238647461
Batch 50/64 loss: -4.108511447906494
Batch 51/64 loss: -4.065909385681152
Batch 52/64 loss: -4.020577430725098
Batch 53/64 loss: -4.178005695343018
Batch 54/64 loss: -3.9521565437316895
Batch 55/64 loss: -3.972869873046875
Batch 56/64 loss: -3.8582301139831543
Batch 57/64 loss: -3.573345184326172
Batch 58/64 loss: -3.937199592590332
Batch 59/64 loss: -4.112399578094482
Batch 60/64 loss: -3.8858284950256348
Batch 61/64 loss: -3.8664588928222656
Batch 62/64 loss: -4.096939563751221
Batch 63/64 loss: -3.840371608734131
Batch 64/64 loss: -8.61231517791748
Epoch 363  Train loss: -4.038557909049239  Val loss: -4.266992300236757
Epoch 364
-------------------------------
Batch 1/64 loss: -3.759082794189453
Batch 2/64 loss: -4.053414344787598
Batch 3/64 loss: -4.058570861816406
Batch 4/64 loss: -4.041494846343994
Batch 5/64 loss: -3.8273134231567383
Batch 6/64 loss: -3.9116578102111816
Batch 7/64 loss: -4.0133185386657715
Batch 8/64 loss: -3.995830535888672
Batch 9/64 loss: -3.7448301315307617
Batch 10/64 loss: -3.7248311042785645
Batch 11/64 loss: -3.9494667053222656
Batch 12/64 loss: -3.90958833694458
Batch 13/64 loss: -3.9734115600585938
Batch 14/64 loss: -3.7560925483703613
Batch 15/64 loss: -3.8388924598693848
Batch 16/64 loss: -3.9954495429992676
Batch 17/64 loss: -3.8629188537597656
Batch 18/64 loss: -4.02274751663208
Batch 19/64 loss: -3.8048171997070312
Batch 20/64 loss: -4.00654411315918
Batch 21/64 loss: -3.997870922088623
Batch 22/64 loss: -3.3322057723999023
Batch 23/64 loss: -3.9682459831237793
Batch 24/64 loss: -4.124678611755371
Batch 25/64 loss: -3.975691318511963
Batch 26/64 loss: -4.134401798248291
Batch 27/64 loss: -3.831596851348877
Batch 28/64 loss: -4.115067005157471
Batch 29/64 loss: -4.099302291870117
Batch 30/64 loss: -4.009521484375
Batch 31/64 loss: -4.027507305145264
Batch 32/64 loss: -4.101446151733398
Batch 33/64 loss: -3.8194785118103027
Batch 34/64 loss: -3.968468189239502
Batch 35/64 loss: -4.023246765136719
Batch 36/64 loss: -4.176333904266357
Batch 37/64 loss: -3.983635425567627
Batch 38/64 loss: -4.070936679840088
Batch 39/64 loss: -4.092167854309082
Batch 40/64 loss: -3.8605799674987793
Batch 41/64 loss: -3.9131827354431152
Batch 42/64 loss: -3.877192497253418
Batch 43/64 loss: -4.149999141693115
Batch 44/64 loss: -4.051628589630127
Batch 45/64 loss: -4.022599697113037
Batch 46/64 loss: -3.894911766052246
Batch 47/64 loss: -4.0712571144104
Batch 48/64 loss: -3.858458995819092
Batch 49/64 loss: -4.001786231994629
Batch 50/64 loss: -3.8808178901672363
Batch 51/64 loss: -4.014709949493408
Batch 52/64 loss: -4.072474479675293
Batch 53/64 loss: -3.7708144187927246
Batch 54/64 loss: -3.9927234649658203
Batch 55/64 loss: -4.0692315101623535
Batch 56/64 loss: -4.0087175369262695
Batch 57/64 loss: -4.059458255767822
Batch 58/64 loss: -3.9704794883728027
Batch 59/64 loss: -3.948361873626709
Batch 60/64 loss: -4.037563800811768
Batch 61/64 loss: -3.986599922180176
Batch 62/64 loss: -4.030274391174316
Batch 63/64 loss: -3.6652708053588867
Batch 64/64 loss: -8.577783584594727
Epoch 364  Train loss: -4.011678561042337  Val loss: -4.424717500037754
Epoch 365
-------------------------------
Batch 1/64 loss: -4.151874542236328
Batch 2/64 loss: -4.120998382568359
Batch 3/64 loss: -3.8464913368225098
Batch 4/64 loss: -4.102138042449951
Batch 5/64 loss: -3.9828968048095703
Batch 6/64 loss: -4.093714714050293
Batch 7/64 loss: -4.087552070617676
Batch 8/64 loss: -4.042088031768799
Batch 9/64 loss: -3.973649501800537
Batch 10/64 loss: -4.1750617027282715
Batch 11/64 loss: -3.9043326377868652
Batch 12/64 loss: -4.120200157165527
Batch 13/64 loss: -4.04032564163208
Batch 14/64 loss: -3.9194679260253906
Batch 15/64 loss: -3.9121413230895996
Batch 16/64 loss: -4.099674701690674
Batch 17/64 loss: -3.9992575645446777
Batch 18/64 loss: -3.8454036712646484
Batch 19/64 loss: -3.9907732009887695
Batch 20/64 loss: -3.8900208473205566
Batch 21/64 loss: -4.090649127960205
Batch 22/64 loss: -3.868277072906494
Batch 23/64 loss: -4.204068183898926
Batch 24/64 loss: -4.11354923248291
Batch 25/64 loss: -4.159230709075928
Batch 26/64 loss: -4.1348161697387695
Batch 27/64 loss: -3.3050899505615234
Batch 28/64 loss: -4.033535003662109
Batch 29/64 loss: -4.093875885009766
Batch 30/64 loss: -4.080677509307861
Batch 31/64 loss: -3.80159854888916
Batch 32/64 loss: -4.1944098472595215
Batch 33/64 loss: -4.074184894561768
Batch 34/64 loss: -4.0623459815979
Batch 35/64 loss: -4.070323467254639
Batch 36/64 loss: -4.0545268058776855
Batch 37/64 loss: -3.955516815185547
Batch 38/64 loss: -3.9484968185424805
Batch 39/64 loss: -3.752603530883789
Batch 40/64 loss: -4.025618553161621
Batch 41/64 loss: -3.9521141052246094
Batch 42/64 loss: -4.018933296203613
Batch 43/64 loss: -4.055960178375244
Batch 44/64 loss: -4.076745510101318
Batch 45/64 loss: -4.2267537117004395
Batch 46/64 loss: -3.9190597534179688
Batch 47/64 loss: -4.021925449371338
Batch 48/64 loss: -4.03685998916626
Batch 49/64 loss: -3.8119397163391113
Batch 50/64 loss: -4.205179214477539
Batch 51/64 loss: -3.9912195205688477
Batch 52/64 loss: -3.649305820465088
Batch 53/64 loss: -3.879685878753662
Batch 54/64 loss: -4.058872222900391
Batch 55/64 loss: -3.8028459548950195
Batch 56/64 loss: -3.8464412689208984
Batch 57/64 loss: -4.125248432159424
Batch 58/64 loss: -3.7127561569213867
Batch 59/64 loss: -4.179434299468994
Batch 60/64 loss: -3.994058132171631
Batch 61/64 loss: -3.9805312156677246
Batch 62/64 loss: -3.9824910163879395
Batch 63/64 loss: -3.7526421546936035
Batch 64/64 loss: -8.493906021118164
Epoch 365  Train loss: -4.04663355958228  Val loss: -4.147856761499779
Epoch 366
-------------------------------
Batch 1/64 loss: -4.039536476135254
Batch 2/64 loss: -3.9378795623779297
Batch 3/64 loss: -3.947122097015381
Batch 4/64 loss: -3.8914170265197754
Batch 5/64 loss: -3.6932106018066406
Batch 6/64 loss: -4.0488200187683105
Batch 7/64 loss: -4.1522369384765625
Batch 8/64 loss: -3.9256606101989746
Batch 9/64 loss: -3.83151912689209
Batch 10/64 loss: -4.072604179382324
Batch 11/64 loss: -3.7302112579345703
Batch 12/64 loss: -3.989777088165283
Batch 13/64 loss: -4.074613571166992
Batch 14/64 loss: -3.9129128456115723
Batch 15/64 loss: -4.009139537811279
Batch 16/64 loss: -4.045130252838135
Batch 17/64 loss: -4.009466648101807
Batch 18/64 loss: -3.8822569847106934
Batch 19/64 loss: -4.100958347320557
Batch 20/64 loss: -3.842149257659912
Batch 21/64 loss: -4.1492390632629395
Batch 22/64 loss: -3.7514853477478027
Batch 23/64 loss: -3.897918224334717
Batch 24/64 loss: -3.9242167472839355
Batch 25/64 loss: -4.0687055587768555
Batch 26/64 loss: -4.083189487457275
Batch 27/64 loss: -4.126771926879883
Batch 28/64 loss: -4.143251895904541
Batch 29/64 loss: -4.034984588623047
Batch 30/64 loss: -3.9909791946411133
Batch 31/64 loss: -4.005787372589111
Batch 32/64 loss: -4.0637335777282715
Batch 33/64 loss: -3.9588804244995117
Batch 34/64 loss: -4.0353193283081055
Batch 35/64 loss: -4.007758140563965
Batch 36/64 loss: -4.1894211769104
Batch 37/64 loss: -4.023332595825195
Batch 38/64 loss: -3.8253283500671387
Batch 39/64 loss: -3.579857349395752
Batch 40/64 loss: -3.938601493835449
Batch 41/64 loss: -4.00192403793335
Batch 42/64 loss: -3.6200785636901855
Batch 43/64 loss: -3.6727418899536133
Batch 44/64 loss: -4.092000484466553
Batch 45/64 loss: -3.9434494972229004
Batch 46/64 loss: -4.003132343292236
Batch 47/64 loss: -3.995716094970703
Batch 48/64 loss: -3.8548569679260254
Batch 49/64 loss: -3.9644336700439453
Batch 50/64 loss: -3.8943257331848145
Batch 51/64 loss: -4.139038562774658
Batch 52/64 loss: -4.07857608795166
Batch 53/64 loss: -4.06538724899292
Batch 54/64 loss: -4.035606861114502
Batch 55/64 loss: -4.202260971069336
Batch 56/64 loss: -4.091922283172607
Batch 57/64 loss: -3.8274388313293457
Batch 58/64 loss: -4.017423629760742
Batch 59/64 loss: -3.8887715339660645
Batch 60/64 loss: -4.02409553527832
Batch 61/64 loss: -4.075926303863525
Batch 62/64 loss: -3.935546875
Batch 63/64 loss: -4.168736934661865
Batch 64/64 loss: -8.410720825195312
Epoch 366  Train loss: -4.028812797396791  Val loss: -4.434712531230704
Epoch 367
-------------------------------
Batch 1/64 loss: -3.8312363624572754
Batch 2/64 loss: -4.254830837249756
Batch 3/64 loss: -4.162032127380371
Batch 4/64 loss: -3.9844250679016113
Batch 5/64 loss: -4.0503315925598145
Batch 6/64 loss: -3.973139762878418
Batch 7/64 loss: -3.9723305702209473
Batch 8/64 loss: -4.12814474105835
Batch 9/64 loss: -4.132976531982422
Batch 10/64 loss: -4.160471439361572
Batch 11/64 loss: -4.109407424926758
Batch 12/64 loss: -4.064789772033691
Batch 13/64 loss: -4.075582504272461
Batch 14/64 loss: -3.973356246948242
Batch 15/64 loss: -3.995049476623535
Batch 16/64 loss: -3.904771327972412
Batch 17/64 loss: -3.9161887168884277
Batch 18/64 loss: -4.0961785316467285
Batch 19/64 loss: -4.02350378036499
Batch 20/64 loss: -4.120181560516357
Batch 21/64 loss: -3.897815704345703
Batch 22/64 loss: -3.9891715049743652
Batch 23/64 loss: -3.991610050201416
Batch 24/64 loss: -3.9000186920166016
Batch 25/64 loss: -3.9539971351623535
Batch 26/64 loss: -4.061186790466309
Batch 27/64 loss: -3.965327262878418
Batch 28/64 loss: -3.8840713500976562
Batch 29/64 loss: -3.9239425659179688
Batch 30/64 loss: -3.9929871559143066
Batch 31/64 loss: -4.127573013305664
Batch 32/64 loss: -3.921614170074463
Batch 33/64 loss: -4.0846734046936035
Batch 34/64 loss: -4.069188117980957
Batch 35/64 loss: -4.173140048980713
Batch 36/64 loss: -3.5263147354125977
Batch 37/64 loss: -3.995173454284668
Batch 38/64 loss: -4.018571376800537
Batch 39/64 loss: -4.06248140335083
Batch 40/64 loss: -4.060712814331055
Batch 41/64 loss: -3.7467994689941406
Batch 42/64 loss: -3.963648796081543
Batch 43/64 loss: -4.062551021575928
Batch 44/64 loss: -4.0315752029418945
Batch 45/64 loss: -4.00567626953125
Batch 46/64 loss: -4.037625312805176
Batch 47/64 loss: -4.009667873382568
Batch 48/64 loss: -3.8486971855163574
Batch 49/64 loss: -3.4106712341308594
Batch 50/64 loss: -3.8334174156188965
Batch 51/64 loss: -4.0705718994140625
Batch 52/64 loss: -3.885150909423828
Batch 53/64 loss: -3.961606502532959
Batch 54/64 loss: -3.995612144470215
Batch 55/64 loss: -4.114577293395996
Batch 56/64 loss: -3.373353958129883
Batch 57/64 loss: -4.041628360748291
Batch 58/64 loss: -3.6230902671813965
Batch 59/64 loss: -3.91825532913208
Batch 60/64 loss: -3.9091391563415527
Batch 61/64 loss: -4.023169040679932
Batch 62/64 loss: -3.955051898956299
Batch 63/64 loss: -3.688007354736328
Batch 64/64 loss: -8.445929527282715
Epoch 367  Train loss: -4.02152925753126  Val loss: -4.366861677661385
Epoch 368
-------------------------------
Batch 1/64 loss: -4.181056499481201
Batch 2/64 loss: -3.941194534301758
Batch 3/64 loss: -3.7591376304626465
Batch 4/64 loss: -3.7046217918395996
Batch 5/64 loss: -4.074459552764893
Batch 6/64 loss: -3.9633216857910156
Batch 7/64 loss: -4.1140522956848145
Batch 8/64 loss: -4.135152816772461
Batch 9/64 loss: -4.015224456787109
Batch 10/64 loss: -3.686710834503174
Batch 11/64 loss: -4.071519374847412
Batch 12/64 loss: -4.041195392608643
Batch 13/64 loss: -4.051083564758301
Batch 14/64 loss: -3.921293258666992
Batch 15/64 loss: -4.070804119110107
Batch 16/64 loss: -3.983431339263916
Batch 17/64 loss: -4.096282482147217
Batch 18/64 loss: -3.696066379547119
Batch 19/64 loss: -3.6644411087036133
Batch 20/64 loss: -4.110764980316162
Batch 21/64 loss: -4.025844573974609
Batch 22/64 loss: -4.043046951293945
Batch 23/64 loss: -4.050180435180664
Batch 24/64 loss: -3.649860382080078
Batch 25/64 loss: -4.206125736236572
Batch 26/64 loss: -4.126464366912842
Batch 27/64 loss: -4.107034206390381
Batch 28/64 loss: -3.808234214782715
Batch 29/64 loss: -4.136687278747559
Batch 30/64 loss: -3.9742560386657715
Batch 31/64 loss: -3.8925561904907227
Batch 32/64 loss: -4.225309371948242
Batch 33/64 loss: -3.9699301719665527
Batch 34/64 loss: -4.091064453125
Batch 35/64 loss: -4.020692825317383
Batch 36/64 loss: -4.059772968292236
Batch 37/64 loss: -3.97403621673584
Batch 38/64 loss: -3.88836669921875
Batch 39/64 loss: -3.931908130645752
Batch 40/64 loss: -3.731595993041992
Batch 41/64 loss: -4.056361198425293
Batch 42/64 loss: -4.016304969787598
Batch 43/64 loss: -4.081181526184082
Batch 44/64 loss: -3.9070825576782227
Batch 45/64 loss: -3.7309188842773438
Batch 46/64 loss: -4.1338067054748535
Batch 47/64 loss: -4.088733673095703
Batch 48/64 loss: -4.1040167808532715
Batch 49/64 loss: -4.046204090118408
Batch 50/64 loss: -3.907343864440918
Batch 51/64 loss: -3.9622182846069336
Batch 52/64 loss: -4.092034816741943
Batch 53/64 loss: -4.082115173339844
Batch 54/64 loss: -4.077999591827393
Batch 55/64 loss: -4.164889335632324
Batch 56/64 loss: -4.1048431396484375
Batch 57/64 loss: -4.11065149307251
Batch 58/64 loss: -3.8665103912353516
Batch 59/64 loss: -4.109500408172607
Batch 60/64 loss: -4.058195114135742
Batch 61/64 loss: -3.983973979949951
Batch 62/64 loss: -3.8740339279174805
Batch 63/64 loss: -3.997620105743408
Batch 64/64 loss: -8.574056625366211
Epoch 368  Train loss: -4.04991158878102  Val loss: -4.477772099865261
Saving best model, epoch: 368
Epoch 369
-------------------------------
Batch 1/64 loss: -3.9804563522338867
Batch 2/64 loss: -3.9243569374084473
Batch 3/64 loss: -4.1022796630859375
Batch 4/64 loss: -3.9542088508605957
Batch 5/64 loss: -4.022846698760986
Batch 6/64 loss: -4.0673441886901855
Batch 7/64 loss: -3.989314079284668
Batch 8/64 loss: -4.164521217346191
Batch 9/64 loss: -3.979043483734131
Batch 10/64 loss: -4.090909004211426
Batch 11/64 loss: -3.913933753967285
Batch 12/64 loss: -4.151151180267334
Batch 13/64 loss: -4.144121170043945
Batch 14/64 loss: -3.9334187507629395
Batch 15/64 loss: -4.054042339324951
Batch 16/64 loss: -3.858625888824463
Batch 17/64 loss: -4.1828484535217285
Batch 18/64 loss: -4.004880905151367
Batch 19/64 loss: -4.101562023162842
Batch 20/64 loss: -4.136256694793701
Batch 21/64 loss: -3.9635801315307617
Batch 22/64 loss: -4.008813858032227
Batch 23/64 loss: -3.9042129516601562
Batch 24/64 loss: -4.06981086730957
Batch 25/64 loss: -3.9606118202209473
Batch 26/64 loss: -4.156922340393066
Batch 27/64 loss: -4.163581371307373
Batch 28/64 loss: -4.122305870056152
Batch 29/64 loss: -4.03735876083374
Batch 30/64 loss: -4.137692451477051
Batch 31/64 loss: -4.160869598388672
Batch 32/64 loss: -3.9280495643615723
Batch 33/64 loss: -3.9507603645324707
Batch 34/64 loss: -3.938509464263916
Batch 35/64 loss: -3.9979324340820312
Batch 36/64 loss: -4.118103504180908
Batch 37/64 loss: -4.022054672241211
Batch 38/64 loss: -4.185941696166992
Batch 39/64 loss: -3.9227218627929688
Batch 40/64 loss: -4.125670909881592
Batch 41/64 loss: -3.8547964096069336
Batch 42/64 loss: -3.925205707550049
Batch 43/64 loss: -4.08423376083374
Batch 44/64 loss: -4.354678153991699
Batch 45/64 loss: -3.934009552001953
Batch 46/64 loss: -3.301565170288086
Batch 47/64 loss: -4.073740482330322
Batch 48/64 loss: -3.9432482719421387
Batch 49/64 loss: -3.951364040374756
Batch 50/64 loss: -3.8389549255371094
Batch 51/64 loss: -4.0733795166015625
Batch 52/64 loss: -4.162661075592041
Batch 53/64 loss: -4.133352756500244
Batch 54/64 loss: -4.075323581695557
Batch 55/64 loss: -4.232566833496094
Batch 56/64 loss: -4.011072158813477
Batch 57/64 loss: -3.819321632385254
Batch 58/64 loss: -4.004202842712402
Batch 59/64 loss: -4.029139041900635
Batch 60/64 loss: -4.025928974151611
Batch 61/64 loss: -3.962836742401123
Batch 62/64 loss: -4.103733539581299
Batch 63/64 loss: -4.105437278747559
Batch 64/64 loss: -8.73440170288086
Epoch 369  Train loss: -4.081304782044654  Val loss: -4.405172236596596
Epoch 370
-------------------------------
Batch 1/64 loss: -4.142750263214111
Batch 2/64 loss: -3.9481778144836426
Batch 3/64 loss: -4.06832218170166
Batch 4/64 loss: -4.139540672302246
Batch 5/64 loss: -4.066483020782471
Batch 6/64 loss: -4.02589750289917
Batch 7/64 loss: -3.9093313217163086
Batch 8/64 loss: -4.242237567901611
Batch 9/64 loss: -3.945211410522461
Batch 10/64 loss: -3.7839531898498535
Batch 11/64 loss: -4.1402740478515625
Batch 12/64 loss: -4.023815631866455
Batch 13/64 loss: -4.091019630432129
Batch 14/64 loss: -4.006375789642334
Batch 15/64 loss: -4.028689861297607
Batch 16/64 loss: -3.9589362144470215
Batch 17/64 loss: -3.745826244354248
Batch 18/64 loss: -4.033814430236816
Batch 19/64 loss: -3.8282980918884277
Batch 20/64 loss: -4.019121170043945
Batch 21/64 loss: -4.059360980987549
Batch 22/64 loss: -4.156344890594482
Batch 23/64 loss: -3.7772297859191895
Batch 24/64 loss: -4.017270088195801
Batch 25/64 loss: -4.097181797027588
Batch 26/64 loss: -4.189983367919922
Batch 27/64 loss: -4.173497676849365
Batch 28/64 loss: -4.114874839782715
Batch 29/64 loss: -4.153855323791504
Batch 30/64 loss: -4.083763599395752
Batch 31/64 loss: -4.0568671226501465
Batch 32/64 loss: -4.073780536651611
Batch 33/64 loss: -4.1683220863342285
Batch 34/64 loss: -4.222419261932373
Batch 35/64 loss: -4.045975208282471
Batch 36/64 loss: -4.062005043029785
Batch 37/64 loss: -4.105845928192139
Batch 38/64 loss: -3.94069242477417
Batch 39/64 loss: -3.9231553077697754
Batch 40/64 loss: -4.1855010986328125
Batch 41/64 loss: -3.953458786010742
Batch 42/64 loss: -3.8561501502990723
Batch 43/64 loss: -4.179051399230957
Batch 44/64 loss: -4.149075984954834
Batch 45/64 loss: -4.109526634216309
Batch 46/64 loss: -4.243192672729492
Batch 47/64 loss: -4.2115020751953125
Batch 48/64 loss: -3.999943256378174
Batch 49/64 loss: -3.8977432250976562
Batch 50/64 loss: -3.931788444519043
Batch 51/64 loss: -4.084094524383545
Batch 52/64 loss: -4.078842639923096
Batch 53/64 loss: -3.859304904937744
Batch 54/64 loss: -4.093397617340088
Batch 55/64 loss: -4.264315128326416
Batch 56/64 loss: -4.15077018737793
Batch 57/64 loss: -4.103348255157471
Batch 58/64 loss: -4.085054397583008
Batch 59/64 loss: -4.053860187530518
Batch 60/64 loss: -4.142184734344482
Batch 61/64 loss: -4.223474502563477
Batch 62/64 loss: -4.229402542114258
Batch 63/64 loss: -4.066462993621826
Batch 64/64 loss: -8.598804473876953
Epoch 370  Train loss: -4.112487074908088  Val loss: -4.476650670631645
Epoch 371
-------------------------------
Batch 1/64 loss: -4.169328212738037
Batch 2/64 loss: -4.236073017120361
Batch 3/64 loss: -3.9055800437927246
Batch 4/64 loss: -4.0092973709106445
Batch 5/64 loss: -4.1577534675598145
Batch 6/64 loss: -4.240269184112549
Batch 7/64 loss: -4.070292949676514
Batch 8/64 loss: -3.927070140838623
Batch 9/64 loss: -4.0231170654296875
Batch 10/64 loss: -4.200697422027588
Batch 11/64 loss: -3.9544782638549805
Batch 12/64 loss: -3.93690824508667
Batch 13/64 loss: -3.931401252746582
Batch 14/64 loss: -3.7403769493103027
Batch 15/64 loss: -3.795804500579834
Batch 16/64 loss: -3.9649691581726074
Batch 17/64 loss: -4.026543617248535
Batch 18/64 loss: -4.026370525360107
Batch 19/64 loss: -4.057206153869629
Batch 20/64 loss: -3.994771957397461
Batch 21/64 loss: -3.8480782508850098
Batch 22/64 loss: -3.9008407592773438
Batch 23/64 loss: -4.036672115325928
Batch 24/64 loss: -4.002305030822754
Batch 25/64 loss: -3.9705119132995605
Batch 26/64 loss: -4.00991153717041
Batch 27/64 loss: -3.932023525238037
Batch 28/64 loss: -4.0882110595703125
Batch 29/64 loss: -4.126217365264893
Batch 30/64 loss: -3.9941649436950684
Batch 31/64 loss: -3.9525012969970703
Batch 32/64 loss: -3.798215389251709
Batch 33/64 loss: -4.013957500457764
Batch 34/64 loss: -3.9403748512268066
Batch 35/64 loss: -3.830624580383301
Batch 36/64 loss: -3.9274182319641113
Batch 37/64 loss: -4.140415668487549
Batch 38/64 loss: -3.829802989959717
Batch 39/64 loss: -3.9443106651306152
Batch 40/64 loss: -2.9623336791992188
Batch 41/64 loss: -3.1835994720458984
Batch 42/64 loss: -3.820742130279541
Batch 43/64 loss: -4.07967472076416
Batch 44/64 loss: -3.763631820678711
Batch 45/64 loss: -3.8285155296325684
Batch 46/64 loss: -3.6643319129943848
Batch 47/64 loss: -4.149534225463867
Batch 48/64 loss: -3.9847240447998047
Batch 49/64 loss: -4.115076065063477
Batch 50/64 loss: -3.928544521331787
Batch 51/64 loss: -3.7804818153381348
Batch 52/64 loss: -3.607998847961426
Batch 53/64 loss: -3.770214557647705
Batch 54/64 loss: -3.8481645584106445
Batch 55/64 loss: -3.840510368347168
Batch 56/64 loss: -3.756804943084717
Batch 57/64 loss: -4.0876030921936035
Batch 58/64 loss: -4.138786315917969
Batch 59/64 loss: -3.975618362426758
Batch 60/64 loss: -4.01976203918457
Batch 61/64 loss: -4.032066345214844
Batch 62/64 loss: -3.952587127685547
Batch 63/64 loss: -3.946817398071289
Batch 64/64 loss: -8.506460189819336
Epoch 371  Train loss: -3.9885935091504865  Val loss: -4.356504905674465
Epoch 372
-------------------------------
Batch 1/64 loss: -3.8856301307678223
Batch 2/64 loss: -4.073296546936035
Batch 3/64 loss: -4.051555633544922
Batch 4/64 loss: -3.8972973823547363
Batch 5/64 loss: -3.930420398712158
Batch 6/64 loss: -4.101104736328125
Batch 7/64 loss: -3.9972715377807617
Batch 8/64 loss: -3.49362850189209
Batch 9/64 loss: -3.9007740020751953
Batch 10/64 loss: -4.0226030349731445
Batch 11/64 loss: -4.01554012298584
Batch 12/64 loss: -4.264005184173584
Batch 13/64 loss: -3.9400558471679688
Batch 14/64 loss: -3.8369126319885254
Batch 15/64 loss: -4.100283622741699
Batch 16/64 loss: -3.9886903762817383
Batch 17/64 loss: -3.6899423599243164
Batch 18/64 loss: -3.9151177406311035
Batch 19/64 loss: -3.6352977752685547
Batch 20/64 loss: -3.925743579864502
Batch 21/64 loss: -3.807464599609375
Batch 22/64 loss: -4.093775749206543
Batch 23/64 loss: -3.9443416595458984
Batch 24/64 loss: -3.9501442909240723
Batch 25/64 loss: -3.871877670288086
Batch 26/64 loss: -4.047109603881836
Batch 27/64 loss: -4.046475887298584
Batch 28/64 loss: -3.6427769660949707
Batch 29/64 loss: -3.8554434776306152
Batch 30/64 loss: -4.189255714416504
Batch 31/64 loss: -3.522462844848633
Batch 32/64 loss: -4.057946681976318
Batch 33/64 loss: -3.600987434387207
Batch 34/64 loss: -3.7387638092041016
Batch 35/64 loss: -3.7848281860351562
Batch 36/64 loss: -3.9763712882995605
Batch 37/64 loss: -3.701913833618164
Batch 38/64 loss: -3.961695671081543
Batch 39/64 loss: -3.861556053161621
Batch 40/64 loss: -4.009990215301514
Batch 41/64 loss: -3.866762161254883
Batch 42/64 loss: -4.1394147872924805
Batch 43/64 loss: -4.056789398193359
Batch 44/64 loss: -4.023136138916016
Batch 45/64 loss: -3.8413033485412598
Batch 46/64 loss: -3.7364864349365234
Batch 47/64 loss: -3.670332431793213
Batch 48/64 loss: -3.9031786918640137
Batch 49/64 loss: -4.023628234863281
Batch 50/64 loss: -3.995008945465088
Batch 51/64 loss: -3.9564738273620605
Batch 52/64 loss: -3.924441337585449
Batch 53/64 loss: -3.8808350563049316
Batch 54/64 loss: -3.982485294342041
Batch 55/64 loss: -3.6586623191833496
Batch 56/64 loss: -3.858036518096924
Batch 57/64 loss: -3.903858184814453
Batch 58/64 loss: -3.9715752601623535
Batch 59/64 loss: -3.993579387664795
Batch 60/64 loss: -4.1465606689453125
Batch 61/64 loss: -3.94899320602417
Batch 62/64 loss: -3.5665626525878906
Batch 63/64 loss: -3.3284826278686523
Batch 64/64 loss: -8.451407432556152
Epoch 372  Train loss: -3.9536548277911017  Val loss: -4.319956133865409
Epoch 373
-------------------------------
Batch 1/64 loss: -3.882596969604492
Batch 2/64 loss: -3.744356155395508
Batch 3/64 loss: -3.8780922889709473
Batch 4/64 loss: -3.886134147644043
Batch 5/64 loss: -4.041507244110107
Batch 6/64 loss: -3.9619174003601074
Batch 7/64 loss: -3.8524765968322754
Batch 8/64 loss: -4.130390167236328
Batch 9/64 loss: -4.094723224639893
Batch 10/64 loss: -3.790289878845215
Batch 11/64 loss: -4.1042656898498535
Batch 12/64 loss: -3.963015556335449
Batch 13/64 loss: -4.111997127532959
Batch 14/64 loss: -4.081599712371826
Batch 15/64 loss: -3.8865599632263184
Batch 16/64 loss: -4.035327434539795
Batch 17/64 loss: -4.119442939758301
Batch 18/64 loss: -3.433670997619629
Batch 19/64 loss: -3.880415439605713
Batch 20/64 loss: -3.811655044555664
Batch 21/64 loss: -3.412660598754883
Batch 22/64 loss: -3.7661514282226562
Batch 23/64 loss: -4.009357929229736
Batch 24/64 loss: -3.753849506378174
Batch 25/64 loss: -4.179052352905273
Batch 26/64 loss: -4.069493293762207
Batch 27/64 loss: -4.1476945877075195
Batch 28/64 loss: -3.7328853607177734
Batch 29/64 loss: -4.025142669677734
Batch 30/64 loss: -4.046096324920654
Batch 31/64 loss: -4.215351104736328
Batch 32/64 loss: -3.875669002532959
Batch 33/64 loss: -4.011297225952148
Batch 34/64 loss: -3.638604164123535
Batch 35/64 loss: -4.021014213562012
Batch 36/64 loss: -3.889023780822754
Batch 37/64 loss: -3.956084728240967
Batch 38/64 loss: -3.8124561309814453
Batch 39/64 loss: -3.869455337524414
Batch 40/64 loss: -4.032482147216797
Batch 41/64 loss: -4.020893096923828
Batch 42/64 loss: -3.997267246246338
Batch 43/64 loss: -3.6323442459106445
Batch 44/64 loss: -3.9574551582336426
Batch 45/64 loss: -4.053956031799316
Batch 46/64 loss: -3.964219570159912
Batch 47/64 loss: -3.9751105308532715
Batch 48/64 loss: -3.8543100357055664
Batch 49/64 loss: -4.19334602355957
Batch 50/64 loss: -3.975022315979004
Batch 51/64 loss: -3.9059534072875977
Batch 52/64 loss: -4.145335674285889
Batch 53/64 loss: -4.102453231811523
Batch 54/64 loss: -3.944828987121582
Batch 55/64 loss: -4.036755084991455
Batch 56/64 loss: -4.086024761199951
Batch 57/64 loss: -3.910160541534424
Batch 58/64 loss: -4.019134998321533
Batch 59/64 loss: -3.8225836753845215
Batch 60/64 loss: -3.8126039505004883
Batch 61/64 loss: -3.682149887084961
Batch 62/64 loss: -3.9637131690979004
Batch 63/64 loss: -3.8853812217712402
Batch 64/64 loss: -8.47872257232666
Epoch 373  Train loss: -3.991440010070801  Val loss: -4.3666395469219825
Epoch 374
-------------------------------
Batch 1/64 loss: -3.846324920654297
Batch 2/64 loss: -4.141685485839844
Batch 3/64 loss: -3.770580291748047
Batch 4/64 loss: -3.8630781173706055
Batch 5/64 loss: -4.10000467300415
Batch 6/64 loss: -4.004189968109131
Batch 7/64 loss: -4.047612190246582
Batch 8/64 loss: -4.089437961578369
Batch 9/64 loss: -3.7638468742370605
Batch 10/64 loss: -4.219964027404785
Batch 11/64 loss: -3.8931050300598145
Batch 12/64 loss: -3.896817207336426
Batch 13/64 loss: -3.874722957611084
Batch 14/64 loss: -4.000411033630371
Batch 15/64 loss: -3.8424153327941895
Batch 16/64 loss: -4.201408386230469
Batch 17/64 loss: -3.8366570472717285
Batch 18/64 loss: -4.053513050079346
Batch 19/64 loss: -3.9188599586486816
Batch 20/64 loss: -4.058331489562988
Batch 21/64 loss: -4.094322204589844
Batch 22/64 loss: -3.9449095726013184
Batch 23/64 loss: -4.007021427154541
Batch 24/64 loss: -3.9555163383483887
Batch 25/64 loss: -3.7382168769836426
Batch 26/64 loss: -3.8753433227539062
Batch 27/64 loss: -4.1133623123168945
Batch 28/64 loss: -3.8824238777160645
Batch 29/64 loss: -3.8517794609069824
Batch 30/64 loss: -3.8933868408203125
Batch 31/64 loss: -4.0438690185546875
Batch 32/64 loss: -3.7371678352355957
Batch 33/64 loss: -3.719165802001953
Batch 34/64 loss: -3.9427595138549805
Batch 35/64 loss: -4.041935920715332
Batch 36/64 loss: -4.059647560119629
Batch 37/64 loss: -3.525066375732422
Batch 38/64 loss: -4.023345947265625
Batch 39/64 loss: -4.031620502471924
Batch 40/64 loss: -3.8069629669189453
Batch 41/64 loss: -3.970369815826416
Batch 42/64 loss: -3.998879909515381
Batch 43/64 loss: -3.936202049255371
Batch 44/64 loss: -3.3942880630493164
Batch 45/64 loss: -3.817770004272461
Batch 46/64 loss: -4.004411697387695
Batch 47/64 loss: -3.8536171913146973
Batch 48/64 loss: -3.8565268516540527
Batch 49/64 loss: -4.092493057250977
Batch 50/64 loss: -3.0211400985717773
Batch 51/64 loss: -4.143621921539307
Batch 52/64 loss: -3.83597469329834
Batch 53/64 loss: -3.1597604751586914
Batch 54/64 loss: -3.9920568466186523
Batch 55/64 loss: -3.9361329078674316
Batch 56/64 loss: -4.03478479385376
Batch 57/64 loss: -4.085756778717041
Batch 58/64 loss: -3.8733949661254883
Batch 59/64 loss: -3.7562999725341797
Batch 60/64 loss: -4.010946273803711
Batch 61/64 loss: -3.5348453521728516
Batch 62/64 loss: -4.033928871154785
Batch 63/64 loss: -4.000150680541992
Batch 64/64 loss: -8.517078399658203
Epoch 374  Train loss: -3.959873752967984  Val loss: -4.1852259291816
Epoch 375
-------------------------------
Batch 1/64 loss: -4.005069732666016
Batch 2/64 loss: -3.9451894760131836
Batch 3/64 loss: -3.6897544860839844
Batch 4/64 loss: -3.9162073135375977
Batch 5/64 loss: -4.063958644866943
Batch 6/64 loss: -3.7204179763793945
Batch 7/64 loss: -3.422304153442383
Batch 8/64 loss: -3.8842573165893555
Batch 9/64 loss: -3.8861641883850098
Batch 10/64 loss: -3.7830100059509277
Batch 11/64 loss: -4.056784629821777
Batch 12/64 loss: -3.679652690887451
Batch 13/64 loss: -3.5548763275146484
Batch 14/64 loss: -3.7775917053222656
Batch 15/64 loss: -3.980426788330078
Batch 16/64 loss: -3.9798831939697266
Batch 17/64 loss: -3.762002944946289
Batch 18/64 loss: -4.019503116607666
Batch 19/64 loss: -3.866429328918457
Batch 20/64 loss: -3.712172031402588
Batch 21/64 loss: -3.5009469985961914
Batch 22/64 loss: -3.830336093902588
Batch 23/64 loss: -3.6776514053344727
Batch 24/64 loss: -3.9969286918640137
Batch 25/64 loss: -3.8329310417175293
Batch 26/64 loss: -3.873145580291748
Batch 27/64 loss: -3.8789710998535156
Batch 28/64 loss: -3.6562304496765137
Batch 29/64 loss: -3.709134101867676
Batch 30/64 loss: -4.0593366622924805
Batch 31/64 loss: -4.210868835449219
Batch 32/64 loss: -3.8714981079101562
Batch 33/64 loss: -4.013147354125977
Batch 34/64 loss: -4.002951145172119
Batch 35/64 loss: -3.7616195678710938
Batch 36/64 loss: -3.6807713508605957
Batch 37/64 loss: -4.178499221801758
Batch 38/64 loss: -4.017915725708008
Batch 39/64 loss: -4.014388084411621
Batch 40/64 loss: -3.9022622108459473
Batch 41/64 loss: -3.9400148391723633
Batch 42/64 loss: -3.926107406616211
Batch 43/64 loss: -3.916538715362549
Batch 44/64 loss: -4.058248519897461
Batch 45/64 loss: -3.9010186195373535
Batch 46/64 loss: -4.080482482910156
Batch 47/64 loss: -4.076597213745117
Batch 48/64 loss: -3.8674654960632324
Batch 49/64 loss: -4.160289764404297
Batch 50/64 loss: -3.8638672828674316
Batch 51/64 loss: -4.0168046951293945
Batch 52/64 loss: -3.8684511184692383
Batch 53/64 loss: -3.884582042694092
Batch 54/64 loss: -3.930950164794922
Batch 55/64 loss: -3.7949962615966797
Batch 56/64 loss: -3.9132323265075684
Batch 57/64 loss: -4.0013108253479
Batch 58/64 loss: -3.815484046936035
Batch 59/64 loss: -3.9372143745422363
Batch 60/64 loss: -3.8621034622192383
Batch 61/64 loss: -4.198429584503174
Batch 62/64 loss: -4.202709674835205
Batch 63/64 loss: -4.126731872558594
Batch 64/64 loss: -8.187243461608887
Epoch 375  Train loss: -3.950733383029115  Val loss: -4.368061917753973
Epoch 376
-------------------------------
Batch 1/64 loss: -4.054138660430908
Batch 2/64 loss: -3.951406478881836
Batch 3/64 loss: -3.7992067337036133
Batch 4/64 loss: -3.8555030822753906
Batch 5/64 loss: -3.88419771194458
Batch 6/64 loss: -3.6582298278808594
Batch 7/64 loss: -3.7524895668029785
Batch 8/64 loss: -4.076565742492676
Batch 9/64 loss: -4.138064861297607
Batch 10/64 loss: -3.939497947692871
Batch 11/64 loss: -4.118062496185303
Batch 12/64 loss: -4.006491184234619
Batch 13/64 loss: -4.029849052429199
Batch 14/64 loss: -4.043885707855225
Batch 15/64 loss: -4.02551794052124
Batch 16/64 loss: -4.179633617401123
Batch 17/64 loss: -4.081881046295166
Batch 18/64 loss: -4.044557571411133
Batch 19/64 loss: -3.949622631072998
Batch 20/64 loss: -3.9737448692321777
Batch 21/64 loss: -3.9578943252563477
Batch 22/64 loss: -3.865917682647705
Batch 23/64 loss: -3.930131435394287
Batch 24/64 loss: -4.162642955780029
Batch 25/64 loss: -4.07084321975708
Batch 26/64 loss: -4.166416645050049
Batch 27/64 loss: -4.099650859832764
Batch 28/64 loss: -4.090925216674805
Batch 29/64 loss: -3.687253952026367
Batch 30/64 loss: -3.9023966789245605
Batch 31/64 loss: -4.001817226409912
Batch 32/64 loss: -4.047455787658691
Batch 33/64 loss: -3.803431510925293
Batch 34/64 loss: -4.073920249938965
Batch 35/64 loss: -3.7080793380737305
Batch 36/64 loss: -4.099722862243652
Batch 37/64 loss: -4.09116268157959
Batch 38/64 loss: -3.8017048835754395
Batch 39/64 loss: -3.9964218139648438
Batch 40/64 loss: -4.076582908630371
Batch 41/64 loss: -3.801845073699951
Batch 42/64 loss: -3.4059324264526367
Batch 43/64 loss: -4.041522979736328
Batch 44/64 loss: -4.046773433685303
Batch 45/64 loss: -3.936084270477295
Batch 46/64 loss: -4.082813262939453
Batch 47/64 loss: -4.160856246948242
Batch 48/64 loss: -4.032228469848633
Batch 49/64 loss: -4.03959846496582
Batch 50/64 loss: -3.9850058555603027
Batch 51/64 loss: -4.040534496307373
Batch 52/64 loss: -3.8851499557495117
Batch 53/64 loss: -4.119314193725586
Batch 54/64 loss: -4.183004856109619
Batch 55/64 loss: -4.072440147399902
Batch 56/64 loss: -4.085474967956543
Batch 57/64 loss: -3.7432432174682617
Batch 58/64 loss: -3.9859890937805176
Batch 59/64 loss: -4.015330791473389
Batch 60/64 loss: -4.094820022583008
Batch 61/64 loss: -3.4381637573242188
Batch 62/64 loss: -3.910184860229492
Batch 63/64 loss: -3.8392672538757324
Batch 64/64 loss: -8.622612953186035
Epoch 376  Train loss: -4.025246380824669  Val loss: -3.8008967396319937
Epoch 377
-------------------------------
Batch 1/64 loss: -4.008307933807373
Batch 2/64 loss: -3.732178211212158
Batch 3/64 loss: -3.0887889862060547
Batch 4/64 loss: -4.0569376945495605
Batch 5/64 loss: -3.8893370628356934
Batch 6/64 loss: -3.5021138191223145
Batch 7/64 loss: -3.5406336784362793
Batch 8/64 loss: -3.7586750984191895
Batch 9/64 loss: -3.917194366455078
Batch 10/64 loss: -3.8874120712280273
Batch 11/64 loss: -3.556900978088379
Batch 12/64 loss: -3.8021135330200195
Batch 13/64 loss: -2.47635555267334
Batch 14/64 loss: -2.9545888900756836
Batch 15/64 loss: -3.777700424194336
Batch 16/64 loss: -3.9490952491760254
Batch 17/64 loss: -3.6073765754699707
Batch 18/64 loss: -2.7575273513793945
Batch 19/64 loss: -3.6627321243286133
Batch 20/64 loss: -3.703031063079834
Batch 21/64 loss: -3.044804573059082
Batch 22/64 loss: -3.236856460571289
Batch 23/64 loss: -3.1088809967041016
Batch 24/64 loss: -3.6227517127990723
Batch 25/64 loss: -3.29437255859375
Batch 26/64 loss: -2.7931346893310547
Batch 27/64 loss: -3.728804111480713
Batch 28/64 loss: -3.6771368980407715
Batch 29/64 loss: -3.870457172393799
Batch 30/64 loss: -3.944693088531494
Batch 31/64 loss: -3.9086012840270996
Batch 32/64 loss: -3.669393539428711
Batch 33/64 loss: -3.7508726119995117
Batch 34/64 loss: -3.0814924240112305
Batch 35/64 loss: -3.901890277862549
Batch 36/64 loss: -4.010824680328369
Batch 37/64 loss: -3.9139866828918457
Batch 38/64 loss: -3.5745058059692383
Batch 39/64 loss: -3.887470245361328
Batch 40/64 loss: -4.093526363372803
Batch 41/64 loss: -3.680509567260742
Batch 42/64 loss: -3.5577049255371094
Batch 43/64 loss: -3.9857330322265625
Batch 44/64 loss: -3.885474681854248
Batch 45/64 loss: -3.818687915802002
Batch 46/64 loss: -3.996108055114746
Batch 47/64 loss: -3.9608540534973145
Batch 48/64 loss: -3.9896292686462402
Batch 49/64 loss: -3.2386980056762695
Batch 50/64 loss: -4.058682918548584
Batch 51/64 loss: -4.022770404815674
Batch 52/64 loss: -3.9312191009521484
Batch 53/64 loss: -3.9871482849121094
Batch 54/64 loss: -3.612732410430908
Batch 55/64 loss: -3.800795078277588
Batch 56/64 loss: -3.8471364974975586
Batch 57/64 loss: -3.698065757751465
Batch 58/64 loss: -3.8644843101501465
Batch 59/64 loss: -3.8176512718200684
Batch 60/64 loss: -3.983856201171875
Batch 61/64 loss: -3.6124753952026367
Batch 62/64 loss: -3.7813706398010254
Batch 63/64 loss: -3.696068286895752
Batch 64/64 loss: -8.410091400146484
Epoch 377  Train loss: -3.7314334345798867  Val loss: -4.269875293744798
Epoch 378
-------------------------------
Batch 1/64 loss: -3.9094176292419434
Batch 2/64 loss: -3.669391632080078
Batch 3/64 loss: -3.9181222915649414
Batch 4/64 loss: -3.9628405570983887
Batch 5/64 loss: -4.012262344360352
Batch 6/64 loss: -3.8888025283813477
Batch 7/64 loss: -4.02296781539917
Batch 8/64 loss: -3.6779441833496094
Batch 9/64 loss: -3.859165668487549
Batch 10/64 loss: -4.108434677124023
Batch 11/64 loss: -3.9336767196655273
Batch 12/64 loss: -3.4408702850341797
Batch 13/64 loss: -3.8471007347106934
Batch 14/64 loss: -3.9581146240234375
Batch 15/64 loss: -3.550189971923828
Batch 16/64 loss: -3.298336982727051
Batch 17/64 loss: -3.8666186332702637
Batch 18/64 loss: -3.589785575866699
Batch 19/64 loss: -4.090144634246826
Batch 20/64 loss: -4.074645519256592
Batch 21/64 loss: -4.021799087524414
Batch 22/64 loss: -3.9458675384521484
Batch 23/64 loss: -3.9770941734313965
Batch 24/64 loss: -4.129122734069824
Batch 25/64 loss: -3.8357582092285156
Batch 26/64 loss: -4.001713752746582
Batch 27/64 loss: -3.9397268295288086
Batch 28/64 loss: -3.89829683303833
Batch 29/64 loss: -3.989065647125244
Batch 30/64 loss: -4.088205337524414
Batch 31/64 loss: -3.9479212760925293
Batch 32/64 loss: -3.8726067543029785
Batch 33/64 loss: -4.00081205368042
Batch 34/64 loss: -3.8434619903564453
Batch 35/64 loss: -3.7855677604675293
Batch 36/64 loss: -3.998141288757324
Batch 37/64 loss: -3.7102975845336914
Batch 38/64 loss: -3.942384719848633
Batch 39/64 loss: -4.096269130706787
Batch 40/64 loss: -4.094151020050049
Batch 41/64 loss: -3.486903190612793
Batch 42/64 loss: -3.9312705993652344
Batch 43/64 loss: -3.8730359077453613
Batch 44/64 loss: -3.7999038696289062
Batch 45/64 loss: -4.085477828979492
Batch 46/64 loss: -4.086703300476074
Batch 47/64 loss: -4.199591159820557
Batch 48/64 loss: -3.9516849517822266
Batch 49/64 loss: -3.880478858947754
Batch 50/64 loss: -3.804098606109619
Batch 51/64 loss: -4.0067901611328125
Batch 52/64 loss: -4.09495735168457
Batch 53/64 loss: -4.083371639251709
Batch 54/64 loss: -3.6096105575561523
Batch 55/64 loss: -3.147428512573242
Batch 56/64 loss: -3.6987857818603516
Batch 57/64 loss: -3.771191120147705
Batch 58/64 loss: -3.930962085723877
Batch 59/64 loss: -3.8488025665283203
Batch 60/64 loss: -3.360285758972168
Batch 61/64 loss: -3.641511917114258
Batch 62/64 loss: -4.086426734924316
Batch 63/64 loss: -4.088238716125488
Batch 64/64 loss: -8.289264678955078
Epoch 378  Train loss: -3.9291224535773783  Val loss: -4.217182526473737
Epoch 379
-------------------------------
Batch 1/64 loss: -3.8613109588623047
Batch 2/64 loss: -3.862487316131592
Batch 3/64 loss: -3.5629324913024902
Batch 4/64 loss: -3.9677600860595703
Batch 5/64 loss: -3.7489356994628906
Batch 6/64 loss: -3.6659817695617676
Batch 7/64 loss: -3.183905601501465
Batch 8/64 loss: -3.417074203491211
Batch 9/64 loss: -3.9199886322021484
Batch 10/64 loss: -3.771583080291748
Batch 11/64 loss: -4.017941474914551
Batch 12/64 loss: -4.01149320602417
Batch 13/64 loss: -3.73378849029541
Batch 14/64 loss: -3.761715888977051
Batch 15/64 loss: -3.9030871391296387
Batch 16/64 loss: -3.9522705078125
Batch 17/64 loss: -3.776468276977539
Batch 18/64 loss: -3.9592456817626953
Batch 19/64 loss: -3.9471611976623535
Batch 20/64 loss: -3.769275188446045
Batch 21/64 loss: -3.8632335662841797
Batch 22/64 loss: -4.027525901794434
Batch 23/64 loss: -3.9299144744873047
Batch 24/64 loss: -3.9632697105407715
Batch 25/64 loss: -3.893611431121826
Batch 26/64 loss: -3.6335558891296387
Batch 27/64 loss: -3.644174098968506
Batch 28/64 loss: -3.9867324829101562
Batch 29/64 loss: -3.872687339782715
Batch 30/64 loss: -4.069633483886719
Batch 31/64 loss: -3.9798765182495117
Batch 32/64 loss: -3.6427345275878906
Batch 33/64 loss: -3.901362895965576
Batch 34/64 loss: -4.012552738189697
Batch 35/64 loss: -3.8791146278381348
Batch 36/64 loss: -3.7920384407043457
Batch 37/64 loss: -3.9004855155944824
Batch 38/64 loss: -3.9536361694335938
Batch 39/64 loss: -3.770097255706787
Batch 40/64 loss: -3.4790773391723633
Batch 41/64 loss: -3.1237411499023438
Batch 42/64 loss: -3.6376876831054688
Batch 43/64 loss: -3.8913626670837402
Batch 44/64 loss: -3.7358713150024414
Batch 45/64 loss: -3.9631614685058594
Batch 46/64 loss: -3.794783115386963
Batch 47/64 loss: -3.5538434982299805
Batch 48/64 loss: -3.8306050300598145
Batch 49/64 loss: -3.5596165657043457
Batch 50/64 loss: -3.7676262855529785
Batch 51/64 loss: -3.2890844345092773
Batch 52/64 loss: -3.7419204711914062
Batch 53/64 loss: -4.079466819763184
Batch 54/64 loss: -4.010187149047852
Batch 55/64 loss: -4.091400623321533
Batch 56/64 loss: -3.6419219970703125
Batch 57/64 loss: -3.852954864501953
Batch 58/64 loss: -3.93595552444458
Batch 59/64 loss: -4.015449523925781
Batch 60/64 loss: -3.9450149536132812
Batch 61/64 loss: -3.490966796875
Batch 62/64 loss: -3.9950408935546875
Batch 63/64 loss: -4.176477432250977
Batch 64/64 loss: -8.45700454711914
Epoch 379  Train loss: -3.8659861171946805  Val loss: -4.289645925829911
Epoch 380
-------------------------------
Batch 1/64 loss: -3.671609878540039
Batch 2/64 loss: -4.141152381896973
Batch 3/64 loss: -4.0748138427734375
Batch 4/64 loss: -3.9808263778686523
Batch 5/64 loss: -3.6739096641540527
Batch 6/64 loss: -4.013159275054932
Batch 7/64 loss: -3.9425201416015625
Batch 8/64 loss: -3.6681771278381348
Batch 9/64 loss: -3.9980177879333496
Batch 10/64 loss: -3.88669490814209
Batch 11/64 loss: -3.579638957977295
Batch 12/64 loss: -3.9093756675720215
Batch 13/64 loss: -3.3412485122680664
Batch 14/64 loss: -3.214177131652832
Batch 15/64 loss: -3.9541449546813965
Batch 16/64 loss: -3.8046469688415527
Batch 17/64 loss: -3.6990137100219727
Batch 18/64 loss: -3.8787379264831543
Batch 19/64 loss: -3.6874561309814453
Batch 20/64 loss: -3.3500938415527344
Batch 21/64 loss: -3.226864814758301
Batch 22/64 loss: -3.7796630859375
Batch 23/64 loss: -3.9625887870788574
Batch 24/64 loss: -3.448519229888916
Batch 25/64 loss: -3.2476091384887695
Batch 26/64 loss: -3.2928037643432617
Batch 27/64 loss: -3.4714317321777344
Batch 28/64 loss: -3.5839905738830566
Batch 29/64 loss: -3.813474178314209
Batch 30/64 loss: -3.6749720573425293
Batch 31/64 loss: -3.6227989196777344
Batch 32/64 loss: -3.8218026161193848
Batch 33/64 loss: -3.1388330459594727
Batch 34/64 loss: -3.7347116470336914
Batch 35/64 loss: -3.655223846435547
Batch 36/64 loss: -3.7275285720825195
Batch 37/64 loss: -3.85213565826416
Batch 38/64 loss: -3.827645778656006
Batch 39/64 loss: -3.759950637817383
Batch 40/64 loss: -3.438509941101074
Batch 41/64 loss: -3.511331558227539
Batch 42/64 loss: -3.805107593536377
Batch 43/64 loss: -3.7102365493774414
Batch 44/64 loss: -3.258957862854004
Batch 45/64 loss: -3.717010498046875
Batch 46/64 loss: -3.9301719665527344
Batch 47/64 loss: -3.5011191368103027
Batch 48/64 loss: -3.7520079612731934
Batch 49/64 loss: -3.6626133918762207
Batch 50/64 loss: -3.1890993118286133
Batch 51/64 loss: -3.905909538269043
Batch 52/64 loss: -3.7004055976867676
Batch 53/64 loss: -3.7996225357055664
Batch 54/64 loss: -3.8681530952453613
Batch 55/64 loss: -3.9642953872680664
Batch 56/64 loss: -4.109762668609619
Batch 57/64 loss: -3.769322395324707
Batch 58/64 loss: -3.814826011657715
Batch 59/64 loss: -3.9799227714538574
Batch 60/64 loss: -3.7111711502075195
Batch 61/64 loss: -4.0395708084106445
Batch 62/64 loss: -3.677417278289795
Batch 63/64 loss: -4.123947620391846
Batch 64/64 loss: -8.375194549560547
Epoch 380  Train loss: -3.769942773557177  Val loss: -4.172360148216851
Epoch 381
-------------------------------
Batch 1/64 loss: -3.9027037620544434
Batch 2/64 loss: -3.6974329948425293
Batch 3/64 loss: -3.928192138671875
Batch 4/64 loss: -3.776150703430176
Batch 5/64 loss: -3.762007713317871
Batch 6/64 loss: -4.020002365112305
Batch 7/64 loss: -3.7899169921875
Batch 8/64 loss: -3.753678321838379
Batch 9/64 loss: -3.9807920455932617
Batch 10/64 loss: -3.826091766357422
Batch 11/64 loss: -3.027812957763672
Batch 12/64 loss: -3.7075209617614746
Batch 13/64 loss: -3.8717455863952637
Batch 14/64 loss: -3.958846092224121
Batch 15/64 loss: -3.7947373390197754
Batch 16/64 loss: -3.942406177520752
Batch 17/64 loss: -3.633706569671631
Batch 18/64 loss: -3.993128776550293
Batch 19/64 loss: -3.8985633850097656
Batch 20/64 loss: -3.2637147903442383
Batch 21/64 loss: -3.895570755004883
Batch 22/64 loss: -3.9022250175476074
Batch 23/64 loss: -3.482053756713867
Batch 24/64 loss: -3.8369083404541016
Batch 25/64 loss: -4.021022796630859
Batch 26/64 loss: -3.722198963165283
Batch 27/64 loss: -3.6217336654663086
Batch 28/64 loss: -3.924774169921875
Batch 29/64 loss: -3.8366103172302246
Batch 30/64 loss: -4.0329909324646
Batch 31/64 loss: -4.069808006286621
Batch 32/64 loss: -3.9005656242370605
Batch 33/64 loss: -3.6674022674560547
Batch 34/64 loss: -3.9079222679138184
Batch 35/64 loss: -3.9356422424316406
Batch 36/64 loss: -3.8771777153015137
Batch 37/64 loss: -3.870551586151123
Batch 38/64 loss: -3.6976213455200195
Batch 39/64 loss: -3.2417373657226562
Batch 40/64 loss: -4.075911521911621
Batch 41/64 loss: -3.781381607055664
Batch 42/64 loss: -3.3508453369140625
Batch 43/64 loss: -3.8212695121765137
Batch 44/64 loss: -3.7845797538757324
Batch 45/64 loss: -3.538980007171631
Batch 46/64 loss: -3.8357138633728027
Batch 47/64 loss: -3.632183074951172
Batch 48/64 loss: -4.016634941101074
Batch 49/64 loss: -4.015882968902588
Batch 50/64 loss: -3.901834487915039
Batch 51/64 loss: -3.933338165283203
Batch 52/64 loss: -3.7022323608398438
Batch 53/64 loss: -3.776817798614502
Batch 54/64 loss: -3.6127448081970215
Batch 55/64 loss: -3.8061161041259766
Batch 56/64 loss: -3.0909786224365234
Batch 57/64 loss: -3.705669403076172
Batch 58/64 loss: -4.027517318725586
Batch 59/64 loss: -4.018139839172363
Batch 60/64 loss: -4.0190911293029785
Batch 61/64 loss: -4.022729396820068
Batch 62/64 loss: -3.1561479568481445
Batch 63/64 loss: -4.034875392913818
Batch 64/64 loss: -8.483993530273438
Epoch 381  Train loss: -3.8431102603089577  Val loss: -4.327922755500295
Epoch 382
-------------------------------
Batch 1/64 loss: -3.747468948364258
Batch 2/64 loss: -3.689058780670166
Batch 3/64 loss: -3.895571708679199
Batch 4/64 loss: -4.1472320556640625
Batch 5/64 loss: -3.9143176078796387
Batch 6/64 loss: -4.0936408042907715
Batch 7/64 loss: -3.853546619415283
Batch 8/64 loss: -4.122384548187256
Batch 9/64 loss: -3.9755706787109375
Batch 10/64 loss: -3.762820243835449
Batch 11/64 loss: -3.8232650756835938
Batch 12/64 loss: -4.1769490242004395
Batch 13/64 loss: -3.9360523223876953
Batch 14/64 loss: -4.026403903961182
Batch 15/64 loss: -4.151697635650635
Batch 16/64 loss: -4.053530216217041
Batch 17/64 loss: -3.9892168045043945
Batch 18/64 loss: -4.166346549987793
Batch 19/64 loss: -4.149433135986328
Batch 20/64 loss: -4.138730049133301
Batch 21/64 loss: -4.116566181182861
Batch 22/64 loss: -3.9886274337768555
Batch 23/64 loss: -4.0330891609191895
Batch 24/64 loss: -4.1380085945129395
Batch 25/64 loss: -3.5059022903442383
Batch 26/64 loss: -4.084113121032715
Batch 27/64 loss: -3.975477695465088
Batch 28/64 loss: -3.8237271308898926
Batch 29/64 loss: -4.007006645202637
Batch 30/64 loss: -3.6523489952087402
Batch 31/64 loss: -3.9775338172912598
Batch 32/64 loss: -4.227754592895508
Batch 33/64 loss: -3.703221321105957
Batch 34/64 loss: -3.9901084899902344
Batch 35/64 loss: -3.6640262603759766
Batch 36/64 loss: -3.6462130546569824
Batch 37/64 loss: -3.601871967315674
Batch 38/64 loss: -2.7963333129882812
Batch 39/64 loss: -4.147905349731445
Batch 40/64 loss: -3.9322962760925293
Batch 41/64 loss: -4.188312530517578
Batch 42/64 loss: -3.927605628967285
Batch 43/64 loss: -4.0057291984558105
Batch 44/64 loss: -3.893186092376709
Batch 45/64 loss: -3.819194793701172
Batch 46/64 loss: -4.089452266693115
Batch 47/64 loss: -3.8523077964782715
Batch 48/64 loss: -4.222514629364014
Batch 49/64 loss: -3.822075366973877
Batch 50/64 loss: -4.143786907196045
Batch 51/64 loss: -3.699209690093994
Batch 52/64 loss: -3.7485246658325195
Batch 53/64 loss: -3.9352431297302246
Batch 54/64 loss: -4.098056793212891
Batch 55/64 loss: -3.7522501945495605
Batch 56/64 loss: -4.1008429527282715
Batch 57/64 loss: -3.7072415351867676
Batch 58/64 loss: -4.104187965393066
Batch 59/64 loss: -4.1187214851379395
Batch 60/64 loss: -4.084235668182373
Batch 61/64 loss: -4.017897129058838
Batch 62/64 loss: -3.988976001739502
Batch 63/64 loss: -4.188539981842041
Batch 64/64 loss: -8.546285629272461
Epoch 382  Train loss: -3.995971373015759  Val loss: -4.371701925480898
Epoch 383
-------------------------------
Batch 1/64 loss: -3.4618396759033203
Batch 2/64 loss: -3.7406301498413086
Batch 3/64 loss: -3.905238151550293
Batch 4/64 loss: -3.846034049987793
Batch 5/64 loss: -3.8890480995178223
Batch 6/64 loss: -3.9043846130371094
Batch 7/64 loss: -3.9320311546325684
Batch 8/64 loss: -4.014267444610596
Batch 9/64 loss: -3.8424978256225586
Batch 10/64 loss: -4.092006206512451
Batch 11/64 loss: -4.083982467651367
Batch 12/64 loss: -3.899230480194092
Batch 13/64 loss: -3.763411045074463
Batch 14/64 loss: -3.9188027381896973
Batch 15/64 loss: -4.023704528808594
Batch 16/64 loss: -4.097143173217773
Batch 17/64 loss: -3.9958763122558594
Batch 18/64 loss: -4.060614109039307
Batch 19/64 loss: -4.088849067687988
Batch 20/64 loss: -4.041567802429199
Batch 21/64 loss: -3.898003101348877
Batch 22/64 loss: -3.9513421058654785
Batch 23/64 loss: -3.6513185501098633
Batch 24/64 loss: -2.6783151626586914
Batch 25/64 loss: -3.903376579284668
Batch 26/64 loss: -4.215592384338379
Batch 27/64 loss: -3.878082275390625
Batch 28/64 loss: -3.4345827102661133
Batch 29/64 loss: -4.16121244430542
Batch 30/64 loss: -4.077723026275635
Batch 31/64 loss: -3.9994759559631348
Batch 32/64 loss: -4.062223434448242
Batch 33/64 loss: -4.058913707733154
Batch 34/64 loss: -4.26428747177124
Batch 35/64 loss: -3.7615628242492676
Batch 36/64 loss: -3.932119369506836
Batch 37/64 loss: -3.9350085258483887
Batch 38/64 loss: -3.979611873626709
Batch 39/64 loss: -4.15978479385376
Batch 40/64 loss: -4.1346211433410645
Batch 41/64 loss: -3.8271188735961914
Batch 42/64 loss: -4.1157002449035645
Batch 43/64 loss: -4.018253803253174
Batch 44/64 loss: -3.9818758964538574
Batch 45/64 loss: -3.534881591796875
Batch 46/64 loss: -4.064895153045654
Batch 47/64 loss: -3.793642520904541
Batch 48/64 loss: -4.1887335777282715
Batch 49/64 loss: -3.834899425506592
Batch 50/64 loss: -3.840528964996338
Batch 51/64 loss: -4.110940933227539
Batch 52/64 loss: -3.9773201942443848
Batch 53/64 loss: -4.066689968109131
Batch 54/64 loss: -4.013210773468018
Batch 55/64 loss: -3.866917610168457
Batch 56/64 loss: -3.9461922645568848
Batch 57/64 loss: -4.140256881713867
Batch 58/64 loss: -4.026157379150391
Batch 59/64 loss: -3.8650646209716797
Batch 60/64 loss: -4.074881553649902
Batch 61/64 loss: -4.155787944793701
Batch 62/64 loss: -4.07827615737915
Batch 63/64 loss: -3.5883541107177734
Batch 64/64 loss: -8.422290802001953
Epoch 383  Train loss: -3.9869116091260723  Val loss: -4.412264807527418
Epoch 384
-------------------------------
Batch 1/64 loss: -4.042349815368652
Batch 2/64 loss: -4.1532816886901855
Batch 3/64 loss: -4.265922546386719
Batch 4/64 loss: -3.7150683403015137
Batch 5/64 loss: -4.040103912353516
Batch 6/64 loss: -4.167609691619873
Batch 7/64 loss: -4.199413776397705
Batch 8/64 loss: -3.882218360900879
Batch 9/64 loss: -4.0275492668151855
Batch 10/64 loss: -3.606635570526123
Batch 11/64 loss: -3.847494602203369
Batch 12/64 loss: -3.9272427558898926
Batch 13/64 loss: -3.782505989074707
Batch 14/64 loss: -3.9838433265686035
Batch 15/64 loss: -3.972902774810791
Batch 16/64 loss: -3.9608449935913086
Batch 17/64 loss: -3.8898963928222656
Batch 18/64 loss: -3.8946027755737305
Batch 19/64 loss: -4.107701778411865
Batch 20/64 loss: -3.8072009086608887
Batch 21/64 loss: -4.03637170791626
Batch 22/64 loss: -4.033779621124268
Batch 23/64 loss: -4.053977012634277
Batch 24/64 loss: -4.06116247177124
Batch 25/64 loss: -3.788994789123535
Batch 26/64 loss: -3.6829819679260254
Batch 27/64 loss: -4.021834373474121
Batch 28/64 loss: -3.992551326751709
Batch 29/64 loss: -4.013668537139893
Batch 30/64 loss: -3.8655810356140137
Batch 31/64 loss: -3.5038557052612305
Batch 32/64 loss: -3.9937429428100586
Batch 33/64 loss: -3.90126371383667
Batch 34/64 loss: -4.017712116241455
Batch 35/64 loss: -4.1430134773254395
Batch 36/64 loss: -3.8790769577026367
Batch 37/64 loss: -3.8597445487976074
Batch 38/64 loss: -4.09129524230957
Batch 39/64 loss: -3.911682605743408
Batch 40/64 loss: -4.127737522125244
Batch 41/64 loss: -3.983771800994873
Batch 42/64 loss: -3.9488039016723633
Batch 43/64 loss: -3.816610813140869
Batch 44/64 loss: -3.9388375282287598
Batch 45/64 loss: -4.030904769897461
Batch 46/64 loss: -4.157840728759766
Batch 47/64 loss: -4.066827297210693
Batch 48/64 loss: -3.8025054931640625
Batch 49/64 loss: -3.9842653274536133
Batch 50/64 loss: -4.088709831237793
Batch 51/64 loss: -4.1528239250183105
Batch 52/64 loss: -4.084449291229248
Batch 53/64 loss: -4.1140456199646
Batch 54/64 loss: -4.001780986785889
Batch 55/64 loss: -4.015111923217773
Batch 56/64 loss: -3.8474388122558594
Batch 57/64 loss: -3.98165225982666
Batch 58/64 loss: -3.8392724990844727
Batch 59/64 loss: -4.097848415374756
Batch 60/64 loss: -3.3642349243164062
Batch 61/64 loss: -4.058971881866455
Batch 62/64 loss: -3.896972179412842
Batch 63/64 loss: -4.065620422363281
Batch 64/64 loss: -8.285741806030273
Epoch 384  Train loss: -4.012674885170132  Val loss: -4.435222219355738
Epoch 385
-------------------------------
Batch 1/64 loss: -4.17610502243042
Batch 2/64 loss: -4.259279727935791
Batch 3/64 loss: -3.9513192176818848
Batch 4/64 loss: -3.408306121826172
Batch 5/64 loss: -4.070123672485352
Batch 6/64 loss: -4.089338302612305
Batch 7/64 loss: -3.8530101776123047
Batch 8/64 loss: -4.064652919769287
Batch 9/64 loss: -3.9514060020446777
Batch 10/64 loss: -3.959660530090332
Batch 11/64 loss: -3.746556282043457
Batch 12/64 loss: -3.9959850311279297
Batch 13/64 loss: -3.969259738922119
Batch 14/64 loss: -4.043262481689453
Batch 15/64 loss: -3.832573890686035
Batch 16/64 loss: -3.8987255096435547
Batch 17/64 loss: -3.684968948364258
Batch 18/64 loss: -4.190627574920654
Batch 19/64 loss: -3.9591360092163086
Batch 20/64 loss: -3.9432320594787598
Batch 21/64 loss: -3.997685432434082
Batch 22/64 loss: -4.07635498046875
Batch 23/64 loss: -4.011638164520264
Batch 24/64 loss: -3.9684319496154785
Batch 25/64 loss: -4.0399169921875
Batch 26/64 loss: -3.825169086456299
Batch 27/64 loss: -4.131885528564453
Batch 28/64 loss: -3.9569411277770996
Batch 29/64 loss: -3.8975443840026855
Batch 30/64 loss: -3.694629669189453
Batch 31/64 loss: -3.983403205871582
Batch 32/64 loss: -3.8621273040771484
Batch 33/64 loss: -3.84266996383667
Batch 34/64 loss: -4.082486152648926
Batch 35/64 loss: -4.0896525382995605
Batch 36/64 loss: -4.151765823364258
Batch 37/64 loss: -3.9561519622802734
Batch 38/64 loss: -3.7281293869018555
Batch 39/64 loss: -3.8980255126953125
Batch 40/64 loss: -3.8698973655700684
Batch 41/64 loss: -3.6679201126098633
Batch 42/64 loss: -3.935497760772705
Batch 43/64 loss: -3.9097471237182617
Batch 44/64 loss: -4.162400722503662
Batch 45/64 loss: -3.9600701332092285
Batch 46/64 loss: -4.106639862060547
Batch 47/64 loss: -4.057167053222656
Batch 48/64 loss: -4.127983093261719
Batch 49/64 loss: -4.109842300415039
Batch 50/64 loss: -4.126476764678955
Batch 51/64 loss: -3.9348344802856445
Batch 52/64 loss: -4.010655403137207
Batch 53/64 loss: -3.991213321685791
Batch 54/64 loss: -3.515252113342285
Batch 55/64 loss: -4.266880512237549
Batch 56/64 loss: -4.097015380859375
Batch 57/64 loss: -4.2011895179748535
Batch 58/64 loss: -3.878293514251709
Batch 59/64 loss: -3.779514789581299
Batch 60/64 loss: -3.777602195739746
Batch 61/64 loss: -4.028125286102295
Batch 62/64 loss: -4.045644283294678
Batch 63/64 loss: -3.994434356689453
Batch 64/64 loss: -8.276507377624512
Epoch 385  Train loss: -4.01574613907758  Val loss: -4.396840387193608
Epoch 386
-------------------------------
Batch 1/64 loss: -3.668570041656494
Batch 2/64 loss: -3.7006993293762207
Batch 3/64 loss: -3.7976884841918945
Batch 4/64 loss: -4.060591697692871
Batch 5/64 loss: -3.9318923950195312
Batch 6/64 loss: -3.9292445182800293
Batch 7/64 loss: -4.076969146728516
Batch 8/64 loss: -3.642418384552002
Batch 9/64 loss: -3.9155430793762207
Batch 10/64 loss: -4.029521942138672
Batch 11/64 loss: -4.010708332061768
Batch 12/64 loss: -4.014664649963379
Batch 13/64 loss: -3.9863367080688477
Batch 14/64 loss: -3.830460548400879
Batch 15/64 loss: -3.9657974243164062
Batch 16/64 loss: -4.145122051239014
Batch 17/64 loss: -4.025571346282959
Batch 18/64 loss: -3.863722324371338
Batch 19/64 loss: -4.1692962646484375
Batch 20/64 loss: -4.162225246429443
Batch 21/64 loss: -3.9536237716674805
Batch 22/64 loss: -3.8217878341674805
Batch 23/64 loss: -4.089268207550049
Batch 24/64 loss: -3.424592971801758
Batch 25/64 loss: -4.127960205078125
Batch 26/64 loss: -4.003139019012451
Batch 27/64 loss: -3.7038936614990234
Batch 28/64 loss: -3.837944984436035
Batch 29/64 loss: -4.024619102478027
Batch 30/64 loss: -3.5312557220458984
Batch 31/64 loss: -4.192554473876953
Batch 32/64 loss: -4.203448295593262
Batch 33/64 loss: -3.9446535110473633
Batch 34/64 loss: -4.028366565704346
Batch 35/64 loss: -3.9713282585144043
Batch 36/64 loss: -3.6030969619750977
Batch 37/64 loss: -4.18855619430542
Batch 38/64 loss: -3.888153553009033
Batch 39/64 loss: -4.046563625335693
Batch 40/64 loss: -4.051948547363281
Batch 41/64 loss: -3.6427321434020996
Batch 42/64 loss: -4.061154842376709
Batch 43/64 loss: -3.4972314834594727
Batch 44/64 loss: -3.2075605392456055
Batch 45/64 loss: -4.020491123199463
Batch 46/64 loss: -3.757124423980713
Batch 47/64 loss: -3.933920383453369
Batch 48/64 loss: -4.166282653808594
Batch 49/64 loss: -3.8275279998779297
Batch 50/64 loss: -3.939582347869873
Batch 51/64 loss: -3.814581871032715
Batch 52/64 loss: -4.081088066101074
Batch 53/64 loss: -3.5935850143432617
Batch 54/64 loss: -4.017917633056641
Batch 55/64 loss: -4.058709144592285
Batch 56/64 loss: -4.021434783935547
Batch 57/64 loss: -3.8998093605041504
Batch 58/64 loss: -3.6640100479125977
Batch 59/64 loss: -3.793680191040039
Batch 60/64 loss: -3.891282081604004
Batch 61/64 loss: -3.658836841583252
Batch 62/64 loss: -3.2656173706054688
Batch 63/64 loss: -3.901998996734619
Batch 64/64 loss: -8.206827163696289
Epoch 386  Train loss: -3.9440796721215343  Val loss: -4.276272409969998
Epoch 387
-------------------------------
Batch 1/64 loss: -3.6977624893188477
Batch 2/64 loss: -3.753739356994629
Batch 3/64 loss: -4.077603340148926
Batch 4/64 loss: -3.907219886779785
Batch 5/64 loss: -3.6181588172912598
Batch 6/64 loss: -3.7255210876464844
Batch 7/64 loss: -3.971177577972412
Batch 8/64 loss: -3.5291481018066406
Batch 9/64 loss: -3.4716906547546387
Batch 10/64 loss: -3.9112558364868164
Batch 11/64 loss: -3.209665298461914
Batch 12/64 loss: -3.692582130432129
Batch 13/64 loss: -3.3904857635498047
Batch 14/64 loss: -3.899211883544922
Batch 15/64 loss: -3.8610587120056152
Batch 16/64 loss: -3.8770904541015625
Batch 17/64 loss: -3.328536033630371
Batch 18/64 loss: -3.6594605445861816
Batch 19/64 loss: -3.812035083770752
Batch 20/64 loss: -3.910912036895752
Batch 21/64 loss: -4.014596939086914
Batch 22/64 loss: -4.18118953704834
Batch 23/64 loss: -3.8557071685791016
Batch 24/64 loss: -3.7095112800598145
Batch 25/64 loss: -4.1880412101745605
Batch 26/64 loss: -3.8363547325134277
Batch 27/64 loss: -3.742074966430664
Batch 28/64 loss: -3.86387300491333
Batch 29/64 loss: -4.1343770027160645
Batch 30/64 loss: -3.9675865173339844
Batch 31/64 loss: -3.851654529571533
Batch 32/64 loss: -3.9854516983032227
Batch 33/64 loss: -3.802237033843994
Batch 34/64 loss: -3.7559313774108887
Batch 35/64 loss: -3.9619431495666504
Batch 36/64 loss: -3.2153453826904297
Batch 37/64 loss: -3.9899935722351074
Batch 38/64 loss: -3.6095480918884277
Batch 39/64 loss: -3.9961748123168945
Batch 40/64 loss: -4.133849143981934
Batch 41/64 loss: -3.7173399925231934
Batch 42/64 loss: -4.122755527496338
Batch 43/64 loss: -3.88063907623291
Batch 44/64 loss: -3.9018445014953613
Batch 45/64 loss: -3.3087244033813477
Batch 46/64 loss: -4.024444103240967
Batch 47/64 loss: -3.984219551086426
Batch 48/64 loss: -4.1281023025512695
Batch 49/64 loss: -3.9863076210021973
Batch 50/64 loss: -3.900139331817627
Batch 51/64 loss: -3.5447168350219727
Batch 52/64 loss: -4.100936412811279
Batch 53/64 loss: -3.5626134872436523
Batch 54/64 loss: -3.7979812622070312
Batch 55/64 loss: -3.9374680519104004
Batch 56/64 loss: -2.8842697143554688
Batch 57/64 loss: -3.986070156097412
Batch 58/64 loss: -4.063757419586182
Batch 59/64 loss: -3.2714271545410156
Batch 60/64 loss: -4.1163458824157715
Batch 61/64 loss: -3.571643829345703
Batch 62/64 loss: -4.072704792022705
Batch 63/64 loss: -4.040703773498535
Batch 64/64 loss: -8.266120910644531
Epoch 387  Train loss: -3.86203140557981  Val loss: -4.289298146041398
Epoch 388
-------------------------------
Batch 1/64 loss: -3.8204755783081055
Batch 2/64 loss: -4.146389007568359
Batch 3/64 loss: -3.3548336029052734
Batch 4/64 loss: -3.8573808670043945
Batch 5/64 loss: -4.021502494812012
Batch 6/64 loss: -3.8916430473327637
Batch 7/64 loss: -4.012434959411621
Batch 8/64 loss: -3.8661727905273438
Batch 9/64 loss: -3.8170456886291504
Batch 10/64 loss: -3.657896041870117
Batch 11/64 loss: -4.0434064865112305
Batch 12/64 loss: -3.9757070541381836
Batch 13/64 loss: -4.079233646392822
Batch 14/64 loss: -3.9917330741882324
Batch 15/64 loss: -3.885974407196045
Batch 16/64 loss: -3.830758571624756
Batch 17/64 loss: -3.5542197227478027
Batch 18/64 loss: -3.7216715812683105
Batch 19/64 loss: -3.8858537673950195
Batch 20/64 loss: -3.712590217590332
Batch 21/64 loss: -3.818671703338623
Batch 22/64 loss: -3.8546605110168457
Batch 23/64 loss: -3.9615936279296875
Batch 24/64 loss: -3.371363639831543
Batch 25/64 loss: -3.8476028442382812
Batch 26/64 loss: -3.516551971435547
Batch 27/64 loss: -3.787951946258545
Batch 28/64 loss: -3.7760047912597656
Batch 29/64 loss: -4.042325019836426
Batch 30/64 loss: -3.9294910430908203
Batch 31/64 loss: -4.068765163421631
Batch 32/64 loss: -4.004466533660889
Batch 33/64 loss: -3.9611191749572754
Batch 34/64 loss: -3.968688488006592
Batch 35/64 loss: -3.9382638931274414
Batch 36/64 loss: -3.5599365234375
Batch 37/64 loss: -4.112964153289795
Batch 38/64 loss: -3.770480155944824
Batch 39/64 loss: -3.956724166870117
Batch 40/64 loss: -4.062332630157471
Batch 41/64 loss: -3.66143798828125
Batch 42/64 loss: -3.726452350616455
Batch 43/64 loss: -4.017440319061279
Batch 44/64 loss: -3.9803714752197266
Batch 45/64 loss: -4.032397270202637
Batch 46/64 loss: -3.9318251609802246
Batch 47/64 loss: -3.5340166091918945
Batch 48/64 loss: -4.01046085357666
Batch 49/64 loss: -3.570430278778076
Batch 50/64 loss: -4.027803421020508
Batch 51/64 loss: -4.136072158813477
Batch 52/64 loss: -3.7917633056640625
Batch 53/64 loss: -4.0149030685424805
Batch 54/64 loss: -3.929080009460449
Batch 55/64 loss: -3.7131495475769043
Batch 56/64 loss: -3.957491874694824
Batch 57/64 loss: -3.5434885025024414
Batch 58/64 loss: -3.4692087173461914
Batch 59/64 loss: -3.9624757766723633
Batch 60/64 loss: -3.8935790061950684
Batch 61/64 loss: -3.9343576431274414
Batch 62/64 loss: -3.9400196075439453
Batch 63/64 loss: -3.975100517272949
Batch 64/64 loss: -8.378772735595703
Epoch 388  Train loss: -3.9133221270991307  Val loss: -4.251578655439554
Epoch 389
-------------------------------
Batch 1/64 loss: -3.8885536193847656
Batch 2/64 loss: -3.971374034881592
Batch 3/64 loss: -3.729057788848877
Batch 4/64 loss: -3.7391462326049805
Batch 5/64 loss: -3.9509568214416504
Batch 6/64 loss: -3.4506921768188477
Batch 7/64 loss: -3.8259453773498535
Batch 8/64 loss: -3.9549202919006348
Batch 9/64 loss: -3.753054141998291
Batch 10/64 loss: -3.6266984939575195
Batch 11/64 loss: -3.6318306922912598
Batch 12/64 loss: -3.930837631225586
Batch 13/64 loss: -3.9869461059570312
Batch 14/64 loss: -3.903907299041748
Batch 15/64 loss: -3.773470878601074
Batch 16/64 loss: -3.8842945098876953
Batch 17/64 loss: -3.9003801345825195
Batch 18/64 loss: -3.878314971923828
Batch 19/64 loss: -3.9344429969787598
Batch 20/64 loss: -4.022802352905273
Batch 21/64 loss: -3.9775280952453613
Batch 22/64 loss: -3.8830556869506836
Batch 23/64 loss: -3.957151412963867
Batch 24/64 loss: -3.9047021865844727
Batch 25/64 loss: -3.997636318206787
Batch 26/64 loss: -3.845043182373047
Batch 27/64 loss: -3.9445395469665527
Batch 28/64 loss: -3.8044166564941406
Batch 29/64 loss: -3.849276065826416
Batch 30/64 loss: -3.7761287689208984
Batch 31/64 loss: -3.7154908180236816
Batch 32/64 loss: -2.7876462936401367
Batch 33/64 loss: -3.902557849884033
Batch 34/64 loss: -3.4818716049194336
Batch 35/64 loss: -4.074013710021973
Batch 36/64 loss: -3.866042137145996
Batch 37/64 loss: -3.9400711059570312
Batch 38/64 loss: -4.025479793548584
Batch 39/64 loss: -3.7191123962402344
Batch 40/64 loss: -3.5659031867980957
Batch 41/64 loss: -3.757272243499756
Batch 42/64 loss: -3.754190444946289
Batch 43/64 loss: -3.9037609100341797
Batch 44/64 loss: -3.786609172821045
Batch 45/64 loss: -3.5897908210754395
Batch 46/64 loss: -3.8686184883117676
Batch 47/64 loss: -3.2104015350341797
Batch 48/64 loss: -3.8338069915771484
Batch 49/64 loss: -3.829965114593506
Batch 50/64 loss: -3.762488842010498
Batch 51/64 loss: -3.8062682151794434
Batch 52/64 loss: -3.838575839996338
Batch 53/64 loss: -3.7942147254943848
Batch 54/64 loss: -3.7020387649536133
Batch 55/64 loss: -3.901118278503418
Batch 56/64 loss: -3.9639811515808105
Batch 57/64 loss: -3.8534412384033203
Batch 58/64 loss: -4.081476211547852
Batch 59/64 loss: -4.009260177612305
Batch 60/64 loss: -3.7325363159179688
Batch 61/64 loss: -4.002166748046875
Batch 62/64 loss: -3.935476779937744
Batch 63/64 loss: -3.145878791809082
Batch 64/64 loss: -8.26650619506836
Epoch 389  Train loss: -3.8591138951918658  Val loss: -4.298660933766578
Epoch 390
-------------------------------
Batch 1/64 loss: -3.966602325439453
Batch 2/64 loss: -3.807504177093506
Batch 3/64 loss: -3.7508926391601562
Batch 4/64 loss: -4.0264177322387695
Batch 5/64 loss: -3.9283151626586914
Batch 6/64 loss: -3.7997894287109375
Batch 7/64 loss: -3.405367851257324
Batch 8/64 loss: -3.835939884185791
Batch 9/64 loss: -3.7765212059020996
Batch 10/64 loss: -3.605393886566162
Batch 11/64 loss: -3.9556846618652344
Batch 12/64 loss: -3.6236495971679688
Batch 13/64 loss: -3.9446921348571777
Batch 14/64 loss: -3.766152858734131
Batch 15/64 loss: -3.9267959594726562
Batch 16/64 loss: -3.907073497772217
Batch 17/64 loss: -4.100671768188477
Batch 18/64 loss: -3.210683822631836
Batch 19/64 loss: -3.806192398071289
Batch 20/64 loss: -3.980931282043457
Batch 21/64 loss: -3.987736701965332
Batch 22/64 loss: -4.016476154327393
Batch 23/64 loss: -4.042721748352051
Batch 24/64 loss: -3.86708402633667
Batch 25/64 loss: -3.7047319412231445
Batch 26/64 loss: -3.8720641136169434
Batch 27/64 loss: -3.922882556915283
Batch 28/64 loss: -3.4421844482421875
Batch 29/64 loss: -3.8905630111694336
Batch 30/64 loss: -4.060003280639648
Batch 31/64 loss: -3.844299793243408
Batch 32/64 loss: -3.8516736030578613
Batch 33/64 loss: -3.7235183715820312
Batch 34/64 loss: -3.6681337356567383
Batch 35/64 loss: -3.750368118286133
Batch 36/64 loss: -4.0219573974609375
Batch 37/64 loss: -3.7653026580810547
Batch 38/64 loss: -3.8869147300720215
Batch 39/64 loss: -3.4964218139648438
Batch 40/64 loss: -3.7979907989501953
Batch 41/64 loss: -3.8316283226013184
Batch 42/64 loss: -3.943403720855713
Batch 43/64 loss: -3.762240409851074
Batch 44/64 loss: -4.047257423400879
Batch 45/64 loss: -3.697296619415283
Batch 46/64 loss: -4.011592864990234
Batch 47/64 loss: -4.067475318908691
Batch 48/64 loss: -4.000374794006348
Batch 49/64 loss: -3.8480281829833984
Batch 50/64 loss: -4.048962593078613
Batch 51/64 loss: -3.603365898132324
Batch 52/64 loss: -3.984342575073242
Batch 53/64 loss: -3.98478364944458
Batch 54/64 loss: -3.975465774536133
Batch 55/64 loss: -3.738008499145508
Batch 56/64 loss: -4.086154460906982
Batch 57/64 loss: -4.083914279937744
Batch 58/64 loss: -3.592581272125244
Batch 59/64 loss: -3.803396701812744
Batch 60/64 loss: -3.2752323150634766
Batch 61/64 loss: -3.732916831970215
Batch 62/64 loss: -3.864020824432373
Batch 63/64 loss: -3.905489444732666
Batch 64/64 loss: -8.271209716796875
Epoch 390  Train loss: -3.887523785759421  Val loss: -4.242501694721864
Epoch 391
-------------------------------
Batch 1/64 loss: -3.8497238159179688
Batch 2/64 loss: -3.69429874420166
Batch 3/64 loss: -3.884962558746338
Batch 4/64 loss: -3.987916946411133
Batch 5/64 loss: -3.7162508964538574
Batch 6/64 loss: -3.7858357429504395
Batch 7/64 loss: -4.048834323883057
Batch 8/64 loss: -3.8013200759887695
Batch 9/64 loss: -3.8066658973693848
Batch 10/64 loss: -3.9821033477783203
Batch 11/64 loss: -3.8596267700195312
Batch 12/64 loss: -3.5978732109069824
Batch 13/64 loss: -3.39351749420166
Batch 14/64 loss: -3.6579713821411133
Batch 15/64 loss: -3.953765392303467
Batch 16/64 loss: -3.9607343673706055
Batch 17/64 loss: -3.8630967140197754
Batch 18/64 loss: -3.737812042236328
Batch 19/64 loss: -3.500412940979004
Batch 20/64 loss: -3.6872572898864746
Batch 21/64 loss: -3.8892107009887695
Batch 22/64 loss: -3.834221839904785
Batch 23/64 loss: -3.672971725463867
Batch 24/64 loss: -3.6872596740722656
Batch 25/64 loss: -3.752758026123047
Batch 26/64 loss: -3.786734104156494
Batch 27/64 loss: -3.85703706741333
Batch 28/64 loss: -3.837730884552002
Batch 29/64 loss: -3.89992094039917
Batch 30/64 loss: -3.2403573989868164
Batch 31/64 loss: -3.7934794425964355
Batch 32/64 loss: -3.9148526191711426
Batch 33/64 loss: -3.2840394973754883
Batch 34/64 loss: -3.6982569694519043
Batch 35/64 loss: -3.7271385192871094
Batch 36/64 loss: -3.757359027862549
Batch 37/64 loss: -3.817225933074951
Batch 38/64 loss: -3.8699498176574707
Batch 39/64 loss: -3.6735167503356934
Batch 40/64 loss: -3.6827707290649414
Batch 41/64 loss: -3.935579776763916
Batch 42/64 loss: -3.9917378425598145
Batch 43/64 loss: -3.7921323776245117
Batch 44/64 loss: -3.9741158485412598
Batch 45/64 loss: -3.8017001152038574
Batch 46/64 loss: -3.9011425971984863
Batch 47/64 loss: -3.9535374641418457
Batch 48/64 loss: -3.961472988128662
Batch 49/64 loss: -3.313995361328125
Batch 50/64 loss: -3.7861857414245605
Batch 51/64 loss: -3.718806266784668
Batch 52/64 loss: -3.806307315826416
Batch 53/64 loss: -3.922598361968994
Batch 54/64 loss: -3.660637855529785
Batch 55/64 loss: -3.5804572105407715
Batch 56/64 loss: -3.8354458808898926
Batch 57/64 loss: -3.894045829772949
Batch 58/64 loss: -3.8994717597961426
Batch 59/64 loss: -3.598189353942871
Batch 60/64 loss: -3.933159828186035
Batch 61/64 loss: -3.600461006164551
Batch 62/64 loss: -3.7581472396850586
Batch 63/64 loss: -3.7947983741760254
Batch 64/64 loss: -8.344165802001953
Epoch 391  Train loss: -3.8293179979511334  Val loss: -4.197117677668936
Epoch 392
-------------------------------
Batch 1/64 loss: -3.8632311820983887
Batch 2/64 loss: -3.778715133666992
Batch 3/64 loss: -3.6271233558654785
Batch 4/64 loss: -3.9510183334350586
Batch 5/64 loss: -3.662003993988037
Batch 6/64 loss: -3.5931739807128906
Batch 7/64 loss: -3.623387336730957
Batch 8/64 loss: -3.7787013053894043
Batch 9/64 loss: -3.979215621948242
Batch 10/64 loss: -3.2291603088378906
Batch 11/64 loss: -3.3083267211914062
Batch 12/64 loss: -3.9798898696899414
Batch 13/64 loss: -3.96597957611084
Batch 14/64 loss: -3.9486308097839355
Batch 15/64 loss: -3.8009748458862305
Batch 16/64 loss: -3.7813310623168945
Batch 17/64 loss: -3.9701900482177734
Batch 18/64 loss: -3.9947328567504883
Batch 19/64 loss: -3.9649391174316406
Batch 20/64 loss: -3.8653182983398438
Batch 21/64 loss: -3.923686981201172
Batch 22/64 loss: -3.072920799255371
Batch 23/64 loss: -3.6790995597839355
Batch 24/64 loss: -4.016605377197266
Batch 25/64 loss: -3.767301559448242
Batch 26/64 loss: -3.5377750396728516
Batch 27/64 loss: -3.560727596282959
Batch 28/64 loss: -3.825925350189209
Batch 29/64 loss: -3.6479711532592773
Batch 30/64 loss: -3.9918370246887207
Batch 31/64 loss: -3.9304561614990234
Batch 32/64 loss: -3.3240909576416016
Batch 33/64 loss: -3.817221164703369
Batch 34/64 loss: -3.733151435852051
Batch 35/64 loss: -3.9142837524414062
Batch 36/64 loss: -3.6669087409973145
Batch 37/64 loss: -3.864319324493408
Batch 38/64 loss: -3.4621801376342773
Batch 39/64 loss: -3.9104385375976562
Batch 40/64 loss: -3.784824848175049
Batch 41/64 loss: -3.7433786392211914
Batch 42/64 loss: -3.822519302368164
Batch 43/64 loss: -3.7638349533081055
Batch 44/64 loss: -3.7275004386901855
Batch 45/64 loss: -3.6332688331604004
Batch 46/64 loss: -3.8839316368103027
Batch 47/64 loss: -3.759133815765381
Batch 48/64 loss: -3.555018901824951
Batch 49/64 loss: -3.875030517578125
Batch 50/64 loss: -3.846378803253174
Batch 51/64 loss: -3.9935402870178223
Batch 52/64 loss: -3.6546268463134766
Batch 53/64 loss: -3.845184803009033
Batch 54/64 loss: -3.9912843704223633
Batch 55/64 loss: -3.7729363441467285
Batch 56/64 loss: -3.6189117431640625
Batch 57/64 loss: -3.909092903137207
Batch 58/64 loss: -3.954911231994629
Batch 59/64 loss: -3.8468165397644043
Batch 60/64 loss: -3.295130729675293
Batch 61/64 loss: -3.9691309928894043
Batch 62/64 loss: -3.835026741027832
Batch 63/64 loss: -3.815173625946045
Batch 64/64 loss: -8.42724609375
Epoch 392  Train loss: -3.820077911077761  Val loss: -4.175662024324293
Epoch 393
-------------------------------
Batch 1/64 loss: -3.920405387878418
Batch 2/64 loss: -3.9686012268066406
Batch 3/64 loss: -3.8701224327087402
Batch 4/64 loss: -3.4872941970825195
Batch 5/64 loss: -3.7122550010681152
Batch 6/64 loss: -3.7506256103515625
Batch 7/64 loss: -3.7329354286193848
Batch 8/64 loss: -3.8342032432556152
Batch 9/64 loss: -4.025625705718994
Batch 10/64 loss: -3.9109716415405273
Batch 11/64 loss: -3.818439483642578
Batch 12/64 loss: -3.6277074813842773
Batch 13/64 loss: -3.6698508262634277
Batch 14/64 loss: -3.9264421463012695
Batch 15/64 loss: -3.786479949951172
Batch 16/64 loss: -3.819852352142334
Batch 17/64 loss: -3.716055393218994
Batch 18/64 loss: -3.888777256011963
Batch 19/64 loss: -3.8316664695739746
Batch 20/64 loss: -4.058257102966309
Batch 21/64 loss: -3.964909076690674
Batch 22/64 loss: -3.489190101623535
Batch 23/64 loss: -3.5988903045654297
Batch 24/64 loss: -3.943009376525879
Batch 25/64 loss: -3.9541378021240234
Batch 26/64 loss: -3.9992918968200684
Batch 27/64 loss: -4.038936138153076
Batch 28/64 loss: -3.974177837371826
Batch 29/64 loss: -4.0936808586120605
Batch 30/64 loss: -3.6297402381896973
Batch 31/64 loss: -3.9753355979919434
Batch 32/64 loss: -4.160727500915527
Batch 33/64 loss: -3.8327603340148926
Batch 34/64 loss: -3.7671332359313965
Batch 35/64 loss: -3.945816993713379
Batch 36/64 loss: -3.8118395805358887
Batch 37/64 loss: -4.063767910003662
Batch 38/64 loss: -3.9452624320983887
Batch 39/64 loss: -4.040128707885742
Batch 40/64 loss: -4.1522650718688965
Batch 41/64 loss: -4.005194664001465
Batch 42/64 loss: -3.840330123901367
Batch 43/64 loss: -4.01563024520874
Batch 44/64 loss: -3.755791187286377
Batch 45/64 loss: -4.022768974304199
Batch 46/64 loss: -3.139897346496582
Batch 47/64 loss: -4.065260887145996
Batch 48/64 loss: -3.982117176055908
Batch 49/64 loss: -3.8263134956359863
Batch 50/64 loss: -4.186458110809326
Batch 51/64 loss: -3.96159029006958
Batch 52/64 loss: -3.9615893363952637
Batch 53/64 loss: -4.1678338050842285
Batch 54/64 loss: -3.4369430541992188
Batch 55/64 loss: -4.097174644470215
Batch 56/64 loss: -3.8317627906799316
Batch 57/64 loss: -3.871953010559082
Batch 58/64 loss: -3.82493257522583
Batch 59/64 loss: -3.8578171730041504
Batch 60/64 loss: -4.064529895782471
Batch 61/64 loss: -3.608830451965332
Batch 62/64 loss: -3.8721671104431152
Batch 63/64 loss: -4.023613929748535
Batch 64/64 loss: -8.377004623413086
Epoch 393  Train loss: -3.9284834992651847  Val loss: -4.417728686250772
Epoch 394
-------------------------------
Batch 1/64 loss: -4.048374176025391
Batch 2/64 loss: -3.6711225509643555
Batch 3/64 loss: -4.153560638427734
Batch 4/64 loss: -3.749605178833008
Batch 5/64 loss: -4.094818592071533
Batch 6/64 loss: -4.026178359985352
Batch 7/64 loss: -3.9681458473205566
Batch 8/64 loss: -4.2349090576171875
Batch 9/64 loss: -4.133029460906982
Batch 10/64 loss: -3.94718074798584
Batch 11/64 loss: -3.813643455505371
Batch 12/64 loss: -4.081108093261719
Batch 13/64 loss: -3.995748519897461
Batch 14/64 loss: -3.8881125450134277
Batch 15/64 loss: -3.9790353775024414
Batch 16/64 loss: -4.116842269897461
Batch 17/64 loss: -3.955061912536621
Batch 18/64 loss: -3.769585132598877
Batch 19/64 loss: -3.9760122299194336
Batch 20/64 loss: -4.097326278686523
Batch 21/64 loss: -4.144914627075195
Batch 22/64 loss: -3.886826992034912
Batch 23/64 loss: -3.9428701400756836
Batch 24/64 loss: -3.9531326293945312
Batch 25/64 loss: -4.023829936981201
Batch 26/64 loss: -4.069380760192871
Batch 27/64 loss: -3.8686347007751465
Batch 28/64 loss: -3.966771125793457
Batch 29/64 loss: -4.04843807220459
Batch 30/64 loss: -3.8974857330322266
Batch 31/64 loss: -4.0760979652404785
Batch 32/64 loss: -4.131189823150635
Batch 33/64 loss: -4.106945991516113
Batch 34/64 loss: -3.9078149795532227
Batch 35/64 loss: -4.154130935668945
Batch 36/64 loss: -3.5982375144958496
Batch 37/64 loss: -3.9359254837036133
Batch 38/64 loss: -4.15727424621582
Batch 39/64 loss: -3.9708023071289062
Batch 40/64 loss: -3.8566818237304688
Batch 41/64 loss: -3.9744815826416016
Batch 42/64 loss: -4.056633472442627
Batch 43/64 loss: -3.881214141845703
Batch 44/64 loss: -3.259084701538086
Batch 45/64 loss: -3.957174301147461
Batch 46/64 loss: -4.052855491638184
Batch 47/64 loss: -3.9750490188598633
Batch 48/64 loss: -3.975224018096924
Batch 49/64 loss: -3.90224027633667
Batch 50/64 loss: -3.83505916595459
Batch 51/64 loss: -3.807514190673828
Batch 52/64 loss: -3.9453930854797363
Batch 53/64 loss: -3.9548535346984863
Batch 54/64 loss: -4.075262546539307
Batch 55/64 loss: -3.894184112548828
Batch 56/64 loss: -3.7786059379577637
Batch 57/64 loss: -3.947385311126709
Batch 58/64 loss: -3.4726762771606445
Batch 59/64 loss: -3.891087532043457
Batch 60/64 loss: -3.8191699981689453
Batch 61/64 loss: -3.6121397018432617
Batch 62/64 loss: -3.1429309844970703
Batch 63/64 loss: -3.644653797149658
Batch 64/64 loss: -8.506474494934082
Epoch 394  Train loss: -3.978533572776645  Val loss: -4.334284582498557
Epoch 395
-------------------------------
Batch 1/64 loss: -3.766745090484619
Batch 2/64 loss: -4.0207295417785645
Batch 3/64 loss: -4.04188346862793
Batch 4/64 loss: -3.953428268432617
Batch 5/64 loss: -3.601508140563965
Batch 6/64 loss: -4.058701038360596
Batch 7/64 loss: -3.798470973968506
Batch 8/64 loss: -3.767709732055664
Batch 9/64 loss: -3.9885611534118652
Batch 10/64 loss: -3.8602733612060547
Batch 11/64 loss: -3.8618335723876953
Batch 12/64 loss: -3.805202007293701
Batch 13/64 loss: -3.9787826538085938
Batch 14/64 loss: -3.5225210189819336
Batch 15/64 loss: -3.8191518783569336
Batch 16/64 loss: -4.053435325622559
Batch 17/64 loss: -3.6859865188598633
Batch 18/64 loss: -3.6081371307373047
Batch 19/64 loss: -3.467013359069824
Batch 20/64 loss: -4.006636142730713
Batch 21/64 loss: -3.676856517791748
Batch 22/64 loss: -3.9246959686279297
Batch 23/64 loss: -3.9737014770507812
Batch 24/64 loss: -4.01514196395874
Batch 25/64 loss: -4.05815315246582
Batch 26/64 loss: -3.781588077545166
Batch 27/64 loss: -3.983625888824463
Batch 28/64 loss: -3.7570600509643555
Batch 29/64 loss: -3.583571434020996
Batch 30/64 loss: -3.8423919677734375
Batch 31/64 loss: -4.007351398468018
Batch 32/64 loss: -4.049120903015137
Batch 33/64 loss: -4.025062084197998
Batch 34/64 loss: -4.203564167022705
Batch 35/64 loss: -3.9992923736572266
Batch 36/64 loss: -3.8679141998291016
Batch 37/64 loss: -4.098371505737305
Batch 38/64 loss: -4.051537990570068
Batch 39/64 loss: -4.0197649002075195
Batch 40/64 loss: -4.0820441246032715
Batch 41/64 loss: -4.241180419921875
Batch 42/64 loss: -3.922107696533203
Batch 43/64 loss: -4.0500030517578125
Batch 44/64 loss: -3.9826178550720215
Batch 45/64 loss: -3.5608510971069336
Batch 46/64 loss: -4.12617301940918
Batch 47/64 loss: -4.057322025299072
Batch 48/64 loss: -4.045977592468262
Batch 49/64 loss: -4.056464672088623
Batch 50/64 loss: -3.3682613372802734
Batch 51/64 loss: -4.134057998657227
Batch 52/64 loss: -4.087090492248535
Batch 53/64 loss: -4.1262078285217285
Batch 54/64 loss: -4.000057220458984
Batch 55/64 loss: -3.844925880432129
Batch 56/64 loss: -3.898949146270752
Batch 57/64 loss: -4.074845314025879
Batch 58/64 loss: -4.1066107749938965
Batch 59/64 loss: -3.948118209838867
Batch 60/64 loss: -3.927170753479004
Batch 61/64 loss: -4.089470386505127
Batch 62/64 loss: -3.930593490600586
Batch 63/64 loss: -4.096677303314209
Batch 64/64 loss: -8.500502586364746
Epoch 395  Train loss: -3.979900094574573  Val loss: -4.42502103720334
Epoch 396
-------------------------------
Batch 1/64 loss: -3.939136028289795
Batch 2/64 loss: -4.041543483734131
Batch 3/64 loss: -4.123471260070801
Batch 4/64 loss: -4.147309303283691
Batch 5/64 loss: -3.8512558937072754
Batch 6/64 loss: -3.5259780883789062
Batch 7/64 loss: -3.773488998413086
Batch 8/64 loss: -3.9875354766845703
Batch 9/64 loss: -4.005563259124756
Batch 10/64 loss: -3.8089027404785156
Batch 11/64 loss: -3.8404836654663086
Batch 12/64 loss: -4.101603031158447
Batch 13/64 loss: -3.9462809562683105
Batch 14/64 loss: -3.899601459503174
Batch 15/64 loss: -4.012309551239014
Batch 16/64 loss: -3.6982598304748535
Batch 17/64 loss: -4.012259006500244
Batch 18/64 loss: -3.989048957824707
Batch 19/64 loss: -3.378933906555176
Batch 20/64 loss: -4.041751861572266
Batch 21/64 loss: -3.9420104026794434
Batch 22/64 loss: -3.9563632011413574
Batch 23/64 loss: -3.792881488800049
Batch 24/64 loss: -3.733339786529541
Batch 25/64 loss: -4.070186614990234
Batch 26/64 loss: -3.590786933898926
Batch 27/64 loss: -4.060779094696045
Batch 28/64 loss: -3.9318509101867676
Batch 29/64 loss: -3.874190330505371
Batch 30/64 loss: -3.562380313873291
Batch 31/64 loss: -3.895064353942871
Batch 32/64 loss: -3.938253402709961
Batch 33/64 loss: -3.5420966148376465
Batch 34/64 loss: -3.5229272842407227
Batch 35/64 loss: -3.7861146926879883
Batch 36/64 loss: -3.7870969772338867
Batch 37/64 loss: -3.9693994522094727
Batch 38/64 loss: -3.9077372550964355
Batch 39/64 loss: -3.456997871398926
Batch 40/64 loss: -3.9769086837768555
Batch 41/64 loss: -3.5911178588867188
Batch 42/64 loss: -3.920943260192871
Batch 43/64 loss: -3.8855433464050293
Batch 44/64 loss: -3.6970667839050293
Batch 45/64 loss: -4.0626959800720215
Batch 46/64 loss: -3.8840861320495605
Batch 47/64 loss: -4.013643264770508
Batch 48/64 loss: -3.6889867782592773
Batch 49/64 loss: -3.897991180419922
Batch 50/64 loss: -3.760899543762207
Batch 51/64 loss: -3.9557862281799316
Batch 52/64 loss: -3.800551414489746
Batch 53/64 loss: -4.076146602630615
Batch 54/64 loss: -3.91359281539917
Batch 55/64 loss: -3.7831616401672363
Batch 56/64 loss: -3.859341621398926
Batch 57/64 loss: -3.7731809616088867
Batch 58/64 loss: -3.8378663063049316
Batch 59/64 loss: -3.7404685020446777
Batch 60/64 loss: -3.866306781768799
Batch 61/64 loss: -3.8513903617858887
Batch 62/64 loss: -3.9440550804138184
Batch 63/64 loss: -3.844165802001953
Batch 64/64 loss: -8.51628589630127
Epoch 396  Train loss: -3.913071138718549  Val loss: -4.236978956923862
Epoch 397
-------------------------------
Batch 1/64 loss: -4.012301445007324
Batch 2/64 loss: -3.8687777519226074
Batch 3/64 loss: -3.9115896224975586
Batch 4/64 loss: -3.8736395835876465
Batch 5/64 loss: -3.8419189453125
Batch 6/64 loss: -4.146090030670166
Batch 7/64 loss: -3.8072218894958496
Batch 8/64 loss: -3.95350980758667
Batch 9/64 loss: -3.8935070037841797
Batch 10/64 loss: -3.9037370681762695
Batch 11/64 loss: -3.774423599243164
Batch 12/64 loss: -3.9863743782043457
Batch 13/64 loss: -4.1994218826293945
Batch 14/64 loss: -3.700324535369873
Batch 15/64 loss: -3.68890380859375
Batch 16/64 loss: -3.855587959289551
Batch 17/64 loss: -3.9304394721984863
Batch 18/64 loss: -3.8063559532165527
Batch 19/64 loss: -3.5325369834899902
Batch 20/64 loss: -3.6736526489257812
Batch 21/64 loss: -3.8325281143188477
Batch 22/64 loss: -4.0190911293029785
Batch 23/64 loss: -4.067523956298828
Batch 24/64 loss: -3.8393607139587402
Batch 25/64 loss: -3.867842674255371
Batch 26/64 loss: -3.7509994506835938
Batch 27/64 loss: -3.9254674911499023
Batch 28/64 loss: -3.714962959289551
Batch 29/64 loss: -3.946707248687744
Batch 30/64 loss: -3.7529735565185547
Batch 31/64 loss: -3.6087307929992676
Batch 32/64 loss: -3.955371379852295
Batch 33/64 loss: -3.8572797775268555
Batch 34/64 loss: -3.99721097946167
Batch 35/64 loss: -3.814566135406494
Batch 36/64 loss: -3.657949447631836
Batch 37/64 loss: -4.158271312713623
Batch 38/64 loss: -3.7008228302001953
Batch 39/64 loss: -3.9840431213378906
Batch 40/64 loss: -3.8363099098205566
Batch 41/64 loss: -3.883596420288086
Batch 42/64 loss: -3.5655980110168457
Batch 43/64 loss: -4.054649829864502
Batch 44/64 loss: -3.875814914703369
Batch 45/64 loss: -3.8834242820739746
Batch 46/64 loss: -3.642800807952881
Batch 47/64 loss: -4.0230889320373535
Batch 48/64 loss: -4.019382953643799
Batch 49/64 loss: -3.960634231567383
Batch 50/64 loss: -3.8885607719421387
Batch 51/64 loss: -4.102221488952637
Batch 52/64 loss: -3.856072425842285
Batch 53/64 loss: -3.6325182914733887
Batch 54/64 loss: -3.9359383583068848
Batch 55/64 loss: -4.162961483001709
Batch 56/64 loss: -3.962527275085449
Batch 57/64 loss: -3.887476921081543
Batch 58/64 loss: -3.892882823944092
Batch 59/64 loss: -3.908377170562744
Batch 60/64 loss: -4.000373363494873
Batch 61/64 loss: -3.840717315673828
Batch 62/64 loss: -4.037013530731201
Batch 63/64 loss: -3.8225255012512207
Batch 64/64 loss: -8.439144134521484
Epoch 397  Train loss: -3.9343818440156824  Val loss: -4.384612814257645
Epoch 398
-------------------------------
Batch 1/64 loss: -3.9509668350219727
Batch 2/64 loss: -4.049465656280518
Batch 3/64 loss: -3.8760409355163574
Batch 4/64 loss: -4.031373977661133
Batch 5/64 loss: -4.000101566314697
Batch 6/64 loss: -4.114372730255127
Batch 7/64 loss: -3.7637176513671875
Batch 8/64 loss: -3.8458986282348633
Batch 9/64 loss: -4.14774751663208
Batch 10/64 loss: -4.127843856811523
Batch 11/64 loss: -4.052768230438232
Batch 12/64 loss: -3.961796760559082
Batch 13/64 loss: -4.100785255432129
Batch 14/64 loss: -3.918055534362793
Batch 15/64 loss: -3.784235954284668
Batch 16/64 loss: -3.538379669189453
Batch 17/64 loss: -4.042685031890869
Batch 18/64 loss: -3.870110034942627
Batch 19/64 loss: -4.076299667358398
Batch 20/64 loss: -3.8933777809143066
Batch 21/64 loss: -4.023578643798828
Batch 22/64 loss: -4.013143539428711
Batch 23/64 loss: -3.9877610206604004
Batch 24/64 loss: -3.820796012878418
Batch 25/64 loss: -3.497878074645996
Batch 26/64 loss: -3.928992748260498
Batch 27/64 loss: -3.987058162689209
Batch 28/64 loss: -4.061918258666992
Batch 29/64 loss: -4.0164794921875
Batch 30/64 loss: -3.7418289184570312
Batch 31/64 loss: -4.13492488861084
Batch 32/64 loss: -4.226320266723633
Batch 33/64 loss: -3.5991358757019043
Batch 34/64 loss: -3.9228477478027344
Batch 35/64 loss: -4.150801181793213
Batch 36/64 loss: -3.864513874053955
Batch 37/64 loss: -4.101796627044678
Batch 38/64 loss: -4.115427017211914
Batch 39/64 loss: -4.07358980178833
Batch 40/64 loss: -2.915529251098633
Batch 41/64 loss: -4.139459133148193
Batch 42/64 loss: -3.8131699562072754
Batch 43/64 loss: -4.203352451324463
Batch 44/64 loss: -4.064034938812256
Batch 45/64 loss: -3.955197334289551
Batch 46/64 loss: -4.154302597045898
Batch 47/64 loss: -3.951141834259033
Batch 48/64 loss: -3.5287866592407227
Batch 49/64 loss: -4.135269641876221
Batch 50/64 loss: -3.830345630645752
Batch 51/64 loss: -3.9659533500671387
Batch 52/64 loss: -4.1431474685668945
Batch 53/64 loss: -4.093260288238525
Batch 54/64 loss: -3.8838891983032227
Batch 55/64 loss: -3.753406524658203
Batch 56/64 loss: -3.960297107696533
Batch 57/64 loss: -4.099358081817627
Batch 58/64 loss: -4.056812286376953
Batch 59/64 loss: -4.038198471069336
Batch 60/64 loss: -4.060887813568115
Batch 61/64 loss: -3.9247350692749023
Batch 62/64 loss: -4.069916725158691
Batch 63/64 loss: -3.989591121673584
Batch 64/64 loss: -8.51030158996582
Epoch 398  Train loss: -4.008275836121802  Val loss: -4.425867742689205
Epoch 399
-------------------------------
Batch 1/64 loss: -4.043531894683838
Batch 2/64 loss: -4.153650283813477
Batch 3/64 loss: -4.151266574859619
Batch 4/64 loss: -3.7237205505371094
Batch 5/64 loss: -3.2107772827148438
Batch 6/64 loss: -4.094967365264893
Batch 7/64 loss: -4.079920291900635
Batch 8/64 loss: -3.9364757537841797
Batch 9/64 loss: -4.07877254486084
Batch 10/64 loss: -3.9552974700927734
Batch 11/64 loss: -4.069392681121826
Batch 12/64 loss: -3.5756983757019043
Batch 13/64 loss: -3.914991855621338
Batch 14/64 loss: -3.7557730674743652
Batch 15/64 loss: -3.985121726989746
Batch 16/64 loss: -4.075475215911865
Batch 17/64 loss: -3.937471389770508
Batch 18/64 loss: -4.1627516746521
Batch 19/64 loss: -3.775271415710449
Batch 20/64 loss: -3.7910475730895996
Batch 21/64 loss: -3.7566542625427246
Batch 22/64 loss: -3.635587215423584
Batch 23/64 loss: -3.9388890266418457
Batch 24/64 loss: -4.052859783172607
Batch 25/64 loss: -4.05457878112793
Batch 26/64 loss: -3.7841367721557617
Batch 27/64 loss: -4.020432949066162
Batch 28/64 loss: -4.0486674308776855
Batch 29/64 loss: -4.007162570953369
Batch 30/64 loss: -3.9748153686523438
Batch 31/64 loss: -4.1270623207092285
Batch 32/64 loss: -3.6914920806884766
Batch 33/64 loss: -4.085206508636475
Batch 34/64 loss: -4.054688453674316
Batch 35/64 loss: -4.033405303955078
Batch 36/64 loss: -3.86637020111084
Batch 37/64 loss: -3.882406711578369
Batch 38/64 loss: -4.1483259201049805
Batch 39/64 loss: -4.172665119171143
Batch 40/64 loss: -3.9768714904785156
Batch 41/64 loss: -3.897120952606201
Batch 42/64 loss: -3.5893540382385254
Batch 43/64 loss: -4.031601428985596
Batch 44/64 loss: -4.025819778442383
Batch 45/64 loss: -4.070973873138428
Batch 46/64 loss: -4.052871227264404
Batch 47/64 loss: -3.879277229309082
Batch 48/64 loss: -4.137806415557861
Batch 49/64 loss: -3.857593536376953
Batch 50/64 loss: -4.032402038574219
Batch 51/64 loss: -4.014194488525391
Batch 52/64 loss: -3.9711270332336426
Batch 53/64 loss: -4.206859588623047
Batch 54/64 loss: -3.9261631965637207
Batch 55/64 loss: -4.165917873382568
Batch 56/64 loss: -3.9337968826293945
Batch 57/64 loss: -3.649174690246582
Batch 58/64 loss: -3.741931438446045
Batch 59/64 loss: -4.041003227233887
Batch 60/64 loss: -3.0346174240112305
Batch 61/64 loss: -4.032310485839844
Batch 62/64 loss: -3.9011712074279785
Batch 63/64 loss: -3.881248950958252
Batch 64/64 loss: -8.314863204956055
Epoch 399  Train loss: -3.9857903948017195  Val loss: -4.45370607933228
Epoch 400
-------------------------------
Batch 1/64 loss: -4.07666015625
Batch 2/64 loss: -4.243804931640625
Batch 3/64 loss: -4.091067790985107
Batch 4/64 loss: -4.178210258483887
Batch 5/64 loss: -4.1182026863098145
Batch 6/64 loss: -4.0430498123168945
Batch 7/64 loss: -4.13671875
Batch 8/64 loss: -4.041351795196533
Batch 9/64 loss: -4.234827518463135
Batch 10/64 loss: -3.8923215866088867
Batch 11/64 loss: -4.007792949676514
Batch 12/64 loss: -3.914684295654297
Batch 13/64 loss: -3.837502956390381
Batch 14/64 loss: -3.752408027648926
Batch 15/64 loss: -3.975806713104248
Batch 16/64 loss: -3.8522191047668457
Batch 17/64 loss: -3.973254680633545
Batch 18/64 loss: -4.128214359283447
Batch 19/64 loss: -3.629154682159424
Batch 20/64 loss: -3.9481077194213867
Batch 21/64 loss: -3.6673688888549805
Batch 22/64 loss: -4.023797988891602
Batch 23/64 loss: -4.195873737335205
Batch 24/64 loss: -3.7771968841552734
Batch 25/64 loss: -4.038784980773926
Batch 26/64 loss: -3.9229660034179688
Batch 27/64 loss: -4.232603073120117
Batch 28/64 loss: -4.035223960876465
Batch 29/64 loss: -4.151047706604004
Batch 30/64 loss: -3.652770519256592
Batch 31/64 loss: -4.145349025726318
Batch 32/64 loss: -3.988345146179199
Batch 33/64 loss: -4.175881385803223
Batch 34/64 loss: -4.113864898681641
Batch 35/64 loss: -4.098095417022705
Batch 36/64 loss: -3.995882987976074
Batch 37/64 loss: -4.165090560913086
Batch 38/64 loss: -3.7936978340148926
Batch 39/64 loss: -4.046067714691162
Batch 40/64 loss: -4.025502681732178
Batch 41/64 loss: -4.085958003997803
Batch 42/64 loss: -4.133272171020508
Batch 43/64 loss: -4.067162990570068
Batch 44/64 loss: -3.9339547157287598
Batch 45/64 loss: -3.888726234436035
Batch 46/64 loss: -3.9377565383911133
Batch 47/64 loss: -3.9825453758239746
Batch 48/64 loss: -3.861025333404541
Batch 49/64 loss: -3.545558452606201
Batch 50/64 loss: -3.9757351875305176
Batch 51/64 loss: -4.229597568511963
Batch 52/64 loss: -3.950122833251953
Batch 53/64 loss: -4.035195350646973
Batch 54/64 loss: -4.105076789855957
Batch 55/64 loss: -3.8606462478637695
Batch 56/64 loss: -4.0422821044921875
Batch 57/64 loss: -3.986180305480957
Batch 58/64 loss: -3.929927349090576
Batch 59/64 loss: -4.093760013580322
Batch 60/64 loss: -3.9769887924194336
Batch 61/64 loss: -3.71403169631958
Batch 62/64 loss: -3.864278793334961
Batch 63/64 loss: -3.786871910095215
Batch 64/64 loss: -8.526334762573242
Epoch 400  Train loss: -4.042387105904374  Val loss: -4.408713599660552
Epoch 401
-------------------------------
Batch 1/64 loss: -4.120389461517334
Batch 2/64 loss: -3.67830228805542
Batch 3/64 loss: -4.010218620300293
Batch 4/64 loss: -3.9808402061462402
Batch 5/64 loss: -3.9292755126953125
Batch 6/64 loss: -4.093392372131348
Batch 7/64 loss: -4.169997692108154
Batch 8/64 loss: -3.8889455795288086
Batch 9/64 loss: -3.947263240814209
Batch 10/64 loss: -3.7804994583129883
Batch 11/64 loss: -3.8738527297973633
Batch 12/64 loss: -3.9625301361083984
Batch 13/64 loss: -3.9963998794555664
Batch 14/64 loss: -3.917055130004883
Batch 15/64 loss: -3.9026451110839844
Batch 16/64 loss: -3.9431710243225098
Batch 17/64 loss: -4.102992057800293
Batch 18/64 loss: -4.1788434982299805
Batch 19/64 loss: -3.5885839462280273
Batch 20/64 loss: -4.005645275115967
Batch 21/64 loss: -4.031825065612793
Batch 22/64 loss: -3.977747917175293
Batch 23/64 loss: -3.8171591758728027
Batch 24/64 loss: -4.216818332672119
Batch 25/64 loss: -4.144697666168213
Batch 26/64 loss: -4.055408954620361
Batch 27/64 loss: -3.9756908416748047
Batch 28/64 loss: -3.9182753562927246
Batch 29/64 loss: -4.08748197555542
Batch 30/64 loss: -4.184821128845215
Batch 31/64 loss: -4.04367733001709
Batch 32/64 loss: -3.8953914642333984
Batch 33/64 loss: -4.021806716918945
Batch 34/64 loss: -4.228173732757568
Batch 35/64 loss: -4.052829742431641
Batch 36/64 loss: -3.9243383407592773
Batch 37/64 loss: -3.945829391479492
Batch 38/64 loss: -4.005671977996826
Batch 39/64 loss: -4.004310131072998
Batch 40/64 loss: -3.9394607543945312
Batch 41/64 loss: -3.4722747802734375
Batch 42/64 loss: -3.7416296005249023
Batch 43/64 loss: -3.719466209411621
Batch 44/64 loss: -3.665773868560791
Batch 45/64 loss: -4.10197114944458
Batch 46/64 loss: -3.873155117034912
Batch 47/64 loss: -4.133100986480713
Batch 48/64 loss: -4.169691562652588
Batch 49/64 loss: -4.0017266273498535
Batch 50/64 loss: -3.831946849822998
Batch 51/64 loss: -3.8341422080993652
Batch 52/64 loss: -3.906144142150879
Batch 53/64 loss: -3.774196147918701
Batch 54/64 loss: -3.7873849868774414
Batch 55/64 loss: -4.091333389282227
Batch 56/64 loss: -3.496501922607422
Batch 57/64 loss: -3.896707057952881
Batch 58/64 loss: -3.955355644226074
Batch 59/64 loss: -3.9268131256103516
Batch 60/64 loss: -3.7844314575195312
Batch 61/64 loss: -3.988375663757324
Batch 62/64 loss: -3.9333748817443848
Batch 63/64 loss: -4.1774492263793945
Batch 64/64 loss: -8.69644546508789
Epoch 401  Train loss: -4.005137881110696  Val loss: -4.362823958249436
Epoch 402
-------------------------------
Batch 1/64 loss: -3.9434127807617188
Batch 2/64 loss: -4.036446571350098
Batch 3/64 loss: -4.1020426750183105
Batch 4/64 loss: -3.7794442176818848
Batch 5/64 loss: -3.9596166610717773
Batch 6/64 loss: -4.043449878692627
Batch 7/64 loss: -3.9308619499206543
Batch 8/64 loss: -4.05165433883667
Batch 9/64 loss: -3.78922176361084
Batch 10/64 loss: -3.8355307579040527
Batch 11/64 loss: -3.59944486618042
Batch 12/64 loss: -3.9591450691223145
Batch 13/64 loss: -3.9673891067504883
Batch 14/64 loss: -3.9212279319763184
Batch 15/64 loss: -4.0782904624938965
Batch 16/64 loss: -4.048184394836426
Batch 17/64 loss: -3.940241813659668
Batch 18/64 loss: -3.7868099212646484
Batch 19/64 loss: -3.934419631958008
Batch 20/64 loss: -4.021594524383545
Batch 21/64 loss: -3.618772029876709
Batch 22/64 loss: -4.072595596313477
Batch 23/64 loss: -4.071893692016602
Batch 24/64 loss: -3.959773063659668
Batch 25/64 loss: -3.6300668716430664
Batch 26/64 loss: -3.9246926307678223
Batch 27/64 loss: -4.004154682159424
Batch 28/64 loss: -4.155455112457275
Batch 29/64 loss: -4.05573034286499
Batch 30/64 loss: -3.99932861328125
Batch 31/64 loss: -3.8484673500061035
Batch 32/64 loss: -4.131037712097168
Batch 33/64 loss: -3.7716169357299805
Batch 34/64 loss: -3.913886547088623
Batch 35/64 loss: -3.977344036102295
Batch 36/64 loss: -4.022210597991943
Batch 37/64 loss: -3.930023193359375
Batch 38/64 loss: -4.012261867523193
Batch 39/64 loss: -3.841996669769287
Batch 40/64 loss: -3.967841148376465
Batch 41/64 loss: -3.815518856048584
Batch 42/64 loss: -4.0356059074401855
Batch 43/64 loss: -3.295468330383301
Batch 44/64 loss: -3.7437496185302734
Batch 45/64 loss: -3.9567012786865234
Batch 46/64 loss: -3.5814056396484375
Batch 47/64 loss: -3.8990774154663086
Batch 48/64 loss: -3.950918674468994
Batch 49/64 loss: -3.9696640968322754
Batch 50/64 loss: -3.70526123046875
Batch 51/64 loss: -3.9393253326416016
Batch 52/64 loss: -4.052892208099365
Batch 53/64 loss: -3.933138370513916
Batch 54/64 loss: -3.689474582672119
Batch 55/64 loss: -3.6611080169677734
Batch 56/64 loss: -3.9259819984436035
Batch 57/64 loss: -3.5802292823791504
Batch 58/64 loss: -4.063991546630859
Batch 59/64 loss: -3.8176698684692383
Batch 60/64 loss: -3.924111843109131
Batch 61/64 loss: -4.025156497955322
Batch 62/64 loss: -4.080179691314697
Batch 63/64 loss: -3.932826042175293
Batch 64/64 loss: -8.457378387451172
Epoch 402  Train loss: -3.961726558909697  Val loss: -4.293264526681802
Epoch 403
-------------------------------
Batch 1/64 loss: -4.051861763000488
Batch 2/64 loss: -3.7975354194641113
Batch 3/64 loss: -4.09121036529541
Batch 4/64 loss: -3.852433681488037
Batch 5/64 loss: -4.0491108894348145
Batch 6/64 loss: -3.7005410194396973
Batch 7/64 loss: -3.9558310508728027
Batch 8/64 loss: -3.858154773712158
Batch 9/64 loss: -3.915588855743408
Batch 10/64 loss: -3.9582643508911133
Batch 11/64 loss: -4.079969882965088
Batch 12/64 loss: -3.9131698608398438
Batch 13/64 loss: -3.9189229011535645
Batch 14/64 loss: -4.032320976257324
Batch 15/64 loss: -3.7702884674072266
Batch 16/64 loss: -4.0492401123046875
Batch 17/64 loss: -4.010809898376465
Batch 18/64 loss: -4.117002487182617
Batch 19/64 loss: -3.8944616317749023
Batch 20/64 loss: -3.801435947418213
Batch 21/64 loss: -4.094900608062744
Batch 22/64 loss: -4.06007194519043
Batch 23/64 loss: -3.8056931495666504
Batch 24/64 loss: -4.035420894622803
Batch 25/64 loss: -3.9512500762939453
Batch 26/64 loss: -3.9425854682922363
Batch 27/64 loss: -4.060142993927002
Batch 28/64 loss: -3.9698915481567383
Batch 29/64 loss: -3.6334052085876465
Batch 30/64 loss: -4.020258903503418
Batch 31/64 loss: -3.8281497955322266
Batch 32/64 loss: -3.9575204849243164
Batch 33/64 loss: -3.9669413566589355
Batch 34/64 loss: -4.043663501739502
Batch 35/64 loss: -3.9294681549072266
Batch 36/64 loss: -4.0091753005981445
Batch 37/64 loss: -3.8573780059814453
Batch 38/64 loss: -4.092580318450928
Batch 39/64 loss: -3.542119026184082
Batch 40/64 loss: -4.210986137390137
Batch 41/64 loss: -4.01671838760376
Batch 42/64 loss: -4.048452377319336
Batch 43/64 loss: -4.153573989868164
Batch 44/64 loss: -4.061154365539551
Batch 45/64 loss: -4.02086877822876
Batch 46/64 loss: -3.810549259185791
Batch 47/64 loss: -3.90287446975708
Batch 48/64 loss: -4.173306941986084
Batch 49/64 loss: -4.159785270690918
Batch 50/64 loss: -4.0753397941589355
Batch 51/64 loss: -3.962676525115967
Batch 52/64 loss: -3.9429502487182617
Batch 53/64 loss: -3.943030834197998
Batch 54/64 loss: -4.158664703369141
Batch 55/64 loss: -4.193263530731201
Batch 56/64 loss: -4.1197686195373535
Batch 57/64 loss: -4.115513324737549
Batch 58/64 loss: -4.029391765594482
Batch 59/64 loss: -4.169845104217529
Batch 60/64 loss: -4.059520721435547
Batch 61/64 loss: -3.704674243927002
Batch 62/64 loss: -4.273751258850098
Batch 63/64 loss: -4.142312526702881
Batch 64/64 loss: -8.628791809082031
Epoch 403  Train loss: -4.039832754696117  Val loss: -4.436226782520203
Epoch 404
-------------------------------
Batch 1/64 loss: -4.034554958343506
Batch 2/64 loss: -3.6517434120178223
Batch 3/64 loss: -3.869887351989746
Batch 4/64 loss: -3.969521999359131
Batch 5/64 loss: -3.7844314575195312
Batch 6/64 loss: -4.106321811676025
Batch 7/64 loss: -4.2943034172058105
Batch 8/64 loss: -4.178503513336182
Batch 9/64 loss: -3.983470916748047
Batch 10/64 loss: -4.109724044799805
Batch 11/64 loss: -3.764584541320801
Batch 12/64 loss: -4.027440547943115
Batch 13/64 loss: -4.048692226409912
Batch 14/64 loss: -4.069011211395264
Batch 15/64 loss: -4.092894077301025
Batch 16/64 loss: -4.177475452423096
Batch 17/64 loss: -4.0079026222229
Batch 18/64 loss: -4.168948650360107
Batch 19/64 loss: -4.05524206161499
Batch 20/64 loss: -4.134988307952881
Batch 21/64 loss: -4.105767726898193
Batch 22/64 loss: -3.8429818153381348
Batch 23/64 loss: -4.018975734710693
Batch 24/64 loss: -4.042762756347656
Batch 25/64 loss: -3.555975914001465
Batch 26/64 loss: -3.7510018348693848
Batch 27/64 loss: -4.042813777923584
Batch 28/64 loss: -4.126343250274658
Batch 29/64 loss: -3.9992904663085938
Batch 30/64 loss: -4.06655740737915
Batch 31/64 loss: -3.9772815704345703
Batch 32/64 loss: -4.042725563049316
Batch 33/64 loss: -3.8379411697387695
Batch 34/64 loss: -4.0361409187316895
Batch 35/64 loss: -4.034013271331787
Batch 36/64 loss: -3.986464023590088
Batch 37/64 loss: -4.061028957366943
Batch 38/64 loss: -3.9862546920776367
Batch 39/64 loss: -3.981024742126465
Batch 40/64 loss: -4.037688732147217
Batch 41/64 loss: -4.038987159729004
Batch 42/64 loss: -4.018764019012451
Batch 43/64 loss: -3.9294276237487793
Batch 44/64 loss: -3.968107223510742
Batch 45/64 loss: -4.142732620239258
Batch 46/64 loss: -3.895216464996338
Batch 47/64 loss: -3.9447832107543945
Batch 48/64 loss: -3.70585298538208
Batch 49/64 loss: -3.900571346282959
Batch 50/64 loss: -3.798475742340088
Batch 51/64 loss: -4.035226345062256
Batch 52/64 loss: -4.0115227699279785
Batch 53/64 loss: -4.109906196594238
Batch 54/64 loss: -4.063869476318359
Batch 55/64 loss: -3.526698112487793
Batch 56/64 loss: -4.05114221572876
Batch 57/64 loss: -4.0822978019714355
Batch 58/64 loss: -3.8804683685302734
Batch 59/64 loss: -3.922630786895752
Batch 60/64 loss: -4.101659297943115
Batch 61/64 loss: -4.044653415679932
Batch 62/64 loss: -4.002520561218262
Batch 63/64 loss: -3.9485578536987305
Batch 64/64 loss: -8.264595031738281
Epoch 404  Train loss: -4.037414820053998  Val loss: -4.431124474174788
Epoch 405
-------------------------------
Batch 1/64 loss: -4.1195502281188965
Batch 2/64 loss: -4.10819673538208
Batch 3/64 loss: -3.955103874206543
Batch 4/64 loss: -3.968024253845215
Batch 5/64 loss: -4.00632381439209
Batch 6/64 loss: -3.925978660583496
Batch 7/64 loss: -3.919273853302002
Batch 8/64 loss: -4.048849105834961
Batch 9/64 loss: -4.095207214355469
Batch 10/64 loss: -4.017385482788086
Batch 11/64 loss: -4.1773505210876465
Batch 12/64 loss: -3.8088974952697754
Batch 13/64 loss: -3.9916467666625977
Batch 14/64 loss: -3.8489580154418945
Batch 15/64 loss: -4.123968601226807
Batch 16/64 loss: -4.132552146911621
Batch 17/64 loss: -4.033199787139893
Batch 18/64 loss: -4.137264728546143
Batch 19/64 loss: -4.17515754699707
Batch 20/64 loss: -4.0444746017456055
Batch 21/64 loss: -4.0072407722473145
Batch 22/64 loss: -3.848991870880127
Batch 23/64 loss: -3.9421567916870117
Batch 24/64 loss: -4.093221664428711
Batch 25/64 loss: -4.013115406036377
Batch 26/64 loss: -3.9552860260009766
Batch 27/64 loss: -3.9700193405151367
Batch 28/64 loss: -3.9221668243408203
Batch 29/64 loss: -3.954963207244873
Batch 30/64 loss: -3.795614242553711
Batch 31/64 loss: -3.8474316596984863
Batch 32/64 loss: -3.8377652168273926
Batch 33/64 loss: -4.085241317749023
Batch 34/64 loss: -3.4175024032592773
Batch 35/64 loss: -4.012217044830322
Batch 36/64 loss: -3.934347629547119
Batch 37/64 loss: -4.0374884605407715
Batch 38/64 loss: -3.861269950866699
Batch 39/64 loss: -3.8761744499206543
Batch 40/64 loss: -3.8091788291931152
Batch 41/64 loss: -3.916836738586426
Batch 42/64 loss: -3.8822455406188965
Batch 43/64 loss: -3.8020148277282715
Batch 44/64 loss: -4.011555194854736
Batch 45/64 loss: -3.9759159088134766
Batch 46/64 loss: -3.901358127593994
Batch 47/64 loss: -3.5372867584228516
Batch 48/64 loss: -3.8871941566467285
Batch 49/64 loss: -3.948141574859619
Batch 50/64 loss: -4.04978084564209
Batch 51/64 loss: -3.8459882736206055
Batch 52/64 loss: -3.897660732269287
Batch 53/64 loss: -3.905214309692383
Batch 54/64 loss: -3.7506961822509766
Batch 55/64 loss: -3.4138355255126953
Batch 56/64 loss: -4.032156467437744
Batch 57/64 loss: -3.838456153869629
Batch 58/64 loss: -3.957490921020508
Batch 59/64 loss: -3.9442806243896484
Batch 60/64 loss: -3.7704358100891113
Batch 61/64 loss: -4.024911403656006
Batch 62/64 loss: -3.9886984825134277
Batch 63/64 loss: -3.917628288269043
Batch 64/64 loss: -8.505395889282227
Epoch 405  Train loss: -3.991177824431775  Val loss: -4.364271930812561
Epoch 406
-------------------------------
Batch 1/64 loss: -3.8971710205078125
Batch 2/64 loss: -4.100555896759033
Batch 3/64 loss: -3.9358668327331543
Batch 4/64 loss: -3.819314956665039
Batch 5/64 loss: -3.93196439743042
Batch 6/64 loss: -3.8348212242126465
Batch 7/64 loss: -3.6884665489196777
Batch 8/64 loss: -4.005831241607666
Batch 9/64 loss: -3.8384132385253906
Batch 10/64 loss: -3.95961332321167
Batch 11/64 loss: -3.7270212173461914
Batch 12/64 loss: -3.989403247833252
Batch 13/64 loss: -3.9335126876831055
Batch 14/64 loss: -3.5910840034484863
Batch 15/64 loss: -3.949420928955078
Batch 16/64 loss: -4.16763162612915
Batch 17/64 loss: -3.806095600128174
Batch 18/64 loss: -3.933967113494873
Batch 19/64 loss: -3.997921943664551
Batch 20/64 loss: -3.831409454345703
Batch 21/64 loss: -3.9987382888793945
Batch 22/64 loss: -3.9647302627563477
Batch 23/64 loss: -4.020841598510742
Batch 24/64 loss: -3.7524309158325195
Batch 25/64 loss: -4.052610874176025
Batch 26/64 loss: -3.920229911804199
Batch 27/64 loss: -3.9803457260131836
Batch 28/64 loss: -4.058622360229492
Batch 29/64 loss: -3.9833645820617676
Batch 30/64 loss: -3.9205269813537598
Batch 31/64 loss: -4.1288557052612305
Batch 32/64 loss: -3.5560851097106934
Batch 33/64 loss: -4.180829048156738
Batch 34/64 loss: -3.995480537414551
Batch 35/64 loss: -3.8324904441833496
Batch 36/64 loss: -4.1173415184021
Batch 37/64 loss: -3.92940092086792
Batch 38/64 loss: -4.055944919586182
Batch 39/64 loss: -4.17094612121582
Batch 40/64 loss: -3.992173671722412
Batch 41/64 loss: -3.7199487686157227
Batch 42/64 loss: -3.9849700927734375
Batch 43/64 loss: -4.0580668449401855
Batch 44/64 loss: -4.099851608276367
Batch 45/64 loss: -3.9785189628601074
Batch 46/64 loss: -4.045680999755859
Batch 47/64 loss: -3.891125202178955
Batch 48/64 loss: -4.119502067565918
Batch 49/64 loss: -3.866117000579834
Batch 50/64 loss: -4.122305870056152
Batch 51/64 loss: -3.94394588470459
Batch 52/64 loss: -4.016164779663086
Batch 53/64 loss: -3.967747688293457
Batch 54/64 loss: -3.917616367340088
Batch 55/64 loss: -3.9903478622436523
Batch 56/64 loss: -4.036582946777344
Batch 57/64 loss: -3.7653932571411133
Batch 58/64 loss: -3.9750261306762695
Batch 59/64 loss: -3.940382480621338
Batch 60/64 loss: -3.8348050117492676
Batch 61/64 loss: -3.9119925498962402
Batch 62/64 loss: -3.7301883697509766
Batch 63/64 loss: -3.8711342811584473
Batch 64/64 loss: -8.644367218017578
Epoch 406  Train loss: -3.997210454005821  Val loss: -4.405961629860999
Epoch 407
-------------------------------
Batch 1/64 loss: -4.075538635253906
Batch 2/64 loss: -4.046093940734863
Batch 3/64 loss: -3.999579906463623
Batch 4/64 loss: -4.099485874176025
Batch 5/64 loss: -4.160900115966797
Batch 6/64 loss: -4.034858226776123
Batch 7/64 loss: -3.890155792236328
Batch 8/64 loss: -3.5336971282958984
Batch 9/64 loss: -3.9468979835510254
Batch 10/64 loss: -3.9832277297973633
Batch 11/64 loss: -4.165740013122559
Batch 12/64 loss: -4.134662628173828
Batch 13/64 loss: -3.8056845664978027
Batch 14/64 loss: -3.898796558380127
Batch 15/64 loss: -3.9930224418640137
Batch 16/64 loss: -4.226190567016602
Batch 17/64 loss: -4.064472675323486
Batch 18/64 loss: -4.026954650878906
Batch 19/64 loss: -4.062297821044922
Batch 20/64 loss: -3.9230856895446777
Batch 21/64 loss: -3.4599661827087402
Batch 22/64 loss: -3.9727869033813477
Batch 23/64 loss: -3.9973316192626953
Batch 24/64 loss: -4.106540679931641
Batch 25/64 loss: -3.8981709480285645
Batch 26/64 loss: -3.551689624786377
Batch 27/64 loss: -3.73928165435791
Batch 28/64 loss: -3.8827080726623535
Batch 29/64 loss: -3.9692978858947754
Batch 30/64 loss: -4.015991687774658
Batch 31/64 loss: -4.057783603668213
Batch 32/64 loss: -4.060034275054932
Batch 33/64 loss: -3.9947261810302734
Batch 34/64 loss: -4.1603684425354
Batch 35/64 loss: -4.064120292663574
Batch 36/64 loss: -4.101319313049316
Batch 37/64 loss: -3.7901415824890137
Batch 38/64 loss: -3.948132038116455
Batch 39/64 loss: -4.018061637878418
Batch 40/64 loss: -4.1847662925720215
Batch 41/64 loss: -4.069632530212402
Batch 42/64 loss: -4.088134765625
Batch 43/64 loss: -4.017386436462402
Batch 44/64 loss: -3.9811859130859375
Batch 45/64 loss: -3.890212059020996
Batch 46/64 loss: -4.116610050201416
Batch 47/64 loss: -3.8895773887634277
Batch 48/64 loss: -4.02046012878418
Batch 49/64 loss: -3.9258389472961426
Batch 50/64 loss: -3.9354658126831055
Batch 51/64 loss: -4.0596537590026855
Batch 52/64 loss: -4.0937910079956055
Batch 53/64 loss: -4.011869430541992
Batch 54/64 loss: -3.9955787658691406
Batch 55/64 loss: -3.9749350547790527
Batch 56/64 loss: -4.079512596130371
Batch 57/64 loss: -3.9725522994995117
Batch 58/64 loss: -4.1187615394592285
Batch 59/64 loss: -4.03997278213501
Batch 60/64 loss: -4.098482131958008
Batch 61/64 loss: -3.989546298980713
Batch 62/64 loss: -4.1613264083862305
Batch 63/64 loss: -4.093307971954346
Batch 64/64 loss: -8.522626876831055
Epoch 407  Train loss: -4.0480051152846395  Val loss: -4.470171925128531
Epoch 408
-------------------------------
Batch 1/64 loss: -3.7444114685058594
Batch 2/64 loss: -4.03958797454834
Batch 3/64 loss: -4.0721821784973145
Batch 4/64 loss: -4.186735153198242
Batch 5/64 loss: -4.181562900543213
Batch 6/64 loss: -4.118786811828613
Batch 7/64 loss: -4.0813422203063965
Batch 8/64 loss: -4.161806583404541
Batch 9/64 loss: -4.069945335388184
Batch 10/64 loss: -4.1657633781433105
Batch 11/64 loss: -4.005202293395996
Batch 12/64 loss: -4.042185306549072
Batch 13/64 loss: -4.092881679534912
Batch 14/64 loss: -4.040750503540039
Batch 15/64 loss: -3.8955917358398438
Batch 16/64 loss: -4.064008712768555
Batch 17/64 loss: -3.9367384910583496
Batch 18/64 loss: -4.0690016746521
Batch 19/64 loss: -3.7574896812438965
Batch 20/64 loss: -4.15707540512085
Batch 21/64 loss: -4.055222511291504
Batch 22/64 loss: -4.165207386016846
Batch 23/64 loss: -4.028757095336914
Batch 24/64 loss: -4.101846218109131
Batch 25/64 loss: -4.083067417144775
Batch 26/64 loss: -4.11976432800293
Batch 27/64 loss: -3.978555202484131
Batch 28/64 loss: -4.06209659576416
Batch 29/64 loss: -4.095666885375977
Batch 30/64 loss: -3.8580164909362793
Batch 31/64 loss: -4.109201431274414
Batch 32/64 loss: -4.214813709259033
Batch 33/64 loss: -4.037733554840088
Batch 34/64 loss: -3.9851527214050293
Batch 35/64 loss: -4.089733600616455
Batch 36/64 loss: -4.1426920890808105
Batch 37/64 loss: -3.9737253189086914
Batch 38/64 loss: -4.03920841217041
Batch 39/64 loss: -4.122875213623047
Batch 40/64 loss: -3.9918384552001953
Batch 41/64 loss: -4.092254161834717
Batch 42/64 loss: -4.058971405029297
Batch 43/64 loss: -4.162417888641357
Batch 44/64 loss: -4.062283515930176
Batch 45/64 loss: -4.218322277069092
Batch 46/64 loss: -4.025209426879883
Batch 47/64 loss: -4.036038398742676
Batch 48/64 loss: -3.948606491088867
Batch 49/64 loss: -4.10050630569458
Batch 50/64 loss: -4.0423126220703125
Batch 51/64 loss: -4.132674217224121
Batch 52/64 loss: -4.175657272338867
Batch 53/64 loss: -4.10263729095459
Batch 54/64 loss: -4.100924491882324
Batch 55/64 loss: -3.903716564178467
Batch 56/64 loss: -4.089715003967285
Batch 57/64 loss: -3.6585817337036133
Batch 58/64 loss: -4.107697486877441
Batch 59/64 loss: -3.4967684745788574
Batch 60/64 loss: -4.158321380615234
Batch 61/64 loss: -4.105953693389893
Batch 62/64 loss: -4.052891731262207
Batch 63/64 loss: -4.064442157745361
Batch 64/64 loss: -8.603475570678711
Epoch 408  Train loss: -4.101768388935164  Val loss: -4.4794515105047585
Saving best model, epoch: 408
Epoch 409
-------------------------------
Batch 1/64 loss: -3.674999713897705
Batch 2/64 loss: -3.7387166023254395
Batch 3/64 loss: -3.9829211235046387
Batch 4/64 loss: -4.023728847503662
Batch 5/64 loss: -3.913379669189453
Batch 6/64 loss: -3.952652931213379
Batch 7/64 loss: -4.052220344543457
Batch 8/64 loss: -4.013564586639404
Batch 9/64 loss: -4.163964748382568
Batch 10/64 loss: -4.097893238067627
Batch 11/64 loss: -4.057482719421387
Batch 12/64 loss: -4.050030708312988
Batch 13/64 loss: -3.9616031646728516
Batch 14/64 loss: -4.076234817504883
Batch 15/64 loss: -4.053643226623535
Batch 16/64 loss: -3.965963840484619
Batch 17/64 loss: -4.074948310852051
Batch 18/64 loss: -4.068314075469971
Batch 19/64 loss: -3.674060821533203
Batch 20/64 loss: -4.151702404022217
Batch 21/64 loss: -4.118534564971924
Batch 22/64 loss: -3.9674482345581055
Batch 23/64 loss: -4.015944480895996
Batch 24/64 loss: -4.223210334777832
Batch 25/64 loss: -4.033059597015381
Batch 26/64 loss: -4.067874431610107
Batch 27/64 loss: -4.139481067657471
Batch 28/64 loss: -3.9668898582458496
Batch 29/64 loss: -4.17086124420166
Batch 30/64 loss: -4.068317413330078
Batch 31/64 loss: -4.070586204528809
Batch 32/64 loss: -3.9993534088134766
Batch 33/64 loss: -4.1412787437438965
Batch 34/64 loss: -4.0416259765625
Batch 35/64 loss: -4.007208824157715
Batch 36/64 loss: -4.159690856933594
Batch 37/64 loss: -4.119593143463135
Batch 38/64 loss: -4.028074741363525
Batch 39/64 loss: -3.901777744293213
Batch 40/64 loss: -4.084035396575928
Batch 41/64 loss: -4.230353832244873
Batch 42/64 loss: -3.9937353134155273
Batch 43/64 loss: -4.030359745025635
Batch 44/64 loss: -3.993652820587158
Batch 45/64 loss: -4.097035884857178
Batch 46/64 loss: -4.232678413391113
Batch 47/64 loss: -4.071201324462891
Batch 48/64 loss: -4.217101097106934
Batch 49/64 loss: -4.1595845222473145
Batch 50/64 loss: -4.025969982147217
Batch 51/64 loss: -3.778296947479248
Batch 52/64 loss: -4.150400638580322
Batch 53/64 loss: -3.975330352783203
Batch 54/64 loss: -4.01878547668457
Batch 55/64 loss: -4.21185302734375
Batch 56/64 loss: -4.094119548797607
Batch 57/64 loss: -3.883330821990967
Batch 58/64 loss: -3.9649477005004883
Batch 59/64 loss: -4.017460823059082
Batch 60/64 loss: -3.839693546295166
Batch 61/64 loss: -3.9876718521118164
Batch 62/64 loss: -3.9671754837036133
Batch 63/64 loss: -4.028407096862793
Batch 64/64 loss: -8.505794525146484
Epoch 409  Train loss: -4.085041008743585  Val loss: -4.386708682345361
Epoch 410
-------------------------------
Batch 1/64 loss: -4.010702133178711
Batch 2/64 loss: -3.7721080780029297
Batch 3/64 loss: -4.078193664550781
Batch 4/64 loss: -4.125332832336426
Batch 5/64 loss: -3.953054428100586
Batch 6/64 loss: -4.010067939758301
Batch 7/64 loss: -4.116012096405029
Batch 8/64 loss: -4.008918762207031
Batch 9/64 loss: -4.102399826049805
Batch 10/64 loss: -4.027711391448975
Batch 11/64 loss: -3.6871871948242188
Batch 12/64 loss: -4.235318183898926
Batch 13/64 loss: -4.090787410736084
Batch 14/64 loss: -4.115673542022705
Batch 15/64 loss: -4.2117390632629395
Batch 16/64 loss: -3.400043487548828
Batch 17/64 loss: -3.996216297149658
Batch 18/64 loss: -3.9937033653259277
Batch 19/64 loss: -3.9005184173583984
Batch 20/64 loss: -4.02912712097168
Batch 21/64 loss: -3.9884133338928223
Batch 22/64 loss: -4.027044773101807
Batch 23/64 loss: -4.031651973724365
Batch 24/64 loss: -3.8976573944091797
Batch 25/64 loss: -3.9572834968566895
Batch 26/64 loss: -4.117391586303711
Batch 27/64 loss: -3.9561614990234375
Batch 28/64 loss: -3.969003677368164
Batch 29/64 loss: -4.016704559326172
Batch 30/64 loss: -3.983285427093506
Batch 31/64 loss: -4.172898769378662
Batch 32/64 loss: -3.9826974868774414
Batch 33/64 loss: -3.988252639770508
Batch 34/64 loss: -4.056258201599121
Batch 35/64 loss: -3.966766834259033
Batch 36/64 loss: -3.8851804733276367
Batch 37/64 loss: -4.0231428146362305
Batch 38/64 loss: -3.8823819160461426
Batch 39/64 loss: -4.0013957023620605
Batch 40/64 loss: -3.9240078926086426
Batch 41/64 loss: -3.9354562759399414
Batch 42/64 loss: -4.032435894012451
Batch 43/64 loss: -4.165581226348877
Batch 44/64 loss: -3.9885330200195312
Batch 45/64 loss: -4.104942321777344
Batch 46/64 loss: -4.123936176300049
Batch 47/64 loss: -4.021857738494873
Batch 48/64 loss: -3.9984846115112305
Batch 49/64 loss: -4.052891254425049
Batch 50/64 loss: -3.994731903076172
Batch 51/64 loss: -3.966303825378418
Batch 52/64 loss: -4.10575008392334
Batch 53/64 loss: -4.096187591552734
Batch 54/64 loss: -4.061851978302002
Batch 55/64 loss: -4.134725093841553
Batch 56/64 loss: -4.012851238250732
Batch 57/64 loss: -4.08030891418457
Batch 58/64 loss: -4.084141731262207
Batch 59/64 loss: -4.0911478996276855
Batch 60/64 loss: -4.198886871337891
Batch 61/64 loss: -4.080064296722412
Batch 62/64 loss: -4.069192886352539
Batch 63/64 loss: -4.0118536949157715
Batch 64/64 loss: -8.524984359741211
Epoch 410  Train loss: -4.070560791913201  Val loss: -4.530341879199051
Saving best model, epoch: 410
Epoch 411
-------------------------------
Batch 1/64 loss: -4.088486671447754
Batch 2/64 loss: -3.6739449501037598
Batch 3/64 loss: -4.17602014541626
Batch 4/64 loss: -4.2123637199401855
Batch 5/64 loss: -4.247946739196777
Batch 6/64 loss: -3.9963226318359375
Batch 7/64 loss: -3.724903106689453
Batch 8/64 loss: -4.092117786407471
Batch 9/64 loss: -4.182569980621338
Batch 10/64 loss: -4.260923385620117
Batch 11/64 loss: -4.037408351898193
Batch 12/64 loss: -3.519423484802246
Batch 13/64 loss: -3.9915637969970703
Batch 14/64 loss: -4.0442094802856445
Batch 15/64 loss: -4.150603771209717
Batch 16/64 loss: -4.035666465759277
Batch 17/64 loss: -4.120193958282471
Batch 18/64 loss: -4.190232276916504
Batch 19/64 loss: -4.014156341552734
Batch 20/64 loss: -3.9090332984924316
Batch 21/64 loss: -3.8277416229248047
Batch 22/64 loss: -3.731255531311035
Batch 23/64 loss: -4.099262714385986
Batch 24/64 loss: -4.097042560577393
Batch 25/64 loss: -4.170348644256592
Batch 26/64 loss: -4.031407833099365
Batch 27/64 loss: -3.924619197845459
Batch 28/64 loss: -4.294666290283203
Batch 29/64 loss: -4.163182735443115
Batch 30/64 loss: -4.068276405334473
Batch 31/64 loss: -4.091533660888672
Batch 32/64 loss: -3.9980249404907227
Batch 33/64 loss: -4.005125045776367
Batch 34/64 loss: -4.082740783691406
Batch 35/64 loss: -4.146675109863281
Batch 36/64 loss: -3.8910818099975586
Batch 37/64 loss: -4.180213451385498
Batch 38/64 loss: -4.173184394836426
Batch 39/64 loss: -4.161898612976074
Batch 40/64 loss: -4.121720314025879
Batch 41/64 loss: -4.0325608253479
Batch 42/64 loss: -4.057729721069336
Batch 43/64 loss: -4.182015895843506
Batch 44/64 loss: -4.201234817504883
Batch 45/64 loss: -3.8924155235290527
Batch 46/64 loss: -4.05618953704834
Batch 47/64 loss: -3.80670166015625
Batch 48/64 loss: -4.029033660888672
Batch 49/64 loss: -4.117347717285156
Batch 50/64 loss: -3.9280738830566406
Batch 51/64 loss: -4.106229782104492
Batch 52/64 loss: -4.140003204345703
Batch 53/64 loss: -4.139853477478027
Batch 54/64 loss: -4.049811840057373
Batch 55/64 loss: -4.026914119720459
Batch 56/64 loss: -4.069256782531738
Batch 57/64 loss: -4.099263668060303
Batch 58/64 loss: -4.101726531982422
Batch 59/64 loss: -4.027439594268799
Batch 60/64 loss: -3.838771343231201
Batch 61/64 loss: -4.233949661254883
Batch 62/64 loss: -4.121584415435791
Batch 63/64 loss: -4.161415100097656
Batch 64/64 loss: -8.647159576416016
Epoch 411  Train loss: -4.10718406976438  Val loss: -4.52513113382346
Epoch 412
-------------------------------
Batch 1/64 loss: -4.249353885650635
Batch 2/64 loss: -4.080068111419678
Batch 3/64 loss: -3.9977192878723145
Batch 4/64 loss: -3.983236312866211
Batch 5/64 loss: -3.8454203605651855
Batch 6/64 loss: -4.120251178741455
Batch 7/64 loss: -3.9737143516540527
Batch 8/64 loss: -4.015692234039307
Batch 9/64 loss: -4.035337448120117
Batch 10/64 loss: -3.9266157150268555
Batch 11/64 loss: -3.901665687561035
Batch 12/64 loss: -3.9642162322998047
Batch 13/64 loss: -3.538675308227539
Batch 14/64 loss: -4.111546993255615
Batch 15/64 loss: -4.26157808303833
Batch 16/64 loss: -4.0539960861206055
Batch 17/64 loss: -4.182705879211426
Batch 18/64 loss: -4.101812362670898
Batch 19/64 loss: -3.871858596801758
Batch 20/64 loss: -4.122352123260498
Batch 21/64 loss: -4.041566371917725
Batch 22/64 loss: -3.8218512535095215
Batch 23/64 loss: -4.0397748947143555
Batch 24/64 loss: -3.9324698448181152
Batch 25/64 loss: -3.9626150131225586
Batch 26/64 loss: -4.082330703735352
Batch 27/64 loss: -4.029544830322266
Batch 28/64 loss: -4.006751537322998
Batch 29/64 loss: -4.017716884613037
Batch 30/64 loss: -4.096652984619141
Batch 31/64 loss: -4.006534099578857
Batch 32/64 loss: -4.163220405578613
Batch 33/64 loss: -4.088481903076172
Batch 34/64 loss: -4.097485542297363
Batch 35/64 loss: -4.001186370849609
Batch 36/64 loss: -3.9922428131103516
Batch 37/64 loss: -4.129818439483643
Batch 38/64 loss: -3.6059107780456543
Batch 39/64 loss: -4.102551460266113
Batch 40/64 loss: -4.005578994750977
Batch 41/64 loss: -3.9383163452148438
Batch 42/64 loss: -3.940995693206787
Batch 43/64 loss: -4.0001702308654785
Batch 44/64 loss: -4.149420261383057
Batch 45/64 loss: -4.1324591636657715
Batch 46/64 loss: -3.9386987686157227
Batch 47/64 loss: -4.004788875579834
Batch 48/64 loss: -3.9466118812561035
Batch 49/64 loss: -3.930788040161133
Batch 50/64 loss: -3.9789509773254395
Batch 51/64 loss: -4.05894136428833
Batch 52/64 loss: -3.684825897216797
Batch 53/64 loss: -4.0817999839782715
Batch 54/64 loss: -3.9727516174316406
Batch 55/64 loss: -4.005704879760742
Batch 56/64 loss: -4.08390474319458
Batch 57/64 loss: -3.8928208351135254
Batch 58/64 loss: -3.8209242820739746
Batch 59/64 loss: -3.580967426300049
Batch 60/64 loss: -4.0342912673950195
Batch 61/64 loss: -4.053693771362305
Batch 62/64 loss: -4.097111225128174
Batch 63/64 loss: -3.9771981239318848
Batch 64/64 loss: -8.399944305419922
Epoch 412  Train loss: -4.049697180355296  Val loss: -4.44427112697326
Epoch 413
-------------------------------
Batch 1/64 loss: -3.9996886253356934
Batch 2/64 loss: -4.028078556060791
Batch 3/64 loss: -3.9168052673339844
Batch 4/64 loss: -4.092894554138184
Batch 5/64 loss: -4.0785017013549805
Batch 6/64 loss: -4.009887218475342
Batch 7/64 loss: -3.9649386405944824
Batch 8/64 loss: -4.021831035614014
Batch 9/64 loss: -4.140925407409668
Batch 10/64 loss: -4.166238784790039
Batch 11/64 loss: -3.855959892272949
Batch 12/64 loss: -3.9296674728393555
Batch 13/64 loss: -4.08734655380249
Batch 14/64 loss: -4.073486328125
Batch 15/64 loss: -3.66513729095459
Batch 16/64 loss: -3.9364700317382812
Batch 17/64 loss: -4.02418327331543
Batch 18/64 loss: -4.052461624145508
Batch 19/64 loss: -4.16864013671875
Batch 20/64 loss: -3.790261745452881
Batch 21/64 loss: -3.855358600616455
Batch 22/64 loss: -4.161095142364502
Batch 23/64 loss: -4.106475353240967
Batch 24/64 loss: -3.9748411178588867
Batch 25/64 loss: -3.9689130783081055
Batch 26/64 loss: -4.039338111877441
Batch 27/64 loss: -4.1110005378723145
Batch 28/64 loss: -3.9795894622802734
Batch 29/64 loss: -4.111915111541748
Batch 30/64 loss: -4.151158809661865
Batch 31/64 loss: -4.1663289070129395
Batch 32/64 loss: -4.102988243103027
Batch 33/64 loss: -4.097789287567139
Batch 34/64 loss: -4.163168430328369
Batch 35/64 loss: -4.169079780578613
Batch 36/64 loss: -4.007813930511475
Batch 37/64 loss: -4.109990119934082
Batch 38/64 loss: -3.850118637084961
Batch 39/64 loss: -4.142122268676758
Batch 40/64 loss: -4.1949591636657715
Batch 41/64 loss: -3.9805331230163574
Batch 42/64 loss: -3.991337299346924
Batch 43/64 loss: -3.931215763092041
Batch 44/64 loss: -4.272148132324219
Batch 45/64 loss: -4.145834445953369
Batch 46/64 loss: -4.098513126373291
Batch 47/64 loss: -3.983264923095703
Batch 48/64 loss: -4.169661045074463
Batch 49/64 loss: -4.119370937347412
Batch 50/64 loss: -3.8893609046936035
Batch 51/64 loss: -3.5865797996520996
Batch 52/64 loss: -4.236457347869873
Batch 53/64 loss: -3.736245632171631
Batch 54/64 loss: -4.089108467102051
Batch 55/64 loss: -4.269344329833984
Batch 56/64 loss: -4.207098007202148
Batch 57/64 loss: -4.083705425262451
Batch 58/64 loss: -3.9991650581359863
Batch 59/64 loss: -4.145299911499023
Batch 60/64 loss: -4.253228187561035
Batch 61/64 loss: -4.090324401855469
Batch 62/64 loss: -4.174800872802734
Batch 63/64 loss: -4.0763163566589355
Batch 64/64 loss: -8.705673217773438
Epoch 413  Train loss: -4.102362614051969  Val loss: -4.52853708168895
Epoch 414
-------------------------------
Batch 1/64 loss: -4.14028263092041
Batch 2/64 loss: -4.133122444152832
Batch 3/64 loss: -4.212834358215332
Batch 4/64 loss: -3.9936227798461914
Batch 5/64 loss: -3.6994991302490234
Batch 6/64 loss: -4.244997501373291
Batch 7/64 loss: -4.075782299041748
Batch 8/64 loss: -4.153859615325928
Batch 9/64 loss: -4.074709892272949
Batch 10/64 loss: -4.200471878051758
Batch 11/64 loss: -4.0576887130737305
Batch 12/64 loss: -4.076504707336426
Batch 13/64 loss: -3.9011569023132324
Batch 14/64 loss: -4.159450531005859
Batch 15/64 loss: -4.084679126739502
Batch 16/64 loss: -3.696349620819092
Batch 17/64 loss: -4.137897491455078
Batch 18/64 loss: -4.169266223907471
Batch 19/64 loss: -4.06339168548584
Batch 20/64 loss: -4.160008907318115
Batch 21/64 loss: -4.262819290161133
Batch 22/64 loss: -4.226253986358643
Batch 23/64 loss: -4.098243713378906
Batch 24/64 loss: -4.1600847244262695
Batch 25/64 loss: -4.006187915802002
Batch 26/64 loss: -4.041693687438965
Batch 27/64 loss: -4.165832996368408
Batch 28/64 loss: -4.132823467254639
Batch 29/64 loss: -4.037319183349609
Batch 30/64 loss: -4.111178874969482
Batch 31/64 loss: -4.111005783081055
Batch 32/64 loss: -4.095003604888916
Batch 33/64 loss: -3.6285548210144043
Batch 34/64 loss: -4.170198917388916
Batch 35/64 loss: -4.248076438903809
Batch 36/64 loss: -4.0119476318359375
Batch 37/64 loss: -4.115066051483154
Batch 38/64 loss: -4.022148132324219
Batch 39/64 loss: -3.9957494735717773
Batch 40/64 loss: -4.217621326446533
Batch 41/64 loss: -4.001055717468262
Batch 42/64 loss: -4.0370402336120605
Batch 43/64 loss: -4.296964645385742
Batch 44/64 loss: -4.189625263214111
Batch 45/64 loss: -4.064128398895264
Batch 46/64 loss: -4.18779993057251
Batch 47/64 loss: -4.001892566680908
Batch 48/64 loss: -4.077835559844971
Batch 49/64 loss: -4.1601152420043945
Batch 50/64 loss: -4.073044300079346
Batch 51/64 loss: -4.160476207733154
Batch 52/64 loss: -4.141715049743652
Batch 53/64 loss: -4.152799606323242
Batch 54/64 loss: -3.939356803894043
Batch 55/64 loss: -4.099941730499268
Batch 56/64 loss: -3.6193766593933105
Batch 57/64 loss: -4.059375762939453
Batch 58/64 loss: -4.085176944732666
Batch 59/64 loss: -4.064637660980225
Batch 60/64 loss: -4.170565605163574
Batch 61/64 loss: -4.2737274169921875
Batch 62/64 loss: -4.2128448486328125
Batch 63/64 loss: -4.239353656768799
Batch 64/64 loss: -8.68918228149414
Epoch 414  Train loss: -4.143045066384708  Val loss: -4.532777412650511
Saving best model, epoch: 414
Epoch 415
-------------------------------
Batch 1/64 loss: -4.1669135093688965
Batch 2/64 loss: -4.228202819824219
Batch 3/64 loss: -3.989262104034424
Batch 4/64 loss: -4.248716831207275
Batch 5/64 loss: -4.277458667755127
Batch 6/64 loss: -4.272188186645508
Batch 7/64 loss: -4.047480583190918
Batch 8/64 loss: -4.109204292297363
Batch 9/64 loss: -4.163226127624512
Batch 10/64 loss: -4.148899078369141
Batch 11/64 loss: -3.552194118499756
Batch 12/64 loss: -4.08867073059082
Batch 13/64 loss: -4.14003849029541
Batch 14/64 loss: -3.678140640258789
Batch 15/64 loss: -3.3410425186157227
Batch 16/64 loss: -4.006062030792236
Batch 17/64 loss: -4.109100341796875
Batch 18/64 loss: -3.8472771644592285
Batch 19/64 loss: -4.067653179168701
Batch 20/64 loss: -3.47841739654541
Batch 21/64 loss: -4.185712814331055
Batch 22/64 loss: -4.1108245849609375
Batch 23/64 loss: -4.055006504058838
Batch 24/64 loss: -3.739302635192871
Batch 25/64 loss: -4.1473469734191895
Batch 26/64 loss: -4.024805068969727
Batch 27/64 loss: -4.12692403793335
Batch 28/64 loss: -3.494746208190918
Batch 29/64 loss: -4.136570930480957
Batch 30/64 loss: -3.9384827613830566
Batch 31/64 loss: -4.108952045440674
Batch 32/64 loss: -4.043102741241455
Batch 33/64 loss: -4.098951816558838
Batch 34/64 loss: -3.9183716773986816
Batch 35/64 loss: -3.8587799072265625
Batch 36/64 loss: -4.035895347595215
Batch 37/64 loss: -3.7691259384155273
Batch 38/64 loss: -3.9774398803710938
Batch 39/64 loss: -3.736198902130127
Batch 40/64 loss: -3.963932991027832
Batch 41/64 loss: -3.851011276245117
Batch 42/64 loss: -4.079529285430908
Batch 43/64 loss: -3.926431179046631
Batch 44/64 loss: -4.105500221252441
Batch 45/64 loss: -3.424323081970215
Batch 46/64 loss: -4.146678447723389
Batch 47/64 loss: -4.062316417694092
Batch 48/64 loss: -3.627957820892334
Batch 49/64 loss: -3.770994186401367
Batch 50/64 loss: -3.906745433807373
Batch 51/64 loss: -4.1134233474731445
Batch 52/64 loss: -3.9981908798217773
Batch 53/64 loss: -4.177894592285156
Batch 54/64 loss: -4.002243518829346
Batch 55/64 loss: -4.033000469207764
Batch 56/64 loss: -3.926729202270508
Batch 57/64 loss: -3.8270397186279297
Batch 58/64 loss: -4.115854740142822
Batch 59/64 loss: -3.952138900756836
Batch 60/64 loss: -3.9656524658203125
Batch 61/64 loss: -3.9676175117492676
Batch 62/64 loss: -4.1571221351623535
Batch 63/64 loss: -4.080873966217041
Batch 64/64 loss: -8.31838607788086
Epoch 415  Train loss: -4.029626367606369  Val loss: -4.3181532633673285
Epoch 416
-------------------------------
Batch 1/64 loss: -4.084461212158203
Batch 2/64 loss: -4.139526844024658
Batch 3/64 loss: -3.9586620330810547
Batch 4/64 loss: -3.9992127418518066
Batch 5/64 loss: -4.141552925109863
Batch 6/64 loss: -4.045297145843506
Batch 7/64 loss: -3.7774033546447754
Batch 8/64 loss: -3.2079343795776367
Batch 9/64 loss: -4.17687463760376
Batch 10/64 loss: -4.076450347900391
Batch 11/64 loss: -3.831768035888672
Batch 12/64 loss: -4.126184463500977
Batch 13/64 loss: -4.162106037139893
Batch 14/64 loss: -4.1309967041015625
Batch 15/64 loss: -4.1188249588012695
Batch 16/64 loss: -4.020370006561279
Batch 17/64 loss: -3.6034536361694336
Batch 18/64 loss: -3.980900287628174
Batch 19/64 loss: -3.9282326698303223
Batch 20/64 loss: -3.967989444732666
Batch 21/64 loss: -4.043130874633789
Batch 22/64 loss: -4.020475387573242
Batch 23/64 loss: -3.9865102767944336
Batch 24/64 loss: -3.9382171630859375
Batch 25/64 loss: -3.886287212371826
Batch 26/64 loss: -3.6037397384643555
Batch 27/64 loss: -4.174923896789551
Batch 28/64 loss: -3.888063430786133
Batch 29/64 loss: -3.9431862831115723
Batch 30/64 loss: -3.883965492248535
Batch 31/64 loss: -4.1644721031188965
Batch 32/64 loss: -4.165162086486816
Batch 33/64 loss: -4.0355377197265625
Batch 34/64 loss: -3.9656825065612793
Batch 35/64 loss: -4.0144171714782715
Batch 36/64 loss: -4.031351566314697
Batch 37/64 loss: -4.120802402496338
Batch 38/64 loss: -4.035318851470947
Batch 39/64 loss: -4.12164306640625
Batch 40/64 loss: -3.993368148803711
Batch 41/64 loss: -4.062821388244629
Batch 42/64 loss: -3.6939563751220703
Batch 43/64 loss: -4.149783611297607
Batch 44/64 loss: -3.9282150268554688
Batch 45/64 loss: -3.5867881774902344
Batch 46/64 loss: -4.099506855010986
Batch 47/64 loss: -4.0318121910095215
Batch 48/64 loss: -3.969120979309082
Batch 49/64 loss: -4.083719253540039
Batch 50/64 loss: -4.2138495445251465
Batch 51/64 loss: -4.027575969696045
Batch 52/64 loss: -4.168236255645752
Batch 53/64 loss: -4.069128513336182
Batch 54/64 loss: -4.068107604980469
Batch 55/64 loss: -4.139848232269287
Batch 56/64 loss: -3.8463244438171387
Batch 57/64 loss: -4.04325008392334
Batch 58/64 loss: -4.054908752441406
Batch 59/64 loss: -4.131352424621582
Batch 60/64 loss: -3.818478584289551
Batch 61/64 loss: -4.022931098937988
Batch 62/64 loss: -4.263640880584717
Batch 63/64 loss: -4.142126083374023
Batch 64/64 loss: -7.913895606994629
Epoch 416  Train loss: -4.0477703730265295  Val loss: -4.342865344175358
Epoch 417
-------------------------------
Batch 1/64 loss: -4.066535949707031
Batch 2/64 loss: -3.7540082931518555
Batch 3/64 loss: -4.075405597686768
Batch 4/64 loss: -4.079162120819092
Batch 5/64 loss: -4.083019733428955
Batch 6/64 loss: -4.149473190307617
Batch 7/64 loss: -3.9866347312927246
Batch 8/64 loss: -3.9885497093200684
Batch 9/64 loss: -4.051916599273682
Batch 10/64 loss: -4.010857582092285
Batch 11/64 loss: -4.179810523986816
Batch 12/64 loss: -3.776027202606201
Batch 13/64 loss: -4.026946067810059
Batch 14/64 loss: -3.915341377258301
Batch 15/64 loss: -4.058948040008545
Batch 16/64 loss: -3.621917247772217
Batch 17/64 loss: -4.114505290985107
Batch 18/64 loss: -4.14763879776001
Batch 19/64 loss: -4.065704822540283
Batch 20/64 loss: -4.055826663970947
Batch 21/64 loss: -3.5659265518188477
Batch 22/64 loss: -4.052840709686279
Batch 23/64 loss: -4.064957618713379
Batch 24/64 loss: -3.8863606452941895
Batch 25/64 loss: -3.963681697845459
Batch 26/64 loss: -4.111262321472168
Batch 27/64 loss: -4.0987019538879395
Batch 28/64 loss: -3.9348788261413574
Batch 29/64 loss: -4.025614261627197
Batch 30/64 loss: -4.026459693908691
Batch 31/64 loss: -4.273739814758301
Batch 32/64 loss: -3.8643593788146973
Batch 33/64 loss: -4.213054180145264
Batch 34/64 loss: -4.132262229919434
Batch 35/64 loss: -3.9097628593444824
Batch 36/64 loss: -4.038919448852539
Batch 37/64 loss: -4.014882564544678
Batch 38/64 loss: -4.019278049468994
Batch 39/64 loss: -4.058986186981201
Batch 40/64 loss: -3.9738779067993164
Batch 41/64 loss: -4.041905879974365
Batch 42/64 loss: -4.102528095245361
Batch 43/64 loss: -4.008021354675293
Batch 44/64 loss: -3.2954893112182617
Batch 45/64 loss: -4.003757953643799
Batch 46/64 loss: -4.148518085479736
Batch 47/64 loss: -4.057183742523193
Batch 48/64 loss: -4.159818649291992
Batch 49/64 loss: -4.091930389404297
Batch 50/64 loss: -3.9678759574890137
Batch 51/64 loss: -3.9833803176879883
Batch 52/64 loss: -3.7285447120666504
Batch 53/64 loss: -4.006476879119873
Batch 54/64 loss: -4.038719654083252
Batch 55/64 loss: -4.033667087554932
Batch 56/64 loss: -3.9023075103759766
Batch 57/64 loss: -3.9992456436157227
Batch 58/64 loss: -4.007262706756592
Batch 59/64 loss: -3.871530532836914
Batch 60/64 loss: -4.045778751373291
Batch 61/64 loss: -4.008114814758301
Batch 62/64 loss: -4.049736022949219
Batch 63/64 loss: -3.992680549621582
Batch 64/64 loss: -8.571365356445312
Epoch 417  Train loss: -4.05350643232757  Val loss: -4.444742615689936
Epoch 418
-------------------------------
Batch 1/64 loss: -4.0137810707092285
Batch 2/64 loss: -4.09259557723999
Batch 3/64 loss: -3.783787250518799
Batch 4/64 loss: -3.897085189819336
Batch 5/64 loss: -4.086700916290283
Batch 6/64 loss: -4.204684257507324
Batch 7/64 loss: -4.022342681884766
Batch 8/64 loss: -4.061315536499023
Batch 9/64 loss: -4.091012954711914
Batch 10/64 loss: -3.9928054809570312
Batch 11/64 loss: -4.151368141174316
Batch 12/64 loss: -4.1150617599487305
Batch 13/64 loss: -4.0609517097473145
Batch 14/64 loss: -3.989396095275879
Batch 15/64 loss: -4.154611587524414
Batch 16/64 loss: -3.976463794708252
Batch 17/64 loss: -4.151938438415527
Batch 18/64 loss: -4.193791389465332
Batch 19/64 loss: -4.1488356590271
Batch 20/64 loss: -3.976125717163086
Batch 21/64 loss: -4.164831161499023
Batch 22/64 loss: -4.021503448486328
Batch 23/64 loss: -3.991575241088867
Batch 24/64 loss: -4.192458152770996
Batch 25/64 loss: -4.05587911605835
Batch 26/64 loss: -3.9930763244628906
Batch 27/64 loss: -4.031805515289307
Batch 28/64 loss: -3.992504596710205
Batch 29/64 loss: -4.066681861877441
Batch 30/64 loss: -4.070840358734131
Batch 31/64 loss: -3.7687087059020996
Batch 32/64 loss: -4.212821006774902
Batch 33/64 loss: -4.10273551940918
Batch 34/64 loss: -3.9806742668151855
Batch 35/64 loss: -4.0579400062561035
Batch 36/64 loss: -4.123121738433838
Batch 37/64 loss: -3.9937214851379395
Batch 38/64 loss: -4.124619007110596
Batch 39/64 loss: -3.957091808319092
Batch 40/64 loss: -3.993075370788574
Batch 41/64 loss: -4.156105995178223
Batch 42/64 loss: -4.087142467498779
Batch 43/64 loss: -4.0345458984375
Batch 44/64 loss: -4.008510112762451
Batch 45/64 loss: -3.9645209312438965
Batch 46/64 loss: -3.6622653007507324
Batch 47/64 loss: -3.903769016265869
Batch 48/64 loss: -4.041584491729736
Batch 49/64 loss: -3.9095687866210938
Batch 50/64 loss: -4.0142598152160645
Batch 51/64 loss: -4.0538787841796875
Batch 52/64 loss: -4.01860237121582
Batch 53/64 loss: -3.961655616760254
Batch 54/64 loss: -3.984360694885254
Batch 55/64 loss: -3.900825023651123
Batch 56/64 loss: -3.8596696853637695
Batch 57/64 loss: -4.214062213897705
Batch 58/64 loss: -4.221999645233154
Batch 59/64 loss: -3.7742533683776855
Batch 60/64 loss: -4.136502265930176
Batch 61/64 loss: -3.962649345397949
Batch 62/64 loss: -3.920264720916748
Batch 63/64 loss: -4.060404300689697
Batch 64/64 loss: -8.235509872436523
Epoch 418  Train loss: -4.079817304424211  Val loss: -4.436942411861878
Epoch 419
-------------------------------
Batch 1/64 loss: -4.168973922729492
Batch 2/64 loss: -3.978264331817627
Batch 3/64 loss: -3.7166619300842285
Batch 4/64 loss: -4.016230583190918
Batch 5/64 loss: -4.015716075897217
Batch 6/64 loss: -4.233911991119385
Batch 7/64 loss: -4.024599075317383
Batch 8/64 loss: -3.6489028930664062
Batch 9/64 loss: -4.114219665527344
Batch 10/64 loss: -4.101391315460205
Batch 11/64 loss: -4.000602722167969
Batch 12/64 loss: -4.081887245178223
Batch 13/64 loss: -4.064273834228516
Batch 14/64 loss: -4.04520320892334
Batch 15/64 loss: -3.7884578704833984
Batch 16/64 loss: -3.614445686340332
Batch 17/64 loss: -3.9369916915893555
Batch 18/64 loss: -4.105928421020508
Batch 19/64 loss: -4.086978912353516
Batch 20/64 loss: -4.011464595794678
Batch 21/64 loss: -4.111577033996582
Batch 22/64 loss: -4.034242153167725
Batch 23/64 loss: -4.0458292961120605
Batch 24/64 loss: -4.044795513153076
Batch 25/64 loss: -3.994586944580078
Batch 26/64 loss: -3.9346203804016113
Batch 27/64 loss: -4.156805992126465
Batch 28/64 loss: -3.9761404991149902
Batch 29/64 loss: -4.055624485015869
Batch 30/64 loss: -3.674675464630127
Batch 31/64 loss: -3.94771671295166
Batch 32/64 loss: -4.100793838500977
Batch 33/64 loss: -4.010116100311279
Batch 34/64 loss: -3.9920568466186523
Batch 35/64 loss: -3.926382064819336
Batch 36/64 loss: -3.931429862976074
Batch 37/64 loss: -3.976625442504883
Batch 38/64 loss: -3.995095729827881
Batch 39/64 loss: -4.1331377029418945
Batch 40/64 loss: -3.9989686012268066
Batch 41/64 loss: -3.9019007682800293
Batch 42/64 loss: -4.0282368659973145
Batch 43/64 loss: -4.052668571472168
Batch 44/64 loss: -4.021444797515869
Batch 45/64 loss: -4.161828517913818
Batch 46/64 loss: -4.017301559448242
Batch 47/64 loss: -4.06837797164917
Batch 48/64 loss: -3.8919897079467773
Batch 49/64 loss: -3.9677023887634277
Batch 50/64 loss: -4.225604057312012
Batch 51/64 loss: -3.9659981727600098
Batch 52/64 loss: -4.16263484954834
Batch 53/64 loss: -4.0784382820129395
Batch 54/64 loss: -4.008244514465332
Batch 55/64 loss: -4.1134562492370605
Batch 56/64 loss: -4.228450775146484
Batch 57/64 loss: -4.040839195251465
Batch 58/64 loss: -4.069311618804932
Batch 59/64 loss: -4.116504192352295
Batch 60/64 loss: -4.007586479187012
Batch 61/64 loss: -4.250353813171387
Batch 62/64 loss: -4.074291706085205
Batch 63/64 loss: -4.291048526763916
Batch 64/64 loss: -8.683361053466797
Epoch 419  Train loss: -4.079263702093386  Val loss: -4.479118871524981
Epoch 420
-------------------------------
Batch 1/64 loss: -3.958911418914795
Batch 2/64 loss: -4.133272171020508
Batch 3/64 loss: -3.747030735015869
Batch 4/64 loss: -4.218899726867676
Batch 5/64 loss: -4.107754707336426
Batch 6/64 loss: -4.176034927368164
Batch 7/64 loss: -4.027480125427246
Batch 8/64 loss: -4.073518753051758
Batch 9/64 loss: -4.111598968505859
Batch 10/64 loss: -4.020401477813721
Batch 11/64 loss: -4.102638244628906
Batch 12/64 loss: -4.070119857788086
Batch 13/64 loss: -4.118670463562012
Batch 14/64 loss: -4.0474066734313965
Batch 15/64 loss: -3.956329822540283
Batch 16/64 loss: -3.764578342437744
Batch 17/64 loss: -4.0890421867370605
Batch 18/64 loss: -4.189208030700684
Batch 19/64 loss: -4.061862945556641
Batch 20/64 loss: -4.136672019958496
Batch 21/64 loss: -4.211270332336426
Batch 22/64 loss: -4.076165199279785
Batch 23/64 loss: -4.12196683883667
Batch 24/64 loss: -4.147850036621094
Batch 25/64 loss: -4.178404808044434
Batch 26/64 loss: -4.218914985656738
Batch 27/64 loss: -4.026966094970703
Batch 28/64 loss: -4.0740532875061035
Batch 29/64 loss: -3.984999656677246
Batch 30/64 loss: -4.199971675872803
Batch 31/64 loss: -4.208110809326172
Batch 32/64 loss: -4.030580997467041
Batch 33/64 loss: -4.154781818389893
Batch 34/64 loss: -4.13377571105957
Batch 35/64 loss: -3.8413734436035156
Batch 36/64 loss: -4.211989402770996
Batch 37/64 loss: -4.132603645324707
Batch 38/64 loss: -4.040984630584717
Batch 39/64 loss: -4.075270175933838
Batch 40/64 loss: -3.996396064758301
Batch 41/64 loss: -4.032034873962402
Batch 42/64 loss: -3.9781365394592285
Batch 43/64 loss: -4.20286226272583
Batch 44/64 loss: -3.840986728668213
Batch 45/64 loss: -3.7899227142333984
Batch 46/64 loss: -4.068679332733154
Batch 47/64 loss: -3.717668056488037
Batch 48/64 loss: -4.008021354675293
Batch 49/64 loss: -3.9446635246276855
Batch 50/64 loss: -4.045368671417236
Batch 51/64 loss: -4.117950439453125
Batch 52/64 loss: -4.0183796882629395
Batch 53/64 loss: -3.9711461067199707
Batch 54/64 loss: -3.6788907051086426
Batch 55/64 loss: -3.958707332611084
Batch 56/64 loss: -4.133136749267578
Batch 57/64 loss: -3.987643241882324
Batch 58/64 loss: -4.213737487792969
Batch 59/64 loss: -4.178651809692383
Batch 60/64 loss: -3.9877891540527344
Batch 61/64 loss: -3.957064628601074
Batch 62/64 loss: -3.9450063705444336
Batch 63/64 loss: -4.0331244468688965
Batch 64/64 loss: -8.4514741897583
Epoch 420  Train loss: -4.099231985503552  Val loss: -4.308775649447622
Epoch 421
-------------------------------
Batch 1/64 loss: -4.000085353851318
Batch 2/64 loss: -3.9042978286743164
Batch 3/64 loss: -4.098398685455322
Batch 4/64 loss: -3.994107246398926
Batch 5/64 loss: -3.451791763305664
Batch 6/64 loss: -3.8819923400878906
Batch 7/64 loss: -3.8720617294311523
Batch 8/64 loss: -4.034205913543701
Batch 9/64 loss: -4.11876916885376
Batch 10/64 loss: -4.047827243804932
Batch 11/64 loss: -4.053252220153809
Batch 12/64 loss: -4.16992712020874
Batch 13/64 loss: -4.006939888000488
Batch 14/64 loss: -4.0028977394104
Batch 15/64 loss: -3.759829044342041
Batch 16/64 loss: -4.1497344970703125
Batch 17/64 loss: -3.741870880126953
Batch 18/64 loss: -4.019473075866699
Batch 19/64 loss: -3.7312870025634766
Batch 20/64 loss: -3.887631893157959
Batch 21/64 loss: -4.17926549911499
Batch 22/64 loss: -3.9977831840515137
Batch 23/64 loss: -4.127941608428955
Batch 24/64 loss: -4.080376148223877
Batch 25/64 loss: -3.901184558868408
Batch 26/64 loss: -3.8970751762390137
Batch 27/64 loss: -3.978452682495117
Batch 28/64 loss: -3.812417507171631
Batch 29/64 loss: -4.033555507659912
Batch 30/64 loss: -3.6157612800598145
Batch 31/64 loss: -3.7768168449401855
Batch 32/64 loss: -4.0241923332214355
Batch 33/64 loss: -4.272260665893555
Batch 34/64 loss: -4.0840582847595215
Batch 35/64 loss: -4.1017961502075195
Batch 36/64 loss: -4.0597734451293945
Batch 37/64 loss: -3.865243434906006
Batch 38/64 loss: -4.093613147735596
Batch 39/64 loss: -3.920590400695801
Batch 40/64 loss: -4.140854835510254
Batch 41/64 loss: -3.9833641052246094
Batch 42/64 loss: -4.158204555511475
Batch 43/64 loss: -4.0114898681640625
Batch 44/64 loss: -4.026839733123779
Batch 45/64 loss: -4.109772205352783
Batch 46/64 loss: -3.6125478744506836
Batch 47/64 loss: -3.9948935508728027
Batch 48/64 loss: -4.045867443084717
Batch 49/64 loss: -4.181790828704834
Batch 50/64 loss: -4.04695987701416
Batch 51/64 loss: -4.075568199157715
Batch 52/64 loss: -3.8926196098327637
Batch 53/64 loss: -4.157874584197998
Batch 54/64 loss: -4.0064239501953125
Batch 55/64 loss: -3.88822078704834
Batch 56/64 loss: -4.138370513916016
Batch 57/64 loss: -4.127716064453125
Batch 58/64 loss: -4.110311508178711
Batch 59/64 loss: -4.023387908935547
Batch 60/64 loss: -4.0973591804504395
Batch 61/64 loss: -3.7184410095214844
Batch 62/64 loss: -3.9163198471069336
Batch 63/64 loss: -3.9396519660949707
Batch 64/64 loss: -8.43907356262207
Epoch 421  Train loss: -4.038944214465571  Val loss: -4.361043150072655
Epoch 422
-------------------------------
Batch 1/64 loss: -4.037971019744873
Batch 2/64 loss: -3.9986820220947266
Batch 3/64 loss: -3.9933948516845703
Batch 4/64 loss: -3.9142537117004395
Batch 5/64 loss: -4.077146053314209
Batch 6/64 loss: -4.055564880371094
Batch 7/64 loss: -4.004316806793213
Batch 8/64 loss: -3.9581079483032227
Batch 9/64 loss: -3.9538745880126953
Batch 10/64 loss: -4.051273822784424
Batch 11/64 loss: -4.134989261627197
Batch 12/64 loss: -3.9656219482421875
Batch 13/64 loss: -3.9740428924560547
Batch 14/64 loss: -3.831509590148926
Batch 15/64 loss: -4.148353099822998
Batch 16/64 loss: -4.281391143798828
Batch 17/64 loss: -3.9494028091430664
Batch 18/64 loss: -3.8135147094726562
Batch 19/64 loss: -4.102599620819092
Batch 20/64 loss: -4.0805253982543945
Batch 21/64 loss: -4.098606109619141
Batch 22/64 loss: -3.8935675621032715
Batch 23/64 loss: -4.038781642913818
Batch 24/64 loss: -4.101081848144531
Batch 25/64 loss: -4.030927658081055
Batch 26/64 loss: -3.8568153381347656
Batch 27/64 loss: -3.986832618713379
Batch 28/64 loss: -4.046655654907227
Batch 29/64 loss: -4.128116607666016
Batch 30/64 loss: -4.029812335968018
Batch 31/64 loss: -3.581973075866699
Batch 32/64 loss: -4.212808132171631
Batch 33/64 loss: -3.8073344230651855
Batch 34/64 loss: -4.179733753204346
Batch 35/64 loss: -4.102690696716309
Batch 36/64 loss: -4.118612766265869
Batch 37/64 loss: -4.221000671386719
Batch 38/64 loss: -4.122043609619141
Batch 39/64 loss: -4.029158592224121
Batch 40/64 loss: -4.173085689544678
Batch 41/64 loss: -3.913290023803711
Batch 42/64 loss: -4.127744674682617
Batch 43/64 loss: -4.198328018188477
Batch 44/64 loss: -4.235112190246582
Batch 45/64 loss: -4.0794854164123535
Batch 46/64 loss: -4.048306941986084
Batch 47/64 loss: -3.983409881591797
Batch 48/64 loss: -4.045146942138672
Batch 49/64 loss: -4.302395343780518
Batch 50/64 loss: -4.170915126800537
Batch 51/64 loss: -3.9489240646362305
Batch 52/64 loss: -4.090801239013672
Batch 53/64 loss: -3.9630126953125
Batch 54/64 loss: -4.131227493286133
Batch 55/64 loss: -4.090533256530762
Batch 56/64 loss: -3.6290812492370605
Batch 57/64 loss: -4.058861255645752
Batch 58/64 loss: -3.974917411804199
Batch 59/64 loss: -3.755157470703125
Batch 60/64 loss: -3.7935938835144043
Batch 61/64 loss: -4.025497913360596
Batch 62/64 loss: -4.1064677238464355
Batch 63/64 loss: -3.9441981315612793
Batch 64/64 loss: -8.731694221496582
Epoch 422  Train loss: -4.082374180064482  Val loss: -4.433213197898209
Epoch 423
-------------------------------
Batch 1/64 loss: -4.0191426277160645
Batch 2/64 loss: -4.0747222900390625
Batch 3/64 loss: -4.104243278503418
Batch 4/64 loss: -4.065768241882324
Batch 5/64 loss: -4.0355095863342285
Batch 6/64 loss: -4.1303391456604
Batch 7/64 loss: -3.9675512313842773
Batch 8/64 loss: -4.227006912231445
Batch 9/64 loss: -4.074337005615234
Batch 10/64 loss: -4.104450225830078
Batch 11/64 loss: -3.8790035247802734
Batch 12/64 loss: -4.08321475982666
Batch 13/64 loss: -4.052907466888428
Batch 14/64 loss: -4.007950782775879
Batch 15/64 loss: -3.89994478225708
Batch 16/64 loss: -4.000694751739502
Batch 17/64 loss: -4.207173824310303
Batch 18/64 loss: -3.78206729888916
Batch 19/64 loss: -4.076202869415283
Batch 20/64 loss: -4.112309455871582
Batch 21/64 loss: -4.0791096687316895
Batch 22/64 loss: -4.111568927764893
Batch 23/64 loss: -4.014403820037842
Batch 24/64 loss: -4.0277099609375
Batch 25/64 loss: -4.0771803855896
Batch 26/64 loss: -4.1024603843688965
Batch 27/64 loss: -3.9875645637512207
Batch 28/64 loss: -4.125738143920898
Batch 29/64 loss: -4.3141279220581055
Batch 30/64 loss: -4.055774688720703
Batch 31/64 loss: -4.1970062255859375
Batch 32/64 loss: -4.2049760818481445
Batch 33/64 loss: -4.131771564483643
Batch 34/64 loss: -4.079916954040527
Batch 35/64 loss: -3.88063907623291
Batch 36/64 loss: -3.762213706970215
Batch 37/64 loss: -4.029999256134033
Batch 38/64 loss: -3.3501157760620117
Batch 39/64 loss: -4.09401273727417
Batch 40/64 loss: -4.195382595062256
Batch 41/64 loss: -4.0342864990234375
Batch 42/64 loss: -3.919196128845215
Batch 43/64 loss: -3.836124897003174
Batch 44/64 loss: -4.084921360015869
Batch 45/64 loss: -4.0743889808654785
Batch 46/64 loss: -3.9331789016723633
Batch 47/64 loss: -3.8637332916259766
Batch 48/64 loss: -3.7802700996398926
Batch 49/64 loss: -3.9898862838745117
Batch 50/64 loss: -4.252173900604248
Batch 51/64 loss: -4.024768829345703
Batch 52/64 loss: -4.116447925567627
Batch 53/64 loss: -4.103066444396973
Batch 54/64 loss: -4.033944129943848
Batch 55/64 loss: -4.112489700317383
Batch 56/64 loss: -4.0253825187683105
Batch 57/64 loss: -3.9593043327331543
Batch 58/64 loss: -3.9334144592285156
Batch 59/64 loss: -4.129101753234863
Batch 60/64 loss: -3.978018283843994
Batch 61/64 loss: -3.6810317039489746
Batch 62/64 loss: -4.044338226318359
Batch 63/64 loss: -4.1280388832092285
Batch 64/64 loss: -8.591548919677734
Epoch 423  Train loss: -4.0816844192205695  Val loss: -4.537791982958817
Saving best model, epoch: 423
Epoch 424
-------------------------------
Batch 1/64 loss: -4.12252950668335
Batch 2/64 loss: -3.8143672943115234
Batch 3/64 loss: -4.148253917694092
Batch 4/64 loss: -3.985940456390381
Batch 5/64 loss: -4.1506242752075195
Batch 6/64 loss: -4.140499114990234
Batch 7/64 loss: -3.9568824768066406
Batch 8/64 loss: -3.887418746948242
Batch 9/64 loss: -3.9697623252868652
Batch 10/64 loss: -4.119770526885986
Batch 11/64 loss: -4.0254225730896
Batch 12/64 loss: -3.8897438049316406
Batch 13/64 loss: -4.066451072692871
Batch 14/64 loss: -4.0087571144104
Batch 15/64 loss: -3.73740291595459
Batch 16/64 loss: -4.0417375564575195
Batch 17/64 loss: -3.491403102874756
Batch 18/64 loss: -4.245802402496338
Batch 19/64 loss: -3.9585494995117188
Batch 20/64 loss: -4.077035427093506
Batch 21/64 loss: -3.9251670837402344
Batch 22/64 loss: -3.941955089569092
Batch 23/64 loss: -4.00801944732666
Batch 24/64 loss: -4.110462188720703
Batch 25/64 loss: -3.991992473602295
Batch 26/64 loss: -4.053725719451904
Batch 27/64 loss: -3.96199369430542
Batch 28/64 loss: -4.143514156341553
Batch 29/64 loss: -3.9709863662719727
Batch 30/64 loss: -4.214372158050537
Batch 31/64 loss: -3.843576431274414
Batch 32/64 loss: -4.033507823944092
Batch 33/64 loss: -4.220610618591309
Batch 34/64 loss: -4.0067949295043945
Batch 35/64 loss: -4.0853376388549805
Batch 36/64 loss: -4.222433090209961
Batch 37/64 loss: -4.080423355102539
Batch 38/64 loss: -4.068772792816162
Batch 39/64 loss: -4.226719856262207
Batch 40/64 loss: -3.808742046356201
Batch 41/64 loss: -4.130701541900635
Batch 42/64 loss: -4.0939249992370605
Batch 43/64 loss: -4.061068058013916
Batch 44/64 loss: -4.108859062194824
Batch 45/64 loss: -3.9665446281433105
Batch 46/64 loss: -3.952012538909912
Batch 47/64 loss: -4.006196975708008
Batch 48/64 loss: -4.133999347686768
Batch 49/64 loss: -4.1329193115234375
Batch 50/64 loss: -4.011496543884277
Batch 51/64 loss: -4.092958927154541
Batch 52/64 loss: -4.056151390075684
Batch 53/64 loss: -4.119295120239258
Batch 54/64 loss: -3.97902250289917
Batch 55/64 loss: -4.208510875701904
Batch 56/64 loss: -3.981182098388672
Batch 57/64 loss: -4.020615100860596
Batch 58/64 loss: -4.121216773986816
Batch 59/64 loss: -4.078714847564697
Batch 60/64 loss: -3.6187100410461426
Batch 61/64 loss: -4.131540298461914
Batch 62/64 loss: -3.9806699752807617
Batch 63/64 loss: -3.9786715507507324
Batch 64/64 loss: -8.30648422241211
Epoch 424  Train loss: -4.077683243097043  Val loss: -4.489633330774471
Epoch 425
-------------------------------
Batch 1/64 loss: -4.027544975280762
Batch 2/64 loss: -4.190929889678955
Batch 3/64 loss: -4.042488098144531
Batch 4/64 loss: -4.15527868270874
Batch 5/64 loss: -4.209019660949707
Batch 6/64 loss: -4.197290897369385
Batch 7/64 loss: -4.1971306800842285
Batch 8/64 loss: -4.243700981140137
Batch 9/64 loss: -3.964491367340088
Batch 10/64 loss: -4.0816168785095215
Batch 11/64 loss: -3.535736083984375
Batch 12/64 loss: -4.080156326293945
Batch 13/64 loss: -4.013645648956299
Batch 14/64 loss: -4.150434970855713
Batch 15/64 loss: -3.6639113426208496
Batch 16/64 loss: -4.057174205780029
Batch 17/64 loss: -4.076415061950684
Batch 18/64 loss: -4.0629496574401855
Batch 19/64 loss: -3.6990346908569336
Batch 20/64 loss: -4.084545612335205
Batch 21/64 loss: -4.124452114105225
Batch 22/64 loss: -4.100861549377441
Batch 23/64 loss: -4.067127227783203
Batch 24/64 loss: -3.9219255447387695
Batch 25/64 loss: -3.8493752479553223
Batch 26/64 loss: -3.9403223991394043
Batch 27/64 loss: -3.9708356857299805
Batch 28/64 loss: -4.126272678375244
Batch 29/64 loss: -3.7485904693603516
Batch 30/64 loss: -4.051519393920898
Batch 31/64 loss: -3.937775135040283
Batch 32/64 loss: -4.243838787078857
Batch 33/64 loss: -4.134718418121338
Batch 34/64 loss: -3.7150444984436035
Batch 35/64 loss: -3.9750595092773438
Batch 36/64 loss: -4.00678825378418
Batch 37/64 loss: -3.910226821899414
Batch 38/64 loss: -4.160467624664307
Batch 39/64 loss: -4.071606159210205
Batch 40/64 loss: -4.0597004890441895
Batch 41/64 loss: -3.866359233856201
Batch 42/64 loss: -3.92659330368042
Batch 43/64 loss: -4.069131851196289
Batch 44/64 loss: -4.024649143218994
Batch 45/64 loss: -3.8330326080322266
Batch 46/64 loss: -4.094899654388428
Batch 47/64 loss: -3.8084030151367188
Batch 48/64 loss: -4.0676798820495605
Batch 49/64 loss: -4.03248929977417
Batch 50/64 loss: -4.166367053985596
Batch 51/64 loss: -3.9276375770568848
Batch 52/64 loss: -4.022165775299072
Batch 53/64 loss: -4.133988380432129
Batch 54/64 loss: -3.981325626373291
Batch 55/64 loss: -4.004492282867432
Batch 56/64 loss: -3.9625840187072754
Batch 57/64 loss: -3.94547176361084
Batch 58/64 loss: -3.6841001510620117
Batch 59/64 loss: -4.189197063446045
Batch 60/64 loss: -3.7259349822998047
Batch 61/64 loss: -4.011763095855713
Batch 62/64 loss: -3.997326374053955
Batch 63/64 loss: -4.074896335601807
Batch 64/64 loss: -8.485918045043945
Epoch 425  Train loss: -4.059057736864277  Val loss: -4.343577316126873
Epoch 426
-------------------------------
Batch 1/64 loss: -3.887606620788574
Batch 2/64 loss: -4.079808712005615
Batch 3/64 loss: -4.024256229400635
Batch 4/64 loss: -4.155116558074951
Batch 5/64 loss: -4.117218494415283
Batch 6/64 loss: -3.966559410095215
Batch 7/64 loss: -3.9559712409973145
Batch 8/64 loss: -4.038362979888916
Batch 9/64 loss: -4.003659248352051
Batch 10/64 loss: -4.090555191040039
Batch 11/64 loss: -4.038285255432129
Batch 12/64 loss: -3.066880226135254
Batch 13/64 loss: -3.8744306564331055
Batch 14/64 loss: -3.9115653038024902
Batch 15/64 loss: -3.951460361480713
Batch 16/64 loss: -4.024005889892578
Batch 17/64 loss: -4.17280912399292
Batch 18/64 loss: -4.050546646118164
Batch 19/64 loss: -4.156952857971191
Batch 20/64 loss: -3.9323716163635254
Batch 21/64 loss: -4.048890113830566
Batch 22/64 loss: -4.036588191986084
Batch 23/64 loss: -4.263760566711426
Batch 24/64 loss: -4.115332126617432
Batch 25/64 loss: -4.158874988555908
Batch 26/64 loss: -4.072572708129883
Batch 27/64 loss: -3.855045795440674
Batch 28/64 loss: -3.7550063133239746
Batch 29/64 loss: -4.139132499694824
Batch 30/64 loss: -4.191981315612793
Batch 31/64 loss: -4.092968940734863
Batch 32/64 loss: -4.02395486831665
Batch 33/64 loss: -4.077512264251709
Batch 34/64 loss: -4.2033610343933105
Batch 35/64 loss: -3.9022083282470703
Batch 36/64 loss: -4.012211322784424
Batch 37/64 loss: -4.196969032287598
Batch 38/64 loss: -4.0286664962768555
Batch 39/64 loss: -3.8372769355773926
Batch 40/64 loss: -3.936371326446533
Batch 41/64 loss: -4.078766822814941
Batch 42/64 loss: -4.106362342834473
Batch 43/64 loss: -4.064985275268555
Batch 44/64 loss: -4.049277305603027
Batch 45/64 loss: -4.041500091552734
Batch 46/64 loss: -4.0760674476623535
Batch 47/64 loss: -4.048562049865723
Batch 48/64 loss: -4.23327112197876
Batch 49/64 loss: -3.9290051460266113
Batch 50/64 loss: -3.5606813430786133
Batch 51/64 loss: -3.9547171592712402
Batch 52/64 loss: -4.0714921951293945
Batch 53/64 loss: -4.056572914123535
Batch 54/64 loss: -3.957906723022461
Batch 55/64 loss: -4.095776081085205
Batch 56/64 loss: -4.205230712890625
Batch 57/64 loss: -3.971745491027832
Batch 58/64 loss: -4.1312336921691895
Batch 59/64 loss: -4.03727912902832
Batch 60/64 loss: -4.082890510559082
Batch 61/64 loss: -4.195009708404541
Batch 62/64 loss: -4.310991287231445
Batch 63/64 loss: -4.162099361419678
Batch 64/64 loss: -8.659151077270508
Epoch 426  Train loss: -4.084123843323951  Val loss: -4.528587170892565
Epoch 427
-------------------------------
Batch 1/64 loss: -4.105859756469727
Batch 2/64 loss: -4.223039627075195
Batch 3/64 loss: -4.175409317016602
Batch 4/64 loss: -3.9685006141662598
Batch 5/64 loss: -4.021296977996826
Batch 6/64 loss: -4.214474678039551
Batch 7/64 loss: -4.126404285430908
Batch 8/64 loss: -4.23350715637207
Batch 9/64 loss: -4.146878719329834
Batch 10/64 loss: -4.214942455291748
Batch 11/64 loss: -3.9118895530700684
Batch 12/64 loss: -4.08335542678833
Batch 13/64 loss: -4.108668804168701
Batch 14/64 loss: -4.018265724182129
Batch 15/64 loss: -4.100090026855469
Batch 16/64 loss: -4.208021640777588
Batch 17/64 loss: -4.198520183563232
Batch 18/64 loss: -4.042463302612305
Batch 19/64 loss: -3.9980697631835938
Batch 20/64 loss: -3.896451473236084
Batch 21/64 loss: -4.208257675170898
Batch 22/64 loss: -4.028853893280029
Batch 23/64 loss: -3.771782398223877
Batch 24/64 loss: -4.126596927642822
Batch 25/64 loss: -4.180627822875977
Batch 26/64 loss: -3.995948314666748
Batch 27/64 loss: -4.185644626617432
Batch 28/64 loss: -4.187478542327881
Batch 29/64 loss: -4.203064441680908
Batch 30/64 loss: -4.252913951873779
Batch 31/64 loss: -4.19525671005249
Batch 32/64 loss: -4.139480113983154
Batch 33/64 loss: -3.870779514312744
Batch 34/64 loss: -4.253297328948975
Batch 35/64 loss: -4.0177788734436035
Batch 36/64 loss: -4.121054649353027
Batch 37/64 loss: -4.173354148864746
Batch 38/64 loss: -4.186281204223633
Batch 39/64 loss: -4.109347820281982
Batch 40/64 loss: -4.212128162384033
Batch 41/64 loss: -4.223142147064209
Batch 42/64 loss: -4.115196704864502
Batch 43/64 loss: -4.102416515350342
Batch 44/64 loss: -4.1139678955078125
Batch 45/64 loss: -4.123971462249756
Batch 46/64 loss: -3.8775696754455566
Batch 47/64 loss: -4.133062362670898
Batch 48/64 loss: -3.8438773155212402
Batch 49/64 loss: -4.1431803703308105
Batch 50/64 loss: -4.144974708557129
Batch 51/64 loss: -4.084816932678223
Batch 52/64 loss: -4.05286979675293
Batch 53/64 loss: -4.063418388366699
Batch 54/64 loss: -4.104344844818115
Batch 55/64 loss: -4.1221818923950195
Batch 56/64 loss: -4.037779808044434
Batch 57/64 loss: -4.142516136169434
Batch 58/64 loss: -4.091697692871094
Batch 59/64 loss: -4.2025580406188965
Batch 60/64 loss: -4.062038421630859
Batch 61/64 loss: -4.186675548553467
Batch 62/64 loss: -3.4570999145507812
Batch 63/64 loss: -3.921079158782959
Batch 64/64 loss: -8.705621719360352
Epoch 427  Train loss: -4.1458147235945155  Val loss: -4.5517901915455194
Saving best model, epoch: 427
Epoch 428
-------------------------------
Batch 1/64 loss: -4.140370845794678
Batch 2/64 loss: -4.138453483581543
Batch 3/64 loss: -4.2302021980285645
Batch 4/64 loss: -4.144762992858887
Batch 5/64 loss: -4.13314962387085
Batch 6/64 loss: -4.110195636749268
Batch 7/64 loss: -4.215210914611816
Batch 8/64 loss: -4.160220623016357
Batch 9/64 loss: -4.23434591293335
Batch 10/64 loss: -3.952726364135742
Batch 11/64 loss: -4.019015312194824
Batch 12/64 loss: -4.202347278594971
Batch 13/64 loss: -3.8081412315368652
Batch 14/64 loss: -4.101450443267822
Batch 15/64 loss: -4.179762363433838
Batch 16/64 loss: -4.2035441398620605
Batch 17/64 loss: -4.139744281768799
Batch 18/64 loss: -4.026872158050537
Batch 19/64 loss: -4.141037464141846
Batch 20/64 loss: -4.100522041320801
Batch 21/64 loss: -4.2894463539123535
Batch 22/64 loss: -3.9525976181030273
Batch 23/64 loss: -4.109341144561768
Batch 24/64 loss: -4.185055255889893
Batch 25/64 loss: -4.160196781158447
Batch 26/64 loss: -4.0128703117370605
Batch 27/64 loss: -4.083041191101074
Batch 28/64 loss: -4.01137638092041
Batch 29/64 loss: -4.135849952697754
Batch 30/64 loss: -4.061219215393066
Batch 31/64 loss: -4.1421308517456055
Batch 32/64 loss: -3.9861888885498047
Batch 33/64 loss: -3.921872615814209
Batch 34/64 loss: -3.968172550201416
Batch 35/64 loss: -4.199437141418457
Batch 36/64 loss: -3.974668502807617
Batch 37/64 loss: -4.175787448883057
Batch 38/64 loss: -4.096877098083496
Batch 39/64 loss: -4.2918267250061035
Batch 40/64 loss: -4.181407451629639
Batch 41/64 loss: -3.731678009033203
Batch 42/64 loss: -3.96488094329834
Batch 43/64 loss: -4.18332576751709
Batch 44/64 loss: -4.203187942504883
Batch 45/64 loss: -4.069299221038818
Batch 46/64 loss: -3.578579902648926
Batch 47/64 loss: -4.183712482452393
Batch 48/64 loss: -3.741403102874756
Batch 49/64 loss: -4.069418907165527
Batch 50/64 loss: -4.0957746505737305
Batch 51/64 loss: -4.0930962562561035
Batch 52/64 loss: -4.100955486297607
Batch 53/64 loss: -3.934811592102051
Batch 54/64 loss: -4.175823211669922
Batch 55/64 loss: -3.9767556190490723
Batch 56/64 loss: -4.064092636108398
Batch 57/64 loss: -4.09789514541626
Batch 58/64 loss: -4.1137213706970215
Batch 59/64 loss: -4.0276312828063965
Batch 60/64 loss: -4.1667890548706055
Batch 61/64 loss: -4.005631446838379
Batch 62/64 loss: -3.9798502922058105
Batch 63/64 loss: -4.1410722732543945
Batch 64/64 loss: -8.654315948486328
Epoch 428  Train loss: -4.133514703488817  Val loss: -4.451126059306037
Epoch 429
-------------------------------
Batch 1/64 loss: -3.962285041809082
Batch 2/64 loss: -4.065528869628906
Batch 3/64 loss: -4.223840713500977
Batch 4/64 loss: -4.215427398681641
Batch 5/64 loss: -4.060269355773926
Batch 6/64 loss: -4.176198482513428
Batch 7/64 loss: -4.012441635131836
Batch 8/64 loss: -4.014066696166992
Batch 9/64 loss: -3.870631694793701
Batch 10/64 loss: -4.075429439544678
Batch 11/64 loss: -3.998164176940918
Batch 12/64 loss: -4.140056610107422
Batch 13/64 loss: -3.917914390563965
Batch 14/64 loss: -4.125217914581299
Batch 15/64 loss: -3.929112434387207
Batch 16/64 loss: -4.084031581878662
Batch 17/64 loss: -4.148950576782227
Batch 18/64 loss: -4.127116680145264
Batch 19/64 loss: -4.071937561035156
Batch 20/64 loss: -3.921889305114746
Batch 21/64 loss: -4.1150665283203125
Batch 22/64 loss: -4.038046836853027
Batch 23/64 loss: -4.0409932136535645
Batch 24/64 loss: -4.025844573974609
Batch 25/64 loss: -4.045137882232666
Batch 26/64 loss: -4.0290608406066895
Batch 27/64 loss: -3.8514270782470703
Batch 28/64 loss: -3.942993640899658
Batch 29/64 loss: -3.874805450439453
Batch 30/64 loss: -4.128968715667725
Batch 31/64 loss: -4.104247570037842
Batch 32/64 loss: -4.063097953796387
Batch 33/64 loss: -3.959897041320801
Batch 34/64 loss: -3.986833095550537
Batch 35/64 loss: -4.017149925231934
Batch 36/64 loss: -4.016595363616943
Batch 37/64 loss: -4.1217241287231445
Batch 38/64 loss: -3.862302780151367
Batch 39/64 loss: -3.6385416984558105
Batch 40/64 loss: -3.8952693939208984
Batch 41/64 loss: -4.1491265296936035
Batch 42/64 loss: -3.973402500152588
Batch 43/64 loss: -4.092487335205078
Batch 44/64 loss: -3.8979320526123047
Batch 45/64 loss: -3.5899081230163574
Batch 46/64 loss: -3.884124279022217
Batch 47/64 loss: -4.12248420715332
Batch 48/64 loss: -3.827681541442871
Batch 49/64 loss: -3.798384189605713
Batch 50/64 loss: -4.029641151428223
Batch 51/64 loss: -4.009884357452393
Batch 52/64 loss: -4.104592323303223
Batch 53/64 loss: -4.089719772338867
Batch 54/64 loss: -3.9997382164001465
Batch 55/64 loss: -4.146080017089844
Batch 56/64 loss: -4.1404218673706055
Batch 57/64 loss: -4.051485538482666
Batch 58/64 loss: -4.052891731262207
Batch 59/64 loss: -3.986149311065674
Batch 60/64 loss: -4.143139839172363
Batch 61/64 loss: -3.401219367980957
Batch 62/64 loss: -3.909343719482422
Batch 63/64 loss: -3.885984420776367
Batch 64/64 loss: -8.583148956298828
Epoch 429  Train loss: -4.05681095497281  Val loss: -4.429219943960917
Epoch 430
-------------------------------
Batch 1/64 loss: -4.047970771789551
Batch 2/64 loss: -4.067006587982178
Batch 3/64 loss: -3.954336643218994
Batch 4/64 loss: -3.9409031867980957
Batch 5/64 loss: -4.129595756530762
Batch 6/64 loss: -3.9541354179382324
Batch 7/64 loss: -3.9731345176696777
Batch 8/64 loss: -4.03670072555542
Batch 9/64 loss: -4.136002540588379
Batch 10/64 loss: -3.922884941101074
Batch 11/64 loss: -3.567317008972168
Batch 12/64 loss: -3.9614362716674805
Batch 13/64 loss: -3.7705111503601074
Batch 14/64 loss: -4.0441813468933105
Batch 15/64 loss: -4.060113430023193
Batch 16/64 loss: -4.155025005340576
Batch 17/64 loss: -4.063603401184082
Batch 18/64 loss: -4.024778842926025
Batch 19/64 loss: -4.204967021942139
Batch 20/64 loss: -4.158097267150879
Batch 21/64 loss: -3.915781021118164
Batch 22/64 loss: -3.9470362663269043
Batch 23/64 loss: -4.034207820892334
Batch 24/64 loss: -4.155657768249512
Batch 25/64 loss: -3.862618923187256
Batch 26/64 loss: -4.1740288734436035
Batch 27/64 loss: -4.0947651863098145
Batch 28/64 loss: -4.185345649719238
Batch 29/64 loss: -4.111604690551758
Batch 30/64 loss: -4.18229341506958
Batch 31/64 loss: -4.143730640411377
Batch 32/64 loss: -3.8611035346984863
Batch 33/64 loss: -4.18239164352417
Batch 34/64 loss: -4.0341410636901855
Batch 35/64 loss: -3.7755250930786133
Batch 36/64 loss: -4.00907564163208
Batch 37/64 loss: -3.9989590644836426
Batch 38/64 loss: -4.23245906829834
Batch 39/64 loss: -4.080360412597656
Batch 40/64 loss: -4.1031084060668945
Batch 41/64 loss: -4.120988368988037
Batch 42/64 loss: -4.085632801055908
Batch 43/64 loss: -4.2009100914001465
Batch 44/64 loss: -3.9330334663391113
Batch 45/64 loss: -4.237683296203613
Batch 46/64 loss: -4.125020503997803
Batch 47/64 loss: -4.089904308319092
Batch 48/64 loss: -4.290053844451904
Batch 49/64 loss: -3.9488821029663086
Batch 50/64 loss: -4.271335124969482
Batch 51/64 loss: -3.9399871826171875
Batch 52/64 loss: -4.09153413772583
Batch 53/64 loss: -3.8287501335144043
Batch 54/64 loss: -4.229538917541504
Batch 55/64 loss: -3.960299015045166
Batch 56/64 loss: -4.1528639793396
Batch 57/64 loss: -4.148849010467529
Batch 58/64 loss: -3.986769676208496
Batch 59/64 loss: -3.9416823387145996
Batch 60/64 loss: -4.080226421356201
Batch 61/64 loss: -4.318018913269043
Batch 62/64 loss: -4.034911155700684
Batch 63/64 loss: -4.046468257904053
Batch 64/64 loss: -8.577937126159668
Epoch 430  Train loss: -4.105940265281528  Val loss: -4.461383269005215
Epoch 431
-------------------------------
Batch 1/64 loss: -3.695322036743164
Batch 2/64 loss: -4.017394065856934
Batch 3/64 loss: -4.10488224029541
Batch 4/64 loss: -4.011379718780518
Batch 5/64 loss: -4.199458599090576
Batch 6/64 loss: -3.7072224617004395
Batch 7/64 loss: -4.122904300689697
Batch 8/64 loss: -4.152065753936768
Batch 9/64 loss: -4.055450439453125
Batch 10/64 loss: -3.8969407081604004
Batch 11/64 loss: -4.0950212478637695
Batch 12/64 loss: -3.9369893074035645
Batch 13/64 loss: -4.206101894378662
Batch 14/64 loss: -3.986431121826172
Batch 15/64 loss: -3.9084300994873047
Batch 16/64 loss: -4.18024206161499
Batch 17/64 loss: -4.294239521026611
Batch 18/64 loss: -4.203492641448975
Batch 19/64 loss: -4.14549446105957
Batch 20/64 loss: -3.9932007789611816
Batch 21/64 loss: -4.104952335357666
Batch 22/64 loss: -4.169955253601074
Batch 23/64 loss: -4.227080821990967
Batch 24/64 loss: -4.167553424835205
Batch 25/64 loss: -4.1405029296875
Batch 26/64 loss: -4.088850498199463
Batch 27/64 loss: -4.039422988891602
Batch 28/64 loss: -3.950268268585205
Batch 29/64 loss: -4.180649280548096
Batch 30/64 loss: -4.068413734436035
Batch 31/64 loss: -4.100756645202637
Batch 32/64 loss: -4.19108247756958
Batch 33/64 loss: -4.34021520614624
Batch 34/64 loss: -4.1973676681518555
Batch 35/64 loss: -3.8530969619750977
Batch 36/64 loss: -4.238789081573486
Batch 37/64 loss: -4.061151027679443
Batch 38/64 loss: -3.8870787620544434
Batch 39/64 loss: -4.177978038787842
Batch 40/64 loss: -3.730337619781494
Batch 41/64 loss: -4.046228885650635
Batch 42/64 loss: -4.257943153381348
Batch 43/64 loss: -4.031272888183594
Batch 44/64 loss: -4.16511344909668
Batch 45/64 loss: -4.188474178314209
Batch 46/64 loss: -4.169371604919434
Batch 47/64 loss: -4.1823835372924805
Batch 48/64 loss: -4.083457946777344
Batch 49/64 loss: -4.188093662261963
Batch 50/64 loss: -3.991468906402588
Batch 51/64 loss: -4.063175201416016
Batch 52/64 loss: -4.235390663146973
Batch 53/64 loss: -4.047595977783203
Batch 54/64 loss: -4.147878170013428
Batch 55/64 loss: -4.188770294189453
Batch 56/64 loss: -4.140172004699707
Batch 57/64 loss: -3.910938262939453
Batch 58/64 loss: -4.202584743499756
Batch 59/64 loss: -4.084354877471924
Batch 60/64 loss: -4.038943290710449
Batch 61/64 loss: -4.3017473220825195
Batch 62/64 loss: -4.126335144042969
Batch 63/64 loss: -4.352628231048584
Batch 64/64 loss: -8.651025772094727
Epoch 431  Train loss: -4.148404050340839  Val loss: -4.540585455615906
Epoch 432
-------------------------------
Batch 1/64 loss: -3.94290828704834
Batch 2/64 loss: -4.269293308258057
Batch 3/64 loss: -3.9664769172668457
Batch 4/64 loss: -4.162764072418213
Batch 5/64 loss: -3.641599655151367
Batch 6/64 loss: -4.172586441040039
Batch 7/64 loss: -4.034160614013672
Batch 8/64 loss: -4.044939041137695
Batch 9/64 loss: -4.113786220550537
Batch 10/64 loss: -4.190475940704346
Batch 11/64 loss: -4.1153388023376465
Batch 12/64 loss: -3.960340976715088
Batch 13/64 loss: -4.211700439453125
Batch 14/64 loss: -4.027032852172852
Batch 15/64 loss: -4.050268650054932
Batch 16/64 loss: -4.11492919921875
Batch 17/64 loss: -4.114642143249512
Batch 18/64 loss: -3.9973044395446777
Batch 19/64 loss: -3.9809861183166504
Batch 20/64 loss: -4.080207824707031
Batch 21/64 loss: -4.202355861663818
Batch 22/64 loss: -4.121999740600586
Batch 23/64 loss: -4.107885837554932
Batch 24/64 loss: -3.8266520500183105
Batch 25/64 loss: -3.9011411666870117
Batch 26/64 loss: -3.958364486694336
Batch 27/64 loss: -4.111201763153076
Batch 28/64 loss: -4.1730241775512695
Batch 29/64 loss: -4.208578109741211
Batch 30/64 loss: -4.055434226989746
Batch 31/64 loss: -4.039844512939453
Batch 32/64 loss: -4.124381065368652
Batch 33/64 loss: -4.001855850219727
Batch 34/64 loss: -4.1518049240112305
Batch 35/64 loss: -3.9606237411499023
Batch 36/64 loss: -4.024605751037598
Batch 37/64 loss: -4.240466117858887
Batch 38/64 loss: -3.877406597137451
Batch 39/64 loss: -4.206708908081055
Batch 40/64 loss: -4.0053181648254395
Batch 41/64 loss: -4.083494663238525
Batch 42/64 loss: -4.075640678405762
Batch 43/64 loss: -4.149223804473877
Batch 44/64 loss: -4.157135963439941
Batch 45/64 loss: -4.081250190734863
Batch 46/64 loss: -4.1039557456970215
Batch 47/64 loss: -3.846601963043213
Batch 48/64 loss: -3.9861059188842773
Batch 49/64 loss: -3.9231972694396973
Batch 50/64 loss: -3.8880128860473633
Batch 51/64 loss: -4.045995712280273
Batch 52/64 loss: -4.09609842300415
Batch 53/64 loss: -4.204090118408203
Batch 54/64 loss: -4.27642822265625
Batch 55/64 loss: -4.159302234649658
Batch 56/64 loss: -4.205802917480469
Batch 57/64 loss: -4.06439208984375
Batch 58/64 loss: -4.001397132873535
Batch 59/64 loss: -3.8665032386779785
Batch 60/64 loss: -3.923036575317383
Batch 61/64 loss: -4.170754432678223
Batch 62/64 loss: -4.194438457489014
Batch 63/64 loss: -4.218435287475586
Batch 64/64 loss: -8.601564407348633
Epoch 432  Train loss: -4.120217446719899  Val loss: -4.438089010232093
Epoch 433
-------------------------------
Batch 1/64 loss: -4.159956932067871
Batch 2/64 loss: -3.865797519683838
Batch 3/64 loss: -4.076323509216309
Batch 4/64 loss: -4.269294261932373
Batch 5/64 loss: -4.059820652008057
Batch 6/64 loss: -4.006561756134033
Batch 7/64 loss: -4.108035087585449
Batch 8/64 loss: -4.236127853393555
Batch 9/64 loss: -4.08068323135376
Batch 10/64 loss: -4.150383949279785
Batch 11/64 loss: -3.960081100463867
Batch 12/64 loss: -4.159024715423584
Batch 13/64 loss: -4.155481338500977
Batch 14/64 loss: -4.094157695770264
Batch 15/64 loss: -3.9560742378234863
Batch 16/64 loss: -4.284379959106445
Batch 17/64 loss: -3.9211411476135254
Batch 18/64 loss: -4.030289649963379
Batch 19/64 loss: -4.104019641876221
Batch 20/64 loss: -4.04774284362793
Batch 21/64 loss: -4.02930212020874
Batch 22/64 loss: -4.012180328369141
Batch 23/64 loss: -4.213695049285889
Batch 24/64 loss: -3.917813301086426
Batch 25/64 loss: -3.3649234771728516
Batch 26/64 loss: -4.124516010284424
Batch 27/64 loss: -4.132487773895264
Batch 28/64 loss: -4.16732931137085
Batch 29/64 loss: -4.086918354034424
Batch 30/64 loss: -4.107211112976074
Batch 31/64 loss: -4.227069854736328
Batch 32/64 loss: -4.19345760345459
Batch 33/64 loss: -4.028010845184326
Batch 34/64 loss: -4.029914379119873
Batch 35/64 loss: -4.161683559417725
Batch 36/64 loss: -4.012796401977539
Batch 37/64 loss: -4.227179527282715
Batch 38/64 loss: -4.097136497497559
Batch 39/64 loss: -3.764814853668213
Batch 40/64 loss: -4.1918230056762695
Batch 41/64 loss: -4.030789852142334
Batch 42/64 loss: -4.07951545715332
Batch 43/64 loss: -4.179538249969482
Batch 44/64 loss: -4.20578670501709
Batch 45/64 loss: -4.099895000457764
Batch 46/64 loss: -4.279781341552734
Batch 47/64 loss: -4.1241774559021
Batch 48/64 loss: -4.146694183349609
Batch 49/64 loss: -4.144794464111328
Batch 50/64 loss: -4.2179436683654785
Batch 51/64 loss: -4.149448871612549
Batch 52/64 loss: -4.108153343200684
Batch 53/64 loss: -4.047758102416992
Batch 54/64 loss: -4.266605377197266
Batch 55/64 loss: -4.090911865234375
Batch 56/64 loss: -4.115439414978027
Batch 57/64 loss: -4.1563615798950195
Batch 58/64 loss: -4.161629676818848
Batch 59/64 loss: -3.953554630279541
Batch 60/64 loss: -4.2163801193237305
Batch 61/64 loss: -4.102166652679443
Batch 62/64 loss: -3.8987627029418945
Batch 63/64 loss: -4.187568187713623
Batch 64/64 loss: -8.523775100708008
Epoch 433  Train loss: -4.1438765282724415  Val loss: -4.574615504733476
Saving best model, epoch: 433
Epoch 434
-------------------------------
Batch 1/64 loss: -4.05104923248291
Batch 2/64 loss: -4.1628570556640625
Batch 3/64 loss: -4.097703456878662
Batch 4/64 loss: -4.129841327667236
Batch 5/64 loss: -4.04757022857666
Batch 6/64 loss: -4.099286079406738
Batch 7/64 loss: -4.233222007751465
Batch 8/64 loss: -4.077627182006836
Batch 9/64 loss: -4.220772743225098
Batch 10/64 loss: -4.040524005889893
Batch 11/64 loss: -4.084005355834961
Batch 12/64 loss: -4.175446033477783
Batch 13/64 loss: -4.046900272369385
Batch 14/64 loss: -4.191462993621826
Batch 15/64 loss: -4.194060802459717
Batch 16/64 loss: -4.138682842254639
Batch 17/64 loss: -4.151195526123047
Batch 18/64 loss: -4.168964385986328
Batch 19/64 loss: -4.005213737487793
Batch 20/64 loss: -3.9923830032348633
Batch 21/64 loss: -4.16190767288208
Batch 22/64 loss: -3.995418071746826
Batch 23/64 loss: -4.144364356994629
Batch 24/64 loss: -4.123456001281738
Batch 25/64 loss: -4.049068927764893
Batch 26/64 loss: -4.200353622436523
Batch 27/64 loss: -4.169812202453613
Batch 28/64 loss: -4.164522171020508
Batch 29/64 loss: -3.9685983657836914
Batch 30/64 loss: -4.086765766143799
Batch 31/64 loss: -4.212418079376221
Batch 32/64 loss: -4.20212459564209
Batch 33/64 loss: -4.033618450164795
Batch 34/64 loss: -4.062864780426025
Batch 35/64 loss: -4.056056022644043
Batch 36/64 loss: -4.150770664215088
Batch 37/64 loss: -4.117730140686035
Batch 38/64 loss: -4.189330101013184
Batch 39/64 loss: -3.7766008377075195
Batch 40/64 loss: -4.106123447418213
Batch 41/64 loss: -4.181456565856934
Batch 42/64 loss: -4.0591325759887695
Batch 43/64 loss: -4.209501266479492
Batch 44/64 loss: -4.252677917480469
Batch 45/64 loss: -4.068099021911621
Batch 46/64 loss: -4.173707485198975
Batch 47/64 loss: -4.206292629241943
Batch 48/64 loss: -3.9931464195251465
Batch 49/64 loss: -4.160839557647705
Batch 50/64 loss: -4.240588665008545
Batch 51/64 loss: -4.17360258102417
Batch 52/64 loss: -4.1792473793029785
Batch 53/64 loss: -4.238646030426025
Batch 54/64 loss: -3.8351192474365234
Batch 55/64 loss: -4.154391765594482
Batch 56/64 loss: -3.828810214996338
Batch 57/64 loss: -4.1155500411987305
Batch 58/64 loss: -4.156607627868652
Batch 59/64 loss: -3.9830923080444336
Batch 60/64 loss: -3.7747488021850586
Batch 61/64 loss: -4.1503729820251465
Batch 62/64 loss: -4.341179847717285
Batch 63/64 loss: -4.091371536254883
Batch 64/64 loss: -8.826791763305664
Epoch 434  Train loss: -4.164218805350509  Val loss: -4.59142224813245
Saving best model, epoch: 434
Epoch 435
-------------------------------
Batch 1/64 loss: -4.246145248413086
Batch 2/64 loss: -4.2253642082214355
Batch 3/64 loss: -4.17466402053833
Batch 4/64 loss: -4.10489559173584
Batch 5/64 loss: -4.187741756439209
Batch 6/64 loss: -4.13194465637207
Batch 7/64 loss: -4.074177265167236
Batch 8/64 loss: -4.2298078536987305
Batch 9/64 loss: -4.2659735679626465
Batch 10/64 loss: -4.148874759674072
Batch 11/64 loss: -4.275814056396484
Batch 12/64 loss: -4.184931755065918
Batch 13/64 loss: -3.9995265007019043
Batch 14/64 loss: -4.048804759979248
Batch 15/64 loss: -4.28732967376709
Batch 16/64 loss: -4.081568241119385
Batch 17/64 loss: -4.108392715454102
Batch 18/64 loss: -4.024399757385254
Batch 19/64 loss: -4.138499736785889
Batch 20/64 loss: -4.006502628326416
Batch 21/64 loss: -4.2005791664123535
Batch 22/64 loss: -4.046549320220947
Batch 23/64 loss: -4.163051605224609
Batch 24/64 loss: -4.079085826873779
Batch 25/64 loss: -4.075742721557617
Batch 26/64 loss: -4.006234169006348
Batch 27/64 loss: -4.15316915512085
Batch 28/64 loss: -4.098827362060547
Batch 29/64 loss: -4.080713748931885
Batch 30/64 loss: -4.276645660400391
Batch 31/64 loss: -4.148229122161865
Batch 32/64 loss: -3.9905295372009277
Batch 33/64 loss: -4.020078659057617
Batch 34/64 loss: -4.227580547332764
Batch 35/64 loss: -4.135228157043457
Batch 36/64 loss: -4.077996730804443
Batch 37/64 loss: -4.132751941680908
Batch 38/64 loss: -4.126511096954346
Batch 39/64 loss: -4.247162342071533
Batch 40/64 loss: -4.23391056060791
Batch 41/64 loss: -4.185144424438477
Batch 42/64 loss: -4.187126159667969
Batch 43/64 loss: -3.8314828872680664
Batch 44/64 loss: -4.174665451049805
Batch 45/64 loss: -4.254034996032715
Batch 46/64 loss: -4.059845447540283
Batch 47/64 loss: -4.209216594696045
Batch 48/64 loss: -4.0880608558654785
Batch 49/64 loss: -4.264039993286133
Batch 50/64 loss: -3.960080623626709
Batch 51/64 loss: -3.773754596710205
Batch 52/64 loss: -3.8563942909240723
Batch 53/64 loss: -4.204359531402588
Batch 54/64 loss: -4.198083400726318
Batch 55/64 loss: -4.213412284851074
Batch 56/64 loss: -3.648249626159668
Batch 57/64 loss: -4.186564922332764
Batch 58/64 loss: -4.146547794342041
Batch 59/64 loss: -4.128128528594971
Batch 60/64 loss: -4.135423183441162
Batch 61/64 loss: -4.224737167358398
Batch 62/64 loss: -3.995847225189209
Batch 63/64 loss: -3.9275288581848145
Batch 64/64 loss: -8.475170135498047
Epoch 435  Train loss: -4.167451649086148  Val loss: -4.502214779149216
Epoch 436
-------------------------------
Batch 1/64 loss: -3.9075188636779785
Batch 2/64 loss: -4.174583435058594
Batch 3/64 loss: -3.628283977508545
Batch 4/64 loss: -4.2001423835754395
Batch 5/64 loss: -4.188784599304199
Batch 6/64 loss: -3.8041582107543945
Batch 7/64 loss: -4.164011001586914
Batch 8/64 loss: -4.263233661651611
Batch 9/64 loss: -4.000475883483887
Batch 10/64 loss: -4.062588691711426
Batch 11/64 loss: -4.312015533447266
Batch 12/64 loss: -3.9285120964050293
Batch 13/64 loss: -3.982374668121338
Batch 14/64 loss: -4.0355224609375
Batch 15/64 loss: -4.2507100105285645
Batch 16/64 loss: -4.112346172332764
Batch 17/64 loss: -4.183208465576172
Batch 18/64 loss: -4.0923171043396
Batch 19/64 loss: -4.191408634185791
Batch 20/64 loss: -4.188565254211426
Batch 21/64 loss: -4.18469762802124
Batch 22/64 loss: -4.057519912719727
Batch 23/64 loss: -3.8946194648742676
Batch 24/64 loss: -4.012726783752441
Batch 25/64 loss: -3.975161075592041
Batch 26/64 loss: -4.035106658935547
Batch 27/64 loss: -4.12568473815918
Batch 28/64 loss: -4.077578067779541
Batch 29/64 loss: -4.203956127166748
Batch 30/64 loss: -4.069236755371094
Batch 31/64 loss: -4.096457004547119
Batch 32/64 loss: -4.100093841552734
Batch 33/64 loss: -4.16292667388916
Batch 34/64 loss: -4.264401912689209
Batch 35/64 loss: -4.274655818939209
Batch 36/64 loss: -4.231592655181885
Batch 37/64 loss: -4.0922088623046875
Batch 38/64 loss: -4.224384307861328
Batch 39/64 loss: -4.082896709442139
Batch 40/64 loss: -4.025789737701416
Batch 41/64 loss: -4.040622711181641
Batch 42/64 loss: -4.064895153045654
Batch 43/64 loss: -3.8935775756835938
Batch 44/64 loss: -3.839810371398926
Batch 45/64 loss: -4.079987525939941
Batch 46/64 loss: -3.483959197998047
Batch 47/64 loss: -3.6863608360290527
Batch 48/64 loss: -3.8437604904174805
Batch 49/64 loss: -3.9729270935058594
Batch 50/64 loss: -3.1326208114624023
Batch 51/64 loss: -3.813262462615967
Batch 52/64 loss: -3.7259902954101562
Batch 53/64 loss: -3.5851402282714844
Batch 54/64 loss: -3.820061206817627
Batch 55/64 loss: -3.882767677307129
Batch 56/64 loss: -3.7839126586914062
Batch 57/64 loss: -3.9124298095703125
Batch 58/64 loss: -3.7827305793762207
Batch 59/64 loss: -3.6876587867736816
Batch 60/64 loss: -3.4820942878723145
Batch 61/64 loss: -3.649911880493164
Batch 62/64 loss: -3.7505874633789062
Batch 63/64 loss: -3.8180389404296875
Batch 64/64 loss: -8.388668060302734
Epoch 436  Train loss: -4.029601018569049  Val loss: -4.152459593572977
Epoch 437
-------------------------------
Batch 1/64 loss: -3.6201629638671875
Batch 2/64 loss: -3.911764621734619
Batch 3/64 loss: -3.94826602935791
Batch 4/64 loss: -3.860929012298584
Batch 5/64 loss: -3.9759535789489746
Batch 6/64 loss: -3.739865779876709
Batch 7/64 loss: -3.742866039276123
Batch 8/64 loss: -3.6932120323181152
Batch 9/64 loss: -4.095529556274414
Batch 10/64 loss: -3.9802427291870117
Batch 11/64 loss: -3.8570337295532227
Batch 12/64 loss: -3.8993849754333496
Batch 13/64 loss: -3.8860931396484375
Batch 14/64 loss: -3.768503189086914
Batch 15/64 loss: -3.7133235931396484
Batch 16/64 loss: -3.817408561706543
Batch 17/64 loss: -4.141165733337402
Batch 18/64 loss: -3.9762678146362305
Batch 19/64 loss: -4.00014066696167
Batch 20/64 loss: -4.125593185424805
Batch 21/64 loss: -3.5683417320251465
Batch 22/64 loss: -3.931194305419922
Batch 23/64 loss: -3.935299873352051
Batch 24/64 loss: -3.9515604972839355
Batch 25/64 loss: -3.936901569366455
Batch 26/64 loss: -4.133358478546143
Batch 27/64 loss: -4.002533912658691
Batch 28/64 loss: -3.8755202293395996
Batch 29/64 loss: -3.970818042755127
Batch 30/64 loss: -3.7772040367126465
Batch 31/64 loss: -4.125668525695801
Batch 32/64 loss: -3.7181077003479004
Batch 33/64 loss: -3.7777962684631348
Batch 34/64 loss: -3.698760509490967
Batch 35/64 loss: -3.8752222061157227
Batch 36/64 loss: -4.244093418121338
Batch 37/64 loss: -3.8896021842956543
Batch 38/64 loss: -3.856739044189453
Batch 39/64 loss: -3.932762622833252
Batch 40/64 loss: -3.942018508911133
Batch 41/64 loss: -4.2461981773376465
Batch 42/64 loss: -4.174563407897949
Batch 43/64 loss: -4.214888572692871
Batch 44/64 loss: -3.989731788635254
Batch 45/64 loss: -3.983180522918701
Batch 46/64 loss: -4.166291236877441
Batch 47/64 loss: -3.844489574432373
Batch 48/64 loss: -3.890878677368164
Batch 49/64 loss: -4.014099597930908
Batch 50/64 loss: -4.166443347930908
Batch 51/64 loss: -3.995910167694092
Batch 52/64 loss: -4.080042362213135
Batch 53/64 loss: -4.14870023727417
Batch 54/64 loss: -4.035752773284912
Batch 55/64 loss: -4.1147260665893555
Batch 56/64 loss: -3.9135499000549316
Batch 57/64 loss: -4.190767288208008
Batch 58/64 loss: -3.823122024536133
Batch 59/64 loss: -3.9181971549987793
Batch 60/64 loss: -3.9980978965759277
Batch 61/64 loss: -3.7310781478881836
Batch 62/64 loss: -4.147432804107666
Batch 63/64 loss: -3.8530616760253906
Batch 64/64 loss: -8.706558227539062
Epoch 437  Train loss: -4.001071885052849  Val loss: -4.288203760520699
Epoch 438
-------------------------------
Batch 1/64 loss: -4.1857171058654785
Batch 2/64 loss: -4.122611045837402
Batch 3/64 loss: -3.981853485107422
Batch 4/64 loss: -3.894517421722412
Batch 5/64 loss: -3.973165988922119
Batch 6/64 loss: -4.084817409515381
Batch 7/64 loss: -4.065517902374268
Batch 8/64 loss: -3.924874782562256
Batch 9/64 loss: -4.046149730682373
Batch 10/64 loss: -4.110040187835693
Batch 11/64 loss: -4.001579761505127
Batch 12/64 loss: -3.8982162475585938
Batch 13/64 loss: -3.9949779510498047
Batch 14/64 loss: -4.065345287322998
Batch 15/64 loss: -4.191006660461426
Batch 16/64 loss: -3.987452983856201
Batch 17/64 loss: -3.906688690185547
Batch 18/64 loss: -3.9517579078674316
Batch 19/64 loss: -4.039795875549316
Batch 20/64 loss: -4.023674011230469
Batch 21/64 loss: -4.222248554229736
Batch 22/64 loss: -4.036725044250488
Batch 23/64 loss: -4.197586536407471
Batch 24/64 loss: -4.19755220413208
Batch 25/64 loss: -4.045684814453125
Batch 26/64 loss: -3.889523983001709
Batch 27/64 loss: -3.7122554779052734
Batch 28/64 loss: -4.121735095977783
Batch 29/64 loss: -4.156126022338867
Batch 30/64 loss: -4.070620536804199
Batch 31/64 loss: -4.150631904602051
Batch 32/64 loss: -4.14327335357666
Batch 33/64 loss: -4.0189900398254395
Batch 34/64 loss: -4.040007591247559
Batch 35/64 loss: -4.023172378540039
Batch 36/64 loss: -3.937465190887451
Batch 37/64 loss: -3.7884440422058105
Batch 38/64 loss: -4.093442440032959
Batch 39/64 loss: -4.161176681518555
Batch 40/64 loss: -3.9354605674743652
Batch 41/64 loss: -4.107825756072998
Batch 42/64 loss: -3.8893065452575684
Batch 43/64 loss: -3.846001148223877
Batch 44/64 loss: -3.821404457092285
Batch 45/64 loss: -3.925304889678955
Batch 46/64 loss: -4.14943265914917
Batch 47/64 loss: -4.111666679382324
Batch 48/64 loss: -4.041398048400879
Batch 49/64 loss: -4.150384902954102
Batch 50/64 loss: -4.113725185394287
Batch 51/64 loss: -4.192376613616943
Batch 52/64 loss: -4.094882965087891
Batch 53/64 loss: -3.949009895324707
Batch 54/64 loss: -3.91920804977417
Batch 55/64 loss: -4.235653877258301
Batch 56/64 loss: -4.192770957946777
Batch 57/64 loss: -4.3156657218933105
Batch 58/64 loss: -3.608186721801758
Batch 59/64 loss: -4.11153507232666
Batch 60/64 loss: -4.062636375427246
Batch 61/64 loss: -4.011443614959717
Batch 62/64 loss: -4.003994941711426
Batch 63/64 loss: -4.100480079650879
Batch 64/64 loss: -8.807193756103516
Epoch 438  Train loss: -4.093358013676662  Val loss: -4.507738919602227
Epoch 439
-------------------------------
Batch 1/64 loss: -4.157723903656006
Batch 2/64 loss: -4.050758361816406
Batch 3/64 loss: -4.066264629364014
Batch 4/64 loss: -4.1839919090271
Batch 5/64 loss: -4.241744518280029
Batch 6/64 loss: -4.215641975402832
Batch 7/64 loss: -4.168691635131836
Batch 8/64 loss: -3.9635419845581055
Batch 9/64 loss: -3.7670888900756836
Batch 10/64 loss: -4.142192363739014
Batch 11/64 loss: -4.069155693054199
Batch 12/64 loss: -3.9501700401306152
Batch 13/64 loss: -4.1646952629089355
Batch 14/64 loss: -4.122806072235107
Batch 15/64 loss: -4.191891193389893
Batch 16/64 loss: -4.285726547241211
Batch 17/64 loss: -4.201501846313477
Batch 18/64 loss: -4.142496109008789
Batch 19/64 loss: -3.973127841949463
Batch 20/64 loss: -3.9980082511901855
Batch 21/64 loss: -4.178929328918457
Batch 22/64 loss: -4.055829048156738
Batch 23/64 loss: -3.8218917846679688
Batch 24/64 loss: -4.0867919921875
Batch 25/64 loss: -4.031255722045898
Batch 26/64 loss: -4.170773029327393
Batch 27/64 loss: -3.743438720703125
Batch 28/64 loss: -4.127883434295654
Batch 29/64 loss: -4.114017486572266
Batch 30/64 loss: -4.13706636428833
Batch 31/64 loss: -3.8857369422912598
Batch 32/64 loss: -4.013650894165039
Batch 33/64 loss: -4.070106029510498
Batch 34/64 loss: -4.0847063064575195
Batch 35/64 loss: -3.813387393951416
Batch 36/64 loss: -3.961550712585449
Batch 37/64 loss: -4.157660961151123
Batch 38/64 loss: -4.215120792388916
Batch 39/64 loss: -4.173563003540039
Batch 40/64 loss: -4.08864688873291
Batch 41/64 loss: -4.246213436126709
Batch 42/64 loss: -4.076506614685059
Batch 43/64 loss: -4.158555507659912
Batch 44/64 loss: -4.238495826721191
Batch 45/64 loss: -4.061289310455322
Batch 46/64 loss: -4.156888961791992
Batch 47/64 loss: -3.8871498107910156
Batch 48/64 loss: -4.009315013885498
Batch 49/64 loss: -4.2402777671813965
Batch 50/64 loss: -4.100440979003906
Batch 51/64 loss: -4.096130847930908
Batch 52/64 loss: -4.233377456665039
Batch 53/64 loss: -4.099207878112793
Batch 54/64 loss: -4.157609939575195
Batch 55/64 loss: -4.135249614715576
Batch 56/64 loss: -4.148411750793457
Batch 57/64 loss: -3.950033187866211
Batch 58/64 loss: -4.101998805999756
Batch 59/64 loss: -3.9279885292053223
Batch 60/64 loss: -4.197963237762451
Batch 61/64 loss: -4.089348793029785
Batch 62/64 loss: -4.144237995147705
Batch 63/64 loss: -4.031688213348389
Batch 64/64 loss: -8.742916107177734
Epoch 439  Train loss: -4.141722234090169  Val loss: -4.548799875265954
Epoch 440
-------------------------------
Batch 1/64 loss: -4.004997730255127
Batch 2/64 loss: -4.156434059143066
Batch 3/64 loss: -4.004567623138428
Batch 4/64 loss: -4.175993919372559
Batch 5/64 loss: -4.073387622833252
Batch 6/64 loss: -4.0898613929748535
Batch 7/64 loss: -4.075840473175049
Batch 8/64 loss: -4.008523464202881
Batch 9/64 loss: -4.152949810028076
Batch 10/64 loss: -4.336964130401611
Batch 11/64 loss: -4.1004815101623535
Batch 12/64 loss: -3.9948787689208984
Batch 13/64 loss: -4.230235576629639
Batch 14/64 loss: -3.9232335090637207
Batch 15/64 loss: -4.167685031890869
Batch 16/64 loss: -4.166855335235596
Batch 17/64 loss: -4.039074420928955
Batch 18/64 loss: -4.090373516082764
Batch 19/64 loss: -4.028112411499023
Batch 20/64 loss: -4.2542524337768555
Batch 21/64 loss: -4.198552131652832
Batch 22/64 loss: -4.1071085929870605
Batch 23/64 loss: -3.7027530670166016
Batch 24/64 loss: -3.9457011222839355
Batch 25/64 loss: -4.049502372741699
Batch 26/64 loss: -4.204235553741455
Batch 27/64 loss: -4.179567337036133
Batch 28/64 loss: -4.117081165313721
Batch 29/64 loss: -3.9981398582458496
Batch 30/64 loss: -4.059308052062988
Batch 31/64 loss: -3.88197660446167
Batch 32/64 loss: -4.259706497192383
Batch 33/64 loss: -4.226071834564209
Batch 34/64 loss: -4.182171821594238
Batch 35/64 loss: -4.26479959487915
Batch 36/64 loss: -4.264642715454102
Batch 37/64 loss: -4.171443462371826
Batch 38/64 loss: -4.1893439292907715
Batch 39/64 loss: -4.207826137542725
Batch 40/64 loss: -4.238415718078613
Batch 41/64 loss: -4.050834655761719
Batch 42/64 loss: -3.7991738319396973
Batch 43/64 loss: -4.058026313781738
Batch 44/64 loss: -4.26234769821167
Batch 45/64 loss: -4.04919958114624
Batch 46/64 loss: -4.167116165161133
Batch 47/64 loss: -4.232234954833984
Batch 48/64 loss: -4.350398540496826
Batch 49/64 loss: -4.28409481048584
Batch 50/64 loss: -4.264891147613525
Batch 51/64 loss: -4.209372043609619
Batch 52/64 loss: -4.178830623626709
Batch 53/64 loss: -4.275310039520264
Batch 54/64 loss: -4.0734663009643555
Batch 55/64 loss: -4.211723327636719
Batch 56/64 loss: -4.305807113647461
Batch 57/64 loss: -4.1986470222473145
Batch 58/64 loss: -3.9558448791503906
Batch 59/64 loss: -4.1419830322265625
Batch 60/64 loss: -4.014888763427734
Batch 61/64 loss: -4.168267726898193
Batch 62/64 loss: -4.244932651519775
Batch 63/64 loss: -4.334042549133301
Batch 64/64 loss: -8.654182434082031
Epoch 440  Train loss: -4.18580581814635  Val loss: -4.589880114158814
Epoch 441
-------------------------------
Batch 1/64 loss: -4.231325626373291
Batch 2/64 loss: -4.0615434646606445
Batch 3/64 loss: -4.179485321044922
Batch 4/64 loss: -4.257413387298584
Batch 5/64 loss: -4.169571399688721
Batch 6/64 loss: -4.083055019378662
Batch 7/64 loss: -4.276442527770996
Batch 8/64 loss: -4.003965377807617
Batch 9/64 loss: -4.173657417297363
Batch 10/64 loss: -4.158085346221924
Batch 11/64 loss: -4.241722106933594
Batch 12/64 loss: -3.6401004791259766
Batch 13/64 loss: -4.144634246826172
Batch 14/64 loss: -4.11663818359375
Batch 15/64 loss: -4.061585426330566
Batch 16/64 loss: -3.9975404739379883
Batch 17/64 loss: -3.6660008430480957
Batch 18/64 loss: -4.2720794677734375
Batch 19/64 loss: -4.111822128295898
Batch 20/64 loss: -4.3349809646606445
Batch 21/64 loss: -4.040429592132568
Batch 22/64 loss: -4.101741313934326
Batch 23/64 loss: -4.096774578094482
Batch 24/64 loss: -4.244321346282959
Batch 25/64 loss: -4.180195331573486
Batch 26/64 loss: -4.172749042510986
Batch 27/64 loss: -3.994232654571533
Batch 28/64 loss: -4.249405384063721
Batch 29/64 loss: -4.109222412109375
Batch 30/64 loss: -3.9710965156555176
Batch 31/64 loss: -3.741652011871338
Batch 32/64 loss: -3.8028502464294434
Batch 33/64 loss: -3.997260093688965
Batch 34/64 loss: -4.08510684967041
Batch 35/64 loss: -3.9685654640197754
Batch 36/64 loss: -4.16571569442749
Batch 37/64 loss: -4.130049705505371
Batch 38/64 loss: -4.221463203430176
Batch 39/64 loss: -4.1660261154174805
Batch 40/64 loss: -4.080775260925293
Batch 41/64 loss: -4.057514667510986
Batch 42/64 loss: -4.090478897094727
Batch 43/64 loss: -4.10975456237793
Batch 44/64 loss: -4.133464336395264
Batch 45/64 loss: -4.159428596496582
Batch 46/64 loss: -3.547534942626953
Batch 47/64 loss: -4.073935508728027
Batch 48/64 loss: -3.9172568321228027
Batch 49/64 loss: -4.092146873474121
Batch 50/64 loss: -4.208308219909668
Batch 51/64 loss: -3.8864078521728516
Batch 52/64 loss: -4.139870643615723
Batch 53/64 loss: -3.8426551818847656
Batch 54/64 loss: -4.265644550323486
Batch 55/64 loss: -4.030661582946777
Batch 56/64 loss: -4.116159439086914
Batch 57/64 loss: -4.090832233428955
Batch 58/64 loss: -3.8676934242248535
Batch 59/64 loss: -4.1228532791137695
Batch 60/64 loss: -4.240646839141846
Batch 61/64 loss: -3.987729549407959
Batch 62/64 loss: -4.141440391540527
Batch 63/64 loss: -4.074034690856934
Batch 64/64 loss: -8.66537094116211
Epoch 441  Train loss: -4.1317139345056875  Val loss: -4.583917794768343
Epoch 442
-------------------------------
Batch 1/64 loss: -4.227924346923828
Batch 2/64 loss: -4.154557228088379
Batch 3/64 loss: -4.104538917541504
Batch 4/64 loss: -4.077033519744873
Batch 5/64 loss: -3.9783453941345215
Batch 6/64 loss: -4.16241455078125
Batch 7/64 loss: -4.257465839385986
Batch 8/64 loss: -4.098420143127441
Batch 9/64 loss: -4.022958755493164
Batch 10/64 loss: -3.8792614936828613
Batch 11/64 loss: -3.780315399169922
Batch 12/64 loss: -4.1805500984191895
Batch 13/64 loss: -4.269802093505859
Batch 14/64 loss: -4.085761070251465
Batch 15/64 loss: -4.16532564163208
Batch 16/64 loss: -4.322110652923584
Batch 17/64 loss: -4.26084566116333
Batch 18/64 loss: -3.978292942047119
Batch 19/64 loss: -4.173738956451416
Batch 20/64 loss: -4.019061088562012
Batch 21/64 loss: -4.059642791748047
Batch 22/64 loss: -4.201436519622803
Batch 23/64 loss: -4.070725440979004
Batch 24/64 loss: -4.13154411315918
Batch 25/64 loss: -4.158776760101318
Batch 26/64 loss: -3.7691359519958496
Batch 27/64 loss: -4.1790313720703125
Batch 28/64 loss: -4.073922157287598
Batch 29/64 loss: -3.6439075469970703
Batch 30/64 loss: -4.303859233856201
Batch 31/64 loss: -4.1724019050598145
Batch 32/64 loss: -4.23910665512085
Batch 33/64 loss: -4.1173095703125
Batch 34/64 loss: -4.3217878341674805
Batch 35/64 loss: -4.280616283416748
Batch 36/64 loss: -4.11714506149292
Batch 37/64 loss: -3.548966884613037
Batch 38/64 loss: -4.131994247436523
Batch 39/64 loss: -4.162898063659668
Batch 40/64 loss: -4.063172340393066
Batch 41/64 loss: -4.160610198974609
Batch 42/64 loss: -4.170123100280762
Batch 43/64 loss: -3.9871387481689453
Batch 44/64 loss: -4.03398323059082
Batch 45/64 loss: -4.012352466583252
Batch 46/64 loss: -4.137112140655518
Batch 47/64 loss: -4.230281352996826
Batch 48/64 loss: -4.130477428436279
Batch 49/64 loss: -3.9544248580932617
Batch 50/64 loss: -4.251539707183838
Batch 51/64 loss: -4.322295188903809
Batch 52/64 loss: -4.221105575561523
Batch 53/64 loss: -3.9855923652648926
Batch 54/64 loss: -4.038260459899902
Batch 55/64 loss: -4.213772296905518
Batch 56/64 loss: -4.1345415115356445
Batch 57/64 loss: -4.002200126647949
Batch 58/64 loss: -4.056946277618408
Batch 59/64 loss: -4.083258628845215
Batch 60/64 loss: -3.9609122276306152
Batch 61/64 loss: -3.9477014541625977
Batch 62/64 loss: -4.171426773071289
Batch 63/64 loss: -4.0752997398376465
Batch 64/64 loss: -8.422151565551758
Epoch 442  Train loss: -4.149710965624043  Val loss: -4.513486187072964
Epoch 443
-------------------------------
Batch 1/64 loss: -3.775287628173828
Batch 2/64 loss: -3.9321155548095703
Batch 3/64 loss: -4.1785969734191895
Batch 4/64 loss: -4.187408924102783
Batch 5/64 loss: -4.14277982711792
Batch 6/64 loss: -3.953011989593506
Batch 7/64 loss: -4.103936195373535
Batch 8/64 loss: -4.169264316558838
Batch 9/64 loss: -4.296818256378174
Batch 10/64 loss: -3.593174457550049
Batch 11/64 loss: -3.911055088043213
Batch 12/64 loss: -3.7720518112182617
Batch 13/64 loss: -4.168277740478516
Batch 14/64 loss: -3.98128080368042
Batch 15/64 loss: -3.8426127433776855
Batch 16/64 loss: -4.097778797149658
Batch 17/64 loss: -3.909660816192627
Batch 18/64 loss: -4.2607102394104
Batch 19/64 loss: -3.7102346420288086
Batch 20/64 loss: -4.103590488433838
Batch 21/64 loss: -4.156020164489746
Batch 22/64 loss: -3.8532276153564453
Batch 23/64 loss: -4.041642665863037
Batch 24/64 loss: -4.227710247039795
Batch 25/64 loss: -3.9097509384155273
Batch 26/64 loss: -4.234799385070801
Batch 27/64 loss: -4.167644500732422
Batch 28/64 loss: -4.02149772644043
Batch 29/64 loss: -4.066701412200928
Batch 30/64 loss: -3.988253116607666
Batch 31/64 loss: -3.9646244049072266
Batch 32/64 loss: -3.9951295852661133
Batch 33/64 loss: -4.146883487701416
Batch 34/64 loss: -3.901841163635254
Batch 35/64 loss: -4.18418025970459
Batch 36/64 loss: -4.180801868438721
Batch 37/64 loss: -4.298499584197998
Batch 38/64 loss: -4.010577201843262
Batch 39/64 loss: -3.690739631652832
Batch 40/64 loss: -4.180605411529541
Batch 41/64 loss: -3.863574504852295
Batch 42/64 loss: -4.208666801452637
Batch 43/64 loss: -4.145216941833496
Batch 44/64 loss: -4.143852710723877
Batch 45/64 loss: -3.899904251098633
Batch 46/64 loss: -3.975919246673584
Batch 47/64 loss: -4.184799671173096
Batch 48/64 loss: -4.171223163604736
Batch 49/64 loss: -4.107770919799805
Batch 50/64 loss: -4.214755058288574
Batch 51/64 loss: -3.7828216552734375
Batch 52/64 loss: -4.132061958312988
Batch 53/64 loss: -4.0885725021362305
Batch 54/64 loss: -4.094954967498779
Batch 55/64 loss: -4.008096694946289
Batch 56/64 loss: -4.161252498626709
Batch 57/64 loss: -4.080036640167236
Batch 58/64 loss: -4.046611309051514
Batch 59/64 loss: -4.28681755065918
Batch 60/64 loss: -3.9080491065979004
Batch 61/64 loss: -4.184197902679443
Batch 62/64 loss: -4.034354209899902
Batch 63/64 loss: -4.081351280212402
Batch 64/64 loss: -8.62521743774414
Epoch 443  Train loss: -4.103287094714595  Val loss: -4.444705412559903
Epoch 444
-------------------------------
Batch 1/64 loss: -4.012415409088135
Batch 2/64 loss: -4.088669300079346
Batch 3/64 loss: -4.153791427612305
Batch 4/64 loss: -4.075295925140381
Batch 5/64 loss: -4.157915115356445
Batch 6/64 loss: -3.972959518432617
Batch 7/64 loss: -4.117672443389893
Batch 8/64 loss: -4.087653160095215
Batch 9/64 loss: -4.0912652015686035
Batch 10/64 loss: -3.8187193870544434
Batch 11/64 loss: -4.118050575256348
Batch 12/64 loss: -4.061628818511963
Batch 13/64 loss: -4.164095878601074
Batch 14/64 loss: -4.188504219055176
Batch 15/64 loss: -4.047844886779785
Batch 16/64 loss: -3.6515254974365234
Batch 17/64 loss: -4.119171142578125
Batch 18/64 loss: -4.106853485107422
Batch 19/64 loss: -4.267142295837402
Batch 20/64 loss: -4.117405414581299
Batch 21/64 loss: -4.145442485809326
Batch 22/64 loss: -4.115313529968262
Batch 23/64 loss: -4.214189052581787
Batch 24/64 loss: -4.090653896331787
Batch 25/64 loss: -3.9929189682006836
Batch 26/64 loss: -3.530384063720703
Batch 27/64 loss: -4.175709247589111
Batch 28/64 loss: -4.170671463012695
Batch 29/64 loss: -4.111278057098389
Batch 30/64 loss: -4.023604393005371
Batch 31/64 loss: -4.221020221710205
Batch 32/64 loss: -4.116677284240723
Batch 33/64 loss: -4.11262845993042
Batch 34/64 loss: -4.050958156585693
Batch 35/64 loss: -4.193066120147705
Batch 36/64 loss: -4.1745429039001465
Batch 37/64 loss: -4.0384016036987305
Batch 38/64 loss: -3.9933252334594727
Batch 39/64 loss: -4.094690799713135
Batch 40/64 loss: -3.9475207328796387
Batch 41/64 loss: -4.204909801483154
Batch 42/64 loss: -4.029772758483887
Batch 43/64 loss: -3.8581385612487793
Batch 44/64 loss: -3.9606337547302246
Batch 45/64 loss: -4.280283451080322
Batch 46/64 loss: -4.120418548583984
Batch 47/64 loss: -4.0394697189331055
Batch 48/64 loss: -4.179102420806885
Batch 49/64 loss: -4.017684459686279
Batch 50/64 loss: -4.0136847496032715
Batch 51/64 loss: -4.138186931610107
Batch 52/64 loss: -4.144205570220947
Batch 53/64 loss: -4.01835298538208
Batch 54/64 loss: -4.116550445556641
Batch 55/64 loss: -4.156777381896973
Batch 56/64 loss: -4.047934532165527
Batch 57/64 loss: -4.164660453796387
Batch 58/64 loss: -3.834186553955078
Batch 59/64 loss: -3.9718432426452637
Batch 60/64 loss: -4.183159828186035
Batch 61/64 loss: -4.118049621582031
Batch 62/64 loss: -4.169918060302734
Batch 63/64 loss: -4.070381164550781
Batch 64/64 loss: -8.775960922241211
Epoch 444  Train loss: -4.131009434718711  Val loss: -4.462616871312721
Epoch 445
-------------------------------
Batch 1/64 loss: -4.011308193206787
Batch 2/64 loss: -4.158444404602051
Batch 3/64 loss: -4.229561805725098
Batch 4/64 loss: -4.064730167388916
Batch 5/64 loss: -3.934251308441162
Batch 6/64 loss: -4.197577476501465
Batch 7/64 loss: -4.072417259216309
Batch 8/64 loss: -4.322022438049316
Batch 9/64 loss: -4.109673023223877
Batch 10/64 loss: -4.167952537536621
Batch 11/64 loss: -4.069360733032227
Batch 12/64 loss: -4.148582935333252
Batch 13/64 loss: -3.9007863998413086
Batch 14/64 loss: -4.106764793395996
Batch 15/64 loss: -4.036805629730225
Batch 16/64 loss: -4.196707248687744
Batch 17/64 loss: -4.02357292175293
Batch 18/64 loss: -3.9160733222961426
Batch 19/64 loss: -4.120876312255859
Batch 20/64 loss: -3.992739200592041
Batch 21/64 loss: -4.148355007171631
Batch 22/64 loss: -3.9919285774230957
Batch 23/64 loss: -4.059019088745117
Batch 24/64 loss: -4.115715503692627
Batch 25/64 loss: -4.139030456542969
Batch 26/64 loss: -3.9561147689819336
Batch 27/64 loss: -4.1618218421936035
Batch 28/64 loss: -4.172547340393066
Batch 29/64 loss: -4.068345069885254
Batch 30/64 loss: -4.199326515197754
Batch 31/64 loss: -3.7400436401367188
Batch 32/64 loss: -3.7789206504821777
Batch 33/64 loss: -4.088500022888184
Batch 34/64 loss: -3.9228997230529785
Batch 35/64 loss: -3.987297534942627
Batch 36/64 loss: -3.4892539978027344
Batch 37/64 loss: -4.093252658843994
Batch 38/64 loss: -3.9743218421936035
Batch 39/64 loss: -3.8158841133117676
Batch 40/64 loss: -3.944639205932617
Batch 41/64 loss: -4.168116092681885
Batch 42/64 loss: -3.9830169677734375
Batch 43/64 loss: -4.223976135253906
Batch 44/64 loss: -4.132195949554443
Batch 45/64 loss: -4.034081935882568
Batch 46/64 loss: -3.7804436683654785
Batch 47/64 loss: -4.165095329284668
Batch 48/64 loss: -4.046175956726074
Batch 49/64 loss: -4.073033809661865
Batch 50/64 loss: -4.057714939117432
Batch 51/64 loss: -3.921276569366455
Batch 52/64 loss: -4.025785446166992
Batch 53/64 loss: -4.152808666229248
Batch 54/64 loss: -4.049442768096924
Batch 55/64 loss: -3.826791763305664
Batch 56/64 loss: -4.163700103759766
Batch 57/64 loss: -4.127288341522217
Batch 58/64 loss: -3.974672317504883
Batch 59/64 loss: -3.8786306381225586
Batch 60/64 loss: -3.998220920562744
Batch 61/64 loss: -4.0999755859375
Batch 62/64 loss: -4.1687445640563965
Batch 63/64 loss: -4.1349263191223145
Batch 64/64 loss: -8.759111404418945
Epoch 445  Train loss: -4.100123513913622  Val loss: -4.400217639621591
Epoch 446
-------------------------------
Batch 1/64 loss: -4.200429439544678
Batch 2/64 loss: -3.693695068359375
Batch 3/64 loss: -3.930361270904541
Batch 4/64 loss: -4.0187177658081055
Batch 5/64 loss: -3.95534610748291
Batch 6/64 loss: -3.9997849464416504
Batch 7/64 loss: -3.956904411315918
Batch 8/64 loss: -4.216658592224121
Batch 9/64 loss: -4.046035289764404
Batch 10/64 loss: -3.934879779815674
Batch 11/64 loss: -4.1560211181640625
Batch 12/64 loss: -4.0869340896606445
Batch 13/64 loss: -4.138476848602295
Batch 14/64 loss: -3.928109645843506
Batch 15/64 loss: -4.058842658996582
Batch 16/64 loss: -4.0527520179748535
Batch 17/64 loss: -4.027548313140869
Batch 18/64 loss: -4.044637680053711
Batch 19/64 loss: -4.111931324005127
Batch 20/64 loss: -4.089080810546875
Batch 21/64 loss: -3.9759316444396973
Batch 22/64 loss: -4.124085903167725
Batch 23/64 loss: -4.147140026092529
Batch 24/64 loss: -3.764617443084717
Batch 25/64 loss: -4.0975871086120605
Batch 26/64 loss: -4.224301338195801
Batch 27/64 loss: -3.396574020385742
Batch 28/64 loss: -3.9306273460388184
Batch 29/64 loss: -3.725067615509033
Batch 30/64 loss: -3.8036675453186035
Batch 31/64 loss: -3.9104552268981934
Batch 32/64 loss: -4.17711877822876
Batch 33/64 loss: -4.119351863861084
Batch 34/64 loss: -4.12217903137207
Batch 35/64 loss: -4.182366371154785
Batch 36/64 loss: -3.997028350830078
Batch 37/64 loss: -3.9772276878356934
Batch 38/64 loss: -4.128496170043945
Batch 39/64 loss: -4.135260105133057
Batch 40/64 loss: -4.057760238647461
Batch 41/64 loss: -4.325433731079102
Batch 42/64 loss: -4.027646064758301
Batch 43/64 loss: -4.184788703918457
Batch 44/64 loss: -3.924531936645508
Batch 45/64 loss: -4.116837501525879
Batch 46/64 loss: -4.126425266265869
Batch 47/64 loss: -4.135913372039795
Batch 48/64 loss: -4.160189628601074
Batch 49/64 loss: -3.853823661804199
Batch 50/64 loss: -4.045097351074219
Batch 51/64 loss: -4.008211612701416
Batch 52/64 loss: -3.725958824157715
Batch 53/64 loss: -4.052947521209717
Batch 54/64 loss: -3.830239772796631
Batch 55/64 loss: -4.055656433105469
Batch 56/64 loss: -3.53891658782959
Batch 57/64 loss: -4.225020885467529
Batch 58/64 loss: -3.89093017578125
Batch 59/64 loss: -4.168639659881592
Batch 60/64 loss: -3.974653720855713
Batch 61/64 loss: -3.7909297943115234
Batch 62/64 loss: -3.9676685333251953
Batch 63/64 loss: -3.965392589569092
Batch 64/64 loss: -8.390634536743164
Epoch 446  Train loss: -4.063259925094306  Val loss: -4.368791639190359
Epoch 447
-------------------------------
Batch 1/64 loss: -4.214662551879883
Batch 2/64 loss: -3.9487032890319824
Batch 3/64 loss: -4.070223331451416
Batch 4/64 loss: -4.093724727630615
Batch 5/64 loss: -4.046480655670166
Batch 6/64 loss: -4.1154303550720215
Batch 7/64 loss: -4.195256233215332
Batch 8/64 loss: -4.078617095947266
Batch 9/64 loss: -3.9769792556762695
Batch 10/64 loss: -4.012609481811523
Batch 11/64 loss: -3.875153064727783
Batch 12/64 loss: -3.9139275550842285
Batch 13/64 loss: -4.085565090179443
Batch 14/64 loss: -4.2903265953063965
Batch 15/64 loss: -3.817776679992676
Batch 16/64 loss: -4.2044148445129395
Batch 17/64 loss: -4.169347286224365
Batch 18/64 loss: -4.072444438934326
Batch 19/64 loss: -4.106189250946045
Batch 20/64 loss: -3.9997053146362305
Batch 21/64 loss: -3.8817567825317383
Batch 22/64 loss: -4.055924892425537
Batch 23/64 loss: -4.207650184631348
Batch 24/64 loss: -4.106574535369873
Batch 25/64 loss: -4.073390483856201
Batch 26/64 loss: -3.971273899078369
Batch 27/64 loss: -4.154471397399902
Batch 28/64 loss: -3.8744616508483887
Batch 29/64 loss: -4.221218585968018
Batch 30/64 loss: -3.929169178009033
Batch 31/64 loss: -4.053531646728516
Batch 32/64 loss: -4.166656017303467
Batch 33/64 loss: -4.074699878692627
Batch 34/64 loss: -4.1092729568481445
Batch 35/64 loss: -3.971126079559326
Batch 36/64 loss: -4.246169567108154
Batch 37/64 loss: -4.040023326873779
Batch 38/64 loss: -4.1842756271362305
Batch 39/64 loss: -4.045474052429199
Batch 40/64 loss: -3.996959686279297
Batch 41/64 loss: -4.053745269775391
Batch 42/64 loss: -4.092473983764648
Batch 43/64 loss: -3.758927822113037
Batch 44/64 loss: -3.953670024871826
Batch 45/64 loss: -4.2264885902404785
Batch 46/64 loss: -4.255788326263428
Batch 47/64 loss: -4.212810039520264
Batch 48/64 loss: -4.180196762084961
Batch 49/64 loss: -3.7560577392578125
Batch 50/64 loss: -4.170563697814941
Batch 51/64 loss: -4.236635208129883
Batch 52/64 loss: -4.161004066467285
Batch 53/64 loss: -4.217297554016113
Batch 54/64 loss: -4.259623050689697
Batch 55/64 loss: -4.007876396179199
Batch 56/64 loss: -4.157799243927002
Batch 57/64 loss: -4.113705635070801
Batch 58/64 loss: -4.1523661613464355
Batch 59/64 loss: -4.232452392578125
Batch 60/64 loss: -4.252147674560547
Batch 61/64 loss: -4.127640724182129
Batch 62/64 loss: -4.267088413238525
Batch 63/64 loss: -3.7613797187805176
Batch 64/64 loss: -8.494941711425781
Epoch 447  Train loss: -4.135381369497262  Val loss: -4.473314265614932
Epoch 448
-------------------------------
Batch 1/64 loss: -4.1977949142456055
Batch 2/64 loss: -4.199790000915527
Batch 3/64 loss: -3.829512119293213
Batch 4/64 loss: -4.275043487548828
Batch 5/64 loss: -4.021841049194336
Batch 6/64 loss: -4.129271507263184
Batch 7/64 loss: -4.206084728240967
Batch 8/64 loss: -3.9834470748901367
Batch 9/64 loss: -3.9215216636657715
Batch 10/64 loss: -4.199301242828369
Batch 11/64 loss: -4.061422824859619
Batch 12/64 loss: -4.105944633483887
Batch 13/64 loss: -4.052020072937012
Batch 14/64 loss: -4.088975429534912
Batch 15/64 loss: -4.224442958831787
Batch 16/64 loss: -4.02699089050293
Batch 17/64 loss: -4.269618511199951
Batch 18/64 loss: -4.090514659881592
Batch 19/64 loss: -4.273240089416504
Batch 20/64 loss: -4.08488130569458
Batch 21/64 loss: -3.898690700531006
Batch 22/64 loss: -3.9509286880493164
Batch 23/64 loss: -4.143185138702393
Batch 24/64 loss: -4.069100379943848
Batch 25/64 loss: -4.079301834106445
Batch 26/64 loss: -4.073372840881348
Batch 27/64 loss: -3.9951272010803223
Batch 28/64 loss: -4.122972011566162
Batch 29/64 loss: -4.01801061630249
Batch 30/64 loss: -4.29302978515625
Batch 31/64 loss: -4.108495235443115
Batch 32/64 loss: -4.07520866394043
Batch 33/64 loss: -4.151503086090088
Batch 34/64 loss: -4.102129936218262
Batch 35/64 loss: -3.934624671936035
Batch 36/64 loss: -3.80655574798584
Batch 37/64 loss: -4.06541109085083
Batch 38/64 loss: -4.296215534210205
Batch 39/64 loss: -3.719571590423584
Batch 40/64 loss: -4.053367614746094
Batch 41/64 loss: -4.135273456573486
Batch 42/64 loss: -3.9275546073913574
Batch 43/64 loss: -4.179842472076416
Batch 44/64 loss: -4.070822715759277
Batch 45/64 loss: -4.025874137878418
Batch 46/64 loss: -4.26656436920166
Batch 47/64 loss: -4.197530269622803
Batch 48/64 loss: -3.915806770324707
Batch 49/64 loss: -4.024135112762451
Batch 50/64 loss: -3.770796298980713
Batch 51/64 loss: -4.02651309967041
Batch 52/64 loss: -4.092411518096924
Batch 53/64 loss: -4.247809886932373
Batch 54/64 loss: -4.141551971435547
Batch 55/64 loss: -4.067641735076904
Batch 56/64 loss: -4.080747604370117
Batch 57/64 loss: -3.918393135070801
Batch 58/64 loss: -4.165431022644043
Batch 59/64 loss: -4.227666854858398
Batch 60/64 loss: -4.1531081199646
Batch 61/64 loss: -4.1711015701293945
Batch 62/64 loss: -3.8523025512695312
Batch 63/64 loss: -3.8931360244750977
Batch 64/64 loss: -8.603780746459961
Epoch 448  Train loss: -4.128679410149069  Val loss: -4.470875035446534
Epoch 449
-------------------------------
Batch 1/64 loss: -4.181163787841797
Batch 2/64 loss: -4.122920989990234
Batch 3/64 loss: -3.770449638366699
Batch 4/64 loss: -4.190831661224365
Batch 5/64 loss: -4.127774715423584
Batch 6/64 loss: -4.121665954589844
Batch 7/64 loss: -4.208929538726807
Batch 8/64 loss: -3.987476348876953
Batch 9/64 loss: -3.996339797973633
Batch 10/64 loss: -3.539677143096924
Batch 11/64 loss: -4.1570234298706055
Batch 12/64 loss: -4.147787570953369
Batch 13/64 loss: -3.883789539337158
Batch 14/64 loss: -4.144001007080078
Batch 15/64 loss: -4.225476264953613
Batch 16/64 loss: -3.9956812858581543
Batch 17/64 loss: -4.176204204559326
Batch 18/64 loss: -4.095333576202393
Batch 19/64 loss: -4.11030387878418
Batch 20/64 loss: -4.251051902770996
Batch 21/64 loss: -4.225698947906494
Batch 22/64 loss: -3.71635103225708
Batch 23/64 loss: -4.175266742706299
Batch 24/64 loss: -4.134909629821777
Batch 25/64 loss: -4.045516490936279
Batch 26/64 loss: -4.149148941040039
Batch 27/64 loss: -4.184711933135986
Batch 28/64 loss: -4.10854959487915
Batch 29/64 loss: -4.109542369842529
Batch 30/64 loss: -4.148013114929199
Batch 31/64 loss: -4.220966339111328
Batch 32/64 loss: -4.081398963928223
Batch 33/64 loss: -4.2027974128723145
Batch 34/64 loss: -4.038227081298828
Batch 35/64 loss: -4.076693534851074
Batch 36/64 loss: -4.205203056335449
Batch 37/64 loss: -4.212216377258301
Batch 38/64 loss: -4.044373512268066
Batch 39/64 loss: -3.982908248901367
Batch 40/64 loss: -3.9215087890625
Batch 41/64 loss: -4.011995315551758
Batch 42/64 loss: -3.847477912902832
Batch 43/64 loss: -4.248357772827148
Batch 44/64 loss: -4.061795234680176
Batch 45/64 loss: -4.1109538078308105
Batch 46/64 loss: -4.0161895751953125
Batch 47/64 loss: -4.087560176849365
Batch 48/64 loss: -4.191972732543945
Batch 49/64 loss: -4.05186128616333
Batch 50/64 loss: -3.791721820831299
Batch 51/64 loss: -4.176974296569824
Batch 52/64 loss: -3.9385666847229004
Batch 53/64 loss: -4.1683549880981445
Batch 54/64 loss: -3.8706130981445312
Batch 55/64 loss: -4.076687812805176
Batch 56/64 loss: -4.054189682006836
Batch 57/64 loss: -3.956326484680176
Batch 58/64 loss: -4.098109245300293
Batch 59/64 loss: -3.9827871322631836
Batch 60/64 loss: -4.19035530090332
Batch 61/64 loss: -4.107321739196777
Batch 62/64 loss: -4.175000190734863
Batch 63/64 loss: -4.141114711761475
Batch 64/64 loss: -8.691400527954102
Epoch 449  Train loss: -4.130081909778071  Val loss: -4.426184978681741
Epoch 450
-------------------------------
Batch 1/64 loss: -4.055140495300293
Batch 2/64 loss: -4.25471305847168
Batch 3/64 loss: -3.709554672241211
Batch 4/64 loss: -4.1234917640686035
Batch 5/64 loss: -4.249990940093994
Batch 6/64 loss: -4.079641342163086
Batch 7/64 loss: -3.7600960731506348
Batch 8/64 loss: -4.180461883544922
Batch 9/64 loss: -4.116654872894287
Batch 10/64 loss: -4.153961181640625
Batch 11/64 loss: -4.14137077331543
Batch 12/64 loss: -4.199159145355225
Batch 13/64 loss: -4.0206685066223145
Batch 14/64 loss: -4.197817325592041
Batch 15/64 loss: -4.055968284606934
Batch 16/64 loss: -4.21484375
Batch 17/64 loss: -4.045551300048828
Batch 18/64 loss: -4.097862243652344
Batch 19/64 loss: -4.061020374298096
Batch 20/64 loss: -4.127878189086914
Batch 21/64 loss: -4.038486480712891
Batch 22/64 loss: -4.127049922943115
Batch 23/64 loss: -4.075933933258057
Batch 24/64 loss: -4.056955337524414
Batch 25/64 loss: -4.225222110748291
Batch 26/64 loss: -4.015048027038574
Batch 27/64 loss: -4.142551898956299
Batch 28/64 loss: -3.6765966415405273
Batch 29/64 loss: -4.03784704208374
Batch 30/64 loss: -4.060916423797607
Batch 31/64 loss: -4.152054786682129
Batch 32/64 loss: -3.938004493713379
Batch 33/64 loss: -4.138479232788086
Batch 34/64 loss: -3.6659698486328125
Batch 35/64 loss: -4.118362903594971
Batch 36/64 loss: -4.127645492553711
Batch 37/64 loss: -4.070069313049316
Batch 38/64 loss: -3.923501968383789
Batch 39/64 loss: -4.130239963531494
Batch 40/64 loss: -4.20783805847168
Batch 41/64 loss: -4.198935508728027
Batch 42/64 loss: -3.8452281951904297
Batch 43/64 loss: -3.845630168914795
Batch 44/64 loss: -4.130885601043701
Batch 45/64 loss: -4.158408164978027
Batch 46/64 loss: -3.8619742393493652
Batch 47/64 loss: -4.1987624168396
Batch 48/64 loss: -4.010356903076172
Batch 49/64 loss: -4.078169345855713
Batch 50/64 loss: -4.121085166931152
Batch 51/64 loss: -4.020566463470459
Batch 52/64 loss: -4.280186653137207
Batch 53/64 loss: -3.9488072395324707
Batch 54/64 loss: -4.184741020202637
Batch 55/64 loss: -4.1556854248046875
Batch 56/64 loss: -4.0276994705200195
Batch 57/64 loss: -4.036731719970703
Batch 58/64 loss: -4.120610237121582
Batch 59/64 loss: -3.838834285736084
Batch 60/64 loss: -4.128124237060547
Batch 61/64 loss: -3.996156692504883
Batch 62/64 loss: -4.071406364440918
Batch 63/64 loss: -4.3239970207214355
Batch 64/64 loss: -8.6710205078125
Epoch 450  Train loss: -4.123307732974782  Val loss: -4.408718082913008
Epoch 451
-------------------------------
Batch 1/64 loss: -4.203886032104492
Batch 2/64 loss: -3.9796152114868164
Batch 3/64 loss: -4.092320442199707
Batch 4/64 loss: -4.090754985809326
Batch 5/64 loss: -4.157128810882568
Batch 6/64 loss: -4.049863815307617
Batch 7/64 loss: -4.14527702331543
Batch 8/64 loss: -4.169309616088867
Batch 9/64 loss: -4.0342488288879395
Batch 10/64 loss: -3.6563005447387695
Batch 11/64 loss: -4.183350563049316
Batch 12/64 loss: -4.145030975341797
Batch 13/64 loss: -4.095625877380371
Batch 14/64 loss: -3.941983699798584
Batch 15/64 loss: -3.9552230834960938
Batch 16/64 loss: -3.572162628173828
Batch 17/64 loss: -4.070314407348633
Batch 18/64 loss: -4.127213478088379
Batch 19/64 loss: -3.9702444076538086
Batch 20/64 loss: -4.082964897155762
Batch 21/64 loss: -3.884920120239258
Batch 22/64 loss: -3.547473907470703
Batch 23/64 loss: -4.0994157791137695
Batch 24/64 loss: -4.134247779846191
Batch 25/64 loss: -4.0547637939453125
Batch 26/64 loss: -4.158722400665283
Batch 27/64 loss: -4.106825351715088
Batch 28/64 loss: -4.137045383453369
Batch 29/64 loss: -3.9200334548950195
Batch 30/64 loss: -3.8705902099609375
Batch 31/64 loss: -4.188394069671631
Batch 32/64 loss: -4.039083003997803
Batch 33/64 loss: -4.169691562652588
Batch 34/64 loss: -4.176281452178955
Batch 35/64 loss: -3.949741840362549
Batch 36/64 loss: -4.0543670654296875
Batch 37/64 loss: -3.9407291412353516
Batch 38/64 loss: -4.142127990722656
Batch 39/64 loss: -4.169056415557861
Batch 40/64 loss: -4.070113182067871
Batch 41/64 loss: -4.049650192260742
Batch 42/64 loss: -3.6662850379943848
Batch 43/64 loss: -4.154049396514893
Batch 44/64 loss: -3.9897618293762207
Batch 45/64 loss: -4.08180570602417
Batch 46/64 loss: -4.201714515686035
Batch 47/64 loss: -3.9517650604248047
Batch 48/64 loss: -4.126609802246094
Batch 49/64 loss: -4.139816761016846
Batch 50/64 loss: -4.212801933288574
Batch 51/64 loss: -4.120479583740234
Batch 52/64 loss: -4.140071392059326
Batch 53/64 loss: -4.11789083480835
Batch 54/64 loss: -3.4758996963500977
Batch 55/64 loss: -3.981545925140381
Batch 56/64 loss: -4.049957752227783
Batch 57/64 loss: -4.223400592803955
Batch 58/64 loss: -4.267823219299316
Batch 59/64 loss: -3.9678196907043457
Batch 60/64 loss: -3.6992030143737793
Batch 61/64 loss: -3.934753894805908
Batch 62/64 loss: -4.051615238189697
Batch 63/64 loss: -4.021039962768555
Batch 64/64 loss: -8.691328048706055
Epoch 451  Train loss: -4.089109024347043  Val loss: -4.372583408945615
Epoch 452
-------------------------------
Batch 1/64 loss: -3.889291763305664
Batch 2/64 loss: -4.033617973327637
Batch 3/64 loss: -4.032350540161133
Batch 4/64 loss: -3.7554450035095215
Batch 5/64 loss: -3.957775592803955
Batch 6/64 loss: -4.073361396789551
Batch 7/64 loss: -4.101276397705078
Batch 8/64 loss: -4.117115020751953
Batch 9/64 loss: -4.12014627456665
Batch 10/64 loss: -4.044577598571777
Batch 11/64 loss: -3.9111409187316895
Batch 12/64 loss: -3.8733911514282227
Batch 13/64 loss: -4.113215923309326
Batch 14/64 loss: -4.005767345428467
Batch 15/64 loss: -3.9156079292297363
Batch 16/64 loss: -3.7931509017944336
Batch 17/64 loss: -3.9487853050231934
Batch 18/64 loss: -4.147777080535889
Batch 19/64 loss: -4.167767524719238
Batch 20/64 loss: -4.129367828369141
Batch 21/64 loss: -3.710747241973877
Batch 22/64 loss: -4.140376567840576
Batch 23/64 loss: -3.920175075531006
Batch 24/64 loss: -4.028493404388428
Batch 25/64 loss: -4.1822028160095215
Batch 26/64 loss: -3.9793577194213867
Batch 27/64 loss: -4.147470951080322
Batch 28/64 loss: -3.7033438682556152
Batch 29/64 loss: -3.944441318511963
Batch 30/64 loss: -4.103351593017578
Batch 31/64 loss: -4.173506259918213
Batch 32/64 loss: -4.119128227233887
Batch 33/64 loss: -4.176066875457764
Batch 34/64 loss: -4.065059661865234
Batch 35/64 loss: -3.840712070465088
Batch 36/64 loss: -4.063364028930664
Batch 37/64 loss: -4.095625400543213
Batch 38/64 loss: -4.181452751159668
Batch 39/64 loss: -4.13798189163208
Batch 40/64 loss: -3.644442558288574
Batch 41/64 loss: -4.028946399688721
Batch 42/64 loss: -4.059474945068359
Batch 43/64 loss: -4.098044395446777
Batch 44/64 loss: -4.225193500518799
Batch 45/64 loss: -4.074306488037109
Batch 46/64 loss: -4.002869129180908
Batch 47/64 loss: -4.076206684112549
Batch 48/64 loss: -4.040141582489014
Batch 49/64 loss: -3.9820356369018555
Batch 50/64 loss: -3.9818482398986816
Batch 51/64 loss: -3.8142433166503906
Batch 52/64 loss: -4.114786148071289
Batch 53/64 loss: -3.985543727874756
Batch 54/64 loss: -4.125272750854492
Batch 55/64 loss: -3.654191017150879
Batch 56/64 loss: -3.836470603942871
Batch 57/64 loss: -3.5751943588256836
Batch 58/64 loss: -3.5797667503356934
Batch 59/64 loss: -3.7685933113098145
Batch 60/64 loss: -3.6982102394104004
Batch 61/64 loss: -3.8273940086364746
Batch 62/64 loss: -3.659001350402832
Batch 63/64 loss: -4.063202857971191
Batch 64/64 loss: -8.11796760559082
Epoch 452  Train loss: -4.0289826337028956  Val loss: -4.096203348480959
Epoch 453
-------------------------------
Batch 1/64 loss: -3.6827754974365234
Batch 2/64 loss: -3.1215248107910156
Batch 3/64 loss: -3.5727028846740723
Batch 4/64 loss: -3.6638827323913574
Batch 5/64 loss: -3.8373336791992188
Batch 6/64 loss: -3.9274744987487793
Batch 7/64 loss: -3.8573694229125977
Batch 8/64 loss: -3.539224147796631
Batch 9/64 loss: -4.086671352386475
Batch 10/64 loss: -3.778779983520508
Batch 11/64 loss: -3.347590446472168
Batch 12/64 loss: -3.656797409057617
Batch 13/64 loss: -3.9820737838745117
Batch 14/64 loss: -3.9235377311706543
Batch 15/64 loss: -3.7897462844848633
Batch 16/64 loss: -3.908626079559326
Batch 17/64 loss: -3.9069175720214844
Batch 18/64 loss: -3.7756471633911133
Batch 19/64 loss: -3.91225528717041
Batch 20/64 loss: -3.2603673934936523
Batch 21/64 loss: -3.862421989440918
Batch 22/64 loss: -3.770975112915039
Batch 23/64 loss: -3.8879127502441406
Batch 24/64 loss: -3.992259979248047
Batch 25/64 loss: -4.06700325012207
Batch 26/64 loss: -3.4438819885253906
Batch 27/64 loss: -3.859714984893799
Batch 28/64 loss: -3.9401445388793945
Batch 29/64 loss: -3.6730475425720215
Batch 30/64 loss: -3.7885446548461914
Batch 31/64 loss: -3.9900832176208496
Batch 32/64 loss: -3.930415630340576
Batch 33/64 loss: -3.9601941108703613
Batch 34/64 loss: -3.978344440460205
Batch 35/64 loss: -3.8036513328552246
Batch 36/64 loss: -3.7802176475524902
Batch 37/64 loss: -3.4015579223632812
Batch 38/64 loss: -4.132773399353027
Batch 39/64 loss: -3.9835634231567383
Batch 40/64 loss: -3.980813980102539
Batch 41/64 loss: -3.9465694427490234
Batch 42/64 loss: -3.917088508605957
Batch 43/64 loss: -3.90903902053833
Batch 44/64 loss: -3.8826818466186523
Batch 45/64 loss: -3.811605453491211
Batch 46/64 loss: -3.9782023429870605
Batch 47/64 loss: -4.005066871643066
Batch 48/64 loss: -3.679513931274414
Batch 49/64 loss: -3.743096351623535
Batch 50/64 loss: -3.466172218322754
Batch 51/64 loss: -4.046810626983643
Batch 52/64 loss: -4.002730369567871
Batch 53/64 loss: -4.107048988342285
Batch 54/64 loss: -3.8319039344787598
Batch 55/64 loss: -4.018975257873535
Batch 56/64 loss: -4.095610618591309
Batch 57/64 loss: -3.9884471893310547
Batch 58/64 loss: -3.774564266204834
Batch 59/64 loss: -3.9742608070373535
Batch 60/64 loss: -3.958700656890869
Batch 61/64 loss: -3.806889057159424
Batch 62/64 loss: -3.701817512512207
Batch 63/64 loss: -4.047137260437012
Batch 64/64 loss: -8.512334823608398
Epoch 453  Train loss: -3.8876392738491883  Val loss: -4.362940037783069
Epoch 454
-------------------------------
Batch 1/64 loss: -3.747786521911621
Batch 2/64 loss: -3.8497071266174316
Batch 3/64 loss: -4.26240873336792
Batch 4/64 loss: -4.006174564361572
Batch 5/64 loss: -3.6764144897460938
Batch 6/64 loss: -4.110724449157715
Batch 7/64 loss: -4.045981407165527
Batch 8/64 loss: -4.107388496398926
Batch 9/64 loss: -3.924142837524414
Batch 10/64 loss: -4.064719200134277
Batch 11/64 loss: -3.8978137969970703
Batch 12/64 loss: -4.176325798034668
Batch 13/64 loss: -3.794743537902832
Batch 14/64 loss: -4.109023094177246
Batch 15/64 loss: -3.861711025238037
Batch 16/64 loss: -4.094384670257568
Batch 17/64 loss: -3.6450414657592773
Batch 18/64 loss: -4.1316423416137695
Batch 19/64 loss: -4.158295154571533
Batch 20/64 loss: -3.6245474815368652
Batch 21/64 loss: -3.8793344497680664
Batch 22/64 loss: -3.8798131942749023
Batch 23/64 loss: -3.540492534637451
Batch 24/64 loss: -3.9814229011535645
Batch 25/64 loss: -4.081169605255127
Batch 26/64 loss: -3.9384312629699707
Batch 27/64 loss: -3.8718371391296387
Batch 28/64 loss: -3.938345432281494
Batch 29/64 loss: -3.957613945007324
Batch 30/64 loss: -4.030970096588135
Batch 31/64 loss: -3.9418792724609375
Batch 32/64 loss: -4.034915924072266
Batch 33/64 loss: -4.073444843292236
Batch 34/64 loss: -4.067262172698975
Batch 35/64 loss: -4.061600685119629
Batch 36/64 loss: -4.107113361358643
Batch 37/64 loss: -4.108593463897705
Batch 38/64 loss: -4.043704509735107
Batch 39/64 loss: -3.87174129486084
Batch 40/64 loss: -4.043763160705566
Batch 41/64 loss: -4.032371520996094
Batch 42/64 loss: -3.8805770874023438
Batch 43/64 loss: -4.078032970428467
Batch 44/64 loss: -4.018388748168945
Batch 45/64 loss: -4.000992298126221
Batch 46/64 loss: -3.76839542388916
Batch 47/64 loss: -4.222061634063721
Batch 48/64 loss: -3.6794700622558594
Batch 49/64 loss: -4.163877010345459
Batch 50/64 loss: -4.0336785316467285
Batch 51/64 loss: -3.5133137702941895
Batch 52/64 loss: -4.143187999725342
Batch 53/64 loss: -3.899698257446289
Batch 54/64 loss: -4.100189208984375
Batch 55/64 loss: -4.184579372406006
Batch 56/64 loss: -4.142592430114746
Batch 57/64 loss: -3.8522987365722656
Batch 58/64 loss: -4.073658466339111
Batch 59/64 loss: -3.7204036712646484
Batch 60/64 loss: -4.153631210327148
Batch 61/64 loss: -4.016652584075928
Batch 62/64 loss: -3.9634523391723633
Batch 63/64 loss: -4.039594650268555
Batch 64/64 loss: -8.114616394042969
Epoch 454  Train loss: -4.023678207397461  Val loss: -4.223128420380792
Epoch 455
-------------------------------
Batch 1/64 loss: -4.072534561157227
Batch 2/64 loss: -4.081030368804932
Batch 3/64 loss: -3.589992046356201
Batch 4/64 loss: -4.086986541748047
Batch 5/64 loss: -3.9469380378723145
Batch 6/64 loss: -4.158025741577148
Batch 7/64 loss: -3.8300533294677734
Batch 8/64 loss: -3.9161291122436523
Batch 9/64 loss: -3.807279586791992
Batch 10/64 loss: -4.023626327514648
Batch 11/64 loss: -4.067973613739014
Batch 12/64 loss: -3.602682590484619
Batch 13/64 loss: -4.059194087982178
Batch 14/64 loss: -3.8713574409484863
Batch 15/64 loss: -3.800675868988037
Batch 16/64 loss: -3.8015193939208984
Batch 17/64 loss: -4.0943989753723145
Batch 18/64 loss: -4.097344398498535
Batch 19/64 loss: -3.6911773681640625
Batch 20/64 loss: -3.8458075523376465
Batch 21/64 loss: -3.7818689346313477
Batch 22/64 loss: -4.043294429779053
Batch 23/64 loss: -4.045144081115723
Batch 24/64 loss: -3.9040169715881348
Batch 25/64 loss: -4.0483174324035645
Batch 26/64 loss: -4.0630717277526855
Batch 27/64 loss: -4.079733848571777
Batch 28/64 loss: -3.9823155403137207
Batch 29/64 loss: -3.894501209259033
Batch 30/64 loss: -4.105224609375
Batch 31/64 loss: -3.9761128425598145
Batch 32/64 loss: -3.9842867851257324
Batch 33/64 loss: -4.050823211669922
Batch 34/64 loss: -4.100622653961182
Batch 35/64 loss: -4.160886764526367
Batch 36/64 loss: -4.107272148132324
Batch 37/64 loss: -3.6369247436523438
Batch 38/64 loss: -3.6092514991760254
Batch 39/64 loss: -4.098753452301025
Batch 40/64 loss: -4.054727554321289
Batch 41/64 loss: -4.150355815887451
Batch 42/64 loss: -4.005277633666992
Batch 43/64 loss: -4.174875259399414
Batch 44/64 loss: -4.115045547485352
Batch 45/64 loss: -4.005722999572754
Batch 46/64 loss: -3.9502105712890625
Batch 47/64 loss: -4.020650386810303
Batch 48/64 loss: -3.9164228439331055
Batch 49/64 loss: -4.028482437133789
Batch 50/64 loss: -4.110254287719727
Batch 51/64 loss: -4.011784553527832
Batch 52/64 loss: -3.9888110160827637
Batch 53/64 loss: -3.808121681213379
Batch 54/64 loss: -4.053014278411865
Batch 55/64 loss: -3.6342711448669434
Batch 56/64 loss: -4.071223735809326
Batch 57/64 loss: -3.971524238586426
Batch 58/64 loss: -3.740746021270752
Batch 59/64 loss: -4.009194850921631
Batch 60/64 loss: -4.025391101837158
Batch 61/64 loss: -3.8285984992980957
Batch 62/64 loss: -4.168374538421631
Batch 63/64 loss: -4.262951850891113
Batch 64/64 loss: -8.739581108093262
Epoch 455  Train loss: -4.0278881334791  Val loss: -4.514793776154928
Epoch 456
-------------------------------
Batch 1/64 loss: -4.262975215911865
Batch 2/64 loss: -4.175540924072266
Batch 3/64 loss: -4.10090446472168
Batch 4/64 loss: -3.995532512664795
Batch 5/64 loss: -4.17130184173584
Batch 6/64 loss: -3.851478099822998
Batch 7/64 loss: -4.13007116317749
Batch 8/64 loss: -4.264342308044434
Batch 9/64 loss: -3.932979106903076
Batch 10/64 loss: -4.074941158294678
Batch 11/64 loss: -3.9732279777526855
Batch 12/64 loss: -4.066614627838135
Batch 13/64 loss: -3.969972610473633
Batch 14/64 loss: -4.175564765930176
Batch 15/64 loss: -4.098471164703369
Batch 16/64 loss: -4.02704381942749
Batch 17/64 loss: -4.063750267028809
Batch 18/64 loss: -4.03746223449707
Batch 19/64 loss: -4.058313369750977
Batch 20/64 loss: -4.048069000244141
Batch 21/64 loss: -3.9434242248535156
Batch 22/64 loss: -3.973724365234375
Batch 23/64 loss: -4.076831340789795
Batch 24/64 loss: -4.128866195678711
Batch 25/64 loss: -4.125683784484863
Batch 26/64 loss: -4.15591287612915
Batch 27/64 loss: -4.149086952209473
Batch 28/64 loss: -4.176567077636719
Batch 29/64 loss: -3.9543895721435547
Batch 30/64 loss: -4.127490520477295
Batch 31/64 loss: -4.258651256561279
Batch 32/64 loss: -3.951747417449951
Batch 33/64 loss: -4.065445423126221
Batch 34/64 loss: -3.849475860595703
Batch 35/64 loss: -3.9678759574890137
Batch 36/64 loss: -4.24247932434082
Batch 37/64 loss: -4.190746307373047
Batch 38/64 loss: -4.143845081329346
Batch 39/64 loss: -4.108754634857178
Batch 40/64 loss: -4.217199325561523
Batch 41/64 loss: -4.133195400238037
Batch 42/64 loss: -4.282047748565674
Batch 43/64 loss: -3.985030174255371
Batch 44/64 loss: -3.6286325454711914
Batch 45/64 loss: -3.87274169921875
Batch 46/64 loss: -4.018209457397461
Batch 47/64 loss: -3.9922547340393066
Batch 48/64 loss: -3.857296943664551
Batch 49/64 loss: -4.149909973144531
Batch 50/64 loss: -4.154173851013184
Batch 51/64 loss: -4.241397857666016
Batch 52/64 loss: -4.119948387145996
Batch 53/64 loss: -4.064995765686035
Batch 54/64 loss: -3.7471752166748047
Batch 55/64 loss: -4.109279632568359
Batch 56/64 loss: -3.691591262817383
Batch 57/64 loss: -3.997493267059326
Batch 58/64 loss: -4.105973720550537
Batch 59/64 loss: -4.229491233825684
Batch 60/64 loss: -4.029402256011963
Batch 61/64 loss: -3.9686756134033203
Batch 62/64 loss: -3.8625192642211914
Batch 63/64 loss: -4.091209411621094
Batch 64/64 loss: -8.655876159667969
Epoch 456  Train loss: -4.111549908507104  Val loss: -4.5541119001985
Epoch 457
-------------------------------
Batch 1/64 loss: -4.1238861083984375
Batch 2/64 loss: -3.674182415008545
Batch 3/64 loss: -4.065403938293457
Batch 4/64 loss: -4.097410202026367
Batch 5/64 loss: -4.152389049530029
Batch 6/64 loss: -4.221405982971191
Batch 7/64 loss: -4.162905693054199
Batch 8/64 loss: -4.09822416305542
Batch 9/64 loss: -3.959291934967041
Batch 10/64 loss: -4.2145915031433105
Batch 11/64 loss: -4.153252124786377
Batch 12/64 loss: -4.096957683563232
Batch 13/64 loss: -4.059943675994873
Batch 14/64 loss: -4.085372447967529
Batch 15/64 loss: -3.9680027961730957
Batch 16/64 loss: -4.051548004150391
Batch 17/64 loss: -4.041687488555908
Batch 18/64 loss: -4.064960956573486
Batch 19/64 loss: -4.161047458648682
Batch 20/64 loss: -4.182815074920654
Batch 21/64 loss: -4.063539505004883
Batch 22/64 loss: -4.076826095581055
Batch 23/64 loss: -4.119499683380127
Batch 24/64 loss: -4.091446399688721
Batch 25/64 loss: -4.290842533111572
Batch 26/64 loss: -3.891724109649658
Batch 27/64 loss: -4.06878137588501
Batch 28/64 loss: -4.233978748321533
Batch 29/64 loss: -4.200368881225586
Batch 30/64 loss: -4.167093753814697
Batch 31/64 loss: -4.201903820037842
Batch 32/64 loss: -4.112417697906494
Batch 33/64 loss: -3.921259880065918
Batch 34/64 loss: -3.9132609367370605
Batch 35/64 loss: -3.8988547325134277
Batch 36/64 loss: -4.095536708831787
Batch 37/64 loss: -4.238044261932373
Batch 38/64 loss: -4.163919448852539
Batch 39/64 loss: -4.166920185089111
Batch 40/64 loss: -4.0999908447265625
Batch 41/64 loss: -4.262850761413574
Batch 42/64 loss: -4.058460235595703
Batch 43/64 loss: -4.178673267364502
Batch 44/64 loss: -4.1415934562683105
Batch 45/64 loss: -4.146908283233643
Batch 46/64 loss: -4.280195713043213
Batch 47/64 loss: -4.186758518218994
Batch 48/64 loss: -4.258856296539307
Batch 49/64 loss: -4.22780179977417
Batch 50/64 loss: -4.242835998535156
Batch 51/64 loss: -4.134884357452393
Batch 52/64 loss: -4.020340442657471
Batch 53/64 loss: -3.928469657897949
Batch 54/64 loss: -4.181024551391602
Batch 55/64 loss: -4.048155307769775
Batch 56/64 loss: -4.184813022613525
Batch 57/64 loss: -4.046646595001221
Batch 58/64 loss: -4.300283908843994
Batch 59/64 loss: -4.166933536529541
Batch 60/64 loss: -4.122165203094482
Batch 61/64 loss: -4.091217041015625
Batch 62/64 loss: -4.215069770812988
Batch 63/64 loss: -4.17282772064209
Batch 64/64 loss: -8.693721771240234
Epoch 457  Train loss: -4.16893404044357  Val loss: -4.59837309847173
Saving best model, epoch: 457
Epoch 458
-------------------------------
Batch 1/64 loss: -3.968111991882324
Batch 2/64 loss: -4.12411642074585
Batch 3/64 loss: -4.099709510803223
Batch 4/64 loss: -4.084312915802002
Batch 5/64 loss: -3.837550163269043
Batch 6/64 loss: -4.218085765838623
Batch 7/64 loss: -4.194945812225342
Batch 8/64 loss: -4.119448661804199
Batch 9/64 loss: -4.060111999511719
Batch 10/64 loss: -4.0025954246521
Batch 11/64 loss: -4.020524024963379
Batch 12/64 loss: -4.079230785369873
Batch 13/64 loss: -4.18080472946167
Batch 14/64 loss: -3.968046188354492
Batch 15/64 loss: -4.19696569442749
Batch 16/64 loss: -4.136707782745361
Batch 17/64 loss: -4.032037258148193
Batch 18/64 loss: -3.9821877479553223
Batch 19/64 loss: -4.093680381774902
Batch 20/64 loss: -4.196485996246338
Batch 21/64 loss: -4.109678268432617
Batch 22/64 loss: -4.245050430297852
Batch 23/64 loss: -4.170889854431152
Batch 24/64 loss: -3.8349952697753906
Batch 25/64 loss: -4.165605545043945
Batch 26/64 loss: -4.160368919372559
Batch 27/64 loss: -4.100955009460449
Batch 28/64 loss: -4.1070451736450195
Batch 29/64 loss: -4.013896465301514
Batch 30/64 loss: -4.2708282470703125
Batch 31/64 loss: -4.180572986602783
Batch 32/64 loss: -3.885601043701172
Batch 33/64 loss: -4.2013258934021
Batch 34/64 loss: -3.9232873916625977
Batch 35/64 loss: -4.193948745727539
Batch 36/64 loss: -4.1396164894104
Batch 37/64 loss: -4.197132110595703
Batch 38/64 loss: -4.166506767272949
Batch 39/64 loss: -4.132033348083496
Batch 40/64 loss: -4.073005199432373
Batch 41/64 loss: -4.054466724395752
Batch 42/64 loss: -4.108641624450684
Batch 43/64 loss: -4.077198028564453
Batch 44/64 loss: -4.0836286544799805
Batch 45/64 loss: -4.093087196350098
Batch 46/64 loss: -4.177440643310547
Batch 47/64 loss: -4.227933883666992
Batch 48/64 loss: -4.188721179962158
Batch 49/64 loss: -4.153181552886963
Batch 50/64 loss: -4.1539692878723145
Batch 51/64 loss: -3.976560115814209
Batch 52/64 loss: -3.8351001739501953
Batch 53/64 loss: -4.1502275466918945
Batch 54/64 loss: -4.187394618988037
Batch 55/64 loss: -4.1204094886779785
Batch 56/64 loss: -4.198035717010498
Batch 57/64 loss: -4.215762138366699
Batch 58/64 loss: -4.141127109527588
Batch 59/64 loss: -4.002336025238037
Batch 60/64 loss: -4.107971668243408
Batch 61/64 loss: -4.195694923400879
Batch 62/64 loss: -4.02174711227417
Batch 63/64 loss: -4.143580913543701
Batch 64/64 loss: -8.860435485839844
Epoch 458  Train loss: -4.158863456576478  Val loss: -4.5300287594090625
Epoch 459
-------------------------------
Batch 1/64 loss: -4.2502312660217285
Batch 2/64 loss: -3.941526412963867
Batch 3/64 loss: -4.070999622344971
Batch 4/64 loss: -4.134644985198975
Batch 5/64 loss: -4.199333190917969
Batch 6/64 loss: -4.134538650512695
Batch 7/64 loss: -4.03363561630249
Batch 8/64 loss: -4.094780921936035
Batch 9/64 loss: -4.22133731842041
Batch 10/64 loss: -4.077210903167725
Batch 11/64 loss: -4.082991600036621
Batch 12/64 loss: -3.721935272216797
Batch 13/64 loss: -4.0249199867248535
Batch 14/64 loss: -4.155832290649414
Batch 15/64 loss: -4.161905765533447
Batch 16/64 loss: -4.015260219573975
Batch 17/64 loss: -3.9234652519226074
Batch 18/64 loss: -4.188249588012695
Batch 19/64 loss: -4.166505336761475
Batch 20/64 loss: -4.100551128387451
Batch 21/64 loss: -4.105391025543213
Batch 22/64 loss: -3.999821186065674
Batch 23/64 loss: -4.024467945098877
Batch 24/64 loss: -3.977504253387451
Batch 25/64 loss: -3.94276762008667
Batch 26/64 loss: -4.1803879737854
Batch 27/64 loss: -4.173539161682129
Batch 28/64 loss: -4.177257537841797
Batch 29/64 loss: -4.314058780670166
Batch 30/64 loss: -3.9999942779541016
Batch 31/64 loss: -3.8081297874450684
Batch 32/64 loss: -4.038021087646484
Batch 33/64 loss: -4.017006874084473
Batch 34/64 loss: -3.9457297325134277
Batch 35/64 loss: -3.9565553665161133
Batch 36/64 loss: -4.173678874969482
Batch 37/64 loss: -4.1643853187561035
Batch 38/64 loss: -3.9929771423339844
Batch 39/64 loss: -4.153923988342285
Batch 40/64 loss: -4.105003356933594
Batch 41/64 loss: -4.206603050231934
Batch 42/64 loss: -4.103617191314697
Batch 43/64 loss: -4.201754093170166
Batch 44/64 loss: -3.9653139114379883
Batch 45/64 loss: -3.997154712677002
Batch 46/64 loss: -4.200778007507324
Batch 47/64 loss: -3.7760982513427734
Batch 48/64 loss: -4.125392913818359
Batch 49/64 loss: -4.161189556121826
Batch 50/64 loss: -3.8363733291625977
Batch 51/64 loss: -4.127737522125244
Batch 52/64 loss: -4.076197147369385
Batch 53/64 loss: -4.190118789672852
Batch 54/64 loss: -4.086259365081787
Batch 55/64 loss: -4.114157199859619
Batch 56/64 loss: -3.8636903762817383
Batch 57/64 loss: -4.2356486320495605
Batch 58/64 loss: -4.1639180183410645
Batch 59/64 loss: -4.09305477142334
Batch 60/64 loss: -4.266906261444092
Batch 61/64 loss: -4.101901054382324
Batch 62/64 loss: -4.139411449432373
Batch 63/64 loss: -4.230706691741943
Batch 64/64 loss: -8.559200286865234
Epoch 459  Train loss: -4.135432770672966  Val loss: -4.448155812791123
Epoch 460
-------------------------------
Batch 1/64 loss: -4.1894659996032715
Batch 2/64 loss: -4.246723175048828
Batch 3/64 loss: -4.0428667068481445
Batch 4/64 loss: -4.185139179229736
Batch 5/64 loss: -4.225717067718506
Batch 6/64 loss: -4.194770336151123
Batch 7/64 loss: -4.235134124755859
Batch 8/64 loss: -4.137462615966797
Batch 9/64 loss: -4.157840251922607
Batch 10/64 loss: -4.165853023529053
Batch 11/64 loss: -4.0535407066345215
Batch 12/64 loss: -3.869485378265381
Batch 13/64 loss: -4.265629768371582
Batch 14/64 loss: -4.068378925323486
Batch 15/64 loss: -3.8912458419799805
Batch 16/64 loss: -3.6511058807373047
Batch 17/64 loss: -4.045708656311035
Batch 18/64 loss: -3.912259101867676
Batch 19/64 loss: -4.0565104484558105
Batch 20/64 loss: -4.100002288818359
Batch 21/64 loss: -3.7772727012634277
Batch 22/64 loss: -4.1842851638793945
Batch 23/64 loss: -3.8933520317077637
Batch 24/64 loss: -4.11395788192749
Batch 25/64 loss: -4.083603382110596
Batch 26/64 loss: -4.025532245635986
Batch 27/64 loss: -4.115660667419434
Batch 28/64 loss: -3.951620578765869
Batch 29/64 loss: -3.892794609069824
Batch 30/64 loss: -4.143070220947266
Batch 31/64 loss: -4.021646022796631
Batch 32/64 loss: -4.183675765991211
Batch 33/64 loss: -3.991067886352539
Batch 34/64 loss: -4.0048346519470215
Batch 35/64 loss: -4.048854827880859
Batch 36/64 loss: -4.074762344360352
Batch 37/64 loss: -4.135093688964844
Batch 38/64 loss: -4.049026012420654
Batch 39/64 loss: -3.8034777641296387
Batch 40/64 loss: -3.867600917816162
Batch 41/64 loss: -4.080268859863281
Batch 42/64 loss: -4.0327253341674805
Batch 43/64 loss: -4.188776016235352
Batch 44/64 loss: -3.958670139312744
Batch 45/64 loss: -4.267763137817383
Batch 46/64 loss: -4.010919570922852
Batch 47/64 loss: -4.207791805267334
Batch 48/64 loss: -4.193758487701416
Batch 49/64 loss: -3.9389801025390625
Batch 50/64 loss: -4.177260875701904
Batch 51/64 loss: -4.185758113861084
Batch 52/64 loss: -4.177992820739746
Batch 53/64 loss: -4.034305095672607
Batch 54/64 loss: -4.051848888397217
Batch 55/64 loss: -4.1590681076049805
Batch 56/64 loss: -3.739349842071533
Batch 57/64 loss: -4.0712890625
Batch 58/64 loss: -4.0863447189331055
Batch 59/64 loss: -4.096137523651123
Batch 60/64 loss: -4.206400394439697
Batch 61/64 loss: -4.125207901000977
Batch 62/64 loss: -4.185877323150635
Batch 63/64 loss: -4.196402072906494
Batch 64/64 loss: -8.601083755493164
Epoch 460  Train loss: -4.1236037310431986  Val loss: -4.556402829094851
Epoch 461
-------------------------------
Batch 1/64 loss: -4.242940902709961
Batch 2/64 loss: -4.196842193603516
Batch 3/64 loss: -4.230669975280762
Batch 4/64 loss: -4.266419410705566
Batch 5/64 loss: -3.9452672004699707
Batch 6/64 loss: -4.138502597808838
Batch 7/64 loss: -3.9830703735351562
Batch 8/64 loss: -4.047752857208252
Batch 9/64 loss: -4.2518415451049805
Batch 10/64 loss: -4.228371620178223
Batch 11/64 loss: -4.163640975952148
Batch 12/64 loss: -4.1979146003723145
Batch 13/64 loss: -4.1588921546936035
Batch 14/64 loss: -4.124457359313965
Batch 15/64 loss: -4.094101905822754
Batch 16/64 loss: -4.134054183959961
Batch 17/64 loss: -4.089119911193848
Batch 18/64 loss: -4.087669372558594
Batch 19/64 loss: -4.114285469055176
Batch 20/64 loss: -4.172530174255371
Batch 21/64 loss: -3.565402030944824
Batch 22/64 loss: -4.017472267150879
Batch 23/64 loss: -4.168843746185303
Batch 24/64 loss: -3.9431371688842773
Batch 25/64 loss: -4.06085729598999
Batch 26/64 loss: -4.288654804229736
Batch 27/64 loss: -4.122218608856201
Batch 28/64 loss: -4.05919885635376
Batch 29/64 loss: -4.106770038604736
Batch 30/64 loss: -4.077960968017578
Batch 31/64 loss: -4.018141746520996
Batch 32/64 loss: -4.179010391235352
Batch 33/64 loss: -3.930063247680664
Batch 34/64 loss: -4.040771007537842
Batch 35/64 loss: -4.167535781860352
Batch 36/64 loss: -4.123003005981445
Batch 37/64 loss: -3.871364116668701
Batch 38/64 loss: -3.8566932678222656
Batch 39/64 loss: -4.0638532638549805
Batch 40/64 loss: -4.161268711090088
Batch 41/64 loss: -4.0947465896606445
Batch 42/64 loss: -4.232308864593506
Batch 43/64 loss: -4.19691801071167
Batch 44/64 loss: -4.0449934005737305
Batch 45/64 loss: -3.9800825119018555
Batch 46/64 loss: -4.133192539215088
Batch 47/64 loss: -4.131697654724121
Batch 48/64 loss: -3.977959156036377
Batch 49/64 loss: -4.190863609313965
Batch 50/64 loss: -4.232793807983398
Batch 51/64 loss: -4.024294853210449
Batch 52/64 loss: -4.097397804260254
Batch 53/64 loss: -4.171817779541016
Batch 54/64 loss: -4.147841453552246
Batch 55/64 loss: -4.0852952003479
Batch 56/64 loss: -3.8666820526123047
Batch 57/64 loss: -4.172261714935303
Batch 58/64 loss: -4.048616409301758
Batch 59/64 loss: -4.110326290130615
Batch 60/64 loss: -3.732271671295166
Batch 61/64 loss: -4.162966728210449
Batch 62/64 loss: -4.184632778167725
Batch 63/64 loss: -3.939263343811035
Batch 64/64 loss: -8.561543464660645
Epoch 461  Train loss: -4.14228936363669  Val loss: -4.5092077746833725
Epoch 462
-------------------------------
Batch 1/64 loss: -4.0231194496154785
Batch 2/64 loss: -4.181223392486572
Batch 3/64 loss: -4.191575527191162
Batch 4/64 loss: -4.174093723297119
Batch 5/64 loss: -4.12821102142334
Batch 6/64 loss: -4.151607513427734
Batch 7/64 loss: -4.179990291595459
Batch 8/64 loss: -4.145448684692383
Batch 9/64 loss: -3.995361328125
Batch 10/64 loss: -4.111129283905029
Batch 11/64 loss: -4.234601020812988
Batch 12/64 loss: -3.9360241889953613
Batch 13/64 loss: -4.118259906768799
Batch 14/64 loss: -4.191951274871826
Batch 15/64 loss: -4.13539981842041
Batch 16/64 loss: -4.070281028747559
Batch 17/64 loss: -4.018855094909668
Batch 18/64 loss: -3.9093399047851562
Batch 19/64 loss: -3.8386316299438477
Batch 20/64 loss: -3.9943790435791016
Batch 21/64 loss: -4.184693336486816
Batch 22/64 loss: -4.079970836639404
Batch 23/64 loss: -3.823014736175537
Batch 24/64 loss: -3.9449191093444824
Batch 25/64 loss: -4.125946044921875
Batch 26/64 loss: -3.9567832946777344
Batch 27/64 loss: -3.796276092529297
Batch 28/64 loss: -4.02110481262207
Batch 29/64 loss: -4.166541576385498
Batch 30/64 loss: -3.737537384033203
Batch 31/64 loss: -3.9692907333374023
Batch 32/64 loss: -3.987380027770996
Batch 33/64 loss: -3.7322397232055664
Batch 34/64 loss: -3.8122363090515137
Batch 35/64 loss: -3.9788007736206055
Batch 36/64 loss: -4.064648151397705
Batch 37/64 loss: -4.073366165161133
Batch 38/64 loss: -3.9250283241271973
Batch 39/64 loss: -3.9667816162109375
Batch 40/64 loss: -3.920762062072754
Batch 41/64 loss: -3.9041404724121094
Batch 42/64 loss: -3.9474124908447266
Batch 43/64 loss: -4.016024112701416
Batch 44/64 loss: -4.0080246925354
Batch 45/64 loss: -3.6823201179504395
Batch 46/64 loss: -3.9702224731445312
Batch 47/64 loss: -3.576651096343994
Batch 48/64 loss: -4.10666036605835
Batch 49/64 loss: -4.170310020446777
Batch 50/64 loss: -3.981823444366455
Batch 51/64 loss: -3.9251718521118164
Batch 52/64 loss: -4.007898807525635
Batch 53/64 loss: -4.125807762145996
Batch 54/64 loss: -3.9720945358276367
Batch 55/64 loss: -4.100372791290283
Batch 56/64 loss: -4.100585460662842
Batch 57/64 loss: -3.5762124061584473
Batch 58/64 loss: -3.84237003326416
Batch 59/64 loss: -4.067185401916504
Batch 60/64 loss: -3.906062126159668
Batch 61/64 loss: -4.160247325897217
Batch 62/64 loss: -4.080813884735107
Batch 63/64 loss: -4.01425313949585
Batch 64/64 loss: -8.485200881958008
Epoch 462  Train loss: -4.056523446475758  Val loss: -4.486665142360831
Epoch 463
-------------------------------
Batch 1/64 loss: -4.1607818603515625
Batch 2/64 loss: -3.862236499786377
Batch 3/64 loss: -3.816143035888672
Batch 4/64 loss: -4.04435920715332
Batch 5/64 loss: -4.181612014770508
Batch 6/64 loss: -3.95475435256958
Batch 7/64 loss: -3.9062061309814453
Batch 8/64 loss: -3.922908306121826
Batch 9/64 loss: -4.061404228210449
Batch 10/64 loss: -3.6311593055725098
Batch 11/64 loss: -4.06708288192749
Batch 12/64 loss: -4.178112030029297
Batch 13/64 loss: -4.228168487548828
Batch 14/64 loss: -4.127737522125244
Batch 15/64 loss: -4.139939785003662
Batch 16/64 loss: -4.129352569580078
Batch 17/64 loss: -4.147624969482422
Batch 18/64 loss: -4.014655590057373
Batch 19/64 loss: -4.238750457763672
Batch 20/64 loss: -3.8851962089538574
Batch 21/64 loss: -3.994452953338623
Batch 22/64 loss: -4.135280609130859
Batch 23/64 loss: -3.884626865386963
Batch 24/64 loss: -4.192442893981934
Batch 25/64 loss: -4.109780311584473
Batch 26/64 loss: -3.818235397338867
Batch 27/64 loss: -4.215348243713379
Batch 28/64 loss: -4.1241021156311035
Batch 29/64 loss: -4.105449199676514
Batch 30/64 loss: -4.188978672027588
Batch 31/64 loss: -3.933088779449463
Batch 32/64 loss: -4.037788391113281
Batch 33/64 loss: -4.101017475128174
Batch 34/64 loss: -3.7989883422851562
Batch 35/64 loss: -4.1235737800598145
Batch 36/64 loss: -4.203659534454346
Batch 37/64 loss: -4.2478203773498535
Batch 38/64 loss: -3.759781837463379
Batch 39/64 loss: -4.049180030822754
Batch 40/64 loss: -4.304837703704834
Batch 41/64 loss: -3.829946994781494
Batch 42/64 loss: -4.161007881164551
Batch 43/64 loss: -4.120062828063965
Batch 44/64 loss: -3.8450193405151367
Batch 45/64 loss: -3.9763755798339844
Batch 46/64 loss: -3.9654273986816406
Batch 47/64 loss: -3.999105453491211
Batch 48/64 loss: -3.958371162414551
Batch 49/64 loss: -4.135733127593994
Batch 50/64 loss: -4.056033134460449
Batch 51/64 loss: -4.010809421539307
Batch 52/64 loss: -4.18673038482666
Batch 53/64 loss: -4.164572238922119
Batch 54/64 loss: -4.180598735809326
Batch 55/64 loss: -4.043210029602051
Batch 56/64 loss: -4.264809608459473
Batch 57/64 loss: -4.102656841278076
Batch 58/64 loss: -4.190546989440918
Batch 59/64 loss: -4.1791462898254395
Batch 60/64 loss: -4.147428512573242
Batch 61/64 loss: -4.21276330947876
Batch 62/64 loss: -3.984379768371582
Batch 63/64 loss: -4.153645992279053
Batch 64/64 loss: -8.643321990966797
Epoch 463  Train loss: -4.11572535645728  Val loss: -4.544716222179714
Epoch 464
-------------------------------
Batch 1/64 loss: -4.057365894317627
Batch 2/64 loss: -4.199918270111084
Batch 3/64 loss: -3.9030799865722656
Batch 4/64 loss: -4.017303466796875
Batch 5/64 loss: -4.133598804473877
Batch 6/64 loss: -4.131693363189697
Batch 7/64 loss: -4.188502788543701
Batch 8/64 loss: -4.2037763595581055
Batch 9/64 loss: -4.028022766113281
Batch 10/64 loss: -3.7645821571350098
Batch 11/64 loss: -4.188167095184326
Batch 12/64 loss: -4.240936756134033
Batch 13/64 loss: -4.1590728759765625
Batch 14/64 loss: -3.940394878387451
Batch 15/64 loss: -4.265012741088867
Batch 16/64 loss: -4.187012195587158
Batch 17/64 loss: -4.0311665534973145
Batch 18/64 loss: -3.7685375213623047
Batch 19/64 loss: -4.099489212036133
Batch 20/64 loss: -3.9940333366394043
Batch 21/64 loss: -3.991642951965332
Batch 22/64 loss: -3.926356792449951
Batch 23/64 loss: -4.141629695892334
Batch 24/64 loss: -4.181990623474121
Batch 25/64 loss: -4.206988334655762
Batch 26/64 loss: -3.9688992500305176
Batch 27/64 loss: -4.144250392913818
Batch 28/64 loss: -4.017177581787109
Batch 29/64 loss: -4.081308364868164
Batch 30/64 loss: -4.114566802978516
Batch 31/64 loss: -4.155129909515381
Batch 32/64 loss: -4.130126953125
Batch 33/64 loss: -4.171435832977295
Batch 34/64 loss: -3.9986014366149902
Batch 35/64 loss: -4.2471818923950195
Batch 36/64 loss: -4.053478717803955
Batch 37/64 loss: -4.139935493469238
Batch 38/64 loss: -4.023085117340088
Batch 39/64 loss: -4.097267150878906
Batch 40/64 loss: -4.140774726867676
Batch 41/64 loss: -4.069849014282227
Batch 42/64 loss: -4.00044584274292
Batch 43/64 loss: -4.244057655334473
Batch 44/64 loss: -4.185730934143066
Batch 45/64 loss: -4.006680488586426
Batch 46/64 loss: -3.896393299102783
Batch 47/64 loss: -4.0824103355407715
Batch 48/64 loss: -4.191702365875244
Batch 49/64 loss: -3.520291328430176
Batch 50/64 loss: -4.167832374572754
Batch 51/64 loss: -4.097963809967041
Batch 52/64 loss: -4.088866233825684
Batch 53/64 loss: -4.015268325805664
Batch 54/64 loss: -3.6914854049682617
Batch 55/64 loss: -4.135356426239014
Batch 56/64 loss: -4.082934856414795
Batch 57/64 loss: -4.203396797180176
Batch 58/64 loss: -4.230405807495117
Batch 59/64 loss: -4.147461414337158
Batch 60/64 loss: -4.1430559158325195
Batch 61/64 loss: -3.928704261779785
Batch 62/64 loss: -4.162592887878418
Batch 63/64 loss: -4.057305335998535
Batch 64/64 loss: -8.570119857788086
Epoch 464  Train loss: -4.1288043302648205  Val loss: -4.564549344511786
Epoch 465
-------------------------------
Batch 1/64 loss: -4.139256954193115
Batch 2/64 loss: -4.178071022033691
Batch 3/64 loss: -4.163708209991455
Batch 4/64 loss: -4.196340560913086
Batch 5/64 loss: -4.082785129547119
Batch 6/64 loss: -4.041500091552734
Batch 7/64 loss: -4.183366298675537
Batch 8/64 loss: -4.1504292488098145
Batch 9/64 loss: -4.119251728057861
Batch 10/64 loss: -4.106873035430908
Batch 11/64 loss: -4.221470355987549
Batch 12/64 loss: -3.986565589904785
Batch 13/64 loss: -4.159265995025635
Batch 14/64 loss: -4.092734336853027
Batch 15/64 loss: -3.8443779945373535
Batch 16/64 loss: -4.1394524574279785
Batch 17/64 loss: -4.248815059661865
Batch 18/64 loss: -4.169346809387207
Batch 19/64 loss: -3.970592975616455
Batch 20/64 loss: -4.293234825134277
Batch 21/64 loss: -4.32373571395874
Batch 22/64 loss: -3.6691575050354004
Batch 23/64 loss: -4.251039028167725
Batch 24/64 loss: -4.12117338180542
Batch 25/64 loss: -4.160149574279785
Batch 26/64 loss: -4.02451229095459
Batch 27/64 loss: -4.067443370819092
Batch 28/64 loss: -4.156296730041504
Batch 29/64 loss: -4.005457401275635
Batch 30/64 loss: -3.8658981323242188
Batch 31/64 loss: -4.267461776733398
Batch 32/64 loss: -4.083795070648193
Batch 33/64 loss: -4.272612571716309
Batch 34/64 loss: -4.158717155456543
Batch 35/64 loss: -4.151869773864746
Batch 36/64 loss: -4.092048645019531
Batch 37/64 loss: -4.148869037628174
Batch 38/64 loss: -4.187404155731201
Batch 39/64 loss: -4.017270088195801
Batch 40/64 loss: -4.051542282104492
Batch 41/64 loss: -4.215395927429199
Batch 42/64 loss: -4.288552284240723
Batch 43/64 loss: -4.276783466339111
Batch 44/64 loss: -4.163575172424316
Batch 45/64 loss: -4.175999164581299
Batch 46/64 loss: -4.233943939208984
Batch 47/64 loss: -3.862532615661621
Batch 48/64 loss: -4.002634525299072
Batch 49/64 loss: -4.297008514404297
Batch 50/64 loss: -4.090628623962402
Batch 51/64 loss: -4.123229503631592
Batch 52/64 loss: -4.236098289489746
Batch 53/64 loss: -4.02339506149292
Batch 54/64 loss: -4.128838539123535
Batch 55/64 loss: -4.034985542297363
Batch 56/64 loss: -4.1493000984191895
Batch 57/64 loss: -4.062296390533447
Batch 58/64 loss: -4.263171672821045
Batch 59/64 loss: -3.8929824829101562
Batch 60/64 loss: -4.001617431640625
Batch 61/64 loss: -3.9793567657470703
Batch 62/64 loss: -4.197550296783447
Batch 63/64 loss: -4.139616966247559
Batch 64/64 loss: -8.57472038269043
Epoch 465  Train loss: -4.169951779234643  Val loss: -4.572328075920184
Epoch 466
-------------------------------
Batch 1/64 loss: -4.130153179168701
Batch 2/64 loss: -3.9807024002075195
Batch 3/64 loss: -4.061975002288818
Batch 4/64 loss: -4.027186870574951
Batch 5/64 loss: -4.023477554321289
Batch 6/64 loss: -3.922595500946045
Batch 7/64 loss: -4.115626811981201
Batch 8/64 loss: -4.156339168548584
Batch 9/64 loss: -4.135158061981201
Batch 10/64 loss: -4.110646724700928
Batch 11/64 loss: -4.133302211761475
Batch 12/64 loss: -4.255826473236084
Batch 13/64 loss: -4.262548446655273
Batch 14/64 loss: -4.1478657722473145
Batch 15/64 loss: -4.153040885925293
Batch 16/64 loss: -3.9988255500793457
Batch 17/64 loss: -4.126183986663818
Batch 18/64 loss: -4.015635967254639
Batch 19/64 loss: -3.9376983642578125
Batch 20/64 loss: -4.008387088775635
Batch 21/64 loss: -4.047774314880371
Batch 22/64 loss: -4.266615390777588
Batch 23/64 loss: -4.256988525390625
Batch 24/64 loss: -3.966243267059326
Batch 25/64 loss: -4.047703742980957
Batch 26/64 loss: -3.8832807540893555
Batch 27/64 loss: -4.210314750671387
Batch 28/64 loss: -4.120553016662598
Batch 29/64 loss: -3.427753448486328
Batch 30/64 loss: -4.044150352478027
Batch 31/64 loss: -3.8964715003967285
Batch 32/64 loss: -4.203084945678711
Batch 33/64 loss: -4.134681701660156
Batch 34/64 loss: -3.9899415969848633
Batch 35/64 loss: -4.041507720947266
Batch 36/64 loss: -4.014132976531982
Batch 37/64 loss: -3.917863368988037
Batch 38/64 loss: -4.060483455657959
Batch 39/64 loss: -4.030711650848389
Batch 40/64 loss: -4.121218681335449
Batch 41/64 loss: -4.2305192947387695
Batch 42/64 loss: -4.11410665512085
Batch 43/64 loss: -3.410449981689453
Batch 44/64 loss: -4.016441822052002
Batch 45/64 loss: -4.1541619300842285
Batch 46/64 loss: -4.011415481567383
Batch 47/64 loss: -3.852853775024414
Batch 48/64 loss: -3.710299015045166
Batch 49/64 loss: -4.200613021850586
Batch 50/64 loss: -4.008880615234375
Batch 51/64 loss: -4.163403511047363
Batch 52/64 loss: -3.7336783409118652
Batch 53/64 loss: -3.9906225204467773
Batch 54/64 loss: -4.021000385284424
Batch 55/64 loss: -4.198774337768555
Batch 56/64 loss: -4.040918350219727
Batch 57/64 loss: -4.1761579513549805
Batch 58/64 loss: -4.088435649871826
Batch 59/64 loss: -4.194764614105225
Batch 60/64 loss: -3.773221492767334
Batch 61/64 loss: -4.015259742736816
Batch 62/64 loss: -4.114620208740234
Batch 63/64 loss: -4.138247013092041
Batch 64/64 loss: -8.743643760681152
Epoch 466  Train loss: -4.098842819064271  Val loss: -4.470176408380987
Epoch 467
-------------------------------
Batch 1/64 loss: -3.9872026443481445
Batch 2/64 loss: -3.850898265838623
Batch 3/64 loss: -4.133047580718994
Batch 4/64 loss: -4.039323806762695
Batch 5/64 loss: -3.865684986114502
Batch 6/64 loss: -3.8755578994750977
Batch 7/64 loss: -4.228604316711426
Batch 8/64 loss: -4.088109493255615
Batch 9/64 loss: -4.121393203735352
Batch 10/64 loss: -4.21476411819458
Batch 11/64 loss: -4.150479316711426
Batch 12/64 loss: -4.139582633972168
Batch 13/64 loss: -3.8817667961120605
Batch 14/64 loss: -3.8534531593322754
Batch 15/64 loss: -4.0278096199035645
Batch 16/64 loss: -4.043453693389893
Batch 17/64 loss: -3.6754183769226074
Batch 18/64 loss: -4.239953994750977
Batch 19/64 loss: -4.089422225952148
Batch 20/64 loss: -4.09326171875
Batch 21/64 loss: -4.3436760902404785
Batch 22/64 loss: -4.2036895751953125
Batch 23/64 loss: -4.168491363525391
Batch 24/64 loss: -4.1238226890563965
Batch 25/64 loss: -4.085341930389404
Batch 26/64 loss: -4.132388591766357
Batch 27/64 loss: -4.107856750488281
Batch 28/64 loss: -4.1377410888671875
Batch 29/64 loss: -4.235137939453125
Batch 30/64 loss: -4.143361568450928
Batch 31/64 loss: -4.1046366691589355
Batch 32/64 loss: -4.087324619293213
Batch 33/64 loss: -4.237706661224365
Batch 34/64 loss: -3.9677062034606934
Batch 35/64 loss: -3.990935802459717
Batch 36/64 loss: -4.152107238769531
Batch 37/64 loss: -4.0211873054504395
Batch 38/64 loss: -3.975991725921631
Batch 39/64 loss: -4.235679626464844
Batch 40/64 loss: -4.2754621505737305
Batch 41/64 loss: -4.215808868408203
Batch 42/64 loss: -4.057100296020508
Batch 43/64 loss: -4.1249165534973145
Batch 44/64 loss: -4.064732074737549
Batch 45/64 loss: -4.022141456604004
Batch 46/64 loss: -4.187292575836182
Batch 47/64 loss: -4.1122026443481445
Batch 48/64 loss: -4.192913055419922
Batch 49/64 loss: -3.835537910461426
Batch 50/64 loss: -4.124927997589111
Batch 51/64 loss: -3.5843052864074707
Batch 52/64 loss: -3.837951183319092
Batch 53/64 loss: -3.9905056953430176
Batch 54/64 loss: -4.205224990844727
Batch 55/64 loss: -4.036588191986084
Batch 56/64 loss: -4.007927417755127
Batch 57/64 loss: -3.890519618988037
Batch 58/64 loss: -4.137878894805908
Batch 59/64 loss: -3.8155465126037598
Batch 60/64 loss: -3.993896007537842
Batch 61/64 loss: -4.05096960067749
Batch 62/64 loss: -4.037055969238281
Batch 63/64 loss: -4.075823783874512
Batch 64/64 loss: -8.588284492492676
Epoch 467  Train loss: -4.115645700342515  Val loss: -4.514710232973918
Epoch 468
-------------------------------
Batch 1/64 loss: -4.212677001953125
Batch 2/64 loss: -3.898139476776123
Batch 3/64 loss: -4.043336391448975
Batch 4/64 loss: -4.134136199951172
Batch 5/64 loss: -4.212783336639404
Batch 6/64 loss: -4.220700740814209
Batch 7/64 loss: -4.240200042724609
Batch 8/64 loss: -4.004989147186279
Batch 9/64 loss: -4.22374963760376
Batch 10/64 loss: -4.177123069763184
Batch 11/64 loss: -3.9964494705200195
Batch 12/64 loss: -4.262844562530518
Batch 13/64 loss: -3.9081430435180664
Batch 14/64 loss: -4.074700355529785
Batch 15/64 loss: -4.100042819976807
Batch 16/64 loss: -4.185056686401367
Batch 17/64 loss: -4.208728790283203
Batch 18/64 loss: -4.151722431182861
Batch 19/64 loss: -4.1357245445251465
Batch 20/64 loss: -4.02379846572876
Batch 21/64 loss: -4.125649452209473
Batch 22/64 loss: -4.1775031089782715
Batch 23/64 loss: -4.170204162597656
Batch 24/64 loss: -4.118886947631836
Batch 25/64 loss: -4.234011650085449
Batch 26/64 loss: -3.8988380432128906
Batch 27/64 loss: -4.066477298736572
Batch 28/64 loss: -3.9875497817993164
Batch 29/64 loss: -4.2866034507751465
Batch 30/64 loss: -4.173561096191406
Batch 31/64 loss: -3.887089729309082
Batch 32/64 loss: -3.9770617485046387
Batch 33/64 loss: -4.038949489593506
Batch 34/64 loss: -4.1561279296875
Batch 35/64 loss: -3.9725542068481445
Batch 36/64 loss: -4.215866565704346
Batch 37/64 loss: -4.204713821411133
Batch 38/64 loss: -4.153040885925293
Batch 39/64 loss: -3.7548179626464844
Batch 40/64 loss: -4.101654052734375
Batch 41/64 loss: -3.913208484649658
Batch 42/64 loss: -4.187063694000244
Batch 43/64 loss: -4.072174549102783
Batch 44/64 loss: -3.9034881591796875
Batch 45/64 loss: -4.137814044952393
Batch 46/64 loss: -4.248700141906738
Batch 47/64 loss: -3.9994606971740723
Batch 48/64 loss: -4.012472152709961
Batch 49/64 loss: -4.000285625457764
Batch 50/64 loss: -4.075390338897705
Batch 51/64 loss: -4.1374101638793945
Batch 52/64 loss: -4.054937839508057
Batch 53/64 loss: -3.5200581550598145
Batch 54/64 loss: -3.981234550476074
Batch 55/64 loss: -4.134115695953369
Batch 56/64 loss: -4.133503437042236
Batch 57/64 loss: -4.1990885734558105
Batch 58/64 loss: -4.139465808868408
Batch 59/64 loss: -4.067287445068359
Batch 60/64 loss: -3.967790126800537
Batch 61/64 loss: -4.1216535568237305
Batch 62/64 loss: -4.1737446784973145
Batch 63/64 loss: -4.024966716766357
Batch 64/64 loss: -8.54959487915039
Epoch 468  Train loss: -4.136999504238951  Val loss: -4.484549099637061
Epoch 469
-------------------------------
Batch 1/64 loss: -4.121827125549316
Batch 2/64 loss: -4.036736965179443
Batch 3/64 loss: -4.0685200691223145
Batch 4/64 loss: -4.167844295501709
Batch 5/64 loss: -4.168916702270508
Batch 6/64 loss: -3.9876155853271484
Batch 7/64 loss: -3.9828968048095703
Batch 8/64 loss: -4.055168151855469
Batch 9/64 loss: -4.090981960296631
Batch 10/64 loss: -4.164980411529541
Batch 11/64 loss: -4.172009468078613
Batch 12/64 loss: -4.048577785491943
Batch 13/64 loss: -4.076035499572754
Batch 14/64 loss: -4.111936569213867
Batch 15/64 loss: -3.928438186645508
Batch 16/64 loss: -3.667809009552002
Batch 17/64 loss: -4.088919162750244
Batch 18/64 loss: -4.108806610107422
Batch 19/64 loss: -4.128810882568359
Batch 20/64 loss: -4.104044437408447
Batch 21/64 loss: -4.170777320861816
Batch 22/64 loss: -4.185421943664551
Batch 23/64 loss: -4.217787265777588
Batch 24/64 loss: -4.182295322418213
Batch 25/64 loss: -4.133199214935303
Batch 26/64 loss: -4.1066694259643555
Batch 27/64 loss: -3.943513870239258
Batch 28/64 loss: -4.034239292144775
Batch 29/64 loss: -4.1031880378723145
Batch 30/64 loss: -3.963583469390869
Batch 31/64 loss: -4.163426399230957
Batch 32/64 loss: -4.306726455688477
Batch 33/64 loss: -4.327506065368652
Batch 34/64 loss: -4.2642621994018555
Batch 35/64 loss: -4.078279495239258
Batch 36/64 loss: -3.940906047821045
Batch 37/64 loss: -4.200995445251465
Batch 38/64 loss: -3.965641498565674
Batch 39/64 loss: -3.8260741233825684
Batch 40/64 loss: -4.342488765716553
Batch 41/64 loss: -3.7009706497192383
Batch 42/64 loss: -4.0168938636779785
Batch 43/64 loss: -4.108364582061768
Batch 44/64 loss: -4.046116352081299
Batch 45/64 loss: -3.503775119781494
Batch 46/64 loss: -3.8865208625793457
Batch 47/64 loss: -4.121530055999756
Batch 48/64 loss: -4.028563499450684
Batch 49/64 loss: -4.079586982727051
Batch 50/64 loss: -3.841017723083496
Batch 51/64 loss: -4.209012985229492
Batch 52/64 loss: -4.201720237731934
Batch 53/64 loss: -4.1674699783325195
Batch 54/64 loss: -3.866848945617676
Batch 55/64 loss: -4.1169819831848145
Batch 56/64 loss: -4.23225736618042
Batch 57/64 loss: -4.274591445922852
Batch 58/64 loss: -4.030364036560059
Batch 59/64 loss: -4.239638805389404
Batch 60/64 loss: -3.984135627746582
Batch 61/64 loss: -3.977193832397461
Batch 62/64 loss: -3.9273557662963867
Batch 63/64 loss: -4.158640384674072
Batch 64/64 loss: -8.631745338439941
Epoch 469  Train loss: -4.124411253835641  Val loss: -4.41987831404119
Epoch 470
-------------------------------
Batch 1/64 loss: -4.0383734703063965
Batch 2/64 loss: -4.072067737579346
Batch 3/64 loss: -4.082061290740967
Batch 4/64 loss: -4.071560859680176
Batch 5/64 loss: -4.006658554077148
Batch 6/64 loss: -4.154756546020508
Batch 7/64 loss: -4.229555606842041
Batch 8/64 loss: -4.003583908081055
Batch 9/64 loss: -4.167985916137695
Batch 10/64 loss: -4.021274089813232
Batch 11/64 loss: -4.209259510040283
Batch 12/64 loss: -4.157039642333984
Batch 13/64 loss: -4.106937885284424
Batch 14/64 loss: -4.0787811279296875
Batch 15/64 loss: -4.0319414138793945
Batch 16/64 loss: -4.320785999298096
Batch 17/64 loss: -4.194862365722656
Batch 18/64 loss: -3.8538918495178223
Batch 19/64 loss: -4.121105670928955
Batch 20/64 loss: -3.686333656311035
Batch 21/64 loss: -3.8656420707702637
Batch 22/64 loss: -3.896976947784424
Batch 23/64 loss: -4.139238357543945
Batch 24/64 loss: -3.8659048080444336
Batch 25/64 loss: -4.041292190551758
Batch 26/64 loss: -4.12278938293457
Batch 27/64 loss: -4.114792346954346
Batch 28/64 loss: -4.057239532470703
Batch 29/64 loss: -4.1485748291015625
Batch 30/64 loss: -4.27142858505249
Batch 31/64 loss: -3.8776283264160156
Batch 32/64 loss: -4.047614574432373
Batch 33/64 loss: -4.218961238861084
Batch 34/64 loss: -4.156883239746094
Batch 35/64 loss: -3.9039340019226074
Batch 36/64 loss: -4.199583530426025
Batch 37/64 loss: -4.2563700675964355
Batch 38/64 loss: -4.116164207458496
Batch 39/64 loss: -4.211507797241211
Batch 40/64 loss: -4.0074992179870605
Batch 41/64 loss: -3.9956727027893066
Batch 42/64 loss: -3.9520087242126465
Batch 43/64 loss: -4.180582523345947
Batch 44/64 loss: -4.086545467376709
Batch 45/64 loss: -4.250973224639893
Batch 46/64 loss: -4.232685089111328
Batch 47/64 loss: -4.058964252471924
Batch 48/64 loss: -4.180272579193115
Batch 49/64 loss: -4.136771202087402
Batch 50/64 loss: -4.2344255447387695
Batch 51/64 loss: -4.227136611938477
Batch 52/64 loss: -3.895702838897705
Batch 53/64 loss: -4.195796012878418
Batch 54/64 loss: -3.9774937629699707
Batch 55/64 loss: -4.008593559265137
Batch 56/64 loss: -4.188096523284912
Batch 57/64 loss: -4.279496192932129
Batch 58/64 loss: -4.1463704109191895
Batch 59/64 loss: -4.179384231567383
Batch 60/64 loss: -4.223447799682617
Batch 61/64 loss: -3.655789852142334
Batch 62/64 loss: -4.075545787811279
Batch 63/64 loss: -4.079960346221924
Batch 64/64 loss: -8.479942321777344
Epoch 470  Train loss: -4.140086499382468  Val loss: -4.552248374703004
Epoch 471
-------------------------------
Batch 1/64 loss: -4.129800319671631
Batch 2/64 loss: -4.2388129234313965
Batch 3/64 loss: -3.8798623085021973
Batch 4/64 loss: -4.050125598907471
Batch 5/64 loss: -4.230539798736572
Batch 6/64 loss: -4.144879341125488
Batch 7/64 loss: -4.198646068572998
Batch 8/64 loss: -4.373954772949219
Batch 9/64 loss: -4.127758979797363
Batch 10/64 loss: -4.301047325134277
Batch 11/64 loss: -3.977267265319824
Batch 12/64 loss: -4.11876106262207
Batch 13/64 loss: -4.186686992645264
Batch 14/64 loss: -4.086880207061768
Batch 15/64 loss: -4.031516075134277
Batch 16/64 loss: -4.120726585388184
Batch 17/64 loss: -4.117485046386719
Batch 18/64 loss: -4.125546932220459
Batch 19/64 loss: -4.036462306976318
Batch 20/64 loss: -4.169534683227539
Batch 21/64 loss: -4.1626691818237305
Batch 22/64 loss: -4.200362205505371
Batch 23/64 loss: -3.992736339569092
Batch 24/64 loss: -4.173480987548828
Batch 25/64 loss: -4.114429473876953
Batch 26/64 loss: -4.105672359466553
Batch 27/64 loss: -3.850534439086914
Batch 28/64 loss: -4.106473922729492
Batch 29/64 loss: -4.1868062019348145
Batch 30/64 loss: -4.001710414886475
Batch 31/64 loss: -3.9331440925598145
Batch 32/64 loss: -4.110065460205078
Batch 33/64 loss: -4.267547130584717
Batch 34/64 loss: -3.8159232139587402
Batch 35/64 loss: -3.9752230644226074
Batch 36/64 loss: -4.176939010620117
Batch 37/64 loss: -4.169466018676758
Batch 38/64 loss: -3.700500011444092
Batch 39/64 loss: -4.0207109451293945
Batch 40/64 loss: -4.020450115203857
Batch 41/64 loss: -4.237476825714111
Batch 42/64 loss: -4.17396879196167
Batch 43/64 loss: -3.5863962173461914
Batch 44/64 loss: -4.182756423950195
Batch 45/64 loss: -4.099093437194824
Batch 46/64 loss: -3.925844192504883
Batch 47/64 loss: -4.084813594818115
Batch 48/64 loss: -4.160902500152588
Batch 49/64 loss: -4.091297149658203
Batch 50/64 loss: -4.244877338409424
Batch 51/64 loss: -3.975924491882324
Batch 52/64 loss: -4.307265758514404
Batch 53/64 loss: -4.015872001647949
Batch 54/64 loss: -4.070586204528809
Batch 55/64 loss: -4.08716344833374
Batch 56/64 loss: -4.1859917640686035
Batch 57/64 loss: -4.1290364265441895
Batch 58/64 loss: -4.30360221862793
Batch 59/64 loss: -4.194892406463623
Batch 60/64 loss: -3.988368034362793
Batch 61/64 loss: -4.105865955352783
Batch 62/64 loss: -4.14384651184082
Batch 63/64 loss: -4.223648548126221
Batch 64/64 loss: -8.673490524291992
Epoch 471  Train loss: -4.153031330482633  Val loss: -4.594918306750531
Epoch 472
-------------------------------
Batch 1/64 loss: -4.134687423706055
Batch 2/64 loss: -4.143625259399414
Batch 3/64 loss: -4.125946044921875
Batch 4/64 loss: -4.3127522468566895
Batch 5/64 loss: -3.8507871627807617
Batch 6/64 loss: -4.254537582397461
Batch 7/64 loss: -4.153404712677002
Batch 8/64 loss: -4.258268356323242
Batch 9/64 loss: -4.083303928375244
Batch 10/64 loss: -4.276580810546875
Batch 11/64 loss: -4.299385070800781
Batch 12/64 loss: -3.943978786468506
Batch 13/64 loss: -4.213183879852295
Batch 14/64 loss: -4.236400127410889
Batch 15/64 loss: -4.215230464935303
Batch 16/64 loss: -4.2568817138671875
Batch 17/64 loss: -4.137302875518799
Batch 18/64 loss: -4.347594738006592
Batch 19/64 loss: -4.15921688079834
Batch 20/64 loss: -4.372164249420166
Batch 21/64 loss: -4.372995853424072
Batch 22/64 loss: -4.326376914978027
Batch 23/64 loss: -4.125697135925293
Batch 24/64 loss: -3.8212718963623047
Batch 25/64 loss: -3.9487133026123047
Batch 26/64 loss: -4.060705661773682
Batch 27/64 loss: -4.203371524810791
Batch 28/64 loss: -4.201000213623047
Batch 29/64 loss: -4.255393028259277
Batch 30/64 loss: -4.163206577301025
Batch 31/64 loss: -4.082137584686279
Batch 32/64 loss: -3.933163642883301
Batch 33/64 loss: -4.195866584777832
Batch 34/64 loss: -4.224512100219727
Batch 35/64 loss: -4.030385494232178
Batch 36/64 loss: -4.293118953704834
Batch 37/64 loss: -4.152464389801025
Batch 38/64 loss: -4.279128074645996
Batch 39/64 loss: -4.266658306121826
Batch 40/64 loss: -4.107108116149902
Batch 41/64 loss: -4.224621295928955
Batch 42/64 loss: -4.073097229003906
Batch 43/64 loss: -4.298785209655762
Batch 44/64 loss: -4.285659313201904
Batch 45/64 loss: -4.271859645843506
Batch 46/64 loss: -4.139663219451904
Batch 47/64 loss: -4.109675884246826
Batch 48/64 loss: -4.269908905029297
Batch 49/64 loss: -4.064393520355225
Batch 50/64 loss: -4.0023884773254395
Batch 51/64 loss: -4.2877397537231445
Batch 52/64 loss: -4.11229944229126
Batch 53/64 loss: -4.323668956756592
Batch 54/64 loss: -4.186439514160156
Batch 55/64 loss: -4.1029558181762695
Batch 56/64 loss: -4.208910942077637
Batch 57/64 loss: -4.090884685516357
Batch 58/64 loss: -4.0799407958984375
Batch 59/64 loss: -4.226771354675293
Batch 60/64 loss: -4.190239906311035
Batch 61/64 loss: -4.401169300079346
Batch 62/64 loss: -4.1780500411987305
Batch 63/64 loss: -3.828691005706787
Batch 64/64 loss: -8.569852828979492
Epoch 472  Train loss: -4.222803317799288  Val loss: -4.636795791154055
Saving best model, epoch: 472
Epoch 473
-------------------------------
Batch 1/64 loss: -4.159299373626709
Batch 2/64 loss: -4.290299415588379
Batch 3/64 loss: -4.298983573913574
Batch 4/64 loss: -4.1555609703063965
Batch 5/64 loss: -4.273177623748779
Batch 6/64 loss: -4.043147087097168
Batch 7/64 loss: -4.291141033172607
Batch 8/64 loss: -4.037242889404297
Batch 9/64 loss: -4.201836109161377
Batch 10/64 loss: -4.079105854034424
Batch 11/64 loss: -4.181981086730957
Batch 12/64 loss: -4.208347320556641
Batch 13/64 loss: -4.1855292320251465
Batch 14/64 loss: -4.289674282073975
Batch 15/64 loss: -4.362922668457031
Batch 16/64 loss: -4.31779670715332
Batch 17/64 loss: -4.254981517791748
Batch 18/64 loss: -4.223423480987549
Batch 19/64 loss: -3.9340295791625977
Batch 20/64 loss: -3.9563851356506348
Batch 21/64 loss: -4.359595775604248
Batch 22/64 loss: -4.2137885093688965
Batch 23/64 loss: -4.285167694091797
Batch 24/64 loss: -4.15079402923584
Batch 25/64 loss: -3.9215550422668457
Batch 26/64 loss: -4.264552593231201
Batch 27/64 loss: -4.242636680603027
Batch 28/64 loss: -3.8518776893615723
Batch 29/64 loss: -4.191798686981201
Batch 30/64 loss: -4.149636268615723
Batch 31/64 loss: -4.071276664733887
Batch 32/64 loss: -3.9358153343200684
Batch 33/64 loss: -4.257691383361816
Batch 34/64 loss: -3.9910154342651367
Batch 35/64 loss: -4.2760009765625
Batch 36/64 loss: -4.091699600219727
Batch 37/64 loss: -3.8617734909057617
Batch 38/64 loss: -4.216418743133545
Batch 39/64 loss: -4.18287467956543
Batch 40/64 loss: -4.119453430175781
Batch 41/64 loss: -3.8418521881103516
Batch 42/64 loss: -3.9993133544921875
Batch 43/64 loss: -4.182258605957031
Batch 44/64 loss: -4.11824893951416
Batch 45/64 loss: -4.334414482116699
Batch 46/64 loss: -3.9548377990722656
Batch 47/64 loss: -4.1151204109191895
Batch 48/64 loss: -4.264247417449951
Batch 49/64 loss: -4.005069255828857
Batch 50/64 loss: -4.150949478149414
Batch 51/64 loss: -4.106228828430176
Batch 52/64 loss: -4.135902404785156
Batch 53/64 loss: -4.109181880950928
Batch 54/64 loss: -4.149704456329346
Batch 55/64 loss: -4.017123699188232
Batch 56/64 loss: -4.322049617767334
Batch 57/64 loss: -3.9162511825561523
Batch 58/64 loss: -4.221240520477295
Batch 59/64 loss: -4.182714462280273
Batch 60/64 loss: -4.094636917114258
Batch 61/64 loss: -4.204784393310547
Batch 62/64 loss: -4.082683086395264
Batch 63/64 loss: -4.253228187561035
Batch 64/64 loss: -8.675514221191406
Epoch 473  Train loss: -4.198415135402305  Val loss: -4.6356894634023975
Epoch 474
-------------------------------
Batch 1/64 loss: -4.244640350341797
Batch 2/64 loss: -4.071475028991699
Batch 3/64 loss: -4.052320957183838
Batch 4/64 loss: -4.2876505851745605
Batch 5/64 loss: -4.109504699707031
Batch 6/64 loss: -4.01167631149292
Batch 7/64 loss: -4.182546615600586
Batch 8/64 loss: -4.110350608825684
Batch 9/64 loss: -4.223170757293701
Batch 10/64 loss: -4.083820343017578
Batch 11/64 loss: -4.272465229034424
Batch 12/64 loss: -4.287556171417236
Batch 13/64 loss: -4.149703502655029
Batch 14/64 loss: -4.234803199768066
Batch 15/64 loss: -4.290345191955566
Batch 16/64 loss: -3.9199018478393555
Batch 17/64 loss: -3.9738616943359375
Batch 18/64 loss: -4.11161994934082
Batch 19/64 loss: -4.260148048400879
Batch 20/64 loss: -4.315718173980713
Batch 21/64 loss: -4.24639892578125
Batch 22/64 loss: -4.2849016189575195
Batch 23/64 loss: -4.105552673339844
Batch 24/64 loss: -4.240334510803223
Batch 25/64 loss: -4.065204620361328
Batch 26/64 loss: -4.25156831741333
Batch 27/64 loss: -3.9451513290405273
Batch 28/64 loss: -4.0257062911987305
Batch 29/64 loss: -4.259469985961914
Batch 30/64 loss: -4.066172122955322
Batch 31/64 loss: -4.374608993530273
Batch 32/64 loss: -4.341474533081055
Batch 33/64 loss: -4.359523773193359
Batch 34/64 loss: -4.025801658630371
Batch 35/64 loss: -4.107727527618408
Batch 36/64 loss: -4.0663652420043945
Batch 37/64 loss: -4.295834541320801
Batch 38/64 loss: -3.7304153442382812
Batch 39/64 loss: -4.143764972686768
Batch 40/64 loss: -4.263839244842529
Batch 41/64 loss: -4.268221855163574
Batch 42/64 loss: -4.354935169219971
Batch 43/64 loss: -4.232279300689697
Batch 44/64 loss: -4.195589065551758
Batch 45/64 loss: -4.237696170806885
Batch 46/64 loss: -4.2501983642578125
Batch 47/64 loss: -4.250769138336182
Batch 48/64 loss: -4.168065071105957
Batch 49/64 loss: -4.38778829574585
Batch 50/64 loss: -4.1551055908203125
Batch 51/64 loss: -4.308755874633789
Batch 52/64 loss: -4.20721435546875
Batch 53/64 loss: -4.153194904327393
Batch 54/64 loss: -4.194029808044434
Batch 55/64 loss: -4.042559623718262
Batch 56/64 loss: -4.3224873542785645
Batch 57/64 loss: -4.2521233558654785
Batch 58/64 loss: -4.254739284515381
Batch 59/64 loss: -4.056281566619873
Batch 60/64 loss: -4.219054698944092
Batch 61/64 loss: -4.20659065246582
Batch 62/64 loss: -4.085055351257324
Batch 63/64 loss: -4.156236171722412
Batch 64/64 loss: -8.777917861938477
Epoch 474  Train loss: -4.234282430013021  Val loss: -4.65720509008034
Saving best model, epoch: 474
Epoch 475
-------------------------------
Batch 1/64 loss: -4.149758815765381
Batch 2/64 loss: -4.247323036193848
Batch 3/64 loss: -4.062333583831787
Batch 4/64 loss: -4.202340126037598
Batch 5/64 loss: -4.181906223297119
Batch 6/64 loss: -4.133421421051025
Batch 7/64 loss: -4.097743988037109
Batch 8/64 loss: -4.2328009605407715
Batch 9/64 loss: -4.165624141693115
Batch 10/64 loss: -4.102184772491455
Batch 11/64 loss: -4.086794853210449
Batch 12/64 loss: -3.631547451019287
Batch 13/64 loss: -4.228000164031982
Batch 14/64 loss: -4.087582588195801
Batch 15/64 loss: -4.318150043487549
Batch 16/64 loss: -4.173175811767578
Batch 17/64 loss: -4.280250549316406
Batch 18/64 loss: -4.244242191314697
Batch 19/64 loss: -4.275227069854736
Batch 20/64 loss: -4.274059295654297
Batch 21/64 loss: -4.253695011138916
Batch 22/64 loss: -4.078974723815918
Batch 23/64 loss: -4.187138080596924
Batch 24/64 loss: -4.193464756011963
Batch 25/64 loss: -3.9502720832824707
Batch 26/64 loss: -4.129835605621338
Batch 27/64 loss: -3.9223947525024414
Batch 28/64 loss: -4.294209003448486
Batch 29/64 loss: -4.2855072021484375
Batch 30/64 loss: -4.221694469451904
Batch 31/64 loss: -4.103067398071289
Batch 32/64 loss: -4.270116806030273
Batch 33/64 loss: -4.231045722961426
Batch 34/64 loss: -4.2970733642578125
Batch 35/64 loss: -4.1244378089904785
Batch 36/64 loss: -4.22131872177124
Batch 37/64 loss: -4.00042200088501
Batch 38/64 loss: -4.349211692810059
Batch 39/64 loss: -4.1404643058776855
Batch 40/64 loss: -4.253878116607666
Batch 41/64 loss: -3.7941651344299316
Batch 42/64 loss: -4.330502033233643
Batch 43/64 loss: -4.171132564544678
Batch 44/64 loss: -4.283588886260986
Batch 45/64 loss: -4.424798011779785
Batch 46/64 loss: -4.312027931213379
Batch 47/64 loss: -4.254006862640381
Batch 48/64 loss: -4.3265228271484375
Batch 49/64 loss: -4.222570419311523
Batch 50/64 loss: -4.2962565422058105
Batch 51/64 loss: -4.113516330718994
Batch 52/64 loss: -4.299975872039795
Batch 53/64 loss: -4.322231769561768
Batch 54/64 loss: -4.048793792724609
Batch 55/64 loss: -4.088308811187744
Batch 56/64 loss: -4.27669095993042
Batch 57/64 loss: -4.206700801849365
Batch 58/64 loss: -4.338629722595215
Batch 59/64 loss: -4.107207298278809
Batch 60/64 loss: -4.205534934997559
Batch 61/64 loss: -4.060727119445801
Batch 62/64 loss: -4.130390167236328
Batch 63/64 loss: -4.260703086853027
Batch 64/64 loss: -8.826390266418457
Epoch 475  Train loss: -4.2380778555776555  Val loss: -4.49502352422865
Epoch 476
-------------------------------
Batch 1/64 loss: -4.237525463104248
Batch 2/64 loss: -4.068603992462158
Batch 3/64 loss: -3.96273136138916
Batch 4/64 loss: -3.9145541191101074
Batch 5/64 loss: -4.207487106323242
Batch 6/64 loss: -4.019983768463135
Batch 7/64 loss: -4.042980194091797
Batch 8/64 loss: -3.9508557319641113
Batch 9/64 loss: -4.16536283493042
Batch 10/64 loss: -4.1627116203308105
Batch 11/64 loss: -3.8342409133911133
Batch 12/64 loss: -3.7240123748779297
Batch 13/64 loss: -4.072054862976074
Batch 14/64 loss: -3.9594836235046387
Batch 15/64 loss: -4.12445592880249
Batch 16/64 loss: -3.8907151222229004
Batch 17/64 loss: -3.9956812858581543
Batch 18/64 loss: -4.134522914886475
Batch 19/64 loss: -4.005350589752197
Batch 20/64 loss: -3.8044071197509766
Batch 21/64 loss: -3.905386447906494
Batch 22/64 loss: -3.969010353088379
Batch 23/64 loss: -4.007104873657227
Batch 24/64 loss: -4.0558390617370605
Batch 25/64 loss: -4.020168781280518
Batch 26/64 loss: -4.071932792663574
Batch 27/64 loss: -3.8314504623413086
Batch 28/64 loss: -3.6114020347595215
Batch 29/64 loss: -3.501467704772949
Batch 30/64 loss: -4.052759647369385
Batch 31/64 loss: -4.156948089599609
Batch 32/64 loss: -3.9436912536621094
Batch 33/64 loss: -3.9196248054504395
Batch 34/64 loss: -4.054355621337891
Batch 35/64 loss: -4.170210361480713
Batch 36/64 loss: -3.9750328063964844
Batch 37/64 loss: -3.8164291381835938
Batch 38/64 loss: -4.179884910583496
Batch 39/64 loss: -4.170383930206299
Batch 40/64 loss: -4.044436454772949
Batch 41/64 loss: -3.989595413208008
Batch 42/64 loss: -4.326217174530029
Batch 43/64 loss: -4.123962879180908
Batch 44/64 loss: -4.090262413024902
Batch 45/64 loss: -3.8058619499206543
Batch 46/64 loss: -4.0648393630981445
Batch 47/64 loss: -4.144455909729004
Batch 48/64 loss: -4.194681644439697
Batch 49/64 loss: -4.271754741668701
Batch 50/64 loss: -4.1691999435424805
Batch 51/64 loss: -4.037715435028076
Batch 52/64 loss: -4.135836601257324
Batch 53/64 loss: -4.1011128425598145
Batch 54/64 loss: -4.008087158203125
Batch 55/64 loss: -4.140084743499756
Batch 56/64 loss: -4.193843841552734
Batch 57/64 loss: -3.930642604827881
Batch 58/64 loss: -4.163600444793701
Batch 59/64 loss: -4.00114107131958
Batch 60/64 loss: -4.003235816955566
Batch 61/64 loss: -3.961655616760254
Batch 62/64 loss: -4.015337944030762
Batch 63/64 loss: -4.074225425720215
Batch 64/64 loss: -8.610921859741211
Epoch 476  Train loss: -4.080639730715284  Val loss: -4.544224571935909
Epoch 477
-------------------------------
Batch 1/64 loss: -4.237441539764404
Batch 2/64 loss: -3.677198886871338
Batch 3/64 loss: -4.211155891418457
Batch 4/64 loss: -4.161375045776367
Batch 5/64 loss: -4.083406925201416
Batch 6/64 loss: -3.9592714309692383
Batch 7/64 loss: -4.155925273895264
Batch 8/64 loss: -4.122359275817871
Batch 9/64 loss: -4.204665184020996
Batch 10/64 loss: -3.966505527496338
Batch 11/64 loss: -3.9948601722717285
Batch 12/64 loss: -4.11077356338501
Batch 13/64 loss: -4.0710625648498535
Batch 14/64 loss: -4.103756427764893
Batch 15/64 loss: -4.060186862945557
Batch 16/64 loss: -4.200897216796875
Batch 17/64 loss: -4.282520294189453
Batch 18/64 loss: -4.164715766906738
Batch 19/64 loss: -3.9602599143981934
Batch 20/64 loss: -4.266289234161377
Batch 21/64 loss: -4.258188724517822
Batch 22/64 loss: -4.240221977233887
Batch 23/64 loss: -4.040638446807861
Batch 24/64 loss: -4.2929887771606445
Batch 25/64 loss: -3.6803131103515625
Batch 26/64 loss: -4.063930034637451
Batch 27/64 loss: -4.15803861618042
Batch 28/64 loss: -4.313950061798096
Batch 29/64 loss: -4.18076229095459
Batch 30/64 loss: -4.142153263092041
Batch 31/64 loss: -4.307012557983398
Batch 32/64 loss: -4.227916717529297
Batch 33/64 loss: -4.210081577301025
Batch 34/64 loss: -4.096869945526123
Batch 35/64 loss: -4.203521728515625
Batch 36/64 loss: -4.24266242980957
Batch 37/64 loss: -4.131417274475098
Batch 38/64 loss: -4.25305700302124
Batch 39/64 loss: -3.8794493675231934
Batch 40/64 loss: -4.058581829071045
Batch 41/64 loss: -4.203598499298096
Batch 42/64 loss: -4.197555065155029
Batch 43/64 loss: -4.203668594360352
Batch 44/64 loss: -4.247884750366211
Batch 45/64 loss: -4.116535663604736
Batch 46/64 loss: -4.179616451263428
Batch 47/64 loss: -4.1418681144714355
Batch 48/64 loss: -4.235721588134766
Batch 49/64 loss: -4.085819721221924
Batch 50/64 loss: -4.0639190673828125
Batch 51/64 loss: -4.147106647491455
Batch 52/64 loss: -4.095010280609131
Batch 53/64 loss: -4.188868522644043
Batch 54/64 loss: -4.144994258880615
Batch 55/64 loss: -3.8784327507019043
Batch 56/64 loss: -4.150777816772461
Batch 57/64 loss: -4.1547532081604
Batch 58/64 loss: -3.977508544921875
Batch 59/64 loss: -3.920638084411621
Batch 60/64 loss: -4.003263473510742
Batch 61/64 loss: -4.119100093841553
Batch 62/64 loss: -4.055577278137207
Batch 63/64 loss: -4.140005111694336
Batch 64/64 loss: -8.608443260192871
Epoch 477  Train loss: -4.173881392385446  Val loss: -4.543535658584018
Epoch 478
-------------------------------
Batch 1/64 loss: -4.378777980804443
Batch 2/64 loss: -4.1604084968566895
Batch 3/64 loss: -4.2018513679504395
Batch 4/64 loss: -4.226767063140869
Batch 5/64 loss: -4.114901542663574
Batch 6/64 loss: -3.7171950340270996
Batch 7/64 loss: -4.0609517097473145
Batch 8/64 loss: -4.007627964019775
Batch 9/64 loss: -4.029159069061279
Batch 10/64 loss: -4.375060558319092
Batch 11/64 loss: -4.019436359405518
Batch 12/64 loss: -4.181303024291992
Batch 13/64 loss: -4.226552486419678
Batch 14/64 loss: -4.250480651855469
Batch 15/64 loss: -4.139664649963379
Batch 16/64 loss: -4.161349296569824
Batch 17/64 loss: -4.261178016662598
Batch 18/64 loss: -4.219773769378662
Batch 19/64 loss: -4.214184284210205
Batch 20/64 loss: -4.208148002624512
Batch 21/64 loss: -4.224339008331299
Batch 22/64 loss: -4.208024024963379
Batch 23/64 loss: -4.163730621337891
Batch 24/64 loss: -4.258129596710205
Batch 25/64 loss: -4.271343231201172
Batch 26/64 loss: -4.222980976104736
Batch 27/64 loss: -4.218299865722656
Batch 28/64 loss: -4.214545249938965
Batch 29/64 loss: -4.247838020324707
Batch 30/64 loss: -4.20884370803833
Batch 31/64 loss: -4.208365440368652
Batch 32/64 loss: -4.032760143280029
Batch 33/64 loss: -4.040727615356445
Batch 34/64 loss: -4.088780879974365
Batch 35/64 loss: -4.289046764373779
Batch 36/64 loss: -4.12463903427124
Batch 37/64 loss: -4.187447547912598
Batch 38/64 loss: -4.1411824226379395
Batch 39/64 loss: -4.267871379852295
Batch 40/64 loss: -4.035470008850098
Batch 41/64 loss: -4.095347881317139
Batch 42/64 loss: -4.15933895111084
Batch 43/64 loss: -4.060705184936523
Batch 44/64 loss: -4.114209175109863
Batch 45/64 loss: -3.993551254272461
Batch 46/64 loss: -4.174908638000488
Batch 47/64 loss: -4.177252769470215
Batch 48/64 loss: -4.218239784240723
Batch 49/64 loss: -4.126054763793945
Batch 50/64 loss: -4.2777485847473145
Batch 51/64 loss: -3.9022841453552246
Batch 52/64 loss: -4.221444606781006
Batch 53/64 loss: -3.8353967666625977
Batch 54/64 loss: -4.095712184906006
Batch 55/64 loss: -4.2911176681518555
Batch 56/64 loss: -4.019536018371582
Batch 57/64 loss: -3.9086689949035645
Batch 58/64 loss: -4.184629440307617
Batch 59/64 loss: -4.039216995239258
Batch 60/64 loss: -4.177064418792725
Batch 61/64 loss: -4.347872257232666
Batch 62/64 loss: -3.921261787414551
Batch 63/64 loss: -4.135341644287109
Batch 64/64 loss: -8.607501983642578
Epoch 478  Train loss: -4.199869290520163  Val loss: -4.59848633336857
Epoch 479
-------------------------------
Batch 1/64 loss: -4.0911545753479
Batch 2/64 loss: -4.148329734802246
Batch 3/64 loss: -4.2891154289245605
Batch 4/64 loss: -4.086767673492432
Batch 5/64 loss: -4.146894454956055
Batch 6/64 loss: -4.18221378326416
Batch 7/64 loss: -4.137027740478516
Batch 8/64 loss: -4.196737289428711
Batch 9/64 loss: -4.175196647644043
Batch 10/64 loss: -4.21185302734375
Batch 11/64 loss: -4.137630462646484
Batch 12/64 loss: -4.043540000915527
Batch 13/64 loss: -3.9897470474243164
Batch 14/64 loss: -4.124334335327148
Batch 15/64 loss: -4.393586158752441
Batch 16/64 loss: -4.17177677154541
Batch 17/64 loss: -4.2112717628479
Batch 18/64 loss: -4.221648693084717
Batch 19/64 loss: -4.185980319976807
Batch 20/64 loss: -4.331748962402344
Batch 21/64 loss: -4.282580852508545
Batch 22/64 loss: -4.251320838928223
Batch 23/64 loss: -4.16424560546875
Batch 24/64 loss: -4.202116966247559
Batch 25/64 loss: -4.083019256591797
Batch 26/64 loss: -4.19517183303833
Batch 27/64 loss: -4.081921100616455
Batch 28/64 loss: -4.128840446472168
Batch 29/64 loss: -4.104528427124023
Batch 30/64 loss: -3.9787850379943848
Batch 31/64 loss: -4.067559242248535
Batch 32/64 loss: -4.251817226409912
Batch 33/64 loss: -4.240561008453369
Batch 34/64 loss: -4.052830219268799
Batch 35/64 loss: -4.162104606628418
Batch 36/64 loss: -4.062919616699219
Batch 37/64 loss: -4.185588836669922
Batch 38/64 loss: -4.116879463195801
Batch 39/64 loss: -4.197010040283203
Batch 40/64 loss: -4.132114410400391
Batch 41/64 loss: -4.016391754150391
Batch 42/64 loss: -4.298910140991211
Batch 43/64 loss: -4.263018608093262
Batch 44/64 loss: -4.293198108673096
Batch 45/64 loss: -4.171831130981445
Batch 46/64 loss: -3.9340500831604004
Batch 47/64 loss: -4.137724876403809
Batch 48/64 loss: -4.076401233673096
Batch 49/64 loss: -4.267683506011963
Batch 50/64 loss: -4.230340957641602
Batch 51/64 loss: -3.710782051086426
Batch 52/64 loss: -4.129065990447998
Batch 53/64 loss: -4.043529987335205
Batch 54/64 loss: -3.824077606201172
Batch 55/64 loss: -3.9989986419677734
Batch 56/64 loss: -4.122021198272705
Batch 57/64 loss: -4.283795356750488
Batch 58/64 loss: -4.291296482086182
Batch 59/64 loss: -4.241015434265137
Batch 60/64 loss: -4.1154961585998535
Batch 61/64 loss: -4.194216728210449
Batch 62/64 loss: -4.273041725158691
Batch 63/64 loss: -4.325532913208008
Batch 64/64 loss: -8.763333320617676
Epoch 479  Train loss: -4.207582597171559  Val loss: -4.61747142621332
Epoch 480
-------------------------------
Batch 1/64 loss: -4.305712699890137
Batch 2/64 loss: -4.255864143371582
Batch 3/64 loss: -4.145622253417969
Batch 4/64 loss: -4.206575870513916
Batch 5/64 loss: -4.362714767456055
Batch 6/64 loss: -4.066446781158447
Batch 7/64 loss: -4.036909103393555
Batch 8/64 loss: -4.14593505859375
Batch 9/64 loss: -4.171081066131592
Batch 10/64 loss: -3.6890316009521484
Batch 11/64 loss: -4.1039814949035645
Batch 12/64 loss: -4.281274318695068
Batch 13/64 loss: -4.307581424713135
Batch 14/64 loss: -4.19756555557251
Batch 15/64 loss: -4.233830451965332
Batch 16/64 loss: -4.3087263107299805
Batch 17/64 loss: -4.128609657287598
Batch 18/64 loss: -4.093594074249268
Batch 19/64 loss: -4.1212310791015625
Batch 20/64 loss: -4.184651851654053
Batch 21/64 loss: -4.026017665863037
Batch 22/64 loss: -4.364710807800293
Batch 23/64 loss: -4.218193054199219
Batch 24/64 loss: -4.247443199157715
Batch 25/64 loss: -4.213017463684082
Batch 26/64 loss: -4.259458065032959
Batch 27/64 loss: -3.842395782470703
Batch 28/64 loss: -4.2617268562316895
Batch 29/64 loss: -4.181230545043945
Batch 30/64 loss: -3.5987181663513184
Batch 31/64 loss: -4.194262981414795
Batch 32/64 loss: -4.296537399291992
Batch 33/64 loss: -4.157785415649414
Batch 34/64 loss: -4.355850696563721
Batch 35/64 loss: -4.162546634674072
Batch 36/64 loss: -4.1499505043029785
Batch 37/64 loss: -4.3540568351745605
Batch 38/64 loss: -4.115732669830322
Batch 39/64 loss: -4.281271934509277
Batch 40/64 loss: -4.253454685211182
Batch 41/64 loss: -4.201694488525391
Batch 42/64 loss: -4.315817832946777
Batch 43/64 loss: -4.18464994430542
Batch 44/64 loss: -4.176675796508789
Batch 45/64 loss: -4.266534328460693
Batch 46/64 loss: -4.08721923828125
Batch 47/64 loss: -4.27191686630249
Batch 48/64 loss: -4.049490928649902
Batch 49/64 loss: -4.1678571701049805
Batch 50/64 loss: -4.152163505554199
Batch 51/64 loss: -4.26624870300293
Batch 52/64 loss: -4.332470417022705
Batch 53/64 loss: -4.251704216003418
Batch 54/64 loss: -4.197062015533447
Batch 55/64 loss: -4.063560962677002
Batch 56/64 loss: -4.196547985076904
Batch 57/64 loss: -4.352658271789551
Batch 58/64 loss: -4.157163143157959
Batch 59/64 loss: -4.152890205383301
Batch 60/64 loss: -4.001433372497559
Batch 61/64 loss: -4.20442008972168
Batch 62/64 loss: -4.353231906890869
Batch 63/64 loss: -4.224583625793457
Batch 64/64 loss: -8.673907279968262
Epoch 480  Train loss: -4.235525120005888  Val loss: -4.626782984258383
Epoch 481
-------------------------------
Batch 1/64 loss: -4.102783203125
Batch 2/64 loss: -4.0944061279296875
Batch 3/64 loss: -4.24381685256958
Batch 4/64 loss: -4.207623481750488
Batch 5/64 loss: -4.1764397621154785
Batch 6/64 loss: -4.179825305938721
Batch 7/64 loss: -4.105666160583496
Batch 8/64 loss: -4.3128981590271
Batch 9/64 loss: -4.044580936431885
Batch 10/64 loss: -4.1594462394714355
Batch 11/64 loss: -4.192957401275635
Batch 12/64 loss: -4.368971347808838
Batch 13/64 loss: -4.18648624420166
Batch 14/64 loss: -3.954986572265625
Batch 15/64 loss: -3.868712902069092
Batch 16/64 loss: -4.145382404327393
Batch 17/64 loss: -4.056234836578369
Batch 18/64 loss: -4.29446268081665
Batch 19/64 loss: -4.177006244659424
Batch 20/64 loss: -4.109296798706055
Batch 21/64 loss: -4.255083084106445
Batch 22/64 loss: -4.270244121551514
Batch 23/64 loss: -4.013095855712891
Batch 24/64 loss: -4.1576690673828125
Batch 25/64 loss: -4.236508369445801
Batch 26/64 loss: -4.052702903747559
Batch 27/64 loss: -4.133908271789551
Batch 28/64 loss: -4.015997886657715
Batch 29/64 loss: -3.705976963043213
Batch 30/64 loss: -4.177586078643799
Batch 31/64 loss: -4.120804786682129
Batch 32/64 loss: -4.169477462768555
Batch 33/64 loss: -4.112331867218018
Batch 34/64 loss: -4.134178161621094
Batch 35/64 loss: -3.797391891479492
Batch 36/64 loss: -4.117103099822998
Batch 37/64 loss: -4.088572978973389
Batch 38/64 loss: -4.2564473152160645
Batch 39/64 loss: -4.020971775054932
Batch 40/64 loss: -4.177005290985107
Batch 41/64 loss: -4.062680721282959
Batch 42/64 loss: -4.076093673706055
Batch 43/64 loss: -4.073982238769531
Batch 44/64 loss: -4.043356418609619
Batch 45/64 loss: -4.276483535766602
Batch 46/64 loss: -3.8098249435424805
Batch 47/64 loss: -4.152688026428223
Batch 48/64 loss: -4.087695598602295
Batch 49/64 loss: -4.029962062835693
Batch 50/64 loss: -4.123326778411865
Batch 51/64 loss: -4.227473735809326
Batch 52/64 loss: -4.108639717102051
Batch 53/64 loss: -4.150247097015381
Batch 54/64 loss: -4.265096187591553
Batch 55/64 loss: -4.226141452789307
Batch 56/64 loss: -4.206554889678955
Batch 57/64 loss: -4.253610134124756
Batch 58/64 loss: -4.345589637756348
Batch 59/64 loss: -4.089103698730469
Batch 60/64 loss: -4.170729637145996
Batch 61/64 loss: -4.206613063812256
Batch 62/64 loss: -4.24785041809082
Batch 63/64 loss: -3.9405789375305176
Batch 64/64 loss: -8.553253173828125
Epoch 481  Train loss: -4.181714562808766  Val loss: -4.572309906949702
Epoch 482
-------------------------------
Batch 1/64 loss: -4.271159648895264
Batch 2/64 loss: -4.240176677703857
Batch 3/64 loss: -4.247934341430664
Batch 4/64 loss: -4.3023295402526855
Batch 5/64 loss: -3.9669809341430664
Batch 6/64 loss: -4.123939514160156
Batch 7/64 loss: -4.208254814147949
Batch 8/64 loss: -4.279706954956055
Batch 9/64 loss: -4.250237464904785
Batch 10/64 loss: -4.1287946701049805
Batch 11/64 loss: -4.082924842834473
Batch 12/64 loss: -4.343387603759766
Batch 13/64 loss: -4.099483013153076
Batch 14/64 loss: -4.068467140197754
Batch 15/64 loss: -3.91873836517334
Batch 16/64 loss: -4.12520694732666
Batch 17/64 loss: -4.204655170440674
Batch 18/64 loss: -4.168002128601074
Batch 19/64 loss: -4.155824184417725
Batch 20/64 loss: -4.148436546325684
Batch 21/64 loss: -4.220179557800293
Batch 22/64 loss: -4.117282390594482
Batch 23/64 loss: -3.97037935256958
Batch 24/64 loss: -4.161040782928467
Batch 25/64 loss: -4.252052307128906
Batch 26/64 loss: -4.278818607330322
Batch 27/64 loss: -4.29666805267334
Batch 28/64 loss: -4.251486301422119
Batch 29/64 loss: -4.1049299240112305
Batch 30/64 loss: -4.007281303405762
Batch 31/64 loss: -4.2310943603515625
Batch 32/64 loss: -3.8700671195983887
Batch 33/64 loss: -3.882976531982422
Batch 34/64 loss: -4.190395355224609
Batch 35/64 loss: -4.252105712890625
Batch 36/64 loss: -3.641510009765625
Batch 37/64 loss: -4.226114749908447
Batch 38/64 loss: -3.9360880851745605
Batch 39/64 loss: -4.1736273765563965
Batch 40/64 loss: -4.280272483825684
Batch 41/64 loss: -4.055460453033447
Batch 42/64 loss: -4.282848834991455
Batch 43/64 loss: -4.152878284454346
Batch 44/64 loss: -4.223196506500244
Batch 45/64 loss: -4.312127113342285
Batch 46/64 loss: -4.119785308837891
Batch 47/64 loss: -4.110838413238525
Batch 48/64 loss: -4.13402795791626
Batch 49/64 loss: -4.040070056915283
Batch 50/64 loss: -4.110028266906738
Batch 51/64 loss: -4.146152496337891
Batch 52/64 loss: -4.2281928062438965
Batch 53/64 loss: -4.099651336669922
Batch 54/64 loss: -4.277029037475586
Batch 55/64 loss: -4.004807472229004
Batch 56/64 loss: -4.068935394287109
Batch 57/64 loss: -4.102480411529541
Batch 58/64 loss: -4.103579521179199
Batch 59/64 loss: -3.827469825744629
Batch 60/64 loss: -4.057546138763428
Batch 61/64 loss: -4.100964546203613
Batch 62/64 loss: -4.1383466720581055
Batch 63/64 loss: -3.9152259826660156
Batch 64/64 loss: -8.599575996398926
Epoch 482  Train loss: -4.18416212867288  Val loss: -4.543821800205715
Epoch 483
-------------------------------
Batch 1/64 loss: -4.343923568725586
Batch 2/64 loss: -4.159251689910889
Batch 3/64 loss: -4.2291340827941895
Batch 4/64 loss: -4.110343933105469
Batch 5/64 loss: -3.879650115966797
Batch 6/64 loss: -4.131428241729736
Batch 7/64 loss: -4.050142765045166
Batch 8/64 loss: -4.140008449554443
Batch 9/64 loss: -4.161447525024414
Batch 10/64 loss: -4.3150954246521
Batch 11/64 loss: -3.9853177070617676
Batch 12/64 loss: -4.1216607093811035
Batch 13/64 loss: -4.155860424041748
Batch 14/64 loss: -4.115206718444824
Batch 15/64 loss: -4.104798793792725
Batch 16/64 loss: -4.03152322769165
Batch 17/64 loss: -4.137827396392822
Batch 18/64 loss: -4.093656539916992
Batch 19/64 loss: -4.192723751068115
Batch 20/64 loss: -4.185863494873047
Batch 21/64 loss: -3.8003106117248535
Batch 22/64 loss: -4.193974018096924
Batch 23/64 loss: -4.226873874664307
Batch 24/64 loss: -3.93129825592041
Batch 25/64 loss: -4.185717582702637
Batch 26/64 loss: -4.093233108520508
Batch 27/64 loss: -3.8843979835510254
Batch 28/64 loss: -4.2570271492004395
Batch 29/64 loss: -4.011562824249268
Batch 30/64 loss: -4.1564435958862305
Batch 31/64 loss: -3.9952392578125
Batch 32/64 loss: -4.094476699829102
Batch 33/64 loss: -4.16229772567749
Batch 34/64 loss: -4.270223140716553
Batch 35/64 loss: -4.087563991546631
Batch 36/64 loss: -4.05254602432251
Batch 37/64 loss: -3.981088638305664
Batch 38/64 loss: -4.136531829833984
Batch 39/64 loss: -4.155879020690918
Batch 40/64 loss: -4.098519802093506
Batch 41/64 loss: -4.27826452255249
Batch 42/64 loss: -4.334011554718018
Batch 43/64 loss: -3.979780673980713
Batch 44/64 loss: -4.0521721839904785
Batch 45/64 loss: -4.2327728271484375
Batch 46/64 loss: -4.04640531539917
Batch 47/64 loss: -4.208670139312744
Batch 48/64 loss: -4.190608978271484
Batch 49/64 loss: -4.287566184997559
Batch 50/64 loss: -4.110378742218018
Batch 51/64 loss: -4.154355525970459
Batch 52/64 loss: -4.221948146820068
Batch 53/64 loss: -4.055952072143555
Batch 54/64 loss: -4.125675201416016
Batch 55/64 loss: -3.987337589263916
Batch 56/64 loss: -3.8930983543395996
Batch 57/64 loss: -3.832275867462158
Batch 58/64 loss: -4.098733901977539
Batch 59/64 loss: -3.9968786239624023
Batch 60/64 loss: -4.143665790557861
Batch 61/64 loss: -4.05362606048584
Batch 62/64 loss: -3.984750747680664
Batch 63/64 loss: -3.984710693359375
Batch 64/64 loss: -8.770955085754395
Epoch 483  Train loss: -4.160814520891975  Val loss: -4.580855418726341
Epoch 484
-------------------------------
Batch 1/64 loss: -4.171121120452881
Batch 2/64 loss: -4.1166863441467285
Batch 3/64 loss: -4.048406600952148
Batch 4/64 loss: -4.175346374511719
Batch 5/64 loss: -4.275146484375
Batch 6/64 loss: -4.171915531158447
Batch 7/64 loss: -4.254355430603027
Batch 8/64 loss: -4.333928108215332
Batch 9/64 loss: -4.108588218688965
Batch 10/64 loss: -4.12956428527832
Batch 11/64 loss: -4.249629020690918
Batch 12/64 loss: -4.3065385818481445
Batch 13/64 loss: -4.059025287628174
Batch 14/64 loss: -4.053353309631348
Batch 15/64 loss: -4.292200088500977
Batch 16/64 loss: -4.074226379394531
Batch 17/64 loss: -4.1802544593811035
Batch 18/64 loss: -4.236151695251465
Batch 19/64 loss: -4.178225517272949
Batch 20/64 loss: -4.150003910064697
Batch 21/64 loss: -4.2389140129089355
Batch 22/64 loss: -4.237239360809326
Batch 23/64 loss: -4.264720439910889
Batch 24/64 loss: -4.299837589263916
Batch 25/64 loss: -4.225146770477295
Batch 26/64 loss: -4.110594272613525
Batch 27/64 loss: -4.108684539794922
Batch 28/64 loss: -4.1369733810424805
Batch 29/64 loss: -4.1158905029296875
Batch 30/64 loss: -3.8807926177978516
Batch 31/64 loss: -4.108943939208984
Batch 32/64 loss: -4.132441520690918
Batch 33/64 loss: -4.290414810180664
Batch 34/64 loss: -4.112555503845215
Batch 35/64 loss: -4.196167469024658
Batch 36/64 loss: -4.269994735717773
Batch 37/64 loss: -4.130428314208984
Batch 38/64 loss: -4.125138282775879
Batch 39/64 loss: -4.157201766967773
Batch 40/64 loss: -4.215878963470459
Batch 41/64 loss: -3.8985042572021484
Batch 42/64 loss: -4.384716510772705
Batch 43/64 loss: -4.221471309661865
Batch 44/64 loss: -4.058681964874268
Batch 45/64 loss: -4.173646450042725
Batch 46/64 loss: -4.330556869506836
Batch 47/64 loss: -4.0675859451293945
Batch 48/64 loss: -4.448067665100098
Batch 49/64 loss: -4.080662250518799
Batch 50/64 loss: -4.061675071716309
Batch 51/64 loss: -4.113953590393066
Batch 52/64 loss: -4.173657417297363
Batch 53/64 loss: -4.388916015625
Batch 54/64 loss: -4.199425220489502
Batch 55/64 loss: -4.286102294921875
Batch 56/64 loss: -4.061790943145752
Batch 57/64 loss: -4.171545505523682
Batch 58/64 loss: -4.127176284790039
Batch 59/64 loss: -3.944425582885742
Batch 60/64 loss: -4.136656284332275
Batch 61/64 loss: -4.227771282196045
Batch 62/64 loss: -4.108699321746826
Batch 63/64 loss: -4.248995780944824
Batch 64/64 loss: -8.591148376464844
Epoch 484  Train loss: -4.224010519887887  Val loss: -4.681422269631088
Saving best model, epoch: 484
Epoch 485
-------------------------------
Batch 1/64 loss: -4.167012691497803
Batch 2/64 loss: -4.183645725250244
Batch 3/64 loss: -4.156764030456543
Batch 4/64 loss: -4.260528564453125
Batch 5/64 loss: -4.2090163230896
Batch 6/64 loss: -4.246156692504883
Batch 7/64 loss: -3.8399105072021484
Batch 8/64 loss: -4.219094753265381
Batch 9/64 loss: -3.709536552429199
Batch 10/64 loss: -4.290461540222168
Batch 11/64 loss: -4.203407287597656
Batch 12/64 loss: -4.119507789611816
Batch 13/64 loss: -4.4011759757995605
Batch 14/64 loss: -4.261318206787109
Batch 15/64 loss: -4.2169108390808105
Batch 16/64 loss: -4.187917232513428
Batch 17/64 loss: -4.175956726074219
Batch 18/64 loss: -4.1131463050842285
Batch 19/64 loss: -4.247134685516357
Batch 20/64 loss: -3.848663806915283
Batch 21/64 loss: -4.2566046714782715
Batch 22/64 loss: -4.172072887420654
Batch 23/64 loss: -3.9877562522888184
Batch 24/64 loss: -4.3108296394348145
Batch 25/64 loss: -4.251276016235352
Batch 26/64 loss: -4.2789692878723145
Batch 27/64 loss: -4.448342800140381
Batch 28/64 loss: -4.242316722869873
Batch 29/64 loss: -4.358862400054932
Batch 30/64 loss: -4.115621089935303
Batch 31/64 loss: -4.1730637550354
Batch 32/64 loss: -4.153188705444336
Batch 33/64 loss: -3.96091365814209
Batch 34/64 loss: -4.085268020629883
Batch 35/64 loss: -4.341566562652588
Batch 36/64 loss: -4.0840349197387695
Batch 37/64 loss: -4.110358715057373
Batch 38/64 loss: -4.278559684753418
Batch 39/64 loss: -4.176752090454102
Batch 40/64 loss: -4.27621603012085
Batch 41/64 loss: -4.2528276443481445
Batch 42/64 loss: -4.157521724700928
Batch 43/64 loss: -4.098958492279053
Batch 44/64 loss: -4.237114429473877
Batch 45/64 loss: -4.22581672668457
Batch 46/64 loss: -4.172576904296875
Batch 47/64 loss: -4.190256595611572
Batch 48/64 loss: -4.210728645324707
Batch 49/64 loss: -4.2904276847839355
Batch 50/64 loss: -4.2560906410217285
Batch 51/64 loss: -4.209776401519775
Batch 52/64 loss: -4.2721734046936035
Batch 53/64 loss: -4.225226402282715
Batch 54/64 loss: -4.110394477844238
Batch 55/64 loss: -4.207756996154785
Batch 56/64 loss: -4.161911964416504
Batch 57/64 loss: -4.120269298553467
Batch 58/64 loss: -4.113008499145508
Batch 59/64 loss: -4.324515342712402
Batch 60/64 loss: -4.256494998931885
Batch 61/64 loss: -4.021559715270996
Batch 62/64 loss: -4.123541831970215
Batch 63/64 loss: -4.218135833740234
Batch 64/64 loss: -8.679000854492188
Epoch 485  Train loss: -4.236645889282227  Val loss: -4.5745378343510055
Epoch 486
-------------------------------
Batch 1/64 loss: -4.132639408111572
Batch 2/64 loss: -4.086340427398682
Batch 3/64 loss: -4.064218521118164
Batch 4/64 loss: -4.066843509674072
Batch 5/64 loss: -4.235791206359863
Batch 6/64 loss: -4.005881309509277
Batch 7/64 loss: -4.006080627441406
Batch 8/64 loss: -4.1829142570495605
Batch 9/64 loss: -4.252851486206055
Batch 10/64 loss: -4.002512454986572
Batch 11/64 loss: -4.19540548324585
Batch 12/64 loss: -4.214515209197998
Batch 13/64 loss: -4.1358642578125
Batch 14/64 loss: -3.9927468299865723
Batch 15/64 loss: -4.221660137176514
Batch 16/64 loss: -4.246771335601807
Batch 17/64 loss: -4.169158935546875
Batch 18/64 loss: -4.124804973602295
Batch 19/64 loss: -4.183553218841553
Batch 20/64 loss: -3.9856505393981934
Batch 21/64 loss: -4.31412410736084
Batch 22/64 loss: -4.275313854217529
Batch 23/64 loss: -4.111597061157227
Batch 24/64 loss: -3.900515556335449
Batch 25/64 loss: -4.157214164733887
Batch 26/64 loss: -4.2194976806640625
Batch 27/64 loss: -4.173098087310791
Batch 28/64 loss: -4.22652006149292
Batch 29/64 loss: -4.259011745452881
Batch 30/64 loss: -4.0935282707214355
Batch 31/64 loss: -4.266574859619141
Batch 32/64 loss: -4.015220642089844
Batch 33/64 loss: -4.075220584869385
Batch 34/64 loss: -4.113700866699219
Batch 35/64 loss: -4.156987190246582
Batch 36/64 loss: -4.162047386169434
Batch 37/64 loss: -4.142702102661133
Batch 38/64 loss: -4.183319091796875
Batch 39/64 loss: -4.191324234008789
Batch 40/64 loss: -3.977273464202881
Batch 41/64 loss: -4.180155277252197
Batch 42/64 loss: -4.044516563415527
Batch 43/64 loss: -4.096287250518799
Batch 44/64 loss: -4.330317974090576
Batch 45/64 loss: -4.273637294769287
Batch 46/64 loss: -4.384274959564209
Batch 47/64 loss: -4.339437484741211
Batch 48/64 loss: -4.125133037567139
Batch 49/64 loss: -4.189671039581299
Batch 50/64 loss: -4.372101783752441
Batch 51/64 loss: -4.056717395782471
Batch 52/64 loss: -4.274304389953613
Batch 53/64 loss: -4.144833564758301
Batch 54/64 loss: -4.243077754974365
Batch 55/64 loss: -4.042868137359619
Batch 56/64 loss: -3.7347092628479004
Batch 57/64 loss: -4.018571853637695
Batch 58/64 loss: -4.126495838165283
Batch 59/64 loss: -4.1422858238220215
Batch 60/64 loss: -4.319234848022461
Batch 61/64 loss: -4.326272010803223
Batch 62/64 loss: -4.295038223266602
Batch 63/64 loss: -4.024169921875
Batch 64/64 loss: -8.885787963867188
Epoch 486  Train loss: -4.208148200839173  Val loss: -4.628636874693775
Epoch 487
-------------------------------
Batch 1/64 loss: -4.15966272354126
Batch 2/64 loss: -3.88551664352417
Batch 3/64 loss: -4.219420909881592
Batch 4/64 loss: -4.188764572143555
Batch 5/64 loss: -4.277650356292725
Batch 6/64 loss: -4.141082286834717
Batch 7/64 loss: -4.188982963562012
Batch 8/64 loss: -4.197397708892822
Batch 9/64 loss: -4.181870460510254
Batch 10/64 loss: -3.9866394996643066
Batch 11/64 loss: -4.157344818115234
Batch 12/64 loss: -4.131819725036621
Batch 13/64 loss: -4.152347087860107
Batch 14/64 loss: -4.129669189453125
Batch 15/64 loss: -4.062974452972412
Batch 16/64 loss: -4.1184916496276855
Batch 17/64 loss: -4.108783721923828
Batch 18/64 loss: -4.243174076080322
Batch 19/64 loss: -4.237064838409424
Batch 20/64 loss: -4.1100640296936035
Batch 21/64 loss: -4.225292205810547
Batch 22/64 loss: -4.284587383270264
Batch 23/64 loss: -4.254411220550537
Batch 24/64 loss: -4.18884801864624
Batch 25/64 loss: -4.234504222869873
Batch 26/64 loss: -4.354501247406006
Batch 27/64 loss: -4.2012715339660645
Batch 28/64 loss: -4.134819507598877
Batch 29/64 loss: -4.157175540924072
Batch 30/64 loss: -4.170974254608154
Batch 31/64 loss: -4.190093040466309
Batch 32/64 loss: -4.1410980224609375
Batch 33/64 loss: -4.156949520111084
Batch 34/64 loss: -4.362206935882568
Batch 35/64 loss: -4.099838733673096
Batch 36/64 loss: -4.175315856933594
Batch 37/64 loss: -4.078064918518066
Batch 38/64 loss: -4.139395236968994
Batch 39/64 loss: -4.10122537612915
Batch 40/64 loss: -3.8314247131347656
Batch 41/64 loss: -3.9608511924743652
Batch 42/64 loss: -4.254138469696045
Batch 43/64 loss: -4.196023941040039
Batch 44/64 loss: -4.075458526611328
Batch 45/64 loss: -4.269736289978027
Batch 46/64 loss: -4.057175159454346
Batch 47/64 loss: -4.160167694091797
Batch 48/64 loss: -4.183687686920166
Batch 49/64 loss: -4.308589458465576
Batch 50/64 loss: -4.251915454864502
Batch 51/64 loss: -4.066928386688232
Batch 52/64 loss: -4.2582688331604
Batch 53/64 loss: -4.23746395111084
Batch 54/64 loss: -4.246460437774658
Batch 55/64 loss: -4.251075744628906
Batch 56/64 loss: -4.122025489807129
Batch 57/64 loss: -4.29257345199585
Batch 58/64 loss: -4.330975532531738
Batch 59/64 loss: -4.008170127868652
Batch 60/64 loss: -4.243819236755371
Batch 61/64 loss: -3.9948277473449707
Batch 62/64 loss: -4.213301658630371
Batch 63/64 loss: -4.257185935974121
Batch 64/64 loss: -8.743900299072266
Epoch 487  Train loss: -4.222109252331304  Val loss: -4.679895420664365
Epoch 488
-------------------------------
Batch 1/64 loss: -4.246092796325684
Batch 2/64 loss: -4.232213497161865
Batch 3/64 loss: -4.0764899253845215
Batch 4/64 loss: -4.038693904876709
Batch 5/64 loss: -4.253833293914795
Batch 6/64 loss: -4.1527862548828125
Batch 7/64 loss: -4.163695812225342
Batch 8/64 loss: -4.253654479980469
Batch 9/64 loss: -4.016517162322998
Batch 10/64 loss: -4.194613456726074
Batch 11/64 loss: -4.067078590393066
Batch 12/64 loss: -4.3120503425598145
Batch 13/64 loss: -4.1931023597717285
Batch 14/64 loss: -4.294520854949951
Batch 15/64 loss: -4.121607780456543
Batch 16/64 loss: -4.0886712074279785
Batch 17/64 loss: -4.176947116851807
Batch 18/64 loss: -3.902522563934326
Batch 19/64 loss: -4.221177577972412
Batch 20/64 loss: -4.19384765625
Batch 21/64 loss: -3.9699912071228027
Batch 22/64 loss: -3.9827804565429688
Batch 23/64 loss: -3.9618940353393555
Batch 24/64 loss: -4.144480228424072
Batch 25/64 loss: -4.061913967132568
Batch 26/64 loss: -4.146433353424072
Batch 27/64 loss: -4.196824550628662
Batch 28/64 loss: -4.155494213104248
Batch 29/64 loss: -3.9500927925109863
Batch 30/64 loss: -4.213232517242432
Batch 31/64 loss: -4.191802501678467
Batch 32/64 loss: -3.983433723449707
Batch 33/64 loss: -4.11622953414917
Batch 34/64 loss: -4.0260233879089355
Batch 35/64 loss: -4.320639133453369
Batch 36/64 loss: -4.27052640914917
Batch 37/64 loss: -3.9352946281433105
Batch 38/64 loss: -4.100627899169922
Batch 39/64 loss: -4.241129398345947
Batch 40/64 loss: -4.183720111846924
Batch 41/64 loss: -4.235584735870361
Batch 42/64 loss: -4.203266143798828
Batch 43/64 loss: -4.032324314117432
Batch 44/64 loss: -4.163110256195068
Batch 45/64 loss: -4.253873348236084
Batch 46/64 loss: -4.056394100189209
Batch 47/64 loss: -3.9717416763305664
Batch 48/64 loss: -3.8499903678894043
Batch 49/64 loss: -4.1652631759643555
Batch 50/64 loss: -4.349430561065674
Batch 51/64 loss: -4.138090133666992
Batch 52/64 loss: -4.089493751525879
Batch 53/64 loss: -4.035064697265625
Batch 54/64 loss: -4.156161785125732
Batch 55/64 loss: -3.9057788848876953
Batch 56/64 loss: -4.091989517211914
Batch 57/64 loss: -4.28631067276001
Batch 58/64 loss: -4.171191692352295
Batch 59/64 loss: -4.233592510223389
Batch 60/64 loss: -4.040434837341309
Batch 61/64 loss: -4.266887187957764
Batch 62/64 loss: -4.193619728088379
Batch 63/64 loss: -4.0645060539245605
Batch 64/64 loss: -8.738529205322266
Epoch 488  Train loss: -4.186049846574372  Val loss: -4.662115903244805
Epoch 489
-------------------------------
Batch 1/64 loss: -4.226324558258057
Batch 2/64 loss: -4.363083839416504
Batch 3/64 loss: -3.9784603118896484
Batch 4/64 loss: -3.824352264404297
Batch 5/64 loss: -4.191154956817627
Batch 6/64 loss: -4.290835857391357
Batch 7/64 loss: -4.1475067138671875
Batch 8/64 loss: -4.252720355987549
Batch 9/64 loss: -4.055647373199463
Batch 10/64 loss: -4.173245429992676
Batch 11/64 loss: -4.209120273590088
Batch 12/64 loss: -4.158605575561523
Batch 13/64 loss: -4.301163196563721
Batch 14/64 loss: -4.119516372680664
Batch 15/64 loss: -4.183399200439453
Batch 16/64 loss: -4.102888584136963
Batch 17/64 loss: -3.6983718872070312
Batch 18/64 loss: -4.322020530700684
Batch 19/64 loss: -4.116799831390381
Batch 20/64 loss: -4.247197151184082
Batch 21/64 loss: -4.161660194396973
Batch 22/64 loss: -3.972109317779541
Batch 23/64 loss: -4.033520221710205
Batch 24/64 loss: -4.239554405212402
Batch 25/64 loss: -3.8682446479797363
Batch 26/64 loss: -4.262673377990723
Batch 27/64 loss: -4.117159843444824
Batch 28/64 loss: -4.137640476226807
Batch 29/64 loss: -3.9749531745910645
Batch 30/64 loss: -4.108588218688965
Batch 31/64 loss: -4.332406044006348
Batch 32/64 loss: -4.170609951019287
Batch 33/64 loss: -4.267366886138916
Batch 34/64 loss: -4.075957775115967
Batch 35/64 loss: -4.068493843078613
Batch 36/64 loss: -4.1436614990234375
Batch 37/64 loss: -4.271961688995361
Batch 38/64 loss: -4.207088470458984
Batch 39/64 loss: -4.225825309753418
Batch 40/64 loss: -4.165934085845947
Batch 41/64 loss: -4.118533134460449
Batch 42/64 loss: -4.319697380065918
Batch 43/64 loss: -3.8068666458129883
Batch 44/64 loss: -4.047310829162598
Batch 45/64 loss: -4.198014736175537
Batch 46/64 loss: -4.2844390869140625
Batch 47/64 loss: -4.19619607925415
Batch 48/64 loss: -4.291390895843506
Batch 49/64 loss: -4.319239139556885
Batch 50/64 loss: -4.207174301147461
Batch 51/64 loss: -4.0763840675354
Batch 52/64 loss: -4.26710319519043
Batch 53/64 loss: -4.06903076171875
Batch 54/64 loss: -4.2374396324157715
Batch 55/64 loss: -4.3203349113464355
Batch 56/64 loss: -4.240946292877197
Batch 57/64 loss: -4.44872522354126
Batch 58/64 loss: -4.263017177581787
Batch 59/64 loss: -4.262430667877197
Batch 60/64 loss: -4.252279758453369
Batch 61/64 loss: -4.284666538238525
Batch 62/64 loss: -4.160919189453125
Batch 63/64 loss: -4.35029935836792
Batch 64/64 loss: -8.838589668273926
Epoch 489  Train loss: -4.2261836070640415  Val loss: -4.607016481484744
Epoch 490
-------------------------------
Batch 1/64 loss: -4.140497207641602
Batch 2/64 loss: -3.791074275970459
Batch 3/64 loss: -4.126921653747559
Batch 4/64 loss: -4.1661810874938965
Batch 5/64 loss: -4.143470287322998
Batch 6/64 loss: -4.082359313964844
Batch 7/64 loss: -4.349917411804199
Batch 8/64 loss: -4.183891296386719
Batch 9/64 loss: -4.287158489227295
Batch 10/64 loss: -4.273112773895264
Batch 11/64 loss: -4.224245548248291
Batch 12/64 loss: -4.2317376136779785
Batch 13/64 loss: -3.8242712020874023
Batch 14/64 loss: -4.297321319580078
Batch 15/64 loss: -4.172823905944824
Batch 16/64 loss: -4.318582057952881
Batch 17/64 loss: -4.263370513916016
Batch 18/64 loss: -4.159161567687988
Batch 19/64 loss: -4.341561317443848
Batch 20/64 loss: -4.164881229400635
Batch 21/64 loss: -4.204721927642822
Batch 22/64 loss: -4.2644548416137695
Batch 23/64 loss: -4.259225845336914
Batch 24/64 loss: -4.144976615905762
Batch 25/64 loss: -4.305697441101074
Batch 26/64 loss: -4.1266398429870605
Batch 27/64 loss: -3.9841465950012207
Batch 28/64 loss: -4.246194839477539
Batch 29/64 loss: -4.244381904602051
Batch 30/64 loss: -4.31369161605835
Batch 31/64 loss: -4.301887035369873
Batch 32/64 loss: -4.157013416290283
Batch 33/64 loss: -4.061154842376709
Batch 34/64 loss: -3.874290943145752
Batch 35/64 loss: -4.049975872039795
Batch 36/64 loss: -4.143290996551514
Batch 37/64 loss: -4.333285808563232
Batch 38/64 loss: -4.005579471588135
Batch 39/64 loss: -4.048470973968506
Batch 40/64 loss: -4.269958972930908
Batch 41/64 loss: -4.186132431030273
Batch 42/64 loss: -4.139787197113037
Batch 43/64 loss: -4.221554279327393
Batch 44/64 loss: -4.1546807289123535
Batch 45/64 loss: -3.763183116912842
Batch 46/64 loss: -4.139157295227051
Batch 47/64 loss: -4.1031951904296875
Batch 48/64 loss: -4.242037296295166
Batch 49/64 loss: -4.076739311218262
Batch 50/64 loss: -4.145561695098877
Batch 51/64 loss: -4.160891056060791
Batch 52/64 loss: -4.077088832855225
Batch 53/64 loss: -4.033372402191162
Batch 54/64 loss: -4.171263694763184
Batch 55/64 loss: -4.254901885986328
Batch 56/64 loss: -4.103072166442871
Batch 57/64 loss: -4.260960102081299
Batch 58/64 loss: -4.250133514404297
Batch 59/64 loss: -3.777052402496338
Batch 60/64 loss: -4.283755302429199
Batch 61/64 loss: -4.156756401062012
Batch 62/64 loss: -4.071335792541504
Batch 63/64 loss: -4.320743560791016
Batch 64/64 loss: -8.846227645874023
Epoch 490  Train loss: -4.213484019859164  Val loss: -4.624602694691661
Epoch 491
-------------------------------
Batch 1/64 loss: -4.288687229156494
Batch 2/64 loss: -4.117773056030273
Batch 3/64 loss: -4.302901268005371
Batch 4/64 loss: -4.0655198097229
Batch 5/64 loss: -4.2164483070373535
Batch 6/64 loss: -4.052008628845215
Batch 7/64 loss: -4.176355838775635
Batch 8/64 loss: -4.242827892303467
Batch 9/64 loss: -4.243300914764404
Batch 10/64 loss: -4.100961685180664
Batch 11/64 loss: -4.1942033767700195
Batch 12/64 loss: -4.022079944610596
Batch 13/64 loss: -4.023778438568115
Batch 14/64 loss: -4.148444652557373
Batch 15/64 loss: -4.137156963348389
Batch 16/64 loss: -4.152140140533447
Batch 17/64 loss: -4.28126859664917
Batch 18/64 loss: -3.352606773376465
Batch 19/64 loss: -4.103566646575928
Batch 20/64 loss: -3.5861387252807617
Batch 21/64 loss: -4.066736221313477
Batch 22/64 loss: -4.175283432006836
Batch 23/64 loss: -4.243100643157959
Batch 24/64 loss: -4.159488201141357
Batch 25/64 loss: -4.150883674621582
Batch 26/64 loss: -4.070397853851318
Batch 27/64 loss: -4.147643089294434
Batch 28/64 loss: -4.166818618774414
Batch 29/64 loss: -4.135119438171387
Batch 30/64 loss: -3.673978805541992
Batch 31/64 loss: -4.113120079040527
Batch 32/64 loss: -4.242598056793213
Batch 33/64 loss: -4.242468357086182
Batch 34/64 loss: -3.995789051055908
Batch 35/64 loss: -4.105243682861328
Batch 36/64 loss: -4.163928031921387
Batch 37/64 loss: -3.6975741386413574
Batch 38/64 loss: -4.164918422698975
Batch 39/64 loss: -4.11823034286499
Batch 40/64 loss: -4.209712505340576
Batch 41/64 loss: -4.094264030456543
Batch 42/64 loss: -4.115365982055664
Batch 43/64 loss: -4.197506904602051
Batch 44/64 loss: -3.8907012939453125
Batch 45/64 loss: -4.070065498352051
Batch 46/64 loss: -4.07301139831543
Batch 47/64 loss: -4.095610618591309
Batch 48/64 loss: -4.141716480255127
Batch 49/64 loss: -4.012760162353516
Batch 50/64 loss: -3.953956127166748
Batch 51/64 loss: -4.047502040863037
Batch 52/64 loss: -4.149572372436523
Batch 53/64 loss: -4.201425552368164
Batch 54/64 loss: -4.271395683288574
Batch 55/64 loss: -4.2556071281433105
Batch 56/64 loss: -3.8560376167297363
Batch 57/64 loss: -4.231739044189453
Batch 58/64 loss: -4.15865421295166
Batch 59/64 loss: -4.228357315063477
Batch 60/64 loss: -4.1327805519104
Batch 61/64 loss: -4.150112628936768
Batch 62/64 loss: -4.104310035705566
Batch 63/64 loss: -4.006534576416016
Batch 64/64 loss: -8.646232604980469
Epoch 491  Train loss: -4.153331188127106  Val loss: -4.623207131611932
Epoch 492
-------------------------------
Batch 1/64 loss: -4.164133071899414
Batch 2/64 loss: -3.8814377784729004
Batch 3/64 loss: -4.059519290924072
Batch 4/64 loss: -4.162775039672852
Batch 5/64 loss: -4.1641526222229
Batch 6/64 loss: -4.239660263061523
Batch 7/64 loss: -4.012884140014648
Batch 8/64 loss: -4.004012584686279
Batch 9/64 loss: -4.000865936279297
Batch 10/64 loss: -4.089175701141357
Batch 11/64 loss: -4.209601879119873
Batch 12/64 loss: -4.282423496246338
Batch 13/64 loss: -4.255116939544678
Batch 14/64 loss: -4.212037563323975
Batch 15/64 loss: -4.073412895202637
Batch 16/64 loss: -4.195896625518799
Batch 17/64 loss: -4.098055839538574
Batch 18/64 loss: -4.067683219909668
Batch 19/64 loss: -4.111600399017334
Batch 20/64 loss: -3.972813606262207
Batch 21/64 loss: -3.812394142150879
Batch 22/64 loss: -4.192012786865234
Batch 23/64 loss: -4.253365993499756
Batch 24/64 loss: -4.403280735015869
Batch 25/64 loss: -4.23411226272583
Batch 26/64 loss: -4.122848033905029
Batch 27/64 loss: -4.242258548736572
Batch 28/64 loss: -4.244256496429443
Batch 29/64 loss: -4.3106279373168945
Batch 30/64 loss: -4.211259365081787
Batch 31/64 loss: -4.252003192901611
Batch 32/64 loss: -3.8280467987060547
Batch 33/64 loss: -4.1708292961120605
Batch 34/64 loss: -4.152206897735596
Batch 35/64 loss: -4.313992977142334
Batch 36/64 loss: -4.148111343383789
Batch 37/64 loss: -4.214756965637207
Batch 38/64 loss: -4.130634784698486
Batch 39/64 loss: -4.278190612792969
Batch 40/64 loss: -4.159585952758789
Batch 41/64 loss: -4.2597503662109375
Batch 42/64 loss: -4.214121341705322
Batch 43/64 loss: -4.43283748626709
Batch 44/64 loss: -4.288878440856934
Batch 45/64 loss: -4.389521598815918
Batch 46/64 loss: -4.147238731384277
Batch 47/64 loss: -4.305969715118408
Batch 48/64 loss: -4.367162227630615
Batch 49/64 loss: -4.253181457519531
Batch 50/64 loss: -3.9710617065429688
Batch 51/64 loss: -4.297882080078125
Batch 52/64 loss: -4.051987171173096
Batch 53/64 loss: -3.743976593017578
Batch 54/64 loss: -4.23649787902832
Batch 55/64 loss: -4.125361919403076
Batch 56/64 loss: -4.296866416931152
Batch 57/64 loss: -4.150859832763672
Batch 58/64 loss: -4.269695281982422
Batch 59/64 loss: -4.128389358520508
Batch 60/64 loss: -4.136822700500488
Batch 61/64 loss: -4.2426886558532715
Batch 62/64 loss: -4.222358703613281
Batch 63/64 loss: -4.351759910583496
Batch 64/64 loss: -8.90995979309082
Epoch 492  Train loss: -4.227441151936849  Val loss: -4.679041112001819
Epoch 493
-------------------------------
Batch 1/64 loss: -4.246767997741699
Batch 2/64 loss: -4.113090991973877
Batch 3/64 loss: -4.226248741149902
Batch 4/64 loss: -4.217752456665039
Batch 5/64 loss: -4.242282390594482
Batch 6/64 loss: -4.311872482299805
Batch 7/64 loss: -4.361968994140625
Batch 8/64 loss: -4.1685285568237305
Batch 9/64 loss: -4.377281665802002
Batch 10/64 loss: -4.220722198486328
Batch 11/64 loss: -4.207426071166992
Batch 12/64 loss: -4.352733135223389
Batch 13/64 loss: -4.1507697105407715
Batch 14/64 loss: -4.314014911651611
Batch 15/64 loss: -4.1470112800598145
Batch 16/64 loss: -4.158917427062988
Batch 17/64 loss: -4.1736345291137695
Batch 18/64 loss: -4.092968463897705
Batch 19/64 loss: -4.156092166900635
Batch 20/64 loss: -4.194061756134033
Batch 21/64 loss: -4.128484725952148
Batch 22/64 loss: -4.055741310119629
Batch 23/64 loss: -4.080504894256592
Batch 24/64 loss: -3.9004507064819336
Batch 25/64 loss: -4.2571234703063965
Batch 26/64 loss: -3.7960305213928223
Batch 27/64 loss: -4.070930480957031
Batch 28/64 loss: -4.167050838470459
Batch 29/64 loss: -3.8811683654785156
Batch 30/64 loss: -3.9846034049987793
Batch 31/64 loss: -4.091280460357666
Batch 32/64 loss: -4.1763458251953125
Batch 33/64 loss: -4.138704299926758
Batch 34/64 loss: -4.2464704513549805
Batch 35/64 loss: -4.260624408721924
Batch 36/64 loss: -4.194715976715088
Batch 37/64 loss: -4.239640712738037
Batch 38/64 loss: -4.3859171867370605
Batch 39/64 loss: -4.1981306076049805
Batch 40/64 loss: -3.7046608924865723
Batch 41/64 loss: -4.1869730949401855
Batch 42/64 loss: -4.114639759063721
Batch 43/64 loss: -3.898850917816162
Batch 44/64 loss: -4.2086100578308105
Batch 45/64 loss: -4.131915092468262
Batch 46/64 loss: -3.9890975952148438
Batch 47/64 loss: -4.179588794708252
Batch 48/64 loss: -4.084782600402832
Batch 49/64 loss: -4.180419921875
Batch 50/64 loss: -4.275524139404297
Batch 51/64 loss: -3.992063522338867
Batch 52/64 loss: -4.206357479095459
Batch 53/64 loss: -4.3772873878479
Batch 54/64 loss: -4.176248550415039
Batch 55/64 loss: -4.254846096038818
Batch 56/64 loss: -4.270874500274658
Batch 57/64 loss: -4.154718399047852
Batch 58/64 loss: -4.249934196472168
Batch 59/64 loss: -4.081547737121582
Batch 60/64 loss: -4.131699562072754
Batch 61/64 loss: -4.207971572875977
Batch 62/64 loss: -3.9771852493286133
Batch 63/64 loss: -4.216926097869873
Batch 64/64 loss: -8.614506721496582
Epoch 493  Train loss: -4.210222240522796  Val loss: -4.60413145609328
Epoch 494
-------------------------------
Batch 1/64 loss: -3.679482936859131
Batch 2/64 loss: -3.98049259185791
Batch 3/64 loss: -4.218729019165039
Batch 4/64 loss: -3.9962210655212402
Batch 5/64 loss: -4.090979099273682
Batch 6/64 loss: -4.169408798217773
Batch 7/64 loss: -4.2216572761535645
Batch 8/64 loss: -4.154088497161865
Batch 9/64 loss: -4.138333320617676
Batch 10/64 loss: -4.025045394897461
Batch 11/64 loss: -3.962472915649414
Batch 12/64 loss: -4.205295085906982
Batch 13/64 loss: -4.3082733154296875
Batch 14/64 loss: -4.285884857177734
Batch 15/64 loss: -4.176567554473877
Batch 16/64 loss: -4.142394542694092
Batch 17/64 loss: -4.17564582824707
Batch 18/64 loss: -4.138016700744629
Batch 19/64 loss: -4.184203624725342
Batch 20/64 loss: -4.280383586883545
Batch 21/64 loss: -3.892850399017334
Batch 22/64 loss: -4.281851768493652
Batch 23/64 loss: -4.326827049255371
Batch 24/64 loss: -4.109105587005615
Batch 25/64 loss: -4.089030742645264
Batch 26/64 loss: -3.9746570587158203
Batch 27/64 loss: -4.305459976196289
Batch 28/64 loss: -4.268281936645508
Batch 29/64 loss: -4.1841583251953125
Batch 30/64 loss: -4.270503520965576
Batch 31/64 loss: -4.063204765319824
Batch 32/64 loss: -4.193117618560791
Batch 33/64 loss: -4.13961124420166
Batch 34/64 loss: -4.156820774078369
Batch 35/64 loss: -4.351576328277588
Batch 36/64 loss: -4.287662982940674
Batch 37/64 loss: -4.333839416503906
Batch 38/64 loss: -4.072772979736328
Batch 39/64 loss: -4.2163214683532715
Batch 40/64 loss: -4.224541187286377
Batch 41/64 loss: -4.1469597816467285
Batch 42/64 loss: -4.232155799865723
Batch 43/64 loss: -4.289108753204346
Batch 44/64 loss: -4.240705490112305
Batch 45/64 loss: -4.197028636932373
Batch 46/64 loss: -4.0845818519592285
Batch 47/64 loss: -4.233541965484619
Batch 48/64 loss: -4.343686103820801
Batch 49/64 loss: -4.302783489227295
Batch 50/64 loss: -4.199567794799805
Batch 51/64 loss: -4.2068328857421875
Batch 52/64 loss: -4.067966461181641
Batch 53/64 loss: -3.931086540222168
Batch 54/64 loss: -4.1277313232421875
Batch 55/64 loss: -4.226503849029541
Batch 56/64 loss: -4.290295124053955
Batch 57/64 loss: -3.7662301063537598
Batch 58/64 loss: -4.199104309082031
Batch 59/64 loss: -4.2339582443237305
Batch 60/64 loss: -4.36307430267334
Batch 61/64 loss: -3.9941277503967285
Batch 62/64 loss: -4.347646713256836
Batch 63/64 loss: -4.286865711212158
Batch 64/64 loss: -8.638887405395508
Epoch 494  Train loss: -4.2206506616929  Val loss: -4.627875534529538
Epoch 495
-------------------------------
Batch 1/64 loss: -4.141603469848633
Batch 2/64 loss: -4.140814781188965
Batch 3/64 loss: -4.132965087890625
Batch 4/64 loss: -4.312803268432617
Batch 5/64 loss: -4.195725440979004
Batch 6/64 loss: -4.1464948654174805
Batch 7/64 loss: -4.216273784637451
Batch 8/64 loss: -4.046361923217773
Batch 9/64 loss: -4.112534523010254
Batch 10/64 loss: -4.073586463928223
Batch 11/64 loss: -4.22411584854126
Batch 12/64 loss: -4.255669116973877
Batch 13/64 loss: -4.152120113372803
Batch 14/64 loss: -4.101428031921387
Batch 15/64 loss: -4.1139702796936035
Batch 16/64 loss: -3.802338123321533
Batch 17/64 loss: -4.155455589294434
Batch 18/64 loss: -4.106630802154541
Batch 19/64 loss: -4.076413154602051
Batch 20/64 loss: -4.056302070617676
Batch 21/64 loss: -4.137068748474121
Batch 22/64 loss: -4.0918097496032715
Batch 23/64 loss: -3.690279006958008
Batch 24/64 loss: -4.148581027984619
Batch 25/64 loss: -4.079721927642822
Batch 26/64 loss: -4.151368141174316
Batch 27/64 loss: -4.138802528381348
Batch 28/64 loss: -4.12642240524292
Batch 29/64 loss: -4.241459369659424
Batch 30/64 loss: -3.9477691650390625
Batch 31/64 loss: -4.073912143707275
Batch 32/64 loss: -4.153517723083496
Batch 33/64 loss: -4.188910007476807
Batch 34/64 loss: -4.159327507019043
Batch 35/64 loss: -4.2458600997924805
Batch 36/64 loss: -4.205110549926758
Batch 37/64 loss: -3.9090795516967773
Batch 38/64 loss: -4.118031978607178
Batch 39/64 loss: -4.207409381866455
Batch 40/64 loss: -4.091568946838379
Batch 41/64 loss: -4.382612705230713
Batch 42/64 loss: -4.115926742553711
Batch 43/64 loss: -3.957472324371338
Batch 44/64 loss: -4.118283271789551
Batch 45/64 loss: -4.098072052001953
Batch 46/64 loss: -4.12493371963501
Batch 47/64 loss: -4.267640113830566
Batch 48/64 loss: -4.209839820861816
Batch 49/64 loss: -4.341680526733398
Batch 50/64 loss: -4.291861057281494
Batch 51/64 loss: -4.278648376464844
Batch 52/64 loss: -4.316680431365967
Batch 53/64 loss: -4.117679119110107
Batch 54/64 loss: -4.1404924392700195
Batch 55/64 loss: -4.126502513885498
Batch 56/64 loss: -4.106808662414551
Batch 57/64 loss: -4.25078010559082
Batch 58/64 loss: -4.220404624938965
Batch 59/64 loss: -4.148555755615234
Batch 60/64 loss: -4.142033100128174
Batch 61/64 loss: -4.255660057067871
Batch 62/64 loss: -4.243565082550049
Batch 63/64 loss: -4.231355667114258
Batch 64/64 loss: -8.837154388427734
Epoch 495  Train loss: -4.200548560946595  Val loss: -4.637029418420956
Epoch 496
-------------------------------
Batch 1/64 loss: -4.148379802703857
Batch 2/64 loss: -4.1999359130859375
Batch 3/64 loss: -4.121448516845703
Batch 4/64 loss: -4.220089435577393
Batch 5/64 loss: -3.828320026397705
Batch 6/64 loss: -4.253513336181641
Batch 7/64 loss: -4.30531644821167
Batch 8/64 loss: -4.219616413116455
Batch 9/64 loss: -4.285190582275391
Batch 10/64 loss: -4.179330348968506
Batch 11/64 loss: -4.15216588973999
Batch 12/64 loss: -4.310712814331055
Batch 13/64 loss: -3.824112892150879
Batch 14/64 loss: -4.167142868041992
Batch 15/64 loss: -4.194377899169922
Batch 16/64 loss: -4.245387554168701
Batch 17/64 loss: -4.32043981552124
Batch 18/64 loss: -3.6769180297851562
Batch 19/64 loss: -4.092526912689209
Batch 20/64 loss: -4.325697422027588
Batch 21/64 loss: -4.2178955078125
Batch 22/64 loss: -4.121935844421387
Batch 23/64 loss: -4.189669609069824
Batch 24/64 loss: -4.202661514282227
Batch 25/64 loss: -4.134609222412109
Batch 26/64 loss: -4.247107982635498
Batch 27/64 loss: -4.262120246887207
Batch 28/64 loss: -4.16376256942749
Batch 29/64 loss: -4.0857157707214355
Batch 30/64 loss: -4.0396928787231445
Batch 31/64 loss: -4.258359432220459
Batch 32/64 loss: -4.0374956130981445
Batch 33/64 loss: -4.247050762176514
Batch 34/64 loss: -4.16511869430542
Batch 35/64 loss: -4.0905375480651855
Batch 36/64 loss: -4.059797286987305
Batch 37/64 loss: -4.352819919586182
Batch 38/64 loss: -4.191643238067627
Batch 39/64 loss: -4.259998798370361
Batch 40/64 loss: -4.190332412719727
Batch 41/64 loss: -4.283496856689453
Batch 42/64 loss: -4.126893043518066
Batch 43/64 loss: -4.253817558288574
Batch 44/64 loss: -4.25624942779541
Batch 45/64 loss: -4.295530319213867
Batch 46/64 loss: -3.890805721282959
Batch 47/64 loss: -4.150912761688232
Batch 48/64 loss: -4.179493427276611
Batch 49/64 loss: -4.280333518981934
Batch 50/64 loss: -4.040778160095215
Batch 51/64 loss: -4.182793140411377
Batch 52/64 loss: -4.168203353881836
Batch 53/64 loss: -4.19857931137085
Batch 54/64 loss: -4.213461399078369
Batch 55/64 loss: -4.092403411865234
Batch 56/64 loss: -4.245452404022217
Batch 57/64 loss: -4.287233352661133
Batch 58/64 loss: -4.084777355194092
Batch 59/64 loss: -4.130852222442627
Batch 60/64 loss: -4.320089340209961
Batch 61/64 loss: -4.108253479003906
Batch 62/64 loss: -4.149920463562012
Batch 63/64 loss: -4.0339155197143555
Batch 64/64 loss: -8.731081008911133
Epoch 496  Train loss: -4.221356926712335  Val loss: -4.61330356139088
Epoch 497
-------------------------------
Batch 1/64 loss: -4.166596412658691
Batch 2/64 loss: -4.14440393447876
Batch 3/64 loss: -4.191608428955078
Batch 4/64 loss: -4.23120641708374
Batch 5/64 loss: -4.200660705566406
Batch 6/64 loss: -4.2374701499938965
Batch 7/64 loss: -4.150235652923584
Batch 8/64 loss: -4.114904403686523
Batch 9/64 loss: -4.214606285095215
Batch 10/64 loss: -4.267143726348877
Batch 11/64 loss: -4.2291669845581055
Batch 12/64 loss: -4.167330265045166
Batch 13/64 loss: -4.097673416137695
Batch 14/64 loss: -4.065003871917725
Batch 15/64 loss: -4.000980854034424
Batch 16/64 loss: -4.151955604553223
Batch 17/64 loss: -4.243803024291992
Batch 18/64 loss: -4.082122325897217
Batch 19/64 loss: -4.205068588256836
Batch 20/64 loss: -4.227372646331787
Batch 21/64 loss: -3.7873177528381348
Batch 22/64 loss: -4.10333776473999
Batch 23/64 loss: -4.060337543487549
Batch 24/64 loss: -3.9112095832824707
Batch 25/64 loss: -4.211123466491699
Batch 26/64 loss: -4.041479587554932
Batch 27/64 loss: -4.272063732147217
Batch 28/64 loss: -4.211274147033691
Batch 29/64 loss: -4.108137130737305
Batch 30/64 loss: -4.164343357086182
Batch 31/64 loss: -4.070001602172852
Batch 32/64 loss: -4.298834800720215
Batch 33/64 loss: -4.0951948165893555
Batch 34/64 loss: -4.2027907371521
Batch 35/64 loss: -4.000795841217041
Batch 36/64 loss: -4.344412803649902
Batch 37/64 loss: -4.223299980163574
Batch 38/64 loss: -4.052706241607666
Batch 39/64 loss: -4.259314060211182
Batch 40/64 loss: -4.198459625244141
Batch 41/64 loss: -3.9317097663879395
Batch 42/64 loss: -3.855642318725586
Batch 43/64 loss: -4.171905517578125
Batch 44/64 loss: -4.236067771911621
Batch 45/64 loss: -4.09388542175293
Batch 46/64 loss: -4.105928421020508
Batch 47/64 loss: -4.11665153503418
Batch 48/64 loss: -3.762033462524414
Batch 49/64 loss: -4.163166046142578
Batch 50/64 loss: -4.197896480560303
Batch 51/64 loss: -4.055787086486816
Batch 52/64 loss: -4.196990013122559
Batch 53/64 loss: -4.1012187004089355
Batch 54/64 loss: -4.312812328338623
Batch 55/64 loss: -4.196741104125977
Batch 56/64 loss: -4.256414890289307
Batch 57/64 loss: -4.188013553619385
Batch 58/64 loss: -4.240208625793457
Batch 59/64 loss: -4.281249046325684
Batch 60/64 loss: -4.011999130249023
Batch 61/64 loss: -4.2633795738220215
Batch 62/64 loss: -4.288905143737793
Batch 63/64 loss: -4.225631237030029
Batch 64/64 loss: -8.939065933227539
Epoch 497  Train loss: -4.203361331715303  Val loss: -4.563910009115422
Epoch 498
-------------------------------
Batch 1/64 loss: -4.233653545379639
Batch 2/64 loss: -4.245487213134766
Batch 3/64 loss: -4.190394878387451
Batch 4/64 loss: -4.086138725280762
Batch 5/64 loss: -4.056241512298584
Batch 6/64 loss: -4.331558704376221
Batch 7/64 loss: -4.329374313354492
Batch 8/64 loss: -4.232421875
Batch 9/64 loss: -4.232349395751953
Batch 10/64 loss: -4.185122489929199
Batch 11/64 loss: -4.329532146453857
Batch 12/64 loss: -4.0308451652526855
Batch 13/64 loss: -4.165026664733887
Batch 14/64 loss: -4.330338954925537
Batch 15/64 loss: -4.2966203689575195
Batch 16/64 loss: -4.018110752105713
Batch 17/64 loss: -4.172833442687988
Batch 18/64 loss: -4.187951564788818
Batch 19/64 loss: -4.36147403717041
Batch 20/64 loss: -4.271836757659912
Batch 21/64 loss: -4.159958362579346
Batch 22/64 loss: -3.688920021057129
Batch 23/64 loss: -4.220226287841797
Batch 24/64 loss: -4.1946611404418945
Batch 25/64 loss: -4.104465961456299
Batch 26/64 loss: -4.1792073249816895
Batch 27/64 loss: -4.033638000488281
Batch 28/64 loss: -4.183393478393555
Batch 29/64 loss: -4.167492389678955
Batch 30/64 loss: -4.257007598876953
Batch 31/64 loss: -4.053289890289307
Batch 32/64 loss: -4.099905014038086
Batch 33/64 loss: -4.065719127655029
Batch 34/64 loss: -4.1817450523376465
Batch 35/64 loss: -4.230682373046875
Batch 36/64 loss: -3.3104076385498047
Batch 37/64 loss: -4.239272594451904
Batch 38/64 loss: -4.0605902671813965
Batch 39/64 loss: -4.146289348602295
Batch 40/64 loss: -4.200333118438721
Batch 41/64 loss: -4.1801066398620605
Batch 42/64 loss: -4.212674617767334
Batch 43/64 loss: -3.9995598793029785
Batch 44/64 loss: -4.249443531036377
Batch 45/64 loss: -3.8787455558776855
Batch 46/64 loss: -4.105677604675293
Batch 47/64 loss: -4.043327808380127
Batch 48/64 loss: -4.1578779220581055
Batch 49/64 loss: -4.066689968109131
Batch 50/64 loss: -4.2365403175354
Batch 51/64 loss: -4.124505996704102
Batch 52/64 loss: -4.173373222351074
Batch 53/64 loss: -4.266754150390625
Batch 54/64 loss: -3.867682933807373
Batch 55/64 loss: -4.195950031280518
Batch 56/64 loss: -4.239152431488037
Batch 57/64 loss: -3.8237385749816895
Batch 58/64 loss: -4.29269552230835
Batch 59/64 loss: -4.25381326675415
Batch 60/64 loss: -4.041363716125488
Batch 61/64 loss: -4.310080528259277
Batch 62/64 loss: -4.105532169342041
Batch 63/64 loss: -4.135213375091553
Batch 64/64 loss: -8.560057640075684
Epoch 498  Train loss: -4.1952166351617555  Val loss: -4.628181326430278
Epoch 499
-------------------------------
Batch 1/64 loss: -4.290185928344727
Batch 2/64 loss: -4.27305269241333
Batch 3/64 loss: -4.189092636108398
Batch 4/64 loss: -4.173874855041504
Batch 5/64 loss: -4.253917217254639
Batch 6/64 loss: -4.253974914550781
Batch 7/64 loss: -4.132603645324707
Batch 8/64 loss: -4.173720836639404
Batch 9/64 loss: -4.162546157836914
Batch 10/64 loss: -3.986326217651367
Batch 11/64 loss: -4.248571395874023
Batch 12/64 loss: -4.387558460235596
Batch 13/64 loss: -4.3256516456604
Batch 14/64 loss: -4.3533430099487305
Batch 15/64 loss: -4.225164413452148
Batch 16/64 loss: -4.1078972816467285
Batch 17/64 loss: -3.8163890838623047
Batch 18/64 loss: -4.306365966796875
Batch 19/64 loss: -4.230257511138916
Batch 20/64 loss: -4.322820663452148
Batch 21/64 loss: -4.263873100280762
Batch 22/64 loss: -4.311819553375244
Batch 23/64 loss: -3.9582600593566895
Batch 24/64 loss: -4.172906398773193
Batch 25/64 loss: -4.16316032409668
Batch 26/64 loss: -4.132077693939209
Batch 27/64 loss: -4.300422191619873
Batch 28/64 loss: -3.9504284858703613
Batch 29/64 loss: -4.302472114562988
Batch 30/64 loss: -4.048101425170898
Batch 31/64 loss: -4.308821201324463
Batch 32/64 loss: -4.228391647338867
Batch 33/64 loss: -3.952578544616699
Batch 34/64 loss: -3.7236175537109375
Batch 35/64 loss: -3.9868035316467285
Batch 36/64 loss: -3.9829912185668945
Batch 37/64 loss: -4.15617561340332
Batch 38/64 loss: -4.055978298187256
Batch 39/64 loss: -4.0686235427856445
Batch 40/64 loss: -4.043802738189697
Batch 41/64 loss: -3.7023606300354004
Batch 42/64 loss: -4.253785133361816
Batch 43/64 loss: -4.087008953094482
Batch 44/64 loss: -4.097665309906006
Batch 45/64 loss: -4.124227046966553
Batch 46/64 loss: -3.718319892883301
Batch 47/64 loss: -3.9432525634765625
Batch 48/64 loss: -4.1499786376953125
Batch 49/64 loss: -4.176366806030273
Batch 50/64 loss: -4.165663719177246
Batch 51/64 loss: -4.189065933227539
Batch 52/64 loss: -3.9177966117858887
Batch 53/64 loss: -3.745591163635254
Batch 54/64 loss: -4.243472576141357
Batch 55/64 loss: -4.159364223480225
Batch 56/64 loss: -4.204680442810059
Batch 57/64 loss: -4.038449287414551
Batch 58/64 loss: -3.9133410453796387
Batch 59/64 loss: -3.793445110321045
Batch 60/64 loss: -4.205347537994385
Batch 61/64 loss: -4.233871936798096
Batch 62/64 loss: -4.135626316070557
Batch 63/64 loss: -4.109610080718994
Batch 64/64 loss: -8.629922866821289
Epoch 499  Train loss: -4.174201613781499  Val loss: -4.4620339960576745
Epoch 500
-------------------------------
Batch 1/64 loss: -4.1882734298706055
Batch 2/64 loss: -4.2283782958984375
Batch 3/64 loss: -3.969913959503174
Batch 4/64 loss: -4.103670597076416
Batch 5/64 loss: -3.9888267517089844
Batch 6/64 loss: -4.147057056427002
Batch 7/64 loss: -3.964832305908203
Batch 8/64 loss: -4.17097282409668
Batch 9/64 loss: -4.0004563331604
Batch 10/64 loss: -3.891939640045166
Batch 11/64 loss: -4.177906036376953
Batch 12/64 loss: -4.178321838378906
Batch 13/64 loss: -4.110612392425537
Batch 14/64 loss: -4.078271389007568
Batch 15/64 loss: -4.170117378234863
Batch 16/64 loss: -4.253006458282471
Batch 17/64 loss: -3.832984447479248
Batch 18/64 loss: -3.752279758453369
Batch 19/64 loss: -4.158819198608398
Batch 20/64 loss: -4.190464019775391
Batch 21/64 loss: -4.091320991516113
Batch 22/64 loss: -4.154382228851318
Batch 23/64 loss: -4.334643840789795
Batch 24/64 loss: -3.8704075813293457
Batch 25/64 loss: -3.787754535675049
Batch 26/64 loss: -4.209962368011475
Batch 27/64 loss: -3.8000521659851074
Batch 28/64 loss: -4.1606974601745605
Batch 29/64 loss: -3.9583935737609863
Batch 30/64 loss: -4.11079740524292
Batch 31/64 loss: -4.115614891052246
Batch 32/64 loss: -4.324374198913574
Batch 33/64 loss: -3.856595993041992
Batch 34/64 loss: -4.250290393829346
Batch 35/64 loss: -4.270574569702148
Batch 36/64 loss: -4.290351867675781
Batch 37/64 loss: -4.288807392120361
Batch 38/64 loss: -3.93922758102417
Batch 39/64 loss: -4.263782501220703
Batch 40/64 loss: -4.304521083831787
Batch 41/64 loss: -4.095118045806885
Batch 42/64 loss: -3.916107177734375
Batch 43/64 loss: -4.144103527069092
Batch 44/64 loss: -4.01058292388916
Batch 45/64 loss: -3.9966487884521484
Batch 46/64 loss: -4.227137565612793
Batch 47/64 loss: -4.315986156463623
Batch 48/64 loss: -4.2422661781311035
Batch 49/64 loss: -4.292016506195068
Batch 50/64 loss: -4.320036888122559
Batch 51/64 loss: -3.8274378776550293
Batch 52/64 loss: -4.024923324584961
Batch 53/64 loss: -4.2436628341674805
Batch 54/64 loss: -4.22055196762085
Batch 55/64 loss: -3.8425140380859375
Batch 56/64 loss: -4.254500865936279
Batch 57/64 loss: -4.2998456954956055
Batch 58/64 loss: -4.209478378295898
Batch 59/64 loss: -3.9794998168945312
Batch 60/64 loss: -4.279376029968262
Batch 61/64 loss: -4.224722385406494
Batch 62/64 loss: -3.956704616546631
Batch 63/64 loss: -3.632498264312744
Batch 64/64 loss: -8.763801574707031
Epoch 500  Train loss: -4.157932984595205  Val loss: -4.596922333707514
SLIC undersegmentation error: 0.17155876288659785
SLIC inter-cluster variation: 0.2547478839367162
SLIC number of superpixels: 9669
SLIC superpixels per image: 33.22680412371134
Model loaded
Test metrics:
-5.2732294613553075 0.34518487972508594 40.019817056598505 tensor(0.4148, dtype=torch.float64) 0.7959279930823049 3.4345570316798995 12721
Inference time: 0.0037640165217553627 seconds
Relabeled undersegmentation error: 0.1260219931271477
Relabeled inter-cluster variation: 0.11267462229812733
Relabeled mean superpixels count: 150.18213058419244
Original mean superpixels count: 43.7147766323024
Done!
Job id: 488559
Job id: 492292
