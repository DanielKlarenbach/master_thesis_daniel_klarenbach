Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 4.633786678314209
Batch 2/64 loss: 4.672602653503418
Batch 3/64 loss: 4.630199432373047
Batch 4/64 loss: 4.625583171844482
Batch 5/64 loss: 4.615114688873291
Batch 6/64 loss: 4.597470283508301
Batch 7/64 loss: 4.601018905639648
Batch 8/64 loss: 4.591479301452637
Batch 9/64 loss: 4.588764190673828
Batch 10/64 loss: 4.588900566101074
Batch 11/64 loss: 4.5829949378967285
Batch 12/64 loss: 4.5863776206970215
Batch 13/64 loss: 4.584537029266357
Batch 14/64 loss: 4.5855207443237305
Batch 15/64 loss: 4.580877780914307
Batch 16/64 loss: 4.583014965057373
Batch 17/64 loss: 4.578186511993408
Batch 18/64 loss: 4.577553749084473
Batch 19/64 loss: 4.578213214874268
Batch 20/64 loss: 4.577281951904297
Batch 21/64 loss: 4.579537391662598
Batch 22/64 loss: 4.575165748596191
Batch 23/64 loss: 4.573549747467041
Batch 24/64 loss: 4.5737080574035645
Batch 25/64 loss: 4.577422618865967
Batch 26/64 loss: 4.5708699226379395
Batch 27/64 loss: 4.573430061340332
Batch 28/64 loss: 4.574092388153076
Batch 29/64 loss: 4.5723161697387695
Batch 30/64 loss: 4.567962646484375
Batch 31/64 loss: 4.569454669952393
Batch 32/64 loss: 4.56743049621582
Batch 33/64 loss: 4.5676655769348145
Batch 34/64 loss: 4.565283298492432
Batch 35/64 loss: 4.562065124511719
Batch 36/64 loss: 4.562185287475586
Batch 37/64 loss: 4.55826473236084
Batch 38/64 loss: 4.56086540222168
Batch 39/64 loss: 4.553739547729492
Batch 40/64 loss: 4.549874782562256
Batch 41/64 loss: 4.550085067749023
Batch 42/64 loss: 4.543378829956055
Batch 43/64 loss: 4.55207633972168
Batch 44/64 loss: 4.536933898925781
Batch 45/64 loss: 4.530616760253906
Batch 46/64 loss: 4.507715225219727
Batch 47/64 loss: 4.497348308563232
Batch 48/64 loss: 4.488336563110352
Batch 49/64 loss: 4.460428237915039
Batch 50/64 loss: 4.4552083015441895
Batch 51/64 loss: 4.450566291809082
Batch 52/64 loss: 4.397772789001465
Batch 53/64 loss: 4.421592712402344
Batch 54/64 loss: 4.356134414672852
Batch 55/64 loss: 4.394528388977051
Batch 56/64 loss: 4.397403240203857
Batch 57/64 loss: 4.402060031890869
Batch 58/64 loss: 4.393105983734131
Batch 59/64 loss: 4.36081075668335
Batch 60/64 loss: 4.325616836547852
Batch 61/64 loss: 4.356339454650879
Batch 62/64 loss: 4.427696704864502
Batch 63/64 loss: 4.369686603546143
Batch 64/64 loss: 3.4248812198638916
Epoch 1  Train loss: 4.518564152250103  Val loss: 4.480255893415602
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 4.377677917480469
Batch 2/64 loss: 4.336612224578857
Batch 3/64 loss: 4.346385478973389
Batch 4/64 loss: 4.399893283843994
Batch 5/64 loss: 4.285464286804199
Batch 6/64 loss: 4.329991817474365
Batch 7/64 loss: 4.302311897277832
Batch 8/64 loss: 4.3026275634765625
Batch 9/64 loss: 4.258035659790039
Batch 10/64 loss: 4.233196258544922
Batch 11/64 loss: 4.339747428894043
Batch 12/64 loss: 4.350799560546875
Batch 13/64 loss: 4.211053848266602
Batch 14/64 loss: 4.324272155761719
Batch 15/64 loss: 4.253061771392822
Batch 16/64 loss: 4.224069595336914
Batch 17/64 loss: 4.234553337097168
Batch 18/64 loss: 4.170974254608154
Batch 19/64 loss: 4.199069976806641
Batch 20/64 loss: 4.124223709106445
Batch 21/64 loss: 4.092202186584473
Batch 22/64 loss: 4.281343460083008
Batch 23/64 loss: 4.075052738189697
Batch 24/64 loss: 4.055908203125
Batch 25/64 loss: 4.098474025726318
Batch 26/64 loss: 4.018923759460449
Batch 27/64 loss: 4.104103088378906
Batch 28/64 loss: 3.9980244636535645
Batch 29/64 loss: 4.099902629852295
Batch 30/64 loss: 4.119752883911133
Batch 31/64 loss: 4.020681858062744
Batch 32/64 loss: 4.04701566696167
Batch 33/64 loss: 3.989342212677002
Batch 34/64 loss: 3.975212574005127
Batch 35/64 loss: 3.9465465545654297
Batch 36/64 loss: 3.903902769088745
Batch 37/64 loss: 3.9323620796203613
Batch 38/64 loss: 3.895094871520996
Batch 39/64 loss: 3.8097805976867676
Batch 40/64 loss: 3.912043333053589
Batch 41/64 loss: 4.039287567138672
Batch 42/64 loss: 3.905348777770996
Batch 43/64 loss: 3.7626590728759766
Batch 44/64 loss: 3.933881998062134
Batch 45/64 loss: 3.7718918323516846
Batch 46/64 loss: 3.877507209777832
Batch 47/64 loss: 3.8355636596679688
Batch 48/64 loss: 3.8206119537353516
Batch 49/64 loss: 3.775522232055664
Batch 50/64 loss: 3.7383041381835938
Batch 51/64 loss: 3.8510684967041016
Batch 52/64 loss: 3.699592351913452
Batch 53/64 loss: 3.612243175506592
Batch 54/64 loss: 3.703518867492676
Batch 55/64 loss: 3.673131227493286
Batch 56/64 loss: 3.480541467666626
Batch 57/64 loss: 3.487708568572998
Batch 58/64 loss: 3.4843990802764893
Batch 59/64 loss: 3.693661689758301
Batch 60/64 loss: 3.444148540496826
Batch 61/64 loss: 3.6296701431274414
Batch 62/64 loss: 3.3944520950317383
Batch 63/64 loss: 3.3454947471618652
Batch 64/64 loss: 1.6936776638031006
Epoch 2  Train loss: 3.9562377901638257  Val loss: 3.4650550789849457
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 3.38765811920166
Batch 2/64 loss: 3.4603323936462402
Batch 3/64 loss: 3.1914737224578857
Batch 4/64 loss: 3.394346237182617
Batch 5/64 loss: 3.570178747177124
Batch 6/64 loss: 3.0482981204986572
Batch 7/64 loss: 3.377032518386841
Batch 8/64 loss: 3.334613084793091
Batch 9/64 loss: 3.2226064205169678
Batch 10/64 loss: 3.30426025390625
Batch 11/64 loss: 3.2395153045654297
Batch 12/64 loss: 3.3202831745147705
Batch 13/64 loss: 3.2675890922546387
Batch 14/64 loss: 3.153559923171997
Batch 15/64 loss: 2.9181101322174072
Batch 16/64 loss: 3.0418660640716553
Batch 17/64 loss: 3.627250909805298
Batch 18/64 loss: 3.0206716060638428
Batch 19/64 loss: 3.333056688308716
Batch 20/64 loss: 3.1126699447631836
Batch 21/64 loss: 3.1961143016815186
Batch 22/64 loss: 3.152628183364868
Batch 23/64 loss: 3.0514142513275146
Batch 24/64 loss: 2.957897901535034
Batch 25/64 loss: 2.7997162342071533
Batch 26/64 loss: 2.764014959335327
Batch 27/64 loss: 3.097017765045166
Batch 28/64 loss: 3.1133875846862793
Batch 29/64 loss: 3.243236541748047
Batch 30/64 loss: 2.9625487327575684
Batch 31/64 loss: 2.9811837673187256
Batch 32/64 loss: 3.164015769958496
Batch 33/64 loss: 3.0203800201416016
Batch 34/64 loss: 3.0514206886291504
Batch 35/64 loss: 2.6153151988983154
Batch 36/64 loss: 2.9170591831207275
Batch 37/64 loss: 2.9838802814483643
Batch 38/64 loss: 2.8896584510803223
Batch 39/64 loss: 2.825801372528076
Batch 40/64 loss: 2.816988229751587
Batch 41/64 loss: 2.839535713195801
Batch 42/64 loss: 2.791125774383545
Batch 43/64 loss: 2.8128819465637207
Batch 44/64 loss: 2.643840789794922
Batch 45/64 loss: 2.6229703426361084
Batch 46/64 loss: 2.6817715167999268
Batch 47/64 loss: 3.00571346282959
Batch 48/64 loss: 2.743440628051758
Batch 49/64 loss: 2.580746650695801
Batch 50/64 loss: 2.58417010307312
Batch 51/64 loss: 2.3819117546081543
Batch 52/64 loss: 2.599907636642456
Batch 53/64 loss: 2.678370714187622
Batch 54/64 loss: 2.647674560546875
Batch 55/64 loss: 2.4074065685272217
Batch 56/64 loss: 2.849661350250244
Batch 57/64 loss: 2.596271514892578
Batch 58/64 loss: 2.455091953277588
Batch 59/64 loss: 2.52590274810791
Batch 60/64 loss: 2.5729739665985107
Batch 61/64 loss: 2.6163330078125
Batch 62/64 loss: 2.5750861167907715
Batch 63/64 loss: 2.415611743927002
Batch 64/64 loss: 0.04754495620727539
Epoch 3  Train loss: 2.9112644887438006  Val loss: 2.6368878879088307
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 2.7080235481262207
Batch 2/64 loss: 2.2871365547180176
Batch 3/64 loss: 2.7102861404418945
Batch 4/64 loss: 2.8971333503723145
Batch 5/64 loss: 2.456109046936035
Batch 6/64 loss: 2.2324318885803223
Batch 7/64 loss: 2.4411849975585938
Batch 8/64 loss: 2.1830053329467773
Batch 9/64 loss: 2.2426085472106934
Batch 10/64 loss: 2.4043493270874023
Batch 11/64 loss: 2.50199556350708
Batch 12/64 loss: 2.5732789039611816
Batch 13/64 loss: 2.272993564605713
Batch 14/64 loss: 2.3748221397399902
Batch 15/64 loss: 2.2972965240478516
Batch 16/64 loss: 2.153891086578369
Batch 17/64 loss: 2.2011523246765137
Batch 18/64 loss: 2.0256218910217285
Batch 19/64 loss: 2.3136181831359863
Batch 20/64 loss: 2.312436103820801
Batch 21/64 loss: 2.844188690185547
Batch 22/64 loss: 1.8791556358337402
Batch 23/64 loss: 2.2438535690307617
Batch 24/64 loss: 2.009596347808838
Batch 25/64 loss: 2.2058143615722656
Batch 26/64 loss: 2.3018064498901367
Batch 27/64 loss: 2.0344467163085938
Batch 28/64 loss: 2.1979708671569824
Batch 29/64 loss: 2.0741019248962402
Batch 30/64 loss: 1.940666675567627
Batch 31/64 loss: 2.136197090148926
Batch 32/64 loss: 2.146909236907959
Batch 33/64 loss: 2.195218563079834
Batch 34/64 loss: 2.122803211212158
Batch 35/64 loss: 2.079707622528076
Batch 36/64 loss: 1.8820257186889648
Batch 37/64 loss: 2.10604190826416
Batch 38/64 loss: 2.0179152488708496
Batch 39/64 loss: 2.0986757278442383
Batch 40/64 loss: 1.6421360969543457
Batch 41/64 loss: 1.807849407196045
Batch 42/64 loss: 1.9047818183898926
Batch 43/64 loss: 1.8266053199768066
Batch 44/64 loss: 2.0161514282226562
Batch 45/64 loss: 1.930102825164795
Batch 46/64 loss: 2.1680116653442383
Batch 47/64 loss: 1.7570276260375977
Batch 48/64 loss: 2.0358333587646484
Batch 49/64 loss: 1.7368583679199219
Batch 50/64 loss: 1.88262939453125
Batch 51/64 loss: 1.432584285736084
Batch 52/64 loss: 1.6689667701721191
Batch 53/64 loss: 1.5975522994995117
Batch 54/64 loss: 1.6121540069580078
Batch 55/64 loss: 1.4716386795043945
Batch 56/64 loss: 2.0533008575439453
Batch 57/64 loss: 1.9800314903259277
Batch 58/64 loss: 1.6164236068725586
Batch 59/64 loss: 2.0249552726745605
Batch 60/64 loss: 1.666557788848877
Batch 61/64 loss: 1.8734869956970215
Batch 62/64 loss: 1.4332046508789062
Batch 63/64 loss: 1.9242582321166992
Batch 64/64 loss: -1.6956024169921875
Epoch 4  Train loss: 2.0376136630189183  Val loss: 1.483242651031599
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 1.8529510498046875
Batch 2/64 loss: 1.6630573272705078
Batch 3/64 loss: 1.6131443977355957
Batch 4/64 loss: 1.5483613014221191
Batch 5/64 loss: 1.7319698333740234
Batch 6/64 loss: 1.3971967697143555
Batch 7/64 loss: 1.442023754119873
Batch 8/64 loss: 1.5737237930297852
Batch 9/64 loss: 1.6487436294555664
Batch 10/64 loss: 1.470069408416748
Batch 11/64 loss: 1.5057687759399414
Batch 12/64 loss: 1.5033602714538574
Batch 13/64 loss: 1.924004077911377
Batch 14/64 loss: 1.692859172821045
Batch 15/64 loss: 1.5292515754699707
Batch 16/64 loss: 1.1476798057556152
Batch 17/64 loss: 1.3696279525756836
Batch 18/64 loss: 1.544917106628418
Batch 19/64 loss: 1.3250861167907715
Batch 20/64 loss: 1.4711732864379883
Batch 21/64 loss: 1.429549217224121
Batch 22/64 loss: 1.5702400207519531
Batch 23/64 loss: 1.5164880752563477
Batch 24/64 loss: 1.3021602630615234
Batch 25/64 loss: 1.3766217231750488
Batch 26/64 loss: 0.6795721054077148
Batch 27/64 loss: 1.193814754486084
Batch 28/64 loss: 1.5469751358032227
Batch 29/64 loss: 1.2370867729187012
Batch 30/64 loss: 1.2799949645996094
Batch 31/64 loss: 0.9610886573791504
Batch 32/64 loss: 1.084763526916504
Batch 33/64 loss: 1.0866856575012207
Batch 34/64 loss: 1.319687843322754
Batch 35/64 loss: 1.6036286354064941
Batch 36/64 loss: 1.200718879699707
Batch 37/64 loss: 1.889859676361084
Batch 38/64 loss: 0.9934992790222168
Batch 39/64 loss: 1.6172504425048828
Batch 40/64 loss: 0.9561843872070312
Batch 41/64 loss: 1.5245046615600586
Batch 42/64 loss: 1.1640186309814453
Batch 43/64 loss: 1.0078763961791992
Batch 44/64 loss: 1.7088356018066406
Batch 45/64 loss: 1.058800220489502
Batch 46/64 loss: 1.1561346054077148
Batch 47/64 loss: 0.7301855087280273
Batch 48/64 loss: 0.9000039100646973
Batch 49/64 loss: 1.2799487113952637
Batch 50/64 loss: 1.3596282005310059
Batch 51/64 loss: 1.0997872352600098
Batch 52/64 loss: 0.9689793586730957
Batch 53/64 loss: 0.9261302947998047
Batch 54/64 loss: 1.229722023010254
Batch 55/64 loss: 0.9542627334594727
Batch 56/64 loss: 1.0513935089111328
Batch 57/64 loss: 1.104921817779541
Batch 58/64 loss: 0.660132884979248
Batch 59/64 loss: 0.9754142761230469
Batch 60/64 loss: 1.216825008392334
Batch 61/64 loss: 1.09116792678833
Batch 62/64 loss: 0.9316635131835938
Batch 63/64 loss: 0.8334803581237793
Batch 64/64 loss: -2.463583469390869
Epoch 5  Train loss: 1.2531289287641936  Val loss: 0.8984454964444399
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 0.7900619506835938
Batch 2/64 loss: 0.9032835960388184
Batch 3/64 loss: 1.0940542221069336
Batch 4/64 loss: 1.375028133392334
Batch 5/64 loss: 0.8740372657775879
Batch 6/64 loss: 1.0912823677062988
Batch 7/64 loss: 0.7592792510986328
Batch 8/64 loss: 1.1354546546936035
Batch 9/64 loss: 1.373732566833496
Batch 10/64 loss: 0.8813056945800781
Batch 11/64 loss: 0.46866607666015625
Batch 12/64 loss: 0.7065548896789551
Batch 13/64 loss: 0.8347692489624023
Batch 14/64 loss: 0.8094544410705566
Batch 15/64 loss: 0.47769832611083984
Batch 16/64 loss: 0.9260573387145996
Batch 17/64 loss: 0.5930690765380859
Batch 18/64 loss: 0.535041332244873
Batch 19/64 loss: 0.7988457679748535
Batch 20/64 loss: 0.9180269241333008
Batch 21/64 loss: 0.7884702682495117
Batch 22/64 loss: 0.7958722114562988
Batch 23/64 loss: 0.9984512329101562
Batch 24/64 loss: 0.23802661895751953
Batch 25/64 loss: 0.821709156036377
Batch 26/64 loss: 1.0895214080810547
Batch 27/64 loss: 0.37784337997436523
Batch 28/64 loss: 0.7130436897277832
Batch 29/64 loss: 0.6399726867675781
Batch 30/64 loss: 0.5823864936828613
Batch 31/64 loss: 0.3918490409851074
Batch 32/64 loss: 0.7754755020141602
Batch 33/64 loss: 1.046093463897705
Batch 34/64 loss: 0.9799709320068359
Batch 35/64 loss: 0.8987283706665039
Batch 36/64 loss: 0.5052733421325684
Batch 37/64 loss: 0.5395030975341797
Batch 38/64 loss: 0.837252140045166
Batch 39/64 loss: 0.6777281761169434
Batch 40/64 loss: 0.9342455863952637
Batch 41/64 loss: 0.8644304275512695
Batch 42/64 loss: 0.9766068458557129
Batch 43/64 loss: 0.6504817008972168
Batch 44/64 loss: 0.8548917770385742
Batch 45/64 loss: 0.879340648651123
Batch 46/64 loss: 0.5534305572509766
Batch 47/64 loss: 0.5032377243041992
Batch 48/64 loss: 0.7361054420471191
Batch 49/64 loss: 0.5562992095947266
Batch 50/64 loss: 0.3283114433288574
Batch 51/64 loss: 0.545494556427002
Batch 52/64 loss: 1.0247173309326172
Batch 53/64 loss: 0.37500429153442383
Batch 54/64 loss: 0.6346397399902344
Batch 55/64 loss: 1.0369873046875
Batch 56/64 loss: 1.013617992401123
Batch 57/64 loss: 0.9586262702941895
Batch 58/64 loss: 1.1727972030639648
Batch 59/64 loss: 0.6151256561279297
Batch 60/64 loss: 0.5755891799926758
Batch 61/64 loss: 0.5285000801086426
Batch 62/64 loss: 0.5247688293457031
Batch 63/64 loss: 0.42751407623291016
Batch 64/64 loss: -2.964566230773926
Epoch 6  Train loss: 0.7229837417602539  Val loss: 0.5381992379414666
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.6988644599914551
Batch 2/64 loss: 1.0234031677246094
Batch 3/64 loss: 0.6227498054504395
Batch 4/64 loss: 0.6080121994018555
Batch 5/64 loss: 0.539365291595459
Batch 6/64 loss: 0.7082529067993164
Batch 7/64 loss: 0.36572933197021484
Batch 8/64 loss: 1.4115829467773438
Batch 9/64 loss: 0.8498334884643555
Batch 10/64 loss: 0.7367229461669922
Batch 11/64 loss: 0.5381026268005371
Batch 12/64 loss: 0.7484288215637207
Batch 13/64 loss: 0.4551529884338379
Batch 14/64 loss: 0.46843910217285156
Batch 15/64 loss: 0.37187910079956055
Batch 16/64 loss: 0.449190616607666
Batch 17/64 loss: 0.17464780807495117
Batch 18/64 loss: 0.5651092529296875
Batch 19/64 loss: 0.39288902282714844
Batch 20/64 loss: 0.9871902465820312
Batch 21/64 loss: 0.6640486717224121
Batch 22/64 loss: 0.633028507232666
Batch 23/64 loss: 0.4566173553466797
Batch 24/64 loss: 0.3873882293701172
Batch 25/64 loss: 0.49852943420410156
Batch 26/64 loss: 0.38675498962402344
Batch 27/64 loss: 0.5581374168395996
Batch 28/64 loss: 0.4783053398132324
Batch 29/64 loss: 0.8358888626098633
Batch 30/64 loss: 0.36483049392700195
Batch 31/64 loss: 0.5251469612121582
Batch 32/64 loss: 0.3170137405395508
Batch 33/64 loss: 0.4636044502258301
Batch 34/64 loss: 0.2317657470703125
Batch 35/64 loss: 0.7987117767333984
Batch 36/64 loss: 0.43697261810302734
Batch 37/64 loss: 0.2623910903930664
Batch 38/64 loss: 0.8025417327880859
Batch 39/64 loss: 0.5929651260375977
Batch 40/64 loss: 0.467984676361084
Batch 41/64 loss: 0.21250343322753906
Batch 42/64 loss: 0.6788716316223145
Batch 43/64 loss: 0.10829305648803711
Batch 44/64 loss: 0.13285160064697266
Batch 45/64 loss: -0.06310510635375977
Batch 46/64 loss: 0.5676589012145996
Batch 47/64 loss: 0.4704251289367676
Batch 48/64 loss: 0.5796308517456055
Batch 49/64 loss: 0.2370314598083496
Batch 50/64 loss: 0.40921926498413086
Batch 51/64 loss: 0.3944249153137207
Batch 52/64 loss: 0.4893803596496582
Batch 53/64 loss: 0.22342348098754883
Batch 54/64 loss: 0.4906582832336426
Batch 55/64 loss: 0.5794916152954102
Batch 56/64 loss: 0.9517998695373535
Batch 57/64 loss: 0.3771224021911621
Batch 58/64 loss: 0.8583030700683594
Batch 59/64 loss: 0.48339271545410156
Batch 60/64 loss: 0.3369741439819336
Batch 61/64 loss: 0.38780736923217773
Batch 62/64 loss: 1.151534080505371
Batch 63/64 loss: 0.3411746025085449
Batch 64/64 loss: -3.555600166320801
Epoch 7  Train loss: 0.4801622016757142  Val loss: 0.5489058216003209
Epoch 8
-------------------------------
Batch 1/64 loss: 0.25144100189208984
Batch 2/64 loss: 0.2491588592529297
Batch 3/64 loss: 0.07583808898925781
Batch 4/64 loss: 0.6485419273376465
Batch 5/64 loss: 0.5004487037658691
Batch 6/64 loss: 0.1792607307434082
Batch 7/64 loss: 0.6439938545227051
Batch 8/64 loss: 0.5108203887939453
Batch 9/64 loss: 0.2756032943725586
Batch 10/64 loss: 0.09816741943359375
Batch 11/64 loss: 0.3293781280517578
Batch 12/64 loss: 0.2865467071533203
Batch 13/64 loss: 0.3848991394042969
Batch 14/64 loss: -0.09401178359985352
Batch 15/64 loss: 0.39891576766967773
Batch 16/64 loss: 0.6038269996643066
Batch 17/64 loss: 0.6206240653991699
Batch 18/64 loss: 0.5400385856628418
Batch 19/64 loss: 0.3875541687011719
Batch 20/64 loss: 0.23481512069702148
Batch 21/64 loss: 0.26398134231567383
Batch 22/64 loss: 0.37289953231811523
Batch 23/64 loss: 0.13415002822875977
Batch 24/64 loss: 0.8131871223449707
Batch 25/64 loss: 0.582150936126709
Batch 26/64 loss: 0.2349987030029297
Batch 27/64 loss: 0.14499521255493164
Batch 28/64 loss: 0.4155125617980957
Batch 29/64 loss: 0.059807777404785156
Batch 30/64 loss: 0.5254960060119629
Batch 31/64 loss: 0.5089330673217773
Batch 32/64 loss: 0.2570834159851074
Batch 33/64 loss: 0.6074628829956055
Batch 34/64 loss: 0.8565802574157715
Batch 35/64 loss: 0.8970131874084473
Batch 36/64 loss: 0.15181732177734375
Batch 37/64 loss: 0.4200301170349121
Batch 38/64 loss: 0.3729372024536133
Batch 39/64 loss: 0.3491668701171875
Batch 40/64 loss: 0.17464208602905273
Batch 41/64 loss: 0.8347644805908203
Batch 42/64 loss: 0.6360502243041992
Batch 43/64 loss: 0.6239833831787109
Batch 44/64 loss: 0.35123777389526367
Batch 45/64 loss: 0.5289087295532227
Batch 46/64 loss: 0.3512544631958008
Batch 47/64 loss: 0.3263363838195801
Batch 48/64 loss: 0.731905460357666
Batch 49/64 loss: 0.22760868072509766
Batch 50/64 loss: 0.5746374130249023
Batch 51/64 loss: 0.6328220367431641
Batch 52/64 loss: 0.5707478523254395
Batch 53/64 loss: 1.0370631217956543
Batch 54/64 loss: 0.31277990341186523
Batch 55/64 loss: 0.7793736457824707
Batch 56/64 loss: 0.3844184875488281
Batch 57/64 loss: 0.2927818298339844
Batch 58/64 loss: 0.3470149040222168
Batch 59/64 loss: 0.41001081466674805
Batch 60/64 loss: 0.16386651992797852
Batch 61/64 loss: 0.21488571166992188
Batch 62/64 loss: -0.03859758377075195
Batch 63/64 loss: 0.1369490623474121
Batch 64/64 loss: -3.491476058959961
Epoch 8  Train loss: 0.3620533812279795  Val loss: 0.04887299685134101
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 0.1419844627380371
Batch 2/64 loss: 0.5750432014465332
Batch 3/64 loss: 0.8439493179321289
Batch 4/64 loss: 0.2687416076660156
Batch 5/64 loss: 0.4954190254211426
Batch 6/64 loss: 0.2404918670654297
Batch 7/64 loss: 0.7690930366516113
Batch 8/64 loss: 0.5693273544311523
Batch 9/64 loss: 0.45306396484375
Batch 10/64 loss: 0.2335643768310547
Batch 11/64 loss: -0.07356882095336914
Batch 12/64 loss: 0.3071165084838867
Batch 13/64 loss: 0.10825729370117188
Batch 14/64 loss: 0.5745329856872559
Batch 15/64 loss: 0.1746387481689453
Batch 16/64 loss: 0.28891897201538086
Batch 17/64 loss: 0.031006813049316406
Batch 18/64 loss: 0.25316619873046875
Batch 19/64 loss: -0.01723623275756836
Batch 20/64 loss: 0.4662814140319824
Batch 21/64 loss: 0.13107585906982422
Batch 22/64 loss: 0.11303472518920898
Batch 23/64 loss: -0.14755868911743164
Batch 24/64 loss: -0.002716064453125
Batch 25/64 loss: 0.17148828506469727
Batch 26/64 loss: 0.6442575454711914
Batch 27/64 loss: 0.5473799705505371
Batch 28/64 loss: 0.36554956436157227
Batch 29/64 loss: 0.35244226455688477
Batch 30/64 loss: -0.10235977172851562
Batch 31/64 loss: 0.2748908996582031
Batch 32/64 loss: 0.3625154495239258
Batch 33/64 loss: 0.30048656463623047
Batch 34/64 loss: -0.0759119987487793
Batch 35/64 loss: -0.35251903533935547
Batch 36/64 loss: -0.13262033462524414
Batch 37/64 loss: 0.3430652618408203
Batch 38/64 loss: 0.24565362930297852
Batch 39/64 loss: 0.3186674118041992
Batch 40/64 loss: 0.27838706970214844
Batch 41/64 loss: -0.37639617919921875
Batch 42/64 loss: 0.14336585998535156
Batch 43/64 loss: -0.20075035095214844
Batch 44/64 loss: -0.1270914077758789
Batch 45/64 loss: 0.026335716247558594
Batch 46/64 loss: 0.16483116149902344
Batch 47/64 loss: -0.27478504180908203
Batch 48/64 loss: 0.006916999816894531
Batch 49/64 loss: -0.03715038299560547
Batch 50/64 loss: -0.03765106201171875
Batch 51/64 loss: 0.17789459228515625
Batch 52/64 loss: 0.2017965316772461
Batch 53/64 loss: 0.005969047546386719
Batch 54/64 loss: 0.6252751350402832
Batch 55/64 loss: -0.12370872497558594
Batch 56/64 loss: 0.44291210174560547
Batch 57/64 loss: 0.2611703872680664
Batch 58/64 loss: 0.008195877075195312
Batch 59/64 loss: 0.25217247009277344
Batch 60/64 loss: -0.0597691535949707
Batch 61/64 loss: 0.0038614273071289062
Batch 62/64 loss: 0.11341381072998047
Batch 63/64 loss: -0.02390289306640625
Batch 64/64 loss: -4.068361759185791
Epoch 9  Train loss: 0.13271584791295668  Val loss: 0.10741588422113268
Epoch 10
-------------------------------
Batch 1/64 loss: 0.056221961975097656
Batch 2/64 loss: -0.04376077651977539
Batch 3/64 loss: 0.005871772766113281
Batch 4/64 loss: 0.5706734657287598
Batch 5/64 loss: 0.26647233963012695
Batch 6/64 loss: -0.2539205551147461
Batch 7/64 loss: 0.3245706558227539
Batch 8/64 loss: -0.06688308715820312
Batch 9/64 loss: 0.6101832389831543
Batch 10/64 loss: 0.29845333099365234
Batch 11/64 loss: 0.15714645385742188
Batch 12/64 loss: 0.10764694213867188
Batch 13/64 loss: 0.3383183479309082
Batch 14/64 loss: 0.2750558853149414
Batch 15/64 loss: 0.15461444854736328
Batch 16/64 loss: 0.046401023864746094
Batch 17/64 loss: 0.034852027893066406
Batch 18/64 loss: 0.12286758422851562
Batch 19/64 loss: -0.16888713836669922
Batch 20/64 loss: 0.007180690765380859
Batch 21/64 loss: 0.09698820114135742
Batch 22/64 loss: 0.4045262336730957
Batch 23/64 loss: 0.2813730239868164
Batch 24/64 loss: -0.09577083587646484
Batch 25/64 loss: -0.0801243782043457
Batch 26/64 loss: -0.13904571533203125
Batch 27/64 loss: -0.038056373596191406
Batch 28/64 loss: 0.3609147071838379
Batch 29/64 loss: -0.3058137893676758
Batch 30/64 loss: 0.05343151092529297
Batch 31/64 loss: 0.01655292510986328
Batch 32/64 loss: -0.21253013610839844
Batch 33/64 loss: 0.11577415466308594
Batch 34/64 loss: -0.14943790435791016
Batch 35/64 loss: -0.008046150207519531
Batch 36/64 loss: 0.13436126708984375
Batch 37/64 loss: 0.24406814575195312
Batch 38/64 loss: 0.4723339080810547
Batch 39/64 loss: -0.06319332122802734
Batch 40/64 loss: -0.12362098693847656
Batch 41/64 loss: 0.13718605041503906
Batch 42/64 loss: 0.29204273223876953
Batch 43/64 loss: -0.18313312530517578
Batch 44/64 loss: -0.2319803237915039
Batch 45/64 loss: 0.15735960006713867
Batch 46/64 loss: -0.0031557083129882812
Batch 47/64 loss: -0.13042926788330078
Batch 48/64 loss: -0.06846809387207031
Batch 49/64 loss: 0.35124683380126953
Batch 50/64 loss: -0.46233558654785156
Batch 51/64 loss: 0.04948234558105469
Batch 52/64 loss: -0.008057594299316406
Batch 53/64 loss: 0.4989194869995117
Batch 54/64 loss: -0.27698612213134766
Batch 55/64 loss: -0.1611785888671875
Batch 56/64 loss: 0.09372520446777344
Batch 57/64 loss: 0.21503829956054688
Batch 58/64 loss: 0.1513042449951172
Batch 59/64 loss: -0.39369678497314453
Batch 60/64 loss: -0.2330780029296875
Batch 61/64 loss: -0.39621734619140625
Batch 62/64 loss: -0.20264720916748047
Batch 63/64 loss: -0.33286571502685547
Batch 64/64 loss: -3.885348320007324
Epoch 10  Train loss: -0.003830161749147901  Val loss: -0.2822911239571588
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: 0.5271601676940918
Batch 2/64 loss: 0.24754047393798828
Batch 3/64 loss: -0.0937643051147461
Batch 4/64 loss: -0.3436470031738281
Batch 5/64 loss: -0.21247482299804688
Batch 6/64 loss: -0.08224296569824219
Batch 7/64 loss: 0.2299795150756836
Batch 8/64 loss: -0.25373363494873047
Batch 9/64 loss: 0.018449783325195312
Batch 10/64 loss: -0.2307291030883789
Batch 11/64 loss: -0.3621959686279297
Batch 12/64 loss: -0.13519668579101562
Batch 13/64 loss: 0.2843484878540039
Batch 14/64 loss: -0.23222064971923828
Batch 15/64 loss: 0.17609310150146484
Batch 16/64 loss: 0.2618546485900879
Batch 17/64 loss: -0.05706977844238281
Batch 18/64 loss: 0.22895145416259766
Batch 19/64 loss: -0.2511434555053711
Batch 20/64 loss: -0.3700084686279297
Batch 21/64 loss: -0.1231698989868164
Batch 22/64 loss: 0.3183574676513672
Batch 23/64 loss: -0.42424964904785156
Batch 24/64 loss: -0.11488151550292969
Batch 25/64 loss: -0.14766979217529297
Batch 26/64 loss: 0.3305091857910156
Batch 27/64 loss: -0.41395092010498047
Batch 28/64 loss: 0.6349096298217773
Batch 29/64 loss: -0.43633460998535156
Batch 30/64 loss: -0.11149406433105469
Batch 31/64 loss: -0.23213672637939453
Batch 32/64 loss: -0.19290447235107422
Batch 33/64 loss: -0.4023857116699219
Batch 34/64 loss: -0.1912221908569336
Batch 35/64 loss: -0.3075590133666992
Batch 36/64 loss: 0.030615806579589844
Batch 37/64 loss: -0.13511085510253906
Batch 38/64 loss: -0.10146903991699219
Batch 39/64 loss: -0.116546630859375
Batch 40/64 loss: -0.17616939544677734
Batch 41/64 loss: 0.19974899291992188
Batch 42/64 loss: -0.024423599243164062
Batch 43/64 loss: 0.13628578186035156
Batch 44/64 loss: -0.24587059020996094
Batch 45/64 loss: -0.22669219970703125
Batch 46/64 loss: -0.04570484161376953
Batch 47/64 loss: -0.19316864013671875
Batch 48/64 loss: 0.4662652015686035
Batch 49/64 loss: -0.33250904083251953
Batch 50/64 loss: -0.06873130798339844
Batch 51/64 loss: -0.6301231384277344
Batch 52/64 loss: 0.4234490394592285
Batch 53/64 loss: -0.06373882293701172
Batch 54/64 loss: -0.2540168762207031
Batch 55/64 loss: 0.056461334228515625
Batch 56/64 loss: -0.045889854431152344
Batch 57/64 loss: -0.25458335876464844
Batch 58/64 loss: -0.1902332305908203
Batch 59/64 loss: -0.40221214294433594
Batch 60/64 loss: 0.1588449478149414
Batch 61/64 loss: 0.28612518310546875
Batch 62/64 loss: -0.039748191833496094
Batch 63/64 loss: -0.31731700897216797
Batch 64/64 loss: -4.400897979736328
Epoch 11  Train loss: -0.12347243065927543  Val loss: -0.23983469697617993
Epoch 12
-------------------------------
Batch 1/64 loss: -0.11251163482666016
Batch 2/64 loss: -0.037689208984375
Batch 3/64 loss: -0.5870428085327148
Batch 4/64 loss: -0.11113929748535156
Batch 5/64 loss: -0.22291278839111328
Batch 6/64 loss: -0.3503713607788086
Batch 7/64 loss: -0.18590068817138672
Batch 8/64 loss: 0.18442916870117188
Batch 9/64 loss: 0.43007469177246094
Batch 10/64 loss: -0.3681926727294922
Batch 11/64 loss: -0.0021162033081054688
Batch 12/64 loss: -0.4396095275878906
Batch 13/64 loss: -0.059650421142578125
Batch 14/64 loss: -0.14564132690429688
Batch 15/64 loss: -0.44092273712158203
Batch 16/64 loss: -0.19662952423095703
Batch 17/64 loss: -0.0027751922607421875
Batch 18/64 loss: -0.5890321731567383
Batch 19/64 loss: -0.47930240631103516
Batch 20/64 loss: -0.2534933090209961
Batch 21/64 loss: 0.24042224884033203
Batch 22/64 loss: -0.31490230560302734
Batch 23/64 loss: 0.0040836334228515625
Batch 24/64 loss: 0.022966384887695312
Batch 25/64 loss: 0.2833585739135742
Batch 26/64 loss: -0.21578598022460938
Batch 27/64 loss: -0.23700904846191406
Batch 28/64 loss: -0.20737266540527344
Batch 29/64 loss: 0.009857177734375
Batch 30/64 loss: -0.14743709564208984
Batch 31/64 loss: -0.2354574203491211
Batch 32/64 loss: -0.36696720123291016
Batch 33/64 loss: -0.21549606323242188
Batch 34/64 loss: -0.2512702941894531
Batch 35/64 loss: -0.17165088653564453
Batch 36/64 loss: 0.3239870071411133
Batch 37/64 loss: -0.20449256896972656
Batch 38/64 loss: -0.23261070251464844
Batch 39/64 loss: -0.003930091857910156
Batch 40/64 loss: -0.48989200592041016
Batch 41/64 loss: -0.13225555419921875
Batch 42/64 loss: 0.0016632080078125
Batch 43/64 loss: -0.6725664138793945
Batch 44/64 loss: -0.4573249816894531
Batch 45/64 loss: 0.14055824279785156
Batch 46/64 loss: -0.43769359588623047
Batch 47/64 loss: 0.037354469299316406
Batch 48/64 loss: -0.1831521987915039
Batch 49/64 loss: -0.3110342025756836
Batch 50/64 loss: -0.40512657165527344
Batch 51/64 loss: -0.30160045623779297
Batch 52/64 loss: -0.38343334197998047
Batch 53/64 loss: 0.015900611877441406
Batch 54/64 loss: -0.12371444702148438
Batch 55/64 loss: -0.18886089324951172
Batch 56/64 loss: -0.32642269134521484
Batch 57/64 loss: -0.18795394897460938
Batch 58/64 loss: -0.40279293060302734
Batch 59/64 loss: -0.3685455322265625
Batch 60/64 loss: 0.08111763000488281
Batch 61/64 loss: 0.34360694885253906
Batch 62/64 loss: -0.3683652877807617
Batch 63/64 loss: 0.11313056945800781
Batch 64/64 loss: -4.0282182693481445
Epoch 12  Train loss: -0.21833260854085287  Val loss: -0.4901129732426909
Saving best model, epoch: 12
Epoch 13
-------------------------------
Batch 1/64 loss: -0.5375661849975586
Batch 2/64 loss: -0.3681488037109375
Batch 3/64 loss: -0.16641521453857422
Batch 4/64 loss: -0.19035053253173828
Batch 5/64 loss: -0.31226348876953125
Batch 6/64 loss: -0.19371795654296875
Batch 7/64 loss: -0.5291814804077148
Batch 8/64 loss: -0.1940011978149414
Batch 9/64 loss: -0.45865917205810547
Batch 10/64 loss: -0.22545433044433594
Batch 11/64 loss: -0.25376224517822266
Batch 12/64 loss: -0.19556140899658203
Batch 13/64 loss: -0.7024335861206055
Batch 14/64 loss: 0.036292076110839844
Batch 15/64 loss: -0.41724395751953125
Batch 16/64 loss: -0.5073471069335938
Batch 17/64 loss: -0.2851991653442383
Batch 18/64 loss: -0.3548765182495117
Batch 19/64 loss: -0.32005882263183594
Batch 20/64 loss: -0.36948680877685547
Batch 21/64 loss: -0.06679248809814453
Batch 22/64 loss: -0.1864461898803711
Batch 23/64 loss: -0.07799148559570312
Batch 24/64 loss: -0.6547632217407227
Batch 25/64 loss: -0.40555477142333984
Batch 26/64 loss: -0.23417949676513672
Batch 27/64 loss: -0.16212844848632812
Batch 28/64 loss: -0.019019126892089844
Batch 29/64 loss: -0.41163158416748047
Batch 30/64 loss: -0.44390201568603516
Batch 31/64 loss: -0.07530879974365234
Batch 32/64 loss: -0.26773929595947266
Batch 33/64 loss: -0.4055595397949219
Batch 34/64 loss: -0.24911117553710938
Batch 35/64 loss: -0.16911029815673828
Batch 36/64 loss: -0.27123451232910156
Batch 37/64 loss: 0.13831615447998047
Batch 38/64 loss: -0.3022756576538086
Batch 39/64 loss: -0.035315513610839844
Batch 40/64 loss: -0.3378181457519531
Batch 41/64 loss: -0.4859647750854492
Batch 42/64 loss: -0.36677074432373047
Batch 43/64 loss: -0.1964101791381836
Batch 44/64 loss: -0.41423702239990234
Batch 45/64 loss: -0.25493431091308594
Batch 46/64 loss: -0.27248668670654297
Batch 47/64 loss: -0.3512887954711914
Batch 48/64 loss: -0.25667667388916016
Batch 49/64 loss: 0.0707559585571289
Batch 50/64 loss: -0.2665376663208008
Batch 51/64 loss: -0.6410093307495117
Batch 52/64 loss: -0.22248268127441406
Batch 53/64 loss: 0.09734535217285156
Batch 54/64 loss: -0.0648965835571289
Batch 55/64 loss: -0.43193912506103516
Batch 56/64 loss: 0.18901538848876953
Batch 57/64 loss: -0.43146324157714844
Batch 58/64 loss: -0.5647983551025391
Batch 59/64 loss: -0.6352767944335938
Batch 60/64 loss: -0.5706195831298828
Batch 61/64 loss: -0.4711427688598633
Batch 62/64 loss: -0.07304763793945312
Batch 63/64 loss: -0.45871448516845703
Batch 64/64 loss: -4.258267402648926
Epoch 13  Train loss: -0.3364750245038201  Val loss: -0.4000677783874302
Epoch 14
-------------------------------
Batch 1/64 loss: -0.35631370544433594
Batch 2/64 loss: -0.5926446914672852
Batch 3/64 loss: -0.3335714340209961
Batch 4/64 loss: 0.08458518981933594
Batch 5/64 loss: 0.13053417205810547
Batch 6/64 loss: -0.43129730224609375
Batch 7/64 loss: -0.6315822601318359
Batch 8/64 loss: -0.2927074432373047
Batch 9/64 loss: -0.17169666290283203
Batch 10/64 loss: -0.33728981018066406
Batch 11/64 loss: -0.516326904296875
Batch 12/64 loss: -0.3457975387573242
Batch 13/64 loss: -0.1481304168701172
Batch 14/64 loss: -0.16461467742919922
Batch 15/64 loss: -0.2310810089111328
Batch 16/64 loss: -0.10541534423828125
Batch 17/64 loss: -0.869481086730957
Batch 18/64 loss: -0.5993661880493164
Batch 19/64 loss: -0.34871864318847656
Batch 20/64 loss: 0.4495563507080078
Batch 21/64 loss: -0.45158958435058594
Batch 22/64 loss: -0.7763423919677734
Batch 23/64 loss: -0.39093971252441406
Batch 24/64 loss: -0.3511390686035156
Batch 25/64 loss: -0.4119424819946289
Batch 26/64 loss: -0.8027143478393555
Batch 27/64 loss: -0.3573312759399414
Batch 28/64 loss: -0.22732830047607422
Batch 29/64 loss: 0.04091167449951172
Batch 30/64 loss: 0.38506603240966797
Batch 31/64 loss: -0.4586925506591797
Batch 32/64 loss: -0.5285272598266602
Batch 33/64 loss: -0.46503448486328125
Batch 34/64 loss: -0.3798370361328125
Batch 35/64 loss: -0.03879547119140625
Batch 36/64 loss: -0.3473701477050781
Batch 37/64 loss: 0.31722164154052734
Batch 38/64 loss: -0.2587146759033203
Batch 39/64 loss: 0.2947263717651367
Batch 40/64 loss: -0.05739593505859375
Batch 41/64 loss: -0.27481937408447266
Batch 42/64 loss: -0.6726036071777344
Batch 43/64 loss: -0.609410285949707
Batch 44/64 loss: -0.7440290451049805
Batch 45/64 loss: -0.6114845275878906
Batch 46/64 loss: -0.48729515075683594
Batch 47/64 loss: -0.5877370834350586
Batch 48/64 loss: -0.40511035919189453
Batch 49/64 loss: -0.4408712387084961
Batch 50/64 loss: -0.4129343032836914
Batch 51/64 loss: -0.8125848770141602
Batch 52/64 loss: -0.5693893432617188
Batch 53/64 loss: 0.024542808532714844
Batch 54/64 loss: 0.02579212188720703
Batch 55/64 loss: -0.21949481964111328
Batch 56/64 loss: -0.4181966781616211
Batch 57/64 loss: -0.4070405960083008
Batch 58/64 loss: -0.1610736846923828
Batch 59/64 loss: 0.19991302490234375
Batch 60/64 loss: -0.6057634353637695
Batch 61/64 loss: -0.3020210266113281
Batch 62/64 loss: -0.38771724700927734
Batch 63/64 loss: -0.6740398406982422
Batch 64/64 loss: -4.264374732971191
Epoch 14  Train loss: -0.37378475338804956  Val loss: -0.5382518571676668
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: -0.7717208862304688
Batch 2/64 loss: -0.6294450759887695
Batch 3/64 loss: -0.33191585540771484
Batch 4/64 loss: -0.38674259185791016
Batch 5/64 loss: -0.7858428955078125
Batch 6/64 loss: -0.02708721160888672
Batch 7/64 loss: -0.48729991912841797
Batch 8/64 loss: -0.6737823486328125
Batch 9/64 loss: -0.5380916595458984
Batch 10/64 loss: -0.5976762771606445
Batch 11/64 loss: -0.17184734344482422
Batch 12/64 loss: -0.4720468521118164
Batch 13/64 loss: -0.2900581359863281
Batch 14/64 loss: -0.6471214294433594
Batch 15/64 loss: -0.7517776489257812
Batch 16/64 loss: -0.6316375732421875
Batch 17/64 loss: -0.33794307708740234
Batch 18/64 loss: -0.4097423553466797
Batch 19/64 loss: -0.12354183197021484
Batch 20/64 loss: -0.45946311950683594
Batch 21/64 loss: -0.4233541488647461
Batch 22/64 loss: -0.2541351318359375
Batch 23/64 loss: -0.22104454040527344
Batch 24/64 loss: -0.4177742004394531
Batch 25/64 loss: -0.7797431945800781
Batch 26/64 loss: -0.42989540100097656
Batch 27/64 loss: -0.2646188735961914
Batch 28/64 loss: -0.20023822784423828
Batch 29/64 loss: 0.176971435546875
Batch 30/64 loss: -0.34072399139404297
Batch 31/64 loss: -0.24727630615234375
Batch 32/64 loss: -0.43282318115234375
Batch 33/64 loss: 0.1260080337524414
Batch 34/64 loss: -0.2251272201538086
Batch 35/64 loss: -0.3510408401489258
Batch 36/64 loss: -0.22201824188232422
Batch 37/64 loss: -0.5556392669677734
Batch 38/64 loss: -0.5111656188964844
Batch 39/64 loss: -0.39495086669921875
Batch 40/64 loss: -0.7355947494506836
Batch 41/64 loss: -0.39739513397216797
Batch 42/64 loss: -0.24183368682861328
Batch 43/64 loss: -0.5555906295776367
Batch 44/64 loss: 0.07086181640625
Batch 45/64 loss: -0.6749401092529297
Batch 46/64 loss: -0.4169797897338867
Batch 47/64 loss: -0.44039344787597656
Batch 48/64 loss: -0.4688558578491211
Batch 49/64 loss: -0.32288265228271484
Batch 50/64 loss: -0.5813207626342773
Batch 51/64 loss: -0.5282220840454102
Batch 52/64 loss: -0.4791383743286133
Batch 53/64 loss: -0.37059783935546875
Batch 54/64 loss: -0.25830936431884766
Batch 55/64 loss: -0.04863929748535156
Batch 56/64 loss: -0.5336875915527344
Batch 57/64 loss: -0.3014402389526367
Batch 58/64 loss: -0.27501678466796875
Batch 59/64 loss: 0.409149169921875
Batch 60/64 loss: -0.6243190765380859
Batch 61/64 loss: -0.5316858291625977
Batch 62/64 loss: -0.63671875
Batch 63/64 loss: -0.1326303482055664
Batch 64/64 loss: -4.054440021514893
Epoch 15  Train loss: -0.43310408311731674  Val loss: -0.35376074879439834
Epoch 16
-------------------------------
Batch 1/64 loss: -0.22719383239746094
Batch 2/64 loss: -0.23333740234375
Batch 3/64 loss: -0.38025760650634766
Batch 4/64 loss: -0.34055042266845703
Batch 5/64 loss: -0.021821022033691406
Batch 6/64 loss: -0.20466136932373047
Batch 7/64 loss: -0.21976375579833984
Batch 8/64 loss: -0.5936832427978516
Batch 9/64 loss: -0.1973428726196289
Batch 10/64 loss: -0.9540042877197266
Batch 11/64 loss: -0.3572235107421875
Batch 12/64 loss: -0.3280954360961914
Batch 13/64 loss: -0.25719165802001953
Batch 14/64 loss: -0.6175022125244141
Batch 15/64 loss: 0.07568168640136719
Batch 16/64 loss: -0.34450626373291016
Batch 17/64 loss: -0.722477912902832
Batch 18/64 loss: -0.1513223648071289
Batch 19/64 loss: -0.2642040252685547
Batch 20/64 loss: -0.27424049377441406
Batch 21/64 loss: -0.41609668731689453
Batch 22/64 loss: -0.2272329330444336
Batch 23/64 loss: -0.6014337539672852
Batch 24/64 loss: -0.17778396606445312
Batch 25/64 loss: -0.25490856170654297
Batch 26/64 loss: -0.4544219970703125
Batch 27/64 loss: -0.539515495300293
Batch 28/64 loss: -0.6340904235839844
Batch 29/64 loss: -0.42039966583251953
Batch 30/64 loss: -0.33591556549072266
Batch 31/64 loss: -0.4722166061401367
Batch 32/64 loss: -0.12735557556152344
Batch 33/64 loss: -0.2281475067138672
Batch 34/64 loss: -0.3280601501464844
Batch 35/64 loss: -0.9548969268798828
Batch 36/64 loss: -0.3130836486816406
Batch 37/64 loss: -0.6300163269042969
Batch 38/64 loss: -0.6917686462402344
Batch 39/64 loss: 0.3993844985961914
Batch 40/64 loss: -0.8938055038452148
Batch 41/64 loss: -0.46233463287353516
Batch 42/64 loss: -0.26339244842529297
Batch 43/64 loss: -0.614314079284668
Batch 44/64 loss: -0.675048828125
Batch 45/64 loss: -0.521514892578125
Batch 46/64 loss: -0.7543792724609375
Batch 47/64 loss: -0.24343585968017578
Batch 48/64 loss: -0.799534797668457
Batch 49/64 loss: -0.5107622146606445
Batch 50/64 loss: -0.720728874206543
Batch 51/64 loss: -0.2583780288696289
Batch 52/64 loss: -0.3440208435058594
Batch 53/64 loss: 0.04445934295654297
Batch 54/64 loss: -0.6299819946289062
Batch 55/64 loss: -0.39685916900634766
Batch 56/64 loss: -0.2391815185546875
Batch 57/64 loss: -0.3243141174316406
Batch 58/64 loss: -0.5098724365234375
Batch 59/64 loss: 0.07878684997558594
Batch 60/64 loss: -0.39640140533447266
Batch 61/64 loss: -1.0061492919921875
Batch 62/64 loss: -0.4684314727783203
Batch 63/64 loss: -0.8401393890380859
Batch 64/64 loss: -4.9647674560546875
Epoch 16  Train loss: -0.4626661712048101  Val loss: -0.6757592007876262
Saving best model, epoch: 16
Epoch 17
-------------------------------
Batch 1/64 loss: -0.31563758850097656
Batch 2/64 loss: -0.7047042846679688
Batch 3/64 loss: -0.09379291534423828
Batch 4/64 loss: -0.45171070098876953
Batch 5/64 loss: -0.5112504959106445
Batch 6/64 loss: -0.4279012680053711
Batch 7/64 loss: -0.5670604705810547
Batch 8/64 loss: -0.6745672225952148
Batch 9/64 loss: -1.0128841400146484
Batch 10/64 loss: -0.5946378707885742
Batch 11/64 loss: -0.8028135299682617
Batch 12/64 loss: -0.5637731552124023
Batch 13/64 loss: -0.7273693084716797
Batch 14/64 loss: -0.7625331878662109
Batch 15/64 loss: -0.8484859466552734
Batch 16/64 loss: -0.5274677276611328
Batch 17/64 loss: -0.5220050811767578
Batch 18/64 loss: -0.9218473434448242
Batch 19/64 loss: -0.2994823455810547
Batch 20/64 loss: -0.6374902725219727
Batch 21/64 loss: -0.7120466232299805
Batch 22/64 loss: -0.6137228012084961
Batch 23/64 loss: -0.3288888931274414
Batch 24/64 loss: -0.7040796279907227
Batch 25/64 loss: -0.500457763671875
Batch 26/64 loss: -0.6596460342407227
Batch 27/64 loss: -0.5221538543701172
Batch 28/64 loss: -0.8111057281494141
Batch 29/64 loss: -0.3069343566894531
Batch 30/64 loss: -0.7583913803100586
Batch 31/64 loss: -0.621124267578125
Batch 32/64 loss: -0.8743076324462891
Batch 33/64 loss: -0.2509908676147461
Batch 34/64 loss: -0.5217046737670898
Batch 35/64 loss: -0.6670923233032227
Batch 36/64 loss: -0.6345834732055664
Batch 37/64 loss: -0.26452159881591797
Batch 38/64 loss: -0.7314319610595703
Batch 39/64 loss: -0.6184768676757812
Batch 40/64 loss: 0.10075092315673828
Batch 41/64 loss: -0.6713752746582031
Batch 42/64 loss: -0.4771003723144531
Batch 43/64 loss: -0.16423320770263672
Batch 44/64 loss: -0.30542659759521484
Batch 45/64 loss: -0.4176826477050781
Batch 46/64 loss: -0.7509078979492188
Batch 47/64 loss: -0.21146488189697266
Batch 48/64 loss: -0.724940299987793
Batch 49/64 loss: -0.7444362640380859
Batch 50/64 loss: -0.03667926788330078
Batch 51/64 loss: -0.3149127960205078
Batch 52/64 loss: -0.48508453369140625
Batch 53/64 loss: -0.607518196105957
Batch 54/64 loss: -0.052224159240722656
Batch 55/64 loss: -0.3068666458129883
Batch 56/64 loss: -0.5891389846801758
Batch 57/64 loss: -0.5107507705688477
Batch 58/64 loss: -0.6976308822631836
Batch 59/64 loss: -0.637054443359375
Batch 60/64 loss: -0.5658645629882812
Batch 61/64 loss: -0.7694883346557617
Batch 62/64 loss: -0.8828363418579102
Batch 63/64 loss: -0.5566120147705078
Batch 64/64 loss: -4.616865634918213
Epoch 17  Train loss: -0.594685541414747  Val loss: -0.5986136079244188
Epoch 18
-------------------------------
Batch 1/64 loss: -0.7697010040283203
Batch 2/64 loss: -0.8819665908813477
Batch 3/64 loss: -0.9885110855102539
Batch 4/64 loss: -0.5657968521118164
Batch 5/64 loss: -0.30443477630615234
Batch 6/64 loss: -0.04226112365722656
Batch 7/64 loss: -0.6341123580932617
Batch 8/64 loss: -0.9853591918945312
Batch 9/64 loss: -0.7137250900268555
Batch 10/64 loss: -0.26134777069091797
Batch 11/64 loss: -0.7319307327270508
Batch 12/64 loss: -0.7517814636230469
Batch 13/64 loss: -0.6777381896972656
Batch 14/64 loss: 0.2588472366333008
Batch 15/64 loss: -0.5050172805786133
Batch 16/64 loss: -0.32705020904541016
Batch 17/64 loss: -0.3845863342285156
Batch 18/64 loss: -0.062488555908203125
Batch 19/64 loss: -0.22377300262451172
Batch 20/64 loss: -0.01974773406982422
Batch 21/64 loss: -0.035592079162597656
Batch 22/64 loss: -0.19246864318847656
Batch 23/64 loss: -0.14244365692138672
Batch 24/64 loss: -0.25606346130371094
Batch 25/64 loss: -0.2930717468261719
Batch 26/64 loss: -0.7602910995483398
Batch 27/64 loss: -0.3091621398925781
Batch 28/64 loss: -0.7261161804199219
Batch 29/64 loss: -0.33736705780029297
Batch 30/64 loss: -0.5658483505249023
Batch 31/64 loss: -0.5646982192993164
Batch 32/64 loss: -0.7729787826538086
Batch 33/64 loss: -0.6056528091430664
Batch 34/64 loss: 0.17127323150634766
Batch 35/64 loss: -0.30610084533691406
Batch 36/64 loss: -0.7029256820678711
Batch 37/64 loss: -0.37726593017578125
Batch 38/64 loss: -0.6728954315185547
Batch 39/64 loss: -0.46169471740722656
Batch 40/64 loss: -0.4757804870605469
Batch 41/64 loss: -0.16026592254638672
Batch 42/64 loss: -0.15934276580810547
Batch 43/64 loss: -0.5526466369628906
Batch 44/64 loss: -0.7040224075317383
Batch 45/64 loss: -0.44252967834472656
Batch 46/64 loss: -0.3608236312866211
Batch 47/64 loss: -0.367218017578125
Batch 48/64 loss: -0.5598068237304688
Batch 49/64 loss: -0.31011295318603516
Batch 50/64 loss: -0.800297737121582
Batch 51/64 loss: -0.4339103698730469
Batch 52/64 loss: -0.5933218002319336
Batch 53/64 loss: -0.4375753402709961
Batch 54/64 loss: -0.5005416870117188
Batch 55/64 loss: -0.9479389190673828
Batch 56/64 loss: -0.8955221176147461
Batch 57/64 loss: -0.6282711029052734
Batch 58/64 loss: -0.2856941223144531
Batch 59/64 loss: -0.7435007095336914
Batch 60/64 loss: -0.7502117156982422
Batch 61/64 loss: -0.6855497360229492
Batch 62/64 loss: -0.668675422668457
Batch 63/64 loss: -0.7857160568237305
Batch 64/64 loss: -4.92151403427124
Epoch 18  Train loss: -0.5399883513357125  Val loss: -0.6000590897917338
Epoch 19
-------------------------------
Batch 1/64 loss: -0.6298236846923828
Batch 2/64 loss: -0.8867368698120117
Batch 3/64 loss: -0.5687637329101562
Batch 4/64 loss: -0.4807109832763672
Batch 5/64 loss: 0.3618593215942383
Batch 6/64 loss: -0.6643400192260742
Batch 7/64 loss: -0.8255844116210938
Batch 8/64 loss: -0.5082521438598633
Batch 9/64 loss: -0.38027000427246094
Batch 10/64 loss: -0.6166219711303711
Batch 11/64 loss: -0.5205678939819336
Batch 12/64 loss: -0.6856498718261719
Batch 13/64 loss: -0.8413400650024414
Batch 14/64 loss: -0.51605224609375
Batch 15/64 loss: -0.2216949462890625
Batch 16/64 loss: -0.21390438079833984
Batch 17/64 loss: -0.29253196716308594
Batch 18/64 loss: -0.45248889923095703
Batch 19/64 loss: -0.5499477386474609
Batch 20/64 loss: -0.17737102508544922
Batch 21/64 loss: -0.6258964538574219
Batch 22/64 loss: -0.6524953842163086
Batch 23/64 loss: -0.2538604736328125
Batch 24/64 loss: -0.5367364883422852
Batch 25/64 loss: -0.7934732437133789
Batch 26/64 loss: -0.34121131896972656
Batch 27/64 loss: -0.5796680450439453
Batch 28/64 loss: -0.41693782806396484
Batch 29/64 loss: 0.08942699432373047
Batch 30/64 loss: -0.4939708709716797
Batch 31/64 loss: -0.9278907775878906
Batch 32/64 loss: -0.48500633239746094
Batch 33/64 loss: -0.7353315353393555
Batch 34/64 loss: -0.8203878402709961
Batch 35/64 loss: -0.5127534866333008
Batch 36/64 loss: -0.2565765380859375
Batch 37/64 loss: -0.47667789459228516
Batch 38/64 loss: -0.9851369857788086
Batch 39/64 loss: -0.6672906875610352
Batch 40/64 loss: -0.36541271209716797
Batch 41/64 loss: -0.7611579895019531
Batch 42/64 loss: -0.38957691192626953
Batch 43/64 loss: -0.7647418975830078
Batch 44/64 loss: -0.5684499740600586
Batch 45/64 loss: -0.0877218246459961
Batch 46/64 loss: -0.33071327209472656
Batch 47/64 loss: -0.7097806930541992
Batch 48/64 loss: -0.609257698059082
Batch 49/64 loss: -0.7770223617553711
Batch 50/64 loss: -0.6261491775512695
Batch 51/64 loss: -0.5408105850219727
Batch 52/64 loss: -0.29312705993652344
Batch 53/64 loss: -0.48485565185546875
Batch 54/64 loss: -0.48741626739501953
Batch 55/64 loss: -1.026815414428711
Batch 56/64 loss: -0.4571685791015625
Batch 57/64 loss: -0.9815540313720703
Batch 58/64 loss: -0.5645523071289062
Batch 59/64 loss: -0.6831369400024414
Batch 60/64 loss: -0.5915651321411133
Batch 61/64 loss: -0.37630462646484375
Batch 62/64 loss: -0.35390377044677734
Batch 63/64 loss: -0.5705013275146484
Batch 64/64 loss: -4.838907241821289
Epoch 19  Train loss: -0.5831144370284735  Val loss: -0.7685600883772283
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: -0.8152084350585938
Batch 2/64 loss: -0.9424657821655273
Batch 3/64 loss: -0.5574464797973633
Batch 4/64 loss: -0.5386495590209961
Batch 5/64 loss: -0.5877799987792969
Batch 6/64 loss: -0.5445451736450195
Batch 7/64 loss: -0.2709064483642578
Batch 8/64 loss: -0.6008100509643555
Batch 9/64 loss: -0.4806947708129883
Batch 10/64 loss: -0.6419658660888672
Batch 11/64 loss: -0.22785663604736328
Batch 12/64 loss: -0.6864490509033203
Batch 13/64 loss: -0.6023550033569336
Batch 14/64 loss: -0.8233766555786133
Batch 15/64 loss: -0.44416332244873047
Batch 16/64 loss: -0.6226224899291992
Batch 17/64 loss: -0.7230443954467773
Batch 18/64 loss: -0.7716808319091797
Batch 19/64 loss: -0.5755805969238281
Batch 20/64 loss: -0.554203987121582
Batch 21/64 loss: -0.5733423233032227
Batch 22/64 loss: -0.29312610626220703
Batch 23/64 loss: -0.5363979339599609
Batch 24/64 loss: -0.1682596206665039
Batch 25/64 loss: -0.6978950500488281
Batch 26/64 loss: -0.7102108001708984
Batch 27/64 loss: -0.41744041442871094
Batch 28/64 loss: -1.2511978149414062
Batch 29/64 loss: -0.8493556976318359
Batch 30/64 loss: -0.5311546325683594
Batch 31/64 loss: -0.5911388397216797
Batch 32/64 loss: -0.37056732177734375
Batch 33/64 loss: -0.6099281311035156
Batch 34/64 loss: -0.9665555953979492
Batch 35/64 loss: -0.7590293884277344
Batch 36/64 loss: -0.02847766876220703
Batch 37/64 loss: -0.6831607818603516
Batch 38/64 loss: -0.6451997756958008
Batch 39/64 loss: -0.8093290328979492
Batch 40/64 loss: -0.4622964859008789
Batch 41/64 loss: -0.850316047668457
Batch 42/64 loss: -0.044536590576171875
Batch 43/64 loss: -1.1935338973999023
Batch 44/64 loss: -0.8497438430786133
Batch 45/64 loss: -0.7221031188964844
Batch 46/64 loss: -0.5525922775268555
Batch 47/64 loss: -0.9116029739379883
Batch 48/64 loss: -0.5752754211425781
Batch 49/64 loss: -0.902766227722168
Batch 50/64 loss: -0.6176013946533203
Batch 51/64 loss: -0.8378133773803711
Batch 52/64 loss: 0.12569141387939453
Batch 53/64 loss: -0.6705226898193359
Batch 54/64 loss: -0.6496038436889648
Batch 55/64 loss: -0.9487552642822266
Batch 56/64 loss: -0.8260822296142578
Batch 57/64 loss: -1.030914306640625
Batch 58/64 loss: -0.6575031280517578
Batch 59/64 loss: -0.6243867874145508
Batch 60/64 loss: -0.6001701354980469
Batch 61/64 loss: -0.31420135498046875
Batch 62/64 loss: -0.8580617904663086
Batch 63/64 loss: -0.5053253173828125
Batch 64/64 loss: -4.960574150085449
Epoch 20  Train loss: -0.6792787477081897  Val loss: -0.783366737496812
Saving best model, epoch: 20
Epoch 21
-------------------------------
Batch 1/64 loss: -0.3065299987792969
Batch 2/64 loss: -0.8361387252807617
Batch 3/64 loss: -0.2785367965698242
Batch 4/64 loss: -0.6741609573364258
Batch 5/64 loss: -0.21073627471923828
Batch 6/64 loss: -0.9393320083618164
Batch 7/64 loss: -1.004791259765625
Batch 8/64 loss: -0.587031364440918
Batch 9/64 loss: -0.7450923919677734
Batch 10/64 loss: -0.5577592849731445
Batch 11/64 loss: -0.7166767120361328
Batch 12/64 loss: -0.8350591659545898
Batch 13/64 loss: -0.787175178527832
Batch 14/64 loss: -0.5962457656860352
Batch 15/64 loss: -0.8034696578979492
Batch 16/64 loss: -0.44612979888916016
Batch 17/64 loss: -0.6481456756591797
Batch 18/64 loss: -0.43883228302001953
Batch 19/64 loss: -0.8708410263061523
Batch 20/64 loss: -0.3676271438598633
Batch 21/64 loss: -1.1330318450927734
Batch 22/64 loss: -0.8227605819702148
Batch 23/64 loss: -0.6857023239135742
Batch 24/64 loss: -0.5742559432983398
Batch 25/64 loss: -0.7192201614379883
Batch 26/64 loss: -0.716160774230957
Batch 27/64 loss: -0.43171024322509766
Batch 28/64 loss: -0.9286699295043945
Batch 29/64 loss: -0.4408607482910156
Batch 30/64 loss: -0.8653650283813477
Batch 31/64 loss: -0.5684957504272461
Batch 32/64 loss: -0.9758577346801758
Batch 33/64 loss: -0.4418926239013672
Batch 34/64 loss: -0.9742746353149414
Batch 35/64 loss: -0.7032985687255859
Batch 36/64 loss: -0.5566673278808594
Batch 37/64 loss: -0.7658452987670898
Batch 38/64 loss: -0.7614898681640625
Batch 39/64 loss: -0.8692655563354492
Batch 40/64 loss: -0.8879146575927734
Batch 41/64 loss: -0.8770122528076172
Batch 42/64 loss: -1.1243009567260742
Batch 43/64 loss: -0.6939020156860352
Batch 44/64 loss: -0.5837087631225586
Batch 45/64 loss: -0.8404150009155273
Batch 46/64 loss: -0.6778373718261719
Batch 47/64 loss: -0.6321477890014648
Batch 48/64 loss: -0.9673910140991211
Batch 49/64 loss: -0.626521110534668
Batch 50/64 loss: -0.8950176239013672
Batch 51/64 loss: -0.7466344833374023
Batch 52/64 loss: -0.9558954238891602
Batch 53/64 loss: -0.6628141403198242
Batch 54/64 loss: -1.0946941375732422
Batch 55/64 loss: -0.7644529342651367
Batch 56/64 loss: -0.17720413208007812
Batch 57/64 loss: -0.8500080108642578
Batch 58/64 loss: -0.44881343841552734
Batch 59/64 loss: -0.6143045425415039
Batch 60/64 loss: -0.7114181518554688
Batch 61/64 loss: -0.8975954055786133
Batch 62/64 loss: -0.979191780090332
Batch 63/64 loss: -0.2418050765991211
Batch 64/64 loss: -4.643538475036621
Epoch 21  Train loss: -0.7532359291525448  Val loss: -0.900448671321279
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: -0.6126928329467773
Batch 2/64 loss: -0.897273063659668
Batch 3/64 loss: -0.908595085144043
Batch 4/64 loss: -0.32779979705810547
Batch 5/64 loss: -0.15202999114990234
Batch 6/64 loss: -1.0039949417114258
Batch 7/64 loss: -0.3132143020629883
Batch 8/64 loss: -0.5364923477172852
Batch 9/64 loss: -1.0537357330322266
Batch 10/64 loss: -0.5932073593139648
Batch 11/64 loss: -1.0879154205322266
Batch 12/64 loss: -0.7861509323120117
Batch 13/64 loss: -0.6113014221191406
Batch 14/64 loss: -0.9131050109863281
Batch 15/64 loss: -1.1630287170410156
Batch 16/64 loss: -1.163853645324707
Batch 17/64 loss: -0.9125509262084961
Batch 18/64 loss: -0.9065961837768555
Batch 19/64 loss: -0.7095184326171875
Batch 20/64 loss: -0.1283578872680664
Batch 21/64 loss: -0.8285179138183594
Batch 22/64 loss: -0.9655647277832031
Batch 23/64 loss: -1.056107521057129
Batch 24/64 loss: -0.8159265518188477
Batch 25/64 loss: -0.45591163635253906
Batch 26/64 loss: -0.6439304351806641
Batch 27/64 loss: -0.5274362564086914
Batch 28/64 loss: -1.0933589935302734
Batch 29/64 loss: -0.8252973556518555
Batch 30/64 loss: -0.8594322204589844
Batch 31/64 loss: -0.9852027893066406
Batch 32/64 loss: -0.8181114196777344
Batch 33/64 loss: -0.9812536239624023
Batch 34/64 loss: -0.506993293762207
Batch 35/64 loss: -0.9970979690551758
Batch 36/64 loss: -0.8985910415649414
Batch 37/64 loss: -0.7449836730957031
Batch 38/64 loss: -0.7093124389648438
Batch 39/64 loss: -0.4993104934692383
Batch 40/64 loss: -0.7471094131469727
Batch 41/64 loss: -0.7688837051391602
Batch 42/64 loss: -0.6502132415771484
Batch 43/64 loss: -0.4754610061645508
Batch 44/64 loss: -0.9611234664916992
Batch 45/64 loss: -0.9717016220092773
Batch 46/64 loss: -0.8251075744628906
Batch 47/64 loss: -0.6645603179931641
Batch 48/64 loss: -1.3380088806152344
Batch 49/64 loss: -0.6649293899536133
Batch 50/64 loss: -0.8547554016113281
Batch 51/64 loss: -0.8214082717895508
Batch 52/64 loss: -0.9985980987548828
Batch 53/64 loss: -0.43059825897216797
Batch 54/64 loss: -0.9403085708618164
Batch 55/64 loss: -0.5567502975463867
Batch 56/64 loss: -0.874943733215332
Batch 57/64 loss: -0.4928112030029297
Batch 58/64 loss: -0.7389669418334961
Batch 59/64 loss: -0.9868621826171875
Batch 60/64 loss: -0.8528976440429688
Batch 61/64 loss: -0.7093324661254883
Batch 62/64 loss: -1.0251903533935547
Batch 63/64 loss: -0.5541410446166992
Batch 64/64 loss: -4.612983703613281
Epoch 22  Train loss: -0.8213043960870481  Val loss: -0.9676998308843764
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: -1.0689506530761719
Batch 2/64 loss: -0.9615678787231445
Batch 3/64 loss: -1.2570104598999023
Batch 4/64 loss: -0.7772150039672852
Batch 5/64 loss: -0.990199089050293
Batch 6/64 loss: -0.8159446716308594
Batch 7/64 loss: -0.675140380859375
Batch 8/64 loss: -0.9735879898071289
Batch 9/64 loss: -0.9518394470214844
Batch 10/64 loss: -1.137864112854004
Batch 11/64 loss: -1.052750587463379
Batch 12/64 loss: -0.8677434921264648
Batch 13/64 loss: -0.9166889190673828
Batch 14/64 loss: -0.637141227722168
Batch 15/64 loss: -0.7181205749511719
Batch 16/64 loss: -0.684814453125
Batch 17/64 loss: -0.5348749160766602
Batch 18/64 loss: -0.6209535598754883
Batch 19/64 loss: -0.9532232284545898
Batch 20/64 loss: -0.6798171997070312
Batch 21/64 loss: -0.7412166595458984
Batch 22/64 loss: -1.0983638763427734
Batch 23/64 loss: -0.857508659362793
Batch 24/64 loss: -0.4219236373901367
Batch 25/64 loss: -0.29287147521972656
Batch 26/64 loss: -0.8836574554443359
Batch 27/64 loss: -0.30708885192871094
Batch 28/64 loss: -0.8825740814208984
Batch 29/64 loss: -0.7209720611572266
Batch 30/64 loss: -0.7555675506591797
Batch 31/64 loss: -0.6965341567993164
Batch 32/64 loss: -0.5962133407592773
Batch 33/64 loss: -0.7493000030517578
Batch 34/64 loss: -0.8701562881469727
Batch 35/64 loss: -0.8063859939575195
Batch 36/64 loss: -0.9043798446655273
Batch 37/64 loss: -0.3153190612792969
Batch 38/64 loss: -0.8491992950439453
Batch 39/64 loss: -0.8668117523193359
Batch 40/64 loss: -0.8737373352050781
Batch 41/64 loss: -1.2314491271972656
Batch 42/64 loss: -0.9511890411376953
Batch 43/64 loss: -0.6153707504272461
Batch 44/64 loss: -0.8687038421630859
Batch 45/64 loss: -0.8786630630493164
Batch 46/64 loss: -0.7395544052124023
Batch 47/64 loss: -1.1276788711547852
Batch 48/64 loss: -1.0027141571044922
Batch 49/64 loss: -0.888157844543457
Batch 50/64 loss: -1.31268310546875
Batch 51/64 loss: -0.8140373229980469
Batch 52/64 loss: -0.459442138671875
Batch 53/64 loss: -1.0366134643554688
Batch 54/64 loss: -0.8409891128540039
Batch 55/64 loss: -0.5579986572265625
Batch 56/64 loss: -1.1091184616088867
Batch 57/64 loss: 0.05600547790527344
Batch 58/64 loss: -0.8806495666503906
Batch 59/64 loss: -0.8838958740234375
Batch 60/64 loss: -0.8695344924926758
Batch 61/64 loss: -1.1395740509033203
Batch 62/64 loss: -0.4643516540527344
Batch 63/64 loss: -0.6870193481445312
Batch 64/64 loss: -4.785130500793457
Epoch 23  Train loss: -0.8573719211653167  Val loss: -0.9086614916824394
Epoch 24
-------------------------------
Batch 1/64 loss: -0.2130718231201172
Batch 2/64 loss: -1.149435043334961
Batch 3/64 loss: -1.2136306762695312
Batch 4/64 loss: -0.5919418334960938
Batch 5/64 loss: -0.9620637893676758
Batch 6/64 loss: -0.8974828720092773
Batch 7/64 loss: -1.0797615051269531
Batch 8/64 loss: -0.6944332122802734
Batch 9/64 loss: -0.7530441284179688
Batch 10/64 loss: -0.19767093658447266
Batch 11/64 loss: -0.9143447875976562
Batch 12/64 loss: -0.2658843994140625
Batch 13/64 loss: -0.8059177398681641
Batch 14/64 loss: -1.1249818801879883
Batch 15/64 loss: -0.5651741027832031
Batch 16/64 loss: -0.6687116622924805
Batch 17/64 loss: -0.6814708709716797
Batch 18/64 loss: -0.8554372787475586
Batch 19/64 loss: -0.6131553649902344
Batch 20/64 loss: -0.9372062683105469
Batch 21/64 loss: -0.9311037063598633
Batch 22/64 loss: -0.7812108993530273
Batch 23/64 loss: -0.6444330215454102
Batch 24/64 loss: -0.5514450073242188
Batch 25/64 loss: -0.9997749328613281
Batch 26/64 loss: -1.2082080841064453
Batch 27/64 loss: -0.8757858276367188
Batch 28/64 loss: -0.9283523559570312
Batch 29/64 loss: -0.7967681884765625
Batch 30/64 loss: -0.8118686676025391
Batch 31/64 loss: -0.9533119201660156
Batch 32/64 loss: -0.9100284576416016
Batch 33/64 loss: -0.5064878463745117
Batch 34/64 loss: -1.0387868881225586
Batch 35/64 loss: -1.1449470520019531
Batch 36/64 loss: -1.0489654541015625
Batch 37/64 loss: -0.9624996185302734
Batch 38/64 loss: -0.5602846145629883
Batch 39/64 loss: -1.1220703125
Batch 40/64 loss: -0.30650901794433594
Batch 41/64 loss: -0.7337245941162109
Batch 42/64 loss: -0.8766021728515625
Batch 43/64 loss: -0.7716703414916992
Batch 44/64 loss: -0.9001283645629883
Batch 45/64 loss: 0.12362957000732422
Batch 46/64 loss: -1.2544708251953125
Batch 47/64 loss: -0.814666748046875
Batch 48/64 loss: -0.9156255722045898
Batch 49/64 loss: -0.8191938400268555
Batch 50/64 loss: -0.9021215438842773
Batch 51/64 loss: -0.9943151473999023
Batch 52/64 loss: -0.7982196807861328
Batch 53/64 loss: -0.5310583114624023
Batch 54/64 loss: -0.9336004257202148
Batch 55/64 loss: 0.13094711303710938
Batch 56/64 loss: -0.9855194091796875
Batch 57/64 loss: -0.7648096084594727
Batch 58/64 loss: -1.0654993057250977
Batch 59/64 loss: -0.9632015228271484
Batch 60/64 loss: -0.9045963287353516
Batch 61/64 loss: -0.43267154693603516
Batch 62/64 loss: -1.1553010940551758
Batch 63/64 loss: -0.7108325958251953
Batch 64/64 loss: -5.2961249351501465
Epoch 24  Train loss: -0.8504001262141209  Val loss: -1.0219826059243113
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: -1.150832176208496
Batch 2/64 loss: -0.9346027374267578
Batch 3/64 loss: -1.1124849319458008
Batch 4/64 loss: -0.9233436584472656
Batch 5/64 loss: -0.9268264770507812
Batch 6/64 loss: -1.1595468521118164
Batch 7/64 loss: -0.9709634780883789
Batch 8/64 loss: -1.0814037322998047
Batch 9/64 loss: -1.191218376159668
Batch 10/64 loss: -0.7036056518554688
Batch 11/64 loss: -0.1368732452392578
Batch 12/64 loss: -0.8576850891113281
Batch 13/64 loss: -0.6621255874633789
Batch 14/64 loss: -0.9276456832885742
Batch 15/64 loss: -0.9792919158935547
Batch 16/64 loss: -0.9295225143432617
Batch 17/64 loss: -1.031285285949707
Batch 18/64 loss: -0.8344488143920898
Batch 19/64 loss: -0.7871551513671875
Batch 20/64 loss: -1.113265037536621
Batch 21/64 loss: -1.0762462615966797
Batch 22/64 loss: -1.099410057067871
Batch 23/64 loss: -0.31711673736572266
Batch 24/64 loss: -0.9474287033081055
Batch 25/64 loss: -0.6144170761108398
Batch 26/64 loss: -0.7404775619506836
Batch 27/64 loss: -0.9283790588378906
Batch 28/64 loss: -0.8065557479858398
Batch 29/64 loss: -0.6220064163208008
Batch 30/64 loss: -0.5545282363891602
Batch 31/64 loss: -0.8053741455078125
Batch 32/64 loss: -0.7741489410400391
Batch 33/64 loss: -0.4861259460449219
Batch 34/64 loss: -0.8224544525146484
Batch 35/64 loss: -0.9048318862915039
Batch 36/64 loss: -0.869171142578125
Batch 37/64 loss: -0.9814186096191406
Batch 38/64 loss: -0.9087009429931641
Batch 39/64 loss: -1.106332778930664
Batch 40/64 loss: -0.7952299118041992
Batch 41/64 loss: -1.130716323852539
Batch 42/64 loss: -0.8324794769287109
Batch 43/64 loss: -0.6979055404663086
Batch 44/64 loss: -0.37672901153564453
Batch 45/64 loss: -1.2229394912719727
Batch 46/64 loss: -0.49434661865234375
Batch 47/64 loss: -0.703221321105957
Batch 48/64 loss: -0.9607267379760742
Batch 49/64 loss: -0.5979270935058594
Batch 50/64 loss: -0.8013849258422852
Batch 51/64 loss: -0.7742395401000977
Batch 52/64 loss: -0.4778766632080078
Batch 53/64 loss: -1.2169408798217773
Batch 54/64 loss: -0.9556884765625
Batch 55/64 loss: -0.9767084121704102
Batch 56/64 loss: -0.6364526748657227
Batch 57/64 loss: -0.604487419128418
Batch 58/64 loss: -0.31226539611816406
Batch 59/64 loss: -1.0664243698120117
Batch 60/64 loss: -1.0041027069091797
Batch 61/64 loss: -0.5704565048217773
Batch 62/64 loss: -0.6121082305908203
Batch 63/64 loss: -0.574005126953125
Batch 64/64 loss: -4.665707111358643
Epoch 25  Train loss: -0.8733159888024423  Val loss: -0.9934053191614315
Epoch 26
-------------------------------
Batch 1/64 loss: -1.1842479705810547
Batch 2/64 loss: -1.0275020599365234
Batch 3/64 loss: -0.7368869781494141
Batch 4/64 loss: -0.1844472885131836
Batch 5/64 loss: -0.7902450561523438
Batch 6/64 loss: -0.7893972396850586
Batch 7/64 loss: -1.1954107284545898
Batch 8/64 loss: -0.8827762603759766
Batch 9/64 loss: -1.1059484481811523
Batch 10/64 loss: -0.8408641815185547
Batch 11/64 loss: -0.5933914184570312
Batch 12/64 loss: -0.5516586303710938
Batch 13/64 loss: -0.9036140441894531
Batch 14/64 loss: -0.7852487564086914
Batch 15/64 loss: -0.4252748489379883
Batch 16/64 loss: -0.6332473754882812
Batch 17/64 loss: -1.010711669921875
Batch 18/64 loss: -1.0815582275390625
Batch 19/64 loss: -0.9374723434448242
Batch 20/64 loss: -0.7847146987915039
Batch 21/64 loss: -0.7236871719360352
Batch 22/64 loss: -0.7634897232055664
Batch 23/64 loss: -0.7995662689208984
Batch 24/64 loss: -0.6616334915161133
Batch 25/64 loss: -0.4180889129638672
Batch 26/64 loss: -0.9163370132446289
Batch 27/64 loss: -0.8263578414916992
Batch 28/64 loss: -0.5896644592285156
Batch 29/64 loss: -0.9838924407958984
Batch 30/64 loss: -0.7135429382324219
Batch 31/64 loss: -0.72418212890625
Batch 32/64 loss: -0.7075891494750977
Batch 33/64 loss: -0.688929557800293
Batch 34/64 loss: -0.8467140197753906
Batch 35/64 loss: -0.7437362670898438
Batch 36/64 loss: -1.1606111526489258
Batch 37/64 loss: -0.8134288787841797
Batch 38/64 loss: -0.8996305465698242
Batch 39/64 loss: -0.9247989654541016
Batch 40/64 loss: -1.04058837890625
Batch 41/64 loss: -0.8012485504150391
Batch 42/64 loss: -1.0468425750732422
Batch 43/64 loss: -0.695286750793457
Batch 44/64 loss: -1.1908988952636719
Batch 45/64 loss: -0.9159040451049805
Batch 46/64 loss: -0.7665519714355469
Batch 47/64 loss: -1.1415863037109375
Batch 48/64 loss: -1.1874504089355469
Batch 49/64 loss: -0.5073585510253906
Batch 50/64 loss: -0.7541713714599609
Batch 51/64 loss: -0.6892528533935547
Batch 52/64 loss: -0.9681358337402344
Batch 53/64 loss: -0.791595458984375
Batch 54/64 loss: -0.9835987091064453
Batch 55/64 loss: -1.1470308303833008
Batch 56/64 loss: -0.7539682388305664
Batch 57/64 loss: -0.5972537994384766
Batch 58/64 loss: -1.4220333099365234
Batch 59/64 loss: -1.0631771087646484
Batch 60/64 loss: -0.9569234848022461
Batch 61/64 loss: -0.8298454284667969
Batch 62/64 loss: -0.8518800735473633
Batch 63/64 loss: -1.0974092483520508
Batch 64/64 loss: -5.051082134246826
Epoch 26  Train loss: -0.8994322028814578  Val loss: -1.026280773464347
Saving best model, epoch: 26
Epoch 27
-------------------------------
Batch 1/64 loss: -0.7716245651245117
Batch 2/64 loss: -0.6694049835205078
Batch 3/64 loss: -1.0715265274047852
Batch 4/64 loss: -1.045760154724121
Batch 5/64 loss: -0.8624935150146484
Batch 6/64 loss: -0.7631998062133789
Batch 7/64 loss: -0.6539134979248047
Batch 8/64 loss: -0.9122419357299805
Batch 9/64 loss: -0.8847322463989258
Batch 10/64 loss: -1.0050745010375977
Batch 11/64 loss: -1.2078351974487305
Batch 12/64 loss: -0.7213096618652344
Batch 13/64 loss: -0.8958969116210938
Batch 14/64 loss: -1.158905029296875
Batch 15/64 loss: -0.5860624313354492
Batch 16/64 loss: -1.1692123413085938
Batch 17/64 loss: -0.963348388671875
Batch 18/64 loss: -0.8848838806152344
Batch 19/64 loss: -0.9638605117797852
Batch 20/64 loss: -1.0946331024169922
Batch 21/64 loss: -1.0026655197143555
Batch 22/64 loss: -1.2764959335327148
Batch 23/64 loss: -1.1900653839111328
Batch 24/64 loss: -0.8295774459838867
Batch 25/64 loss: -0.6182622909545898
Batch 26/64 loss: -1.1553192138671875
Batch 27/64 loss: -0.7738380432128906
Batch 28/64 loss: -0.9967899322509766
Batch 29/64 loss: -0.5965461730957031
Batch 30/64 loss: -0.4887561798095703
Batch 31/64 loss: -1.1774959564208984
Batch 32/64 loss: -0.7005348205566406
Batch 33/64 loss: -0.8564119338989258
Batch 34/64 loss: -1.0875892639160156
Batch 35/64 loss: -0.6629476547241211
Batch 36/64 loss: -0.9394607543945312
Batch 37/64 loss: -0.6181373596191406
Batch 38/64 loss: -0.7298135757446289
Batch 39/64 loss: -0.6462602615356445
Batch 40/64 loss: -0.8051824569702148
Batch 41/64 loss: -1.1166057586669922
Batch 42/64 loss: -1.0086727142333984
Batch 43/64 loss: -1.2074546813964844
Batch 44/64 loss: -0.47994422912597656
Batch 45/64 loss: -1.2297248840332031
Batch 46/64 loss: -0.6708097457885742
Batch 47/64 loss: -0.6093540191650391
Batch 48/64 loss: -1.2435693740844727
Batch 49/64 loss: -0.8341121673583984
Batch 50/64 loss: -0.526087760925293
Batch 51/64 loss: -0.9675502777099609
Batch 52/64 loss: -0.8960981369018555
Batch 53/64 loss: -0.636235237121582
Batch 54/64 loss: -0.9735441207885742
Batch 55/64 loss: -0.9874429702758789
Batch 56/64 loss: -1.223862648010254
Batch 57/64 loss: -0.7417192459106445
Batch 58/64 loss: -0.5367250442504883
Batch 59/64 loss: -0.8510198593139648
Batch 60/64 loss: -0.8565645217895508
Batch 61/64 loss: -1.0496816635131836
Batch 62/64 loss: -0.912877082824707
Batch 63/64 loss: -1.1315574645996094
Batch 64/64 loss: -4.682315826416016
Epoch 27  Train loss: -0.9355454089594822  Val loss: -0.997134297164445
Epoch 28
-------------------------------
Batch 1/64 loss: -0.6312894821166992
Batch 2/64 loss: -0.5850095748901367
Batch 3/64 loss: -0.8495559692382812
Batch 4/64 loss: -0.7634305953979492
Batch 5/64 loss: -0.9628591537475586
Batch 6/64 loss: -0.7120084762573242
Batch 7/64 loss: -0.9610824584960938
Batch 8/64 loss: -0.6357412338256836
Batch 9/64 loss: -0.6406011581420898
Batch 10/64 loss: -0.7482624053955078
Batch 11/64 loss: -1.1299238204956055
Batch 12/64 loss: -1.332718849182129
Batch 13/64 loss: -0.7960290908813477
Batch 14/64 loss: -0.7012538909912109
Batch 15/64 loss: -0.6234846115112305
Batch 16/64 loss: -0.9628744125366211
Batch 17/64 loss: -0.8928861618041992
Batch 18/64 loss: -0.8486852645874023
Batch 19/64 loss: -1.247696876525879
Batch 20/64 loss: -1.0262441635131836
Batch 21/64 loss: -0.9419918060302734
Batch 22/64 loss: -0.8834066390991211
Batch 23/64 loss: -0.8996877670288086
Batch 24/64 loss: -1.364511489868164
Batch 25/64 loss: -0.14664840698242188
Batch 26/64 loss: -1.064906120300293
Batch 27/64 loss: -1.229527473449707
Batch 28/64 loss: -1.0210208892822266
Batch 29/64 loss: -0.869873046875
Batch 30/64 loss: -0.5847492218017578
Batch 31/64 loss: -1.245086669921875
Batch 32/64 loss: -0.8484296798706055
Batch 33/64 loss: -1.0405263900756836
Batch 34/64 loss: -1.0819778442382812
Batch 35/64 loss: -0.5679254531860352
Batch 36/64 loss: -1.0365104675292969
Batch 37/64 loss: -1.014613151550293
Batch 38/64 loss: -1.0711774826049805
Batch 39/64 loss: -1.335038185119629
Batch 40/64 loss: -0.3726387023925781
Batch 41/64 loss: -0.8214330673217773
Batch 42/64 loss: -1.040471076965332
Batch 43/64 loss: -1.3474416732788086
Batch 44/64 loss: -1.135232925415039
Batch 45/64 loss: -0.7872724533081055
Batch 46/64 loss: -1.017038345336914
Batch 47/64 loss: -0.771082878112793
Batch 48/64 loss: -1.1907930374145508
Batch 49/64 loss: -0.7443027496337891
Batch 50/64 loss: -1.2425155639648438
Batch 51/64 loss: -1.1588153839111328
Batch 52/64 loss: -1.2178735733032227
Batch 53/64 loss: -0.7756118774414062
Batch 54/64 loss: -0.4493293762207031
Batch 55/64 loss: -0.4616823196411133
Batch 56/64 loss: -0.7565717697143555
Batch 57/64 loss: -1.2081470489501953
Batch 58/64 loss: -0.8379878997802734
Batch 59/64 loss: -1.2691125869750977
Batch 60/64 loss: -1.1847991943359375
Batch 61/64 loss: -1.1508264541625977
Batch 62/64 loss: -0.49248600006103516
Batch 63/64 loss: -1.1692008972167969
Batch 64/64 loss: -5.11154842376709
Epoch 28  Train loss: -0.9684011608946557  Val loss: -1.087963615496134
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: -0.9480953216552734
Batch 2/64 loss: -1.224370002746582
Batch 3/64 loss: -0.9438724517822266
Batch 4/64 loss: -1.233743667602539
Batch 5/64 loss: -1.0468244552612305
Batch 6/64 loss: -0.8697214126586914
Batch 7/64 loss: -0.8947610855102539
Batch 8/64 loss: -0.8801488876342773
Batch 9/64 loss: -1.0651721954345703
Batch 10/64 loss: -1.334620475769043
Batch 11/64 loss: -0.9092559814453125
Batch 12/64 loss: -0.7336301803588867
Batch 13/64 loss: -1.243363380432129
Batch 14/64 loss: -0.8259000778198242
Batch 15/64 loss: -1.4118690490722656
Batch 16/64 loss: -0.6049041748046875
Batch 17/64 loss: -1.0427131652832031
Batch 18/64 loss: -0.8228864669799805
Batch 19/64 loss: -1.0817289352416992
Batch 20/64 loss: -1.0027189254760742
Batch 21/64 loss: -1.156172752380371
Batch 22/64 loss: -0.7609233856201172
Batch 23/64 loss: -0.7813501358032227
Batch 24/64 loss: -1.003392219543457
Batch 25/64 loss: -1.3844785690307617
Batch 26/64 loss: -0.43907737731933594
Batch 27/64 loss: -0.7173595428466797
Batch 28/64 loss: -1.2299928665161133
Batch 29/64 loss: -0.831334114074707
Batch 30/64 loss: -0.6081609725952148
Batch 31/64 loss: -0.6169977188110352
Batch 32/64 loss: -0.7900381088256836
Batch 33/64 loss: -1.2976045608520508
Batch 34/64 loss: -0.6693544387817383
Batch 35/64 loss: -1.0959854125976562
Batch 36/64 loss: -1.0953598022460938
Batch 37/64 loss: -0.8681917190551758
Batch 38/64 loss: -0.5177450180053711
Batch 39/64 loss: -1.1609630584716797
Batch 40/64 loss: -0.9998311996459961
Batch 41/64 loss: -1.0086936950683594
Batch 42/64 loss: -1.108534812927246
Batch 43/64 loss: -1.1303119659423828
Batch 44/64 loss: -0.6595859527587891
Batch 45/64 loss: -1.005753517150879
Batch 46/64 loss: -1.2603063583374023
Batch 47/64 loss: -0.4186687469482422
Batch 48/64 loss: -1.2732343673706055
Batch 49/64 loss: -0.8244104385375977
Batch 50/64 loss: -0.5123977661132812
Batch 51/64 loss: -1.0442438125610352
Batch 52/64 loss: -0.4846534729003906
Batch 53/64 loss: -1.1345996856689453
Batch 54/64 loss: -1.147109031677246
Batch 55/64 loss: -0.8960847854614258
Batch 56/64 loss: -0.9050235748291016
Batch 57/64 loss: -1.3144779205322266
Batch 58/64 loss: -0.8616495132446289
Batch 59/64 loss: -1.0651483535766602
Batch 60/64 loss: -1.125885009765625
Batch 61/64 loss: -1.4024839401245117
Batch 62/64 loss: -0.9250383377075195
Batch 63/64 loss: -1.2848634719848633
Batch 64/64 loss: -3.79669189453125
Epoch 29  Train loss: -1.0005535798914291  Val loss: -1.1277539099204992
Saving best model, epoch: 29
Epoch 30
-------------------------------
Batch 1/64 loss: -0.8736686706542969
Batch 2/64 loss: -1.0039329528808594
Batch 3/64 loss: -1.093388557434082
Batch 4/64 loss: -0.9245309829711914
Batch 5/64 loss: -0.9194297790527344
Batch 6/64 loss: -0.8619918823242188
Batch 7/64 loss: -0.4232950210571289
Batch 8/64 loss: -0.9474554061889648
Batch 9/64 loss: -0.6420068740844727
Batch 10/64 loss: -0.9824514389038086
Batch 11/64 loss: -0.6644039154052734
Batch 12/64 loss: -0.8932514190673828
Batch 13/64 loss: -0.536686897277832
Batch 14/64 loss: -1.1045961380004883
Batch 15/64 loss: -0.8948631286621094
Batch 16/64 loss: -1.1409282684326172
Batch 17/64 loss: -1.0973796844482422
Batch 18/64 loss: -0.5336704254150391
Batch 19/64 loss: -0.6958074569702148
Batch 20/64 loss: -0.41731929779052734
Batch 21/64 loss: -0.7451200485229492
Batch 22/64 loss: -1.3111515045166016
Batch 23/64 loss: -0.7463893890380859
Batch 24/64 loss: -0.6279525756835938
Batch 25/64 loss: -0.8543787002563477
Batch 26/64 loss: -1.024129867553711
Batch 27/64 loss: -0.9602565765380859
Batch 28/64 loss: -1.110483169555664
Batch 29/64 loss: -0.6766633987426758
Batch 30/64 loss: -0.9958438873291016
Batch 31/64 loss: -1.2228870391845703
Batch 32/64 loss: -1.111053466796875
Batch 33/64 loss: -0.4039335250854492
Batch 34/64 loss: -0.8775930404663086
Batch 35/64 loss: -1.3663206100463867
Batch 36/64 loss: -1.078639030456543
Batch 37/64 loss: -0.5954122543334961
Batch 38/64 loss: -1.06878662109375
Batch 39/64 loss: -0.4990234375
Batch 40/64 loss: -1.1124086380004883
Batch 41/64 loss: -1.1213264465332031
Batch 42/64 loss: -1.0235004425048828
Batch 43/64 loss: -1.1570119857788086
Batch 44/64 loss: -0.6103219985961914
Batch 45/64 loss: -0.6272392272949219
Batch 46/64 loss: -0.8198471069335938
Batch 47/64 loss: -1.049790382385254
Batch 48/64 loss: -1.0872812271118164
Batch 49/64 loss: -1.1038999557495117
Batch 50/64 loss: -0.45391273498535156
Batch 51/64 loss: -0.8255605697631836
Batch 52/64 loss: -0.8827848434448242
Batch 53/64 loss: -0.7388248443603516
Batch 54/64 loss: -0.7768077850341797
Batch 55/64 loss: -1.067169189453125
Batch 56/64 loss: -0.7397146224975586
Batch 57/64 loss: -0.5438013076782227
Batch 58/64 loss: -1.2003555297851562
Batch 59/64 loss: -0.6417531967163086
Batch 60/64 loss: -0.5975370407104492
Batch 61/64 loss: -1.1067876815795898
Batch 62/64 loss: -0.8635377883911133
Batch 63/64 loss: -1.030416488647461
Batch 64/64 loss: -4.949624538421631
Epoch 30  Train loss: -0.9226805612152698  Val loss: -1.1586114549145257
Saving best model, epoch: 30
Epoch 31
-------------------------------
Batch 1/64 loss: -1.1499757766723633
Batch 2/64 loss: -1.1947288513183594
Batch 3/64 loss: -0.9716987609863281
Batch 4/64 loss: -1.1678943634033203
Batch 5/64 loss: -0.39815521240234375
Batch 6/64 loss: -0.3341217041015625
Batch 7/64 loss: -1.1538152694702148
Batch 8/64 loss: -0.7263975143432617
Batch 9/64 loss: -1.3497896194458008
Batch 10/64 loss: -0.5951156616210938
Batch 11/64 loss: -0.8087978363037109
Batch 12/64 loss: -1.0253534317016602
Batch 13/64 loss: -1.3219070434570312
Batch 14/64 loss: -1.3604469299316406
Batch 15/64 loss: -1.3759431838989258
Batch 16/64 loss: -1.111166000366211
Batch 17/64 loss: -1.378204345703125
Batch 18/64 loss: -0.5845870971679688
Batch 19/64 loss: -1.019491195678711
Batch 20/64 loss: -1.3449583053588867
Batch 21/64 loss: -0.9969959259033203
Batch 22/64 loss: -1.0626592636108398
Batch 23/64 loss: -0.8519573211669922
Batch 24/64 loss: -0.7192592620849609
Batch 25/64 loss: -1.0323562622070312
Batch 26/64 loss: -1.215163230895996
Batch 27/64 loss: -0.9702930450439453
Batch 28/64 loss: -0.7916269302368164
Batch 29/64 loss: -0.6304922103881836
Batch 30/64 loss: -0.8528604507446289
Batch 31/64 loss: -0.97918701171875
Batch 32/64 loss: -1.148965835571289
Batch 33/64 loss: -0.9026756286621094
Batch 34/64 loss: -1.4712610244750977
Batch 35/64 loss: -0.9487953186035156
Batch 36/64 loss: -1.0116453170776367
Batch 37/64 loss: -0.9125347137451172
Batch 38/64 loss: -1.0258092880249023
Batch 39/64 loss: -1.2310066223144531
Batch 40/64 loss: -0.7204904556274414
Batch 41/64 loss: -0.48874378204345703
Batch 42/64 loss: -0.937408447265625
Batch 43/64 loss: -0.857661247253418
Batch 44/64 loss: -1.0187788009643555
Batch 45/64 loss: -1.0726242065429688
Batch 46/64 loss: -0.6851902008056641
Batch 47/64 loss: -1.1278018951416016
Batch 48/64 loss: -0.9588584899902344
Batch 49/64 loss: -1.0226478576660156
Batch 50/64 loss: -1.1042003631591797
Batch 51/64 loss: -0.6346530914306641
Batch 52/64 loss: -1.2135000228881836
Batch 53/64 loss: -0.9315423965454102
Batch 54/64 loss: -1.3674612045288086
Batch 55/64 loss: -1.0695676803588867
Batch 56/64 loss: -0.8668117523193359
Batch 57/64 loss: -0.9558334350585938
Batch 58/64 loss: -1.1010398864746094
Batch 59/64 loss: -0.9504165649414062
Batch 60/64 loss: -1.0138206481933594
Batch 61/64 loss: -1.2070512771606445
Batch 62/64 loss: -0.9723100662231445
Batch 63/64 loss: -1.0551319122314453
Batch 64/64 loss: -5.114856243133545
Epoch 31  Train loss: -1.039965186399572  Val loss: -1.2649488809592127
Saving best model, epoch: 31
Epoch 32
-------------------------------
Batch 1/64 loss: -0.9123544692993164
Batch 2/64 loss: -0.8477611541748047
Batch 3/64 loss: -0.8932361602783203
Batch 4/64 loss: -0.8604221343994141
Batch 5/64 loss: -1.2805309295654297
Batch 6/64 loss: -0.8913555145263672
Batch 7/64 loss: -1.0722293853759766
Batch 8/64 loss: -1.3064241409301758
Batch 9/64 loss: -1.3409318923950195
Batch 10/64 loss: -0.5323209762573242
Batch 11/64 loss: -1.2607450485229492
Batch 12/64 loss: -1.434861183166504
Batch 13/64 loss: -0.978154182434082
Batch 14/64 loss: -1.1125478744506836
Batch 15/64 loss: -1.0816574096679688
Batch 16/64 loss: -1.01165771484375
Batch 17/64 loss: -1.2293586730957031
Batch 18/64 loss: -1.1487293243408203
Batch 19/64 loss: -1.2381305694580078
Batch 20/64 loss: -1.451446533203125
Batch 21/64 loss: -1.1155033111572266
Batch 22/64 loss: -0.6564540863037109
Batch 23/64 loss: -0.6726455688476562
Batch 24/64 loss: -1.3590621948242188
Batch 25/64 loss: -0.7696657180786133
Batch 26/64 loss: -1.014817237854004
Batch 27/64 loss: -1.1896114349365234
Batch 28/64 loss: -1.432413101196289
Batch 29/64 loss: -1.2216815948486328
Batch 30/64 loss: -1.1213998794555664
Batch 31/64 loss: -0.8514556884765625
Batch 32/64 loss: -1.22100830078125
Batch 33/64 loss: -1.1839065551757812
Batch 34/64 loss: -1.1722898483276367
Batch 35/64 loss: -1.3151702880859375
Batch 36/64 loss: -1.1759252548217773
Batch 37/64 loss: -0.4679403305053711
Batch 38/64 loss: -0.7240962982177734
Batch 39/64 loss: -0.9324836730957031
Batch 40/64 loss: -0.49555015563964844
Batch 41/64 loss: -1.2001371383666992
Batch 42/64 loss: -0.8225412368774414
Batch 43/64 loss: -1.3021869659423828
Batch 44/64 loss: -1.0560016632080078
Batch 45/64 loss: -1.152425765991211
Batch 46/64 loss: -1.1368303298950195
Batch 47/64 loss: -1.4941930770874023
Batch 48/64 loss: -1.0453195571899414
Batch 49/64 loss: -1.050750732421875
Batch 50/64 loss: -1.0755672454833984
Batch 51/64 loss: -0.9505319595336914
Batch 52/64 loss: -1.2060718536376953
Batch 53/64 loss: -1.1265230178833008
Batch 54/64 loss: -1.1362485885620117
Batch 55/64 loss: -0.3887948989868164
Batch 56/64 loss: -1.1343202590942383
Batch 57/64 loss: -1.074570655822754
Batch 58/64 loss: -1.0499515533447266
Batch 59/64 loss: -1.2742671966552734
Batch 60/64 loss: -1.2299327850341797
Batch 61/64 loss: -1.1612977981567383
Batch 62/64 loss: -0.9441633224487305
Batch 63/64 loss: -0.9863224029541016
Batch 64/64 loss: -5.14096736907959
Epoch 32  Train loss: -1.1110997854494582  Val loss: -1.3201641987279518
Saving best model, epoch: 32
Epoch 33
-------------------------------
Batch 1/64 loss: -1.2173376083374023
Batch 2/64 loss: -1.3406658172607422
Batch 3/64 loss: -0.946197509765625
Batch 4/64 loss: -1.515242576599121
Batch 5/64 loss: -0.7510871887207031
Batch 6/64 loss: -1.334024429321289
Batch 7/64 loss: -0.8338108062744141
Batch 8/64 loss: -1.0430116653442383
Batch 9/64 loss: -0.7206602096557617
Batch 10/64 loss: -0.9023103713989258
Batch 11/64 loss: -1.1790742874145508
Batch 12/64 loss: -1.2954998016357422
Batch 13/64 loss: -1.3202428817749023
Batch 14/64 loss: -1.4216804504394531
Batch 15/64 loss: -1.2551403045654297
Batch 16/64 loss: -1.2527008056640625
Batch 17/64 loss: -1.1939668655395508
Batch 18/64 loss: -1.0533971786499023
Batch 19/64 loss: -0.9462575912475586
Batch 20/64 loss: -1.2155637741088867
Batch 21/64 loss: -1.3892936706542969
Batch 22/64 loss: -1.3715391159057617
Batch 23/64 loss: -1.0606002807617188
Batch 24/64 loss: -1.2613410949707031
Batch 25/64 loss: -0.7538299560546875
Batch 26/64 loss: -0.6456489562988281
Batch 27/64 loss: -0.8815040588378906
Batch 28/64 loss: -1.220667839050293
Batch 29/64 loss: -1.5033369064331055
Batch 30/64 loss: -1.1225090026855469
Batch 31/64 loss: -1.1719255447387695
Batch 32/64 loss: -0.8727693557739258
Batch 33/64 loss: -1.6048698425292969
Batch 34/64 loss: -0.7449712753295898
Batch 35/64 loss: -1.4179859161376953
Batch 36/64 loss: -1.0789012908935547
Batch 37/64 loss: -0.6274290084838867
Batch 38/64 loss: -1.0533037185668945
Batch 39/64 loss: -0.5414886474609375
Batch 40/64 loss: -1.3528499603271484
Batch 41/64 loss: -0.9857854843139648
Batch 42/64 loss: -1.4732885360717773
Batch 43/64 loss: -0.9114599227905273
Batch 44/64 loss: -0.8920230865478516
Batch 45/64 loss: -1.3363409042358398
Batch 46/64 loss: -0.8768672943115234
Batch 47/64 loss: -0.8486080169677734
Batch 48/64 loss: -0.9234256744384766
Batch 49/64 loss: -1.4296655654907227
Batch 50/64 loss: -1.1821231842041016
Batch 51/64 loss: -0.8674430847167969
Batch 52/64 loss: -1.1961803436279297
Batch 53/64 loss: -1.177414894104004
Batch 54/64 loss: -0.9395103454589844
Batch 55/64 loss: -1.299652099609375
Batch 56/64 loss: -0.8869867324829102
Batch 57/64 loss: -1.0711078643798828
Batch 58/64 loss: -1.3346328735351562
Batch 59/64 loss: -1.017629623413086
Batch 60/64 loss: -1.1817903518676758
Batch 61/64 loss: -1.3980379104614258
Batch 62/64 loss: -0.9476547241210938
Batch 63/64 loss: -1.2108497619628906
Batch 64/64 loss: -5.084821701049805
Epoch 33  Train loss: -1.154772268557081  Val loss: -1.17126654923167
Epoch 34
-------------------------------
Batch 1/64 loss: -1.1307992935180664
Batch 2/64 loss: -0.9590368270874023
Batch 3/64 loss: -0.9607257843017578
Batch 4/64 loss: -0.9775495529174805
Batch 5/64 loss: -1.3131208419799805
Batch 6/64 loss: -0.7746076583862305
Batch 7/64 loss: -1.2695302963256836
Batch 8/64 loss: -1.3714780807495117
Batch 9/64 loss: -0.8070096969604492
Batch 10/64 loss: -1.3313312530517578
Batch 11/64 loss: -1.021087646484375
Batch 12/64 loss: -1.4208898544311523
Batch 13/64 loss: -1.1741418838500977
Batch 14/64 loss: -0.6559286117553711
Batch 15/64 loss: -0.9053792953491211
Batch 16/64 loss: -1.358677864074707
Batch 17/64 loss: -1.0814237594604492
Batch 18/64 loss: -0.9090337753295898
Batch 19/64 loss: -1.1201181411743164
Batch 20/64 loss: -1.1342945098876953
Batch 21/64 loss: -1.0725536346435547
Batch 22/64 loss: -1.4412260055541992
Batch 23/64 loss: -1.0767383575439453
Batch 24/64 loss: -1.3326663970947266
Batch 25/64 loss: -1.4190301895141602
Batch 26/64 loss: -1.415802001953125
Batch 27/64 loss: -1.2400503158569336
Batch 28/64 loss: -1.1859302520751953
Batch 29/64 loss: -1.237070083618164
Batch 30/64 loss: -1.1361808776855469
Batch 31/64 loss: -1.1089630126953125
Batch 32/64 loss: -1.3520069122314453
Batch 33/64 loss: -0.8546104431152344
Batch 34/64 loss: -1.1463212966918945
Batch 35/64 loss: -1.237870216369629
Batch 36/64 loss: -1.1535959243774414
Batch 37/64 loss: -1.407705307006836
Batch 38/64 loss: -0.8482913970947266
Batch 39/64 loss: -1.2272539138793945
Batch 40/64 loss: -0.9178371429443359
Batch 41/64 loss: -1.541524887084961
Batch 42/64 loss: -1.1125984191894531
Batch 43/64 loss: -1.3923301696777344
Batch 44/64 loss: -1.0388622283935547
Batch 45/64 loss: -1.1210660934448242
Batch 46/64 loss: -1.2902288436889648
Batch 47/64 loss: -1.2252473831176758
Batch 48/64 loss: -0.9240999221801758
Batch 49/64 loss: -1.459101676940918
Batch 50/64 loss: -1.0936450958251953
Batch 51/64 loss: -1.1968441009521484
Batch 52/64 loss: -1.4718570709228516
Batch 53/64 loss: -1.0241708755493164
Batch 54/64 loss: -0.7335281372070312
Batch 55/64 loss: -1.1431846618652344
Batch 56/64 loss: -1.1291227340698242
Batch 57/64 loss: -0.9069900512695312
Batch 58/64 loss: -1.208139419555664
Batch 59/64 loss: -1.0605039596557617
Batch 60/64 loss: -0.9560613632202148
Batch 61/64 loss: -1.2019853591918945
Batch 62/64 loss: -1.1067237854003906
Batch 63/64 loss: -0.9610166549682617
Batch 64/64 loss: -4.87223482131958
Epoch 34  Train loss: -1.1833863108765845  Val loss: -1.306582237846663
Epoch 35
-------------------------------
Batch 1/64 loss: -1.2429208755493164
Batch 2/64 loss: -1.1799182891845703
Batch 3/64 loss: -1.2547359466552734
Batch 4/64 loss: -1.2584476470947266
Batch 5/64 loss: -1.0240850448608398
Batch 6/64 loss: -0.8038406372070312
Batch 7/64 loss: -1.028092384338379
Batch 8/64 loss: -1.2595653533935547
Batch 9/64 loss: -1.124140739440918
Batch 10/64 loss: -1.030630111694336
Batch 11/64 loss: -0.7472934722900391
Batch 12/64 loss: -0.9709281921386719
Batch 13/64 loss: -1.1419668197631836
Batch 14/64 loss: -1.503005027770996
Batch 15/64 loss: -1.0889978408813477
Batch 16/64 loss: -1.3669395446777344
Batch 17/64 loss: -1.3030204772949219
Batch 18/64 loss: -1.504140853881836
Batch 19/64 loss: -1.1658802032470703
Batch 20/64 loss: -0.9344806671142578
Batch 21/64 loss: -0.9793939590454102
Batch 22/64 loss: -1.5022926330566406
Batch 23/64 loss: -1.432525634765625
Batch 24/64 loss: -0.9496746063232422
Batch 25/64 loss: -1.2242164611816406
Batch 26/64 loss: -0.8427152633666992
Batch 27/64 loss: -1.2473363876342773
Batch 28/64 loss: -1.2712831497192383
Batch 29/64 loss: -0.8033723831176758
Batch 30/64 loss: -0.8455734252929688
Batch 31/64 loss: -1.0448017120361328
Batch 32/64 loss: -1.4854621887207031
Batch 33/64 loss: -1.3566112518310547
Batch 34/64 loss: -1.280508041381836
Batch 35/64 loss: -1.1130027770996094
Batch 36/64 loss: -1.647542953491211
Batch 37/64 loss: -1.0320100784301758
Batch 38/64 loss: -1.2463550567626953
Batch 39/64 loss: -0.8927106857299805
Batch 40/64 loss: -1.3121623992919922
Batch 41/64 loss: -1.1845531463623047
Batch 42/64 loss: -1.2008676528930664
Batch 43/64 loss: -1.1502628326416016
Batch 44/64 loss: -0.830174446105957
Batch 45/64 loss: -1.4511852264404297
Batch 46/64 loss: -1.1287450790405273
Batch 47/64 loss: -1.1767282485961914
Batch 48/64 loss: -1.1827993392944336
Batch 49/64 loss: -1.0568151473999023
Batch 50/64 loss: -1.2262630462646484
Batch 51/64 loss: -0.85968017578125
Batch 52/64 loss: -0.562586784362793
Batch 53/64 loss: -1.168900489807129
Batch 54/64 loss: -0.9175100326538086
Batch 55/64 loss: -1.4017372131347656
Batch 56/64 loss: -1.6685333251953125
Batch 57/64 loss: -1.070073127746582
Batch 58/64 loss: -0.35022640228271484
Batch 59/64 loss: -1.1615276336669922
Batch 60/64 loss: -1.5131187438964844
Batch 61/64 loss: -0.9637374877929688
Batch 62/64 loss: -1.3812036514282227
Batch 63/64 loss: -1.5159063339233398
Batch 64/64 loss: -4.763281345367432
Epoch 35  Train loss: -1.1943243569018793  Val loss: -1.3042432647390463
Epoch 36
-------------------------------
Batch 1/64 loss: -1.2272014617919922
Batch 2/64 loss: -1.5086383819580078
Batch 3/64 loss: -1.578390121459961
Batch 4/64 loss: -0.6614322662353516
Batch 5/64 loss: -1.2083196640014648
Batch 6/64 loss: -1.4353761672973633
Batch 7/64 loss: -1.4176874160766602
Batch 8/64 loss: -1.3710765838623047
Batch 9/64 loss: -0.7282896041870117
Batch 10/64 loss: -1.1550931930541992
Batch 11/64 loss: -1.0821752548217773
Batch 12/64 loss: -1.142099380493164
Batch 13/64 loss: -1.258427619934082
Batch 14/64 loss: -1.4331321716308594
Batch 15/64 loss: -0.7272977828979492
Batch 16/64 loss: -1.5551557540893555
Batch 17/64 loss: -1.396498680114746
Batch 18/64 loss: -0.7465839385986328
Batch 19/64 loss: -1.1980295181274414
Batch 20/64 loss: -1.1889047622680664
Batch 21/64 loss: -1.2504291534423828
Batch 22/64 loss: -1.1343822479248047
Batch 23/64 loss: -1.183553695678711
Batch 24/64 loss: -0.9376258850097656
Batch 25/64 loss: -1.1523094177246094
Batch 26/64 loss: -0.44853687286376953
Batch 27/64 loss: -1.5795869827270508
Batch 28/64 loss: -1.411299705505371
Batch 29/64 loss: -0.8683137893676758
Batch 30/64 loss: -0.9860620498657227
Batch 31/64 loss: -0.8218812942504883
Batch 32/64 loss: -0.8038253784179688
Batch 33/64 loss: -1.1171703338623047
Batch 34/64 loss: -1.002293586730957
Batch 35/64 loss: -1.1039371490478516
Batch 36/64 loss: -1.2305679321289062
Batch 37/64 loss: -0.9303884506225586
Batch 38/64 loss: -1.3153448104858398
Batch 39/64 loss: -0.6692361831665039
Batch 40/64 loss: -1.5572052001953125
Batch 41/64 loss: -1.379018783569336
Batch 42/64 loss: -1.436380386352539
Batch 43/64 loss: -1.2869071960449219
Batch 44/64 loss: -0.8517122268676758
Batch 45/64 loss: -1.2488079071044922
Batch 46/64 loss: -1.3586845397949219
Batch 47/64 loss: -1.3315906524658203
Batch 48/64 loss: -0.5445833206176758
Batch 49/64 loss: -1.173492431640625
Batch 50/64 loss: -1.3815279006958008
Batch 51/64 loss: -1.119267463684082
Batch 52/64 loss: -1.220433235168457
Batch 53/64 loss: -1.2742815017700195
Batch 54/64 loss: -1.137033462524414
Batch 55/64 loss: -0.9994935989379883
Batch 56/64 loss: -1.088892936706543
Batch 57/64 loss: -1.482961654663086
Batch 58/64 loss: -1.3332023620605469
Batch 59/64 loss: -1.2956018447875977
Batch 60/64 loss: -0.9986143112182617
Batch 61/64 loss: -1.3715009689331055
Batch 62/64 loss: -0.977264404296875
Batch 63/64 loss: -1.2117929458618164
Batch 64/64 loss: -5.574249744415283
Epoch 36  Train loss: -1.211097932329365  Val loss: -1.3437389622848879
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: -1.3013124465942383
Batch 2/64 loss: -1.3074235916137695
Batch 3/64 loss: -1.1161861419677734
Batch 4/64 loss: -1.285024642944336
Batch 5/64 loss: -1.3122024536132812
Batch 6/64 loss: -0.6329841613769531
Batch 7/64 loss: -1.1144838333129883
Batch 8/64 loss: -1.403533935546875
Batch 9/64 loss: -0.7375240325927734
Batch 10/64 loss: -0.9979686737060547
Batch 11/64 loss: -1.3864316940307617
Batch 12/64 loss: -1.2386884689331055
Batch 13/64 loss: -1.3874502182006836
Batch 14/64 loss: -1.2041358947753906
Batch 15/64 loss: -1.217294692993164
Batch 16/64 loss: -1.3154621124267578
Batch 17/64 loss: -1.178314208984375
Batch 18/64 loss: -1.4882698059082031
Batch 19/64 loss: -1.2454147338867188
Batch 20/64 loss: -1.3614473342895508
Batch 21/64 loss: -1.3633956909179688
Batch 22/64 loss: -1.3879566192626953
Batch 23/64 loss: -0.981968879699707
Batch 24/64 loss: -1.5477104187011719
Batch 25/64 loss: -1.494394302368164
Batch 26/64 loss: -1.1528129577636719
Batch 27/64 loss: -0.8095388412475586
Batch 28/64 loss: -1.2910280227661133
Batch 29/64 loss: -1.3994522094726562
Batch 30/64 loss: -1.118882179260254
Batch 31/64 loss: -1.2225675582885742
Batch 32/64 loss: -1.453969955444336
Batch 33/64 loss: -1.1535978317260742
Batch 34/64 loss: -1.3042840957641602
Batch 35/64 loss: -0.7257881164550781
Batch 36/64 loss: -1.1305856704711914
Batch 37/64 loss: -1.3852348327636719
Batch 38/64 loss: -1.1323862075805664
Batch 39/64 loss: -0.9778642654418945
Batch 40/64 loss: -0.9336452484130859
Batch 41/64 loss: -1.2471799850463867
Batch 42/64 loss: -1.3736333847045898
Batch 43/64 loss: -1.4701423645019531
Batch 44/64 loss: -1.0364809036254883
Batch 45/64 loss: -1.426661491394043
Batch 46/64 loss: -1.2351932525634766
Batch 47/64 loss: -1.2450618743896484
Batch 48/64 loss: -0.9475498199462891
Batch 49/64 loss: -1.4969425201416016
Batch 50/64 loss: -0.8245630264282227
Batch 51/64 loss: -1.3752994537353516
Batch 52/64 loss: -0.923548698425293
Batch 53/64 loss: -1.1997394561767578
Batch 54/64 loss: -0.8172016143798828
Batch 55/64 loss: -1.2463197708129883
Batch 56/64 loss: -1.3371171951293945
Batch 57/64 loss: -0.8272237777709961
Batch 58/64 loss: -1.2572650909423828
Batch 59/64 loss: -1.1902885437011719
Batch 60/64 loss: -0.8870086669921875
Batch 61/64 loss: -1.3300018310546875
Batch 62/64 loss: -1.1920194625854492
Batch 63/64 loss: -1.1584930419921875
Batch 64/64 loss: -5.27073860168457
Epoch 37  Train loss: -1.2422997044581994  Val loss: -1.318660854064312
Epoch 38
-------------------------------
Batch 1/64 loss: -1.0232057571411133
Batch 2/64 loss: -1.4990453720092773
Batch 3/64 loss: -1.0897397994995117
Batch 4/64 loss: -1.2148361206054688
Batch 5/64 loss: -1.310835838317871
Batch 6/64 loss: -0.7863340377807617
Batch 7/64 loss: -0.9338102340698242
Batch 8/64 loss: -1.4611272811889648
Batch 9/64 loss: -1.3291244506835938
Batch 10/64 loss: -0.9425010681152344
Batch 11/64 loss: -1.3538799285888672
Batch 12/64 loss: -1.1050806045532227
Batch 13/64 loss: -1.5061330795288086
Batch 14/64 loss: -1.4283828735351562
Batch 15/64 loss: -1.073155403137207
Batch 16/64 loss: -1.1447820663452148
Batch 17/64 loss: -1.1830615997314453
Batch 18/64 loss: -0.9897928237915039
Batch 19/64 loss: -1.2018251419067383
Batch 20/64 loss: -1.123361587524414
Batch 21/64 loss: -1.1003456115722656
Batch 22/64 loss: -1.481114387512207
Batch 23/64 loss: -1.0983619689941406
Batch 24/64 loss: -1.3698101043701172
Batch 25/64 loss: -1.1871318817138672
Batch 26/64 loss: -1.2421493530273438
Batch 27/64 loss: -1.1785154342651367
Batch 28/64 loss: -1.1770973205566406
Batch 29/64 loss: -1.3769197463989258
Batch 30/64 loss: -0.942108154296875
Batch 31/64 loss: -1.2716197967529297
Batch 32/64 loss: -1.2140560150146484
Batch 33/64 loss: -1.128204345703125
Batch 34/64 loss: -1.4408798217773438
Batch 35/64 loss: -1.1395034790039062
Batch 36/64 loss: -1.0575799942016602
Batch 37/64 loss: -1.4671154022216797
Batch 38/64 loss: -1.2699470520019531
Batch 39/64 loss: -1.3521356582641602
Batch 40/64 loss: -1.2717456817626953
Batch 41/64 loss: -1.1183147430419922
Batch 42/64 loss: -1.0522956848144531
Batch 43/64 loss: -1.1880512237548828
Batch 44/64 loss: -0.9466276168823242
Batch 45/64 loss: -0.8927431106567383
Batch 46/64 loss: -1.3150482177734375
Batch 47/64 loss: -1.289656639099121
Batch 48/64 loss: -1.2495288848876953
Batch 49/64 loss: -1.4259490966796875
Batch 50/64 loss: -0.7734613418579102
Batch 51/64 loss: -1.0328598022460938
Batch 52/64 loss: -0.8843545913696289
Batch 53/64 loss: -1.2642908096313477
Batch 54/64 loss: -1.155679702758789
Batch 55/64 loss: -1.500223159790039
Batch 56/64 loss: -1.2994203567504883
Batch 57/64 loss: -1.181859016418457
Batch 58/64 loss: -1.3654975891113281
Batch 59/64 loss: -1.0609474182128906
Batch 60/64 loss: -1.232412338256836
Batch 61/64 loss: -1.3480091094970703
Batch 62/64 loss: -1.3587512969970703
Batch 63/64 loss: -0.6122493743896484
Batch 64/64 loss: -5.691496849060059
Epoch 38  Train loss: -1.2436581966923732  Val loss: -1.27033228399008
Epoch 39
-------------------------------
Batch 1/64 loss: -0.7947711944580078
Batch 2/64 loss: -1.6742677688598633
Batch 3/64 loss: -1.3602428436279297
Batch 4/64 loss: -0.7480630874633789
Batch 5/64 loss: -0.9780473709106445
Batch 6/64 loss: -1.1189374923706055
Batch 7/64 loss: -1.613816261291504
Batch 8/64 loss: -0.5886135101318359
Batch 9/64 loss: -0.9902381896972656
Batch 10/64 loss: -1.1334056854248047
Batch 11/64 loss: -1.2798471450805664
Batch 12/64 loss: -1.287846565246582
Batch 13/64 loss: -0.9001140594482422
Batch 14/64 loss: -1.171895980834961
Batch 15/64 loss: -1.0266399383544922
Batch 16/64 loss: -1.5559101104736328
Batch 17/64 loss: -1.5638198852539062
Batch 18/64 loss: -1.2284049987792969
Batch 19/64 loss: -1.1587886810302734
Batch 20/64 loss: -1.081385612487793
Batch 21/64 loss: -0.864811897277832
Batch 22/64 loss: -1.5315790176391602
Batch 23/64 loss: -1.1482505798339844
Batch 24/64 loss: -0.6425447463989258
Batch 25/64 loss: -1.2917985916137695
Batch 26/64 loss: -1.6161975860595703
Batch 27/64 loss: -0.8978176116943359
Batch 28/64 loss: -1.5153617858886719
Batch 29/64 loss: -1.1678924560546875
Batch 30/64 loss: -1.268477439880371
Batch 31/64 loss: -1.469461441040039
Batch 32/64 loss: -1.3660268783569336
Batch 33/64 loss: -1.1818227767944336
Batch 34/64 loss: -1.2460699081420898
Batch 35/64 loss: -1.1907711029052734
Batch 36/64 loss: -1.4028682708740234
Batch 37/64 loss: -1.6431493759155273
Batch 38/64 loss: -1.2739315032958984
Batch 39/64 loss: -1.3143997192382812
Batch 40/64 loss: -1.036646842956543
Batch 41/64 loss: -1.3263483047485352
Batch 42/64 loss: -0.9280595779418945
Batch 43/64 loss: -1.3498516082763672
Batch 44/64 loss: -1.5553722381591797
Batch 45/64 loss: -1.0979938507080078
Batch 46/64 loss: -1.1557598114013672
Batch 47/64 loss: -1.4250869750976562
Batch 48/64 loss: -1.3649787902832031
Batch 49/64 loss: -1.4362659454345703
Batch 50/64 loss: -1.1538715362548828
Batch 51/64 loss: -1.543950080871582
Batch 52/64 loss: -1.4936962127685547
Batch 53/64 loss: -1.4915647506713867
Batch 54/64 loss: -1.150289535522461
Batch 55/64 loss: -1.2572565078735352
Batch 56/64 loss: -0.7399921417236328
Batch 57/64 loss: -1.416529655456543
Batch 58/64 loss: -1.379159927368164
Batch 59/64 loss: -1.715559959411621
Batch 60/64 loss: -1.4788427352905273
Batch 61/64 loss: -1.231149673461914
Batch 62/64 loss: -1.4374361038208008
Batch 63/64 loss: -1.3200836181640625
Batch 64/64 loss: -5.512946128845215
Epoch 39  Train loss: -1.3005293341243969  Val loss: -1.3684019108408505
Saving best model, epoch: 39
Epoch 40
-------------------------------
Batch 1/64 loss: -1.238138198852539
Batch 2/64 loss: -1.5628137588500977
Batch 3/64 loss: -1.8097352981567383
Batch 4/64 loss: -1.3449602127075195
Batch 5/64 loss: -1.3796215057373047
Batch 6/64 loss: -1.2685260772705078
Batch 7/64 loss: -1.5691843032836914
Batch 8/64 loss: -1.1660757064819336
Batch 9/64 loss: -1.335524559020996
Batch 10/64 loss: -1.6699333190917969
Batch 11/64 loss: -1.513941764831543
Batch 12/64 loss: -1.1436882019042969
Batch 13/64 loss: -1.0960187911987305
Batch 14/64 loss: -1.093679428100586
Batch 15/64 loss: -1.3278923034667969
Batch 16/64 loss: -1.4576196670532227
Batch 17/64 loss: -1.3201913833618164
Batch 18/64 loss: -1.0517816543579102
Batch 19/64 loss: -1.5304489135742188
Batch 20/64 loss: -1.3652629852294922
Batch 21/64 loss: -1.1141643524169922
Batch 22/64 loss: -1.1079187393188477
Batch 23/64 loss: -1.3663530349731445
Batch 24/64 loss: -1.534341812133789
Batch 25/64 loss: -1.481593132019043
Batch 26/64 loss: -1.3332386016845703
Batch 27/64 loss: -1.2801704406738281
Batch 28/64 loss: -0.9332790374755859
Batch 29/64 loss: -1.0932140350341797
Batch 30/64 loss: -1.1757659912109375
Batch 31/64 loss: -1.0617733001708984
Batch 32/64 loss: -0.9311742782592773
Batch 33/64 loss: -1.1052894592285156
Batch 34/64 loss: -1.128525733947754
Batch 35/64 loss: -0.6699895858764648
Batch 36/64 loss: -1.4541130065917969
Batch 37/64 loss: -0.9611854553222656
Batch 38/64 loss: -0.9356536865234375
Batch 39/64 loss: -1.4346036911010742
Batch 40/64 loss: -1.4349746704101562
Batch 41/64 loss: -1.133296012878418
Batch 42/64 loss: -1.2497749328613281
Batch 43/64 loss: -1.104116439819336
Batch 44/64 loss: -1.211958885192871
Batch 45/64 loss: -1.3562259674072266
Batch 46/64 loss: -1.1109895706176758
Batch 47/64 loss: -1.4484367370605469
Batch 48/64 loss: -1.3167076110839844
Batch 49/64 loss: -1.288508415222168
Batch 50/64 loss: -1.3943119049072266
Batch 51/64 loss: -1.3887405395507812
Batch 52/64 loss: -1.0984134674072266
Batch 53/64 loss: -0.5782413482666016
Batch 54/64 loss: -1.0455331802368164
Batch 55/64 loss: -1.120504379272461
Batch 56/64 loss: -0.925628662109375
Batch 57/64 loss: -1.1051664352416992
Batch 58/64 loss: -1.3369083404541016
Batch 59/64 loss: -0.9907627105712891
Batch 60/64 loss: -1.1853713989257812
Batch 61/64 loss: -1.3914432525634766
Batch 62/64 loss: -1.587254524230957
Batch 63/64 loss: -1.2911853790283203
Batch 64/64 loss: -5.8647541999816895
Epoch 40  Train loss: -1.2994573462243173  Val loss: -1.3872785666554244
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: -1.206343650817871
Batch 2/64 loss: -1.594289779663086
Batch 3/64 loss: -1.144144058227539
Batch 4/64 loss: -1.5612735748291016
Batch 5/64 loss: -1.5758399963378906
Batch 6/64 loss: -1.2108659744262695
Batch 7/64 loss: -1.3418445587158203
Batch 8/64 loss: -0.9828710556030273
Batch 9/64 loss: -0.8089389801025391
Batch 10/64 loss: -1.1365957260131836
Batch 11/64 loss: -1.0737371444702148
Batch 12/64 loss: -1.2900972366333008
Batch 13/64 loss: -1.5402698516845703
Batch 14/64 loss: -1.12432861328125
Batch 15/64 loss: -1.505375862121582
Batch 16/64 loss: -0.9497385025024414
Batch 17/64 loss: -1.3796300888061523
Batch 18/64 loss: -1.0979499816894531
Batch 19/64 loss: -1.0991497039794922
Batch 20/64 loss: -0.8314456939697266
Batch 21/64 loss: -1.4384889602661133
Batch 22/64 loss: -1.2408027648925781
Batch 23/64 loss: -1.5119209289550781
Batch 24/64 loss: -1.2644433975219727
Batch 25/64 loss: -1.2277507781982422
Batch 26/64 loss: -1.060307502746582
Batch 27/64 loss: -1.6461067199707031
Batch 28/64 loss: -1.2316465377807617
Batch 29/64 loss: -1.4916791915893555
Batch 30/64 loss: -1.3717155456542969
Batch 31/64 loss: -1.4709110260009766
Batch 32/64 loss: -1.2158689498901367
Batch 33/64 loss: -1.063878059387207
Batch 34/64 loss: -1.134293556213379
Batch 35/64 loss: -1.3698759078979492
Batch 36/64 loss: -1.1050033569335938
Batch 37/64 loss: -1.6066064834594727
Batch 38/64 loss: -1.4107160568237305
Batch 39/64 loss: -1.3371877670288086
Batch 40/64 loss: -1.2319536209106445
Batch 41/64 loss: -1.5264129638671875
Batch 42/64 loss: -1.3662738800048828
Batch 43/64 loss: -1.0539045333862305
Batch 44/64 loss: -1.3319683074951172
Batch 45/64 loss: -1.309901237487793
Batch 46/64 loss: -0.8621912002563477
Batch 47/64 loss: -1.0315427780151367
Batch 48/64 loss: -1.3487052917480469
Batch 49/64 loss: -1.4055681228637695
Batch 50/64 loss: -1.4705390930175781
Batch 51/64 loss: -1.5900096893310547
Batch 52/64 loss: -0.9506864547729492
Batch 53/64 loss: -1.1022205352783203
Batch 54/64 loss: -1.273397445678711
Batch 55/64 loss: -1.1631965637207031
Batch 56/64 loss: -1.2796745300292969
Batch 57/64 loss: -1.3482751846313477
Batch 58/64 loss: -1.2979145050048828
Batch 59/64 loss: -1.167531967163086
Batch 60/64 loss: -0.8296442031860352
Batch 61/64 loss: -1.3028249740600586
Batch 62/64 loss: -1.356328010559082
Batch 63/64 loss: -1.1685447692871094
Batch 64/64 loss: -5.499431133270264
Epoch 41  Train loss: -1.3105524194006826  Val loss: -1.3328459697081052
Epoch 42
-------------------------------
Batch 1/64 loss: -1.4615287780761719
Batch 2/64 loss: -1.0123882293701172
Batch 3/64 loss: -0.2861442565917969
Batch 4/64 loss: -1.4481067657470703
Batch 5/64 loss: -1.0266046524047852
Batch 6/64 loss: -1.191411018371582
Batch 7/64 loss: -1.2379817962646484
Batch 8/64 loss: -1.5584735870361328
Batch 9/64 loss: -1.4148120880126953
Batch 10/64 loss: -1.072962760925293
Batch 11/64 loss: -1.439610481262207
Batch 12/64 loss: -1.189427375793457
Batch 13/64 loss: -1.3451051712036133
Batch 14/64 loss: -1.469649314880371
Batch 15/64 loss: -1.4590873718261719
Batch 16/64 loss: -1.372323989868164
Batch 17/64 loss: -1.030390739440918
Batch 18/64 loss: -1.2833642959594727
Batch 19/64 loss: -1.559248924255371
Batch 20/64 loss: -1.5482759475708008
Batch 21/64 loss: -1.3091154098510742
Batch 22/64 loss: -1.2521896362304688
Batch 23/64 loss: -0.4414653778076172
Batch 24/64 loss: -1.4456357955932617
Batch 25/64 loss: -1.3664045333862305
Batch 26/64 loss: -1.1789312362670898
Batch 27/64 loss: -1.5503616333007812
Batch 28/64 loss: -1.3684940338134766
Batch 29/64 loss: -1.2283525466918945
Batch 30/64 loss: -1.16729736328125
Batch 31/64 loss: -1.257120132446289
Batch 32/64 loss: -1.0088272094726562
Batch 33/64 loss: -1.0290298461914062
Batch 34/64 loss: -1.52520751953125
Batch 35/64 loss: -1.214888572692871
Batch 36/64 loss: -1.3055267333984375
Batch 37/64 loss: -1.4565496444702148
Batch 38/64 loss: -1.0545568466186523
Batch 39/64 loss: -1.1412811279296875
Batch 40/64 loss: -1.544877052307129
Batch 41/64 loss: -1.4387683868408203
Batch 42/64 loss: -1.3163137435913086
Batch 43/64 loss: -1.6155986785888672
Batch 44/64 loss: -1.2778406143188477
Batch 45/64 loss: -1.2518177032470703
Batch 46/64 loss: -1.0260629653930664
Batch 47/64 loss: -1.1801729202270508
Batch 48/64 loss: -1.5019149780273438
Batch 49/64 loss: -0.5340347290039062
Batch 50/64 loss: -1.3839139938354492
Batch 51/64 loss: -1.171976089477539
Batch 52/64 loss: -1.3607063293457031
Batch 53/64 loss: -1.001011848449707
Batch 54/64 loss: -1.0395221710205078
Batch 55/64 loss: -1.0936880111694336
Batch 56/64 loss: -1.0046625137329102
Batch 57/64 loss: -1.3097238540649414
Batch 58/64 loss: -1.1089344024658203
Batch 59/64 loss: -0.8625125885009766
Batch 60/64 loss: -1.2370796203613281
Batch 61/64 loss: -1.3749160766601562
Batch 62/64 loss: -1.5176630020141602
Batch 63/64 loss: -1.2665376663208008
Batch 64/64 loss: -5.894970417022705
Epoch 42  Train loss: -1.29489585091086  Val loss: -1.4062946752174614
Saving best model, epoch: 42
Epoch 43
-------------------------------
Batch 1/64 loss: -1.322636604309082
Batch 2/64 loss: -0.6100893020629883
Batch 3/64 loss: -1.291921615600586
Batch 4/64 loss: -1.2565574645996094
Batch 5/64 loss: -1.4551162719726562
Batch 6/64 loss: -1.2039508819580078
Batch 7/64 loss: -0.9125156402587891
Batch 8/64 loss: -1.3316192626953125
Batch 9/64 loss: -1.7560348510742188
Batch 10/64 loss: -1.2275571823120117
Batch 11/64 loss: -0.6563787460327148
Batch 12/64 loss: -1.5386285781860352
Batch 13/64 loss: -1.2092695236206055
Batch 14/64 loss: -1.0290117263793945
Batch 15/64 loss: -1.19403076171875
Batch 16/64 loss: -0.8391304016113281
Batch 17/64 loss: -1.3222417831420898
Batch 18/64 loss: -1.3294305801391602
Batch 19/64 loss: -1.2824115753173828
Batch 20/64 loss: -1.2260818481445312
Batch 21/64 loss: -1.0670051574707031
Batch 22/64 loss: -1.2380666732788086
Batch 23/64 loss: -1.2644004821777344
Batch 24/64 loss: -1.5088262557983398
Batch 25/64 loss: -1.4361963272094727
Batch 26/64 loss: -1.1101922988891602
Batch 27/64 loss: -1.2259674072265625
Batch 28/64 loss: -0.9541711807250977
Batch 29/64 loss: -1.519317626953125
Batch 30/64 loss: -1.0687217712402344
Batch 31/64 loss: -1.4097566604614258
Batch 32/64 loss: -1.2284297943115234
Batch 33/64 loss: -1.5569171905517578
Batch 34/64 loss: -1.3194093704223633
Batch 35/64 loss: -0.9973134994506836
Batch 36/64 loss: -1.264918327331543
Batch 37/64 loss: -0.8473892211914062
Batch 38/64 loss: -1.0667619705200195
Batch 39/64 loss: -1.2075281143188477
Batch 40/64 loss: -1.3409643173217773
Batch 41/64 loss: -1.1801128387451172
Batch 42/64 loss: -1.085392951965332
Batch 43/64 loss: -1.5557308197021484
Batch 44/64 loss: -1.4753665924072266
Batch 45/64 loss: -1.2360553741455078
Batch 46/64 loss: -1.3062334060668945
Batch 47/64 loss: -1.4483489990234375
Batch 48/64 loss: -1.3284673690795898
Batch 49/64 loss: -1.5824708938598633
Batch 50/64 loss: -1.0334901809692383
Batch 51/64 loss: -1.5526161193847656
Batch 52/64 loss: -1.3956060409545898
Batch 53/64 loss: -1.1861038208007812
Batch 54/64 loss: -1.3687400817871094
Batch 55/64 loss: -1.5285491943359375
Batch 56/64 loss: -0.24701690673828125
Batch 57/64 loss: -1.4139575958251953
Batch 58/64 loss: -1.562124252319336
Batch 59/64 loss: -1.4814949035644531
Batch 60/64 loss: -1.2989912033081055
Batch 61/64 loss: -1.1893234252929688
Batch 62/64 loss: -0.9497871398925781
Batch 63/64 loss: -1.1242408752441406
Batch 64/64 loss: -5.680510997772217
Epoch 43  Train loss: -1.2928230977525899  Val loss: -1.4020444339083642
Epoch 44
-------------------------------
Batch 1/64 loss: -1.2723045349121094
Batch 2/64 loss: -0.8771638870239258
Batch 3/64 loss: -1.4694499969482422
Batch 4/64 loss: -1.149698257446289
Batch 5/64 loss: -1.4980640411376953
Batch 6/64 loss: -1.2651071548461914
Batch 7/64 loss: -0.6343364715576172
Batch 8/64 loss: -1.1629247665405273
Batch 9/64 loss: -1.090353012084961
Batch 10/64 loss: -1.365860939025879
Batch 11/64 loss: -1.426774024963379
Batch 12/64 loss: -1.4553213119506836
Batch 13/64 loss: -1.4672355651855469
Batch 14/64 loss: -1.1389436721801758
Batch 15/64 loss: -1.4510860443115234
Batch 16/64 loss: -1.0673179626464844
Batch 17/64 loss: -1.5760602951049805
Batch 18/64 loss: -1.1673364639282227
Batch 19/64 loss: -0.954803466796875
Batch 20/64 loss: -1.262648582458496
Batch 21/64 loss: -0.6157407760620117
Batch 22/64 loss: -1.2833213806152344
Batch 23/64 loss: -0.7635955810546875
Batch 24/64 loss: -0.574488639831543
Batch 25/64 loss: -1.0352497100830078
Batch 26/64 loss: -1.5660228729248047
Batch 27/64 loss: -0.9576892852783203
Batch 28/64 loss: -1.3061447143554688
Batch 29/64 loss: -1.4493598937988281
Batch 30/64 loss: -1.1477422714233398
Batch 31/64 loss: -1.2168407440185547
Batch 32/64 loss: -1.1072921752929688
Batch 33/64 loss: -1.2121210098266602
Batch 34/64 loss: -1.4902667999267578
Batch 35/64 loss: -0.9614696502685547
Batch 36/64 loss: -1.6508302688598633
Batch 37/64 loss: -1.3101749420166016
Batch 38/64 loss: -1.1919431686401367
Batch 39/64 loss: -1.2001457214355469
Batch 40/64 loss: -1.3001012802124023
Batch 41/64 loss: -1.3260793685913086
Batch 42/64 loss: -1.5009994506835938
Batch 43/64 loss: -1.5930938720703125
Batch 44/64 loss: -1.5196666717529297
Batch 45/64 loss: -1.3318719863891602
Batch 46/64 loss: -1.4058513641357422
Batch 47/64 loss: -1.1479530334472656
Batch 48/64 loss: -1.0595531463623047
Batch 49/64 loss: -1.6233711242675781
Batch 50/64 loss: -1.448904037475586
Batch 51/64 loss: -1.2960901260375977
Batch 52/64 loss: -1.333724021911621
Batch 53/64 loss: -1.2715797424316406
Batch 54/64 loss: -1.4254398345947266
Batch 55/64 loss: -1.4818077087402344
Batch 56/64 loss: -1.154952049255371
Batch 57/64 loss: -0.9826765060424805
Batch 58/64 loss: -1.308720588684082
Batch 59/64 loss: -1.3428716659545898
Batch 60/64 loss: -1.4697761535644531
Batch 61/64 loss: -1.2227363586425781
Batch 62/64 loss: -1.3468122482299805
Batch 63/64 loss: -1.2438955307006836
Batch 64/64 loss: -5.918675422668457
Epoch 44  Train loss: -1.3077766979441923  Val loss: -1.3175318478718656
Epoch 45
-------------------------------
Batch 1/64 loss: -1.6710681915283203
Batch 2/64 loss: -1.3412837982177734
Batch 3/64 loss: -1.0133275985717773
Batch 4/64 loss: -1.2712068557739258
Batch 5/64 loss: -1.3413848876953125
Batch 6/64 loss: -1.4630956649780273
Batch 7/64 loss: -1.6426124572753906
Batch 8/64 loss: -1.0104732513427734
Batch 9/64 loss: -1.5873756408691406
Batch 10/64 loss: -1.304957389831543
Batch 11/64 loss: -1.0007667541503906
Batch 12/64 loss: -1.2180938720703125
Batch 13/64 loss: -1.1953163146972656
Batch 14/64 loss: -0.9393091201782227
Batch 15/64 loss: -1.5534782409667969
Batch 16/64 loss: -1.4237499237060547
Batch 17/64 loss: -1.5926532745361328
Batch 18/64 loss: -1.099461555480957
Batch 19/64 loss: -1.3334150314331055
Batch 20/64 loss: -1.2775907516479492
Batch 21/64 loss: -0.8999462127685547
Batch 22/64 loss: -1.5044803619384766
Batch 23/64 loss: -1.5258092880249023
Batch 24/64 loss: -1.2085390090942383
Batch 25/64 loss: -1.259800910949707
Batch 26/64 loss: -1.6307964324951172
Batch 27/64 loss: -1.1895761489868164
Batch 28/64 loss: -1.4163837432861328
Batch 29/64 loss: -1.254404067993164
Batch 30/64 loss: -1.2717180252075195
Batch 31/64 loss: -1.3519678115844727
Batch 32/64 loss: -1.5443744659423828
Batch 33/64 loss: -1.2333059310913086
Batch 34/64 loss: -1.6018095016479492
Batch 35/64 loss: -1.6671380996704102
Batch 36/64 loss: -1.5536603927612305
Batch 37/64 loss: -1.5896196365356445
Batch 38/64 loss: -1.3678598403930664
Batch 39/64 loss: -1.6868791580200195
Batch 40/64 loss: -1.3172798156738281
Batch 41/64 loss: -1.5405197143554688
Batch 42/64 loss: -1.4123754501342773
Batch 43/64 loss: -1.577387809753418
Batch 44/64 loss: -1.1446056365966797
Batch 45/64 loss: -0.9259891510009766
Batch 46/64 loss: -0.9728755950927734
Batch 47/64 loss: -1.6519079208374023
Batch 48/64 loss: -1.5975637435913086
Batch 49/64 loss: -1.0216178894042969
Batch 50/64 loss: -1.384221076965332
Batch 51/64 loss: -1.192117691040039
Batch 52/64 loss: -1.474461555480957
Batch 53/64 loss: -1.3964977264404297
Batch 54/64 loss: -1.3595142364501953
Batch 55/64 loss: -1.4282569885253906
Batch 56/64 loss: -1.4209461212158203
Batch 57/64 loss: -1.1783294677734375
Batch 58/64 loss: -1.0141525268554688
Batch 59/64 loss: -1.290785789489746
Batch 60/64 loss: -0.9910488128662109
Batch 61/64 loss: -1.2699003219604492
Batch 62/64 loss: -1.3490428924560547
Batch 63/64 loss: -1.1187477111816406
Batch 64/64 loss: -5.847925186157227
Epoch 45  Train loss: -1.3875259474212047  Val loss: -1.477217723413841
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: -1.6701736450195312
Batch 2/64 loss: -1.4685735702514648
Batch 3/64 loss: -1.2071475982666016
Batch 4/64 loss: -1.6202259063720703
Batch 5/64 loss: -0.8000402450561523
Batch 6/64 loss: -1.4792804718017578
Batch 7/64 loss: -1.451676368713379
Batch 8/64 loss: -1.5212640762329102
Batch 9/64 loss: -0.9973115921020508
Batch 10/64 loss: -1.6562328338623047
Batch 11/64 loss: -1.1536674499511719
Batch 12/64 loss: -0.9471769332885742
Batch 13/64 loss: -1.2571840286254883
Batch 14/64 loss: -1.441237449645996
Batch 15/64 loss: -1.6671028137207031
Batch 16/64 loss: -1.3631649017333984
Batch 17/64 loss: -1.1649351119995117
Batch 18/64 loss: -1.5526018142700195
Batch 19/64 loss: -1.4160661697387695
Batch 20/64 loss: -0.9066619873046875
Batch 21/64 loss: -1.0549612045288086
Batch 22/64 loss: -1.2582941055297852
Batch 23/64 loss: -1.3518791198730469
Batch 24/64 loss: -1.0213184356689453
Batch 25/64 loss: -1.2790651321411133
Batch 26/64 loss: -1.3010187149047852
Batch 27/64 loss: -1.464493751525879
Batch 28/64 loss: -1.3826265335083008
Batch 29/64 loss: -1.6226005554199219
Batch 30/64 loss: -1.3858165740966797
Batch 31/64 loss: -1.1455755233764648
Batch 32/64 loss: -1.6613702774047852
Batch 33/64 loss: -1.4233818054199219
Batch 34/64 loss: -1.707366943359375
Batch 35/64 loss: -1.460677146911621
Batch 36/64 loss: -1.5742664337158203
Batch 37/64 loss: -1.8693647384643555
Batch 38/64 loss: -1.3896484375
Batch 39/64 loss: -1.3795042037963867
Batch 40/64 loss: -1.6417570114135742
Batch 41/64 loss: -1.6961393356323242
Batch 42/64 loss: -1.2828254699707031
Batch 43/64 loss: -1.2688226699829102
Batch 44/64 loss: -1.3840522766113281
Batch 45/64 loss: -1.2970161437988281
Batch 46/64 loss: -1.4392213821411133
Batch 47/64 loss: -1.5575275421142578
Batch 48/64 loss: -1.3512248992919922
Batch 49/64 loss: -1.418074607849121
Batch 50/64 loss: -1.5508298873901367
Batch 51/64 loss: -1.393514633178711
Batch 52/64 loss: -0.4763460159301758
Batch 53/64 loss: -1.319106101989746
Batch 54/64 loss: -1.6281871795654297
Batch 55/64 loss: -1.4883337020874023
Batch 56/64 loss: -1.2613258361816406
Batch 57/64 loss: -1.4063606262207031
Batch 58/64 loss: -1.6133995056152344
Batch 59/64 loss: -1.2692222595214844
Batch 60/64 loss: -1.4449491500854492
Batch 61/64 loss: -1.0328702926635742
Batch 62/64 loss: -1.6141185760498047
Batch 63/64 loss: -0.9281339645385742
Batch 64/64 loss: -5.932941913604736
Epoch 46  Train loss: -1.4225571781981226  Val loss: -1.5597629612663768
Saving best model, epoch: 46
Epoch 47
-------------------------------
Batch 1/64 loss: -1.899261474609375
Batch 2/64 loss: -1.6456308364868164
Batch 3/64 loss: -0.8988199234008789
Batch 4/64 loss: -1.6855897903442383
Batch 5/64 loss: -1.3892822265625
Batch 6/64 loss: -1.4823665618896484
Batch 7/64 loss: -1.3018341064453125
Batch 8/64 loss: -1.1061248779296875
Batch 9/64 loss: -1.32177734375
Batch 10/64 loss: -1.4161338806152344
Batch 11/64 loss: -1.3612422943115234
Batch 12/64 loss: -1.6245841979980469
Batch 13/64 loss: -1.4872989654541016
Batch 14/64 loss: -1.000706672668457
Batch 15/64 loss: -1.4576120376586914
Batch 16/64 loss: -1.0565872192382812
Batch 17/64 loss: -1.3928184509277344
Batch 18/64 loss: -1.4423713684082031
Batch 19/64 loss: -1.1747169494628906
Batch 20/64 loss: -0.8989410400390625
Batch 21/64 loss: -1.3218650817871094
Batch 22/64 loss: -1.6111812591552734
Batch 23/64 loss: -1.2206459045410156
Batch 24/64 loss: -1.5644664764404297
Batch 25/64 loss: -1.3549346923828125
Batch 26/64 loss: -1.558262825012207
Batch 27/64 loss: -1.5266246795654297
Batch 28/64 loss: -1.6404037475585938
Batch 29/64 loss: -1.0175867080688477
Batch 30/64 loss: -1.545760154724121
Batch 31/64 loss: -1.222132682800293
Batch 32/64 loss: -1.723830223083496
Batch 33/64 loss: -1.6625652313232422
Batch 34/64 loss: -1.8062925338745117
Batch 35/64 loss: -1.5576038360595703
Batch 36/64 loss: -1.7037334442138672
Batch 37/64 loss: -1.3822669982910156
Batch 38/64 loss: -1.6134099960327148
Batch 39/64 loss: -1.6441679000854492
Batch 40/64 loss: -1.721379280090332
Batch 41/64 loss: -1.2970399856567383
Batch 42/64 loss: -1.426161766052246
Batch 43/64 loss: -1.5170536041259766
Batch 44/64 loss: -1.1917219161987305
Batch 45/64 loss: -1.654581069946289
Batch 46/64 loss: -1.3909263610839844
Batch 47/64 loss: -1.6784343719482422
Batch 48/64 loss: -1.4547319412231445
Batch 49/64 loss: -1.5498933792114258
Batch 50/64 loss: -1.5198259353637695
Batch 51/64 loss: -0.9296531677246094
Batch 52/64 loss: -1.5703792572021484
Batch 53/64 loss: -1.0998859405517578
Batch 54/64 loss: -1.6198492050170898
Batch 55/64 loss: -1.3962602615356445
Batch 56/64 loss: -1.09423828125
Batch 57/64 loss: -1.1897716522216797
Batch 58/64 loss: -1.3698234558105469
Batch 59/64 loss: -1.0816497802734375
Batch 60/64 loss: -1.4982013702392578
Batch 61/64 loss: -1.4177255630493164
Batch 62/64 loss: -0.8734750747680664
Batch 63/64 loss: -1.6251001358032227
Batch 64/64 loss: -5.567377090454102
Epoch 47  Train loss: -1.4598389045864928  Val loss: -1.4641827848768725
Epoch 48
-------------------------------
Batch 1/64 loss: -1.854196548461914
Batch 2/64 loss: -1.3091344833374023
Batch 3/64 loss: -1.4964656829833984
Batch 4/64 loss: -1.1802902221679688
Batch 5/64 loss: -1.6397161483764648
Batch 6/64 loss: -1.5715398788452148
Batch 7/64 loss: -1.4443416595458984
Batch 8/64 loss: -1.314697265625
Batch 9/64 loss: -1.404296875
Batch 10/64 loss: -1.6337223052978516
Batch 11/64 loss: -1.719015121459961
Batch 12/64 loss: -1.2077522277832031
Batch 13/64 loss: -0.8502616882324219
Batch 14/64 loss: -1.3650474548339844
Batch 15/64 loss: -1.2873554229736328
Batch 16/64 loss: -1.2305221557617188
Batch 17/64 loss: -1.3489627838134766
Batch 18/64 loss: -1.688650131225586
Batch 19/64 loss: -1.4839086532592773
Batch 20/64 loss: -1.3760309219360352
Batch 21/64 loss: -1.7143869400024414
Batch 22/64 loss: -0.7353725433349609
Batch 23/64 loss: -1.3453521728515625
Batch 24/64 loss: -1.4043569564819336
Batch 25/64 loss: -1.5697250366210938
Batch 26/64 loss: -1.534799575805664
Batch 27/64 loss: -1.1737947463989258
Batch 28/64 loss: -1.694662094116211
Batch 29/64 loss: -1.4101753234863281
Batch 30/64 loss: -1.488433837890625
Batch 31/64 loss: -0.7278470993041992
Batch 32/64 loss: -1.4974908828735352
Batch 33/64 loss: -1.5066547393798828
Batch 34/64 loss: -1.461806297302246
Batch 35/64 loss: -1.3476638793945312
Batch 36/64 loss: -1.2820234298706055
Batch 37/64 loss: -1.1698417663574219
Batch 38/64 loss: -1.4358625411987305
Batch 39/64 loss: -1.1466941833496094
Batch 40/64 loss: -1.1590518951416016
Batch 41/64 loss: -1.6245450973510742
Batch 42/64 loss: -1.2099218368530273
Batch 43/64 loss: -1.4018030166625977
Batch 44/64 loss: -1.4340496063232422
Batch 45/64 loss: -1.3123283386230469
Batch 46/64 loss: -1.4139375686645508
Batch 47/64 loss: -1.0860843658447266
Batch 48/64 loss: -1.5310249328613281
Batch 49/64 loss: -1.2759733200073242
Batch 50/64 loss: -1.6057519912719727
Batch 51/64 loss: -1.1521024703979492
Batch 52/64 loss: -1.4037399291992188
Batch 53/64 loss: -0.9822244644165039
Batch 54/64 loss: -1.1111927032470703
Batch 55/64 loss: -1.5520563125610352
Batch 56/64 loss: -1.3581581115722656
Batch 57/64 loss: -0.7088260650634766
Batch 58/64 loss: -1.3520593643188477
Batch 59/64 loss: -1.7717151641845703
Batch 60/64 loss: -1.4845514297485352
Batch 61/64 loss: -1.350855827331543
Batch 62/64 loss: -1.6797285079956055
Batch 63/64 loss: -1.0854415893554688
Batch 64/64 loss: -5.691195964813232
Epoch 48  Train loss: -1.417543098973293  Val loss: -1.4327509771917284
Epoch 49
-------------------------------
Batch 1/64 loss: -1.387263298034668
Batch 2/64 loss: -1.7803926467895508
Batch 3/64 loss: -1.217569351196289
Batch 4/64 loss: -1.284841537475586
Batch 5/64 loss: -1.5320053100585938
Batch 6/64 loss: -1.4525318145751953
Batch 7/64 loss: -1.1457643508911133
Batch 8/64 loss: -1.5886192321777344
Batch 9/64 loss: -0.9675130844116211
Batch 10/64 loss: -1.2401676177978516
Batch 11/64 loss: -1.5964117050170898
Batch 12/64 loss: -1.693354606628418
Batch 13/64 loss: -1.4475460052490234
Batch 14/64 loss: -1.760110855102539
Batch 15/64 loss: -1.5893487930297852
Batch 16/64 loss: -1.2738237380981445
Batch 17/64 loss: -1.2809944152832031
Batch 18/64 loss: -1.0803251266479492
Batch 19/64 loss: -1.5671463012695312
Batch 20/64 loss: -1.5152063369750977
Batch 21/64 loss: -1.336385726928711
Batch 22/64 loss: -1.6543750762939453
Batch 23/64 loss: -1.450587272644043
Batch 24/64 loss: -1.4500532150268555
Batch 25/64 loss: -1.6758594512939453
Batch 26/64 loss: -1.3590888977050781
Batch 27/64 loss: -1.0092525482177734
Batch 28/64 loss: -1.0534067153930664
Batch 29/64 loss: -1.7234506607055664
Batch 30/64 loss: -1.2876672744750977
Batch 31/64 loss: -1.5311298370361328
Batch 32/64 loss: -1.5739679336547852
Batch 33/64 loss: -1.3715019226074219
Batch 34/64 loss: -1.5502357482910156
Batch 35/64 loss: -1.6347379684448242
Batch 36/64 loss: -1.7395505905151367
Batch 37/64 loss: -1.5450248718261719
Batch 38/64 loss: -1.014449119567871
Batch 39/64 loss: -1.0313777923583984
Batch 40/64 loss: -1.576730728149414
Batch 41/64 loss: -1.39471435546875
Batch 42/64 loss: -1.689335823059082
Batch 43/64 loss: -1.6532402038574219
Batch 44/64 loss: -1.677210807800293
Batch 45/64 loss: -1.4891929626464844
Batch 46/64 loss: -1.256791114807129
Batch 47/64 loss: -1.148758888244629
Batch 48/64 loss: -1.7211227416992188
Batch 49/64 loss: -1.2925357818603516
Batch 50/64 loss: -1.7135353088378906
Batch 51/64 loss: -1.3926267623901367
Batch 52/64 loss: -1.5589628219604492
Batch 53/64 loss: -1.0782012939453125
Batch 54/64 loss: -1.6901121139526367
Batch 55/64 loss: -1.393045425415039
Batch 56/64 loss: -1.512075424194336
Batch 57/64 loss: -1.242051124572754
Batch 58/64 loss: -1.354140281677246
Batch 59/64 loss: -1.5258560180664062
Batch 60/64 loss: -1.6036357879638672
Batch 61/64 loss: -1.357625961303711
Batch 62/64 loss: -0.9187307357788086
Batch 63/64 loss: -1.29449462890625
Batch 64/64 loss: -5.585170745849609
Epoch 49  Train loss: -1.4763395122453278  Val loss: -1.6005389288938332
Saving best model, epoch: 49
Epoch 50
-------------------------------
Batch 1/64 loss: -1.3249225616455078
Batch 2/64 loss: -1.7046937942504883
Batch 3/64 loss: -1.3378162384033203
Batch 4/64 loss: -0.7375679016113281
Batch 5/64 loss: -1.1230802536010742
Batch 6/64 loss: -1.4768562316894531
Batch 7/64 loss: -1.6280488967895508
Batch 8/64 loss: -1.6224384307861328
Batch 9/64 loss: -1.4388618469238281
Batch 10/64 loss: -1.5238628387451172
Batch 11/64 loss: -1.4282474517822266
Batch 12/64 loss: -1.4081039428710938
Batch 13/64 loss: -1.7525720596313477
Batch 14/64 loss: -1.3866558074951172
Batch 15/64 loss: -1.3702287673950195
Batch 16/64 loss: -1.1353635787963867
Batch 17/64 loss: -1.5050640106201172
Batch 18/64 loss: -1.7727880477905273
Batch 19/64 loss: -1.265671730041504
Batch 20/64 loss: -1.2367315292358398
Batch 21/64 loss: -1.3701601028442383
Batch 22/64 loss: -1.3608694076538086
Batch 23/64 loss: -1.3918895721435547
Batch 24/64 loss: -1.556793212890625
Batch 25/64 loss: -1.5566091537475586
Batch 26/64 loss: -1.5108585357666016
Batch 27/64 loss: -1.3831701278686523
Batch 28/64 loss: -1.579214096069336
Batch 29/64 loss: -1.426091194152832
Batch 30/64 loss: -1.615309715270996
Batch 31/64 loss: -1.51763916015625
Batch 32/64 loss: -1.65447998046875
Batch 33/64 loss: -1.5904655456542969
Batch 34/64 loss: -1.6111021041870117
Batch 35/64 loss: -1.126460075378418
Batch 36/64 loss: -1.6101598739624023
Batch 37/64 loss: -1.627359390258789
Batch 38/64 loss: -1.5766477584838867
Batch 39/64 loss: -1.4353418350219727
Batch 40/64 loss: -1.4317197799682617
Batch 41/64 loss: -1.4047927856445312
Batch 42/64 loss: -1.4830446243286133
Batch 43/64 loss: -1.0865602493286133
Batch 44/64 loss: -1.3068370819091797
Batch 45/64 loss: -1.4688825607299805
Batch 46/64 loss: -1.4334354400634766
Batch 47/64 loss: -1.5326147079467773
Batch 48/64 loss: -1.733962059020996
Batch 49/64 loss: -1.3654813766479492
Batch 50/64 loss: -1.529435157775879
Batch 51/64 loss: -1.5143098831176758
Batch 52/64 loss: -1.325225830078125
Batch 53/64 loss: -1.3118009567260742
Batch 54/64 loss: -1.1967010498046875
Batch 55/64 loss: -1.628859519958496
Batch 56/64 loss: -0.7033176422119141
Batch 57/64 loss: -1.5624666213989258
Batch 58/64 loss: -1.2617006301879883
Batch 59/64 loss: -1.766322135925293
Batch 60/64 loss: -1.2374134063720703
Batch 61/64 loss: -1.3225650787353516
Batch 62/64 loss: -1.4717378616333008
Batch 63/64 loss: -1.2601909637451172
Batch 64/64 loss: -5.863520622253418
Epoch 50  Train loss: -1.4810543471691655  Val loss: -1.4616496161496926
Epoch 51
-------------------------------
Batch 1/64 loss: -1.2425165176391602
Batch 2/64 loss: -1.6911849975585938
Batch 3/64 loss: -1.5392541885375977
Batch 4/64 loss: -1.0819272994995117
Batch 5/64 loss: -1.1351089477539062
Batch 6/64 loss: -1.4771537780761719
Batch 7/64 loss: -1.3469581604003906
Batch 8/64 loss: -1.3306560516357422
Batch 9/64 loss: -1.4589710235595703
Batch 10/64 loss: -1.2303380966186523
Batch 11/64 loss: -1.7424631118774414
Batch 12/64 loss: -1.4813518524169922
Batch 13/64 loss: -1.1461849212646484
Batch 14/64 loss: -1.1213159561157227
Batch 15/64 loss: -1.622279167175293
Batch 16/64 loss: -1.3831634521484375
Batch 17/64 loss: -1.3542709350585938
Batch 18/64 loss: -1.5969047546386719
Batch 19/64 loss: -1.5306768417358398
Batch 20/64 loss: -1.5951175689697266
Batch 21/64 loss: -1.4713077545166016
Batch 22/64 loss: -1.376993179321289
Batch 23/64 loss: -1.4495210647583008
Batch 24/64 loss: -1.1070194244384766
Batch 25/64 loss: -0.6278877258300781
Batch 26/64 loss: -1.3099746704101562
Batch 27/64 loss: -1.6190557479858398
Batch 28/64 loss: -1.2319660186767578
Batch 29/64 loss: -1.4573497772216797
Batch 30/64 loss: -1.6713027954101562
Batch 31/64 loss: -1.173741340637207
Batch 32/64 loss: -1.1596097946166992
Batch 33/64 loss: -1.5811777114868164
Batch 34/64 loss: -1.0681562423706055
Batch 35/64 loss: -1.6064205169677734
Batch 36/64 loss: -1.5972471237182617
Batch 37/64 loss: -1.1048297882080078
Batch 38/64 loss: -1.3505420684814453
Batch 39/64 loss: -1.6817970275878906
Batch 40/64 loss: -1.4810810089111328
Batch 41/64 loss: -1.1508369445800781
Batch 42/64 loss: -1.1102294921875
Batch 43/64 loss: -1.2696542739868164
Batch 44/64 loss: -1.7040472030639648
Batch 45/64 loss: -1.4953508377075195
Batch 46/64 loss: -1.6482629776000977
Batch 47/64 loss: -1.3221282958984375
Batch 48/64 loss: -1.627634048461914
Batch 49/64 loss: -1.4290342330932617
Batch 50/64 loss: -1.748368263244629
Batch 51/64 loss: -1.6829814910888672
Batch 52/64 loss: -1.2946834564208984
Batch 53/64 loss: -1.4219112396240234
Batch 54/64 loss: -1.5702800750732422
Batch 55/64 loss: -1.7426223754882812
Batch 56/64 loss: -1.863011360168457
Batch 57/64 loss: -1.8296051025390625
Batch 58/64 loss: -1.5668439865112305
Batch 59/64 loss: -0.994598388671875
Batch 60/64 loss: -1.252028465270996
Batch 61/64 loss: -1.7651758193969727
Batch 62/64 loss: -1.7716741561889648
Batch 63/64 loss: -1.6617860794067383
Batch 64/64 loss: -5.646709442138672
Epoch 51  Train loss: -1.4806675929649205  Val loss: -1.557612560049365
Epoch 52
-------------------------------
Batch 1/64 loss: -1.5405330657958984
Batch 2/64 loss: -1.3392410278320312
Batch 3/64 loss: -1.398935317993164
Batch 4/64 loss: -1.3477792739868164
Batch 5/64 loss: -1.6481494903564453
Batch 6/64 loss: -1.0886859893798828
Batch 7/64 loss: -1.3007516860961914
Batch 8/64 loss: -0.8337745666503906
Batch 9/64 loss: -1.7116365432739258
Batch 10/64 loss: -1.6330642700195312
Batch 11/64 loss: -1.5167770385742188
Batch 12/64 loss: -1.7555246353149414
Batch 13/64 loss: -1.395425796508789
Batch 14/64 loss: -1.7589111328125
Batch 15/64 loss: -1.7220726013183594
Batch 16/64 loss: -1.2542734146118164
Batch 17/64 loss: -1.8350152969360352
Batch 18/64 loss: -1.582768440246582
Batch 19/64 loss: -1.0146465301513672
Batch 20/64 loss: -1.4828453063964844
Batch 21/64 loss: -1.6466913223266602
Batch 22/64 loss: -1.5712461471557617
Batch 23/64 loss: -1.6550626754760742
Batch 24/64 loss: -1.356898307800293
Batch 25/64 loss: -1.6437244415283203
Batch 26/64 loss: -1.4835939407348633
Batch 27/64 loss: -1.8912601470947266
Batch 28/64 loss: -1.3162164688110352
Batch 29/64 loss: -1.6195831298828125
Batch 30/64 loss: -1.2968969345092773
Batch 31/64 loss: -1.6291179656982422
Batch 32/64 loss: -1.5953712463378906
Batch 33/64 loss: -1.5921525955200195
Batch 34/64 loss: -1.2706737518310547
Batch 35/64 loss: -1.4264249801635742
Batch 36/64 loss: -1.2972803115844727
Batch 37/64 loss: -1.849726676940918
Batch 38/64 loss: -1.6049108505249023
Batch 39/64 loss: -1.3599014282226562
Batch 40/64 loss: -1.3712539672851562
Batch 41/64 loss: -1.156930923461914
Batch 42/64 loss: -1.3015804290771484
Batch 43/64 loss: -1.1883344650268555
Batch 44/64 loss: -1.6517009735107422
Batch 45/64 loss: -0.41517162322998047
Batch 46/64 loss: -1.0672645568847656
Batch 47/64 loss: -1.670182228088379
Batch 48/64 loss: -1.6112852096557617
Batch 49/64 loss: -1.2687005996704102
Batch 50/64 loss: -1.6789512634277344
Batch 51/64 loss: -1.631056785583496
Batch 52/64 loss: -1.3658123016357422
Batch 53/64 loss: -1.522343635559082
Batch 54/64 loss: -1.484832763671875
Batch 55/64 loss: -1.1744318008422852
Batch 56/64 loss: -1.541341781616211
Batch 57/64 loss: -1.6167497634887695
Batch 58/64 loss: -1.7155828475952148
Batch 59/64 loss: -0.8737411499023438
Batch 60/64 loss: -1.7001113891601562
Batch 61/64 loss: -1.584609031677246
Batch 62/64 loss: -1.640233039855957
Batch 63/64 loss: -1.3503551483154297
Batch 64/64 loss: -5.792107105255127
Epoch 52  Train loss: -1.5089283569186343  Val loss: -1.498025743412398
Epoch 53
-------------------------------
Batch 1/64 loss: -0.8928165435791016
Batch 2/64 loss: -1.255946159362793
Batch 3/64 loss: -1.6024112701416016
Batch 4/64 loss: -1.56878662109375
Batch 5/64 loss: -0.7553043365478516
Batch 6/64 loss: -1.3133792877197266
Batch 7/64 loss: -1.2501134872436523
Batch 8/64 loss: -1.7600717544555664
Batch 9/64 loss: -1.6175880432128906
Batch 10/64 loss: -1.3761510848999023
Batch 11/64 loss: -1.376175880432129
Batch 12/64 loss: -1.1341238021850586
Batch 13/64 loss: -1.383890151977539
Batch 14/64 loss: -1.6448822021484375
Batch 15/64 loss: -1.3460302352905273
Batch 16/64 loss: -1.4419164657592773
Batch 17/64 loss: -1.709625244140625
Batch 18/64 loss: -1.2910089492797852
Batch 19/64 loss: -1.473271369934082
Batch 20/64 loss: -1.347280502319336
Batch 21/64 loss: -1.4062042236328125
Batch 22/64 loss: -1.7073860168457031
Batch 23/64 loss: -1.3486175537109375
Batch 24/64 loss: -0.9533796310424805
Batch 25/64 loss: -1.1533565521240234
Batch 26/64 loss: -1.2553253173828125
Batch 27/64 loss: -1.463958740234375
Batch 28/64 loss: -1.3106937408447266
Batch 29/64 loss: -1.167093276977539
Batch 30/64 loss: -1.7492313385009766
Batch 31/64 loss: -1.5516386032104492
Batch 32/64 loss: -1.8078117370605469
Batch 33/64 loss: -1.4160480499267578
Batch 34/64 loss: -1.421072006225586
Batch 35/64 loss: -1.5639104843139648
Batch 36/64 loss: -1.4212512969970703
Batch 37/64 loss: -1.1755399703979492
Batch 38/64 loss: -1.2631101608276367
Batch 39/64 loss: -1.4379024505615234
Batch 40/64 loss: -1.183243751525879
Batch 41/64 loss: -1.6734800338745117
Batch 42/64 loss: -1.4947280883789062
Batch 43/64 loss: -1.8065872192382812
Batch 44/64 loss: -1.6210212707519531
Batch 45/64 loss: -1.6907854080200195
Batch 46/64 loss: -1.5298662185668945
Batch 47/64 loss: -1.8044776916503906
Batch 48/64 loss: -1.498347282409668
Batch 49/64 loss: -1.5647268295288086
Batch 50/64 loss: -1.3890771865844727
Batch 51/64 loss: -1.4471139907836914
Batch 52/64 loss: -1.7557945251464844
Batch 53/64 loss: -1.4910812377929688
Batch 54/64 loss: -1.2665786743164062
Batch 55/64 loss: -0.49013710021972656
Batch 56/64 loss: -1.1806869506835938
Batch 57/64 loss: -1.2998161315917969
Batch 58/64 loss: -1.4148778915405273
Batch 59/64 loss: -1.5021038055419922
Batch 60/64 loss: -1.398228645324707
Batch 61/64 loss: -1.5877656936645508
Batch 62/64 loss: -1.7257061004638672
Batch 63/64 loss: -1.7513837814331055
Batch 64/64 loss: -5.695013999938965
Epoch 53  Train loss: -1.4737753812004537  Val loss: -1.6180123660162962
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: -1.5249319076538086
Batch 2/64 loss: -1.6082887649536133
Batch 3/64 loss: -1.5067996978759766
Batch 4/64 loss: -1.605210304260254
Batch 5/64 loss: -1.5085039138793945
Batch 6/64 loss: -1.6435432434082031
Batch 7/64 loss: -1.6556062698364258
Batch 8/64 loss: -1.4512338638305664
Batch 9/64 loss: -0.9916458129882812
Batch 10/64 loss: -1.2343416213989258
Batch 11/64 loss: -1.3185205459594727
Batch 12/64 loss: -1.5198020935058594
Batch 13/64 loss: -1.3585481643676758
Batch 14/64 loss: -1.765681266784668
Batch 15/64 loss: -1.3209867477416992
Batch 16/64 loss: -1.3293771743774414
Batch 17/64 loss: -1.0934467315673828
Batch 18/64 loss: -1.5577754974365234
Batch 19/64 loss: -1.5401735305786133
Batch 20/64 loss: -1.4224414825439453
Batch 21/64 loss: -1.6670703887939453
Batch 22/64 loss: -1.7939672470092773
Batch 23/64 loss: -1.5739192962646484
Batch 24/64 loss: -1.736297607421875
Batch 25/64 loss: -1.505995750427246
Batch 26/64 loss: -1.7629976272583008
Batch 27/64 loss: -0.9841432571411133
Batch 28/64 loss: -1.1686506271362305
Batch 29/64 loss: -1.7026348114013672
Batch 30/64 loss: -1.5336847305297852
Batch 31/64 loss: -1.6264190673828125
Batch 32/64 loss: -1.256429672241211
Batch 33/64 loss: -1.7542657852172852
Batch 34/64 loss: -1.748483657836914
Batch 35/64 loss: -1.596369743347168
Batch 36/64 loss: -0.9867753982543945
Batch 37/64 loss: -1.5274791717529297
Batch 38/64 loss: -1.527327537536621
Batch 39/64 loss: -1.8522100448608398
Batch 40/64 loss: -1.5691194534301758
Batch 41/64 loss: -1.2106456756591797
Batch 42/64 loss: -1.7767601013183594
Batch 43/64 loss: -1.1541872024536133
Batch 44/64 loss: -1.3902645111083984
Batch 45/64 loss: -1.3743782043457031
Batch 46/64 loss: -1.6334714889526367
Batch 47/64 loss: -1.565373420715332
Batch 48/64 loss: -1.440805435180664
Batch 49/64 loss: -1.8016462326049805
Batch 50/64 loss: -1.5339059829711914
Batch 51/64 loss: -1.9195194244384766
Batch 52/64 loss: -1.2821893692016602
Batch 53/64 loss: -1.5950984954833984
Batch 54/64 loss: -1.6135387420654297
Batch 55/64 loss: -1.4135379791259766
Batch 56/64 loss: -1.6154088973999023
Batch 57/64 loss: -1.4643096923828125
Batch 58/64 loss: -1.2037134170532227
Batch 59/64 loss: -1.5004997253417969
Batch 60/64 loss: -1.3794927597045898
Batch 61/64 loss: -1.3890352249145508
Batch 62/64 loss: -1.2293996810913086
Batch 63/64 loss: -1.6080961227416992
Batch 64/64 loss: -5.474153995513916
Epoch 54  Train loss: -1.5377567496954225  Val loss: -1.6595738597751892
Saving best model, epoch: 54
Epoch 55
-------------------------------
Batch 1/64 loss: -1.6258296966552734
Batch 2/64 loss: -1.6685409545898438
Batch 3/64 loss: -0.9409236907958984
Batch 4/64 loss: -1.4674263000488281
Batch 5/64 loss: -1.3467941284179688
Batch 6/64 loss: -1.3168373107910156
Batch 7/64 loss: -1.3214855194091797
Batch 8/64 loss: -1.2605457305908203
Batch 9/64 loss: -1.540252685546875
Batch 10/64 loss: -1.665837287902832
Batch 11/64 loss: -1.4115705490112305
Batch 12/64 loss: -1.518956184387207
Batch 13/64 loss: -1.4556121826171875
Batch 14/64 loss: -1.5245141983032227
Batch 15/64 loss: -1.6477279663085938
Batch 16/64 loss: -1.4630498886108398
Batch 17/64 loss: -1.5411138534545898
Batch 18/64 loss: -1.258589744567871
Batch 19/64 loss: -1.520482063293457
Batch 20/64 loss: -1.711989402770996
Batch 21/64 loss: -1.9628143310546875
Batch 22/64 loss: -1.4764556884765625
Batch 23/64 loss: -1.3058700561523438
Batch 24/64 loss: -1.904728889465332
Batch 25/64 loss: -1.355881690979004
Batch 26/64 loss: -1.2068595886230469
Batch 27/64 loss: -1.6769704818725586
Batch 28/64 loss: -1.646336555480957
Batch 29/64 loss: -1.709543228149414
Batch 30/64 loss: -1.5330886840820312
Batch 31/64 loss: -1.2305021286010742
Batch 32/64 loss: -1.9656295776367188
Batch 33/64 loss: -0.8532400131225586
Batch 34/64 loss: -1.7143049240112305
Batch 35/64 loss: -1.7551212310791016
Batch 36/64 loss: -1.4993410110473633
Batch 37/64 loss: -1.2786874771118164
Batch 38/64 loss: -1.4952430725097656
Batch 39/64 loss: -1.4961776733398438
Batch 40/64 loss: -1.648970603942871
Batch 41/64 loss: -1.371312141418457
Batch 42/64 loss: -1.5755596160888672
Batch 43/64 loss: -1.8745155334472656
Batch 44/64 loss: -1.5886459350585938
Batch 45/64 loss: -2.011812210083008
Batch 46/64 loss: -1.2653589248657227
Batch 47/64 loss: -1.6291389465332031
Batch 48/64 loss: -1.7033720016479492
Batch 49/64 loss: -1.3662986755371094
Batch 50/64 loss: -1.744222640991211
Batch 51/64 loss: -1.6305713653564453
Batch 52/64 loss: -1.3575916290283203
Batch 53/64 loss: -1.4157333374023438
Batch 54/64 loss: -1.6693954467773438
Batch 55/64 loss: -1.7010717391967773
Batch 56/64 loss: -2.0583724975585938
Batch 57/64 loss: -1.4688138961791992
Batch 58/64 loss: -1.7565078735351562
Batch 59/64 loss: -1.9148035049438477
Batch 60/64 loss: -1.715785026550293
Batch 61/64 loss: -1.3556718826293945
Batch 62/64 loss: -1.4849214553833008
Batch 63/64 loss: -1.3868169784545898
Batch 64/64 loss: -6.155547142028809
Epoch 55  Train loss: -1.5935184291764801  Val loss: -1.7011494718466427
Saving best model, epoch: 55
Epoch 56
-------------------------------
Batch 1/64 loss: -2.0527029037475586
Batch 2/64 loss: -1.5711822509765625
Batch 3/64 loss: -1.8370399475097656
Batch 4/64 loss: -1.8275871276855469
Batch 5/64 loss: -1.8132009506225586
Batch 6/64 loss: -1.4547882080078125
Batch 7/64 loss: -1.571298599243164
Batch 8/64 loss: -1.646097183227539
Batch 9/64 loss: -1.9197797775268555
Batch 10/64 loss: -1.8562955856323242
Batch 11/64 loss: -1.8803653717041016
Batch 12/64 loss: -1.9423208236694336
Batch 13/64 loss: -1.5239105224609375
Batch 14/64 loss: -1.6208162307739258
Batch 15/64 loss: -1.6589059829711914
Batch 16/64 loss: -1.4114322662353516
Batch 17/64 loss: -1.7230377197265625
Batch 18/64 loss: -1.576462745666504
Batch 19/64 loss: -1.7031688690185547
Batch 20/64 loss: -1.6510934829711914
Batch 21/64 loss: -1.7134895324707031
Batch 22/64 loss: -1.7389335632324219
Batch 23/64 loss: -1.5656070709228516
Batch 24/64 loss: -1.188232421875
Batch 25/64 loss: -1.6339750289916992
Batch 26/64 loss: -1.595902442932129
Batch 27/64 loss: -1.9619712829589844
Batch 28/64 loss: -1.3972663879394531
Batch 29/64 loss: -1.3648996353149414
Batch 30/64 loss: -1.634322166442871
Batch 31/64 loss: -1.8342456817626953
Batch 32/64 loss: -1.807784080505371
Batch 33/64 loss: -1.4544057846069336
Batch 34/64 loss: -1.5483427047729492
Batch 35/64 loss: -1.7846746444702148
Batch 36/64 loss: -1.3453903198242188
Batch 37/64 loss: -1.5434455871582031
Batch 38/64 loss: -1.9382219314575195
Batch 39/64 loss: -1.7681846618652344
Batch 40/64 loss: -1.7189245223999023
Batch 41/64 loss: -1.8391170501708984
Batch 42/64 loss: -1.5333757400512695
Batch 43/64 loss: -1.285447120666504
Batch 44/64 loss: -1.656020164489746
Batch 45/64 loss: -1.409123420715332
Batch 46/64 loss: -1.6119804382324219
Batch 47/64 loss: -1.3777389526367188
Batch 48/64 loss: -1.6891670227050781
Batch 49/64 loss: -0.5589914321899414
Batch 50/64 loss: -1.8702888488769531
Batch 51/64 loss: -1.1651430130004883
Batch 52/64 loss: -1.6841440200805664
Batch 53/64 loss: -1.3096399307250977
Batch 54/64 loss: -1.6758441925048828
Batch 55/64 loss: -1.4689149856567383
Batch 56/64 loss: -1.612135887145996
Batch 57/64 loss: -1.3906850814819336
Batch 58/64 loss: -1.3655414581298828
Batch 59/64 loss: -1.5659875869750977
Batch 60/64 loss: -1.9245185852050781
Batch 61/64 loss: -1.4622745513916016
Batch 62/64 loss: -1.3468599319458008
Batch 63/64 loss: -1.7386341094970703
Batch 64/64 loss: -5.155276775360107
Epoch 56  Train loss: -1.650003719329834  Val loss: -1.7704606465867294
Saving best model, epoch: 56
Epoch 57
-------------------------------
Batch 1/64 loss: -1.4219112396240234
Batch 2/64 loss: -1.7907466888427734
Batch 3/64 loss: -1.6630306243896484
Batch 4/64 loss: -1.652419090270996
Batch 5/64 loss: -1.3548650741577148
Batch 6/64 loss: -1.6759166717529297
Batch 7/64 loss: -1.7770709991455078
Batch 8/64 loss: -1.5335407257080078
Batch 9/64 loss: -1.6191234588623047
Batch 10/64 loss: -1.8287124633789062
Batch 11/64 loss: -1.7109012603759766
Batch 12/64 loss: -1.5951929092407227
Batch 13/64 loss: -1.4851608276367188
Batch 14/64 loss: -1.6529922485351562
Batch 15/64 loss: -1.5681791305541992
Batch 16/64 loss: -1.5707988739013672
Batch 17/64 loss: -1.4941539764404297
Batch 18/64 loss: -1.5637483596801758
Batch 19/64 loss: -1.8513250350952148
Batch 20/64 loss: -1.4311285018920898
Batch 21/64 loss: -1.7632455825805664
Batch 22/64 loss: -1.647308349609375
Batch 23/64 loss: -1.5578975677490234
Batch 24/64 loss: -1.5168256759643555
Batch 25/64 loss: -1.6382875442504883
Batch 26/64 loss: -1.5975284576416016
Batch 27/64 loss: -0.9260740280151367
Batch 28/64 loss: -1.517385482788086
Batch 29/64 loss: -1.614522933959961
Batch 30/64 loss: -1.7217350006103516
Batch 31/64 loss: -1.3523731231689453
Batch 32/64 loss: -1.6999597549438477
Batch 33/64 loss: -1.3804254531860352
Batch 34/64 loss: -1.9428119659423828
Batch 35/64 loss: -1.5587339401245117
Batch 36/64 loss: -1.4410390853881836
Batch 37/64 loss: -1.4615678787231445
Batch 38/64 loss: -1.7859115600585938
Batch 39/64 loss: -1.551447868347168
Batch 40/64 loss: -1.818619728088379
Batch 41/64 loss: -1.880990982055664
Batch 42/64 loss: -1.2836198806762695
Batch 43/64 loss: -1.799422264099121
Batch 44/64 loss: -1.7788562774658203
Batch 45/64 loss: -1.8655242919921875
Batch 46/64 loss: -1.8262958526611328
Batch 47/64 loss: -1.6845293045043945
Batch 48/64 loss: -1.5435686111450195
Batch 49/64 loss: -1.716714859008789
Batch 50/64 loss: -1.7152996063232422
Batch 51/64 loss: -1.6499853134155273
Batch 52/64 loss: -1.642533302307129
Batch 53/64 loss: -1.4332256317138672
Batch 54/64 loss: -1.6794919967651367
Batch 55/64 loss: -1.5070209503173828
Batch 56/64 loss: -1.6210746765136719
Batch 57/64 loss: -1.3966569900512695
Batch 58/64 loss: -1.457585334777832
Batch 59/64 loss: -1.767430305480957
Batch 60/64 loss: -1.7716083526611328
Batch 61/64 loss: -1.6031208038330078
Batch 62/64 loss: -1.6118431091308594
Batch 63/64 loss: -1.8036298751831055
Batch 64/64 loss: -6.152760982513428
Epoch 57  Train loss: -1.6688504854838053  Val loss: -1.7020041999947984
Epoch 58
-------------------------------
Batch 1/64 loss: -1.6604938507080078
Batch 2/64 loss: -0.7976865768432617
Batch 3/64 loss: -1.7359418869018555
Batch 4/64 loss: -1.68719482421875
Batch 5/64 loss: -1.772547721862793
Batch 6/64 loss: -1.374603271484375
Batch 7/64 loss: -1.4439811706542969
Batch 8/64 loss: -1.7544183731079102
Batch 9/64 loss: -1.2600164413452148
Batch 10/64 loss: -1.5832338333129883
Batch 11/64 loss: -1.4583940505981445
Batch 12/64 loss: -1.4192476272583008
Batch 13/64 loss: -1.6723833084106445
Batch 14/64 loss: -1.6145086288452148
Batch 15/64 loss: -1.6344013214111328
Batch 16/64 loss: -1.8680572509765625
Batch 17/64 loss: -1.9473905563354492
Batch 18/64 loss: -1.7182073593139648
Batch 19/64 loss: -1.343679428100586
Batch 20/64 loss: -1.8734493255615234
Batch 21/64 loss: -1.984628677368164
Batch 22/64 loss: -1.4282808303833008
Batch 23/64 loss: -0.9951305389404297
Batch 24/64 loss: -1.359522819519043
Batch 25/64 loss: -1.7400493621826172
Batch 26/64 loss: -1.7849998474121094
Batch 27/64 loss: -1.7663536071777344
Batch 28/64 loss: -1.6834535598754883
Batch 29/64 loss: -2.002962112426758
Batch 30/64 loss: -1.961207389831543
Batch 31/64 loss: -1.5388202667236328
Batch 32/64 loss: -1.9011096954345703
Batch 33/64 loss: -1.4612932205200195
Batch 34/64 loss: -1.2312707901000977
Batch 35/64 loss: -1.8643856048583984
Batch 36/64 loss: -1.6415739059448242
Batch 37/64 loss: -1.6817922592163086
Batch 38/64 loss: -1.3331689834594727
Batch 39/64 loss: -1.7367429733276367
Batch 40/64 loss: -1.7348337173461914
Batch 41/64 loss: -1.4699268341064453
Batch 42/64 loss: -1.6021337509155273
Batch 43/64 loss: -1.5147762298583984
Batch 44/64 loss: -1.348280906677246
Batch 45/64 loss: -1.8473529815673828
Batch 46/64 loss: -1.5534095764160156
Batch 47/64 loss: -1.6374168395996094
Batch 48/64 loss: -1.4672307968139648
Batch 49/64 loss: -1.8884944915771484
Batch 50/64 loss: -1.4993858337402344
Batch 51/64 loss: -1.7577543258666992
Batch 52/64 loss: -1.6465978622436523
Batch 53/64 loss: -1.895040512084961
Batch 54/64 loss: -1.7743492126464844
Batch 55/64 loss: -1.7558221817016602
Batch 56/64 loss: -1.3748092651367188
Batch 57/64 loss: -1.635573387145996
Batch 58/64 loss: -1.5639562606811523
Batch 59/64 loss: -1.9417724609375
Batch 60/64 loss: -1.9121780395507812
Batch 61/64 loss: -1.9128456115722656
Batch 62/64 loss: -1.6312227249145508
Batch 63/64 loss: -1.6551485061645508
Batch 64/64 loss: -5.85034704208374
Epoch 58  Train loss: -1.6803867583181344  Val loss: -1.7373494806977892
Epoch 59
-------------------------------
Batch 1/64 loss: -1.7308921813964844
Batch 2/64 loss: -1.6722326278686523
Batch 3/64 loss: -1.759805679321289
Batch 4/64 loss: -1.7500238418579102
Batch 5/64 loss: -1.722947120666504
Batch 6/64 loss: -1.1976966857910156
Batch 7/64 loss: -1.2291240692138672
Batch 8/64 loss: -1.5190143585205078
Batch 9/64 loss: -1.391545295715332
Batch 10/64 loss: -1.8512868881225586
Batch 11/64 loss: -1.6838092803955078
Batch 12/64 loss: -1.8294811248779297
Batch 13/64 loss: -1.412409782409668
Batch 14/64 loss: -1.657440185546875
Batch 15/64 loss: -1.5076675415039062
Batch 16/64 loss: -1.5315017700195312
Batch 17/64 loss: -1.4099178314208984
Batch 18/64 loss: -1.9949111938476562
Batch 19/64 loss: -1.5086793899536133
Batch 20/64 loss: -1.7675275802612305
Batch 21/64 loss: -1.4566411972045898
Batch 22/64 loss: -1.7871522903442383
Batch 23/64 loss: -1.6898307800292969
Batch 24/64 loss: -1.5331430435180664
Batch 25/64 loss: -1.4123554229736328
Batch 26/64 loss: -1.6770153045654297
Batch 27/64 loss: -1.3454055786132812
Batch 28/64 loss: -1.9854984283447266
Batch 29/64 loss: -1.6425848007202148
Batch 30/64 loss: -1.8600120544433594
Batch 31/64 loss: -1.4745044708251953
Batch 32/64 loss: -1.6782922744750977
Batch 33/64 loss: -1.2312088012695312
Batch 34/64 loss: -1.6231756210327148
Batch 35/64 loss: -1.9479494094848633
Batch 36/64 loss: -1.813441276550293
Batch 37/64 loss: -1.7619667053222656
Batch 38/64 loss: -1.6663637161254883
Batch 39/64 loss: -1.8471565246582031
Batch 40/64 loss: -2.043911933898926
Batch 41/64 loss: -1.8564949035644531
Batch 42/64 loss: -1.4673852920532227
Batch 43/64 loss: -1.3613100051879883
Batch 44/64 loss: -1.7139873504638672
Batch 45/64 loss: -1.5971784591674805
Batch 46/64 loss: -1.5936641693115234
Batch 47/64 loss: -1.624028205871582
Batch 48/64 loss: -1.7126483917236328
Batch 49/64 loss: -1.6147937774658203
Batch 50/64 loss: -1.814682960510254
Batch 51/64 loss: -2.001026153564453
Batch 52/64 loss: -1.3566761016845703
Batch 53/64 loss: -1.5799598693847656
Batch 54/64 loss: -1.940155029296875
Batch 55/64 loss: -1.646615982055664
Batch 56/64 loss: -1.7910547256469727
Batch 57/64 loss: -1.9492301940917969
Batch 58/64 loss: -1.512101173400879
Batch 59/64 loss: -1.750502586364746
Batch 60/64 loss: -1.389089584350586
Batch 61/64 loss: -1.7650480270385742
Batch 62/64 loss: -1.6247434616088867
Batch 63/64 loss: -1.4829158782958984
Batch 64/64 loss: -6.035665988922119
Epoch 59  Train loss: -1.6984716209710813  Val loss: -1.7920990776769894
Saving best model, epoch: 59
Epoch 60
-------------------------------
Batch 1/64 loss: -1.7820777893066406
Batch 2/64 loss: -1.4419078826904297
Batch 3/64 loss: -1.7677984237670898
Batch 4/64 loss: -1.7001323699951172
Batch 5/64 loss: -1.3597431182861328
Batch 6/64 loss: -1.6948347091674805
Batch 7/64 loss: -1.707784652709961
Batch 8/64 loss: -1.8718175888061523
Batch 9/64 loss: -1.7961902618408203
Batch 10/64 loss: -1.4758167266845703
Batch 11/64 loss: -1.9828147888183594
Batch 12/64 loss: -1.2809324264526367
Batch 13/64 loss: -1.7899742126464844
Batch 14/64 loss: -1.6423931121826172
Batch 15/64 loss: -1.519270896911621
Batch 16/64 loss: -1.470719337463379
Batch 17/64 loss: -1.5604219436645508
Batch 18/64 loss: -1.6632871627807617
Batch 19/64 loss: -1.596491813659668
Batch 20/64 loss: -1.1142692565917969
Batch 21/64 loss: -1.381185531616211
Batch 22/64 loss: -1.6326360702514648
Batch 23/64 loss: -1.593602180480957
Batch 24/64 loss: -1.3579673767089844
Batch 25/64 loss: -1.5593528747558594
Batch 26/64 loss: -1.666886329650879
Batch 27/64 loss: -1.4355058670043945
Batch 28/64 loss: -1.4818906784057617
Batch 29/64 loss: -1.7434511184692383
Batch 30/64 loss: -1.649510383605957
Batch 31/64 loss: -1.66644287109375
Batch 32/64 loss: -1.6237382888793945
Batch 33/64 loss: -1.9110889434814453
Batch 34/64 loss: -1.5834016799926758
Batch 35/64 loss: -1.4409732818603516
Batch 36/64 loss: -1.8419389724731445
Batch 37/64 loss: -1.5054168701171875
Batch 38/64 loss: -1.9331636428833008
Batch 39/64 loss: -1.7015161514282227
Batch 40/64 loss: -1.7671728134155273
Batch 41/64 loss: -1.7477331161499023
Batch 42/64 loss: -2.0120534896850586
Batch 43/64 loss: -1.7799110412597656
Batch 44/64 loss: -1.870020866394043
Batch 45/64 loss: -1.7475061416625977
Batch 46/64 loss: -1.1145153045654297
Batch 47/64 loss: -1.5486679077148438
Batch 48/64 loss: -1.3896284103393555
Batch 49/64 loss: -1.9230785369873047
Batch 50/64 loss: -1.6239852905273438
Batch 51/64 loss: -1.9319829940795898
Batch 52/64 loss: -1.7324609756469727
Batch 53/64 loss: -2.028697967529297
Batch 54/64 loss: -1.3391122817993164
Batch 55/64 loss: -1.5695257186889648
Batch 56/64 loss: -1.724198341369629
Batch 57/64 loss: -1.4388542175292969
Batch 58/64 loss: -1.7511558532714844
Batch 59/64 loss: -1.7510709762573242
Batch 60/64 loss: -1.6102218627929688
Batch 61/64 loss: -1.5958023071289062
Batch 62/64 loss: -1.8457069396972656
Batch 63/64 loss: -1.7589445114135742
Batch 64/64 loss: -6.313313961029053
Epoch 60  Train loss: -1.698279857635498  Val loss: -1.7596398972973382
Epoch 61
-------------------------------
Batch 1/64 loss: -1.9591026306152344
Batch 2/64 loss: -1.527918815612793
Batch 3/64 loss: -1.4978809356689453
Batch 4/64 loss: -1.7703914642333984
Batch 5/64 loss: -1.6182069778442383
Batch 6/64 loss: -1.3620147705078125
Batch 7/64 loss: -1.5837221145629883
Batch 8/64 loss: -1.838587760925293
Batch 9/64 loss: -1.8848066329956055
Batch 10/64 loss: -1.4171371459960938
Batch 11/64 loss: -1.5323171615600586
Batch 12/64 loss: -1.49346923828125
Batch 13/64 loss: -1.8312454223632812
Batch 14/64 loss: -1.6942977905273438
Batch 15/64 loss: -1.628173828125
Batch 16/64 loss: -1.7244129180908203
Batch 17/64 loss: -1.936920166015625
Batch 18/64 loss: -1.543675422668457
Batch 19/64 loss: -0.5309009552001953
Batch 20/64 loss: -2.0861730575561523
Batch 21/64 loss: -1.431849479675293
Batch 22/64 loss: -1.7795381546020508
Batch 23/64 loss: -1.3826265335083008
Batch 24/64 loss: -1.4329328536987305
Batch 25/64 loss: -1.561385154724121
Batch 26/64 loss: -1.728994369506836
Batch 27/64 loss: -1.7281064987182617
Batch 28/64 loss: -1.3525257110595703
Batch 29/64 loss: -1.3288793563842773
Batch 30/64 loss: -1.8314647674560547
Batch 31/64 loss: -1.5963716506958008
Batch 32/64 loss: -1.8771095275878906
Batch 33/64 loss: -1.7043218612670898
Batch 34/64 loss: -1.3783493041992188
Batch 35/64 loss: -1.2912864685058594
Batch 36/64 loss: -1.1834630966186523
Batch 37/64 loss: -1.6936750411987305
Batch 38/64 loss: -1.494450569152832
Batch 39/64 loss: -1.6635522842407227
Batch 40/64 loss: -1.6359128952026367
Batch 41/64 loss: -1.5823612213134766
Batch 42/64 loss: -1.673614501953125
Batch 43/64 loss: -1.7771778106689453
Batch 44/64 loss: -1.5031452178955078
Batch 45/64 loss: -1.825857162475586
Batch 46/64 loss: -1.8151941299438477
Batch 47/64 loss: -1.5674419403076172
Batch 48/64 loss: -1.8773107528686523
Batch 49/64 loss: -1.867995262145996
Batch 50/64 loss: -1.520517349243164
Batch 51/64 loss: -1.8843793869018555
Batch 52/64 loss: -1.8117609024047852
Batch 53/64 loss: -1.7541980743408203
Batch 54/64 loss: -1.5735788345336914
Batch 55/64 loss: -1.392786979675293
Batch 56/64 loss: -1.754561424255371
Batch 57/64 loss: -1.9144554138183594
Batch 58/64 loss: -1.8952817916870117
Batch 59/64 loss: -1.5496177673339844
Batch 60/64 loss: -1.5582895278930664
Batch 61/64 loss: -1.823080062866211
Batch 62/64 loss: -1.8187942504882812
Batch 63/64 loss: -1.8002147674560547
Batch 64/64 loss: -5.756859302520752
Epoch 61  Train loss: -1.684665251713173  Val loss: -1.8174916034711595
Saving best model, epoch: 61
Epoch 62
-------------------------------
Batch 1/64 loss: -1.6750717163085938
Batch 2/64 loss: -1.7371997833251953
Batch 3/64 loss: -1.9007511138916016
Batch 4/64 loss: -1.455225944519043
Batch 5/64 loss: -1.741434097290039
Batch 6/64 loss: -1.5696096420288086
Batch 7/64 loss: -1.7718191146850586
Batch 8/64 loss: -1.1676082611083984
Batch 9/64 loss: -1.602452278137207
Batch 10/64 loss: -1.736689567565918
Batch 11/64 loss: -1.9898672103881836
Batch 12/64 loss: -1.4583864212036133
Batch 13/64 loss: -1.5099124908447266
Batch 14/64 loss: -1.6707773208618164
Batch 15/64 loss: -1.7967634201049805
Batch 16/64 loss: -1.1843986511230469
Batch 17/64 loss: -1.672236442565918
Batch 18/64 loss: -1.7220401763916016
Batch 19/64 loss: -1.881138801574707
Batch 20/64 loss: -1.5737113952636719
Batch 21/64 loss: -1.6551580429077148
Batch 22/64 loss: -1.793975830078125
Batch 23/64 loss: -1.8197669982910156
Batch 24/64 loss: -1.755767822265625
Batch 25/64 loss: -2.0096492767333984
Batch 26/64 loss: -1.2752866744995117
Batch 27/64 loss: -1.990631103515625
Batch 28/64 loss: -1.7327156066894531
Batch 29/64 loss: -1.964085578918457
Batch 30/64 loss: -1.9457244873046875
Batch 31/64 loss: -1.5291833877563477
Batch 32/64 loss: -1.7944869995117188
Batch 33/64 loss: -1.5557031631469727
Batch 34/64 loss: -1.6642866134643555
Batch 35/64 loss: -1.7450923919677734
Batch 36/64 loss: -1.6553153991699219
Batch 37/64 loss: -1.5172443389892578
Batch 38/64 loss: -1.6848888397216797
Batch 39/64 loss: -1.9512805938720703
Batch 40/64 loss: -1.5264034271240234
Batch 41/64 loss: -1.7733144760131836
Batch 42/64 loss: -1.5291109085083008
Batch 43/64 loss: -1.9736385345458984
Batch 44/64 loss: -1.9326963424682617
Batch 45/64 loss: -1.4164867401123047
Batch 46/64 loss: -1.800424575805664
Batch 47/64 loss: -1.610203742980957
Batch 48/64 loss: -1.680002212524414
Batch 49/64 loss: -1.2843208312988281
Batch 50/64 loss: -1.8419380187988281
Batch 51/64 loss: -1.6000385284423828
Batch 52/64 loss: -1.789729118347168
Batch 53/64 loss: -1.577195167541504
Batch 54/64 loss: -1.6185722351074219
Batch 55/64 loss: -1.7665128707885742
Batch 56/64 loss: -1.5941476821899414
Batch 57/64 loss: -0.9695596694946289
Batch 58/64 loss: -1.5190887451171875
Batch 59/64 loss: -1.753464698791504
Batch 60/64 loss: -1.5800809860229492
Batch 61/64 loss: -1.9014892578125
Batch 62/64 loss: -1.395986557006836
Batch 63/64 loss: -1.745713233947754
Batch 64/64 loss: -5.9106621742248535
Epoch 62  Train loss: -1.7171835637560078  Val loss: -1.908349735220683
Saving best model, epoch: 62
Epoch 63
-------------------------------
Batch 1/64 loss: -1.9103450775146484
Batch 2/64 loss: -1.6830883026123047
Batch 3/64 loss: -1.602890968322754
Batch 4/64 loss: -1.7580652236938477
Batch 5/64 loss: -1.738297462463379
Batch 6/64 loss: -1.4357471466064453
Batch 7/64 loss: -1.9771156311035156
Batch 8/64 loss: -1.3842735290527344
Batch 9/64 loss: -1.876601219177246
Batch 10/64 loss: -1.792947769165039
Batch 11/64 loss: -2.058535575866699
Batch 12/64 loss: -1.352808952331543
Batch 13/64 loss: -1.683298110961914
Batch 14/64 loss: -1.6894664764404297
Batch 15/64 loss: -1.4021720886230469
Batch 16/64 loss: -1.7927780151367188
Batch 17/64 loss: -1.7529630661010742
Batch 18/64 loss: -1.775986671447754
Batch 19/64 loss: -1.4160146713256836
Batch 20/64 loss: -1.7077865600585938
Batch 21/64 loss: -1.9870023727416992
Batch 22/64 loss: -1.6257905960083008
Batch 23/64 loss: -1.5790824890136719
Batch 24/64 loss: -1.6942548751831055
Batch 25/64 loss: -1.8407878875732422
Batch 26/64 loss: -1.7745122909545898
Batch 27/64 loss: -1.9117202758789062
Batch 28/64 loss: -1.6479768753051758
Batch 29/64 loss: -1.5061511993408203
Batch 30/64 loss: -1.8545160293579102
Batch 31/64 loss: -1.506281852722168
Batch 32/64 loss: -1.686936378479004
Batch 33/64 loss: -1.706216812133789
Batch 34/64 loss: -1.83203125
Batch 35/64 loss: -1.9475221633911133
Batch 36/64 loss: -1.6364316940307617
Batch 37/64 loss: -1.501129150390625
Batch 38/64 loss: -1.5589714050292969
Batch 39/64 loss: -1.6711292266845703
Batch 40/64 loss: -1.638932228088379
Batch 41/64 loss: -1.641566276550293
Batch 42/64 loss: -1.7786798477172852
Batch 43/64 loss: -1.6986827850341797
Batch 44/64 loss: -1.8244600296020508
Batch 45/64 loss: -1.4982690811157227
Batch 46/64 loss: -2.0319900512695312
Batch 47/64 loss: -1.6209783554077148
Batch 48/64 loss: -1.4830570220947266
Batch 49/64 loss: -1.438307762145996
Batch 50/64 loss: -1.8656644821166992
Batch 51/64 loss: -1.914937973022461
Batch 52/64 loss: -1.7540369033813477
Batch 53/64 loss: -0.7903051376342773
Batch 54/64 loss: -1.6783332824707031
Batch 55/64 loss: -1.7151355743408203
Batch 56/64 loss: -1.3746089935302734
Batch 57/64 loss: -1.5627269744873047
Batch 58/64 loss: -1.3367462158203125
Batch 59/64 loss: -1.5738086700439453
Batch 60/64 loss: -1.696578025817871
Batch 61/64 loss: -1.6586933135986328
Batch 62/64 loss: -1.9729747772216797
Batch 63/64 loss: -1.3978681564331055
Batch 64/64 loss: -5.8062310218811035
Epoch 63  Train loss: -1.7186140004326316  Val loss: -1.8368141069445003
Epoch 64
-------------------------------
Batch 1/64 loss: -1.7025318145751953
Batch 2/64 loss: -1.8865966796875
Batch 3/64 loss: -1.4724082946777344
Batch 4/64 loss: -2.0105085372924805
Batch 5/64 loss: -1.7981224060058594
Batch 6/64 loss: -1.154475212097168
Batch 7/64 loss: -1.8651924133300781
Batch 8/64 loss: -1.6023139953613281
Batch 9/64 loss: -1.7143630981445312
Batch 10/64 loss: -1.8879709243774414
Batch 11/64 loss: -1.8734893798828125
Batch 12/64 loss: -1.5320825576782227
Batch 13/64 loss: -1.5190792083740234
Batch 14/64 loss: -1.593160629272461
Batch 15/64 loss: -1.8714237213134766
Batch 16/64 loss: -1.929184913635254
Batch 17/64 loss: -1.774709701538086
Batch 18/64 loss: -2.0048532485961914
Batch 19/64 loss: -1.6101999282836914
Batch 20/64 loss: -1.9765634536743164
Batch 21/64 loss: -1.7833251953125
Batch 22/64 loss: -2.0086755752563477
Batch 23/64 loss: -1.3224048614501953
Batch 24/64 loss: -1.4248466491699219
Batch 25/64 loss: -1.4092655181884766
Batch 26/64 loss: -1.8000297546386719
Batch 27/64 loss: -1.867487907409668
Batch 28/64 loss: -1.9348697662353516
Batch 29/64 loss: -1.8326101303100586
Batch 30/64 loss: -1.9999170303344727
Batch 31/64 loss: -1.7582883834838867
Batch 32/64 loss: -1.2599849700927734
Batch 33/64 loss: -1.5830039978027344
Batch 34/64 loss: -1.285177230834961
Batch 35/64 loss: -1.0959606170654297
Batch 36/64 loss: -1.6529731750488281
Batch 37/64 loss: -1.3858356475830078
Batch 38/64 loss: -1.8180656433105469
Batch 39/64 loss: -1.9400205612182617
Batch 40/64 loss: -1.7382173538208008
Batch 41/64 loss: -1.6444358825683594
Batch 42/64 loss: -1.2706775665283203
Batch 43/64 loss: -1.856125831604004
Batch 44/64 loss: -1.7183351516723633
Batch 45/64 loss: -1.941533088684082
Batch 46/64 loss: -1.638758659362793
Batch 47/64 loss: -1.6632719039916992
Batch 48/64 loss: -1.2500181198120117
Batch 49/64 loss: -1.768519401550293
Batch 50/64 loss: -1.953343391418457
Batch 51/64 loss: -1.815023422241211
Batch 52/64 loss: -1.989511489868164
Batch 53/64 loss: -1.2632255554199219
Batch 54/64 loss: -1.6512470245361328
Batch 55/64 loss: -1.5436992645263672
Batch 56/64 loss: -1.9541988372802734
Batch 57/64 loss: -1.7839889526367188
Batch 58/64 loss: -1.8504257202148438
Batch 59/64 loss: -1.6207923889160156
Batch 60/64 loss: -1.9414777755737305
Batch 61/64 loss: -1.3346214294433594
Batch 62/64 loss: -1.7086563110351562
Batch 63/64 loss: -1.8611173629760742
Batch 64/64 loss: -6.224555015563965
Epoch 64  Train loss: -1.7470056608611462  Val loss: -1.8937544281949703
Epoch 65
-------------------------------
Batch 1/64 loss: -1.745401382446289
Batch 2/64 loss: -1.5785236358642578
Batch 3/64 loss: -1.4526634216308594
Batch 4/64 loss: -1.5555229187011719
Batch 5/64 loss: -1.953577995300293
Batch 6/64 loss: -1.618391990661621
Batch 7/64 loss: -1.8143796920776367
Batch 8/64 loss: -1.6451406478881836
Batch 9/64 loss: -1.4688940048217773
Batch 10/64 loss: -1.5588245391845703
Batch 11/64 loss: -1.6952142715454102
Batch 12/64 loss: -1.6438665390014648
Batch 13/64 loss: -1.901627540588379
Batch 14/64 loss: -1.4671783447265625
Batch 15/64 loss: -2.142488479614258
Batch 16/64 loss: -1.6067142486572266
Batch 17/64 loss: -1.9578475952148438
Batch 18/64 loss: -2.1011962890625
Batch 19/64 loss: -1.8590307235717773
Batch 20/64 loss: -1.8843965530395508
Batch 21/64 loss: -1.7078914642333984
Batch 22/64 loss: -1.6231136322021484
Batch 23/64 loss: -1.988694190979004
Batch 24/64 loss: -1.6423530578613281
Batch 25/64 loss: -2.050579071044922
Batch 26/64 loss: -1.476893424987793
Batch 27/64 loss: -1.652700424194336
Batch 28/64 loss: -1.6568174362182617
Batch 29/64 loss: -1.92572021484375
Batch 30/64 loss: -1.8251667022705078
Batch 31/64 loss: -1.4099225997924805
Batch 32/64 loss: -1.7335929870605469
Batch 33/64 loss: -1.5554962158203125
Batch 34/64 loss: -1.5792760848999023
Batch 35/64 loss: -1.8457164764404297
Batch 36/64 loss: -1.7665319442749023
Batch 37/64 loss: -1.838369369506836
Batch 38/64 loss: -1.0213565826416016
Batch 39/64 loss: -1.8787727355957031
Batch 40/64 loss: -1.8026742935180664
Batch 41/64 loss: -1.611098289489746
Batch 42/64 loss: -1.5003509521484375
Batch 43/64 loss: -1.7607231140136719
Batch 44/64 loss: -1.2877740859985352
Batch 45/64 loss: -1.9594316482543945
Batch 46/64 loss: -1.9085779190063477
Batch 47/64 loss: -1.7414979934692383
Batch 48/64 loss: -1.9678621292114258
Batch 49/64 loss: -2.0670957565307617
Batch 50/64 loss: -1.7882843017578125
Batch 51/64 loss: -1.2114582061767578
Batch 52/64 loss: -1.3124761581420898
Batch 53/64 loss: -2.0669078826904297
Batch 54/64 loss: -1.789311408996582
Batch 55/64 loss: -1.9216642379760742
Batch 56/64 loss: -2.0343122482299805
Batch 57/64 loss: -1.5663871765136719
Batch 58/64 loss: -1.3005590438842773
Batch 59/64 loss: -1.838129997253418
Batch 60/64 loss: -1.8296623229980469
Batch 61/64 loss: -1.797896385192871
Batch 62/64 loss: -1.6032485961914062
Batch 63/64 loss: -1.9338197708129883
Batch 64/64 loss: -5.994036674499512
Epoch 65  Train loss: -1.7713972839654661  Val loss: -1.7949801179551588
Epoch 66
-------------------------------
Batch 1/64 loss: -1.5553741455078125
Batch 2/64 loss: -1.537196159362793
Batch 3/64 loss: -1.9415922164916992
Batch 4/64 loss: -1.8370075225830078
Batch 5/64 loss: -1.518113136291504
Batch 6/64 loss: -1.8741655349731445
Batch 7/64 loss: -1.3576154708862305
Batch 8/64 loss: -1.693532943725586
Batch 9/64 loss: -1.7650680541992188
Batch 10/64 loss: -1.1397666931152344
Batch 11/64 loss: -1.6310625076293945
Batch 12/64 loss: -1.7661447525024414
Batch 13/64 loss: -1.5931167602539062
Batch 14/64 loss: -1.9289522171020508
Batch 15/64 loss: -1.6053142547607422
Batch 16/64 loss: -1.8829727172851562
Batch 17/64 loss: -1.6258583068847656
Batch 18/64 loss: -1.536977767944336
Batch 19/64 loss: -1.543130874633789
Batch 20/64 loss: -1.7498226165771484
Batch 21/64 loss: -1.5883302688598633
Batch 22/64 loss: -1.590376853942871
Batch 23/64 loss: -1.2953195571899414
Batch 24/64 loss: -1.921595573425293
Batch 25/64 loss: -1.7720861434936523
Batch 26/64 loss: -1.4121065139770508
Batch 27/64 loss: -1.6484785079956055
Batch 28/64 loss: -1.29132080078125
Batch 29/64 loss: -1.9291887283325195
Batch 30/64 loss: -2.005032539367676
Batch 31/64 loss: -1.868295669555664
Batch 32/64 loss: -1.8368568420410156
Batch 33/64 loss: -1.7819585800170898
Batch 34/64 loss: -2.1621522903442383
Batch 35/64 loss: -1.733938217163086
Batch 36/64 loss: -2.020040512084961
Batch 37/64 loss: -1.596841812133789
Batch 38/64 loss: -1.7248620986938477
Batch 39/64 loss: -1.7012834548950195
Batch 40/64 loss: -1.4847707748413086
Batch 41/64 loss: -1.7052192687988281
Batch 42/64 loss: -1.8811759948730469
Batch 43/64 loss: -1.860243797302246
Batch 44/64 loss: -1.6608953475952148
Batch 45/64 loss: -1.6916275024414062
Batch 46/64 loss: -1.6785335540771484
Batch 47/64 loss: -1.9980792999267578
Batch 48/64 loss: -1.9245548248291016
Batch 49/64 loss: -2.03298282623291
Batch 50/64 loss: -2.0542917251586914
Batch 51/64 loss: -2.0185441970825195
Batch 52/64 loss: -1.5981483459472656
Batch 53/64 loss: -1.9068899154663086
Batch 54/64 loss: -1.9327239990234375
Batch 55/64 loss: -2.1518497467041016
Batch 56/64 loss: -2.0108747482299805
Batch 57/64 loss: -2.1346778869628906
Batch 58/64 loss: -1.969956398010254
Batch 59/64 loss: -1.419266700744629
Batch 60/64 loss: -1.817276954650879
Batch 61/64 loss: -1.5793828964233398
Batch 62/64 loss: -1.9623088836669922
Batch 63/64 loss: -1.570570945739746
Batch 64/64 loss: -5.9289045333862305
Epoch 66  Train loss: -1.7953627380670285  Val loss: -1.9417053301309801
Saving best model, epoch: 66
Epoch 67
-------------------------------
Batch 1/64 loss: -1.8902320861816406
Batch 2/64 loss: -1.794708251953125
Batch 3/64 loss: -1.8863859176635742
Batch 4/64 loss: -2.035153388977051
Batch 5/64 loss: -1.4855413436889648
Batch 6/64 loss: -1.4472475051879883
Batch 7/64 loss: -1.642979621887207
Batch 8/64 loss: -1.898636817932129
Batch 9/64 loss: -1.8225164413452148
Batch 10/64 loss: -1.592508316040039
Batch 11/64 loss: -1.8666210174560547
Batch 12/64 loss: -1.501399040222168
Batch 13/64 loss: -1.6875953674316406
Batch 14/64 loss: -2.004270553588867
Batch 15/64 loss: -2.035895347595215
Batch 16/64 loss: -1.857874870300293
Batch 17/64 loss: -1.9117889404296875
Batch 18/64 loss: -1.835052490234375
Batch 19/64 loss: -1.9974308013916016
Batch 20/64 loss: -1.7313899993896484
Batch 21/64 loss: -1.8370904922485352
Batch 22/64 loss: -1.9009590148925781
Batch 23/64 loss: -1.9985952377319336
Batch 24/64 loss: -1.3820829391479492
Batch 25/64 loss: -1.8668498992919922
Batch 26/64 loss: -1.524815559387207
Batch 27/64 loss: -1.8083019256591797
Batch 28/64 loss: -1.6551904678344727
Batch 29/64 loss: -1.8464813232421875
Batch 30/64 loss: -1.488576889038086
Batch 31/64 loss: -1.8654298782348633
Batch 32/64 loss: -0.9816780090332031
Batch 33/64 loss: -1.8316755294799805
Batch 34/64 loss: -1.6112232208251953
Batch 35/64 loss: -1.3517341613769531
Batch 36/64 loss: -1.516519546508789
Batch 37/64 loss: -1.607588768005371
Batch 38/64 loss: -1.6806879043579102
Batch 39/64 loss: -1.997666358947754
Batch 40/64 loss: -1.6988296508789062
Batch 41/64 loss: -1.5943641662597656
Batch 42/64 loss: -1.8900117874145508
Batch 43/64 loss: -1.8209075927734375
Batch 44/64 loss: -1.5984716415405273
Batch 45/64 loss: -1.7600879669189453
Batch 46/64 loss: -2.182241439819336
Batch 47/64 loss: -1.8624334335327148
Batch 48/64 loss: -1.701578140258789
Batch 49/64 loss: -1.9977874755859375
Batch 50/64 loss: -1.5453910827636719
Batch 51/64 loss: -1.8775625228881836
Batch 52/64 loss: -1.7972307205200195
Batch 53/64 loss: -1.7470512390136719
Batch 54/64 loss: -1.5544500350952148
Batch 55/64 loss: -1.7294464111328125
Batch 56/64 loss: -1.4893836975097656
Batch 57/64 loss: -1.7583236694335938
Batch 58/64 loss: -1.8522968292236328
Batch 59/64 loss: -1.6935186386108398
Batch 60/64 loss: -1.7608089447021484
Batch 61/64 loss: -1.4787778854370117
Batch 62/64 loss: -2.033135414123535
Batch 63/64 loss: -1.8419837951660156
Batch 64/64 loss: -6.125045299530029
Epoch 67  Train loss: -1.796678170970842  Val loss: -1.9493660287758738
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: -1.6946287155151367
Batch 2/64 loss: -2.16953182220459
Batch 3/64 loss: -1.6162223815917969
Batch 4/64 loss: -1.4821128845214844
Batch 5/64 loss: -1.1633644104003906
Batch 6/64 loss: -1.7201080322265625
Batch 7/64 loss: -1.5871992111206055
Batch 8/64 loss: -1.3788137435913086
Batch 9/64 loss: -1.7414627075195312
Batch 10/64 loss: -1.932687759399414
Batch 11/64 loss: -1.7801389694213867
Batch 12/64 loss: -2.026426315307617
Batch 13/64 loss: -2.127713203430176
Batch 14/64 loss: -1.9976720809936523
Batch 15/64 loss: -1.4779281616210938
Batch 16/64 loss: -2.0895700454711914
Batch 17/64 loss: -1.7014055252075195
Batch 18/64 loss: -1.8451356887817383
Batch 19/64 loss: -2.018040657043457
Batch 20/64 loss: -1.7242002487182617
Batch 21/64 loss: -1.6955499649047852
Batch 22/64 loss: -1.4036684036254883
Batch 23/64 loss: -1.4796810150146484
Batch 24/64 loss: -1.8806743621826172
Batch 25/64 loss: -1.7305126190185547
Batch 26/64 loss: -2.0251379013061523
Batch 27/64 loss: -1.6657209396362305
Batch 28/64 loss: -1.6212224960327148
Batch 29/64 loss: -1.6193370819091797
Batch 30/64 loss: -1.7378301620483398
Batch 31/64 loss: -1.3443021774291992
Batch 32/64 loss: -1.843308448791504
Batch 33/64 loss: -1.9707155227661133
Batch 34/64 loss: -1.9038162231445312
Batch 35/64 loss: -2.0615768432617188
Batch 36/64 loss: -1.4451351165771484
Batch 37/64 loss: -2.1084251403808594
Batch 38/64 loss: -1.711888313293457
Batch 39/64 loss: -1.718989372253418
Batch 40/64 loss: -1.3977794647216797
Batch 41/64 loss: -1.9065618515014648
Batch 42/64 loss: -1.8681764602661133
Batch 43/64 loss: -1.9203519821166992
Batch 44/64 loss: -2.0423049926757812
Batch 45/64 loss: -1.357107162475586
Batch 46/64 loss: -1.7994709014892578
Batch 47/64 loss: -2.128188133239746
Batch 48/64 loss: -1.2271413803100586
Batch 49/64 loss: -1.7943105697631836
Batch 50/64 loss: -1.8518705368041992
Batch 51/64 loss: -1.9474153518676758
Batch 52/64 loss: -1.7253131866455078
Batch 53/64 loss: -1.9735584259033203
Batch 54/64 loss: -1.6225814819335938
Batch 55/64 loss: -1.6369028091430664
Batch 56/64 loss: -1.8552169799804688
Batch 57/64 loss: -1.9854440689086914
Batch 58/64 loss: -1.8781309127807617
Batch 59/64 loss: -1.5570716857910156
Batch 60/64 loss: -1.6118698120117188
Batch 61/64 loss: -1.7955646514892578
Batch 62/64 loss: -1.806971549987793
Batch 63/64 loss: -1.8053655624389648
Batch 64/64 loss: -6.393892288208008
Epoch 68  Train loss: -1.812265785067689  Val loss: -2.045915374231502
Saving best model, epoch: 68
Epoch 69
-------------------------------
Batch 1/64 loss: -1.8728399276733398
Batch 2/64 loss: -1.863785743713379
Batch 3/64 loss: -1.9240407943725586
Batch 4/64 loss: -1.569467544555664
Batch 5/64 loss: -1.8663110733032227
Batch 6/64 loss: -1.8598623275756836
Batch 7/64 loss: -1.8793907165527344
Batch 8/64 loss: -1.5738639831542969
Batch 9/64 loss: -1.820998191833496
Batch 10/64 loss: -2.1572389602661133
Batch 11/64 loss: -1.988077163696289
Batch 12/64 loss: -1.905782699584961
Batch 13/64 loss: -1.9780902862548828
Batch 14/64 loss: -1.9670171737670898
Batch 15/64 loss: -1.6261463165283203
Batch 16/64 loss: -1.9711055755615234
Batch 17/64 loss: -1.6739606857299805
Batch 18/64 loss: -1.950531005859375
Batch 19/64 loss: -1.9461708068847656
Batch 20/64 loss: -2.069390296936035
Batch 21/64 loss: -1.7937936782836914
Batch 22/64 loss: -1.8681859970092773
Batch 23/64 loss: -1.679570198059082
Batch 24/64 loss: -1.503453254699707
Batch 25/64 loss: -1.511174201965332
Batch 26/64 loss: -2.1206188201904297
Batch 27/64 loss: -1.8879289627075195
Batch 28/64 loss: -1.2881755828857422
Batch 29/64 loss: -2.0396080017089844
Batch 30/64 loss: -1.8068456649780273
Batch 31/64 loss: -1.7750864028930664
Batch 32/64 loss: -1.6372766494750977
Batch 33/64 loss: -1.8405342102050781
Batch 34/64 loss: -1.6359920501708984
Batch 35/64 loss: -1.4754180908203125
Batch 36/64 loss: -0.9962625503540039
Batch 37/64 loss: -1.4434423446655273
Batch 38/64 loss: -1.9127798080444336
Batch 39/64 loss: -2.143744468688965
Batch 40/64 loss: -1.4923181533813477
Batch 41/64 loss: -1.8473052978515625
Batch 42/64 loss: -1.563222885131836
Batch 43/64 loss: -2.042973518371582
Batch 44/64 loss: -2.169889450073242
Batch 45/64 loss: -1.8229188919067383
Batch 46/64 loss: -2.080540657043457
Batch 47/64 loss: -1.6118879318237305
Batch 48/64 loss: -1.8867597579956055
Batch 49/64 loss: -1.6121978759765625
Batch 50/64 loss: -1.567098617553711
Batch 51/64 loss: -1.9414901733398438
Batch 52/64 loss: -2.068844795227051
Batch 53/64 loss: -2.2079200744628906
Batch 54/64 loss: -1.9758424758911133
Batch 55/64 loss: -1.6355371475219727
Batch 56/64 loss: -1.6316204071044922
Batch 57/64 loss: -1.4336109161376953
Batch 58/64 loss: -1.2104501724243164
Batch 59/64 loss: -1.8435983657836914
Batch 60/64 loss: -1.5814323425292969
Batch 61/64 loss: -1.7121753692626953
Batch 62/64 loss: -1.956660270690918
Batch 63/64 loss: -1.941798210144043
Batch 64/64 loss: -5.924802303314209
Epoch 69  Train loss: -1.8369514932819442  Val loss: -2.000319149895632
Epoch 70
-------------------------------
Batch 1/64 loss: -1.8324098587036133
Batch 2/64 loss: -1.8941497802734375
Batch 3/64 loss: -2.184141159057617
Batch 4/64 loss: -1.5279903411865234
Batch 5/64 loss: -2.1664276123046875
Batch 6/64 loss: -1.6846227645874023
Batch 7/64 loss: -1.8971166610717773
Batch 8/64 loss: -1.8503379821777344
Batch 9/64 loss: -1.970780372619629
Batch 10/64 loss: -1.755263328552246
Batch 11/64 loss: -1.968644142150879
Batch 12/64 loss: -1.6944293975830078
Batch 13/64 loss: -1.8145694732666016
Batch 14/64 loss: -2.033207893371582
Batch 15/64 loss: -1.6838016510009766
Batch 16/64 loss: -2.202730178833008
Batch 17/64 loss: -2.020634651184082
Batch 18/64 loss: -2.0923871994018555
Batch 19/64 loss: -1.3494415283203125
Batch 20/64 loss: -1.867100715637207
Batch 21/64 loss: -1.6753339767456055
Batch 22/64 loss: -1.5788764953613281
Batch 23/64 loss: -1.9242448806762695
Batch 24/64 loss: -1.6873970031738281
Batch 25/64 loss: -1.6399545669555664
Batch 26/64 loss: -1.8672637939453125
Batch 27/64 loss: -1.6998310089111328
Batch 28/64 loss: -1.715327262878418
Batch 29/64 loss: -1.7107954025268555
Batch 30/64 loss: -1.605574607849121
Batch 31/64 loss: -1.7752456665039062
Batch 32/64 loss: -1.0899696350097656
Batch 33/64 loss: -1.7606840133666992
Batch 34/64 loss: -1.8651714324951172
Batch 35/64 loss: -1.3450632095336914
Batch 36/64 loss: -1.8191986083984375
Batch 37/64 loss: -2.037714958190918
Batch 38/64 loss: -1.8521194458007812
Batch 39/64 loss: -1.1217536926269531
Batch 40/64 loss: -2.031702995300293
Batch 41/64 loss: -1.5219087600708008
Batch 42/64 loss: -1.972804069519043
Batch 43/64 loss: -1.8769865036010742
Batch 44/64 loss: -1.7701435089111328
Batch 45/64 loss: -1.9481191635131836
Batch 46/64 loss: -1.63275146484375
Batch 47/64 loss: -2.026566505432129
Batch 48/64 loss: -1.4746742248535156
Batch 49/64 loss: -1.670496940612793
Batch 50/64 loss: -1.822831153869629
Batch 51/64 loss: -1.9590234756469727
Batch 52/64 loss: -2.013585090637207
Batch 53/64 loss: -1.7166595458984375
Batch 54/64 loss: -2.1385412216186523
Batch 55/64 loss: -1.9921350479125977
Batch 56/64 loss: -2.0073556900024414
Batch 57/64 loss: -1.7370567321777344
Batch 58/64 loss: -1.7942276000976562
Batch 59/64 loss: -1.9559955596923828
Batch 60/64 loss: -1.9760799407958984
Batch 61/64 loss: -2.1180877685546875
Batch 62/64 loss: -1.6734609603881836
Batch 63/64 loss: -1.638474464416504
Batch 64/64 loss: -6.26819372177124
Epoch 70  Train loss: -1.8577650201086904  Val loss: -2.0361219976366183
Epoch 71
-------------------------------
Batch 1/64 loss: -2.030149459838867
Batch 2/64 loss: -1.7981796264648438
Batch 3/64 loss: -1.6620216369628906
Batch 4/64 loss: -2.1641740798950195
Batch 5/64 loss: -2.028986930847168
Batch 6/64 loss: -2.018260955810547
Batch 7/64 loss: -1.794229507446289
Batch 8/64 loss: -1.8125896453857422
Batch 9/64 loss: -2.063420295715332
Batch 10/64 loss: -1.8964881896972656
Batch 11/64 loss: -1.6136846542358398
Batch 12/64 loss: -2.0710601806640625
Batch 13/64 loss: -1.713820457458496
Batch 14/64 loss: -1.624734878540039
Batch 15/64 loss: -1.8602466583251953
Batch 16/64 loss: -1.2538957595825195
Batch 17/64 loss: -1.6253242492675781
Batch 18/64 loss: -2.0909528732299805
Batch 19/64 loss: -2.0536231994628906
Batch 20/64 loss: -1.5976734161376953
Batch 21/64 loss: -2.255695343017578
Batch 22/64 loss: -1.79302978515625
Batch 23/64 loss: -1.7356548309326172
Batch 24/64 loss: -1.795755386352539
Batch 25/64 loss: -1.7039546966552734
Batch 26/64 loss: -2.08786678314209
Batch 27/64 loss: -1.6838579177856445
Batch 28/64 loss: -1.8788251876831055
Batch 29/64 loss: -1.8123493194580078
Batch 30/64 loss: -1.8200721740722656
Batch 31/64 loss: -1.8431158065795898
Batch 32/64 loss: -1.5685310363769531
Batch 33/64 loss: -1.5698747634887695
Batch 34/64 loss: -1.4747676849365234
Batch 35/64 loss: -1.9293909072875977
Batch 36/64 loss: -1.582839012145996
Batch 37/64 loss: -1.566697120666504
Batch 38/64 loss: -1.835759162902832
Batch 39/64 loss: -1.8803987503051758
Batch 40/64 loss: -2.230952262878418
Batch 41/64 loss: -1.9401235580444336
Batch 42/64 loss: -1.6952686309814453
Batch 43/64 loss: -2.1720151901245117
Batch 44/64 loss: -1.6495704650878906
Batch 45/64 loss: -1.6845521926879883
Batch 46/64 loss: -2.0134143829345703
Batch 47/64 loss: -2.0024938583374023
Batch 48/64 loss: -1.8375377655029297
Batch 49/64 loss: -1.9969263076782227
Batch 50/64 loss: -1.5552406311035156
Batch 51/64 loss: -1.921173095703125
Batch 52/64 loss: -1.7350282669067383
Batch 53/64 loss: -1.8416261672973633
Batch 54/64 loss: -2.0250864028930664
Batch 55/64 loss: -1.9083499908447266
Batch 56/64 loss: -1.9599523544311523
Batch 57/64 loss: -2.0106849670410156
Batch 58/64 loss: -1.8283233642578125
Batch 59/64 loss: -2.0952606201171875
Batch 60/64 loss: -1.9323368072509766
Batch 61/64 loss: -1.693948745727539
Batch 62/64 loss: -1.8678970336914062
Batch 63/64 loss: -1.8557977676391602
Batch 64/64 loss: -6.2865705490112305
Epoch 71  Train loss: -1.8942814284679936  Val loss: -1.9877862176534646
Epoch 72
-------------------------------
Batch 1/64 loss: -1.9941158294677734
Batch 2/64 loss: -2.233173370361328
Batch 3/64 loss: -1.9727706909179688
Batch 4/64 loss: -2.1050825119018555
Batch 5/64 loss: -1.890707015991211
Batch 6/64 loss: -1.6749382019042969
Batch 7/64 loss: -1.7737226486206055
Batch 8/64 loss: -1.6693668365478516
Batch 9/64 loss: -2.014775276184082
Batch 10/64 loss: -2.217184066772461
Batch 11/64 loss: -1.8915071487426758
Batch 12/64 loss: -1.8280572891235352
Batch 13/64 loss: -1.9099149703979492
Batch 14/64 loss: -1.9108009338378906
Batch 15/64 loss: -1.9005413055419922
Batch 16/64 loss: -2.114370346069336
Batch 17/64 loss: -1.9966764450073242
Batch 18/64 loss: -1.5686798095703125
Batch 19/64 loss: -2.07327938079834
Batch 20/64 loss: -2.025820732116699
Batch 21/64 loss: -2.1085519790649414
Batch 22/64 loss: -1.3179712295532227
Batch 23/64 loss: -1.7290096282958984
Batch 24/64 loss: -1.9172096252441406
Batch 25/64 loss: -1.6150197982788086
Batch 26/64 loss: -1.3928394317626953
Batch 27/64 loss: -2.045377731323242
Batch 28/64 loss: -1.495966911315918
Batch 29/64 loss: -1.920663833618164
Batch 30/64 loss: -2.031871795654297
Batch 31/64 loss: -1.690079689025879
Batch 32/64 loss: -1.9958667755126953
Batch 33/64 loss: -1.7041807174682617
Batch 34/64 loss: -1.742711067199707
Batch 35/64 loss: -1.9519929885864258
Batch 36/64 loss: -1.8703413009643555
Batch 37/64 loss: -1.9276208877563477
Batch 38/64 loss: -1.8226966857910156
Batch 39/64 loss: -1.6821460723876953
Batch 40/64 loss: -1.931478500366211
Batch 41/64 loss: -1.6356277465820312
Batch 42/64 loss: -2.06032657623291
Batch 43/64 loss: -1.7404718399047852
Batch 44/64 loss: -1.6332206726074219
Batch 45/64 loss: -1.9891853332519531
Batch 46/64 loss: -1.9719467163085938
Batch 47/64 loss: -1.37078857421875
Batch 48/64 loss: -1.7057809829711914
Batch 49/64 loss: -1.9942455291748047
Batch 50/64 loss: -1.6042776107788086
Batch 51/64 loss: -1.6484699249267578
Batch 52/64 loss: -1.9408721923828125
Batch 53/64 loss: -1.619943618774414
Batch 54/64 loss: -1.5317926406860352
Batch 55/64 loss: -1.884307861328125
Batch 56/64 loss: -1.5770807266235352
Batch 57/64 loss: -1.7617416381835938
Batch 58/64 loss: -1.6158723831176758
Batch 59/64 loss: -1.8781852722167969
Batch 60/64 loss: -1.5566864013671875
Batch 61/64 loss: -1.872720718383789
Batch 62/64 loss: -1.92529296875
Batch 63/64 loss: -1.5139617919921875
Batch 64/64 loss: -6.234680652618408
Epoch 72  Train loss: -1.872437516380759  Val loss: -1.945975549442252
Epoch 73
-------------------------------
Batch 1/64 loss: -1.751082420349121
Batch 2/64 loss: -1.8409595489501953
Batch 3/64 loss: -1.6580009460449219
Batch 4/64 loss: -1.9566373825073242
Batch 5/64 loss: -1.953597068786621
Batch 6/64 loss: -1.3596076965332031
Batch 7/64 loss: -1.8254976272583008
Batch 8/64 loss: -1.8197393417358398
Batch 9/64 loss: -1.6086177825927734
Batch 10/64 loss: -1.9877510070800781
Batch 11/64 loss: -1.9864692687988281
Batch 12/64 loss: -1.834197998046875
Batch 13/64 loss: -1.6532011032104492
Batch 14/64 loss: -1.8484535217285156
Batch 15/64 loss: -1.7828388214111328
Batch 16/64 loss: -1.840867042541504
Batch 17/64 loss: -1.6422100067138672
Batch 18/64 loss: -1.883793830871582
Batch 19/64 loss: -2.057297706604004
Batch 20/64 loss: -1.9194440841674805
Batch 21/64 loss: -1.7874078750610352
Batch 22/64 loss: -1.6391286849975586
Batch 23/64 loss: -1.9182310104370117
Batch 24/64 loss: -1.8609552383422852
Batch 25/64 loss: -1.129836082458496
Batch 26/64 loss: -1.446335792541504
Batch 27/64 loss: -1.774622917175293
Batch 28/64 loss: -1.5556659698486328
Batch 29/64 loss: -1.330367088317871
Batch 30/64 loss: -2.042496681213379
Batch 31/64 loss: -1.739893913269043
Batch 32/64 loss: -1.8106508255004883
Batch 33/64 loss: -1.7686386108398438
Batch 34/64 loss: -1.803558349609375
Batch 35/64 loss: -1.8930597305297852
Batch 36/64 loss: -2.0954132080078125
Batch 37/64 loss: -1.8780059814453125
Batch 38/64 loss: -1.9877042770385742
Batch 39/64 loss: -1.9099912643432617
Batch 40/64 loss: -1.7429981231689453
Batch 41/64 loss: -1.838007926940918
Batch 42/64 loss: -1.3885173797607422
Batch 43/64 loss: -1.720296859741211
Batch 44/64 loss: -2.0311946868896484
Batch 45/64 loss: -1.8691558837890625
Batch 46/64 loss: -1.837021827697754
Batch 47/64 loss: -1.7295913696289062
Batch 48/64 loss: -2.063426971435547
Batch 49/64 loss: -1.8958702087402344
Batch 50/64 loss: -2.067564010620117
Batch 51/64 loss: -1.8983163833618164
Batch 52/64 loss: -1.8891162872314453
Batch 53/64 loss: -1.9460391998291016
Batch 54/64 loss: -1.585280418395996
Batch 55/64 loss: -2.009654998779297
Batch 56/64 loss: -1.417531967163086
Batch 57/64 loss: -2.28228759765625
Batch 58/64 loss: -2.129481315612793
Batch 59/64 loss: -1.4771900177001953
Batch 60/64 loss: -1.810659408569336
Batch 61/64 loss: -2.001504898071289
Batch 62/64 loss: -2.0398998260498047
Batch 63/64 loss: -2.2001733779907227
Batch 64/64 loss: -5.626154899597168
Epoch 73  Train loss: -1.861531369826373  Val loss: -2.035611116599381
Epoch 74
-------------------------------
Batch 1/64 loss: -2.1263389587402344
Batch 2/64 loss: -1.6521329879760742
Batch 3/64 loss: -1.5718278884887695
Batch 4/64 loss: -2.0929203033447266
Batch 5/64 loss: -1.966827392578125
Batch 6/64 loss: -1.7239065170288086
Batch 7/64 loss: -1.9645214080810547
Batch 8/64 loss: -1.5137252807617188
Batch 9/64 loss: -1.8754587173461914
Batch 10/64 loss: -2.0296173095703125
Batch 11/64 loss: -1.7400627136230469
Batch 12/64 loss: -1.4081077575683594
Batch 13/64 loss: -1.790578842163086
Batch 14/64 loss: -1.9193859100341797
Batch 15/64 loss: -2.0710792541503906
Batch 16/64 loss: -1.9522390365600586
Batch 17/64 loss: -1.9243545532226562
Batch 18/64 loss: -1.9329853057861328
Batch 19/64 loss: -1.6966848373413086
Batch 20/64 loss: -2.0286426544189453
Batch 21/64 loss: -2.0159473419189453
Batch 22/64 loss: -1.8251380920410156
Batch 23/64 loss: -1.4944067001342773
Batch 24/64 loss: -1.8716497421264648
Batch 25/64 loss: -1.7501068115234375
Batch 26/64 loss: -1.8611774444580078
Batch 27/64 loss: -1.8674278259277344
Batch 28/64 loss: -2.284912109375
Batch 29/64 loss: -1.9888906478881836
Batch 30/64 loss: -1.8909263610839844
Batch 31/64 loss: -2.18253231048584
Batch 32/64 loss: -1.039443016052246
Batch 33/64 loss: -1.6646442413330078
Batch 34/64 loss: -2.0231552124023438
Batch 35/64 loss: -1.578298568725586
Batch 36/64 loss: -1.489445686340332
Batch 37/64 loss: -2.07875919342041
Batch 38/64 loss: -1.866694450378418
Batch 39/64 loss: -1.8722925186157227
Batch 40/64 loss: -1.9585351943969727
Batch 41/64 loss: -1.944631576538086
Batch 42/64 loss: -2.083568572998047
Batch 43/64 loss: -1.9838638305664062
Batch 44/64 loss: -1.3344459533691406
Batch 45/64 loss: -1.8403186798095703
Batch 46/64 loss: -1.7470073699951172
Batch 47/64 loss: -1.5768775939941406
Batch 48/64 loss: -1.980534553527832
Batch 49/64 loss: -2.149165153503418
Batch 50/64 loss: -1.9037284851074219
Batch 51/64 loss: -1.4914121627807617
Batch 52/64 loss: -1.741520881652832
Batch 53/64 loss: -1.8626270294189453
Batch 54/64 loss: -1.880558967590332
Batch 55/64 loss: -2.0339183807373047
Batch 56/64 loss: -1.768437385559082
Batch 57/64 loss: -1.7407655715942383
Batch 58/64 loss: -1.8344039916992188
Batch 59/64 loss: -1.7205820083618164
Batch 60/64 loss: -1.933609962463379
Batch 61/64 loss: -1.7848596572875977
Batch 62/64 loss: -2.0147743225097656
Batch 63/64 loss: -1.9199399948120117
Batch 64/64 loss: -6.421692848205566
Epoch 74  Train loss: -1.8929192599128275  Val loss: -2.0482434800400355
Saving best model, epoch: 74
Epoch 75
-------------------------------
Batch 1/64 loss: -1.883819580078125
Batch 2/64 loss: -2.0027618408203125
Batch 3/64 loss: -2.0179271697998047
Batch 4/64 loss: -1.7145442962646484
Batch 5/64 loss: -1.9886016845703125
Batch 6/64 loss: -2.0178890228271484
Batch 7/64 loss: -1.9356346130371094
Batch 8/64 loss: -1.9341487884521484
Batch 9/64 loss: -1.9904375076293945
Batch 10/64 loss: -1.8387651443481445
Batch 11/64 loss: -1.9660024642944336
Batch 12/64 loss: -1.8958673477172852
Batch 13/64 loss: -2.021350860595703
Batch 14/64 loss: -1.693385124206543
Batch 15/64 loss: -2.1414594650268555
Batch 16/64 loss: -1.9807605743408203
Batch 17/64 loss: -1.816666603088379
Batch 18/64 loss: -2.0648365020751953
Batch 19/64 loss: -1.632136344909668
Batch 20/64 loss: -1.918304443359375
Batch 21/64 loss: -1.8271207809448242
Batch 22/64 loss: -2.1442928314208984
Batch 23/64 loss: -1.6206398010253906
Batch 24/64 loss: -2.0199575424194336
Batch 25/64 loss: -1.7544031143188477
Batch 26/64 loss: -2.0338640213012695
Batch 27/64 loss: -1.747767448425293
Batch 28/64 loss: -2.2007131576538086
Batch 29/64 loss: -1.5271492004394531
Batch 30/64 loss: -2.006702423095703
Batch 31/64 loss: -1.7940196990966797
Batch 32/64 loss: -1.703902244567871
Batch 33/64 loss: -1.8521289825439453
Batch 34/64 loss: -2.0955333709716797
Batch 35/64 loss: -2.0928001403808594
Batch 36/64 loss: -1.9241008758544922
Batch 37/64 loss: -1.8768501281738281
Batch 38/64 loss: -1.873086929321289
Batch 39/64 loss: -1.6490402221679688
Batch 40/64 loss: -1.838587760925293
Batch 41/64 loss: -1.9898605346679688
Batch 42/64 loss: -1.8213376998901367
Batch 43/64 loss: -1.7969779968261719
Batch 44/64 loss: -1.7758045196533203
Batch 45/64 loss: -1.4977998733520508
Batch 46/64 loss: -2.1155033111572266
Batch 47/64 loss: -1.2243099212646484
Batch 48/64 loss: -2.073944091796875
Batch 49/64 loss: -2.1906652450561523
Batch 50/64 loss: -1.8171472549438477
Batch 51/64 loss: -1.89337158203125
Batch 52/64 loss: -2.018239974975586
Batch 53/64 loss: -1.6518793106079102
Batch 54/64 loss: -1.8333120346069336
Batch 55/64 loss: -1.9368133544921875
Batch 56/64 loss: -1.8450555801391602
Batch 57/64 loss: -1.9838428497314453
Batch 58/64 loss: -1.3583917617797852
Batch 59/64 loss: -2.015962600708008
Batch 60/64 loss: -1.790909767150879
Batch 61/64 loss: -2.0078468322753906
Batch 62/64 loss: -1.706695556640625
Batch 63/64 loss: -2.0356616973876953
Batch 64/64 loss: -5.643828392028809
Epoch 75  Train loss: -1.9239555246689741  Val loss: -1.927896729039982
Epoch 76
-------------------------------
Batch 1/64 loss: -1.898824691772461
Batch 2/64 loss: -2.167752265930176
Batch 3/64 loss: -1.7989788055419922
Batch 4/64 loss: -1.8579578399658203
Batch 5/64 loss: -1.8537406921386719
Batch 6/64 loss: -1.7706995010375977
Batch 7/64 loss: -1.830038070678711
Batch 8/64 loss: -2.0798654556274414
Batch 9/64 loss: -2.0321788787841797
Batch 10/64 loss: -1.793900489807129
Batch 11/64 loss: -1.8844680786132812
Batch 12/64 loss: -2.1634302139282227
Batch 13/64 loss: -2.012078285217285
Batch 14/64 loss: -2.03043270111084
Batch 15/64 loss: -1.935135841369629
Batch 16/64 loss: -1.5572700500488281
Batch 17/64 loss: -1.7489118576049805
Batch 18/64 loss: -1.3238201141357422
Batch 19/64 loss: -1.8968572616577148
Batch 20/64 loss: -1.6586151123046875
Batch 21/64 loss: -1.9144096374511719
Batch 22/64 loss: -2.1110639572143555
Batch 23/64 loss: -1.674067497253418
Batch 24/64 loss: -1.6752634048461914
Batch 25/64 loss: -1.8484487533569336
Batch 26/64 loss: -1.9876937866210938
Batch 27/64 loss: -1.9809808731079102
Batch 28/64 loss: -1.8676738739013672
Batch 29/64 loss: -1.6173839569091797
Batch 30/64 loss: -1.969508171081543
Batch 31/64 loss: -1.6232500076293945
Batch 32/64 loss: -2.156552314758301
Batch 33/64 loss: -1.6925973892211914
Batch 34/64 loss: -2.11441707611084
Batch 35/64 loss: -1.5442314147949219
Batch 36/64 loss: -1.765864372253418
Batch 37/64 loss: -1.6846647262573242
Batch 38/64 loss: -1.4661445617675781
Batch 39/64 loss: -2.0018310546875
Batch 40/64 loss: -1.5262603759765625
Batch 41/64 loss: -1.6218194961547852
Batch 42/64 loss: -2.2883968353271484
Batch 43/64 loss: -1.9928693771362305
Batch 44/64 loss: -1.8935060501098633
Batch 45/64 loss: -1.9172630310058594
Batch 46/64 loss: -1.9124488830566406
Batch 47/64 loss: -2.024871826171875
Batch 48/64 loss: -2.0636348724365234
Batch 49/64 loss: -1.8078374862670898
Batch 50/64 loss: -1.7374382019042969
Batch 51/64 loss: -2.1336021423339844
Batch 52/64 loss: -1.9435482025146484
Batch 53/64 loss: -1.9588994979858398
Batch 54/64 loss: -1.5705146789550781
Batch 55/64 loss: -1.9684028625488281
Batch 56/64 loss: -1.9776573181152344
Batch 57/64 loss: -1.8334836959838867
Batch 58/64 loss: -1.699845314025879
Batch 59/64 loss: -1.7631664276123047
Batch 60/64 loss: -2.21256160736084
Batch 61/64 loss: -1.6189146041870117
Batch 62/64 loss: -1.5847063064575195
Batch 63/64 loss: -1.820816993713379
Batch 64/64 loss: -6.1614885330200195
Epoch 76  Train loss: -1.905640557233025  Val loss: -2.0467556563439646
Epoch 77
-------------------------------
Batch 1/64 loss: -1.3602714538574219
Batch 2/64 loss: -1.7798337936401367
Batch 3/64 loss: -2.051499366760254
Batch 4/64 loss: -2.1600799560546875
Batch 5/64 loss: -1.8847637176513672
Batch 6/64 loss: -1.6959571838378906
Batch 7/64 loss: -1.9966259002685547
Batch 8/64 loss: -2.1353883743286133
Batch 9/64 loss: -1.9116687774658203
Batch 10/64 loss: -2.2078609466552734
Batch 11/64 loss: -2.0562562942504883
Batch 12/64 loss: -2.1297683715820312
Batch 13/64 loss: -2.1906614303588867
Batch 14/64 loss: -1.8703413009643555
Batch 15/64 loss: -2.0646495819091797
Batch 16/64 loss: -1.8962011337280273
Batch 17/64 loss: -1.9440126419067383
Batch 18/64 loss: -1.6595516204833984
Batch 19/64 loss: -1.899073600769043
Batch 20/64 loss: -1.9645214080810547
Batch 21/64 loss: -2.1292953491210938
Batch 22/64 loss: -1.7011709213256836
Batch 23/64 loss: -1.8196372985839844
Batch 24/64 loss: -1.507216453552246
Batch 25/64 loss: -1.968923568725586
Batch 26/64 loss: -1.9196405410766602
Batch 27/64 loss: -1.8815555572509766
Batch 28/64 loss: -2.029020309448242
Batch 29/64 loss: -1.6261415481567383
Batch 30/64 loss: -1.7608118057250977
Batch 31/64 loss: -1.9728069305419922
Batch 32/64 loss: -1.7929677963256836
Batch 33/64 loss: -1.970224380493164
Batch 34/64 loss: -1.8940563201904297
Batch 35/64 loss: -1.9853525161743164
Batch 36/64 loss: -1.964869499206543
Batch 37/64 loss: -2.0743799209594727
Batch 38/64 loss: -1.9407129287719727
Batch 39/64 loss: -1.7492504119873047
Batch 40/64 loss: -1.780196189880371
Batch 41/64 loss: -1.9151124954223633
Batch 42/64 loss: -1.9185266494750977
Batch 43/64 loss: -1.9047822952270508
Batch 44/64 loss: -2.220128059387207
Batch 45/64 loss: -2.2519283294677734
Batch 46/64 loss: -2.127499580383301
Batch 47/64 loss: -2.0173521041870117
Batch 48/64 loss: -1.9810104370117188
Batch 49/64 loss: -1.8602867126464844
Batch 50/64 loss: -2.162384033203125
Batch 51/64 loss: -1.7417192459106445
Batch 52/64 loss: -1.705174446105957
Batch 53/64 loss: -1.8532590866088867
Batch 54/64 loss: -2.025278091430664
Batch 55/64 loss: -1.6395559310913086
Batch 56/64 loss: -1.4750127792358398
Batch 57/64 loss: -1.9621305465698242
Batch 58/64 loss: -1.7390670776367188
Batch 59/64 loss: -1.7157602310180664
Batch 60/64 loss: -1.9638757705688477
Batch 61/64 loss: -1.7731657028198242
Batch 62/64 loss: -1.885148048400879
Batch 63/64 loss: -2.2640209197998047
Batch 64/64 loss: -5.866321563720703
Epoch 77  Train loss: -1.958104107426662  Val loss: -2.1064844033152785
Saving best model, epoch: 77
Epoch 78
-------------------------------
Batch 1/64 loss: -1.6957416534423828
Batch 2/64 loss: -1.9495172500610352
Batch 3/64 loss: -2.095944404602051
Batch 4/64 loss: -1.86358642578125
Batch 5/64 loss: -1.9125661849975586
Batch 6/64 loss: -1.962019920349121
Batch 7/64 loss: -2.1536026000976562
Batch 8/64 loss: -1.9596672058105469
Batch 9/64 loss: -2.07088565826416
Batch 10/64 loss: -1.8448638916015625
Batch 11/64 loss: -2.1022443771362305
Batch 12/64 loss: -1.8188085556030273
Batch 13/64 loss: -2.0432872772216797
Batch 14/64 loss: -2.0642929077148438
Batch 15/64 loss: -2.137759208679199
Batch 16/64 loss: -1.5778789520263672
Batch 17/64 loss: -1.6492366790771484
Batch 18/64 loss: -2.230414390563965
Batch 19/64 loss: -1.9823904037475586
Batch 20/64 loss: -1.5884294509887695
Batch 21/64 loss: -1.8990859985351562
Batch 22/64 loss: -2.0165109634399414
Batch 23/64 loss: -2.125554084777832
Batch 24/64 loss: -2.1765222549438477
Batch 25/64 loss: -2.014524459838867
Batch 26/64 loss: -1.559072494506836
Batch 27/64 loss: -1.666743278503418
Batch 28/64 loss: -1.6874885559082031
Batch 29/64 loss: -2.072394371032715
Batch 30/64 loss: -1.8944120407104492
Batch 31/64 loss: -1.754608154296875
Batch 32/64 loss: -1.6514501571655273
Batch 33/64 loss: -2.0637378692626953
Batch 34/64 loss: -1.6230344772338867
Batch 35/64 loss: -1.6377592086791992
Batch 36/64 loss: -2.2595834732055664
Batch 37/64 loss: -1.8139667510986328
Batch 38/64 loss: -1.9647712707519531
Batch 39/64 loss: -1.6480913162231445
Batch 40/64 loss: -1.6474180221557617
Batch 41/64 loss: -1.695378303527832
Batch 42/64 loss: -1.9944210052490234
Batch 43/64 loss: -1.938441276550293
Batch 44/64 loss: -2.017475128173828
Batch 45/64 loss: -2.082150459289551
Batch 46/64 loss: -2.0185422897338867
Batch 47/64 loss: -1.8309087753295898
Batch 48/64 loss: -1.4593229293823242
Batch 49/64 loss: -1.9931659698486328
Batch 50/64 loss: -1.598531723022461
Batch 51/64 loss: -1.7671575546264648
Batch 52/64 loss: -1.7365550994873047
Batch 53/64 loss: -1.9643831253051758
Batch 54/64 loss: -2.018390655517578
Batch 55/64 loss: -1.408365249633789
Batch 56/64 loss: -2.196195602416992
Batch 57/64 loss: -1.887089729309082
Batch 58/64 loss: -1.763895034790039
Batch 59/64 loss: -1.8843107223510742
Batch 60/64 loss: -1.9815425872802734
Batch 61/64 loss: -1.6967096328735352
Batch 62/64 loss: -1.7401485443115234
Batch 63/64 loss: -1.987828254699707
Batch 64/64 loss: -6.484630584716797
Epoch 78  Train loss: -1.9357529284907322  Val loss: -1.8568089803059895
Epoch 79
-------------------------------
Batch 1/64 loss: -1.951136589050293
Batch 2/64 loss: -2.141036033630371
Batch 3/64 loss: -1.8320074081420898
Batch 4/64 loss: -2.014296531677246
Batch 5/64 loss: -1.7692022323608398
Batch 6/64 loss: -1.5092973709106445
Batch 7/64 loss: -1.8232793807983398
Batch 8/64 loss: -2.2366132736206055
Batch 9/64 loss: -2.0370426177978516
Batch 10/64 loss: -2.245223045349121
Batch 11/64 loss: -2.046022415161133
Batch 12/64 loss: -1.605128288269043
Batch 13/64 loss: -1.6932439804077148
Batch 14/64 loss: -1.8526811599731445
Batch 15/64 loss: -1.6170787811279297
Batch 16/64 loss: -1.9035625457763672
Batch 17/64 loss: -1.3143796920776367
Batch 18/64 loss: -2.1352930068969727
Batch 19/64 loss: -1.8130531311035156
Batch 20/64 loss: -1.5760631561279297
Batch 21/64 loss: -1.88604736328125
Batch 22/64 loss: -1.669327735900879
Batch 23/64 loss: -1.923142433166504
Batch 24/64 loss: -1.9488544464111328
Batch 25/64 loss: -2.0712766647338867
Batch 26/64 loss: -2.0684738159179688
Batch 27/64 loss: -2.0434722900390625
Batch 28/64 loss: -1.0751676559448242
Batch 29/64 loss: -1.644357681274414
Batch 30/64 loss: -1.8852224349975586
Batch 31/64 loss: -2.2105207443237305
Batch 32/64 loss: -1.5331382751464844
Batch 33/64 loss: -1.8315391540527344
Batch 34/64 loss: -1.9848175048828125
Batch 35/64 loss: -2.0760669708251953
Batch 36/64 loss: -1.8927001953125
Batch 37/64 loss: -0.6354618072509766
Batch 38/64 loss: -1.7116966247558594
Batch 39/64 loss: -2.143124580383301
Batch 40/64 loss: -1.8531932830810547
Batch 41/64 loss: -1.9713125228881836
Batch 42/64 loss: -2.095595359802246
Batch 43/64 loss: -1.8899707794189453
Batch 44/64 loss: -1.8084478378295898
Batch 45/64 loss: -1.8641691207885742
Batch 46/64 loss: -1.5885677337646484
Batch 47/64 loss: -1.8128032684326172
Batch 48/64 loss: -2.082305908203125
Batch 49/64 loss: -1.9717130661010742
Batch 50/64 loss: -1.9854373931884766
Batch 51/64 loss: -1.9836816787719727
Batch 52/64 loss: -2.2224531173706055
Batch 53/64 loss: -1.4213733673095703
Batch 54/64 loss: -1.9662914276123047
Batch 55/64 loss: -1.7517805099487305
Batch 56/64 loss: -1.8988895416259766
Batch 57/64 loss: -1.7391223907470703
Batch 58/64 loss: -1.750290870666504
Batch 59/64 loss: -1.6460180282592773
Batch 60/64 loss: -2.191192626953125
Batch 61/64 loss: -2.12493896484375
Batch 62/64 loss: -2.1016693115234375
Batch 63/64 loss: -2.076766014099121
Batch 64/64 loss: -6.201303005218506
Epoch 79  Train loss: -1.910572712094176  Val loss: -2.0270392952096423
Epoch 80
-------------------------------
Batch 1/64 loss: -1.814499855041504
Batch 2/64 loss: -2.082688331604004
Batch 3/64 loss: -1.5029525756835938
Batch 4/64 loss: -1.680006980895996
Batch 5/64 loss: -2.041031837463379
Batch 6/64 loss: -1.872049331665039
Batch 7/64 loss: -2.1135902404785156
Batch 8/64 loss: -2.1473312377929688
Batch 9/64 loss: -2.154356002807617
Batch 10/64 loss: -1.9245119094848633
Batch 11/64 loss: -1.6796293258666992
Batch 12/64 loss: -1.9508838653564453
Batch 13/64 loss: -2.107511520385742
Batch 14/64 loss: -1.9902458190917969
Batch 15/64 loss: -2.0291786193847656
Batch 16/64 loss: -1.7055120468139648
Batch 17/64 loss: -1.9030513763427734
Batch 18/64 loss: -1.8906097412109375
Batch 19/64 loss: -2.1253175735473633
Batch 20/64 loss: -1.8248157501220703
Batch 21/64 loss: -1.7709426879882812
Batch 22/64 loss: -2.0463857650756836
Batch 23/64 loss: -1.5700368881225586
Batch 24/64 loss: -1.933110237121582
Batch 25/64 loss: -1.861159324645996
Batch 26/64 loss: -1.4874677658081055
Batch 27/64 loss: -2.0159778594970703
Batch 28/64 loss: -2.0341110229492188
Batch 29/64 loss: -2.0390310287475586
Batch 30/64 loss: -2.1320972442626953
Batch 31/64 loss: -2.2115554809570312
Batch 32/64 loss: -2.204268455505371
Batch 33/64 loss: -1.916778564453125
Batch 34/64 loss: -1.8139877319335938
Batch 35/64 loss: -1.7795562744140625
Batch 36/64 loss: -2.2010250091552734
Batch 37/64 loss: -1.7666845321655273
Batch 38/64 loss: -2.150027275085449
Batch 39/64 loss: -1.2636041641235352
Batch 40/64 loss: -1.8280105590820312
Batch 41/64 loss: -1.7063779830932617
Batch 42/64 loss: -1.7359294891357422
Batch 43/64 loss: -1.7172374725341797
Batch 44/64 loss: -1.8393564224243164
Batch 45/64 loss: -1.679330825805664
Batch 46/64 loss: -1.8002071380615234
Batch 47/64 loss: -2.0173072814941406
Batch 48/64 loss: -2.2716712951660156
Batch 49/64 loss: -1.866042137145996
Batch 50/64 loss: -1.9924259185791016
Batch 51/64 loss: -1.9868602752685547
Batch 52/64 loss: -1.7219266891479492
Batch 53/64 loss: -2.0116329193115234
Batch 54/64 loss: -2.042570114135742
Batch 55/64 loss: -1.597991943359375
Batch 56/64 loss: -2.0311012268066406
Batch 57/64 loss: -1.940983772277832
Batch 58/64 loss: -1.6694869995117188
Batch 59/64 loss: -2.106016159057617
Batch 60/64 loss: -1.8522653579711914
Batch 61/64 loss: -2.067814826965332
Batch 62/64 loss: -1.4675321578979492
Batch 63/64 loss: -1.7678651809692383
Batch 64/64 loss: -6.217030048370361
Epoch 80  Train loss: -1.9469536930907005  Val loss: -2.098611929981979
Epoch 81
-------------------------------
Batch 1/64 loss: -1.8027667999267578
Batch 2/64 loss: -2.119309425354004
Batch 3/64 loss: -2.194821357727051
Batch 4/64 loss: -2.1301355361938477
Batch 5/64 loss: -1.9304218292236328
Batch 6/64 loss: -1.8767166137695312
Batch 7/64 loss: -2.0887575149536133
Batch 8/64 loss: -2.1518192291259766
Batch 9/64 loss: -1.8658332824707031
Batch 10/64 loss: -1.9663496017456055
Batch 11/64 loss: -1.8571081161499023
Batch 12/64 loss: -1.3819866180419922
Batch 13/64 loss: -2.1161422729492188
Batch 14/64 loss: -2.2029590606689453
Batch 15/64 loss: -1.951798439025879
Batch 16/64 loss: -1.7270221710205078
Batch 17/64 loss: -1.7853965759277344
Batch 18/64 loss: -1.8787050247192383
Batch 19/64 loss: -2.1432504653930664
Batch 20/64 loss: -1.8736038208007812
Batch 21/64 loss: -2.082540512084961
Batch 22/64 loss: -1.8629140853881836
Batch 23/64 loss: -2.1997556686401367
Batch 24/64 loss: -2.22316837310791
Batch 25/64 loss: -2.111581802368164
Batch 26/64 loss: -2.2074804306030273
Batch 27/64 loss: -1.780935287475586
Batch 28/64 loss: -1.881455421447754
Batch 29/64 loss: -2.059321403503418
Batch 30/64 loss: -1.3664140701293945
Batch 31/64 loss: -2.0529251098632812
Batch 32/64 loss: -1.8126859664916992
Batch 33/64 loss: -1.7593250274658203
Batch 34/64 loss: -1.931406021118164
Batch 35/64 loss: -1.8369789123535156
Batch 36/64 loss: -2.006197929382324
Batch 37/64 loss: -2.182204246520996
Batch 38/64 loss: -1.3568010330200195
Batch 39/64 loss: -1.7455596923828125
Batch 40/64 loss: -1.7947044372558594
Batch 41/64 loss: -1.8969793319702148
Batch 42/64 loss: -1.9493532180786133
Batch 43/64 loss: -1.6889562606811523
Batch 44/64 loss: -2.004927635192871
Batch 45/64 loss: -1.7927045822143555
Batch 46/64 loss: -2.0112266540527344
Batch 47/64 loss: -2.1342716217041016
Batch 48/64 loss: -1.8729677200317383
Batch 49/64 loss: -1.9430522918701172
Batch 50/64 loss: -1.887843132019043
Batch 51/64 loss: -1.916193962097168
Batch 52/64 loss: -2.192683219909668
Batch 53/64 loss: -1.9662494659423828
Batch 54/64 loss: -1.7739334106445312
Batch 55/64 loss: -1.7469635009765625
Batch 56/64 loss: -1.7509174346923828
Batch 57/64 loss: -1.8848724365234375
Batch 58/64 loss: -2.1806039810180664
Batch 59/64 loss: -2.207777976989746
Batch 60/64 loss: -1.8974285125732422
Batch 61/64 loss: -1.875539779663086
Batch 62/64 loss: -2.389187812805176
Batch 63/64 loss: -2.2640514373779297
Batch 64/64 loss: -5.938294410705566
Epoch 81  Train loss: -1.9918692607505648  Val loss: -2.171924761480482
Saving best model, epoch: 81
Epoch 82
-------------------------------
Batch 1/64 loss: -1.810795783996582
Batch 2/64 loss: -1.6532869338989258
Batch 3/64 loss: -1.9298439025878906
Batch 4/64 loss: -2.1616439819335938
Batch 5/64 loss: -2.131667137145996
Batch 6/64 loss: -2.0375709533691406
Batch 7/64 loss: -2.067319869995117
Batch 8/64 loss: -1.7137079238891602
Batch 9/64 loss: -1.999049186706543
Batch 10/64 loss: -1.8260765075683594
Batch 11/64 loss: -2.0935115814208984
Batch 12/64 loss: -1.920649528503418
Batch 13/64 loss: -2.135972023010254
Batch 14/64 loss: -1.9503679275512695
Batch 15/64 loss: -2.0461196899414062
Batch 16/64 loss: -1.9303560256958008
Batch 17/64 loss: -1.9733915328979492
Batch 18/64 loss: -1.9412555694580078
Batch 19/64 loss: -1.8753881454467773
Batch 20/64 loss: -1.8162384033203125
Batch 21/64 loss: -1.9988632202148438
Batch 22/64 loss: -2.121088981628418
Batch 23/64 loss: -2.2019996643066406
Batch 24/64 loss: -1.9065027236938477
Batch 25/64 loss: -1.7309598922729492
Batch 26/64 loss: -2.1737003326416016
Batch 27/64 loss: -1.7415952682495117
Batch 28/64 loss: -1.9503307342529297
Batch 29/64 loss: -2.1099462509155273
Batch 30/64 loss: -1.969996452331543
Batch 31/64 loss: -2.1500635147094727
Batch 32/64 loss: -1.605820655822754
Batch 33/64 loss: -2.1383304595947266
Batch 34/64 loss: -2.2866945266723633
Batch 35/64 loss: -2.004611015319824
Batch 36/64 loss: -2.1261119842529297
Batch 37/64 loss: -1.9610557556152344
Batch 38/64 loss: -1.9528255462646484
Batch 39/64 loss: -1.8874015808105469
Batch 40/64 loss: -1.9575614929199219
Batch 41/64 loss: -1.9374303817749023
Batch 42/64 loss: -1.8342256546020508
Batch 43/64 loss: -2.3179807662963867
Batch 44/64 loss: -2.030109405517578
Batch 45/64 loss: -2.1677942276000977
Batch 46/64 loss: -1.685831069946289
Batch 47/64 loss: -1.7043981552124023
Batch 48/64 loss: -2.088334083557129
Batch 49/64 loss: -2.2204713821411133
Batch 50/64 loss: -2.00553035736084
Batch 51/64 loss: -1.7990493774414062
Batch 52/64 loss: -1.9353055953979492
Batch 53/64 loss: -1.4055423736572266
Batch 54/64 loss: -2.1859092712402344
Batch 55/64 loss: -2.1711807250976562
Batch 56/64 loss: -1.934122085571289
Batch 57/64 loss: -1.9145221710205078
Batch 58/64 loss: -1.758692741394043
Batch 59/64 loss: -1.7783784866333008
Batch 60/64 loss: -2.2580204010009766
Batch 61/64 loss: -1.7831144332885742
Batch 62/64 loss: -1.6985559463500977
Batch 63/64 loss: -1.9066200256347656
Batch 64/64 loss: -6.472567081451416
Epoch 82  Train loss: -2.0135720327788706  Val loss: -2.1890251054796566
Saving best model, epoch: 82
Epoch 83
-------------------------------
Batch 1/64 loss: -1.6786632537841797
Batch 2/64 loss: -2.2056398391723633
Batch 3/64 loss: -1.8401079177856445
Batch 4/64 loss: -1.3040828704833984
Batch 5/64 loss: -2.214402198791504
Batch 6/64 loss: -2.227048873901367
Batch 7/64 loss: -1.798583984375
Batch 8/64 loss: -2.092513084411621
Batch 9/64 loss: -2.039402961730957
Batch 10/64 loss: -2.0965394973754883
Batch 11/64 loss: -1.8054494857788086
Batch 12/64 loss: -1.4227476119995117
Batch 13/64 loss: -1.770707130432129
Batch 14/64 loss: -1.8550291061401367
Batch 15/64 loss: -2.1033363342285156
Batch 16/64 loss: -1.777482032775879
Batch 17/64 loss: -2.0048131942749023
Batch 18/64 loss: -2.1310510635375977
Batch 19/64 loss: -2.0873146057128906
Batch 20/64 loss: -2.113215446472168
Batch 21/64 loss: -2.334878921508789
Batch 22/64 loss: -2.2851028442382812
Batch 23/64 loss: -1.6349906921386719
Batch 24/64 loss: -2.347409248352051
Batch 25/64 loss: -1.7330913543701172
Batch 26/64 loss: -2.115689277648926
Batch 27/64 loss: -2.339618682861328
Batch 28/64 loss: -1.3529071807861328
Batch 29/64 loss: -2.3650283813476562
Batch 30/64 loss: -1.9316978454589844
Batch 31/64 loss: -2.0291786193847656
Batch 32/64 loss: -1.8920621871948242
Batch 33/64 loss: -1.9767417907714844
Batch 34/64 loss: -2.1118125915527344
Batch 35/64 loss: -1.8578929901123047
Batch 36/64 loss: -1.8906679153442383
Batch 37/64 loss: -1.9691047668457031
Batch 38/64 loss: -2.0070924758911133
Batch 39/64 loss: -2.0814523696899414
Batch 40/64 loss: -2.3422985076904297
Batch 41/64 loss: -2.0497026443481445
Batch 42/64 loss: -2.08425235748291
Batch 43/64 loss: -1.9448280334472656
Batch 44/64 loss: -1.8048686981201172
Batch 45/64 loss: -2.0005483627319336
Batch 46/64 loss: -2.1075220108032227
Batch 47/64 loss: -1.5309162139892578
Batch 48/64 loss: -2.0335922241210938
Batch 49/64 loss: -1.7086267471313477
Batch 50/64 loss: -1.6380138397216797
Batch 51/64 loss: -2.266453742980957
Batch 52/64 loss: -1.9471139907836914
Batch 53/64 loss: -2.071314811706543
Batch 54/64 loss: -1.9571504592895508
Batch 55/64 loss: -1.6737070083618164
Batch 56/64 loss: -1.7793827056884766
Batch 57/64 loss: -2.045762062072754
Batch 58/64 loss: -1.951981544494629
Batch 59/64 loss: -1.953420639038086
Batch 60/64 loss: -2.015242576599121
Batch 61/64 loss: -2.0807600021362305
Batch 62/64 loss: -1.7019243240356445
Batch 63/64 loss: -1.7170124053955078
Batch 64/64 loss: -6.344001770019531
Epoch 83  Train loss: -2.007669770483877  Val loss: -2.1336279931346986
Epoch 84
-------------------------------
Batch 1/64 loss: -1.795175552368164
Batch 2/64 loss: -1.7460565567016602
Batch 3/64 loss: -1.8519411087036133
Batch 4/64 loss: -1.9404487609863281
Batch 5/64 loss: -1.685908317565918
Batch 6/64 loss: -1.7589807510375977
Batch 7/64 loss: -2.1242189407348633
Batch 8/64 loss: -2.0669660568237305
Batch 9/64 loss: -1.7399091720581055
Batch 10/64 loss: -2.1262426376342773
Batch 11/64 loss: -2.009889602661133
Batch 12/64 loss: -1.995041847229004
Batch 13/64 loss: -2.208454132080078
Batch 14/64 loss: -2.1797027587890625
Batch 15/64 loss: -2.2118778228759766
Batch 16/64 loss: -1.931309700012207
Batch 17/64 loss: -1.5814104080200195
Batch 18/64 loss: -2.019009590148926
Batch 19/64 loss: -2.042879104614258
Batch 20/64 loss: -2.142942428588867
Batch 21/64 loss: -2.0699329376220703
Batch 22/64 loss: -2.361517906188965
Batch 23/64 loss: -2.004836082458496
Batch 24/64 loss: -1.8333015441894531
Batch 25/64 loss: -1.7770185470581055
Batch 26/64 loss: -1.6596784591674805
Batch 27/64 loss: -2.062802314758301
Batch 28/64 loss: -2.3152713775634766
Batch 29/64 loss: -2.0255661010742188
Batch 30/64 loss: -2.011507987976074
Batch 31/64 loss: -2.0086898803710938
Batch 32/64 loss: -2.1563100814819336
Batch 33/64 loss: -1.9588241577148438
Batch 34/64 loss: -1.6787004470825195
Batch 35/64 loss: -1.9379873275756836
Batch 36/64 loss: -2.055593490600586
Batch 37/64 loss: -2.176023483276367
Batch 38/64 loss: -2.243694305419922
Batch 39/64 loss: -1.8919239044189453
Batch 40/64 loss: -2.198910713195801
Batch 41/64 loss: -1.9524898529052734
Batch 42/64 loss: -2.4272546768188477
Batch 43/64 loss: -2.1939640045166016
Batch 44/64 loss: -1.7128477096557617
Batch 45/64 loss: -2.2066612243652344
Batch 46/64 loss: -2.072089195251465
Batch 47/64 loss: -1.9846487045288086
Batch 48/64 loss: -2.033784866333008
Batch 49/64 loss: -2.184865951538086
Batch 50/64 loss: -2.053868293762207
Batch 51/64 loss: -2.173638343811035
Batch 52/64 loss: -2.3281593322753906
Batch 53/64 loss: -1.5748624801635742
Batch 54/64 loss: -2.0088424682617188
Batch 55/64 loss: -2.1321754455566406
Batch 56/64 loss: -1.990809440612793
Batch 57/64 loss: -1.6829509735107422
Batch 58/64 loss: -2.224137306213379
Batch 59/64 loss: -1.5039567947387695
Batch 60/64 loss: -1.9849185943603516
Batch 61/64 loss: -2.1117143630981445
Batch 62/64 loss: -2.119962692260742
Batch 63/64 loss: -2.028750419616699
Batch 64/64 loss: -5.957013130187988
Epoch 84  Train loss: -2.050848145578422  Val loss: -2.2753053383319237
Saving best model, epoch: 84
Epoch 85
-------------------------------
Batch 1/64 loss: -1.7913856506347656
Batch 2/64 loss: -1.6998920440673828
Batch 3/64 loss: -2.2822980880737305
Batch 4/64 loss: -2.2895193099975586
Batch 5/64 loss: -1.8445110321044922
Batch 6/64 loss: -1.592249870300293
Batch 7/64 loss: -2.070492744445801
Batch 8/64 loss: -1.924778938293457
Batch 9/64 loss: -2.0244483947753906
Batch 10/64 loss: -2.2087221145629883
Batch 11/64 loss: -2.194626808166504
Batch 12/64 loss: -1.9245166778564453
Batch 13/64 loss: -2.0721282958984375
Batch 14/64 loss: -1.9421443939208984
Batch 15/64 loss: -2.0118484497070312
Batch 16/64 loss: -2.167006492614746
Batch 17/64 loss: -1.7310447692871094
Batch 18/64 loss: -1.6758012771606445
Batch 19/64 loss: -1.7138118743896484
Batch 20/64 loss: -1.8200082778930664
Batch 21/64 loss: -2.0469608306884766
Batch 22/64 loss: -1.7636375427246094
Batch 23/64 loss: -1.736241340637207
Batch 24/64 loss: -2.0295848846435547
Batch 25/64 loss: -2.0147485733032227
Batch 26/64 loss: -1.8602123260498047
Batch 27/64 loss: -1.7493581771850586
Batch 28/64 loss: -1.8791780471801758
Batch 29/64 loss: -1.9693384170532227
Batch 30/64 loss: -1.830784797668457
Batch 31/64 loss: -1.6684608459472656
Batch 32/64 loss: -1.89666748046875
Batch 33/64 loss: -2.2656822204589844
Batch 34/64 loss: -1.8099994659423828
Batch 35/64 loss: -2.023651123046875
Batch 36/64 loss: -1.711893081665039
Batch 37/64 loss: -2.239485740661621
Batch 38/64 loss: -1.524362564086914
Batch 39/64 loss: -2.038510322570801
Batch 40/64 loss: -2.1013917922973633
Batch 41/64 loss: -2.219099998474121
Batch 42/64 loss: -2.256683349609375
Batch 43/64 loss: -2.1530046463012695
Batch 44/64 loss: -1.4345645904541016
Batch 45/64 loss: -2.2661190032958984
Batch 46/64 loss: -2.1565113067626953
Batch 47/64 loss: -1.9773588180541992
Batch 48/64 loss: -1.7233362197875977
Batch 49/64 loss: -2.1643733978271484
Batch 50/64 loss: -1.624979019165039
Batch 51/64 loss: -2.115218162536621
Batch 52/64 loss: -2.0310678482055664
Batch 53/64 loss: -2.152801513671875
Batch 54/64 loss: -2.1121530532836914
Batch 55/64 loss: -2.0947132110595703
Batch 56/64 loss: -1.6955108642578125
Batch 57/64 loss: -2.1093196868896484
Batch 58/64 loss: -1.9288129806518555
Batch 59/64 loss: -1.9830036163330078
Batch 60/64 loss: -2.1720809936523438
Batch 61/64 loss: -2.0745697021484375
Batch 62/64 loss: -2.1520261764526367
Batch 63/64 loss: -1.940816879272461
Batch 64/64 loss: -6.339092254638672
Epoch 85  Train loss: -2.014648302863626  Val loss: -2.1464904444324193
Epoch 86
-------------------------------
Batch 1/64 loss: -2.0669755935668945
Batch 2/64 loss: -1.8744163513183594
Batch 3/64 loss: -1.7224082946777344
Batch 4/64 loss: -2.1895675659179688
Batch 5/64 loss: -1.9632043838500977
Batch 6/64 loss: -1.989389419555664
Batch 7/64 loss: -1.693197250366211
Batch 8/64 loss: -2.2807703018188477
Batch 9/64 loss: -1.619821548461914
Batch 10/64 loss: -1.734910011291504
Batch 11/64 loss: -1.8044967651367188
Batch 12/64 loss: -1.7789440155029297
Batch 13/64 loss: -1.9335613250732422
Batch 14/64 loss: -2.095090866088867
Batch 15/64 loss: -1.906407356262207
Batch 16/64 loss: -2.255314826965332
Batch 17/64 loss: -1.6302804946899414
Batch 18/64 loss: -2.0758743286132812
Batch 19/64 loss: -2.2054977416992188
Batch 20/64 loss: -1.7108831405639648
Batch 21/64 loss: -2.066737174987793
Batch 22/64 loss: -2.2713403701782227
Batch 23/64 loss: -1.9109230041503906
Batch 24/64 loss: -2.063887596130371
Batch 25/64 loss: -2.38516902923584
Batch 26/64 loss: -2.069085121154785
Batch 27/64 loss: -2.0015974044799805
Batch 28/64 loss: -2.466738700866699
Batch 29/64 loss: -1.7438945770263672
Batch 30/64 loss: -2.1585617065429688
Batch 31/64 loss: -1.9954776763916016
Batch 32/64 loss: -1.885615348815918
Batch 33/64 loss: -1.5503301620483398
Batch 34/64 loss: -2.045644760131836
Batch 35/64 loss: -1.8245906829833984
Batch 36/64 loss: -1.5825366973876953
Batch 37/64 loss: -1.9355239868164062
Batch 38/64 loss: -2.0599985122680664
Batch 39/64 loss: -2.328977584838867
Batch 40/64 loss: -2.1122541427612305
Batch 41/64 loss: -1.7305288314819336
Batch 42/64 loss: -1.9937868118286133
Batch 43/64 loss: -2.075930595397949
Batch 44/64 loss: -1.9262199401855469
Batch 45/64 loss: -1.9891977310180664
Batch 46/64 loss: -2.074732780456543
Batch 47/64 loss: -2.2050952911376953
Batch 48/64 loss: -1.9736242294311523
Batch 49/64 loss: -1.6118192672729492
Batch 50/64 loss: -2.206106185913086
Batch 51/64 loss: -1.538376808166504
Batch 52/64 loss: -2.3000125885009766
Batch 53/64 loss: -1.9861822128295898
Batch 54/64 loss: -2.112919807434082
Batch 55/64 loss: -2.3146533966064453
Batch 56/64 loss: -2.031963348388672
Batch 57/64 loss: -2.0286340713500977
Batch 58/64 loss: -2.150815010070801
Batch 59/64 loss: -2.162374496459961
Batch 60/64 loss: -2.1870737075805664
Batch 61/64 loss: -1.689483642578125
Batch 62/64 loss: -1.4595928192138672
Batch 63/64 loss: -2.069215774536133
Batch 64/64 loss: -6.683990955352783
Epoch 86  Train loss: -2.0364114256466137  Val loss: -2.2131622026056768
Epoch 87
-------------------------------
Batch 1/64 loss: -1.8397340774536133
Batch 2/64 loss: -2.073885917663574
Batch 3/64 loss: -1.8601055145263672
Batch 4/64 loss: -1.865570068359375
Batch 5/64 loss: -2.036294937133789
Batch 6/64 loss: -1.4233951568603516
Batch 7/64 loss: -1.9073057174682617
Batch 8/64 loss: -1.6405630111694336
Batch 9/64 loss: -2.244696617126465
Batch 10/64 loss: -2.055079460144043
Batch 11/64 loss: -1.8018417358398438
Batch 12/64 loss: -2.0817203521728516
Batch 13/64 loss: -1.8465147018432617
Batch 14/64 loss: -2.127157211303711
Batch 15/64 loss: -1.594670295715332
Batch 16/64 loss: -1.6554174423217773
Batch 17/64 loss: -2.2818174362182617
Batch 18/64 loss: -1.587636947631836
Batch 19/64 loss: -2.2561120986938477
Batch 20/64 loss: -2.017348289489746
Batch 21/64 loss: -2.2246150970458984
Batch 22/64 loss: -1.984553337097168
Batch 23/64 loss: -2.3191070556640625
Batch 24/64 loss: -2.088812828063965
Batch 25/64 loss: -2.1337738037109375
Batch 26/64 loss: -2.3558835983276367
Batch 27/64 loss: -1.9775104522705078
Batch 28/64 loss: -2.321500778198242
Batch 29/64 loss: -1.9408464431762695
Batch 30/64 loss: -1.7988080978393555
Batch 31/64 loss: -2.0554885864257812
Batch 32/64 loss: -1.3191204071044922
Batch 33/64 loss: -2.259884834289551
Batch 34/64 loss: -2.0137405395507812
Batch 35/64 loss: -2.1029720306396484
Batch 36/64 loss: -1.8840045928955078
Batch 37/64 loss: -1.8879528045654297
Batch 38/64 loss: -1.9467716217041016
Batch 39/64 loss: -2.3143606185913086
Batch 40/64 loss: -2.1031293869018555
Batch 41/64 loss: -1.6120729446411133
Batch 42/64 loss: -2.1340160369873047
Batch 43/64 loss: -2.107893943786621
Batch 44/64 loss: -2.0869626998901367
Batch 45/64 loss: -2.1835145950317383
Batch 46/64 loss: -1.9524288177490234
Batch 47/64 loss: -2.2199087142944336
Batch 48/64 loss: -1.9024991989135742
Batch 49/64 loss: -2.1920671463012695
Batch 50/64 loss: -2.121885299682617
Batch 51/64 loss: -1.9575319290161133
Batch 52/64 loss: -1.5124292373657227
Batch 53/64 loss: -1.6842145919799805
Batch 54/64 loss: -2.1378211975097656
Batch 55/64 loss: -1.8569536209106445
Batch 56/64 loss: -1.9908533096313477
Batch 57/64 loss: -2.0708999633789062
Batch 58/64 loss: -2.037872314453125
Batch 59/64 loss: -1.8060426712036133
Batch 60/64 loss: -1.8853120803833008
Batch 61/64 loss: -1.8876237869262695
Batch 62/64 loss: -2.18044376373291
Batch 63/64 loss: -2.030336380004883
Batch 64/64 loss: -6.741415023803711
Epoch 87  Train loss: -2.0366643045462816  Val loss: -2.1978735120845414
Epoch 88
-------------------------------
Batch 1/64 loss: -2.2873220443725586
Batch 2/64 loss: -1.989990234375
Batch 3/64 loss: -2.1241378784179688
Batch 4/64 loss: -2.002884864807129
Batch 5/64 loss: -2.035768508911133
Batch 6/64 loss: -1.8781099319458008
Batch 7/64 loss: -2.2672033309936523
Batch 8/64 loss: -1.757399559020996
Batch 9/64 loss: -1.9983205795288086
Batch 10/64 loss: -2.1696176528930664
Batch 11/64 loss: -2.161722183227539
Batch 12/64 loss: -2.0328359603881836
Batch 13/64 loss: -1.717315673828125
Batch 14/64 loss: -1.9082279205322266
Batch 15/64 loss: -2.1257925033569336
Batch 16/64 loss: -2.086465835571289
Batch 17/64 loss: -1.8666152954101562
Batch 18/64 loss: -1.927140235900879
Batch 19/64 loss: -1.9608793258666992
Batch 20/64 loss: -2.2097597122192383
Batch 21/64 loss: -2.287303924560547
Batch 22/64 loss: -2.1511220932006836
Batch 23/64 loss: -2.140568733215332
Batch 24/64 loss: -2.1757116317749023
Batch 25/64 loss: -1.6461601257324219
Batch 26/64 loss: -2.2367935180664062
Batch 27/64 loss: -2.12404727935791
Batch 28/64 loss: -2.242302894592285
Batch 29/64 loss: -2.0893478393554688
Batch 30/64 loss: -1.6224117279052734
Batch 31/64 loss: -2.188288688659668
Batch 32/64 loss: -2.057387351989746
Batch 33/64 loss: -1.7563276290893555
Batch 34/64 loss: -2.375448226928711
Batch 35/64 loss: -1.98175048828125
Batch 36/64 loss: -1.9839506149291992
Batch 37/64 loss: -2.127243995666504
Batch 38/64 loss: -2.101956367492676
Batch 39/64 loss: -2.137681007385254
Batch 40/64 loss: -2.0333194732666016
Batch 41/64 loss: -2.2459287643432617
Batch 42/64 loss: -2.114238739013672
Batch 43/64 loss: -1.6297922134399414
Batch 44/64 loss: -1.866969108581543
Batch 45/64 loss: -2.0681276321411133
Batch 46/64 loss: -2.0593767166137695
Batch 47/64 loss: -1.9052305221557617
Batch 48/64 loss: -1.7335920333862305
Batch 49/64 loss: -2.108081817626953
Batch 50/64 loss: -1.8852424621582031
Batch 51/64 loss: -2.0655689239501953
Batch 52/64 loss: -2.175426483154297
Batch 53/64 loss: -2.211207389831543
Batch 54/64 loss: -1.9760732650756836
Batch 55/64 loss: -1.9468650817871094
Batch 56/64 loss: -2.0312976837158203
Batch 57/64 loss: -1.9047555923461914
Batch 58/64 loss: -2.0563011169433594
Batch 59/64 loss: -2.054901123046875
Batch 60/64 loss: -2.202761650085449
Batch 61/64 loss: -1.745713233947754
Batch 62/64 loss: -2.027568817138672
Batch 63/64 loss: -2.1468000411987305
Batch 64/64 loss: -6.252629280090332
Epoch 88  Train loss: -2.0834184347414504  Val loss: -2.1980460124327146
Epoch 89
-------------------------------
Batch 1/64 loss: -2.165546417236328
Batch 2/64 loss: -2.1718883514404297
Batch 3/64 loss: -2.1070289611816406
Batch 4/64 loss: -2.0090036392211914
Batch 5/64 loss: -2.039029121398926
Batch 6/64 loss: -1.9345922470092773
Batch 7/64 loss: -1.8814334869384766
Batch 8/64 loss: -1.832594871520996
Batch 9/64 loss: -2.0968942642211914
Batch 10/64 loss: -1.7027435302734375
Batch 11/64 loss: -1.929574966430664
Batch 12/64 loss: -1.9584169387817383
Batch 13/64 loss: -1.661025047302246
Batch 14/64 loss: -2.1026382446289062
Batch 15/64 loss: -2.0141420364379883
Batch 16/64 loss: -1.9509773254394531
Batch 17/64 loss: -2.128922462463379
Batch 18/64 loss: -2.2602319717407227
Batch 19/64 loss: -1.9610681533813477
Batch 20/64 loss: -1.801060676574707
Batch 21/64 loss: -2.154421806335449
Batch 22/64 loss: -2.1574954986572266
Batch 23/64 loss: -2.2838191986083984
Batch 24/64 loss: -1.9744195938110352
Batch 25/64 loss: -2.125044822692871
Batch 26/64 loss: -2.07204532623291
Batch 27/64 loss: -2.0457983016967773
Batch 28/64 loss: -2.144843101501465
Batch 29/64 loss: -1.3438224792480469
Batch 30/64 loss: -2.317458152770996
Batch 31/64 loss: -2.216794967651367
Batch 32/64 loss: -1.9638471603393555
Batch 33/64 loss: -2.1623010635375977
Batch 34/64 loss: -2.2156572341918945
Batch 35/64 loss: -1.7983884811401367
Batch 36/64 loss: -2.265896797180176
Batch 37/64 loss: -2.0076894760131836
Batch 38/64 loss: -2.10134220123291
Batch 39/64 loss: -1.9429874420166016
Batch 40/64 loss: -2.2398414611816406
Batch 41/64 loss: -1.8871526718139648
Batch 42/64 loss: -2.2238330841064453
Batch 43/64 loss: -2.2772064208984375
Batch 44/64 loss: -2.358264923095703
Batch 45/64 loss: -1.5179204940795898
Batch 46/64 loss: -2.2595348358154297
Batch 47/64 loss: -2.3770437240600586
Batch 48/64 loss: -1.767289161682129
Batch 49/64 loss: -1.7457866668701172
Batch 50/64 loss: -2.2612600326538086
Batch 51/64 loss: -1.8816242218017578
Batch 52/64 loss: -1.6745004653930664
Batch 53/64 loss: -2.4561710357666016
Batch 54/64 loss: -1.835646629333496
Batch 55/64 loss: -2.1576433181762695
Batch 56/64 loss: -1.98309326171875
Batch 57/64 loss: -2.0049686431884766
Batch 58/64 loss: -2.098080635070801
Batch 59/64 loss: -2.189152717590332
Batch 60/64 loss: -2.212137222290039
Batch 61/64 loss: -2.146245002746582
Batch 62/64 loss: -1.7951202392578125
Batch 63/64 loss: -2.1490774154663086
Batch 64/64 loss: -6.080288887023926
Epoch 89  Train loss: -2.08724230224011  Val loss: -2.255136286679822
Epoch 90
-------------------------------
Batch 1/64 loss: -1.8301753997802734
Batch 2/64 loss: -2.1777820587158203
Batch 3/64 loss: -2.1640825271606445
Batch 4/64 loss: -1.5053892135620117
Batch 5/64 loss: -2.2989444732666016
Batch 6/64 loss: -2.29390811920166
Batch 7/64 loss: -2.2423276901245117
Batch 8/64 loss: -1.7120723724365234
Batch 9/64 loss: -2.24831485748291
Batch 10/64 loss: -2.1566362380981445
Batch 11/64 loss: -2.166018486022949
Batch 12/64 loss: -1.9235353469848633
Batch 13/64 loss: -1.9954757690429688
Batch 14/64 loss: -1.9009675979614258
Batch 15/64 loss: -2.15653133392334
Batch 16/64 loss: -1.3331613540649414
Batch 17/64 loss: -2.2451372146606445
Batch 18/64 loss: -2.133768081665039
Batch 19/64 loss: -2.0320186614990234
Batch 20/64 loss: -1.816777229309082
Batch 21/64 loss: -2.2150001525878906
Batch 22/64 loss: -2.3254480361938477
Batch 23/64 loss: -1.6388139724731445
Batch 24/64 loss: -1.7133417129516602
Batch 25/64 loss: -2.299139976501465
Batch 26/64 loss: -1.8044519424438477
Batch 27/64 loss: -1.8710317611694336
Batch 28/64 loss: -1.6723814010620117
Batch 29/64 loss: -1.6044597625732422
Batch 30/64 loss: -2.0195751190185547
Batch 31/64 loss: -1.7184152603149414
Batch 32/64 loss: -2.0153913497924805
Batch 33/64 loss: -1.932408332824707
Batch 34/64 loss: -1.978623390197754
Batch 35/64 loss: -1.8285388946533203
Batch 36/64 loss: -2.199787139892578
Batch 37/64 loss: -1.4750480651855469
Batch 38/64 loss: -2.286726951599121
Batch 39/64 loss: -1.6039505004882812
Batch 40/64 loss: -2.213129997253418
Batch 41/64 loss: -1.912637710571289
Batch 42/64 loss: -1.479562759399414
Batch 43/64 loss: -1.5615558624267578
Batch 44/64 loss: -1.7300920486450195
Batch 45/64 loss: -2.091144561767578
Batch 46/64 loss: -1.839278221130371
Batch 47/64 loss: -1.9221830368041992
Batch 48/64 loss: -2.0715503692626953
Batch 49/64 loss: -1.8830795288085938
Batch 50/64 loss: -2.148159980773926
Batch 51/64 loss: -1.71868896484375
Batch 52/64 loss: -2.052618980407715
Batch 53/64 loss: -2.036696434020996
Batch 54/64 loss: -2.0287561416625977
Batch 55/64 loss: -2.05374813079834
Batch 56/64 loss: -2.2598648071289062
Batch 57/64 loss: -1.914149284362793
Batch 58/64 loss: -1.9107694625854492
Batch 59/64 loss: -1.9325809478759766
Batch 60/64 loss: -2.06729793548584
Batch 61/64 loss: -1.881765365600586
Batch 62/64 loss: -2.122500419616699
Batch 63/64 loss: -2.0403928756713867
Batch 64/64 loss: -6.490694999694824
Epoch 90  Train loss: -2.0121691423303942  Val loss: -2.156135414883853
Epoch 91
-------------------------------
Batch 1/64 loss: -2.0837020874023438
Batch 2/64 loss: -1.7847747802734375
Batch 3/64 loss: -2.3057918548583984
Batch 4/64 loss: -1.9170007705688477
Batch 5/64 loss: -1.9508447647094727
Batch 6/64 loss: -2.1033811569213867
Batch 7/64 loss: -1.8516731262207031
Batch 8/64 loss: -1.9113245010375977
Batch 9/64 loss: -2.251389503479004
Batch 10/64 loss: -2.2072067260742188
Batch 11/64 loss: -1.8103084564208984
Batch 12/64 loss: -1.835958480834961
Batch 13/64 loss: -2.065166473388672
Batch 14/64 loss: -2.1280431747436523
Batch 15/64 loss: -1.968714714050293
Batch 16/64 loss: -1.9019546508789062
Batch 17/64 loss: -2.2184371948242188
Batch 18/64 loss: -1.9072380065917969
Batch 19/64 loss: -2.1242189407348633
Batch 20/64 loss: -2.0388097763061523
Batch 21/64 loss: -2.026996612548828
Batch 22/64 loss: -2.04250431060791
Batch 23/64 loss: -2.011775016784668
Batch 24/64 loss: -2.071953773498535
Batch 25/64 loss: -1.378626823425293
Batch 26/64 loss: -2.044186592102051
Batch 27/64 loss: -2.226656913757324
Batch 28/64 loss: -1.9338397979736328
Batch 29/64 loss: -2.28369140625
Batch 30/64 loss: -1.946279525756836
Batch 31/64 loss: -1.7805747985839844
Batch 32/64 loss: -2.2270917892456055
Batch 33/64 loss: -1.5503768920898438
Batch 34/64 loss: -2.445558547973633
Batch 35/64 loss: -2.0213804244995117
Batch 36/64 loss: -2.2651185989379883
Batch 37/64 loss: -1.9006013870239258
Batch 38/64 loss: -1.9668025970458984
Batch 39/64 loss: -1.6292543411254883
Batch 40/64 loss: -2.256411552429199
Batch 41/64 loss: -1.782236099243164
Batch 42/64 loss: -2.1634387969970703
Batch 43/64 loss: -2.2615041732788086
Batch 44/64 loss: -2.1362133026123047
Batch 45/64 loss: -1.770524024963379
Batch 46/64 loss: -2.354641914367676
Batch 47/64 loss: -2.0656375885009766
Batch 48/64 loss: -1.609421730041504
Batch 49/64 loss: -2.194268226623535
Batch 50/64 loss: -2.1769142150878906
Batch 51/64 loss: -2.186992645263672
Batch 52/64 loss: -1.527627944946289
Batch 53/64 loss: -2.3471155166625977
Batch 54/64 loss: -2.2508544921875
Batch 55/64 loss: -2.011259078979492
Batch 56/64 loss: -2.21453857421875
Batch 57/64 loss: -1.894906997680664
Batch 58/64 loss: -2.105581283569336
Batch 59/64 loss: -2.052867889404297
Batch 60/64 loss: -1.9721860885620117
Batch 61/64 loss: -1.862588882446289
Batch 62/64 loss: -1.7347173690795898
Batch 63/64 loss: -2.3027191162109375
Batch 64/64 loss: -6.5806427001953125
Epoch 91  Train loss: -2.075135040283203  Val loss: -2.240735240818299
Epoch 92
-------------------------------
Batch 1/64 loss: -1.6381444931030273
Batch 2/64 loss: -2.136019706726074
Batch 3/64 loss: -2.070476531982422
Batch 4/64 loss: -1.5067481994628906
Batch 5/64 loss: -2.0383424758911133
Batch 6/64 loss: -2.2179203033447266
Batch 7/64 loss: -2.2004146575927734
Batch 8/64 loss: -1.9445409774780273
Batch 9/64 loss: -2.0455455780029297
Batch 10/64 loss: -2.2505273818969727
Batch 11/64 loss: -2.158474922180176
Batch 12/64 loss: -2.017754554748535
Batch 13/64 loss: -1.9551172256469727
Batch 14/64 loss: -2.0327529907226562
Batch 15/64 loss: -2.3894948959350586
Batch 16/64 loss: -1.9389009475708008
Batch 17/64 loss: -2.205991744995117
Batch 18/64 loss: -2.2100143432617188
Batch 19/64 loss: -2.1541996002197266
Batch 20/64 loss: -1.9206085205078125
Batch 21/64 loss: -2.1442031860351562
Batch 22/64 loss: -1.2359533309936523
Batch 23/64 loss: -1.8932743072509766
Batch 24/64 loss: -2.1443710327148438
Batch 25/64 loss: -2.1814889907836914
Batch 26/64 loss: -2.1958770751953125
Batch 27/64 loss: -1.9827003479003906
Batch 28/64 loss: -2.037189483642578
Batch 29/64 loss: -2.0104990005493164
Batch 30/64 loss: -2.2995986938476562
Batch 31/64 loss: -1.71038818359375
Batch 32/64 loss: -2.1879234313964844
Batch 33/64 loss: -1.6892166137695312
Batch 34/64 loss: -2.027679443359375
Batch 35/64 loss: -2.280594825744629
Batch 36/64 loss: -2.2515382766723633
Batch 37/64 loss: -1.9080781936645508
Batch 38/64 loss: -2.0396652221679688
Batch 39/64 loss: -2.0010271072387695
Batch 40/64 loss: -1.7851037979125977
Batch 41/64 loss: -2.163785934448242
Batch 42/64 loss: -1.8625125885009766
Batch 43/64 loss: -2.086400032043457
Batch 44/64 loss: -1.80059814453125
Batch 45/64 loss: -1.9462852478027344
Batch 46/64 loss: -1.990952491760254
Batch 47/64 loss: -1.6976747512817383
Batch 48/64 loss: -1.8544044494628906
Batch 49/64 loss: -2.2847766876220703
Batch 50/64 loss: -2.2116546630859375
Batch 51/64 loss: -1.945033073425293
Batch 52/64 loss: -1.4422903060913086
Batch 53/64 loss: -1.8294429779052734
Batch 54/64 loss: -1.7208137512207031
Batch 55/64 loss: -2.038278579711914
Batch 56/64 loss: -2.0299272537231445
Batch 57/64 loss: -2.19197940826416
Batch 58/64 loss: -2.101302146911621
Batch 59/64 loss: -2.1746816635131836
Batch 60/64 loss: -2.120945930480957
Batch 61/64 loss: -2.201784133911133
Batch 62/64 loss: -2.1794843673706055
Batch 63/64 loss: -2.113093376159668
Batch 64/64 loss: -6.356673240661621
Epoch 92  Train loss: -2.067356352712594  Val loss: -2.1111340473607645
Epoch 93
-------------------------------
Batch 1/64 loss: -2.0269908905029297
Batch 2/64 loss: -1.3162460327148438
Batch 3/64 loss: -2.0453357696533203
Batch 4/64 loss: -1.9253778457641602
Batch 5/64 loss: -2.0704755783081055
Batch 6/64 loss: -2.1561050415039062
Batch 7/64 loss: -2.277358055114746
Batch 8/64 loss: -1.6387224197387695
Batch 9/64 loss: -1.9846744537353516
Batch 10/64 loss: -1.5709352493286133
Batch 11/64 loss: -1.6396284103393555
Batch 12/64 loss: -1.9015178680419922
Batch 13/64 loss: -2.3563308715820312
Batch 14/64 loss: -2.268331527709961
Batch 15/64 loss: -2.3409671783447266
Batch 16/64 loss: -2.1154775619506836
Batch 17/64 loss: -2.1483936309814453
Batch 18/64 loss: -1.9491796493530273
Batch 19/64 loss: -2.1470460891723633
Batch 20/64 loss: -2.393770217895508
Batch 21/64 loss: -2.333721160888672
Batch 22/64 loss: -1.962942123413086
Batch 23/64 loss: -1.6785306930541992
Batch 24/64 loss: -2.607522964477539
Batch 25/64 loss: -2.039379119873047
Batch 26/64 loss: -2.194634437561035
Batch 27/64 loss: -2.1632394790649414
Batch 28/64 loss: -2.1430110931396484
Batch 29/64 loss: -1.525599479675293
Batch 30/64 loss: -2.23146915435791
Batch 31/64 loss: -2.0112733840942383
Batch 32/64 loss: -1.933267593383789
Batch 33/64 loss: -1.9198999404907227
Batch 34/64 loss: -2.2801265716552734
Batch 35/64 loss: -2.192964553833008
Batch 36/64 loss: -2.422697067260742
Batch 37/64 loss: -1.668187141418457
Batch 38/64 loss: -1.8666048049926758
Batch 39/64 loss: -1.9561243057250977
Batch 40/64 loss: -2.014523506164551
Batch 41/64 loss: -1.892136573791504
Batch 42/64 loss: -1.9074029922485352
Batch 43/64 loss: -2.0175933837890625
Batch 44/64 loss: -2.072904586791992
Batch 45/64 loss: -2.178293228149414
Batch 46/64 loss: -2.0266103744506836
Batch 47/64 loss: -2.318680763244629
Batch 48/64 loss: -1.8895645141601562
Batch 49/64 loss: -1.9294509887695312
Batch 50/64 loss: -2.0399742126464844
Batch 51/64 loss: -2.1721229553222656
Batch 52/64 loss: -2.2178802490234375
Batch 53/64 loss: -1.6966142654418945
Batch 54/64 loss: -1.8924617767333984
Batch 55/64 loss: -1.9627342224121094
Batch 56/64 loss: -2.0656232833862305
Batch 57/64 loss: -2.0278940200805664
Batch 58/64 loss: -2.0871334075927734
Batch 59/64 loss: -2.162790298461914
Batch 60/64 loss: -1.8144378662109375
Batch 61/64 loss: -2.356736183166504
Batch 62/64 loss: -2.256716728210449
Batch 63/64 loss: -2.089707374572754
Batch 64/64 loss: -6.449404239654541
Epoch 93  Train loss: -2.091468240700516  Val loss: -2.272426080867597
Epoch 94
-------------------------------
Batch 1/64 loss: -1.4790620803833008
Batch 2/64 loss: -2.320826530456543
Batch 3/64 loss: -1.6557178497314453
Batch 4/64 loss: -2.0704421997070312
Batch 5/64 loss: -2.213192939758301
Batch 6/64 loss: -2.0129518508911133
Batch 7/64 loss: -2.3223705291748047
Batch 8/64 loss: -1.8797073364257812
Batch 9/64 loss: -1.9311561584472656
Batch 10/64 loss: -2.2630233764648438
Batch 11/64 loss: -2.31899356842041
Batch 12/64 loss: -2.063383102416992
Batch 13/64 loss: -1.7816057205200195
Batch 14/64 loss: -2.0267333984375
Batch 15/64 loss: -2.1747493743896484
Batch 16/64 loss: -2.096162796020508
Batch 17/64 loss: -2.2837629318237305
Batch 18/64 loss: -2.0464372634887695
Batch 19/64 loss: -1.8988876342773438
Batch 20/64 loss: -2.311124801635742
Batch 21/64 loss: -2.106499671936035
Batch 22/64 loss: -2.229180335998535
Batch 23/64 loss: -2.251432418823242
Batch 24/64 loss: -1.6150455474853516
Batch 25/64 loss: -1.8781318664550781
Batch 26/64 loss: -2.0144529342651367
Batch 27/64 loss: -2.0398855209350586
Batch 28/64 loss: -1.9609289169311523
Batch 29/64 loss: -1.5657463073730469
Batch 30/64 loss: -2.2160520553588867
Batch 31/64 loss: -1.9877872467041016
Batch 32/64 loss: -2.142000198364258
Batch 33/64 loss: -1.8831405639648438
Batch 34/64 loss: -2.367504119873047
Batch 35/64 loss: -2.1835813522338867
Batch 36/64 loss: -1.7977571487426758
Batch 37/64 loss: -2.1340436935424805
Batch 38/64 loss: -2.024425506591797
Batch 39/64 loss: -2.1531219482421875
Batch 40/64 loss: -1.9078693389892578
Batch 41/64 loss: -2.138437271118164
Batch 42/64 loss: -1.6789464950561523
Batch 43/64 loss: -1.9634342193603516
Batch 44/64 loss: -1.8788270950317383
Batch 45/64 loss: -2.271259307861328
Batch 46/64 loss: -1.87139892578125
Batch 47/64 loss: -2.3707780838012695
Batch 48/64 loss: -2.186555862426758
Batch 49/64 loss: -1.6527528762817383
Batch 50/64 loss: -1.7610845565795898
Batch 51/64 loss: -2.0264158248901367
Batch 52/64 loss: -2.1283512115478516
Batch 53/64 loss: -1.9270963668823242
Batch 54/64 loss: -2.171783447265625
Batch 55/64 loss: -1.8375043869018555
Batch 56/64 loss: -2.259711265563965
Batch 57/64 loss: -1.512812614440918
Batch 58/64 loss: -1.8648805618286133
Batch 59/64 loss: -2.3854856491088867
Batch 60/64 loss: -2.3624277114868164
Batch 61/64 loss: -1.9182186126708984
Batch 62/64 loss: -1.9649667739868164
Batch 63/64 loss: -2.1226024627685547
Batch 64/64 loss: -6.72613525390625
Epoch 94  Train loss: -2.0848503711176853  Val loss: -2.3126358609019277
Saving best model, epoch: 94
Epoch 95
-------------------------------
Batch 1/64 loss: -2.2131271362304688
Batch 2/64 loss: -1.869333267211914
Batch 3/64 loss: -1.9920682907104492
Batch 4/64 loss: -2.1832456588745117
Batch 5/64 loss: -2.1834592819213867
Batch 6/64 loss: -2.080307960510254
Batch 7/64 loss: -2.086836814880371
Batch 8/64 loss: -2.2472620010375977
Batch 9/64 loss: -2.1026716232299805
Batch 10/64 loss: -2.238710403442383
Batch 11/64 loss: -2.106001853942871
Batch 12/64 loss: -2.1200180053710938
Batch 13/64 loss: -1.1857538223266602
Batch 14/64 loss: -2.1432294845581055
Batch 15/64 loss: -1.616591453552246
Batch 16/64 loss: -2.197169303894043
Batch 17/64 loss: -2.1053237915039062
Batch 18/64 loss: -1.7353105545043945
Batch 19/64 loss: -2.0248613357543945
Batch 20/64 loss: -1.849991798400879
Batch 21/64 loss: -2.0384721755981445
Batch 22/64 loss: -0.6215057373046875
Batch 23/64 loss: -2.227829933166504
Batch 24/64 loss: -2.1093320846557617
Batch 25/64 loss: -2.2147645950317383
Batch 26/64 loss: -2.296614646911621
Batch 27/64 loss: -2.2686519622802734
Batch 28/64 loss: -2.1007118225097656
Batch 29/64 loss: -2.3160762786865234
Batch 30/64 loss: -2.00631046295166
Batch 31/64 loss: -2.1352977752685547
Batch 32/64 loss: -1.7462024688720703
Batch 33/64 loss: -1.8357362747192383
Batch 34/64 loss: -2.240706443786621
Batch 35/64 loss: -1.925210952758789
Batch 36/64 loss: -2.172914505004883
Batch 37/64 loss: -1.8393869400024414
Batch 38/64 loss: -2.0075435638427734
Batch 39/64 loss: -1.9905633926391602
Batch 40/64 loss: -2.316957473754883
Batch 41/64 loss: -2.445009231567383
Batch 42/64 loss: -2.1554574966430664
Batch 43/64 loss: -2.057253837585449
Batch 44/64 loss: -2.245020866394043
Batch 45/64 loss: -1.7213983535766602
Batch 46/64 loss: -2.146021842956543
Batch 47/64 loss: -2.1069765090942383
Batch 48/64 loss: -1.8478498458862305
Batch 49/64 loss: -2.0796890258789062
Batch 50/64 loss: -2.2817068099975586
Batch 51/64 loss: -1.8438796997070312
Batch 52/64 loss: -2.2186880111694336
Batch 53/64 loss: -1.9968318939208984
Batch 54/64 loss: -1.9624395370483398
Batch 55/64 loss: -2.16500186920166
Batch 56/64 loss: -1.9098262786865234
Batch 57/64 loss: -2.2438411712646484
Batch 58/64 loss: -1.8122138977050781
Batch 59/64 loss: -2.135801315307617
Batch 60/64 loss: -1.734543800354004
Batch 61/64 loss: -2.359347343444824
Batch 62/64 loss: -1.9652595520019531
Batch 63/64 loss: -2.0939598083496094
Batch 64/64 loss: -6.390996932983398
Epoch 95  Train loss: -2.0864835926130705  Val loss: -2.335088644650384
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: -2.2200984954833984
Batch 2/64 loss: -1.8541812896728516
Batch 3/64 loss: -2.3684654235839844
Batch 4/64 loss: -1.7482566833496094
Batch 5/64 loss: -2.348377227783203
Batch 6/64 loss: -1.5866107940673828
Batch 7/64 loss: -1.175313949584961
Batch 8/64 loss: -2.2547130584716797
Batch 9/64 loss: -2.12575626373291
Batch 10/64 loss: -2.1027345657348633
Batch 11/64 loss: -2.112969398498535
Batch 12/64 loss: -2.1010055541992188
Batch 13/64 loss: -2.18833065032959
Batch 14/64 loss: -2.271641731262207
Batch 15/64 loss: -2.0399961471557617
Batch 16/64 loss: -2.235006332397461
Batch 17/64 loss: -1.4893426895141602
Batch 18/64 loss: -2.2519617080688477
Batch 19/64 loss: -2.084400177001953
Batch 20/64 loss: -2.3845434188842773
Batch 21/64 loss: -1.9297761917114258
Batch 22/64 loss: -2.2121667861938477
Batch 23/64 loss: -2.079019546508789
Batch 24/64 loss: -1.789194107055664
Batch 25/64 loss: -1.6711444854736328
Batch 26/64 loss: -2.2396154403686523
Batch 27/64 loss: -2.2348880767822266
Batch 28/64 loss: -2.1224966049194336
Batch 29/64 loss: -2.1362953186035156
Batch 30/64 loss: -2.098573684692383
Batch 31/64 loss: -1.7103137969970703
Batch 32/64 loss: -2.2998247146606445
Batch 33/64 loss: -2.396479606628418
Batch 34/64 loss: -2.1964588165283203
Batch 35/64 loss: -2.528203010559082
Batch 36/64 loss: -2.3661508560180664
Batch 37/64 loss: -1.6899747848510742
Batch 38/64 loss: -1.954819679260254
Batch 39/64 loss: -2.355290412902832
Batch 40/64 loss: -2.1498470306396484
Batch 41/64 loss: -2.004624366760254
Batch 42/64 loss: -2.1013174057006836
Batch 43/64 loss: -1.9446115493774414
Batch 44/64 loss: -2.104519844055176
Batch 45/64 loss: -2.2856884002685547
Batch 46/64 loss: -1.6974220275878906
Batch 47/64 loss: -1.6981525421142578
Batch 48/64 loss: -1.9696311950683594
Batch 49/64 loss: -1.673802375793457
Batch 50/64 loss: -2.0260543823242188
Batch 51/64 loss: -2.2594614028930664
Batch 52/64 loss: -1.968226432800293
Batch 53/64 loss: -2.3342714309692383
Batch 54/64 loss: -1.8090238571166992
Batch 55/64 loss: -2.2588930130004883
Batch 56/64 loss: -2.188876152038574
Batch 57/64 loss: -2.277830123901367
Batch 58/64 loss: -2.266246795654297
Batch 59/64 loss: -2.1732654571533203
Batch 60/64 loss: -1.9985408782958984
Batch 61/64 loss: -1.9821977615356445
Batch 62/64 loss: -2.1788177490234375
Batch 63/64 loss: -2.2510910034179688
Batch 64/64 loss: -6.544079780578613
Epoch 96  Train loss: -2.1249390508614336  Val loss: -2.2622824862240924
Epoch 97
-------------------------------
Batch 1/64 loss: -2.207324981689453
Batch 2/64 loss: -1.7790775299072266
Batch 3/64 loss: -2.051877021789551
Batch 4/64 loss: -2.145235061645508
Batch 5/64 loss: -2.101461410522461
Batch 6/64 loss: -2.0749521255493164
Batch 7/64 loss: -2.297642707824707
Batch 8/64 loss: -2.18418025970459
Batch 9/64 loss: -2.1131362915039062
Batch 10/64 loss: -1.8452835083007812
Batch 11/64 loss: -1.9650659561157227
Batch 12/64 loss: -2.2499189376831055
Batch 13/64 loss: -2.1680736541748047
Batch 14/64 loss: -2.2955265045166016
Batch 15/64 loss: -2.1550989151000977
Batch 16/64 loss: -2.260364532470703
Batch 17/64 loss: -2.3075523376464844
Batch 18/64 loss: -1.7691335678100586
Batch 19/64 loss: -1.799947738647461
Batch 20/64 loss: -2.066187858581543
Batch 21/64 loss: -2.0784683227539062
Batch 22/64 loss: -1.8918838500976562
Batch 23/64 loss: -2.3365097045898438
Batch 24/64 loss: -2.2872915267944336
Batch 25/64 loss: -2.064608573913574
Batch 26/64 loss: -1.9400339126586914
Batch 27/64 loss: -2.038374900817871
Batch 28/64 loss: -1.7053098678588867
Batch 29/64 loss: -2.163745880126953
Batch 30/64 loss: -2.3556137084960938
Batch 31/64 loss: -2.377300262451172
Batch 32/64 loss: -2.0788116455078125
Batch 33/64 loss: -2.2023611068725586
Batch 34/64 loss: -2.0377397537231445
Batch 35/64 loss: -1.6339359283447266
Batch 36/64 loss: -2.069575309753418
Batch 37/64 loss: -1.7782812118530273
Batch 38/64 loss: -2.178712844848633
Batch 39/64 loss: -1.9748926162719727
Batch 40/64 loss: -2.1412181854248047
Batch 41/64 loss: -2.392608642578125
Batch 42/64 loss: -2.221865653991699
Batch 43/64 loss: -2.1956348419189453
Batch 44/64 loss: -2.030393600463867
Batch 45/64 loss: -2.182741165161133
Batch 46/64 loss: -2.028860092163086
Batch 47/64 loss: -1.8292961120605469
Batch 48/64 loss: -1.63665771484375
Batch 49/64 loss: -2.240830421447754
Batch 50/64 loss: -1.8816461563110352
Batch 51/64 loss: -1.903665542602539
Batch 52/64 loss: -2.099055290222168
Batch 53/64 loss: -2.154595375061035
Batch 54/64 loss: -1.683053970336914
Batch 55/64 loss: -1.980961799621582
Batch 56/64 loss: -2.064329147338867
Batch 57/64 loss: -1.9080467224121094
Batch 58/64 loss: -2.098443031311035
Batch 59/64 loss: -1.982879638671875
Batch 60/64 loss: -1.8382768630981445
Batch 61/64 loss: -1.8182201385498047
Batch 62/64 loss: -1.884749412536621
Batch 63/64 loss: -2.2781448364257812
Batch 64/64 loss: -6.620072841644287
Epoch 97  Train loss: -2.109360326505175  Val loss: -2.2490938455378475
Epoch 98
-------------------------------
Batch 1/64 loss: -1.7997541427612305
Batch 2/64 loss: -1.6567096710205078
Batch 3/64 loss: -2.0077428817749023
Batch 4/64 loss: -2.3709821701049805
Batch 5/64 loss: -2.2328567504882812
Batch 6/64 loss: -2.19821834564209
Batch 7/64 loss: -2.149458885192871
Batch 8/64 loss: -2.282106399536133
Batch 9/64 loss: -1.5623512268066406
Batch 10/64 loss: -1.9206504821777344
Batch 11/64 loss: -1.793574333190918
Batch 12/64 loss: -2.3080759048461914
Batch 13/64 loss: -2.0479631423950195
Batch 14/64 loss: -1.8460311889648438
Batch 15/64 loss: -2.041825294494629
Batch 16/64 loss: -1.9946584701538086
Batch 17/64 loss: -2.3049583435058594
Batch 18/64 loss: -1.5687780380249023
Batch 19/64 loss: -2.343630790710449
Batch 20/64 loss: -1.553518295288086
Batch 21/64 loss: -2.2431640625
Batch 22/64 loss: -2.0546693801879883
Batch 23/64 loss: -1.9384689331054688
Batch 24/64 loss: -2.0752134323120117
Batch 25/64 loss: -2.0425643920898438
Batch 26/64 loss: -2.0434770584106445
Batch 27/64 loss: -2.042470932006836
Batch 28/64 loss: -1.7480173110961914
Batch 29/64 loss: -2.347304344177246
Batch 30/64 loss: -1.7768440246582031
Batch 31/64 loss: -1.9410266876220703
Batch 32/64 loss: -2.2937164306640625
Batch 33/64 loss: -1.9254035949707031
Batch 34/64 loss: -1.7047157287597656
Batch 35/64 loss: -2.102153778076172
Batch 36/64 loss: -2.1318235397338867
Batch 37/64 loss: -2.1101913452148438
Batch 38/64 loss: -2.2202634811401367
Batch 39/64 loss: -2.183018684387207
Batch 40/64 loss: -2.1007213592529297
Batch 41/64 loss: -2.2847747802734375
Batch 42/64 loss: -1.8763275146484375
Batch 43/64 loss: -1.6468925476074219
Batch 44/64 loss: -1.7730321884155273
Batch 45/64 loss: -2.2155628204345703
Batch 46/64 loss: -1.8090105056762695
Batch 47/64 loss: -2.0777816772460938
Batch 48/64 loss: -2.3577070236206055
Batch 49/64 loss: -2.2760562896728516
Batch 50/64 loss: -2.278201103210449
Batch 51/64 loss: -2.275026321411133
Batch 52/64 loss: -2.308473587036133
Batch 53/64 loss: -2.1980552673339844
Batch 54/64 loss: -2.0433273315429688
Batch 55/64 loss: -2.4707679748535156
Batch 56/64 loss: -2.240044593811035
Batch 57/64 loss: -2.220203399658203
Batch 58/64 loss: -2.2466888427734375
Batch 59/64 loss: -1.815922737121582
Batch 60/64 loss: -2.032695770263672
Batch 61/64 loss: -2.252634048461914
Batch 62/64 loss: -1.801487922668457
Batch 63/64 loss: -1.9870758056640625
Batch 64/64 loss: -6.4674072265625
Epoch 98  Train loss: -2.1074098624435127  Val loss: -2.3802639282855793
Saving best model, epoch: 98
Epoch 99
-------------------------------
Batch 1/64 loss: -2.233096122741699
Batch 2/64 loss: -2.2210588455200195
Batch 3/64 loss: -1.9693336486816406
Batch 4/64 loss: -2.077559471130371
Batch 5/64 loss: -2.2122631072998047
Batch 6/64 loss: -1.680527687072754
Batch 7/64 loss: -2.1387128829956055
Batch 8/64 loss: -2.3433876037597656
Batch 9/64 loss: -1.946589469909668
Batch 10/64 loss: -1.9713201522827148
Batch 11/64 loss: -2.207526206970215
Batch 12/64 loss: -2.4118919372558594
Batch 13/64 loss: -2.264204978942871
Batch 14/64 loss: -2.250753402709961
Batch 15/64 loss: -2.1085453033447266
Batch 16/64 loss: -2.0358428955078125
Batch 17/64 loss: -2.235419273376465
Batch 18/64 loss: -1.7808246612548828
Batch 19/64 loss: -2.067416191101074
Batch 20/64 loss: -2.3331422805786133
Batch 21/64 loss: -2.400650978088379
Batch 22/64 loss: -2.0044307708740234
Batch 23/64 loss: -2.0924787521362305
Batch 24/64 loss: -1.7767534255981445
Batch 25/64 loss: -2.0191917419433594
Batch 26/64 loss: -1.9480905532836914
Batch 27/64 loss: -2.2567644119262695
Batch 28/64 loss: -1.6079702377319336
Batch 29/64 loss: -1.7076139450073242
Batch 30/64 loss: -2.135021209716797
Batch 31/64 loss: -2.1018753051757812
Batch 32/64 loss: -1.6859445571899414
Batch 33/64 loss: -2.4791412353515625
Batch 34/64 loss: -1.9126405715942383
Batch 35/64 loss: -1.9686508178710938
Batch 36/64 loss: -2.3407459259033203
Batch 37/64 loss: -2.2819557189941406
Batch 38/64 loss: -2.1060791015625
Batch 39/64 loss: -1.9422082901000977
Batch 40/64 loss: -2.3880577087402344
Batch 41/64 loss: -1.8443422317504883
Batch 42/64 loss: -2.0181312561035156
Batch 43/64 loss: -2.255599021911621
Batch 44/64 loss: -1.8602876663208008
Batch 45/64 loss: -2.2703800201416016
Batch 46/64 loss: -2.2384824752807617
Batch 47/64 loss: -2.282154083251953
Batch 48/64 loss: -1.929579734802246
Batch 49/64 loss: -2.172032356262207
Batch 50/64 loss: -2.0528125762939453
Batch 51/64 loss: -2.092517852783203
Batch 52/64 loss: -1.6212387084960938
Batch 53/64 loss: -2.341254234313965
Batch 54/64 loss: -2.0476837158203125
Batch 55/64 loss: -2.2110910415649414
Batch 56/64 loss: -1.6530895233154297
Batch 57/64 loss: -1.9458389282226562
Batch 58/64 loss: -2.2888641357421875
Batch 59/64 loss: -2.0879554748535156
Batch 60/64 loss: -1.9878606796264648
Batch 61/64 loss: -2.0873031616210938
Batch 62/64 loss: -1.8219690322875977
Batch 63/64 loss: -2.23004150390625
Batch 64/64 loss: -6.404021739959717
Epoch 99  Train loss: -2.130026778052835  Val loss: -2.3529147249726496
Epoch 100
-------------------------------
Batch 1/64 loss: -2.2367382049560547
Batch 2/64 loss: -2.1261301040649414
Batch 3/64 loss: -2.122830390930176
Batch 4/64 loss: -1.5709724426269531
Batch 5/64 loss: -2.1443300247192383
Batch 6/64 loss: -1.92523193359375
Batch 7/64 loss: -2.2773265838623047
Batch 8/64 loss: -2.306549072265625
Batch 9/64 loss: -1.862466812133789
Batch 10/64 loss: -2.272153854370117
Batch 11/64 loss: -2.2996301651000977
Batch 12/64 loss: -1.685673713684082
Batch 13/64 loss: -2.4068212509155273
Batch 14/64 loss: -2.1456966400146484
Batch 15/64 loss: -1.947117805480957
Batch 16/64 loss: -2.144272804260254
Batch 17/64 loss: -1.9703350067138672
Batch 18/64 loss: -1.9397974014282227
Batch 19/64 loss: -1.6601581573486328
Batch 20/64 loss: -1.598750114440918
Batch 21/64 loss: -2.332882881164551
Batch 22/64 loss: -2.152872085571289
Batch 23/64 loss: -2.0957298278808594
Batch 24/64 loss: -2.164712905883789
Batch 25/64 loss: -2.204787254333496
Batch 26/64 loss: -2.141909599304199
Batch 27/64 loss: -1.7865543365478516
Batch 28/64 loss: -1.958958625793457
Batch 29/64 loss: -2.123101234436035
Batch 30/64 loss: -2.1687679290771484
Batch 31/64 loss: -2.258707046508789
Batch 32/64 loss: -1.9463615417480469
Batch 33/64 loss: -1.7363033294677734
Batch 34/64 loss: -2.0882701873779297
Batch 35/64 loss: -1.9447298049926758
Batch 36/64 loss: -2.0209598541259766
Batch 37/64 loss: -2.0463695526123047
Batch 38/64 loss: -1.519784927368164
Batch 39/64 loss: -2.195502281188965
Batch 40/64 loss: -2.294589042663574
Batch 41/64 loss: -2.0972557067871094
Batch 42/64 loss: -2.3747148513793945
Batch 43/64 loss: -2.1351747512817383
Batch 44/64 loss: -2.281435966491699
Batch 45/64 loss: -2.3068933486938477
Batch 46/64 loss: -2.2934160232543945
Batch 47/64 loss: -2.1106948852539062
Batch 48/64 loss: -2.093626022338867
Batch 49/64 loss: -1.4993562698364258
Batch 50/64 loss: -1.9843387603759766
Batch 51/64 loss: -1.9510173797607422
Batch 52/64 loss: -2.2488231658935547
Batch 53/64 loss: -2.1020727157592773
Batch 54/64 loss: -2.5294580459594727
Batch 55/64 loss: -1.8653678894042969
Batch 56/64 loss: -1.9673118591308594
Batch 57/64 loss: -2.168546676635742
Batch 58/64 loss: -2.369563102722168
Batch 59/64 loss: -2.360884666442871
Batch 60/64 loss: -2.2738990783691406
Batch 61/64 loss: -2.2513303756713867
Batch 62/64 loss: -2.2413644790649414
Batch 63/64 loss: -1.8336143493652344
Batch 64/64 loss: -6.771538257598877
Epoch 100  Train loss: -2.137155306573008  Val loss: -2.3622548604748914
Epoch 101
-------------------------------
Batch 1/64 loss: -2.3122386932373047
Batch 2/64 loss: -1.9729156494140625
Batch 3/64 loss: -1.6275129318237305
Batch 4/64 loss: -2.151618003845215
Batch 5/64 loss: -2.218926429748535
Batch 6/64 loss: -2.118350028991699
Batch 7/64 loss: -2.0426740646362305
Batch 8/64 loss: -2.4327869415283203
Batch 9/64 loss: -2.3272247314453125
Batch 10/64 loss: -2.107121467590332
Batch 11/64 loss: -2.146735191345215
Batch 12/64 loss: -1.9964017868041992
Batch 13/64 loss: -2.248758316040039
Batch 14/64 loss: -1.8209419250488281
Batch 15/64 loss: -2.2463626861572266
Batch 16/64 loss: -2.264772415161133
Batch 17/64 loss: -2.3163671493530273
Batch 18/64 loss: -2.196086883544922
Batch 19/64 loss: -2.1434459686279297
Batch 20/64 loss: -2.378438949584961
Batch 21/64 loss: -1.6483259201049805
Batch 22/64 loss: -2.1989240646362305
Batch 23/64 loss: -2.2531423568725586
Batch 24/64 loss: -2.1299619674682617
Batch 25/64 loss: -2.0767459869384766
Batch 26/64 loss: -2.261115074157715
Batch 27/64 loss: -2.2455081939697266
Batch 28/64 loss: -2.170642852783203
Batch 29/64 loss: -2.3704700469970703
Batch 30/64 loss: -2.229024887084961
Batch 31/64 loss: -1.9673185348510742
Batch 32/64 loss: -2.227306365966797
Batch 33/64 loss: -1.6700658798217773
Batch 34/64 loss: -1.919189453125
Batch 35/64 loss: -2.262070655822754
Batch 36/64 loss: -2.0039663314819336
Batch 37/64 loss: -2.0140295028686523
Batch 38/64 loss: -2.00588321685791
Batch 39/64 loss: -2.032710075378418
Batch 40/64 loss: -1.8442583084106445
Batch 41/64 loss: -1.9513006210327148
Batch 42/64 loss: -1.0789833068847656
Batch 43/64 loss: -2.2604732513427734
Batch 44/64 loss: -2.054920196533203
Batch 45/64 loss: -1.6812782287597656
Batch 46/64 loss: -2.2381105422973633
Batch 47/64 loss: -2.2393836975097656
Batch 48/64 loss: -1.8186044692993164
Batch 49/64 loss: -1.815481185913086
Batch 50/64 loss: -2.3379392623901367
Batch 51/64 loss: -2.536623001098633
Batch 52/64 loss: -2.1684303283691406
Batch 53/64 loss: -2.501363754272461
Batch 54/64 loss: -1.8680286407470703
Batch 55/64 loss: -2.2176074981689453
Batch 56/64 loss: -2.38671875
Batch 57/64 loss: -2.307931900024414
Batch 58/64 loss: -2.2275476455688477
Batch 59/64 loss: -2.137176513671875
Batch 60/64 loss: -2.2234277725219727
Batch 61/64 loss: -2.1463499069213867
Batch 62/64 loss: -2.348562240600586
Batch 63/64 loss: -2.1168928146362305
Batch 64/64 loss: -6.600247859954834
Epoch 101  Train loss: -2.1680574323616777  Val loss: -2.318785821449306
Epoch 102
-------------------------------
Batch 1/64 loss: -2.2533884048461914
Batch 2/64 loss: -2.0090465545654297
Batch 3/64 loss: -2.1013784408569336
Batch 4/64 loss: -2.294053077697754
Batch 5/64 loss: -2.1576976776123047
Batch 6/64 loss: -2.152398109436035
Batch 7/64 loss: -2.4617958068847656
Batch 8/64 loss: -2.30926513671875
Batch 9/64 loss: -2.091000556945801
Batch 10/64 loss: -2.1282997131347656
Batch 11/64 loss: -2.3239622116088867
Batch 12/64 loss: -2.1937332153320312
Batch 13/64 loss: -2.2671003341674805
Batch 14/64 loss: -1.9646663665771484
Batch 15/64 loss: -1.6216936111450195
Batch 16/64 loss: -2.257288932800293
Batch 17/64 loss: -2.394413948059082
Batch 18/64 loss: -2.0615806579589844
Batch 19/64 loss: -2.218766212463379
Batch 20/64 loss: -2.0435781478881836
Batch 21/64 loss: -1.8950738906860352
Batch 22/64 loss: -2.203680992126465
Batch 23/64 loss: -2.0199947357177734
Batch 24/64 loss: -1.9733686447143555
Batch 25/64 loss: -1.5480451583862305
Batch 26/64 loss: -2.2585153579711914
Batch 27/64 loss: -1.5204095840454102
Batch 28/64 loss: -2.2209224700927734
Batch 29/64 loss: -2.192885398864746
Batch 30/64 loss: -2.0654592514038086
Batch 31/64 loss: -2.1136350631713867
Batch 32/64 loss: -2.42080020904541
Batch 33/64 loss: -2.310344696044922
Batch 34/64 loss: -2.112490653991699
Batch 35/64 loss: -2.3227767944335938
Batch 36/64 loss: -1.7064695358276367
Batch 37/64 loss: -2.201295852661133
Batch 38/64 loss: -2.220073699951172
Batch 39/64 loss: -2.0766191482543945
Batch 40/64 loss: -2.05422306060791
Batch 41/64 loss: -2.2490224838256836
Batch 42/64 loss: -2.4037389755249023
Batch 43/64 loss: -2.006235122680664
Batch 44/64 loss: -1.6319599151611328
Batch 45/64 loss: -2.104363441467285
Batch 46/64 loss: -2.1064071655273438
Batch 47/64 loss: -2.3782119750976562
Batch 48/64 loss: -2.31272029876709
Batch 49/64 loss: -1.8822317123413086
Batch 50/64 loss: -2.1170129776000977
Batch 51/64 loss: -2.297100067138672
Batch 52/64 loss: -2.466273307800293
Batch 53/64 loss: -1.8909215927124023
Batch 54/64 loss: -2.1311864852905273
Batch 55/64 loss: -2.223134994506836
Batch 56/64 loss: -1.264434814453125
Batch 57/64 loss: -2.2236223220825195
Batch 58/64 loss: -1.9726390838623047
Batch 59/64 loss: -2.242520332336426
Batch 60/64 loss: -2.292837142944336
Batch 61/64 loss: -2.298460006713867
Batch 62/64 loss: -2.174248695373535
Batch 63/64 loss: -1.8708972930908203
Batch 64/64 loss: -5.742741584777832
Epoch 102  Train loss: -2.1582655326992857  Val loss: -2.2485898991221007
Epoch 103
-------------------------------
Batch 1/64 loss: -1.884425163269043
Batch 2/64 loss: -2.185131072998047
Batch 3/64 loss: -2.2926502227783203
Batch 4/64 loss: -2.3416738510131836
Batch 5/64 loss: -2.0276708602905273
Batch 6/64 loss: -2.163297653198242
Batch 7/64 loss: -2.2391586303710938
Batch 8/64 loss: -1.7234954833984375
Batch 9/64 loss: -2.232147216796875
Batch 10/64 loss: -2.0429811477661133
Batch 11/64 loss: -2.465768814086914
Batch 12/64 loss: -2.2035036087036133
Batch 13/64 loss: -2.292621612548828
Batch 14/64 loss: -2.20883846282959
Batch 15/64 loss: -2.5374441146850586
Batch 16/64 loss: -2.0261659622192383
Batch 17/64 loss: -1.850332260131836
Batch 18/64 loss: -2.2377090454101562
Batch 19/64 loss: -2.080596923828125
Batch 20/64 loss: -2.4054603576660156
Batch 21/64 loss: -2.083211898803711
Batch 22/64 loss: -2.4103469848632812
Batch 23/64 loss: -1.7652006149291992
Batch 24/64 loss: -2.1719141006469727
Batch 25/64 loss: -1.6923179626464844
Batch 26/64 loss: -2.3796558380126953
Batch 27/64 loss: -2.15433406829834
Batch 28/64 loss: -2.397066116333008
Batch 29/64 loss: -2.051095962524414
Batch 30/64 loss: -1.7792739868164062
Batch 31/64 loss: -1.7692956924438477
Batch 32/64 loss: -2.4375362396240234
Batch 33/64 loss: -2.372063636779785
Batch 34/64 loss: -1.0841569900512695
Batch 35/64 loss: -2.0102100372314453
Batch 36/64 loss: -2.4787654876708984
Batch 37/64 loss: -2.2073583602905273
Batch 38/64 loss: -2.1634960174560547
Batch 39/64 loss: -2.144110679626465
Batch 40/64 loss: -1.7892475128173828
Batch 41/64 loss: -2.01470947265625
Batch 42/64 loss: -2.030808448791504
Batch 43/64 loss: -1.8866071701049805
Batch 44/64 loss: -1.8904409408569336
Batch 45/64 loss: -1.9132928848266602
Batch 46/64 loss: -2.32073974609375
Batch 47/64 loss: -1.0037612915039062
Batch 48/64 loss: -2.206671714782715
Batch 49/64 loss: -1.9506950378417969
Batch 50/64 loss: -2.4791603088378906
Batch 51/64 loss: -1.9118680953979492
Batch 52/64 loss: -2.144087791442871
Batch 53/64 loss: -1.5793733596801758
Batch 54/64 loss: -2.233957290649414
Batch 55/64 loss: -1.7904701232910156
Batch 56/64 loss: -2.043787956237793
Batch 57/64 loss: -1.9453840255737305
Batch 58/64 loss: -0.8947277069091797
Batch 59/64 loss: -2.4682254791259766
Batch 60/64 loss: -2.0843915939331055
Batch 61/64 loss: -2.113043785095215
Batch 62/64 loss: -1.886749267578125
Batch 63/64 loss: -2.325566291809082
Batch 64/64 loss: -6.200160503387451
Epoch 103  Train loss: -2.1105940519594677  Val loss: -2.068650065418781
Epoch 104
-------------------------------
Batch 1/64 loss: -2.3078794479370117
Batch 2/64 loss: -2.049372673034668
Batch 3/64 loss: -1.2874479293823242
Batch 4/64 loss: -1.8437747955322266
Batch 5/64 loss: -2.0541276931762695
Batch 6/64 loss: -2.0735549926757812
Batch 7/64 loss: -2.0564651489257812
Batch 8/64 loss: -2.380764961242676
Batch 9/64 loss: -2.1138153076171875
Batch 10/64 loss: -1.6510896682739258
Batch 11/64 loss: -2.21248722076416
Batch 12/64 loss: -2.156757354736328
Batch 13/64 loss: -2.0945348739624023
Batch 14/64 loss: -2.4149646759033203
Batch 15/64 loss: -2.4089221954345703
Batch 16/64 loss: -2.0641860961914062
Batch 17/64 loss: -2.2794933319091797
Batch 18/64 loss: -1.5260820388793945
Batch 19/64 loss: -1.7493581771850586
Batch 20/64 loss: -2.255617141723633
Batch 21/64 loss: -2.310873031616211
Batch 22/64 loss: -2.1356325149536133
Batch 23/64 loss: -1.7872743606567383
Batch 24/64 loss: -2.3037233352661133
Batch 25/64 loss: -2.0850257873535156
Batch 26/64 loss: -1.6312885284423828
Batch 27/64 loss: -2.056936264038086
Batch 28/64 loss: -2.023226737976074
Batch 29/64 loss: -2.3354568481445312
Batch 30/64 loss: -2.2158708572387695
Batch 31/64 loss: -2.0315990447998047
Batch 32/64 loss: -1.4536466598510742
Batch 33/64 loss: -2.3000125885009766
Batch 34/64 loss: -2.2371788024902344
Batch 35/64 loss: -2.343256950378418
Batch 36/64 loss: -2.117964744567871
Batch 37/64 loss: -1.7539176940917969
Batch 38/64 loss: -2.0936689376831055
Batch 39/64 loss: -2.2576074600219727
Batch 40/64 loss: -1.8959846496582031
Batch 41/64 loss: -2.1735963821411133
Batch 42/64 loss: -1.4696073532104492
Batch 43/64 loss: -2.34102725982666
Batch 44/64 loss: -2.185666084289551
Batch 45/64 loss: -2.1131553649902344
Batch 46/64 loss: -2.2585277557373047
Batch 47/64 loss: -2.2735595703125
Batch 48/64 loss: -2.0401687622070312
Batch 49/64 loss: -2.322564125061035
Batch 50/64 loss: -1.6619386672973633
Batch 51/64 loss: -2.240077018737793
Batch 52/64 loss: -2.3239221572875977
Batch 53/64 loss: -2.242678642272949
Batch 54/64 loss: -2.4201135635375977
Batch 55/64 loss: -1.7209205627441406
Batch 56/64 loss: -1.7447023391723633
Batch 57/64 loss: -1.0591764450073242
Batch 58/64 loss: -1.892909049987793
Batch 59/64 loss: -2.001307487487793
Batch 60/64 loss: -2.3505659103393555
Batch 61/64 loss: -2.1325864791870117
Batch 62/64 loss: -2.0043325424194336
Batch 63/64 loss: -2.2994308471679688
Batch 64/64 loss: -6.478516101837158
Epoch 104  Train loss: -2.1095256936316398  Val loss: -2.197347372258242
Epoch 105
-------------------------------
Batch 1/64 loss: -1.9008541107177734
Batch 2/64 loss: -1.6928482055664062
Batch 3/64 loss: -2.2875795364379883
Batch 4/64 loss: -2.3077545166015625
Batch 5/64 loss: -1.9272193908691406
Batch 6/64 loss: -2.179337501525879
Batch 7/64 loss: -2.029547691345215
Batch 8/64 loss: -1.9189558029174805
Batch 9/64 loss: -2.2489871978759766
Batch 10/64 loss: -2.229161262512207
Batch 11/64 loss: -1.5911083221435547
Batch 12/64 loss: -1.9930458068847656
Batch 13/64 loss: -2.2921056747436523
Batch 14/64 loss: -1.5915861129760742
Batch 15/64 loss: -2.346170425415039
Batch 16/64 loss: -2.210773468017578
Batch 17/64 loss: -2.378305435180664
Batch 18/64 loss: -2.2258100509643555
Batch 19/64 loss: -2.085784912109375
Batch 20/64 loss: -2.1007614135742188
Batch 21/64 loss: -2.2763729095458984
Batch 22/64 loss: -2.2033300399780273
Batch 23/64 loss: -1.9442672729492188
Batch 24/64 loss: -2.3608169555664062
Batch 25/64 loss: -2.1187210083007812
Batch 26/64 loss: -2.1340560913085938
Batch 27/64 loss: -2.364302635192871
Batch 28/64 loss: -2.3884029388427734
Batch 29/64 loss: -2.0777196884155273
Batch 30/64 loss: -2.2999267578125
Batch 31/64 loss: -2.1888904571533203
Batch 32/64 loss: -2.1885786056518555
Batch 33/64 loss: -2.1573562622070312
Batch 34/64 loss: -2.316716194152832
Batch 35/64 loss: -2.31143856048584
Batch 36/64 loss: -2.037118911743164
Batch 37/64 loss: -2.032533645629883
Batch 38/64 loss: -2.171126365661621
Batch 39/64 loss: -2.233295440673828
Batch 40/64 loss: -2.3604774475097656
Batch 41/64 loss: -2.3870067596435547
Batch 42/64 loss: -2.197856903076172
Batch 43/64 loss: -2.0998668670654297
Batch 44/64 loss: -2.016201972961426
Batch 45/64 loss: -2.236849784851074
Batch 46/64 loss: -2.1667957305908203
Batch 47/64 loss: -0.9039392471313477
Batch 48/64 loss: -1.724806785583496
Batch 49/64 loss: -1.9613771438598633
Batch 50/64 loss: -1.9585084915161133
Batch 51/64 loss: -2.2630128860473633
Batch 52/64 loss: -1.817215919494629
Batch 53/64 loss: -1.8821449279785156
Batch 54/64 loss: -2.240753173828125
Batch 55/64 loss: -2.311655044555664
Batch 56/64 loss: -2.1099090576171875
Batch 57/64 loss: -1.5738115310668945
Batch 58/64 loss: -1.9700899124145508
Batch 59/64 loss: -1.6676769256591797
Batch 60/64 loss: -1.7066841125488281
Batch 61/64 loss: -2.147953987121582
Batch 62/64 loss: -1.8485298156738281
Batch 63/64 loss: -1.8898744583129883
Batch 64/64 loss: -6.612727165222168
Epoch 105  Train loss: -2.1293366563086416  Val loss: -2.147979447931768
Epoch 106
-------------------------------
Batch 1/64 loss: -2.04268741607666
Batch 2/64 loss: -2.2415943145751953
Batch 3/64 loss: -2.3958139419555664
Batch 4/64 loss: -2.034440040588379
Batch 5/64 loss: -2.1231746673583984
Batch 6/64 loss: -1.8370323181152344
Batch 7/64 loss: -2.3507509231567383
Batch 8/64 loss: -1.7622747421264648
Batch 9/64 loss: -2.083932876586914
Batch 10/64 loss: -2.146190643310547
Batch 11/64 loss: -1.8164911270141602
Batch 12/64 loss: -2.386385917663574
Batch 13/64 loss: -2.0787105560302734
Batch 14/64 loss: -2.0307979583740234
Batch 15/64 loss: -2.2849817276000977
Batch 16/64 loss: -2.0748023986816406
Batch 17/64 loss: -2.175234794616699
Batch 18/64 loss: -2.056698799133301
Batch 19/64 loss: -1.879979133605957
Batch 20/64 loss: -1.9607067108154297
Batch 21/64 loss: -2.1046714782714844
Batch 22/64 loss: -1.9274072647094727
Batch 23/64 loss: -1.9234342575073242
Batch 24/64 loss: -2.1313905715942383
Batch 25/64 loss: -2.263639450073242
Batch 26/64 loss: -2.329235076904297
Batch 27/64 loss: -2.172125816345215
Batch 28/64 loss: -1.919489860534668
Batch 29/64 loss: -2.232426643371582
Batch 30/64 loss: -2.366185188293457
Batch 31/64 loss: -1.7989988327026367
Batch 32/64 loss: -1.7346620559692383
Batch 33/64 loss: -1.4811420440673828
Batch 34/64 loss: -2.0005855560302734
Batch 35/64 loss: -2.4505367279052734
Batch 36/64 loss: -2.564682960510254
Batch 37/64 loss: -1.7394514083862305
Batch 38/64 loss: -2.0834312438964844
Batch 39/64 loss: -2.3392791748046875
Batch 40/64 loss: -2.1932859420776367
Batch 41/64 loss: -1.4798479080200195
Batch 42/64 loss: -2.1429481506347656
Batch 43/64 loss: -1.6101350784301758
Batch 44/64 loss: -1.9552001953125
Batch 45/64 loss: -1.9778995513916016
Batch 46/64 loss: -2.068025588989258
Batch 47/64 loss: -2.030228614807129
Batch 48/64 loss: -2.1259765625
Batch 49/64 loss: -2.378392219543457
Batch 50/64 loss: -2.1038923263549805
Batch 51/64 loss: -1.6628150939941406
Batch 52/64 loss: -1.7134342193603516
Batch 53/64 loss: -2.034353256225586
Batch 54/64 loss: -1.8308601379394531
Batch 55/64 loss: -2.1782360076904297
Batch 56/64 loss: -2.1625871658325195
Batch 57/64 loss: -1.923360824584961
Batch 58/64 loss: -2.2395496368408203
Batch 59/64 loss: -2.1196327209472656
Batch 60/64 loss: -1.565241813659668
Batch 61/64 loss: -2.5969972610473633
Batch 62/64 loss: -0.43462181091308594
Batch 63/64 loss: -1.907567024230957
Batch 64/64 loss: -6.4877119064331055
Epoch 106  Train loss: -2.0804130142810298  Val loss: -2.1336781085561642
Epoch 107
-------------------------------
Batch 1/64 loss: -1.9383363723754883
Batch 2/64 loss: -2.0617666244506836
Batch 3/64 loss: -2.042692184448242
Batch 4/64 loss: -1.4368867874145508
Batch 5/64 loss: -2.0792741775512695
Batch 6/64 loss: -1.9346113204956055
Batch 7/64 loss: -1.7589139938354492
Batch 8/64 loss: -1.8644952774047852
Batch 9/64 loss: -1.0829343795776367
Batch 10/64 loss: -2.057161331176758
Batch 11/64 loss: -2.0375146865844727
Batch 12/64 loss: -2.270193099975586
Batch 13/64 loss: -2.2201356887817383
Batch 14/64 loss: -1.9570350646972656
Batch 15/64 loss: -2.3635902404785156
Batch 16/64 loss: -2.1766767501831055
Batch 17/64 loss: -2.1534738540649414
Batch 18/64 loss: -2.364490509033203
Batch 19/64 loss: -1.6104803085327148
Batch 20/64 loss: -2.184232711791992
Batch 21/64 loss: -1.550161361694336
Batch 22/64 loss: -2.4424495697021484
Batch 23/64 loss: -1.8962278366088867
Batch 24/64 loss: -1.4492969512939453
Batch 25/64 loss: -1.8458099365234375
Batch 26/64 loss: -1.684678077697754
Batch 27/64 loss: -2.3725996017456055
Batch 28/64 loss: -1.438711166381836
Batch 29/64 loss: -2.256450653076172
Batch 30/64 loss: -1.844660758972168
Batch 31/64 loss: -1.9142284393310547
Batch 32/64 loss: -2.177143096923828
Batch 33/64 loss: -2.120772361755371
Batch 34/64 loss: -2.1644887924194336
Batch 35/64 loss: -0.9891996383666992
Batch 36/64 loss: -1.8375720977783203
Batch 37/64 loss: -1.6464729309082031
Batch 38/64 loss: -1.1221561431884766
Batch 39/64 loss: -1.798126220703125
Batch 40/64 loss: -2.2049970626831055
Batch 41/64 loss: -1.279642105102539
Batch 42/64 loss: -2.0172271728515625
Batch 43/64 loss: -1.3909215927124023
Batch 44/64 loss: -2.026876449584961
Batch 45/64 loss: -1.9352350234985352
Batch 46/64 loss: -1.962911605834961
Batch 47/64 loss: -1.6745052337646484
Batch 48/64 loss: -2.1729869842529297
Batch 49/64 loss: -1.915985107421875
Batch 50/64 loss: -2.108139991760254
Batch 51/64 loss: -1.7643146514892578
Batch 52/64 loss: -1.522989273071289
Batch 53/64 loss: -1.6255407333374023
Batch 54/64 loss: -2.1593217849731445
Batch 55/64 loss: -1.948716163635254
Batch 56/64 loss: -2.408370018005371
Batch 57/64 loss: -1.8458061218261719
Batch 58/64 loss: -1.0920028686523438
Batch 59/64 loss: -1.6062698364257812
Batch 60/64 loss: -1.5225963592529297
Batch 61/64 loss: -2.0545387268066406
Batch 62/64 loss: -1.9816179275512695
Batch 63/64 loss: -1.6937799453735352
Batch 64/64 loss: -6.749687194824219
Epoch 107  Train loss: -1.931351515826057  Val loss: -1.9600759027749812
Epoch 108
-------------------------------
Batch 1/64 loss: -1.8667678833007812
Batch 2/64 loss: -2.1313581466674805
Batch 3/64 loss: -1.7906208038330078
Batch 4/64 loss: -2.117521286010742
Batch 5/64 loss: -1.3356208801269531
Batch 6/64 loss: -2.0531930923461914
Batch 7/64 loss: -1.811720848083496
Batch 8/64 loss: -2.0631608963012695
Batch 9/64 loss: -1.9068174362182617
Batch 10/64 loss: -1.957383155822754
Batch 11/64 loss: -2.2105369567871094
Batch 12/64 loss: -2.315370559692383
Batch 13/64 loss: -1.8509025573730469
Batch 14/64 loss: -2.079092025756836
Batch 15/64 loss: -1.526026725769043
Batch 16/64 loss: -2.173799514770508
Batch 17/64 loss: -1.0881156921386719
Batch 18/64 loss: -2.2561702728271484
Batch 19/64 loss: -2.210969924926758
Batch 20/64 loss: -2.1460866928100586
Batch 21/64 loss: -2.236363410949707
Batch 22/64 loss: -2.2340431213378906
Batch 23/64 loss: -2.3936071395874023
Batch 24/64 loss: -2.072026252746582
Batch 25/64 loss: -2.321880340576172
Batch 26/64 loss: -1.985443115234375
Batch 27/64 loss: -2.083512306213379
Batch 28/64 loss: -1.731642723083496
Batch 29/64 loss: -2.2612342834472656
Batch 30/64 loss: -2.1326732635498047
Batch 31/64 loss: -1.231705665588379
Batch 32/64 loss: -1.677865982055664
Batch 33/64 loss: -2.5138063430786133
Batch 34/64 loss: -1.0864410400390625
Batch 35/64 loss: -2.1132965087890625
Batch 36/64 loss: -2.101655960083008
Batch 37/64 loss: -1.9348907470703125
Batch 38/64 loss: -1.9098730087280273
Batch 39/64 loss: -1.9197368621826172
Batch 40/64 loss: -2.024087905883789
Batch 41/64 loss: -2.1264524459838867
Batch 42/64 loss: -2.1919727325439453
Batch 43/64 loss: -1.6535720825195312
Batch 44/64 loss: -1.3929338455200195
Batch 45/64 loss: -1.8952903747558594
Batch 46/64 loss: -1.1314353942871094
Batch 47/64 loss: -2.057300567626953
Batch 48/64 loss: -2.1097793579101562
Batch 49/64 loss: -2.021235466003418
Batch 50/64 loss: -1.7472000122070312
Batch 51/64 loss: -2.015697479248047
Batch 52/64 loss: -2.218820571899414
Batch 53/64 loss: -1.8404197692871094
Batch 54/64 loss: -1.9370574951171875
Batch 55/64 loss: -2.1743087768554688
Batch 56/64 loss: -1.796940803527832
Batch 57/64 loss: -1.475569725036621
Batch 58/64 loss: -1.6955089569091797
Batch 59/64 loss: -2.130988121032715
Batch 60/64 loss: -2.0780115127563477
Batch 61/64 loss: -2.2812232971191406
Batch 62/64 loss: -2.161693572998047
Batch 63/64 loss: -1.7398881912231445
Batch 64/64 loss: -6.579020977020264
Epoch 108  Train loss: -2.002581766539929  Val loss: -1.9263510294386612
Epoch 109
-------------------------------
Batch 1/64 loss: -1.2608833312988281
Batch 2/64 loss: -1.5874872207641602
Batch 3/64 loss: -1.933140754699707
Batch 4/64 loss: -2.1052350997924805
Batch 5/64 loss: -1.6162405014038086
Batch 6/64 loss: -1.9501113891601562
Batch 7/64 loss: -1.7942619323730469
Batch 8/64 loss: -1.9497909545898438
Batch 9/64 loss: -1.7227067947387695
Batch 10/64 loss: -2.3357009887695312
Batch 11/64 loss: -2.3201303482055664
Batch 12/64 loss: -2.3000364303588867
Batch 13/64 loss: -1.9136285781860352
Batch 14/64 loss: -2.1066055297851562
Batch 15/64 loss: -2.2053308486938477
Batch 16/64 loss: -2.1852731704711914
Batch 17/64 loss: -1.7823114395141602
Batch 18/64 loss: -1.8857059478759766
Batch 19/64 loss: -2.1196975708007812
Batch 20/64 loss: -2.1401424407958984
Batch 21/64 loss: -2.1488304138183594
Batch 22/64 loss: -1.996312141418457
Batch 23/64 loss: -1.1419563293457031
Batch 24/64 loss: -2.084721565246582
Batch 25/64 loss: -1.9356498718261719
Batch 26/64 loss: -2.0964508056640625
Batch 27/64 loss: -2.1990346908569336
Batch 28/64 loss: -2.101329803466797
Batch 29/64 loss: -1.8530921936035156
Batch 30/64 loss: -2.134331703186035
Batch 31/64 loss: -1.8275108337402344
Batch 32/64 loss: -1.7580699920654297
Batch 33/64 loss: -2.370431900024414
Batch 34/64 loss: -1.9476661682128906
Batch 35/64 loss: -2.153994560241699
Batch 36/64 loss: -1.8140249252319336
Batch 37/64 loss: -2.219332695007324
Batch 38/64 loss: -1.1557588577270508
Batch 39/64 loss: -1.787759780883789
Batch 40/64 loss: -1.844517707824707
Batch 41/64 loss: -2.1717348098754883
Batch 42/64 loss: -1.9411506652832031
Batch 43/64 loss: -1.9863462448120117
Batch 44/64 loss: -1.730752944946289
Batch 45/64 loss: -2.1005868911743164
Batch 46/64 loss: -1.8953094482421875
Batch 47/64 loss: -2.2521934509277344
Batch 48/64 loss: -2.1163787841796875
Batch 49/64 loss: -2.057284355163574
Batch 50/64 loss: -2.0757274627685547
Batch 51/64 loss: -2.253512382507324
Batch 52/64 loss: -2.0510740280151367
Batch 53/64 loss: -2.158658981323242
Batch 54/64 loss: -1.863774299621582
Batch 55/64 loss: -2.1416263580322266
Batch 56/64 loss: -2.15933895111084
Batch 57/64 loss: -1.6539440155029297
Batch 58/64 loss: -1.7127580642700195
Batch 59/64 loss: -1.5504531860351562
Batch 60/64 loss: -2.046525001525879
Batch 61/64 loss: -2.029468536376953
Batch 62/64 loss: -1.5759544372558594
Batch 63/64 loss: -1.3670110702514648
Batch 64/64 loss: -6.545452117919922
Epoch 109  Train loss: -2.0013466928519454  Val loss: -2.220022011458669
Epoch 110
-------------------------------
Batch 1/64 loss: -1.8922109603881836
Batch 2/64 loss: -2.140202522277832
Batch 3/64 loss: -2.144412040710449
Batch 4/64 loss: -1.949483871459961
Batch 5/64 loss: -2.2766761779785156
Batch 6/64 loss: -2.292819023132324
Batch 7/64 loss: -2.296844482421875
Batch 8/64 loss: -2.161439895629883
Batch 9/64 loss: -2.113677978515625
Batch 10/64 loss: -1.7993640899658203
Batch 11/64 loss: -1.8967933654785156
Batch 12/64 loss: -1.5710868835449219
Batch 13/64 loss: -2.259563446044922
Batch 14/64 loss: -2.0164575576782227
Batch 15/64 loss: -2.3106212615966797
Batch 16/64 loss: -1.9972105026245117
Batch 17/64 loss: -1.6290912628173828
Batch 18/64 loss: -2.035959243774414
Batch 19/64 loss: -2.287670135498047
Batch 20/64 loss: -2.074544906616211
Batch 21/64 loss: -2.109485626220703
Batch 22/64 loss: -2.009531021118164
Batch 23/64 loss: -2.134892463684082
Batch 24/64 loss: -2.086379051208496
Batch 25/64 loss: -2.2422704696655273
Batch 26/64 loss: -2.1034460067749023
Batch 27/64 loss: -2.2526369094848633
Batch 28/64 loss: -2.3348217010498047
Batch 29/64 loss: -2.1516456604003906
Batch 30/64 loss: -1.3790864944458008
Batch 31/64 loss: -1.3752193450927734
Batch 32/64 loss: -0.22327613830566406
Batch 33/64 loss: -1.9480810165405273
Batch 34/64 loss: -1.7219152450561523
Batch 35/64 loss: -1.850956916809082
Batch 36/64 loss: -2.39434814453125
Batch 37/64 loss: -1.2471208572387695
Batch 38/64 loss: -1.8033628463745117
Batch 39/64 loss: -1.908574104309082
Batch 40/64 loss: -2.2654199600219727
Batch 41/64 loss: -1.9759979248046875
Batch 42/64 loss: -1.7619400024414062
Batch 43/64 loss: -1.5569286346435547
Batch 44/64 loss: -1.5170459747314453
Batch 45/64 loss: -1.6464519500732422
Batch 46/64 loss: -2.2123680114746094
Batch 47/64 loss: -1.8804616928100586
Batch 48/64 loss: -2.192255973815918
Batch 49/64 loss: -2.120511054992676
Batch 50/64 loss: -2.0252370834350586
Batch 51/64 loss: -1.8003501892089844
Batch 52/64 loss: -2.14450740814209
Batch 53/64 loss: -1.9142017364501953
Batch 54/64 loss: -1.7790517807006836
Batch 55/64 loss: -1.0289325714111328
Batch 56/64 loss: -2.2378501892089844
Batch 57/64 loss: -2.2505083084106445
Batch 58/64 loss: -2.0846433639526367
Batch 59/64 loss: -2.105441093444824
Batch 60/64 loss: -2.1156997680664062
Batch 61/64 loss: -2.3159189224243164
Batch 62/64 loss: -1.9182939529418945
Batch 63/64 loss: -2.056056022644043
Batch 64/64 loss: -6.450382232666016
Epoch 110  Train loss: -2.0104633705288757  Val loss: -1.97458032562151
Epoch 111
-------------------------------
Batch 1/64 loss: -2.016664505004883
Batch 2/64 loss: -2.0365591049194336
Batch 3/64 loss: -1.8812541961669922
Batch 4/64 loss: -1.6157646179199219
Batch 5/64 loss: -1.7449588775634766
Batch 6/64 loss: -1.8698101043701172
Batch 7/64 loss: -1.2234249114990234
Batch 8/64 loss: -2.220107078552246
Batch 9/64 loss: -1.7584047317504883
Batch 10/64 loss: -2.424184799194336
Batch 11/64 loss: -1.355412483215332
Batch 12/64 loss: -1.9663276672363281
Batch 13/64 loss: -2.233339309692383
Batch 14/64 loss: -2.06368350982666
Batch 15/64 loss: -0.6667051315307617
Batch 16/64 loss: -2.178955078125
Batch 17/64 loss: -2.0383596420288086
Batch 18/64 loss: -2.019773483276367
Batch 19/64 loss: -1.7397937774658203
Batch 20/64 loss: -2.174384117126465
Batch 21/64 loss: -2.111469268798828
Batch 22/64 loss: -1.8867063522338867
Batch 23/64 loss: -1.9884424209594727
Batch 24/64 loss: -2.1245994567871094
Batch 25/64 loss: -1.69610595703125
Batch 26/64 loss: -2.0353384017944336
Batch 27/64 loss: -1.9168920516967773
Batch 28/64 loss: -2.2543725967407227
Batch 29/64 loss: -1.8477849960327148
Batch 30/64 loss: -1.9733400344848633
Batch 31/64 loss: -2.245819091796875
Batch 32/64 loss: -0.9979352951049805
Batch 33/64 loss: -2.0109872817993164
Batch 34/64 loss: -2.1835575103759766
Batch 35/64 loss: -1.9901914596557617
Batch 36/64 loss: -1.8088226318359375
Batch 37/64 loss: -2.1160888671875
Batch 38/64 loss: -1.3847684860229492
Batch 39/64 loss: -2.154788017272949
Batch 40/64 loss: -1.9534873962402344
Batch 41/64 loss: -2.1328954696655273
Batch 42/64 loss: -2.135066032409668
Batch 43/64 loss: -2.372727394104004
Batch 44/64 loss: -1.0710563659667969
Batch 45/64 loss: -2.1971874237060547
Batch 46/64 loss: -0.39638233184814453
Batch 47/64 loss: -2.3037147521972656
Batch 48/64 loss: -2.299679756164551
Batch 49/64 loss: -1.9071683883666992
Batch 50/64 loss: -2.1290016174316406
Batch 51/64 loss: -2.300633430480957
Batch 52/64 loss: -2.041825294494629
Batch 53/64 loss: -1.9102840423583984
Batch 54/64 loss: -2.214601516723633
Batch 55/64 loss: -1.8175983428955078
Batch 56/64 loss: -2.177907943725586
Batch 57/64 loss: -1.3014135360717773
Batch 58/64 loss: -1.9499950408935547
Batch 59/64 loss: -2.2452621459960938
Batch 60/64 loss: -2.402470588684082
Batch 61/64 loss: -2.046994209289551
Batch 62/64 loss: -2.094226837158203
Batch 63/64 loss: -2.285552978515625
Batch 64/64 loss: -6.508580684661865
Epoch 111  Train loss: -1.9846971867131251  Val loss: -2.218856785305587
Epoch 112
-------------------------------
Batch 1/64 loss: -1.993760108947754
Batch 2/64 loss: -1.7612543106079102
Batch 3/64 loss: -1.6034832000732422
Batch 4/64 loss: -2.0369873046875
Batch 5/64 loss: -1.7353734970092773
Batch 6/64 loss: -2.271784782409668
Batch 7/64 loss: -1.344752311706543
Batch 8/64 loss: -2.166261672973633
Batch 9/64 loss: -2.277218818664551
Batch 10/64 loss: -2.0523557662963867
Batch 11/64 loss: -2.2931413650512695
Batch 12/64 loss: -1.8824539184570312
Batch 13/64 loss: -1.995560646057129
Batch 14/64 loss: -2.409067153930664
Batch 15/64 loss: -2.1449995040893555
Batch 16/64 loss: -2.2522668838500977
Batch 17/64 loss: -1.8179044723510742
Batch 18/64 loss: -2.1824474334716797
Batch 19/64 loss: -1.9282331466674805
Batch 20/64 loss: -2.5001401901245117
Batch 21/64 loss: -2.331742286682129
Batch 22/64 loss: -1.7371788024902344
Batch 23/64 loss: -2.261843681335449
Batch 24/64 loss: -1.8064117431640625
Batch 25/64 loss: -2.063868522644043
Batch 26/64 loss: -2.300684928894043
Batch 27/64 loss: -2.1382360458374023
Batch 28/64 loss: -2.0575342178344727
Batch 29/64 loss: -2.014657974243164
Batch 30/64 loss: -2.293750762939453
Batch 31/64 loss: -2.285097122192383
Batch 32/64 loss: -1.6215667724609375
Batch 33/64 loss: -1.9899959564208984
Batch 34/64 loss: -1.86981201171875
Batch 35/64 loss: -2.0887250900268555
Batch 36/64 loss: -1.749521255493164
Batch 37/64 loss: -1.819380760192871
Batch 38/64 loss: -2.1662025451660156
Batch 39/64 loss: -1.705850601196289
Batch 40/64 loss: -2.2428102493286133
Batch 41/64 loss: -2.2102108001708984
Batch 42/64 loss: -2.254545211791992
Batch 43/64 loss: -2.0487327575683594
Batch 44/64 loss: -1.8706598281860352
Batch 45/64 loss: -2.2860794067382812
Batch 46/64 loss: -2.2578468322753906
Batch 47/64 loss: -2.189971923828125
Batch 48/64 loss: -2.1697750091552734
Batch 49/64 loss: -2.0219783782958984
Batch 50/64 loss: -1.7843017578125
Batch 51/64 loss: -2.2796411514282227
Batch 52/64 loss: -2.261904716491699
Batch 53/64 loss: -1.622633934020996
Batch 54/64 loss: -2.14870548248291
Batch 55/64 loss: -2.075385093688965
Batch 56/64 loss: -2.3505430221557617
Batch 57/64 loss: -1.924692153930664
Batch 58/64 loss: -1.340646743774414
Batch 59/64 loss: -1.5258350372314453
Batch 60/64 loss: -2.2293996810913086
Batch 61/64 loss: -2.1109466552734375
Batch 62/64 loss: -2.264519691467285
Batch 63/64 loss: -2.022669792175293
Batch 64/64 loss: -6.5415143966674805
Epoch 112  Train loss: -2.091797312568216  Val loss: -2.2436004192968415
Epoch 113
-------------------------------
Batch 1/64 loss: -2.4008703231811523
Batch 2/64 loss: -2.2834701538085938
Batch 3/64 loss: -1.8912639617919922
Batch 4/64 loss: -2.0343151092529297
Batch 5/64 loss: -2.2914505004882812
Batch 6/64 loss: -2.0749826431274414
Batch 7/64 loss: -2.2308578491210938
Batch 8/64 loss: -2.23587703704834
Batch 9/64 loss: -2.33929443359375
Batch 10/64 loss: -2.095391273498535
Batch 11/64 loss: -2.4825448989868164
Batch 12/64 loss: -2.2440900802612305
Batch 13/64 loss: -2.13067626953125
Batch 14/64 loss: -2.158273696899414
Batch 15/64 loss: -2.0086421966552734
Batch 16/64 loss: -2.2998199462890625
Batch 17/64 loss: -1.6737995147705078
Batch 18/64 loss: -1.9491777420043945
Batch 19/64 loss: -2.117659568786621
Batch 20/64 loss: -1.7840194702148438
Batch 21/64 loss: -2.1415281295776367
Batch 22/64 loss: -2.3268394470214844
Batch 23/64 loss: -2.3730506896972656
Batch 24/64 loss: -1.5715360641479492
Batch 25/64 loss: -2.1239185333251953
Batch 26/64 loss: -2.370028495788574
Batch 27/64 loss: -1.6129140853881836
Batch 28/64 loss: -1.6574296951293945
Batch 29/64 loss: -2.068972587585449
Batch 30/64 loss: -2.142340660095215
Batch 31/64 loss: -2.2303009033203125
Batch 32/64 loss: -1.9329099655151367
Batch 33/64 loss: -2.1949548721313477
Batch 34/64 loss: -2.2623605728149414
Batch 35/64 loss: -2.17885684967041
Batch 36/64 loss: -2.451284408569336
Batch 37/64 loss: -2.100884437561035
Batch 38/64 loss: -2.2315731048583984
Batch 39/64 loss: -2.0942211151123047
Batch 40/64 loss: -2.0694046020507812
Batch 41/64 loss: -1.8491106033325195
Batch 42/64 loss: -1.5490264892578125
Batch 43/64 loss: -1.9899702072143555
Batch 44/64 loss: -2.0598649978637695
Batch 45/64 loss: -2.037234306335449
Batch 46/64 loss: -2.0119457244873047
Batch 47/64 loss: -2.1914167404174805
Batch 48/64 loss: -2.2198610305786133
Batch 49/64 loss: -1.9631309509277344
Batch 50/64 loss: -2.069263458251953
Batch 51/64 loss: -2.0367374420166016
Batch 52/64 loss: -2.138641357421875
Batch 53/64 loss: -1.596909523010254
Batch 54/64 loss: -2.077389717102051
Batch 55/64 loss: -2.341032028198242
Batch 56/64 loss: -2.1602420806884766
Batch 57/64 loss: -2.328580856323242
Batch 58/64 loss: -2.166210174560547
Batch 59/64 loss: -1.6589546203613281
Batch 60/64 loss: -2.205317497253418
Batch 61/64 loss: -2.291781425476074
Batch 62/64 loss: -2.073516845703125
Batch 63/64 loss: -2.3721847534179688
Batch 64/64 loss: -6.4507927894592285
Epoch 113  Train loss: -2.150403189191631  Val loss: -2.333829335740342
Epoch 114
-------------------------------
Batch 1/64 loss: -2.3881845474243164
Batch 2/64 loss: -1.7466888427734375
Batch 3/64 loss: -1.9413261413574219
Batch 4/64 loss: -2.4239301681518555
Batch 5/64 loss: -2.2487316131591797
Batch 6/64 loss: -1.577672004699707
Batch 7/64 loss: -2.3313589096069336
Batch 8/64 loss: -2.2008047103881836
Batch 9/64 loss: -2.183147430419922
Batch 10/64 loss: -2.2251176834106445
Batch 11/64 loss: -2.4484481811523438
Batch 12/64 loss: -2.3648643493652344
Batch 13/64 loss: -1.9774036407470703
Batch 14/64 loss: -1.8076934814453125
Batch 15/64 loss: -1.774515151977539
Batch 16/64 loss: -2.039608955383301
Batch 17/64 loss: -1.9548044204711914
Batch 18/64 loss: -1.4136552810668945
Batch 19/64 loss: -2.172771453857422
Batch 20/64 loss: -2.1512317657470703
Batch 21/64 loss: -2.399362564086914
Batch 22/64 loss: -2.345902442932129
Batch 23/64 loss: -2.2707138061523438
Batch 24/64 loss: -2.137518882751465
Batch 25/64 loss: -2.212937355041504
Batch 26/64 loss: -1.9010028839111328
Batch 27/64 loss: -2.2096757888793945
Batch 28/64 loss: -1.8041725158691406
Batch 29/64 loss: -2.4035682678222656
Batch 30/64 loss: -1.8359384536743164
Batch 31/64 loss: -2.2225351333618164
Batch 32/64 loss: -1.9608421325683594
Batch 33/64 loss: -2.0461196899414062
Batch 34/64 loss: -2.3184738159179688
Batch 35/64 loss: -2.315476417541504
Batch 36/64 loss: -2.409147262573242
Batch 37/64 loss: -2.3360767364501953
Batch 38/64 loss: -2.1407546997070312
Batch 39/64 loss: -2.17362117767334
Batch 40/64 loss: -2.340237617492676
Batch 41/64 loss: -2.405877113342285
Batch 42/64 loss: -2.1931657791137695
Batch 43/64 loss: -2.4360361099243164
Batch 44/64 loss: -1.906911849975586
Batch 45/64 loss: -2.410245895385742
Batch 46/64 loss: -1.6441326141357422
Batch 47/64 loss: -1.9804134368896484
Batch 48/64 loss: -2.092916488647461
Batch 49/64 loss: -2.3254194259643555
Batch 50/64 loss: -2.211345672607422
Batch 51/64 loss: -2.0962390899658203
Batch 52/64 loss: -2.3540258407592773
Batch 53/64 loss: -2.3366756439208984
Batch 54/64 loss: -2.2704763412475586
Batch 55/64 loss: -2.5451154708862305
Batch 56/64 loss: -1.6881437301635742
Batch 57/64 loss: -1.9610776901245117
Batch 58/64 loss: -1.714991569519043
Batch 59/64 loss: -2.1401729583740234
Batch 60/64 loss: -2.0455751419067383
Batch 61/64 loss: -2.022639274597168
Batch 62/64 loss: -2.0078916549682617
Batch 63/64 loss: -1.6111574172973633
Batch 64/64 loss: -6.773222923278809
Epoch 114  Train loss: -2.1746917612412395  Val loss: -2.344182974694111
Epoch 115
-------------------------------
Batch 1/64 loss: -1.9133901596069336
Batch 2/64 loss: -2.124156951904297
Batch 3/64 loss: -2.309422492980957
Batch 4/64 loss: -2.366459846496582
Batch 5/64 loss: -2.245302200317383
Batch 6/64 loss: -2.067929267883301
Batch 7/64 loss: -2.121480941772461
Batch 8/64 loss: -2.342522621154785
Batch 9/64 loss: -1.9421443939208984
Batch 10/64 loss: -2.0673751831054688
Batch 11/64 loss: -2.2234058380126953
Batch 12/64 loss: -2.380970001220703
Batch 13/64 loss: -1.8043451309204102
Batch 14/64 loss: -1.4469680786132812
Batch 15/64 loss: -2.1061697006225586
Batch 16/64 loss: -2.1468849182128906
Batch 17/64 loss: -2.34027099609375
Batch 18/64 loss: -2.213320732116699
Batch 19/64 loss: -2.437066078186035
Batch 20/64 loss: -2.3648881912231445
Batch 21/64 loss: -1.9649848937988281
Batch 22/64 loss: -2.3819589614868164
Batch 23/64 loss: -1.3719110488891602
Batch 24/64 loss: -2.3019790649414062
Batch 25/64 loss: -2.042757987976074
Batch 26/64 loss: -2.010528564453125
Batch 27/64 loss: -2.1928415298461914
Batch 28/64 loss: -2.2453794479370117
Batch 29/64 loss: -1.5950088500976562
Batch 30/64 loss: -2.173295021057129
Batch 31/64 loss: -2.352323532104492
Batch 32/64 loss: -2.308974266052246
Batch 33/64 loss: -2.283858299255371
Batch 34/64 loss: -1.991837501525879
Batch 35/64 loss: -2.0662384033203125
Batch 36/64 loss: -2.3900442123413086
Batch 37/64 loss: -2.4100732803344727
Batch 38/64 loss: -1.7373933792114258
Batch 39/64 loss: -1.4775171279907227
Batch 40/64 loss: -2.3064584732055664
Batch 41/64 loss: -2.181450843811035
Batch 42/64 loss: -2.3315563201904297
Batch 43/64 loss: -2.2878732681274414
Batch 44/64 loss: -2.442434310913086
Batch 45/64 loss: -2.3816213607788086
Batch 46/64 loss: -2.1403541564941406
Batch 47/64 loss: -2.2132387161254883
Batch 48/64 loss: -2.4012441635131836
Batch 49/64 loss: -2.178145408630371
Batch 50/64 loss: -2.0162954330444336
Batch 51/64 loss: -2.2790822982788086
Batch 52/64 loss: -2.142629623413086
Batch 53/64 loss: -1.9184799194335938
Batch 54/64 loss: -2.125046730041504
Batch 55/64 loss: -1.8297395706176758
Batch 56/64 loss: -2.2201194763183594
Batch 57/64 loss: -2.40850830078125
Batch 58/64 loss: -2.1898269653320312
Batch 59/64 loss: -2.175215721130371
Batch 60/64 loss: -2.142237663269043
Batch 61/64 loss: -1.9491987228393555
Batch 62/64 loss: -2.0687475204467773
Batch 63/64 loss: -2.175990104675293
Batch 64/64 loss: -6.64050817489624
Epoch 115  Train loss: -2.192145181169697  Val loss: -2.416542367836864
Saving best model, epoch: 115
Epoch 116
-------------------------------
Batch 1/64 loss: -2.0972633361816406
Batch 2/64 loss: -2.355605125427246
Batch 3/64 loss: -2.3366947174072266
Batch 4/64 loss: -1.7199745178222656
Batch 5/64 loss: -1.8035717010498047
Batch 6/64 loss: -2.2274093627929688
Batch 7/64 loss: -1.6971635818481445
Batch 8/64 loss: -2.164806365966797
Batch 9/64 loss: -2.146817207336426
Batch 10/64 loss: -1.8897724151611328
Batch 11/64 loss: -2.382086753845215
Batch 12/64 loss: -2.444751739501953
Batch 13/64 loss: -1.6290178298950195
Batch 14/64 loss: -2.472219467163086
Batch 15/64 loss: -2.0538339614868164
Batch 16/64 loss: -2.1277599334716797
Batch 17/64 loss: -2.1171159744262695
Batch 18/64 loss: -2.4296932220458984
Batch 19/64 loss: -2.3919448852539062
Batch 20/64 loss: -2.2367305755615234
Batch 21/64 loss: -1.9212627410888672
Batch 22/64 loss: -2.4572858810424805
Batch 23/64 loss: -2.0649309158325195
Batch 24/64 loss: -2.3946361541748047
Batch 25/64 loss: -2.587965965270996
Batch 26/64 loss: -2.2916908264160156
Batch 27/64 loss: -2.2223997116088867
Batch 28/64 loss: -2.0520429611206055
Batch 29/64 loss: -2.277364730834961
Batch 30/64 loss: -2.207829475402832
Batch 31/64 loss: -2.378512382507324
Batch 32/64 loss: -1.5145244598388672
Batch 33/64 loss: -2.1309337615966797
Batch 34/64 loss: -2.3812198638916016
Batch 35/64 loss: -2.3661365509033203
Batch 36/64 loss: -1.999190330505371
Batch 37/64 loss: -2.182417869567871
Batch 38/64 loss: -2.2612552642822266
Batch 39/64 loss: -2.520364761352539
Batch 40/64 loss: -1.7654953002929688
Batch 41/64 loss: -2.469841957092285
Batch 42/64 loss: -2.5113306045532227
Batch 43/64 loss: -2.4406042098999023
Batch 44/64 loss: -2.3305587768554688
Batch 45/64 loss: -2.0874271392822266
Batch 46/64 loss: -2.4442434310913086
Batch 47/64 loss: -2.1644067764282227
Batch 48/64 loss: -1.7185735702514648
Batch 49/64 loss: -2.25302791595459
Batch 50/64 loss: -2.5860681533813477
Batch 51/64 loss: -2.6048269271850586
Batch 52/64 loss: -2.2087230682373047
Batch 53/64 loss: -2.3425769805908203
Batch 54/64 loss: -2.1593570709228516
Batch 55/64 loss: -2.3808555603027344
Batch 56/64 loss: -2.020674705505371
Batch 57/64 loss: -2.184706687927246
Batch 58/64 loss: -2.142230987548828
Batch 59/64 loss: -2.2280073165893555
Batch 60/64 loss: -2.4136829376220703
Batch 61/64 loss: -2.0344791412353516
Batch 62/64 loss: -2.0974855422973633
Batch 63/64 loss: -2.3034238815307617
Batch 64/64 loss: -6.759171485900879
Epoch 116  Train loss: -2.2572264241237265  Val loss: -2.4143675709098473
Epoch 117
-------------------------------
Batch 1/64 loss: -2.265059471130371
Batch 2/64 loss: -2.022695541381836
Batch 3/64 loss: -2.07535457611084
Batch 4/64 loss: -2.5850095748901367
Batch 5/64 loss: -2.272366523742676
Batch 6/64 loss: -1.8150577545166016
Batch 7/64 loss: -2.121382713317871
Batch 8/64 loss: -2.031834602355957
Batch 9/64 loss: -2.3984270095825195
Batch 10/64 loss: -2.4159936904907227
Batch 11/64 loss: -2.2213945388793945
Batch 12/64 loss: -2.1677474975585938
Batch 13/64 loss: -2.3044652938842773
Batch 14/64 loss: -2.235433578491211
Batch 15/64 loss: -1.8590526580810547
Batch 16/64 loss: -2.375772476196289
Batch 17/64 loss: -2.269540786743164
Batch 18/64 loss: -2.4140920639038086
Batch 19/64 loss: -2.122256278991699
Batch 20/64 loss: -2.364424705505371
Batch 21/64 loss: -2.3481435775756836
Batch 22/64 loss: -2.2989349365234375
Batch 23/64 loss: -1.706040382385254
Batch 24/64 loss: -2.1114931106567383
Batch 25/64 loss: -1.8057689666748047
Batch 26/64 loss: -2.4062376022338867
Batch 27/64 loss: -1.853653907775879
Batch 28/64 loss: -2.1135635375976562
Batch 29/64 loss: -2.0227584838867188
Batch 30/64 loss: -2.0003414154052734
Batch 31/64 loss: -2.3978261947631836
Batch 32/64 loss: -2.260798454284668
Batch 33/64 loss: -1.6039161682128906
Batch 34/64 loss: -2.4983091354370117
Batch 35/64 loss: -2.0599546432495117
Batch 36/64 loss: -2.3199729919433594
Batch 37/64 loss: -2.354739189147949
Batch 38/64 loss: -2.203585624694824
Batch 39/64 loss: -2.431778907775879
Batch 40/64 loss: -2.1441516876220703
Batch 41/64 loss: -2.083041191101074
Batch 42/64 loss: -2.183473587036133
Batch 43/64 loss: -2.521493911743164
Batch 44/64 loss: -1.8866081237792969
Batch 45/64 loss: -2.193596839904785
Batch 46/64 loss: -2.471341133117676
Batch 47/64 loss: -1.995391845703125
Batch 48/64 loss: -2.1652584075927734
Batch 49/64 loss: -2.065609931945801
Batch 50/64 loss: -2.150059700012207
Batch 51/64 loss: -2.1310815811157227
Batch 52/64 loss: -2.3453922271728516
Batch 53/64 loss: -2.2222366333007812
Batch 54/64 loss: -1.9080028533935547
Batch 55/64 loss: -2.3667707443237305
Batch 56/64 loss: -2.312649726867676
Batch 57/64 loss: -2.376920700073242
Batch 58/64 loss: -2.037128448486328
Batch 59/64 loss: -2.1866989135742188
Batch 60/64 loss: -2.26419734954834
Batch 61/64 loss: -2.254770278930664
Batch 62/64 loss: -2.0430593490600586
Batch 63/64 loss: -2.3482704162597656
Batch 64/64 loss: -6.585850238800049
Epoch 117  Train loss: -2.2389297541450053  Val loss: -2.409190921848992
Epoch 118
-------------------------------
Batch 1/64 loss: -2.3636512756347656
Batch 2/64 loss: -2.543577194213867
Batch 3/64 loss: -2.449824333190918
Batch 4/64 loss: -2.1829280853271484
Batch 5/64 loss: -2.183137893676758
Batch 6/64 loss: -1.800400733947754
Batch 7/64 loss: -2.0440597534179688
Batch 8/64 loss: -2.385401725769043
Batch 9/64 loss: -2.1220264434814453
Batch 10/64 loss: -2.0590829849243164
Batch 11/64 loss: -2.414069175720215
Batch 12/64 loss: -2.4887733459472656
Batch 13/64 loss: -1.8767919540405273
Batch 14/64 loss: -2.137685775756836
Batch 15/64 loss: -2.502481460571289
Batch 16/64 loss: -2.330106735229492
Batch 17/64 loss: -2.2882251739501953
Batch 18/64 loss: -2.2797317504882812
Batch 19/64 loss: -2.3738832473754883
Batch 20/64 loss: -2.1119651794433594
Batch 21/64 loss: -2.1830806732177734
Batch 22/64 loss: -2.0018415451049805
Batch 23/64 loss: -2.4060287475585938
Batch 24/64 loss: -2.4930944442749023
Batch 25/64 loss: -2.2325639724731445
Batch 26/64 loss: -1.7810134887695312
Batch 27/64 loss: -2.3656787872314453
Batch 28/64 loss: -2.4310035705566406
Batch 29/64 loss: -2.242807388305664
Batch 30/64 loss: -2.5129594802856445
Batch 31/64 loss: -2.1276559829711914
Batch 32/64 loss: -2.3203554153442383
Batch 33/64 loss: -2.3398284912109375
Batch 34/64 loss: -1.9339971542358398
Batch 35/64 loss: -1.8627262115478516
Batch 36/64 loss: -1.8845901489257812
Batch 37/64 loss: -2.385420799255371
Batch 38/64 loss: -1.8023061752319336
Batch 39/64 loss: -2.502513885498047
Batch 40/64 loss: -2.2312145233154297
Batch 41/64 loss: -2.2762556076049805
Batch 42/64 loss: -2.1926937103271484
Batch 43/64 loss: -2.361495018005371
Batch 44/64 loss: -1.6833620071411133
Batch 45/64 loss: -2.3203535079956055
Batch 46/64 loss: -2.4109115600585938
Batch 47/64 loss: -2.3169145584106445
Batch 48/64 loss: -2.4331045150756836
Batch 49/64 loss: -2.3208847045898438
Batch 50/64 loss: -2.4883241653442383
Batch 51/64 loss: -2.079914093017578
Batch 52/64 loss: -2.2791271209716797
Batch 53/64 loss: -2.562687873840332
Batch 54/64 loss: -2.1297502517700195
Batch 55/64 loss: -1.8816375732421875
Batch 56/64 loss: -2.0970563888549805
Batch 57/64 loss: -2.0948715209960938
Batch 58/64 loss: -2.028667449951172
Batch 59/64 loss: -2.391404151916504
Batch 60/64 loss: -2.039886474609375
Batch 61/64 loss: -2.1675100326538086
Batch 62/64 loss: -2.390562057495117
Batch 63/64 loss: -2.4201087951660156
Batch 64/64 loss: -6.949476718902588
Epoch 118  Train loss: -2.2832639338923437  Val loss: -2.5150650653642477
Saving best model, epoch: 118
Epoch 119
-------------------------------
Batch 1/64 loss: -2.3439292907714844
Batch 2/64 loss: -2.0471343994140625
Batch 3/64 loss: -1.8404464721679688
Batch 4/64 loss: -2.331716537475586
Batch 5/64 loss: -2.624903678894043
Batch 6/64 loss: -2.4181222915649414
Batch 7/64 loss: -1.8576030731201172
Batch 8/64 loss: -2.417285919189453
Batch 9/64 loss: -2.039827346801758
Batch 10/64 loss: -2.376236915588379
Batch 11/64 loss: -2.3411941528320312
Batch 12/64 loss: -2.2896833419799805
Batch 13/64 loss: -1.8132810592651367
Batch 14/64 loss: -2.293079376220703
Batch 15/64 loss: -2.5637712478637695
Batch 16/64 loss: -2.4761171340942383
Batch 17/64 loss: -2.177999496459961
Batch 18/64 loss: -2.2183332443237305
Batch 19/64 loss: -2.327056884765625
Batch 20/64 loss: -2.4137754440307617
Batch 21/64 loss: -2.359891891479492
Batch 22/64 loss: -2.3092222213745117
Batch 23/64 loss: -2.335023880004883
Batch 24/64 loss: -1.9212055206298828
Batch 25/64 loss: -1.9622306823730469
Batch 26/64 loss: -1.9357280731201172
Batch 27/64 loss: -2.584547996520996
Batch 28/64 loss: -1.8326416015625
Batch 29/64 loss: -1.9583158493041992
Batch 30/64 loss: -1.7402725219726562
Batch 31/64 loss: -2.3543500900268555
Batch 32/64 loss: -2.2317285537719727
Batch 33/64 loss: -2.335390090942383
Batch 34/64 loss: -2.3288116455078125
Batch 35/64 loss: -2.2450294494628906
Batch 36/64 loss: -2.4712915420532227
Batch 37/64 loss: -2.2333717346191406
Batch 38/64 loss: -2.3062000274658203
Batch 39/64 loss: -2.3056821823120117
Batch 40/64 loss: -2.274632453918457
Batch 41/64 loss: -2.1164913177490234
Batch 42/64 loss: -2.344010353088379
Batch 43/64 loss: -2.3469390869140625
Batch 44/64 loss: -2.1980600357055664
Batch 45/64 loss: -2.2033348083496094
Batch 46/64 loss: -2.1312808990478516
Batch 47/64 loss: -2.3870248794555664
Batch 48/64 loss: -2.15322208404541
Batch 49/64 loss: -2.250730514526367
Batch 50/64 loss: -2.17724609375
Batch 51/64 loss: -2.5374584197998047
Batch 52/64 loss: -2.353424072265625
Batch 53/64 loss: -2.460648536682129
Batch 54/64 loss: -2.206526756286621
Batch 55/64 loss: -2.0876026153564453
Batch 56/64 loss: -2.370584487915039
Batch 57/64 loss: -2.465327262878418
Batch 58/64 loss: -2.3697891235351562
Batch 59/64 loss: -2.41709041595459
Batch 60/64 loss: -1.5949993133544922
Batch 61/64 loss: -2.078378677368164
Batch 62/64 loss: -2.238846778869629
Batch 63/64 loss: -2.2945451736450195
Batch 64/64 loss: -6.9526262283325195
Epoch 119  Train loss: -2.2938838696947284  Val loss: -2.3857958030045237
Epoch 120
-------------------------------
Batch 1/64 loss: -2.5844039916992188
Batch 2/64 loss: -2.0527868270874023
Batch 3/64 loss: -2.349071502685547
Batch 4/64 loss: -2.4417123794555664
Batch 5/64 loss: -2.1822128295898438
Batch 6/64 loss: -2.383915901184082
Batch 7/64 loss: -2.3644256591796875
Batch 8/64 loss: -2.1849842071533203
Batch 9/64 loss: -2.2461585998535156
Batch 10/64 loss: -2.390657424926758
Batch 11/64 loss: -2.360200881958008
Batch 12/64 loss: -2.16396427154541
Batch 13/64 loss: -2.4099035263061523
Batch 14/64 loss: -2.362642288208008
Batch 15/64 loss: -2.274372100830078
Batch 16/64 loss: -2.1082229614257812
Batch 17/64 loss: -2.1516542434692383
Batch 18/64 loss: -2.468019485473633
Batch 19/64 loss: -2.3960628509521484
Batch 20/64 loss: -1.9593000411987305
Batch 21/64 loss: -2.0827159881591797
Batch 22/64 loss: -2.4713830947875977
Batch 23/64 loss: -2.463568687438965
Batch 24/64 loss: -2.138376235961914
Batch 25/64 loss: -2.3271961212158203
Batch 26/64 loss: -2.1632919311523438
Batch 27/64 loss: -2.2621870040893555
Batch 28/64 loss: -2.0017032623291016
Batch 29/64 loss: -2.1014299392700195
Batch 30/64 loss: -2.2479019165039062
Batch 31/64 loss: -2.3129777908325195
Batch 32/64 loss: -2.307675361633301
Batch 33/64 loss: -2.2895421981811523
Batch 34/64 loss: -1.950754165649414
Batch 35/64 loss: -1.8897991180419922
Batch 36/64 loss: -2.490541458129883
Batch 37/64 loss: -2.070723533630371
Batch 38/64 loss: -2.3225393295288086
Batch 39/64 loss: -2.0441694259643555
Batch 40/64 loss: -2.1046667098999023
Batch 41/64 loss: -2.4598779678344727
Batch 42/64 loss: -2.045414924621582
Batch 43/64 loss: -2.0137481689453125
Batch 44/64 loss: -2.156155586242676
Batch 45/64 loss: -2.44753360748291
Batch 46/64 loss: -1.968428611755371
Batch 47/64 loss: -2.2592411041259766
Batch 48/64 loss: -2.4575462341308594
Batch 49/64 loss: -2.0627832412719727
Batch 50/64 loss: -2.451388359069824
Batch 51/64 loss: -2.016336441040039
Batch 52/64 loss: -2.3859033584594727
Batch 53/64 loss: -2.3757619857788086
Batch 54/64 loss: -2.272944450378418
Batch 55/64 loss: -2.3385543823242188
Batch 56/64 loss: -2.068209648132324
Batch 57/64 loss: -2.3657236099243164
Batch 58/64 loss: -2.428645133972168
Batch 59/64 loss: -2.5008296966552734
Batch 60/64 loss: -2.360198974609375
Batch 61/64 loss: -2.470806121826172
Batch 62/64 loss: -2.0012874603271484
Batch 63/64 loss: -2.434755325317383
Batch 64/64 loss: -6.99370813369751
Epoch 120  Train loss: -2.3131791488797058  Val loss: -2.5113984071921647
Epoch 121
-------------------------------
Batch 1/64 loss: -1.884608268737793
Batch 2/64 loss: -2.388120651245117
Batch 3/64 loss: -1.5878620147705078
Batch 4/64 loss: -2.400218963623047
Batch 5/64 loss: -2.196229934692383
Batch 6/64 loss: -2.3707122802734375
Batch 7/64 loss: -2.339750289916992
Batch 8/64 loss: -2.3394241333007812
Batch 9/64 loss: -2.2796478271484375
Batch 10/64 loss: -2.0505332946777344
Batch 11/64 loss: -2.101351737976074
Batch 12/64 loss: -1.7919855117797852
Batch 13/64 loss: -2.2342262268066406
Batch 14/64 loss: -2.3167076110839844
Batch 15/64 loss: -2.229879379272461
Batch 16/64 loss: -2.5320663452148438
Batch 17/64 loss: -2.20950984954834
Batch 18/64 loss: -2.438936233520508
Batch 19/64 loss: -2.4958457946777344
Batch 20/64 loss: -2.184854507446289
Batch 21/64 loss: -2.287796974182129
Batch 22/64 loss: -2.5033187866210938
Batch 23/64 loss: -2.17132568359375
Batch 24/64 loss: -2.253607749938965
Batch 25/64 loss: -2.1700477600097656
Batch 26/64 loss: -2.3556995391845703
Batch 27/64 loss: -2.3953094482421875
Batch 28/64 loss: -2.278902053833008
Batch 29/64 loss: -2.1571712493896484
Batch 30/64 loss: -2.468463897705078
Batch 31/64 loss: -1.871725082397461
Batch 32/64 loss: -2.368490219116211
Batch 33/64 loss: -1.8331327438354492
Batch 34/64 loss: -2.483616828918457
Batch 35/64 loss: -2.492717742919922
Batch 36/64 loss: -2.3002710342407227
Batch 37/64 loss: -2.1581430435180664
Batch 38/64 loss: -2.185882568359375
Batch 39/64 loss: -2.373318672180176
Batch 40/64 loss: -2.465867042541504
Batch 41/64 loss: -2.4876203536987305
Batch 42/64 loss: -2.261094093322754
Batch 43/64 loss: -2.24783992767334
Batch 44/64 loss: -2.1557960510253906
Batch 45/64 loss: -2.4665422439575195
Batch 46/64 loss: -2.3900222778320312
Batch 47/64 loss: -2.6300973892211914
Batch 48/64 loss: -2.1071481704711914
Batch 49/64 loss: -2.3507394790649414
Batch 50/64 loss: -2.4404449462890625
Batch 51/64 loss: -2.144913673400879
Batch 52/64 loss: -1.6589698791503906
Batch 53/64 loss: -2.215762138366699
Batch 54/64 loss: -2.4336042404174805
Batch 55/64 loss: -2.0553159713745117
Batch 56/64 loss: -2.4000606536865234
Batch 57/64 loss: -1.8250923156738281
Batch 58/64 loss: -2.4002323150634766
Batch 59/64 loss: -2.276639938354492
Batch 60/64 loss: -1.8909273147583008
Batch 61/64 loss: -2.2473392486572266
Batch 62/64 loss: -2.196584701538086
Batch 63/64 loss: -2.3965530395507812
Batch 64/64 loss: -6.910460472106934
Epoch 121  Train loss: -2.3028935638128543  Val loss: -2.5048886721896144
Epoch 122
-------------------------------
Batch 1/64 loss: -2.303971290588379
Batch 2/64 loss: -2.383427619934082
Batch 3/64 loss: -2.3998641967773438
Batch 4/64 loss: -2.3913564682006836
Batch 5/64 loss: -2.3974075317382812
Batch 6/64 loss: -2.1080007553100586
Batch 7/64 loss: -2.4555959701538086
Batch 8/64 loss: -2.237513542175293
Batch 9/64 loss: -2.2692461013793945
Batch 10/64 loss: -2.3417606353759766
Batch 11/64 loss: -2.018198013305664
Batch 12/64 loss: -2.3482627868652344
Batch 13/64 loss: -2.210270881652832
Batch 14/64 loss: -2.1699466705322266
Batch 15/64 loss: -1.9472637176513672
Batch 16/64 loss: -2.1816349029541016
Batch 17/64 loss: -2.3289976119995117
Batch 18/64 loss: -2.0801162719726562
Batch 19/64 loss: -2.0545663833618164
Batch 20/64 loss: -2.2703189849853516
Batch 21/64 loss: -2.0397214889526367
Batch 22/64 loss: -2.1493911743164062
Batch 23/64 loss: -2.393376350402832
Batch 24/64 loss: -2.2811365127563477
Batch 25/64 loss: -2.0474319458007812
Batch 26/64 loss: -2.5030269622802734
Batch 27/64 loss: -2.281595230102539
Batch 28/64 loss: -2.0180158615112305
Batch 29/64 loss: -2.0196475982666016
Batch 30/64 loss: -2.3759374618530273
Batch 31/64 loss: -2.026331901550293
Batch 32/64 loss: -2.2381715774536133
Batch 33/64 loss: -2.3764610290527344
Batch 34/64 loss: -2.349940299987793
Batch 35/64 loss: -2.1949567794799805
Batch 36/64 loss: -1.882084846496582
Batch 37/64 loss: -2.3918495178222656
Batch 38/64 loss: -2.303110122680664
Batch 39/64 loss: -2.478689193725586
Batch 40/64 loss: -2.3431968688964844
Batch 41/64 loss: -2.3060388565063477
Batch 42/64 loss: -2.070110321044922
Batch 43/64 loss: -2.0015344619750977
Batch 44/64 loss: -2.28347110748291
Batch 45/64 loss: -2.2709579467773438
Batch 46/64 loss: -2.1932497024536133
Batch 47/64 loss: -2.570463180541992
Batch 48/64 loss: -2.5136098861694336
Batch 49/64 loss: -2.41323184967041
Batch 50/64 loss: -2.166635513305664
Batch 51/64 loss: -2.2662458419799805
Batch 52/64 loss: -2.416508674621582
Batch 53/64 loss: -2.4667844772338867
Batch 54/64 loss: -2.494464874267578
Batch 55/64 loss: -2.1890907287597656
Batch 56/64 loss: -2.20676326751709
Batch 57/64 loss: -2.3927478790283203
Batch 58/64 loss: -2.4115028381347656
Batch 59/64 loss: -2.175182342529297
Batch 60/64 loss: -2.55057430267334
Batch 61/64 loss: -2.370697021484375
Batch 62/64 loss: -2.1168107986450195
Batch 63/64 loss: -2.4864501953125
Batch 64/64 loss: -6.336141586303711
Epoch 122  Train loss: -2.316502357931698  Val loss: -2.4799739536141203
Epoch 123
-------------------------------
Batch 1/64 loss: -2.300713539123535
Batch 2/64 loss: -2.4641733169555664
Batch 3/64 loss: -2.234175682067871
Batch 4/64 loss: -2.2632312774658203
Batch 5/64 loss: -2.6032371520996094
Batch 6/64 loss: -2.3481616973876953
Batch 7/64 loss: -2.1842241287231445
Batch 8/64 loss: -2.367979049682617
Batch 9/64 loss: -2.2649688720703125
Batch 10/64 loss: -2.596367835998535
Batch 11/64 loss: -2.2419281005859375
Batch 12/64 loss: -2.5465316772460938
Batch 13/64 loss: -2.2570505142211914
Batch 14/64 loss: -2.337759017944336
Batch 15/64 loss: -2.2216272354125977
Batch 16/64 loss: -2.5000667572021484
Batch 17/64 loss: -2.400728225708008
Batch 18/64 loss: -2.2186450958251953
Batch 19/64 loss: -2.163522720336914
Batch 20/64 loss: -1.957162857055664
Batch 21/64 loss: -2.5281200408935547
Batch 22/64 loss: -2.491013526916504
Batch 23/64 loss: -2.2473344802856445
Batch 24/64 loss: -1.9115772247314453
Batch 25/64 loss: -2.1635074615478516
Batch 26/64 loss: -2.111557960510254
Batch 27/64 loss: -2.2349777221679688
Batch 28/64 loss: -2.1651105880737305
Batch 29/64 loss: -2.43868350982666
Batch 30/64 loss: -2.226499557495117
Batch 31/64 loss: -2.1980485916137695
Batch 32/64 loss: -2.1490840911865234
Batch 33/64 loss: -2.2226762771606445
Batch 34/64 loss: -2.4154796600341797
Batch 35/64 loss: -1.8664464950561523
Batch 36/64 loss: -2.3276615142822266
Batch 37/64 loss: -2.4063940048217773
Batch 38/64 loss: -2.366265296936035
Batch 39/64 loss: -2.283078193664551
Batch 40/64 loss: -2.3262929916381836
Batch 41/64 loss: -2.418572425842285
Batch 42/64 loss: -2.20465087890625
Batch 43/64 loss: -2.2996139526367188
Batch 44/64 loss: -2.1032943725585938
Batch 45/64 loss: -2.4785852432250977
Batch 46/64 loss: -2.4242706298828125
Batch 47/64 loss: -1.9738054275512695
Batch 48/64 loss: -2.3651123046875
Batch 49/64 loss: -2.429868698120117
Batch 50/64 loss: -2.319575309753418
Batch 51/64 loss: -2.4631614685058594
Batch 52/64 loss: -2.3967161178588867
Batch 53/64 loss: -2.155787467956543
Batch 54/64 loss: -2.034909248352051
Batch 55/64 loss: -2.195908546447754
Batch 56/64 loss: -2.4559850692749023
Batch 57/64 loss: -2.367809295654297
Batch 58/64 loss: -2.3039894104003906
Batch 59/64 loss: -2.4282798767089844
Batch 60/64 loss: -2.4994869232177734
Batch 61/64 loss: -2.458258628845215
Batch 62/64 loss: -2.177906036376953
Batch 63/64 loss: -2.2768211364746094
Batch 64/64 loss: -6.507349967956543
Epoch 123  Train loss: -2.3476854099946864  Val loss: -2.5623031170507478
Saving best model, epoch: 123
Epoch 124
-------------------------------
Batch 1/64 loss: -2.1170597076416016
Batch 2/64 loss: -2.261392593383789
Batch 3/64 loss: -2.404545783996582
Batch 4/64 loss: -2.556856155395508
Batch 5/64 loss: -2.183633804321289
Batch 6/64 loss: -2.2296152114868164
Batch 7/64 loss: -2.52432918548584
Batch 8/64 loss: -2.352275848388672
Batch 9/64 loss: -1.832585334777832
Batch 10/64 loss: -2.501850128173828
Batch 11/64 loss: -2.078594207763672
Batch 12/64 loss: -2.4946117401123047
Batch 13/64 loss: -2.464545249938965
Batch 14/64 loss: -2.299121856689453
Batch 15/64 loss: -2.5894880294799805
Batch 16/64 loss: -2.09841251373291
Batch 17/64 loss: -2.3147153854370117
Batch 18/64 loss: -2.237253189086914
Batch 19/64 loss: -2.3954057693481445
Batch 20/64 loss: -2.33579158782959
Batch 21/64 loss: -2.0769262313842773
Batch 22/64 loss: -2.1568212509155273
Batch 23/64 loss: -2.2083864212036133
Batch 24/64 loss: -2.4537124633789062
Batch 25/64 loss: -2.5850839614868164
Batch 26/64 loss: -2.3514633178710938
Batch 27/64 loss: -2.360200881958008
Batch 28/64 loss: -2.1474733352661133
Batch 29/64 loss: -2.200786590576172
Batch 30/64 loss: -2.14639949798584
Batch 31/64 loss: -2.2816219329833984
Batch 32/64 loss: -2.3862695693969727
Batch 33/64 loss: -2.4245243072509766
Batch 34/64 loss: -2.2881603240966797
Batch 35/64 loss: -2.395437240600586
Batch 36/64 loss: -2.507638931274414
Batch 37/64 loss: -2.1628923416137695
Batch 38/64 loss: -2.067244529724121
Batch 39/64 loss: -2.2401323318481445
Batch 40/64 loss: -2.5000877380371094
Batch 41/64 loss: -2.3047561645507812
Batch 42/64 loss: -1.9027881622314453
Batch 43/64 loss: -2.261859893798828
Batch 44/64 loss: -2.3161191940307617
Batch 45/64 loss: -2.1205968856811523
Batch 46/64 loss: -2.0317459106445312
Batch 47/64 loss: -2.246927261352539
Batch 48/64 loss: -2.3604841232299805
Batch 49/64 loss: -1.9714117050170898
Batch 50/64 loss: -2.213364601135254
Batch 51/64 loss: -2.2595224380493164
Batch 52/64 loss: -1.9229907989501953
Batch 53/64 loss: -2.1499814987182617
Batch 54/64 loss: -2.2524490356445312
Batch 55/64 loss: -2.2180566787719727
Batch 56/64 loss: -2.047959327697754
Batch 57/64 loss: -2.157515525817871
Batch 58/64 loss: -2.4520339965820312
Batch 59/64 loss: -2.670217514038086
Batch 60/64 loss: -1.8671627044677734
Batch 61/64 loss: -1.6861200332641602
Batch 62/64 loss: -2.107372283935547
Batch 63/64 loss: -2.445402145385742
Batch 64/64 loss: -6.910031795501709
Epoch 124  Train loss: -2.311571893505022  Val loss: -2.3845288253731742
Epoch 125
-------------------------------
Batch 1/64 loss: -1.9554071426391602
Batch 2/64 loss: -2.259611129760742
Batch 3/64 loss: -2.3707542419433594
Batch 4/64 loss: -2.612992286682129
Batch 5/64 loss: -2.374485969543457
Batch 6/64 loss: -2.36850643157959
Batch 7/64 loss: -2.0699081420898438
Batch 8/64 loss: -2.177762985229492
Batch 9/64 loss: -2.4807233810424805
Batch 10/64 loss: -2.2394676208496094
Batch 11/64 loss: -2.4064512252807617
Batch 12/64 loss: -2.288750648498535
Batch 13/64 loss: -2.413492202758789
Batch 14/64 loss: -2.2285823822021484
Batch 15/64 loss: -2.186060905456543
Batch 16/64 loss: -1.969557762145996
Batch 17/64 loss: -2.4597673416137695
Batch 18/64 loss: -2.023458480834961
Batch 19/64 loss: -2.247830390930176
Batch 20/64 loss: -2.084779739379883
Batch 21/64 loss: -2.4839563369750977
Batch 22/64 loss: -1.9206562042236328
Batch 23/64 loss: -1.960362434387207
Batch 24/64 loss: -1.9058618545532227
Batch 25/64 loss: -2.533092498779297
Batch 26/64 loss: -2.3203372955322266
Batch 27/64 loss: -2.2783327102661133
Batch 28/64 loss: -2.222559928894043
Batch 29/64 loss: -2.1350250244140625
Batch 30/64 loss: -2.6249074935913086
Batch 31/64 loss: -2.1721811294555664
Batch 32/64 loss: -2.233405113220215
Batch 33/64 loss: -2.3754663467407227
Batch 34/64 loss: -1.985814094543457
Batch 35/64 loss: -2.2637338638305664
Batch 36/64 loss: -2.291346549987793
Batch 37/64 loss: -1.9481086730957031
Batch 38/64 loss: -2.1753416061401367
Batch 39/64 loss: -2.14047908782959
Batch 40/64 loss: -2.4176883697509766
Batch 41/64 loss: -2.0593976974487305
Batch 42/64 loss: -2.2713518142700195
Batch 43/64 loss: -2.2395830154418945
Batch 44/64 loss: -2.1902379989624023
Batch 45/64 loss: -2.4670658111572266
Batch 46/64 loss: -1.8598747253417969
Batch 47/64 loss: -2.2774534225463867
Batch 48/64 loss: -2.2947607040405273
Batch 49/64 loss: -2.2732791900634766
Batch 50/64 loss: -2.3799142837524414
Batch 51/64 loss: -2.4422950744628906
Batch 52/64 loss: -2.339906692504883
Batch 53/64 loss: -2.234344482421875
Batch 54/64 loss: -2.4325218200683594
Batch 55/64 loss: -2.396653175354004
Batch 56/64 loss: -2.393418312072754
Batch 57/64 loss: -2.3973569869995117
Batch 58/64 loss: -2.1735610961914062
Batch 59/64 loss: -2.082521438598633
Batch 60/64 loss: -2.2657032012939453
Batch 61/64 loss: -2.5309457778930664
Batch 62/64 loss: -2.391145706176758
Batch 63/64 loss: -2.477581024169922
Batch 64/64 loss: -6.688577175140381
Epoch 125  Train loss: -2.313636287988401  Val loss: -2.4176490233116543
Epoch 126
-------------------------------
Batch 1/64 loss: -2.238152503967285
Batch 2/64 loss: -2.3238658905029297
Batch 3/64 loss: -2.1757450103759766
Batch 4/64 loss: -2.5495004653930664
Batch 5/64 loss: -2.1191177368164062
Batch 6/64 loss: -2.2093276977539062
Batch 7/64 loss: -1.8342657089233398
Batch 8/64 loss: -2.412503242492676
Batch 9/64 loss: -2.4461841583251953
Batch 10/64 loss: -2.4073781967163086
Batch 11/64 loss: -2.473118782043457
Batch 12/64 loss: -2.4169883728027344
Batch 13/64 loss: -2.013594627380371
Batch 14/64 loss: -2.28292179107666
Batch 15/64 loss: -2.450863838195801
Batch 16/64 loss: -2.467113494873047
Batch 17/64 loss: -2.421046257019043
Batch 18/64 loss: -2.170969009399414
Batch 19/64 loss: -2.118319511413574
Batch 20/64 loss: -2.4397335052490234
Batch 21/64 loss: -2.5512619018554688
Batch 22/64 loss: -2.0171279907226562
Batch 23/64 loss: -2.4544057846069336
Batch 24/64 loss: -2.0181989669799805
Batch 25/64 loss: -2.3087501525878906
Batch 26/64 loss: -2.12579345703125
Batch 27/64 loss: -2.244706153869629
Batch 28/64 loss: -2.377436637878418
Batch 29/64 loss: -2.5646791458129883
Batch 30/64 loss: -2.431600570678711
Batch 31/64 loss: -2.3544368743896484
Batch 32/64 loss: -1.6411151885986328
Batch 33/64 loss: -1.7156476974487305
Batch 34/64 loss: -2.32517147064209
Batch 35/64 loss: -1.669875144958496
Batch 36/64 loss: -1.753713607788086
Batch 37/64 loss: -2.189380645751953
Batch 38/64 loss: -1.9487571716308594
Batch 39/64 loss: -2.3266048431396484
Batch 40/64 loss: -2.349247932434082
Batch 41/64 loss: -2.2602462768554688
Batch 42/64 loss: -2.273622512817383
Batch 43/64 loss: -1.7749919891357422
Batch 44/64 loss: -2.3501949310302734
Batch 45/64 loss: -2.462514877319336
Batch 46/64 loss: -2.2769412994384766
Batch 47/64 loss: -2.0104379653930664
Batch 48/64 loss: -2.2555322647094727
Batch 49/64 loss: -1.9713001251220703
Batch 50/64 loss: -2.401700019836426
Batch 51/64 loss: -2.3739099502563477
Batch 52/64 loss: -2.1551647186279297
Batch 53/64 loss: -2.2689590454101562
Batch 54/64 loss: -2.161592483520508
Batch 55/64 loss: -2.2773618698120117
Batch 56/64 loss: -2.2931108474731445
Batch 57/64 loss: -2.062802314758301
Batch 58/64 loss: -2.3787097930908203
Batch 59/64 loss: -2.248607635498047
Batch 60/64 loss: -2.324112892150879
Batch 61/64 loss: -2.078645706176758
Batch 62/64 loss: -2.2713193893432617
Batch 63/64 loss: -2.516826629638672
Batch 64/64 loss: -6.850305557250977
Epoch 126  Train loss: -2.2890189152137905  Val loss: -2.5010334552358517
Epoch 127
-------------------------------
Batch 1/64 loss: -2.4581212997436523
Batch 2/64 loss: -2.3400983810424805
Batch 3/64 loss: -2.522547721862793
Batch 4/64 loss: -2.580348014831543
Batch 5/64 loss: -2.455306053161621
Batch 6/64 loss: -1.648040771484375
Batch 7/64 loss: -2.231487274169922
Batch 8/64 loss: -1.8075799942016602
Batch 9/64 loss: -1.9752511978149414
Batch 10/64 loss: -2.1475019454956055
Batch 11/64 loss: -1.7319831848144531
Batch 12/64 loss: -2.2304210662841797
Batch 13/64 loss: -2.2105350494384766
Batch 14/64 loss: -2.277009963989258
Batch 15/64 loss: -2.0282115936279297
Batch 16/64 loss: -2.3969554901123047
Batch 17/64 loss: -2.1356658935546875
Batch 18/64 loss: -2.285573959350586
Batch 19/64 loss: -2.2649335861206055
Batch 20/64 loss: -2.3730926513671875
Batch 21/64 loss: -2.3767127990722656
Batch 22/64 loss: -2.10707950592041
Batch 23/64 loss: -2.1030445098876953
Batch 24/64 loss: -2.285630226135254
Batch 25/64 loss: -2.546781539916992
Batch 26/64 loss: -2.4445133209228516
Batch 27/64 loss: -2.3919754028320312
Batch 28/64 loss: -1.8657875061035156
Batch 29/64 loss: -2.391561508178711
Batch 30/64 loss: -2.3623971939086914
Batch 31/64 loss: -2.337268829345703
Batch 32/64 loss: -2.451483726501465
Batch 33/64 loss: -2.317333221435547
Batch 34/64 loss: -2.3567733764648438
Batch 35/64 loss: -2.3371353149414062
Batch 36/64 loss: -2.050326347351074
Batch 37/64 loss: -2.3085222244262695
Batch 38/64 loss: -1.8884973526000977
Batch 39/64 loss: -2.5248708724975586
Batch 40/64 loss: -2.2860307693481445
Batch 41/64 loss: -2.0740556716918945
Batch 42/64 loss: -1.9928579330444336
Batch 43/64 loss: -2.371432304382324
Batch 44/64 loss: -2.1213598251342773
Batch 45/64 loss: -2.452591896057129
Batch 46/64 loss: -2.3986949920654297
Batch 47/64 loss: -1.9892024993896484
Batch 48/64 loss: -2.36752986907959
Batch 49/64 loss: -2.378584861755371
Batch 50/64 loss: -1.8888530731201172
Batch 51/64 loss: -2.5216970443725586
Batch 52/64 loss: -2.473796844482422
Batch 53/64 loss: -2.3421478271484375
Batch 54/64 loss: -2.446756362915039
Batch 55/64 loss: -2.228703498840332
Batch 56/64 loss: -2.492621421813965
Batch 57/64 loss: -2.1079959869384766
Batch 58/64 loss: -2.32271671295166
Batch 59/64 loss: -2.443866729736328
Batch 60/64 loss: -2.4430036544799805
Batch 61/64 loss: -2.2093353271484375
Batch 62/64 loss: -1.674300193786621
Batch 63/64 loss: -2.378729820251465
Batch 64/64 loss: -6.856766700744629
Epoch 127  Train loss: -2.3074164708455402  Val loss: -2.4639382509841132
Epoch 128
-------------------------------
Batch 1/64 loss: -1.8815956115722656
Batch 2/64 loss: -2.082962989807129
Batch 3/64 loss: -2.387155532836914
Batch 4/64 loss: -2.424600601196289
Batch 5/64 loss: -2.0099573135375977
Batch 6/64 loss: -2.492791175842285
Batch 7/64 loss: -2.1674842834472656
Batch 8/64 loss: -2.617001533508301
Batch 9/64 loss: -2.1201066970825195
Batch 10/64 loss: -2.514206886291504
Batch 11/64 loss: -2.3437719345092773
Batch 12/64 loss: -2.0713319778442383
Batch 13/64 loss: -2.484463691711426
Batch 14/64 loss: -2.207942008972168
Batch 15/64 loss: -2.301910400390625
Batch 16/64 loss: -2.382495880126953
Batch 17/64 loss: -2.0898189544677734
Batch 18/64 loss: -2.4219284057617188
Batch 19/64 loss: -2.2664804458618164
Batch 20/64 loss: -2.038717269897461
Batch 21/64 loss: -1.7701988220214844
Batch 22/64 loss: -2.4126968383789062
Batch 23/64 loss: -2.190688133239746
Batch 24/64 loss: -2.4048080444335938
Batch 25/64 loss: -2.300813674926758
Batch 26/64 loss: -2.339437484741211
Batch 27/64 loss: -2.420987129211426
Batch 28/64 loss: -2.1786298751831055
Batch 29/64 loss: -2.1348628997802734
Batch 30/64 loss: -2.3706798553466797
Batch 31/64 loss: -1.9823637008666992
Batch 32/64 loss: -1.9933996200561523
Batch 33/64 loss: -2.3094310760498047
Batch 34/64 loss: -2.1555566787719727
Batch 35/64 loss: -2.236644744873047
Batch 36/64 loss: -2.2996416091918945
Batch 37/64 loss: -2.052454948425293
Batch 38/64 loss: -2.238986015319824
Batch 39/64 loss: -2.0504236221313477
Batch 40/64 loss: -2.3381290435791016
Batch 41/64 loss: -1.8088874816894531
Batch 42/64 loss: -2.203950881958008
Batch 43/64 loss: -2.2659921646118164
Batch 44/64 loss: -2.581681251525879
Batch 45/64 loss: -2.5749588012695312
Batch 46/64 loss: -1.6803979873657227
Batch 47/64 loss: -2.3184642791748047
Batch 48/64 loss: -2.356663703918457
Batch 49/64 loss: -2.5213375091552734
Batch 50/64 loss: -2.4068613052368164
Batch 51/64 loss: -2.260035514831543
Batch 52/64 loss: -2.3262062072753906
Batch 53/64 loss: -2.433539390563965
Batch 54/64 loss: -2.5031614303588867
Batch 55/64 loss: -2.2265138626098633
Batch 56/64 loss: -2.60268497467041
Batch 57/64 loss: -2.424896240234375
Batch 58/64 loss: -1.9645509719848633
Batch 59/64 loss: -1.5318269729614258
Batch 60/64 loss: -2.2857704162597656
Batch 61/64 loss: -2.1655540466308594
Batch 62/64 loss: -2.217167854309082
Batch 63/64 loss: -2.351917266845703
Batch 64/64 loss: -6.856051445007324
Epoch 128  Train loss: -2.300276337417902  Val loss: -2.5017443260376395
Epoch 129
-------------------------------
Batch 1/64 loss: -2.477703094482422
Batch 2/64 loss: -2.3176116943359375
Batch 3/64 loss: -2.447453498840332
Batch 4/64 loss: -1.9760236740112305
Batch 5/64 loss: -2.1141233444213867
Batch 6/64 loss: -2.5682201385498047
Batch 7/64 loss: -2.0288162231445312
Batch 8/64 loss: -2.421107292175293
Batch 9/64 loss: -2.325282096862793
Batch 10/64 loss: -2.4136667251586914
Batch 11/64 loss: -2.3674468994140625
Batch 12/64 loss: -2.265742301940918
Batch 13/64 loss: -2.2331762313842773
Batch 14/64 loss: -2.033078193664551
Batch 15/64 loss: -2.1915597915649414
Batch 16/64 loss: -2.0224227905273438
Batch 17/64 loss: -2.2922725677490234
Batch 18/64 loss: -2.1565914154052734
Batch 19/64 loss: -2.2500648498535156
Batch 20/64 loss: -2.3529891967773438
Batch 21/64 loss: -2.4748353958129883
Batch 22/64 loss: -2.434659004211426
Batch 23/64 loss: -1.953639030456543
Batch 24/64 loss: -2.2518911361694336
Batch 25/64 loss: -1.717315673828125
Batch 26/64 loss: -2.35105037689209
Batch 27/64 loss: -2.33095645904541
Batch 28/64 loss: -2.256373405456543
Batch 29/64 loss: -2.2234411239624023
Batch 30/64 loss: -2.201160430908203
Batch 31/64 loss: -2.0759668350219727
Batch 32/64 loss: -2.0031137466430664
Batch 33/64 loss: -2.266660690307617
Batch 34/64 loss: -2.2579946517944336
Batch 35/64 loss: -2.494966506958008
Batch 36/64 loss: -2.5852622985839844
Batch 37/64 loss: -2.1609907150268555
Batch 38/64 loss: -2.170599937438965
Batch 39/64 loss: -2.4725637435913086
Batch 40/64 loss: -2.569202423095703
Batch 41/64 loss: -2.372126579284668
Batch 42/64 loss: -2.1744565963745117
Batch 43/64 loss: -1.990896224975586
Batch 44/64 loss: -2.243577003479004
Batch 45/64 loss: -2.5284032821655273
Batch 46/64 loss: -2.582794189453125
Batch 47/64 loss: -2.3230695724487305
Batch 48/64 loss: -2.278696060180664
Batch 49/64 loss: -1.923563003540039
Batch 50/64 loss: -2.1439132690429688
Batch 51/64 loss: -2.5673046112060547
Batch 52/64 loss: -2.3204727172851562
Batch 53/64 loss: -2.4778900146484375
Batch 54/64 loss: -2.100587844848633
Batch 55/64 loss: -2.3915138244628906
Batch 56/64 loss: -2.2133426666259766
Batch 57/64 loss: -2.212299346923828
Batch 58/64 loss: -2.4066543579101562
Batch 59/64 loss: -2.331235885620117
Batch 60/64 loss: -2.4217329025268555
Batch 61/64 loss: -2.3198280334472656
Batch 62/64 loss: -2.4935503005981445
Batch 63/64 loss: -2.3340301513671875
Batch 64/64 loss: -6.889199256896973
Epoch 129  Train loss: -2.334538564495012  Val loss: -2.5511997655494927
Epoch 130
-------------------------------
Batch 1/64 loss: -2.6213560104370117
Batch 2/64 loss: -2.3686418533325195
Batch 3/64 loss: -2.2384986877441406
Batch 4/64 loss: -2.470534324645996
Batch 5/64 loss: -2.432549476623535
Batch 6/64 loss: -2.230118751525879
Batch 7/64 loss: -1.9592838287353516
Batch 8/64 loss: -2.3426246643066406
Batch 9/64 loss: -1.9533090591430664
Batch 10/64 loss: -2.2169036865234375
Batch 11/64 loss: -2.25521183013916
Batch 12/64 loss: -2.3929061889648438
Batch 13/64 loss: -2.3133859634399414
Batch 14/64 loss: -2.4091196060180664
Batch 15/64 loss: -2.4118824005126953
Batch 16/64 loss: -2.4737930297851562
Batch 17/64 loss: -2.247988700866699
Batch 18/64 loss: -2.34140682220459
Batch 19/64 loss: -2.268752098083496
Batch 20/64 loss: -2.559903144836426
Batch 21/64 loss: -2.3719844818115234
Batch 22/64 loss: -2.270541191101074
Batch 23/64 loss: -2.3773670196533203
Batch 24/64 loss: -2.2324790954589844
Batch 25/64 loss: -2.1528549194335938
Batch 26/64 loss: -2.2018699645996094
Batch 27/64 loss: -2.3639659881591797
Batch 28/64 loss: -2.4453468322753906
Batch 29/64 loss: -2.1447067260742188
Batch 30/64 loss: -2.404634475708008
Batch 31/64 loss: -2.52748966217041
Batch 32/64 loss: -2.1584205627441406
Batch 33/64 loss: -2.667797088623047
Batch 34/64 loss: -2.370037078857422
Batch 35/64 loss: -2.2271013259887695
Batch 36/64 loss: -2.6523656845092773
Batch 37/64 loss: -2.2470998764038086
Batch 38/64 loss: -2.186835289001465
Batch 39/64 loss: -2.083712577819824
Batch 40/64 loss: -2.2563323974609375
Batch 41/64 loss: -2.3917322158813477
Batch 42/64 loss: -2.231565475463867
Batch 43/64 loss: -2.3238143920898438
Batch 44/64 loss: -1.70458984375
Batch 45/64 loss: -2.4402332305908203
Batch 46/64 loss: -2.3133468627929688
Batch 47/64 loss: -2.6026620864868164
Batch 48/64 loss: -2.3121337890625
Batch 49/64 loss: -2.2090415954589844
Batch 50/64 loss: -2.298532485961914
Batch 51/64 loss: -2.09710693359375
Batch 52/64 loss: -2.5272417068481445
Batch 53/64 loss: -2.133997917175293
Batch 54/64 loss: -2.188296318054199
Batch 55/64 loss: -2.308023452758789
Batch 56/64 loss: -2.051039695739746
Batch 57/64 loss: -2.02316951751709
Batch 58/64 loss: -2.602773666381836
Batch 59/64 loss: -2.228168487548828
Batch 60/64 loss: -2.410144805908203
Batch 61/64 loss: -2.193739891052246
Batch 62/64 loss: -2.2804183959960938
Batch 63/64 loss: -2.302767753601074
Batch 64/64 loss: -6.466080188751221
Epoch 130  Train loss: -2.3509837337568693  Val loss: -2.52957867756742
Epoch 131
-------------------------------
Batch 1/64 loss: -2.3266353607177734
Batch 2/64 loss: -2.320384979248047
Batch 3/64 loss: -2.153925895690918
Batch 4/64 loss: -2.2215805053710938
Batch 5/64 loss: -2.608091354370117
Batch 6/64 loss: -2.333102226257324
Batch 7/64 loss: -2.6012163162231445
Batch 8/64 loss: -2.490668296813965
Batch 9/64 loss: -2.0346145629882812
Batch 10/64 loss: -2.310253143310547
Batch 11/64 loss: -2.4693708419799805
Batch 12/64 loss: -2.1923437118530273
Batch 13/64 loss: -2.237277030944824
Batch 14/64 loss: -2.436734199523926
Batch 15/64 loss: -2.4375715255737305
Batch 16/64 loss: -2.3629350662231445
Batch 17/64 loss: -2.0263633728027344
Batch 18/64 loss: -2.2399635314941406
Batch 19/64 loss: -2.4322376251220703
Batch 20/64 loss: -2.5511322021484375
Batch 21/64 loss: -2.5252246856689453
Batch 22/64 loss: -2.277031898498535
Batch 23/64 loss: -2.1537370681762695
Batch 24/64 loss: -2.4278745651245117
Batch 25/64 loss: -2.2650318145751953
Batch 26/64 loss: -2.0942087173461914
Batch 27/64 loss: -2.6172828674316406
Batch 28/64 loss: -2.3725852966308594
Batch 29/64 loss: -2.41135311126709
Batch 30/64 loss: -2.136166572570801
Batch 31/64 loss: -2.1320486068725586
Batch 32/64 loss: -2.3521461486816406
Batch 33/64 loss: -1.6902170181274414
Batch 34/64 loss: -2.5412416458129883
Batch 35/64 loss: -2.4486923217773438
Batch 36/64 loss: -2.1447219848632812
Batch 37/64 loss: -2.1242685317993164
Batch 38/64 loss: -2.2334470748901367
Batch 39/64 loss: -2.4505443572998047
Batch 40/64 loss: -2.486856460571289
Batch 41/64 loss: -2.313373565673828
Batch 42/64 loss: -2.2626123428344727
Batch 43/64 loss: -2.244866371154785
Batch 44/64 loss: -2.2148971557617188
Batch 45/64 loss: -2.3239212036132812
Batch 46/64 loss: -2.039149284362793
Batch 47/64 loss: -2.1528806686401367
Batch 48/64 loss: -2.396613121032715
Batch 49/64 loss: -2.414752960205078
Batch 50/64 loss: -2.3875083923339844
Batch 51/64 loss: -2.467595100402832
Batch 52/64 loss: -2.3417015075683594
Batch 53/64 loss: -2.6315526962280273
Batch 54/64 loss: -2.330145835876465
Batch 55/64 loss: -2.431674003601074
Batch 56/64 loss: -2.2502784729003906
Batch 57/64 loss: -2.4951601028442383
Batch 58/64 loss: -2.281759262084961
Batch 59/64 loss: -2.6150474548339844
Batch 60/64 loss: -2.6464319229125977
Batch 61/64 loss: -2.3186445236206055
Batch 62/64 loss: -2.405270576477051
Batch 63/64 loss: -2.2872352600097656
Batch 64/64 loss: -6.940886974334717
Epoch 131  Train loss: -2.3863501099979176  Val loss: -2.5179347664220226
Epoch 132
-------------------------------
Batch 1/64 loss: -2.60269832611084
Batch 2/64 loss: -2.0197458267211914
Batch 3/64 loss: -2.5226545333862305
Batch 4/64 loss: -2.2530126571655273
Batch 5/64 loss: -1.941049575805664
Batch 6/64 loss: -2.182140350341797
Batch 7/64 loss: -1.8205327987670898
Batch 8/64 loss: -2.362698554992676
Batch 9/64 loss: -2.3847341537475586
Batch 10/64 loss: -2.59423828125
Batch 11/64 loss: -2.4894466400146484
Batch 12/64 loss: -2.377261161804199
Batch 13/64 loss: -2.18709659576416
Batch 14/64 loss: -2.6085519790649414
Batch 15/64 loss: -2.5638160705566406
Batch 16/64 loss: -2.2095651626586914
Batch 17/64 loss: -2.3440332412719727
Batch 18/64 loss: -2.5249805450439453
Batch 19/64 loss: -1.9383268356323242
Batch 20/64 loss: -1.6496953964233398
Batch 21/64 loss: -2.4884891510009766
Batch 22/64 loss: -1.5010662078857422
Batch 23/64 loss: -2.525897979736328
Batch 24/64 loss: -2.527050018310547
Batch 25/64 loss: -2.019510269165039
Batch 26/64 loss: -2.3395214080810547
Batch 27/64 loss: -2.2792911529541016
Batch 28/64 loss: -2.297421455383301
Batch 29/64 loss: -2.421356201171875
Batch 30/64 loss: -2.3058958053588867
Batch 31/64 loss: -2.184432029724121
Batch 32/64 loss: -2.391519546508789
Batch 33/64 loss: -2.319303512573242
Batch 34/64 loss: -2.1301422119140625
Batch 35/64 loss: -2.2175073623657227
Batch 36/64 loss: -2.3826446533203125
Batch 37/64 loss: -2.4227523803710938
Batch 38/64 loss: -2.1284666061401367
Batch 39/64 loss: -2.527224540710449
Batch 40/64 loss: -2.2726593017578125
Batch 41/64 loss: -2.2179718017578125
Batch 42/64 loss: -2.244169235229492
Batch 43/64 loss: -2.279949188232422
Batch 44/64 loss: -2.037533760070801
Batch 45/64 loss: -2.2962465286254883
Batch 46/64 loss: -2.441099166870117
Batch 47/64 loss: -2.450808525085449
Batch 48/64 loss: -2.2696571350097656
Batch 49/64 loss: -2.5396242141723633
Batch 50/64 loss: -2.355231285095215
Batch 51/64 loss: -2.0381898880004883
Batch 52/64 loss: -2.3400678634643555
Batch 53/64 loss: -2.240523338317871
Batch 54/64 loss: -1.6777563095092773
Batch 55/64 loss: -2.415928840637207
Batch 56/64 loss: -2.2468643188476562
Batch 57/64 loss: -2.361368179321289
Batch 58/64 loss: -2.4952802658081055
Batch 59/64 loss: -2.346088409423828
Batch 60/64 loss: -2.3707408905029297
Batch 61/64 loss: -2.4684667587280273
Batch 62/64 loss: -2.3046178817749023
Batch 63/64 loss: -2.476064682006836
Batch 64/64 loss: -6.621774673461914
Epoch 132  Train loss: -2.3394354502360026  Val loss: -2.4254188537597656
Epoch 133
-------------------------------
Batch 1/64 loss: -2.2444658279418945
Batch 2/64 loss: -2.590388298034668
Batch 3/64 loss: -2.4448585510253906
Batch 4/64 loss: -2.4226455688476562
Batch 5/64 loss: -2.4587812423706055
Batch 6/64 loss: -2.345273971557617
Batch 7/64 loss: -2.313488006591797
Batch 8/64 loss: -2.328810691833496
Batch 9/64 loss: -2.095388412475586
Batch 10/64 loss: -2.455742835998535
Batch 11/64 loss: -2.6496267318725586
Batch 12/64 loss: -1.8871593475341797
Batch 13/64 loss: -2.361177444458008
Batch 14/64 loss: -2.0823183059692383
Batch 15/64 loss: -2.4331369400024414
Batch 16/64 loss: -2.170454978942871
Batch 17/64 loss: -2.1842079162597656
Batch 18/64 loss: -2.370941162109375
Batch 19/64 loss: -2.352388381958008
Batch 20/64 loss: -1.579716682434082
Batch 21/64 loss: -2.3307180404663086
Batch 22/64 loss: -2.2138843536376953
Batch 23/64 loss: -2.442448616027832
Batch 24/64 loss: -2.1950368881225586
Batch 25/64 loss: -2.5719785690307617
Batch 26/64 loss: -2.300166130065918
Batch 27/64 loss: -2.3572988510131836
Batch 28/64 loss: -1.9663896560668945
Batch 29/64 loss: -1.7613773345947266
Batch 30/64 loss: -2.0065994262695312
Batch 31/64 loss: -2.160311698913574
Batch 32/64 loss: -2.2631359100341797
Batch 33/64 loss: -2.3203582763671875
Batch 34/64 loss: -2.2072830200195312
Batch 35/64 loss: -2.3721437454223633
Batch 36/64 loss: -2.5958852767944336
Batch 37/64 loss: -2.0183353424072266
Batch 38/64 loss: -2.273038864135742
Batch 39/64 loss: -2.3498525619506836
Batch 40/64 loss: -2.351978302001953
Batch 41/64 loss: -2.009335517883301
Batch 42/64 loss: -2.0966081619262695
Batch 43/64 loss: -2.562746047973633
Batch 44/64 loss: -2.315945625305176
Batch 45/64 loss: -2.459418296813965
Batch 46/64 loss: -2.2145023345947266
Batch 47/64 loss: -2.0716333389282227
Batch 48/64 loss: -2.313849449157715
Batch 49/64 loss: -2.088041305541992
Batch 50/64 loss: -2.487088203430176
Batch 51/64 loss: -2.2184152603149414
Batch 52/64 loss: -2.409298896789551
Batch 53/64 loss: -2.1807126998901367
Batch 54/64 loss: -2.670973777770996
Batch 55/64 loss: -2.18636417388916
Batch 56/64 loss: -2.1650590896606445
Batch 57/64 loss: -2.3299713134765625
Batch 58/64 loss: -2.2863693237304688
Batch 59/64 loss: -2.0196638107299805
Batch 60/64 loss: -2.4824295043945312
Batch 61/64 loss: -2.340043067932129
Batch 62/64 loss: -2.13204288482666
Batch 63/64 loss: -2.0412492752075195
Batch 64/64 loss: -6.929806232452393
Epoch 133  Train loss: -2.3232675795461617  Val loss: -2.3581885898236146
Epoch 134
-------------------------------
Batch 1/64 loss: -2.0570478439331055
Batch 2/64 loss: -2.442784309387207
Batch 3/64 loss: -2.407414436340332
Batch 4/64 loss: -2.3041763305664062
Batch 5/64 loss: -2.6241025924682617
Batch 6/64 loss: -2.356417655944824
Batch 7/64 loss: -2.324152946472168
Batch 8/64 loss: -2.303805351257324
Batch 9/64 loss: -1.9744033813476562
Batch 10/64 loss: -2.663257598876953
Batch 11/64 loss: -2.184213638305664
Batch 12/64 loss: -2.0203027725219727
Batch 13/64 loss: -2.3231935501098633
Batch 14/64 loss: -2.338115692138672
Batch 15/64 loss: -2.340104103088379
Batch 16/64 loss: -2.039461135864258
Batch 17/64 loss: -2.4742021560668945
Batch 18/64 loss: -2.1021623611450195
Batch 19/64 loss: -1.9585256576538086
Batch 20/64 loss: -1.945662498474121
Batch 21/64 loss: -2.219829559326172
Batch 22/64 loss: -2.382598876953125
Batch 23/64 loss: -2.3950109481811523
Batch 24/64 loss: -2.3408432006835938
Batch 25/64 loss: -2.57047176361084
Batch 26/64 loss: -2.3734607696533203
Batch 27/64 loss: -2.173795700073242
Batch 28/64 loss: -2.3817996978759766
Batch 29/64 loss: -2.5605316162109375
Batch 30/64 loss: -2.554856300354004
Batch 31/64 loss: -2.3345375061035156
Batch 32/64 loss: -2.254423141479492
Batch 33/64 loss: -2.5859241485595703
Batch 34/64 loss: -2.033977508544922
Batch 35/64 loss: -2.0245161056518555
Batch 36/64 loss: -1.7488975524902344
Batch 37/64 loss: -2.3697071075439453
Batch 38/64 loss: -2.6089611053466797
Batch 39/64 loss: -2.309408187866211
Batch 40/64 loss: -2.411799430847168
Batch 41/64 loss: -2.243070602416992
Batch 42/64 loss: -2.5526018142700195
Batch 43/64 loss: -2.49639892578125
Batch 44/64 loss: -2.2288341522216797
Batch 45/64 loss: -2.451016426086426
Batch 46/64 loss: -2.5033302307128906
Batch 47/64 loss: -2.2233848571777344
Batch 48/64 loss: -2.285358428955078
Batch 49/64 loss: -2.5548505783081055
Batch 50/64 loss: -2.214885711669922
Batch 51/64 loss: -2.261425018310547
Batch 52/64 loss: -2.5332765579223633
Batch 53/64 loss: -2.1110315322875977
Batch 54/64 loss: -2.380986213684082
Batch 55/64 loss: -2.398646354675293
Batch 56/64 loss: -2.3094921112060547
Batch 57/64 loss: -2.5317678451538086
Batch 58/64 loss: -2.164534568786621
Batch 59/64 loss: -2.357858657836914
Batch 60/64 loss: -2.336618423461914
Batch 61/64 loss: -2.3204708099365234
Batch 62/64 loss: -2.401516914367676
Batch 63/64 loss: -2.054769515991211
Batch 64/64 loss: -6.356089115142822
Epoch 134  Train loss: -2.3608164600297514  Val loss: -2.517305564224925
Epoch 135
-------------------------------
Batch 1/64 loss: -2.5252695083618164
Batch 2/64 loss: -2.1522960662841797
Batch 3/64 loss: -2.264254570007324
Batch 4/64 loss: -2.6304140090942383
Batch 5/64 loss: -2.242182731628418
Batch 6/64 loss: -2.49167537689209
Batch 7/64 loss: -2.271486282348633
Batch 8/64 loss: -2.0713605880737305
Batch 9/64 loss: -1.8519067764282227
Batch 10/64 loss: -2.270723342895508
Batch 11/64 loss: -2.295577049255371
Batch 12/64 loss: -1.8541889190673828
Batch 13/64 loss: -2.0488157272338867
Batch 14/64 loss: -2.348287582397461
Batch 15/64 loss: -2.4255361557006836
Batch 16/64 loss: -2.447610855102539
Batch 17/64 loss: -2.304018974304199
Batch 18/64 loss: -2.501628875732422
Batch 19/64 loss: -2.2198991775512695
Batch 20/64 loss: -1.9675769805908203
Batch 21/64 loss: -2.705059051513672
Batch 22/64 loss: -2.416438102722168
Batch 23/64 loss: -2.395632743835449
Batch 24/64 loss: -2.2826671600341797
Batch 25/64 loss: -2.140247344970703
Batch 26/64 loss: -2.208857536315918
Batch 27/64 loss: -2.1852455139160156
Batch 28/64 loss: -2.290360450744629
Batch 29/64 loss: -2.3169546127319336
Batch 30/64 loss: -2.192840576171875
Batch 31/64 loss: -2.210233688354492
Batch 32/64 loss: -2.382139205932617
Batch 33/64 loss: -2.5784921646118164
Batch 34/64 loss: -2.399078369140625
Batch 35/64 loss: -2.3583717346191406
Batch 36/64 loss: -2.503814697265625
Batch 37/64 loss: -2.3815813064575195
Batch 38/64 loss: -2.2262086868286133
Batch 39/64 loss: -2.0074520111083984
Batch 40/64 loss: -2.392369270324707
Batch 41/64 loss: -2.5119094848632812
Batch 42/64 loss: -2.4715585708618164
Batch 43/64 loss: -1.7420568466186523
Batch 44/64 loss: -2.2229652404785156
Batch 45/64 loss: -2.361104965209961
Batch 46/64 loss: -2.305203437805176
Batch 47/64 loss: -2.188657760620117
Batch 48/64 loss: -2.268671989440918
Batch 49/64 loss: -2.5710134506225586
Batch 50/64 loss: -2.4806318283081055
Batch 51/64 loss: -2.36397647857666
Batch 52/64 loss: -1.9640169143676758
Batch 53/64 loss: -2.1450233459472656
Batch 54/64 loss: -2.2017431259155273
Batch 55/64 loss: -2.2283267974853516
Batch 56/64 loss: -2.487884521484375
Batch 57/64 loss: -2.2158584594726562
Batch 58/64 loss: -2.343395233154297
Batch 59/64 loss: -2.058971405029297
Batch 60/64 loss: -2.1964588165283203
Batch 61/64 loss: -2.534994125366211
Batch 62/64 loss: -2.1226396560668945
Batch 63/64 loss: -2.04520320892334
Batch 64/64 loss: -6.786505699157715
Epoch 135  Train loss: -2.335386646495146  Val loss: -2.46753455355405
Epoch 136
-------------------------------
Batch 1/64 loss: -2.287435531616211
Batch 2/64 loss: -2.536870002746582
Batch 3/64 loss: -2.1157312393188477
Batch 4/64 loss: -2.1827783584594727
Batch 5/64 loss: -2.4520444869995117
Batch 6/64 loss: -2.3665008544921875
Batch 7/64 loss: -2.548295021057129
Batch 8/64 loss: -1.8569488525390625
Batch 9/64 loss: -2.410618782043457
Batch 10/64 loss: -2.100186347961426
Batch 11/64 loss: -2.186382293701172
Batch 12/64 loss: -2.309030532836914
Batch 13/64 loss: -2.025113105773926
Batch 14/64 loss: -2.4693851470947266
Batch 15/64 loss: -2.200484275817871
Batch 16/64 loss: -2.265639305114746
Batch 17/64 loss: -2.4949913024902344
Batch 18/64 loss: -2.2791500091552734
Batch 19/64 loss: -2.584479331970215
Batch 20/64 loss: -2.229490280151367
Batch 21/64 loss: -2.2966203689575195
Batch 22/64 loss: -1.860015869140625
Batch 23/64 loss: -2.503162384033203
Batch 24/64 loss: -2.3590145111083984
Batch 25/64 loss: -2.478025436401367
Batch 26/64 loss: -2.1462478637695312
Batch 27/64 loss: -2.4676198959350586
Batch 28/64 loss: -2.272197723388672
Batch 29/64 loss: -2.0169153213500977
Batch 30/64 loss: -2.3686790466308594
Batch 31/64 loss: -2.321226119995117
Batch 32/64 loss: -2.128183364868164
Batch 33/64 loss: -1.8860788345336914
Batch 34/64 loss: -2.404623031616211
Batch 35/64 loss: -2.501495361328125
Batch 36/64 loss: -2.0317153930664062
Batch 37/64 loss: -2.253270149230957
Batch 38/64 loss: -2.2948989868164062
Batch 39/64 loss: -1.9211902618408203
Batch 40/64 loss: -2.5503673553466797
Batch 41/64 loss: -2.254582405090332
Batch 42/64 loss: -2.545294761657715
Batch 43/64 loss: -2.3789749145507812
Batch 44/64 loss: -2.007549285888672
Batch 45/64 loss: -2.4860830307006836
Batch 46/64 loss: -2.1820802688598633
Batch 47/64 loss: -2.2573251724243164
Batch 48/64 loss: -2.5401620864868164
Batch 49/64 loss: -2.440814971923828
Batch 50/64 loss: -2.4320812225341797
Batch 51/64 loss: -2.244818687438965
Batch 52/64 loss: -2.342705726623535
Batch 53/64 loss: -2.4589462280273438
Batch 54/64 loss: -2.3737010955810547
Batch 55/64 loss: -2.4742050170898438
Batch 56/64 loss: -2.471891403198242
Batch 57/64 loss: -2.3760318756103516
Batch 58/64 loss: -2.2624778747558594
Batch 59/64 loss: -2.513538360595703
Batch 60/64 loss: -2.2228498458862305
Batch 61/64 loss: -2.3713483810424805
Batch 62/64 loss: -2.254939079284668
Batch 63/64 loss: -2.271240234375
Batch 64/64 loss: -6.992520332336426
Epoch 136  Train loss: -2.358762894424738  Val loss: -2.4929302254902947
Epoch 137
-------------------------------
Batch 1/64 loss: -2.2818479537963867
Batch 2/64 loss: -2.4826745986938477
Batch 3/64 loss: -2.3683834075927734
Batch 4/64 loss: -2.5293331146240234
Batch 5/64 loss: -2.347811698913574
Batch 6/64 loss: -2.154364585876465
Batch 7/64 loss: -2.434718132019043
Batch 8/64 loss: -2.5345993041992188
Batch 9/64 loss: -2.415912628173828
Batch 10/64 loss: -2.3050050735473633
Batch 11/64 loss: -2.640133857727051
Batch 12/64 loss: -2.052159309387207
Batch 13/64 loss: -2.064154624938965
Batch 14/64 loss: -2.104546546936035
Batch 15/64 loss: -2.2613449096679688
Batch 16/64 loss: -2.345221519470215
Batch 17/64 loss: -2.2191295623779297
Batch 18/64 loss: -2.4941043853759766
Batch 19/64 loss: -2.26149845123291
Batch 20/64 loss: -2.1383934020996094
Batch 21/64 loss: -2.06912899017334
Batch 22/64 loss: -2.32150936126709
Batch 23/64 loss: -2.371975898742676
Batch 24/64 loss: -2.197617530822754
Batch 25/64 loss: -2.1745033264160156
Batch 26/64 loss: -2.4604644775390625
Batch 27/64 loss: -2.1898698806762695
Batch 28/64 loss: -2.3574352264404297
Batch 29/64 loss: -2.3447399139404297
Batch 30/64 loss: -2.41312313079834
Batch 31/64 loss: -2.529285430908203
Batch 32/64 loss: -2.6694631576538086
Batch 33/64 loss: -2.273935317993164
Batch 34/64 loss: -2.547806739807129
Batch 35/64 loss: -2.107968330383301
Batch 36/64 loss: -1.9083843231201172
Batch 37/64 loss: -2.5121545791625977
Batch 38/64 loss: -2.311185836791992
Batch 39/64 loss: -1.8891077041625977
Batch 40/64 loss: -2.379758834838867
Batch 41/64 loss: -2.141561508178711
Batch 42/64 loss: -2.285503387451172
Batch 43/64 loss: -2.4479122161865234
Batch 44/64 loss: -2.452768325805664
Batch 45/64 loss: -2.0494775772094727
Batch 46/64 loss: -2.4136438369750977
Batch 47/64 loss: -2.6480941772460938
Batch 48/64 loss: -2.343292236328125
Batch 49/64 loss: -2.052774429321289
Batch 50/64 loss: -2.4084692001342773
Batch 51/64 loss: -2.438481330871582
Batch 52/64 loss: -2.529229164123535
Batch 53/64 loss: -2.3082008361816406
Batch 54/64 loss: -2.4752235412597656
Batch 55/64 loss: -2.3193883895874023
Batch 56/64 loss: -2.4887571334838867
Batch 57/64 loss: -2.3246517181396484
Batch 58/64 loss: -2.2670955657958984
Batch 59/64 loss: -2.5621795654296875
Batch 60/64 loss: -2.542290687561035
Batch 61/64 loss: -2.417034149169922
Batch 62/64 loss: -2.3302125930786133
Batch 63/64 loss: -2.4968395233154297
Batch 64/64 loss: -6.341765880584717
Epoch 137  Train loss: -2.383751538220574  Val loss: -2.665645114334998
Saving best model, epoch: 137
Epoch 138
-------------------------------
Batch 1/64 loss: -2.0898237228393555
Batch 2/64 loss: -2.287228584289551
Batch 3/64 loss: -2.568385124206543
Batch 4/64 loss: -2.305398941040039
Batch 5/64 loss: -2.5296478271484375
Batch 6/64 loss: -2.6106767654418945
Batch 7/64 loss: -2.399928092956543
Batch 8/64 loss: -2.2518444061279297
Batch 9/64 loss: -2.548551559448242
Batch 10/64 loss: -2.365706443786621
Batch 11/64 loss: -2.295670509338379
Batch 12/64 loss: -2.140493392944336
Batch 13/64 loss: -2.6792736053466797
Batch 14/64 loss: -2.214284896850586
Batch 15/64 loss: -2.231961250305176
Batch 16/64 loss: -1.811971664428711
Batch 17/64 loss: -2.3260087966918945
Batch 18/64 loss: -2.4802656173706055
Batch 19/64 loss: -2.119678497314453
Batch 20/64 loss: -2.349276542663574
Batch 21/64 loss: -2.1999387741088867
Batch 22/64 loss: -2.3738393783569336
Batch 23/64 loss: -2.1896562576293945
Batch 24/64 loss: -2.3160343170166016
Batch 25/64 loss: -2.2194032669067383
Batch 26/64 loss: -2.5456085205078125
Batch 27/64 loss: -2.672390937805176
Batch 28/64 loss: -2.0704383850097656
Batch 29/64 loss: -2.4867382049560547
Batch 30/64 loss: -2.450737953186035
Batch 31/64 loss: -2.3573474884033203
Batch 32/64 loss: -2.0601911544799805
Batch 33/64 loss: -2.2196950912475586
Batch 34/64 loss: -2.4465465545654297
Batch 35/64 loss: -2.5080947875976562
Batch 36/64 loss: -2.327033042907715
Batch 37/64 loss: -2.4691953659057617
Batch 38/64 loss: -2.1390180587768555
Batch 39/64 loss: -2.407586097717285
Batch 40/64 loss: -2.2879257202148438
Batch 41/64 loss: -2.263570785522461
Batch 42/64 loss: -2.321122169494629
Batch 43/64 loss: -2.340951919555664
Batch 44/64 loss: -2.5380773544311523
Batch 45/64 loss: -1.9248933792114258
Batch 46/64 loss: -2.4428815841674805
Batch 47/64 loss: -2.5559377670288086
Batch 48/64 loss: -2.439826011657715
Batch 49/64 loss: -2.4877471923828125
Batch 50/64 loss: -2.458189010620117
Batch 51/64 loss: -2.475405693054199
Batch 52/64 loss: -2.0407238006591797
Batch 53/64 loss: -2.2180395126342773
Batch 54/64 loss: -2.559000015258789
Batch 55/64 loss: -2.315502166748047
Batch 56/64 loss: -2.509758949279785
Batch 57/64 loss: -2.3108606338500977
Batch 58/64 loss: -2.461745262145996
Batch 59/64 loss: -2.2625808715820312
Batch 60/64 loss: -2.1696014404296875
Batch 61/64 loss: -2.3763961791992188
Batch 62/64 loss: -2.5013484954833984
Batch 63/64 loss: -2.4066076278686523
Batch 64/64 loss: -6.750234603881836
Epoch 138  Train loss: -2.3968147352630016  Val loss: -2.53815371064386
Epoch 139
-------------------------------
Batch 1/64 loss: -1.9948205947875977
Batch 2/64 loss: -2.1719846725463867
Batch 3/64 loss: -2.133915901184082
Batch 4/64 loss: -2.5641536712646484
Batch 5/64 loss: -2.2175636291503906
Batch 6/64 loss: -2.5210657119750977
Batch 7/64 loss: -2.2609615325927734
Batch 8/64 loss: -2.3386402130126953
Batch 9/64 loss: -2.3780899047851562
Batch 10/64 loss: -2.3967809677124023
Batch 11/64 loss: -2.6548280715942383
Batch 12/64 loss: -2.2015581130981445
Batch 13/64 loss: -2.5211915969848633
Batch 14/64 loss: -2.4801597595214844
Batch 15/64 loss: -2.2543697357177734
Batch 16/64 loss: -2.403095245361328
Batch 17/64 loss: -2.5332460403442383
Batch 18/64 loss: -2.3123083114624023
Batch 19/64 loss: -2.3598318099975586
Batch 20/64 loss: -2.468273162841797
Batch 21/64 loss: -2.237971305847168
Batch 22/64 loss: -2.3631591796875
Batch 23/64 loss: -2.212526321411133
Batch 24/64 loss: -2.548460006713867
Batch 25/64 loss: -2.279179573059082
Batch 26/64 loss: -2.326897621154785
Batch 27/64 loss: -2.393047332763672
Batch 28/64 loss: -2.329068183898926
Batch 29/64 loss: -2.325529098510742
Batch 30/64 loss: -2.0417327880859375
Batch 31/64 loss: -2.16892147064209
Batch 32/64 loss: -2.3194580078125
Batch 33/64 loss: -2.3881683349609375
Batch 34/64 loss: -2.3882265090942383
Batch 35/64 loss: -2.396355628967285
Batch 36/64 loss: -2.3973188400268555
Batch 37/64 loss: -2.3720197677612305
Batch 38/64 loss: -2.444530487060547
Batch 39/64 loss: -2.3367719650268555
Batch 40/64 loss: -2.122875213623047
Batch 41/64 loss: -2.3176403045654297
Batch 42/64 loss: -1.98223876953125
Batch 43/64 loss: -1.9552192687988281
Batch 44/64 loss: -2.261810302734375
Batch 45/64 loss: -2.661623954772949
Batch 46/64 loss: -2.3003368377685547
Batch 47/64 loss: -2.4652624130249023
Batch 48/64 loss: -2.3588085174560547
Batch 49/64 loss: -2.4277191162109375
Batch 50/64 loss: -2.402345657348633
Batch 51/64 loss: -2.5318899154663086
Batch 52/64 loss: -2.3361120223999023
Batch 53/64 loss: -2.404749870300293
Batch 54/64 loss: -2.4727869033813477
Batch 55/64 loss: -2.497404098510742
Batch 56/64 loss: -2.6056299209594727
Batch 57/64 loss: -1.9973926544189453
Batch 58/64 loss: -2.474040985107422
Batch 59/64 loss: -1.8977737426757812
Batch 60/64 loss: -2.5553855895996094
Batch 61/64 loss: -2.3418445587158203
Batch 62/64 loss: -2.101405143737793
Batch 63/64 loss: -2.0379714965820312
Batch 64/64 loss: -7.064434051513672
Epoch 139  Train loss: -2.388153315525429  Val loss: -2.5921252011433498
Epoch 140
-------------------------------
Batch 1/64 loss: -2.468008041381836
Batch 2/64 loss: -2.4251041412353516
Batch 3/64 loss: -2.094167709350586
Batch 4/64 loss: -2.6844406127929688
Batch 5/64 loss: -2.28365421295166
Batch 6/64 loss: -2.254596710205078
Batch 7/64 loss: -2.3654022216796875
Batch 8/64 loss: -2.3475894927978516
Batch 9/64 loss: -2.461923599243164
Batch 10/64 loss: -2.441412925720215
Batch 11/64 loss: -2.4178218841552734
Batch 12/64 loss: -2.4920053482055664
Batch 13/64 loss: -2.506476402282715
Batch 14/64 loss: -2.2477025985717773
Batch 15/64 loss: -2.2479848861694336
Batch 16/64 loss: -2.3815364837646484
Batch 17/64 loss: -2.460635185241699
Batch 18/64 loss: -2.2470016479492188
Batch 19/64 loss: -2.2618961334228516
Batch 20/64 loss: -2.2973718643188477
Batch 21/64 loss: -2.371683120727539
Batch 22/64 loss: -2.271087646484375
Batch 23/64 loss: -2.5035781860351562
Batch 24/64 loss: -2.3851423263549805
Batch 25/64 loss: -2.5674047470092773
Batch 26/64 loss: -1.794642448425293
Batch 27/64 loss: -2.3950462341308594
Batch 28/64 loss: -2.5876150131225586
Batch 29/64 loss: -2.488856315612793
Batch 30/64 loss: -2.3463850021362305
Batch 31/64 loss: -2.370387077331543
Batch 32/64 loss: -2.2583141326904297
Batch 33/64 loss: -2.308269500732422
Batch 34/64 loss: -2.5197572708129883
Batch 35/64 loss: -2.197779655456543
Batch 36/64 loss: -2.355463981628418
Batch 37/64 loss: -2.2928876876831055
Batch 38/64 loss: -2.415557861328125
Batch 39/64 loss: -2.153414726257324
Batch 40/64 loss: -1.9228401184082031
Batch 41/64 loss: -1.8695735931396484
Batch 42/64 loss: -2.3022031784057617
Batch 43/64 loss: -2.431656837463379
Batch 44/64 loss: -2.457643508911133
Batch 45/64 loss: -2.4276933670043945
Batch 46/64 loss: -2.452946662902832
Batch 47/64 loss: -2.4866857528686523
Batch 48/64 loss: -2.535593032836914
Batch 49/64 loss: -2.0372886657714844
Batch 50/64 loss: -2.3737974166870117
Batch 51/64 loss: -2.4716930389404297
Batch 52/64 loss: -2.108088493347168
Batch 53/64 loss: -2.1866769790649414
Batch 54/64 loss: -2.1540918350219727
Batch 55/64 loss: -2.5982866287231445
Batch 56/64 loss: -2.2481021881103516
Batch 57/64 loss: -2.5889196395874023
Batch 58/64 loss: -2.469301223754883
Batch 59/64 loss: -2.469607353210449
Batch 60/64 loss: -1.9001684188842773
Batch 61/64 loss: -2.410806655883789
Batch 62/64 loss: -2.4130382537841797
Batch 63/64 loss: -2.288680076599121
Batch 64/64 loss: -6.992059707641602
Epoch 140  Train loss: -2.3971675723206762  Val loss: -2.5893151981314433
Epoch 141
-------------------------------
Batch 1/64 loss: -2.3135433197021484
Batch 2/64 loss: -2.066512107849121
Batch 3/64 loss: -2.2038793563842773
Batch 4/64 loss: -2.2452592849731445
Batch 5/64 loss: -2.4176836013793945
Batch 6/64 loss: -2.534616470336914
Batch 7/64 loss: -2.4113121032714844
Batch 8/64 loss: -2.46022891998291
Batch 9/64 loss: -2.4432544708251953
Batch 10/64 loss: -1.9807052612304688
Batch 11/64 loss: -2.3910770416259766
Batch 12/64 loss: -2.441131591796875
Batch 13/64 loss: -2.0880470275878906
Batch 14/64 loss: -2.199399948120117
Batch 15/64 loss: -2.383845329284668
Batch 16/64 loss: -2.475275993347168
Batch 17/64 loss: -2.234729766845703
Batch 18/64 loss: -2.3110342025756836
Batch 19/64 loss: -2.5185251235961914
Batch 20/64 loss: -2.7153921127319336
Batch 21/64 loss: -2.442803382873535
Batch 22/64 loss: -2.154587745666504
Batch 23/64 loss: -1.7671947479248047
Batch 24/64 loss: -2.3092517852783203
Batch 25/64 loss: -2.725442886352539
Batch 26/64 loss: -1.8296480178833008
Batch 27/64 loss: -2.5221900939941406
Batch 28/64 loss: -2.3585548400878906
Batch 29/64 loss: -2.6462574005126953
Batch 30/64 loss: -2.409252166748047
Batch 31/64 loss: -2.4479312896728516
Batch 32/64 loss: -2.1811695098876953
Batch 33/64 loss: -2.3856201171875
Batch 34/64 loss: -2.4485960006713867
Batch 35/64 loss: -2.2793407440185547
Batch 36/64 loss: -2.4126548767089844
Batch 37/64 loss: -2.544137954711914
Batch 38/64 loss: -2.382697105407715
Batch 39/64 loss: -2.414515495300293
Batch 40/64 loss: -2.4968204498291016
Batch 41/64 loss: -2.760547637939453
Batch 42/64 loss: -2.47721004486084
Batch 43/64 loss: -2.4089269638061523
Batch 44/64 loss: -2.1469812393188477
Batch 45/64 loss: -2.435683250427246
Batch 46/64 loss: -2.149266242980957
Batch 47/64 loss: -2.5608787536621094
Batch 48/64 loss: -2.3181591033935547
Batch 49/64 loss: -2.590362548828125
Batch 50/64 loss: -2.3522605895996094
Batch 51/64 loss: -2.242093086242676
Batch 52/64 loss: -2.6280460357666016
Batch 53/64 loss: -2.471517562866211
Batch 54/64 loss: -2.5380125045776367
Batch 55/64 loss: -2.388094902038574
Batch 56/64 loss: -2.2368879318237305
Batch 57/64 loss: -2.391551971435547
Batch 58/64 loss: -2.5067806243896484
Batch 59/64 loss: -2.1698875427246094
Batch 60/64 loss: -2.4856443405151367
Batch 61/64 loss: -2.277437210083008
Batch 62/64 loss: -2.583889961242676
Batch 63/64 loss: -2.078683853149414
Batch 64/64 loss: -6.994588851928711
Epoch 141  Train loss: -2.4225704342711207  Val loss: -2.6204436783938063
Epoch 142
-------------------------------
Batch 1/64 loss: -2.5412912368774414
Batch 2/64 loss: -2.498563766479492
Batch 3/64 loss: -2.4736757278442383
Batch 4/64 loss: -2.2270689010620117
Batch 5/64 loss: -2.4353275299072266
Batch 6/64 loss: -2.118678092956543
Batch 7/64 loss: -2.257796287536621
Batch 8/64 loss: -2.3852691650390625
Batch 9/64 loss: -2.332737922668457
Batch 10/64 loss: -2.3857126235961914
Batch 11/64 loss: -2.607624053955078
Batch 12/64 loss: -2.174957275390625
Batch 13/64 loss: -1.871678352355957
Batch 14/64 loss: -2.4497146606445312
Batch 15/64 loss: -2.557419776916504
Batch 16/64 loss: -2.6215438842773438
Batch 17/64 loss: -2.580280303955078
Batch 18/64 loss: -2.469052314758301
Batch 19/64 loss: -2.3359289169311523
Batch 20/64 loss: -2.492738723754883
Batch 21/64 loss: -2.3207807540893555
Batch 22/64 loss: -2.612118721008301
Batch 23/64 loss: -2.6662826538085938
Batch 24/64 loss: -2.6854496002197266
Batch 25/64 loss: -2.313748359680176
Batch 26/64 loss: -2.3853559494018555
Batch 27/64 loss: -2.4558916091918945
Batch 28/64 loss: -2.0807952880859375
Batch 29/64 loss: -2.0437774658203125
Batch 30/64 loss: -2.4919233322143555
Batch 31/64 loss: -2.241546630859375
Batch 32/64 loss: -1.9877195358276367
Batch 33/64 loss: -2.6295080184936523
Batch 34/64 loss: -2.299806594848633
Batch 35/64 loss: -2.4373350143432617
Batch 36/64 loss: -2.452341079711914
Batch 37/64 loss: -2.2877368927001953
Batch 38/64 loss: -2.164189338684082
Batch 39/64 loss: -2.185628890991211
Batch 40/64 loss: -2.2455263137817383
Batch 41/64 loss: -2.451907157897949
Batch 42/64 loss: -2.4248571395874023
Batch 43/64 loss: -2.194643974304199
Batch 44/64 loss: -2.4010868072509766
Batch 45/64 loss: -2.247905731201172
Batch 46/64 loss: -2.274510383605957
Batch 47/64 loss: -2.7198190689086914
Batch 48/64 loss: -2.5953760147094727
Batch 49/64 loss: -2.471524238586426
Batch 50/64 loss: -2.189939498901367
Batch 51/64 loss: -2.5809011459350586
Batch 52/64 loss: -2.4123458862304688
Batch 53/64 loss: -2.5439796447753906
Batch 54/64 loss: -2.6211280822753906
Batch 55/64 loss: -2.4273595809936523
Batch 56/64 loss: -2.1952667236328125
Batch 57/64 loss: -2.728949546813965
Batch 58/64 loss: -2.4811716079711914
Batch 59/64 loss: -2.2049293518066406
Batch 60/64 loss: -2.4868173599243164
Batch 61/64 loss: -2.5025577545166016
Batch 62/64 loss: -2.6531600952148438
Batch 63/64 loss: -2.4476499557495117
Batch 64/64 loss: -7.034585475921631
Epoch 142  Train loss: -2.4523646653867237  Val loss: -2.576989400018122
Epoch 143
-------------------------------
Batch 1/64 loss: -2.2355966567993164
Batch 2/64 loss: -2.68548583984375
Batch 3/64 loss: -1.9646148681640625
Batch 4/64 loss: -2.137327194213867
Batch 5/64 loss: -2.168635368347168
Batch 6/64 loss: -2.597731590270996
Batch 7/64 loss: -2.4912548065185547
Batch 8/64 loss: -2.4338178634643555
Batch 9/64 loss: -2.6066503524780273
Batch 10/64 loss: -2.6741323471069336
Batch 11/64 loss: -1.9234800338745117
Batch 12/64 loss: -2.3927383422851562
Batch 13/64 loss: -2.6942434310913086
Batch 14/64 loss: -2.498077392578125
Batch 15/64 loss: -2.402019500732422
Batch 16/64 loss: -2.407735824584961
Batch 17/64 loss: -2.5641603469848633
Batch 18/64 loss: -2.421280860900879
Batch 19/64 loss: -2.414224624633789
Batch 20/64 loss: -2.4312362670898438
Batch 21/64 loss: -2.629964828491211
Batch 22/64 loss: -2.4811906814575195
Batch 23/64 loss: -2.2339582443237305
Batch 24/64 loss: -2.0749149322509766
Batch 25/64 loss: -2.4891319274902344
Batch 26/64 loss: -2.531094551086426
Batch 27/64 loss: -2.323558807373047
Batch 28/64 loss: -2.393834114074707
Batch 29/64 loss: -2.158595085144043
Batch 30/64 loss: -2.6506528854370117
Batch 31/64 loss: -2.5794897079467773
Batch 32/64 loss: -2.259431838989258
Batch 33/64 loss: -2.4308958053588867
Batch 34/64 loss: -2.324509620666504
Batch 35/64 loss: -2.1367063522338867
Batch 36/64 loss: -1.9431343078613281
Batch 37/64 loss: -2.4515514373779297
Batch 38/64 loss: -2.4590492248535156
Batch 39/64 loss: -2.385176658630371
Batch 40/64 loss: -2.2104053497314453
Batch 41/64 loss: -2.3514108657836914
Batch 42/64 loss: -2.522921562194824
Batch 43/64 loss: -2.415530204772949
Batch 44/64 loss: -1.9711055755615234
Batch 45/64 loss: -2.544661521911621
Batch 46/64 loss: -2.3771286010742188
Batch 47/64 loss: -2.3898019790649414
Batch 48/64 loss: -2.5285720825195312
Batch 49/64 loss: -2.4506921768188477
Batch 50/64 loss: -2.1768369674682617
Batch 51/64 loss: -2.6349945068359375
Batch 52/64 loss: -2.3207836151123047
Batch 53/64 loss: -2.567326545715332
Batch 54/64 loss: -1.9561738967895508
Batch 55/64 loss: -2.6168527603149414
Batch 56/64 loss: -2.4224300384521484
Batch 57/64 loss: -2.698147773742676
Batch 58/64 loss: -2.53118896484375
Batch 59/64 loss: -2.1384811401367188
Batch 60/64 loss: -2.456955909729004
Batch 61/64 loss: -2.008211135864258
Batch 62/64 loss: -2.616297721862793
Batch 63/64 loss: -2.3451404571533203
Batch 64/64 loss: -6.927927017211914
Epoch 143  Train loss: -2.4396749982646866  Val loss: -2.5604537098678115
Epoch 144
-------------------------------
Batch 1/64 loss: -2.5262699127197266
Batch 2/64 loss: -2.513195037841797
Batch 3/64 loss: -2.5012130737304688
Batch 4/64 loss: -2.229656219482422
Batch 5/64 loss: -2.000983238220215
Batch 6/64 loss: -2.3836889266967773
Batch 7/64 loss: -2.231472969055176
Batch 8/64 loss: -2.459606170654297
Batch 9/64 loss: -2.579983711242676
Batch 10/64 loss: -2.4655094146728516
Batch 11/64 loss: -2.480001449584961
Batch 12/64 loss: -2.365920066833496
Batch 13/64 loss: -2.48854923248291
Batch 14/64 loss: -2.4135303497314453
Batch 15/64 loss: -2.3794870376586914
Batch 16/64 loss: -2.656553268432617
Batch 17/64 loss: -2.1416778564453125
Batch 18/64 loss: -2.393482208251953
Batch 19/64 loss: -2.6433897018432617
Batch 20/64 loss: -2.3234615325927734
Batch 21/64 loss: -2.3734941482543945
Batch 22/64 loss: -2.4523792266845703
Batch 23/64 loss: -2.4608335494995117
Batch 24/64 loss: -2.236177444458008
Batch 25/64 loss: -2.3953981399536133
Batch 26/64 loss: -2.3804569244384766
Batch 27/64 loss: -2.110316276550293
Batch 28/64 loss: -2.251066207885742
Batch 29/64 loss: -2.5879011154174805
Batch 30/64 loss: -2.406728744506836
Batch 31/64 loss: -2.27871036529541
Batch 32/64 loss: -2.3505172729492188
Batch 33/64 loss: -2.509945869445801
Batch 34/64 loss: -2.427122116088867
Batch 35/64 loss: -2.0199289321899414
Batch 36/64 loss: -2.2457199096679688
Batch 37/64 loss: -2.2026243209838867
Batch 38/64 loss: -1.9452838897705078
Batch 39/64 loss: -2.4894256591796875
Batch 40/64 loss: -2.4139089584350586
Batch 41/64 loss: -2.443605422973633
Batch 42/64 loss: -2.5325517654418945
Batch 43/64 loss: -2.5261621475219727
Batch 44/64 loss: -2.21539306640625
Batch 45/64 loss: -2.1106491088867188
Batch 46/64 loss: -2.223677635192871
Batch 47/64 loss: -1.8202457427978516
Batch 48/64 loss: -2.614360809326172
Batch 49/64 loss: -2.399521827697754
Batch 50/64 loss: -2.482022285461426
Batch 51/64 loss: -2.5779218673706055
Batch 52/64 loss: -2.2722949981689453
Batch 53/64 loss: -2.106717109680176
Batch 54/64 loss: -2.564507484436035
Batch 55/64 loss: -2.0217790603637695
Batch 56/64 loss: -2.409550666809082
Batch 57/64 loss: -2.2953643798828125
Batch 58/64 loss: -2.529294967651367
Batch 59/64 loss: -2.563953399658203
Batch 60/64 loss: -2.5384693145751953
Batch 61/64 loss: -2.469090461730957
Batch 62/64 loss: -2.445138931274414
Batch 63/64 loss: -2.3642988204956055
Batch 64/64 loss: -6.804272174835205
Epoch 144  Train loss: -2.4211034643883798  Val loss: -2.636524239766229
Epoch 145
-------------------------------
Batch 1/64 loss: -2.6487932205200195
Batch 2/64 loss: -2.1693992614746094
Batch 3/64 loss: -2.5059309005737305
Batch 4/64 loss: -2.5895137786865234
Batch 5/64 loss: -2.2448387145996094
Batch 6/64 loss: -2.2992773056030273
Batch 7/64 loss: -2.550138473510742
Batch 8/64 loss: -2.6639719009399414
Batch 9/64 loss: -2.4776878356933594
Batch 10/64 loss: -2.57785701751709
Batch 11/64 loss: -2.062453269958496
Batch 12/64 loss: -2.4734058380126953
Batch 13/64 loss: -2.265399932861328
Batch 14/64 loss: -2.3945112228393555
Batch 15/64 loss: -2.5042877197265625
Batch 16/64 loss: -2.376986503601074
Batch 17/64 loss: -2.583385467529297
Batch 18/64 loss: -2.5049686431884766
Batch 19/64 loss: -2.199551582336426
Batch 20/64 loss: -2.2904043197631836
Batch 21/64 loss: -2.2649621963500977
Batch 22/64 loss: -2.3953113555908203
Batch 23/64 loss: -2.4022769927978516
Batch 24/64 loss: -2.447338104248047
Batch 25/64 loss: -1.9733085632324219
Batch 26/64 loss: -2.2639503479003906
Batch 27/64 loss: -2.383420944213867
Batch 28/64 loss: -2.1914987564086914
Batch 29/64 loss: -2.759305953979492
Batch 30/64 loss: -2.19364070892334
Batch 31/64 loss: -2.690042495727539
Batch 32/64 loss: -2.048985481262207
Batch 33/64 loss: -2.1197166442871094
Batch 34/64 loss: -2.4068498611450195
Batch 35/64 loss: -2.624238967895508
Batch 36/64 loss: -2.2997541427612305
Batch 37/64 loss: -2.619932174682617
Batch 38/64 loss: -1.8152780532836914
Batch 39/64 loss: -2.4652652740478516
Batch 40/64 loss: -2.409921646118164
Batch 41/64 loss: -1.8560380935668945
Batch 42/64 loss: -2.1820497512817383
Batch 43/64 loss: -2.429140090942383
Batch 44/64 loss: -2.2971973419189453
Batch 45/64 loss: -1.9365005493164062
Batch 46/64 loss: -2.561387062072754
Batch 47/64 loss: -2.2915563583374023
Batch 48/64 loss: -2.5420026779174805
Batch 49/64 loss: -2.5517187118530273
Batch 50/64 loss: -2.500997543334961
Batch 51/64 loss: -2.5942468643188477
Batch 52/64 loss: -2.4730520248413086
Batch 53/64 loss: -2.602461814880371
Batch 54/64 loss: -2.4054880142211914
Batch 55/64 loss: -2.3954429626464844
Batch 56/64 loss: -2.0860586166381836
Batch 57/64 loss: -2.8498544692993164
Batch 58/64 loss: -2.2659082412719727
Batch 59/64 loss: -2.0593509674072266
Batch 60/64 loss: -2.149507522583008
Batch 61/64 loss: -2.326352119445801
Batch 62/64 loss: -2.1404495239257812
Batch 63/64 loss: -2.4063539505004883
Batch 64/64 loss: -7.029554843902588
Epoch 145  Train loss: -2.420910478105732  Val loss: -2.6016497267890224
Epoch 146
-------------------------------
Batch 1/64 loss: -2.254261016845703
Batch 2/64 loss: -2.3217344284057617
Batch 3/64 loss: -2.4421281814575195
Batch 4/64 loss: -2.580775260925293
Batch 5/64 loss: -2.306687355041504
Batch 6/64 loss: -2.547517776489258
Batch 7/64 loss: -1.9662914276123047
Batch 8/64 loss: -2.580866813659668
Batch 9/64 loss: -2.617133140563965
Batch 10/64 loss: -2.0224733352661133
Batch 11/64 loss: -2.2194108963012695
Batch 12/64 loss: -2.689854621887207
Batch 13/64 loss: -2.471409797668457
Batch 14/64 loss: -2.493515968322754
Batch 15/64 loss: -2.699522018432617
Batch 16/64 loss: -2.2503414154052734
Batch 17/64 loss: -2.5047855377197266
Batch 18/64 loss: -2.111124038696289
Batch 19/64 loss: -2.283956527709961
Batch 20/64 loss: -2.7752981185913086
Batch 21/64 loss: -2.528596878051758
Batch 22/64 loss: -2.494016647338867
Batch 23/64 loss: -2.5468101501464844
Batch 24/64 loss: -2.489834785461426
Batch 25/64 loss: -2.698002815246582
Batch 26/64 loss: -2.443998336791992
Batch 27/64 loss: -2.300553321838379
Batch 28/64 loss: -2.5048160552978516
Batch 29/64 loss: -2.1733922958374023
Batch 30/64 loss: -2.537933349609375
Batch 31/64 loss: -2.40567684173584
Batch 32/64 loss: -2.6379470825195312
Batch 33/64 loss: -2.536953926086426
Batch 34/64 loss: -2.284543991088867
Batch 35/64 loss: -1.7489852905273438
Batch 36/64 loss: -2.3837385177612305
Batch 37/64 loss: -2.0474119186401367
Batch 38/64 loss: -2.3102588653564453
Batch 39/64 loss: -2.2508249282836914
Batch 40/64 loss: -2.0758047103881836
Batch 41/64 loss: -2.490420341491699
Batch 42/64 loss: -2.3544015884399414
Batch 43/64 loss: -2.147716522216797
Batch 44/64 loss: -1.9993886947631836
Batch 45/64 loss: -2.0768442153930664
Batch 46/64 loss: -2.5937767028808594
Batch 47/64 loss: -1.908289909362793
Batch 48/64 loss: -2.2191715240478516
Batch 49/64 loss: -2.320406913757324
Batch 50/64 loss: -2.587582588195801
Batch 51/64 loss: -2.3162450790405273
Batch 52/64 loss: -2.1854124069213867
Batch 53/64 loss: -2.4538278579711914
Batch 54/64 loss: -2.3640995025634766
Batch 55/64 loss: -2.169682502746582
Batch 56/64 loss: -2.3733882904052734
Batch 57/64 loss: -2.2336435317993164
Batch 58/64 loss: -2.4490480422973633
Batch 59/64 loss: -2.3890609741210938
Batch 60/64 loss: -2.1605749130249023
Batch 61/64 loss: -2.379086494445801
Batch 62/64 loss: -2.281919479370117
Batch 63/64 loss: -2.3441314697265625
Batch 64/64 loss: -6.970625400543213
Epoch 146  Train loss: -2.408867089888629  Val loss: -2.419375599864422
Epoch 147
-------------------------------
Batch 1/64 loss: -2.4681434631347656
Batch 2/64 loss: -2.467526435852051
Batch 3/64 loss: -2.6041030883789062
Batch 4/64 loss: -2.1792144775390625
Batch 5/64 loss: -1.8699798583984375
Batch 6/64 loss: -2.5542993545532227
Batch 7/64 loss: -2.49259090423584
Batch 8/64 loss: -2.028188705444336
Batch 9/64 loss: -2.1332626342773438
Batch 10/64 loss: -2.1662702560424805
Batch 11/64 loss: -2.219202995300293
Batch 12/64 loss: -2.5088863372802734
Batch 13/64 loss: -2.136265754699707
Batch 14/64 loss: -2.4025049209594727
Batch 15/64 loss: -2.1410341262817383
Batch 16/64 loss: -1.979074478149414
Batch 17/64 loss: -2.48026180267334
Batch 18/64 loss: -2.1060962677001953
Batch 19/64 loss: -2.2238569259643555
Batch 20/64 loss: -2.780017852783203
Batch 21/64 loss: -2.2587623596191406
Batch 22/64 loss: -2.497931480407715
Batch 23/64 loss: -2.3766908645629883
Batch 24/64 loss: -2.321369171142578
Batch 25/64 loss: -2.4855613708496094
Batch 26/64 loss: -2.2031593322753906
Batch 27/64 loss: -2.247711181640625
Batch 28/64 loss: -2.4754209518432617
Batch 29/64 loss: -2.3730392456054688
Batch 30/64 loss: -2.2455835342407227
Batch 31/64 loss: -1.9302787780761719
Batch 32/64 loss: -2.5165205001831055
Batch 33/64 loss: -2.2726974487304688
Batch 34/64 loss: -2.275859832763672
Batch 35/64 loss: -2.4574594497680664
Batch 36/64 loss: -2.639401435852051
Batch 37/64 loss: -2.3458728790283203
Batch 38/64 loss: -2.2801742553710938
Batch 39/64 loss: -2.6055994033813477
Batch 40/64 loss: -2.2457237243652344
Batch 41/64 loss: -2.270756721496582
Batch 42/64 loss: -2.4947710037231445
Batch 43/64 loss: -2.504079818725586
Batch 44/64 loss: -2.4306602478027344
Batch 45/64 loss: -2.474921226501465
Batch 46/64 loss: -2.192753791809082
Batch 47/64 loss: -2.4629316329956055
Batch 48/64 loss: -2.4452037811279297
Batch 49/64 loss: -2.3728179931640625
Batch 50/64 loss: -2.3486433029174805
Batch 51/64 loss: -2.55972957611084
Batch 52/64 loss: -2.54073429107666
Batch 53/64 loss: -2.579228401184082
Batch 54/64 loss: -2.536850929260254
Batch 55/64 loss: -2.3673505783081055
Batch 56/64 loss: -2.4228458404541016
Batch 57/64 loss: -2.381406784057617
Batch 58/64 loss: -2.427243232727051
Batch 59/64 loss: -2.4024477005004883
Batch 60/64 loss: -2.4235143661499023
Batch 61/64 loss: -2.3822221755981445
Batch 62/64 loss: -2.5984582901000977
Batch 63/64 loss: -2.2230844497680664
Batch 64/64 loss: -7.026432514190674
Epoch 147  Train loss: -2.4173816213420793  Val loss: -2.613097344886806
Epoch 148
-------------------------------
Batch 1/64 loss: -2.646503448486328
Batch 2/64 loss: -2.3151912689208984
Batch 3/64 loss: -2.2929162979125977
Batch 4/64 loss: -2.3948869705200195
Batch 5/64 loss: -2.675914764404297
Batch 6/64 loss: -2.46268367767334
Batch 7/64 loss: -2.237351417541504
Batch 8/64 loss: -2.1248779296875
Batch 9/64 loss: -2.382295608520508
Batch 10/64 loss: -2.627535820007324
Batch 11/64 loss: -2.6457815170288086
Batch 12/64 loss: -2.3178653717041016
Batch 13/64 loss: -2.3968400955200195
Batch 14/64 loss: -2.437289237976074
Batch 15/64 loss: -2.4522762298583984
Batch 16/64 loss: -2.493640899658203
Batch 17/64 loss: -2.381241798400879
Batch 18/64 loss: -2.386758804321289
Batch 19/64 loss: -2.6630382537841797
Batch 20/64 loss: -2.3930768966674805
Batch 21/64 loss: -2.2726259231567383
Batch 22/64 loss: -2.40140438079834
Batch 23/64 loss: -2.2742624282836914
Batch 24/64 loss: -2.0902748107910156
Batch 25/64 loss: -2.2468910217285156
Batch 26/64 loss: -2.506199836730957
Batch 27/64 loss: -2.7209014892578125
Batch 28/64 loss: -2.4856386184692383
Batch 29/64 loss: -2.3203420639038086
Batch 30/64 loss: -2.3425512313842773
Batch 31/64 loss: -2.4218368530273438
Batch 32/64 loss: -2.5236854553222656
Batch 33/64 loss: -2.3694591522216797
Batch 34/64 loss: -2.595632553100586
Batch 35/64 loss: -2.2931060791015625
Batch 36/64 loss: -2.5831565856933594
Batch 37/64 loss: -2.42431640625
Batch 38/64 loss: -2.26088809967041
Batch 39/64 loss: -2.2885990142822266
Batch 40/64 loss: -2.5404415130615234
Batch 41/64 loss: -2.259775161743164
Batch 42/64 loss: -2.5995359420776367
Batch 43/64 loss: -2.441446304321289
Batch 44/64 loss: -2.5113868713378906
Batch 45/64 loss: -2.621408462524414
Batch 46/64 loss: -2.2104969024658203
Batch 47/64 loss: -2.28324031829834
Batch 48/64 loss: -2.4952220916748047
Batch 49/64 loss: -2.2584972381591797
Batch 50/64 loss: -2.2246246337890625
Batch 51/64 loss: -2.6192779541015625
Batch 52/64 loss: -2.0739059448242188
Batch 53/64 loss: -2.5308828353881836
Batch 54/64 loss: -2.3764638900756836
Batch 55/64 loss: -2.4505348205566406
Batch 56/64 loss: -2.2426576614379883
Batch 57/64 loss: -2.290999412536621
Batch 58/64 loss: -2.3053789138793945
Batch 59/64 loss: -2.1047096252441406
Batch 60/64 loss: -2.604093551635742
Batch 61/64 loss: -2.4389476776123047
Batch 62/64 loss: -2.47418212890625
Batch 63/64 loss: -2.239990234375
Batch 64/64 loss: -5.785859107971191
Epoch 148  Train loss: -2.442152670318005  Val loss: -2.574040154001557
Epoch 149
-------------------------------
Batch 1/64 loss: -2.610945701599121
Batch 2/64 loss: -2.61197566986084
Batch 3/64 loss: -2.3615989685058594
Batch 4/64 loss: -2.3824777603149414
Batch 5/64 loss: -2.5590553283691406
Batch 6/64 loss: -2.5645179748535156
Batch 7/64 loss: -2.4384193420410156
Batch 8/64 loss: -2.38739013671875
Batch 9/64 loss: -2.5245885848999023
Batch 10/64 loss: -2.560519218444824
Batch 11/64 loss: -2.29886531829834
Batch 12/64 loss: -2.36177921295166
Batch 13/64 loss: -2.22640323638916
Batch 14/64 loss: -2.4443750381469727
Batch 15/64 loss: -2.4954986572265625
Batch 16/64 loss: -2.165480613708496
Batch 17/64 loss: -2.4343156814575195
Batch 18/64 loss: -2.7069787979125977
Batch 19/64 loss: -2.4932022094726562
Batch 20/64 loss: -2.3905487060546875
Batch 21/64 loss: -2.430190086364746
Batch 22/64 loss: -2.4091739654541016
Batch 23/64 loss: -2.67861270904541
Batch 24/64 loss: -2.4406538009643555
Batch 25/64 loss: -2.365072250366211
Batch 26/64 loss: -2.5589609146118164
Batch 27/64 loss: -2.309309959411621
Batch 28/64 loss: -2.114567756652832
Batch 29/64 loss: -2.2538013458251953
Batch 30/64 loss: -2.44472599029541
Batch 31/64 loss: -2.3075132369995117
Batch 32/64 loss: -2.5192270278930664
Batch 33/64 loss: -2.1525440216064453
Batch 34/64 loss: -2.6472301483154297
Batch 35/64 loss: -2.3653182983398438
Batch 36/64 loss: -2.2115373611450195
Batch 37/64 loss: -2.410623550415039
Batch 38/64 loss: -1.8565425872802734
Batch 39/64 loss: -2.663144111633301
Batch 40/64 loss: -2.5114145278930664
Batch 41/64 loss: -2.1591062545776367
Batch 42/64 loss: -2.3424806594848633
Batch 43/64 loss: -2.406369209289551
Batch 44/64 loss: -2.4113779067993164
Batch 45/64 loss: -2.6418142318725586
Batch 46/64 loss: -2.1504955291748047
Batch 47/64 loss: -2.336798667907715
Batch 48/64 loss: -2.389934539794922
Batch 49/64 loss: -2.4227466583251953
Batch 50/64 loss: -2.001458168029785
Batch 51/64 loss: -2.002650260925293
Batch 52/64 loss: -2.116128921508789
Batch 53/64 loss: -2.507601737976074
Batch 54/64 loss: -2.6345529556274414
Batch 55/64 loss: -2.5748558044433594
Batch 56/64 loss: -2.466144561767578
Batch 57/64 loss: -2.0607643127441406
Batch 58/64 loss: -1.9546279907226562
Batch 59/64 loss: -2.41964054107666
Batch 60/64 loss: -2.5640039443969727
Batch 61/64 loss: -2.452519416809082
Batch 62/64 loss: -2.2805118560791016
Batch 63/64 loss: -2.2944774627685547
Batch 64/64 loss: -6.466956615447998
Epoch 149  Train loss: -2.433103982140036  Val loss: -2.631637848529619
Epoch 150
-------------------------------
Batch 1/64 loss: -2.225766181945801
Batch 2/64 loss: -2.5491228103637695
Batch 3/64 loss: -2.48590087890625
Batch 4/64 loss: -2.2303218841552734
Batch 5/64 loss: -2.50177001953125
Batch 6/64 loss: -2.459707260131836
Batch 7/64 loss: -2.21628475189209
Batch 8/64 loss: -2.4498214721679688
Batch 9/64 loss: -2.4818496704101562
Batch 10/64 loss: -2.831719398498535
Batch 11/64 loss: -2.402155876159668
Batch 12/64 loss: -2.3572282791137695
Batch 13/64 loss: -1.9456872940063477
Batch 14/64 loss: -2.4523239135742188
Batch 15/64 loss: -2.2139148712158203
Batch 16/64 loss: -2.2974510192871094
Batch 17/64 loss: -2.511188507080078
Batch 18/64 loss: -2.22263240814209
Batch 19/64 loss: -2.3426284790039062
Batch 20/64 loss: -2.573338508605957
Batch 21/64 loss: -2.7337942123413086
Batch 22/64 loss: -2.373067855834961
Batch 23/64 loss: -2.369110107421875
Batch 24/64 loss: -2.476048469543457
Batch 25/64 loss: -2.4298086166381836
Batch 26/64 loss: -2.4299278259277344
Batch 27/64 loss: -2.2943077087402344
Batch 28/64 loss: -2.484236717224121
Batch 29/64 loss: -2.5381088256835938
Batch 30/64 loss: -2.599048614501953
Batch 31/64 loss: -2.538930892944336
Batch 32/64 loss: -2.643556594848633
Batch 33/64 loss: -2.111295700073242
Batch 34/64 loss: -2.324403762817383
Batch 35/64 loss: -2.380133628845215
Batch 36/64 loss: -2.475703239440918
Batch 37/64 loss: -2.0833969116210938
Batch 38/64 loss: -2.2880125045776367
Batch 39/64 loss: -2.691638946533203
Batch 40/64 loss: -2.4067649841308594
Batch 41/64 loss: -2.456096649169922
Batch 42/64 loss: -2.4564647674560547
Batch 43/64 loss: -2.319183349609375
Batch 44/64 loss: -2.6511144638061523
Batch 45/64 loss: -2.2698774337768555
Batch 46/64 loss: -2.313155174255371
Batch 47/64 loss: -2.5595884323120117
Batch 48/64 loss: -2.4000844955444336
Batch 49/64 loss: -2.508793830871582
Batch 50/64 loss: -2.2036867141723633
Batch 51/64 loss: -2.423938751220703
Batch 52/64 loss: -2.5797252655029297
Batch 53/64 loss: -2.462643623352051
Batch 54/64 loss: -1.848724365234375
Batch 55/64 loss: -2.428424835205078
Batch 56/64 loss: -2.192058563232422
Batch 57/64 loss: -2.6588478088378906
Batch 58/64 loss: -2.1945714950561523
Batch 59/64 loss: -2.37725830078125
Batch 60/64 loss: -2.5948734283447266
Batch 61/64 loss: -1.9640388488769531
Batch 62/64 loss: -2.358452796936035
Batch 63/64 loss: -2.3015270233154297
Batch 64/64 loss: -6.786162376403809
Epoch 150  Train loss: -2.4476056753420363  Val loss: -2.5830020970085643
Epoch 151
-------------------------------
Batch 1/64 loss: -2.4610490798950195
Batch 2/64 loss: -2.1371259689331055
Batch 3/64 loss: -2.474867820739746
Batch 4/64 loss: -2.52219295501709
Batch 5/64 loss: -2.45703125
Batch 6/64 loss: -2.3928956985473633
Batch 7/64 loss: -2.3368148803710938
Batch 8/64 loss: -2.496462821960449
Batch 9/64 loss: -2.482206344604492
Batch 10/64 loss: -2.2760190963745117
Batch 11/64 loss: -2.5301828384399414
Batch 12/64 loss: -2.247309684753418
Batch 13/64 loss: -2.565948486328125
Batch 14/64 loss: -2.501620292663574
Batch 15/64 loss: -2.244168281555176
Batch 16/64 loss: -2.580693244934082
Batch 17/64 loss: -2.5830135345458984
Batch 18/64 loss: -2.136460304260254
Batch 19/64 loss: -2.4786291122436523
Batch 20/64 loss: -2.386045455932617
Batch 21/64 loss: -2.2872562408447266
Batch 22/64 loss: -2.336960792541504
Batch 23/64 loss: -2.4007062911987305
Batch 24/64 loss: -1.6848077774047852
Batch 25/64 loss: -2.3492021560668945
Batch 26/64 loss: -2.5557069778442383
Batch 27/64 loss: -2.045102119445801
Batch 28/64 loss: -2.3541555404663086
Batch 29/64 loss: -2.520505905151367
Batch 30/64 loss: -2.575179100036621
Batch 31/64 loss: -2.6898679733276367
Batch 32/64 loss: -1.976923942565918
Batch 33/64 loss: -2.452815055847168
Batch 34/64 loss: -2.400326728820801
Batch 35/64 loss: -2.7102832794189453
Batch 36/64 loss: -2.319502830505371
Batch 37/64 loss: -2.32700252532959
Batch 38/64 loss: -2.6023969650268555
Batch 39/64 loss: -2.189812660217285
Batch 40/64 loss: -2.3840560913085938
Batch 41/64 loss: -2.3554677963256836
Batch 42/64 loss: -2.3274078369140625
Batch 43/64 loss: -2.2657108306884766
Batch 44/64 loss: -2.400951385498047
Batch 45/64 loss: -2.385035514831543
Batch 46/64 loss: -2.5274171829223633
Batch 47/64 loss: -2.381580352783203
Batch 48/64 loss: -2.3260726928710938
Batch 49/64 loss: -1.9431257247924805
Batch 50/64 loss: -2.062380790710449
Batch 51/64 loss: -2.3738574981689453
Batch 52/64 loss: -2.3839855194091797
Batch 53/64 loss: -2.5030574798583984
Batch 54/64 loss: -2.224961280822754
Batch 55/64 loss: -2.458113670349121
Batch 56/64 loss: -2.3816299438476562
Batch 57/64 loss: -2.6332950592041016
Batch 58/64 loss: -2.6474294662475586
Batch 59/64 loss: -2.467294692993164
Batch 60/64 loss: -2.660341262817383
Batch 61/64 loss: -2.635631561279297
Batch 62/64 loss: -2.1239824295043945
Batch 63/64 loss: -2.317864418029785
Batch 64/64 loss: -6.7211174964904785
Epoch 151  Train loss: -2.4357763234306784  Val loss: -2.655337159985939
Epoch 152
-------------------------------
Batch 1/64 loss: -2.1800594329833984
Batch 2/64 loss: -2.5064077377319336
Batch 3/64 loss: -2.3359289169311523
Batch 4/64 loss: -2.3601503372192383
Batch 5/64 loss: -2.462193489074707
Batch 6/64 loss: -2.168705940246582
Batch 7/64 loss: -2.5896072387695312
Batch 8/64 loss: -2.4792709350585938
Batch 9/64 loss: -2.4753103256225586
Batch 10/64 loss: -2.5583133697509766
Batch 11/64 loss: -2.4456663131713867
Batch 12/64 loss: -2.2607345581054688
Batch 13/64 loss: -2.563068389892578
Batch 14/64 loss: -2.1601762771606445
Batch 15/64 loss: -2.1289901733398438
Batch 16/64 loss: -2.2542572021484375
Batch 17/64 loss: -2.586181640625
Batch 18/64 loss: -2.3670997619628906
Batch 19/64 loss: -2.4743614196777344
Batch 20/64 loss: -2.5929689407348633
Batch 21/64 loss: -1.9659605026245117
Batch 22/64 loss: -2.46176815032959
Batch 23/64 loss: -2.351217269897461
Batch 24/64 loss: -2.6922035217285156
Batch 25/64 loss: -2.433455467224121
Batch 26/64 loss: -2.5496788024902344
Batch 27/64 loss: -2.421370506286621
Batch 28/64 loss: -2.508547782897949
Batch 29/64 loss: -2.2414979934692383
Batch 30/64 loss: -2.473031997680664
Batch 31/64 loss: -2.441250801086426
Batch 32/64 loss: -2.53102970123291
Batch 33/64 loss: -2.4229297637939453
Batch 34/64 loss: -2.4480981826782227
Batch 35/64 loss: -2.4851417541503906
Batch 36/64 loss: -2.7161808013916016
Batch 37/64 loss: -2.3078250885009766
Batch 38/64 loss: -2.420781135559082
Batch 39/64 loss: -1.7283668518066406
Batch 40/64 loss: -2.5175466537475586
Batch 41/64 loss: -2.7557125091552734
Batch 42/64 loss: -2.455681800842285
Batch 43/64 loss: -2.5561599731445312
Batch 44/64 loss: -2.667363166809082
Batch 45/64 loss: -2.622372627258301
Batch 46/64 loss: -2.2355175018310547
Batch 47/64 loss: -2.1780967712402344
Batch 48/64 loss: -2.5261125564575195
Batch 49/64 loss: -2.3327627182006836
Batch 50/64 loss: -2.217235565185547
Batch 51/64 loss: -2.4332733154296875
Batch 52/64 loss: -2.5243473052978516
Batch 53/64 loss: -2.42624568939209
Batch 54/64 loss: -2.5253543853759766
Batch 55/64 loss: -2.4017343521118164
Batch 56/64 loss: -2.587714195251465
Batch 57/64 loss: -2.012798309326172
Batch 58/64 loss: -2.451258659362793
Batch 59/64 loss: -2.4380531311035156
Batch 60/64 loss: -2.5410728454589844
Batch 61/64 loss: -2.442180633544922
Batch 62/64 loss: -2.631654739379883
Batch 63/64 loss: -2.310399055480957
Batch 64/64 loss: -6.590914249420166
Epoch 152  Train loss: -2.467194080352783  Val loss: -2.628047458084998
Epoch 153
-------------------------------
Batch 1/64 loss: -2.3551511764526367
Batch 2/64 loss: -2.5853681564331055
Batch 3/64 loss: -2.606438636779785
Batch 4/64 loss: -2.543269157409668
Batch 5/64 loss: -2.5466928482055664
Batch 6/64 loss: -2.5548229217529297
Batch 7/64 loss: -2.487612724304199
Batch 8/64 loss: -2.2504472732543945
Batch 9/64 loss: -2.1978607177734375
Batch 10/64 loss: -2.4739608764648438
Batch 11/64 loss: -2.3972902297973633
Batch 12/64 loss: -2.15944766998291
Batch 13/64 loss: -2.297952651977539
Batch 14/64 loss: -2.6006832122802734
Batch 15/64 loss: -2.636138916015625
Batch 16/64 loss: -2.108797073364258
Batch 17/64 loss: -2.4315900802612305
Batch 18/64 loss: -2.5193233489990234
Batch 19/64 loss: -2.5474472045898438
Batch 20/64 loss: -2.4100828170776367
Batch 21/64 loss: -2.622586250305176
Batch 22/64 loss: -2.3916873931884766
Batch 23/64 loss: -2.6586904525756836
Batch 24/64 loss: -2.4222030639648438
Batch 25/64 loss: -2.545156478881836
Batch 26/64 loss: -2.645199775695801
Batch 27/64 loss: -2.5727920532226562
Batch 28/64 loss: -2.30313777923584
Batch 29/64 loss: -2.1696996688842773
Batch 30/64 loss: -2.228095054626465
Batch 31/64 loss: -2.1825695037841797
Batch 32/64 loss: -2.2680130004882812
Batch 33/64 loss: -2.5313796997070312
Batch 34/64 loss: -2.312591552734375
Batch 35/64 loss: -2.737246513366699
Batch 36/64 loss: -2.06246280670166
Batch 37/64 loss: -2.5678415298461914
Batch 38/64 loss: -2.5442447662353516
Batch 39/64 loss: -1.8242788314819336
Batch 40/64 loss: -2.134200096130371
Batch 41/64 loss: -2.271538734436035
Batch 42/64 loss: -2.4941158294677734
Batch 43/64 loss: -2.479928970336914
Batch 44/64 loss: -2.302621841430664
Batch 45/64 loss: -2.434515953063965
Batch 46/64 loss: -2.580291748046875
Batch 47/64 loss: -2.5075607299804688
Batch 48/64 loss: -2.3396968841552734
Batch 49/64 loss: -2.5271387100219727
Batch 50/64 loss: -2.4863452911376953
Batch 51/64 loss: -2.1270322799682617
Batch 52/64 loss: -2.529118537902832
Batch 53/64 loss: -2.640146255493164
Batch 54/64 loss: -2.5180492401123047
Batch 55/64 loss: -2.2582807540893555
Batch 56/64 loss: -2.4439964294433594
Batch 57/64 loss: -2.421664237976074
Batch 58/64 loss: -2.272690773010254
Batch 59/64 loss: -2.36917781829834
Batch 60/64 loss: -2.1811304092407227
Batch 61/64 loss: -2.35611629486084
Batch 62/64 loss: -2.3327178955078125
Batch 63/64 loss: -2.320420265197754
Batch 64/64 loss: -6.861178874969482
Epoch 153  Train loss: -2.4592099451551253  Val loss: -2.614485409661257
Epoch 154
-------------------------------
Batch 1/64 loss: -2.4279184341430664
Batch 2/64 loss: -2.2895469665527344
Batch 3/64 loss: -2.1663875579833984
Batch 4/64 loss: -2.496480941772461
Batch 5/64 loss: -2.4279890060424805
Batch 6/64 loss: -2.3966007232666016
Batch 7/64 loss: -2.1481876373291016
Batch 8/64 loss: -2.3171768188476562
Batch 9/64 loss: -2.5158586502075195
Batch 10/64 loss: -2.468203544616699
Batch 11/64 loss: -2.3289690017700195
Batch 12/64 loss: -2.5152969360351562
Batch 13/64 loss: -2.3419809341430664
Batch 14/64 loss: -2.2655582427978516
Batch 15/64 loss: -2.4156837463378906
Batch 16/64 loss: -1.9662342071533203
Batch 17/64 loss: -2.200183868408203
Batch 18/64 loss: -2.682109832763672
Batch 19/64 loss: -2.6563825607299805
Batch 20/64 loss: -2.648066520690918
Batch 21/64 loss: -2.462773323059082
Batch 22/64 loss: -2.381214141845703
Batch 23/64 loss: -2.6740026473999023
Batch 24/64 loss: -2.59487247467041
Batch 25/64 loss: -2.4007978439331055
Batch 26/64 loss: -2.0368576049804688
Batch 27/64 loss: -2.5418081283569336
Batch 28/64 loss: -2.425814628601074
Batch 29/64 loss: -2.611125946044922
Batch 30/64 loss: -2.489482879638672
Batch 31/64 loss: -2.602163314819336
Batch 32/64 loss: -2.254673957824707
Batch 33/64 loss: -2.4228830337524414
Batch 34/64 loss: -2.409982681274414
Batch 35/64 loss: -2.515544891357422
Batch 36/64 loss: -2.381566047668457
Batch 37/64 loss: -2.5188112258911133
Batch 38/64 loss: -2.4561614990234375
Batch 39/64 loss: -2.401124954223633
Batch 40/64 loss: -2.6048030853271484
Batch 41/64 loss: -2.424321174621582
Batch 42/64 loss: -2.2562875747680664
Batch 43/64 loss: -2.123140335083008
Batch 44/64 loss: -2.4164609909057617
Batch 45/64 loss: -2.632600784301758
Batch 46/64 loss: -2.6828060150146484
Batch 47/64 loss: -2.5594663619995117
Batch 48/64 loss: -2.4246912002563477
Batch 49/64 loss: -2.431386947631836
Batch 50/64 loss: -2.485529899597168
Batch 51/64 loss: -2.4543018341064453
Batch 52/64 loss: -1.8603572845458984
Batch 53/64 loss: -2.57047176361084
Batch 54/64 loss: -2.4702539443969727
Batch 55/64 loss: -2.3522653579711914
Batch 56/64 loss: -2.553408622741699
Batch 57/64 loss: -2.232088088989258
Batch 58/64 loss: -2.7324066162109375
Batch 59/64 loss: -2.3979930877685547
Batch 60/64 loss: -2.4417476654052734
Batch 61/64 loss: -2.6470861434936523
Batch 62/64 loss: -2.575815200805664
Batch 63/64 loss: -2.219668388366699
Batch 64/64 loss: -7.091497421264648
Epoch 154  Train loss: -2.4803836672913793  Val loss: -2.6461504251276913
Epoch 155
-------------------------------
Batch 1/64 loss: -2.2843713760375977
Batch 2/64 loss: -2.0003271102905273
Batch 3/64 loss: -2.3401870727539062
Batch 4/64 loss: -2.7358016967773438
Batch 5/64 loss: -2.3433332443237305
Batch 6/64 loss: -2.463193893432617
Batch 7/64 loss: -2.67568302154541
Batch 8/64 loss: -2.562906265258789
Batch 9/64 loss: -2.5333690643310547
Batch 10/64 loss: -2.692070960998535
Batch 11/64 loss: -2.663529396057129
Batch 12/64 loss: -2.658534049987793
Batch 13/64 loss: -2.3364334106445312
Batch 14/64 loss: -2.6044673919677734
Batch 15/64 loss: -2.6933374404907227
Batch 16/64 loss: -2.392300605773926
Batch 17/64 loss: -2.443791389465332
Batch 18/64 loss: -1.8879833221435547
Batch 19/64 loss: -2.2631988525390625
Batch 20/64 loss: -2.4066505432128906
Batch 21/64 loss: -2.404852867126465
Batch 22/64 loss: -2.2999258041381836
Batch 23/64 loss: -2.442812919616699
Batch 24/64 loss: -2.528925895690918
Batch 25/64 loss: -2.3230791091918945
Batch 26/64 loss: -2.4977102279663086
Batch 27/64 loss: -2.6135454177856445
Batch 28/64 loss: -2.39003849029541
Batch 29/64 loss: -2.430628776550293
Batch 30/64 loss: -2.244405746459961
Batch 31/64 loss: -2.5882720947265625
Batch 32/64 loss: -2.4969892501831055
Batch 33/64 loss: -2.2585630416870117
Batch 34/64 loss: -2.2688684463500977
Batch 35/64 loss: -2.4756336212158203
Batch 36/64 loss: -2.1824655532836914
Batch 37/64 loss: -2.4056873321533203
Batch 38/64 loss: -2.556032180786133
Batch 39/64 loss: -2.3954668045043945
Batch 40/64 loss: -2.4164628982543945
Batch 41/64 loss: -2.634291648864746
Batch 42/64 loss: -2.45965576171875
Batch 43/64 loss: -2.473202705383301
Batch 44/64 loss: -2.3536911010742188
Batch 45/64 loss: -2.1993751525878906
Batch 46/64 loss: -2.5544042587280273
Batch 47/64 loss: -2.28570556640625
Batch 48/64 loss: -2.7408571243286133
Batch 49/64 loss: -2.311741828918457
Batch 50/64 loss: -2.391634941101074
Batch 51/64 loss: -2.27401065826416
Batch 52/64 loss: -2.2896690368652344
Batch 53/64 loss: -2.5738563537597656
Batch 54/64 loss: -2.338602066040039
Batch 55/64 loss: -2.5960779190063477
Batch 56/64 loss: -2.7820663452148438
Batch 57/64 loss: -2.4098215103149414
Batch 58/64 loss: -2.639009475708008
Batch 59/64 loss: -2.272104263305664
Batch 60/64 loss: -2.2528867721557617
Batch 61/64 loss: -2.668290138244629
Batch 62/64 loss: -2.362518310546875
Batch 63/64 loss: -2.548731803894043
Batch 64/64 loss: -7.082005023956299
Epoch 155  Train loss: -2.492949727002312  Val loss: -2.6397630750518486
Epoch 156
-------------------------------
Batch 1/64 loss: -2.4563560485839844
Batch 2/64 loss: -2.7233734130859375
Batch 3/64 loss: -2.6426496505737305
Batch 4/64 loss: -2.445134162902832
Batch 5/64 loss: -2.5033721923828125
Batch 6/64 loss: -2.539888381958008
Batch 7/64 loss: -2.6546993255615234
Batch 8/64 loss: -2.715970993041992
Batch 9/64 loss: -2.5515546798706055
Batch 10/64 loss: -2.1814565658569336
Batch 11/64 loss: -2.31949520111084
Batch 12/64 loss: -2.140317916870117
Batch 13/64 loss: -2.5854721069335938
Batch 14/64 loss: -2.408846855163574
Batch 15/64 loss: -2.4276351928710938
Batch 16/64 loss: -2.3676204681396484
Batch 17/64 loss: -2.4183740615844727
Batch 18/64 loss: -2.6541709899902344
Batch 19/64 loss: -2.692347526550293
Batch 20/64 loss: -2.6861038208007812
Batch 21/64 loss: -2.4240074157714844
Batch 22/64 loss: -2.5796728134155273
Batch 23/64 loss: -2.2384204864501953
Batch 24/64 loss: -2.221188545227051
Batch 25/64 loss: -2.547207832336426
Batch 26/64 loss: -2.57000732421875
Batch 27/64 loss: -2.306708335876465
Batch 28/64 loss: -2.2579832077026367
Batch 29/64 loss: -2.41971492767334
Batch 30/64 loss: -2.2821531295776367
Batch 31/64 loss: -2.4446897506713867
Batch 32/64 loss: -2.617341995239258
Batch 33/64 loss: -2.3637027740478516
Batch 34/64 loss: -2.238645553588867
Batch 35/64 loss: -2.662745475769043
Batch 36/64 loss: -2.6419382095336914
Batch 37/64 loss: -2.5536251068115234
Batch 38/64 loss: -2.5936803817749023
Batch 39/64 loss: -2.2091197967529297
Batch 40/64 loss: -2.4455785751342773
Batch 41/64 loss: -2.1818742752075195
Batch 42/64 loss: -2.5989303588867188
Batch 43/64 loss: -2.738332748413086
Batch 44/64 loss: -2.491204261779785
Batch 45/64 loss: -2.1581687927246094
Batch 46/64 loss: -2.61464786529541
Batch 47/64 loss: -2.5285558700561523
Batch 48/64 loss: -2.4786605834960938
Batch 49/64 loss: -2.4640378952026367
Batch 50/64 loss: -2.582782745361328
Batch 51/64 loss: -2.6312217712402344
Batch 52/64 loss: -2.186854362487793
Batch 53/64 loss: -2.6169519424438477
Batch 54/64 loss: -2.7230358123779297
Batch 55/64 loss: -2.485154151916504
Batch 56/64 loss: -2.4391469955444336
Batch 57/64 loss: -2.470341682434082
Batch 58/64 loss: -2.1175928115844727
Batch 59/64 loss: -2.2232465744018555
Batch 60/64 loss: -2.3141374588012695
Batch 61/64 loss: -2.695794105529785
Batch 62/64 loss: -2.375607490539551
Batch 63/64 loss: -2.491191864013672
Batch 64/64 loss: -6.609755992889404
Epoch 156  Train loss: -2.514474676169601  Val loss: -2.5411117527493086
Epoch 157
-------------------------------
Batch 1/64 loss: -2.376924514770508
Batch 2/64 loss: -1.855733871459961
Batch 3/64 loss: -2.5471839904785156
Batch 4/64 loss: -2.225597381591797
Batch 5/64 loss: -2.4856624603271484
Batch 6/64 loss: -2.5705432891845703
Batch 7/64 loss: -2.3444948196411133
Batch 8/64 loss: -2.659883499145508
Batch 9/64 loss: -2.4811105728149414
Batch 10/64 loss: -2.3924741744995117
Batch 11/64 loss: -2.2400131225585938
Batch 12/64 loss: -2.414522171020508
Batch 13/64 loss: -2.192028045654297
Batch 14/64 loss: -2.411264419555664
Batch 15/64 loss: -2.518425941467285
Batch 16/64 loss: -2.4018068313598633
Batch 17/64 loss: -2.3049631118774414
Batch 18/64 loss: -2.442281723022461
Batch 19/64 loss: -2.6126317977905273
Batch 20/64 loss: -2.370941162109375
Batch 21/64 loss: -2.5534019470214844
Batch 22/64 loss: -2.4481000900268555
Batch 23/64 loss: -2.3561201095581055
Batch 24/64 loss: -2.613877296447754
Batch 25/64 loss: -2.7047691345214844
Batch 26/64 loss: -2.556920051574707
Batch 27/64 loss: -2.4374141693115234
Batch 28/64 loss: -2.5073089599609375
Batch 29/64 loss: -2.2341842651367188
Batch 30/64 loss: -2.3553266525268555
Batch 31/64 loss: -2.264944076538086
Batch 32/64 loss: -2.61093807220459
Batch 33/64 loss: -2.50576114654541
Batch 34/64 loss: -2.637019157409668
Batch 35/64 loss: -2.4870128631591797
Batch 36/64 loss: -2.637789726257324
Batch 37/64 loss: -2.557375907897949
Batch 38/64 loss: -2.8218994140625
Batch 39/64 loss: -2.4929895401000977
Batch 40/64 loss: -2.552586555480957
Batch 41/64 loss: -2.3091087341308594
Batch 42/64 loss: -2.655858039855957
Batch 43/64 loss: -2.5109901428222656
Batch 44/64 loss: -2.401762008666992
Batch 45/64 loss: -2.4770984649658203
Batch 46/64 loss: -2.6736679077148438
Batch 47/64 loss: -1.8171815872192383
Batch 48/64 loss: -2.509979248046875
Batch 49/64 loss: -2.175980567932129
Batch 50/64 loss: -2.6050634384155273
Batch 51/64 loss: -2.5799293518066406
Batch 52/64 loss: -2.5606374740600586
Batch 53/64 loss: -2.395967483520508
Batch 54/64 loss: -2.38747501373291
Batch 55/64 loss: -2.370610237121582
Batch 56/64 loss: -2.6388673782348633
Batch 57/64 loss: -2.4462594985961914
Batch 58/64 loss: -2.6011743545532227
Batch 59/64 loss: -2.30490779876709
Batch 60/64 loss: -2.534377098083496
Batch 61/64 loss: -2.410402297973633
Batch 62/64 loss: -2.5818281173706055
Batch 63/64 loss: -2.5272216796875
Batch 64/64 loss: -6.950320720672607
Epoch 157  Train loss: -2.5078166980369416  Val loss: -2.6483791915002146
Epoch 158
-------------------------------
Batch 1/64 loss: -2.483400344848633
Batch 2/64 loss: -2.5677566528320312
Batch 3/64 loss: -2.536566734313965
Batch 4/64 loss: -2.468231201171875
Batch 5/64 loss: -2.632981300354004
Batch 6/64 loss: -2.4433441162109375
Batch 7/64 loss: -2.525348663330078
Batch 8/64 loss: -2.3059120178222656
Batch 9/64 loss: -1.8038549423217773
Batch 10/64 loss: -2.648068428039551
Batch 11/64 loss: -2.452763557434082
Batch 12/64 loss: -2.203144073486328
Batch 13/64 loss: -2.3348913192749023
Batch 14/64 loss: -2.657094955444336
Batch 15/64 loss: -2.687875747680664
Batch 16/64 loss: -2.4834728240966797
Batch 17/64 loss: -2.199237823486328
Batch 18/64 loss: -2.624781608581543
Batch 19/64 loss: -2.6377782821655273
Batch 20/64 loss: -2.5609560012817383
Batch 21/64 loss: -2.4986915588378906
Batch 22/64 loss: -2.4384641647338867
Batch 23/64 loss: -2.5992679595947266
Batch 24/64 loss: -2.3385009765625
Batch 25/64 loss: -2.291501998901367
Batch 26/64 loss: -2.528827667236328
Batch 27/64 loss: -2.5529098510742188
Batch 28/64 loss: -2.018416404724121
Batch 29/64 loss: -2.4504451751708984
Batch 30/64 loss: -2.369584083557129
Batch 31/64 loss: -2.625380516052246
Batch 32/64 loss: -2.5854997634887695
Batch 33/64 loss: -2.1126575469970703
Batch 34/64 loss: -2.421809196472168
Batch 35/64 loss: -2.187610626220703
Batch 36/64 loss: -2.418837547302246
Batch 37/64 loss: -2.0723085403442383
Batch 38/64 loss: -2.214138984680176
Batch 39/64 loss: -2.0690765380859375
Batch 40/64 loss: -2.505809783935547
Batch 41/64 loss: -2.2423019409179688
Batch 42/64 loss: -2.273036003112793
Batch 43/64 loss: -2.484316825866699
Batch 44/64 loss: -2.371654510498047
Batch 45/64 loss: -2.231954574584961
Batch 46/64 loss: -2.0290699005126953
Batch 47/64 loss: -1.9392261505126953
Batch 48/64 loss: -2.6255950927734375
Batch 49/64 loss: -2.604062080383301
Batch 50/64 loss: -2.3118371963500977
Batch 51/64 loss: -2.4261646270751953
Batch 52/64 loss: -2.4238204956054688
Batch 53/64 loss: -2.522449493408203
Batch 54/64 loss: -2.179056167602539
Batch 55/64 loss: -2.5709848403930664
Batch 56/64 loss: -2.3453750610351562
Batch 57/64 loss: -2.606647491455078
Batch 58/64 loss: -2.6254796981811523
Batch 59/64 loss: -2.5030384063720703
Batch 60/64 loss: -2.5036230087280273
Batch 61/64 loss: -2.6377954483032227
Batch 62/64 loss: -2.4603652954101562
Batch 63/64 loss: -2.463960647583008
Batch 64/64 loss: -6.989633560180664
Epoch 158  Train loss: -2.465588072234509  Val loss: -2.6823610259904895
Saving best model, epoch: 158
Epoch 159
-------------------------------
Batch 1/64 loss: -2.627913475036621
Batch 2/64 loss: -2.152484893798828
Batch 3/64 loss: -2.375490188598633
Batch 4/64 loss: -2.4897890090942383
Batch 5/64 loss: -2.671976089477539
Batch 6/64 loss: -2.2141332626342773
Batch 7/64 loss: -2.4311599731445312
Batch 8/64 loss: -2.4883804321289062
Batch 9/64 loss: -2.4482240676879883
Batch 10/64 loss: -2.70059871673584
Batch 11/64 loss: -2.5152292251586914
Batch 12/64 loss: -2.753361701965332
Batch 13/64 loss: -2.2865867614746094
Batch 14/64 loss: -2.5233030319213867
Batch 15/64 loss: -1.8861207962036133
Batch 16/64 loss: -2.0612611770629883
Batch 17/64 loss: -2.4973411560058594
Batch 18/64 loss: -2.3753232955932617
Batch 19/64 loss: -2.5679616928100586
Batch 20/64 loss: -2.4916505813598633
Batch 21/64 loss: -2.6016111373901367
Batch 22/64 loss: -2.429229736328125
Batch 23/64 loss: -2.5619001388549805
Batch 24/64 loss: -2.4728784561157227
Batch 25/64 loss: -2.4387922286987305
Batch 26/64 loss: -2.466275215148926
Batch 27/64 loss: -2.69931697845459
Batch 28/64 loss: -2.545546531677246
Batch 29/64 loss: -2.3606529235839844
Batch 30/64 loss: -2.490041732788086
Batch 31/64 loss: -2.351896286010742
Batch 32/64 loss: -2.226994514465332
Batch 33/64 loss: -2.578280448913574
Batch 34/64 loss: -2.542698860168457
Batch 35/64 loss: -2.493227958679199
Batch 36/64 loss: -2.6097803115844727
Batch 37/64 loss: -2.553741455078125
Batch 38/64 loss: -2.750152587890625
Batch 39/64 loss: -2.2704343795776367
Batch 40/64 loss: -2.6699399948120117
Batch 41/64 loss: -1.6452951431274414
Batch 42/64 loss: -2.5565147399902344
Batch 43/64 loss: -1.9342317581176758
Batch 44/64 loss: -2.30001163482666
Batch 45/64 loss: -2.2909059524536133
Batch 46/64 loss: -2.6562423706054688
Batch 47/64 loss: -2.3573312759399414
Batch 48/64 loss: -2.1645965576171875
Batch 49/64 loss: -2.5589065551757812
Batch 50/64 loss: -2.6231393814086914
Batch 51/64 loss: -2.512399673461914
Batch 52/64 loss: -2.52239990234375
Batch 53/64 loss: -2.541482925415039
Batch 54/64 loss: -1.5593185424804688
Batch 55/64 loss: -2.108856201171875
Batch 56/64 loss: -2.5988292694091797
Batch 57/64 loss: -2.255828857421875
Batch 58/64 loss: -2.4432249069213867
Batch 59/64 loss: -1.973496437072754
Batch 60/64 loss: -2.572676658630371
Batch 61/64 loss: -2.6212244033813477
Batch 62/64 loss: -2.232440948486328
Batch 63/64 loss: -2.397991180419922
Batch 64/64 loss: -6.735604286193848
Epoch 159  Train loss: -2.465109488543342  Val loss: -2.67516796203823
Epoch 160
-------------------------------
Batch 1/64 loss: -2.2124223709106445
Batch 2/64 loss: -2.466944694519043
Batch 3/64 loss: -2.412721633911133
Batch 4/64 loss: -2.3731918334960938
Batch 5/64 loss: -2.135880470275879
Batch 6/64 loss: -2.3824262619018555
Batch 7/64 loss: -2.6433029174804688
Batch 8/64 loss: -2.437786102294922
Batch 9/64 loss: -2.469405174255371
Batch 10/64 loss: -2.6063051223754883
Batch 11/64 loss: -2.4799985885620117
Batch 12/64 loss: -2.5655012130737305
Batch 13/64 loss: -2.038166046142578
Batch 14/64 loss: -2.4177417755126953
Batch 15/64 loss: -2.560267448425293
Batch 16/64 loss: -2.4944019317626953
Batch 17/64 loss: -2.499009132385254
Batch 18/64 loss: -2.2340087890625
Batch 19/64 loss: -2.539705276489258
Batch 20/64 loss: -2.607205390930176
Batch 21/64 loss: -2.631816864013672
Batch 22/64 loss: -2.2150421142578125
Batch 23/64 loss: -2.4954538345336914
Batch 24/64 loss: -2.5259199142456055
Batch 25/64 loss: -2.141085624694824
Batch 26/64 loss: -2.3719730377197266
Batch 27/64 loss: -2.2173852920532227
Batch 28/64 loss: -2.5564661026000977
Batch 29/64 loss: -2.5186195373535156
Batch 30/64 loss: -2.5679121017456055
Batch 31/64 loss: -2.3172874450683594
Batch 32/64 loss: -2.192948341369629
Batch 33/64 loss: -2.4136056900024414
Batch 34/64 loss: -2.499098777770996
Batch 35/64 loss: -2.581284523010254
Batch 36/64 loss: -2.2682857513427734
Batch 37/64 loss: -2.5223922729492188
Batch 38/64 loss: -2.5986337661743164
Batch 39/64 loss: -2.504605293273926
Batch 40/64 loss: -2.52211856842041
Batch 41/64 loss: -2.5223188400268555
Batch 42/64 loss: -2.5608081817626953
Batch 43/64 loss: -2.4651565551757812
Batch 44/64 loss: -2.4552440643310547
Batch 45/64 loss: -2.60446834564209
Batch 46/64 loss: -2.3218936920166016
Batch 47/64 loss: -2.622159004211426
Batch 48/64 loss: -2.146038055419922
Batch 49/64 loss: -2.632730484008789
Batch 50/64 loss: -2.6310901641845703
Batch 51/64 loss: -2.598484992980957
Batch 52/64 loss: -2.4066343307495117
Batch 53/64 loss: -2.4049196243286133
Batch 54/64 loss: -2.075773239135742
Batch 55/64 loss: -2.533207893371582
Batch 56/64 loss: -2.377438545227051
Batch 57/64 loss: -2.3590564727783203
Batch 58/64 loss: -2.447634696960449
Batch 59/64 loss: -2.4519357681274414
Batch 60/64 loss: -2.1206016540527344
Batch 61/64 loss: -2.5485754013061523
Batch 62/64 loss: -2.387491226196289
Batch 63/64 loss: -2.2784929275512695
Batch 64/64 loss: -7.020484924316406
Epoch 160  Train loss: -2.485581880457261  Val loss: -2.5759906965432706
Epoch 161
-------------------------------
Batch 1/64 loss: -2.5765609741210938
Batch 2/64 loss: -2.52036190032959
Batch 3/64 loss: -2.4359092712402344
Batch 4/64 loss: -2.1555709838867188
Batch 5/64 loss: -2.300107002258301
Batch 6/64 loss: -2.2054080963134766
Batch 7/64 loss: -2.148061752319336
Batch 8/64 loss: -2.3196592330932617
Batch 9/64 loss: -2.6267080307006836
Batch 10/64 loss: -2.49582576751709
Batch 11/64 loss: -2.0133581161499023
Batch 12/64 loss: -2.181332588195801
Batch 13/64 loss: -2.4434337615966797
Batch 14/64 loss: -2.6598052978515625
Batch 15/64 loss: -2.426711082458496
Batch 16/64 loss: -2.0680856704711914
Batch 17/64 loss: -2.483919143676758
Batch 18/64 loss: -2.6099853515625
Batch 19/64 loss: -2.364476203918457
Batch 20/64 loss: -2.317255973815918
Batch 21/64 loss: -2.4079437255859375
Batch 22/64 loss: -2.6191349029541016
Batch 23/64 loss: -2.5357866287231445
Batch 24/64 loss: -2.52178955078125
Batch 25/64 loss: -2.5317306518554688
Batch 26/64 loss: -2.6080713272094727
Batch 27/64 loss: -2.6268606185913086
Batch 28/64 loss: -2.505051612854004
Batch 29/64 loss: -2.362699508666992
Batch 30/64 loss: -2.6977720260620117
Batch 31/64 loss: -2.5361194610595703
Batch 32/64 loss: -2.1847591400146484
Batch 33/64 loss: -2.50506591796875
Batch 34/64 loss: -2.654452323913574
Batch 35/64 loss: -2.5293216705322266
Batch 36/64 loss: -2.447840690612793
Batch 37/64 loss: -2.3442087173461914
Batch 38/64 loss: -2.4935131072998047
Batch 39/64 loss: -2.1727781295776367
Batch 40/64 loss: -2.1647253036499023
Batch 41/64 loss: -2.4407520294189453
Batch 42/64 loss: -2.462897300720215
Batch 43/64 loss: -2.2400121688842773
Batch 44/64 loss: -2.5463180541992188
Batch 45/64 loss: -2.0462942123413086
Batch 46/64 loss: -2.4176273345947266
Batch 47/64 loss: -2.3852033615112305
Batch 48/64 loss: -2.4719982147216797
Batch 49/64 loss: -2.4576187133789062
Batch 50/64 loss: -2.5451974868774414
Batch 51/64 loss: -2.4087162017822266
Batch 52/64 loss: -2.040860176086426
Batch 53/64 loss: -2.3201704025268555
Batch 54/64 loss: -2.125080108642578
Batch 55/64 loss: -2.520517349243164
Batch 56/64 loss: -2.531867027282715
Batch 57/64 loss: -2.322338104248047
Batch 58/64 loss: -2.406468391418457
Batch 59/64 loss: -2.3779773712158203
Batch 60/64 loss: -2.154216766357422
Batch 61/64 loss: -2.2251291275024414
Batch 62/64 loss: -2.095616340637207
Batch 63/64 loss: -2.3041372299194336
Batch 64/64 loss: -6.852565288543701
Epoch 161  Train loss: -2.4437427240259506  Val loss: -2.7269706201717208
Saving best model, epoch: 161
Epoch 162
-------------------------------
Batch 1/64 loss: -2.471311569213867
Batch 2/64 loss: -2.5803041458129883
Batch 3/64 loss: -2.6021671295166016
Batch 4/64 loss: -2.37014102935791
Batch 5/64 loss: -2.5400466918945312
Batch 6/64 loss: -2.362401008605957
Batch 7/64 loss: -2.597039222717285
Batch 8/64 loss: -2.0904197692871094
Batch 9/64 loss: -2.4989328384399414
Batch 10/64 loss: -2.6519241333007812
Batch 11/64 loss: -2.1706228256225586
Batch 12/64 loss: -2.1528854370117188
Batch 13/64 loss: -2.1827468872070312
Batch 14/64 loss: -2.6835527420043945
Batch 15/64 loss: -2.563932418823242
Batch 16/64 loss: -2.274796485900879
Batch 17/64 loss: -2.4871063232421875
Batch 18/64 loss: -1.842635154724121
Batch 19/64 loss: -2.555239677429199
Batch 20/64 loss: -2.25445556640625
Batch 21/64 loss: -2.5392837524414062
Batch 22/64 loss: -2.4664440155029297
Batch 23/64 loss: -2.3018360137939453
Batch 24/64 loss: -2.3611574172973633
Batch 25/64 loss: -2.239835739135742
Batch 26/64 loss: -2.394563674926758
Batch 27/64 loss: -2.179379463195801
Batch 28/64 loss: -2.496042251586914
Batch 29/64 loss: -2.600719451904297
Batch 30/64 loss: -2.4520626068115234
Batch 31/64 loss: -2.54489803314209
Batch 32/64 loss: -2.5325984954833984
Batch 33/64 loss: -2.3873376846313477
Batch 34/64 loss: -2.570502281188965
Batch 35/64 loss: -2.450162887573242
Batch 36/64 loss: -2.213589668273926
Batch 37/64 loss: -2.6858816146850586
Batch 38/64 loss: -2.5768566131591797
Batch 39/64 loss: -2.163454055786133
Batch 40/64 loss: -2.717182159423828
Batch 41/64 loss: -2.556546211242676
Batch 42/64 loss: -2.3625659942626953
Batch 43/64 loss: -2.4317054748535156
Batch 44/64 loss: -2.501877784729004
Batch 45/64 loss: -2.3365478515625
Batch 46/64 loss: -2.3701982498168945
Batch 47/64 loss: -2.1983566284179688
Batch 48/64 loss: -2.428399085998535
Batch 49/64 loss: -2.5738143920898438
Batch 50/64 loss: -2.5454187393188477
Batch 51/64 loss: -2.514878273010254
Batch 52/64 loss: -2.634889602661133
Batch 53/64 loss: -2.162721633911133
Batch 54/64 loss: -2.671846389770508
Batch 55/64 loss: -2.5452194213867188
Batch 56/64 loss: -2.6152687072753906
Batch 57/64 loss: -2.357271194458008
Batch 58/64 loss: -2.5502614974975586
Batch 59/64 loss: -2.523797035217285
Batch 60/64 loss: -2.650510787963867
Batch 61/64 loss: -2.5247507095336914
Batch 62/64 loss: -2.23569393157959
Batch 63/64 loss: -2.4729089736938477
Batch 64/64 loss: -6.701675891876221
Epoch 162  Train loss: -2.4878141870685653  Val loss: -2.6638288727330997
Epoch 163
-------------------------------
Batch 1/64 loss: -2.4024839401245117
Batch 2/64 loss: -2.556797981262207
Batch 3/64 loss: -2.5189075469970703
Batch 4/64 loss: -2.130857467651367
Batch 5/64 loss: -2.6271514892578125
Batch 6/64 loss: -2.440079689025879
Batch 7/64 loss: -2.4747819900512695
Batch 8/64 loss: -2.199483871459961
Batch 9/64 loss: -2.6206960678100586
Batch 10/64 loss: -2.6202802658081055
Batch 11/64 loss: -2.003188133239746
Batch 12/64 loss: -2.3998117446899414
Batch 13/64 loss: -2.4788389205932617
Batch 14/64 loss: -2.60709285736084
Batch 15/64 loss: -2.328584671020508
Batch 16/64 loss: -2.4931182861328125
Batch 17/64 loss: -2.5312938690185547
Batch 18/64 loss: -2.6701345443725586
Batch 19/64 loss: -2.5432958602905273
Batch 20/64 loss: -2.4629735946655273
Batch 21/64 loss: -2.5610275268554688
Batch 22/64 loss: -2.6311216354370117
Batch 23/64 loss: -2.1731691360473633
Batch 24/64 loss: -2.439634323120117
Batch 25/64 loss: -2.5226402282714844
Batch 26/64 loss: -2.568368911743164
Batch 27/64 loss: -2.602663040161133
Batch 28/64 loss: -2.252882957458496
Batch 29/64 loss: -2.62796688079834
Batch 30/64 loss: -2.273130416870117
Batch 31/64 loss: -2.6401710510253906
Batch 32/64 loss: -2.63985538482666
Batch 33/64 loss: -2.257208824157715
Batch 34/64 loss: -2.260045051574707
Batch 35/64 loss: -2.1668272018432617
Batch 36/64 loss: -2.6778926849365234
Batch 37/64 loss: -2.3809356689453125
Batch 38/64 loss: -2.5246238708496094
Batch 39/64 loss: -2.4643468856811523
Batch 40/64 loss: -2.4493274688720703
Batch 41/64 loss: -2.3981847763061523
Batch 42/64 loss: -2.6251602172851562
Batch 43/64 loss: -2.349224090576172
Batch 44/64 loss: -2.5097179412841797
Batch 45/64 loss: -2.6260547637939453
Batch 46/64 loss: -2.424534797668457
Batch 47/64 loss: -2.5845890045166016
Batch 48/64 loss: -2.4593334197998047
Batch 49/64 loss: -2.2500619888305664
Batch 50/64 loss: -2.409770965576172
Batch 51/64 loss: -2.7804155349731445
Batch 52/64 loss: -2.0858869552612305
Batch 53/64 loss: -2.4660863876342773
Batch 54/64 loss: -2.638504981994629
Batch 55/64 loss: -2.2181453704833984
Batch 56/64 loss: -2.49127197265625
Batch 57/64 loss: -2.6245927810668945
Batch 58/64 loss: -2.5956897735595703
Batch 59/64 loss: -2.657589912414551
Batch 60/64 loss: -2.475338935852051
Batch 61/64 loss: -2.1094512939453125
Batch 62/64 loss: -2.637434959411621
Batch 63/64 loss: -2.7237472534179688
Batch 64/64 loss: -6.986513137817383
Epoch 163  Train loss: -2.5192841548545686  Val loss: -2.7955435264561186
Saving best model, epoch: 163
Epoch 164
-------------------------------
Batch 1/64 loss: -2.322969436645508
Batch 2/64 loss: -2.590585708618164
Batch 3/64 loss: -2.1168699264526367
Batch 4/64 loss: -2.5411291122436523
Batch 5/64 loss: -2.3648815155029297
Batch 6/64 loss: -2.658450126647949
Batch 7/64 loss: -2.8117141723632812
Batch 8/64 loss: -2.5825843811035156
Batch 9/64 loss: -2.7361536026000977
Batch 10/64 loss: -2.724452018737793
Batch 11/64 loss: -2.4316463470458984
Batch 12/64 loss: -2.630563735961914
Batch 13/64 loss: -2.768260955810547
Batch 14/64 loss: -2.6280517578125
Batch 15/64 loss: -2.3036556243896484
Batch 16/64 loss: -2.6333160400390625
Batch 17/64 loss: -2.452824592590332
Batch 18/64 loss: -2.442080497741699
Batch 19/64 loss: -2.554800033569336
Batch 20/64 loss: -2.62540340423584
Batch 21/64 loss: -2.5789480209350586
Batch 22/64 loss: -2.59954833984375
Batch 23/64 loss: -2.3479394912719727
Batch 24/64 loss: -2.689666748046875
Batch 25/64 loss: -2.3197851181030273
Batch 26/64 loss: -2.7926292419433594
Batch 27/64 loss: -2.697347640991211
Batch 28/64 loss: -2.258547782897949
Batch 29/64 loss: -2.441347122192383
Batch 30/64 loss: -2.6581993103027344
Batch 31/64 loss: -2.7329721450805664
Batch 32/64 loss: -2.3524341583251953
Batch 33/64 loss: -2.3880996704101562
Batch 34/64 loss: -2.6291093826293945
Batch 35/64 loss: -2.392087936401367
Batch 36/64 loss: -2.336541175842285
Batch 37/64 loss: -2.4117279052734375
Batch 38/64 loss: -2.35817813873291
Batch 39/64 loss: -2.6626644134521484
Batch 40/64 loss: -2.7079782485961914
Batch 41/64 loss: -2.631990432739258
Batch 42/64 loss: -2.4139089584350586
Batch 43/64 loss: -2.73244571685791
Batch 44/64 loss: -2.5062179565429688
Batch 45/64 loss: -2.7704038619995117
Batch 46/64 loss: -2.618597984313965
Batch 47/64 loss: -2.723361015319824
Batch 48/64 loss: -2.5835561752319336
Batch 49/64 loss: -2.6541786193847656
Batch 50/64 loss: -2.7209672927856445
Batch 51/64 loss: -2.688920021057129
Batch 52/64 loss: -2.401348114013672
Batch 53/64 loss: -2.6847925186157227
Batch 54/64 loss: -2.583700180053711
Batch 55/64 loss: -2.4776716232299805
Batch 56/64 loss: -2.5210561752319336
Batch 57/64 loss: -2.389516830444336
Batch 58/64 loss: -2.4552507400512695
Batch 59/64 loss: -2.327024459838867
Batch 60/64 loss: -2.7968454360961914
Batch 61/64 loss: -2.3020076751708984
Batch 62/64 loss: -2.425753593444824
Batch 63/64 loss: -2.5568532943725586
Batch 64/64 loss: -6.941245079040527
Epoch 164  Train loss: -2.595269764170927  Val loss: -2.696658419579575
Epoch 165
-------------------------------
Batch 1/64 loss: -2.649250030517578
Batch 2/64 loss: -2.6025524139404297
Batch 3/64 loss: -2.635293960571289
Batch 4/64 loss: -2.2991771697998047
Batch 5/64 loss: -2.628718376159668
Batch 6/64 loss: -2.4312076568603516
Batch 7/64 loss: -2.6576175689697266
Batch 8/64 loss: -2.679166793823242
Batch 9/64 loss: -2.6185178756713867
Batch 10/64 loss: -2.6584978103637695
Batch 11/64 loss: -2.7398481369018555
Batch 12/64 loss: -2.393214225769043
Batch 13/64 loss: -2.874919891357422
Batch 14/64 loss: -2.6173229217529297
Batch 15/64 loss: -2.414309501647949
Batch 16/64 loss: -2.303168296813965
Batch 17/64 loss: -2.5783681869506836
Batch 18/64 loss: -2.6290664672851562
Batch 19/64 loss: -2.472423553466797
Batch 20/64 loss: -2.644955635070801
Batch 21/64 loss: -2.6287155151367188
Batch 22/64 loss: -2.6549177169799805
Batch 23/64 loss: -2.7687368392944336
Batch 24/64 loss: -2.6422643661499023
Batch 25/64 loss: -2.2174129486083984
Batch 26/64 loss: -2.5163450241088867
Batch 27/64 loss: -2.2626571655273438
Batch 28/64 loss: -2.6067867279052734
Batch 29/64 loss: -2.046842575073242
Batch 30/64 loss: -2.5790443420410156
Batch 31/64 loss: -2.5457239151000977
Batch 32/64 loss: -2.253133773803711
Batch 33/64 loss: -2.5409841537475586
Batch 34/64 loss: -2.5244197845458984
Batch 35/64 loss: -2.402092933654785
Batch 36/64 loss: -2.4305944442749023
Batch 37/64 loss: -2.1559295654296875
Batch 38/64 loss: -2.2477598190307617
Batch 39/64 loss: -2.7032718658447266
Batch 40/64 loss: -2.379378318786621
Batch 41/64 loss: -2.462688446044922
Batch 42/64 loss: -2.309859275817871
Batch 43/64 loss: -2.7179183959960938
Batch 44/64 loss: -2.3115386962890625
Batch 45/64 loss: -2.6581993103027344
Batch 46/64 loss: -2.436163902282715
Batch 47/64 loss: -2.7381343841552734
Batch 48/64 loss: -2.502467155456543
Batch 49/64 loss: -2.640141487121582
Batch 50/64 loss: -2.6328210830688477
Batch 51/64 loss: -2.6688079833984375
Batch 52/64 loss: -2.494565963745117
Batch 53/64 loss: -2.354537010192871
Batch 54/64 loss: -2.5631961822509766
Batch 55/64 loss: -2.479127883911133
Batch 56/64 loss: -2.2843074798583984
Batch 57/64 loss: -2.3757762908935547
Batch 58/64 loss: -2.6302261352539062
Batch 59/64 loss: -2.3110713958740234
Batch 60/64 loss: -2.494760513305664
Batch 61/64 loss: -2.57327938079834
Batch 62/64 loss: -2.1309337615966797
Batch 63/64 loss: -1.996342658996582
Batch 64/64 loss: -6.5135111808776855
Epoch 165  Train loss: -2.5456722577412925  Val loss: -2.736425524315064
Epoch 166
-------------------------------
Batch 1/64 loss: -2.1734495162963867
Batch 2/64 loss: -2.7075023651123047
Batch 3/64 loss: -2.541539192199707
Batch 4/64 loss: -2.2066307067871094
Batch 5/64 loss: -2.4246416091918945
Batch 6/64 loss: -2.6446266174316406
Batch 7/64 loss: -2.483867645263672
Batch 8/64 loss: -2.542510986328125
Batch 9/64 loss: -2.4912471771240234
Batch 10/64 loss: -2.6077442169189453
Batch 11/64 loss: -2.5057201385498047
Batch 12/64 loss: -2.2646141052246094
Batch 13/64 loss: -2.637441635131836
Batch 14/64 loss: -2.2686662673950195
Batch 15/64 loss: -2.3690481185913086
Batch 16/64 loss: -2.2350034713745117
Batch 17/64 loss: -2.7831153869628906
Batch 18/64 loss: -2.5520057678222656
Batch 19/64 loss: -2.376567840576172
Batch 20/64 loss: -2.5923948287963867
Batch 21/64 loss: -2.416898727416992
Batch 22/64 loss: -2.282595634460449
Batch 23/64 loss: -2.741455078125
Batch 24/64 loss: -2.191473960876465
Batch 25/64 loss: -2.722956657409668
Batch 26/64 loss: -2.5039520263671875
Batch 27/64 loss: -2.535196304321289
Batch 28/64 loss: -2.668511390686035
Batch 29/64 loss: -2.460848808288574
Batch 30/64 loss: -2.5344533920288086
Batch 31/64 loss: -2.4754600524902344
Batch 32/64 loss: -2.696676254272461
Batch 33/64 loss: -2.410172462463379
Batch 34/64 loss: -2.535332679748535
Batch 35/64 loss: -2.32781982421875
Batch 36/64 loss: -2.6896772384643555
Batch 37/64 loss: -2.34613037109375
Batch 38/64 loss: -2.368549346923828
Batch 39/64 loss: -2.0730810165405273
Batch 40/64 loss: -2.6046266555786133
Batch 41/64 loss: -2.2432126998901367
Batch 42/64 loss: -2.656505584716797
Batch 43/64 loss: -2.414548873901367
Batch 44/64 loss: -2.289811134338379
Batch 45/64 loss: -2.4826765060424805
Batch 46/64 loss: -2.5217981338500977
Batch 47/64 loss: -2.3959474563598633
Batch 48/64 loss: -2.2625303268432617
Batch 49/64 loss: -2.3063793182373047
Batch 50/64 loss: -2.0070009231567383
Batch 51/64 loss: -2.3399829864501953
Batch 52/64 loss: -2.5428266525268555
Batch 53/64 loss: -2.62467098236084
Batch 54/64 loss: -2.557065963745117
Batch 55/64 loss: -2.587055206298828
Batch 56/64 loss: -2.598112106323242
Batch 57/64 loss: -2.367060661315918
Batch 58/64 loss: -2.1488075256347656
Batch 59/64 loss: -2.4838523864746094
Batch 60/64 loss: -2.474484443664551
Batch 61/64 loss: -2.2507524490356445
Batch 62/64 loss: -2.3105669021606445
Batch 63/64 loss: -2.228546142578125
Batch 64/64 loss: -7.033549785614014
Epoch 166  Train loss: -2.499820598901487  Val loss: -2.5694564347414626
Epoch 167
-------------------------------
Batch 1/64 loss: -2.310384750366211
Batch 2/64 loss: -2.4914722442626953
Batch 3/64 loss: -2.630910873413086
Batch 4/64 loss: -2.5906667709350586
Batch 5/64 loss: -2.6902427673339844
Batch 6/64 loss: -2.5746240615844727
Batch 7/64 loss: -2.361255645751953
Batch 8/64 loss: -2.6386289596557617
Batch 9/64 loss: -2.458200454711914
Batch 10/64 loss: -2.355989456176758
Batch 11/64 loss: -2.5390424728393555
Batch 12/64 loss: -2.4794769287109375
Batch 13/64 loss: -2.53476619720459
Batch 14/64 loss: -2.369842529296875
Batch 15/64 loss: -2.312471389770508
Batch 16/64 loss: -2.3468151092529297
Batch 17/64 loss: -2.636622428894043
Batch 18/64 loss: -2.706528663635254
Batch 19/64 loss: -2.6601476669311523
Batch 20/64 loss: -2.4056930541992188
Batch 21/64 loss: -2.4411840438842773
Batch 22/64 loss: -2.2031259536743164
Batch 23/64 loss: -2.5604171752929688
Batch 24/64 loss: -2.1463165283203125
Batch 25/64 loss: -1.9072484970092773
Batch 26/64 loss: -2.548673629760742
Batch 27/64 loss: -2.4625301361083984
Batch 28/64 loss: -2.6069507598876953
Batch 29/64 loss: -2.4806108474731445
Batch 30/64 loss: -2.4939308166503906
Batch 31/64 loss: -2.5503740310668945
Batch 32/64 loss: -2.6595754623413086
Batch 33/64 loss: -2.346454620361328
Batch 34/64 loss: -2.6141233444213867
Batch 35/64 loss: -2.748721122741699
Batch 36/64 loss: -2.49906063079834
Batch 37/64 loss: -2.172308921813965
Batch 38/64 loss: -2.338825225830078
Batch 39/64 loss: -2.5377187728881836
Batch 40/64 loss: -2.0788888931274414
Batch 41/64 loss: -2.7587966918945312
Batch 42/64 loss: -2.6010684967041016
Batch 43/64 loss: -2.7708568572998047
Batch 44/64 loss: -2.6599674224853516
Batch 45/64 loss: -2.454707145690918
Batch 46/64 loss: -2.613348960876465
Batch 47/64 loss: -2.171571731567383
Batch 48/64 loss: -2.4258270263671875
Batch 49/64 loss: -2.0775651931762695
Batch 50/64 loss: -2.190309524536133
Batch 51/64 loss: -2.1286449432373047
Batch 52/64 loss: -2.3146276473999023
Batch 53/64 loss: -2.285281181335449
Batch 54/64 loss: -2.1393308639526367
Batch 55/64 loss: -2.7253293991088867
Batch 56/64 loss: -2.588552474975586
Batch 57/64 loss: -2.1923437118530273
Batch 58/64 loss: -2.39949893951416
Batch 59/64 loss: -2.327202796936035
Batch 60/64 loss: -2.5216522216796875
Batch 61/64 loss: -2.7502832412719727
Batch 62/64 loss: -2.5757293701171875
Batch 63/64 loss: -2.3858604431152344
Batch 64/64 loss: -7.1753621101379395
Epoch 167  Train loss: -2.5087168581345503  Val loss: -2.730760541568507
Epoch 168
-------------------------------
Batch 1/64 loss: -2.6345033645629883
Batch 2/64 loss: -1.9920768737792969
Batch 3/64 loss: -2.151156425476074
Batch 4/64 loss: -2.7674379348754883
Batch 5/64 loss: -2.3882713317871094
Batch 6/64 loss: -2.390984535217285
Batch 7/64 loss: -2.3807201385498047
Batch 8/64 loss: -2.5660781860351562
Batch 9/64 loss: -2.1334495544433594
Batch 10/64 loss: -2.2705068588256836
Batch 11/64 loss: -2.6042137145996094
Batch 12/64 loss: -2.435056686401367
Batch 13/64 loss: -2.5848541259765625
Batch 14/64 loss: -2.825131416320801
Batch 15/64 loss: -2.2693376541137695
Batch 16/64 loss: -2.858719825744629
Batch 17/64 loss: -2.548628807067871
Batch 18/64 loss: -2.5776729583740234
Batch 19/64 loss: -2.060361862182617
Batch 20/64 loss: -2.1255369186401367
Batch 21/64 loss: -2.4729137420654297
Batch 22/64 loss: -2.6583003997802734
Batch 23/64 loss: -2.3821840286254883
Batch 24/64 loss: -2.09873104095459
Batch 25/64 loss: -2.4251928329467773
Batch 26/64 loss: -2.8377227783203125
Batch 27/64 loss: -2.6899776458740234
Batch 28/64 loss: -2.2906932830810547
Batch 29/64 loss: -2.5585880279541016
Batch 30/64 loss: -2.6899824142456055
Batch 31/64 loss: -2.682821273803711
Batch 32/64 loss: -2.604663848876953
Batch 33/64 loss: -2.20481014251709
Batch 34/64 loss: -2.4707555770874023
Batch 35/64 loss: -2.557973861694336
Batch 36/64 loss: -2.6717653274536133
Batch 37/64 loss: -2.472283363342285
Batch 38/64 loss: -2.3918581008911133
Batch 39/64 loss: -2.714191436767578
Batch 40/64 loss: -2.597471237182617
Batch 41/64 loss: -2.667355537414551
Batch 42/64 loss: -2.6699113845825195
Batch 43/64 loss: -2.561471939086914
Batch 44/64 loss: -2.6628808975219727
Batch 45/64 loss: -2.6569299697875977
Batch 46/64 loss: -2.704888343811035
Batch 47/64 loss: -2.513554573059082
Batch 48/64 loss: -2.4246416091918945
Batch 49/64 loss: -2.64044189453125
Batch 50/64 loss: -2.724407196044922
Batch 51/64 loss: -2.6642818450927734
Batch 52/64 loss: -2.3830270767211914
Batch 53/64 loss: -2.0163955688476562
Batch 54/64 loss: -2.5569334030151367
Batch 55/64 loss: -2.6248979568481445
Batch 56/64 loss: -2.5594043731689453
Batch 57/64 loss: -2.3425216674804688
Batch 58/64 loss: -2.438216209411621
Batch 59/64 loss: -2.493997573852539
Batch 60/64 loss: -2.426076889038086
Batch 61/64 loss: -2.6161365509033203
Batch 62/64 loss: -2.478114128112793
Batch 63/64 loss: -2.412379264831543
Batch 64/64 loss: -6.3596673011779785
Epoch 168  Train loss: -2.541901111602783  Val loss: -2.8517283541230403
Saving best model, epoch: 168
Epoch 169
-------------------------------
Batch 1/64 loss: -2.7282352447509766
Batch 2/64 loss: -2.7758102416992188
Batch 3/64 loss: -2.406759262084961
Batch 4/64 loss: -2.511843681335449
Batch 5/64 loss: -2.5720348358154297
Batch 6/64 loss: -2.439241409301758
Batch 7/64 loss: -2.5688371658325195
Batch 8/64 loss: -2.216996192932129
Batch 9/64 loss: -2.425717353820801
Batch 10/64 loss: -2.3428850173950195
Batch 11/64 loss: -2.4477128982543945
Batch 12/64 loss: -2.2926435470581055
Batch 13/64 loss: -2.5006933212280273
Batch 14/64 loss: -2.5780296325683594
Batch 15/64 loss: -2.305011749267578
Batch 16/64 loss: -2.245089530944824
Batch 17/64 loss: -2.660350799560547
Batch 18/64 loss: -2.695021629333496
Batch 19/64 loss: -2.5565690994262695
Batch 20/64 loss: -2.670125961303711
Batch 21/64 loss: -2.7087326049804688
Batch 22/64 loss: -2.5957345962524414
Batch 23/64 loss: -2.4624509811401367
Batch 24/64 loss: -2.6294164657592773
Batch 25/64 loss: -2.6241321563720703
Batch 26/64 loss: -2.432523727416992
Batch 27/64 loss: -2.631545066833496
Batch 28/64 loss: -2.464191436767578
Batch 29/64 loss: -2.49356746673584
Batch 30/64 loss: -2.6816930770874023
Batch 31/64 loss: -2.740713119506836
Batch 32/64 loss: -2.644327163696289
Batch 33/64 loss: -2.40194034576416
Batch 34/64 loss: -2.568540573120117
Batch 35/64 loss: -2.4976749420166016
Batch 36/64 loss: -2.562527656555176
Batch 37/64 loss: -2.438992500305176
Batch 38/64 loss: -2.568674087524414
Batch 39/64 loss: -2.2276973724365234
Batch 40/64 loss: -2.4764089584350586
Batch 41/64 loss: -2.449835777282715
Batch 42/64 loss: -2.144362449645996
Batch 43/64 loss: -2.48452091217041
Batch 44/64 loss: -2.637850761413574
Batch 45/64 loss: -2.686305046081543
Batch 46/64 loss: -2.695669174194336
Batch 47/64 loss: -2.674602508544922
Batch 48/64 loss: -2.4894332885742188
Batch 49/64 loss: -2.0654850006103516
Batch 50/64 loss: -2.7069902420043945
Batch 51/64 loss: -2.055720329284668
Batch 52/64 loss: -2.6419429779052734
Batch 53/64 loss: -2.5207481384277344
Batch 54/64 loss: -2.262516975402832
Batch 55/64 loss: -2.6023244857788086
Batch 56/64 loss: -2.838730812072754
Batch 57/64 loss: -2.344414710998535
Batch 58/64 loss: -2.256237030029297
Batch 59/64 loss: -2.5197277069091797
Batch 60/64 loss: -2.6313114166259766
Batch 61/64 loss: -2.4850053787231445
Batch 62/64 loss: -2.1493616104125977
Batch 63/64 loss: -2.215996742248535
Batch 64/64 loss: -6.900017738342285
Epoch 169  Train loss: -2.5494148964975394  Val loss: -2.7998976953250847
Epoch 170
-------------------------------
Batch 1/64 loss: -2.5049848556518555
Batch 2/64 loss: -2.493960380554199
Batch 3/64 loss: -2.549483299255371
Batch 4/64 loss: -2.417691230773926
Batch 5/64 loss: -2.6390905380249023
Batch 6/64 loss: -2.5838632583618164
Batch 7/64 loss: -2.71990966796875
Batch 8/64 loss: -2.711195945739746
Batch 9/64 loss: -2.58477783203125
Batch 10/64 loss: -2.42795467376709
Batch 11/64 loss: -2.6366806030273438
Batch 12/64 loss: -2.6375389099121094
Batch 13/64 loss: -2.632510185241699
Batch 14/64 loss: -2.628267288208008
Batch 15/64 loss: -2.6267433166503906
Batch 16/64 loss: -2.467556953430176
Batch 17/64 loss: -2.1945276260375977
Batch 18/64 loss: -2.6916418075561523
Batch 19/64 loss: -1.97552490234375
Batch 20/64 loss: -2.499117851257324
Batch 21/64 loss: -2.584836959838867
Batch 22/64 loss: -2.6698055267333984
Batch 23/64 loss: -2.566364288330078
Batch 24/64 loss: -2.5180435180664062
Batch 25/64 loss: -2.422567367553711
Batch 26/64 loss: -2.6321334838867188
Batch 27/64 loss: -2.587765693664551
Batch 28/64 loss: -2.3424177169799805
Batch 29/64 loss: -2.117847442626953
Batch 30/64 loss: -2.5020828247070312
Batch 31/64 loss: -2.6888322830200195
Batch 32/64 loss: -2.7591466903686523
Batch 33/64 loss: -2.604898452758789
Batch 34/64 loss: -2.1958913803100586
Batch 35/64 loss: -2.2321014404296875
Batch 36/64 loss: -2.3129892349243164
Batch 37/64 loss: -2.501032829284668
Batch 38/64 loss: -2.5376205444335938
Batch 39/64 loss: -2.6083641052246094
Batch 40/64 loss: -2.7092056274414062
Batch 41/64 loss: -2.556333541870117
Batch 42/64 loss: -2.509453773498535
Batch 43/64 loss: -2.5689897537231445
Batch 44/64 loss: -2.492316246032715
Batch 45/64 loss: -2.827756881713867
Batch 46/64 loss: -2.542782783508301
Batch 47/64 loss: -2.5162763595581055
Batch 48/64 loss: -2.3546390533447266
Batch 49/64 loss: -2.363056182861328
Batch 50/64 loss: -2.0042953491210938
Batch 51/64 loss: -2.0263242721557617
Batch 52/64 loss: -2.5089893341064453
Batch 53/64 loss: -2.8241147994995117
Batch 54/64 loss: -2.3766021728515625
Batch 55/64 loss: -2.5898170471191406
Batch 56/64 loss: -2.621870994567871
Batch 57/64 loss: -2.654526710510254
Batch 58/64 loss: -2.5226688385009766
Batch 59/64 loss: -2.5039596557617188
Batch 60/64 loss: -2.385561943054199
Batch 61/64 loss: -2.179793357849121
Batch 62/64 loss: -2.559859275817871
Batch 63/64 loss: -2.4578285217285156
Batch 64/64 loss: -7.158102989196777
Epoch 170  Train loss: -2.5573860804239907  Val loss: -2.7451402460996226
Epoch 171
-------------------------------
Batch 1/64 loss: -2.629863739013672
Batch 2/64 loss: -2.2513580322265625
Batch 3/64 loss: -2.1473779678344727
Batch 4/64 loss: -2.58331298828125
Batch 5/64 loss: -2.7078447341918945
Batch 6/64 loss: -2.526805877685547
Batch 7/64 loss: -2.363008499145508
Batch 8/64 loss: -2.715547561645508
Batch 9/64 loss: -2.5925464630126953
Batch 10/64 loss: -2.6506690979003906
Batch 11/64 loss: -1.9972858428955078
Batch 12/64 loss: -2.0700864791870117
Batch 13/64 loss: -2.398505210876465
Batch 14/64 loss: -2.446063995361328
Batch 15/64 loss: -2.3403234481811523
Batch 16/64 loss: -2.502448081970215
Batch 17/64 loss: -2.458481788635254
Batch 18/64 loss: -2.693056106567383
Batch 19/64 loss: -2.339737892150879
Batch 20/64 loss: -2.528413772583008
Batch 21/64 loss: -2.243058204650879
Batch 22/64 loss: -2.6903276443481445
Batch 23/64 loss: -2.802732467651367
Batch 24/64 loss: -2.697920799255371
Batch 25/64 loss: -2.619847297668457
Batch 26/64 loss: -2.6082611083984375
Batch 27/64 loss: -2.7933120727539062
Batch 28/64 loss: -2.3791351318359375
Batch 29/64 loss: -2.2317495346069336
Batch 30/64 loss: -2.664226531982422
Batch 31/64 loss: -1.7438983917236328
Batch 32/64 loss: -2.4051313400268555
Batch 33/64 loss: -2.645127296447754
Batch 34/64 loss: -2.405424118041992
Batch 35/64 loss: -2.636442184448242
Batch 36/64 loss: -2.554445266723633
Batch 37/64 loss: -2.537078857421875
Batch 38/64 loss: -2.71956729888916
Batch 39/64 loss: -2.2069921493530273
Batch 40/64 loss: -2.5712804794311523
Batch 41/64 loss: -2.5230979919433594
Batch 42/64 loss: -2.515702247619629
Batch 43/64 loss: -2.816629409790039
Batch 44/64 loss: -2.570028305053711
Batch 45/64 loss: -2.591994285583496
Batch 46/64 loss: -2.5069894790649414
Batch 47/64 loss: -2.7034692764282227
Batch 48/64 loss: -2.567852020263672
Batch 49/64 loss: -2.363016128540039
Batch 50/64 loss: -2.7330312728881836
Batch 51/64 loss: -2.608776092529297
Batch 52/64 loss: -2.695237159729004
Batch 53/64 loss: -2.6770362854003906
Batch 54/64 loss: -2.516958236694336
Batch 55/64 loss: -2.4558591842651367
Batch 56/64 loss: -2.142125129699707
Batch 57/64 loss: -2.7355031967163086
Batch 58/64 loss: -2.4123544692993164
Batch 59/64 loss: -2.1679935455322266
Batch 60/64 loss: -2.783207893371582
Batch 61/64 loss: -2.646808624267578
Batch 62/64 loss: -2.50363826751709
Batch 63/64 loss: -2.389218330383301
Batch 64/64 loss: -6.982880115509033
Epoch 171  Train loss: -2.556272669399486  Val loss: -2.774743057198541
Epoch 172
-------------------------------
Batch 1/64 loss: -2.5837221145629883
Batch 2/64 loss: -2.4653987884521484
Batch 3/64 loss: -2.5811233520507812
Batch 4/64 loss: -2.519338607788086
Batch 5/64 loss: -2.634213447570801
Batch 6/64 loss: -2.7806930541992188
Batch 7/64 loss: -2.2513198852539062
Batch 8/64 loss: -2.5256567001342773
Batch 9/64 loss: -2.6188268661499023
Batch 10/64 loss: -2.5844345092773438
Batch 11/64 loss: -2.5518760681152344
Batch 12/64 loss: -2.560689926147461
Batch 13/64 loss: -2.4637250900268555
Batch 14/64 loss: -2.710460662841797
Batch 15/64 loss: -2.5113649368286133
Batch 16/64 loss: -2.3393611907958984
Batch 17/64 loss: -2.328639030456543
Batch 18/64 loss: -2.668649673461914
Batch 19/64 loss: -2.7813987731933594
Batch 20/64 loss: -2.2047224044799805
Batch 21/64 loss: -2.4836206436157227
Batch 22/64 loss: -2.7286033630371094
Batch 23/64 loss: -2.745960235595703
Batch 24/64 loss: -2.8167381286621094
Batch 25/64 loss: -2.4781980514526367
Batch 26/64 loss: -2.594428062438965
Batch 27/64 loss: -2.8667850494384766
Batch 28/64 loss: -2.5218095779418945
Batch 29/64 loss: -2.550360679626465
Batch 30/64 loss: -2.7415342330932617
Batch 31/64 loss: -2.6001100540161133
Batch 32/64 loss: -2.251375198364258
Batch 33/64 loss: -2.68508243560791
Batch 34/64 loss: -2.6747169494628906
Batch 35/64 loss: -2.2176132202148438
Batch 36/64 loss: -2.6836605072021484
Batch 37/64 loss: -2.3961429595947266
Batch 38/64 loss: -2.505892753601074
Batch 39/64 loss: -2.4088945388793945
Batch 40/64 loss: -2.495920181274414
Batch 41/64 loss: -2.4431962966918945
Batch 42/64 loss: -2.6728219985961914
Batch 43/64 loss: -2.367227554321289
Batch 44/64 loss: -2.590458869934082
Batch 45/64 loss: -2.1377077102661133
Batch 46/64 loss: -2.558685302734375
Batch 47/64 loss: -2.603199005126953
Batch 48/64 loss: -2.4842567443847656
Batch 49/64 loss: -2.347585678100586
Batch 50/64 loss: -2.6395254135131836
Batch 51/64 loss: -2.375823974609375
Batch 52/64 loss: -2.180225372314453
Batch 53/64 loss: -2.51509952545166
Batch 54/64 loss: -2.7525739669799805
Batch 55/64 loss: -2.6317853927612305
Batch 56/64 loss: -2.573634147644043
Batch 57/64 loss: -2.0709848403930664
Batch 58/64 loss: -2.875882148742676
Batch 59/64 loss: -2.70259952545166
Batch 60/64 loss: -2.561354637145996
Batch 61/64 loss: -2.4899654388427734
Batch 62/64 loss: -2.4726037979125977
Batch 63/64 loss: -2.6773338317871094
Batch 64/64 loss: -6.757728576660156
Epoch 172  Train loss: -2.5867590511546417  Val loss: -2.6507820837276497
Epoch 173
-------------------------------
Batch 1/64 loss: -1.8269624710083008
Batch 2/64 loss: -2.883042335510254
Batch 3/64 loss: -2.6962175369262695
Batch 4/64 loss: -2.722383499145508
Batch 5/64 loss: -2.535106658935547
Batch 6/64 loss: -2.251667022705078
Batch 7/64 loss: -2.5184574127197266
Batch 8/64 loss: -2.849851608276367
Batch 9/64 loss: -2.462024688720703
Batch 10/64 loss: -2.5577754974365234
Batch 11/64 loss: -2.82110595703125
Batch 12/64 loss: -2.741628646850586
Batch 13/64 loss: -2.739107131958008
Batch 14/64 loss: -2.5045623779296875
Batch 15/64 loss: -2.523972511291504
Batch 16/64 loss: -2.782595634460449
Batch 17/64 loss: -2.478158950805664
Batch 18/64 loss: -2.3830995559692383
Batch 19/64 loss: -2.079129219055176
Batch 20/64 loss: -2.1441383361816406
Batch 21/64 loss: -2.6869821548461914
Batch 22/64 loss: -2.498011589050293
Batch 23/64 loss: -2.4016809463500977
Batch 24/64 loss: -2.567662239074707
Batch 25/64 loss: -2.6688766479492188
Batch 26/64 loss: -2.755474090576172
Batch 27/64 loss: -2.4745683670043945
Batch 28/64 loss: -2.4498653411865234
Batch 29/64 loss: -2.6718387603759766
Batch 30/64 loss: -2.525082588195801
Batch 31/64 loss: -2.504206657409668
Batch 32/64 loss: -2.563650131225586
Batch 33/64 loss: -2.844943046569824
Batch 34/64 loss: -2.7052793502807617
Batch 35/64 loss: -2.4677505493164062
Batch 36/64 loss: -2.527438163757324
Batch 37/64 loss: -2.6118431091308594
Batch 38/64 loss: -2.761455535888672
Batch 39/64 loss: -2.55147647857666
Batch 40/64 loss: -2.7404441833496094
Batch 41/64 loss: -2.0711135864257812
Batch 42/64 loss: -2.645697593688965
Batch 43/64 loss: -2.64975643157959
Batch 44/64 loss: -2.4702281951904297
Batch 45/64 loss: -2.6127891540527344
Batch 46/64 loss: -2.6847620010375977
Batch 47/64 loss: -2.723438262939453
Batch 48/64 loss: -2.6783370971679688
Batch 49/64 loss: -2.534712791442871
Batch 50/64 loss: -2.4757843017578125
Batch 51/64 loss: -2.658249855041504
Batch 52/64 loss: -2.6685924530029297
Batch 53/64 loss: -2.4486560821533203
Batch 54/64 loss: -2.555013656616211
Batch 55/64 loss: -2.792088508605957
Batch 56/64 loss: -2.757002830505371
Batch 57/64 loss: -2.366938591003418
Batch 58/64 loss: -2.7764711380004883
Batch 59/64 loss: -2.2762718200683594
Batch 60/64 loss: -2.700876235961914
Batch 61/64 loss: -2.6825408935546875
Batch 62/64 loss: -2.239988327026367
Batch 63/64 loss: -2.254603385925293
Batch 64/64 loss: -6.944978713989258
Epoch 173  Train loss: -2.6103868895885993  Val loss: -2.8010463780144237
Epoch 174
-------------------------------
Batch 1/64 loss: -2.8673744201660156
Batch 2/64 loss: -2.7006540298461914
Batch 3/64 loss: -2.628145217895508
Batch 4/64 loss: -2.834737777709961
Batch 5/64 loss: -2.7857112884521484
Batch 6/64 loss: -2.353372573852539
Batch 7/64 loss: -2.6021080017089844
Batch 8/64 loss: -2.431833267211914
Batch 9/64 loss: -2.479161262512207
Batch 10/64 loss: -2.444293975830078
Batch 11/64 loss: -2.658413887023926
Batch 12/64 loss: -2.624929428100586
Batch 13/64 loss: -2.427069664001465
Batch 14/64 loss: -2.696183204650879
Batch 15/64 loss: -2.715261459350586
Batch 16/64 loss: -2.2194910049438477
Batch 17/64 loss: -2.6613922119140625
Batch 18/64 loss: -2.4941158294677734
Batch 19/64 loss: -2.833904266357422
Batch 20/64 loss: -2.702694892883301
Batch 21/64 loss: -2.4022912979125977
Batch 22/64 loss: -2.70931339263916
Batch 23/64 loss: -2.8765153884887695
Batch 24/64 loss: -2.6793136596679688
Batch 25/64 loss: -2.689920425415039
Batch 26/64 loss: -2.506357192993164
Batch 27/64 loss: -2.549713134765625
Batch 28/64 loss: -2.3957672119140625
Batch 29/64 loss: -2.3477563858032227
Batch 30/64 loss: -2.632944107055664
Batch 31/64 loss: -2.6851234436035156
Batch 32/64 loss: -2.8428268432617188
Batch 33/64 loss: -2.562999725341797
Batch 34/64 loss: -2.5786867141723633
Batch 35/64 loss: -2.7479028701782227
Batch 36/64 loss: -2.6466922760009766
Batch 37/64 loss: -2.130232810974121
Batch 38/64 loss: -2.5553207397460938
Batch 39/64 loss: -2.2365283966064453
Batch 40/64 loss: -2.8729324340820312
Batch 41/64 loss: -2.533344268798828
Batch 42/64 loss: -2.681184768676758
Batch 43/64 loss: -2.666248321533203
Batch 44/64 loss: -2.815000534057617
Batch 45/64 loss: -2.331374168395996
Batch 46/64 loss: -2.79097843170166
Batch 47/64 loss: -2.501662254333496
Batch 48/64 loss: -2.7143030166625977
Batch 49/64 loss: -2.5778121948242188
Batch 50/64 loss: -2.7629356384277344
Batch 51/64 loss: -2.2444381713867188
Batch 52/64 loss: -2.6954755783081055
Batch 53/64 loss: -2.4648265838623047
Batch 54/64 loss: -2.4424314498901367
Batch 55/64 loss: -2.8113088607788086
Batch 56/64 loss: -2.6219911575317383
Batch 57/64 loss: -2.353292465209961
Batch 58/64 loss: -2.7858009338378906
Batch 59/64 loss: -2.4061412811279297
Batch 60/64 loss: -2.362405776977539
Batch 61/64 loss: -2.6002559661865234
Batch 62/64 loss: -2.737135887145996
Batch 63/64 loss: -2.49668025970459
Batch 64/64 loss: -6.538818359375
Epoch 174  Train loss: -2.6370372996610754  Val loss: -2.8230585052385364
Epoch 175
-------------------------------
Batch 1/64 loss: -2.672088623046875
Batch 2/64 loss: -2.688685417175293
Batch 3/64 loss: -2.5948028564453125
Batch 4/64 loss: -2.7013072967529297
Batch 5/64 loss: -2.4217233657836914
Batch 6/64 loss: -2.352261543273926
Batch 7/64 loss: -2.455179214477539
Batch 8/64 loss: -2.509779930114746
Batch 9/64 loss: -2.2280540466308594
Batch 10/64 loss: -2.367621421813965
Batch 11/64 loss: -2.6440505981445312
Batch 12/64 loss: -2.610015869140625
Batch 13/64 loss: -2.3756818771362305
Batch 14/64 loss: -2.4400634765625
Batch 15/64 loss: -2.634974479675293
Batch 16/64 loss: -2.7371463775634766
Batch 17/64 loss: -2.706629753112793
Batch 18/64 loss: -2.4446773529052734
Batch 19/64 loss: -2.564983367919922
Batch 20/64 loss: -2.555575370788574
Batch 21/64 loss: -2.5089292526245117
Batch 22/64 loss: -2.6104021072387695
Batch 23/64 loss: -2.5652284622192383
Batch 24/64 loss: -2.621522903442383
Batch 25/64 loss: -2.651545524597168
Batch 26/64 loss: -2.4045114517211914
Batch 27/64 loss: -2.747971534729004
Batch 28/64 loss: -2.493436813354492
Batch 29/64 loss: -2.7555770874023438
Batch 30/64 loss: -2.632502555847168
Batch 31/64 loss: -2.4032373428344727
Batch 32/64 loss: -2.32840633392334
Batch 33/64 loss: -2.6465797424316406
Batch 34/64 loss: -2.736260414123535
Batch 35/64 loss: -2.64993953704834
Batch 36/64 loss: -2.578251838684082
Batch 37/64 loss: -2.308779716491699
Batch 38/64 loss: -2.714634895324707
Batch 39/64 loss: -2.4220542907714844
Batch 40/64 loss: -2.5010204315185547
Batch 41/64 loss: -2.187586784362793
Batch 42/64 loss: -2.8429126739501953
Batch 43/64 loss: -2.638631820678711
Batch 44/64 loss: -2.775768280029297
Batch 45/64 loss: -2.693380355834961
Batch 46/64 loss: -2.73406982421875
Batch 47/64 loss: -2.5040664672851562
Batch 48/64 loss: -2.559861183166504
Batch 49/64 loss: -2.4405899047851562
Batch 50/64 loss: -2.7896013259887695
Batch 51/64 loss: -2.6962289810180664
Batch 52/64 loss: -2.744601249694824
Batch 53/64 loss: -2.6428003311157227
Batch 54/64 loss: -2.878742218017578
Batch 55/64 loss: -2.266720771789551
Batch 56/64 loss: -2.5434513092041016
Batch 57/64 loss: -2.25363826751709
Batch 58/64 loss: -2.3841552734375
Batch 59/64 loss: -2.606581687927246
Batch 60/64 loss: -2.783442497253418
Batch 61/64 loss: -2.7775211334228516
Batch 62/64 loss: -2.754423141479492
Batch 63/64 loss: -2.804135322570801
Batch 64/64 loss: -7.03521203994751
Epoch 175  Train loss: -2.628477087207869  Val loss: -2.872828244343656
Saving best model, epoch: 175
Epoch 176
-------------------------------
Batch 1/64 loss: -2.613612174987793
Batch 2/64 loss: -2.7370290756225586
Batch 3/64 loss: -2.9256229400634766
Batch 4/64 loss: -2.6286020278930664
Batch 5/64 loss: -2.2749404907226562
Batch 6/64 loss: -2.591541290283203
Batch 7/64 loss: -2.632382392883301
Batch 8/64 loss: -2.8185510635375977
Batch 9/64 loss: -2.22182559967041
Batch 10/64 loss: -2.642017364501953
Batch 11/64 loss: -2.6510133743286133
Batch 12/64 loss: -2.6569080352783203
Batch 13/64 loss: -2.518265724182129
Batch 14/64 loss: -2.5941524505615234
Batch 15/64 loss: -2.5865135192871094
Batch 16/64 loss: -2.8110084533691406
Batch 17/64 loss: -2.7481651306152344
Batch 18/64 loss: -2.5212526321411133
Batch 19/64 loss: -2.4847946166992188
Batch 20/64 loss: -2.809724807739258
Batch 21/64 loss: -2.707728385925293
Batch 22/64 loss: -2.8713932037353516
Batch 23/64 loss: -2.5930356979370117
Batch 24/64 loss: -2.752028465270996
Batch 25/64 loss: -2.4509057998657227
Batch 26/64 loss: -2.5482606887817383
Batch 27/64 loss: -2.5392284393310547
Batch 28/64 loss: -2.718812942504883
Batch 29/64 loss: -2.328817367553711
Batch 30/64 loss: -2.6858301162719727
Batch 31/64 loss: -2.6121883392333984
Batch 32/64 loss: -2.6679248809814453
Batch 33/64 loss: -2.463724136352539
Batch 34/64 loss: -2.4261093139648438
Batch 35/64 loss: -2.804774284362793
Batch 36/64 loss: -2.6623058319091797
Batch 37/64 loss: -2.606694221496582
Batch 38/64 loss: -2.3892202377319336
Batch 39/64 loss: -2.6574792861938477
Batch 40/64 loss: -2.6932859420776367
Batch 41/64 loss: -2.600447654724121
Batch 42/64 loss: -2.490581512451172
Batch 43/64 loss: -2.7716150283813477
Batch 44/64 loss: -2.613433837890625
Batch 45/64 loss: -2.7744827270507812
Batch 46/64 loss: -2.5771636962890625
Batch 47/64 loss: -2.510753631591797
Batch 48/64 loss: -2.417959213256836
Batch 49/64 loss: -2.6053056716918945
Batch 50/64 loss: -2.705002784729004
Batch 51/64 loss: -2.182218551635742
Batch 52/64 loss: -2.649001121520996
Batch 53/64 loss: -2.388591766357422
Batch 54/64 loss: -2.5869064331054688
Batch 55/64 loss: -2.545877456665039
Batch 56/64 loss: -2.675351142883301
Batch 57/64 loss: -2.803553581237793
Batch 58/64 loss: -2.6448020935058594
Batch 59/64 loss: -2.4457387924194336
Batch 60/64 loss: -2.2877683639526367
Batch 61/64 loss: -2.1764402389526367
Batch 62/64 loss: -2.378326416015625
Batch 63/64 loss: -2.6079702377319336
Batch 64/64 loss: -7.012764930725098
Epoch 176  Train loss: -2.6407299827126898  Val loss: -2.7752430185009933
Epoch 177
-------------------------------
Batch 1/64 loss: -2.851922035217285
Batch 2/64 loss: -2.363865852355957
Batch 3/64 loss: -2.5538015365600586
Batch 4/64 loss: -2.4902334213256836
Batch 5/64 loss: -2.663763999938965
Batch 6/64 loss: -2.4990501403808594
Batch 7/64 loss: -2.6478471755981445
Batch 8/64 loss: -2.728574752807617
Batch 9/64 loss: -2.3673229217529297
Batch 10/64 loss: -2.3368282318115234
Batch 11/64 loss: -2.5295143127441406
Batch 12/64 loss: -2.6839399337768555
Batch 13/64 loss: -2.7270736694335938
Batch 14/64 loss: -2.674436569213867
Batch 15/64 loss: -2.7462854385375977
Batch 16/64 loss: -2.709784507751465
Batch 17/64 loss: -2.7572717666625977
Batch 18/64 loss: -2.376514434814453
Batch 19/64 loss: -2.669168472290039
Batch 20/64 loss: -2.2732295989990234
Batch 21/64 loss: -2.609602928161621
Batch 22/64 loss: -2.357698440551758
Batch 23/64 loss: -2.4145469665527344
Batch 24/64 loss: -2.635115623474121
Batch 25/64 loss: -2.7473020553588867
Batch 26/64 loss: -2.5186519622802734
Batch 27/64 loss: -2.7188596725463867
Batch 28/64 loss: -2.727367401123047
Batch 29/64 loss: -2.5009422302246094
Batch 30/64 loss: -2.566910743713379
Batch 31/64 loss: -2.474581718444824
Batch 32/64 loss: -2.7791366577148438
Batch 33/64 loss: -2.5308570861816406
Batch 34/64 loss: -2.763120651245117
Batch 35/64 loss: -2.500621795654297
Batch 36/64 loss: -2.3443288803100586
Batch 37/64 loss: -2.7643117904663086
Batch 38/64 loss: -2.349811553955078
Batch 39/64 loss: -2.778567314147949
Batch 40/64 loss: -2.7030248641967773
Batch 41/64 loss: -2.4999313354492188
Batch 42/64 loss: -2.5990381240844727
Batch 43/64 loss: -2.725820541381836
Batch 44/64 loss: -2.6598825454711914
Batch 45/64 loss: -2.7880001068115234
Batch 46/64 loss: -2.468358039855957
Batch 47/64 loss: -2.7605152130126953
Batch 48/64 loss: -2.8336238861083984
Batch 49/64 loss: -2.599214553833008
Batch 50/64 loss: -2.827080726623535
Batch 51/64 loss: -2.6026220321655273
Batch 52/64 loss: -2.7631301879882812
Batch 53/64 loss: -2.793750762939453
Batch 54/64 loss: -2.6844444274902344
Batch 55/64 loss: -2.7784948348999023
Batch 56/64 loss: -2.815155029296875
Batch 57/64 loss: -2.401026725769043
Batch 58/64 loss: -2.669510841369629
Batch 59/64 loss: -2.7508468627929688
Batch 60/64 loss: -2.200678825378418
Batch 61/64 loss: -2.485011100769043
Batch 62/64 loss: -2.453568458557129
Batch 63/64 loss: -2.411375045776367
Batch 64/64 loss: -6.932656288146973
Epoch 177  Train loss: -2.654217435799393  Val loss: -2.8953600355849645
Saving best model, epoch: 177
Epoch 178
-------------------------------
Batch 1/64 loss: -2.763068199157715
Batch 2/64 loss: -2.683079719543457
Batch 3/64 loss: -2.5981569290161133
Batch 4/64 loss: -2.6665334701538086
Batch 5/64 loss: -2.5509376525878906
Batch 6/64 loss: -2.4663047790527344
Batch 7/64 loss: -2.4484853744506836
Batch 8/64 loss: -2.3869218826293945
Batch 9/64 loss: -2.5701866149902344
Batch 10/64 loss: -2.3662052154541016
Batch 11/64 loss: -2.7517757415771484
Batch 12/64 loss: -2.5218114852905273
Batch 13/64 loss: -2.716364860534668
Batch 14/64 loss: -2.2982444763183594
Batch 15/64 loss: -2.65582275390625
Batch 16/64 loss: -2.366231918334961
Batch 17/64 loss: -2.644268035888672
Batch 18/64 loss: -2.3971853256225586
Batch 19/64 loss: -2.744645118713379
Batch 20/64 loss: -2.450594902038574
Batch 21/64 loss: -2.7391252517700195
Batch 22/64 loss: -2.7210397720336914
Batch 23/64 loss: -2.7433032989501953
Batch 24/64 loss: -2.5909900665283203
Batch 25/64 loss: -2.5031251907348633
Batch 26/64 loss: -2.8149051666259766
Batch 27/64 loss: -2.1574764251708984
Batch 28/64 loss: -2.3204832077026367
Batch 29/64 loss: -2.5937576293945312
Batch 30/64 loss: -2.503525733947754
Batch 31/64 loss: -2.732438087463379
Batch 32/64 loss: -2.7445144653320312
Batch 33/64 loss: -2.513045310974121
Batch 34/64 loss: -2.6610355377197266
Batch 35/64 loss: -2.591700553894043
Batch 36/64 loss: -2.538895606994629
Batch 37/64 loss: -2.6227264404296875
Batch 38/64 loss: -2.584906578063965
Batch 39/64 loss: -2.592418670654297
Batch 40/64 loss: -2.7875261306762695
Batch 41/64 loss: -2.269904136657715
Batch 42/64 loss: -2.4056825637817383
Batch 43/64 loss: -2.540149688720703
Batch 44/64 loss: -2.641964912414551
Batch 45/64 loss: -2.5843753814697266
Batch 46/64 loss: -2.5917959213256836
Batch 47/64 loss: -2.7009220123291016
Batch 48/64 loss: -2.642226219177246
Batch 49/64 loss: -2.3315858840942383
Batch 50/64 loss: -2.5127782821655273
Batch 51/64 loss: -2.6475696563720703
Batch 52/64 loss: -2.7429351806640625
Batch 53/64 loss: -2.545687675476074
Batch 54/64 loss: -2.5522031784057617
Batch 55/64 loss: -2.7519474029541016
Batch 56/64 loss: -2.5206680297851562
Batch 57/64 loss: -2.432077407836914
Batch 58/64 loss: -2.5797014236450195
Batch 59/64 loss: -2.360309600830078
Batch 60/64 loss: -2.6871728897094727
Batch 61/64 loss: -2.596064567565918
Batch 62/64 loss: -2.6517066955566406
Batch 63/64 loss: -2.330709457397461
Batch 64/64 loss: -7.037452220916748
Epoch 178  Train loss: -2.619639073166193  Val loss: -2.84199765130007
Epoch 179
-------------------------------
Batch 1/64 loss: -2.361454963684082
Batch 2/64 loss: -2.6864070892333984
Batch 3/64 loss: -2.480224609375
Batch 4/64 loss: -2.8348188400268555
Batch 5/64 loss: -2.550088882446289
Batch 6/64 loss: -2.3120031356811523
Batch 7/64 loss: -2.398406982421875
Batch 8/64 loss: -2.5248403549194336
Batch 9/64 loss: -2.57315731048584
Batch 10/64 loss: -2.6414546966552734
Batch 11/64 loss: -2.5358009338378906
Batch 12/64 loss: -2.7668113708496094
Batch 13/64 loss: -2.981266975402832
Batch 14/64 loss: -2.4852380752563477
Batch 15/64 loss: -2.792186737060547
Batch 16/64 loss: -2.72737979888916
Batch 17/64 loss: -2.791543960571289
Batch 18/64 loss: -2.5918664932250977
Batch 19/64 loss: -2.4194326400756836
Batch 20/64 loss: -2.6895523071289062
Batch 21/64 loss: -2.7262001037597656
Batch 22/64 loss: -2.629678726196289
Batch 23/64 loss: -2.7358198165893555
Batch 24/64 loss: -2.8236818313598633
Batch 25/64 loss: -2.8031044006347656
Batch 26/64 loss: -2.6582231521606445
Batch 27/64 loss: -2.5771589279174805
Batch 28/64 loss: -2.4025955200195312
Batch 29/64 loss: -2.128887176513672
Batch 30/64 loss: -2.4996862411499023
Batch 31/64 loss: -2.6692686080932617
Batch 32/64 loss: -2.772648811340332
Batch 33/64 loss: -2.809173583984375
Batch 34/64 loss: -2.7717180252075195
Batch 35/64 loss: -2.6858510971069336
Batch 36/64 loss: -2.812786102294922
Batch 37/64 loss: -2.2854766845703125
Batch 38/64 loss: -2.4727516174316406
Batch 39/64 loss: -2.686387062072754
Batch 40/64 loss: -2.761751174926758
Batch 41/64 loss: -2.76688289642334
Batch 42/64 loss: -2.745732307434082
Batch 43/64 loss: -2.738189697265625
Batch 44/64 loss: -2.719244956970215
Batch 45/64 loss: -2.849604606628418
Batch 46/64 loss: -2.280367851257324
Batch 47/64 loss: -2.5375213623046875
Batch 48/64 loss: -2.690484046936035
Batch 49/64 loss: -2.4783153533935547
Batch 50/64 loss: -2.6097335815429688
Batch 51/64 loss: -2.799384117126465
Batch 52/64 loss: -2.8504886627197266
Batch 53/64 loss: -2.1809873580932617
Batch 54/64 loss: -2.6147947311401367
Batch 55/64 loss: -2.685396194458008
Batch 56/64 loss: -2.4597063064575195
Batch 57/64 loss: -2.8545827865600586
Batch 58/64 loss: -2.560147285461426
Batch 59/64 loss: -2.3541746139526367
Batch 60/64 loss: -2.8263301849365234
Batch 61/64 loss: -2.7864646911621094
Batch 62/64 loss: -2.4106693267822266
Batch 63/64 loss: -2.495598793029785
Batch 64/64 loss: -7.314335823059082
Epoch 179  Train loss: -2.6766641317629345  Val loss: -2.872793794087938
Epoch 180
-------------------------------
Batch 1/64 loss: -2.684647560119629
Batch 2/64 loss: -2.0232839584350586
Batch 3/64 loss: -2.649921417236328
Batch 4/64 loss: -2.8698463439941406
Batch 5/64 loss: -2.2353668212890625
Batch 6/64 loss: -2.785144805908203
Batch 7/64 loss: -2.5069541931152344
Batch 8/64 loss: -2.659219741821289
Batch 9/64 loss: -2.608393669128418
Batch 10/64 loss: -2.5220212936401367
Batch 11/64 loss: -2.5188074111938477
Batch 12/64 loss: -2.6366662979125977
Batch 13/64 loss: -2.6602935791015625
Batch 14/64 loss: -2.572176933288574
Batch 15/64 loss: -2.3689212799072266
Batch 16/64 loss: -2.7330427169799805
Batch 17/64 loss: -2.837216377258301
Batch 18/64 loss: -2.628190040588379
Batch 19/64 loss: -2.2595338821411133
Batch 20/64 loss: -2.5660457611083984
Batch 21/64 loss: -2.6473140716552734
Batch 22/64 loss: -2.723210334777832
Batch 23/64 loss: -2.3453855514526367
Batch 24/64 loss: -2.4553403854370117
Batch 25/64 loss: -2.9298601150512695
Batch 26/64 loss: -2.605788230895996
Batch 27/64 loss: -2.647658348083496
Batch 28/64 loss: -2.3254051208496094
Batch 29/64 loss: -2.381566047668457
Batch 30/64 loss: -2.3968143463134766
Batch 31/64 loss: -2.259004592895508
Batch 32/64 loss: -2.6615982055664062
Batch 33/64 loss: -2.3449716567993164
Batch 34/64 loss: -2.4344606399536133
Batch 35/64 loss: -2.7874269485473633
Batch 36/64 loss: -2.589602470397949
Batch 37/64 loss: -2.802816390991211
Batch 38/64 loss: -2.7675914764404297
Batch 39/64 loss: -2.6466522216796875
Batch 40/64 loss: -2.662935256958008
Batch 41/64 loss: -2.6944942474365234
Batch 42/64 loss: -2.8802871704101562
Batch 43/64 loss: -2.83404541015625
Batch 44/64 loss: -2.445646286010742
Batch 45/64 loss: -2.6706981658935547
Batch 46/64 loss: -2.8918495178222656
Batch 47/64 loss: -2.7434425354003906
Batch 48/64 loss: -2.4898624420166016
Batch 49/64 loss: -2.5612974166870117
Batch 50/64 loss: -2.7339773178100586
Batch 51/64 loss: -2.545106887817383
Batch 52/64 loss: -2.6910629272460938
Batch 53/64 loss: -2.543428421020508
Batch 54/64 loss: -2.623988151550293
Batch 55/64 loss: -2.7290477752685547
Batch 56/64 loss: -2.70047664642334
Batch 57/64 loss: -2.624770164489746
Batch 58/64 loss: -2.593459129333496
Batch 59/64 loss: -2.6973791122436523
Batch 60/64 loss: -2.5746030807495117
Batch 61/64 loss: -2.877847671508789
Batch 62/64 loss: -2.383730888366699
Batch 63/64 loss: -2.492431640625
Batch 64/64 loss: -7.053626537322998
Epoch 180  Train loss: -2.6518313632291908  Val loss: -2.754711872113939
Epoch 181
-------------------------------
Batch 1/64 loss: -2.469472885131836
Batch 2/64 loss: -2.535284996032715
Batch 3/64 loss: -2.6699628829956055
Batch 4/64 loss: -2.7284469604492188
Batch 5/64 loss: -2.7048072814941406
Batch 6/64 loss: -2.6015090942382812
Batch 7/64 loss: -2.8083677291870117
Batch 8/64 loss: -2.7123804092407227
Batch 9/64 loss: -2.8591737747192383
Batch 10/64 loss: -2.6026840209960938
Batch 11/64 loss: -2.2987279891967773
Batch 12/64 loss: -2.4434022903442383
Batch 13/64 loss: -2.526787757873535
Batch 14/64 loss: -2.7231502532958984
Batch 15/64 loss: -2.6310644149780273
Batch 16/64 loss: -2.3454647064208984
Batch 17/64 loss: -2.5361862182617188
Batch 18/64 loss: -2.5578432083129883
Batch 19/64 loss: -2.8564071655273438
Batch 20/64 loss: -2.744485855102539
Batch 21/64 loss: -2.801410675048828
Batch 22/64 loss: -2.853896141052246
Batch 23/64 loss: -2.4824752807617188
Batch 24/64 loss: -2.6971025466918945
Batch 25/64 loss: -2.6759090423583984
Batch 26/64 loss: -2.651674270629883
Batch 27/64 loss: -2.7308406829833984
Batch 28/64 loss: -2.842165946960449
Batch 29/64 loss: -2.6780834197998047
Batch 30/64 loss: -2.274150848388672
Batch 31/64 loss: -2.6612682342529297
Batch 32/64 loss: -2.3666372299194336
Batch 33/64 loss: -2.316195487976074
Batch 34/64 loss: -2.830230712890625
Batch 35/64 loss: -2.6770896911621094
Batch 36/64 loss: -2.5952959060668945
Batch 37/64 loss: -2.6379709243774414
Batch 38/64 loss: -2.486286163330078
Batch 39/64 loss: -2.6698312759399414
Batch 40/64 loss: -2.603095054626465
Batch 41/64 loss: -2.7793703079223633
Batch 42/64 loss: -2.8264245986938477
Batch 43/64 loss: -2.476652145385742
Batch 44/64 loss: -2.923870086669922
Batch 45/64 loss: -2.8319435119628906
Batch 46/64 loss: -2.532700538635254
Batch 47/64 loss: -2.8029661178588867
Batch 48/64 loss: -2.726290702819824
Batch 49/64 loss: -2.6406421661376953
Batch 50/64 loss: -2.7088804244995117
Batch 51/64 loss: -2.2141876220703125
Batch 52/64 loss: -2.481684684753418
Batch 53/64 loss: -2.552541732788086
Batch 54/64 loss: -2.699228286743164
Batch 55/64 loss: -2.03548526763916
Batch 56/64 loss: -2.737298011779785
Batch 57/64 loss: -2.41104793548584
Batch 58/64 loss: -2.624582290649414
Batch 59/64 loss: -2.7131872177124023
Batch 60/64 loss: -2.514492988586426
Batch 61/64 loss: -2.622443199157715
Batch 62/64 loss: -2.658053398132324
Batch 63/64 loss: -2.8332748413085938
Batch 64/64 loss: -6.889561176300049
Epoch 181  Train loss: -2.6729668766844505  Val loss: -2.8912304094976577
Epoch 182
-------------------------------
Batch 1/64 loss: -2.743157386779785
Batch 2/64 loss: -2.8550853729248047
Batch 3/64 loss: -2.732358932495117
Batch 4/64 loss: -2.713974952697754
Batch 5/64 loss: -2.650674819946289
Batch 6/64 loss: -2.647568702697754
Batch 7/64 loss: -2.6282739639282227
Batch 8/64 loss: -2.715696334838867
Batch 9/64 loss: -2.40114688873291
Batch 10/64 loss: -2.0691261291503906
Batch 11/64 loss: -2.647597312927246
Batch 12/64 loss: -2.0541563034057617
Batch 13/64 loss: -2.649932861328125
Batch 14/64 loss: -2.51485538482666
Batch 15/64 loss: -2.6322832107543945
Batch 16/64 loss: -2.698838233947754
Batch 17/64 loss: -2.7307748794555664
Batch 18/64 loss: -2.573202133178711
Batch 19/64 loss: -2.6880064010620117
Batch 20/64 loss: -2.693826675415039
Batch 21/64 loss: -2.435704231262207
Batch 22/64 loss: -2.688265800476074
Batch 23/64 loss: -2.6507091522216797
Batch 24/64 loss: -2.8048629760742188
Batch 25/64 loss: -2.818784713745117
Batch 26/64 loss: -2.653559684753418
Batch 27/64 loss: -2.7685298919677734
Batch 28/64 loss: -2.8357629776000977
Batch 29/64 loss: -2.5600976943969727
Batch 30/64 loss: -2.428500175476074
Batch 31/64 loss: -2.49324893951416
Batch 32/64 loss: -2.692601203918457
Batch 33/64 loss: -2.8341197967529297
Batch 34/64 loss: -2.7131032943725586
Batch 35/64 loss: -2.3544254302978516
Batch 36/64 loss: -2.7579336166381836
Batch 37/64 loss: -2.698087692260742
Batch 38/64 loss: -2.50216007232666
Batch 39/64 loss: -2.723137855529785
Batch 40/64 loss: -2.5483102798461914
Batch 41/64 loss: -2.781564712524414
Batch 42/64 loss: -2.7717113494873047
Batch 43/64 loss: -2.554067611694336
Batch 44/64 loss: -2.528231620788574
Batch 45/64 loss: -2.7306814193725586
Batch 46/64 loss: -2.551654815673828
Batch 47/64 loss: -2.578237533569336
Batch 48/64 loss: -2.788865089416504
Batch 49/64 loss: -2.5284948348999023
Batch 50/64 loss: -2.8299436569213867
Batch 51/64 loss: -2.526254653930664
Batch 52/64 loss: -2.8488407135009766
Batch 53/64 loss: -2.9586029052734375
Batch 54/64 loss: -2.63222599029541
Batch 55/64 loss: -2.4813613891601562
Batch 56/64 loss: -2.6917638778686523
Batch 57/64 loss: -2.4863128662109375
Batch 58/64 loss: -2.7369613647460938
Batch 59/64 loss: -2.8542490005493164
Batch 60/64 loss: -2.694459915161133
Batch 61/64 loss: -2.6233930587768555
Batch 62/64 loss: -2.494631767272949
Batch 63/64 loss: -2.500642776489258
Batch 64/64 loss: -7.392406463623047
Epoch 182  Train loss: -2.693645492254519  Val loss: -2.8889188995885684
Epoch 183
-------------------------------
Batch 1/64 loss: -2.728358268737793
Batch 2/64 loss: -2.6699743270874023
Batch 3/64 loss: -2.406778335571289
Batch 4/64 loss: -2.4136486053466797
Batch 5/64 loss: -2.594405174255371
Batch 6/64 loss: -2.66162109375
Batch 7/64 loss: -2.8198890686035156
Batch 8/64 loss: -2.671255111694336
Batch 9/64 loss: -2.54970645904541
Batch 10/64 loss: -2.748697280883789
Batch 11/64 loss: -2.5849056243896484
Batch 12/64 loss: -2.6386499404907227
Batch 13/64 loss: -2.437100410461426
Batch 14/64 loss: -2.5041513442993164
Batch 15/64 loss: -2.684877395629883
Batch 16/64 loss: -2.3552989959716797
Batch 17/64 loss: -2.5450639724731445
Batch 18/64 loss: -2.717203140258789
Batch 19/64 loss: -2.921985626220703
Batch 20/64 loss: -2.3323984146118164
Batch 21/64 loss: -2.908310890197754
Batch 22/64 loss: -2.537430763244629
Batch 23/64 loss: -2.4916810989379883
Batch 24/64 loss: -2.5111875534057617
Batch 25/64 loss: -2.5235681533813477
Batch 26/64 loss: -2.333928108215332
Batch 27/64 loss: -2.483218193054199
Batch 28/64 loss: -2.20920467376709
Batch 29/64 loss: -2.4996204376220703
Batch 30/64 loss: -2.4117441177368164
Batch 31/64 loss: -2.683485984802246
Batch 32/64 loss: -2.7393226623535156
Batch 33/64 loss: -2.8149614334106445
Batch 34/64 loss: -2.625058174133301
Batch 35/64 loss: -2.6170644760131836
Batch 36/64 loss: -2.711589813232422
Batch 37/64 loss: -2.0802831649780273
Batch 38/64 loss: -2.902438163757324
Batch 39/64 loss: -2.8111276626586914
Batch 40/64 loss: -2.807919502258301
Batch 41/64 loss: -2.34649658203125
Batch 42/64 loss: -2.6008825302124023
Batch 43/64 loss: -2.5899181365966797
Batch 44/64 loss: -2.709996223449707
Batch 45/64 loss: -2.761219024658203
Batch 46/64 loss: -2.292910575866699
Batch 47/64 loss: -2.4831933975219727
Batch 48/64 loss: -2.4952917098999023
Batch 49/64 loss: -2.74941349029541
Batch 50/64 loss: -2.7012643814086914
Batch 51/64 loss: -2.8899879455566406
Batch 52/64 loss: -2.6716365814208984
Batch 53/64 loss: -2.31862735748291
Batch 54/64 loss: -2.845193862915039
Batch 55/64 loss: -2.805908203125
Batch 56/64 loss: -2.7379417419433594
Batch 57/64 loss: -2.8863096237182617
Batch 58/64 loss: -2.674504280090332
Batch 59/64 loss: -2.7850770950317383
Batch 60/64 loss: -2.8780765533447266
Batch 61/64 loss: -2.841578483581543
Batch 62/64 loss: -2.701620101928711
Batch 63/64 loss: -2.344723701477051
Batch 64/64 loss: -7.019461631774902
Epoch 183  Train loss: -2.667693826264026  Val loss: -2.865343480585367
Epoch 184
-------------------------------
Batch 1/64 loss: -2.649534225463867
Batch 2/64 loss: -2.2502822875976562
Batch 3/64 loss: -2.5310564041137695
Batch 4/64 loss: -2.408907890319824
Batch 5/64 loss: -2.3782997131347656
Batch 6/64 loss: -2.1688270568847656
Batch 7/64 loss: -2.7033252716064453
Batch 8/64 loss: -2.5713701248168945
Batch 9/64 loss: -2.392536163330078
Batch 10/64 loss: -2.749638557434082
Batch 11/64 loss: -2.6224050521850586
Batch 12/64 loss: -2.6391286849975586
Batch 13/64 loss: -2.509702682495117
Batch 14/64 loss: -2.782668113708496
Batch 15/64 loss: -2.8041744232177734
Batch 16/64 loss: -2.6760330200195312
Batch 17/64 loss: -2.605105400085449
Batch 18/64 loss: -2.751898765563965
Batch 19/64 loss: -2.778689384460449
Batch 20/64 loss: -2.929692268371582
Batch 21/64 loss: -2.6220293045043945
Batch 22/64 loss: -2.5210494995117188
Batch 23/64 loss: -2.5230607986450195
Batch 24/64 loss: -2.4979724884033203
Batch 25/64 loss: -2.666431427001953
Batch 26/64 loss: -2.879134178161621
Batch 27/64 loss: -2.1228713989257812
Batch 28/64 loss: -2.6969804763793945
Batch 29/64 loss: -2.6932668685913086
Batch 30/64 loss: -2.3935956954956055
Batch 31/64 loss: -2.7395973205566406
Batch 32/64 loss: -2.810853958129883
Batch 33/64 loss: -2.4962635040283203
Batch 34/64 loss: -2.6524534225463867
Batch 35/64 loss: -2.9495277404785156
Batch 36/64 loss: -2.7741966247558594
Batch 37/64 loss: -2.807117462158203
Batch 38/64 loss: -2.532693862915039
Batch 39/64 loss: -2.2314205169677734
Batch 40/64 loss: -1.9075813293457031
Batch 41/64 loss: -2.5701522827148438
Batch 42/64 loss: -2.8219947814941406
Batch 43/64 loss: -2.8733272552490234
Batch 44/64 loss: -2.7281789779663086
Batch 45/64 loss: -2.4385251998901367
Batch 46/64 loss: -2.774977684020996
Batch 47/64 loss: -2.785480499267578
Batch 48/64 loss: -2.784714698791504
Batch 49/64 loss: -2.5654115676879883
Batch 50/64 loss: -2.5871801376342773
Batch 51/64 loss: -2.7224178314208984
Batch 52/64 loss: -2.5814361572265625
Batch 53/64 loss: -2.7253007888793945
Batch 54/64 loss: -2.5691938400268555
Batch 55/64 loss: -2.781522750854492
Batch 56/64 loss: -2.3872976303100586
Batch 57/64 loss: -2.594264030456543
Batch 58/64 loss: -2.5967140197753906
Batch 59/64 loss: -2.6333494186401367
Batch 60/64 loss: -2.8065662384033203
Batch 61/64 loss: -2.4174203872680664
Batch 62/64 loss: -2.476215362548828
Batch 63/64 loss: -2.6186742782592773
Batch 64/64 loss: -7.392353534698486
Epoch 184  Train loss: -2.663622813131295  Val loss: -2.89774464086159
Saving best model, epoch: 184
Epoch 185
-------------------------------
Batch 1/64 loss: -2.6344404220581055
Batch 2/64 loss: -2.5673561096191406
Batch 3/64 loss: -2.544382095336914
Batch 4/64 loss: -2.6055660247802734
Batch 5/64 loss: -2.659923553466797
Batch 6/64 loss: -2.5847368240356445
Batch 7/64 loss: -2.6756839752197266
Batch 8/64 loss: -2.687811851501465
Batch 9/64 loss: -2.8116416931152344
Batch 10/64 loss: -2.188082695007324
Batch 11/64 loss: -2.9486236572265625
Batch 12/64 loss: -2.522859573364258
Batch 13/64 loss: -2.5814743041992188
Batch 14/64 loss: -2.8232975006103516
Batch 15/64 loss: -2.5395288467407227
Batch 16/64 loss: -2.540498733520508
Batch 17/64 loss: -2.426424026489258
Batch 18/64 loss: -2.486703872680664
Batch 19/64 loss: -2.600435256958008
Batch 20/64 loss: -2.751628875732422
Batch 21/64 loss: -2.7272510528564453
Batch 22/64 loss: -2.5987234115600586
Batch 23/64 loss: -2.6333789825439453
Batch 24/64 loss: -2.5456247329711914
Batch 25/64 loss: -2.77993106842041
Batch 26/64 loss: -2.7555055618286133
Batch 27/64 loss: -2.6683177947998047
Batch 28/64 loss: -2.799680709838867
Batch 29/64 loss: -2.6141395568847656
Batch 30/64 loss: -2.724151611328125
Batch 31/64 loss: -2.7474679946899414
Batch 32/64 loss: -2.618682861328125
Batch 33/64 loss: -2.6258506774902344
Batch 34/64 loss: -2.6950273513793945
Batch 35/64 loss: -2.668642044067383
Batch 36/64 loss: -2.5967416763305664
Batch 37/64 loss: -2.5466346740722656
Batch 38/64 loss: -2.689864158630371
Batch 39/64 loss: -2.603055000305176
Batch 40/64 loss: -2.5437917709350586
Batch 41/64 loss: -2.2083616256713867
Batch 42/64 loss: -1.9777421951293945
Batch 43/64 loss: -2.3949155807495117
Batch 44/64 loss: -2.9581298828125
Batch 45/64 loss: -2.7111024856567383
Batch 46/64 loss: -2.5514936447143555
Batch 47/64 loss: -2.2903738021850586
Batch 48/64 loss: -2.568592071533203
Batch 49/64 loss: -2.5881166458129883
Batch 50/64 loss: -2.468860626220703
Batch 51/64 loss: -2.357868194580078
Batch 52/64 loss: -2.531940460205078
Batch 53/64 loss: -2.477969169616699
Batch 54/64 loss: -2.79705810546875
Batch 55/64 loss: -2.4210329055786133
Batch 56/64 loss: -2.6134157180786133
Batch 57/64 loss: -2.5953454971313477
Batch 58/64 loss: -2.392157554626465
Batch 59/64 loss: -2.5777359008789062
Batch 60/64 loss: -2.846693992614746
Batch 61/64 loss: -2.3162174224853516
Batch 62/64 loss: -2.773533821105957
Batch 63/64 loss: -2.654820442199707
Batch 64/64 loss: -7.2139763832092285
Epoch 185  Train loss: -2.6485885900609634  Val loss: -2.728395494808446
Epoch 186
-------------------------------
Batch 1/64 loss: -2.768599510192871
Batch 2/64 loss: -2.6435365676879883
Batch 3/64 loss: -2.803804397583008
Batch 4/64 loss: -2.7192516326904297
Batch 5/64 loss: -2.728581428527832
Batch 6/64 loss: -2.856198310852051
Batch 7/64 loss: -2.7251148223876953
Batch 8/64 loss: -2.643918991088867
Batch 9/64 loss: -2.7429122924804688
Batch 10/64 loss: -2.3807830810546875
Batch 11/64 loss: -2.788341522216797
Batch 12/64 loss: -2.803126335144043
Batch 13/64 loss: -2.944155693054199
Batch 14/64 loss: -2.657647132873535
Batch 15/64 loss: -2.7068796157836914
Batch 16/64 loss: -2.7646236419677734
Batch 17/64 loss: -2.262340545654297
Batch 18/64 loss: -2.7520694732666016
Batch 19/64 loss: -2.7403640747070312
Batch 20/64 loss: -2.4178457260131836
Batch 21/64 loss: -2.545377731323242
Batch 22/64 loss: -2.7068910598754883
Batch 23/64 loss: -2.7487945556640625
Batch 24/64 loss: -2.6827707290649414
Batch 25/64 loss: -2.84749698638916
Batch 26/64 loss: -2.6845903396606445
Batch 27/64 loss: -2.6855592727661133
Batch 28/64 loss: -2.772247314453125
Batch 29/64 loss: -2.213075637817383
Batch 30/64 loss: -2.577633857727051
Batch 31/64 loss: -2.5401105880737305
Batch 32/64 loss: -2.6343183517456055
Batch 33/64 loss: -2.7978153228759766
Batch 34/64 loss: -2.6336746215820312
Batch 35/64 loss: -2.8150548934936523
Batch 36/64 loss: -2.6385364532470703
Batch 37/64 loss: -2.814441680908203
Batch 38/64 loss: -2.2605104446411133
Batch 39/64 loss: -2.329920768737793
Batch 40/64 loss: -2.734320640563965
Batch 41/64 loss: -2.747190475463867
Batch 42/64 loss: -2.5456113815307617
Batch 43/64 loss: -2.5161781311035156
Batch 44/64 loss: -2.6687936782836914
Batch 45/64 loss: -2.424586296081543
Batch 46/64 loss: -2.21591854095459
Batch 47/64 loss: -2.4578237533569336
Batch 48/64 loss: -2.705845832824707
Batch 49/64 loss: -2.0523767471313477
Batch 50/64 loss: -2.663699150085449
Batch 51/64 loss: -2.3790531158447266
Batch 52/64 loss: -2.5737438201904297
Batch 53/64 loss: -2.444925308227539
Batch 54/64 loss: -2.273322105407715
Batch 55/64 loss: -2.5954952239990234
Batch 56/64 loss: -2.3540430068969727
Batch 57/64 loss: -2.5056943893432617
Batch 58/64 loss: -2.755462646484375
Batch 59/64 loss: -2.502971649169922
Batch 60/64 loss: -2.6438827514648438
Batch 61/64 loss: -2.146967887878418
Batch 62/64 loss: -2.470669746398926
Batch 63/64 loss: -2.4284181594848633
Batch 64/64 loss: -7.243892192840576
Epoch 186  Train loss: -2.651275748832553  Val loss: -2.8468692556689286
Epoch 187
-------------------------------
Batch 1/64 loss: -2.697999954223633
Batch 2/64 loss: -2.7730178833007812
Batch 3/64 loss: -2.7529544830322266
Batch 4/64 loss: -2.6980152130126953
Batch 5/64 loss: -2.8767709732055664
Batch 6/64 loss: -2.470280647277832
Batch 7/64 loss: -2.458773612976074
Batch 8/64 loss: -2.541934013366699
Batch 9/64 loss: -2.232358932495117
Batch 10/64 loss: -2.6682519912719727
Batch 11/64 loss: -2.5905752182006836
Batch 12/64 loss: -2.6246681213378906
Batch 13/64 loss: -2.7856616973876953
Batch 14/64 loss: -2.385641098022461
Batch 15/64 loss: -2.8921079635620117
Batch 16/64 loss: -2.5887880325317383
Batch 17/64 loss: -2.6722660064697266
Batch 18/64 loss: -2.331157684326172
Batch 19/64 loss: -2.875978469848633
Batch 20/64 loss: -2.601759910583496
Batch 21/64 loss: -2.447134017944336
Batch 22/64 loss: -2.5363264083862305
Batch 23/64 loss: -2.5491390228271484
Batch 24/64 loss: -2.717020034790039
Batch 25/64 loss: -2.529026985168457
Batch 26/64 loss: -2.8668127059936523
Batch 27/64 loss: -2.067211151123047
Batch 28/64 loss: -2.829808235168457
Batch 29/64 loss: -2.212869644165039
Batch 30/64 loss: -2.7347164154052734
Batch 31/64 loss: -2.426945686340332
Batch 32/64 loss: -2.660612106323242
Batch 33/64 loss: -2.4777307510375977
Batch 34/64 loss: -2.469881057739258
Batch 35/64 loss: -2.8029708862304688
Batch 36/64 loss: -2.449106216430664
Batch 37/64 loss: -2.5246667861938477
Batch 38/64 loss: -2.5068626403808594
Batch 39/64 loss: -2.8334531784057617
Batch 40/64 loss: -2.525136947631836
Batch 41/64 loss: -2.560654640197754
Batch 42/64 loss: -2.6746129989624023
Batch 43/64 loss: -2.5811758041381836
Batch 44/64 loss: -2.658196449279785
Batch 45/64 loss: -2.4560890197753906
Batch 46/64 loss: -2.2258081436157227
Batch 47/64 loss: -2.5902862548828125
Batch 48/64 loss: -2.9536123275756836
Batch 49/64 loss: -2.7300615310668945
Batch 50/64 loss: -2.6076526641845703
Batch 51/64 loss: -2.44876766204834
Batch 52/64 loss: -2.367987632751465
Batch 53/64 loss: -2.8555164337158203
Batch 54/64 loss: -2.602889060974121
Batch 55/64 loss: -2.558572769165039
Batch 56/64 loss: -2.713934898376465
Batch 57/64 loss: -2.781841278076172
Batch 58/64 loss: -2.822694778442383
Batch 59/64 loss: -2.6405229568481445
Batch 60/64 loss: -2.4372682571411133
Batch 61/64 loss: -2.4927453994750977
Batch 62/64 loss: -2.5845813751220703
Batch 63/64 loss: -2.7327041625976562
Batch 64/64 loss: -6.85415506362915
Epoch 187  Train loss: -2.649493107141233  Val loss: -2.7721501379897915
Epoch 188
-------------------------------
Batch 1/64 loss: -2.443488121032715
Batch 2/64 loss: -2.3139123916625977
Batch 3/64 loss: -2.3780765533447266
Batch 4/64 loss: -2.681546211242676
Batch 5/64 loss: -2.402294158935547
Batch 6/64 loss: -2.8015365600585938
Batch 7/64 loss: -2.754972457885742
Batch 8/64 loss: -2.8252792358398438
Batch 9/64 loss: -2.230194091796875
Batch 10/64 loss: -2.701869010925293
Batch 11/64 loss: -2.22182559967041
Batch 12/64 loss: -2.7659664154052734
Batch 13/64 loss: -2.675116539001465
Batch 14/64 loss: -2.6365795135498047
Batch 15/64 loss: -2.783921241760254
Batch 16/64 loss: -2.897855758666992
Batch 17/64 loss: -2.65509033203125
Batch 18/64 loss: -2.713214874267578
Batch 19/64 loss: -2.530606269836426
Batch 20/64 loss: -2.5984153747558594
Batch 21/64 loss: -2.600534439086914
Batch 22/64 loss: -2.5838499069213867
Batch 23/64 loss: -2.5402822494506836
Batch 24/64 loss: -2.5944252014160156
Batch 25/64 loss: -2.572140693664551
Batch 26/64 loss: -2.761331558227539
Batch 27/64 loss: -2.2204504013061523
Batch 28/64 loss: -2.76444149017334
Batch 29/64 loss: -2.6027135848999023
Batch 30/64 loss: -2.6132116317749023
Batch 31/64 loss: -2.3981943130493164
Batch 32/64 loss: -2.3046674728393555
Batch 33/64 loss: -2.2994985580444336
Batch 34/64 loss: -2.400935173034668
Batch 35/64 loss: -2.7641735076904297
Batch 36/64 loss: -2.157334327697754
Batch 37/64 loss: -2.676882743835449
Batch 38/64 loss: -2.5034046173095703
Batch 39/64 loss: -2.6825084686279297
Batch 40/64 loss: -2.2970142364501953
Batch 41/64 loss: -2.6669483184814453
Batch 42/64 loss: -2.6733903884887695
Batch 43/64 loss: -2.416008949279785
Batch 44/64 loss: -2.519545555114746
Batch 45/64 loss: -2.6543359756469727
Batch 46/64 loss: -2.8188705444335938
Batch 47/64 loss: -2.868877410888672
Batch 48/64 loss: -2.5857934951782227
Batch 49/64 loss: -2.582324981689453
Batch 50/64 loss: -2.7846813201904297
Batch 51/64 loss: -2.7311534881591797
Batch 52/64 loss: -2.799288749694824
Batch 53/64 loss: -2.8916215896606445
Batch 54/64 loss: -2.6552677154541016
Batch 55/64 loss: -2.393965721130371
Batch 56/64 loss: -2.605955123901367
Batch 57/64 loss: -2.730380058288574
Batch 58/64 loss: -2.7076759338378906
Batch 59/64 loss: -2.6760568618774414
Batch 60/64 loss: -2.6327943801879883
Batch 61/64 loss: -2.568112373352051
Batch 62/64 loss: -2.634187698364258
Batch 63/64 loss: -2.391925811767578
Batch 64/64 loss: -7.130027770996094
Epoch 188  Train loss: -2.646061781340954  Val loss: -2.8618814658463205
Epoch 189
-------------------------------
Batch 1/64 loss: -1.9241905212402344
Batch 2/64 loss: -2.5304718017578125
Batch 3/64 loss: -2.7597904205322266
Batch 4/64 loss: -2.772348403930664
Batch 5/64 loss: -2.7826337814331055
Batch 6/64 loss: -2.8469667434692383
Batch 7/64 loss: -2.4016151428222656
Batch 8/64 loss: -2.5951757431030273
Batch 9/64 loss: -2.689502716064453
Batch 10/64 loss: -2.660372734069824
Batch 11/64 loss: -2.626127243041992
Batch 12/64 loss: -2.813291549682617
Batch 13/64 loss: -2.565633773803711
Batch 14/64 loss: -2.805636405944824
Batch 15/64 loss: -2.4853200912475586
Batch 16/64 loss: -2.4935197830200195
Batch 17/64 loss: -2.6504554748535156
Batch 18/64 loss: -2.542841911315918
Batch 19/64 loss: -2.7931880950927734
Batch 20/64 loss: -2.7087297439575195
Batch 21/64 loss: -2.5273780822753906
Batch 22/64 loss: -2.5693511962890625
Batch 23/64 loss: -2.67919921875
Batch 24/64 loss: -2.735926628112793
Batch 25/64 loss: -2.3182334899902344
Batch 26/64 loss: -2.8615846633911133
Batch 27/64 loss: -2.8048715591430664
Batch 28/64 loss: -2.7870922088623047
Batch 29/64 loss: -2.3212976455688477
Batch 30/64 loss: -2.5742321014404297
Batch 31/64 loss: -2.422274589538574
Batch 32/64 loss: -2.656515121459961
Batch 33/64 loss: -2.6073970794677734
Batch 34/64 loss: -2.75360107421875
Batch 35/64 loss: -2.4565954208374023
Batch 36/64 loss: -2.2084970474243164
Batch 37/64 loss: -2.7136363983154297
Batch 38/64 loss: -2.717127799987793
Batch 39/64 loss: -2.396794319152832
Batch 40/64 loss: -2.5460920333862305
Batch 41/64 loss: -2.307952880859375
Batch 42/64 loss: -2.7209901809692383
Batch 43/64 loss: -2.5180978775024414
Batch 44/64 loss: -2.8033761978149414
Batch 45/64 loss: -2.7898826599121094
Batch 46/64 loss: -2.614628791809082
Batch 47/64 loss: -2.758793830871582
Batch 48/64 loss: -2.593520164489746
Batch 49/64 loss: -2.575704574584961
Batch 50/64 loss: -2.69504451751709
Batch 51/64 loss: -2.722522735595703
Batch 52/64 loss: -2.7870712280273438
Batch 53/64 loss: -2.669191360473633
Batch 54/64 loss: -2.881596565246582
Batch 55/64 loss: -2.8830108642578125
Batch 56/64 loss: -2.829747200012207
Batch 57/64 loss: -2.5975685119628906
Batch 58/64 loss: -2.762240409851074
Batch 59/64 loss: -2.5196285247802734
Batch 60/64 loss: -2.2454795837402344
Batch 61/64 loss: -2.179377555847168
Batch 62/64 loss: -2.347909927368164
Batch 63/64 loss: -2.6691551208496094
Batch 64/64 loss: -6.902095794677734
Epoch 189  Train loss: -2.6628168293074066  Val loss: -2.8167722774125457
Epoch 190
-------------------------------
Batch 1/64 loss: -2.6760025024414062
Batch 2/64 loss: -2.586775779724121
Batch 3/64 loss: -2.4511804580688477
Batch 4/64 loss: -2.3689775466918945
Batch 5/64 loss: -2.778146743774414
Batch 6/64 loss: -2.4821109771728516
Batch 7/64 loss: -2.815455436706543
Batch 8/64 loss: -2.564297676086426
Batch 9/64 loss: -2.392148971557617
Batch 10/64 loss: -2.3291683197021484
Batch 11/64 loss: -2.574953079223633
Batch 12/64 loss: -2.113144874572754
Batch 13/64 loss: -2.5167179107666016
Batch 14/64 loss: -2.5573272705078125
Batch 15/64 loss: -2.7650718688964844
Batch 16/64 loss: -2.6461849212646484
Batch 17/64 loss: -2.5791091918945312
Batch 18/64 loss: -2.7605161666870117
Batch 19/64 loss: -2.278017044067383
Batch 20/64 loss: -2.522296905517578
Batch 21/64 loss: -2.7762985229492188
Batch 22/64 loss: -2.4149961471557617
Batch 23/64 loss: -2.602410316467285
Batch 24/64 loss: -2.5657825469970703
Batch 25/64 loss: -2.5576343536376953
Batch 26/64 loss: -2.407379150390625
Batch 27/64 loss: -2.914827346801758
Batch 28/64 loss: -2.454594612121582
Batch 29/64 loss: -2.562375068664551
Batch 30/64 loss: -2.6532859802246094
Batch 31/64 loss: -2.701810836791992
Batch 32/64 loss: -2.4472389221191406
Batch 33/64 loss: -2.4945154190063477
Batch 34/64 loss: -2.5039405822753906
Batch 35/64 loss: -2.6676769256591797
Batch 36/64 loss: -2.738677978515625
Batch 37/64 loss: -2.595876693725586
Batch 38/64 loss: -2.6334095001220703
Batch 39/64 loss: -2.711928367614746
Batch 40/64 loss: -2.7562246322631836
Batch 41/64 loss: -2.7978086471557617
Batch 42/64 loss: -2.337087631225586
Batch 43/64 loss: -2.762166976928711
Batch 44/64 loss: -2.3779220581054688
Batch 45/64 loss: -2.621504783630371
Batch 46/64 loss: -2.8018531799316406
Batch 47/64 loss: -2.676187515258789
Batch 48/64 loss: -2.3981761932373047
Batch 49/64 loss: -2.542665481567383
Batch 50/64 loss: -2.512287139892578
Batch 51/64 loss: -2.754680633544922
Batch 52/64 loss: -2.46185302734375
Batch 53/64 loss: -2.5392913818359375
Batch 54/64 loss: -2.7030696868896484
Batch 55/64 loss: -2.7382450103759766
Batch 56/64 loss: -2.271733283996582
Batch 57/64 loss: -2.7712717056274414
Batch 58/64 loss: -2.6321420669555664
Batch 59/64 loss: -2.6457509994506836
Batch 60/64 loss: -2.449254035949707
Batch 61/64 loss: -2.7281341552734375
Batch 62/64 loss: -2.5294485092163086
Batch 63/64 loss: -2.6726646423339844
Batch 64/64 loss: -7.071535587310791
Epoch 190  Train loss: -2.6344680468241375  Val loss: -2.820636906574682
Epoch 191
-------------------------------
Batch 1/64 loss: -2.472174644470215
Batch 2/64 loss: -2.264479637145996
Batch 3/64 loss: -2.652899742126465
Batch 4/64 loss: -2.780294418334961
Batch 5/64 loss: -2.625621795654297
Batch 6/64 loss: -2.86032772064209
Batch 7/64 loss: -2.7097387313842773
Batch 8/64 loss: -2.751376152038574
Batch 9/64 loss: -2.6578264236450195
Batch 10/64 loss: -2.70058536529541
Batch 11/64 loss: -2.401601791381836
Batch 12/64 loss: -2.7150821685791016
Batch 13/64 loss: -2.823972702026367
Batch 14/64 loss: -2.5491085052490234
Batch 15/64 loss: -2.8567094802856445
Batch 16/64 loss: -2.6243515014648438
Batch 17/64 loss: -2.3410825729370117
Batch 18/64 loss: -2.4952831268310547
Batch 19/64 loss: -2.5734691619873047
Batch 20/64 loss: -2.673457145690918
Batch 21/64 loss: -2.7569103240966797
Batch 22/64 loss: -2.7278928756713867
Batch 23/64 loss: -2.7381973266601562
Batch 24/64 loss: -2.594280242919922
Batch 25/64 loss: -2.6282005310058594
Batch 26/64 loss: -2.7123937606811523
Batch 27/64 loss: -2.5810909271240234
Batch 28/64 loss: -2.813992500305176
Batch 29/64 loss: -2.540513038635254
Batch 30/64 loss: -2.4287109375
Batch 31/64 loss: -2.5507898330688477
Batch 32/64 loss: -2.6132888793945312
Batch 33/64 loss: -2.764974594116211
Batch 34/64 loss: -2.49991512298584
Batch 35/64 loss: -2.8302202224731445
Batch 36/64 loss: -2.834726333618164
Batch 37/64 loss: -2.700503349304199
Batch 38/64 loss: -2.792109489440918
Batch 39/64 loss: -2.705463409423828
Batch 40/64 loss: -2.6112136840820312
Batch 41/64 loss: -2.8173837661743164
Batch 42/64 loss: -2.695828437805176
Batch 43/64 loss: -2.7090940475463867
Batch 44/64 loss: -2.683505058288574
Batch 45/64 loss: -2.7644777297973633
Batch 46/64 loss: -2.6311264038085938
Batch 47/64 loss: -2.6095361709594727
Batch 48/64 loss: -2.558722496032715
Batch 49/64 loss: -2.1018686294555664
Batch 50/64 loss: -2.61160945892334
Batch 51/64 loss: -2.5158843994140625
Batch 52/64 loss: -2.1835641860961914
Batch 53/64 loss: -2.3858652114868164
Batch 54/64 loss: -2.3457422256469727
Batch 55/64 loss: -2.76387882232666
Batch 56/64 loss: -2.572829246520996
Batch 57/64 loss: -2.7149314880371094
Batch 58/64 loss: -2.2696313858032227
Batch 59/64 loss: -2.5397186279296875
Batch 60/64 loss: -2.650571823120117
Batch 61/64 loss: -2.731273651123047
Batch 62/64 loss: -2.4374046325683594
Batch 63/64 loss: -2.8670578002929688
Batch 64/64 loss: -7.11518669128418
Epoch 191  Train loss: -2.673768249212527  Val loss: -2.833496893394444
Epoch 192
-------------------------------
Batch 1/64 loss: -2.710312843322754
Batch 2/64 loss: -2.5606822967529297
Batch 3/64 loss: -2.711012840270996
Batch 4/64 loss: -2.662661552429199
Batch 5/64 loss: -2.8925228118896484
Batch 6/64 loss: -2.7669496536254883
Batch 7/64 loss: -2.7370500564575195
Batch 8/64 loss: -2.440373420715332
Batch 9/64 loss: -2.56522274017334
Batch 10/64 loss: -2.6237659454345703
Batch 11/64 loss: -2.7064285278320312
Batch 12/64 loss: -2.695958137512207
Batch 13/64 loss: -2.6082191467285156
Batch 14/64 loss: -2.761843681335449
Batch 15/64 loss: -2.49825382232666
Batch 16/64 loss: -2.4580726623535156
Batch 17/64 loss: -2.774674415588379
Batch 18/64 loss: -2.3225250244140625
Batch 19/64 loss: -2.3295907974243164
Batch 20/64 loss: -2.8357009887695312
Batch 21/64 loss: -2.814472198486328
Batch 22/64 loss: -2.6629638671875
Batch 23/64 loss: -2.7992658615112305
Batch 24/64 loss: -2.165858268737793
Batch 25/64 loss: -2.4323129653930664
Batch 26/64 loss: -2.7269678115844727
Batch 27/64 loss: -2.370147705078125
Batch 28/64 loss: -2.8690032958984375
Batch 29/64 loss: -2.5893383026123047
Batch 30/64 loss: -2.4344310760498047
Batch 31/64 loss: -2.623745918273926
Batch 32/64 loss: -2.692707061767578
Batch 33/64 loss: -2.6706809997558594
Batch 34/64 loss: -2.671194076538086
Batch 35/64 loss: -2.4777088165283203
Batch 36/64 loss: -2.729503631591797
Batch 37/64 loss: -2.755809783935547
Batch 38/64 loss: -2.7386207580566406
Batch 39/64 loss: -2.754169464111328
Batch 40/64 loss: -2.7737302780151367
Batch 41/64 loss: -2.890683174133301
Batch 42/64 loss: -2.5123071670532227
Batch 43/64 loss: -2.6679258346557617
Batch 44/64 loss: -2.7518138885498047
Batch 45/64 loss: -2.832918167114258
Batch 46/64 loss: -2.6613731384277344
Batch 47/64 loss: -2.53781795501709
Batch 48/64 loss: -2.460127830505371
Batch 49/64 loss: -2.6116771697998047
Batch 50/64 loss: -2.6664953231811523
Batch 51/64 loss: -2.800724983215332
Batch 52/64 loss: -2.3108205795288086
Batch 53/64 loss: -2.868037223815918
Batch 54/64 loss: -2.5206804275512695
Batch 55/64 loss: -2.6794891357421875
Batch 56/64 loss: -2.62526798248291
Batch 57/64 loss: -2.266521453857422
Batch 58/64 loss: -2.786224365234375
Batch 59/64 loss: -2.734015464782715
Batch 60/64 loss: -2.698698043823242
Batch 61/64 loss: -2.520657539367676
Batch 62/64 loss: -2.5296096801757812
Batch 63/64 loss: -2.6291236877441406
Batch 64/64 loss: -7.177459239959717
Epoch 192  Train loss: -2.6880087553286085  Val loss: -2.873660372704575
Epoch 193
-------------------------------
Batch 1/64 loss: -2.7026405334472656
Batch 2/64 loss: -2.3733644485473633
Batch 3/64 loss: -2.7637939453125
Batch 4/64 loss: -2.8296127319335938
Batch 5/64 loss: -2.6825971603393555
Batch 6/64 loss: -2.6174612045288086
Batch 7/64 loss: -2.9332284927368164
Batch 8/64 loss: -2.9620752334594727
Batch 9/64 loss: -2.6138811111450195
Batch 10/64 loss: -2.488266944885254
Batch 11/64 loss: -2.815728187561035
Batch 12/64 loss: -2.6812915802001953
Batch 13/64 loss: -2.5687503814697266
Batch 14/64 loss: -2.8360471725463867
Batch 15/64 loss: -2.61074161529541
Batch 16/64 loss: -2.738692283630371
Batch 17/64 loss: -2.4829940795898438
Batch 18/64 loss: -2.619020462036133
Batch 19/64 loss: -2.5437583923339844
Batch 20/64 loss: -2.80452823638916
Batch 21/64 loss: -2.453118324279785
Batch 22/64 loss: -2.6597518920898438
Batch 23/64 loss: -2.5783443450927734
Batch 24/64 loss: -2.692575454711914
Batch 25/64 loss: -2.795938491821289
Batch 26/64 loss: -2.6170740127563477
Batch 27/64 loss: -2.7071571350097656
Batch 28/64 loss: -2.564181327819824
Batch 29/64 loss: -2.703761100769043
Batch 30/64 loss: -2.577219009399414
Batch 31/64 loss: -2.7126598358154297
Batch 32/64 loss: -2.642416000366211
Batch 33/64 loss: -2.8701210021972656
Batch 34/64 loss: -2.2755794525146484
Batch 35/64 loss: -2.6154870986938477
Batch 36/64 loss: -2.9003868103027344
Batch 37/64 loss: -2.5306100845336914
Batch 38/64 loss: -2.7522478103637695
Batch 39/64 loss: -2.629672050476074
Batch 40/64 loss: -2.2106285095214844
Batch 41/64 loss: -2.701727867126465
Batch 42/64 loss: -2.7496042251586914
Batch 43/64 loss: -2.6794376373291016
Batch 44/64 loss: -2.7395458221435547
Batch 45/64 loss: -2.7244701385498047
Batch 46/64 loss: -2.7528886795043945
Batch 47/64 loss: -2.5499706268310547
Batch 48/64 loss: -2.508725166320801
Batch 49/64 loss: -2.805265426635742
Batch 50/64 loss: -2.397505760192871
Batch 51/64 loss: -2.8322696685791016
Batch 52/64 loss: -2.453126907348633
Batch 53/64 loss: -2.454339027404785
Batch 54/64 loss: -2.7539100646972656
Batch 55/64 loss: -2.5253076553344727
Batch 56/64 loss: -2.669361114501953
Batch 57/64 loss: -2.667104721069336
Batch 58/64 loss: -2.688521385192871
Batch 59/64 loss: -2.783224105834961
Batch 60/64 loss: -2.7248620986938477
Batch 61/64 loss: -2.7034616470336914
Batch 62/64 loss: -2.7330217361450195
Batch 63/64 loss: -2.759406089782715
Batch 64/64 loss: -7.121674537658691
Epoch 193  Train loss: -2.7114622340482826  Val loss: -2.8519988043611404
Epoch 194
-------------------------------
Batch 1/64 loss: -2.700773239135742
Batch 2/64 loss: -2.842715263366699
Batch 3/64 loss: -2.963189125061035
Batch 4/64 loss: -2.667609214782715
Batch 5/64 loss: -2.5544862747192383
Batch 6/64 loss: -2.909928321838379
Batch 7/64 loss: -2.785083770751953
Batch 8/64 loss: -2.838754653930664
Batch 9/64 loss: -2.7522811889648438
Batch 10/64 loss: -2.4221925735473633
Batch 11/64 loss: -2.745039939880371
Batch 12/64 loss: -2.3758106231689453
Batch 13/64 loss: -2.7091493606567383
Batch 14/64 loss: -2.7938461303710938
Batch 15/64 loss: -2.889392852783203
Batch 16/64 loss: -2.588958740234375
Batch 17/64 loss: -2.67844295501709
Batch 18/64 loss: -2.4951257705688477
Batch 19/64 loss: -2.5793228149414062
Batch 20/64 loss: -2.7862586975097656
Batch 21/64 loss: -2.6290950775146484
Batch 22/64 loss: -2.6599225997924805
Batch 23/64 loss: -2.337352752685547
Batch 24/64 loss: -2.7204904556274414
Batch 25/64 loss: -2.647165298461914
Batch 26/64 loss: -2.8111305236816406
Batch 27/64 loss: -2.7136030197143555
Batch 28/64 loss: -2.6672000885009766
Batch 29/64 loss: -2.6814041137695312
Batch 30/64 loss: -2.617593765258789
Batch 31/64 loss: -2.7212181091308594
Batch 32/64 loss: -2.3700923919677734
Batch 33/64 loss: -2.2092227935791016
Batch 34/64 loss: -2.4241018295288086
Batch 35/64 loss: -2.365903854370117
Batch 36/64 loss: -2.636545181274414
Batch 37/64 loss: -2.83675479888916
Batch 38/64 loss: -2.6108007431030273
Batch 39/64 loss: -2.8130311965942383
Batch 40/64 loss: -2.7636098861694336
Batch 41/64 loss: -2.599095344543457
Batch 42/64 loss: -2.611307144165039
Batch 43/64 loss: -2.477217674255371
Batch 44/64 loss: -2.8135223388671875
Batch 45/64 loss: -2.831939697265625
Batch 46/64 loss: -2.831136703491211
Batch 47/64 loss: -2.786005973815918
Batch 48/64 loss: -2.6238136291503906
Batch 49/64 loss: -2.5888872146606445
Batch 50/64 loss: -2.318462371826172
Batch 51/64 loss: -2.731536865234375
Batch 52/64 loss: -2.735501289367676
Batch 53/64 loss: -2.4730119705200195
Batch 54/64 loss: -2.611722946166992
Batch 55/64 loss: -2.762417793273926
Batch 56/64 loss: -2.627565383911133
Batch 57/64 loss: -2.7351932525634766
Batch 58/64 loss: -2.7338380813598633
Batch 59/64 loss: -2.7964773178100586
Batch 60/64 loss: -2.592160224914551
Batch 61/64 loss: -2.4586105346679688
Batch 62/64 loss: -2.9168548583984375
Batch 63/64 loss: -2.774752616882324
Batch 64/64 loss: -7.078402042388916
Epoch 194  Train loss: -2.7145793372509526  Val loss: -2.888394608120738
Epoch 195
-------------------------------
Batch 1/64 loss: -2.5392723083496094
Batch 2/64 loss: -2.7393016815185547
Batch 3/64 loss: -2.410024642944336
Batch 4/64 loss: -2.6567554473876953
Batch 5/64 loss: -2.7194271087646484
Batch 6/64 loss: -2.6296567916870117
Batch 7/64 loss: -2.618000030517578
Batch 8/64 loss: -2.8541479110717773
Batch 9/64 loss: -2.827739715576172
Batch 10/64 loss: -2.5501556396484375
Batch 11/64 loss: -2.7485971450805664
Batch 12/64 loss: -2.683547019958496
Batch 13/64 loss: -2.6324329376220703
Batch 14/64 loss: -2.7519874572753906
Batch 15/64 loss: -2.875883102416992
Batch 16/64 loss: -2.5974912643432617
Batch 17/64 loss: -2.9226160049438477
Batch 18/64 loss: -2.4683895111083984
Batch 19/64 loss: -2.78066349029541
Batch 20/64 loss: -2.2177791595458984
Batch 21/64 loss: -2.633758544921875
Batch 22/64 loss: -2.7320432662963867
Batch 23/64 loss: -2.6724681854248047
Batch 24/64 loss: -2.460871696472168
Batch 25/64 loss: -2.7475929260253906
Batch 26/64 loss: -2.2469968795776367
Batch 27/64 loss: -2.6111183166503906
Batch 28/64 loss: -2.5152769088745117
Batch 29/64 loss: -2.7385644912719727
Batch 30/64 loss: -2.6711111068725586
Batch 31/64 loss: -2.86599063873291
Batch 32/64 loss: -2.567246437072754
Batch 33/64 loss: -2.71604061126709
Batch 34/64 loss: -2.5246896743774414
Batch 35/64 loss: -2.694138526916504
Batch 36/64 loss: -2.7120227813720703
Batch 37/64 loss: -2.5673484802246094
Batch 38/64 loss: -2.6745986938476562
Batch 39/64 loss: -2.4749250411987305
Batch 40/64 loss: -2.7374114990234375
Batch 41/64 loss: -2.7651071548461914
Batch 42/64 loss: -2.5823802947998047
Batch 43/64 loss: -2.707935333251953
Batch 44/64 loss: -2.727283477783203
Batch 45/64 loss: -2.7127389907836914
Batch 46/64 loss: -2.646038055419922
Batch 47/64 loss: -2.789729118347168
Batch 48/64 loss: -2.7941532135009766
Batch 49/64 loss: -2.905214309692383
Batch 50/64 loss: -2.6665515899658203
Batch 51/64 loss: -2.619051933288574
Batch 52/64 loss: -2.764592170715332
Batch 53/64 loss: -2.6476640701293945
Batch 54/64 loss: -2.6243133544921875
Batch 55/64 loss: -2.7847299575805664
Batch 56/64 loss: -2.821928024291992
Batch 57/64 loss: -2.5863895416259766
Batch 58/64 loss: -2.880385398864746
Batch 59/64 loss: -2.4309024810791016
Batch 60/64 loss: -2.4831666946411133
Batch 61/64 loss: -2.588411331176758
Batch 62/64 loss: -2.4271411895751953
Batch 63/64 loss: -2.407149314880371
Batch 64/64 loss: -7.171961307525635
Epoch 195  Train loss: -2.706353114632999  Val loss: -2.847136271368597
Epoch 196
-------------------------------
Batch 1/64 loss: -2.732156753540039
Batch 2/64 loss: -2.69802188873291
Batch 3/64 loss: -2.6446142196655273
Batch 4/64 loss: -2.515216827392578
Batch 5/64 loss: -2.5551366806030273
Batch 6/64 loss: -2.7927932739257812
Batch 7/64 loss: -2.6070518493652344
Batch 8/64 loss: -2.632338523864746
Batch 9/64 loss: -2.521200180053711
Batch 10/64 loss: -2.687746047973633
Batch 11/64 loss: -2.7224512100219727
Batch 12/64 loss: -2.6280641555786133
Batch 13/64 loss: -2.7851524353027344
Batch 14/64 loss: -2.432467460632324
Batch 15/64 loss: -2.484635353088379
Batch 16/64 loss: -2.92056941986084
Batch 17/64 loss: -2.7707719802856445
Batch 18/64 loss: -2.77609920501709
Batch 19/64 loss: -2.5697736740112305
Batch 20/64 loss: -2.5709524154663086
Batch 21/64 loss: -2.8011913299560547
Batch 22/64 loss: -2.7306137084960938
Batch 23/64 loss: -2.806133270263672
Batch 24/64 loss: -2.7242202758789062
Batch 25/64 loss: -2.608518600463867
Batch 26/64 loss: -2.6193408966064453
Batch 27/64 loss: -2.5811967849731445
Batch 28/64 loss: -2.6452531814575195
Batch 29/64 loss: -2.723128318786621
Batch 30/64 loss: -1.7501468658447266
Batch 31/64 loss: -2.743785858154297
Batch 32/64 loss: -2.775300979614258
Batch 33/64 loss: -2.745650291442871
Batch 34/64 loss: -2.4660253524780273
Batch 35/64 loss: -2.6730356216430664
Batch 36/64 loss: -2.659454345703125
Batch 37/64 loss: -2.739744186401367
Batch 38/64 loss: -2.6830530166625977
Batch 39/64 loss: -2.625147819519043
Batch 40/64 loss: -2.5427093505859375
Batch 41/64 loss: -2.676309585571289
Batch 42/64 loss: -2.6492319107055664
Batch 43/64 loss: -2.7864952087402344
Batch 44/64 loss: -2.5078630447387695
Batch 45/64 loss: -2.9446754455566406
Batch 46/64 loss: -2.389911651611328
Batch 47/64 loss: -2.6116886138916016
Batch 48/64 loss: -2.8963985443115234
Batch 49/64 loss: -2.7787904739379883
Batch 50/64 loss: -2.776200294494629
Batch 51/64 loss: -2.662220001220703
Batch 52/64 loss: -2.557827949523926
Batch 53/64 loss: -2.7975053787231445
Batch 54/64 loss: -1.9695253372192383
Batch 55/64 loss: -2.5923471450805664
Batch 56/64 loss: -2.7351064682006836
Batch 57/64 loss: -2.704115867614746
Batch 58/64 loss: -2.6563520431518555
Batch 59/64 loss: -2.9170684814453125
Batch 60/64 loss: -2.521902084350586
Batch 61/64 loss: -2.8079328536987305
Batch 62/64 loss: -2.5109691619873047
Batch 63/64 loss: -2.352450370788574
Batch 64/64 loss: -7.288142204284668
Epoch 196  Train loss: -2.6974095400641946  Val loss: -2.845892824258182
Epoch 197
-------------------------------
Batch 1/64 loss: -2.614542007446289
Batch 2/64 loss: -2.540236473083496
Batch 3/64 loss: -2.2888784408569336
Batch 4/64 loss: -2.7119016647338867
Batch 5/64 loss: -2.6477584838867188
Batch 6/64 loss: -2.7931175231933594
Batch 7/64 loss: -2.685257911682129
Batch 8/64 loss: -2.525136947631836
Batch 9/64 loss: -2.6421260833740234
Batch 10/64 loss: -2.8283023834228516
Batch 11/64 loss: -2.752513885498047
Batch 12/64 loss: -2.5237350463867188
Batch 13/64 loss: -2.5307083129882812
Batch 14/64 loss: -2.9205827713012695
Batch 15/64 loss: -2.7302846908569336
Batch 16/64 loss: -2.802654266357422
Batch 17/64 loss: -2.6961660385131836
Batch 18/64 loss: -2.766263961791992
Batch 19/64 loss: -2.7523412704467773
Batch 20/64 loss: -2.717595100402832
Batch 21/64 loss: -2.035959243774414
Batch 22/64 loss: -2.19205379486084
Batch 23/64 loss: -2.545520782470703
Batch 24/64 loss: -2.633133888244629
Batch 25/64 loss: -2.6459760665893555
Batch 26/64 loss: -2.823965072631836
Batch 27/64 loss: -2.843705177307129
Batch 28/64 loss: -2.4431934356689453
Batch 29/64 loss: -2.6516618728637695
Batch 30/64 loss: -2.4679365158081055
Batch 31/64 loss: -2.7537546157836914
Batch 32/64 loss: -2.4706201553344727
Batch 33/64 loss: -2.8326902389526367
Batch 34/64 loss: -2.6240577697753906
Batch 35/64 loss: -2.866168975830078
Batch 36/64 loss: -2.143463134765625
Batch 37/64 loss: -2.764559745788574
Batch 38/64 loss: -2.7856969833374023
Batch 39/64 loss: -2.659071922302246
Batch 40/64 loss: -2.7638378143310547
Batch 41/64 loss: -2.395524024963379
Batch 42/64 loss: -2.389240264892578
Batch 43/64 loss: -2.7235517501831055
Batch 44/64 loss: -2.7446422576904297
Batch 45/64 loss: -2.572146415710449
Batch 46/64 loss: -2.049075126647949
Batch 47/64 loss: -2.4482955932617188
Batch 48/64 loss: -2.675278663635254
Batch 49/64 loss: -2.7525529861450195
Batch 50/64 loss: -2.7821521759033203
Batch 51/64 loss: -2.6221065521240234
Batch 52/64 loss: -2.737483024597168
Batch 53/64 loss: -2.6528921127319336
Batch 54/64 loss: -2.943805694580078
Batch 55/64 loss: -2.4954748153686523
Batch 56/64 loss: -2.687289237976074
Batch 57/64 loss: -2.8511857986450195
Batch 58/64 loss: -2.5438241958618164
Batch 59/64 loss: -2.849240303039551
Batch 60/64 loss: -2.4931983947753906
Batch 61/64 loss: -2.6463918685913086
Batch 62/64 loss: -2.6167850494384766
Batch 63/64 loss: -2.8602828979492188
Batch 64/64 loss: -7.413919448852539
Epoch 197  Train loss: -2.690352772731407  Val loss: -2.846369425455729
Epoch 198
-------------------------------
Batch 1/64 loss: -2.7742481231689453
Batch 2/64 loss: -2.3909263610839844
Batch 3/64 loss: -2.7088623046875
Batch 4/64 loss: -2.7888612747192383
Batch 5/64 loss: -2.83701229095459
Batch 6/64 loss: -2.535177230834961
Batch 7/64 loss: -2.78704833984375
Batch 8/64 loss: -2.2595014572143555
Batch 9/64 loss: -2.511716842651367
Batch 10/64 loss: -2.7629270553588867
Batch 11/64 loss: -2.565326690673828
Batch 12/64 loss: -2.5090503692626953
Batch 13/64 loss: -2.677700996398926
Batch 14/64 loss: -2.8234806060791016
Batch 15/64 loss: -2.631114959716797
Batch 16/64 loss: -2.733184814453125
Batch 17/64 loss: -1.765864372253418
Batch 18/64 loss: -2.362429618835449
Batch 19/64 loss: -2.5805740356445312
Batch 20/64 loss: -2.517862319946289
Batch 21/64 loss: -2.63710880279541
Batch 22/64 loss: -2.930288314819336
Batch 23/64 loss: -2.498077392578125
Batch 24/64 loss: -2.3443374633789062
Batch 25/64 loss: -2.6182432174682617
Batch 26/64 loss: -2.880582809448242
Batch 27/64 loss: -2.4681835174560547
Batch 28/64 loss: -2.6708011627197266
Batch 29/64 loss: -2.7744569778442383
Batch 30/64 loss: -2.799983024597168
Batch 31/64 loss: -2.719048500061035
Batch 32/64 loss: -2.2848825454711914
Batch 33/64 loss: -2.1134424209594727
Batch 34/64 loss: -2.5438661575317383
Batch 35/64 loss: -2.6901512145996094
Batch 36/64 loss: -2.3187599182128906
Batch 37/64 loss: -2.789658546447754
Batch 38/64 loss: -2.8179283142089844
Batch 39/64 loss: -2.666654586791992
Batch 40/64 loss: -2.7566089630126953
Batch 41/64 loss: -2.540471076965332
Batch 42/64 loss: -2.4682703018188477
Batch 43/64 loss: -2.816309928894043
Batch 44/64 loss: -2.819591522216797
Batch 45/64 loss: -2.7274646759033203
Batch 46/64 loss: -2.4246292114257812
Batch 47/64 loss: -2.510138511657715
Batch 48/64 loss: -2.4064035415649414
Batch 49/64 loss: -2.372086524963379
Batch 50/64 loss: -2.69842529296875
Batch 51/64 loss: -2.4665069580078125
Batch 52/64 loss: -2.851888656616211
Batch 53/64 loss: -2.4447011947631836
Batch 54/64 loss: -2.779226303100586
Batch 55/64 loss: -2.7982702255249023
Batch 56/64 loss: -2.776841163635254
Batch 57/64 loss: -2.7442750930786133
Batch 58/64 loss: -2.7821130752563477
Batch 59/64 loss: -2.846541404724121
Batch 60/64 loss: -2.6321048736572266
Batch 61/64 loss: -2.702655792236328
Batch 62/64 loss: -2.5689754486083984
Batch 63/64 loss: -2.960437774658203
Batch 64/64 loss: -7.331742763519287
Epoch 198  Train loss: -2.674244228063845  Val loss: -2.8464624988254403
Epoch 199
-------------------------------
Batch 1/64 loss: -2.3529233932495117
Batch 2/64 loss: -2.604330062866211
Batch 3/64 loss: -2.431621551513672
Batch 4/64 loss: -2.8925790786743164
Batch 5/64 loss: -2.6304092407226562
Batch 6/64 loss: -2.556180953979492
Batch 7/64 loss: -2.7507429122924805
Batch 8/64 loss: -2.613274574279785
Batch 9/64 loss: -2.409961700439453
Batch 10/64 loss: -2.922008514404297
Batch 11/64 loss: -2.676539421081543
Batch 12/64 loss: -2.8497743606567383
Batch 13/64 loss: -2.3288135528564453
Batch 14/64 loss: -2.8853158950805664
Batch 15/64 loss: -2.581836700439453
Batch 16/64 loss: -2.843362808227539
Batch 17/64 loss: -2.5909433364868164
Batch 18/64 loss: -2.8069515228271484
Batch 19/64 loss: -2.5805835723876953
Batch 20/64 loss: -2.722482681274414
Batch 21/64 loss: -2.376802444458008
Batch 22/64 loss: -2.8168020248413086
Batch 23/64 loss: -2.4830141067504883
Batch 24/64 loss: -2.86928653717041
Batch 25/64 loss: -2.1001224517822266
Batch 26/64 loss: -2.4016313552856445
Batch 27/64 loss: -2.811699867248535
Batch 28/64 loss: -2.8329668045043945
Batch 29/64 loss: -2.6604156494140625
Batch 30/64 loss: -2.7636585235595703
Batch 31/64 loss: -2.359572410583496
Batch 32/64 loss: -2.9256067276000977
Batch 33/64 loss: -2.0928564071655273
Batch 34/64 loss: -2.519719123840332
Batch 35/64 loss: -2.726607322692871
Batch 36/64 loss: -2.728689193725586
Batch 37/64 loss: -2.7395782470703125
Batch 38/64 loss: -2.789388656616211
Batch 39/64 loss: -2.6388912200927734
Batch 40/64 loss: -2.0535335540771484
Batch 41/64 loss: -2.877285957336426
Batch 42/64 loss: -2.616617202758789
Batch 43/64 loss: -2.604353904724121
Batch 44/64 loss: -2.499199867248535
Batch 45/64 loss: -2.462031364440918
Batch 46/64 loss: -2.7978553771972656
Batch 47/64 loss: -2.0307302474975586
Batch 48/64 loss: -2.616445541381836
Batch 49/64 loss: -2.7874927520751953
Batch 50/64 loss: -2.4774370193481445
Batch 51/64 loss: -2.715944290161133
Batch 52/64 loss: -2.7638864517211914
Batch 53/64 loss: -2.958683967590332
Batch 54/64 loss: -2.6926937103271484
Batch 55/64 loss: -2.7614803314208984
Batch 56/64 loss: -2.692173957824707
Batch 57/64 loss: -2.5502843856811523
Batch 58/64 loss: -2.888308525085449
Batch 59/64 loss: -2.830979347229004
Batch 60/64 loss: -2.7872495651245117
Batch 61/64 loss: -2.915437698364258
Batch 62/64 loss: -2.735818862915039
Batch 63/64 loss: -2.5424232482910156
Batch 64/64 loss: -7.134385585784912
Epoch 199  Train loss: -2.6929738231733733  Val loss: -2.88284238834971
Epoch 200
-------------------------------
Batch 1/64 loss: -2.817657470703125
Batch 2/64 loss: -2.7105350494384766
Batch 3/64 loss: -2.508772850036621
Batch 4/64 loss: -2.531407356262207
Batch 5/64 loss: -2.606999397277832
Batch 6/64 loss: -2.6000776290893555
Batch 7/64 loss: -2.389803886413574
Batch 8/64 loss: -2.4327392578125
Batch 9/64 loss: -2.6059389114379883
Batch 10/64 loss: -2.4379196166992188
Batch 11/64 loss: -2.767420768737793
Batch 12/64 loss: -2.9705562591552734
Batch 13/64 loss: -2.8195972442626953
Batch 14/64 loss: -2.4244518280029297
Batch 15/64 loss: -2.568225860595703
Batch 16/64 loss: -2.825967788696289
Batch 17/64 loss: -2.883761405944824
Batch 18/64 loss: -2.3446693420410156
Batch 19/64 loss: -2.744664192199707
Batch 20/64 loss: -2.449155807495117
Batch 21/64 loss: -2.74929141998291
Batch 22/64 loss: -2.4030189514160156
Batch 23/64 loss: -2.6732053756713867
Batch 24/64 loss: -2.6097326278686523
Batch 25/64 loss: -2.791579246520996
Batch 26/64 loss: -2.598883628845215
Batch 27/64 loss: -2.5595712661743164
Batch 28/64 loss: -2.3373565673828125
Batch 29/64 loss: -2.5272626876831055
Batch 30/64 loss: -2.654717445373535
Batch 31/64 loss: -2.2896547317504883
Batch 32/64 loss: -2.7537546157836914
Batch 33/64 loss: -2.6833572387695312
Batch 34/64 loss: -2.3754100799560547
Batch 35/64 loss: -2.4640321731567383
Batch 36/64 loss: -2.8570556640625
Batch 37/64 loss: -2.773688316345215
Batch 38/64 loss: -2.4255809783935547
Batch 39/64 loss: -2.826986312866211
Batch 40/64 loss: -2.9811105728149414
Batch 41/64 loss: -2.506704330444336
Batch 42/64 loss: -2.4601497650146484
Batch 43/64 loss: -2.7538557052612305
Batch 44/64 loss: -2.339278221130371
Batch 45/64 loss: -2.5311012268066406
Batch 46/64 loss: -2.821478843688965
Batch 47/64 loss: -2.6191720962524414
Batch 48/64 loss: -2.731386184692383
Batch 49/64 loss: -2.7025070190429688
Batch 50/64 loss: -2.7572641372680664
Batch 51/64 loss: -2.6874475479125977
Batch 52/64 loss: -2.609668731689453
Batch 53/64 loss: -2.7432355880737305
Batch 54/64 loss: -2.632807731628418
Batch 55/64 loss: -2.6184864044189453
Batch 56/64 loss: -2.4295597076416016
Batch 57/64 loss: -2.4476871490478516
Batch 58/64 loss: -2.253612518310547
Batch 59/64 loss: -2.623300552368164
Batch 60/64 loss: -2.4094886779785156
Batch 61/64 loss: -2.584249496459961
Batch 62/64 loss: -2.8754310607910156
Batch 63/64 loss: -2.7648305892944336
Batch 64/64 loss: -7.054610252380371
Epoch 200  Train loss: -2.6661840438842774  Val loss: -2.884911225833434
Epoch 201
-------------------------------
Batch 1/64 loss: -2.5441856384277344
Batch 2/64 loss: -2.3831405639648438
Batch 3/64 loss: -2.6081857681274414
Batch 4/64 loss: -2.808269500732422
Batch 5/64 loss: -2.3715286254882812
Batch 6/64 loss: -2.8396263122558594
Batch 7/64 loss: -2.7054080963134766
Batch 8/64 loss: -2.782832145690918
Batch 9/64 loss: -2.818089485168457
Batch 10/64 loss: -2.4437475204467773
Batch 11/64 loss: -2.446131706237793
Batch 12/64 loss: -2.4971494674682617
Batch 13/64 loss: -2.3660268783569336
Batch 14/64 loss: -2.625821113586426
Batch 15/64 loss: -2.625271797180176
Batch 16/64 loss: -2.4962644577026367
Batch 17/64 loss: -2.5756845474243164
Batch 18/64 loss: -2.4469385147094727
Batch 19/64 loss: -2.7022151947021484
Batch 20/64 loss: -2.8326597213745117
Batch 21/64 loss: -2.6060848236083984
Batch 22/64 loss: -2.345065116882324
Batch 23/64 loss: -2.4736766815185547
Batch 24/64 loss: -2.8681907653808594
Batch 25/64 loss: -2.6379241943359375
Batch 26/64 loss: -2.7864913940429688
Batch 27/64 loss: -2.90419864654541
Batch 28/64 loss: -2.5834646224975586
Batch 29/64 loss: -2.738102912902832
Batch 30/64 loss: -2.350255012512207
Batch 31/64 loss: -2.6926469802856445
Batch 32/64 loss: -2.703658103942871
Batch 33/64 loss: -2.864945411682129
Batch 34/64 loss: -2.556539535522461
Batch 35/64 loss: -2.8125524520874023
Batch 36/64 loss: -2.886305809020996
Batch 37/64 loss: -2.4745941162109375
Batch 38/64 loss: -2.676297187805176
Batch 39/64 loss: -2.827291488647461
Batch 40/64 loss: -2.7368860244750977
Batch 41/64 loss: -2.7065820693969727
Batch 42/64 loss: -2.9059972763061523
Batch 43/64 loss: -2.8297157287597656
Batch 44/64 loss: -2.39117431640625
Batch 45/64 loss: -2.7215423583984375
Batch 46/64 loss: -2.318265914916992
Batch 47/64 loss: -2.4492082595825195
Batch 48/64 loss: -2.5060319900512695
Batch 49/64 loss: -2.8761329650878906
Batch 50/64 loss: -2.1616125106811523
Batch 51/64 loss: -2.570741653442383
Batch 52/64 loss: -2.775731086730957
Batch 53/64 loss: -2.6619319915771484
Batch 54/64 loss: -2.782794952392578
Batch 55/64 loss: -2.922121047973633
Batch 56/64 loss: -2.7804393768310547
Batch 57/64 loss: -2.9130897521972656
Batch 58/64 loss: -2.979935646057129
Batch 59/64 loss: -2.6367998123168945
Batch 60/64 loss: -2.7887868881225586
Batch 61/64 loss: -2.4687585830688477
Batch 62/64 loss: -2.3427162170410156
Batch 63/64 loss: -2.8088769912719727
Batch 64/64 loss: -7.077981472015381
Epoch 201  Train loss: -2.698852107104133  Val loss: -2.846658726328427
Epoch 202
-------------------------------
Batch 1/64 loss: -2.364811897277832
Batch 2/64 loss: -2.7318925857543945
Batch 3/64 loss: -2.7116594314575195
Batch 4/64 loss: -2.6583080291748047
Batch 5/64 loss: -2.470113754272461
Batch 6/64 loss: -2.858414649963379
Batch 7/64 loss: -2.7247142791748047
Batch 8/64 loss: -2.3079729080200195
Batch 9/64 loss: -2.651169776916504
Batch 10/64 loss: -2.728856086730957
Batch 11/64 loss: -2.832162857055664
Batch 12/64 loss: -2.773714065551758
Batch 13/64 loss: -2.8771371841430664
Batch 14/64 loss: -2.6147146224975586
Batch 15/64 loss: -2.467926025390625
Batch 16/64 loss: -2.780078887939453
Batch 17/64 loss: -2.8487319946289062
Batch 18/64 loss: -2.230776786804199
Batch 19/64 loss: -2.5536909103393555
Batch 20/64 loss: -2.7976436614990234
Batch 21/64 loss: -2.6292781829833984
Batch 22/64 loss: -2.4797468185424805
Batch 23/64 loss: -2.901163101196289
Batch 24/64 loss: -2.512540817260742
Batch 25/64 loss: -2.870621681213379
Batch 26/64 loss: -2.5866527557373047
Batch 27/64 loss: -2.7675580978393555
Batch 28/64 loss: -2.425046920776367
Batch 29/64 loss: -2.4298458099365234
Batch 30/64 loss: -2.8337926864624023
Batch 31/64 loss: -2.776643753051758
Batch 32/64 loss: -2.7357301712036133
Batch 33/64 loss: -2.7347192764282227
Batch 34/64 loss: -2.826160430908203
Batch 35/64 loss: -2.5686960220336914
Batch 36/64 loss: -2.7651376724243164
Batch 37/64 loss: -2.8633060455322266
Batch 38/64 loss: -2.7621498107910156
Batch 39/64 loss: -2.7180919647216797
Batch 40/64 loss: -2.5837621688842773
Batch 41/64 loss: -2.934943199157715
Batch 42/64 loss: -2.7048139572143555
Batch 43/64 loss: -2.6647768020629883
Batch 44/64 loss: -2.3390274047851562
Batch 45/64 loss: -2.5278053283691406
Batch 46/64 loss: -2.710886001586914
Batch 47/64 loss: -2.702116012573242
Batch 48/64 loss: -2.662053108215332
Batch 49/64 loss: -2.7134971618652344
Batch 50/64 loss: -2.748507499694824
Batch 51/64 loss: -2.4938831329345703
Batch 52/64 loss: -2.913527488708496
Batch 53/64 loss: -2.650729179382324
Batch 54/64 loss: -2.7391233444213867
Batch 55/64 loss: -2.555556297302246
Batch 56/64 loss: -2.6043930053710938
Batch 57/64 loss: -2.5993423461914062
Batch 58/64 loss: -2.475172996520996
Batch 59/64 loss: -2.7741851806640625
Batch 60/64 loss: -2.3920974731445312
Batch 61/64 loss: -2.787112236022949
Batch 62/64 loss: -2.6218576431274414
Batch 63/64 loss: -2.7132768630981445
Batch 64/64 loss: -7.131310939788818
Epoch 202  Train loss: -2.715800807055305  Val loss: -2.913690888185272
Saving best model, epoch: 202
Epoch 203
-------------------------------
Batch 1/64 loss: -2.1979551315307617
Batch 2/64 loss: -2.717839241027832
Batch 3/64 loss: -2.750518798828125
Batch 4/64 loss: -2.9228553771972656
Batch 5/64 loss: -2.8160133361816406
Batch 6/64 loss: -2.7268543243408203
Batch 7/64 loss: -2.7175188064575195
Batch 8/64 loss: -2.6125802993774414
Batch 9/64 loss: -2.8186445236206055
Batch 10/64 loss: -2.8569488525390625
Batch 11/64 loss: -2.0901670455932617
Batch 12/64 loss: -2.487502098083496
Batch 13/64 loss: -2.9029111862182617
Batch 14/64 loss: -2.62709903717041
Batch 15/64 loss: -2.514781951904297
Batch 16/64 loss: -2.532778739929199
Batch 17/64 loss: -2.5960569381713867
Batch 18/64 loss: -2.446697235107422
Batch 19/64 loss: -2.665781021118164
Batch 20/64 loss: -2.451589584350586
Batch 21/64 loss: -2.532395362854004
Batch 22/64 loss: -2.747203826904297
Batch 23/64 loss: -2.276463508605957
Batch 24/64 loss: -2.636082649230957
Batch 25/64 loss: -2.8251657485961914
Batch 26/64 loss: -2.801203727722168
Batch 27/64 loss: -2.817667007446289
Batch 28/64 loss: -2.675922393798828
Batch 29/64 loss: -2.8122453689575195
Batch 30/64 loss: -2.7635650634765625
Batch 31/64 loss: -2.8267126083374023
Batch 32/64 loss: -2.6535329818725586
Batch 33/64 loss: -2.810922622680664
Batch 34/64 loss: -2.7748613357543945
Batch 35/64 loss: -2.7464828491210938
Batch 36/64 loss: -2.372063636779785
Batch 37/64 loss: -2.6248035430908203
Batch 38/64 loss: -2.7201919555664062
Batch 39/64 loss: -2.2151899337768555
Batch 40/64 loss: -2.2334136962890625
Batch 41/64 loss: -2.77813720703125
Batch 42/64 loss: -2.3849573135375977
Batch 43/64 loss: -2.559329032897949
Batch 44/64 loss: -2.6875534057617188
Batch 45/64 loss: -2.5985965728759766
Batch 46/64 loss: -2.3346986770629883
Batch 47/64 loss: -2.69596004486084
Batch 48/64 loss: -2.797252655029297
Batch 49/64 loss: -2.7288055419921875
Batch 50/64 loss: -2.625704765319824
Batch 51/64 loss: -2.7613887786865234
Batch 52/64 loss: -2.7420778274536133
Batch 53/64 loss: -2.7934112548828125
Batch 54/64 loss: -2.5266904830932617
Batch 55/64 loss: -2.5814342498779297
Batch 56/64 loss: -2.5146636962890625
Batch 57/64 loss: -2.6903457641601562
Batch 58/64 loss: -2.4772844314575195
Batch 59/64 loss: -2.6120195388793945
Batch 60/64 loss: -2.495762825012207
Batch 61/64 loss: -2.7796497344970703
Batch 62/64 loss: -2.692201614379883
Batch 63/64 loss: -2.8744468688964844
Batch 64/64 loss: -7.1726179122924805
Epoch 203  Train loss: -2.689114024592381  Val loss: -2.9135461132141325
Epoch 204
-------------------------------
Batch 1/64 loss: -2.484609603881836
Batch 2/64 loss: -2.7490644454956055
Batch 3/64 loss: -2.9572744369506836
Batch 4/64 loss: -2.1159420013427734
Batch 5/64 loss: -2.8570022583007812
Batch 6/64 loss: -2.6065683364868164
Batch 7/64 loss: -2.49808406829834
Batch 8/64 loss: -2.830451011657715
Batch 9/64 loss: -3.0081892013549805
Batch 10/64 loss: -2.9007272720336914
Batch 11/64 loss: -2.901860237121582
Batch 12/64 loss: -2.919025421142578
Batch 13/64 loss: -2.7134876251220703
Batch 14/64 loss: -2.8222551345825195
Batch 15/64 loss: -2.6957788467407227
Batch 16/64 loss: -2.568669319152832
Batch 17/64 loss: -2.465059280395508
Batch 18/64 loss: -2.864962577819824
Batch 19/64 loss: -2.4569530487060547
Batch 20/64 loss: -2.8122377395629883
Batch 21/64 loss: -2.596050262451172
Batch 22/64 loss: -2.7590456008911133
Batch 23/64 loss: -2.7471256256103516
Batch 24/64 loss: -2.645843505859375
Batch 25/64 loss: -2.639430046081543
Batch 26/64 loss: -2.5294666290283203
Batch 27/64 loss: -2.6476402282714844
Batch 28/64 loss: -2.285151481628418
Batch 29/64 loss: -2.6158456802368164
Batch 30/64 loss: -2.7945566177368164
Batch 31/64 loss: -2.463324546813965
Batch 32/64 loss: -2.442485809326172
Batch 33/64 loss: -2.3573427200317383
Batch 34/64 loss: -2.7439756393432617
Batch 35/64 loss: -2.753443717956543
Batch 36/64 loss: -2.5625782012939453
Batch 37/64 loss: -2.811556816101074
Batch 38/64 loss: -2.5623817443847656
Batch 39/64 loss: -2.4655981063842773
Batch 40/64 loss: -2.7594470977783203
Batch 41/64 loss: -2.692349433898926
Batch 42/64 loss: -2.8080263137817383
Batch 43/64 loss: -2.5377883911132812
Batch 44/64 loss: -2.488907814025879
Batch 45/64 loss: -3.0631799697875977
Batch 46/64 loss: -2.728635787963867
Batch 47/64 loss: -2.478978157043457
Batch 48/64 loss: -2.746962547302246
Batch 49/64 loss: -2.413344383239746
Batch 50/64 loss: -2.522627830505371
Batch 51/64 loss: -2.636098861694336
Batch 52/64 loss: -2.776578903198242
Batch 53/64 loss: -2.8466110229492188
Batch 54/64 loss: -2.6759328842163086
Batch 55/64 loss: -2.4066410064697266
Batch 56/64 loss: -2.7858152389526367
Batch 57/64 loss: -2.6017379760742188
Batch 58/64 loss: -2.6565208435058594
Batch 59/64 loss: -2.6607542037963867
Batch 60/64 loss: -2.767293930053711
Batch 61/64 loss: -2.798794746398926
Batch 62/64 loss: -2.7567596435546875
Batch 63/64 loss: -2.6941280364990234
Batch 64/64 loss: -7.157351016998291
Epoch 204  Train loss: -2.7187917354060156  Val loss: -2.8414660974876167
Epoch 205
-------------------------------
Batch 1/64 loss: -2.7225341796875
Batch 2/64 loss: -2.865964889526367
Batch 3/64 loss: -2.822005271911621
Batch 4/64 loss: -2.7066125869750977
Batch 5/64 loss: -2.8905839920043945
Batch 6/64 loss: -2.7005491256713867
Batch 7/64 loss: -2.5610218048095703
Batch 8/64 loss: -2.6148757934570312
Batch 9/64 loss: -2.2940073013305664
Batch 10/64 loss: -2.3711748123168945
Batch 11/64 loss: -2.3705921173095703
Batch 12/64 loss: -2.7549848556518555
Batch 13/64 loss: -2.6577577590942383
Batch 14/64 loss: -2.6875438690185547
Batch 15/64 loss: -2.4815292358398438
Batch 16/64 loss: -2.65256404876709
Batch 17/64 loss: -2.4629974365234375
Batch 18/64 loss: -2.714862823486328
Batch 19/64 loss: -2.723329544067383
Batch 20/64 loss: -2.8454408645629883
Batch 21/64 loss: -2.5738487243652344
Batch 22/64 loss: -2.5856313705444336
Batch 23/64 loss: -2.4862194061279297
Batch 24/64 loss: -2.422870635986328
Batch 25/64 loss: -2.8264284133911133
Batch 26/64 loss: -2.808544158935547
Batch 27/64 loss: -2.695405960083008
Batch 28/64 loss: -2.7998781204223633
Batch 29/64 loss: -2.4379892349243164
Batch 30/64 loss: -2.703188896179199
Batch 31/64 loss: -2.8146743774414062
Batch 32/64 loss: -2.7791824340820312
Batch 33/64 loss: -2.629972457885742
Batch 34/64 loss: -2.6431713104248047
Batch 35/64 loss: -2.5416860580444336
Batch 36/64 loss: -2.5783424377441406
Batch 37/64 loss: -2.5492639541625977
Batch 38/64 loss: -2.61136531829834
Batch 39/64 loss: -2.587613105773926
Batch 40/64 loss: -2.1733570098876953
Batch 41/64 loss: -2.8562841415405273
Batch 42/64 loss: -2.919017791748047
Batch 43/64 loss: -2.474602699279785
Batch 44/64 loss: -2.677051544189453
Batch 45/64 loss: -2.8269081115722656
Batch 46/64 loss: -2.580381393432617
Batch 47/64 loss: -2.765188217163086
Batch 48/64 loss: -2.747028350830078
Batch 49/64 loss: -2.7535696029663086
Batch 50/64 loss: -2.7720985412597656
Batch 51/64 loss: -2.2918004989624023
Batch 52/64 loss: -2.8260536193847656
Batch 53/64 loss: -2.631561279296875
Batch 54/64 loss: -2.9760875701904297
Batch 55/64 loss: -2.8945932388305664
Batch 56/64 loss: -2.7376632690429688
Batch 57/64 loss: -2.7138853073120117
Batch 58/64 loss: -2.170085906982422
Batch 59/64 loss: -2.690664291381836
Batch 60/64 loss: -2.824406623840332
Batch 61/64 loss: -2.5978450775146484
Batch 62/64 loss: -2.6294679641723633
Batch 63/64 loss: -2.7548341751098633
Batch 64/64 loss: -6.847917556762695
Epoch 205  Train loss: -2.7042601267496744  Val loss: -2.8501359343119095
Epoch 206
-------------------------------
Batch 1/64 loss: -2.854175567626953
Batch 2/64 loss: -2.6801538467407227
Batch 3/64 loss: -2.616924285888672
Batch 4/64 loss: -2.8048057556152344
Batch 5/64 loss: -2.7396535873413086
Batch 6/64 loss: -2.611907958984375
Batch 7/64 loss: -2.6049728393554688
Batch 8/64 loss: -2.7009763717651367
Batch 9/64 loss: -2.681218147277832
Batch 10/64 loss: -2.9088516235351562
Batch 11/64 loss: -2.478055000305176
Batch 12/64 loss: -2.385101318359375
Batch 13/64 loss: -2.210808753967285
Batch 14/64 loss: -2.678569793701172
Batch 15/64 loss: -2.719294548034668
Batch 16/64 loss: -2.5563669204711914
Batch 17/64 loss: -2.710794448852539
Batch 18/64 loss: -2.4575414657592773
Batch 19/64 loss: -2.6325931549072266
Batch 20/64 loss: -2.6602678298950195
Batch 21/64 loss: -2.4299087524414062
Batch 22/64 loss: -2.5478639602661133
Batch 23/64 loss: -2.5801944732666016
Batch 24/64 loss: -2.677762985229492
Batch 25/64 loss: -2.5336647033691406
Batch 26/64 loss: -2.778982162475586
Batch 27/64 loss: -2.417323112487793
Batch 28/64 loss: -2.813767433166504
Batch 29/64 loss: -2.6316604614257812
Batch 30/64 loss: -2.63411808013916
Batch 31/64 loss: -2.6426210403442383
Batch 32/64 loss: -2.733340263366699
Batch 33/64 loss: -2.741457939147949
Batch 34/64 loss: -2.5196847915649414
Batch 35/64 loss: -2.76973819732666
Batch 36/64 loss: -2.600287437438965
Batch 37/64 loss: -2.8190746307373047
Batch 38/64 loss: -2.825380325317383
Batch 39/64 loss: -2.7665252685546875
Batch 40/64 loss: -2.7880868911743164
Batch 41/64 loss: -2.615994453430176
Batch 42/64 loss: -2.550839424133301
Batch 43/64 loss: -2.717365264892578
Batch 44/64 loss: -2.562192916870117
Batch 45/64 loss: -2.424264907836914
Batch 46/64 loss: -2.83660888671875
Batch 47/64 loss: -1.9922046661376953
Batch 48/64 loss: -2.4776010513305664
Batch 49/64 loss: -2.3886775970458984
Batch 50/64 loss: -2.5424938201904297
Batch 51/64 loss: -2.51271915435791
Batch 52/64 loss: -2.4512710571289062
Batch 53/64 loss: -2.669949531555176
Batch 54/64 loss: -2.5351104736328125
Batch 55/64 loss: -2.7554922103881836
Batch 56/64 loss: -2.7392234802246094
Batch 57/64 loss: -2.6146039962768555
Batch 58/64 loss: -2.719729423522949
Batch 59/64 loss: -2.8384180068969727
Batch 60/64 loss: -2.5144834518432617
Batch 61/64 loss: -2.003683090209961
Batch 62/64 loss: -2.506340980529785
Batch 63/64 loss: -2.8633804321289062
Batch 64/64 loss: -7.267813205718994
Epoch 206  Train loss: -2.6702428911246505  Val loss: -2.7405842784344125
Epoch 207
-------------------------------
Batch 1/64 loss: -2.2321271896362305
Batch 2/64 loss: -2.5014495849609375
Batch 3/64 loss: -2.6801490783691406
Batch 4/64 loss: -2.4950132369995117
Batch 5/64 loss: -2.558283805847168
Batch 6/64 loss: -2.574237823486328
Batch 7/64 loss: -2.4464120864868164
Batch 8/64 loss: -2.506755828857422
Batch 9/64 loss: -2.4535131454467773
Batch 10/64 loss: -2.5641098022460938
Batch 11/64 loss: -2.790287971496582
Batch 12/64 loss: -2.7358531951904297
Batch 13/64 loss: -2.6908740997314453
Batch 14/64 loss: -2.7955713272094727
Batch 15/64 loss: -2.6317176818847656
Batch 16/64 loss: -2.7839231491088867
Batch 17/64 loss: -2.5804004669189453
Batch 18/64 loss: -2.76239013671875
Batch 19/64 loss: -2.5770721435546875
Batch 20/64 loss: -2.68734073638916
Batch 21/64 loss: -2.7590150833129883
Batch 22/64 loss: -2.774168014526367
Batch 23/64 loss: -2.5269927978515625
Batch 24/64 loss: -2.4937877655029297
Batch 25/64 loss: -2.0430307388305664
Batch 26/64 loss: -2.812716484069824
Batch 27/64 loss: -2.6746749877929688
Batch 28/64 loss: -2.5866308212280273
Batch 29/64 loss: -2.867940902709961
Batch 30/64 loss: -2.5247535705566406
Batch 31/64 loss: -2.722386360168457
Batch 32/64 loss: -2.5966405868530273
Batch 33/64 loss: -2.714183807373047
Batch 34/64 loss: -2.5978403091430664
Batch 35/64 loss: -2.7714548110961914
Batch 36/64 loss: -2.759042739868164
Batch 37/64 loss: -2.665228843688965
Batch 38/64 loss: -2.4563732147216797
Batch 39/64 loss: -2.7011146545410156
Batch 40/64 loss: -2.7449254989624023
Batch 41/64 loss: -2.5726394653320312
Batch 42/64 loss: -2.668280601501465
Batch 43/64 loss: -2.8436803817749023
Batch 44/64 loss: -2.734903335571289
Batch 45/64 loss: -2.517031669616699
Batch 46/64 loss: -2.5564708709716797
Batch 47/64 loss: -2.519245147705078
Batch 48/64 loss: -2.743699073791504
Batch 49/64 loss: -2.76523494720459
Batch 50/64 loss: -2.5175046920776367
Batch 51/64 loss: -2.646974563598633
Batch 52/64 loss: -2.443108558654785
Batch 53/64 loss: -2.8223352432250977
Batch 54/64 loss: -2.6759490966796875
Batch 55/64 loss: -2.560725212097168
Batch 56/64 loss: -2.3095436096191406
Batch 57/64 loss: -2.411985397338867
Batch 58/64 loss: -2.4603347778320312
Batch 59/64 loss: -2.5107460021972656
Batch 60/64 loss: -2.7882490158081055
Batch 61/64 loss: -2.373368263244629
Batch 62/64 loss: -2.283247947692871
Batch 63/64 loss: -2.828629493713379
Batch 64/64 loss: -6.826471328735352
Epoch 207  Train loss: -2.659045103484509  Val loss: -2.842710540876356
Epoch 208
-------------------------------
Batch 1/64 loss: -2.778860092163086
Batch 2/64 loss: -2.7963457107543945
Batch 3/64 loss: -2.597745895385742
Batch 4/64 loss: -2.646116256713867
Batch 5/64 loss: -2.3324995040893555
Batch 6/64 loss: -2.629908561706543
Batch 7/64 loss: -2.8507814407348633
Batch 8/64 loss: -2.5854063034057617
Batch 9/64 loss: -2.1857213973999023
Batch 10/64 loss: -2.5731449127197266
Batch 11/64 loss: -2.71026611328125
Batch 12/64 loss: -2.7543773651123047
Batch 13/64 loss: -2.486475944519043
Batch 14/64 loss: -2.8526039123535156
Batch 15/64 loss: -2.8181562423706055
Batch 16/64 loss: -1.9440507888793945
Batch 17/64 loss: -2.748000144958496
Batch 18/64 loss: -2.7133407592773438
Batch 19/64 loss: -2.6104183197021484
Batch 20/64 loss: -2.759110450744629
Batch 21/64 loss: -2.71036434173584
Batch 22/64 loss: -2.5229053497314453
Batch 23/64 loss: -2.8581600189208984
Batch 24/64 loss: -2.656543731689453
Batch 25/64 loss: -2.7533273696899414
Batch 26/64 loss: -2.5069875717163086
Batch 27/64 loss: -1.8274288177490234
Batch 28/64 loss: -2.583449363708496
Batch 29/64 loss: -2.6678361892700195
Batch 30/64 loss: -2.1254024505615234
Batch 31/64 loss: -2.5948333740234375
Batch 32/64 loss: -2.605548858642578
Batch 33/64 loss: -2.6503114700317383
Batch 34/64 loss: -1.9683237075805664
Batch 35/64 loss: -2.6228456497192383
Batch 36/64 loss: -2.554764747619629
Batch 37/64 loss: -2.686356544494629
Batch 38/64 loss: -2.315267562866211
Batch 39/64 loss: -2.6768617630004883
Batch 40/64 loss: -2.5481414794921875
Batch 41/64 loss: -2.5081396102905273
Batch 42/64 loss: -2.4621763229370117
Batch 43/64 loss: -2.5408735275268555
Batch 44/64 loss: -2.6359615325927734
Batch 45/64 loss: -2.389338493347168
Batch 46/64 loss: -2.673816680908203
Batch 47/64 loss: -2.7387542724609375
Batch 48/64 loss: -2.7708559036254883
Batch 49/64 loss: -2.567782402038574
Batch 50/64 loss: -2.780484199523926
Batch 51/64 loss: -2.868374824523926
Batch 52/64 loss: -2.359705924987793
Batch 53/64 loss: -2.5035438537597656
Batch 54/64 loss: -2.250703811645508
Batch 55/64 loss: -2.714202880859375
Batch 56/64 loss: -1.7042055130004883
Batch 57/64 loss: -2.6255617141723633
Batch 58/64 loss: -2.7105979919433594
Batch 59/64 loss: -2.8566207885742188
Batch 60/64 loss: -2.6813812255859375
Batch 61/64 loss: -2.8397350311279297
Batch 62/64 loss: -2.6319541931152344
Batch 63/64 loss: -2.375535011291504
Batch 64/64 loss: -7.190930366516113
Epoch 208  Train loss: -2.625764611188103  Val loss: -2.806995208320749
Epoch 209
-------------------------------
Batch 1/64 loss: -2.5778589248657227
Batch 2/64 loss: -2.563577651977539
Batch 3/64 loss: -2.33579158782959
Batch 4/64 loss: -1.887394905090332
Batch 5/64 loss: -2.7198333740234375
Batch 6/64 loss: -2.578038215637207
Batch 7/64 loss: -2.4997711181640625
Batch 8/64 loss: -2.661314010620117
Batch 9/64 loss: -2.667141914367676
Batch 10/64 loss: -2.1729631423950195
Batch 11/64 loss: -2.464594841003418
Batch 12/64 loss: -2.5617589950561523
Batch 13/64 loss: -2.2874250411987305
Batch 14/64 loss: -2.357203483581543
Batch 15/64 loss: -1.5367918014526367
Batch 16/64 loss: -2.7384328842163086
Batch 17/64 loss: -2.5460262298583984
Batch 18/64 loss: -2.636155128479004
Batch 19/64 loss: -2.6304492950439453
Batch 20/64 loss: -2.6417064666748047
Batch 21/64 loss: -2.389187812805176
Batch 22/64 loss: -2.768324851989746
Batch 23/64 loss: -2.6155405044555664
Batch 24/64 loss: -2.828810691833496
Batch 25/64 loss: -2.027219772338867
Batch 26/64 loss: -2.8299055099487305
Batch 27/64 loss: -2.541196823120117
Batch 28/64 loss: -2.547591209411621
Batch 29/64 loss: -2.665675163269043
Batch 30/64 loss: -2.343465805053711
Batch 31/64 loss: -2.36368465423584
Batch 32/64 loss: -2.6823463439941406
Batch 33/64 loss: -2.799673080444336
Batch 34/64 loss: -2.958555221557617
Batch 35/64 loss: -2.182628631591797
Batch 36/64 loss: -2.447347640991211
Batch 37/64 loss: -2.700815200805664
Batch 38/64 loss: -2.666213035583496
Batch 39/64 loss: -2.6355695724487305
Batch 40/64 loss: -2.428717613220215
Batch 41/64 loss: -2.5851221084594727
Batch 42/64 loss: -2.905893325805664
Batch 43/64 loss: -2.9065027236938477
Batch 44/64 loss: -2.786224365234375
Batch 45/64 loss: -2.672122001647949
Batch 46/64 loss: -2.44482421875
Batch 47/64 loss: -2.50164794921875
Batch 48/64 loss: -2.6370019912719727
Batch 49/64 loss: -2.7403173446655273
Batch 50/64 loss: -2.49233341217041
Batch 51/64 loss: -2.081326484680176
Batch 52/64 loss: -2.894418716430664
Batch 53/64 loss: -2.2465314865112305
Batch 54/64 loss: -2.8139820098876953
Batch 55/64 loss: -2.832967758178711
Batch 56/64 loss: -2.701479911804199
Batch 57/64 loss: -2.600447654724121
Batch 58/64 loss: -2.6507606506347656
Batch 59/64 loss: -2.7130775451660156
Batch 60/64 loss: -2.8386144638061523
Batch 61/64 loss: -2.181004524230957
Batch 62/64 loss: -2.8226804733276367
Batch 63/64 loss: -2.459442138671875
Batch 64/64 loss: -7.319241046905518
Epoch 209  Train loss: -2.611527093251546  Val loss: -2.4439347388408437
Epoch 210
-------------------------------
Batch 1/64 loss: -2.469265937805176
Batch 2/64 loss: -2.576791763305664
Batch 3/64 loss: -2.704270362854004
Batch 4/64 loss: -2.622528076171875
Batch 5/64 loss: -2.689708709716797
Batch 6/64 loss: -2.539381980895996
Batch 7/64 loss: -2.1663618087768555
Batch 8/64 loss: -2.750905990600586
Batch 9/64 loss: -2.5752601623535156
Batch 10/64 loss: -2.3709774017333984
Batch 11/64 loss: -2.5343103408813477
Batch 12/64 loss: -2.6835927963256836
Batch 13/64 loss: -2.3104591369628906
Batch 14/64 loss: -2.76131534576416
Batch 15/64 loss: -2.6145362854003906
Batch 16/64 loss: -2.3776445388793945
Batch 17/64 loss: -2.534536361694336
Batch 18/64 loss: -2.796123504638672
Batch 19/64 loss: -2.246166229248047
Batch 20/64 loss: -2.495218276977539
Batch 21/64 loss: -2.756357192993164
Batch 22/64 loss: -2.8995132446289062
Batch 23/64 loss: -2.786989212036133
Batch 24/64 loss: -2.481412887573242
Batch 25/64 loss: -2.3902368545532227
Batch 26/64 loss: -2.58347225189209
Batch 27/64 loss: -2.693391799926758
Batch 28/64 loss: -2.446976661682129
Batch 29/64 loss: -2.1069211959838867
Batch 30/64 loss: -2.696974754333496
Batch 31/64 loss: -2.5842533111572266
Batch 32/64 loss: -2.7780704498291016
Batch 33/64 loss: -2.664478302001953
Batch 34/64 loss: -2.7017107009887695
Batch 35/64 loss: -2.1722984313964844
Batch 36/64 loss: -2.322511672973633
Batch 37/64 loss: -2.6903953552246094
Batch 38/64 loss: -2.4487686157226562
Batch 39/64 loss: -2.0718746185302734
Batch 40/64 loss: -2.120852470397949
Batch 41/64 loss: -2.8676319122314453
Batch 42/64 loss: -2.777501106262207
Batch 43/64 loss: -2.7010393142700195
Batch 44/64 loss: -2.173417091369629
Batch 45/64 loss: -2.7938289642333984
Batch 46/64 loss: -2.2741174697875977
Batch 47/64 loss: -2.3074827194213867
Batch 48/64 loss: -2.084773063659668
Batch 49/64 loss: -2.8337297439575195
Batch 50/64 loss: -2.349782943725586
Batch 51/64 loss: -2.5879640579223633
Batch 52/64 loss: -2.1047277450561523
Batch 53/64 loss: -2.8017187118530273
Batch 54/64 loss: -2.6093358993530273
Batch 55/64 loss: -2.6500186920166016
Batch 56/64 loss: -2.741724967956543
Batch 57/64 loss: -2.6464223861694336
Batch 58/64 loss: -2.9519596099853516
Batch 59/64 loss: -2.714850425720215
Batch 60/64 loss: -2.4694395065307617
Batch 61/64 loss: -2.5606203079223633
Batch 62/64 loss: -2.7675580978393555
Batch 63/64 loss: -2.7781734466552734
Batch 64/64 loss: -7.235353946685791
Epoch 210  Train loss: -2.6069199786466712  Val loss: -2.7925339793831214
Epoch 211
-------------------------------
Batch 1/64 loss: -2.712430953979492
Batch 2/64 loss: -2.665109634399414
Batch 3/64 loss: -2.5391006469726562
Batch 4/64 loss: -2.6622915267944336
Batch 5/64 loss: -2.704221725463867
Batch 6/64 loss: -2.757920265197754
Batch 7/64 loss: -2.6451759338378906
Batch 8/64 loss: -2.5994033813476562
Batch 9/64 loss: -2.593716621398926
Batch 10/64 loss: -2.748790740966797
Batch 11/64 loss: -2.6136045455932617
Batch 12/64 loss: -2.4034223556518555
Batch 13/64 loss: -2.6206912994384766
Batch 14/64 loss: -2.513845443725586
Batch 15/64 loss: -2.604681968688965
Batch 16/64 loss: -2.7749757766723633
Batch 17/64 loss: -2.9028444290161133
Batch 18/64 loss: -2.7821502685546875
Batch 19/64 loss: -2.6872873306274414
Batch 20/64 loss: -2.630917549133301
Batch 21/64 loss: -2.4740867614746094
Batch 22/64 loss: -2.68851375579834
Batch 23/64 loss: -2.575510025024414
Batch 24/64 loss: -2.768596649169922
Batch 25/64 loss: -2.558725357055664
Batch 26/64 loss: -2.688436508178711
Batch 27/64 loss: -2.441314697265625
Batch 28/64 loss: -2.5499820709228516
Batch 29/64 loss: -2.4844722747802734
Batch 30/64 loss: -2.7497406005859375
Batch 31/64 loss: -2.591856002807617
Batch 32/64 loss: -2.8410911560058594
Batch 33/64 loss: -2.748715400695801
Batch 34/64 loss: -2.652888298034668
Batch 35/64 loss: -2.638782501220703
Batch 36/64 loss: -2.3610754013061523
Batch 37/64 loss: -2.7731008529663086
Batch 38/64 loss: -2.692948341369629
Batch 39/64 loss: -2.2561893463134766
Batch 40/64 loss: -2.749469757080078
Batch 41/64 loss: -2.4984025955200195
Batch 42/64 loss: -2.82419490814209
Batch 43/64 loss: -2.562620162963867
Batch 44/64 loss: -2.5761680603027344
Batch 45/64 loss: -2.844461441040039
Batch 46/64 loss: -2.491128921508789
Batch 47/64 loss: -2.6811342239379883
Batch 48/64 loss: -2.788130760192871
Batch 49/64 loss: -2.9151268005371094
Batch 50/64 loss: -2.398423194885254
Batch 51/64 loss: -2.511672019958496
Batch 52/64 loss: -2.574711799621582
Batch 53/64 loss: -2.7228927612304688
Batch 54/64 loss: -2.611867904663086
Batch 55/64 loss: -2.795260429382324
Batch 56/64 loss: -2.5754871368408203
Batch 57/64 loss: -2.592479705810547
Batch 58/64 loss: -2.8147058486938477
Batch 59/64 loss: -2.6944408416748047
Batch 60/64 loss: -2.4512758255004883
Batch 61/64 loss: -2.501638412475586
Batch 62/64 loss: -2.0398483276367188
Batch 63/64 loss: -2.478938102722168
Batch 64/64 loss: -7.258033752441406
Epoch 211  Train loss: -2.679790018119064  Val loss: -2.8894616484232376
Epoch 212
-------------------------------
Batch 1/64 loss: -2.6398143768310547
Batch 2/64 loss: -2.5414438247680664
Batch 3/64 loss: -2.7131919860839844
Batch 4/64 loss: -2.6904191970825195
Batch 5/64 loss: -2.597503662109375
Batch 6/64 loss: -2.381625175476074
Batch 7/64 loss: -2.8677196502685547
Batch 8/64 loss: -2.538052558898926
Batch 9/64 loss: -2.6357421875
Batch 10/64 loss: -2.7296981811523438
Batch 11/64 loss: -2.7176923751831055
Batch 12/64 loss: -2.9000539779663086
Batch 13/64 loss: -2.926791191101074
Batch 14/64 loss: -2.6067676544189453
Batch 15/64 loss: -2.42447566986084
Batch 16/64 loss: -2.787022590637207
Batch 17/64 loss: -2.7616710662841797
Batch 18/64 loss: -2.6471338272094727
Batch 19/64 loss: -2.479215621948242
Batch 20/64 loss: -2.7856998443603516
Batch 21/64 loss: -2.3198041915893555
Batch 22/64 loss: -2.283907890319824
Batch 23/64 loss: -2.711136817932129
Batch 24/64 loss: -2.541292190551758
Batch 25/64 loss: -1.945791244506836
Batch 26/64 loss: -2.769594192504883
Batch 27/64 loss: -2.366448402404785
Batch 28/64 loss: -3.009349822998047
Batch 29/64 loss: -2.6739864349365234
Batch 30/64 loss: -2.6738786697387695
Batch 31/64 loss: -2.606907844543457
Batch 32/64 loss: -2.862804412841797
Batch 33/64 loss: -2.3369922637939453
Batch 34/64 loss: -2.5452003479003906
Batch 35/64 loss: -2.5824432373046875
Batch 36/64 loss: -2.57977294921875
Batch 37/64 loss: -2.3634166717529297
Batch 38/64 loss: -2.6305418014526367
Batch 39/64 loss: -2.5212106704711914
Batch 40/64 loss: -2.136734962463379
Batch 41/64 loss: -2.8072500228881836
Batch 42/64 loss: -2.872391700744629
Batch 43/64 loss: -2.8000783920288086
Batch 44/64 loss: -2.1824159622192383
Batch 45/64 loss: -2.6984949111938477
Batch 46/64 loss: -2.480422019958496
Batch 47/64 loss: -2.725863456726074
Batch 48/64 loss: -2.833860397338867
Batch 49/64 loss: -2.583867073059082
Batch 50/64 loss: -2.531190872192383
Batch 51/64 loss: -2.566112518310547
Batch 52/64 loss: -2.69388484954834
Batch 53/64 loss: -2.4806766510009766
Batch 54/64 loss: -2.449687957763672
Batch 55/64 loss: -2.571578025817871
Batch 56/64 loss: -2.7537593841552734
Batch 57/64 loss: -2.613600730895996
Batch 58/64 loss: -2.557943344116211
Batch 59/64 loss: -2.373811721801758
Batch 60/64 loss: -2.7407331466674805
Batch 61/64 loss: -2.658721923828125
Batch 62/64 loss: -2.222219467163086
Batch 63/64 loss: -2.4468870162963867
Batch 64/64 loss: -7.171416282653809
Epoch 212  Train loss: -2.648736680722704  Val loss: -2.766212279853952
Epoch 213
-------------------------------
Batch 1/64 loss: -2.8875389099121094
Batch 2/64 loss: -2.6587867736816406
Batch 3/64 loss: -2.4056243896484375
Batch 4/64 loss: -2.75565242767334
Batch 5/64 loss: -2.663969039916992
Batch 6/64 loss: -2.636284828186035
Batch 7/64 loss: -2.629836082458496
Batch 8/64 loss: -2.678354263305664
Batch 9/64 loss: -2.605863571166992
Batch 10/64 loss: -2.597789764404297
Batch 11/64 loss: -2.752285957336426
Batch 12/64 loss: -2.5891151428222656
Batch 13/64 loss: -2.835507392883301
Batch 14/64 loss: -2.6265134811401367
Batch 15/64 loss: -2.3139171600341797
Batch 16/64 loss: -2.465359687805176
Batch 17/64 loss: -2.691793441772461
Batch 18/64 loss: -2.8177804946899414
Batch 19/64 loss: -2.431537628173828
Batch 20/64 loss: -2.4579553604125977
Batch 21/64 loss: -2.2915639877319336
Batch 22/64 loss: -2.445343017578125
Batch 23/64 loss: -2.7120237350463867
Batch 24/64 loss: -2.5706968307495117
Batch 25/64 loss: -2.343306541442871
Batch 26/64 loss: -2.7895421981811523
Batch 27/64 loss: -2.471920967102051
Batch 28/64 loss: -2.519216537475586
Batch 29/64 loss: -2.6178035736083984
Batch 30/64 loss: -2.3687267303466797
Batch 31/64 loss: -2.1813135147094727
Batch 32/64 loss: -2.6307477951049805
Batch 33/64 loss: -2.6865358352661133
Batch 34/64 loss: -2.573615074157715
Batch 35/64 loss: -2.576303482055664
Batch 36/64 loss: -2.72843074798584
Batch 37/64 loss: -2.6213932037353516
Batch 38/64 loss: -2.645322799682617
Batch 39/64 loss: -2.8452892303466797
Batch 40/64 loss: -2.5493850708007812
Batch 41/64 loss: -2.817075729370117
Batch 42/64 loss: -2.4990339279174805
Batch 43/64 loss: -2.527329444885254
Batch 44/64 loss: -2.6779050827026367
Batch 45/64 loss: -2.6843223571777344
Batch 46/64 loss: -2.122677803039551
Batch 47/64 loss: -2.7632007598876953
Batch 48/64 loss: -2.895292282104492
Batch 49/64 loss: -2.911396026611328
Batch 50/64 loss: -2.4048919677734375
Batch 51/64 loss: -2.2926816940307617
Batch 52/64 loss: -2.476393699645996
Batch 53/64 loss: -2.8729705810546875
Batch 54/64 loss: -2.7193307876586914
Batch 55/64 loss: -2.65017032623291
Batch 56/64 loss: -2.6107101440429688
Batch 57/64 loss: -2.6283349990844727
Batch 58/64 loss: -2.6011829376220703
Batch 59/64 loss: -2.7266035079956055
Batch 60/64 loss: -2.561814308166504
Batch 61/64 loss: -2.554380416870117
Batch 62/64 loss: -2.07778263092041
Batch 63/64 loss: -2.5987558364868164
Batch 64/64 loss: -6.8594794273376465
Epoch 213  Train loss: -2.642961466546152  Val loss: -2.719831696080998
Epoch 214
-------------------------------
Batch 1/64 loss: -2.5133886337280273
Batch 2/64 loss: -2.414632797241211
Batch 3/64 loss: -2.8560495376586914
Batch 4/64 loss: -2.7163400650024414
Batch 5/64 loss: -2.6550426483154297
Batch 6/64 loss: -2.5805110931396484
Batch 7/64 loss: -2.578810691833496
Batch 8/64 loss: -2.455796241760254
Batch 9/64 loss: -2.6869239807128906
Batch 10/64 loss: -2.6666336059570312
Batch 11/64 loss: -2.6023693084716797
Batch 12/64 loss: -2.49088191986084
Batch 13/64 loss: -2.517022132873535
Batch 14/64 loss: -2.5801496505737305
Batch 15/64 loss: -2.740253448486328
Batch 16/64 loss: -2.503591537475586
Batch 17/64 loss: -2.534623146057129
Batch 18/64 loss: -2.6439199447631836
Batch 19/64 loss: -2.574441909790039
Batch 20/64 loss: -2.5544166564941406
Batch 21/64 loss: -2.5735416412353516
Batch 22/64 loss: -2.557628631591797
Batch 23/64 loss: -2.6381759643554688
Batch 24/64 loss: -2.623889923095703
Batch 25/64 loss: -2.75897216796875
Batch 26/64 loss: -2.6902198791503906
Batch 27/64 loss: -2.428783416748047
Batch 28/64 loss: -2.3224000930786133
Batch 29/64 loss: -2.670823097229004
Batch 30/64 loss: -2.643498420715332
Batch 31/64 loss: -2.6829757690429688
Batch 32/64 loss: -2.6434803009033203
Batch 33/64 loss: -2.746328353881836
Batch 34/64 loss: -2.6872129440307617
Batch 35/64 loss: -2.6253623962402344
Batch 36/64 loss: -2.599172592163086
Batch 37/64 loss: -2.549215316772461
Batch 38/64 loss: -2.531846046447754
Batch 39/64 loss: -2.422931671142578
Batch 40/64 loss: -2.652346611022949
Batch 41/64 loss: -2.42514705657959
Batch 42/64 loss: -2.416825294494629
Batch 43/64 loss: -2.335742950439453
Batch 44/64 loss: -2.783313751220703
Batch 45/64 loss: -2.7520666122436523
Batch 46/64 loss: -2.792421340942383
Batch 47/64 loss: -2.401796340942383
Batch 48/64 loss: -2.5122108459472656
Batch 49/64 loss: -2.4485063552856445
Batch 50/64 loss: -2.783566474914551
Batch 51/64 loss: -2.80997371673584
Batch 52/64 loss: -2.218804359436035
Batch 53/64 loss: -2.6742191314697266
Batch 54/64 loss: -2.645388603210449
Batch 55/64 loss: -2.5158262252807617
Batch 56/64 loss: -2.5738182067871094
Batch 57/64 loss: -1.9348783493041992
Batch 58/64 loss: -2.6689414978027344
Batch 59/64 loss: -2.5691375732421875
Batch 60/64 loss: -2.6941442489624023
Batch 61/64 loss: -2.544893264770508
Batch 62/64 loss: -2.2361793518066406
Batch 63/64 loss: -2.588104248046875
Batch 64/64 loss: -7.248233795166016
Epoch 214  Train loss: -2.630222515031403  Val loss: -2.6637568916242147
Epoch 215
-------------------------------
Batch 1/64 loss: -2.480846405029297
Batch 2/64 loss: -2.397296905517578
Batch 3/64 loss: -2.617611885070801
Batch 4/64 loss: -2.599485397338867
Batch 5/64 loss: -2.654712677001953
Batch 6/64 loss: -2.033985137939453
Batch 7/64 loss: -2.1868133544921875
Batch 8/64 loss: -2.412273406982422
Batch 9/64 loss: -2.881678581237793
Batch 10/64 loss: -2.4247331619262695
Batch 11/64 loss: -2.645681381225586
Batch 12/64 loss: -2.789236068725586
Batch 13/64 loss: -2.2334346771240234
Batch 14/64 loss: -2.81186580657959
Batch 15/64 loss: -2.4238758087158203
Batch 16/64 loss: -2.864530563354492
Batch 17/64 loss: -2.662489891052246
Batch 18/64 loss: -2.7053956985473633
Batch 19/64 loss: -2.55251407623291
Batch 20/64 loss: -2.6269102096557617
Batch 21/64 loss: -2.55417537689209
Batch 22/64 loss: -2.843618392944336
Batch 23/64 loss: -2.633209228515625
Batch 24/64 loss: -2.834111213684082
Batch 25/64 loss: -2.6883115768432617
Batch 26/64 loss: -2.8437118530273438
Batch 27/64 loss: -2.5793371200561523
Batch 28/64 loss: -2.7055959701538086
Batch 29/64 loss: -2.715639114379883
Batch 30/64 loss: -2.834085464477539
Batch 31/64 loss: -2.677231788635254
Batch 32/64 loss: -2.387981414794922
Batch 33/64 loss: -2.3299741744995117
Batch 34/64 loss: -2.3847169876098633
Batch 35/64 loss: -2.142247200012207
Batch 36/64 loss: -2.8062829971313477
Batch 37/64 loss: -2.244357109069824
Batch 38/64 loss: -2.074098587036133
Batch 39/64 loss: -2.456179618835449
Batch 40/64 loss: -2.6242733001708984
Batch 41/64 loss: -2.6362104415893555
Batch 42/64 loss: -2.5931167602539062
Batch 43/64 loss: -2.6703643798828125
Batch 44/64 loss: -2.7432613372802734
Batch 45/64 loss: -2.8412790298461914
Batch 46/64 loss: -2.7636775970458984
Batch 47/64 loss: -2.7724647521972656
Batch 48/64 loss: -2.778066635131836
Batch 49/64 loss: -2.694843292236328
Batch 50/64 loss: -2.8190927505493164
Batch 51/64 loss: -2.8062572479248047
Batch 52/64 loss: -2.632394790649414
Batch 53/64 loss: -2.786396026611328
Batch 54/64 loss: -2.713369369506836
Batch 55/64 loss: -2.655487060546875
Batch 56/64 loss: -2.5978736877441406
Batch 57/64 loss: -2.463075637817383
Batch 58/64 loss: -2.205874443054199
Batch 59/64 loss: -2.312702178955078
Batch 60/64 loss: -2.847728729248047
Batch 61/64 loss: -2.3020238876342773
Batch 62/64 loss: -2.7311277389526367
Batch 63/64 loss: -3.0108203887939453
Batch 64/64 loss: -7.158050060272217
Epoch 215  Train loss: -2.6527145928027585  Val loss: -2.779081390485731
Epoch 216
-------------------------------
Batch 1/64 loss: -2.691028594970703
Batch 2/64 loss: -2.732053756713867
Batch 3/64 loss: -2.498594284057617
Batch 4/64 loss: -2.618241310119629
Batch 5/64 loss: -2.680063247680664
Batch 6/64 loss: -2.54740047454834
Batch 7/64 loss: -2.53240966796875
Batch 8/64 loss: -2.687925338745117
Batch 9/64 loss: -2.704824447631836
Batch 10/64 loss: -2.342074394226074
Batch 11/64 loss: -2.587472915649414
Batch 12/64 loss: -2.0571184158325195
Batch 13/64 loss: -2.674997329711914
Batch 14/64 loss: -2.4879188537597656
Batch 15/64 loss: -2.4591827392578125
Batch 16/64 loss: -2.5541372299194336
Batch 17/64 loss: -2.715315818786621
Batch 18/64 loss: -2.19482421875
Batch 19/64 loss: -2.6638317108154297
Batch 20/64 loss: -2.8959779739379883
Batch 21/64 loss: -2.7110795974731445
Batch 22/64 loss: -2.6661767959594727
Batch 23/64 loss: -2.4931201934814453
Batch 24/64 loss: -2.762907028198242
Batch 25/64 loss: -2.5807876586914062
Batch 26/64 loss: -2.577500343322754
Batch 27/64 loss: -2.4806127548217773
Batch 28/64 loss: -2.0706567764282227
Batch 29/64 loss: -2.644754409790039
Batch 30/64 loss: -2.695113182067871
Batch 31/64 loss: -2.697299003601074
Batch 32/64 loss: -2.790891647338867
Batch 33/64 loss: -2.6891889572143555
Batch 34/64 loss: -2.6999330520629883
Batch 35/64 loss: -2.7075891494750977
Batch 36/64 loss: -2.539679527282715
Batch 37/64 loss: -2.799142837524414
Batch 38/64 loss: -2.577334403991699
Batch 39/64 loss: -2.171966552734375
Batch 40/64 loss: -2.683213233947754
Batch 41/64 loss: -2.6712770462036133
Batch 42/64 loss: -2.590921401977539
Batch 43/64 loss: -2.663180351257324
Batch 44/64 loss: -2.5878963470458984
Batch 45/64 loss: -2.587559700012207
Batch 46/64 loss: -2.4382410049438477
Batch 47/64 loss: -2.516554832458496
Batch 48/64 loss: -2.7508163452148438
Batch 49/64 loss: -2.5408382415771484
Batch 50/64 loss: -2.8302669525146484
Batch 51/64 loss: -2.6003189086914062
Batch 52/64 loss: -2.8678760528564453
Batch 53/64 loss: -2.602799415588379
Batch 54/64 loss: -2.5568408966064453
Batch 55/64 loss: -2.844285011291504
Batch 56/64 loss: -2.934943199157715
Batch 57/64 loss: -2.7037906646728516
Batch 58/64 loss: -2.6265506744384766
Batch 59/64 loss: -1.9030799865722656
Batch 60/64 loss: -2.6588268280029297
Batch 61/64 loss: -2.699007034301758
Batch 62/64 loss: -2.702263832092285
Batch 63/64 loss: -2.7013511657714844
Batch 64/64 loss: -6.465201377868652
Epoch 216  Train loss: -2.6477290471394856  Val loss: -2.794597927237704
Epoch 217
-------------------------------
Batch 1/64 loss: -2.549004554748535
Batch 2/64 loss: -2.3347110748291016
Batch 3/64 loss: -2.4061851501464844
Batch 4/64 loss: -2.346468925476074
Batch 5/64 loss: -2.5345077514648438
Batch 6/64 loss: -2.7280149459838867
Batch 7/64 loss: -2.5691986083984375
Batch 8/64 loss: -2.5626726150512695
Batch 9/64 loss: -2.704751968383789
Batch 10/64 loss: -2.7159500122070312
Batch 11/64 loss: -2.7808752059936523
Batch 12/64 loss: -2.5841989517211914
Batch 13/64 loss: -2.635641098022461
Batch 14/64 loss: -2.3684072494506836
Batch 15/64 loss: -2.7719736099243164
Batch 16/64 loss: -2.6466236114501953
Batch 17/64 loss: -2.6212472915649414
Batch 18/64 loss: -2.422475814819336
Batch 19/64 loss: -2.6950273513793945
Batch 20/64 loss: -2.7334461212158203
Batch 21/64 loss: -2.699312210083008
Batch 22/64 loss: -2.719766616821289
Batch 23/64 loss: -2.42838191986084
Batch 24/64 loss: -2.4680185317993164
Batch 25/64 loss: -2.648500442504883
Batch 26/64 loss: -2.5952205657958984
Batch 27/64 loss: -2.845003128051758
Batch 28/64 loss: -2.409891128540039
Batch 29/64 loss: -2.8891592025756836
Batch 30/64 loss: -2.004079818725586
Batch 31/64 loss: -2.37423038482666
Batch 32/64 loss: -2.530763626098633
Batch 33/64 loss: -2.771023750305176
Batch 34/64 loss: -2.7927684783935547
Batch 35/64 loss: -2.7266807556152344
Batch 36/64 loss: -2.4716453552246094
Batch 37/64 loss: -2.52718448638916
Batch 38/64 loss: -2.6220483779907227
Batch 39/64 loss: -2.4340734481811523
Batch 40/64 loss: -2.0148534774780273
Batch 41/64 loss: -2.640538215637207
Batch 42/64 loss: -2.062551498413086
Batch 43/64 loss: -2.107150077819824
Batch 44/64 loss: -2.463796615600586
Batch 45/64 loss: -2.6460494995117188
Batch 46/64 loss: -2.50949764251709
Batch 47/64 loss: -2.628689765930176
Batch 48/64 loss: -2.5535192489624023
Batch 49/64 loss: -2.560588836669922
Batch 50/64 loss: -2.268488883972168
Batch 51/64 loss: -2.533109664916992
Batch 52/64 loss: -2.7283201217651367
Batch 53/64 loss: -2.4675559997558594
Batch 54/64 loss: -2.5280561447143555
Batch 55/64 loss: -2.6546268463134766
Batch 56/64 loss: -2.3650379180908203
Batch 57/64 loss: -2.526569366455078
Batch 58/64 loss: -2.5836868286132812
Batch 59/64 loss: -2.318950653076172
Batch 60/64 loss: -2.4090328216552734
Batch 61/64 loss: -2.7452640533447266
Batch 62/64 loss: -2.739849090576172
Batch 63/64 loss: -2.5082950592041016
Batch 64/64 loss: -7.137655258178711
Epoch 217  Train loss: -2.597434571210076  Val loss: -2.7537505421851507
Epoch 218
-------------------------------
Batch 1/64 loss: -2.418649673461914
Batch 2/64 loss: -2.5115556716918945
Batch 3/64 loss: -2.716433525085449
Batch 4/64 loss: -2.831820487976074
Batch 5/64 loss: -2.528156280517578
Batch 6/64 loss: -2.705451011657715
Batch 7/64 loss: -2.672907829284668
Batch 8/64 loss: -2.5700435638427734
Batch 9/64 loss: -2.465230941772461
Batch 10/64 loss: -2.8602161407470703
Batch 11/64 loss: -2.649876594543457
Batch 12/64 loss: -2.555405616760254
Batch 13/64 loss: -2.794048309326172
Batch 14/64 loss: -2.4951772689819336
Batch 15/64 loss: -2.546727180480957
Batch 16/64 loss: -2.399298667907715
Batch 17/64 loss: -2.6604089736938477
Batch 18/64 loss: -2.4593124389648438
Batch 19/64 loss: -2.771066665649414
Batch 20/64 loss: -2.718700408935547
Batch 21/64 loss: -2.797273635864258
Batch 22/64 loss: -2.6509008407592773
Batch 23/64 loss: -2.463785171508789
Batch 24/64 loss: -2.534128189086914
Batch 25/64 loss: -2.6492843627929688
Batch 26/64 loss: -2.436884880065918
Batch 27/64 loss: -2.381549835205078
Batch 28/64 loss: -2.851543426513672
Batch 29/64 loss: -2.7526512145996094
Batch 30/64 loss: -2.814615249633789
Batch 31/64 loss: -2.2681446075439453
Batch 32/64 loss: -2.595226287841797
Batch 33/64 loss: -2.4223833084106445
Batch 34/64 loss: -2.5378828048706055
Batch 35/64 loss: -2.788522720336914
Batch 36/64 loss: -2.5293054580688477
Batch 37/64 loss: -2.867696762084961
Batch 38/64 loss: -2.8350048065185547
Batch 39/64 loss: -2.666140556335449
Batch 40/64 loss: -2.1485891342163086
Batch 41/64 loss: -2.660719871520996
Batch 42/64 loss: -2.672183036804199
Batch 43/64 loss: -2.8346195220947266
Batch 44/64 loss: -2.7531919479370117
Batch 45/64 loss: -2.276820182800293
Batch 46/64 loss: -2.634819984436035
Batch 47/64 loss: -2.613992691040039
Batch 48/64 loss: -2.4117345809936523
Batch 49/64 loss: -2.4273223876953125
Batch 50/64 loss: -2.7960214614868164
Batch 51/64 loss: -2.7395706176757812
Batch 52/64 loss: -1.7753477096557617
Batch 53/64 loss: -2.783733367919922
Batch 54/64 loss: -2.644942283630371
Batch 55/64 loss: -2.536458969116211
Batch 56/64 loss: -2.668179512023926
Batch 57/64 loss: -2.6389570236206055
Batch 58/64 loss: -2.744579315185547
Batch 59/64 loss: -2.7754201889038086
Batch 60/64 loss: -2.664764404296875
Batch 61/64 loss: -2.72428035736084
Batch 62/64 loss: -2.5363731384277344
Batch 63/64 loss: -2.739046096801758
Batch 64/64 loss: -7.015253067016602
Epoch 218  Train loss: -2.6609650032193053  Val loss: -2.8663134099691594
Epoch 219
-------------------------------
Batch 1/64 loss: -2.5998668670654297
Batch 2/64 loss: -2.747854232788086
Batch 3/64 loss: -2.801555633544922
Batch 4/64 loss: -2.977811813354492
Batch 5/64 loss: -2.778078079223633
Batch 6/64 loss: -2.566800117492676
Batch 7/64 loss: -2.6632080078125
Batch 8/64 loss: -2.813082695007324
Batch 9/64 loss: -2.767444610595703
Batch 10/64 loss: -2.8141050338745117
Batch 11/64 loss: -2.554746627807617
Batch 12/64 loss: -2.539144515991211
Batch 13/64 loss: -2.7423133850097656
Batch 14/64 loss: -2.5106430053710938
Batch 15/64 loss: -2.8268356323242188
Batch 16/64 loss: -2.6903791427612305
Batch 17/64 loss: -2.399984359741211
Batch 18/64 loss: -2.5493669509887695
Batch 19/64 loss: -2.4639291763305664
Batch 20/64 loss: -2.628506660461426
Batch 21/64 loss: -2.547374725341797
Batch 22/64 loss: -2.130239486694336
Batch 23/64 loss: -2.447464942932129
Batch 24/64 loss: -2.6101646423339844
Batch 25/64 loss: -2.786055564880371
Batch 26/64 loss: -2.711294174194336
Batch 27/64 loss: -2.52109432220459
Batch 28/64 loss: -2.599790573120117
Batch 29/64 loss: -2.756525993347168
Batch 30/64 loss: -2.6709470748901367
Batch 31/64 loss: -2.830259323120117
Batch 32/64 loss: -2.4926528930664062
Batch 33/64 loss: -2.728839874267578
Batch 34/64 loss: -2.4184818267822266
Batch 35/64 loss: -2.645533561706543
Batch 36/64 loss: -2.3370742797851562
Batch 37/64 loss: -2.6602983474731445
Batch 38/64 loss: -2.498292922973633
Batch 39/64 loss: -2.25924015045166
Batch 40/64 loss: -2.58420467376709
Batch 41/64 loss: -2.8647994995117188
Batch 42/64 loss: -2.5408124923706055
Batch 43/64 loss: -2.412480354309082
Batch 44/64 loss: -2.5456314086914062
Batch 45/64 loss: -2.74178409576416
Batch 46/64 loss: -2.15106201171875
Batch 47/64 loss: -2.705179214477539
Batch 48/64 loss: -2.791468620300293
Batch 49/64 loss: -2.0710525512695312
Batch 50/64 loss: -2.897808074951172
Batch 51/64 loss: -2.7906265258789062
Batch 52/64 loss: -2.6253528594970703
Batch 53/64 loss: -2.397003173828125
Batch 54/64 loss: -2.6046342849731445
Batch 55/64 loss: -2.776538848876953
Batch 56/64 loss: -2.567819595336914
Batch 57/64 loss: -2.9086503982543945
Batch 58/64 loss: -2.575453758239746
Batch 59/64 loss: -2.4096126556396484
Batch 60/64 loss: -2.7563371658325195
Batch 61/64 loss: -2.6854066848754883
Batch 62/64 loss: -2.796092987060547
Batch 63/64 loss: -2.6768798828125
Batch 64/64 loss: -6.665836334228516
Epoch 219  Train loss: -2.6660917693493413  Val loss: -2.6270060981671834
Epoch 220
-------------------------------
Batch 1/64 loss: -2.330373764038086
Batch 2/64 loss: -2.574587821960449
Batch 3/64 loss: -2.3662004470825195
Batch 4/64 loss: -2.8338422775268555
Batch 5/64 loss: -2.752817153930664
Batch 6/64 loss: -2.716721534729004
Batch 7/64 loss: -2.622502326965332
Batch 8/64 loss: -2.3765392303466797
Batch 9/64 loss: -1.9526796340942383
Batch 10/64 loss: -2.5153703689575195
Batch 11/64 loss: -2.6482276916503906
Batch 12/64 loss: -2.435699462890625
Batch 13/64 loss: -2.5773916244506836
Batch 14/64 loss: -2.474310874938965
Batch 15/64 loss: -2.473936080932617
Batch 16/64 loss: -2.246270179748535
Batch 17/64 loss: -2.6018495559692383
Batch 18/64 loss: -2.577230453491211
Batch 19/64 loss: -2.626565933227539
Batch 20/64 loss: -2.2894248962402344
Batch 21/64 loss: -2.7688941955566406
Batch 22/64 loss: -2.629086494445801
Batch 23/64 loss: -2.600078582763672
Batch 24/64 loss: -2.8071508407592773
Batch 25/64 loss: -2.521531105041504
Batch 26/64 loss: -2.7543582916259766
Batch 27/64 loss: -2.429149627685547
Batch 28/64 loss: -2.3269081115722656
Batch 29/64 loss: -2.816629409790039
Batch 30/64 loss: -2.701504707336426
Batch 31/64 loss: -2.4057626724243164
Batch 32/64 loss: -2.1261072158813477
Batch 33/64 loss: -2.4654130935668945
Batch 34/64 loss: -2.1486101150512695
Batch 35/64 loss: -2.53851318359375
Batch 36/64 loss: -2.4030580520629883
Batch 37/64 loss: -2.934229850769043
Batch 38/64 loss: -2.441929817199707
Batch 39/64 loss: -2.9418439865112305
Batch 40/64 loss: -2.7828311920166016
Batch 41/64 loss: -2.470860481262207
Batch 42/64 loss: -2.6837501525878906
Batch 43/64 loss: -2.808711051940918
Batch 44/64 loss: -2.5156211853027344
Batch 45/64 loss: -2.7281322479248047
Batch 46/64 loss: -2.6093530654907227
Batch 47/64 loss: -2.7952699661254883
Batch 48/64 loss: -2.515625
Batch 49/64 loss: -2.7323617935180664
Batch 50/64 loss: -2.8281173706054688
Batch 51/64 loss: -2.688082695007324
Batch 52/64 loss: -2.2431650161743164
Batch 53/64 loss: -2.6329383850097656
Batch 54/64 loss: -2.8509836196899414
Batch 55/64 loss: -2.7165279388427734
Batch 56/64 loss: -2.4065675735473633
Batch 57/64 loss: -2.7512636184692383
Batch 58/64 loss: -2.924806594848633
Batch 59/64 loss: -2.662872314453125
Batch 60/64 loss: -2.776884078979492
Batch 61/64 loss: -2.870504379272461
Batch 62/64 loss: -2.4530630111694336
Batch 63/64 loss: -2.8208494186401367
Batch 64/64 loss: -7.136529445648193
Epoch 220  Train loss: -2.6411739592458687  Val loss: -2.949899470273572
Saving best model, epoch: 220
Epoch 221
-------------------------------
Batch 1/64 loss: -2.732682228088379
Batch 2/64 loss: -2.65317440032959
Batch 3/64 loss: -2.5329360961914062
Batch 4/64 loss: -2.762730598449707
Batch 5/64 loss: -2.716952323913574
Batch 6/64 loss: -2.5337343215942383
Batch 7/64 loss: -2.91815185546875
Batch 8/64 loss: -2.772869110107422
Batch 9/64 loss: -2.912503242492676
Batch 10/64 loss: -2.794952392578125
Batch 11/64 loss: -2.76505184173584
Batch 12/64 loss: -2.6151771545410156
Batch 13/64 loss: -2.5902271270751953
Batch 14/64 loss: -2.5569143295288086
Batch 15/64 loss: -2.743618965148926
Batch 16/64 loss: -2.9135522842407227
Batch 17/64 loss: -2.587991714477539
Batch 18/64 loss: -2.71710205078125
Batch 19/64 loss: -2.843438148498535
Batch 20/64 loss: -2.490886688232422
Batch 21/64 loss: -2.574528694152832
Batch 22/64 loss: -2.6604461669921875
Batch 23/64 loss: -2.765172004699707
Batch 24/64 loss: -2.817922592163086
Batch 25/64 loss: -2.54769229888916
Batch 26/64 loss: -2.301065444946289
Batch 27/64 loss: -2.5242395401000977
Batch 28/64 loss: -2.73465633392334
Batch 29/64 loss: -2.8471994400024414
Batch 30/64 loss: -2.4939308166503906
Batch 31/64 loss: -2.6762819290161133
Batch 32/64 loss: -2.8444652557373047
Batch 33/64 loss: -2.8120689392089844
Batch 34/64 loss: -2.44272518157959
Batch 35/64 loss: -2.67874813079834
Batch 36/64 loss: -2.9354896545410156
Batch 37/64 loss: -2.793781280517578
Batch 38/64 loss: -2.518930435180664
Batch 39/64 loss: -2.677053451538086
Batch 40/64 loss: -2.7297792434692383
Batch 41/64 loss: -2.605588912963867
Batch 42/64 loss: -2.665848731994629
Batch 43/64 loss: -2.756732940673828
Batch 44/64 loss: -2.8680505752563477
Batch 45/64 loss: -2.646421432495117
Batch 46/64 loss: -2.8694076538085938
Batch 47/64 loss: -2.6773462295532227
Batch 48/64 loss: -2.6574535369873047
Batch 49/64 loss: -2.706780433654785
Batch 50/64 loss: -2.947589874267578
Batch 51/64 loss: -2.7098922729492188
Batch 52/64 loss: -2.3585100173950195
Batch 53/64 loss: -2.449408531188965
Batch 54/64 loss: -2.3567399978637695
Batch 55/64 loss: -2.9544715881347656
Batch 56/64 loss: -2.581106185913086
Batch 57/64 loss: -2.755600929260254
Batch 58/64 loss: -2.539602279663086
Batch 59/64 loss: -2.3596019744873047
Batch 60/64 loss: -2.9230661392211914
Batch 61/64 loss: -2.415982246398926
Batch 62/64 loss: -2.495356559753418
Batch 63/64 loss: -2.745136260986328
Batch 64/64 loss: -7.302572250366211
Epoch 221  Train loss: -2.7302501678466795  Val loss: -2.9675168302870287
Saving best model, epoch: 221
Epoch 222
-------------------------------
Batch 1/64 loss: -2.661055564880371
Batch 2/64 loss: -2.6947755813598633
Batch 3/64 loss: -2.8795719146728516
Batch 4/64 loss: -2.6604089736938477
Batch 5/64 loss: -2.5940771102905273
Batch 6/64 loss: -2.655925750732422
Batch 7/64 loss: -2.4093217849731445
Batch 8/64 loss: -2.8389511108398438
Batch 9/64 loss: -2.686870574951172
Batch 10/64 loss: -2.3223886489868164
Batch 11/64 loss: -2.6494483947753906
Batch 12/64 loss: -2.496976852416992
Batch 13/64 loss: -2.7217512130737305
Batch 14/64 loss: -2.4159154891967773
Batch 15/64 loss: -2.875575065612793
Batch 16/64 loss: -2.551682472229004
Batch 17/64 loss: -2.6528444290161133
Batch 18/64 loss: -2.5714826583862305
Batch 19/64 loss: -2.556640625
Batch 20/64 loss: -2.607783317565918
Batch 21/64 loss: -2.7118234634399414
Batch 22/64 loss: -2.751087188720703
Batch 23/64 loss: -2.7224693298339844
Batch 24/64 loss: -2.826735496520996
Batch 25/64 loss: -2.6419315338134766
Batch 26/64 loss: -2.6943254470825195
Batch 27/64 loss: -2.718873977661133
Batch 28/64 loss: -2.636387825012207
Batch 29/64 loss: -2.6770238876342773
Batch 30/64 loss: -2.790616989135742
Batch 31/64 loss: -2.7873544692993164
Batch 32/64 loss: -2.671171188354492
Batch 33/64 loss: -2.7196216583251953
Batch 34/64 loss: -2.8088197708129883
Batch 35/64 loss: -2.843052864074707
Batch 36/64 loss: -2.651163101196289
Batch 37/64 loss: -2.5677804946899414
Batch 38/64 loss: -2.96065616607666
Batch 39/64 loss: -2.4811267852783203
Batch 40/64 loss: -2.799923896789551
Batch 41/64 loss: -2.3837900161743164
Batch 42/64 loss: -2.8996219635009766
Batch 43/64 loss: -2.433291435241699
Batch 44/64 loss: -2.635361671447754
Batch 45/64 loss: -2.193325996398926
Batch 46/64 loss: -2.7321577072143555
Batch 47/64 loss: -2.818528175354004
Batch 48/64 loss: -2.7512378692626953
Batch 49/64 loss: -2.766465187072754
Batch 50/64 loss: -2.5146427154541016
Batch 51/64 loss: -2.8031845092773438
Batch 52/64 loss: -2.3948612213134766
Batch 53/64 loss: -2.8113327026367188
Batch 54/64 loss: -2.516615867614746
Batch 55/64 loss: -2.66074275970459
Batch 56/64 loss: -2.750396728515625
Batch 57/64 loss: -2.8048391342163086
Batch 58/64 loss: -2.7911758422851562
Batch 59/64 loss: -2.5234832763671875
Batch 60/64 loss: -2.8354721069335938
Batch 61/64 loss: -2.9090213775634766
Batch 62/64 loss: -2.9053287506103516
Batch 63/64 loss: -2.6044979095458984
Batch 64/64 loss: -7.307318687438965
Epoch 222  Train loss: -2.727611874599083  Val loss: -2.9464112507928277
Epoch 223
-------------------------------
Batch 1/64 loss: -2.7362756729125977
Batch 2/64 loss: -2.2592878341674805
Batch 3/64 loss: -2.596172332763672
Batch 4/64 loss: -2.7192611694335938
Batch 5/64 loss: -2.4065933227539062
Batch 6/64 loss: -2.810934066772461
Batch 7/64 loss: -2.748072624206543
Batch 8/64 loss: -2.818880081176758
Batch 9/64 loss: -2.787994384765625
Batch 10/64 loss: -2.92581844329834
Batch 11/64 loss: -2.712308883666992
Batch 12/64 loss: -2.760068893432617
Batch 13/64 loss: -2.806488037109375
Batch 14/64 loss: -2.674464225769043
Batch 15/64 loss: -2.9055747985839844
Batch 16/64 loss: -2.7473745346069336
Batch 17/64 loss: -2.6277780532836914
Batch 18/64 loss: -2.692624092102051
Batch 19/64 loss: -2.611837387084961
Batch 20/64 loss: -2.9098892211914062
Batch 21/64 loss: -2.441221237182617
Batch 22/64 loss: -2.799880027770996
Batch 23/64 loss: -2.7515811920166016
Batch 24/64 loss: -2.658071517944336
Batch 25/64 loss: -2.854912757873535
Batch 26/64 loss: -2.8457250595092773
Batch 27/64 loss: -2.4992685317993164
Batch 28/64 loss: -2.3834362030029297
Batch 29/64 loss: -2.663008689880371
Batch 30/64 loss: -2.7007951736450195
Batch 31/64 loss: -2.87579345703125
Batch 32/64 loss: -2.6326045989990234
Batch 33/64 loss: -2.555940628051758
Batch 34/64 loss: -2.9023571014404297
Batch 35/64 loss: -2.6399927139282227
Batch 36/64 loss: -2.8238019943237305
Batch 37/64 loss: -2.264449119567871
Batch 38/64 loss: -2.687344551086426
Batch 39/64 loss: -2.7852420806884766
Batch 40/64 loss: -2.726198196411133
Batch 41/64 loss: -2.804629325866699
Batch 42/64 loss: -2.7627201080322266
Batch 43/64 loss: -2.4112863540649414
Batch 44/64 loss: -2.6537647247314453
Batch 45/64 loss: -2.541370391845703
Batch 46/64 loss: -2.8404369354248047
Batch 47/64 loss: -2.5986013412475586
Batch 48/64 loss: -2.7777605056762695
Batch 49/64 loss: -2.795668601989746
Batch 50/64 loss: -2.8398923873901367
Batch 51/64 loss: -2.715329170227051
Batch 52/64 loss: -2.6751251220703125
Batch 53/64 loss: -2.518434524536133
Batch 54/64 loss: -2.9078168869018555
Batch 55/64 loss: -2.7216548919677734
Batch 56/64 loss: -2.612293243408203
Batch 57/64 loss: -2.8782119750976562
Batch 58/64 loss: -2.676091194152832
Batch 59/64 loss: -2.8302717208862305
Batch 60/64 loss: -2.686276435852051
Batch 61/64 loss: -2.579456329345703
Batch 62/64 loss: -2.652602195739746
Batch 63/64 loss: -2.6317949295043945
Batch 64/64 loss: -7.2010178565979
Epoch 223  Train loss: -2.7492011855630314  Val loss: -2.9443670318708386
Epoch 224
-------------------------------
Batch 1/64 loss: -2.7602853775024414
Batch 2/64 loss: -2.5652103424072266
Batch 3/64 loss: -2.576871871948242
Batch 4/64 loss: -2.775160789489746
Batch 5/64 loss: -2.773710250854492
Batch 6/64 loss: -2.295034408569336
Batch 7/64 loss: -2.71382999420166
Batch 8/64 loss: -2.7116594314575195
Batch 9/64 loss: -2.627596855163574
Batch 10/64 loss: -2.6269140243530273
Batch 11/64 loss: -2.979128837585449
Batch 12/64 loss: -2.7492218017578125
Batch 13/64 loss: -2.654245376586914
Batch 14/64 loss: -2.785456657409668
Batch 15/64 loss: -2.8684730529785156
Batch 16/64 loss: -2.850733757019043
Batch 17/64 loss: -2.618593215942383
Batch 18/64 loss: -2.70529842376709
Batch 19/64 loss: -2.671213150024414
Batch 20/64 loss: -2.6826162338256836
Batch 21/64 loss: -2.9256763458251953
Batch 22/64 loss: -2.8435306549072266
Batch 23/64 loss: -2.402493476867676
Batch 24/64 loss: -2.814053535461426
Batch 25/64 loss: -2.995574951171875
Batch 26/64 loss: -2.5493602752685547
Batch 27/64 loss: -2.7621774673461914
Batch 28/64 loss: -2.743022918701172
Batch 29/64 loss: -2.728466033935547
Batch 30/64 loss: -2.533768653869629
Batch 31/64 loss: -2.727280616760254
Batch 32/64 loss: -2.8707332611083984
Batch 33/64 loss: -2.8112688064575195
Batch 34/64 loss: -2.584597587585449
Batch 35/64 loss: -2.722135543823242
Batch 36/64 loss: -2.696183204650879
Batch 37/64 loss: -2.7919750213623047
Batch 38/64 loss: -2.8772668838500977
Batch 39/64 loss: -2.6541662216186523
Batch 40/64 loss: -2.9669904708862305
Batch 41/64 loss: -1.458256721496582
Batch 42/64 loss: -2.861636161804199
Batch 43/64 loss: -2.8380002975463867
Batch 44/64 loss: -2.7468833923339844
Batch 45/64 loss: -2.7635374069213867
Batch 46/64 loss: -2.675168991088867
Batch 47/64 loss: -2.90625
Batch 48/64 loss: -2.6059112548828125
Batch 49/64 loss: -2.548603057861328
Batch 50/64 loss: -2.7402877807617188
Batch 51/64 loss: -2.7334423065185547
Batch 52/64 loss: -2.8739013671875
Batch 53/64 loss: -2.6900997161865234
Batch 54/64 loss: -2.897520065307617
Batch 55/64 loss: -2.839137077331543
Batch 56/64 loss: -2.3481521606445312
Batch 57/64 loss: -2.6305198669433594
Batch 58/64 loss: -2.8588218688964844
Batch 59/64 loss: -2.7487220764160156
Batch 60/64 loss: -2.3335180282592773
Batch 61/64 loss: -2.796926498413086
Batch 62/64 loss: -2.1385250091552734
Batch 63/64 loss: -2.770303726196289
Batch 64/64 loss: -7.23028039932251
Epoch 224  Train loss: -2.748530367308972  Val loss: -2.8549656294465473
Epoch 225
-------------------------------
Batch 1/64 loss: -2.4004335403442383
Batch 2/64 loss: -2.816103935241699
Batch 3/64 loss: -2.5304489135742188
Batch 4/64 loss: -2.8825674057006836
Batch 5/64 loss: -2.378159523010254
Batch 6/64 loss: -2.653940200805664
Batch 7/64 loss: -2.4480810165405273
Batch 8/64 loss: -2.773435592651367
Batch 9/64 loss: -2.60884952545166
Batch 10/64 loss: -2.4892988204956055
Batch 11/64 loss: -2.8173341751098633
Batch 12/64 loss: -2.8437585830688477
Batch 13/64 loss: -2.944979667663574
Batch 14/64 loss: -2.518392562866211
Batch 15/64 loss: -2.96927547454834
Batch 16/64 loss: -2.853038787841797
Batch 17/64 loss: -2.3847522735595703
Batch 18/64 loss: -2.5607595443725586
Batch 19/64 loss: -2.540553092956543
Batch 20/64 loss: -2.8529186248779297
Batch 21/64 loss: -2.7935075759887695
Batch 22/64 loss: -2.4452085494995117
Batch 23/64 loss: -2.7792863845825195
Batch 24/64 loss: -2.821946144104004
Batch 25/64 loss: -2.845089912414551
Batch 26/64 loss: -2.545071601867676
Batch 27/64 loss: -2.7040529251098633
Batch 28/64 loss: -2.9566421508789062
Batch 29/64 loss: -2.1935949325561523
Batch 30/64 loss: -2.595799446105957
Batch 31/64 loss: -2.5414609909057617
Batch 32/64 loss: -2.6820859909057617
Batch 33/64 loss: -2.5504369735717773
Batch 34/64 loss: -2.9076242446899414
Batch 35/64 loss: -2.8419599533081055
Batch 36/64 loss: -2.7430171966552734
Batch 37/64 loss: -2.687274932861328
Batch 38/64 loss: -2.508089065551758
Batch 39/64 loss: -2.6039037704467773
Batch 40/64 loss: -2.5181360244750977
Batch 41/64 loss: -2.7553529739379883
Batch 42/64 loss: -2.46881103515625
Batch 43/64 loss: -2.7372779846191406
Batch 44/64 loss: -2.5563507080078125
Batch 45/64 loss: -2.7021398544311523
Batch 46/64 loss: -2.700897216796875
Batch 47/64 loss: -2.6527366638183594
Batch 48/64 loss: -2.7905044555664062
Batch 49/64 loss: -2.7656021118164062
Batch 50/64 loss: -2.8878679275512695
Batch 51/64 loss: -2.5053272247314453
Batch 52/64 loss: -2.6881723403930664
Batch 53/64 loss: -2.7871694564819336
Batch 54/64 loss: -2.7836713790893555
Batch 55/64 loss: -2.8191261291503906
Batch 56/64 loss: -2.801706314086914
Batch 57/64 loss: -2.961528778076172
Batch 58/64 loss: -2.8323888778686523
Batch 59/64 loss: -2.8909568786621094
Batch 60/64 loss: -2.8851699829101562
Batch 61/64 loss: -2.8603572845458984
Batch 62/64 loss: -2.5045108795166016
Batch 63/64 loss: -2.8297500610351562
Batch 64/64 loss: -7.2201738357543945
Epoch 225  Train loss: -2.746882775250603  Val loss: -2.9810276359217274
Saving best model, epoch: 225
Epoch 226
-------------------------------
Batch 1/64 loss: -2.4327220916748047
Batch 2/64 loss: -2.609206199645996
Batch 3/64 loss: -2.7237958908081055
Batch 4/64 loss: -2.657118797302246
Batch 5/64 loss: -2.4331188201904297
Batch 6/64 loss: -2.82753849029541
Batch 7/64 loss: -2.7448883056640625
Batch 8/64 loss: -2.7982797622680664
Batch 9/64 loss: -2.7995223999023438
Batch 10/64 loss: -2.8185834884643555
Batch 11/64 loss: -1.9682035446166992
Batch 12/64 loss: -2.390974998474121
Batch 13/64 loss: -2.7060794830322266
Batch 14/64 loss: -2.919544219970703
Batch 15/64 loss: -2.807328224182129
Batch 16/64 loss: -2.6357812881469727
Batch 17/64 loss: -2.7554187774658203
Batch 18/64 loss: -2.8770389556884766
Batch 19/64 loss: -2.4781198501586914
Batch 20/64 loss: -2.8797407150268555
Batch 21/64 loss: -2.2200698852539062
Batch 22/64 loss: -2.5924158096313477
Batch 23/64 loss: -2.553982734680176
Batch 24/64 loss: -2.8114681243896484
Batch 25/64 loss: -2.5274152755737305
Batch 26/64 loss: -2.5871353149414062
Batch 27/64 loss: -2.5308609008789062
Batch 28/64 loss: -2.981499671936035
Batch 29/64 loss: -2.750408172607422
Batch 30/64 loss: -2.726529121398926
Batch 31/64 loss: -2.6847267150878906
Batch 32/64 loss: -2.668701171875
Batch 33/64 loss: -2.8251962661743164
Batch 34/64 loss: -2.455477714538574
Batch 35/64 loss: -2.796576499938965
Batch 36/64 loss: -2.955817222595215
Batch 37/64 loss: -2.8619794845581055
Batch 38/64 loss: -2.776505470275879
Batch 39/64 loss: -2.7101526260375977
Batch 40/64 loss: -2.737253189086914
Batch 41/64 loss: -2.6926183700561523
Batch 42/64 loss: -2.448650360107422
Batch 43/64 loss: -2.3131752014160156
Batch 44/64 loss: -2.628340721130371
Batch 45/64 loss: -2.6206111907958984
Batch 46/64 loss: -2.5315322875976562
Batch 47/64 loss: -2.7373886108398438
Batch 48/64 loss: -2.5211362838745117
Batch 49/64 loss: -2.906930923461914
Batch 50/64 loss: -2.456146240234375
Batch 51/64 loss: -2.5136117935180664
Batch 52/64 loss: -2.6256914138793945
Batch 53/64 loss: -2.707538604736328
Batch 54/64 loss: -2.625408172607422
Batch 55/64 loss: -2.753873825073242
Batch 56/64 loss: -2.8605918884277344
Batch 57/64 loss: -2.9614953994750977
Batch 58/64 loss: -2.8134145736694336
Batch 59/64 loss: -2.7032766342163086
Batch 60/64 loss: -2.5459165573120117
Batch 61/64 loss: -2.785181999206543
Batch 62/64 loss: -2.51686954498291
Batch 63/64 loss: -2.9140119552612305
Batch 64/64 loss: -7.261683940887451
Epoch 226  Train loss: -2.72387217540367  Val loss: -2.7989151027194414
Epoch 227
-------------------------------
Batch 1/64 loss: -2.7052507400512695
Batch 2/64 loss: -2.5112180709838867
Batch 3/64 loss: -2.735584259033203
Batch 4/64 loss: -2.505910873413086
Batch 5/64 loss: -2.566434860229492
Batch 6/64 loss: -2.640735626220703
Batch 7/64 loss: -2.7803239822387695
Batch 8/64 loss: -2.754880905151367
Batch 9/64 loss: -2.7937850952148438
Batch 10/64 loss: -2.5446176528930664
Batch 11/64 loss: -2.729188919067383
Batch 12/64 loss: -2.7082862854003906
Batch 13/64 loss: -2.6508073806762695
Batch 14/64 loss: -2.5494308471679688
Batch 15/64 loss: -2.669706344604492
Batch 16/64 loss: -2.8290538787841797
Batch 17/64 loss: -2.863043785095215
Batch 18/64 loss: -2.6957569122314453
Batch 19/64 loss: -2.6567420959472656
Batch 20/64 loss: -2.797806739807129
Batch 21/64 loss: -3.018519401550293
Batch 22/64 loss: -2.7579727172851562
Batch 23/64 loss: -2.5043258666992188
Batch 24/64 loss: -2.8327255249023438
Batch 25/64 loss: -2.7562646865844727
Batch 26/64 loss: -2.828845977783203
Batch 27/64 loss: -2.825763702392578
Batch 28/64 loss: -2.9018383026123047
Batch 29/64 loss: -2.911410331726074
Batch 30/64 loss: -2.778078079223633
Batch 31/64 loss: -2.8730039596557617
Batch 32/64 loss: -2.704178810119629
Batch 33/64 loss: -2.651826858520508
Batch 34/64 loss: -2.918262481689453
Batch 35/64 loss: -2.6568708419799805
Batch 36/64 loss: -2.770814895629883
Batch 37/64 loss: -2.3543825149536133
Batch 38/64 loss: -2.3258752822875977
Batch 39/64 loss: -2.774325370788574
Batch 40/64 loss: -2.48007869720459
Batch 41/64 loss: -2.802379608154297
Batch 42/64 loss: -2.4525585174560547
Batch 43/64 loss: -2.709723472595215
Batch 44/64 loss: -2.6932621002197266
Batch 45/64 loss: -2.690005302429199
Batch 46/64 loss: -2.522425651550293
Batch 47/64 loss: -2.9239931106567383
Batch 48/64 loss: -2.7332000732421875
Batch 49/64 loss: -2.6203689575195312
Batch 50/64 loss: -2.910487174987793
Batch 51/64 loss: -2.614396095275879
Batch 52/64 loss: -2.696011543273926
Batch 53/64 loss: -2.472357749938965
Batch 54/64 loss: -2.4249706268310547
Batch 55/64 loss: -2.6772403717041016
Batch 56/64 loss: -2.5416603088378906
Batch 57/64 loss: -2.536208152770996
Batch 58/64 loss: -2.543654441833496
Batch 59/64 loss: -2.241952896118164
Batch 60/64 loss: -2.98577880859375
Batch 61/64 loss: -2.428004264831543
Batch 62/64 loss: -2.7117443084716797
Batch 63/64 loss: -2.594989776611328
Batch 64/64 loss: -7.258899211883545
Epoch 227  Train loss: -2.7338898396959492  Val loss: -2.938880029003235
Epoch 228
-------------------------------
Batch 1/64 loss: -2.8045272827148438
Batch 2/64 loss: -2.5970659255981445
Batch 3/64 loss: -2.2882471084594727
Batch 4/64 loss: -2.4749221801757812
Batch 5/64 loss: -2.384884834289551
Batch 6/64 loss: -2.839059829711914
Batch 7/64 loss: -2.5690860748291016
Batch 8/64 loss: -2.5323963165283203
Batch 9/64 loss: -2.566843032836914
Batch 10/64 loss: -2.6807079315185547
Batch 11/64 loss: -2.793539047241211
Batch 12/64 loss: -2.5843639373779297
Batch 13/64 loss: -2.6643381118774414
Batch 14/64 loss: -2.7310171127319336
Batch 15/64 loss: -2.5019893646240234
Batch 16/64 loss: -2.567291259765625
Batch 17/64 loss: -2.875185012817383
Batch 18/64 loss: -2.878704071044922
Batch 19/64 loss: -2.7513608932495117
Batch 20/64 loss: -2.395148277282715
Batch 21/64 loss: -2.7535533905029297
Batch 22/64 loss: -2.7800121307373047
Batch 23/64 loss: -2.343977928161621
Batch 24/64 loss: -2.838534355163574
Batch 25/64 loss: -2.867656707763672
Batch 26/64 loss: -2.5674219131469727
Batch 27/64 loss: -2.8679580688476562
Batch 28/64 loss: -2.5844106674194336
Batch 29/64 loss: -2.7156877517700195
Batch 30/64 loss: -2.6917648315429688
Batch 31/64 loss: -2.9111242294311523
Batch 32/64 loss: -2.8492393493652344
Batch 33/64 loss: -2.734804153442383
Batch 34/64 loss: -2.544647216796875
Batch 35/64 loss: -2.7391767501831055
Batch 36/64 loss: -2.5989294052124023
Batch 37/64 loss: -2.853231430053711
Batch 38/64 loss: -2.748520851135254
Batch 39/64 loss: -2.958587646484375
Batch 40/64 loss: -2.5303688049316406
Batch 41/64 loss: -2.7512006759643555
Batch 42/64 loss: -2.7062206268310547
Batch 43/64 loss: -2.768718719482422
Batch 44/64 loss: -2.9362926483154297
Batch 45/64 loss: -2.589385986328125
Batch 46/64 loss: -2.5698957443237305
Batch 47/64 loss: -2.6404600143432617
Batch 48/64 loss: -2.6171512603759766
Batch 49/64 loss: -2.868594169616699
Batch 50/64 loss: -2.7729759216308594
Batch 51/64 loss: -2.379605293273926
Batch 52/64 loss: -2.6899423599243164
Batch 53/64 loss: -2.8202056884765625
Batch 54/64 loss: -2.6784849166870117
Batch 55/64 loss: -2.8585214614868164
Batch 56/64 loss: -2.73779296875
Batch 57/64 loss: -2.7529001235961914
Batch 58/64 loss: -2.2908334732055664
Batch 59/64 loss: -2.936979293823242
Batch 60/64 loss: -2.700061798095703
Batch 61/64 loss: -2.601487159729004
Batch 62/64 loss: -2.871042251586914
Batch 63/64 loss: -2.5241079330444336
Batch 64/64 loss: -6.817512512207031
Epoch 228  Train loss: -2.7315494911343445  Val loss: -3.018437244638135
Saving best model, epoch: 228
Epoch 229
-------------------------------
Batch 1/64 loss: -2.9720458984375
Batch 2/64 loss: -2.4719343185424805
Batch 3/64 loss: -2.7864322662353516
Batch 4/64 loss: -2.7642860412597656
Batch 5/64 loss: -2.788114547729492
Batch 6/64 loss: -2.4720163345336914
Batch 7/64 loss: -2.805685043334961
Batch 8/64 loss: -2.7165327072143555
Batch 9/64 loss: -2.860576629638672
Batch 10/64 loss: -2.65126895904541
Batch 11/64 loss: -2.887701988220215
Batch 12/64 loss: -2.8769216537475586
Batch 13/64 loss: -2.5859594345092773
Batch 14/64 loss: -2.611922264099121
Batch 15/64 loss: -2.929619789123535
Batch 16/64 loss: -2.8354997634887695
Batch 17/64 loss: -2.548586845397949
Batch 18/64 loss: -2.4835205078125
Batch 19/64 loss: -2.9453163146972656
Batch 20/64 loss: -2.71829891204834
Batch 21/64 loss: -2.8830671310424805
Batch 22/64 loss: -2.4761085510253906
Batch 23/64 loss: -2.9403076171875
Batch 24/64 loss: -2.654892921447754
Batch 25/64 loss: -2.7235870361328125
Batch 26/64 loss: -2.7116222381591797
Batch 27/64 loss: -2.5625734329223633
Batch 28/64 loss: -2.773496627807617
Batch 29/64 loss: -2.921389579772949
Batch 30/64 loss: -2.653620719909668
Batch 31/64 loss: -2.803786277770996
Batch 32/64 loss: -2.606541633605957
Batch 33/64 loss: -2.765927314758301
Batch 34/64 loss: -2.5960235595703125
Batch 35/64 loss: -2.594485282897949
Batch 36/64 loss: -2.8566789627075195
Batch 37/64 loss: -2.9154253005981445
Batch 38/64 loss: -2.8423194885253906
Batch 39/64 loss: -2.7648277282714844
Batch 40/64 loss: -2.879572868347168
Batch 41/64 loss: -3.025282859802246
Batch 42/64 loss: -2.5189294815063477
Batch 43/64 loss: -2.713857650756836
Batch 44/64 loss: -2.8685474395751953
Batch 45/64 loss: -2.6643686294555664
Batch 46/64 loss: -2.744929313659668
Batch 47/64 loss: -2.6639328002929688
Batch 48/64 loss: -2.75461483001709
Batch 49/64 loss: -2.5250205993652344
Batch 50/64 loss: -2.8655624389648438
Batch 51/64 loss: -2.741729736328125
Batch 52/64 loss: -2.754399299621582
Batch 53/64 loss: -2.793768882751465
Batch 54/64 loss: -2.7719268798828125
Batch 55/64 loss: -2.654539108276367
Batch 56/64 loss: -2.8072214126586914
Batch 57/64 loss: -2.8356714248657227
Batch 58/64 loss: -2.744267463684082
Batch 59/64 loss: -2.6598072052001953
Batch 60/64 loss: -2.552361488342285
Batch 61/64 loss: -2.334641456604004
Batch 62/64 loss: -2.7839012145996094
Batch 63/64 loss: -2.321011543273926
Batch 64/64 loss: -7.008593559265137
Epoch 229  Train loss: -2.7763958089491902  Val loss: -2.948291018246785
Epoch 230
-------------------------------
Batch 1/64 loss: -2.8995542526245117
Batch 2/64 loss: -2.6995201110839844
Batch 3/64 loss: -2.5144386291503906
Batch 4/64 loss: -2.476210594177246
Batch 5/64 loss: -2.692018508911133
Batch 6/64 loss: -2.88370418548584
Batch 7/64 loss: -2.785393714904785
Batch 8/64 loss: -2.84210205078125
Batch 9/64 loss: -2.8154678344726562
Batch 10/64 loss: -2.666327476501465
Batch 11/64 loss: -2.765209197998047
Batch 12/64 loss: -2.6529836654663086
Batch 13/64 loss: -3.018193244934082
Batch 14/64 loss: -2.7812347412109375
Batch 15/64 loss: -2.548813819885254
Batch 16/64 loss: -2.594766616821289
Batch 17/64 loss: -2.9000329971313477
Batch 18/64 loss: -2.6592817306518555
Batch 19/64 loss: -2.8031787872314453
Batch 20/64 loss: -2.901364326477051
Batch 21/64 loss: -2.903818130493164
Batch 22/64 loss: -2.8768434524536133
Batch 23/64 loss: -2.9948501586914062
Batch 24/64 loss: -2.7646656036376953
Batch 25/64 loss: -2.808126449584961
Batch 26/64 loss: -2.7326221466064453
Batch 27/64 loss: -2.694091796875
Batch 28/64 loss: -2.624357223510742
Batch 29/64 loss: -2.564427375793457
Batch 30/64 loss: -2.850461959838867
Batch 31/64 loss: -2.8458290100097656
Batch 32/64 loss: -2.4994821548461914
Batch 33/64 loss: -2.553485870361328
Batch 34/64 loss: -2.5874223709106445
Batch 35/64 loss: -2.651876449584961
Batch 36/64 loss: -2.837423324584961
Batch 37/64 loss: -2.768692970275879
Batch 38/64 loss: -2.89762020111084
Batch 39/64 loss: -2.6059999465942383
Batch 40/64 loss: -2.8791723251342773
Batch 41/64 loss: -2.6084165573120117
Batch 42/64 loss: -2.4540185928344727
Batch 43/64 loss: -2.5956506729125977
Batch 44/64 loss: -2.7884349822998047
Batch 45/64 loss: -2.909442901611328
Batch 46/64 loss: -2.6915483474731445
Batch 47/64 loss: -2.932478904724121
Batch 48/64 loss: -2.564565658569336
Batch 49/64 loss: -2.240133285522461
Batch 50/64 loss: -2.755125045776367
Batch 51/64 loss: -2.693711280822754
Batch 52/64 loss: -2.6690330505371094
Batch 53/64 loss: -2.643223762512207
Batch 54/64 loss: -2.65054988861084
Batch 55/64 loss: -2.778583526611328
Batch 56/64 loss: -2.4605636596679688
Batch 57/64 loss: -2.7850894927978516
Batch 58/64 loss: -2.5987558364868164
Batch 59/64 loss: -2.724306106567383
Batch 60/64 loss: -2.6772031784057617
Batch 61/64 loss: -2.8868408203125
Batch 62/64 loss: -2.668402671813965
Batch 63/64 loss: -2.873745918273926
Batch 64/64 loss: -7.1802496910095215
Epoch 230  Train loss: -2.7745266951766667  Val loss: -2.963244539765558
Epoch 231
-------------------------------
Batch 1/64 loss: -2.6483306884765625
Batch 2/64 loss: -2.876326560974121
Batch 3/64 loss: -2.83138370513916
Batch 4/64 loss: -2.817389488220215
Batch 5/64 loss: -2.7064714431762695
Batch 6/64 loss: -2.8518543243408203
Batch 7/64 loss: -2.6635704040527344
Batch 8/64 loss: -2.9290170669555664
Batch 9/64 loss: -2.856586456298828
Batch 10/64 loss: -2.4902658462524414
Batch 11/64 loss: -2.677215576171875
Batch 12/64 loss: -2.651303291320801
Batch 13/64 loss: -2.8369016647338867
Batch 14/64 loss: -2.3957929611206055
Batch 15/64 loss: -2.971590042114258
Batch 16/64 loss: -2.8140554428100586
Batch 17/64 loss: -2.8212146759033203
Batch 18/64 loss: -2.724712371826172
Batch 19/64 loss: -2.712998390197754
Batch 20/64 loss: -2.7997093200683594
Batch 21/64 loss: -2.938497543334961
Batch 22/64 loss: -2.511533737182617
Batch 23/64 loss: -2.7130308151245117
Batch 24/64 loss: -2.5676870346069336
Batch 25/64 loss: -2.911539077758789
Batch 26/64 loss: -2.820585250854492
Batch 27/64 loss: -2.8457345962524414
Batch 28/64 loss: -2.6068172454833984
Batch 29/64 loss: -2.571756362915039
Batch 30/64 loss: -2.550922393798828
Batch 31/64 loss: -2.7736196517944336
Batch 32/64 loss: -2.823592185974121
Batch 33/64 loss: -2.85690975189209
Batch 34/64 loss: -2.585421562194824
Batch 35/64 loss: -3.024017333984375
Batch 36/64 loss: -2.749260902404785
Batch 37/64 loss: -2.6309518814086914
Batch 38/64 loss: -2.6861143112182617
Batch 39/64 loss: -2.851186752319336
Batch 40/64 loss: -2.9107494354248047
Batch 41/64 loss: -2.6048574447631836
Batch 42/64 loss: -2.6312055587768555
Batch 43/64 loss: -2.7842864990234375
Batch 44/64 loss: -2.7106618881225586
Batch 45/64 loss: -2.7489376068115234
Batch 46/64 loss: -2.8469467163085938
Batch 47/64 loss: -2.616077423095703
Batch 48/64 loss: -2.7519540786743164
Batch 49/64 loss: -2.6975831985473633
Batch 50/64 loss: -2.676342010498047
Batch 51/64 loss: -2.5963563919067383
Batch 52/64 loss: -2.7613983154296875
Batch 53/64 loss: -2.7912940979003906
Batch 54/64 loss: -2.970240592956543
Batch 55/64 loss: -2.6333322525024414
Batch 56/64 loss: -2.6392030715942383
Batch 57/64 loss: -2.8082876205444336
Batch 58/64 loss: -2.6267690658569336
Batch 59/64 loss: -2.815319061279297
Batch 60/64 loss: -2.717855453491211
Batch 61/64 loss: -2.6426963806152344
Batch 62/64 loss: -2.7626476287841797
Batch 63/64 loss: -2.811537742614746
Batch 64/64 loss: -7.3219895362854
Epoch 231  Train loss: -2.7944141144846  Val loss: -2.983096761801808
Epoch 232
-------------------------------
Batch 1/64 loss: -2.7976512908935547
Batch 2/64 loss: -2.9100160598754883
Batch 3/64 loss: -2.60929012298584
Batch 4/64 loss: -2.7835073471069336
Batch 5/64 loss: -2.880260467529297
Batch 6/64 loss: -2.635678291320801
Batch 7/64 loss: -2.9968385696411133
Batch 8/64 loss: -2.9216737747192383
Batch 9/64 loss: -2.775501251220703
Batch 10/64 loss: -2.7579565048217773
Batch 11/64 loss: -2.7581663131713867
Batch 12/64 loss: -3.0293893814086914
Batch 13/64 loss: -2.7661924362182617
Batch 14/64 loss: -2.980379104614258
Batch 15/64 loss: -2.5291996002197266
Batch 16/64 loss: -2.9295034408569336
Batch 17/64 loss: -2.642759323120117
Batch 18/64 loss: -3.0173425674438477
Batch 19/64 loss: -2.7447710037231445
Batch 20/64 loss: -2.717940330505371
Batch 21/64 loss: -2.91652774810791
Batch 22/64 loss: -2.90317440032959
Batch 23/64 loss: -2.7100515365600586
Batch 24/64 loss: -2.814432144165039
Batch 25/64 loss: -2.4045324325561523
Batch 26/64 loss: -2.7637786865234375
Batch 27/64 loss: -2.739241600036621
Batch 28/64 loss: -2.752535820007324
Batch 29/64 loss: -2.711064338684082
Batch 30/64 loss: -2.6791810989379883
Batch 31/64 loss: -2.477710723876953
Batch 32/64 loss: -2.862760543823242
Batch 33/64 loss: -2.962095260620117
Batch 34/64 loss: -2.922212600708008
Batch 35/64 loss: -2.737421989440918
Batch 36/64 loss: -2.795919418334961
Batch 37/64 loss: -2.725644111633301
Batch 38/64 loss: -2.7745561599731445
Batch 39/64 loss: -2.8636960983276367
Batch 40/64 loss: -2.4370546340942383
Batch 41/64 loss: -2.414700508117676
Batch 42/64 loss: -2.8111610412597656
Batch 43/64 loss: -2.610243797302246
Batch 44/64 loss: -2.5282087326049805
Batch 45/64 loss: -2.802126884460449
Batch 46/64 loss: -3.0286712646484375
Batch 47/64 loss: -2.8109540939331055
Batch 48/64 loss: -2.696582794189453
Batch 49/64 loss: -2.6522741317749023
Batch 50/64 loss: -2.5433645248413086
Batch 51/64 loss: -2.6598329544067383
Batch 52/64 loss: -2.979546546936035
Batch 53/64 loss: -2.7354736328125
Batch 54/64 loss: -2.9114580154418945
Batch 55/64 loss: -2.574456214904785
Batch 56/64 loss: -2.655893325805664
Batch 57/64 loss: -2.6192665100097656
Batch 58/64 loss: -2.7007999420166016
Batch 59/64 loss: -2.848465919494629
Batch 60/64 loss: -2.6749629974365234
Batch 61/64 loss: -2.876373291015625
Batch 62/64 loss: -2.9097814559936523
Batch 63/64 loss: -3.0111465454101562
Batch 64/64 loss: -7.126131057739258
Epoch 232  Train loss: -2.816281599156997  Val loss: -3.0524347836209325
Saving best model, epoch: 232
Epoch 233
-------------------------------
Batch 1/64 loss: -2.630866050720215
Batch 2/64 loss: -2.753377914428711
Batch 3/64 loss: -2.87869930267334
Batch 4/64 loss: -2.8737382888793945
Batch 5/64 loss: -2.549043655395508
Batch 6/64 loss: -2.8214282989501953
Batch 7/64 loss: -2.7475643157958984
Batch 8/64 loss: -2.983332633972168
Batch 9/64 loss: -2.812042236328125
Batch 10/64 loss: -2.6553964614868164
Batch 11/64 loss: -2.8660669326782227
Batch 12/64 loss: -2.7480287551879883
Batch 13/64 loss: -2.9312362670898438
Batch 14/64 loss: -2.92349910736084
Batch 15/64 loss: -2.9156360626220703
Batch 16/64 loss: -2.8850011825561523
Batch 17/64 loss: -2.809295654296875
Batch 18/64 loss: -2.878763198852539
Batch 19/64 loss: -2.88588809967041
Batch 20/64 loss: -2.5665807723999023
Batch 21/64 loss: -2.7515172958374023
Batch 22/64 loss: -2.622197151184082
Batch 23/64 loss: -2.343271255493164
Batch 24/64 loss: -3.004061698913574
Batch 25/64 loss: -2.5059032440185547
Batch 26/64 loss: -2.8857078552246094
Batch 27/64 loss: -2.6927261352539062
Batch 28/64 loss: -2.7989940643310547
Batch 29/64 loss: -2.5984630584716797
Batch 30/64 loss: -2.702609062194824
Batch 31/64 loss: -2.9026002883911133
Batch 32/64 loss: -2.834613800048828
Batch 33/64 loss: -2.735621452331543
Batch 34/64 loss: -3.0085906982421875
Batch 35/64 loss: -2.7785778045654297
Batch 36/64 loss: -2.795194625854492
Batch 37/64 loss: -2.8727540969848633
Batch 38/64 loss: -2.372028350830078
Batch 39/64 loss: -2.917525291442871
Batch 40/64 loss: -3.001758575439453
Batch 41/64 loss: -2.6315793991088867
Batch 42/64 loss: -2.6340932846069336
Batch 43/64 loss: -2.486628532409668
Batch 44/64 loss: -3.0276565551757812
Batch 45/64 loss: -2.627505302429199
Batch 46/64 loss: -2.8041954040527344
Batch 47/64 loss: -3.0478992462158203
Batch 48/64 loss: -2.5360288619995117
Batch 49/64 loss: -2.5610342025756836
Batch 50/64 loss: -2.8813514709472656
Batch 51/64 loss: -2.832821846008301
Batch 52/64 loss: -2.9383058547973633
Batch 53/64 loss: -2.7255067825317383
Batch 54/64 loss: -2.5351953506469727
Batch 55/64 loss: -2.890228271484375
Batch 56/64 loss: -2.710171699523926
Batch 57/64 loss: -3.1211423873901367
Batch 58/64 loss: -2.635629653930664
Batch 59/64 loss: -2.709141731262207
Batch 60/64 loss: -2.888888359069824
Batch 61/64 loss: -2.86126708984375
Batch 62/64 loss: -2.670360565185547
Batch 63/64 loss: -2.8018407821655273
Batch 64/64 loss: -6.625441074371338
Epoch 233  Train loss: -2.81988634408689  Val loss: -3.0332898929766365
Epoch 234
-------------------------------
Batch 1/64 loss: -2.920233726501465
Batch 2/64 loss: -2.64810848236084
Batch 3/64 loss: -2.795437812805176
Batch 4/64 loss: -2.727140426635742
Batch 5/64 loss: -2.88582706451416
Batch 6/64 loss: -2.915980339050293
Batch 7/64 loss: -2.442096710205078
Batch 8/64 loss: -2.6263208389282227
Batch 9/64 loss: -2.663667678833008
Batch 10/64 loss: -2.868640899658203
Batch 11/64 loss: -2.8559160232543945
Batch 12/64 loss: -2.9169559478759766
Batch 13/64 loss: -2.8625783920288086
Batch 14/64 loss: -2.683086395263672
Batch 15/64 loss: -2.829763412475586
Batch 16/64 loss: -2.665205955505371
Batch 17/64 loss: -2.6158056259155273
Batch 18/64 loss: -2.7581472396850586
Batch 19/64 loss: -2.279393196105957
Batch 20/64 loss: -3.0112438201904297
Batch 21/64 loss: -2.8036041259765625
Batch 22/64 loss: -2.8110408782958984
Batch 23/64 loss: -3.0855560302734375
Batch 24/64 loss: -2.8214941024780273
Batch 25/64 loss: -2.8320369720458984
Batch 26/64 loss: -2.407917022705078
Batch 27/64 loss: -2.53375244140625
Batch 28/64 loss: -2.7485570907592773
Batch 29/64 loss: -2.6985244750976562
Batch 30/64 loss: -2.95053768157959
Batch 31/64 loss: -2.89168643951416
Batch 32/64 loss: -2.8538284301757812
Batch 33/64 loss: -2.7964649200439453
Batch 34/64 loss: -2.7385940551757812
Batch 35/64 loss: -2.745645523071289
Batch 36/64 loss: -2.6435937881469727
Batch 37/64 loss: -2.646585464477539
Batch 38/64 loss: -2.708157539367676
Batch 39/64 loss: -2.700839042663574
Batch 40/64 loss: -2.7406396865844727
Batch 41/64 loss: -2.5589599609375
Batch 42/64 loss: -2.6126527786254883
Batch 43/64 loss: -2.8006057739257812
Batch 44/64 loss: -2.7767953872680664
Batch 45/64 loss: -2.7860260009765625
Batch 46/64 loss: -2.6669349670410156
Batch 47/64 loss: -2.6629228591918945
Batch 48/64 loss: -2.5539064407348633
Batch 49/64 loss: -2.656437873840332
Batch 50/64 loss: -2.929081916809082
Batch 51/64 loss: -2.978940010070801
Batch 52/64 loss: -2.733780860900879
Batch 53/64 loss: -2.818854331970215
Batch 54/64 loss: -2.7428131103515625
Batch 55/64 loss: -2.5020503997802734
Batch 56/64 loss: -2.63704776763916
Batch 57/64 loss: -2.746267318725586
Batch 58/64 loss: -2.6202898025512695
Batch 59/64 loss: -2.8849687576293945
Batch 60/64 loss: -2.6866207122802734
Batch 61/64 loss: -2.687267303466797
Batch 62/64 loss: -2.7091827392578125
Batch 63/64 loss: -2.7577314376831055
Batch 64/64 loss: -7.181434154510498
Epoch 234  Train loss: -2.7925775658850576  Val loss: -2.967802224699984
Epoch 235
-------------------------------
Batch 1/64 loss: -2.7604455947875977
Batch 2/64 loss: -2.7359352111816406
Batch 3/64 loss: -3.0698366165161133
Batch 4/64 loss: -2.535707473754883
Batch 5/64 loss: -2.625864028930664
Batch 6/64 loss: -2.8438825607299805
Batch 7/64 loss: -2.8348426818847656
Batch 8/64 loss: -2.901303291320801
Batch 9/64 loss: -2.9543256759643555
Batch 10/64 loss: -2.8178157806396484
Batch 11/64 loss: -2.4216537475585938
Batch 12/64 loss: -2.715688705444336
Batch 13/64 loss: -2.8365211486816406
Batch 14/64 loss: -2.8424224853515625
Batch 15/64 loss: -2.5316457748413086
Batch 16/64 loss: -2.827061653137207
Batch 17/64 loss: -2.8898000717163086
Batch 18/64 loss: -2.761568069458008
Batch 19/64 loss: -2.8436403274536133
Batch 20/64 loss: -2.807727813720703
Batch 21/64 loss: -2.843747138977051
Batch 22/64 loss: -2.5247116088867188
Batch 23/64 loss: -2.953847885131836
Batch 24/64 loss: -2.871623992919922
Batch 25/64 loss: -2.6487302780151367
Batch 26/64 loss: -2.5910606384277344
Batch 27/64 loss: -2.802687644958496
Batch 28/64 loss: -2.860184669494629
Batch 29/64 loss: -2.7516727447509766
Batch 30/64 loss: -2.744161605834961
Batch 31/64 loss: -2.7089719772338867
Batch 32/64 loss: -2.655726432800293
Batch 33/64 loss: -2.8033018112182617
Batch 34/64 loss: -2.271696090698242
Batch 35/64 loss: -2.84454345703125
Batch 36/64 loss: -2.8077545166015625
Batch 37/64 loss: -3.0867414474487305
Batch 38/64 loss: -2.803154945373535
Batch 39/64 loss: -2.637998580932617
Batch 40/64 loss: -2.6812353134155273
Batch 41/64 loss: -2.774991989135742
Batch 42/64 loss: -2.993328094482422
Batch 43/64 loss: -2.796942710876465
Batch 44/64 loss: -2.4969310760498047
Batch 45/64 loss: -2.864736557006836
Batch 46/64 loss: -2.631093978881836
Batch 47/64 loss: -2.919297218322754
Batch 48/64 loss: -2.504075050354004
Batch 49/64 loss: -2.8874740600585938
Batch 50/64 loss: -2.8364877700805664
Batch 51/64 loss: -2.894585609436035
Batch 52/64 loss: -2.860968589782715
Batch 53/64 loss: -2.7336626052856445
Batch 54/64 loss: -2.886052131652832
Batch 55/64 loss: -2.791269302368164
Batch 56/64 loss: -2.4969968795776367
Batch 57/64 loss: -2.6606340408325195
Batch 58/64 loss: -2.411433219909668
Batch 59/64 loss: -2.6646995544433594
Batch 60/64 loss: -2.5567493438720703
Batch 61/64 loss: -2.8513193130493164
Batch 62/64 loss: -3.011646270751953
Batch 63/64 loss: -2.5383920669555664
Batch 64/64 loss: -6.698829650878906
Epoch 235  Train loss: -2.8006138221890318  Val loss: -3.029801581733415
Epoch 236
-------------------------------
Batch 1/64 loss: -2.8201351165771484
Batch 2/64 loss: -2.863445281982422
Batch 3/64 loss: -2.5460033416748047
Batch 4/64 loss: -2.767364501953125
Batch 5/64 loss: -2.8985042572021484
Batch 6/64 loss: -2.6641530990600586
Batch 7/64 loss: -2.6413984298706055
Batch 8/64 loss: -2.825532913208008
Batch 9/64 loss: -2.825845718383789
Batch 10/64 loss: -2.6862001419067383
Batch 11/64 loss: -2.5347824096679688
Batch 12/64 loss: -2.8937292098999023
Batch 13/64 loss: -2.9744129180908203
Batch 14/64 loss: -2.645188331604004
Batch 15/64 loss: -2.7651939392089844
Batch 16/64 loss: -3.0031490325927734
Batch 17/64 loss: -2.836811065673828
Batch 18/64 loss: -2.6371870040893555
Batch 19/64 loss: -2.7195615768432617
Batch 20/64 loss: -2.850881576538086
Batch 21/64 loss: -2.85634708404541
Batch 22/64 loss: -2.9608373641967773
Batch 23/64 loss: -2.8081207275390625
Batch 24/64 loss: -2.758059501647949
Batch 25/64 loss: -2.5960874557495117
Batch 26/64 loss: -2.817318916320801
Batch 27/64 loss: -2.6688108444213867
Batch 28/64 loss: -2.6778879165649414
Batch 29/64 loss: -2.6458568572998047
Batch 30/64 loss: -2.7709169387817383
Batch 31/64 loss: -2.8366785049438477
Batch 32/64 loss: -2.3729171752929688
Batch 33/64 loss: -2.8684425354003906
Batch 34/64 loss: -2.8648195266723633
Batch 35/64 loss: -2.7209672927856445
Batch 36/64 loss: -2.839588165283203
Batch 37/64 loss: -2.7139711380004883
Batch 38/64 loss: -2.9531240463256836
Batch 39/64 loss: -2.927753448486328
Batch 40/64 loss: -2.8678512573242188
Batch 41/64 loss: -2.7483606338500977
Batch 42/64 loss: -2.600248336791992
Batch 43/64 loss: -2.8177289962768555
Batch 44/64 loss: -2.8034162521362305
Batch 45/64 loss: -2.715325355529785
Batch 46/64 loss: -2.863771438598633
Batch 47/64 loss: -2.2283878326416016
Batch 48/64 loss: -2.7531862258911133
Batch 49/64 loss: -2.6614809036254883
Batch 50/64 loss: -3.0044240951538086
Batch 51/64 loss: -2.272115707397461
Batch 52/64 loss: -2.963390350341797
Batch 53/64 loss: -2.936234474182129
Batch 54/64 loss: -2.693653106689453
Batch 55/64 loss: -3.0325450897216797
Batch 56/64 loss: -2.71090030670166
Batch 57/64 loss: -2.810610771179199
Batch 58/64 loss: -2.8009042739868164
Batch 59/64 loss: -2.976940155029297
Batch 60/64 loss: -2.832512855529785
Batch 61/64 loss: -2.663410186767578
Batch 62/64 loss: -2.905435562133789
Batch 63/64 loss: -2.9047813415527344
Batch 64/64 loss: -7.357347011566162
Epoch 236  Train loss: -2.8257821344861798  Val loss: -3.0155617494353724
Epoch 237
-------------------------------
Batch 1/64 loss: -2.876544952392578
Batch 2/64 loss: -2.912167549133301
Batch 3/64 loss: -2.812710762023926
Batch 4/64 loss: -2.7998218536376953
Batch 5/64 loss: -2.617445945739746
Batch 6/64 loss: -2.3570737838745117
Batch 7/64 loss: -2.778550148010254
Batch 8/64 loss: -2.704561233520508
Batch 9/64 loss: -2.8742589950561523
Batch 10/64 loss: -2.820730209350586
Batch 11/64 loss: -2.83333683013916
Batch 12/64 loss: -2.876704216003418
Batch 13/64 loss: -2.9280099868774414
Batch 14/64 loss: -2.893817901611328
Batch 15/64 loss: -2.7138500213623047
Batch 16/64 loss: -2.61814022064209
Batch 17/64 loss: -2.6336183547973633
Batch 18/64 loss: -2.8964319229125977
Batch 19/64 loss: -2.997255325317383
Batch 20/64 loss: -2.7758426666259766
Batch 21/64 loss: -2.9909658432006836
Batch 22/64 loss: -2.87109375
Batch 23/64 loss: -2.6635847091674805
Batch 24/64 loss: -2.8484725952148438
Batch 25/64 loss: -2.732876777648926
Batch 26/64 loss: -2.930938720703125
Batch 27/64 loss: -2.5229930877685547
Batch 28/64 loss: -2.772305488586426
Batch 29/64 loss: -2.552800178527832
Batch 30/64 loss: -2.738798141479492
Batch 31/64 loss: -2.6436681747436523
Batch 32/64 loss: -2.673128128051758
Batch 33/64 loss: -2.7293777465820312
Batch 34/64 loss: -2.745006561279297
Batch 35/64 loss: -2.940241813659668
Batch 36/64 loss: -3.0152063369750977
Batch 37/64 loss: -2.82053279876709
Batch 38/64 loss: -2.767289161682129
Batch 39/64 loss: -2.6868553161621094
Batch 40/64 loss: -2.4538660049438477
Batch 41/64 loss: -2.8609352111816406
Batch 42/64 loss: -2.88906192779541
Batch 43/64 loss: -2.7329092025756836
Batch 44/64 loss: -2.677950859069824
Batch 45/64 loss: -2.794210433959961
Batch 46/64 loss: -2.682986259460449
Batch 47/64 loss: -2.769468307495117
Batch 48/64 loss: -2.8896589279174805
Batch 49/64 loss: -2.659099578857422
Batch 50/64 loss: -2.7305402755737305
Batch 51/64 loss: -2.780278205871582
Batch 52/64 loss: -2.4219141006469727
Batch 53/64 loss: -3.0273256301879883
Batch 54/64 loss: -2.7918643951416016
Batch 55/64 loss: -2.744542121887207
Batch 56/64 loss: -2.7170495986938477
Batch 57/64 loss: -2.703022003173828
Batch 58/64 loss: -2.90512752532959
Batch 59/64 loss: -2.747213363647461
Batch 60/64 loss: -2.7386598587036133
Batch 61/64 loss: -2.8351011276245117
Batch 62/64 loss: -2.7972488403320312
Batch 63/64 loss: -2.796977996826172
Batch 64/64 loss: -7.300490856170654
Epoch 237  Train loss: -2.823362950717702  Val loss: -2.9919260555935887
Epoch 238
-------------------------------
Batch 1/64 loss: -2.766993522644043
Batch 2/64 loss: -2.8979921340942383
Batch 3/64 loss: -2.8743085861206055
Batch 4/64 loss: -2.8920488357543945
Batch 5/64 loss: -2.8732805252075195
Batch 6/64 loss: -2.55218505859375
Batch 7/64 loss: -3.0472564697265625
Batch 8/64 loss: -2.9975404739379883
Batch 9/64 loss: -2.6035337448120117
Batch 10/64 loss: -2.5971574783325195
Batch 11/64 loss: -2.526287078857422
Batch 12/64 loss: -2.785210609436035
Batch 13/64 loss: -2.7642135620117188
Batch 14/64 loss: -2.8679656982421875
Batch 15/64 loss: -2.5894947052001953
Batch 16/64 loss: -2.8165483474731445
Batch 17/64 loss: -2.446512222290039
Batch 18/64 loss: -2.6647348403930664
Batch 19/64 loss: -2.7898778915405273
Batch 20/64 loss: -2.9375200271606445
Batch 21/64 loss: -2.7988529205322266
Batch 22/64 loss: -2.696864128112793
Batch 23/64 loss: -2.492565155029297
Batch 24/64 loss: -2.712449073791504
Batch 25/64 loss: -2.4235754013061523
Batch 26/64 loss: -2.4876527786254883
Batch 27/64 loss: -2.538588523864746
Batch 28/64 loss: -2.639235496520996
Batch 29/64 loss: -2.8538808822631836
Batch 30/64 loss: -2.8867883682250977
Batch 31/64 loss: -2.158426284790039
Batch 32/64 loss: -2.6003665924072266
Batch 33/64 loss: -2.435993194580078
Batch 34/64 loss: -2.733710289001465
Batch 35/64 loss: -2.5923986434936523
Batch 36/64 loss: -2.775721549987793
Batch 37/64 loss: -2.8720836639404297
Batch 38/64 loss: -2.829228401184082
Batch 39/64 loss: -2.8368406295776367
Batch 40/64 loss: -2.798403739929199
Batch 41/64 loss: -2.609938621520996
Batch 42/64 loss: -2.695408821105957
Batch 43/64 loss: -2.8279190063476562
Batch 44/64 loss: -2.7828378677368164
Batch 45/64 loss: -2.759671211242676
Batch 46/64 loss: -2.6453943252563477
Batch 47/64 loss: -2.7198333740234375
Batch 48/64 loss: -2.238828659057617
Batch 49/64 loss: -2.8353652954101562
Batch 50/64 loss: -2.8399667739868164
Batch 51/64 loss: -2.6095943450927734
Batch 52/64 loss: -2.504486083984375
Batch 53/64 loss: -2.862964630126953
Batch 54/64 loss: -2.5761375427246094
Batch 55/64 loss: -2.9469804763793945
Batch 56/64 loss: -2.2009267807006836
Batch 57/64 loss: -2.7342348098754883
Batch 58/64 loss: -2.920548439025879
Batch 59/64 loss: -2.866459846496582
Batch 60/64 loss: -2.4666671752929688
Batch 61/64 loss: -2.9407501220703125
Batch 62/64 loss: -2.877444267272949
Batch 63/64 loss: -2.735942840576172
Batch 64/64 loss: -7.189208030700684
Epoch 238  Train loss: -2.761482272428625  Val loss: -2.8392966883289037
Epoch 239
-------------------------------
Batch 1/64 loss: -2.6362743377685547
Batch 2/64 loss: -2.8155603408813477
Batch 3/64 loss: -2.648919105529785
Batch 4/64 loss: -2.51766300201416
Batch 5/64 loss: -2.4866294860839844
Batch 6/64 loss: -2.7095870971679688
Batch 7/64 loss: -2.742494583129883
Batch 8/64 loss: -2.707962989807129
Batch 9/64 loss: -2.505739212036133
Batch 10/64 loss: -2.927424430847168
Batch 11/64 loss: -3.0005979537963867
Batch 12/64 loss: -2.498332977294922
Batch 13/64 loss: -2.5736351013183594
Batch 14/64 loss: -2.7578372955322266
Batch 15/64 loss: -2.3612709045410156
Batch 16/64 loss: -2.6204891204833984
Batch 17/64 loss: -2.942647933959961
Batch 18/64 loss: -2.1737279891967773
Batch 19/64 loss: -2.6497249603271484
Batch 20/64 loss: -2.753042221069336
Batch 21/64 loss: -2.689422607421875
Batch 22/64 loss: -2.84403133392334
Batch 23/64 loss: -1.6888360977172852
Batch 24/64 loss: -2.636733055114746
Batch 25/64 loss: -2.7212352752685547
Batch 26/64 loss: -2.6443185806274414
Batch 27/64 loss: -2.768360137939453
Batch 28/64 loss: -2.76021671295166
Batch 29/64 loss: -2.753506660461426
Batch 30/64 loss: -2.6839427947998047
Batch 31/64 loss: -2.5080881118774414
Batch 32/64 loss: -2.358684539794922
Batch 33/64 loss: -2.7116785049438477
Batch 34/64 loss: -2.7297353744506836
Batch 35/64 loss: -2.617377281188965
Batch 36/64 loss: -2.750110626220703
Batch 37/64 loss: -2.6624536514282227
Batch 38/64 loss: -2.8235034942626953
Batch 39/64 loss: -2.5439882278442383
Batch 40/64 loss: -2.5081167221069336
Batch 41/64 loss: -2.5845727920532227
Batch 42/64 loss: -2.8484325408935547
Batch 43/64 loss: -2.9661178588867188
Batch 44/64 loss: -2.5486326217651367
Batch 45/64 loss: -2.7066917419433594
Batch 46/64 loss: -2.6852188110351562
Batch 47/64 loss: -2.3995447158813477
Batch 48/64 loss: -2.7691192626953125
Batch 49/64 loss: -2.122661590576172
Batch 50/64 loss: -2.8381118774414062
Batch 51/64 loss: -2.7501583099365234
Batch 52/64 loss: -2.889017105102539
Batch 53/64 loss: -2.4495487213134766
Batch 54/64 loss: -2.5124406814575195
Batch 55/64 loss: -2.836029052734375
Batch 56/64 loss: -2.8459510803222656
Batch 57/64 loss: -2.9027538299560547
Batch 58/64 loss: -2.585413932800293
Batch 59/64 loss: -2.6323060989379883
Batch 60/64 loss: -2.472012519836426
Batch 61/64 loss: -2.7185144424438477
Batch 62/64 loss: -2.601140022277832
Batch 63/64 loss: -2.799229621887207
Batch 64/64 loss: -7.269403457641602
Epoch 239  Train loss: -2.7035227083692366  Val loss: -2.9739861242549934
Epoch 240
-------------------------------
Batch 1/64 loss: -2.859267234802246
Batch 2/64 loss: -2.613994598388672
Batch 3/64 loss: -2.918013572692871
Batch 4/64 loss: -2.361135482788086
Batch 5/64 loss: -2.860006332397461
Batch 6/64 loss: -2.650149345397949
Batch 7/64 loss: -2.7848033905029297
Batch 8/64 loss: -2.856935501098633
Batch 9/64 loss: -2.5199356079101562
Batch 10/64 loss: -2.737180709838867
Batch 11/64 loss: -2.9837875366210938
Batch 12/64 loss: -2.9128074645996094
Batch 13/64 loss: -1.4820213317871094
Batch 14/64 loss: -2.884746551513672
Batch 15/64 loss: -2.803255081176758
Batch 16/64 loss: -2.720539093017578
Batch 17/64 loss: -2.502474784851074
Batch 18/64 loss: -2.9050369262695312
Batch 19/64 loss: -2.17147159576416
Batch 20/64 loss: -2.83026123046875
Batch 21/64 loss: -2.646434783935547
Batch 22/64 loss: -2.5097599029541016
Batch 23/64 loss: -2.8947267532348633
Batch 24/64 loss: -2.83449649810791
Batch 25/64 loss: -2.755868911743164
Batch 26/64 loss: -2.4137468338012695
Batch 27/64 loss: -2.8582210540771484
Batch 28/64 loss: -2.8148117065429688
Batch 29/64 loss: -2.6665115356445312
Batch 30/64 loss: -2.9358901977539062
Batch 31/64 loss: -2.6958837509155273
Batch 32/64 loss: -2.544736862182617
Batch 33/64 loss: -2.2051563262939453
Batch 34/64 loss: -2.826430320739746
Batch 35/64 loss: -3.0001792907714844
Batch 36/64 loss: -2.5687999725341797
Batch 37/64 loss: -2.5893774032592773
Batch 38/64 loss: -3.0136804580688477
Batch 39/64 loss: -2.5713205337524414
Batch 40/64 loss: -2.6712770462036133
Batch 41/64 loss: -3.013901710510254
Batch 42/64 loss: -2.5971155166625977
Batch 43/64 loss: -2.7455196380615234
Batch 44/64 loss: -2.905590057373047
Batch 45/64 loss: -2.4814090728759766
Batch 46/64 loss: -2.8293027877807617
Batch 47/64 loss: -2.7008867263793945
Batch 48/64 loss: -2.832705497741699
Batch 49/64 loss: -2.591188430786133
Batch 50/64 loss: -2.7887802124023438
Batch 51/64 loss: -2.7061281204223633
Batch 52/64 loss: -2.5562353134155273
Batch 53/64 loss: -2.889385223388672
Batch 54/64 loss: -2.572589874267578
Batch 55/64 loss: -2.5630836486816406
Batch 56/64 loss: -2.731710433959961
Batch 57/64 loss: -2.909770965576172
Batch 58/64 loss: -2.6244659423828125
Batch 59/64 loss: -2.6953697204589844
Batch 60/64 loss: -2.685527801513672
Batch 61/64 loss: -2.9882707595825195
Batch 62/64 loss: -3.0195789337158203
Batch 63/64 loss: -2.573049545288086
Batch 64/64 loss: -6.812728404998779
Epoch 240  Train loss: -2.752725423551073  Val loss: -2.9705692959814956
Epoch 241
-------------------------------
Batch 1/64 loss: -2.744931221008301
Batch 2/64 loss: -2.806157112121582
Batch 3/64 loss: -2.798046112060547
Batch 4/64 loss: -2.792421340942383
Batch 5/64 loss: -2.763382911682129
Batch 6/64 loss: -2.3937501907348633
Batch 7/64 loss: -2.934009552001953
Batch 8/64 loss: -2.4121036529541016
Batch 9/64 loss: -2.6319522857666016
Batch 10/64 loss: -2.584970474243164
Batch 11/64 loss: -2.66664981842041
Batch 12/64 loss: -2.752138137817383
Batch 13/64 loss: -2.8165502548217773
Batch 14/64 loss: -2.7167787551879883
Batch 15/64 loss: -2.756411552429199
Batch 16/64 loss: -2.80572509765625
Batch 17/64 loss: -2.8783130645751953
Batch 18/64 loss: -2.4797191619873047
Batch 19/64 loss: -2.846682548522949
Batch 20/64 loss: -2.8746557235717773
Batch 21/64 loss: -2.7281742095947266
Batch 22/64 loss: -2.7433719635009766
Batch 23/64 loss: -2.4858169555664062
Batch 24/64 loss: -2.7997493743896484
Batch 25/64 loss: -2.8456077575683594
Batch 26/64 loss: -2.547377586364746
Batch 27/64 loss: -2.894291877746582
Batch 28/64 loss: -2.875762939453125
Batch 29/64 loss: -2.985279083251953
Batch 30/64 loss: -2.757014274597168
Batch 31/64 loss: -2.9459238052368164
Batch 32/64 loss: -2.830249786376953
Batch 33/64 loss: -2.7930192947387695
Batch 34/64 loss: -2.7596216201782227
Batch 35/64 loss: -2.9398317337036133
Batch 36/64 loss: -2.3719682693481445
Batch 37/64 loss: -2.862232208251953
Batch 38/64 loss: -2.415325164794922
Batch 39/64 loss: -2.9093093872070312
Batch 40/64 loss: -2.907888412475586
Batch 41/64 loss: -2.3627729415893555
Batch 42/64 loss: -2.8448171615600586
Batch 43/64 loss: -2.912952423095703
Batch 44/64 loss: -2.846284866333008
Batch 45/64 loss: -2.7279367446899414
Batch 46/64 loss: -2.733290672302246
Batch 47/64 loss: -2.3318424224853516
Batch 48/64 loss: -2.8775205612182617
Batch 49/64 loss: -2.5646820068359375
Batch 50/64 loss: -2.4273996353149414
Batch 51/64 loss: -2.933499336242676
Batch 52/64 loss: -2.695815086364746
Batch 53/64 loss: -2.747166633605957
Batch 54/64 loss: -2.8041696548461914
Batch 55/64 loss: -2.441187858581543
Batch 56/64 loss: -2.512721061706543
Batch 57/64 loss: -2.720865249633789
Batch 58/64 loss: -2.683969497680664
Batch 59/64 loss: -2.842275619506836
Batch 60/64 loss: -2.656942367553711
Batch 61/64 loss: -2.9502696990966797
Batch 62/64 loss: -2.5690250396728516
Batch 63/64 loss: -2.8165225982666016
Batch 64/64 loss: -7.218310356140137
Epoch 241  Train loss: -2.780718848284553  Val loss: -2.920731534662935
Epoch 242
-------------------------------
Batch 1/64 loss: -2.591796875
Batch 2/64 loss: -2.7409191131591797
Batch 3/64 loss: -2.6329145431518555
Batch 4/64 loss: -2.516158103942871
Batch 5/64 loss: -2.705521583557129
Batch 6/64 loss: -2.852865219116211
Batch 7/64 loss: -2.7499313354492188
Batch 8/64 loss: -3.0158491134643555
Batch 9/64 loss: -2.8812437057495117
Batch 10/64 loss: -2.3894309997558594
Batch 11/64 loss: -2.992110252380371
Batch 12/64 loss: -2.72995662689209
Batch 13/64 loss: -2.8835926055908203
Batch 14/64 loss: -2.8278846740722656
Batch 15/64 loss: -2.706789970397949
Batch 16/64 loss: -2.8350114822387695
Batch 17/64 loss: -2.4702043533325195
Batch 18/64 loss: -2.1594982147216797
Batch 19/64 loss: -2.711263656616211
Batch 20/64 loss: -2.8772974014282227
Batch 21/64 loss: -2.5086069107055664
Batch 22/64 loss: -2.647709846496582
Batch 23/64 loss: -2.7656774520874023
Batch 24/64 loss: -2.841371536254883
Batch 25/64 loss: -2.8010730743408203
Batch 26/64 loss: -2.634396553039551
Batch 27/64 loss: -2.6498146057128906
Batch 28/64 loss: -2.8505935668945312
Batch 29/64 loss: -2.8673362731933594
Batch 30/64 loss: -2.862642288208008
Batch 31/64 loss: -2.709249496459961
Batch 32/64 loss: -2.515681266784668
Batch 33/64 loss: -2.7540578842163086
Batch 34/64 loss: -2.4403886795043945
Batch 35/64 loss: -2.7372255325317383
Batch 36/64 loss: -2.726663589477539
Batch 37/64 loss: -2.630343437194824
Batch 38/64 loss: -2.8678016662597656
Batch 39/64 loss: -2.9120073318481445
Batch 40/64 loss: -2.9532089233398438
Batch 41/64 loss: -2.9239187240600586
Batch 42/64 loss: -2.660074234008789
Batch 43/64 loss: -2.80751895904541
Batch 44/64 loss: -3.0402421951293945
Batch 45/64 loss: -2.3709821701049805
Batch 46/64 loss: -2.886951446533203
Batch 47/64 loss: -2.5936079025268555
Batch 48/64 loss: -2.7496700286865234
Batch 49/64 loss: -2.7299604415893555
Batch 50/64 loss: -2.726469039916992
Batch 51/64 loss: -2.4760608673095703
Batch 52/64 loss: -2.9716978073120117
Batch 53/64 loss: -2.6979360580444336
Batch 54/64 loss: -2.4528579711914062
Batch 55/64 loss: -2.568514823913574
Batch 56/64 loss: -2.601058006286621
Batch 57/64 loss: -2.625364303588867
Batch 58/64 loss: -2.672438621520996
Batch 59/64 loss: -2.6528167724609375
Batch 60/64 loss: -2.7600393295288086
Batch 61/64 loss: -2.2460994720458984
Batch 62/64 loss: -2.7441320419311523
Batch 63/64 loss: -2.7231616973876953
Batch 64/64 loss: -7.365150451660156
Epoch 242  Train loss: -2.763161184273514  Val loss: -2.980949074132336
Epoch 243
-------------------------------
Batch 1/64 loss: -2.663442611694336
Batch 2/64 loss: -2.2707462310791016
Batch 3/64 loss: -2.8708600997924805
Batch 4/64 loss: -2.593358039855957
Batch 5/64 loss: -2.47176456451416
Batch 6/64 loss: -2.9591503143310547
Batch 7/64 loss: -2.950143814086914
Batch 8/64 loss: -3.0140323638916016
Batch 9/64 loss: -2.643000602722168
Batch 10/64 loss: -2.381368637084961
Batch 11/64 loss: -2.6272592544555664
Batch 12/64 loss: -2.523106575012207
Batch 13/64 loss: -2.9437713623046875
Batch 14/64 loss: -2.7458877563476562
Batch 15/64 loss: -2.5332136154174805
Batch 16/64 loss: -2.581496238708496
Batch 17/64 loss: -3.059450149536133
Batch 18/64 loss: -2.8447036743164062
Batch 19/64 loss: -2.799004554748535
Batch 20/64 loss: -2.828929901123047
Batch 21/64 loss: -2.8955583572387695
Batch 22/64 loss: -2.7552833557128906
Batch 23/64 loss: -2.430539131164551
Batch 24/64 loss: -2.956205368041992
Batch 25/64 loss: -2.871936798095703
Batch 26/64 loss: -2.67166805267334
Batch 27/64 loss: -2.522274971008301
Batch 28/64 loss: -2.9074182510375977
Batch 29/64 loss: -2.793391227722168
Batch 30/64 loss: -2.6811466217041016
Batch 31/64 loss: -3.084221839904785
Batch 32/64 loss: -2.4581499099731445
Batch 33/64 loss: -2.6105785369873047
Batch 34/64 loss: -2.316817283630371
Batch 35/64 loss: -2.821791648864746
Batch 36/64 loss: -2.742556571960449
Batch 37/64 loss: -2.723982810974121
Batch 38/64 loss: -2.6009521484375
Batch 39/64 loss: -2.6737070083618164
Batch 40/64 loss: -2.6757373809814453
Batch 41/64 loss: -2.584200859069824
Batch 42/64 loss: -2.7497615814208984
Batch 43/64 loss: -2.658135414123535
Batch 44/64 loss: -2.7281293869018555
Batch 45/64 loss: -2.7913246154785156
Batch 46/64 loss: -2.8607378005981445
Batch 47/64 loss: -2.970500946044922
Batch 48/64 loss: -2.5468969345092773
Batch 49/64 loss: -2.6919727325439453
Batch 50/64 loss: -2.9158315658569336
Batch 51/64 loss: -2.9103870391845703
Batch 52/64 loss: -2.933568000793457
Batch 53/64 loss: -2.834872245788574
Batch 54/64 loss: -2.5674190521240234
Batch 55/64 loss: -2.849496841430664
Batch 56/64 loss: -2.5331554412841797
Batch 57/64 loss: -2.89907169342041
Batch 58/64 loss: -2.3309640884399414
Batch 59/64 loss: -2.6117897033691406
Batch 60/64 loss: -2.717532157897949
Batch 61/64 loss: -2.645660400390625
Batch 62/64 loss: -2.5622730255126953
Batch 63/64 loss: -2.6206703186035156
Batch 64/64 loss: -6.975712776184082
Epoch 243  Train loss: -2.764623436273313  Val loss: -2.955744805614563
Epoch 244
-------------------------------
Batch 1/64 loss: -2.559401512145996
Batch 2/64 loss: -2.7707529067993164
Batch 3/64 loss: -2.8833112716674805
Batch 4/64 loss: -2.567013740539551
Batch 5/64 loss: -2.519298553466797
Batch 6/64 loss: -2.9711971282958984
Batch 7/64 loss: -2.4574928283691406
Batch 8/64 loss: -2.9364213943481445
Batch 9/64 loss: -2.9537487030029297
Batch 10/64 loss: -2.599834442138672
Batch 11/64 loss: -2.019268035888672
Batch 12/64 loss: -2.5584487915039062
Batch 13/64 loss: -2.8502283096313477
Batch 14/64 loss: -2.4251632690429688
Batch 15/64 loss: -2.714278221130371
Batch 16/64 loss: -2.7430524826049805
Batch 17/64 loss: -2.906313896179199
Batch 18/64 loss: -2.641556739807129
Batch 19/64 loss: -2.5062856674194336
Batch 20/64 loss: -2.728696823120117
Batch 21/64 loss: -2.8797178268432617
Batch 22/64 loss: -3.0062170028686523
Batch 23/64 loss: -2.8312196731567383
Batch 24/64 loss: -2.7285470962524414
Batch 25/64 loss: -2.7535343170166016
Batch 26/64 loss: -2.733196258544922
Batch 27/64 loss: -2.834970474243164
Batch 28/64 loss: -2.6935606002807617
Batch 29/64 loss: -2.4951305389404297
Batch 30/64 loss: -3.0068836212158203
Batch 31/64 loss: -2.976408004760742
Batch 32/64 loss: -2.84352970123291
Batch 33/64 loss: -2.9162368774414062
Batch 34/64 loss: -2.786785125732422
Batch 35/64 loss: -2.85105037689209
Batch 36/64 loss: -2.7123374938964844
Batch 37/64 loss: -2.769540786743164
Batch 38/64 loss: -2.6262712478637695
Batch 39/64 loss: -2.7783737182617188
Batch 40/64 loss: -2.8788557052612305
Batch 41/64 loss: -2.7902164459228516
Batch 42/64 loss: -2.086113929748535
Batch 43/64 loss: -2.521235466003418
Batch 44/64 loss: -2.642833709716797
Batch 45/64 loss: -2.864727020263672
Batch 46/64 loss: -2.958393096923828
Batch 47/64 loss: -2.7770633697509766
Batch 48/64 loss: -2.922133445739746
Batch 49/64 loss: -2.6223068237304688
Batch 50/64 loss: -2.4940261840820312
Batch 51/64 loss: -2.707284927368164
Batch 52/64 loss: -3.0135326385498047
Batch 53/64 loss: -2.7233190536499023
Batch 54/64 loss: -2.468423843383789
Batch 55/64 loss: -2.888434410095215
Batch 56/64 loss: -2.9473915100097656
Batch 57/64 loss: -2.747434616088867
Batch 58/64 loss: -2.820384979248047
Batch 59/64 loss: -2.51202392578125
Batch 60/64 loss: -2.8004961013793945
Batch 61/64 loss: -2.536745071411133
Batch 62/64 loss: -2.8262577056884766
Batch 63/64 loss: -2.602541923522949
Batch 64/64 loss: -7.273279190063477
Epoch 244  Train loss: -2.7787044824338425  Val loss: -2.9823200186503303
Epoch 245
-------------------------------
Batch 1/64 loss: -2.7778854370117188
Batch 2/64 loss: -2.657001495361328
Batch 3/64 loss: -2.9369354248046875
Batch 4/64 loss: -2.864274024963379
Batch 5/64 loss: -2.6469507217407227
Batch 6/64 loss: -2.5532360076904297
Batch 7/64 loss: -2.856557846069336
Batch 8/64 loss: -2.605213165283203
Batch 9/64 loss: -2.797292709350586
Batch 10/64 loss: -2.93796443939209
Batch 11/64 loss: -2.8673200607299805
Batch 12/64 loss: -2.698723793029785
Batch 13/64 loss: -2.445704460144043
Batch 14/64 loss: -2.5456857681274414
Batch 15/64 loss: -2.7567672729492188
Batch 16/64 loss: -2.9087343215942383
Batch 17/64 loss: -2.548081398010254
Batch 18/64 loss: -2.393404960632324
Batch 19/64 loss: -2.9340362548828125
Batch 20/64 loss: -2.831418991088867
Batch 21/64 loss: -2.9226226806640625
Batch 22/64 loss: -2.8052167892456055
Batch 23/64 loss: -2.680699348449707
Batch 24/64 loss: -2.6515674591064453
Batch 25/64 loss: -2.8540592193603516
Batch 26/64 loss: -2.7937326431274414
Batch 27/64 loss: -2.806086540222168
Batch 28/64 loss: -2.685408592224121
Batch 29/64 loss: -2.9625492095947266
Batch 30/64 loss: -2.753145217895508
Batch 31/64 loss: -2.68387508392334
Batch 32/64 loss: -2.934515953063965
Batch 33/64 loss: -2.867013931274414
Batch 34/64 loss: -2.6765079498291016
Batch 35/64 loss: -2.805154800415039
Batch 36/64 loss: -2.5856761932373047
Batch 37/64 loss: -2.6501598358154297
Batch 38/64 loss: -2.7117156982421875
Batch 39/64 loss: -2.751758575439453
Batch 40/64 loss: -2.7539825439453125
Batch 41/64 loss: -2.9371337890625
Batch 42/64 loss: -2.5648183822631836
Batch 43/64 loss: -2.808748245239258
Batch 44/64 loss: -2.8143529891967773
Batch 45/64 loss: -2.8949899673461914
Batch 46/64 loss: -2.8372325897216797
Batch 47/64 loss: -2.7968873977661133
Batch 48/64 loss: -2.704390525817871
Batch 49/64 loss: -2.0480527877807617
Batch 50/64 loss: -2.802046775817871
Batch 51/64 loss: -2.551669120788574
Batch 52/64 loss: -2.4515380859375
Batch 53/64 loss: -2.5180206298828125
Batch 54/64 loss: -2.3916711807250977
Batch 55/64 loss: -2.724966049194336
Batch 56/64 loss: -2.660329818725586
Batch 57/64 loss: -2.679623603820801
Batch 58/64 loss: -2.804912567138672
Batch 59/64 loss: -2.7412586212158203
Batch 60/64 loss: -2.781766891479492
Batch 61/64 loss: -2.7721710205078125
Batch 62/64 loss: -2.7940359115600586
Batch 63/64 loss: -2.5244617462158203
Batch 64/64 loss: -7.27763557434082
Epoch 245  Train loss: -2.775873603072821  Val loss: -2.8401026512749006
Epoch 246
-------------------------------
Batch 1/64 loss: -2.902440071105957
Batch 2/64 loss: -2.19362735748291
Batch 3/64 loss: -2.680140495300293
Batch 4/64 loss: -2.6978893280029297
Batch 5/64 loss: -2.727245330810547
Batch 6/64 loss: -2.268033027648926
Batch 7/64 loss: -2.5454788208007812
Batch 8/64 loss: -2.3776092529296875
Batch 9/64 loss: -2.7619705200195312
Batch 10/64 loss: -2.5623960494995117
Batch 11/64 loss: -2.6177120208740234
Batch 12/64 loss: -2.5637340545654297
Batch 13/64 loss: -2.8818464279174805
Batch 14/64 loss: -2.5746641159057617
Batch 15/64 loss: -2.8031301498413086
Batch 16/64 loss: -2.6976451873779297
Batch 17/64 loss: -2.60845947265625
Batch 18/64 loss: -0.44954681396484375
Batch 19/64 loss: -2.9586868286132812
Batch 20/64 loss: -2.7794103622436523
Batch 21/64 loss: -2.990420341491699
Batch 22/64 loss: -2.9090728759765625
Batch 23/64 loss: -2.774385452270508
Batch 24/64 loss: -2.7341623306274414
Batch 25/64 loss: -2.512228012084961
Batch 26/64 loss: -2.8553009033203125
Batch 27/64 loss: -2.6916027069091797
Batch 28/64 loss: -2.1144113540649414
Batch 29/64 loss: -2.5906143188476562
Batch 30/64 loss: -2.489090919494629
Batch 31/64 loss: -2.8026723861694336
Batch 32/64 loss: -2.7230138778686523
Batch 33/64 loss: -2.3260498046875
Batch 34/64 loss: -2.1672983169555664
Batch 35/64 loss: -2.6668291091918945
Batch 36/64 loss: -2.4117050170898438
Batch 37/64 loss: -2.8403844833374023
Batch 38/64 loss: -2.9190406799316406
Batch 39/64 loss: -2.355976104736328
Batch 40/64 loss: -2.891653060913086
Batch 41/64 loss: -2.734649658203125
Batch 42/64 loss: -2.747110366821289
Batch 43/64 loss: -2.857468605041504
Batch 44/64 loss: -2.588970184326172
Batch 45/64 loss: -2.7385406494140625
Batch 46/64 loss: -2.944491386413574
Batch 47/64 loss: -2.9247398376464844
Batch 48/64 loss: -2.9047441482543945
Batch 49/64 loss: -2.6134862899780273
Batch 50/64 loss: -2.794215202331543
Batch 51/64 loss: -2.5642623901367188
Batch 52/64 loss: -2.631333351135254
Batch 53/64 loss: -2.7566843032836914
Batch 54/64 loss: -2.6981725692749023
Batch 55/64 loss: -2.547600746154785
Batch 56/64 loss: -2.6317577362060547
Batch 57/64 loss: -2.6121864318847656
Batch 58/64 loss: -2.6446056365966797
Batch 59/64 loss: -2.643871307373047
Batch 60/64 loss: -2.88228702545166
Batch 61/64 loss: -2.840444564819336
Batch 62/64 loss: -2.428717613220215
Batch 63/64 loss: -2.6411123275756836
Batch 64/64 loss: -7.031125068664551
Epoch 246  Train loss: -2.6833313549266142  Val loss: -2.946238501375074
Epoch 247
-------------------------------
Batch 1/64 loss: -2.7652244567871094
Batch 2/64 loss: -2.60629940032959
Batch 3/64 loss: -2.3766965866088867
Batch 4/64 loss: -2.7850847244262695
Batch 5/64 loss: -2.7603626251220703
Batch 6/64 loss: -2.771657943725586
Batch 7/64 loss: -2.2511281967163086
Batch 8/64 loss: -2.5611562728881836
Batch 9/64 loss: -2.718499183654785
Batch 10/64 loss: -2.5017337799072266
Batch 11/64 loss: -2.64017391204834
Batch 12/64 loss: -2.7794551849365234
Batch 13/64 loss: -2.8140268325805664
Batch 14/64 loss: -2.8495235443115234
Batch 15/64 loss: -2.7433090209960938
Batch 16/64 loss: -2.6621761322021484
Batch 17/64 loss: -2.5220937728881836
Batch 18/64 loss: -2.6255788803100586
Batch 19/64 loss: -2.934811592102051
Batch 20/64 loss: -2.7236852645874023
Batch 21/64 loss: -2.591425895690918
Batch 22/64 loss: -2.5906753540039062
Batch 23/64 loss: -2.898036003112793
Batch 24/64 loss: -2.2119369506835938
Batch 25/64 loss: -2.7087087631225586
Batch 26/64 loss: -2.8624277114868164
Batch 27/64 loss: -2.8870439529418945
Batch 28/64 loss: -2.838841438293457
Batch 29/64 loss: -2.740260124206543
Batch 30/64 loss: -2.7451276779174805
Batch 31/64 loss: -2.74405574798584
Batch 32/64 loss: -2.2009029388427734
Batch 33/64 loss: -2.937620162963867
Batch 34/64 loss: -2.782451629638672
Batch 35/64 loss: -3.029982566833496
Batch 36/64 loss: -2.804476737976074
Batch 37/64 loss: -2.3570032119750977
Batch 38/64 loss: -2.52852725982666
Batch 39/64 loss: -2.4915103912353516
Batch 40/64 loss: -2.579892158508301
Batch 41/64 loss: -2.8500165939331055
Batch 42/64 loss: -2.7710580825805664
Batch 43/64 loss: -2.923185348510742
Batch 44/64 loss: -2.906785011291504
Batch 45/64 loss: -2.9015884399414062
Batch 46/64 loss: -2.538405418395996
Batch 47/64 loss: -2.973809242248535
Batch 48/64 loss: -2.9061355590820312
Batch 49/64 loss: -2.2791290283203125
Batch 50/64 loss: -2.4578332901000977
Batch 51/64 loss: -2.2383899688720703
Batch 52/64 loss: -3.1348886489868164
Batch 53/64 loss: -2.8298397064208984
Batch 54/64 loss: -2.7887210845947266
Batch 55/64 loss: -2.3386621475219727
Batch 56/64 loss: -2.69882869720459
Batch 57/64 loss: -2.7597856521606445
Batch 58/64 loss: -2.8296823501586914
Batch 59/64 loss: -2.586489677429199
Batch 60/64 loss: -2.607166290283203
Batch 61/64 loss: -3.072890281677246
Batch 62/64 loss: -2.418947219848633
Batch 63/64 loss: -2.683929443359375
Batch 64/64 loss: -7.250744342803955
Epoch 247  Train loss: -2.7428675988141227  Val loss: -2.938352604502255
Epoch 248
-------------------------------
Batch 1/64 loss: -2.803280830383301
Batch 2/64 loss: -2.9112281799316406
Batch 3/64 loss: -2.431309700012207
Batch 4/64 loss: -2.7177467346191406
Batch 5/64 loss: -2.3902854919433594
Batch 6/64 loss: -2.7058591842651367
Batch 7/64 loss: -2.7589330673217773
Batch 8/64 loss: -2.918193817138672
Batch 9/64 loss: -2.6402111053466797
Batch 10/64 loss: -2.1366615295410156
Batch 11/64 loss: -2.566451072692871
Batch 12/64 loss: -2.9200210571289062
Batch 13/64 loss: -2.739828109741211
Batch 14/64 loss: -2.5083723068237305
Batch 15/64 loss: -2.727121353149414
Batch 16/64 loss: -2.8813705444335938
Batch 17/64 loss: -2.8110809326171875
Batch 18/64 loss: -2.858138084411621
Batch 19/64 loss: -2.903493881225586
Batch 20/64 loss: -2.88541316986084
Batch 21/64 loss: -2.7719783782958984
Batch 22/64 loss: -2.936844825744629
Batch 23/64 loss: -2.4875125885009766
Batch 24/64 loss: -2.702239990234375
Batch 25/64 loss: -2.800686836242676
Batch 26/64 loss: -2.6559925079345703
Batch 27/64 loss: -2.740147590637207
Batch 28/64 loss: -2.640753746032715
Batch 29/64 loss: -2.995724678039551
Batch 30/64 loss: -2.655411720275879
Batch 31/64 loss: -2.424626350402832
Batch 32/64 loss: -2.932933807373047
Batch 33/64 loss: -2.8485450744628906
Batch 34/64 loss: -2.9031620025634766
Batch 35/64 loss: -2.7487316131591797
Batch 36/64 loss: -2.7057857513427734
Batch 37/64 loss: -2.6587581634521484
Batch 38/64 loss: -2.8080625534057617
Batch 39/64 loss: -2.7418088912963867
Batch 40/64 loss: -2.910567283630371
Batch 41/64 loss: -2.621859550476074
Batch 42/64 loss: -2.795337677001953
Batch 43/64 loss: -2.6825780868530273
Batch 44/64 loss: -2.557093620300293
Batch 45/64 loss: -2.4902219772338867
Batch 46/64 loss: -2.66525936126709
Batch 47/64 loss: -2.689861297607422
Batch 48/64 loss: -2.672041893005371
Batch 49/64 loss: -2.6422042846679688
Batch 50/64 loss: -2.8746299743652344
Batch 51/64 loss: -2.977410316467285
Batch 52/64 loss: -2.627971649169922
Batch 53/64 loss: -2.8471736907958984
Batch 54/64 loss: -2.7688140869140625
Batch 55/64 loss: -2.7561864852905273
Batch 56/64 loss: -2.634139060974121
Batch 57/64 loss: -2.5276803970336914
Batch 58/64 loss: -2.8988285064697266
Batch 59/64 loss: -2.4747705459594727
Batch 60/64 loss: -2.964137077331543
Batch 61/64 loss: -2.5243749618530273
Batch 62/64 loss: -2.771512031555176
Batch 63/64 loss: -2.856839179992676
Batch 64/64 loss: -7.4534220695495605
Epoch 248  Train loss: -2.7795492826723587  Val loss: -2.9471563752164545
Epoch 249
-------------------------------
Batch 1/64 loss: -2.91117000579834
Batch 2/64 loss: -2.573845863342285
Batch 3/64 loss: -2.5171804428100586
Batch 4/64 loss: -2.7886476516723633
Batch 5/64 loss: -2.650503158569336
Batch 6/64 loss: -2.8021812438964844
Batch 7/64 loss: -2.85526180267334
Batch 8/64 loss: -2.697681427001953
Batch 9/64 loss: -2.702404022216797
Batch 10/64 loss: -2.7904396057128906
Batch 11/64 loss: -2.7640228271484375
Batch 12/64 loss: -2.5745792388916016
Batch 13/64 loss: -2.8381099700927734
Batch 14/64 loss: -2.9048776626586914
Batch 15/64 loss: -2.6738710403442383
Batch 16/64 loss: -2.706610679626465
Batch 17/64 loss: -2.8913698196411133
Batch 18/64 loss: -2.9855127334594727
Batch 19/64 loss: -2.736199378967285
Batch 20/64 loss: -2.7381744384765625
Batch 21/64 loss: -2.957066535949707
Batch 22/64 loss: -2.597217559814453
Batch 23/64 loss: -2.7244653701782227
Batch 24/64 loss: -2.9833240509033203
Batch 25/64 loss: -2.650663375854492
Batch 26/64 loss: -2.8630380630493164
Batch 27/64 loss: -2.9795074462890625
Batch 28/64 loss: -2.564394950866699
Batch 29/64 loss: -2.5293655395507812
Batch 30/64 loss: -2.65493106842041
Batch 31/64 loss: -3.0830793380737305
Batch 32/64 loss: -2.8863983154296875
Batch 33/64 loss: -2.6870336532592773
Batch 34/64 loss: -2.720952033996582
Batch 35/64 loss: -2.8488073348999023
Batch 36/64 loss: -2.8103933334350586
Batch 37/64 loss: -2.7370214462280273
Batch 38/64 loss: -2.859933853149414
Batch 39/64 loss: -2.5352182388305664
Batch 40/64 loss: -2.8036699295043945
Batch 41/64 loss: -2.508481979370117
Batch 42/64 loss: -2.8709726333618164
Batch 43/64 loss: -2.767327308654785
Batch 44/64 loss: -2.838780403137207
Batch 45/64 loss: -2.5754547119140625
Batch 46/64 loss: -2.7983856201171875
Batch 47/64 loss: -2.6692028045654297
Batch 48/64 loss: -2.5952558517456055
Batch 49/64 loss: -2.8236169815063477
Batch 50/64 loss: -2.4849958419799805
Batch 51/64 loss: -2.8081836700439453
Batch 52/64 loss: -2.7082719802856445
Batch 53/64 loss: -2.779252052307129
Batch 54/64 loss: -2.6738014221191406
Batch 55/64 loss: -2.6834964752197266
Batch 56/64 loss: -2.582047462463379
Batch 57/64 loss: -2.7371091842651367
Batch 58/64 loss: -1.8732109069824219
Batch 59/64 loss: -2.593440055847168
Batch 60/64 loss: -2.8482656478881836
Batch 61/64 loss: -2.8694324493408203
Batch 62/64 loss: -2.5389156341552734
Batch 63/64 loss: -2.352189064025879
Batch 64/64 loss: -7.0937418937683105
Epoch 249  Train loss: -2.7745807217616663  Val loss: -2.974640495588689
Epoch 250
-------------------------------
Batch 1/64 loss: -2.662825584411621
Batch 2/64 loss: -2.629960060119629
Batch 3/64 loss: -2.9838695526123047
Batch 4/64 loss: -2.917447090148926
Batch 5/64 loss: -2.6274948120117188
Batch 6/64 loss: -2.8060665130615234
Batch 7/64 loss: -2.822079658508301
Batch 8/64 loss: -2.718874931335449
Batch 9/64 loss: -2.5799646377563477
Batch 10/64 loss: -2.472532272338867
Batch 11/64 loss: -2.6205358505249023
Batch 12/64 loss: -2.9801530838012695
Batch 13/64 loss: -2.7709951400756836
Batch 14/64 loss: -2.8909645080566406
Batch 15/64 loss: -2.9352922439575195
Batch 16/64 loss: -2.85208797454834
Batch 17/64 loss: -2.9447994232177734
Batch 18/64 loss: -2.64095401763916
Batch 19/64 loss: -2.834549903869629
Batch 20/64 loss: -2.813015937805176
Batch 21/64 loss: -2.7728824615478516
Batch 22/64 loss: -2.932188034057617
Batch 23/64 loss: -2.914165496826172
Batch 24/64 loss: -2.78411865234375
Batch 25/64 loss: -2.5740394592285156
Batch 26/64 loss: -2.583089828491211
Batch 27/64 loss: -2.52099609375
Batch 28/64 loss: -2.4980621337890625
Batch 29/64 loss: -2.631566047668457
Batch 30/64 loss: -2.7681503295898438
Batch 31/64 loss: -2.1783628463745117
Batch 32/64 loss: -2.598944664001465
Batch 33/64 loss: -2.6566715240478516
Batch 34/64 loss: -2.825815200805664
Batch 35/64 loss: -2.8734073638916016
Batch 36/64 loss: -2.6940736770629883
Batch 37/64 loss: -2.703127861022949
Batch 38/64 loss: -2.889423370361328
Batch 39/64 loss: -2.2541685104370117
Batch 40/64 loss: -2.7477426528930664
Batch 41/64 loss: -2.8617992401123047
Batch 42/64 loss: -2.9343013763427734
Batch 43/64 loss: -2.4347667694091797
Batch 44/64 loss: -2.7645740509033203
Batch 45/64 loss: -2.8846044540405273
Batch 46/64 loss: -2.774317741394043
Batch 47/64 loss: -2.834196090698242
Batch 48/64 loss: -2.8798904418945312
Batch 49/64 loss: -2.759524345397949
Batch 50/64 loss: -2.7581024169921875
Batch 51/64 loss: -2.5688228607177734
Batch 52/64 loss: -2.8059167861938477
Batch 53/64 loss: -2.7323551177978516
Batch 54/64 loss: -2.4056406021118164
Batch 55/64 loss: -2.985879898071289
Batch 56/64 loss: -2.8277931213378906
Batch 57/64 loss: -2.4911680221557617
Batch 58/64 loss: -2.7783384323120117
Batch 59/64 loss: -2.769730567932129
Batch 60/64 loss: -2.962421417236328
Batch 61/64 loss: -2.731534004211426
Batch 62/64 loss: -2.7559776306152344
Batch 63/64 loss: -2.7988758087158203
Batch 64/64 loss: -6.886709213256836
Epoch 250  Train loss: -2.7854278040867224  Val loss: -2.9906330698544217
Epoch 251
-------------------------------
Batch 1/64 loss: -2.677398681640625
Batch 2/64 loss: -2.783693313598633
Batch 3/64 loss: -2.682832717895508
Batch 4/64 loss: -2.8148183822631836
Batch 5/64 loss: -2.610781669616699
Batch 6/64 loss: -2.658458709716797
Batch 7/64 loss: -2.79648494720459
Batch 8/64 loss: -2.9075565338134766
Batch 9/64 loss: -2.8798837661743164
Batch 10/64 loss: -2.4994945526123047
Batch 11/64 loss: -2.9476680755615234
Batch 12/64 loss: -2.5986499786376953
Batch 13/64 loss: -2.8922080993652344
Batch 14/64 loss: -2.750460624694824
Batch 15/64 loss: -2.9613542556762695
Batch 16/64 loss: -2.823685646057129
Batch 17/64 loss: -2.8384132385253906
Batch 18/64 loss: -2.9325742721557617
Batch 19/64 loss: -2.684657096862793
Batch 20/64 loss: -2.852950096130371
Batch 21/64 loss: -2.6128664016723633
Batch 22/64 loss: -2.780276298522949
Batch 23/64 loss: -2.6020278930664062
Batch 24/64 loss: -2.612339973449707
Batch 25/64 loss: -2.6086320877075195
Batch 26/64 loss: -2.7065277099609375
Batch 27/64 loss: -2.5909318923950195
Batch 28/64 loss: -2.8563108444213867
Batch 29/64 loss: -2.385317802429199
Batch 30/64 loss: -2.580953598022461
Batch 31/64 loss: -2.977789878845215
Batch 32/64 loss: -2.1983556747436523
Batch 33/64 loss: -2.844729423522949
Batch 34/64 loss: -2.6841278076171875
Batch 35/64 loss: -2.9455881118774414
Batch 36/64 loss: -2.8972558975219727
Batch 37/64 loss: -2.679368019104004
Batch 38/64 loss: -2.861454963684082
Batch 39/64 loss: -2.4470481872558594
Batch 40/64 loss: -2.582681655883789
Batch 41/64 loss: -2.601107597351074
Batch 42/64 loss: -2.7838315963745117
Batch 43/64 loss: -2.3045482635498047
Batch 44/64 loss: -3.0005884170532227
Batch 45/64 loss: -2.406357765197754
Batch 46/64 loss: -2.5728225708007812
Batch 47/64 loss: -2.8320446014404297
Batch 48/64 loss: -2.405531883239746
Batch 49/64 loss: -2.8624868392944336
Batch 50/64 loss: -2.598647117614746
Batch 51/64 loss: -2.882657051086426
Batch 52/64 loss: -2.655599594116211
Batch 53/64 loss: -2.850587844848633
Batch 54/64 loss: -2.720444679260254
Batch 55/64 loss: -2.652907371520996
Batch 56/64 loss: -2.899171829223633
Batch 57/64 loss: -2.984532356262207
Batch 58/64 loss: -2.631932258605957
Batch 59/64 loss: -2.667490005493164
Batch 60/64 loss: -2.749530792236328
Batch 61/64 loss: -2.465991973876953
Batch 62/64 loss: -2.7406797409057617
Batch 63/64 loss: -2.847951889038086
Batch 64/64 loss: -7.347163200378418
Epoch 251  Train loss: -2.771394905389524  Val loss: -3.0110606295136653
Epoch 252
-------------------------------
Batch 1/64 loss: -2.4835281372070312
Batch 2/64 loss: -2.9433937072753906
Batch 3/64 loss: -2.6520910263061523
Batch 4/64 loss: -2.769717216491699
Batch 5/64 loss: -2.769669532775879
Batch 6/64 loss: -2.8054943084716797
Batch 7/64 loss: -2.8371458053588867
Batch 8/64 loss: -2.804104804992676
Batch 9/64 loss: -2.975661277770996
Batch 10/64 loss: -2.8913917541503906
Batch 11/64 loss: -2.9844131469726562
Batch 12/64 loss: -2.8660736083984375
Batch 13/64 loss: -2.7842769622802734
Batch 14/64 loss: -2.637478828430176
Batch 15/64 loss: -2.9023056030273438
Batch 16/64 loss: -2.5077085494995117
Batch 17/64 loss: -2.9281625747680664
Batch 18/64 loss: -2.6661624908447266
Batch 19/64 loss: -2.646185874938965
Batch 20/64 loss: -2.683333396911621
Batch 21/64 loss: -2.630594253540039
Batch 22/64 loss: -2.8295888900756836
Batch 23/64 loss: -2.6025800704956055
Batch 24/64 loss: -2.851083755493164
Batch 25/64 loss: -2.8140430450439453
Batch 26/64 loss: -3.1318960189819336
Batch 27/64 loss: -2.7378177642822266
Batch 28/64 loss: -2.331493377685547
Batch 29/64 loss: -2.8345632553100586
Batch 30/64 loss: -2.80800724029541
Batch 31/64 loss: -2.930668830871582
Batch 32/64 loss: -2.610647201538086
Batch 33/64 loss: -2.883517265319824
Batch 34/64 loss: -2.9130563735961914
Batch 35/64 loss: -2.5449037551879883
Batch 36/64 loss: -2.7364044189453125
Batch 37/64 loss: -2.847494125366211
Batch 38/64 loss: -2.7358903884887695
Batch 39/64 loss: -2.687167167663574
Batch 40/64 loss: -2.549997329711914
Batch 41/64 loss: -2.906156539916992
Batch 42/64 loss: -2.6228113174438477
Batch 43/64 loss: -2.927178382873535
Batch 44/64 loss: -2.7934112548828125
Batch 45/64 loss: -2.755852699279785
Batch 46/64 loss: -2.7841901779174805
Batch 47/64 loss: -2.667024612426758
Batch 48/64 loss: -2.8293333053588867
Batch 49/64 loss: -2.7910404205322266
Batch 50/64 loss: -2.462531089782715
Batch 51/64 loss: -2.82611083984375
Batch 52/64 loss: -3.016627311706543
Batch 53/64 loss: -2.685586929321289
Batch 54/64 loss: -2.79360294342041
Batch 55/64 loss: -2.7311010360717773
Batch 56/64 loss: -2.30120849609375
Batch 57/64 loss: -2.7326440811157227
Batch 58/64 loss: -2.7241649627685547
Batch 59/64 loss: -2.739530563354492
Batch 60/64 loss: -2.728470802307129
Batch 61/64 loss: -2.919567108154297
Batch 62/64 loss: -2.4814491271972656
Batch 63/64 loss: -2.8196420669555664
Batch 64/64 loss: -7.55222225189209
Epoch 252  Train loss: -2.8118135826260438  Val loss: -2.991225711258826
Epoch 253
-------------------------------
Batch 1/64 loss: -2.9681406021118164
Batch 2/64 loss: -3.041219711303711
Batch 3/64 loss: -2.576939582824707
Batch 4/64 loss: -2.9274539947509766
Batch 5/64 loss: -2.772439956665039
Batch 6/64 loss: -2.559795379638672
Batch 7/64 loss: -2.658651351928711
Batch 8/64 loss: -2.607036590576172
Batch 9/64 loss: -3.004448890686035
Batch 10/64 loss: -2.7361764907836914
Batch 11/64 loss: -2.7530975341796875
Batch 12/64 loss: -2.7041501998901367
Batch 13/64 loss: -2.534273147583008
Batch 14/64 loss: -2.858628273010254
Batch 15/64 loss: -2.6248722076416016
Batch 16/64 loss: -2.770859718322754
Batch 17/64 loss: -2.6864376068115234
Batch 18/64 loss: -2.7951478958129883
Batch 19/64 loss: -2.66082763671875
Batch 20/64 loss: -2.782115936279297
Batch 21/64 loss: -2.9136581420898438
Batch 22/64 loss: -2.8966569900512695
Batch 23/64 loss: -2.864993095397949
Batch 24/64 loss: -2.834857940673828
Batch 25/64 loss: -2.601273536682129
Batch 26/64 loss: -2.4512815475463867
Batch 27/64 loss: -2.9010744094848633
Batch 28/64 loss: -2.7953433990478516
Batch 29/64 loss: -2.893885612487793
Batch 30/64 loss: -2.679140090942383
Batch 31/64 loss: -2.860548973083496
Batch 32/64 loss: -2.78507137298584
Batch 33/64 loss: -2.8898496627807617
Batch 34/64 loss: -2.9327573776245117
Batch 35/64 loss: -2.5704994201660156
Batch 36/64 loss: -2.466456413269043
Batch 37/64 loss: -2.7806901931762695
Batch 38/64 loss: -2.59206485748291
Batch 39/64 loss: -2.8717613220214844
Batch 40/64 loss: -2.8312454223632812
Batch 41/64 loss: -2.8782596588134766
Batch 42/64 loss: -2.909334182739258
Batch 43/64 loss: -2.7618255615234375
Batch 44/64 loss: -2.665989875793457
Batch 45/64 loss: -2.5017032623291016
Batch 46/64 loss: -2.822296142578125
Batch 47/64 loss: -2.8413333892822266
Batch 48/64 loss: -2.869495391845703
Batch 49/64 loss: -2.746678352355957
Batch 50/64 loss: -2.7933359146118164
Batch 51/64 loss: -2.4751768112182617
Batch 52/64 loss: -2.9282636642456055
Batch 53/64 loss: -2.791229248046875
Batch 54/64 loss: -2.973097801208496
Batch 55/64 loss: -2.3145904541015625
Batch 56/64 loss: -2.7336435317993164
Batch 57/64 loss: -2.59438419342041
Batch 58/64 loss: -2.7279510498046875
Batch 59/64 loss: -2.9083080291748047
Batch 60/64 loss: -2.93569278717041
Batch 61/64 loss: -2.808293342590332
Batch 62/64 loss: -2.8159284591674805
Batch 63/64 loss: -2.7177066802978516
Batch 64/64 loss: -7.0906662940979
Epoch 253  Train loss: -2.81205239202462  Val loss: -2.960491442598428
Epoch 254
-------------------------------
Batch 1/64 loss: -3.1042861938476562
Batch 2/64 loss: -2.8860645294189453
Batch 3/64 loss: -2.806224822998047
Batch 4/64 loss: -2.910961151123047
Batch 5/64 loss: -2.6950531005859375
Batch 6/64 loss: -2.1340255737304688
Batch 7/64 loss: -2.9078245162963867
Batch 8/64 loss: -2.741847038269043
Batch 9/64 loss: -2.938016891479492
Batch 10/64 loss: -2.872701644897461
Batch 11/64 loss: -2.84328556060791
Batch 12/64 loss: -2.662649154663086
Batch 13/64 loss: -2.714959144592285
Batch 14/64 loss: -2.869025230407715
Batch 15/64 loss: -2.6760644912719727
Batch 16/64 loss: -2.736849784851074
Batch 17/64 loss: -2.883784294128418
Batch 18/64 loss: -2.7061328887939453
Batch 19/64 loss: -2.5637969970703125
Batch 20/64 loss: -2.637592315673828
Batch 21/64 loss: -2.7097835540771484
Batch 22/64 loss: -2.8189239501953125
Batch 23/64 loss: -2.4836483001708984
Batch 24/64 loss: -2.763363838195801
Batch 25/64 loss: -2.9190311431884766
Batch 26/64 loss: -2.9729719161987305
Batch 27/64 loss: -2.658360481262207
Batch 28/64 loss: -2.9795846939086914
Batch 29/64 loss: -2.8571882247924805
Batch 30/64 loss: -2.1239700317382812
Batch 31/64 loss: -2.7973508834838867
Batch 32/64 loss: -2.6791038513183594
Batch 33/64 loss: -2.9568519592285156
Batch 34/64 loss: -2.810126304626465
Batch 35/64 loss: -2.8183584213256836
Batch 36/64 loss: -2.9406585693359375
Batch 37/64 loss: -2.823995590209961
Batch 38/64 loss: -2.958348274230957
Batch 39/64 loss: -2.866997718811035
Batch 40/64 loss: -2.776395797729492
Batch 41/64 loss: -2.9206085205078125
Batch 42/64 loss: -2.7861499786376953
Batch 43/64 loss: -2.9414167404174805
Batch 44/64 loss: -2.552945137023926
Batch 45/64 loss: -2.7275218963623047
Batch 46/64 loss: -2.3576745986938477
Batch 47/64 loss: -2.409337043762207
Batch 48/64 loss: -2.6956233978271484
Batch 49/64 loss: -2.705754280090332
Batch 50/64 loss: -2.7590742111206055
Batch 51/64 loss: -2.6981639862060547
Batch 52/64 loss: -2.498000144958496
Batch 53/64 loss: -2.7376909255981445
Batch 54/64 loss: -2.985367774963379
Batch 55/64 loss: -2.8863754272460938
Batch 56/64 loss: -2.7026405334472656
Batch 57/64 loss: -2.711737632751465
Batch 58/64 loss: -2.9128170013427734
Batch 59/64 loss: -2.7839555740356445
Batch 60/64 loss: -2.7571706771850586
Batch 61/64 loss: -2.5344924926757812
Batch 62/64 loss: -2.8822078704833984
Batch 63/64 loss: -2.8407278060913086
Batch 64/64 loss: -6.790225982666016
Epoch 254  Train loss: -2.806059324975107  Val loss: -3.0146029102023935
Epoch 255
-------------------------------
Batch 1/64 loss: -2.6417160034179688
Batch 2/64 loss: -2.714322090148926
Batch 3/64 loss: -2.9871158599853516
Batch 4/64 loss: -2.261514663696289
Batch 5/64 loss: -2.3538589477539062
Batch 6/64 loss: -2.8426074981689453
Batch 7/64 loss: -2.9408159255981445
Batch 8/64 loss: -2.9167585372924805
Batch 9/64 loss: -2.9066238403320312
Batch 10/64 loss: -2.9120397567749023
Batch 11/64 loss: -2.840970993041992
Batch 12/64 loss: -2.786534309387207
Batch 13/64 loss: -2.806241989135742
Batch 14/64 loss: -2.8725786209106445
Batch 15/64 loss: -2.7548465728759766
Batch 16/64 loss: -2.9610471725463867
Batch 17/64 loss: -3.085847854614258
Batch 18/64 loss: -3.010573387145996
Batch 19/64 loss: -2.8689651489257812
Batch 20/64 loss: -2.853710174560547
Batch 21/64 loss: -2.9591856002807617
Batch 22/64 loss: -2.846573829650879
Batch 23/64 loss: -2.8202123641967773
Batch 24/64 loss: -2.753652572631836
Batch 25/64 loss: -2.805935859680176
Batch 26/64 loss: -2.530764579772949
Batch 27/64 loss: -2.878915786743164
Batch 28/64 loss: -2.967212677001953
Batch 29/64 loss: -2.6061220169067383
Batch 30/64 loss: -2.4780540466308594
Batch 31/64 loss: -2.219881057739258
Batch 32/64 loss: -2.495791435241699
Batch 33/64 loss: -2.587064743041992
Batch 34/64 loss: -2.7879533767700195
Batch 35/64 loss: -2.750168800354004
Batch 36/64 loss: -2.9948930740356445
Batch 37/64 loss: -2.8238162994384766
Batch 38/64 loss: -2.809659004211426
Batch 39/64 loss: -2.97623348236084
Batch 40/64 loss: -2.707341194152832
Batch 41/64 loss: -2.421706199645996
Batch 42/64 loss: -2.6307058334350586
Batch 43/64 loss: -2.622753143310547
Batch 44/64 loss: -2.6554155349731445
Batch 45/64 loss: -2.4555139541625977
Batch 46/64 loss: -2.758822441101074
Batch 47/64 loss: -2.7695960998535156
Batch 48/64 loss: -2.6558570861816406
Batch 49/64 loss: -2.938465118408203
Batch 50/64 loss: -2.7091760635375977
Batch 51/64 loss: -2.8697710037231445
Batch 52/64 loss: -3.0242176055908203
Batch 53/64 loss: -2.7036123275756836
Batch 54/64 loss: -3.0697498321533203
Batch 55/64 loss: -2.740086555480957
Batch 56/64 loss: -2.9735422134399414
Batch 57/64 loss: -2.561206817626953
Batch 58/64 loss: -2.9185638427734375
Batch 59/64 loss: -2.4875736236572266
Batch 60/64 loss: -2.534237861633301
Batch 61/64 loss: -3.147024154663086
Batch 62/64 loss: -2.8708810806274414
Batch 63/64 loss: -2.8323278427124023
Batch 64/64 loss: -7.463010787963867
Epoch 255  Train loss: -2.8245676152846393  Val loss: -3.038544238637813
Epoch 256
-------------------------------
Batch 1/64 loss: -2.929429054260254
Batch 2/64 loss: -2.8769140243530273
Batch 3/64 loss: -2.897162437438965
Batch 4/64 loss: -3.046541213989258
Batch 5/64 loss: -2.997715950012207
Batch 6/64 loss: -2.958566665649414
Batch 7/64 loss: -2.6951398849487305
Batch 8/64 loss: -2.994147300720215
Batch 9/64 loss: -2.785984992980957
Batch 10/64 loss: -2.743161201477051
Batch 11/64 loss: -3.094759941101074
Batch 12/64 loss: -2.718931198120117
Batch 13/64 loss: -2.733928680419922
Batch 14/64 loss: -2.682389259338379
Batch 15/64 loss: -2.8458871841430664
Batch 16/64 loss: -2.903087615966797
Batch 17/64 loss: -2.929586410522461
Batch 18/64 loss: -2.8441591262817383
Batch 19/64 loss: -2.5646820068359375
Batch 20/64 loss: -2.8864755630493164
Batch 21/64 loss: -2.7222843170166016
Batch 22/64 loss: -2.9387340545654297
Batch 23/64 loss: -2.7680253982543945
Batch 24/64 loss: -2.788328170776367
Batch 25/64 loss: -2.697427749633789
Batch 26/64 loss: -2.5817670822143555
Batch 27/64 loss: -2.9528417587280273
Batch 28/64 loss: -2.8459043502807617
Batch 29/64 loss: -2.7468156814575195
Batch 30/64 loss: -2.2581043243408203
Batch 31/64 loss: -2.6148319244384766
Batch 32/64 loss: -2.881753921508789
Batch 33/64 loss: -2.16904354095459
Batch 34/64 loss: -2.838590621948242
Batch 35/64 loss: -2.7662315368652344
Batch 36/64 loss: -2.660127639770508
Batch 37/64 loss: -2.461965560913086
Batch 38/64 loss: -2.5772886276245117
Batch 39/64 loss: -2.7419614791870117
Batch 40/64 loss: -2.7848920822143555
Batch 41/64 loss: -2.798129081726074
Batch 42/64 loss: -2.8765201568603516
Batch 43/64 loss: -2.892232894897461
Batch 44/64 loss: -2.9972362518310547
Batch 45/64 loss: -2.9442930221557617
Batch 46/64 loss: -2.8068666458129883
Batch 47/64 loss: -2.668428421020508
Batch 48/64 loss: -2.729755401611328
Batch 49/64 loss: -2.795413017272949
Batch 50/64 loss: -2.8653364181518555
Batch 51/64 loss: -2.7001543045043945
Batch 52/64 loss: -2.914854049682617
Batch 53/64 loss: -2.836729049682617
Batch 54/64 loss: -2.766460418701172
Batch 55/64 loss: -2.778135299682617
Batch 56/64 loss: -2.4966087341308594
Batch 57/64 loss: -2.932453155517578
Batch 58/64 loss: -2.76297664642334
Batch 59/64 loss: -2.472691535949707
Batch 60/64 loss: -2.628772735595703
Batch 61/64 loss: -2.637850761413574
Batch 62/64 loss: -2.293874740600586
Batch 63/64 loss: -2.7786712646484375
Batch 64/64 loss: -7.227431297302246
Epoch 256  Train loss: -2.819146462982776  Val loss: -3.0371755357460466
Epoch 257
-------------------------------
Batch 1/64 loss: -2.8658828735351562
Batch 2/64 loss: -2.8649940490722656
Batch 3/64 loss: -2.714691162109375
Batch 4/64 loss: -2.8868207931518555
Batch 5/64 loss: -1.9384498596191406
Batch 6/64 loss: -2.9362831115722656
Batch 7/64 loss: -2.6366701126098633
Batch 8/64 loss: -2.826443672180176
Batch 9/64 loss: -2.8116655349731445
Batch 10/64 loss: -2.8403682708740234
Batch 11/64 loss: -2.8195838928222656
Batch 12/64 loss: -2.933028221130371
Batch 13/64 loss: -2.8445539474487305
Batch 14/64 loss: -2.761563301086426
Batch 15/64 loss: -2.9747819900512695
Batch 16/64 loss: -2.760106086730957
Batch 17/64 loss: -2.9509010314941406
Batch 18/64 loss: -2.9497060775756836
Batch 19/64 loss: -2.9424638748168945
Batch 20/64 loss: -2.4533538818359375
Batch 21/64 loss: -2.5770530700683594
Batch 22/64 loss: -2.812798500061035
Batch 23/64 loss: -2.513111114501953
Batch 24/64 loss: -2.794391632080078
Batch 25/64 loss: -2.5852622985839844
Batch 26/64 loss: -2.6547956466674805
Batch 27/64 loss: -2.569089889526367
Batch 28/64 loss: -2.9748096466064453
Batch 29/64 loss: -2.6206130981445312
Batch 30/64 loss: -2.5291013717651367
Batch 31/64 loss: -2.79184627532959
Batch 32/64 loss: -2.6618423461914062
Batch 33/64 loss: -2.8013792037963867
Batch 34/64 loss: -2.623293876647949
Batch 35/64 loss: -2.757089614868164
Batch 36/64 loss: -2.9293336868286133
Batch 37/64 loss: -2.8066415786743164
Batch 38/64 loss: -2.873668670654297
Batch 39/64 loss: -2.8898754119873047
Batch 40/64 loss: -2.716752052307129
Batch 41/64 loss: -2.782547950744629
Batch 42/64 loss: -2.660893440246582
Batch 43/64 loss: -2.856736183166504
Batch 44/64 loss: -2.459322929382324
Batch 45/64 loss: -2.4169845581054688
Batch 46/64 loss: -2.8979806900024414
Batch 47/64 loss: -2.7456464767456055
Batch 48/64 loss: -3.020003318786621
Batch 49/64 loss: -2.7061233520507812
Batch 50/64 loss: -2.533723831176758
Batch 51/64 loss: -2.8895416259765625
Batch 52/64 loss: -2.592203140258789
Batch 53/64 loss: -2.8641700744628906
Batch 54/64 loss: -2.70485782623291
Batch 55/64 loss: -2.682157516479492
Batch 56/64 loss: -2.926839828491211
Batch 57/64 loss: -2.526844024658203
Batch 58/64 loss: -2.394529342651367
Batch 59/64 loss: -2.627701759338379
Batch 60/64 loss: -2.7378101348876953
Batch 61/64 loss: -2.774844169616699
Batch 62/64 loss: -2.8220577239990234
Batch 63/64 loss: -2.919083595275879
Batch 64/64 loss: -7.291429042816162
Epoch 257  Train loss: -2.7953919373306575  Val loss: -2.9518580748043517
Epoch 258
-------------------------------
Batch 1/64 loss: -2.924880027770996
Batch 2/64 loss: -2.7150087356567383
Batch 3/64 loss: -2.7704343795776367
Batch 4/64 loss: -2.2990760803222656
Batch 5/64 loss: -2.7529592514038086
Batch 6/64 loss: -2.782695770263672
Batch 7/64 loss: -3.038243293762207
Batch 8/64 loss: -2.705876350402832
Batch 9/64 loss: -2.6491565704345703
Batch 10/64 loss: -2.5525732040405273
Batch 11/64 loss: -2.5592451095581055
Batch 12/64 loss: -2.6772165298461914
Batch 13/64 loss: -2.7396154403686523
Batch 14/64 loss: -2.6551475524902344
Batch 15/64 loss: -2.701772689819336
Batch 16/64 loss: -2.6515445709228516
Batch 17/64 loss: -2.870285987854004
Batch 18/64 loss: -2.774444580078125
Batch 19/64 loss: -2.8040571212768555
Batch 20/64 loss: -2.684536933898926
Batch 21/64 loss: -2.461503028869629
Batch 22/64 loss: -2.5014114379882812
Batch 23/64 loss: -2.8545141220092773
Batch 24/64 loss: -2.8210229873657227
Batch 25/64 loss: -2.6064414978027344
Batch 26/64 loss: -2.7152318954467773
Batch 27/64 loss: -2.817544937133789
Batch 28/64 loss: -3.009701728820801
Batch 29/64 loss: -2.6257286071777344
Batch 30/64 loss: -2.711679458618164
Batch 31/64 loss: -2.851095199584961
Batch 32/64 loss: -2.6768321990966797
Batch 33/64 loss: -2.7031478881835938
Batch 34/64 loss: -2.433487892150879
Batch 35/64 loss: -2.8629093170166016
Batch 36/64 loss: -2.2368412017822266
Batch 37/64 loss: -2.7396488189697266
Batch 38/64 loss: -2.7245702743530273
Batch 39/64 loss: -2.802959442138672
Batch 40/64 loss: -2.732851982116699
Batch 41/64 loss: -2.9861230850219727
Batch 42/64 loss: -2.95461368560791
Batch 43/64 loss: -2.9663286209106445
Batch 44/64 loss: -2.75673770904541
Batch 45/64 loss: -2.8405513763427734
Batch 46/64 loss: -2.737802505493164
Batch 47/64 loss: -2.8036069869995117
Batch 48/64 loss: -2.800809860229492
Batch 49/64 loss: -2.650607109069824
Batch 50/64 loss: -2.8239927291870117
Batch 51/64 loss: -2.7859582901000977
Batch 52/64 loss: -2.4849510192871094
Batch 53/64 loss: -2.900162696838379
Batch 54/64 loss: -2.6978235244750977
Batch 55/64 loss: -2.742868423461914
Batch 56/64 loss: -2.642974853515625
Batch 57/64 loss: -2.7719602584838867
Batch 58/64 loss: -2.0674524307250977
Batch 59/64 loss: -2.719283103942871
Batch 60/64 loss: -2.893310546875
Batch 61/64 loss: -2.7903823852539062
Batch 62/64 loss: -2.902170181274414
Batch 63/64 loss: -2.701176643371582
Batch 64/64 loss: -7.392831802368164
Epoch 258  Train loss: -2.779045740763346  Val loss: -2.993482543840441
Epoch 259
-------------------------------
Batch 1/64 loss: -2.8652429580688477
Batch 2/64 loss: -2.600924491882324
Batch 3/64 loss: -2.578009605407715
Batch 4/64 loss: -2.909905433654785
Batch 5/64 loss: -2.8214168548583984
Batch 6/64 loss: -2.7999143600463867
Batch 7/64 loss: -2.8829822540283203
Batch 8/64 loss: -2.896089553833008
Batch 9/64 loss: -2.998082160949707
Batch 10/64 loss: -2.8249988555908203
Batch 11/64 loss: -2.879847526550293
Batch 12/64 loss: -2.955042839050293
Batch 13/64 loss: -2.421113967895508
Batch 14/64 loss: -2.800924301147461
Batch 15/64 loss: -2.6918468475341797
Batch 16/64 loss: -2.849252700805664
Batch 17/64 loss: -2.7164382934570312
Batch 18/64 loss: -2.7159910202026367
Batch 19/64 loss: -2.817131996154785
Batch 20/64 loss: -2.829583168029785
Batch 21/64 loss: -2.786651611328125
Batch 22/64 loss: -2.3325395584106445
Batch 23/64 loss: -3.0999584197998047
Batch 24/64 loss: -2.7908458709716797
Batch 25/64 loss: -2.511368751525879
Batch 26/64 loss: -2.3581295013427734
Batch 27/64 loss: -2.59478759765625
Batch 28/64 loss: -2.5490379333496094
Batch 29/64 loss: -2.403195381164551
Batch 30/64 loss: -2.9140634536743164
Batch 31/64 loss: -2.824869155883789
Batch 32/64 loss: -2.7117481231689453
Batch 33/64 loss: -2.66695499420166
Batch 34/64 loss: -2.878652572631836
Batch 35/64 loss: -2.867428779602051
Batch 36/64 loss: -2.7959651947021484
Batch 37/64 loss: -2.663606643676758
Batch 38/64 loss: -2.960224151611328
Batch 39/64 loss: -2.623579978942871
Batch 40/64 loss: -2.8034753799438477
Batch 41/64 loss: -2.68829345703125
Batch 42/64 loss: -3.0327491760253906
Batch 43/64 loss: -2.7650957107543945
Batch 44/64 loss: -2.927128791809082
Batch 45/64 loss: -2.670224189758301
Batch 46/64 loss: -2.6316423416137695
Batch 47/64 loss: -3.064878463745117
Batch 48/64 loss: -2.8582687377929688
Batch 49/64 loss: -2.4827394485473633
Batch 50/64 loss: -2.848402976989746
Batch 51/64 loss: -2.846986770629883
Batch 52/64 loss: -2.7516469955444336
Batch 53/64 loss: -2.7352828979492188
Batch 54/64 loss: -2.9635868072509766
Batch 55/64 loss: -2.822812080383301
Batch 56/64 loss: -2.69390869140625
Batch 57/64 loss: -2.673768997192383
Batch 58/64 loss: -2.8048248291015625
Batch 59/64 loss: -2.728839874267578
Batch 60/64 loss: -2.66256046295166
Batch 61/64 loss: -2.8402137756347656
Batch 62/64 loss: -2.7331161499023438
Batch 63/64 loss: -2.60699462890625
Batch 64/64 loss: -6.982580184936523
Epoch 259  Train loss: -2.8088270374372892  Val loss: -3.0124274185023356
Epoch 260
-------------------------------
Batch 1/64 loss: -2.8530054092407227
Batch 2/64 loss: -2.7720947265625
Batch 3/64 loss: -2.925839424133301
Batch 4/64 loss: -2.713374137878418
Batch 5/64 loss: -2.70535945892334
Batch 6/64 loss: -2.9592723846435547
Batch 7/64 loss: -2.7061376571655273
Batch 8/64 loss: -2.66530704498291
Batch 9/64 loss: -2.833803176879883
Batch 10/64 loss: -2.8713035583496094
Batch 11/64 loss: -3.028225898742676
Batch 12/64 loss: -2.779416084289551
Batch 13/64 loss: -2.871997833251953
Batch 14/64 loss: -2.9508113861083984
Batch 15/64 loss: -2.9312171936035156
Batch 16/64 loss: -2.990117073059082
Batch 17/64 loss: -2.620830535888672
Batch 18/64 loss: -2.887173652648926
Batch 19/64 loss: -2.7303104400634766
Batch 20/64 loss: -2.797975540161133
Batch 21/64 loss: -2.8477354049682617
Batch 22/64 loss: -2.526212692260742
Batch 23/64 loss: -2.9015321731567383
Batch 24/64 loss: -2.9237985610961914
Batch 25/64 loss: -2.866755485534668
Batch 26/64 loss: -2.6746225357055664
Batch 27/64 loss: -2.9437742233276367
Batch 28/64 loss: -2.7928686141967773
Batch 29/64 loss: -2.708529472351074
Batch 30/64 loss: -2.5993337631225586
Batch 31/64 loss: -2.6260032653808594
Batch 32/64 loss: -2.639826774597168
Batch 33/64 loss: -2.9703102111816406
Batch 34/64 loss: -2.68829345703125
Batch 35/64 loss: -2.5747785568237305
Batch 36/64 loss: -2.7409868240356445
Batch 37/64 loss: -2.540912628173828
Batch 38/64 loss: -2.8893136978149414
Batch 39/64 loss: -2.349215507507324
Batch 40/64 loss: -2.780402183532715
Batch 41/64 loss: -3.029987335205078
Batch 42/64 loss: -2.580704689025879
Batch 43/64 loss: -2.7212371826171875
Batch 44/64 loss: -2.65380859375
Batch 45/64 loss: -2.862959861755371
Batch 46/64 loss: -2.851991653442383
Batch 47/64 loss: -2.788119316101074
Batch 48/64 loss: -2.961721420288086
Batch 49/64 loss: -2.862215995788574
Batch 50/64 loss: -2.74569034576416
Batch 51/64 loss: -2.220113754272461
Batch 52/64 loss: -2.8001155853271484
Batch 53/64 loss: -2.670365333557129
Batch 54/64 loss: -2.865572929382324
Batch 55/64 loss: -2.8881092071533203
Batch 56/64 loss: -2.9388561248779297
Batch 57/64 loss: -2.8642120361328125
Batch 58/64 loss: -2.7791032791137695
Batch 59/64 loss: -2.77365779876709
Batch 60/64 loss: -2.6659278869628906
Batch 61/64 loss: -2.6805925369262695
Batch 62/64 loss: -2.897000312805176
Batch 63/64 loss: -2.751772880554199
Batch 64/64 loss: -6.853456020355225
Epoch 260  Train loss: -2.8262385368347167  Val loss: -3.0034364785525396
Epoch 261
-------------------------------
Batch 1/64 loss: -2.8285274505615234
Batch 2/64 loss: -2.588076591491699
Batch 3/64 loss: -2.8304080963134766
Batch 4/64 loss: -2.658675193786621
Batch 5/64 loss: -2.727910041809082
Batch 6/64 loss: -2.6214475631713867
Batch 7/64 loss: -2.8675308227539062
Batch 8/64 loss: -2.8356971740722656
Batch 9/64 loss: -2.924175262451172
Batch 10/64 loss: -2.891900062561035
Batch 11/64 loss: -2.6036319732666016
Batch 12/64 loss: -2.8914222717285156
Batch 13/64 loss: -3.1383886337280273
Batch 14/64 loss: -3.0488109588623047
Batch 15/64 loss: -2.5706405639648438
Batch 16/64 loss: -2.959652900695801
Batch 17/64 loss: -2.573802947998047
Batch 18/64 loss: -2.8212289810180664
Batch 19/64 loss: -2.717714309692383
Batch 20/64 loss: -2.915555953979492
Batch 21/64 loss: -2.8176345825195312
Batch 22/64 loss: -2.6957321166992188
Batch 23/64 loss: -2.8853702545166016
Batch 24/64 loss: -2.9577598571777344
Batch 25/64 loss: -2.9098339080810547
Batch 26/64 loss: -2.5971755981445312
Batch 27/64 loss: -2.5840654373168945
Batch 28/64 loss: -2.978074073791504
Batch 29/64 loss: -2.765146255493164
Batch 30/64 loss: -2.5942554473876953
Batch 31/64 loss: -2.9764041900634766
Batch 32/64 loss: -2.7944908142089844
Batch 33/64 loss: -2.3023834228515625
Batch 34/64 loss: -2.807753562927246
Batch 35/64 loss: -2.6125850677490234
Batch 36/64 loss: -2.908550262451172
Batch 37/64 loss: -2.8643369674682617
Batch 38/64 loss: -2.9694032669067383
Batch 39/64 loss: -2.70416259765625
Batch 40/64 loss: -2.558439254760742
Batch 41/64 loss: -2.910761833190918
Batch 42/64 loss: -2.595743179321289
Batch 43/64 loss: -2.6729307174682617
Batch 44/64 loss: -3.04451847076416
Batch 45/64 loss: -2.96817684173584
Batch 46/64 loss: -2.5045080184936523
Batch 47/64 loss: -2.654181480407715
Batch 48/64 loss: -2.4890146255493164
Batch 49/64 loss: -2.4509572982788086
Batch 50/64 loss: -2.742382049560547
Batch 51/64 loss: -2.900789260864258
Batch 52/64 loss: -2.829190254211426
Batch 53/64 loss: -2.7609214782714844
Batch 54/64 loss: -2.610722541809082
Batch 55/64 loss: -2.6952524185180664
Batch 56/64 loss: -2.788545608520508
Batch 57/64 loss: -2.6935253143310547
Batch 58/64 loss: -2.5195541381835938
Batch 59/64 loss: -2.497386932373047
Batch 60/64 loss: -2.7370481491088867
Batch 61/64 loss: -2.517205238342285
Batch 62/64 loss: -2.783903121948242
Batch 63/64 loss: -2.5554494857788086
Batch 64/64 loss: -7.109199523925781
Epoch 261  Train loss: -2.800836435953776  Val loss: -2.975610726477764
Epoch 262
-------------------------------
Batch 1/64 loss: -2.7999467849731445
Batch 2/64 loss: -2.8632946014404297
Batch 3/64 loss: -2.93886661529541
Batch 4/64 loss: -2.6420955657958984
Batch 5/64 loss: -2.383864402770996
Batch 6/64 loss: -2.854325294494629
Batch 7/64 loss: -2.690304756164551
Batch 8/64 loss: -2.935335159301758
Batch 9/64 loss: -2.9095191955566406
Batch 10/64 loss: -2.706228256225586
Batch 11/64 loss: -2.561786651611328
Batch 12/64 loss: -2.4142627716064453
Batch 13/64 loss: -3.0017175674438477
Batch 14/64 loss: -2.923065185546875
Batch 15/64 loss: -2.7420339584350586
Batch 16/64 loss: -2.3965349197387695
Batch 17/64 loss: -2.8640871047973633
Batch 18/64 loss: -2.7859907150268555
Batch 19/64 loss: -2.9167890548706055
Batch 20/64 loss: -2.681717872619629
Batch 21/64 loss: -2.722174644470215
Batch 22/64 loss: -2.602349281311035
Batch 23/64 loss: -2.966920852661133
Batch 24/64 loss: -2.869929313659668
Batch 25/64 loss: -3.073606491088867
Batch 26/64 loss: -2.9180898666381836
Batch 27/64 loss: -2.79360294342041
Batch 28/64 loss: -2.6781253814697266
Batch 29/64 loss: -2.5923280715942383
Batch 30/64 loss: -2.6609325408935547
Batch 31/64 loss: -2.8297319412231445
Batch 32/64 loss: -2.8456172943115234
Batch 33/64 loss: -2.6273012161254883
Batch 34/64 loss: -2.7623062133789062
Batch 35/64 loss: -2.598374366760254
Batch 36/64 loss: -2.8317623138427734
Batch 37/64 loss: -2.6560630798339844
Batch 38/64 loss: -2.6403684616088867
Batch 39/64 loss: -3.006406784057617
Batch 40/64 loss: -2.827744483947754
Batch 41/64 loss: -2.9927358627319336
Batch 42/64 loss: -2.7247743606567383
Batch 43/64 loss: -3.001173973083496
Batch 44/64 loss: -2.8729238510131836
Batch 45/64 loss: -2.86356258392334
Batch 46/64 loss: -2.6911230087280273
Batch 47/64 loss: -2.7730417251586914
Batch 48/64 loss: -2.918790817260742
Batch 49/64 loss: -2.5978031158447266
Batch 50/64 loss: -2.6903276443481445
Batch 51/64 loss: -2.483896255493164
Batch 52/64 loss: -2.90911865234375
Batch 53/64 loss: -2.4966726303100586
Batch 54/64 loss: -2.631772041320801
Batch 55/64 loss: -2.6528053283691406
Batch 56/64 loss: -2.83577823638916
Batch 57/64 loss: -2.7294673919677734
Batch 58/64 loss: -2.634183883666992
Batch 59/64 loss: -2.422107696533203
Batch 60/64 loss: -2.731996536254883
Batch 61/64 loss: -2.8215627670288086
Batch 62/64 loss: -2.365096092224121
Batch 63/64 loss: -2.7402877807617188
Batch 64/64 loss: -7.398444175720215
Epoch 262  Train loss: -2.802279801462211  Val loss: -2.855871836344401
Epoch 263
-------------------------------
Batch 1/64 loss: -2.8362655639648438
Batch 2/64 loss: -2.628138542175293
Batch 3/64 loss: -2.506622314453125
Batch 4/64 loss: -2.6063413619995117
Batch 5/64 loss: -2.793126106262207
Batch 6/64 loss: -2.668609619140625
Batch 7/64 loss: -2.7250747680664062
Batch 8/64 loss: -2.871143341064453
Batch 9/64 loss: -2.735868453979492
Batch 10/64 loss: -2.7049684524536133
Batch 11/64 loss: -2.754561424255371
Batch 12/64 loss: -2.7594804763793945
Batch 13/64 loss: -2.5944976806640625
Batch 14/64 loss: -2.5000925064086914
Batch 15/64 loss: -2.988905906677246
Batch 16/64 loss: -2.8404951095581055
Batch 17/64 loss: -2.7995920181274414
Batch 18/64 loss: -2.961167335510254
Batch 19/64 loss: -2.826420783996582
Batch 20/64 loss: -2.5969552993774414
Batch 21/64 loss: -2.695542335510254
Batch 22/64 loss: -2.8378772735595703
Batch 23/64 loss: -2.794529914855957
Batch 24/64 loss: -2.8676719665527344
Batch 25/64 loss: -2.8439998626708984
Batch 26/64 loss: -2.7461862564086914
Batch 27/64 loss: -2.2976322174072266
Batch 28/64 loss: -2.8514747619628906
Batch 29/64 loss: -2.6971282958984375
Batch 30/64 loss: -2.612025260925293
Batch 31/64 loss: -2.9000368118286133
Batch 32/64 loss: -2.6949520111083984
Batch 33/64 loss: -2.1987600326538086
Batch 34/64 loss: -2.564128875732422
Batch 35/64 loss: -2.9051904678344727
Batch 36/64 loss: -2.5652990341186523
Batch 37/64 loss: -2.811521530151367
Batch 38/64 loss: -2.776988983154297
Batch 39/64 loss: -2.5356578826904297
Batch 40/64 loss: -2.7640533447265625
Batch 41/64 loss: -2.5865659713745117
Batch 42/64 loss: -2.583094596862793
Batch 43/64 loss: -2.9164915084838867
Batch 44/64 loss: -2.8542728424072266
Batch 45/64 loss: -2.8130922317504883
Batch 46/64 loss: -2.879375457763672
Batch 47/64 loss: -2.695919990539551
Batch 48/64 loss: -2.782343864440918
Batch 49/64 loss: -2.7099266052246094
Batch 50/64 loss: -2.7536468505859375
Batch 51/64 loss: -2.8657379150390625
Batch 52/64 loss: -2.592402458190918
Batch 53/64 loss: -2.5613412857055664
Batch 54/64 loss: -2.6687936782836914
Batch 55/64 loss: -2.8864316940307617
Batch 56/64 loss: -2.8649797439575195
Batch 57/64 loss: -2.72174072265625
Batch 58/64 loss: -2.799004554748535
Batch 59/64 loss: -2.5786046981811523
Batch 60/64 loss: -2.813779830932617
Batch 61/64 loss: -2.6159753799438477
Batch 62/64 loss: -2.777594566345215
Batch 63/64 loss: -2.712996482849121
Batch 64/64 loss: -7.162504196166992
Epoch 263  Train loss: -2.7774898080264823  Val loss: -2.9772870696287383
Epoch 264
-------------------------------
Batch 1/64 loss: -2.968968391418457
Batch 2/64 loss: -2.8738794326782227
Batch 3/64 loss: -2.9074010848999023
Batch 4/64 loss: -2.6417980194091797
Batch 5/64 loss: -2.660956382751465
Batch 6/64 loss: -2.6722803115844727
Batch 7/64 loss: -2.960934638977051
Batch 8/64 loss: -2.8326549530029297
Batch 9/64 loss: -2.6386470794677734
Batch 10/64 loss: -2.6082754135131836
Batch 11/64 loss: -2.8883914947509766
Batch 12/64 loss: -2.3950271606445312
Batch 13/64 loss: -2.781874656677246
Batch 14/64 loss: -2.7062549591064453
Batch 15/64 loss: -2.7402219772338867
Batch 16/64 loss: -2.826838493347168
Batch 17/64 loss: -2.506760597229004
Batch 18/64 loss: -2.6094846725463867
Batch 19/64 loss: -2.664308547973633
Batch 20/64 loss: -2.762770652770996
Batch 21/64 loss: -2.8513174057006836
Batch 22/64 loss: -2.7867612838745117
Batch 23/64 loss: -2.658280372619629
Batch 24/64 loss: -2.5720748901367188
Batch 25/64 loss: -2.6980695724487305
Batch 26/64 loss: -2.947704315185547
Batch 27/64 loss: -2.3185081481933594
Batch 28/64 loss: -2.8662214279174805
Batch 29/64 loss: -2.5940141677856445
Batch 30/64 loss: -2.9386863708496094
Batch 31/64 loss: -2.8850135803222656
Batch 32/64 loss: -2.9725990295410156
Batch 33/64 loss: -2.8465051651000977
Batch 34/64 loss: -2.7113943099975586
Batch 35/64 loss: -2.737455368041992
Batch 36/64 loss: -2.9112911224365234
Batch 37/64 loss: -2.7679691314697266
Batch 38/64 loss: -2.9959049224853516
Batch 39/64 loss: -2.6558780670166016
Batch 40/64 loss: -2.5991764068603516
Batch 41/64 loss: -2.5780248641967773
Batch 42/64 loss: -2.769845962524414
Batch 43/64 loss: -2.258894920349121
Batch 44/64 loss: -2.0714197158813477
Batch 45/64 loss: -2.603069305419922
Batch 46/64 loss: -2.622960090637207
Batch 47/64 loss: -2.7431678771972656
Batch 48/64 loss: -2.7702341079711914
Batch 49/64 loss: -2.676201820373535
Batch 50/64 loss: -2.925079345703125
Batch 51/64 loss: -2.703251838684082
Batch 52/64 loss: -2.74190616607666
Batch 53/64 loss: -2.760848045349121
Batch 54/64 loss: -2.843708038330078
Batch 55/64 loss: -2.826409339904785
Batch 56/64 loss: -2.519608497619629
Batch 57/64 loss: -2.281564712524414
Batch 58/64 loss: -2.31510066986084
Batch 59/64 loss: -2.5247154235839844
Batch 60/64 loss: -2.539149284362793
Batch 61/64 loss: -2.9075698852539062
Batch 62/64 loss: -2.5735130310058594
Batch 63/64 loss: -2.7601938247680664
Batch 64/64 loss: -7.281101226806641
Epoch 264  Train loss: -2.7567030065199907  Val loss: -2.9542869358128288
Epoch 265
-------------------------------
Batch 1/64 loss: -2.758787155151367
Batch 2/64 loss: -3.0300331115722656
Batch 3/64 loss: -2.9829635620117188
Batch 4/64 loss: -2.462998390197754
Batch 5/64 loss: -2.804388999938965
Batch 6/64 loss: -2.8020992279052734
Batch 7/64 loss: -2.5662498474121094
Batch 8/64 loss: -2.5004358291625977
Batch 9/64 loss: -2.7480945587158203
Batch 10/64 loss: -2.304989814758301
Batch 11/64 loss: -2.5635929107666016
Batch 12/64 loss: -2.568547248840332
Batch 13/64 loss: -2.842240333557129
Batch 14/64 loss: -2.9295730590820312
Batch 15/64 loss: -2.7863645553588867
Batch 16/64 loss: -2.513174057006836
Batch 17/64 loss: -2.5717201232910156
Batch 18/64 loss: -2.641852378845215
Batch 19/64 loss: -2.838247299194336
Batch 20/64 loss: -2.693157196044922
Batch 21/64 loss: -2.424854278564453
Batch 22/64 loss: -2.7039175033569336
Batch 23/64 loss: -2.675821304321289
Batch 24/64 loss: -2.725226402282715
Batch 25/64 loss: -2.91998291015625
Batch 26/64 loss: -2.7663497924804688
Batch 27/64 loss: -2.958475112915039
Batch 28/64 loss: -2.9962406158447266
Batch 29/64 loss: -2.532991409301758
Batch 30/64 loss: -2.4751386642456055
Batch 31/64 loss: -2.9246206283569336
Batch 32/64 loss: -2.821589469909668
Batch 33/64 loss: -2.7295799255371094
Batch 34/64 loss: -2.565213203430176
Batch 35/64 loss: -2.695148468017578
Batch 36/64 loss: -2.725027084350586
Batch 37/64 loss: -2.879087448120117
Batch 38/64 loss: -2.7113704681396484
Batch 39/64 loss: -2.7968263626098633
Batch 40/64 loss: -2.610830307006836
Batch 41/64 loss: -2.6606264114379883
Batch 42/64 loss: -2.7708282470703125
Batch 43/64 loss: -2.5937118530273438
Batch 44/64 loss: -2.557093620300293
Batch 45/64 loss: -2.5316238403320312
Batch 46/64 loss: -2.7430686950683594
Batch 47/64 loss: -2.6574392318725586
Batch 48/64 loss: -2.4994916915893555
Batch 49/64 loss: -2.616331100463867
Batch 50/64 loss: -1.9802894592285156
Batch 51/64 loss: -2.716708183288574
Batch 52/64 loss: -2.2925357818603516
Batch 53/64 loss: -2.880767822265625
Batch 54/64 loss: -2.7438440322875977
Batch 55/64 loss: -2.424729347229004
Batch 56/64 loss: -2.7951650619506836
Batch 57/64 loss: -2.7895994186401367
Batch 58/64 loss: -2.5255346298217773
Batch 59/64 loss: -2.665437698364258
Batch 60/64 loss: -2.7079715728759766
Batch 61/64 loss: -2.810469627380371
Batch 62/64 loss: -2.803908348083496
Batch 63/64 loss: -2.916985511779785
Batch 64/64 loss: -6.97977352142334
Epoch 265  Train loss: -2.7367339975693645  Val loss: -2.925802040755544
Epoch 266
-------------------------------
Batch 1/64 loss: -3.008695602416992
Batch 2/64 loss: -2.7230701446533203
Batch 3/64 loss: -2.7758569717407227
Batch 4/64 loss: -2.478774070739746
Batch 5/64 loss: -2.7977819442749023
Batch 6/64 loss: -2.677133560180664
Batch 7/64 loss: -2.8458471298217773
Batch 8/64 loss: -2.577029228210449
Batch 9/64 loss: -2.6148319244384766
Batch 10/64 loss: -2.589625358581543
Batch 11/64 loss: -2.7697715759277344
Batch 12/64 loss: -2.701496124267578
Batch 13/64 loss: -2.644656181335449
Batch 14/64 loss: -2.646904945373535
Batch 15/64 loss: -2.811279296875
Batch 16/64 loss: -2.714592933654785
Batch 17/64 loss: -2.7013425827026367
Batch 18/64 loss: -2.665445327758789
Batch 19/64 loss: -2.7896556854248047
Batch 20/64 loss: -2.8521299362182617
Batch 21/64 loss: -2.684330940246582
Batch 22/64 loss: -2.6920785903930664
Batch 23/64 loss: -2.571016311645508
Batch 24/64 loss: -2.7576074600219727
Batch 25/64 loss: -2.708847999572754
Batch 26/64 loss: -2.688565254211426
Batch 27/64 loss: -2.589672088623047
Batch 28/64 loss: -2.938222885131836
Batch 29/64 loss: -2.74484920501709
Batch 30/64 loss: -2.800877571105957
Batch 31/64 loss: -2.642245292663574
Batch 32/64 loss: -3.015277862548828
Batch 33/64 loss: -2.6847190856933594
Batch 34/64 loss: -2.7217025756835938
Batch 35/64 loss: -2.560257911682129
Batch 36/64 loss: -2.6205453872680664
Batch 37/64 loss: -2.784684181213379
Batch 38/64 loss: -2.7996320724487305
Batch 39/64 loss: -3.0120811462402344
Batch 40/64 loss: -2.870354652404785
Batch 41/64 loss: -2.780366897583008
Batch 42/64 loss: -2.937591552734375
Batch 43/64 loss: -2.823060989379883
Batch 44/64 loss: -2.8498640060424805
Batch 45/64 loss: -2.5170536041259766
Batch 46/64 loss: -2.740325927734375
Batch 47/64 loss: -2.620388984680176
Batch 48/64 loss: -2.709355354309082
Batch 49/64 loss: -2.5874452590942383
Batch 50/64 loss: -2.8196372985839844
Batch 51/64 loss: -2.8367786407470703
Batch 52/64 loss: -2.540315628051758
Batch 53/64 loss: -2.60107421875
Batch 54/64 loss: -2.931868553161621
Batch 55/64 loss: -2.7690248489379883
Batch 56/64 loss: -2.8859729766845703
Batch 57/64 loss: -2.9426698684692383
Batch 58/64 loss: -2.6681833267211914
Batch 59/64 loss: -2.6223249435424805
Batch 60/64 loss: -2.38754940032959
Batch 61/64 loss: -2.39955997467041
Batch 62/64 loss: -2.1877899169921875
Batch 63/64 loss: -3.003251075744629
Batch 64/64 loss: -6.665722846984863
Epoch 266  Train loss: -2.767595833423091  Val loss: -3.016306991839327
Epoch 267
-------------------------------
Batch 1/64 loss: -2.9582748413085938
Batch 2/64 loss: -2.5369491577148438
Batch 3/64 loss: -2.606431007385254
Batch 4/64 loss: -2.738424301147461
Batch 5/64 loss: -2.7950658798217773
Batch 6/64 loss: -2.6580467224121094
Batch 7/64 loss: -2.817042350769043
Batch 8/64 loss: -2.72969913482666
Batch 9/64 loss: -2.852914810180664
Batch 10/64 loss: -2.7902135848999023
Batch 11/64 loss: -2.7437448501586914
Batch 12/64 loss: -2.690443992614746
Batch 13/64 loss: -2.3447494506835938
Batch 14/64 loss: -2.5545568466186523
Batch 15/64 loss: -2.3241920471191406
Batch 16/64 loss: -2.63995361328125
Batch 17/64 loss: -2.599935531616211
Batch 18/64 loss: -2.7941408157348633
Batch 19/64 loss: -2.819181442260742
Batch 20/64 loss: -2.9798927307128906
Batch 21/64 loss: -2.399540901184082
Batch 22/64 loss: -2.723860740661621
Batch 23/64 loss: -2.9501953125
Batch 24/64 loss: -2.6869754791259766
Batch 25/64 loss: -2.9232845306396484
Batch 26/64 loss: -2.4916086196899414
Batch 27/64 loss: -2.767083168029785
Batch 28/64 loss: -2.713223457336426
Batch 29/64 loss: -2.4118309020996094
Batch 30/64 loss: -2.5075416564941406
Batch 31/64 loss: -2.8400211334228516
Batch 32/64 loss: -2.2672157287597656
Batch 33/64 loss: -2.881964683532715
Batch 34/64 loss: -2.5758047103881836
Batch 35/64 loss: -2.6379823684692383
Batch 36/64 loss: -2.8519668579101562
Batch 37/64 loss: -2.6538238525390625
Batch 38/64 loss: -2.943051338195801
Batch 39/64 loss: -2.7235517501831055
Batch 40/64 loss: -2.766965866088867
Batch 41/64 loss: -2.470038414001465
Batch 42/64 loss: -2.7716760635375977
Batch 43/64 loss: -2.685087203979492
Batch 44/64 loss: -2.5177412033081055
Batch 45/64 loss: -2.7498254776000977
Batch 46/64 loss: -2.61861515045166
Batch 47/64 loss: -2.5042219161987305
Batch 48/64 loss: -2.929287910461426
Batch 49/64 loss: -2.5244855880737305
Batch 50/64 loss: -2.6679773330688477
Batch 51/64 loss: -2.6121177673339844
Batch 52/64 loss: -2.6293840408325195
Batch 53/64 loss: -2.6427135467529297
Batch 54/64 loss: -2.608983039855957
Batch 55/64 loss: -2.483565330505371
Batch 56/64 loss: -2.670973777770996
Batch 57/64 loss: -2.6256933212280273
Batch 58/64 loss: -2.969005584716797
Batch 59/64 loss: -2.875870704650879
Batch 60/64 loss: -2.5588340759277344
Batch 61/64 loss: -2.881084442138672
Batch 62/64 loss: -2.7791738510131836
Batch 63/64 loss: -2.836848258972168
Batch 64/64 loss: -7.329151630401611
Epoch 267  Train loss: -2.741982963038426  Val loss: -3.046540407790351
Epoch 268
-------------------------------
Batch 1/64 loss: -2.748908042907715
Batch 2/64 loss: -2.516791343688965
Batch 3/64 loss: -2.846426010131836
Batch 4/64 loss: -2.718621253967285
Batch 5/64 loss: -2.8750391006469727
Batch 6/64 loss: -2.9943723678588867
Batch 7/64 loss: -2.675137519836426
Batch 8/64 loss: -2.858142852783203
Batch 9/64 loss: -2.8991336822509766
Batch 10/64 loss: -2.8594093322753906
Batch 11/64 loss: -2.3916730880737305
Batch 12/64 loss: -2.8204755783081055
Batch 13/64 loss: -2.7010412216186523
Batch 14/64 loss: -2.9626998901367188
Batch 15/64 loss: -2.824054718017578
Batch 16/64 loss: -2.8195934295654297
Batch 17/64 loss: -2.7169885635375977
Batch 18/64 loss: -2.7005062103271484
Batch 19/64 loss: -2.8094301223754883
Batch 20/64 loss: -2.9119253158569336
Batch 21/64 loss: -2.867506980895996
Batch 22/64 loss: -2.646381378173828
Batch 23/64 loss: -2.8792409896850586
Batch 24/64 loss: -2.8297863006591797
Batch 25/64 loss: -2.884711265563965
Batch 26/64 loss: -2.7138185501098633
Batch 27/64 loss: -2.8294239044189453
Batch 28/64 loss: -2.630406379699707
Batch 29/64 loss: -2.733346939086914
Batch 30/64 loss: -2.742372512817383
Batch 31/64 loss: -2.5842370986938477
Batch 32/64 loss: -2.268580436706543
Batch 33/64 loss: -2.746514320373535
Batch 34/64 loss: -2.4034271240234375
Batch 35/64 loss: -2.656804084777832
Batch 36/64 loss: -2.8597335815429688
Batch 37/64 loss: -2.8340110778808594
Batch 38/64 loss: -2.7711267471313477
Batch 39/64 loss: -2.828658103942871
Batch 40/64 loss: -2.8324060440063477
Batch 41/64 loss: -2.6440696716308594
Batch 42/64 loss: -2.8708648681640625
Batch 43/64 loss: -2.596470832824707
Batch 44/64 loss: -2.560370445251465
Batch 45/64 loss: -2.907917022705078
Batch 46/64 loss: -2.6796464920043945
Batch 47/64 loss: -2.7648515701293945
Batch 48/64 loss: -2.8698530197143555
Batch 49/64 loss: -2.8755178451538086
Batch 50/64 loss: -2.6030588150024414
Batch 51/64 loss: -2.884227752685547
Batch 52/64 loss: -2.7153968811035156
Batch 53/64 loss: -2.5921669006347656
Batch 54/64 loss: -2.5537948608398438
Batch 55/64 loss: -2.82204532623291
Batch 56/64 loss: -2.725299835205078
Batch 57/64 loss: -2.839289665222168
Batch 58/64 loss: -2.363779067993164
Batch 59/64 loss: -2.860213279724121
Batch 60/64 loss: -2.7943172454833984
Batch 61/64 loss: -2.77120304107666
Batch 62/64 loss: -2.772359848022461
Batch 63/64 loss: -2.74654483795166
Batch 64/64 loss: -7.2770256996154785
Epoch 268  Train loss: -2.799433597863889  Val loss: -3.0441372796022605
Epoch 269
-------------------------------
Batch 1/64 loss: -2.960613250732422
Batch 2/64 loss: -2.873371124267578
Batch 3/64 loss: -2.132844924926758
Batch 4/64 loss: -2.6803789138793945
Batch 5/64 loss: -2.8340530395507812
Batch 6/64 loss: -2.8916139602661133
Batch 7/64 loss: -2.7782983779907227
Batch 8/64 loss: -2.922060966491699
Batch 9/64 loss: -2.369553565979004
Batch 10/64 loss: -2.745553970336914
Batch 11/64 loss: -2.9064273834228516
Batch 12/64 loss: -2.7795419692993164
Batch 13/64 loss: -2.7628517150878906
Batch 14/64 loss: -2.718191146850586
Batch 15/64 loss: -2.5977840423583984
Batch 16/64 loss: -2.559994697570801
Batch 17/64 loss: -2.4712038040161133
Batch 18/64 loss: -2.949824333190918
Batch 19/64 loss: -2.631101608276367
Batch 20/64 loss: -2.987180709838867
Batch 21/64 loss: -2.887056350708008
Batch 22/64 loss: -2.8341503143310547
Batch 23/64 loss: -2.646470069885254
Batch 24/64 loss: -2.8057870864868164
Batch 25/64 loss: -2.9495468139648438
Batch 26/64 loss: -2.822803497314453
Batch 27/64 loss: -2.827683448791504
Batch 28/64 loss: -2.880948066711426
Batch 29/64 loss: -2.8248252868652344
Batch 30/64 loss: -2.652587890625
Batch 31/64 loss: -2.7261180877685547
Batch 32/64 loss: -2.9521255493164062
Batch 33/64 loss: -2.741487503051758
Batch 34/64 loss: -2.941554069519043
Batch 35/64 loss: -3.11151123046875
Batch 36/64 loss: -2.88930606842041
Batch 37/64 loss: -2.8811750411987305
Batch 38/64 loss: -2.8746023178100586
Batch 39/64 loss: -2.3615293502807617
Batch 40/64 loss: -2.9893064498901367
Batch 41/64 loss: -2.4723281860351562
Batch 42/64 loss: -2.979755401611328
Batch 43/64 loss: -3.0059118270874023
Batch 44/64 loss: -2.5584449768066406
Batch 45/64 loss: -2.683765411376953
Batch 46/64 loss: -2.7015228271484375
Batch 47/64 loss: -3.06707763671875
Batch 48/64 loss: -2.638051986694336
Batch 49/64 loss: -2.8180322647094727
Batch 50/64 loss: -2.7144775390625
Batch 51/64 loss: -2.746333122253418
Batch 52/64 loss: -2.4593334197998047
Batch 53/64 loss: -2.8835792541503906
Batch 54/64 loss: -2.8829450607299805
Batch 55/64 loss: -2.9365854263305664
Batch 56/64 loss: -2.613313674926758
Batch 57/64 loss: -2.772794723510742
Batch 58/64 loss: -2.5812673568725586
Batch 59/64 loss: -3.08414363861084
Batch 60/64 loss: -2.8634958267211914
Batch 61/64 loss: -2.760723114013672
Batch 62/64 loss: -2.53594970703125
Batch 63/64 loss: -2.8130617141723633
Batch 64/64 loss: -7.491462707519531
Epoch 269  Train loss: -2.8289334764667586  Val loss: -3.037311671935406
Epoch 270
-------------------------------
Batch 1/64 loss: -2.553380012512207
Batch 2/64 loss: -2.8594894409179688
Batch 3/64 loss: -2.9226865768432617
Batch 4/64 loss: -2.9422426223754883
Batch 5/64 loss: -2.8405532836914062
Batch 6/64 loss: -2.81447696685791
Batch 7/64 loss: -2.808422088623047
Batch 8/64 loss: -2.873575210571289
Batch 9/64 loss: -2.7175188064575195
Batch 10/64 loss: -2.6598825454711914
Batch 11/64 loss: -2.980217933654785
Batch 12/64 loss: -2.5764942169189453
Batch 13/64 loss: -2.8576412200927734
Batch 14/64 loss: -2.9774370193481445
Batch 15/64 loss: -2.83980655670166
Batch 16/64 loss: -2.826953887939453
Batch 17/64 loss: -2.8563222885131836
Batch 18/64 loss: -2.855767250061035
Batch 19/64 loss: -2.713494300842285
Batch 20/64 loss: -2.7589759826660156
Batch 21/64 loss: -2.902590751647949
Batch 22/64 loss: -2.695061683654785
Batch 23/64 loss: -2.9166507720947266
Batch 24/64 loss: -2.949758529663086
Batch 25/64 loss: -2.966885566711426
Batch 26/64 loss: -2.5117902755737305
Batch 27/64 loss: -2.8075523376464844
Batch 28/64 loss: -2.7531471252441406
Batch 29/64 loss: -2.829766273498535
Batch 30/64 loss: -2.9537429809570312
Batch 31/64 loss: -2.9191856384277344
Batch 32/64 loss: -2.621809959411621
Batch 33/64 loss: -2.5671186447143555
Batch 34/64 loss: -2.732743263244629
Batch 35/64 loss: -2.1315927505493164
Batch 36/64 loss: -2.6846399307250977
Batch 37/64 loss: -2.838456153869629
Batch 38/64 loss: -2.6717538833618164
Batch 39/64 loss: -2.498706817626953
Batch 40/64 loss: -2.701700210571289
Batch 41/64 loss: -2.877584457397461
Batch 42/64 loss: -2.6669321060180664
Batch 43/64 loss: -2.64544677734375
Batch 44/64 loss: -2.5632095336914062
Batch 45/64 loss: -2.591358184814453
Batch 46/64 loss: -2.817580223083496
Batch 47/64 loss: -2.901876449584961
Batch 48/64 loss: -2.952622413635254
Batch 49/64 loss: -2.707718849182129
Batch 50/64 loss: -2.6563119888305664
Batch 51/64 loss: -2.9036006927490234
Batch 52/64 loss: -2.7603206634521484
Batch 53/64 loss: -2.7614316940307617
Batch 54/64 loss: -2.960275650024414
Batch 55/64 loss: -2.7768611907958984
Batch 56/64 loss: -2.5878772735595703
Batch 57/64 loss: -2.738117218017578
Batch 58/64 loss: -2.804149627685547
Batch 59/64 loss: -2.4106292724609375
Batch 60/64 loss: -2.9451704025268555
Batch 61/64 loss: -2.6015682220458984
Batch 62/64 loss: -2.9888229370117188
Batch 63/64 loss: -2.8142499923706055
Batch 64/64 loss: -7.342494964599609
Epoch 270  Train loss: -2.8208718243767232  Val loss: -3.054945077273444
Saving best model, epoch: 270
Epoch 271
-------------------------------
Batch 1/64 loss: -2.9567136764526367
Batch 2/64 loss: -2.6738052368164062
Batch 3/64 loss: -2.8051071166992188
Batch 4/64 loss: -2.8721418380737305
Batch 5/64 loss: -2.563444137573242
Batch 6/64 loss: -3.0295114517211914
Batch 7/64 loss: -2.7956085205078125
Batch 8/64 loss: -2.831562042236328
Batch 9/64 loss: -3.0224781036376953
Batch 10/64 loss: -2.58870792388916
Batch 11/64 loss: -2.9147262573242188
Batch 12/64 loss: -2.544279098510742
Batch 13/64 loss: -2.6495771408081055
Batch 14/64 loss: -2.5789260864257812
Batch 15/64 loss: -2.6921777725219727
Batch 16/64 loss: -2.5812501907348633
Batch 17/64 loss: -2.882096290588379
Batch 18/64 loss: -2.8722944259643555
Batch 19/64 loss: -2.914613723754883
Batch 20/64 loss: -3.049057960510254
Batch 21/64 loss: -2.6585121154785156
Batch 22/64 loss: -2.742051124572754
Batch 23/64 loss: -2.3885269165039062
Batch 24/64 loss: -2.92653751373291
Batch 25/64 loss: -2.6009225845336914
Batch 26/64 loss: -2.8900136947631836
Batch 27/64 loss: -2.937718391418457
Batch 28/64 loss: -2.557887077331543
Batch 29/64 loss: -2.7209091186523438
Batch 30/64 loss: -2.775531768798828
Batch 31/64 loss: -2.6164236068725586
Batch 32/64 loss: -2.813711166381836
Batch 33/64 loss: -2.718234062194824
Batch 34/64 loss: -2.4763622283935547
Batch 35/64 loss: -2.872955322265625
Batch 36/64 loss: -2.8561201095581055
Batch 37/64 loss: -2.874384880065918
Batch 38/64 loss: -2.646791458129883
Batch 39/64 loss: -2.733160972595215
Batch 40/64 loss: -2.7802696228027344
Batch 41/64 loss: -2.889455795288086
Batch 42/64 loss: -2.9335708618164062
Batch 43/64 loss: -2.91951847076416
Batch 44/64 loss: -2.533538818359375
Batch 45/64 loss: -2.7244348526000977
Batch 46/64 loss: -2.994354248046875
Batch 47/64 loss: -2.5891313552856445
Batch 48/64 loss: -2.746962547302246
Batch 49/64 loss: -2.9485015869140625
Batch 50/64 loss: -2.818800926208496
Batch 51/64 loss: -2.677140235900879
Batch 52/64 loss: -2.6791534423828125
Batch 53/64 loss: -2.96543025970459
Batch 54/64 loss: -2.638185501098633
Batch 55/64 loss: -2.908306121826172
Batch 56/64 loss: -2.9059295654296875
Batch 57/64 loss: -2.890106201171875
Batch 58/64 loss: -2.7331666946411133
Batch 59/64 loss: -2.7531490325927734
Batch 60/64 loss: -2.7331924438476562
Batch 61/64 loss: -2.939474105834961
Batch 62/64 loss: -2.760068893432617
Batch 63/64 loss: -2.582183837890625
Batch 64/64 loss: -7.238930702209473
Epoch 271  Train loss: -2.8250675538006953  Val loss: -3.060449082417177
Saving best model, epoch: 271
Epoch 272
-------------------------------
Batch 1/64 loss: -2.7307300567626953
Batch 2/64 loss: -2.9544477462768555
Batch 3/64 loss: -2.716653823852539
Batch 4/64 loss: -2.5484886169433594
Batch 5/64 loss: -2.84079647064209
Batch 6/64 loss: -2.5513458251953125
Batch 7/64 loss: -2.8092432022094727
Batch 8/64 loss: -2.9560937881469727
Batch 9/64 loss: -2.8449106216430664
Batch 10/64 loss: -3.036332130432129
Batch 11/64 loss: -2.8621959686279297
Batch 12/64 loss: -2.593311309814453
Batch 13/64 loss: -2.7843408584594727
Batch 14/64 loss: -2.7116498947143555
Batch 15/64 loss: -2.9823360443115234
Batch 16/64 loss: -2.798551559448242
Batch 17/64 loss: -3.0501861572265625
Batch 18/64 loss: -2.767592430114746
Batch 19/64 loss: -2.7685718536376953
Batch 20/64 loss: -2.875082015991211
Batch 21/64 loss: -2.96250057220459
Batch 22/64 loss: -2.7852325439453125
Batch 23/64 loss: -2.790999412536621
Batch 24/64 loss: -2.793257713317871
Batch 25/64 loss: -2.721416473388672
Batch 26/64 loss: -3.0692434310913086
Batch 27/64 loss: -2.534482002258301
Batch 28/64 loss: -2.6247386932373047
Batch 29/64 loss: -2.9766502380371094
Batch 30/64 loss: -2.69722843170166
Batch 31/64 loss: -2.863409996032715
Batch 32/64 loss: -2.8711671829223633
Batch 33/64 loss: -2.5871543884277344
Batch 34/64 loss: -2.6914138793945312
Batch 35/64 loss: -3.0198163986206055
Batch 36/64 loss: -2.8724212646484375
Batch 37/64 loss: -2.9429264068603516
Batch 38/64 loss: -2.6888208389282227
Batch 39/64 loss: -2.8826465606689453
Batch 40/64 loss: -2.7314987182617188
Batch 41/64 loss: -2.996112823486328
Batch 42/64 loss: -2.5785293579101562
Batch 43/64 loss: -2.697319984436035
Batch 44/64 loss: -2.7464065551757812
Batch 45/64 loss: -2.615171432495117
Batch 46/64 loss: -2.73197078704834
Batch 47/64 loss: -2.6355581283569336
Batch 48/64 loss: -2.8271799087524414
Batch 49/64 loss: -2.771286964416504
Batch 50/64 loss: -2.987447738647461
Batch 51/64 loss: -2.9555130004882812
Batch 52/64 loss: -2.5289058685302734
Batch 53/64 loss: -2.989194869995117
Batch 54/64 loss: -2.8735036849975586
Batch 55/64 loss: -2.798494338989258
Batch 56/64 loss: -2.7098770141601562
Batch 57/64 loss: -2.842644691467285
Batch 58/64 loss: -2.8030805587768555
Batch 59/64 loss: -2.751246452331543
Batch 60/64 loss: -2.7850093841552734
Batch 61/64 loss: -2.7868776321411133
Batch 62/64 loss: -2.8552780151367188
Batch 63/64 loss: -3.0613489151000977
Batch 64/64 loss: -7.387583255767822
Epoch 272  Train loss: -2.857388722662832  Val loss: -3.0925386697565975
Saving best model, epoch: 272
Epoch 273
-------------------------------
Batch 1/64 loss: -2.9325780868530273
Batch 2/64 loss: -2.7915544509887695
Batch 3/64 loss: -2.8415298461914062
Batch 4/64 loss: -2.4305620193481445
Batch 5/64 loss: -2.9658451080322266
Batch 6/64 loss: -2.6683664321899414
Batch 7/64 loss: -2.9671592712402344
Batch 8/64 loss: -2.284083366394043
Batch 9/64 loss: -2.4968013763427734
Batch 10/64 loss: -2.3040390014648438
Batch 11/64 loss: -2.648527145385742
Batch 12/64 loss: -3.1321544647216797
Batch 13/64 loss: -2.849546432495117
Batch 14/64 loss: -2.562847137451172
Batch 15/64 loss: -2.875133514404297
Batch 16/64 loss: -2.7575178146362305
Batch 17/64 loss: -2.9661741256713867
Batch 18/64 loss: -2.734933853149414
Batch 19/64 loss: -2.8872289657592773
Batch 20/64 loss: -2.6629180908203125
Batch 21/64 loss: -3.000288963317871
Batch 22/64 loss: -2.6956491470336914
Batch 23/64 loss: -2.841303825378418
Batch 24/64 loss: -2.940835952758789
Batch 25/64 loss: -2.3148622512817383
Batch 26/64 loss: -2.933929443359375
Batch 27/64 loss: -2.9015378952026367
Batch 28/64 loss: -2.708650588989258
Batch 29/64 loss: -2.8631858825683594
Batch 30/64 loss: -2.8888511657714844
Batch 31/64 loss: -2.6127147674560547
Batch 32/64 loss: -2.8371171951293945
Batch 33/64 loss: -2.712190628051758
Batch 34/64 loss: -2.779118537902832
Batch 35/64 loss: -2.664196014404297
Batch 36/64 loss: -2.8288869857788086
Batch 37/64 loss: -2.8469972610473633
Batch 38/64 loss: -2.708371162414551
Batch 39/64 loss: -2.7991819381713867
Batch 40/64 loss: -2.565540313720703
Batch 41/64 loss: -2.8234710693359375
Batch 42/64 loss: -2.863424301147461
Batch 43/64 loss: -3.0151233673095703
Batch 44/64 loss: -2.789155960083008
Batch 45/64 loss: -2.760610580444336
Batch 46/64 loss: -2.976437568664551
Batch 47/64 loss: -2.8395442962646484
Batch 48/64 loss: -2.7778377532958984
Batch 49/64 loss: -2.8159008026123047
Batch 50/64 loss: -2.878192901611328
Batch 51/64 loss: -2.840557098388672
Batch 52/64 loss: -2.8069381713867188
Batch 53/64 loss: -2.9039411544799805
Batch 54/64 loss: -2.7881507873535156
Batch 55/64 loss: -2.769542694091797
Batch 56/64 loss: -2.862065315246582
Batch 57/64 loss: -2.704209327697754
Batch 58/64 loss: -3.008671760559082
Batch 59/64 loss: -2.7541799545288086
Batch 60/64 loss: -2.817967414855957
Batch 61/64 loss: -2.904460906982422
Batch 62/64 loss: -2.709099769592285
Batch 63/64 loss: -2.6187219619750977
Batch 64/64 loss: -7.359695911407471
Epoch 273  Train loss: -2.8353080356822296  Val loss: -2.9590565265249142
Epoch 274
-------------------------------
Batch 1/64 loss: -2.745791435241699
Batch 2/64 loss: -2.7979917526245117
Batch 3/64 loss: -2.958632469177246
Batch 4/64 loss: -2.8660850524902344
Batch 5/64 loss: -2.385056495666504
Batch 6/64 loss: -2.2102108001708984
Batch 7/64 loss: -2.7435150146484375
Batch 8/64 loss: -2.896613121032715
Batch 9/64 loss: -2.85806941986084
Batch 10/64 loss: -2.768411636352539
Batch 11/64 loss: -2.7982845306396484
Batch 12/64 loss: -2.86606502532959
Batch 13/64 loss: -2.8064565658569336
Batch 14/64 loss: -2.5041723251342773
Batch 15/64 loss: -2.7629098892211914
Batch 16/64 loss: -2.35001277923584
Batch 17/64 loss: -3.057558059692383
Batch 18/64 loss: -2.882841110229492
Batch 19/64 loss: -2.8183650970458984
Batch 20/64 loss: -2.657639503479004
Batch 21/64 loss: -2.778688430786133
Batch 22/64 loss: -2.5575618743896484
Batch 23/64 loss: -2.8530588150024414
Batch 24/64 loss: -3.0167245864868164
Batch 25/64 loss: -2.954660415649414
Batch 26/64 loss: -3.0128707885742188
Batch 27/64 loss: -2.7482213973999023
Batch 28/64 loss: -2.8690147399902344
Batch 29/64 loss: -2.938096046447754
Batch 30/64 loss: -2.777576446533203
Batch 31/64 loss: -2.4948558807373047
Batch 32/64 loss: -3.029566764831543
Batch 33/64 loss: -2.7233753204345703
Batch 34/64 loss: -2.8755292892456055
Batch 35/64 loss: -2.7772998809814453
Batch 36/64 loss: -2.911257743835449
Batch 37/64 loss: -2.9220314025878906
Batch 38/64 loss: -2.979562759399414
Batch 39/64 loss: -2.9022789001464844
Batch 40/64 loss: -2.8981313705444336
Batch 41/64 loss: -2.833332061767578
Batch 42/64 loss: -2.8798818588256836
Batch 43/64 loss: -2.6834487915039062
Batch 44/64 loss: -2.899775505065918
Batch 45/64 loss: -2.8787641525268555
Batch 46/64 loss: -2.6471166610717773
Batch 47/64 loss: -3.003755569458008
Batch 48/64 loss: -2.9999313354492188
Batch 49/64 loss: -2.8320817947387695
Batch 50/64 loss: -2.8295650482177734
Batch 51/64 loss: -2.8072004318237305
Batch 52/64 loss: -2.6058349609375
Batch 53/64 loss: -2.729302406311035
Batch 54/64 loss: -2.817744255065918
Batch 55/64 loss: -2.614142417907715
Batch 56/64 loss: -2.6265344619750977
Batch 57/64 loss: -2.3244895935058594
Batch 58/64 loss: -2.950497627258301
Batch 59/64 loss: -2.6918020248413086
Batch 60/64 loss: -2.8038978576660156
Batch 61/64 loss: -2.9104108810424805
Batch 62/64 loss: -2.809581756591797
Batch 63/64 loss: -2.927779197692871
Batch 64/64 loss: -7.211581230163574
Epoch 274  Train loss: -2.8434604158588486  Val loss: -3.041856313489147
Epoch 275
-------------------------------
Batch 1/64 loss: -2.994720458984375
Batch 2/64 loss: -2.952752113342285
Batch 3/64 loss: -2.8760433197021484
Batch 4/64 loss: -2.938783645629883
Batch 5/64 loss: -2.7434511184692383
Batch 6/64 loss: -2.8341522216796875
Batch 7/64 loss: -2.572556495666504
Batch 8/64 loss: -2.7064828872680664
Batch 9/64 loss: -2.791017532348633
Batch 10/64 loss: -2.9176130294799805
Batch 11/64 loss: -2.6608266830444336
Batch 12/64 loss: -2.719095230102539
Batch 13/64 loss: -2.586362838745117
Batch 14/64 loss: -2.758246421813965
Batch 15/64 loss: -2.8009119033813477
Batch 16/64 loss: -2.715275764465332
Batch 17/64 loss: -2.5659399032592773
Batch 18/64 loss: -2.532233238220215
Batch 19/64 loss: -2.8085479736328125
Batch 20/64 loss: -2.745250701904297
Batch 21/64 loss: -2.86080265045166
Batch 22/64 loss: -2.9294490814208984
Batch 23/64 loss: -2.7173328399658203
Batch 24/64 loss: -2.833956718444824
Batch 25/64 loss: -2.5423965454101562
Batch 26/64 loss: -2.864564895629883
Batch 27/64 loss: -2.876972198486328
Batch 28/64 loss: -3.0088558197021484
Batch 29/64 loss: -2.7194061279296875
Batch 30/64 loss: -2.8501672744750977
Batch 31/64 loss: -2.640017509460449
Batch 32/64 loss: -2.7086963653564453
Batch 33/64 loss: -2.755906105041504
Batch 34/64 loss: -2.818826675415039
Batch 35/64 loss: -2.8303728103637695
Batch 36/64 loss: -2.739166259765625
Batch 37/64 loss: -2.591899871826172
Batch 38/64 loss: -2.7150936126708984
Batch 39/64 loss: -2.7505950927734375
Batch 40/64 loss: -2.9401330947875977
Batch 41/64 loss: -2.6811180114746094
Batch 42/64 loss: -2.669384002685547
Batch 43/64 loss: -2.5904016494750977
Batch 44/64 loss: -2.8987417221069336
Batch 45/64 loss: -2.7476415634155273
Batch 46/64 loss: -2.842721939086914
Batch 47/64 loss: -2.9425745010375977
Batch 48/64 loss: -2.7903003692626953
Batch 49/64 loss: -2.908940315246582
Batch 50/64 loss: -2.5754318237304688
Batch 51/64 loss: -2.8650522232055664
Batch 52/64 loss: -2.7833051681518555
Batch 53/64 loss: -2.828972816467285
Batch 54/64 loss: -2.7716970443725586
Batch 55/64 loss: -2.797513008117676
Batch 56/64 loss: -2.688037872314453
Batch 57/64 loss: -2.937899589538574
Batch 58/64 loss: -3.0210466384887695
Batch 59/64 loss: -2.7748680114746094
Batch 60/64 loss: -3.0103302001953125
Batch 61/64 loss: -2.9353761672973633
Batch 62/64 loss: -2.7705202102661133
Batch 63/64 loss: -2.4864416122436523
Batch 64/64 loss: -7.364056587219238
Epoch 275  Train loss: -2.8353919047935334  Val loss: -3.0562712417025746
Epoch 276
-------------------------------
Batch 1/64 loss: -2.938730239868164
Batch 2/64 loss: -2.7520456314086914
Batch 3/64 loss: -3.050381660461426
Batch 4/64 loss: -2.660318374633789
Batch 5/64 loss: -2.6835460662841797
Batch 6/64 loss: -2.856903076171875
Batch 7/64 loss: -3.0259313583374023
Batch 8/64 loss: -2.8040771484375
Batch 9/64 loss: -2.8800277709960938
Batch 10/64 loss: -2.6531991958618164
Batch 11/64 loss: -3.0173397064208984
Batch 12/64 loss: -2.870065689086914
Batch 13/64 loss: -3.033686637878418
Batch 14/64 loss: -2.9980506896972656
Batch 15/64 loss: -2.850672721862793
Batch 16/64 loss: -2.543459892272949
Batch 17/64 loss: -2.6958932876586914
Batch 18/64 loss: -2.64267635345459
Batch 19/64 loss: -2.787477493286133
Batch 20/64 loss: -2.9737510681152344
Batch 21/64 loss: -3.0064563751220703
Batch 22/64 loss: -3.0220947265625
Batch 23/64 loss: -3.102402687072754
Batch 24/64 loss: -2.6356563568115234
Batch 25/64 loss: -2.8603954315185547
Batch 26/64 loss: -2.352614402770996
Batch 27/64 loss: -2.7209243774414062
Batch 28/64 loss: -2.903841018676758
Batch 29/64 loss: -2.930093765258789
Batch 30/64 loss: -2.7751665115356445
Batch 31/64 loss: -2.745290756225586
Batch 32/64 loss: -2.9079818725585938
Batch 33/64 loss: -2.955768585205078
Batch 34/64 loss: -2.6581859588623047
Batch 35/64 loss: -2.8938474655151367
Batch 36/64 loss: -2.888641357421875
Batch 37/64 loss: -2.7699804306030273
Batch 38/64 loss: -2.8248910903930664
Batch 39/64 loss: -2.8265647888183594
Batch 40/64 loss: -3.1761932373046875
Batch 41/64 loss: -2.7928991317749023
Batch 42/64 loss: -2.8050994873046875
Batch 43/64 loss: -2.811741828918457
Batch 44/64 loss: -2.703218460083008
Batch 45/64 loss: -2.663299560546875
Batch 46/64 loss: -2.722187042236328
Batch 47/64 loss: -2.1872243881225586
Batch 48/64 loss: -2.776026725769043
Batch 49/64 loss: -2.971390724182129
Batch 50/64 loss: -2.709228515625
Batch 51/64 loss: -2.836686134338379
Batch 52/64 loss: -2.828622817993164
Batch 53/64 loss: -2.7958993911743164
Batch 54/64 loss: -2.798206329345703
Batch 55/64 loss: -2.885645866394043
Batch 56/64 loss: -2.7583227157592773
Batch 57/64 loss: -2.9132909774780273
Batch 58/64 loss: -2.411952018737793
Batch 59/64 loss: -3.0027313232421875
Batch 60/64 loss: -2.873965263366699
Batch 61/64 loss: -2.821941375732422
Batch 62/64 loss: -2.566516876220703
Batch 63/64 loss: -2.9524850845336914
Batch 64/64 loss: -7.184778690338135
Epoch 276  Train loss: -2.865135550031475  Val loss: -3.1415080041000523
Saving best model, epoch: 276
Epoch 277
-------------------------------
Batch 1/64 loss: -2.8324289321899414
Batch 2/64 loss: -2.905233383178711
Batch 3/64 loss: -2.8338680267333984
Batch 4/64 loss: -2.9510040283203125
Batch 5/64 loss: -2.884908676147461
Batch 6/64 loss: -2.464198112487793
Batch 7/64 loss: -2.9032506942749023
Batch 8/64 loss: -3.075986862182617
Batch 9/64 loss: -2.784425735473633
Batch 10/64 loss: -2.9873533248901367
Batch 11/64 loss: -2.749140739440918
Batch 12/64 loss: -2.76987361907959
Batch 13/64 loss: -2.8961105346679688
Batch 14/64 loss: -2.5301361083984375
Batch 15/64 loss: -2.931547164916992
Batch 16/64 loss: -2.5053348541259766
Batch 17/64 loss: -2.5337648391723633
Batch 18/64 loss: -3.0334243774414062
Batch 19/64 loss: -2.958308219909668
Batch 20/64 loss: -2.466189384460449
Batch 21/64 loss: -2.7224655151367188
Batch 22/64 loss: -2.657406806945801
Batch 23/64 loss: -2.825263023376465
Batch 24/64 loss: -2.902714729309082
Batch 25/64 loss: -2.9038639068603516
Batch 26/64 loss: -2.9680519104003906
Batch 27/64 loss: -2.9799671173095703
Batch 28/64 loss: -2.6851139068603516
Batch 29/64 loss: -2.9645442962646484
Batch 30/64 loss: -2.8858280181884766
Batch 31/64 loss: -2.857356071472168
Batch 32/64 loss: -2.8132991790771484
Batch 33/64 loss: -2.8744516372680664
Batch 34/64 loss: -2.57059383392334
Batch 35/64 loss: -2.918971061706543
Batch 36/64 loss: -3.096674919128418
Batch 37/64 loss: -2.7827415466308594
Batch 38/64 loss: -2.713019371032715
Batch 39/64 loss: -2.883429527282715
Batch 40/64 loss: -2.8350095748901367
Batch 41/64 loss: -2.8545284271240234
Batch 42/64 loss: -2.961172103881836
Batch 43/64 loss: -2.9853715896606445
Batch 44/64 loss: -2.9304656982421875
Batch 45/64 loss: -2.8991260528564453
Batch 46/64 loss: -2.7342309951782227
Batch 47/64 loss: -2.4208507537841797
Batch 48/64 loss: -2.78286075592041
Batch 49/64 loss: -2.8523263931274414
Batch 50/64 loss: -2.896233558654785
Batch 51/64 loss: -2.7055368423461914
Batch 52/64 loss: -2.791219711303711
Batch 53/64 loss: -2.879314422607422
Batch 54/64 loss: -2.746511459350586
Batch 55/64 loss: -2.6921958923339844
Batch 56/64 loss: -2.8674192428588867
Batch 57/64 loss: -3.009725570678711
Batch 58/64 loss: -2.9413185119628906
Batch 59/64 loss: -2.636829376220703
Batch 60/64 loss: -2.7132644653320312
Batch 61/64 loss: -2.7254180908203125
Batch 62/64 loss: -2.8305931091308594
Batch 63/64 loss: -2.890838623046875
Batch 64/64 loss: -7.489959239959717
Epoch 277  Train loss: -2.8737580336776434  Val loss: -2.9905205428395485
Epoch 278
-------------------------------
Batch 1/64 loss: -2.744051933288574
Batch 2/64 loss: -2.851705551147461
Batch 3/64 loss: -2.765512466430664
Batch 4/64 loss: -2.7709226608276367
Batch 5/64 loss: -2.7394142150878906
Batch 6/64 loss: -2.7227306365966797
Batch 7/64 loss: -2.8296899795532227
Batch 8/64 loss: -2.6307601928710938
Batch 9/64 loss: -2.907994270324707
Batch 10/64 loss: -2.783061981201172
Batch 11/64 loss: -2.850417137145996
Batch 12/64 loss: -2.811295509338379
Batch 13/64 loss: -3.012089729309082
Batch 14/64 loss: -3.0559911727905273
Batch 15/64 loss: -2.7973222732543945
Batch 16/64 loss: -2.8010683059692383
Batch 17/64 loss: -2.693966865539551
Batch 18/64 loss: -2.766681671142578
Batch 19/64 loss: -2.899883270263672
Batch 20/64 loss: -2.758204460144043
Batch 21/64 loss: -2.7202272415161133
Batch 22/64 loss: -2.823969841003418
Batch 23/64 loss: -2.829573631286621
Batch 24/64 loss: -2.8909997940063477
Batch 25/64 loss: -2.408720016479492
Batch 26/64 loss: -2.800980567932129
Batch 27/64 loss: -2.458892822265625
Batch 28/64 loss: -2.903719902038574
Batch 29/64 loss: -2.3677139282226562
Batch 30/64 loss: -2.775994300842285
Batch 31/64 loss: -2.9163198471069336
Batch 32/64 loss: -2.809001922607422
Batch 33/64 loss: -2.727283477783203
Batch 34/64 loss: -3.0062808990478516
Batch 35/64 loss: -2.9915876388549805
Batch 36/64 loss: -2.8214550018310547
Batch 37/64 loss: -2.8881959915161133
Batch 38/64 loss: -2.700298309326172
Batch 39/64 loss: -2.961515426635742
Batch 40/64 loss: -2.409146308898926
Batch 41/64 loss: -2.955592155456543
Batch 42/64 loss: -2.9144983291625977
Batch 43/64 loss: -2.6090917587280273
Batch 44/64 loss: -2.9484777450561523
Batch 45/64 loss: -2.7231645584106445
Batch 46/64 loss: -2.8631153106689453
Batch 47/64 loss: -2.708420753479004
Batch 48/64 loss: -2.8779735565185547
Batch 49/64 loss: -2.7419357299804688
Batch 50/64 loss: -2.815980911254883
Batch 51/64 loss: -2.8448314666748047
Batch 52/64 loss: -2.8143434524536133
Batch 53/64 loss: -2.724562644958496
Batch 54/64 loss: -2.9508419036865234
Batch 55/64 loss: -2.680558204650879
Batch 56/64 loss: -2.6932849884033203
Batch 57/64 loss: -3.0456581115722656
Batch 58/64 loss: -2.6547765731811523
Batch 59/64 loss: -2.8775291442871094
Batch 60/64 loss: -2.7858333587646484
Batch 61/64 loss: -2.9836959838867188
Batch 62/64 loss: -2.8458375930786133
Batch 63/64 loss: -2.8271379470825195
Batch 64/64 loss: -7.456433296203613
Epoch 278  Train loss: -2.853084051842783  Val loss: -2.9966673179180763
Epoch 279
-------------------------------
Batch 1/64 loss: -2.7978410720825195
Batch 2/64 loss: -2.9930038452148438
Batch 3/64 loss: -2.4443206787109375
Batch 4/64 loss: -2.7086658477783203
Batch 5/64 loss: -2.589773178100586
Batch 6/64 loss: -2.9599123001098633
Batch 7/64 loss: -2.634777069091797
Batch 8/64 loss: -3.065570831298828
Batch 9/64 loss: -2.7240772247314453
Batch 10/64 loss: -2.759402275085449
Batch 11/64 loss: -2.788848876953125
Batch 12/64 loss: -2.8715877532958984
Batch 13/64 loss: -2.9373464584350586
Batch 14/64 loss: -2.956934928894043
Batch 15/64 loss: -2.8872251510620117
Batch 16/64 loss: -2.9646453857421875
Batch 17/64 loss: -2.8207788467407227
Batch 18/64 loss: -2.9862537384033203
Batch 19/64 loss: -2.565526008605957
Batch 20/64 loss: -2.9882049560546875
Batch 21/64 loss: -2.929842948913574
Batch 22/64 loss: -3.003706932067871
Batch 23/64 loss: -2.911606788635254
Batch 24/64 loss: -2.588346481323242
Batch 25/64 loss: -2.965177536010742
Batch 26/64 loss: -2.837773323059082
Batch 27/64 loss: -2.6281747817993164
Batch 28/64 loss: -2.7005910873413086
Batch 29/64 loss: -2.9387502670288086
Batch 30/64 loss: -2.738938331604004
Batch 31/64 loss: -2.9505367279052734
Batch 32/64 loss: -2.9807662963867188
Batch 33/64 loss: -2.6267013549804688
Batch 34/64 loss: -2.7610015869140625
Batch 35/64 loss: -2.834845542907715
Batch 36/64 loss: -2.7359237670898438
Batch 37/64 loss: -2.888216972351074
Batch 38/64 loss: -2.6811647415161133
Batch 39/64 loss: -2.831056594848633
Batch 40/64 loss: -2.833740234375
Batch 41/64 loss: -3.0061588287353516
Batch 42/64 loss: -2.998776435852051
Batch 43/64 loss: -2.747922897338867
Batch 44/64 loss: -3.0220508575439453
Batch 45/64 loss: -2.6609296798706055
Batch 46/64 loss: -2.8313426971435547
Batch 47/64 loss: -2.747882843017578
Batch 48/64 loss: -2.859635353088379
Batch 49/64 loss: -2.727593421936035
Batch 50/64 loss: -3.000922203063965
Batch 51/64 loss: -2.697453498840332
Batch 52/64 loss: -2.7180700302124023
Batch 53/64 loss: -3.039586067199707
Batch 54/64 loss: -2.784287452697754
Batch 55/64 loss: -2.7099618911743164
Batch 56/64 loss: -2.970709800720215
Batch 57/64 loss: -2.7896652221679688
Batch 58/64 loss: -2.9375104904174805
Batch 59/64 loss: -2.793715476989746
Batch 60/64 loss: -2.686237335205078
Batch 61/64 loss: -2.7117958068847656
Batch 62/64 loss: -2.9180545806884766
Batch 63/64 loss: -2.7455453872680664
Batch 64/64 loss: -7.409980297088623
Epoch 279  Train loss: -2.8780368973227106  Val loss: -3.0749651328804566
Epoch 280
-------------------------------
Batch 1/64 loss: -2.871875762939453
Batch 2/64 loss: -2.90256404876709
Batch 3/64 loss: -2.8161659240722656
Batch 4/64 loss: -2.972580909729004
Batch 5/64 loss: -3.0387439727783203
Batch 6/64 loss: -2.8417234420776367
Batch 7/64 loss: -2.643404960632324
Batch 8/64 loss: -2.564138412475586
Batch 9/64 loss: -2.6828699111938477
Batch 10/64 loss: -2.94256591796875
Batch 11/64 loss: -2.663468360900879
Batch 12/64 loss: -2.4774160385131836
Batch 13/64 loss: -2.8179893493652344
Batch 14/64 loss: -2.5416975021362305
Batch 15/64 loss: -2.812192916870117
Batch 16/64 loss: -2.999691963195801
Batch 17/64 loss: -3.043522834777832
Batch 18/64 loss: -2.639850616455078
Batch 19/64 loss: -2.811753273010254
Batch 20/64 loss: -3.022125244140625
Batch 21/64 loss: -2.866448402404785
Batch 22/64 loss: -2.7430992126464844
Batch 23/64 loss: -3.0387067794799805
Batch 24/64 loss: -2.8205699920654297
Batch 25/64 loss: -2.8944501876831055
Batch 26/64 loss: -3.026317596435547
Batch 27/64 loss: -2.70113468170166
Batch 28/64 loss: -2.7690858840942383
Batch 29/64 loss: -2.819380760192871
Batch 30/64 loss: -2.8348331451416016
Batch 31/64 loss: -2.802248001098633
Batch 32/64 loss: -2.8554210662841797
Batch 33/64 loss: -2.6203813552856445
Batch 34/64 loss: -2.7099952697753906
Batch 35/64 loss: -2.668320655822754
Batch 36/64 loss: -2.928213119506836
Batch 37/64 loss: -2.8070430755615234
Batch 38/64 loss: -2.850447654724121
Batch 39/64 loss: -2.872051239013672
Batch 40/64 loss: -3.111532211303711
Batch 41/64 loss: -2.9274330139160156
Batch 42/64 loss: -2.905400276184082
Batch 43/64 loss: -2.666092872619629
Batch 44/64 loss: -3.0343570709228516
Batch 45/64 loss: -2.674884796142578
Batch 46/64 loss: -2.9711570739746094
Batch 47/64 loss: -2.999091148376465
Batch 48/64 loss: -3.049386978149414
Batch 49/64 loss: -2.8561267852783203
Batch 50/64 loss: -2.7297325134277344
Batch 51/64 loss: -2.792325019836426
Batch 52/64 loss: -2.6217784881591797
Batch 53/64 loss: -2.7774248123168945
Batch 54/64 loss: -2.927145004272461
Batch 55/64 loss: -2.8375940322875977
Batch 56/64 loss: -2.8294382095336914
Batch 57/64 loss: -2.6559362411499023
Batch 58/64 loss: -2.348968505859375
Batch 59/64 loss: -2.93338680267334
Batch 60/64 loss: -3.049899101257324
Batch 61/64 loss: -2.7545928955078125
Batch 62/64 loss: -3.049527168273926
Batch 63/64 loss: -2.61529541015625
Batch 64/64 loss: -7.35527229309082
Epoch 280  Train loss: -2.8763835308598535  Val loss: -2.993947386331984
Epoch 281
-------------------------------
Batch 1/64 loss: -2.490022659301758
Batch 2/64 loss: -2.9557151794433594
Batch 3/64 loss: -2.6788673400878906
Batch 4/64 loss: -2.7266616821289062
Batch 5/64 loss: -2.83376407623291
Batch 6/64 loss: -2.9526309967041016
Batch 7/64 loss: -2.922323226928711
Batch 8/64 loss: -2.2908077239990234
Batch 9/64 loss: -2.7847366333007812
Batch 10/64 loss: -2.8758926391601562
Batch 11/64 loss: -2.6819705963134766
Batch 12/64 loss: -2.530191421508789
Batch 13/64 loss: -2.579343795776367
Batch 14/64 loss: -2.3871097564697266
Batch 15/64 loss: -2.6299991607666016
Batch 16/64 loss: -2.7781763076782227
Batch 17/64 loss: -2.9684572219848633
Batch 18/64 loss: -2.9231691360473633
Batch 19/64 loss: -2.592562675476074
Batch 20/64 loss: -2.828601837158203
Batch 21/64 loss: -2.926607131958008
Batch 22/64 loss: -2.9272003173828125
Batch 23/64 loss: -2.69295597076416
Batch 24/64 loss: -2.971341133117676
Batch 25/64 loss: -2.913609504699707
Batch 26/64 loss: -2.796015739440918
Batch 27/64 loss: -3.1302366256713867
Batch 28/64 loss: -3.0306663513183594
Batch 29/64 loss: -2.7473697662353516
Batch 30/64 loss: -2.540097236633301
Batch 31/64 loss: -2.6089906692504883
Batch 32/64 loss: -2.51450252532959
Batch 33/64 loss: -2.660769462585449
Batch 34/64 loss: -2.727828025817871
Batch 35/64 loss: -2.8288965225219727
Batch 36/64 loss: -2.811311721801758
Batch 37/64 loss: -2.802431106567383
Batch 38/64 loss: -2.894463539123535
Batch 39/64 loss: -2.937375068664551
Batch 40/64 loss: -2.6835289001464844
Batch 41/64 loss: -2.9382553100585938
Batch 42/64 loss: -3.0096254348754883
Batch 43/64 loss: -2.636920928955078
Batch 44/64 loss: -2.6097412109375
Batch 45/64 loss: -2.57993221282959
Batch 46/64 loss: -2.794870376586914
Batch 47/64 loss: -2.6706151962280273
Batch 48/64 loss: -2.752354621887207
Batch 49/64 loss: -2.6095809936523438
Batch 50/64 loss: -2.525554656982422
Batch 51/64 loss: -2.830203056335449
Batch 52/64 loss: -2.8023500442504883
Batch 53/64 loss: -2.8503847122192383
Batch 54/64 loss: -2.9481277465820312
Batch 55/64 loss: -2.944112777709961
Batch 56/64 loss: -2.9741830825805664
Batch 57/64 loss: -2.822662353515625
Batch 58/64 loss: -2.896839141845703
Batch 59/64 loss: -3.008625030517578
Batch 60/64 loss: -2.8608808517456055
Batch 61/64 loss: -2.5372543334960938
Batch 62/64 loss: -2.7268285751342773
Batch 63/64 loss: -2.936208724975586
Batch 64/64 loss: -7.289926528930664
Epoch 281  Train loss: -2.828090316174077  Val loss: -3.0644671777679338
Epoch 282
-------------------------------
Batch 1/64 loss: -2.8001527786254883
Batch 2/64 loss: -2.625967025756836
Batch 3/64 loss: -2.954629898071289
Batch 4/64 loss: -2.769287109375
Batch 5/64 loss: -2.8902969360351562
Batch 6/64 loss: -2.919198989868164
Batch 7/64 loss: -2.726511001586914
Batch 8/64 loss: -2.8763351440429688
Batch 9/64 loss: -2.8470888137817383
Batch 10/64 loss: -2.644200325012207
Batch 11/64 loss: -2.8156347274780273
Batch 12/64 loss: -2.7784175872802734
Batch 13/64 loss: -3.099055767059326
Batch 14/64 loss: -2.755253791809082
Batch 15/64 loss: -2.727992057800293
Batch 16/64 loss: -2.9507017135620117
Batch 17/64 loss: -2.911783218383789
Batch 18/64 loss: -2.8482627868652344
Batch 19/64 loss: -2.8937339782714844
Batch 20/64 loss: -2.9694671630859375
Batch 21/64 loss: -2.667294502258301
Batch 22/64 loss: -2.7329111099243164
Batch 23/64 loss: -2.864142417907715
Batch 24/64 loss: -2.948044776916504
Batch 25/64 loss: -2.864853858947754
Batch 26/64 loss: -2.9588117599487305
Batch 27/64 loss: -2.6088008880615234
Batch 28/64 loss: -2.762394905090332
Batch 29/64 loss: -2.1685104370117188
Batch 30/64 loss: -2.5322914123535156
Batch 31/64 loss: -2.88303279876709
Batch 32/64 loss: -2.842036247253418
Batch 33/64 loss: -2.6363391876220703
Batch 34/64 loss: -3.0285892486572266
Batch 35/64 loss: -2.8446712493896484
Batch 36/64 loss: -2.269622802734375
Batch 37/64 loss: -3.024176597595215
Batch 38/64 loss: -2.799640655517578
Batch 39/64 loss: -2.805985450744629
Batch 40/64 loss: -2.603549003601074
Batch 41/64 loss: -2.7447261810302734
Batch 42/64 loss: -2.7077903747558594
Batch 43/64 loss: -2.8068675994873047
Batch 44/64 loss: -2.8617982864379883
Batch 45/64 loss: -2.6351499557495117
Batch 46/64 loss: -2.959691047668457
Batch 47/64 loss: -2.987494468688965
Batch 48/64 loss: -2.763554573059082
Batch 49/64 loss: -3.118605613708496
Batch 50/64 loss: -2.705002784729004
Batch 51/64 loss: -2.7883501052856445
Batch 52/64 loss: -2.9933595657348633
Batch 53/64 loss: -2.9375991821289062
Batch 54/64 loss: -2.4900474548339844
Batch 55/64 loss: -2.893861770629883
Batch 56/64 loss: -2.6140928268432617
Batch 57/64 loss: -2.816683769226074
Batch 58/64 loss: -2.913135528564453
Batch 59/64 loss: -2.9311981201171875
Batch 60/64 loss: -2.4479875564575195
Batch 61/64 loss: -3.024186134338379
Batch 62/64 loss: -2.798666000366211
Batch 63/64 loss: -2.6685256958007812
Batch 64/64 loss: -7.22586727142334
Epoch 282  Train loss: -2.8498422772276637  Val loss: -3.0058004372718
Epoch 283
-------------------------------
Batch 1/64 loss: -2.8727264404296875
Batch 2/64 loss: -2.941462516784668
Batch 3/64 loss: -2.7664079666137695
Batch 4/64 loss: -2.479290008544922
Batch 5/64 loss: -2.5382394790649414
Batch 6/64 loss: -2.818666458129883
Batch 7/64 loss: -2.8848867416381836
Batch 8/64 loss: -3.0110130310058594
Batch 9/64 loss: -2.748795509338379
Batch 10/64 loss: -2.6764564514160156
Batch 11/64 loss: -2.9647293090820312
Batch 12/64 loss: -2.9388856887817383
Batch 13/64 loss: -2.7137508392333984
Batch 14/64 loss: -2.8248281478881836
Batch 15/64 loss: -2.5812244415283203
Batch 16/64 loss: -2.7233457565307617
Batch 17/64 loss: -2.4588871002197266
Batch 18/64 loss: -2.5812768936157227
Batch 19/64 loss: -2.6843090057373047
Batch 20/64 loss: -2.9457807540893555
Batch 21/64 loss: -2.9497604370117188
Batch 22/64 loss: -2.945720672607422
Batch 23/64 loss: -2.701570510864258
Batch 24/64 loss: -3.091157913208008
Batch 25/64 loss: -2.9395618438720703
Batch 26/64 loss: -3.0389814376831055
Batch 27/64 loss: -2.9640846252441406
Batch 28/64 loss: -2.834136962890625
Batch 29/64 loss: -2.8997936248779297
Batch 30/64 loss: -2.8386058807373047
Batch 31/64 loss: -2.854424476623535
Batch 32/64 loss: -2.7062015533447266
Batch 33/64 loss: -2.730396270751953
Batch 34/64 loss: -2.9048805236816406
Batch 35/64 loss: -2.8506555557250977
Batch 36/64 loss: -3.0043468475341797
Batch 37/64 loss: -2.8145971298217773
Batch 38/64 loss: -2.7554616928100586
Batch 39/64 loss: -2.9179811477661133
Batch 40/64 loss: -2.8229055404663086
Batch 41/64 loss: -2.8622093200683594
Batch 42/64 loss: -2.698995590209961
Batch 43/64 loss: -2.8667097091674805
Batch 44/64 loss: -2.9946107864379883
Batch 45/64 loss: -2.4825897216796875
Batch 46/64 loss: -2.4084110260009766
Batch 47/64 loss: -2.975192070007324
Batch 48/64 loss: -2.8913955688476562
Batch 49/64 loss: -2.6748580932617188
Batch 50/64 loss: -2.8239669799804688
Batch 51/64 loss: -2.7431631088256836
Batch 52/64 loss: -2.870467185974121
Batch 53/64 loss: -2.8935489654541016
Batch 54/64 loss: -2.9891357421875
Batch 55/64 loss: -2.753209114074707
Batch 56/64 loss: -2.611858367919922
Batch 57/64 loss: -2.609135627746582
Batch 58/64 loss: -2.8849916458129883
Batch 59/64 loss: -2.824801445007324
Batch 60/64 loss: -2.9416418075561523
Batch 61/64 loss: -2.7453203201293945
Batch 62/64 loss: -2.670302391052246
Batch 63/64 loss: -3.0543317794799805
Batch 64/64 loss: -7.4369916915893555
Epoch 283  Train loss: -2.863823958004222  Val loss: -3.0467551057691016
Epoch 284
-------------------------------
Batch 1/64 loss: -3.043118476867676
Batch 2/64 loss: -2.9785242080688477
Batch 3/64 loss: -2.7433395385742188
Batch 4/64 loss: -2.8028650283813477
Batch 5/64 loss: -2.758106231689453
Batch 6/64 loss: -2.807450294494629
Batch 7/64 loss: -2.725884437561035
Batch 8/64 loss: -2.7151613235473633
Batch 9/64 loss: -3.0377197265625
Batch 10/64 loss: -2.7476978302001953
Batch 11/64 loss: -2.8602914810180664
Batch 12/64 loss: -2.705991744995117
Batch 13/64 loss: -2.8681631088256836
Batch 14/64 loss: -2.9482507705688477
Batch 15/64 loss: -2.916792869567871
Batch 16/64 loss: -2.86464786529541
Batch 17/64 loss: -2.925417900085449
Batch 18/64 loss: -2.963512420654297
Batch 19/64 loss: -2.828977584838867
Batch 20/64 loss: -2.6358442306518555
Batch 21/64 loss: -2.9139204025268555
Batch 22/64 loss: -2.8637685775756836
Batch 23/64 loss: -2.6723899841308594
Batch 24/64 loss: -2.918759346008301
Batch 25/64 loss: -2.783829689025879
Batch 26/64 loss: -3.1094655990600586
Batch 27/64 loss: -2.8844289779663086
Batch 28/64 loss: -2.562713623046875
Batch 29/64 loss: -3.049677848815918
Batch 30/64 loss: -2.43375301361084
Batch 31/64 loss: -2.8420886993408203
Batch 32/64 loss: -2.7811899185180664
Batch 33/64 loss: -2.6834592819213867
Batch 34/64 loss: -2.841362953186035
Batch 35/64 loss: -2.546274185180664
Batch 36/64 loss: -2.8866376876831055
Batch 37/64 loss: -2.768162727355957
Batch 38/64 loss: -2.6181907653808594
Batch 39/64 loss: -2.7920541763305664
Batch 40/64 loss: -2.8028039932250977
Batch 41/64 loss: -2.8273258209228516
Batch 42/64 loss: -2.679922103881836
Batch 43/64 loss: -2.788003921508789
Batch 44/64 loss: -2.9191951751708984
Batch 45/64 loss: -2.7949581146240234
Batch 46/64 loss: -2.9627933502197266
Batch 47/64 loss: -2.7194862365722656
Batch 48/64 loss: -2.812924385070801
Batch 49/64 loss: -3.000049591064453
Batch 50/64 loss: -2.714472770690918
Batch 51/64 loss: -3.013113021850586
Batch 52/64 loss: -2.7991981506347656
Batch 53/64 loss: -2.791545867919922
Batch 54/64 loss: -2.738292694091797
Batch 55/64 loss: -2.7776317596435547
Batch 56/64 loss: -2.8944883346557617
Batch 57/64 loss: -2.945937156677246
Batch 58/64 loss: -2.875438690185547
Batch 59/64 loss: -2.9642333984375
Batch 60/64 loss: -2.886693000793457
Batch 61/64 loss: -2.7080984115600586
Batch 62/64 loss: -2.7780513763427734
Batch 63/64 loss: -2.7713088989257812
Batch 64/64 loss: -7.075646877288818
Epoch 284  Train loss: -2.872197426066679  Val loss: -3.0704906240771317
Epoch 285
-------------------------------
Batch 1/64 loss: -2.9492712020874023
Batch 2/64 loss: -2.7885560989379883
Batch 3/64 loss: -2.819276809692383
Batch 4/64 loss: -2.7851152420043945
Batch 5/64 loss: -2.7540435791015625
Batch 6/64 loss: -2.8939781188964844
Batch 7/64 loss: -2.731980323791504
Batch 8/64 loss: -2.7160768508911133
Batch 9/64 loss: -2.735226631164551
Batch 10/64 loss: -2.965226173400879
Batch 11/64 loss: -2.9777517318725586
Batch 12/64 loss: -2.869023323059082
Batch 13/64 loss: -2.859074592590332
Batch 14/64 loss: -2.9828500747680664
Batch 15/64 loss: -2.761347770690918
Batch 16/64 loss: -2.6546764373779297
Batch 17/64 loss: -2.669426918029785
Batch 18/64 loss: -2.79052734375
Batch 19/64 loss: -3.0367088317871094
Batch 20/64 loss: -2.2092723846435547
Batch 21/64 loss: -2.8831634521484375
Batch 22/64 loss: -2.70229434967041
Batch 23/64 loss: -2.7961349487304688
Batch 24/64 loss: -2.639187812805176
Batch 25/64 loss: -2.8312931060791016
Batch 26/64 loss: -2.6438169479370117
Batch 27/64 loss: -2.307864189147949
Batch 28/64 loss: -2.8396711349487305
Batch 29/64 loss: -3.003246307373047
Batch 30/64 loss: -2.918794631958008
Batch 31/64 loss: -3.0395307540893555
Batch 32/64 loss: -2.593362808227539
Batch 33/64 loss: -2.8644933700561523
Batch 34/64 loss: -2.601346969604492
Batch 35/64 loss: -2.7592363357543945
Batch 36/64 loss: -2.5275726318359375
Batch 37/64 loss: -2.6131038665771484
Batch 38/64 loss: -2.747036933898926
Batch 39/64 loss: -2.8582420349121094
Batch 40/64 loss: -2.8781890869140625
Batch 41/64 loss: -2.895437240600586
Batch 42/64 loss: -2.9537010192871094
Batch 43/64 loss: -2.8939361572265625
Batch 44/64 loss: -2.8222856521606445
Batch 45/64 loss: -2.6834802627563477
Batch 46/64 loss: -2.993832588195801
Batch 47/64 loss: -2.732563018798828
Batch 48/64 loss: -2.902371406555176
Batch 49/64 loss: -2.640500068664551
Batch 50/64 loss: -2.818293571472168
Batch 51/64 loss: -3.0520200729370117
Batch 52/64 loss: -2.956936836242676
Batch 53/64 loss: -2.943131446838379
Batch 54/64 loss: -2.7139358520507812
Batch 55/64 loss: -2.8583126068115234
Batch 56/64 loss: -2.6186752319335938
Batch 57/64 loss: -2.8217973709106445
Batch 58/64 loss: -2.6567440032958984
Batch 59/64 loss: -2.4171342849731445
Batch 60/64 loss: -2.803241729736328
Batch 61/64 loss: -2.633896827697754
Batch 62/64 loss: -2.763911247253418
Batch 63/64 loss: -2.9372148513793945
Batch 64/64 loss: -7.4093122482299805
Epoch 285  Train loss: -2.840271837571088  Val loss: -3.0206165117086825
Epoch 286
-------------------------------
Batch 1/64 loss: -2.955913543701172
Batch 2/64 loss: -2.6305627822875977
Batch 3/64 loss: -2.8271045684814453
Batch 4/64 loss: -3.063783645629883
Batch 5/64 loss: -2.942230224609375
Batch 6/64 loss: -2.9591331481933594
Batch 7/64 loss: -2.7794322967529297
Batch 8/64 loss: -2.718682289123535
Batch 9/64 loss: -2.686748504638672
Batch 10/64 loss: -2.75991153717041
Batch 11/64 loss: -2.7989120483398438
Batch 12/64 loss: -3.006010055541992
Batch 13/64 loss: -2.6288986206054688
Batch 14/64 loss: -2.649386405944824
Batch 15/64 loss: -2.853512763977051
Batch 16/64 loss: -2.783331871032715
Batch 17/64 loss: -2.8593692779541016
Batch 18/64 loss: -2.8223094940185547
Batch 19/64 loss: -2.7751455307006836
Batch 20/64 loss: -2.574143409729004
Batch 21/64 loss: -2.9515151977539062
Batch 22/64 loss: -2.937448501586914
Batch 23/64 loss: -2.8488845825195312
Batch 24/64 loss: -2.6121292114257812
Batch 25/64 loss: -2.962369918823242
Batch 26/64 loss: -2.735227584838867
Batch 27/64 loss: -2.9253625869750977
Batch 28/64 loss: -2.5172319412231445
Batch 29/64 loss: -3.088315010070801
Batch 30/64 loss: -2.3233489990234375
Batch 31/64 loss: -2.7931509017944336
Batch 32/64 loss: -2.7322139739990234
Batch 33/64 loss: -2.6504297256469727
Batch 34/64 loss: -2.511075973510742
Batch 35/64 loss: -2.921086311340332
Batch 36/64 loss: -2.7462148666381836
Batch 37/64 loss: -2.9635915756225586
Batch 38/64 loss: -2.4753494262695312
Batch 39/64 loss: -2.893242835998535
Batch 40/64 loss: -2.947676658630371
Batch 41/64 loss: -2.9977235794067383
Batch 42/64 loss: -3.0525102615356445
Batch 43/64 loss: -2.7162437438964844
Batch 44/64 loss: -2.588761329650879
Batch 45/64 loss: -2.923609733581543
Batch 46/64 loss: -2.6267786026000977
Batch 47/64 loss: -3.048312187194824
Batch 48/64 loss: -2.722076416015625
Batch 49/64 loss: -2.8907318115234375
Batch 50/64 loss: -2.877981185913086
Batch 51/64 loss: -2.9001054763793945
Batch 52/64 loss: -2.7787914276123047
Batch 53/64 loss: -2.694873809814453
Batch 54/64 loss: -2.8886842727661133
Batch 55/64 loss: -2.8897666931152344
Batch 56/64 loss: -2.530893325805664
Batch 57/64 loss: -2.8085994720458984
Batch 58/64 loss: -2.8502931594848633
Batch 59/64 loss: -3.0006446838378906
Batch 60/64 loss: -2.809817314147949
Batch 61/64 loss: -2.639298439025879
Batch 62/64 loss: -2.9510011672973633
Batch 63/64 loss: -2.674327850341797
Batch 64/64 loss: -7.241319179534912
Epoch 286  Train loss: -2.8533835785061705  Val loss: -3.114045618325984
Epoch 287
-------------------------------
Batch 1/64 loss: -2.6515846252441406
Batch 2/64 loss: -2.7913999557495117
Batch 3/64 loss: -2.909327507019043
Batch 4/64 loss: -2.8154821395874023
Batch 5/64 loss: -2.8272523880004883
Batch 6/64 loss: -3.04434871673584
Batch 7/64 loss: -2.8285531997680664
Batch 8/64 loss: -2.9772167205810547
Batch 9/64 loss: -2.926698684692383
Batch 10/64 loss: -2.8615360260009766
Batch 11/64 loss: -2.7443342208862305
Batch 12/64 loss: -2.7808656692504883
Batch 13/64 loss: -2.6288890838623047
Batch 14/64 loss: -3.0007667541503906
Batch 15/64 loss: -2.857144355773926
Batch 16/64 loss: -2.7200002670288086
Batch 17/64 loss: -2.8864221572875977
Batch 18/64 loss: -2.870420455932617
Batch 19/64 loss: -2.702054977416992
Batch 20/64 loss: -2.775649070739746
Batch 21/64 loss: -2.965947151184082
Batch 22/64 loss: -2.9736385345458984
Batch 23/64 loss: -2.816152572631836
Batch 24/64 loss: -2.6263418197631836
Batch 25/64 loss: -2.802114486694336
Batch 26/64 loss: -2.8187503814697266
Batch 27/64 loss: -2.977752685546875
Batch 28/64 loss: -2.7219200134277344
Batch 29/64 loss: -3.059682846069336
Batch 30/64 loss: -2.6831140518188477
Batch 31/64 loss: -3.177199363708496
Batch 32/64 loss: -2.5777788162231445
Batch 33/64 loss: -2.82334041595459
Batch 34/64 loss: -2.9135913848876953
Batch 35/64 loss: -2.729330062866211
Batch 36/64 loss: -3.0675220489501953
Batch 37/64 loss: -3.019406318664551
Batch 38/64 loss: -2.898308753967285
Batch 39/64 loss: -2.8742780685424805
Batch 40/64 loss: -2.829209327697754
Batch 41/64 loss: -2.85107421875
Batch 42/64 loss: -2.879161834716797
Batch 43/64 loss: -3.003917694091797
Batch 44/64 loss: -2.432859420776367
Batch 45/64 loss: -2.9400854110717773
Batch 46/64 loss: -2.670024871826172
Batch 47/64 loss: -2.7904911041259766
Batch 48/64 loss: -2.573230743408203
Batch 49/64 loss: -2.4999818801879883
Batch 50/64 loss: -2.851926803588867
Batch 51/64 loss: -2.959321975708008
Batch 52/64 loss: -2.6936168670654297
Batch 53/64 loss: -3.026017189025879
Batch 54/64 loss: -2.8637990951538086
Batch 55/64 loss: -2.6786584854125977
Batch 56/64 loss: -2.959353446960449
Batch 57/64 loss: -2.842373847961426
Batch 58/64 loss: -2.951814651489258
Batch 59/64 loss: -2.7041635513305664
Batch 60/64 loss: -2.9143543243408203
Batch 61/64 loss: -2.8906688690185547
Batch 62/64 loss: -2.6671524047851562
Batch 63/64 loss: -2.447237968444824
Batch 64/64 loss: -7.336302757263184
Epoch 287  Train loss: -2.8791974871766333  Val loss: -3.068972715397471
Epoch 288
-------------------------------
Batch 1/64 loss: -2.7107725143432617
Batch 2/64 loss: -2.775503158569336
Batch 3/64 loss: -2.7162694931030273
Batch 4/64 loss: -2.7663164138793945
Batch 5/64 loss: -3.054738998413086
Batch 6/64 loss: -2.8097944259643555
Batch 7/64 loss: -2.696761131286621
Batch 8/64 loss: -2.5631675720214844
Batch 9/64 loss: -2.981755256652832
Batch 10/64 loss: -2.804067611694336
Batch 11/64 loss: -2.8871240615844727
Batch 12/64 loss: -2.513225555419922
Batch 13/64 loss: -2.9542036056518555
Batch 14/64 loss: -2.7647323608398438
Batch 15/64 loss: -2.789846420288086
Batch 16/64 loss: -2.5535850524902344
Batch 17/64 loss: -2.7862062454223633
Batch 18/64 loss: -2.8874082565307617
Batch 19/64 loss: -2.946828842163086
Batch 20/64 loss: -3.0398244857788086
Batch 21/64 loss: -2.818537712097168
Batch 22/64 loss: -2.8204708099365234
Batch 23/64 loss: -2.7075061798095703
Batch 24/64 loss: -2.9200897216796875
Batch 25/64 loss: -3.0200185775756836
Batch 26/64 loss: -2.8065433502197266
Batch 27/64 loss: -2.3697872161865234
Batch 28/64 loss: -3.045454978942871
Batch 29/64 loss: -2.808180809020996
Batch 30/64 loss: -2.920003890991211
Batch 31/64 loss: -2.836183547973633
Batch 32/64 loss: -2.853884696960449
Batch 33/64 loss: -2.744797706604004
Batch 34/64 loss: -2.8062658309936523
Batch 35/64 loss: -2.7299537658691406
Batch 36/64 loss: -3.0856571197509766
Batch 37/64 loss: -2.808131217956543
Batch 38/64 loss: -2.627169609069824
Batch 39/64 loss: -2.7342586517333984
Batch 40/64 loss: -2.7407426834106445
Batch 41/64 loss: -2.7996482849121094
Batch 42/64 loss: -3.0338382720947266
Batch 43/64 loss: -2.658928871154785
Batch 44/64 loss: -2.6682262420654297
Batch 45/64 loss: -2.8083419799804688
Batch 46/64 loss: -2.8648548126220703
Batch 47/64 loss: -2.606198310852051
Batch 48/64 loss: -2.7396631240844727
Batch 49/64 loss: -2.7720279693603516
Batch 50/64 loss: -2.492203712463379
Batch 51/64 loss: -2.7208251953125
Batch 52/64 loss: -2.9063024520874023
Batch 53/64 loss: -2.8255977630615234
Batch 54/64 loss: -2.9283294677734375
Batch 55/64 loss: -2.4789047241210938
Batch 56/64 loss: -2.897444725036621
Batch 57/64 loss: -2.9662227630615234
Batch 58/64 loss: -2.8373146057128906
Batch 59/64 loss: -2.821627616882324
Batch 60/64 loss: -2.566840171813965
Batch 61/64 loss: -2.9451828002929688
Batch 62/64 loss: -2.649411201477051
Batch 63/64 loss: -2.647970199584961
Batch 64/64 loss: -7.235831260681152
Epoch 288  Train loss: -2.843428207846249  Val loss: -3.010039771955038
Epoch 289
-------------------------------
Batch 1/64 loss: -3.0297908782958984
Batch 2/64 loss: -2.9980831146240234
Batch 3/64 loss: -2.820964813232422
Batch 4/64 loss: -2.6870203018188477
Batch 5/64 loss: -2.743640899658203
Batch 6/64 loss: -3.079798698425293
Batch 7/64 loss: -2.7895708084106445
Batch 8/64 loss: -2.7531042098999023
Batch 9/64 loss: -2.497783660888672
Batch 10/64 loss: -2.8880701065063477
Batch 11/64 loss: -2.9101686477661133
Batch 12/64 loss: -2.6689071655273438
Batch 13/64 loss: -2.9029808044433594
Batch 14/64 loss: -3.0575132369995117
Batch 15/64 loss: -2.819356918334961
Batch 16/64 loss: -3.0249290466308594
Batch 17/64 loss: -2.853957176208496
Batch 18/64 loss: -2.7820262908935547
Batch 19/64 loss: -2.9219017028808594
Batch 20/64 loss: -2.9442663192749023
Batch 21/64 loss: -2.820209503173828
Batch 22/64 loss: -2.9001169204711914
Batch 23/64 loss: -2.919076919555664
Batch 24/64 loss: -2.853546142578125
Batch 25/64 loss: -2.6863250732421875
Batch 26/64 loss: -2.6209287643432617
Batch 27/64 loss: -2.5536623001098633
Batch 28/64 loss: -2.596261978149414
Batch 29/64 loss: -2.8907432556152344
Batch 30/64 loss: -2.644510269165039
Batch 31/64 loss: -2.773630142211914
Batch 32/64 loss: -2.946573257446289
Batch 33/64 loss: -2.8264245986938477
Batch 34/64 loss: -2.6510257720947266
Batch 35/64 loss: -2.8011884689331055
Batch 36/64 loss: -2.907759666442871
Batch 37/64 loss: -2.8546905517578125
Batch 38/64 loss: -2.7633848190307617
Batch 39/64 loss: -2.7405128479003906
Batch 40/64 loss: -2.6430721282958984
Batch 41/64 loss: -2.905149459838867
Batch 42/64 loss: -2.786252975463867
Batch 43/64 loss: -2.4490928649902344
Batch 44/64 loss: -2.876434326171875
Batch 45/64 loss: -2.8685503005981445
Batch 46/64 loss: -2.781766891479492
Batch 47/64 loss: -2.629587173461914
Batch 48/64 loss: -2.6915969848632812
Batch 49/64 loss: -2.694973945617676
Batch 50/64 loss: -2.5606470108032227
Batch 51/64 loss: -2.9216041564941406
Batch 52/64 loss: -2.756026268005371
Batch 53/64 loss: -2.8559532165527344
Batch 54/64 loss: -2.882902145385742
Batch 55/64 loss: -2.7104949951171875
Batch 56/64 loss: -2.752129554748535
Batch 57/64 loss: -2.4947872161865234
Batch 58/64 loss: -2.6383981704711914
Batch 59/64 loss: -2.4673233032226562
Batch 60/64 loss: -2.539438247680664
Batch 61/64 loss: -2.76566219329834
Batch 62/64 loss: -2.6535606384277344
Batch 63/64 loss: -2.6139135360717773
Batch 64/64 loss: -7.5072197914123535
Epoch 289  Train loss: -2.831280605465758  Val loss: -3.0053035041310943
Epoch 290
-------------------------------
Batch 1/64 loss: -2.5550432205200195
Batch 2/64 loss: -2.888561248779297
Batch 3/64 loss: -2.9550771713256836
Batch 4/64 loss: -2.729389190673828
Batch 5/64 loss: -2.8354434967041016
Batch 6/64 loss: -2.6244430541992188
Batch 7/64 loss: -2.643505096435547
Batch 8/64 loss: -2.856924057006836
Batch 9/64 loss: -3.0097341537475586
Batch 10/64 loss: -3.0530452728271484
Batch 11/64 loss: -2.9904441833496094
Batch 12/64 loss: -2.7910594940185547
Batch 13/64 loss: -2.6786041259765625
Batch 14/64 loss: -2.539454460144043
Batch 15/64 loss: -2.9295263290405273
Batch 16/64 loss: -3.028463363647461
Batch 17/64 loss: -2.5086488723754883
Batch 18/64 loss: -2.7604799270629883
Batch 19/64 loss: -2.637237548828125
Batch 20/64 loss: -2.6850996017456055
Batch 21/64 loss: -2.795882225036621
Batch 22/64 loss: -2.767733573913574
Batch 23/64 loss: -2.7358903884887695
Batch 24/64 loss: -2.898787498474121
Batch 25/64 loss: -2.9324827194213867
Batch 26/64 loss: -2.8845157623291016
Batch 27/64 loss: -2.804945945739746
Batch 28/64 loss: -2.8551855087280273
Batch 29/64 loss: -2.9426259994506836
Batch 30/64 loss: -2.37075138092041
Batch 31/64 loss: -2.816807746887207
Batch 32/64 loss: -2.9748239517211914
Batch 33/64 loss: -2.8162527084350586
Batch 34/64 loss: -2.755352020263672
Batch 35/64 loss: -2.859530448913574
Batch 36/64 loss: -2.7468013763427734
Batch 37/64 loss: -2.7905960083007812
Batch 38/64 loss: -2.9903573989868164
Batch 39/64 loss: -2.7835464477539062
Batch 40/64 loss: -2.8370866775512695
Batch 41/64 loss: -2.5909061431884766
Batch 42/64 loss: -2.7725839614868164
Batch 43/64 loss: -2.846712112426758
Batch 44/64 loss: -2.8350439071655273
Batch 45/64 loss: -2.813420295715332
Batch 46/64 loss: -2.8289623260498047
Batch 47/64 loss: -2.656325340270996
Batch 48/64 loss: -2.9505558013916016
Batch 49/64 loss: -2.888583183288574
Batch 50/64 loss: -2.872574806213379
Batch 51/64 loss: -2.871908187866211
Batch 52/64 loss: -2.662590980529785
Batch 53/64 loss: -2.9194459915161133
Batch 54/64 loss: -2.9538097381591797
Batch 55/64 loss: -2.887049674987793
Batch 56/64 loss: -2.7646894454956055
Batch 57/64 loss: -2.977457046508789
Batch 58/64 loss: -2.9723434448242188
Batch 59/64 loss: -2.918203353881836
Batch 60/64 loss: -2.883085250854492
Batch 61/64 loss: -2.9121932983398438
Batch 62/64 loss: -2.8769006729125977
Batch 63/64 loss: -2.9497909545898438
Batch 64/64 loss: -7.484414100646973
Epoch 290  Train loss: -2.8749582141053445  Val loss: -3.073391288416492
Epoch 291
-------------------------------
Batch 1/64 loss: -2.9812984466552734
Batch 2/64 loss: -3.020029067993164
Batch 3/64 loss: -2.7971534729003906
Batch 4/64 loss: -2.9353647232055664
Batch 5/64 loss: -2.5639657974243164
Batch 6/64 loss: -3.040677070617676
Batch 7/64 loss: -2.8731460571289062
Batch 8/64 loss: -2.727494239807129
Batch 9/64 loss: -2.934515953063965
Batch 10/64 loss: -2.877100944519043
Batch 11/64 loss: -2.7828750610351562
Batch 12/64 loss: -2.7781219482421875
Batch 13/64 loss: -3.0352115631103516
Batch 14/64 loss: -2.620305061340332
Batch 15/64 loss: -2.9350967407226562
Batch 16/64 loss: -3.0335988998413086
Batch 17/64 loss: -2.9625606536865234
Batch 18/64 loss: -2.7807674407958984
Batch 19/64 loss: -2.7871170043945312
Batch 20/64 loss: -2.9269657135009766
Batch 21/64 loss: -2.52951717376709
Batch 22/64 loss: -2.8700647354125977
Batch 23/64 loss: -2.873943328857422
Batch 24/64 loss: -2.661569595336914
Batch 25/64 loss: -2.931947708129883
Batch 26/64 loss: -2.8470468521118164
Batch 27/64 loss: -2.8922252655029297
Batch 28/64 loss: -2.8038034439086914
Batch 29/64 loss: -2.957892417907715
Batch 30/64 loss: -3.148845672607422
Batch 31/64 loss: -2.9656906127929688
Batch 32/64 loss: -2.8476486206054688
Batch 33/64 loss: -2.6948232650756836
Batch 34/64 loss: -2.9814653396606445
Batch 35/64 loss: -2.801025390625
Batch 36/64 loss: -2.9804563522338867
Batch 37/64 loss: -2.954207420349121
Batch 38/64 loss: -2.922459602355957
Batch 39/64 loss: -2.9649972915649414
Batch 40/64 loss: -2.71622371673584
Batch 41/64 loss: -2.8531293869018555
Batch 42/64 loss: -3.03348445892334
Batch 43/64 loss: -2.924027442932129
Batch 44/64 loss: -2.962352752685547
Batch 45/64 loss: -2.9665603637695312
Batch 46/64 loss: -2.8776702880859375
Batch 47/64 loss: -2.918978691101074
Batch 48/64 loss: -2.615324020385742
Batch 49/64 loss: -3.0203733444213867
Batch 50/64 loss: -2.658834457397461
Batch 51/64 loss: -2.673940658569336
Batch 52/64 loss: -2.89412784576416
Batch 53/64 loss: -2.7929611206054688
Batch 54/64 loss: -2.7284631729125977
Batch 55/64 loss: -2.625577926635742
Batch 56/64 loss: -2.6178808212280273
Batch 57/64 loss: -2.9571304321289062
Batch 58/64 loss: -2.7883987426757812
Batch 59/64 loss: -2.99014949798584
Batch 60/64 loss: -2.8663768768310547
Batch 61/64 loss: -2.6609182357788086
Batch 62/64 loss: -2.9268875122070312
Batch 63/64 loss: -2.9625234603881836
Batch 64/64 loss: -7.253859043121338
Epoch 291  Train loss: -2.9097362424813067  Val loss: -3.1000546196482026
Epoch 292
-------------------------------
Batch 1/64 loss: -2.9584531784057617
Batch 2/64 loss: -2.8640804290771484
Batch 3/64 loss: -2.790072441101074
Batch 4/64 loss: -2.9728097915649414
Batch 5/64 loss: -2.935969352722168
Batch 6/64 loss: -2.924886703491211
Batch 7/64 loss: -2.6788549423217773
Batch 8/64 loss: -3.0529680252075195
Batch 9/64 loss: -2.728761672973633
Batch 10/64 loss: -2.87937068939209
Batch 11/64 loss: -2.819281578063965
Batch 12/64 loss: -2.870713233947754
Batch 13/64 loss: -2.9638452529907227
Batch 14/64 loss: -2.9868907928466797
Batch 15/64 loss: -2.835635185241699
Batch 16/64 loss: -2.972494125366211
Batch 17/64 loss: -2.701357841491699
Batch 18/64 loss: -3.0805749893188477
Batch 19/64 loss: -2.7308197021484375
Batch 20/64 loss: -2.9748973846435547
Batch 21/64 loss: -2.602588653564453
Batch 22/64 loss: -2.685854911804199
Batch 23/64 loss: -2.539815902709961
Batch 24/64 loss: -2.88407039642334
Batch 25/64 loss: -2.9825220108032227
Batch 26/64 loss: -2.6780786514282227
Batch 27/64 loss: -2.4092836380004883
Batch 28/64 loss: -2.719949722290039
Batch 29/64 loss: -2.701509475708008
Batch 30/64 loss: -2.960773468017578
Batch 31/64 loss: -2.9524002075195312
Batch 32/64 loss: -2.8977136611938477
Batch 33/64 loss: -2.3841142654418945
Batch 34/64 loss: -3.0425634384155273
Batch 35/64 loss: -2.9996767044067383
Batch 36/64 loss: -2.8738555908203125
Batch 37/64 loss: -2.633281707763672
Batch 38/64 loss: -2.7633190155029297
Batch 39/64 loss: -2.9085168838500977
Batch 40/64 loss: -2.7217273712158203
Batch 41/64 loss: -2.731271743774414
Batch 42/64 loss: -2.899862289428711
Batch 43/64 loss: -2.8913707733154297
Batch 44/64 loss: -2.763791084289551
Batch 45/64 loss: -2.8408899307250977
Batch 46/64 loss: -3.0859203338623047
Batch 47/64 loss: -2.8044252395629883
Batch 48/64 loss: -2.687375068664551
Batch 49/64 loss: -2.942721366882324
Batch 50/64 loss: -2.7959461212158203
Batch 51/64 loss: -2.9550695419311523
Batch 52/64 loss: -2.9481430053710938
Batch 53/64 loss: -2.7444000244140625
Batch 54/64 loss: -2.955657958984375
Batch 55/64 loss: -2.842230796813965
Batch 56/64 loss: -2.8792123794555664
Batch 57/64 loss: -2.337411880493164
Batch 58/64 loss: -2.612794876098633
Batch 59/64 loss: -2.694833755493164
Batch 60/64 loss: -2.7782459259033203
Batch 61/64 loss: -2.7322349548339844
Batch 62/64 loss: -2.75154972076416
Batch 63/64 loss: -3.0497007369995117
Batch 64/64 loss: -7.40833854675293
Epoch 292  Train loss: -2.8760104534672757  Val loss: -3.0541638770873605
Epoch 293
-------------------------------
Batch 1/64 loss: -2.513918876647949
Batch 2/64 loss: -2.443282127380371
Batch 3/64 loss: -2.803999900817871
Batch 4/64 loss: -2.896207809448242
Batch 5/64 loss: -2.6778411865234375
Batch 6/64 loss: -2.693470001220703
Batch 7/64 loss: -2.9005136489868164
Batch 8/64 loss: -2.9241437911987305
Batch 9/64 loss: -2.7364606857299805
Batch 10/64 loss: -2.7797346115112305
Batch 11/64 loss: -2.884840965270996
Batch 12/64 loss: -2.945540428161621
Batch 13/64 loss: -2.930121421813965
Batch 14/64 loss: -2.323881149291992
Batch 15/64 loss: -2.5870113372802734
Batch 16/64 loss: -2.96323299407959
Batch 17/64 loss: -2.8392515182495117
Batch 18/64 loss: -2.7394676208496094
Batch 19/64 loss: -2.9903364181518555
Batch 20/64 loss: -3.1297969818115234
Batch 21/64 loss: -2.88527774810791
Batch 22/64 loss: -3.0223770141601562
Batch 23/64 loss: -2.801229476928711
Batch 24/64 loss: -2.823824882507324
Batch 25/64 loss: -3.045757293701172
Batch 26/64 loss: -2.857809066772461
Batch 27/64 loss: -2.7318201065063477
Batch 28/64 loss: -2.9320640563964844
Batch 29/64 loss: -2.90084171295166
Batch 30/64 loss: -2.8257951736450195
Batch 31/64 loss: -2.9453487396240234
Batch 32/64 loss: -2.8346548080444336
Batch 33/64 loss: -2.8279008865356445
Batch 34/64 loss: -2.9137096405029297
Batch 35/64 loss: -2.8253393173217773
Batch 36/64 loss: -2.7850160598754883
Batch 37/64 loss: -2.9566144943237305
Batch 38/64 loss: -2.6185550689697266
Batch 39/64 loss: -2.7363357543945312
Batch 40/64 loss: -2.6627159118652344
Batch 41/64 loss: -2.8358850479125977
Batch 42/64 loss: -2.825742721557617
Batch 43/64 loss: -3.054628372192383
Batch 44/64 loss: -2.755589485168457
Batch 45/64 loss: -2.989818572998047
Batch 46/64 loss: -2.5779733657836914
Batch 47/64 loss: -2.770951271057129
Batch 48/64 loss: -2.3773746490478516
Batch 49/64 loss: -3.041449546813965
Batch 50/64 loss: -2.6901025772094727
Batch 51/64 loss: -2.491975784301758
Batch 52/64 loss: -2.7536888122558594
Batch 53/64 loss: -3.005843162536621
Batch 54/64 loss: -3.052027702331543
Batch 55/64 loss: -2.6971054077148438
Batch 56/64 loss: -2.734006881713867
Batch 57/64 loss: -2.9640932083129883
Batch 58/64 loss: -2.936345100402832
Batch 59/64 loss: -2.8470458984375
Batch 60/64 loss: -2.8493223190307617
Batch 61/64 loss: -2.902401924133301
Batch 62/64 loss: -2.854391098022461
Batch 63/64 loss: -2.9250545501708984
Batch 64/64 loss: -6.966039180755615
Epoch 293  Train loss: -2.867347255407595  Val loss: -3.0171976646606864
Epoch 294
-------------------------------
Batch 1/64 loss: -2.750576972961426
Batch 2/64 loss: -3.0711193084716797
Batch 3/64 loss: -2.544070243835449
Batch 4/64 loss: -2.4504384994506836
Batch 5/64 loss: -2.9854660034179688
Batch 6/64 loss: -2.809206962585449
Batch 7/64 loss: -2.4708375930786133
Batch 8/64 loss: -2.8761138916015625
Batch 9/64 loss: -2.6266040802001953
Batch 10/64 loss: -3.0025930404663086
Batch 11/64 loss: -2.777449607849121
Batch 12/64 loss: -2.745492935180664
Batch 13/64 loss: -2.9311647415161133
Batch 14/64 loss: -2.8472862243652344
Batch 15/64 loss: -2.6820297241210938
Batch 16/64 loss: -2.812638282775879
Batch 17/64 loss: -3.000126838684082
Batch 18/64 loss: -2.8789892196655273
Batch 19/64 loss: -2.53973388671875
Batch 20/64 loss: -2.7619876861572266
Batch 21/64 loss: -2.936979293823242
Batch 22/64 loss: -2.758538246154785
Batch 23/64 loss: -2.7548675537109375
Batch 24/64 loss: -2.9385814666748047
Batch 25/64 loss: -2.920625686645508
Batch 26/64 loss: -2.8282623291015625
Batch 27/64 loss: -2.813443183898926
Batch 28/64 loss: -2.9249114990234375
Batch 29/64 loss: -2.8434696197509766
Batch 30/64 loss: -2.968461036682129
Batch 31/64 loss: -2.726285934448242
Batch 32/64 loss: -2.9862136840820312
Batch 33/64 loss: -2.6809425354003906
Batch 34/64 loss: -2.939472198486328
Batch 35/64 loss: -2.9668197631835938
Batch 36/64 loss: -2.9424753189086914
Batch 37/64 loss: -2.8206005096435547
Batch 38/64 loss: -2.893813133239746
Batch 39/64 loss: -2.986024856567383
Batch 40/64 loss: -2.669295310974121
Batch 41/64 loss: -2.8828306198120117
Batch 42/64 loss: -2.9087982177734375
Batch 43/64 loss: -3.00958251953125
Batch 44/64 loss: -2.7470083236694336
Batch 45/64 loss: -2.685098648071289
Batch 46/64 loss: -2.6381702423095703
Batch 47/64 loss: -2.732998847961426
Batch 48/64 loss: -2.7392587661743164
Batch 49/64 loss: -2.93621826171875
Batch 50/64 loss: -2.803563117980957
Batch 51/64 loss: -2.9264936447143555
Batch 52/64 loss: -2.8137121200561523
Batch 53/64 loss: -2.913667678833008
Batch 54/64 loss: -2.766908645629883
Batch 55/64 loss: -2.763615608215332
Batch 56/64 loss: -2.826207160949707
Batch 57/64 loss: -2.7675743103027344
Batch 58/64 loss: -2.9044599533081055
Batch 59/64 loss: -2.712641716003418
Batch 60/64 loss: -2.672928810119629
Batch 61/64 loss: -3.0189266204833984
Batch 62/64 loss: -2.742222785949707
Batch 63/64 loss: -2.843748092651367
Batch 64/64 loss: -7.1563496589660645
Epoch 294  Train loss: -2.8703985232932894  Val loss: -3.0715439524437556
Epoch 295
-------------------------------
Batch 1/64 loss: -3.019650459289551
Batch 2/64 loss: -2.5128679275512695
Batch 3/64 loss: -2.93765926361084
Batch 4/64 loss: -2.7384376525878906
Batch 5/64 loss: -3.001397132873535
Batch 6/64 loss: -2.8970813751220703
Batch 7/64 loss: -2.9397010803222656
Batch 8/64 loss: -2.942124366760254
Batch 9/64 loss: -2.797083854675293
Batch 10/64 loss: -2.9491872787475586
Batch 11/64 loss: -2.8083181381225586
Batch 12/64 loss: -2.927495002746582
Batch 13/64 loss: -2.9584131240844727
Batch 14/64 loss: -2.7154455184936523
Batch 15/64 loss: -2.663893699645996
Batch 16/64 loss: -2.9642629623413086
Batch 17/64 loss: -3.0642576217651367
Batch 18/64 loss: -2.6820993423461914
Batch 19/64 loss: -2.8346452713012695
Batch 20/64 loss: -3.03751277923584
Batch 21/64 loss: -2.7109289169311523
Batch 22/64 loss: -2.778165817260742
Batch 23/64 loss: -2.8269853591918945
Batch 24/64 loss: -3.043842315673828
Batch 25/64 loss: -2.90255069732666
Batch 26/64 loss: -2.8408403396606445
Batch 27/64 loss: -2.4601001739501953
Batch 28/64 loss: -2.8878583908081055
Batch 29/64 loss: -2.7109451293945312
Batch 30/64 loss: -2.603604316711426
Batch 31/64 loss: -2.8292360305786133
Batch 32/64 loss: -2.6364736557006836
Batch 33/64 loss: -2.833972930908203
Batch 34/64 loss: -2.6814470291137695
Batch 35/64 loss: -2.535991668701172
Batch 36/64 loss: -2.8637161254882812
Batch 37/64 loss: -2.8183422088623047
Batch 38/64 loss: -3.034505844116211
Batch 39/64 loss: -2.8878259658813477
Batch 40/64 loss: -2.914112091064453
Batch 41/64 loss: -2.779360771179199
Batch 42/64 loss: -2.764857292175293
Batch 43/64 loss: -2.92099666595459
Batch 44/64 loss: -2.8051538467407227
Batch 45/64 loss: -2.8014354705810547
Batch 46/64 loss: -2.873612403869629
Batch 47/64 loss: -2.765155792236328
Batch 48/64 loss: -2.8525304794311523
Batch 49/64 loss: -2.9430665969848633
Batch 50/64 loss: -2.800830841064453
Batch 51/64 loss: -2.936539649963379
Batch 52/64 loss: -2.7434263229370117
Batch 53/64 loss: -2.8624629974365234
Batch 54/64 loss: -2.7830982208251953
Batch 55/64 loss: -2.683328628540039
Batch 56/64 loss: -2.7235002517700195
Batch 57/64 loss: -2.8856582641601562
Batch 58/64 loss: -2.626321792602539
Batch 59/64 loss: -2.6326303482055664
Batch 60/64 loss: -2.90621280670166
Batch 61/64 loss: -2.812718391418457
Batch 62/64 loss: -2.680055618286133
Batch 63/64 loss: -2.7580080032348633
Batch 64/64 loss: -7.012208938598633
Epoch 295  Train loss: -2.8673426983403223  Val loss: -3.019846611416217
Epoch 296
-------------------------------
Batch 1/64 loss: -2.971189498901367
Batch 2/64 loss: -2.8373985290527344
Batch 3/64 loss: -2.7753772735595703
Batch 4/64 loss: -3.0800886154174805
Batch 5/64 loss: -2.7893571853637695
Batch 6/64 loss: -2.6412715911865234
Batch 7/64 loss: -2.9113950729370117
Batch 8/64 loss: -2.935379981994629
Batch 9/64 loss: -2.7961301803588867
Batch 10/64 loss: -2.8812952041625977
Batch 11/64 loss: -2.6932754516601562
Batch 12/64 loss: -2.981161117553711
Batch 13/64 loss: -2.7793312072753906
Batch 14/64 loss: -2.801004409790039
Batch 15/64 loss: -2.738419532775879
Batch 16/64 loss: -2.9786367416381836
Batch 17/64 loss: -2.8162946701049805
Batch 18/64 loss: -2.8274688720703125
Batch 19/64 loss: -2.8488054275512695
Batch 20/64 loss: -2.959749221801758
Batch 21/64 loss: -3.073845863342285
Batch 22/64 loss: -2.849982261657715
Batch 23/64 loss: -2.774477005004883
Batch 24/64 loss: -2.733339309692383
Batch 25/64 loss: -3.0177574157714844
Batch 26/64 loss: -2.533041000366211
Batch 27/64 loss: -2.864347457885742
Batch 28/64 loss: -2.9167213439941406
Batch 29/64 loss: -2.851851463317871
Batch 30/64 loss: -2.7802305221557617
Batch 31/64 loss: -2.7593917846679688
Batch 32/64 loss: -2.9757022857666016
Batch 33/64 loss: -3.0288095474243164
Batch 34/64 loss: -2.946995735168457
Batch 35/64 loss: -3.0403575897216797
Batch 36/64 loss: -2.9626169204711914
Batch 37/64 loss: -2.7247390747070312
Batch 38/64 loss: -2.6779136657714844
Batch 39/64 loss: -3.0941600799560547
Batch 40/64 loss: -2.695741653442383
Batch 41/64 loss: -2.7446842193603516
Batch 42/64 loss: -2.6607494354248047
Batch 43/64 loss: -2.911245346069336
Batch 44/64 loss: -3.0392370223999023
Batch 45/64 loss: -2.856492042541504
Batch 46/64 loss: -2.851496696472168
Batch 47/64 loss: -2.989354133605957
Batch 48/64 loss: -2.8292360305786133
Batch 49/64 loss: -2.7479753494262695
Batch 50/64 loss: -2.8713274002075195
Batch 51/64 loss: -2.617778778076172
Batch 52/64 loss: -2.9942550659179688
Batch 53/64 loss: -2.6138763427734375
Batch 54/64 loss: -2.895552635192871
Batch 55/64 loss: -2.92073917388916
Batch 56/64 loss: -2.924518585205078
Batch 57/64 loss: -2.840280532836914
Batch 58/64 loss: -2.77646541595459
Batch 59/64 loss: -2.5486221313476562
Batch 60/64 loss: -2.648252487182617
Batch 61/64 loss: -2.9001855850219727
Batch 62/64 loss: -2.9894227981567383
Batch 63/64 loss: -2.8375654220581055
Batch 64/64 loss: -7.505100250244141
Epoch 296  Train loss: -2.9016970914952895  Val loss: -3.066967993667445
Epoch 297
-------------------------------
Batch 1/64 loss: -3.06170654296875
Batch 2/64 loss: -2.7036094665527344
Batch 3/64 loss: -2.592813491821289
Batch 4/64 loss: -3.0698747634887695
Batch 5/64 loss: -2.6054229736328125
Batch 6/64 loss: -2.947021484375
Batch 7/64 loss: -2.971003532409668
Batch 8/64 loss: -2.963809013366699
Batch 9/64 loss: -3.0631837844848633
Batch 10/64 loss: -2.7233686447143555
Batch 11/64 loss: -2.6839675903320312
Batch 12/64 loss: -3.022566795349121
Batch 13/64 loss: -3.0844221115112305
Batch 14/64 loss: -2.931696891784668
Batch 15/64 loss: -3.0045366287231445
Batch 16/64 loss: -2.810239791870117
Batch 17/64 loss: -2.6345815658569336
Batch 18/64 loss: -2.504240036010742
Batch 19/64 loss: -3.003049850463867
Batch 20/64 loss: -3.0852622985839844
Batch 21/64 loss: -2.929244041442871
Batch 22/64 loss: -2.9014577865600586
Batch 23/64 loss: -2.8833093643188477
Batch 24/64 loss: -2.97678279876709
Batch 25/64 loss: -2.9456787109375
Batch 26/64 loss: -2.9482421875
Batch 27/64 loss: -2.8910045623779297
Batch 28/64 loss: -2.7065134048461914
Batch 29/64 loss: -3.062504768371582
Batch 30/64 loss: -2.6546125411987305
Batch 31/64 loss: -2.4939193725585938
Batch 32/64 loss: -2.882863998413086
Batch 33/64 loss: -2.9149599075317383
Batch 34/64 loss: -2.850430488586426
Batch 35/64 loss: -2.918567657470703
Batch 36/64 loss: -2.815993309020996
Batch 37/64 loss: -2.950906753540039
Batch 38/64 loss: -2.9686384201049805
Batch 39/64 loss: -2.910585403442383
Batch 40/64 loss: -2.865054130554199
Batch 41/64 loss: -2.758660316467285
Batch 42/64 loss: -2.912144660949707
Batch 43/64 loss: -2.627213478088379
Batch 44/64 loss: -2.9785871505737305
Batch 45/64 loss: -2.9975099563598633
Batch 46/64 loss: -2.9505739212036133
Batch 47/64 loss: -2.670008659362793
Batch 48/64 loss: -2.9955997467041016
Batch 49/64 loss: -2.9922943115234375
Batch 50/64 loss: -2.94252872467041
Batch 51/64 loss: -2.9343795776367188
Batch 52/64 loss: -2.7561235427856445
Batch 53/64 loss: -2.3227434158325195
Batch 54/64 loss: -2.995054244995117
Batch 55/64 loss: -2.7770652770996094
Batch 56/64 loss: -2.7291078567504883
Batch 57/64 loss: -2.584735870361328
Batch 58/64 loss: -3.044973373413086
Batch 59/64 loss: -2.819713592529297
Batch 60/64 loss: -2.7930212020874023
Batch 61/64 loss: -2.8008813858032227
Batch 62/64 loss: -3.06185245513916
Batch 63/64 loss: -2.854085922241211
Batch 64/64 loss: -7.483249664306641
Epoch 297  Train loss: -2.9152775334376915  Val loss: -3.112533097414626
Epoch 298
-------------------------------
Batch 1/64 loss: -2.8545074462890625
Batch 2/64 loss: -2.8913660049438477
Batch 3/64 loss: -2.999814987182617
Batch 4/64 loss: -2.8770999908447266
Batch 5/64 loss: -2.9102935791015625
Batch 6/64 loss: -2.579080581665039
Batch 7/64 loss: -2.964583396911621
Batch 8/64 loss: -2.806389808654785
Batch 9/64 loss: -2.8188085556030273
Batch 10/64 loss: -2.860982894897461
Batch 11/64 loss: -3.1121387481689453
Batch 12/64 loss: -2.8910226821899414
Batch 13/64 loss: -2.8652076721191406
Batch 14/64 loss: -2.934462547302246
Batch 15/64 loss: -2.945437431335449
Batch 16/64 loss: -3.028453826904297
Batch 17/64 loss: -2.7853994369506836
Batch 18/64 loss: -2.760082244873047
Batch 19/64 loss: -2.823537826538086
Batch 20/64 loss: -2.880560874938965
Batch 21/64 loss: -2.9479761123657227
Batch 22/64 loss: -2.640291213989258
Batch 23/64 loss: -2.920024871826172
Batch 24/64 loss: -2.90268611907959
Batch 25/64 loss: -2.6477231979370117
Batch 26/64 loss: -3.0707969665527344
Batch 27/64 loss: -2.7714662551879883
Batch 28/64 loss: -2.9646100997924805
Batch 29/64 loss: -3.0243234634399414
Batch 30/64 loss: -2.9421491622924805
Batch 31/64 loss: -2.9611682891845703
Batch 32/64 loss: -2.9652099609375
Batch 33/64 loss: -2.5941572189331055
Batch 34/64 loss: -2.943650245666504
Batch 35/64 loss: -2.5902843475341797
Batch 36/64 loss: -2.6024723052978516
Batch 37/64 loss: -2.544099807739258
Batch 38/64 loss: -2.98586368560791
Batch 39/64 loss: -2.981046676635742
Batch 40/64 loss: -2.8840599060058594
Batch 41/64 loss: -2.7479658126831055
Batch 42/64 loss: -2.918778419494629
Batch 43/64 loss: -2.885770797729492
Batch 44/64 loss: -2.648611068725586
Batch 45/64 loss: -2.8286266326904297
Batch 46/64 loss: -3.041804313659668
Batch 47/64 loss: -2.5948305130004883
Batch 48/64 loss: -2.802779197692871
Batch 49/64 loss: -2.704843521118164
Batch 50/64 loss: -2.8930892944335938
Batch 51/64 loss: -3.014528274536133
Batch 52/64 loss: -2.9525365829467773
Batch 53/64 loss: -2.9982175827026367
Batch 54/64 loss: -2.7671079635620117
Batch 55/64 loss: -2.890873908996582
Batch 56/64 loss: -2.959530830383301
Batch 57/64 loss: -2.7351036071777344
Batch 58/64 loss: -3.0178070068359375
Batch 59/64 loss: -2.878520965576172
Batch 60/64 loss: -2.790637969970703
Batch 61/64 loss: -3.012228012084961
Batch 62/64 loss: -2.959493637084961
Batch 63/64 loss: -3.022414207458496
Batch 64/64 loss: -7.414525985717773
Epoch 298  Train loss: -2.919220157698089  Val loss: -3.087499703738288
Epoch 299
-------------------------------
Batch 1/64 loss: -2.966588020324707
Batch 2/64 loss: -3.026339530944824
Batch 3/64 loss: -2.9280357360839844
Batch 4/64 loss: -2.871866226196289
Batch 5/64 loss: -2.475295066833496
Batch 6/64 loss: -2.9107847213745117
Batch 7/64 loss: -2.948831558227539
Batch 8/64 loss: -3.0776987075805664
Batch 9/64 loss: -2.637387275695801
Batch 10/64 loss: -3.0415449142456055
Batch 11/64 loss: -2.951639175415039
Batch 12/64 loss: -2.7165699005126953
Batch 13/64 loss: -2.784442901611328
Batch 14/64 loss: -2.6749448776245117
Batch 15/64 loss: -2.914884567260742
Batch 16/64 loss: -2.95328426361084
Batch 17/64 loss: -2.643252372741699
Batch 18/64 loss: -2.7106332778930664
Batch 19/64 loss: -2.8242549896240234
Batch 20/64 loss: -2.745755195617676
Batch 21/64 loss: -2.8380966186523438
Batch 22/64 loss: -2.985825538635254
Batch 23/64 loss: -2.89774227142334
Batch 24/64 loss: -2.9778919219970703
Batch 25/64 loss: -3.027102470397949
Batch 26/64 loss: -2.9259653091430664
Batch 27/64 loss: -2.4482460021972656
Batch 28/64 loss: -2.9263153076171875
Batch 29/64 loss: -2.9746179580688477
Batch 30/64 loss: -2.8809776306152344
Batch 31/64 loss: -3.012608528137207
Batch 32/64 loss: -2.9093494415283203
Batch 33/64 loss: -2.9544849395751953
Batch 34/64 loss: -2.9229888916015625
Batch 35/64 loss: -2.765976905822754
Batch 36/64 loss: -3.014225959777832
Batch 37/64 loss: -2.7628297805786133
Batch 38/64 loss: -2.8215293884277344
Batch 39/64 loss: -2.6033639907836914
Batch 40/64 loss: -2.883777618408203
Batch 41/64 loss: -2.910311698913574
Batch 42/64 loss: -2.891322135925293
Batch 43/64 loss: -2.965463638305664
Batch 44/64 loss: -2.743208885192871
Batch 45/64 loss: -3.0535688400268555
Batch 46/64 loss: -2.9763059616088867
Batch 47/64 loss: -2.6119203567504883
Batch 48/64 loss: -2.6457748413085938
Batch 49/64 loss: -3.077564239501953
Batch 50/64 loss: -2.8516740798950195
Batch 51/64 loss: -2.8049449920654297
Batch 52/64 loss: -2.667454719543457
Batch 53/64 loss: -2.7534475326538086
Batch 54/64 loss: -3.123004913330078
Batch 55/64 loss: -2.874542236328125
Batch 56/64 loss: -2.815821647644043
Batch 57/64 loss: -2.664576530456543
Batch 58/64 loss: -3.029110908508301
Batch 59/64 loss: -2.9657535552978516
Batch 60/64 loss: -2.8014259338378906
Batch 61/64 loss: -2.79251766204834
Batch 62/64 loss: -2.8041505813598633
Batch 63/64 loss: -2.6988916397094727
Batch 64/64 loss: -7.454702377319336
Epoch 299  Train loss: -2.9090468088785806  Val loss: -3.099598887859751
Epoch 300
-------------------------------
Batch 1/64 loss: -2.879352569580078
Batch 2/64 loss: -2.775951385498047
Batch 3/64 loss: -2.9657726287841797
Batch 4/64 loss: -2.906494140625
Batch 5/64 loss: -2.771712303161621
Batch 6/64 loss: -2.7182140350341797
Batch 7/64 loss: -2.7079200744628906
Batch 8/64 loss: -2.643742561340332
Batch 9/64 loss: -3.030533790588379
Batch 10/64 loss: -2.7694692611694336
Batch 11/64 loss: -2.8442745208740234
Batch 12/64 loss: -2.979884147644043
Batch 13/64 loss: -2.8066625595092773
Batch 14/64 loss: -2.8321781158447266
Batch 15/64 loss: -2.8541955947875977
Batch 16/64 loss: -2.7485170364379883
Batch 17/64 loss: -2.988494873046875
Batch 18/64 loss: -2.640239715576172
Batch 19/64 loss: -2.969456672668457
Batch 20/64 loss: -3.113947868347168
Batch 21/64 loss: -3.0549278259277344
Batch 22/64 loss: -2.8409509658813477
Batch 23/64 loss: -2.993661880493164
Batch 24/64 loss: -2.803830146789551
Batch 25/64 loss: -2.771204948425293
Batch 26/64 loss: -2.9305734634399414
Batch 27/64 loss: -2.979142189025879
Batch 28/64 loss: -2.7475624084472656
Batch 29/64 loss: -2.8362131118774414
Batch 30/64 loss: -2.9599742889404297
Batch 31/64 loss: -2.979933738708496
Batch 32/64 loss: -2.791203498840332
Batch 33/64 loss: -2.814406394958496
Batch 34/64 loss: -2.744609832763672
Batch 35/64 loss: -3.0034847259521484
Batch 36/64 loss: -2.666836738586426
Batch 37/64 loss: -2.8783721923828125
Batch 38/64 loss: -2.657642364501953
Batch 39/64 loss: -2.9223461151123047
Batch 40/64 loss: -2.871382713317871
Batch 41/64 loss: -2.757017135620117
Batch 42/64 loss: -2.9106578826904297
Batch 43/64 loss: -2.7644729614257812
Batch 44/64 loss: -3.153355598449707
Batch 45/64 loss: -2.8137969970703125
Batch 46/64 loss: -3.014738082885742
Batch 47/64 loss: -2.8888320922851562
Batch 48/64 loss: -3.0383615493774414
Batch 49/64 loss: -2.9018373489379883
Batch 50/64 loss: -3.0494260787963867
Batch 51/64 loss: -3.0986671447753906
Batch 52/64 loss: -2.902158737182617
Batch 53/64 loss: -2.618168830871582
Batch 54/64 loss: -2.8792057037353516
Batch 55/64 loss: -2.60699462890625
Batch 56/64 loss: -3.086533546447754
Batch 57/64 loss: -2.8763046264648438
Batch 58/64 loss: -2.748258590698242
Batch 59/64 loss: -2.7241477966308594
Batch 60/64 loss: -2.816880226135254
Batch 61/64 loss: -2.827688217163086
Batch 62/64 loss: -2.7573442459106445
Batch 63/64 loss: -2.793710708618164
Batch 64/64 loss: -7.340485095977783
Epoch 300  Train loss: -2.9133991521947524  Val loss: -3.021797035977603
Epoch 301
-------------------------------
Batch 1/64 loss: -2.996792793273926
Batch 2/64 loss: -2.959506034851074
Batch 3/64 loss: -2.8777265548706055
Batch 4/64 loss: -3.043593406677246
Batch 5/64 loss: -2.8575315475463867
Batch 6/64 loss: -2.8274192810058594
Batch 7/64 loss: -2.9247589111328125
Batch 8/64 loss: -2.3264923095703125
Batch 9/64 loss: -2.764286994934082
Batch 10/64 loss: -2.6235742568969727
Batch 11/64 loss: -3.0343284606933594
Batch 12/64 loss: -2.7418222427368164
Batch 13/64 loss: -2.846991539001465
Batch 14/64 loss: -2.8850955963134766
Batch 15/64 loss: -2.849165916442871
Batch 16/64 loss: -2.9335460662841797
Batch 17/64 loss: -2.966244697570801
Batch 18/64 loss: -3.050769805908203
Batch 19/64 loss: -2.8013668060302734
Batch 20/64 loss: -2.8661375045776367
Batch 21/64 loss: -2.9765262603759766
Batch 22/64 loss: -2.9985666275024414
Batch 23/64 loss: -2.688570976257324
Batch 24/64 loss: -2.8908166885375977
Batch 25/64 loss: -2.847701072692871
Batch 26/64 loss: -2.9145612716674805
Batch 27/64 loss: -2.9449844360351562
Batch 28/64 loss: -2.8410720825195312
Batch 29/64 loss: -3.0414180755615234
Batch 30/64 loss: -2.557964324951172
Batch 31/64 loss: -2.7418270111083984
Batch 32/64 loss: -2.8315296173095703
Batch 33/64 loss: -2.9653854370117188
Batch 34/64 loss: -2.6484384536743164
Batch 35/64 loss: -2.7669124603271484
Batch 36/64 loss: -2.7865686416625977
Batch 37/64 loss: -2.539820671081543
Batch 38/64 loss: -2.9183311462402344
Batch 39/64 loss: -2.845400810241699
Batch 40/64 loss: -2.813685417175293
Batch 41/64 loss: -2.8773412704467773
Batch 42/64 loss: -2.6837549209594727
Batch 43/64 loss: -2.9831295013427734
Batch 44/64 loss: -2.9520950317382812
Batch 45/64 loss: -2.5995426177978516
Batch 46/64 loss: -2.9818477630615234
Batch 47/64 loss: -3.0481739044189453
Batch 48/64 loss: -2.9217100143432617
Batch 49/64 loss: -2.709805488586426
Batch 50/64 loss: -2.8954248428344727
Batch 51/64 loss: -2.818203926086426
Batch 52/64 loss: -2.85150146484375
Batch 53/64 loss: -2.985536575317383
Batch 54/64 loss: -2.886216163635254
Batch 55/64 loss: -2.714158058166504
Batch 56/64 loss: -2.7034759521484375
Batch 57/64 loss: -2.8669748306274414
Batch 58/64 loss: -2.8819828033447266
Batch 59/64 loss: -3.025970458984375
Batch 60/64 loss: -2.9677276611328125
Batch 61/64 loss: -2.9329872131347656
Batch 62/64 loss: -2.867086410522461
Batch 63/64 loss: -2.925914764404297
Batch 64/64 loss: -7.300278186798096
Epoch 301  Train loss: -2.906556901744768  Val loss: -3.1009013644608436
Epoch 302
-------------------------------
Batch 1/64 loss: -2.8605566024780273
Batch 2/64 loss: -2.736546516418457
Batch 3/64 loss: -2.856302261352539
Batch 4/64 loss: -2.7761001586914062
Batch 5/64 loss: -2.7165651321411133
Batch 6/64 loss: -2.924525260925293
Batch 7/64 loss: -2.6764326095581055
Batch 8/64 loss: -2.9000720977783203
Batch 9/64 loss: -2.774740219116211
Batch 10/64 loss: -2.746828079223633
Batch 11/64 loss: -2.5693588256835938
Batch 12/64 loss: -2.8778467178344727
Batch 13/64 loss: -2.8193788528442383
Batch 14/64 loss: -2.9388160705566406
Batch 15/64 loss: -3.0153112411499023
Batch 16/64 loss: -2.8868627548217773
Batch 17/64 loss: -2.913620948791504
Batch 18/64 loss: -2.987903594970703
Batch 19/64 loss: -2.8193588256835938
Batch 20/64 loss: -2.48122501373291
Batch 21/64 loss: -3.0697689056396484
Batch 22/64 loss: -2.684795379638672
Batch 23/64 loss: -2.918701171875
Batch 24/64 loss: -2.737314224243164
Batch 25/64 loss: -2.8835792541503906
Batch 26/64 loss: -3.041471481323242
Batch 27/64 loss: -2.8107223510742188
Batch 28/64 loss: -2.733570098876953
Batch 29/64 loss: -3.190868854522705
Batch 30/64 loss: -2.9715490341186523
Batch 31/64 loss: -2.9231691360473633
Batch 32/64 loss: -2.7627859115600586
Batch 33/64 loss: -2.76790714263916
Batch 34/64 loss: -2.9687576293945312
Batch 35/64 loss: -2.808751106262207
Batch 36/64 loss: -2.698622703552246
Batch 37/64 loss: -2.9177637100219727
Batch 38/64 loss: -2.7779102325439453
Batch 39/64 loss: -2.932863235473633
Batch 40/64 loss: -2.7177419662475586
Batch 41/64 loss: -2.7550888061523438
Batch 42/64 loss: -2.511124610900879
Batch 43/64 loss: -2.907864570617676
Batch 44/64 loss: -2.9182891845703125
Batch 45/64 loss: -2.7656145095825195
Batch 46/64 loss: -2.4065189361572266
Batch 47/64 loss: -2.7453699111938477
Batch 48/64 loss: -2.9221696853637695
Batch 49/64 loss: -3.0991640090942383
Batch 50/64 loss: -2.8890438079833984
Batch 51/64 loss: -2.6295461654663086
Batch 52/64 loss: -2.354867935180664
Batch 53/64 loss: -2.822315216064453
Batch 54/64 loss: -2.7357053756713867
Batch 55/64 loss: -2.8854761123657227
Batch 56/64 loss: -2.7720279693603516
Batch 57/64 loss: -3.0435800552368164
Batch 58/64 loss: -2.852163314819336
Batch 59/64 loss: -2.998079299926758
Batch 60/64 loss: -2.7062931060791016
Batch 61/64 loss: -3.004544258117676
Batch 62/64 loss: -2.9253406524658203
Batch 63/64 loss: -2.886615753173828
Batch 64/64 loss: -7.526576519012451
Epoch 302  Train loss: -2.8828031521217494  Val loss: -2.917209389283485
Epoch 303
-------------------------------
Batch 1/64 loss: -2.4647626876831055
Batch 2/64 loss: -2.9198570251464844
Batch 3/64 loss: -3.0040388107299805
Batch 4/64 loss: -2.781193733215332
Batch 5/64 loss: -2.875582695007324
Batch 6/64 loss: -3.1161327362060547
Batch 7/64 loss: -2.612213134765625
Batch 8/64 loss: -2.9844799041748047
Batch 9/64 loss: -2.8268260955810547
Batch 10/64 loss: -3.0064516067504883
Batch 11/64 loss: -2.774412155151367
Batch 12/64 loss: -2.9319467544555664
Batch 13/64 loss: -3.012592315673828
Batch 14/64 loss: -2.8085756301879883
Batch 15/64 loss: -2.7231225967407227
Batch 16/64 loss: -2.6563634872436523
Batch 17/64 loss: -2.8848047256469727
Batch 18/64 loss: -2.9526596069335938
Batch 19/64 loss: -2.641219139099121
Batch 20/64 loss: -2.626638412475586
Batch 21/64 loss: -2.5564956665039062
Batch 22/64 loss: -2.917217254638672
Batch 23/64 loss: -2.555501937866211
Batch 24/64 loss: -2.9015722274780273
Batch 25/64 loss: -2.964056968688965
Batch 26/64 loss: -2.6677589416503906
Batch 27/64 loss: -2.6477909088134766
Batch 28/64 loss: -2.8395814895629883
Batch 29/64 loss: -2.8588743209838867
Batch 30/64 loss: -2.8696765899658203
Batch 31/64 loss: -2.8879098892211914
Batch 32/64 loss: -2.637269973754883
Batch 33/64 loss: -2.7741928100585938
Batch 34/64 loss: -2.63671875
Batch 35/64 loss: -2.8966550827026367
Batch 36/64 loss: -2.898104667663574
Batch 37/64 loss: -2.8844051361083984
Batch 38/64 loss: -3.032504081726074
Batch 39/64 loss: -2.636127471923828
Batch 40/64 loss: -2.8967199325561523
Batch 41/64 loss: -2.898813247680664
Batch 42/64 loss: -2.865793228149414
Batch 43/64 loss: -2.838801383972168
Batch 44/64 loss: -2.90231990814209
Batch 45/64 loss: -2.5884132385253906
Batch 46/64 loss: -3.084134101867676
Batch 47/64 loss: -2.8567895889282227
Batch 48/64 loss: -2.9013595581054688
Batch 49/64 loss: -2.900461196899414
Batch 50/64 loss: -2.7494869232177734
Batch 51/64 loss: -2.9097824096679688
Batch 52/64 loss: -2.834580421447754
Batch 53/64 loss: -2.9255685806274414
Batch 54/64 loss: -2.6901941299438477
Batch 55/64 loss: -2.94985294342041
Batch 56/64 loss: -2.8371095657348633
Batch 57/64 loss: -3.123411178588867
Batch 58/64 loss: -2.654961585998535
Batch 59/64 loss: -2.937225341796875
Batch 60/64 loss: -3.020443916320801
Batch 61/64 loss: -2.872260093688965
Batch 62/64 loss: -3.0372695922851562
Batch 63/64 loss: -2.8042821884155273
Batch 64/64 loss: -7.129997730255127
Epoch 303  Train loss: -2.887746195699654  Val loss: -3.1733680410483447
Saving best model, epoch: 303
Epoch 304
-------------------------------
Batch 1/64 loss: -2.9556989669799805
Batch 2/64 loss: -2.8125009536743164
Batch 3/64 loss: -2.7395591735839844
Batch 4/64 loss: -3.002552032470703
Batch 5/64 loss: -3.0496387481689453
Batch 6/64 loss: -2.9131650924682617
Batch 7/64 loss: -2.9840221405029297
Batch 8/64 loss: -2.6466064453125
Batch 9/64 loss: -2.515392303466797
Batch 10/64 loss: -2.9229116439819336
Batch 11/64 loss: -2.8927392959594727
Batch 12/64 loss: -2.7625608444213867
Batch 13/64 loss: -2.9903860092163086
Batch 14/64 loss: -2.967719078063965
Batch 15/64 loss: -3.0029897689819336
Batch 16/64 loss: -2.8100128173828125
Batch 17/64 loss: -2.5412673950195312
Batch 18/64 loss: -2.976759910583496
Batch 19/64 loss: -2.8541135787963867
Batch 20/64 loss: -3.0064516067504883
Batch 21/64 loss: -2.9401674270629883
Batch 22/64 loss: -2.7028942108154297
Batch 23/64 loss: -2.7317352294921875
Batch 24/64 loss: -2.854175567626953
Batch 25/64 loss: -2.798185348510742
Batch 26/64 loss: -2.724869728088379
Batch 27/64 loss: -3.0873918533325195
Batch 28/64 loss: -2.9656057357788086
Batch 29/64 loss: -2.7703819274902344
Batch 30/64 loss: -2.8180580139160156
Batch 31/64 loss: -2.93841552734375
Batch 32/64 loss: -2.641303062438965
Batch 33/64 loss: -2.624171257019043
Batch 34/64 loss: -2.7295408248901367
Batch 35/64 loss: -2.912571907043457
Batch 36/64 loss: -2.8636837005615234
Batch 37/64 loss: -2.5273513793945312
Batch 38/64 loss: -3.0722875595092773
Batch 39/64 loss: -2.623800277709961
Batch 40/64 loss: -2.9333276748657227
Batch 41/64 loss: -2.796255111694336
Batch 42/64 loss: -2.874051094055176
Batch 43/64 loss: -2.189122200012207
Batch 44/64 loss: -2.961758613586426
Batch 45/64 loss: -3.0570907592773438
Batch 46/64 loss: -2.8167686462402344
Batch 47/64 loss: -2.8379507064819336
Batch 48/64 loss: -2.924528121948242
Batch 49/64 loss: -2.829848289489746
Batch 50/64 loss: -2.75759220123291
Batch 51/64 loss: -2.897916793823242
Batch 52/64 loss: -2.840177536010742
Batch 53/64 loss: -2.948366165161133
Batch 54/64 loss: -2.6559314727783203
Batch 55/64 loss: -3.015270233154297
Batch 56/64 loss: -2.978549003601074
Batch 57/64 loss: -2.897645950317383
Batch 58/64 loss: -2.66916561126709
Batch 59/64 loss: -2.8009872436523438
Batch 60/64 loss: -3.0452451705932617
Batch 61/64 loss: -3.0168256759643555
Batch 62/64 loss: -2.866182327270508
Batch 63/64 loss: -3.037886619567871
Batch 64/64 loss: -7.42382287979126
Epoch 304  Train loss: -2.900234489814908  Val loss: -3.106650060804439
Epoch 305
-------------------------------
Batch 1/64 loss: -2.8169775009155273
Batch 2/64 loss: -2.9493255615234375
Batch 3/64 loss: -2.8902997970581055
Batch 4/64 loss: -2.4822492599487305
Batch 5/64 loss: -2.8930234909057617
Batch 6/64 loss: -2.890216827392578
Batch 7/64 loss: -3.018697738647461
Batch 8/64 loss: -2.6685352325439453
Batch 9/64 loss: -3.0606937408447266
Batch 10/64 loss: -2.928241729736328
Batch 11/64 loss: -2.841153144836426
Batch 12/64 loss: -2.696183204650879
Batch 13/64 loss: -2.850094795227051
Batch 14/64 loss: -2.847339630126953
Batch 15/64 loss: -2.516465187072754
Batch 16/64 loss: -2.8566513061523438
Batch 17/64 loss: -2.9056339263916016
Batch 18/64 loss: -2.9873733520507812
Batch 19/64 loss: -2.743912696838379
Batch 20/64 loss: -2.7396249771118164
Batch 21/64 loss: -2.8120718002319336
Batch 22/64 loss: -2.6835384368896484
Batch 23/64 loss: -2.8865060806274414
Batch 24/64 loss: -2.690824508666992
Batch 25/64 loss: -2.747859001159668
Batch 26/64 loss: -2.903233528137207
Batch 27/64 loss: -3.0452489852905273
Batch 28/64 loss: -2.9707775115966797
Batch 29/64 loss: -2.947751998901367
Batch 30/64 loss: -2.6981983184814453
Batch 31/64 loss: -3.0473785400390625
Batch 32/64 loss: -2.6659250259399414
Batch 33/64 loss: -2.749378204345703
Batch 34/64 loss: -2.8677587509155273
Batch 35/64 loss: -2.749527931213379
Batch 36/64 loss: -2.917454719543457
Batch 37/64 loss: -2.9441041946411133
Batch 38/64 loss: -2.981228828430176
Batch 39/64 loss: -2.5367536544799805
Batch 40/64 loss: -2.5871877670288086
Batch 41/64 loss: -2.9980344772338867
Batch 42/64 loss: -2.968869209289551
Batch 43/64 loss: -3.047597885131836
Batch 44/64 loss: -2.458892822265625
Batch 45/64 loss: -2.8812828063964844
Batch 46/64 loss: -2.9461746215820312
Batch 47/64 loss: -2.865293502807617
Batch 48/64 loss: -2.75516414642334
Batch 49/64 loss: -2.5872421264648438
Batch 50/64 loss: -2.95111083984375
Batch 51/64 loss: -2.9385814666748047
Batch 52/64 loss: -2.6322593688964844
Batch 53/64 loss: -2.7273826599121094
Batch 54/64 loss: -3.052798271179199
Batch 55/64 loss: -3.0320377349853516
Batch 56/64 loss: -3.0141754150390625
Batch 57/64 loss: -3.0357885360717773
Batch 58/64 loss: -2.926790237426758
Batch 59/64 loss: -3.1341285705566406
Batch 60/64 loss: -2.929293632507324
Batch 61/64 loss: -2.609189033508301
Batch 62/64 loss: -2.8449573516845703
Batch 63/64 loss: -2.7020530700683594
Batch 64/64 loss: -7.335744857788086
Epoch 305  Train loss: -2.895000899071787  Val loss: -3.1200203911955002
Epoch 306
-------------------------------
Batch 1/64 loss: -2.930389404296875
Batch 2/64 loss: -2.9383010864257812
Batch 3/64 loss: -3.0873918533325195
Batch 4/64 loss: -2.7884178161621094
Batch 5/64 loss: -2.904085159301758
Batch 6/64 loss: -2.995391845703125
Batch 7/64 loss: -2.702463150024414
Batch 8/64 loss: -2.8482494354248047
Batch 9/64 loss: -2.493781089782715
Batch 10/64 loss: -3.010565757751465
Batch 11/64 loss: -3.0470056533813477
Batch 12/64 loss: -2.8844966888427734
Batch 13/64 loss: -2.865205764770508
Batch 14/64 loss: -2.703826904296875
Batch 15/64 loss: -2.7481775283813477
Batch 16/64 loss: -2.984217643737793
Batch 17/64 loss: -2.677967071533203
Batch 18/64 loss: -2.6797542572021484
Batch 19/64 loss: -2.8029537200927734
Batch 20/64 loss: -2.6699466705322266
Batch 21/64 loss: -2.681929588317871
Batch 22/64 loss: -2.6223621368408203
Batch 23/64 loss: -2.841843605041504
Batch 24/64 loss: -2.806464195251465
Batch 25/64 loss: -2.9854984283447266
Batch 26/64 loss: -2.7571706771850586
Batch 27/64 loss: -2.85275936126709
Batch 28/64 loss: -2.823558807373047
Batch 29/64 loss: -2.7746496200561523
Batch 30/64 loss: -2.937741279602051
Batch 31/64 loss: -2.982513427734375
Batch 32/64 loss: -2.8820009231567383
Batch 33/64 loss: -2.748562812805176
Batch 34/64 loss: -2.709339141845703
Batch 35/64 loss: -2.678727149963379
Batch 36/64 loss: -2.6462173461914062
Batch 37/64 loss: -3.0422582626342773
Batch 38/64 loss: -2.8340702056884766
Batch 39/64 loss: -2.7313079833984375
Batch 40/64 loss: -2.9022035598754883
Batch 41/64 loss: -3.0500640869140625
Batch 42/64 loss: -2.8777542114257812
Batch 43/64 loss: -2.7230396270751953
Batch 44/64 loss: -2.8268537521362305
Batch 45/64 loss: -3.061678886413574
Batch 46/64 loss: -2.965071678161621
Batch 47/64 loss: -2.8294878005981445
Batch 48/64 loss: -2.760197639465332
Batch 49/64 loss: -2.8389596939086914
Batch 50/64 loss: -2.4503707885742188
Batch 51/64 loss: -2.7612380981445312
Batch 52/64 loss: -2.7586889266967773
Batch 53/64 loss: -2.5642213821411133
Batch 54/64 loss: -2.811295509338379
Batch 55/64 loss: -2.5042715072631836
Batch 56/64 loss: -3.0685033798217773
Batch 57/64 loss: -2.8419265747070312
Batch 58/64 loss: -2.9817380905151367
Batch 59/64 loss: -2.7969884872436523
Batch 60/64 loss: -2.4531307220458984
Batch 61/64 loss: -3.0632171630859375
Batch 62/64 loss: -2.825937271118164
Batch 63/64 loss: -2.876859664916992
Batch 64/64 loss: -7.632111072540283
Epoch 306  Train loss: -2.8771662001516303  Val loss: -2.7234623702531007
Epoch 307
-------------------------------
Batch 1/64 loss: -2.3826589584350586
Batch 2/64 loss: -2.5084333419799805
Batch 3/64 loss: -2.9388113021850586
Batch 4/64 loss: -2.755343437194824
Batch 5/64 loss: -2.4942922592163086
Batch 6/64 loss: -2.959676742553711
Batch 7/64 loss: -2.727595329284668
Batch 8/64 loss: -2.811899185180664
Batch 9/64 loss: -2.9995508193969727
Batch 10/64 loss: -2.9084911346435547
Batch 11/64 loss: -2.8855180740356445
Batch 12/64 loss: -2.817896842956543
Batch 13/64 loss: -2.8018198013305664
Batch 14/64 loss: -2.9666290283203125
Batch 15/64 loss: -2.982224464416504
Batch 16/64 loss: -3.018442153930664
Batch 17/64 loss: -2.823801040649414
Batch 18/64 loss: -2.866487503051758
Batch 19/64 loss: -2.4092140197753906
Batch 20/64 loss: -2.7723865509033203
Batch 21/64 loss: -2.9624462127685547
Batch 22/64 loss: -2.7842941284179688
Batch 23/64 loss: -2.669745445251465
Batch 24/64 loss: -3.0037975311279297
Batch 25/64 loss: -2.881834030151367
Batch 26/64 loss: -2.6988420486450195
Batch 27/64 loss: -3.0094518661499023
Batch 28/64 loss: -2.533111572265625
Batch 29/64 loss: -2.6926050186157227
Batch 30/64 loss: -2.9434289932250977
Batch 31/64 loss: -2.7852602005004883
Batch 32/64 loss: -2.7954940795898438
Batch 33/64 loss: -2.8220510482788086
Batch 34/64 loss: -2.8431501388549805
Batch 35/64 loss: -2.8773984909057617
Batch 36/64 loss: -3.061735153198242
Batch 37/64 loss: -2.8953943252563477
Batch 38/64 loss: -2.7512617111206055
Batch 39/64 loss: -2.955129623413086
Batch 40/64 loss: -2.8128976821899414
Batch 41/64 loss: -2.966184616088867
Batch 42/64 loss: -2.5981435775756836
Batch 43/64 loss: -2.9195995330810547
Batch 44/64 loss: -2.837902069091797
Batch 45/64 loss: -2.8857030868530273
Batch 46/64 loss: -2.8335752487182617
Batch 47/64 loss: -2.895480155944824
Batch 48/64 loss: -2.8303918838500977
Batch 49/64 loss: -2.8960113525390625
Batch 50/64 loss: -2.8717336654663086
Batch 51/64 loss: -3.075868606567383
Batch 52/64 loss: -2.567007064819336
Batch 53/64 loss: -3.1013259887695312
Batch 54/64 loss: -2.877314567565918
Batch 55/64 loss: -2.7024059295654297
Batch 56/64 loss: -2.9299163818359375
Batch 57/64 loss: -2.730091094970703
Batch 58/64 loss: -3.0633325576782227
Batch 59/64 loss: -2.962080955505371
Batch 60/64 loss: -2.9885196685791016
Batch 61/64 loss: -2.90975284576416
Batch 62/64 loss: -2.8504552841186523
Batch 63/64 loss: -2.8434247970581055
Batch 64/64 loss: -7.586236953735352
Epoch 307  Train loss: -2.8931199990066827  Val loss: -3.133447181727878
Epoch 308
-------------------------------
Batch 1/64 loss: -2.8502187728881836
Batch 2/64 loss: -2.692233085632324
Batch 3/64 loss: -2.937265396118164
Batch 4/64 loss: -2.8203630447387695
Batch 5/64 loss: -3.0354108810424805
Batch 6/64 loss: -2.9507675170898438
Batch 7/64 loss: -3.041238784790039
Batch 8/64 loss: -2.749095916748047
Batch 9/64 loss: -2.7514724731445312
Batch 10/64 loss: -2.9175119400024414
Batch 11/64 loss: -2.9005794525146484
Batch 12/64 loss: -2.59932804107666
Batch 13/64 loss: -3.0568199157714844
Batch 14/64 loss: -3.1599998474121094
Batch 15/64 loss: -2.8335304260253906
Batch 16/64 loss: -2.811577796936035
Batch 17/64 loss: -2.942448616027832
Batch 18/64 loss: -2.9462385177612305
Batch 19/64 loss: -2.8227338790893555
Batch 20/64 loss: -2.8834543228149414
Batch 21/64 loss: -2.90625
Batch 22/64 loss: -2.7831249237060547
Batch 23/64 loss: -2.856884002685547
Batch 24/64 loss: -2.7002954483032227
Batch 25/64 loss: -2.9136791229248047
Batch 26/64 loss: -2.983983039855957
Batch 27/64 loss: -2.853729248046875
Batch 28/64 loss: -3.0443801879882812
Batch 29/64 loss: -2.986851692199707
Batch 30/64 loss: -2.9547462463378906
Batch 31/64 loss: -3.0951461791992188
Batch 32/64 loss: -2.8005199432373047
Batch 33/64 loss: -2.6557044982910156
Batch 34/64 loss: -3.005793571472168
Batch 35/64 loss: -2.6818056106567383
Batch 36/64 loss: -2.7270822525024414
Batch 37/64 loss: -2.7980947494506836
Batch 38/64 loss: -2.994352340698242
Batch 39/64 loss: -3.0573368072509766
Batch 40/64 loss: -2.9378862380981445
Batch 41/64 loss: -2.7997121810913086
Batch 42/64 loss: -2.983799934387207
Batch 43/64 loss: -2.9040069580078125
Batch 44/64 loss: -2.913980484008789
Batch 45/64 loss: -2.820603370666504
Batch 46/64 loss: -2.83530330657959
Batch 47/64 loss: -2.771542549133301
Batch 48/64 loss: -2.8481950759887695
Batch 49/64 loss: -2.7849864959716797
Batch 50/64 loss: -2.625162124633789
Batch 51/64 loss: -3.136935234069824
Batch 52/64 loss: -3.0557804107666016
Batch 53/64 loss: -2.9002885818481445
Batch 54/64 loss: -2.888503074645996
Batch 55/64 loss: -3.0706863403320312
Batch 56/64 loss: -2.800220489501953
Batch 57/64 loss: -2.9484071731567383
Batch 58/64 loss: -2.9978818893432617
Batch 59/64 loss: -3.000072479248047
Batch 60/64 loss: -2.6699600219726562
Batch 61/64 loss: -2.745171546936035
Batch 62/64 loss: -2.5395383834838867
Batch 63/64 loss: -2.6560726165771484
Batch 64/64 loss: -7.490298271179199
Epoch 308  Train loss: -2.9294818691178865  Val loss: -3.1570010234400168
Epoch 309
-------------------------------
Batch 1/64 loss: -2.6115550994873047
Batch 2/64 loss: -2.844050407409668
Batch 3/64 loss: -2.7220449447631836
Batch 4/64 loss: -2.968233108520508
Batch 5/64 loss: -2.7440366744995117
Batch 6/64 loss: -2.937983512878418
Batch 7/64 loss: -2.719095230102539
Batch 8/64 loss: -2.8867759704589844
Batch 9/64 loss: -2.9813995361328125
Batch 10/64 loss: -2.9660234451293945
Batch 11/64 loss: -2.6773719787597656
Batch 12/64 loss: -2.904841423034668
Batch 13/64 loss: -3.0621376037597656
Batch 14/64 loss: -2.891145706176758
Batch 15/64 loss: -3.108713150024414
Batch 16/64 loss: -3.0337467193603516
Batch 17/64 loss: -2.576827049255371
Batch 18/64 loss: -2.7817211151123047
Batch 19/64 loss: -2.835543632507324
Batch 20/64 loss: -2.9522171020507812
Batch 21/64 loss: -2.983658790588379
Batch 22/64 loss: -3.081117630004883
Batch 23/64 loss: -3.022106170654297
Batch 24/64 loss: -3.0514097213745117
Batch 25/64 loss: -2.965320587158203
Batch 26/64 loss: -2.826716423034668
Batch 27/64 loss: -2.8235769271850586
Batch 28/64 loss: -2.9110851287841797
Batch 29/64 loss: -2.995985984802246
Batch 30/64 loss: -2.8970069885253906
Batch 31/64 loss: -2.7724742889404297
Batch 32/64 loss: -3.004800796508789
Batch 33/64 loss: -2.9869794845581055
Batch 34/64 loss: -2.9883899688720703
Batch 35/64 loss: -2.967494010925293
Batch 36/64 loss: -2.7751693725585938
Batch 37/64 loss: -2.805948257446289
Batch 38/64 loss: -3.018418312072754
Batch 39/64 loss: -3.035524368286133
Batch 40/64 loss: -2.9853954315185547
Batch 41/64 loss: -3.044931411743164
Batch 42/64 loss: -2.8598060607910156
Batch 43/64 loss: -2.676759719848633
Batch 44/64 loss: -2.7212724685668945
Batch 45/64 loss: -3.0419235229492188
Batch 46/64 loss: -2.858734130859375
Batch 47/64 loss: -3.0699119567871094
Batch 48/64 loss: -2.7827234268188477
Batch 49/64 loss: -2.864347457885742
Batch 50/64 loss: -2.892481803894043
Batch 51/64 loss: -2.955611228942871
Batch 52/64 loss: -2.770711898803711
Batch 53/64 loss: -2.9021339416503906
Batch 54/64 loss: -2.8563127517700195
Batch 55/64 loss: -2.8379154205322266
Batch 56/64 loss: -2.82181453704834
Batch 57/64 loss: -2.841562271118164
Batch 58/64 loss: -2.917922019958496
Batch 59/64 loss: -2.8638954162597656
Batch 60/64 loss: -2.582815170288086
Batch 61/64 loss: -2.913228988647461
Batch 62/64 loss: -2.8125381469726562
Batch 63/64 loss: -2.774639129638672
Batch 64/64 loss: -7.293514251708984
Epoch 309  Train loss: -2.9370693431181065  Val loss: -3.153537225887128
Epoch 310
-------------------------------
Batch 1/64 loss: -2.826810836791992
Batch 2/64 loss: -2.744053840637207
Batch 3/64 loss: -2.9373703002929688
Batch 4/64 loss: -2.8929061889648438
Batch 5/64 loss: -2.873311996459961
Batch 6/64 loss: -2.9527034759521484
Batch 7/64 loss: -3.0143203735351562
Batch 8/64 loss: -2.9799718856811523
Batch 9/64 loss: -2.7351980209350586
Batch 10/64 loss: -3.105060577392578
Batch 11/64 loss: -3.0356216430664062
Batch 12/64 loss: -2.981503486633301
Batch 13/64 loss: -3.106379508972168
Batch 14/64 loss: -2.828547477722168
Batch 15/64 loss: -3.1113500595092773
Batch 16/64 loss: -3.101369857788086
Batch 17/64 loss: -2.913005828857422
Batch 18/64 loss: -2.87740421295166
Batch 19/64 loss: -2.9096832275390625
Batch 20/64 loss: -2.908644676208496
Batch 21/64 loss: -2.838499069213867
Batch 22/64 loss: -2.5995101928710938
Batch 23/64 loss: -2.8666391372680664
Batch 24/64 loss: -2.947652816772461
Batch 25/64 loss: -2.988035202026367
Batch 26/64 loss: -2.78472900390625
Batch 27/64 loss: -3.0133371353149414
Batch 28/64 loss: -2.67311954498291
Batch 29/64 loss: -2.8217811584472656
Batch 30/64 loss: -3.124500274658203
Batch 31/64 loss: -2.7728052139282227
Batch 32/64 loss: -2.9841575622558594
Batch 33/64 loss: -2.7611780166625977
Batch 34/64 loss: -2.87459659576416
Batch 35/64 loss: -2.7483787536621094
Batch 36/64 loss: -3.0326967239379883
Batch 37/64 loss: -2.835930824279785
Batch 38/64 loss: -2.9819908142089844
Batch 39/64 loss: -2.986569404602051
Batch 40/64 loss: -2.9324817657470703
Batch 41/64 loss: -2.6823415756225586
Batch 42/64 loss: -2.700921058654785
Batch 43/64 loss: -2.858705520629883
Batch 44/64 loss: -2.802267074584961
Batch 45/64 loss: -3.005753517150879
Batch 46/64 loss: -2.689746856689453
Batch 47/64 loss: -2.787051200866699
Batch 48/64 loss: -2.8983469009399414
Batch 49/64 loss: -2.9870243072509766
Batch 50/64 loss: -2.705141067504883
Batch 51/64 loss: -2.9394760131835938
Batch 52/64 loss: -2.6608285903930664
Batch 53/64 loss: -2.900327682495117
Batch 54/64 loss: -3.025172233581543
Batch 55/64 loss: -2.7443618774414062
Batch 56/64 loss: -2.7879419326782227
Batch 57/64 loss: -2.577897071838379
Batch 58/64 loss: -2.869396209716797
Batch 59/64 loss: -2.8120126724243164
Batch 60/64 loss: -2.922966957092285
Batch 61/64 loss: -2.8254175186157227
Batch 62/64 loss: -2.4037981033325195
Batch 63/64 loss: -2.9004898071289062
Batch 64/64 loss: -7.255619525909424
Epoch 310  Train loss: -2.922869130676868  Val loss: -3.1574670981705393
Epoch 311
-------------------------------
Batch 1/64 loss: -2.807870864868164
Batch 2/64 loss: -2.585293769836426
Batch 3/64 loss: -3.0092620849609375
Batch 4/64 loss: -2.87300968170166
Batch 5/64 loss: -2.957095146179199
Batch 6/64 loss: -2.695429801940918
Batch 7/64 loss: -2.9031143188476562
Batch 8/64 loss: -2.913311004638672
Batch 9/64 loss: -2.940401077270508
Batch 10/64 loss: -2.9502525329589844
Batch 11/64 loss: -2.7130489349365234
Batch 12/64 loss: -2.920530319213867
Batch 13/64 loss: -2.821080207824707
Batch 14/64 loss: -2.8252382278442383
Batch 15/64 loss: -3.038990020751953
Batch 16/64 loss: -2.920774459838867
Batch 17/64 loss: -2.713351249694824
Batch 18/64 loss: -2.8103599548339844
Batch 19/64 loss: -3.037355422973633
Batch 20/64 loss: -2.9000635147094727
Batch 21/64 loss: -2.596559524536133
Batch 22/64 loss: -2.7047595977783203
Batch 23/64 loss: -3.0155258178710938
Batch 24/64 loss: -2.8680295944213867
Batch 25/64 loss: -2.652528762817383
Batch 26/64 loss: -3.1298770904541016
Batch 27/64 loss: -2.81939697265625
Batch 28/64 loss: -2.830630302429199
Batch 29/64 loss: -2.850945472717285
Batch 30/64 loss: -2.798624038696289
Batch 31/64 loss: -2.811276435852051
Batch 32/64 loss: -2.755194664001465
Batch 33/64 loss: -3.04349422454834
Batch 34/64 loss: -2.933243751525879
Batch 35/64 loss: -3.021678924560547
Batch 36/64 loss: -2.715937614440918
Batch 37/64 loss: -3.110584259033203
Batch 38/64 loss: -3.04647159576416
Batch 39/64 loss: -2.6355972290039062
Batch 40/64 loss: -2.9701318740844727
Batch 41/64 loss: -2.716414451599121
Batch 42/64 loss: -2.751584053039551
Batch 43/64 loss: -2.8818626403808594
Batch 44/64 loss: -2.753795623779297
Batch 45/64 loss: -2.649186134338379
Batch 46/64 loss: -2.8613100051879883
Batch 47/64 loss: -2.9501495361328125
Batch 48/64 loss: -2.556483268737793
Batch 49/64 loss: -3.0746498107910156
Batch 50/64 loss: -2.913834571838379
Batch 51/64 loss: -3.0450048446655273
Batch 52/64 loss: -3.048870086669922
Batch 53/64 loss: -2.9293270111083984
Batch 54/64 loss: -2.9356260299682617
Batch 55/64 loss: -2.967090606689453
Batch 56/64 loss: -3.038705825805664
Batch 57/64 loss: -2.973796844482422
Batch 58/64 loss: -2.562793731689453
Batch 59/64 loss: -2.854058265686035
Batch 60/64 loss: -2.9461898803710938
Batch 61/64 loss: -2.9198856353759766
Batch 62/64 loss: -2.984933853149414
Batch 63/64 loss: -2.817087173461914
Batch 64/64 loss: -7.543410778045654
Epoch 311  Train loss: -2.9244944048862833  Val loss: -3.1360390915493785
Epoch 312
-------------------------------
Batch 1/64 loss: -2.7635860443115234
Batch 2/64 loss: -3.0931396484375
Batch 3/64 loss: -3.063878059387207
Batch 4/64 loss: -2.9383745193481445
Batch 5/64 loss: -2.4352827072143555
Batch 6/64 loss: -2.9118528366088867
Batch 7/64 loss: -3.0439558029174805
Batch 8/64 loss: -3.1272201538085938
Batch 9/64 loss: -2.8416852951049805
Batch 10/64 loss: -2.8517189025878906
Batch 11/64 loss: -2.9398889541625977
Batch 12/64 loss: -2.6226463317871094
Batch 13/64 loss: -2.924139976501465
Batch 14/64 loss: -2.566533088684082
Batch 15/64 loss: -3.1442623138427734
Batch 16/64 loss: -2.901434898376465
Batch 17/64 loss: -2.9430694580078125
Batch 18/64 loss: -2.6501102447509766
Batch 19/64 loss: -2.540432929992676
Batch 20/64 loss: -3.0629539489746094
Batch 21/64 loss: -2.8864402770996094
Batch 22/64 loss: -2.966398239135742
Batch 23/64 loss: -2.8973474502563477
Batch 24/64 loss: -2.9509458541870117
Batch 25/64 loss: -3.032520294189453
Batch 26/64 loss: -2.917128562927246
Batch 27/64 loss: -2.84146785736084
Batch 28/64 loss: -2.8287134170532227
Batch 29/64 loss: -2.666393280029297
Batch 30/64 loss: -2.9663867950439453
Batch 31/64 loss: -3.02001953125
Batch 32/64 loss: -2.9972639083862305
Batch 33/64 loss: -3.1536688804626465
Batch 34/64 loss: -2.787980079650879
Batch 35/64 loss: -2.966618537902832
Batch 36/64 loss: -2.923882484436035
Batch 37/64 loss: -2.914595603942871
Batch 38/64 loss: -2.974273681640625
Batch 39/64 loss: -2.8817291259765625
Batch 40/64 loss: -2.770907402038574
Batch 41/64 loss: -2.8769006729125977
Batch 42/64 loss: -2.991300582885742
Batch 43/64 loss: -2.7567596435546875
Batch 44/64 loss: -2.4806137084960938
Batch 45/64 loss: -3.0020952224731445
Batch 46/64 loss: -3.01806640625
Batch 47/64 loss: -2.921381950378418
Batch 48/64 loss: -2.9939346313476562
Batch 49/64 loss: -2.79473876953125
Batch 50/64 loss: -2.835068702697754
Batch 51/64 loss: -2.5767412185668945
Batch 52/64 loss: -2.9051828384399414
Batch 53/64 loss: -2.812032699584961
Batch 54/64 loss: -2.9375057220458984
Batch 55/64 loss: -2.9903078079223633
Batch 56/64 loss: -2.978693962097168
Batch 57/64 loss: -2.691965103149414
Batch 58/64 loss: -2.8797197341918945
Batch 59/64 loss: -2.9284067153930664
Batch 60/64 loss: -3.0015716552734375
Batch 61/64 loss: -2.8807802200317383
Batch 62/64 loss: -2.8550148010253906
Batch 63/64 loss: -2.964883804321289
Batch 64/64 loss: -7.328481197357178
Epoch 312  Train loss: -2.9377392133076987  Val loss: -3.157414413399713
Epoch 313
-------------------------------
Batch 1/64 loss: -2.8189077377319336
Batch 2/64 loss: -3.0757246017456055
Batch 3/64 loss: -2.8993234634399414
Batch 4/64 loss: -2.6974334716796875
Batch 5/64 loss: -2.764759063720703
Batch 6/64 loss: -3.094829559326172
Batch 7/64 loss: -2.907590866088867
Batch 8/64 loss: -3.134882926940918
Batch 9/64 loss: -3.1493263244628906
Batch 10/64 loss: -3.0939741134643555
Batch 11/64 loss: -2.9222984313964844
Batch 12/64 loss: -2.7991409301757812
Batch 13/64 loss: -2.6205310821533203
Batch 14/64 loss: -3.0441207885742188
Batch 15/64 loss: -2.8906869888305664
Batch 16/64 loss: -3.0017318725585938
Batch 17/64 loss: -2.8856630325317383
Batch 18/64 loss: -2.7369298934936523
Batch 19/64 loss: -2.9467906951904297
Batch 20/64 loss: -2.855463981628418
Batch 21/64 loss: -3.0676183700561523
Batch 22/64 loss: -2.3635997772216797
Batch 23/64 loss: -2.890530586242676
Batch 24/64 loss: -3.048463821411133
Batch 25/64 loss: -3.008472442626953
Batch 26/64 loss: -2.8873071670532227
Batch 27/64 loss: -2.6625595092773438
Batch 28/64 loss: -2.8068370819091797
Batch 29/64 loss: -2.8484630584716797
Batch 30/64 loss: -2.5167083740234375
Batch 31/64 loss: -2.3463287353515625
Batch 32/64 loss: -2.953463554382324
Batch 33/64 loss: -2.8532514572143555
Batch 34/64 loss: -3.0742034912109375
Batch 35/64 loss: -2.7367753982543945
Batch 36/64 loss: -2.9117822647094727
Batch 37/64 loss: -2.9136533737182617
Batch 38/64 loss: -2.656909942626953
Batch 39/64 loss: -2.760272979736328
Batch 40/64 loss: -3.0649824142456055
Batch 41/64 loss: -3.0218992233276367
Batch 42/64 loss: -2.763378143310547
Batch 43/64 loss: -2.6174631118774414
Batch 44/64 loss: -2.885422706604004
Batch 45/64 loss: -2.5812063217163086
Batch 46/64 loss: -2.8682661056518555
Batch 47/64 loss: -2.89321231842041
Batch 48/64 loss: -2.666792869567871
Batch 49/64 loss: -2.7224626541137695
Batch 50/64 loss: -2.6433591842651367
Batch 51/64 loss: -2.7507591247558594
Batch 52/64 loss: -2.7408218383789062
Batch 53/64 loss: -3.0046463012695312
Batch 54/64 loss: -2.9604053497314453
Batch 55/64 loss: -3.049297332763672
Batch 56/64 loss: -2.7168960571289062
Batch 57/64 loss: -2.89511775970459
Batch 58/64 loss: -2.7729454040527344
Batch 59/64 loss: -2.9853076934814453
Batch 60/64 loss: -3.046372413635254
Batch 61/64 loss: -2.928438186645508
Batch 62/64 loss: -2.94720458984375
Batch 63/64 loss: -2.918058395385742
Batch 64/64 loss: -7.252857208251953
Epoch 313  Train loss: -2.910300699869792  Val loss: -3.1073467739668907
Epoch 314
-------------------------------
Batch 1/64 loss: -2.8160104751586914
Batch 2/64 loss: -2.733919143676758
Batch 3/64 loss: -2.952695846557617
Batch 4/64 loss: -2.8429174423217773
Batch 5/64 loss: -2.7070388793945312
Batch 6/64 loss: -2.9671525955200195
Batch 7/64 loss: -3.043787956237793
Batch 8/64 loss: -2.8947486877441406
Batch 9/64 loss: -2.7454490661621094
Batch 10/64 loss: -2.8211841583251953
Batch 11/64 loss: -2.6628904342651367
Batch 12/64 loss: -2.8720531463623047
Batch 13/64 loss: -2.965205192565918
Batch 14/64 loss: -3.0284347534179688
Batch 15/64 loss: -3.011837959289551
Batch 16/64 loss: -2.724137306213379
Batch 17/64 loss: -2.497678756713867
Batch 18/64 loss: -2.6904802322387695
Batch 19/64 loss: -2.81292724609375
Batch 20/64 loss: -2.9365081787109375
Batch 21/64 loss: -2.6619081497192383
Batch 22/64 loss: -3.0485410690307617
Batch 23/64 loss: -3.0429468154907227
Batch 24/64 loss: -2.719541549682617
Batch 25/64 loss: -2.9877376556396484
Batch 26/64 loss: -2.891880989074707
Batch 27/64 loss: -3.015430450439453
Batch 28/64 loss: -2.8902320861816406
Batch 29/64 loss: -2.9376535415649414
Batch 30/64 loss: -3.0068044662475586
Batch 31/64 loss: -2.5901784896850586
Batch 32/64 loss: -2.576157569885254
Batch 33/64 loss: -2.911452293395996
Batch 34/64 loss: -2.823641777038574
Batch 35/64 loss: -2.655949592590332
Batch 36/64 loss: -2.897001266479492
Batch 37/64 loss: -3.024251937866211
Batch 38/64 loss: -2.789065361022949
Batch 39/64 loss: -2.919719696044922
Batch 40/64 loss: -2.848125457763672
Batch 41/64 loss: -2.501551628112793
Batch 42/64 loss: -2.9537105560302734
Batch 43/64 loss: -2.701700210571289
Batch 44/64 loss: -2.749131202697754
Batch 45/64 loss: -2.821640968322754
Batch 46/64 loss: -2.9527387619018555
Batch 47/64 loss: -2.5902223587036133
Batch 48/64 loss: -2.9939794540405273
Batch 49/64 loss: -2.7529611587524414
Batch 50/64 loss: -2.8349857330322266
Batch 51/64 loss: -3.0393686294555664
Batch 52/64 loss: -3.00258731842041
Batch 53/64 loss: -2.852151870727539
Batch 54/64 loss: -2.9839372634887695
Batch 55/64 loss: -2.7722721099853516
Batch 56/64 loss: -2.760981559753418
Batch 57/64 loss: -2.8619165420532227
Batch 58/64 loss: -2.579526901245117
Batch 59/64 loss: -2.9136581420898438
Batch 60/64 loss: -2.920236587524414
Batch 61/64 loss: -2.812985420227051
Batch 62/64 loss: -2.409769058227539
Batch 63/64 loss: -2.706146240234375
Batch 64/64 loss: -7.2632246017456055
Epoch 314  Train loss: -2.884405581156413  Val loss: -3.118069914198413
Epoch 315
-------------------------------
Batch 1/64 loss: -2.845457077026367
Batch 2/64 loss: -2.473952293395996
Batch 3/64 loss: -2.617826461791992
Batch 4/64 loss: -2.8688478469848633
Batch 5/64 loss: -2.964508056640625
Batch 6/64 loss: -2.684231758117676
Batch 7/64 loss: -2.2099733352661133
Batch 8/64 loss: -3.004239082336426
Batch 9/64 loss: -2.7218761444091797
Batch 10/64 loss: -2.943484306335449
Batch 11/64 loss: -2.779386520385742
Batch 12/64 loss: -2.766354560852051
Batch 13/64 loss: -2.7726831436157227
Batch 14/64 loss: -2.9486618041992188
Batch 15/64 loss: -2.9649658203125
Batch 16/64 loss: -3.134885787963867
Batch 17/64 loss: -2.8872575759887695
Batch 18/64 loss: -2.868666648864746
Batch 19/64 loss: -2.943208694458008
Batch 20/64 loss: -2.6945924758911133
Batch 21/64 loss: -2.6546850204467773
Batch 22/64 loss: -2.776637077331543
Batch 23/64 loss: -2.8078155517578125
Batch 24/64 loss: -2.864534378051758
Batch 25/64 loss: -2.9644203186035156
Batch 26/64 loss: -2.6570634841918945
Batch 27/64 loss: -2.9851293563842773
Batch 28/64 loss: -2.9672670364379883
Batch 29/64 loss: -2.8546009063720703
Batch 30/64 loss: -2.922419548034668
Batch 31/64 loss: -3.081083297729492
Batch 32/64 loss: -2.7502946853637695
Batch 33/64 loss: -2.827948570251465
Batch 34/64 loss: -2.7696352005004883
Batch 35/64 loss: -2.925553321838379
Batch 36/64 loss: -2.8814926147460938
Batch 37/64 loss: -2.936748504638672
Batch 38/64 loss: -2.921140670776367
Batch 39/64 loss: -2.7990331649780273
Batch 40/64 loss: -2.7299680709838867
Batch 41/64 loss: -3.015108108520508
Batch 42/64 loss: -2.806772232055664
Batch 43/64 loss: -2.9318838119506836
Batch 44/64 loss: -2.9109725952148438
Batch 45/64 loss: -2.8874406814575195
Batch 46/64 loss: -2.8306779861450195
Batch 47/64 loss: -2.767263412475586
Batch 48/64 loss: -2.68210506439209
Batch 49/64 loss: -2.700629234313965
Batch 50/64 loss: -2.8536643981933594
Batch 51/64 loss: -2.800877571105957
Batch 52/64 loss: -2.8216934204101562
Batch 53/64 loss: -2.9306507110595703
Batch 54/64 loss: -2.875030517578125
Batch 55/64 loss: -2.9505748748779297
Batch 56/64 loss: -2.90045166015625
Batch 57/64 loss: -2.8843841552734375
Batch 58/64 loss: -2.6648149490356445
Batch 59/64 loss: -2.7272119522094727
Batch 60/64 loss: -2.582770347595215
Batch 61/64 loss: -3.0571956634521484
Batch 62/64 loss: -2.824922561645508
Batch 63/64 loss: -2.864346504211426
Batch 64/64 loss: -7.3979034423828125
Epoch 315  Train loss: -2.8861552967744717  Val loss: -3.0982987053205875
Epoch 316
-------------------------------
Batch 1/64 loss: -2.894540786743164
Batch 2/64 loss: -2.836453437805176
Batch 3/64 loss: -2.9290199279785156
Batch 4/64 loss: -2.8968000411987305
Batch 5/64 loss: -2.6003990173339844
Batch 6/64 loss: -2.8025569915771484
Batch 7/64 loss: -2.993579864501953
Batch 8/64 loss: -2.8753347396850586
Batch 9/64 loss: -2.7537412643432617
Batch 10/64 loss: -2.8075380325317383
Batch 11/64 loss: -2.799250602722168
Batch 12/64 loss: -2.8788280487060547
Batch 13/64 loss: -2.9066524505615234
Batch 14/64 loss: -2.729084014892578
Batch 15/64 loss: -2.873964309692383
Batch 16/64 loss: -2.807366371154785
Batch 17/64 loss: -2.971271514892578
Batch 18/64 loss: -3.038853645324707
Batch 19/64 loss: -2.7706403732299805
Batch 20/64 loss: -2.8639707565307617
Batch 21/64 loss: -2.913290023803711
Batch 22/64 loss: -3.0449085235595703
Batch 23/64 loss: -2.7623071670532227
Batch 24/64 loss: -2.675485610961914
Batch 25/64 loss: -2.6860294342041016
Batch 26/64 loss: -2.5862369537353516
Batch 27/64 loss: -2.7882442474365234
Batch 28/64 loss: -2.8078060150146484
Batch 29/64 loss: -2.760274887084961
Batch 30/64 loss: -2.8669614791870117
Batch 31/64 loss: -2.855030059814453
Batch 32/64 loss: -2.8428306579589844
Batch 33/64 loss: -2.8742895126342773
Batch 34/64 loss: -2.918177604675293
Batch 35/64 loss: -2.873967170715332
Batch 36/64 loss: -3.1696271896362305
Batch 37/64 loss: -2.7139854431152344
Batch 38/64 loss: -2.987828254699707
Batch 39/64 loss: -2.902592658996582
Batch 40/64 loss: -3.0301103591918945
Batch 41/64 loss: -2.8811159133911133
Batch 42/64 loss: -2.9455461502075195
Batch 43/64 loss: -3.022571563720703
Batch 44/64 loss: -2.846282958984375
Batch 45/64 loss: -2.9730215072631836
Batch 46/64 loss: -2.788290023803711
Batch 47/64 loss: -2.651902198791504
Batch 48/64 loss: -2.9284238815307617
Batch 49/64 loss: -3.0988245010375977
Batch 50/64 loss: -2.801344871520996
Batch 51/64 loss: -3.0475597381591797
Batch 52/64 loss: -2.857891082763672
Batch 53/64 loss: -2.7357139587402344
Batch 54/64 loss: -3.141376495361328
Batch 55/64 loss: -3.1035871505737305
Batch 56/64 loss: -2.8809289932250977
Batch 57/64 loss: -2.749696731567383
Batch 58/64 loss: -2.7278099060058594
Batch 59/64 loss: -3.075575828552246
Batch 60/64 loss: -2.6824779510498047
Batch 61/64 loss: -2.8759469985961914
Batch 62/64 loss: -2.835206985473633
Batch 63/64 loss: -2.9133310317993164
Batch 64/64 loss: -6.724701404571533
Epoch 316  Train loss: -2.9129063830656166  Val loss: -3.0404744885631443
Epoch 317
-------------------------------
Batch 1/64 loss: -2.7213573455810547
Batch 2/64 loss: -2.9140853881835938
Batch 3/64 loss: -2.817843437194824
Batch 4/64 loss: -2.629659652709961
Batch 5/64 loss: -2.96182918548584
Batch 6/64 loss: -3.088979721069336
Batch 7/64 loss: -2.8315553665161133
Batch 8/64 loss: -3.054306983947754
Batch 9/64 loss: -2.7677574157714844
Batch 10/64 loss: -3.0305709838867188
Batch 11/64 loss: -3.0157155990600586
Batch 12/64 loss: -2.754831314086914
Batch 13/64 loss: -3.068937301635742
Batch 14/64 loss: -2.8886489868164062
Batch 15/64 loss: -3.0644454956054688
Batch 16/64 loss: -2.9847488403320312
Batch 17/64 loss: -2.9765634536743164
Batch 18/64 loss: -2.9733505249023438
Batch 19/64 loss: -2.8687429428100586
Batch 20/64 loss: -2.8402328491210938
Batch 21/64 loss: -2.9087705612182617
Batch 22/64 loss: -2.7312068939208984
Batch 23/64 loss: -2.983295440673828
Batch 24/64 loss: -2.5983591079711914
Batch 25/64 loss: -3.1353845596313477
Batch 26/64 loss: -2.9557323455810547
Batch 27/64 loss: -2.7559947967529297
Batch 28/64 loss: -2.8353309631347656
Batch 29/64 loss: -2.637073516845703
Batch 30/64 loss: -2.8905906677246094
Batch 31/64 loss: -2.83206844329834
Batch 32/64 loss: -3.0208816528320312
Batch 33/64 loss: -2.820584297180176
Batch 34/64 loss: -2.9067726135253906
Batch 35/64 loss: -2.608217239379883
Batch 36/64 loss: -2.8796844482421875
Batch 37/64 loss: -2.944368362426758
Batch 38/64 loss: -2.8449296951293945
Batch 39/64 loss: -2.863504409790039
Batch 40/64 loss: -2.9516496658325195
Batch 41/64 loss: -2.95613956451416
Batch 42/64 loss: -2.7670412063598633
Batch 43/64 loss: -2.804570198059082
Batch 44/64 loss: -3.100132942199707
Batch 45/64 loss: -2.972601890563965
Batch 46/64 loss: -2.827836036682129
Batch 47/64 loss: -2.9239301681518555
Batch 48/64 loss: -2.728907585144043
Batch 49/64 loss: -2.893488883972168
Batch 50/64 loss: -2.8530445098876953
Batch 51/64 loss: -2.8754491806030273
Batch 52/64 loss: -2.9447364807128906
Batch 53/64 loss: -2.7979564666748047
Batch 54/64 loss: -2.8410415649414062
Batch 55/64 loss: -2.6144304275512695
Batch 56/64 loss: -2.90248966217041
Batch 57/64 loss: -2.9615964889526367
Batch 58/64 loss: -2.8699331283569336
Batch 59/64 loss: -2.9176597595214844
Batch 60/64 loss: -2.6927356719970703
Batch 61/64 loss: -2.5982894897460938
Batch 62/64 loss: -2.874173164367676
Batch 63/64 loss: -2.8587160110473633
Batch 64/64 loss: -7.392515659332275
Epoch 317  Train loss: -2.925174112880931  Val loss: -3.1298909269247677
Epoch 318
-------------------------------
Batch 1/64 loss: -2.7566003799438477
Batch 2/64 loss: -2.810805320739746
Batch 3/64 loss: -2.647067070007324
Batch 4/64 loss: -2.9669065475463867
Batch 5/64 loss: -2.6352577209472656
Batch 6/64 loss: -2.9481725692749023
Batch 7/64 loss: -2.9708433151245117
Batch 8/64 loss: -3.0714731216430664
Batch 9/64 loss: -2.9092025756835938
Batch 10/64 loss: -3.0907392501831055
Batch 11/64 loss: -2.96334171295166
Batch 12/64 loss: -3.1206722259521484
Batch 13/64 loss: -2.4336843490600586
Batch 14/64 loss: -2.704669952392578
Batch 15/64 loss: -2.665085792541504
Batch 16/64 loss: -2.7382450103759766
Batch 17/64 loss: -2.862203598022461
Batch 18/64 loss: -3.0538949966430664
Batch 19/64 loss: -3.040837287902832
Batch 20/64 loss: -2.588076591491699
Batch 21/64 loss: -2.7177648544311523
Batch 22/64 loss: -2.957813262939453
Batch 23/64 loss: -2.8261947631835938
Batch 24/64 loss: -2.8001174926757812
Batch 25/64 loss: -2.917064666748047
Batch 26/64 loss: -3.0683698654174805
Batch 27/64 loss: -3.0087709426879883
Batch 28/64 loss: -3.0333738327026367
Batch 29/64 loss: -3.167705535888672
Batch 30/64 loss: -2.5450820922851562
Batch 31/64 loss: -2.9729862213134766
Batch 32/64 loss: -2.6361284255981445
Batch 33/64 loss: -3.144740104675293
Batch 34/64 loss: -2.863469123840332
Batch 35/64 loss: -2.7375564575195312
Batch 36/64 loss: -2.78891658782959
Batch 37/64 loss: -2.55301570892334
Batch 38/64 loss: -2.8418092727661133
Batch 39/64 loss: -2.9552059173583984
Batch 40/64 loss: -2.8641481399536133
Batch 41/64 loss: -2.7776336669921875
Batch 42/64 loss: -2.9880590438842773
Batch 43/64 loss: -2.9422035217285156
Batch 44/64 loss: -2.7282590866088867
Batch 45/64 loss: -2.691899299621582
Batch 46/64 loss: -3.0710582733154297
Batch 47/64 loss: -2.6959962844848633
Batch 48/64 loss: -2.873260498046875
Batch 49/64 loss: -2.923839569091797
Batch 50/64 loss: -3.073650360107422
Batch 51/64 loss: -3.0592031478881836
Batch 52/64 loss: -2.9714136123657227
Batch 53/64 loss: -2.708646774291992
Batch 54/64 loss: -2.997163772583008
Batch 55/64 loss: -2.8637285232543945
Batch 56/64 loss: -2.833507537841797
Batch 57/64 loss: -2.9203290939331055
Batch 58/64 loss: -2.5968780517578125
Batch 59/64 loss: -2.610844612121582
Batch 60/64 loss: -3.1242971420288086
Batch 61/64 loss: -2.750852584838867
Batch 62/64 loss: -2.809422492980957
Batch 63/64 loss: -2.8242788314819336
Batch 64/64 loss: -7.487734317779541
Epoch 318  Train loss: -2.9149841439490225  Val loss: -3.1340378830113362
Epoch 319
-------------------------------
Batch 1/64 loss: -2.7570247650146484
Batch 2/64 loss: -2.8772878646850586
Batch 3/64 loss: -3.003922462463379
Batch 4/64 loss: -2.8213062286376953
Batch 5/64 loss: -2.9056453704833984
Batch 6/64 loss: -2.962362289428711
Batch 7/64 loss: -2.966313362121582
Batch 8/64 loss: -2.805837631225586
Batch 9/64 loss: -2.699833869934082
Batch 10/64 loss: -2.960268020629883
Batch 11/64 loss: -2.98049259185791
Batch 12/64 loss: -2.847391128540039
Batch 13/64 loss: -2.965177536010742
Batch 14/64 loss: -2.8395004272460938
Batch 15/64 loss: -2.6536426544189453
Batch 16/64 loss: -2.8195037841796875
Batch 17/64 loss: -2.8132753372192383
Batch 18/64 loss: -2.491133689880371
Batch 19/64 loss: -2.6989307403564453
Batch 20/64 loss: -2.7414636611938477
Batch 21/64 loss: -2.8513364791870117
Batch 22/64 loss: -2.940143585205078
Batch 23/64 loss: -3.011049270629883
Batch 24/64 loss: -2.8351478576660156
Batch 25/64 loss: -2.7301855087280273
Batch 26/64 loss: -3.0012121200561523
Batch 27/64 loss: -2.888751983642578
Batch 28/64 loss: -2.7629356384277344
Batch 29/64 loss: -2.579988479614258
Batch 30/64 loss: -2.7396745681762695
Batch 31/64 loss: -2.719754219055176
Batch 32/64 loss: -3.0327396392822266
Batch 33/64 loss: -3.000575065612793
Batch 34/64 loss: -2.7916574478149414
Batch 35/64 loss: -2.7849197387695312
Batch 36/64 loss: -2.9839468002319336
Batch 37/64 loss: -2.9303665161132812
Batch 38/64 loss: -2.812811851501465
Batch 39/64 loss: -2.835993766784668
Batch 40/64 loss: -2.7193613052368164
Batch 41/64 loss: -3.0326194763183594
Batch 42/64 loss: -2.9848079681396484
Batch 43/64 loss: -2.952397346496582
Batch 44/64 loss: -3.044576644897461
Batch 45/64 loss: -2.78629207611084
Batch 46/64 loss: -2.822755813598633
Batch 47/64 loss: -2.885684013366699
Batch 48/64 loss: -3.0366334915161133
Batch 49/64 loss: -2.5971527099609375
Batch 50/64 loss: -2.8926076889038086
Batch 51/64 loss: -2.9407482147216797
Batch 52/64 loss: -3.037700653076172
Batch 53/64 loss: -2.821597099304199
Batch 54/64 loss: -3.0611867904663086
Batch 55/64 loss: -2.8080978393554688
Batch 56/64 loss: -2.869915008544922
Batch 57/64 loss: -2.820857048034668
Batch 58/64 loss: -2.8188533782958984
Batch 59/64 loss: -2.4477415084838867
Batch 60/64 loss: -2.852092742919922
Batch 61/64 loss: -3.08817195892334
Batch 62/64 loss: -3.0194520950317383
Batch 63/64 loss: -2.9309444427490234
Batch 64/64 loss: -7.457025051116943
Epoch 319  Train loss: -2.913074824389289  Val loss: -3.158248468772652
Epoch 320
-------------------------------
Batch 1/64 loss: -2.7759552001953125
Batch 2/64 loss: -3.120844841003418
Batch 3/64 loss: -3.061039924621582
Batch 4/64 loss: -2.8774337768554688
Batch 5/64 loss: -2.8585710525512695
Batch 6/64 loss: -2.529873847961426
Batch 7/64 loss: -2.8561601638793945
Batch 8/64 loss: -2.9801998138427734
Batch 9/64 loss: -2.7716245651245117
Batch 10/64 loss: -2.766322135925293
Batch 11/64 loss: -2.8606557846069336
Batch 12/64 loss: -3.043063163757324
Batch 13/64 loss: -2.85001277923584
Batch 14/64 loss: -2.843769073486328
Batch 15/64 loss: -2.9879817962646484
Batch 16/64 loss: -2.890033721923828
Batch 17/64 loss: -2.997213363647461
Batch 18/64 loss: -2.768857955932617
Batch 19/64 loss: -2.958780288696289
Batch 20/64 loss: -2.6793270111083984
Batch 21/64 loss: -2.9341373443603516
Batch 22/64 loss: -3.0172224044799805
Batch 23/64 loss: -3.0267200469970703
Batch 24/64 loss: -2.908428192138672
Batch 25/64 loss: -3.0825300216674805
Batch 26/64 loss: -2.9069995880126953
Batch 27/64 loss: -3.013669013977051
Batch 28/64 loss: -2.833834648132324
Batch 29/64 loss: -2.5094690322875977
Batch 30/64 loss: -2.466463088989258
Batch 31/64 loss: -2.8818063735961914
Batch 32/64 loss: -3.0210886001586914
Batch 33/64 loss: -2.9768075942993164
Batch 34/64 loss: -2.8350696563720703
Batch 35/64 loss: -2.8288984298706055
Batch 36/64 loss: -2.8378677368164062
Batch 37/64 loss: -3.0171384811401367
Batch 38/64 loss: -2.876185417175293
Batch 39/64 loss: -2.9382667541503906
Batch 40/64 loss: -2.717282295227051
Batch 41/64 loss: -2.9313058853149414
Batch 42/64 loss: -2.800161361694336
Batch 43/64 loss: -2.8794965744018555
Batch 44/64 loss: -2.7500228881835938
Batch 45/64 loss: -2.9808578491210938
Batch 46/64 loss: -2.924483299255371
Batch 47/64 loss: -2.894017219543457
Batch 48/64 loss: -2.7257089614868164
Batch 49/64 loss: -2.955648422241211
Batch 50/64 loss: -2.685688018798828
Batch 51/64 loss: -2.709040641784668
Batch 52/64 loss: -2.983184814453125
Batch 53/64 loss: -2.8286237716674805
Batch 54/64 loss: -3.037539482116699
Batch 55/64 loss: -2.7141427993774414
Batch 56/64 loss: -2.8217506408691406
Batch 57/64 loss: -3.0838184356689453
Batch 58/64 loss: -2.5134544372558594
Batch 59/64 loss: -2.6608028411865234
Batch 60/64 loss: -2.9407548904418945
Batch 61/64 loss: -2.915249824523926
Batch 62/64 loss: -3.152894973754883
Batch 63/64 loss: -2.817117691040039
Batch 64/64 loss: -7.38657283782959
Epoch 320  Train loss: -2.9231890248317343  Val loss: -3.0693165100726887
Epoch 321
-------------------------------
Batch 1/64 loss: -3.0046939849853516
Batch 2/64 loss: -2.9974708557128906
Batch 3/64 loss: -3.137143135070801
Batch 4/64 loss: -2.6514673233032227
Batch 5/64 loss: -3.0264692306518555
Batch 6/64 loss: -2.8563766479492188
Batch 7/64 loss: -2.8372888565063477
Batch 8/64 loss: -2.9056406021118164
Batch 9/64 loss: -2.846446990966797
Batch 10/64 loss: -3.0482406616210938
Batch 11/64 loss: -2.459620475769043
Batch 12/64 loss: -2.9188880920410156
Batch 13/64 loss: -2.7738218307495117
Batch 14/64 loss: -3.0585317611694336
Batch 15/64 loss: -3.03009033203125
Batch 16/64 loss: -2.917294502258301
Batch 17/64 loss: -2.816425323486328
Batch 18/64 loss: -3.0410242080688477
Batch 19/64 loss: -2.4594335556030273
Batch 20/64 loss: -3.033388137817383
Batch 21/64 loss: -2.9480714797973633
Batch 22/64 loss: -2.864828109741211
Batch 23/64 loss: -2.8412818908691406
Batch 24/64 loss: -2.913888931274414
Batch 25/64 loss: -2.8720340728759766
Batch 26/64 loss: -2.6839380264282227
Batch 27/64 loss: -2.9445371627807617
Batch 28/64 loss: -2.809347152709961
Batch 29/64 loss: -2.908475875854492
Batch 30/64 loss: -2.9073028564453125
Batch 31/64 loss: -2.9400062561035156
Batch 32/64 loss: -3.001462936401367
Batch 33/64 loss: -2.913792610168457
Batch 34/64 loss: -2.8369178771972656
Batch 35/64 loss: -2.845852851867676
Batch 36/64 loss: -3.0072813034057617
Batch 37/64 loss: -2.9532527923583984
Batch 38/64 loss: -3.043100357055664
Batch 39/64 loss: -3.0377731323242188
Batch 40/64 loss: -3.1135940551757812
Batch 41/64 loss: -2.842301368713379
Batch 42/64 loss: -2.273514747619629
Batch 43/64 loss: -2.900101661682129
Batch 44/64 loss: -2.9519433975219727
Batch 45/64 loss: -2.8968582153320312
Batch 46/64 loss: -2.789121627807617
Batch 47/64 loss: -2.916440963745117
Batch 48/64 loss: -2.5118274688720703
Batch 49/64 loss: -3.023710250854492
Batch 50/64 loss: -2.7201480865478516
Batch 51/64 loss: -3.0115718841552734
Batch 52/64 loss: -2.6737184524536133
Batch 53/64 loss: -2.7678327560424805
Batch 54/64 loss: -3.066622734069824
Batch 55/64 loss: -2.861945152282715
Batch 56/64 loss: -3.058779716491699
Batch 57/64 loss: -2.867985725402832
Batch 58/64 loss: -2.996448516845703
Batch 59/64 loss: -2.8578033447265625
Batch 60/64 loss: -2.8024721145629883
Batch 61/64 loss: -3.048786163330078
Batch 62/64 loss: -2.574216842651367
Batch 63/64 loss: -2.818849563598633
Batch 64/64 loss: -7.091552257537842
Epoch 321  Train loss: -2.9295397833281873  Val loss: -3.138170838765672
Epoch 322
-------------------------------
Batch 1/64 loss: -2.9033374786376953
Batch 2/64 loss: -3.0313072204589844
Batch 3/64 loss: -2.984219551086426
Batch 4/64 loss: -2.9382781982421875
Batch 5/64 loss: -2.9171323776245117
Batch 6/64 loss: -2.5433969497680664
Batch 7/64 loss: -2.8996076583862305
Batch 8/64 loss: -2.77463436126709
Batch 9/64 loss: -2.873673439025879
Batch 10/64 loss: -2.880767822265625
Batch 11/64 loss: -2.7242431640625
Batch 12/64 loss: -2.8550243377685547
Batch 13/64 loss: -3.1438379287719727
Batch 14/64 loss: -2.672098159790039
Batch 15/64 loss: -2.8172245025634766
Batch 16/64 loss: -2.989034652709961
Batch 17/64 loss: -2.8072166442871094
Batch 18/64 loss: -2.854482650756836
Batch 19/64 loss: -2.698990821838379
Batch 20/64 loss: -2.990553855895996
Batch 21/64 loss: -2.7731056213378906
Batch 22/64 loss: -3.0271873474121094
Batch 23/64 loss: -2.8754806518554688
Batch 24/64 loss: -2.841090202331543
Batch 25/64 loss: -2.9762516021728516
Batch 26/64 loss: -2.767486572265625
Batch 27/64 loss: -2.9891128540039062
Batch 28/64 loss: -2.907679557800293
Batch 29/64 loss: -2.9567480087280273
Batch 30/64 loss: -3.0314807891845703
Batch 31/64 loss: -3.141012191772461
Batch 32/64 loss: -2.741029739379883
Batch 33/64 loss: -2.488907814025879
Batch 34/64 loss: -2.971658706665039
Batch 35/64 loss: -2.759065628051758
Batch 36/64 loss: -3.0847597122192383
Batch 37/64 loss: -2.957120895385742
Batch 38/64 loss: -3.0142154693603516
Batch 39/64 loss: -2.858292579650879
Batch 40/64 loss: -2.91799259185791
Batch 41/64 loss: -3.0748472213745117
Batch 42/64 loss: -2.795527458190918
Batch 43/64 loss: -2.949845314025879
Batch 44/64 loss: -3.1155452728271484
Batch 45/64 loss: -2.969614028930664
Batch 46/64 loss: -3.07161808013916
Batch 47/64 loss: -3.0411062240600586
Batch 48/64 loss: -2.789884567260742
Batch 49/64 loss: -2.9909467697143555
Batch 50/64 loss: -3.0782508850097656
Batch 51/64 loss: -2.8986892700195312
Batch 52/64 loss: -3.019345283508301
Batch 53/64 loss: -2.902433395385742
Batch 54/64 loss: -2.979696273803711
Batch 55/64 loss: -2.6830291748046875
Batch 56/64 loss: -2.9157228469848633
Batch 57/64 loss: -2.976548194885254
Batch 58/64 loss: -2.7333755493164062
Batch 59/64 loss: -2.7166528701782227
Batch 60/64 loss: -2.7236404418945312
Batch 61/64 loss: -3.082864761352539
Batch 62/64 loss: -2.8904027938842773
Batch 63/64 loss: -2.6334877014160156
Batch 64/64 loss: -7.569454669952393
Epoch 322  Train loss: -2.9504142069349104  Val loss: -3.185149858088018
Saving best model, epoch: 322
Epoch 323
-------------------------------
Batch 1/64 loss: -2.8362503051757812
Batch 2/64 loss: -3.0208778381347656
Batch 3/64 loss: -3.0441436767578125
Batch 4/64 loss: -2.8985109329223633
Batch 5/64 loss: -2.9361419677734375
Batch 6/64 loss: -2.980001449584961
Batch 7/64 loss: -2.7103118896484375
Batch 8/64 loss: -2.9609222412109375
Batch 9/64 loss: -2.8198413848876953
Batch 10/64 loss: -2.6275806427001953
Batch 11/64 loss: -2.6342573165893555
Batch 12/64 loss: -3.009662628173828
Batch 13/64 loss: -2.864241600036621
Batch 14/64 loss: -2.8216733932495117
Batch 15/64 loss: -2.80100154876709
Batch 16/64 loss: -2.752509117126465
Batch 17/64 loss: -2.9616689682006836
Batch 18/64 loss: -2.9842090606689453
Batch 19/64 loss: -2.987982749938965
Batch 20/64 loss: -2.800572395324707
Batch 21/64 loss: -2.863658905029297
Batch 22/64 loss: -2.725849151611328
Batch 23/64 loss: -2.8824539184570312
Batch 24/64 loss: -2.838594436645508
Batch 25/64 loss: -2.7917070388793945
Batch 26/64 loss: -2.81777286529541
Batch 27/64 loss: -2.857513427734375
Batch 28/64 loss: -2.7744293212890625
Batch 29/64 loss: -2.9387893676757812
Batch 30/64 loss: -2.9747142791748047
Batch 31/64 loss: -2.930644989013672
Batch 32/64 loss: -3.1119070053100586
Batch 33/64 loss: -2.8489065170288086
Batch 34/64 loss: -2.6158018112182617
Batch 35/64 loss: -3.0316553115844727
Batch 36/64 loss: -2.955183982849121
Batch 37/64 loss: -2.9172821044921875
Batch 38/64 loss: -2.8835020065307617
Batch 39/64 loss: -2.900172233581543
Batch 40/64 loss: -2.7903871536254883
Batch 41/64 loss: -2.765742301940918
Batch 42/64 loss: -2.72200870513916
Batch 43/64 loss: -2.784613609313965
Batch 44/64 loss: -3.040675163269043
Batch 45/64 loss: -2.82437801361084
Batch 46/64 loss: -2.73544979095459
Batch 47/64 loss: -2.9711599349975586
Batch 48/64 loss: -2.899266242980957
Batch 49/64 loss: -2.9905529022216797
Batch 50/64 loss: -2.7936792373657227
Batch 51/64 loss: -3.038008689880371
Batch 52/64 loss: -3.037595748901367
Batch 53/64 loss: -3.0622615814208984
Batch 54/64 loss: -2.769031524658203
Batch 55/64 loss: -2.7786436080932617
Batch 56/64 loss: -2.810304641723633
Batch 57/64 loss: -2.8413848876953125
Batch 58/64 loss: -2.9524240493774414
Batch 59/64 loss: -2.9816951751708984
Batch 60/64 loss: -2.777982711791992
Batch 61/64 loss: -2.858064651489258
Batch 62/64 loss: -2.650524139404297
Batch 63/64 loss: -2.9320735931396484
Batch 64/64 loss: -7.466668128967285
Epoch 323  Train loss: -2.9258166107476926  Val loss: -3.1127555689860866
Epoch 324
-------------------------------
Batch 1/64 loss: -3.0178728103637695
Batch 2/64 loss: -3.055990219116211
Batch 3/64 loss: -2.924626350402832
Batch 4/64 loss: -2.917142868041992
Batch 5/64 loss: -2.9858474731445312
Batch 6/64 loss: -3.0988569259643555
Batch 7/64 loss: -2.8405637741088867
Batch 8/64 loss: -2.9377269744873047
Batch 9/64 loss: -2.3784399032592773
Batch 10/64 loss: -2.9650840759277344
Batch 11/64 loss: -2.9573097229003906
Batch 12/64 loss: -2.6544971466064453
Batch 13/64 loss: -2.7385635375976562
Batch 14/64 loss: -2.3404369354248047
Batch 15/64 loss: -2.9699697494506836
Batch 16/64 loss: -2.757195472717285
Batch 17/64 loss: -3.0531158447265625
Batch 18/64 loss: -2.821758270263672
Batch 19/64 loss: -2.9175291061401367
Batch 20/64 loss: -2.5876893997192383
Batch 21/64 loss: -2.6932191848754883
Batch 22/64 loss: -2.718494415283203
Batch 23/64 loss: -2.877513885498047
Batch 24/64 loss: -2.97428035736084
Batch 25/64 loss: -2.927596092224121
Batch 26/64 loss: -2.9578189849853516
Batch 27/64 loss: -3.0387935638427734
Batch 28/64 loss: -2.8204336166381836
Batch 29/64 loss: -2.745062828063965
Batch 30/64 loss: -2.7845821380615234
Batch 31/64 loss: -2.914104461669922
Batch 32/64 loss: -2.814419746398926
Batch 33/64 loss: -2.96364688873291
Batch 34/64 loss: -2.980867385864258
Batch 35/64 loss: -2.8533239364624023
Batch 36/64 loss: -3.0012454986572266
Batch 37/64 loss: -2.973421096801758
Batch 38/64 loss: -2.8283863067626953
Batch 39/64 loss: -3.0242137908935547
Batch 40/64 loss: -2.918705940246582
Batch 41/64 loss: -2.5582733154296875
Batch 42/64 loss: -2.8397254943847656
Batch 43/64 loss: -2.5516347885131836
Batch 44/64 loss: -2.688267707824707
Batch 45/64 loss: -2.935850143432617
Batch 46/64 loss: -2.935366630554199
Batch 47/64 loss: -3.050400733947754
Batch 48/64 loss: -2.9332189559936523
Batch 49/64 loss: -2.900716781616211
Batch 50/64 loss: -2.990046501159668
Batch 51/64 loss: -2.8203487396240234
Batch 52/64 loss: -2.9132490158081055
Batch 53/64 loss: -3.126004219055176
Batch 54/64 loss: -2.760228157043457
Batch 55/64 loss: -3.032162666320801
Batch 56/64 loss: -3.055678367614746
Batch 57/64 loss: -2.9172306060791016
Batch 58/64 loss: -2.7455644607543945
Batch 59/64 loss: -2.659115791320801
Batch 60/64 loss: -2.6767616271972656
Batch 61/64 loss: -2.674004554748535
Batch 62/64 loss: -2.7723913192749023
Batch 63/64 loss: -2.9702301025390625
Batch 64/64 loss: -7.535684585571289
Epoch 324  Train loss: -2.9158993066525927  Val loss: -3.1175837434853886
Epoch 325
-------------------------------
Batch 1/64 loss: -3.011873245239258
Batch 2/64 loss: -3.0186147689819336
Batch 3/64 loss: -3.082512855529785
Batch 4/64 loss: -2.864147186279297
Batch 5/64 loss: -3.02481746673584
Batch 6/64 loss: -2.914125442504883
Batch 7/64 loss: -2.645263671875
Batch 8/64 loss: -3.131981372833252
Batch 9/64 loss: -2.9783430099487305
Batch 10/64 loss: -2.8123340606689453
Batch 11/64 loss: -2.584061622619629
Batch 12/64 loss: -2.9458179473876953
Batch 13/64 loss: -2.8858985900878906
Batch 14/64 loss: -3.0931196212768555
Batch 15/64 loss: -2.7000341415405273
Batch 16/64 loss: -2.963685989379883
Batch 17/64 loss: -2.8001461029052734
Batch 18/64 loss: -2.9121007919311523
Batch 19/64 loss: -2.9763355255126953
Batch 20/64 loss: -2.6916427612304688
Batch 21/64 loss: -3.1465277671813965
Batch 22/64 loss: -3.0763931274414062
Batch 23/64 loss: -2.72536563873291
Batch 24/64 loss: -2.907942771911621
Batch 25/64 loss: -2.8731908798217773
Batch 26/64 loss: -3.0789499282836914
Batch 27/64 loss: -2.789630889892578
Batch 28/64 loss: -2.8474206924438477
Batch 29/64 loss: -3.0901660919189453
Batch 30/64 loss: -2.8286666870117188
Batch 31/64 loss: -2.6948604583740234
Batch 32/64 loss: -2.924851417541504
Batch 33/64 loss: -2.9590511322021484
Batch 34/64 loss: -2.978992462158203
Batch 35/64 loss: -2.9499340057373047
Batch 36/64 loss: -2.9827442169189453
Batch 37/64 loss: -2.9511966705322266
Batch 38/64 loss: -2.774502754211426
Batch 39/64 loss: -2.937211036682129
Batch 40/64 loss: -2.7704954147338867
Batch 41/64 loss: -2.624749183654785
Batch 42/64 loss: -2.328862190246582
Batch 43/64 loss: -2.87082576751709
Batch 44/64 loss: -3.021167755126953
Batch 45/64 loss: -3.102644920349121
Batch 46/64 loss: -2.7165746688842773
Batch 47/64 loss: -3.1203622817993164
Batch 48/64 loss: -2.906193733215332
Batch 49/64 loss: -2.9369916915893555
Batch 50/64 loss: -2.9336118698120117
Batch 51/64 loss: -2.6760330200195312
Batch 52/64 loss: -2.6740827560424805
Batch 53/64 loss: -2.75852108001709
Batch 54/64 loss: -2.689218521118164
Batch 55/64 loss: -2.7964916229248047
Batch 56/64 loss: -2.6907901763916016
Batch 57/64 loss: -2.8573684692382812
Batch 58/64 loss: -2.7855091094970703
Batch 59/64 loss: -2.8908815383911133
Batch 60/64 loss: -2.652017593383789
Batch 61/64 loss: -3.0829811096191406
Batch 62/64 loss: -2.989230155944824
Batch 63/64 loss: -2.7944250106811523
Batch 64/64 loss: -7.546983242034912
Epoch 325  Train loss: -2.9315250490226  Val loss: -3.0794650598899604
Epoch 326
-------------------------------
Batch 1/64 loss: -2.763308525085449
Batch 2/64 loss: -2.9444494247436523
Batch 3/64 loss: -2.828707695007324
Batch 4/64 loss: -2.8158016204833984
Batch 5/64 loss: -2.749762535095215
Batch 6/64 loss: -2.6563987731933594
Batch 7/64 loss: -2.7484664916992188
Batch 8/64 loss: -3.071908950805664
Batch 9/64 loss: -2.914242744445801
Batch 10/64 loss: -2.765833854675293
Batch 11/64 loss: -2.758970260620117
Batch 12/64 loss: -2.77756404876709
Batch 13/64 loss: -2.9882030487060547
Batch 14/64 loss: -3.078258514404297
Batch 15/64 loss: -2.609724998474121
Batch 16/64 loss: -2.7811079025268555
Batch 17/64 loss: -3.0728673934936523
Batch 18/64 loss: -2.93914794921875
Batch 19/64 loss: -2.8142995834350586
Batch 20/64 loss: -2.9434022903442383
Batch 21/64 loss: -2.8764877319335938
Batch 22/64 loss: -2.772024154663086
Batch 23/64 loss: -3.021158218383789
Batch 24/64 loss: -2.7425241470336914
Batch 25/64 loss: -3.027782440185547
Batch 26/64 loss: -2.933298110961914
Batch 27/64 loss: -2.976205825805664
Batch 28/64 loss: -2.501275062561035
Batch 29/64 loss: -2.9252214431762695
Batch 30/64 loss: -2.5891761779785156
Batch 31/64 loss: -2.876509666442871
Batch 32/64 loss: -2.966355323791504
Batch 33/64 loss: -2.8326120376586914
Batch 34/64 loss: -3.0106048583984375
Batch 35/64 loss: -2.9151430130004883
Batch 36/64 loss: -3.009100914001465
Batch 37/64 loss: -2.9402055740356445
Batch 38/64 loss: -2.691596031188965
Batch 39/64 loss: -3.009296417236328
Batch 40/64 loss: -2.948444366455078
Batch 41/64 loss: -2.9277219772338867
Batch 42/64 loss: -2.718398094177246
Batch 43/64 loss: -2.940659523010254
Batch 44/64 loss: -2.8342761993408203
Batch 45/64 loss: -2.9581737518310547
Batch 46/64 loss: -2.8874101638793945
Batch 47/64 loss: -2.6239147186279297
Batch 48/64 loss: -2.8472509384155273
Batch 49/64 loss: -2.9454221725463867
Batch 50/64 loss: -2.857069969177246
Batch 51/64 loss: -3.0354175567626953
Batch 52/64 loss: -2.7339134216308594
Batch 53/64 loss: -2.902912139892578
Batch 54/64 loss: -3.0230417251586914
Batch 55/64 loss: -2.945012092590332
Batch 56/64 loss: -3.174896240234375
Batch 57/64 loss: -2.922795295715332
Batch 58/64 loss: -2.9473190307617188
Batch 59/64 loss: -3.040297508239746
Batch 60/64 loss: -2.6314754486083984
Batch 61/64 loss: -2.9046010971069336
Batch 62/64 loss: -2.9430322647094727
Batch 63/64 loss: -2.8659439086914062
Batch 64/64 loss: -7.368227481842041
Epoch 326  Train loss: -2.9290129250171137  Val loss: -3.16775217744493
Epoch 327
-------------------------------
Batch 1/64 loss: -2.9978275299072266
Batch 2/64 loss: -2.7959518432617188
Batch 3/64 loss: -2.9352731704711914
Batch 4/64 loss: -3.0178442001342773
Batch 5/64 loss: -2.9610557556152344
Batch 6/64 loss: -2.7852954864501953
Batch 7/64 loss: -2.7309350967407227
Batch 8/64 loss: -2.9894771575927734
Batch 9/64 loss: -2.9335384368896484
Batch 10/64 loss: -3.063462257385254
Batch 11/64 loss: -3.030902862548828
Batch 12/64 loss: -2.8743982315063477
Batch 13/64 loss: -2.9371347427368164
Batch 14/64 loss: -2.4753379821777344
Batch 15/64 loss: -2.994203567504883
Batch 16/64 loss: -2.976353645324707
Batch 17/64 loss: -2.82205867767334
Batch 18/64 loss: -2.8950271606445312
Batch 19/64 loss: -2.9616098403930664
Batch 20/64 loss: -2.575894355773926
Batch 21/64 loss: -2.971010208129883
Batch 22/64 loss: -2.5678329467773438
Batch 23/64 loss: -3.0180721282958984
Batch 24/64 loss: -3.052274703979492
Batch 25/64 loss: -2.952880859375
Batch 26/64 loss: -2.7511825561523438
Batch 27/64 loss: -2.903693199157715
Batch 28/64 loss: -2.806647300720215
Batch 29/64 loss: -2.8792200088500977
Batch 30/64 loss: -2.8575029373168945
Batch 31/64 loss: -2.8139686584472656
Batch 32/64 loss: -2.8703536987304688
Batch 33/64 loss: -3.1198787689208984
Batch 34/64 loss: -2.8912830352783203
Batch 35/64 loss: -2.8319292068481445
Batch 36/64 loss: -2.767505645751953
Batch 37/64 loss: -2.9387102127075195
Batch 38/64 loss: -2.9730873107910156
Batch 39/64 loss: -2.8948822021484375
Batch 40/64 loss: -3.085683822631836
Batch 41/64 loss: -3.0821895599365234
Batch 42/64 loss: -3.000971794128418
Batch 43/64 loss: -2.7475690841674805
Batch 44/64 loss: -2.774545669555664
Batch 45/64 loss: -2.972470283508301
Batch 46/64 loss: -2.8992204666137695
Batch 47/64 loss: -2.6615991592407227
Batch 48/64 loss: -2.8049888610839844
Batch 49/64 loss: -2.921113967895508
Batch 50/64 loss: -2.7266435623168945
Batch 51/64 loss: -2.738727569580078
Batch 52/64 loss: -2.6298227310180664
Batch 53/64 loss: -2.696805000305176
Batch 54/64 loss: -2.7116384506225586
Batch 55/64 loss: -2.982571601867676
Batch 56/64 loss: -3.049912452697754
Batch 57/64 loss: -2.826793670654297
Batch 58/64 loss: -2.939922332763672
Batch 59/64 loss: -3.028339385986328
Batch 60/64 loss: -3.015848159790039
Batch 61/64 loss: -2.9011173248291016
Batch 62/64 loss: -2.912046432495117
Batch 63/64 loss: -2.884489059448242
Batch 64/64 loss: -7.513618469238281
Epoch 327  Train loss: -2.937188107359643  Val loss: -3.1478636961212683
Epoch 328
-------------------------------
Batch 1/64 loss: -2.9022560119628906
Batch 2/64 loss: -2.9143056869506836
Batch 3/64 loss: -3.0482473373413086
Batch 4/64 loss: -3.0121469497680664
Batch 5/64 loss: -2.6475963592529297
Batch 6/64 loss: -3.0965843200683594
Batch 7/64 loss: -2.8645200729370117
Batch 8/64 loss: -3.0548362731933594
Batch 9/64 loss: -2.9173355102539062
Batch 10/64 loss: -2.881253242492676
Batch 11/64 loss: -2.941208839416504
Batch 12/64 loss: -2.7475643157958984
Batch 13/64 loss: -3.025843620300293
Batch 14/64 loss: -2.8839216232299805
Batch 15/64 loss: -2.9824981689453125
Batch 16/64 loss: -2.878091812133789
Batch 17/64 loss: -3.0766210556030273
Batch 18/64 loss: -2.7752437591552734
Batch 19/64 loss: -2.3473949432373047
Batch 20/64 loss: -2.7763118743896484
Batch 21/64 loss: -2.781993865966797
Batch 22/64 loss: -2.8176021575927734
Batch 23/64 loss: -2.9093799591064453
Batch 24/64 loss: -2.8289175033569336
Batch 25/64 loss: -2.7368412017822266
Batch 26/64 loss: -2.741291046142578
Batch 27/64 loss: -3.062868118286133
Batch 28/64 loss: -2.6984243392944336
Batch 29/64 loss: -2.708028793334961
Batch 30/64 loss: -2.491779327392578
Batch 31/64 loss: -2.8029909133911133
Batch 32/64 loss: -2.971151351928711
Batch 33/64 loss: -2.914809226989746
Batch 34/64 loss: -2.6350440979003906
Batch 35/64 loss: -2.799860954284668
Batch 36/64 loss: -2.7086524963378906
Batch 37/64 loss: -2.957301139831543
Batch 38/64 loss: -2.794365882873535
Batch 39/64 loss: -2.913151741027832
Batch 40/64 loss: -2.7902307510375977
Batch 41/64 loss: -3.0096426010131836
Batch 42/64 loss: -2.8405466079711914
Batch 43/64 loss: -2.789030075073242
Batch 44/64 loss: -2.681546211242676
Batch 45/64 loss: -2.7949838638305664
Batch 46/64 loss: -2.825124740600586
Batch 47/64 loss: -2.7054872512817383
Batch 48/64 loss: -2.5762453079223633
Batch 49/64 loss: -2.790006637573242
Batch 50/64 loss: -2.9430160522460938
Batch 51/64 loss: -2.7181568145751953
Batch 52/64 loss: -3.0721817016601562
Batch 53/64 loss: -2.80810546875
Batch 54/64 loss: -3.0300474166870117
Batch 55/64 loss: -3.0699615478515625
Batch 56/64 loss: -2.9773550033569336
Batch 57/64 loss: -2.7284603118896484
Batch 58/64 loss: -3.0874500274658203
Batch 59/64 loss: -2.914004325866699
Batch 60/64 loss: -2.9961442947387695
Batch 61/64 loss: -2.989853858947754
Batch 62/64 loss: -2.8217716217041016
Batch 63/64 loss: -2.983182907104492
Batch 64/64 loss: -7.374453544616699
Epoch 328  Train loss: -2.9101429247388655  Val loss: -3.168911504581622
Epoch 329
-------------------------------
Batch 1/64 loss: -2.6034555435180664
Batch 2/64 loss: -2.6600427627563477
Batch 3/64 loss: -2.8866500854492188
Batch 4/64 loss: -2.9395217895507812
Batch 5/64 loss: -2.930830955505371
Batch 6/64 loss: -2.779041290283203
Batch 7/64 loss: -2.796314239501953
Batch 8/64 loss: -2.978435516357422
Batch 9/64 loss: -2.824127197265625
Batch 10/64 loss: -2.809206008911133
Batch 11/64 loss: -3.0335655212402344
Batch 12/64 loss: -2.676471710205078
Batch 13/64 loss: -2.6585874557495117
Batch 14/64 loss: -2.9245290756225586
Batch 15/64 loss: -3.0197343826293945
Batch 16/64 loss: -2.975907325744629
Batch 17/64 loss: -3.0683345794677734
Batch 18/64 loss: -3.032162666320801
Batch 19/64 loss: -2.7896852493286133
Batch 20/64 loss: -2.668463706970215
Batch 21/64 loss: -2.7404918670654297
Batch 22/64 loss: -2.9690427780151367
Batch 23/64 loss: -2.7921066284179688
Batch 24/64 loss: -3.030573844909668
Batch 25/64 loss: -2.8711366653442383
Batch 26/64 loss: -2.773202896118164
Batch 27/64 loss: -3.0635108947753906
Batch 28/64 loss: -2.9501352310180664
Batch 29/64 loss: -2.9379568099975586
Batch 30/64 loss: -2.6909408569335938
Batch 31/64 loss: -3.04941463470459
Batch 32/64 loss: -2.847296714782715
Batch 33/64 loss: -2.530827522277832
Batch 34/64 loss: -2.9403810501098633
Batch 35/64 loss: -3.0817441940307617
Batch 36/64 loss: -2.6185073852539062
Batch 37/64 loss: -2.930577278137207
Batch 38/64 loss: -2.6617517471313477
Batch 39/64 loss: -2.8587570190429688
Batch 40/64 loss: -3.067368507385254
Batch 41/64 loss: -3.117786407470703
Batch 42/64 loss: -2.900729179382324
Batch 43/64 loss: -2.578860282897949
Batch 44/64 loss: -2.749666213989258
Batch 45/64 loss: -2.886874198913574
Batch 46/64 loss: -2.9687881469726562
Batch 47/64 loss: -2.933450698852539
Batch 48/64 loss: -3.0106334686279297
Batch 49/64 loss: -2.7187414169311523
Batch 50/64 loss: -2.7679662704467773
Batch 51/64 loss: -2.921769142150879
Batch 52/64 loss: -2.7149276733398438
Batch 53/64 loss: -2.821812629699707
Batch 54/64 loss: -2.838542938232422
Batch 55/64 loss: -2.520843505859375
Batch 56/64 loss: -2.6955652236938477
Batch 57/64 loss: -2.88372802734375
Batch 58/64 loss: -2.98439884185791
Batch 59/64 loss: -2.918025016784668
Batch 60/64 loss: -2.886646270751953
Batch 61/64 loss: -2.946108818054199
Batch 62/64 loss: -2.813983917236328
Batch 63/64 loss: -2.7609262466430664
Batch 64/64 loss: -7.3916521072387695
Epoch 329  Train loss: -2.9073773365394744  Val loss: -3.1704956788787317
Epoch 330
-------------------------------
Batch 1/64 loss: -2.716546058654785
Batch 2/64 loss: -2.9518566131591797
Batch 3/64 loss: -2.889261245727539
Batch 4/64 loss: -2.935525894165039
Batch 5/64 loss: -2.845515251159668
Batch 6/64 loss: -2.9031972885131836
Batch 7/64 loss: -2.882871627807617
Batch 8/64 loss: -2.7241783142089844
Batch 9/64 loss: -2.788702964782715
Batch 10/64 loss: -2.8617448806762695
Batch 11/64 loss: -2.820831298828125
Batch 12/64 loss: -3.06744384765625
Batch 13/64 loss: -2.9967966079711914
Batch 14/64 loss: -2.872821807861328
Batch 15/64 loss: -2.9183530807495117
Batch 16/64 loss: -2.9049501419067383
Batch 17/64 loss: -2.7843379974365234
Batch 18/64 loss: -2.9968137741088867
Batch 19/64 loss: -2.942838668823242
Batch 20/64 loss: -3.0483713150024414
Batch 21/64 loss: -2.7971715927124023
Batch 22/64 loss: -2.8173694610595703
Batch 23/64 loss: -2.8640708923339844
Batch 24/64 loss: -2.86895751953125
Batch 25/64 loss: -2.96852970123291
Batch 26/64 loss: -2.842165946960449
Batch 27/64 loss: -2.688518524169922
Batch 28/64 loss: -2.837893486022949
Batch 29/64 loss: -2.9431514739990234
Batch 30/64 loss: -2.8144168853759766
Batch 31/64 loss: -2.9235410690307617
Batch 32/64 loss: -2.7245025634765625
Batch 33/64 loss: -2.903803825378418
Batch 34/64 loss: -2.811150550842285
Batch 35/64 loss: -3.0565948486328125
Batch 36/64 loss: -2.885702133178711
Batch 37/64 loss: -2.7781782150268555
Batch 38/64 loss: -2.413003921508789
Batch 39/64 loss: -2.72381591796875
Batch 40/64 loss: -2.788973808288574
Batch 41/64 loss: -3.0236330032348633
Batch 42/64 loss: -2.8747406005859375
Batch 43/64 loss: -2.7318782806396484
Batch 44/64 loss: -2.9930505752563477
Batch 45/64 loss: -2.8613080978393555
Batch 46/64 loss: -3.0862693786621094
Batch 47/64 loss: -2.825263023376465
Batch 48/64 loss: -2.8661441802978516
Batch 49/64 loss: -2.8646230697631836
Batch 50/64 loss: -2.7595348358154297
Batch 51/64 loss: -2.988239288330078
Batch 52/64 loss: -2.8644371032714844
Batch 53/64 loss: -2.886617660522461
Batch 54/64 loss: -2.7856693267822266
Batch 55/64 loss: -2.921992301940918
Batch 56/64 loss: -2.98410701751709
Batch 57/64 loss: -2.996943473815918
Batch 58/64 loss: -3.040191650390625
Batch 59/64 loss: -2.8024702072143555
Batch 60/64 loss: -2.909517288208008
Batch 61/64 loss: -3.063166618347168
Batch 62/64 loss: -2.9178380966186523
Batch 63/64 loss: -2.8536863327026367
Batch 64/64 loss: -7.625541687011719
Epoch 330  Train loss: -2.932156057918773  Val loss: -3.1918549422955595
Saving best model, epoch: 330
Epoch 331
-------------------------------
Batch 1/64 loss: -2.9693479537963867
Batch 2/64 loss: -2.6574182510375977
Batch 3/64 loss: -2.76735782623291
Batch 4/64 loss: -2.6452198028564453
Batch 5/64 loss: -3.050806999206543
Batch 6/64 loss: -2.8069868087768555
Batch 7/64 loss: -2.9528751373291016
Batch 8/64 loss: -2.9615306854248047
Batch 9/64 loss: -2.70742130279541
Batch 10/64 loss: -3.0535736083984375
Batch 11/64 loss: -2.9536705017089844
Batch 12/64 loss: -2.969491958618164
Batch 13/64 loss: -2.9763364791870117
Batch 14/64 loss: -2.9309558868408203
Batch 15/64 loss: -2.650461196899414
Batch 16/64 loss: -2.9072933197021484
Batch 17/64 loss: -3.0414514541625977
Batch 18/64 loss: -2.722146987915039
Batch 19/64 loss: -2.8311758041381836
Batch 20/64 loss: -3.019343376159668
Batch 21/64 loss: -2.6424331665039062
Batch 22/64 loss: -2.829409599304199
Batch 23/64 loss: -2.7088708877563477
Batch 24/64 loss: -3.075303077697754
Batch 25/64 loss: -2.9658126831054688
Batch 26/64 loss: -2.8866796493530273
Batch 27/64 loss: -2.8742456436157227
Batch 28/64 loss: -2.901651382446289
Batch 29/64 loss: -3.0025863647460938
Batch 30/64 loss: -2.796576499938965
Batch 31/64 loss: -2.94002628326416
Batch 32/64 loss: -2.89028263092041
Batch 33/64 loss: -3.1345205307006836
Batch 34/64 loss: -2.93172550201416
Batch 35/64 loss: -3.107189178466797
Batch 36/64 loss: -2.730036735534668
Batch 37/64 loss: -2.9318933486938477
Batch 38/64 loss: -2.797189712524414
Batch 39/64 loss: -2.7789058685302734
Batch 40/64 loss: -2.672088623046875
Batch 41/64 loss: -2.9273805618286133
Batch 42/64 loss: -2.770016670227051
Batch 43/64 loss: -2.6079206466674805
Batch 44/64 loss: -3.1178503036499023
Batch 45/64 loss: -3.010965347290039
Batch 46/64 loss: -3.1389951705932617
Batch 47/64 loss: -2.56691837310791
Batch 48/64 loss: -2.707087516784668
Batch 49/64 loss: -2.9490280151367188
Batch 50/64 loss: -2.8218555450439453
Batch 51/64 loss: -2.885211944580078
Batch 52/64 loss: -2.9644994735717773
Batch 53/64 loss: -2.921163558959961
Batch 54/64 loss: -2.9635019302368164
Batch 55/64 loss: -2.9269542694091797
Batch 56/64 loss: -2.8696041107177734
Batch 57/64 loss: -2.6963634490966797
Batch 58/64 loss: -3.0525522232055664
Batch 59/64 loss: -2.7532997131347656
Batch 60/64 loss: -2.7021303176879883
Batch 61/64 loss: -3.00616455078125
Batch 62/64 loss: -2.7709617614746094
Batch 63/64 loss: -3.067403793334961
Batch 64/64 loss: -7.061135292053223
Epoch 331  Train loss: -2.9280937007829255  Val loss: -3.218860377151122
Saving best model, epoch: 331
Epoch 332
-------------------------------
Batch 1/64 loss: -3.0260934829711914
Batch 2/64 loss: -2.769707679748535
Batch 3/64 loss: -3.022435188293457
Batch 4/64 loss: -2.6648855209350586
Batch 5/64 loss: -2.752293586730957
Batch 6/64 loss: -2.8451223373413086
Batch 7/64 loss: -2.7221717834472656
Batch 8/64 loss: -2.7989110946655273
Batch 9/64 loss: -2.9278783798217773
Batch 10/64 loss: -2.891751289367676
Batch 11/64 loss: -2.858173370361328
Batch 12/64 loss: -3.093151092529297
Batch 13/64 loss: -2.4955739974975586
Batch 14/64 loss: -3.0615596771240234
Batch 15/64 loss: -2.84964656829834
Batch 16/64 loss: -2.9926671981811523
Batch 17/64 loss: -2.9545249938964844
Batch 18/64 loss: -2.9791688919067383
Batch 19/64 loss: -3.0463666915893555
Batch 20/64 loss: -2.91274356842041
Batch 21/64 loss: -3.1272735595703125
Batch 22/64 loss: -3.0054750442504883
Batch 23/64 loss: -2.979724884033203
Batch 24/64 loss: -2.9031190872192383
Batch 25/64 loss: -3.064448356628418
Batch 26/64 loss: -2.9770631790161133
Batch 27/64 loss: -2.585799217224121
Batch 28/64 loss: -2.840137481689453
Batch 29/64 loss: -3.0350217819213867
Batch 30/64 loss: -2.950667381286621
Batch 31/64 loss: -2.9600305557250977
Batch 32/64 loss: -3.0361013412475586
Batch 33/64 loss: -2.9456138610839844
Batch 34/64 loss: -2.7134485244750977
Batch 35/64 loss: -3.082468032836914
Batch 36/64 loss: -2.86734676361084
Batch 37/64 loss: -2.8943347930908203
Batch 38/64 loss: -2.9358596801757812
Batch 39/64 loss: -2.924762725830078
Batch 40/64 loss: -3.037172317504883
Batch 41/64 loss: -2.973613739013672
Batch 42/64 loss: -3.0551834106445312
Batch 43/64 loss: -3.027207374572754
Batch 44/64 loss: -2.351302146911621
Batch 45/64 loss: -2.8229360580444336
Batch 46/64 loss: -2.7033472061157227
Batch 47/64 loss: -2.889012336730957
Batch 48/64 loss: -3.0005807876586914
Batch 49/64 loss: -2.71389102935791
Batch 50/64 loss: -2.887918472290039
Batch 51/64 loss: -2.916073799133301
Batch 52/64 loss: -3.012396812438965
Batch 53/64 loss: -2.808579444885254
Batch 54/64 loss: -3.041928291320801
Batch 55/64 loss: -3.0888261795043945
Batch 56/64 loss: -2.9522523880004883
Batch 57/64 loss: -2.842524528503418
Batch 58/64 loss: -2.848116874694824
Batch 59/64 loss: -3.0745391845703125
Batch 60/64 loss: -2.9463844299316406
Batch 61/64 loss: -2.8752517700195312
Batch 62/64 loss: -2.7342700958251953
Batch 63/64 loss: -2.9074220657348633
Batch 64/64 loss: -7.519095420837402
Epoch 332  Train loss: -2.959114901224772  Val loss: -3.1848255563847387
Epoch 333
-------------------------------
Batch 1/64 loss: -2.706385612487793
Batch 2/64 loss: -3.0043201446533203
Batch 3/64 loss: -2.8976831436157227
Batch 4/64 loss: -2.992621421813965
Batch 5/64 loss: -2.90371036529541
Batch 6/64 loss: -2.7780303955078125
Batch 7/64 loss: -3.0341501235961914
Batch 8/64 loss: -2.987773895263672
Batch 9/64 loss: -2.867936134338379
Batch 10/64 loss: -2.984868049621582
Batch 11/64 loss: -2.910201072692871
Batch 12/64 loss: -2.901308059692383
Batch 13/64 loss: -2.848616600036621
Batch 14/64 loss: -3.063054084777832
Batch 15/64 loss: -2.7639665603637695
Batch 16/64 loss: -2.7669286727905273
Batch 17/64 loss: -2.703322410583496
Batch 18/64 loss: -2.9534225463867188
Batch 19/64 loss: -3.015348434448242
Batch 20/64 loss: -2.9331398010253906
Batch 21/64 loss: -2.979914665222168
Batch 22/64 loss: -2.788008689880371
Batch 23/64 loss: -2.8734817504882812
Batch 24/64 loss: -2.9499740600585938
Batch 25/64 loss: -2.962418556213379
Batch 26/64 loss: -2.993292808532715
Batch 27/64 loss: -3.150838851928711
Batch 28/64 loss: -2.833433151245117
Batch 29/64 loss: -3.0324182510375977
Batch 30/64 loss: -3.1263484954833984
Batch 31/64 loss: -2.9248409271240234
Batch 32/64 loss: -3.0214157104492188
Batch 33/64 loss: -2.898345947265625
Batch 34/64 loss: -3.046304702758789
Batch 35/64 loss: -2.8042593002319336
Batch 36/64 loss: -2.683262825012207
Batch 37/64 loss: -2.77150821685791
Batch 38/64 loss: -2.7855958938598633
Batch 39/64 loss: -2.890705108642578
Batch 40/64 loss: -2.9718523025512695
Batch 41/64 loss: -2.795811653137207
Batch 42/64 loss: -2.726710319519043
Batch 43/64 loss: -2.9945812225341797
Batch 44/64 loss: -3.0154457092285156
Batch 45/64 loss: -2.6838932037353516
Batch 46/64 loss: -2.942620277404785
Batch 47/64 loss: -2.9758100509643555
Batch 48/64 loss: -3.0027008056640625
Batch 49/64 loss: -3.039078712463379
Batch 50/64 loss: -2.9249820709228516
Batch 51/64 loss: -2.7100791931152344
Batch 52/64 loss: -2.9594497680664062
Batch 53/64 loss: -3.1078062057495117
Batch 54/64 loss: -2.8537464141845703
Batch 55/64 loss: -2.6433353424072266
Batch 56/64 loss: -2.6521873474121094
Batch 57/64 loss: -2.9021949768066406
Batch 58/64 loss: -2.7732114791870117
Batch 59/64 loss: -3.028240203857422
Batch 60/64 loss: -2.8911399841308594
Batch 61/64 loss: -2.9205617904663086
Batch 62/64 loss: -2.8370609283447266
Batch 63/64 loss: -2.9419336318969727
Batch 64/64 loss: -7.383322238922119
Epoch 333  Train loss: -2.954746364144718  Val loss: -3.175469283795439
Epoch 334
-------------------------------
Batch 1/64 loss: -2.847041130065918
Batch 2/64 loss: -2.7547121047973633
Batch 3/64 loss: -2.9225378036499023
Batch 4/64 loss: -2.8549299240112305
Batch 5/64 loss: -2.8113574981689453
Batch 6/64 loss: -3.0192651748657227
Batch 7/64 loss: -2.970335006713867
Batch 8/64 loss: -2.9801712036132812
Batch 9/64 loss: -3.0708799362182617
Batch 10/64 loss: -2.991389274597168
Batch 11/64 loss: -2.7313232421875
Batch 12/64 loss: -3.077556610107422
Batch 13/64 loss: -3.0694150924682617
Batch 14/64 loss: -2.842489242553711
Batch 15/64 loss: -2.971278190612793
Batch 16/64 loss: -2.9378061294555664
Batch 17/64 loss: -2.627277374267578
Batch 18/64 loss: -2.812580108642578
Batch 19/64 loss: -2.9030399322509766
Batch 20/64 loss: -3.115886688232422
Batch 21/64 loss: -2.5706939697265625
Batch 22/64 loss: -2.8936805725097656
Batch 23/64 loss: -2.863959312438965
Batch 24/64 loss: -2.859208106994629
Batch 25/64 loss: -2.6991043090820312
Batch 26/64 loss: -2.895069122314453
Batch 27/64 loss: -2.8609580993652344
Batch 28/64 loss: -3.05635929107666
Batch 29/64 loss: -2.666354179382324
Batch 30/64 loss: -2.763106346130371
Batch 31/64 loss: -2.700084686279297
Batch 32/64 loss: -2.7678298950195312
Batch 33/64 loss: -2.8397035598754883
Batch 34/64 loss: -2.964230537414551
Batch 35/64 loss: -2.7290096282958984
Batch 36/64 loss: -3.016796112060547
Batch 37/64 loss: -2.8852767944335938
Batch 38/64 loss: -2.95438289642334
Batch 39/64 loss: -2.7704696655273438
Batch 40/64 loss: -2.879426956176758
Batch 41/64 loss: -3.1512928009033203
Batch 42/64 loss: -3.0181589126586914
Batch 43/64 loss: -2.741806983947754
Batch 44/64 loss: -3.0371551513671875
Batch 45/64 loss: -3.118119239807129
Batch 46/64 loss: -2.8192853927612305
Batch 47/64 loss: -2.546694755554199
Batch 48/64 loss: -2.9403018951416016
Batch 49/64 loss: -3.043764114379883
Batch 50/64 loss: -2.8186941146850586
Batch 51/64 loss: -2.835129737854004
Batch 52/64 loss: -3.0041561126708984
Batch 53/64 loss: -2.736058235168457
Batch 54/64 loss: -2.8154296875
Batch 55/64 loss: -3.0538930892944336
Batch 56/64 loss: -2.7721567153930664
Batch 57/64 loss: -2.896587371826172
Batch 58/64 loss: -2.901545524597168
Batch 59/64 loss: -2.9669342041015625
Batch 60/64 loss: -3.00284481048584
Batch 61/64 loss: -2.9382925033569336
Batch 62/64 loss: -2.8294992446899414
Batch 63/64 loss: -2.7602720260620117
Batch 64/64 loss: -7.438793182373047
Epoch 334  Train loss: -2.9376336191214767  Val loss: -3.154339688750067
Epoch 335
-------------------------------
Batch 1/64 loss: -2.649616241455078
Batch 2/64 loss: -2.7975082397460938
Batch 3/64 loss: -2.7560062408447266
Batch 4/64 loss: -2.513124465942383
Batch 5/64 loss: -2.8510589599609375
Batch 6/64 loss: -3.025737762451172
Batch 7/64 loss: -2.8798017501831055
Batch 8/64 loss: -2.942136764526367
Batch 9/64 loss: -2.929248809814453
Batch 10/64 loss: -3.0255327224731445
Batch 11/64 loss: -2.77785587310791
Batch 12/64 loss: -2.866180419921875
Batch 13/64 loss: -3.02463436126709
Batch 14/64 loss: -2.925283432006836
Batch 15/64 loss: -2.965496063232422
Batch 16/64 loss: -3.0503931045532227
Batch 17/64 loss: -3.0246620178222656
Batch 18/64 loss: -2.964021682739258
Batch 19/64 loss: -2.7091732025146484
Batch 20/64 loss: -2.8710250854492188
Batch 21/64 loss: -3.122516632080078
Batch 22/64 loss: -2.8048295974731445
Batch 23/64 loss: -3.0872278213500977
Batch 24/64 loss: -3.0187902450561523
Batch 25/64 loss: -2.6351823806762695
Batch 26/64 loss: -2.892767906188965
Batch 27/64 loss: -2.6507015228271484
Batch 28/64 loss: -3.0366744995117188
Batch 29/64 loss: -2.7839832305908203
Batch 30/64 loss: -2.675581932067871
Batch 31/64 loss: -2.608323097229004
Batch 32/64 loss: -2.8465700149536133
Batch 33/64 loss: -2.9267663955688477
Batch 34/64 loss: -3.064981460571289
Batch 35/64 loss: -2.9322023391723633
Batch 36/64 loss: -2.7562217712402344
Batch 37/64 loss: -2.9494028091430664
Batch 38/64 loss: -2.4063806533813477
Batch 39/64 loss: -3.0829219818115234
Batch 40/64 loss: -2.6745424270629883
Batch 41/64 loss: -3.132356643676758
Batch 42/64 loss: -2.948641777038574
Batch 43/64 loss: -2.773540496826172
Batch 44/64 loss: -2.778517723083496
Batch 45/64 loss: -2.9669418334960938
Batch 46/64 loss: -2.9522762298583984
Batch 47/64 loss: -2.6849775314331055
Batch 48/64 loss: -2.9635982513427734
Batch 49/64 loss: -2.857707977294922
Batch 50/64 loss: -3.024319648742676
Batch 51/64 loss: -3.020639419555664
Batch 52/64 loss: -2.7086610794067383
Batch 53/64 loss: -2.943789482116699
Batch 54/64 loss: -2.843134880065918
Batch 55/64 loss: -3.0926923751831055
Batch 56/64 loss: -2.9693117141723633
Batch 57/64 loss: -2.789947509765625
Batch 58/64 loss: -3.0503883361816406
Batch 59/64 loss: -2.625535011291504
Batch 60/64 loss: -2.9838972091674805
Batch 61/64 loss: -2.9533472061157227
Batch 62/64 loss: -2.7915992736816406
Batch 63/64 loss: -2.807206153869629
Batch 64/64 loss: -7.542031764984131
Epoch 335  Train loss: -2.9305822353737025  Val loss: -3.176422368210206
Epoch 336
-------------------------------
Batch 1/64 loss: -2.9324169158935547
Batch 2/64 loss: -2.9666261672973633
Batch 3/64 loss: -2.8975276947021484
Batch 4/64 loss: -3.0272998809814453
Batch 5/64 loss: -2.8650388717651367
Batch 6/64 loss: -2.8770275115966797
Batch 7/64 loss: -2.8469181060791016
Batch 8/64 loss: -2.967571258544922
Batch 9/64 loss: -3.091522216796875
Batch 10/64 loss: -2.9469966888427734
Batch 11/64 loss: -2.8378305435180664
Batch 12/64 loss: -2.705974578857422
Batch 13/64 loss: -2.9087915420532227
Batch 14/64 loss: -2.5294742584228516
Batch 15/64 loss: -2.9877214431762695
Batch 16/64 loss: -2.7738447189331055
Batch 17/64 loss: -3.0758657455444336
Batch 18/64 loss: -2.83107852935791
Batch 19/64 loss: -3.098308563232422
Batch 20/64 loss: -3.026129722595215
Batch 21/64 loss: -2.856321334838867
Batch 22/64 loss: -2.819965362548828
Batch 23/64 loss: -2.8188915252685547
Batch 24/64 loss: -2.9791946411132812
Batch 25/64 loss: -3.080805778503418
Batch 26/64 loss: -3.05142879486084
Batch 27/64 loss: -2.8368120193481445
Batch 28/64 loss: -3.0292491912841797
Batch 29/64 loss: -2.8252296447753906
Batch 30/64 loss: -2.8265151977539062
Batch 31/64 loss: -2.9309616088867188
Batch 32/64 loss: -2.9968318939208984
Batch 33/64 loss: -2.983020782470703
Batch 34/64 loss: -2.674208641052246
Batch 35/64 loss: -2.661320686340332
Batch 36/64 loss: -3.055659294128418
Batch 37/64 loss: -3.0792837142944336
Batch 38/64 loss: -2.9357967376708984
Batch 39/64 loss: -2.906312942504883
Batch 40/64 loss: -2.806234359741211
Batch 41/64 loss: -2.714625358581543
Batch 42/64 loss: -2.712078094482422
Batch 43/64 loss: -3.0370073318481445
Batch 44/64 loss: -2.8846492767333984
Batch 45/64 loss: -2.7835264205932617
Batch 46/64 loss: -2.8385791778564453
Batch 47/64 loss: -2.880793571472168
Batch 48/64 loss: -2.709371566772461
Batch 49/64 loss: -2.836790084838867
Batch 50/64 loss: -2.9051904678344727
Batch 51/64 loss: -2.8509225845336914
Batch 52/64 loss: -3.0204010009765625
Batch 53/64 loss: -3.0344810485839844
Batch 54/64 loss: -3.090651512145996
Batch 55/64 loss: -3.0483598709106445
Batch 56/64 loss: -2.818723678588867
Batch 57/64 loss: -2.9067258834838867
Batch 58/64 loss: -2.8111343383789062
Batch 59/64 loss: -3.005746841430664
Batch 60/64 loss: -2.6829166412353516
Batch 61/64 loss: -3.024477005004883
Batch 62/64 loss: -3.0322275161743164
Batch 63/64 loss: -2.756157875061035
Batch 64/64 loss: -7.461784839630127
Epoch 336  Train loss: -2.954194272733202  Val loss: -3.2011708393949005
Epoch 337
-------------------------------
Batch 1/64 loss: -2.876650810241699
Batch 2/64 loss: -3.020833969116211
Batch 3/64 loss: -2.75376033782959
Batch 4/64 loss: -3.0455102920532227
Batch 5/64 loss: -3.064004898071289
Batch 6/64 loss: -2.9606332778930664
Batch 7/64 loss: -3.0033226013183594
Batch 8/64 loss: -2.7714691162109375
Batch 9/64 loss: -3.087055206298828
Batch 10/64 loss: -2.836054801940918
Batch 11/64 loss: -2.795074462890625
Batch 12/64 loss: -2.856260299682617
Batch 13/64 loss: -2.7515459060668945
Batch 14/64 loss: -2.926816940307617
Batch 15/64 loss: -3.1887550354003906
Batch 16/64 loss: -3.105902671813965
Batch 17/64 loss: -3.029505729675293
Batch 18/64 loss: -2.6960830688476562
Batch 19/64 loss: -2.8581151962280273
Batch 20/64 loss: -2.961520195007324
Batch 21/64 loss: -2.928739547729492
Batch 22/64 loss: -3.0212574005126953
Batch 23/64 loss: -3.01849365234375
Batch 24/64 loss: -2.7664928436279297
Batch 25/64 loss: -2.9287710189819336
Batch 26/64 loss: -3.094252586364746
Batch 27/64 loss: -2.9129648208618164
Batch 28/64 loss: -2.9106874465942383
Batch 29/64 loss: -2.4634342193603516
Batch 30/64 loss: -2.952056884765625
Batch 31/64 loss: -2.8541078567504883
Batch 32/64 loss: -2.630512237548828
Batch 33/64 loss: -3.030975341796875
Batch 34/64 loss: -2.8794307708740234
Batch 35/64 loss: -2.8098583221435547
Batch 36/64 loss: -2.863901138305664
Batch 37/64 loss: -2.906975746154785
Batch 38/64 loss: -3.0555267333984375
Batch 39/64 loss: -2.9179325103759766
Batch 40/64 loss: -2.912302017211914
Batch 41/64 loss: -2.9469966888427734
Batch 42/64 loss: -2.773477554321289
Batch 43/64 loss: -2.9735822677612305
Batch 44/64 loss: -2.593276023864746
Batch 45/64 loss: -3.038058280944824
Batch 46/64 loss: -2.873215675354004
Batch 47/64 loss: -2.7365636825561523
Batch 48/64 loss: -2.7914915084838867
Batch 49/64 loss: -2.86907958984375
Batch 50/64 loss: -3.0101003646850586
Batch 51/64 loss: -2.699831962585449
Batch 52/64 loss: -2.709822654724121
Batch 53/64 loss: -2.8954553604125977
Batch 54/64 loss: -3.054917335510254
Batch 55/64 loss: -2.718794822692871
Batch 56/64 loss: -2.87786865234375
Batch 57/64 loss: -2.487966537475586
Batch 58/64 loss: -2.8587684631347656
Batch 59/64 loss: -2.8097944259643555
Batch 60/64 loss: -3.0607404708862305
Batch 61/64 loss: -2.451934814453125
Batch 62/64 loss: -3.0144243240356445
Batch 63/64 loss: -2.947270393371582
Batch 64/64 loss: -7.384925365447998
Epoch 337  Train loss: -2.936151745740105  Val loss: -3.1744220248612343
Epoch 338
-------------------------------
Batch 1/64 loss: -3.078352928161621
Batch 2/64 loss: -2.9294862747192383
Batch 3/64 loss: -2.840090751647949
Batch 4/64 loss: -2.9789962768554688
Batch 5/64 loss: -2.6530981063842773
Batch 6/64 loss: -2.538893699645996
Batch 7/64 loss: -2.8108978271484375
Batch 8/64 loss: -2.900944709777832
Batch 9/64 loss: -2.959742546081543
Batch 10/64 loss: -2.8035507202148438
Batch 11/64 loss: -2.929004669189453
Batch 12/64 loss: -2.9469146728515625
Batch 13/64 loss: -3.0693531036376953
Batch 14/64 loss: -2.529351234436035
Batch 15/64 loss: -2.9758358001708984
Batch 16/64 loss: -2.7784881591796875
Batch 17/64 loss: -2.8581113815307617
Batch 18/64 loss: -2.920103073120117
Batch 19/64 loss: -3.0736751556396484
Batch 20/64 loss: -3.076714515686035
Batch 21/64 loss: -3.0095605850219727
Batch 22/64 loss: -3.185698986053467
Batch 23/64 loss: -3.0410871505737305
Batch 24/64 loss: -2.7766151428222656
Batch 25/64 loss: -2.9996442794799805
Batch 26/64 loss: -2.728799819946289
Batch 27/64 loss: -2.8568248748779297
Batch 28/64 loss: -3.042379379272461
Batch 29/64 loss: -2.9699106216430664
Batch 30/64 loss: -2.490109443664551
Batch 31/64 loss: -2.8911046981811523
Batch 32/64 loss: -2.81610107421875
Batch 33/64 loss: -2.808802604675293
Batch 34/64 loss: -2.7165327072143555
Batch 35/64 loss: -2.851276397705078
Batch 36/64 loss: -3.0358734130859375
Batch 37/64 loss: -3.0743751525878906
Batch 38/64 loss: -2.7474565505981445
Batch 39/64 loss: -2.8788528442382812
Batch 40/64 loss: -2.6647653579711914
Batch 41/64 loss: -2.851851463317871
Batch 42/64 loss: -2.9819297790527344
Batch 43/64 loss: -2.974043846130371
Batch 44/64 loss: -2.5178661346435547
Batch 45/64 loss: -3.051372528076172
Batch 46/64 loss: -2.845926284790039
Batch 47/64 loss: -2.8679676055908203
Batch 48/64 loss: -2.2736740112304688
Batch 49/64 loss: -2.616522789001465
Batch 50/64 loss: -2.943577766418457
Batch 51/64 loss: -2.961361885070801
Batch 52/64 loss: -3.0899477005004883
Batch 53/64 loss: -3.022629737854004
Batch 54/64 loss: -2.7255659103393555
Batch 55/64 loss: -2.874876022338867
Batch 56/64 loss: -2.8321380615234375
Batch 57/64 loss: -2.906643867492676
Batch 58/64 loss: -3.0219039916992188
Batch 59/64 loss: -2.6686391830444336
Batch 60/64 loss: -2.8221607208251953
Batch 61/64 loss: -2.7007017135620117
Batch 62/64 loss: -2.97548770904541
Batch 63/64 loss: -2.8179779052734375
Batch 64/64 loss: -7.339494228363037
Epoch 338  Train loss: -2.91900806240007  Val loss: -3.1520111896737744
Epoch 339
-------------------------------
Batch 1/64 loss: -3.090853691101074
Batch 2/64 loss: -3.0775279998779297
Batch 3/64 loss: -2.9802799224853516
Batch 4/64 loss: -2.766733169555664
Batch 5/64 loss: -3.024651527404785
Batch 6/64 loss: -3.0241317749023438
Batch 7/64 loss: -2.754549980163574
Batch 8/64 loss: -2.876084327697754
Batch 9/64 loss: -2.623720169067383
Batch 10/64 loss: -2.749166488647461
Batch 11/64 loss: -3.0273284912109375
Batch 12/64 loss: -2.8058958053588867
Batch 13/64 loss: -2.869196891784668
Batch 14/64 loss: -2.8586950302124023
Batch 15/64 loss: -2.8817081451416016
Batch 16/64 loss: -2.7951269149780273
Batch 17/64 loss: -2.8304643630981445
Batch 18/64 loss: -2.9408178329467773
Batch 19/64 loss: -2.801091194152832
Batch 20/64 loss: -2.9898881912231445
Batch 21/64 loss: -3.038379669189453
Batch 22/64 loss: -2.4185009002685547
Batch 23/64 loss: -2.843669891357422
Batch 24/64 loss: -2.6892995834350586
Batch 25/64 loss: -2.880338668823242
Batch 26/64 loss: -2.976456642150879
Batch 27/64 loss: -2.7924442291259766
Batch 28/64 loss: -3.049973487854004
Batch 29/64 loss: -2.742664337158203
Batch 30/64 loss: -3.11452579498291
Batch 31/64 loss: -2.936063766479492
Batch 32/64 loss: -2.949953079223633
Batch 33/64 loss: -2.673436164855957
Batch 34/64 loss: -2.8065872192382812
Batch 35/64 loss: -3.014629364013672
Batch 36/64 loss: -2.979116439819336
Batch 37/64 loss: -2.740443229675293
Batch 38/64 loss: -2.8410329818725586
Batch 39/64 loss: -2.875995635986328
Batch 40/64 loss: -2.9405975341796875
Batch 41/64 loss: -2.8813905715942383
Batch 42/64 loss: -2.8472251892089844
Batch 43/64 loss: -2.576631546020508
Batch 44/64 loss: -3.1256322860717773
Batch 45/64 loss: -2.981304168701172
Batch 46/64 loss: -2.94287109375
Batch 47/64 loss: -2.858541488647461
Batch 48/64 loss: -2.995258331298828
Batch 49/64 loss: -2.609795570373535
Batch 50/64 loss: -3.0167932510375977
Batch 51/64 loss: -2.7824392318725586
Batch 52/64 loss: -2.871443748474121
Batch 53/64 loss: -3.090773582458496
Batch 54/64 loss: -2.9184131622314453
Batch 55/64 loss: -2.9847373962402344
Batch 56/64 loss: -2.9595584869384766
Batch 57/64 loss: -3.0667152404785156
Batch 58/64 loss: -2.928377151489258
Batch 59/64 loss: -2.719040870666504
Batch 60/64 loss: -2.5482797622680664
Batch 61/64 loss: -2.8000192642211914
Batch 62/64 loss: -2.879657745361328
Batch 63/64 loss: -2.908702850341797
Batch 64/64 loss: -7.529813289642334
Epoch 339  Train loss: -2.9335369801988787  Val loss: -3.1369140860960654
Epoch 340
-------------------------------
Batch 1/64 loss: -2.7018041610717773
Batch 2/64 loss: -2.8552255630493164
Batch 3/64 loss: -2.939542770385742
Batch 4/64 loss: -3.1501755714416504
Batch 5/64 loss: -2.389894485473633
Batch 6/64 loss: -2.897014617919922
Batch 7/64 loss: -2.9716548919677734
Batch 8/64 loss: -2.7077484130859375
Batch 9/64 loss: -2.9706687927246094
Batch 10/64 loss: -2.9988832473754883
Batch 11/64 loss: -2.6379852294921875
Batch 12/64 loss: -3.031026840209961
Batch 13/64 loss: -2.7088842391967773
Batch 14/64 loss: -2.6837053298950195
Batch 15/64 loss: -2.8196420669555664
Batch 16/64 loss: -2.9111509323120117
Batch 17/64 loss: -2.90450382232666
Batch 18/64 loss: -2.765561103820801
Batch 19/64 loss: -2.85343074798584
Batch 20/64 loss: -2.914834976196289
Batch 21/64 loss: -2.6347646713256836
Batch 22/64 loss: -2.8261337280273438
Batch 23/64 loss: -2.9224042892456055
Batch 24/64 loss: -2.9515905380249023
Batch 25/64 loss: -3.0068130493164062
Batch 26/64 loss: -3.017207145690918
Batch 27/64 loss: -2.9434642791748047
Batch 28/64 loss: -2.8319473266601562
Batch 29/64 loss: -2.75510311126709
Batch 30/64 loss: -2.8755388259887695
Batch 31/64 loss: -2.501371383666992
Batch 32/64 loss: -2.8204288482666016
Batch 33/64 loss: -2.87149715423584
Batch 34/64 loss: -2.8648977279663086
Batch 35/64 loss: -2.9339065551757812
Batch 36/64 loss: -2.795140266418457
Batch 37/64 loss: -3.0464439392089844
Batch 38/64 loss: -3.132805347442627
Batch 39/64 loss: -2.760089874267578
Batch 40/64 loss: -2.944058418273926
Batch 41/64 loss: -2.921736717224121
Batch 42/64 loss: -2.770406723022461
Batch 43/64 loss: -2.8269100189208984
Batch 44/64 loss: -3.0349531173706055
Batch 45/64 loss: -2.905445098876953
Batch 46/64 loss: -2.901315689086914
Batch 47/64 loss: -2.996668815612793
Batch 48/64 loss: -2.81223201751709
Batch 49/64 loss: -2.8331174850463867
Batch 50/64 loss: -3.1409640312194824
Batch 51/64 loss: -2.9648666381835938
Batch 52/64 loss: -3.103804588317871
Batch 53/64 loss: -2.66225528717041
Batch 54/64 loss: -2.693613052368164
Batch 55/64 loss: -2.554971694946289
Batch 56/64 loss: -2.8123836517333984
Batch 57/64 loss: -3.0559921264648438
Batch 58/64 loss: -2.897706985473633
Batch 59/64 loss: -3.1356801986694336
Batch 60/64 loss: -2.75152587890625
Batch 61/64 loss: -2.918224334716797
Batch 62/64 loss: -2.9537343978881836
Batch 63/64 loss: -2.8077144622802734
Batch 64/64 loss: -7.452352046966553
Epoch 340  Train loss: -2.922265589470957  Val loss: -3.094853679748745
Epoch 341
-------------------------------
Batch 1/64 loss: -2.9905033111572266
Batch 2/64 loss: -2.634309768676758
Batch 3/64 loss: -2.762709617614746
Batch 4/64 loss: -2.4627676010131836
Batch 5/64 loss: -3.0262231826782227
Batch 6/64 loss: -3.0224075317382812
Batch 7/64 loss: -3.0488929748535156
Batch 8/64 loss: -2.624112129211426
Batch 9/64 loss: -2.921156883239746
Batch 10/64 loss: -2.7930946350097656
Batch 11/64 loss: -3.0713491439819336
Batch 12/64 loss: -2.9191055297851562
Batch 13/64 loss: -2.937589645385742
Batch 14/64 loss: -2.9556055068969727
Batch 15/64 loss: -2.9866819381713867
Batch 16/64 loss: -2.6373348236083984
Batch 17/64 loss: -2.9837942123413086
Batch 18/64 loss: -2.9880475997924805
Batch 19/64 loss: -2.7051162719726562
Batch 20/64 loss: -2.7496538162231445
Batch 21/64 loss: -2.725773811340332
Batch 22/64 loss: -3.0841941833496094
Batch 23/64 loss: -2.4299564361572266
Batch 24/64 loss: -2.767104148864746
Batch 25/64 loss: -2.6646604537963867
Batch 26/64 loss: -2.6232528686523438
Batch 27/64 loss: -2.8011560440063477
Batch 28/64 loss: -2.9366073608398438
Batch 29/64 loss: -2.9070911407470703
Batch 30/64 loss: -2.8646392822265625
Batch 31/64 loss: -2.80987548828125
Batch 32/64 loss: -3.0003585815429688
Batch 33/64 loss: -2.875680923461914
Batch 34/64 loss: -2.5475854873657227
Batch 35/64 loss: -3.016866683959961
Batch 36/64 loss: -3.1571130752563477
Batch 37/64 loss: -2.9108810424804688
Batch 38/64 loss: -2.8395605087280273
Batch 39/64 loss: -2.8800411224365234
Batch 40/64 loss: -2.9810171127319336
Batch 41/64 loss: -2.978928565979004
Batch 42/64 loss: -2.8553314208984375
Batch 43/64 loss: -2.9072351455688477
Batch 44/64 loss: -3.0272035598754883
Batch 45/64 loss: -2.929854393005371
Batch 46/64 loss: -2.824202537536621
Batch 47/64 loss: -3.024904251098633
Batch 48/64 loss: -2.8905553817749023
Batch 49/64 loss: -2.922332763671875
Batch 50/64 loss: -3.115628242492676
Batch 51/64 loss: -2.98403263092041
Batch 52/64 loss: -2.554506301879883
Batch 53/64 loss: -2.962447166442871
Batch 54/64 loss: -2.843207359313965
Batch 55/64 loss: -2.8897953033447266
Batch 56/64 loss: -3.0786428451538086
Batch 57/64 loss: -2.924187660217285
Batch 58/64 loss: -2.98842716217041
Batch 59/64 loss: -2.969736099243164
Batch 60/64 loss: -2.935025215148926
Batch 61/64 loss: -2.8597497940063477
Batch 62/64 loss: -2.758591651916504
Batch 63/64 loss: -2.8661346435546875
Batch 64/64 loss: -7.2384843826293945
Epoch 341  Train loss: -2.9264846315570905  Val loss: -3.1943299205032822
Epoch 342
-------------------------------
Batch 1/64 loss: -2.907428741455078
Batch 2/64 loss: -2.8890609741210938
Batch 3/64 loss: -2.9445552825927734
Batch 4/64 loss: -3.1361513137817383
Batch 5/64 loss: -2.434774398803711
Batch 6/64 loss: -3.0055036544799805
Batch 7/64 loss: -2.935061454772949
Batch 8/64 loss: -2.989286422729492
Batch 9/64 loss: -3.0124502182006836
Batch 10/64 loss: -2.8987693786621094
Batch 11/64 loss: -2.902843475341797
Batch 12/64 loss: -2.896489143371582
Batch 13/64 loss: -2.802016258239746
Batch 14/64 loss: -2.8487071990966797
Batch 15/64 loss: -2.8583364486694336
Batch 16/64 loss: -2.9235658645629883
Batch 17/64 loss: -3.028172492980957
Batch 18/64 loss: -2.739543914794922
Batch 19/64 loss: -2.696624755859375
Batch 20/64 loss: -2.864217758178711
Batch 21/64 loss: -2.8244409561157227
Batch 22/64 loss: -2.829401969909668
Batch 23/64 loss: -2.827238082885742
Batch 24/64 loss: -2.9693431854248047
Batch 25/64 loss: -3.0513525009155273
Batch 26/64 loss: -2.910588264465332
Batch 27/64 loss: -2.887984275817871
Batch 28/64 loss: -3.0093650817871094
Batch 29/64 loss: -2.8994789123535156
Batch 30/64 loss: -2.853419303894043
Batch 31/64 loss: -2.9397096633911133
Batch 32/64 loss: -2.921614646911621
Batch 33/64 loss: -2.894346237182617
Batch 34/64 loss: -2.677379608154297
Batch 35/64 loss: -2.962307929992676
Batch 36/64 loss: -2.668593406677246
Batch 37/64 loss: -2.933206558227539
Batch 38/64 loss: -2.8392581939697266
Batch 39/64 loss: -3.0091781616210938
Batch 40/64 loss: -2.8101425170898438
Batch 41/64 loss: -3.0597190856933594
Batch 42/64 loss: -2.7968931198120117
Batch 43/64 loss: -2.861666679382324
Batch 44/64 loss: -2.8382997512817383
Batch 45/64 loss: -2.8937339782714844
Batch 46/64 loss: -2.8460445404052734
Batch 47/64 loss: -2.7212533950805664
Batch 48/64 loss: -2.792400360107422
Batch 49/64 loss: -2.8809728622436523
Batch 50/64 loss: -2.7032880783081055
Batch 51/64 loss: -3.015721321105957
Batch 52/64 loss: -2.9752731323242188
Batch 53/64 loss: -2.655040740966797
Batch 54/64 loss: -2.86141300201416
Batch 55/64 loss: -3.142282485961914
Batch 56/64 loss: -3.0712995529174805
Batch 57/64 loss: -2.661332130432129
Batch 58/64 loss: -2.6530399322509766
Batch 59/64 loss: -2.936769485473633
Batch 60/64 loss: -3.1436424255371094
Batch 61/64 loss: -3.1258583068847656
Batch 62/64 loss: -3.073727607727051
Batch 63/64 loss: -2.91903018951416
Batch 64/64 loss: -7.516883373260498
Epoch 342  Train loss: -2.94428664001764  Val loss: -3.1396257721681367
Epoch 343
-------------------------------
Batch 1/64 loss: -2.621623992919922
Batch 2/64 loss: -2.6669464111328125
Batch 3/64 loss: -3.0569677352905273
Batch 4/64 loss: -3.0511016845703125
Batch 5/64 loss: -2.5548629760742188
Batch 6/64 loss: -2.943112373352051
Batch 7/64 loss: -2.8686437606811523
Batch 8/64 loss: -2.906765937805176
Batch 9/64 loss: -2.757948875427246
Batch 10/64 loss: -2.8047609329223633
Batch 11/64 loss: -3.055988311767578
Batch 12/64 loss: -2.9886159896850586
Batch 13/64 loss: -3.0224924087524414
Batch 14/64 loss: -2.7472848892211914
Batch 15/64 loss: -3.053384780883789
Batch 16/64 loss: -2.6580419540405273
Batch 17/64 loss: -2.9086809158325195
Batch 18/64 loss: -3.034388542175293
Batch 19/64 loss: -2.954824447631836
Batch 20/64 loss: -3.0118846893310547
Batch 21/64 loss: -2.9650192260742188
Batch 22/64 loss: -3.111265182495117
Batch 23/64 loss: -2.481210708618164
Batch 24/64 loss: -2.638784408569336
Batch 25/64 loss: -2.5318832397460938
Batch 26/64 loss: -2.677560806274414
Batch 27/64 loss: -2.9488401412963867
Batch 28/64 loss: -2.786893844604492
Batch 29/64 loss: -2.8889617919921875
Batch 30/64 loss: -2.8109703063964844
Batch 31/64 loss: -2.996112823486328
Batch 32/64 loss: -2.681929588317871
Batch 33/64 loss: -2.8559417724609375
Batch 34/64 loss: -2.922252655029297
Batch 35/64 loss: -3.0783462524414062
Batch 36/64 loss: -2.608448028564453
Batch 37/64 loss: -3.114130973815918
Batch 38/64 loss: -2.973954200744629
Batch 39/64 loss: -2.897937774658203
Batch 40/64 loss: -3.0217485427856445
Batch 41/64 loss: -2.7375431060791016
Batch 42/64 loss: -2.9284839630126953
Batch 43/64 loss: -3.0593795776367188
Batch 44/64 loss: -3.0467491149902344
Batch 45/64 loss: -2.712679862976074
Batch 46/64 loss: -2.5928964614868164
Batch 47/64 loss: -2.9023303985595703
Batch 48/64 loss: -2.475165367126465
Batch 49/64 loss: -2.9425411224365234
Batch 50/64 loss: -2.9963064193725586
Batch 51/64 loss: -2.78464412689209
Batch 52/64 loss: -2.999617576599121
Batch 53/64 loss: -2.7847137451171875
Batch 54/64 loss: -2.8112268447875977
Batch 55/64 loss: -2.6873741149902344
Batch 56/64 loss: -2.7372570037841797
Batch 57/64 loss: -2.8997459411621094
Batch 58/64 loss: -2.8675718307495117
Batch 59/64 loss: -2.770449638366699
Batch 60/64 loss: -2.9621810913085938
Batch 61/64 loss: -2.9414548873901367
Batch 62/64 loss: -2.714019775390625
Batch 63/64 loss: -2.7570228576660156
Batch 64/64 loss: -7.591903209686279
Epoch 343  Train loss: -2.909267390008066  Val loss: -3.1798424212793304
Epoch 344
-------------------------------
Batch 1/64 loss: -2.798748016357422
Batch 2/64 loss: -3.1039552688598633
Batch 3/64 loss: -2.839761734008789
Batch 4/64 loss: -3.032301902770996
Batch 5/64 loss: -2.8760557174682617
Batch 6/64 loss: -3.0137205123901367
Batch 7/64 loss: -2.923677444458008
Batch 8/64 loss: -2.786421775817871
Batch 9/64 loss: -2.9826583862304688
Batch 10/64 loss: -2.9359331130981445
Batch 11/64 loss: -2.769674301147461
Batch 12/64 loss: -2.774169921875
Batch 13/64 loss: -3.007430076599121
Batch 14/64 loss: -2.7739181518554688
Batch 15/64 loss: -3.001042366027832
Batch 16/64 loss: -2.6694726943969727
Batch 17/64 loss: -2.9399404525756836
Batch 18/64 loss: -2.7809953689575195
Batch 19/64 loss: -2.9297962188720703
Batch 20/64 loss: -2.889054298400879
Batch 21/64 loss: -2.9349145889282227
Batch 22/64 loss: -3.0916852951049805
Batch 23/64 loss: -1.9766826629638672
Batch 24/64 loss: -2.9093523025512695
Batch 25/64 loss: -2.818118095397949
Batch 26/64 loss: -2.873697280883789
Batch 27/64 loss: -2.9536428451538086
Batch 28/64 loss: -2.7501964569091797
Batch 29/64 loss: -2.9532899856567383
Batch 30/64 loss: -3.008808135986328
Batch 31/64 loss: -2.6454086303710938
Batch 32/64 loss: -2.9594554901123047
Batch 33/64 loss: -2.921243667602539
Batch 34/64 loss: -2.63126277923584
Batch 35/64 loss: -2.987489700317383
Batch 36/64 loss: -3.026123046875
Batch 37/64 loss: -2.4005651473999023
Batch 38/64 loss: -2.6095027923583984
Batch 39/64 loss: -3.0836286544799805
Batch 40/64 loss: -2.919004440307617
Batch 41/64 loss: -2.830794334411621
Batch 42/64 loss: -2.8876867294311523
Batch 43/64 loss: -2.8482542037963867
Batch 44/64 loss: -2.5403385162353516
Batch 45/64 loss: -2.9678993225097656
Batch 46/64 loss: -2.728067398071289
Batch 47/64 loss: -2.9060192108154297
Batch 48/64 loss: -3.00588321685791
Batch 49/64 loss: -2.985135078430176
Batch 50/64 loss: -2.203658103942871
Batch 51/64 loss: -2.9118595123291016
Batch 52/64 loss: -2.9841489791870117
Batch 53/64 loss: -2.9689769744873047
Batch 54/64 loss: -2.865673065185547
Batch 55/64 loss: -2.9042539596557617
Batch 56/64 loss: -3.105997085571289
Batch 57/64 loss: -2.5220861434936523
Batch 58/64 loss: -3.0840911865234375
Batch 59/64 loss: -2.8648509979248047
Batch 60/64 loss: -3.0053491592407227
Batch 61/64 loss: -2.8526573181152344
Batch 62/64 loss: -2.9127798080444336
Batch 63/64 loss: -2.926616668701172
Batch 64/64 loss: -7.565569877624512
Epoch 344  Train loss: -2.9140400643442192  Val loss: -3.1770197681544983
Epoch 345
-------------------------------
Batch 1/64 loss: -2.7401838302612305
Batch 2/64 loss: -3.0808610916137695
Batch 3/64 loss: -2.965813636779785
Batch 4/64 loss: -2.9602508544921875
Batch 5/64 loss: -2.8497161865234375
Batch 6/64 loss: -2.7528915405273438
Batch 7/64 loss: -3.1653690338134766
Batch 8/64 loss: -2.8835134506225586
Batch 9/64 loss: -2.9356307983398438
Batch 10/64 loss: -3.081705093383789
Batch 11/64 loss: -2.999418258666992
Batch 12/64 loss: -3.002470016479492
Batch 13/64 loss: -3.0490550994873047
Batch 14/64 loss: -3.1748809814453125
Batch 15/64 loss: -3.069912910461426
Batch 16/64 loss: -2.8741397857666016
Batch 17/64 loss: -2.7840442657470703
Batch 18/64 loss: -3.075223922729492
Batch 19/64 loss: -2.8943605422973633
Batch 20/64 loss: -2.915513038635254
Batch 21/64 loss: -2.835193634033203
Batch 22/64 loss: -2.9496870040893555
Batch 23/64 loss: -2.840272903442383
Batch 24/64 loss: -2.7208375930786133
Batch 25/64 loss: -2.8812522888183594
Batch 26/64 loss: -2.93399715423584
Batch 27/64 loss: -2.59918212890625
Batch 28/64 loss: -2.828089714050293
Batch 29/64 loss: -2.792440414428711
Batch 30/64 loss: -3.016477584838867
Batch 31/64 loss: -2.926717758178711
Batch 32/64 loss: -2.7523021697998047
Batch 33/64 loss: -2.855343818664551
Batch 34/64 loss: -2.777411460876465
Batch 35/64 loss: -2.9447622299194336
Batch 36/64 loss: -2.9751405715942383
Batch 37/64 loss: -2.931452751159668
Batch 38/64 loss: -3.020528793334961
Batch 39/64 loss: -2.9504575729370117
Batch 40/64 loss: -2.868403434753418
Batch 41/64 loss: -2.6119632720947266
Batch 42/64 loss: -3.01723575592041
Batch 43/64 loss: -3.056807518005371
Batch 44/64 loss: -2.891594886779785
Batch 45/64 loss: -2.621541976928711
Batch 46/64 loss: -3.0036468505859375
Batch 47/64 loss: -2.428919792175293
Batch 48/64 loss: -2.570209503173828
Batch 49/64 loss: -2.950685501098633
Batch 50/64 loss: -3.0573253631591797
Batch 51/64 loss: -2.7987613677978516
Batch 52/64 loss: -2.9712886810302734
Batch 53/64 loss: -2.8340368270874023
Batch 54/64 loss: -2.9126596450805664
Batch 55/64 loss: -2.8909339904785156
Batch 56/64 loss: -2.6237735748291016
Batch 57/64 loss: -3.117264747619629
Batch 58/64 loss: -2.900057792663574
Batch 59/64 loss: -2.4195947647094727
Batch 60/64 loss: -2.7660818099975586
Batch 61/64 loss: -3.112283706665039
Batch 62/64 loss: -2.8386335372924805
Batch 63/64 loss: -2.9535884857177734
Batch 64/64 loss: -7.344696998596191
Epoch 345  Train loss: -2.941369685004739  Val loss: -3.158164309472153
Epoch 346
-------------------------------
Batch 1/64 loss: -2.7734899520874023
Batch 2/64 loss: -3.18646240234375
Batch 3/64 loss: -2.9846620559692383
Batch 4/64 loss: -2.918264389038086
Batch 5/64 loss: -2.8423051834106445
Batch 6/64 loss: -3.1037635803222656
Batch 7/64 loss: -2.707669258117676
Batch 8/64 loss: -2.470639228820801
Batch 9/64 loss: -2.6091127395629883
Batch 10/64 loss: -2.8698196411132812
Batch 11/64 loss: -2.7143173217773438
Batch 12/64 loss: -3.0929927825927734
Batch 13/64 loss: -2.9206018447875977
Batch 14/64 loss: -2.8883056640625
Batch 15/64 loss: -2.992748260498047
Batch 16/64 loss: -2.9114198684692383
Batch 17/64 loss: -2.930182456970215
Batch 18/64 loss: -2.5860776901245117
Batch 19/64 loss: -2.9962263107299805
Batch 20/64 loss: -2.976262092590332
Batch 21/64 loss: -2.9350175857543945
Batch 22/64 loss: -2.797909736633301
Batch 23/64 loss: -2.9667892456054688
Batch 24/64 loss: -2.8437843322753906
Batch 25/64 loss: -2.6280107498168945
Batch 26/64 loss: -3.0321102142333984
Batch 27/64 loss: -2.645040512084961
Batch 28/64 loss: -2.877103805541992
Batch 29/64 loss: -2.659818649291992
Batch 30/64 loss: -2.971904754638672
Batch 31/64 loss: -3.0366296768188477
Batch 32/64 loss: -2.770817756652832
Batch 33/64 loss: -2.8559131622314453
Batch 34/64 loss: -2.9850521087646484
Batch 35/64 loss: -2.746872901916504
Batch 36/64 loss: -2.9179840087890625
Batch 37/64 loss: -2.8588199615478516
Batch 38/64 loss: -2.78594970703125
Batch 39/64 loss: -2.86361026763916
Batch 40/64 loss: -2.856189727783203
Batch 41/64 loss: -3.146796226501465
Batch 42/64 loss: -3.075162887573242
Batch 43/64 loss: -3.040705680847168
Batch 44/64 loss: -2.734149932861328
Batch 45/64 loss: -3.0045576095581055
Batch 46/64 loss: -2.7018232345581055
Batch 47/64 loss: -2.8397865295410156
Batch 48/64 loss: -2.840444564819336
Batch 49/64 loss: -2.7088069915771484
Batch 50/64 loss: -2.8345441818237305
Batch 51/64 loss: -2.9200239181518555
Batch 52/64 loss: -2.8995304107666016
Batch 53/64 loss: -3.022134780883789
Batch 54/64 loss: -2.887009620666504
Batch 55/64 loss: -2.8790454864501953
Batch 56/64 loss: -3.119927406311035
Batch 57/64 loss: -3.033590316772461
Batch 58/64 loss: -2.6417665481567383
Batch 59/64 loss: -2.910013198852539
Batch 60/64 loss: -2.7593564987182617
Batch 61/64 loss: -2.8661603927612305
Batch 62/64 loss: -2.7912063598632812
Batch 63/64 loss: -3.0075035095214844
Batch 64/64 loss: -7.320720195770264
Epoch 346  Train loss: -2.9280821650635964  Val loss: -3.093167963716173
Epoch 347
-------------------------------
Batch 1/64 loss: -2.844329833984375
Batch 2/64 loss: -2.740971565246582
Batch 3/64 loss: -2.755483627319336
Batch 4/64 loss: -2.930455207824707
Batch 5/64 loss: -3.021944999694824
Batch 6/64 loss: -2.969353675842285
Batch 7/64 loss: -3.0281906127929688
Batch 8/64 loss: -2.710831642150879
Batch 9/64 loss: -3.080540657043457
Batch 10/64 loss: -2.9564027786254883
Batch 11/64 loss: -2.803635597229004
Batch 12/64 loss: -2.82236385345459
Batch 13/64 loss: -2.907245635986328
Batch 14/64 loss: -2.9387826919555664
Batch 15/64 loss: -2.892399787902832
Batch 16/64 loss: -2.9291276931762695
Batch 17/64 loss: -3.0790672302246094
Batch 18/64 loss: -2.5849084854125977
Batch 19/64 loss: -2.8641738891601562
Batch 20/64 loss: -3.039639472961426
Batch 21/64 loss: -2.8467302322387695
Batch 22/64 loss: -2.9966211318969727
Batch 23/64 loss: -2.980743408203125
Batch 24/64 loss: -2.653848648071289
Batch 25/64 loss: -2.900784492492676
Batch 26/64 loss: -2.782893180847168
Batch 27/64 loss: -2.8775978088378906
Batch 28/64 loss: -2.9191055297851562
Batch 29/64 loss: -3.0819568634033203
Batch 30/64 loss: -2.9833765029907227
Batch 31/64 loss: -2.7413387298583984
Batch 32/64 loss: -2.9534378051757812
Batch 33/64 loss: -3.039823532104492
Batch 34/64 loss: -2.8411331176757812
Batch 35/64 loss: -3.1883106231689453
Batch 36/64 loss: -3.1254167556762695
Batch 37/64 loss: -2.82928466796875
Batch 38/64 loss: -2.5214662551879883
Batch 39/64 loss: -2.7570133209228516
Batch 40/64 loss: -2.983351707458496
Batch 41/64 loss: -2.621201515197754
Batch 42/64 loss: -2.8097362518310547
Batch 43/64 loss: -2.961155891418457
Batch 44/64 loss: -2.868605613708496
Batch 45/64 loss: -2.958280563354492
Batch 46/64 loss: -2.822951316833496
Batch 47/64 loss: -2.777811050415039
Batch 48/64 loss: -2.781674385070801
Batch 49/64 loss: -2.964679718017578
Batch 50/64 loss: -2.9488391876220703
Batch 51/64 loss: -2.9494142532348633
Batch 52/64 loss: -2.784536361694336
Batch 53/64 loss: -2.7030982971191406
Batch 54/64 loss: -3.153921127319336
Batch 55/64 loss: -2.9639081954956055
Batch 56/64 loss: -2.8085451126098633
Batch 57/64 loss: -3.073605537414551
Batch 58/64 loss: -2.821261405944824
Batch 59/64 loss: -2.9807729721069336
Batch 60/64 loss: -3.0138025283813477
Batch 61/64 loss: -2.9228553771972656
Batch 62/64 loss: -2.794933319091797
Batch 63/64 loss: -2.9799423217773438
Batch 64/64 loss: -7.096796989440918
Epoch 347  Train loss: -2.9441915811276904  Val loss: -3.1579372891036095
Epoch 348
-------------------------------
Batch 1/64 loss: -3.015491485595703
Batch 2/64 loss: -2.803386688232422
Batch 3/64 loss: -2.862537384033203
Batch 4/64 loss: -3.037827491760254
Batch 5/64 loss: -2.70068359375
Batch 6/64 loss: -2.8518600463867188
Batch 7/64 loss: -2.794062614440918
Batch 8/64 loss: -2.629962921142578
Batch 9/64 loss: -2.9813146591186523
Batch 10/64 loss: -2.8560914993286133
Batch 11/64 loss: -3.0661706924438477
Batch 12/64 loss: -2.6994142532348633
Batch 13/64 loss: -2.9424915313720703
Batch 14/64 loss: -2.947331428527832
Batch 15/64 loss: -2.963589668273926
Batch 16/64 loss: -2.8599853515625
Batch 17/64 loss: -3.1181535720825195
Batch 18/64 loss: -2.950042724609375
Batch 19/64 loss: -2.92557430267334
Batch 20/64 loss: -2.8512353897094727
Batch 21/64 loss: -3.0800065994262695
Batch 22/64 loss: -2.987173080444336
Batch 23/64 loss: -2.9527206420898438
Batch 24/64 loss: -3.0344924926757812
Batch 25/64 loss: -2.810055732727051
Batch 26/64 loss: -2.87789249420166
Batch 27/64 loss: -2.72910213470459
Batch 28/64 loss: -3.137636184692383
Batch 29/64 loss: -2.7289047241210938
Batch 30/64 loss: -2.854569435119629
Batch 31/64 loss: -2.7856855392456055
Batch 32/64 loss: -2.811518669128418
Batch 33/64 loss: -2.703643798828125
Batch 34/64 loss: -3.097395896911621
Batch 35/64 loss: -2.6329994201660156
Batch 36/64 loss: -3.0645618438720703
Batch 37/64 loss: -3.0891666412353516
Batch 38/64 loss: -2.7584476470947266
Batch 39/64 loss: -2.9668540954589844
Batch 40/64 loss: -3.0584630966186523
Batch 41/64 loss: -3.0276098251342773
Batch 42/64 loss: -3.116124153137207
Batch 43/64 loss: -3.067045211791992
Batch 44/64 loss: -3.0665903091430664
Batch 45/64 loss: -2.9053268432617188
Batch 46/64 loss: -2.9557085037231445
Batch 47/64 loss: -2.9980125427246094
Batch 48/64 loss: -2.8634185791015625
Batch 49/64 loss: -2.7960996627807617
Batch 50/64 loss: -3.0791025161743164
Batch 51/64 loss: -2.7804689407348633
Batch 52/64 loss: -2.8157739639282227
Batch 53/64 loss: -2.9228954315185547
Batch 54/64 loss: -3.0312061309814453
Batch 55/64 loss: -2.6280813217163086
Batch 56/64 loss: -2.980833053588867
Batch 57/64 loss: -2.8319950103759766
Batch 58/64 loss: -2.9498233795166016
Batch 59/64 loss: -2.7018260955810547
Batch 60/64 loss: -2.688201904296875
Batch 61/64 loss: -2.7806148529052734
Batch 62/64 loss: -2.690643310546875
Batch 63/64 loss: -2.6865577697753906
Batch 64/64 loss: -7.3467254638671875
Epoch 348  Train loss: -2.947333347096163  Val loss: -3.1734877124275127
Epoch 349
-------------------------------
Batch 1/64 loss: -2.8030624389648438
Batch 2/64 loss: -2.809560775756836
Batch 3/64 loss: -2.5409040451049805
Batch 4/64 loss: -3.0668087005615234
Batch 5/64 loss: -3.037482261657715
Batch 6/64 loss: -2.760774612426758
Batch 7/64 loss: -2.8716135025024414
Batch 8/64 loss: -2.9669017791748047
Batch 9/64 loss: -2.8147153854370117
Batch 10/64 loss: -2.912548065185547
Batch 11/64 loss: -2.9960861206054688
Batch 12/64 loss: -2.603949546813965
Batch 13/64 loss: -2.7216062545776367
Batch 14/64 loss: -2.990078926086426
Batch 15/64 loss: -2.9856462478637695
Batch 16/64 loss: -2.53664493560791
Batch 17/64 loss: -2.9344701766967773
Batch 18/64 loss: -2.9968433380126953
Batch 19/64 loss: -3.083322525024414
Batch 20/64 loss: -2.7972307205200195
Batch 21/64 loss: -2.793458938598633
Batch 22/64 loss: -2.9181718826293945
Batch 23/64 loss: -2.8762998580932617
Batch 24/64 loss: -2.8711814880371094
Batch 25/64 loss: -2.757962226867676
Batch 26/64 loss: -2.875202178955078
Batch 27/64 loss: -3.047234535217285
Batch 28/64 loss: -2.7935075759887695
Batch 29/64 loss: -2.9058847427368164
Batch 30/64 loss: -3.0123987197875977
Batch 31/64 loss: -2.8536291122436523
Batch 32/64 loss: -2.8810548782348633
Batch 33/64 loss: -3.05655574798584
Batch 34/64 loss: -2.792759895324707
Batch 35/64 loss: -3.0766468048095703
Batch 36/64 loss: -2.571819305419922
Batch 37/64 loss: -2.677722930908203
Batch 38/64 loss: -3.077813148498535
Batch 39/64 loss: -2.8651342391967773
Batch 40/64 loss: -2.974856376647949
Batch 41/64 loss: -2.7287817001342773
Batch 42/64 loss: -3.025376319885254
Batch 43/64 loss: -2.8406143188476562
Batch 44/64 loss: -3.0491113662719727
Batch 45/64 loss: -2.952315330505371
Batch 46/64 loss: -2.988692283630371
Batch 47/64 loss: -2.826422691345215
Batch 48/64 loss: -2.6749391555786133
Batch 49/64 loss: -2.828782081604004
Batch 50/64 loss: -3.055551528930664
Batch 51/64 loss: -2.738557815551758
Batch 52/64 loss: -2.9286317825317383
Batch 53/64 loss: -2.706082344055176
Batch 54/64 loss: -2.8301544189453125
Batch 55/64 loss: -2.7597169876098633
Batch 56/64 loss: -2.9990663528442383
Batch 57/64 loss: -3.065474510192871
Batch 58/64 loss: -3.1171207427978516
Batch 59/64 loss: -2.9027347564697266
Batch 60/64 loss: -3.019026756286621
Batch 61/64 loss: -3.1476869583129883
Batch 62/64 loss: -3.0024795532226562
Batch 63/64 loss: -2.807394027709961
Batch 64/64 loss: -7.2589030265808105
Epoch 349  Train loss: -2.9387989960464775  Val loss: -3.1792227623798595
Epoch 350
-------------------------------
Batch 1/64 loss: -2.7685375213623047
Batch 2/64 loss: -2.8495235443115234
Batch 3/64 loss: -3.0110387802124023
Batch 4/64 loss: -2.8514366149902344
Batch 5/64 loss: -2.986311912536621
Batch 6/64 loss: -2.875478744506836
Batch 7/64 loss: -2.6653261184692383
Batch 8/64 loss: -2.8710784912109375
Batch 9/64 loss: -2.5983800888061523
Batch 10/64 loss: -2.772459030151367
Batch 11/64 loss: -2.8629989624023438
Batch 12/64 loss: -2.451228141784668
Batch 13/64 loss: -2.388277053833008
Batch 14/64 loss: -2.8852577209472656
Batch 15/64 loss: -2.9150495529174805
Batch 16/64 loss: -2.8865785598754883
Batch 17/64 loss: -2.904752731323242
Batch 18/64 loss: -2.9669666290283203
Batch 19/64 loss: -3.036229133605957
Batch 20/64 loss: -2.8695125579833984
Batch 21/64 loss: -2.7004690170288086
Batch 22/64 loss: -3.148308753967285
Batch 23/64 loss: -2.967386245727539
Batch 24/64 loss: -2.831974983215332
Batch 25/64 loss: -2.9641265869140625
Batch 26/64 loss: -2.899404525756836
Batch 27/64 loss: -2.9306631088256836
Batch 28/64 loss: -3.1486921310424805
Batch 29/64 loss: -2.807077407836914
Batch 30/64 loss: -3.062437057495117
Batch 31/64 loss: -2.9984607696533203
Batch 32/64 loss: -2.8035221099853516
Batch 33/64 loss: -2.854358673095703
Batch 34/64 loss: -2.875967025756836
Batch 35/64 loss: -2.8901939392089844
Batch 36/64 loss: -2.7930803298950195
Batch 37/64 loss: -2.957948684692383
Batch 38/64 loss: -3.06461238861084
Batch 39/64 loss: -3.007298469543457
Batch 40/64 loss: -2.9857730865478516
Batch 41/64 loss: -3.049689292907715
Batch 42/64 loss: -2.9273080825805664
Batch 43/64 loss: -2.6194753646850586
Batch 44/64 loss: -3.0508766174316406
Batch 45/64 loss: -2.8983354568481445
Batch 46/64 loss: -2.7205162048339844
Batch 47/64 loss: -2.7432632446289062
Batch 48/64 loss: -3.051846504211426
Batch 49/64 loss: -2.9765377044677734
Batch 50/64 loss: -2.948568344116211
Batch 51/64 loss: -2.998398780822754
Batch 52/64 loss: -2.7661142349243164
Batch 53/64 loss: -2.829456329345703
Batch 54/64 loss: -2.817011833190918
Batch 55/64 loss: -2.733043670654297
Batch 56/64 loss: -2.9963340759277344
Batch 57/64 loss: -2.8265018463134766
Batch 58/64 loss: -2.7222490310668945
Batch 59/64 loss: -3.0299243927001953
Batch 60/64 loss: -3.121440887451172
Batch 61/64 loss: -2.6695051193237305
Batch 62/64 loss: -2.7934703826904297
Batch 63/64 loss: -2.9238061904907227
Batch 64/64 loss: -7.569624900817871
Epoch 350  Train loss: -2.9333187365064433  Val loss: -3.117890374357348
Epoch 351
-------------------------------
Batch 1/64 loss: -3.0000791549682617
Batch 2/64 loss: -2.997610092163086
Batch 3/64 loss: -3.0049352645874023
Batch 4/64 loss: -2.8686599731445312
Batch 5/64 loss: -2.7305049896240234
Batch 6/64 loss: -3.0724592208862305
Batch 7/64 loss: -2.7341461181640625
Batch 8/64 loss: -2.8574390411376953
Batch 9/64 loss: -3.0730810165405273
Batch 10/64 loss: -2.844862937927246
Batch 11/64 loss: -2.803234100341797
Batch 12/64 loss: -2.828927993774414
Batch 13/64 loss: -2.8091964721679688
Batch 14/64 loss: -2.8544998168945312
Batch 15/64 loss: -3.0313806533813477
Batch 16/64 loss: -2.9686222076416016
Batch 17/64 loss: -2.9558305740356445
Batch 18/64 loss: -2.9020652770996094
Batch 19/64 loss: -3.0553150177001953
Batch 20/64 loss: -2.850374221801758
Batch 21/64 loss: -2.8752994537353516
Batch 22/64 loss: -2.8245582580566406
Batch 23/64 loss: -2.7904834747314453
Batch 24/64 loss: -2.74761962890625
Batch 25/64 loss: -2.84860897064209
Batch 26/64 loss: -2.827855110168457
Batch 27/64 loss: -2.836832046508789
Batch 28/64 loss: -2.6519622802734375
Batch 29/64 loss: -2.6567230224609375
Batch 30/64 loss: -2.974259376525879
Batch 31/64 loss: -2.943082809448242
Batch 32/64 loss: -2.8497495651245117
Batch 33/64 loss: -2.830441474914551
Batch 34/64 loss: -2.9280529022216797
Batch 35/64 loss: -2.463486671447754
Batch 36/64 loss: -2.7867555618286133
Batch 37/64 loss: -2.913088798522949
Batch 38/64 loss: -2.9885921478271484
Batch 39/64 loss: -2.884049415588379
Batch 40/64 loss: -2.8739242553710938
Batch 41/64 loss: -3.066329002380371
Batch 42/64 loss: -2.7915029525756836
Batch 43/64 loss: -2.865633964538574
Batch 44/64 loss: -3.0910496711730957
Batch 45/64 loss: -2.6563968658447266
Batch 46/64 loss: -2.7965879440307617
Batch 47/64 loss: -2.8351898193359375
Batch 48/64 loss: -2.830512046813965
Batch 49/64 loss: -2.7661523818969727
Batch 50/64 loss: -2.645681381225586
Batch 51/64 loss: -2.891725540161133
Batch 52/64 loss: -2.9023618698120117
Batch 53/64 loss: -2.944705009460449
Batch 54/64 loss: -2.843294143676758
Batch 55/64 loss: -3.011773109436035
Batch 56/64 loss: -2.7060537338256836
Batch 57/64 loss: -2.32370662689209
Batch 58/64 loss: -2.9315271377563477
Batch 59/64 loss: -3.032900810241699
Batch 60/64 loss: -2.928058624267578
Batch 61/64 loss: -2.882124900817871
Batch 62/64 loss: -2.7001953125
Batch 63/64 loss: -2.6608028411865234
Batch 64/64 loss: -7.373261451721191
Epoch 351  Train loss: -2.907809586618461  Val loss: -3.171038231079521
Epoch 352
-------------------------------
Batch 1/64 loss: -2.668252944946289
Batch 2/64 loss: -2.811603546142578
Batch 3/64 loss: -3.051119327545166
Batch 4/64 loss: -2.902297019958496
Batch 5/64 loss: -2.8429126739501953
Batch 6/64 loss: -3.10305118560791
Batch 7/64 loss: -2.8504533767700195
Batch 8/64 loss: -3.011838436126709
Batch 9/64 loss: -2.886918067932129
Batch 10/64 loss: -2.893651008605957
Batch 11/64 loss: -2.766988754272461
Batch 12/64 loss: -3.1574740409851074
Batch 13/64 loss: -2.8164501190185547
Batch 14/64 loss: -2.9197463989257812
Batch 15/64 loss: -2.9625940322875977
Batch 16/64 loss: -3.0207815170288086
Batch 17/64 loss: -2.972259521484375
Batch 18/64 loss: -2.5056819915771484
Batch 19/64 loss: -3.0103673934936523
Batch 20/64 loss: -3.0024843215942383
Batch 21/64 loss: -3.0657854080200195
Batch 22/64 loss: -3.076234817504883
Batch 23/64 loss: -2.8610267639160156
Batch 24/64 loss: -2.8880767822265625
Batch 25/64 loss: -2.852297782897949
Batch 26/64 loss: -2.849432945251465
Batch 27/64 loss: -3.0228843688964844
Batch 28/64 loss: -2.8667917251586914
Batch 29/64 loss: -2.9663610458374023
Batch 30/64 loss: -2.816404342651367
Batch 31/64 loss: -2.8581790924072266
Batch 32/64 loss: -2.8426828384399414
Batch 33/64 loss: -2.9022607803344727
Batch 34/64 loss: -2.79929256439209
Batch 35/64 loss: -2.8779258728027344
Batch 36/64 loss: -2.933316230773926
Batch 37/64 loss: -2.860506057739258
Batch 38/64 loss: -2.848456382751465
Batch 39/64 loss: -2.8216724395751953
Batch 40/64 loss: -3.015359878540039
Batch 41/64 loss: -3.109987258911133
Batch 42/64 loss: -3.0301923751831055
Batch 43/64 loss: -2.866853713989258
Batch 44/64 loss: -2.760986328125
Batch 45/64 loss: -2.9887237548828125
Batch 46/64 loss: -2.9253787994384766
Batch 47/64 loss: -2.8773040771484375
Batch 48/64 loss: -2.814542770385742
Batch 49/64 loss: -2.408463478088379
Batch 50/64 loss: -2.988436698913574
Batch 51/64 loss: -2.728764533996582
Batch 52/64 loss: -3.035712242126465
Batch 53/64 loss: -3.0264663696289062
Batch 54/64 loss: -3.0346298217773438
Batch 55/64 loss: -2.7849035263061523
Batch 56/64 loss: -2.955441474914551
Batch 57/64 loss: -2.794732093811035
Batch 58/64 loss: -2.743466377258301
Batch 59/64 loss: -2.694002151489258
Batch 60/64 loss: -2.814983367919922
Batch 61/64 loss: -3.116209030151367
Batch 62/64 loss: -2.672403335571289
Batch 63/64 loss: -2.9464492797851562
Batch 64/64 loss: -7.5609002113342285
Epoch 352  Train loss: -2.9485738324184045  Val loss: -3.2402599767311333
Saving best model, epoch: 352
Epoch 353
-------------------------------
Batch 1/64 loss: -3.0906009674072266
Batch 2/64 loss: -3.026076316833496
Batch 3/64 loss: -2.9053125381469727
Batch 4/64 loss: -2.8418846130371094
Batch 5/64 loss: -2.804263114929199
Batch 6/64 loss: -2.972018241882324
Batch 7/64 loss: -3.076663017272949
Batch 8/64 loss: -3.007533073425293
Batch 9/64 loss: -2.9994659423828125
Batch 10/64 loss: -2.82940673828125
Batch 11/64 loss: -2.845211982727051
Batch 12/64 loss: -3.055548667907715
Batch 13/64 loss: -2.857452392578125
Batch 14/64 loss: -2.9439964294433594
Batch 15/64 loss: -2.6054582595825195
Batch 16/64 loss: -2.81838321685791
Batch 17/64 loss: -3.1069822311401367
Batch 18/64 loss: -2.850235939025879
Batch 19/64 loss: -2.6453895568847656
Batch 20/64 loss: -2.73330020904541
Batch 21/64 loss: -2.723997116088867
Batch 22/64 loss: -2.801802635192871
Batch 23/64 loss: -2.950418472290039
Batch 24/64 loss: -2.820797920227051
Batch 25/64 loss: -2.9664459228515625
Batch 26/64 loss: -2.88662052154541
Batch 27/64 loss: -3.018278121948242
Batch 28/64 loss: -3.1028289794921875
Batch 29/64 loss: -2.8903932571411133
Batch 30/64 loss: -3.0631837844848633
Batch 31/64 loss: -2.8029251098632812
Batch 32/64 loss: -3.0861902236938477
Batch 33/64 loss: -2.9460678100585938
Batch 34/64 loss: -2.9134016036987305
Batch 35/64 loss: -3.1154861450195312
Batch 36/64 loss: -2.709242820739746
Batch 37/64 loss: -2.978276252746582
Batch 38/64 loss: -2.647406578063965
Batch 39/64 loss: -2.8209590911865234
Batch 40/64 loss: -2.952582359313965
Batch 41/64 loss: -3.1386871337890625
Batch 42/64 loss: -2.9081573486328125
Batch 43/64 loss: -2.8423337936401367
Batch 44/64 loss: -2.9143590927124023
Batch 45/64 loss: -2.799126625061035
Batch 46/64 loss: -2.9819679260253906
Batch 47/64 loss: -2.9328746795654297
Batch 48/64 loss: -2.9199838638305664
Batch 49/64 loss: -2.8174667358398438
Batch 50/64 loss: -2.985898971557617
Batch 51/64 loss: -3.0676679611206055
Batch 52/64 loss: -2.9933290481567383
Batch 53/64 loss: -3.192166328430176
Batch 54/64 loss: -2.7441606521606445
Batch 55/64 loss: -2.8410215377807617
Batch 56/64 loss: -2.9725589752197266
Batch 57/64 loss: -2.7366819381713867
Batch 58/64 loss: -3.029208183288574
Batch 59/64 loss: -2.979381561279297
Batch 60/64 loss: -3.0590391159057617
Batch 61/64 loss: -3.121753692626953
Batch 62/64 loss: -3.0079774856567383
Batch 63/64 loss: -2.7319393157958984
Batch 64/64 loss: -7.646905899047852
Epoch 353  Train loss: -2.97514367945054  Val loss: -3.151797134032364
Epoch 354
-------------------------------
Batch 1/64 loss: -2.680516242980957
Batch 2/64 loss: -3.080691337585449
Batch 3/64 loss: -2.916104316711426
Batch 4/64 loss: -3.081716537475586
Batch 5/64 loss: -2.9620094299316406
Batch 6/64 loss: -2.611574172973633
Batch 7/64 loss: -2.537837028503418
Batch 8/64 loss: -2.8068695068359375
Batch 9/64 loss: -2.899505615234375
Batch 10/64 loss: -2.8834362030029297
Batch 11/64 loss: -2.9747495651245117
Batch 12/64 loss: -2.9790468215942383
Batch 13/64 loss: -2.891094207763672
Batch 14/64 loss: -3.005978584289551
Batch 15/64 loss: -2.945744514465332
Batch 16/64 loss: -2.9324588775634766
Batch 17/64 loss: -3.1250991821289062
Batch 18/64 loss: -3.0190353393554688
Batch 19/64 loss: -2.646153450012207
Batch 20/64 loss: -2.8957509994506836
Batch 21/64 loss: -3.105475425720215
Batch 22/64 loss: -2.8983516693115234
Batch 23/64 loss: -2.58261775970459
Batch 24/64 loss: -2.852579116821289
Batch 25/64 loss: -2.819242477416992
Batch 26/64 loss: -3.01711368560791
Batch 27/64 loss: -2.951899528503418
Batch 28/64 loss: -2.848696708679199
Batch 29/64 loss: -2.9580841064453125
Batch 30/64 loss: -3.1684131622314453
Batch 31/64 loss: -2.9605607986450195
Batch 32/64 loss: -3.112370491027832
Batch 33/64 loss: -2.668476104736328
Batch 34/64 loss: -2.9507579803466797
Batch 35/64 loss: -2.86978816986084
Batch 36/64 loss: -2.862227439880371
Batch 37/64 loss: -2.949007987976074
Batch 38/64 loss: -2.9989261627197266
Batch 39/64 loss: -2.9296083450317383
Batch 40/64 loss: -2.969632148742676
Batch 41/64 loss: -2.9090681076049805
Batch 42/64 loss: -2.755934715270996
Batch 43/64 loss: -2.8136062622070312
Batch 44/64 loss: -3.0093040466308594
Batch 45/64 loss: -2.668241500854492
Batch 46/64 loss: -2.993986129760742
Batch 47/64 loss: -2.963229179382324
Batch 48/64 loss: -3.100113868713379
Batch 49/64 loss: -2.812594413757324
Batch 50/64 loss: -2.9427490234375
Batch 51/64 loss: -2.871183395385742
Batch 52/64 loss: -2.8794374465942383
Batch 53/64 loss: -2.870621681213379
Batch 54/64 loss: -2.8641557693481445
Batch 55/64 loss: -2.6892452239990234
Batch 56/64 loss: -2.954257011413574
Batch 57/64 loss: -2.874654769897461
Batch 58/64 loss: -2.860049247741699
Batch 59/64 loss: -2.689549446105957
Batch 60/64 loss: -2.9082565307617188
Batch 61/64 loss: -2.860401153564453
Batch 62/64 loss: -2.740206718444824
Batch 63/64 loss: -2.851321220397949
Batch 64/64 loss: -7.3873291015625
Epoch 354  Train loss: -2.9454410178988586  Val loss: -3.2026269001649417
Epoch 355
-------------------------------
Batch 1/64 loss: -2.4948863983154297
Batch 2/64 loss: -3.015871047973633
Batch 3/64 loss: -2.947014808654785
Batch 4/64 loss: -3.0695438385009766
Batch 5/64 loss: -3.029463768005371
Batch 6/64 loss: -3.001898765563965
Batch 7/64 loss: -3.038118362426758
Batch 8/64 loss: -3.035902976989746
Batch 9/64 loss: -3.052461624145508
Batch 10/64 loss: -2.9741411209106445
Batch 11/64 loss: -2.8959808349609375
Batch 12/64 loss: -3.064523696899414
Batch 13/64 loss: -3.051506996154785
Batch 14/64 loss: -2.9690818786621094
Batch 15/64 loss: -3.008397102355957
Batch 16/64 loss: -2.867511749267578
Batch 17/64 loss: -2.892704963684082
Batch 18/64 loss: -3.0973119735717773
Batch 19/64 loss: -2.836310386657715
Batch 20/64 loss: -2.7580814361572266
Batch 21/64 loss: -2.9037227630615234
Batch 22/64 loss: -2.9776830673217773
Batch 23/64 loss: -2.993405342102051
Batch 24/64 loss: -2.7068309783935547
Batch 25/64 loss: -2.719790458679199
Batch 26/64 loss: -2.8781185150146484
Batch 27/64 loss: -2.720733642578125
Batch 28/64 loss: -3.157796859741211
Batch 29/64 loss: -2.823807716369629
Batch 30/64 loss: -2.9496994018554688
Batch 31/64 loss: -2.8985185623168945
Batch 32/64 loss: -2.971428871154785
Batch 33/64 loss: -3.074892997741699
Batch 34/64 loss: -3.0246105194091797
Batch 35/64 loss: -2.611886978149414
Batch 36/64 loss: -3.0795679092407227
Batch 37/64 loss: -2.9344186782836914
Batch 38/64 loss: -2.943913459777832
Batch 39/64 loss: -2.9816741943359375
Batch 40/64 loss: -2.7620277404785156
Batch 41/64 loss: -3.0304412841796875
Batch 42/64 loss: -2.6430797576904297
Batch 43/64 loss: -2.91068172454834
Batch 44/64 loss: -2.9601802825927734
Batch 45/64 loss: -2.8769168853759766
Batch 46/64 loss: -3.023442268371582
Batch 47/64 loss: -2.9577674865722656
Batch 48/64 loss: -2.6945199966430664
Batch 49/64 loss: -2.8862123489379883
Batch 50/64 loss: -2.7555160522460938
Batch 51/64 loss: -2.7798233032226562
Batch 52/64 loss: -3.0374507904052734
Batch 53/64 loss: -2.635822296142578
Batch 54/64 loss: -2.8457040786743164
Batch 55/64 loss: -2.7073707580566406
Batch 56/64 loss: -2.82358455657959
Batch 57/64 loss: -2.920516014099121
Batch 58/64 loss: -2.9824275970458984
Batch 59/64 loss: -2.9090662002563477
Batch 60/64 loss: -2.669879913330078
Batch 61/64 loss: -3.052532196044922
Batch 62/64 loss: -2.6436004638671875
Batch 63/64 loss: -2.9244813919067383
Batch 64/64 loss: -6.937678337097168
Epoch 355  Train loss: -2.9504238240859086  Val loss: -3.1377684078675365
Epoch 356
-------------------------------
Batch 1/64 loss: -2.976388931274414
Batch 2/64 loss: -2.69796085357666
Batch 3/64 loss: -2.838613510131836
Batch 4/64 loss: -2.932976722717285
Batch 5/64 loss: -2.7831287384033203
Batch 6/64 loss: -2.5963306427001953
Batch 7/64 loss: -2.838956832885742
Batch 8/64 loss: -3.1293296813964844
Batch 9/64 loss: -3.000030517578125
Batch 10/64 loss: -2.767317771911621
Batch 11/64 loss: -3.025233268737793
Batch 12/64 loss: -2.829416275024414
Batch 13/64 loss: -2.9762001037597656
Batch 14/64 loss: -2.8972339630126953
Batch 15/64 loss: -2.7239112854003906
Batch 16/64 loss: -2.667356491088867
Batch 17/64 loss: -3.0278453826904297
Batch 18/64 loss: -3.0299015045166016
Batch 19/64 loss: -2.836117744445801
Batch 20/64 loss: -2.930281639099121
Batch 21/64 loss: -2.808155059814453
Batch 22/64 loss: -3.0531044006347656
Batch 23/64 loss: -3.0458545684814453
Batch 24/64 loss: -2.9778690338134766
Batch 25/64 loss: -3.050063133239746
Batch 26/64 loss: -2.9875946044921875
Batch 27/64 loss: -3.097599983215332
Batch 28/64 loss: -2.964296340942383
Batch 29/64 loss: -3.0504188537597656
Batch 30/64 loss: -3.0455780029296875
Batch 31/64 loss: -2.784200668334961
Batch 32/64 loss: -2.780080795288086
Batch 33/64 loss: -2.991734504699707
Batch 34/64 loss: -2.8088502883911133
Batch 35/64 loss: -2.6281137466430664
Batch 36/64 loss: -2.959160804748535
Batch 37/64 loss: -3.118161201477051
Batch 38/64 loss: -2.9604530334472656
Batch 39/64 loss: -2.734269142150879
Batch 40/64 loss: -3.1172847747802734
Batch 41/64 loss: -2.989150047302246
Batch 42/64 loss: -3.0527753829956055
Batch 43/64 loss: -3.106562614440918
Batch 44/64 loss: -2.9186477661132812
Batch 45/64 loss: -2.981721878051758
Batch 46/64 loss: -3.1201601028442383
Batch 47/64 loss: -3.0495452880859375
Batch 48/64 loss: -2.8701305389404297
Batch 49/64 loss: -3.0416431427001953
Batch 50/64 loss: -3.0590572357177734
Batch 51/64 loss: -3.017867088317871
Batch 52/64 loss: -2.7491321563720703
Batch 53/64 loss: -2.991084098815918
Batch 54/64 loss: -3.0837879180908203
Batch 55/64 loss: -2.857929229736328
Batch 56/64 loss: -2.8883657455444336
Batch 57/64 loss: -2.7890138626098633
Batch 58/64 loss: -2.9885406494140625
Batch 59/64 loss: -2.5597267150878906
Batch 60/64 loss: -3.0104942321777344
Batch 61/64 loss: -2.8090171813964844
Batch 62/64 loss: -2.9523019790649414
Batch 63/64 loss: -3.1438755989074707
Batch 64/64 loss: -7.6435089111328125
Epoch 356  Train loss: -2.9840084225523706  Val loss: -3.2350963317241863
Epoch 357
-------------------------------
Batch 1/64 loss: -3.04791259765625
Batch 2/64 loss: -2.783534049987793
Batch 3/64 loss: -2.942476272583008
Batch 4/64 loss: -2.7421483993530273
Batch 5/64 loss: -2.9732017517089844
Batch 6/64 loss: -3.040469169616699
Batch 7/64 loss: -2.7273406982421875
Batch 8/64 loss: -2.748143196105957
Batch 9/64 loss: -2.9856624603271484
Batch 10/64 loss: -2.75827693939209
Batch 11/64 loss: -3.0753870010375977
Batch 12/64 loss: -3.1134262084960938
Batch 13/64 loss: -2.901177406311035
Batch 14/64 loss: -2.9316158294677734
Batch 15/64 loss: -3.083402633666992
Batch 16/64 loss: -2.7978343963623047
Batch 17/64 loss: -3.06622314453125
Batch 18/64 loss: -2.8495492935180664
Batch 19/64 loss: -2.9371414184570312
Batch 20/64 loss: -2.9425010681152344
Batch 21/64 loss: -3.0602293014526367
Batch 22/64 loss: -2.981313705444336
Batch 23/64 loss: -3.011953353881836
Batch 24/64 loss: -2.99298095703125
Batch 25/64 loss: -3.0161304473876953
Batch 26/64 loss: -3.075253486633301
Batch 27/64 loss: -2.9831228256225586
Batch 28/64 loss: -3.073007583618164
Batch 29/64 loss: -2.933134078979492
Batch 30/64 loss: -2.759359359741211
Batch 31/64 loss: -2.9045801162719727
Batch 32/64 loss: -2.654343605041504
Batch 33/64 loss: -2.9521656036376953
Batch 34/64 loss: -2.838223457336426
Batch 35/64 loss: -2.7513771057128906
Batch 36/64 loss: -2.5387744903564453
Batch 37/64 loss: -3.00408935546875
Batch 38/64 loss: -2.9597949981689453
Batch 39/64 loss: -2.65054988861084
Batch 40/64 loss: -2.9642515182495117
Batch 41/64 loss: -2.914762496948242
Batch 42/64 loss: -2.9724254608154297
Batch 43/64 loss: -2.8721446990966797
Batch 44/64 loss: -3.0502090454101562
Batch 45/64 loss: -2.9271411895751953
Batch 46/64 loss: -2.6036062240600586
Batch 47/64 loss: -2.912957191467285
Batch 48/64 loss: -3.1449646949768066
Batch 49/64 loss: -3.1117124557495117
Batch 50/64 loss: -2.950930595397949
Batch 51/64 loss: -2.9997005462646484
Batch 52/64 loss: -2.9505929946899414
Batch 53/64 loss: -3.1663646697998047
Batch 54/64 loss: -2.933330535888672
Batch 55/64 loss: -2.955972671508789
Batch 56/64 loss: -3.055482864379883
Batch 57/64 loss: -2.8386764526367188
Batch 58/64 loss: -3.001683235168457
Batch 59/64 loss: -2.826413154602051
Batch 60/64 loss: -3.129558563232422
Batch 61/64 loss: -2.7841482162475586
Batch 62/64 loss: -3.002561569213867
Batch 63/64 loss: -2.901902198791504
Batch 64/64 loss: -7.2212629318237305
Epoch 357  Train loss: -2.980003891739191  Val loss: -3.2384454261806
Epoch 358
-------------------------------
Batch 1/64 loss: -3.0153989791870117
Batch 2/64 loss: -3.0123348236083984
Batch 3/64 loss: -2.9623775482177734
Batch 4/64 loss: -2.8265981674194336
Batch 5/64 loss: -3.0482845306396484
Batch 6/64 loss: -2.8301868438720703
Batch 7/64 loss: -2.8635520935058594
Batch 8/64 loss: -3.0511932373046875
Batch 9/64 loss: -2.9417552947998047
Batch 10/64 loss: -3.0183496475219727
Batch 11/64 loss: -2.892885208129883
Batch 12/64 loss: -2.7558107376098633
Batch 13/64 loss: -2.6670303344726562
Batch 14/64 loss: -2.868589401245117
Batch 15/64 loss: -3.0219268798828125
Batch 16/64 loss: -2.959230422973633
Batch 17/64 loss: -2.932598114013672
Batch 18/64 loss: -3.000812530517578
Batch 19/64 loss: -2.783860206604004
Batch 20/64 loss: -3.0104551315307617
Batch 21/64 loss: -3.1706199645996094
Batch 22/64 loss: -3.144256591796875
Batch 23/64 loss: -3.082050323486328
Batch 24/64 loss: -2.8482418060302734
Batch 25/64 loss: -3.0445566177368164
Batch 26/64 loss: -2.6508970260620117
Batch 27/64 loss: -2.656855583190918
Batch 28/64 loss: -3.014338493347168
Batch 29/64 loss: -2.8334293365478516
Batch 30/64 loss: -2.977116584777832
Batch 31/64 loss: -2.9756383895874023
Batch 32/64 loss: -3.078897476196289
Batch 33/64 loss: -2.820352554321289
Batch 34/64 loss: -2.830923080444336
Batch 35/64 loss: -3.011244773864746
Batch 36/64 loss: -3.005105972290039
Batch 37/64 loss: -2.75252628326416
Batch 38/64 loss: -3.117915153503418
Batch 39/64 loss: -2.9989185333251953
Batch 40/64 loss: -2.757373809814453
Batch 41/64 loss: -2.9591970443725586
Batch 42/64 loss: -3.1083431243896484
Batch 43/64 loss: -2.8780994415283203
Batch 44/64 loss: -2.9737396240234375
Batch 45/64 loss: -2.984743118286133
Batch 46/64 loss: -3.041440010070801
Batch 47/64 loss: -3.110321521759033
Batch 48/64 loss: -2.7836790084838867
Batch 49/64 loss: -3.0112857818603516
Batch 50/64 loss: -3.0444555282592773
Batch 51/64 loss: -3.1024293899536133
Batch 52/64 loss: -2.681796073913574
Batch 53/64 loss: -2.9771862030029297
Batch 54/64 loss: -2.951815605163574
Batch 55/64 loss: -2.927445411682129
Batch 56/64 loss: -2.9800262451171875
Batch 57/64 loss: -2.738652229309082
Batch 58/64 loss: -2.953227996826172
Batch 59/64 loss: -2.8663158416748047
Batch 60/64 loss: -3.0548648834228516
Batch 61/64 loss: -2.9389877319335938
Batch 62/64 loss: -2.7490711212158203
Batch 63/64 loss: -2.9671144485473633
Batch 64/64 loss: -7.4418792724609375
Epoch 358  Train loss: -2.9898060443354586  Val loss: -3.230019376040324
Epoch 359
-------------------------------
Batch 1/64 loss: -2.880237579345703
Batch 2/64 loss: -2.94162654876709
Batch 3/64 loss: -2.901036262512207
Batch 4/64 loss: -2.7479305267333984
Batch 5/64 loss: -2.948573112487793
Batch 6/64 loss: -3.007669448852539
Batch 7/64 loss: -3.0602855682373047
Batch 8/64 loss: -2.9931259155273438
Batch 9/64 loss: -3.0697059631347656
Batch 10/64 loss: -2.60440731048584
Batch 11/64 loss: -2.8008499145507812
Batch 12/64 loss: -2.879220962524414
Batch 13/64 loss: -2.9834041595458984
Batch 14/64 loss: -3.0105714797973633
Batch 15/64 loss: -2.831724166870117
Batch 16/64 loss: -2.733475685119629
Batch 17/64 loss: -2.9614381790161133
Batch 18/64 loss: -2.965383529663086
Batch 19/64 loss: -2.998284339904785
Batch 20/64 loss: -2.8202438354492188
Batch 21/64 loss: -3.1211185455322266
Batch 22/64 loss: -2.8909387588500977
Batch 23/64 loss: -2.8211727142333984
Batch 24/64 loss: -2.6586151123046875
Batch 25/64 loss: -3.052001953125
Batch 26/64 loss: -2.96486759185791
Batch 27/64 loss: -2.9380111694335938
Batch 28/64 loss: -3.0816774368286133
Batch 29/64 loss: -2.7789268493652344
Batch 30/64 loss: -2.965256690979004
Batch 31/64 loss: -3.027348518371582
Batch 32/64 loss: -2.912356376647949
Batch 33/64 loss: -2.8947229385375977
Batch 34/64 loss: -2.7292022705078125
Batch 35/64 loss: -2.531243324279785
Batch 36/64 loss: -2.9033584594726562
Batch 37/64 loss: -2.9558000564575195
Batch 38/64 loss: -2.8238754272460938
Batch 39/64 loss: -3.0399837493896484
Batch 40/64 loss: -3.030999183654785
Batch 41/64 loss: -2.393263816833496
Batch 42/64 loss: -3.0139827728271484
Batch 43/64 loss: -2.930375099182129
Batch 44/64 loss: -2.686555862426758
Batch 45/64 loss: -3.001832962036133
Batch 46/64 loss: -3.0816421508789062
Batch 47/64 loss: -3.0749025344848633
Batch 48/64 loss: -2.9188308715820312
Batch 49/64 loss: -2.9157114028930664
Batch 50/64 loss: -2.737460136413574
Batch 51/64 loss: -2.677618980407715
Batch 52/64 loss: -2.9915285110473633
Batch 53/64 loss: -2.8806896209716797
Batch 54/64 loss: -2.723374366760254
Batch 55/64 loss: -2.763983726501465
Batch 56/64 loss: -3.0536413192749023
Batch 57/64 loss: -3.033413887023926
Batch 58/64 loss: -3.0364513397216797
Batch 59/64 loss: -3.0232715606689453
Batch 60/64 loss: -3.0019350051879883
Batch 61/64 loss: -2.9129018783569336
Batch 62/64 loss: -2.39125919342041
Batch 63/64 loss: -3.065807342529297
Batch 64/64 loss: -7.406262397766113
Epoch 359  Train loss: -2.9509929843977387  Val loss: -3.2775448146964266
Saving best model, epoch: 359
Epoch 360
-------------------------------
Batch 1/64 loss: -3.045823097229004
Batch 2/64 loss: -2.9830408096313477
Batch 3/64 loss: -3.085940361022949
Batch 4/64 loss: -3.0570878982543945
Batch 5/64 loss: -2.796053886413574
Batch 6/64 loss: -2.989809989929199
Batch 7/64 loss: -2.9490909576416016
Batch 8/64 loss: -2.966449737548828
Batch 9/64 loss: -2.9629993438720703
Batch 10/64 loss: -2.886624336242676
Batch 11/64 loss: -2.725205421447754
Batch 12/64 loss: -3.0689430236816406
Batch 13/64 loss: -3.1401100158691406
Batch 14/64 loss: -1.728963851928711
Batch 15/64 loss: -2.927610397338867
Batch 16/64 loss: -2.827120780944824
Batch 17/64 loss: -2.8510446548461914
Batch 18/64 loss: -3.0141096115112305
Batch 19/64 loss: -2.8660335540771484
Batch 20/64 loss: -2.8855361938476562
Batch 21/64 loss: -3.0538320541381836
Batch 22/64 loss: -2.685429573059082
Batch 23/64 loss: -2.6936607360839844
Batch 24/64 loss: -2.8648929595947266
Batch 25/64 loss: -2.82421875
Batch 26/64 loss: -2.69020938873291
Batch 27/64 loss: -3.084597587585449
Batch 28/64 loss: -2.9394569396972656
Batch 29/64 loss: -2.561595916748047
Batch 30/64 loss: -2.753183364868164
Batch 31/64 loss: -2.761773109436035
Batch 32/64 loss: -3.0379533767700195
Batch 33/64 loss: -3.0225114822387695
Batch 34/64 loss: -3.054915428161621
Batch 35/64 loss: -3.0974388122558594
Batch 36/64 loss: -3.1044015884399414
Batch 37/64 loss: -2.742709159851074
Batch 38/64 loss: -3.053739547729492
Batch 39/64 loss: -2.9735326766967773
Batch 40/64 loss: -2.653763771057129
Batch 41/64 loss: -2.9450082778930664
Batch 42/64 loss: -2.954092025756836
Batch 43/64 loss: -3.0267887115478516
Batch 44/64 loss: -2.9528160095214844
Batch 45/64 loss: -3.058795928955078
Batch 46/64 loss: -2.68380069732666
Batch 47/64 loss: -2.750579833984375
Batch 48/64 loss: -2.9004249572753906
Batch 49/64 loss: -2.7568397521972656
Batch 50/64 loss: -2.8322629928588867
Batch 51/64 loss: -2.8892698287963867
Batch 52/64 loss: -2.880643844604492
Batch 53/64 loss: -3.0315961837768555
Batch 54/64 loss: -2.947895050048828
Batch 55/64 loss: -2.7349185943603516
Batch 56/64 loss: -3.052639961242676
Batch 57/64 loss: -2.9174556732177734
Batch 58/64 loss: -2.93483829498291
Batch 59/64 loss: -2.8338184356689453
Batch 60/64 loss: -3.0308799743652344
Batch 61/64 loss: -3.022223472595215
Batch 62/64 loss: -2.8949174880981445
Batch 63/64 loss: -1.9222021102905273
Batch 64/64 loss: -7.561424732208252
Epoch 360  Train loss: -2.9339167183520747  Val loss: -3.2117702969161095
Epoch 361
-------------------------------
Batch 1/64 loss: -3.026768684387207
Batch 2/64 loss: -3.002560615539551
Batch 3/64 loss: -2.5213184356689453
Batch 4/64 loss: -2.886707305908203
Batch 5/64 loss: -2.78713321685791
Batch 6/64 loss: -2.8020572662353516
Batch 7/64 loss: -2.8715829849243164
Batch 8/64 loss: -2.8643436431884766
Batch 9/64 loss: -2.9299869537353516
Batch 10/64 loss: -2.8039379119873047
Batch 11/64 loss: -2.8689308166503906
Batch 12/64 loss: -2.533278465270996
Batch 13/64 loss: -2.9653873443603516
Batch 14/64 loss: -2.8406381607055664
Batch 15/64 loss: -2.881546974182129
Batch 16/64 loss: -2.9644031524658203
Batch 17/64 loss: -2.8194923400878906
Batch 18/64 loss: -3.031073570251465
Batch 19/64 loss: -3.074106216430664
Batch 20/64 loss: -2.386286735534668
Batch 21/64 loss: -2.8805055618286133
Batch 22/64 loss: -2.452364921569824
Batch 23/64 loss: -3.099252700805664
Batch 24/64 loss: -3.0126218795776367
Batch 25/64 loss: -3.0535755157470703
Batch 26/64 loss: -2.8654918670654297
Batch 27/64 loss: -2.8858985900878906
Batch 28/64 loss: -2.7976694107055664
Batch 29/64 loss: -2.8641958236694336
Batch 30/64 loss: -3.0283098220825195
Batch 31/64 loss: -2.85894775390625
Batch 32/64 loss: -3.134490966796875
Batch 33/64 loss: -2.8200950622558594
Batch 34/64 loss: -2.82028865814209
Batch 35/64 loss: -2.8150081634521484
Batch 36/64 loss: -2.6175384521484375
Batch 37/64 loss: -3.064859390258789
Batch 38/64 loss: -2.9338865280151367
Batch 39/64 loss: -2.993307113647461
Batch 40/64 loss: -3.0771827697753906
Batch 41/64 loss: -2.83829402923584
Batch 42/64 loss: -2.7832632064819336
Batch 43/64 loss: -2.9187440872192383
Batch 44/64 loss: -3.044292449951172
Batch 45/64 loss: -2.7173357009887695
Batch 46/64 loss: -2.827411651611328
Batch 47/64 loss: -3.053365707397461
Batch 48/64 loss: -2.9802169799804688
Batch 49/64 loss: -3.2127275466918945
Batch 50/64 loss: -2.9670562744140625
Batch 51/64 loss: -3.0985937118530273
Batch 52/64 loss: -2.837418556213379
Batch 53/64 loss: -3.062540054321289
Batch 54/64 loss: -3.0153865814208984
Batch 55/64 loss: -2.801541328430176
Batch 56/64 loss: -2.731307029724121
Batch 57/64 loss: -2.878720283508301
Batch 58/64 loss: -2.690548896789551
Batch 59/64 loss: -3.0681047439575195
Batch 60/64 loss: -2.8429059982299805
Batch 61/64 loss: -2.771182060241699
Batch 62/64 loss: -2.8672752380371094
Batch 63/64 loss: -2.6955385208129883
Batch 64/64 loss: -7.302970886230469
Epoch 361  Train loss: -2.935184792911305  Val loss: -3.1829984605926827
Epoch 362
-------------------------------
Batch 1/64 loss: -3.0216989517211914
Batch 2/64 loss: -2.9343385696411133
Batch 3/64 loss: -2.4759254455566406
Batch 4/64 loss: -2.914958953857422
Batch 5/64 loss: -2.9451637268066406
Batch 6/64 loss: -2.8178157806396484
Batch 7/64 loss: -3.093808174133301
Batch 8/64 loss: -3.0563716888427734
Batch 9/64 loss: -2.963459014892578
Batch 10/64 loss: -2.809141159057617
Batch 11/64 loss: -2.901412010192871
Batch 12/64 loss: -2.6655263900756836
Batch 13/64 loss: -3.0182485580444336
Batch 14/64 loss: -2.9001054763793945
Batch 15/64 loss: -3.012340545654297
Batch 16/64 loss: -2.978837013244629
Batch 17/64 loss: -2.8725051879882812
Batch 18/64 loss: -2.9565372467041016
Batch 19/64 loss: -2.971616744995117
Batch 20/64 loss: -3.1017045974731445
Batch 21/64 loss: -2.754643440246582
Batch 22/64 loss: -2.7737112045288086
Batch 23/64 loss: -2.894362449645996
Batch 24/64 loss: -2.8279237747192383
Batch 25/64 loss: -3.0289220809936523
Batch 26/64 loss: -2.603910446166992
Batch 27/64 loss: -2.829472541809082
Batch 28/64 loss: -2.9182968139648438
Batch 29/64 loss: -2.9582176208496094
Batch 30/64 loss: -2.957871437072754
Batch 31/64 loss: -3.0671863555908203
Batch 32/64 loss: -2.8113632202148438
Batch 33/64 loss: -3.1812973022460938
Batch 34/64 loss: -2.8779916763305664
Batch 35/64 loss: -2.9373388290405273
Batch 36/64 loss: -2.286686897277832
Batch 37/64 loss: -2.888545036315918
Batch 38/64 loss: -2.949981689453125
Batch 39/64 loss: -3.0029897689819336
Batch 40/64 loss: -2.9099559783935547
Batch 41/64 loss: -2.696317672729492
Batch 42/64 loss: -3.195436477661133
Batch 43/64 loss: -2.6178903579711914
Batch 44/64 loss: -2.5210447311401367
Batch 45/64 loss: -2.8147506713867188
Batch 46/64 loss: -2.78741455078125
Batch 47/64 loss: -2.4420175552368164
Batch 48/64 loss: -2.7726850509643555
Batch 49/64 loss: -3.0435543060302734
Batch 50/64 loss: -2.771879196166992
Batch 51/64 loss: -2.678020477294922
Batch 52/64 loss: -2.8035154342651367
Batch 53/64 loss: -3.0549936294555664
Batch 54/64 loss: -2.8077564239501953
Batch 55/64 loss: -2.8724365234375
Batch 56/64 loss: -2.715423583984375
Batch 57/64 loss: -2.779947280883789
Batch 58/64 loss: -2.6149120330810547
Batch 59/64 loss: -2.7979650497436523
Batch 60/64 loss: -2.920121192932129
Batch 61/64 loss: -3.0234880447387695
Batch 62/64 loss: -2.898085594177246
Batch 63/64 loss: -2.69232177734375
Batch 64/64 loss: -7.315201759338379
Epoch 362  Train loss: -2.912636278189865  Val loss: -3.106658384972012
Epoch 363
-------------------------------
Batch 1/64 loss: -2.8819475173950195
Batch 2/64 loss: -2.998394012451172
Batch 3/64 loss: -2.8850183486938477
Batch 4/64 loss: -2.840073585510254
Batch 5/64 loss: -2.7547073364257812
Batch 6/64 loss: -3.0482282638549805
Batch 7/64 loss: -3.073897361755371
Batch 8/64 loss: -3.1020402908325195
Batch 9/64 loss: -2.762984275817871
Batch 10/64 loss: -2.898226737976074
Batch 11/64 loss: -2.7719688415527344
Batch 12/64 loss: -2.922344207763672
Batch 13/64 loss: -2.8500261306762695
Batch 14/64 loss: -2.9229488372802734
Batch 15/64 loss: -2.7945470809936523
Batch 16/64 loss: -2.7846460342407227
Batch 17/64 loss: -3.0152158737182617
Batch 18/64 loss: -2.7875118255615234
Batch 19/64 loss: -3.018771171569824
Batch 20/64 loss: -2.9393234252929688
Batch 21/64 loss: -3.108384132385254
Batch 22/64 loss: -2.7343692779541016
Batch 23/64 loss: -2.335293769836426
Batch 24/64 loss: -1.8946399688720703
Batch 25/64 loss: -2.899325370788574
Batch 26/64 loss: -2.8289289474487305
Batch 27/64 loss: -2.762457847595215
Batch 28/64 loss: -2.977914810180664
Batch 29/64 loss: -2.669833183288574
Batch 30/64 loss: -2.645998001098633
Batch 31/64 loss: -2.6713037490844727
Batch 32/64 loss: -2.962614059448242
Batch 33/64 loss: -2.7656822204589844
Batch 34/64 loss: -2.733346939086914
Batch 35/64 loss: -2.8795108795166016
Batch 36/64 loss: -3.0896387100219727
Batch 37/64 loss: -2.9213390350341797
Batch 38/64 loss: -2.942892074584961
Batch 39/64 loss: -2.702058792114258
Batch 40/64 loss: -2.864236831665039
Batch 41/64 loss: -2.9112558364868164
Batch 42/64 loss: -3.021463394165039
Batch 43/64 loss: -2.895228385925293
Batch 44/64 loss: -2.4096803665161133
Batch 45/64 loss: -2.998530387878418
Batch 46/64 loss: -2.9314212799072266
Batch 47/64 loss: -3.0712709426879883
Batch 48/64 loss: -3.0123376846313477
Batch 49/64 loss: -2.95782470703125
Batch 50/64 loss: -2.4998645782470703
Batch 51/64 loss: -3.010560989379883
Batch 52/64 loss: -2.829756736755371
Batch 53/64 loss: -3.035843849182129
Batch 54/64 loss: -2.769838333129883
Batch 55/64 loss: -2.8466262817382812
Batch 56/64 loss: -2.978860855102539
Batch 57/64 loss: -3.1635236740112305
Batch 58/64 loss: -2.476407051086426
Batch 59/64 loss: -2.9907455444335938
Batch 60/64 loss: -2.622727394104004
Batch 61/64 loss: -3.0578718185424805
Batch 62/64 loss: -2.8701114654541016
Batch 63/64 loss: -2.8804149627685547
Batch 64/64 loss: -7.676370620727539
Epoch 363  Train loss: -2.9088946548162724  Val loss: -2.8226564020635334
Epoch 364
-------------------------------
Batch 1/64 loss: -2.727290153503418
Batch 2/64 loss: -1.8130464553833008
Batch 3/64 loss: -2.7312393188476562
Batch 4/64 loss: -2.966029167175293
Batch 5/64 loss: -2.661107063293457
Batch 6/64 loss: -2.9753952026367188
Batch 7/64 loss: -2.582259178161621
Batch 8/64 loss: -2.5874528884887695
Batch 9/64 loss: -2.961711883544922
Batch 10/64 loss: -2.7852964401245117
Batch 11/64 loss: -2.791823387145996
Batch 12/64 loss: -2.712763786315918
Batch 13/64 loss: -2.396773338317871
Batch 14/64 loss: -2.8189849853515625
Batch 15/64 loss: -2.9409408569335938
Batch 16/64 loss: -2.608086585998535
Batch 17/64 loss: -3.1399450302124023
Batch 18/64 loss: -1.5863771438598633
Batch 19/64 loss: -2.845463752746582
Batch 20/64 loss: -2.377285957336426
Batch 21/64 loss: -2.7219161987304688
Batch 22/64 loss: -3.0132980346679688
Batch 23/64 loss: -2.70064640045166
Batch 24/64 loss: -2.7040843963623047
Batch 25/64 loss: -2.8127660751342773
Batch 26/64 loss: -2.7446842193603516
Batch 27/64 loss: -2.962029457092285
Batch 28/64 loss: -3.1479053497314453
Batch 29/64 loss: -2.5670299530029297
Batch 30/64 loss: -2.7684144973754883
Batch 31/64 loss: -2.7653656005859375
Batch 32/64 loss: -2.7618417739868164
Batch 33/64 loss: -2.9803895950317383
Batch 34/64 loss: -2.9603500366210938
Batch 35/64 loss: -2.5201539993286133
Batch 36/64 loss: -2.9588871002197266
Batch 37/64 loss: -2.9406185150146484
Batch 38/64 loss: -2.9691238403320312
Batch 39/64 loss: -3.0672388076782227
Batch 40/64 loss: -2.8848085403442383
Batch 41/64 loss: -2.7934417724609375
Batch 42/64 loss: -2.7390785217285156
Batch 43/64 loss: -3.0090932846069336
Batch 44/64 loss: -3.150895118713379
Batch 45/64 loss: -2.858308792114258
Batch 46/64 loss: -2.867177963256836
Batch 47/64 loss: -2.766324043273926
Batch 48/64 loss: -2.936685562133789
Batch 49/64 loss: -2.387775421142578
Batch 50/64 loss: -2.8640308380126953
Batch 51/64 loss: -3.103240966796875
Batch 52/64 loss: -2.8043079376220703
Batch 53/64 loss: -2.5599212646484375
Batch 54/64 loss: -2.869955062866211
Batch 55/64 loss: -2.432209014892578
Batch 56/64 loss: -2.6963024139404297
Batch 57/64 loss: -3.0144100189208984
Batch 58/64 loss: -2.6826324462890625
Batch 59/64 loss: -3.0960559844970703
Batch 60/64 loss: -2.9722824096679688
Batch 61/64 loss: -2.7748756408691406
Batch 62/64 loss: -3.0418663024902344
Batch 63/64 loss: -2.2274656295776367
Batch 64/64 loss: -7.173161029815674
Epoch 364  Train loss: -2.8233573670480765  Val loss: -2.8278857621130666
Epoch 365
-------------------------------
Batch 1/64 loss: -3.081279754638672
Batch 2/64 loss: -2.428107261657715
Batch 3/64 loss: -2.885787010192871
Batch 4/64 loss: -2.328733444213867
Batch 5/64 loss: -2.679464340209961
Batch 6/64 loss: -2.411318778991699
Batch 7/64 loss: -2.815823554992676
Batch 8/64 loss: -2.3697118759155273
Batch 9/64 loss: -2.8298721313476562
Batch 10/64 loss: -2.5007333755493164
Batch 11/64 loss: -2.7296524047851562
Batch 12/64 loss: -2.644362449645996
Batch 13/64 loss: -2.720858573913574
Batch 14/64 loss: -2.977044105529785
Batch 15/64 loss: -2.82656192779541
Batch 16/64 loss: -2.461313247680664
Batch 17/64 loss: -2.6021299362182617
Batch 18/64 loss: -2.612645149230957
Batch 19/64 loss: -2.733369827270508
Batch 20/64 loss: -2.794774055480957
Batch 21/64 loss: -2.5495119094848633
Batch 22/64 loss: -2.8926429748535156
Batch 23/64 loss: -2.992997169494629
Batch 24/64 loss: -2.985177993774414
Batch 25/64 loss: -2.6417837142944336
Batch 26/64 loss: -2.7822046279907227
Batch 27/64 loss: -2.808107376098633
Batch 28/64 loss: -2.7527904510498047
Batch 29/64 loss: -3.0067358016967773
Batch 30/64 loss: -2.540562629699707
Batch 31/64 loss: -2.7479591369628906
Batch 32/64 loss: -2.286815643310547
Batch 33/64 loss: -2.8053054809570312
Batch 34/64 loss: -2.8664541244506836
Batch 35/64 loss: -2.809126853942871
Batch 36/64 loss: -3.0375518798828125
Batch 37/64 loss: -3.023937225341797
Batch 38/64 loss: -2.7944583892822266
Batch 39/64 loss: -2.7390518188476562
Batch 40/64 loss: -2.6222400665283203
Batch 41/64 loss: -2.8788042068481445
Batch 42/64 loss: -2.9406604766845703
Batch 43/64 loss: -2.9026432037353516
Batch 44/64 loss: -2.730443000793457
Batch 45/64 loss: -2.75888729095459
Batch 46/64 loss: -2.754627227783203
Batch 47/64 loss: -2.6972217559814453
Batch 48/64 loss: -2.541698455810547
Batch 49/64 loss: -2.9848146438598633
Batch 50/64 loss: -2.754483222961426
Batch 51/64 loss: -2.90132999420166
Batch 52/64 loss: -2.5151052474975586
Batch 53/64 loss: -2.4487991333007812
Batch 54/64 loss: -2.892454147338867
Batch 55/64 loss: -2.813913345336914
Batch 56/64 loss: -3.046161651611328
Batch 57/64 loss: -2.959073066711426
Batch 58/64 loss: -2.9983434677124023
Batch 59/64 loss: -2.9582014083862305
Batch 60/64 loss: -2.5759849548339844
Batch 61/64 loss: -2.6593856811523438
Batch 62/64 loss: -2.779172897338867
Batch 63/64 loss: -2.6475744247436523
Batch 64/64 loss: -7.355518341064453
Epoch 365  Train loss: -2.804319688385608  Val loss: -2.991004812758403
Epoch 366
-------------------------------
Batch 1/64 loss: -2.8791866302490234
Batch 2/64 loss: -2.976072311401367
Batch 3/64 loss: -2.871980667114258
Batch 4/64 loss: -2.9170713424682617
Batch 5/64 loss: -2.6991214752197266
Batch 6/64 loss: -2.9199390411376953
Batch 7/64 loss: -2.3595800399780273
Batch 8/64 loss: -2.9311132431030273
Batch 9/64 loss: -2.422517776489258
Batch 10/64 loss: -2.38082218170166
Batch 11/64 loss: -2.72690486907959
Batch 12/64 loss: -2.8544349670410156
Batch 13/64 loss: -2.971407890319824
Batch 14/64 loss: -2.813204765319824
Batch 15/64 loss: -2.2819862365722656
Batch 16/64 loss: -2.6400089263916016
Batch 17/64 loss: -2.783755302429199
Batch 18/64 loss: -2.973139762878418
Batch 19/64 loss: -2.761458396911621
Batch 20/64 loss: -2.841242790222168
Batch 21/64 loss: -2.7947235107421875
Batch 22/64 loss: -2.829679489135742
Batch 23/64 loss: -2.1775426864624023
Batch 24/64 loss: -3.095301628112793
Batch 25/64 loss: -3.119844436645508
Batch 26/64 loss: -2.8886146545410156
Batch 27/64 loss: -2.757044792175293
Batch 28/64 loss: -2.5200843811035156
Batch 29/64 loss: -2.93509578704834
Batch 30/64 loss: -2.750957489013672
Batch 31/64 loss: -2.439882278442383
Batch 32/64 loss: -2.7855377197265625
Batch 33/64 loss: -2.9396324157714844
Batch 34/64 loss: -2.7747602462768555
Batch 35/64 loss: -3.0554590225219727
Batch 36/64 loss: -2.902987480163574
Batch 37/64 loss: -2.954580307006836
Batch 38/64 loss: -2.421818733215332
Batch 39/64 loss: -2.6021337509155273
Batch 40/64 loss: -2.9963455200195312
Batch 41/64 loss: -2.906491279602051
Batch 42/64 loss: -2.738920211791992
Batch 43/64 loss: -2.8848094940185547
Batch 44/64 loss: -2.9229650497436523
Batch 45/64 loss: -2.585470199584961
Batch 46/64 loss: -3.048318862915039
Batch 47/64 loss: -2.734921455383301
Batch 48/64 loss: -3.0766782760620117
Batch 49/64 loss: -2.9622325897216797
Batch 50/64 loss: -2.8955936431884766
Batch 51/64 loss: -2.7636117935180664
Batch 52/64 loss: -2.2938899993896484
Batch 53/64 loss: -2.893101692199707
Batch 54/64 loss: -2.736178398132324
Batch 55/64 loss: -2.7884559631347656
Batch 56/64 loss: -2.8238096237182617
Batch 57/64 loss: -2.0659570693969727
Batch 58/64 loss: -2.27530574798584
Batch 59/64 loss: -2.9495763778686523
Batch 60/64 loss: -2.9907407760620117
Batch 61/64 loss: -2.754110336303711
Batch 62/64 loss: -3.038071632385254
Batch 63/64 loss: -2.5915794372558594
Batch 64/64 loss: -7.435861110687256
Epoch 366  Train loss: -2.8242299715677897  Val loss: -3.063452730473784
Epoch 367
-------------------------------
Batch 1/64 loss: -2.8743371963500977
Batch 2/64 loss: -2.928874969482422
Batch 3/64 loss: -2.7327194213867188
Batch 4/64 loss: -2.767984390258789
Batch 5/64 loss: -3.0059213638305664
Batch 6/64 loss: -2.8181724548339844
Batch 7/64 loss: -2.8224172592163086
Batch 8/64 loss: -2.371790885925293
Batch 9/64 loss: -2.5921249389648438
Batch 10/64 loss: -3.073589324951172
Batch 11/64 loss: -2.9569692611694336
Batch 12/64 loss: -2.9467296600341797
Batch 13/64 loss: -2.877460479736328
Batch 14/64 loss: -2.85866641998291
Batch 15/64 loss: -2.8639450073242188
Batch 16/64 loss: -2.9584827423095703
Batch 17/64 loss: -2.963865280151367
Batch 18/64 loss: -3.001338005065918
Batch 19/64 loss: -2.9362621307373047
Batch 20/64 loss: -2.8735971450805664
Batch 21/64 loss: -2.656388282775879
Batch 22/64 loss: -2.8545007705688477
Batch 23/64 loss: -2.879131317138672
Batch 24/64 loss: -3.074225425720215
Batch 25/64 loss: -2.2863597869873047
Batch 26/64 loss: -2.6255111694335938
Batch 27/64 loss: -2.6912546157836914
Batch 28/64 loss: -2.901808738708496
Batch 29/64 loss: -2.6712894439697266
Batch 30/64 loss: -3.1171703338623047
Batch 31/64 loss: -2.4028701782226562
Batch 32/64 loss: -2.990478515625
Batch 33/64 loss: -3.008416175842285
Batch 34/64 loss: -3.058161735534668
Batch 35/64 loss: -2.6958084106445312
Batch 36/64 loss: -3.0017776489257812
Batch 37/64 loss: -2.91945743560791
Batch 38/64 loss: -2.2081050872802734
Batch 39/64 loss: -3.1290817260742188
Batch 40/64 loss: -2.840475082397461
Batch 41/64 loss: -2.1806211471557617
Batch 42/64 loss: -3.09475040435791
Batch 43/64 loss: -2.643564224243164
Batch 44/64 loss: -2.7115097045898438
Batch 45/64 loss: -2.952458381652832
Batch 46/64 loss: -2.968059539794922
Batch 47/64 loss: -3.0967607498168945
Batch 48/64 loss: -2.8829898834228516
Batch 49/64 loss: -2.8002967834472656
Batch 50/64 loss: -2.512998580932617
Batch 51/64 loss: -2.92825984954834
Batch 52/64 loss: -3.0874929428100586
Batch 53/64 loss: -2.9220781326293945
Batch 54/64 loss: -2.6275482177734375
Batch 55/64 loss: -2.741278648376465
Batch 56/64 loss: -3.079195976257324
Batch 57/64 loss: -3.1055612564086914
Batch 58/64 loss: -2.9766483306884766
Batch 59/64 loss: -2.9933719635009766
Batch 60/64 loss: -2.6069116592407227
Batch 61/64 loss: -3.159071922302246
Batch 62/64 loss: -2.937312126159668
Batch 63/64 loss: -2.721409797668457
Batch 64/64 loss: -7.280681610107422
Epoch 367  Train loss: -2.8929910846785005  Val loss: -3.1592468445243704
Epoch 368
-------------------------------
Batch 1/64 loss: -2.8122730255126953
Batch 2/64 loss: -2.9692230224609375
Batch 3/64 loss: -2.671595573425293
Batch 4/64 loss: -3.0875205993652344
Batch 5/64 loss: -3.0539073944091797
Batch 6/64 loss: -2.889847755432129
Batch 7/64 loss: -3.066934585571289
Batch 8/64 loss: -2.941225051879883
Batch 9/64 loss: -2.829935073852539
Batch 10/64 loss: -2.8004589080810547
Batch 11/64 loss: -3.1014366149902344
Batch 12/64 loss: -3.0577611923217773
Batch 13/64 loss: -2.9440250396728516
Batch 14/64 loss: -2.91512393951416
Batch 15/64 loss: -2.4404611587524414
Batch 16/64 loss: -3.0388193130493164
Batch 17/64 loss: -2.908388137817383
Batch 18/64 loss: -2.8994626998901367
Batch 19/64 loss: -2.264542579650879
Batch 20/64 loss: -3.0186195373535156
Batch 21/64 loss: -2.9838523864746094
Batch 22/64 loss: -2.9916582107543945
Batch 23/64 loss: -2.655026435852051
Batch 24/64 loss: -2.42722225189209
Batch 25/64 loss: -2.8761634826660156
Batch 26/64 loss: -2.7969961166381836
Batch 27/64 loss: -2.8979711532592773
Batch 28/64 loss: -3.049713134765625
Batch 29/64 loss: -3.0961694717407227
Batch 30/64 loss: -2.786348342895508
Batch 31/64 loss: -3.1250858306884766
Batch 32/64 loss: -3.0790653228759766
Batch 33/64 loss: -2.8850173950195312
Batch 34/64 loss: -3.0052738189697266
Batch 35/64 loss: -2.9413509368896484
Batch 36/64 loss: -2.964625358581543
Batch 37/64 loss: -2.6814441680908203
Batch 38/64 loss: -3.055861473083496
Batch 39/64 loss: -2.8969907760620117
Batch 40/64 loss: -3.0701799392700195
Batch 41/64 loss: -2.783308982849121
Batch 42/64 loss: -2.951231002807617
Batch 43/64 loss: -2.9461536407470703
Batch 44/64 loss: -2.445652961730957
Batch 45/64 loss: -2.7756004333496094
Batch 46/64 loss: -3.001889228820801
Batch 47/64 loss: -2.854717254638672
Batch 48/64 loss: -2.4546546936035156
Batch 49/64 loss: -2.901538848876953
Batch 50/64 loss: -2.579617500305176
Batch 51/64 loss: -2.697758674621582
Batch 52/64 loss: -2.154301643371582
Batch 53/64 loss: -2.730837821960449
Batch 54/64 loss: -2.520233154296875
Batch 55/64 loss: -2.812654495239258
Batch 56/64 loss: -2.6315793991088867
Batch 57/64 loss: -3.0038328170776367
Batch 58/64 loss: -2.8413009643554688
Batch 59/64 loss: -2.748101234436035
Batch 60/64 loss: -3.1524534225463867
Batch 61/64 loss: -2.765871047973633
Batch 62/64 loss: -2.6654481887817383
Batch 63/64 loss: -2.663132667541504
Batch 64/64 loss: -7.318177223205566
Epoch 368  Train loss: -2.894871846367331  Val loss: -2.941423829068843
Epoch 369
-------------------------------
Batch 1/64 loss: -2.7604293823242188
Batch 2/64 loss: -3.060004234313965
Batch 3/64 loss: -2.9448633193969727
Batch 4/64 loss: -2.9925222396850586
Batch 5/64 loss: -2.829387664794922
Batch 6/64 loss: -2.7611188888549805
Batch 7/64 loss: -3.092055320739746
Batch 8/64 loss: -2.8946971893310547
Batch 9/64 loss: -2.842113494873047
Batch 10/64 loss: -2.7604494094848633
Batch 11/64 loss: -2.8515920639038086
Batch 12/64 loss: -2.7840890884399414
Batch 13/64 loss: -2.7922096252441406
Batch 14/64 loss: -2.509711265563965
Batch 15/64 loss: -2.9121599197387695
Batch 16/64 loss: -2.801542282104492
Batch 17/64 loss: -2.898715019226074
Batch 18/64 loss: -2.834981918334961
Batch 19/64 loss: -2.659177780151367
Batch 20/64 loss: -2.962592124938965
Batch 21/64 loss: -2.667276382446289
Batch 22/64 loss: -3.054286003112793
Batch 23/64 loss: -2.443964958190918
Batch 24/64 loss: -2.7071704864501953
Batch 25/64 loss: -2.6611976623535156
Batch 26/64 loss: -2.769045829772949
Batch 27/64 loss: -2.9794845581054688
Batch 28/64 loss: -2.9616689682006836
Batch 29/64 loss: -2.325380325317383
Batch 30/64 loss: -3.0634937286376953
Batch 31/64 loss: -2.8455142974853516
Batch 32/64 loss: -2.693039894104004
Batch 33/64 loss: -2.856390953063965
Batch 34/64 loss: -2.55625057220459
Batch 35/64 loss: -2.9792709350585938
Batch 36/64 loss: -2.8993148803710938
Batch 37/64 loss: -2.923027992248535
Batch 38/64 loss: -2.8791799545288086
Batch 39/64 loss: -2.810086250305176
Batch 40/64 loss: -2.8285865783691406
Batch 41/64 loss: -2.9719953536987305
Batch 42/64 loss: -2.801100730895996
Batch 43/64 loss: -2.7536163330078125
Batch 44/64 loss: -2.6288928985595703
Batch 45/64 loss: -3.2424511909484863
Batch 46/64 loss: -2.8517141342163086
Batch 47/64 loss: -2.407785415649414
Batch 48/64 loss: -2.8655614852905273
Batch 49/64 loss: -2.360398292541504
Batch 50/64 loss: -3.000123977661133
Batch 51/64 loss: -3.062615394592285
Batch 52/64 loss: -2.6421289443969727
Batch 53/64 loss: -2.7733726501464844
Batch 54/64 loss: -2.97330379486084
Batch 55/64 loss: -3.002286911010742
Batch 56/64 loss: -2.400991439819336
Batch 57/64 loss: -2.9688587188720703
Batch 58/64 loss: -2.926398277282715
Batch 59/64 loss: -2.7852611541748047
Batch 60/64 loss: -3.0695390701293945
Batch 61/64 loss: -3.1119298934936523
Batch 62/64 loss: -2.5990066528320312
Batch 63/64 loss: -2.8214550018310547
Batch 64/64 loss: -7.653375148773193
Epoch 369  Train loss: -2.880139019910027  Val loss: -3.148205498239838
Epoch 370
-------------------------------
Batch 1/64 loss: -2.890575408935547
Batch 2/64 loss: -2.9375829696655273
Batch 3/64 loss: -2.324838638305664
Batch 4/64 loss: -2.7550201416015625
Batch 5/64 loss: -2.8705997467041016
Batch 6/64 loss: -2.9808082580566406
Batch 7/64 loss: -3.0902671813964844
Batch 8/64 loss: -2.46328067779541
Batch 9/64 loss: -2.9621362686157227
Batch 10/64 loss: -2.9557981491088867
Batch 11/64 loss: -2.821258544921875
Batch 12/64 loss: -2.7528152465820312
Batch 13/64 loss: -2.7891225814819336
Batch 14/64 loss: -2.89022159576416
Batch 15/64 loss: -2.9174299240112305
Batch 16/64 loss: -2.3100833892822266
Batch 17/64 loss: -3.0761451721191406
Batch 18/64 loss: -2.181619644165039
Batch 19/64 loss: -2.4998340606689453
Batch 20/64 loss: -2.8841114044189453
Batch 21/64 loss: -2.9728431701660156
Batch 22/64 loss: -2.5177812576293945
Batch 23/64 loss: -2.9969911575317383
Batch 24/64 loss: -2.7868051528930664
Batch 25/64 loss: -2.9267683029174805
Batch 26/64 loss: -2.780406951904297
Batch 27/64 loss: -2.5444812774658203
Batch 28/64 loss: -2.974453926086426
Batch 29/64 loss: -3.1474924087524414
Batch 30/64 loss: -3.0368432998657227
Batch 31/64 loss: -3.0105819702148438
Batch 32/64 loss: -2.823370933532715
Batch 33/64 loss: -2.669245719909668
Batch 34/64 loss: -3.131711959838867
Batch 35/64 loss: -2.926450729370117
Batch 36/64 loss: -2.8793277740478516
Batch 37/64 loss: -2.168527603149414
Batch 38/64 loss: -2.8844547271728516
Batch 39/64 loss: -2.885211944580078
Batch 40/64 loss: -2.7248477935791016
Batch 41/64 loss: -2.8551673889160156
Batch 42/64 loss: -2.723430633544922
Batch 43/64 loss: -2.824191093444824
Batch 44/64 loss: -2.5641555786132812
Batch 45/64 loss: -2.8861589431762695
Batch 46/64 loss: -2.8485469818115234
Batch 47/64 loss: -2.879270553588867
Batch 48/64 loss: -2.8400096893310547
Batch 49/64 loss: -2.978940963745117
Batch 50/64 loss: -2.663712501525879
Batch 51/64 loss: -2.8707923889160156
Batch 52/64 loss: -2.974209785461426
Batch 53/64 loss: -3.060917854309082
Batch 54/64 loss: -2.483339309692383
Batch 55/64 loss: -3.128894805908203
Batch 56/64 loss: -2.8596744537353516
Batch 57/64 loss: -3.098531723022461
Batch 58/64 loss: -3.070802688598633
Batch 59/64 loss: -2.627687454223633
Batch 60/64 loss: -2.8176097869873047
Batch 61/64 loss: -2.8100290298461914
Batch 62/64 loss: -2.6111364364624023
Batch 63/64 loss: -2.8380355834960938
Batch 64/64 loss: -7.603131294250488
Epoch 370  Train loss: -2.873093979031432  Val loss: -3.0781800050506067
Epoch 371
-------------------------------
Batch 1/64 loss: -2.648580551147461
Batch 2/64 loss: -2.7777891159057617
Batch 3/64 loss: -2.9904041290283203
Batch 4/64 loss: -2.748599052429199
Batch 5/64 loss: -3.0274457931518555
Batch 6/64 loss: -2.8491029739379883
Batch 7/64 loss: -2.766508102416992
Batch 8/64 loss: -2.7210187911987305
Batch 9/64 loss: -2.4634599685668945
Batch 10/64 loss: -2.705573081970215
Batch 11/64 loss: -3.0287551879882812
Batch 12/64 loss: -2.8791818618774414
Batch 13/64 loss: -2.931948661804199
Batch 14/64 loss: -2.8689050674438477
Batch 15/64 loss: -2.6093435287475586
Batch 16/64 loss: -2.726841926574707
Batch 17/64 loss: -2.5398664474487305
Batch 18/64 loss: -2.631450653076172
Batch 19/64 loss: -2.8596811294555664
Batch 20/64 loss: -2.58998966217041
Batch 21/64 loss: -2.8466405868530273
Batch 22/64 loss: -2.142458915710449
Batch 23/64 loss: -2.8691253662109375
Batch 24/64 loss: -2.4372034072875977
Batch 25/64 loss: -2.7667160034179688
Batch 26/64 loss: -2.9646244049072266
Batch 27/64 loss: -2.874401092529297
Batch 28/64 loss: -2.91287899017334
Batch 29/64 loss: -2.7623825073242188
Batch 30/64 loss: -2.9921951293945312
Batch 31/64 loss: -2.858099937438965
Batch 32/64 loss: -2.9442787170410156
Batch 33/64 loss: -2.902920722961426
Batch 34/64 loss: -2.8131275177001953
Batch 35/64 loss: -2.9568872451782227
Batch 36/64 loss: -2.925487518310547
Batch 37/64 loss: -2.934713363647461
Batch 38/64 loss: -2.995133399963379
Batch 39/64 loss: -2.451968193054199
Batch 40/64 loss: -2.6349048614501953
Batch 41/64 loss: -2.788318634033203
Batch 42/64 loss: -3.043590545654297
Batch 43/64 loss: -3.0347976684570312
Batch 44/64 loss: -2.879667282104492
Batch 45/64 loss: -2.7770280838012695
Batch 46/64 loss: -3.0124969482421875
Batch 47/64 loss: -2.887941360473633
Batch 48/64 loss: -3.025247573852539
Batch 49/64 loss: -1.9198408126831055
Batch 50/64 loss: -2.6969127655029297
Batch 51/64 loss: -2.8946895599365234
Batch 52/64 loss: -2.571619987487793
Batch 53/64 loss: -3.097270965576172
Batch 54/64 loss: -3.041073799133301
Batch 55/64 loss: -3.008610725402832
Batch 56/64 loss: -2.815850257873535
Batch 57/64 loss: -2.8681516647338867
Batch 58/64 loss: -2.953022003173828
Batch 59/64 loss: -2.9329843521118164
Batch 60/64 loss: -2.8511133193969727
Batch 61/64 loss: -3.0612382888793945
Batch 62/64 loss: -2.9041624069213867
Batch 63/64 loss: -2.2339439392089844
Batch 64/64 loss: -7.467223644256592
Epoch 371  Train loss: -2.8588326940349504  Val loss: -3.0394441401425913
Epoch 372
-------------------------------
Batch 1/64 loss: -3.0855493545532227
Batch 2/64 loss: -2.471141815185547
Batch 3/64 loss: -2.829904556274414
Batch 4/64 loss: -2.760409355163574
Batch 5/64 loss: -2.4709339141845703
Batch 6/64 loss: -2.3015146255493164
Batch 7/64 loss: -2.7942724227905273
Batch 8/64 loss: -2.946287155151367
Batch 9/64 loss: -2.8799848556518555
Batch 10/64 loss: -2.7404212951660156
Batch 11/64 loss: -2.1146984100341797
Batch 12/64 loss: -2.974214553833008
Batch 13/64 loss: -2.788020133972168
Batch 14/64 loss: -2.3062267303466797
Batch 15/64 loss: -2.808976173400879
Batch 16/64 loss: -2.6136646270751953
Batch 17/64 loss: -2.6850452423095703
Batch 18/64 loss: -2.561751365661621
Batch 19/64 loss: -2.999216079711914
Batch 20/64 loss: -2.463994026184082
Batch 21/64 loss: -2.9266538619995117
Batch 22/64 loss: -2.7599048614501953
Batch 23/64 loss: -3.134380340576172
Batch 24/64 loss: -2.4496688842773438
Batch 25/64 loss: -2.3940391540527344
Batch 26/64 loss: -3.079258918762207
Batch 27/64 loss: -2.602847099304199
Batch 28/64 loss: -2.8904037475585938
Batch 29/64 loss: -2.5719385147094727
Batch 30/64 loss: -2.689729690551758
Batch 31/64 loss: -2.911433219909668
Batch 32/64 loss: -3.013935089111328
Batch 33/64 loss: -2.8012447357177734
Batch 34/64 loss: -2.571308135986328
Batch 35/64 loss: -2.9377546310424805
Batch 36/64 loss: -2.045938491821289
Batch 37/64 loss: -2.9430980682373047
Batch 38/64 loss: -2.8966102600097656
Batch 39/64 loss: -2.9577808380126953
Batch 40/64 loss: -3.18660831451416
Batch 41/64 loss: -2.816974639892578
Batch 42/64 loss: -2.9477949142456055
Batch 43/64 loss: -2.798731803894043
Batch 44/64 loss: -2.7642526626586914
Batch 45/64 loss: -2.8040266036987305
Batch 46/64 loss: -2.8529891967773438
Batch 47/64 loss: -2.959980010986328
Batch 48/64 loss: -2.39111328125
Batch 49/64 loss: -2.872706413269043
Batch 50/64 loss: -2.6195335388183594
Batch 51/64 loss: -2.6692895889282227
Batch 52/64 loss: -2.860654830932617
Batch 53/64 loss: -3.1027116775512695
Batch 54/64 loss: -2.9536209106445312
Batch 55/64 loss: -2.9122238159179688
Batch 56/64 loss: -2.5261478424072266
Batch 57/64 loss: -2.8514060974121094
Batch 58/64 loss: -2.9797277450561523
Batch 59/64 loss: -2.7749814987182617
Batch 60/64 loss: -2.9154720306396484
Batch 61/64 loss: -2.623326301574707
Batch 62/64 loss: -2.839339256286621
Batch 63/64 loss: -2.820021629333496
Batch 64/64 loss: -7.554429054260254
Epoch 372  Train loss: -2.818566456963034  Val loss: -3.1722882457615174
Epoch 373
-------------------------------
Batch 1/64 loss: -2.8000173568725586
Batch 2/64 loss: -2.7460145950317383
Batch 3/64 loss: -2.820331573486328
Batch 4/64 loss: -2.964114189147949
Batch 5/64 loss: -2.171158790588379
Batch 6/64 loss: -2.4586057662963867
Batch 7/64 loss: -3.0917844772338867
Batch 8/64 loss: -3.036360740661621
Batch 9/64 loss: -2.8439712524414062
Batch 10/64 loss: -2.7781686782836914
Batch 11/64 loss: -2.7179689407348633
Batch 12/64 loss: -3.0223588943481445
Batch 13/64 loss: -2.6238718032836914
Batch 14/64 loss: -2.7943735122680664
Batch 15/64 loss: -2.4225568771362305
Batch 16/64 loss: -2.8685741424560547
Batch 17/64 loss: -2.9329023361206055
Batch 18/64 loss: -2.8914127349853516
Batch 19/64 loss: -2.9274473190307617
Batch 20/64 loss: -2.713719367980957
Batch 21/64 loss: -2.584183692932129
Batch 22/64 loss: -3.051346778869629
Batch 23/64 loss: -2.9494876861572266
Batch 24/64 loss: -2.5429162979125977
Batch 25/64 loss: -2.7576160430908203
Batch 26/64 loss: -3.096071243286133
Batch 27/64 loss: -2.7803564071655273
Batch 28/64 loss: -2.9067935943603516
Batch 29/64 loss: -2.9390363693237305
Batch 30/64 loss: -2.7665538787841797
Batch 31/64 loss: -2.959695816040039
Batch 32/64 loss: -2.5641345977783203
Batch 33/64 loss: -2.7328758239746094
Batch 34/64 loss: -3.172236442565918
Batch 35/64 loss: -3.0572853088378906
Batch 36/64 loss: -3.087103843688965
Batch 37/64 loss: -2.728640556335449
Batch 38/64 loss: -2.5737619400024414
Batch 39/64 loss: -2.9504051208496094
Batch 40/64 loss: -2.977264404296875
Batch 41/64 loss: -3.09698486328125
Batch 42/64 loss: -3.025552749633789
Batch 43/64 loss: -2.425924301147461
Batch 44/64 loss: -2.8604354858398438
Batch 45/64 loss: -2.761693000793457
Batch 46/64 loss: -3.1541872024536133
Batch 47/64 loss: -2.8190603256225586
Batch 48/64 loss: -2.1825790405273438
Batch 49/64 loss: -2.7373056411743164
Batch 50/64 loss: -2.8910131454467773
Batch 51/64 loss: -2.5369300842285156
Batch 52/64 loss: -2.9663639068603516
Batch 53/64 loss: -3.078725814819336
Batch 54/64 loss: -2.9612646102905273
Batch 55/64 loss: -3.1028852462768555
Batch 56/64 loss: -2.918473243713379
Batch 57/64 loss: -2.982417106628418
Batch 58/64 loss: -2.879354476928711
Batch 59/64 loss: -2.3630361557006836
Batch 60/64 loss: -2.8304834365844727
Batch 61/64 loss: -2.8102550506591797
Batch 62/64 loss: -2.8830766677856445
Batch 63/64 loss: -2.7662038803100586
Batch 64/64 loss: -7.470276832580566
Epoch 373  Train loss: -2.8774963491103227  Val loss: -3.115753632640511
Epoch 374
-------------------------------
Batch 1/64 loss: -2.893831253051758
Batch 2/64 loss: -2.6867494583129883
Batch 3/64 loss: -2.585230827331543
Batch 4/64 loss: -3.0415802001953125
Batch 5/64 loss: -2.2346839904785156
Batch 6/64 loss: -2.605635643005371
Batch 7/64 loss: -2.810561180114746
Batch 8/64 loss: -2.973390579223633
Batch 9/64 loss: -2.8421735763549805
Batch 10/64 loss: -2.9195289611816406
Batch 11/64 loss: -2.9070053100585938
Batch 12/64 loss: -2.942901611328125
Batch 13/64 loss: -3.038510322570801
Batch 14/64 loss: -2.9037704467773438
Batch 15/64 loss: -3.026585578918457
Batch 16/64 loss: -3.0260629653930664
Batch 17/64 loss: -3.0852622985839844
Batch 18/64 loss: -2.7263832092285156
Batch 19/64 loss: -3.0209693908691406
Batch 20/64 loss: -2.821627616882324
Batch 21/64 loss: -3.0178823471069336
Batch 22/64 loss: -2.6764516830444336
Batch 23/64 loss: -3.1860570907592773
Batch 24/64 loss: -3.095890998840332
Batch 25/64 loss: -2.3046875
Batch 26/64 loss: -3.054680824279785
Batch 27/64 loss: -2.9198999404907227
Batch 28/64 loss: -2.9300079345703125
Batch 29/64 loss: -2.861417770385742
Batch 30/64 loss: -3.1101150512695312
Batch 31/64 loss: -2.7933359146118164
Batch 32/64 loss: -2.7489404678344727
Batch 33/64 loss: -2.9796791076660156
Batch 34/64 loss: -2.8520002365112305
Batch 35/64 loss: -2.6473608016967773
Batch 36/64 loss: -3.036890983581543
Batch 37/64 loss: -2.958907127380371
Batch 38/64 loss: -2.9011335372924805
Batch 39/64 loss: -3.0309925079345703
Batch 40/64 loss: -2.78749942779541
Batch 41/64 loss: -3.0186262130737305
Batch 42/64 loss: -2.486051559448242
Batch 43/64 loss: -2.901042938232422
Batch 44/64 loss: -2.880032539367676
Batch 45/64 loss: -3.059250831604004
Batch 46/64 loss: -3.1638317108154297
Batch 47/64 loss: -2.976001739501953
Batch 48/64 loss: -2.805891990661621
Batch 49/64 loss: -2.779435157775879
Batch 50/64 loss: -2.8566179275512695
Batch 51/64 loss: -2.5954465866088867
Batch 52/64 loss: -2.9597530364990234
Batch 53/64 loss: -3.001070976257324
Batch 54/64 loss: -2.7236595153808594
Batch 55/64 loss: -3.014383316040039
Batch 56/64 loss: -2.276993751525879
Batch 57/64 loss: -3.026913642883301
Batch 58/64 loss: -2.5585947036743164
Batch 59/64 loss: -2.386773109436035
Batch 60/64 loss: -3.027433395385742
Batch 61/64 loss: -2.904932975769043
Batch 62/64 loss: -2.989354133605957
Batch 63/64 loss: -2.9752025604248047
Batch 64/64 loss: -7.289953231811523
Epoch 374  Train loss: -2.9148397632673677  Val loss: -3.1745122011584517
Epoch 375
-------------------------------
Batch 1/64 loss: -2.9750747680664062
Batch 2/64 loss: -2.535327911376953
Batch 3/64 loss: -2.9724111557006836
Batch 4/64 loss: -2.872222900390625
Batch 5/64 loss: -2.7076845169067383
Batch 6/64 loss: -3.2094240188598633
Batch 7/64 loss: -2.800182342529297
Batch 8/64 loss: -1.9671201705932617
Batch 9/64 loss: -3.1384220123291016
Batch 10/64 loss: -2.600916862487793
Batch 11/64 loss: -2.7846860885620117
Batch 12/64 loss: -2.1562557220458984
Batch 13/64 loss: -2.8972702026367188
Batch 14/64 loss: -3.026874542236328
Batch 15/64 loss: -3.044405937194824
Batch 16/64 loss: -2.919158935546875
Batch 17/64 loss: -2.9585933685302734
Batch 18/64 loss: -2.9762964248657227
Batch 19/64 loss: -2.9162397384643555
Batch 20/64 loss: -2.7948083877563477
Batch 21/64 loss: -2.838456153869629
Batch 22/64 loss: -2.8882999420166016
Batch 23/64 loss: -2.97206974029541
Batch 24/64 loss: -2.1826858520507812
Batch 25/64 loss: -2.9305858612060547
Batch 26/64 loss: -2.7456932067871094
Batch 27/64 loss: -2.762274742126465
Batch 28/64 loss: -3.0576934814453125
Batch 29/64 loss: -2.98648738861084
Batch 30/64 loss: -3.120814323425293
Batch 31/64 loss: -2.6993417739868164
Batch 32/64 loss: -2.8709449768066406
Batch 33/64 loss: -2.7867507934570312
Batch 34/64 loss: -2.9736366271972656
Batch 35/64 loss: -2.866086959838867
Batch 36/64 loss: -2.7710323333740234
Batch 37/64 loss: -3.096637725830078
Batch 38/64 loss: -2.873678207397461
Batch 39/64 loss: -2.7467737197875977
Batch 40/64 loss: -2.9680233001708984
Batch 41/64 loss: -3.0409975051879883
Batch 42/64 loss: -2.9697017669677734
Batch 43/64 loss: -2.7440147399902344
Batch 44/64 loss: -2.746084213256836
Batch 45/64 loss: -3.032294273376465
Batch 46/64 loss: -2.967395782470703
Batch 47/64 loss: -2.9484634399414062
Batch 48/64 loss: -2.9183273315429688
Batch 49/64 loss: -2.646397590637207
Batch 50/64 loss: -3.1246652603149414
Batch 51/64 loss: -2.7798337936401367
Batch 52/64 loss: -3.071822166442871
Batch 53/64 loss: -2.950735092163086
Batch 54/64 loss: -3.004974365234375
Batch 55/64 loss: -3.050930976867676
Batch 56/64 loss: -2.7982378005981445
Batch 57/64 loss: -2.784730911254883
Batch 58/64 loss: -2.799406051635742
Batch 59/64 loss: -2.757779121398926
Batch 60/64 loss: -2.582914352416992
Batch 61/64 loss: -3.0243911743164062
Batch 62/64 loss: -2.721872329711914
Batch 63/64 loss: -2.7703752517700195
Batch 64/64 loss: -7.496074199676514
Epoch 375  Train loss: -2.905878338159299  Val loss: -3.176427755978509
Epoch 376
-------------------------------
Batch 1/64 loss: -3.0618696212768555
Batch 2/64 loss: -3.0170822143554688
Batch 3/64 loss: -2.6925086975097656
Batch 4/64 loss: -2.928776741027832
Batch 5/64 loss: -2.383824348449707
Batch 6/64 loss: -2.7365846633911133
Batch 7/64 loss: -3.0883750915527344
Batch 8/64 loss: -2.4908676147460938
Batch 9/64 loss: -2.9767799377441406
Batch 10/64 loss: -2.8852052688598633
Batch 11/64 loss: -2.9377918243408203
Batch 12/64 loss: -2.9587345123291016
Batch 13/64 loss: -2.914745330810547
Batch 14/64 loss: -2.0879478454589844
Batch 15/64 loss: -2.774115562438965
Batch 16/64 loss: -2.970705986022949
Batch 17/64 loss: -2.941181182861328
Batch 18/64 loss: -2.9986820220947266
Batch 19/64 loss: -2.846493721008301
Batch 20/64 loss: -2.8132200241088867
Batch 21/64 loss: -2.912954330444336
Batch 22/64 loss: -2.7141408920288086
Batch 23/64 loss: -2.780590057373047
Batch 24/64 loss: -2.775775909423828
Batch 25/64 loss: -2.8644485473632812
Batch 26/64 loss: -2.0202598571777344
Batch 27/64 loss: -2.4478368759155273
Batch 28/64 loss: -3.0749130249023438
Batch 29/64 loss: -3.1710596084594727
Batch 30/64 loss: -2.8878889083862305
Batch 31/64 loss: -2.8974790573120117
Batch 32/64 loss: -2.9083595275878906
Batch 33/64 loss: -2.8894262313842773
Batch 34/64 loss: -2.6909875869750977
Batch 35/64 loss: -2.506413459777832
Batch 36/64 loss: -2.568452835083008
Batch 37/64 loss: -2.969088554382324
Batch 38/64 loss: -2.9165000915527344
Batch 39/64 loss: -2.860154151916504
Batch 40/64 loss: -2.9869699478149414
Batch 41/64 loss: -2.9246091842651367
Batch 42/64 loss: -3.0493946075439453
Batch 43/64 loss: -3.167302131652832
Batch 44/64 loss: -2.9010543823242188
Batch 45/64 loss: -2.0669870376586914
Batch 46/64 loss: -2.657710075378418
Batch 47/64 loss: -2.888707160949707
Batch 48/64 loss: -2.907498359680176
Batch 49/64 loss: -2.5906553268432617
Batch 50/64 loss: -2.9015426635742188
Batch 51/64 loss: -2.8394088745117188
Batch 52/64 loss: -2.8439855575561523
Batch 53/64 loss: -3.0063886642456055
Batch 54/64 loss: -2.336911201477051
Batch 55/64 loss: -2.2716283798217773
Batch 56/64 loss: -2.83341121673584
Batch 57/64 loss: -2.8229894638061523
Batch 58/64 loss: -2.920045852661133
Batch 59/64 loss: -2.833127021789551
Batch 60/64 loss: -3.01662540435791
Batch 61/64 loss: -2.71372127532959
Batch 62/64 loss: -2.8666763305664062
Batch 63/64 loss: -2.8625688552856445
Batch 64/64 loss: -7.272994518280029
Epoch 376  Train loss: -2.8553237110960716  Val loss: -3.1278701336523103
Epoch 377
-------------------------------
Batch 1/64 loss: -2.6361026763916016
Batch 2/64 loss: -2.5515708923339844
Batch 3/64 loss: -2.907883644104004
Batch 4/64 loss: -2.957179069519043
Batch 5/64 loss: -1.9560346603393555
Batch 6/64 loss: -2.533329963684082
Batch 7/64 loss: -2.8182363510131836
Batch 8/64 loss: -2.983135223388672
Batch 9/64 loss: -3.055889129638672
Batch 10/64 loss: -2.7025270462036133
Batch 11/64 loss: -2.922743797302246
Batch 12/64 loss: -2.9592552185058594
Batch 13/64 loss: -2.5843124389648438
Batch 14/64 loss: -3.0506105422973633
Batch 15/64 loss: -2.7731971740722656
Batch 16/64 loss: -2.773744583129883
Batch 17/64 loss: -2.9273834228515625
Batch 18/64 loss: -2.942337989807129
Batch 19/64 loss: -2.908611297607422
Batch 20/64 loss: -2.850987434387207
Batch 21/64 loss: -2.987537384033203
Batch 22/64 loss: -2.9073028564453125
Batch 23/64 loss: -2.7720890045166016
Batch 24/64 loss: -2.8201398849487305
Batch 25/64 loss: -2.6584949493408203
Batch 26/64 loss: -2.687994956970215
Batch 27/64 loss: -2.8556413650512695
Batch 28/64 loss: -3.004696846008301
Batch 29/64 loss: -2.8937692642211914
Batch 30/64 loss: -2.993575096130371
Batch 31/64 loss: -2.8381214141845703
Batch 32/64 loss: -2.329204559326172
Batch 33/64 loss: -2.9591712951660156
Batch 34/64 loss: -2.599370002746582
Batch 35/64 loss: -2.188441276550293
Batch 36/64 loss: -2.743893623352051
Batch 37/64 loss: -2.999156951904297
Batch 38/64 loss: -2.742584228515625
Batch 39/64 loss: -3.0022411346435547
Batch 40/64 loss: -3.119701385498047
Batch 41/64 loss: -3.0465002059936523
Batch 42/64 loss: -2.8985557556152344
Batch 43/64 loss: -2.826539993286133
Batch 44/64 loss: -2.811923027038574
Batch 45/64 loss: -3.051717758178711
Batch 46/64 loss: -2.977198600769043
Batch 47/64 loss: -2.7708120346069336
Batch 48/64 loss: -2.7846336364746094
Batch 49/64 loss: -2.9536266326904297
Batch 50/64 loss: -3.104135513305664
Batch 51/64 loss: -2.4726715087890625
Batch 52/64 loss: -2.332223892211914
Batch 53/64 loss: -2.9493026733398438
Batch 54/64 loss: -2.803150177001953
Batch 55/64 loss: -2.542141914367676
Batch 56/64 loss: -2.893739700317383
Batch 57/64 loss: -2.7728071212768555
Batch 58/64 loss: -2.985729217529297
Batch 59/64 loss: -2.900636672973633
Batch 60/64 loss: -2.929708480834961
Batch 61/64 loss: -2.4816370010375977
Batch 62/64 loss: -2.6123123168945312
Batch 63/64 loss: -3.140270233154297
Batch 64/64 loss: -7.509289741516113
Epoch 377  Train loss: -2.8638767279830635  Val loss: -3.1728380340890787
Epoch 378
-------------------------------
Batch 1/64 loss: -2.6847362518310547
Batch 2/64 loss: -3.0756187438964844
Batch 3/64 loss: -2.7563695907592773
Batch 4/64 loss: -2.857044219970703
Batch 5/64 loss: -2.916719436645508
Batch 6/64 loss: -3.0351858139038086
Batch 7/64 loss: -2.860200881958008
Batch 8/64 loss: -2.7725725173950195
Batch 9/64 loss: -2.8026065826416016
Batch 10/64 loss: -2.2714357376098633
Batch 11/64 loss: -2.782773971557617
Batch 12/64 loss: -3.096233367919922
Batch 13/64 loss: -2.9546308517456055
Batch 14/64 loss: -2.817647933959961
Batch 15/64 loss: -2.9923830032348633
Batch 16/64 loss: -2.931271553039551
Batch 17/64 loss: -2.908991813659668
Batch 18/64 loss: -3.0319013595581055
Batch 19/64 loss: -3.0164194107055664
Batch 20/64 loss: -2.9127721786499023
Batch 21/64 loss: -2.8783769607543945
Batch 22/64 loss: -2.7728376388549805
Batch 23/64 loss: -3.0693864822387695
Batch 24/64 loss: -2.8757076263427734
Batch 25/64 loss: -3.0715551376342773
Batch 26/64 loss: -2.8464651107788086
Batch 27/64 loss: -3.0762081146240234
Batch 28/64 loss: -2.982877731323242
Batch 29/64 loss: -2.843568801879883
Batch 30/64 loss: -2.957247734069824
Batch 31/64 loss: -3.068669319152832
Batch 32/64 loss: -3.0123300552368164
Batch 33/64 loss: -2.8737802505493164
Batch 34/64 loss: -2.999495506286621
Batch 35/64 loss: -2.8490657806396484
Batch 36/64 loss: -3.119678497314453
Batch 37/64 loss: -2.9266443252563477
Batch 38/64 loss: -2.296100616455078
Batch 39/64 loss: -2.705373764038086
Batch 40/64 loss: -2.482853889465332
Batch 41/64 loss: -3.0619449615478516
Batch 42/64 loss: -2.451131820678711
Batch 43/64 loss: -2.935225486755371
Batch 44/64 loss: -2.5562639236450195
Batch 45/64 loss: -2.735520362854004
Batch 46/64 loss: -2.957733154296875
Batch 47/64 loss: -1.8095388412475586
Batch 48/64 loss: -1.5972328186035156
Batch 49/64 loss: -2.6112327575683594
Batch 50/64 loss: -2.9269418716430664
Batch 51/64 loss: -2.566086769104004
Batch 52/64 loss: -0.9899063110351562
Batch 53/64 loss: -2.3947315216064453
Batch 54/64 loss: -2.412875175476074
Batch 55/64 loss: -2.2087764739990234
Batch 56/64 loss: -1.9184064865112305
Batch 57/64 loss: -2.7571964263916016
Batch 58/64 loss: -2.8752450942993164
Batch 59/64 loss: -2.5705528259277344
Batch 60/64 loss: -2.578557014465332
Batch 61/64 loss: -2.8352136611938477
Batch 62/64 loss: -2.8858108520507812
Batch 63/64 loss: -2.746458053588867
Batch 64/64 loss: -7.379013538360596
Epoch 378  Train loss: -2.7937659824595733  Val loss: -2.828403826841374
Epoch 379
-------------------------------
Batch 1/64 loss: -1.200272560119629
Batch 2/64 loss: -2.8935022354125977
Batch 3/64 loss: -2.055666923522949
Batch 4/64 loss: -2.2504167556762695
Batch 5/64 loss: -2.2976560592651367
Batch 6/64 loss: -2.6275548934936523
Batch 7/64 loss: -2.6163406372070312
Batch 8/64 loss: -1.1453571319580078
Batch 9/64 loss: -2.6480674743652344
Batch 10/64 loss: -2.5993309020996094
Batch 11/64 loss: -1.4510211944580078
Batch 12/64 loss: -2.345700263977051
Batch 13/64 loss: -2.900113105773926
Batch 14/64 loss: -1.971034049987793
Batch 15/64 loss: -2.9046192169189453
Batch 16/64 loss: -2.863652229309082
Batch 17/64 loss: -2.8005151748657227
Batch 18/64 loss: -2.872530937194824
Batch 19/64 loss: -2.9639644622802734
Batch 20/64 loss: -2.8913192749023438
Batch 21/64 loss: -2.8210840225219727
Batch 22/64 loss: -2.6615772247314453
Batch 23/64 loss: -3.0073299407958984
Batch 24/64 loss: -2.165879249572754
Batch 25/64 loss: -2.6649370193481445
Batch 26/64 loss: -2.9224958419799805
Batch 27/64 loss: -2.870718002319336
Batch 28/64 loss: -2.4906702041625977
Batch 29/64 loss: -1.7923955917358398
Batch 30/64 loss: -2.6147403717041016
Batch 31/64 loss: -2.8165979385375977
Batch 32/64 loss: -2.5023889541625977
Batch 33/64 loss: -2.9251813888549805
Batch 34/64 loss: -2.6299314498901367
Batch 35/64 loss: -2.6387548446655273
Batch 36/64 loss: -2.875152587890625
Batch 37/64 loss: -2.2262754440307617
Batch 38/64 loss: -2.5517587661743164
Batch 39/64 loss: -3.0315780639648438
Batch 40/64 loss: -2.5945329666137695
Batch 41/64 loss: -2.9942102432250977
Batch 42/64 loss: -2.831753730773926
Batch 43/64 loss: -2.665374755859375
Batch 44/64 loss: -2.8313684463500977
Batch 45/64 loss: -2.5941429138183594
Batch 46/64 loss: -2.5130720138549805
Batch 47/64 loss: -2.660773277282715
Batch 48/64 loss: -2.6849822998046875
Batch 49/64 loss: -2.4821605682373047
Batch 50/64 loss: -2.4807233810424805
Batch 51/64 loss: -2.679473876953125
Batch 52/64 loss: -2.307462692260742
Batch 53/64 loss: -2.6853256225585938
Batch 54/64 loss: -2.571261405944824
Batch 55/64 loss: -2.9655351638793945
Batch 56/64 loss: -2.8965072631835938
Batch 57/64 loss: -2.821652412414551
Batch 58/64 loss: -2.443544387817383
Batch 59/64 loss: -2.654055595397949
Batch 60/64 loss: -2.9538774490356445
Batch 61/64 loss: -2.7812576293945312
Batch 62/64 loss: -1.9111299514770508
Batch 63/64 loss: -2.9221229553222656
Batch 64/64 loss: -7.479516983032227
Epoch 379  Train loss: -2.635984645170324  Val loss: -3.009486378673016
Epoch 380
-------------------------------
Batch 1/64 loss: -0.8393802642822266
Batch 2/64 loss: -2.888768196105957
Batch 3/64 loss: -2.0221118927001953
Batch 4/64 loss: -2.9514598846435547
Batch 5/64 loss: -2.6304492950439453
Batch 6/64 loss: -2.2969865798950195
Batch 7/64 loss: -1.927901268005371
Batch 8/64 loss: -2.9316415786743164
Batch 9/64 loss: -2.972623825073242
Batch 10/64 loss: -3.133120536804199
Batch 11/64 loss: -2.8141260147094727
Batch 12/64 loss: -2.7065792083740234
Batch 13/64 loss: -2.3171768188476562
Batch 14/64 loss: -2.855794906616211
Batch 15/64 loss: -2.7648744583129883
Batch 16/64 loss: -2.9444265365600586
Batch 17/64 loss: -2.626157760620117
Batch 18/64 loss: -2.998013496398926
Batch 19/64 loss: -2.748171806335449
Batch 20/64 loss: -2.8414134979248047
Batch 21/64 loss: -2.792308807373047
Batch 22/64 loss: -3.048473358154297
Batch 23/64 loss: -2.86767578125
Batch 24/64 loss: -2.922257423400879
Batch 25/64 loss: -2.628024101257324
Batch 26/64 loss: -2.595198631286621
Batch 27/64 loss: -3.0715456008911133
Batch 28/64 loss: -2.9090824127197266
Batch 29/64 loss: -2.8456649780273438
Batch 30/64 loss: -2.836554527282715
Batch 31/64 loss: -3.031780242919922
Batch 32/64 loss: -2.7683582305908203
Batch 33/64 loss: -2.9915847778320312
Batch 34/64 loss: -2.5843124389648438
Batch 35/64 loss: -2.895883560180664
Batch 36/64 loss: -3.0390052795410156
Batch 37/64 loss: -2.80228328704834
Batch 38/64 loss: -2.784329414367676
Batch 39/64 loss: -2.680387496948242
Batch 40/64 loss: -2.5242319107055664
Batch 41/64 loss: -3.190732002258301
Batch 42/64 loss: -2.752412796020508
Batch 43/64 loss: -3.0010108947753906
Batch 44/64 loss: -2.7375593185424805
Batch 45/64 loss: -2.707233428955078
Batch 46/64 loss: -3.030689239501953
Batch 47/64 loss: -2.912539482116699
Batch 48/64 loss: -2.8667497634887695
Batch 49/64 loss: -2.8327503204345703
Batch 50/64 loss: -3.1870031356811523
Batch 51/64 loss: -2.7666969299316406
Batch 52/64 loss: -2.8167524337768555
Batch 53/64 loss: -2.2816028594970703
Batch 54/64 loss: -2.7512054443359375
Batch 55/64 loss: -2.8766393661499023
Batch 56/64 loss: -2.375612258911133
Batch 57/64 loss: -3.0536727905273438
Batch 58/64 loss: -2.862290382385254
Batch 59/64 loss: -2.8983116149902344
Batch 60/64 loss: -2.6476612091064453
Batch 61/64 loss: -2.9174070358276367
Batch 62/64 loss: -2.898125648498535
Batch 63/64 loss: -3.0559206008911133
Batch 64/64 loss: -7.502196311950684
Epoch 380  Train loss: -2.821605431799795  Val loss: -3.120919532382611
Epoch 381
-------------------------------
Batch 1/64 loss: -2.688239097595215
Batch 2/64 loss: -3.046354293823242
Batch 3/64 loss: -2.8938474655151367
Batch 4/64 loss: -3.0158157348632812
Batch 5/64 loss: -3.056180953979492
Batch 6/64 loss: -2.8266077041625977
Batch 7/64 loss: -2.957425117492676
Batch 8/64 loss: -2.8529624938964844
Batch 9/64 loss: -2.878377914428711
Batch 10/64 loss: -3.0817346572875977
Batch 11/64 loss: -2.9361534118652344
Batch 12/64 loss: -2.527088165283203
Batch 13/64 loss: -3.0608139038085938
Batch 14/64 loss: -3.055295944213867
Batch 15/64 loss: -2.896747589111328
Batch 16/64 loss: -2.957775115966797
Batch 17/64 loss: -2.907862663269043
Batch 18/64 loss: -3.0769786834716797
Batch 19/64 loss: -2.9393234252929688
Batch 20/64 loss: -3.157925605773926
Batch 21/64 loss: -2.9986162185668945
Batch 22/64 loss: -3.0038671493530273
Batch 23/64 loss: -3.0290708541870117
Batch 24/64 loss: -2.5554332733154297
Batch 25/64 loss: -2.820876121520996
Batch 26/64 loss: -2.8381481170654297
Batch 27/64 loss: -2.9807586669921875
Batch 28/64 loss: -3.0309104919433594
Batch 29/64 loss: -2.647573471069336
Batch 30/64 loss: -3.06302547454834
Batch 31/64 loss: -2.927858352661133
Batch 32/64 loss: -2.931795120239258
Batch 33/64 loss: -2.940402030944824
Batch 34/64 loss: -2.922390937805176
Batch 35/64 loss: -2.476201057434082
Batch 36/64 loss: -2.9180049896240234
Batch 37/64 loss: -2.300487518310547
Batch 38/64 loss: -3.194756507873535
Batch 39/64 loss: -2.9704065322875977
Batch 40/64 loss: -2.775527000427246
Batch 41/64 loss: -2.8138694763183594
Batch 42/64 loss: -2.9597225189208984
Batch 43/64 loss: -2.7911624908447266
Batch 44/64 loss: -2.3862838745117188
Batch 45/64 loss: -2.932065963745117
Batch 46/64 loss: -2.549131393432617
Batch 47/64 loss: -2.529372215270996
Batch 48/64 loss: -3.013951301574707
Batch 49/64 loss: -1.875931739807129
Batch 50/64 loss: -2.3252334594726562
Batch 51/64 loss: -2.5797224044799805
Batch 52/64 loss: -2.920659065246582
Batch 53/64 loss: -2.655266761779785
Batch 54/64 loss: -2.384934425354004
Batch 55/64 loss: -2.790867805480957
Batch 56/64 loss: -2.596917152404785
Batch 57/64 loss: -2.8264055252075195
Batch 58/64 loss: -2.975527763366699
Batch 59/64 loss: -2.8721561431884766
Batch 60/64 loss: -2.0023460388183594
Batch 61/64 loss: -2.796891212463379
Batch 62/64 loss: -2.5385875701904297
Batch 63/64 loss: -3.000309944152832
Batch 64/64 loss: -7.051529884338379
Epoch 381  Train loss: -2.8634601331224627  Val loss: -3.091108512222972
Epoch 382
-------------------------------
Batch 1/64 loss: -2.9460973739624023
Batch 2/64 loss: -2.810032844543457
Batch 3/64 loss: -2.790694236755371
Batch 4/64 loss: -3.088076591491699
Batch 5/64 loss: -2.7346067428588867
Batch 6/64 loss: -2.7941150665283203
Batch 7/64 loss: -2.8414268493652344
Batch 8/64 loss: -3.042222023010254
Batch 9/64 loss: -2.754204750061035
Batch 10/64 loss: -3.00319766998291
Batch 11/64 loss: -2.904416084289551
Batch 12/64 loss: -2.841949462890625
Batch 13/64 loss: -2.8096437454223633
Batch 14/64 loss: -2.60782527923584
Batch 15/64 loss: -3.093179702758789
Batch 16/64 loss: -2.242903709411621
Batch 17/64 loss: -3.026982307434082
Batch 18/64 loss: -2.6037368774414062
Batch 19/64 loss: -2.859273910522461
Batch 20/64 loss: -2.6610612869262695
Batch 21/64 loss: -2.8274078369140625
Batch 22/64 loss: -2.272541046142578
Batch 23/64 loss: -2.489495277404785
Batch 24/64 loss: -2.9615516662597656
Batch 25/64 loss: -3.0437488555908203
Batch 26/64 loss: -2.9904651641845703
Batch 27/64 loss: -2.806772232055664
Batch 28/64 loss: -2.5581130981445312
Batch 29/64 loss: -3.088555335998535
Batch 30/64 loss: -2.785140037536621
Batch 31/64 loss: -2.8680343627929688
Batch 32/64 loss: -2.7374305725097656
Batch 33/64 loss: -2.9546937942504883
Batch 34/64 loss: -2.168924331665039
Batch 35/64 loss: -2.869391441345215
Batch 36/64 loss: -2.933403968811035
Batch 37/64 loss: -2.718585968017578
Batch 38/64 loss: -2.6219425201416016
Batch 39/64 loss: -2.725857734680176
Batch 40/64 loss: -2.728273391723633
Batch 41/64 loss: -2.8594350814819336
Batch 42/64 loss: -3.1241769790649414
Batch 43/64 loss: -2.7098474502563477
Batch 44/64 loss: -2.8728342056274414
Batch 45/64 loss: -3.081301689147949
Batch 46/64 loss: -2.2498092651367188
Batch 47/64 loss: -2.7398223876953125
Batch 48/64 loss: -2.825082778930664
Batch 49/64 loss: -2.704540252685547
Batch 50/64 loss: -2.9273433685302734
Batch 51/64 loss: -2.6454286575317383
Batch 52/64 loss: -2.979823112487793
Batch 53/64 loss: -2.903580665588379
Batch 54/64 loss: -2.708085060119629
Batch 55/64 loss: -3.0167503356933594
Batch 56/64 loss: -2.630101203918457
Batch 57/64 loss: -2.3548965454101562
Batch 58/64 loss: -2.8438596725463867
Batch 59/64 loss: -2.9733657836914062
Batch 60/64 loss: -2.916865348815918
Batch 61/64 loss: -2.9940919876098633
Batch 62/64 loss: -2.7977142333984375
Batch 63/64 loss: -2.5892763137817383
Batch 64/64 loss: -7.088296413421631
Epoch 382  Train loss: -2.8450232131808413  Val loss: -3.186005058157485
Epoch 383
-------------------------------
Batch 1/64 loss: -3.064753532409668
Batch 2/64 loss: -2.68942928314209
Batch 3/64 loss: -2.6152639389038086
Batch 4/64 loss: -3.0984487533569336
Batch 5/64 loss: -2.7714319229125977
Batch 6/64 loss: -2.718189239501953
Batch 7/64 loss: -2.931757926940918
Batch 8/64 loss: -2.9525585174560547
Batch 9/64 loss: -2.927774429321289
Batch 10/64 loss: -3.0176477432250977
Batch 11/64 loss: -2.3867416381835938
Batch 12/64 loss: -2.8325328826904297
Batch 13/64 loss: -3.0050430297851562
Batch 14/64 loss: -2.9300928115844727
Batch 15/64 loss: -2.9246559143066406
Batch 16/64 loss: -2.838902473449707
Batch 17/64 loss: -2.83516788482666
Batch 18/64 loss: -2.6475963592529297
Batch 19/64 loss: -2.6934757232666016
Batch 20/64 loss: -2.684610366821289
Batch 21/64 loss: -3.0754499435424805
Batch 22/64 loss: -2.888901710510254
Batch 23/64 loss: -2.9947948455810547
Batch 24/64 loss: -2.9294843673706055
Batch 25/64 loss: -2.5559396743774414
Batch 26/64 loss: -3.0218772888183594
Batch 27/64 loss: -2.932745933532715
Batch 28/64 loss: -2.8682260513305664
Batch 29/64 loss: -2.890676498413086
Batch 30/64 loss: -2.3721160888671875
Batch 31/64 loss: -3.0662803649902344
Batch 32/64 loss: -2.5181055068969727
Batch 33/64 loss: -2.415637969970703
Batch 34/64 loss: -2.882431983947754
Batch 35/64 loss: -2.8498802185058594
Batch 36/64 loss: -2.9313201904296875
Batch 37/64 loss: -2.9205808639526367
Batch 38/64 loss: -2.938455581665039
Batch 39/64 loss: -3.0281829833984375
Batch 40/64 loss: -2.622542381286621
Batch 41/64 loss: -2.757086753845215
Batch 42/64 loss: -2.9207334518432617
Batch 43/64 loss: -3.0663232803344727
Batch 44/64 loss: -2.822707176208496
Batch 45/64 loss: -2.7868146896362305
Batch 46/64 loss: -2.5258007049560547
Batch 47/64 loss: -2.7461233139038086
Batch 48/64 loss: -2.83828067779541
Batch 49/64 loss: -2.989185333251953
Batch 50/64 loss: -2.809725761413574
Batch 51/64 loss: -3.0133914947509766
Batch 52/64 loss: -2.8350601196289062
Batch 53/64 loss: -2.8395118713378906
Batch 54/64 loss: -2.9473743438720703
Batch 55/64 loss: -2.978814125061035
Batch 56/64 loss: -2.908719062805176
Batch 57/64 loss: -2.7544288635253906
Batch 58/64 loss: -2.792278289794922
Batch 59/64 loss: -2.8480653762817383
Batch 60/64 loss: -2.910501480102539
Batch 61/64 loss: -2.837230682373047
Batch 62/64 loss: -2.828667640686035
Batch 63/64 loss: -2.252779006958008
Batch 64/64 loss: -7.415946006774902
Epoch 383  Train loss: -2.8837845933203603  Val loss: -3.161148766062104
Epoch 384
-------------------------------
Batch 1/64 loss: -3.0563220977783203
Batch 2/64 loss: -2.84378719329834
Batch 3/64 loss: -3.086465835571289
Batch 4/64 loss: -3.056987762451172
Batch 5/64 loss: -2.567379951477051
Batch 6/64 loss: -2.6678037643432617
Batch 7/64 loss: -2.6815900802612305
Batch 8/64 loss: -2.8854427337646484
Batch 9/64 loss: -2.8076915740966797
Batch 10/64 loss: -2.752805709838867
Batch 11/64 loss: -2.8731565475463867
Batch 12/64 loss: -2.690415382385254
Batch 13/64 loss: -2.577031135559082
Batch 14/64 loss: -2.954019546508789
Batch 15/64 loss: -2.924304962158203
Batch 16/64 loss: -2.8326892852783203
Batch 17/64 loss: -3.092635154724121
Batch 18/64 loss: -2.8871946334838867
Batch 19/64 loss: -2.8373146057128906
Batch 20/64 loss: -2.5955018997192383
Batch 21/64 loss: -2.7759971618652344
Batch 22/64 loss: -2.7768030166625977
Batch 23/64 loss: -2.868427276611328
Batch 24/64 loss: -2.855134963989258
Batch 25/64 loss: -2.8033018112182617
Batch 26/64 loss: -2.709920883178711
Batch 27/64 loss: -2.634857177734375
Batch 28/64 loss: -2.716395378112793
Batch 29/64 loss: -2.9771337509155273
Batch 30/64 loss: -3.0221548080444336
Batch 31/64 loss: -2.854414939880371
Batch 32/64 loss: -2.886749267578125
Batch 33/64 loss: -2.9931230545043945
Batch 34/64 loss: -2.8281373977661133
Batch 35/64 loss: -2.90756893157959
Batch 36/64 loss: -2.5941572189331055
Batch 37/64 loss: -2.861764907836914
Batch 38/64 loss: -2.8138818740844727
Batch 39/64 loss: -3.122584342956543
Batch 40/64 loss: -2.8376693725585938
Batch 41/64 loss: -2.764279365539551
Batch 42/64 loss: -2.942697525024414
Batch 43/64 loss: -3.0440587997436523
Batch 44/64 loss: -2.9526195526123047
Batch 45/64 loss: -2.315328598022461
Batch 46/64 loss: -2.7684011459350586
Batch 47/64 loss: -2.7146387100219727
Batch 48/64 loss: -2.8006153106689453
Batch 49/64 loss: -2.6067886352539062
Batch 50/64 loss: -2.872425079345703
Batch 51/64 loss: -3.104290008544922
Batch 52/64 loss: -2.8447771072387695
Batch 53/64 loss: -2.902639389038086
Batch 54/64 loss: -2.2996273040771484
Batch 55/64 loss: -2.7197160720825195
Batch 56/64 loss: -2.905040740966797
Batch 57/64 loss: -2.932973861694336
Batch 58/64 loss: -2.7764625549316406
Batch 59/64 loss: -3.0017566680908203
Batch 60/64 loss: -2.795795440673828
Batch 61/64 loss: -3.000974655151367
Batch 62/64 loss: -2.820646286010742
Batch 63/64 loss: -2.584099769592285
Batch 64/64 loss: -7.593836307525635
Epoch 384  Train loss: -2.881203877692129  Val loss: -3.1911336761159994
Epoch 385
-------------------------------
Batch 1/64 loss: -3.0274152755737305
Batch 2/64 loss: -2.695009231567383
Batch 3/64 loss: -2.9256935119628906
Batch 4/64 loss: -2.8367347717285156
Batch 5/64 loss: -2.7850112915039062
Batch 6/64 loss: -2.8746442794799805
Batch 7/64 loss: -2.7149124145507812
Batch 8/64 loss: -2.951120376586914
Batch 9/64 loss: -2.9386072158813477
Batch 10/64 loss: -2.9376182556152344
Batch 11/64 loss: -2.8764286041259766
Batch 12/64 loss: -3.039340019226074
Batch 13/64 loss: -2.960890769958496
Batch 14/64 loss: -2.9919958114624023
Batch 15/64 loss: -2.983074188232422
Batch 16/64 loss: -2.8774728775024414
Batch 17/64 loss: -3.026028633117676
Batch 18/64 loss: -2.96304988861084
Batch 19/64 loss: -3.003037452697754
Batch 20/64 loss: -3.0515995025634766
Batch 21/64 loss: -2.863776206970215
Batch 22/64 loss: -2.786932945251465
Batch 23/64 loss: -3.043844223022461
Batch 24/64 loss: -3.1441545486450195
Batch 25/64 loss: -2.7668657302856445
Batch 26/64 loss: -3.1078529357910156
Batch 27/64 loss: -2.74379825592041
Batch 28/64 loss: -2.8562192916870117
Batch 29/64 loss: -3.0181331634521484
Batch 30/64 loss: -2.9820919036865234
Batch 31/64 loss: -2.5540666580200195
Batch 32/64 loss: -2.334017753601074
Batch 33/64 loss: -2.517144203186035
Batch 34/64 loss: -2.3305130004882812
Batch 35/64 loss: -2.7450742721557617
Batch 36/64 loss: -2.878359794616699
Batch 37/64 loss: -3.034709930419922
Batch 38/64 loss: -3.0086536407470703
Batch 39/64 loss: -2.961716651916504
Batch 40/64 loss: -2.692379951477051
Batch 41/64 loss: -2.887608528137207
Batch 42/64 loss: -2.733469009399414
Batch 43/64 loss: -2.5004758834838867
Batch 44/64 loss: -2.8337440490722656
Batch 45/64 loss: -2.650649070739746
Batch 46/64 loss: -2.955991744995117
Batch 47/64 loss: -2.756688117980957
Batch 48/64 loss: -2.8803014755249023
Batch 49/64 loss: -3.089482307434082
Batch 50/64 loss: -2.737550735473633
Batch 51/64 loss: -2.9255924224853516
Batch 52/64 loss: -2.465677261352539
Batch 53/64 loss: -2.9331045150756836
Batch 54/64 loss: -2.8651552200317383
Batch 55/64 loss: -2.614482879638672
Batch 56/64 loss: -2.8411808013916016
Batch 57/64 loss: -2.878146171569824
Batch 58/64 loss: -2.9766454696655273
Batch 59/64 loss: -3.046658515930176
Batch 60/64 loss: -2.934634208679199
Batch 61/64 loss: -2.6869821548461914
Batch 62/64 loss: -2.916776657104492
Batch 63/64 loss: -2.987532615661621
Batch 64/64 loss: -7.485735893249512
Epoch 385  Train loss: -2.9104756261788163  Val loss: -3.158260030844777
Epoch 386
-------------------------------
Batch 1/64 loss: -2.7745895385742188
Batch 2/64 loss: -2.7605886459350586
Batch 3/64 loss: -2.803227424621582
Batch 4/64 loss: -2.85677433013916
Batch 5/64 loss: -2.895906448364258
Batch 6/64 loss: -2.793135643005371
Batch 7/64 loss: -2.9750967025756836
Batch 8/64 loss: -2.930924415588379
Batch 9/64 loss: -2.905609130859375
Batch 10/64 loss: -2.936751365661621
Batch 11/64 loss: -2.9085350036621094
Batch 12/64 loss: -3.030651092529297
Batch 13/64 loss: -3.010774612426758
Batch 14/64 loss: -2.9299278259277344
Batch 15/64 loss: -2.940566062927246
Batch 16/64 loss: -2.7067861557006836
Batch 17/64 loss: -2.7834386825561523
Batch 18/64 loss: -2.9315357208251953
Batch 19/64 loss: -2.799671173095703
Batch 20/64 loss: -3.038846969604492
Batch 21/64 loss: -2.957263946533203
Batch 22/64 loss: -2.9155149459838867
Batch 23/64 loss: -2.999185562133789
Batch 24/64 loss: -2.9977035522460938
Batch 25/64 loss: -3.0611438751220703
Batch 26/64 loss: -3.007537841796875
Batch 27/64 loss: -3.186591625213623
Batch 28/64 loss: -2.709970474243164
Batch 29/64 loss: -2.656386375427246
Batch 30/64 loss: -3.1390857696533203
Batch 31/64 loss: -3.0747690200805664
Batch 32/64 loss: -2.96549129486084
Batch 33/64 loss: -2.962801933288574
Batch 34/64 loss: -3.0262441635131836
Batch 35/64 loss: -3.097688674926758
Batch 36/64 loss: -3.0795717239379883
Batch 37/64 loss: -2.899148941040039
Batch 38/64 loss: -2.903636932373047
Batch 39/64 loss: -3.0116443634033203
Batch 40/64 loss: -2.4341049194335938
Batch 41/64 loss: -2.8915014266967773
Batch 42/64 loss: -2.926558494567871
Batch 43/64 loss: -2.801227569580078
Batch 44/64 loss: -2.663285255432129
Batch 45/64 loss: -3.0951786041259766
Batch 46/64 loss: -2.976552963256836
Batch 47/64 loss: -2.9464874267578125
Batch 48/64 loss: -2.880721092224121
Batch 49/64 loss: -2.9971542358398438
Batch 50/64 loss: -2.968538284301758
Batch 51/64 loss: -3.05367374420166
Batch 52/64 loss: -2.842020034790039
Batch 53/64 loss: -3.092123031616211
Batch 54/64 loss: -3.1428565979003906
Batch 55/64 loss: -3.0500049591064453
Batch 56/64 loss: -2.9787826538085938
Batch 57/64 loss: -2.9692859649658203
Batch 58/64 loss: -2.7588539123535156
Batch 59/64 loss: -2.221236228942871
Batch 60/64 loss: -2.810098648071289
Batch 61/64 loss: -2.419856071472168
Batch 62/64 loss: -2.154726982116699
Batch 63/64 loss: -2.8246192932128906
Batch 64/64 loss: -7.439173698425293
Epoch 386  Train loss: -2.9465654373168944  Val loss: -3.2350744791456925
Epoch 387
-------------------------------
Batch 1/64 loss: -3.0332651138305664
Batch 2/64 loss: -3.1736860275268555
Batch 3/64 loss: -3.0988035202026367
Batch 4/64 loss: -3.155064582824707
Batch 5/64 loss: -3.083150863647461
Batch 6/64 loss: -2.950511932373047
Batch 7/64 loss: -2.975399971008301
Batch 8/64 loss: -2.947460174560547
Batch 9/64 loss: -2.5637922286987305
Batch 10/64 loss: -2.9430370330810547
Batch 11/64 loss: -2.2347068786621094
Batch 12/64 loss: -2.971205711364746
Batch 13/64 loss: -2.829195976257324
Batch 14/64 loss: -2.2887353897094727
Batch 15/64 loss: -2.7650976181030273
Batch 16/64 loss: -3.0561885833740234
Batch 17/64 loss: -3.1672658920288086
Batch 18/64 loss: -3.058633804321289
Batch 19/64 loss: -2.7436628341674805
Batch 20/64 loss: -2.9952707290649414
Batch 21/64 loss: -3.0717668533325195
Batch 22/64 loss: -2.7966203689575195
Batch 23/64 loss: -3.051020622253418
Batch 24/64 loss: -3.001338005065918
Batch 25/64 loss: -3.1176576614379883
Batch 26/64 loss: -3.023622512817383
Batch 27/64 loss: -2.916741371154785
Batch 28/64 loss: -2.8426895141601562
Batch 29/64 loss: -2.9592466354370117
Batch 30/64 loss: -2.617489814758301
Batch 31/64 loss: -2.938997268676758
Batch 32/64 loss: -3.121805191040039
Batch 33/64 loss: -3.200193405151367
Batch 34/64 loss: -2.859999656677246
Batch 35/64 loss: -2.9898767471313477
Batch 36/64 loss: -2.989238739013672
Batch 37/64 loss: -2.969106674194336
Batch 38/64 loss: -2.9949188232421875
Batch 39/64 loss: -2.7405433654785156
Batch 40/64 loss: -2.811274528503418
Batch 41/64 loss: -2.9292984008789062
Batch 42/64 loss: -2.8094730377197266
Batch 43/64 loss: -3.0089378356933594
Batch 44/64 loss: -2.8265018463134766
Batch 45/64 loss: -2.9206066131591797
Batch 46/64 loss: -2.5488548278808594
Batch 47/64 loss: -2.9873247146606445
Batch 48/64 loss: -2.8986406326293945
Batch 49/64 loss: -3.112612724304199
Batch 50/64 loss: -3.0163326263427734
Batch 51/64 loss: -2.5996360778808594
Batch 52/64 loss: -3.065765380859375
Batch 53/64 loss: -3.0748634338378906
Batch 54/64 loss: -2.908879280090332
Batch 55/64 loss: -2.924330711364746
Batch 56/64 loss: -2.9072628021240234
Batch 57/64 loss: -2.809697151184082
Batch 58/64 loss: -2.827817916870117
Batch 59/64 loss: -3.077225685119629
Batch 60/64 loss: -2.73940372467041
Batch 61/64 loss: -2.9041213989257812
Batch 62/64 loss: -1.9576215744018555
Batch 63/64 loss: -2.9657764434814453
Batch 64/64 loss: -7.1699748039245605
Epoch 387  Train loss: -2.952890173594157  Val loss: -3.137265706799694
Epoch 388
-------------------------------
Batch 1/64 loss: -2.9532737731933594
Batch 2/64 loss: -2.9122018814086914
Batch 3/64 loss: -2.8966188430786133
Batch 4/64 loss: -3.048330307006836
Batch 5/64 loss: -3.0433883666992188
Batch 6/64 loss: -2.786015510559082
Batch 7/64 loss: -2.8262510299682617
Batch 8/64 loss: -2.8599853515625
Batch 9/64 loss: -2.670228958129883
Batch 10/64 loss: -2.9066848754882812
Batch 11/64 loss: -2.685985565185547
Batch 12/64 loss: -3.06380558013916
Batch 13/64 loss: -3.1584930419921875
Batch 14/64 loss: -2.8097925186157227
Batch 15/64 loss: -2.6149044036865234
Batch 16/64 loss: -3.0334653854370117
Batch 17/64 loss: -2.871647834777832
Batch 18/64 loss: -2.5416259765625
Batch 19/64 loss: -3.124752998352051
Batch 20/64 loss: -2.6435861587524414
Batch 21/64 loss: -2.8938026428222656
Batch 22/64 loss: -2.89138126373291
Batch 23/64 loss: -2.714426040649414
Batch 24/64 loss: -2.875115394592285
Batch 25/64 loss: -2.602987289428711
Batch 26/64 loss: -2.823971748352051
Batch 27/64 loss: -2.707991600036621
Batch 28/64 loss: -2.990163803100586
Batch 29/64 loss: -2.1910552978515625
Batch 30/64 loss: -2.776031494140625
Batch 31/64 loss: -2.845125198364258
Batch 32/64 loss: -2.7742557525634766
Batch 33/64 loss: -3.152894973754883
Batch 34/64 loss: -3.065699577331543
Batch 35/64 loss: -2.8215999603271484
Batch 36/64 loss: -2.602278709411621
Batch 37/64 loss: -3.004837989807129
Batch 38/64 loss: -2.8130645751953125
Batch 39/64 loss: -3.1031150817871094
Batch 40/64 loss: -2.8391294479370117
Batch 41/64 loss: -2.8926963806152344
Batch 42/64 loss: -2.7793264389038086
Batch 43/64 loss: -2.829195976257324
Batch 44/64 loss: -2.940927505493164
Batch 45/64 loss: -2.738173484802246
Batch 46/64 loss: -2.453169822692871
Batch 47/64 loss: -2.7231521606445312
Batch 48/64 loss: -2.490166664123535
Batch 49/64 loss: -1.9557104110717773
Batch 50/64 loss: -2.8775863647460938
Batch 51/64 loss: -2.872091293334961
Batch 52/64 loss: -2.933629035949707
Batch 53/64 loss: -2.1113014221191406
Batch 54/64 loss: -2.79300594329834
Batch 55/64 loss: -2.3388357162475586
Batch 56/64 loss: -2.98098087310791
Batch 57/64 loss: -2.601040840148926
Batch 58/64 loss: -3.0367650985717773
Batch 59/64 loss: -2.9669322967529297
Batch 60/64 loss: -2.7185773849487305
Batch 61/64 loss: -2.955061912536621
Batch 62/64 loss: -2.9892702102661133
Batch 63/64 loss: -3.0830163955688477
Batch 64/64 loss: -7.411665439605713
Epoch 388  Train loss: -2.8636757476657047  Val loss: -3.03335676160465
Epoch 389
-------------------------------
Batch 1/64 loss: -3.025141716003418
Batch 2/64 loss: -2.864272117614746
Batch 3/64 loss: -2.6218414306640625
Batch 4/64 loss: -2.9955520629882812
Batch 5/64 loss: -2.4903717041015625
Batch 6/64 loss: -3.1265316009521484
Batch 7/64 loss: -2.457569122314453
Batch 8/64 loss: -2.7933387756347656
Batch 9/64 loss: -2.6522769927978516
Batch 10/64 loss: -3.1701765060424805
Batch 11/64 loss: -2.4145431518554688
Batch 12/64 loss: -2.31210994720459
Batch 13/64 loss: -3.0534963607788086
Batch 14/64 loss: -2.877699851989746
Batch 15/64 loss: -2.654191017150879
Batch 16/64 loss: -3.0238771438598633
Batch 17/64 loss: -2.9384775161743164
Batch 18/64 loss: -2.830033302307129
Batch 19/64 loss: -3.163743019104004
Batch 20/64 loss: -3.082411766052246
Batch 21/64 loss: -2.686922073364258
Batch 22/64 loss: -2.7344789505004883
Batch 23/64 loss: -2.9130859375
Batch 24/64 loss: -3.141408920288086
Batch 25/64 loss: -2.889040946960449
Batch 26/64 loss: -2.8404617309570312
Batch 27/64 loss: -2.9407968521118164
Batch 28/64 loss: -3.0411577224731445
Batch 29/64 loss: -3.0770139694213867
Batch 30/64 loss: -2.334963798522949
Batch 31/64 loss: -2.495486259460449
Batch 32/64 loss: -3.0828285217285156
Batch 33/64 loss: -2.912607192993164
Batch 34/64 loss: -2.7266416549682617
Batch 35/64 loss: -2.3829565048217773
Batch 36/64 loss: -3.133082389831543
Batch 37/64 loss: -2.971795082092285
Batch 38/64 loss: -3.02288818359375
Batch 39/64 loss: -3.02689266204834
Batch 40/64 loss: -2.730008125305176
Batch 41/64 loss: -2.7699451446533203
Batch 42/64 loss: -2.303799629211426
Batch 43/64 loss: -2.941983222961426
Batch 44/64 loss: -3.0633440017700195
Batch 45/64 loss: -2.9583511352539062
Batch 46/64 loss: -2.827813148498535
Batch 47/64 loss: -2.5703048706054688
Batch 48/64 loss: -3.0807933807373047
Batch 49/64 loss: -2.8180713653564453
Batch 50/64 loss: -2.9427967071533203
Batch 51/64 loss: -2.7557430267333984
Batch 52/64 loss: -2.357707977294922
Batch 53/64 loss: -2.739908218383789
Batch 54/64 loss: -2.6112871170043945
Batch 55/64 loss: -2.629650115966797
Batch 56/64 loss: -3.101223945617676
Batch 57/64 loss: -2.734647750854492
Batch 58/64 loss: -2.827151298522949
Batch 59/64 loss: -2.959789276123047
Batch 60/64 loss: -2.866365432739258
Batch 61/64 loss: -2.992879867553711
Batch 62/64 loss: -3.1751089096069336
Batch 63/64 loss: -2.7170190811157227
Batch 64/64 loss: -7.431219577789307
Epoch 389  Train loss: -2.8855101473191205  Val loss: -3.1388137528986455
Epoch 390
-------------------------------
Batch 1/64 loss: -3.116976737976074
Batch 2/64 loss: -2.8737058639526367
Batch 3/64 loss: -2.8098716735839844
Batch 4/64 loss: -2.9563827514648438
Batch 5/64 loss: -2.783153533935547
Batch 6/64 loss: -2.902599334716797
Batch 7/64 loss: -2.6790170669555664
Batch 8/64 loss: -2.938060760498047
Batch 9/64 loss: -2.9184703826904297
Batch 10/64 loss: -2.954012870788574
Batch 11/64 loss: -2.8964738845825195
Batch 12/64 loss: -3.09152889251709
Batch 13/64 loss: -2.9796581268310547
Batch 14/64 loss: -2.9517602920532227
Batch 15/64 loss: -2.944713592529297
Batch 16/64 loss: -3.024613380432129
Batch 17/64 loss: -2.8786067962646484
Batch 18/64 loss: -2.7059755325317383
Batch 19/64 loss: -2.703038215637207
Batch 20/64 loss: -2.953122138977051
Batch 21/64 loss: -2.7802610397338867
Batch 22/64 loss: -2.2449378967285156
Batch 23/64 loss: -2.8305253982543945
Batch 24/64 loss: -2.722064971923828
Batch 25/64 loss: -2.9908361434936523
Batch 26/64 loss: -2.851679801940918
Batch 27/64 loss: -2.868877410888672
Batch 28/64 loss: -2.7961387634277344
Batch 29/64 loss: -2.928694725036621
Batch 30/64 loss: -2.7554683685302734
Batch 31/64 loss: -2.8252058029174805
Batch 32/64 loss: -3.038156509399414
Batch 33/64 loss: -2.9520139694213867
Batch 34/64 loss: -2.955735206604004
Batch 35/64 loss: -2.9240169525146484
Batch 36/64 loss: -2.9665699005126953
Batch 37/64 loss: -2.1212644577026367
Batch 38/64 loss: -2.968503952026367
Batch 39/64 loss: -2.7812366485595703
Batch 40/64 loss: -3.1584768295288086
Batch 41/64 loss: -2.6259689331054688
Batch 42/64 loss: -2.766092300415039
Batch 43/64 loss: -2.1417102813720703
Batch 44/64 loss: -2.7331809997558594
Batch 45/64 loss: -3.1486902236938477
Batch 46/64 loss: -2.9494857788085938
Batch 47/64 loss: -2.9348020553588867
Batch 48/64 loss: -3.0393762588500977
Batch 49/64 loss: -2.9093799591064453
Batch 50/64 loss: -3.046078681945801
Batch 51/64 loss: -2.8560009002685547
Batch 52/64 loss: -2.8400354385375977
Batch 53/64 loss: -2.9672584533691406
Batch 54/64 loss: -2.83404541015625
Batch 55/64 loss: -3.0439586639404297
Batch 56/64 loss: -2.9732398986816406
Batch 57/64 loss: -3.0001983642578125
Batch 58/64 loss: -2.983989715576172
Batch 59/64 loss: -2.9644241333007812
Batch 60/64 loss: -2.631084442138672
Batch 61/64 loss: -2.41341495513916
Batch 62/64 loss: -2.9099578857421875
Batch 63/64 loss: -2.8959054946899414
Batch 64/64 loss: -6.82621955871582
Epoch 390  Train loss: -2.905887850593118  Val loss: -3.0869358102070916
Epoch 391
-------------------------------
Batch 1/64 loss: -3.027088165283203
Batch 2/64 loss: -2.6660385131835938
Batch 3/64 loss: -2.67331600189209
Batch 4/64 loss: -3.039332389831543
Batch 5/64 loss: -2.7318239212036133
Batch 6/64 loss: -2.612131118774414
Batch 7/64 loss: -2.8901777267456055
Batch 8/64 loss: -2.983973503112793
Batch 9/64 loss: -2.977423667907715
Batch 10/64 loss: -2.8641414642333984
Batch 11/64 loss: -2.624429702758789
Batch 12/64 loss: -2.765697479248047
Batch 13/64 loss: -2.7979211807250977
Batch 14/64 loss: -3.035594940185547
Batch 15/64 loss: -2.9960079193115234
Batch 16/64 loss: -3.1291513442993164
Batch 17/64 loss: -2.670459747314453
Batch 18/64 loss: -2.533203125
Batch 19/64 loss: -3.00069522857666
Batch 20/64 loss: -2.844357490539551
Batch 21/64 loss: -2.7589855194091797
Batch 22/64 loss: -2.9207763671875
Batch 23/64 loss: -3.0824108123779297
Batch 24/64 loss: -2.6286211013793945
Batch 25/64 loss: -2.86185359954834
Batch 26/64 loss: -3.2186784744262695
Batch 27/64 loss: -3.0157947540283203
Batch 28/64 loss: -2.908649444580078
Batch 29/64 loss: -2.94561767578125
Batch 30/64 loss: -2.68808650970459
Batch 31/64 loss: -2.8578758239746094
Batch 32/64 loss: -2.3186559677124023
Batch 33/64 loss: -2.437281608581543
Batch 34/64 loss: -2.642327308654785
Batch 35/64 loss: -2.8012351989746094
Batch 36/64 loss: -2.8948259353637695
Batch 37/64 loss: -3.0298967361450195
Batch 38/64 loss: -2.6485652923583984
Batch 39/64 loss: -2.890488624572754
Batch 40/64 loss: -2.860322952270508
Batch 41/64 loss: -2.9191808700561523
Batch 42/64 loss: -2.849440574645996
Batch 43/64 loss: -2.9727516174316406
Batch 44/64 loss: -2.6405982971191406
Batch 45/64 loss: -2.73561954498291
Batch 46/64 loss: -2.5565853118896484
Batch 47/64 loss: -2.728142738342285
Batch 48/64 loss: -1.9523744583129883
Batch 49/64 loss: -2.3740148544311523
Batch 50/64 loss: -3.220609664916992
Batch 51/64 loss: -2.9090843200683594
Batch 52/64 loss: -2.888702392578125
Batch 53/64 loss: -2.8906822204589844
Batch 54/64 loss: -3.050543785095215
Batch 55/64 loss: -3.001462936401367
Batch 56/64 loss: -3.0301504135131836
Batch 57/64 loss: -3.010211944580078
Batch 58/64 loss: -2.8023481369018555
Batch 59/64 loss: -2.949446678161621
Batch 60/64 loss: -2.6082706451416016
Batch 61/64 loss: -2.6855545043945312
Batch 62/64 loss: -2.8331079483032227
Batch 63/64 loss: -2.872370719909668
Batch 64/64 loss: -7.428475856781006
Epoch 391  Train loss: -2.8757102087432265  Val loss: -3.0397852081613443
Epoch 392
-------------------------------
Batch 1/64 loss: -2.8399505615234375
Batch 2/64 loss: -2.651556968688965
Batch 3/64 loss: -3.0164642333984375
Batch 4/64 loss: -3.0048885345458984
Batch 5/64 loss: -2.900968551635742
Batch 6/64 loss: -3.0806589126586914
Batch 7/64 loss: -2.840869903564453
Batch 8/64 loss: -2.9106788635253906
Batch 9/64 loss: -2.7788753509521484
Batch 10/64 loss: -2.8668746948242188
Batch 11/64 loss: -2.878830909729004
Batch 12/64 loss: -3.01328182220459
Batch 13/64 loss: -2.8524322509765625
Batch 14/64 loss: -2.0744428634643555
Batch 15/64 loss: -2.704824447631836
Batch 16/64 loss: -2.9460134506225586
Batch 17/64 loss: -2.6953516006469727
Batch 18/64 loss: -2.686269760131836
Batch 19/64 loss: -2.7994213104248047
Batch 20/64 loss: -2.823361396789551
Batch 21/64 loss: -2.879861831665039
Batch 22/64 loss: -2.754732131958008
Batch 23/64 loss: -2.963475227355957
Batch 24/64 loss: -2.845217704772949
Batch 25/64 loss: -2.8790769577026367
Batch 26/64 loss: -2.8116540908813477
Batch 27/64 loss: -2.703981399536133
Batch 28/64 loss: -2.9433679580688477
Batch 29/64 loss: -3.052924156188965
Batch 30/64 loss: -2.2322263717651367
Batch 31/64 loss: -2.8611087799072266
Batch 32/64 loss: -2.927316665649414
Batch 33/64 loss: -2.7235355377197266
Batch 34/64 loss: -2.5186357498168945
Batch 35/64 loss: -2.828362464904785
Batch 36/64 loss: -2.988165855407715
Batch 37/64 loss: -2.8720874786376953
Batch 38/64 loss: -2.3381404876708984
Batch 39/64 loss: -2.9858226776123047
Batch 40/64 loss: -2.7687149047851562
Batch 41/64 loss: -2.8110246658325195
Batch 42/64 loss: -2.308505058288574
Batch 43/64 loss: -2.952299118041992
Batch 44/64 loss: -2.623255729675293
Batch 45/64 loss: -2.7873144149780273
Batch 46/64 loss: -2.906996726989746
Batch 47/64 loss: -2.6758642196655273
Batch 48/64 loss: -3.025022506713867
Batch 49/64 loss: -2.9718456268310547
Batch 50/64 loss: -2.982776641845703
Batch 51/64 loss: -2.7972545623779297
Batch 52/64 loss: -2.9760093688964844
Batch 53/64 loss: -2.6478805541992188
Batch 54/64 loss: -2.8934926986694336
Batch 55/64 loss: -2.8317108154296875
Batch 56/64 loss: -2.860719680786133
Batch 57/64 loss: -2.332254409790039
Batch 58/64 loss: -2.792999267578125
Batch 59/64 loss: -2.730794906616211
Batch 60/64 loss: -2.803609848022461
Batch 61/64 loss: -2.7640151977539062
Batch 62/64 loss: -2.578030586242676
Batch 63/64 loss: -2.647336006164551
Batch 64/64 loss: -7.17850923538208
Epoch 392  Train loss: -2.8443814801234826  Val loss: -3.1371176939240026
Epoch 393
-------------------------------
Batch 1/64 loss: -2.301480293273926
Batch 2/64 loss: -2.6119003295898438
Batch 3/64 loss: -2.921907424926758
Batch 4/64 loss: -2.83697509765625
Batch 5/64 loss: -2.747884750366211
Batch 6/64 loss: -2.8028831481933594
Batch 7/64 loss: -2.8234291076660156
Batch 8/64 loss: -2.9400978088378906
Batch 9/64 loss: -3.105276107788086
Batch 10/64 loss: -2.5062179565429688
Batch 11/64 loss: -2.890875816345215
Batch 12/64 loss: -2.9586477279663086
Batch 13/64 loss: -2.9912919998168945
Batch 14/64 loss: -2.7189102172851562
Batch 15/64 loss: -2.9562435150146484
Batch 16/64 loss: -2.711984634399414
Batch 17/64 loss: -2.468998908996582
Batch 18/64 loss: -2.301097869873047
Batch 19/64 loss: -2.97512149810791
Batch 20/64 loss: -3.1544923782348633
Batch 21/64 loss: -2.814329147338867
Batch 22/64 loss: -2.915464401245117
Batch 23/64 loss: -2.4160709381103516
Batch 24/64 loss: -2.736323356628418
Batch 25/64 loss: -2.923187255859375
Batch 26/64 loss: -3.130099296569824
Batch 27/64 loss: -2.2424936294555664
Batch 28/64 loss: -2.7414207458496094
Batch 29/64 loss: -2.827838897705078
Batch 30/64 loss: -2.9004669189453125
Batch 31/64 loss: -2.970078468322754
Batch 32/64 loss: -2.8899011611938477
Batch 33/64 loss: -2.955174446105957
Batch 34/64 loss: -2.8925399780273438
Batch 35/64 loss: -2.978520393371582
Batch 36/64 loss: -3.1017236709594727
Batch 37/64 loss: -2.8114376068115234
Batch 38/64 loss: -2.8955087661743164
Batch 39/64 loss: -3.1178722381591797
Batch 40/64 loss: -2.724184989929199
Batch 41/64 loss: -2.8533573150634766
Batch 42/64 loss: -2.532482147216797
Batch 43/64 loss: -2.614459991455078
Batch 44/64 loss: -2.348794937133789
Batch 45/64 loss: -2.9438533782958984
Batch 46/64 loss: -2.5803375244140625
Batch 47/64 loss: -2.970370292663574
Batch 48/64 loss: -2.5576295852661133
Batch 49/64 loss: -3.017169952392578
Batch 50/64 loss: -2.7332229614257812
Batch 51/64 loss: -2.8408422470092773
Batch 52/64 loss: -3.09860897064209
Batch 53/64 loss: -2.5810346603393555
Batch 54/64 loss: -3.027027130126953
Batch 55/64 loss: -2.6786651611328125
Batch 56/64 loss: -2.868668556213379
Batch 57/64 loss: -3.0827159881591797
Batch 58/64 loss: -2.9653892517089844
Batch 59/64 loss: -2.8161849975585938
Batch 60/64 loss: -2.915329933166504
Batch 61/64 loss: -2.9094762802124023
Batch 62/64 loss: -2.5790815353393555
Batch 63/64 loss: -3.0678014755249023
Batch 64/64 loss: -7.578627109527588
Epoch 393  Train loss: -2.870224745133344  Val loss: -3.10274973603868
Epoch 394
-------------------------------
Batch 1/64 loss: -3.040675163269043
Batch 2/64 loss: -3.093441963195801
Batch 3/64 loss: -2.842670440673828
Batch 4/64 loss: -2.774892807006836
Batch 5/64 loss: -2.6575374603271484
Batch 6/64 loss: -2.918081283569336
Batch 7/64 loss: -3.0777368545532227
Batch 8/64 loss: -2.8470468521118164
Batch 9/64 loss: -2.4876861572265625
Batch 10/64 loss: -3.0560150146484375
Batch 11/64 loss: -2.958493232727051
Batch 12/64 loss: -2.8351097106933594
Batch 13/64 loss: -2.874143600463867
Batch 14/64 loss: -3.1284656524658203
Batch 15/64 loss: -2.8788633346557617
Batch 16/64 loss: -2.8741073608398438
Batch 17/64 loss: -2.9816532135009766
Batch 18/64 loss: -2.9217424392700195
Batch 19/64 loss: -3.050503730773926
Batch 20/64 loss: -3.0187625885009766
Batch 21/64 loss: -3.0342884063720703
Batch 22/64 loss: -2.1430740356445312
Batch 23/64 loss: -2.886918067932129
Batch 24/64 loss: -2.535231590270996
Batch 25/64 loss: -2.767192840576172
Batch 26/64 loss: -2.84384822845459
Batch 27/64 loss: -2.799945831298828
Batch 28/64 loss: -2.85107421875
Batch 29/64 loss: -2.8886756896972656
Batch 30/64 loss: -3.0301103591918945
Batch 31/64 loss: -2.7949295043945312
Batch 32/64 loss: -2.7789382934570312
Batch 33/64 loss: -2.8737611770629883
Batch 34/64 loss: -2.8938350677490234
Batch 35/64 loss: -2.9919681549072266
Batch 36/64 loss: -2.5762128829956055
Batch 37/64 loss: -2.936488151550293
Batch 38/64 loss: -3.0036354064941406
Batch 39/64 loss: -3.10945987701416
Batch 40/64 loss: -2.618936538696289
Batch 41/64 loss: -2.9451780319213867
Batch 42/64 loss: -3.046566963195801
Batch 43/64 loss: -2.536083221435547
Batch 44/64 loss: -2.3866348266601562
Batch 45/64 loss: -2.6906051635742188
Batch 46/64 loss: -2.584853172302246
Batch 47/64 loss: -3.017568588256836
Batch 48/64 loss: -2.825265884399414
Batch 49/64 loss: -2.965378761291504
Batch 50/64 loss: -2.671736717224121
Batch 51/64 loss: -2.9455671310424805
Batch 52/64 loss: -2.848679542541504
Batch 53/64 loss: -2.7016897201538086
Batch 54/64 loss: -2.962338447570801
Batch 55/64 loss: -2.9689226150512695
Batch 56/64 loss: -3.047412872314453
Batch 57/64 loss: -3.121945381164551
Batch 58/64 loss: -2.6236515045166016
Batch 59/64 loss: -2.659097671508789
Batch 60/64 loss: -2.5132017135620117
Batch 61/64 loss: -2.7409486770629883
Batch 62/64 loss: -2.800400733947754
Batch 63/64 loss: -2.9747085571289062
Batch 64/64 loss: -6.701888084411621
Epoch 394  Train loss: -2.8906824336332435  Val loss: -3.1215450116449204
Epoch 395
-------------------------------
Batch 1/64 loss: -2.928330421447754
Batch 2/64 loss: -2.571742057800293
Batch 3/64 loss: -3.026852607727051
Batch 4/64 loss: -2.7869701385498047
Batch 5/64 loss: -2.695570945739746
Batch 6/64 loss: -2.681891441345215
Batch 7/64 loss: -3.0664968490600586
Batch 8/64 loss: -2.77725887298584
Batch 9/64 loss: -2.925426483154297
Batch 10/64 loss: -2.8960084915161133
Batch 11/64 loss: -2.879439353942871
Batch 12/64 loss: -2.8041934967041016
Batch 13/64 loss: -2.761782646179199
Batch 14/64 loss: -3.007822036743164
Batch 15/64 loss: -3.056180953979492
Batch 16/64 loss: -2.9676103591918945
Batch 17/64 loss: -3.0606231689453125
Batch 18/64 loss: -2.847254753112793
Batch 19/64 loss: -2.9617538452148438
Batch 20/64 loss: -2.8552465438842773
Batch 21/64 loss: -2.7928380966186523
Batch 22/64 loss: -2.9977035522460938
Batch 23/64 loss: -2.53995418548584
Batch 24/64 loss: -3.127589225769043
Batch 25/64 loss: -2.907851219177246
Batch 26/64 loss: -3.0196657180786133
Batch 27/64 loss: -2.9668283462524414
Batch 28/64 loss: -2.7337169647216797
Batch 29/64 loss: -2.905919075012207
Batch 30/64 loss: -3.0044021606445312
Batch 31/64 loss: -2.888427734375
Batch 32/64 loss: -2.7598114013671875
Batch 33/64 loss: -3.001668930053711
Batch 34/64 loss: -2.1894712448120117
Batch 35/64 loss: -2.786757469177246
Batch 36/64 loss: -2.904430389404297
Batch 37/64 loss: -2.81046199798584
Batch 38/64 loss: -2.4074058532714844
Batch 39/64 loss: -2.9000024795532227
Batch 40/64 loss: -2.870528221130371
Batch 41/64 loss: -2.8366432189941406
Batch 42/64 loss: -2.9886550903320312
Batch 43/64 loss: -2.931041717529297
Batch 44/64 loss: -2.8293447494506836
Batch 45/64 loss: -2.9039735794067383
Batch 46/64 loss: -2.83062744140625
Batch 47/64 loss: -2.8210973739624023
Batch 48/64 loss: -2.931239128112793
Batch 49/64 loss: -2.7902307510375977
Batch 50/64 loss: -2.786757469177246
Batch 51/64 loss: -2.5080604553222656
Batch 52/64 loss: -2.9321184158325195
Batch 53/64 loss: -2.883138656616211
Batch 54/64 loss: -3.1021289825439453
Batch 55/64 loss: -2.210873603820801
Batch 56/64 loss: -3.0467348098754883
Batch 57/64 loss: -2.8502893447875977
Batch 58/64 loss: -2.8533239364624023
Batch 59/64 loss: -2.7789392471313477
Batch 60/64 loss: -2.96144962310791
Batch 61/64 loss: -2.9767255783081055
Batch 62/64 loss: -2.8619136810302734
Batch 63/64 loss: -2.7997913360595703
Batch 64/64 loss: -7.615509986877441
Epoch 395  Train loss: -2.905107771181593  Val loss: -3.1444438134681727
Epoch 396
-------------------------------
Batch 1/64 loss: -3.0120630264282227
Batch 2/64 loss: -3.131450653076172
Batch 3/64 loss: -3.065357208251953
Batch 4/64 loss: -2.9434871673583984
Batch 5/64 loss: -3.0723772048950195
Batch 6/64 loss: -2.70943546295166
Batch 7/64 loss: -2.325627326965332
Batch 8/64 loss: -2.564324378967285
Batch 9/64 loss: -2.782421112060547
Batch 10/64 loss: -2.205336570739746
Batch 11/64 loss: -3.076204299926758
Batch 12/64 loss: -2.990184783935547
Batch 13/64 loss: -3.104513168334961
Batch 14/64 loss: -2.9854907989501953
Batch 15/64 loss: -3.043156623840332
Batch 16/64 loss: -2.7096662521362305
Batch 17/64 loss: -2.9538707733154297
Batch 18/64 loss: -2.7029972076416016
Batch 19/64 loss: -2.8965072631835938
Batch 20/64 loss: -2.8774375915527344
Batch 21/64 loss: -2.9964075088500977
Batch 22/64 loss: -3.042910575866699
Batch 23/64 loss: -2.9104080200195312
Batch 24/64 loss: -2.9965410232543945
Batch 25/64 loss: -2.7613954544067383
Batch 26/64 loss: -2.9013938903808594
Batch 27/64 loss: -3.1377925872802734
Batch 28/64 loss: -2.735306739807129
Batch 29/64 loss: -3.11557674407959
Batch 30/64 loss: -2.9068384170532227
Batch 31/64 loss: -2.9032058715820312
Batch 32/64 loss: -3.088433265686035
Batch 33/64 loss: -2.675161361694336
Batch 34/64 loss: -2.961611747741699
Batch 35/64 loss: -3.1195907592773438
Batch 36/64 loss: -3.084644317626953
Batch 37/64 loss: -2.9784154891967773
Batch 38/64 loss: -2.9874467849731445
Batch 39/64 loss: -2.800973892211914
Batch 40/64 loss: -2.645024299621582
Batch 41/64 loss: -3.133504867553711
Batch 42/64 loss: -2.8878726959228516
Batch 43/64 loss: -2.860297203063965
Batch 44/64 loss: -2.864691734313965
Batch 45/64 loss: -2.967630386352539
Batch 46/64 loss: -3.0643606185913086
Batch 47/64 loss: -3.0766963958740234
Batch 48/64 loss: -3.039891242980957
Batch 49/64 loss: -3.004549026489258
Batch 50/64 loss: -2.5827836990356445
Batch 51/64 loss: -2.8300065994262695
Batch 52/64 loss: -3.0298471450805664
Batch 53/64 loss: -2.8519439697265625
Batch 54/64 loss: -3.005803108215332
Batch 55/64 loss: -2.7697324752807617
Batch 56/64 loss: -2.896932601928711
Batch 57/64 loss: -2.9207096099853516
Batch 58/64 loss: -2.926481246948242
Batch 59/64 loss: -2.888814926147461
Batch 60/64 loss: -3.0614585876464844
Batch 61/64 loss: -2.1773157119750977
Batch 62/64 loss: -2.9430112838745117
Batch 63/64 loss: -2.6076107025146484
Batch 64/64 loss: -7.636997699737549
Epoch 396  Train loss: -2.9493440272761324  Val loss: -3.2426322071822646
Epoch 397
-------------------------------
Batch 1/64 loss: -2.8201284408569336
Batch 2/64 loss: -3.137486457824707
Batch 3/64 loss: -2.814976692199707
Batch 4/64 loss: -2.5806312561035156
Batch 5/64 loss: -3.055368423461914
Batch 6/64 loss: -2.635112762451172
Batch 7/64 loss: -2.953789710998535
Batch 8/64 loss: -2.805394172668457
Batch 9/64 loss: -3.090151786804199
Batch 10/64 loss: -2.9729862213134766
Batch 11/64 loss: -2.968480110168457
Batch 12/64 loss: -3.0755796432495117
Batch 13/64 loss: -2.440138816833496
Batch 14/64 loss: -3.013340950012207
Batch 15/64 loss: -2.892946243286133
Batch 16/64 loss: -3.0334672927856445
Batch 17/64 loss: -2.9987125396728516
Batch 18/64 loss: -2.9305601119995117
Batch 19/64 loss: -3.0412845611572266
Batch 20/64 loss: -3.1124649047851562
Batch 21/64 loss: -3.0345754623413086
Batch 22/64 loss: -2.2849693298339844
Batch 23/64 loss: -3.155759811401367
Batch 24/64 loss: -2.902923583984375
Batch 25/64 loss: -2.7174549102783203
Batch 26/64 loss: -2.7755212783813477
Batch 27/64 loss: -2.9491395950317383
Batch 28/64 loss: -3.056107521057129
Batch 29/64 loss: -2.6371517181396484
Batch 30/64 loss: -2.817652702331543
Batch 31/64 loss: -2.9052820205688477
Batch 32/64 loss: -2.8462085723876953
Batch 33/64 loss: -2.6797380447387695
Batch 34/64 loss: -2.7741775512695312
Batch 35/64 loss: -2.9343833923339844
Batch 36/64 loss: -2.8274383544921875
Batch 37/64 loss: -2.885173797607422
Batch 38/64 loss: -2.937930107116699
Batch 39/64 loss: -2.8190298080444336
Batch 40/64 loss: -2.980518341064453
Batch 41/64 loss: -3.012815475463867
Batch 42/64 loss: -3.088437080383301
Batch 43/64 loss: -3.08431339263916
Batch 44/64 loss: -2.5241003036499023
Batch 45/64 loss: -3.1132984161376953
Batch 46/64 loss: -2.6531105041503906
Batch 47/64 loss: -2.7041702270507812
Batch 48/64 loss: -2.8189573287963867
Batch 49/64 loss: -2.9998064041137695
Batch 50/64 loss: -2.9151268005371094
Batch 51/64 loss: -3.205634117126465
Batch 52/64 loss: -3.127242088317871
Batch 53/64 loss: -3.0859670639038086
Batch 54/64 loss: -3.044179916381836
Batch 55/64 loss: -2.8330821990966797
Batch 56/64 loss: -3.0800962448120117
Batch 57/64 loss: -2.7813024520874023
Batch 58/64 loss: -2.6931285858154297
Batch 59/64 loss: -2.732987403869629
Batch 60/64 loss: -2.470335006713867
Batch 61/64 loss: -3.057384490966797
Batch 62/64 loss: -3.1612062454223633
Batch 63/64 loss: -2.6884870529174805
Batch 64/64 loss: -7.620158672332764
Epoch 397  Train loss: -2.9472066636179006  Val loss: -3.2028601734908584
Epoch 398
-------------------------------
Batch 1/64 loss: -3.1110057830810547
Batch 2/64 loss: -2.930936813354492
Batch 3/64 loss: -3.121774673461914
Batch 4/64 loss: -3.096424102783203
Batch 5/64 loss: -3.1542301177978516
Batch 6/64 loss: -2.6832685470581055
Batch 7/64 loss: -2.9683141708374023
Batch 8/64 loss: -2.944096565246582
Batch 9/64 loss: -2.882603645324707
Batch 10/64 loss: -3.0006675720214844
Batch 11/64 loss: -3.0104055404663086
Batch 12/64 loss: -3.104811668395996
Batch 13/64 loss: -2.9700727462768555
Batch 14/64 loss: -2.9832944869995117
Batch 15/64 loss: -2.3861093521118164
Batch 16/64 loss: -2.9232187271118164
Batch 17/64 loss: -2.765056610107422
Batch 18/64 loss: -3.024491310119629
Batch 19/64 loss: -3.0822248458862305
Batch 20/64 loss: -2.9977970123291016
Batch 21/64 loss: -2.947382926940918
Batch 22/64 loss: -2.204470634460449
Batch 23/64 loss: -3.0206212997436523
Batch 24/64 loss: -3.06784725189209
Batch 25/64 loss: -2.890620231628418
Batch 26/64 loss: -2.854763984680176
Batch 27/64 loss: -2.9384422302246094
Batch 28/64 loss: -2.924612045288086
Batch 29/64 loss: -2.5843992233276367
Batch 30/64 loss: -2.972270965576172
Batch 31/64 loss: -3.068347930908203
Batch 32/64 loss: -3.0506467819213867
Batch 33/64 loss: -3.004368782043457
Batch 34/64 loss: -2.2388534545898438
Batch 35/64 loss: -2.9875917434692383
Batch 36/64 loss: -2.9215354919433594
Batch 37/64 loss: -2.7849512100219727
Batch 38/64 loss: -3.014641761779785
Batch 39/64 loss: -2.6531686782836914
Batch 40/64 loss: -2.7557382583618164
Batch 41/64 loss: -3.066722869873047
Batch 42/64 loss: -3.0915279388427734
Batch 43/64 loss: -2.981779098510742
Batch 44/64 loss: -3.080233573913574
Batch 45/64 loss: -2.624953269958496
Batch 46/64 loss: -2.836899757385254
Batch 47/64 loss: -3.0885095596313477
Batch 48/64 loss: -2.9579591751098633
Batch 49/64 loss: -3.044253349304199
Batch 50/64 loss: -2.7766075134277344
Batch 51/64 loss: -2.7401580810546875
Batch 52/64 loss: -2.990004539489746
Batch 53/64 loss: -2.3608312606811523
Batch 54/64 loss: -2.904926300048828
Batch 55/64 loss: -3.1222543716430664
Batch 56/64 loss: -2.772663116455078
Batch 57/64 loss: -3.1147327423095703
Batch 58/64 loss: -3.223295211791992
Batch 59/64 loss: -2.8418331146240234
Batch 60/64 loss: -3.014765739440918
Batch 61/64 loss: -2.77163028717041
Batch 62/64 loss: -3.063601493835449
Batch 63/64 loss: -3.004690170288086
Batch 64/64 loss: -7.417483329772949
Epoch 398  Train loss: -2.9657101836859012  Val loss: -3.2951322732512485
Saving best model, epoch: 398
Epoch 399
-------------------------------
Batch 1/64 loss: -2.3441314697265625
Batch 2/64 loss: -2.6346359252929688
Batch 3/64 loss: -3.205625534057617
Batch 4/64 loss: -2.87894344329834
Batch 5/64 loss: -2.792491912841797
Batch 6/64 loss: -2.941769599914551
Batch 7/64 loss: -2.9756994247436523
Batch 8/64 loss: -3.0697460174560547
Batch 9/64 loss: -3.0145788192749023
Batch 10/64 loss: -2.982889175415039
Batch 11/64 loss: -2.7592220306396484
Batch 12/64 loss: -3.0087671279907227
Batch 13/64 loss: -2.908548355102539
Batch 14/64 loss: -3.0729970932006836
Batch 15/64 loss: -2.727354049682617
Batch 16/64 loss: -3.0216026306152344
Batch 17/64 loss: -2.9752941131591797
Batch 18/64 loss: -3.055191993713379
Batch 19/64 loss: -2.6032838821411133
Batch 20/64 loss: -3.045626640319824
Batch 21/64 loss: -2.1517181396484375
Batch 22/64 loss: -3.040925979614258
Batch 23/64 loss: -3.0438575744628906
Batch 24/64 loss: -2.876943588256836
Batch 25/64 loss: -2.9953060150146484
Batch 26/64 loss: -3.2215003967285156
Batch 27/64 loss: -3.0946149826049805
Batch 28/64 loss: -2.926447868347168
Batch 29/64 loss: -3.0540761947631836
Batch 30/64 loss: -3.0245866775512695
Batch 31/64 loss: -3.11226749420166
Batch 32/64 loss: -2.9454450607299805
Batch 33/64 loss: -2.7257156372070312
Batch 34/64 loss: -3.1670589447021484
Batch 35/64 loss: -3.038210868835449
Batch 36/64 loss: -2.976581573486328
Batch 37/64 loss: -3.020216941833496
Batch 38/64 loss: -3.0239810943603516
Batch 39/64 loss: -3.125446319580078
Batch 40/64 loss: -3.0244569778442383
Batch 41/64 loss: -2.885812759399414
Batch 42/64 loss: -2.6355409622192383
Batch 43/64 loss: -2.845510482788086
Batch 44/64 loss: -2.9528627395629883
Batch 45/64 loss: -2.9604415893554688
Batch 46/64 loss: -2.5093870162963867
Batch 47/64 loss: -3.132997512817383
Batch 48/64 loss: -2.7783870697021484
Batch 49/64 loss: -3.1159095764160156
Batch 50/64 loss: -3.157266616821289
Batch 51/64 loss: -2.942850112915039
Batch 52/64 loss: -3.1482086181640625
Batch 53/64 loss: -2.7793121337890625
Batch 54/64 loss: -2.953362464904785
Batch 55/64 loss: -2.8962602615356445
Batch 56/64 loss: -3.0872116088867188
Batch 57/64 loss: -3.118541717529297
Batch 58/64 loss: -2.8702049255371094
Batch 59/64 loss: -3.084636688232422
Batch 60/64 loss: -2.794375419616699
Batch 61/64 loss: -3.013195037841797
Batch 62/64 loss: -3.0287628173828125
Batch 63/64 loss: -3.073244094848633
Batch 64/64 loss: -7.542864799499512
Epoch 399  Train loss: -2.9965362885419062  Val loss: -3.2601848877582356
Epoch 400
-------------------------------
Batch 1/64 loss: -2.9081315994262695
Batch 2/64 loss: -3.1530189514160156
Batch 3/64 loss: -2.497182846069336
Batch 4/64 loss: -2.8939828872680664
Batch 5/64 loss: -2.825650215148926
Batch 6/64 loss: -2.877861976623535
Batch 7/64 loss: -3.04654598236084
Batch 8/64 loss: -2.687715530395508
Batch 9/64 loss: -2.9810190200805664
Batch 10/64 loss: -2.949946403503418
Batch 11/64 loss: -3.1434030532836914
Batch 12/64 loss: -3.109677314758301
Batch 13/64 loss: -3.0239744186401367
Batch 14/64 loss: -3.03826904296875
Batch 15/64 loss: -2.835017204284668
Batch 16/64 loss: -2.6746788024902344
Batch 17/64 loss: -2.3159799575805664
Batch 18/64 loss: -3.14212703704834
Batch 19/64 loss: -3.018425941467285
Batch 20/64 loss: -3.021897315979004
Batch 21/64 loss: -2.8399534225463867
Batch 22/64 loss: -3.1267881393432617
Batch 23/64 loss: -2.9944705963134766
Batch 24/64 loss: -2.961374282836914
Batch 25/64 loss: -2.7758665084838867
Batch 26/64 loss: -2.8866119384765625
Batch 27/64 loss: -2.419619560241699
Batch 28/64 loss: -2.9102935791015625
Batch 29/64 loss: -2.7737865447998047
Batch 30/64 loss: -3.0657224655151367
Batch 31/64 loss: -2.967092514038086
Batch 32/64 loss: -3.1656408309936523
Batch 33/64 loss: -3.093377113342285
Batch 34/64 loss: -3.231912612915039
Batch 35/64 loss: -3.0069103240966797
Batch 36/64 loss: -2.8811044692993164
Batch 37/64 loss: -2.7945098876953125
Batch 38/64 loss: -2.876309394836426
Batch 39/64 loss: -2.998445510864258
Batch 40/64 loss: -2.94553279876709
Batch 41/64 loss: -2.872058868408203
Batch 42/64 loss: -2.8093013763427734
Batch 43/64 loss: -2.905449867248535
Batch 44/64 loss: -2.23284912109375
Batch 45/64 loss: -2.9611387252807617
Batch 46/64 loss: -2.896505355834961
Batch 47/64 loss: -3.15012264251709
Batch 48/64 loss: -3.2288990020751953
Batch 49/64 loss: -2.897038459777832
Batch 50/64 loss: -2.7309837341308594
Batch 51/64 loss: -3.1181230545043945
Batch 52/64 loss: -3.081456184387207
Batch 53/64 loss: -3.1588354110717773
Batch 54/64 loss: -2.989455223083496
Batch 55/64 loss: -2.9364547729492188
Batch 56/64 loss: -3.0435791015625
Batch 57/64 loss: -2.920931816101074
Batch 58/64 loss: -2.9647903442382812
Batch 59/64 loss: -2.9897518157958984
Batch 60/64 loss: -2.968010902404785
Batch 61/64 loss: -2.9404706954956055
Batch 62/64 loss: -2.837005615234375
Batch 63/64 loss: -2.754180908203125
Batch 64/64 loss: -7.651215553283691
Epoch 400  Train loss: -2.9801667867922315  Val loss: -3.219841488448205
Epoch 401
-------------------------------
Batch 1/64 loss: -2.874129295349121
Batch 2/64 loss: -2.931671142578125
Batch 3/64 loss: -3.05715274810791
Batch 4/64 loss: -2.996746063232422
Batch 5/64 loss: -3.1738176345825195
Batch 6/64 loss: -3.102754592895508
Batch 7/64 loss: -3.0844898223876953
Batch 8/64 loss: -3.1114768981933594
Batch 9/64 loss: -2.7507686614990234
Batch 10/64 loss: -2.7145395278930664
Batch 11/64 loss: -2.9953689575195312
Batch 12/64 loss: -2.996034622192383
Batch 13/64 loss: -2.882570266723633
Batch 14/64 loss: -3.009340286254883
Batch 15/64 loss: -3.074939727783203
Batch 16/64 loss: -2.7495603561401367
Batch 17/64 loss: -3.1425046920776367
Batch 18/64 loss: -2.895069122314453
Batch 19/64 loss: -2.591557502746582
Batch 20/64 loss: -2.5122079849243164
Batch 21/64 loss: -3.1125564575195312
Batch 22/64 loss: -2.899404525756836
Batch 23/64 loss: -2.873044013977051
Batch 24/64 loss: -2.6211977005004883
Batch 25/64 loss: -2.404543876647949
Batch 26/64 loss: -2.9348573684692383
Batch 27/64 loss: -2.8884315490722656
Batch 28/64 loss: -2.991556167602539
Batch 29/64 loss: -2.8310546875
Batch 30/64 loss: -2.918553352355957
Batch 31/64 loss: -2.9257612228393555
Batch 32/64 loss: -2.9357147216796875
Batch 33/64 loss: -3.1383590698242188
Batch 34/64 loss: -2.762237548828125
Batch 35/64 loss: -2.908102035522461
Batch 36/64 loss: -2.7735776901245117
Batch 37/64 loss: -2.879794120788574
Batch 38/64 loss: -3.076176643371582
Batch 39/64 loss: -2.074591636657715
Batch 40/64 loss: -2.9853429794311523
Batch 41/64 loss: -2.894383430480957
Batch 42/64 loss: -2.879349708557129
Batch 43/64 loss: -3.2165603637695312
Batch 44/64 loss: -2.7269363403320312
Batch 45/64 loss: -2.8582353591918945
Batch 46/64 loss: -3.269826889038086
Batch 47/64 loss: -3.138753890991211
Batch 48/64 loss: -2.869579315185547
Batch 49/64 loss: -2.964519500732422
Batch 50/64 loss: -3.1119136810302734
Batch 51/64 loss: -3.030207633972168
Batch 52/64 loss: -2.8395862579345703
Batch 53/64 loss: -2.7138757705688477
Batch 54/64 loss: -2.8573503494262695
Batch 55/64 loss: -2.8738574981689453
Batch 56/64 loss: -3.0997047424316406
Batch 57/64 loss: -3.183016777038574
Batch 58/64 loss: -3.0458927154541016
Batch 59/64 loss: -2.9957590103149414
Batch 60/64 loss: -3.0774221420288086
Batch 61/64 loss: -2.992216110229492
Batch 62/64 loss: -2.555678367614746
Batch 63/64 loss: -2.9952993392944336
Batch 64/64 loss: -7.543936729431152
Epoch 401  Train loss: -2.971442117878035  Val loss: -3.27555564015182
Epoch 402
-------------------------------
Batch 1/64 loss: -2.9666852951049805
Batch 2/64 loss: -2.9029178619384766
Batch 3/64 loss: -2.694520950317383
Batch 4/64 loss: -2.961441993713379
Batch 5/64 loss: -2.9793434143066406
Batch 6/64 loss: -3.0376052856445312
Batch 7/64 loss: -3.1211633682250977
Batch 8/64 loss: -2.886807441711426
Batch 9/64 loss: -2.7896175384521484
Batch 10/64 loss: -3.0044689178466797
Batch 11/64 loss: -2.8800230026245117
Batch 12/64 loss: -2.8851242065429688
Batch 13/64 loss: -2.4933719635009766
Batch 14/64 loss: -3.121342658996582
Batch 15/64 loss: -2.889863967895508
Batch 16/64 loss: -2.959475517272949
Batch 17/64 loss: -3.1772851943969727
Batch 18/64 loss: -2.755983352661133
Batch 19/64 loss: -2.918487548828125
Batch 20/64 loss: -2.871978759765625
Batch 21/64 loss: -2.5111474990844727
Batch 22/64 loss: -3.099628448486328
Batch 23/64 loss: -3.0201845169067383
Batch 24/64 loss: -3.1299686431884766
Batch 25/64 loss: -2.9930171966552734
Batch 26/64 loss: -2.88720703125
Batch 27/64 loss: -2.8041820526123047
Batch 28/64 loss: -3.0702571868896484
Batch 29/64 loss: -2.8245534896850586
Batch 30/64 loss: -3.142592430114746
Batch 31/64 loss: -2.372340202331543
Batch 32/64 loss: -3.0208816528320312
Batch 33/64 loss: -3.051361083984375
Batch 34/64 loss: -2.9081554412841797
Batch 35/64 loss: -3.130950927734375
Batch 36/64 loss: -2.2889928817749023
Batch 37/64 loss: -3.0390491485595703
Batch 38/64 loss: -2.948420524597168
Batch 39/64 loss: -3.0097198486328125
Batch 40/64 loss: -2.9071006774902344
Batch 41/64 loss: -2.8359928131103516
Batch 42/64 loss: -2.595414161682129
Batch 43/64 loss: -3.103938102722168
Batch 44/64 loss: -3.214066505432129
Batch 45/64 loss: -2.5073556900024414
Batch 46/64 loss: -2.8148860931396484
Batch 47/64 loss: -3.125324249267578
Batch 48/64 loss: -3.008761405944824
Batch 49/64 loss: -3.0036697387695312
Batch 50/64 loss: -2.7448196411132812
Batch 51/64 loss: -2.9359073638916016
Batch 52/64 loss: -2.6909008026123047
Batch 53/64 loss: -2.9544267654418945
Batch 54/64 loss: -3.0589828491210938
Batch 55/64 loss: -2.8431148529052734
Batch 56/64 loss: -2.2412595748901367
Batch 57/64 loss: -2.644322395324707
Batch 58/64 loss: -2.775602340698242
Batch 59/64 loss: -2.932784080505371
Batch 60/64 loss: -3.0614147186279297
Batch 61/64 loss: -3.1456375122070312
Batch 62/64 loss: -2.9688549041748047
Batch 63/64 loss: -2.956801414489746
Batch 64/64 loss: -7.433140754699707
Epoch 402  Train loss: -2.952099022210813  Val loss: -3.1527238301804794
Epoch 403
-------------------------------
Batch 1/64 loss: -2.941671371459961
Batch 2/64 loss: -2.741853713989258
Batch 3/64 loss: -2.984133720397949
Batch 4/64 loss: -3.090426445007324
Batch 5/64 loss: -3.0583133697509766
Batch 6/64 loss: -3.0152664184570312
Batch 7/64 loss: -3.0726499557495117
Batch 8/64 loss: -2.9637937545776367
Batch 9/64 loss: -3.0426387786865234
Batch 10/64 loss: -2.752120018005371
Batch 11/64 loss: -2.79150390625
Batch 12/64 loss: -3.015862464904785
Batch 13/64 loss: -3.016413688659668
Batch 14/64 loss: -2.921109199523926
Batch 15/64 loss: -2.971676826477051
Batch 16/64 loss: -3.106400489807129
Batch 17/64 loss: -2.939382553100586
Batch 18/64 loss: -2.9058971405029297
Batch 19/64 loss: -3.1114683151245117
Batch 20/64 loss: -2.645883560180664
Batch 21/64 loss: -3.0232315063476562
Batch 22/64 loss: -3.0421648025512695
Batch 23/64 loss: -3.03494930267334
Batch 24/64 loss: -2.633758544921875
Batch 25/64 loss: -2.734424591064453
Batch 26/64 loss: -2.956915855407715
Batch 27/64 loss: -2.2753915786743164
Batch 28/64 loss: -2.887465476989746
Batch 29/64 loss: -3.1053571701049805
Batch 30/64 loss: -3.056607246398926
Batch 31/64 loss: -2.975828170776367
Batch 32/64 loss: -3.0200061798095703
Batch 33/64 loss: -2.840587615966797
Batch 34/64 loss: -2.927802085876465
Batch 35/64 loss: -3.0925493240356445
Batch 36/64 loss: -3.048248291015625
Batch 37/64 loss: -3.193221092224121
Batch 38/64 loss: -2.954587936401367
Batch 39/64 loss: -2.533785820007324
Batch 40/64 loss: -2.6360435485839844
Batch 41/64 loss: -2.8888235092163086
Batch 42/64 loss: -2.820929527282715
Batch 43/64 loss: -3.105072021484375
Batch 44/64 loss: -2.5596132278442383
Batch 45/64 loss: -2.841928482055664
Batch 46/64 loss: -3.046177864074707
Batch 47/64 loss: -2.5982189178466797
Batch 48/64 loss: -2.7383546829223633
Batch 49/64 loss: -2.5937414169311523
Batch 50/64 loss: -3.1002817153930664
Batch 51/64 loss: -3.0371665954589844
Batch 52/64 loss: -2.439004898071289
Batch 53/64 loss: -3.068131446838379
Batch 54/64 loss: -2.8350019454956055
Batch 55/64 loss: -2.860595703125
Batch 56/64 loss: -3.080233573913574
Batch 57/64 loss: -3.1055469512939453
Batch 58/64 loss: -2.944767951965332
Batch 59/64 loss: -2.7039880752563477
Batch 60/64 loss: -3.1591854095458984
Batch 61/64 loss: -2.994542121887207
Batch 62/64 loss: -2.9758262634277344
Batch 63/64 loss: -3.009720802307129
Batch 64/64 loss: -7.5260114669799805
Epoch 403  Train loss: -2.968043192695169  Val loss: -3.2200286576838018
Epoch 404
-------------------------------
Batch 1/64 loss: -2.703444480895996
Batch 2/64 loss: -2.7474365234375
Batch 3/64 loss: -2.8137474060058594
Batch 4/64 loss: -3.0260162353515625
Batch 5/64 loss: -3.0528488159179688
Batch 6/64 loss: -2.847370147705078
Batch 7/64 loss: -2.607583999633789
Batch 8/64 loss: -3.03603458404541
Batch 9/64 loss: -3.0481624603271484
Batch 10/64 loss: -2.922572135925293
Batch 11/64 loss: -3.1812047958374023
Batch 12/64 loss: -3.0520238876342773
Batch 13/64 loss: -3.040776252746582
Batch 14/64 loss: -2.7792673110961914
Batch 15/64 loss: -3.0398216247558594
Batch 16/64 loss: -2.995244026184082
Batch 17/64 loss: -2.7834529876708984
Batch 18/64 loss: -3.114603042602539
Batch 19/64 loss: -3.0951690673828125
Batch 20/64 loss: -3.094623565673828
Batch 21/64 loss: -3.103978157043457
Batch 22/64 loss: -2.9629669189453125
Batch 23/64 loss: -3.1958703994750977
Batch 24/64 loss: -3.125239372253418
Batch 25/64 loss: -3.0860328674316406
Batch 26/64 loss: -3.1840906143188477
Batch 27/64 loss: -3.0881853103637695
Batch 28/64 loss: -2.915586471557617
Batch 29/64 loss: -2.9896011352539062
Batch 30/64 loss: -3.1720991134643555
Batch 31/64 loss: -2.0716991424560547
Batch 32/64 loss: -2.985727310180664
Batch 33/64 loss: -3.0761795043945312
Batch 34/64 loss: -3.126096725463867
Batch 35/64 loss: -2.922776222229004
Batch 36/64 loss: -3.088512420654297
Batch 37/64 loss: -2.990102767944336
Batch 38/64 loss: -3.025297164916992
Batch 39/64 loss: -2.818854331970215
Batch 40/64 loss: -2.8376235961914062
Batch 41/64 loss: -2.9515180587768555
Batch 42/64 loss: -2.126633644104004
Batch 43/64 loss: -2.938169479370117
Batch 44/64 loss: -3.1261796951293945
Batch 45/64 loss: -3.0077619552612305
Batch 46/64 loss: -2.9551467895507812
Batch 47/64 loss: -2.9654102325439453
Batch 48/64 loss: -2.9148406982421875
Batch 49/64 loss: -2.9938488006591797
Batch 50/64 loss: -3.1448745727539062
Batch 51/64 loss: -2.594742774963379
Batch 52/64 loss: -2.856700897216797
Batch 53/64 loss: -3.081301689147949
Batch 54/64 loss: -2.938385009765625
Batch 55/64 loss: -3.0825185775756836
Batch 56/64 loss: -3.1169004440307617
Batch 57/64 loss: -2.897428512573242
Batch 58/64 loss: -2.870450019836426
Batch 59/64 loss: -3.0190887451171875
Batch 60/64 loss: -3.0751733779907227
Batch 61/64 loss: -3.073369026184082
Batch 62/64 loss: -2.913783073425293
Batch 63/64 loss: -2.772581100463867
Batch 64/64 loss: -7.538002967834473
Epoch 404  Train loss: -3.0089134478101545  Val loss: -3.212592344513464
Epoch 405
-------------------------------
Batch 1/64 loss: -3.0025196075439453
Batch 2/64 loss: -2.7437267303466797
Batch 3/64 loss: -2.8870115280151367
Batch 4/64 loss: -3.0852718353271484
Batch 5/64 loss: -2.937906265258789
Batch 6/64 loss: -2.953500747680664
Batch 7/64 loss: -3.119694709777832
Batch 8/64 loss: -2.6656713485717773
Batch 9/64 loss: -3.1310644149780273
Batch 10/64 loss: -2.6943931579589844
Batch 11/64 loss: -2.7533035278320312
Batch 12/64 loss: -2.9861297607421875
Batch 13/64 loss: -2.8343591690063477
Batch 14/64 loss: -2.7362442016601562
Batch 15/64 loss: -2.9683895111083984
Batch 16/64 loss: -2.5579404830932617
Batch 17/64 loss: -3.0898752212524414
Batch 18/64 loss: -2.7564048767089844
Batch 19/64 loss: -2.8744630813598633
Batch 20/64 loss: -2.8839406967163086
Batch 21/64 loss: -2.915982246398926
Batch 22/64 loss: -3.02590274810791
Batch 23/64 loss: -2.8517818450927734
Batch 24/64 loss: -2.933962821960449
Batch 25/64 loss: -3.147332191467285
Batch 26/64 loss: -2.3935861587524414
Batch 27/64 loss: -2.994656562805176
Batch 28/64 loss: -2.8482656478881836
Batch 29/64 loss: -2.9743738174438477
Batch 30/64 loss: -2.8549413681030273
Batch 31/64 loss: -2.947542190551758
Batch 32/64 loss: -3.011763572692871
Batch 33/64 loss: -2.983552932739258
Batch 34/64 loss: -2.596430778503418
Batch 35/64 loss: -2.788890838623047
Batch 36/64 loss: -2.978224754333496
Batch 37/64 loss: -2.865591049194336
Batch 38/64 loss: -2.8573055267333984
Batch 39/64 loss: -2.962649345397949
Batch 40/64 loss: -2.890615463256836
Batch 41/64 loss: -2.945704460144043
Batch 42/64 loss: -2.9839859008789062
Batch 43/64 loss: -2.9608049392700195
Batch 44/64 loss: -2.982837677001953
Batch 45/64 loss: -2.500284194946289
Batch 46/64 loss: -2.636444091796875
Batch 47/64 loss: -2.8911447525024414
Batch 48/64 loss: -3.011798858642578
Batch 49/64 loss: -3.139596939086914
Batch 50/64 loss: -2.8795223236083984
Batch 51/64 loss: -2.9055252075195312
Batch 52/64 loss: -2.3755645751953125
Batch 53/64 loss: -3.0555639266967773
Batch 54/64 loss: -2.763082504272461
Batch 55/64 loss: -2.5334644317626953
Batch 56/64 loss: -2.725043296813965
Batch 57/64 loss: -3.0103368759155273
Batch 58/64 loss: -3.0985822677612305
Batch 59/64 loss: -2.874478340148926
Batch 60/64 loss: -3.122772216796875
Batch 61/64 loss: -2.83731746673584
Batch 62/64 loss: -2.4841976165771484
Batch 63/64 loss: -2.8767032623291016
Batch 64/64 loss: -7.459759712219238
Epoch 405  Train loss: -2.9282311944400563  Val loss: -3.274583744429231
Epoch 406
-------------------------------
Batch 1/64 loss: -3.078423500061035
Batch 2/64 loss: -2.7964868545532227
Batch 3/64 loss: -3.0526609420776367
Batch 4/64 loss: -2.823428153991699
Batch 5/64 loss: -2.6935205459594727
Batch 6/64 loss: -2.9886999130249023
Batch 7/64 loss: -3.0216121673583984
Batch 8/64 loss: -2.8034744262695312
Batch 9/64 loss: -3.078561782836914
Batch 10/64 loss: -2.932063102722168
Batch 11/64 loss: -2.3512725830078125
Batch 12/64 loss: -3.0347280502319336
Batch 13/64 loss: -2.992979049682617
Batch 14/64 loss: -2.9392967224121094
Batch 15/64 loss: -3.0526723861694336
Batch 16/64 loss: -2.6465396881103516
Batch 17/64 loss: -2.843761444091797
Batch 18/64 loss: -3.125600814819336
Batch 19/64 loss: -2.756657600402832
Batch 20/64 loss: -2.9226083755493164
Batch 21/64 loss: -2.583902359008789
Batch 22/64 loss: -3.040040969848633
Batch 23/64 loss: -2.836292266845703
Batch 24/64 loss: -2.8623266220092773
Batch 25/64 loss: -2.9471397399902344
Batch 26/64 loss: -2.712174415588379
Batch 27/64 loss: -2.9913253784179688
Batch 28/64 loss: -2.958989143371582
Batch 29/64 loss: -2.9531822204589844
Batch 30/64 loss: -2.9684486389160156
Batch 31/64 loss: -2.8904037475585938
Batch 32/64 loss: -3.0763025283813477
Batch 33/64 loss: -2.8644227981567383
Batch 34/64 loss: -2.780989646911621
Batch 35/64 loss: -2.118593215942383
Batch 36/64 loss: -2.1165122985839844
Batch 37/64 loss: -2.62131404876709
Batch 38/64 loss: -2.678112030029297
Batch 39/64 loss: -2.836244583129883
Batch 40/64 loss: -3.010906219482422
Batch 41/64 loss: -2.588446617126465
Batch 42/64 loss: -2.984524726867676
Batch 43/64 loss: -2.9776248931884766
Batch 44/64 loss: -2.9886913299560547
Batch 45/64 loss: -2.9920101165771484
Batch 46/64 loss: -2.837832450866699
Batch 47/64 loss: -2.971074104309082
Batch 48/64 loss: -2.3191890716552734
Batch 49/64 loss: -2.9597930908203125
Batch 50/64 loss: -2.919078826904297
Batch 51/64 loss: -2.7556915283203125
Batch 52/64 loss: -2.686859130859375
Batch 53/64 loss: -3.043855667114258
Batch 54/64 loss: -2.96041202545166
Batch 55/64 loss: -2.8257951736450195
Batch 56/64 loss: -3.0544919967651367
Batch 57/64 loss: -2.9650659561157227
Batch 58/64 loss: -2.679654121398926
Batch 59/64 loss: -2.9684677124023438
Batch 60/64 loss: -2.5728979110717773
Batch 61/64 loss: -2.851806640625
Batch 62/64 loss: -2.5127429962158203
Batch 63/64 loss: -3.0096874237060547
Batch 64/64 loss: -7.3001933097839355
Epoch 406  Train loss: -2.8969962269652125  Val loss: -3.1224737003496834
Epoch 407
-------------------------------
Batch 1/64 loss: -2.6297836303710938
Batch 2/64 loss: -3.1037139892578125
Batch 3/64 loss: -3.0465545654296875
Batch 4/64 loss: -2.9249000549316406
Batch 5/64 loss: -2.745502471923828
Batch 6/64 loss: -2.8055343627929688
Batch 7/64 loss: -2.619264602661133
Batch 8/64 loss: -2.6282434463500977
Batch 9/64 loss: -2.7794580459594727
Batch 10/64 loss: -2.756566047668457
Batch 11/64 loss: -3.0038881301879883
Batch 12/64 loss: -2.9981584548950195
Batch 13/64 loss: -2.641659736633301
Batch 14/64 loss: -2.694098472595215
Batch 15/64 loss: -2.153334617614746
Batch 16/64 loss: -3.0340938568115234
Batch 17/64 loss: -2.7884445190429688
Batch 18/64 loss: -2.6664962768554688
Batch 19/64 loss: -2.7573862075805664
Batch 20/64 loss: -2.6216039657592773
Batch 21/64 loss: -2.973287582397461
Batch 22/64 loss: -2.91485595703125
Batch 23/64 loss: -2.832921028137207
Batch 24/64 loss: -2.981088638305664
Batch 25/64 loss: -2.9318771362304688
Batch 26/64 loss: -2.869980812072754
Batch 27/64 loss: -2.6896324157714844
Batch 28/64 loss: -2.684206008911133
Batch 29/64 loss: -2.937088966369629
Batch 30/64 loss: -2.903517723083496
Batch 31/64 loss: -2.5668840408325195
Batch 32/64 loss: -2.880983352661133
Batch 33/64 loss: -2.8093032836914062
Batch 34/64 loss: -2.978860855102539
Batch 35/64 loss: -2.7477169036865234
Batch 36/64 loss: -3.032526969909668
Batch 37/64 loss: -2.92325496673584
Batch 38/64 loss: -2.855292320251465
Batch 39/64 loss: -2.9084014892578125
Batch 40/64 loss: -2.728433609008789
Batch 41/64 loss: -2.697019577026367
Batch 42/64 loss: -3.006394386291504
Batch 43/64 loss: -2.571138381958008
Batch 44/64 loss: -2.9149580001831055
Batch 45/64 loss: -2.9201183319091797
Batch 46/64 loss: -2.9144134521484375
Batch 47/64 loss: -3.1143016815185547
Batch 48/64 loss: -3.025204658508301
Batch 49/64 loss: -2.9656877517700195
Batch 50/64 loss: -2.973155975341797
Batch 51/64 loss: -2.818849563598633
Batch 52/64 loss: -2.95192813873291
Batch 53/64 loss: -2.8536062240600586
Batch 54/64 loss: -2.9738311767578125
Batch 55/64 loss: -2.9455337524414062
Batch 56/64 loss: -1.651799201965332
Batch 57/64 loss: -2.8551340103149414
Batch 58/64 loss: -2.6056385040283203
Batch 59/64 loss: -2.997330665588379
Batch 60/64 loss: -3.13076114654541
Batch 61/64 loss: -3.059145927429199
Batch 62/64 loss: -2.846255302429199
Batch 63/64 loss: -3.0897254943847656
Batch 64/64 loss: -7.247379302978516
Epoch 407  Train loss: -2.884176710540173  Val loss: -3.100929116055728
Epoch 408
-------------------------------
Batch 1/64 loss: -2.894576072692871
Batch 2/64 loss: -2.955158233642578
Batch 3/64 loss: -2.924528121948242
Batch 4/64 loss: -2.7260942459106445
Batch 5/64 loss: -2.864959716796875
Batch 6/64 loss: -3.0011520385742188
Batch 7/64 loss: -2.9458818435668945
Batch 8/64 loss: -2.873103141784668
Batch 9/64 loss: -2.839559555053711
Batch 10/64 loss: -2.787281036376953
Batch 11/64 loss: -2.760533332824707
Batch 12/64 loss: -2.881654739379883
Batch 13/64 loss: -2.5368480682373047
Batch 14/64 loss: -2.8604583740234375
Batch 15/64 loss: -2.8478918075561523
Batch 16/64 loss: -3.0041866302490234
Batch 17/64 loss: -2.595857620239258
Batch 18/64 loss: -3.0625009536743164
Batch 19/64 loss: -2.872539520263672
Batch 20/64 loss: -2.95650577545166
Batch 21/64 loss: -2.686084747314453
Batch 22/64 loss: -2.7059555053710938
Batch 23/64 loss: -2.8886938095092773
Batch 24/64 loss: -2.9044761657714844
Batch 25/64 loss: -2.8604612350463867
Batch 26/64 loss: -2.7613401412963867
Batch 27/64 loss: -2.7590465545654297
Batch 28/64 loss: -2.921670913696289
Batch 29/64 loss: -3.2134389877319336
Batch 30/64 loss: -3.028951644897461
Batch 31/64 loss: -2.730504035949707
Batch 32/64 loss: -2.7212772369384766
Batch 33/64 loss: -3.122028350830078
Batch 34/64 loss: -2.897690773010254
Batch 35/64 loss: -2.349752426147461
Batch 36/64 loss: -2.94077205657959
Batch 37/64 loss: -2.029219627380371
Batch 38/64 loss: -2.7888870239257812
Batch 39/64 loss: -2.753429412841797
Batch 40/64 loss: -2.814946174621582
Batch 41/64 loss: -2.946727752685547
Batch 42/64 loss: -2.8418312072753906
Batch 43/64 loss: -3.083728790283203
Batch 44/64 loss: -2.9786434173583984
Batch 45/64 loss: -2.673948287963867
Batch 46/64 loss: -2.5878067016601562
Batch 47/64 loss: -3.038736343383789
Batch 48/64 loss: -2.5227270126342773
Batch 49/64 loss: -2.8328256607055664
Batch 50/64 loss: -2.8926496505737305
Batch 51/64 loss: -2.9838714599609375
Batch 52/64 loss: -3.045334815979004
Batch 53/64 loss: -3.1502113342285156
Batch 54/64 loss: -2.959010124206543
Batch 55/64 loss: -2.988748550415039
Batch 56/64 loss: -3.092949867248535
Batch 57/64 loss: -2.377655029296875
Batch 58/64 loss: -2.769913673400879
Batch 59/64 loss: -3.0155296325683594
Batch 60/64 loss: -2.9817028045654297
Batch 61/64 loss: -2.452363967895508
Batch 62/64 loss: -3.076329231262207
Batch 63/64 loss: -2.9015207290649414
Batch 64/64 loss: -7.621878623962402
Epoch 408  Train loss: -2.901663884929582  Val loss: -3.214281298450588
Epoch 409
-------------------------------
Batch 1/64 loss: -2.842413902282715
Batch 2/64 loss: -2.675943374633789
Batch 3/64 loss: -2.838939666748047
Batch 4/64 loss: -2.5744247436523438
Batch 5/64 loss: -2.83707332611084
Batch 6/64 loss: -2.9333553314208984
Batch 7/64 loss: -2.8055992126464844
Batch 8/64 loss: -2.962742805480957
Batch 9/64 loss: -2.854231834411621
Batch 10/64 loss: -3.0428218841552734
Batch 11/64 loss: -2.9580373764038086
Batch 12/64 loss: -3.1033802032470703
Batch 13/64 loss: -2.879018783569336
Batch 14/64 loss: -3.0017194747924805
Batch 15/64 loss: -2.757418632507324
Batch 16/64 loss: -2.90146541595459
Batch 17/64 loss: -2.1091814041137695
Batch 18/64 loss: -2.76993465423584
Batch 19/64 loss: -2.986220359802246
Batch 20/64 loss: -2.8826980590820312
Batch 21/64 loss: -2.76092529296875
Batch 22/64 loss: -2.9381322860717773
Batch 23/64 loss: -2.8984851837158203
Batch 24/64 loss: -3.0706233978271484
Batch 25/64 loss: -2.7556943893432617
Batch 26/64 loss: -3.1273508071899414
Batch 27/64 loss: -2.845536231994629
Batch 28/64 loss: -2.958868980407715
Batch 29/64 loss: -3.0663070678710938
Batch 30/64 loss: -2.988283157348633
Batch 31/64 loss: -3.096364974975586
Batch 32/64 loss: -2.9924373626708984
Batch 33/64 loss: -2.9946460723876953
Batch 34/64 loss: -3.0082950592041016
Batch 35/64 loss: -3.1278696060180664
Batch 36/64 loss: -2.9312829971313477
Batch 37/64 loss: -2.9086360931396484
Batch 38/64 loss: -2.79278564453125
Batch 39/64 loss: -3.0949859619140625
Batch 40/64 loss: -2.5438289642333984
Batch 41/64 loss: -2.962512969970703
Batch 42/64 loss: -2.7390689849853516
Batch 43/64 loss: -2.94149112701416
Batch 44/64 loss: -3.0249948501586914
Batch 45/64 loss: -2.7543516159057617
Batch 46/64 loss: -2.8110694885253906
Batch 47/64 loss: -2.6817455291748047
Batch 48/64 loss: -3.0912370681762695
Batch 49/64 loss: -3.0210647583007812
Batch 50/64 loss: -2.879823684692383
Batch 51/64 loss: -3.044053077697754
Batch 52/64 loss: -3.0757837295532227
Batch 53/64 loss: -3.043807029724121
Batch 54/64 loss: -2.842890739440918
Batch 55/64 loss: -2.232436180114746
Batch 56/64 loss: -2.725399971008301
Batch 57/64 loss: -2.8809471130371094
Batch 58/64 loss: -2.9310827255249023
Batch 59/64 loss: -2.928590774536133
Batch 60/64 loss: -2.804041862487793
Batch 61/64 loss: -2.7978601455688477
Batch 62/64 loss: -3.019986152648926
Batch 63/64 loss: -2.365537643432617
Batch 64/64 loss: -7.674459934234619
Epoch 409  Train loss: -2.93291893566356  Val loss: -3.2099819379983487
Epoch 410
-------------------------------
Batch 1/64 loss: -2.7621450424194336
Batch 2/64 loss: -3.1738948822021484
Batch 3/64 loss: -2.8014822006225586
Batch 4/64 loss: -2.4500083923339844
Batch 5/64 loss: -2.9069957733154297
Batch 6/64 loss: -3.0802297592163086
Batch 7/64 loss: -2.9690027236938477
Batch 8/64 loss: -2.5490636825561523
Batch 9/64 loss: -2.668402671813965
Batch 10/64 loss: -2.9374475479125977
Batch 11/64 loss: -2.9046764373779297
Batch 12/64 loss: -2.524256706237793
Batch 13/64 loss: -3.052863121032715
Batch 14/64 loss: -2.9475278854370117
Batch 15/64 loss: -2.7358713150024414
Batch 16/64 loss: -2.7957916259765625
Batch 17/64 loss: -2.9715232849121094
Batch 18/64 loss: -3.0760507583618164
Batch 19/64 loss: -2.6702194213867188
Batch 20/64 loss: -2.975116729736328
Batch 21/64 loss: -2.9421586990356445
Batch 22/64 loss: -3.0408687591552734
Batch 23/64 loss: -3.0473270416259766
Batch 24/64 loss: -2.0471744537353516
Batch 25/64 loss: -3.061107635498047
Batch 26/64 loss: -2.747220039367676
Batch 27/64 loss: -2.8924560546875
Batch 28/64 loss: -3.0005273818969727
Batch 29/64 loss: -2.811673164367676
Batch 30/64 loss: -3.1535139083862305
Batch 31/64 loss: -2.780506134033203
Batch 32/64 loss: -3.102937698364258
Batch 33/64 loss: -2.8987245559692383
Batch 34/64 loss: -2.6830101013183594
Batch 35/64 loss: -3.0865039825439453
Batch 36/64 loss: -3.0275468826293945
Batch 37/64 loss: -2.9964418411254883
Batch 38/64 loss: -2.935763359069824
Batch 39/64 loss: -2.963751792907715
Batch 40/64 loss: -2.868788719177246
Batch 41/64 loss: -2.7802047729492188
Batch 42/64 loss: -3.0142107009887695
Batch 43/64 loss: -2.883464813232422
Batch 44/64 loss: -3.1275243759155273
Batch 45/64 loss: -2.8501596450805664
Batch 46/64 loss: -3.0465002059936523
Batch 47/64 loss: -2.866183280944824
Batch 48/64 loss: -2.8001794815063477
Batch 49/64 loss: -2.8440046310424805
Batch 50/64 loss: -2.824282646179199
Batch 51/64 loss: -3.0779762268066406
Batch 52/64 loss: -2.7494964599609375
Batch 53/64 loss: -3.071343421936035
Batch 54/64 loss: -3.0206985473632812
Batch 55/64 loss: -3.004054069519043
Batch 56/64 loss: -3.1020851135253906
Batch 57/64 loss: -2.935213088989258
Batch 58/64 loss: -3.110492706298828
Batch 59/64 loss: -2.8805179595947266
Batch 60/64 loss: -2.4184913635253906
Batch 61/64 loss: -3.0266761779785156
Batch 62/64 loss: -2.758665084838867
Batch 63/64 loss: -2.835068702697754
Batch 64/64 loss: -7.113677501678467
Epoch 410  Train loss: -2.939659980699128  Val loss: -3.2083381443089225
Epoch 411
-------------------------------
Batch 1/64 loss: -2.8283376693725586
Batch 2/64 loss: -2.9056529998779297
Batch 3/64 loss: -2.735762596130371
Batch 4/64 loss: -3.025899887084961
Batch 5/64 loss: -2.972545623779297
Batch 6/64 loss: -3.1012229919433594
Batch 7/64 loss: -2.988247871398926
Batch 8/64 loss: -2.7689590454101562
Batch 9/64 loss: -2.899876594543457
Batch 10/64 loss: -2.968738555908203
Batch 11/64 loss: -2.7121458053588867
Batch 12/64 loss: -2.9966001510620117
Batch 13/64 loss: -2.8681411743164062
Batch 14/64 loss: -2.869185447692871
Batch 15/64 loss: -2.7930212020874023
Batch 16/64 loss: -2.8220510482788086
Batch 17/64 loss: -2.803314208984375
Batch 18/64 loss: -2.6314525604248047
Batch 19/64 loss: -2.8289499282836914
Batch 20/64 loss: -2.8921451568603516
Batch 21/64 loss: -2.8604040145874023
Batch 22/64 loss: -2.47470760345459
Batch 23/64 loss: -2.9621963500976562
Batch 24/64 loss: -2.8581199645996094
Batch 25/64 loss: -2.7726173400878906
Batch 26/64 loss: -3.052225112915039
Batch 27/64 loss: -2.9887609481811523
Batch 28/64 loss: -2.9448022842407227
Batch 29/64 loss: -2.8423690795898438
Batch 30/64 loss: -2.7214317321777344
Batch 31/64 loss: -2.910167694091797
Batch 32/64 loss: -2.7383651733398438
Batch 33/64 loss: -2.8857650756835938
Batch 34/64 loss: -3.113581657409668
Batch 35/64 loss: -3.093709945678711
Batch 36/64 loss: -3.0557050704956055
Batch 37/64 loss: -2.832113265991211
Batch 38/64 loss: -2.8973236083984375
Batch 39/64 loss: -3.067049026489258
Batch 40/64 loss: -2.452983856201172
Batch 41/64 loss: -2.91744327545166
Batch 42/64 loss: -2.6840476989746094
Batch 43/64 loss: -3.064168930053711
Batch 44/64 loss: -2.472330093383789
Batch 45/64 loss: -3.0763816833496094
Batch 46/64 loss: -2.8660640716552734
Batch 47/64 loss: -3.091634750366211
Batch 48/64 loss: -2.9726829528808594
Batch 49/64 loss: -2.73476505279541
Batch 50/64 loss: -3.0362367630004883
Batch 51/64 loss: -2.493377685546875
Batch 52/64 loss: -2.8170204162597656
Batch 53/64 loss: -3.0076026916503906
Batch 54/64 loss: -2.6581907272338867
Batch 55/64 loss: -2.90777587890625
Batch 56/64 loss: -3.1751413345336914
Batch 57/64 loss: -2.7897424697875977
Batch 58/64 loss: -3.0466222763061523
Batch 59/64 loss: -2.8955392837524414
Batch 60/64 loss: -3.2440080642700195
Batch 61/64 loss: -3.0487728118896484
Batch 62/64 loss: -2.337970733642578
Batch 63/64 loss: -2.8261194229125977
Batch 64/64 loss: -7.685077667236328
Epoch 411  Train loss: -2.931201515945734  Val loss: -3.2306677434862276
Epoch 412
-------------------------------
Batch 1/64 loss: -2.763850212097168
Batch 2/64 loss: -3.1385765075683594
Batch 3/64 loss: -3.038853645324707
Batch 4/64 loss: -2.988001823425293
Batch 5/64 loss: -2.781383514404297
Batch 6/64 loss: -2.9805707931518555
Batch 7/64 loss: -3.0422439575195312
Batch 8/64 loss: -2.915386199951172
Batch 9/64 loss: -2.6462488174438477
Batch 10/64 loss: -3.0402755737304688
Batch 11/64 loss: -2.855867385864258
Batch 12/64 loss: -2.971822738647461
Batch 13/64 loss: -2.7421531677246094
Batch 14/64 loss: -3.092841148376465
Batch 15/64 loss: -2.978160858154297
Batch 16/64 loss: -3.107546806335449
Batch 17/64 loss: -2.8064355850219727
Batch 18/64 loss: -3.036770820617676
Batch 19/64 loss: -3.122722625732422
Batch 20/64 loss: -3.0856428146362305
Batch 21/64 loss: -2.893362045288086
Batch 22/64 loss: -2.879631996154785
Batch 23/64 loss: -2.5985450744628906
Batch 24/64 loss: -2.4127187728881836
Batch 25/64 loss: -3.0503063201904297
Batch 26/64 loss: -2.420553207397461
Batch 27/64 loss: -2.810641288757324
Batch 28/64 loss: -2.9016857147216797
Batch 29/64 loss: -2.8447017669677734
Batch 30/64 loss: -3.1738319396972656
Batch 31/64 loss: -2.9023666381835938
Batch 32/64 loss: -2.9922409057617188
Batch 33/64 loss: -2.617839813232422
Batch 34/64 loss: -3.1326522827148438
Batch 35/64 loss: -2.6277122497558594
Batch 36/64 loss: -2.900040626525879
Batch 37/64 loss: -2.9997119903564453
Batch 38/64 loss: -3.0757532119750977
Batch 39/64 loss: -2.751920700073242
Batch 40/64 loss: -2.978300094604492
Batch 41/64 loss: -3.1713180541992188
Batch 42/64 loss: -3.125149726867676
Batch 43/64 loss: -2.9650955200195312
Batch 44/64 loss: -3.09686279296875
Batch 45/64 loss: -2.764516830444336
Batch 46/64 loss: -2.662672996520996
Batch 47/64 loss: -2.8761377334594727
Batch 48/64 loss: -3.113819122314453
Batch 49/64 loss: -3.011798858642578
Batch 50/64 loss: -2.972323417663574
Batch 51/64 loss: -2.9461793899536133
Batch 52/64 loss: -3.000555992126465
Batch 53/64 loss: -3.0163183212280273
Batch 54/64 loss: -3.083038330078125
Batch 55/64 loss: -3.067145347595215
Batch 56/64 loss: -2.976834297180176
Batch 57/64 loss: -2.871603012084961
Batch 58/64 loss: -2.840237617492676
Batch 59/64 loss: -2.8194780349731445
Batch 60/64 loss: -3.036287307739258
Batch 61/64 loss: -2.5538225173950195
Batch 62/64 loss: -3.1358718872070312
Batch 63/64 loss: -3.007126808166504
Batch 64/64 loss: -7.461892127990723
Epoch 412  Train loss: -2.977419367023543  Val loss: -3.2774003805573453
Epoch 413
-------------------------------
Batch 1/64 loss: -2.906373977661133
Batch 2/64 loss: -2.904245376586914
Batch 3/64 loss: -2.921062469482422
Batch 4/64 loss: -2.4821996688842773
Batch 5/64 loss: -3.182424545288086
Batch 6/64 loss: -3.1052751541137695
Batch 7/64 loss: -2.7520179748535156
Batch 8/64 loss: -2.961785316467285
Batch 9/64 loss: -2.86415958404541
Batch 10/64 loss: -2.151822090148926
Batch 11/64 loss: -2.937567710876465
Batch 12/64 loss: -2.789926528930664
Batch 13/64 loss: -2.984402656555176
Batch 14/64 loss: -3.1127920150756836
Batch 15/64 loss: -2.8820886611938477
Batch 16/64 loss: -3.081019401550293
Batch 17/64 loss: -3.1175622940063477
Batch 18/64 loss: -3.001375198364258
Batch 19/64 loss: -2.854905128479004
Batch 20/64 loss: -2.9265356063842773
Batch 21/64 loss: -3.0577192306518555
Batch 22/64 loss: -2.929716110229492
Batch 23/64 loss: -3.129833221435547
Batch 24/64 loss: -3.0886688232421875
Batch 25/64 loss: -3.0891265869140625
Batch 26/64 loss: -2.9555749893188477
Batch 27/64 loss: -2.8202037811279297
Batch 28/64 loss: -2.466419219970703
Batch 29/64 loss: -2.8182058334350586
Batch 30/64 loss: -3.096223831176758
Batch 31/64 loss: -2.7762794494628906
Batch 32/64 loss: -2.776810646057129
Batch 33/64 loss: -3.226860523223877
Batch 34/64 loss: -3.0564260482788086
Batch 35/64 loss: -2.8374595642089844
Batch 36/64 loss: -2.9272518157958984
Batch 37/64 loss: -3.1472387313842773
Batch 38/64 loss: -2.621469497680664
Batch 39/64 loss: -3.1039047241210938
Batch 40/64 loss: -3.087709426879883
Batch 41/64 loss: -3.16841459274292
Batch 42/64 loss: -3.040487289428711
Batch 43/64 loss: -2.9272594451904297
Batch 44/64 loss: -2.6807146072387695
Batch 45/64 loss: -3.097322463989258
Batch 46/64 loss: -2.7136926651000977
Batch 47/64 loss: -3.026055335998535
Batch 48/64 loss: -3.120969772338867
Batch 49/64 loss: -3.0461807250976562
Batch 50/64 loss: -3.1598424911499023
Batch 51/64 loss: -2.917266845703125
Batch 52/64 loss: -2.844402313232422
Batch 53/64 loss: -2.9456796646118164
Batch 54/64 loss: -2.9379653930664062
Batch 55/64 loss: -2.829298973083496
Batch 56/64 loss: -3.055814743041992
Batch 57/64 loss: -2.1690359115600586
Batch 58/64 loss: -3.0152320861816406
Batch 59/64 loss: -3.068675994873047
Batch 60/64 loss: -3.1020517349243164
Batch 61/64 loss: -3.1519241333007812
Batch 62/64 loss: -3.006331443786621
Batch 63/64 loss: -2.9969253540039062
Batch 64/64 loss: -7.082695007324219
Epoch 413  Train loss: -2.984567978802849  Val loss: -3.2713280248478105
Epoch 414
-------------------------------
Batch 1/64 loss: -3.081544876098633
Batch 2/64 loss: -2.7768335342407227
Batch 3/64 loss: -3.0631093978881836
Batch 4/64 loss: -2.3913984298706055
Batch 5/64 loss: -3.193716049194336
Batch 6/64 loss: -3.063404083251953
Batch 7/64 loss: -2.988567352294922
Batch 8/64 loss: -2.607227325439453
Batch 9/64 loss: -2.8988828659057617
Batch 10/64 loss: -3.116549491882324
Batch 11/64 loss: -3.022353172302246
Batch 12/64 loss: -2.7274045944213867
Batch 13/64 loss: -3.0523805618286133
Batch 14/64 loss: -3.082265853881836
Batch 15/64 loss: -2.624342918395996
Batch 16/64 loss: -3.024648666381836
Batch 17/64 loss: -3.1437206268310547
Batch 18/64 loss: -2.9551219940185547
Batch 19/64 loss: -3.0454959869384766
Batch 20/64 loss: -2.6879749298095703
Batch 21/64 loss: -2.881373405456543
Batch 22/64 loss: -3.10723876953125
Batch 23/64 loss: -2.6684789657592773
Batch 24/64 loss: -2.82296085357666
Batch 25/64 loss: -2.8613767623901367
Batch 26/64 loss: -3.1667537689208984
Batch 27/64 loss: -2.937750816345215
Batch 28/64 loss: -3.094590187072754
Batch 29/64 loss: -2.7914581298828125
Batch 30/64 loss: -3.0437488555908203
Batch 31/64 loss: -3.078977584838867
Batch 32/64 loss: -3.019577980041504
Batch 33/64 loss: -3.0297365188598633
Batch 34/64 loss: -2.931704521179199
Batch 35/64 loss: -3.146900177001953
Batch 36/64 loss: -2.8061628341674805
Batch 37/64 loss: -3.08544921875
Batch 38/64 loss: -2.8294200897216797
Batch 39/64 loss: -2.9690980911254883
Batch 40/64 loss: -2.81247615814209
Batch 41/64 loss: -3.1343936920166016
Batch 42/64 loss: -2.8466272354125977
Batch 43/64 loss: -2.984402656555176
Batch 44/64 loss: -2.9226465225219727
Batch 45/64 loss: -3.063084602355957
Batch 46/64 loss: -3.1018877029418945
Batch 47/64 loss: -3.090383529663086
Batch 48/64 loss: -2.790879249572754
Batch 49/64 loss: -3.0583152770996094
Batch 50/64 loss: -3.0794992446899414
Batch 51/64 loss: -2.708815574645996
Batch 52/64 loss: -3.0359411239624023
Batch 53/64 loss: -3.208463668823242
Batch 54/64 loss: -3.0717201232910156
Batch 55/64 loss: -3.1607542037963867
Batch 56/64 loss: -2.6780166625976562
Batch 57/64 loss: -2.820241928100586
Batch 58/64 loss: -3.1284360885620117
Batch 59/64 loss: -2.946962356567383
Batch 60/64 loss: -2.8249807357788086
Batch 61/64 loss: -3.003970146179199
Batch 62/64 loss: -2.8828468322753906
Batch 63/64 loss: -3.160464286804199
Batch 64/64 loss: -6.511521816253662
Epoch 414  Train loss: -2.9995223718530992  Val loss: -3.2794113028090432
Epoch 415
-------------------------------
Batch 1/64 loss: -3.1579532623291016
Batch 2/64 loss: -3.012722969055176
Batch 3/64 loss: -2.908444404602051
Batch 4/64 loss: -2.8864078521728516
Batch 5/64 loss: -3.021437644958496
Batch 6/64 loss: -3.028116226196289
Batch 7/64 loss: -2.8742380142211914
Batch 8/64 loss: -2.9772701263427734
Batch 9/64 loss: -3.037109375
Batch 10/64 loss: -3.0252952575683594
Batch 11/64 loss: -2.621548652648926
Batch 12/64 loss: -2.8435935974121094
Batch 13/64 loss: -3.1055307388305664
Batch 14/64 loss: -2.7733230590820312
Batch 15/64 loss: -2.859437942504883
Batch 16/64 loss: -2.999791145324707
Batch 17/64 loss: -2.888662338256836
Batch 18/64 loss: -3.004608154296875
Batch 19/64 loss: -3.035116195678711
Batch 20/64 loss: -2.4267568588256836
Batch 21/64 loss: -3.1640024185180664
Batch 22/64 loss: -2.992974281311035
Batch 23/64 loss: -3.199124336242676
Batch 24/64 loss: -3.0037240982055664
Batch 25/64 loss: -3.0949649810791016
Batch 26/64 loss: -3.1261281967163086
Batch 27/64 loss: -3.085759162902832
Batch 28/64 loss: -3.058948516845703
Batch 29/64 loss: -3.1583614349365234
Batch 30/64 loss: -2.910262107849121
Batch 31/64 loss: -2.6119604110717773
Batch 32/64 loss: -3.0773401260375977
Batch 33/64 loss: -2.860867500305176
Batch 34/64 loss: -3.108304977416992
Batch 35/64 loss: -2.8444271087646484
Batch 36/64 loss: -2.985184669494629
Batch 37/64 loss: -3.1061477661132812
Batch 38/64 loss: -2.998936653137207
Batch 39/64 loss: -2.8971166610717773
Batch 40/64 loss: -2.934626579284668
Batch 41/64 loss: -2.9627065658569336
Batch 42/64 loss: -2.8183231353759766
Batch 43/64 loss: -3.0752716064453125
Batch 44/64 loss: -3.00775146484375
Batch 45/64 loss: -2.9753637313842773
Batch 46/64 loss: -2.9681177139282227
Batch 47/64 loss: -2.9632415771484375
Batch 48/64 loss: -3.0537166595458984
Batch 49/64 loss: -2.6311588287353516
Batch 50/64 loss: -2.5680055618286133
Batch 51/64 loss: -3.0816659927368164
Batch 52/64 loss: -2.5113964080810547
Batch 53/64 loss: -3.0142717361450195
Batch 54/64 loss: -3.046121597290039
Batch 55/64 loss: -2.8581295013427734
Batch 56/64 loss: -2.8907299041748047
Batch 57/64 loss: -2.7855606079101562
Batch 58/64 loss: -2.980134963989258
Batch 59/64 loss: -3.1875433921813965
Batch 60/64 loss: -2.9130783081054688
Batch 61/64 loss: -2.817082405090332
Batch 62/64 loss: -2.9427337646484375
Batch 63/64 loss: -2.83444881439209
Batch 64/64 loss: -6.92860746383667
Epoch 415  Train loss: -2.9927770296732583  Val loss: -3.245066639483999
Epoch 416
-------------------------------
Batch 1/64 loss: -3.024890899658203
Batch 2/64 loss: -2.928868293762207
Batch 3/64 loss: -2.971160888671875
Batch 4/64 loss: -3.120115280151367
Batch 5/64 loss: -3.019775390625
Batch 6/64 loss: -2.6089134216308594
Batch 7/64 loss: -2.9853315353393555
Batch 8/64 loss: -2.4899330139160156
Batch 9/64 loss: -3.059457778930664
Batch 10/64 loss: -2.8129281997680664
Batch 11/64 loss: -3.128725051879883
Batch 12/64 loss: -3.1047468185424805
Batch 13/64 loss: -2.9391050338745117
Batch 14/64 loss: -3.1152820587158203
Batch 15/64 loss: -2.8652820587158203
Batch 16/64 loss: -3.0173110961914062
Batch 17/64 loss: -2.8878555297851562
Batch 18/64 loss: -3.0212249755859375
Batch 19/64 loss: -3.1660566329956055
Batch 20/64 loss: -2.8321008682250977
Batch 21/64 loss: -3.09378719329834
Batch 22/64 loss: -2.9862632751464844
Batch 23/64 loss: -2.834395408630371
Batch 24/64 loss: -2.6592416763305664
Batch 25/64 loss: -2.885098457336426
Batch 26/64 loss: -2.9183120727539062
Batch 27/64 loss: -2.8683204650878906
Batch 28/64 loss: -2.817471504211426
Batch 29/64 loss: -2.9928808212280273
Batch 30/64 loss: -3.1683216094970703
Batch 31/64 loss: -2.8812389373779297
Batch 32/64 loss: -2.987192153930664
Batch 33/64 loss: -2.9503068923950195
Batch 34/64 loss: -2.814462661743164
Batch 35/64 loss: -3.0571136474609375
Batch 36/64 loss: -2.7684526443481445
Batch 37/64 loss: -3.0974817276000977
Batch 38/64 loss: -3.0567188262939453
Batch 39/64 loss: -2.9925174713134766
Batch 40/64 loss: -2.863579750061035
Batch 41/64 loss: -2.9100284576416016
Batch 42/64 loss: -3.0992822647094727
Batch 43/64 loss: -2.242176055908203
Batch 44/64 loss: -2.3053741455078125
Batch 45/64 loss: -3.003769874572754
Batch 46/64 loss: -2.900188446044922
Batch 47/64 loss: -2.8537654876708984
Batch 48/64 loss: -2.7524585723876953
Batch 49/64 loss: -2.8466901779174805
Batch 50/64 loss: -3.0733375549316406
Batch 51/64 loss: -2.9261226654052734
Batch 52/64 loss: -2.7783470153808594
Batch 53/64 loss: -3.1081247329711914
Batch 54/64 loss: -2.1955270767211914
Batch 55/64 loss: -2.6491317749023438
Batch 56/64 loss: -3.181389808654785
Batch 57/64 loss: -2.8443098068237305
Batch 58/64 loss: -3.193974494934082
Batch 59/64 loss: -3.041628837585449
Batch 60/64 loss: -3.0432777404785156
Batch 61/64 loss: -2.7612476348876953
Batch 62/64 loss: -2.87442684173584
Batch 63/64 loss: -2.9746408462524414
Batch 64/64 loss: -7.583314418792725
Epoch 416  Train loss: -2.965316520017736  Val loss: -3.257638688759296
Epoch 417
-------------------------------
Batch 1/64 loss: -2.996708869934082
Batch 2/64 loss: -3.2292728424072266
Batch 3/64 loss: -3.0892629623413086
Batch 4/64 loss: -2.9551820755004883
Batch 5/64 loss: -2.856128692626953
Batch 6/64 loss: -2.7734375
Batch 7/64 loss: -3.246321201324463
Batch 8/64 loss: -2.4915943145751953
Batch 9/64 loss: -2.8488731384277344
Batch 10/64 loss: -2.832034111022949
Batch 11/64 loss: -3.0907211303710938
Batch 12/64 loss: -2.9415740966796875
Batch 13/64 loss: -2.9318056106567383
Batch 14/64 loss: -2.9783992767333984
Batch 15/64 loss: -2.8794422149658203
Batch 16/64 loss: -2.974581718444824
Batch 17/64 loss: -3.150374412536621
Batch 18/64 loss: -2.9084606170654297
Batch 19/64 loss: -2.950253486633301
Batch 20/64 loss: -2.9179019927978516
Batch 21/64 loss: -2.1583547592163086
Batch 22/64 loss: -2.7515907287597656
Batch 23/64 loss: -3.098015785217285
Batch 24/64 loss: -2.7306461334228516
Batch 25/64 loss: -2.85992431640625
Batch 26/64 loss: -2.321765899658203
Batch 27/64 loss: -3.0871620178222656
Batch 28/64 loss: -2.9005842208862305
Batch 29/64 loss: -2.8543691635131836
Batch 30/64 loss: -3.0210962295532227
Batch 31/64 loss: -2.934115409851074
Batch 32/64 loss: -3.0999937057495117
Batch 33/64 loss: -2.9940595626831055
Batch 34/64 loss: -2.917050361633301
Batch 35/64 loss: -2.8959779739379883
Batch 36/64 loss: -2.989347457885742
Batch 37/64 loss: -2.851712226867676
Batch 38/64 loss: -2.7373695373535156
Batch 39/64 loss: -2.8508901596069336
Batch 40/64 loss: -2.8395652770996094
Batch 41/64 loss: -2.890623092651367
Batch 42/64 loss: -3.082033157348633
Batch 43/64 loss: -2.7036046981811523
Batch 44/64 loss: -3.0428380966186523
Batch 45/64 loss: -2.9849815368652344
Batch 46/64 loss: -3.081562042236328
Batch 47/64 loss: -2.858369827270508
Batch 48/64 loss: -3.090489387512207
Batch 49/64 loss: -3.08693790435791
Batch 50/64 loss: -2.8648529052734375
Batch 51/64 loss: -2.5157833099365234
Batch 52/64 loss: -2.966477394104004
Batch 53/64 loss: -2.712085723876953
Batch 54/64 loss: -2.98789119720459
Batch 55/64 loss: -2.894075393676758
Batch 56/64 loss: -2.7472991943359375
Batch 57/64 loss: -3.0503149032592773
Batch 58/64 loss: -2.9949159622192383
Batch 59/64 loss: -2.961772918701172
Batch 60/64 loss: -2.9916019439697266
Batch 61/64 loss: -2.894857406616211
Batch 62/64 loss: -3.0703325271606445
Batch 63/64 loss: -2.744614601135254
Batch 64/64 loss: -7.377343654632568
Epoch 417  Train loss: -2.9597999067867504  Val loss: -3.2581314925885283
Epoch 418
-------------------------------
Batch 1/64 loss: -3.031137466430664
Batch 2/64 loss: -3.0310287475585938
Batch 3/64 loss: -2.950387954711914
Batch 4/64 loss: -2.8824691772460938
Batch 5/64 loss: -2.3553876876831055
Batch 6/64 loss: -3.163161277770996
Batch 7/64 loss: -2.992171287536621
Batch 8/64 loss: -2.9422950744628906
Batch 9/64 loss: -2.8092470169067383
Batch 10/64 loss: -2.9177417755126953
Batch 11/64 loss: -2.8443737030029297
Batch 12/64 loss: -3.1634645462036133
Batch 13/64 loss: -2.916717529296875
Batch 14/64 loss: -2.86527156829834
Batch 15/64 loss: -3.1086549758911133
Batch 16/64 loss: -3.060914993286133
Batch 17/64 loss: -2.9177656173706055
Batch 18/64 loss: -3.1596670150756836
Batch 19/64 loss: -3.0084781646728516
Batch 20/64 loss: -2.998215675354004
Batch 21/64 loss: -3.044398307800293
Batch 22/64 loss: -2.8942079544067383
Batch 23/64 loss: -2.9767513275146484
Batch 24/64 loss: -2.9916982650756836
Batch 25/64 loss: -2.853710174560547
Batch 26/64 loss: -3.10892391204834
Batch 27/64 loss: -2.033951759338379
Batch 28/64 loss: -3.1474533081054688
Batch 29/64 loss: -2.952519416809082
Batch 30/64 loss: -2.7136878967285156
Batch 31/64 loss: -3.0053157806396484
Batch 32/64 loss: -3.1016931533813477
Batch 33/64 loss: -2.9104175567626953
Batch 34/64 loss: -3.0972414016723633
Batch 35/64 loss: -2.9861927032470703
Batch 36/64 loss: -3.0512304306030273
Batch 37/64 loss: -2.9179458618164062
Batch 38/64 loss: -2.8866748809814453
Batch 39/64 loss: -3.202162742614746
Batch 40/64 loss: -2.6040420532226562
Batch 41/64 loss: -2.6636486053466797
Batch 42/64 loss: -2.9802846908569336
Batch 43/64 loss: -2.920572280883789
Batch 44/64 loss: -3.134955406188965
Batch 45/64 loss: -3.029714584350586
Batch 46/64 loss: -2.552088737487793
Batch 47/64 loss: -2.5800352096557617
Batch 48/64 loss: -2.6816883087158203
Batch 49/64 loss: -3.0479907989501953
Batch 50/64 loss: -2.5009641647338867
Batch 51/64 loss: -2.949681282043457
Batch 52/64 loss: -3.090360641479492
Batch 53/64 loss: -3.0298519134521484
Batch 54/64 loss: -3.1659250259399414
Batch 55/64 loss: -2.93557071685791
Batch 56/64 loss: -3.1791181564331055
Batch 57/64 loss: -3.036055564880371
Batch 58/64 loss: -2.47420597076416
Batch 59/64 loss: -2.8607616424560547
Batch 60/64 loss: -2.922329902648926
Batch 61/64 loss: -2.6081953048706055
Batch 62/64 loss: -3.0716171264648438
Batch 63/64 loss: -3.0658254623413086
Batch 64/64 loss: -7.473345756530762
Epoch 418  Train loss: -2.975454446381214  Val loss: -3.2920942404835496
Epoch 419
-------------------------------
Batch 1/64 loss: -3.0111818313598633
Batch 2/64 loss: -3.0593385696411133
Batch 3/64 loss: -2.8566112518310547
Batch 4/64 loss: -2.638392448425293
Batch 5/64 loss: -2.9538450241088867
Batch 6/64 loss: -2.5235347747802734
Batch 7/64 loss: -3.1556386947631836
Batch 8/64 loss: -2.68898868560791
Batch 9/64 loss: -2.9913883209228516
Batch 10/64 loss: -2.938509941101074
Batch 11/64 loss: -3.0613393783569336
Batch 12/64 loss: -3.1517152786254883
Batch 13/64 loss: -2.892454147338867
Batch 14/64 loss: -2.964750289916992
Batch 15/64 loss: -3.163705825805664
Batch 16/64 loss: -2.891476631164551
Batch 17/64 loss: -2.964287757873535
Batch 18/64 loss: -2.662302017211914
Batch 19/64 loss: -2.9531049728393555
Batch 20/64 loss: -2.736109733581543
Batch 21/64 loss: -2.998424530029297
Batch 22/64 loss: -2.790879249572754
Batch 23/64 loss: -3.0391435623168945
Batch 24/64 loss: -3.1156787872314453
Batch 25/64 loss: -2.928670883178711
Batch 26/64 loss: -2.925753593444824
Batch 27/64 loss: -3.031015396118164
Batch 28/64 loss: -2.977396011352539
Batch 29/64 loss: -2.9275875091552734
Batch 30/64 loss: -3.245661735534668
Batch 31/64 loss: -2.885019302368164
Batch 32/64 loss: -2.9576072692871094
Batch 33/64 loss: -3.181931495666504
Batch 34/64 loss: -2.8912181854248047
Batch 35/64 loss: -3.056089401245117
Batch 36/64 loss: -2.9342832565307617
Batch 37/64 loss: -3.0180301666259766
Batch 38/64 loss: -3.091658592224121
Batch 39/64 loss: -3.0397462844848633
Batch 40/64 loss: -2.6491355895996094
Batch 41/64 loss: -2.444154739379883
Batch 42/64 loss: -2.868666648864746
Batch 43/64 loss: -3.217958450317383
Batch 44/64 loss: -3.0886449813842773
Batch 45/64 loss: -2.9451589584350586
Batch 46/64 loss: -2.9878549575805664
Batch 47/64 loss: -3.0386085510253906
Batch 48/64 loss: -2.685053825378418
Batch 49/64 loss: -2.5133495330810547
Batch 50/64 loss: -2.5261154174804688
Batch 51/64 loss: -2.5335464477539062
Batch 52/64 loss: -2.79522705078125
Batch 53/64 loss: -2.8942947387695312
Batch 54/64 loss: -2.5558366775512695
Batch 55/64 loss: -2.4789352416992188
Batch 56/64 loss: -1.8614473342895508
Batch 57/64 loss: -2.466120719909668
Batch 58/64 loss: -2.8551645278930664
Batch 59/64 loss: -2.0304183959960938
Batch 60/64 loss: -0.813450813293457
Batch 61/64 loss: -2.894354820251465
Batch 62/64 loss: -2.4617557525634766
Batch 63/64 loss: -2.414196014404297
Batch 64/64 loss: -6.8453850746154785
Epoch 419  Train loss: -2.8619287808736167  Val loss: -1.9790002488598382
Epoch 420
-------------------------------
Batch 1/64 loss: -2.6965818405151367
Batch 2/64 loss: -2.215402603149414
Batch 3/64 loss: -2.6417675018310547
Batch 4/64 loss: -2.432199478149414
Batch 5/64 loss: -2.279123306274414
Batch 6/64 loss: -2.169858932495117
Batch 7/64 loss: -2.47509765625
Batch 8/64 loss: -1.7107782363891602
Batch 9/64 loss: -2.122343063354492
Batch 10/64 loss: -1.1408939361572266
Batch 11/64 loss: -2.2976646423339844
Batch 12/64 loss: -2.4785871505737305
Batch 13/64 loss: -2.363901138305664
Batch 14/64 loss: -2.5013599395751953
Batch 15/64 loss: -2.572174072265625
Batch 16/64 loss: -2.4595489501953125
Batch 17/64 loss: -2.48626708984375
Batch 18/64 loss: -2.5971736907958984
Batch 19/64 loss: -1.7655229568481445
Batch 20/64 loss: -2.614760398864746
Batch 21/64 loss: -2.3148651123046875
Batch 22/64 loss: -2.7697267532348633
Batch 23/64 loss: -2.3682022094726562
Batch 24/64 loss: -2.0318565368652344
Batch 25/64 loss: -1.0296010971069336
Batch 26/64 loss: -2.48138427734375
Batch 27/64 loss: -2.4249114990234375
Batch 28/64 loss: -2.748040199279785
Batch 29/64 loss: -2.359546661376953
Batch 30/64 loss: -0.5670108795166016
Batch 31/64 loss: -2.3206615447998047
Batch 32/64 loss: -1.9828262329101562
Batch 33/64 loss: -1.931997299194336
Batch 34/64 loss: -1.7465391159057617
Batch 35/64 loss: -2.230116844177246
Batch 36/64 loss: -2.6173505783081055
Batch 37/64 loss: -2.380814552307129
Batch 38/64 loss: -2.3683881759643555
Batch 39/64 loss: -2.1861143112182617
Batch 40/64 loss: -2.399913787841797
Batch 41/64 loss: -1.2386035919189453
Batch 42/64 loss: -2.6541357040405273
Batch 43/64 loss: -2.519577980041504
Batch 44/64 loss: -2.4830493927001953
Batch 45/64 loss: -2.449934959411621
Batch 46/64 loss: -2.5656843185424805
Batch 47/64 loss: -2.0359020233154297
Batch 48/64 loss: -1.322484016418457
Batch 49/64 loss: -2.2270050048828125
Batch 50/64 loss: -2.6984663009643555
Batch 51/64 loss: -1.786372184753418
Batch 52/64 loss: -2.17917537689209
Batch 53/64 loss: -2.911892890930176
Batch 54/64 loss: -1.9683971405029297
Batch 55/64 loss: -2.4284563064575195
Batch 56/64 loss: -2.566556930541992
Batch 57/64 loss: -2.5519094467163086
Batch 58/64 loss: -2.2840261459350586
Batch 59/64 loss: -2.0717220306396484
Batch 60/64 loss: -2.471925735473633
Batch 61/64 loss: -2.4233055114746094
Batch 62/64 loss: -2.004253387451172
Batch 63/64 loss: -2.5844316482543945
Batch 64/64 loss: -7.313711166381836
Epoch 420  Train loss: -2.3089164808684703  Val loss: -2.569817428326689
Epoch 421
-------------------------------
Batch 1/64 loss: -2.660778045654297
Batch 2/64 loss: -2.2713279724121094
Batch 3/64 loss: -2.804568290710449
Batch 4/64 loss: -2.358907699584961
Batch 5/64 loss: -2.869802474975586
Batch 6/64 loss: -1.2339096069335938
Batch 7/64 loss: -2.0127382278442383
Batch 8/64 loss: -2.398530960083008
Batch 9/64 loss: -2.2114791870117188
Batch 10/64 loss: -2.3962221145629883
Batch 11/64 loss: -2.504462242126465
Batch 12/64 loss: -2.520758628845215
Batch 13/64 loss: -2.3882598876953125
Batch 14/64 loss: -2.7522125244140625
Batch 15/64 loss: -2.1093692779541016
Batch 16/64 loss: -2.7472734451293945
Batch 17/64 loss: -2.3610305786132812
Batch 18/64 loss: -2.7715072631835938
Batch 19/64 loss: -2.764934539794922
Batch 20/64 loss: -2.3500518798828125
Batch 21/64 loss: -2.621352195739746
Batch 22/64 loss: -2.894561767578125
Batch 23/64 loss: -2.931220054626465
Batch 24/64 loss: -3.0269203186035156
Batch 25/64 loss: -2.718832015991211
Batch 26/64 loss: -2.7044010162353516
Batch 27/64 loss: -1.519852638244629
Batch 28/64 loss: -2.3651952743530273
Batch 29/64 loss: -2.7574462890625
Batch 30/64 loss: -2.509143829345703
Batch 31/64 loss: -1.4885549545288086
Batch 32/64 loss: -2.8096532821655273
Batch 33/64 loss: -2.5570106506347656
Batch 34/64 loss: -2.680771827697754
Batch 35/64 loss: -2.8164358139038086
Batch 36/64 loss: -2.712118148803711
Batch 37/64 loss: -2.5951852798461914
Batch 38/64 loss: -2.776193618774414
Batch 39/64 loss: -2.6636476516723633
Batch 40/64 loss: -2.8706283569335938
Batch 41/64 loss: -2.0379467010498047
Batch 42/64 loss: -2.8522214889526367
Batch 43/64 loss: -1.892714500427246
Batch 44/64 loss: -2.6124982833862305
Batch 45/64 loss: -2.7581701278686523
Batch 46/64 loss: -2.6749649047851562
Batch 47/64 loss: -2.294614791870117
Batch 48/64 loss: -2.2821474075317383
Batch 49/64 loss: -2.5322132110595703
Batch 50/64 loss: -2.6415796279907227
Batch 51/64 loss: -2.3444719314575195
Batch 52/64 loss: -2.189180374145508
Batch 53/64 loss: -2.57684326171875
Batch 54/64 loss: -2.66898250579834
Batch 55/64 loss: -2.468693733215332
Batch 56/64 loss: -2.5183753967285156
Batch 57/64 loss: -2.6459569931030273
Batch 58/64 loss: -2.206423759460449
Batch 59/64 loss: -2.374725341796875
Batch 60/64 loss: -2.945876121520996
Batch 61/64 loss: -2.66616153717041
Batch 62/64 loss: -2.7273731231689453
Batch 63/64 loss: -2.5788145065307617
Batch 64/64 loss: -6.764432907104492
Epoch 421  Train loss: -2.557984692442651  Val loss: -2.8812928740511237
Epoch 422
-------------------------------
Batch 1/64 loss: -2.508737564086914
Batch 2/64 loss: -2.6815242767333984
Batch 3/64 loss: -2.548520088195801
Batch 4/64 loss: -2.6522607803344727
Batch 5/64 loss: -1.5026416778564453
Batch 6/64 loss: -2.916689872741699
Batch 7/64 loss: -2.529017448425293
Batch 8/64 loss: -2.364908218383789
Batch 9/64 loss: -3.0311689376831055
Batch 10/64 loss: -2.5352907180786133
Batch 11/64 loss: -2.2384023666381836
Batch 12/64 loss: -2.9641246795654297
Batch 13/64 loss: -2.6393566131591797
Batch 14/64 loss: -2.9751815795898438
Batch 15/64 loss: -2.593660354614258
Batch 16/64 loss: -2.7796669006347656
Batch 17/64 loss: -2.662252426147461
Batch 18/64 loss: -2.549576759338379
Batch 19/64 loss: -2.885232925415039
Batch 20/64 loss: -2.7671995162963867
Batch 21/64 loss: -2.670299530029297
Batch 22/64 loss: -2.9077072143554688
Batch 23/64 loss: -2.709627151489258
Batch 24/64 loss: -2.5532703399658203
Batch 25/64 loss: -2.96584415435791
Batch 26/64 loss: -2.51043701171875
Batch 27/64 loss: -2.8352432250976562
Batch 28/64 loss: -2.744553565979004
Batch 29/64 loss: -2.7951736450195312
Batch 30/64 loss: -2.774031639099121
Batch 31/64 loss: -2.758175849914551
Batch 32/64 loss: -2.31795597076416
Batch 33/64 loss: -3.05092716217041
Batch 34/64 loss: -2.6784114837646484
Batch 35/64 loss: -2.5418195724487305
Batch 36/64 loss: -2.653487205505371
Batch 37/64 loss: -2.7381153106689453
Batch 38/64 loss: -2.277083396911621
Batch 39/64 loss: -2.6417903900146484
Batch 40/64 loss: -2.366039276123047
Batch 41/64 loss: -2.3438892364501953
Batch 42/64 loss: -2.8849496841430664
Batch 43/64 loss: -2.6204051971435547
Batch 44/64 loss: -2.888310432434082
Batch 45/64 loss: -2.8490333557128906
Batch 46/64 loss: -2.8619632720947266
Batch 47/64 loss: -2.914407730102539
Batch 48/64 loss: -1.4621086120605469
Batch 49/64 loss: -2.902956008911133
Batch 50/64 loss: -2.4582414627075195
Batch 51/64 loss: -2.921261787414551
Batch 52/64 loss: -1.6963462829589844
Batch 53/64 loss: -2.9576473236083984
Batch 54/64 loss: -2.7965354919433594
Batch 55/64 loss: -2.7870101928710938
Batch 56/64 loss: -2.5976572036743164
Batch 57/64 loss: -2.4713573455810547
Batch 58/64 loss: -3.0349273681640625
Batch 59/64 loss: -2.064999580383301
Batch 60/64 loss: -2.042816162109375
Batch 61/64 loss: -2.957509994506836
Batch 62/64 loss: -2.9272050857543945
Batch 63/64 loss: -3.16524600982666
Batch 64/64 loss: -7.299509525299072
Epoch 422  Train loss: -2.696420764923096  Val loss: -2.993150979792539
Epoch 423
-------------------------------
Batch 1/64 loss: -2.749039649963379
Batch 2/64 loss: -2.7051963806152344
Batch 3/64 loss: -2.5514516830444336
Batch 4/64 loss: -2.8417539596557617
Batch 5/64 loss: -2.914402961730957
Batch 6/64 loss: -2.917607307434082
Batch 7/64 loss: -2.949970245361328
Batch 8/64 loss: -2.974062919616699
Batch 9/64 loss: -2.7717323303222656
Batch 10/64 loss: -2.8842926025390625
Batch 11/64 loss: -2.979031562805176
Batch 12/64 loss: -2.8095340728759766
Batch 13/64 loss: -3.005303382873535
Batch 14/64 loss: -2.978729248046875
Batch 15/64 loss: -2.8879690170288086
Batch 16/64 loss: -2.842538833618164
Batch 17/64 loss: -2.704707145690918
Batch 18/64 loss: -2.892812728881836
Batch 19/64 loss: -2.784844398498535
Batch 20/64 loss: -2.9131221771240234
Batch 21/64 loss: -2.488370895385742
Batch 22/64 loss: -2.9298133850097656
Batch 23/64 loss: -2.8601417541503906
Batch 24/64 loss: -2.6569366455078125
Batch 25/64 loss: -2.8624610900878906
Batch 26/64 loss: -2.618594169616699
Batch 27/64 loss: -2.7812604904174805
Batch 28/64 loss: -2.960574150085449
Batch 29/64 loss: -2.991109848022461
Batch 30/64 loss: -2.309267044067383
Batch 31/64 loss: -2.4457693099975586
Batch 32/64 loss: -2.0983285903930664
Batch 33/64 loss: -2.753983497619629
Batch 34/64 loss: -2.902848243713379
Batch 35/64 loss: -2.6259021759033203
Batch 36/64 loss: -2.9216814041137695
Batch 37/64 loss: -2.679523468017578
Batch 38/64 loss: -2.8173532485961914
Batch 39/64 loss: -2.3674278259277344
Batch 40/64 loss: -2.374650001525879
Batch 41/64 loss: -2.399290084838867
Batch 42/64 loss: -2.5664892196655273
Batch 43/64 loss: -2.8527421951293945
Batch 44/64 loss: -2.538553237915039
Batch 45/64 loss: -2.850156784057617
Batch 46/64 loss: -2.6299610137939453
Batch 47/64 loss: -1.871042251586914
Batch 48/64 loss: -2.5020084381103516
Batch 49/64 loss: -2.7804994583129883
Batch 50/64 loss: -2.264577865600586
Batch 51/64 loss: -2.6418371200561523
Batch 52/64 loss: -1.9851875305175781
Batch 53/64 loss: -2.617128372192383
Batch 54/64 loss: -2.7210330963134766
Batch 55/64 loss: -2.5740976333618164
Batch 56/64 loss: -2.7153806686401367
Batch 57/64 loss: -2.8494510650634766
Batch 58/64 loss: -2.697267532348633
Batch 59/64 loss: -2.603578567504883
Batch 60/64 loss: -2.77779483795166
Batch 61/64 loss: -2.8366193771362305
Batch 62/64 loss: -2.859127998352051
Batch 63/64 loss: -3.036576271057129
Batch 64/64 loss: -7.2116875648498535
Epoch 423  Train loss: -2.7620904492396936  Val loss: -2.969079348639524
Epoch 424
-------------------------------
Batch 1/64 loss: -2.589334487915039
Batch 2/64 loss: -2.79038143157959
Batch 3/64 loss: -2.8980283737182617
Batch 4/64 loss: -2.85684871673584
Batch 5/64 loss: -2.825018882751465
Batch 6/64 loss: -2.8089723587036133
Batch 7/64 loss: -2.65230655670166
Batch 8/64 loss: -3.048768997192383
Batch 9/64 loss: -2.1843671798706055
Batch 10/64 loss: -2.951663017272949
Batch 11/64 loss: -2.8942203521728516
Batch 12/64 loss: -2.844283103942871
Batch 13/64 loss: -2.9628190994262695
Batch 14/64 loss: -2.4092483520507812
Batch 15/64 loss: -2.770869255065918
Batch 16/64 loss: -2.6952829360961914
Batch 17/64 loss: -2.7236671447753906
Batch 18/64 loss: -2.8047399520874023
Batch 19/64 loss: -2.8946266174316406
Batch 20/64 loss: -2.277393341064453
Batch 21/64 loss: -2.694951057434082
Batch 22/64 loss: -2.4367141723632812
Batch 23/64 loss: -2.6551733016967773
Batch 24/64 loss: -2.8674755096435547
Batch 25/64 loss: -2.1603736877441406
Batch 26/64 loss: -2.8517494201660156
Batch 27/64 loss: -2.9010848999023438
Batch 28/64 loss: -2.782345771789551
Batch 29/64 loss: -2.9166250228881836
Batch 30/64 loss: -2.926027297973633
Batch 31/64 loss: -2.955465316772461
Batch 32/64 loss: -2.8977489471435547
Batch 33/64 loss: -2.7457237243652344
Batch 34/64 loss: -2.6172733306884766
Batch 35/64 loss: -2.3119115829467773
Batch 36/64 loss: -2.94350528717041
Batch 37/64 loss: -2.785184860229492
Batch 38/64 loss: -2.829495429992676
Batch 39/64 loss: -2.817564010620117
Batch 40/64 loss: -3.1601152420043945
Batch 41/64 loss: -2.7604827880859375
Batch 42/64 loss: -2.70040225982666
Batch 43/64 loss: -2.2083702087402344
Batch 44/64 loss: -2.9995222091674805
Batch 45/64 loss: -3.0483999252319336
Batch 46/64 loss: -2.891629219055176
Batch 47/64 loss: -2.878459930419922
Batch 48/64 loss: -2.5423269271850586
Batch 49/64 loss: -2.9501380920410156
Batch 50/64 loss: -2.833113670349121
Batch 51/64 loss: -3.0334949493408203
Batch 52/64 loss: -2.622690200805664
Batch 53/64 loss: -3.060333251953125
Batch 54/64 loss: -2.9942779541015625
Batch 55/64 loss: -2.237992286682129
Batch 56/64 loss: -2.9184484481811523
Batch 57/64 loss: -2.8203439712524414
Batch 58/64 loss: -2.826923370361328
Batch 59/64 loss: -2.757394790649414
Batch 60/64 loss: -3.007354736328125
Batch 61/64 loss: -2.640562057495117
Batch 62/64 loss: -2.7930221557617188
Batch 63/64 loss: -1.8142414093017578
Batch 64/64 loss: -7.3293256759643555
Epoch 424  Train loss: -2.8074708564608706  Val loss: -2.991254550894511
Epoch 425
-------------------------------
Batch 1/64 loss: -2.6991472244262695
Batch 2/64 loss: -2.979959487915039
Batch 3/64 loss: -2.7648305892944336
Batch 4/64 loss: -2.0607948303222656
Batch 5/64 loss: -2.9797067642211914
Batch 6/64 loss: -2.448248863220215
Batch 7/64 loss: -2.520883560180664
Batch 8/64 loss: -2.891450881958008
Batch 9/64 loss: -2.607480049133301
Batch 10/64 loss: -2.2803125381469727
Batch 11/64 loss: -2.329853057861328
Batch 12/64 loss: -2.834343910217285
Batch 13/64 loss: -2.5598831176757812
Batch 14/64 loss: -3.0865392684936523
Batch 15/64 loss: -2.295309066772461
Batch 16/64 loss: -2.767022132873535
Batch 17/64 loss: -2.8563060760498047
Batch 18/64 loss: -2.5985403060913086
Batch 19/64 loss: -2.747333526611328
Batch 20/64 loss: -2.9634580612182617
Batch 21/64 loss: -2.8333988189697266
Batch 22/64 loss: -3.0062694549560547
Batch 23/64 loss: -2.646677017211914
Batch 24/64 loss: -2.856204032897949
Batch 25/64 loss: -2.8242902755737305
Batch 26/64 loss: -2.830667495727539
Batch 27/64 loss: -2.2526769638061523
Batch 28/64 loss: -2.5178909301757812
Batch 29/64 loss: -2.813920021057129
Batch 30/64 loss: -2.5946455001831055
Batch 31/64 loss: -2.6801929473876953
Batch 32/64 loss: -2.906055450439453
Batch 33/64 loss: -1.6268835067749023
Batch 34/64 loss: -2.4690628051757812
Batch 35/64 loss: -2.6226720809936523
Batch 36/64 loss: -2.759799003601074
Batch 37/64 loss: -3.0113582611083984
Batch 38/64 loss: -2.9488086700439453
Batch 39/64 loss: -3.120089530944824
Batch 40/64 loss: -2.7139663696289062
Batch 41/64 loss: -2.567167282104492
Batch 42/64 loss: -2.9247398376464844
Batch 43/64 loss: -2.4695634841918945
Batch 44/64 loss: -2.9365921020507812
Batch 45/64 loss: -3.0065345764160156
Batch 46/64 loss: -2.10971736907959
Batch 47/64 loss: -2.9225778579711914
Batch 48/64 loss: -3.0923233032226562
Batch 49/64 loss: -2.853954315185547
Batch 50/64 loss: -2.928802490234375
Batch 51/64 loss: -2.931288719177246
Batch 52/64 loss: -2.782271385192871
Batch 53/64 loss: -2.925217628479004
Batch 54/64 loss: -2.687863349914551
Batch 55/64 loss: -2.894291877746582
Batch 56/64 loss: -2.7121877670288086
Batch 57/64 loss: -2.8357725143432617
Batch 58/64 loss: -2.6574440002441406
Batch 59/64 loss: -2.352919578552246
Batch 60/64 loss: -2.6767873764038086
Batch 61/64 loss: -2.95822811126709
Batch 62/64 loss: -3.1540536880493164
Batch 63/64 loss: -2.8590545654296875
Batch 64/64 loss: -7.5586748123168945
Epoch 425  Train loss: -2.779847713545257  Val loss: -3.136042735830615
Epoch 426
-------------------------------
Batch 1/64 loss: -2.750271797180176
Batch 2/64 loss: -2.856901168823242
Batch 3/64 loss: -3.0812883377075195
Batch 4/64 loss: -2.347087860107422
Batch 5/64 loss: -2.710055351257324
Batch 6/64 loss: -3.0694684982299805
Batch 7/64 loss: -2.637178421020508
Batch 8/64 loss: -2.753840446472168
Batch 9/64 loss: -3.074093818664551
Batch 10/64 loss: -2.8963327407836914
Batch 11/64 loss: -2.6463375091552734
Batch 12/64 loss: -3.0451583862304688
Batch 13/64 loss: -2.6257028579711914
Batch 14/64 loss: -2.9146127700805664
Batch 15/64 loss: -2.822564125061035
Batch 16/64 loss: -2.533926010131836
Batch 17/64 loss: -3.076601982116699
Batch 18/64 loss: -2.765594482421875
Batch 19/64 loss: -2.933563232421875
Batch 20/64 loss: -2.3568248748779297
Batch 21/64 loss: -2.494980812072754
Batch 22/64 loss: -2.575963020324707
Batch 23/64 loss: -2.9064626693725586
Batch 24/64 loss: -3.108036994934082
Batch 25/64 loss: -2.488840103149414
Batch 26/64 loss: -1.4849815368652344
Batch 27/64 loss: -2.3651676177978516
Batch 28/64 loss: -3.0395278930664062
Batch 29/64 loss: -2.8826236724853516
Batch 30/64 loss: -2.6932897567749023
Batch 31/64 loss: -2.9350833892822266
Batch 32/64 loss: -3.1050424575805664
Batch 33/64 loss: -2.8827028274536133
Batch 34/64 loss: -2.9896364212036133
Batch 35/64 loss: -3.0455474853515625
Batch 36/64 loss: -2.6929216384887695
Batch 37/64 loss: -3.071229934692383
Batch 38/64 loss: -2.8290185928344727
Batch 39/64 loss: -2.83689022064209
Batch 40/64 loss: -2.7814178466796875
Batch 41/64 loss: -2.7588891983032227
Batch 42/64 loss: -2.461337089538574
Batch 43/64 loss: -2.475811004638672
Batch 44/64 loss: -3.0654592514038086
Batch 45/64 loss: -3.0052337646484375
Batch 46/64 loss: -3.0393905639648438
Batch 47/64 loss: -2.721294403076172
Batch 48/64 loss: -3.0803117752075195
Batch 49/64 loss: -2.4265012741088867
Batch 50/64 loss: -2.8867855072021484
Batch 51/64 loss: -2.7973413467407227
Batch 52/64 loss: -2.8715248107910156
Batch 53/64 loss: -2.8524513244628906
Batch 54/64 loss: -3.1816492080688477
Batch 55/64 loss: -2.9586544036865234
Batch 56/64 loss: -3.0421266555786133
Batch 57/64 loss: -3.04055118560791
Batch 58/64 loss: -2.8715944290161133
Batch 59/64 loss: -2.908632278442383
Batch 60/64 loss: -2.971590042114258
Batch 61/64 loss: -2.6128854751586914
Batch 62/64 loss: -3.03781795501709
Batch 63/64 loss: -2.816958427429199
Batch 64/64 loss: -7.468951225280762
Epoch 426  Train loss: -2.8642082251754464  Val loss: -3.0881099111026096
Epoch 427
-------------------------------
Batch 1/64 loss: -2.9788427352905273
Batch 2/64 loss: -2.6019487380981445
Batch 3/64 loss: -2.8404998779296875
Batch 4/64 loss: -2.864161491394043
Batch 5/64 loss: -3.0926647186279297
Batch 6/64 loss: -2.854869842529297
Batch 7/64 loss: -2.91487979888916
Batch 8/64 loss: -2.8233489990234375
Batch 9/64 loss: -2.526456832885742
Batch 10/64 loss: -2.502957344055176
Batch 11/64 loss: -2.978501319885254
Batch 12/64 loss: -2.923886299133301
Batch 13/64 loss: -2.879171371459961
Batch 14/64 loss: -2.8926124572753906
Batch 15/64 loss: -2.942715644836426
Batch 16/64 loss: -2.8209400177001953
Batch 17/64 loss: -2.984745979309082
Batch 18/64 loss: -2.974005699157715
Batch 19/64 loss: -3.017885208129883
Batch 20/64 loss: -2.3340883255004883
Batch 21/64 loss: -2.9212169647216797
Batch 22/64 loss: -2.8069982528686523
Batch 23/64 loss: -3.0577640533447266
Batch 24/64 loss: -2.7974815368652344
Batch 25/64 loss: -2.9789934158325195
Batch 26/64 loss: -2.879696846008301
Batch 27/64 loss: -2.9234066009521484
Batch 28/64 loss: -2.9687185287475586
Batch 29/64 loss: -2.789182662963867
Batch 30/64 loss: -3.0381011962890625
Batch 31/64 loss: -3.1900320053100586
Batch 32/64 loss: -2.870542526245117
Batch 33/64 loss: -2.755338668823242
Batch 34/64 loss: -2.640498161315918
Batch 35/64 loss: -3.097588539123535
Batch 36/64 loss: -2.392099380493164
Batch 37/64 loss: -2.870332717895508
Batch 38/64 loss: -2.7068681716918945
Batch 39/64 loss: -2.9113235473632812
Batch 40/64 loss: -2.974720001220703
Batch 41/64 loss: -2.6934728622436523
Batch 42/64 loss: -2.1727190017700195
Batch 43/64 loss: -3.0887880325317383
Batch 44/64 loss: -3.1646623611450195
Batch 45/64 loss: -2.845993995666504
Batch 46/64 loss: -2.8452444076538086
Batch 47/64 loss: -2.8121461868286133
Batch 48/64 loss: -3.0043907165527344
Batch 49/64 loss: -3.1003189086914062
Batch 50/64 loss: -2.9960412979125977
Batch 51/64 loss: -2.572115898132324
Batch 52/64 loss: -2.886465072631836
Batch 53/64 loss: -2.797433853149414
Batch 54/64 loss: -3.032832145690918
Batch 55/64 loss: -3.038572311401367
Batch 56/64 loss: -2.5817432403564453
Batch 57/64 loss: -3.0844717025756836
Batch 58/64 loss: -3.025567054748535
Batch 59/64 loss: -2.6278390884399414
Batch 60/64 loss: -2.8588829040527344
Batch 61/64 loss: -2.5823707580566406
Batch 62/64 loss: -2.6876821517944336
Batch 63/64 loss: -2.696277618408203
Batch 64/64 loss: -7.046327590942383
Epoch 427  Train loss: -2.898837078318876  Val loss: -3.1482151857356437
Epoch 428
-------------------------------
Batch 1/64 loss: -3.044194221496582
Batch 2/64 loss: -3.111024856567383
Batch 3/64 loss: -2.700286865234375
Batch 4/64 loss: -3.139516830444336
Batch 5/64 loss: -3.1254892349243164
Batch 6/64 loss: -2.9490957260131836
Batch 7/64 loss: -2.8022937774658203
Batch 8/64 loss: -2.9350690841674805
Batch 9/64 loss: -2.38407039642334
Batch 10/64 loss: -3.0447025299072266
Batch 11/64 loss: -2.573884963989258
Batch 12/64 loss: -2.909585952758789
Batch 13/64 loss: -2.8487606048583984
Batch 14/64 loss: -2.750276565551758
Batch 15/64 loss: -3.008220672607422
Batch 16/64 loss: -2.553119659423828
Batch 17/64 loss: -2.705465316772461
Batch 18/64 loss: -2.8807525634765625
Batch 19/64 loss: -2.9472579956054688
Batch 20/64 loss: -2.989264488220215
Batch 21/64 loss: -2.840208053588867
Batch 22/64 loss: -3.061552047729492
Batch 23/64 loss: -2.906167984008789
Batch 24/64 loss: -3.0270347595214844
Batch 25/64 loss: -2.1615095138549805
Batch 26/64 loss: -2.8418045043945312
Batch 27/64 loss: -2.8976449966430664
Batch 28/64 loss: -2.9225339889526367
Batch 29/64 loss: -3.0686864852905273
Batch 30/64 loss: -2.788996696472168
Batch 31/64 loss: -3.1762590408325195
Batch 32/64 loss: -2.9293861389160156
Batch 33/64 loss: -3.00881290435791
Batch 34/64 loss: -2.6605710983276367
Batch 35/64 loss: -2.8063459396362305
Batch 36/64 loss: -2.8506383895874023
Batch 37/64 loss: -3.0070619583129883
Batch 38/64 loss: -2.723252296447754
Batch 39/64 loss: -2.9312286376953125
Batch 40/64 loss: -2.617844581604004
Batch 41/64 loss: -2.6907129287719727
Batch 42/64 loss: -2.8888778686523438
Batch 43/64 loss: -2.8620643615722656
Batch 44/64 loss: -2.926753044128418
Batch 45/64 loss: -2.8381271362304688
Batch 46/64 loss: -2.857351303100586
Batch 47/64 loss: -2.29903507232666
Batch 48/64 loss: -2.715404510498047
Batch 49/64 loss: -2.714632987976074
Batch 50/64 loss: -2.954833984375
Batch 51/64 loss: -3.080887794494629
Batch 52/64 loss: -2.9558191299438477
Batch 53/64 loss: -2.8762760162353516
Batch 54/64 loss: -3.14432430267334
Batch 55/64 loss: -2.884702682495117
Batch 56/64 loss: -2.8844528198242188
Batch 57/64 loss: -2.342503547668457
Batch 58/64 loss: -3.020686149597168
Batch 59/64 loss: -3.127450942993164
Batch 60/64 loss: -3.2042341232299805
Batch 61/64 loss: -2.795827865600586
Batch 62/64 loss: -2.915225028991699
Batch 63/64 loss: -3.1559505462646484
Batch 64/64 loss: -7.452916145324707
Epoch 428  Train loss: -2.9232265659407073  Val loss: -3.1852226126234964
Epoch 429
-------------------------------
Batch 1/64 loss: -3.038484573364258
Batch 2/64 loss: -2.900120735168457
Batch 3/64 loss: -2.918668746948242
Batch 4/64 loss: -2.941568374633789
Batch 5/64 loss: -3.030972480773926
Batch 6/64 loss: -2.8544445037841797
Batch 7/64 loss: -2.475858688354492
Batch 8/64 loss: -3.222196578979492
Batch 9/64 loss: -3.058422088623047
Batch 10/64 loss: -2.481062889099121
Batch 11/64 loss: -3.064600944519043
Batch 12/64 loss: -2.860732078552246
Batch 13/64 loss: -2.866929054260254
Batch 14/64 loss: -2.9258861541748047
Batch 15/64 loss: -2.9000396728515625
Batch 16/64 loss: -2.660013198852539
Batch 17/64 loss: -2.495375633239746
Batch 18/64 loss: -3.1319236755371094
Batch 19/64 loss: -3.090060234069824
Batch 20/64 loss: -2.9423627853393555
Batch 21/64 loss: -2.6620988845825195
Batch 22/64 loss: -3.09964656829834
Batch 23/64 loss: -2.547809600830078
Batch 24/64 loss: -3.0440025329589844
Batch 25/64 loss: -3.1696949005126953
Batch 26/64 loss: -3.1712608337402344
Batch 27/64 loss: -2.9055280685424805
Batch 28/64 loss: -3.067103385925293
Batch 29/64 loss: -2.9968366622924805
Batch 30/64 loss: -3.0186328887939453
Batch 31/64 loss: -1.8605718612670898
Batch 32/64 loss: -2.287992477416992
Batch 33/64 loss: -2.991291046142578
Batch 34/64 loss: -2.8875083923339844
Batch 35/64 loss: -2.406388282775879
Batch 36/64 loss: -2.7876691818237305
Batch 37/64 loss: -2.8194332122802734
Batch 38/64 loss: -2.8377389907836914
Batch 39/64 loss: -2.7363414764404297
Batch 40/64 loss: -3.095871925354004
Batch 41/64 loss: -2.7862606048583984
Batch 42/64 loss: -3.068549156188965
Batch 43/64 loss: -2.841510772705078
Batch 44/64 loss: -2.5153274536132812
Batch 45/64 loss: -2.7621641159057617
Batch 46/64 loss: -2.782303810119629
Batch 47/64 loss: -3.207943916320801
Batch 48/64 loss: -2.9724082946777344
Batch 49/64 loss: -2.9418249130249023
Batch 50/64 loss: -2.582758903503418
Batch 51/64 loss: -2.903675079345703
Batch 52/64 loss: -2.4949684143066406
Batch 53/64 loss: -2.899639129638672
Batch 54/64 loss: -2.7007322311401367
Batch 55/64 loss: -2.952786445617676
Batch 56/64 loss: -2.5973806381225586
Batch 57/64 loss: -3.1701574325561523
Batch 58/64 loss: -2.94718074798584
Batch 59/64 loss: -2.9054555892944336
Batch 60/64 loss: -2.956401824951172
Batch 61/64 loss: -2.897602081298828
Batch 62/64 loss: -3.141559600830078
Batch 63/64 loss: -2.9878931045532227
Batch 64/64 loss: -7.488718509674072
Epoch 429  Train loss: -2.9158614495221307  Val loss: -3.154820969833951
Epoch 430
-------------------------------
Batch 1/64 loss: -2.8395118713378906
Batch 2/64 loss: -2.3793725967407227
Batch 3/64 loss: -2.6870384216308594
Batch 4/64 loss: -2.926947593688965
Batch 5/64 loss: -2.61151123046875
Batch 6/64 loss: -3.0211896896362305
Batch 7/64 loss: -2.4201221466064453
Batch 8/64 loss: -2.9751462936401367
Batch 9/64 loss: -2.9616851806640625
Batch 10/64 loss: -2.8990392684936523
Batch 11/64 loss: -2.953786849975586
Batch 12/64 loss: -2.2368698120117188
Batch 13/64 loss: -2.654799461364746
Batch 14/64 loss: -2.5800905227661133
Batch 15/64 loss: -2.796884536743164
Batch 16/64 loss: -3.1768875122070312
Batch 17/64 loss: -2.95644474029541
Batch 18/64 loss: -2.562323570251465
Batch 19/64 loss: -2.766251564025879
Batch 20/64 loss: -2.6210832595825195
Batch 21/64 loss: -2.497063636779785
Batch 22/64 loss: -3.029125213623047
Batch 23/64 loss: -3.1120986938476562
Batch 24/64 loss: -2.6661672592163086
Batch 25/64 loss: -3.121194839477539
Batch 26/64 loss: -3.007340431213379
Batch 27/64 loss: -3.0110960006713867
Batch 28/64 loss: -2.765981674194336
Batch 29/64 loss: -2.9765501022338867
Batch 30/64 loss: -3.087421417236328
Batch 31/64 loss: -1.8041324615478516
Batch 32/64 loss: -2.833341598510742
Batch 33/64 loss: -3.1053390502929688
Batch 34/64 loss: -3.0199851989746094
Batch 35/64 loss: -2.79022216796875
Batch 36/64 loss: -2.9077558517456055
Batch 37/64 loss: -2.9177913665771484
Batch 38/64 loss: -2.890890121459961
Batch 39/64 loss: -2.273378372192383
Batch 40/64 loss: -2.8693132400512695
Batch 41/64 loss: -2.926929473876953
Batch 42/64 loss: -2.866908073425293
Batch 43/64 loss: -3.0364370346069336
Batch 44/64 loss: -2.988104820251465
Batch 45/64 loss: -2.877462387084961
Batch 46/64 loss: -2.7736339569091797
Batch 47/64 loss: -2.7976112365722656
Batch 48/64 loss: -3.0691957473754883
Batch 49/64 loss: -2.65224552154541
Batch 50/64 loss: -3.017552375793457
Batch 51/64 loss: -2.9740114212036133
Batch 52/64 loss: -3.072512626647949
Batch 53/64 loss: -2.9718551635742188
Batch 54/64 loss: -2.680543899536133
Batch 55/64 loss: -2.9949817657470703
Batch 56/64 loss: -3.010128974914551
Batch 57/64 loss: -2.976408004760742
Batch 58/64 loss: -2.706697463989258
Batch 59/64 loss: -3.0229310989379883
Batch 60/64 loss: -3.012683868408203
Batch 61/64 loss: -3.0402326583862305
Batch 62/64 loss: -2.9832000732421875
Batch 63/64 loss: -2.700807571411133
Batch 64/64 loss: -7.4167938232421875
Epoch 430  Train loss: -2.893001496558096  Val loss: -3.169385103835273
Epoch 431
-------------------------------
Batch 1/64 loss: -2.9378604888916016
Batch 2/64 loss: -2.87735652923584
Batch 3/64 loss: -2.4988107681274414
Batch 4/64 loss: -2.9427242279052734
Batch 5/64 loss: -3.069912910461426
Batch 6/64 loss: -2.848724365234375
Batch 7/64 loss: -2.646195411682129
Batch 8/64 loss: -2.983816146850586
Batch 9/64 loss: -2.9911937713623047
Batch 10/64 loss: -3.135420799255371
Batch 11/64 loss: -2.257260322570801
Batch 12/64 loss: -3.013225555419922
Batch 13/64 loss: -2.75445556640625
Batch 14/64 loss: -2.8619518280029297
Batch 15/64 loss: -2.469111442565918
Batch 16/64 loss: -3.001405715942383
Batch 17/64 loss: -2.6958398818969727
Batch 18/64 loss: -3.160031318664551
Batch 19/64 loss: -2.979869842529297
Batch 20/64 loss: -2.4652023315429688
Batch 21/64 loss: -3.1144447326660156
Batch 22/64 loss: -2.8701000213623047
Batch 23/64 loss: -2.970841407775879
Batch 24/64 loss: -2.9392919540405273
Batch 25/64 loss: -2.871603012084961
Batch 26/64 loss: -2.780245780944824
Batch 27/64 loss: -2.764638900756836
Batch 28/64 loss: -3.136021614074707
Batch 29/64 loss: -3.125528335571289
Batch 30/64 loss: -3.1122827529907227
Batch 31/64 loss: -2.771059989929199
Batch 32/64 loss: -3.2099533081054688
Batch 33/64 loss: -3.160747528076172
Batch 34/64 loss: -2.8952808380126953
Batch 35/64 loss: -2.9596290588378906
Batch 36/64 loss: -3.100675582885742
Batch 37/64 loss: -2.6763648986816406
Batch 38/64 loss: -2.1402177810668945
Batch 39/64 loss: -2.9130048751831055
Batch 40/64 loss: -2.8520212173461914
Batch 41/64 loss: -2.925675392150879
Batch 42/64 loss: -2.973761558532715
Batch 43/64 loss: -2.819477081298828
Batch 44/64 loss: -2.9290122985839844
Batch 45/64 loss: -3.112898826599121
Batch 46/64 loss: -3.072634696960449
Batch 47/64 loss: -2.9803237915039062
Batch 48/64 loss: -3.0868873596191406
Batch 49/64 loss: -3.0619916915893555
Batch 50/64 loss: -2.797466278076172
Batch 51/64 loss: -2.260223388671875
Batch 52/64 loss: -2.875490188598633
Batch 53/64 loss: -3.2850728034973145
Batch 54/64 loss: -3.0473690032958984
Batch 55/64 loss: -2.829395294189453
Batch 56/64 loss: -3.016879081726074
Batch 57/64 loss: -3.0189332962036133
Batch 58/64 loss: -2.794863700866699
Batch 59/64 loss: -2.9126272201538086
Batch 60/64 loss: -2.8780603408813477
Batch 61/64 loss: -2.918088912963867
Batch 62/64 loss: -2.6964149475097656
Batch 63/64 loss: -3.0720863342285156
Batch 64/64 loss: -7.313089370727539
Epoch 431  Train loss: -2.945957228716682  Val loss: -3.1916818127189717
Epoch 432
-------------------------------
Batch 1/64 loss: -2.8752946853637695
Batch 2/64 loss: -2.8052406311035156
Batch 3/64 loss: -3.066664695739746
Batch 4/64 loss: -3.068208694458008
Batch 5/64 loss: -2.870656967163086
Batch 6/64 loss: -2.9265480041503906
Batch 7/64 loss: -2.9692020416259766
Batch 8/64 loss: -2.3663711547851562
Batch 9/64 loss: -2.904094696044922
Batch 10/64 loss: -2.921603202819824
Batch 11/64 loss: -3.091000556945801
Batch 12/64 loss: -3.091141700744629
Batch 13/64 loss: -2.8223085403442383
Batch 14/64 loss: -2.980844497680664
Batch 15/64 loss: -2.875521659851074
Batch 16/64 loss: -2.7872610092163086
Batch 17/64 loss: -3.1082029342651367
Batch 18/64 loss: -2.8794469833374023
Batch 19/64 loss: -2.9133996963500977
Batch 20/64 loss: -2.8112869262695312
Batch 21/64 loss: -2.611583709716797
Batch 22/64 loss: -3.130599021911621
Batch 23/64 loss: -2.688589096069336
Batch 24/64 loss: -3.0020694732666016
Batch 25/64 loss: -3.019394874572754
Batch 26/64 loss: -2.6321887969970703
Batch 27/64 loss: -2.8914575576782227
Batch 28/64 loss: -2.3583030700683594
Batch 29/64 loss: -3.1431713104248047
Batch 30/64 loss: -2.7831735610961914
Batch 31/64 loss: -3.0081615447998047
Batch 32/64 loss: -2.9590530395507812
Batch 33/64 loss: -2.5996150970458984
Batch 34/64 loss: -3.140007972717285
Batch 35/64 loss: -2.6074934005737305
Batch 36/64 loss: -2.9670944213867188
Batch 37/64 loss: -2.623410224914551
Batch 38/64 loss: -2.8728132247924805
Batch 39/64 loss: -3.057889938354492
Batch 40/64 loss: -2.8295536041259766
Batch 41/64 loss: -3.099642753601074
Batch 42/64 loss: -3.21390438079834
Batch 43/64 loss: -2.809779167175293
Batch 44/64 loss: -3.0768823623657227
Batch 45/64 loss: -2.8508777618408203
Batch 46/64 loss: -3.093926429748535
Batch 47/64 loss: -2.7448225021362305
Batch 48/64 loss: -2.861395835876465
Batch 49/64 loss: -2.931093215942383
Batch 50/64 loss: -2.3498992919921875
Batch 51/64 loss: -3.15352725982666
Batch 52/64 loss: -2.9112443923950195
Batch 53/64 loss: -3.045534133911133
Batch 54/64 loss: -2.8150901794433594
Batch 55/64 loss: -2.874516487121582
Batch 56/64 loss: -3.0560150146484375
Batch 57/64 loss: -3.0848264694213867
Batch 58/64 loss: -2.853250503540039
Batch 59/64 loss: -2.9220943450927734
Batch 60/64 loss: -3.0203323364257812
Batch 61/64 loss: -3.186995506286621
Batch 62/64 loss: -3.1330413818359375
Batch 63/64 loss: -2.461644172668457
Batch 64/64 loss: -7.348148345947266
Epoch 432  Train loss: -2.9509234409706266  Val loss: -3.2343263658870947
Epoch 433
-------------------------------
Batch 1/64 loss: -2.882573127746582
Batch 2/64 loss: -2.8286209106445312
Batch 3/64 loss: -3.0231151580810547
Batch 4/64 loss: -2.5620431900024414
Batch 5/64 loss: -2.765713691711426
Batch 6/64 loss: -2.7974720001220703
Batch 7/64 loss: -2.7292842864990234
Batch 8/64 loss: -3.0867433547973633
Batch 9/64 loss: -1.8405733108520508
Batch 10/64 loss: -2.947157859802246
Batch 11/64 loss: -2.9531021118164062
Batch 12/64 loss: -2.9286375045776367
Batch 13/64 loss: -2.9445695877075195
Batch 14/64 loss: -2.8009634017944336
Batch 15/64 loss: -2.9726686477661133
Batch 16/64 loss: -3.080716133117676
Batch 17/64 loss: -3.069878578186035
Batch 18/64 loss: -2.9492969512939453
Batch 19/64 loss: -2.832639694213867
Batch 20/64 loss: -3.0818328857421875
Batch 21/64 loss: -3.079387664794922
Batch 22/64 loss: -2.984042167663574
Batch 23/64 loss: -2.880305290222168
Batch 24/64 loss: -2.8318729400634766
Batch 25/64 loss: -2.9194812774658203
Batch 26/64 loss: -2.9336986541748047
Batch 27/64 loss: -2.748845100402832
Batch 28/64 loss: -3.108356475830078
Batch 29/64 loss: -2.640380859375
Batch 30/64 loss: -3.145472526550293
Batch 31/64 loss: -2.7702836990356445
Batch 32/64 loss: -3.0291366577148438
Batch 33/64 loss: -3.0385379791259766
Batch 34/64 loss: -2.851531982421875
Batch 35/64 loss: -3.0044450759887695
Batch 36/64 loss: -3.0525875091552734
Batch 37/64 loss: -3.2045068740844727
Batch 38/64 loss: -3.037862777709961
Batch 39/64 loss: -2.206918716430664
Batch 40/64 loss: -3.0619258880615234
Batch 41/64 loss: -3.132282257080078
Batch 42/64 loss: -2.955185890197754
Batch 43/64 loss: -2.797734260559082
Batch 44/64 loss: -2.9802093505859375
Batch 45/64 loss: -2.976344108581543
Batch 46/64 loss: -2.5486268997192383
Batch 47/64 loss: -2.994450569152832
Batch 48/64 loss: -2.827874183654785
Batch 49/64 loss: -2.736631393432617
Batch 50/64 loss: -3.0183162689208984
Batch 51/64 loss: -3.168063163757324
Batch 52/64 loss: -3.056558609008789
Batch 53/64 loss: -3.09710693359375
Batch 54/64 loss: -3.0650711059570312
Batch 55/64 loss: -3.0978527069091797
Batch 56/64 loss: -3.0703554153442383
Batch 57/64 loss: -3.0413990020751953
Batch 58/64 loss: -3.058424949645996
Batch 59/64 loss: -3.119662284851074
Batch 60/64 loss: -2.8161239624023438
Batch 61/64 loss: -2.376286506652832
Batch 62/64 loss: -3.1134204864501953
Batch 63/64 loss: -3.1344070434570312
Batch 64/64 loss: -7.380107402801514
Epoch 433  Train loss: -2.969798437754313  Val loss: -3.2013600405139204
Epoch 434
-------------------------------
Batch 1/64 loss: -2.511167526245117
Batch 2/64 loss: -3.0088844299316406
Batch 3/64 loss: -2.322218894958496
Batch 4/64 loss: -2.9740495681762695
Batch 5/64 loss: -2.8895864486694336
Batch 6/64 loss: -2.7033004760742188
Batch 7/64 loss: -3.0476837158203125
Batch 8/64 loss: -2.9289722442626953
Batch 9/64 loss: -2.8384790420532227
Batch 10/64 loss: -3.0378570556640625
Batch 11/64 loss: -3.0367794036865234
Batch 12/64 loss: -3.028146743774414
Batch 13/64 loss: -3.1632070541381836
Batch 14/64 loss: -2.9950380325317383
Batch 15/64 loss: -2.964670181274414
Batch 16/64 loss: -2.7336673736572266
Batch 17/64 loss: -2.964226722717285
Batch 18/64 loss: -2.9520559310913086
Batch 19/64 loss: -2.4269027709960938
Batch 20/64 loss: -3.077338218688965
Batch 21/64 loss: -2.515165328979492
Batch 22/64 loss: -2.905059814453125
Batch 23/64 loss: -3.081787109375
Batch 24/64 loss: -3.037069320678711
Batch 25/64 loss: -3.112887382507324
Batch 26/64 loss: -2.835017204284668
Batch 27/64 loss: -2.7187089920043945
Batch 28/64 loss: -3.117279052734375
Batch 29/64 loss: -2.804762840270996
Batch 30/64 loss: -2.926516532897949
Batch 31/64 loss: -3.0281944274902344
Batch 32/64 loss: -3.0369577407836914
Batch 33/64 loss: -2.9598045349121094
Batch 34/64 loss: -2.7340898513793945
Batch 35/64 loss: -3.0754594802856445
Batch 36/64 loss: -2.9955949783325195
Batch 37/64 loss: -2.959782600402832
Batch 38/64 loss: -2.995774269104004
Batch 39/64 loss: -2.875311851501465
Batch 40/64 loss: -3.0519304275512695
Batch 41/64 loss: -3.0342540740966797
Batch 42/64 loss: -3.076068878173828
Batch 43/64 loss: -2.660053253173828
Batch 44/64 loss: -2.8298349380493164
Batch 45/64 loss: -3.000335693359375
Batch 46/64 loss: -2.7860450744628906
Batch 47/64 loss: -2.8455276489257812
Batch 48/64 loss: -2.995469093322754
Batch 49/64 loss: -3.2207956314086914
Batch 50/64 loss: -3.042508125305176
Batch 51/64 loss: -2.738117218017578
Batch 52/64 loss: -2.9611339569091797
Batch 53/64 loss: -3.0315113067626953
Batch 54/64 loss: -3.086503028869629
Batch 55/64 loss: -2.9637317657470703
Batch 56/64 loss: -3.084909439086914
Batch 57/64 loss: -2.998776435852051
Batch 58/64 loss: -3.081462860107422
Batch 59/64 loss: -2.7157154083251953
Batch 60/64 loss: -3.071709632873535
Batch 61/64 loss: -2.2863569259643555
Batch 62/64 loss: -2.781125068664551
Batch 63/64 loss: -3.024594306945801
Batch 64/64 loss: -7.417255401611328
Epoch 434  Train loss: -2.9686410492541744  Val loss: -3.2446108552598463
Epoch 435
-------------------------------
Batch 1/64 loss: -2.951918601989746
Batch 2/64 loss: -2.9788732528686523
Batch 3/64 loss: -3.0210676193237305
Batch 4/64 loss: -3.0137977600097656
Batch 5/64 loss: -2.9374094009399414
Batch 6/64 loss: -3.2591800689697266
Batch 7/64 loss: -2.8258132934570312
Batch 8/64 loss: -3.0788793563842773
Batch 9/64 loss: -3.0191869735717773
Batch 10/64 loss: -2.861985206604004
Batch 11/64 loss: -3.061282157897949
Batch 12/64 loss: -2.9769601821899414
Batch 13/64 loss: -3.2121171951293945
Batch 14/64 loss: -3.2064857482910156
Batch 15/64 loss: -2.9625749588012695
Batch 16/64 loss: -2.977947235107422
Batch 17/64 loss: -2.898134231567383
Batch 18/64 loss: -3.1869306564331055
Batch 19/64 loss: -3.118619918823242
Batch 20/64 loss: -2.7529640197753906
Batch 21/64 loss: -2.8105125427246094
Batch 22/64 loss: -3.1712770462036133
Batch 23/64 loss: -3.0497493743896484
Batch 24/64 loss: -2.8183155059814453
Batch 25/64 loss: -2.769979476928711
Batch 26/64 loss: -2.9832773208618164
Batch 27/64 loss: -2.8515682220458984
Batch 28/64 loss: -2.6361894607543945
Batch 29/64 loss: -2.8018064498901367
Batch 30/64 loss: -3.0832061767578125
Batch 31/64 loss: -2.3985071182250977
Batch 32/64 loss: -2.921201705932617
Batch 33/64 loss: -2.6546812057495117
Batch 34/64 loss: -3.035943031311035
Batch 35/64 loss: -3.0410518646240234
Batch 36/64 loss: -3.103512763977051
Batch 37/64 loss: -3.029313087463379
Batch 38/64 loss: -2.2451744079589844
Batch 39/64 loss: -2.8834943771362305
Batch 40/64 loss: -2.8723201751708984
Batch 41/64 loss: -2.3540048599243164
Batch 42/64 loss: -2.990335464477539
Batch 43/64 loss: -3.0475730895996094
Batch 44/64 loss: -3.0818862915039062
Batch 45/64 loss: -2.985775947570801
Batch 46/64 loss: -3.1247730255126953
Batch 47/64 loss: -2.8276987075805664
Batch 48/64 loss: -2.944798469543457
Batch 49/64 loss: -2.990995407104492
Batch 50/64 loss: -2.960542678833008
Batch 51/64 loss: -2.890904426574707
Batch 52/64 loss: -2.9343881607055664
Batch 53/64 loss: -2.6543025970458984
Batch 54/64 loss: -3.0170516967773438
Batch 55/64 loss: -3.076594352722168
Batch 56/64 loss: -3.0868101119995117
Batch 57/64 loss: -3.0603466033935547
Batch 58/64 loss: -3.096402168273926
Batch 59/64 loss: -2.653557777404785
Batch 60/64 loss: -2.880021095275879
Batch 61/64 loss: -2.3568296432495117
Batch 62/64 loss: -3.162294387817383
Batch 63/64 loss: -2.854816436767578
Batch 64/64 loss: -7.778902053833008
Epoch 435  Train loss: -2.9855700249765436  Val loss: -3.113879973945749
Epoch 436
-------------------------------
Batch 1/64 loss: -3.0930519104003906
Batch 2/64 loss: -3.1251068115234375
Batch 3/64 loss: -2.4323930740356445
Batch 4/64 loss: -1.7973079681396484
Batch 5/64 loss: -2.963170051574707
Batch 6/64 loss: -2.7046470642089844
Batch 7/64 loss: -2.6102333068847656
Batch 8/64 loss: -3.0509557723999023
Batch 9/64 loss: -2.6076507568359375
Batch 10/64 loss: -2.5946245193481445
Batch 11/64 loss: -3.0225934982299805
Batch 12/64 loss: -2.9340696334838867
Batch 13/64 loss: -3.0063514709472656
Batch 14/64 loss: -3.104951858520508
Batch 15/64 loss: -2.7622756958007812
Batch 16/64 loss: -2.691634178161621
Batch 17/64 loss: -2.9733381271362305
Batch 18/64 loss: -3.16329288482666
Batch 19/64 loss: -3.22933292388916
Batch 20/64 loss: -3.1244192123413086
Batch 21/64 loss: -3.0915708541870117
Batch 22/64 loss: -3.0870895385742188
Batch 23/64 loss: -3.102771759033203
Batch 24/64 loss: -2.887714385986328
Batch 25/64 loss: -2.95375919342041
Batch 26/64 loss: -2.6936216354370117
Batch 27/64 loss: -2.7636499404907227
Batch 28/64 loss: -2.7927846908569336
Batch 29/64 loss: -2.900604248046875
Batch 30/64 loss: -3.0533790588378906
Batch 31/64 loss: -3.0002050399780273
Batch 32/64 loss: -2.7591724395751953
Batch 33/64 loss: -2.978276252746582
Batch 34/64 loss: -2.4601869583129883
Batch 35/64 loss: -2.90228271484375
Batch 36/64 loss: -2.7754440307617188
Batch 37/64 loss: -3.0666866302490234
Batch 38/64 loss: -3.038882255554199
Batch 39/64 loss: -3.1029930114746094
Batch 40/64 loss: -2.8688316345214844
Batch 41/64 loss: -2.1808881759643555
Batch 42/64 loss: -3.1135387420654297
Batch 43/64 loss: -2.904353141784668
Batch 44/64 loss: -2.6932363510131836
Batch 45/64 loss: -3.17244815826416
Batch 46/64 loss: -2.9201364517211914
Batch 47/64 loss: -2.83322811126709
Batch 48/64 loss: -2.955864906311035
Batch 49/64 loss: -3.0191268920898438
Batch 50/64 loss: -2.7929792404174805
Batch 51/64 loss: -3.014317512512207
Batch 52/64 loss: -2.9214839935302734
Batch 53/64 loss: -2.6673431396484375
Batch 54/64 loss: -3.118619918823242
Batch 55/64 loss: -2.823847770690918
Batch 56/64 loss: -3.0628557205200195
Batch 57/64 loss: -3.133856773376465
Batch 58/64 loss: -3.137751579284668
Batch 59/64 loss: -3.123978614807129
Batch 60/64 loss: -3.067026138305664
Batch 61/64 loss: -2.079655647277832
Batch 62/64 loss: -2.9666976928710938
Batch 63/64 loss: -2.9059572219848633
Batch 64/64 loss: -7.47019100189209
Epoch 436  Train loss: -2.9409120335298424  Val loss: -3.25144968983234
Epoch 437
-------------------------------
Batch 1/64 loss: -2.968695640563965
Batch 2/64 loss: -2.7339677810668945
Batch 3/64 loss: -3.019235610961914
Batch 4/64 loss: -3.049675941467285
Batch 5/64 loss: -2.746443748474121
Batch 6/64 loss: -2.6116209030151367
Batch 7/64 loss: -2.79410457611084
Batch 8/64 loss: -2.305967330932617
Batch 9/64 loss: -3.117457389831543
Batch 10/64 loss: -3.0836381912231445
Batch 11/64 loss: -2.8696517944335938
Batch 12/64 loss: -3.144232749938965
Batch 13/64 loss: -3.0810728073120117
Batch 14/64 loss: -2.5829858779907227
Batch 15/64 loss: -3.005040168762207
Batch 16/64 loss: -2.848782539367676
Batch 17/64 loss: -2.8062171936035156
Batch 18/64 loss: -3.0170021057128906
Batch 19/64 loss: -2.9253177642822266
Batch 20/64 loss: -3.0926132202148438
Batch 21/64 loss: -3.1829681396484375
Batch 22/64 loss: -3.0105743408203125
Batch 23/64 loss: -2.9215354919433594
Batch 24/64 loss: -2.983487129211426
Batch 25/64 loss: -2.8702163696289062
Batch 26/64 loss: -3.0156707763671875
Batch 27/64 loss: -2.8398141860961914
Batch 28/64 loss: -2.65887451171875
Batch 29/64 loss: -2.053323745727539
Batch 30/64 loss: -2.7984933853149414
Batch 31/64 loss: -2.7624692916870117
Batch 32/64 loss: -3.0313186645507812
Batch 33/64 loss: -2.8508377075195312
Batch 34/64 loss: -2.970071792602539
Batch 35/64 loss: -2.9535818099975586
Batch 36/64 loss: -2.825924873352051
Batch 37/64 loss: -3.002549171447754
Batch 38/64 loss: -2.877016067504883
Batch 39/64 loss: -3.0097150802612305
Batch 40/64 loss: -3.157832145690918
Batch 41/64 loss: -2.9750280380249023
Batch 42/64 loss: -2.889498710632324
Batch 43/64 loss: -2.8964614868164062
Batch 44/64 loss: -2.9479331970214844
Batch 45/64 loss: -3.039560317993164
Batch 46/64 loss: -2.915524482727051
Batch 47/64 loss: -3.041611671447754
Batch 48/64 loss: -2.925497055053711
Batch 49/64 loss: -3.138249397277832
Batch 50/64 loss: -2.8031253814697266
Batch 51/64 loss: -2.6385116577148438
Batch 52/64 loss: -2.9906702041625977
Batch 53/64 loss: -3.0810317993164062
Batch 54/64 loss: -3.109084129333496
Batch 55/64 loss: -2.8888750076293945
Batch 56/64 loss: -3.070767402648926
Batch 57/64 loss: -3.0608158111572266
Batch 58/64 loss: -2.7370214462280273
Batch 59/64 loss: -3.0133113861083984
Batch 60/64 loss: -2.9301576614379883
Batch 61/64 loss: -2.9428720474243164
Batch 62/64 loss: -2.5627365112304688
Batch 63/64 loss: -2.790339469909668
Batch 64/64 loss: -7.48928165435791
Epoch 437  Train loss: -2.958206173017913  Val loss: -3.3293993710652248
Saving best model, epoch: 437
Epoch 438
-------------------------------
Batch 1/64 loss: -2.6579294204711914
Batch 2/64 loss: -2.8480567932128906
Batch 3/64 loss: -3.07733154296875
Batch 4/64 loss: -2.9927453994750977
Batch 5/64 loss: -3.2205581665039062
Batch 6/64 loss: -2.769089698791504
Batch 7/64 loss: -2.708682060241699
Batch 8/64 loss: -3.0791101455688477
Batch 9/64 loss: -3.0293760299682617
Batch 10/64 loss: -2.896373748779297
Batch 11/64 loss: -2.6431102752685547
Batch 12/64 loss: -2.8346872329711914
Batch 13/64 loss: -2.731236457824707
Batch 14/64 loss: -2.8917722702026367
Batch 15/64 loss: -2.9013681411743164
Batch 16/64 loss: -3.088235855102539
Batch 17/64 loss: -2.9363555908203125
Batch 18/64 loss: -3.0264816284179688
Batch 19/64 loss: -2.8474111557006836
Batch 20/64 loss: -2.259707450866699
Batch 21/64 loss: -3.031038284301758
Batch 22/64 loss: -2.9298324584960938
Batch 23/64 loss: -3.039362907409668
Batch 24/64 loss: -2.984018325805664
Batch 25/64 loss: -2.718989372253418
Batch 26/64 loss: -2.6806745529174805
Batch 27/64 loss: -3.1616783142089844
Batch 28/64 loss: -3.0028581619262695
Batch 29/64 loss: -2.976729393005371
Batch 30/64 loss: -2.979517936706543
Batch 31/64 loss: -3.054450035095215
Batch 32/64 loss: -3.175069808959961
Batch 33/64 loss: -2.9410648345947266
Batch 34/64 loss: -2.9654388427734375
Batch 35/64 loss: -1.7982959747314453
Batch 36/64 loss: -3.0596580505371094
Batch 37/64 loss: -3.107274055480957
Batch 38/64 loss: -2.8241844177246094
Batch 39/64 loss: -3.1657934188842773
Batch 40/64 loss: -2.7397499084472656
Batch 41/64 loss: -3.0365781784057617
Batch 42/64 loss: -2.9139537811279297
Batch 43/64 loss: -3.1043596267700195
Batch 44/64 loss: -2.670276641845703
Batch 45/64 loss: -2.7106943130493164
Batch 46/64 loss: -3.123941421508789
Batch 47/64 loss: -3.1114301681518555
Batch 48/64 loss: -2.7598791122436523
Batch 49/64 loss: -3.0071372985839844
Batch 50/64 loss: -3.057684898376465
Batch 51/64 loss: -2.706806182861328
Batch 52/64 loss: -3.1324081420898438
Batch 53/64 loss: -2.8620080947875977
Batch 54/64 loss: -2.822615623474121
Batch 55/64 loss: -2.876114845275879
Batch 56/64 loss: -2.5024051666259766
Batch 57/64 loss: -2.816653251647949
Batch 58/64 loss: -2.990677833557129
Batch 59/64 loss: -3.0161256790161133
Batch 60/64 loss: -2.5885839462280273
Batch 61/64 loss: -2.917268753051758
Batch 62/64 loss: -3.035292625427246
Batch 63/64 loss: -2.6515121459960938
Batch 64/64 loss: -7.405757427215576
Epoch 438  Train loss: -2.945004296770283  Val loss: -3.215165678987798
Epoch 439
-------------------------------
Batch 1/64 loss: -3.0554237365722656
Batch 2/64 loss: -3.164703369140625
Batch 3/64 loss: -3.0668506622314453
Batch 4/64 loss: -2.803071975708008
Batch 5/64 loss: -3.1179027557373047
Batch 6/64 loss: -2.934697151184082
Batch 7/64 loss: -2.9938669204711914
Batch 8/64 loss: -3.0255985260009766
Batch 9/64 loss: -2.9806413650512695
Batch 10/64 loss: -2.8206329345703125
Batch 11/64 loss: -3.155545234680176
Batch 12/64 loss: -2.8901796340942383
Batch 13/64 loss: -2.9670419692993164
Batch 14/64 loss: -2.9862937927246094
Batch 15/64 loss: -2.3610382080078125
Batch 16/64 loss: -3.011136054992676
Batch 17/64 loss: -2.7647714614868164
Batch 18/64 loss: -2.904268264770508
Batch 19/64 loss: -3.063082695007324
Batch 20/64 loss: -2.875370979309082
Batch 21/64 loss: -2.654155731201172
Batch 22/64 loss: -3.0075178146362305
Batch 23/64 loss: -3.009824752807617
Batch 24/64 loss: -3.016204833984375
Batch 25/64 loss: -2.617856025695801
Batch 26/64 loss: -2.988785743713379
Batch 27/64 loss: -2.5103254318237305
Batch 28/64 loss: -3.1247024536132812
Batch 29/64 loss: -3.0918807983398438
Batch 30/64 loss: -2.733107566833496
Batch 31/64 loss: -2.631260871887207
Batch 32/64 loss: -2.052638053894043
Batch 33/64 loss: -3.0041637420654297
Batch 34/64 loss: -2.8667144775390625
Batch 35/64 loss: -2.786412239074707
Batch 36/64 loss: -3.086817741394043
Batch 37/64 loss: -2.9815454483032227
Batch 38/64 loss: -3.128629684448242
Batch 39/64 loss: -2.8516721725463867
Batch 40/64 loss: -2.852815628051758
Batch 41/64 loss: -2.7674684524536133
Batch 42/64 loss: -3.1307754516601562
Batch 43/64 loss: -2.903641700744629
Batch 44/64 loss: -2.6902008056640625
Batch 45/64 loss: -3.054025650024414
Batch 46/64 loss: -2.673834800720215
Batch 47/64 loss: -2.947115898132324
Batch 48/64 loss: -3.023861885070801
Batch 49/64 loss: -2.9400386810302734
Batch 50/64 loss: -3.0177431106567383
Batch 51/64 loss: -3.035353660583496
Batch 52/64 loss: -2.994288444519043
Batch 53/64 loss: -2.9619884490966797
Batch 54/64 loss: -2.7698402404785156
Batch 55/64 loss: -3.0506505966186523
Batch 56/64 loss: -2.460735321044922
Batch 57/64 loss: -3.129861831665039
Batch 58/64 loss: -2.793562889099121
Batch 59/64 loss: -2.7044811248779297
Batch 60/64 loss: -2.0010643005371094
Batch 61/64 loss: -2.8549251556396484
Batch 62/64 loss: -2.6375856399536133
Batch 63/64 loss: -2.5620737075805664
Batch 64/64 loss: -7.363453388214111
Epoch 439  Train loss: -2.9265389292847876  Val loss: -3.2337182821686734
Epoch 440
-------------------------------
Batch 1/64 loss: -2.435023307800293
Batch 2/64 loss: -2.9158754348754883
Batch 3/64 loss: -2.5382766723632812
Batch 4/64 loss: -3.1254796981811523
Batch 5/64 loss: -3.0538549423217773
Batch 6/64 loss: -2.8447017669677734
Batch 7/64 loss: -2.8118438720703125
Batch 8/64 loss: -3.008686065673828
Batch 9/64 loss: -3.0178003311157227
Batch 10/64 loss: -2.9400405883789062
Batch 11/64 loss: -2.896106719970703
Batch 12/64 loss: -3.0321178436279297
Batch 13/64 loss: -2.9683237075805664
Batch 14/64 loss: -2.908829689025879
Batch 15/64 loss: -2.9619693756103516
Batch 16/64 loss: -3.006561279296875
Batch 17/64 loss: -3.0979413986206055
Batch 18/64 loss: -2.9205703735351562
Batch 19/64 loss: -2.7261152267456055
Batch 20/64 loss: -3.0971460342407227
Batch 21/64 loss: -2.9583654403686523
Batch 22/64 loss: -3.013852119445801
Batch 23/64 loss: -2.3630990982055664
Batch 24/64 loss: -2.9815540313720703
Batch 25/64 loss: -2.774163246154785
Batch 26/64 loss: -2.6452579498291016
Batch 27/64 loss: -3.076535224914551
Batch 28/64 loss: -3.033832550048828
Batch 29/64 loss: -2.8768978118896484
Batch 30/64 loss: -2.7098569869995117
Batch 31/64 loss: -2.9161901473999023
Batch 32/64 loss: -3.053577423095703
Batch 33/64 loss: -2.788909912109375
Batch 34/64 loss: -2.8540525436401367
Batch 35/64 loss: -2.8899335861206055
Batch 36/64 loss: -2.760647773742676
Batch 37/64 loss: -3.0412349700927734
Batch 38/64 loss: -2.168245315551758
Batch 39/64 loss: -2.186532974243164
Batch 40/64 loss: -3.1114015579223633
Batch 41/64 loss: -2.719843864440918
Batch 42/64 loss: -3.026182174682617
Batch 43/64 loss: -3.2081074714660645
Batch 44/64 loss: -2.9012832641601562
Batch 45/64 loss: -2.8870010375976562
Batch 46/64 loss: -2.6094093322753906
Batch 47/64 loss: -2.8488101959228516
Batch 48/64 loss: -3.0643491744995117
Batch 49/64 loss: -3.262803077697754
Batch 50/64 loss: -2.2870101928710938
Batch 51/64 loss: -3.124526023864746
Batch 52/64 loss: -2.9356651306152344
Batch 53/64 loss: -2.231842041015625
Batch 54/64 loss: -2.959528923034668
Batch 55/64 loss: -2.5614442825317383
Batch 56/64 loss: -2.9433536529541016
Batch 57/64 loss: -3.0597381591796875
Batch 58/64 loss: -3.00496768951416
Batch 59/64 loss: -3.0928850173950195
Batch 60/64 loss: -2.615560531616211
Batch 61/64 loss: -3.1745338439941406
Batch 62/64 loss: -3.0215635299682617
Batch 63/64 loss: -2.813680648803711
Batch 64/64 loss: -7.580248832702637
Epoch 440  Train loss: -2.9262851902082856  Val loss: -3.2811613181202683
Epoch 441
-------------------------------
Batch 1/64 loss: -3.040353775024414
Batch 2/64 loss: -3.0244436264038086
Batch 3/64 loss: -2.470404624938965
Batch 4/64 loss: -3.094540596008301
Batch 5/64 loss: -3.142791748046875
Batch 6/64 loss: -2.8188724517822266
Batch 7/64 loss: -2.9296188354492188
Batch 8/64 loss: -2.981656074523926
Batch 9/64 loss: -2.6974258422851562
Batch 10/64 loss: -2.8988447189331055
Batch 11/64 loss: -2.770115852355957
Batch 12/64 loss: -3.160409927368164
Batch 13/64 loss: -2.9433116912841797
Batch 14/64 loss: -1.9529523849487305
Batch 15/64 loss: -2.923419952392578
Batch 16/64 loss: -2.71848201751709
Batch 17/64 loss: -2.825381278991699
Batch 18/64 loss: -2.9599246978759766
Batch 19/64 loss: -2.69403076171875
Batch 20/64 loss: -3.1124038696289062
Batch 21/64 loss: -2.901211738586426
Batch 22/64 loss: -3.081270217895508
Batch 23/64 loss: -3.0312185287475586
Batch 24/64 loss: -3.0775136947631836
Batch 25/64 loss: -2.742849349975586
Batch 26/64 loss: -2.9648704528808594
Batch 27/64 loss: -2.933568000793457
Batch 28/64 loss: -3.095456123352051
Batch 29/64 loss: -3.0205211639404297
Batch 30/64 loss: -3.0042123794555664
Batch 31/64 loss: -2.580082893371582
Batch 32/64 loss: -3.093015670776367
Batch 33/64 loss: -2.9621028900146484
Batch 34/64 loss: -3.0893478393554688
Batch 35/64 loss: -3.0148210525512695
Batch 36/64 loss: -2.7623443603515625
Batch 37/64 loss: -2.8343706130981445
Batch 38/64 loss: -2.9357948303222656
Batch 39/64 loss: -2.9469738006591797
Batch 40/64 loss: -2.930706024169922
Batch 41/64 loss: -3.123048782348633
Batch 42/64 loss: -3.077362060546875
Batch 43/64 loss: -3.138840675354004
Batch 44/64 loss: -2.9777793884277344
Batch 45/64 loss: -2.3190507888793945
Batch 46/64 loss: -2.5784549713134766
Batch 47/64 loss: -2.9654550552368164
Batch 48/64 loss: -3.1151018142700195
Batch 49/64 loss: -3.138570785522461
Batch 50/64 loss: -2.7987022399902344
Batch 51/64 loss: -3.10239315032959
Batch 52/64 loss: -3.00235652923584
Batch 53/64 loss: -2.94423770904541
Batch 54/64 loss: -3.1444835662841797
Batch 55/64 loss: -3.0503244400024414
Batch 56/64 loss: -2.7641067504882812
Batch 57/64 loss: -2.8567914962768555
Batch 58/64 loss: -3.1273880004882812
Batch 59/64 loss: -2.9879636764526367
Batch 60/64 loss: -3.125823974609375
Batch 61/64 loss: -2.754934310913086
Batch 62/64 loss: -3.147515296936035
Batch 63/64 loss: -2.872028350830078
Batch 64/64 loss: -7.650317192077637
Epoch 441  Train loss: -2.9805817734961417  Val loss: -3.2292260894251035
Epoch 442
-------------------------------
Batch 1/64 loss: -3.0648326873779297
Batch 2/64 loss: -2.9456253051757812
Batch 3/64 loss: -2.2367286682128906
Batch 4/64 loss: -2.9533872604370117
Batch 5/64 loss: -2.9524316787719727
Batch 6/64 loss: -2.7194671630859375
Batch 7/64 loss: -3.055150032043457
Batch 8/64 loss: -3.124441146850586
Batch 9/64 loss: -3.043961524963379
Batch 10/64 loss: -2.9766435623168945
Batch 11/64 loss: -3.0176000595092773
Batch 12/64 loss: -2.4012632369995117
Batch 13/64 loss: -3.175752639770508
Batch 14/64 loss: -3.1016807556152344
Batch 15/64 loss: -3.1674575805664062
Batch 16/64 loss: -2.72550106048584
Batch 17/64 loss: -2.2922792434692383
Batch 18/64 loss: -1.886911392211914
Batch 19/64 loss: -3.185972213745117
Batch 20/64 loss: -2.892354965209961
Batch 21/64 loss: -2.8862810134887695
Batch 22/64 loss: -3.022592544555664
Batch 23/64 loss: -2.95913028717041
Batch 24/64 loss: -2.973374366760254
Batch 25/64 loss: -3.1595077514648438
Batch 26/64 loss: -3.0203189849853516
Batch 27/64 loss: -2.656844139099121
Batch 28/64 loss: -2.649594306945801
Batch 29/64 loss: -2.9397716522216797
Batch 30/64 loss: -3.1844587326049805
Batch 31/64 loss: -2.755105972290039
Batch 32/64 loss: -2.9707651138305664
Batch 33/64 loss: -2.898954391479492
Batch 34/64 loss: -2.773261070251465
Batch 35/64 loss: -2.8820600509643555
Batch 36/64 loss: -2.8526782989501953
Batch 37/64 loss: -2.7918262481689453
Batch 38/64 loss: -2.925861358642578
Batch 39/64 loss: -2.9438095092773438
Batch 40/64 loss: -3.0887136459350586
Batch 41/64 loss: -3.0126771926879883
Batch 42/64 loss: -3.002725601196289
Batch 43/64 loss: -2.7641525268554688
Batch 44/64 loss: -2.7456321716308594
Batch 45/64 loss: -2.8708677291870117
Batch 46/64 loss: -2.586236000061035
Batch 47/64 loss: -2.6772689819335938
Batch 48/64 loss: -2.593414306640625
Batch 49/64 loss: -2.998615264892578
Batch 50/64 loss: -2.8020687103271484
Batch 51/64 loss: -2.5587854385375977
Batch 52/64 loss: -2.9223556518554688
Batch 53/64 loss: -2.607682228088379
Batch 54/64 loss: -2.926600456237793
Batch 55/64 loss: -2.680556297302246
Batch 56/64 loss: -3.083019256591797
Batch 57/64 loss: -3.1331968307495117
Batch 58/64 loss: -2.8441333770751953
Batch 59/64 loss: -2.739246368408203
Batch 60/64 loss: -2.932415008544922
Batch 61/64 loss: -3.026155471801758
Batch 62/64 loss: -2.7008256912231445
Batch 63/64 loss: -2.893893241882324
Batch 64/64 loss: -6.855338096618652
Epoch 442  Train loss: -2.9097784939934224  Val loss: -3.12466261558926
Epoch 443
-------------------------------
Batch 1/64 loss: -2.2578039169311523
Batch 2/64 loss: -2.879591941833496
Batch 3/64 loss: -2.665755271911621
Batch 4/64 loss: -2.9892654418945312
Batch 5/64 loss: -3.0342235565185547
Batch 6/64 loss: -2.887681007385254
Batch 7/64 loss: -3.0867996215820312
Batch 8/64 loss: -3.0135135650634766
Batch 9/64 loss: -2.7900381088256836
Batch 10/64 loss: -2.8285675048828125
Batch 11/64 loss: -2.934011459350586
Batch 12/64 loss: -3.0156402587890625
Batch 13/64 loss: -2.8310747146606445
Batch 14/64 loss: -2.728278160095215
Batch 15/64 loss: -2.8572683334350586
Batch 16/64 loss: -3.0450000762939453
Batch 17/64 loss: -3.0664939880371094
Batch 18/64 loss: -2.675600051879883
Batch 19/64 loss: -2.521718978881836
Batch 20/64 loss: -3.1842193603515625
Batch 21/64 loss: -2.9177141189575195
Batch 22/64 loss: -2.793323516845703
Batch 23/64 loss: -2.723208427429199
Batch 24/64 loss: -2.5441932678222656
Batch 25/64 loss: -3.0732765197753906
Batch 26/64 loss: -2.244291305541992
Batch 27/64 loss: -2.944779396057129
Batch 28/64 loss: -2.767533302307129
Batch 29/64 loss: -2.7360734939575195
Batch 30/64 loss: -2.9922266006469727
Batch 31/64 loss: -3.180591583251953
Batch 32/64 loss: -2.747354507446289
Batch 33/64 loss: -2.9160585403442383
Batch 34/64 loss: -2.9692201614379883
Batch 35/64 loss: -2.3612165451049805
Batch 36/64 loss: -3.0698118209838867
Batch 37/64 loss: -2.4257707595825195
Batch 38/64 loss: -2.8535823822021484
Batch 39/64 loss: -2.866299629211426
Batch 40/64 loss: -2.8805532455444336
Batch 41/64 loss: -2.960476875305176
Batch 42/64 loss: -2.843364715576172
Batch 43/64 loss: -2.198702812194824
Batch 44/64 loss: -2.816647529602051
Batch 45/64 loss: -2.97989559173584
Batch 46/64 loss: -2.6702327728271484
Batch 47/64 loss: -2.9200267791748047
Batch 48/64 loss: -2.595308303833008
Batch 49/64 loss: -3.127415657043457
Batch 50/64 loss: -2.9807987213134766
Batch 51/64 loss: -2.730367660522461
Batch 52/64 loss: -2.9068307876586914
Batch 53/64 loss: -2.8462114334106445
Batch 54/64 loss: -2.83992862701416
Batch 55/64 loss: -2.6246747970581055
Batch 56/64 loss: -3.0940752029418945
Batch 57/64 loss: -2.6640872955322266
Batch 58/64 loss: -3.07586669921875
Batch 59/64 loss: -3.0349788665771484
Batch 60/64 loss: -3.100094795227051
Batch 61/64 loss: -2.978888511657715
Batch 62/64 loss: -3.0374889373779297
Batch 63/64 loss: -3.0760879516601562
Batch 64/64 loss: -7.377309322357178
Epoch 443  Train loss: -2.9009420824985876  Val loss: -3.233548377387712
Epoch 444
-------------------------------
Batch 1/64 loss: -2.9942455291748047
Batch 2/64 loss: -2.7859582901000977
Batch 3/64 loss: -2.8347368240356445
Batch 4/64 loss: -2.6619014739990234
Batch 5/64 loss: -2.741694450378418
Batch 6/64 loss: -3.12624454498291
Batch 7/64 loss: -2.695619583129883
Batch 8/64 loss: -2.994351387023926
Batch 9/64 loss: -2.97406005859375
Batch 10/64 loss: -3.109860420227051
Batch 11/64 loss: -3.0485029220581055
Batch 12/64 loss: -3.0785951614379883
Batch 13/64 loss: -2.9802074432373047
Batch 14/64 loss: -2.705678939819336
Batch 15/64 loss: -2.9227781295776367
Batch 16/64 loss: -2.6815853118896484
Batch 17/64 loss: -3.070526123046875
Batch 18/64 loss: -2.553030014038086
Batch 19/64 loss: -3.062417984008789
Batch 20/64 loss: -3.044260025024414
Batch 21/64 loss: -2.9540748596191406
Batch 22/64 loss: -2.1283140182495117
Batch 23/64 loss: -2.7971878051757812
Batch 24/64 loss: -2.9555540084838867
Batch 25/64 loss: -3.0717430114746094
Batch 26/64 loss: -2.6276798248291016
Batch 27/64 loss: -2.969930648803711
Batch 28/64 loss: -2.719508171081543
Batch 29/64 loss: -2.9453582763671875
Batch 30/64 loss: -2.902132034301758
Batch 31/64 loss: -2.726015090942383
Batch 32/64 loss: -2.9982709884643555
Batch 33/64 loss: -2.4515018463134766
Batch 34/64 loss: -2.999380111694336
Batch 35/64 loss: -2.8375253677368164
Batch 36/64 loss: -2.6072206497192383
Batch 37/64 loss: -2.718534469604492
Batch 38/64 loss: -2.7917919158935547
Batch 39/64 loss: -3.0735368728637695
Batch 40/64 loss: -2.966294288635254
Batch 41/64 loss: -2.88299560546875
Batch 42/64 loss: -2.8388137817382812
Batch 43/64 loss: -3.030588150024414
Batch 44/64 loss: -2.9768638610839844
Batch 45/64 loss: -3.1169662475585938
Batch 46/64 loss: -3.2579636573791504
Batch 47/64 loss: -2.811656951904297
Batch 48/64 loss: -2.8966245651245117
Batch 49/64 loss: -2.853814125061035
Batch 50/64 loss: -2.975653648376465
Batch 51/64 loss: -2.927689552307129
Batch 52/64 loss: -2.894040107727051
Batch 53/64 loss: -2.7409286499023438
Batch 54/64 loss: -2.96356201171875
Batch 55/64 loss: -3.1245641708374023
Batch 56/64 loss: -2.863234519958496
Batch 57/64 loss: -2.980044364929199
Batch 58/64 loss: -2.1567153930664062
Batch 59/64 loss: -2.9422969818115234
Batch 60/64 loss: -2.687467575073242
Batch 61/64 loss: -2.829878807067871
Batch 62/64 loss: -2.897481918334961
Batch 63/64 loss: -2.7967796325683594
Batch 64/64 loss: -7.5597453117370605
Epoch 444  Train loss: -2.924301837472355  Val loss: -3.290486627427983
Epoch 445
-------------------------------
Batch 1/64 loss: -2.9049081802368164
Batch 2/64 loss: -2.4679813385009766
Batch 3/64 loss: -3.25681209564209
Batch 4/64 loss: -2.734002113342285
Batch 5/64 loss: -3.1293773651123047
Batch 6/64 loss: -3.0253067016601562
Batch 7/64 loss: -2.8537845611572266
Batch 8/64 loss: -3.0248594284057617
Batch 9/64 loss: -2.87725830078125
Batch 10/64 loss: -1.7240791320800781
Batch 11/64 loss: -2.943697929382324
Batch 12/64 loss: -2.8137378692626953
Batch 13/64 loss: -2.792804718017578
Batch 14/64 loss: -3.0190963745117188
Batch 15/64 loss: -2.6723642349243164
Batch 16/64 loss: -2.835911750793457
Batch 17/64 loss: -2.6699676513671875
Batch 18/64 loss: -2.6465225219726562
Batch 19/64 loss: -3.1040029525756836
Batch 20/64 loss: -3.1139793395996094
Batch 21/64 loss: -2.933422088623047
Batch 22/64 loss: -2.800351142883301
Batch 23/64 loss: -2.9437685012817383
Batch 24/64 loss: -3.125652313232422
Batch 25/64 loss: -3.059300422668457
Batch 26/64 loss: -3.085897445678711
Batch 27/64 loss: -2.981008529663086
Batch 28/64 loss: -2.5518875122070312
Batch 29/64 loss: -3.062716484069824
Batch 30/64 loss: -3.091165542602539
Batch 31/64 loss: -2.8272104263305664
Batch 32/64 loss: -2.900259017944336
Batch 33/64 loss: -2.826688766479492
Batch 34/64 loss: -3.0884456634521484
Batch 35/64 loss: -2.911052703857422
Batch 36/64 loss: -3.011180877685547
Batch 37/64 loss: -2.914358139038086
Batch 38/64 loss: -3.033376693725586
Batch 39/64 loss: -2.791714668273926
Batch 40/64 loss: -2.921755790710449
Batch 41/64 loss: -2.9951601028442383
Batch 42/64 loss: -2.8538103103637695
Batch 43/64 loss: -3.0397586822509766
Batch 44/64 loss: -3.173039436340332
Batch 45/64 loss: -2.7944374084472656
Batch 46/64 loss: -2.871941566467285
Batch 47/64 loss: -3.004222869873047
Batch 48/64 loss: -2.8185787200927734
Batch 49/64 loss: -2.904247283935547
Batch 50/64 loss: -2.4876699447631836
Batch 51/64 loss: -3.0336132049560547
Batch 52/64 loss: -2.9638519287109375
Batch 53/64 loss: -2.8340225219726562
Batch 54/64 loss: -3.0242815017700195
Batch 55/64 loss: -3.010068893432617
Batch 56/64 loss: -2.6761064529418945
Batch 57/64 loss: -2.9474477767944336
Batch 58/64 loss: -2.8883275985717773
Batch 59/64 loss: -2.9843130111694336
Batch 60/64 loss: -3.1898584365844727
Batch 61/64 loss: -3.1368541717529297
Batch 62/64 loss: -2.8255863189697266
Batch 63/64 loss: -2.9038448333740234
Batch 64/64 loss: -7.4668378829956055
Epoch 445  Train loss: -2.955809234170353  Val loss: -3.2917365765653526
Epoch 446
-------------------------------
Batch 1/64 loss: -2.9896669387817383
Batch 2/64 loss: -2.986649513244629
Batch 3/64 loss: -3.034153938293457
Batch 4/64 loss: -3.03499698638916
Batch 5/64 loss: -3.146733283996582
Batch 6/64 loss: -2.6047468185424805
Batch 7/64 loss: -2.9585485458374023
Batch 8/64 loss: -2.84175968170166
Batch 9/64 loss: -2.8384132385253906
Batch 10/64 loss: -2.857492446899414
Batch 11/64 loss: -3.050374984741211
Batch 12/64 loss: -2.9763221740722656
Batch 13/64 loss: -2.8383865356445312
Batch 14/64 loss: -2.4663991928100586
Batch 15/64 loss: -2.974907875061035
Batch 16/64 loss: -3.013620376586914
Batch 17/64 loss: -3.0281896591186523
Batch 18/64 loss: -3.0154972076416016
Batch 19/64 loss: -3.00437068939209
Batch 20/64 loss: -2.38547420501709
Batch 21/64 loss: -2.9980831146240234
Batch 22/64 loss: -3.0376033782958984
Batch 23/64 loss: -2.9326725006103516
Batch 24/64 loss: -2.581902503967285
Batch 25/64 loss: -3.048739433288574
Batch 26/64 loss: -2.815786361694336
Batch 27/64 loss: -2.7485742568969727
Batch 28/64 loss: -2.9790916442871094
Batch 29/64 loss: -2.980558395385742
Batch 30/64 loss: -2.964016914367676
Batch 31/64 loss: -2.8916473388671875
Batch 32/64 loss: -3.0905885696411133
Batch 33/64 loss: -2.801616668701172
Batch 34/64 loss: -2.9906110763549805
Batch 35/64 loss: -2.9121274948120117
Batch 36/64 loss: -2.8066749572753906
Batch 37/64 loss: -2.810460090637207
Batch 38/64 loss: -3.0278053283691406
Batch 39/64 loss: -3.115412712097168
Batch 40/64 loss: -2.9337520599365234
Batch 41/64 loss: -3.0862836837768555
Batch 42/64 loss: -2.8206558227539062
Batch 43/64 loss: -2.9397048950195312
Batch 44/64 loss: -3.0718955993652344
Batch 45/64 loss: -3.1094141006469727
Batch 46/64 loss: -3.0834732055664062
Batch 47/64 loss: -3.0271520614624023
Batch 48/64 loss: -2.989405632019043
Batch 49/64 loss: -3.0022544860839844
Batch 50/64 loss: -2.8246841430664062
Batch 51/64 loss: -2.8257904052734375
Batch 52/64 loss: -2.9405460357666016
Batch 53/64 loss: -3.0318775177001953
Batch 54/64 loss: -2.437776565551758
Batch 55/64 loss: -2.9258251190185547
Batch 56/64 loss: -2.9129791259765625
Batch 57/64 loss: -3.092378616333008
Batch 58/64 loss: -2.900583267211914
Batch 59/64 loss: -2.9501638412475586
Batch 60/64 loss: -3.070328712463379
Batch 61/64 loss: -2.842365264892578
Batch 62/64 loss: -3.0178585052490234
Batch 63/64 loss: -3.091928482055664
Batch 64/64 loss: -7.5322370529174805
Epoch 446  Train loss: -2.9828852073819028  Val loss: -3.289632358092213
Epoch 447
-------------------------------
Batch 1/64 loss: -3.10943603515625
Batch 2/64 loss: -2.9678421020507812
Batch 3/64 loss: -3.045347213745117
Batch 4/64 loss: -2.8640689849853516
Batch 5/64 loss: -2.9570798873901367
Batch 6/64 loss: -3.1298885345458984
Batch 7/64 loss: -2.93878173828125
Batch 8/64 loss: -3.0162010192871094
Batch 9/64 loss: -2.562532424926758
Batch 10/64 loss: -2.8657970428466797
Batch 11/64 loss: -2.866525650024414
Batch 12/64 loss: -2.988618850708008
Batch 13/64 loss: -3.006284713745117
Batch 14/64 loss: -2.814824104309082
Batch 15/64 loss: -3.0044546127319336
Batch 16/64 loss: -3.036203384399414
Batch 17/64 loss: -2.7204055786132812
Batch 18/64 loss: -2.779644012451172
Batch 19/64 loss: -2.91750431060791
Batch 20/64 loss: -2.842456817626953
Batch 21/64 loss: -2.610748291015625
Batch 22/64 loss: -3.0161380767822266
Batch 23/64 loss: -2.5685367584228516
Batch 24/64 loss: -2.982606887817383
Batch 25/64 loss: -3.0545482635498047
Batch 26/64 loss: -2.8248043060302734
Batch 27/64 loss: -2.7409934997558594
Batch 28/64 loss: -2.891857147216797
Batch 29/64 loss: -2.9261837005615234
Batch 30/64 loss: -2.88826847076416
Batch 31/64 loss: -2.9900007247924805
Batch 32/64 loss: -3.0081100463867188
Batch 33/64 loss: -3.071516990661621
Batch 34/64 loss: -2.9926795959472656
Batch 35/64 loss: -3.155573844909668
Batch 36/64 loss: -3.065180778503418
Batch 37/64 loss: -2.974555015563965
Batch 38/64 loss: -2.28585147857666
Batch 39/64 loss: -3.003739356994629
Batch 40/64 loss: -3.00167179107666
Batch 41/64 loss: -3.163604736328125
Batch 42/64 loss: -3.1680898666381836
Batch 43/64 loss: -2.7733917236328125
Batch 44/64 loss: -2.4205732345581055
Batch 45/64 loss: -3.0104541778564453
Batch 46/64 loss: -2.980875015258789
Batch 47/64 loss: -3.0281219482421875
Batch 48/64 loss: -2.6225013732910156
Batch 49/64 loss: -3.0106935501098633
Batch 50/64 loss: -2.7691783905029297
Batch 51/64 loss: -3.0457534790039062
Batch 52/64 loss: -3.0096349716186523
Batch 53/64 loss: -2.8419761657714844
Batch 54/64 loss: -3.048046112060547
Batch 55/64 loss: -3.010678291320801
Batch 56/64 loss: -3.0927209854125977
Batch 57/64 loss: -2.9525833129882812
Batch 58/64 loss: -3.0293397903442383
Batch 59/64 loss: -3.022672653198242
Batch 60/64 loss: -2.8189926147460938
Batch 61/64 loss: -2.8258066177368164
Batch 62/64 loss: -2.8373374938964844
Batch 63/64 loss: -2.7991113662719727
Batch 64/64 loss: -7.31113338470459
Epoch 447  Train loss: -2.968673724754184  Val loss: -3.216103557049204
Epoch 448
-------------------------------
Batch 1/64 loss: -2.866408348083496
Batch 2/64 loss: -2.348909378051758
Batch 3/64 loss: -2.8767356872558594
Batch 4/64 loss: -2.9693546295166016
Batch 5/64 loss: -2.394576072692871
Batch 6/64 loss: -3.003270149230957
Batch 7/64 loss: -3.094789505004883
Batch 8/64 loss: -2.986480712890625
Batch 9/64 loss: -2.814544677734375
Batch 10/64 loss: -3.06533145904541
Batch 11/64 loss: -2.1735267639160156
Batch 12/64 loss: -2.9639081954956055
Batch 13/64 loss: -2.8711700439453125
Batch 14/64 loss: -2.9236669540405273
Batch 15/64 loss: -3.242992401123047
Batch 16/64 loss: -3.0228519439697266
Batch 17/64 loss: -3.0557565689086914
Batch 18/64 loss: -3.1374034881591797
Batch 19/64 loss: -2.7701854705810547
Batch 20/64 loss: -2.9067039489746094
Batch 21/64 loss: -2.6843032836914062
Batch 22/64 loss: -2.916510581970215
Batch 23/64 loss: -2.9076738357543945
Batch 24/64 loss: -2.9892492294311523
Batch 25/64 loss: -3.065901756286621
Batch 26/64 loss: -2.92812442779541
Batch 27/64 loss: -3.109180450439453
Batch 28/64 loss: -2.908572196960449
Batch 29/64 loss: -2.997720718383789
Batch 30/64 loss: -2.9338178634643555
Batch 31/64 loss: -3.2342395782470703
Batch 32/64 loss: -2.753148078918457
Batch 33/64 loss: -2.840092658996582
Batch 34/64 loss: -3.018397331237793
Batch 35/64 loss: -3.0015783309936523
Batch 36/64 loss: -2.864910125732422
Batch 37/64 loss: -2.9868669509887695
Batch 38/64 loss: -2.7109832763671875
Batch 39/64 loss: -3.1760854721069336
Batch 40/64 loss: -3.164979934692383
Batch 41/64 loss: -2.5658702850341797
Batch 42/64 loss: -2.7814836502075195
Batch 43/64 loss: -2.7019662857055664
Batch 44/64 loss: -2.866392135620117
Batch 45/64 loss: -2.979311943054199
Batch 46/64 loss: -2.91928768157959
Batch 47/64 loss: -2.716843605041504
Batch 48/64 loss: -2.9063215255737305
Batch 49/64 loss: -2.8022327423095703
Batch 50/64 loss: -2.9494504928588867
Batch 51/64 loss: -3.0106735229492188
Batch 52/64 loss: -3.2248077392578125
Batch 53/64 loss: -3.144953727722168
Batch 54/64 loss: -2.90396785736084
Batch 55/64 loss: -2.7548608779907227
Batch 56/64 loss: -2.8191490173339844
Batch 57/64 loss: -2.117903709411621
Batch 58/64 loss: -3.0018720626831055
Batch 59/64 loss: -3.0171375274658203
Batch 60/64 loss: -3.1106834411621094
Batch 61/64 loss: -2.981289863586426
Batch 62/64 loss: -3.1404361724853516
Batch 63/64 loss: -2.9573488235473633
Batch 64/64 loss: -7.535735130310059
Epoch 448  Train loss: -2.960108996372597  Val loss: -3.2156934705386866
Epoch 449
-------------------------------
Batch 1/64 loss: -2.9568614959716797
Batch 2/64 loss: -3.0734071731567383
Batch 3/64 loss: -2.8873376846313477
Batch 4/64 loss: -2.9469985961914062
Batch 5/64 loss: -2.957972526550293
Batch 6/64 loss: -3.061251640319824
Batch 7/64 loss: -2.393726348876953
Batch 8/64 loss: -3.082465171813965
Batch 9/64 loss: -2.574904441833496
Batch 10/64 loss: -2.614269256591797
Batch 11/64 loss: -2.818417549133301
Batch 12/64 loss: -2.8424901962280273
Batch 13/64 loss: -3.182183265686035
Batch 14/64 loss: -3.105973243713379
Batch 15/64 loss: -3.1191577911376953
Batch 16/64 loss: -2.9723806381225586
Batch 17/64 loss: -3.0083789825439453
Batch 18/64 loss: -3.049502372741699
Batch 19/64 loss: -2.964602470397949
Batch 20/64 loss: -2.7934398651123047
Batch 21/64 loss: -3.0444440841674805
Batch 22/64 loss: -2.44467830657959
Batch 23/64 loss: -2.6600141525268555
Batch 24/64 loss: -3.006392478942871
Batch 25/64 loss: -2.644655227661133
Batch 26/64 loss: -2.94510555267334
Batch 27/64 loss: -2.8391027450561523
Batch 28/64 loss: -3.0868091583251953
Batch 29/64 loss: -2.810482978820801
Batch 30/64 loss: -2.722278594970703
Batch 31/64 loss: -2.2795591354370117
Batch 32/64 loss: -3.083643913269043
Batch 33/64 loss: -2.824953079223633
Batch 34/64 loss: -2.7390823364257812
Batch 35/64 loss: -2.9806461334228516
Batch 36/64 loss: -2.9189653396606445
Batch 37/64 loss: -2.7145118713378906
Batch 38/64 loss: -3.118533134460449
Batch 39/64 loss: -2.730565071105957
Batch 40/64 loss: -2.8982458114624023
Batch 41/64 loss: -2.862335205078125
Batch 42/64 loss: -2.8544740676879883
Batch 43/64 loss: -2.6900978088378906
Batch 44/64 loss: -2.8707008361816406
Batch 45/64 loss: -2.7074193954467773
Batch 46/64 loss: -2.7445688247680664
Batch 47/64 loss: -2.8318405151367188
Batch 48/64 loss: -2.4594221115112305
Batch 49/64 loss: -3.0199718475341797
Batch 50/64 loss: -3.0198965072631836
Batch 51/64 loss: -2.717949867248535
Batch 52/64 loss: -2.9591073989868164
Batch 53/64 loss: -2.8253488540649414
Batch 54/64 loss: -2.9485645294189453
Batch 55/64 loss: -2.812347412109375
Batch 56/64 loss: -2.2736711502075195
Batch 57/64 loss: -2.9655628204345703
Batch 58/64 loss: -3.025423049926758
Batch 59/64 loss: -3.0997962951660156
Batch 60/64 loss: -2.2202796936035156
Batch 61/64 loss: -3.1256933212280273
Batch 62/64 loss: -2.78195858001709
Batch 63/64 loss: -2.9750442504882812
Batch 64/64 loss: -7.589951992034912
Epoch 449  Train loss: -2.9079580886691225  Val loss: -3.1609202250582245
Epoch 450
-------------------------------
Batch 1/64 loss: -2.9978628158569336
Batch 2/64 loss: -2.9733991622924805
Batch 3/64 loss: -3.0341081619262695
Batch 4/64 loss: -2.9401702880859375
Batch 5/64 loss: -2.793808937072754
Batch 6/64 loss: -3.030794143676758
Batch 7/64 loss: -2.923707962036133
Batch 8/64 loss: -2.9065608978271484
Batch 9/64 loss: -2.33868408203125
Batch 10/64 loss: -2.6111860275268555
Batch 11/64 loss: -2.6365909576416016
Batch 12/64 loss: -3.0104618072509766
Batch 13/64 loss: -3.032071113586426
Batch 14/64 loss: -3.0318756103515625
Batch 15/64 loss: -2.7430343627929688
Batch 16/64 loss: -2.975663185119629
Batch 17/64 loss: -3.000472068786621
Batch 18/64 loss: -2.942816734313965
Batch 19/64 loss: -3.0336103439331055
Batch 20/64 loss: -2.8894739151000977
Batch 21/64 loss: -3.042634963989258
Batch 22/64 loss: -2.553177833557129
Batch 23/64 loss: -3.1790637969970703
Batch 24/64 loss: -2.948672294616699
Batch 25/64 loss: -2.6800928115844727
Batch 26/64 loss: -2.844888687133789
Batch 27/64 loss: -2.3486766815185547
Batch 28/64 loss: -3.1340208053588867
Batch 29/64 loss: -2.8672704696655273
Batch 30/64 loss: -3.033329963684082
Batch 31/64 loss: -2.988832473754883
Batch 32/64 loss: -3.1105422973632812
Batch 33/64 loss: -2.902207374572754
Batch 34/64 loss: -3.086331367492676
Batch 35/64 loss: -2.331986427307129
Batch 36/64 loss: -3.025092124938965
Batch 37/64 loss: -3.052248954772949
Batch 38/64 loss: -2.9940881729125977
Batch 39/64 loss: -3.036696434020996
Batch 40/64 loss: -2.9339494705200195
Batch 41/64 loss: -3.0660743713378906
Batch 42/64 loss: -2.9987077713012695
Batch 43/64 loss: -2.990589141845703
Batch 44/64 loss: -2.902102470397949
Batch 45/64 loss: -3.278799057006836
Batch 46/64 loss: -2.406526565551758
Batch 47/64 loss: -3.167099952697754
Batch 48/64 loss: -3.096646308898926
Batch 49/64 loss: -3.092513084411621
Batch 50/64 loss: -2.845060348510742
Batch 51/64 loss: -2.934828758239746
Batch 52/64 loss: -2.868497848510742
Batch 53/64 loss: -3.0419139862060547
Batch 54/64 loss: -2.5841779708862305
Batch 55/64 loss: -2.929598808288574
Batch 56/64 loss: -2.97369384765625
Batch 57/64 loss: -2.982144355773926
Batch 58/64 loss: -2.950810432434082
Batch 59/64 loss: -2.558783531188965
Batch 60/64 loss: -2.9171371459960938
Batch 61/64 loss: -3.0031356811523438
Batch 62/64 loss: -2.7044553756713867
Batch 63/64 loss: -2.873600959777832
Batch 64/64 loss: -7.239164352416992
Epoch 450  Train loss: -2.957434149349437  Val loss: -3.0577823992857
Epoch 451
-------------------------------
Batch 1/64 loss: -3.0846071243286133
Batch 2/64 loss: -2.8097991943359375
Batch 3/64 loss: -2.850025177001953
Batch 4/64 loss: -3.005918502807617
Batch 5/64 loss: -3.0540084838867188
Batch 6/64 loss: -3.029189109802246
Batch 7/64 loss: -2.984027862548828
Batch 8/64 loss: -2.984529495239258
Batch 9/64 loss: -2.99599552154541
Batch 10/64 loss: -3.260031223297119
Batch 11/64 loss: -1.9406051635742188
Batch 12/64 loss: -2.932490348815918
Batch 13/64 loss: -2.7999496459960938
Batch 14/64 loss: -2.9528675079345703
Batch 15/64 loss: -3.1161766052246094
Batch 16/64 loss: -2.896742820739746
Batch 17/64 loss: -3.04998779296875
Batch 18/64 loss: -2.747036933898926
Batch 19/64 loss: -2.9999876022338867
Batch 20/64 loss: -2.675474166870117
Batch 21/64 loss: -2.9982099533081055
Batch 22/64 loss: -3.0786237716674805
Batch 23/64 loss: -2.986757278442383
Batch 24/64 loss: -2.852407455444336
Batch 25/64 loss: -2.82912540435791
Batch 26/64 loss: -2.4520225524902344
Batch 27/64 loss: -2.959024429321289
Batch 28/64 loss: -2.7317800521850586
Batch 29/64 loss: -3.020557403564453
Batch 30/64 loss: -2.76511287689209
Batch 31/64 loss: -3.0412044525146484
Batch 32/64 loss: -3.1111621856689453
Batch 33/64 loss: -2.530703544616699
Batch 34/64 loss: -2.8763628005981445
Batch 35/64 loss: -3.0511856079101562
Batch 36/64 loss: -2.853853225708008
Batch 37/64 loss: -2.9136056900024414
Batch 38/64 loss: -2.3868255615234375
Batch 39/64 loss: -2.8118200302124023
Batch 40/64 loss: -3.288628578186035
Batch 41/64 loss: -2.862211227416992
Batch 42/64 loss: -3.013530731201172
Batch 43/64 loss: -3.13238525390625
Batch 44/64 loss: -2.8897523880004883
Batch 45/64 loss: -2.8125486373901367
Batch 46/64 loss: -2.9349002838134766
Batch 47/64 loss: -2.7036514282226562
Batch 48/64 loss: -2.1831798553466797
Batch 49/64 loss: -2.9164953231811523
Batch 50/64 loss: -2.8874988555908203
Batch 51/64 loss: -2.998544692993164
Batch 52/64 loss: -3.101898193359375
Batch 53/64 loss: -3.149038314819336
Batch 54/64 loss: -2.9925498962402344
Batch 55/64 loss: -2.8449277877807617
Batch 56/64 loss: -2.712325096130371
Batch 57/64 loss: -3.0311660766601562
Batch 58/64 loss: -3.0204830169677734
Batch 59/64 loss: -3.038418769836426
Batch 60/64 loss: -2.277377128601074
Batch 61/64 loss: -3.140024185180664
Batch 62/64 loss: -3.112339973449707
Batch 63/64 loss: -3.017416000366211
Batch 64/64 loss: -7.106893539428711
Epoch 451  Train loss: -2.9460589240579043  Val loss: -3.2915038407053734
Epoch 452
-------------------------------
Batch 1/64 loss: -2.934232711791992
Batch 2/64 loss: -2.9819984436035156
Batch 3/64 loss: -2.4656381607055664
Batch 4/64 loss: -3.0545568466186523
Batch 5/64 loss: -3.06024169921875
Batch 6/64 loss: -3.051995277404785
Batch 7/64 loss: -2.887645721435547
Batch 8/64 loss: -2.99008846282959
Batch 9/64 loss: -3.02634334564209
Batch 10/64 loss: -3.1710519790649414
Batch 11/64 loss: -2.86971378326416
Batch 12/64 loss: -2.993406295776367
Batch 13/64 loss: -2.6712684631347656
Batch 14/64 loss: -3.054957389831543
Batch 15/64 loss: -2.9422178268432617
Batch 16/64 loss: -2.9396305084228516
Batch 17/64 loss: -2.9439573287963867
Batch 18/64 loss: -3.0628490447998047
Batch 19/64 loss: -2.5946502685546875
Batch 20/64 loss: -2.892244338989258
Batch 21/64 loss: -2.9858264923095703
Batch 22/64 loss: -3.129836082458496
Batch 23/64 loss: -2.9602298736572266
Batch 24/64 loss: -3.0423812866210938
Batch 25/64 loss: -2.9140634536743164
Batch 26/64 loss: -2.825371742248535
Batch 27/64 loss: -3.063814163208008
Batch 28/64 loss: -2.962141990661621
Batch 29/64 loss: -3.005044937133789
Batch 30/64 loss: -2.795060157775879
Batch 31/64 loss: -2.5406198501586914
Batch 32/64 loss: -2.785562515258789
Batch 33/64 loss: -2.9933481216430664
Batch 34/64 loss: -2.7565441131591797
Batch 35/64 loss: -3.158143997192383
Batch 36/64 loss: -3.074155807495117
Batch 37/64 loss: -3.139500617980957
Batch 38/64 loss: -2.843377113342285
Batch 39/64 loss: -2.9389562606811523
Batch 40/64 loss: -3.152644157409668
Batch 41/64 loss: -3.054409980773926
Batch 42/64 loss: -2.873764991760254
Batch 43/64 loss: -3.042926788330078
Batch 44/64 loss: -3.225250244140625
Batch 45/64 loss: -3.1035079956054688
Batch 46/64 loss: -2.830690383911133
Batch 47/64 loss: -2.722423553466797
Batch 48/64 loss: -3.0676193237304688
Batch 49/64 loss: -2.961125373840332
Batch 50/64 loss: -3.187406539916992
Batch 51/64 loss: -2.9781103134155273
Batch 52/64 loss: -3.078383445739746
Batch 53/64 loss: -2.9969844818115234
Batch 54/64 loss: -3.115492820739746
Batch 55/64 loss: -2.9358301162719727
Batch 56/64 loss: -3.010244369506836
Batch 57/64 loss: -2.9097299575805664
Batch 58/64 loss: -2.6435298919677734
Batch 59/64 loss: -2.9026498794555664
Batch 60/64 loss: -2.564183235168457
Batch 61/64 loss: -3.1170310974121094
Batch 62/64 loss: -2.4409284591674805
Batch 63/64 loss: -2.9794864654541016
Batch 64/64 loss: -7.554895401000977
Epoch 452  Train loss: -2.9970696767171225  Val loss: -3.3214101496431017
Epoch 453
-------------------------------
Batch 1/64 loss: -2.9919357299804688
Batch 2/64 loss: -3.145503044128418
Batch 3/64 loss: -2.964655876159668
Batch 4/64 loss: -3.036940574645996
Batch 5/64 loss: -2.9996204376220703
Batch 6/64 loss: -3.140744209289551
Batch 7/64 loss: -2.1801633834838867
Batch 8/64 loss: -2.803678512573242
Batch 9/64 loss: -2.9750843048095703
Batch 10/64 loss: -3.065967559814453
Batch 11/64 loss: -2.863607406616211
Batch 12/64 loss: -2.7017316818237305
Batch 13/64 loss: -2.8701248168945312
Batch 14/64 loss: -2.993130683898926
Batch 15/64 loss: -3.011547088623047
Batch 16/64 loss: -3.003403663635254
Batch 17/64 loss: -3.1523513793945312
Batch 18/64 loss: -2.736321449279785
Batch 19/64 loss: -2.3958911895751953
Batch 20/64 loss: -2.7941102981567383
Batch 21/64 loss: -2.823976516723633
Batch 22/64 loss: -3.0207386016845703
Batch 23/64 loss: -2.970245361328125
Batch 24/64 loss: -3.140047073364258
Batch 25/64 loss: -2.9150238037109375
Batch 26/64 loss: -2.9506006240844727
Batch 27/64 loss: -3.1270408630371094
Batch 28/64 loss: -3.1843795776367188
Batch 29/64 loss: -3.1999940872192383
Batch 30/64 loss: -3.0172834396362305
Batch 31/64 loss: -3.058643341064453
Batch 32/64 loss: -2.9567480087280273
Batch 33/64 loss: -2.9667978286743164
Batch 34/64 loss: -2.9605350494384766
Batch 35/64 loss: -2.7574567794799805
Batch 36/64 loss: -3.095428466796875
Batch 37/64 loss: -3.1594505310058594
Batch 38/64 loss: -2.581218719482422
Batch 39/64 loss: -2.264246940612793
Batch 40/64 loss: -2.9214162826538086
Batch 41/64 loss: -2.708024024963379
Batch 42/64 loss: -2.8845014572143555
Batch 43/64 loss: -2.7769107818603516
Batch 44/64 loss: -2.281527519226074
Batch 45/64 loss: -2.5691070556640625
Batch 46/64 loss: -2.816422462463379
Batch 47/64 loss: -2.674525260925293
Batch 48/64 loss: -2.9266738891601562
Batch 49/64 loss: -2.944045066833496
Batch 50/64 loss: -3.058055877685547
Batch 51/64 loss: -3.2213687896728516
Batch 52/64 loss: -2.957592010498047
Batch 53/64 loss: -3.1226205825805664
Batch 54/64 loss: -3.1394081115722656
Batch 55/64 loss: -3.139484405517578
Batch 56/64 loss: -3.117051124572754
Batch 57/64 loss: -3.0539093017578125
Batch 58/64 loss: -3.043400764465332
Batch 59/64 loss: -2.666253089904785
Batch 60/64 loss: -3.185853958129883
Batch 61/64 loss: -2.847057342529297
Batch 62/64 loss: -3.190964698791504
Batch 63/64 loss: -2.9267091751098633
Batch 64/64 loss: -7.7057037353515625
Epoch 453  Train loss: -2.9792710547353707  Val loss: -3.3316349147521342
Saving best model, epoch: 453
Epoch 454
-------------------------------
Batch 1/64 loss: -3.0584983825683594
Batch 2/64 loss: -3.1260766983032227
Batch 3/64 loss: -3.101881980895996
Batch 4/64 loss: -3.112593650817871
Batch 5/64 loss: -2.9168472290039062
Batch 6/64 loss: -2.8025684356689453
Batch 7/64 loss: -2.4631776809692383
Batch 8/64 loss: -2.8674449920654297
Batch 9/64 loss: -3.1254730224609375
Batch 10/64 loss: -2.9491100311279297
Batch 11/64 loss: -3.1440391540527344
Batch 12/64 loss: -3.1622238159179688
Batch 13/64 loss: -2.826284408569336
Batch 14/64 loss: -3.044522285461426
Batch 15/64 loss: -2.776556968688965
Batch 16/64 loss: -2.4473772048950195
Batch 17/64 loss: -3.178380012512207
Batch 18/64 loss: -3.100888252258301
Batch 19/64 loss: -3.0341920852661133
Batch 20/64 loss: -3.161712646484375
Batch 21/64 loss: -3.220102310180664
Batch 22/64 loss: -3.193293571472168
Batch 23/64 loss: -2.813075065612793
Batch 24/64 loss: -3.149897575378418
Batch 25/64 loss: -3.0264816284179688
Batch 26/64 loss: -3.1452455520629883
Batch 27/64 loss: -2.620969772338867
Batch 28/64 loss: -2.7334814071655273
Batch 29/64 loss: -2.1420669555664062
Batch 30/64 loss: -2.940683364868164
Batch 31/64 loss: -2.9339599609375
Batch 32/64 loss: -2.897716522216797
Batch 33/64 loss: -3.0554561614990234
Batch 34/64 loss: -3.063295364379883
Batch 35/64 loss: -3.042149543762207
Batch 36/64 loss: -2.839641571044922
Batch 37/64 loss: -2.9367027282714844
Batch 38/64 loss: -2.978322982788086
Batch 39/64 loss: -2.8487462997436523
Batch 40/64 loss: -3.1177244186401367
Batch 41/64 loss: -2.1782712936401367
Batch 42/64 loss: -3.099466323852539
Batch 43/64 loss: -2.7208938598632812
Batch 44/64 loss: -3.050900459289551
Batch 45/64 loss: -3.033353805541992
Batch 46/64 loss: -2.888103485107422
Batch 47/64 loss: -3.063918113708496
Batch 48/64 loss: -2.9530630111694336
Batch 49/64 loss: -2.917201042175293
Batch 50/64 loss: -3.032320976257324
Batch 51/64 loss: -2.936211585998535
Batch 52/64 loss: -3.1685361862182617
Batch 53/64 loss: -2.960015296936035
Batch 54/64 loss: -2.7578344345092773
Batch 55/64 loss: -2.839448928833008
Batch 56/64 loss: -2.9479055404663086
Batch 57/64 loss: -3.028331756591797
Batch 58/64 loss: -2.6709184646606445
Batch 59/64 loss: -3.010075569152832
Batch 60/64 loss: -3.012587547302246
Batch 61/64 loss: -3.0671586990356445
Batch 62/64 loss: -3.0602035522460938
Batch 63/64 loss: -3.1449432373046875
Batch 64/64 loss: -7.602529525756836
Epoch 454  Train loss: -3.0014497569963043  Val loss: -3.3336641894992685
Saving best model, epoch: 454
Epoch 455
-------------------------------
Batch 1/64 loss: -2.924427032470703
Batch 2/64 loss: -3.0215072631835938
Batch 3/64 loss: -3.0758237838745117
Batch 4/64 loss: -3.035792350769043
Batch 5/64 loss: -3.0655927658081055
Batch 6/64 loss: -2.6114063262939453
Batch 7/64 loss: -2.5954456329345703
Batch 8/64 loss: -2.87015438079834
Batch 9/64 loss: -2.871922492980957
Batch 10/64 loss: -2.8618688583374023
Batch 11/64 loss: -2.9774656295776367
Batch 12/64 loss: -2.6433334350585938
Batch 13/64 loss: -3.0132246017456055
Batch 14/64 loss: -3.014310836791992
Batch 15/64 loss: -3.1735992431640625
Batch 16/64 loss: -2.767538070678711
Batch 17/64 loss: -2.8781309127807617
Batch 18/64 loss: -3.06972599029541
Batch 19/64 loss: -3.0463714599609375
Batch 20/64 loss: -3.0147171020507812
Batch 21/64 loss: -1.9657468795776367
Batch 22/64 loss: -2.992119789123535
Batch 23/64 loss: -3.0054922103881836
Batch 24/64 loss: -3.0463056564331055
Batch 25/64 loss: -2.7710647583007812
Batch 26/64 loss: -2.735597610473633
Batch 27/64 loss: -3.096522331237793
Batch 28/64 loss: -3.189080238342285
Batch 29/64 loss: -2.592489242553711
Batch 30/64 loss: -2.872081756591797
Batch 31/64 loss: -3.1321630477905273
Batch 32/64 loss: -3.0527830123901367
Batch 33/64 loss: -3.0434274673461914
Batch 34/64 loss: -2.9348011016845703
Batch 35/64 loss: -2.9866485595703125
Batch 36/64 loss: -2.655013084411621
Batch 37/64 loss: -3.09554386138916
Batch 38/64 loss: -3.0087194442749023
Batch 39/64 loss: -2.9965171813964844
Batch 40/64 loss: -2.493192672729492
Batch 41/64 loss: -3.2541332244873047
Batch 42/64 loss: -3.0130367279052734
Batch 43/64 loss: -3.1166763305664062
Batch 44/64 loss: -2.981085777282715
Batch 45/64 loss: -2.994180679321289
Batch 46/64 loss: -3.180739402770996
Batch 47/64 loss: -3.128389358520508
Batch 48/64 loss: -2.9352731704711914
Batch 49/64 loss: -3.089156150817871
Batch 50/64 loss: -2.9151906967163086
Batch 51/64 loss: -3.1871776580810547
Batch 52/64 loss: -2.979363441467285
Batch 53/64 loss: -3.1276044845581055
Batch 54/64 loss: -3.200531005859375
Batch 55/64 loss: -2.965947151184082
Batch 56/64 loss: -3.060622215270996
Batch 57/64 loss: -3.0450916290283203
Batch 58/64 loss: -3.0252561569213867
Batch 59/64 loss: -3.174243927001953
Batch 60/64 loss: -3.178915023803711
Batch 61/64 loss: -3.210521697998047
Batch 62/64 loss: -2.954037666320801
Batch 63/64 loss: -3.195005416870117
Batch 64/64 loss: -7.31454610824585
Epoch 455  Train loss: -3.0211099082348394  Val loss: -3.326971860276055
Epoch 456
-------------------------------
Batch 1/64 loss: -3.1089324951171875
Batch 2/64 loss: -2.9530715942382812
Batch 3/64 loss: -2.402216911315918
Batch 4/64 loss: -3.0151214599609375
Batch 5/64 loss: -2.9200267791748047
Batch 6/64 loss: -3.1813344955444336
Batch 7/64 loss: -3.056166648864746
Batch 8/64 loss: -3.088719367980957
Batch 9/64 loss: -3.166213035583496
Batch 10/64 loss: -2.9257326126098633
Batch 11/64 loss: -3.0503721237182617
Batch 12/64 loss: -3.037752151489258
Batch 13/64 loss: -2.991474151611328
Batch 14/64 loss: -3.1016693115234375
Batch 15/64 loss: -3.005618095397949
Batch 16/64 loss: -3.0665550231933594
Batch 17/64 loss: -2.8814849853515625
Batch 18/64 loss: -3.0812225341796875
Batch 19/64 loss: -3.0464000701904297
Batch 20/64 loss: -3.0856475830078125
Batch 21/64 loss: -3.105947494506836
Batch 22/64 loss: -3.1801347732543945
Batch 23/64 loss: -3.1883373260498047
Batch 24/64 loss: -3.046497344970703
Batch 25/64 loss: -3.201888084411621
Batch 26/64 loss: -2.857499122619629
Batch 27/64 loss: -3.096158027648926
Batch 28/64 loss: -2.9147214889526367
Batch 29/64 loss: -3.0232362747192383
Batch 30/64 loss: -2.384293556213379
Batch 31/64 loss: -2.624140739440918
Batch 32/64 loss: -2.8492116928100586
Batch 33/64 loss: -3.06082820892334
Batch 34/64 loss: -2.817906379699707
Batch 35/64 loss: -2.919644355773926
Batch 36/64 loss: -2.8888282775878906
Batch 37/64 loss: -2.970210075378418
Batch 38/64 loss: -2.8007020950317383
Batch 39/64 loss: -3.028388023376465
Batch 40/64 loss: -3.032867431640625
Batch 41/64 loss: -2.923373222351074
Batch 42/64 loss: -3.089506149291992
Batch 43/64 loss: -3.1092662811279297
Batch 44/64 loss: -3.1392927169799805
Batch 45/64 loss: -2.9968490600585938
Batch 46/64 loss: -3.010186195373535
Batch 47/64 loss: -2.9850025177001953
Batch 48/64 loss: -2.9036951065063477
Batch 49/64 loss: -2.8607940673828125
Batch 50/64 loss: -3.0338878631591797
Batch 51/64 loss: -2.921222686767578
Batch 52/64 loss: -3.0677871704101562
Batch 53/64 loss: -3.196192741394043
Batch 54/64 loss: -2.6855955123901367
Batch 55/64 loss: -2.9324750900268555
Batch 56/64 loss: -3.1332454681396484
Batch 57/64 loss: -3.0361766815185547
Batch 58/64 loss: -2.9682064056396484
Batch 59/64 loss: -2.4573822021484375
Batch 60/64 loss: -3.056173324584961
Batch 61/64 loss: -2.888254165649414
Batch 62/64 loss: -3.112447738647461
Batch 63/64 loss: -3.0558528900146484
Batch 64/64 loss: -7.499764442443848
Epoch 456  Train loss: -3.0328605614456476  Val loss: -3.346325261486355
Saving best model, epoch: 456
Epoch 457
-------------------------------
Batch 1/64 loss: -2.8351011276245117
Batch 2/64 loss: -3.1106042861938477
Batch 3/64 loss: -3.11163330078125
Batch 4/64 loss: -3.0923404693603516
Batch 5/64 loss: -2.907748222351074
Batch 6/64 loss: -3.156454086303711
Batch 7/64 loss: -3.149287223815918
Batch 8/64 loss: -2.5979995727539062
Batch 9/64 loss: -3.16384220123291
Batch 10/64 loss: -3.0960683822631836
Batch 11/64 loss: -2.9788894653320312
Batch 12/64 loss: -2.851703643798828
Batch 13/64 loss: -3.102750778198242
Batch 14/64 loss: -3.0115766525268555
Batch 15/64 loss: -2.8614749908447266
Batch 16/64 loss: -3.0872621536254883
Batch 17/64 loss: -2.6479721069335938
Batch 18/64 loss: -2.9410476684570312
Batch 19/64 loss: -2.7848806381225586
Batch 20/64 loss: -3.0833139419555664
Batch 21/64 loss: -2.7727699279785156
Batch 22/64 loss: -3.032421112060547
Batch 23/64 loss: -2.978076934814453
Batch 24/64 loss: -2.5192203521728516
Batch 25/64 loss: -3.1484336853027344
Batch 26/64 loss: -3.0171127319335938
Batch 27/64 loss: -3.0905933380126953
Batch 28/64 loss: -3.051774024963379
Batch 29/64 loss: -3.0324487686157227
Batch 30/64 loss: -2.945611000061035
Batch 31/64 loss: -3.0385971069335938
Batch 32/64 loss: -2.8450422286987305
Batch 33/64 loss: -2.9513120651245117
Batch 34/64 loss: -3.2659177780151367
Batch 35/64 loss: -3.0057897567749023
Batch 36/64 loss: -3.0945301055908203
Batch 37/64 loss: -3.004362106323242
Batch 38/64 loss: -2.977259635925293
Batch 39/64 loss: -3.0492334365844727
Batch 40/64 loss: -2.8937463760375977
Batch 41/64 loss: -2.887417793273926
Batch 42/64 loss: -3.1081161499023438
Batch 43/64 loss: -3.0094032287597656
Batch 44/64 loss: -3.1129627227783203
Batch 45/64 loss: -3.095789909362793
Batch 46/64 loss: -3.0976037979125977
Batch 47/64 loss: -3.041257858276367
Batch 48/64 loss: -3.109537124633789
Batch 49/64 loss: -2.940980911254883
Batch 50/64 loss: -3.104414939880371
Batch 51/64 loss: -2.9923973083496094
Batch 52/64 loss: -3.037546157836914
Batch 53/64 loss: -2.615945816040039
Batch 54/64 loss: -2.977726936340332
Batch 55/64 loss: -2.2657346725463867
Batch 56/64 loss: -3.1317033767700195
Batch 57/64 loss: -3.01448917388916
Batch 58/64 loss: -3.079897880554199
Batch 59/64 loss: -3.228665351867676
Batch 60/64 loss: -2.602170944213867
Batch 61/64 loss: -3.168269157409668
Batch 62/64 loss: -3.1817522048950195
Batch 63/64 loss: -3.04544734954834
Batch 64/64 loss: -7.6581573486328125
Epoch 457  Train loss: -3.0412400339163987  Val loss: -3.352269844500879
Saving best model, epoch: 457
Epoch 458
-------------------------------
Batch 1/64 loss: -3.09995174407959
Batch 2/64 loss: -3.1321678161621094
Batch 3/64 loss: -2.9871788024902344
Batch 4/64 loss: -3.0436487197875977
Batch 5/64 loss: -3.2061996459960938
Batch 6/64 loss: -3.2006168365478516
Batch 7/64 loss: -2.9142684936523438
Batch 8/64 loss: -3.0106678009033203
Batch 9/64 loss: -2.9817590713500977
Batch 10/64 loss: -2.997300148010254
Batch 11/64 loss: -2.90737247467041
Batch 12/64 loss: -3.067948341369629
Batch 13/64 loss: -3.1579694747924805
Batch 14/64 loss: -2.9776601791381836
Batch 15/64 loss: -2.946932792663574
Batch 16/64 loss: -3.1713476181030273
Batch 17/64 loss: -2.715182304382324
Batch 18/64 loss: -3.12896728515625
Batch 19/64 loss: -3.004335403442383
Batch 20/64 loss: -2.8812332153320312
Batch 21/64 loss: -2.8635129928588867
Batch 22/64 loss: -3.0098581314086914
Batch 23/64 loss: -2.7323150634765625
Batch 24/64 loss: -3.1262731552124023
Batch 25/64 loss: -3.00197696685791
Batch 26/64 loss: -3.0842819213867188
Batch 27/64 loss: -3.2300186157226562
Batch 28/64 loss: -3.128596305847168
Batch 29/64 loss: -2.941476821899414
Batch 30/64 loss: -3.114011764526367
Batch 31/64 loss: -3.111745834350586
Batch 32/64 loss: -2.6185522079467773
Batch 33/64 loss: -3.0471620559692383
Batch 34/64 loss: -2.3364248275756836
Batch 35/64 loss: -3.093184471130371
Batch 36/64 loss: -2.9145545959472656
Batch 37/64 loss: -2.971468925476074
Batch 38/64 loss: -2.96511173248291
Batch 39/64 loss: -2.8618383407592773
Batch 40/64 loss: -2.94333553314209
Batch 41/64 loss: -2.6329784393310547
Batch 42/64 loss: -3.11293888092041
Batch 43/64 loss: -3.1132936477661133
Batch 44/64 loss: -2.949435234069824
Batch 45/64 loss: -3.008737564086914
Batch 46/64 loss: -3.0896787643432617
Batch 47/64 loss: -3.028822898864746
Batch 48/64 loss: -3.023991584777832
Batch 49/64 loss: -3.043911933898926
Batch 50/64 loss: -2.9697141647338867
Batch 51/64 loss: -2.773286819458008
Batch 52/64 loss: -3.076422691345215
Batch 53/64 loss: -2.9939775466918945
Batch 54/64 loss: -3.1363725662231445
Batch 55/64 loss: -2.6656370162963867
Batch 56/64 loss: -3.053119659423828
Batch 57/64 loss: -2.9953365325927734
Batch 58/64 loss: -2.3464088439941406
Batch 59/64 loss: -3.0859508514404297
Batch 60/64 loss: -2.868715286254883
Batch 61/64 loss: -3.0363025665283203
Batch 62/64 loss: -2.993258476257324
Batch 63/64 loss: -3.0789318084716797
Batch 64/64 loss: -7.230459213256836
Epoch 458  Train loss: -3.0294662999171837  Val loss: -3.3265480487207366
Epoch 459
-------------------------------
Batch 1/64 loss: -2.9608821868896484
Batch 2/64 loss: -2.7704553604125977
Batch 3/64 loss: -3.06149959564209
Batch 4/64 loss: -2.9292430877685547
Batch 5/64 loss: -2.7310256958007812
Batch 6/64 loss: -3.1620941162109375
Batch 7/64 loss: -3.0694780349731445
Batch 8/64 loss: -2.860597610473633
Batch 9/64 loss: -3.0375213623046875
Batch 10/64 loss: -2.8578624725341797
Batch 11/64 loss: -3.0996780395507812
Batch 12/64 loss: -3.0632686614990234
Batch 13/64 loss: -2.9181995391845703
Batch 14/64 loss: -2.9214000701904297
Batch 15/64 loss: -3.2123355865478516
Batch 16/64 loss: -3.0797643661499023
Batch 17/64 loss: -2.8453855514526367
Batch 18/64 loss: -3.0033388137817383
Batch 19/64 loss: -3.0733909606933594
Batch 20/64 loss: -3.0835695266723633
Batch 21/64 loss: -2.975475311279297
Batch 22/64 loss: -3.0586986541748047
Batch 23/64 loss: -3.0115623474121094
Batch 24/64 loss: -3.268617630004883
Batch 25/64 loss: -2.930490493774414
Batch 26/64 loss: -1.9055089950561523
Batch 27/64 loss: -3.0631942749023438
Batch 28/64 loss: -2.7614450454711914
Batch 29/64 loss: -2.8402252197265625
Batch 30/64 loss: -3.037809371948242
Batch 31/64 loss: -3.135981559753418
Batch 32/64 loss: -2.817164421081543
Batch 33/64 loss: -2.9174652099609375
Batch 34/64 loss: -2.7283525466918945
Batch 35/64 loss: -2.7964277267456055
Batch 36/64 loss: -3.2320876121520996
Batch 37/64 loss: -3.1584606170654297
Batch 38/64 loss: -3.029932975769043
Batch 39/64 loss: -3.1414260864257812
Batch 40/64 loss: -3.2248096466064453
Batch 41/64 loss: -2.9967517852783203
Batch 42/64 loss: -2.914907455444336
Batch 43/64 loss: -2.9296493530273438
Batch 44/64 loss: -2.9070215225219727
Batch 45/64 loss: -2.8271255493164062
Batch 46/64 loss: -3.2129125595092773
Batch 47/64 loss: -2.918598175048828
Batch 48/64 loss: -2.7939376831054688
Batch 49/64 loss: -3.0258255004882812
Batch 50/64 loss: -3.1054067611694336
Batch 51/64 loss: -2.9913196563720703
Batch 52/64 loss: -2.3912439346313477
Batch 53/64 loss: -3.067655563354492
Batch 54/64 loss: -3.074357032775879
Batch 55/64 loss: -2.6197099685668945
Batch 56/64 loss: -2.9387388229370117
Batch 57/64 loss: -3.0491857528686523
Batch 58/64 loss: -2.989931106567383
Batch 59/64 loss: -2.933206558227539
Batch 60/64 loss: -3.0023765563964844
Batch 61/64 loss: -3.2101192474365234
Batch 62/64 loss: -3.0603065490722656
Batch 63/64 loss: -2.944652557373047
Batch 64/64 loss: -7.654809951782227
Epoch 459  Train loss: -3.018387035295075  Val loss: -3.2577362453814636
Epoch 460
-------------------------------
Batch 1/64 loss: -3.0576658248901367
Batch 2/64 loss: -2.87197208404541
Batch 3/64 loss: -2.9803829193115234
Batch 4/64 loss: -3.0060205459594727
Batch 5/64 loss: -3.038632392883301
Batch 6/64 loss: -3.075887680053711
Batch 7/64 loss: -3.0828676223754883
Batch 8/64 loss: -2.752613067626953
Batch 9/64 loss: -3.0205764770507812
Batch 10/64 loss: -3.053934097290039
Batch 11/64 loss: -2.8915138244628906
Batch 12/64 loss: -2.6974830627441406
Batch 13/64 loss: -3.0964622497558594
Batch 14/64 loss: -2.827421188354492
Batch 15/64 loss: -3.0351104736328125
Batch 16/64 loss: -3.028902053833008
Batch 17/64 loss: -3.107725143432617
Batch 18/64 loss: -3.0357866287231445
Batch 19/64 loss: -3.134611129760742
Batch 20/64 loss: -3.01932430267334
Batch 21/64 loss: -2.9090089797973633
Batch 22/64 loss: -2.5026674270629883
Batch 23/64 loss: -3.1902647018432617
Batch 24/64 loss: -2.663637161254883
Batch 25/64 loss: -3.0573463439941406
Batch 26/64 loss: -2.494344711303711
Batch 27/64 loss: -2.8616180419921875
Batch 28/64 loss: -3.044464111328125
Batch 29/64 loss: -3.0862865447998047
Batch 30/64 loss: -3.109856605529785
Batch 31/64 loss: -2.892000198364258
Batch 32/64 loss: -2.8983402252197266
Batch 33/64 loss: -2.9746551513671875
Batch 34/64 loss: -3.146434783935547
Batch 35/64 loss: -2.967291831970215
Batch 36/64 loss: -2.793309211730957
Batch 37/64 loss: -3.133772850036621
Batch 38/64 loss: -2.572239875793457
Batch 39/64 loss: -2.981644630432129
Batch 40/64 loss: -2.693209648132324
Batch 41/64 loss: -2.8985776901245117
Batch 42/64 loss: -3.0877580642700195
Batch 43/64 loss: -2.5787343978881836
Batch 44/64 loss: -3.0179691314697266
Batch 45/64 loss: -2.976715087890625
Batch 46/64 loss: -2.9308223724365234
Batch 47/64 loss: -3.0581321716308594
Batch 48/64 loss: -2.765989303588867
Batch 49/64 loss: -2.9358606338500977
Batch 50/64 loss: -2.994844436645508
Batch 51/64 loss: -3.0342864990234375
Batch 52/64 loss: -3.012897491455078
Batch 53/64 loss: -3.0881261825561523
Batch 54/64 loss: -2.709920883178711
Batch 55/64 loss: -2.848616600036621
Batch 56/64 loss: -2.285045623779297
Batch 57/64 loss: -2.9629201889038086
Batch 58/64 loss: -3.082791328430176
Batch 59/64 loss: -2.929682731628418
Batch 60/64 loss: -2.948843002319336
Batch 61/64 loss: -2.774165153503418
Batch 62/64 loss: -2.6072044372558594
Batch 63/64 loss: -3.195249557495117
Batch 64/64 loss: -7.425516128540039
Epoch 460  Train loss: -2.9816717783610027  Val loss: -3.2725719176616863
Epoch 461
-------------------------------
Batch 1/64 loss: -2.9229183197021484
Batch 2/64 loss: -3.0485010147094727
Batch 3/64 loss: -3.059840202331543
Batch 4/64 loss: -2.676443099975586
Batch 5/64 loss: -2.9019041061401367
Batch 6/64 loss: -2.7607040405273438
Batch 7/64 loss: -3.0011959075927734
Batch 8/64 loss: -3.1473875045776367
Batch 9/64 loss: -3.095980644226074
Batch 10/64 loss: -2.839289665222168
Batch 11/64 loss: -2.941404342651367
Batch 12/64 loss: -2.7549819946289062
Batch 13/64 loss: -3.077157974243164
Batch 14/64 loss: -3.1714038848876953
Batch 15/64 loss: -3.145846366882324
Batch 16/64 loss: -2.9235219955444336
Batch 17/64 loss: -3.1967458724975586
Batch 18/64 loss: -3.041550636291504
Batch 19/64 loss: -3.0445423126220703
Batch 20/64 loss: -3.030466079711914
Batch 21/64 loss: -3.057000160217285
Batch 22/64 loss: -3.0809831619262695
Batch 23/64 loss: -2.947450637817383
Batch 24/64 loss: -2.681905746459961
Batch 25/64 loss: -2.920866012573242
Batch 26/64 loss: -3.0359716415405273
Batch 27/64 loss: -2.6240758895874023
Batch 28/64 loss: -2.738248825073242
Batch 29/64 loss: -3.1531906127929688
Batch 30/64 loss: -3.173041343688965
Batch 31/64 loss: -3.0335512161254883
Batch 32/64 loss: -3.101626396179199
Batch 33/64 loss: -3.0965566635131836
Batch 34/64 loss: -3.0381641387939453
Batch 35/64 loss: -3.026669502258301
Batch 36/64 loss: -2.825474739074707
Batch 37/64 loss: -2.9212684631347656
Batch 38/64 loss: -2.875247001647949
Batch 39/64 loss: -3.182985305786133
Batch 40/64 loss: -2.508401870727539
Batch 41/64 loss: -3.0817480087280273
Batch 42/64 loss: -3.095850944519043
Batch 43/64 loss: -2.5589494705200195
Batch 44/64 loss: -3.05300235748291
Batch 45/64 loss: -2.883730888366699
Batch 46/64 loss: -2.9761581420898438
Batch 47/64 loss: -3.0522842407226562
Batch 48/64 loss: -3.014716148376465
Batch 49/64 loss: -2.997804641723633
Batch 50/64 loss: -2.929692268371582
Batch 51/64 loss: -3.090238571166992
Batch 52/64 loss: -3.031435966491699
Batch 53/64 loss: -3.0133304595947266
Batch 54/64 loss: -2.7860212326049805
Batch 55/64 loss: -3.120746612548828
Batch 56/64 loss: -3.043018341064453
Batch 57/64 loss: -3.1643190383911133
Batch 58/64 loss: -2.8513031005859375
Batch 59/64 loss: -3.218319892883301
Batch 60/64 loss: -2.349203109741211
Batch 61/64 loss: -2.9721450805664062
Batch 62/64 loss: -2.4104719161987305
Batch 63/64 loss: -2.8841304779052734
Batch 64/64 loss: -7.625568866729736
Epoch 461  Train loss: -3.01336882909139  Val loss: -3.289929930696782
Epoch 462
-------------------------------
Batch 1/64 loss: -3.2026968002319336
Batch 2/64 loss: -3.01676082611084
Batch 3/64 loss: -2.935978889465332
Batch 4/64 loss: -3.0159120559692383
Batch 5/64 loss: -2.9992446899414062
Batch 6/64 loss: -2.9650211334228516
Batch 7/64 loss: -3.024679183959961
Batch 8/64 loss: -3.2396111488342285
Batch 9/64 loss: -2.8267135620117188
Batch 10/64 loss: -3.0968332290649414
Batch 11/64 loss: -3.0713014602661133
Batch 12/64 loss: -3.091303825378418
Batch 13/64 loss: -3.0829381942749023
Batch 14/64 loss: -3.0731143951416016
Batch 15/64 loss: -3.0604162216186523
Batch 16/64 loss: -3.2020788192749023
Batch 17/64 loss: -2.317784309387207
Batch 18/64 loss: -3.074721336364746
Batch 19/64 loss: -3.1149349212646484
Batch 20/64 loss: -3.007038116455078
Batch 21/64 loss: -3.044255256652832
Batch 22/64 loss: -3.1916894912719727
Batch 23/64 loss: -2.8939056396484375
Batch 24/64 loss: -3.0345849990844727
Batch 25/64 loss: -2.893742561340332
Batch 26/64 loss: -3.0243568420410156
Batch 27/64 loss: -3.0890207290649414
Batch 28/64 loss: -3.103793144226074
Batch 29/64 loss: -3.0538177490234375
Batch 30/64 loss: -2.1691646575927734
Batch 31/64 loss: -2.8562183380126953
Batch 32/64 loss: -2.9465484619140625
Batch 33/64 loss: -2.9891862869262695
Batch 34/64 loss: -3.100081443786621
Batch 35/64 loss: -3.0917396545410156
Batch 36/64 loss: -3.0612354278564453
Batch 37/64 loss: -2.9563093185424805
Batch 38/64 loss: -2.7902631759643555
Batch 39/64 loss: -3.028813362121582
Batch 40/64 loss: -2.82645320892334
Batch 41/64 loss: -3.039102554321289
Batch 42/64 loss: -2.816971778869629
Batch 43/64 loss: -3.151456832885742
Batch 44/64 loss: -3.0641279220581055
Batch 45/64 loss: -3.196467399597168
Batch 46/64 loss: -2.998382568359375
Batch 47/64 loss: -2.7881345748901367
Batch 48/64 loss: -2.8933277130126953
Batch 49/64 loss: -3.0910634994506836
Batch 50/64 loss: -2.6112966537475586
Batch 51/64 loss: -2.8088464736938477
Batch 52/64 loss: -3.201899528503418
Batch 53/64 loss: -3.1291303634643555
Batch 54/64 loss: -2.993170738220215
Batch 55/64 loss: -3.1163759231567383
Batch 56/64 loss: -3.0813817977905273
Batch 57/64 loss: -2.9513425827026367
Batch 58/64 loss: -3.0687503814697266
Batch 59/64 loss: -2.974825859069824
Batch 60/64 loss: -3.0050525665283203
Batch 61/64 loss: -3.1945157051086426
Batch 62/64 loss: -2.9741697311401367
Batch 63/64 loss: -2.942044258117676
Batch 64/64 loss: -7.409656524658203
Epoch 462  Train loss: -3.0464838065353095  Val loss: -3.3483937057023194
Epoch 463
-------------------------------
Batch 1/64 loss: -3.122298240661621
Batch 2/64 loss: -3.2429018020629883
Batch 3/64 loss: -2.976581573486328
Batch 4/64 loss: -3.2614493370056152
Batch 5/64 loss: -3.2248830795288086
Batch 6/64 loss: -3.1360864639282227
Batch 7/64 loss: -3.0631866455078125
Batch 8/64 loss: -3.062070846557617
Batch 9/64 loss: -3.145627975463867
Batch 10/64 loss: -2.9390363693237305
Batch 11/64 loss: -2.8681373596191406
Batch 12/64 loss: -2.739431381225586
Batch 13/64 loss: -3.0660133361816406
Batch 14/64 loss: -3.1547393798828125
Batch 15/64 loss: -3.0961732864379883
Batch 16/64 loss: -3.096379280090332
Batch 17/64 loss: -3.048419952392578
Batch 18/64 loss: -2.994988441467285
Batch 19/64 loss: -2.8777198791503906
Batch 20/64 loss: -3.099724769592285
Batch 21/64 loss: -2.9401559829711914
Batch 22/64 loss: -2.960439682006836
Batch 23/64 loss: -2.8533248901367188
Batch 24/64 loss: -2.561039924621582
Batch 25/64 loss: -2.904367446899414
Batch 26/64 loss: -2.914560317993164
Batch 27/64 loss: -2.954033851623535
Batch 28/64 loss: -2.6876020431518555
Batch 29/64 loss: -3.0676870346069336
Batch 30/64 loss: -2.965266227722168
Batch 31/64 loss: -2.978013038635254
Batch 32/64 loss: -3.2098140716552734
Batch 33/64 loss: -3.09737491607666
Batch 34/64 loss: -3.1022109985351562
Batch 35/64 loss: -3.1780004501342773
Batch 36/64 loss: -2.6901397705078125
Batch 37/64 loss: -3.0866899490356445
Batch 38/64 loss: -3.0087623596191406
Batch 39/64 loss: -2.2906627655029297
Batch 40/64 loss: -3.058812141418457
Batch 41/64 loss: -3.019716262817383
Batch 42/64 loss: -2.9537715911865234
Batch 43/64 loss: -3.1356115341186523
Batch 44/64 loss: -3.026230812072754
Batch 45/64 loss: -3.135106086730957
Batch 46/64 loss: -3.0735692977905273
Batch 47/64 loss: -2.8497180938720703
Batch 48/64 loss: -2.9758405685424805
Batch 49/64 loss: -2.815845489501953
Batch 50/64 loss: -3.1096019744873047
Batch 51/64 loss: -3.024094581604004
Batch 52/64 loss: -2.657120704650879
Batch 53/64 loss: -3.093489646911621
Batch 54/64 loss: -2.861387252807617
Batch 55/64 loss: -3.1203651428222656
Batch 56/64 loss: -3.1633262634277344
Batch 57/64 loss: -2.8390092849731445
Batch 58/64 loss: -3.139317512512207
Batch 59/64 loss: -2.9223709106445312
Batch 60/64 loss: -3.038410186767578
Batch 61/64 loss: -1.7481670379638672
Batch 62/64 loss: -3.0646772384643555
Batch 63/64 loss: -3.131199836730957
Batch 64/64 loss: -7.034316062927246
Epoch 463  Train loss: -3.0258586920943915  Val loss: -3.325591280697957
Epoch 464
-------------------------------
Batch 1/64 loss: -2.722165107727051
Batch 2/64 loss: -3.2874555587768555
Batch 3/64 loss: -3.06333589553833
Batch 4/64 loss: -3.0142669677734375
Batch 5/64 loss: -2.535867691040039
Batch 6/64 loss: -3.126190185546875
Batch 7/64 loss: -3.050416946411133
Batch 8/64 loss: -3.051025390625
Batch 9/64 loss: -2.885690689086914
Batch 10/64 loss: -2.869866371154785
Batch 11/64 loss: -3.0938034057617188
Batch 12/64 loss: -3.120001792907715
Batch 13/64 loss: -3.0733985900878906
Batch 14/64 loss: -2.9679317474365234
Batch 15/64 loss: -2.5136070251464844
Batch 16/64 loss: -3.330781936645508
Batch 17/64 loss: -3.03397274017334
Batch 18/64 loss: -3.1876115798950195
Batch 19/64 loss: -2.953579902648926
Batch 20/64 loss: -2.9482650756835938
Batch 21/64 loss: -3.129683494567871
Batch 22/64 loss: -3.0034542083740234
Batch 23/64 loss: -2.9694395065307617
Batch 24/64 loss: -3.251345157623291
Batch 25/64 loss: -2.813669204711914
Batch 26/64 loss: -3.132364273071289
Batch 27/64 loss: -3.251980781555176
Batch 28/64 loss: -3.0558767318725586
Batch 29/64 loss: -3.1094369888305664
Batch 30/64 loss: -3.0438947677612305
Batch 31/64 loss: -2.9936094284057617
Batch 32/64 loss: -3.0965566635131836
Batch 33/64 loss: -2.500051498413086
Batch 34/64 loss: -3.040432929992676
Batch 35/64 loss: -3.1096372604370117
Batch 36/64 loss: -3.1137266159057617
Batch 37/64 loss: -2.4144296646118164
Batch 38/64 loss: -3.0870933532714844
Batch 39/64 loss: -3.034229278564453
Batch 40/64 loss: -3.1287851333618164
Batch 41/64 loss: -3.090022087097168
Batch 42/64 loss: -2.9920225143432617
Batch 43/64 loss: -2.5398759841918945
Batch 44/64 loss: -2.97489070892334
Batch 45/64 loss: -3.1836137771606445
Batch 46/64 loss: -2.919741630554199
Batch 47/64 loss: -2.8748035430908203
Batch 48/64 loss: -3.099032402038574
Batch 49/64 loss: -2.605250358581543
Batch 50/64 loss: -2.8546438217163086
Batch 51/64 loss: -3.1934890747070312
Batch 52/64 loss: -3.102794647216797
Batch 53/64 loss: -3.184879779815674
Batch 54/64 loss: -2.94158935546875
Batch 55/64 loss: -3.132854461669922
Batch 56/64 loss: -2.8884544372558594
Batch 57/64 loss: -3.2754411697387695
Batch 58/64 loss: -3.1703433990478516
Batch 59/64 loss: -3.0840110778808594
Batch 60/64 loss: -3.050466537475586
Batch 61/64 loss: -3.1531476974487305
Batch 62/64 loss: -2.8921871185302734
Batch 63/64 loss: -3.0107955932617188
Batch 64/64 loss: -7.320284843444824
Epoch 464  Train loss: -3.0558979819802676  Val loss: -3.307606844557929
Epoch 465
-------------------------------
Batch 1/64 loss: -2.628298759460449
Batch 2/64 loss: -2.880599021911621
Batch 3/64 loss: -3.1886777877807617
Batch 4/64 loss: -2.777202606201172
Batch 5/64 loss: -3.088409423828125
Batch 6/64 loss: -3.1236562728881836
Batch 7/64 loss: -3.0081567764282227
Batch 8/64 loss: -2.8252029418945312
Batch 9/64 loss: -3.0367679595947266
Batch 10/64 loss: -3.1770849227905273
Batch 11/64 loss: -2.8880701065063477
Batch 12/64 loss: -2.85805606842041
Batch 13/64 loss: -3.0606727600097656
Batch 14/64 loss: -3.0149173736572266
Batch 15/64 loss: -3.164487838745117
Batch 16/64 loss: -2.1900978088378906
Batch 17/64 loss: -2.6553497314453125
Batch 18/64 loss: -2.986562728881836
Batch 19/64 loss: -2.9031248092651367
Batch 20/64 loss: -3.005413055419922
Batch 21/64 loss: -2.9583330154418945
Batch 22/64 loss: -2.974644660949707
Batch 23/64 loss: -2.9598331451416016
Batch 24/64 loss: -2.9196653366088867
Batch 25/64 loss: -3.0953140258789062
Batch 26/64 loss: -3.0052013397216797
Batch 27/64 loss: -3.052135467529297
Batch 28/64 loss: -3.1142749786376953
Batch 29/64 loss: -3.122361183166504
Batch 30/64 loss: -2.7724390029907227
Batch 31/64 loss: -2.9735918045043945
Batch 32/64 loss: -2.7204065322875977
Batch 33/64 loss: -3.094280242919922
Batch 34/64 loss: -3.0837764739990234
Batch 35/64 loss: -3.113844871520996
Batch 36/64 loss: -3.0443735122680664
Batch 37/64 loss: -2.9570627212524414
Batch 38/64 loss: -3.067681312561035
Batch 39/64 loss: -2.6657114028930664
Batch 40/64 loss: -3.0936269760131836
Batch 41/64 loss: -3.023468017578125
Batch 42/64 loss: -2.7872724533081055
Batch 43/64 loss: -3.2462949752807617
Batch 44/64 loss: -2.997894287109375
Batch 45/64 loss: -2.8943119049072266
Batch 46/64 loss: -3.1090145111083984
Batch 47/64 loss: -3.1645145416259766
Batch 48/64 loss: -2.4795827865600586
Batch 49/64 loss: -2.6699914932250977
Batch 50/64 loss: -2.996188163757324
Batch 51/64 loss: -2.9802675247192383
Batch 52/64 loss: -2.841970443725586
Batch 53/64 loss: -3.0997114181518555
Batch 54/64 loss: -3.0913829803466797
Batch 55/64 loss: -3.1165199279785156
Batch 56/64 loss: -2.7856178283691406
Batch 57/64 loss: -3.2649693489074707
Batch 58/64 loss: -3.1970014572143555
Batch 59/64 loss: -2.4653406143188477
Batch 60/64 loss: -3.185993194580078
Batch 61/64 loss: -3.097630500793457
Batch 62/64 loss: -2.9756059646606445
Batch 63/64 loss: -2.766484260559082
Batch 64/64 loss: -7.572092056274414
Epoch 465  Train loss: -3.0143602259018842  Val loss: -3.2847340770603455
Epoch 466
-------------------------------
Batch 1/64 loss: -3.1203126907348633
Batch 2/64 loss: -2.959207534790039
Batch 3/64 loss: -3.0485496520996094
Batch 4/64 loss: -3.146350860595703
Batch 5/64 loss: -2.9094886779785156
Batch 6/64 loss: -3.2697181701660156
Batch 7/64 loss: -3.1263341903686523
Batch 8/64 loss: -2.284273147583008
Batch 9/64 loss: -3.1042118072509766
Batch 10/64 loss: -3.097627639770508
Batch 11/64 loss: -2.987558364868164
Batch 12/64 loss: -3.098642349243164
Batch 13/64 loss: -3.0129051208496094
Batch 14/64 loss: -3.183375358581543
Batch 15/64 loss: -2.9928789138793945
Batch 16/64 loss: -3.0999650955200195
Batch 17/64 loss: -2.508373260498047
Batch 18/64 loss: -2.9993438720703125
Batch 19/64 loss: -2.8421525955200195
Batch 20/64 loss: -3.105388641357422
Batch 21/64 loss: -2.7298107147216797
Batch 22/64 loss: -3.0275564193725586
Batch 23/64 loss: -2.9823646545410156
Batch 24/64 loss: -3.1382083892822266
Batch 25/64 loss: -2.976578712463379
Batch 26/64 loss: -2.7634057998657227
Batch 27/64 loss: -2.774179458618164
Batch 28/64 loss: -3.0067739486694336
Batch 29/64 loss: -2.9042673110961914
Batch 30/64 loss: -2.8951845169067383
Batch 31/64 loss: -3.070009231567383
Batch 32/64 loss: -3.0082597732543945
Batch 33/64 loss: -3.1817893981933594
Batch 34/64 loss: -2.8070497512817383
Batch 35/64 loss: -2.9700117111206055
Batch 36/64 loss: -3.02023983001709
Batch 37/64 loss: -3.1439504623413086
Batch 38/64 loss: -3.048457145690918
Batch 39/64 loss: -2.860410690307617
Batch 40/64 loss: -2.9210243225097656
Batch 41/64 loss: -2.7275028228759766
Batch 42/64 loss: -2.928338050842285
Batch 43/64 loss: -3.0486536026000977
Batch 44/64 loss: -2.5178756713867188
Batch 45/64 loss: -3.1540040969848633
Batch 46/64 loss: -2.994359016418457
Batch 47/64 loss: -2.5646018981933594
Batch 48/64 loss: -3.0251283645629883
Batch 49/64 loss: -2.824310302734375
Batch 50/64 loss: -3.0798873901367188
Batch 51/64 loss: -3.052300453186035
Batch 52/64 loss: -3.0037174224853516
Batch 53/64 loss: -3.028656005859375
Batch 54/64 loss: -3.193716049194336
Batch 55/64 loss: -2.858022689819336
Batch 56/64 loss: -3.074129104614258
Batch 57/64 loss: -2.952749252319336
Batch 58/64 loss: -3.1234378814697266
Batch 59/64 loss: -3.3215279579162598
Batch 60/64 loss: -2.946380615234375
Batch 61/64 loss: -2.6234121322631836
Batch 62/64 loss: -3.1368837356567383
Batch 63/64 loss: -3.097179412841797
Batch 64/64 loss: -7.504857063293457
Epoch 466  Train loss: -3.0279467750998106  Val loss: -3.297061107412646
Epoch 467
-------------------------------
Batch 1/64 loss: -3.1484222412109375
Batch 2/64 loss: -3.201350212097168
Batch 3/64 loss: -2.9586801528930664
Batch 4/64 loss: -2.4804277420043945
Batch 5/64 loss: -3.0046777725219727
Batch 6/64 loss: -3.2795352935791016
Batch 7/64 loss: -3.024822235107422
Batch 8/64 loss: -3.3019776344299316
Batch 9/64 loss: -3.107192039489746
Batch 10/64 loss: -3.111283302307129
Batch 11/64 loss: -2.8448524475097656
Batch 12/64 loss: -3.023922920227051
Batch 13/64 loss: -2.998204231262207
Batch 14/64 loss: -2.980203628540039
Batch 15/64 loss: -3.010068893432617
Batch 16/64 loss: -3.166813850402832
Batch 17/64 loss: -3.024041175842285
Batch 18/64 loss: -2.3550758361816406
Batch 19/64 loss: -3.0291833877563477
Batch 20/64 loss: -3.207887649536133
Batch 21/64 loss: -3.095182418823242
Batch 22/64 loss: -2.956653594970703
Batch 23/64 loss: -2.8592700958251953
Batch 24/64 loss: -3.0616331100463867
Batch 25/64 loss: -3.1301116943359375
Batch 26/64 loss: -3.083430290222168
Batch 27/64 loss: -3.0128040313720703
Batch 28/64 loss: -2.8259353637695312
Batch 29/64 loss: -3.140401840209961
Batch 30/64 loss: -3.06168270111084
Batch 31/64 loss: -2.9151926040649414
Batch 32/64 loss: -3.182344436645508
Batch 33/64 loss: -3.143728256225586
Batch 34/64 loss: -2.720144271850586
Batch 35/64 loss: -2.731281280517578
Batch 36/64 loss: -3.115187644958496
Batch 37/64 loss: -2.990056037902832
Batch 38/64 loss: -3.296635150909424
Batch 39/64 loss: -3.0057477951049805
Batch 40/64 loss: -3.0202722549438477
Batch 41/64 loss: -3.052981376647949
Batch 42/64 loss: -2.880094528198242
Batch 43/64 loss: -2.717606544494629
Batch 44/64 loss: -2.8913373947143555
Batch 45/64 loss: -3.1971874237060547
Batch 46/64 loss: -3.1200618743896484
Batch 47/64 loss: -3.2212400436401367
Batch 48/64 loss: -3.13124942779541
Batch 49/64 loss: -2.4029178619384766
Batch 50/64 loss: -2.9493093490600586
Batch 51/64 loss: -3.1078710556030273
Batch 52/64 loss: -2.9791440963745117
Batch 53/64 loss: -3.2034292221069336
Batch 54/64 loss: -3.0290842056274414
Batch 55/64 loss: -2.922372817993164
Batch 56/64 loss: -2.9434194564819336
Batch 57/64 loss: -2.981165885925293
Batch 58/64 loss: -3.1152725219726562
Batch 59/64 loss: -2.991347312927246
Batch 60/64 loss: -2.9638757705688477
Batch 61/64 loss: -2.9901180267333984
Batch 62/64 loss: -3.000448226928711
Batch 63/64 loss: -3.0767898559570312
Batch 64/64 loss: -7.520486354827881
Epoch 467  Train loss: -3.0606275539772185  Val loss: -3.330932276355442
Epoch 468
-------------------------------
Batch 1/64 loss: -2.8478355407714844
Batch 2/64 loss: -3.1988630294799805
Batch 3/64 loss: -3.164348602294922
Batch 4/64 loss: -2.5706262588500977
Batch 5/64 loss: -3.152872085571289
Batch 6/64 loss: -2.6279544830322266
Batch 7/64 loss: -3.1344451904296875
Batch 8/64 loss: -3.088618278503418
Batch 9/64 loss: -3.182419776916504
Batch 10/64 loss: -3.1446352005004883
Batch 11/64 loss: -2.906508445739746
Batch 12/64 loss: -3.0488710403442383
Batch 13/64 loss: -2.9197311401367188
Batch 14/64 loss: -3.17264461517334
Batch 15/64 loss: -2.94522762298584
Batch 16/64 loss: -3.0444202423095703
Batch 17/64 loss: -3.1121673583984375
Batch 18/64 loss: -3.1800785064697266
Batch 19/64 loss: -3.1417722702026367
Batch 20/64 loss: -3.0961217880249023
Batch 21/64 loss: -3.2510933876037598
Batch 22/64 loss: -3.092312812805176
Batch 23/64 loss: -2.7437524795532227
Batch 24/64 loss: -2.3663501739501953
Batch 25/64 loss: -3.1226186752319336
Batch 26/64 loss: -2.9729976654052734
Batch 27/64 loss: -2.9137754440307617
Batch 28/64 loss: -3.131795883178711
Batch 29/64 loss: -3.0579357147216797
Batch 30/64 loss: -2.965176582336426
Batch 31/64 loss: -3.053328514099121
Batch 32/64 loss: -2.9714136123657227
Batch 33/64 loss: -3.104890823364258
Batch 34/64 loss: -3.160830497741699
Batch 35/64 loss: -3.108687400817871
Batch 36/64 loss: -2.9673585891723633
Batch 37/64 loss: -3.1256322860717773
Batch 38/64 loss: -3.014805793762207
Batch 39/64 loss: -3.2245168685913086
Batch 40/64 loss: -2.9542160034179688
Batch 41/64 loss: -2.4299097061157227
Batch 42/64 loss: -3.0264644622802734
Batch 43/64 loss: -3.109649658203125
Batch 44/64 loss: -2.7857275009155273
Batch 45/64 loss: -2.85092830657959
Batch 46/64 loss: -3.172762870788574
Batch 47/64 loss: -3.110248565673828
Batch 48/64 loss: -2.9226303100585938
Batch 49/64 loss: -2.857330322265625
Batch 50/64 loss: -2.4978294372558594
Batch 51/64 loss: -2.91217041015625
Batch 52/64 loss: -3.0393190383911133
Batch 53/64 loss: -2.9196815490722656
Batch 54/64 loss: -3.076444625854492
Batch 55/64 loss: -2.9794578552246094
Batch 56/64 loss: -2.7286462783813477
Batch 57/64 loss: -3.061427116394043
Batch 58/64 loss: -3.180391311645508
Batch 59/64 loss: -3.0997438430786133
Batch 60/64 loss: -3.1482839584350586
Batch 61/64 loss: -2.9953250885009766
Batch 62/64 loss: -3.0466995239257812
Batch 63/64 loss: -2.949131965637207
Batch 64/64 loss: -7.571884632110596
Epoch 468  Train loss: -3.0519649860905664  Val loss: -3.32718758075098
Epoch 469
-------------------------------
Batch 1/64 loss: -3.070995330810547
Batch 2/64 loss: -3.079814910888672
Batch 3/64 loss: -3.0800657272338867
Batch 4/64 loss: -3.123959541320801
Batch 5/64 loss: -2.9226951599121094
Batch 6/64 loss: -2.9783973693847656
Batch 7/64 loss: -2.984090805053711
Batch 8/64 loss: -2.9399337768554688
Batch 9/64 loss: -2.8182477951049805
Batch 10/64 loss: -3.051825523376465
Batch 11/64 loss: -2.743000030517578
Batch 12/64 loss: -2.798429489135742
Batch 13/64 loss: -3.012289047241211
Batch 14/64 loss: -3.0627031326293945
Batch 15/64 loss: -3.048419952392578
Batch 16/64 loss: -2.817159652709961
Batch 17/64 loss: -2.8303518295288086
Batch 18/64 loss: -2.8857078552246094
Batch 19/64 loss: -3.114126205444336
Batch 20/64 loss: -3.072258949279785
Batch 21/64 loss: -2.517536163330078
Batch 22/64 loss: -2.8179502487182617
Batch 23/64 loss: -3.1077394485473633
Batch 24/64 loss: -2.4152050018310547
Batch 25/64 loss: -3.145322799682617
Batch 26/64 loss: -3.010099411010742
Batch 27/64 loss: -3.0981292724609375
Batch 28/64 loss: -2.8109264373779297
Batch 29/64 loss: -2.899834632873535
Batch 30/64 loss: -2.7987585067749023
Batch 31/64 loss: -2.985751152038574
Batch 32/64 loss: -2.8306808471679688
Batch 33/64 loss: -3.1442747116088867
Batch 34/64 loss: -2.9351062774658203
Batch 35/64 loss: -3.1544189453125
Batch 36/64 loss: -2.947016716003418
Batch 37/64 loss: -3.070467948913574
Batch 38/64 loss: -3.0359363555908203
Batch 39/64 loss: -3.077791213989258
Batch 40/64 loss: -3.0532474517822266
Batch 41/64 loss: -3.006485939025879
Batch 42/64 loss: -3.0584545135498047
Batch 43/64 loss: -3.0439300537109375
Batch 44/64 loss: -3.1509275436401367
Batch 45/64 loss: -3.1235733032226562
Batch 46/64 loss: -2.9256439208984375
Batch 47/64 loss: -2.4752931594848633
Batch 48/64 loss: -3.192204475402832
Batch 49/64 loss: -2.970221519470215
Batch 50/64 loss: -3.1599302291870117
Batch 51/64 loss: -2.838027000427246
Batch 52/64 loss: -3.056652069091797
Batch 53/64 loss: -3.005949020385742
Batch 54/64 loss: -3.078183174133301
Batch 55/64 loss: -3.013546943664551
Batch 56/64 loss: -2.925726890563965
Batch 57/64 loss: -3.0937280654907227
Batch 58/64 loss: -2.9816818237304688
Batch 59/64 loss: -3.0718555450439453
Batch 60/64 loss: -2.472501754760742
Batch 61/64 loss: -2.823871612548828
Batch 62/64 loss: -3.025172233581543
Batch 63/64 loss: -2.9199514389038086
Batch 64/64 loss: -7.616647720336914
Epoch 469  Train loss: -3.018300606222714  Val loss: -3.372247178120302
Saving best model, epoch: 469
Epoch 470
-------------------------------
Batch 1/64 loss: -2.8430051803588867
Batch 2/64 loss: -3.159316062927246
Batch 3/64 loss: -3.056499481201172
Batch 4/64 loss: -2.9696292877197266
Batch 5/64 loss: -2.8939523696899414
Batch 6/64 loss: -3.1129150390625
Batch 7/64 loss: -3.0749120712280273
Batch 8/64 loss: -3.141842842102051
Batch 9/64 loss: -3.1804819107055664
Batch 10/64 loss: -3.07753849029541
Batch 11/64 loss: -3.147327423095703
Batch 12/64 loss: -3.037710189819336
Batch 13/64 loss: -2.839510917663574
Batch 14/64 loss: -2.9544639587402344
Batch 15/64 loss: -2.450411796569824
Batch 16/64 loss: -3.0342893600463867
Batch 17/64 loss: -3.035429000854492
Batch 18/64 loss: -3.1148176193237305
Batch 19/64 loss: -3.166604995727539
Batch 20/64 loss: -3.1399192810058594
Batch 21/64 loss: -2.500452995300293
Batch 22/64 loss: -2.432583808898926
Batch 23/64 loss: -2.210391044616699
Batch 24/64 loss: -3.0160045623779297
Batch 25/64 loss: -3.029923439025879
Batch 26/64 loss: -2.880685806274414
Batch 27/64 loss: -2.744722366333008
Batch 28/64 loss: -3.1692190170288086
Batch 29/64 loss: -2.820672035217285
Batch 30/64 loss: -3.1163434982299805
Batch 31/64 loss: -2.892190933227539
Batch 32/64 loss: -2.964980125427246
Batch 33/64 loss: -2.853107452392578
Batch 34/64 loss: -3.147791862487793
Batch 35/64 loss: -3.0114850997924805
Batch 36/64 loss: -3.1197519302368164
Batch 37/64 loss: -3.0409297943115234
Batch 38/64 loss: -2.921219825744629
Batch 39/64 loss: -3.0485105514526367
Batch 40/64 loss: -2.784682273864746
Batch 41/64 loss: -3.0164690017700195
Batch 42/64 loss: -3.1128597259521484
Batch 43/64 loss: -2.524026870727539
Batch 44/64 loss: -3.02886962890625
Batch 45/64 loss: -3.056692123413086
Batch 46/64 loss: -3.172144889831543
Batch 47/64 loss: -3.1208181381225586
Batch 48/64 loss: -3.136988639831543
Batch 49/64 loss: -3.1193456649780273
Batch 50/64 loss: -3.0428638458251953
Batch 51/64 loss: -3.0041189193725586
Batch 52/64 loss: -2.7022790908813477
Batch 53/64 loss: -3.015681266784668
Batch 54/64 loss: -3.0616140365600586
Batch 55/64 loss: -3.135408401489258
Batch 56/64 loss: -3.1178979873657227
Batch 57/64 loss: -2.959193229675293
Batch 58/64 loss: -3.0618724822998047
Batch 59/64 loss: -3.1302175521850586
Batch 60/64 loss: -2.884794235229492
Batch 61/64 loss: -3.055173873901367
Batch 62/64 loss: -3.1965227127075195
Batch 63/64 loss: -3.2219371795654297
Batch 64/64 loss: -7.583166122436523
Epoch 470  Train loss: -3.038453173169903  Val loss: -3.334131863518679
Epoch 471
-------------------------------
Batch 1/64 loss: -3.343825340270996
Batch 2/64 loss: -3.115725517272949
Batch 3/64 loss: -2.8645095825195312
Batch 4/64 loss: -2.8220767974853516
Batch 5/64 loss: -2.9907474517822266
Batch 6/64 loss: -2.8281211853027344
Batch 7/64 loss: -3.0113086700439453
Batch 8/64 loss: -3.1394834518432617
Batch 9/64 loss: -2.4963560104370117
Batch 10/64 loss: -3.286284923553467
Batch 11/64 loss: -2.789067268371582
Batch 12/64 loss: -3.1170225143432617
Batch 13/64 loss: -3.1707372665405273
Batch 14/64 loss: -3.1047067642211914
Batch 15/64 loss: -3.110799789428711
Batch 16/64 loss: -2.977227210998535
Batch 17/64 loss: -2.887735366821289
Batch 18/64 loss: -3.080097198486328
Batch 19/64 loss: -3.118762969970703
Batch 20/64 loss: -3.050225257873535
Batch 21/64 loss: -3.108642578125
Batch 22/64 loss: -2.9585351943969727
Batch 23/64 loss: -2.381441116333008
Batch 24/64 loss: -2.917295455932617
Batch 25/64 loss: -2.9640913009643555
Batch 26/64 loss: -2.893765449523926
Batch 27/64 loss: -2.8720006942749023
Batch 28/64 loss: -3.2236380577087402
Batch 29/64 loss: -2.7490949630737305
Batch 30/64 loss: -2.8099851608276367
Batch 31/64 loss: -2.95611572265625
Batch 32/64 loss: -2.4457597732543945
Batch 33/64 loss: -2.9370250701904297
Batch 34/64 loss: -2.90938663482666
Batch 35/64 loss: -2.973733901977539
Batch 36/64 loss: -2.9919443130493164
Batch 37/64 loss: -2.9128313064575195
Batch 38/64 loss: -3.016080856323242
Batch 39/64 loss: -3.144041061401367
Batch 40/64 loss: -2.3359365463256836
Batch 41/64 loss: -3.0613555908203125
Batch 42/64 loss: -3.014680862426758
Batch 43/64 loss: -3.2407174110412598
Batch 44/64 loss: -3.136317253112793
Batch 45/64 loss: -3.0408010482788086
Batch 46/64 loss: -3.0363826751708984
Batch 47/64 loss: -2.99906063079834
Batch 48/64 loss: -2.96761417388916
Batch 49/64 loss: -3.0554847717285156
Batch 50/64 loss: -2.9465837478637695
Batch 51/64 loss: -2.971302032470703
Batch 52/64 loss: -3.104869842529297
Batch 53/64 loss: -2.3255224227905273
Batch 54/64 loss: -3.016282081604004
Batch 55/64 loss: -3.1769824028015137
Batch 56/64 loss: -2.9695873260498047
Batch 57/64 loss: -2.5972423553466797
Batch 58/64 loss: -3.0054969787597656
Batch 59/64 loss: -3.0037126541137695
Batch 60/64 loss: -3.1635684967041016
Batch 61/64 loss: -2.6096887588500977
Batch 62/64 loss: -3.1911535263061523
Batch 63/64 loss: -3.0106077194213867
Batch 64/64 loss: -7.571337699890137
Epoch 471  Train loss: -3.0137989605174345  Val loss: -3.204879695197561
Epoch 472
-------------------------------
Batch 1/64 loss: -2.934988021850586
Batch 2/64 loss: -3.1868515014648438
Batch 3/64 loss: -2.779059410095215
Batch 4/64 loss: -2.7613677978515625
Batch 5/64 loss: -2.831144332885742
Batch 6/64 loss: -3.0328445434570312
Batch 7/64 loss: -2.5644140243530273
Batch 8/64 loss: -2.6977272033691406
Batch 9/64 loss: -2.8432188034057617
Batch 10/64 loss: -2.8805551528930664
Batch 11/64 loss: -2.8049497604370117
Batch 12/64 loss: -2.800037384033203
Batch 13/64 loss: -3.051732063293457
Batch 14/64 loss: -3.068203926086426
Batch 15/64 loss: -3.0075931549072266
Batch 16/64 loss: -2.7256784439086914
Batch 17/64 loss: -2.9268035888671875
Batch 18/64 loss: -2.984102249145508
Batch 19/64 loss: -2.970505714416504
Batch 20/64 loss: -3.1227035522460938
Batch 21/64 loss: -2.671963691711426
Batch 22/64 loss: -2.8913869857788086
Batch 23/64 loss: -3.0870494842529297
Batch 24/64 loss: -2.8589210510253906
Batch 25/64 loss: -2.344876289367676
Batch 26/64 loss: -2.978687286376953
Batch 27/64 loss: -2.8547544479370117
Batch 28/64 loss: -2.9010305404663086
Batch 29/64 loss: -2.840707778930664
Batch 30/64 loss: -2.8438634872436523
Batch 31/64 loss: -3.1354751586914062
Batch 32/64 loss: -2.962087631225586
Batch 33/64 loss: -3.1154394149780273
Batch 34/64 loss: -2.7305994033813477
Batch 35/64 loss: -2.8141965866088867
Batch 36/64 loss: -2.9404802322387695
Batch 37/64 loss: -2.9404001235961914
Batch 38/64 loss: -2.869929313659668
Batch 39/64 loss: -2.8256988525390625
Batch 40/64 loss: -2.631875991821289
Batch 41/64 loss: -2.986992835998535
Batch 42/64 loss: -2.883969306945801
Batch 43/64 loss: -3.130875587463379
Batch 44/64 loss: -3.0349578857421875
Batch 45/64 loss: -2.4354515075683594
Batch 46/64 loss: -2.9043588638305664
Batch 47/64 loss: -3.0218019485473633
Batch 48/64 loss: -3.091181755065918
Batch 49/64 loss: -3.1700868606567383
Batch 50/64 loss: -3.1743412017822266
Batch 51/64 loss: -3.0664920806884766
Batch 52/64 loss: -2.5885438919067383
Batch 53/64 loss: -2.7694902420043945
Batch 54/64 loss: -2.827016830444336
Batch 55/64 loss: -2.8028392791748047
Batch 56/64 loss: -3.00382137298584
Batch 57/64 loss: -3.242691993713379
Batch 58/64 loss: -3.14443302154541
Batch 59/64 loss: -3.1392526626586914
Batch 60/64 loss: -3.060384750366211
Batch 61/64 loss: -2.748533248901367
Batch 62/64 loss: -3.1831579208374023
Batch 63/64 loss: -2.9369773864746094
Batch 64/64 loss: -7.660696983337402
Epoch 472  Train loss: -2.9695228165271237  Val loss: -3.3807169465264915
Saving best model, epoch: 472
Epoch 473
-------------------------------
Batch 1/64 loss: -2.9434900283813477
Batch 2/64 loss: -3.16617488861084
Batch 3/64 loss: -3.236583709716797
Batch 4/64 loss: -2.650075912475586
Batch 5/64 loss: -2.8286867141723633
Batch 6/64 loss: -3.1376800537109375
Batch 7/64 loss: -3.1113500595092773
Batch 8/64 loss: -3.0052080154418945
Batch 9/64 loss: -2.9357471466064453
Batch 10/64 loss: -3.047612190246582
Batch 11/64 loss: -2.929758071899414
Batch 12/64 loss: -2.816051483154297
Batch 13/64 loss: -3.1553916931152344
Batch 14/64 loss: -2.655069351196289
Batch 15/64 loss: -3.0984792709350586
Batch 16/64 loss: -3.1275548934936523
Batch 17/64 loss: -2.533421516418457
Batch 18/64 loss: -2.767803192138672
Batch 19/64 loss: -3.0228519439697266
Batch 20/64 loss: -3.0688915252685547
Batch 21/64 loss: -2.9471616744995117
Batch 22/64 loss: -3.0375356674194336
Batch 23/64 loss: -3.2967348098754883
Batch 24/64 loss: -2.82082462310791
Batch 25/64 loss: -2.7086591720581055
Batch 26/64 loss: -2.706493377685547
Batch 27/64 loss: -2.583022117614746
Batch 28/64 loss: -3.1048622131347656
Batch 29/64 loss: -3.15335750579834
Batch 30/64 loss: -3.1365842819213867
Batch 31/64 loss: -3.097376823425293
Batch 32/64 loss: -3.0130205154418945
Batch 33/64 loss: -2.8409271240234375
Batch 34/64 loss: -2.8504133224487305
Batch 35/64 loss: -3.0203142166137695
Batch 36/64 loss: -2.8166255950927734
Batch 37/64 loss: -3.1289377212524414
Batch 38/64 loss: -3.1820478439331055
Batch 39/64 loss: -3.284268379211426
Batch 40/64 loss: -2.97092342376709
Batch 41/64 loss: -3.001858711242676
Batch 42/64 loss: -2.9469470977783203
Batch 43/64 loss: -2.763148307800293
Batch 44/64 loss: -3.028712272644043
Batch 45/64 loss: -3.074069023132324
Batch 46/64 loss: -3.0929489135742188
Batch 47/64 loss: -3.0893774032592773
Batch 48/64 loss: -2.8280115127563477
Batch 49/64 loss: -2.748056411743164
Batch 50/64 loss: -2.984787940979004
Batch 51/64 loss: -3.178281307220459
Batch 52/64 loss: -3.1128101348876953
Batch 53/64 loss: -3.139763832092285
Batch 54/64 loss: -2.46462345123291
Batch 55/64 loss: -2.7060327529907227
Batch 56/64 loss: -2.962651252746582
Batch 57/64 loss: -3.178818702697754
Batch 58/64 loss: -3.0175914764404297
Batch 59/64 loss: -2.7786865234375
Batch 60/64 loss: -3.0360050201416016
Batch 61/64 loss: -3.0365524291992188
Batch 62/64 loss: -3.0488052368164062
Batch 63/64 loss: -2.8607025146484375
Batch 64/64 loss: -7.30045223236084
Epoch 473  Train loss: -3.0194910348630417  Val loss: -3.31892952148857
Epoch 474
-------------------------------
Batch 1/64 loss: -3.060293197631836
Batch 2/64 loss: -2.9645919799804688
Batch 3/64 loss: -3.177122116088867
Batch 4/64 loss: -2.789065361022949
Batch 5/64 loss: -3.1055450439453125
Batch 6/64 loss: -2.835513114929199
Batch 7/64 loss: -2.5855512619018555
Batch 8/64 loss: -2.9028100967407227
Batch 9/64 loss: -3.0011558532714844
Batch 10/64 loss: -3.1312456130981445
Batch 11/64 loss: -3.0026063919067383
Batch 12/64 loss: -2.2496023178100586
Batch 13/64 loss: -3.16009521484375
Batch 14/64 loss: -3.122738838195801
Batch 15/64 loss: -2.441514015197754
Batch 16/64 loss: -3.119363784790039
Batch 17/64 loss: -3.0825014114379883
Batch 18/64 loss: -3.116579055786133
Batch 19/64 loss: -2.943296432495117
Batch 20/64 loss: -2.9333572387695312
Batch 21/64 loss: -3.140303611755371
Batch 22/64 loss: -2.825005531311035
Batch 23/64 loss: -3.0309228897094727
Batch 24/64 loss: -3.018169403076172
Batch 25/64 loss: -3.043025016784668
Batch 26/64 loss: -3.0716543197631836
Batch 27/64 loss: -2.981217384338379
Batch 28/64 loss: -3.127934455871582
Batch 29/64 loss: -2.8938684463500977
Batch 30/64 loss: -3.0376548767089844
Batch 31/64 loss: -2.886077880859375
Batch 32/64 loss: -2.817439079284668
Batch 33/64 loss: -2.9422922134399414
Batch 34/64 loss: -2.8824691772460938
Batch 35/64 loss: -3.1078338623046875
Batch 36/64 loss: -3.0242528915405273
Batch 37/64 loss: -3.019144058227539
Batch 38/64 loss: -3.059246063232422
Batch 39/64 loss: -3.10504150390625
Batch 40/64 loss: -2.283492088317871
Batch 41/64 loss: -2.8080406188964844
Batch 42/64 loss: -2.7015485763549805
Batch 43/64 loss: -2.5011510848999023
Batch 44/64 loss: -2.9596128463745117
Batch 45/64 loss: -2.869966506958008
Batch 46/64 loss: -3.0087108612060547
Batch 47/64 loss: -3.174311637878418
Batch 48/64 loss: -2.9549827575683594
Batch 49/64 loss: -2.6827592849731445
Batch 50/64 loss: -3.130927085876465
Batch 51/64 loss: -3.0575084686279297
Batch 52/64 loss: -3.080656051635742
Batch 53/64 loss: -2.7854394912719727
Batch 54/64 loss: -2.8435020446777344
Batch 55/64 loss: -2.9669084548950195
Batch 56/64 loss: -2.973628044128418
Batch 57/64 loss: -2.7485532760620117
Batch 58/64 loss: -3.1216182708740234
Batch 59/64 loss: -2.7194719314575195
Batch 60/64 loss: -2.914470672607422
Batch 61/64 loss: -2.968477249145508
Batch 62/64 loss: -3.033749580383301
Batch 63/64 loss: -2.9422149658203125
Batch 64/64 loss: -7.260733604431152
Epoch 474  Train loss: -2.9869074989767634  Val loss: -3.2895672591691163
Epoch 475
-------------------------------
Batch 1/64 loss: -2.633798599243164
Batch 2/64 loss: -2.6518688201904297
Batch 3/64 loss: -3.0298891067504883
Batch 4/64 loss: -2.818789482116699
Batch 5/64 loss: -2.7503223419189453
Batch 6/64 loss: -3.075577735900879
Batch 7/64 loss: -3.10561466217041
Batch 8/64 loss: -2.950742721557617
Batch 9/64 loss: -2.509613037109375
Batch 10/64 loss: -3.020566940307617
Batch 11/64 loss: -2.4377546310424805
Batch 12/64 loss: -2.7131357192993164
Batch 13/64 loss: -2.928243637084961
Batch 14/64 loss: -2.9920568466186523
Batch 15/64 loss: -2.8172779083251953
Batch 16/64 loss: -2.8781280517578125
Batch 17/64 loss: -2.8782434463500977
Batch 18/64 loss: -2.794194221496582
Batch 19/64 loss: -3.033076286315918
Batch 20/64 loss: -2.9857406616210938
Batch 21/64 loss: -3.100675582885742
Batch 22/64 loss: -2.9690961837768555
Batch 23/64 loss: -2.9587326049804688
Batch 24/64 loss: -2.9468460083007812
Batch 25/64 loss: -2.984259605407715
Batch 26/64 loss: -2.5804805755615234
Batch 27/64 loss: -2.846438407897949
Batch 28/64 loss: -2.8207836151123047
Batch 29/64 loss: -2.777181625366211
Batch 30/64 loss: -3.129840850830078
Batch 31/64 loss: -3.081075668334961
Batch 32/64 loss: -3.1016273498535156
Batch 33/64 loss: -3.160780906677246
Batch 34/64 loss: -2.9436235427856445
Batch 35/64 loss: -2.5027332305908203
Batch 36/64 loss: -3.1324539184570312
Batch 37/64 loss: -2.969392776489258
Batch 38/64 loss: -2.9198684692382812
Batch 39/64 loss: -2.9538803100585938
Batch 40/64 loss: -2.876187324523926
Batch 41/64 loss: -2.8048534393310547
Batch 42/64 loss: -2.9868221282958984
Batch 43/64 loss: -3.039120674133301
Batch 44/64 loss: -2.377974510192871
Batch 45/64 loss: -2.897693634033203
Batch 46/64 loss: -3.1520986557006836
Batch 47/64 loss: -3.0677309036254883
Batch 48/64 loss: -2.9171581268310547
Batch 49/64 loss: -2.9842710494995117
Batch 50/64 loss: -3.050787925720215
Batch 51/64 loss: -3.066287040710449
Batch 52/64 loss: -3.199981689453125
Batch 53/64 loss: -2.9240341186523438
Batch 54/64 loss: -2.984219551086426
Batch 55/64 loss: -2.828219413757324
Batch 56/64 loss: -3.137073516845703
Batch 57/64 loss: -3.0005102157592773
Batch 58/64 loss: -3.138347625732422
Batch 59/64 loss: -2.951718330383301
Batch 60/64 loss: -3.002971649169922
Batch 61/64 loss: -3.0604915618896484
Batch 62/64 loss: -2.610236167907715
Batch 63/64 loss: -3.137436866760254
Batch 64/64 loss: -7.517746925354004
Epoch 475  Train loss: -2.9759834102555818  Val loss: -3.327380701438668
Epoch 476
-------------------------------
Batch 1/64 loss: -3.0158615112304688
Batch 2/64 loss: -2.842310905456543
Batch 3/64 loss: -3.1085634231567383
Batch 4/64 loss: -3.060701370239258
Batch 5/64 loss: -2.909648895263672
Batch 6/64 loss: -2.690915107727051
Batch 7/64 loss: -2.906081199645996
Batch 8/64 loss: -3.076859474182129
Batch 9/64 loss: -3.1685562133789062
Batch 10/64 loss: -2.600661277770996
Batch 11/64 loss: -3.2258710861206055
Batch 12/64 loss: -2.992129325866699
Batch 13/64 loss: -3.0917625427246094
Batch 14/64 loss: -3.042665481567383
Batch 15/64 loss: -2.768551826477051
Batch 16/64 loss: -3.1205921173095703
Batch 17/64 loss: -2.8891773223876953
Batch 18/64 loss: -2.999394416809082
Batch 19/64 loss: -3.1280651092529297
Batch 20/64 loss: -3.0501537322998047
Batch 21/64 loss: -3.128951072692871
Batch 22/64 loss: -3.225600242614746
Batch 23/64 loss: -3.054483413696289
Batch 24/64 loss: -3.01859188079834
Batch 25/64 loss: -3.077275276184082
Batch 26/64 loss: -2.9638938903808594
Batch 27/64 loss: -3.1604604721069336
Batch 28/64 loss: -3.0364770889282227
Batch 29/64 loss: -3.023627281188965
Batch 30/64 loss: -3.132965087890625
Batch 31/64 loss: -2.938344955444336
Batch 32/64 loss: -2.070638656616211
Batch 33/64 loss: -2.813497543334961
Batch 34/64 loss: -3.1665048599243164
Batch 35/64 loss: -3.2304468154907227
Batch 36/64 loss: -3.051323890686035
Batch 37/64 loss: -2.917947769165039
Batch 38/64 loss: -3.148118019104004
Batch 39/64 loss: -3.1349916458129883
Batch 40/64 loss: -2.461176872253418
Batch 41/64 loss: -3.136625289916992
Batch 42/64 loss: -3.1117515563964844
Batch 43/64 loss: -2.7387847900390625
Batch 44/64 loss: -3.0570507049560547
Batch 45/64 loss: -2.870248794555664
Batch 46/64 loss: -2.9516706466674805
Batch 47/64 loss: -2.79605770111084
Batch 48/64 loss: -2.9407596588134766
Batch 49/64 loss: -3.087963104248047
Batch 50/64 loss: -2.8723459243774414
Batch 51/64 loss: -3.153388023376465
Batch 52/64 loss: -3.09957218170166
Batch 53/64 loss: -3.036386489868164
Batch 54/64 loss: -3.1334638595581055
Batch 55/64 loss: -3.0973777770996094
Batch 56/64 loss: -3.1338844299316406
Batch 57/64 loss: -3.293630599975586
Batch 58/64 loss: -2.927607536315918
Batch 59/64 loss: -2.902188301086426
Batch 60/64 loss: -3.0337820053100586
Batch 61/64 loss: -2.480463981628418
Batch 62/64 loss: -2.7659683227539062
Batch 63/64 loss: -3.078643798828125
Batch 64/64 loss: -7.5241875648498535
Epoch 476  Train loss: -3.0397897290248497  Val loss: -3.3617450412606047
Epoch 477
-------------------------------
Batch 1/64 loss: -3.065877914428711
Batch 2/64 loss: -3.199522018432617
Batch 3/64 loss: -2.7113037109375
Batch 4/64 loss: -3.2028818130493164
Batch 5/64 loss: -3.118903160095215
Batch 6/64 loss: -2.901460647583008
Batch 7/64 loss: -3.1269655227661133
Batch 8/64 loss: -3.0563926696777344
Batch 9/64 loss: -2.932013511657715
Batch 10/64 loss: -3.2928762435913086
Batch 11/64 loss: -3.00954532623291
Batch 12/64 loss: -3.224153518676758
Batch 13/64 loss: -3.247173309326172
Batch 14/64 loss: -3.1148929595947266
Batch 15/64 loss: -3.061953544616699
Batch 16/64 loss: -2.724660873413086
Batch 17/64 loss: -3.0653839111328125
Batch 18/64 loss: -3.281834602355957
Batch 19/64 loss: -2.9660491943359375
Batch 20/64 loss: -3.1277828216552734
Batch 21/64 loss: -2.7317514419555664
Batch 22/64 loss: -3.226578712463379
Batch 23/64 loss: -3.0245723724365234
Batch 24/64 loss: -3.010104179382324
Batch 25/64 loss: -2.705782890319824
Batch 26/64 loss: -3.206787109375
Batch 27/64 loss: -3.0025720596313477
Batch 28/64 loss: -3.1780471801757812
Batch 29/64 loss: -2.9725255966186523
Batch 30/64 loss: -2.2855587005615234
Batch 31/64 loss: -2.4676218032836914
Batch 32/64 loss: -2.755345344543457
Batch 33/64 loss: -3.2083892822265625
Batch 34/64 loss: -2.8560409545898438
Batch 35/64 loss: -3.056446075439453
Batch 36/64 loss: -2.3132190704345703
Batch 37/64 loss: -2.7856321334838867
Batch 38/64 loss: -3.206432342529297
Batch 39/64 loss: -3.0778512954711914
Batch 40/64 loss: -3.1085433959960938
Batch 41/64 loss: -3.028292655944824
Batch 42/64 loss: -2.8666019439697266
Batch 43/64 loss: -3.1117849349975586
Batch 44/64 loss: -3.071709632873535
Batch 45/64 loss: -3.059307098388672
Batch 46/64 loss: -3.152104377746582
Batch 47/64 loss: -2.6138010025024414
Batch 48/64 loss: -2.960186004638672
Batch 49/64 loss: -3.1553730964660645
Batch 50/64 loss: -3.240163803100586
Batch 51/64 loss: -2.9529075622558594
Batch 52/64 loss: -2.4354896545410156
Batch 53/64 loss: -3.1886730194091797
Batch 54/64 loss: -2.984731674194336
Batch 55/64 loss: -3.1437149047851562
Batch 56/64 loss: -2.954692840576172
Batch 57/64 loss: -3.115736961364746
Batch 58/64 loss: -3.035799026489258
Batch 59/64 loss: -2.9070444107055664
Batch 60/64 loss: -3.159768581390381
Batch 61/64 loss: -3.1406068801879883
Batch 62/64 loss: -2.9831323623657227
Batch 63/64 loss: -3.0029850006103516
Batch 64/64 loss: -7.524496078491211
Epoch 477  Train loss: -3.0512848423976524  Val loss: -3.303023177733536
Epoch 478
-------------------------------
Batch 1/64 loss: -3.115297317504883
Batch 2/64 loss: -2.5967044830322266
Batch 3/64 loss: -3.1013736724853516
Batch 4/64 loss: -2.8583431243896484
Batch 5/64 loss: -2.6009788513183594
Batch 6/64 loss: -3.143941879272461
Batch 7/64 loss: -2.8786916732788086
Batch 8/64 loss: -3.2398176193237305
Batch 9/64 loss: -3.1200428009033203
Batch 10/64 loss: -2.81935977935791
Batch 11/64 loss: -2.29062557220459
Batch 12/64 loss: -2.9843130111694336
Batch 13/64 loss: -3.179769515991211
Batch 14/64 loss: -3.098111152648926
Batch 15/64 loss: -2.9554853439331055
Batch 16/64 loss: -2.9477367401123047
Batch 17/64 loss: -3.0572566986083984
Batch 18/64 loss: -2.580913543701172
Batch 19/64 loss: -3.027144432067871
Batch 20/64 loss: -2.936985969543457
Batch 21/64 loss: -3.166581153869629
Batch 22/64 loss: -3.04335880279541
Batch 23/64 loss: -3.194404125213623
Batch 24/64 loss: -2.9183902740478516
Batch 25/64 loss: -2.210947036743164
Batch 26/64 loss: -2.8943796157836914
Batch 27/64 loss: -3.047452926635742
Batch 28/64 loss: -2.899707794189453
Batch 29/64 loss: -2.593534469604492
Batch 30/64 loss: -3.0652170181274414
Batch 31/64 loss: -3.1992673873901367
Batch 32/64 loss: -3.1975936889648438
Batch 33/64 loss: -3.006625175476074
Batch 34/64 loss: -2.9826478958129883
Batch 35/64 loss: -3.114500045776367
Batch 36/64 loss: -2.824721336364746
Batch 37/64 loss: -3.0681533813476562
Batch 38/64 loss: -3.12994384765625
Batch 39/64 loss: -2.9519433975219727
Batch 40/64 loss: -3.0537490844726562
Batch 41/64 loss: -3.171586036682129
Batch 42/64 loss: -3.202747344970703
Batch 43/64 loss: -2.960927963256836
Batch 44/64 loss: -3.3244094848632812
Batch 45/64 loss: -3.05582332611084
Batch 46/64 loss: -3.2773752212524414
Batch 47/64 loss: -2.8591079711914062
Batch 48/64 loss: -2.963247299194336
Batch 49/64 loss: -3.053389549255371
Batch 50/64 loss: -3.1386356353759766
Batch 51/64 loss: -3.262876033782959
Batch 52/64 loss: -3.196343421936035
Batch 53/64 loss: -3.08905029296875
Batch 54/64 loss: -3.0352582931518555
Batch 55/64 loss: -2.7882080078125
Batch 56/64 loss: -3.0729312896728516
Batch 57/64 loss: -3.0778865814208984
Batch 58/64 loss: -2.9623403549194336
Batch 59/64 loss: -3.02667236328125
Batch 60/64 loss: -3.139632225036621
Batch 61/64 loss: -3.004092216491699
Batch 62/64 loss: -2.7994861602783203
Batch 63/64 loss: -3.2303543090820312
Batch 64/64 loss: -7.649735927581787
Epoch 478  Train loss: -3.051383450452019  Val loss: -3.3367848609321307
Epoch 479
-------------------------------
Batch 1/64 loss: -3.1798629760742188
Batch 2/64 loss: -3.0586252212524414
Batch 3/64 loss: -2.7832727432250977
Batch 4/64 loss: -3.0200538635253906
Batch 5/64 loss: -2.772001266479492
Batch 6/64 loss: -3.0405969619750977
Batch 7/64 loss: -3.096271514892578
Batch 8/64 loss: -2.8302536010742188
Batch 9/64 loss: -2.8473377227783203
Batch 10/64 loss: -3.010430335998535
Batch 11/64 loss: -3.1650466918945312
Batch 12/64 loss: -3.054549217224121
Batch 13/64 loss: -2.6573486328125
Batch 14/64 loss: -2.9110536575317383
Batch 15/64 loss: -2.9714107513427734
Batch 16/64 loss: -3.1113271713256836
Batch 17/64 loss: -2.8071250915527344
Batch 18/64 loss: -2.578709602355957
Batch 19/64 loss: -2.950343132019043
Batch 20/64 loss: -3.0573673248291016
Batch 21/64 loss: -2.9558162689208984
Batch 22/64 loss: -2.546217918395996
Batch 23/64 loss: -2.9059152603149414
Batch 24/64 loss: -2.803774833679199
Batch 25/64 loss: -3.0940637588500977
Batch 26/64 loss: -2.468327522277832
Batch 27/64 loss: -3.028301239013672
Batch 28/64 loss: -3.1966161727905273
Batch 29/64 loss: -3.248483657836914
Batch 30/64 loss: -3.2305221557617188
Batch 31/64 loss: -2.7882890701293945
Batch 32/64 loss: -3.1017866134643555
Batch 33/64 loss: -2.945023536682129
Batch 34/64 loss: -2.761847496032715
Batch 35/64 loss: -3.070509910583496
Batch 36/64 loss: -3.0870981216430664
Batch 37/64 loss: -2.512226104736328
Batch 38/64 loss: -2.735361099243164
Batch 39/64 loss: -2.9819555282592773
Batch 40/64 loss: -3.112640380859375
Batch 41/64 loss: -3.027920722961426
Batch 42/64 loss: -2.977907180786133
Batch 43/64 loss: -2.9938039779663086
Batch 44/64 loss: -2.9535341262817383
Batch 45/64 loss: -3.0589170455932617
Batch 46/64 loss: -2.4305191040039062
Batch 47/64 loss: -2.734837532043457
Batch 48/64 loss: -3.106271743774414
Batch 49/64 loss: -3.126132011413574
Batch 50/64 loss: -2.854567527770996
Batch 51/64 loss: -3.0470046997070312
Batch 52/64 loss: -3.154407501220703
Batch 53/64 loss: -2.8442907333374023
Batch 54/64 loss: -2.939929962158203
Batch 55/64 loss: -3.151299476623535
Batch 56/64 loss: -3.20786190032959
Batch 57/64 loss: -2.967532157897949
Batch 58/64 loss: -3.1414785385131836
Batch 59/64 loss: -3.0647239685058594
Batch 60/64 loss: -2.3543615341186523
Batch 61/64 loss: -3.0644779205322266
Batch 62/64 loss: -3.158816337585449
Batch 63/64 loss: -3.2183046340942383
Batch 64/64 loss: -7.340280532836914
Epoch 479  Train loss: -3.0048921547684015  Val loss: -3.2762583965288403
Epoch 480
-------------------------------
Batch 1/64 loss: -2.984490394592285
Batch 2/64 loss: -3.222439765930176
Batch 3/64 loss: -2.891551971435547
Batch 4/64 loss: -3.010591506958008
Batch 5/64 loss: -3.2115373611450195
Batch 6/64 loss: -3.1914777755737305
Batch 7/64 loss: -2.9002628326416016
Batch 8/64 loss: -3.24072265625
Batch 9/64 loss: -3.1383752822875977
Batch 10/64 loss: -2.9482927322387695
Batch 11/64 loss: -3.2534236907958984
Batch 12/64 loss: -3.209244728088379
Batch 13/64 loss: -3.154766082763672
Batch 14/64 loss: -2.806856155395508
Batch 15/64 loss: -2.68326473236084
Batch 16/64 loss: -2.8930559158325195
Batch 17/64 loss: -2.6752376556396484
Batch 18/64 loss: -3.1049604415893555
Batch 19/64 loss: -2.1554555892944336
Batch 20/64 loss: -3.145339012145996
Batch 21/64 loss: -3.1186046600341797
Batch 22/64 loss: -2.9733047485351562
Batch 23/64 loss: -2.538187026977539
Batch 24/64 loss: -2.9554929733276367
Batch 25/64 loss: -2.964308738708496
Batch 26/64 loss: -3.1771717071533203
Batch 27/64 loss: -3.0484848022460938
Batch 28/64 loss: -2.670790672302246
Batch 29/64 loss: -2.899447441101074
Batch 30/64 loss: -3.078350067138672
Batch 31/64 loss: -2.6863889694213867
Batch 32/64 loss: -3.014834403991699
Batch 33/64 loss: -3.186260223388672
Batch 34/64 loss: -2.9943418502807617
Batch 35/64 loss: -3.118178367614746
Batch 36/64 loss: -3.163972854614258
Batch 37/64 loss: -3.041764259338379
Batch 38/64 loss: -3.0582103729248047
Batch 39/64 loss: -3.0868043899536133
Batch 40/64 loss: -3.0013837814331055
Batch 41/64 loss: -2.993947982788086
Batch 42/64 loss: -2.959260940551758
Batch 43/64 loss: -3.0280399322509766
Batch 44/64 loss: -3.15799617767334
Batch 45/64 loss: -3.031245231628418
Batch 46/64 loss: -2.993375778198242
Batch 47/64 loss: -2.9430389404296875
Batch 48/64 loss: -3.09429931640625
Batch 49/64 loss: -2.8375473022460938
Batch 50/64 loss: -3.1370601654052734
Batch 51/64 loss: -2.916029930114746
Batch 52/64 loss: -3.098660469055176
Batch 53/64 loss: -3.0290231704711914
Batch 54/64 loss: -2.458721160888672
Batch 55/64 loss: -2.537839889526367
Batch 56/64 loss: -3.1926116943359375
Batch 57/64 loss: -3.040699005126953
Batch 58/64 loss: -2.5588035583496094
Batch 59/64 loss: -3.1548919677734375
Batch 60/64 loss: -3.096573829650879
Batch 61/64 loss: -2.779245376586914
Batch 62/64 loss: -2.68581485748291
Batch 63/64 loss: -2.8139848709106445
Batch 64/64 loss: -7.638613224029541
Epoch 480  Train loss: -3.025338040146173  Val loss: -3.3537760862370125
Epoch 481
-------------------------------
Batch 1/64 loss: -3.1415205001831055
Batch 2/64 loss: -3.00539493560791
Batch 3/64 loss: -2.3066539764404297
Batch 4/64 loss: -3.1992931365966797
Batch 5/64 loss: -3.1125354766845703
Batch 6/64 loss: -3.0076370239257812
Batch 7/64 loss: -2.994692802429199
Batch 8/64 loss: -3.1653337478637695
Batch 9/64 loss: -2.974813461303711
Batch 10/64 loss: -3.0901689529418945
Batch 11/64 loss: -2.8791685104370117
Batch 12/64 loss: -2.8127336502075195
Batch 13/64 loss: -3.1156797409057617
Batch 14/64 loss: -3.068359375
Batch 15/64 loss: -2.8473901748657227
Batch 16/64 loss: -3.0116939544677734
Batch 17/64 loss: -3.200204849243164
Batch 18/64 loss: -2.907376289367676
Batch 19/64 loss: -3.089596748352051
Batch 20/64 loss: -3.151935577392578
Batch 21/64 loss: -2.985257148742676
Batch 22/64 loss: -3.056584358215332
Batch 23/64 loss: -3.079671859741211
Batch 24/64 loss: -2.864840507507324
Batch 25/64 loss: -3.096198081970215
Batch 26/64 loss: -2.9587764739990234
Batch 27/64 loss: -3.175074577331543
Batch 28/64 loss: -2.92128849029541
Batch 29/64 loss: -3.1642160415649414
Batch 30/64 loss: -3.2286386489868164
Batch 31/64 loss: -3.176128387451172
Batch 32/64 loss: -3.0597400665283203
Batch 33/64 loss: -3.050551414489746
Batch 34/64 loss: -3.019559860229492
Batch 35/64 loss: -3.102910041809082
Batch 36/64 loss: -2.873077392578125
Batch 37/64 loss: -3.033694267272949
Batch 38/64 loss: -3.2106781005859375
Batch 39/64 loss: -3.0627174377441406
Batch 40/64 loss: -2.9435129165649414
Batch 41/64 loss: -3.0764341354370117
Batch 42/64 loss: -2.9349594116210938
Batch 43/64 loss: -3.2464499473571777
Batch 44/64 loss: -3.1098575592041016
Batch 45/64 loss: -3.0767383575439453
Batch 46/64 loss: -3.0462446212768555
Batch 47/64 loss: -3.060894012451172
Batch 48/64 loss: -3.1259984970092773
Batch 49/64 loss: -2.8081130981445312
Batch 50/64 loss: -3.086498260498047
Batch 51/64 loss: -2.3917055130004883
Batch 52/64 loss: -2.755864143371582
Batch 53/64 loss: -2.858616828918457
Batch 54/64 loss: -3.046067237854004
Batch 55/64 loss: -3.0878381729125977
Batch 56/64 loss: -2.8749399185180664
Batch 57/64 loss: -2.838930130004883
Batch 58/64 loss: -2.6722583770751953
Batch 59/64 loss: -2.461451530456543
Batch 60/64 loss: -2.8035478591918945
Batch 61/64 loss: -3.193338394165039
Batch 62/64 loss: -2.9950408935546875
Batch 63/64 loss: -3.177657127380371
Batch 64/64 loss: -7.065624713897705
Epoch 481  Train loss: -3.0458660630618826  Val loss: -3.3259385754562327
Epoch 482
-------------------------------
Batch 1/64 loss: -3.1418685913085938
Batch 2/64 loss: -2.7655410766601562
Batch 3/64 loss: -3.0630006790161133
Batch 4/64 loss: -3.095304489135742
Batch 5/64 loss: -3.0919113159179688
Batch 6/64 loss: -2.8985910415649414
Batch 7/64 loss: -2.9310970306396484
Batch 8/64 loss: -3.2403297424316406
Batch 9/64 loss: -3.1392459869384766
Batch 10/64 loss: -2.759068489074707
Batch 11/64 loss: -2.8442068099975586
Batch 12/64 loss: -3.050267219543457
Batch 13/64 loss: -3.098324775695801
Batch 14/64 loss: -3.0366907119750977
Batch 15/64 loss: -3.117280960083008
Batch 16/64 loss: -2.946864128112793
Batch 17/64 loss: -2.821650505065918
Batch 18/64 loss: -3.2249860763549805
Batch 19/64 loss: -2.8591690063476562
Batch 20/64 loss: -2.935605049133301
Batch 21/64 loss: -2.9425134658813477
Batch 22/64 loss: -2.733534812927246
Batch 23/64 loss: -2.42818546295166
Batch 24/64 loss: -2.815732955932617
Batch 25/64 loss: -2.8386192321777344
Batch 26/64 loss: -3.222118377685547
Batch 27/64 loss: -3.128406524658203
Batch 28/64 loss: -3.0631542205810547
Batch 29/64 loss: -2.2312355041503906
Batch 30/64 loss: -3.046036720275879
Batch 31/64 loss: -3.25339412689209
Batch 32/64 loss: -2.5366010665893555
Batch 33/64 loss: -2.657938003540039
Batch 34/64 loss: -2.9335451126098633
Batch 35/64 loss: -2.191168785095215
Batch 36/64 loss: -2.701960563659668
Batch 37/64 loss: -2.6072874069213867
Batch 38/64 loss: -3.1788549423217773
Batch 39/64 loss: -2.929379463195801
Batch 40/64 loss: -2.9703474044799805
Batch 41/64 loss: -2.951531410217285
Batch 42/64 loss: -2.834087371826172
Batch 43/64 loss: -3.0593090057373047
Batch 44/64 loss: -3.0528297424316406
Batch 45/64 loss: -3.2071285247802734
Batch 46/64 loss: -2.716994285583496
Batch 47/64 loss: -3.0139102935791016
Batch 48/64 loss: -2.9609670639038086
Batch 49/64 loss: -3.022294044494629
Batch 50/64 loss: -3.066373825073242
Batch 51/64 loss: -3.112795829772949
Batch 52/64 loss: -2.8201799392700195
Batch 53/64 loss: -3.0929737091064453
Batch 54/64 loss: -3.0590057373046875
Batch 55/64 loss: -3.0495986938476562
Batch 56/64 loss: -2.96895694732666
Batch 57/64 loss: -2.9365243911743164
Batch 58/64 loss: -2.9743356704711914
Batch 59/64 loss: -2.8048038482666016
Batch 60/64 loss: -3.0877037048339844
Batch 61/64 loss: -2.9679317474365234
Batch 62/64 loss: -2.876431465148926
Batch 63/64 loss: -2.4025936126708984
Batch 64/64 loss: -7.49077033996582
Epoch 482  Train loss: -2.9824055914785346  Val loss: -3.2639642433612206
Epoch 483
-------------------------------
Batch 1/64 loss: -2.9555130004882812
Batch 2/64 loss: -2.94674015045166
Batch 3/64 loss: -2.816473960876465
Batch 4/64 loss: -2.9071569442749023
Batch 5/64 loss: -3.113797187805176
Batch 6/64 loss: -2.921666145324707
Batch 7/64 loss: -2.2478246688842773
Batch 8/64 loss: -3.108610153198242
Batch 9/64 loss: -3.131988525390625
Batch 10/64 loss: -3.111565589904785
Batch 11/64 loss: -3.240354537963867
Batch 12/64 loss: -3.1032485961914062
Batch 13/64 loss: -3.1039628982543945
Batch 14/64 loss: -3.0517396926879883
Batch 15/64 loss: -2.685781478881836
Batch 16/64 loss: -2.6100969314575195
Batch 17/64 loss: -2.9584455490112305
Batch 18/64 loss: -2.922069549560547
Batch 19/64 loss: -2.7661075592041016
Batch 20/64 loss: -3.084949493408203
Batch 21/64 loss: -3.1293725967407227
Batch 22/64 loss: -3.149531364440918
Batch 23/64 loss: -2.944563865661621
Batch 24/64 loss: -2.7408361434936523
Batch 25/64 loss: -3.0716514587402344
Batch 26/64 loss: -2.7874631881713867
Batch 27/64 loss: -3.0066490173339844
Batch 28/64 loss: -3.0331506729125977
Batch 29/64 loss: -3.1660051345825195
Batch 30/64 loss: -2.826995849609375
Batch 31/64 loss: -3.0817861557006836
Batch 32/64 loss: -3.152557373046875
Batch 33/64 loss: -2.7482757568359375
Batch 34/64 loss: -3.1022987365722656
Batch 35/64 loss: -3.1087913513183594
Batch 36/64 loss: -2.992155075073242
Batch 37/64 loss: -2.860128402709961
Batch 38/64 loss: -2.995027542114258
Batch 39/64 loss: -2.974278450012207
Batch 40/64 loss: -3.0129261016845703
Batch 41/64 loss: -3.121206283569336
Batch 42/64 loss: -3.0600271224975586
Batch 43/64 loss: -2.7889814376831055
Batch 44/64 loss: -2.988245964050293
Batch 45/64 loss: -3.114781379699707
Batch 46/64 loss: -3.0385303497314453
Batch 47/64 loss: -3.029825210571289
Batch 48/64 loss: -2.804410934448242
Batch 49/64 loss: -2.83560848236084
Batch 50/64 loss: -3.1192665100097656
Batch 51/64 loss: -2.8733091354370117
Batch 52/64 loss: -3.1589183807373047
Batch 53/64 loss: -2.554384231567383
Batch 54/64 loss: -3.174403190612793
Batch 55/64 loss: -3.1262121200561523
Batch 56/64 loss: -3.062310218811035
Batch 57/64 loss: -3.076083183288574
Batch 58/64 loss: -3.1184825897216797
Batch 59/64 loss: -3.095820426940918
Batch 60/64 loss: -2.8389205932617188
Batch 61/64 loss: -3.116276741027832
Batch 62/64 loss: -3.076144218444824
Batch 63/64 loss: -3.1769914627075195
Batch 64/64 loss: -7.557493686676025
Epoch 483  Train loss: -3.0382713299171598  Val loss: -3.268573931402357
Epoch 484
-------------------------------
Batch 1/64 loss: -2.969618797302246
Batch 2/64 loss: -2.5711631774902344
Batch 3/64 loss: -2.974905014038086
Batch 4/64 loss: -3.0179214477539062
Batch 5/64 loss: -3.085146903991699
Batch 6/64 loss: -3.2483816146850586
Batch 7/64 loss: -3.157958984375
Batch 8/64 loss: -3.0327653884887695
Batch 9/64 loss: -2.9455947875976562
Batch 10/64 loss: -3.0898818969726562
Batch 11/64 loss: -3.2685728073120117
Batch 12/64 loss: -2.8804264068603516
Batch 13/64 loss: -3.169403076171875
Batch 14/64 loss: -2.892375946044922
Batch 15/64 loss: -3.136317253112793
Batch 16/64 loss: -3.0125646591186523
Batch 17/64 loss: -3.1221513748168945
Batch 18/64 loss: -2.5625171661376953
Batch 19/64 loss: -2.9419679641723633
Batch 20/64 loss: -3.011622428894043
Batch 21/64 loss: -3.14426326751709
Batch 22/64 loss: -3.1671762466430664
Batch 23/64 loss: -3.225937843322754
Batch 24/64 loss: -2.4834461212158203
Batch 25/64 loss: -3.1848316192626953
Batch 26/64 loss: -3.0641555786132812
Batch 27/64 loss: -2.8425426483154297
Batch 28/64 loss: -2.99135684967041
Batch 29/64 loss: -3.0333328247070312
Batch 30/64 loss: -3.0703659057617188
Batch 31/64 loss: -3.1303157806396484
Batch 32/64 loss: -3.0988893508911133
Batch 33/64 loss: -2.918206214904785
Batch 34/64 loss: -3.0291357040405273
Batch 35/64 loss: -2.9401321411132812
Batch 36/64 loss: -3.130642890930176
Batch 37/64 loss: -2.3732528686523438
Batch 38/64 loss: -3.1058177947998047
Batch 39/64 loss: -2.990656852722168
Batch 40/64 loss: -3.054677963256836
Batch 41/64 loss: -2.8836450576782227
Batch 42/64 loss: -2.9993457794189453
Batch 43/64 loss: -2.8605175018310547
Batch 44/64 loss: -2.7109622955322266
Batch 45/64 loss: -2.617550849914551
Batch 46/64 loss: -3.036868095397949
Batch 47/64 loss: -2.3551416397094727
Batch 48/64 loss: -3.1472549438476562
Batch 49/64 loss: -3.0230140686035156
Batch 50/64 loss: -3.0150203704833984
Batch 51/64 loss: -3.0721302032470703
Batch 52/64 loss: -2.494553565979004
Batch 53/64 loss: -2.8392162322998047
Batch 54/64 loss: -2.8483800888061523
Batch 55/64 loss: -3.085865020751953
Batch 56/64 loss: -3.019510269165039
Batch 57/64 loss: -3.047091484069824
Batch 58/64 loss: -3.114307403564453
Batch 59/64 loss: -3.02899169921875
Batch 60/64 loss: -3.1581878662109375
Batch 61/64 loss: -3.235825538635254
Batch 62/64 loss: -3.163926124572754
Batch 63/64 loss: -2.9396276473999023
Batch 64/64 loss: -7.3944091796875
Epoch 484  Train loss: -3.0323628893085552  Val loss: -3.1667683001646063
Epoch 485
-------------------------------
Batch 1/64 loss: -3.0911436080932617
Batch 2/64 loss: -2.9468002319335938
Batch 3/64 loss: -3.1119956970214844
Batch 4/64 loss: -3.0872488021850586
Batch 5/64 loss: -2.4421167373657227
Batch 6/64 loss: -3.1479616165161133
Batch 7/64 loss: -3.2630128860473633
Batch 8/64 loss: -3.019589424133301
Batch 9/64 loss: -3.0455894470214844
Batch 10/64 loss: -2.975794792175293
Batch 11/64 loss: -2.963393211364746
Batch 12/64 loss: -3.028697967529297
Batch 13/64 loss: -3.1463193893432617
Batch 14/64 loss: -3.1464710235595703
Batch 15/64 loss: -3.0827980041503906
Batch 16/64 loss: -2.976106643676758
Batch 17/64 loss: -2.978242874145508
Batch 18/64 loss: -3.06052303314209
Batch 19/64 loss: -2.7496423721313477
Batch 20/64 loss: -2.9332151412963867
Batch 21/64 loss: -2.933812141418457
Batch 22/64 loss: -3.046916961669922
Batch 23/64 loss: -3.144775390625
Batch 24/64 loss: -3.178607940673828
Batch 25/64 loss: -3.1667919158935547
Batch 26/64 loss: -3.1521310806274414
Batch 27/64 loss: -3.1423120498657227
Batch 28/64 loss: -2.8834447860717773
Batch 29/64 loss: -3.164644241333008
Batch 30/64 loss: -2.995756149291992
Batch 31/64 loss: -3.2763452529907227
Batch 32/64 loss: -3.022737503051758
Batch 33/64 loss: -3.040468215942383
Batch 34/64 loss: -2.3514366149902344
Batch 35/64 loss: -2.7332496643066406
Batch 36/64 loss: -3.0035171508789062
Batch 37/64 loss: -2.875399589538574
Batch 38/64 loss: -2.877140998840332
Batch 39/64 loss: -2.9765148162841797
Batch 40/64 loss: -3.0536985397338867
Batch 41/64 loss: -2.6079578399658203
Batch 42/64 loss: -2.4069700241088867
Batch 43/64 loss: -2.833944320678711
Batch 44/64 loss: -2.855783462524414
Batch 45/64 loss: -3.260641098022461
Batch 46/64 loss: -2.883758544921875
Batch 47/64 loss: -3.04074764251709
Batch 48/64 loss: -2.997640609741211
Batch 49/64 loss: -2.8410472869873047
Batch 50/64 loss: -2.7931442260742188
Batch 51/64 loss: -3.0718812942504883
Batch 52/64 loss: -2.9454383850097656
Batch 53/64 loss: -2.9291934967041016
Batch 54/64 loss: -3.0136146545410156
Batch 55/64 loss: -2.8396968841552734
Batch 56/64 loss: -3.080643653869629
Batch 57/64 loss: -3.207216262817383
Batch 58/64 loss: -3.065366744995117
Batch 59/64 loss: -2.9731178283691406
Batch 60/64 loss: -3.019044876098633
Batch 61/64 loss: -2.9760847091674805
Batch 62/64 loss: -3.033367156982422
Batch 63/64 loss: -2.7922754287719727
Batch 64/64 loss: -7.152901649475098
Epoch 485  Train loss: -3.028229279611625  Val loss: -3.30086459654713
Epoch 486
-------------------------------
Batch 1/64 loss: -3.0714120864868164
Batch 2/64 loss: -3.0623464584350586
Batch 3/64 loss: -2.9870424270629883
Batch 4/64 loss: -3.200551986694336
Batch 5/64 loss: -3.313478946685791
Batch 6/64 loss: -2.76967716217041
Batch 7/64 loss: -3.2136125564575195
Batch 8/64 loss: -3.0187883377075195
Batch 9/64 loss: -3.0566768646240234
Batch 10/64 loss: -3.09134578704834
Batch 11/64 loss: -2.9424667358398438
Batch 12/64 loss: -3.2421875
Batch 13/64 loss: -3.193881034851074
Batch 14/64 loss: -2.948275566101074
Batch 15/64 loss: -3.1154279708862305
Batch 16/64 loss: -2.8126049041748047
Batch 17/64 loss: -3.193347930908203
Batch 18/64 loss: -3.2307519912719727
Batch 19/64 loss: -3.1262598037719727
Batch 20/64 loss: -3.0783863067626953
Batch 21/64 loss: -3.052870750427246
Batch 22/64 loss: -3.1241273880004883
Batch 23/64 loss: -3.291499137878418
Batch 24/64 loss: -3.115720748901367
Batch 25/64 loss: -2.5017290115356445
Batch 26/64 loss: -2.994802474975586
Batch 27/64 loss: -3.226602554321289
Batch 28/64 loss: -3.08267879486084
Batch 29/64 loss: -2.687088966369629
Batch 30/64 loss: -3.125101089477539
Batch 31/64 loss: -2.7039175033569336
Batch 32/64 loss: -2.8396596908569336
Batch 33/64 loss: -2.930936813354492
Batch 34/64 loss: -3.0896387100219727
Batch 35/64 loss: -3.1348676681518555
Batch 36/64 loss: -2.2634897232055664
Batch 37/64 loss: -2.852889060974121
Batch 38/64 loss: -2.8689661026000977
Batch 39/64 loss: -2.772418975830078
Batch 40/64 loss: -2.915699005126953
Batch 41/64 loss: -3.041614532470703
Batch 42/64 loss: -2.3209095001220703
Batch 43/64 loss: -3.091716766357422
Batch 44/64 loss: -3.0854368209838867
Batch 45/64 loss: -3.144162178039551
Batch 46/64 loss: -2.923961639404297
Batch 47/64 loss: -2.8848915100097656
Batch 48/64 loss: -2.9090538024902344
Batch 49/64 loss: -3.0598134994506836
Batch 50/64 loss: -2.7818212509155273
Batch 51/64 loss: -3.140805244445801
Batch 52/64 loss: -3.1189308166503906
Batch 53/64 loss: -2.660104751586914
Batch 54/64 loss: -2.578165054321289
Batch 55/64 loss: -2.941608428955078
Batch 56/64 loss: -3.1890907287597656
Batch 57/64 loss: -3.029726982116699
Batch 58/64 loss: -2.891364097595215
Batch 59/64 loss: -3.0516910552978516
Batch 60/64 loss: -3.054783821105957
Batch 61/64 loss: -2.949040412902832
Batch 62/64 loss: -3.0629568099975586
Batch 63/64 loss: -3.0318899154663086
Batch 64/64 loss: -7.692302227020264
Epoch 486  Train loss: -3.0424469461628036  Val loss: -3.3288096529511653
Epoch 487
-------------------------------
Batch 1/64 loss: -3.0374345779418945
Batch 2/64 loss: -3.132248878479004
Batch 3/64 loss: -3.128589630126953
Batch 4/64 loss: -2.926333427429199
Batch 5/64 loss: -2.562856674194336
Batch 6/64 loss: -2.9601640701293945
Batch 7/64 loss: -3.044070243835449
Batch 8/64 loss: -3.198711395263672
Batch 9/64 loss: -3.1990880966186523
Batch 10/64 loss: -3.1800537109375
Batch 11/64 loss: -3.038071632385254
Batch 12/64 loss: -3.0412607192993164
Batch 13/64 loss: -3.0634288787841797
Batch 14/64 loss: -3.0358400344848633
Batch 15/64 loss: -3.2261667251586914
Batch 16/64 loss: -2.9857521057128906
Batch 17/64 loss: -2.926192283630371
Batch 18/64 loss: -2.563526153564453
Batch 19/64 loss: -2.9778852462768555
Batch 20/64 loss: -3.0409421920776367
Batch 21/64 loss: -2.899979591369629
Batch 22/64 loss: -2.9627561569213867
Batch 23/64 loss: -2.746255874633789
Batch 24/64 loss: -2.486082077026367
Batch 25/64 loss: -3.079991340637207
Batch 26/64 loss: -2.8249807357788086
Batch 27/64 loss: -3.196796417236328
Batch 28/64 loss: -3.0854415893554688
Batch 29/64 loss: -3.0872840881347656
Batch 30/64 loss: -2.9791383743286133
Batch 31/64 loss: -2.6081714630126953
Batch 32/64 loss: -3.15238094329834
Batch 33/64 loss: -2.97640323638916
Batch 34/64 loss: -3.0846548080444336
Batch 35/64 loss: -2.9964818954467773
Batch 36/64 loss: -3.1802101135253906
Batch 37/64 loss: -3.2135491371154785
Batch 38/64 loss: -3.0101194381713867
Batch 39/64 loss: -2.9652938842773438
Batch 40/64 loss: -3.093817710876465
Batch 41/64 loss: -2.7988357543945312
Batch 42/64 loss: -3.052250862121582
Batch 43/64 loss: -3.1963748931884766
Batch 44/64 loss: -2.970613479614258
Batch 45/64 loss: -3.0942163467407227
Batch 46/64 loss: -2.9834089279174805
Batch 47/64 loss: -2.984889030456543
Batch 48/64 loss: -3.143500328063965
Batch 49/64 loss: -3.001864433288574
Batch 50/64 loss: -2.9094581604003906
Batch 51/64 loss: -3.0884532928466797
Batch 52/64 loss: -3.0167083740234375
Batch 53/64 loss: -3.234066963195801
Batch 54/64 loss: -2.9520797729492188
Batch 55/64 loss: -3.1755475997924805
Batch 56/64 loss: -3.0108604431152344
Batch 57/64 loss: -3.159364700317383
Batch 58/64 loss: -2.93203067779541
Batch 59/64 loss: -2.383878707885742
Batch 60/64 loss: -2.7643613815307617
Batch 61/64 loss: -3.1252193450927734
Batch 62/64 loss: -3.2672834396362305
Batch 63/64 loss: -2.935336112976074
Batch 64/64 loss: -7.573617458343506
Epoch 487  Train loss: -3.0550466144786164  Val loss: -3.376041897383752
Epoch 488
-------------------------------
Batch 1/64 loss: -3.1851558685302734
Batch 2/64 loss: -3.2823400497436523
Batch 3/64 loss: -3.263848304748535
Batch 4/64 loss: -3.0029678344726562
Batch 5/64 loss: -3.113985061645508
Batch 6/64 loss: -3.067686080932617
Batch 7/64 loss: -3.0610599517822266
Batch 8/64 loss: -3.3631210327148438
Batch 9/64 loss: -2.6112051010131836
Batch 10/64 loss: -3.2676639556884766
Batch 11/64 loss: -3.0943117141723633
Batch 12/64 loss: -3.025364875793457
Batch 13/64 loss: -2.956263542175293
Batch 14/64 loss: -3.242650032043457
Batch 15/64 loss: -3.205935478210449
Batch 16/64 loss: -2.9798059463500977
Batch 17/64 loss: -3.027127265930176
Batch 18/64 loss: -2.8449020385742188
Batch 19/64 loss: -3.2975664138793945
Batch 20/64 loss: -3.0717267990112305
Batch 21/64 loss: -3.0074472427368164
Batch 22/64 loss: -3.088934898376465
Batch 23/64 loss: -2.6845598220825195
Batch 24/64 loss: -3.1647415161132812
Batch 25/64 loss: -2.896916389465332
Batch 26/64 loss: -2.7132320404052734
Batch 27/64 loss: -3.014437675476074
Batch 28/64 loss: -2.9093971252441406
Batch 29/64 loss: -2.9644174575805664
Batch 30/64 loss: -3.1401453018188477
Batch 31/64 loss: -2.9666852951049805
Batch 32/64 loss: -2.928908348083496
Batch 33/64 loss: -2.9868993759155273
Batch 34/64 loss: -2.9431371688842773
Batch 35/64 loss: -3.03817081451416
Batch 36/64 loss: -3.152315139770508
Batch 37/64 loss: -3.0350265502929688
Batch 38/64 loss: -3.066650390625
Batch 39/64 loss: -2.409639358520508
Batch 40/64 loss: -3.015517234802246
Batch 41/64 loss: -2.620512008666992
Batch 42/64 loss: -2.678168296813965
Batch 43/64 loss: -2.825756072998047
Batch 44/64 loss: -2.2289628982543945
Batch 45/64 loss: -3.1594038009643555
Batch 46/64 loss: -2.3486480712890625
Batch 47/64 loss: -2.9682483673095703
Batch 48/64 loss: -2.918087959289551
Batch 49/64 loss: -2.9578981399536133
Batch 50/64 loss: -2.9869070053100586
Batch 51/64 loss: -2.992659568786621
Batch 52/64 loss: -2.785053253173828
Batch 53/64 loss: -2.870591163635254
Batch 54/64 loss: -2.831361770629883
Batch 55/64 loss: -2.983944892883301
Batch 56/64 loss: -3.184657096862793
Batch 57/64 loss: -3.0179691314697266
Batch 58/64 loss: -2.931884765625
Batch 59/64 loss: -3.0870656967163086
Batch 60/64 loss: -3.002997398376465
Batch 61/64 loss: -2.9172544479370117
Batch 62/64 loss: -3.0999631881713867
Batch 63/64 loss: -2.8676319122314453
Batch 64/64 loss: -7.703285217285156
Epoch 488  Train loss: -3.0295679578594132  Val loss: -3.359069444059916
Epoch 489
-------------------------------
Batch 1/64 loss: -2.7060298919677734
Batch 2/64 loss: -3.0179262161254883
Batch 3/64 loss: -3.242072105407715
Batch 4/64 loss: -3.0811853408813477
Batch 5/64 loss: -3.2901649475097656
Batch 6/64 loss: -3.0786991119384766
Batch 7/64 loss: -2.90787410736084
Batch 8/64 loss: -2.818850517272949
Batch 9/64 loss: -3.1788272857666016
Batch 10/64 loss: -3.135343551635742
Batch 11/64 loss: -2.669405937194824
Batch 12/64 loss: -3.056654930114746
Batch 13/64 loss: -2.9442338943481445
Batch 14/64 loss: -2.8273801803588867
Batch 15/64 loss: -2.351764678955078
Batch 16/64 loss: -3.0066404342651367
Batch 17/64 loss: -3.1221771240234375
Batch 18/64 loss: -3.0816383361816406
Batch 19/64 loss: -3.220365524291992
Batch 20/64 loss: -2.8936662673950195
Batch 21/64 loss: -3.2166643142700195
Batch 22/64 loss: -3.1652297973632812
Batch 23/64 loss: -3.041872024536133
Batch 24/64 loss: -2.843613624572754
Batch 25/64 loss: -2.954165458679199
Batch 26/64 loss: -2.6465225219726562
Batch 27/64 loss: -2.5871925354003906
Batch 28/64 loss: -3.1013946533203125
Batch 29/64 loss: -3.0277767181396484
Batch 30/64 loss: -2.9347171783447266
Batch 31/64 loss: -3.1371917724609375
Batch 32/64 loss: -2.795233726501465
Batch 33/64 loss: -3.1506729125976562
Batch 34/64 loss: -3.0060720443725586
Batch 35/64 loss: -2.842963218688965
Batch 36/64 loss: -3.0193634033203125
Batch 37/64 loss: -3.0802841186523438
Batch 38/64 loss: -3.1177682876586914
Batch 39/64 loss: -3.087082862854004
Batch 40/64 loss: -2.9476566314697266
Batch 41/64 loss: -3.0971269607543945
Batch 42/64 loss: -2.949955940246582
Batch 43/64 loss: -3.17197322845459
Batch 44/64 loss: -3.209474563598633
Batch 45/64 loss: -2.995115280151367
Batch 46/64 loss: -2.9192399978637695
Batch 47/64 loss: -3.0535268783569336
Batch 48/64 loss: -3.236207962036133
Batch 49/64 loss: -2.8572731018066406
Batch 50/64 loss: -2.9316816329956055
Batch 51/64 loss: -3.1527481079101562
Batch 52/64 loss: -3.072458267211914
Batch 53/64 loss: -3.062251091003418
Batch 54/64 loss: -3.1428728103637695
Batch 55/64 loss: -3.056687355041504
Batch 56/64 loss: -2.797880172729492
Batch 57/64 loss: -2.778779983520508
Batch 58/64 loss: -3.041973114013672
Batch 59/64 loss: -3.1033239364624023
Batch 60/64 loss: -3.118143081665039
Batch 61/64 loss: -3.1142616271972656
Batch 62/64 loss: -2.3793468475341797
Batch 63/64 loss: -2.8298120498657227
Batch 64/64 loss: -7.602572441101074
Epoch 489  Train loss: -3.0448373570161706  Val loss: -3.3523851506079185
Epoch 490
-------------------------------
Batch 1/64 loss: -3.1680450439453125
Batch 2/64 loss: -3.1339454650878906
Batch 3/64 loss: -3.149359703063965
Batch 4/64 loss: -3.140824317932129
Batch 5/64 loss: -2.975931167602539
Batch 6/64 loss: -3.0322866439819336
Batch 7/64 loss: -2.953110694885254
Batch 8/64 loss: -2.7080249786376953
Batch 9/64 loss: -3.076737403869629
Batch 10/64 loss: -3.205900192260742
Batch 11/64 loss: -3.0064773559570312
Batch 12/64 loss: -2.9809398651123047
Batch 13/64 loss: -2.1472415924072266
Batch 14/64 loss: -3.038325309753418
Batch 15/64 loss: -3.1682233810424805
Batch 16/64 loss: -3.0526018142700195
Batch 17/64 loss: -3.101652145385742
Batch 18/64 loss: -3.128507614135742
Batch 19/64 loss: -3.234518051147461
Batch 20/64 loss: -3.1156816482543945
Batch 21/64 loss: -3.092740058898926
Batch 22/64 loss: -3.059680938720703
Batch 23/64 loss: -2.9810972213745117
Batch 24/64 loss: -2.6575422286987305
Batch 25/64 loss: -2.869267463684082
Batch 26/64 loss: -3.1581411361694336
Batch 27/64 loss: -3.196406364440918
Batch 28/64 loss: -2.906850814819336
Batch 29/64 loss: -2.91796875
Batch 30/64 loss: -3.2909669876098633
Batch 31/64 loss: -2.969733238220215
Batch 32/64 loss: -3.22946834564209
Batch 33/64 loss: -3.193793296813965
Batch 34/64 loss: -3.1506738662719727
Batch 35/64 loss: -2.867180824279785
Batch 36/64 loss: -3.0098628997802734
Batch 37/64 loss: -3.2089357376098633
Batch 38/64 loss: -2.8706750869750977
Batch 39/64 loss: -3.1630859375
Batch 40/64 loss: -2.9571237564086914
Batch 41/64 loss: -3.1376991271972656
Batch 42/64 loss: -3.0985002517700195
Batch 43/64 loss: -2.5954160690307617
Batch 44/64 loss: -2.9678001403808594
Batch 45/64 loss: -2.98403263092041
Batch 46/64 loss: -2.8706226348876953
Batch 47/64 loss: -3.052877426147461
Batch 48/64 loss: -2.916006088256836
Batch 49/64 loss: -2.809478759765625
Batch 50/64 loss: -2.5104150772094727
Batch 51/64 loss: -3.0764503479003906
Batch 52/64 loss: -2.722628593444824
Batch 53/64 loss: -3.0051422119140625
Batch 54/64 loss: -3.3031272888183594
Batch 55/64 loss: -3.011507034301758
Batch 56/64 loss: -2.9995203018188477
Batch 57/64 loss: -2.9439573287963867
Batch 58/64 loss: -3.0644636154174805
Batch 59/64 loss: -3.147703170776367
Batch 60/64 loss: -2.954713821411133
Batch 61/64 loss: -2.886312484741211
Batch 62/64 loss: -2.527937889099121
Batch 63/64 loss: -2.887253761291504
Batch 64/64 loss: -7.390498161315918
Epoch 490  Train loss: -3.047623043434293  Val loss: -3.249018980465394
Epoch 491
-------------------------------
Batch 1/64 loss: -3.111631393432617
Batch 2/64 loss: -3.1746034622192383
Batch 3/64 loss: -2.718960762023926
Batch 4/64 loss: -2.8114585876464844
Batch 5/64 loss: -3.0020008087158203
Batch 6/64 loss: -3.0715866088867188
Batch 7/64 loss: -3.100299835205078
Batch 8/64 loss: -3.157599449157715
Batch 9/64 loss: -2.9908390045166016
Batch 10/64 loss: -2.974087715148926
Batch 11/64 loss: -2.9937992095947266
Batch 12/64 loss: -2.799610137939453
Batch 13/64 loss: -2.881169319152832
Batch 14/64 loss: -2.7125205993652344
Batch 15/64 loss: -3.184680938720703
Batch 16/64 loss: -2.7119836807250977
Batch 17/64 loss: -2.392239570617676
Batch 18/64 loss: -1.9707870483398438
Batch 19/64 loss: -2.828540802001953
Batch 20/64 loss: -2.9733104705810547
Batch 21/64 loss: -2.9988813400268555
Batch 22/64 loss: -2.987765312194824
Batch 23/64 loss: -2.7791948318481445
Batch 24/64 loss: -3.008525848388672
Batch 25/64 loss: -2.7761716842651367
Batch 26/64 loss: -2.6454362869262695
Batch 27/64 loss: -2.863445281982422
Batch 28/64 loss: -2.792304039001465
Batch 29/64 loss: -3.1961498260498047
Batch 30/64 loss: -3.0620603561401367
Batch 31/64 loss: -3.009103775024414
Batch 32/64 loss: -2.9888572692871094
Batch 33/64 loss: -2.975884437561035
Batch 34/64 loss: -2.981904983520508
Batch 35/64 loss: -2.6284751892089844
Batch 36/64 loss: -3.1853151321411133
Batch 37/64 loss: -2.9332361221313477
Batch 38/64 loss: -2.4253158569335938
Batch 39/64 loss: -3.0941362380981445
Batch 40/64 loss: -2.589885711669922
Batch 41/64 loss: -2.4924545288085938
Batch 42/64 loss: -2.8804683685302734
Batch 43/64 loss: -2.5175094604492188
Batch 44/64 loss: -2.761079788208008
Batch 45/64 loss: -2.615507125854492
Batch 46/64 loss: -2.901653289794922
Batch 47/64 loss: -2.079676628112793
Batch 48/64 loss: -2.9902400970458984
Batch 49/64 loss: -3.039133071899414
Batch 50/64 loss: -2.9567575454711914
Batch 51/64 loss: -2.851686477661133
Batch 52/64 loss: -2.3907957077026367
Batch 53/64 loss: -2.6976099014282227
Batch 54/64 loss: -3.0007314682006836
Batch 55/64 loss: -3.0684871673583984
Batch 56/64 loss: -3.125883102416992
Batch 57/64 loss: -1.9353513717651367
Batch 58/64 loss: -2.6898584365844727
Batch 59/64 loss: -2.3722715377807617
Batch 60/64 loss: -2.901333808898926
Batch 61/64 loss: -3.035848617553711
Batch 62/64 loss: -2.500324249267578
Batch 63/64 loss: -2.601675033569336
Batch 64/64 loss: -7.5334062576293945
Epoch 491  Train loss: -2.8790611828074737  Val loss: -3.0405229915867964
Epoch 492
-------------------------------
Batch 1/64 loss: -3.07407283782959
Batch 2/64 loss: -2.4785985946655273
Batch 3/64 loss: -3.0879898071289062
Batch 4/64 loss: -2.640965461730957
Batch 5/64 loss: -2.8904685974121094
Batch 6/64 loss: -2.8382978439331055
Batch 7/64 loss: -2.4935779571533203
Batch 8/64 loss: -2.99627685546875
Batch 9/64 loss: -2.632720947265625
Batch 10/64 loss: -1.9665756225585938
Batch 11/64 loss: -2.8634891510009766
Batch 12/64 loss: -3.077831268310547
Batch 13/64 loss: -2.780874252319336
Batch 14/64 loss: -2.323598861694336
Batch 15/64 loss: -3.137258529663086
Batch 16/64 loss: -2.690584182739258
Batch 17/64 loss: -2.7985877990722656
Batch 18/64 loss: -2.613306999206543
Batch 19/64 loss: -2.9209985733032227
Batch 20/64 loss: -2.0699939727783203
Batch 21/64 loss: -2.5292930603027344
Batch 22/64 loss: -2.9417171478271484
Batch 23/64 loss: -2.614168167114258
Batch 24/64 loss: -3.0674095153808594
Batch 25/64 loss: -3.100905418395996
Batch 26/64 loss: -2.195436477661133
Batch 27/64 loss: -2.831852912902832
Batch 28/64 loss: -2.5255231857299805
Batch 29/64 loss: -2.983154296875
Batch 30/64 loss: -2.8527145385742188
Batch 31/64 loss: -3.128420829772949
Batch 32/64 loss: -2.8580093383789062
Batch 33/64 loss: -2.747075080871582
Batch 34/64 loss: -3.1409597396850586
Batch 35/64 loss: -2.445127487182617
Batch 36/64 loss: -2.9329423904418945
Batch 37/64 loss: -2.7924070358276367
Batch 38/64 loss: -2.5727224349975586
Batch 39/64 loss: -2.316897392272949
Batch 40/64 loss: -2.531296730041504
Batch 41/64 loss: -3.0631561279296875
Batch 42/64 loss: -2.20999813079834
Batch 43/64 loss: -2.9507875442504883
Batch 44/64 loss: -2.8036394119262695
Batch 45/64 loss: -3.030893325805664
Batch 46/64 loss: -2.82843017578125
Batch 47/64 loss: -2.387798309326172
Batch 48/64 loss: -2.519312858581543
Batch 49/64 loss: -3.0739784240722656
Batch 50/64 loss: -2.7228269577026367
Batch 51/64 loss: -2.99530029296875
Batch 52/64 loss: -3.110569953918457
Batch 53/64 loss: -3.0010547637939453
Batch 54/64 loss: -3.225067138671875
Batch 55/64 loss: -2.748472213745117
Batch 56/64 loss: -3.1171483993530273
Batch 57/64 loss: -2.901421546936035
Batch 58/64 loss: -2.854874610900879
Batch 59/64 loss: -3.0939598083496094
Batch 60/64 loss: -2.736083984375
Batch 61/64 loss: -2.817018508911133
Batch 62/64 loss: -2.911454200744629
Batch 63/64 loss: -2.560365676879883
Batch 64/64 loss: -7.625439167022705
Epoch 492  Train loss: -2.8371261652778177  Val loss: -3.2234718086793253
Epoch 493
-------------------------------
Batch 1/64 loss: -2.8799753189086914
Batch 2/64 loss: -3.042512893676758
Batch 3/64 loss: -3.013317108154297
Batch 4/64 loss: -3.149799346923828
Batch 5/64 loss: -2.3017263412475586
Batch 6/64 loss: -2.849053382873535
Batch 7/64 loss: -3.0613670349121094
Batch 8/64 loss: -3.1335878372192383
Batch 9/64 loss: -2.7739648818969727
Batch 10/64 loss: -2.6003007888793945
Batch 11/64 loss: -2.5482053756713867
Batch 12/64 loss: -2.9372692108154297
Batch 13/64 loss: -2.9955310821533203
Batch 14/64 loss: -2.981386184692383
Batch 15/64 loss: -2.7640304565429688
Batch 16/64 loss: -3.214320182800293
Batch 17/64 loss: -2.9469070434570312
Batch 18/64 loss: -2.7734479904174805
Batch 19/64 loss: -2.8833866119384766
Batch 20/64 loss: -2.806669235229492
Batch 21/64 loss: -3.017056465148926
Batch 22/64 loss: -2.71798038482666
Batch 23/64 loss: -2.9441909790039062
Batch 24/64 loss: -2.8761730194091797
Batch 25/64 loss: -2.2971582412719727
Batch 26/64 loss: -3.0455169677734375
Batch 27/64 loss: -2.5657243728637695
Batch 28/64 loss: -2.69576358795166
Batch 29/64 loss: -2.243532180786133
Batch 30/64 loss: -3.004413604736328
Batch 31/64 loss: -2.5032033920288086
Batch 32/64 loss: -2.909931182861328
Batch 33/64 loss: -2.8508386611938477
Batch 34/64 loss: -2.8980417251586914
Batch 35/64 loss: -2.9742584228515625
Batch 36/64 loss: -2.675387382507324
Batch 37/64 loss: -2.185336112976074
Batch 38/64 loss: -2.7456798553466797
Batch 39/64 loss: -3.242398262023926
Batch 40/64 loss: -2.7659568786621094
Batch 41/64 loss: -2.368276596069336
Batch 42/64 loss: -2.967331886291504
Batch 43/64 loss: -2.7426528930664062
Batch 44/64 loss: -2.64111328125
Batch 45/64 loss: -3.023326873779297
Batch 46/64 loss: -2.42543888092041
Batch 47/64 loss: -2.595417022705078
Batch 48/64 loss: -2.7423248291015625
Batch 49/64 loss: -2.5719709396362305
Batch 50/64 loss: -2.8055715560913086
Batch 51/64 loss: -2.896721839904785
Batch 52/64 loss: -2.5343189239501953
Batch 53/64 loss: -2.960714340209961
Batch 54/64 loss: -2.8904151916503906
Batch 55/64 loss: -2.8660707473754883
Batch 56/64 loss: -2.998110771179199
Batch 57/64 loss: -2.9414186477661133
Batch 58/64 loss: -3.0985097885131836
Batch 59/64 loss: -2.938802719116211
Batch 60/64 loss: -2.7768678665161133
Batch 61/64 loss: -2.6860294342041016
Batch 62/64 loss: -2.88323974609375
Batch 63/64 loss: -2.9626893997192383
Batch 64/64 loss: -7.5748820304870605
Epoch 493  Train loss: -2.8676673833061668  Val loss: -3.288970750631745
Epoch 494
-------------------------------
Batch 1/64 loss: -2.9630203247070312
Batch 2/64 loss: -2.4703359603881836
Batch 3/64 loss: -2.911454200744629
Batch 4/64 loss: -2.186199188232422
Batch 5/64 loss: -2.964016914367676
Batch 6/64 loss: -2.840806007385254
Batch 7/64 loss: -3.1767759323120117
Batch 8/64 loss: -2.930342674255371
Batch 9/64 loss: -3.1243457794189453
Batch 10/64 loss: -2.9829044342041016
Batch 11/64 loss: -2.2392044067382812
Batch 12/64 loss: -2.73928165435791
Batch 13/64 loss: -2.9816503524780273
Batch 14/64 loss: -3.054539680480957
Batch 15/64 loss: -2.4341421127319336
Batch 16/64 loss: -2.920260429382324
Batch 17/64 loss: -2.918489456176758
Batch 18/64 loss: -2.278745651245117
Batch 19/64 loss: -2.51369571685791
Batch 20/64 loss: -2.9843807220458984
Batch 21/64 loss: -3.0229415893554688
Batch 22/64 loss: -2.7644519805908203
Batch 23/64 loss: -3.1637697219848633
Batch 24/64 loss: -3.1359329223632812
Batch 25/64 loss: -3.0851173400878906
Batch 26/64 loss: -2.4527692794799805
Batch 27/64 loss: -2.7069053649902344
Batch 28/64 loss: -2.638509750366211
Batch 29/64 loss: -2.5895462036132812
Batch 30/64 loss: -3.032132148742676
Batch 31/64 loss: -2.8318042755126953
Batch 32/64 loss: -2.7424087524414062
Batch 33/64 loss: -3.097829818725586
Batch 34/64 loss: -2.797870635986328
Batch 35/64 loss: -2.8608598709106445
Batch 36/64 loss: -2.697114944458008
Batch 37/64 loss: -3.089599609375
Batch 38/64 loss: -3.067551612854004
Batch 39/64 loss: -2.7763214111328125
Batch 40/64 loss: -2.7711715698242188
Batch 41/64 loss: -3.0042800903320312
Batch 42/64 loss: -2.851226806640625
Batch 43/64 loss: -2.9582815170288086
Batch 44/64 loss: -2.9205493927001953
Batch 45/64 loss: -2.414853096008301
Batch 46/64 loss: -2.7787094116210938
Batch 47/64 loss: -3.0268163681030273
Batch 48/64 loss: -2.923821449279785
Batch 49/64 loss: -3.1347532272338867
Batch 50/64 loss: -2.886624336242676
Batch 51/64 loss: -3.074313163757324
Batch 52/64 loss: -3.0038042068481445
Batch 53/64 loss: -2.989811897277832
Batch 54/64 loss: -2.691089630126953
Batch 55/64 loss: -2.8697357177734375
Batch 56/64 loss: -2.835118293762207
Batch 57/64 loss: -3.001267433166504
Batch 58/64 loss: -2.972466468811035
Batch 59/64 loss: -2.59212589263916
Batch 60/64 loss: -2.809197425842285
Batch 61/64 loss: -2.899489402770996
Batch 62/64 loss: -3.0761499404907227
Batch 63/64 loss: -2.931157112121582
Batch 64/64 loss: -7.468677997589111
Epoch 494  Train loss: -2.904883940079633  Val loss: -3.2851998371766604
Epoch 495
-------------------------------
Batch 1/64 loss: -3.0654296875
Batch 2/64 loss: -3.06500244140625
Batch 3/64 loss: -2.967860221862793
Batch 4/64 loss: -2.9678239822387695
Batch 5/64 loss: -2.8747215270996094
Batch 6/64 loss: -2.8996124267578125
Batch 7/64 loss: -3.062005043029785
Batch 8/64 loss: -2.8213424682617188
Batch 9/64 loss: -2.396367073059082
Batch 10/64 loss: -3.1172056198120117
Batch 11/64 loss: -2.3904600143432617
Batch 12/64 loss: -2.939091682434082
Batch 13/64 loss: -2.773164749145508
Batch 14/64 loss: -3.220182418823242
Batch 15/64 loss: -3.050421714782715
Batch 16/64 loss: -3.0036191940307617
Batch 17/64 loss: -2.9305601119995117
Batch 18/64 loss: -2.9777231216430664
Batch 19/64 loss: -2.751375198364258
Batch 20/64 loss: -3.095304489135742
Batch 21/64 loss: -3.057374954223633
Batch 22/64 loss: -2.9241762161254883
Batch 23/64 loss: -2.6068496704101562
Batch 24/64 loss: -2.840862274169922
Batch 25/64 loss: -2.837204933166504
Batch 26/64 loss: -3.049981117248535
Batch 27/64 loss: -3.1672773361206055
Batch 28/64 loss: -2.804232597351074
Batch 29/64 loss: -2.958040237426758
Batch 30/64 loss: -2.3150978088378906
Batch 31/64 loss: -2.727214813232422
Batch 32/64 loss: -2.9829959869384766
Batch 33/64 loss: -2.840526580810547
Batch 34/64 loss: -2.317636489868164
Batch 35/64 loss: -3.0696563720703125
Batch 36/64 loss: -3.07273006439209
Batch 37/64 loss: -2.924173355102539
Batch 38/64 loss: -2.814620018005371
Batch 39/64 loss: -2.7780418395996094
Batch 40/64 loss: -2.5195236206054688
Batch 41/64 loss: -2.779778480529785
Batch 42/64 loss: -2.7076663970947266
Batch 43/64 loss: -2.8592023849487305
Batch 44/64 loss: -2.818136215209961
Batch 45/64 loss: -3.0616607666015625
Batch 46/64 loss: -3.0370635986328125
Batch 47/64 loss: -2.5572032928466797
Batch 48/64 loss: -2.7951841354370117
Batch 49/64 loss: -2.9275150299072266
Batch 50/64 loss: -2.917628288269043
Batch 51/64 loss: -2.7145442962646484
Batch 52/64 loss: -2.8114423751831055
Batch 53/64 loss: -2.689228057861328
Batch 54/64 loss: -2.9589767456054688
Batch 55/64 loss: -2.854198455810547
Batch 56/64 loss: -2.923999786376953
Batch 57/64 loss: -2.7718114852905273
Batch 58/64 loss: -2.230099678039551
Batch 59/64 loss: -2.5979881286621094
Batch 60/64 loss: -2.912644386291504
Batch 61/64 loss: -2.88192081451416
Batch 62/64 loss: -2.7102622985839844
Batch 63/64 loss: -2.7990474700927734
Batch 64/64 loss: -7.4598894119262695
Epoch 495  Train loss: -2.9002291623283836  Val loss: -3.2287108300068126
Epoch 496
-------------------------------
Batch 1/64 loss: -2.540024757385254
Batch 2/64 loss: -2.7599992752075195
Batch 3/64 loss: -2.7963857650756836
Batch 4/64 loss: -2.922819137573242
Batch 5/64 loss: -2.996540069580078
Batch 6/64 loss: -2.3494644165039062
Batch 7/64 loss: -2.8656044006347656
Batch 8/64 loss: -2.9056396484375
Batch 9/64 loss: -2.0301876068115234
Batch 10/64 loss: -2.8864517211914062
Batch 11/64 loss: -3.0477657318115234
Batch 12/64 loss: -2.7807188034057617
Batch 13/64 loss: -2.8792247772216797
Batch 14/64 loss: -3.0294313430786133
Batch 15/64 loss: -3.1145496368408203
Batch 16/64 loss: -2.86551570892334
Batch 17/64 loss: -2.5077524185180664
Batch 18/64 loss: -3.092700958251953
Batch 19/64 loss: -2.5550155639648438
Batch 20/64 loss: -2.837648391723633
Batch 21/64 loss: -3.0130109786987305
Batch 22/64 loss: -3.2283573150634766
Batch 23/64 loss: -2.953557014465332
Batch 24/64 loss: -3.187769889831543
Batch 25/64 loss: -3.144961357116699
Batch 26/64 loss: -2.8370494842529297
Batch 27/64 loss: -2.849842071533203
Batch 28/64 loss: -2.6985559463500977
Batch 29/64 loss: -2.784623146057129
Batch 30/64 loss: -2.8087940216064453
Batch 31/64 loss: -3.0850048065185547
Batch 32/64 loss: -3.089426040649414
Batch 33/64 loss: -3.0926876068115234
Batch 34/64 loss: -2.924947738647461
Batch 35/64 loss: -3.023588180541992
Batch 36/64 loss: -3.277285099029541
Batch 37/64 loss: -2.987799644470215
Batch 38/64 loss: -3.1680078506469727
Batch 39/64 loss: -3.032512664794922
Batch 40/64 loss: -2.9981422424316406
Batch 41/64 loss: -2.8601150512695312
Batch 42/64 loss: -2.994304656982422
Batch 43/64 loss: -2.5329065322875977
Batch 44/64 loss: -2.807154655456543
Batch 45/64 loss: -2.847092628479004
Batch 46/64 loss: -2.975374221801758
Batch 47/64 loss: -3.1074914932250977
Batch 48/64 loss: -3.107309341430664
Batch 49/64 loss: -2.8425168991088867
Batch 50/64 loss: -3.047175407409668
Batch 51/64 loss: -2.8802900314331055
Batch 52/64 loss: -2.552135467529297
Batch 53/64 loss: -2.9766855239868164
Batch 54/64 loss: -2.9912805557250977
Batch 55/64 loss: -2.891071319580078
Batch 56/64 loss: -3.0120162963867188
Batch 57/64 loss: -3.0879573822021484
Batch 58/64 loss: -2.7278900146484375
Batch 59/64 loss: -2.7260732650756836
Batch 60/64 loss: -3.0989465713500977
Batch 61/64 loss: -3.030917167663574
Batch 62/64 loss: -3.116703987121582
Batch 63/64 loss: -2.822686195373535
Batch 64/64 loss: -7.29829216003418
Epoch 496  Train loss: -2.9562223845837163  Val loss: -3.255238916456085
Epoch 497
-------------------------------
Batch 1/64 loss: -2.863056182861328
Batch 2/64 loss: -2.1640710830688477
Batch 3/64 loss: -3.0623703002929688
Batch 4/64 loss: -2.883500099182129
Batch 5/64 loss: -2.9970703125
Batch 6/64 loss: -2.822874069213867
Batch 7/64 loss: -2.9760608673095703
Batch 8/64 loss: -2.8885936737060547
Batch 9/64 loss: -3.043887138366699
Batch 10/64 loss: -2.712162971496582
Batch 11/64 loss: -2.9603376388549805
Batch 12/64 loss: -2.9159669876098633
Batch 13/64 loss: -2.8443078994750977
Batch 14/64 loss: -3.017580986022949
Batch 15/64 loss: -3.0469112396240234
Batch 16/64 loss: -2.8066043853759766
Batch 17/64 loss: -3.187596321105957
Batch 18/64 loss: -3.0166501998901367
Batch 19/64 loss: -2.9816160202026367
Batch 20/64 loss: -2.8577709197998047
Batch 21/64 loss: -2.996079444885254
Batch 22/64 loss: -2.8097896575927734
Batch 23/64 loss: -2.860078811645508
Batch 24/64 loss: -2.6838464736938477
Batch 25/64 loss: -2.8365840911865234
Batch 26/64 loss: -2.908745765686035
Batch 27/64 loss: -2.953916549682617
Batch 28/64 loss: -3.0873308181762695
Batch 29/64 loss: -2.538712501525879
Batch 30/64 loss: -3.1327390670776367
Batch 31/64 loss: -3.0448408126831055
Batch 32/64 loss: -3.0740652084350586
Batch 33/64 loss: -3.252117156982422
Batch 34/64 loss: -2.5725784301757812
Batch 35/64 loss: -2.926534652709961
Batch 36/64 loss: -2.8047561645507812
Batch 37/64 loss: -2.794374465942383
Batch 38/64 loss: -3.0956735610961914
Batch 39/64 loss: -2.639704704284668
Batch 40/64 loss: -2.565567970275879
Batch 41/64 loss: -2.913492202758789
Batch 42/64 loss: -2.901784896850586
Batch 43/64 loss: -3.004258155822754
Batch 44/64 loss: -3.0229387283325195
Batch 45/64 loss: -2.934661865234375
Batch 46/64 loss: -2.9663639068603516
Batch 47/64 loss: -2.5612306594848633
Batch 48/64 loss: -3.0236072540283203
Batch 49/64 loss: -2.4052915573120117
Batch 50/64 loss: -2.9972286224365234
Batch 51/64 loss: -2.999068260192871
Batch 52/64 loss: -2.8818235397338867
Batch 53/64 loss: -2.824777603149414
Batch 54/64 loss: -3.081658363342285
Batch 55/64 loss: -2.8801679611206055
Batch 56/64 loss: -3.1013784408569336
Batch 57/64 loss: -3.1386804580688477
Batch 58/64 loss: -3.120631217956543
Batch 59/64 loss: -2.5003490447998047
Batch 60/64 loss: -2.7988405227661133
Batch 61/64 loss: -2.5963134765625
Batch 62/64 loss: -3.008159637451172
Batch 63/64 loss: -3.2392024993896484
Batch 64/64 loss: -7.506368637084961
Epoch 497  Train loss: -2.9515091914756626  Val loss: -3.265831216504074
Epoch 498
-------------------------------
Batch 1/64 loss: -2.6363649368286133
Batch 2/64 loss: -3.0675249099731445
Batch 3/64 loss: -3.136962890625
Batch 4/64 loss: -2.981840133666992
Batch 5/64 loss: -2.9266843795776367
Batch 6/64 loss: -2.938387870788574
Batch 7/64 loss: -3.0021677017211914
Batch 8/64 loss: -2.964883804321289
Batch 9/64 loss: -2.634352684020996
Batch 10/64 loss: -2.9485607147216797
Batch 11/64 loss: -3.115152359008789
Batch 12/64 loss: -2.843595504760742
Batch 13/64 loss: -3.0369577407836914
Batch 14/64 loss: -3.1231985092163086
Batch 15/64 loss: -2.9371557235717773
Batch 16/64 loss: -2.8204259872436523
Batch 17/64 loss: -3.1277236938476562
Batch 18/64 loss: -3.145719528198242
Batch 19/64 loss: -3.026455879211426
Batch 20/64 loss: -3.172801971435547
Batch 21/64 loss: -1.8937292098999023
Batch 22/64 loss: -2.5301856994628906
Batch 23/64 loss: -2.8741626739501953
Batch 24/64 loss: -3.1308212280273438
Batch 25/64 loss: -2.958756446838379
Batch 26/64 loss: -2.7342166900634766
Batch 27/64 loss: -3.0848464965820312
Batch 28/64 loss: -2.8289690017700195
Batch 29/64 loss: -3.123453140258789
Batch 30/64 loss: -2.853856086730957
Batch 31/64 loss: -3.0193920135498047
Batch 32/64 loss: -2.39646053314209
Batch 33/64 loss: -2.944342613220215
Batch 34/64 loss: -3.0367422103881836
Batch 35/64 loss: -2.7220516204833984
Batch 36/64 loss: -3.0035743713378906
Batch 37/64 loss: -2.812771797180176
Batch 38/64 loss: -3.048222541809082
Batch 39/64 loss: -2.886223793029785
Batch 40/64 loss: -2.991231918334961
Batch 41/64 loss: -2.908205032348633
Batch 42/64 loss: -2.883453369140625
Batch 43/64 loss: -3.141695976257324
Batch 44/64 loss: -3.2088842391967773
Batch 45/64 loss: -3.052675247192383
Batch 46/64 loss: -3.0483779907226562
Batch 47/64 loss: -2.89656925201416
Batch 48/64 loss: -2.8145036697387695
Batch 49/64 loss: -3.163942337036133
Batch 50/64 loss: -3.113192558288574
Batch 51/64 loss: -2.899690628051758
Batch 52/64 loss: -2.3684005737304688
Batch 53/64 loss: -2.9306373596191406
Batch 54/64 loss: -3.1134109497070312
Batch 55/64 loss: -2.841419219970703
Batch 56/64 loss: -2.8573179244995117
Batch 57/64 loss: -2.8392553329467773
Batch 58/64 loss: -3.1000871658325195
Batch 59/64 loss: -2.953352928161621
Batch 60/64 loss: -3.0787534713745117
Batch 61/64 loss: -3.1182737350463867
Batch 62/64 loss: -2.988147735595703
Batch 63/64 loss: -2.964254379272461
Batch 64/64 loss: -7.458538055419922
Epoch 498  Train loss: -2.985715005912033  Val loss: -3.327489269558097
Epoch 499
-------------------------------
Batch 1/64 loss: -2.898533821105957
Batch 2/64 loss: -2.6305103302001953
Batch 3/64 loss: -3.177644729614258
Batch 4/64 loss: -2.980680465698242
Batch 5/64 loss: -3.0316162109375
Batch 6/64 loss: -3.156757354736328
Batch 7/64 loss: -3.0832767486572266
Batch 8/64 loss: -2.960023880004883
Batch 9/64 loss: -2.6279773712158203
Batch 10/64 loss: -3.006606101989746
Batch 11/64 loss: -3.0496034622192383
Batch 12/64 loss: -2.9055871963500977
Batch 13/64 loss: -2.9408464431762695
Batch 14/64 loss: -3.091726303100586
Batch 15/64 loss: -3.02945613861084
Batch 16/64 loss: -3.296844959259033
Batch 17/64 loss: -2.9967422485351562
Batch 18/64 loss: -3.2345685958862305
Batch 19/64 loss: -2.9293947219848633
Batch 20/64 loss: -3.1359291076660156
Batch 21/64 loss: -2.8561811447143555
Batch 22/64 loss: -3.0567054748535156
Batch 23/64 loss: -2.1662158966064453
Batch 24/64 loss: -2.94632625579834
Batch 25/64 loss: -3.0087833404541016
Batch 26/64 loss: -3.019977569580078
Batch 27/64 loss: -3.1987199783325195
Batch 28/64 loss: -3.077113151550293
Batch 29/64 loss: -2.896368980407715
Batch 30/64 loss: -2.5556774139404297
Batch 31/64 loss: -3.2232255935668945
Batch 32/64 loss: -3.1384572982788086
Batch 33/64 loss: -3.18496036529541
Batch 34/64 loss: -2.8843727111816406
Batch 35/64 loss: -2.9519195556640625
Batch 36/64 loss: -2.3029298782348633
Batch 37/64 loss: -2.948413848876953
Batch 38/64 loss: -3.0218334197998047
Batch 39/64 loss: -2.917292594909668
Batch 40/64 loss: -2.878711700439453
Batch 41/64 loss: -2.928900718688965
Batch 42/64 loss: -3.1906986236572266
Batch 43/64 loss: -3.2407588958740234
Batch 44/64 loss: -2.625189781188965
Batch 45/64 loss: -3.069082260131836
Batch 46/64 loss: -3.052125930786133
Batch 47/64 loss: -3.0252437591552734
Batch 48/64 loss: -2.928370475769043
Batch 49/64 loss: -3.2077760696411133
Batch 50/64 loss: -2.474820137023926
Batch 51/64 loss: -2.826108932495117
Batch 52/64 loss: -2.7330474853515625
Batch 53/64 loss: -2.6500015258789062
Batch 54/64 loss: -2.997325897216797
Batch 55/64 loss: -3.142104148864746
Batch 56/64 loss: -3.06463623046875
Batch 57/64 loss: -2.6526927947998047
Batch 58/64 loss: -3.0546560287475586
Batch 59/64 loss: -3.0647459030151367
Batch 60/64 loss: -2.9123640060424805
Batch 61/64 loss: -2.6065902709960938
Batch 62/64 loss: -3.0507259368896484
Batch 63/64 loss: -2.970414161682129
Batch 64/64 loss: -7.4542012214660645
Epoch 499  Train loss: -3.003255580453312  Val loss: -3.2488208783860877
Epoch 500
-------------------------------
Batch 1/64 loss: -2.907719612121582
Batch 2/64 loss: -3.1314382553100586
Batch 3/64 loss: -2.371476173400879
Batch 4/64 loss: -3.060882568359375
Batch 5/64 loss: -2.9599523544311523
Batch 6/64 loss: -2.577577590942383
Batch 7/64 loss: -3.0706281661987305
Batch 8/64 loss: -3.1088523864746094
Batch 9/64 loss: -2.8686037063598633
Batch 10/64 loss: -2.926393508911133
Batch 11/64 loss: -2.393549919128418
Batch 12/64 loss: -2.498992919921875
Batch 13/64 loss: -3.239103317260742
Batch 14/64 loss: -3.061586380004883
Batch 15/64 loss: -2.756747245788574
Batch 16/64 loss: -2.961733818054199
Batch 17/64 loss: -2.8649139404296875
Batch 18/64 loss: -2.8623228073120117
Batch 19/64 loss: -3.205010414123535
Batch 20/64 loss: -3.224102020263672
Batch 21/64 loss: -3.28635311126709
Batch 22/64 loss: -3.0525989532470703
Batch 23/64 loss: -3.2859554290771484
Batch 24/64 loss: -3.006490707397461
Batch 25/64 loss: -3.1166200637817383
Batch 26/64 loss: -3.1489667892456055
Batch 27/64 loss: -2.783660888671875
Batch 28/64 loss: -3.0979785919189453
Batch 29/64 loss: -2.855484962463379
Batch 30/64 loss: -2.8602075576782227
Batch 31/64 loss: -3.086151123046875
Batch 32/64 loss: -2.9041290283203125
Batch 33/64 loss: -3.198550224304199
Batch 34/64 loss: -2.957653045654297
Batch 35/64 loss: -3.276111125946045
Batch 36/64 loss: -3.027587890625
Batch 37/64 loss: -2.8798913955688477
Batch 38/64 loss: -3.060596466064453
Batch 39/64 loss: -2.3873300552368164
Batch 40/64 loss: -3.031513214111328
Batch 41/64 loss: -2.8115901947021484
Batch 42/64 loss: -3.1873044967651367
Batch 43/64 loss: -3.121645927429199
Batch 44/64 loss: -2.9768495559692383
Batch 45/64 loss: -2.9684877395629883
Batch 46/64 loss: -3.073497772216797
Batch 47/64 loss: -2.7745723724365234
Batch 48/64 loss: -3.062042236328125
Batch 49/64 loss: -2.722405433654785
Batch 50/64 loss: -3.1343231201171875
Batch 51/64 loss: -2.833930015563965
Batch 52/64 loss: -3.1003971099853516
Batch 53/64 loss: -3.047369956970215
Batch 54/64 loss: -3.1466197967529297
Batch 55/64 loss: -3.0138626098632812
Batch 56/64 loss: -3.0488672256469727
Batch 57/64 loss: -2.927433967590332
Batch 58/64 loss: -3.020465850830078
Batch 59/64 loss: -3.266415596008301
Batch 60/64 loss: -3.106039047241211
Batch 61/64 loss: -3.1034469604492188
Batch 62/64 loss: -2.9950904846191406
Batch 63/64 loss: -3.101109504699707
Batch 64/64 loss: -7.376373767852783
Epoch 500  Train loss: -3.0342190592896703  Val loss: -3.3642598050566472
SLIC undersegmentation error: 0.12412920962199316
SLIC inter-cluster variation: 0.13904419774313004
SLIC number of superpixels: 21483
SLIC superpixels per image: 73.82474226804123
Model loaded
Test metrics:
-4.08702095267699 0.2944082474226804 25.23485218635379 tensor(0.2662, dtype=torch.float64) 0.6411117758041508 2.3828631908333717 21731
Inference time: 0.0036327199837596145 seconds
Relabeled undersegmentation error: 0.11956288659793814
Relabeled inter-cluster variation: 0.09453909221596028
Relabeled mean superpixels count: 177.9553264604811
Original mean superpixels count: 74.67697594501718
Done!
Job id: 490851
Job id: 492266
