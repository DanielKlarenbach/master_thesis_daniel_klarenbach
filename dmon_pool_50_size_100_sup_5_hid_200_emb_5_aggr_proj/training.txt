Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 4.621790885925293
Batch 2/64 loss: 4.6256890296936035
Batch 3/64 loss: 4.629409313201904
Batch 4/64 loss: 4.607184410095215
Batch 5/64 loss: 4.610311508178711
Batch 6/64 loss: 4.599405765533447
Batch 7/64 loss: 4.5936455726623535
Batch 8/64 loss: 4.595081806182861
Batch 9/64 loss: 4.588846206665039
Batch 10/64 loss: 4.590666770935059
Batch 11/64 loss: 4.59074068069458
Batch 12/64 loss: 4.584709644317627
Batch 13/64 loss: 4.5843610763549805
Batch 14/64 loss: 4.581387519836426
Batch 15/64 loss: 4.579997539520264
Batch 16/64 loss: 4.5860819816589355
Batch 17/64 loss: 4.578405380249023
Batch 18/64 loss: 4.582261562347412
Batch 19/64 loss: 4.5781731605529785
Batch 20/64 loss: 4.579582214355469
Batch 21/64 loss: 4.578362941741943
Batch 22/64 loss: 4.5765204429626465
Batch 23/64 loss: 4.576986789703369
Batch 24/64 loss: 4.576395034790039
Batch 25/64 loss: 4.574850559234619
Batch 26/64 loss: 4.574193954467773
Batch 27/64 loss: 4.572539806365967
Batch 28/64 loss: 4.57273530960083
Batch 29/64 loss: 4.572307109832764
Batch 30/64 loss: 4.569215774536133
Batch 31/64 loss: 4.57041072845459
Batch 32/64 loss: 4.571011066436768
Batch 33/64 loss: 4.566627025604248
Batch 34/64 loss: 4.564798355102539
Batch 35/64 loss: 4.5651631355285645
Batch 36/64 loss: 4.557861804962158
Batch 37/64 loss: 4.561521530151367
Batch 38/64 loss: 4.562074661254883
Batch 39/64 loss: 4.55507230758667
Batch 40/64 loss: 4.551571846008301
Batch 41/64 loss: 4.5495171546936035
Batch 42/64 loss: 4.548801422119141
Batch 43/64 loss: 4.5439605712890625
Batch 44/64 loss: 4.545815944671631
Batch 45/64 loss: 4.530165195465088
Batch 46/64 loss: 4.530644416809082
Batch 47/64 loss: 4.525908946990967
Batch 48/64 loss: 4.523486614227295
Batch 49/64 loss: 4.509317874908447
Batch 50/64 loss: 4.509570598602295
Batch 51/64 loss: 4.496628284454346
Batch 52/64 loss: 4.498997211456299
Batch 53/64 loss: 4.488607406616211
Batch 54/64 loss: 4.481311798095703
Batch 55/64 loss: 4.480387210845947
Batch 56/64 loss: 4.469672679901123
Batch 57/64 loss: 4.442389488220215
Batch 58/64 loss: 4.423261642456055
Batch 59/64 loss: 4.400397300720215
Batch 60/64 loss: 4.397903919219971
Batch 61/64 loss: 4.450772762298584
Batch 62/64 loss: 4.408206939697266
Batch 63/64 loss: 4.420529365539551
Batch 64/64 loss: 3.4635682106018066
Epoch 1  Train loss: 4.533833460714303  Val loss: 4.475215844272339
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 4.41661262512207
Batch 2/64 loss: 4.332356929779053
Batch 3/64 loss: 4.327049255371094
Batch 4/64 loss: 4.511148929595947
Batch 5/64 loss: 4.334502696990967
Batch 6/64 loss: 4.304621696472168
Batch 7/64 loss: 4.23872709274292
Batch 8/64 loss: 4.243913650512695
Batch 9/64 loss: 4.199220657348633
Batch 10/64 loss: 4.2378692626953125
Batch 11/64 loss: 4.228042125701904
Batch 12/64 loss: 4.168186187744141
Batch 13/64 loss: 4.173763275146484
Batch 14/64 loss: 4.258762836456299
Batch 15/64 loss: 4.1312174797058105
Batch 16/64 loss: 4.146594524383545
Batch 17/64 loss: 4.16975212097168
Batch 18/64 loss: 4.247021675109863
Batch 19/64 loss: 4.140785217285156
Batch 20/64 loss: 4.112354755401611
Batch 21/64 loss: 4.104850769042969
Batch 22/64 loss: 4.1120195388793945
Batch 23/64 loss: 4.122145175933838
Batch 24/64 loss: 4.002851486206055
Batch 25/64 loss: 4.208230972290039
Batch 26/64 loss: 4.209568023681641
Batch 27/64 loss: 4.113036155700684
Batch 28/64 loss: 4.063015937805176
Batch 29/64 loss: 4.099793434143066
Batch 30/64 loss: 4.058457374572754
Batch 31/64 loss: 4.131446361541748
Batch 32/64 loss: 4.0458269119262695
Batch 33/64 loss: 4.083022594451904
Batch 34/64 loss: 3.9736249446868896
Batch 35/64 loss: 4.113072872161865
Batch 36/64 loss: 4.100242614746094
Batch 37/64 loss: 4.083890914916992
Batch 38/64 loss: 4.052746772766113
Batch 39/64 loss: 4.020224571228027
Batch 40/64 loss: 3.9562740325927734
Batch 41/64 loss: 3.950352907180786
Batch 42/64 loss: 3.851408004760742
Batch 43/64 loss: 3.8865392208099365
Batch 44/64 loss: 3.868579864501953
Batch 45/64 loss: 3.9158077239990234
Batch 46/64 loss: 3.778115749359131
Batch 47/64 loss: 3.8065128326416016
Batch 48/64 loss: 3.7861523628234863
Batch 49/64 loss: 3.744919538497925
Batch 50/64 loss: 3.882284641265869
Batch 51/64 loss: 3.957916259765625
Batch 52/64 loss: 3.7180070877075195
Batch 53/64 loss: 3.8382492065429688
Batch 54/64 loss: 3.7594642639160156
Batch 55/64 loss: 3.691396713256836
Batch 56/64 loss: 3.6752243041992188
Batch 57/64 loss: 3.710174798965454
Batch 58/64 loss: 3.8571712970733643
Batch 59/64 loss: 3.688025951385498
Batch 60/64 loss: 3.677126884460449
Batch 61/64 loss: 3.7750110626220703
Batch 62/64 loss: 3.611379623413086
Batch 63/64 loss: 3.6579976081848145
Batch 64/64 loss: 2.1141042709350586
Epoch 2  Train loss: 4.003925342185824  Val loss: 3.849025519852786
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 3.929755210876465
Batch 2/64 loss: 3.5839943885803223
Batch 3/64 loss: 3.8845810890197754
Batch 4/64 loss: 3.669806718826294
Batch 5/64 loss: 3.598203659057617
Batch 6/64 loss: 3.758932113647461
Batch 7/64 loss: 3.6108226776123047
Batch 8/64 loss: 3.5842056274414062
Batch 9/64 loss: 3.78120756149292
Batch 10/64 loss: 3.6223459243774414
Batch 11/64 loss: 3.533677577972412
Batch 12/64 loss: 3.6244163513183594
Batch 13/64 loss: 3.794428586959839
Batch 14/64 loss: 3.5474705696105957
Batch 15/64 loss: 3.4801156520843506
Batch 16/64 loss: 3.495547294616699
Batch 17/64 loss: 3.587850332260132
Batch 18/64 loss: 3.5129458904266357
Batch 19/64 loss: 3.6155426502227783
Batch 20/64 loss: 3.6482057571411133
Batch 21/64 loss: 3.464414358139038
Batch 22/64 loss: 3.4171886444091797
Batch 23/64 loss: 3.32894229888916
Batch 24/64 loss: 3.3821418285369873
Batch 25/64 loss: 3.6521735191345215
Batch 26/64 loss: 3.454906463623047
Batch 27/64 loss: 3.424072265625
Batch 28/64 loss: 3.5803234577178955
Batch 29/64 loss: 3.473588466644287
Batch 30/64 loss: 3.5037026405334473
Batch 31/64 loss: 3.3628547191619873
Batch 32/64 loss: 3.3305392265319824
Batch 33/64 loss: 3.3185932636260986
Batch 34/64 loss: 3.389453411102295
Batch 35/64 loss: 3.367356538772583
Batch 36/64 loss: 3.252030372619629
Batch 37/64 loss: 3.251997709274292
Batch 38/64 loss: 3.3006904125213623
Batch 39/64 loss: 3.3509087562561035
Batch 40/64 loss: 3.546462297439575
Batch 41/64 loss: 3.2349629402160645
Batch 42/64 loss: 3.46541690826416
Batch 43/64 loss: 3.3377468585968018
Batch 44/64 loss: 3.2637603282928467
Batch 45/64 loss: 3.3901312351226807
Batch 46/64 loss: 3.261016845703125
Batch 47/64 loss: 3.3332817554473877
Batch 48/64 loss: 3.2260682582855225
Batch 49/64 loss: 3.487283945083618
Batch 50/64 loss: 3.1841280460357666
Batch 51/64 loss: 3.189286231994629
Batch 52/64 loss: 3.309835195541382
Batch 53/64 loss: 3.299424648284912
Batch 54/64 loss: 3.1890947818756104
Batch 55/64 loss: 3.2935900688171387
Batch 56/64 loss: 3.220421075820923
Batch 57/64 loss: 3.1552765369415283
Batch 58/64 loss: 3.283374309539795
Batch 59/64 loss: 3.1263535022735596
Batch 60/64 loss: 3.041243314743042
Batch 61/64 loss: 2.991898775100708
Batch 62/64 loss: 3.020601987838745
Batch 63/64 loss: 3.1804933547973633
Batch 64/64 loss: 1.0905816555023193
Epoch 3  Train loss: 3.393239583221136  Val loss: 3.018816941382549
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 3.06540846824646
Batch 2/64 loss: 3.1101903915405273
Batch 3/64 loss: 3.0186970233917236
Batch 4/64 loss: 3.2432520389556885
Batch 5/64 loss: 3.0138511657714844
Batch 6/64 loss: 2.905348300933838
Batch 7/64 loss: 3.0262889862060547
Batch 8/64 loss: 2.7873690128326416
Batch 9/64 loss: 2.8693199157714844
Batch 10/64 loss: 3.036471128463745
Batch 11/64 loss: 3.1795437335968018
Batch 12/64 loss: 2.9682013988494873
Batch 13/64 loss: 2.9929537773132324
Batch 14/64 loss: 3.116105318069458
Batch 15/64 loss: 3.054503917694092
Batch 16/64 loss: 3.114013671875
Batch 17/64 loss: 2.9982848167419434
Batch 18/64 loss: 3.2614264488220215
Batch 19/64 loss: 2.939105272293091
Batch 20/64 loss: 2.8689849376678467
Batch 21/64 loss: 3.0721750259399414
Batch 22/64 loss: 3.0210916996002197
Batch 23/64 loss: 2.8149590492248535
Batch 24/64 loss: 2.75311017036438
Batch 25/64 loss: 2.7601592540740967
Batch 26/64 loss: 3.140878438949585
Batch 27/64 loss: 2.7452542781829834
Batch 28/64 loss: 2.8294475078582764
Batch 29/64 loss: 2.8169660568237305
Batch 30/64 loss: 2.970642328262329
Batch 31/64 loss: 2.7179694175720215
Batch 32/64 loss: 2.973088264465332
Batch 33/64 loss: 2.566380023956299
Batch 34/64 loss: 2.7182371616363525
Batch 35/64 loss: 2.7894272804260254
Batch 36/64 loss: 2.6309666633605957
Batch 37/64 loss: 2.6825366020202637
Batch 38/64 loss: 3.031648635864258
Batch 39/64 loss: 2.797377109527588
Batch 40/64 loss: 2.4988412857055664
Batch 41/64 loss: 2.5699148178100586
Batch 42/64 loss: 2.5946104526519775
Batch 43/64 loss: 2.7823398113250732
Batch 44/64 loss: 2.494640827178955
Batch 45/64 loss: 2.583644151687622
Batch 46/64 loss: 2.461841344833374
Batch 47/64 loss: 2.4166250228881836
Batch 48/64 loss: 2.416154384613037
Batch 49/64 loss: 2.5578737258911133
Batch 50/64 loss: 2.5310072898864746
Batch 51/64 loss: 2.2539353370666504
Batch 52/64 loss: 3.118973731994629
Batch 53/64 loss: 2.6515755653381348
Batch 54/64 loss: 2.502574920654297
Batch 55/64 loss: 2.411531925201416
Batch 56/64 loss: 2.554408550262451
Batch 57/64 loss: 2.472060203552246
Batch 58/64 loss: 2.5182695388793945
Batch 59/64 loss: 2.4826879501342773
Batch 60/64 loss: 2.372969150543213
Batch 61/64 loss: 2.557697296142578
Batch 62/64 loss: 2.3346753120422363
Batch 63/64 loss: 2.413419246673584
Batch 64/64 loss: -0.108551025390625
Epoch 4  Train loss: 2.7430979336009305  Val loss: 3.1079757729756463
Epoch 5
-------------------------------
Batch 1/64 loss: 2.2921252250671387
Batch 2/64 loss: 2.705723762512207
Batch 3/64 loss: 2.235635280609131
Batch 4/64 loss: 2.385937213897705
Batch 5/64 loss: 2.0765457153320312
Batch 6/64 loss: 2.4728307723999023
Batch 7/64 loss: 2.255429744720459
Batch 8/64 loss: 2.1504769325256348
Batch 9/64 loss: 2.2244668006896973
Batch 10/64 loss: 2.332148551940918
Batch 11/64 loss: 2.157769203186035
Batch 12/64 loss: 2.357163906097412
Batch 13/64 loss: 2.196155071258545
Batch 14/64 loss: 2.1452383995056152
Batch 15/64 loss: 2.147615909576416
Batch 16/64 loss: 2.3186450004577637
Batch 17/64 loss: 2.037048816680908
Batch 18/64 loss: 2.155579090118408
Batch 19/64 loss: 2.019062042236328
Batch 20/64 loss: 1.9876751899719238
Batch 21/64 loss: 1.8931989669799805
Batch 22/64 loss: 1.8971643447875977
Batch 23/64 loss: 2.0050406455993652
Batch 24/64 loss: 1.9088163375854492
Batch 25/64 loss: 1.6939697265625
Batch 26/64 loss: 2.006502628326416
Batch 27/64 loss: 1.8902320861816406
Batch 28/64 loss: 2.0016937255859375
Batch 29/64 loss: 1.8793158531188965
Batch 30/64 loss: 1.8257055282592773
Batch 31/64 loss: 1.8752408027648926
Batch 32/64 loss: 1.8206887245178223
Batch 33/64 loss: 2.335604667663574
Batch 34/64 loss: 1.8370771408081055
Batch 35/64 loss: 1.7780146598815918
Batch 36/64 loss: 1.7753381729125977
Batch 37/64 loss: 1.879772663116455
Batch 38/64 loss: 1.6309266090393066
Batch 39/64 loss: 1.894681453704834
Batch 40/64 loss: 1.9051518440246582
Batch 41/64 loss: 2.058042526245117
Batch 42/64 loss: 1.9432649612426758
Batch 43/64 loss: 1.9956955909729004
Batch 44/64 loss: 1.7096056938171387
Batch 45/64 loss: 2.255824565887451
Batch 46/64 loss: 1.8523855209350586
Batch 47/64 loss: 1.8089771270751953
Batch 48/64 loss: 2.114053726196289
Batch 49/64 loss: 1.7938990592956543
Batch 50/64 loss: 1.7913284301757812
Batch 51/64 loss: 1.5471138954162598
Batch 52/64 loss: 1.5951757431030273
Batch 53/64 loss: 1.6313438415527344
Batch 54/64 loss: 2.233687400817871
Batch 55/64 loss: 1.5918726921081543
Batch 56/64 loss: 1.4808897972106934
Batch 57/64 loss: 1.921682357788086
Batch 58/64 loss: 1.5301728248596191
Batch 59/64 loss: 1.7815680503845215
Batch 60/64 loss: 1.3935799598693848
Batch 61/64 loss: 1.5546998977661133
Batch 62/64 loss: 1.8022336959838867
Batch 63/64 loss: 1.8719706535339355
Batch 64/64 loss: -1.7840652465820312
Epoch 5  Train loss: 1.918563580980488  Val loss: 1.5266995511923458
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 1.7685356140136719
Batch 2/64 loss: 1.4798049926757812
Batch 3/64 loss: 1.6530003547668457
Batch 4/64 loss: 1.512657642364502
Batch 5/64 loss: 1.522489070892334
Batch 6/64 loss: 1.389998435974121
Batch 7/64 loss: 1.1873254776000977
Batch 8/64 loss: 1.1844582557678223
Batch 9/64 loss: 1.2975130081176758
Batch 10/64 loss: 1.2685480117797852
Batch 11/64 loss: 1.1149983406066895
Batch 12/64 loss: 0.893928050994873
Batch 13/64 loss: 1.226137638092041
Batch 14/64 loss: 1.2054619789123535
Batch 15/64 loss: 1.5881705284118652
Batch 16/64 loss: 1.2293424606323242
Batch 17/64 loss: 1.2241387367248535
Batch 18/64 loss: 0.9222064018249512
Batch 19/64 loss: 1.1310186386108398
Batch 20/64 loss: 1.064467430114746
Batch 21/64 loss: 0.9687395095825195
Batch 22/64 loss: 1.322439193725586
Batch 23/64 loss: 0.9208221435546875
Batch 24/64 loss: 0.8534321784973145
Batch 25/64 loss: 1.0369987487792969
Batch 26/64 loss: 1.0625371932983398
Batch 27/64 loss: 1.0837044715881348
Batch 28/64 loss: 1.1704363822937012
Batch 29/64 loss: 0.9287552833557129
Batch 30/64 loss: 0.7620506286621094
Batch 31/64 loss: 1.0345487594604492
Batch 32/64 loss: 0.7328987121582031
Batch 33/64 loss: 0.9356026649475098
Batch 34/64 loss: 1.102614402770996
Batch 35/64 loss: 0.7850379943847656
Batch 36/64 loss: 0.8236789703369141
Batch 37/64 loss: 0.9265732765197754
Batch 38/64 loss: 1.0733981132507324
Batch 39/64 loss: 0.46627044677734375
Batch 40/64 loss: 0.6281871795654297
Batch 41/64 loss: 0.6308140754699707
Batch 42/64 loss: 0.6878132820129395
Batch 43/64 loss: 1.1766400337219238
Batch 44/64 loss: 0.8955783843994141
Batch 45/64 loss: 1.116684913635254
Batch 46/64 loss: 1.2232441902160645
Batch 47/64 loss: 1.0007925033569336
Batch 48/64 loss: 0.9167289733886719
Batch 49/64 loss: 0.942349910736084
Batch 50/64 loss: 0.9467577934265137
Batch 51/64 loss: 0.934016227722168
Batch 52/64 loss: 0.9909868240356445
Batch 53/64 loss: 0.5496382713317871
Batch 54/64 loss: 0.5438876152038574
Batch 55/64 loss: 0.7540626525878906
Batch 56/64 loss: 1.0463719367980957
Batch 57/64 loss: 0.8313250541687012
Batch 58/64 loss: 1.1548123359680176
Batch 59/64 loss: 0.7739167213439941
Batch 60/64 loss: 0.7729125022888184
Batch 61/64 loss: 1.2063145637512207
Batch 62/64 loss: 0.7162537574768066
Batch 63/64 loss: 0.7792224884033203
Batch 64/64 loss: -2.8627548217773438
Epoch 6  Train loss: 0.9870899798823338  Val loss: 1.2391206669233918
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 0.6529622077941895
Batch 2/64 loss: 1.0021171569824219
Batch 3/64 loss: 0.7870998382568359
Batch 4/64 loss: 0.8677792549133301
Batch 5/64 loss: 0.8955526351928711
Batch 6/64 loss: 0.8154439926147461
Batch 7/64 loss: 0.7956781387329102
Batch 8/64 loss: 1.0132269859313965
Batch 9/64 loss: 0.7610011100769043
Batch 10/64 loss: 0.6763701438903809
Batch 11/64 loss: 0.8162431716918945
Batch 12/64 loss: 0.5709314346313477
Batch 13/64 loss: 0.6350507736206055
Batch 14/64 loss: 0.4373950958251953
Batch 15/64 loss: 0.5302262306213379
Batch 16/64 loss: 1.0683555603027344
Batch 17/64 loss: 0.6603846549987793
Batch 18/64 loss: 0.43566465377807617
Batch 19/64 loss: 0.6701884269714355
Batch 20/64 loss: 0.8686299324035645
Batch 21/64 loss: 0.5968303680419922
Batch 22/64 loss: 0.4838399887084961
Batch 23/64 loss: 0.2948904037475586
Batch 24/64 loss: 0.46387147903442383
Batch 25/64 loss: 1.0868873596191406
Batch 26/64 loss: 0.8243927955627441
Batch 27/64 loss: 0.7483530044555664
Batch 28/64 loss: 0.6930999755859375
Batch 29/64 loss: 0.8583383560180664
Batch 30/64 loss: 0.2977719306945801
Batch 31/64 loss: 0.8505830764770508
Batch 32/64 loss: 0.9178738594055176
Batch 33/64 loss: 0.5313339233398438
Batch 34/64 loss: 0.4675726890563965
Batch 35/64 loss: 0.6864848136901855
Batch 36/64 loss: 0.44907426834106445
Batch 37/64 loss: 0.36760377883911133
Batch 38/64 loss: 0.5674686431884766
Batch 39/64 loss: 0.4092855453491211
Batch 40/64 loss: 0.17935800552368164
Batch 41/64 loss: 0.3371915817260742
Batch 42/64 loss: 0.38486385345458984
Batch 43/64 loss: 0.6015748977661133
Batch 44/64 loss: 0.3540043830871582
Batch 45/64 loss: 0.3021259307861328
Batch 46/64 loss: 0.9082560539245605
Batch 47/64 loss: 0.49141407012939453
Batch 48/64 loss: 0.7097320556640625
Batch 49/64 loss: 0.5565543174743652
Batch 50/64 loss: 0.5160245895385742
Batch 51/64 loss: 0.1388564109802246
Batch 52/64 loss: 0.42905426025390625
Batch 53/64 loss: 0.7106342315673828
Batch 54/64 loss: 0.17931270599365234
Batch 55/64 loss: 0.404630184173584
Batch 56/64 loss: 0.5277061462402344
Batch 57/64 loss: 0.5451016426086426
Batch 58/64 loss: 0.2893400192260742
Batch 59/64 loss: 0.6056656837463379
Batch 60/64 loss: 0.4857802391052246
Batch 61/64 loss: 0.4991908073425293
Batch 62/64 loss: 0.8015322685241699
Batch 63/64 loss: 0.7177376747131348
Batch 64/64 loss: -3.1938209533691406
Epoch 7  Train loss: 0.5621354346181832  Val loss: 0.8434724840511572
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 0.6315121650695801
Batch 2/64 loss: 0.44176626205444336
Batch 3/64 loss: 1.1727089881896973
Batch 4/64 loss: 0.31998538970947266
Batch 5/64 loss: 0.8589339256286621
Batch 6/64 loss: 0.31401681900024414
Batch 7/64 loss: 0.22341251373291016
Batch 8/64 loss: 0.8266243934631348
Batch 9/64 loss: 0.6902561187744141
Batch 10/64 loss: 0.4931774139404297
Batch 11/64 loss: 0.5106348991394043
Batch 12/64 loss: 0.5029025077819824
Batch 13/64 loss: 0.49175214767456055
Batch 14/64 loss: 0.7106914520263672
Batch 15/64 loss: 0.46624279022216797
Batch 16/64 loss: 0.5802288055419922
Batch 17/64 loss: 0.9212369918823242
Batch 18/64 loss: 0.4038381576538086
Batch 19/64 loss: 0.4310574531555176
Batch 20/64 loss: 0.357177734375
Batch 21/64 loss: 0.9490108489990234
Batch 22/64 loss: 0.8152318000793457
Batch 23/64 loss: 0.7062997817993164
Batch 24/64 loss: 1.010000228881836
Batch 25/64 loss: 0.8109550476074219
Batch 26/64 loss: 0.6157021522521973
Batch 27/64 loss: 0.859250545501709
Batch 28/64 loss: 0.7705802917480469
Batch 29/64 loss: 0.6088647842407227
Batch 30/64 loss: 0.04020261764526367
Batch 31/64 loss: 0.5670571327209473
Batch 32/64 loss: 0.5451078414916992
Batch 33/64 loss: 0.25351524353027344
Batch 34/64 loss: 0.6909480094909668
Batch 35/64 loss: 0.5244431495666504
Batch 36/64 loss: 0.6056809425354004
Batch 37/64 loss: 0.3381376266479492
Batch 38/64 loss: 0.416043758392334
Batch 39/64 loss: 0.3440985679626465
Batch 40/64 loss: 0.5479846000671387
Batch 41/64 loss: 0.060903072357177734
Batch 42/64 loss: 0.5748372077941895
Batch 43/64 loss: 0.3628087043762207
Batch 44/64 loss: 0.020089149475097656
Batch 45/64 loss: 0.3010735511779785
Batch 46/64 loss: 1.4872822761535645
Batch 47/64 loss: 0.3742351531982422
Batch 48/64 loss: 0.4858994483947754
Batch 49/64 loss: 0.5404353141784668
Batch 50/64 loss: 0.42540454864501953
Batch 51/64 loss: 0.4055781364440918
Batch 52/64 loss: 0.5546612739562988
Batch 53/64 loss: 0.06768560409545898
Batch 54/64 loss: 0.1167001724243164
Batch 55/64 loss: 0.27167367935180664
Batch 56/64 loss: -0.11024618148803711
Batch 57/64 loss: 0.6238818168640137
Batch 58/64 loss: 0.7524285316467285
Batch 59/64 loss: 0.22525501251220703
Batch 60/64 loss: -0.11347723007202148
Batch 61/64 loss: -0.02664041519165039
Batch 62/64 loss: 0.266603946685791
Batch 63/64 loss: -0.03191184997558594
Batch 64/64 loss: -3.627065658569336
Epoch 8  Train loss: 0.44364131104712395  Val loss: 0.11962056897350193
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 0.04010725021362305
Batch 2/64 loss: 0.8199524879455566
Batch 3/64 loss: -0.0640716552734375
Batch 4/64 loss: 0.0653085708618164
Batch 5/64 loss: 0.054633140563964844
Batch 6/64 loss: 0.539980411529541
Batch 7/64 loss: 0.23961448669433594
Batch 8/64 loss: 0.10828256607055664
Batch 9/64 loss: 0.2667560577392578
Batch 10/64 loss: 0.09986066818237305
Batch 11/64 loss: 0.1775984764099121
Batch 12/64 loss: -0.1327195167541504
Batch 13/64 loss: -0.03700828552246094
Batch 14/64 loss: 0.0374302864074707
Batch 15/64 loss: -0.04156017303466797
Batch 16/64 loss: 0.12678146362304688
Batch 17/64 loss: 0.5259146690368652
Batch 18/64 loss: -0.030914306640625
Batch 19/64 loss: 0.15043354034423828
Batch 20/64 loss: 0.24543094635009766
Batch 21/64 loss: 0.17073488235473633
Batch 22/64 loss: 0.05667591094970703
Batch 23/64 loss: 0.6308565139770508
Batch 24/64 loss: 0.17648553848266602
Batch 25/64 loss: 0.249298095703125
Batch 26/64 loss: 0.45194149017333984
Batch 27/64 loss: 0.37405872344970703
Batch 28/64 loss: 0.18879127502441406
Batch 29/64 loss: 0.06099891662597656
Batch 30/64 loss: 0.25525951385498047
Batch 31/64 loss: 0.17075252532958984
Batch 32/64 loss: 0.04749870300292969
Batch 33/64 loss: 0.03631401062011719
Batch 34/64 loss: 0.518308162689209
Batch 35/64 loss: 0.4562821388244629
Batch 36/64 loss: 0.3401641845703125
Batch 37/64 loss: -0.11586141586303711
Batch 38/64 loss: 0.6898946762084961
Batch 39/64 loss: 0.39828014373779297
Batch 40/64 loss: -0.010604381561279297
Batch 41/64 loss: 0.5982465744018555
Batch 42/64 loss: 0.1565389633178711
Batch 43/64 loss: 0.03849172592163086
Batch 44/64 loss: -0.08562326431274414
Batch 45/64 loss: 0.18567991256713867
Batch 46/64 loss: -0.01247549057006836
Batch 47/64 loss: 0.359403133392334
Batch 48/64 loss: 0.11181879043579102
Batch 49/64 loss: 0.19962644577026367
Batch 50/64 loss: 0.03890419006347656
Batch 51/64 loss: -0.2537388801574707
Batch 52/64 loss: 0.39343929290771484
Batch 53/64 loss: 0.1854085922241211
Batch 54/64 loss: -0.00223541259765625
Batch 55/64 loss: -0.1270904541015625
Batch 56/64 loss: 0.1174459457397461
Batch 57/64 loss: 0.17541217803955078
Batch 58/64 loss: 0.22919225692749023
Batch 59/64 loss: 0.11209726333618164
Batch 60/64 loss: 0.0944833755493164
Batch 61/64 loss: -0.08365345001220703
Batch 62/64 loss: -0.2807149887084961
Batch 63/64 loss: 0.05918550491333008
Batch 64/64 loss: -3.763493061065674
Epoch 9  Train loss: 0.12117902905333276  Val loss: -0.09442529317849281
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: -0.06623983383178711
Batch 2/64 loss: -0.017905235290527344
Batch 3/64 loss: -0.12402629852294922
Batch 4/64 loss: 0.12627506256103516
Batch 5/64 loss: 0.04351377487182617
Batch 6/64 loss: 0.11041450500488281
Batch 7/64 loss: -0.1783161163330078
Batch 8/64 loss: -0.030941009521484375
Batch 9/64 loss: 0.26645946502685547
Batch 10/64 loss: 0.080413818359375
Batch 11/64 loss: 0.8432197570800781
Batch 12/64 loss: 0.14541339874267578
Batch 13/64 loss: -0.17321157455444336
Batch 14/64 loss: -0.19389629364013672
Batch 15/64 loss: -0.1915731430053711
Batch 16/64 loss: -0.2466869354248047
Batch 17/64 loss: -0.13420963287353516
Batch 18/64 loss: -0.4019155502319336
Batch 19/64 loss: 0.5242080688476562
Batch 20/64 loss: 0.16591739654541016
Batch 21/64 loss: 0.057861328125
Batch 22/64 loss: 0.17239665985107422
Batch 23/64 loss: 0.11268806457519531
Batch 24/64 loss: 0.1559762954711914
Batch 25/64 loss: -0.4322986602783203
Batch 26/64 loss: 0.07411956787109375
Batch 27/64 loss: 0.24766063690185547
Batch 28/64 loss: -0.1817913055419922
Batch 29/64 loss: 0.14437007904052734
Batch 30/64 loss: -0.11093616485595703
Batch 31/64 loss: 0.37134742736816406
Batch 32/64 loss: 0.15998458862304688
Batch 33/64 loss: -0.046586036682128906
Batch 34/64 loss: 0.18570327758789062
Batch 35/64 loss: 0.3967714309692383
Batch 36/64 loss: 0.9852957725524902
Batch 37/64 loss: -0.308380126953125
Batch 38/64 loss: -0.06540966033935547
Batch 39/64 loss: -0.27121925354003906
Batch 40/64 loss: -0.035286903381347656
Batch 41/64 loss: 0.2048792839050293
Batch 42/64 loss: -0.1585674285888672
Batch 43/64 loss: 0.15096426010131836
Batch 44/64 loss: -0.11816883087158203
Batch 45/64 loss: -0.08521270751953125
Batch 46/64 loss: -0.021808147430419922
Batch 47/64 loss: -0.04220008850097656
Batch 48/64 loss: -0.06460046768188477
Batch 49/64 loss: -0.1542530059814453
Batch 50/64 loss: -0.017220020294189453
Batch 51/64 loss: -0.280242919921875
Batch 52/64 loss: -0.3735055923461914
Batch 53/64 loss: 0.2914743423461914
Batch 54/64 loss: -0.06133460998535156
Batch 55/64 loss: 0.22423267364501953
Batch 56/64 loss: -0.1835489273071289
Batch 57/64 loss: -0.1795492172241211
Batch 58/64 loss: 0.31919002532958984
Batch 59/64 loss: 0.1297750473022461
Batch 60/64 loss: -0.26947689056396484
Batch 61/64 loss: -0.24220752716064453
Batch 62/64 loss: -0.030297279357910156
Batch 63/64 loss: -0.1912984848022461
Batch 64/64 loss: -3.639566421508789
Epoch 10  Train loss: -0.027034834319469975  Val loss: -0.18366904766698883
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: 0.19384288787841797
Batch 2/64 loss: -0.3090629577636719
Batch 3/64 loss: -0.020343780517578125
Batch 4/64 loss: -0.0822134017944336
Batch 5/64 loss: -0.26792144775390625
Batch 6/64 loss: -0.15246963500976562
Batch 7/64 loss: 0.07573509216308594
Batch 8/64 loss: -0.1065053939819336
Batch 9/64 loss: 0.39755916595458984
Batch 10/64 loss: 0.30341100692749023
Batch 11/64 loss: -0.12059402465820312
Batch 12/64 loss: -0.042901039123535156
Batch 13/64 loss: 0.02248525619506836
Batch 14/64 loss: -0.25833797454833984
Batch 15/64 loss: 0.22057342529296875
Batch 16/64 loss: -0.2574882507324219
Batch 17/64 loss: -0.4454212188720703
Batch 18/64 loss: -0.1729745864868164
Batch 19/64 loss: -0.2254471778869629
Batch 20/64 loss: 0.15405654907226562
Batch 21/64 loss: -0.268951416015625
Batch 22/64 loss: -0.020189285278320312
Batch 23/64 loss: -0.058035850524902344
Batch 24/64 loss: -0.27779197692871094
Batch 25/64 loss: -0.4153766632080078
Batch 26/64 loss: -0.34058380126953125
Batch 27/64 loss: -0.2310638427734375
Batch 28/64 loss: -0.306424617767334
Batch 29/64 loss: -0.07523059844970703
Batch 30/64 loss: -0.08981513977050781
Batch 31/64 loss: -0.23575878143310547
Batch 32/64 loss: 0.11628437042236328
Batch 33/64 loss: -0.017749786376953125
Batch 34/64 loss: -0.03729057312011719
Batch 35/64 loss: -0.30531978607177734
Batch 36/64 loss: 0.0025348663330078125
Batch 37/64 loss: 0.005367279052734375
Batch 38/64 loss: -0.0882730484008789
Batch 39/64 loss: -0.36554813385009766
Batch 40/64 loss: 0.05256080627441406
Batch 41/64 loss: 0.10822391510009766
Batch 42/64 loss: -0.3240385055541992
Batch 43/64 loss: -0.06914043426513672
Batch 44/64 loss: -0.06156444549560547
Batch 45/64 loss: -0.2696800231933594
Batch 46/64 loss: -0.23668289184570312
Batch 47/64 loss: 0.0496363639831543
Batch 48/64 loss: -0.14711570739746094
Batch 49/64 loss: -0.22571849822998047
Batch 50/64 loss: -0.22918033599853516
Batch 51/64 loss: 0.20025873184204102
Batch 52/64 loss: 0.25626277923583984
Batch 53/64 loss: 0.31490039825439453
Batch 54/64 loss: -0.17403125762939453
Batch 55/64 loss: -0.3254985809326172
Batch 56/64 loss: -0.3625679016113281
Batch 57/64 loss: 0.2777099609375
Batch 58/64 loss: 0.10525035858154297
Batch 59/64 loss: -0.35784435272216797
Batch 60/64 loss: 0.3516674041748047
Batch 61/64 loss: -0.4563407897949219
Batch 62/64 loss: -0.4344472885131836
Batch 63/64 loss: -0.07609081268310547
Batch 64/64 loss: -4.30233907699585
Epoch 11  Train loss: -0.1468777993146111  Val loss: -0.17724386523269706
Epoch 12
-------------------------------
Batch 1/64 loss: 0.035744667053222656
Batch 2/64 loss: 0.11511611938476562
Batch 3/64 loss: -0.07672691345214844
Batch 4/64 loss: -0.570277214050293
Batch 5/64 loss: 0.04427051544189453
Batch 6/64 loss: 0.2889270782470703
Batch 7/64 loss: -0.3518953323364258
Batch 8/64 loss: 0.15242576599121094
Batch 9/64 loss: -0.17800617218017578
Batch 10/64 loss: 0.020409584045410156
Batch 11/64 loss: -0.4441385269165039
Batch 12/64 loss: -0.11610603332519531
Batch 13/64 loss: -0.15975666046142578
Batch 14/64 loss: 0.38691234588623047
Batch 15/64 loss: 0.07021903991699219
Batch 16/64 loss: -0.34913158416748047
Batch 17/64 loss: -0.15524673461914062
Batch 18/64 loss: -0.2751760482788086
Batch 19/64 loss: -0.0391387939453125
Batch 20/64 loss: -0.742645263671875
Batch 21/64 loss: -0.21006202697753906
Batch 22/64 loss: -0.22974491119384766
Batch 23/64 loss: 0.39456748962402344
Batch 24/64 loss: -0.5573549270629883
Batch 25/64 loss: -0.08687400817871094
Batch 26/64 loss: -0.14567852020263672
Batch 27/64 loss: -0.3674583435058594
Batch 28/64 loss: 0.1113138198852539
Batch 29/64 loss: -0.3208932876586914
Batch 30/64 loss: -0.03854656219482422
Batch 31/64 loss: 0.6401796340942383
Batch 32/64 loss: -0.06815242767333984
Batch 33/64 loss: 0.06663131713867188
Batch 34/64 loss: -0.36323070526123047
Batch 35/64 loss: -0.04920482635498047
Batch 36/64 loss: -0.4421577453613281
Batch 37/64 loss: -0.31526660919189453
Batch 38/64 loss: 0.10007047653198242
Batch 39/64 loss: -0.3825645446777344
Batch 40/64 loss: -0.03368091583251953
Batch 41/64 loss: -0.5251445770263672
Batch 42/64 loss: -0.3444862365722656
Batch 43/64 loss: -0.5738744735717773
Batch 44/64 loss: -0.3792409896850586
Batch 45/64 loss: 0.06568527221679688
Batch 46/64 loss: -0.5188608169555664
Batch 47/64 loss: 0.020829200744628906
Batch 48/64 loss: -0.2349853515625
Batch 49/64 loss: -0.017208099365234375
Batch 50/64 loss: -0.11530017852783203
Batch 51/64 loss: -0.216705322265625
Batch 52/64 loss: -0.26639556884765625
Batch 53/64 loss: -0.3188915252685547
Batch 54/64 loss: -0.24569416046142578
Batch 55/64 loss: -0.37125301361083984
Batch 56/64 loss: -0.7795867919921875
Batch 57/64 loss: -0.18665218353271484
Batch 58/64 loss: -0.2823009490966797
Batch 59/64 loss: 0.05372428894042969
Batch 60/64 loss: 0.2371692657470703
Batch 61/64 loss: -0.1642017364501953
Batch 62/64 loss: -0.3548870086669922
Batch 63/64 loss: -0.14415645599365234
Batch 64/64 loss: -3.946483612060547
Epoch 12  Train loss: -0.20807228088378907  Val loss: -0.2109060647971032
Saving best model, epoch: 12
Epoch 13
-------------------------------
Batch 1/64 loss: -0.5638570785522461
Batch 2/64 loss: 0.015726089477539062
Batch 3/64 loss: -0.38776302337646484
Batch 4/64 loss: -0.2614908218383789
Batch 5/64 loss: -0.2935819625854492
Batch 6/64 loss: -0.41977405548095703
Batch 7/64 loss: -0.09039020538330078
Batch 8/64 loss: -0.3621253967285156
Batch 9/64 loss: -0.28725624084472656
Batch 10/64 loss: -0.1959857940673828
Batch 11/64 loss: -0.18732357025146484
Batch 12/64 loss: 0.10773468017578125
Batch 13/64 loss: -0.03059673309326172
Batch 14/64 loss: -0.24007701873779297
Batch 15/64 loss: 0.4584646224975586
Batch 16/64 loss: -0.4882698059082031
Batch 17/64 loss: -0.2757911682128906
Batch 18/64 loss: -0.7001581192016602
Batch 19/64 loss: -0.4870567321777344
Batch 20/64 loss: -0.4471778869628906
Batch 21/64 loss: -0.4938068389892578
Batch 22/64 loss: -0.4409065246582031
Batch 23/64 loss: -0.17834949493408203
Batch 24/64 loss: -0.3744964599609375
Batch 25/64 loss: 0.07871627807617188
Batch 26/64 loss: -0.6397581100463867
Batch 27/64 loss: -0.568455696105957
Batch 28/64 loss: -0.4358024597167969
Batch 29/64 loss: -0.30221080780029297
Batch 30/64 loss: -0.5392265319824219
Batch 31/64 loss: 0.38216686248779297
Batch 32/64 loss: 0.7516584396362305
Batch 33/64 loss: -0.26772308349609375
Batch 34/64 loss: -0.4678020477294922
Batch 35/64 loss: 0.11443519592285156
Batch 36/64 loss: -0.15301799774169922
Batch 37/64 loss: -0.09938716888427734
Batch 38/64 loss: -0.2631568908691406
Batch 39/64 loss: -0.24451637268066406
Batch 40/64 loss: 0.1859598159790039
Batch 41/64 loss: -0.41994380950927734
Batch 42/64 loss: 0.3551473617553711
Batch 43/64 loss: -0.24160194396972656
Batch 44/64 loss: 0.09264850616455078
Batch 45/64 loss: -0.05148506164550781
Batch 46/64 loss: 0.13314151763916016
Batch 47/64 loss: -0.27666187286376953
Batch 48/64 loss: -0.11623191833496094
Batch 49/64 loss: -0.030076980590820312
Batch 50/64 loss: 0.0999917984008789
Batch 51/64 loss: -0.09719467163085938
Batch 52/64 loss: -0.31945228576660156
Batch 53/64 loss: -0.21254634857177734
Batch 54/64 loss: -0.5351800918579102
Batch 55/64 loss: -0.3565702438354492
Batch 56/64 loss: -0.0751810073852539
Batch 57/64 loss: -0.2309579849243164
Batch 58/64 loss: -0.19823551177978516
Batch 59/64 loss: 0.066986083984375
Batch 60/64 loss: -0.5604476928710938
Batch 61/64 loss: -0.45000743865966797
Batch 62/64 loss: 0.025762557983398438
Batch 63/64 loss: -0.0961923599243164
Batch 64/64 loss: -4.619380474090576
Epoch 13  Train loss: -0.2517843900942335  Val loss: -0.0197230729040821
Epoch 14
-------------------------------
Batch 1/64 loss: 0.08916664123535156
Batch 2/64 loss: -0.7256574630737305
Batch 3/64 loss: -0.16473102569580078
Batch 4/64 loss: 0.004444122314453125
Batch 5/64 loss: 0.03345298767089844
Batch 6/64 loss: -0.1371469497680664
Batch 7/64 loss: -0.24626827239990234
Batch 8/64 loss: -0.4114532470703125
Batch 9/64 loss: -0.2911806106567383
Batch 10/64 loss: -0.06314945220947266
Batch 11/64 loss: -0.08443355560302734
Batch 12/64 loss: -0.11394786834716797
Batch 13/64 loss: -0.20131492614746094
Batch 14/64 loss: -0.5200586318969727
Batch 15/64 loss: -0.17685985565185547
Batch 16/64 loss: -0.22320175170898438
Batch 17/64 loss: -0.5367918014526367
Batch 18/64 loss: -0.22640609741210938
Batch 19/64 loss: -0.1871166229248047
Batch 20/64 loss: -0.3721342086791992
Batch 21/64 loss: -0.07590103149414062
Batch 22/64 loss: -0.6896486282348633
Batch 23/64 loss: -0.22157955169677734
Batch 24/64 loss: -0.2462472915649414
Batch 25/64 loss: -0.3104429244995117
Batch 26/64 loss: -0.33572864532470703
Batch 27/64 loss: -0.41186046600341797
Batch 28/64 loss: -0.2758064270019531
Batch 29/64 loss: -0.4960479736328125
Batch 30/64 loss: -0.5011081695556641
Batch 31/64 loss: 0.16739463806152344
Batch 32/64 loss: -0.4521656036376953
Batch 33/64 loss: -0.34230995178222656
Batch 34/64 loss: 0.03796195983886719
Batch 35/64 loss: -0.5352096557617188
Batch 36/64 loss: -0.21056652069091797
Batch 37/64 loss: -0.2447185516357422
Batch 38/64 loss: -0.5308094024658203
Batch 39/64 loss: -0.5559244155883789
Batch 40/64 loss: 0.037590980529785156
Batch 41/64 loss: -0.2831544876098633
Batch 42/64 loss: -0.4839134216308594
Batch 43/64 loss: -0.32295989990234375
Batch 44/64 loss: -0.8923788070678711
Batch 45/64 loss: -0.31526947021484375
Batch 46/64 loss: -0.28232860565185547
Batch 47/64 loss: -0.6765146255493164
Batch 48/64 loss: -0.2660055160522461
Batch 49/64 loss: -0.6299610137939453
Batch 50/64 loss: -0.014486312866210938
Batch 51/64 loss: 0.1566009521484375
Batch 52/64 loss: -0.12617969512939453
Batch 53/64 loss: -0.3921375274658203
Batch 54/64 loss: -0.17441082000732422
Batch 55/64 loss: -0.4858055114746094
Batch 56/64 loss: -0.3776741027832031
Batch 57/64 loss: -0.12926483154296875
Batch 58/64 loss: 0.09257698059082031
Batch 59/64 loss: -0.36348485946655273
Batch 60/64 loss: -0.3259119987487793
Batch 61/64 loss: -0.3641805648803711
Batch 62/64 loss: -0.38176918029785156
Batch 63/64 loss: -0.19336891174316406
Batch 64/64 loss: -4.091256141662598
Epoch 14  Train loss: -0.33017004798440375  Val loss: -0.4558744397769679
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: -0.2448596954345703
Batch 2/64 loss: 0.02869415283203125
Batch 3/64 loss: -0.3701610565185547
Batch 4/64 loss: -0.6433076858520508
Batch 5/64 loss: -0.36026477813720703
Batch 6/64 loss: -0.4730243682861328
Batch 7/64 loss: -0.23759078979492188
Batch 8/64 loss: -0.6588888168334961
Batch 9/64 loss: -0.37300968170166016
Batch 10/64 loss: -0.3400135040283203
Batch 11/64 loss: -0.7690467834472656
Batch 12/64 loss: -0.4440269470214844
Batch 13/64 loss: -0.1422595977783203
Batch 14/64 loss: -0.4015665054321289
Batch 15/64 loss: -0.5497217178344727
Batch 16/64 loss: -0.6258268356323242
Batch 17/64 loss: -0.5014333724975586
Batch 18/64 loss: -0.6077718734741211
Batch 19/64 loss: 0.12635087966918945
Batch 20/64 loss: -0.7810602188110352
Batch 21/64 loss: -0.4640617370605469
Batch 22/64 loss: -0.06587409973144531
Batch 23/64 loss: -0.06833839416503906
Batch 24/64 loss: -0.5091943740844727
Batch 25/64 loss: -0.6160335540771484
Batch 26/64 loss: -0.8183441162109375
Batch 27/64 loss: -0.2657499313354492
Batch 28/64 loss: -0.42727184295654297
Batch 29/64 loss: -0.44783496856689453
Batch 30/64 loss: -0.7092266082763672
Batch 31/64 loss: -0.6942834854125977
Batch 32/64 loss: -0.8345422744750977
Batch 33/64 loss: -0.8270988464355469
Batch 34/64 loss: -0.5533571243286133
Batch 35/64 loss: -0.16492843627929688
Batch 36/64 loss: -0.6378250122070312
Batch 37/64 loss: -0.4835987091064453
Batch 38/64 loss: 0.012865066528320312
Batch 39/64 loss: -0.670680046081543
Batch 40/64 loss: -0.5529975891113281
Batch 41/64 loss: 0.2078571319580078
Batch 42/64 loss: -0.38794803619384766
Batch 43/64 loss: -0.11116313934326172
Batch 44/64 loss: -0.592432975769043
Batch 45/64 loss: -0.5899686813354492
Batch 46/64 loss: -0.10153388977050781
Batch 47/64 loss: -0.2776451110839844
Batch 48/64 loss: -0.6568927764892578
Batch 49/64 loss: -0.4500703811645508
Batch 50/64 loss: -0.6815214157104492
Batch 51/64 loss: -0.654942512512207
Batch 52/64 loss: -0.21069049835205078
Batch 53/64 loss: -0.27756786346435547
Batch 54/64 loss: -0.4755973815917969
Batch 55/64 loss: -0.48447704315185547
Batch 56/64 loss: -0.5885658264160156
Batch 57/64 loss: -0.4316902160644531
Batch 58/64 loss: -0.7221460342407227
Batch 59/64 loss: -0.38500308990478516
Batch 60/64 loss: -0.6711235046386719
Batch 61/64 loss: -0.8010053634643555
Batch 62/64 loss: -0.5391998291015625
Batch 63/64 loss: -0.5233955383300781
Batch 64/64 loss: -4.607952117919922
Epoch 15  Train loss: -0.5024290720621745  Val loss: -0.4766526762972173
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: -0.4090843200683594
Batch 2/64 loss: -0.8505420684814453
Batch 3/64 loss: -0.5342941284179688
Batch 4/64 loss: -0.7011613845825195
Batch 5/64 loss: -0.35578060150146484
Batch 6/64 loss: -0.3522500991821289
Batch 7/64 loss: -0.5181303024291992
Batch 8/64 loss: -0.39972782135009766
Batch 9/64 loss: -0.6161031723022461
Batch 10/64 loss: -0.3012371063232422
Batch 11/64 loss: -0.6882057189941406
Batch 12/64 loss: -0.4279317855834961
Batch 13/64 loss: -0.3689689636230469
Batch 14/64 loss: -0.5127410888671875
Batch 15/64 loss: -0.6000823974609375
Batch 16/64 loss: -0.4166440963745117
Batch 17/64 loss: -0.47716808319091797
Batch 18/64 loss: -0.42787933349609375
Batch 19/64 loss: 0.009063720703125
Batch 20/64 loss: -0.7790279388427734
Batch 21/64 loss: -0.5223503112792969
Batch 22/64 loss: -0.4701347351074219
Batch 23/64 loss: -0.9204425811767578
Batch 24/64 loss: -0.28564453125
Batch 25/64 loss: -0.40888023376464844
Batch 26/64 loss: -0.8048343658447266
Batch 27/64 loss: -0.650813102722168
Batch 28/64 loss: -0.8943214416503906
Batch 29/64 loss: -0.5237522125244141
Batch 30/64 loss: -0.3171100616455078
Batch 31/64 loss: -0.31696414947509766
Batch 32/64 loss: -0.044785499572753906
Batch 33/64 loss: -0.8635025024414062
Batch 34/64 loss: -0.7433156967163086
Batch 35/64 loss: -0.06519603729248047
Batch 36/64 loss: -0.5403938293457031
Batch 37/64 loss: -0.14001846313476562
Batch 38/64 loss: -0.4316892623901367
Batch 39/64 loss: -0.3388347625732422
Batch 40/64 loss: -0.41301918029785156
Batch 41/64 loss: -0.5327167510986328
Batch 42/64 loss: -0.11130428314208984
Batch 43/64 loss: -0.3968009948730469
Batch 44/64 loss: -0.5266733169555664
Batch 45/64 loss: -0.2491006851196289
Batch 46/64 loss: -0.47090721130371094
Batch 47/64 loss: -0.4714374542236328
Batch 48/64 loss: -0.5757656097412109
Batch 49/64 loss: -0.07814598083496094
Batch 50/64 loss: -0.5817937850952148
Batch 51/64 loss: -0.39623451232910156
Batch 52/64 loss: -0.3730001449584961
Batch 53/64 loss: -0.6142492294311523
Batch 54/64 loss: -0.7262763977050781
Batch 55/64 loss: -0.4761066436767578
Batch 56/64 loss: -0.37410545349121094
Batch 57/64 loss: -0.35181713104248047
Batch 58/64 loss: -0.49500179290771484
Batch 59/64 loss: -0.4795246124267578
Batch 60/64 loss: -0.44823551177978516
Batch 61/64 loss: -0.8608331680297852
Batch 62/64 loss: -0.5421628952026367
Batch 63/64 loss: -0.4031496047973633
Batch 64/64 loss: -3.6543312072753906
Epoch 16  Train loss: -0.5129410388422947  Val loss: -0.35278263944121163
Epoch 17
-------------------------------
Batch 1/64 loss: 0.11156558990478516
Batch 2/64 loss: -0.501927375793457
Batch 3/64 loss: -0.6319379806518555
Batch 4/64 loss: -0.2661571502685547
Batch 5/64 loss: -0.6343421936035156
Batch 6/64 loss: -0.49911022186279297
Batch 7/64 loss: -0.2605266571044922
Batch 8/64 loss: 0.00403594970703125
Batch 9/64 loss: -0.26499366760253906
Batch 10/64 loss: -0.28635215759277344
Batch 11/64 loss: -0.24942493438720703
Batch 12/64 loss: -0.6112575531005859
Batch 13/64 loss: -0.5283946990966797
Batch 14/64 loss: -0.4011507034301758
Batch 15/64 loss: -0.2572202682495117
Batch 16/64 loss: -0.18941497802734375
Batch 17/64 loss: -0.6479501724243164
Batch 18/64 loss: -0.24443531036376953
Batch 19/64 loss: -0.017905235290527344
Batch 20/64 loss: -0.25293922424316406
Batch 21/64 loss: -0.3286275863647461
Batch 22/64 loss: -0.6737070083618164
Batch 23/64 loss: -0.313140869140625
Batch 24/64 loss: -0.6563386917114258
Batch 25/64 loss: -0.7820796966552734
Batch 26/64 loss: -0.4376106262207031
Batch 27/64 loss: -0.37868499755859375
Batch 28/64 loss: -0.6014127731323242
Batch 29/64 loss: -0.4144277572631836
Batch 30/64 loss: -0.6300725936889648
Batch 31/64 loss: -0.5869054794311523
Batch 32/64 loss: -0.6602020263671875
Batch 33/64 loss: -0.44499874114990234
Batch 34/64 loss: -0.7034797668457031
Batch 35/64 loss: -0.3581533432006836
Batch 36/64 loss: -0.329864501953125
Batch 37/64 loss: -0.5670528411865234
Batch 38/64 loss: -0.17757606506347656
Batch 39/64 loss: -0.11344623565673828
Batch 40/64 loss: -0.3358325958251953
Batch 41/64 loss: -0.592864990234375
Batch 42/64 loss: -0.6812868118286133
Batch 43/64 loss: 0.22837066650390625
Batch 44/64 loss: -0.56787109375
Batch 45/64 loss: -0.40554141998291016
Batch 46/64 loss: -0.6487579345703125
Batch 47/64 loss: -0.839472770690918
Batch 48/64 loss: -0.7339382171630859
Batch 49/64 loss: -0.4736604690551758
Batch 50/64 loss: -0.4012737274169922
Batch 51/64 loss: -0.8272762298583984
Batch 52/64 loss: -0.29711437225341797
Batch 53/64 loss: -0.3572559356689453
Batch 54/64 loss: -0.3375835418701172
Batch 55/64 loss: -0.4170341491699219
Batch 56/64 loss: -0.5850305557250977
Batch 57/64 loss: -0.7013654708862305
Batch 58/64 loss: -0.5929288864135742
Batch 59/64 loss: -0.9217958450317383
Batch 60/64 loss: -0.6783294677734375
Batch 61/64 loss: -0.20280075073242188
Batch 62/64 loss: -0.6639823913574219
Batch 63/64 loss: -0.6567621231079102
Batch 64/64 loss: -4.716208457946777
Epoch 17  Train loss: -0.5022143681844076  Val loss: -0.7355468723782149
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: -0.4143962860107422
Batch 2/64 loss: -0.29985523223876953
Batch 3/64 loss: -0.719660758972168
Batch 4/64 loss: -0.6460151672363281
Batch 5/64 loss: -0.7476863861083984
Batch 6/64 loss: -0.72430419921875
Batch 7/64 loss: -0.7818851470947266
Batch 8/64 loss: -0.24979496002197266
Batch 9/64 loss: -0.8988437652587891
Batch 10/64 loss: -0.5323972702026367
Batch 11/64 loss: -0.8626689910888672
Batch 12/64 loss: -0.5743656158447266
Batch 13/64 loss: -0.4658803939819336
Batch 14/64 loss: -0.6347894668579102
Batch 15/64 loss: -0.8421344757080078
Batch 16/64 loss: -0.38889217376708984
Batch 17/64 loss: -0.5607414245605469
Batch 18/64 loss: -0.832371711730957
Batch 19/64 loss: -0.4643287658691406
Batch 20/64 loss: -0.9040708541870117
Batch 21/64 loss: -0.8625345230102539
Batch 22/64 loss: -0.6957111358642578
Batch 23/64 loss: -0.71795654296875
Batch 24/64 loss: -0.6855335235595703
Batch 25/64 loss: -0.2775888442993164
Batch 26/64 loss: -0.8848247528076172
Batch 27/64 loss: -0.4434232711791992
Batch 28/64 loss: -0.6518878936767578
Batch 29/64 loss: -0.6098260879516602
Batch 30/64 loss: 0.24816322326660156
Batch 31/64 loss: -0.46173763275146484
Batch 32/64 loss: -0.5564727783203125
Batch 33/64 loss: -0.048130035400390625
Batch 34/64 loss: -0.6238307952880859
Batch 35/64 loss: -0.6730661392211914
Batch 36/64 loss: -0.8042469024658203
Batch 37/64 loss: -0.6418466567993164
Batch 38/64 loss: -0.6535520553588867
Batch 39/64 loss: -0.7064733505249023
Batch 40/64 loss: -0.5724334716796875
Batch 41/64 loss: -0.5170927047729492
Batch 42/64 loss: -0.546849250793457
Batch 43/64 loss: -0.7623958587646484
Batch 44/64 loss: -0.4086160659790039
Batch 45/64 loss: -0.8163061141967773
Batch 46/64 loss: -0.8179512023925781
Batch 47/64 loss: -1.0403165817260742
Batch 48/64 loss: -0.7230100631713867
Batch 49/64 loss: -0.7033939361572266
Batch 50/64 loss: -0.5357761383056641
Batch 51/64 loss: -0.40026187896728516
Batch 52/64 loss: -0.6159830093383789
Batch 53/64 loss: -0.5417079925537109
Batch 54/64 loss: -0.7587747573852539
Batch 55/64 loss: -0.8822708129882812
Batch 56/64 loss: -0.13080120086669922
Batch 57/64 loss: -0.655517578125
Batch 58/64 loss: -0.9022302627563477
Batch 59/64 loss: -0.6592912673950195
Batch 60/64 loss: -0.7930383682250977
Batch 61/64 loss: -0.46149253845214844
Batch 62/64 loss: -0.6104040145874023
Batch 63/64 loss: -0.7298974990844727
Batch 64/64 loss: -4.102653503417969
Epoch 18  Train loss: -0.6581704382802925  Val loss: -0.6618213981287586
Epoch 19
-------------------------------
Batch 1/64 loss: 0.09962272644042969
Batch 2/64 loss: -0.5387554168701172
Batch 3/64 loss: -0.9138689041137695
Batch 4/64 loss: -0.3847169876098633
Batch 5/64 loss: -0.44520092010498047
Batch 6/64 loss: -0.27927494049072266
Batch 7/64 loss: -0.8003969192504883
Batch 8/64 loss: -0.8452053070068359
Batch 9/64 loss: -0.8929986953735352
Batch 10/64 loss: -0.8024511337280273
Batch 11/64 loss: -0.43470001220703125
Batch 12/64 loss: -0.6979913711547852
Batch 13/64 loss: -0.9695339202880859
Batch 14/64 loss: -0.20771026611328125
Batch 15/64 loss: -0.8869199752807617
Batch 16/64 loss: -0.8415546417236328
Batch 17/64 loss: -0.5566387176513672
Batch 18/64 loss: -0.8967838287353516
Batch 19/64 loss: -0.6628866195678711
Batch 20/64 loss: -0.5585870742797852
Batch 21/64 loss: -0.4169149398803711
Batch 22/64 loss: -0.2697114944458008
Batch 23/64 loss: -0.3883495330810547
Batch 24/64 loss: -0.9213504791259766
Batch 25/64 loss: -0.6896820068359375
Batch 26/64 loss: -0.54425048828125
Batch 27/64 loss: -0.7689552307128906
Batch 28/64 loss: -0.15674543380737305
Batch 29/64 loss: -0.718592643737793
Batch 30/64 loss: -0.5543422698974609
Batch 31/64 loss: -0.7147293090820312
Batch 32/64 loss: -0.7098245620727539
Batch 33/64 loss: -0.8998632431030273
Batch 34/64 loss: -0.9694929122924805
Batch 35/64 loss: -0.5420036315917969
Batch 36/64 loss: -0.6961221694946289
Batch 37/64 loss: -0.5995512008666992
Batch 38/64 loss: -0.8491945266723633
Batch 39/64 loss: -0.6434803009033203
Batch 40/64 loss: -0.7092456817626953
Batch 41/64 loss: -0.26136302947998047
Batch 42/64 loss: -0.9353675842285156
Batch 43/64 loss: -0.625239372253418
Batch 44/64 loss: -0.3809623718261719
Batch 45/64 loss: -0.5896902084350586
Batch 46/64 loss: -0.9764080047607422
Batch 47/64 loss: -0.9916248321533203
Batch 48/64 loss: -0.7967700958251953
Batch 49/64 loss: -0.8181400299072266
Batch 50/64 loss: -0.8067722320556641
Batch 51/64 loss: -1.0152168273925781
Batch 52/64 loss: -0.9666814804077148
Batch 53/64 loss: -0.3981161117553711
Batch 54/64 loss: -0.4394207000732422
Batch 55/64 loss: -0.7029542922973633
Batch 56/64 loss: -0.7173213958740234
Batch 57/64 loss: -0.6416759490966797
Batch 58/64 loss: -0.6737861633300781
Batch 59/64 loss: -0.2494029998779297
Batch 60/64 loss: -0.6786413192749023
Batch 61/64 loss: -0.7374658584594727
Batch 62/64 loss: -0.1571207046508789
Batch 63/64 loss: -0.7821559906005859
Batch 64/64 loss: -4.741518020629883
Epoch 19  Train loss: -0.6929786831724878  Val loss: -0.9143783202286029
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: -0.9104909896850586
Batch 2/64 loss: -0.7724676132202148
Batch 3/64 loss: -0.6887712478637695
Batch 4/64 loss: -0.792262077331543
Batch 5/64 loss: -0.30141353607177734
Batch 6/64 loss: -0.5491218566894531
Batch 7/64 loss: -0.9144668579101562
Batch 8/64 loss: -0.802638053894043
Batch 9/64 loss: -0.13368701934814453
Batch 10/64 loss: -0.8906288146972656
Batch 11/64 loss: -0.6491127014160156
Batch 12/64 loss: -0.6352624893188477
Batch 13/64 loss: -1.079324722290039
Batch 14/64 loss: -0.576751708984375
Batch 15/64 loss: -0.8801479339599609
Batch 16/64 loss: -0.8330917358398438
Batch 17/64 loss: -0.580296516418457
Batch 18/64 loss: -0.4325113296508789
Batch 19/64 loss: -0.5358610153198242
Batch 20/64 loss: -0.7471227645874023
Batch 21/64 loss: -0.9506387710571289
Batch 22/64 loss: -0.7884988784790039
Batch 23/64 loss: -0.1995372772216797
Batch 24/64 loss: -0.7250232696533203
Batch 25/64 loss: -0.7374763488769531
Batch 26/64 loss: -0.33671092987060547
Batch 27/64 loss: -0.41178035736083984
Batch 28/64 loss: -0.8719549179077148
Batch 29/64 loss: -0.6845359802246094
Batch 30/64 loss: -0.9238996505737305
Batch 31/64 loss: -0.5443296432495117
Batch 32/64 loss: -0.9413738250732422
Batch 33/64 loss: -0.6935768127441406
Batch 34/64 loss: -0.5782203674316406
Batch 35/64 loss: -0.678462028503418
Batch 36/64 loss: -0.7143802642822266
Batch 37/64 loss: -0.28095245361328125
Batch 38/64 loss: -0.3489847183227539
Batch 39/64 loss: -0.15060043334960938
Batch 40/64 loss: -0.7958536148071289
Batch 41/64 loss: -0.9191808700561523
Batch 42/64 loss: -0.7189064025878906
Batch 43/64 loss: -0.5678510665893555
Batch 44/64 loss: -0.7661819458007812
Batch 45/64 loss: -0.5971298217773438
Batch 46/64 loss: -0.6653470993041992
Batch 47/64 loss: -0.7705297470092773
Batch 48/64 loss: -1.0457878112792969
Batch 49/64 loss: -0.6145353317260742
Batch 50/64 loss: -0.5914230346679688
Batch 51/64 loss: -0.7156600952148438
Batch 52/64 loss: -0.5731163024902344
Batch 53/64 loss: -0.9041385650634766
Batch 54/64 loss: -0.5252676010131836
Batch 55/64 loss: -0.6999921798706055
Batch 56/64 loss: -0.47898387908935547
Batch 57/64 loss: -0.796299934387207
Batch 58/64 loss: -0.6782655715942383
Batch 59/64 loss: -0.528778076171875
Batch 60/64 loss: -0.804081916809082
Batch 61/64 loss: -0.7503900527954102
Batch 62/64 loss: -0.49008941650390625
Batch 63/64 loss: -0.7429895401000977
Batch 64/64 loss: -4.7103142738342285
Epoch 20  Train loss: -0.7143511136372884  Val loss: -0.35030906388849736
Epoch 21
-------------------------------
Batch 1/64 loss: -0.36055946350097656
Batch 2/64 loss: -0.4483976364135742
Batch 3/64 loss: -0.4106006622314453
Batch 4/64 loss: -1.0378189086914062
Batch 5/64 loss: -1.1226768493652344
Batch 6/64 loss: -0.4879741668701172
Batch 7/64 loss: -0.6035976409912109
Batch 8/64 loss: -0.8753499984741211
Batch 9/64 loss: -0.7675352096557617
Batch 10/64 loss: -0.7531423568725586
Batch 11/64 loss: -0.8120441436767578
Batch 12/64 loss: -0.896209716796875
Batch 13/64 loss: -0.6148834228515625
Batch 14/64 loss: -1.1082210540771484
Batch 15/64 loss: -0.7380447387695312
Batch 16/64 loss: -0.6457805633544922
Batch 17/64 loss: -0.31133556365966797
Batch 18/64 loss: -0.7368888854980469
Batch 19/64 loss: -0.8467330932617188
Batch 20/64 loss: -0.32231807708740234
Batch 21/64 loss: -0.44768428802490234
Batch 22/64 loss: -0.5292625427246094
Batch 23/64 loss: -0.7236118316650391
Batch 24/64 loss: -0.5258359909057617
Batch 25/64 loss: -0.3899650573730469
Batch 26/64 loss: -0.9876213073730469
Batch 27/64 loss: -0.6916999816894531
Batch 28/64 loss: -0.8957557678222656
Batch 29/64 loss: -1.0679807662963867
Batch 30/64 loss: -0.6555690765380859
Batch 31/64 loss: -0.7942075729370117
Batch 32/64 loss: -0.9578533172607422
Batch 33/64 loss: -0.8788785934448242
Batch 34/64 loss: -0.8173856735229492
Batch 35/64 loss: -0.9535999298095703
Batch 36/64 loss: -0.9588384628295898
Batch 37/64 loss: -0.9182682037353516
Batch 38/64 loss: -0.8371944427490234
Batch 39/64 loss: -0.5022487640380859
Batch 40/64 loss: -1.1112489700317383
Batch 41/64 loss: -0.39895153045654297
Batch 42/64 loss: -0.45386219024658203
Batch 43/64 loss: -0.7311534881591797
Batch 44/64 loss: -0.7413558959960938
Batch 45/64 loss: -0.7964887619018555
Batch 46/64 loss: -0.9714479446411133
Batch 47/64 loss: -0.33866119384765625
Batch 48/64 loss: -0.6052446365356445
Batch 49/64 loss: -0.36548805236816406
Batch 50/64 loss: -0.7686729431152344
Batch 51/64 loss: -0.8056697845458984
Batch 52/64 loss: -0.3878164291381836
Batch 53/64 loss: -0.42208099365234375
Batch 54/64 loss: -0.9413928985595703
Batch 55/64 loss: -1.041398048400879
Batch 56/64 loss: -0.9497261047363281
Batch 57/64 loss: -0.35675048828125
Batch 58/64 loss: -0.6138210296630859
Batch 59/64 loss: -0.5283670425415039
Batch 60/64 loss: -0.5370540618896484
Batch 61/64 loss: -1.0787839889526367
Batch 62/64 loss: -0.7295370101928711
Batch 63/64 loss: -0.9594631195068359
Batch 64/64 loss: -4.9599080085754395
Epoch 21  Train loss: -0.7653010405746161  Val loss: -0.5848472306818487
Epoch 22
-------------------------------
Batch 1/64 loss: -0.694061279296875
Batch 2/64 loss: -0.8769607543945312
Batch 3/64 loss: -0.5531072616577148
Batch 4/64 loss: -0.6119813919067383
Batch 5/64 loss: -0.6903629302978516
Batch 6/64 loss: -0.6901559829711914
Batch 7/64 loss: -0.9171466827392578
Batch 8/64 loss: -0.5866594314575195
Batch 9/64 loss: -0.5918598175048828
Batch 10/64 loss: 0.1092233657836914
Batch 11/64 loss: -0.7830781936645508
Batch 12/64 loss: -0.7840900421142578
Batch 13/64 loss: -0.17525768280029297
Batch 14/64 loss: -0.4685859680175781
Batch 15/64 loss: -0.6846885681152344
Batch 16/64 loss: -0.6462259292602539
Batch 17/64 loss: -0.8471231460571289
Batch 18/64 loss: -0.83001708984375
Batch 19/64 loss: -0.7312307357788086
Batch 20/64 loss: -0.7328052520751953
Batch 21/64 loss: 0.060761451721191406
Batch 22/64 loss: -0.47415733337402344
Batch 23/64 loss: -0.7998371124267578
Batch 24/64 loss: -0.4573812484741211
Batch 25/64 loss: -0.6836862564086914
Batch 26/64 loss: -0.5601825714111328
Batch 27/64 loss: -0.7257413864135742
Batch 28/64 loss: -0.9272451400756836
Batch 29/64 loss: -0.7284832000732422
Batch 30/64 loss: -0.7379913330078125
Batch 31/64 loss: -0.8419046401977539
Batch 32/64 loss: -0.22468280792236328
Batch 33/64 loss: -0.7782564163208008
Batch 34/64 loss: -0.8825302124023438
Batch 35/64 loss: -0.8682765960693359
Batch 36/64 loss: -0.9105472564697266
Batch 37/64 loss: -0.07257461547851562
Batch 38/64 loss: -0.7396163940429688
Batch 39/64 loss: -0.8990764617919922
Batch 40/64 loss: -0.8640556335449219
Batch 41/64 loss: -0.1495199203491211
Batch 42/64 loss: -0.852869987487793
Batch 43/64 loss: -0.3029470443725586
Batch 44/64 loss: -0.26070213317871094
Batch 45/64 loss: -0.8177757263183594
Batch 46/64 loss: -0.8904256820678711
Batch 47/64 loss: -0.5926408767700195
Batch 48/64 loss: -0.6416425704956055
Batch 49/64 loss: -0.9769268035888672
Batch 50/64 loss: -0.5972213745117188
Batch 51/64 loss: -0.38269519805908203
Batch 52/64 loss: -0.36567115783691406
Batch 53/64 loss: -0.6039867401123047
Batch 54/64 loss: -0.7907533645629883
Batch 55/64 loss: -0.6898889541625977
Batch 56/64 loss: -1.013566017150879
Batch 57/64 loss: -0.7078523635864258
Batch 58/64 loss: -0.6403713226318359
Batch 59/64 loss: -0.7086563110351562
Batch 60/64 loss: -0.9732999801635742
Batch 61/64 loss: -0.7750320434570312
Batch 62/64 loss: -0.9627847671508789
Batch 63/64 loss: -0.7967844009399414
Batch 64/64 loss: -4.879954814910889
Epoch 22  Train loss: -0.706754835914163  Val loss: -0.44597891843605697
Epoch 23
-------------------------------
Batch 1/64 loss: -1.0177850723266602
Batch 2/64 loss: -0.5723800659179688
Batch 3/64 loss: -0.6292705535888672
Batch 4/64 loss: -0.1198873519897461
Batch 5/64 loss: -0.892817497253418
Batch 6/64 loss: -0.9525356292724609
Batch 7/64 loss: -0.7835283279418945
Batch 8/64 loss: -0.9310770034790039
Batch 9/64 loss: -0.7124385833740234
Batch 10/64 loss: -0.9974327087402344
Batch 11/64 loss: -0.629450798034668
Batch 12/64 loss: -0.7924842834472656
Batch 13/64 loss: -1.059554100036621
Batch 14/64 loss: -0.4765281677246094
Batch 15/64 loss: -0.4844484329223633
Batch 16/64 loss: -0.8532238006591797
Batch 17/64 loss: -1.0219860076904297
Batch 18/64 loss: -0.6374330520629883
Batch 19/64 loss: -0.6743268966674805
Batch 20/64 loss: -0.7952957153320312
Batch 21/64 loss: -0.8100414276123047
Batch 22/64 loss: -1.0731801986694336
Batch 23/64 loss: -0.6717233657836914
Batch 24/64 loss: -0.9991741180419922
Batch 25/64 loss: -0.7260446548461914
Batch 26/64 loss: -0.6729393005371094
Batch 27/64 loss: -0.7752475738525391
Batch 28/64 loss: -0.9881830215454102
Batch 29/64 loss: -0.5623016357421875
Batch 30/64 loss: -1.2216787338256836
Batch 31/64 loss: -0.8183813095092773
Batch 32/64 loss: -0.9656105041503906
Batch 33/64 loss: -0.8080482482910156
Batch 34/64 loss: -0.8495635986328125
Batch 35/64 loss: -0.4501361846923828
Batch 36/64 loss: -1.2856521606445312
Batch 37/64 loss: -0.8698644638061523
Batch 38/64 loss: -0.6438188552856445
Batch 39/64 loss: -0.7989368438720703
Batch 40/64 loss: -0.6951847076416016
Batch 41/64 loss: -0.42428016662597656
Batch 42/64 loss: -1.0320463180541992
Batch 43/64 loss: -0.6539325714111328
Batch 44/64 loss: -0.4538898468017578
Batch 45/64 loss: -1.2431669235229492
Batch 46/64 loss: -1.0437021255493164
Batch 47/64 loss: -0.8990345001220703
Batch 48/64 loss: -1.1142997741699219
Batch 49/64 loss: -0.7412872314453125
Batch 50/64 loss: -0.7589521408081055
Batch 51/64 loss: -0.9804868698120117
Batch 52/64 loss: -0.47078800201416016
Batch 53/64 loss: -0.22016429901123047
Batch 54/64 loss: -0.7346010208129883
Batch 55/64 loss: -0.761225700378418
Batch 56/64 loss: -0.5365161895751953
Batch 57/64 loss: -0.16136741638183594
Batch 58/64 loss: -0.6880502700805664
Batch 59/64 loss: -0.5917282104492188
Batch 60/64 loss: -1.0738153457641602
Batch 61/64 loss: -0.9168996810913086
Batch 62/64 loss: -1.1255769729614258
Batch 63/64 loss: -1.0825319290161133
Batch 64/64 loss: -4.735934257507324
Epoch 23  Train loss: -0.8310570847754385  Val loss: -1.0601327902672626
Saving best model, epoch: 23
Epoch 24
-------------------------------
Batch 1/64 loss: -0.5087814331054688
Batch 2/64 loss: -0.6480865478515625
Batch 3/64 loss: -1.1149606704711914
Batch 4/64 loss: -0.9576406478881836
Batch 5/64 loss: -0.680912971496582
Batch 6/64 loss: -1.3891534805297852
Batch 7/64 loss: -1.080709457397461
Batch 8/64 loss: -1.1202669143676758
Batch 9/64 loss: -0.7003364562988281
Batch 10/64 loss: -0.8098335266113281
Batch 11/64 loss: -0.38079261779785156
Batch 12/64 loss: -0.8463497161865234
Batch 13/64 loss: -0.7984342575073242
Batch 14/64 loss: -0.8802223205566406
Batch 15/64 loss: -1.0095148086547852
Batch 16/64 loss: -0.8395595550537109
Batch 17/64 loss: -0.9419221878051758
Batch 18/64 loss: -0.7117795944213867
Batch 19/64 loss: -0.7470703125
Batch 20/64 loss: -0.7982683181762695
Batch 21/64 loss: -0.6385011672973633
Batch 22/64 loss: -0.7606391906738281
Batch 23/64 loss: -0.5650873184204102
Batch 24/64 loss: -0.9057769775390625
Batch 25/64 loss: -0.7487831115722656
Batch 26/64 loss: -0.2536630630493164
Batch 27/64 loss: -0.7757511138916016
Batch 28/64 loss: -0.956059455871582
Batch 29/64 loss: -0.7731952667236328
Batch 30/64 loss: -0.9800271987915039
Batch 31/64 loss: -0.920893669128418
Batch 32/64 loss: -0.7990531921386719
Batch 33/64 loss: -1.0112276077270508
Batch 34/64 loss: -0.9715099334716797
Batch 35/64 loss: -0.6089115142822266
Batch 36/64 loss: -0.5230827331542969
Batch 37/64 loss: -1.1819753646850586
Batch 38/64 loss: -0.8043336868286133
Batch 39/64 loss: -0.8338203430175781
Batch 40/64 loss: -1.0223207473754883
Batch 41/64 loss: -0.5271816253662109
Batch 42/64 loss: -0.6011219024658203
Batch 43/64 loss: -0.7258081436157227
Batch 44/64 loss: -1.1545591354370117
Batch 45/64 loss: -0.5598764419555664
Batch 46/64 loss: -1.086430549621582
Batch 47/64 loss: -0.5804576873779297
Batch 48/64 loss: -0.6516618728637695
Batch 49/64 loss: -0.8973779678344727
Batch 50/64 loss: -0.7779254913330078
Batch 51/64 loss: -0.9066543579101562
Batch 52/64 loss: -0.8948955535888672
Batch 53/64 loss: -0.9111328125
Batch 54/64 loss: -0.7891635894775391
Batch 55/64 loss: -0.7952966690063477
Batch 56/64 loss: -0.8905668258666992
Batch 57/64 loss: -1.1841402053833008
Batch 58/64 loss: -1.1526288986206055
Batch 59/64 loss: -0.8012828826904297
Batch 60/64 loss: -0.6500740051269531
Batch 61/64 loss: -1.107722282409668
Batch 62/64 loss: -0.7120237350463867
Batch 63/64 loss: -1.0702323913574219
Batch 64/64 loss: -4.7995405197143555
Epoch 24  Train loss: -0.878856139089547  Val loss: -1.0342305108034324
Epoch 25
-------------------------------
Batch 1/64 loss: -0.7906875610351562
Batch 2/64 loss: -0.8714313507080078
Batch 3/64 loss: -0.782404899597168
Batch 4/64 loss: -0.9247169494628906
Batch 5/64 loss: -1.031691551208496
Batch 6/64 loss: -0.9218921661376953
Batch 7/64 loss: -0.7697277069091797
Batch 8/64 loss: -1.0014533996582031
Batch 9/64 loss: -1.262852668762207
Batch 10/64 loss: -0.7463617324829102
Batch 11/64 loss: -1.2414436340332031
Batch 12/64 loss: -1.1629791259765625
Batch 13/64 loss: -0.6664094924926758
Batch 14/64 loss: -0.6427850723266602
Batch 15/64 loss: -0.5892562866210938
Batch 16/64 loss: -0.8222818374633789
Batch 17/64 loss: -1.2721757888793945
Batch 18/64 loss: -1.3468198776245117
Batch 19/64 loss: -0.635197639465332
Batch 20/64 loss: -0.8795251846313477
Batch 21/64 loss: -1.1091318130493164
Batch 22/64 loss: -1.0086650848388672
Batch 23/64 loss: -0.9915237426757812
Batch 24/64 loss: -0.9999580383300781
Batch 25/64 loss: -0.9449462890625
Batch 26/64 loss: -0.9386367797851562
Batch 27/64 loss: -0.6502885818481445
Batch 28/64 loss: -1.3949813842773438
Batch 29/64 loss: -0.8436546325683594
Batch 30/64 loss: -1.1292076110839844
Batch 31/64 loss: -0.22379589080810547
Batch 32/64 loss: -1.0039520263671875
Batch 33/64 loss: -0.8650455474853516
Batch 34/64 loss: -0.810032844543457
Batch 35/64 loss: -0.7672796249389648
Batch 36/64 loss: -0.5999794006347656
Batch 37/64 loss: -0.5691719055175781
Batch 38/64 loss: -0.8777866363525391
Batch 39/64 loss: -0.9218778610229492
Batch 40/64 loss: -1.0499944686889648
Batch 41/64 loss: -0.9160470962524414
Batch 42/64 loss: -1.0412511825561523
Batch 43/64 loss: -0.3666543960571289
Batch 44/64 loss: -0.860753059387207
Batch 45/64 loss: -0.5684280395507812
Batch 46/64 loss: -0.6725358963012695
Batch 47/64 loss: -1.0276451110839844
Batch 48/64 loss: -0.6364116668701172
Batch 49/64 loss: -0.7165813446044922
Batch 50/64 loss: -0.7798538208007812
Batch 51/64 loss: -0.3958559036254883
Batch 52/64 loss: -1.033778190612793
Batch 53/64 loss: -0.5655603408813477
Batch 54/64 loss: -0.8797712326049805
Batch 55/64 loss: -0.8793745040893555
Batch 56/64 loss: -0.9984130859375
Batch 57/64 loss: -0.9334583282470703
Batch 58/64 loss: -0.8628749847412109
Batch 59/64 loss: -1.1564435958862305
Batch 60/64 loss: -0.9810733795166016
Batch 61/64 loss: -1.0481996536254883
Batch 62/64 loss: -0.35938453674316406
Batch 63/64 loss: -0.23089122772216797
Batch 64/64 loss: -4.851998329162598
Epoch 25  Train loss: -0.9037214653164732  Val loss: -0.8607460493893967
Epoch 26
-------------------------------
Batch 1/64 loss: -0.6269779205322266
Batch 2/64 loss: -1.0791091918945312
Batch 3/64 loss: -0.6204032897949219
Batch 4/64 loss: -1.2252197265625
Batch 5/64 loss: -0.9203157424926758
Batch 6/64 loss: -0.9462127685546875
Batch 7/64 loss: -0.6638727188110352
Batch 8/64 loss: -1.072805404663086
Batch 9/64 loss: -1.1274547576904297
Batch 10/64 loss: -0.9347991943359375
Batch 11/64 loss: -1.2224178314208984
Batch 12/64 loss: -0.9769802093505859
Batch 13/64 loss: -0.9476585388183594
Batch 14/64 loss: -1.0004692077636719
Batch 15/64 loss: -1.0575628280639648
Batch 16/64 loss: -0.770756721496582
Batch 17/64 loss: -1.1912364959716797
Batch 18/64 loss: -1.3221960067749023
Batch 19/64 loss: -0.3942298889160156
Batch 20/64 loss: -1.2177448272705078
Batch 21/64 loss: -0.9393234252929688
Batch 22/64 loss: -1.0892419815063477
Batch 23/64 loss: -0.8203439712524414
Batch 24/64 loss: -0.9894447326660156
Batch 25/64 loss: -0.5987443923950195
Batch 26/64 loss: -0.7555179595947266
Batch 27/64 loss: -0.36074161529541016
Batch 28/64 loss: -0.6730117797851562
Batch 29/64 loss: -0.923975944519043
Batch 30/64 loss: -0.02955913543701172
Batch 31/64 loss: -1.1058616638183594
Batch 32/64 loss: -1.1350164413452148
Batch 33/64 loss: -0.8252944946289062
Batch 34/64 loss: -0.5251369476318359
Batch 35/64 loss: -0.5266637802124023
Batch 36/64 loss: -1.0611209869384766
Batch 37/64 loss: -0.6021871566772461
Batch 38/64 loss: -0.9176425933837891
Batch 39/64 loss: -0.8986644744873047
Batch 40/64 loss: -0.8768711090087891
Batch 41/64 loss: -0.967381477355957
Batch 42/64 loss: -1.0475988388061523
Batch 43/64 loss: -1.04266357421875
Batch 44/64 loss: -0.8134660720825195
Batch 45/64 loss: -1.0146150588989258
Batch 46/64 loss: -1.1003780364990234
Batch 47/64 loss: -0.9724550247192383
Batch 48/64 loss: -1.1337223052978516
Batch 49/64 loss: -0.9181060791015625
Batch 50/64 loss: -0.845428466796875
Batch 51/64 loss: -0.7342128753662109
Batch 52/64 loss: -1.0403614044189453
Batch 53/64 loss: -0.9081048965454102
Batch 54/64 loss: -0.45416831970214844
Batch 55/64 loss: -0.9616641998291016
Batch 56/64 loss: -0.680633544921875
Batch 57/64 loss: -0.5979776382446289
Batch 58/64 loss: -1.1496858596801758
Batch 59/64 loss: -0.7058324813842773
Batch 60/64 loss: -0.7959737777709961
Batch 61/64 loss: -0.7686491012573242
Batch 62/64 loss: -0.7219886779785156
Batch 63/64 loss: -0.9882173538208008
Batch 64/64 loss: -4.589386463165283
Epoch 26  Train loss: -0.9220096120647355  Val loss: -0.5545688904437822
Epoch 27
-------------------------------
Batch 1/64 loss: -0.8148164749145508
Batch 2/64 loss: -0.4538097381591797
Batch 3/64 loss: -0.7519655227661133
Batch 4/64 loss: -0.8862428665161133
Batch 5/64 loss: -0.5954246520996094
Batch 6/64 loss: -0.43817901611328125
Batch 7/64 loss: -0.689906120300293
Batch 8/64 loss: -0.5909109115600586
Batch 9/64 loss: -0.8344697952270508
Batch 10/64 loss: -0.5500659942626953
Batch 11/64 loss: -0.9732532501220703
Batch 12/64 loss: -1.1013221740722656
Batch 13/64 loss: -0.603693962097168
Batch 14/64 loss: -0.5879678726196289
Batch 15/64 loss: -0.8183784484863281
Batch 16/64 loss: -0.5438671112060547
Batch 17/64 loss: -0.632014274597168
Batch 18/64 loss: -0.9672822952270508
Batch 19/64 loss: -0.6710052490234375
Batch 20/64 loss: -1.1523571014404297
Batch 21/64 loss: -0.9868049621582031
Batch 22/64 loss: -0.9724826812744141
Batch 23/64 loss: -0.7220182418823242
Batch 24/64 loss: -0.9308624267578125
Batch 25/64 loss: -0.9568233489990234
Batch 26/64 loss: -0.789942741394043
Batch 27/64 loss: -1.1468009948730469
Batch 28/64 loss: -0.7346773147583008
Batch 29/64 loss: -0.9194517135620117
Batch 30/64 loss: -0.6266822814941406
Batch 31/64 loss: -0.7695722579956055
Batch 32/64 loss: -0.8491029739379883
Batch 33/64 loss: -0.8628931045532227
Batch 34/64 loss: -0.9427852630615234
Batch 35/64 loss: -1.06658935546875
Batch 36/64 loss: -1.0367717742919922
Batch 37/64 loss: -1.0044403076171875
Batch 38/64 loss: -0.834345817565918
Batch 39/64 loss: -0.8263521194458008
Batch 40/64 loss: -0.8697748184204102
Batch 41/64 loss: -0.5544967651367188
Batch 42/64 loss: -1.175558090209961
Batch 43/64 loss: -1.0823307037353516
Batch 44/64 loss: -0.6608648300170898
Batch 45/64 loss: -1.3570537567138672
Batch 46/64 loss: -0.6608943939208984
Batch 47/64 loss: -0.6585960388183594
Batch 48/64 loss: -0.9258012771606445
Batch 49/64 loss: -1.185715675354004
Batch 50/64 loss: -1.0333900451660156
Batch 51/64 loss: -1.1088676452636719
Batch 52/64 loss: -1.065962791442871
Batch 53/64 loss: -1.194962501525879
Batch 54/64 loss: -1.0474376678466797
Batch 55/64 loss: -0.8844499588012695
Batch 56/64 loss: -1.0575790405273438
Batch 57/64 loss: -0.7573051452636719
Batch 58/64 loss: -0.9613275527954102
Batch 59/64 loss: -0.6814889907836914
Batch 60/64 loss: -0.7330484390258789
Batch 61/64 loss: -0.8975934982299805
Batch 62/64 loss: -1.0054750442504883
Batch 63/64 loss: -1.002589225769043
Batch 64/64 loss: -4.698514938354492
Epoch 27  Train loss: -0.9054554135191675  Val loss: -0.9826888251550419
Epoch 28
-------------------------------
Batch 1/64 loss: -0.5380287170410156
Batch 2/64 loss: -1.1121702194213867
Batch 3/64 loss: -0.6798133850097656
Batch 4/64 loss: -0.8379249572753906
Batch 5/64 loss: -0.9893522262573242
Batch 6/64 loss: -1.0451345443725586
Batch 7/64 loss: -1.0138673782348633
Batch 8/64 loss: -1.1675472259521484
Batch 9/64 loss: -0.8485355377197266
Batch 10/64 loss: -1.1774749755859375
Batch 11/64 loss: -0.5776653289794922
Batch 12/64 loss: -1.167902946472168
Batch 13/64 loss: -1.1617965698242188
Batch 14/64 loss: -0.881779670715332
Batch 15/64 loss: -0.5661983489990234
Batch 16/64 loss: -0.9163427352905273
Batch 17/64 loss: -1.3941946029663086
Batch 18/64 loss: -0.8530731201171875
Batch 19/64 loss: -1.1707181930541992
Batch 20/64 loss: -0.6378936767578125
Batch 21/64 loss: -1.1701974868774414
Batch 22/64 loss: -0.8522138595581055
Batch 23/64 loss: -1.3171806335449219
Batch 24/64 loss: -0.9050502777099609
Batch 25/64 loss: -0.7796297073364258
Batch 26/64 loss: -1.1061506271362305
Batch 27/64 loss: -0.9502172470092773
Batch 28/64 loss: -0.7033863067626953
Batch 29/64 loss: -1.0029516220092773
Batch 30/64 loss: -0.7996149063110352
Batch 31/64 loss: -1.0366201400756836
Batch 32/64 loss: -0.8460350036621094
Batch 33/64 loss: -0.7434396743774414
Batch 34/64 loss: -0.7807989120483398
Batch 35/64 loss: -0.9888858795166016
Batch 36/64 loss: -0.7816829681396484
Batch 37/64 loss: -1.0298166275024414
Batch 38/64 loss: -0.7033834457397461
Batch 39/64 loss: -1.2493162155151367
Batch 40/64 loss: -1.141861915588379
Batch 41/64 loss: -0.6807441711425781
Batch 42/64 loss: -1.1782493591308594
Batch 43/64 loss: -1.1021699905395508
Batch 44/64 loss: -1.023625373840332
Batch 45/64 loss: -0.6798124313354492
Batch 46/64 loss: -1.089895248413086
Batch 47/64 loss: -1.1624517440795898
Batch 48/64 loss: -0.999506950378418
Batch 49/64 loss: -1.1576318740844727
Batch 50/64 loss: -0.8501901626586914
Batch 51/64 loss: -1.294325828552246
Batch 52/64 loss: -1.1908674240112305
Batch 53/64 loss: -1.0311965942382812
Batch 54/64 loss: -1.2305021286010742
Batch 55/64 loss: -1.3032398223876953
Batch 56/64 loss: -1.2104606628417969
Batch 57/64 loss: -0.879857063293457
Batch 58/64 loss: -0.8809938430786133
Batch 59/64 loss: -0.7298336029052734
Batch 60/64 loss: -1.0681524276733398
Batch 61/64 loss: -0.8535737991333008
Batch 62/64 loss: -1.2318115234375
Batch 63/64 loss: -0.5286540985107422
Batch 64/64 loss: -4.955361843109131
Epoch 28  Train loss: -1.0149037697735954  Val loss: -1.2266195500429553
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: -0.8901166915893555
Batch 2/64 loss: -1.2823734283447266
Batch 3/64 loss: -1.087961196899414
Batch 4/64 loss: -1.3056907653808594
Batch 5/64 loss: -0.5463953018188477
Batch 6/64 loss: -0.8945856094360352
Batch 7/64 loss: -0.8946866989135742
Batch 8/64 loss: -1.3356313705444336
Batch 9/64 loss: -0.7635707855224609
Batch 10/64 loss: -1.0331840515136719
Batch 11/64 loss: -0.6975898742675781
Batch 12/64 loss: -0.7991580963134766
Batch 13/64 loss: -0.6420011520385742
Batch 14/64 loss: -1.3381977081298828
Batch 15/64 loss: -0.9207868576049805
Batch 16/64 loss: -1.0058794021606445
Batch 17/64 loss: -0.8265848159790039
Batch 18/64 loss: -1.1695337295532227
Batch 19/64 loss: -1.1063289642333984
Batch 20/64 loss: -1.2460308074951172
Batch 21/64 loss: -1.3169403076171875
Batch 22/64 loss: -0.7861099243164062
Batch 23/64 loss: -0.9003887176513672
Batch 24/64 loss: -0.9782371520996094
Batch 25/64 loss: -0.8829488754272461
Batch 26/64 loss: -1.1815366744995117
Batch 27/64 loss: -0.37989044189453125
Batch 28/64 loss: -1.1902732849121094
Batch 29/64 loss: -1.2414894104003906
Batch 30/64 loss: -1.162038803100586
Batch 31/64 loss: -0.6101474761962891
Batch 32/64 loss: -1.1146039962768555
Batch 33/64 loss: -1.0473880767822266
Batch 34/64 loss: -1.0225658416748047
Batch 35/64 loss: -1.3415050506591797
Batch 36/64 loss: -0.9519157409667969
Batch 37/64 loss: -0.7935934066772461
Batch 38/64 loss: -0.5038986206054688
Batch 39/64 loss: -1.2982006072998047
Batch 40/64 loss: -0.883056640625
Batch 41/64 loss: -1.0478429794311523
Batch 42/64 loss: -0.7987480163574219
Batch 43/64 loss: -0.9245891571044922
Batch 44/64 loss: -1.0312423706054688
Batch 45/64 loss: -1.1264019012451172
Batch 46/64 loss: -1.0817975997924805
Batch 47/64 loss: -1.373164176940918
Batch 48/64 loss: -0.5622224807739258
Batch 49/64 loss: -1.1749839782714844
Batch 50/64 loss: -0.9170732498168945
Batch 51/64 loss: -0.6608552932739258
Batch 52/64 loss: -0.9503717422485352
Batch 53/64 loss: -1.1086015701293945
Batch 54/64 loss: -1.1506271362304688
Batch 55/64 loss: -1.1428346633911133
Batch 56/64 loss: -1.0228605270385742
Batch 57/64 loss: -0.8338375091552734
Batch 58/64 loss: -0.6257219314575195
Batch 59/64 loss: -1.3279638290405273
Batch 60/64 loss: -1.2540855407714844
Batch 61/64 loss: -1.3893146514892578
Batch 62/64 loss: -0.9382991790771484
Batch 63/64 loss: -1.2390718460083008
Batch 64/64 loss: -5.439482688903809
Epoch 29  Train loss: -1.0531002306470685  Val loss: -0.9559372839649108
Epoch 30
-------------------------------
Batch 1/64 loss: -0.9471502304077148
Batch 2/64 loss: -1.0101680755615234
Batch 3/64 loss: -0.715235710144043
Batch 4/64 loss: -0.7727479934692383
Batch 5/64 loss: -1.001434326171875
Batch 6/64 loss: -0.8832559585571289
Batch 7/64 loss: -0.9939346313476562
Batch 8/64 loss: -1.217503547668457
Batch 9/64 loss: -1.2312183380126953
Batch 10/64 loss: -1.1219482421875
Batch 11/64 loss: -0.8253593444824219
Batch 12/64 loss: -1.0892505645751953
Batch 13/64 loss: -1.1362199783325195
Batch 14/64 loss: -1.2259550094604492
Batch 15/64 loss: -0.8334980010986328
Batch 16/64 loss: -0.900843620300293
Batch 17/64 loss: -1.1673030853271484
Batch 18/64 loss: -1.0535078048706055
Batch 19/64 loss: -1.0887832641601562
Batch 20/64 loss: -1.043839454650879
Batch 21/64 loss: -0.9090871810913086
Batch 22/64 loss: -1.172943115234375
Batch 23/64 loss: -0.29650211334228516
Batch 24/64 loss: -1.0028867721557617
Batch 25/64 loss: -1.101740837097168
Batch 26/64 loss: -1.0537796020507812
Batch 27/64 loss: -1.1134796142578125
Batch 28/64 loss: -0.9217205047607422
Batch 29/64 loss: -0.8759346008300781
Batch 30/64 loss: -1.1815996170043945
Batch 31/64 loss: -1.038766860961914
Batch 32/64 loss: -1.2769546508789062
Batch 33/64 loss: -0.813450813293457
Batch 34/64 loss: -0.8987236022949219
Batch 35/64 loss: -0.9038267135620117
Batch 36/64 loss: -0.9117660522460938
Batch 37/64 loss: -0.47083473205566406
Batch 38/64 loss: -1.3822546005249023
Batch 39/64 loss: -0.5164699554443359
Batch 40/64 loss: -0.8053131103515625
Batch 41/64 loss: -1.0634336471557617
Batch 42/64 loss: -0.7136106491088867
Batch 43/64 loss: -1.3242568969726562
Batch 44/64 loss: -1.0904207229614258
Batch 45/64 loss: -1.2195844650268555
Batch 46/64 loss: -0.8055515289306641
Batch 47/64 loss: -1.076401710510254
Batch 48/64 loss: -1.1406135559082031
Batch 49/64 loss: -1.0441656112670898
Batch 50/64 loss: -1.0842924118041992
Batch 51/64 loss: -1.238703727722168
Batch 52/64 loss: -1.0332469940185547
Batch 53/64 loss: -0.9789237976074219
Batch 54/64 loss: -1.0337905883789062
Batch 55/64 loss: -1.246088981628418
Batch 56/64 loss: -1.0547599792480469
Batch 57/64 loss: -0.8694314956665039
Batch 58/64 loss: -1.1656227111816406
Batch 59/64 loss: -0.7705955505371094
Batch 60/64 loss: -1.198847770690918
Batch 61/64 loss: -1.4790153503417969
Batch 62/64 loss: -1.3531837463378906
Batch 63/64 loss: -1.127859115600586
Batch 64/64 loss: -5.193817138671875
Epoch 30  Train loss: -1.0653326445934819  Val loss: -1.2039618344651055
Epoch 31
-------------------------------
Batch 1/64 loss: -0.7331304550170898
Batch 2/64 loss: -1.3424005508422852
Batch 3/64 loss: -1.229360580444336
Batch 4/64 loss: -1.2883987426757812
Batch 5/64 loss: -0.8985481262207031
Batch 6/64 loss: -1.1901664733886719
Batch 7/64 loss: -1.1278133392333984
Batch 8/64 loss: -1.1199541091918945
Batch 9/64 loss: -0.7815542221069336
Batch 10/64 loss: -1.1642427444458008
Batch 11/64 loss: -1.331181526184082
Batch 12/64 loss: -1.087113380432129
Batch 13/64 loss: -1.028432846069336
Batch 14/64 loss: -1.2425661087036133
Batch 15/64 loss: -0.850163459777832
Batch 16/64 loss: -1.2905817031860352
Batch 17/64 loss: -1.3507823944091797
Batch 18/64 loss: -0.8077964782714844
Batch 19/64 loss: -0.6264076232910156
Batch 20/64 loss: -0.9550085067749023
Batch 21/64 loss: -1.4106731414794922
Batch 22/64 loss: -1.0851430892944336
Batch 23/64 loss: -1.0149612426757812
Batch 24/64 loss: -1.0108613967895508
Batch 25/64 loss: -1.4094772338867188
Batch 26/64 loss: -1.3639650344848633
Batch 27/64 loss: -1.0740718841552734
Batch 28/64 loss: -1.0401411056518555
Batch 29/64 loss: -1.0638208389282227
Batch 30/64 loss: -1.01544189453125
Batch 31/64 loss: -1.1641693115234375
Batch 32/64 loss: -0.8594331741333008
Batch 33/64 loss: -1.1791982650756836
Batch 34/64 loss: -1.2589006423950195
Batch 35/64 loss: -0.9369354248046875
Batch 36/64 loss: -1.007181167602539
Batch 37/64 loss: -1.0828351974487305
Batch 38/64 loss: -1.1403217315673828
Batch 39/64 loss: -1.0388154983520508
Batch 40/64 loss: -0.8258142471313477
Batch 41/64 loss: -0.6714105606079102
Batch 42/64 loss: -0.9278860092163086
Batch 43/64 loss: -0.9487123489379883
Batch 44/64 loss: -1.2229413986206055
Batch 45/64 loss: -1.0098285675048828
Batch 46/64 loss: -1.1801719665527344
Batch 47/64 loss: -1.1723175048828125
Batch 48/64 loss: -1.2133769989013672
Batch 49/64 loss: -0.6371994018554688
Batch 50/64 loss: -1.0466079711914062
Batch 51/64 loss: -0.6199665069580078
Batch 52/64 loss: -1.1251802444458008
Batch 53/64 loss: -1.3369150161743164
Batch 54/64 loss: -0.4490795135498047
Batch 55/64 loss: -1.2416725158691406
Batch 56/64 loss: -1.120976448059082
Batch 57/64 loss: -0.9366798400878906
Batch 58/64 loss: -1.0060749053955078
Batch 59/64 loss: -1.2500181198120117
Batch 60/64 loss: -1.3387212753295898
Batch 61/64 loss: -1.2164373397827148
Batch 62/64 loss: -1.142862319946289
Batch 63/64 loss: -0.6153774261474609
Batch 64/64 loss: -5.403026580810547
Epoch 31  Train loss: -1.1123207690669041  Val loss: -1.18587710193752
Epoch 32
-------------------------------
Batch 1/64 loss: -0.482666015625
Batch 2/64 loss: -0.9913597106933594
Batch 3/64 loss: -1.2649335861206055
Batch 4/64 loss: -0.7473201751708984
Batch 5/64 loss: -0.7248373031616211
Batch 6/64 loss: -1.3184928894042969
Batch 7/64 loss: -0.9598140716552734
Batch 8/64 loss: -0.7752313613891602
Batch 9/64 loss: -1.53179931640625
Batch 10/64 loss: -1.1858234405517578
Batch 11/64 loss: -1.1384611129760742
Batch 12/64 loss: -1.1441917419433594
Batch 13/64 loss: -0.9344272613525391
Batch 14/64 loss: -0.9886083602905273
Batch 15/64 loss: -1.1950712203979492
Batch 16/64 loss: -0.9948234558105469
Batch 17/64 loss: -1.0258426666259766
Batch 18/64 loss: -0.9803848266601562
Batch 19/64 loss: -1.488142967224121
Batch 20/64 loss: -1.0108814239501953
Batch 21/64 loss: -0.8530082702636719
Batch 22/64 loss: -0.7882537841796875
Batch 23/64 loss: -1.1376724243164062
Batch 24/64 loss: -1.4194517135620117
Batch 25/64 loss: -0.9226694107055664
Batch 26/64 loss: -0.9527654647827148
Batch 27/64 loss: -0.715153694152832
Batch 28/64 loss: -1.2688493728637695
Batch 29/64 loss: -1.1987323760986328
Batch 30/64 loss: -1.3030309677124023
Batch 31/64 loss: -0.7578802108764648
Batch 32/64 loss: -0.939946174621582
Batch 33/64 loss: -1.0699396133422852
Batch 34/64 loss: -1.019911766052246
Batch 35/64 loss: -1.1350030899047852
Batch 36/64 loss: -1.0610876083374023
Batch 37/64 loss: -0.8406763076782227
Batch 38/64 loss: -0.8275184631347656
Batch 39/64 loss: -1.372410774230957
Batch 40/64 loss: -1.241154670715332
Batch 41/64 loss: -1.038970947265625
Batch 42/64 loss: -1.2782135009765625
Batch 43/64 loss: -1.1169795989990234
Batch 44/64 loss: -1.2493047714233398
Batch 45/64 loss: -1.2137575149536133
Batch 46/64 loss: -1.476593017578125
Batch 47/64 loss: -1.3005475997924805
Batch 48/64 loss: -1.1799421310424805
Batch 49/64 loss: -0.8062000274658203
Batch 50/64 loss: -1.3203439712524414
Batch 51/64 loss: -1.1136837005615234
Batch 52/64 loss: -0.9033699035644531
Batch 53/64 loss: -1.1855201721191406
Batch 54/64 loss: -0.8355627059936523
Batch 55/64 loss: -1.1334686279296875
Batch 56/64 loss: -1.1133537292480469
Batch 57/64 loss: -1.3738059997558594
Batch 58/64 loss: -1.2741966247558594
Batch 59/64 loss: -0.8199577331542969
Batch 60/64 loss: -0.8523492813110352
Batch 61/64 loss: -0.7946863174438477
Batch 62/64 loss: -0.9511852264404297
Batch 63/64 loss: -0.8029336929321289
Batch 64/64 loss: -5.360841751098633
Epoch 32  Train loss: -1.1115888184192133  Val loss: -0.3999118870476267
Epoch 33
-------------------------------
Batch 1/64 loss: -0.9521331787109375
Batch 2/64 loss: -1.3771209716796875
Batch 3/64 loss: -0.9577741622924805
Batch 4/64 loss: -1.1579856872558594
Batch 5/64 loss: -0.77197265625
Batch 6/64 loss: -0.8174114227294922
Batch 7/64 loss: -1.1117801666259766
Batch 8/64 loss: -0.3993997573852539
Batch 9/64 loss: -0.3913078308105469
Batch 10/64 loss: -1.1197624206542969
Batch 11/64 loss: -1.1576709747314453
Batch 12/64 loss: -0.8875770568847656
Batch 13/64 loss: -0.7608499526977539
Batch 14/64 loss: -0.9654474258422852
Batch 15/64 loss: -0.6942634582519531
Batch 16/64 loss: -1.1284809112548828
Batch 17/64 loss: -1.2894830703735352
Batch 18/64 loss: -0.9476318359375
Batch 19/64 loss: -0.8912868499755859
Batch 20/64 loss: -0.7524404525756836
Batch 21/64 loss: -1.4316158294677734
Batch 22/64 loss: -1.0780601501464844
Batch 23/64 loss: -1.2299928665161133
Batch 24/64 loss: -0.8029041290283203
Batch 25/64 loss: -1.1426944732666016
Batch 26/64 loss: -1.054945945739746
Batch 27/64 loss: -0.9960803985595703
Batch 28/64 loss: -1.010599136352539
Batch 29/64 loss: -1.1410655975341797
Batch 30/64 loss: -1.3141536712646484
Batch 31/64 loss: -1.305135726928711
Batch 32/64 loss: -1.1189193725585938
Batch 33/64 loss: -0.8941965103149414
Batch 34/64 loss: -0.8430976867675781
Batch 35/64 loss: -1.0483951568603516
Batch 36/64 loss: -1.0236330032348633
Batch 37/64 loss: -0.895294189453125
Batch 38/64 loss: -0.9280071258544922
Batch 39/64 loss: -0.9168500900268555
Batch 40/64 loss: -0.7010049819946289
Batch 41/64 loss: -1.1521005630493164
Batch 42/64 loss: -1.0734748840332031
Batch 43/64 loss: -1.2806682586669922
Batch 44/64 loss: -1.0245676040649414
Batch 45/64 loss: -0.9802970886230469
Batch 46/64 loss: -1.285811424255371
Batch 47/64 loss: -1.13629150390625
Batch 48/64 loss: -1.524134635925293
Batch 49/64 loss: -1.0631122589111328
Batch 50/64 loss: -1.270634651184082
Batch 51/64 loss: -1.069014549255371
Batch 52/64 loss: -1.1946372985839844
Batch 53/64 loss: -0.889470100402832
Batch 54/64 loss: -1.279571533203125
Batch 55/64 loss: -1.292337417602539
Batch 56/64 loss: -1.2392044067382812
Batch 57/64 loss: -1.1261539459228516
Batch 58/64 loss: -1.2535877227783203
Batch 59/64 loss: -1.0307750701904297
Batch 60/64 loss: -1.235504150390625
Batch 61/64 loss: -1.2117919921875
Batch 62/64 loss: -0.8876848220825195
Batch 63/64 loss: -0.6942672729492188
Batch 64/64 loss: -5.68063497543335
Epoch 33  Train loss: -1.0959058144513298  Val loss: -1.2464889840981395
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: -1.2189455032348633
Batch 2/64 loss: -0.7787904739379883
Batch 3/64 loss: -0.8127651214599609
Batch 4/64 loss: -0.9712390899658203
Batch 5/64 loss: -1.013117790222168
Batch 6/64 loss: -1.1125669479370117
Batch 7/64 loss: -1.3694791793823242
Batch 8/64 loss: -1.0935001373291016
Batch 9/64 loss: -1.1756811141967773
Batch 10/64 loss: -1.1364660263061523
Batch 11/64 loss: -1.4230585098266602
Batch 12/64 loss: -1.3897638320922852
Batch 13/64 loss: -1.5029888153076172
Batch 14/64 loss: -1.0614042282104492
Batch 15/64 loss: -0.9129447937011719
Batch 16/64 loss: -1.0157175064086914
Batch 17/64 loss: -0.783015251159668
Batch 18/64 loss: -1.4170846939086914
Batch 19/64 loss: -1.0400962829589844
Batch 20/64 loss: -1.1581344604492188
Batch 21/64 loss: -0.5715141296386719
Batch 22/64 loss: -1.1282339096069336
Batch 23/64 loss: -0.6552934646606445
Batch 24/64 loss: -0.980137825012207
Batch 25/64 loss: -0.9270868301391602
Batch 26/64 loss: -1.1539297103881836
Batch 27/64 loss: -0.9951267242431641
Batch 28/64 loss: -1.0231914520263672
Batch 29/64 loss: -1.1496028900146484
Batch 30/64 loss: -1.3861398696899414
Batch 31/64 loss: -1.2318830490112305
Batch 32/64 loss: -0.8266944885253906
Batch 33/64 loss: -1.3834428787231445
Batch 34/64 loss: -1.2103500366210938
Batch 35/64 loss: -1.317270278930664
Batch 36/64 loss: -1.3718976974487305
Batch 37/64 loss: -1.333627700805664
Batch 38/64 loss: -1.0313148498535156
Batch 39/64 loss: -0.9375848770141602
Batch 40/64 loss: -1.0674076080322266
Batch 41/64 loss: -0.9371004104614258
Batch 42/64 loss: -1.4296979904174805
Batch 43/64 loss: -1.1124162673950195
Batch 44/64 loss: -0.892481803894043
Batch 45/64 loss: -1.001352310180664
Batch 46/64 loss: -1.2253265380859375
Batch 47/64 loss: -1.0301170349121094
Batch 48/64 loss: -1.1130867004394531
Batch 49/64 loss: -1.154402732849121
Batch 50/64 loss: -1.4566888809204102
Batch 51/64 loss: -1.2622613906860352
Batch 52/64 loss: -0.8236331939697266
Batch 53/64 loss: -1.1356840133666992
Batch 54/64 loss: -0.8566722869873047
Batch 55/64 loss: -1.42315673828125
Batch 56/64 loss: -1.3881988525390625
Batch 57/64 loss: -1.5853796005249023
Batch 58/64 loss: -1.1046333312988281
Batch 59/64 loss: -0.9686088562011719
Batch 60/64 loss: -1.2278623580932617
Batch 61/64 loss: -1.2042264938354492
Batch 62/64 loss: -1.1049776077270508
Batch 63/64 loss: -1.1693363189697266
Batch 64/64 loss: -5.8571319580078125
Epoch 34  Train loss: -1.1775473052380132  Val loss: -1.2484425810194506
Saving best model, epoch: 34
Epoch 35
-------------------------------
Batch 1/64 loss: -1.119546890258789
Batch 2/64 loss: -1.3984260559082031
Batch 3/64 loss: -1.1091880798339844
Batch 4/64 loss: -1.0509138107299805
Batch 5/64 loss: -1.3799638748168945
Batch 6/64 loss: -1.065424919128418
Batch 7/64 loss: -0.9228944778442383
Batch 8/64 loss: -0.9503374099731445
Batch 9/64 loss: -1.2204551696777344
Batch 10/64 loss: -1.4076166152954102
Batch 11/64 loss: -0.3674297332763672
Batch 12/64 loss: -1.274561882019043
Batch 13/64 loss: -1.1451282501220703
Batch 14/64 loss: -1.295180320739746
Batch 15/64 loss: -0.8650789260864258
Batch 16/64 loss: -0.9970359802246094
Batch 17/64 loss: -1.1325883865356445
Batch 18/64 loss: -1.1724767684936523
Batch 19/64 loss: -1.3646411895751953
Batch 20/64 loss: -1.2900266647338867
Batch 21/64 loss: -1.376235008239746
Batch 22/64 loss: -1.0483598709106445
Batch 23/64 loss: -1.2226781845092773
Batch 24/64 loss: -1.2125835418701172
Batch 25/64 loss: -1.1251306533813477
Batch 26/64 loss: -1.0876436233520508
Batch 27/64 loss: -1.28564453125
Batch 28/64 loss: -1.2664060592651367
Batch 29/64 loss: -1.2919979095458984
Batch 30/64 loss: -1.1595067977905273
Batch 31/64 loss: -1.0888795852661133
Batch 32/64 loss: -0.6893224716186523
Batch 33/64 loss: -0.9112844467163086
Batch 34/64 loss: -1.3133602142333984
Batch 35/64 loss: -1.2093544006347656
Batch 36/64 loss: -0.804046630859375
Batch 37/64 loss: -0.6621303558349609
Batch 38/64 loss: -0.9710702896118164
Batch 39/64 loss: -1.1775436401367188
Batch 40/64 loss: -1.4440412521362305
Batch 41/64 loss: -1.0690641403198242
Batch 42/64 loss: -1.5704612731933594
Batch 43/64 loss: -1.2601757049560547
Batch 44/64 loss: -1.0557079315185547
Batch 45/64 loss: -0.9530916213989258
Batch 46/64 loss: -1.4205751419067383
Batch 47/64 loss: -1.1493091583251953
Batch 48/64 loss: -0.33739662170410156
Batch 49/64 loss: -1.2925710678100586
Batch 50/64 loss: -1.280381202697754
Batch 51/64 loss: -1.3188896179199219
Batch 52/64 loss: -1.2954978942871094
Batch 53/64 loss: -0.8465023040771484
Batch 54/64 loss: -0.734710693359375
Batch 55/64 loss: -1.3597307205200195
Batch 56/64 loss: -1.465519905090332
Batch 57/64 loss: -1.0844335556030273
Batch 58/64 loss: -1.2698431015014648
Batch 59/64 loss: -1.1161375045776367
Batch 60/64 loss: -0.6440649032592773
Batch 61/64 loss: -1.2136907577514648
Batch 62/64 loss: -1.575174331665039
Batch 63/64 loss: -0.9548587799072266
Batch 64/64 loss: -5.793033599853516
Epoch 35  Train loss: -1.1841364393047258  Val loss: -1.2393731579338152
Epoch 36
-------------------------------
Batch 1/64 loss: -1.276158332824707
Batch 2/64 loss: -1.2383794784545898
Batch 3/64 loss: -1.470158576965332
Batch 4/64 loss: -1.3907279968261719
Batch 5/64 loss: -1.4335556030273438
Batch 6/64 loss: -1.4918708801269531
Batch 7/64 loss: -1.6250343322753906
Batch 8/64 loss: -1.0678529739379883
Batch 9/64 loss: -1.0719451904296875
Batch 10/64 loss: -1.0685815811157227
Batch 11/64 loss: -0.8956975936889648
Batch 12/64 loss: -1.0669059753417969
Batch 13/64 loss: -0.5915136337280273
Batch 14/64 loss: -1.4201469421386719
Batch 15/64 loss: -1.16033935546875
Batch 16/64 loss: -1.2728071212768555
Batch 17/64 loss: -1.1175518035888672
Batch 18/64 loss: -1.0204458236694336
Batch 19/64 loss: -1.4137840270996094
Batch 20/64 loss: -1.4997520446777344
Batch 21/64 loss: -1.3374958038330078
Batch 22/64 loss: -0.8450613021850586
Batch 23/64 loss: -0.7364339828491211
Batch 24/64 loss: -1.044820785522461
Batch 25/64 loss: -1.5633792877197266
Batch 26/64 loss: -1.0612850189208984
Batch 27/64 loss: -0.9347333908081055
Batch 28/64 loss: -1.1898765563964844
Batch 29/64 loss: -1.3848352432250977
Batch 30/64 loss: -1.1426305770874023
Batch 31/64 loss: -0.9867095947265625
Batch 32/64 loss: -1.1002569198608398
Batch 33/64 loss: -0.8250675201416016
Batch 34/64 loss: -1.185887336730957
Batch 35/64 loss: -1.143463134765625
Batch 36/64 loss: -1.1004133224487305
Batch 37/64 loss: -1.033721923828125
Batch 38/64 loss: -1.5543546676635742
Batch 39/64 loss: -1.189009666442871
Batch 40/64 loss: -1.3165321350097656
Batch 41/64 loss: -1.1526517868041992
Batch 42/64 loss: -0.7288436889648438
Batch 43/64 loss: -1.2124128341674805
Batch 44/64 loss: -0.8808603286743164
Batch 45/64 loss: -1.0349645614624023
Batch 46/64 loss: -1.5337228775024414
Batch 47/64 loss: -0.9888877868652344
Batch 48/64 loss: -0.6194305419921875
Batch 49/64 loss: -1.596693992614746
Batch 50/64 loss: -1.542104721069336
Batch 51/64 loss: -0.8958730697631836
Batch 52/64 loss: -0.912714958190918
Batch 53/64 loss: -1.0234003067016602
Batch 54/64 loss: -1.0605573654174805
Batch 55/64 loss: -1.0728845596313477
Batch 56/64 loss: -1.2968635559082031
Batch 57/64 loss: -1.2291250228881836
Batch 58/64 loss: -1.5190629959106445
Batch 59/64 loss: -0.8021507263183594
Batch 60/64 loss: -1.1701555252075195
Batch 61/64 loss: -0.6363592147827148
Batch 62/64 loss: -1.4013710021972656
Batch 63/64 loss: -1.192967414855957
Batch 64/64 loss: -5.593774795532227
Epoch 36  Train loss: -1.207350076413622  Val loss: -1.191190608178627
Epoch 37
-------------------------------
Batch 1/64 loss: -1.1318397521972656
Batch 2/64 loss: -1.381972312927246
Batch 3/64 loss: -1.2758350372314453
Batch 4/64 loss: -1.280135154724121
Batch 5/64 loss: -1.323979377746582
Batch 6/64 loss: -1.2030792236328125
Batch 7/64 loss: -0.5493001937866211
Batch 8/64 loss: -0.9086732864379883
Batch 9/64 loss: -1.1237411499023438
Batch 10/64 loss: -1.1888809204101562
Batch 11/64 loss: -1.5651664733886719
Batch 12/64 loss: -0.8816957473754883
Batch 13/64 loss: -1.210214614868164
Batch 14/64 loss: -0.950709342956543
Batch 15/64 loss: -1.0680475234985352
Batch 16/64 loss: -1.2258214950561523
Batch 17/64 loss: -1.2973976135253906
Batch 18/64 loss: -1.2283973693847656
Batch 19/64 loss: -0.8283863067626953
Batch 20/64 loss: -1.2879695892333984
Batch 21/64 loss: -1.549295425415039
Batch 22/64 loss: -1.634028434753418
Batch 23/64 loss: -1.2482614517211914
Batch 24/64 loss: -0.6634912490844727
Batch 25/64 loss: -1.2635183334350586
Batch 26/64 loss: -1.2927169799804688
Batch 27/64 loss: -1.2762737274169922
Batch 28/64 loss: -1.0152416229248047
Batch 29/64 loss: -1.7584266662597656
Batch 30/64 loss: -0.655914306640625
Batch 31/64 loss: -1.2606353759765625
Batch 32/64 loss: -1.0357685089111328
Batch 33/64 loss: -0.9750185012817383
Batch 34/64 loss: -1.0259504318237305
Batch 35/64 loss: -1.0864639282226562
Batch 36/64 loss: -1.260655403137207
Batch 37/64 loss: -1.524765968322754
Batch 38/64 loss: -1.156869888305664
Batch 39/64 loss: -1.1808767318725586
Batch 40/64 loss: -0.7940092086791992
Batch 41/64 loss: -1.116485595703125
Batch 42/64 loss: -1.2311773300170898
Batch 43/64 loss: -1.2617616653442383
Batch 44/64 loss: -1.1891193389892578
Batch 45/64 loss: -1.2501258850097656
Batch 46/64 loss: -1.320479393005371
Batch 47/64 loss: -0.9336280822753906
Batch 48/64 loss: -1.3392858505249023
Batch 49/64 loss: -1.0912504196166992
Batch 50/64 loss: -1.165018081665039
Batch 51/64 loss: -1.2847824096679688
Batch 52/64 loss: -1.2874441146850586
Batch 53/64 loss: -1.3305654525756836
Batch 54/64 loss: -0.4096202850341797
Batch 55/64 loss: -1.220083236694336
Batch 56/64 loss: -1.2118844985961914
Batch 57/64 loss: -1.2412538528442383
Batch 58/64 loss: -1.1256818771362305
Batch 59/64 loss: -1.3137931823730469
Batch 60/64 loss: -0.8888072967529297
Batch 61/64 loss: -1.2152376174926758
Batch 62/64 loss: -1.002634048461914
Batch 63/64 loss: -0.9945383071899414
Batch 64/64 loss: -5.107423782348633
Epoch 37  Train loss: -1.2050925535314223  Val loss: -1.0568995524927514
Epoch 38
-------------------------------
Batch 1/64 loss: -0.844569206237793
Batch 2/64 loss: -1.621251106262207
Batch 3/64 loss: -0.9498920440673828
Batch 4/64 loss: -1.212510108947754
Batch 5/64 loss: -1.0503730773925781
Batch 6/64 loss: -1.2302217483520508
Batch 7/64 loss: -0.8953685760498047
Batch 8/64 loss: -0.8961019515991211
Batch 9/64 loss: -1.2159957885742188
Batch 10/64 loss: -0.9942235946655273
Batch 11/64 loss: -0.6526365280151367
Batch 12/64 loss: -1.2976226806640625
Batch 13/64 loss: -1.4038257598876953
Batch 14/64 loss: -1.0027837753295898
Batch 15/64 loss: -1.261800765991211
Batch 16/64 loss: -1.0198583602905273
Batch 17/64 loss: -0.9571628570556641
Batch 18/64 loss: -1.205134391784668
Batch 19/64 loss: -1.119614601135254
Batch 20/64 loss: -1.1150827407836914
Batch 21/64 loss: -1.2333135604858398
Batch 22/64 loss: -1.2546300888061523
Batch 23/64 loss: -1.3599128723144531
Batch 24/64 loss: -1.3958330154418945
Batch 25/64 loss: -1.3917264938354492
Batch 26/64 loss: -1.292832374572754
Batch 27/64 loss: -0.8967142105102539
Batch 28/64 loss: -1.4357414245605469
Batch 29/64 loss: -0.90679931640625
Batch 30/64 loss: -1.2410879135131836
Batch 31/64 loss: -0.8941402435302734
Batch 32/64 loss: -1.1549692153930664
Batch 33/64 loss: -1.1262435913085938
Batch 34/64 loss: -1.151529312133789
Batch 35/64 loss: -0.7020473480224609
Batch 36/64 loss: -0.9591922760009766
Batch 37/64 loss: -0.9599609375
Batch 38/64 loss: -0.8137779235839844
Batch 39/64 loss: -1.3211069107055664
Batch 40/64 loss: -1.0891332626342773
Batch 41/64 loss: -1.2398395538330078
Batch 42/64 loss: -1.0305919647216797
Batch 43/64 loss: -1.1415033340454102
Batch 44/64 loss: -0.7286977767944336
Batch 45/64 loss: -1.3391666412353516
Batch 46/64 loss: -0.9013833999633789
Batch 47/64 loss: -1.2147836685180664
Batch 48/64 loss: -0.8928842544555664
Batch 49/64 loss: -1.0356416702270508
Batch 50/64 loss: -1.2387971878051758
Batch 51/64 loss: -1.3602800369262695
Batch 52/64 loss: -0.8986063003540039
Batch 53/64 loss: -1.1661977767944336
Batch 54/64 loss: -1.3454866409301758
Batch 55/64 loss: -1.2035274505615234
Batch 56/64 loss: -1.190155029296875
Batch 57/64 loss: -1.2036676406860352
Batch 58/64 loss: -0.9675989151000977
Batch 59/64 loss: -1.3396844863891602
Batch 60/64 loss: -1.368875503540039
Batch 61/64 loss: -1.4347171783447266
Batch 62/64 loss: -1.3528118133544922
Batch 63/64 loss: -1.1996488571166992
Batch 64/64 loss: -5.642852783203125
Epoch 38  Train loss: -1.1851515078077128  Val loss: -1.3170572785577415
Saving best model, epoch: 38
Epoch 39
-------------------------------
Batch 1/64 loss: -1.4138364791870117
Batch 2/64 loss: -1.1470775604248047
Batch 3/64 loss: -1.3943395614624023
Batch 4/64 loss: -1.578434944152832
Batch 5/64 loss: -1.1276607513427734
Batch 6/64 loss: -1.128645896911621
Batch 7/64 loss: -1.5182380676269531
Batch 8/64 loss: -1.412491798400879
Batch 9/64 loss: -1.1243391036987305
Batch 10/64 loss: -1.4079351425170898
Batch 11/64 loss: -1.1100473403930664
Batch 12/64 loss: -0.8098611831665039
Batch 13/64 loss: -1.233372688293457
Batch 14/64 loss: -1.031367301940918
Batch 15/64 loss: -1.1721315383911133
Batch 16/64 loss: -0.9720096588134766
Batch 17/64 loss: -1.1543827056884766
Batch 18/64 loss: -1.1389141082763672
Batch 19/64 loss: -0.5287456512451172
Batch 20/64 loss: -1.042440414428711
Batch 21/64 loss: -1.0679616928100586
Batch 22/64 loss: -1.1047258377075195
Batch 23/64 loss: -1.3195838928222656
Batch 24/64 loss: -1.0394792556762695
Batch 25/64 loss: -0.9041862487792969
Batch 26/64 loss: -1.1008806228637695
Batch 27/64 loss: -1.1921405792236328
Batch 28/64 loss: -1.391927719116211
Batch 29/64 loss: -1.304194450378418
Batch 30/64 loss: -0.9184436798095703
Batch 31/64 loss: -0.8946361541748047
Batch 32/64 loss: -0.39215755462646484
Batch 33/64 loss: -0.9064397811889648
Batch 34/64 loss: -1.204371452331543
Batch 35/64 loss: -1.1625852584838867
Batch 36/64 loss: -1.2200593948364258
Batch 37/64 loss: -1.1294364929199219
Batch 38/64 loss: -1.1055307388305664
Batch 39/64 loss: -1.440993309020996
Batch 40/64 loss: -1.13665771484375
Batch 41/64 loss: -1.1327247619628906
Batch 42/64 loss: -0.8394002914428711
Batch 43/64 loss: -1.3132696151733398
Batch 44/64 loss: -1.38299560546875
Batch 45/64 loss: -1.620976448059082
Batch 46/64 loss: -1.4666967391967773
Batch 47/64 loss: -1.160843849182129
Batch 48/64 loss: -1.0813922882080078
Batch 49/64 loss: -0.536259651184082
Batch 50/64 loss: -1.0811767578125
Batch 51/64 loss: -1.3392486572265625
Batch 52/64 loss: -1.4013671875
Batch 53/64 loss: -1.1999168395996094
Batch 54/64 loss: -1.286747932434082
Batch 55/64 loss: -1.116063117980957
Batch 56/64 loss: -1.1300392150878906
Batch 57/64 loss: -1.2673139572143555
Batch 58/64 loss: -1.109665870666504
Batch 59/64 loss: -0.7048578262329102
Batch 60/64 loss: -1.013484001159668
Batch 61/64 loss: -1.6141138076782227
Batch 62/64 loss: -1.1459808349609375
Batch 63/64 loss: -0.9504833221435547
Batch 64/64 loss: -5.895040512084961
Epoch 39  Train loss: -1.2031209833481733  Val loss: -1.3453702893863428
Saving best model, epoch: 39
Epoch 40
-------------------------------
Batch 1/64 loss: -1.3294248580932617
Batch 2/64 loss: -1.242079734802246
Batch 3/64 loss: -1.5416326522827148
Batch 4/64 loss: -1.3828363418579102
Batch 5/64 loss: -1.176316261291504
Batch 6/64 loss: -1.1524581909179688
Batch 7/64 loss: -1.2768030166625977
Batch 8/64 loss: -0.8301992416381836
Batch 9/64 loss: -1.237264633178711
Batch 10/64 loss: -0.8673648834228516
Batch 11/64 loss: -1.4417362213134766
Batch 12/64 loss: -1.3147382736206055
Batch 13/64 loss: -1.1612300872802734
Batch 14/64 loss: -1.3384466171264648
Batch 15/64 loss: -1.3114051818847656
Batch 16/64 loss: -0.86212158203125
Batch 17/64 loss: -1.3532733917236328
Batch 18/64 loss: -1.350137710571289
Batch 19/64 loss: -1.1514358520507812
Batch 20/64 loss: -1.1154203414916992
Batch 21/64 loss: -1.4020700454711914
Batch 22/64 loss: -1.5085325241088867
Batch 23/64 loss: -1.3749971389770508
Batch 24/64 loss: -1.0523643493652344
Batch 25/64 loss: -1.196528434753418
Batch 26/64 loss: -1.415888786315918
Batch 27/64 loss: -0.12968730926513672
Batch 28/64 loss: -1.483755111694336
Batch 29/64 loss: -1.064375877380371
Batch 30/64 loss: -1.1055679321289062
Batch 31/64 loss: -1.3790264129638672
Batch 32/64 loss: -1.1381502151489258
Batch 33/64 loss: -1.6523246765136719
Batch 34/64 loss: -0.8853139877319336
Batch 35/64 loss: -0.9329118728637695
Batch 36/64 loss: -1.2471342086791992
Batch 37/64 loss: -1.1025161743164062
Batch 38/64 loss: -1.0594587326049805
Batch 39/64 loss: -1.2971391677856445
Batch 40/64 loss: -1.0755910873413086
Batch 41/64 loss: -1.0362958908081055
Batch 42/64 loss: -1.1192607879638672
Batch 43/64 loss: -1.0992021560668945
Batch 44/64 loss: -1.3563365936279297
Batch 45/64 loss: -0.9555253982543945
Batch 46/64 loss: -1.062657356262207
Batch 47/64 loss: -0.6283636093139648
Batch 48/64 loss: -1.155613899230957
Batch 49/64 loss: -1.488149642944336
Batch 50/64 loss: -1.1431560516357422
Batch 51/64 loss: -1.2101831436157227
Batch 52/64 loss: -1.6039352416992188
Batch 53/64 loss: -1.4870033264160156
Batch 54/64 loss: -1.2620973587036133
Batch 55/64 loss: -1.1398811340332031
Batch 56/64 loss: -1.0211257934570312
Batch 57/64 loss: -0.8461809158325195
Batch 58/64 loss: -1.0345592498779297
Batch 59/64 loss: -1.332284927368164
Batch 60/64 loss: -1.378861427307129
Batch 61/64 loss: -1.5057010650634766
Batch 62/64 loss: -1.0339860916137695
Batch 63/64 loss: -1.2896509170532227
Batch 64/64 loss: -5.73470401763916
Epoch 40  Train loss: -1.2459717507455863  Val loss: -1.3748094617705984
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: -1.0644502639770508
Batch 2/64 loss: -1.4904918670654297
Batch 3/64 loss: -1.4782304763793945
Batch 4/64 loss: -1.4274711608886719
Batch 5/64 loss: -1.0453195571899414
Batch 6/64 loss: -1.1634483337402344
Batch 7/64 loss: -1.2699041366577148
Batch 8/64 loss: -0.9691801071166992
Batch 9/64 loss: -1.000131607055664
Batch 10/64 loss: -1.4207801818847656
Batch 11/64 loss: -0.42850494384765625
Batch 12/64 loss: -1.3504562377929688
Batch 13/64 loss: -0.25840187072753906
Batch 14/64 loss: -1.2166547775268555
Batch 15/64 loss: -1.263279914855957
Batch 16/64 loss: -1.3724336624145508
Batch 17/64 loss: -1.4024372100830078
Batch 18/64 loss: -0.19380760192871094
Batch 19/64 loss: -1.1334056854248047
Batch 20/64 loss: -0.8596744537353516
Batch 21/64 loss: -0.8708362579345703
Batch 22/64 loss: -1.4247627258300781
Batch 23/64 loss: -1.2479009628295898
Batch 24/64 loss: -1.0174674987792969
Batch 25/64 loss: -1.292673110961914
Batch 26/64 loss: -1.0105762481689453
Batch 27/64 loss: -0.1965036392211914
Batch 28/64 loss: -1.3087396621704102
Batch 29/64 loss: -1.0527448654174805
Batch 30/64 loss: -1.325770378112793
Batch 31/64 loss: -1.2745256423950195
Batch 32/64 loss: -0.8961277008056641
Batch 33/64 loss: -1.1288070678710938
Batch 34/64 loss: -1.1181020736694336
Batch 35/64 loss: -1.1626472473144531
Batch 36/64 loss: -0.9935407638549805
Batch 37/64 loss: -1.1070852279663086
Batch 38/64 loss: -1.2777023315429688
Batch 39/64 loss: -0.8038425445556641
Batch 40/64 loss: -0.947728157043457
Batch 41/64 loss: -0.8302831649780273
Batch 42/64 loss: -1.440333366394043
Batch 43/64 loss: -0.9849414825439453
Batch 44/64 loss: -0.5601339340209961
Batch 45/64 loss: -1.094858169555664
Batch 46/64 loss: -0.9542665481567383
Batch 47/64 loss: -1.1482524871826172
Batch 48/64 loss: -1.057241439819336
Batch 49/64 loss: -1.3430614471435547
Batch 50/64 loss: -1.3335046768188477
Batch 51/64 loss: -0.9419116973876953
Batch 52/64 loss: -1.4332590103149414
Batch 53/64 loss: -1.5164594650268555
Batch 54/64 loss: -1.051896095275879
Batch 55/64 loss: -0.8200054168701172
Batch 56/64 loss: -1.3065271377563477
Batch 57/64 loss: -1.3625516891479492
Batch 58/64 loss: -1.2986774444580078
Batch 59/64 loss: -0.6928806304931641
Batch 60/64 loss: -1.1070899963378906
Batch 61/64 loss: -1.046163558959961
Batch 62/64 loss: -1.3603239059448242
Batch 63/64 loss: -1.1225042343139648
Batch 64/64 loss: -5.757457733154297
Epoch 41  Train loss: -1.1512434267530254  Val loss: -1.377216588180909
Saving best model, epoch: 41
Epoch 42
-------------------------------
Batch 1/64 loss: -1.385817527770996
Batch 2/64 loss: -1.0078649520874023
Batch 3/64 loss: -1.576547622680664
Batch 4/64 loss: -1.4220962524414062
Batch 5/64 loss: -0.9467411041259766
Batch 6/64 loss: -0.685246467590332
Batch 7/64 loss: -1.1558151245117188
Batch 8/64 loss: -1.5817975997924805
Batch 9/64 loss: -1.3492488861083984
Batch 10/64 loss: -1.1830196380615234
Batch 11/64 loss: -1.1368818283081055
Batch 12/64 loss: -0.3759298324584961
Batch 13/64 loss: -1.4802656173706055
Batch 14/64 loss: -1.6302566528320312
Batch 15/64 loss: -1.347146987915039
Batch 16/64 loss: -1.2451295852661133
Batch 17/64 loss: -1.0849475860595703
Batch 18/64 loss: -1.3818683624267578
Batch 19/64 loss: -0.8163366317749023
Batch 20/64 loss: -1.283315658569336
Batch 21/64 loss: -1.0438308715820312
Batch 22/64 loss: -1.3613834381103516
Batch 23/64 loss: -1.1430244445800781
Batch 24/64 loss: -1.637002944946289
Batch 25/64 loss: -0.6906099319458008
Batch 26/64 loss: -1.4895133972167969
Batch 27/64 loss: -1.0968866348266602
Batch 28/64 loss: -1.1542930603027344
Batch 29/64 loss: -1.1966161727905273
Batch 30/64 loss: -1.6119928359985352
Batch 31/64 loss: -0.4668588638305664
Batch 32/64 loss: -1.4009122848510742
Batch 33/64 loss: -1.0566558837890625
Batch 34/64 loss: -1.1438121795654297
Batch 35/64 loss: -1.5037555694580078
Batch 36/64 loss: -1.0575265884399414
Batch 37/64 loss: -1.082697868347168
Batch 38/64 loss: -1.043783187866211
Batch 39/64 loss: -0.8288106918334961
Batch 40/64 loss: -1.1878700256347656
Batch 41/64 loss: -0.8032741546630859
Batch 42/64 loss: -1.2451915740966797
Batch 43/64 loss: -1.3372697830200195
Batch 44/64 loss: -0.9864616394042969
Batch 45/64 loss: -0.6635141372680664
Batch 46/64 loss: -1.0562992095947266
Batch 47/64 loss: -0.9959144592285156
Batch 48/64 loss: -1.503122329711914
Batch 49/64 loss: -1.3272714614868164
Batch 50/64 loss: -1.3623075485229492
Batch 51/64 loss: -0.8178071975708008
Batch 52/64 loss: -1.0994691848754883
Batch 53/64 loss: -1.206345558166504
Batch 54/64 loss: -1.1131200790405273
Batch 55/64 loss: -1.251943588256836
Batch 56/64 loss: -1.3159608840942383
Batch 57/64 loss: -1.461277961730957
Batch 58/64 loss: -0.917327880859375
Batch 59/64 loss: -0.7606945037841797
Batch 60/64 loss: -1.105332374572754
Batch 61/64 loss: -1.2616653442382812
Batch 62/64 loss: -1.1814289093017578
Batch 63/64 loss: -1.0476293563842773
Batch 64/64 loss: -5.820408821105957
Epoch 42  Train loss: -1.2150595534081552  Val loss: -1.3549200759310902
Epoch 43
-------------------------------
Batch 1/64 loss: -0.8942232131958008
Batch 2/64 loss: -1.592447280883789
Batch 3/64 loss: -1.6348857879638672
Batch 4/64 loss: -1.4903335571289062
Batch 5/64 loss: -1.3270511627197266
Batch 6/64 loss: -1.0573396682739258
Batch 7/64 loss: -0.7475786209106445
Batch 8/64 loss: -1.3779306411743164
Batch 9/64 loss: -1.231337547302246
Batch 10/64 loss: -1.437124252319336
Batch 11/64 loss: -1.12164306640625
Batch 12/64 loss: -0.949951171875
Batch 13/64 loss: -0.9397611618041992
Batch 14/64 loss: -1.1645784378051758
Batch 15/64 loss: -1.258871078491211
Batch 16/64 loss: -0.7637462615966797
Batch 17/64 loss: -0.8516750335693359
Batch 18/64 loss: -1.4947853088378906
Batch 19/64 loss: -1.4059219360351562
Batch 20/64 loss: -1.0196495056152344
Batch 21/64 loss: -1.086954116821289
Batch 22/64 loss: -1.5800189971923828
Batch 23/64 loss: -0.9389286041259766
Batch 24/64 loss: -0.9636363983154297
Batch 25/64 loss: -1.2817001342773438
Batch 26/64 loss: -1.3667535781860352
Batch 27/64 loss: -1.37542724609375
Batch 28/64 loss: -1.5036420822143555
Batch 29/64 loss: -1.2703218460083008
Batch 30/64 loss: -1.061478614807129
Batch 31/64 loss: -1.1517829895019531
Batch 32/64 loss: -1.4319744110107422
Batch 33/64 loss: -1.2254400253295898
Batch 34/64 loss: -1.2874412536621094
Batch 35/64 loss: -1.2280817031860352
Batch 36/64 loss: -1.2309989929199219
Batch 37/64 loss: -1.278212547302246
Batch 38/64 loss: -1.260331153869629
Batch 39/64 loss: -1.2833642959594727
Batch 40/64 loss: -1.1647872924804688
Batch 41/64 loss: -1.4970006942749023
Batch 42/64 loss: -1.3675594329833984
Batch 43/64 loss: -1.1912307739257812
Batch 44/64 loss: -1.434061050415039
Batch 45/64 loss: -1.0514554977416992
Batch 46/64 loss: -1.4779653549194336
Batch 47/64 loss: -0.8726701736450195
Batch 48/64 loss: -1.4118366241455078
Batch 49/64 loss: -1.3570528030395508
Batch 50/64 loss: -1.195486068725586
Batch 51/64 loss: -1.406118392944336
Batch 52/64 loss: -1.3665170669555664
Batch 53/64 loss: -1.1977062225341797
Batch 54/64 loss: -1.289717674255371
Batch 55/64 loss: -1.5231637954711914
Batch 56/64 loss: -1.6985960006713867
Batch 57/64 loss: -1.4864921569824219
Batch 58/64 loss: -1.4783124923706055
Batch 59/64 loss: -1.4044857025146484
Batch 60/64 loss: -1.528132438659668
Batch 61/64 loss: -1.307927131652832
Batch 62/64 loss: -1.4781770706176758
Batch 63/64 loss: -1.0948572158813477
Batch 64/64 loss: -5.829133987426758
Epoch 43  Train loss: -1.3211056204403149  Val loss: -1.4954505867974455
Saving best model, epoch: 43
Epoch 44
-------------------------------
Batch 1/64 loss: -1.5535898208618164
Batch 2/64 loss: -1.233865737915039
Batch 3/64 loss: -1.2030830383300781
Batch 4/64 loss: -1.5827665328979492
Batch 5/64 loss: -1.474452018737793
Batch 6/64 loss: -1.0017051696777344
Batch 7/64 loss: -0.954249382019043
Batch 8/64 loss: -1.4174108505249023
Batch 9/64 loss: -1.4098625183105469
Batch 10/64 loss: -1.5216255187988281
Batch 11/64 loss: -1.4735727310180664
Batch 12/64 loss: -1.1427001953125
Batch 13/64 loss: -1.2934598922729492
Batch 14/64 loss: -1.2388362884521484
Batch 15/64 loss: -1.106527328491211
Batch 16/64 loss: -0.8370609283447266
Batch 17/64 loss: -1.203221321105957
Batch 18/64 loss: -1.4309921264648438
Batch 19/64 loss: -1.467137336730957
Batch 20/64 loss: -1.6496601104736328
Batch 21/64 loss: -1.5027456283569336
Batch 22/64 loss: -1.4546356201171875
Batch 23/64 loss: -1.676492691040039
Batch 24/64 loss: -1.6414308547973633
Batch 25/64 loss: -1.4887399673461914
Batch 26/64 loss: -1.2021293640136719
Batch 27/64 loss: -1.459406852722168
Batch 28/64 loss: -1.1627206802368164
Batch 29/64 loss: -1.494131088256836
Batch 30/64 loss: -1.4939250946044922
Batch 31/64 loss: -0.6451120376586914
Batch 32/64 loss: -1.3008975982666016
Batch 33/64 loss: -1.358163833618164
Batch 34/64 loss: -1.2345619201660156
Batch 35/64 loss: -1.3999090194702148
Batch 36/64 loss: -1.2761850357055664
Batch 37/64 loss: -1.2336130142211914
Batch 38/64 loss: -0.6221818923950195
Batch 39/64 loss: -0.9189186096191406
Batch 40/64 loss: -1.2170648574829102
Batch 41/64 loss: -1.342529296875
Batch 42/64 loss: -1.2609310150146484
Batch 43/64 loss: -0.7882299423217773
Batch 44/64 loss: -1.460667610168457
Batch 45/64 loss: -1.519693374633789
Batch 46/64 loss: -1.4223709106445312
Batch 47/64 loss: -1.2289543151855469
Batch 48/64 loss: -1.5722436904907227
Batch 49/64 loss: -1.4775276184082031
Batch 50/64 loss: -0.9024543762207031
Batch 51/64 loss: -1.1857175827026367
Batch 52/64 loss: -1.3319435119628906
Batch 53/64 loss: -1.1700496673583984
Batch 54/64 loss: -1.5702171325683594
Batch 55/64 loss: -1.407242774963379
Batch 56/64 loss: -1.3893632888793945
Batch 57/64 loss: -1.2001733779907227
Batch 58/64 loss: -0.9999418258666992
Batch 59/64 loss: -0.7847137451171875
Batch 60/64 loss: -1.5014629364013672
Batch 61/64 loss: -1.3396692276000977
Batch 62/64 loss: -1.0141048431396484
Batch 63/64 loss: -0.8501949310302734
Batch 64/64 loss: -5.485494613647461
Epoch 44  Train loss: -1.3304041170606427  Val loss: -1.2147965709778041
Epoch 45
-------------------------------
Batch 1/64 loss: -1.3023452758789062
Batch 2/64 loss: -0.7456541061401367
Batch 3/64 loss: -0.9137477874755859
Batch 4/64 loss: -1.393651008605957
Batch 5/64 loss: -1.2233762741088867
Batch 6/64 loss: -1.419234275817871
Batch 7/64 loss: -0.8801145553588867
Batch 8/64 loss: -0.848963737487793
Batch 9/64 loss: -1.266190528869629
Batch 10/64 loss: -1.484811782836914
Batch 11/64 loss: -1.1408977508544922
Batch 12/64 loss: -1.195648193359375
Batch 13/64 loss: -1.624018669128418
Batch 14/64 loss: -1.3827857971191406
Batch 15/64 loss: -1.434971809387207
Batch 16/64 loss: -1.3517932891845703
Batch 17/64 loss: -1.448552131652832
Batch 18/64 loss: -0.7635583877563477
Batch 19/64 loss: -1.4497547149658203
Batch 20/64 loss: -1.2203760147094727
Batch 21/64 loss: -1.1861467361450195
Batch 22/64 loss: -1.3829631805419922
Batch 23/64 loss: -0.9427804946899414
Batch 24/64 loss: -1.346480369567871
Batch 25/64 loss: -1.3002796173095703
Batch 26/64 loss: -1.0320940017700195
Batch 27/64 loss: -1.2031240463256836
Batch 28/64 loss: -1.2476110458374023
Batch 29/64 loss: -1.3059272766113281
Batch 30/64 loss: -1.6394319534301758
Batch 31/64 loss: -1.2702093124389648
Batch 32/64 loss: -1.3397998809814453
Batch 33/64 loss: -1.6778984069824219
Batch 34/64 loss: -1.3416109085083008
Batch 35/64 loss: -1.2667121887207031
Batch 36/64 loss: -1.503096580505371
Batch 37/64 loss: -1.1488094329833984
Batch 38/64 loss: -1.3979167938232422
Batch 39/64 loss: -1.4548730850219727
Batch 40/64 loss: -1.356424331665039
Batch 41/64 loss: -1.2760486602783203
Batch 42/64 loss: -1.4858074188232422
Batch 43/64 loss: -1.4126720428466797
Batch 44/64 loss: -1.2985620498657227
Batch 45/64 loss: -1.0633525848388672
Batch 46/64 loss: -1.1976385116577148
Batch 47/64 loss: -1.0644922256469727
Batch 48/64 loss: -1.3883113861083984
Batch 49/64 loss: -1.4004497528076172
Batch 50/64 loss: -1.217982292175293
Batch 51/64 loss: -1.3701047897338867
Batch 52/64 loss: -1.5121641159057617
Batch 53/64 loss: -1.2000741958618164
Batch 54/64 loss: -1.6282539367675781
Batch 55/64 loss: -1.5612850189208984
Batch 56/64 loss: -1.4488649368286133
Batch 57/64 loss: -1.0569849014282227
Batch 58/64 loss: -1.5986595153808594
Batch 59/64 loss: -0.9464340209960938
Batch 60/64 loss: -1.1980915069580078
Batch 61/64 loss: -1.035055160522461
Batch 62/64 loss: -0.9897575378417969
Batch 63/64 loss: -1.5352067947387695
Batch 64/64 loss: -5.668127059936523
Epoch 45  Train loss: -1.3328938727285349  Val loss: -1.2558311514838045
Epoch 46
-------------------------------
Batch 1/64 loss: -1.5100765228271484
Batch 2/64 loss: -1.2092523574829102
Batch 3/64 loss: -1.145228385925293
Batch 4/64 loss: -1.0834426879882812
Batch 5/64 loss: -1.1642513275146484
Batch 6/64 loss: -1.4170818328857422
Batch 7/64 loss: -1.1868715286254883
Batch 8/64 loss: -1.3930644989013672
Batch 9/64 loss: -1.2758541107177734
Batch 10/64 loss: -1.683293342590332
Batch 11/64 loss: -1.4068145751953125
Batch 12/64 loss: -1.4573230743408203
Batch 13/64 loss: -1.0470008850097656
Batch 14/64 loss: -1.599905014038086
Batch 15/64 loss: -1.4734230041503906
Batch 16/64 loss: -1.468613624572754
Batch 17/64 loss: -1.2660045623779297
Batch 18/64 loss: -1.478062629699707
Batch 19/64 loss: -1.2699823379516602
Batch 20/64 loss: -1.1917400360107422
Batch 21/64 loss: -1.2241172790527344
Batch 22/64 loss: -1.0774641036987305
Batch 23/64 loss: -1.0868721008300781
Batch 24/64 loss: -1.2782936096191406
Batch 25/64 loss: -1.3951139450073242
Batch 26/64 loss: -0.8463659286499023
Batch 27/64 loss: -1.3360090255737305
Batch 28/64 loss: -1.3611335754394531
Batch 29/64 loss: -1.0097942352294922
Batch 30/64 loss: -1.2757806777954102
Batch 31/64 loss: -1.3557968139648438
Batch 32/64 loss: -1.327352523803711
Batch 33/64 loss: -1.4035253524780273
Batch 34/64 loss: -0.6344709396362305
Batch 35/64 loss: -1.5445528030395508
Batch 36/64 loss: -1.4233951568603516
Batch 37/64 loss: -1.0930118560791016
Batch 38/64 loss: -1.2906732559204102
Batch 39/64 loss: -1.0772933959960938
Batch 40/64 loss: -1.6484365463256836
Batch 41/64 loss: -1.5289134979248047
Batch 42/64 loss: -1.6690053939819336
Batch 43/64 loss: -1.3913793563842773
Batch 44/64 loss: -1.3476715087890625
Batch 45/64 loss: -1.4873552322387695
Batch 46/64 loss: -1.3086938858032227
Batch 47/64 loss: -0.7936277389526367
Batch 48/64 loss: -1.1689176559448242
Batch 49/64 loss: -0.9317512512207031
Batch 50/64 loss: -0.6391754150390625
Batch 51/64 loss: -1.516672134399414
Batch 52/64 loss: -1.5488700866699219
Batch 53/64 loss: -1.5637283325195312
Batch 54/64 loss: -1.145646095275879
Batch 55/64 loss: -1.1503448486328125
Batch 56/64 loss: -1.2873353958129883
Batch 57/64 loss: -1.2048406600952148
Batch 58/64 loss: -1.371419906616211
Batch 59/64 loss: -1.6102781295776367
Batch 60/64 loss: -1.183547019958496
Batch 61/64 loss: -1.5416231155395508
Batch 62/64 loss: -1.3075323104858398
Batch 63/64 loss: -0.7897806167602539
Batch 64/64 loss: -5.366096496582031
Epoch 46  Train loss: -1.3322262184292661  Val loss: -1.1390031244336944
Epoch 47
-------------------------------
Batch 1/64 loss: -1.2479658126831055
Batch 2/64 loss: -0.7534666061401367
Batch 3/64 loss: -0.8826713562011719
Batch 4/64 loss: -1.1517934799194336
Batch 5/64 loss: -1.0790672302246094
Batch 6/64 loss: -1.1338882446289062
Batch 7/64 loss: -0.9238309860229492
Batch 8/64 loss: -1.557077407836914
Batch 9/64 loss: -1.157771110534668
Batch 10/64 loss: -1.3398962020874023
Batch 11/64 loss: -1.560323715209961
Batch 12/64 loss: -1.12152099609375
Batch 13/64 loss: -1.557337760925293
Batch 14/64 loss: -1.4418907165527344
Batch 15/64 loss: -1.3891363143920898
Batch 16/64 loss: -1.0762948989868164
Batch 17/64 loss: -1.4398746490478516
Batch 18/64 loss: -1.6801156997680664
Batch 19/64 loss: -1.080521583557129
Batch 20/64 loss: -1.2572460174560547
Batch 21/64 loss: -0.9155435562133789
Batch 22/64 loss: -1.5774097442626953
Batch 23/64 loss: -1.3646860122680664
Batch 24/64 loss: -1.4621706008911133
Batch 25/64 loss: -0.7021980285644531
Batch 26/64 loss: -1.2117528915405273
Batch 27/64 loss: -1.5412559509277344
Batch 28/64 loss: -1.4843482971191406
Batch 29/64 loss: -1.6191596984863281
Batch 30/64 loss: -1.7386531829833984
Batch 31/64 loss: -1.4722604751586914
Batch 32/64 loss: -1.4132394790649414
Batch 33/64 loss: -1.1044578552246094
Batch 34/64 loss: -1.101400375366211
Batch 35/64 loss: -1.518503189086914
Batch 36/64 loss: -1.709122657775879
Batch 37/64 loss: -1.5879011154174805
Batch 38/64 loss: -1.484471321105957
Batch 39/64 loss: -0.7945156097412109
Batch 40/64 loss: -1.3089609146118164
Batch 41/64 loss: -1.3599061965942383
Batch 42/64 loss: -0.7658023834228516
Batch 43/64 loss: -1.6218194961547852
Batch 44/64 loss: -1.0867557525634766
Batch 45/64 loss: -1.5321483612060547
Batch 46/64 loss: -1.3583717346191406
Batch 47/64 loss: -1.512711524963379
Batch 48/64 loss: -1.6576414108276367
Batch 49/64 loss: -1.1753101348876953
Batch 50/64 loss: -1.5438804626464844
Batch 51/64 loss: -1.4511775970458984
Batch 52/64 loss: -1.3823728561401367
Batch 53/64 loss: -1.5662107467651367
Batch 54/64 loss: -1.4950075149536133
Batch 55/64 loss: -1.1634883880615234
Batch 56/64 loss: -1.1443042755126953
Batch 57/64 loss: -0.9493474960327148
Batch 58/64 loss: -1.542189598083496
Batch 59/64 loss: -1.6600332260131836
Batch 60/64 loss: -1.59619140625
Batch 61/64 loss: -1.4460573196411133
Batch 62/64 loss: -1.4697065353393555
Batch 63/64 loss: -1.3430185317993164
Batch 64/64 loss: -5.805754661560059
Epoch 47  Train loss: -1.3822975794474284  Val loss: -1.5730676421594783
Saving best model, epoch: 47
Epoch 48
-------------------------------
Batch 1/64 loss: -1.501957893371582
Batch 2/64 loss: -1.0653409957885742
Batch 3/64 loss: -1.6140975952148438
Batch 4/64 loss: -1.6828384399414062
Batch 5/64 loss: -1.4854345321655273
Batch 6/64 loss: -1.1000995635986328
Batch 7/64 loss: -1.1168403625488281
Batch 8/64 loss: -1.2413911819458008
Batch 9/64 loss: -1.421499252319336
Batch 10/64 loss: -1.3240203857421875
Batch 11/64 loss: -1.5465660095214844
Batch 12/64 loss: -1.357295036315918
Batch 13/64 loss: -1.1480960845947266
Batch 14/64 loss: -1.1235103607177734
Batch 15/64 loss: -0.9647798538208008
Batch 16/64 loss: -1.3974504470825195
Batch 17/64 loss: -1.5642690658569336
Batch 18/64 loss: -1.108774185180664
Batch 19/64 loss: -1.5734834671020508
Batch 20/64 loss: -0.9475374221801758
Batch 21/64 loss: -1.1150398254394531
Batch 22/64 loss: -1.4718828201293945
Batch 23/64 loss: -1.4987850189208984
Batch 24/64 loss: -1.4968194961547852
Batch 25/64 loss: -1.3388452529907227
Batch 26/64 loss: -0.9648666381835938
Batch 27/64 loss: -0.8843584060668945
Batch 28/64 loss: -1.204925537109375
Batch 29/64 loss: -1.239069938659668
Batch 30/64 loss: -1.1684894561767578
Batch 31/64 loss: -1.3374967575073242
Batch 32/64 loss: -1.5245838165283203
Batch 33/64 loss: -1.0986356735229492
Batch 34/64 loss: -1.0900936126708984
Batch 35/64 loss: -1.206273078918457
Batch 36/64 loss: -1.5688152313232422
Batch 37/64 loss: -1.081618309020996
Batch 38/64 loss: -1.1414670944213867
Batch 39/64 loss: -1.2556390762329102
Batch 40/64 loss: -1.5846681594848633
Batch 41/64 loss: -1.587956428527832
Batch 42/64 loss: -1.8052940368652344
Batch 43/64 loss: -1.329376220703125
Batch 44/64 loss: -1.0598840713500977
Batch 45/64 loss: -1.4484167098999023
Batch 46/64 loss: -1.3395204544067383
Batch 47/64 loss: -1.5757675170898438
Batch 48/64 loss: -1.2504606246948242
Batch 49/64 loss: -1.5653629302978516
Batch 50/64 loss: -1.4768953323364258
Batch 51/64 loss: -0.7918062210083008
Batch 52/64 loss: -1.5191783905029297
Batch 53/64 loss: -0.7057485580444336
Batch 54/64 loss: -1.4078617095947266
Batch 55/64 loss: -1.4714746475219727
Batch 56/64 loss: -1.0233268737792969
Batch 57/64 loss: -1.2746381759643555
Batch 58/64 loss: -1.5560789108276367
Batch 59/64 loss: -1.3074579238891602
Batch 60/64 loss: -1.2851495742797852
Batch 61/64 loss: -0.8563718795776367
Batch 62/64 loss: -1.4961967468261719
Batch 63/64 loss: -1.5541343688964844
Batch 64/64 loss: -5.364793300628662
Epoch 48  Train loss: -1.3532487626169243  Val loss: -1.386570540490429
Epoch 49
-------------------------------
Batch 1/64 loss: -1.422978401184082
Batch 2/64 loss: -1.123896598815918
Batch 3/64 loss: -1.5797271728515625
Batch 4/64 loss: -1.454524040222168
Batch 5/64 loss: -1.3442611694335938
Batch 6/64 loss: -1.2985105514526367
Batch 7/64 loss: -0.9678688049316406
Batch 8/64 loss: -0.8164339065551758
Batch 9/64 loss: -1.2256393432617188
Batch 10/64 loss: -1.2986993789672852
Batch 11/64 loss: -1.2556066513061523
Batch 12/64 loss: -1.582259178161621
Batch 13/64 loss: -1.4047813415527344
Batch 14/64 loss: -1.5144157409667969
Batch 15/64 loss: -0.6682729721069336
Batch 16/64 loss: -1.4568252563476562
Batch 17/64 loss: -1.4938554763793945
Batch 18/64 loss: -1.6633071899414062
Batch 19/64 loss: -1.047307014465332
Batch 20/64 loss: -0.7339801788330078
Batch 21/64 loss: -1.073629379272461
Batch 22/64 loss: -1.3889045715332031
Batch 23/64 loss: -1.420506477355957
Batch 24/64 loss: -1.3172740936279297
Batch 25/64 loss: -1.3593368530273438
Batch 26/64 loss: -1.3325157165527344
Batch 27/64 loss: -1.3722124099731445
Batch 28/64 loss: -1.3557710647583008
Batch 29/64 loss: -1.145857810974121
Batch 30/64 loss: -1.0271720886230469
Batch 31/64 loss: -1.4481878280639648
Batch 32/64 loss: -1.3070030212402344
Batch 33/64 loss: -1.6927375793457031
Batch 34/64 loss: -1.5433778762817383
Batch 35/64 loss: -1.6699743270874023
Batch 36/64 loss: -1.2073278427124023
Batch 37/64 loss: -1.5764350891113281
Batch 38/64 loss: -1.4717559814453125
Batch 39/64 loss: -1.117903709411621
Batch 40/64 loss: -1.6826171875
Batch 41/64 loss: -1.5239582061767578
Batch 42/64 loss: -1.3374929428100586
Batch 43/64 loss: -1.510451316833496
Batch 44/64 loss: -1.3961114883422852
Batch 45/64 loss: -1.59130859375
Batch 46/64 loss: -1.5524215698242188
Batch 47/64 loss: -0.6860027313232422
Batch 48/64 loss: -1.261845588684082
Batch 49/64 loss: -1.2370624542236328
Batch 50/64 loss: -0.9751033782958984
Batch 51/64 loss: -1.0666732788085938
Batch 52/64 loss: -0.8975954055786133
Batch 53/64 loss: -1.0957880020141602
Batch 54/64 loss: -1.308943748474121
Batch 55/64 loss: -1.1943540573120117
Batch 56/64 loss: -1.0657844543457031
Batch 57/64 loss: -1.2216577529907227
Batch 58/64 loss: -1.2402334213256836
Batch 59/64 loss: -1.3917665481567383
Batch 60/64 loss: -1.3561792373657227
Batch 61/64 loss: -1.1522588729858398
Batch 62/64 loss: -1.4804821014404297
Batch 63/64 loss: -1.207864761352539
Batch 64/64 loss: -5.3204665184021
Epoch 49  Train loss: -1.3428288796368768  Val loss: -1.455255711611194
Epoch 50
-------------------------------
Batch 1/64 loss: -1.2632513046264648
Batch 2/64 loss: -1.5005664825439453
Batch 3/64 loss: -1.4319334030151367
Batch 4/64 loss: -1.5384693145751953
Batch 5/64 loss: -1.7395973205566406
Batch 6/64 loss: -1.4544744491577148
Batch 7/64 loss: -1.246490478515625
Batch 8/64 loss: -0.567042350769043
Batch 9/64 loss: -1.3323392868041992
Batch 10/64 loss: -1.4364328384399414
Batch 11/64 loss: -1.346970558166504
Batch 12/64 loss: -1.707000732421875
Batch 13/64 loss: -1.5160284042358398
Batch 14/64 loss: -1.6124649047851562
Batch 15/64 loss: -1.3890199661254883
Batch 16/64 loss: -1.3704376220703125
Batch 17/64 loss: -1.4416389465332031
Batch 18/64 loss: -1.692774772644043
Batch 19/64 loss: -1.2498855590820312
Batch 20/64 loss: -1.6168947219848633
Batch 21/64 loss: -1.106863021850586
Batch 22/64 loss: -1.0992727279663086
Batch 23/64 loss: -1.4869298934936523
Batch 24/64 loss: -1.2121610641479492
Batch 25/64 loss: -1.649810791015625
Batch 26/64 loss: -1.274892807006836
Batch 27/64 loss: -1.5582695007324219
Batch 28/64 loss: -0.6617965698242188
Batch 29/64 loss: -1.4329204559326172
Batch 30/64 loss: -1.4602985382080078
Batch 31/64 loss: -1.623250961303711
Batch 32/64 loss: -1.0303239822387695
Batch 33/64 loss: -1.245809555053711
Batch 34/64 loss: -1.4643001556396484
Batch 35/64 loss: -1.4662361145019531
Batch 36/64 loss: -1.6509809494018555
Batch 37/64 loss: -1.3941993713378906
Batch 38/64 loss: -1.2836856842041016
Batch 39/64 loss: -1.2777605056762695
Batch 40/64 loss: -1.2641830444335938
Batch 41/64 loss: -1.6466550827026367
Batch 42/64 loss: -1.6006431579589844
Batch 43/64 loss: -0.9680690765380859
Batch 44/64 loss: -1.4120569229125977
Batch 45/64 loss: -1.252120018005371
Batch 46/64 loss: -1.4898109436035156
Batch 47/64 loss: -1.3276214599609375
Batch 48/64 loss: -1.4241714477539062
Batch 49/64 loss: -1.1961708068847656
Batch 50/64 loss: -1.4525909423828125
Batch 51/64 loss: -1.5576467514038086
Batch 52/64 loss: -1.4452791213989258
Batch 53/64 loss: -1.421696662902832
Batch 54/64 loss: -1.657379150390625
Batch 55/64 loss: -1.3603439331054688
Batch 56/64 loss: -1.137430191040039
Batch 57/64 loss: -1.6566734313964844
Batch 58/64 loss: -1.7133188247680664
Batch 59/64 loss: -1.4811687469482422
Batch 60/64 loss: -0.9118566513061523
Batch 61/64 loss: -1.4998054504394531
Batch 62/64 loss: -1.3481388092041016
Batch 63/64 loss: -1.5416650772094727
Batch 64/64 loss: -5.949614524841309
Epoch 50  Train loss: -1.4441126692528818  Val loss: -1.4075256295220548
Epoch 51
-------------------------------
Batch 1/64 loss: -1.2071495056152344
Batch 2/64 loss: -1.3630390167236328
Batch 3/64 loss: -1.1498527526855469
Batch 4/64 loss: -1.3185768127441406
Batch 5/64 loss: -1.2604923248291016
Batch 6/64 loss: -1.4933700561523438
Batch 7/64 loss: -1.7661504745483398
Batch 8/64 loss: -0.9024467468261719
Batch 9/64 loss: -1.450296401977539
Batch 10/64 loss: -1.26055908203125
Batch 11/64 loss: -1.4768552780151367
Batch 12/64 loss: -1.6736383438110352
Batch 13/64 loss: -1.5276679992675781
Batch 14/64 loss: -1.4671392440795898
Batch 15/64 loss: -1.4481096267700195
Batch 16/64 loss: -1.2836761474609375
Batch 17/64 loss: -1.3509397506713867
Batch 18/64 loss: -1.4244089126586914
Batch 19/64 loss: -1.519160270690918
Batch 20/64 loss: -1.6713342666625977
Batch 21/64 loss: -1.3201570510864258
Batch 22/64 loss: -1.6608476638793945
Batch 23/64 loss: -1.183485984802246
Batch 24/64 loss: -1.5082769393920898
Batch 25/64 loss: -1.4942169189453125
Batch 26/64 loss: -1.6076250076293945
Batch 27/64 loss: -1.7046594619750977
Batch 28/64 loss: -1.6113500595092773
Batch 29/64 loss: -1.1506319046020508
Batch 30/64 loss: -0.8643674850463867
Batch 31/64 loss: -1.7126178741455078
Batch 32/64 loss: -1.4625787734985352
Batch 33/64 loss: -1.324997901916504
Batch 34/64 loss: -1.7916650772094727
Batch 35/64 loss: -1.4346122741699219
Batch 36/64 loss: -1.6759023666381836
Batch 37/64 loss: -1.3443822860717773
Batch 38/64 loss: -1.3349609375
Batch 39/64 loss: -1.2424116134643555
Batch 40/64 loss: -1.5662107467651367
Batch 41/64 loss: -1.6695871353149414
Batch 42/64 loss: -1.7887868881225586
Batch 43/64 loss: -1.3186349868774414
Batch 44/64 loss: -1.4745206832885742
Batch 45/64 loss: -1.498159408569336
Batch 46/64 loss: -1.1167287826538086
Batch 47/64 loss: -1.6119346618652344
Batch 48/64 loss: -1.5996789932250977
Batch 49/64 loss: -1.6868515014648438
Batch 50/64 loss: -1.4952106475830078
Batch 51/64 loss: -1.543722152709961
Batch 52/64 loss: -1.2803211212158203
Batch 53/64 loss: -1.434305191040039
Batch 54/64 loss: -1.7587976455688477
Batch 55/64 loss: -1.6521930694580078
Batch 56/64 loss: -0.9163732528686523
Batch 57/64 loss: -1.5077943801879883
Batch 58/64 loss: -1.4237346649169922
Batch 59/64 loss: -1.489729881286621
Batch 60/64 loss: -1.7202835083007812
Batch 61/64 loss: -1.3576126098632812
Batch 62/64 loss: -1.3473644256591797
Batch 63/64 loss: -1.580674171447754
Batch 64/64 loss: -5.304417610168457
Epoch 51  Train loss: -1.4943079892326803  Val loss: -1.3809548997387444
Epoch 52
-------------------------------
Batch 1/64 loss: -1.5352325439453125
Batch 2/64 loss: -1.5691795349121094
Batch 3/64 loss: -1.1522626876831055
Batch 4/64 loss: -1.484705924987793
Batch 5/64 loss: -0.24007797241210938
Batch 6/64 loss: -1.5579843521118164
Batch 7/64 loss: -1.614344596862793
Batch 8/64 loss: -1.476572036743164
Batch 9/64 loss: -1.5478248596191406
Batch 10/64 loss: -1.6870803833007812
Batch 11/64 loss: -1.550053596496582
Batch 12/64 loss: -1.2199010848999023
Batch 13/64 loss: -1.6180782318115234
Batch 14/64 loss: -1.2606067657470703
Batch 15/64 loss: -1.3657941818237305
Batch 16/64 loss: -1.58038330078125
Batch 17/64 loss: -1.0710182189941406
Batch 18/64 loss: -1.1325759887695312
Batch 19/64 loss: -1.1634464263916016
Batch 20/64 loss: -1.337411880493164
Batch 21/64 loss: -1.3336782455444336
Batch 22/64 loss: -1.2951631546020508
Batch 23/64 loss: -1.589303970336914
Batch 24/64 loss: -1.522207260131836
Batch 25/64 loss: -1.144892692565918
Batch 26/64 loss: -1.5189437866210938
Batch 27/64 loss: -0.7550020217895508
Batch 28/64 loss: -1.430527687072754
Batch 29/64 loss: -1.599273681640625
Batch 30/64 loss: -1.6033897399902344
Batch 31/64 loss: -1.5504570007324219
Batch 32/64 loss: -1.1488018035888672
Batch 33/64 loss: -1.202387809753418
Batch 34/64 loss: -1.2998847961425781
Batch 35/64 loss: -1.5662736892700195
Batch 36/64 loss: -1.2627897262573242
Batch 37/64 loss: -1.4954605102539062
Batch 38/64 loss: -1.767568588256836
Batch 39/64 loss: -1.8066749572753906
Batch 40/64 loss: -1.3696098327636719
Batch 41/64 loss: -1.6980762481689453
Batch 42/64 loss: -1.641566276550293
Batch 43/64 loss: -1.6079893112182617
Batch 44/64 loss: -1.1203174591064453
Batch 45/64 loss: -1.5302314758300781
Batch 46/64 loss: -1.052180290222168
Batch 47/64 loss: -1.3369512557983398
Batch 48/64 loss: -1.4348821640014648
Batch 49/64 loss: -0.995326042175293
Batch 50/64 loss: -1.557180404663086
Batch 51/64 loss: -1.440363883972168
Batch 52/64 loss: -1.434122085571289
Batch 53/64 loss: -1.5788965225219727
Batch 54/64 loss: -1.2976951599121094
Batch 55/64 loss: -1.720376968383789
Batch 56/64 loss: -1.2988166809082031
Batch 57/64 loss: -1.5397157669067383
Batch 58/64 loss: -1.7476835250854492
Batch 59/64 loss: -1.040268898010254
Batch 60/64 loss: -0.8814496994018555
Batch 61/64 loss: -0.9383811950683594
Batch 62/64 loss: -1.6879596710205078
Batch 63/64 loss: -1.400313377380371
Batch 64/64 loss: -5.781817436218262
Epoch 52  Train loss: -1.439120517057531  Val loss: -1.1601540083737718
Epoch 53
-------------------------------
Batch 1/64 loss: -1.2678680419921875
Batch 2/64 loss: -1.5299959182739258
Batch 3/64 loss: -1.6054325103759766
Batch 4/64 loss: -1.2877197265625
Batch 5/64 loss: -1.4073143005371094
Batch 6/64 loss: -1.2241363525390625
Batch 7/64 loss: -1.1880207061767578
Batch 8/64 loss: -1.37261962890625
Batch 9/64 loss: -1.4920377731323242
Batch 10/64 loss: -1.3187360763549805
Batch 11/64 loss: -1.4074668884277344
Batch 12/64 loss: -1.6822023391723633
Batch 13/64 loss: -1.7175111770629883
Batch 14/64 loss: -1.4027080535888672
Batch 15/64 loss: -1.1576347351074219
Batch 16/64 loss: -1.5059776306152344
Batch 17/64 loss: -1.5616340637207031
Batch 18/64 loss: -1.5440254211425781
Batch 19/64 loss: -1.5528640747070312
Batch 20/64 loss: -1.0824394226074219
Batch 21/64 loss: -1.4874420166015625
Batch 22/64 loss: -1.235661506652832
Batch 23/64 loss: -1.2403459548950195
Batch 24/64 loss: -1.140477180480957
Batch 25/64 loss: -1.4645757675170898
Batch 26/64 loss: -1.583709716796875
Batch 27/64 loss: -1.7378425598144531
Batch 28/64 loss: -1.7807064056396484
Batch 29/64 loss: -1.263784408569336
Batch 30/64 loss: -1.5835342407226562
Batch 31/64 loss: -1.4492769241333008
Batch 32/64 loss: -1.3691110610961914
Batch 33/64 loss: -1.4334783554077148
Batch 34/64 loss: -1.511641502380371
Batch 35/64 loss: -1.5991458892822266
Batch 36/64 loss: -1.7262706756591797
Batch 37/64 loss: -1.365835189819336
Batch 38/64 loss: -1.4742279052734375
Batch 39/64 loss: -1.7309026718139648
Batch 40/64 loss: -1.0491886138916016
Batch 41/64 loss: -1.383030891418457
Batch 42/64 loss: -1.3694992065429688
Batch 43/64 loss: -1.0016403198242188
Batch 44/64 loss: -1.6838111877441406
Batch 45/64 loss: -1.3855724334716797
Batch 46/64 loss: -1.647705078125
Batch 47/64 loss: -1.663726806640625
Batch 48/64 loss: -1.6109752655029297
Batch 49/64 loss: -1.1319732666015625
Batch 50/64 loss: -1.6559791564941406
Batch 51/64 loss: -1.2909021377563477
Batch 52/64 loss: -1.2317209243774414
Batch 53/64 loss: -1.6607484817504883
Batch 54/64 loss: -1.1058731079101562
Batch 55/64 loss: -1.6332902908325195
Batch 56/64 loss: -1.483327865600586
Batch 57/64 loss: -1.0035648345947266
Batch 58/64 loss: -1.716073989868164
Batch 59/64 loss: -1.5143098831176758
Batch 60/64 loss: -1.5292348861694336
Batch 61/64 loss: -1.4109554290771484
Batch 62/64 loss: -1.4985074996948242
Batch 63/64 loss: -1.002568244934082
Batch 64/64 loss: -5.732733249664307
Epoch 53  Train loss: -1.481569325690176  Val loss: -1.5713743229502255
Epoch 54
-------------------------------
Batch 1/64 loss: -1.2355146408081055
Batch 2/64 loss: -1.3179216384887695
Batch 3/64 loss: -1.6465578079223633
Batch 4/64 loss: -1.872995376586914
Batch 5/64 loss: -1.595407485961914
Batch 6/64 loss: -1.7438392639160156
Batch 7/64 loss: -1.0177297592163086
Batch 8/64 loss: -1.202284812927246
Batch 9/64 loss: -1.6400556564331055
Batch 10/64 loss: -0.9500217437744141
Batch 11/64 loss: -1.2742996215820312
Batch 12/64 loss: -1.553696632385254
Batch 13/64 loss: -1.2843866348266602
Batch 14/64 loss: -1.3778963088989258
Batch 15/64 loss: -1.4861440658569336
Batch 16/64 loss: -1.6083335876464844
Batch 17/64 loss: -1.7626104354858398
Batch 18/64 loss: -1.5711708068847656
Batch 19/64 loss: -1.6734695434570312
Batch 20/64 loss: -1.2945585250854492
Batch 21/64 loss: -1.623300552368164
Batch 22/64 loss: -1.4316539764404297
Batch 23/64 loss: -1.477736473083496
Batch 24/64 loss: -1.3010406494140625
Batch 25/64 loss: -1.3390378952026367
Batch 26/64 loss: -1.5909690856933594
Batch 27/64 loss: -1.6553869247436523
Batch 28/64 loss: -1.5486431121826172
Batch 29/64 loss: -1.7473106384277344
Batch 30/64 loss: -1.7709016799926758
Batch 31/64 loss: -1.6040267944335938
Batch 32/64 loss: -1.6897697448730469
Batch 33/64 loss: -1.7756767272949219
Batch 34/64 loss: -1.8174467086791992
Batch 35/64 loss: -1.5860567092895508
Batch 36/64 loss: -1.2739696502685547
Batch 37/64 loss: -1.5290565490722656
Batch 38/64 loss: -1.3404550552368164
Batch 39/64 loss: -1.6278924942016602
Batch 40/64 loss: -1.5284967422485352
Batch 41/64 loss: -1.532780647277832
Batch 42/64 loss: -1.2564611434936523
Batch 43/64 loss: -1.607381820678711
Batch 44/64 loss: -1.3056907653808594
Batch 45/64 loss: -1.5564651489257812
Batch 46/64 loss: -1.645040512084961
Batch 47/64 loss: -1.5295190811157227
Batch 48/64 loss: -1.8400049209594727
Batch 49/64 loss: -1.6498613357543945
Batch 50/64 loss: -1.5596075057983398
Batch 51/64 loss: -1.133500099182129
Batch 52/64 loss: -1.020075798034668
Batch 53/64 loss: -1.2392807006835938
Batch 54/64 loss: -1.5836372375488281
Batch 55/64 loss: -1.3855400085449219
Batch 56/64 loss: -1.5373764038085938
Batch 57/64 loss: -1.789036750793457
Batch 58/64 loss: -0.8373308181762695
Batch 59/64 loss: -1.3814201354980469
Batch 60/64 loss: -0.8585309982299805
Batch 61/64 loss: -1.6606712341308594
Batch 62/64 loss: -1.447707176208496
Batch 63/64 loss: -1.0964164733886719
Batch 64/64 loss: -5.839930057525635
Epoch 54  Train loss: -1.524721674825631  Val loss: -1.222074017082293
Epoch 55
-------------------------------
Batch 1/64 loss: -1.1735992431640625
Batch 2/64 loss: -0.7598667144775391
Batch 3/64 loss: -1.5691823959350586
Batch 4/64 loss: -1.599802017211914
Batch 5/64 loss: -0.9863967895507812
Batch 6/64 loss: -1.540757179260254
Batch 7/64 loss: -0.5930795669555664
Batch 8/64 loss: -1.1916675567626953
Batch 9/64 loss: -1.0752840042114258
Batch 10/64 loss: -1.2678699493408203
Batch 11/64 loss: -1.5972070693969727
Batch 12/64 loss: -1.4472360610961914
Batch 13/64 loss: -1.3136024475097656
Batch 14/64 loss: -1.3490304946899414
Batch 15/64 loss: -1.4099035263061523
Batch 16/64 loss: -1.6550445556640625
Batch 17/64 loss: -1.2565603256225586
Batch 18/64 loss: -1.4498939514160156
Batch 19/64 loss: -1.836172103881836
Batch 20/64 loss: -1.5992813110351562
Batch 21/64 loss: -1.467508316040039
Batch 22/64 loss: -1.3599720001220703
Batch 23/64 loss: -1.7519683837890625
Batch 24/64 loss: -1.583221435546875
Batch 25/64 loss: -1.4870586395263672
Batch 26/64 loss: -1.4301490783691406
Batch 27/64 loss: -1.1776161193847656
Batch 28/64 loss: -1.5088415145874023
Batch 29/64 loss: -1.4599275588989258
Batch 30/64 loss: -1.635040283203125
Batch 31/64 loss: -0.9539089202880859
Batch 32/64 loss: -1.0891704559326172
Batch 33/64 loss: -1.4411201477050781
Batch 34/64 loss: -1.4590864181518555
Batch 35/64 loss: -1.3622045516967773
Batch 36/64 loss: -1.3994617462158203
Batch 37/64 loss: -1.5018720626831055
Batch 38/64 loss: -1.5549077987670898
Batch 39/64 loss: -1.367340087890625
Batch 40/64 loss: -0.9073200225830078
Batch 41/64 loss: -0.9545154571533203
Batch 42/64 loss: -1.044377326965332
Batch 43/64 loss: -1.539046287536621
Batch 44/64 loss: -1.621469497680664
Batch 45/64 loss: -1.3002738952636719
Batch 46/64 loss: -1.2703933715820312
Batch 47/64 loss: -1.7017440795898438
Batch 48/64 loss: -1.8718461990356445
Batch 49/64 loss: -1.1637258529663086
Batch 50/64 loss: -1.6057090759277344
Batch 51/64 loss: -1.0585155487060547
Batch 52/64 loss: -1.531571388244629
Batch 53/64 loss: -1.4502944946289062
Batch 54/64 loss: -1.7195138931274414
Batch 55/64 loss: -1.5503253936767578
Batch 56/64 loss: -1.6933746337890625
Batch 57/64 loss: -1.3275527954101562
Batch 58/64 loss: -1.5206031799316406
Batch 59/64 loss: -1.5495214462280273
Batch 60/64 loss: -1.724599838256836
Batch 61/64 loss: -1.588545799255371
Batch 62/64 loss: -1.3616914749145508
Batch 63/64 loss: -1.471954345703125
Batch 64/64 loss: -6.046619415283203
Epoch 55  Train loss: -1.4545139237946154  Val loss: -1.6473673004465006
Saving best model, epoch: 55
Epoch 56
-------------------------------
Batch 1/64 loss: -1.3699560165405273
Batch 2/64 loss: -1.439157485961914
Batch 3/64 loss: -0.9528789520263672
Batch 4/64 loss: -1.3020305633544922
Batch 5/64 loss: -1.4198102951049805
Batch 6/64 loss: -1.4380388259887695
Batch 7/64 loss: -1.9272727966308594
Batch 8/64 loss: -1.5809898376464844
Batch 9/64 loss: -1.5957536697387695
Batch 10/64 loss: -1.5901460647583008
Batch 11/64 loss: -1.6447620391845703
Batch 12/64 loss: -1.6439476013183594
Batch 13/64 loss: -1.5719633102416992
Batch 14/64 loss: -1.611527442932129
Batch 15/64 loss: -1.5701751708984375
Batch 16/64 loss: -1.545588493347168
Batch 17/64 loss: -1.6133451461791992
Batch 18/64 loss: -1.6604318618774414
Batch 19/64 loss: -1.5267581939697266
Batch 20/64 loss: -1.9265966415405273
Batch 21/64 loss: -1.5657272338867188
Batch 22/64 loss: -1.3852853775024414
Batch 23/64 loss: -1.3700904846191406
Batch 24/64 loss: -1.327117919921875
Batch 25/64 loss: -1.371230125427246
Batch 26/64 loss: -1.2390251159667969
Batch 27/64 loss: -1.359354019165039
Batch 28/64 loss: -1.394841194152832
Batch 29/64 loss: -1.6378517150878906
Batch 30/64 loss: -1.470179557800293
Batch 31/64 loss: -1.6526784896850586
Batch 32/64 loss: -1.5097932815551758
Batch 33/64 loss: -1.268387794494629
Batch 34/64 loss: -1.5446834564208984
Batch 35/64 loss: -1.3934555053710938
Batch 36/64 loss: -1.534524917602539
Batch 37/64 loss: -1.2036323547363281
Batch 38/64 loss: -1.7166662216186523
Batch 39/64 loss: -1.5162363052368164
Batch 40/64 loss: -1.6258878707885742
Batch 41/64 loss: -1.7230205535888672
Batch 42/64 loss: -1.4080429077148438
Batch 43/64 loss: -1.6394624710083008
Batch 44/64 loss: -1.519632339477539
Batch 45/64 loss: -1.2852849960327148
Batch 46/64 loss: -1.4618911743164062
Batch 47/64 loss: -1.3918113708496094
Batch 48/64 loss: -1.3540172576904297
Batch 49/64 loss: -1.7122745513916016
Batch 50/64 loss: -1.5339231491088867
Batch 51/64 loss: -1.2191858291625977
Batch 52/64 loss: -1.6913995742797852
Batch 53/64 loss: -1.4859485626220703
Batch 54/64 loss: -1.3824796676635742
Batch 55/64 loss: -1.7173919677734375
Batch 56/64 loss: -1.2877569198608398
Batch 57/64 loss: -1.2195758819580078
Batch 58/64 loss: -1.388545036315918
Batch 59/64 loss: -1.4753971099853516
Batch 60/64 loss: -0.9076242446899414
Batch 61/64 loss: -1.4544086456298828
Batch 62/64 loss: -1.5154838562011719
Batch 63/64 loss: -1.601405143737793
Batch 64/64 loss: -6.034571647644043
Epoch 56  Train loss: -1.5359948438756605  Val loss: -1.5308825306056701
Epoch 57
-------------------------------
Batch 1/64 loss: -1.320094108581543
Batch 2/64 loss: -1.0285892486572266
Batch 3/64 loss: -1.3307380676269531
Batch 4/64 loss: -1.264185905456543
Batch 5/64 loss: -0.8866357803344727
Batch 6/64 loss: -1.4112701416015625
Batch 7/64 loss: -1.4885482788085938
Batch 8/64 loss: -1.301741600036621
Batch 9/64 loss: -1.7519607543945312
Batch 10/64 loss: -1.2055864334106445
Batch 11/64 loss: -1.3569097518920898
Batch 12/64 loss: -1.545273780822754
Batch 13/64 loss: -1.5419301986694336
Batch 14/64 loss: -1.7520942687988281
Batch 15/64 loss: -1.603724479675293
Batch 16/64 loss: -1.5546579360961914
Batch 17/64 loss: -1.3734502792358398
Batch 18/64 loss: -1.809300422668457
Batch 19/64 loss: -1.4689750671386719
Batch 20/64 loss: -1.7634162902832031
Batch 21/64 loss: -1.6772727966308594
Batch 22/64 loss: -1.6105070114135742
Batch 23/64 loss: -1.8408527374267578
Batch 24/64 loss: -1.5803728103637695
Batch 25/64 loss: -1.711334228515625
Batch 26/64 loss: -1.8427362442016602
Batch 27/64 loss: -1.4575824737548828
Batch 28/64 loss: -1.3383407592773438
Batch 29/64 loss: -1.4319467544555664
Batch 30/64 loss: -1.5820598602294922
Batch 31/64 loss: -1.677931785583496
Batch 32/64 loss: -1.644566535949707
Batch 33/64 loss: -1.4603462219238281
Batch 34/64 loss: -1.2361431121826172
Batch 35/64 loss: -1.7709846496582031
Batch 36/64 loss: -1.7949934005737305
Batch 37/64 loss: -1.6803693771362305
Batch 38/64 loss: -1.8576679229736328
Batch 39/64 loss: -1.6672143936157227
Batch 40/64 loss: -1.5480670928955078
Batch 41/64 loss: -1.7183961868286133
Batch 42/64 loss: -1.247532844543457
Batch 43/64 loss: -1.605184555053711
Batch 44/64 loss: -1.7963848114013672
Batch 45/64 loss: -1.4361743927001953
Batch 46/64 loss: -1.7324943542480469
Batch 47/64 loss: -1.388016700744629
Batch 48/64 loss: -1.7449111938476562
Batch 49/64 loss: -1.270146369934082
Batch 50/64 loss: -1.7875185012817383
Batch 51/64 loss: -1.6537399291992188
Batch 52/64 loss: -1.4142637252807617
Batch 53/64 loss: -1.4824542999267578
Batch 54/64 loss: -1.4365158081054688
Batch 55/64 loss: -1.724532127380371
Batch 56/64 loss: -1.6830482482910156
Batch 57/64 loss: -1.8483390808105469
Batch 58/64 loss: -1.144526481628418
Batch 59/64 loss: -1.744161605834961
Batch 60/64 loss: -1.6675100326538086
Batch 61/64 loss: -1.6230659484863281
Batch 62/64 loss: -1.7251472473144531
Batch 63/64 loss: -1.4792261123657227
Batch 64/64 loss: -5.831509113311768
Epoch 57  Train loss: -1.5983889467575971  Val loss: -1.604891183859704
Epoch 58
-------------------------------
Batch 1/64 loss: -1.4054346084594727
Batch 2/64 loss: -0.9132194519042969
Batch 3/64 loss: -1.288996696472168
Batch 4/64 loss: -1.6253290176391602
Batch 5/64 loss: -1.7745113372802734
Batch 6/64 loss: -1.3582429885864258
Batch 7/64 loss: -1.3814268112182617
Batch 8/64 loss: -1.34881591796875
Batch 9/64 loss: -1.5127182006835938
Batch 10/64 loss: -1.0474348068237305
Batch 11/64 loss: -1.3879880905151367
Batch 12/64 loss: -0.7898130416870117
Batch 13/64 loss: -1.4044599533081055
Batch 14/64 loss: -1.5097684860229492
Batch 15/64 loss: -1.0782766342163086
Batch 16/64 loss: -1.4910526275634766
Batch 17/64 loss: -1.2667360305786133
Batch 18/64 loss: -1.3730354309082031
Batch 19/64 loss: -1.7000904083251953
Batch 20/64 loss: -1.5701971054077148
Batch 21/64 loss: -1.5767240524291992
Batch 22/64 loss: -1.515019416809082
Batch 23/64 loss: -1.3403663635253906
Batch 24/64 loss: -1.6113910675048828
Batch 25/64 loss: -1.741105079650879
Batch 26/64 loss: -0.6780643463134766
Batch 27/64 loss: -1.5812110900878906
Batch 28/64 loss: -1.5581464767456055
Batch 29/64 loss: -1.7077865600585938
Batch 30/64 loss: -1.3084793090820312
Batch 31/64 loss: -1.5558252334594727
Batch 32/64 loss: -0.9389810562133789
Batch 33/64 loss: -1.2753820419311523
Batch 34/64 loss: -1.4729652404785156
Batch 35/64 loss: -1.4484615325927734
Batch 36/64 loss: -1.5238943099975586
Batch 37/64 loss: -1.1435890197753906
Batch 38/64 loss: -1.7419986724853516
Batch 39/64 loss: -1.3059749603271484
Batch 40/64 loss: -1.7169055938720703
Batch 41/64 loss: -1.5088176727294922
Batch 42/64 loss: -1.557952880859375
Batch 43/64 loss: -1.4750652313232422
Batch 44/64 loss: -1.749384880065918
Batch 45/64 loss: -1.6696395874023438
Batch 46/64 loss: -1.5103216171264648
Batch 47/64 loss: -1.4352378845214844
Batch 48/64 loss: -1.5797443389892578
Batch 49/64 loss: -1.236344337463379
Batch 50/64 loss: -1.426365852355957
Batch 51/64 loss: -1.5585699081420898
Batch 52/64 loss: -1.4362764358520508
Batch 53/64 loss: -1.871476173400879
Batch 54/64 loss: -1.4769468307495117
Batch 55/64 loss: -1.4972763061523438
Batch 56/64 loss: -1.3054170608520508
Batch 57/64 loss: -1.3075942993164062
Batch 58/64 loss: -1.4931964874267578
Batch 59/64 loss: -1.7759733200073242
Batch 60/64 loss: -0.9711732864379883
Batch 61/64 loss: -1.3606843948364258
Batch 62/64 loss: -1.5409250259399414
Batch 63/64 loss: -1.6428298950195312
Batch 64/64 loss: -5.4420294761657715
Epoch 58  Train loss: -1.4813890962039724  Val loss: -1.5618326901570219
Epoch 59
-------------------------------
Batch 1/64 loss: -1.548314094543457
Batch 2/64 loss: -1.039031982421875
Batch 3/64 loss: -1.517806053161621
Batch 4/64 loss: -1.408639907836914
Batch 5/64 loss: -1.453390121459961
Batch 6/64 loss: -1.6349668502807617
Batch 7/64 loss: -1.6425676345825195
Batch 8/64 loss: -1.5522699356079102
Batch 9/64 loss: -1.6759052276611328
Batch 10/64 loss: -1.1848020553588867
Batch 11/64 loss: -1.4866456985473633
Batch 12/64 loss: -1.5443964004516602
Batch 13/64 loss: -1.0845975875854492
Batch 14/64 loss: -1.8069047927856445
Batch 15/64 loss: -1.4852218627929688
Batch 16/64 loss: -1.6562623977661133
Batch 17/64 loss: -1.2249298095703125
Batch 18/64 loss: -1.5724878311157227
Batch 19/64 loss: -1.3589553833007812
Batch 20/64 loss: -1.9273271560668945
Batch 21/64 loss: -1.5595455169677734
Batch 22/64 loss: -1.5979290008544922
Batch 23/64 loss: -1.4904718399047852
Batch 24/64 loss: -1.273299217224121
Batch 25/64 loss: -1.5924091339111328
Batch 26/64 loss: -1.7358760833740234
Batch 27/64 loss: -1.5588245391845703
Batch 28/64 loss: -1.6402292251586914
Batch 29/64 loss: -1.5098333358764648
Batch 30/64 loss: -1.1078596115112305
Batch 31/64 loss: -1.3654956817626953
Batch 32/64 loss: -1.549962043762207
Batch 33/64 loss: -1.668497085571289
Batch 34/64 loss: -1.9046077728271484
Batch 35/64 loss: -1.7777462005615234
Batch 36/64 loss: -1.8169288635253906
Batch 37/64 loss: -1.596780776977539
Batch 38/64 loss: -1.7090415954589844
Batch 39/64 loss: -1.7582635879516602
Batch 40/64 loss: -1.265486717224121
Batch 41/64 loss: -1.5157012939453125
Batch 42/64 loss: -1.6500911712646484
Batch 43/64 loss: -1.2025384902954102
Batch 44/64 loss: -1.7806024551391602
Batch 45/64 loss: -1.6346206665039062
Batch 46/64 loss: -1.3954181671142578
Batch 47/64 loss: -1.4934968948364258
Batch 48/64 loss: -1.757863998413086
Batch 49/64 loss: -1.8442420959472656
Batch 50/64 loss: -1.6018953323364258
Batch 51/64 loss: -2.0360517501831055
Batch 52/64 loss: -1.7334012985229492
Batch 53/64 loss: -1.7794628143310547
Batch 54/64 loss: -1.3642749786376953
Batch 55/64 loss: -1.5832433700561523
Batch 56/64 loss: -1.739731788635254
Batch 57/64 loss: -1.4142074584960938
Batch 58/64 loss: -1.777440071105957
Batch 59/64 loss: -1.5461483001708984
Batch 60/64 loss: -1.2965784072875977
Batch 61/64 loss: -1.008376121520996
Batch 62/64 loss: -1.8394250869750977
Batch 63/64 loss: -1.6428279876708984
Batch 64/64 loss: -5.9525885581970215
Epoch 59  Train loss: -1.606064188714121  Val loss: -1.6792331184308553
Saving best model, epoch: 59
Epoch 60
-------------------------------
Batch 1/64 loss: -1.7182493209838867
Batch 2/64 loss: -1.720259666442871
Batch 3/64 loss: -1.7882423400878906
Batch 4/64 loss: -1.6055421829223633
Batch 5/64 loss: -1.5678768157958984
Batch 6/64 loss: -1.6854400634765625
Batch 7/64 loss: -1.8548460006713867
Batch 8/64 loss: -1.1289854049682617
Batch 9/64 loss: -1.8015871047973633
Batch 10/64 loss: -1.5707683563232422
Batch 11/64 loss: -1.7985506057739258
Batch 12/64 loss: -1.6711997985839844
Batch 13/64 loss: -1.78363037109375
Batch 14/64 loss: -1.865799903869629
Batch 15/64 loss: -1.6729888916015625
Batch 16/64 loss: -1.2736759185791016
Batch 17/64 loss: -1.6215324401855469
Batch 18/64 loss: -1.2487192153930664
Batch 19/64 loss: -1.424077033996582
Batch 20/64 loss: -1.1829919815063477
Batch 21/64 loss: -1.7512197494506836
Batch 22/64 loss: -1.5047836303710938
Batch 23/64 loss: -1.5426464080810547
Batch 24/64 loss: -1.8463897705078125
Batch 25/64 loss: -1.4720573425292969
Batch 26/64 loss: -1.693756103515625
Batch 27/64 loss: -1.4469633102416992
Batch 28/64 loss: -1.4407939910888672
Batch 29/64 loss: -1.4874153137207031
Batch 30/64 loss: -1.6137323379516602
Batch 31/64 loss: -1.8486251831054688
Batch 32/64 loss: -2.0583534240722656
Batch 33/64 loss: -1.677290916442871
Batch 34/64 loss: -1.2181510925292969
Batch 35/64 loss: -1.447739601135254
Batch 36/64 loss: -1.300811767578125
Batch 37/64 loss: -1.5967473983764648
Batch 38/64 loss: -1.6633529663085938
Batch 39/64 loss: -1.723215103149414
Batch 40/64 loss: -1.7342090606689453
Batch 41/64 loss: -1.8463220596313477
Batch 42/64 loss: -1.2964849472045898
Batch 43/64 loss: -1.3958024978637695
Batch 44/64 loss: -1.4231433868408203
Batch 45/64 loss: -1.549361228942871
Batch 46/64 loss: -1.3101816177368164
Batch 47/64 loss: -1.594294548034668
Batch 48/64 loss: -1.4499711990356445
Batch 49/64 loss: -0.9772462844848633
Batch 50/64 loss: -1.8086252212524414
Batch 51/64 loss: -1.6475152969360352
Batch 52/64 loss: -1.607499122619629
Batch 53/64 loss: -1.6621837615966797
Batch 54/64 loss: -1.0090608596801758
Batch 55/64 loss: -1.570052146911621
Batch 56/64 loss: -1.5926933288574219
Batch 57/64 loss: -1.559168815612793
Batch 58/64 loss: -1.6184673309326172
Batch 59/64 loss: -1.8080320358276367
Batch 60/64 loss: -1.7383394241333008
Batch 61/64 loss: -2.047980308532715
Batch 62/64 loss: -1.6399965286254883
Batch 63/64 loss: -1.7421236038208008
Batch 64/64 loss: -5.9357123374938965
Epoch 60  Train loss: -1.6376399638606052  Val loss: -0.26249115409719986
Epoch 61
-------------------------------
Batch 1/64 loss: -1.1391048431396484
Batch 2/64 loss: -1.542811393737793
Batch 3/64 loss: -1.5299739837646484
Batch 4/64 loss: -1.6967229843139648
Batch 5/64 loss: -1.380568504333496
Batch 6/64 loss: -1.2659978866577148
Batch 7/64 loss: -1.8030481338500977
Batch 8/64 loss: -1.131683349609375
Batch 9/64 loss: -1.2352266311645508
Batch 10/64 loss: -1.5484418869018555
Batch 11/64 loss: -1.808304786682129
Batch 12/64 loss: -1.3836746215820312
Batch 13/64 loss: -1.1796884536743164
Batch 14/64 loss: -1.6039304733276367
Batch 15/64 loss: -1.4657745361328125
Batch 16/64 loss: -1.5446109771728516
Batch 17/64 loss: -0.7505655288696289
Batch 18/64 loss: -1.6055011749267578
Batch 19/64 loss: -1.5023088455200195
Batch 20/64 loss: -1.6133432388305664
Batch 21/64 loss: -1.4852705001831055
Batch 22/64 loss: -1.3144159317016602
Batch 23/64 loss: -1.4986896514892578
Batch 24/64 loss: -1.413346290588379
Batch 25/64 loss: -1.474654197692871
Batch 26/64 loss: -1.6882781982421875
Batch 27/64 loss: -1.7289466857910156
Batch 28/64 loss: -1.226984977722168
Batch 29/64 loss: -1.3073549270629883
Batch 30/64 loss: -1.453399658203125
Batch 31/64 loss: -1.6676445007324219
Batch 32/64 loss: -1.3671684265136719
Batch 33/64 loss: -1.6198463439941406
Batch 34/64 loss: -1.7305278778076172
Batch 35/64 loss: -1.5667991638183594
Batch 36/64 loss: -1.2828731536865234
Batch 37/64 loss: -1.4782276153564453
Batch 38/64 loss: -1.1423749923706055
Batch 39/64 loss: -1.7999067306518555
Batch 40/64 loss: -1.625697135925293
Batch 41/64 loss: -1.4996376037597656
Batch 42/64 loss: -1.453287124633789
Batch 43/64 loss: -1.4717187881469727
Batch 44/64 loss: -1.8022642135620117
Batch 45/64 loss: -1.6979846954345703
Batch 46/64 loss: -1.9315452575683594
Batch 47/64 loss: -1.5809316635131836
Batch 48/64 loss: -1.5371475219726562
Batch 49/64 loss: -1.5395383834838867
Batch 50/64 loss: -1.8216285705566406
Batch 51/64 loss: -1.5979194641113281
Batch 52/64 loss: -1.7763118743896484
Batch 53/64 loss: -1.4911861419677734
Batch 54/64 loss: -1.7409496307373047
Batch 55/64 loss: -1.659799575805664
Batch 56/64 loss: -1.3627614974975586
Batch 57/64 loss: -1.6731739044189453
Batch 58/64 loss: -1.5749282836914062
Batch 59/64 loss: -1.4644784927368164
Batch 60/64 loss: -1.209005355834961
Batch 61/64 loss: -1.6025352478027344
Batch 62/64 loss: -1.550766944885254
Batch 63/64 loss: -1.6770706176757812
Batch 64/64 loss: -5.971714019775391
Epoch 61  Train loss: -1.5654752245136336  Val loss: -1.2166128519064783
Epoch 62
-------------------------------
Batch 1/64 loss: -1.3490638732910156
Batch 2/64 loss: -1.407240867614746
Batch 3/64 loss: -1.609086036682129
Batch 4/64 loss: -1.7186765670776367
Batch 5/64 loss: -0.9321222305297852
Batch 6/64 loss: -1.1681814193725586
Batch 7/64 loss: -0.6986608505249023
Batch 8/64 loss: -1.198918342590332
Batch 9/64 loss: -1.3353548049926758
Batch 10/64 loss: -0.7798252105712891
Batch 11/64 loss: -1.086146354675293
Batch 12/64 loss: -1.0181055068969727
Batch 13/64 loss: -1.586258888244629
Batch 14/64 loss: -1.5449628829956055
Batch 15/64 loss: -0.6588659286499023
Batch 16/64 loss: -1.3556909561157227
Batch 17/64 loss: -1.5178594589233398
Batch 18/64 loss: -1.4048805236816406
Batch 19/64 loss: -1.0884971618652344
Batch 20/64 loss: -1.2247066497802734
Batch 21/64 loss: -1.599191665649414
Batch 22/64 loss: -0.8135652542114258
Batch 23/64 loss: -1.6048336029052734
Batch 24/64 loss: -1.8522453308105469
Batch 25/64 loss: -1.2491474151611328
Batch 26/64 loss: -1.8557310104370117
Batch 27/64 loss: -1.6080188751220703
Batch 28/64 loss: -1.3705568313598633
Batch 29/64 loss: -1.4880256652832031
Batch 30/64 loss: -1.597947120666504
Batch 31/64 loss: -1.3907833099365234
Batch 32/64 loss: -1.789280891418457
Batch 33/64 loss: -1.9013938903808594
Batch 34/64 loss: -1.7082700729370117
Batch 35/64 loss: -1.7114830017089844
Batch 36/64 loss: -1.5696535110473633
Batch 37/64 loss: -1.6374530792236328
Batch 38/64 loss: -1.1631278991699219
Batch 39/64 loss: -1.6985340118408203
Batch 40/64 loss: -1.6312150955200195
Batch 41/64 loss: -1.8314123153686523
Batch 42/64 loss: -1.424978256225586
Batch 43/64 loss: -1.6544971466064453
Batch 44/64 loss: -1.2900924682617188
Batch 45/64 loss: -1.488677978515625
Batch 46/64 loss: -1.4775476455688477
Batch 47/64 loss: -1.421701431274414
Batch 48/64 loss: -1.062154769897461
Batch 49/64 loss: -1.5704479217529297
Batch 50/64 loss: -1.8186330795288086
Batch 51/64 loss: -1.5183134078979492
Batch 52/64 loss: -0.9976482391357422
Batch 53/64 loss: -1.6983041763305664
Batch 54/64 loss: -1.846980094909668
Batch 55/64 loss: -1.6957626342773438
Batch 56/64 loss: -1.6898174285888672
Batch 57/64 loss: -1.822601318359375
Batch 58/64 loss: -1.217839241027832
Batch 59/64 loss: -1.764878273010254
Batch 60/64 loss: -1.5837583541870117
Batch 61/64 loss: -1.5552244186401367
Batch 62/64 loss: -1.6552810668945312
Batch 63/64 loss: -1.3224382400512695
Batch 64/64 loss: -5.767080783843994
Epoch 62  Train loss: -1.5005154908872118  Val loss: -1.7391457967332138
Saving best model, epoch: 62
Epoch 63
-------------------------------
Batch 1/64 loss: -1.5157251358032227
Batch 2/64 loss: -1.420222282409668
Batch 3/64 loss: -1.4436845779418945
Batch 4/64 loss: -1.6030702590942383
Batch 5/64 loss: -1.8592920303344727
Batch 6/64 loss: -1.4688739776611328
Batch 7/64 loss: -1.6431636810302734
Batch 8/64 loss: -1.600083351135254
Batch 9/64 loss: -1.4734230041503906
Batch 10/64 loss: -1.7895402908325195
Batch 11/64 loss: -1.0013055801391602
Batch 12/64 loss: -1.6543560028076172
Batch 13/64 loss: -1.452890396118164
Batch 14/64 loss: -1.8253612518310547
Batch 15/64 loss: -1.5556297302246094
Batch 16/64 loss: -1.6692094802856445
Batch 17/64 loss: -1.625056266784668
Batch 18/64 loss: -1.670060157775879
Batch 19/64 loss: -1.6124763488769531
Batch 20/64 loss: -1.5958681106567383
Batch 21/64 loss: -1.6776628494262695
Batch 22/64 loss: -1.601099967956543
Batch 23/64 loss: -1.0744199752807617
Batch 24/64 loss: -1.747314453125
Batch 25/64 loss: -1.6279630661010742
Batch 26/64 loss: -1.207341194152832
Batch 27/64 loss: -1.9315967559814453
Batch 28/64 loss: -1.774317741394043
Batch 29/64 loss: -1.4587955474853516
Batch 30/64 loss: -1.4958696365356445
Batch 31/64 loss: -1.5915374755859375
Batch 32/64 loss: -1.0990943908691406
Batch 33/64 loss: -1.9056377410888672
Batch 34/64 loss: -1.1376333236694336
Batch 35/64 loss: -1.7310724258422852
Batch 36/64 loss: -1.716679573059082
Batch 37/64 loss: -1.6883697509765625
Batch 38/64 loss: -1.3936595916748047
Batch 39/64 loss: -1.5547599792480469
Batch 40/64 loss: -1.4942150115966797
Batch 41/64 loss: -1.6444807052612305
Batch 42/64 loss: -1.6141166687011719
Batch 43/64 loss: -1.6264801025390625
Batch 44/64 loss: -1.482264518737793
Batch 45/64 loss: -1.5607242584228516
Batch 46/64 loss: -1.421036720275879
Batch 47/64 loss: -1.851456642150879
Batch 48/64 loss: -1.6444664001464844
Batch 49/64 loss: -1.3186912536621094
Batch 50/64 loss: -1.1914215087890625
Batch 51/64 loss: -0.9363794326782227
Batch 52/64 loss: -0.42043304443359375
Batch 53/64 loss: -1.2090768814086914
Batch 54/64 loss: -1.168410301208496
Batch 55/64 loss: -0.9466285705566406
Batch 56/64 loss: -1.3100786209106445
Batch 57/64 loss: -1.3597068786621094
Batch 58/64 loss: -1.4000053405761719
Batch 59/64 loss: -1.0411968231201172
Batch 60/64 loss: -1.1001272201538086
Batch 61/64 loss: -1.1841421127319336
Batch 62/64 loss: -0.7813882827758789
Batch 63/64 loss: -1.6178417205810547
Batch 64/64 loss: -5.3714189529418945
Epoch 63  Train loss: -1.509763930825626  Val loss: -1.351895125870852
Epoch 64
-------------------------------
Batch 1/64 loss: -1.2429389953613281
Batch 2/64 loss: -0.6731119155883789
Batch 3/64 loss: -1.1887941360473633
Batch 4/64 loss: -1.203984260559082
Batch 5/64 loss: -1.428466796875
Batch 6/64 loss: -1.221231460571289
Batch 7/64 loss: -0.8870306015014648
Batch 8/64 loss: -1.013230323791504
Batch 9/64 loss: -0.47992515563964844
Batch 10/64 loss: -1.3368511199951172
Batch 11/64 loss: -0.9586582183837891
Batch 12/64 loss: -1.3460474014282227
Batch 13/64 loss: -0.6651744842529297
Batch 14/64 loss: -0.9155559539794922
Batch 15/64 loss: -1.1444015502929688
Batch 16/64 loss: -1.0432233810424805
Batch 17/64 loss: -0.7406606674194336
Batch 18/64 loss: -1.2713003158569336
Batch 19/64 loss: -1.0118169784545898
Batch 20/64 loss: -1.3992319107055664
Batch 21/64 loss: -1.347005844116211
Batch 22/64 loss: -0.30613040924072266
Batch 23/64 loss: -1.3647527694702148
Batch 24/64 loss: -1.3091468811035156
Batch 25/64 loss: -1.10723876953125
Batch 26/64 loss: -1.2745437622070312
Batch 27/64 loss: -1.6417913436889648
Batch 28/64 loss: -1.5126686096191406
Batch 29/64 loss: -1.571080207824707
Batch 30/64 loss: -1.657017707824707
Batch 31/64 loss: -1.0025548934936523
Batch 32/64 loss: -1.3092355728149414
Batch 33/64 loss: -1.3219938278198242
Batch 34/64 loss: -0.9324131011962891
Batch 35/64 loss: -1.5052881240844727
Batch 36/64 loss: -1.3796720504760742
Batch 37/64 loss: -1.7378606796264648
Batch 38/64 loss: -1.295100212097168
Batch 39/64 loss: -1.0993766784667969
Batch 40/64 loss: -1.077591896057129
Batch 41/64 loss: -1.454458236694336
Batch 42/64 loss: -0.3759431838989258
Batch 43/64 loss: -1.0434198379516602
Batch 44/64 loss: -1.4397573471069336
Batch 45/64 loss: -1.0776481628417969
Batch 46/64 loss: -1.4648942947387695
Batch 47/64 loss: -1.4386177062988281
Batch 48/64 loss: -1.3410263061523438
Batch 49/64 loss: -1.0767059326171875
Batch 50/64 loss: -1.590841293334961
Batch 51/64 loss: -1.7959604263305664
Batch 52/64 loss: -1.4929380416870117
Batch 53/64 loss: -1.7077884674072266
Batch 54/64 loss: -1.382695198059082
Batch 55/64 loss: -1.548964500427246
Batch 56/64 loss: -1.5124702453613281
Batch 57/64 loss: -1.3295087814331055
Batch 58/64 loss: -1.635634422302246
Batch 59/64 loss: -1.2911176681518555
Batch 60/64 loss: -1.5671119689941406
Batch 61/64 loss: 0.7835159301757812
Batch 62/64 loss: -1.314162254333496
Batch 63/64 loss: -0.8113183975219727
Batch 64/64 loss: -6.109647750854492
Epoch 64  Train loss: -1.2614243376488778  Val loss: -1.4764833876357455
Epoch 65
-------------------------------
Batch 1/64 loss: -1.5179996490478516
Batch 2/64 loss: -1.6298294067382812
Batch 3/64 loss: -1.0470209121704102
Batch 4/64 loss: -1.2657108306884766
Batch 5/64 loss: -1.3450956344604492
Batch 6/64 loss: -1.5150890350341797
Batch 7/64 loss: -1.711618423461914
Batch 8/64 loss: -1.7039518356323242
Batch 9/64 loss: -1.0885076522827148
Batch 10/64 loss: -1.0086040496826172
Batch 11/64 loss: -1.8126821517944336
Batch 12/64 loss: -1.370748519897461
Batch 13/64 loss: -1.4883499145507812
Batch 14/64 loss: -1.2399463653564453
Batch 15/64 loss: -1.1866378784179688
Batch 16/64 loss: -1.635519027709961
Batch 17/64 loss: -1.4471826553344727
Batch 18/64 loss: -1.3365135192871094
Batch 19/64 loss: -1.5976276397705078
Batch 20/64 loss: -1.1371965408325195
Batch 21/64 loss: -1.5790338516235352
Batch 22/64 loss: -1.6309185028076172
Batch 23/64 loss: -1.0887832641601562
Batch 24/64 loss: -1.4471826553344727
Batch 25/64 loss: -1.7589569091796875
Batch 26/64 loss: -1.7375545501708984
Batch 27/64 loss: -1.6830501556396484
Batch 28/64 loss: -1.437021255493164
Batch 29/64 loss: -1.272078514099121
Batch 30/64 loss: -1.616623878479004
Batch 31/64 loss: -1.8028125762939453
Batch 32/64 loss: -1.5885429382324219
Batch 33/64 loss: -1.4496889114379883
Batch 34/64 loss: -1.6989974975585938
Batch 35/64 loss: -1.6303167343139648
Batch 36/64 loss: -1.4153099060058594
Batch 37/64 loss: -1.441244125366211
Batch 38/64 loss: -1.567509651184082
Batch 39/64 loss: -1.6885147094726562
Batch 40/64 loss: -1.8179254531860352
Batch 41/64 loss: -1.8795080184936523
Batch 42/64 loss: -1.457686424255371
Batch 43/64 loss: -1.351165771484375
Batch 44/64 loss: -0.8832645416259766
Batch 45/64 loss: -1.3061370849609375
Batch 46/64 loss: -1.3623123168945312
Batch 47/64 loss: -1.6777105331420898
Batch 48/64 loss: -1.0577106475830078
Batch 49/64 loss: -1.1095104217529297
Batch 50/64 loss: -1.28875732421875
Batch 51/64 loss: -1.7488365173339844
Batch 52/64 loss: -1.513533592224121
Batch 53/64 loss: -1.4385900497436523
Batch 54/64 loss: -1.540419578552246
Batch 55/64 loss: -1.683344841003418
Batch 56/64 loss: -1.6791448593139648
Batch 57/64 loss: -0.678462028503418
Batch 58/64 loss: -1.6327228546142578
Batch 59/64 loss: -1.6150283813476562
Batch 60/64 loss: -1.5495338439941406
Batch 61/64 loss: -1.2100143432617188
Batch 62/64 loss: -1.4172754287719727
Batch 63/64 loss: -1.48004150390625
Batch 64/64 loss: -5.876077651977539
Epoch 65  Train loss: -1.5122457541671455  Val loss: -1.5044563398328434
Epoch 66
-------------------------------
Batch 1/64 loss: -1.4365034103393555
Batch 2/64 loss: -1.4522886276245117
Batch 3/64 loss: -1.357858657836914
Batch 4/64 loss: -1.8490161895751953
Batch 5/64 loss: -1.5314464569091797
Batch 6/64 loss: -1.6011114120483398
Batch 7/64 loss: -1.5041427612304688
Batch 8/64 loss: -2.020994186401367
Batch 9/64 loss: -1.7245635986328125
Batch 10/64 loss: -1.602254867553711
Batch 11/64 loss: -1.3937644958496094
Batch 12/64 loss: -1.7428655624389648
Batch 13/64 loss: -1.5330982208251953
Batch 14/64 loss: -1.587447166442871
Batch 15/64 loss: -1.5846929550170898
Batch 16/64 loss: -1.4523487091064453
Batch 17/64 loss: -1.5673952102661133
Batch 18/64 loss: -1.6951541900634766
Batch 19/64 loss: -1.4701051712036133
Batch 20/64 loss: -1.6467647552490234
Batch 21/64 loss: -0.8982067108154297
Batch 22/64 loss: -1.216465950012207
Batch 23/64 loss: -1.8080720901489258
Batch 24/64 loss: -1.306401252746582
Batch 25/64 loss: -1.5227327346801758
Batch 26/64 loss: -1.7473649978637695
Batch 27/64 loss: -1.7644309997558594
Batch 28/64 loss: -1.2665176391601562
Batch 29/64 loss: -1.217726707458496
Batch 30/64 loss: -1.668771743774414
Batch 31/64 loss: -1.4936046600341797
Batch 32/64 loss: -1.7657785415649414
Batch 33/64 loss: -1.449789047241211
Batch 34/64 loss: -1.4714584350585938
Batch 35/64 loss: -1.2427186965942383
Batch 36/64 loss: -1.4361257553100586
Batch 37/64 loss: -1.4241619110107422
Batch 38/64 loss: -1.379164695739746
Batch 39/64 loss: -1.5959644317626953
Batch 40/64 loss: -1.232736587524414
Batch 41/64 loss: -1.5531158447265625
Batch 42/64 loss: -1.7066574096679688
Batch 43/64 loss: -1.0656299591064453
Batch 44/64 loss: -1.1654319763183594
Batch 45/64 loss: -0.9854965209960938
Batch 46/64 loss: -1.0441932678222656
Batch 47/64 loss: -1.3241748809814453
Batch 48/64 loss: -1.3114347457885742
Batch 49/64 loss: -1.2163515090942383
Batch 50/64 loss: -1.6702594757080078
Batch 51/64 loss: -1.732522964477539
Batch 52/64 loss: -1.5284843444824219
Batch 53/64 loss: -1.417276382446289
Batch 54/64 loss: -1.3429985046386719
Batch 55/64 loss: -1.763906478881836
Batch 56/64 loss: -1.521378517150879
Batch 57/64 loss: -1.4740123748779297
Batch 58/64 loss: -1.1807327270507812
Batch 59/64 loss: -1.466562271118164
Batch 60/64 loss: -1.3173513412475586
Batch 61/64 loss: -1.2964296340942383
Batch 62/64 loss: -1.3194351196289062
Batch 63/64 loss: -1.8741703033447266
Batch 64/64 loss: -5.942410469055176
Epoch 66  Train loss: -1.527793327032351  Val loss: -1.6448179684144115
Epoch 67
-------------------------------
Batch 1/64 loss: -1.5422143936157227
Batch 2/64 loss: -1.2391386032104492
Batch 3/64 loss: -1.294118881225586
Batch 4/64 loss: -1.8140926361083984
Batch 5/64 loss: -1.6327762603759766
Batch 6/64 loss: -1.231684684753418
Batch 7/64 loss: -1.5406427383422852
Batch 8/64 loss: -1.452871322631836
Batch 9/64 loss: -1.8414697647094727
Batch 10/64 loss: -1.5320472717285156
Batch 11/64 loss: -1.8079767227172852
Batch 12/64 loss: -1.7311277389526367
Batch 13/64 loss: -1.8609561920166016
Batch 14/64 loss: -1.6170663833618164
Batch 15/64 loss: -1.5242033004760742
Batch 16/64 loss: -1.6982440948486328
Batch 17/64 loss: -1.7106971740722656
Batch 18/64 loss: -1.6474151611328125
Batch 19/64 loss: -1.2178640365600586
Batch 20/64 loss: -1.4713220596313477
Batch 21/64 loss: -1.8407812118530273
Batch 22/64 loss: -1.7600955963134766
Batch 23/64 loss: -1.4579410552978516
Batch 24/64 loss: -1.5110349655151367
Batch 25/64 loss: -1.7573118209838867
Batch 26/64 loss: -1.622629165649414
Batch 27/64 loss: -1.7630348205566406
Batch 28/64 loss: -1.0025930404663086
Batch 29/64 loss: -1.5499811172485352
Batch 30/64 loss: -0.6997127532958984
Batch 31/64 loss: -1.368398666381836
Batch 32/64 loss: -1.6127185821533203
Batch 33/64 loss: -1.235513687133789
Batch 34/64 loss: -1.7288084030151367
Batch 35/64 loss: -1.758549690246582
Batch 36/64 loss: -1.4841747283935547
Batch 37/64 loss: -1.7232770919799805
Batch 38/64 loss: -1.5426216125488281
Batch 39/64 loss: -1.5583162307739258
Batch 40/64 loss: -1.3295660018920898
Batch 41/64 loss: -0.9611549377441406
Batch 42/64 loss: -1.5906715393066406
Batch 43/64 loss: -1.6169395446777344
Batch 44/64 loss: -1.3783721923828125
Batch 45/64 loss: -1.614706039428711
Batch 46/64 loss: -1.7599172592163086
Batch 47/64 loss: -1.2750959396362305
Batch 48/64 loss: -0.7268314361572266
Batch 49/64 loss: -1.1940593719482422
Batch 50/64 loss: -1.1408710479736328
Batch 51/64 loss: -1.582143783569336
Batch 52/64 loss: -1.698857307434082
Batch 53/64 loss: -1.509469985961914
Batch 54/64 loss: -1.7042913436889648
Batch 55/64 loss: -1.6800527572631836
Batch 56/64 loss: -1.6673450469970703
Batch 57/64 loss: -1.5898323059082031
Batch 58/64 loss: -1.9229469299316406
Batch 59/64 loss: -1.5143451690673828
Batch 60/64 loss: -1.5502634048461914
Batch 61/64 loss: -1.9047508239746094
Batch 62/64 loss: -1.369659423828125
Batch 63/64 loss: -1.1637592315673828
Batch 64/64 loss: -5.913459777832031
Epoch 67  Train loss: -1.572806608910654  Val loss: -1.6514286683597106
Epoch 68
-------------------------------
Batch 1/64 loss: -1.8535242080688477
Batch 2/64 loss: -1.5854501724243164
Batch 3/64 loss: -1.4006242752075195
Batch 4/64 loss: -1.7189788818359375
Batch 5/64 loss: -1.5314579010009766
Batch 6/64 loss: -1.7636327743530273
Batch 7/64 loss: -1.6301822662353516
Batch 8/64 loss: -1.458083152770996
Batch 9/64 loss: -1.528738021850586
Batch 10/64 loss: -1.6544256210327148
Batch 11/64 loss: -1.8488378524780273
Batch 12/64 loss: -1.7682485580444336
Batch 13/64 loss: -1.3903217315673828
Batch 14/64 loss: -1.5697755813598633
Batch 15/64 loss: -1.9375686645507812
Batch 16/64 loss: -0.7131166458129883
Batch 17/64 loss: -1.5393400192260742
Batch 18/64 loss: -1.628030776977539
Batch 19/64 loss: -1.617873191833496
Batch 20/64 loss: -1.7637901306152344
Batch 21/64 loss: -1.6732139587402344
Batch 22/64 loss: -1.779555320739746
Batch 23/64 loss: -1.5638294219970703
Batch 24/64 loss: -1.857316017150879
Batch 25/64 loss: -1.745859146118164
Batch 26/64 loss: -1.3473577499389648
Batch 27/64 loss: -1.6467018127441406
Batch 28/64 loss: -1.8703556060791016
Batch 29/64 loss: -1.3964958190917969
Batch 30/64 loss: -1.8683338165283203
Batch 31/64 loss: -1.2697458267211914
Batch 32/64 loss: -1.16070556640625
Batch 33/64 loss: -1.607370376586914
Batch 34/64 loss: -1.5642328262329102
Batch 35/64 loss: -1.5072832107543945
Batch 36/64 loss: -1.710855484008789
Batch 37/64 loss: -1.2722854614257812
Batch 38/64 loss: -1.5333194732666016
Batch 39/64 loss: -1.5897579193115234
Batch 40/64 loss: -1.4124870300292969
Batch 41/64 loss: -1.4536981582641602
Batch 42/64 loss: -1.7384405136108398
Batch 43/64 loss: -1.9706363677978516
Batch 44/64 loss: -1.4172601699829102
Batch 45/64 loss: -0.8600339889526367
Batch 46/64 loss: -1.8003969192504883
Batch 47/64 loss: -1.7299585342407227
Batch 48/64 loss: -1.5430412292480469
Batch 49/64 loss: -1.7264862060546875
Batch 50/64 loss: -1.5069236755371094
Batch 51/64 loss: -1.1597528457641602
Batch 52/64 loss: -1.7099714279174805
Batch 53/64 loss: -1.7047491073608398
Batch 54/64 loss: -0.7591543197631836
Batch 55/64 loss: -1.4808874130249023
Batch 56/64 loss: -1.1066570281982422
Batch 57/64 loss: -1.6371383666992188
Batch 58/64 loss: -1.6607303619384766
Batch 59/64 loss: -1.5990943908691406
Batch 60/64 loss: -1.792104721069336
Batch 61/64 loss: -1.293828010559082
Batch 62/64 loss: -1.251143455505371
Batch 63/64 loss: -1.7285842895507812
Batch 64/64 loss: -5.837907314300537
Epoch 68  Train loss: -1.6045202236549527  Val loss: -1.2594418738715838
Epoch 69
-------------------------------
Batch 1/64 loss: -1.1747550964355469
Batch 2/64 loss: -1.9939603805541992
Batch 3/64 loss: -1.6005687713623047
Batch 4/64 loss: -0.846771240234375
Batch 5/64 loss: -1.764430046081543
Batch 6/64 loss: -1.582230567932129
Batch 7/64 loss: -1.5540571212768555
Batch 8/64 loss: -1.8208694458007812
Batch 9/64 loss: -1.381352424621582
Batch 10/64 loss: -1.4164400100708008
Batch 11/64 loss: -1.4479246139526367
Batch 12/64 loss: -1.564523696899414
Batch 13/64 loss: -1.4292230606079102
Batch 14/64 loss: -1.7851200103759766
Batch 15/64 loss: -1.7401371002197266
Batch 16/64 loss: -1.3441476821899414
Batch 17/64 loss: -1.7500629425048828
Batch 18/64 loss: -1.1329059600830078
Batch 19/64 loss: -1.2914485931396484
Batch 20/64 loss: -1.4586267471313477
Batch 21/64 loss: -1.760697364807129
Batch 22/64 loss: -1.3629465103149414
Batch 23/64 loss: -1.3869400024414062
Batch 24/64 loss: -1.1266069412231445
Batch 25/64 loss: -1.8151435852050781
Batch 26/64 loss: -1.6262836456298828
Batch 27/64 loss: -1.3421497344970703
Batch 28/64 loss: -1.8169527053833008
Batch 29/64 loss: -1.6015958786010742
Batch 30/64 loss: -1.8623886108398438
Batch 31/64 loss: -1.477778434753418
Batch 32/64 loss: -1.6603202819824219
Batch 33/64 loss: -1.4310226440429688
Batch 34/64 loss: -1.7262382507324219
Batch 35/64 loss: -1.831242561340332
Batch 36/64 loss: -1.4830350875854492
Batch 37/64 loss: -1.504155158996582
Batch 38/64 loss: -1.7048864364624023
Batch 39/64 loss: -1.0868558883666992
Batch 40/64 loss: -1.7726430892944336
Batch 41/64 loss: -1.709792137145996
Batch 42/64 loss: -1.3744144439697266
Batch 43/64 loss: -1.7971162796020508
Batch 44/64 loss: -1.3723945617675781
Batch 45/64 loss: -1.1869564056396484
Batch 46/64 loss: -1.4708442687988281
Batch 47/64 loss: -1.623311996459961
Batch 48/64 loss: -1.7220687866210938
Batch 49/64 loss: -1.6306085586547852
Batch 50/64 loss: -1.7579593658447266
Batch 51/64 loss: -1.5729999542236328
Batch 52/64 loss: -1.6340360641479492
Batch 53/64 loss: -1.8512964248657227
Batch 54/64 loss: -1.479654312133789
Batch 55/64 loss: -1.5547266006469727
Batch 56/64 loss: -1.5888566970825195
Batch 57/64 loss: -1.4053850173950195
Batch 58/64 loss: -1.5455551147460938
Batch 59/64 loss: -1.8102102279663086
Batch 60/64 loss: -1.8237266540527344
Batch 61/64 loss: -1.9968643188476562
Batch 62/64 loss: -1.316812515258789
Batch 63/64 loss: -1.739027976989746
Batch 64/64 loss: -5.559690475463867
Epoch 69  Train loss: -1.60931489981857  Val loss: -1.5982443163894706
Epoch 70
-------------------------------
Batch 1/64 loss: -1.4136943817138672
Batch 2/64 loss: -1.285543441772461
Batch 3/64 loss: -1.5060710906982422
Batch 4/64 loss: -1.5996818542480469
Batch 5/64 loss: -1.7455596923828125
Batch 6/64 loss: -1.6514568328857422
Batch 7/64 loss: -1.5958671569824219
Batch 8/64 loss: -1.5165681838989258
Batch 9/64 loss: -1.2227354049682617
Batch 10/64 loss: -1.6840219497680664
Batch 11/64 loss: -1.5531835556030273
Batch 12/64 loss: -1.886580467224121
Batch 13/64 loss: -1.4135971069335938
Batch 14/64 loss: -1.549494743347168
Batch 15/64 loss: -1.7239160537719727
Batch 16/64 loss: -1.3106050491333008
Batch 17/64 loss: -1.9268827438354492
Batch 18/64 loss: -1.466238021850586
Batch 19/64 loss: -1.8607215881347656
Batch 20/64 loss: -1.084482192993164
Batch 21/64 loss: -1.6679153442382812
Batch 22/64 loss: -1.5575284957885742
Batch 23/64 loss: -1.3037357330322266
Batch 24/64 loss: -1.6815948486328125
Batch 25/64 loss: -1.8533811569213867
Batch 26/64 loss: -1.163966178894043
Batch 27/64 loss: -1.547475814819336
Batch 28/64 loss: -1.8170099258422852
Batch 29/64 loss: -1.8188514709472656
Batch 30/64 loss: -1.4831666946411133
Batch 31/64 loss: -1.7679758071899414
Batch 32/64 loss: -1.7034778594970703
Batch 33/64 loss: -1.5943126678466797
Batch 34/64 loss: -1.7287893295288086
Batch 35/64 loss: -1.4074335098266602
Batch 36/64 loss: -2.031466484069824
Batch 37/64 loss: -1.0611381530761719
Batch 38/64 loss: -1.6193952560424805
Batch 39/64 loss: -1.3941936492919922
Batch 40/64 loss: -1.6213655471801758
Batch 41/64 loss: -1.5620527267456055
Batch 42/64 loss: -1.8251466751098633
Batch 43/64 loss: -1.5756587982177734
Batch 44/64 loss: -1.7446327209472656
Batch 45/64 loss: -1.538351058959961
Batch 46/64 loss: -1.8726024627685547
Batch 47/64 loss: -2.04421329498291
Batch 48/64 loss: -1.6209001541137695
Batch 49/64 loss: -1.8021163940429688
Batch 50/64 loss: -1.3033409118652344
Batch 51/64 loss: -1.8229284286499023
Batch 52/64 loss: -1.7448101043701172
Batch 53/64 loss: -1.6174983978271484
Batch 54/64 loss: -2.0524606704711914
Batch 55/64 loss: -1.6843595504760742
Batch 56/64 loss: -1.5414257049560547
Batch 57/64 loss: -1.512908935546875
Batch 58/64 loss: -1.8317985534667969
Batch 59/64 loss: -1.1575241088867188
Batch 60/64 loss: -1.6905155181884766
Batch 61/64 loss: -1.8335046768188477
Batch 62/64 loss: -1.864959716796875
Batch 63/64 loss: -1.3127241134643555
Batch 64/64 loss: -6.1641740798950195
Epoch 70  Train loss: -1.662755132188984  Val loss: -1.8528682276145698
Saving best model, epoch: 70
Epoch 71
-------------------------------
Batch 1/64 loss: -1.5968132019042969
Batch 2/64 loss: -1.8279123306274414
Batch 3/64 loss: -1.604360580444336
Batch 4/64 loss: -1.6117525100708008
Batch 5/64 loss: -2.024245262145996
Batch 6/64 loss: -1.1568546295166016
Batch 7/64 loss: -1.5374202728271484
Batch 8/64 loss: -1.5244178771972656
Batch 9/64 loss: -1.655893325805664
Batch 10/64 loss: -1.600900650024414
Batch 11/64 loss: -1.7794685363769531
Batch 12/64 loss: -1.680063247680664
Batch 13/64 loss: -1.7588281631469727
Batch 14/64 loss: -1.6511268615722656
Batch 15/64 loss: -1.9346904754638672
Batch 16/64 loss: -1.574824333190918
Batch 17/64 loss: -1.6872930526733398
Batch 18/64 loss: -1.4529743194580078
Batch 19/64 loss: -1.885019302368164
Batch 20/64 loss: -1.2504692077636719
Batch 21/64 loss: -1.6332645416259766
Batch 22/64 loss: -1.9022951126098633
Batch 23/64 loss: -1.5397930145263672
Batch 24/64 loss: -1.8102350234985352
Batch 25/64 loss: -1.7903337478637695
Batch 26/64 loss: -1.7529268264770508
Batch 27/64 loss: -1.5387182235717773
Batch 28/64 loss: -1.7850341796875
Batch 29/64 loss: -1.6156644821166992
Batch 30/64 loss: -1.8504095077514648
Batch 31/64 loss: -1.8093481063842773
Batch 32/64 loss: -1.9423761367797852
Batch 33/64 loss: -1.6054906845092773
Batch 34/64 loss: -1.8481378555297852
Batch 35/64 loss: -1.9249944686889648
Batch 36/64 loss: -1.7536821365356445
Batch 37/64 loss: -1.8910484313964844
Batch 38/64 loss: -1.5543537139892578
Batch 39/64 loss: -1.8533601760864258
Batch 40/64 loss: -1.3848514556884766
Batch 41/64 loss: -1.8607778549194336
Batch 42/64 loss: -1.7599906921386719
Batch 43/64 loss: -1.519017219543457
Batch 44/64 loss: -1.791499137878418
Batch 45/64 loss: -1.9848260879516602
Batch 46/64 loss: -1.7681999206542969
Batch 47/64 loss: -1.4755477905273438
Batch 48/64 loss: -2.0826854705810547
Batch 49/64 loss: -1.4919233322143555
Batch 50/64 loss: -1.9858932495117188
Batch 51/64 loss: -1.7617111206054688
Batch 52/64 loss: -1.8601627349853516
Batch 53/64 loss: -1.510568618774414
Batch 54/64 loss: -1.5569305419921875
Batch 55/64 loss: -1.800297737121582
Batch 56/64 loss: -1.5198078155517578
Batch 57/64 loss: -1.777151107788086
Batch 58/64 loss: -1.5325565338134766
Batch 59/64 loss: -1.4267539978027344
Batch 60/64 loss: -1.1376018524169922
Batch 61/64 loss: -1.7152824401855469
Batch 62/64 loss: -1.1925363540649414
Batch 63/64 loss: -1.7319812774658203
Batch 64/64 loss: -5.708456993103027
Epoch 71  Train loss: -1.7271637897865444  Val loss: -1.1956826960507947
Epoch 72
-------------------------------
Batch 1/64 loss: -1.5156984329223633
Batch 2/64 loss: -1.4288883209228516
Batch 3/64 loss: -1.7282953262329102
Batch 4/64 loss: -1.7163619995117188
Batch 5/64 loss: -1.7121171951293945
Batch 6/64 loss: -1.4744501113891602
Batch 7/64 loss: -1.3427352905273438
Batch 8/64 loss: -1.3978872299194336
Batch 9/64 loss: -1.7042760848999023
Batch 10/64 loss: -1.5008859634399414
Batch 11/64 loss: -1.4722909927368164
Batch 12/64 loss: -1.6461734771728516
Batch 13/64 loss: -1.9372186660766602
Batch 14/64 loss: -1.5409774780273438
Batch 15/64 loss: -1.3615293502807617
Batch 16/64 loss: -1.5243034362792969
Batch 17/64 loss: -1.6686019897460938
Batch 18/64 loss: -1.705240249633789
Batch 19/64 loss: -1.5474071502685547
Batch 20/64 loss: -0.9847545623779297
Batch 21/64 loss: -1.6755151748657227
Batch 22/64 loss: -1.6045894622802734
Batch 23/64 loss: -1.5750179290771484
Batch 24/64 loss: -1.5843629837036133
Batch 25/64 loss: -1.667698860168457
Batch 26/64 loss: -1.3105974197387695
Batch 27/64 loss: -1.7004804611206055
Batch 28/64 loss: -1.559483528137207
Batch 29/64 loss: -1.6284208297729492
Batch 30/64 loss: -1.9304018020629883
Batch 31/64 loss: -1.3991575241088867
Batch 32/64 loss: -1.4906492233276367
Batch 33/64 loss: -1.2971458435058594
Batch 34/64 loss: -1.9873933792114258
Batch 35/64 loss: -0.99615478515625
Batch 36/64 loss: -1.9209556579589844
Batch 37/64 loss: -1.831202507019043
Batch 38/64 loss: -1.7354326248168945
Batch 39/64 loss: -1.6035995483398438
Batch 40/64 loss: -1.6599693298339844
Batch 41/64 loss: -1.5092391967773438
Batch 42/64 loss: -1.7430610656738281
Batch 43/64 loss: -1.6768712997436523
Batch 44/64 loss: -1.811142921447754
Batch 45/64 loss: -1.8732337951660156
Batch 46/64 loss: -1.9036140441894531
Batch 47/64 loss: -1.5737228393554688
Batch 48/64 loss: -1.2424793243408203
Batch 49/64 loss: -1.3265533447265625
Batch 50/64 loss: -1.3334112167358398
Batch 51/64 loss: -1.9673080444335938
Batch 52/64 loss: -1.6104860305786133
Batch 53/64 loss: -2.0075674057006836
Batch 54/64 loss: -1.6266708374023438
Batch 55/64 loss: -1.6601676940917969
Batch 56/64 loss: -1.8559379577636719
Batch 57/64 loss: -1.6175947189331055
Batch 58/64 loss: -1.6996049880981445
Batch 59/64 loss: -1.7130012512207031
Batch 60/64 loss: -1.7633056640625
Batch 61/64 loss: -1.2774858474731445
Batch 62/64 loss: -1.6220693588256836
Batch 63/64 loss: -1.6070222854614258
Batch 64/64 loss: -6.258073329925537
Epoch 72  Train loss: -1.659347895079968  Val loss: -1.9006881713867188
Saving best model, epoch: 72
Epoch 73
-------------------------------
Batch 1/64 loss: -1.357407569885254
Batch 2/64 loss: -1.344400405883789
Batch 3/64 loss: -1.8406295776367188
Batch 4/64 loss: -1.4681205749511719
Batch 5/64 loss: -1.5157194137573242
Batch 6/64 loss: -1.718465805053711
Batch 7/64 loss: -1.6920785903930664
Batch 8/64 loss: -1.6773271560668945
Batch 9/64 loss: -1.2308197021484375
Batch 10/64 loss: -1.3647537231445312
Batch 11/64 loss: -1.7812690734863281
Batch 12/64 loss: -1.621429443359375
Batch 13/64 loss: -1.5352449417114258
Batch 14/64 loss: -1.7768220901489258
Batch 15/64 loss: -1.4894084930419922
Batch 16/64 loss: -1.0113611221313477
Batch 17/64 loss: -1.805222511291504
Batch 18/64 loss: -1.7459077835083008
Batch 19/64 loss: -1.6610002517700195
Batch 20/64 loss: -1.7681913375854492
Batch 21/64 loss: -1.3466720581054688
Batch 22/64 loss: -1.8559436798095703
Batch 23/64 loss: -1.6429510116577148
Batch 24/64 loss: -1.6619386672973633
Batch 25/64 loss: -1.887258529663086
Batch 26/64 loss: -1.4344615936279297
Batch 27/64 loss: -1.5787773132324219
Batch 28/64 loss: -1.4580869674682617
Batch 29/64 loss: -1.4474353790283203
Batch 30/64 loss: -1.888401985168457
Batch 31/64 loss: -1.7425413131713867
Batch 32/64 loss: -1.7762393951416016
Batch 33/64 loss: -1.6663694381713867
Batch 34/64 loss: -1.6010169982910156
Batch 35/64 loss: -2.1121177673339844
Batch 36/64 loss: -1.4217472076416016
Batch 37/64 loss: -2.0417118072509766
Batch 38/64 loss: -2.05977725982666
Batch 39/64 loss: -1.4040040969848633
Batch 40/64 loss: -1.6837491989135742
Batch 41/64 loss: -1.3818778991699219
Batch 42/64 loss: -1.8192720413208008
Batch 43/64 loss: -1.7056074142456055
Batch 44/64 loss: -1.8007173538208008
Batch 45/64 loss: -1.8594341278076172
Batch 46/64 loss: -1.7098770141601562
Batch 47/64 loss: -1.4715948104858398
Batch 48/64 loss: -1.906351089477539
Batch 49/64 loss: -1.3622961044311523
Batch 50/64 loss: -1.9531517028808594
Batch 51/64 loss: -2.0473814010620117
Batch 52/64 loss: -1.7828340530395508
Batch 53/64 loss: -1.4798622131347656
Batch 54/64 loss: -1.5495233535766602
Batch 55/64 loss: -2.0484018325805664
Batch 56/64 loss: -1.3693580627441406
Batch 57/64 loss: -1.8417911529541016
Batch 58/64 loss: -1.6271438598632812
Batch 59/64 loss: -1.5513925552368164
Batch 60/64 loss: -1.6257505416870117
Batch 61/64 loss: -1.6373052597045898
Batch 62/64 loss: -1.828322410583496
Batch 63/64 loss: -1.3358898162841797
Batch 64/64 loss: -6.360836029052734
Epoch 73  Train loss: -1.7032555972828585  Val loss: -1.9156295671495784
Saving best model, epoch: 73
Epoch 74
-------------------------------
Batch 1/64 loss: -1.8471403121948242
Batch 2/64 loss: -1.8269052505493164
Batch 3/64 loss: -1.3962764739990234
Batch 4/64 loss: -1.736851692199707
Batch 5/64 loss: -1.7954826354980469
Batch 6/64 loss: -1.8737382888793945
Batch 7/64 loss: -1.7151641845703125
Batch 8/64 loss: -1.9444694519042969
Batch 9/64 loss: -1.6326484680175781
Batch 10/64 loss: -1.0015621185302734
Batch 11/64 loss: -1.4866180419921875
Batch 12/64 loss: -1.5608940124511719
Batch 13/64 loss: -1.5327224731445312
Batch 14/64 loss: -1.775853157043457
Batch 15/64 loss: -1.3594484329223633
Batch 16/64 loss: -1.4572162628173828
Batch 17/64 loss: -1.6259231567382812
Batch 18/64 loss: -1.7769994735717773
Batch 19/64 loss: -1.9405479431152344
Batch 20/64 loss: -1.7086296081542969
Batch 21/64 loss: -1.7061214447021484
Batch 22/64 loss: -1.6657094955444336
Batch 23/64 loss: -2.0268869400024414
Batch 24/64 loss: -1.7619361877441406
Batch 25/64 loss: -1.7409477233886719
Batch 26/64 loss: -1.643784523010254
Batch 27/64 loss: -1.5006475448608398
Batch 28/64 loss: -1.682180404663086
Batch 29/64 loss: -1.9992618560791016
Batch 30/64 loss: -1.8201885223388672
Batch 31/64 loss: -1.8416032791137695
Batch 32/64 loss: -1.7428083419799805
Batch 33/64 loss: -1.5698661804199219
Batch 34/64 loss: -1.379953384399414
Batch 35/64 loss: -1.5021686553955078
Batch 36/64 loss: -1.7553491592407227
Batch 37/64 loss: -1.595815658569336
Batch 38/64 loss: -1.9230365753173828
Batch 39/64 loss: -1.8603572845458984
Batch 40/64 loss: -1.6937437057495117
Batch 41/64 loss: -1.7109479904174805
Batch 42/64 loss: -2.0302839279174805
Batch 43/64 loss: -1.1908702850341797
Batch 44/64 loss: -1.1524887084960938
Batch 45/64 loss: -1.692185401916504
Batch 46/64 loss: -1.766829490661621
Batch 47/64 loss: -1.590468406677246
Batch 48/64 loss: -1.8813419342041016
Batch 49/64 loss: -1.3277587890625
Batch 50/64 loss: -1.5906572341918945
Batch 51/64 loss: -1.6856498718261719
Batch 52/64 loss: -1.3168563842773438
Batch 53/64 loss: -1.7992973327636719
Batch 54/64 loss: -1.7311782836914062
Batch 55/64 loss: -1.4834232330322266
Batch 56/64 loss: -1.934107780456543
Batch 57/64 loss: -1.6364126205444336
Batch 58/64 loss: -1.2335186004638672
Batch 59/64 loss: -1.8581485748291016
Batch 60/64 loss: -1.9369020462036133
Batch 61/64 loss: -1.7415733337402344
Batch 62/64 loss: -1.6341876983642578
Batch 63/64 loss: -1.8141603469848633
Batch 64/64 loss: -5.940916538238525
Epoch 74  Train loss: -1.7192532389771704  Val loss: -1.7972787548995919
Epoch 75
-------------------------------
Batch 1/64 loss: -1.5475282669067383
Batch 2/64 loss: -1.8886632919311523
Batch 3/64 loss: -1.6230173110961914
Batch 4/64 loss: -1.6780881881713867
Batch 5/64 loss: -1.6779098510742188
Batch 6/64 loss: -1.9997787475585938
Batch 7/64 loss: -1.4797754287719727
Batch 8/64 loss: -1.7226505279541016
Batch 9/64 loss: -1.5483875274658203
Batch 10/64 loss: -1.8157520294189453
Batch 11/64 loss: -1.623734474182129
Batch 12/64 loss: -1.6791372299194336
Batch 13/64 loss: -1.676025390625
Batch 14/64 loss: -1.4827766418457031
Batch 15/64 loss: -1.7078971862792969
Batch 16/64 loss: -1.2629013061523438
Batch 17/64 loss: -1.7146625518798828
Batch 18/64 loss: -1.7607078552246094
Batch 19/64 loss: -1.8900680541992188
Batch 20/64 loss: -1.8123664855957031
Batch 21/64 loss: -1.6742525100708008
Batch 22/64 loss: -1.9481687545776367
Batch 23/64 loss: -1.824808120727539
Batch 24/64 loss: -1.7520427703857422
Batch 25/64 loss: -1.7418384552001953
Batch 26/64 loss: -1.2776737213134766
Batch 27/64 loss: -1.7105979919433594
Batch 28/64 loss: -1.8909072875976562
Batch 29/64 loss: -1.045999526977539
Batch 30/64 loss: -1.5352821350097656
Batch 31/64 loss: -1.8484392166137695
Batch 32/64 loss: -1.7374029159545898
Batch 33/64 loss: -1.9340972900390625
Batch 34/64 loss: -1.693781852722168
Batch 35/64 loss: -1.8601350784301758
Batch 36/64 loss: -1.5667076110839844
Batch 37/64 loss: -1.7702703475952148
Batch 38/64 loss: -1.8572750091552734
Batch 39/64 loss: -1.7513484954833984
Batch 40/64 loss: -1.4786500930786133
Batch 41/64 loss: -1.7617979049682617
Batch 42/64 loss: -1.8051862716674805
Batch 43/64 loss: -2.0570716857910156
Batch 44/64 loss: -1.7691364288330078
Batch 45/64 loss: -1.8178911209106445
Batch 46/64 loss: -1.896575927734375
Batch 47/64 loss: -1.525259017944336
Batch 48/64 loss: -1.8371238708496094
Batch 49/64 loss: -1.5714540481567383
Batch 50/64 loss: -1.6825408935546875
Batch 51/64 loss: -1.8054475784301758
Batch 52/64 loss: -2.0258922576904297
Batch 53/64 loss: -1.9048986434936523
Batch 54/64 loss: -1.2989788055419922
Batch 55/64 loss: -1.180363655090332
Batch 56/64 loss: -1.8835668563842773
Batch 57/64 loss: -1.629256248474121
Batch 58/64 loss: -1.4015111923217773
Batch 59/64 loss: -1.5821962356567383
Batch 60/64 loss: -1.8244962692260742
Batch 61/64 loss: -1.5749330520629883
Batch 62/64 loss: -1.63909912109375
Batch 63/64 loss: -1.848855972290039
Batch 64/64 loss: -5.731452465057373
Epoch 75  Train loss: -1.742958900975246  Val loss: -1.9792273872087092
Saving best model, epoch: 75
Epoch 76
-------------------------------
Batch 1/64 loss: -2.0435352325439453
Batch 2/64 loss: -1.7778301239013672
Batch 3/64 loss: -1.7500619888305664
Batch 4/64 loss: -2.049880027770996
Batch 5/64 loss: -1.9084711074829102
Batch 6/64 loss: -1.6611700057983398
Batch 7/64 loss: -1.5360946655273438
Batch 8/64 loss: -1.7954473495483398
Batch 9/64 loss: -1.4497098922729492
Batch 10/64 loss: -1.9099903106689453
Batch 11/64 loss: -1.7503576278686523
Batch 12/64 loss: -1.7979621887207031
Batch 13/64 loss: -1.7841072082519531
Batch 14/64 loss: -1.7693872451782227
Batch 15/64 loss: -1.4923648834228516
Batch 16/64 loss: -2.097792625427246
Batch 17/64 loss: -1.8283967971801758
Batch 18/64 loss: -1.7840547561645508
Batch 19/64 loss: -1.875065803527832
Batch 20/64 loss: -1.3720684051513672
Batch 21/64 loss: -1.8228416442871094
Batch 22/64 loss: -1.4887075424194336
Batch 23/64 loss: -1.8472747802734375
Batch 24/64 loss: -1.4320383071899414
Batch 25/64 loss: -1.2299919128417969
Batch 26/64 loss: -1.101963996887207
Batch 27/64 loss: -2.061023712158203
Batch 28/64 loss: -1.8283252716064453
Batch 29/64 loss: -1.7703733444213867
Batch 30/64 loss: -1.6673965454101562
Batch 31/64 loss: -1.7662248611450195
Batch 32/64 loss: -1.5562000274658203
Batch 33/64 loss: -2.0004148483276367
Batch 34/64 loss: -1.8878297805786133
Batch 35/64 loss: -1.9386072158813477
Batch 36/64 loss: -1.5688543319702148
Batch 37/64 loss: -1.8114633560180664
Batch 38/64 loss: -1.5526161193847656
Batch 39/64 loss: -1.9686193466186523
Batch 40/64 loss: -1.679976463317871
Batch 41/64 loss: -1.355971336364746
Batch 42/64 loss: -1.8517875671386719
Batch 43/64 loss: -1.5616474151611328
Batch 44/64 loss: -1.606398582458496
Batch 45/64 loss: -1.5805644989013672
Batch 46/64 loss: -1.835261344909668
Batch 47/64 loss: -1.8952207565307617
Batch 48/64 loss: -1.804448127746582
Batch 49/64 loss: -1.6035432815551758
Batch 50/64 loss: -1.6229877471923828
Batch 51/64 loss: -1.8471908569335938
Batch 52/64 loss: -1.605698585510254
Batch 53/64 loss: -1.5061845779418945
Batch 54/64 loss: -1.8736839294433594
Batch 55/64 loss: -1.8689193725585938
Batch 56/64 loss: -1.735264778137207
Batch 57/64 loss: -1.6279010772705078
Batch 58/64 loss: -1.838334083557129
Batch 59/64 loss: -1.7456722259521484
Batch 60/64 loss: -1.6348991394042969
Batch 61/64 loss: -1.770339012145996
Batch 62/64 loss: -2.0312414169311523
Batch 63/64 loss: -1.812255859375
Batch 64/64 loss: -6.377421855926514
Epoch 76  Train loss: -1.7853015469569786  Val loss: -1.8080861724119415
Epoch 77
-------------------------------
Batch 1/64 loss: -1.5845985412597656
Batch 2/64 loss: -1.5452909469604492
Batch 3/64 loss: -2.020735740661621
Batch 4/64 loss: -1.8137741088867188
Batch 5/64 loss: -1.7518243789672852
Batch 6/64 loss: -1.7411460876464844
Batch 7/64 loss: -2.1164960861206055
Batch 8/64 loss: -1.8503007888793945
Batch 9/64 loss: -1.6079025268554688
Batch 10/64 loss: -1.9283361434936523
Batch 11/64 loss: -2.017385482788086
Batch 12/64 loss: -1.538823127746582
Batch 13/64 loss: -1.844071388244629
Batch 14/64 loss: -1.350642204284668
Batch 15/64 loss: -1.1148910522460938
Batch 16/64 loss: -1.5481071472167969
Batch 17/64 loss: -1.676828384399414
Batch 18/64 loss: -1.8438901901245117
Batch 19/64 loss: -2.09329891204834
Batch 20/64 loss: -1.500910758972168
Batch 21/64 loss: -1.871988296508789
Batch 22/64 loss: -1.3986129760742188
Batch 23/64 loss: -2.0564117431640625
Batch 24/64 loss: -1.810211181640625
Batch 25/64 loss: -1.9281978607177734
Batch 26/64 loss: -1.5937061309814453
Batch 27/64 loss: -2.139118194580078
Batch 28/64 loss: -2.0615711212158203
Batch 29/64 loss: -1.851226806640625
Batch 30/64 loss: -1.7509336471557617
Batch 31/64 loss: -1.9792451858520508
Batch 32/64 loss: -1.8473825454711914
Batch 33/64 loss: -1.9140548706054688
Batch 34/64 loss: -1.375828742980957
Batch 35/64 loss: -1.9323663711547852
Batch 36/64 loss: -1.7678747177124023
Batch 37/64 loss: -2.0790786743164062
Batch 38/64 loss: -1.9575042724609375
Batch 39/64 loss: -1.7150354385375977
Batch 40/64 loss: -1.7592992782592773
Batch 41/64 loss: -1.3087272644042969
Batch 42/64 loss: -1.6882638931274414
Batch 43/64 loss: -1.28387451171875
Batch 44/64 loss: -1.8522062301635742
Batch 45/64 loss: -1.786865234375
Batch 46/64 loss: -1.8290767669677734
Batch 47/64 loss: -1.534078598022461
Batch 48/64 loss: -1.566361427307129
Batch 49/64 loss: -1.7087526321411133
Batch 50/64 loss: -1.4375629425048828
Batch 51/64 loss: -1.8870048522949219
Batch 52/64 loss: -1.7021093368530273
Batch 53/64 loss: -2.0053787231445312
Batch 54/64 loss: -1.598799705505371
Batch 55/64 loss: -1.3871898651123047
Batch 56/64 loss: -1.775247573852539
Batch 57/64 loss: -1.852309226989746
Batch 58/64 loss: -1.8057289123535156
Batch 59/64 loss: -1.757725715637207
Batch 60/64 loss: -1.5296382904052734
Batch 61/64 loss: -1.8304929733276367
Batch 62/64 loss: -1.975172996520996
Batch 63/64 loss: -1.479043960571289
Batch 64/64 loss: -5.878109931945801
Epoch 77  Train loss: -1.7924564099779317  Val loss: -1.6920444055930854
Epoch 78
-------------------------------
Batch 1/64 loss: -1.5305347442626953
Batch 2/64 loss: -1.8860454559326172
Batch 3/64 loss: -1.8405113220214844
Batch 4/64 loss: -1.7218847274780273
Batch 5/64 loss: -1.9844846725463867
Batch 6/64 loss: -1.8455352783203125
Batch 7/64 loss: -1.359025001525879
Batch 8/64 loss: -1.434316635131836
Batch 9/64 loss: -1.7517642974853516
Batch 10/64 loss: -1.4247941970825195
Batch 11/64 loss: -1.6502408981323242
Batch 12/64 loss: -1.7115764617919922
Batch 13/64 loss: -1.5627899169921875
Batch 14/64 loss: -1.883082389831543
Batch 15/64 loss: -1.8877754211425781
Batch 16/64 loss: -1.669825553894043
Batch 17/64 loss: -1.6884040832519531
Batch 18/64 loss: -1.8689279556274414
Batch 19/64 loss: -1.4909286499023438
Batch 20/64 loss: -0.9038114547729492
Batch 21/64 loss: -1.7902841567993164
Batch 22/64 loss: -1.8203067779541016
Batch 23/64 loss: -1.8846368789672852
Batch 24/64 loss: -1.781773567199707
Batch 25/64 loss: -1.9877214431762695
Batch 26/64 loss: -1.660369873046875
Batch 27/64 loss: -2.0547056198120117
Batch 28/64 loss: -1.8746004104614258
Batch 29/64 loss: -1.8261423110961914
Batch 30/64 loss: -1.7775888442993164
Batch 31/64 loss: -1.8684282302856445
Batch 32/64 loss: -1.8041515350341797
Batch 33/64 loss: -1.1998672485351562
Batch 34/64 loss: -1.8158349990844727
Batch 35/64 loss: -1.9565324783325195
Batch 36/64 loss: -1.15234375
Batch 37/64 loss: -1.6354780197143555
Batch 38/64 loss: -1.9208812713623047
Batch 39/64 loss: -1.7396516799926758
Batch 40/64 loss: -1.7267093658447266
Batch 41/64 loss: -1.558457374572754
Batch 42/64 loss: -1.5450468063354492
Batch 43/64 loss: -2.034639358520508
Batch 44/64 loss: -1.7239818572998047
Batch 45/64 loss: -1.9485597610473633
Batch 46/64 loss: -1.4489965438842773
Batch 47/64 loss: -1.6708335876464844
Batch 48/64 loss: -1.9856204986572266
Batch 49/64 loss: -1.64227294921875
Batch 50/64 loss: -1.090834617614746
Batch 51/64 loss: -1.586745262145996
Batch 52/64 loss: -1.5761404037475586
Batch 53/64 loss: -1.5797185897827148
Batch 54/64 loss: -1.5829658508300781
Batch 55/64 loss: -1.7395849227905273
Batch 56/64 loss: -1.484644889831543
Batch 57/64 loss: -1.2395553588867188
Batch 58/64 loss: -1.857985496520996
Batch 59/64 loss: -1.3855199813842773
Batch 60/64 loss: -1.398636817932129
Batch 61/64 loss: -1.7051429748535156
Batch 62/64 loss: -1.613142967224121
Batch 63/64 loss: -1.5361480712890625
Batch 64/64 loss: -5.293741226196289
Epoch 78  Train loss: -1.7141921323888443  Val loss: -1.770938427587555
Epoch 79
-------------------------------
Batch 1/64 loss: -1.5263299942016602
Batch 2/64 loss: -1.6485748291015625
Batch 3/64 loss: -1.5647964477539062
Batch 4/64 loss: -1.4698600769042969
Batch 5/64 loss: -1.6500978469848633
Batch 6/64 loss: -1.895608901977539
Batch 7/64 loss: -1.9007606506347656
Batch 8/64 loss: -1.7142066955566406
Batch 9/64 loss: -1.7584810256958008
Batch 10/64 loss: -1.665781021118164
Batch 11/64 loss: -1.4678268432617188
Batch 12/64 loss: -2.1046876907348633
Batch 13/64 loss: -1.828780174255371
Batch 14/64 loss: -1.0878047943115234
Batch 15/64 loss: -1.8817319869995117
Batch 16/64 loss: -1.5832977294921875
Batch 17/64 loss: -1.9882621765136719
Batch 18/64 loss: -1.6793956756591797
Batch 19/64 loss: -1.4826040267944336
Batch 20/64 loss: -1.8355932235717773
Batch 21/64 loss: -2.2199926376342773
Batch 22/64 loss: -1.9601430892944336
Batch 23/64 loss: -1.8122186660766602
Batch 24/64 loss: -2.0541419982910156
Batch 25/64 loss: -1.6218442916870117
Batch 26/64 loss: -1.740036964416504
Batch 27/64 loss: -1.9216032028198242
Batch 28/64 loss: -1.4576473236083984
Batch 29/64 loss: -1.554774284362793
Batch 30/64 loss: -1.7955989837646484
Batch 31/64 loss: -1.88714599609375
Batch 32/64 loss: -1.858755111694336
Batch 33/64 loss: -1.8094558715820312
Batch 34/64 loss: -1.4008255004882812
Batch 35/64 loss: -1.891678810119629
Batch 36/64 loss: -1.2998342514038086
Batch 37/64 loss: -1.973398208618164
Batch 38/64 loss: -1.7583465576171875
Batch 39/64 loss: -1.9659862518310547
Batch 40/64 loss: -1.4943609237670898
Batch 41/64 loss: -1.6178092956542969
Batch 42/64 loss: -1.9325675964355469
Batch 43/64 loss: -1.3764057159423828
Batch 44/64 loss: -1.7896919250488281
Batch 45/64 loss: -2.075167655944824
Batch 46/64 loss: -1.458907127380371
Batch 47/64 loss: -1.9204444885253906
Batch 48/64 loss: -1.6845207214355469
Batch 49/64 loss: -1.541738510131836
Batch 50/64 loss: -1.9396581649780273
Batch 51/64 loss: -1.5034160614013672
Batch 52/64 loss: -1.7657127380371094
Batch 53/64 loss: -1.6948719024658203
Batch 54/64 loss: -1.8398571014404297
Batch 55/64 loss: -2.0305356979370117
Batch 56/64 loss: -1.3753108978271484
Batch 57/64 loss: -1.7973899841308594
Batch 58/64 loss: -1.599008560180664
Batch 59/64 loss: -1.1781320571899414
Batch 60/64 loss: -1.7585220336914062
Batch 61/64 loss: -1.8701400756835938
Batch 62/64 loss: -1.7151498794555664
Batch 63/64 loss: -1.6698188781738281
Batch 64/64 loss: -6.21877908706665
Epoch 79  Train loss: -1.7727236411150764  Val loss: -2.001935139554473
Saving best model, epoch: 79
Epoch 80
-------------------------------
Batch 1/64 loss: -1.5119314193725586
Batch 2/64 loss: -1.8487272262573242
Batch 3/64 loss: -1.664937973022461
Batch 4/64 loss: -1.7688817977905273
Batch 5/64 loss: -1.6664323806762695
Batch 6/64 loss: -1.5669498443603516
Batch 7/64 loss: -1.728602409362793
Batch 8/64 loss: -2.00058650970459
Batch 9/64 loss: -1.8755359649658203
Batch 10/64 loss: -1.9127893447875977
Batch 11/64 loss: -1.6861534118652344
Batch 12/64 loss: -1.4932355880737305
Batch 13/64 loss: -1.9304685592651367
Batch 14/64 loss: -1.754547119140625
Batch 15/64 loss: -1.8180885314941406
Batch 16/64 loss: -1.6157350540161133
Batch 17/64 loss: -1.9144468307495117
Batch 18/64 loss: -1.7056636810302734
Batch 19/64 loss: -1.4572772979736328
Batch 20/64 loss: -1.6423730850219727
Batch 21/64 loss: -1.8857851028442383
Batch 22/64 loss: -1.2587194442749023
Batch 23/64 loss: -1.874547004699707
Batch 24/64 loss: -1.7282075881958008
Batch 25/64 loss: -1.769658088684082
Batch 26/64 loss: -1.707406997680664
Batch 27/64 loss: -1.7556266784667969
Batch 28/64 loss: -1.953261375427246
Batch 29/64 loss: -1.861741065979004
Batch 30/64 loss: -1.7065982818603516
Batch 31/64 loss: -1.6970291137695312
Batch 32/64 loss: -1.9893598556518555
Batch 33/64 loss: -1.8575372695922852
Batch 34/64 loss: -1.6644573211669922
Batch 35/64 loss: -1.6851043701171875
Batch 36/64 loss: -1.6180238723754883
Batch 37/64 loss: -1.9593801498413086
Batch 38/64 loss: -1.7914161682128906
Batch 39/64 loss: -1.9794883728027344
Batch 40/64 loss: -1.9239931106567383
Batch 41/64 loss: -1.6500873565673828
Batch 42/64 loss: -1.7577190399169922
Batch 43/64 loss: -1.687967300415039
Batch 44/64 loss: -1.8723020553588867
Batch 45/64 loss: -1.8897771835327148
Batch 46/64 loss: -1.9788169860839844
Batch 47/64 loss: -1.849111557006836
Batch 48/64 loss: -1.8344383239746094
Batch 49/64 loss: -1.9399089813232422
Batch 50/64 loss: -1.8874568939208984
Batch 51/64 loss: -1.8323545455932617
Batch 52/64 loss: -1.7562456130981445
Batch 53/64 loss: -1.548842430114746
Batch 54/64 loss: -1.9326295852661133
Batch 55/64 loss: -1.6238689422607422
Batch 56/64 loss: -1.5351085662841797
Batch 57/64 loss: -1.7662811279296875
Batch 58/64 loss: -1.8943862915039062
Batch 59/64 loss: -1.7747917175292969
Batch 60/64 loss: -1.7987051010131836
Batch 61/64 loss: -1.6086540222167969
Batch 62/64 loss: -1.6382007598876953
Batch 63/64 loss: -1.5019359588623047
Batch 64/64 loss: -6.430265426635742
Epoch 80  Train loss: -1.8135371713077322  Val loss: -2.0008746012789276
Epoch 81
-------------------------------
Batch 1/64 loss: -1.5319976806640625
Batch 2/64 loss: -1.859145164489746
Batch 3/64 loss: -1.6793718338012695
Batch 4/64 loss: -1.5051240921020508
Batch 5/64 loss: -1.792612075805664
Batch 6/64 loss: -1.9800033569335938
Batch 7/64 loss: -1.9893302917480469
Batch 8/64 loss: -1.7449274063110352
Batch 9/64 loss: -1.5647954940795898
Batch 10/64 loss: -1.7096233367919922
Batch 11/64 loss: -1.6977815628051758
Batch 12/64 loss: -1.9323196411132812
Batch 13/64 loss: -2.122988700866699
Batch 14/64 loss: -2.07448673248291
Batch 15/64 loss: -1.6827325820922852
Batch 16/64 loss: -1.557474136352539
Batch 17/64 loss: -1.5155391693115234
Batch 18/64 loss: -1.6600933074951172
Batch 19/64 loss: -1.7874298095703125
Batch 20/64 loss: -1.750518798828125
Batch 21/64 loss: -1.9301567077636719
Batch 22/64 loss: -1.7911710739135742
Batch 23/64 loss: -1.806534767150879
Batch 24/64 loss: -1.8624591827392578
Batch 25/64 loss: -1.5467491149902344
Batch 26/64 loss: -1.6194639205932617
Batch 27/64 loss: -1.6962451934814453
Batch 28/64 loss: -1.849289894104004
Batch 29/64 loss: -1.3300504684448242
Batch 30/64 loss: -1.5865240097045898
Batch 31/64 loss: -2.036290168762207
Batch 32/64 loss: -1.8318166732788086
Batch 33/64 loss: -1.5742435455322266
Batch 34/64 loss: -1.3163070678710938
Batch 35/64 loss: -1.8538389205932617
Batch 36/64 loss: -2.0686168670654297
Batch 37/64 loss: -1.857008934020996
Batch 38/64 loss: -1.818613052368164
Batch 39/64 loss: -1.694626808166504
Batch 40/64 loss: -1.930776596069336
Batch 41/64 loss: -1.9578542709350586
Batch 42/64 loss: -1.749664306640625
Batch 43/64 loss: -1.7649555206298828
Batch 44/64 loss: -1.8489446640014648
Batch 45/64 loss: -1.8061485290527344
Batch 46/64 loss: -1.975137710571289
Batch 47/64 loss: -1.9405078887939453
Batch 48/64 loss: -1.4558343887329102
Batch 49/64 loss: -1.568018913269043
Batch 50/64 loss: -2.140918731689453
Batch 51/64 loss: -1.9207983016967773
Batch 52/64 loss: -1.6798677444458008
Batch 53/64 loss: -2.1865291595458984
Batch 54/64 loss: -1.9439544677734375
Batch 55/64 loss: -2.13568115234375
Batch 56/64 loss: -1.6113367080688477
Batch 57/64 loss: -1.6964759826660156
Batch 58/64 loss: -1.7166204452514648
Batch 59/64 loss: -1.0939970016479492
Batch 60/64 loss: -1.7545642852783203
Batch 61/64 loss: -1.7354822158813477
Batch 62/64 loss: -1.6716594696044922
Batch 63/64 loss: -1.8940715789794922
Batch 64/64 loss: -6.445972442626953
Epoch 81  Train loss: -1.823099308387906  Val loss: -1.8953568894428896
Epoch 82
-------------------------------
Batch 1/64 loss: -1.456003189086914
Batch 2/64 loss: -1.5417957305908203
Batch 3/64 loss: -1.5082855224609375
Batch 4/64 loss: -1.5596723556518555
Batch 5/64 loss: -1.6499834060668945
Batch 6/64 loss: -1.643951416015625
Batch 7/64 loss: -1.5255956649780273
Batch 8/64 loss: -1.8255138397216797
Batch 9/64 loss: -1.5980262756347656
Batch 10/64 loss: -1.947500228881836
Batch 11/64 loss: -1.7049694061279297
Batch 12/64 loss: -1.8644609451293945
Batch 13/64 loss: -1.8379125595092773
Batch 14/64 loss: -2.006753921508789
Batch 15/64 loss: -1.8116998672485352
Batch 16/64 loss: -1.3779983520507812
Batch 17/64 loss: -1.832840919494629
Batch 18/64 loss: -1.8504457473754883
Batch 19/64 loss: -1.7317438125610352
Batch 20/64 loss: -1.3449792861938477
Batch 21/64 loss: -1.6633338928222656
Batch 22/64 loss: -2.094052314758301
Batch 23/64 loss: -1.6834239959716797
Batch 24/64 loss: -1.851973533630371
Batch 25/64 loss: -2.0485572814941406
Batch 26/64 loss: -1.628488540649414
Batch 27/64 loss: -1.7006092071533203
Batch 28/64 loss: -1.4575681686401367
Batch 29/64 loss: -1.9431266784667969
Batch 30/64 loss: -1.6571874618530273
Batch 31/64 loss: -1.616368293762207
Batch 32/64 loss: -1.8369417190551758
Batch 33/64 loss: -1.660832405090332
Batch 34/64 loss: -1.6649293899536133
Batch 35/64 loss: -1.6849899291992188
Batch 36/64 loss: -1.6928825378417969
Batch 37/64 loss: -1.574631690979004
Batch 38/64 loss: -1.5660247802734375
Batch 39/64 loss: -2.013230323791504
Batch 40/64 loss: -1.758077621459961
Batch 41/64 loss: -1.7380800247192383
Batch 42/64 loss: -1.5158185958862305
Batch 43/64 loss: -1.6342382431030273
Batch 44/64 loss: -2.119915008544922
Batch 45/64 loss: -1.6923799514770508
Batch 46/64 loss: -1.8907155990600586
Batch 47/64 loss: -1.349543571472168
Batch 48/64 loss: -1.3341197967529297
Batch 49/64 loss: -2.0078601837158203
Batch 50/64 loss: -1.3409433364868164
Batch 51/64 loss: -1.592808723449707
Batch 52/64 loss: -1.8758201599121094
Batch 53/64 loss: -2.18035888671875
Batch 54/64 loss: -1.68267822265625
Batch 55/64 loss: -1.6040372848510742
Batch 56/64 loss: -1.9569292068481445
Batch 57/64 loss: -1.83526611328125
Batch 58/64 loss: -1.8177680969238281
Batch 59/64 loss: -1.740952491760254
Batch 60/64 loss: -1.6465415954589844
Batch 61/64 loss: -1.9671058654785156
Batch 62/64 loss: -1.937180519104004
Batch 63/64 loss: -1.8703393936157227
Batch 64/64 loss: -5.930365562438965
Epoch 82  Train loss: -1.7756319569606407  Val loss: -1.8909822706504376
Epoch 83
-------------------------------
Batch 1/64 loss: -1.6940183639526367
Batch 2/64 loss: -1.7071619033813477
Batch 3/64 loss: -1.6792526245117188
Batch 4/64 loss: -1.6318025588989258
Batch 5/64 loss: -2.0166311264038086
Batch 6/64 loss: -2.0745391845703125
Batch 7/64 loss: -2.05413818359375
Batch 8/64 loss: -1.6951189041137695
Batch 9/64 loss: -1.5167922973632812
Batch 10/64 loss: -1.5193977355957031
Batch 11/64 loss: -1.6693429946899414
Batch 12/64 loss: -1.742701530456543
Batch 13/64 loss: -1.8247613906860352
Batch 14/64 loss: -1.53387451171875
Batch 15/64 loss: -1.8143386840820312
Batch 16/64 loss: -1.7910995483398438
Batch 17/64 loss: -1.6285696029663086
Batch 18/64 loss: -1.6193552017211914
Batch 19/64 loss: -1.8884239196777344
Batch 20/64 loss: -1.842900276184082
Batch 21/64 loss: -1.5585594177246094
Batch 22/64 loss: -1.9103803634643555
Batch 23/64 loss: -1.866206169128418
Batch 24/64 loss: -1.513197898864746
Batch 25/64 loss: -1.6758594512939453
Batch 26/64 loss: -1.817037582397461
Batch 27/64 loss: -1.4371776580810547
Batch 28/64 loss: -1.3820886611938477
Batch 29/64 loss: -1.6906194686889648
Batch 30/64 loss: -1.620443344116211
Batch 31/64 loss: -1.6292686462402344
Batch 32/64 loss: -1.883544921875
Batch 33/64 loss: -1.9048881530761719
Batch 34/64 loss: -1.841139793395996
Batch 35/64 loss: -1.6316728591918945
Batch 36/64 loss: -1.0897026062011719
Batch 37/64 loss: -1.4748754501342773
Batch 38/64 loss: -1.5496702194213867
Batch 39/64 loss: -1.9102554321289062
Batch 40/64 loss: -2.030263900756836
Batch 41/64 loss: -1.6227169036865234
Batch 42/64 loss: -1.775965690612793
Batch 43/64 loss: -1.9671030044555664
Batch 44/64 loss: -1.5332393646240234
Batch 45/64 loss: -1.7385931015014648
Batch 46/64 loss: -1.617558479309082
Batch 47/64 loss: -1.6929903030395508
Batch 48/64 loss: -1.9049043655395508
Batch 49/64 loss: -1.8108186721801758
Batch 50/64 loss: -1.5443620681762695
Batch 51/64 loss: -1.8027410507202148
Batch 52/64 loss: -1.8188934326171875
Batch 53/64 loss: -1.925745964050293
Batch 54/64 loss: -1.6980724334716797
Batch 55/64 loss: -1.6975936889648438
Batch 56/64 loss: -1.9778223037719727
Batch 57/64 loss: -1.405843734741211
Batch 58/64 loss: -1.6810064315795898
Batch 59/64 loss: -1.824753761291504
Batch 60/64 loss: -1.6091508865356445
Batch 61/64 loss: -1.4874277114868164
Batch 62/64 loss: -2.1835784912109375
Batch 63/64 loss: -1.2277860641479492
Batch 64/64 loss: -6.209494113922119
Epoch 83  Train loss: -1.7657546828774844  Val loss: -1.8742458042000578
Epoch 84
-------------------------------
Batch 1/64 loss: -1.5069646835327148
Batch 2/64 loss: -1.859114646911621
Batch 3/64 loss: -1.6409807205200195
Batch 4/64 loss: -1.939962387084961
Batch 5/64 loss: -1.7619390487670898
Batch 6/64 loss: -2.0117950439453125
Batch 7/64 loss: -0.993260383605957
Batch 8/64 loss: -1.473618507385254
Batch 9/64 loss: -1.6594352722167969
Batch 10/64 loss: -1.9078960418701172
Batch 11/64 loss: -1.7845706939697266
Batch 12/64 loss: -1.740818977355957
Batch 13/64 loss: -1.9148674011230469
Batch 14/64 loss: -1.7083206176757812
Batch 15/64 loss: -1.8708925247192383
Batch 16/64 loss: -1.2669668197631836
Batch 17/64 loss: -1.4148225784301758
Batch 18/64 loss: -1.5859308242797852
Batch 19/64 loss: -1.640263557434082
Batch 20/64 loss: -2.1474246978759766
Batch 21/64 loss: -2.0279102325439453
Batch 22/64 loss: -2.085111618041992
Batch 23/64 loss: -1.465907096862793
Batch 24/64 loss: -1.8502168655395508
Batch 25/64 loss: -1.8624210357666016
Batch 26/64 loss: -1.5559749603271484
Batch 27/64 loss: -1.978806495666504
Batch 28/64 loss: -1.6666641235351562
Batch 29/64 loss: -1.7134742736816406
Batch 30/64 loss: -2.063812255859375
Batch 31/64 loss: -1.8760042190551758
Batch 32/64 loss: -1.3914079666137695
Batch 33/64 loss: -1.352961540222168
Batch 34/64 loss: -1.8101081848144531
Batch 35/64 loss: -1.6856012344360352
Batch 36/64 loss: -1.7684745788574219
Batch 37/64 loss: -1.8527898788452148
Batch 38/64 loss: -1.7380199432373047
Batch 39/64 loss: -1.7588653564453125
Batch 40/64 loss: -2.0301132202148438
Batch 41/64 loss: -1.9523544311523438
Batch 42/64 loss: -1.4024677276611328
Batch 43/64 loss: -1.7540712356567383
Batch 44/64 loss: -1.8803539276123047
Batch 45/64 loss: -1.752481460571289
Batch 46/64 loss: -1.625558853149414
Batch 47/64 loss: -1.776871681213379
Batch 48/64 loss: -1.224125862121582
Batch 49/64 loss: -1.7427129745483398
Batch 50/64 loss: -1.8822851181030273
Batch 51/64 loss: -1.7865877151489258
Batch 52/64 loss: -1.9808597564697266
Batch 53/64 loss: -1.760213851928711
Batch 54/64 loss: -2.0689802169799805
Batch 55/64 loss: -2.0998640060424805
Batch 56/64 loss: -2.087283134460449
Batch 57/64 loss: -1.6926240921020508
Batch 58/64 loss: -1.7111530303955078
Batch 59/64 loss: -1.9073667526245117
Batch 60/64 loss: -1.8784980773925781
Batch 61/64 loss: -1.8289365768432617
Batch 62/64 loss: -1.2370805740356445
Batch 63/64 loss: -1.708944320678711
Batch 64/64 loss: -6.175998687744141
Epoch 84  Train loss: -1.7998143513997396  Val loss: -2.0196257653514955
Saving best model, epoch: 84
Epoch 85
-------------------------------
Batch 1/64 loss: -1.9471607208251953
Batch 2/64 loss: -1.5856170654296875
Batch 3/64 loss: -1.9027366638183594
Batch 4/64 loss: -1.8803844451904297
Batch 5/64 loss: -2.0323801040649414
Batch 6/64 loss: -1.7229557037353516
Batch 7/64 loss: -1.759958267211914
Batch 8/64 loss: -1.4801197052001953
Batch 9/64 loss: -1.954925537109375
Batch 10/64 loss: -2.112934112548828
Batch 11/64 loss: -2.0486955642700195
Batch 12/64 loss: -1.9715805053710938
Batch 13/64 loss: -1.8014516830444336
Batch 14/64 loss: -1.8949928283691406
Batch 15/64 loss: -2.040280342102051
Batch 16/64 loss: -1.7587003707885742
Batch 17/64 loss: -1.597764015197754
Batch 18/64 loss: -1.6732206344604492
Batch 19/64 loss: -1.8976964950561523
Batch 20/64 loss: -1.6410865783691406
Batch 21/64 loss: -1.8817329406738281
Batch 22/64 loss: -1.2649574279785156
Batch 23/64 loss: -1.9460783004760742
Batch 24/64 loss: -1.6919450759887695
Batch 25/64 loss: -1.4652118682861328
Batch 26/64 loss: -1.7866134643554688
Batch 27/64 loss: -1.7249069213867188
Batch 28/64 loss: -1.6801786422729492
Batch 29/64 loss: -1.9312372207641602
Batch 30/64 loss: -1.1436853408813477
Batch 31/64 loss: -1.7446174621582031
Batch 32/64 loss: -1.5107574462890625
Batch 33/64 loss: -1.2821054458618164
Batch 34/64 loss: -1.1711091995239258
Batch 35/64 loss: -1.5582599639892578
Batch 36/64 loss: -1.7228336334228516
Batch 37/64 loss: -1.7094497680664062
Batch 38/64 loss: -1.7122039794921875
Batch 39/64 loss: -1.8733110427856445
Batch 40/64 loss: -2.049032211303711
Batch 41/64 loss: -1.8877239227294922
Batch 42/64 loss: -1.9902839660644531
Batch 43/64 loss: -2.062673568725586
Batch 44/64 loss: -1.9756641387939453
Batch 45/64 loss: -1.8267126083374023
Batch 46/64 loss: -1.6057634353637695
Batch 47/64 loss: -1.8843231201171875
Batch 48/64 loss: -1.8422164916992188
Batch 49/64 loss: -2.002378463745117
Batch 50/64 loss: -1.2770729064941406
Batch 51/64 loss: -1.7492284774780273
Batch 52/64 loss: -1.9820976257324219
Batch 53/64 loss: -1.1473426818847656
Batch 54/64 loss: -1.1561861038208008
Batch 55/64 loss: -1.771224021911621
Batch 56/64 loss: -2.0347509384155273
Batch 57/64 loss: -1.7502813339233398
Batch 58/64 loss: -1.7872724533081055
Batch 59/64 loss: -1.7984533309936523
Batch 60/64 loss: -1.8168106079101562
Batch 61/64 loss: -1.943985939025879
Batch 62/64 loss: -1.802042007446289
Batch 63/64 loss: -1.6273431777954102
Batch 64/64 loss: -5.88544225692749
Epoch 85  Train loss: -1.799071085686777  Val loss: -1.9181828187503356
Epoch 86
-------------------------------
Batch 1/64 loss: -1.8812456130981445
Batch 2/64 loss: -1.8620481491088867
Batch 3/64 loss: -2.061070442199707
Batch 4/64 loss: -1.7187891006469727
Batch 5/64 loss: -1.4088563919067383
Batch 6/64 loss: -1.8280506134033203
Batch 7/64 loss: -1.606673240661621
Batch 8/64 loss: -1.5478544235229492
Batch 9/64 loss: -1.7590618133544922
Batch 10/64 loss: -1.377882957458496
Batch 11/64 loss: -1.8474655151367188
Batch 12/64 loss: -1.560490608215332
Batch 13/64 loss: -1.9031152725219727
Batch 14/64 loss: -1.8291864395141602
Batch 15/64 loss: -1.514373779296875
Batch 16/64 loss: -1.4864015579223633
Batch 17/64 loss: -1.865992546081543
Batch 18/64 loss: -1.9925146102905273
Batch 19/64 loss: -1.6739425659179688
Batch 20/64 loss: -1.9478683471679688
Batch 21/64 loss: -1.8411989212036133
Batch 22/64 loss: -1.8873672485351562
Batch 23/64 loss: -1.792520523071289
Batch 24/64 loss: -2.1384429931640625
Batch 25/64 loss: -2.0655946731567383
Batch 26/64 loss: -1.8897991180419922
Batch 27/64 loss: -1.8748598098754883
Batch 28/64 loss: -1.8709478378295898
Batch 29/64 loss: -1.8961210250854492
Batch 30/64 loss: -1.938638687133789
Batch 31/64 loss: -2.043020248413086
Batch 32/64 loss: -1.5545587539672852
Batch 33/64 loss: -1.7869834899902344
Batch 34/64 loss: -1.7470474243164062
Batch 35/64 loss: -1.8624372482299805
Batch 36/64 loss: -1.5685920715332031
Batch 37/64 loss: -1.7732257843017578
Batch 38/64 loss: -1.8274497985839844
Batch 39/64 loss: -1.6447935104370117
Batch 40/64 loss: -1.7469244003295898
Batch 41/64 loss: -1.837118148803711
Batch 42/64 loss: -1.777634620666504
Batch 43/64 loss: -2.160458564758301
Batch 44/64 loss: -1.3423290252685547
Batch 45/64 loss: -1.3785266876220703
Batch 46/64 loss: -1.2390527725219727
Batch 47/64 loss: -2.0847339630126953
Batch 48/64 loss: -2.0717668533325195
Batch 49/64 loss: -1.582906723022461
Batch 50/64 loss: -1.7820682525634766
Batch 51/64 loss: -1.7230243682861328
Batch 52/64 loss: -2.189215660095215
Batch 53/64 loss: -1.953089714050293
Batch 54/64 loss: -2.0982189178466797
Batch 55/64 loss: -1.6572999954223633
Batch 56/64 loss: -2.1489105224609375
Batch 57/64 loss: -1.726898193359375
Batch 58/64 loss: -1.9011125564575195
Batch 59/64 loss: -1.940627098083496
Batch 60/64 loss: -1.776315689086914
Batch 61/64 loss: -1.968531608581543
Batch 62/64 loss: -1.7688732147216797
Batch 63/64 loss: -1.4021625518798828
Batch 64/64 loss: -5.881063461303711
Epoch 86  Train loss: -1.840707150627585  Val loss: -1.9124512426631968
Epoch 87
-------------------------------
Batch 1/64 loss: -1.994436264038086
Batch 2/64 loss: -1.717402458190918
Batch 3/64 loss: -1.9735536575317383
Batch 4/64 loss: -2.158379554748535
Batch 5/64 loss: -1.8360986709594727
Batch 6/64 loss: -1.8121185302734375
Batch 7/64 loss: -1.3643121719360352
Batch 8/64 loss: -1.8844146728515625
Batch 9/64 loss: -1.7548818588256836
Batch 10/64 loss: -1.0357084274291992
Batch 11/64 loss: -1.911956787109375
Batch 12/64 loss: -2.0013580322265625
Batch 13/64 loss: -1.6110658645629883
Batch 14/64 loss: -1.8892126083374023
Batch 15/64 loss: -1.4249181747436523
Batch 16/64 loss: -1.9633445739746094
Batch 17/64 loss: -2.038498878479004
Batch 18/64 loss: -1.7848873138427734
Batch 19/64 loss: -1.6558074951171875
Batch 20/64 loss: -1.396036148071289
Batch 21/64 loss: -1.9281740188598633
Batch 22/64 loss: -1.8534812927246094
Batch 23/64 loss: -1.7737712860107422
Batch 24/64 loss: -1.7294960021972656
Batch 25/64 loss: -2.068943977355957
Batch 26/64 loss: -1.8785486221313477
Batch 27/64 loss: -1.576807975769043
Batch 28/64 loss: -1.9476089477539062
Batch 29/64 loss: -1.4864826202392578
Batch 30/64 loss: -1.9596529006958008
Batch 31/64 loss: -1.88623046875
Batch 32/64 loss: -2.0174856185913086
Batch 33/64 loss: -1.905074119567871
Batch 34/64 loss: -2.0855464935302734
Batch 35/64 loss: -1.919412612915039
Batch 36/64 loss: -1.7014789581298828
Batch 37/64 loss: -2.0489015579223633
Batch 38/64 loss: -1.5525903701782227
Batch 39/64 loss: -1.5451202392578125
Batch 40/64 loss: -1.4334239959716797
Batch 41/64 loss: -1.7070684432983398
Batch 42/64 loss: -1.9153194427490234
Batch 43/64 loss: -1.7756385803222656
Batch 44/64 loss: -1.73907470703125
Batch 45/64 loss: -1.9000415802001953
Batch 46/64 loss: -1.636561393737793
Batch 47/64 loss: -1.9884023666381836
Batch 48/64 loss: -2.0195980072021484
Batch 49/64 loss: -1.8123388290405273
Batch 50/64 loss: -1.7468833923339844
Batch 51/64 loss: -2.0424652099609375
Batch 52/64 loss: -2.104074478149414
Batch 53/64 loss: -1.9121265411376953
Batch 54/64 loss: -1.746622085571289
Batch 55/64 loss: -1.699845314025879
Batch 56/64 loss: -1.7951107025146484
Batch 57/64 loss: -1.7337665557861328
Batch 58/64 loss: -1.9138078689575195
Batch 59/64 loss: -1.6242265701293945
Batch 60/64 loss: -1.493119239807129
Batch 61/64 loss: -2.1218032836914062
Batch 62/64 loss: -2.0620431900024414
Batch 63/64 loss: -1.7591400146484375
Batch 64/64 loss: -6.106307029724121
Epoch 87  Train loss: -1.8562420751534257  Val loss: -2.0216509107871565
Saving best model, epoch: 87
Epoch 88
-------------------------------
Batch 1/64 loss: -1.7877168655395508
Batch 2/64 loss: -1.9516706466674805
Batch 3/64 loss: -1.9778366088867188
Batch 4/64 loss: -1.684061050415039
Batch 5/64 loss: -1.9061193466186523
Batch 6/64 loss: -1.9609031677246094
Batch 7/64 loss: -1.809199333190918
Batch 8/64 loss: -1.6400175094604492
Batch 9/64 loss: -1.7231311798095703
Batch 10/64 loss: -1.4494943618774414
Batch 11/64 loss: -1.9235410690307617
Batch 12/64 loss: -1.4192867279052734
Batch 13/64 loss: -2.126209259033203
Batch 14/64 loss: -1.8418397903442383
Batch 15/64 loss: -1.9699735641479492
Batch 16/64 loss: -1.7492256164550781
Batch 17/64 loss: -1.750753402709961
Batch 18/64 loss: -1.7630615234375
Batch 19/64 loss: -1.898015022277832
Batch 20/64 loss: -1.6128816604614258
Batch 21/64 loss: -1.9257068634033203
Batch 22/64 loss: -2.218899726867676
Batch 23/64 loss: -1.5225191116333008
Batch 24/64 loss: -1.3821430206298828
Batch 25/64 loss: -1.915236473083496
Batch 26/64 loss: -1.8051490783691406
Batch 27/64 loss: -1.6905908584594727
Batch 28/64 loss: -1.9746809005737305
Batch 29/64 loss: -1.6396656036376953
Batch 30/64 loss: -1.976430892944336
Batch 31/64 loss: -1.6051759719848633
Batch 32/64 loss: -1.8541479110717773
Batch 33/64 loss: -2.100052833557129
Batch 34/64 loss: -2.215132713317871
Batch 35/64 loss: -1.935542106628418
Batch 36/64 loss: -1.4690313339233398
Batch 37/64 loss: -1.8038005828857422
Batch 38/64 loss: -1.9039669036865234
Batch 39/64 loss: -1.755845069885254
Batch 40/64 loss: -1.9062232971191406
Batch 41/64 loss: -1.8329544067382812
Batch 42/64 loss: -1.0774869918823242
Batch 43/64 loss: -2.0699071884155273
Batch 44/64 loss: -2.006410598754883
Batch 45/64 loss: -2.079479217529297
Batch 46/64 loss: -1.9269495010375977
Batch 47/64 loss: -1.9580307006835938
Batch 48/64 loss: -1.9665136337280273
Batch 49/64 loss: -1.8140764236450195
Batch 50/64 loss: -1.8203411102294922
Batch 51/64 loss: -1.8041667938232422
Batch 52/64 loss: -1.8389692306518555
Batch 53/64 loss: -2.0188465118408203
Batch 54/64 loss: -1.6614065170288086
Batch 55/64 loss: -1.8933582305908203
Batch 56/64 loss: -1.8244915008544922
Batch 57/64 loss: -1.875075340270996
Batch 58/64 loss: -1.7022390365600586
Batch 59/64 loss: -1.9066028594970703
Batch 60/64 loss: -1.5739326477050781
Batch 61/64 loss: -2.1659841537475586
Batch 62/64 loss: -1.8025531768798828
Batch 63/64 loss: -1.7015609741210938
Batch 64/64 loss: -6.512969970703125
Epoch 88  Train loss: -1.8784461675905715  Val loss: -1.7850169152328648
Epoch 89
-------------------------------
Batch 1/64 loss: -1.734227180480957
Batch 2/64 loss: -2.0024023056030273
Batch 3/64 loss: -1.949427604675293
Batch 4/64 loss: -2.133152961730957
Batch 5/64 loss: -1.3613014221191406
Batch 6/64 loss: -1.606729507446289
Batch 7/64 loss: -1.6990880966186523
Batch 8/64 loss: -2.160384178161621
Batch 9/64 loss: -1.9416322708129883
Batch 10/64 loss: -1.6437816619873047
Batch 11/64 loss: -1.7927274703979492
Batch 12/64 loss: -1.9747943878173828
Batch 13/64 loss: -2.080686569213867
Batch 14/64 loss: -1.4576492309570312
Batch 15/64 loss: -1.785287857055664
Batch 16/64 loss: -1.4938535690307617
Batch 17/64 loss: -1.3227787017822266
Batch 18/64 loss: -1.8894319534301758
Batch 19/64 loss: -1.303797721862793
Batch 20/64 loss: -2.073512077331543
Batch 21/64 loss: -1.9263811111450195
Batch 22/64 loss: -1.8551301956176758
Batch 23/64 loss: -1.8449382781982422
Batch 24/64 loss: -1.7995615005493164
Batch 25/64 loss: -1.9224023818969727
Batch 26/64 loss: -1.794769287109375
Batch 27/64 loss: -2.0231857299804688
Batch 28/64 loss: -1.497274398803711
Batch 29/64 loss: -1.597926139831543
Batch 30/64 loss: -1.8782787322998047
Batch 31/64 loss: -1.6462974548339844
Batch 32/64 loss: -1.41363525390625
Batch 33/64 loss: -1.6527786254882812
Batch 34/64 loss: -1.7809371948242188
Batch 35/64 loss: -1.8893775939941406
Batch 36/64 loss: -1.9815263748168945
Batch 37/64 loss: -1.9498720169067383
Batch 38/64 loss: -1.9827156066894531
Batch 39/64 loss: -2.0728721618652344
Batch 40/64 loss: -1.9821395874023438
Batch 41/64 loss: -1.9542427062988281
Batch 42/64 loss: -1.818058967590332
Batch 43/64 loss: -1.869673728942871
Batch 44/64 loss: -2.0933170318603516
Batch 45/64 loss: -1.9969358444213867
Batch 46/64 loss: -1.6874141693115234
Batch 47/64 loss: -1.7516441345214844
Batch 48/64 loss: -2.012584686279297
Batch 49/64 loss: -1.4306669235229492
Batch 50/64 loss: -1.8682641983032227
Batch 51/64 loss: -1.7737112045288086
Batch 52/64 loss: -1.6461563110351562
Batch 53/64 loss: -1.7192440032958984
Batch 54/64 loss: -1.521256446838379
Batch 55/64 loss: -1.9212169647216797
Batch 56/64 loss: -1.8220605850219727
Batch 57/64 loss: -1.9711551666259766
Batch 58/64 loss: -2.137345314025879
Batch 59/64 loss: -1.8960456848144531
Batch 60/64 loss: -1.8352060317993164
Batch 61/64 loss: -1.6572198867797852
Batch 62/64 loss: -1.8389902114868164
Batch 63/64 loss: -1.8203582763671875
Batch 64/64 loss: -5.940994739532471
Epoch 89  Train loss: -1.857210366866168  Val loss: -1.9651808984500845
Epoch 90
-------------------------------
Batch 1/64 loss: -1.9216547012329102
Batch 2/64 loss: -2.137476921081543
Batch 3/64 loss: -1.885603904724121
Batch 4/64 loss: -1.5981721878051758
Batch 5/64 loss: -1.984750747680664
Batch 6/64 loss: -1.9198980331420898
Batch 7/64 loss: -1.937845230102539
Batch 8/64 loss: -1.7073984146118164
Batch 9/64 loss: -1.7121086120605469
Batch 10/64 loss: -2.0116539001464844
Batch 11/64 loss: -2.0420103073120117
Batch 12/64 loss: -1.8032608032226562
Batch 13/64 loss: -1.9610471725463867
Batch 14/64 loss: -1.8582706451416016
Batch 15/64 loss: -1.949014663696289
Batch 16/64 loss: -1.8450775146484375
Batch 17/64 loss: -1.6023893356323242
Batch 18/64 loss: -1.6177520751953125
Batch 19/64 loss: -2.05710506439209
Batch 20/64 loss: -1.735433578491211
Batch 21/64 loss: -1.7814931869506836
Batch 22/64 loss: -1.881331443786621
Batch 23/64 loss: -1.7622919082641602
Batch 24/64 loss: -1.570871353149414
Batch 25/64 loss: -1.4530925750732422
Batch 26/64 loss: -1.3971290588378906
Batch 27/64 loss: -1.8304405212402344
Batch 28/64 loss: -1.9962549209594727
Batch 29/64 loss: -2.114619255065918
Batch 30/64 loss: -1.541163444519043
Batch 31/64 loss: -1.6312150955200195
Batch 32/64 loss: -1.9927129745483398
Batch 33/64 loss: -1.9782114028930664
Batch 34/64 loss: -1.7217302322387695
Batch 35/64 loss: -2.002202033996582
Batch 36/64 loss: -1.8207530975341797
Batch 37/64 loss: -1.971273422241211
Batch 38/64 loss: -1.7431097030639648
Batch 39/64 loss: -1.9437532424926758
Batch 40/64 loss: -2.0638513565063477
Batch 41/64 loss: -1.829916000366211
Batch 42/64 loss: -2.296884536743164
Batch 43/64 loss: -1.9128713607788086
Batch 44/64 loss: -1.8372650146484375
Batch 45/64 loss: -2.1250762939453125
Batch 46/64 loss: -1.9681816101074219
Batch 47/64 loss: -1.5094985961914062
Batch 48/64 loss: -1.5321836471557617
Batch 49/64 loss: -2.0620317459106445
Batch 50/64 loss: -1.8095245361328125
Batch 51/64 loss: -1.5383625030517578
Batch 52/64 loss: -1.9131488800048828
Batch 53/64 loss: -1.2411375045776367
Batch 54/64 loss: -1.902252197265625
Batch 55/64 loss: -1.865285873413086
Batch 56/64 loss: -1.917811393737793
Batch 57/64 loss: -1.9982013702392578
Batch 58/64 loss: -1.5462942123413086
Batch 59/64 loss: -1.5797157287597656
Batch 60/64 loss: -1.7604608535766602
Batch 61/64 loss: -2.0026111602783203
Batch 62/64 loss: -2.019794464111328
Batch 63/64 loss: -1.94256591796875
Batch 64/64 loss: -6.158117294311523
Epoch 90  Train loss: -1.8857268613927505  Val loss: -1.9096548598246885
Epoch 91
-------------------------------
Batch 1/64 loss: -2.062016487121582
Batch 2/64 loss: -1.737070083618164
Batch 3/64 loss: -1.6381111145019531
Batch 4/64 loss: -1.5157957077026367
Batch 5/64 loss: -2.1160478591918945
Batch 6/64 loss: -1.7622251510620117
Batch 7/64 loss: -1.8220090866088867
Batch 8/64 loss: -1.948225975036621
Batch 9/64 loss: -1.8180475234985352
Batch 10/64 loss: -1.7111072540283203
Batch 11/64 loss: -1.29754638671875
Batch 12/64 loss: -1.8646793365478516
Batch 13/64 loss: -1.7439556121826172
Batch 14/64 loss: -1.4732751846313477
Batch 15/64 loss: -1.7994890213012695
Batch 16/64 loss: -1.6819486618041992
Batch 17/64 loss: -2.006402015686035
Batch 18/64 loss: -1.606130599975586
Batch 19/64 loss: -1.5098562240600586
Batch 20/64 loss: -1.7960824966430664
Batch 21/64 loss: -1.333761215209961
Batch 22/64 loss: -1.8161420822143555
Batch 23/64 loss: -1.776942253112793
Batch 24/64 loss: -1.9090147018432617
Batch 25/64 loss: -1.8905162811279297
Batch 26/64 loss: -1.7734575271606445
Batch 27/64 loss: -1.8492937088012695
Batch 28/64 loss: -1.342733383178711
Batch 29/64 loss: -1.962911605834961
Batch 30/64 loss: -1.356003761291504
Batch 31/64 loss: -1.9550714492797852
Batch 32/64 loss: -1.7021942138671875
Batch 33/64 loss: -1.9497718811035156
Batch 34/64 loss: -2.087111473083496
Batch 35/64 loss: -1.911147117614746
Batch 36/64 loss: -1.914175033569336
Batch 37/64 loss: -1.8323583602905273
Batch 38/64 loss: -1.9238452911376953
Batch 39/64 loss: -1.9807252883911133
Batch 40/64 loss: -1.9553537368774414
Batch 41/64 loss: -1.8041410446166992
Batch 42/64 loss: -2.047527313232422
Batch 43/64 loss: -1.8109931945800781
Batch 44/64 loss: -2.131157875061035
Batch 45/64 loss: -1.356764793395996
Batch 46/64 loss: -1.7455739974975586
Batch 47/64 loss: -1.889845848083496
Batch 48/64 loss: -2.0695724487304688
Batch 49/64 loss: -1.812394142150879
Batch 50/64 loss: -1.5856866836547852
Batch 51/64 loss: -2.0919666290283203
Batch 52/64 loss: -1.9615354537963867
Batch 53/64 loss: -2.095094680786133
Batch 54/64 loss: -1.9498777389526367
Batch 55/64 loss: -1.922292709350586
Batch 56/64 loss: -2.114396095275879
Batch 57/64 loss: -1.9830255508422852
Batch 58/64 loss: -1.3656187057495117
Batch 59/64 loss: -2.1268577575683594
Batch 60/64 loss: -1.6827058792114258
Batch 61/64 loss: -2.0456056594848633
Batch 62/64 loss: -2.0600509643554688
Batch 63/64 loss: -1.964818000793457
Batch 64/64 loss: -6.077002048492432
Epoch 91  Train loss: -1.8714950094036027  Val loss: -1.9722348898137148
Epoch 92
-------------------------------
Batch 1/64 loss: -1.7825899124145508
Batch 2/64 loss: -1.991969108581543
Batch 3/64 loss: -1.6792221069335938
Batch 4/64 loss: -1.906815528869629
Batch 5/64 loss: -1.7198448181152344
Batch 6/64 loss: -2.0922813415527344
Batch 7/64 loss: -1.7394695281982422
Batch 8/64 loss: -1.896876335144043
Batch 9/64 loss: -1.969193458557129
Batch 10/64 loss: -1.8664331436157227
Batch 11/64 loss: -1.8274364471435547
Batch 12/64 loss: -2.0083751678466797
Batch 13/64 loss: -1.952657699584961
Batch 14/64 loss: -1.9073314666748047
Batch 15/64 loss: -2.1126604080200195
Batch 16/64 loss: -2.0271987915039062
Batch 17/64 loss: -1.8676338195800781
Batch 18/64 loss: -2.102266311645508
Batch 19/64 loss: -1.9607973098754883
Batch 20/64 loss: -2.022761344909668
Batch 21/64 loss: -2.0248241424560547
Batch 22/64 loss: -2.020109176635742
Batch 23/64 loss: -2.0360612869262695
Batch 24/64 loss: -2.2485170364379883
Batch 25/64 loss: -2.090177536010742
Batch 26/64 loss: -2.006291389465332
Batch 27/64 loss: -1.938084602355957
Batch 28/64 loss: -2.1111831665039062
Batch 29/64 loss: -2.064624786376953
Batch 30/64 loss: -1.9746818542480469
Batch 31/64 loss: -1.8987560272216797
Batch 32/64 loss: -1.3600234985351562
Batch 33/64 loss: -2.0401744842529297
Batch 34/64 loss: -1.959242820739746
Batch 35/64 loss: -1.8006458282470703
Batch 36/64 loss: -2.04941463470459
Batch 37/64 loss: -1.8703479766845703
Batch 38/64 loss: -2.1464242935180664
Batch 39/64 loss: -2.056565284729004
Batch 40/64 loss: -1.841329574584961
Batch 41/64 loss: -2.031341552734375
Batch 42/64 loss: -2.152461051940918
Batch 43/64 loss: -1.4775762557983398
Batch 44/64 loss: -1.8675212860107422
Batch 45/64 loss: -1.452591896057129
Batch 46/64 loss: -2.1020431518554688
Batch 47/64 loss: -1.5946903228759766
Batch 48/64 loss: -1.8260383605957031
Batch 49/64 loss: -2.0210485458374023
Batch 50/64 loss: -1.7278804779052734
Batch 51/64 loss: -1.7123479843139648
Batch 52/64 loss: -2.051166534423828
Batch 53/64 loss: -1.6056461334228516
Batch 54/64 loss: -1.679673194885254
Batch 55/64 loss: -1.1208457946777344
Batch 56/64 loss: -1.859086036682129
Batch 57/64 loss: -1.8366832733154297
Batch 58/64 loss: -1.780527114868164
Batch 59/64 loss: -1.9956598281860352
Batch 60/64 loss: -1.762441635131836
Batch 61/64 loss: -1.9350910186767578
Batch 62/64 loss: -1.7824459075927734
Batch 63/64 loss: -1.9515790939331055
Batch 64/64 loss: -6.395054817199707
Epoch 92  Train loss: -1.946572094337613  Val loss: -2.0387229919433594
Saving best model, epoch: 92
Epoch 93
-------------------------------
Batch 1/64 loss: -1.5698738098144531
Batch 2/64 loss: -2.03851318359375
Batch 3/64 loss: -1.8811044692993164
Batch 4/64 loss: -1.0161104202270508
Batch 5/64 loss: -1.8281793594360352
Batch 6/64 loss: -1.875234603881836
Batch 7/64 loss: -1.8619232177734375
Batch 8/64 loss: -1.3003406524658203
Batch 9/64 loss: -1.8761100769042969
Batch 10/64 loss: -1.8349237442016602
Batch 11/64 loss: -1.729903221130371
Batch 12/64 loss: -1.9922285079956055
Batch 13/64 loss: -1.7839374542236328
Batch 14/64 loss: -1.6855297088623047
Batch 15/64 loss: -1.6222476959228516
Batch 16/64 loss: -1.6633358001708984
Batch 17/64 loss: -1.9065284729003906
Batch 18/64 loss: -1.9412813186645508
Batch 19/64 loss: -1.662693977355957
Batch 20/64 loss: -1.5499992370605469
Batch 21/64 loss: -1.7246570587158203
Batch 22/64 loss: -0.44074344635009766
Batch 23/64 loss: -1.590468406677246
Batch 24/64 loss: -1.3087358474731445
Batch 25/64 loss: -1.5516090393066406
Batch 26/64 loss: -2.011366844177246
Batch 27/64 loss: -1.9712400436401367
Batch 28/64 loss: -1.8513565063476562
Batch 29/64 loss: -1.567300796508789
Batch 30/64 loss: -1.535043716430664
Batch 31/64 loss: -1.8010568618774414
Batch 32/64 loss: -1.061990737915039
Batch 33/64 loss: -1.9261722564697266
Batch 34/64 loss: -1.8676815032958984
Batch 35/64 loss: -1.5609054565429688
Batch 36/64 loss: -1.3183650970458984
Batch 37/64 loss: -1.1499204635620117
Batch 38/64 loss: -1.3423547744750977
Batch 39/64 loss: -1.385573387145996
Batch 40/64 loss: -1.5898456573486328
Batch 41/64 loss: -1.3413000106811523
Batch 42/64 loss: -1.2433805465698242
Batch 43/64 loss: -1.467005729675293
Batch 44/64 loss: -1.761652946472168
Batch 45/64 loss: -1.15728759765625
Batch 46/64 loss: -1.4597043991088867
Batch 47/64 loss: -1.7756404876708984
Batch 48/64 loss: -1.8861274719238281
Batch 49/64 loss: -1.7362213134765625
Batch 50/64 loss: -1.8137702941894531
Batch 51/64 loss: -1.7041759490966797
Batch 52/64 loss: -1.4093551635742188
Batch 53/64 loss: -1.8198823928833008
Batch 54/64 loss: -1.6159372329711914
Batch 55/64 loss: -1.3911352157592773
Batch 56/64 loss: -1.510685920715332
Batch 57/64 loss: -1.9242849349975586
Batch 58/64 loss: -1.7816390991210938
Batch 59/64 loss: -1.7027616500854492
Batch 60/64 loss: -1.8216533660888672
Batch 61/64 loss: -1.5669851303100586
Batch 62/64 loss: -1.5330848693847656
Batch 63/64 loss: -1.0474300384521484
Batch 64/64 loss: -5.9571990966796875
Epoch 93  Train loss: -1.6645551045735678  Val loss: -1.4265918010698562
Epoch 94
-------------------------------
Batch 1/64 loss: -1.6626806259155273
Batch 2/64 loss: -1.0332889556884766
Batch 3/64 loss: -1.6413564682006836
Batch 4/64 loss: -1.7578535079956055
Batch 5/64 loss: -1.516749382019043
Batch 6/64 loss: -1.6872825622558594
Batch 7/64 loss: -1.690230369567871
Batch 8/64 loss: -1.360687255859375
Batch 9/64 loss: -1.6822338104248047
Batch 10/64 loss: -1.7632017135620117
Batch 11/64 loss: -1.1045951843261719
Batch 12/64 loss: -1.5715713500976562
Batch 13/64 loss: -1.5435924530029297
Batch 14/64 loss: -1.485422134399414
Batch 15/64 loss: -1.7980337142944336
Batch 16/64 loss: -1.954066276550293
Batch 17/64 loss: -2.07296085357666
Batch 18/64 loss: -1.9438714981079102
Batch 19/64 loss: -1.7947921752929688
Batch 20/64 loss: -2.119091033935547
Batch 21/64 loss: -2.0471086502075195
Batch 22/64 loss: -1.9830150604248047
Batch 23/64 loss: -2.0288209915161133
Batch 24/64 loss: -1.8054590225219727
Batch 25/64 loss: -1.5651960372924805
Batch 26/64 loss: -1.903559684753418
Batch 27/64 loss: -1.8744049072265625
Batch 28/64 loss: -1.8830060958862305
Batch 29/64 loss: -1.7919445037841797
Batch 30/64 loss: -1.7944440841674805
Batch 31/64 loss: -1.6634244918823242
Batch 32/64 loss: -1.7817487716674805
Batch 33/64 loss: -1.7430763244628906
Batch 34/64 loss: -1.991973876953125
Batch 35/64 loss: -1.9026565551757812
Batch 36/64 loss: -1.7415056228637695
Batch 37/64 loss: -1.6687812805175781
Batch 38/64 loss: -1.5207319259643555
Batch 39/64 loss: -1.710738182067871
Batch 40/64 loss: -1.5081634521484375
Batch 41/64 loss: -1.7872333526611328
Batch 42/64 loss: -1.845555305480957
Batch 43/64 loss: -1.8370676040649414
Batch 44/64 loss: -1.7414989471435547
Batch 45/64 loss: -1.9547834396362305
Batch 46/64 loss: -1.4952259063720703
Batch 47/64 loss: -1.7706241607666016
Batch 48/64 loss: -2.168607711791992
Batch 49/64 loss: -1.496241569519043
Batch 50/64 loss: -2.0295944213867188
Batch 51/64 loss: -1.9848623275756836
Batch 52/64 loss: -1.8265104293823242
Batch 53/64 loss: -2.1488161087036133
Batch 54/64 loss: -1.8358430862426758
Batch 55/64 loss: -1.8512554168701172
Batch 56/64 loss: -2.0248584747314453
Batch 57/64 loss: -1.6513195037841797
Batch 58/64 loss: -1.8869905471801758
Batch 59/64 loss: -1.9285774230957031
Batch 60/64 loss: -1.9032812118530273
Batch 61/64 loss: -2.059946060180664
Batch 62/64 loss: -1.7385187149047852
Batch 63/64 loss: -1.7833995819091797
Batch 64/64 loss: -6.253151893615723
Epoch 94  Train loss: -1.8279811148549996  Val loss: -2.0390935812619135
Saving best model, epoch: 94
Epoch 95
-------------------------------
Batch 1/64 loss: -1.5353803634643555
Batch 2/64 loss: -1.9023828506469727
Batch 3/64 loss: -2.1166763305664062
Batch 4/64 loss: -1.7597904205322266
Batch 5/64 loss: -1.9678735733032227
Batch 6/64 loss: -1.8376140594482422
Batch 7/64 loss: -1.7717876434326172
Batch 8/64 loss: -1.8484716415405273
Batch 9/64 loss: -1.8636674880981445
Batch 10/64 loss: -1.4765739440917969
Batch 11/64 loss: -1.8528804779052734
Batch 12/64 loss: -1.935044288635254
Batch 13/64 loss: -1.7243318557739258
Batch 14/64 loss: -1.7814397811889648
Batch 15/64 loss: -2.058961868286133
Batch 16/64 loss: -1.8787240982055664
Batch 17/64 loss: -1.8804798126220703
Batch 18/64 loss: -1.5623502731323242
Batch 19/64 loss: -1.8923311233520508
Batch 20/64 loss: -1.9171419143676758
Batch 21/64 loss: -2.0079946517944336
Batch 22/64 loss: -1.6997394561767578
Batch 23/64 loss: -2.031651496887207
Batch 24/64 loss: -2.022970199584961
Batch 25/64 loss: -1.5649604797363281
Batch 26/64 loss: -1.6591148376464844
Batch 27/64 loss: -1.947397232055664
Batch 28/64 loss: -2.0385732650756836
Batch 29/64 loss: -1.9899730682373047
Batch 30/64 loss: -1.6865816116333008
Batch 31/64 loss: -1.5230073928833008
Batch 32/64 loss: -1.8832359313964844
Batch 33/64 loss: -2.1365833282470703
Batch 34/64 loss: -1.5313425064086914
Batch 35/64 loss: -1.8712902069091797
Batch 36/64 loss: -2.11602783203125
Batch 37/64 loss: -1.996795654296875
Batch 38/64 loss: -1.879441261291504
Batch 39/64 loss: -1.465113639831543
Batch 40/64 loss: -1.67803955078125
Batch 41/64 loss: -2.0926284790039062
Batch 42/64 loss: -2.009284019470215
Batch 43/64 loss: -1.7519683837890625
Batch 44/64 loss: -1.7625417709350586
Batch 45/64 loss: -2.032522201538086
Batch 46/64 loss: -1.9933137893676758
Batch 47/64 loss: -2.148379325866699
Batch 48/64 loss: -1.9960956573486328
Batch 49/64 loss: -2.2335195541381836
Batch 50/64 loss: -1.740926742553711
Batch 51/64 loss: -1.8762712478637695
Batch 52/64 loss: -2.2159414291381836
Batch 53/64 loss: -2.124020576477051
Batch 54/64 loss: -1.7619524002075195
Batch 55/64 loss: -1.5636520385742188
Batch 56/64 loss: -1.8156499862670898
Batch 57/64 loss: -2.0168685913085938
Batch 58/64 loss: -1.8711509704589844
Batch 59/64 loss: -2.1198348999023438
Batch 60/64 loss: -1.6877899169921875
Batch 61/64 loss: -1.5898160934448242
Batch 62/64 loss: -1.9903450012207031
Batch 63/64 loss: -1.6897764205932617
Batch 64/64 loss: -6.519606590270996
Epoch 95  Train loss: -1.9179245780496037  Val loss: -2.0607045229357954
Saving best model, epoch: 95
Epoch 96
-------------------------------
Batch 1/64 loss: -2.053619384765625
Batch 2/64 loss: -2.0043764114379883
Batch 3/64 loss: -2.089773178100586
Batch 4/64 loss: -2.158644676208496
Batch 5/64 loss: -1.9670066833496094
Batch 6/64 loss: -2.074772834777832
Batch 7/64 loss: -2.1110763549804688
Batch 8/64 loss: -1.9417648315429688
Batch 9/64 loss: -1.4492158889770508
Batch 10/64 loss: -1.7804937362670898
Batch 11/64 loss: -1.7544097900390625
Batch 12/64 loss: -1.8425445556640625
Batch 13/64 loss: -1.9491214752197266
Batch 14/64 loss: -2.0831966400146484
Batch 15/64 loss: -2.20328426361084
Batch 16/64 loss: -1.887166976928711
Batch 17/64 loss: -1.8181657791137695
Batch 18/64 loss: -2.1905431747436523
Batch 19/64 loss: -2.1280298233032227
Batch 20/64 loss: -1.9002685546875
Batch 21/64 loss: -1.738992691040039
Batch 22/64 loss: -1.903839111328125
Batch 23/64 loss: -1.7730512619018555
Batch 24/64 loss: -1.4310235977172852
Batch 25/64 loss: -2.0396642684936523
Batch 26/64 loss: -1.863591194152832
Batch 27/64 loss: -1.948190689086914
Batch 28/64 loss: -2.0093917846679688
Batch 29/64 loss: -2.3984375
Batch 30/64 loss: -1.996037483215332
Batch 31/64 loss: -2.2342119216918945
Batch 32/64 loss: -2.0804595947265625
Batch 33/64 loss: -1.8082380294799805
Batch 34/64 loss: -1.6975574493408203
Batch 35/64 loss: -1.9408941268920898
Batch 36/64 loss: -1.8080310821533203
Batch 37/64 loss: -2.0951194763183594
Batch 38/64 loss: -1.6318645477294922
Batch 39/64 loss: -2.064939498901367
Batch 40/64 loss: -2.0941028594970703
Batch 41/64 loss: -1.9335145950317383
Batch 42/64 loss: -1.9118232727050781
Batch 43/64 loss: -2.13266658782959
Batch 44/64 loss: -1.869765281677246
Batch 45/64 loss: -2.1748294830322266
Batch 46/64 loss: -1.8321332931518555
Batch 47/64 loss: -1.456838607788086
Batch 48/64 loss: -2.143026351928711
Batch 49/64 loss: -1.8835763931274414
Batch 50/64 loss: -1.8720273971557617
Batch 51/64 loss: -1.8324604034423828
Batch 52/64 loss: -1.8844099044799805
Batch 53/64 loss: -2.1662216186523438
Batch 54/64 loss: -2.018916130065918
Batch 55/64 loss: -1.4732322692871094
Batch 56/64 loss: -1.8862419128417969
Batch 57/64 loss: -1.9482545852661133
Batch 58/64 loss: -0.9852542877197266
Batch 59/64 loss: -1.2802057266235352
Batch 60/64 loss: -1.9682302474975586
Batch 61/64 loss: -2.004733085632324
Batch 62/64 loss: -1.9653940200805664
Batch 63/64 loss: -1.7479162216186523
Batch 64/64 loss: -6.307370185852051
Epoch 96  Train loss: -1.9615264705583162  Val loss: -2.1014513100955083
Saving best model, epoch: 96
Epoch 97
-------------------------------
Batch 1/64 loss: -1.7879142761230469
Batch 2/64 loss: -2.1149234771728516
Batch 3/64 loss: -1.9821062088012695
Batch 4/64 loss: -1.749070167541504
Batch 5/64 loss: -1.9663314819335938
Batch 6/64 loss: -2.021871566772461
Batch 7/64 loss: -1.9548568725585938
Batch 8/64 loss: -2.1595401763916016
Batch 9/64 loss: -2.1809988021850586
Batch 10/64 loss: -1.7499732971191406
Batch 11/64 loss: -2.2396373748779297
Batch 12/64 loss: -2.124199867248535
Batch 13/64 loss: -2.033167839050293
Batch 14/64 loss: -2.064085006713867
Batch 15/64 loss: -1.649430274963379
Batch 16/64 loss: -2.0227928161621094
Batch 17/64 loss: -2.167107582092285
Batch 18/64 loss: -1.9811792373657227
Batch 19/64 loss: -1.9510679244995117
Batch 20/64 loss: -1.9531049728393555
Batch 21/64 loss: -1.721334457397461
Batch 22/64 loss: -1.9477510452270508
Batch 23/64 loss: -2.1714563369750977
Batch 24/64 loss: -2.143071174621582
Batch 25/64 loss: -1.915797233581543
Batch 26/64 loss: -2.2171545028686523
Batch 27/64 loss: -2.067202568054199
Batch 28/64 loss: -2.11248779296875
Batch 29/64 loss: -1.9614791870117188
Batch 30/64 loss: -1.8959007263183594
Batch 31/64 loss: -1.4719667434692383
Batch 32/64 loss: -1.5853796005249023
Batch 33/64 loss: -2.227473258972168
Batch 34/64 loss: -2.000394821166992
Batch 35/64 loss: -1.939422607421875
Batch 36/64 loss: -1.8344697952270508
Batch 37/64 loss: -1.8623600006103516
Batch 38/64 loss: -2.097360610961914
Batch 39/64 loss: -2.0773744583129883
Batch 40/64 loss: -1.9318313598632812
Batch 41/64 loss: -2.142580986022949
Batch 42/64 loss: -2.1358938217163086
Batch 43/64 loss: -2.2637739181518555
Batch 44/64 loss: -1.46759033203125
Batch 45/64 loss: -2.1250219345092773
Batch 46/64 loss: -2.007547378540039
Batch 47/64 loss: -2.156068801879883
Batch 48/64 loss: -2.004166603088379
Batch 49/64 loss: -2.1614675521850586
Batch 50/64 loss: -1.9183063507080078
Batch 51/64 loss: -1.8139114379882812
Batch 52/64 loss: -1.867462158203125
Batch 53/64 loss: -1.794978141784668
Batch 54/64 loss: -1.9882879257202148
Batch 55/64 loss: -1.7032508850097656
Batch 56/64 loss: -1.857100486755371
Batch 57/64 loss: -2.207019805908203
Batch 58/64 loss: -1.8884544372558594
Batch 59/64 loss: -1.7861156463623047
Batch 60/64 loss: -1.9631423950195312
Batch 61/64 loss: -1.7860517501831055
Batch 62/64 loss: -1.9788141250610352
Batch 63/64 loss: -2.1134214401245117
Batch 64/64 loss: -6.58760929107666
Epoch 97  Train loss: -2.025194710376216  Val loss: -2.128402342911029
Saving best model, epoch: 97
Epoch 98
-------------------------------
Batch 1/64 loss: -1.3789291381835938
Batch 2/64 loss: -1.9501190185546875
Batch 3/64 loss: -2.2629289627075195
Batch 4/64 loss: -1.8057861328125
Batch 5/64 loss: -2.0289669036865234
Batch 6/64 loss: -2.040304183959961
Batch 7/64 loss: -1.9872703552246094
Batch 8/64 loss: -1.7125396728515625
Batch 9/64 loss: -1.9603843688964844
Batch 10/64 loss: -1.8744230270385742
Batch 11/64 loss: -1.8197765350341797
Batch 12/64 loss: -2.138151168823242
Batch 13/64 loss: -1.958176612854004
Batch 14/64 loss: -2.102473258972168
Batch 15/64 loss: -2.229170799255371
Batch 16/64 loss: -1.4655895233154297
Batch 17/64 loss: -1.6656312942504883
Batch 18/64 loss: -1.5949468612670898
Batch 19/64 loss: -2.037510871887207
Batch 20/64 loss: -1.9832649230957031
Batch 21/64 loss: -1.0242385864257812
Batch 22/64 loss: -2.0692529678344727
Batch 23/64 loss: -1.9033384323120117
Batch 24/64 loss: -1.6637258529663086
Batch 25/64 loss: -1.6822423934936523
Batch 26/64 loss: -1.8972177505493164
Batch 27/64 loss: -1.6991863250732422
Batch 28/64 loss: -1.8748712539672852
Batch 29/64 loss: -1.8743314743041992
Batch 30/64 loss: -1.8561859130859375
Batch 31/64 loss: -1.955245018005371
Batch 32/64 loss: -1.5879411697387695
Batch 33/64 loss: -1.5154123306274414
Batch 34/64 loss: -1.5035896301269531
Batch 35/64 loss: -2.0473623275756836
Batch 36/64 loss: -1.8302621841430664
Batch 37/64 loss: -1.6576671600341797
Batch 38/64 loss: -2.135568618774414
Batch 39/64 loss: -1.9477729797363281
Batch 40/64 loss: -1.932779312133789
Batch 41/64 loss: -1.6166934967041016
Batch 42/64 loss: -1.644179344177246
Batch 43/64 loss: -1.3334522247314453
Batch 44/64 loss: -1.8097715377807617
Batch 45/64 loss: -2.164224624633789
Batch 46/64 loss: -2.067511558532715
Batch 47/64 loss: -1.6373958587646484
Batch 48/64 loss: -1.9590930938720703
Batch 49/64 loss: -1.4434661865234375
Batch 50/64 loss: -1.7432212829589844
Batch 51/64 loss: -1.6262245178222656
Batch 52/64 loss: -1.7276897430419922
Batch 53/64 loss: -1.9595451354980469
Batch 54/64 loss: -1.8356447219848633
Batch 55/64 loss: -1.7677059173583984
Batch 56/64 loss: -1.7846994400024414
Batch 57/64 loss: -1.693246841430664
Batch 58/64 loss: -1.5241127014160156
Batch 59/64 loss: -1.8257999420166016
Batch 60/64 loss: -1.7709264755249023
Batch 61/64 loss: -1.4948530197143555
Batch 62/64 loss: -1.8308773040771484
Batch 63/64 loss: -1.7191543579101562
Batch 64/64 loss: -6.522595405578613
Epoch 98  Train loss: -1.859230920380237  Val loss: -1.835789500233234
Epoch 99
-------------------------------
Batch 1/64 loss: -2.035433769226074
Batch 2/64 loss: -1.9368724822998047
Batch 3/64 loss: -1.9060440063476562
Batch 4/64 loss: -1.8185243606567383
Batch 5/64 loss: -1.8031692504882812
Batch 6/64 loss: -1.2199487686157227
Batch 7/64 loss: -1.7460527420043945
Batch 8/64 loss: -1.8203229904174805
Batch 9/64 loss: -1.6519737243652344
Batch 10/64 loss: -2.0527143478393555
Batch 11/64 loss: -1.8178815841674805
Batch 12/64 loss: -1.852823257446289
Batch 13/64 loss: -2.110605239868164
Batch 14/64 loss: -1.951324462890625
Batch 15/64 loss: -1.622910499572754
Batch 16/64 loss: -2.0867929458618164
Batch 17/64 loss: -1.7835063934326172
Batch 18/64 loss: -1.9074935913085938
Batch 19/64 loss: -1.9147863388061523
Batch 20/64 loss: -2.0555124282836914
Batch 21/64 loss: -2.09665584564209
Batch 22/64 loss: -1.4818010330200195
Batch 23/64 loss: -1.9364252090454102
Batch 24/64 loss: -1.9476995468139648
Batch 25/64 loss: -1.5000324249267578
Batch 26/64 loss: -2.203484535217285
Batch 27/64 loss: -1.9645328521728516
Batch 28/64 loss: -1.9512882232666016
Batch 29/64 loss: -2.1467676162719727
Batch 30/64 loss: -2.1114730834960938
Batch 31/64 loss: -2.058368682861328
Batch 32/64 loss: -1.8162384033203125
Batch 33/64 loss: -2.1761960983276367
Batch 34/64 loss: -1.9182682037353516
Batch 35/64 loss: -1.9398393630981445
Batch 36/64 loss: -1.8768510818481445
Batch 37/64 loss: -2.0097618103027344
Batch 38/64 loss: -2.1865739822387695
Batch 39/64 loss: -1.6846837997436523
Batch 40/64 loss: -1.7684459686279297
Batch 41/64 loss: -2.077627182006836
Batch 42/64 loss: -1.3250484466552734
Batch 43/64 loss: -1.9844532012939453
Batch 44/64 loss: -2.1105079650878906
Batch 45/64 loss: -2.0833921432495117
Batch 46/64 loss: -2.16281795501709
Batch 47/64 loss: -2.104039192199707
Batch 48/64 loss: -2.048299789428711
Batch 49/64 loss: -1.9796562194824219
Batch 50/64 loss: -1.950922966003418
Batch 51/64 loss: -1.9925193786621094
Batch 52/64 loss: -2.1392650604248047
Batch 53/64 loss: -1.8900012969970703
Batch 54/64 loss: -1.468337059020996
Batch 55/64 loss: -1.4879484176635742
Batch 56/64 loss: -1.7487115859985352
Batch 57/64 loss: -1.737192153930664
Batch 58/64 loss: -2.0561141967773438
Batch 59/64 loss: -2.2550153732299805
Batch 60/64 loss: -1.6719942092895508
Batch 61/64 loss: -2.052302360534668
Batch 62/64 loss: -2.077852249145508
Batch 63/64 loss: -2.0403928756713867
Batch 64/64 loss: -6.562741279602051
Epoch 99  Train loss: -1.9644948734956629  Val loss: -2.079439405723126
Epoch 100
-------------------------------
Batch 1/64 loss: -1.4519224166870117
Batch 2/64 loss: -2.199801445007324
Batch 3/64 loss: -1.8615179061889648
Batch 4/64 loss: -1.6646957397460938
Batch 5/64 loss: -2.0161027908325195
Batch 6/64 loss: -1.9562950134277344
Batch 7/64 loss: -1.8844223022460938
Batch 8/64 loss: -1.8388471603393555
Batch 9/64 loss: -1.9484367370605469
Batch 10/64 loss: -2.086118698120117
Batch 11/64 loss: -1.7824077606201172
Batch 12/64 loss: -2.150984764099121
Batch 13/64 loss: -1.868271827697754
Batch 14/64 loss: -1.8851938247680664
Batch 15/64 loss: -2.059206008911133
Batch 16/64 loss: -1.746541976928711
Batch 17/64 loss: -1.7458486557006836
Batch 18/64 loss: -2.149219512939453
Batch 19/64 loss: -1.7235193252563477
Batch 20/64 loss: -1.7405776977539062
Batch 21/64 loss: -2.1147422790527344
Batch 22/64 loss: -1.980881690979004
Batch 23/64 loss: -2.00669002532959
Batch 24/64 loss: -1.837956428527832
Batch 25/64 loss: -2.099856376647949
Batch 26/64 loss: -1.9528923034667969
Batch 27/64 loss: -1.8368682861328125
Batch 28/64 loss: -2.031007766723633
Batch 29/64 loss: -2.0363330841064453
Batch 30/64 loss: -1.8025188446044922
Batch 31/64 loss: -1.4072933197021484
Batch 32/64 loss: -1.8776559829711914
Batch 33/64 loss: -2.143162727355957
Batch 34/64 loss: -2.1300296783447266
Batch 35/64 loss: -1.9897384643554688
Batch 36/64 loss: -1.5483417510986328
Batch 37/64 loss: -1.976881980895996
Batch 38/64 loss: -2.138507843017578
Batch 39/64 loss: -2.215505599975586
Batch 40/64 loss: -1.974268913269043
Batch 41/64 loss: -2.1339197158813477
Batch 42/64 loss: -1.6870079040527344
Batch 43/64 loss: -2.163728713989258
Batch 44/64 loss: -1.9558897018432617
Batch 45/64 loss: -2.1454763412475586
Batch 46/64 loss: -1.88787841796875
Batch 47/64 loss: -2.177556037902832
Batch 48/64 loss: -2.254960060119629
Batch 49/64 loss: -1.9153718948364258
Batch 50/64 loss: -2.1488285064697266
Batch 51/64 loss: -1.6858644485473633
Batch 52/64 loss: -2.2756271362304688
Batch 53/64 loss: -1.959397315979004
Batch 54/64 loss: -1.9879770278930664
Batch 55/64 loss: -2.1812829971313477
Batch 56/64 loss: -1.8495550155639648
Batch 57/64 loss: -1.9805517196655273
Batch 58/64 loss: -2.017575263977051
Batch 59/64 loss: -1.9287958145141602
Batch 60/64 loss: -1.5320825576782227
Batch 61/64 loss: -2.086522102355957
Batch 62/64 loss: -2.170745849609375
Batch 63/64 loss: -1.8857622146606445
Batch 64/64 loss: -6.546957492828369
Epoch 100  Train loss: -2.0044492515863155  Val loss: -2.10429940764437
Epoch 101
-------------------------------
Batch 1/64 loss: -1.9708538055419922
Batch 2/64 loss: -1.703871726989746
Batch 3/64 loss: -1.9687252044677734
Batch 4/64 loss: -2.0639238357543945
Batch 5/64 loss: -2.0431222915649414
Batch 6/64 loss: -1.9502859115600586
Batch 7/64 loss: -1.358139991760254
Batch 8/64 loss: -2.0758743286132812
Batch 9/64 loss: -2.04726505279541
Batch 10/64 loss: -1.9490251541137695
Batch 11/64 loss: -1.680241584777832
Batch 12/64 loss: -1.7939090728759766
Batch 13/64 loss: -1.8772163391113281
Batch 14/64 loss: -1.2677326202392578
Batch 15/64 loss: -1.491593360900879
Batch 16/64 loss: -1.8478574752807617
Batch 17/64 loss: -1.6400432586669922
Batch 18/64 loss: -1.7177295684814453
Batch 19/64 loss: -1.3124475479125977
Batch 20/64 loss: -1.6573944091796875
Batch 21/64 loss: -1.7893524169921875
Batch 22/64 loss: -1.9151840209960938
Batch 23/64 loss: -1.2624444961547852
Batch 24/64 loss: -2.017758369445801
Batch 25/64 loss: -1.8898019790649414
Batch 26/64 loss: -1.7617549896240234
Batch 27/64 loss: -0.8439741134643555
Batch 28/64 loss: -1.3454294204711914
Batch 29/64 loss: -1.8765544891357422
Batch 30/64 loss: -1.2212409973144531
Batch 31/64 loss: -0.9776439666748047
Batch 32/64 loss: -1.4055509567260742
Batch 33/64 loss: 1.3221769332885742
Batch 34/64 loss: -0.4887428283691406
Batch 35/64 loss: -0.6317358016967773
Batch 36/64 loss: -1.6300830841064453
Batch 37/64 loss: -1.0742988586425781
Batch 38/64 loss: -0.4170064926147461
Batch 39/64 loss: -1.2341232299804688
Batch 40/64 loss: -1.6990852355957031
Batch 41/64 loss: -1.5116586685180664
Batch 42/64 loss: -1.4155597686767578
Batch 43/64 loss: -1.4409608840942383
Batch 44/64 loss: -1.7581920623779297
Batch 45/64 loss: -1.218703269958496
Batch 46/64 loss: -0.9650821685791016
Batch 47/64 loss: -1.5079517364501953
Batch 48/64 loss: -1.0834236145019531
Batch 49/64 loss: -1.1794462203979492
Batch 50/64 loss: -0.9974241256713867
Batch 51/64 loss: -1.2249574661254883
Batch 52/64 loss: -0.8930454254150391
Batch 53/64 loss: -1.124262809753418
Batch 54/64 loss: -0.74603271484375
Batch 55/64 loss: -1.1584749221801758
Batch 56/64 loss: -1.5048236846923828
Batch 57/64 loss: -0.6060037612915039
Batch 58/64 loss: -1.439626693725586
Batch 59/64 loss: -0.6850824356079102
Batch 60/64 loss: -1.5958328247070312
Batch 61/64 loss: -1.339111328125
Batch 62/64 loss: -1.714400291442871
Batch 63/64 loss: -1.3603754043579102
Batch 64/64 loss: -5.624518871307373
Epoch 101  Train loss: -1.4473045143426633  Val loss: -1.3472477889962213
Epoch 102
-------------------------------
Batch 1/64 loss: -1.3324480056762695
Batch 2/64 loss: -1.1537408828735352
Batch 3/64 loss: -1.749434471130371
Batch 4/64 loss: -1.890127182006836
Batch 5/64 loss: -1.6657333374023438
Batch 6/64 loss: -1.6163663864135742
Batch 7/64 loss: -1.1604509353637695
Batch 8/64 loss: -1.7280950546264648
Batch 9/64 loss: -1.2649574279785156
Batch 10/64 loss: -1.3613367080688477
Batch 11/64 loss: -1.7795953750610352
Batch 12/64 loss: -1.5889997482299805
Batch 13/64 loss: -1.9100236892700195
Batch 14/64 loss: -1.5325946807861328
Batch 15/64 loss: -1.8000078201293945
Batch 16/64 loss: -1.2291908264160156
Batch 17/64 loss: -1.557499885559082
Batch 18/64 loss: -1.5190057754516602
Batch 19/64 loss: -1.1887969970703125
Batch 20/64 loss: -1.1125316619873047
Batch 21/64 loss: -0.9201240539550781
Batch 22/64 loss: -1.765507698059082
Batch 23/64 loss: -1.6655464172363281
Batch 24/64 loss: -1.1815729141235352
Batch 25/64 loss: -1.4004850387573242
Batch 26/64 loss: -1.7952461242675781
Batch 27/64 loss: -1.3023643493652344
Batch 28/64 loss: -1.5747594833374023
Batch 29/64 loss: -1.880624771118164
Batch 30/64 loss: -1.301407814025879
Batch 31/64 loss: -1.1629695892333984
Batch 32/64 loss: -1.3247861862182617
Batch 33/64 loss: -1.4527921676635742
Batch 34/64 loss: -1.5178442001342773
Batch 35/64 loss: -1.4380273818969727
Batch 36/64 loss: -1.5097780227661133
Batch 37/64 loss: -1.3665952682495117
Batch 38/64 loss: -1.6236257553100586
Batch 39/64 loss: -1.279623031616211
Batch 40/64 loss: -1.6246871948242188
Batch 41/64 loss: -1.2618656158447266
Batch 42/64 loss: -1.508061408996582
Batch 43/64 loss: -1.4951715469360352
Batch 44/64 loss: -1.1075372695922852
Batch 45/64 loss: -1.3837461471557617
Batch 46/64 loss: -1.497899055480957
Batch 47/64 loss: -1.6104116439819336
Batch 48/64 loss: -1.3440113067626953
Batch 49/64 loss: -1.789876937866211
Batch 50/64 loss: -1.6975088119506836
Batch 51/64 loss: -1.6172561645507812
Batch 52/64 loss: -1.1222953796386719
Batch 53/64 loss: -1.7711524963378906
Batch 54/64 loss: -1.8574638366699219
Batch 55/64 loss: -1.0913610458374023
Batch 56/64 loss: -1.6446294784545898
Batch 57/64 loss: -1.7626571655273438
Batch 58/64 loss: -1.8759784698486328
Batch 59/64 loss: -1.9861822128295898
Batch 60/64 loss: -1.470686912536621
Batch 61/64 loss: -1.8615331649780273
Batch 62/64 loss: -1.4860610961914062
Batch 63/64 loss: -1.7114439010620117
Batch 64/64 loss: -6.154130935668945
Epoch 102  Train loss: -1.5654853895598766  Val loss: -1.8257761689805494
Epoch 103
-------------------------------
Batch 1/64 loss: -1.6427068710327148
Batch 2/64 loss: -1.3125581741333008
Batch 3/64 loss: -1.4458980560302734
Batch 4/64 loss: -1.8969049453735352
Batch 5/64 loss: -2.1972122192382812
Batch 6/64 loss: -1.7499408721923828
Batch 7/64 loss: -1.383387565612793
Batch 8/64 loss: -2.1157760620117188
Batch 9/64 loss: -1.4695405960083008
Batch 10/64 loss: -1.9580326080322266
Batch 11/64 loss: -1.5193214416503906
Batch 12/64 loss: -1.9888677597045898
Batch 13/64 loss: -1.3871479034423828
Batch 14/64 loss: -1.965087890625
Batch 15/64 loss: -1.9736480712890625
Batch 16/64 loss: -1.8318700790405273
Batch 17/64 loss: -1.7554569244384766
Batch 18/64 loss: -1.9046316146850586
Batch 19/64 loss: -1.981400489807129
Batch 20/64 loss: -1.5370025634765625
Batch 21/64 loss: -1.8290424346923828
Batch 22/64 loss: -1.8374147415161133
Batch 23/64 loss: -1.980687141418457
Batch 24/64 loss: -1.9062385559082031
Batch 25/64 loss: -2.24118709564209
Batch 26/64 loss: -1.6931819915771484
Batch 27/64 loss: -1.8502159118652344
Batch 28/64 loss: -2.048262596130371
Batch 29/64 loss: -2.0976181030273438
Batch 30/64 loss: -2.0166168212890625
Batch 31/64 loss: -1.69219970703125
Batch 32/64 loss: -1.8812332153320312
Batch 33/64 loss: -1.947340965270996
Batch 34/64 loss: -1.5312719345092773
Batch 35/64 loss: -1.704594612121582
Batch 36/64 loss: -2.3175487518310547
Batch 37/64 loss: -1.9615869522094727
Batch 38/64 loss: -1.5658760070800781
Batch 39/64 loss: -2.0409164428710938
Batch 40/64 loss: -1.6884098052978516
Batch 41/64 loss: -1.6681833267211914
Batch 42/64 loss: -2.088273048400879
Batch 43/64 loss: -1.9403667449951172
Batch 44/64 loss: -2.1914024353027344
Batch 45/64 loss: -1.8009147644042969
Batch 46/64 loss: -1.620347023010254
Batch 47/64 loss: -1.9110994338989258
Batch 48/64 loss: -2.155515670776367
Batch 49/64 loss: -1.8197174072265625
Batch 50/64 loss: -1.970442771911621
Batch 51/64 loss: -1.694045066833496
Batch 52/64 loss: -2.0975217819213867
Batch 53/64 loss: -2.0831518173217773
Batch 54/64 loss: -1.9799737930297852
Batch 55/64 loss: -1.8954830169677734
Batch 56/64 loss: -1.690216064453125
Batch 57/64 loss: -1.816014289855957
Batch 58/64 loss: -1.6278676986694336
Batch 59/64 loss: -1.9554872512817383
Batch 60/64 loss: -2.073863983154297
Batch 61/64 loss: -1.8809967041015625
Batch 62/64 loss: -1.9557161331176758
Batch 63/64 loss: -2.0343446731567383
Batch 64/64 loss: -6.231608867645264
Epoch 103  Train loss: -1.9054507928736069  Val loss: -2.143159020807325
Saving best model, epoch: 103
Epoch 104
-------------------------------
Batch 1/64 loss: -2.1846694946289062
Batch 2/64 loss: -1.9940900802612305
Batch 3/64 loss: -1.8888578414916992
Batch 4/64 loss: -1.021286964416504
Batch 5/64 loss: -1.582890510559082
Batch 6/64 loss: -1.8798885345458984
Batch 7/64 loss: -1.9120492935180664
Batch 8/64 loss: -1.7804641723632812
Batch 9/64 loss: -1.922506332397461
Batch 10/64 loss: -1.8021554946899414
Batch 11/64 loss: -1.6548137664794922
Batch 12/64 loss: -2.154815673828125
Batch 13/64 loss: -2.2007627487182617
Batch 14/64 loss: -1.8161134719848633
Batch 15/64 loss: -2.1736793518066406
Batch 16/64 loss: -1.919968605041504
Batch 17/64 loss: -2.027642250061035
Batch 18/64 loss: -1.5579519271850586
Batch 19/64 loss: -1.3501510620117188
Batch 20/64 loss: -2.0183563232421875
Batch 21/64 loss: -1.889547348022461
Batch 22/64 loss: -2.169461250305176
Batch 23/64 loss: -2.221503257751465
Batch 24/64 loss: -2.2677793502807617
Batch 25/64 loss: -2.1148195266723633
Batch 26/64 loss: -2.1493072509765625
Batch 27/64 loss: -2.2976675033569336
Batch 28/64 loss: -2.036703109741211
Batch 29/64 loss: -2.1959447860717773
Batch 30/64 loss: -2.16823673248291
Batch 31/64 loss: -2.2989416122436523
Batch 32/64 loss: -2.064602851867676
Batch 33/64 loss: -1.9904966354370117
Batch 34/64 loss: -2.002208709716797
Batch 35/64 loss: -2.0606250762939453
Batch 36/64 loss: -2.276869773864746
Batch 37/64 loss: -1.7812490463256836
Batch 38/64 loss: -1.9209861755371094
Batch 39/64 loss: -2.1262617111206055
Batch 40/64 loss: -1.564560890197754
Batch 41/64 loss: -1.9926328659057617
Batch 42/64 loss: -1.8269033432006836
Batch 43/64 loss: -1.7447338104248047
Batch 44/64 loss: -2.1367034912109375
Batch 45/64 loss: -2.053910255432129
Batch 46/64 loss: -2.151984214782715
Batch 47/64 loss: -1.5844535827636719
Batch 48/64 loss: -2.2970428466796875
Batch 49/64 loss: -1.7992067337036133
Batch 50/64 loss: -1.9424552917480469
Batch 51/64 loss: -1.9025049209594727
Batch 52/64 loss: -1.9516096115112305
Batch 53/64 loss: -2.2363100051879883
Batch 54/64 loss: -1.9440040588378906
Batch 55/64 loss: -1.5940723419189453
Batch 56/64 loss: -2.253438949584961
Batch 57/64 loss: -1.9716796875
Batch 58/64 loss: -2.0574817657470703
Batch 59/64 loss: -2.203716278076172
Batch 60/64 loss: -1.6034049987792969
Batch 61/64 loss: -1.704239845275879
Batch 62/64 loss: -1.9613361358642578
Batch 63/64 loss: -2.1099653244018555
Batch 64/64 loss: -6.34654426574707
Epoch 104  Train loss: -2.011366040098901  Val loss: -2.063922790317601
Epoch 105
-------------------------------
Batch 1/64 loss: -2.012295722961426
Batch 2/64 loss: -2.014131546020508
Batch 3/64 loss: -1.8469467163085938
Batch 4/64 loss: -1.8617639541625977
Batch 5/64 loss: -1.8803510665893555
Batch 6/64 loss: -2.238262176513672
Batch 7/64 loss: -1.812993049621582
Batch 8/64 loss: -1.9622316360473633
Batch 9/64 loss: -1.7948694229125977
Batch 10/64 loss: -2.1204967498779297
Batch 11/64 loss: -2.0117263793945312
Batch 12/64 loss: -1.9072685241699219
Batch 13/64 loss: -2.053377151489258
Batch 14/64 loss: -2.1108665466308594
Batch 15/64 loss: -1.9570131301879883
Batch 16/64 loss: -1.9806852340698242
Batch 17/64 loss: -1.984665870666504
Batch 18/64 loss: -2.260456085205078
Batch 19/64 loss: -1.9614543914794922
Batch 20/64 loss: -1.8658332824707031
Batch 21/64 loss: -1.5467872619628906
Batch 22/64 loss: -2.155101776123047
Batch 23/64 loss: -1.9620046615600586
Batch 24/64 loss: -1.8411054611206055
Batch 25/64 loss: -2.0450305938720703
Batch 26/64 loss: -1.877213478088379
Batch 27/64 loss: -2.037611961364746
Batch 28/64 loss: -1.8718070983886719
Batch 29/64 loss: -1.7531194686889648
Batch 30/64 loss: -1.9912071228027344
Batch 31/64 loss: -2.0860233306884766
Batch 32/64 loss: -1.711324691772461
Batch 33/64 loss: -2.1742563247680664
Batch 34/64 loss: -1.661778450012207
Batch 35/64 loss: -1.8278131484985352
Batch 36/64 loss: -2.0341081619262695
Batch 37/64 loss: -1.550450325012207
Batch 38/64 loss: -1.9697866439819336
Batch 39/64 loss: -2.1488037109375
Batch 40/64 loss: -2.25205135345459
Batch 41/64 loss: -1.814967155456543
Batch 42/64 loss: -1.8178777694702148
Batch 43/64 loss: -2.0894784927368164
Batch 44/64 loss: -2.178553581237793
Batch 45/64 loss: -1.5153703689575195
Batch 46/64 loss: -1.5279598236083984
Batch 47/64 loss: -1.9189224243164062
Batch 48/64 loss: -2.1348743438720703
Batch 49/64 loss: -2.1578073501586914
Batch 50/64 loss: -2.156682014465332
Batch 51/64 loss: -2.2793378829956055
Batch 52/64 loss: -2.06093692779541
Batch 53/64 loss: -1.317800521850586
Batch 54/64 loss: -1.3582267761230469
Batch 55/64 loss: -1.6590709686279297
Batch 56/64 loss: -1.7802925109863281
Batch 57/64 loss: -1.805068016052246
Batch 58/64 loss: -2.184117317199707
Batch 59/64 loss: -2.1982898712158203
Batch 60/64 loss: -2.086639404296875
Batch 61/64 loss: -1.7817106246948242
Batch 62/64 loss: -2.1599931716918945
Batch 63/64 loss: -1.760676383972168
Batch 64/64 loss: -6.620106220245361
Epoch 105  Train loss: -1.9897224631963992  Val loss: -2.250306775070138
Saving best model, epoch: 105
Epoch 106
-------------------------------
Batch 1/64 loss: -1.2053308486938477
Batch 2/64 loss: -2.1734790802001953
Batch 3/64 loss: -1.8682889938354492
Batch 4/64 loss: -1.7823400497436523
Batch 5/64 loss: -1.993668556213379
Batch 6/64 loss: -2.073497772216797
Batch 7/64 loss: -2.06882381439209
Batch 8/64 loss: -1.9874773025512695
Batch 9/64 loss: -1.643641471862793
Batch 10/64 loss: -1.7090044021606445
Batch 11/64 loss: -2.0335607528686523
Batch 12/64 loss: -2.295384407043457
Batch 13/64 loss: -1.9417695999145508
Batch 14/64 loss: -2.168614387512207
Batch 15/64 loss: -1.9621906280517578
Batch 16/64 loss: -1.7171001434326172
Batch 17/64 loss: -2.259899139404297
Batch 18/64 loss: -1.7414255142211914
Batch 19/64 loss: -2.1435041427612305
Batch 20/64 loss: -1.7962255477905273
Batch 21/64 loss: -2.220399856567383
Batch 22/64 loss: -1.8837366104125977
Batch 23/64 loss: -2.002805709838867
Batch 24/64 loss: -1.6966657638549805
Batch 25/64 loss: -2.0530385971069336
Batch 26/64 loss: -2.010744094848633
Batch 27/64 loss: -1.8650693893432617
Batch 28/64 loss: -1.885366439819336
Batch 29/64 loss: -2.1946487426757812
Batch 30/64 loss: -1.8503360748291016
Batch 31/64 loss: -1.9461345672607422
Batch 32/64 loss: -1.4243717193603516
Batch 33/64 loss: -1.671809196472168
Batch 34/64 loss: -1.8455142974853516
Batch 35/64 loss: -1.9660215377807617
Batch 36/64 loss: -2.1367664337158203
Batch 37/64 loss: -1.9885940551757812
Batch 38/64 loss: -1.9159746170043945
Batch 39/64 loss: -2.0630903244018555
Batch 40/64 loss: -2.29325008392334
Batch 41/64 loss: -1.8499555587768555
Batch 42/64 loss: -1.559030532836914
Batch 43/64 loss: -1.865250587463379
Batch 44/64 loss: -1.7907218933105469
Batch 45/64 loss: -1.9809017181396484
Batch 46/64 loss: -1.4068355560302734
Batch 47/64 loss: -2.287339210510254
Batch 48/64 loss: -2.064542770385742
Batch 49/64 loss: -1.448038101196289
Batch 50/64 loss: -1.919865608215332
Batch 51/64 loss: -2.122190475463867
Batch 52/64 loss: -1.9499969482421875
Batch 53/64 loss: -2.121798515319824
Batch 54/64 loss: -2.1915340423583984
Batch 55/64 loss: -2.0324182510375977
Batch 56/64 loss: -1.6615076065063477
Batch 57/64 loss: -1.89727783203125
Batch 58/64 loss: -2.2015933990478516
Batch 59/64 loss: -2.102341651916504
Batch 60/64 loss: -1.9212093353271484
Batch 61/64 loss: -2.094423294067383
Batch 62/64 loss: -2.04598331451416
Batch 63/64 loss: -2.02938175201416
Batch 64/64 loss: -6.614880084991455
Epoch 106  Train loss: -1.9919194146698596  Val loss: -2.2205575897111927
Epoch 107
-------------------------------
Batch 1/64 loss: -2.10174560546875
Batch 2/64 loss: -1.7379093170166016
Batch 3/64 loss: -2.053727149963379
Batch 4/64 loss: -1.5660600662231445
Batch 5/64 loss: -2.0207061767578125
Batch 6/64 loss: -2.199258804321289
Batch 7/64 loss: -2.02101993560791
Batch 8/64 loss: -2.1011877059936523
Batch 9/64 loss: -2.11041259765625
Batch 10/64 loss: -1.777449607849121
Batch 11/64 loss: -1.6912460327148438
Batch 12/64 loss: -1.7631826400756836
Batch 13/64 loss: -2.027468681335449
Batch 14/64 loss: -2.040421485900879
Batch 15/64 loss: -2.19412899017334
Batch 16/64 loss: -1.8201942443847656
Batch 17/64 loss: -1.9141530990600586
Batch 18/64 loss: -1.8570022583007812
Batch 19/64 loss: -2.1639509201049805
Batch 20/64 loss: -1.9341239929199219
Batch 21/64 loss: -1.7317886352539062
Batch 22/64 loss: -1.8357257843017578
Batch 23/64 loss: -2.160952568054199
Batch 24/64 loss: -1.7662038803100586
Batch 25/64 loss: -1.863321304321289
Batch 26/64 loss: -2.0617456436157227
Batch 27/64 loss: -1.5825605392456055
Batch 28/64 loss: -1.9796934127807617
Batch 29/64 loss: -2.058206558227539
Batch 30/64 loss: -1.8557672500610352
Batch 31/64 loss: -1.9132890701293945
Batch 32/64 loss: -2.042287826538086
Batch 33/64 loss: -1.550058364868164
Batch 34/64 loss: -2.2333011627197266
Batch 35/64 loss: -1.8957796096801758
Batch 36/64 loss: -1.9110774993896484
Batch 37/64 loss: -1.8466148376464844
Batch 38/64 loss: -2.055269241333008
Batch 39/64 loss: -1.7734766006469727
Batch 40/64 loss: -1.7959508895874023
Batch 41/64 loss: -1.9196691513061523
Batch 42/64 loss: -2.0807266235351562
Batch 43/64 loss: -1.349884033203125
Batch 44/64 loss: -2.1599063873291016
Batch 45/64 loss: -1.8382129669189453
Batch 46/64 loss: -2.14095401763916
Batch 47/64 loss: -2.106747627258301
Batch 48/64 loss: -2.062978744506836
Batch 49/64 loss: -2.040496826171875
Batch 50/64 loss: -1.1143016815185547
Batch 51/64 loss: -1.6218996047973633
Batch 52/64 loss: -2.1163272857666016
Batch 53/64 loss: -1.933889389038086
Batch 54/64 loss: -2.252253532409668
Batch 55/64 loss: -2.1429576873779297
Batch 56/64 loss: -1.941476821899414
Batch 57/64 loss: -1.713766098022461
Batch 58/64 loss: -2.0326385498046875
Batch 59/64 loss: -2.197681427001953
Batch 60/64 loss: -2.275148391723633
Batch 61/64 loss: -2.028134346008301
Batch 62/64 loss: -1.911489486694336
Batch 63/64 loss: -2.14102840423584
Batch 64/64 loss: -6.490325450897217
Epoch 107  Train loss: -1.9921369907902737  Val loss: -2.230282275537445
Epoch 108
-------------------------------
Batch 1/64 loss: -2.158205032348633
Batch 2/64 loss: -2.0298404693603516
Batch 3/64 loss: -2.121382713317871
Batch 4/64 loss: -2.2813873291015625
Batch 5/64 loss: -2.1641197204589844
Batch 6/64 loss: -1.9352912902832031
Batch 7/64 loss: -1.4370689392089844
Batch 8/64 loss: -2.154703140258789
Batch 9/64 loss: -2.1797590255737305
Batch 10/64 loss: -2.010390281677246
Batch 11/64 loss: -2.09244441986084
Batch 12/64 loss: -1.858236312866211
Batch 13/64 loss: -2.251753807067871
Batch 14/64 loss: -1.8539714813232422
Batch 15/64 loss: -2.119913101196289
Batch 16/64 loss: -1.973165512084961
Batch 17/64 loss: -1.9921674728393555
Batch 18/64 loss: -2.01251220703125
Batch 19/64 loss: -1.957474708557129
Batch 20/64 loss: -1.988896369934082
Batch 21/64 loss: -1.772287368774414
Batch 22/64 loss: -1.8479156494140625
Batch 23/64 loss: -2.165691375732422
Batch 24/64 loss: -1.846888542175293
Batch 25/64 loss: -2.108755111694336
Batch 26/64 loss: -2.0631752014160156
Batch 27/64 loss: -2.1320571899414062
Batch 28/64 loss: -1.3576488494873047
Batch 29/64 loss: -2.0407495498657227
Batch 30/64 loss: -1.7552356719970703
Batch 31/64 loss: -1.192368507385254
Batch 32/64 loss: -2.271233558654785
Batch 33/64 loss: -1.9866046905517578
Batch 34/64 loss: -1.9787111282348633
Batch 35/64 loss: -2.1576528549194336
Batch 36/64 loss: -2.1694984436035156
Batch 37/64 loss: -2.175365447998047
Batch 38/64 loss: -2.2773122787475586
Batch 39/64 loss: -2.01389217376709
Batch 40/64 loss: -1.6387109756469727
Batch 41/64 loss: -1.8390207290649414
Batch 42/64 loss: -2.313055992126465
Batch 43/64 loss: -1.8357114791870117
Batch 44/64 loss: -1.9331979751586914
Batch 45/64 loss: -2.138063430786133
Batch 46/64 loss: -2.1499576568603516
Batch 47/64 loss: -2.061309814453125
Batch 48/64 loss: -1.9314661026000977
Batch 49/64 loss: -2.116969108581543
Batch 50/64 loss: -1.7694339752197266
Batch 51/64 loss: -2.3433837890625
Batch 52/64 loss: -2.1879005432128906
Batch 53/64 loss: -2.2226600646972656
Batch 54/64 loss: -2.1121082305908203
Batch 55/64 loss: -2.1936683654785156
Batch 56/64 loss: -2.0825767517089844
Batch 57/64 loss: -1.95794677734375
Batch 58/64 loss: -1.8928613662719727
Batch 59/64 loss: -2.128509521484375
Batch 60/64 loss: -2.178563117980957
Batch 61/64 loss: -1.7783021926879883
Batch 62/64 loss: -1.9904451370239258
Batch 63/64 loss: -1.5808820724487305
Batch 64/64 loss: -6.621102809906006
Epoch 108  Train loss: -2.0584824973461675  Val loss: -2.1648899878013586
Epoch 109
-------------------------------
Batch 1/64 loss: -2.05950927734375
Batch 2/64 loss: -1.2090167999267578
Batch 3/64 loss: -1.8642511367797852
Batch 4/64 loss: -2.1106481552124023
Batch 5/64 loss: -1.7306318283081055
Batch 6/64 loss: -1.9870386123657227
Batch 7/64 loss: -2.043463706970215
Batch 8/64 loss: -1.8576040267944336
Batch 9/64 loss: -2.1775808334350586
Batch 10/64 loss: -2.1467676162719727
Batch 11/64 loss: -2.1266584396362305
Batch 12/64 loss: -2.22933292388916
Batch 13/64 loss: -1.8643903732299805
Batch 14/64 loss: -1.7310247421264648
Batch 15/64 loss: -2.0406627655029297
Batch 16/64 loss: -1.799637794494629
Batch 17/64 loss: -2.2569046020507812
Batch 18/64 loss: -1.9629325866699219
Batch 19/64 loss: -1.915135383605957
Batch 20/64 loss: -2.3960533142089844
Batch 21/64 loss: -2.2186851501464844
Batch 22/64 loss: -1.3422698974609375
Batch 23/64 loss: -1.904311180114746
Batch 24/64 loss: -2.1241703033447266
Batch 25/64 loss: -2.1140565872192383
Batch 26/64 loss: -1.533935546875
Batch 27/64 loss: -2.126997947692871
Batch 28/64 loss: -2.34395694732666
Batch 29/64 loss: -2.233346939086914
Batch 30/64 loss: -1.9096088409423828
Batch 31/64 loss: -2.408823013305664
Batch 32/64 loss: -2.261159896850586
Batch 33/64 loss: -1.8143911361694336
Batch 34/64 loss: -1.879399299621582
Batch 35/64 loss: -2.0505552291870117
Batch 36/64 loss: -1.8823394775390625
Batch 37/64 loss: -2.154299736022949
Batch 38/64 loss: -2.0010414123535156
Batch 39/64 loss: -2.082639694213867
Batch 40/64 loss: -2.1181564331054688
Batch 41/64 loss: -1.9160776138305664
Batch 42/64 loss: -2.1758041381835938
Batch 43/64 loss: -2.066340446472168
Batch 44/64 loss: -1.9535608291625977
Batch 45/64 loss: -2.0307464599609375
Batch 46/64 loss: -2.002664566040039
Batch 47/64 loss: -1.5738105773925781
Batch 48/64 loss: -2.2096452713012695
Batch 49/64 loss: -2.4086217880249023
Batch 50/64 loss: -1.8885498046875
Batch 51/64 loss: -1.7956972122192383
Batch 52/64 loss: -2.017462730407715
Batch 53/64 loss: -1.6845998764038086
Batch 54/64 loss: -1.9827690124511719
Batch 55/64 loss: -2.4127883911132812
Batch 56/64 loss: -2.1724014282226562
Batch 57/64 loss: -1.442556381225586
Batch 58/64 loss: -2.000115394592285
Batch 59/64 loss: -2.1776885986328125
Batch 60/64 loss: -2.2385683059692383
Batch 61/64 loss: -1.9796390533447266
Batch 62/64 loss: -2.280488967895508
Batch 63/64 loss: -2.3232851028442383
Batch 64/64 loss: -6.222326278686523
Epoch 109  Train loss: -2.061396333283069  Val loss: -2.3099986859613266
Saving best model, epoch: 109
Epoch 110
-------------------------------
Batch 1/64 loss: -2.252194404602051
Batch 2/64 loss: -1.8929872512817383
Batch 3/64 loss: -2.0609560012817383
Batch 4/64 loss: -2.009990692138672
Batch 5/64 loss: -2.346898078918457
Batch 6/64 loss: -2.3978357315063477
Batch 7/64 loss: -2.2550840377807617
Batch 8/64 loss: -1.731379508972168
Batch 9/64 loss: -2.3814687728881836
Batch 10/64 loss: -2.104459762573242
Batch 11/64 loss: -2.086629867553711
Batch 12/64 loss: -1.9212322235107422
Batch 13/64 loss: -2.199380874633789
Batch 14/64 loss: -2.25331974029541
Batch 15/64 loss: -1.7702627182006836
Batch 16/64 loss: -2.3506526947021484
Batch 17/64 loss: -2.169841766357422
Batch 18/64 loss: -1.976405143737793
Batch 19/64 loss: -2.0417261123657227
Batch 20/64 loss: -2.0441627502441406
Batch 21/64 loss: -1.9794960021972656
Batch 22/64 loss: -2.077267646789551
Batch 23/64 loss: -2.3606033325195312
Batch 24/64 loss: -1.8899765014648438
Batch 25/64 loss: -2.073369026184082
Batch 26/64 loss: -2.311107635498047
Batch 27/64 loss: -2.059337615966797
Batch 28/64 loss: -2.4159955978393555
Batch 29/64 loss: -2.3109045028686523
Batch 30/64 loss: -1.904709815979004
Batch 31/64 loss: -2.2300405502319336
Batch 32/64 loss: -1.593562126159668
Batch 33/64 loss: -2.1302013397216797
Batch 34/64 loss: -1.9211320877075195
Batch 35/64 loss: -2.06166934967041
Batch 36/64 loss: -2.2330284118652344
Batch 37/64 loss: -1.9661149978637695
Batch 38/64 loss: -1.9271764755249023
Batch 39/64 loss: -1.8920574188232422
Batch 40/64 loss: -2.1265621185302734
Batch 41/64 loss: -1.9691267013549805
Batch 42/64 loss: -2.0266122817993164
Batch 43/64 loss: -1.8884563446044922
Batch 44/64 loss: -1.5981292724609375
Batch 45/64 loss: -1.8900423049926758
Batch 46/64 loss: -2.1720666885375977
Batch 47/64 loss: -2.2181434631347656
Batch 48/64 loss: -2.3598766326904297
Batch 49/64 loss: -2.16934871673584
Batch 50/64 loss: -2.1457691192626953
Batch 51/64 loss: -2.286473274230957
Batch 52/64 loss: -1.9727363586425781
Batch 53/64 loss: -1.8150310516357422
Batch 54/64 loss: -1.8144216537475586
Batch 55/64 loss: -2.164069175720215
Batch 56/64 loss: -2.228363037109375
Batch 57/64 loss: -2.1900177001953125
Batch 58/64 loss: -1.931595802307129
Batch 59/64 loss: -1.9872732162475586
Batch 60/64 loss: -2.267960548400879
Batch 61/64 loss: -1.8402862548828125
Batch 62/64 loss: -1.1975984573364258
Batch 63/64 loss: -2.186762809753418
Batch 64/64 loss: -6.355915546417236
Epoch 110  Train loss: -2.114482795490938  Val loss: -2.248460487811426
Epoch 111
-------------------------------
Batch 1/64 loss: -1.5229759216308594
Batch 2/64 loss: -2.0981884002685547
Batch 3/64 loss: -2.2526473999023438
Batch 4/64 loss: -2.356668472290039
Batch 5/64 loss: -2.097611427307129
Batch 6/64 loss: -1.9665031433105469
Batch 7/64 loss: -2.3264169692993164
Batch 8/64 loss: -2.0897178649902344
Batch 9/64 loss: -1.8663835525512695
Batch 10/64 loss: -1.7792129516601562
Batch 11/64 loss: -1.7164230346679688
Batch 12/64 loss: -2.1199417114257812
Batch 13/64 loss: -1.9236345291137695
Batch 14/64 loss: -1.9425621032714844
Batch 15/64 loss: -1.9764366149902344
Batch 16/64 loss: -1.8726205825805664
Batch 17/64 loss: -2.0717601776123047
Batch 18/64 loss: -2.050267219543457
Batch 19/64 loss: -2.2398452758789062
Batch 20/64 loss: -2.2829132080078125
Batch 21/64 loss: -2.176638603210449
Batch 22/64 loss: -2.278008460998535
Batch 23/64 loss: -1.9666528701782227
Batch 24/64 loss: -2.1565284729003906
Batch 25/64 loss: -2.133732795715332
Batch 26/64 loss: -1.8447742462158203
Batch 27/64 loss: -2.165121078491211
Batch 28/64 loss: -1.8358182907104492
Batch 29/64 loss: -2.1029272079467773
Batch 30/64 loss: -2.2706384658813477
Batch 31/64 loss: -2.0364370346069336
Batch 32/64 loss: -1.8656625747680664
Batch 33/64 loss: -1.9573535919189453
Batch 34/64 loss: -2.234299659729004
Batch 35/64 loss: -2.0805540084838867
Batch 36/64 loss: -2.2811079025268555
Batch 37/64 loss: -2.1707210540771484
Batch 38/64 loss: -2.1594724655151367
Batch 39/64 loss: -2.1177616119384766
Batch 40/64 loss: -2.0038414001464844
Batch 41/64 loss: -2.143683433532715
Batch 42/64 loss: -1.9945402145385742
Batch 43/64 loss: -2.251758575439453
Batch 44/64 loss: -2.419841766357422
Batch 45/64 loss: -2.1054763793945312
Batch 46/64 loss: -1.9618844985961914
Batch 47/64 loss: -2.249584197998047
Batch 48/64 loss: -2.027650833129883
Batch 49/64 loss: -1.8854093551635742
Batch 50/64 loss: -2.054553985595703
Batch 51/64 loss: -2.0076065063476562
Batch 52/64 loss: -1.883467674255371
Batch 53/64 loss: -2.051198959350586
Batch 54/64 loss: -2.2983312606811523
Batch 55/64 loss: -1.9770708084106445
Batch 56/64 loss: -2.0780858993530273
Batch 57/64 loss: -1.9172935485839844
Batch 58/64 loss: -2.3296022415161133
Batch 59/64 loss: -1.7121515274047852
Batch 60/64 loss: -1.9087553024291992
Batch 61/64 loss: -2.1927881240844727
Batch 62/64 loss: -2.1867523193359375
Batch 63/64 loss: -2.177156448364258
Batch 64/64 loss: -6.098153591156006
Epoch 111  Train loss: -2.1141810417175293  Val loss: -2.1964088125327197
Epoch 112
-------------------------------
Batch 1/64 loss: -2.0736074447631836
Batch 2/64 loss: -2.1359148025512695
Batch 3/64 loss: -2.213772773742676
Batch 4/64 loss: -2.1640548706054688
Batch 5/64 loss: -1.8562679290771484
Batch 6/64 loss: -1.9016094207763672
Batch 7/64 loss: -1.1797637939453125
Batch 8/64 loss: -2.2535171508789062
Batch 9/64 loss: -2.1169776916503906
Batch 10/64 loss: -2.3058366775512695
Batch 11/64 loss: -1.9178447723388672
Batch 12/64 loss: -2.176276206970215
Batch 13/64 loss: -1.9789094924926758
Batch 14/64 loss: -2.064427375793457
Batch 15/64 loss: -2.2289724349975586
Batch 16/64 loss: -1.96624755859375
Batch 17/64 loss: -2.3497047424316406
Batch 18/64 loss: -1.8380546569824219
Batch 19/64 loss: -2.1521072387695312
Batch 20/64 loss: -2.184568405151367
Batch 21/64 loss: -2.0257625579833984
Batch 22/64 loss: -2.0201539993286133
Batch 23/64 loss: -2.128544807434082
Batch 24/64 loss: -2.0376949310302734
Batch 25/64 loss: -1.788313865661621
Batch 26/64 loss: -2.32705020904541
Batch 27/64 loss: -2.06223201751709
Batch 28/64 loss: -1.6396751403808594
Batch 29/64 loss: -2.080005645751953
Batch 30/64 loss: -2.0318565368652344
Batch 31/64 loss: -2.2529211044311523
Batch 32/64 loss: -2.371823310852051
Batch 33/64 loss: -1.9108333587646484
Batch 34/64 loss: -1.6126794815063477
Batch 35/64 loss: -1.999495506286621
Batch 36/64 loss: -2.2185678482055664
Batch 37/64 loss: -2.1076221466064453
Batch 38/64 loss: -2.2083396911621094
Batch 39/64 loss: -1.6670246124267578
Batch 40/64 loss: -1.780202865600586
Batch 41/64 loss: -1.6548738479614258
Batch 42/64 loss: -2.3468408584594727
Batch 43/64 loss: -1.8496427536010742
Batch 44/64 loss: -2.254246711730957
Batch 45/64 loss: -1.5823183059692383
Batch 46/64 loss: -2.0996932983398438
Batch 47/64 loss: -2.199493408203125
Batch 48/64 loss: -2.187066078186035
Batch 49/64 loss: -2.351736068725586
Batch 50/64 loss: -2.2969799041748047
Batch 51/64 loss: -2.162867546081543
Batch 52/64 loss: -1.848912239074707
Batch 53/64 loss: -1.8032665252685547
Batch 54/64 loss: -1.9750795364379883
Batch 55/64 loss: -1.6792306900024414
Batch 56/64 loss: -2.0914249420166016
Batch 57/64 loss: -2.035149574279785
Batch 58/64 loss: -1.6492910385131836
Batch 59/64 loss: -2.00689697265625
Batch 60/64 loss: -1.9054012298583984
Batch 61/64 loss: -2.2805986404418945
Batch 62/64 loss: -2.1742162704467773
Batch 63/64 loss: -2.037053108215332
Batch 64/64 loss: -6.691993713378906
Epoch 112  Train loss: -2.0834589789895452  Val loss: -2.148512810775914
Epoch 113
-------------------------------
Batch 1/64 loss: -1.8615179061889648
Batch 2/64 loss: -1.9626598358154297
Batch 3/64 loss: -2.219766616821289
Batch 4/64 loss: -2.2270803451538086
Batch 5/64 loss: -2.031540870666504
Batch 6/64 loss: -2.100855827331543
Batch 7/64 loss: -2.3393821716308594
Batch 8/64 loss: -2.2773618698120117
Batch 9/64 loss: -1.7866735458374023
Batch 10/64 loss: -1.625828742980957
Batch 11/64 loss: -2.005906105041504
Batch 12/64 loss: -1.7917661666870117
Batch 13/64 loss: -1.8729009628295898
Batch 14/64 loss: -2.127730369567871
Batch 15/64 loss: -1.8216962814331055
Batch 16/64 loss: -2.348644256591797
Batch 17/64 loss: -2.2255783081054688
Batch 18/64 loss: -2.2111997604370117
Batch 19/64 loss: -1.9367656707763672
Batch 20/64 loss: -2.069188117980957
Batch 21/64 loss: -2.330996513366699
Batch 22/64 loss: -2.1216259002685547
Batch 23/64 loss: -2.249476432800293
Batch 24/64 loss: -2.1882553100585938
Batch 25/64 loss: -2.226801872253418
Batch 26/64 loss: -1.9025182723999023
Batch 27/64 loss: -2.2008838653564453
Batch 28/64 loss: -1.8594694137573242
Batch 29/64 loss: -1.7475042343139648
Batch 30/64 loss: -2.148984909057617
Batch 31/64 loss: -1.9179792404174805
Batch 32/64 loss: -1.0969314575195312
Batch 33/64 loss: -1.989426612854004
Batch 34/64 loss: -2.2438888549804688
Batch 35/64 loss: -2.1981000900268555
Batch 36/64 loss: -2.410773277282715
Batch 37/64 loss: -2.141874313354492
Batch 38/64 loss: -1.9331836700439453
Batch 39/64 loss: -2.1878175735473633
Batch 40/64 loss: -2.2458343505859375
Batch 41/64 loss: -2.293264389038086
Batch 42/64 loss: -1.9891796112060547
Batch 43/64 loss: -2.161147117614746
Batch 44/64 loss: -2.240215301513672
Batch 45/64 loss: -2.052750587463379
Batch 46/64 loss: -2.1151933670043945
Batch 47/64 loss: -1.9658164978027344
Batch 48/64 loss: -1.8834171295166016
Batch 49/64 loss: -1.9327144622802734
Batch 50/64 loss: -2.044590950012207
Batch 51/64 loss: -2.001514434814453
Batch 52/64 loss: -2.0555505752563477
Batch 53/64 loss: -2.250089645385742
Batch 54/64 loss: -2.080416679382324
Batch 55/64 loss: -2.054713249206543
Batch 56/64 loss: -2.16355037689209
Batch 57/64 loss: -1.8212718963623047
Batch 58/64 loss: -2.093756675720215
Batch 59/64 loss: -2.0940351486206055
Batch 60/64 loss: -2.068373680114746
Batch 61/64 loss: -2.3268728256225586
Batch 62/64 loss: -2.106165885925293
Batch 63/64 loss: -2.1882781982421875
Batch 64/64 loss: -6.42317008972168
Epoch 113  Train loss: -2.1174372729133157  Val loss: -2.088261764893417
Epoch 114
-------------------------------
Batch 1/64 loss: -2.323362350463867
Batch 2/64 loss: -2.4224987030029297
Batch 3/64 loss: -1.6585807800292969
Batch 4/64 loss: -2.1309547424316406
Batch 5/64 loss: -2.1024417877197266
Batch 6/64 loss: -2.089212417602539
Batch 7/64 loss: -1.6171884536743164
Batch 8/64 loss: -1.9092826843261719
Batch 9/64 loss: -1.8868818283081055
Batch 10/64 loss: -1.8778657913208008
Batch 11/64 loss: -1.871607780456543
Batch 12/64 loss: -1.908991813659668
Batch 13/64 loss: -2.147202491760254
Batch 14/64 loss: -1.9482803344726562
Batch 15/64 loss: -1.832077980041504
Batch 16/64 loss: -1.523585319519043
Batch 17/64 loss: -2.004157066345215
Batch 18/64 loss: -1.897247314453125
Batch 19/64 loss: -1.8730134963989258
Batch 20/64 loss: -2.1322078704833984
Batch 21/64 loss: -2.128689765930176
Batch 22/64 loss: -1.7401752471923828
Batch 23/64 loss: -2.1090707778930664
Batch 24/64 loss: -2.2546205520629883
Batch 25/64 loss: -1.921365737915039
Batch 26/64 loss: -1.8445587158203125
Batch 27/64 loss: -2.2418155670166016
Batch 28/64 loss: -1.845266342163086
Batch 29/64 loss: -1.602950096130371
Batch 30/64 loss: -2.0560436248779297
Batch 31/64 loss: -1.9335050582885742
Batch 32/64 loss: -1.5578994750976562
Batch 33/64 loss: -1.8022432327270508
Batch 34/64 loss: -1.8073301315307617
Batch 35/64 loss: -1.5263252258300781
Batch 36/64 loss: -1.811396598815918
Batch 37/64 loss: -2.0703163146972656
Batch 38/64 loss: -2.0453672409057617
Batch 39/64 loss: -2.2961578369140625
Batch 40/64 loss: -2.215142250061035
Batch 41/64 loss: -1.8978824615478516
Batch 42/64 loss: -2.003704071044922
Batch 43/64 loss: -2.19235897064209
Batch 44/64 loss: -2.0093231201171875
Batch 45/64 loss: -2.0755929946899414
Batch 46/64 loss: -2.1839723587036133
Batch 47/64 loss: -2.0113754272460938
Batch 48/64 loss: -2.333897590637207
Batch 49/64 loss: -2.114546775817871
Batch 50/64 loss: -1.9459753036499023
Batch 51/64 loss: -2.1398487091064453
Batch 52/64 loss: -2.0172653198242188
Batch 53/64 loss: -2.032883644104004
Batch 54/64 loss: -2.2755117416381836
Batch 55/64 loss: -2.185253143310547
Batch 56/64 loss: -2.2698869705200195
Batch 57/64 loss: -1.9060049057006836
Batch 58/64 loss: -1.7350807189941406
Batch 59/64 loss: -2.3568477630615234
Batch 60/64 loss: -1.8765344619750977
Batch 61/64 loss: -2.128920555114746
Batch 62/64 loss: -2.325596809387207
Batch 63/64 loss: -2.115823745727539
Batch 64/64 loss: -6.676371097564697
Epoch 114  Train loss: -2.0565999479854806  Val loss: -2.245473016168653
Epoch 115
-------------------------------
Batch 1/64 loss: -2.2483482360839844
Batch 2/64 loss: -2.1533546447753906
Batch 3/64 loss: -1.7415828704833984
Batch 4/64 loss: -2.28786563873291
Batch 5/64 loss: -2.229708671569824
Batch 6/64 loss: -2.1379623413085938
Batch 7/64 loss: -2.275179862976074
Batch 8/64 loss: -2.1921281814575195
Batch 9/64 loss: -2.1930408477783203
Batch 10/64 loss: -2.02701473236084
Batch 11/64 loss: -1.859842300415039
Batch 12/64 loss: -2.009845733642578
Batch 13/64 loss: -2.1437177658081055
Batch 14/64 loss: -1.933023452758789
Batch 15/64 loss: -2.2294387817382812
Batch 16/64 loss: -2.0843324661254883
Batch 17/64 loss: -1.9414710998535156
Batch 18/64 loss: -2.095470428466797
Batch 19/64 loss: -2.018312454223633
Batch 20/64 loss: -1.196791648864746
Batch 21/64 loss: -1.9590225219726562
Batch 22/64 loss: -1.709528923034668
Batch 23/64 loss: -1.7604951858520508
Batch 24/64 loss: -2.061553955078125
Batch 25/64 loss: -1.7932186126708984
Batch 26/64 loss: -2.0846023559570312
Batch 27/64 loss: -2.379915237426758
Batch 28/64 loss: -2.131138801574707
Batch 29/64 loss: -1.7737970352172852
Batch 30/64 loss: -2.0742111206054688
Batch 31/64 loss: -2.296619415283203
Batch 32/64 loss: -2.126768112182617
Batch 33/64 loss: -1.840378761291504
Batch 34/64 loss: -1.6666259765625
Batch 35/64 loss: -2.188192367553711
Batch 36/64 loss: -2.220292091369629
Batch 37/64 loss: -2.349400520324707
Batch 38/64 loss: -1.8330326080322266
Batch 39/64 loss: -2.1304826736450195
Batch 40/64 loss: -2.0109081268310547
Batch 41/64 loss: -2.114164352416992
Batch 42/64 loss: -2.0025062561035156
Batch 43/64 loss: -2.008424758911133
Batch 44/64 loss: -2.109921455383301
Batch 45/64 loss: -2.0788192749023438
Batch 46/64 loss: -2.402998924255371
Batch 47/64 loss: -1.8193273544311523
Batch 48/64 loss: -2.0610456466674805
Batch 49/64 loss: -2.128816604614258
Batch 50/64 loss: -1.483088493347168
Batch 51/64 loss: -1.9860191345214844
Batch 52/64 loss: -2.1546030044555664
Batch 53/64 loss: -2.289457321166992
Batch 54/64 loss: -2.2900447845458984
Batch 55/64 loss: -1.9434261322021484
Batch 56/64 loss: -2.074930191040039
Batch 57/64 loss: -1.9815788269042969
Batch 58/64 loss: -1.627798080444336
Batch 59/64 loss: -1.9491758346557617
Batch 60/64 loss: -1.693467140197754
Batch 61/64 loss: -1.9577856063842773
Batch 62/64 loss: -2.0786380767822266
Batch 63/64 loss: -2.111617088317871
Batch 64/64 loss: -6.192983627319336
Epoch 115  Train loss: -2.0765648411769493  Val loss: -2.148109881738617
Epoch 116
-------------------------------
Batch 1/64 loss: -2.1168899536132812
Batch 2/64 loss: -2.268342971801758
Batch 3/64 loss: -2.0195674896240234
Batch 4/64 loss: -2.1684141159057617
Batch 5/64 loss: -1.8098716735839844
Batch 6/64 loss: -2.213651657104492
Batch 7/64 loss: -2.375718116760254
Batch 8/64 loss: -1.662679672241211
Batch 9/64 loss: -2.044369697570801
Batch 10/64 loss: -2.0880002975463867
Batch 11/64 loss: -2.4441843032836914
Batch 12/64 loss: -1.9765558242797852
Batch 13/64 loss: -1.8572673797607422
Batch 14/64 loss: -2.320962905883789
Batch 15/64 loss: -2.1942920684814453
Batch 16/64 loss: -2.140676498413086
Batch 17/64 loss: -2.289888381958008
Batch 18/64 loss: -2.1135940551757812
Batch 19/64 loss: -2.0438547134399414
Batch 20/64 loss: -2.307917594909668
Batch 21/64 loss: -1.8468313217163086
Batch 22/64 loss: -2.113870620727539
Batch 23/64 loss: -2.0018224716186523
Batch 24/64 loss: -2.01265811920166
Batch 25/64 loss: -1.3667421340942383
Batch 26/64 loss: -1.4036359786987305
Batch 27/64 loss: -2.0801849365234375
Batch 28/64 loss: -2.1017866134643555
Batch 29/64 loss: -1.5168819427490234
Batch 30/64 loss: -2.0734357833862305
Batch 31/64 loss: -2.3932113647460938
Batch 32/64 loss: -2.180596351623535
Batch 33/64 loss: -2.421834945678711
Batch 34/64 loss: -2.3299856185913086
Batch 35/64 loss: -2.225454330444336
Batch 36/64 loss: -2.0769920349121094
Batch 37/64 loss: -2.208662986755371
Batch 38/64 loss: -2.328801155090332
Batch 39/64 loss: -2.187021255493164
Batch 40/64 loss: -2.1638917922973633
Batch 41/64 loss: -2.3462371826171875
Batch 42/64 loss: -1.8495969772338867
Batch 43/64 loss: -1.8933610916137695
Batch 44/64 loss: -2.037360191345215
Batch 45/64 loss: -2.207900047302246
Batch 46/64 loss: -2.2231578826904297
Batch 47/64 loss: -2.3239002227783203
Batch 48/64 loss: -2.1650352478027344
Batch 49/64 loss: -2.228274345397949
Batch 50/64 loss: -2.1785144805908203
Batch 51/64 loss: -2.2036218643188477
Batch 52/64 loss: -1.6207523345947266
Batch 53/64 loss: -1.4295759201049805
Batch 54/64 loss: -1.9188060760498047
Batch 55/64 loss: -2.10272216796875
Batch 56/64 loss: -2.1982765197753906
Batch 57/64 loss: -2.0983028411865234
Batch 58/64 loss: -2.268373489379883
Batch 59/64 loss: -1.998880386352539
Batch 60/64 loss: -2.1058616638183594
Batch 61/64 loss: -1.9301443099975586
Batch 62/64 loss: -2.1086950302124023
Batch 63/64 loss: -2.001493453979492
Batch 64/64 loss: -6.5069427490234375
Epoch 116  Train loss: -2.130353755576938  Val loss: -2.142218861792915
Epoch 117
-------------------------------
Batch 1/64 loss: -2.022714614868164
Batch 2/64 loss: -1.8473310470581055
Batch 3/64 loss: -1.870004653930664
Batch 4/64 loss: -2.4194555282592773
Batch 5/64 loss: -2.069117546081543
Batch 6/64 loss: -1.9744024276733398
Batch 7/64 loss: -2.0573387145996094
Batch 8/64 loss: -2.0288190841674805
Batch 9/64 loss: -1.871689796447754
Batch 10/64 loss: -1.5320329666137695
Batch 11/64 loss: -1.3393335342407227
Batch 12/64 loss: -2.2115964889526367
Batch 13/64 loss: -1.746725082397461
Batch 14/64 loss: -2.2001495361328125
Batch 15/64 loss: -1.6671075820922852
Batch 16/64 loss: -1.8913555145263672
Batch 17/64 loss: -2.0008974075317383
Batch 18/64 loss: -2.273683547973633
Batch 19/64 loss: -2.117830276489258
Batch 20/64 loss: -2.020846366882324
Batch 21/64 loss: -2.1906023025512695
Batch 22/64 loss: -1.7717962265014648
Batch 23/64 loss: -2.1361379623413086
Batch 24/64 loss: -1.1627740859985352
Batch 25/64 loss: -1.6703109741210938
Batch 26/64 loss: -1.9702816009521484
Batch 27/64 loss: -2.2048778533935547
Batch 28/64 loss: -1.9537248611450195
Batch 29/64 loss: -2.129863739013672
Batch 30/64 loss: -1.7855463027954102
Batch 31/64 loss: -1.6950578689575195
Batch 32/64 loss: -1.8423728942871094
Batch 33/64 loss: -1.7265167236328125
Batch 34/64 loss: -2.1083946228027344
Batch 35/64 loss: -1.930058479309082
Batch 36/64 loss: -1.637380599975586
Batch 37/64 loss: -2.129673957824707
Batch 38/64 loss: -1.8337974548339844
Batch 39/64 loss: -2.1984405517578125
Batch 40/64 loss: -2.0421581268310547
Batch 41/64 loss: -1.858902931213379
Batch 42/64 loss: -2.116455078125
Batch 43/64 loss: -1.7573070526123047
Batch 44/64 loss: -2.102025032043457
Batch 45/64 loss: -2.291092872619629
Batch 46/64 loss: -1.7103033065795898
Batch 47/64 loss: -2.0834035873413086
Batch 48/64 loss: -1.9284439086914062
Batch 49/64 loss: -1.671736717224121
Batch 50/64 loss: -2.0684213638305664
Batch 51/64 loss: -2.111273765563965
Batch 52/64 loss: -1.9367313385009766
Batch 53/64 loss: -2.1190004348754883
Batch 54/64 loss: -2.105867385864258
Batch 55/64 loss: -2.2468690872192383
Batch 56/64 loss: -1.9573278427124023
Batch 57/64 loss: -2.0298662185668945
Batch 58/64 loss: -1.878617286682129
Batch 59/64 loss: -2.0685901641845703
Batch 60/64 loss: -1.7948646545410156
Batch 61/64 loss: -1.9626903533935547
Batch 62/64 loss: -1.6642303466796875
Batch 63/64 loss: -1.927022933959961
Batch 64/64 loss: -6.562965393066406
Epoch 117  Train loss: -2.0014975155101102  Val loss: -2.074889586143887
Epoch 118
-------------------------------
Batch 1/64 loss: -1.8192024230957031
Batch 2/64 loss: -2.192938804626465
Batch 3/64 loss: -2.2337799072265625
Batch 4/64 loss: -2.029252052307129
Batch 5/64 loss: -2.160612106323242
Batch 6/64 loss: -1.9725427627563477
Batch 7/64 loss: -1.8493213653564453
Batch 8/64 loss: -1.97723388671875
Batch 9/64 loss: -2.044386863708496
Batch 10/64 loss: -1.9999465942382812
Batch 11/64 loss: -2.284648895263672
Batch 12/64 loss: -2.0438709259033203
Batch 13/64 loss: -2.0708274841308594
Batch 14/64 loss: -2.15289306640625
Batch 15/64 loss: -2.229673385620117
Batch 16/64 loss: -2.1191911697387695
Batch 17/64 loss: -2.2834339141845703
Batch 18/64 loss: -1.7828826904296875
Batch 19/64 loss: -2.107468605041504
Batch 20/64 loss: -1.6261367797851562
Batch 21/64 loss: -1.8038969039916992
Batch 22/64 loss: -1.946725845336914
Batch 23/64 loss: -2.194337844848633
Batch 24/64 loss: -2.1841068267822266
Batch 25/64 loss: -2.014200210571289
Batch 26/64 loss: -1.2301206588745117
Batch 27/64 loss: -2.1241493225097656
Batch 28/64 loss: -1.9870576858520508
Batch 29/64 loss: -2.2788286209106445
Batch 30/64 loss: -1.7873773574829102
Batch 31/64 loss: -2.196213722229004
Batch 32/64 loss: -2.1468000411987305
Batch 33/64 loss: -2.0705442428588867
Batch 34/64 loss: -1.8988542556762695
Batch 35/64 loss: -2.3872756958007812
Batch 36/64 loss: -1.690835952758789
Batch 37/64 loss: -1.9696855545043945
Batch 38/64 loss: -2.03389835357666
Batch 39/64 loss: -2.061345100402832
Batch 40/64 loss: -2.1064510345458984
Batch 41/64 loss: -1.9712486267089844
Batch 42/64 loss: -2.255812644958496
Batch 43/64 loss: -1.8268318176269531
Batch 44/64 loss: -2.0330467224121094
Batch 45/64 loss: -1.726832389831543
Batch 46/64 loss: -2.1814260482788086
Batch 47/64 loss: -1.3835458755493164
Batch 48/64 loss: -2.027963638305664
Batch 49/64 loss: -2.153803825378418
Batch 50/64 loss: -2.0687198638916016
Batch 51/64 loss: -2.016773223876953
Batch 52/64 loss: -2.0571985244750977
Batch 53/64 loss: -1.5816097259521484
Batch 54/64 loss: -2.1112136840820312
Batch 55/64 loss: -1.8007316589355469
Batch 56/64 loss: -2.265544891357422
Batch 57/64 loss: -1.870335578918457
Batch 58/64 loss: -2.0165319442749023
Batch 59/64 loss: -1.7747468948364258
Batch 60/64 loss: -1.8795661926269531
Batch 61/64 loss: -1.7346792221069336
Batch 62/64 loss: -1.8354063034057617
Batch 63/64 loss: -1.602560043334961
Batch 64/64 loss: -6.357027053833008
Epoch 118  Train loss: -2.0397937026678346  Val loss: -2.1661106909263586
Epoch 119
-------------------------------
Batch 1/64 loss: -1.3042335510253906
Batch 2/64 loss: -1.7467317581176758
Batch 3/64 loss: -1.8880138397216797
Batch 4/64 loss: -1.7786731719970703
Batch 5/64 loss: -2.103419303894043
Batch 6/64 loss: -2.1571617126464844
Batch 7/64 loss: -1.9198236465454102
Batch 8/64 loss: -2.0081186294555664
Batch 9/64 loss: -1.7857961654663086
Batch 10/64 loss: -1.6621456146240234
Batch 11/64 loss: -1.948868751525879
Batch 12/64 loss: -1.9687366485595703
Batch 13/64 loss: -1.8153772354125977
Batch 14/64 loss: -2.0613393783569336
Batch 15/64 loss: -2.089601516723633
Batch 16/64 loss: -2.1883773803710938
Batch 17/64 loss: -1.6737308502197266
Batch 18/64 loss: -1.9362640380859375
Batch 19/64 loss: -2.240447998046875
Batch 20/64 loss: -1.4333925247192383
Batch 21/64 loss: -2.142073631286621
Batch 22/64 loss: -2.04654598236084
Batch 23/64 loss: -2.1327171325683594
Batch 24/64 loss: -2.1467952728271484
Batch 25/64 loss: -2.1373815536499023
Batch 26/64 loss: -2.175105094909668
Batch 27/64 loss: -2.1518850326538086
Batch 28/64 loss: -2.324148178100586
Batch 29/64 loss: -2.2330923080444336
Batch 30/64 loss: -1.9341773986816406
Batch 31/64 loss: -1.6477470397949219
Batch 32/64 loss: -1.6919269561767578
Batch 33/64 loss: -1.9954519271850586
Batch 34/64 loss: -1.7678098678588867
Batch 35/64 loss: -2.218722343444824
Batch 36/64 loss: -2.291074752807617
Batch 37/64 loss: -2.0377941131591797
Batch 38/64 loss: -2.2548599243164062
Batch 39/64 loss: -2.067150115966797
Batch 40/64 loss: -1.736983299255371
Batch 41/64 loss: -2.0482606887817383
Batch 42/64 loss: -2.3091135025024414
Batch 43/64 loss: -2.238755226135254
Batch 44/64 loss: -1.9272441864013672
Batch 45/64 loss: -1.877791404724121
Batch 46/64 loss: -2.1866064071655273
Batch 47/64 loss: -2.2733535766601562
Batch 48/64 loss: -1.839223861694336
Batch 49/64 loss: -2.110264778137207
Batch 50/64 loss: -1.8490772247314453
Batch 51/64 loss: -1.8914270401000977
Batch 52/64 loss: -1.8581819534301758
Batch 53/64 loss: -2.1334447860717773
Batch 54/64 loss: -2.26138973236084
Batch 55/64 loss: -2.0813074111938477
Batch 56/64 loss: -1.886077880859375
Batch 57/64 loss: -2.0254526138305664
Batch 58/64 loss: -2.0511045455932617
Batch 59/64 loss: -2.071622848510742
Batch 60/64 loss: -2.268528938293457
Batch 61/64 loss: -2.2129154205322266
Batch 62/64 loss: -2.191891670227051
Batch 63/64 loss: -2.179762840270996
Batch 64/64 loss: -6.502326011657715
Epoch 119  Train loss: -2.0626390382355333  Val loss: -2.2153179129374396
Epoch 120
-------------------------------
Batch 1/64 loss: -2.0901193618774414
Batch 2/64 loss: -1.9878044128417969
Batch 3/64 loss: -2.140194892883301
Batch 4/64 loss: -1.772705078125
Batch 5/64 loss: -2.2915878295898438
Batch 6/64 loss: -1.904555320739746
Batch 7/64 loss: -1.9606523513793945
Batch 8/64 loss: -2.296542167663574
Batch 9/64 loss: -2.352969169616699
Batch 10/64 loss: -2.309978485107422
Batch 11/64 loss: -1.9427518844604492
Batch 12/64 loss: -2.5122976303100586
Batch 13/64 loss: -1.7509031295776367
Batch 14/64 loss: -2.2038497924804688
Batch 15/64 loss: -1.9605340957641602
Batch 16/64 loss: -2.1001453399658203
Batch 17/64 loss: -2.3830747604370117
Batch 18/64 loss: -1.8249855041503906
Batch 19/64 loss: -2.1933975219726562
Batch 20/64 loss: -2.1031723022460938
Batch 21/64 loss: -1.976679801940918
Batch 22/64 loss: -1.8626127243041992
Batch 23/64 loss: -2.2536354064941406
Batch 24/64 loss: -2.078855514526367
Batch 25/64 loss: -2.2434797286987305
Batch 26/64 loss: -2.091747283935547
Batch 27/64 loss: -1.734461784362793
Batch 28/64 loss: -2.135408401489258
Batch 29/64 loss: -2.2770509719848633
Batch 30/64 loss: -1.9597625732421875
Batch 31/64 loss: -1.9558210372924805
Batch 32/64 loss: -1.673274040222168
Batch 33/64 loss: -2.0853986740112305
Batch 34/64 loss: -2.0761232376098633
Batch 35/64 loss: -1.4213972091674805
Batch 36/64 loss: -1.7403545379638672
Batch 37/64 loss: -2.1651535034179688
Batch 38/64 loss: -2.0131959915161133
Batch 39/64 loss: -1.644597053527832
Batch 40/64 loss: -2.13555908203125
Batch 41/64 loss: -1.8841218948364258
Batch 42/64 loss: -1.8249187469482422
Batch 43/64 loss: -2.236461639404297
Batch 44/64 loss: -2.3434715270996094
Batch 45/64 loss: -2.269383430480957
Batch 46/64 loss: -1.9971637725830078
Batch 47/64 loss: -1.884373664855957
Batch 48/64 loss: -1.9269447326660156
Batch 49/64 loss: -2.031435966491699
Batch 50/64 loss: -2.1825122833251953
Batch 51/64 loss: -1.9995088577270508
Batch 52/64 loss: -2.219694137573242
Batch 53/64 loss: -2.2801218032836914
Batch 54/64 loss: -2.2298974990844727
Batch 55/64 loss: -2.041646957397461
Batch 56/64 loss: -2.0009517669677734
Batch 57/64 loss: -2.134018898010254
Batch 58/64 loss: -2.2115859985351562
Batch 59/64 loss: -2.2286033630371094
Batch 60/64 loss: -1.9496746063232422
Batch 61/64 loss: -2.2395591735839844
Batch 62/64 loss: -2.0551090240478516
Batch 63/64 loss: -2.323423385620117
Batch 64/64 loss: -6.496463775634766
Epoch 120  Train loss: -2.117234832165288  Val loss: -2.1877041715117254
Epoch 121
-------------------------------
Batch 1/64 loss: -2.0760860443115234
Batch 2/64 loss: -1.6292991638183594
Batch 3/64 loss: -2.1757469177246094
Batch 4/64 loss: -2.0895156860351562
Batch 5/64 loss: -2.117776870727539
Batch 6/64 loss: -2.200021743774414
Batch 7/64 loss: -2.0583114624023438
Batch 8/64 loss: -1.8400487899780273
Batch 9/64 loss: -1.8780698776245117
Batch 10/64 loss: -1.8001184463500977
Batch 11/64 loss: -2.06101131439209
Batch 12/64 loss: -2.0088748931884766
Batch 13/64 loss: -2.191864013671875
Batch 14/64 loss: -2.4562292098999023
Batch 15/64 loss: -2.286336898803711
Batch 16/64 loss: -2.0481204986572266
Batch 17/64 loss: -2.245762825012207
Batch 18/64 loss: -2.1889657974243164
Batch 19/64 loss: -2.0676841735839844
Batch 20/64 loss: -2.3029098510742188
Batch 21/64 loss: -2.1216020584106445
Batch 22/64 loss: -2.3174734115600586
Batch 23/64 loss: -2.2386045455932617
Batch 24/64 loss: -2.1195926666259766
Batch 25/64 loss: -2.237502098083496
Batch 26/64 loss: -2.1321964263916016
Batch 27/64 loss: -1.9709720611572266
Batch 28/64 loss: -2.239818572998047
Batch 29/64 loss: -2.401010513305664
Batch 30/64 loss: -1.8090763092041016
Batch 31/64 loss: -1.8262748718261719
Batch 32/64 loss: -2.310426712036133
Batch 33/64 loss: -2.088623046875
Batch 34/64 loss: -2.212818145751953
Batch 35/64 loss: -1.9008922576904297
Batch 36/64 loss: -2.1670827865600586
Batch 37/64 loss: -1.984689712524414
Batch 38/64 loss: -1.8343067169189453
Batch 39/64 loss: -1.6038713455200195
Batch 40/64 loss: -2.43801212310791
Batch 41/64 loss: -2.2583322525024414
Batch 42/64 loss: -2.336162567138672
Batch 43/64 loss: -2.4237594604492188
Batch 44/64 loss: -2.097823143005371
Batch 45/64 loss: -2.22189998626709
Batch 46/64 loss: -2.3651723861694336
Batch 47/64 loss: -2.309187889099121
Batch 48/64 loss: -2.394376754760742
Batch 49/64 loss: -2.3845062255859375
Batch 50/64 loss: -2.1359853744506836
Batch 51/64 loss: -2.25313663482666
Batch 52/64 loss: -2.271240234375
Batch 53/64 loss: -2.089101791381836
Batch 54/64 loss: -1.767965316772461
Batch 55/64 loss: -2.0017051696777344
Batch 56/64 loss: -1.5637445449829102
Batch 57/64 loss: -1.9319257736206055
Batch 58/64 loss: -1.9284400939941406
Batch 59/64 loss: -2.1100635528564453
Batch 60/64 loss: -2.0407819747924805
Batch 61/64 loss: -2.0728940963745117
Batch 62/64 loss: -2.127322196960449
Batch 63/64 loss: -2.071044921875
Batch 64/64 loss: -6.626509666442871
Epoch 121  Train loss: -2.1616322423897536  Val loss: -2.175653752592421
Epoch 122
-------------------------------
Batch 1/64 loss: -2.006275177001953
Batch 2/64 loss: -1.6277532577514648
Batch 3/64 loss: -2.277268409729004
Batch 4/64 loss: -2.1735916137695312
Batch 5/64 loss: -2.4791908264160156
Batch 6/64 loss: -1.9343080520629883
Batch 7/64 loss: -2.013932228088379
Batch 8/64 loss: -2.0297040939331055
Batch 9/64 loss: -2.0879945755004883
Batch 10/64 loss: -2.1900386810302734
Batch 11/64 loss: -2.023989677429199
Batch 12/64 loss: -2.1733951568603516
Batch 13/64 loss: -2.146146774291992
Batch 14/64 loss: -1.8951530456542969
Batch 15/64 loss: -1.9947195053100586
Batch 16/64 loss: -1.8259010314941406
Batch 17/64 loss: -2.038943290710449
Batch 18/64 loss: -1.9338855743408203
Batch 19/64 loss: -1.9940366744995117
Batch 20/64 loss: -2.2758960723876953
Batch 21/64 loss: -2.111387252807617
Batch 22/64 loss: -2.005117416381836
Batch 23/64 loss: -1.7661828994750977
Batch 24/64 loss: -2.387157440185547
Batch 25/64 loss: -2.310647964477539
Batch 26/64 loss: -2.139890670776367
Batch 27/64 loss: -2.0777721405029297
Batch 28/64 loss: -2.3001623153686523
Batch 29/64 loss: -1.8979673385620117
Batch 30/64 loss: -2.41794490814209
Batch 31/64 loss: -2.1965274810791016
Batch 32/64 loss: -2.0978260040283203
Batch 33/64 loss: -2.051126480102539
Batch 34/64 loss: -1.8613710403442383
Batch 35/64 loss: -1.7120637893676758
Batch 36/64 loss: -2.0333261489868164
Batch 37/64 loss: -2.1148176193237305
Batch 38/64 loss: -2.1705875396728516
Batch 39/64 loss: -1.8847122192382812
Batch 40/64 loss: -2.1439571380615234
Batch 41/64 loss: -2.1368179321289062
Batch 42/64 loss: -2.1453609466552734
Batch 43/64 loss: -1.9276657104492188
Batch 44/64 loss: -1.9196281433105469
Batch 45/64 loss: -2.1847667694091797
Batch 46/64 loss: -2.183382987976074
Batch 47/64 loss: -2.173969268798828
Batch 48/64 loss: -1.9862890243530273
Batch 49/64 loss: -1.9073266983032227
Batch 50/64 loss: -1.9932222366333008
Batch 51/64 loss: -2.0705137252807617
Batch 52/64 loss: -2.2791147232055664
Batch 53/64 loss: -2.1385135650634766
Batch 54/64 loss: -2.2502593994140625
Batch 55/64 loss: -2.3095579147338867
Batch 56/64 loss: -1.7007265090942383
Batch 57/64 loss: -2.3446197509765625
Batch 58/64 loss: -2.1467933654785156
Batch 59/64 loss: -2.0518484115600586
Batch 60/64 loss: -1.9432640075683594
Batch 61/64 loss: -2.3729400634765625
Batch 62/64 loss: -2.353146553039551
Batch 63/64 loss: -1.8073415756225586
Batch 64/64 loss: -6.580890655517578
Epoch 122  Train loss: -2.134359322342218  Val loss: -2.249740574368087
Epoch 123
-------------------------------
Batch 1/64 loss: -2.1157283782958984
Batch 2/64 loss: -2.327493667602539
Batch 3/64 loss: -2.286871910095215
Batch 4/64 loss: -1.7706708908081055
Batch 5/64 loss: -1.8543272018432617
Batch 6/64 loss: -2.3557815551757812
Batch 7/64 loss: -2.3361997604370117
Batch 8/64 loss: -2.0849008560180664
Batch 9/64 loss: -2.139507293701172
Batch 10/64 loss: -2.017899513244629
Batch 11/64 loss: -2.1366968154907227
Batch 12/64 loss: -2.166810989379883
Batch 13/64 loss: -2.193462371826172
Batch 14/64 loss: -2.271696090698242
Batch 15/64 loss: -2.1354799270629883
Batch 16/64 loss: -2.301266670227051
Batch 17/64 loss: -2.1171913146972656
Batch 18/64 loss: -2.237624168395996
Batch 19/64 loss: -1.8599376678466797
Batch 20/64 loss: -2.1422243118286133
Batch 21/64 loss: -2.170638084411621
Batch 22/64 loss: -1.7226552963256836
Batch 23/64 loss: -1.9055414199829102
Batch 24/64 loss: -2.251214027404785
Batch 25/64 loss: -2.3684463500976562
Batch 26/64 loss: -2.043241500854492
Batch 27/64 loss: -2.214756965637207
Batch 28/64 loss: -1.8124933242797852
Batch 29/64 loss: -2.3601207733154297
Batch 30/64 loss: -2.354525566101074
Batch 31/64 loss: -2.0383081436157227
Batch 32/64 loss: -2.288466453552246
Batch 33/64 loss: -2.3248376846313477
Batch 34/64 loss: -1.9622116088867188
Batch 35/64 loss: -2.1660079956054688
Batch 36/64 loss: -2.278057098388672
Batch 37/64 loss: -1.9565744400024414
Batch 38/64 loss: -2.230318069458008
Batch 39/64 loss: -2.131776809692383
Batch 40/64 loss: -1.8609447479248047
Batch 41/64 loss: -2.145780563354492
Batch 42/64 loss: -2.0302906036376953
Batch 43/64 loss: -2.3639984130859375
Batch 44/64 loss: -2.191617965698242
Batch 45/64 loss: -2.1137399673461914
Batch 46/64 loss: -2.1444482803344727
Batch 47/64 loss: -1.4476194381713867
Batch 48/64 loss: -1.855668067932129
Batch 49/64 loss: -1.9359922409057617
Batch 50/64 loss: -2.251763343811035
Batch 51/64 loss: -2.3311567306518555
Batch 52/64 loss: -2.2306365966796875
Batch 53/64 loss: -2.082630157470703
Batch 54/64 loss: -2.271204948425293
Batch 55/64 loss: -2.170414924621582
Batch 56/64 loss: -2.4977312088012695
Batch 57/64 loss: -1.9864082336425781
Batch 58/64 loss: -2.2693777084350586
Batch 59/64 loss: -1.868168830871582
Batch 60/64 loss: -2.1246414184570312
Batch 61/64 loss: -2.2718429565429688
Batch 62/64 loss: -2.3439016342163086
Batch 63/64 loss: -2.1379613876342773
Batch 64/64 loss: -6.234959602355957
Epoch 123  Train loss: -2.180958792742561  Val loss: -2.319884362499329
Saving best model, epoch: 123
Epoch 124
-------------------------------
Batch 1/64 loss: -1.9965038299560547
Batch 2/64 loss: -2.4619665145874023
Batch 3/64 loss: -2.2933835983276367
Batch 4/64 loss: -1.8514528274536133
Batch 5/64 loss: -2.305438995361328
Batch 6/64 loss: -2.2093725204467773
Batch 7/64 loss: -2.14847469329834
Batch 8/64 loss: -2.139284133911133
Batch 9/64 loss: -1.8685312271118164
Batch 10/64 loss: -2.305978775024414
Batch 11/64 loss: -2.163330078125
Batch 12/64 loss: -2.361339569091797
Batch 13/64 loss: -1.9388065338134766
Batch 14/64 loss: -2.2404727935791016
Batch 15/64 loss: -2.3811302185058594
Batch 16/64 loss: -2.3207483291625977
Batch 17/64 loss: -1.8526334762573242
Batch 18/64 loss: -2.4059810638427734
Batch 19/64 loss: -2.1739978790283203
Batch 20/64 loss: -2.214961051940918
Batch 21/64 loss: -2.189530372619629
Batch 22/64 loss: -2.3008174896240234
Batch 23/64 loss: -2.009303092956543
Batch 24/64 loss: -1.8401479721069336
Batch 25/64 loss: -2.267777442932129
Batch 26/64 loss: -1.8129758834838867
Batch 27/64 loss: -2.272454261779785
Batch 28/64 loss: -2.374849319458008
Batch 29/64 loss: -2.1014413833618164
Batch 30/64 loss: -2.099475860595703
Batch 31/64 loss: -2.1903457641601562
Batch 32/64 loss: -2.2826614379882812
Batch 33/64 loss: -2.212183952331543
Batch 34/64 loss: -2.3293237686157227
Batch 35/64 loss: -2.1636714935302734
Batch 36/64 loss: -2.346057891845703
Batch 37/64 loss: -1.9247627258300781
Batch 38/64 loss: -1.9072837829589844
Batch 39/64 loss: -2.218944549560547
Batch 40/64 loss: -2.366511344909668
Batch 41/64 loss: -2.2576990127563477
Batch 42/64 loss: -2.124826431274414
Batch 43/64 loss: -2.2415199279785156
Batch 44/64 loss: -2.1471424102783203
Batch 45/64 loss: -2.3279170989990234
Batch 46/64 loss: -2.123056411743164
Batch 47/64 loss: -2.251485824584961
Batch 48/64 loss: -2.3735647201538086
Batch 49/64 loss: -2.309619903564453
Batch 50/64 loss: -2.2289180755615234
Batch 51/64 loss: -2.231212615966797
Batch 52/64 loss: -1.4315853118896484
Batch 53/64 loss: -1.9370574951171875
Batch 54/64 loss: -1.7549333572387695
Batch 55/64 loss: -2.337977409362793
Batch 56/64 loss: -2.2390565872192383
Batch 57/64 loss: -1.966496467590332
Batch 58/64 loss: -2.371805191040039
Batch 59/64 loss: -1.9541282653808594
Batch 60/64 loss: -2.1383867263793945
Batch 61/64 loss: -2.2575578689575195
Batch 62/64 loss: -2.0115718841552734
Batch 63/64 loss: -2.2020950317382812
Batch 64/64 loss: -6.85869836807251
Epoch 124  Train loss: -2.2150265992856495  Val loss: -2.161248682290828
Epoch 125
-------------------------------
Batch 1/64 loss: -2.328213691711426
Batch 2/64 loss: -2.1583852767944336
Batch 3/64 loss: -1.8928861618041992
Batch 4/64 loss: -2.116684913635254
Batch 5/64 loss: -2.3093223571777344
Batch 6/64 loss: -1.6435003280639648
Batch 7/64 loss: -2.0535850524902344
Batch 8/64 loss: -2.4399824142456055
Batch 9/64 loss: -1.865987777709961
Batch 10/64 loss: -1.7465076446533203
Batch 11/64 loss: -2.110078811645508
Batch 12/64 loss: -2.0570545196533203
Batch 13/64 loss: -2.1946792602539062
Batch 14/64 loss: -1.6592531204223633
Batch 15/64 loss: -2.0348920822143555
Batch 16/64 loss: -2.283574104309082
Batch 17/64 loss: -2.052863121032715
Batch 18/64 loss: -2.0041675567626953
Batch 19/64 loss: -2.224850654602051
Batch 20/64 loss: -2.032939910888672
Batch 21/64 loss: -2.0283374786376953
Batch 22/64 loss: -1.9233417510986328
Batch 23/64 loss: -2.188246726989746
Batch 24/64 loss: -2.3538436889648438
Batch 25/64 loss: -2.2796554565429688
Batch 26/64 loss: -2.1099748611450195
Batch 27/64 loss: -2.076474189758301
Batch 28/64 loss: -1.9540767669677734
Batch 29/64 loss: -2.414388656616211
Batch 30/64 loss: -2.1967172622680664
Batch 31/64 loss: -2.1895933151245117
Batch 32/64 loss: -1.8201398849487305
Batch 33/64 loss: -1.9837150573730469
Batch 34/64 loss: -2.3358469009399414
Batch 35/64 loss: -2.0594215393066406
Batch 36/64 loss: -2.165599822998047
Batch 37/64 loss: -2.249070167541504
Batch 38/64 loss: -2.381988525390625
Batch 39/64 loss: -2.128599166870117
Batch 40/64 loss: -1.9101371765136719
Batch 41/64 loss: -1.8850736618041992
Batch 42/64 loss: -2.416921615600586
Batch 43/64 loss: -1.852869987487793
Batch 44/64 loss: -1.4174747467041016
Batch 45/64 loss: -2.3045854568481445
Batch 46/64 loss: -1.5098142623901367
Batch 47/64 loss: -2.4269533157348633
Batch 48/64 loss: -2.2424211502075195
Batch 49/64 loss: -2.0837831497192383
Batch 50/64 loss: -2.12677001953125
Batch 51/64 loss: -2.025693893432617
Batch 52/64 loss: -1.8240385055541992
Batch 53/64 loss: -2.082122802734375
Batch 54/64 loss: -2.055130958557129
Batch 55/64 loss: -2.181699752807617
Batch 56/64 loss: -1.9628257751464844
Batch 57/64 loss: -2.430124282836914
Batch 58/64 loss: -2.0148515701293945
Batch 59/64 loss: -2.260099411010742
Batch 60/64 loss: -2.294656753540039
Batch 61/64 loss: -2.0999317169189453
Batch 62/64 loss: -2.0403671264648438
Batch 63/64 loss: -1.8463630676269531
Batch 64/64 loss: -6.618777275085449
Epoch 125  Train loss: -2.138152676002652  Val loss: -2.1396514525528216
Epoch 126
-------------------------------
Batch 1/64 loss: -2.389270782470703
Batch 2/64 loss: -1.9716672897338867
Batch 3/64 loss: -1.8655834197998047
Batch 4/64 loss: -2.2340869903564453
Batch 5/64 loss: -2.0538291931152344
Batch 6/64 loss: -1.8522815704345703
Batch 7/64 loss: -2.315855026245117
Batch 8/64 loss: -2.080354690551758
Batch 9/64 loss: -1.921422004699707
Batch 10/64 loss: -1.7705154418945312
Batch 11/64 loss: -2.1405582427978516
Batch 12/64 loss: -2.081376075744629
Batch 13/64 loss: -2.0324602127075195
Batch 14/64 loss: -2.467243194580078
Batch 15/64 loss: -1.635146141052246
Batch 16/64 loss: -1.9292497634887695
Batch 17/64 loss: -1.8851890563964844
Batch 18/64 loss: -2.154848098754883
Batch 19/64 loss: -1.6928958892822266
Batch 20/64 loss: -2.2421674728393555
Batch 21/64 loss: -2.134669303894043
Batch 22/64 loss: -2.1287364959716797
Batch 23/64 loss: -2.1955127716064453
Batch 24/64 loss: -1.8978710174560547
Batch 25/64 loss: -1.9733638763427734
Batch 26/64 loss: -2.456662178039551
Batch 27/64 loss: -2.3173751831054688
Batch 28/64 loss: -2.204679489135742
Batch 29/64 loss: -1.721024513244629
Batch 30/64 loss: -1.781484603881836
Batch 31/64 loss: -2.041872978210449
Batch 32/64 loss: -2.307708740234375
Batch 33/64 loss: -2.4387550354003906
Batch 34/64 loss: -1.9558124542236328
Batch 35/64 loss: -2.277276039123535
Batch 36/64 loss: -2.4857749938964844
Batch 37/64 loss: -2.1281938552856445
Batch 38/64 loss: -1.9747953414916992
Batch 39/64 loss: -2.1567506790161133
Batch 40/64 loss: -2.381162643432617
Batch 41/64 loss: -1.9512834548950195
Batch 42/64 loss: -2.280416488647461
Batch 43/64 loss: -1.8264455795288086
Batch 44/64 loss: -2.1638717651367188
Batch 45/64 loss: -2.2617626190185547
Batch 46/64 loss: -1.6279821395874023
Batch 47/64 loss: -2.135517120361328
Batch 48/64 loss: -2.3572044372558594
Batch 49/64 loss: -2.107320785522461
Batch 50/64 loss: -2.321950912475586
Batch 51/64 loss: -1.8133773803710938
Batch 52/64 loss: -2.427206039428711
Batch 53/64 loss: -2.082974433898926
Batch 54/64 loss: -2.0788393020629883
Batch 55/64 loss: -2.065196990966797
Batch 56/64 loss: -2.3566675186157227
Batch 57/64 loss: -2.1982879638671875
Batch 58/64 loss: -2.2556400299072266
Batch 59/64 loss: -2.339240074157715
Batch 60/64 loss: -2.244168281555176
Batch 61/64 loss: -2.251418113708496
Batch 62/64 loss: -2.174468994140625
Batch 63/64 loss: -2.2521820068359375
Batch 64/64 loss: -6.765746116638184
Epoch 126  Train loss: -2.1697759179507985  Val loss: -2.4944605089954495
Saving best model, epoch: 126
Epoch 127
-------------------------------
Batch 1/64 loss: -2.3030128479003906
Batch 2/64 loss: -2.278140068054199
Batch 3/64 loss: -2.2892284393310547
Batch 4/64 loss: -2.108517646789551
Batch 5/64 loss: -2.299715042114258
Batch 6/64 loss: -2.116151809692383
Batch 7/64 loss: -1.9874906539916992
Batch 8/64 loss: -2.308320999145508
Batch 9/64 loss: -2.4157629013061523
Batch 10/64 loss: -2.3224258422851562
Batch 11/64 loss: -1.9391040802001953
Batch 12/64 loss: -2.088839530944824
Batch 13/64 loss: -2.289425849914551
Batch 14/64 loss: -2.328451156616211
Batch 15/64 loss: -2.1742706298828125
Batch 16/64 loss: -2.0273332595825195
Batch 17/64 loss: -2.3103694915771484
Batch 18/64 loss: -2.348094940185547
Batch 19/64 loss: -2.237537384033203
Batch 20/64 loss: -2.3954601287841797
Batch 21/64 loss: -2.39241886138916
Batch 22/64 loss: -2.1694154739379883
Batch 23/64 loss: -2.238020896911621
Batch 24/64 loss: -1.7304792404174805
Batch 25/64 loss: -2.311002731323242
Batch 26/64 loss: -2.181692123413086
Batch 27/64 loss: -2.386115074157715
Batch 28/64 loss: -2.1634693145751953
Batch 29/64 loss: -1.915959358215332
Batch 30/64 loss: -2.1239328384399414
Batch 31/64 loss: -1.9031810760498047
Batch 32/64 loss: -1.868302345275879
Batch 33/64 loss: -2.254519462585449
Batch 34/64 loss: -1.9985637664794922
Batch 35/64 loss: -1.9505882263183594
Batch 36/64 loss: -2.309600830078125
Batch 37/64 loss: -2.010791778564453
Batch 38/64 loss: -2.141620635986328
Batch 39/64 loss: -1.9386472702026367
Batch 40/64 loss: -2.307265281677246
Batch 41/64 loss: -1.9814233779907227
Batch 42/64 loss: -2.079073905944824
Batch 43/64 loss: -2.188884735107422
Batch 44/64 loss: -1.9554834365844727
Batch 45/64 loss: -2.019747734069824
Batch 46/64 loss: -2.087355613708496
Batch 47/64 loss: -2.1827383041381836
Batch 48/64 loss: -1.9436073303222656
Batch 49/64 loss: -2.167452812194824
Batch 50/64 loss: -2.018397331237793
Batch 51/64 loss: -2.145451545715332
Batch 52/64 loss: -2.3078298568725586
Batch 53/64 loss: -2.156022071838379
Batch 54/64 loss: -1.9578399658203125
Batch 55/64 loss: -2.1664419174194336
Batch 56/64 loss: -2.4079465866088867
Batch 57/64 loss: -2.3358421325683594
Batch 58/64 loss: -2.3486404418945312
Batch 59/64 loss: -2.105916976928711
Batch 60/64 loss: -2.126047134399414
Batch 61/64 loss: -1.9917926788330078
Batch 62/64 loss: -2.264531135559082
Batch 63/64 loss: -2.3934831619262695
Batch 64/64 loss: -6.2740607261657715
Epoch 127  Train loss: -2.210207608166863  Val loss: -2.4074727087905727
Epoch 128
-------------------------------
Batch 1/64 loss: -2.2115535736083984
Batch 2/64 loss: -2.25555419921875
Batch 3/64 loss: -2.246912956237793
Batch 4/64 loss: -2.1678857803344727
Batch 5/64 loss: -2.4623355865478516
Batch 6/64 loss: -1.9765863418579102
Batch 7/64 loss: -1.7898006439208984
Batch 8/64 loss: -2.155911445617676
Batch 9/64 loss: -2.340378761291504
Batch 10/64 loss: -2.191391944885254
Batch 11/64 loss: -2.022642135620117
Batch 12/64 loss: -2.217742919921875
Batch 13/64 loss: -2.0335817337036133
Batch 14/64 loss: -1.7870655059814453
Batch 15/64 loss: -2.1499385833740234
Batch 16/64 loss: -1.815155029296875
Batch 17/64 loss: -2.3684864044189453
Batch 18/64 loss: -2.237959861755371
Batch 19/64 loss: -2.2127561569213867
Batch 20/64 loss: -2.1511011123657227
Batch 21/64 loss: -2.0570812225341797
Batch 22/64 loss: -2.64658260345459
Batch 23/64 loss: -2.133133888244629
Batch 24/64 loss: -2.262303352355957
Batch 25/64 loss: -2.4072389602661133
Batch 26/64 loss: -2.2745895385742188
Batch 27/64 loss: -2.369511604309082
Batch 28/64 loss: -2.27445125579834
Batch 29/64 loss: -2.233663558959961
Batch 30/64 loss: -2.1773529052734375
Batch 31/64 loss: -2.1076650619506836
Batch 32/64 loss: -2.321658134460449
Batch 33/64 loss: -2.1396923065185547
Batch 34/64 loss: -2.0557804107666016
Batch 35/64 loss: -1.8563337326049805
Batch 36/64 loss: -2.1196231842041016
Batch 37/64 loss: -2.299457550048828
Batch 38/64 loss: -2.347412109375
Batch 39/64 loss: -2.2582807540893555
Batch 40/64 loss: -2.297703742980957
Batch 41/64 loss: -2.2635974884033203
Batch 42/64 loss: -2.308858871459961
Batch 43/64 loss: -2.380415916442871
Batch 44/64 loss: -2.478936195373535
Batch 45/64 loss: -2.2355899810791016
Batch 46/64 loss: -1.9756784439086914
Batch 47/64 loss: -2.3797683715820312
Batch 48/64 loss: -2.048924446105957
Batch 49/64 loss: -2.2062511444091797
Batch 50/64 loss: -1.6530771255493164
Batch 51/64 loss: -2.1535520553588867
Batch 52/64 loss: -1.8840160369873047
Batch 53/64 loss: -2.5777101516723633
Batch 54/64 loss: -2.162202835083008
Batch 55/64 loss: -2.1553173065185547
Batch 56/64 loss: -2.2832841873168945
Batch 57/64 loss: -1.8803339004516602
Batch 58/64 loss: -2.1754369735717773
Batch 59/64 loss: -2.1236753463745117
Batch 60/64 loss: -2.1546716690063477
Batch 61/64 loss: -2.517200469970703
Batch 62/64 loss: -1.9584646224975586
Batch 63/64 loss: -2.2962799072265625
Batch 64/64 loss: -6.772738456726074
Epoch 128  Train loss: -2.239483197530111  Val loss: -2.406454145293875
Epoch 129
-------------------------------
Batch 1/64 loss: -1.8807659149169922
Batch 2/64 loss: -1.7952470779418945
Batch 3/64 loss: -2.279317855834961
Batch 4/64 loss: -2.206801414489746
Batch 5/64 loss: -2.2764291763305664
Batch 6/64 loss: -2.1085329055786133
Batch 7/64 loss: -1.9695720672607422
Batch 8/64 loss: -2.310739517211914
Batch 9/64 loss: -2.468996047973633
Batch 10/64 loss: -2.1845321655273438
Batch 11/64 loss: -2.1547021865844727
Batch 12/64 loss: -1.883408546447754
Batch 13/64 loss: -2.2178945541381836
Batch 14/64 loss: -2.0936641693115234
Batch 15/64 loss: -2.1793384552001953
Batch 16/64 loss: -2.3044815063476562
Batch 17/64 loss: -2.4547672271728516
Batch 18/64 loss: -2.265679359436035
Batch 19/64 loss: -2.2712936401367188
Batch 20/64 loss: -2.1298742294311523
Batch 21/64 loss: -2.2068538665771484
Batch 22/64 loss: -2.32464599609375
Batch 23/64 loss: -2.2308692932128906
Batch 24/64 loss: -2.018217086791992
Batch 25/64 loss: -1.6496925354003906
Batch 26/64 loss: -1.9964513778686523
Batch 27/64 loss: -2.1344804763793945
Batch 28/64 loss: -2.0982656478881836
Batch 29/64 loss: -1.8991832733154297
Batch 30/64 loss: -1.8280916213989258
Batch 31/64 loss: -1.8866472244262695
Batch 32/64 loss: -2.02834415435791
Batch 33/64 loss: -2.1275863647460938
Batch 34/64 loss: -2.5165233612060547
Batch 35/64 loss: -2.20184326171875
Batch 36/64 loss: -2.176778793334961
Batch 37/64 loss: -2.1498537063598633
Batch 38/64 loss: -2.0837793350219727
Batch 39/64 loss: -2.1237125396728516
Batch 40/64 loss: -2.1040163040161133
Batch 41/64 loss: -2.401294708251953
Batch 42/64 loss: -2.2138748168945312
Batch 43/64 loss: -2.243114471435547
Batch 44/64 loss: -1.9986486434936523
Batch 45/64 loss: -2.21005916595459
Batch 46/64 loss: -2.2234907150268555
Batch 47/64 loss: -2.254124641418457
Batch 48/64 loss: -1.916365623474121
Batch 49/64 loss: -2.182377815246582
Batch 50/64 loss: -1.7815437316894531
Batch 51/64 loss: -2.1099729537963867
Batch 52/64 loss: -2.256174087524414
Batch 53/64 loss: -2.159860610961914
Batch 54/64 loss: -1.883988380432129
Batch 55/64 loss: -2.2495603561401367
Batch 56/64 loss: -2.213685989379883
Batch 57/64 loss: -2.0617971420288086
Batch 58/64 loss: -1.8656072616577148
Batch 59/64 loss: -2.3161258697509766
Batch 60/64 loss: -2.2756738662719727
Batch 61/64 loss: -1.8289203643798828
Batch 62/64 loss: -2.155454635620117
Batch 63/64 loss: -2.1195497512817383
Batch 64/64 loss: -6.611473560333252
Epoch 129  Train loss: -2.181988157010546  Val loss: -2.274377409944829
Epoch 130
-------------------------------
Batch 1/64 loss: -2.2442808151245117
Batch 2/64 loss: -2.110879898071289
Batch 3/64 loss: -2.1748743057250977
Batch 4/64 loss: -2.298938751220703
Batch 5/64 loss: -2.101933479309082
Batch 6/64 loss: -2.0698909759521484
Batch 7/64 loss: -2.3654422760009766
Batch 8/64 loss: -2.3429203033447266
Batch 9/64 loss: -2.1533327102661133
Batch 10/64 loss: -2.1862850189208984
Batch 11/64 loss: -2.4518938064575195
Batch 12/64 loss: -2.2384042739868164
Batch 13/64 loss: -2.274110794067383
Batch 14/64 loss: -2.374591827392578
Batch 15/64 loss: -1.9340362548828125
Batch 16/64 loss: -1.9795856475830078
Batch 17/64 loss: -1.6856584548950195
Batch 18/64 loss: -2.1119871139526367
Batch 19/64 loss: -1.938767433166504
Batch 20/64 loss: -2.0684585571289062
Batch 21/64 loss: -2.058468818664551
Batch 22/64 loss: -2.4339475631713867
Batch 23/64 loss: -2.130284309387207
Batch 24/64 loss: -1.917470932006836
Batch 25/64 loss: -2.1995296478271484
Batch 26/64 loss: -2.0924644470214844
Batch 27/64 loss: -2.171412467956543
Batch 28/64 loss: -2.168994903564453
Batch 29/64 loss: -2.464141845703125
Batch 30/64 loss: -1.8263750076293945
Batch 31/64 loss: -2.1486949920654297
Batch 32/64 loss: -2.4524431228637695
Batch 33/64 loss: -2.168760299682617
Batch 34/64 loss: -2.078213691711426
Batch 35/64 loss: -1.9927330017089844
Batch 36/64 loss: -1.9548406600952148
Batch 37/64 loss: -2.2675418853759766
Batch 38/64 loss: -2.3034963607788086
Batch 39/64 loss: -2.178694725036621
Batch 40/64 loss: -2.2355804443359375
Batch 41/64 loss: -1.9114341735839844
Batch 42/64 loss: -2.379815101623535
Batch 43/64 loss: -2.2565717697143555
Batch 44/64 loss: -2.180426597595215
Batch 45/64 loss: -2.209718704223633
Batch 46/64 loss: -2.396449089050293
Batch 47/64 loss: -1.6490278244018555
Batch 48/64 loss: -2.081925392150879
Batch 49/64 loss: -2.547994613647461
Batch 50/64 loss: -2.1654253005981445
Batch 51/64 loss: -2.2535171508789062
Batch 52/64 loss: -2.3653059005737305
Batch 53/64 loss: -1.9120912551879883
Batch 54/64 loss: -2.1985702514648438
Batch 55/64 loss: -1.4951744079589844
Batch 56/64 loss: -2.200103759765625
Batch 57/64 loss: -2.196587562561035
Batch 58/64 loss: -1.4347620010375977
Batch 59/64 loss: -2.352269172668457
Batch 60/64 loss: -2.4232397079467773
Batch 61/64 loss: -2.4295434951782227
Batch 62/64 loss: -2.2036800384521484
Batch 63/64 loss: -1.6697845458984375
Batch 64/64 loss: -6.604536056518555
Epoch 130  Train loss: -2.1994852028641048  Val loss: -2.284304458251114
Epoch 131
-------------------------------
Batch 1/64 loss: -1.7994670867919922
Batch 2/64 loss: -2.3243894577026367
Batch 3/64 loss: -2.1005067825317383
Batch 4/64 loss: -2.3673486709594727
Batch 5/64 loss: -2.222731590270996
Batch 6/64 loss: -2.1035852432250977
Batch 7/64 loss: -2.4028663635253906
Batch 8/64 loss: -2.271775245666504
Batch 9/64 loss: -1.9203014373779297
Batch 10/64 loss: -2.1837167739868164
Batch 11/64 loss: -1.9081745147705078
Batch 12/64 loss: -1.9652252197265625
Batch 13/64 loss: -2.2185420989990234
Batch 14/64 loss: -2.330432891845703
Batch 15/64 loss: -2.1395339965820312
Batch 16/64 loss: -2.3831729888916016
Batch 17/64 loss: -2.1247758865356445
Batch 18/64 loss: -2.3426170349121094
Batch 19/64 loss: -2.2109861373901367
Batch 20/64 loss: -1.7874088287353516
Batch 21/64 loss: -2.035202980041504
Batch 22/64 loss: -2.403545379638672
Batch 23/64 loss: -2.186394691467285
Batch 24/64 loss: -2.2125844955444336
Batch 25/64 loss: -2.3750057220458984
Batch 26/64 loss: -2.372285842895508
Batch 27/64 loss: -1.8490180969238281
Batch 28/64 loss: -2.192411422729492
Batch 29/64 loss: -2.0876407623291016
Batch 30/64 loss: -2.1986265182495117
Batch 31/64 loss: -2.2170896530151367
Batch 32/64 loss: -1.6927061080932617
Batch 33/64 loss: -2.237128257751465
Batch 34/64 loss: -1.8286046981811523
Batch 35/64 loss: -2.2386837005615234
Batch 36/64 loss: -2.4058876037597656
Batch 37/64 loss: -2.34378719329834
Batch 38/64 loss: -1.8866949081420898
Batch 39/64 loss: -2.2422943115234375
Batch 40/64 loss: -2.187257766723633
Batch 41/64 loss: -2.496685028076172
Batch 42/64 loss: -1.9051589965820312
Batch 43/64 loss: -2.1808433532714844
Batch 44/64 loss: -2.071643829345703
Batch 45/64 loss: -1.9655122756958008
Batch 46/64 loss: -2.3964242935180664
Batch 47/64 loss: -1.8915948867797852
Batch 48/64 loss: -2.0702199935913086
Batch 49/64 loss: -2.237377166748047
Batch 50/64 loss: -2.2822322845458984
Batch 51/64 loss: -2.4314136505126953
Batch 52/64 loss: -2.3278112411499023
Batch 53/64 loss: -2.283705711364746
Batch 54/64 loss: -1.8719606399536133
Batch 55/64 loss: -2.1738901138305664
Batch 56/64 loss: -2.4241132736206055
Batch 57/64 loss: -1.828512191772461
Batch 58/64 loss: -2.237092971801758
Batch 59/64 loss: -2.1913204193115234
Batch 60/64 loss: -2.0870885848999023
Batch 61/64 loss: -2.2132043838500977
Batch 62/64 loss: -2.226442337036133
Batch 63/64 loss: -2.049581527709961
Batch 64/64 loss: -6.643188953399658
Epoch 131  Train loss: -2.2137510467978085  Val loss: -2.401840393485892
Epoch 132
-------------------------------
Batch 1/64 loss: -2.2136449813842773
Batch 2/64 loss: -2.338322639465332
Batch 3/64 loss: -2.068842887878418
Batch 4/64 loss: -2.3059816360473633
Batch 5/64 loss: -2.1690750122070312
Batch 6/64 loss: -2.002945899963379
Batch 7/64 loss: -2.469538688659668
Batch 8/64 loss: -2.010563850402832
Batch 9/64 loss: -2.2060718536376953
Batch 10/64 loss: -2.163386344909668
Batch 11/64 loss: -2.16196346282959
Batch 12/64 loss: -2.3060121536254883
Batch 13/64 loss: -2.1642866134643555
Batch 14/64 loss: -2.1848526000976562
Batch 15/64 loss: -1.895315170288086
Batch 16/64 loss: -1.9592094421386719
Batch 17/64 loss: -2.1259241104125977
Batch 18/64 loss: -2.257229804992676
Batch 19/64 loss: -2.2746715545654297
Batch 20/64 loss: -2.1101417541503906
Batch 21/64 loss: -2.3090734481811523
Batch 22/64 loss: -2.4087095260620117
Batch 23/64 loss: -2.0814876556396484
Batch 24/64 loss: -2.444159507751465
Batch 25/64 loss: -2.303142547607422
Batch 26/64 loss: -2.08103084564209
Batch 27/64 loss: -2.106586456298828
Batch 28/64 loss: -2.330923080444336
Batch 29/64 loss: -1.9946403503417969
Batch 30/64 loss: -2.1696434020996094
Batch 31/64 loss: -2.217700958251953
Batch 32/64 loss: -2.1219968795776367
Batch 33/64 loss: -2.245025634765625
Batch 34/64 loss: -2.2111663818359375
Batch 35/64 loss: -1.5743331909179688
Batch 36/64 loss: -2.115264892578125
Batch 37/64 loss: -1.8775806427001953
Batch 38/64 loss: -2.260157585144043
Batch 39/64 loss: -2.235377311706543
Batch 40/64 loss: -1.7627029418945312
Batch 41/64 loss: -2.1787805557250977
Batch 42/64 loss: -2.2201080322265625
Batch 43/64 loss: -2.339578628540039
Batch 44/64 loss: -2.1059865951538086
Batch 45/64 loss: -2.208329200744629
Batch 46/64 loss: -2.363393783569336
Batch 47/64 loss: -2.1270618438720703
Batch 48/64 loss: -2.426555633544922
Batch 49/64 loss: -2.207193374633789
Batch 50/64 loss: -2.3713512420654297
Batch 51/64 loss: -1.9198923110961914
Batch 52/64 loss: -2.0854272842407227
Batch 53/64 loss: -2.060394287109375
Batch 54/64 loss: -2.272963523864746
Batch 55/64 loss: -2.4034080505371094
Batch 56/64 loss: -2.1502904891967773
Batch 57/64 loss: -2.3243398666381836
Batch 58/64 loss: -2.414449691772461
Batch 59/64 loss: -1.9755125045776367
Batch 60/64 loss: -2.1876049041748047
Batch 61/64 loss: -1.9537429809570312
Batch 62/64 loss: -1.904541015625
Batch 63/64 loss: -2.099461555480957
Batch 64/64 loss: -6.663029670715332
Epoch 132  Train loss: -2.220177620532466  Val loss: -2.1564127079809654
Epoch 133
-------------------------------
Batch 1/64 loss: -1.2885408401489258
Batch 2/64 loss: -1.452463150024414
Batch 3/64 loss: -1.871408462524414
Batch 4/64 loss: -1.9085865020751953
Batch 5/64 loss: -1.9893245697021484
Batch 6/64 loss: -1.9763174057006836
Batch 7/64 loss: -1.7803449630737305
Batch 8/64 loss: -1.9272241592407227
Batch 9/64 loss: -1.9120264053344727
Batch 10/64 loss: -1.0036487579345703
Batch 11/64 loss: -1.970383644104004
Batch 12/64 loss: -2.0418624877929688
Batch 13/64 loss: -2.082756996154785
Batch 14/64 loss: -1.6628808975219727
Batch 15/64 loss: -1.8859615325927734
Batch 16/64 loss: -1.9535579681396484
Batch 17/64 loss: -2.279865264892578
Batch 18/64 loss: -2.345754623413086
Batch 19/64 loss: -1.9358940124511719
Batch 20/64 loss: -2.246164321899414
Batch 21/64 loss: -2.0784521102905273
Batch 22/64 loss: -2.3036270141601562
Batch 23/64 loss: -2.0369081497192383
Batch 24/64 loss: -2.2063283920288086
Batch 25/64 loss: -2.2938575744628906
Batch 26/64 loss: -2.324819564819336
Batch 27/64 loss: -1.8769378662109375
Batch 28/64 loss: -2.1897382736206055
Batch 29/64 loss: -2.393277168273926
Batch 30/64 loss: -1.820521354675293
Batch 31/64 loss: -1.8995380401611328
Batch 32/64 loss: -2.2267942428588867
Batch 33/64 loss: -2.482438087463379
Batch 34/64 loss: -1.836745262145996
Batch 35/64 loss: -1.916447639465332
Batch 36/64 loss: -2.524369239807129
Batch 37/64 loss: -2.192265510559082
Batch 38/64 loss: -2.340665817260742
Batch 39/64 loss: -2.2147817611694336
Batch 40/64 loss: -2.2586631774902344
Batch 41/64 loss: -2.060039520263672
Batch 42/64 loss: -2.239926338195801
Batch 43/64 loss: -2.4642810821533203
Batch 44/64 loss: -2.1635446548461914
Batch 45/64 loss: -2.1300506591796875
Batch 46/64 loss: -2.3440628051757812
Batch 47/64 loss: -2.2888574600219727
Batch 48/64 loss: -2.052845001220703
Batch 49/64 loss: -2.200362205505371
Batch 50/64 loss: -2.4553098678588867
Batch 51/64 loss: -2.1587371826171875
Batch 52/64 loss: -2.263673782348633
Batch 53/64 loss: -2.3145790100097656
Batch 54/64 loss: -2.193368911743164
Batch 55/64 loss: -2.340818405151367
Batch 56/64 loss: -2.222248077392578
Batch 57/64 loss: -2.33876895904541
Batch 58/64 loss: -2.227004051208496
Batch 59/64 loss: -2.0518531799316406
Batch 60/64 loss: -2.423910140991211
Batch 61/64 loss: -2.466533660888672
Batch 62/64 loss: -2.116908073425293
Batch 63/64 loss: -2.1694908142089844
Batch 64/64 loss: -6.707431316375732
Epoch 133  Train loss: -2.1592139692867502  Val loss: -2.410856817186493
Epoch 134
-------------------------------
Batch 1/64 loss: -2.3889503479003906
Batch 2/64 loss: -2.2333621978759766
Batch 3/64 loss: -2.431882858276367
Batch 4/64 loss: -1.848459243774414
Batch 5/64 loss: -2.4488325119018555
Batch 6/64 loss: -2.277981758117676
Batch 7/64 loss: -2.404353141784668
Batch 8/64 loss: -2.2582340240478516
Batch 9/64 loss: -1.9243888854980469
Batch 10/64 loss: -2.4110193252563477
Batch 11/64 loss: -1.9919509887695312
Batch 12/64 loss: -2.1153669357299805
Batch 13/64 loss: -2.0729732513427734
Batch 14/64 loss: -2.2473249435424805
Batch 15/64 loss: -2.265995979309082
Batch 16/64 loss: -2.256326675415039
Batch 17/64 loss: -2.2321529388427734
Batch 18/64 loss: -2.437143325805664
Batch 19/64 loss: -2.076542854309082
Batch 20/64 loss: -2.135220527648926
Batch 21/64 loss: -2.4441452026367188
Batch 22/64 loss: -2.325554847717285
Batch 23/64 loss: -2.3962106704711914
Batch 24/64 loss: -2.3768491744995117
Batch 25/64 loss: -1.9944229125976562
Batch 26/64 loss: -2.110743522644043
Batch 27/64 loss: -2.219043731689453
Batch 28/64 loss: -2.453667640686035
Batch 29/64 loss: -2.3514413833618164
Batch 30/64 loss: -1.5564460754394531
Batch 31/64 loss: -2.2005443572998047
Batch 32/64 loss: -2.0085201263427734
Batch 33/64 loss: -2.3071680068969727
Batch 34/64 loss: -2.1369524002075195
Batch 35/64 loss: -2.1116485595703125
Batch 36/64 loss: -2.133082389831543
Batch 37/64 loss: -2.2032880783081055
Batch 38/64 loss: -2.41733455657959
Batch 39/64 loss: -1.7469615936279297
Batch 40/64 loss: -2.348583221435547
Batch 41/64 loss: -2.289065361022949
Batch 42/64 loss: -2.4391393661499023
Batch 43/64 loss: -1.8773612976074219
Batch 44/64 loss: -2.049492835998535
Batch 45/64 loss: -2.153291702270508
Batch 46/64 loss: -2.355337142944336
Batch 47/64 loss: -2.3740310668945312
Batch 48/64 loss: -2.0254135131835938
Batch 49/64 loss: -2.0856399536132812
Batch 50/64 loss: -2.1552248001098633
Batch 51/64 loss: -1.9021873474121094
Batch 52/64 loss: -2.4381179809570312
Batch 53/64 loss: -2.3600378036499023
Batch 54/64 loss: -2.2490921020507812
Batch 55/64 loss: -2.2009763717651367
Batch 56/64 loss: -2.169635772705078
Batch 57/64 loss: -2.1579627990722656
Batch 58/64 loss: -2.1856212615966797
Batch 59/64 loss: -2.2611465454101562
Batch 60/64 loss: -2.323367118835449
Batch 61/64 loss: -2.521648406982422
Batch 62/64 loss: -1.7772712707519531
Batch 63/64 loss: -2.084423065185547
Batch 64/64 loss: -6.890913486480713
Epoch 134  Train loss: -2.2573292732238768  Val loss: -2.0674453158558848
Epoch 135
-------------------------------
Batch 1/64 loss: -2.326664924621582
Batch 2/64 loss: -1.9084281921386719
Batch 3/64 loss: -2.11984920501709
Batch 4/64 loss: -2.1699113845825195
Batch 5/64 loss: -2.3453922271728516
Batch 6/64 loss: -2.0880651473999023
Batch 7/64 loss: -2.044584274291992
Batch 8/64 loss: -2.216310501098633
Batch 9/64 loss: -2.2403249740600586
Batch 10/64 loss: -1.9604644775390625
Batch 11/64 loss: -1.9686822891235352
Batch 12/64 loss: -1.637578010559082
Batch 13/64 loss: -1.7277393341064453
Batch 14/64 loss: -2.1540088653564453
Batch 15/64 loss: -2.1468114852905273
Batch 16/64 loss: -2.113954544067383
Batch 17/64 loss: -2.045705795288086
Batch 18/64 loss: -2.09061336517334
Batch 19/64 loss: -2.0935821533203125
Batch 20/64 loss: -1.9652423858642578
Batch 21/64 loss: -1.6658439636230469
Batch 22/64 loss: -2.236661911010742
Batch 23/64 loss: -2.2436628341674805
Batch 24/64 loss: -1.9244394302368164
Batch 25/64 loss: -2.4313011169433594
Batch 26/64 loss: -2.3235158920288086
Batch 27/64 loss: -2.2626190185546875
Batch 28/64 loss: -2.2014102935791016
Batch 29/64 loss: -2.1969223022460938
Batch 30/64 loss: -1.8865938186645508
Batch 31/64 loss: -2.3529138565063477
Batch 32/64 loss: -2.10202693939209
Batch 33/64 loss: -1.9579229354858398
Batch 34/64 loss: -2.2821998596191406
Batch 35/64 loss: -2.2940073013305664
Batch 36/64 loss: -2.221912384033203
Batch 37/64 loss: -2.099167823791504
Batch 38/64 loss: -1.6425037384033203
Batch 39/64 loss: -2.311504364013672
Batch 40/64 loss: -2.157939910888672
Batch 41/64 loss: -2.153848648071289
Batch 42/64 loss: -2.1269359588623047
Batch 43/64 loss: -2.4370241165161133
Batch 44/64 loss: -1.861398696899414
Batch 45/64 loss: -2.0069265365600586
Batch 46/64 loss: -2.2803401947021484
Batch 47/64 loss: -2.4194259643554688
Batch 48/64 loss: -2.368353843688965
Batch 49/64 loss: -2.2818241119384766
Batch 50/64 loss: -2.053011894226074
Batch 51/64 loss: -2.3036632537841797
Batch 52/64 loss: -2.1398696899414062
Batch 53/64 loss: -2.346123695373535
Batch 54/64 loss: -1.9532585144042969
Batch 55/64 loss: -2.323134422302246
Batch 56/64 loss: -2.323770523071289
Batch 57/64 loss: -2.25522518157959
Batch 58/64 loss: -2.097583770751953
Batch 59/64 loss: -2.2836856842041016
Batch 60/64 loss: -1.8744087219238281
Batch 61/64 loss: -2.214352607727051
Batch 62/64 loss: -2.0590314865112305
Batch 63/64 loss: -1.700967788696289
Batch 64/64 loss: -6.736957550048828
Epoch 135  Train loss: -2.181582222732843  Val loss: -2.46819288378319
Epoch 136
-------------------------------
Batch 1/64 loss: -2.1045217514038086
Batch 2/64 loss: -2.4568796157836914
Batch 3/64 loss: -2.357232093811035
Batch 4/64 loss: -1.835714340209961
Batch 5/64 loss: -2.2367000579833984
Batch 6/64 loss: -2.1270875930786133
Batch 7/64 loss: -1.7468233108520508
Batch 8/64 loss: -2.347980499267578
Batch 9/64 loss: -2.4176034927368164
Batch 10/64 loss: -1.9849872589111328
Batch 11/64 loss: -2.235438346862793
Batch 12/64 loss: -2.11843204498291
Batch 13/64 loss: -1.9871177673339844
Batch 14/64 loss: -2.4181623458862305
Batch 15/64 loss: -2.358912467956543
Batch 16/64 loss: -2.1819686889648438
Batch 17/64 loss: -2.1383800506591797
Batch 18/64 loss: -2.3767261505126953
Batch 19/64 loss: -2.3868064880371094
Batch 20/64 loss: -2.328329086303711
Batch 21/64 loss: -2.3397932052612305
Batch 22/64 loss: -2.101095199584961
Batch 23/64 loss: -2.379763603210449
Batch 24/64 loss: -2.2027597427368164
Batch 25/64 loss: -2.0507726669311523
Batch 26/64 loss: -2.378793716430664
Batch 27/64 loss: -2.417983055114746
Batch 28/64 loss: -2.3408823013305664
Batch 29/64 loss: -2.265277862548828
Batch 30/64 loss: -2.3401575088500977
Batch 31/64 loss: -2.195749282836914
Batch 32/64 loss: -2.1679515838623047
Batch 33/64 loss: -1.8945579528808594
Batch 34/64 loss: -2.1829748153686523
Batch 35/64 loss: -2.1986122131347656
Batch 36/64 loss: -1.758819580078125
Batch 37/64 loss: -2.0791683197021484
Batch 38/64 loss: -1.9928312301635742
Batch 39/64 loss: -1.9487600326538086
Batch 40/64 loss: -2.1531982421875
Batch 41/64 loss: -2.3263654708862305
Batch 42/64 loss: -2.1537561416625977
Batch 43/64 loss: -2.1999082565307617
Batch 44/64 loss: -2.190034866333008
Batch 45/64 loss: -1.9247961044311523
Batch 46/64 loss: -2.412904739379883
Batch 47/64 loss: -2.190532684326172
Batch 48/64 loss: -1.7932796478271484
Batch 49/64 loss: -1.9091167449951172
Batch 50/64 loss: -2.292591094970703
Batch 51/64 loss: -2.3614912033081055
Batch 52/64 loss: -1.608194351196289
Batch 53/64 loss: -2.150723457336426
Batch 54/64 loss: -2.270702362060547
Batch 55/64 loss: -2.401841163635254
Batch 56/64 loss: -2.376741409301758
Batch 57/64 loss: -2.2748775482177734
Batch 58/64 loss: -2.1747846603393555
Batch 59/64 loss: -2.147219657897949
Batch 60/64 loss: -2.362314224243164
Batch 61/64 loss: -2.297072410583496
Batch 62/64 loss: -1.442448616027832
Batch 63/64 loss: -2.3589553833007812
Batch 64/64 loss: -6.8770670890808105
Epoch 136  Train loss: -2.2323789503060136  Val loss: -2.3533631813075533
Epoch 137
-------------------------------
Batch 1/64 loss: -2.082487106323242
Batch 2/64 loss: -2.490194320678711
Batch 3/64 loss: -1.9527578353881836
Batch 4/64 loss: -2.2363109588623047
Batch 5/64 loss: -2.5981674194335938
Batch 6/64 loss: -1.936018943786621
Batch 7/64 loss: -1.9708499908447266
Batch 8/64 loss: -2.3559064865112305
Batch 9/64 loss: -2.0338993072509766
Batch 10/64 loss: -2.0675888061523438
Batch 11/64 loss: -2.3206405639648438
Batch 12/64 loss: -2.0936899185180664
Batch 13/64 loss: -2.354705810546875
Batch 14/64 loss: -2.439328193664551
Batch 15/64 loss: -2.4458303451538086
Batch 16/64 loss: -1.9750337600708008
Batch 17/64 loss: -2.311465263366699
Batch 18/64 loss: -2.084954261779785
Batch 19/64 loss: -2.1976680755615234
Batch 20/64 loss: -2.2290239334106445
Batch 21/64 loss: -2.0028820037841797
Batch 22/64 loss: -2.071272850036621
Batch 23/64 loss: -2.1810293197631836
Batch 24/64 loss: -2.1163082122802734
Batch 25/64 loss: -2.2796154022216797
Batch 26/64 loss: -1.6478052139282227
Batch 27/64 loss: -2.3311328887939453
Batch 28/64 loss: -2.1397247314453125
Batch 29/64 loss: -2.310112953186035
Batch 30/64 loss: -1.8245134353637695
Batch 31/64 loss: -2.454005241394043
Batch 32/64 loss: -2.007870674133301
Batch 33/64 loss: -2.201205253601074
Batch 34/64 loss: -2.335991859436035
Batch 35/64 loss: -2.356210708618164
Batch 36/64 loss: -2.253237724304199
Batch 37/64 loss: -2.304905891418457
Batch 38/64 loss: -2.3872127532958984
Batch 39/64 loss: -1.5546131134033203
Batch 40/64 loss: -2.1307363510131836
Batch 41/64 loss: -2.033719062805176
Batch 42/64 loss: -2.013835906982422
Batch 43/64 loss: -2.322711944580078
Batch 44/64 loss: -2.034881591796875
Batch 45/64 loss: -2.2846317291259766
Batch 46/64 loss: -2.496575355529785
Batch 47/64 loss: -2.343799591064453
Batch 48/64 loss: -2.166703224182129
Batch 49/64 loss: -1.5805339813232422
Batch 50/64 loss: -1.7407455444335938
Batch 51/64 loss: -2.3480825424194336
Batch 52/64 loss: -2.1770057678222656
Batch 53/64 loss: -2.1192455291748047
Batch 54/64 loss: -2.2271318435668945
Batch 55/64 loss: -2.1887311935424805
Batch 56/64 loss: -2.122037887573242
Batch 57/64 loss: -2.3371267318725586
Batch 58/64 loss: -1.9448585510253906
Batch 59/64 loss: -1.929849624633789
Batch 60/64 loss: -2.0786523818969727
Batch 61/64 loss: -2.4350709915161133
Batch 62/64 loss: -2.0547924041748047
Batch 63/64 loss: -2.4002685546875
Batch 64/64 loss: -6.742908000946045
Epoch 137  Train loss: -2.219687542260862  Val loss: -2.3551565085080073
Epoch 138
-------------------------------
Batch 1/64 loss: -2.1616811752319336
Batch 2/64 loss: -2.215045928955078
Batch 3/64 loss: -1.9188508987426758
Batch 4/64 loss: -2.0038557052612305
Batch 5/64 loss: -1.9485282897949219
Batch 6/64 loss: -2.082813262939453
Batch 7/64 loss: -2.2389001846313477
Batch 8/64 loss: -2.1037187576293945
Batch 9/64 loss: -2.1279144287109375
Batch 10/64 loss: -1.890462875366211
Batch 11/64 loss: -2.445981979370117
Batch 12/64 loss: -2.396312713623047
Batch 13/64 loss: -2.1040143966674805
Batch 14/64 loss: -1.592794418334961
Batch 15/64 loss: -2.2833080291748047
Batch 16/64 loss: -2.201319694519043
Batch 17/64 loss: -2.2959060668945312
Batch 18/64 loss: -2.3891115188598633
Batch 19/64 loss: -1.990386962890625
Batch 20/64 loss: -1.960653305053711
Batch 21/64 loss: -2.189457893371582
Batch 22/64 loss: -1.865555763244629
Batch 23/64 loss: -2.182440757751465
Batch 24/64 loss: -1.9599542617797852
Batch 25/64 loss: -2.024381637573242
Batch 26/64 loss: -2.1869077682495117
Batch 27/64 loss: -2.1821794509887695
Batch 28/64 loss: -2.02877140045166
Batch 29/64 loss: -2.2073049545288086
Batch 30/64 loss: -2.03631591796875
Batch 31/64 loss: -2.123861312866211
Batch 32/64 loss: -1.9744062423706055
Batch 33/64 loss: -2.115509033203125
Batch 34/64 loss: -1.943760871887207
Batch 35/64 loss: -2.4829702377319336
Batch 36/64 loss: -2.1015491485595703
Batch 37/64 loss: -2.124849319458008
Batch 38/64 loss: -1.9894800186157227
Batch 39/64 loss: -2.327206611633301
Batch 40/64 loss: -2.163005828857422
Batch 41/64 loss: -2.1065855026245117
Batch 42/64 loss: -1.542250633239746
Batch 43/64 loss: -2.2790422439575195
Batch 44/64 loss: -1.8750638961791992
Batch 45/64 loss: -1.798299789428711
Batch 46/64 loss: -2.0483627319335938
Batch 47/64 loss: -1.7641048431396484
Batch 48/64 loss: -1.7008552551269531
Batch 49/64 loss: -2.3116273880004883
Batch 50/64 loss: -2.285313606262207
Batch 51/64 loss: -1.4512996673583984
Batch 52/64 loss: -2.2909364700317383
Batch 53/64 loss: -2.2628746032714844
Batch 54/64 loss: -2.0492286682128906
Batch 55/64 loss: -2.016995429992676
Batch 56/64 loss: -2.1379966735839844
Batch 57/64 loss: -1.861006736755371
Batch 58/64 loss: -2.0793752670288086
Batch 59/64 loss: -2.3077354431152344
Batch 60/64 loss: -2.1451759338378906
Batch 61/64 loss: -2.13248348236084
Batch 62/64 loss: -1.9820642471313477
Batch 63/64 loss: -2.183330535888672
Batch 64/64 loss: -6.418191432952881
Epoch 138  Train loss: -2.133130692500694  Val loss: -2.347844402404995
Epoch 139
-------------------------------
Batch 1/64 loss: -2.2561378479003906
Batch 2/64 loss: -2.148836135864258
Batch 3/64 loss: -1.494074821472168
Batch 4/64 loss: -2.2539148330688477
Batch 5/64 loss: -1.7611799240112305
Batch 6/64 loss: -1.977860450744629
Batch 7/64 loss: -2.046359062194824
Batch 8/64 loss: -2.354233741760254
Batch 9/64 loss: -2.045931816101074
Batch 10/64 loss: -2.174053192138672
Batch 11/64 loss: -2.1210174560546875
Batch 12/64 loss: -2.2178211212158203
Batch 13/64 loss: -2.1192312240600586
Batch 14/64 loss: -1.8745040893554688
Batch 15/64 loss: -1.9799375534057617
Batch 16/64 loss: -2.3195981979370117
Batch 17/64 loss: -2.0374622344970703
Batch 18/64 loss: -2.1196155548095703
Batch 19/64 loss: -2.3970813751220703
Batch 20/64 loss: -2.4809579849243164
Batch 21/64 loss: -2.4750280380249023
Batch 22/64 loss: -2.275186538696289
Batch 23/64 loss: -2.2426748275756836
Batch 24/64 loss: -2.3365230560302734
Batch 25/64 loss: -2.0532732009887695
Batch 26/64 loss: -2.2106523513793945
Batch 27/64 loss: -2.313490867614746
Batch 28/64 loss: -2.3716917037963867
Batch 29/64 loss: -2.2131099700927734
Batch 30/64 loss: -2.0893468856811523
Batch 31/64 loss: -1.7869033813476562
Batch 32/64 loss: -2.2821455001831055
Batch 33/64 loss: -2.2455310821533203
Batch 34/64 loss: -2.4073638916015625
Batch 35/64 loss: -2.1376943588256836
Batch 36/64 loss: -2.310725212097168
Batch 37/64 loss: -1.854771614074707
Batch 38/64 loss: -2.1397361755371094
Batch 39/64 loss: -2.4184999465942383
Batch 40/64 loss: -2.197477340698242
Batch 41/64 loss: -1.6444873809814453
Batch 42/64 loss: -2.274921417236328
Batch 43/64 loss: -2.3295087814331055
Batch 44/64 loss: -1.9678802490234375
Batch 45/64 loss: -2.360177993774414
Batch 46/64 loss: -1.9719781875610352
Batch 47/64 loss: -2.082547187805176
Batch 48/64 loss: -2.378803253173828
Batch 49/64 loss: -2.209888458251953
Batch 50/64 loss: -2.4877634048461914
Batch 51/64 loss: -2.3014841079711914
Batch 52/64 loss: -1.884751319885254
Batch 53/64 loss: -2.328664779663086
Batch 54/64 loss: -2.3753890991210938
Batch 55/64 loss: -1.6336135864257812
Batch 56/64 loss: -2.2779035568237305
Batch 57/64 loss: -2.4210567474365234
Batch 58/64 loss: -2.0619163513183594
Batch 59/64 loss: -1.8462848663330078
Batch 60/64 loss: -2.298590660095215
Batch 61/64 loss: -2.408863067626953
Batch 62/64 loss: -1.6520261764526367
Batch 63/64 loss: -2.0995073318481445
Batch 64/64 loss: -6.814280033111572
Epoch 139  Train loss: -2.210985922345928  Val loss: -2.3981133949306
Epoch 140
-------------------------------
Batch 1/64 loss: -1.9374351501464844
Batch 2/64 loss: -2.2173070907592773
Batch 3/64 loss: -2.221172332763672
Batch 4/64 loss: -1.9858789443969727
Batch 5/64 loss: -2.423977851867676
Batch 6/64 loss: -2.4411134719848633
Batch 7/64 loss: -2.3360767364501953
Batch 8/64 loss: -1.9495506286621094
Batch 9/64 loss: -2.41202449798584
Batch 10/64 loss: -2.363833427429199
Batch 11/64 loss: -2.376389503479004
Batch 12/64 loss: -2.158970832824707
Batch 13/64 loss: -2.2034902572631836
Batch 14/64 loss: -2.313990592956543
Batch 15/64 loss: -2.4224319458007812
Batch 16/64 loss: -2.236697196960449
Batch 17/64 loss: -2.0313501358032227
Batch 18/64 loss: -2.007539749145508
Batch 19/64 loss: -1.7653141021728516
Batch 20/64 loss: -2.382094383239746
Batch 21/64 loss: -2.0251598358154297
Batch 22/64 loss: -2.128152847290039
Batch 23/64 loss: -1.8887510299682617
Batch 24/64 loss: -1.865966796875
Batch 25/64 loss: -2.3321876525878906
Batch 26/64 loss: -2.2225332260131836
Batch 27/64 loss: -2.188547134399414
Batch 28/64 loss: -2.130380630493164
Batch 29/64 loss: -2.3952322006225586
Batch 30/64 loss: -2.328915596008301
Batch 31/64 loss: -2.109241485595703
Batch 32/64 loss: -2.1025943756103516
Batch 33/64 loss: -2.2895545959472656
Batch 34/64 loss: -2.279153823852539
Batch 35/64 loss: -2.157285690307617
Batch 36/64 loss: -2.351363182067871
Batch 37/64 loss: -2.0588998794555664
Batch 38/64 loss: -2.0470590591430664
Batch 39/64 loss: -2.2002391815185547
Batch 40/64 loss: -2.3808326721191406
Batch 41/64 loss: -1.907435417175293
Batch 42/64 loss: -1.8881874084472656
Batch 43/64 loss: -2.3885879516601562
Batch 44/64 loss: -2.3908815383911133
Batch 45/64 loss: -2.1984405517578125
Batch 46/64 loss: -2.3368091583251953
Batch 47/64 loss: -2.513591766357422
Batch 48/64 loss: -2.120577812194824
Batch 49/64 loss: -2.3942832946777344
Batch 50/64 loss: -2.3648157119750977
Batch 51/64 loss: -1.9844532012939453
Batch 52/64 loss: -1.9423141479492188
Batch 53/64 loss: -1.9741582870483398
Batch 54/64 loss: -2.535676956176758
Batch 55/64 loss: -2.376986503601074
Batch 56/64 loss: -2.054783821105957
Batch 57/64 loss: -2.1295175552368164
Batch 58/64 loss: -2.126983642578125
Batch 59/64 loss: -2.241824150085449
Batch 60/64 loss: -2.6215972900390625
Batch 61/64 loss: -2.5537824630737305
Batch 62/64 loss: -2.28304386138916
Batch 63/64 loss: -2.3469371795654297
Batch 64/64 loss: -6.7119855880737305
Epoch 140  Train loss: -2.264758409238329  Val loss: -2.4523468017578125
Epoch 141
-------------------------------
Batch 1/64 loss: -2.1403207778930664
Batch 2/64 loss: -1.528874397277832
Batch 3/64 loss: -2.276033401489258
Batch 4/64 loss: -2.2093658447265625
Batch 5/64 loss: -2.0846385955810547
Batch 6/64 loss: -2.315789222717285
Batch 7/64 loss: -2.016127586364746
Batch 8/64 loss: -2.298466682434082
Batch 9/64 loss: -2.500242233276367
Batch 10/64 loss: -2.061178207397461
Batch 11/64 loss: -2.3348522186279297
Batch 12/64 loss: -1.9195852279663086
Batch 13/64 loss: -2.247152328491211
Batch 14/64 loss: -2.4970455169677734
Batch 15/64 loss: -2.234518051147461
Batch 16/64 loss: -1.9959545135498047
Batch 17/64 loss: -1.895895004272461
Batch 18/64 loss: -2.2561635971069336
Batch 19/64 loss: -1.8139190673828125
Batch 20/64 loss: -2.2956838607788086
Batch 21/64 loss: -2.3846817016601562
Batch 22/64 loss: -2.1795644760131836
Batch 23/64 loss: -2.4715938568115234
Batch 24/64 loss: -2.3320188522338867
Batch 25/64 loss: -2.384230613708496
Batch 26/64 loss: -2.072237014770508
Batch 27/64 loss: -2.506406784057617
Batch 28/64 loss: -2.410830497741699
Batch 29/64 loss: -2.39544677734375
Batch 30/64 loss: -2.213374137878418
Batch 31/64 loss: -2.5173721313476562
Batch 32/64 loss: -2.3325090408325195
Batch 33/64 loss: -1.965616226196289
Batch 34/64 loss: -2.224820137023926
Batch 35/64 loss: -2.215846061706543
Batch 36/64 loss: -2.0878000259399414
Batch 37/64 loss: -2.280104637145996
Batch 38/64 loss: -2.295257568359375
Batch 39/64 loss: -1.9171504974365234
Batch 40/64 loss: -2.3951234817504883
Batch 41/64 loss: -1.949641227722168
Batch 42/64 loss: -2.360955238342285
Batch 43/64 loss: -2.318373680114746
Batch 44/64 loss: -2.332294464111328
Batch 45/64 loss: -2.0567245483398438
Batch 46/64 loss: -2.1372337341308594
Batch 47/64 loss: -2.086709976196289
Batch 48/64 loss: -2.270772933959961
Batch 49/64 loss: -2.0786170959472656
Batch 50/64 loss: -2.408496856689453
Batch 51/64 loss: -1.8474063873291016
Batch 52/64 loss: -2.119626998901367
Batch 53/64 loss: -2.3385496139526367
Batch 54/64 loss: -2.2764291763305664
Batch 55/64 loss: -2.119635581970215
Batch 56/64 loss: -2.0062599182128906
Batch 57/64 loss: -2.0501832962036133
Batch 58/64 loss: -1.264174461364746
Batch 59/64 loss: -1.6724624633789062
Batch 60/64 loss: -1.902970314025879
Batch 61/64 loss: -2.048617362976074
Batch 62/64 loss: -1.883622169494629
Batch 63/64 loss: -1.9600954055786133
Batch 64/64 loss: -5.86214542388916
Epoch 141  Train loss: -2.2022000443701653  Val loss: -1.9565341988789666
Epoch 142
-------------------------------
Batch 1/64 loss: -1.9828643798828125
Batch 2/64 loss: -1.9941530227661133
Batch 3/64 loss: -2.2849502563476562
Batch 4/64 loss: -2.059938430786133
Batch 5/64 loss: -1.5488548278808594
Batch 6/64 loss: -1.793208122253418
Batch 7/64 loss: -2.0968074798583984
Batch 8/64 loss: -1.5390338897705078
Batch 9/64 loss: -1.8103466033935547
Batch 10/64 loss: -1.7991838455200195
Batch 11/64 loss: -2.2023134231567383
Batch 12/64 loss: -1.861250877380371
Batch 13/64 loss: -1.5938453674316406
Batch 14/64 loss: -2.092188835144043
Batch 15/64 loss: -2.1901044845581055
Batch 16/64 loss: -2.367340087890625
Batch 17/64 loss: -1.8849611282348633
Batch 18/64 loss: -1.8601312637329102
Batch 19/64 loss: -1.91802978515625
Batch 20/64 loss: -1.517181396484375
Batch 21/64 loss: -1.4446048736572266
Batch 22/64 loss: -2.140026092529297
Batch 23/64 loss: -2.02142333984375
Batch 24/64 loss: -2.04055118560791
Batch 25/64 loss: -2.001920700073242
Batch 26/64 loss: -1.6879806518554688
Batch 27/64 loss: -2.1193838119506836
Batch 28/64 loss: -2.205508232116699
Batch 29/64 loss: -2.0623722076416016
Batch 30/64 loss: -1.3745718002319336
Batch 31/64 loss: -1.454451560974121
Batch 32/64 loss: -1.5655450820922852
Batch 33/64 loss: -1.7695674896240234
Batch 34/64 loss: -2.1302547454833984
Batch 35/64 loss: -2.1216421127319336
Batch 36/64 loss: -1.6339597702026367
Batch 37/64 loss: -2.0688629150390625
Batch 38/64 loss: -1.8734159469604492
Batch 39/64 loss: -2.2037353515625
Batch 40/64 loss: -1.6025848388671875
Batch 41/64 loss: -2.294278144836426
Batch 42/64 loss: -2.074049949645996
Batch 43/64 loss: -2.0402469635009766
Batch 44/64 loss: -2.1399707794189453
Batch 45/64 loss: -2.1733665466308594
Batch 46/64 loss: -1.8737373352050781
Batch 47/64 loss: -1.7511796951293945
Batch 48/64 loss: -2.021402359008789
Batch 49/64 loss: -1.9855270385742188
Batch 50/64 loss: -1.9619474411010742
Batch 51/64 loss: -1.731694221496582
Batch 52/64 loss: -1.7137794494628906
Batch 53/64 loss: -2.249553680419922
Batch 54/64 loss: -2.1320409774780273
Batch 55/64 loss: -2.159255027770996
Batch 56/64 loss: -2.1694250106811523
Batch 57/64 loss: -1.881357192993164
Batch 58/64 loss: -1.9466047286987305
Batch 59/64 loss: -2.122945785522461
Batch 60/64 loss: -2.036362648010254
Batch 61/64 loss: -1.9892377853393555
Batch 62/64 loss: -2.443060874938965
Batch 63/64 loss: -2.1779823303222656
Batch 64/64 loss: -6.311577796936035
Epoch 142  Train loss: -2.003478267146092  Val loss: -2.2830597002481676
Epoch 143
-------------------------------
Batch 1/64 loss: -2.078338623046875
Batch 2/64 loss: -2.1448440551757812
Batch 3/64 loss: -2.1748743057250977
Batch 4/64 loss: -2.179194450378418
Batch 5/64 loss: -2.251946449279785
Batch 6/64 loss: -2.3904943466186523
Batch 7/64 loss: -2.312145233154297
Batch 8/64 loss: -2.0750045776367188
Batch 9/64 loss: -1.9552440643310547
Batch 10/64 loss: -1.9631919860839844
Batch 11/64 loss: -2.128345489501953
Batch 12/64 loss: -2.324504852294922
Batch 13/64 loss: -1.9673738479614258
Batch 14/64 loss: -2.464442253112793
Batch 15/64 loss: -1.8036432266235352
Batch 16/64 loss: -2.162750244140625
Batch 17/64 loss: -2.0726308822631836
Batch 18/64 loss: -1.9130268096923828
Batch 19/64 loss: -2.0841331481933594
Batch 20/64 loss: -1.9619064331054688
Batch 21/64 loss: -2.31522274017334
Batch 22/64 loss: -2.010347366333008
Batch 23/64 loss: -2.0804967880249023
Batch 24/64 loss: -2.1121301651000977
Batch 25/64 loss: -2.116715431213379
Batch 26/64 loss: -2.2362852096557617
Batch 27/64 loss: -2.405074119567871
Batch 28/64 loss: -2.00665283203125
Batch 29/64 loss: -2.1107969284057617
Batch 30/64 loss: -2.155305862426758
Batch 31/64 loss: -2.067415237426758
Batch 32/64 loss: -2.3273963928222656
Batch 33/64 loss: -2.227855682373047
Batch 34/64 loss: -2.1692514419555664
Batch 35/64 loss: -2.459774971008301
Batch 36/64 loss: -2.288137435913086
Batch 37/64 loss: -1.8299856185913086
Batch 38/64 loss: -2.0830326080322266
Batch 39/64 loss: -1.7490854263305664
Batch 40/64 loss: -2.2145538330078125
Batch 41/64 loss: -1.947164535522461
Batch 42/64 loss: -2.185845375061035
Batch 43/64 loss: -2.2117748260498047
Batch 44/64 loss: -1.4691524505615234
Batch 45/64 loss: -2.2382431030273438
Batch 46/64 loss: -2.172957420349121
Batch 47/64 loss: -2.163145065307617
Batch 48/64 loss: -2.144618034362793
Batch 49/64 loss: -2.340456962585449
Batch 50/64 loss: -1.755549430847168
Batch 51/64 loss: -2.2219810485839844
Batch 52/64 loss: -2.084181785583496
Batch 53/64 loss: -2.1911067962646484
Batch 54/64 loss: -2.3090476989746094
Batch 55/64 loss: -2.0706615447998047
Batch 56/64 loss: -2.259489059448242
Batch 57/64 loss: -2.222177505493164
Batch 58/64 loss: -2.08304500579834
Batch 59/64 loss: -2.3638248443603516
Batch 60/64 loss: -2.0466670989990234
Batch 61/64 loss: -1.8151445388793945
Batch 62/64 loss: -2.0427770614624023
Batch 63/64 loss: -1.9899864196777344
Batch 64/64 loss: -6.486353874206543
Epoch 143  Train loss: -2.173604931550867  Val loss: -2.2913024745036648
Epoch 144
-------------------------------
Batch 1/64 loss: -2.1351242065429688
Batch 2/64 loss: -2.092715263366699
Batch 3/64 loss: -1.9768486022949219
Batch 4/64 loss: -2.283503532409668
Batch 5/64 loss: -0.6084890365600586
Batch 6/64 loss: -1.5674800872802734
Batch 7/64 loss: -2.0980663299560547
Batch 8/64 loss: -2.124582290649414
Batch 9/64 loss: -1.5835952758789062
Batch 10/64 loss: -1.9465560913085938
Batch 11/64 loss: -2.284372329711914
Batch 12/64 loss: -1.7962989807128906
Batch 13/64 loss: -1.931248664855957
Batch 14/64 loss: -2.020920753479004
Batch 15/64 loss: -2.3422231674194336
Batch 16/64 loss: -2.282229423522949
Batch 17/64 loss: -1.9203948974609375
Batch 18/64 loss: -2.0639524459838867
Batch 19/64 loss: -1.9165191650390625
Batch 20/64 loss: -2.394402503967285
Batch 21/64 loss: -2.072263717651367
Batch 22/64 loss: -1.8112459182739258
Batch 23/64 loss: -2.227954864501953
Batch 24/64 loss: -2.3079891204833984
Batch 25/64 loss: -1.9111213684082031
Batch 26/64 loss: -2.145474433898926
Batch 27/64 loss: -1.750650405883789
Batch 28/64 loss: -2.095560073852539
Batch 29/64 loss: -2.0896759033203125
Batch 30/64 loss: -2.42728328704834
Batch 31/64 loss: -1.9888782501220703
Batch 32/64 loss: -2.116975784301758
Batch 33/64 loss: -2.110762596130371
Batch 34/64 loss: -1.928396224975586
Batch 35/64 loss: -2.3944177627563477
Batch 36/64 loss: -2.100247383117676
Batch 37/64 loss: -2.5404348373413086
Batch 38/64 loss: -2.4348068237304688
Batch 39/64 loss: -2.2723121643066406
Batch 40/64 loss: -2.2889394760131836
Batch 41/64 loss: -2.386293411254883
Batch 42/64 loss: -2.1044044494628906
Batch 43/64 loss: -2.1683168411254883
Batch 44/64 loss: -2.1077089309692383
Batch 45/64 loss: -1.8980140686035156
Batch 46/64 loss: -2.4790515899658203
Batch 47/64 loss: -2.167095184326172
Batch 48/64 loss: -2.1218481063842773
Batch 49/64 loss: -2.115945816040039
Batch 50/64 loss: -2.377765655517578
Batch 51/64 loss: -2.261916160583496
Batch 52/64 loss: -2.326401710510254
Batch 53/64 loss: -2.4288930892944336
Batch 54/64 loss: -2.2354726791381836
Batch 55/64 loss: -2.62288761138916
Batch 56/64 loss: -2.1509552001953125
Batch 57/64 loss: -1.6178226470947266
Batch 58/64 loss: -1.9985828399658203
Batch 59/64 loss: -1.4760751724243164
Batch 60/64 loss: -2.333950996398926
Batch 61/64 loss: -2.232503890991211
Batch 62/64 loss: -2.248257637023926
Batch 63/64 loss: -2.442211151123047
Batch 64/64 loss: -6.2100138664245605
Epoch 144  Train loss: -2.1544282146528655  Val loss: -2.486148716248188
Epoch 145
-------------------------------
Batch 1/64 loss: -2.418301582336426
Batch 2/64 loss: -2.1864852905273438
Batch 3/64 loss: -2.3176136016845703
Batch 4/64 loss: -2.389224052429199
Batch 5/64 loss: -2.1399307250976562
Batch 6/64 loss: -2.2894411087036133
Batch 7/64 loss: -2.086305618286133
Batch 8/64 loss: -1.7620468139648438
Batch 9/64 loss: -2.409862518310547
Batch 10/64 loss: -2.2713518142700195
Batch 11/64 loss: -2.4037694931030273
Batch 12/64 loss: -2.3020009994506836
Batch 13/64 loss: -2.1988525390625
Batch 14/64 loss: -2.4605960845947266
Batch 15/64 loss: -2.024449348449707
Batch 16/64 loss: -2.319626808166504
Batch 17/64 loss: -1.508988380432129
Batch 18/64 loss: -1.9695329666137695
Batch 19/64 loss: -2.375293731689453
Batch 20/64 loss: -2.3439855575561523
Batch 21/64 loss: -2.235581398010254
Batch 22/64 loss: -2.421253204345703
Batch 23/64 loss: -2.406336784362793
Batch 24/64 loss: -1.7852325439453125
Batch 25/64 loss: -2.2621774673461914
Batch 26/64 loss: -2.3858489990234375
Batch 27/64 loss: -2.153388023376465
Batch 28/64 loss: -2.140867233276367
Batch 29/64 loss: -2.4673290252685547
Batch 30/64 loss: -2.190913200378418
Batch 31/64 loss: -2.4543466567993164
Batch 32/64 loss: -2.3067140579223633
Batch 33/64 loss: -2.4970035552978516
Batch 34/64 loss: -2.080143928527832
Batch 35/64 loss: -2.091268539428711
Batch 36/64 loss: -2.0201416015625
Batch 37/64 loss: -2.330622673034668
Batch 38/64 loss: -2.2325820922851562
Batch 39/64 loss: -1.909775733947754
Batch 40/64 loss: -2.42343807220459
Batch 41/64 loss: -2.274677276611328
Batch 42/64 loss: -2.447024345397949
Batch 43/64 loss: -2.3939599990844727
Batch 44/64 loss: -2.1197404861450195
Batch 45/64 loss: -2.605386734008789
Batch 46/64 loss: -2.243281364440918
Batch 47/64 loss: -2.00972843170166
Batch 48/64 loss: -2.2005624771118164
Batch 49/64 loss: -2.102022171020508
Batch 50/64 loss: -1.7537422180175781
Batch 51/64 loss: -2.2129411697387695
Batch 52/64 loss: -2.171276092529297
Batch 53/64 loss: -2.11287784576416
Batch 54/64 loss: -2.079662322998047
Batch 55/64 loss: -2.206406593322754
Batch 56/64 loss: -2.4146499633789062
Batch 57/64 loss: -2.406754493713379
Batch 58/64 loss: -2.46639347076416
Batch 59/64 loss: -2.3521480560302734
Batch 60/64 loss: -2.1495895385742188
Batch 61/64 loss: -2.384476661682129
Batch 62/64 loss: -2.3990907669067383
Batch 63/64 loss: -2.2956771850585938
Batch 64/64 loss: -6.917314529418945
Epoch 145  Train loss: -2.289610657037473  Val loss: -2.569870270404619
Saving best model, epoch: 145
Epoch 146
-------------------------------
Batch 1/64 loss: -2.5908336639404297
Batch 2/64 loss: -2.494731903076172
Batch 3/64 loss: -1.8883228302001953
Batch 4/64 loss: -1.8318109512329102
Batch 5/64 loss: -2.1207056045532227
Batch 6/64 loss: -2.3433618545532227
Batch 7/64 loss: -2.0930585861206055
Batch 8/64 loss: -2.0898523330688477
Batch 9/64 loss: -2.0382280349731445
Batch 10/64 loss: -2.509291648864746
Batch 11/64 loss: -2.338986396789551
Batch 12/64 loss: -2.365696907043457
Batch 13/64 loss: -1.7905330657958984
Batch 14/64 loss: -2.465163230895996
Batch 15/64 loss: -2.414097785949707
Batch 16/64 loss: -2.2445573806762695
Batch 17/64 loss: -2.2646522521972656
Batch 18/64 loss: -2.2193965911865234
Batch 19/64 loss: -2.4621448516845703
Batch 20/64 loss: -2.0938453674316406
Batch 21/64 loss: -2.2102155685424805
Batch 22/64 loss: -2.248077392578125
Batch 23/64 loss: -2.463353157043457
Batch 24/64 loss: -2.106245994567871
Batch 25/64 loss: -1.9832592010498047
Batch 26/64 loss: -2.3638839721679688
Batch 27/64 loss: -2.355997085571289
Batch 28/64 loss: -2.395083427429199
Batch 29/64 loss: -2.199483871459961
Batch 30/64 loss: -2.0200328826904297
Batch 31/64 loss: -2.1512441635131836
Batch 32/64 loss: -2.306394577026367
Batch 33/64 loss: -2.4431915283203125
Batch 34/64 loss: -2.488924026489258
Batch 35/64 loss: -2.3038883209228516
Batch 36/64 loss: -2.351194381713867
Batch 37/64 loss: -2.5408458709716797
Batch 38/64 loss: -2.1949691772460938
Batch 39/64 loss: -2.3941869735717773
Batch 40/64 loss: -2.3753280639648438
Batch 41/64 loss: -2.2954063415527344
Batch 42/64 loss: -2.276089668273926
Batch 43/64 loss: -2.4814653396606445
Batch 44/64 loss: -2.5462636947631836
Batch 45/64 loss: -2.5040273666381836
Batch 46/64 loss: -2.5821895599365234
Batch 47/64 loss: -2.1808738708496094
Batch 48/64 loss: -2.060953140258789
Batch 49/64 loss: -2.3033952713012695
Batch 50/64 loss: -1.9461145401000977
Batch 51/64 loss: -2.2092761993408203
Batch 52/64 loss: -2.4420595169067383
Batch 53/64 loss: -2.324125289916992
Batch 54/64 loss: -1.8075065612792969
Batch 55/64 loss: -2.280599594116211
Batch 56/64 loss: -2.315502166748047
Batch 57/64 loss: -2.1539382934570312
Batch 58/64 loss: -2.3776473999023438
Batch 59/64 loss: -2.4749717712402344
Batch 60/64 loss: -2.184403419494629
Batch 61/64 loss: -1.7442054748535156
Batch 62/64 loss: -2.0669126510620117
Batch 63/64 loss: -2.382862091064453
Batch 64/64 loss: -6.772033214569092
Epoch 146  Train loss: -2.314900157030891  Val loss: -2.5896918306645658
Saving best model, epoch: 146
Epoch 147
-------------------------------
Batch 1/64 loss: -2.329287528991699
Batch 2/64 loss: -2.399298667907715
Batch 3/64 loss: -2.2268972396850586
Batch 4/64 loss: -2.1830739974975586
Batch 5/64 loss: -2.3767852783203125
Batch 6/64 loss: -2.261141777038574
Batch 7/64 loss: -2.2225608825683594
Batch 8/64 loss: -2.5355539321899414
Batch 9/64 loss: -2.249074935913086
Batch 10/64 loss: -2.156916618347168
Batch 11/64 loss: -2.3387393951416016
Batch 12/64 loss: -2.1797447204589844
Batch 13/64 loss: -2.357254981994629
Batch 14/64 loss: -2.1711063385009766
Batch 15/64 loss: -1.997511863708496
Batch 16/64 loss: -1.955348014831543
Batch 17/64 loss: -2.5201539993286133
Batch 18/64 loss: -2.3417625427246094
Batch 19/64 loss: -2.139242172241211
Batch 20/64 loss: -2.2104673385620117
Batch 21/64 loss: -2.312335968017578
Batch 22/64 loss: -2.3624486923217773
Batch 23/64 loss: -2.2766265869140625
Batch 24/64 loss: -2.479949951171875
Batch 25/64 loss: -2.356487274169922
Batch 26/64 loss: -2.3447093963623047
Batch 27/64 loss: -2.4951791763305664
Batch 28/64 loss: -2.299144744873047
Batch 29/64 loss: -2.439080238342285
Batch 30/64 loss: -1.9620494842529297
Batch 31/64 loss: -1.9001922607421875
Batch 32/64 loss: -2.237605094909668
Batch 33/64 loss: -2.3860349655151367
Batch 34/64 loss: -2.307246208190918
Batch 35/64 loss: -2.2861404418945312
Batch 36/64 loss: -2.2556962966918945
Batch 37/64 loss: -1.9012250900268555
Batch 38/64 loss: -1.7983121871948242
Batch 39/64 loss: -2.2821617126464844
Batch 40/64 loss: -2.250617027282715
Batch 41/64 loss: -2.3008174896240234
Batch 42/64 loss: -1.901768684387207
Batch 43/64 loss: -2.1646604537963867
Batch 44/64 loss: -2.227972984313965
Batch 45/64 loss: -2.316155433654785
Batch 46/64 loss: -2.091925621032715
Batch 47/64 loss: -2.3206663131713867
Batch 48/64 loss: -2.0229320526123047
Batch 49/64 loss: -2.392399787902832
Batch 50/64 loss: -2.3014326095581055
Batch 51/64 loss: -2.4212112426757812
Batch 52/64 loss: -2.232973098754883
Batch 53/64 loss: -2.240161895751953
Batch 54/64 loss: -2.30465030670166
Batch 55/64 loss: -2.516176223754883
Batch 56/64 loss: -2.2798643112182617
Batch 57/64 loss: -2.2601242065429688
Batch 58/64 loss: -2.3934574127197266
Batch 59/64 loss: -2.4535627365112305
Batch 60/64 loss: -2.482752799987793
Batch 61/64 loss: -2.2350101470947266
Batch 62/64 loss: -2.4172744750976562
Batch 63/64 loss: -2.466336250305176
Batch 64/64 loss: -6.979201316833496
Epoch 147  Train loss: -2.3225702360564586  Val loss: -2.4286934501936344
Epoch 148
-------------------------------
Batch 1/64 loss: -2.44851016998291
Batch 2/64 loss: -2.539335250854492
Batch 3/64 loss: -2.3638172149658203
Batch 4/64 loss: -2.5060291290283203
Batch 5/64 loss: -2.3430137634277344
Batch 6/64 loss: -1.9838685989379883
Batch 7/64 loss: -1.686356544494629
Batch 8/64 loss: -1.8278064727783203
Batch 9/64 loss: -2.2874345779418945
Batch 10/64 loss: -2.1838321685791016
Batch 11/64 loss: -2.0358810424804688
Batch 12/64 loss: -1.5032310485839844
Batch 13/64 loss: -2.248105049133301
Batch 14/64 loss: -2.5761489868164062
Batch 15/64 loss: -2.42901611328125
Batch 16/64 loss: -2.4849042892456055
Batch 17/64 loss: -2.1564159393310547
Batch 18/64 loss: -2.212368965148926
Batch 19/64 loss: -2.3103713989257812
Batch 20/64 loss: -2.310318946838379
Batch 21/64 loss: -2.446864128112793
Batch 22/64 loss: -2.5700464248657227
Batch 23/64 loss: -2.2598047256469727
Batch 24/64 loss: -2.1097946166992188
Batch 25/64 loss: -2.187023162841797
Batch 26/64 loss: -2.015408515930176
Batch 27/64 loss: -2.1559219360351562
Batch 28/64 loss: -2.6065759658813477
Batch 29/64 loss: -2.4752683639526367
Batch 30/64 loss: -2.0251588821411133
Batch 31/64 loss: -2.365200996398926
Batch 32/64 loss: -2.2294788360595703
Batch 33/64 loss: -2.4332008361816406
Batch 34/64 loss: -2.322317123413086
Batch 35/64 loss: -2.1530513763427734
Batch 36/64 loss: -2.0924081802368164
Batch 37/64 loss: -2.516071319580078
Batch 38/64 loss: -2.0049571990966797
Batch 39/64 loss: -2.1236190795898438
Batch 40/64 loss: -2.3376636505126953
Batch 41/64 loss: -2.441862106323242
Batch 42/64 loss: -1.983414649963379
Batch 43/64 loss: -2.008241653442383
Batch 44/64 loss: -2.469928741455078
Batch 45/64 loss: -2.3918542861938477
Batch 46/64 loss: -2.415360450744629
Batch 47/64 loss: -2.208073616027832
Batch 48/64 loss: -2.1838178634643555
Batch 49/64 loss: -1.9198999404907227
Batch 50/64 loss: -2.290426254272461
Batch 51/64 loss: -2.351822853088379
Batch 52/64 loss: -2.243600845336914
Batch 53/64 loss: -2.1674118041992188
Batch 54/64 loss: -2.128274917602539
Batch 55/64 loss: -2.334400177001953
Batch 56/64 loss: -2.200960159301758
Batch 57/64 loss: -2.4958019256591797
Batch 58/64 loss: -1.8096332550048828
Batch 59/64 loss: -2.2299861907958984
Batch 60/64 loss: -2.2379188537597656
Batch 61/64 loss: -2.362429618835449
Batch 62/64 loss: -1.9200162887573242
Batch 63/64 loss: -2.2057132720947266
Batch 64/64 loss: -6.503809928894043
Epoch 148  Train loss: -2.28620091232599  Val loss: -2.3659022091999904
Epoch 149
-------------------------------
Batch 1/64 loss: -2.2868709564208984
Batch 2/64 loss: -2.4124889373779297
Batch 3/64 loss: -1.731689453125
Batch 4/64 loss: -2.408632278442383
Batch 5/64 loss: -2.1510581970214844
Batch 6/64 loss: -1.998274803161621
Batch 7/64 loss: -2.014394760131836
Batch 8/64 loss: -2.256460189819336
Batch 9/64 loss: -2.5037498474121094
Batch 10/64 loss: -2.016538619995117
Batch 11/64 loss: -2.0648603439331055
Batch 12/64 loss: -2.1658458709716797
Batch 13/64 loss: -2.409198760986328
Batch 14/64 loss: -2.161815643310547
Batch 15/64 loss: -1.629420280456543
Batch 16/64 loss: -2.1100711822509766
Batch 17/64 loss: -2.02191162109375
Batch 18/64 loss: -2.3165502548217773
Batch 19/64 loss: -2.39111328125
Batch 20/64 loss: -2.1136903762817383
Batch 21/64 loss: -2.2673988342285156
Batch 22/64 loss: -2.3955183029174805
Batch 23/64 loss: -2.3028078079223633
Batch 24/64 loss: -2.128702163696289
Batch 25/64 loss: -2.4694910049438477
Batch 26/64 loss: -2.3890562057495117
Batch 27/64 loss: -2.2761316299438477
Batch 28/64 loss: -2.3205814361572266
Batch 29/64 loss: -2.342660903930664
Batch 30/64 loss: -2.2438602447509766
Batch 31/64 loss: -1.8276596069335938
Batch 32/64 loss: -2.0713748931884766
Batch 33/64 loss: -2.010268211364746
Batch 34/64 loss: -2.271249771118164
Batch 35/64 loss: -2.2321462631225586
Batch 36/64 loss: -2.3980026245117188
Batch 37/64 loss: -2.413698196411133
Batch 38/64 loss: -2.357699394226074
Batch 39/64 loss: -2.031308174133301
Batch 40/64 loss: -2.314812660217285
Batch 41/64 loss: -2.0943212509155273
Batch 42/64 loss: -2.03530216217041
Batch 43/64 loss: -2.2577590942382812
Batch 44/64 loss: -2.2151575088500977
Batch 45/64 loss: -1.605391502380371
Batch 46/64 loss: -2.134455680847168
Batch 47/64 loss: -2.334872245788574
Batch 48/64 loss: -1.2775373458862305
Batch 49/64 loss: -2.164915084838867
Batch 50/64 loss: -2.2263898849487305
Batch 51/64 loss: -2.164274215698242
Batch 52/64 loss: -2.4057188034057617
Batch 53/64 loss: -1.9087696075439453
Batch 54/64 loss: -2.4783143997192383
Batch 55/64 loss: -2.4132213592529297
Batch 56/64 loss: -1.9412298202514648
Batch 57/64 loss: -2.2371034622192383
Batch 58/64 loss: -2.3459701538085938
Batch 59/64 loss: -1.9851055145263672
Batch 60/64 loss: -2.2295989990234375
Batch 61/64 loss: -2.1168031692504883
Batch 62/64 loss: -2.3049983978271484
Batch 63/64 loss: -1.8596248626708984
Batch 64/64 loss: -6.678204536437988
Epoch 149  Train loss: -2.227051794762705  Val loss: -2.3667569897838474
Epoch 150
-------------------------------
Batch 1/64 loss: -2.2127809524536133
Batch 2/64 loss: -1.7806997299194336
Batch 3/64 loss: -2.302600860595703
Batch 4/64 loss: -1.7068815231323242
Batch 5/64 loss: -2.3480405807495117
Batch 6/64 loss: -2.3595361709594727
Batch 7/64 loss: -2.281871795654297
Batch 8/64 loss: -2.1730146408081055
Batch 9/64 loss: -2.5701723098754883
Batch 10/64 loss: -1.9984359741210938
Batch 11/64 loss: -1.8051633834838867
Batch 12/64 loss: -2.4830846786499023
Batch 13/64 loss: -2.2400569915771484
Batch 14/64 loss: -2.552607536315918
Batch 15/64 loss: -2.2637624740600586
Batch 16/64 loss: -2.307662010192871
Batch 17/64 loss: -2.019742012023926
Batch 18/64 loss: -2.3778562545776367
Batch 19/64 loss: -2.410325050354004
Batch 20/64 loss: -2.053311347961426
Batch 21/64 loss: -2.219052314758301
Batch 22/64 loss: -2.35660457611084
Batch 23/64 loss: -2.4032278060913086
Batch 24/64 loss: -2.325458526611328
Batch 25/64 loss: -2.298577308654785
Batch 26/64 loss: -2.092095375061035
Batch 27/64 loss: -2.325244903564453
Batch 28/64 loss: -2.25924015045166
Batch 29/64 loss: -2.031007766723633
Batch 30/64 loss: -2.2970447540283203
Batch 31/64 loss: -2.373777389526367
Batch 32/64 loss: -2.208104133605957
Batch 33/64 loss: -2.4632081985473633
Batch 34/64 loss: -2.2095117568969727
Batch 35/64 loss: -2.2845535278320312
Batch 36/64 loss: -2.4163637161254883
Batch 37/64 loss: -2.4178314208984375
Batch 38/64 loss: -2.32208251953125
Batch 39/64 loss: -2.099142074584961
Batch 40/64 loss: -2.26113224029541
Batch 41/64 loss: -1.9102697372436523
Batch 42/64 loss: -2.165106773376465
Batch 43/64 loss: -2.157689094543457
Batch 44/64 loss: -2.1606969833374023
Batch 45/64 loss: -1.9518060684204102
Batch 46/64 loss: -2.180630683898926
Batch 47/64 loss: -2.185537338256836
Batch 48/64 loss: -2.288701057434082
Batch 49/64 loss: -2.436690330505371
Batch 50/64 loss: -2.258822441101074
Batch 51/64 loss: -2.160649299621582
Batch 52/64 loss: -2.110415458679199
Batch 53/64 loss: -2.469205856323242
Batch 54/64 loss: -2.098141670227051
Batch 55/64 loss: -2.2349443435668945
Batch 56/64 loss: -2.0715818405151367
Batch 57/64 loss: -2.0604982376098633
Batch 58/64 loss: -2.281155586242676
Batch 59/64 loss: -2.1256608963012695
Batch 60/64 loss: -2.4437665939331055
Batch 61/64 loss: -2.132802963256836
Batch 62/64 loss: -1.868016242980957
Batch 63/64 loss: -2.093128204345703
Batch 64/64 loss: -6.8421525955200195
Epoch 150  Train loss: -2.2727591982074813  Val loss: -2.4574947553811612
Epoch 151
-------------------------------
Batch 1/64 loss: -2.301664352416992
Batch 2/64 loss: -2.1659278869628906
Batch 3/64 loss: -2.39202880859375
Batch 4/64 loss: -2.338033676147461
Batch 5/64 loss: -2.087904930114746
Batch 6/64 loss: -2.214015007019043
Batch 7/64 loss: -2.2907323837280273
Batch 8/64 loss: -1.6392316818237305
Batch 9/64 loss: -2.1121225357055664
Batch 10/64 loss: -2.1794281005859375
Batch 11/64 loss: -2.06583309173584
Batch 12/64 loss: -2.6048707962036133
Batch 13/64 loss: -2.3704776763916016
Batch 14/64 loss: -2.1802568435668945
Batch 15/64 loss: -2.4996566772460938
Batch 16/64 loss: -2.039095878601074
Batch 17/64 loss: -2.2894086837768555
Batch 18/64 loss: -2.176669120788574
Batch 19/64 loss: -2.2332963943481445
Batch 20/64 loss: -1.9808483123779297
Batch 21/64 loss: -2.428647041320801
Batch 22/64 loss: -2.304983139038086
Batch 23/64 loss: -1.962423324584961
Batch 24/64 loss: -1.656829833984375
Batch 25/64 loss: -2.272343635559082
Batch 26/64 loss: -2.3626251220703125
Batch 27/64 loss: -2.418210029602051
Batch 28/64 loss: -2.6150875091552734
Batch 29/64 loss: -2.291900634765625
Batch 30/64 loss: -2.171900749206543
Batch 31/64 loss: -2.5154037475585938
Batch 32/64 loss: -2.312434196472168
Batch 33/64 loss: -2.257502555847168
Batch 34/64 loss: -2.3422107696533203
Batch 35/64 loss: -2.1823043823242188
Batch 36/64 loss: -1.9099798202514648
Batch 37/64 loss: -2.2660741806030273
Batch 38/64 loss: -2.27230167388916
Batch 39/64 loss: -2.376981735229492
Batch 40/64 loss: -2.378443717956543
Batch 41/64 loss: -2.4180526733398438
Batch 42/64 loss: -2.5491294860839844
Batch 43/64 loss: -2.0278501510620117
Batch 44/64 loss: -2.3709373474121094
Batch 45/64 loss: -2.3389511108398438
Batch 46/64 loss: -2.408815383911133
Batch 47/64 loss: -2.512692451477051
Batch 48/64 loss: -2.055478096008301
Batch 49/64 loss: -2.403301239013672
Batch 50/64 loss: -2.37381649017334
Batch 51/64 loss: -2.3443613052368164
Batch 52/64 loss: -1.7563467025756836
Batch 53/64 loss: -2.2186098098754883
Batch 54/64 loss: -2.2966508865356445
Batch 55/64 loss: -2.3329524993896484
Batch 56/64 loss: -2.267610549926758
Batch 57/64 loss: -2.227566719055176
Batch 58/64 loss: -2.432061195373535
Batch 59/64 loss: -2.555882453918457
Batch 60/64 loss: -2.2295150756835938
Batch 61/64 loss: -2.2569713592529297
Batch 62/64 loss: -1.7455387115478516
Batch 63/64 loss: -2.4105024337768555
Batch 64/64 loss: -6.924308776855469
Epoch 151  Train loss: -2.3088143741383274  Val loss: -2.5634539758216883
Epoch 152
-------------------------------
Batch 1/64 loss: -2.4590139389038086
Batch 2/64 loss: -1.822336196899414
Batch 3/64 loss: -2.431208610534668
Batch 4/64 loss: -2.3773021697998047
Batch 5/64 loss: -2.2165164947509766
Batch 6/64 loss: -2.3314971923828125
Batch 7/64 loss: -2.309847831726074
Batch 8/64 loss: -2.328197479248047
Batch 9/64 loss: -2.5886220932006836
Batch 10/64 loss: -2.236438751220703
Batch 11/64 loss: -2.211132049560547
Batch 12/64 loss: -2.5132598876953125
Batch 13/64 loss: -2.324512481689453
Batch 14/64 loss: -2.3354663848876953
Batch 15/64 loss: -2.3707399368286133
Batch 16/64 loss: -2.2347593307495117
Batch 17/64 loss: -2.294734001159668
Batch 18/64 loss: -1.8473138809204102
Batch 19/64 loss: -2.470132827758789
Batch 20/64 loss: -2.337822914123535
Batch 21/64 loss: -2.3946542739868164
Batch 22/64 loss: -2.3049440383911133
Batch 23/64 loss: -2.2774438858032227
Batch 24/64 loss: -2.413747787475586
Batch 25/64 loss: -2.2588605880737305
Batch 26/64 loss: -2.258892059326172
Batch 27/64 loss: -2.3861818313598633
Batch 28/64 loss: -2.403498649597168
Batch 29/64 loss: -2.232532501220703
Batch 30/64 loss: -2.168593406677246
Batch 31/64 loss: -1.9465141296386719
Batch 32/64 loss: -2.2299184799194336
Batch 33/64 loss: -2.1839399337768555
Batch 34/64 loss: -2.4177865982055664
Batch 35/64 loss: -2.242274284362793
Batch 36/64 loss: -2.3401222229003906
Batch 37/64 loss: -1.7488365173339844
Batch 38/64 loss: -2.4838476181030273
Batch 39/64 loss: -2.596261978149414
Batch 40/64 loss: -2.311041831970215
Batch 41/64 loss: -2.2808284759521484
Batch 42/64 loss: -2.545684814453125
Batch 43/64 loss: -2.2953720092773438
Batch 44/64 loss: -2.287550926208496
Batch 45/64 loss: -2.4081506729125977
Batch 46/64 loss: -2.5205488204956055
Batch 47/64 loss: -2.4993972778320312
Batch 48/64 loss: -2.4536571502685547
Batch 49/64 loss: -2.3940887451171875
Batch 50/64 loss: -2.334610939025879
Batch 51/64 loss: -2.0893678665161133
Batch 52/64 loss: -2.288166046142578
Batch 53/64 loss: -1.8870534896850586
Batch 54/64 loss: -2.258355140686035
Batch 55/64 loss: -2.3532495498657227
Batch 56/64 loss: -2.1240501403808594
Batch 57/64 loss: -2.397200584411621
Batch 58/64 loss: -2.0979270935058594
Batch 59/64 loss: -2.490335464477539
Batch 60/64 loss: -2.369039535522461
Batch 61/64 loss: -2.4498300552368164
Batch 62/64 loss: -2.517855644226074
Batch 63/64 loss: -2.257552146911621
Batch 64/64 loss: -6.422657012939453
Epoch 152  Train loss: -2.3538449006922106  Val loss: -2.520592325741483
Epoch 153
-------------------------------
Batch 1/64 loss: -2.5325889587402344
Batch 2/64 loss: -2.259270668029785
Batch 3/64 loss: -2.451277732849121
Batch 4/64 loss: -2.136941909790039
Batch 5/64 loss: -2.536823272705078
Batch 6/64 loss: -2.220036506652832
Batch 7/64 loss: -2.156047821044922
Batch 8/64 loss: -2.529611587524414
Batch 9/64 loss: -2.390810966491699
Batch 10/64 loss: -2.493408203125
Batch 11/64 loss: -2.402585983276367
Batch 12/64 loss: -2.255208969116211
Batch 13/64 loss: -2.2613906860351562
Batch 14/64 loss: -2.3297033309936523
Batch 15/64 loss: -2.406238555908203
Batch 16/64 loss: -1.9546833038330078
Batch 17/64 loss: -2.3628644943237305
Batch 18/64 loss: -2.2730655670166016
Batch 19/64 loss: -2.2213354110717773
Batch 20/64 loss: -2.4121856689453125
Batch 21/64 loss: -2.4843358993530273
Batch 22/64 loss: -2.1576929092407227
Batch 23/64 loss: -2.418807029724121
Batch 24/64 loss: -2.6358022689819336
Batch 25/64 loss: -2.5736560821533203
Batch 26/64 loss: -2.3637866973876953
Batch 27/64 loss: -2.4178504943847656
Batch 28/64 loss: -2.0335731506347656
Batch 29/64 loss: -2.486001968383789
Batch 30/64 loss: -2.238884925842285
Batch 31/64 loss: -2.3724441528320312
Batch 32/64 loss: -2.56722354888916
Batch 33/64 loss: -2.2900867462158203
Batch 34/64 loss: -1.922196388244629
Batch 35/64 loss: -2.3802261352539062
Batch 36/64 loss: -2.0935020446777344
Batch 37/64 loss: -2.3517656326293945
Batch 38/64 loss: -1.886946678161621
Batch 39/64 loss: -2.215273857116699
Batch 40/64 loss: -2.3874006271362305
Batch 41/64 loss: -2.441211700439453
Batch 42/64 loss: -2.368922233581543
Batch 43/64 loss: -2.0070295333862305
Batch 44/64 loss: -2.234602928161621
Batch 45/64 loss: -2.3510799407958984
Batch 46/64 loss: -2.3563232421875
Batch 47/64 loss: -2.211869239807129
Batch 48/64 loss: -2.316094398498535
Batch 49/64 loss: -2.181802749633789
Batch 50/64 loss: -2.1913957595825195
Batch 51/64 loss: -2.3860292434692383
Batch 52/64 loss: -2.044919013977051
Batch 53/64 loss: -2.218796730041504
Batch 54/64 loss: -2.181654930114746
Batch 55/64 loss: -2.499802589416504
Batch 56/64 loss: -2.1496334075927734
Batch 57/64 loss: -1.6548662185668945
Batch 58/64 loss: -2.406561851501465
Batch 59/64 loss: -2.4550552368164062
Batch 60/64 loss: -2.4785070419311523
Batch 61/64 loss: -2.226530075073242
Batch 62/64 loss: -2.098555564880371
Batch 63/64 loss: -2.40799617767334
Batch 64/64 loss: -6.646955490112305
Epoch 153  Train loss: -2.3485175413243913  Val loss: -2.5379933491605255
Epoch 154
-------------------------------
Batch 1/64 loss: -1.8453502655029297
Batch 2/64 loss: -2.1669912338256836
Batch 3/64 loss: -2.4392995834350586
Batch 4/64 loss: -2.2835540771484375
Batch 5/64 loss: -2.272136688232422
Batch 6/64 loss: -1.4847040176391602
Batch 7/64 loss: -2.3275928497314453
Batch 8/64 loss: -1.8981304168701172
Batch 9/64 loss: -2.472235679626465
Batch 10/64 loss: -2.369950294494629
Batch 11/64 loss: -2.4679956436157227
Batch 12/64 loss: -2.4730701446533203
Batch 13/64 loss: -2.1821250915527344
Batch 14/64 loss: -2.2615928649902344
Batch 15/64 loss: -2.2890396118164062
Batch 16/64 loss: -2.2851486206054688
Batch 17/64 loss: -1.6997041702270508
Batch 18/64 loss: -2.581266403198242
Batch 19/64 loss: -2.159799575805664
Batch 20/64 loss: -2.2954931259155273
Batch 21/64 loss: -2.118882179260254
Batch 22/64 loss: -2.4443559646606445
Batch 23/64 loss: -2.472391128540039
Batch 24/64 loss: -2.390627861022949
Batch 25/64 loss: -2.065084457397461
Batch 26/64 loss: -2.005337715148926
Batch 27/64 loss: -2.5185251235961914
Batch 28/64 loss: -2.195310592651367
Batch 29/64 loss: -2.3552846908569336
Batch 30/64 loss: -2.2406415939331055
Batch 31/64 loss: -2.635814666748047
Batch 32/64 loss: -2.423093795776367
Batch 33/64 loss: -2.5813331604003906
Batch 34/64 loss: -1.9694833755493164
Batch 35/64 loss: -2.1596622467041016
Batch 36/64 loss: -2.0688581466674805
Batch 37/64 loss: -2.20794677734375
Batch 38/64 loss: -2.5380706787109375
Batch 39/64 loss: -2.564084053039551
Batch 40/64 loss: -2.3872900009155273
Batch 41/64 loss: -2.382113456726074
Batch 42/64 loss: -2.246396064758301
Batch 43/64 loss: -2.379261016845703
Batch 44/64 loss: -2.3611278533935547
Batch 45/64 loss: -2.3990049362182617
Batch 46/64 loss: -2.2858333587646484
Batch 47/64 loss: -1.8932008743286133
Batch 48/64 loss: -1.9571533203125
Batch 49/64 loss: -2.230588912963867
Batch 50/64 loss: -2.2923812866210938
Batch 51/64 loss: -2.207818031311035
Batch 52/64 loss: -2.2848024368286133
Batch 53/64 loss: -2.237285614013672
Batch 54/64 loss: -2.262505531311035
Batch 55/64 loss: -2.0998010635375977
Batch 56/64 loss: -1.9155206680297852
Batch 57/64 loss: -2.2154054641723633
Batch 58/64 loss: -2.0268373489379883
Batch 59/64 loss: -2.149825096130371
Batch 60/64 loss: -2.4264469146728516
Batch 61/64 loss: -2.5206480026245117
Batch 62/64 loss: -2.3470277786254883
Batch 63/64 loss: -2.29709529876709
Batch 64/64 loss: -6.502597808837891
Epoch 154  Train loss: -2.304192741244447  Val loss: -2.4211039461221073
Epoch 155
-------------------------------
Batch 1/64 loss: -2.513547897338867
Batch 2/64 loss: -2.0007476806640625
Batch 3/64 loss: -2.26705265045166
Batch 4/64 loss: -2.241217613220215
Batch 5/64 loss: -1.7689533233642578
Batch 6/64 loss: -2.165660858154297
Batch 7/64 loss: -2.319133758544922
Batch 8/64 loss: -1.9811391830444336
Batch 9/64 loss: -2.262960433959961
Batch 10/64 loss: -2.037626266479492
Batch 11/64 loss: -2.3580408096313477
Batch 12/64 loss: -2.14919376373291
Batch 13/64 loss: -2.3487424850463867
Batch 14/64 loss: -2.5286340713500977
Batch 15/64 loss: -2.027176856994629
Batch 16/64 loss: -1.9141473770141602
Batch 17/64 loss: -2.2424097061157227
Batch 18/64 loss: -1.9854869842529297
Batch 19/64 loss: -2.376265525817871
Batch 20/64 loss: -2.242579460144043
Batch 21/64 loss: -2.488541603088379
Batch 22/64 loss: -2.2543277740478516
Batch 23/64 loss: -2.4552345275878906
Batch 24/64 loss: -1.9721708297729492
Batch 25/64 loss: -1.8580141067504883
Batch 26/64 loss: -2.3092613220214844
Batch 27/64 loss: -1.9509973526000977
Batch 28/64 loss: -2.350203514099121
Batch 29/64 loss: -2.6019420623779297
Batch 30/64 loss: -2.3080577850341797
Batch 31/64 loss: -2.331777572631836
Batch 32/64 loss: -2.2137651443481445
Batch 33/64 loss: -2.32879638671875
Batch 34/64 loss: -2.2401857376098633
Batch 35/64 loss: -2.00864315032959
Batch 36/64 loss: -2.400562286376953
Batch 37/64 loss: -2.42911434173584
Batch 38/64 loss: -2.225640296936035
Batch 39/64 loss: -2.293333053588867
Batch 40/64 loss: -2.2747621536254883
Batch 41/64 loss: -1.6834392547607422
Batch 42/64 loss: -2.238191604614258
Batch 43/64 loss: -2.391343116760254
Batch 44/64 loss: -2.0781335830688477
Batch 45/64 loss: -2.250227928161621
Batch 46/64 loss: -2.3549671173095703
Batch 47/64 loss: -2.170663833618164
Batch 48/64 loss: -1.6589155197143555
Batch 49/64 loss: -2.396456718444824
Batch 50/64 loss: -2.2013731002807617
Batch 51/64 loss: -1.9840116500854492
Batch 52/64 loss: -2.143019676208496
Batch 53/64 loss: -2.363473892211914
Batch 54/64 loss: -2.585728645324707
Batch 55/64 loss: -2.338578224182129
Batch 56/64 loss: -2.02915096282959
Batch 57/64 loss: -1.977799415588379
Batch 58/64 loss: -2.3041534423828125
Batch 59/64 loss: -2.349888801574707
Batch 60/64 loss: -2.08705997467041
Batch 61/64 loss: -2.198108673095703
Batch 62/64 loss: -2.2050533294677734
Batch 63/64 loss: -2.5204086303710938
Batch 64/64 loss: -6.998868465423584
Epoch 155  Train loss: -2.2711426847121294  Val loss: -2.554385614559003
Epoch 156
-------------------------------
Batch 1/64 loss: -2.1917991638183594
Batch 2/64 loss: -2.5466699600219727
Batch 3/64 loss: -2.3682613372802734
Batch 4/64 loss: -2.158066749572754
Batch 5/64 loss: -2.3334741592407227
Batch 6/64 loss: -2.380600929260254
Batch 7/64 loss: -1.9287357330322266
Batch 8/64 loss: -2.367015838623047
Batch 9/64 loss: -2.4416284561157227
Batch 10/64 loss: -2.2247676849365234
Batch 11/64 loss: -2.095980644226074
Batch 12/64 loss: -2.454029083251953
Batch 13/64 loss: -2.3211145401000977
Batch 14/64 loss: -2.428068161010742
Batch 15/64 loss: -2.257312774658203
Batch 16/64 loss: -2.265316963195801
Batch 17/64 loss: -2.271707534790039
Batch 18/64 loss: -2.208388328552246
Batch 19/64 loss: -2.3949174880981445
Batch 20/64 loss: -2.3514671325683594
Batch 21/64 loss: -1.7013940811157227
Batch 22/64 loss: -1.942530632019043
Batch 23/64 loss: -2.2896947860717773
Batch 24/64 loss: -1.9037704467773438
Batch 25/64 loss: -2.601956367492676
Batch 26/64 loss: -2.452016830444336
Batch 27/64 loss: -2.4394006729125977
Batch 28/64 loss: -2.334336280822754
Batch 29/64 loss: -2.455423355102539
Batch 30/64 loss: -2.372652053833008
Batch 31/64 loss: -2.2992210388183594
Batch 32/64 loss: -2.3689050674438477
Batch 33/64 loss: -2.3271522521972656
Batch 34/64 loss: -1.8570823669433594
Batch 35/64 loss: -2.3600692749023438
Batch 36/64 loss: -2.4301605224609375
Batch 37/64 loss: -2.5040388107299805
Batch 38/64 loss: -2.2170801162719727
Batch 39/64 loss: -2.283278465270996
Batch 40/64 loss: -1.9126243591308594
Batch 41/64 loss: -2.4716901779174805
Batch 42/64 loss: -2.3310680389404297
Batch 43/64 loss: -2.139139175415039
Batch 44/64 loss: -2.365938186645508
Batch 45/64 loss: -2.0626707077026367
Batch 46/64 loss: -1.9884443283081055
Batch 47/64 loss: -2.433237075805664
Batch 48/64 loss: -2.0333681106567383
Batch 49/64 loss: -2.3366565704345703
Batch 50/64 loss: -2.189356803894043
Batch 51/64 loss: -2.3909225463867188
Batch 52/64 loss: -2.270419120788574
Batch 53/64 loss: -2.136651039123535
Batch 54/64 loss: -2.360269546508789
Batch 55/64 loss: -2.1407814025878906
Batch 56/64 loss: -2.020946502685547
Batch 57/64 loss: -2.416571617126465
Batch 58/64 loss: -2.420785903930664
Batch 59/64 loss: -1.7171592712402344
Batch 60/64 loss: -2.177395820617676
Batch 61/64 loss: -2.3236846923828125
Batch 62/64 loss: -2.194181442260742
Batch 63/64 loss: -2.2765798568725586
Batch 64/64 loss: -6.968724250793457
Epoch 156  Train loss: -2.3132011226579254  Val loss: -2.550722705539559
Epoch 157
-------------------------------
Batch 1/64 loss: -2.2239532470703125
Batch 2/64 loss: -2.149277687072754
Batch 3/64 loss: -2.255385398864746
Batch 4/64 loss: -2.3686790466308594
Batch 5/64 loss: -2.5576562881469727
Batch 6/64 loss: -2.0105209350585938
Batch 7/64 loss: -2.247746467590332
Batch 8/64 loss: -2.192460060119629
Batch 9/64 loss: -2.26318359375
Batch 10/64 loss: -2.2619266510009766
Batch 11/64 loss: -2.569352149963379
Batch 12/64 loss: -2.377835273742676
Batch 13/64 loss: -2.3417015075683594
Batch 14/64 loss: -2.4693946838378906
Batch 15/64 loss: -2.230012893676758
Batch 16/64 loss: -2.361368179321289
Batch 17/64 loss: -2.116893768310547
Batch 18/64 loss: -1.5608854293823242
Batch 19/64 loss: -2.367342948913574
Batch 20/64 loss: -1.8659591674804688
Batch 21/64 loss: -2.503885269165039
Batch 22/64 loss: -2.2492780685424805
Batch 23/64 loss: -2.347926139831543
Batch 24/64 loss: -2.3194808959960938
Batch 25/64 loss: -2.49367618560791
Batch 26/64 loss: -2.1788692474365234
Batch 27/64 loss: -2.4405441284179688
Batch 28/64 loss: -2.5468931198120117
Batch 29/64 loss: -2.6144533157348633
Batch 30/64 loss: -2.362399101257324
Batch 31/64 loss: -2.122163772583008
Batch 32/64 loss: -2.476559638977051
Batch 33/64 loss: -2.2376699447631836
Batch 34/64 loss: -2.3187246322631836
Batch 35/64 loss: -2.4229469299316406
Batch 36/64 loss: -2.0358400344848633
Batch 37/64 loss: -2.6050233840942383
Batch 38/64 loss: -1.6519393920898438
Batch 39/64 loss: -2.5813283920288086
Batch 40/64 loss: -2.599672317504883
Batch 41/64 loss: -2.356618881225586
Batch 42/64 loss: -2.481721878051758
Batch 43/64 loss: -2.437924385070801
Batch 44/64 loss: -2.352174758911133
Batch 45/64 loss: -2.525930404663086
Batch 46/64 loss: -2.39572811126709
Batch 47/64 loss: -2.4560060501098633
Batch 48/64 loss: -2.19077205657959
Batch 49/64 loss: -2.273378372192383
Batch 50/64 loss: -2.551647186279297
Batch 51/64 loss: -2.3772335052490234
Batch 52/64 loss: -2.693889617919922
Batch 53/64 loss: -2.502382278442383
Batch 54/64 loss: -2.337909698486328
Batch 55/64 loss: -2.1829662322998047
Batch 56/64 loss: -2.5775556564331055
Batch 57/64 loss: -2.3607940673828125
Batch 58/64 loss: -2.337552070617676
Batch 59/64 loss: -2.199270248413086
Batch 60/64 loss: -2.383289337158203
Batch 61/64 loss: -2.250112533569336
Batch 62/64 loss: -2.479985237121582
Batch 63/64 loss: -2.2727155685424805
Batch 64/64 loss: -6.943683624267578
Epoch 157  Train loss: -2.3856647865445004  Val loss: -2.5297542060773397
Epoch 158
-------------------------------
Batch 1/64 loss: -2.4303722381591797
Batch 2/64 loss: -2.2273921966552734
Batch 3/64 loss: -2.2818689346313477
Batch 4/64 loss: -2.2584667205810547
Batch 5/64 loss: -2.4795570373535156
Batch 6/64 loss: -2.139266014099121
Batch 7/64 loss: -2.6898584365844727
Batch 8/64 loss: -2.549274444580078
Batch 9/64 loss: -2.399494171142578
Batch 10/64 loss: -2.149397850036621
Batch 11/64 loss: -2.1399192810058594
Batch 12/64 loss: -2.1071977615356445
Batch 13/64 loss: -2.242007255554199
Batch 14/64 loss: -2.127674102783203
Batch 15/64 loss: -2.5193986892700195
Batch 16/64 loss: -2.4548072814941406
Batch 17/64 loss: -2.305922508239746
Batch 18/64 loss: -2.172060012817383
Batch 19/64 loss: -2.4275503158569336
Batch 20/64 loss: -2.398630142211914
Batch 21/64 loss: -2.2216596603393555
Batch 22/64 loss: -2.443526268005371
Batch 23/64 loss: -2.509829521179199
Batch 24/64 loss: -2.273484230041504
Batch 25/64 loss: -2.4130773544311523
Batch 26/64 loss: -2.326305389404297
Batch 27/64 loss: -2.361919403076172
Batch 28/64 loss: -2.452914237976074
Batch 29/64 loss: -2.1796092987060547
Batch 30/64 loss: -2.1757020950317383
Batch 31/64 loss: -2.413519859313965
Batch 32/64 loss: -1.7760906219482422
Batch 33/64 loss: -2.45797061920166
Batch 34/64 loss: -2.267658233642578
Batch 35/64 loss: -2.2372217178344727
Batch 36/64 loss: -2.3272781372070312
Batch 37/64 loss: -2.372417449951172
Batch 38/64 loss: -2.189197540283203
Batch 39/64 loss: -2.551187515258789
Batch 40/64 loss: -2.3856096267700195
Batch 41/64 loss: -2.340188980102539
Batch 42/64 loss: -2.25518798828125
Batch 43/64 loss: -2.242746353149414
Batch 44/64 loss: -2.7333269119262695
Batch 45/64 loss: -1.956003189086914
Batch 46/64 loss: -2.231503486633301
Batch 47/64 loss: -2.2702770233154297
Batch 48/64 loss: -2.385425567626953
Batch 49/64 loss: -2.4569854736328125
Batch 50/64 loss: -2.3987951278686523
Batch 51/64 loss: -2.385763168334961
Batch 52/64 loss: -2.2453994750976562
Batch 53/64 loss: -2.252582550048828
Batch 54/64 loss: -2.35225772857666
Batch 55/64 loss: -2.3352394104003906
Batch 56/64 loss: -2.55112361907959
Batch 57/64 loss: -2.4064645767211914
Batch 58/64 loss: -2.369699478149414
Batch 59/64 loss: -2.450802803039551
Batch 60/64 loss: -2.1524314880371094
Batch 61/64 loss: -2.285125732421875
Batch 62/64 loss: -2.4361343383789062
Batch 63/64 loss: -2.4409379959106445
Batch 64/64 loss: -6.785070419311523
Epoch 158  Train loss: -2.3821097953646793  Val loss: -2.564546775162425
Epoch 159
-------------------------------
Batch 1/64 loss: -2.453550338745117
Batch 2/64 loss: -2.152545928955078
Batch 3/64 loss: -2.5116262435913086
Batch 4/64 loss: -2.221029281616211
Batch 5/64 loss: -2.4092397689819336
Batch 6/64 loss: -1.9971294403076172
Batch 7/64 loss: -2.261507034301758
Batch 8/64 loss: -2.2558412551879883
Batch 9/64 loss: -2.03460693359375
Batch 10/64 loss: -2.4977426528930664
Batch 11/64 loss: -2.210437774658203
Batch 12/64 loss: -2.4212121963500977
Batch 13/64 loss: -2.5216903686523438
Batch 14/64 loss: -2.3714427947998047
Batch 15/64 loss: -2.479206085205078
Batch 16/64 loss: -2.329209327697754
Batch 17/64 loss: -2.3426733016967773
Batch 18/64 loss: -2.577853202819824
Batch 19/64 loss: -2.452299118041992
Batch 20/64 loss: -2.4955224990844727
Batch 21/64 loss: -2.478940963745117
Batch 22/64 loss: -2.254199981689453
Batch 23/64 loss: -2.268887519836426
Batch 24/64 loss: -2.271951675415039
Batch 25/64 loss: -2.0699968338012695
Batch 26/64 loss: -2.408015251159668
Batch 27/64 loss: -2.4059009552001953
Batch 28/64 loss: -2.200589179992676
Batch 29/64 loss: -2.4707698822021484
Batch 30/64 loss: -2.4368276596069336
Batch 31/64 loss: -2.2999801635742188
Batch 32/64 loss: -2.41060733795166
Batch 33/64 loss: -2.120856285095215
Batch 34/64 loss: -2.3918371200561523
Batch 35/64 loss: -2.301259994506836
Batch 36/64 loss: -2.2647342681884766
Batch 37/64 loss: -2.457691192626953
Batch 38/64 loss: -2.4785146713256836
Batch 39/64 loss: -2.389261245727539
Batch 40/64 loss: -2.28330135345459
Batch 41/64 loss: -2.4996871948242188
Batch 42/64 loss: -2.2242164611816406
Batch 43/64 loss: -2.511277198791504
Batch 44/64 loss: -2.500469207763672
Batch 45/64 loss: -2.3351869583129883
Batch 46/64 loss: -2.0061445236206055
Batch 47/64 loss: -2.076108932495117
Batch 48/64 loss: -2.322747230529785
Batch 49/64 loss: -2.273261070251465
Batch 50/64 loss: -2.24300479888916
Batch 51/64 loss: -2.344590187072754
Batch 52/64 loss: -2.2218265533447266
Batch 53/64 loss: -1.9682998657226562
Batch 54/64 loss: -1.672886848449707
Batch 55/64 loss: -2.315095901489258
Batch 56/64 loss: -2.345417022705078
Batch 57/64 loss: -2.0105323791503906
Batch 58/64 loss: -2.402982711791992
Batch 59/64 loss: -2.5132246017456055
Batch 60/64 loss: -2.241567611694336
Batch 61/64 loss: -2.1522884368896484
Batch 62/64 loss: -2.2766427993774414
Batch 63/64 loss: -1.9959297180175781
Batch 64/64 loss: -6.542836666107178
Epoch 159  Train loss: -2.353270663467108  Val loss: -2.4445155822124676
Epoch 160
-------------------------------
Batch 1/64 loss: -2.0656890869140625
Batch 2/64 loss: -2.503048896789551
Batch 3/64 loss: -2.484745979309082
Batch 4/64 loss: -2.2528467178344727
Batch 5/64 loss: -2.263461112976074
Batch 6/64 loss: -2.312088966369629
Batch 7/64 loss: -2.2993879318237305
Batch 8/64 loss: -1.9646940231323242
Batch 9/64 loss: -2.5013036727905273
Batch 10/64 loss: -2.1690073013305664
Batch 11/64 loss: -2.387399673461914
Batch 12/64 loss: -2.447528839111328
Batch 13/64 loss: -2.369288444519043
Batch 14/64 loss: -2.076343536376953
Batch 15/64 loss: -2.4561967849731445
Batch 16/64 loss: -2.1559181213378906
Batch 17/64 loss: -2.7548351287841797
Batch 18/64 loss: -2.532379150390625
Batch 19/64 loss: -2.2059717178344727
Batch 20/64 loss: -2.1171493530273438
Batch 21/64 loss: -2.079193115234375
Batch 22/64 loss: -2.4515504837036133
Batch 23/64 loss: -2.2671499252319336
Batch 24/64 loss: -2.514699935913086
Batch 25/64 loss: -2.558173179626465
Batch 26/64 loss: -2.1081361770629883
Batch 27/64 loss: -2.3718690872192383
Batch 28/64 loss: -2.499281883239746
Batch 29/64 loss: -1.8821477890014648
Batch 30/64 loss: -2.453873634338379
Batch 31/64 loss: -2.184992790222168
Batch 32/64 loss: -2.4394960403442383
Batch 33/64 loss: -2.0982227325439453
Batch 34/64 loss: -2.3867454528808594
Batch 35/64 loss: -2.3021364212036133
Batch 36/64 loss: -2.03983211517334
Batch 37/64 loss: -2.3180198669433594
Batch 38/64 loss: -2.512300491333008
Batch 39/64 loss: -2.4082717895507812
Batch 40/64 loss: -2.107166290283203
Batch 41/64 loss: -2.432117462158203
Batch 42/64 loss: -2.2879886627197266
Batch 43/64 loss: -2.2203989028930664
Batch 44/64 loss: -2.156785011291504
Batch 45/64 loss: -2.146646499633789
Batch 46/64 loss: -2.30438232421875
Batch 47/64 loss: -2.276078224182129
Batch 48/64 loss: -1.943868637084961
Batch 49/64 loss: -2.3569297790527344
Batch 50/64 loss: -2.2007007598876953
Batch 51/64 loss: -2.4521617889404297
Batch 52/64 loss: -2.3264827728271484
Batch 53/64 loss: -2.244612693786621
Batch 54/64 loss: -2.2817373275756836
Batch 55/64 loss: -2.5459671020507812
Batch 56/64 loss: -2.296605110168457
Batch 57/64 loss: -2.389078140258789
Batch 58/64 loss: -2.390331268310547
Batch 59/64 loss: -2.027195930480957
Batch 60/64 loss: -2.4640092849731445
Batch 61/64 loss: -2.4825010299682617
Batch 62/64 loss: -2.612889289855957
Batch 63/64 loss: -2.362715721130371
Batch 64/64 loss: -6.959126949310303
Epoch 160  Train loss: -2.3642991776559867  Val loss: -2.4445658156142613
Epoch 161
-------------------------------
Batch 1/64 loss: -2.4050121307373047
Batch 2/64 loss: -2.435302734375
Batch 3/64 loss: -2.113332748413086
Batch 4/64 loss: -2.423211097717285
Batch 5/64 loss: -2.2705278396606445
Batch 6/64 loss: -2.4432373046875
Batch 7/64 loss: -2.1339616775512695
Batch 8/64 loss: -2.2570810317993164
Batch 9/64 loss: -2.428704261779785
Batch 10/64 loss: -2.088261604309082
Batch 11/64 loss: -2.3194055557250977
Batch 12/64 loss: -2.165037155151367
Batch 13/64 loss: -1.9414100646972656
Batch 14/64 loss: -2.143953323364258
Batch 15/64 loss: -2.3577661514282227
Batch 16/64 loss: -2.538100242614746
Batch 17/64 loss: -2.105466842651367
Batch 18/64 loss: -2.4234485626220703
Batch 19/64 loss: -1.9938373565673828
Batch 20/64 loss: -2.354161262512207
Batch 21/64 loss: -2.480783462524414
Batch 22/64 loss: -2.321441650390625
Batch 23/64 loss: -2.457113265991211
Batch 24/64 loss: -2.6490116119384766
Batch 25/64 loss: -2.4275617599487305
Batch 26/64 loss: -2.115659713745117
Batch 27/64 loss: -2.4492034912109375
Batch 28/64 loss: -2.4930715560913086
Batch 29/64 loss: -2.2813711166381836
Batch 30/64 loss: -2.0072107315063477
Batch 31/64 loss: -2.186671257019043
Batch 32/64 loss: -2.2714996337890625
Batch 33/64 loss: -2.4060134887695312
Batch 34/64 loss: -2.2116165161132812
Batch 35/64 loss: -2.5718584060668945
Batch 36/64 loss: -2.397806167602539
Batch 37/64 loss: -2.712212562561035
Batch 38/64 loss: -2.556072235107422
Batch 39/64 loss: -2.4072189331054688
Batch 40/64 loss: -2.4187278747558594
Batch 41/64 loss: -2.391961097717285
Batch 42/64 loss: -2.5360965728759766
Batch 43/64 loss: -2.495100975036621
Batch 44/64 loss: -2.15799617767334
Batch 45/64 loss: -2.443486213684082
Batch 46/64 loss: -2.4618921279907227
Batch 47/64 loss: -2.32952880859375
Batch 48/64 loss: -2.5486574172973633
Batch 49/64 loss: -2.285337448120117
Batch 50/64 loss: -2.468050956726074
Batch 51/64 loss: -2.301764488220215
Batch 52/64 loss: -2.3294153213500977
Batch 53/64 loss: -2.4457626342773438
Batch 54/64 loss: -2.5487117767333984
Batch 55/64 loss: -2.4433679580688477
Batch 56/64 loss: -2.2112903594970703
Batch 57/64 loss: -2.519597053527832
Batch 58/64 loss: -2.314638137817383
Batch 59/64 loss: -2.4628171920776367
Batch 60/64 loss: -2.4291601181030273
Batch 61/64 loss: -2.2184228897094727
Batch 62/64 loss: -2.2386093139648438
Batch 63/64 loss: -2.3717288970947266
Batch 64/64 loss: -6.764797210693359
Epoch 161  Train loss: -2.4029856663124236  Val loss: -2.6179687657307102
Saving best model, epoch: 161
Epoch 162
-------------------------------
Batch 1/64 loss: -2.376211166381836
Batch 2/64 loss: -2.4461517333984375
Batch 3/64 loss: -2.4821557998657227
Batch 4/64 loss: -2.1721315383911133
Batch 5/64 loss: -2.286931037902832
Batch 6/64 loss: -2.4365968704223633
Batch 7/64 loss: -2.26296329498291
Batch 8/64 loss: -2.419940948486328
Batch 9/64 loss: -2.237908363342285
Batch 10/64 loss: -2.5302839279174805
Batch 11/64 loss: -2.414897918701172
Batch 12/64 loss: -2.5821123123168945
Batch 13/64 loss: -2.28311824798584
Batch 14/64 loss: -2.1046361923217773
Batch 15/64 loss: -2.3551273345947266
Batch 16/64 loss: -2.444066047668457
Batch 17/64 loss: -2.326078414916992
Batch 18/64 loss: -2.1824493408203125
Batch 19/64 loss: -2.322010040283203
Batch 20/64 loss: -2.1779823303222656
Batch 21/64 loss: -2.3758888244628906
Batch 22/64 loss: -2.566925048828125
Batch 23/64 loss: -2.608644485473633
Batch 24/64 loss: -2.2336463928222656
Batch 25/64 loss: -2.5095653533935547
Batch 26/64 loss: -2.4982528686523438
Batch 27/64 loss: -2.387179374694824
Batch 28/64 loss: -2.433643341064453
Batch 29/64 loss: -2.3372154235839844
Batch 30/64 loss: -2.348525047302246
Batch 31/64 loss: -2.3372793197631836
Batch 32/64 loss: -2.3224048614501953
Batch 33/64 loss: -2.59279727935791
Batch 34/64 loss: -2.446949005126953
Batch 35/64 loss: -2.5167064666748047
Batch 36/64 loss: -2.475889205932617
Batch 37/64 loss: -2.4965639114379883
Batch 38/64 loss: -2.580693244934082
Batch 39/64 loss: -2.3959474563598633
Batch 40/64 loss: -2.5593366622924805
Batch 41/64 loss: -2.425443649291992
Batch 42/64 loss: -2.1132097244262695
Batch 43/64 loss: -2.581862449645996
Batch 44/64 loss: -2.325526237487793
Batch 45/64 loss: -2.1801300048828125
Batch 46/64 loss: -1.8947973251342773
Batch 47/64 loss: -2.2851858139038086
Batch 48/64 loss: -2.423100471496582
Batch 49/64 loss: -2.2622594833374023
Batch 50/64 loss: -2.603390693664551
Batch 51/64 loss: -2.561434745788574
Batch 52/64 loss: -2.3097400665283203
Batch 53/64 loss: -2.2616825103759766
Batch 54/64 loss: -2.4299983978271484
Batch 55/64 loss: -2.1181840896606445
Batch 56/64 loss: -2.319096565246582
Batch 57/64 loss: -2.286545753479004
Batch 58/64 loss: -2.14034366607666
Batch 59/64 loss: -2.484861373901367
Batch 60/64 loss: -2.2898006439208984
Batch 61/64 loss: -2.1186866760253906
Batch 62/64 loss: -2.2616195678710938
Batch 63/64 loss: -2.4403562545776367
Batch 64/64 loss: -7.047584056854248
Epoch 162  Train loss: -2.419933343401142  Val loss: -2.38884488659626
Epoch 163
-------------------------------
Batch 1/64 loss: -1.9429073333740234
Batch 2/64 loss: -1.8067493438720703
Batch 3/64 loss: -1.919229507446289
Batch 4/64 loss: -2.0887222290039062
Batch 5/64 loss: -2.431224822998047
Batch 6/64 loss: -2.194363594055176
Batch 7/64 loss: -2.1890878677368164
Batch 8/64 loss: -2.335993766784668
Batch 9/64 loss: -2.397580146789551
Batch 10/64 loss: -2.16326904296875
Batch 11/64 loss: -2.155240058898926
Batch 12/64 loss: -2.326519012451172
Batch 13/64 loss: -2.0300216674804688
Batch 14/64 loss: -2.2486648559570312
Batch 15/64 loss: -2.3308143615722656
Batch 16/64 loss: -2.4595823287963867
Batch 17/64 loss: -2.050564765930176
Batch 18/64 loss: -2.205556869506836
Batch 19/64 loss: -2.2569961547851562
Batch 20/64 loss: -2.5659027099609375
Batch 21/64 loss: -2.259488105773926
Batch 22/64 loss: -2.3971996307373047
Batch 23/64 loss: -2.240192413330078
Batch 24/64 loss: -2.053720474243164
Batch 25/64 loss: -2.2298898696899414
Batch 26/64 loss: -1.9889001846313477
Batch 27/64 loss: -2.295055389404297
Batch 28/64 loss: -2.3596134185791016
Batch 29/64 loss: -2.0009164810180664
Batch 30/64 loss: -2.373687744140625
Batch 31/64 loss: -2.358452796936035
Batch 32/64 loss: -2.1832780838012695
Batch 33/64 loss: -2.093303680419922
Batch 34/64 loss: -2.2706470489501953
Batch 35/64 loss: -2.1233386993408203
Batch 36/64 loss: -2.204159736633301
Batch 37/64 loss: -2.383401870727539
Batch 38/64 loss: -2.2857303619384766
Batch 39/64 loss: -2.2112016677856445
Batch 40/64 loss: -2.2375411987304688
Batch 41/64 loss: -2.3946285247802734
Batch 42/64 loss: -2.220273017883301
Batch 43/64 loss: -2.421767234802246
Batch 44/64 loss: -2.1330623626708984
Batch 45/64 loss: -2.337675094604492
Batch 46/64 loss: -1.978194236755371
Batch 47/64 loss: -2.0473556518554688
Batch 48/64 loss: -2.020688056945801
Batch 49/64 loss: -2.2006473541259766
Batch 50/64 loss: -2.2322616577148438
Batch 51/64 loss: -2.16103458404541
Batch 52/64 loss: -2.2402544021606445
Batch 53/64 loss: -2.3652210235595703
Batch 54/64 loss: -1.8495979309082031
Batch 55/64 loss: -2.1659069061279297
Batch 56/64 loss: -1.548996925354004
Batch 57/64 loss: -2.2642364501953125
Batch 58/64 loss: -2.3303070068359375
Batch 59/64 loss: -2.3051204681396484
Batch 60/64 loss: -2.12044620513916
Batch 61/64 loss: -2.026045799255371
Batch 62/64 loss: -2.0612592697143555
Batch 63/64 loss: -2.159860610961914
Batch 64/64 loss: -6.829421043395996
Epoch 163  Train loss: -2.2487155428119734  Val loss: -2.3231340650840315
Epoch 164
-------------------------------
Batch 1/64 loss: -2.388777732849121
Batch 2/64 loss: -2.0655288696289062
Batch 3/64 loss: -2.355714797973633
Batch 4/64 loss: -2.371260643005371
Batch 5/64 loss: -2.279407501220703
Batch 6/64 loss: -2.1210060119628906
Batch 7/64 loss: -2.071648597717285
Batch 8/64 loss: -2.1000471115112305
Batch 9/64 loss: -2.158144950866699
Batch 10/64 loss: -1.754878044128418
Batch 11/64 loss: -2.552657127380371
Batch 12/64 loss: -2.5825843811035156
Batch 13/64 loss: -2.2152624130249023
Batch 14/64 loss: -2.1521949768066406
Batch 15/64 loss: -2.3865251541137695
Batch 16/64 loss: -1.940089225769043
Batch 17/64 loss: -1.9661874771118164
Batch 18/64 loss: -1.9609622955322266
Batch 19/64 loss: -2.293951988220215
Batch 20/64 loss: -2.237582206726074
Batch 21/64 loss: -2.24387264251709
Batch 22/64 loss: -2.247134208679199
Batch 23/64 loss: -2.185394287109375
Batch 24/64 loss: -2.352964401245117
Batch 25/64 loss: -2.237546920776367
Batch 26/64 loss: -2.376535415649414
Batch 27/64 loss: -2.28912353515625
Batch 28/64 loss: -2.1176958084106445
Batch 29/64 loss: -2.2114458084106445
Batch 30/64 loss: -2.496124267578125
Batch 31/64 loss: -1.7623109817504883
Batch 32/64 loss: -1.7998466491699219
Batch 33/64 loss: -2.046168327331543
Batch 34/64 loss: -2.1278038024902344
Batch 35/64 loss: -2.3028030395507812
Batch 36/64 loss: -2.3046951293945312
Batch 37/64 loss: -2.080984115600586
Batch 38/64 loss: -2.42307186126709
Batch 39/64 loss: -2.0995588302612305
Batch 40/64 loss: -2.1236648559570312
Batch 41/64 loss: -2.2826528549194336
Batch 42/64 loss: -1.8979606628417969
Batch 43/64 loss: -2.2409753799438477
Batch 44/64 loss: -2.2804946899414062
Batch 45/64 loss: -2.404571533203125
Batch 46/64 loss: -2.2470703125
Batch 47/64 loss: -1.6919479370117188
Batch 48/64 loss: -2.2546424865722656
Batch 49/64 loss: -2.213655471801758
Batch 50/64 loss: -2.1689453125
Batch 51/64 loss: -1.8106889724731445
Batch 52/64 loss: -2.3374204635620117
Batch 53/64 loss: -2.0527915954589844
Batch 54/64 loss: -2.053858757019043
Batch 55/64 loss: -2.114347457885742
Batch 56/64 loss: -2.347536087036133
Batch 57/64 loss: -2.248105049133301
Batch 58/64 loss: -1.7741918563842773
Batch 59/64 loss: -2.188736915588379
Batch 60/64 loss: -2.410348892211914
Batch 61/64 loss: -2.218997001647949
Batch 62/64 loss: -2.0826330184936523
Batch 63/64 loss: -2.012383460998535
Batch 64/64 loss: -6.267681121826172
Epoch 164  Train loss: -2.224609778909122  Val loss: -2.37413477160267
Epoch 165
-------------------------------
Batch 1/64 loss: -2.365353584289551
Batch 2/64 loss: -1.9120025634765625
Batch 3/64 loss: -1.9817180633544922
Batch 4/64 loss: -2.263251304626465
Batch 5/64 loss: -2.3457212448120117
Batch 6/64 loss: -2.2462844848632812
Batch 7/64 loss: -2.2036514282226562
Batch 8/64 loss: -2.1342334747314453
Batch 9/64 loss: -2.4073925018310547
Batch 10/64 loss: -2.305065155029297
Batch 11/64 loss: -2.0420732498168945
Batch 12/64 loss: -2.13739013671875
Batch 13/64 loss: -1.8036775588989258
Batch 14/64 loss: -2.1530838012695312
Batch 15/64 loss: -2.3096399307250977
Batch 16/64 loss: -2.11795711517334
Batch 17/64 loss: -2.257152557373047
Batch 18/64 loss: -2.3980703353881836
Batch 19/64 loss: -2.458889961242676
Batch 20/64 loss: -2.1452198028564453
Batch 21/64 loss: -2.0759973526000977
Batch 22/64 loss: -1.911910057067871
Batch 23/64 loss: -1.962850570678711
Batch 24/64 loss: -2.091639518737793
Batch 25/64 loss: -2.40103816986084
Batch 26/64 loss: -2.0275745391845703
Batch 27/64 loss: -2.368021011352539
Batch 28/64 loss: -2.4223031997680664
Batch 29/64 loss: -1.8590984344482422
Batch 30/64 loss: -2.1231489181518555
Batch 31/64 loss: -2.2759838104248047
Batch 32/64 loss: -2.408938407897949
Batch 33/64 loss: -2.314054489135742
Batch 34/64 loss: -2.1991920471191406
Batch 35/64 loss: -1.9242916107177734
Batch 36/64 loss: -2.2626571655273438
Batch 37/64 loss: -2.299391746520996
Batch 38/64 loss: -2.3701648712158203
Batch 39/64 loss: -2.323672294616699
Batch 40/64 loss: -2.379068374633789
Batch 41/64 loss: -2.1447877883911133
Batch 42/64 loss: -2.323489189147949
Batch 43/64 loss: -2.466193199157715
Batch 44/64 loss: -2.0986766815185547
Batch 45/64 loss: -2.146426200866699
Batch 46/64 loss: -2.169003486633301
Batch 47/64 loss: -1.8403844833374023
Batch 48/64 loss: -2.163773536682129
Batch 49/64 loss: -2.1477012634277344
Batch 50/64 loss: -2.4609689712524414
Batch 51/64 loss: -1.5731697082519531
Batch 52/64 loss: -2.360015869140625
Batch 53/64 loss: -2.1035051345825195
Batch 54/64 loss: -2.396625518798828
Batch 55/64 loss: -2.4712400436401367
Batch 56/64 loss: -2.19705867767334
Batch 57/64 loss: -2.292478561401367
Batch 58/64 loss: -2.4959564208984375
Batch 59/64 loss: -2.2895593643188477
Batch 60/64 loss: -2.428976058959961
Batch 61/64 loss: -2.3821964263916016
Batch 62/64 loss: -2.2508773803710938
Batch 63/64 loss: -2.4134836196899414
Batch 64/64 loss: -6.773359775543213
Epoch 165  Train loss: -2.26957478055767  Val loss: -2.3219867326139996
Epoch 166
-------------------------------
Batch 1/64 loss: -2.158426284790039
Batch 2/64 loss: -2.199420928955078
Batch 3/64 loss: -2.518855094909668
Batch 4/64 loss: -2.4218263626098633
Batch 5/64 loss: -2.3073835372924805
Batch 6/64 loss: -2.3503198623657227
Batch 7/64 loss: -1.5857486724853516
Batch 8/64 loss: -2.365692138671875
Batch 9/64 loss: -2.44368839263916
Batch 10/64 loss: -2.4292049407958984
Batch 11/64 loss: -1.9388494491577148
Batch 12/64 loss: -2.3993215560913086
Batch 13/64 loss: -2.3960342407226562
Batch 14/64 loss: -2.0214099884033203
Batch 15/64 loss: -2.2549924850463867
Batch 16/64 loss: -2.5384445190429688
Batch 17/64 loss: -2.547389030456543
Batch 18/64 loss: -2.0844812393188477
Batch 19/64 loss: -2.0546646118164062
Batch 20/64 loss: -2.537106513977051
Batch 21/64 loss: -2.357748031616211
Batch 22/64 loss: -1.9142303466796875
Batch 23/64 loss: -2.2237510681152344
Batch 24/64 loss: -2.575802803039551
Batch 25/64 loss: -2.3389177322387695
Batch 26/64 loss: -2.459747314453125
Batch 27/64 loss: -2.4451255798339844
Batch 28/64 loss: -2.4310569763183594
Batch 29/64 loss: -2.4609270095825195
Batch 30/64 loss: -2.116567611694336
Batch 31/64 loss: -2.3351526260375977
Batch 32/64 loss: -2.4624643325805664
Batch 33/64 loss: -2.4335803985595703
Batch 34/64 loss: -2.465177536010742
Batch 35/64 loss: -2.4411163330078125
Batch 36/64 loss: -2.427602767944336
Batch 37/64 loss: -2.1705093383789062
Batch 38/64 loss: -2.3624744415283203
Batch 39/64 loss: -2.659176826477051
Batch 40/64 loss: -2.101557731628418
Batch 41/64 loss: -2.4781322479248047
Batch 42/64 loss: -2.2227554321289062
Batch 43/64 loss: -2.5768327713012695
Batch 44/64 loss: -2.555577278137207
Batch 45/64 loss: -2.5931644439697266
Batch 46/64 loss: -2.3322038650512695
Batch 47/64 loss: -2.369892120361328
Batch 48/64 loss: -2.524045944213867
Batch 49/64 loss: -2.222454071044922
Batch 50/64 loss: -2.413619041442871
Batch 51/64 loss: -2.2045507431030273
Batch 52/64 loss: -1.942617416381836
Batch 53/64 loss: -2.483942985534668
Batch 54/64 loss: -2.4382123947143555
Batch 55/64 loss: -2.0407333374023438
Batch 56/64 loss: -2.196202278137207
Batch 57/64 loss: -2.1047449111938477
Batch 58/64 loss: -2.0382728576660156
Batch 59/64 loss: -2.3467025756835938
Batch 60/64 loss: -2.464747428894043
Batch 61/64 loss: -2.4974365234375
Batch 62/64 loss: -2.5716552734375
Batch 63/64 loss: -2.2141895294189453
Batch 64/64 loss: -6.842141151428223
Epoch 166  Train loss: -2.379611576304716  Val loss: -2.469174584981912
Epoch 167
-------------------------------
Batch 1/64 loss: -2.4613609313964844
Batch 2/64 loss: -2.4577770233154297
Batch 3/64 loss: -2.3918771743774414
Batch 4/64 loss: -1.8408422470092773
Batch 5/64 loss: -2.099658966064453
Batch 6/64 loss: -2.338313102722168
Batch 7/64 loss: -2.468930244445801
Batch 8/64 loss: -2.306852340698242
Batch 9/64 loss: -2.4604835510253906
Batch 10/64 loss: -2.2955455780029297
Batch 11/64 loss: -2.062239646911621
Batch 12/64 loss: -2.092287063598633
Batch 13/64 loss: -2.1877450942993164
Batch 14/64 loss: -2.370380401611328
Batch 15/64 loss: -2.6042776107788086
Batch 16/64 loss: -2.4842004776000977
Batch 17/64 loss: -2.3654232025146484
Batch 18/64 loss: -2.2617483139038086
Batch 19/64 loss: -2.444215774536133
Batch 20/64 loss: -2.318648338317871
Batch 21/64 loss: -2.5416440963745117
Batch 22/64 loss: -2.4265079498291016
Batch 23/64 loss: -2.355562210083008
Batch 24/64 loss: -2.1611785888671875
Batch 25/64 loss: -2.171907424926758
Batch 26/64 loss: -2.38824462890625
Batch 27/64 loss: -2.5027666091918945
Batch 28/64 loss: -2.168015480041504
Batch 29/64 loss: -2.4340009689331055
Batch 30/64 loss: -2.1320133209228516
Batch 31/64 loss: -2.341432571411133
Batch 32/64 loss: -2.547419548034668
Batch 33/64 loss: -2.31097412109375
Batch 34/64 loss: -2.28768253326416
Batch 35/64 loss: -2.3440399169921875
Batch 36/64 loss: -2.445725440979004
Batch 37/64 loss: -2.2809457778930664
Batch 38/64 loss: -2.3304567337036133
Batch 39/64 loss: -2.1431055068969727
Batch 40/64 loss: -2.546200752258301
Batch 41/64 loss: -2.1402339935302734
Batch 42/64 loss: -2.2167530059814453
Batch 43/64 loss: -2.5053091049194336
Batch 44/64 loss: -2.3701562881469727
Batch 45/64 loss: -1.8972339630126953
Batch 46/64 loss: -2.468966484069824
Batch 47/64 loss: -2.4553298950195312
Batch 48/64 loss: -2.431791305541992
Batch 49/64 loss: -2.391672134399414
Batch 50/64 loss: -2.601900100708008
Batch 51/64 loss: -2.358030319213867
Batch 52/64 loss: -2.5447378158569336
Batch 53/64 loss: -2.538991928100586
Batch 54/64 loss: -1.7441167831420898
Batch 55/64 loss: -2.3936948776245117
Batch 56/64 loss: -2.4128103256225586
Batch 57/64 loss: -2.1450729370117188
Batch 58/64 loss: -2.2374887466430664
Batch 59/64 loss: -2.2994461059570312
Batch 60/64 loss: -2.236844062805176
Batch 61/64 loss: -2.186612129211426
Batch 62/64 loss: -2.2816781997680664
Batch 63/64 loss: -2.4454193115234375
Batch 64/64 loss: -6.892522811889648
Epoch 167  Train loss: -2.378765697105258  Val loss: -2.4504464664000416
Epoch 168
-------------------------------
Batch 1/64 loss: -2.2753658294677734
Batch 2/64 loss: -1.9589614868164062
Batch 3/64 loss: -2.2715988159179688
Batch 4/64 loss: -2.514925956726074
Batch 5/64 loss: -2.3155860900878906
Batch 6/64 loss: -2.408132553100586
Batch 7/64 loss: -2.512052536010742
Batch 8/64 loss: -2.357365608215332
Batch 9/64 loss: -2.157062530517578
Batch 10/64 loss: -2.55893611907959
Batch 11/64 loss: -2.2816152572631836
Batch 12/64 loss: -2.571230888366699
Batch 13/64 loss: -2.498284339904785
Batch 14/64 loss: -2.010634422302246
Batch 15/64 loss: -2.494548797607422
Batch 16/64 loss: -2.5561304092407227
Batch 17/64 loss: -2.1732826232910156
Batch 18/64 loss: -2.5642242431640625
Batch 19/64 loss: -2.423208236694336
Batch 20/64 loss: -2.046703338623047
Batch 21/64 loss: -2.3307714462280273
Batch 22/64 loss: -2.302638053894043
Batch 23/64 loss: -2.3593015670776367
Batch 24/64 loss: -2.192605972290039
Batch 25/64 loss: -1.2420587539672852
Batch 26/64 loss: -2.2622385025024414
Batch 27/64 loss: -2.199033737182617
Batch 28/64 loss: -2.3611555099487305
Batch 29/64 loss: -1.8640451431274414
Batch 30/64 loss: -2.525212287902832
Batch 31/64 loss: -2.1893463134765625
Batch 32/64 loss: -2.4567089080810547
Batch 33/64 loss: -2.520811080932617
Batch 34/64 loss: -2.134129524230957
Batch 35/64 loss: -1.9295825958251953
Batch 36/64 loss: -2.08383846282959
Batch 37/64 loss: -2.2792301177978516
Batch 38/64 loss: -2.5275049209594727
Batch 39/64 loss: -2.1119251251220703
Batch 40/64 loss: -2.3623247146606445
Batch 41/64 loss: -2.424006462097168
Batch 42/64 loss: -2.4953536987304688
Batch 43/64 loss: -2.3175830841064453
Batch 44/64 loss: -2.6063127517700195
Batch 45/64 loss: -2.4408769607543945
Batch 46/64 loss: -2.4265527725219727
Batch 47/64 loss: -2.543931007385254
Batch 48/64 loss: -2.4580087661743164
Batch 49/64 loss: -2.1193113327026367
Batch 50/64 loss: -2.04616641998291
Batch 51/64 loss: -2.4371089935302734
Batch 52/64 loss: -1.9745635986328125
Batch 53/64 loss: -1.493734359741211
Batch 54/64 loss: -2.239119529724121
Batch 55/64 loss: -2.4101924896240234
Batch 56/64 loss: -1.6746950149536133
Batch 57/64 loss: -2.4652271270751953
Batch 58/64 loss: -2.03444766998291
Batch 59/64 loss: -2.280158042907715
Batch 60/64 loss: -2.701718330383301
Batch 61/64 loss: -2.0226287841796875
Batch 62/64 loss: -2.3324060440063477
Batch 63/64 loss: -2.3022565841674805
Batch 64/64 loss: -6.755339622497559
Epoch 168  Train loss: -2.329367488038306  Val loss: -2.5452673476176573
Epoch 169
-------------------------------
Batch 1/64 loss: -2.6662893295288086
Batch 2/64 loss: -2.535198211669922
Batch 3/64 loss: -2.5075511932373047
Batch 4/64 loss: -2.133925437927246
Batch 5/64 loss: -2.2348594665527344
Batch 6/64 loss: -2.3176889419555664
Batch 7/64 loss: -1.9151830673217773
Batch 8/64 loss: -2.220065116882324
Batch 9/64 loss: -2.5607786178588867
Batch 10/64 loss: -2.255072593688965
Batch 11/64 loss: -2.333423614501953
Batch 12/64 loss: -2.0511531829833984
Batch 13/64 loss: -2.124980926513672
Batch 14/64 loss: -2.3083152770996094
Batch 15/64 loss: -2.4491872787475586
Batch 16/64 loss: -2.411518096923828
Batch 17/64 loss: -2.55938720703125
Batch 18/64 loss: -2.23984432220459
Batch 19/64 loss: -2.262263298034668
Batch 20/64 loss: -2.4025497436523438
Batch 21/64 loss: -2.3413448333740234
Batch 22/64 loss: -2.4039220809936523
Batch 23/64 loss: -2.097214698791504
Batch 24/64 loss: -2.276740074157715
Batch 25/64 loss: -2.3308982849121094
Batch 26/64 loss: -2.4116287231445312
Batch 27/64 loss: -2.5258188247680664
Batch 28/64 loss: -2.496471405029297
Batch 29/64 loss: -2.157228469848633
Batch 30/64 loss: -1.9865665435791016
Batch 31/64 loss: -2.2873878479003906
Batch 32/64 loss: -2.4248342514038086
Batch 33/64 loss: -2.368340492248535
Batch 34/64 loss: -2.324460029602051
Batch 35/64 loss: -2.6149120330810547
Batch 36/64 loss: -2.373906135559082
Batch 37/64 loss: -2.0680179595947266
Batch 38/64 loss: -2.2515487670898438
Batch 39/64 loss: -2.070492744445801
Batch 40/64 loss: -2.0534820556640625
Batch 41/64 loss: -2.2476587295532227
Batch 42/64 loss: -2.482616424560547
Batch 43/64 loss: -2.2567663192749023
Batch 44/64 loss: -2.4059858322143555
Batch 45/64 loss: -2.505962371826172
Batch 46/64 loss: -2.2562150955200195
Batch 47/64 loss: -2.5493154525756836
Batch 48/64 loss: -2.4061012268066406
Batch 49/64 loss: -2.0979347229003906
Batch 50/64 loss: -2.2234067916870117
Batch 51/64 loss: -2.2955493927001953
Batch 52/64 loss: -2.3603591918945312
Batch 53/64 loss: -2.309473991394043
Batch 54/64 loss: -2.4808435440063477
Batch 55/64 loss: -2.171534538269043
Batch 56/64 loss: -2.4290761947631836
Batch 57/64 loss: -2.6686315536499023
Batch 58/64 loss: -2.4430665969848633
Batch 59/64 loss: -2.298311233520508
Batch 60/64 loss: -1.7588920593261719
Batch 61/64 loss: -2.2243261337280273
Batch 62/64 loss: -2.235271453857422
Batch 63/64 loss: -2.4846553802490234
Batch 64/64 loss: -6.69645881652832
Epoch 169  Train loss: -2.3681372474221623  Val loss: -2.5468823147803237
Epoch 170
-------------------------------
Batch 1/64 loss: -2.2656288146972656
Batch 2/64 loss: -2.458310127258301
Batch 3/64 loss: -2.3165483474731445
Batch 4/64 loss: -2.3637094497680664
Batch 5/64 loss: -2.342092514038086
Batch 6/64 loss: -2.2834157943725586
Batch 7/64 loss: -1.9824533462524414
Batch 8/64 loss: -2.6829099655151367
Batch 9/64 loss: -2.3942956924438477
Batch 10/64 loss: -2.290464401245117
Batch 11/64 loss: -2.52890682220459
Batch 12/64 loss: -2.5193376541137695
Batch 13/64 loss: -2.476367950439453
Batch 14/64 loss: -2.1401147842407227
Batch 15/64 loss: -2.316103935241699
Batch 16/64 loss: -2.430178642272949
Batch 17/64 loss: -1.6862449645996094
Batch 18/64 loss: -2.425466537475586
Batch 19/64 loss: -1.9554500579833984
Batch 20/64 loss: -2.2265491485595703
Batch 21/64 loss: -2.067519187927246
Batch 22/64 loss: -2.3122758865356445
Batch 23/64 loss: -2.2607269287109375
Batch 24/64 loss: -2.551150321960449
Batch 25/64 loss: -2.3026981353759766
Batch 26/64 loss: -2.4138078689575195
Batch 27/64 loss: -2.3249473571777344
Batch 28/64 loss: -2.522808074951172
Batch 29/64 loss: -2.1004762649536133
Batch 30/64 loss: -2.47263240814209
Batch 31/64 loss: -2.4845399856567383
Batch 32/64 loss: -2.372653007507324
Batch 33/64 loss: -2.5170602798461914
Batch 34/64 loss: -1.9197416305541992
Batch 35/64 loss: -2.07180118560791
Batch 36/64 loss: -2.5116004943847656
Batch 37/64 loss: -1.7418222427368164
Batch 38/64 loss: -1.9482059478759766
Batch 39/64 loss: -2.4176225662231445
Batch 40/64 loss: -1.9889602661132812
Batch 41/64 loss: -2.233692169189453
Batch 42/64 loss: -2.268002510070801
Batch 43/64 loss: -2.099543571472168
Batch 44/64 loss: -2.0202713012695312
Batch 45/64 loss: -2.254458427429199
Batch 46/64 loss: -2.014866828918457
Batch 47/64 loss: -2.484607696533203
Batch 48/64 loss: -2.6073198318481445
Batch 49/64 loss: -2.1982812881469727
Batch 50/64 loss: -2.0539093017578125
Batch 51/64 loss: -2.197286605834961
Batch 52/64 loss: -2.464423179626465
Batch 53/64 loss: -2.195683479309082
Batch 54/64 loss: -2.1325340270996094
Batch 55/64 loss: -2.1445608139038086
Batch 56/64 loss: -2.1289281845092773
Batch 57/64 loss: -2.0704002380371094
Batch 58/64 loss: -2.4169921875
Batch 59/64 loss: -1.9262456893920898
Batch 60/64 loss: -2.225557327270508
Batch 61/64 loss: -1.8141555786132812
Batch 62/64 loss: -2.12570858001709
Batch 63/64 loss: -2.1209163665771484
Batch 64/64 loss: -6.670112133026123
Epoch 170  Train loss: -2.2994278945174873  Val loss: -1.9693295455880182
Epoch 171
-------------------------------
Batch 1/64 loss: -1.6677217483520508
Batch 2/64 loss: -2.3051061630249023
Batch 3/64 loss: -1.380742073059082
Batch 4/64 loss: -2.2784929275512695
Batch 5/64 loss: -1.8953933715820312
Batch 6/64 loss: -2.3370933532714844
Batch 7/64 loss: -2.2152814865112305
Batch 8/64 loss: -2.3879690170288086
Batch 9/64 loss: -2.325270652770996
Batch 10/64 loss: -1.9181585311889648
Batch 11/64 loss: -2.1116037368774414
Batch 12/64 loss: -2.307366371154785
Batch 13/64 loss: -2.1218481063842773
Batch 14/64 loss: -2.376152992248535
Batch 15/64 loss: -1.8980398178100586
Batch 16/64 loss: -1.8951330184936523
Batch 17/64 loss: -1.7157278060913086
Batch 18/64 loss: -2.217824935913086
Batch 19/64 loss: -1.6987943649291992
Batch 20/64 loss: -2.0823936462402344
Batch 21/64 loss: -2.312742233276367
Batch 22/64 loss: -1.7212800979614258
Batch 23/64 loss: -1.840470314025879
Batch 24/64 loss: -2.3717470169067383
Batch 25/64 loss: -2.548853874206543
Batch 26/64 loss: -2.4015274047851562
Batch 27/64 loss: -2.1373720169067383
Batch 28/64 loss: -2.376100540161133
Batch 29/64 loss: -2.783097267150879
Batch 30/64 loss: -2.0694360733032227
Batch 31/64 loss: -2.543895721435547
Batch 32/64 loss: -2.317000389099121
Batch 33/64 loss: -2.3646411895751953
Batch 34/64 loss: -1.6473455429077148
Batch 35/64 loss: -2.1356801986694336
Batch 36/64 loss: -2.3215112686157227
Batch 37/64 loss: -2.3511085510253906
Batch 38/64 loss: -2.105465888977051
Batch 39/64 loss: -2.3318681716918945
Batch 40/64 loss: -2.3384904861450195
Batch 41/64 loss: -2.376662254333496
Batch 42/64 loss: -2.2992401123046875
Batch 43/64 loss: -2.3790979385375977
Batch 44/64 loss: -2.4457225799560547
Batch 45/64 loss: -2.48366641998291
Batch 46/64 loss: -1.9554195404052734
Batch 47/64 loss: -2.5982465744018555
Batch 48/64 loss: -2.1691408157348633
Batch 49/64 loss: -2.178424835205078
Batch 50/64 loss: -2.2669010162353516
Batch 51/64 loss: -1.484389305114746
Batch 52/64 loss: -2.140932083129883
Batch 53/64 loss: -2.138822555541992
Batch 54/64 loss: -2.2794055938720703
Batch 55/64 loss: -2.302596092224121
Batch 56/64 loss: -2.539576530456543
Batch 57/64 loss: -2.153116226196289
Batch 58/64 loss: -2.424253463745117
Batch 59/64 loss: -2.333040237426758
Batch 60/64 loss: -2.4061384201049805
Batch 61/64 loss: -2.407764434814453
Batch 62/64 loss: -2.6291732788085938
Batch 63/64 loss: -2.448214530944824
Batch 64/64 loss: -6.952715873718262
Epoch 171  Train loss: -2.262121256660013  Val loss: -2.581237203067111
Epoch 172
-------------------------------
Batch 1/64 loss: -2.3148889541625977
Batch 2/64 loss: -2.5978546142578125
Batch 3/64 loss: -1.9528627395629883
Batch 4/64 loss: -2.453359603881836
Batch 5/64 loss: -2.4011411666870117
Batch 6/64 loss: -2.3526268005371094
Batch 7/64 loss: -2.312318801879883
Batch 8/64 loss: -2.2107925415039062
Batch 9/64 loss: -2.1414546966552734
Batch 10/64 loss: -2.3811731338500977
Batch 11/64 loss: -2.0316877365112305
Batch 12/64 loss: -2.449021339416504
Batch 13/64 loss: -2.559281349182129
Batch 14/64 loss: -2.1157989501953125
Batch 15/64 loss: -2.4077491760253906
Batch 16/64 loss: -2.549144744873047
Batch 17/64 loss: -2.472245216369629
Batch 18/64 loss: -2.4197568893432617
Batch 19/64 loss: -2.372203826904297
Batch 20/64 loss: -2.2779712677001953
Batch 21/64 loss: -2.442668914794922
Batch 22/64 loss: -2.2964839935302734
Batch 23/64 loss: -2.4928455352783203
Batch 24/64 loss: -2.6553096771240234
Batch 25/64 loss: -2.4085655212402344
Batch 26/64 loss: -2.349618911743164
Batch 27/64 loss: -2.0891313552856445
Batch 28/64 loss: -2.2668323516845703
Batch 29/64 loss: -2.407480239868164
Batch 30/64 loss: -2.173062324523926
Batch 31/64 loss: -2.3071203231811523
Batch 32/64 loss: -2.3919286727905273
Batch 33/64 loss: -2.23333740234375
Batch 34/64 loss: -2.5816078186035156
Batch 35/64 loss: -2.5218496322631836
Batch 36/64 loss: -2.1367435455322266
Batch 37/64 loss: -2.068934440612793
Batch 38/64 loss: -2.0461273193359375
Batch 39/64 loss: -2.1997861862182617
Batch 40/64 loss: -2.2285966873168945
Batch 41/64 loss: -2.283980369567871
Batch 42/64 loss: -2.497325897216797
Batch 43/64 loss: -2.143199920654297
Batch 44/64 loss: -2.0539159774780273
Batch 45/64 loss: -2.34835147857666
Batch 46/64 loss: -2.4828500747680664
Batch 47/64 loss: -2.455061912536621
Batch 48/64 loss: -2.4759445190429688
Batch 49/64 loss: -2.4994354248046875
Batch 50/64 loss: -2.4161062240600586
Batch 51/64 loss: -2.371490478515625
Batch 52/64 loss: -2.5083236694335938
Batch 53/64 loss: -2.29988956451416
Batch 54/64 loss: -2.2215499877929688
Batch 55/64 loss: -2.4928083419799805
Batch 56/64 loss: -2.323740005493164
Batch 57/64 loss: -2.5624780654907227
Batch 58/64 loss: -2.345712661743164
Batch 59/64 loss: -2.392446517944336
Batch 60/64 loss: -2.406900405883789
Batch 61/64 loss: -2.240509033203125
Batch 62/64 loss: -2.297022819519043
Batch 63/64 loss: -2.4863719940185547
Batch 64/64 loss: -7.035506725311279
Epoch 172  Train loss: -2.399269173192043  Val loss: -2.6170231534033706
Epoch 173
-------------------------------
Batch 1/64 loss: -2.381575584411621
Batch 2/64 loss: -1.8965816497802734
Batch 3/64 loss: -2.4361133575439453
Batch 4/64 loss: -2.344388008117676
Batch 5/64 loss: -2.4256582260131836
Batch 6/64 loss: -2.425718307495117
Batch 7/64 loss: -2.4042558670043945
Batch 8/64 loss: -2.0433435440063477
Batch 9/64 loss: -2.2916183471679688
Batch 10/64 loss: -2.4751319885253906
Batch 11/64 loss: -2.5724563598632812
Batch 12/64 loss: -2.6507530212402344
Batch 13/64 loss: -2.576127052307129
Batch 14/64 loss: -2.269540786743164
Batch 15/64 loss: -2.051088333129883
Batch 16/64 loss: -2.4375972747802734
Batch 17/64 loss: -2.3787498474121094
Batch 18/64 loss: -2.451085090637207
Batch 19/64 loss: -2.2815322875976562
Batch 20/64 loss: -2.4177141189575195
Batch 21/64 loss: -2.0473709106445312
Batch 22/64 loss: -2.364016532897949
Batch 23/64 loss: -2.3879518508911133
Batch 24/64 loss: -2.2710275650024414
Batch 25/64 loss: -2.3934803009033203
Batch 26/64 loss: -2.205573081970215
Batch 27/64 loss: -2.492884635925293
Batch 28/64 loss: -2.5392656326293945
Batch 29/64 loss: -2.5914230346679688
Batch 30/64 loss: -2.4340591430664062
Batch 31/64 loss: -2.3305368423461914
Batch 32/64 loss: -2.3957090377807617
Batch 33/64 loss: -2.0640878677368164
Batch 34/64 loss: -2.3465919494628906
Batch 35/64 loss: -2.523797035217285
Batch 36/64 loss: -2.6762962341308594
Batch 37/64 loss: -2.5668373107910156
Batch 38/64 loss: -2.3120155334472656
Batch 39/64 loss: -2.64328670501709
Batch 40/64 loss: -2.28562068939209
Batch 41/64 loss: -1.9375019073486328
Batch 42/64 loss: -2.063344955444336
Batch 43/64 loss: -2.285289764404297
Batch 44/64 loss: -2.4954423904418945
Batch 45/64 loss: -2.27121639251709
Batch 46/64 loss: -2.2630701065063477
Batch 47/64 loss: -2.104212760925293
Batch 48/64 loss: -2.340900421142578
Batch 49/64 loss: -2.501741409301758
Batch 50/64 loss: -2.6035690307617188
Batch 51/64 loss: -2.1678924560546875
Batch 52/64 loss: -2.2531375885009766
Batch 53/64 loss: -2.3285417556762695
Batch 54/64 loss: -2.5212221145629883
Batch 55/64 loss: -2.559880256652832
Batch 56/64 loss: -2.4327545166015625
Batch 57/64 loss: -2.570000648498535
Batch 58/64 loss: -2.283447265625
Batch 59/64 loss: -2.322154998779297
Batch 60/64 loss: -2.3798398971557617
Batch 61/64 loss: -2.3867673873901367
Batch 62/64 loss: -2.3347291946411133
Batch 63/64 loss: -2.7447128295898438
Batch 64/64 loss: -7.232339859008789
Epoch 173  Train loss: -2.426015464932311  Val loss: -2.5534173237908746
Epoch 174
-------------------------------
Batch 1/64 loss: -2.3798694610595703
Batch 2/64 loss: -2.5181446075439453
Batch 3/64 loss: -2.473501205444336
Batch 4/64 loss: -2.355670928955078
Batch 5/64 loss: -2.4587554931640625
Batch 6/64 loss: -2.4011430740356445
Batch 7/64 loss: -2.2269954681396484
Batch 8/64 loss: -2.148251533508301
Batch 9/64 loss: -2.044915199279785
Batch 10/64 loss: -2.4473934173583984
Batch 11/64 loss: -2.4847640991210938
Batch 12/64 loss: -2.220417022705078
Batch 13/64 loss: -2.4241838455200195
Batch 14/64 loss: -2.3288345336914062
Batch 15/64 loss: -2.260478973388672
Batch 16/64 loss: -2.3555049896240234
Batch 17/64 loss: -2.2625932693481445
Batch 18/64 loss: -1.8698539733886719
Batch 19/64 loss: -2.4904823303222656
Batch 20/64 loss: -2.290416717529297
Batch 21/64 loss: -2.255462646484375
Batch 22/64 loss: -1.9955339431762695
Batch 23/64 loss: -2.526744842529297
Batch 24/64 loss: -2.191364288330078
Batch 25/64 loss: -2.2232398986816406
Batch 26/64 loss: -2.41886043548584
Batch 27/64 loss: -2.493459701538086
Batch 28/64 loss: -2.3548288345336914
Batch 29/64 loss: -2.417633056640625
Batch 30/64 loss: -2.1749982833862305
Batch 31/64 loss: -2.3335819244384766
Batch 32/64 loss: -2.288684844970703
Batch 33/64 loss: -2.389301300048828
Batch 34/64 loss: -2.048600196838379
Batch 35/64 loss: -2.363436698913574
Batch 36/64 loss: -2.0937376022338867
Batch 37/64 loss: -2.4008235931396484
Batch 38/64 loss: -2.4357872009277344
Batch 39/64 loss: -2.3530654907226562
Batch 40/64 loss: -2.129086494445801
Batch 41/64 loss: -2.437821388244629
Batch 42/64 loss: -2.2277326583862305
Batch 43/64 loss: -2.26657772064209
Batch 44/64 loss: -2.2955026626586914
Batch 45/64 loss: -2.3346452713012695
Batch 46/64 loss: -2.587273597717285
Batch 47/64 loss: -2.4689769744873047
Batch 48/64 loss: -2.115607261657715
Batch 49/64 loss: -2.1660804748535156
Batch 50/64 loss: -2.4508514404296875
Batch 51/64 loss: -2.5360069274902344
Batch 52/64 loss: -2.1667613983154297
Batch 53/64 loss: -2.143768310546875
Batch 54/64 loss: -2.4149656295776367
Batch 55/64 loss: -2.0523996353149414
Batch 56/64 loss: -2.2313108444213867
Batch 57/64 loss: -2.4853668212890625
Batch 58/64 loss: -2.4388856887817383
Batch 59/64 loss: -2.4332847595214844
Batch 60/64 loss: -2.515011787414551
Batch 61/64 loss: -1.9783058166503906
Batch 62/64 loss: -2.259695053100586
Batch 63/64 loss: -2.3078689575195312
Batch 64/64 loss: -7.171231269836426
Epoch 174  Train loss: -2.3689964855418486  Val loss: -2.48720154647565
Epoch 175
-------------------------------
Batch 1/64 loss: -2.42636775970459
Batch 2/64 loss: -2.2005157470703125
Batch 3/64 loss: -2.270986557006836
Batch 4/64 loss: -2.3808631896972656
Batch 5/64 loss: -2.25986385345459
Batch 6/64 loss: -2.094296455383301
Batch 7/64 loss: -2.405000686645508
Batch 8/64 loss: -2.3877410888671875
Batch 9/64 loss: -2.423020362854004
Batch 10/64 loss: -2.3353118896484375
Batch 11/64 loss: -2.379775047302246
Batch 12/64 loss: -2.549300193786621
Batch 13/64 loss: -2.497002601623535
Batch 14/64 loss: -2.537398338317871
Batch 15/64 loss: -2.2472991943359375
Batch 16/64 loss: -2.581918716430664
Batch 17/64 loss: -2.169981002807617
Batch 18/64 loss: -2.4853267669677734
Batch 19/64 loss: -2.2468528747558594
Batch 20/64 loss: -2.377168655395508
Batch 21/64 loss: -2.3723526000976562
Batch 22/64 loss: -2.069258689880371
Batch 23/64 loss: -2.3550920486450195
Batch 24/64 loss: -2.1041269302368164
Batch 25/64 loss: -2.192084312438965
Batch 26/64 loss: -2.4138736724853516
Batch 27/64 loss: -2.182910919189453
Batch 28/64 loss: -2.28908634185791
Batch 29/64 loss: -2.501171112060547
Batch 30/64 loss: -2.097508430480957
Batch 31/64 loss: -2.439268112182617
Batch 32/64 loss: -2.361644744873047
Batch 33/64 loss: -2.5452747344970703
Batch 34/64 loss: -2.3160934448242188
Batch 35/64 loss: -2.352358818054199
Batch 36/64 loss: -2.2877330780029297
Batch 37/64 loss: -2.5200681686401367
Batch 38/64 loss: -2.5188026428222656
Batch 39/64 loss: -2.461545944213867
Batch 40/64 loss: -2.4732542037963867
Batch 41/64 loss: -2.319150924682617
Batch 42/64 loss: -2.5004148483276367
Batch 43/64 loss: -2.4208154678344727
Batch 44/64 loss: -2.593886375427246
Batch 45/64 loss: -2.4180822372436523
Batch 46/64 loss: -2.0851354598999023
Batch 47/64 loss: -2.058821678161621
Batch 48/64 loss: -2.368596076965332
Batch 49/64 loss: -2.4549484252929688
Batch 50/64 loss: -2.1740341186523438
Batch 51/64 loss: -2.263678550720215
Batch 52/64 loss: -2.434558868408203
Batch 53/64 loss: -2.509140968322754
Batch 54/64 loss: -2.473886489868164
Batch 55/64 loss: -2.316531181335449
Batch 56/64 loss: -2.008744239807129
Batch 57/64 loss: -2.6610002517700195
Batch 58/64 loss: -2.2824764251708984
Batch 59/64 loss: -2.5101680755615234
Batch 60/64 loss: -2.4385147094726562
Batch 61/64 loss: -2.134309768676758
Batch 62/64 loss: -2.0434370040893555
Batch 63/64 loss: -2.3787431716918945
Batch 64/64 loss: -6.279245376586914
Epoch 175  Train loss: -2.3947923024495443  Val loss: -2.6383697142715716
Saving best model, epoch: 175
Epoch 176
-------------------------------
Batch 1/64 loss: -2.476302146911621
Batch 2/64 loss: -2.3188323974609375
Batch 3/64 loss: -2.36991024017334
Batch 4/64 loss: -2.4660425186157227
Batch 5/64 loss: -2.1284265518188477
Batch 6/64 loss: -2.0956668853759766
Batch 7/64 loss: -2.4952964782714844
Batch 8/64 loss: -2.5923309326171875
Batch 9/64 loss: -2.2398195266723633
Batch 10/64 loss: -2.572474479675293
Batch 11/64 loss: -2.595108985900879
Batch 12/64 loss: -2.67586612701416
Batch 13/64 loss: -2.5395631790161133
Batch 14/64 loss: -2.6184635162353516
Batch 15/64 loss: -2.3884963989257812
Batch 16/64 loss: -2.6406641006469727
Batch 17/64 loss: -2.392655372619629
Batch 18/64 loss: -2.254495620727539
Batch 19/64 loss: -2.4115724563598633
Batch 20/64 loss: -2.399505615234375
Batch 21/64 loss: -2.658440589904785
Batch 22/64 loss: -2.7068262100219727
Batch 23/64 loss: -2.3554649353027344
Batch 24/64 loss: -2.463033676147461
Batch 25/64 loss: -2.161520004272461
Batch 26/64 loss: -2.5200605392456055
Batch 27/64 loss: -2.357131004333496
Batch 28/64 loss: -2.2538156509399414
Batch 29/64 loss: -2.380769729614258
Batch 30/64 loss: -2.2552223205566406
Batch 31/64 loss: -2.253767967224121
Batch 32/64 loss: -2.4558658599853516
Batch 33/64 loss: -2.4746036529541016
Batch 34/64 loss: -2.550724983215332
Batch 35/64 loss: -2.276848793029785
Batch 36/64 loss: -2.412029266357422
Batch 37/64 loss: -2.440976142883301
Batch 38/64 loss: -2.6637659072875977
Batch 39/64 loss: -2.5904645919799805
Batch 40/64 loss: -2.650646209716797
Batch 41/64 loss: -2.3428955078125
Batch 42/64 loss: -2.601229667663574
Batch 43/64 loss: -2.432366371154785
Batch 44/64 loss: -2.5584182739257812
Batch 45/64 loss: -2.4066267013549805
Batch 46/64 loss: -2.223721504211426
Batch 47/64 loss: -2.3531084060668945
Batch 48/64 loss: -2.409515380859375
Batch 49/64 loss: -2.461459159851074
Batch 50/64 loss: -2.5593252182006836
Batch 51/64 loss: -1.8613367080688477
Batch 52/64 loss: -2.565608024597168
Batch 53/64 loss: -2.4649200439453125
Batch 54/64 loss: -2.392367362976074
Batch 55/64 loss: -2.371286392211914
Batch 56/64 loss: -2.5231103897094727
Batch 57/64 loss: -2.5347585678100586
Batch 58/64 loss: -2.4708595275878906
Batch 59/64 loss: -2.4148330688476562
Batch 60/64 loss: -2.4938840866088867
Batch 61/64 loss: -2.301377296447754
Batch 62/64 loss: -2.6494226455688477
Batch 63/64 loss: -2.315180778503418
Batch 64/64 loss: -6.6945719718933105
Epoch 176  Train loss: -2.482855084363152  Val loss: -2.684665863456595
Saving best model, epoch: 176
Epoch 177
-------------------------------
Batch 1/64 loss: -2.534238815307617
Batch 2/64 loss: -2.5484085083007812
Batch 3/64 loss: -2.384993553161621
Batch 4/64 loss: -2.085071563720703
Batch 5/64 loss: -2.534693717956543
Batch 6/64 loss: -2.313199043273926
Batch 7/64 loss: -2.545588493347168
Batch 8/64 loss: -2.5373849868774414
Batch 9/64 loss: -2.539107322692871
Batch 10/64 loss: -2.4654903411865234
Batch 11/64 loss: -2.1140546798706055
Batch 12/64 loss: -2.1338443756103516
Batch 13/64 loss: -2.6967973709106445
Batch 14/64 loss: -2.4780845642089844
Batch 15/64 loss: -2.300839424133301
Batch 16/64 loss: -2.5383663177490234
Batch 17/64 loss: -2.3677501678466797
Batch 18/64 loss: -2.5076370239257812
Batch 19/64 loss: -2.683600425720215
Batch 20/64 loss: -2.416745185852051
Batch 21/64 loss: -2.5945568084716797
Batch 22/64 loss: -2.5037031173706055
Batch 23/64 loss: -2.5801191329956055
Batch 24/64 loss: -2.419020652770996
Batch 25/64 loss: -2.4813528060913086
Batch 26/64 loss: -2.5910024642944336
Batch 27/64 loss: -2.3376998901367188
Batch 28/64 loss: -2.530520439147949
Batch 29/64 loss: -2.513731002807617
Batch 30/64 loss: -2.650867462158203
Batch 31/64 loss: -1.8572607040405273
Batch 32/64 loss: -2.6441879272460938
Batch 33/64 loss: -2.5869064331054688
Batch 34/64 loss: -2.302217483520508
Batch 35/64 loss: -2.333798408508301
Batch 36/64 loss: -2.121763229370117
Batch 37/64 loss: -2.338740348815918
Batch 38/64 loss: -2.4647598266601562
Batch 39/64 loss: -2.572739601135254
Batch 40/64 loss: -2.036149024963379
Batch 41/64 loss: -2.1645431518554688
Batch 42/64 loss: -2.204498291015625
Batch 43/64 loss: -2.3926610946655273
Batch 44/64 loss: -2.3661670684814453
Batch 45/64 loss: -2.4742250442504883
Batch 46/64 loss: -2.1894826889038086
Batch 47/64 loss: -2.3062877655029297
Batch 48/64 loss: -2.4626693725585938
Batch 49/64 loss: -2.3487634658813477
Batch 50/64 loss: -2.3692026138305664
Batch 51/64 loss: -2.400254249572754
Batch 52/64 loss: -2.459413528442383
Batch 53/64 loss: -2.651167869567871
Batch 54/64 loss: -2.008152961730957
Batch 55/64 loss: -2.435133934020996
Batch 56/64 loss: -2.2141714096069336
Batch 57/64 loss: -2.002321243286133
Batch 58/64 loss: -2.4652605056762695
Batch 59/64 loss: -2.5182085037231445
Batch 60/64 loss: -2.200479507446289
Batch 61/64 loss: -2.4204626083374023
Batch 62/64 loss: -2.4000244140625
Batch 63/64 loss: -2.4105348587036133
Batch 64/64 loss: -6.909241199493408
Epoch 177  Train loss: -2.45071387758442  Val loss: -2.705182904640014
Saving best model, epoch: 177
Epoch 178
-------------------------------
Batch 1/64 loss: -2.1722278594970703
Batch 2/64 loss: -2.390382766723633
Batch 3/64 loss: -2.306797981262207
Batch 4/64 loss: -2.4617977142333984
Batch 5/64 loss: -2.5258007049560547
Batch 6/64 loss: -2.4833812713623047
Batch 7/64 loss: -2.5228567123413086
Batch 8/64 loss: -2.2302026748657227
Batch 9/64 loss: -2.4416818618774414
Batch 10/64 loss: -2.40206241607666
Batch 11/64 loss: -2.5593080520629883
Batch 12/64 loss: -2.287851333618164
Batch 13/64 loss: -2.2982587814331055
Batch 14/64 loss: -1.9754838943481445
Batch 15/64 loss: -2.4934120178222656
Batch 16/64 loss: -2.1555099487304688
Batch 17/64 loss: -2.2140722274780273
Batch 18/64 loss: -2.646089553833008
Batch 19/64 loss: -2.178830146789551
Batch 20/64 loss: -2.371011734008789
Batch 21/64 loss: -2.1275739669799805
Batch 22/64 loss: -2.3291730880737305
Batch 23/64 loss: -2.1547489166259766
Batch 24/64 loss: -2.652181625366211
Batch 25/64 loss: -2.2821664810180664
Batch 26/64 loss: -2.572042465209961
Batch 27/64 loss: -2.283306121826172
Batch 28/64 loss: -2.5410919189453125
Batch 29/64 loss: -2.3947153091430664
Batch 30/64 loss: -2.4695701599121094
Batch 31/64 loss: -2.5965442657470703
Batch 32/64 loss: -2.4370040893554688
Batch 33/64 loss: -2.2900381088256836
Batch 34/64 loss: -2.545804977416992
Batch 35/64 loss: -2.2028493881225586
Batch 36/64 loss: -2.4594478607177734
Batch 37/64 loss: -2.3683700561523438
Batch 38/64 loss: -2.532355308532715
Batch 39/64 loss: -1.9644804000854492
Batch 40/64 loss: -2.191652297973633
Batch 41/64 loss: -2.1241397857666016
Batch 42/64 loss: -2.5376739501953125
Batch 43/64 loss: -2.2779884338378906
Batch 44/64 loss: -2.5589942932128906
Batch 45/64 loss: -1.948843002319336
Batch 46/64 loss: -2.4028024673461914
Batch 47/64 loss: -2.197847366333008
Batch 48/64 loss: -2.4768991470336914
Batch 49/64 loss: -2.281747817993164
Batch 50/64 loss: -2.46315860748291
Batch 51/64 loss: -2.0568904876708984
Batch 52/64 loss: -2.4995546340942383
Batch 53/64 loss: -2.4113283157348633
Batch 54/64 loss: -2.3481216430664062
Batch 55/64 loss: -2.498806953430176
Batch 56/64 loss: -2.612950325012207
Batch 57/64 loss: -2.555145263671875
Batch 58/64 loss: -2.459071159362793
Batch 59/64 loss: -2.53786563873291
Batch 60/64 loss: -2.3062543869018555
Batch 61/64 loss: -2.4494762420654297
Batch 62/64 loss: -2.4564361572265625
Batch 63/64 loss: -2.4750614166259766
Batch 64/64 loss: -6.907012462615967
Epoch 178  Train loss: -2.425560051787133  Val loss: -2.643141585936661
Epoch 179
-------------------------------
Batch 1/64 loss: -2.4800939559936523
Batch 2/64 loss: -2.2169008255004883
Batch 3/64 loss: -2.370990753173828
Batch 4/64 loss: -2.4254417419433594
Batch 5/64 loss: -2.414547920227051
Batch 6/64 loss: -2.4361400604248047
Batch 7/64 loss: -1.9658870697021484
Batch 8/64 loss: -2.51102352142334
Batch 9/64 loss: -2.299823760986328
Batch 10/64 loss: -2.5215139389038086
Batch 11/64 loss: -2.599018096923828
Batch 12/64 loss: -2.477299690246582
Batch 13/64 loss: -2.2124853134155273
Batch 14/64 loss: -1.4721956253051758
Batch 15/64 loss: -2.4758310317993164
Batch 16/64 loss: -2.571547508239746
Batch 17/64 loss: -2.4758548736572266
Batch 18/64 loss: -2.465701103210449
Batch 19/64 loss: -2.5280494689941406
Batch 20/64 loss: -2.3781986236572266
Batch 21/64 loss: -2.226729393005371
Batch 22/64 loss: -2.212963104248047
Batch 23/64 loss: -1.9848823547363281
Batch 24/64 loss: -2.576369285583496
Batch 25/64 loss: -2.4582748413085938
Batch 26/64 loss: -2.167840003967285
Batch 27/64 loss: -2.512383460998535
Batch 28/64 loss: -2.427279472351074
Batch 29/64 loss: -2.408620834350586
Batch 30/64 loss: -2.6025075912475586
Batch 31/64 loss: -2.496466636657715
Batch 32/64 loss: -2.218783378601074
Batch 33/64 loss: -2.091029167175293
Batch 34/64 loss: -2.3068838119506836
Batch 35/64 loss: -2.6691160202026367
Batch 36/64 loss: -2.513087272644043
Batch 37/64 loss: -2.447873115539551
Batch 38/64 loss: -2.493316650390625
Batch 39/64 loss: -2.335123062133789
Batch 40/64 loss: -2.355295181274414
Batch 41/64 loss: -2.558504104614258
Batch 42/64 loss: -2.265378952026367
Batch 43/64 loss: -2.4390087127685547
Batch 44/64 loss: -2.4991836547851562
Batch 45/64 loss: -2.4586801528930664
Batch 46/64 loss: -2.4762401580810547
Batch 47/64 loss: -2.5000314712524414
Batch 48/64 loss: -2.6231613159179688
Batch 49/64 loss: -2.5641746520996094
Batch 50/64 loss: -2.7937612533569336
Batch 51/64 loss: -2.5238513946533203
Batch 52/64 loss: -2.0811538696289062
Batch 53/64 loss: -2.3740100860595703
Batch 54/64 loss: -2.328280448913574
Batch 55/64 loss: -2.6712112426757812
Batch 56/64 loss: -2.502039909362793
Batch 57/64 loss: -2.4621639251708984
Batch 58/64 loss: -2.5477705001831055
Batch 59/64 loss: -2.647067070007324
Batch 60/64 loss: -2.451641082763672
Batch 61/64 loss: -2.5855417251586914
Batch 62/64 loss: -2.5516767501831055
Batch 63/64 loss: -2.1437320709228516
Batch 64/64 loss: -6.852720737457275
Epoch 179  Train loss: -2.4626066600575167  Val loss: -2.641776920593891
Epoch 180
-------------------------------
Batch 1/64 loss: -1.8695850372314453
Batch 2/64 loss: -1.7532081604003906
Batch 3/64 loss: -1.8815679550170898
Batch 4/64 loss: -2.3643369674682617
Batch 5/64 loss: -2.311945915222168
Batch 6/64 loss: -2.5548954010009766
Batch 7/64 loss: -2.440091133117676
Batch 8/64 loss: -2.3522443771362305
Batch 9/64 loss: -1.9768943786621094
Batch 10/64 loss: -2.1827316284179688
Batch 11/64 loss: -2.4869985580444336
Batch 12/64 loss: -2.6370553970336914
Batch 13/64 loss: -2.358506202697754
Batch 14/64 loss: -2.3384323120117188
Batch 15/64 loss: -2.270003318786621
Batch 16/64 loss: -2.2330799102783203
Batch 17/64 loss: -2.56711483001709
Batch 18/64 loss: -2.2551918029785156
Batch 19/64 loss: -2.49764347076416
Batch 20/64 loss: -2.34429931640625
Batch 21/64 loss: -2.5243539810180664
Batch 22/64 loss: -2.6552352905273438
Batch 23/64 loss: -2.651310920715332
Batch 24/64 loss: -2.376523017883301
Batch 25/64 loss: -2.421245574951172
Batch 26/64 loss: -2.500732421875
Batch 27/64 loss: -2.4605798721313477
Batch 28/64 loss: -2.3950624465942383
Batch 29/64 loss: -2.2776012420654297
Batch 30/64 loss: -2.5368423461914062
Batch 31/64 loss: -2.647017478942871
Batch 32/64 loss: -2.5638160705566406
Batch 33/64 loss: -2.4107179641723633
Batch 34/64 loss: -2.005289077758789
Batch 35/64 loss: -2.5058069229125977
Batch 36/64 loss: -2.5324745178222656
Batch 37/64 loss: -2.7188596725463867
Batch 38/64 loss: -2.634286880493164
Batch 39/64 loss: -2.556544303894043
Batch 40/64 loss: -2.2286510467529297
Batch 41/64 loss: -2.520228385925293
Batch 42/64 loss: -2.688473701477051
Batch 43/64 loss: -2.431241989135742
Batch 44/64 loss: -2.3570518493652344
Batch 45/64 loss: -2.3417882919311523
Batch 46/64 loss: -2.462588310241699
Batch 47/64 loss: -2.210503578186035
Batch 48/64 loss: -2.3828601837158203
Batch 49/64 loss: -2.5587778091430664
Batch 50/64 loss: -2.551799774169922
Batch 51/64 loss: -2.475081443786621
Batch 52/64 loss: -2.438706398010254
Batch 53/64 loss: -2.653346061706543
Batch 54/64 loss: -2.1826047897338867
Batch 55/64 loss: -2.3075103759765625
Batch 56/64 loss: -2.2242584228515625
Batch 57/64 loss: -2.644998550415039
Batch 58/64 loss: -2.614055633544922
Batch 59/64 loss: -2.4307804107666016
Batch 60/64 loss: -2.623051643371582
Batch 61/64 loss: -2.670262336730957
Batch 62/64 loss: -2.5657033920288086
Batch 63/64 loss: -2.5543222427368164
Batch 64/64 loss: -6.799049377441406
Epoch 180  Train loss: -2.46694995655733  Val loss: -2.741469864992751
Saving best model, epoch: 180
Epoch 181
-------------------------------
Batch 1/64 loss: -2.606947898864746
Batch 2/64 loss: -2.5748043060302734
Batch 3/64 loss: -1.8164052963256836
Batch 4/64 loss: -2.2513017654418945
Batch 5/64 loss: -2.590536117553711
Batch 6/64 loss: -2.4866867065429688
Batch 7/64 loss: -2.451536178588867
Batch 8/64 loss: -2.396145820617676
Batch 9/64 loss: -2.3290605545043945
Batch 10/64 loss: -2.704862594604492
Batch 11/64 loss: -2.6647729873657227
Batch 12/64 loss: -2.545962333679199
Batch 13/64 loss: -2.6060943603515625
Batch 14/64 loss: -2.479379653930664
Batch 15/64 loss: -1.7862777709960938
Batch 16/64 loss: -2.3517379760742188
Batch 17/64 loss: -2.330815315246582
Batch 18/64 loss: -2.5983972549438477
Batch 19/64 loss: -2.2996530532836914
Batch 20/64 loss: -2.3378171920776367
Batch 21/64 loss: -2.5441713333129883
Batch 22/64 loss: -2.590664863586426
Batch 23/64 loss: -2.350034713745117
Batch 24/64 loss: -2.624347686767578
Batch 25/64 loss: -2.562307357788086
Batch 26/64 loss: -2.3753108978271484
Batch 27/64 loss: -2.5679731369018555
Batch 28/64 loss: -2.4551706314086914
Batch 29/64 loss: -2.3652429580688477
Batch 30/64 loss: -2.4831886291503906
Batch 31/64 loss: -2.634129524230957
Batch 32/64 loss: -2.52634334564209
Batch 33/64 loss: -2.384561538696289
Batch 34/64 loss: -2.6783266067504883
Batch 35/64 loss: -2.196035385131836
Batch 36/64 loss: -2.4818124771118164
Batch 37/64 loss: -2.2715272903442383
Batch 38/64 loss: -2.609884262084961
Batch 39/64 loss: -2.485774040222168
Batch 40/64 loss: -2.429764747619629
Batch 41/64 loss: -2.5295934677124023
Batch 42/64 loss: -2.4762868881225586
Batch 43/64 loss: -1.916788101196289
Batch 44/64 loss: -2.4434070587158203
Batch 45/64 loss: -2.1917715072631836
Batch 46/64 loss: -2.5280046463012695
Batch 47/64 loss: -2.5793418884277344
Batch 48/64 loss: -2.296323776245117
Batch 49/64 loss: -2.138824462890625
Batch 50/64 loss: -2.3342037200927734
Batch 51/64 loss: -2.587935447692871
Batch 52/64 loss: -2.3718671798706055
Batch 53/64 loss: -2.4411773681640625
Batch 54/64 loss: -2.186849594116211
Batch 55/64 loss: -2.42868709564209
Batch 56/64 loss: -2.490593910217285
Batch 57/64 loss: -2.4750919342041016
Batch 58/64 loss: -2.6747865676879883
Batch 59/64 loss: -2.398636817932129
Batch 60/64 loss: -2.2676963806152344
Batch 61/64 loss: -2.176959991455078
Batch 62/64 loss: -2.5186080932617188
Batch 63/64 loss: -2.5837936401367188
Batch 64/64 loss: -7.030673503875732
Epoch 181  Train loss: -2.480564725165274  Val loss: -2.6891046111116705
Epoch 182
-------------------------------
Batch 1/64 loss: -2.523622512817383
Batch 2/64 loss: -2.6023035049438477
Batch 3/64 loss: -2.3418874740600586
Batch 4/64 loss: -2.0357255935668945
Batch 5/64 loss: -2.4065446853637695
Batch 6/64 loss: -2.490053176879883
Batch 7/64 loss: -2.3103437423706055
Batch 8/64 loss: -2.5134172439575195
Batch 9/64 loss: -2.008800506591797
Batch 10/64 loss: -2.352076530456543
Batch 11/64 loss: -2.4540863037109375
Batch 12/64 loss: -2.402115821838379
Batch 13/64 loss: -2.7122364044189453
Batch 14/64 loss: -2.4681529998779297
Batch 15/64 loss: -2.5264406204223633
Batch 16/64 loss: -2.6743812561035156
Batch 17/64 loss: -2.621488571166992
Batch 18/64 loss: -2.351980209350586
Batch 19/64 loss: -2.170551300048828
Batch 20/64 loss: -2.595822334289551
Batch 21/64 loss: -2.514921188354492
Batch 22/64 loss: -2.520479202270508
Batch 23/64 loss: -2.749927520751953
Batch 24/64 loss: -2.366988182067871
Batch 25/64 loss: -2.6087331771850586
Batch 26/64 loss: -2.578409194946289
Batch 27/64 loss: -2.2660093307495117
Batch 28/64 loss: -2.4437437057495117
Batch 29/64 loss: -2.402729034423828
Batch 30/64 loss: -2.391657829284668
Batch 31/64 loss: -2.582146644592285
Batch 32/64 loss: -2.514039993286133
Batch 33/64 loss: -2.490934371948242
Batch 34/64 loss: -2.5261306762695312
Batch 35/64 loss: -2.6591720581054688
Batch 36/64 loss: -1.9519681930541992
Batch 37/64 loss: -2.5484237670898438
Batch 38/64 loss: -2.0806884765625
Batch 39/64 loss: -2.54669189453125
Batch 40/64 loss: -2.598649024963379
Batch 41/64 loss: -2.0924415588378906
Batch 42/64 loss: -2.5208053588867188
Batch 43/64 loss: -2.3548202514648438
Batch 44/64 loss: -2.4312896728515625
Batch 45/64 loss: -2.4146995544433594
Batch 46/64 loss: -2.4897985458374023
Batch 47/64 loss: -2.385986328125
Batch 48/64 loss: -2.4325637817382812
Batch 49/64 loss: -2.481670379638672
Batch 50/64 loss: -2.561574935913086
Batch 51/64 loss: -2.4892215728759766
Batch 52/64 loss: -2.4689674377441406
Batch 53/64 loss: -2.328266143798828
Batch 54/64 loss: -2.1888961791992188
Batch 55/64 loss: -2.5554628372192383
Batch 56/64 loss: -2.486966133117676
Batch 57/64 loss: -2.418036460876465
Batch 58/64 loss: -2.6684093475341797
Batch 59/64 loss: -2.514714241027832
Batch 60/64 loss: -2.348324775695801
Batch 61/64 loss: -2.3597278594970703
Batch 62/64 loss: -2.403315544128418
Batch 63/64 loss: -1.9581871032714844
Batch 64/64 loss: -7.049307823181152
Epoch 182  Train loss: -2.4869898216397153  Val loss: -2.52224416831105
Epoch 183
-------------------------------
Batch 1/64 loss: -2.4121875762939453
Batch 2/64 loss: -2.066197395324707
Batch 3/64 loss: -2.3148317337036133
Batch 4/64 loss: -2.4575395584106445
Batch 5/64 loss: -2.3906002044677734
Batch 6/64 loss: -2.3125905990600586
Batch 7/64 loss: -2.6422510147094727
Batch 8/64 loss: -2.278109550476074
Batch 9/64 loss: -2.5432863235473633
Batch 10/64 loss: -2.4368362426757812
Batch 11/64 loss: -2.535212516784668
Batch 12/64 loss: -2.256770133972168
Batch 13/64 loss: -2.6938371658325195
Batch 14/64 loss: -2.047840118408203
Batch 15/64 loss: -2.387454032897949
Batch 16/64 loss: -2.711728096008301
Batch 17/64 loss: -2.487534523010254
Batch 18/64 loss: -2.577549934387207
Batch 19/64 loss: -2.4071569442749023
Batch 20/64 loss: -2.4757814407348633
Batch 21/64 loss: -2.301706314086914
Batch 22/64 loss: -2.5676040649414062
Batch 23/64 loss: -2.132171630859375
Batch 24/64 loss: -2.140277862548828
Batch 25/64 loss: -2.0651445388793945
Batch 26/64 loss: -2.5158910751342773
Batch 27/64 loss: -2.6651153564453125
Batch 28/64 loss: -2.311859130859375
Batch 29/64 loss: -2.0970945358276367
Batch 30/64 loss: -2.759768486022949
Batch 31/64 loss: -2.3079090118408203
Batch 32/64 loss: -2.1423940658569336
Batch 33/64 loss: -2.3189687728881836
Batch 34/64 loss: -2.292544364929199
Batch 35/64 loss: -2.4650449752807617
Batch 36/64 loss: -2.2188491821289062
Batch 37/64 loss: -2.384183883666992
Batch 38/64 loss: -2.574941635131836
Batch 39/64 loss: -2.640109062194824
Batch 40/64 loss: -2.6819515228271484
Batch 41/64 loss: -2.3423280715942383
Batch 42/64 loss: -2.7301158905029297
Batch 43/64 loss: -2.406810760498047
Batch 44/64 loss: -2.278265953063965
Batch 45/64 loss: -2.4646549224853516
Batch 46/64 loss: -2.3404464721679688
Batch 47/64 loss: -2.4434814453125
Batch 48/64 loss: -2.5679712295532227
Batch 49/64 loss: -2.3651857376098633
Batch 50/64 loss: -2.397366523742676
Batch 51/64 loss: -2.4750499725341797
Batch 52/64 loss: -2.316486358642578
Batch 53/64 loss: -2.471097946166992
Batch 54/64 loss: -2.0826120376586914
Batch 55/64 loss: -1.9623661041259766
Batch 56/64 loss: -2.567279815673828
Batch 57/64 loss: -2.3545045852661133
Batch 58/64 loss: -2.3666629791259766
Batch 59/64 loss: -2.244664192199707
Batch 60/64 loss: -2.331040382385254
Batch 61/64 loss: -2.336050033569336
Batch 62/64 loss: -2.1908702850341797
Batch 63/64 loss: -2.5649070739746094
Batch 64/64 loss: -6.766321182250977
Epoch 183  Train loss: -2.442255439010321  Val loss: -2.672791484295298
Epoch 184
-------------------------------
Batch 1/64 loss: -2.3890113830566406
Batch 2/64 loss: -2.500753402709961
Batch 3/64 loss: -2.578798294067383
Batch 4/64 loss: -2.5770797729492188
Batch 5/64 loss: -2.354691505432129
Batch 6/64 loss: -2.637392997741699
Batch 7/64 loss: -2.581523895263672
Batch 8/64 loss: -2.255861282348633
Batch 9/64 loss: -2.5579090118408203
Batch 10/64 loss: -2.5674352645874023
Batch 11/64 loss: -2.224048614501953
Batch 12/64 loss: -2.5392303466796875
Batch 13/64 loss: -2.5685863494873047
Batch 14/64 loss: -2.2778682708740234
Batch 15/64 loss: -2.2285356521606445
Batch 16/64 loss: -2.365201950073242
Batch 17/64 loss: -2.4016170501708984
Batch 18/64 loss: -2.4881105422973633
Batch 19/64 loss: -2.3610963821411133
Batch 20/64 loss: -2.6797523498535156
Batch 21/64 loss: -2.642106056213379
Batch 22/64 loss: -2.218212127685547
Batch 23/64 loss: -2.5154123306274414
Batch 24/64 loss: -2.279984474182129
Batch 25/64 loss: -2.258120536804199
Batch 26/64 loss: -2.44760799407959
Batch 27/64 loss: -2.5457706451416016
Batch 28/64 loss: -2.2102508544921875
Batch 29/64 loss: -2.308060646057129
Batch 30/64 loss: -2.53753662109375
Batch 31/64 loss: -2.7056570053100586
Batch 32/64 loss: -2.556325912475586
Batch 33/64 loss: -2.267825126647949
Batch 34/64 loss: -2.6472644805908203
Batch 35/64 loss: -2.3505477905273438
Batch 36/64 loss: -2.322382926940918
Batch 37/64 loss: -2.5603933334350586
Batch 38/64 loss: -2.6386213302612305
Batch 39/64 loss: -2.406341552734375
Batch 40/64 loss: -2.500326156616211
Batch 41/64 loss: -2.552260398864746
Batch 42/64 loss: -2.394947052001953
Batch 43/64 loss: -2.213571548461914
Batch 44/64 loss: -2.5646963119506836
Batch 45/64 loss: -1.9119415283203125
Batch 46/64 loss: -2.395465850830078
Batch 47/64 loss: -2.4506282806396484
Batch 48/64 loss: -2.608247756958008
Batch 49/64 loss: -2.5747900009155273
Batch 50/64 loss: -2.0948476791381836
Batch 51/64 loss: -2.53385066986084
Batch 52/64 loss: -2.1671266555786133
Batch 53/64 loss: -2.6911277770996094
Batch 54/64 loss: -2.3888092041015625
Batch 55/64 loss: -2.2923145294189453
Batch 56/64 loss: -2.5228986740112305
Batch 57/64 loss: -2.2768659591674805
Batch 58/64 loss: -2.3138065338134766
Batch 59/64 loss: -2.075432777404785
Batch 60/64 loss: -2.303370475769043
Batch 61/64 loss: -2.1714839935302734
Batch 62/64 loss: -2.3002634048461914
Batch 63/64 loss: -2.0387487411499023
Batch 64/64 loss: -6.6478118896484375
Epoch 184  Train loss: -2.4608095206466376  Val loss: -2.6605498848092517
Epoch 185
-------------------------------
Batch 1/64 loss: -2.5559206008911133
Batch 2/64 loss: -2.394775390625
Batch 3/64 loss: -2.39630126953125
Batch 4/64 loss: -2.5154361724853516
Batch 5/64 loss: -2.106051445007324
Batch 6/64 loss: -2.7040481567382812
Batch 7/64 loss: -2.5552825927734375
Batch 8/64 loss: -2.625002861022949
Batch 9/64 loss: -2.3736391067504883
Batch 10/64 loss: -2.393202781677246
Batch 11/64 loss: -2.363842010498047
Batch 12/64 loss: -2.571518898010254
Batch 13/64 loss: -2.3233184814453125
Batch 14/64 loss: -2.627261161804199
Batch 15/64 loss: -2.3958740234375
Batch 16/64 loss: -2.439396858215332
Batch 17/64 loss: -2.673220634460449
Batch 18/64 loss: -2.4255523681640625
Batch 19/64 loss: -2.4614810943603516
Batch 20/64 loss: -2.6384830474853516
Batch 21/64 loss: -2.338353157043457
Batch 22/64 loss: -2.2706899642944336
Batch 23/64 loss: -2.679694175720215
Batch 24/64 loss: -2.5507869720458984
Batch 25/64 loss: -2.526599884033203
Batch 26/64 loss: -2.510957717895508
Batch 27/64 loss: -2.5097532272338867
Batch 28/64 loss: -2.4301185607910156
Batch 29/64 loss: -2.5362253189086914
Batch 30/64 loss: -2.670680046081543
Batch 31/64 loss: -2.282280921936035
Batch 32/64 loss: -2.546006202697754
Batch 33/64 loss: -2.1880035400390625
Batch 34/64 loss: -2.4994001388549805
Batch 35/64 loss: -2.3117456436157227
Batch 36/64 loss: -2.192471504211426
Batch 37/64 loss: -2.3167877197265625
Batch 38/64 loss: -2.461899757385254
Batch 39/64 loss: -2.5199155807495117
Batch 40/64 loss: -2.245820999145508
Batch 41/64 loss: -2.3557376861572266
Batch 42/64 loss: -2.294973373413086
Batch 43/64 loss: -2.0890846252441406
Batch 44/64 loss: -2.5237836837768555
Batch 45/64 loss: -2.457538604736328
Batch 46/64 loss: -2.3222885131835938
Batch 47/64 loss: -2.347808837890625
Batch 48/64 loss: -2.2945451736450195
Batch 49/64 loss: -2.0189085006713867
Batch 50/64 loss: -2.4348068237304688
Batch 51/64 loss: -2.492288589477539
Batch 52/64 loss: -2.123760223388672
Batch 53/64 loss: -2.387941360473633
Batch 54/64 loss: -2.139373779296875
Batch 55/64 loss: -2.4732542037963867
Batch 56/64 loss: -2.562429428100586
Batch 57/64 loss: -2.45566463470459
Batch 58/64 loss: -2.0369787216186523
Batch 59/64 loss: -2.439518928527832
Batch 60/64 loss: -2.342850685119629
Batch 61/64 loss: -2.504199981689453
Batch 62/64 loss: -2.382619857788086
Batch 63/64 loss: -2.4131526947021484
Batch 64/64 loss: -7.074515342712402
Epoch 185  Train loss: -2.4678775749954522  Val loss: -2.6621298118145607
Epoch 186
-------------------------------
Batch 1/64 loss: -2.4781312942504883
Batch 2/64 loss: -2.3754663467407227
Batch 3/64 loss: -2.3453359603881836
Batch 4/64 loss: -2.464982032775879
Batch 5/64 loss: -2.3199501037597656
Batch 6/64 loss: -2.356182098388672
Batch 7/64 loss: -2.451812744140625
Batch 8/64 loss: -2.3518857955932617
Batch 9/64 loss: -2.2788658142089844
Batch 10/64 loss: -2.2661142349243164
Batch 11/64 loss: -2.094191551208496
Batch 12/64 loss: -2.5002145767211914
Batch 13/64 loss: -2.5035572052001953
Batch 14/64 loss: -2.6035003662109375
Batch 15/64 loss: -2.410015106201172
Batch 16/64 loss: -2.3204269409179688
Batch 17/64 loss: -2.4317808151245117
Batch 18/64 loss: -2.560288429260254
Batch 19/64 loss: -2.419722557067871
Batch 20/64 loss: -2.4217538833618164
Batch 21/64 loss: -1.3697948455810547
Batch 22/64 loss: -2.323481559753418
Batch 23/64 loss: -2.512662887573242
Batch 24/64 loss: -2.382305145263672
Batch 25/64 loss: -2.5970096588134766
Batch 26/64 loss: -2.2435474395751953
Batch 27/64 loss: -2.532947540283203
Batch 28/64 loss: -2.4845476150512695
Batch 29/64 loss: -2.3542909622192383
Batch 30/64 loss: -2.381223678588867
Batch 31/64 loss: -2.5068531036376953
Batch 32/64 loss: -2.2335662841796875
Batch 33/64 loss: -2.6143369674682617
Batch 34/64 loss: -2.5207033157348633
Batch 35/64 loss: -2.3200368881225586
Batch 36/64 loss: -2.4165878295898438
Batch 37/64 loss: -2.473729133605957
Batch 38/64 loss: -2.549431800842285
Batch 39/64 loss: -2.663008689880371
Batch 40/64 loss: -2.6103029251098633
Batch 41/64 loss: -2.721548080444336
Batch 42/64 loss: -2.599010467529297
Batch 43/64 loss: -2.4165210723876953
Batch 44/64 loss: -2.5504608154296875
Batch 45/64 loss: -2.4435462951660156
Batch 46/64 loss: -2.6331357955932617
Batch 47/64 loss: -2.6396989822387695
Batch 48/64 loss: -2.020078659057617
Batch 49/64 loss: -2.7003746032714844
Batch 50/64 loss: -2.413501739501953
Batch 51/64 loss: -2.237337112426758
Batch 52/64 loss: -2.504166603088379
Batch 53/64 loss: -2.3890342712402344
Batch 54/64 loss: -2.242788314819336
Batch 55/64 loss: -2.354123115539551
Batch 56/64 loss: -2.2190113067626953
Batch 57/64 loss: -2.342036247253418
Batch 58/64 loss: -2.25972843170166
Batch 59/64 loss: -2.509479522705078
Batch 60/64 loss: -2.290421485900879
Batch 61/64 loss: -2.165210723876953
Batch 62/64 loss: -2.637226104736328
Batch 63/64 loss: -2.485401153564453
Batch 64/64 loss: -7.149632930755615
Epoch 186  Train loss: -2.465578223209755  Val loss: -2.726009146044754
Epoch 187
-------------------------------
Batch 1/64 loss: -2.638965606689453
Batch 2/64 loss: -2.5012359619140625
Batch 3/64 loss: -2.7762632369995117
Batch 4/64 loss: -2.515077590942383
Batch 5/64 loss: -2.338125228881836
Batch 6/64 loss: -2.3042802810668945
Batch 7/64 loss: -2.552762031555176
Batch 8/64 loss: -2.7202863693237305
Batch 9/64 loss: -2.433553695678711
Batch 10/64 loss: -2.3390331268310547
Batch 11/64 loss: -2.609156608581543
Batch 12/64 loss: -2.365767478942871
Batch 13/64 loss: -2.419862747192383
Batch 14/64 loss: -2.306948661804199
Batch 15/64 loss: -2.3461008071899414
Batch 16/64 loss: -2.4724273681640625
Batch 17/64 loss: -2.360690116882324
Batch 18/64 loss: -2.545313835144043
Batch 19/64 loss: -2.456117630004883
Batch 20/64 loss: -2.5719118118286133
Batch 21/64 loss: -2.549778938293457
Batch 22/64 loss: -2.7374420166015625
Batch 23/64 loss: -2.1727380752563477
Batch 24/64 loss: -2.5963010787963867
Batch 25/64 loss: -1.7446813583374023
Batch 26/64 loss: -2.488335609436035
Batch 27/64 loss: -2.3640689849853516
Batch 28/64 loss: -2.3873291015625
Batch 29/64 loss: -2.5725326538085938
Batch 30/64 loss: -2.377809524536133
Batch 31/64 loss: -2.5846023559570312
Batch 32/64 loss: -2.6374034881591797
Batch 33/64 loss: -2.5774316787719727
Batch 34/64 loss: -2.2779407501220703
Batch 35/64 loss: -2.508657455444336
Batch 36/64 loss: -2.33547306060791
Batch 37/64 loss: -2.06500244140625
Batch 38/64 loss: -2.3585033416748047
Batch 39/64 loss: -2.521246910095215
Batch 40/64 loss: -2.5236434936523438
Batch 41/64 loss: -2.2817087173461914
Batch 42/64 loss: -2.249065399169922
Batch 43/64 loss: -2.1252059936523438
Batch 44/64 loss: -2.3809003829956055
Batch 45/64 loss: -2.00753116607666
Batch 46/64 loss: -2.560990333557129
Batch 47/64 loss: -2.355680465698242
Batch 48/64 loss: -2.54495906829834
Batch 49/64 loss: -2.4089431762695312
Batch 50/64 loss: -2.4438905715942383
Batch 51/64 loss: -2.758835792541504
Batch 52/64 loss: -2.237563133239746
Batch 53/64 loss: -2.521251678466797
Batch 54/64 loss: -2.7175216674804688
Batch 55/64 loss: -2.550271987915039
Batch 56/64 loss: -2.6349754333496094
Batch 57/64 loss: -2.407865524291992
Batch 58/64 loss: -2.505830764770508
Batch 59/64 loss: -2.5407896041870117
Batch 60/64 loss: -2.5882301330566406
Batch 61/64 loss: -2.4449901580810547
Batch 62/64 loss: -2.248208999633789
Batch 63/64 loss: -2.6128435134887695
Batch 64/64 loss: -6.890522003173828
Epoch 187  Train loss: -2.4980509440104166  Val loss: -2.635110756785599
Epoch 188
-------------------------------
Batch 1/64 loss: -2.47432804107666
Batch 2/64 loss: -2.539388656616211
Batch 3/64 loss: -2.4387645721435547
Batch 4/64 loss: -2.4505672454833984
Batch 5/64 loss: -2.6694107055664062
Batch 6/64 loss: -2.46144962310791
Batch 7/64 loss: -2.5606136322021484
Batch 8/64 loss: -2.542365074157715
Batch 9/64 loss: -2.5080738067626953
Batch 10/64 loss: -2.302602767944336
Batch 11/64 loss: -2.537684440612793
Batch 12/64 loss: -2.822134017944336
Batch 13/64 loss: -2.483064651489258
Batch 14/64 loss: -2.5906314849853516
Batch 15/64 loss: -2.015237808227539
Batch 16/64 loss: -2.508894920349121
Batch 17/64 loss: -2.425156593322754
Batch 18/64 loss: -2.6741695404052734
Batch 19/64 loss: -2.4621057510375977
Batch 20/64 loss: -2.281559944152832
Batch 21/64 loss: -2.536968231201172
Batch 22/64 loss: -2.388833999633789
Batch 23/64 loss: -2.4579591751098633
Batch 24/64 loss: -2.4408884048461914
Batch 25/64 loss: -2.4377012252807617
Batch 26/64 loss: -2.433169364929199
Batch 27/64 loss: -2.425978660583496
Batch 28/64 loss: -2.5401296615600586
Batch 29/64 loss: -2.535515785217285
Batch 30/64 loss: -2.618051528930664
Batch 31/64 loss: -2.1578941345214844
Batch 32/64 loss: -2.143970489501953
Batch 33/64 loss: -2.3799076080322266
Batch 34/64 loss: -2.60394287109375
Batch 35/64 loss: -2.3393354415893555
Batch 36/64 loss: -2.3543052673339844
Batch 37/64 loss: -2.272280693054199
Batch 38/64 loss: -2.3863439559936523
Batch 39/64 loss: -2.4930286407470703
Batch 40/64 loss: -2.3792381286621094
Batch 41/64 loss: -2.512995719909668
Batch 42/64 loss: -2.408535957336426
Batch 43/64 loss: -2.588015556335449
Batch 44/64 loss: -2.322843551635742
Batch 45/64 loss: -2.3676490783691406
Batch 46/64 loss: -2.489572525024414
Batch 47/64 loss: -2.280367851257324
Batch 48/64 loss: -2.531047821044922
Batch 49/64 loss: -2.407027244567871
Batch 50/64 loss: -2.4111013412475586
Batch 51/64 loss: -2.7180919647216797
Batch 52/64 loss: -2.3776350021362305
Batch 53/64 loss: -2.2982254028320312
Batch 54/64 loss: -2.5019845962524414
Batch 55/64 loss: -2.321415901184082
Batch 56/64 loss: -2.304684638977051
Batch 57/64 loss: -2.43448543548584
Batch 58/64 loss: -2.1080026626586914
Batch 59/64 loss: -2.3788442611694336
Batch 60/64 loss: -2.3881139755249023
Batch 61/64 loss: -2.172297477722168
Batch 62/64 loss: -2.374624252319336
Batch 63/64 loss: -2.3657474517822266
Batch 64/64 loss: -7.027158737182617
Epoch 188  Train loss: -2.4848207885143805  Val loss: -2.6420961360341493
Epoch 189
-------------------------------
Batch 1/64 loss: -2.319845199584961
Batch 2/64 loss: -2.3826770782470703
Batch 3/64 loss: -1.9725942611694336
Batch 4/64 loss: -2.510159492492676
Batch 5/64 loss: -2.2564945220947266
Batch 6/64 loss: -2.1877212524414062
Batch 7/64 loss: -2.278470993041992
Batch 8/64 loss: -2.3402090072631836
Batch 9/64 loss: -2.453052520751953
Batch 10/64 loss: -2.2972326278686523
Batch 11/64 loss: -2.0994138717651367
Batch 12/64 loss: -2.5127830505371094
Batch 13/64 loss: -2.4235639572143555
Batch 14/64 loss: -2.2626514434814453
Batch 15/64 loss: -2.2457666397094727
Batch 16/64 loss: -2.383756637573242
Batch 17/64 loss: -2.352842330932617
Batch 18/64 loss: -2.403104782104492
Batch 19/64 loss: -2.601130485534668
Batch 20/64 loss: -2.231779098510742
Batch 21/64 loss: -2.540299415588379
Batch 22/64 loss: -2.287716865539551
Batch 23/64 loss: -2.1859331130981445
Batch 24/64 loss: -2.361391067504883
Batch 25/64 loss: -2.3342199325561523
Batch 26/64 loss: -2.6000823974609375
Batch 27/64 loss: -2.3032407760620117
Batch 28/64 loss: -2.5002832412719727
Batch 29/64 loss: -2.6110382080078125
Batch 30/64 loss: -2.5123062133789062
Batch 31/64 loss: -2.0200138092041016
Batch 32/64 loss: -2.480828285217285
Batch 33/64 loss: -2.5189714431762695
Batch 34/64 loss: -2.2743968963623047
Batch 35/64 loss: -2.3976268768310547
Batch 36/64 loss: -2.094829559326172
Batch 37/64 loss: -2.5715513229370117
Batch 38/64 loss: -2.2411251068115234
Batch 39/64 loss: -2.454554557800293
Batch 40/64 loss: -2.0634918212890625
Batch 41/64 loss: -2.0983171463012695
Batch 42/64 loss: -2.494839668273926
Batch 43/64 loss: -2.3101911544799805
Batch 44/64 loss: -2.5032567977905273
Batch 45/64 loss: -2.4636268615722656
Batch 46/64 loss: -2.2782373428344727
Batch 47/64 loss: -2.280259132385254
Batch 48/64 loss: -2.346010208129883
Batch 49/64 loss: -2.4802589416503906
Batch 50/64 loss: -2.0245580673217773
Batch 51/64 loss: -2.0238285064697266
Batch 52/64 loss: -2.5638227462768555
Batch 53/64 loss: -2.412027359008789
Batch 54/64 loss: -2.380718231201172
Batch 55/64 loss: -2.451470375061035
Batch 56/64 loss: -2.2825326919555664
Batch 57/64 loss: -2.6302175521850586
Batch 58/64 loss: -2.473748207092285
Batch 59/64 loss: -2.41513729095459
Batch 60/64 loss: -2.534402847290039
Batch 61/64 loss: -2.30605411529541
Batch 62/64 loss: -1.9802484512329102
Batch 63/64 loss: -2.587667465209961
Batch 64/64 loss: -7.178079128265381
Epoch 189  Train loss: -2.409006128124162  Val loss: -2.6794171021976014
Epoch 190
-------------------------------
Batch 1/64 loss: -2.1547136306762695
Batch 2/64 loss: -2.4857072830200195
Batch 3/64 loss: -2.5584468841552734
Batch 4/64 loss: -2.474360466003418
Batch 5/64 loss: -2.368893623352051
Batch 6/64 loss: -2.2344207763671875
Batch 7/64 loss: -2.1759872436523438
Batch 8/64 loss: -2.5125560760498047
Batch 9/64 loss: -2.0618200302124023
Batch 10/64 loss: -2.3873214721679688
Batch 11/64 loss: -2.265552520751953
Batch 12/64 loss: -2.278179168701172
Batch 13/64 loss: -2.456112861633301
Batch 14/64 loss: -2.3641414642333984
Batch 15/64 loss: -2.221080780029297
Batch 16/64 loss: -2.478146553039551
Batch 17/64 loss: -2.2964353561401367
Batch 18/64 loss: -2.344348907470703
Batch 19/64 loss: -2.300863265991211
Batch 20/64 loss: -2.4095115661621094
Batch 21/64 loss: -2.5509719848632812
Batch 22/64 loss: -2.488865852355957
Batch 23/64 loss: -1.7970075607299805
Batch 24/64 loss: -2.454522132873535
Batch 25/64 loss: -2.3305463790893555
Batch 26/64 loss: -2.54543399810791
Batch 27/64 loss: -2.394489288330078
Batch 28/64 loss: -2.4079771041870117
Batch 29/64 loss: -2.211576461791992
Batch 30/64 loss: -2.3996753692626953
Batch 31/64 loss: -2.059415817260742
Batch 32/64 loss: -2.717458724975586
Batch 33/64 loss: -2.4351587295532227
Batch 34/64 loss: -2.307623863220215
Batch 35/64 loss: -2.464646339416504
Batch 36/64 loss: -2.3483171463012695
Batch 37/64 loss: -2.3360862731933594
Batch 38/64 loss: -2.219270706176758
Batch 39/64 loss: -2.3110198974609375
Batch 40/64 loss: -2.2529211044311523
Batch 41/64 loss: -2.548039436340332
Batch 42/64 loss: -2.4603271484375
Batch 43/64 loss: -2.6247806549072266
Batch 44/64 loss: -2.150357246398926
Batch 45/64 loss: -2.358647346496582
Batch 46/64 loss: -2.683138847351074
Batch 47/64 loss: -2.5380868911743164
Batch 48/64 loss: -2.384767532348633
Batch 49/64 loss: -2.582217216491699
Batch 50/64 loss: -2.452437400817871
Batch 51/64 loss: -2.4388599395751953
Batch 52/64 loss: -2.362276077270508
Batch 53/64 loss: -2.554335594177246
Batch 54/64 loss: -2.3898019790649414
Batch 55/64 loss: -2.455352783203125
Batch 56/64 loss: -2.4412126541137695
Batch 57/64 loss: -2.4187870025634766
Batch 58/64 loss: -2.4830121994018555
Batch 59/64 loss: -2.2666053771972656
Batch 60/64 loss: -2.492609977722168
Batch 61/64 loss: -1.9399518966674805
Batch 62/64 loss: -2.625337600708008
Batch 63/64 loss: -2.2891950607299805
Batch 64/64 loss: -6.879469871520996
Epoch 190  Train loss: -2.4307658812578987  Val loss: -2.7120075422463956
Epoch 191
-------------------------------
Batch 1/64 loss: -2.3591184616088867
Batch 2/64 loss: -2.4937782287597656
Batch 3/64 loss: -2.1954469680786133
Batch 4/64 loss: -2.3988399505615234
Batch 5/64 loss: -2.3093690872192383
Batch 6/64 loss: -2.6006669998168945
Batch 7/64 loss: -2.532036781311035
Batch 8/64 loss: -2.6348419189453125
Batch 9/64 loss: -2.272930145263672
Batch 10/64 loss: -2.7322683334350586
Batch 11/64 loss: -2.3724288940429688
Batch 12/64 loss: -2.076615333557129
Batch 13/64 loss: -2.6718339920043945
Batch 14/64 loss: -2.2234392166137695
Batch 15/64 loss: -2.5132083892822266
Batch 16/64 loss: -2.536611557006836
Batch 17/64 loss: -2.5863542556762695
Batch 18/64 loss: -2.4537734985351562
Batch 19/64 loss: -2.681163787841797
Batch 20/64 loss: -2.347471237182617
Batch 21/64 loss: -2.2904129028320312
Batch 22/64 loss: -2.556699752807617
Batch 23/64 loss: -2.5168228149414062
Batch 24/64 loss: -2.6523866653442383
Batch 25/64 loss: -2.4755449295043945
Batch 26/64 loss: -2.419675827026367
Batch 27/64 loss: -2.5268850326538086
Batch 28/64 loss: -2.403111457824707
Batch 29/64 loss: -2.423436164855957
Batch 30/64 loss: -2.473006248474121
Batch 31/64 loss: -2.6062450408935547
Batch 32/64 loss: -2.614993095397949
Batch 33/64 loss: -2.4175195693969727
Batch 34/64 loss: -2.702273368835449
Batch 35/64 loss: -2.6526594161987305
Batch 36/64 loss: -2.715825080871582
Batch 37/64 loss: -2.6444530487060547
Batch 38/64 loss: -2.7635326385498047
Batch 39/64 loss: -2.5843658447265625
Batch 40/64 loss: -2.4764795303344727
Batch 41/64 loss: -2.5503435134887695
Batch 42/64 loss: -2.418607711791992
Batch 43/64 loss: -2.6204957962036133
Batch 44/64 loss: -2.1646785736083984
Batch 45/64 loss: -2.3199310302734375
Batch 46/64 loss: -2.5278091430664062
Batch 47/64 loss: -2.128803253173828
Batch 48/64 loss: -2.4017553329467773
Batch 49/64 loss: -2.4521102905273438
Batch 50/64 loss: -2.4523391723632812
Batch 51/64 loss: -2.4066829681396484
Batch 52/64 loss: -2.6258621215820312
Batch 53/64 loss: -2.4727182388305664
Batch 54/64 loss: -2.111575126647949
Batch 55/64 loss: -2.5272274017333984
Batch 56/64 loss: -2.597771644592285
Batch 57/64 loss: -2.262770652770996
Batch 58/64 loss: -2.489445686340332
Batch 59/64 loss: -2.560518264770508
Batch 60/64 loss: -2.4600677490234375
Batch 61/64 loss: -2.704120635986328
Batch 62/64 loss: -2.5257081985473633
Batch 63/64 loss: -2.31668758392334
Batch 64/64 loss: -7.067092418670654
Epoch 191  Train loss: -2.5303039195490817  Val loss: -2.6403492275382234
Epoch 192
-------------------------------
Batch 1/64 loss: -2.348788261413574
Batch 2/64 loss: -2.54787540435791
Batch 3/64 loss: -2.854243278503418
Batch 4/64 loss: -2.6044187545776367
Batch 5/64 loss: -2.422445297241211
Batch 6/64 loss: -2.120781898498535
Batch 7/64 loss: -2.740372657775879
Batch 8/64 loss: -2.614910125732422
Batch 9/64 loss: -2.1284561157226562
Batch 10/64 loss: -2.310626983642578
Batch 11/64 loss: -2.759749412536621
Batch 12/64 loss: -2.536982536315918
Batch 13/64 loss: -2.566451072692871
Batch 14/64 loss: -2.731069564819336
Batch 15/64 loss: -2.6351280212402344
Batch 16/64 loss: -2.560842514038086
Batch 17/64 loss: -2.4117937088012695
Batch 18/64 loss: -2.453521728515625
Batch 19/64 loss: -2.456303596496582
Batch 20/64 loss: -2.6354074478149414
Batch 21/64 loss: -2.4363107681274414
Batch 22/64 loss: -2.5079545974731445
Batch 23/64 loss: -2.6206655502319336
Batch 24/64 loss: -2.372892379760742
Batch 25/64 loss: -2.579132080078125
Batch 26/64 loss: -2.628037452697754
Batch 27/64 loss: -2.5705642700195312
Batch 28/64 loss: -2.6708145141601562
Batch 29/64 loss: -2.5237550735473633
Batch 30/64 loss: -2.7213621139526367
Batch 31/64 loss: -2.6283369064331055
Batch 32/64 loss: -2.620941162109375
Batch 33/64 loss: -2.1283798217773438
Batch 34/64 loss: -2.703120231628418
Batch 35/64 loss: -2.260991096496582
Batch 36/64 loss: -2.3440141677856445
Batch 37/64 loss: -2.6607131958007812
Batch 38/64 loss: -2.3209285736083984
Batch 39/64 loss: -2.5239877700805664
Batch 40/64 loss: -2.3743486404418945
Batch 41/64 loss: -2.351358413696289
Batch 42/64 loss: -2.620443344116211
Batch 43/64 loss: -2.634629249572754
Batch 44/64 loss: -2.707554817199707
Batch 45/64 loss: -2.204458236694336
Batch 46/64 loss: -2.4452409744262695
Batch 47/64 loss: -2.5554122924804688
Batch 48/64 loss: -2.4591856002807617
Batch 49/64 loss: -2.574718475341797
Batch 50/64 loss: -2.47952938079834
Batch 51/64 loss: -2.494974136352539
Batch 52/64 loss: -2.4302873611450195
Batch 53/64 loss: -2.3030691146850586
Batch 54/64 loss: -2.858592987060547
Batch 55/64 loss: -2.292117118835449
Batch 56/64 loss: -2.5247650146484375
Batch 57/64 loss: -2.4309206008911133
Batch 58/64 loss: -2.6728734970092773
Batch 59/64 loss: -2.7397241592407227
Batch 60/64 loss: -2.310004234313965
Batch 61/64 loss: -2.2955284118652344
Batch 62/64 loss: -2.523517608642578
Batch 63/64 loss: -2.7319021224975586
Batch 64/64 loss: -7.004898548126221
Epoch 192  Train loss: -2.5652062715268604  Val loss: -2.8092996263012444
Saving best model, epoch: 192
Epoch 193
-------------------------------
Batch 1/64 loss: -2.489564895629883
Batch 2/64 loss: -2.500044822692871
Batch 3/64 loss: -2.326045036315918
Batch 4/64 loss: -1.9675712585449219
Batch 5/64 loss: -2.442319869995117
Batch 6/64 loss: -2.5230398178100586
Batch 7/64 loss: -2.744852066040039
Batch 8/64 loss: -2.466763496398926
Batch 9/64 loss: -2.535080909729004
Batch 10/64 loss: -2.3172073364257812
Batch 11/64 loss: -2.3536014556884766
Batch 12/64 loss: -2.759524345397949
Batch 13/64 loss: -2.464188575744629
Batch 14/64 loss: -2.098782539367676
Batch 15/64 loss: -2.4917287826538086
Batch 16/64 loss: -2.486125946044922
Batch 17/64 loss: -2.765899658203125
Batch 18/64 loss: -2.2639760971069336
Batch 19/64 loss: -2.501765251159668
Batch 20/64 loss: -2.102166175842285
Batch 21/64 loss: -2.636479377746582
Batch 22/64 loss: -2.390483856201172
Batch 23/64 loss: -2.6512622833251953
Batch 24/64 loss: -2.715695381164551
Batch 25/64 loss: -2.523754119873047
Batch 26/64 loss: -2.5039281845092773
Batch 27/64 loss: -2.628620147705078
Batch 28/64 loss: -2.378061294555664
Batch 29/64 loss: -2.6434717178344727
Batch 30/64 loss: -2.513197898864746
Batch 31/64 loss: -2.4183483123779297
Batch 32/64 loss: -2.742861747741699
Batch 33/64 loss: -2.5564775466918945
Batch 34/64 loss: -2.7092628479003906
Batch 35/64 loss: -2.5134057998657227
Batch 36/64 loss: -2.8449182510375977
Batch 37/64 loss: -2.7704086303710938
Batch 38/64 loss: -2.417013168334961
Batch 39/64 loss: -2.653622627258301
Batch 40/64 loss: -2.4355316162109375
Batch 41/64 loss: -2.5949792861938477
Batch 42/64 loss: -2.6249160766601562
Batch 43/64 loss: -2.3488826751708984
Batch 44/64 loss: -2.6666603088378906
Batch 45/64 loss: -2.6053342819213867
Batch 46/64 loss: -2.3888397216796875
Batch 47/64 loss: -2.697768211364746
Batch 48/64 loss: -2.444403648376465
Batch 49/64 loss: -2.4563140869140625
Batch 50/64 loss: -2.1540260314941406
Batch 51/64 loss: -2.236416816711426
Batch 52/64 loss: -2.4099855422973633
Batch 53/64 loss: -2.1734180450439453
Batch 54/64 loss: -2.398965835571289
Batch 55/64 loss: -2.7030601501464844
Batch 56/64 loss: -2.1571435928344727
Batch 57/64 loss: -2.5608835220336914
Batch 58/64 loss: -2.572834014892578
Batch 59/64 loss: -2.5511255264282227
Batch 60/64 loss: -2.569028854370117
Batch 61/64 loss: -2.3858509063720703
Batch 62/64 loss: -2.6944265365600586
Batch 63/64 loss: -2.3888769149780273
Batch 64/64 loss: -6.7367844581604
Epoch 193  Train loss: -2.5424906992444805  Val loss: -2.736099570887195
Epoch 194
-------------------------------
Batch 1/64 loss: -2.525790214538574
Batch 2/64 loss: -2.580031394958496
Batch 3/64 loss: -2.013233184814453
Batch 4/64 loss: -2.6403894424438477
Batch 5/64 loss: -2.3556957244873047
Batch 6/64 loss: -2.5000553131103516
Batch 7/64 loss: -2.4540233612060547
Batch 8/64 loss: -2.1997127532958984
Batch 9/64 loss: -2.280819892883301
Batch 10/64 loss: -2.5439796447753906
Batch 11/64 loss: -2.4084701538085938
Batch 12/64 loss: -2.720456123352051
Batch 13/64 loss: -2.591310501098633
Batch 14/64 loss: -2.461414337158203
Batch 15/64 loss: -2.4124088287353516
Batch 16/64 loss: -2.5687999725341797
Batch 17/64 loss: -2.53878116607666
Batch 18/64 loss: -2.4785242080688477
Batch 19/64 loss: -2.584710121154785
Batch 20/64 loss: -2.6092405319213867
Batch 21/64 loss: -2.641964912414551
Batch 22/64 loss: -2.618305206298828
Batch 23/64 loss: -2.4865779876708984
Batch 24/64 loss: -2.264253616333008
Batch 25/64 loss: -2.1790666580200195
Batch 26/64 loss: -2.691155433654785
Batch 27/64 loss: -2.4040746688842773
Batch 28/64 loss: -2.833343505859375
Batch 29/64 loss: -2.45858097076416
Batch 30/64 loss: -2.532862663269043
Batch 31/64 loss: -2.497772216796875
Batch 32/64 loss: -2.6300926208496094
Batch 33/64 loss: -2.3463268280029297
Batch 34/64 loss: -2.0526647567749023
Batch 35/64 loss: -2.0458831787109375
Batch 36/64 loss: -2.622134208679199
Batch 37/64 loss: -2.585573196411133
Batch 38/64 loss: -2.4621267318725586
Batch 39/64 loss: -2.4949445724487305
Batch 40/64 loss: -2.475170135498047
Batch 41/64 loss: -2.3796138763427734
Batch 42/64 loss: -2.491621971130371
Batch 43/64 loss: -2.728271484375
Batch 44/64 loss: -2.3934688568115234
Batch 45/64 loss: -2.5856590270996094
Batch 46/64 loss: -2.5658273696899414
Batch 47/64 loss: -2.5945777893066406
Batch 48/64 loss: -2.55203914642334
Batch 49/64 loss: -2.4372806549072266
Batch 50/64 loss: -2.3157663345336914
Batch 51/64 loss: -2.354668617248535
Batch 52/64 loss: -2.3885250091552734
Batch 53/64 loss: -2.614291191101074
Batch 54/64 loss: -2.5454225540161133
Batch 55/64 loss: -2.3664674758911133
Batch 56/64 loss: -2.42657470703125
Batch 57/64 loss: -2.4063358306884766
Batch 58/64 loss: -2.6375865936279297
Batch 59/64 loss: -2.523056983947754
Batch 60/64 loss: -2.355581283569336
Batch 61/64 loss: -1.669921875
Batch 62/64 loss: -2.773585319519043
Batch 63/64 loss: -2.3057775497436523
Batch 64/64 loss: -7.134456634521484
Epoch 194  Train loss: -2.518486037908816  Val loss: -2.6501010619487957
Epoch 195
-------------------------------
Batch 1/64 loss: -2.614222526550293
Batch 2/64 loss: -2.33712100982666
Batch 3/64 loss: -2.5661611557006836
Batch 4/64 loss: -2.5908899307250977
Batch 5/64 loss: -2.4861717224121094
Batch 6/64 loss: -2.4878578186035156
Batch 7/64 loss: -2.653980255126953
Batch 8/64 loss: -2.632756233215332
Batch 9/64 loss: -2.135723114013672
Batch 10/64 loss: -2.6577281951904297
Batch 11/64 loss: -2.5483036041259766
Batch 12/64 loss: -2.557663917541504
Batch 13/64 loss: -2.115178108215332
Batch 14/64 loss: -2.487179756164551
Batch 15/64 loss: -1.7755460739135742
Batch 16/64 loss: -1.8337774276733398
Batch 17/64 loss: -2.4567337036132812
Batch 18/64 loss: -2.6540088653564453
Batch 19/64 loss: -2.3342161178588867
Batch 20/64 loss: -2.4208078384399414
Batch 21/64 loss: -2.438267707824707
Batch 22/64 loss: -2.291102409362793
Batch 23/64 loss: -2.3935546875
Batch 24/64 loss: -2.675644874572754
Batch 25/64 loss: -2.495123863220215
Batch 26/64 loss: -2.0948801040649414
Batch 27/64 loss: -2.207472801208496
Batch 28/64 loss: -2.4000253677368164
Batch 29/64 loss: -2.5217857360839844
Batch 30/64 loss: -2.3632631301879883
Batch 31/64 loss: -2.380486488342285
Batch 32/64 loss: -2.496366500854492
Batch 33/64 loss: -2.4664487838745117
Batch 34/64 loss: -2.4572067260742188
Batch 35/64 loss: -2.5884265899658203
Batch 36/64 loss: -2.345078468322754
Batch 37/64 loss: -2.252696990966797
Batch 38/64 loss: -2.6516828536987305
Batch 39/64 loss: -2.5144424438476562
Batch 40/64 loss: -2.7019872665405273
Batch 41/64 loss: -2.5878734588623047
Batch 42/64 loss: -2.428323745727539
Batch 43/64 loss: -2.595287322998047
Batch 44/64 loss: -2.4026193618774414
Batch 45/64 loss: -2.19460391998291
Batch 46/64 loss: -2.566793441772461
Batch 47/64 loss: -2.598538398742676
Batch 48/64 loss: -2.557779312133789
Batch 49/64 loss: -2.5723447799682617
Batch 50/64 loss: -2.6377029418945312
Batch 51/64 loss: -2.1610336303710938
Batch 52/64 loss: -2.5821285247802734
Batch 53/64 loss: -2.518143653869629
Batch 54/64 loss: -2.456099510192871
Batch 55/64 loss: -2.732431411743164
Batch 56/64 loss: -2.551849365234375
Batch 57/64 loss: -2.533914566040039
Batch 58/64 loss: -2.2708559036254883
Batch 59/64 loss: -2.4616451263427734
Batch 60/64 loss: -2.464785575866699
Batch 61/64 loss: -2.7450904846191406
Batch 62/64 loss: -2.5276451110839844
Batch 63/64 loss: -2.65435791015625
Batch 64/64 loss: -7.081244945526123
Epoch 195  Train loss: -2.512858860165465  Val loss: -2.6488268612995998
Epoch 196
-------------------------------
Batch 1/64 loss: -2.608144760131836
Batch 2/64 loss: -2.219977378845215
Batch 3/64 loss: -2.663331985473633
Batch 4/64 loss: -2.558945655822754
Batch 5/64 loss: -2.646209716796875
Batch 6/64 loss: -2.3814516067504883
Batch 7/64 loss: -2.5185861587524414
Batch 8/64 loss: -2.373086929321289
Batch 9/64 loss: -2.757277488708496
Batch 10/64 loss: -2.6269359588623047
Batch 11/64 loss: -2.640080451965332
Batch 12/64 loss: -2.618351936340332
Batch 13/64 loss: -2.518341064453125
Batch 14/64 loss: -2.4944515228271484
Batch 15/64 loss: -2.3519811630249023
Batch 16/64 loss: -2.515988349914551
Batch 17/64 loss: -2.32027530670166
Batch 18/64 loss: -2.5363330841064453
Batch 19/64 loss: -2.5446109771728516
Batch 20/64 loss: -2.2537670135498047
Batch 21/64 loss: -2.605658531188965
Batch 22/64 loss: -2.682788848876953
Batch 23/64 loss: -2.5616331100463867
Batch 24/64 loss: -2.621262550354004
Batch 25/64 loss: -2.466073989868164
Batch 26/64 loss: -2.437577247619629
Batch 27/64 loss: -2.693553924560547
Batch 28/64 loss: -2.796102523803711
Batch 29/64 loss: -2.584562301635742
Batch 30/64 loss: -2.501803398132324
Batch 31/64 loss: -2.435577392578125
Batch 32/64 loss: -2.2995071411132812
Batch 33/64 loss: -2.6610536575317383
Batch 34/64 loss: -2.3310842514038086
Batch 35/64 loss: -2.671144485473633
Batch 36/64 loss: -2.6469173431396484
Batch 37/64 loss: -2.411688804626465
Batch 38/64 loss: -2.332707405090332
Batch 39/64 loss: -2.3039398193359375
Batch 40/64 loss: -2.776719093322754
Batch 41/64 loss: -2.507420539855957
Batch 42/64 loss: -2.417874336242676
Batch 43/64 loss: -2.5794172286987305
Batch 44/64 loss: -2.339925765991211
Batch 45/64 loss: -2.7386579513549805
Batch 46/64 loss: -2.699599266052246
Batch 47/64 loss: -2.5083627700805664
Batch 48/64 loss: -2.4236392974853516
Batch 49/64 loss: -2.6895437240600586
Batch 50/64 loss: -2.573190689086914
Batch 51/64 loss: -2.4452428817749023
Batch 52/64 loss: -2.4853439331054688
Batch 53/64 loss: -2.4739933013916016
Batch 54/64 loss: -2.509457588195801
Batch 55/64 loss: -2.462277412414551
Batch 56/64 loss: -2.715097427368164
Batch 57/64 loss: -2.259915351867676
Batch 58/64 loss: -2.54518985748291
Batch 59/64 loss: -2.685811996459961
Batch 60/64 loss: -2.667287826538086
Batch 61/64 loss: -2.6365489959716797
Batch 62/64 loss: -2.3691253662109375
Batch 63/64 loss: -2.4473628997802734
Batch 64/64 loss: -7.140918254852295
Epoch 196  Train loss: -2.580477794946409  Val loss: -2.8371759526098717
Saving best model, epoch: 196
Epoch 197
-------------------------------
Batch 1/64 loss: -2.18123722076416
Batch 2/64 loss: -2.4069509506225586
Batch 3/64 loss: -2.707113265991211
Batch 4/64 loss: -2.7786264419555664
Batch 5/64 loss: -2.7026920318603516
Batch 6/64 loss: -2.6971054077148438
Batch 7/64 loss: -2.20770263671875
Batch 8/64 loss: -2.756779670715332
Batch 9/64 loss: -2.4942169189453125
Batch 10/64 loss: -2.3739566802978516
Batch 11/64 loss: -2.63283634185791
Batch 12/64 loss: -2.55397891998291
Batch 13/64 loss: -2.769733428955078
Batch 14/64 loss: -2.574695587158203
Batch 15/64 loss: -2.7468442916870117
Batch 16/64 loss: -2.5549163818359375
Batch 17/64 loss: -2.608057975769043
Batch 18/64 loss: -2.244800567626953
Batch 19/64 loss: -2.594599723815918
Batch 20/64 loss: -2.5827035903930664
Batch 21/64 loss: -2.6595802307128906
Batch 22/64 loss: -2.168485641479492
Batch 23/64 loss: -2.5653343200683594
Batch 24/64 loss: -2.53928279876709
Batch 25/64 loss: -2.4589948654174805
Batch 26/64 loss: -2.5573368072509766
Batch 27/64 loss: -2.2752418518066406
Batch 28/64 loss: -2.656526565551758
Batch 29/64 loss: -2.441218376159668
Batch 30/64 loss: -2.5837860107421875
Batch 31/64 loss: -2.3892345428466797
Batch 32/64 loss: -2.201192855834961
Batch 33/64 loss: -2.5142946243286133
Batch 34/64 loss: -2.4231796264648438
Batch 35/64 loss: -2.3287134170532227
Batch 36/64 loss: -2.5938796997070312
Batch 37/64 loss: -2.380056381225586
Batch 38/64 loss: -2.6014814376831055
Batch 39/64 loss: -2.6699905395507812
Batch 40/64 loss: -2.427583694458008
Batch 41/64 loss: -2.562908172607422
Batch 42/64 loss: -2.413315773010254
Batch 43/64 loss: -2.597921371459961
Batch 44/64 loss: -2.673429489135742
Batch 45/64 loss: -2.4925270080566406
Batch 46/64 loss: -2.3532772064208984
Batch 47/64 loss: -2.7343311309814453
Batch 48/64 loss: -2.553903579711914
Batch 49/64 loss: -2.669513702392578
Batch 50/64 loss: -2.6196041107177734
Batch 51/64 loss: -2.350104331970215
Batch 52/64 loss: -2.2715835571289062
Batch 53/64 loss: -2.676006317138672
Batch 54/64 loss: -2.4438037872314453
Batch 55/64 loss: -1.9588127136230469
Batch 56/64 loss: -2.715251922607422
Batch 57/64 loss: -2.5758018493652344
Batch 58/64 loss: -2.599907875061035
Batch 59/64 loss: -2.560201644897461
Batch 60/64 loss: -2.629204750061035
Batch 61/64 loss: -2.493605613708496
Batch 62/64 loss: -2.504754066467285
Batch 63/64 loss: -2.8460865020751953
Batch 64/64 loss: -7.1049299240112305
Epoch 197  Train loss: -2.576148960637111  Val loss: -2.725168667298412
Epoch 198
-------------------------------
Batch 1/64 loss: -2.6062393188476562
Batch 2/64 loss: -2.806276321411133
Batch 3/64 loss: -2.568134307861328
Batch 4/64 loss: -2.6709680557250977
Batch 5/64 loss: -2.677145004272461
Batch 6/64 loss: -2.4951696395874023
Batch 7/64 loss: -2.6764440536499023
Batch 8/64 loss: -2.63677978515625
Batch 9/64 loss: -2.4376564025878906
Batch 10/64 loss: -2.4118690490722656
Batch 11/64 loss: -2.6752777099609375
Batch 12/64 loss: -2.1699447631835938
Batch 13/64 loss: -2.2731103897094727
Batch 14/64 loss: -2.5105533599853516
Batch 15/64 loss: -2.5080089569091797
Batch 16/64 loss: -2.6481828689575195
Batch 17/64 loss: -2.5890607833862305
Batch 18/64 loss: -2.520052909851074
Batch 19/64 loss: -2.5137596130371094
Batch 20/64 loss: -2.3835344314575195
Batch 21/64 loss: -2.4576120376586914
Batch 22/64 loss: -2.567981719970703
Batch 23/64 loss: -1.9917383193969727
Batch 24/64 loss: -2.3940248489379883
Batch 25/64 loss: -2.1792831420898438
Batch 26/64 loss: -2.4241552352905273
Batch 27/64 loss: -2.175509452819824
Batch 28/64 loss: -2.625542640686035
Batch 29/64 loss: -2.6583023071289062
Batch 30/64 loss: -2.1957035064697266
Batch 31/64 loss: -2.469761848449707
Batch 32/64 loss: -2.5594873428344727
Batch 33/64 loss: -2.3884077072143555
Batch 34/64 loss: -2.569181442260742
Batch 35/64 loss: -2.436783790588379
Batch 36/64 loss: -2.373702049255371
Batch 37/64 loss: -2.571216583251953
Batch 38/64 loss: -2.474842071533203
Batch 39/64 loss: -2.5809812545776367
Batch 40/64 loss: -2.680537223815918
Batch 41/64 loss: -2.4200878143310547
Batch 42/64 loss: -2.3377418518066406
Batch 43/64 loss: -2.391486167907715
Batch 44/64 loss: -2.626239776611328
Batch 45/64 loss: -2.3509836196899414
Batch 46/64 loss: -2.644235610961914
Batch 47/64 loss: -2.344532012939453
Batch 48/64 loss: -2.441434860229492
Batch 49/64 loss: -2.0075244903564453
Batch 50/64 loss: -2.5359668731689453
Batch 51/64 loss: -2.514341354370117
Batch 52/64 loss: -2.3006200790405273
Batch 53/64 loss: -2.0142202377319336
Batch 54/64 loss: -1.6728553771972656
Batch 55/64 loss: -2.250594139099121
Batch 56/64 loss: -2.455233573913574
Batch 57/64 loss: -2.704221725463867
Batch 58/64 loss: -2.51223087310791
Batch 59/64 loss: -1.9568939208984375
Batch 60/64 loss: -2.3817052841186523
Batch 61/64 loss: -2.3846044540405273
Batch 62/64 loss: -2.5204591751098633
Batch 63/64 loss: -2.4199094772338867
Batch 64/64 loss: -6.917803764343262
Epoch 198  Train loss: -2.493010161904728  Val loss: -2.742182571044083
Epoch 199
-------------------------------
Batch 1/64 loss: -2.4696245193481445
Batch 2/64 loss: -2.5636520385742188
Batch 3/64 loss: -2.7172813415527344
Batch 4/64 loss: -2.3207340240478516
Batch 5/64 loss: -2.399843215942383
Batch 6/64 loss: -2.750791549682617
Batch 7/64 loss: -2.5540056228637695
Batch 8/64 loss: -2.5421276092529297
Batch 9/64 loss: -2.578700065612793
Batch 10/64 loss: -2.558466911315918
Batch 11/64 loss: -2.4613571166992188
Batch 12/64 loss: -2.6856985092163086
Batch 13/64 loss: -2.569364547729492
Batch 14/64 loss: -2.368051528930664
Batch 15/64 loss: -2.4927053451538086
Batch 16/64 loss: -2.525033950805664
Batch 17/64 loss: -2.1249961853027344
Batch 18/64 loss: -2.227996826171875
Batch 19/64 loss: -2.3731861114501953
Batch 20/64 loss: -2.186903953552246
Batch 21/64 loss: -2.437044143676758
Batch 22/64 loss: -2.6035871505737305
Batch 23/64 loss: -2.3411407470703125
Batch 24/64 loss: -2.1350717544555664
Batch 25/64 loss: -2.426486015319824
Batch 26/64 loss: -2.212909698486328
Batch 27/64 loss: -2.4140682220458984
Batch 28/64 loss: -2.002335548400879
Batch 29/64 loss: -2.6257095336914062
Batch 30/64 loss: -2.1146011352539062
Batch 31/64 loss: -2.701475143432617
Batch 32/64 loss: -2.699951171875
Batch 33/64 loss: -2.1079444885253906
Batch 34/64 loss: -2.3617401123046875
Batch 35/64 loss: -2.4563207626342773
Batch 36/64 loss: -2.035154342651367
Batch 37/64 loss: -2.2010068893432617
Batch 38/64 loss: -1.8836612701416016
Batch 39/64 loss: -2.2603254318237305
Batch 40/64 loss: -2.0031633377075195
Batch 41/64 loss: -2.125666618347168
Batch 42/64 loss: -2.0524492263793945
Batch 43/64 loss: -1.681793212890625
Batch 44/64 loss: -2.544187545776367
Batch 45/64 loss: -2.427722930908203
Batch 46/64 loss: -2.090695381164551
Batch 47/64 loss: -2.149043083190918
Batch 48/64 loss: -1.7224998474121094
Batch 49/64 loss: -2.275040626525879
Batch 50/64 loss: -2.272052764892578
Batch 51/64 loss: -2.06418514251709
Batch 52/64 loss: -2.2840003967285156
Batch 53/64 loss: -2.1259803771972656
Batch 54/64 loss: -2.5872879028320312
Batch 55/64 loss: -2.4295854568481445
Batch 56/64 loss: -1.9216289520263672
Batch 57/64 loss: -2.071941375732422
Batch 58/64 loss: -2.30403995513916
Batch 59/64 loss: -2.432539939880371
Batch 60/64 loss: -2.261590003967285
Batch 61/64 loss: -2.5610599517822266
Batch 62/64 loss: -2.3042221069335938
Batch 63/64 loss: -2.3323593139648438
Batch 64/64 loss: -7.063462257385254
Epoch 199  Train loss: -2.3813864577050303  Val loss: -2.642756131096804
Epoch 200
-------------------------------
Batch 1/64 loss: -2.588343620300293
Batch 2/64 loss: -2.453908920288086
Batch 3/64 loss: -2.446178436279297
Batch 4/64 loss: -2.4114608764648438
Batch 5/64 loss: -2.174727439880371
Batch 6/64 loss: -2.6364831924438477
Batch 7/64 loss: -2.665475845336914
Batch 8/64 loss: -2.5508813858032227
Batch 9/64 loss: -2.3741884231567383
Batch 10/64 loss: -2.6029233932495117
Batch 11/64 loss: -2.718423843383789
Batch 12/64 loss: -2.7034988403320312
Batch 13/64 loss: -2.469449043273926
Batch 14/64 loss: -2.4890518188476562
Batch 15/64 loss: -2.45772647857666
Batch 16/64 loss: -2.1643218994140625
Batch 17/64 loss: -2.3171768188476562
Batch 18/64 loss: -2.439345359802246
Batch 19/64 loss: -2.708746910095215
Batch 20/64 loss: -2.618856430053711
Batch 21/64 loss: -2.4241104125976562
Batch 22/64 loss: -2.6763505935668945
Batch 23/64 loss: -2.444014549255371
Batch 24/64 loss: -2.4267168045043945
Batch 25/64 loss: -1.9379596710205078
Batch 26/64 loss: -2.5954580307006836
Batch 27/64 loss: -2.6337766647338867
Batch 28/64 loss: -2.667778968811035
Batch 29/64 loss: -2.28079891204834
Batch 30/64 loss: -2.4708757400512695
Batch 31/64 loss: -2.7263193130493164
Batch 32/64 loss: -2.3422679901123047
Batch 33/64 loss: -2.4578495025634766
Batch 34/64 loss: -2.498380661010742
Batch 35/64 loss: -2.389420509338379
Batch 36/64 loss: -2.6617679595947266
Batch 37/64 loss: -2.229729652404785
Batch 38/64 loss: -2.2134923934936523
Batch 39/64 loss: -2.5103769302368164
Batch 40/64 loss: -2.512523651123047
Batch 41/64 loss: -2.6798229217529297
Batch 42/64 loss: -2.038418769836426
Batch 43/64 loss: -2.4687023162841797
Batch 44/64 loss: -1.6955718994140625
Batch 45/64 loss: -2.505537986755371
Batch 46/64 loss: -2.564207077026367
Batch 47/64 loss: -2.4654502868652344
Batch 48/64 loss: -2.352969169616699
Batch 49/64 loss: -2.2377853393554688
Batch 50/64 loss: -2.122936248779297
Batch 51/64 loss: -2.474609375
Batch 52/64 loss: -2.3180246353149414
Batch 53/64 loss: -1.9994468688964844
Batch 54/64 loss: -2.0370073318481445
Batch 55/64 loss: -2.430588722229004
Batch 56/64 loss: -2.2192764282226562
Batch 57/64 loss: -2.5919294357299805
Batch 58/64 loss: -2.2018299102783203
Batch 59/64 loss: -2.5816831588745117
Batch 60/64 loss: -2.373737335205078
Batch 61/64 loss: -2.3953609466552734
Batch 62/64 loss: -2.1074771881103516
Batch 63/64 loss: -2.4431419372558594
Batch 64/64 loss: -6.846683502197266
Epoch 200  Train loss: -2.4710849537568933  Val loss: -2.607970011602972
Epoch 201
-------------------------------
Batch 1/64 loss: -2.48184871673584
Batch 2/64 loss: -2.2646656036376953
Batch 3/64 loss: -2.6714658737182617
Batch 4/64 loss: -2.5769853591918945
Batch 5/64 loss: -2.430962562561035
Batch 6/64 loss: -2.47036075592041
Batch 7/64 loss: -2.3437986373901367
Batch 8/64 loss: -2.1016111373901367
Batch 9/64 loss: -1.9379301071166992
Batch 10/64 loss: -2.3876800537109375
Batch 11/64 loss: -2.540386199951172
Batch 12/64 loss: -2.4993324279785156
Batch 13/64 loss: -2.6744728088378906
Batch 14/64 loss: -2.341062545776367
Batch 15/64 loss: -2.448423385620117
Batch 16/64 loss: -2.5459375381469727
Batch 17/64 loss: -2.4284448623657227
Batch 18/64 loss: -2.603466033935547
Batch 19/64 loss: -2.2702808380126953
Batch 20/64 loss: -2.5095138549804688
Batch 21/64 loss: -2.465831756591797
Batch 22/64 loss: -2.339322090148926
Batch 23/64 loss: -2.374908447265625
Batch 24/64 loss: -2.73525333404541
Batch 25/64 loss: -2.6815967559814453
Batch 26/64 loss: -2.488780975341797
Batch 27/64 loss: -2.5919370651245117
Batch 28/64 loss: -2.523649215698242
Batch 29/64 loss: -2.4828615188598633
Batch 30/64 loss: -2.852982521057129
Batch 31/64 loss: -2.4748287200927734
Batch 32/64 loss: -2.5943851470947266
Batch 33/64 loss: -2.613409996032715
Batch 34/64 loss: -2.6901845932006836
Batch 35/64 loss: -2.643108367919922
Batch 36/64 loss: -2.547358512878418
Batch 37/64 loss: -2.2583999633789062
Batch 38/64 loss: -2.5743770599365234
Batch 39/64 loss: -2.5704164505004883
Batch 40/64 loss: -2.432797431945801
Batch 41/64 loss: -2.6279420852661133
Batch 42/64 loss: -2.499704360961914
Batch 43/64 loss: -2.710620880126953
Batch 44/64 loss: -2.4745445251464844
Batch 45/64 loss: -2.282114028930664
Batch 46/64 loss: -2.5411758422851562
Batch 47/64 loss: -2.557072639465332
Batch 48/64 loss: -2.443511962890625
Batch 49/64 loss: -2.599346160888672
Batch 50/64 loss: -2.5030202865600586
Batch 51/64 loss: -2.2134084701538086
Batch 52/64 loss: -2.439854621887207
Batch 53/64 loss: -2.2472076416015625
Batch 54/64 loss: -2.4724292755126953
Batch 55/64 loss: -2.366082191467285
Batch 56/64 loss: -2.408842086791992
Batch 57/64 loss: -2.594792366027832
Batch 58/64 loss: -2.4466066360473633
Batch 59/64 loss: -2.2945756912231445
Batch 60/64 loss: -2.5000839233398438
Batch 61/64 loss: -2.6577234268188477
Batch 62/64 loss: -2.282374382019043
Batch 63/64 loss: -2.749814987182617
Batch 64/64 loss: -7.092686176300049
Epoch 201  Train loss: -2.536429526759129  Val loss: -2.7707561479811
Epoch 202
-------------------------------
Batch 1/64 loss: -2.6463165283203125
Batch 2/64 loss: -2.5655927658081055
Batch 3/64 loss: -2.677433967590332
Batch 4/64 loss: -2.6331300735473633
Batch 5/64 loss: -2.540347099304199
Batch 6/64 loss: -2.627142906188965
Batch 7/64 loss: -2.6081018447875977
Batch 8/64 loss: -2.399909019470215
Batch 9/64 loss: -2.482640266418457
Batch 10/64 loss: -2.4906721115112305
Batch 11/64 loss: -2.2530832290649414
Batch 12/64 loss: -2.3609886169433594
Batch 13/64 loss: -2.430816650390625
Batch 14/64 loss: -2.5208587646484375
Batch 15/64 loss: -2.607297897338867
Batch 16/64 loss: -2.5910701751708984
Batch 17/64 loss: -2.1542444229125977
Batch 18/64 loss: -2.547976493835449
Batch 19/64 loss: -2.4246702194213867
Batch 20/64 loss: -2.2271080017089844
Batch 21/64 loss: -1.93096923828125
Batch 22/64 loss: -2.40842342376709
Batch 23/64 loss: -2.443516731262207
Batch 24/64 loss: -2.5304956436157227
Batch 25/64 loss: -2.4567909240722656
Batch 26/64 loss: -2.472015380859375
Batch 27/64 loss: -2.4212636947631836
Batch 28/64 loss: -2.1874990463256836
Batch 29/64 loss: -2.6716108322143555
Batch 30/64 loss: -2.473299980163574
Batch 31/64 loss: -2.6201725006103516
Batch 32/64 loss: -2.4534616470336914
Batch 33/64 loss: -2.6481847763061523
Batch 34/64 loss: -2.5239715576171875
Batch 35/64 loss: -2.293670654296875
Batch 36/64 loss: -2.731321334838867
Batch 37/64 loss: -2.5352563858032227
Batch 38/64 loss: -2.4392528533935547
Batch 39/64 loss: -2.4492149353027344
Batch 40/64 loss: -2.549501419067383
Batch 41/64 loss: -2.4641666412353516
Batch 42/64 loss: -2.590078353881836
Batch 43/64 loss: -2.637343406677246
Batch 44/64 loss: -2.3885488510131836
Batch 45/64 loss: -2.6375045776367188
Batch 46/64 loss: -2.060305595397949
Batch 47/64 loss: -1.8471136093139648
Batch 48/64 loss: -2.56411075592041
Batch 49/64 loss: -2.645000457763672
Batch 50/64 loss: -2.3149757385253906
Batch 51/64 loss: -2.389799118041992
Batch 52/64 loss: -2.5973072052001953
Batch 53/64 loss: -2.401308059692383
Batch 54/64 loss: -2.417635917663574
Batch 55/64 loss: -2.394015312194824
Batch 56/64 loss: -2.1312685012817383
Batch 57/64 loss: -2.4910507202148438
Batch 58/64 loss: -2.609516143798828
Batch 59/64 loss: -2.5721435546875
Batch 60/64 loss: -2.477588653564453
Batch 61/64 loss: -2.619466781616211
Batch 62/64 loss: -2.2578420639038086
Batch 63/64 loss: -2.480661392211914
Batch 64/64 loss: -7.038542747497559
Epoch 202  Train loss: -2.5144619997809916  Val loss: -2.6276644021784725
Epoch 203
-------------------------------
Batch 1/64 loss: -2.521256446838379
Batch 2/64 loss: -2.481205940246582
Batch 3/64 loss: -2.4807004928588867
Batch 4/64 loss: -1.9616355895996094
Batch 5/64 loss: -2.566542625427246
Batch 6/64 loss: -2.4835386276245117
Batch 7/64 loss: -2.048053741455078
Batch 8/64 loss: -2.1139354705810547
Batch 9/64 loss: -2.4732017517089844
Batch 10/64 loss: -2.509518623352051
Batch 11/64 loss: -2.348139762878418
Batch 12/64 loss: -2.6658849716186523
Batch 13/64 loss: -2.1708316802978516
Batch 14/64 loss: -2.4992361068725586
Batch 15/64 loss: -2.5683794021606445
Batch 16/64 loss: -2.5568246841430664
Batch 17/64 loss: -2.4801387786865234
Batch 18/64 loss: -2.4103918075561523
Batch 19/64 loss: -2.5818252563476562
Batch 20/64 loss: -2.54398250579834
Batch 21/64 loss: -2.4094228744506836
Batch 22/64 loss: -2.5346384048461914
Batch 23/64 loss: -2.516301155090332
Batch 24/64 loss: -2.4472084045410156
Batch 25/64 loss: -2.4540634155273438
Batch 26/64 loss: -2.133112907409668
Batch 27/64 loss: -2.5126724243164062
Batch 28/64 loss: -2.153141975402832
Batch 29/64 loss: -2.2749271392822266
Batch 30/64 loss: -2.2261390686035156
Batch 31/64 loss: -2.5222511291503906
Batch 32/64 loss: -1.788710594177246
Batch 33/64 loss: -2.3551158905029297
Batch 34/64 loss: -2.0773706436157227
Batch 35/64 loss: -2.5172462463378906
Batch 36/64 loss: -2.236347198486328
Batch 37/64 loss: -2.540874481201172
Batch 38/64 loss: -2.314948081970215
Batch 39/64 loss: -2.3190908432006836
Batch 40/64 loss: -2.4314498901367188
Batch 41/64 loss: -2.464205741882324
Batch 42/64 loss: -2.3423871994018555
Batch 43/64 loss: -2.3435983657836914
Batch 44/64 loss: -2.6302833557128906
Batch 45/64 loss: -2.326718330383301
Batch 46/64 loss: -2.488020896911621
Batch 47/64 loss: -2.2779769897460938
Batch 48/64 loss: -2.2273073196411133
Batch 49/64 loss: -2.172940254211426
Batch 50/64 loss: -2.4785213470458984
Batch 51/64 loss: -2.343459129333496
Batch 52/64 loss: -2.674576759338379
Batch 53/64 loss: -1.952901840209961
Batch 54/64 loss: -2.095745086669922
Batch 55/64 loss: -2.559335708618164
Batch 56/64 loss: -2.6972475051879883
Batch 57/64 loss: -2.1892919540405273
Batch 58/64 loss: -2.63958740234375
Batch 59/64 loss: -2.3433170318603516
Batch 60/64 loss: -2.4310340881347656
Batch 61/64 loss: -2.6000242233276367
Batch 62/64 loss: -2.3198070526123047
Batch 63/64 loss: -2.467721939086914
Batch 64/64 loss: -6.92378568649292
Epoch 203  Train loss: -2.439044797186758  Val loss: -2.398060513525894
Epoch 204
-------------------------------
Batch 1/64 loss: -2.3098926544189453
Batch 2/64 loss: -2.502786636352539
Batch 3/64 loss: -2.4456586837768555
Batch 4/64 loss: -2.437821388244629
Batch 5/64 loss: -2.197357177734375
Batch 6/64 loss: -2.326801300048828
Batch 7/64 loss: -2.405689239501953
Batch 8/64 loss: -2.452596664428711
Batch 9/64 loss: -2.534661293029785
Batch 10/64 loss: -2.6180267333984375
Batch 11/64 loss: -2.7570953369140625
Batch 12/64 loss: -2.5624465942382812
Batch 13/64 loss: -2.375223159790039
Batch 14/64 loss: -2.201601028442383
Batch 15/64 loss: -2.357041358947754
Batch 16/64 loss: -2.488842010498047
Batch 17/64 loss: -2.4980058670043945
Batch 18/64 loss: -2.6740379333496094
Batch 19/64 loss: -2.3282833099365234
Batch 20/64 loss: -2.2810001373291016
Batch 21/64 loss: -2.4852752685546875
Batch 22/64 loss: -2.2582502365112305
Batch 23/64 loss: -2.5717830657958984
Batch 24/64 loss: -2.74068546295166
Batch 25/64 loss: -2.579928398132324
Batch 26/64 loss: -2.663893699645996
Batch 27/64 loss: -2.6272459030151367
Batch 28/64 loss: -2.2178754806518555
Batch 29/64 loss: -2.565092086791992
Batch 30/64 loss: -2.580571174621582
Batch 31/64 loss: -2.400191307067871
Batch 32/64 loss: -2.5238189697265625
Batch 33/64 loss: -2.377943992614746
Batch 34/64 loss: -2.704648971557617
Batch 35/64 loss: -2.657404899597168
Batch 36/64 loss: -2.2224016189575195
Batch 37/64 loss: -2.6258277893066406
Batch 38/64 loss: -2.5719823837280273
Batch 39/64 loss: -2.653580665588379
Batch 40/64 loss: -2.2192859649658203
Batch 41/64 loss: -2.5364303588867188
Batch 42/64 loss: -2.752079963684082
Batch 43/64 loss: -2.7647199630737305
Batch 44/64 loss: -2.353825569152832
Batch 45/64 loss: -2.5195751190185547
Batch 46/64 loss: -2.5281829833984375
Batch 47/64 loss: -2.420330047607422
Batch 48/64 loss: -2.6906089782714844
Batch 49/64 loss: -2.48807430267334
Batch 50/64 loss: -2.544168472290039
Batch 51/64 loss: -2.2719497680664062
Batch 52/64 loss: -2.5342330932617188
Batch 53/64 loss: -2.4794206619262695
Batch 54/64 loss: -2.401338577270508
Batch 55/64 loss: -2.6839847564697266
Batch 56/64 loss: -2.5570154190063477
Batch 57/64 loss: -2.417393684387207
Batch 58/64 loss: -2.6295595169067383
Batch 59/64 loss: -2.251898765563965
Batch 60/64 loss: -2.6933250427246094
Batch 61/64 loss: -2.6175050735473633
Batch 62/64 loss: -2.3008251190185547
Batch 63/64 loss: -2.513641357421875
Batch 64/64 loss: -7.171812057495117
Epoch 204  Train loss: -2.5463764938653686  Val loss: -2.758908471700662
Epoch 205
-------------------------------
Batch 1/64 loss: -2.526158332824707
Batch 2/64 loss: -2.6172361373901367
Batch 3/64 loss: -2.187859535217285
Batch 4/64 loss: -2.1258296966552734
Batch 5/64 loss: -2.4451751708984375
Batch 6/64 loss: -2.597370147705078
Batch 7/64 loss: -2.546670913696289
Batch 8/64 loss: -2.6379175186157227
Batch 9/64 loss: -2.5349931716918945
Batch 10/64 loss: -2.283064842224121
Batch 11/64 loss: -2.4704484939575195
Batch 12/64 loss: -2.53977108001709
Batch 13/64 loss: -2.3266735076904297
Batch 14/64 loss: -2.293543815612793
Batch 15/64 loss: -2.526386260986328
Batch 16/64 loss: -2.5591115951538086
Batch 17/64 loss: -2.5927600860595703
Batch 18/64 loss: -2.883024215698242
Batch 19/64 loss: -2.6888370513916016
Batch 20/64 loss: -2.5051469802856445
Batch 21/64 loss: -2.559016227722168
Batch 22/64 loss: -2.693404197692871
Batch 23/64 loss: -2.6816463470458984
Batch 24/64 loss: -2.537388801574707
Batch 25/64 loss: -2.730020523071289
Batch 26/64 loss: -2.7085647583007812
Batch 27/64 loss: -2.8050317764282227
Batch 28/64 loss: -2.77139949798584
Batch 29/64 loss: -2.617044448852539
Batch 30/64 loss: -2.658275604248047
Batch 31/64 loss: -2.5760698318481445
Batch 32/64 loss: -2.635213851928711
Batch 33/64 loss: -2.60565185546875
Batch 34/64 loss: -2.720078468322754
Batch 35/64 loss: -2.57216739654541
Batch 36/64 loss: -2.4664621353149414
Batch 37/64 loss: -2.7185144424438477
Batch 38/64 loss: -2.5368223190307617
Batch 39/64 loss: -2.33846378326416
Batch 40/64 loss: -2.5179262161254883
Batch 41/64 loss: -2.2084836959838867
Batch 42/64 loss: -2.5953989028930664
Batch 43/64 loss: -2.6512088775634766
Batch 44/64 loss: -2.6105127334594727
Batch 45/64 loss: -2.4596433639526367
Batch 46/64 loss: -2.1619033813476562
Batch 47/64 loss: -2.736029624938965
Batch 48/64 loss: -2.786539077758789
Batch 49/64 loss: -2.497417449951172
Batch 50/64 loss: -2.6120710372924805
Batch 51/64 loss: -2.699495315551758
Batch 52/64 loss: -2.615290641784668
Batch 53/64 loss: -2.4982900619506836
Batch 54/64 loss: -2.5646848678588867
Batch 55/64 loss: -2.71832275390625
Batch 56/64 loss: -2.3611507415771484
Batch 57/64 loss: -2.3918609619140625
Batch 58/64 loss: -2.359023094177246
Batch 59/64 loss: -2.279306411743164
Batch 60/64 loss: -2.7101287841796875
Batch 61/64 loss: -2.368802070617676
Batch 62/64 loss: -2.697930335998535
Batch 63/64 loss: -2.6637697219848633
Batch 64/64 loss: -7.176608085632324
Epoch 205  Train loss: -2.603401741327024  Val loss: -2.804545477903176
Epoch 206
-------------------------------
Batch 1/64 loss: -2.3987178802490234
Batch 2/64 loss: -2.770387649536133
Batch 3/64 loss: -2.463703155517578
Batch 4/64 loss: -2.286832809448242
Batch 5/64 loss: -2.7177963256835938
Batch 6/64 loss: -2.6420955657958984
Batch 7/64 loss: -2.2875022888183594
Batch 8/64 loss: -2.5362043380737305
Batch 9/64 loss: -2.412677764892578
Batch 10/64 loss: -2.6391525268554688
Batch 11/64 loss: -2.4873170852661133
Batch 12/64 loss: -2.6983375549316406
Batch 13/64 loss: -2.5779895782470703
Batch 14/64 loss: -2.3120346069335938
Batch 15/64 loss: -2.437215805053711
Batch 16/64 loss: -2.690140724182129
Batch 17/64 loss: -2.5966787338256836
Batch 18/64 loss: -2.479297637939453
Batch 19/64 loss: -2.7583179473876953
Batch 20/64 loss: -2.57022762298584
Batch 21/64 loss: -2.2228736877441406
Batch 22/64 loss: -2.6273860931396484
Batch 23/64 loss: -2.1039600372314453
Batch 24/64 loss: -2.687143325805664
Batch 25/64 loss: -2.6936492919921875
Batch 26/64 loss: -2.3694705963134766
Batch 27/64 loss: -2.4200944900512695
Batch 28/64 loss: -2.6599178314208984
Batch 29/64 loss: -2.379251480102539
Batch 30/64 loss: -2.5352249145507812
Batch 31/64 loss: -2.655850410461426
Batch 32/64 loss: -2.6586856842041016
Batch 33/64 loss: -2.488644599914551
Batch 34/64 loss: -2.4344959259033203
Batch 35/64 loss: -2.4964170455932617
Batch 36/64 loss: -2.682560920715332
Batch 37/64 loss: -2.186115264892578
Batch 38/64 loss: -2.50958251953125
Batch 39/64 loss: -2.525631904602051
Batch 40/64 loss: -2.5011672973632812
Batch 41/64 loss: -2.66757869720459
Batch 42/64 loss: -2.525265693664551
Batch 43/64 loss: -2.5391674041748047
Batch 44/64 loss: -2.8114547729492188
Batch 45/64 loss: -2.21142578125
Batch 46/64 loss: -2.6090707778930664
Batch 47/64 loss: -2.616692543029785
Batch 48/64 loss: -2.49373722076416
Batch 49/64 loss: -2.674685478210449
Batch 50/64 loss: -2.3826169967651367
Batch 51/64 loss: -2.4552040100097656
Batch 52/64 loss: -2.6838035583496094
Batch 53/64 loss: -2.5495786666870117
Batch 54/64 loss: -2.5092849731445312
Batch 55/64 loss: -2.311960220336914
Batch 56/64 loss: -2.623851776123047
Batch 57/64 loss: -2.5134506225585938
Batch 58/64 loss: -2.5740280151367188
Batch 59/64 loss: -2.392155647277832
Batch 60/64 loss: -2.503143310546875
Batch 61/64 loss: -2.737110137939453
Batch 62/64 loss: -2.6731157302856445
Batch 63/64 loss: -2.473978042602539
Batch 64/64 loss: -6.824865341186523
Epoch 206  Train loss: -2.576498196171779  Val loss: -2.5948263738573214
Epoch 207
-------------------------------
Batch 1/64 loss: -2.350130081176758
Batch 2/64 loss: -2.740363121032715
Batch 3/64 loss: -2.608488082885742
Batch 4/64 loss: -2.4071884155273438
Batch 5/64 loss: -2.594618797302246
Batch 6/64 loss: -2.5410890579223633
Batch 7/64 loss: -2.5563268661499023
Batch 8/64 loss: -2.7064151763916016
Batch 9/64 loss: -2.598025321960449
Batch 10/64 loss: -2.4165821075439453
Batch 11/64 loss: -2.17319393157959
Batch 12/64 loss: -2.67043399810791
Batch 13/64 loss: -2.0591907501220703
Batch 14/64 loss: -2.781007766723633
Batch 15/64 loss: -2.163095474243164
Batch 16/64 loss: -2.6541919708251953
Batch 17/64 loss: -2.6716108322143555
Batch 18/64 loss: -2.6826305389404297
Batch 19/64 loss: -2.3472280502319336
Batch 20/64 loss: -2.5812768936157227
Batch 21/64 loss: -2.4262380599975586
Batch 22/64 loss: -2.6779775619506836
Batch 23/64 loss: -2.393798828125
Batch 24/64 loss: -2.7115821838378906
Batch 25/64 loss: -2.5348424911499023
Batch 26/64 loss: -2.6580944061279297
Batch 27/64 loss: -2.6280717849731445
Batch 28/64 loss: -2.7235851287841797
Batch 29/64 loss: -2.6806983947753906
Batch 30/64 loss: -2.656545639038086
Batch 31/64 loss: -2.627307891845703
Batch 32/64 loss: -2.5756282806396484
Batch 33/64 loss: -2.402341842651367
Batch 34/64 loss: -2.451418876647949
Batch 35/64 loss: -2.6670188903808594
Batch 36/64 loss: -2.5234689712524414
Batch 37/64 loss: -2.689162254333496
Batch 38/64 loss: -2.6236648559570312
Batch 39/64 loss: -2.7352352142333984
Batch 40/64 loss: -2.142086982727051
Batch 41/64 loss: -2.597090721130371
Batch 42/64 loss: -2.6372766494750977
Batch 43/64 loss: -2.6769657135009766
Batch 44/64 loss: -2.292635917663574
Batch 45/64 loss: -2.680415153503418
Batch 46/64 loss: -2.320723533630371
Batch 47/64 loss: -2.6658735275268555
Batch 48/64 loss: -2.1917858123779297
Batch 49/64 loss: -2.5987958908081055
Batch 50/64 loss: -2.4779586791992188
Batch 51/64 loss: -2.5830793380737305
Batch 52/64 loss: -2.636310577392578
Batch 53/64 loss: -2.6146888732910156
Batch 54/64 loss: -2.7215700149536133
Batch 55/64 loss: -2.567154884338379
Batch 56/64 loss: -2.4275331497192383
Batch 57/64 loss: -2.792957305908203
Batch 58/64 loss: -2.4137487411499023
Batch 59/64 loss: -2.389409065246582
Batch 60/64 loss: -2.117940902709961
Batch 61/64 loss: -2.3601865768432617
Batch 62/64 loss: -2.58396053314209
Batch 63/64 loss: -2.602872848510742
Batch 64/64 loss: -6.95351505279541
Epoch 207  Train loss: -2.5882027682136086  Val loss: -2.785059270170546
Epoch 208
-------------------------------
Batch 1/64 loss: -2.353302001953125
Batch 2/64 loss: -2.2876176834106445
Batch 3/64 loss: -2.3981800079345703
Batch 4/64 loss: -2.7042741775512695
Batch 5/64 loss: -2.549920082092285
Batch 6/64 loss: -2.4622507095336914
Batch 7/64 loss: -2.6244325637817383
Batch 8/64 loss: -2.5453100204467773
Batch 9/64 loss: -2.400728225708008
Batch 10/64 loss: -2.5867443084716797
Batch 11/64 loss: -2.4477920532226562
Batch 12/64 loss: -2.4906044006347656
Batch 13/64 loss: -2.301987648010254
Batch 14/64 loss: -2.4724159240722656
Batch 15/64 loss: -2.561221122741699
Batch 16/64 loss: -2.4603958129882812
Batch 17/64 loss: -2.298534393310547
Batch 18/64 loss: -2.6421680450439453
Batch 19/64 loss: -2.4444961547851562
Batch 20/64 loss: -2.209660530090332
Batch 21/64 loss: -2.49851131439209
Batch 22/64 loss: -2.6401376724243164
Batch 23/64 loss: -2.5821304321289062
Batch 24/64 loss: -2.5184402465820312
Batch 25/64 loss: -2.5152435302734375
Batch 26/64 loss: -2.5591421127319336
Batch 27/64 loss: -2.544754981994629
Batch 28/64 loss: -2.616694450378418
Batch 29/64 loss: -2.537446975708008
Batch 30/64 loss: -2.640932083129883
Batch 31/64 loss: -2.7454309463500977
Batch 32/64 loss: -2.4871606826782227
Batch 33/64 loss: -2.7393932342529297
Batch 34/64 loss: -2.551971435546875
Batch 35/64 loss: -2.110367774963379
Batch 36/64 loss: -2.5563879013061523
Batch 37/64 loss: -2.1717538833618164
Batch 38/64 loss: -2.648989677429199
Batch 39/64 loss: -2.414501190185547
Batch 40/64 loss: -2.254075050354004
Batch 41/64 loss: -2.4575939178466797
Batch 42/64 loss: -2.6084327697753906
Batch 43/64 loss: -2.7546157836914062
Batch 44/64 loss: -2.6664199829101562
Batch 45/64 loss: -2.67950439453125
Batch 46/64 loss: -2.2866744995117188
Batch 47/64 loss: -2.59628963470459
Batch 48/64 loss: -2.6995620727539062
Batch 49/64 loss: -2.395493507385254
Batch 50/64 loss: -2.4892234802246094
Batch 51/64 loss: -2.546018600463867
Batch 52/64 loss: -2.7781057357788086
Batch 53/64 loss: -2.516326904296875
Batch 54/64 loss: -2.5939273834228516
Batch 55/64 loss: -2.488308906555176
Batch 56/64 loss: -2.4515085220336914
Batch 57/64 loss: -2.691744804382324
Batch 58/64 loss: -2.56927490234375
Batch 59/64 loss: -2.5382137298583984
Batch 60/64 loss: -2.6958961486816406
Batch 61/64 loss: -2.632566452026367
Batch 62/64 loss: -2.518378257751465
Batch 63/64 loss: -2.6363143920898438
Batch 64/64 loss: -7.046811580657959
Epoch 208  Train loss: -2.5749177240857892  Val loss: -2.7415805043223798
Epoch 209
-------------------------------
Batch 1/64 loss: -2.697385787963867
Batch 2/64 loss: -2.4610977172851562
Batch 3/64 loss: -2.578221321105957
Batch 4/64 loss: -2.175577163696289
Batch 5/64 loss: -2.356809616088867
Batch 6/64 loss: -2.6490631103515625
Batch 7/64 loss: -2.440702438354492
Batch 8/64 loss: -2.2870216369628906
Batch 9/64 loss: -2.4000301361083984
Batch 10/64 loss: -2.3848800659179688
Batch 11/64 loss: -2.483257293701172
Batch 12/64 loss: -2.279751777648926
Batch 13/64 loss: -2.2625255584716797
Batch 14/64 loss: -2.326597213745117
Batch 15/64 loss: -2.479745864868164
Batch 16/64 loss: -2.5772790908813477
Batch 17/64 loss: -2.532465934753418
Batch 18/64 loss: -2.3040771484375
Batch 19/64 loss: -2.6174659729003906
Batch 20/64 loss: -2.0375843048095703
Batch 21/64 loss: -2.394083023071289
Batch 22/64 loss: -2.3372373580932617
Batch 23/64 loss: -2.6154775619506836
Batch 24/64 loss: -2.7036056518554688
Batch 25/64 loss: -2.649388313293457
Batch 26/64 loss: -2.7248802185058594
Batch 27/64 loss: -2.717989921569824
Batch 28/64 loss: -2.4719371795654297
Batch 29/64 loss: -2.2398691177368164
Batch 30/64 loss: -2.6038427352905273
Batch 31/64 loss: -2.657172203063965
Batch 32/64 loss: -2.3672351837158203
Batch 33/64 loss: -2.2831954956054688
Batch 34/64 loss: -2.60245418548584
Batch 35/64 loss: -2.5444421768188477
Batch 36/64 loss: -2.8117637634277344
Batch 37/64 loss: -2.552032470703125
Batch 38/64 loss: -2.553661346435547
Batch 39/64 loss: -2.734170913696289
Batch 40/64 loss: -2.6457481384277344
Batch 41/64 loss: -2.7845840454101562
Batch 42/64 loss: -2.6969614028930664
Batch 43/64 loss: -2.6415481567382812
Batch 44/64 loss: -2.6100664138793945
Batch 45/64 loss: -2.7527828216552734
Batch 46/64 loss: -2.6587162017822266
Batch 47/64 loss: -2.6010026931762695
Batch 48/64 loss: -2.0809688568115234
Batch 49/64 loss: -2.4819202423095703
Batch 50/64 loss: -2.6108388900756836
Batch 51/64 loss: -2.434065818786621
Batch 52/64 loss: -2.8117361068725586
Batch 53/64 loss: -2.6585474014282227
Batch 54/64 loss: -2.6387691497802734
Batch 55/64 loss: -2.668722152709961
Batch 56/64 loss: -2.7077131271362305
Batch 57/64 loss: -2.627255439758301
Batch 58/64 loss: -2.6095027923583984
Batch 59/64 loss: -2.5720109939575195
Batch 60/64 loss: -2.505825996398926
Batch 61/64 loss: -2.6021642684936523
Batch 62/64 loss: -2.7953977584838867
Batch 63/64 loss: -2.736082077026367
Batch 64/64 loss: -6.962289810180664
Epoch 209  Train loss: -2.589029431810566  Val loss: -2.8511724439273585
Saving best model, epoch: 209
Epoch 210
-------------------------------
Batch 1/64 loss: -2.570664405822754
Batch 2/64 loss: -2.5112838745117188
Batch 3/64 loss: -2.817843437194824
Batch 4/64 loss: -2.379500389099121
Batch 5/64 loss: -2.2409133911132812
Batch 6/64 loss: -2.2803878784179688
Batch 7/64 loss: -2.6910362243652344
Batch 8/64 loss: -2.7636756896972656
Batch 9/64 loss: -2.70941162109375
Batch 10/64 loss: -2.5309457778930664
Batch 11/64 loss: -2.4055662155151367
Batch 12/64 loss: -2.714179039001465
Batch 13/64 loss: -2.599271774291992
Batch 14/64 loss: -2.728501319885254
Batch 15/64 loss: -2.6728830337524414
Batch 16/64 loss: -2.7330141067504883
Batch 17/64 loss: -2.7505598068237305
Batch 18/64 loss: -2.641206741333008
Batch 19/64 loss: -2.670766830444336
Batch 20/64 loss: -2.216184616088867
Batch 21/64 loss: -2.5165414810180664
Batch 22/64 loss: -2.607667922973633
Batch 23/64 loss: -2.549654006958008
Batch 24/64 loss: -2.5572376251220703
Batch 25/64 loss: -2.7251062393188477
Batch 26/64 loss: -2.760411262512207
Batch 27/64 loss: -2.44240665435791
Batch 28/64 loss: -2.2051868438720703
Batch 29/64 loss: -2.710714340209961
Batch 30/64 loss: -2.5847816467285156
Batch 31/64 loss: -2.497103691101074
Batch 32/64 loss: -2.9042701721191406
Batch 33/64 loss: -2.743490219116211
Batch 34/64 loss: -2.4369287490844727
Batch 35/64 loss: -2.4606733322143555
Batch 36/64 loss: -2.796023368835449
Batch 37/64 loss: -2.4707260131835938
Batch 38/64 loss: -2.56766414642334
Batch 39/64 loss: -2.713520050048828
Batch 40/64 loss: -2.675325393676758
Batch 41/64 loss: -2.578113555908203
Batch 42/64 loss: -2.2993412017822266
Batch 43/64 loss: -2.3883724212646484
Batch 44/64 loss: -2.589883804321289
Batch 45/64 loss: -1.6664514541625977
Batch 46/64 loss: -2.4125537872314453
Batch 47/64 loss: -2.5928611755371094
Batch 48/64 loss: -2.5214996337890625
Batch 49/64 loss: -2.3697547912597656
Batch 50/64 loss: -2.3178634643554688
Batch 51/64 loss: -2.4397363662719727
Batch 52/64 loss: -2.0243072509765625
Batch 53/64 loss: -2.052393913269043
Batch 54/64 loss: -2.573794364929199
Batch 55/64 loss: -2.17800235748291
Batch 56/64 loss: -2.5506200790405273
Batch 57/64 loss: -2.2467947006225586
Batch 58/64 loss: -2.46285343170166
Batch 59/64 loss: -1.7101707458496094
Batch 60/64 loss: -2.30230712890625
Batch 61/64 loss: -2.0789031982421875
Batch 62/64 loss: -2.194284439086914
Batch 63/64 loss: -2.3956375122070312
Batch 64/64 loss: -7.003590106964111
Epoch 210  Train loss: -2.5372929049473183  Val loss: -2.3750221540837764
Epoch 211
-------------------------------
Batch 1/64 loss: -2.5719528198242188
Batch 2/64 loss: -2.3222179412841797
Batch 3/64 loss: -2.4391326904296875
Batch 4/64 loss: -2.212216377258301
Batch 5/64 loss: -2.287233352661133
Batch 6/64 loss: -2.607119560241699
Batch 7/64 loss: -2.4925460815429688
Batch 8/64 loss: -2.5442495346069336
Batch 9/64 loss: -2.457596778869629
Batch 10/64 loss: -2.5090885162353516
Batch 11/64 loss: -1.8736886978149414
Batch 12/64 loss: -2.1303787231445312
Batch 13/64 loss: -1.7808761596679688
Batch 14/64 loss: -2.0509109497070312
Batch 15/64 loss: -2.3611392974853516
Batch 16/64 loss: -2.4227542877197266
Batch 17/64 loss: -2.468568801879883
Batch 18/64 loss: -2.422682762145996
Batch 19/64 loss: -2.2438669204711914
Batch 20/64 loss: -2.4036026000976562
Batch 21/64 loss: -2.2474489212036133
Batch 22/64 loss: -2.157072067260742
Batch 23/64 loss: -1.3016796112060547
Batch 24/64 loss: -1.6035680770874023
Batch 25/64 loss: -2.274806022644043
Batch 26/64 loss: -1.699070930480957
Batch 27/64 loss: -2.4915857315063477
Batch 28/64 loss: -0.6557588577270508
Batch 29/64 loss: -2.175185203552246
Batch 30/64 loss: -2.4242162704467773
Batch 31/64 loss: -1.4099454879760742
Batch 32/64 loss: -2.3603954315185547
Batch 33/64 loss: -2.087531089782715
Batch 34/64 loss: -2.1319007873535156
Batch 35/64 loss: -1.651153564453125
Batch 36/64 loss: -1.3959980010986328
Batch 37/64 loss: -1.350703239440918
Batch 38/64 loss: -2.366856575012207
Batch 39/64 loss: -2.1746397018432617
Batch 40/64 loss: -2.1410465240478516
Batch 41/64 loss: -2.5709009170532227
Batch 42/64 loss: -2.0799026489257812
Batch 43/64 loss: -1.7300786972045898
Batch 44/64 loss: -2.110818862915039
Batch 45/64 loss: -2.3386707305908203
Batch 46/64 loss: -2.432924270629883
Batch 47/64 loss: -2.1571426391601562
Batch 48/64 loss: -1.0035600662231445
Batch 49/64 loss: -1.7112674713134766
Batch 50/64 loss: -0.9798154830932617
Batch 51/64 loss: -2.2010135650634766
Batch 52/64 loss: -2.0379772186279297
Batch 53/64 loss: -1.7321605682373047
Batch 54/64 loss: -2.0464868545532227
Batch 55/64 loss: -1.2012147903442383
Batch 56/64 loss: -1.2377052307128906
Batch 57/64 loss: -2.1561527252197266
Batch 58/64 loss: -0.46283435821533203
Batch 59/64 loss: -2.103672981262207
Batch 60/64 loss: -1.005929946899414
Batch 61/64 loss: -1.2974557876586914
Batch 62/64 loss: -2.0599470138549805
Batch 63/64 loss: -0.6864023208618164
Batch 64/64 loss: -6.387020587921143
Epoch 211  Train loss: -2.0209676162869323  Val loss: -0.4413464470827293
Epoch 212
-------------------------------
Batch 1/64 loss: -1.4904375076293945
Batch 2/64 loss: -1.2270841598510742
Batch 3/64 loss: -0.1080331802368164
Batch 4/64 loss: -2.133416175842285
Batch 5/64 loss: -1.9348115921020508
Batch 6/64 loss: -1.4997224807739258
Batch 7/64 loss: -2.085416793823242
Batch 8/64 loss: -1.204970359802246
Batch 9/64 loss: -1.8484315872192383
Batch 10/64 loss: -1.5352373123168945
Batch 11/64 loss: -1.766805648803711
Batch 12/64 loss: -1.7363643646240234
Batch 13/64 loss: -1.1347131729125977
Batch 14/64 loss: -2.055583953857422
Batch 15/64 loss: -2.288907051086426
Batch 16/64 loss: -1.6641206741333008
Batch 17/64 loss: -1.940476417541504
Batch 18/64 loss: -1.7970504760742188
Batch 19/64 loss: -2.1411380767822266
Batch 20/64 loss: -1.2890100479125977
Batch 21/64 loss: -2.1443042755126953
Batch 22/64 loss: -1.7893123626708984
Batch 23/64 loss: -2.233213424682617
Batch 24/64 loss: -1.915435791015625
Batch 25/64 loss: -1.7519655227661133
Batch 26/64 loss: -1.7733678817749023
Batch 27/64 loss: -1.8282966613769531
Batch 28/64 loss: -1.9541969299316406
Batch 29/64 loss: -1.7363166809082031
Batch 30/64 loss: -1.7691612243652344
Batch 31/64 loss: -2.2022886276245117
Batch 32/64 loss: -2.056586265563965
Batch 33/64 loss: -1.7633438110351562
Batch 34/64 loss: -2.1341867446899414
Batch 35/64 loss: -1.5605812072753906
Batch 36/64 loss: -1.8408584594726562
Batch 37/64 loss: -2.1254100799560547
Batch 38/64 loss: -2.1402721405029297
Batch 39/64 loss: -2.5176477432250977
Batch 40/64 loss: -2.270970344543457
Batch 41/64 loss: -2.1405715942382812
Batch 42/64 loss: -2.1696062088012695
Batch 43/64 loss: -1.9087400436401367
Batch 44/64 loss: -2.44228458404541
Batch 45/64 loss: -2.465829849243164
Batch 46/64 loss: -1.8921928405761719
Batch 47/64 loss: -2.5485668182373047
Batch 48/64 loss: -2.221771240234375
Batch 49/64 loss: -1.9446592330932617
Batch 50/64 loss: -2.257549285888672
Batch 51/64 loss: -1.7817506790161133
Batch 52/64 loss: -1.426041603088379
Batch 53/64 loss: -2.0538740158081055
Batch 54/64 loss: -2.019839286804199
Batch 55/64 loss: -1.9891748428344727
Batch 56/64 loss: -2.0149412155151367
Batch 57/64 loss: -2.3777856826782227
Batch 58/64 loss: -1.843003273010254
Batch 59/64 loss: -2.4201536178588867
Batch 60/64 loss: -1.9787015914916992
Batch 61/64 loss: -2.12302303314209
Batch 62/64 loss: -1.9865226745605469
Batch 63/64 loss: -1.9394493103027344
Batch 64/64 loss: -6.747307300567627
Epoch 212  Train loss: -1.9669954543020212  Val loss: -2.2623121123952963
Epoch 213
-------------------------------
Batch 1/64 loss: -1.9358482360839844
Batch 2/64 loss: -1.4933271408081055
Batch 3/64 loss: -2.3351850509643555
Batch 4/64 loss: -1.6097612380981445
Batch 5/64 loss: -2.055657386779785
Batch 6/64 loss: -2.0945825576782227
Batch 7/64 loss: -1.9706926345825195
Batch 8/64 loss: -2.195101737976074
Batch 9/64 loss: -2.1722936630249023
Batch 10/64 loss: -2.456737518310547
Batch 11/64 loss: -2.0524978637695312
Batch 12/64 loss: -1.411184310913086
Batch 13/64 loss: -2.314438819885254
Batch 14/64 loss: -2.3989944458007812
Batch 15/64 loss: -2.259918212890625
Batch 16/64 loss: -2.0501718521118164
Batch 17/64 loss: -2.0466299057006836
Batch 18/64 loss: -1.9858598709106445
Batch 19/64 loss: -2.461613655090332
Batch 20/64 loss: -2.3512697219848633
Batch 21/64 loss: -2.131166458129883
Batch 22/64 loss: -2.1227893829345703
Batch 23/64 loss: -2.497269630432129
Batch 24/64 loss: -1.6824283599853516
Batch 25/64 loss: -1.8171014785766602
Batch 26/64 loss: -2.322671890258789
Batch 27/64 loss: -2.059366226196289
Batch 28/64 loss: -2.3542327880859375
Batch 29/64 loss: -1.674631118774414
Batch 30/64 loss: -1.8717689514160156
Batch 31/64 loss: -2.4602699279785156
Batch 32/64 loss: -2.3591346740722656
Batch 33/64 loss: -1.586054801940918
Batch 34/64 loss: -2.568208694458008
Batch 35/64 loss: -2.365274429321289
Batch 36/64 loss: -2.2623062133789062
Batch 37/64 loss: -2.4461755752563477
Batch 38/64 loss: -2.3889245986938477
Batch 39/64 loss: -2.197983741760254
Batch 40/64 loss: -2.269904136657715
Batch 41/64 loss: -2.481785774230957
Batch 42/64 loss: -1.8865671157836914
Batch 43/64 loss: -2.251431465148926
Batch 44/64 loss: -2.2938108444213867
Batch 45/64 loss: -2.201235771179199
Batch 46/64 loss: -2.2087764739990234
Batch 47/64 loss: -1.878239631652832
Batch 48/64 loss: -2.2450056076049805
Batch 49/64 loss: -2.1459274291992188
Batch 50/64 loss: -1.8471956253051758
Batch 51/64 loss: -1.8815011978149414
Batch 52/64 loss: -2.1411914825439453
Batch 53/64 loss: -2.2342891693115234
Batch 54/64 loss: -2.378535270690918
Batch 55/64 loss: -2.0405454635620117
Batch 56/64 loss: -2.3746509552001953
Batch 57/64 loss: -2.302475929260254
Batch 58/64 loss: -2.098398208618164
Batch 59/64 loss: -2.5091609954833984
Batch 60/64 loss: -2.4021825790405273
Batch 61/64 loss: -2.2961931228637695
Batch 62/64 loss: -2.2863969802856445
Batch 63/64 loss: -2.6083202362060547
Batch 64/64 loss: -6.782351493835449
Epoch 213  Train loss: -2.2144315270816577  Val loss: -2.5159512024974497
Epoch 214
-------------------------------
Batch 1/64 loss: -2.5876359939575195
Batch 2/64 loss: -2.3556575775146484
Batch 3/64 loss: -2.1767730712890625
Batch 4/64 loss: -2.2453842163085938
Batch 5/64 loss: -2.380875587463379
Batch 6/64 loss: -2.3647098541259766
Batch 7/64 loss: -2.2202301025390625
Batch 8/64 loss: -2.5149126052856445
Batch 9/64 loss: -2.5459957122802734
Batch 10/64 loss: -2.1974611282348633
Batch 11/64 loss: -2.4871578216552734
Batch 12/64 loss: -2.506551742553711
Batch 13/64 loss: -2.503122329711914
Batch 14/64 loss: -2.2891082763671875
Batch 15/64 loss: -2.3984270095825195
Batch 16/64 loss: -2.500843048095703
Batch 17/64 loss: -2.3792428970336914
Batch 18/64 loss: -2.140920639038086
Batch 19/64 loss: -2.5640363693237305
Batch 20/64 loss: -2.0795488357543945
Batch 21/64 loss: -2.3067121505737305
Batch 22/64 loss: -2.439485549926758
Batch 23/64 loss: -2.6430912017822266
Batch 24/64 loss: -2.343817710876465
Batch 25/64 loss: -2.181443214416504
Batch 26/64 loss: -2.6290273666381836
Batch 27/64 loss: -2.401860237121582
Batch 28/64 loss: -2.3034887313842773
Batch 29/64 loss: -2.4149255752563477
Batch 30/64 loss: -2.531672477722168
Batch 31/64 loss: -2.5865564346313477
Batch 32/64 loss: -2.3298816680908203
Batch 33/64 loss: -2.2819366455078125
Batch 34/64 loss: -2.222726821899414
Batch 35/64 loss: -2.2866249084472656
Batch 36/64 loss: -2.34830379486084
Batch 37/64 loss: -2.4974489212036133
Batch 38/64 loss: -2.5788145065307617
Batch 39/64 loss: -2.3811302185058594
Batch 40/64 loss: -2.638819694519043
Batch 41/64 loss: -2.4881086349487305
Batch 42/64 loss: -2.4117345809936523
Batch 43/64 loss: -2.3675765991210938
Batch 44/64 loss: -2.0548925399780273
Batch 45/64 loss: -2.5363197326660156
Batch 46/64 loss: -2.539278030395508
Batch 47/64 loss: -2.570993423461914
Batch 48/64 loss: -2.324601173400879
Batch 49/64 loss: -2.3692407608032227
Batch 50/64 loss: -2.348219871520996
Batch 51/64 loss: -2.128279685974121
Batch 52/64 loss: -2.542409896850586
Batch 53/64 loss: -2.4334936141967773
Batch 54/64 loss: -2.5844202041625977
Batch 55/64 loss: -2.2370967864990234
Batch 56/64 loss: -2.7651872634887695
Batch 57/64 loss: -2.467034339904785
Batch 58/64 loss: -2.32875919342041
Batch 59/64 loss: -2.534809112548828
Batch 60/64 loss: -2.6617774963378906
Batch 61/64 loss: -1.8394088745117188
Batch 62/64 loss: -2.681767463684082
Batch 63/64 loss: -2.784914016723633
Batch 64/64 loss: -7.25369930267334
Epoch 214  Train loss: -2.4663052614997416  Val loss: -2.733788559117268
Epoch 215
-------------------------------
Batch 1/64 loss: -2.539799690246582
Batch 2/64 loss: -2.6766176223754883
Batch 3/64 loss: -2.423727035522461
Batch 4/64 loss: -2.7764892578125
Batch 5/64 loss: -2.439995765686035
Batch 6/64 loss: -2.707980155944824
Batch 7/64 loss: -2.5603771209716797
Batch 8/64 loss: -2.6109848022460938
Batch 9/64 loss: -2.5239810943603516
Batch 10/64 loss: -2.577495574951172
Batch 11/64 loss: -2.7209596633911133
Batch 12/64 loss: -2.6938095092773438
Batch 13/64 loss: -2.119175910949707
Batch 14/64 loss: -2.6458606719970703
Batch 15/64 loss: -2.440985679626465
Batch 16/64 loss: -2.3282642364501953
Batch 17/64 loss: -2.277383804321289
Batch 18/64 loss: -2.534940719604492
Batch 19/64 loss: -2.619837760925293
Batch 20/64 loss: -2.5055017471313477
Batch 21/64 loss: -2.660151481628418
Batch 22/64 loss: -2.6606149673461914
Batch 23/64 loss: -2.627239227294922
Batch 24/64 loss: -2.52530574798584
Batch 25/64 loss: -2.461125373840332
Batch 26/64 loss: -2.316150665283203
Batch 27/64 loss: -2.801738739013672
Batch 28/64 loss: -2.29437255859375
Batch 29/64 loss: -2.4355688095092773
Batch 30/64 loss: -2.587466239929199
Batch 31/64 loss: -2.5832738876342773
Batch 32/64 loss: -2.5515527725219727
Batch 33/64 loss: -2.631148338317871
Batch 34/64 loss: -2.519969940185547
Batch 35/64 loss: -2.4868268966674805
Batch 36/64 loss: -2.395824432373047
Batch 37/64 loss: -2.566488265991211
Batch 38/64 loss: -2.5049352645874023
Batch 39/64 loss: -2.4562768936157227
Batch 40/64 loss: -2.036083221435547
Batch 41/64 loss: -2.5231332778930664
Batch 42/64 loss: -2.4959716796875
Batch 43/64 loss: -2.801654815673828
Batch 44/64 loss: -2.3448896408081055
Batch 45/64 loss: -2.4362106323242188
Batch 46/64 loss: -2.674074172973633
Batch 47/64 loss: -2.8337574005126953
Batch 48/64 loss: -2.170790672302246
Batch 49/64 loss: -2.25839900970459
Batch 50/64 loss: -2.6220083236694336
Batch 51/64 loss: -2.44384765625
Batch 52/64 loss: -2.4725160598754883
Batch 53/64 loss: -2.7723817825317383
Batch 54/64 loss: -2.768400192260742
Batch 55/64 loss: -2.19854736328125
Batch 56/64 loss: -2.2710580825805664
Batch 57/64 loss: -2.455842971801758
Batch 58/64 loss: -2.523191452026367
Batch 59/64 loss: -2.62673282623291
Batch 60/64 loss: -2.6150903701782227
Batch 61/64 loss: -2.604715347290039
Batch 62/64 loss: -2.197293281555176
Batch 63/64 loss: -2.6179208755493164
Batch 64/64 loss: -7.092758655548096
Epoch 215  Train loss: -2.5705769164889465  Val loss: -2.825471622427714
Epoch 216
-------------------------------
Batch 1/64 loss: -2.586176872253418
Batch 2/64 loss: -2.5962448120117188
Batch 3/64 loss: -2.4980058670043945
Batch 4/64 loss: -2.279783248901367
Batch 5/64 loss: -2.602550506591797
Batch 6/64 loss: -2.543916702270508
Batch 7/64 loss: -2.4470529556274414
Batch 8/64 loss: -2.591135025024414
Batch 9/64 loss: -2.812440872192383
Batch 10/64 loss: -2.178956985473633
Batch 11/64 loss: -1.9896049499511719
Batch 12/64 loss: -2.44722843170166
Batch 13/64 loss: -2.6373729705810547
Batch 14/64 loss: -2.6230945587158203
Batch 15/64 loss: -2.4645910263061523
Batch 16/64 loss: -2.732940673828125
Batch 17/64 loss: -2.614185333251953
Batch 18/64 loss: -2.619297981262207
Batch 19/64 loss: -2.639559745788574
Batch 20/64 loss: -2.6702232360839844
Batch 21/64 loss: -2.2357864379882812
Batch 22/64 loss: -2.776883125305176
Batch 23/64 loss: -2.5342016220092773
Batch 24/64 loss: -2.663235664367676
Batch 25/64 loss: -2.7833662033081055
Batch 26/64 loss: -2.4328737258911133
Batch 27/64 loss: -2.5596532821655273
Batch 28/64 loss: -2.4797592163085938
Batch 29/64 loss: -2.395604133605957
Batch 30/64 loss: -2.6489152908325195
Batch 31/64 loss: -2.7079896926879883
Batch 32/64 loss: -2.748721122741699
Batch 33/64 loss: -2.3987932205200195
Batch 34/64 loss: -2.480807304382324
Batch 35/64 loss: -2.696317672729492
Batch 36/64 loss: -2.037799835205078
Batch 37/64 loss: -2.328401565551758
Batch 38/64 loss: -2.7659006118774414
Batch 39/64 loss: -2.6673812866210938
Batch 40/64 loss: -2.270313262939453
Batch 41/64 loss: -2.7584543228149414
Batch 42/64 loss: -2.7026748657226562
Batch 43/64 loss: -2.769961357116699
Batch 44/64 loss: -1.8728742599487305
Batch 45/64 loss: -2.534111976623535
Batch 46/64 loss: -2.4274511337280273
Batch 47/64 loss: -2.43111515045166
Batch 48/64 loss: -2.7831058502197266
Batch 49/64 loss: -2.731546401977539
Batch 50/64 loss: -2.593172073364258
Batch 51/64 loss: -2.593374252319336
Batch 52/64 loss: -2.534398078918457
Batch 53/64 loss: -2.8081207275390625
Batch 54/64 loss: -2.2551937103271484
Batch 55/64 loss: -2.565797805786133
Batch 56/64 loss: -2.7361650466918945
Batch 57/64 loss: -2.5761280059814453
Batch 58/64 loss: -2.514235496520996
Batch 59/64 loss: -2.006959915161133
Batch 60/64 loss: -2.419827461242676
Batch 61/64 loss: -2.582082748413086
Batch 62/64 loss: -2.508213996887207
Batch 63/64 loss: -2.7019710540771484
Batch 64/64 loss: -7.239758014678955
Epoch 216  Train loss: -2.5886089605443616  Val loss: -2.8319081965181017
Epoch 217
-------------------------------
Batch 1/64 loss: -2.3408374786376953
Batch 2/64 loss: -2.7982654571533203
Batch 3/64 loss: -2.382571220397949
Batch 4/64 loss: -2.6722774505615234
Batch 5/64 loss: -2.5171327590942383
Batch 6/64 loss: -2.50722599029541
Batch 7/64 loss: -2.6330347061157227
Batch 8/64 loss: -2.828968048095703
Batch 9/64 loss: -2.8871631622314453
Batch 10/64 loss: -2.7835254669189453
Batch 11/64 loss: -2.595442771911621
Batch 12/64 loss: -2.6778154373168945
Batch 13/64 loss: -2.5547075271606445
Batch 14/64 loss: -2.423861503601074
Batch 15/64 loss: -2.636721611022949
Batch 16/64 loss: -2.4384326934814453
Batch 17/64 loss: -2.448526382446289
Batch 18/64 loss: -2.094540596008301
Batch 19/64 loss: -2.5859031677246094
Batch 20/64 loss: -2.714345932006836
Batch 21/64 loss: -2.458010673522949
Batch 22/64 loss: -2.5476531982421875
Batch 23/64 loss: -2.558502197265625
Batch 24/64 loss: -2.4674205780029297
Batch 25/64 loss: -2.638443946838379
Batch 26/64 loss: -2.5616140365600586
Batch 27/64 loss: -2.566373825073242
Batch 28/64 loss: -2.398970603942871
Batch 29/64 loss: -2.593132972717285
Batch 30/64 loss: -2.6909637451171875
Batch 31/64 loss: -2.6704063415527344
Batch 32/64 loss: -2.543459892272949
Batch 33/64 loss: -2.7055273056030273
Batch 34/64 loss: -2.8005638122558594
Batch 35/64 loss: -2.620030403137207
Batch 36/64 loss: -2.3351211547851562
Batch 37/64 loss: -2.386702537536621
Batch 38/64 loss: -2.6961116790771484
Batch 39/64 loss: -2.681778907775879
Batch 40/64 loss: -2.081766128540039
Batch 41/64 loss: -2.5040435791015625
Batch 42/64 loss: -2.6527023315429688
Batch 43/64 loss: -2.5531044006347656
Batch 44/64 loss: -2.513763427734375
Batch 45/64 loss: -2.622504234313965
Batch 46/64 loss: -2.671478271484375
Batch 47/64 loss: -2.4150209426879883
Batch 48/64 loss: -2.2650680541992188
Batch 49/64 loss: -2.687246322631836
Batch 50/64 loss: -2.7311363220214844
Batch 51/64 loss: -2.665477752685547
Batch 52/64 loss: -2.568558692932129
Batch 53/64 loss: -2.3867807388305664
Batch 54/64 loss: -2.394402503967285
Batch 55/64 loss: -2.637457847595215
Batch 56/64 loss: -2.2794599533081055
Batch 57/64 loss: -2.555196762084961
Batch 58/64 loss: -2.074502944946289
Batch 59/64 loss: -2.6133012771606445
Batch 60/64 loss: -2.4437732696533203
Batch 61/64 loss: -2.5580263137817383
Batch 62/64 loss: -2.169422149658203
Batch 63/64 loss: -2.228968620300293
Batch 64/64 loss: -6.775934219360352
Epoch 217  Train loss: -2.5850541283102597  Val loss: -2.745856098293029
Epoch 218
-------------------------------
Batch 1/64 loss: -2.0400028228759766
Batch 2/64 loss: -2.6899290084838867
Batch 3/64 loss: -2.0937108993530273
Batch 4/64 loss: -2.456249237060547
Batch 5/64 loss: -2.6428956985473633
Batch 6/64 loss: -2.5328750610351562
Batch 7/64 loss: -2.5761232376098633
Batch 8/64 loss: -2.5026540756225586
Batch 9/64 loss: -2.3212318420410156
Batch 10/64 loss: -2.5399837493896484
Batch 11/64 loss: -2.6771535873413086
Batch 12/64 loss: -2.469331741333008
Batch 13/64 loss: -2.6229496002197266
Batch 14/64 loss: -2.4418411254882812
Batch 15/64 loss: -2.7140512466430664
Batch 16/64 loss: -2.4893579483032227
Batch 17/64 loss: -2.5695667266845703
Batch 18/64 loss: -2.6320981979370117
Batch 19/64 loss: -2.3695859909057617
Batch 20/64 loss: -2.5549564361572266
Batch 21/64 loss: -2.290207862854004
Batch 22/64 loss: -2.8440170288085938
Batch 23/64 loss: -2.220552444458008
Batch 24/64 loss: -2.8311634063720703
Batch 25/64 loss: -2.674619674682617
Batch 26/64 loss: -2.4959287643432617
Batch 27/64 loss: -2.6444549560546875
Batch 28/64 loss: -2.465250015258789
Batch 29/64 loss: -2.539118766784668
Batch 30/64 loss: -2.5037412643432617
Batch 31/64 loss: -2.7651824951171875
Batch 32/64 loss: -2.6626462936401367
Batch 33/64 loss: -2.175567626953125
Batch 34/64 loss: -2.3831586837768555
Batch 35/64 loss: -2.429011344909668
Batch 36/64 loss: -2.5239782333374023
Batch 37/64 loss: -2.486924171447754
Batch 38/64 loss: -2.694520950317383
Batch 39/64 loss: -2.071756362915039
Batch 40/64 loss: -2.5334300994873047
Batch 41/64 loss: -2.584956169128418
Batch 42/64 loss: -2.610611915588379
Batch 43/64 loss: -2.168450355529785
Batch 44/64 loss: -2.1698198318481445
Batch 45/64 loss: -2.6833457946777344
Batch 46/64 loss: -2.4164419174194336
Batch 47/64 loss: -2.2989892959594727
Batch 48/64 loss: -2.675548553466797
Batch 49/64 loss: -2.4880619049072266
Batch 50/64 loss: -2.408611297607422
Batch 51/64 loss: -2.6770334243774414
Batch 52/64 loss: -2.75528621673584
Batch 53/64 loss: -2.6564102172851562
Batch 54/64 loss: -2.6847047805786133
Batch 55/64 loss: -2.6613855361938477
Batch 56/64 loss: -2.6535844802856445
Batch 57/64 loss: -2.4539756774902344
Batch 58/64 loss: -2.6672401428222656
Batch 59/64 loss: -2.700490951538086
Batch 60/64 loss: -2.415607452392578
Batch 61/64 loss: -2.451951026916504
Batch 62/64 loss: -2.4785079956054688
Batch 63/64 loss: -2.3122129440307617
Batch 64/64 loss: -7.165122985839844
Epoch 218  Train loss: -2.566570177265242  Val loss: -2.8797603489197408
Saving best model, epoch: 218
Epoch 219
-------------------------------
Batch 1/64 loss: -2.602869987487793
Batch 2/64 loss: -2.4038209915161133
Batch 3/64 loss: -2.2494869232177734
Batch 4/64 loss: -2.4052248001098633
Batch 5/64 loss: -2.224301338195801
Batch 6/64 loss: -2.754807472229004
Batch 7/64 loss: -2.4077844619750977
Batch 8/64 loss: -2.714113235473633
Batch 9/64 loss: -2.666417121887207
Batch 10/64 loss: -2.587512969970703
Batch 11/64 loss: -2.762892723083496
Batch 12/64 loss: -2.6017236709594727
Batch 13/64 loss: -2.6350717544555664
Batch 14/64 loss: -2.6740875244140625
Batch 15/64 loss: -2.775120735168457
Batch 16/64 loss: -2.369185447692871
Batch 17/64 loss: -2.2132740020751953
Batch 18/64 loss: -2.7495222091674805
Batch 19/64 loss: -2.8503379821777344
Batch 20/64 loss: -2.245022773742676
Batch 21/64 loss: -2.6268234252929688
Batch 22/64 loss: -2.665522575378418
Batch 23/64 loss: -2.0857839584350586
Batch 24/64 loss: -2.5315074920654297
Batch 25/64 loss: -2.539217948913574
Batch 26/64 loss: -2.78579044342041
Batch 27/64 loss: -2.6295270919799805
Batch 28/64 loss: -2.49782657623291
Batch 29/64 loss: -2.091146469116211
Batch 30/64 loss: -2.4880104064941406
Batch 31/64 loss: -2.5261592864990234
Batch 32/64 loss: -2.2694387435913086
Batch 33/64 loss: -2.8284873962402344
Batch 34/64 loss: -2.721284866333008
Batch 35/64 loss: -2.1868629455566406
Batch 36/64 loss: -2.7244224548339844
Batch 37/64 loss: -2.583860397338867
Batch 38/64 loss: -2.6171340942382812
Batch 39/64 loss: -2.539030075073242
Batch 40/64 loss: -2.4915342330932617
Batch 41/64 loss: -2.1337194442749023
Batch 42/64 loss: -2.593851089477539
Batch 43/64 loss: -2.681767463684082
Batch 44/64 loss: -2.2008094787597656
Batch 45/64 loss: -2.2729368209838867
Batch 46/64 loss: -2.5639734268188477
Batch 47/64 loss: -2.6974000930786133
Batch 48/64 loss: -2.705655097961426
Batch 49/64 loss: -2.7708816528320312
Batch 50/64 loss: -2.7229995727539062
Batch 51/64 loss: -2.6620712280273438
Batch 52/64 loss: -2.7948408126831055
Batch 53/64 loss: -2.617703437805176
Batch 54/64 loss: -2.682623863220215
Batch 55/64 loss: -2.818452835083008
Batch 56/64 loss: -2.5072250366210938
Batch 57/64 loss: -2.546137809753418
Batch 58/64 loss: -2.554422378540039
Batch 59/64 loss: -2.5675973892211914
Batch 60/64 loss: -2.481625556945801
Batch 61/64 loss: -2.500929832458496
Batch 62/64 loss: -2.809149742126465
Batch 63/64 loss: -2.7119979858398438
Batch 64/64 loss: -7.1152567863464355
Epoch 219  Train loss: -2.607955508138619  Val loss: -2.828982821854529
Epoch 220
-------------------------------
Batch 1/64 loss: -2.4179916381835938
Batch 2/64 loss: -2.7617359161376953
Batch 3/64 loss: -2.493753433227539
Batch 4/64 loss: -2.702446937561035
Batch 5/64 loss: -2.671611785888672
Batch 6/64 loss: -2.398301124572754
Batch 7/64 loss: -1.6528034210205078
Batch 8/64 loss: -2.3188791275024414
Batch 9/64 loss: -2.4308080673217773
Batch 10/64 loss: -2.572519302368164
Batch 11/64 loss: -2.564453125
Batch 12/64 loss: -2.5881919860839844
Batch 13/64 loss: -2.5256900787353516
Batch 14/64 loss: -2.5256662368774414
Batch 15/64 loss: -2.648543357849121
Batch 16/64 loss: -2.5797243118286133
Batch 17/64 loss: -2.7068662643432617
Batch 18/64 loss: -2.4796533584594727
Batch 19/64 loss: -1.9796991348266602
Batch 20/64 loss: -2.4278430938720703
Batch 21/64 loss: -2.5546884536743164
Batch 22/64 loss: -2.580354690551758
Batch 23/64 loss: -2.5311946868896484
Batch 24/64 loss: -2.549999237060547
Batch 25/64 loss: -2.1930370330810547
Batch 26/64 loss: -2.085031509399414
Batch 27/64 loss: -2.516103744506836
Batch 28/64 loss: -2.3344783782958984
Batch 29/64 loss: -2.5862045288085938
Batch 30/64 loss: -2.546780586242676
Batch 31/64 loss: -2.592768669128418
Batch 32/64 loss: -2.6940383911132812
Batch 33/64 loss: -2.5198192596435547
Batch 34/64 loss: -2.780514717102051
Batch 35/64 loss: -2.810004234313965
Batch 36/64 loss: -2.613398551940918
Batch 37/64 loss: -2.60848331451416
Batch 38/64 loss: -2.7668657302856445
Batch 39/64 loss: -2.457693099975586
Batch 40/64 loss: -2.83554744720459
Batch 41/64 loss: -2.6129579544067383
Batch 42/64 loss: -2.540093421936035
Batch 43/64 loss: -2.7486438751220703
Batch 44/64 loss: -2.5773134231567383
Batch 45/64 loss: -2.6024179458618164
Batch 46/64 loss: -2.7078332901000977
Batch 47/64 loss: -2.826253890991211
Batch 48/64 loss: -2.5420761108398438
Batch 49/64 loss: -2.7308835983276367
Batch 50/64 loss: -2.4995031356811523
Batch 51/64 loss: -2.3747615814208984
Batch 52/64 loss: -2.5631303787231445
Batch 53/64 loss: -2.5549240112304688
Batch 54/64 loss: -2.6197805404663086
Batch 55/64 loss: -2.793532371520996
Batch 56/64 loss: -2.58095645904541
Batch 57/64 loss: -2.765962600708008
Batch 58/64 loss: -2.6528072357177734
Batch 59/64 loss: -2.3188676834106445
Batch 60/64 loss: -2.647409439086914
Batch 61/64 loss: -2.317401885986328
Batch 62/64 loss: -2.6101760864257812
Batch 63/64 loss: -2.5047035217285156
Batch 64/64 loss: -7.040883541107178
Epoch 220  Train loss: -2.5972900558920466  Val loss: -2.920468962888947
Saving best model, epoch: 220
Epoch 221
-------------------------------
Batch 1/64 loss: -2.9008617401123047
Batch 2/64 loss: -2.498171806335449
Batch 3/64 loss: -1.651188850402832
Batch 4/64 loss: -2.4360713958740234
Batch 5/64 loss: -2.247828483581543
Batch 6/64 loss: -2.3245553970336914
Batch 7/64 loss: -2.6493377685546875
Batch 8/64 loss: -2.636920928955078
Batch 9/64 loss: -2.630915641784668
Batch 10/64 loss: -2.811476707458496
Batch 11/64 loss: -2.5736684799194336
Batch 12/64 loss: -2.807570457458496
Batch 13/64 loss: -2.5335540771484375
Batch 14/64 loss: -2.5625038146972656
Batch 15/64 loss: -2.511185646057129
Batch 16/64 loss: -2.378812789916992
Batch 17/64 loss: -2.7245655059814453
Batch 18/64 loss: -2.8014869689941406
Batch 19/64 loss: -2.708163261413574
Batch 20/64 loss: -2.666653633117676
Batch 21/64 loss: -2.547901153564453
Batch 22/64 loss: -2.4278974533081055
Batch 23/64 loss: -2.4679384231567383
Batch 24/64 loss: -2.799870491027832
Batch 25/64 loss: -2.634641647338867
Batch 26/64 loss: -2.60573673248291
Batch 27/64 loss: -2.756340980529785
Batch 28/64 loss: -2.5298986434936523
Batch 29/64 loss: -2.6214065551757812
Batch 30/64 loss: -2.6222734451293945
Batch 31/64 loss: -2.7721519470214844
Batch 32/64 loss: -2.809720993041992
Batch 33/64 loss: -2.866971015930176
Batch 34/64 loss: -2.852602958679199
Batch 35/64 loss: -2.5337305068969727
Batch 36/64 loss: -2.6496496200561523
Batch 37/64 loss: -2.4353885650634766
Batch 38/64 loss: -2.7045602798461914
Batch 39/64 loss: -2.499354362487793
Batch 40/64 loss: -2.6592044830322266
Batch 41/64 loss: -2.454500198364258
Batch 42/64 loss: -2.5503768920898438
Batch 43/64 loss: -2.584728240966797
Batch 44/64 loss: -2.5561161041259766
Batch 45/64 loss: -2.616952896118164
Batch 46/64 loss: -2.4034719467163086
Batch 47/64 loss: -2.7760448455810547
Batch 48/64 loss: -2.679171562194824
Batch 49/64 loss: -2.811406135559082
Batch 50/64 loss: -2.7013139724731445
Batch 51/64 loss: -2.6861743927001953
Batch 52/64 loss: -2.6887731552124023
Batch 53/64 loss: -2.654186248779297
Batch 54/64 loss: -2.7879409790039062
Batch 55/64 loss: -2.0741071701049805
Batch 56/64 loss: -2.714541435241699
Batch 57/64 loss: -2.4802656173706055
Batch 58/64 loss: -2.5266056060791016
Batch 59/64 loss: -2.4524831771850586
Batch 60/64 loss: -2.7524194717407227
Batch 61/64 loss: -2.635347366333008
Batch 62/64 loss: -2.4752798080444336
Batch 63/64 loss: -2.755703926086426
Batch 64/64 loss: -7.241039276123047
Epoch 221  Train loss: -2.652571360270182  Val loss: -2.8787584337581884
Epoch 222
-------------------------------
Batch 1/64 loss: -2.3049917221069336
Batch 2/64 loss: -2.6313304901123047
Batch 3/64 loss: -2.6757583618164062
Batch 4/64 loss: -2.702756881713867
Batch 5/64 loss: -2.487682342529297
Batch 6/64 loss: -2.672487258911133
Batch 7/64 loss: -2.4043798446655273
Batch 8/64 loss: -2.6859922409057617
Batch 9/64 loss: -2.6725893020629883
Batch 10/64 loss: -2.568086624145508
Batch 11/64 loss: -2.35526180267334
Batch 12/64 loss: -2.5224552154541016
Batch 13/64 loss: -2.6108016967773438
Batch 14/64 loss: -2.5072507858276367
Batch 15/64 loss: -2.46392822265625
Batch 16/64 loss: -2.7182092666625977
Batch 17/64 loss: -2.641815185546875
Batch 18/64 loss: -2.534181594848633
Batch 19/64 loss: -2.557882308959961
Batch 20/64 loss: -2.6477279663085938
Batch 21/64 loss: -2.6548309326171875
Batch 22/64 loss: -2.385244369506836
Batch 23/64 loss: -2.3730573654174805
Batch 24/64 loss: -2.426955223083496
Batch 25/64 loss: -2.5986099243164062
Batch 26/64 loss: -2.7674217224121094
Batch 27/64 loss: -2.50252628326416
Batch 28/64 loss: -2.6088876724243164
Batch 29/64 loss: -2.527106285095215
Batch 30/64 loss: -2.457822799682617
Batch 31/64 loss: -2.567676544189453
Batch 32/64 loss: -2.1976709365844727
Batch 33/64 loss: -2.2686643600463867
Batch 34/64 loss: -2.2912397384643555
Batch 35/64 loss: -2.927182197570801
Batch 36/64 loss: -2.718916893005371
Batch 37/64 loss: -2.5259571075439453
Batch 38/64 loss: -2.4065542221069336
Batch 39/64 loss: -2.6154708862304688
Batch 40/64 loss: -2.666563034057617
Batch 41/64 loss: -2.727407455444336
Batch 42/64 loss: -2.6100034713745117
Batch 43/64 loss: -2.6247968673706055
Batch 44/64 loss: -2.18612003326416
Batch 45/64 loss: -2.585641860961914
Batch 46/64 loss: -2.649982452392578
Batch 47/64 loss: -2.7557783126831055
Batch 48/64 loss: -2.4000539779663086
Batch 49/64 loss: -2.6377363204956055
Batch 50/64 loss: -2.608798027038574
Batch 51/64 loss: -2.8131465911865234
Batch 52/64 loss: -2.2851524353027344
Batch 53/64 loss: -2.5383262634277344
Batch 54/64 loss: -2.615053176879883
Batch 55/64 loss: -2.5931406021118164
Batch 56/64 loss: -2.6484718322753906
Batch 57/64 loss: -2.655017852783203
Batch 58/64 loss: -2.7966623306274414
Batch 59/64 loss: -2.7054996490478516
Batch 60/64 loss: -2.459299087524414
Batch 61/64 loss: -2.4222488403320312
Batch 62/64 loss: -2.708247184753418
Batch 63/64 loss: -2.6896190643310547
Batch 64/64 loss: -6.953166484832764
Epoch 222  Train loss: -2.6162353908314424  Val loss: -2.781765062784411
Epoch 223
-------------------------------
Batch 1/64 loss: -2.4496850967407227
Batch 2/64 loss: -2.4419450759887695
Batch 3/64 loss: -2.72625732421875
Batch 4/64 loss: -1.962122917175293
Batch 5/64 loss: -2.446054458618164
Batch 6/64 loss: -2.85186767578125
Batch 7/64 loss: -2.5901317596435547
Batch 8/64 loss: -2.550755500793457
Batch 9/64 loss: -2.634730339050293
Batch 10/64 loss: -2.4873342514038086
Batch 11/64 loss: -2.3775205612182617
Batch 12/64 loss: -2.449199676513672
Batch 13/64 loss: -2.6155853271484375
Batch 14/64 loss: -2.3918323516845703
Batch 15/64 loss: -2.664609909057617
Batch 16/64 loss: -2.6948680877685547
Batch 17/64 loss: -2.5901241302490234
Batch 18/64 loss: -2.3153533935546875
Batch 19/64 loss: -2.6448421478271484
Batch 20/64 loss: -2.714448928833008
Batch 21/64 loss: -2.500669479370117
Batch 22/64 loss: -2.655684471130371
Batch 23/64 loss: -2.0859832763671875
Batch 24/64 loss: -2.512441635131836
Batch 25/64 loss: -2.3137598037719727
Batch 26/64 loss: -2.498319625854492
Batch 27/64 loss: -2.2355690002441406
Batch 28/64 loss: -2.436068534851074
Batch 29/64 loss: -2.1027603149414062
Batch 30/64 loss: -2.3834428787231445
Batch 31/64 loss: -2.3695411682128906
Batch 32/64 loss: -2.369901657104492
Batch 33/64 loss: -2.6499996185302734
Batch 34/64 loss: -2.5922183990478516
Batch 35/64 loss: -2.473050117492676
Batch 36/64 loss: -2.6089248657226562
Batch 37/64 loss: -2.7863521575927734
Batch 38/64 loss: -2.5740699768066406
Batch 39/64 loss: -2.5925655364990234
Batch 40/64 loss: -1.9335298538208008
Batch 41/64 loss: -2.3025684356689453
Batch 42/64 loss: -2.4903345108032227
Batch 43/64 loss: -2.301516532897949
Batch 44/64 loss: -2.493412971496582
Batch 45/64 loss: -2.3872737884521484
Batch 46/64 loss: -2.221442222595215
Batch 47/64 loss: -2.374789237976074
Batch 48/64 loss: -2.339797019958496
Batch 49/64 loss: -2.647763252258301
Batch 50/64 loss: -2.4251480102539062
Batch 51/64 loss: -2.6572494506835938
Batch 52/64 loss: -2.378276824951172
Batch 53/64 loss: -2.2848358154296875
Batch 54/64 loss: -2.20430850982666
Batch 55/64 loss: -2.052578926086426
Batch 56/64 loss: -2.280862808227539
Batch 57/64 loss: -2.52512264251709
Batch 58/64 loss: -2.060037612915039
Batch 59/64 loss: -2.51798152923584
Batch 60/64 loss: -1.9129352569580078
Batch 61/64 loss: -2.4341001510620117
Batch 62/64 loss: -2.4062376022338867
Batch 63/64 loss: -2.5753488540649414
Batch 64/64 loss: -7.05353307723999
Epoch 223  Train loss: -2.4915794989641973  Val loss: -2.431741917665881
Epoch 224
-------------------------------
Batch 1/64 loss: -2.6277236938476562
Batch 2/64 loss: -1.905181884765625
Batch 3/64 loss: -2.5535802841186523
Batch 4/64 loss: -2.3683109283447266
Batch 5/64 loss: -2.2726335525512695
Batch 6/64 loss: -2.4861583709716797
Batch 7/64 loss: -2.5481109619140625
Batch 8/64 loss: -2.1160430908203125
Batch 9/64 loss: -2.5946340560913086
Batch 10/64 loss: -2.3980016708374023
Batch 11/64 loss: -2.316248893737793
Batch 12/64 loss: -2.3555803298950195
Batch 13/64 loss: -2.4781036376953125
Batch 14/64 loss: -2.554123878479004
Batch 15/64 loss: -2.5972023010253906
Batch 16/64 loss: -2.429347038269043
Batch 17/64 loss: -2.6466236114501953
Batch 18/64 loss: -2.3542346954345703
Batch 19/64 loss: -2.6314382553100586
Batch 20/64 loss: -2.5184555053710938
Batch 21/64 loss: -2.4927186965942383
Batch 22/64 loss: -2.6344680786132812
Batch 23/64 loss: -2.749752998352051
Batch 24/64 loss: -2.3132896423339844
Batch 25/64 loss: -2.6134681701660156
Batch 26/64 loss: -2.2436399459838867
Batch 27/64 loss: -2.4549570083618164
Batch 28/64 loss: -2.5315685272216797
Batch 29/64 loss: -2.75933837890625
Batch 30/64 loss: -2.8332033157348633
Batch 31/64 loss: -2.620425224304199
Batch 32/64 loss: -2.019373893737793
Batch 33/64 loss: -2.6195898056030273
Batch 34/64 loss: -2.706563949584961
Batch 35/64 loss: -2.5743751525878906
Batch 36/64 loss: -2.479785919189453
Batch 37/64 loss: -2.8168869018554688
Batch 38/64 loss: -2.6872434616088867
Batch 39/64 loss: -2.4281110763549805
Batch 40/64 loss: -2.2632503509521484
Batch 41/64 loss: -2.488534927368164
Batch 42/64 loss: -2.541278839111328
Batch 43/64 loss: -2.708439826965332
Batch 44/64 loss: -2.6365108489990234
Batch 45/64 loss: -2.6769790649414062
Batch 46/64 loss: -2.680988311767578
Batch 47/64 loss: -2.4587268829345703
Batch 48/64 loss: -2.464968681335449
Batch 49/64 loss: -2.719799041748047
Batch 50/64 loss: -2.651627540588379
Batch 51/64 loss: -2.591794967651367
Batch 52/64 loss: -2.538559913635254
Batch 53/64 loss: -2.500311851501465
Batch 54/64 loss: -2.7048988342285156
Batch 55/64 loss: -2.515353202819824
Batch 56/64 loss: -2.6437082290649414
Batch 57/64 loss: -2.4278488159179688
Batch 58/64 loss: -2.5275516510009766
Batch 59/64 loss: -2.6502647399902344
Batch 60/64 loss: -2.7448129653930664
Batch 61/64 loss: -2.6708431243896484
Batch 62/64 loss: -2.7009220123291016
Batch 63/64 loss: -2.3180952072143555
Batch 64/64 loss: -6.822551727294922
Epoch 224  Train loss: -2.576838908475988  Val loss: -2.83261867405213
Epoch 225
-------------------------------
Batch 1/64 loss: -2.5017919540405273
Batch 2/64 loss: -2.6407432556152344
Batch 3/64 loss: -2.664196014404297
Batch 4/64 loss: -2.5649242401123047
Batch 5/64 loss: -2.394728660583496
Batch 6/64 loss: -2.7940444946289062
Batch 7/64 loss: -2.7425899505615234
Batch 8/64 loss: -2.719099998474121
Batch 9/64 loss: -2.223968505859375
Batch 10/64 loss: -2.4782752990722656
Batch 11/64 loss: -2.6541261672973633
Batch 12/64 loss: -2.1031322479248047
Batch 13/64 loss: -2.5817012786865234
Batch 14/64 loss: -2.3976526260375977
Batch 15/64 loss: -2.6636838912963867
Batch 16/64 loss: -2.166804313659668
Batch 17/64 loss: -2.6912097930908203
Batch 18/64 loss: -2.4961986541748047
Batch 19/64 loss: -2.5515384674072266
Batch 20/64 loss: -2.0805444717407227
Batch 21/64 loss: -2.589017868041992
Batch 22/64 loss: -2.5727195739746094
Batch 23/64 loss: -2.529353141784668
Batch 24/64 loss: -2.522592544555664
Batch 25/64 loss: -2.741434097290039
Batch 26/64 loss: -2.610952377319336
Batch 27/64 loss: -2.7768688201904297
Batch 28/64 loss: -2.6121339797973633
Batch 29/64 loss: -2.363412857055664
Batch 30/64 loss: -2.360091209411621
Batch 31/64 loss: -2.4625635147094727
Batch 32/64 loss: -2.6256351470947266
Batch 33/64 loss: -2.5832042694091797
Batch 34/64 loss: -2.6883230209350586
Batch 35/64 loss: -2.6266889572143555
Batch 36/64 loss: -2.3145132064819336
Batch 37/64 loss: -2.3390321731567383
Batch 38/64 loss: -2.5158815383911133
Batch 39/64 loss: -2.56912899017334
Batch 40/64 loss: -2.338141441345215
Batch 41/64 loss: -2.6089601516723633
Batch 42/64 loss: -2.5055885314941406
Batch 43/64 loss: -2.3654136657714844
Batch 44/64 loss: -2.4544925689697266
Batch 45/64 loss: -2.650392532348633
Batch 46/64 loss: -2.395216941833496
Batch 47/64 loss: -2.6019296646118164
Batch 48/64 loss: -2.529172897338867
Batch 49/64 loss: -2.458047866821289
Batch 50/64 loss: -2.4594039916992188
Batch 51/64 loss: -2.5651702880859375
Batch 52/64 loss: -2.837221145629883
Batch 53/64 loss: -2.3713884353637695
Batch 54/64 loss: -2.6546144485473633
Batch 55/64 loss: -2.5762758255004883
Batch 56/64 loss: -2.7062883377075195
Batch 57/64 loss: -2.8269004821777344
Batch 58/64 loss: -2.6817703247070312
Batch 59/64 loss: -2.5439682006835938
Batch 60/64 loss: -2.7053537368774414
Batch 61/64 loss: -2.604916572570801
Batch 62/64 loss: -2.7871246337890625
Batch 63/64 loss: -2.678349494934082
Batch 64/64 loss: -7.250288963317871
Epoch 225  Train loss: -2.601699144699994  Val loss: -2.8676502450634933
Epoch 226
-------------------------------
Batch 1/64 loss: -2.44405460357666
Batch 2/64 loss: -2.7345046997070312
Batch 3/64 loss: -2.679157257080078
Batch 4/64 loss: -2.374547004699707
Batch 5/64 loss: -2.6678295135498047
Batch 6/64 loss: -2.3923511505126953
Batch 7/64 loss: -2.684657096862793
Batch 8/64 loss: -2.524057388305664
Batch 9/64 loss: -2.3168601989746094
Batch 10/64 loss: -2.6150875091552734
Batch 11/64 loss: -2.3880691528320312
Batch 12/64 loss: -2.6420135498046875
Batch 13/64 loss: -2.5712175369262695
Batch 14/64 loss: -2.707024574279785
Batch 15/64 loss: -2.493682861328125
Batch 16/64 loss: -2.3240346908569336
Batch 17/64 loss: -2.519237518310547
Batch 18/64 loss: -2.681293487548828
Batch 19/64 loss: -2.648003578186035
Batch 20/64 loss: -2.499147415161133
Batch 21/64 loss: -2.5299806594848633
Batch 22/64 loss: -2.2455568313598633
Batch 23/64 loss: -2.662604331970215
Batch 24/64 loss: -2.6329116821289062
Batch 25/64 loss: -2.531686782836914
Batch 26/64 loss: -2.3414812088012695
Batch 27/64 loss: -2.6717567443847656
Batch 28/64 loss: -2.763735771179199
Batch 29/64 loss: -2.658970832824707
Batch 30/64 loss: -2.564535140991211
Batch 31/64 loss: -2.581332206726074
Batch 32/64 loss: -2.586488723754883
Batch 33/64 loss: -2.587770462036133
Batch 34/64 loss: -2.4098711013793945
Batch 35/64 loss: -2.5510005950927734
Batch 36/64 loss: -2.6378097534179688
Batch 37/64 loss: -2.7412796020507812
Batch 38/64 loss: -2.5140562057495117
Batch 39/64 loss: -2.6104507446289062
Batch 40/64 loss: -2.541975975036621
Batch 41/64 loss: -2.8231048583984375
Batch 42/64 loss: -2.6900177001953125
Batch 43/64 loss: -2.644625663757324
Batch 44/64 loss: -2.7330780029296875
Batch 45/64 loss: -2.3447322845458984
Batch 46/64 loss: -2.3984689712524414
Batch 47/64 loss: -2.6472177505493164
Batch 48/64 loss: -2.339327812194824
Batch 49/64 loss: -1.9174509048461914
Batch 50/64 loss: -2.6024398803710938
Batch 51/64 loss: -2.5240049362182617
Batch 52/64 loss: -2.4429283142089844
Batch 53/64 loss: -2.544987678527832
Batch 54/64 loss: -2.4679670333862305
Batch 55/64 loss: -2.483488082885742
Batch 56/64 loss: -2.7729034423828125
Batch 57/64 loss: -2.760824203491211
Batch 58/64 loss: -2.8234939575195312
Batch 59/64 loss: -2.5413904190063477
Batch 60/64 loss: -2.4747610092163086
Batch 61/64 loss: -2.062631607055664
Batch 62/64 loss: -2.6599578857421875
Batch 63/64 loss: -2.7019777297973633
Batch 64/64 loss: -7.218266487121582
Epoch 226  Train loss: -2.605295155095119  Val loss: -2.896021970768565
Epoch 227
-------------------------------
Batch 1/64 loss: -2.713085174560547
Batch 2/64 loss: -2.360992431640625
Batch 3/64 loss: -2.511712074279785
Batch 4/64 loss: -2.4887943267822266
Batch 5/64 loss: -2.611403465270996
Batch 6/64 loss: -2.600827217102051
Batch 7/64 loss: -2.7139482498168945
Batch 8/64 loss: -2.621800422668457
Batch 9/64 loss: -2.526116371154785
Batch 10/64 loss: -2.4068212509155273
Batch 11/64 loss: -2.683405876159668
Batch 12/64 loss: -2.6400537490844727
Batch 13/64 loss: -2.5745315551757812
Batch 14/64 loss: -2.6630868911743164
Batch 15/64 loss: -2.637418746948242
Batch 16/64 loss: -2.6204681396484375
Batch 17/64 loss: -2.5516738891601562
Batch 18/64 loss: -2.6292219161987305
Batch 19/64 loss: -2.6392154693603516
Batch 20/64 loss: -2.7397279739379883
Batch 21/64 loss: -2.548426628112793
Batch 22/64 loss: -2.6265716552734375
Batch 23/64 loss: -2.80356502532959
Batch 24/64 loss: -2.7788333892822266
Batch 25/64 loss: -2.7260007858276367
Batch 26/64 loss: -2.6469316482543945
Batch 27/64 loss: -2.554729461669922
Batch 28/64 loss: -2.540658950805664
Batch 29/64 loss: -2.7470312118530273
Batch 30/64 loss: -2.7111549377441406
Batch 31/64 loss: -2.6003923416137695
Batch 32/64 loss: -2.5300121307373047
Batch 33/64 loss: -2.486720085144043
Batch 34/64 loss: -2.5179052352905273
Batch 35/64 loss: -2.807492256164551
Batch 36/64 loss: -2.4294700622558594
Batch 37/64 loss: -2.5909910202026367
Batch 38/64 loss: -2.5998945236206055
Batch 39/64 loss: -2.4484853744506836
Batch 40/64 loss: -2.4860591888427734
Batch 41/64 loss: -2.464599609375
Batch 42/64 loss: -2.742678642272949
Batch 43/64 loss: -2.9368534088134766
Batch 44/64 loss: -2.764627456665039
Batch 45/64 loss: -2.593916893005371
Batch 46/64 loss: -2.459484100341797
Batch 47/64 loss: -2.7281875610351562
Batch 48/64 loss: -2.955759048461914
Batch 49/64 loss: -2.833028793334961
Batch 50/64 loss: -2.6238279342651367
Batch 51/64 loss: -2.5476274490356445
Batch 52/64 loss: -2.448110580444336
Batch 53/64 loss: -2.780986785888672
Batch 54/64 loss: -2.668415069580078
Batch 55/64 loss: -2.700913429260254
Batch 56/64 loss: -2.7328948974609375
Batch 57/64 loss: -2.5114755630493164
Batch 58/64 loss: -2.5921554565429688
Batch 59/64 loss: -2.391765594482422
Batch 60/64 loss: -2.709347724914551
Batch 61/64 loss: -2.5669612884521484
Batch 62/64 loss: -2.7370357513427734
Batch 63/64 loss: -2.65749454498291
Batch 64/64 loss: -7.110465049743652
Epoch 227  Train loss: -2.6760255290012736  Val loss: -2.937754706418801
Saving best model, epoch: 227
Epoch 228
-------------------------------
Batch 1/64 loss: -2.5794363021850586
Batch 2/64 loss: -2.6563262939453125
Batch 3/64 loss: -2.726902961730957
Batch 4/64 loss: -2.698200225830078
Batch 5/64 loss: -2.657045364379883
Batch 6/64 loss: -2.578470230102539
Batch 7/64 loss: -2.6545839309692383
Batch 8/64 loss: -2.9607133865356445
Batch 9/64 loss: -2.6595640182495117
Batch 10/64 loss: -2.5596561431884766
Batch 11/64 loss: -2.7853832244873047
Batch 12/64 loss: -2.7495803833007812
Batch 13/64 loss: -2.6070756912231445
Batch 14/64 loss: -2.498152732849121
Batch 15/64 loss: -2.7487783432006836
Batch 16/64 loss: -2.982522964477539
Batch 17/64 loss: -2.4631309509277344
Batch 18/64 loss: -2.4999380111694336
Batch 19/64 loss: -2.687347412109375
Batch 20/64 loss: -2.5670671463012695
Batch 21/64 loss: -2.3422021865844727
Batch 22/64 loss: -1.9659137725830078
Batch 23/64 loss: -2.721503257751465
Batch 24/64 loss: -2.4888248443603516
Batch 25/64 loss: -2.5248804092407227
Batch 26/64 loss: -2.6019296646118164
Batch 27/64 loss: -2.4930877685546875
Batch 28/64 loss: -2.4111499786376953
Batch 29/64 loss: -2.831427574157715
Batch 30/64 loss: -2.80718994140625
Batch 31/64 loss: -2.356072425842285
Batch 32/64 loss: -2.5323925018310547
Batch 33/64 loss: -2.69692325592041
Batch 34/64 loss: -2.15230655670166
Batch 35/64 loss: -2.336113929748535
Batch 36/64 loss: -2.690732955932617
Batch 37/64 loss: -2.79598331451416
Batch 38/64 loss: -2.380509376525879
Batch 39/64 loss: -2.5718936920166016
Batch 40/64 loss: -2.669025421142578
Batch 41/64 loss: -2.7404556274414062
Batch 42/64 loss: -2.6008338928222656
Batch 43/64 loss: -2.796205520629883
Batch 44/64 loss: -2.5624589920043945
Batch 45/64 loss: -2.6667299270629883
Batch 46/64 loss: -2.4636363983154297
Batch 47/64 loss: -2.492544174194336
Batch 48/64 loss: -2.2492990493774414
Batch 49/64 loss: -2.520411491394043
Batch 50/64 loss: -2.6940059661865234
Batch 51/64 loss: -2.6846208572387695
Batch 52/64 loss: -2.7090368270874023
Batch 53/64 loss: -2.5921449661254883
Batch 54/64 loss: -2.287626266479492
Batch 55/64 loss: -2.912775993347168
Batch 56/64 loss: -2.6536083221435547
Batch 57/64 loss: -2.7222681045532227
Batch 58/64 loss: -2.448028564453125
Batch 59/64 loss: -2.6132984161376953
Batch 60/64 loss: -2.44244384765625
Batch 61/64 loss: -2.719649314880371
Batch 62/64 loss: -2.599336624145508
Batch 63/64 loss: -2.7089691162109375
Batch 64/64 loss: -7.108359336853027
Epoch 228  Train loss: -2.6494368048275216  Val loss: -2.9055798193023787
Epoch 229
-------------------------------
Batch 1/64 loss: -2.404911994934082
Batch 2/64 loss: -2.6381912231445312
Batch 3/64 loss: -2.702273368835449
Batch 4/64 loss: -2.6279916763305664
Batch 5/64 loss: -2.7278900146484375
Batch 6/64 loss: -2.696014404296875
Batch 7/64 loss: -2.536121368408203
Batch 8/64 loss: -2.6535205841064453
Batch 9/64 loss: -2.0676889419555664
Batch 10/64 loss: -2.6384401321411133
Batch 11/64 loss: -2.431328773498535
Batch 12/64 loss: -2.622267723083496
Batch 13/64 loss: -2.7831249237060547
Batch 14/64 loss: -2.5685348510742188
Batch 15/64 loss: -2.7622814178466797
Batch 16/64 loss: -2.464906692504883
Batch 17/64 loss: -2.647459030151367
Batch 18/64 loss: -2.667424201965332
Batch 19/64 loss: -2.5833654403686523
Batch 20/64 loss: -2.5879955291748047
Batch 21/64 loss: -2.66534423828125
Batch 22/64 loss: -2.5330991744995117
Batch 23/64 loss: -2.691263198852539
Batch 24/64 loss: -2.6549949645996094
Batch 25/64 loss: -2.656977653503418
Batch 26/64 loss: -2.574769973754883
Batch 27/64 loss: -2.5179052352905273
Batch 28/64 loss: -2.7206926345825195
Batch 29/64 loss: -2.540895462036133
Batch 30/64 loss: -2.72552490234375
Batch 31/64 loss: -2.8062610626220703
Batch 32/64 loss: -2.498440742492676
Batch 33/64 loss: -2.572068214416504
Batch 34/64 loss: -2.894537925720215
Batch 35/64 loss: -2.316840171813965
Batch 36/64 loss: -2.4544429779052734
Batch 37/64 loss: -2.771554946899414
Batch 38/64 loss: -2.817194938659668
Batch 39/64 loss: -2.5528717041015625
Batch 40/64 loss: -2.48635196685791
Batch 41/64 loss: -2.650691032409668
Batch 42/64 loss: -2.5211267471313477
Batch 43/64 loss: -2.6659040451049805
Batch 44/64 loss: -2.526906967163086
Batch 45/64 loss: -2.6030731201171875
Batch 46/64 loss: -2.9592771530151367
Batch 47/64 loss: -2.826648712158203
Batch 48/64 loss: -2.7918004989624023
Batch 49/64 loss: -2.7640628814697266
Batch 50/64 loss: -2.8660926818847656
Batch 51/64 loss: -2.7778806686401367
Batch 52/64 loss: -2.3916101455688477
Batch 53/64 loss: -2.6677169799804688
Batch 54/64 loss: -2.3606576919555664
Batch 55/64 loss: -2.553622245788574
Batch 56/64 loss: -2.6242904663085938
Batch 57/64 loss: -2.7975101470947266
Batch 58/64 loss: -2.7433958053588867
Batch 59/64 loss: -2.7327404022216797
Batch 60/64 loss: -2.8918724060058594
Batch 61/64 loss: -2.542387008666992
Batch 62/64 loss: -2.6799850463867188
Batch 63/64 loss: -2.6092395782470703
Batch 64/64 loss: -7.350483417510986
Epoch 229  Train loss: -2.6874528529597264  Val loss: -2.9543985189850797
Saving best model, epoch: 229
Epoch 230
-------------------------------
Batch 1/64 loss: -2.6665115356445312
Batch 2/64 loss: -2.8360042572021484
Batch 3/64 loss: -2.7122764587402344
Batch 4/64 loss: -2.7030982971191406
Batch 5/64 loss: -2.529179573059082
Batch 6/64 loss: -2.499063491821289
Batch 7/64 loss: -2.5447206497192383
Batch 8/64 loss: -2.810145378112793
Batch 9/64 loss: -2.741532325744629
Batch 10/64 loss: -2.2744970321655273
Batch 11/64 loss: -2.6000328063964844
Batch 12/64 loss: -2.77085018157959
Batch 13/64 loss: -2.361456871032715
Batch 14/64 loss: -2.665499687194824
Batch 15/64 loss: -2.7352447509765625
Batch 16/64 loss: -2.6666259765625
Batch 17/64 loss: -2.568796157836914
Batch 18/64 loss: -2.852786064147949
Batch 19/64 loss: -2.6008129119873047
Batch 20/64 loss: -2.520796775817871
Batch 21/64 loss: -2.6533632278442383
Batch 22/64 loss: -2.7989654541015625
Batch 23/64 loss: -2.7552642822265625
Batch 24/64 loss: -2.603940010070801
Batch 25/64 loss: -2.7190818786621094
Batch 26/64 loss: -2.764744758605957
Batch 27/64 loss: -2.6624927520751953
Batch 28/64 loss: -2.8835372924804688
Batch 29/64 loss: -2.7736597061157227
Batch 30/64 loss: -2.679159164428711
Batch 31/64 loss: -2.4504032135009766
Batch 32/64 loss: -2.7213239669799805
Batch 33/64 loss: -2.5394344329833984
Batch 34/64 loss: -2.8407468795776367
Batch 35/64 loss: -2.647014617919922
Batch 36/64 loss: -2.7018203735351562
Batch 37/64 loss: -2.5417041778564453
Batch 38/64 loss: -2.738856315612793
Batch 39/64 loss: -2.5676498413085938
Batch 40/64 loss: -2.801504135131836
Batch 41/64 loss: -2.5000438690185547
Batch 42/64 loss: -2.783153533935547
Batch 43/64 loss: -2.49544620513916
Batch 44/64 loss: -2.8970746994018555
Batch 45/64 loss: -2.842698097229004
Batch 46/64 loss: -2.6497020721435547
Batch 47/64 loss: -2.5466108322143555
Batch 48/64 loss: -2.7321395874023438
Batch 49/64 loss: -2.604684829711914
Batch 50/64 loss: -2.6333694458007812
Batch 51/64 loss: -2.2587547302246094
Batch 52/64 loss: -2.8229732513427734
Batch 53/64 loss: -2.665665626525879
Batch 54/64 loss: -2.6532716751098633
Batch 55/64 loss: -2.6664047241210938
Batch 56/64 loss: -2.6998510360717773
Batch 57/64 loss: -2.577178955078125
Batch 58/64 loss: -2.5563278198242188
Batch 59/64 loss: -2.6445274353027344
Batch 60/64 loss: -2.66473388671875
Batch 61/64 loss: -2.7237863540649414
Batch 62/64 loss: -2.7292089462280273
Batch 63/64 loss: -2.7156753540039062
Batch 64/64 loss: -7.126702308654785
Epoch 230  Train loss: -2.7123593311683805  Val loss: -3.0349119258500457
Saving best model, epoch: 230
Epoch 231
-------------------------------
Batch 1/64 loss: -2.6310501098632812
Batch 2/64 loss: -2.670970916748047
Batch 3/64 loss: -2.2018632888793945
Batch 4/64 loss: -2.5426931381225586
Batch 5/64 loss: -2.7351999282836914
Batch 6/64 loss: -2.5591678619384766
Batch 7/64 loss: -2.5746383666992188
Batch 8/64 loss: -2.5213470458984375
Batch 9/64 loss: -2.806349754333496
Batch 10/64 loss: -2.6306533813476562
Batch 11/64 loss: -2.3582229614257812
Batch 12/64 loss: -2.635679244995117
Batch 13/64 loss: -2.7062559127807617
Batch 14/64 loss: -2.7054262161254883
Batch 15/64 loss: -2.6645641326904297
Batch 16/64 loss: -2.795975685119629
Batch 17/64 loss: -2.589740753173828
Batch 18/64 loss: -2.799478530883789
Batch 19/64 loss: -2.792628288269043
Batch 20/64 loss: -2.8320178985595703
Batch 21/64 loss: -2.7324352264404297
Batch 22/64 loss: -2.738478660583496
Batch 23/64 loss: -2.7615652084350586
Batch 24/64 loss: -2.4359073638916016
Batch 25/64 loss: -2.692906379699707
Batch 26/64 loss: -2.653799057006836
Batch 27/64 loss: -2.7250537872314453
Batch 28/64 loss: -2.857574462890625
Batch 29/64 loss: -2.5725860595703125
Batch 30/64 loss: -2.5881500244140625
Batch 31/64 loss: -2.68966007232666
Batch 32/64 loss: -2.46781063079834
Batch 33/64 loss: -2.7795028686523438
Batch 34/64 loss: -2.6589231491088867
Batch 35/64 loss: -2.639084815979004
Batch 36/64 loss: -2.67626953125
Batch 37/64 loss: -2.471536636352539
Batch 38/64 loss: -2.805391311645508
Batch 39/64 loss: -2.3470773696899414
Batch 40/64 loss: -2.8169374465942383
Batch 41/64 loss: -2.8220176696777344
Batch 42/64 loss: -2.782376289367676
Batch 43/64 loss: -2.7184743881225586
Batch 44/64 loss: -2.802126884460449
Batch 45/64 loss: -2.5187549591064453
Batch 46/64 loss: -2.6597814559936523
Batch 47/64 loss: -2.5066490173339844
Batch 48/64 loss: -2.6029367446899414
Batch 49/64 loss: -2.67822265625
Batch 50/64 loss: -2.408566474914551
Batch 51/64 loss: -2.8481922149658203
Batch 52/64 loss: -2.836732864379883
Batch 53/64 loss: -2.289250373840332
Batch 54/64 loss: -2.660576820373535
Batch 55/64 loss: -2.7724714279174805
Batch 56/64 loss: -2.458423614501953
Batch 57/64 loss: -1.9566650390625
Batch 58/64 loss: -2.608445167541504
Batch 59/64 loss: -2.77901554107666
Batch 60/64 loss: -2.6579904556274414
Batch 61/64 loss: -2.824674606323242
Batch 62/64 loss: -2.481210708618164
Batch 63/64 loss: -2.6427574157714844
Batch 64/64 loss: -7.237710475921631
Epoch 231  Train loss: -2.6919085353028542  Val loss: -2.881794224899659
Epoch 232
-------------------------------
Batch 1/64 loss: -2.8088550567626953
Batch 2/64 loss: -2.717099189758301
Batch 3/64 loss: -2.802964210510254
Batch 4/64 loss: -2.5307130813598633
Batch 5/64 loss: -2.3949050903320312
Batch 6/64 loss: -2.781177520751953
Batch 7/64 loss: -2.877330780029297
Batch 8/64 loss: -2.7091121673583984
Batch 9/64 loss: -2.593165397644043
Batch 10/64 loss: -2.7757740020751953
Batch 11/64 loss: -2.662281036376953
Batch 12/64 loss: -2.594061851501465
Batch 13/64 loss: -2.8183069229125977
Batch 14/64 loss: -2.6811561584472656
Batch 15/64 loss: -2.4640626907348633
Batch 16/64 loss: -2.8075761795043945
Batch 17/64 loss: -2.515666961669922
Batch 18/64 loss: -2.5279455184936523
Batch 19/64 loss: -2.4601898193359375
Batch 20/64 loss: -2.869295120239258
Batch 21/64 loss: -2.815300941467285
Batch 22/64 loss: -2.662899971008301
Batch 23/64 loss: -2.5772504806518555
Batch 24/64 loss: -2.2648048400878906
Batch 25/64 loss: -2.560647964477539
Batch 26/64 loss: -2.556685447692871
Batch 27/64 loss: -2.5666933059692383
Batch 28/64 loss: -2.6998395919799805
Batch 29/64 loss: -2.634023666381836
Batch 30/64 loss: -2.4036388397216797
Batch 31/64 loss: -2.9568214416503906
Batch 32/64 loss: -2.6251440048217773
Batch 33/64 loss: -2.4138336181640625
Batch 34/64 loss: -2.721353530883789
Batch 35/64 loss: -2.7045278549194336
Batch 36/64 loss: -2.774829864501953
Batch 37/64 loss: -2.554586410522461
Batch 38/64 loss: -2.294351577758789
Batch 39/64 loss: -2.461301803588867
Batch 40/64 loss: -2.703152656555176
Batch 41/64 loss: -2.7708911895751953
Batch 42/64 loss: -2.4254980087280273
Batch 43/64 loss: -2.5805959701538086
Batch 44/64 loss: -2.628314971923828
Batch 45/64 loss: -2.647639274597168
Batch 46/64 loss: -2.699310302734375
Batch 47/64 loss: -2.5247068405151367
Batch 48/64 loss: -2.569125175476074
Batch 49/64 loss: -2.7768754959106445
Batch 50/64 loss: -2.8804454803466797
Batch 51/64 loss: -2.6496591567993164
Batch 52/64 loss: -2.6464080810546875
Batch 53/64 loss: -2.353944778442383
Batch 54/64 loss: -2.6564903259277344
Batch 55/64 loss: -2.840810775756836
Batch 56/64 loss: -2.693910598754883
Batch 57/64 loss: -2.3744993209838867
Batch 58/64 loss: -2.805975914001465
Batch 59/64 loss: -2.396054267883301
Batch 60/64 loss: -2.775506019592285
Batch 61/64 loss: -2.7018051147460938
Batch 62/64 loss: -2.7499427795410156
Batch 63/64 loss: -2.5595035552978516
Batch 64/64 loss: -7.097935199737549
Epoch 232  Train loss: -2.688230452818029  Val loss: -3.0050678711986216
Epoch 233
-------------------------------
Batch 1/64 loss: -2.654644012451172
Batch 2/64 loss: -2.280694007873535
Batch 3/64 loss: -2.762017250061035
Batch 4/64 loss: -2.5948877334594727
Batch 5/64 loss: -2.2444725036621094
Batch 6/64 loss: -2.8077516555786133
Batch 7/64 loss: -2.7358999252319336
Batch 8/64 loss: -2.33676815032959
Batch 9/64 loss: -2.8030004501342773
Batch 10/64 loss: -2.555419921875
Batch 11/64 loss: -2.729689598083496
Batch 12/64 loss: -2.342538833618164
Batch 13/64 loss: -2.596853256225586
Batch 14/64 loss: -2.9523983001708984
Batch 15/64 loss: -2.7680845260620117
Batch 16/64 loss: -2.5849742889404297
Batch 17/64 loss: -2.456925392150879
Batch 18/64 loss: -2.884756088256836
Batch 19/64 loss: -2.6071596145629883
Batch 20/64 loss: -2.932246208190918
Batch 21/64 loss: -2.7370834350585938
Batch 22/64 loss: -2.5126171112060547
Batch 23/64 loss: -2.704451560974121
Batch 24/64 loss: -2.7530431747436523
Batch 25/64 loss: -2.843592643737793
Batch 26/64 loss: -2.312178611755371
Batch 27/64 loss: -2.6110124588012695
Batch 28/64 loss: -2.6502532958984375
Batch 29/64 loss: -2.6554880142211914
Batch 30/64 loss: -2.1495962142944336
Batch 31/64 loss: -2.6573028564453125
Batch 32/64 loss: -2.5012407302856445
Batch 33/64 loss: -2.678778648376465
Batch 34/64 loss: -2.905106544494629
Batch 35/64 loss: -2.6717681884765625
Batch 36/64 loss: -2.638347625732422
Batch 37/64 loss: -2.4948244094848633
Batch 38/64 loss: -2.706366539001465
Batch 39/64 loss: -2.718637466430664
Batch 40/64 loss: -2.778317451477051
Batch 41/64 loss: -2.79156494140625
Batch 42/64 loss: -2.6575565338134766
Batch 43/64 loss: -2.655487060546875
Batch 44/64 loss: -2.6990203857421875
Batch 45/64 loss: -2.6956634521484375
Batch 46/64 loss: -2.626296043395996
Batch 47/64 loss: -2.824099540710449
Batch 48/64 loss: -2.6931610107421875
Batch 49/64 loss: -2.745965003967285
Batch 50/64 loss: -2.4959049224853516
Batch 51/64 loss: -2.380923271179199
Batch 52/64 loss: -2.8340253829956055
Batch 53/64 loss: -2.718174934387207
Batch 54/64 loss: -2.688542366027832
Batch 55/64 loss: -2.6581907272338867
Batch 56/64 loss: -2.3051795959472656
Batch 57/64 loss: -2.6983814239501953
Batch 58/64 loss: -2.630617141723633
Batch 59/64 loss: -2.709609031677246
Batch 60/64 loss: -2.8509140014648438
Batch 61/64 loss: -2.7098217010498047
Batch 62/64 loss: -2.8581647872924805
Batch 63/64 loss: -2.772787094116211
Batch 64/64 loss: -6.667860984802246
Epoch 233  Train loss: -2.69822956533993  Val loss: -3.030836478951051
Epoch 234
-------------------------------
Batch 1/64 loss: -2.7079391479492188
Batch 2/64 loss: -2.6432952880859375
Batch 3/64 loss: -2.4829559326171875
Batch 4/64 loss: -2.556912422180176
Batch 5/64 loss: -2.809279441833496
Batch 6/64 loss: -2.509617805480957
Batch 7/64 loss: -2.6135387420654297
Batch 8/64 loss: -2.696287155151367
Batch 9/64 loss: -2.8178329467773438
Batch 10/64 loss: -2.789022445678711
Batch 11/64 loss: -2.5503101348876953
Batch 12/64 loss: -2.7513303756713867
Batch 13/64 loss: -2.8216676712036133
Batch 14/64 loss: -2.1453609466552734
Batch 15/64 loss: -2.6222715377807617
Batch 16/64 loss: -2.5551748275756836
Batch 17/64 loss: -2.6607189178466797
Batch 18/64 loss: -2.403639793395996
Batch 19/64 loss: -2.754486083984375
Batch 20/64 loss: -2.5905628204345703
Batch 21/64 loss: -2.441472053527832
Batch 22/64 loss: -2.40665340423584
Batch 23/64 loss: -2.4048824310302734
Batch 24/64 loss: -2.500499725341797
Batch 25/64 loss: -2.72420597076416
Batch 26/64 loss: -2.436783790588379
Batch 27/64 loss: -2.7326526641845703
Batch 28/64 loss: -2.7092037200927734
Batch 29/64 loss: -2.526095390319824
Batch 30/64 loss: -2.689845085144043
Batch 31/64 loss: -2.7096662521362305
Batch 32/64 loss: -2.682440757751465
Batch 33/64 loss: -2.5342884063720703
Batch 34/64 loss: -2.759354591369629
Batch 35/64 loss: -2.5617589950561523
Batch 36/64 loss: -2.7860918045043945
Batch 37/64 loss: -2.699183464050293
Batch 38/64 loss: -2.597500801086426
Batch 39/64 loss: -2.725738525390625
Batch 40/64 loss: -2.559271812438965
Batch 41/64 loss: -2.829226493835449
Batch 42/64 loss: -2.4601669311523438
Batch 43/64 loss: -2.5298099517822266
Batch 44/64 loss: -2.5377683639526367
Batch 45/64 loss: -2.6864442825317383
Batch 46/64 loss: -2.838724136352539
Batch 47/64 loss: -2.709916114807129
Batch 48/64 loss: -2.613673210144043
Batch 49/64 loss: -2.7499914169311523
Batch 50/64 loss: -2.641946792602539
Batch 51/64 loss: -2.6641969680786133
Batch 52/64 loss: -2.7023820877075195
Batch 53/64 loss: -2.591311454772949
Batch 54/64 loss: -2.6539907455444336
Batch 55/64 loss: -2.6747379302978516
Batch 56/64 loss: -2.391998291015625
Batch 57/64 loss: -2.426668167114258
Batch 58/64 loss: -2.574244499206543
Batch 59/64 loss: -2.693087577819824
Batch 60/64 loss: -2.2070741653442383
Batch 61/64 loss: -2.1300735473632812
Batch 62/64 loss: -2.590099334716797
Batch 63/64 loss: -2.5564165115356445
Batch 64/64 loss: -7.198149681091309
Epoch 234  Train loss: -2.6591742010677564  Val loss: -2.9317671785649564
Epoch 235
-------------------------------
Batch 1/64 loss: -2.636874198913574
Batch 2/64 loss: -2.3056564331054688
Batch 3/64 loss: -2.717985153198242
Batch 4/64 loss: -2.2947139739990234
Batch 5/64 loss: -2.5448665618896484
Batch 6/64 loss: -2.281805992126465
Batch 7/64 loss: -2.47640323638916
Batch 8/64 loss: -2.733785629272461
Batch 9/64 loss: -2.581592559814453
Batch 10/64 loss: -2.820857048034668
Batch 11/64 loss: -2.4880857467651367
Batch 12/64 loss: -2.5269594192504883
Batch 13/64 loss: -2.755791664123535
Batch 14/64 loss: -2.4114274978637695
Batch 15/64 loss: -2.783590316772461
Batch 16/64 loss: -2.816377639770508
Batch 17/64 loss: -2.713857650756836
Batch 18/64 loss: -2.514080047607422
Batch 19/64 loss: -2.5652551651000977
Batch 20/64 loss: -2.5618972778320312
Batch 21/64 loss: -2.678769111633301
Batch 22/64 loss: -2.621649742126465
Batch 23/64 loss: -2.127849578857422
Batch 24/64 loss: -2.421320915222168
Batch 25/64 loss: -2.7120018005371094
Batch 26/64 loss: -2.799160957336426
Batch 27/64 loss: -2.5958032608032227
Batch 28/64 loss: -2.7654685974121094
Batch 29/64 loss: -2.714053153991699
Batch 30/64 loss: -2.803849220275879
Batch 31/64 loss: -2.8317480087280273
Batch 32/64 loss: -2.6153030395507812
Batch 33/64 loss: -2.554690361022949
Batch 34/64 loss: -2.4748048782348633
Batch 35/64 loss: -2.5446624755859375
Batch 36/64 loss: -2.630216598510742
Batch 37/64 loss: -2.1804752349853516
Batch 38/64 loss: -2.8608903884887695
Batch 39/64 loss: -2.549504280090332
Batch 40/64 loss: -2.859182357788086
Batch 41/64 loss: -2.570680618286133
Batch 42/64 loss: -2.586498260498047
Batch 43/64 loss: -2.719432830810547
Batch 44/64 loss: -2.7392215728759766
Batch 45/64 loss: -2.5677671432495117
Batch 46/64 loss: -2.464435577392578
Batch 47/64 loss: -2.664860725402832
Batch 48/64 loss: -2.3785905838012695
Batch 49/64 loss: -2.407954216003418
Batch 50/64 loss: -2.526437759399414
Batch 51/64 loss: -2.4962034225463867
Batch 52/64 loss: -2.613168716430664
Batch 53/64 loss: -2.6675567626953125
Batch 54/64 loss: -2.6921443939208984
Batch 55/64 loss: -2.7413206100463867
Batch 56/64 loss: -2.602224349975586
Batch 57/64 loss: -2.611024856567383
Batch 58/64 loss: -2.188108444213867
Batch 59/64 loss: -2.2030105590820312
Batch 60/64 loss: -2.3185625076293945
Batch 61/64 loss: -2.6975021362304688
Batch 62/64 loss: -2.702360153198242
Batch 63/64 loss: -2.7286224365234375
Batch 64/64 loss: -6.767721176147461
Epoch 235  Train loss: -2.6327332814534503  Val loss: -2.8685689054403927
Epoch 236
-------------------------------
Batch 1/64 loss: -2.693924903869629
Batch 2/64 loss: -2.3667964935302734
Batch 3/64 loss: -2.548232078552246
Batch 4/64 loss: -2.43741512298584
Batch 5/64 loss: -2.211277961730957
Batch 6/64 loss: -1.5260133743286133
Batch 7/64 loss: -2.524786949157715
Batch 8/64 loss: -2.601414680480957
Batch 9/64 loss: -2.6602745056152344
Batch 10/64 loss: -2.7328758239746094
Batch 11/64 loss: -2.3217859268188477
Batch 12/64 loss: -2.5877676010131836
Batch 13/64 loss: -2.5728225708007812
Batch 14/64 loss: -2.730428695678711
Batch 15/64 loss: -2.8116836547851562
Batch 16/64 loss: -2.756307601928711
Batch 17/64 loss: -2.487664222717285
Batch 18/64 loss: -2.6995372772216797
Batch 19/64 loss: -2.6315784454345703
Batch 20/64 loss: -2.342698097229004
Batch 21/64 loss: -2.4009761810302734
Batch 22/64 loss: -2.6968994140625
Batch 23/64 loss: -2.5443124771118164
Batch 24/64 loss: -2.4935903549194336
Batch 25/64 loss: -2.540471076965332
Batch 26/64 loss: -2.6505470275878906
Batch 27/64 loss: -2.74338436126709
Batch 28/64 loss: -2.710177421569824
Batch 29/64 loss: -2.7405004501342773
Batch 30/64 loss: -2.5674686431884766
Batch 31/64 loss: -2.5746231079101562
Batch 32/64 loss: -2.7971343994140625
Batch 33/64 loss: -2.2008724212646484
Batch 34/64 loss: -2.722227096557617
Batch 35/64 loss: -2.5710506439208984
Batch 36/64 loss: -2.6122446060180664
Batch 37/64 loss: -2.770498275756836
Batch 38/64 loss: -2.717254638671875
Batch 39/64 loss: -2.7666616439819336
Batch 40/64 loss: -2.731534004211426
Batch 41/64 loss: -2.663212776184082
Batch 42/64 loss: -2.7599000930786133
Batch 43/64 loss: -2.673405647277832
Batch 44/64 loss: -2.3009090423583984
Batch 45/64 loss: -2.744978904724121
Batch 46/64 loss: -2.6302671432495117
Batch 47/64 loss: -2.402113914489746
Batch 48/64 loss: -2.8683347702026367
Batch 49/64 loss: -2.489166259765625
Batch 50/64 loss: -2.6056270599365234
Batch 51/64 loss: -2.6347389221191406
Batch 52/64 loss: -2.5945510864257812
Batch 53/64 loss: -2.614804267883301
Batch 54/64 loss: -2.566878318786621
Batch 55/64 loss: -2.6044130325317383
Batch 56/64 loss: -2.7399778366088867
Batch 57/64 loss: -2.6454763412475586
Batch 58/64 loss: -2.6160459518432617
Batch 59/64 loss: -2.2496509552001953
Batch 60/64 loss: -2.713747978210449
Batch 61/64 loss: -2.4908618927001953
Batch 62/64 loss: -2.8164520263671875
Batch 63/64 loss: -2.56353759765625
Batch 64/64 loss: -7.085793495178223
Epoch 236  Train loss: -2.6368801752726236  Val loss: -2.8763477155023423
Epoch 237
-------------------------------
Batch 1/64 loss: -2.626297950744629
Batch 2/64 loss: -2.700861930847168
Batch 3/64 loss: -2.480605125427246
Batch 4/64 loss: -2.1012134552001953
Batch 5/64 loss: -2.598261833190918
Batch 6/64 loss: -2.7775049209594727
Batch 7/64 loss: -2.71701717376709
Batch 8/64 loss: -2.713785171508789
Batch 9/64 loss: -2.4898509979248047
Batch 10/64 loss: -2.703817367553711
Batch 11/64 loss: -2.400604248046875
Batch 12/64 loss: -2.5987472534179688
Batch 13/64 loss: -2.727879524230957
Batch 14/64 loss: -2.7859878540039062
Batch 15/64 loss: -2.8621063232421875
Batch 16/64 loss: -2.746798515319824
Batch 17/64 loss: -2.632669448852539
Batch 18/64 loss: -2.4890966415405273
Batch 19/64 loss: -2.936992645263672
Batch 20/64 loss: -2.6259164810180664
Batch 21/64 loss: -2.585367202758789
Batch 22/64 loss: -2.7090654373168945
Batch 23/64 loss: -2.7288331985473633
Batch 24/64 loss: -2.6800718307495117
Batch 25/64 loss: -2.2964439392089844
Batch 26/64 loss: -2.7764930725097656
Batch 27/64 loss: -2.772123336791992
Batch 28/64 loss: -2.3652753829956055
Batch 29/64 loss: -2.492443084716797
Batch 30/64 loss: -2.6424102783203125
Batch 31/64 loss: -2.8005170822143555
Batch 32/64 loss: -2.492232322692871
Batch 33/64 loss: -2.6419458389282227
Batch 34/64 loss: -2.8009376525878906
Batch 35/64 loss: -2.602344512939453
Batch 36/64 loss: -2.398289680480957
Batch 37/64 loss: -2.7235097885131836
Batch 38/64 loss: -2.7097043991088867
Batch 39/64 loss: -2.730649948120117
Batch 40/64 loss: -2.7413625717163086
Batch 41/64 loss: -2.650527000427246
Batch 42/64 loss: -2.7401857376098633
Batch 43/64 loss: -2.458528518676758
Batch 44/64 loss: -2.6431989669799805
Batch 45/64 loss: -2.4370155334472656
Batch 46/64 loss: -2.612847328186035
Batch 47/64 loss: -2.7187089920043945
Batch 48/64 loss: -2.0034408569335938
Batch 49/64 loss: -2.780900001525879
Batch 50/64 loss: -2.75274658203125
Batch 51/64 loss: -2.396921157836914
Batch 52/64 loss: -2.31369686126709
Batch 53/64 loss: -2.73099422454834
Batch 54/64 loss: -2.5159502029418945
Batch 55/64 loss: -2.588955879211426
Batch 56/64 loss: -2.653506278991699
Batch 57/64 loss: -2.6422224044799805
Batch 58/64 loss: -2.639349937438965
Batch 59/64 loss: -2.3667049407958984
Batch 60/64 loss: -2.7600927352905273
Batch 61/64 loss: -2.3947391510009766
Batch 62/64 loss: -2.6826047897338867
Batch 63/64 loss: -2.4929189682006836
Batch 64/64 loss: -7.053847789764404
Epoch 237  Train loss: -2.6615400520025516  Val loss: -2.8252414428081707
Epoch 238
-------------------------------
Batch 1/64 loss: -2.58297061920166
Batch 2/64 loss: -2.5827293395996094
Batch 3/64 loss: -2.656205177307129
Batch 4/64 loss: -2.645880699157715
Batch 5/64 loss: -2.573934555053711
Batch 6/64 loss: -2.5263071060180664
Batch 7/64 loss: -2.762660026550293
Batch 8/64 loss: -2.839503288269043
Batch 9/64 loss: -2.502253532409668
Batch 10/64 loss: -2.7330150604248047
Batch 11/64 loss: -2.6387643814086914
Batch 12/64 loss: -2.4559459686279297
Batch 13/64 loss: -2.8363704681396484
Batch 14/64 loss: -2.6903457641601562
Batch 15/64 loss: -2.2416744232177734
Batch 16/64 loss: -2.6279306411743164
Batch 17/64 loss: -2.542600631713867
Batch 18/64 loss: -2.436910629272461
Batch 19/64 loss: -2.620926856994629
Batch 20/64 loss: -2.7495994567871094
Batch 21/64 loss: -2.64406681060791
Batch 22/64 loss: -2.3651037216186523
Batch 23/64 loss: -2.6746463775634766
Batch 24/64 loss: -2.719475746154785
Batch 25/64 loss: -2.8661422729492188
Batch 26/64 loss: -2.7826433181762695
Batch 27/64 loss: -2.526529312133789
Batch 28/64 loss: -2.755990982055664
Batch 29/64 loss: -2.7780752182006836
Batch 30/64 loss: -2.6481008529663086
Batch 31/64 loss: -2.4009828567504883
Batch 32/64 loss: -2.754610061645508
Batch 33/64 loss: -2.526731491088867
Batch 34/64 loss: -2.6295251846313477
Batch 35/64 loss: -2.4253854751586914
Batch 36/64 loss: -2.550045967102051
Batch 37/64 loss: -2.18265438079834
Batch 38/64 loss: -2.7352142333984375
Batch 39/64 loss: -2.856236457824707
Batch 40/64 loss: -2.43475341796875
Batch 41/64 loss: -2.6133832931518555
Batch 42/64 loss: -2.4294443130493164
Batch 43/64 loss: -2.6967334747314453
Batch 44/64 loss: -2.631850242614746
Batch 45/64 loss: -2.654325485229492
Batch 46/64 loss: -2.6141929626464844
Batch 47/64 loss: -2.687755584716797
Batch 48/64 loss: -2.5145645141601562
Batch 49/64 loss: -2.8584327697753906
Batch 50/64 loss: -2.631594657897949
Batch 51/64 loss: -2.820624351501465
Batch 52/64 loss: -2.2895870208740234
Batch 53/64 loss: -2.437009811401367
Batch 54/64 loss: -2.460561752319336
Batch 55/64 loss: -2.5268239974975586
Batch 56/64 loss: -2.659374237060547
Batch 57/64 loss: -2.254300117492676
Batch 58/64 loss: -2.603461265563965
Batch 59/64 loss: -2.7431182861328125
Batch 60/64 loss: -2.834939956665039
Batch 61/64 loss: -2.508443832397461
Batch 62/64 loss: -2.7388381958007812
Batch 63/64 loss: -2.7187156677246094
Batch 64/64 loss: -7.19486141204834
Epoch 238  Train loss: -2.6639633664897846  Val loss: -2.7850983872036754
Epoch 239
-------------------------------
Batch 1/64 loss: -2.7870254516601562
Batch 2/64 loss: -2.6467132568359375
Batch 3/64 loss: -2.5129899978637695
Batch 4/64 loss: -2.3157291412353516
Batch 5/64 loss: -2.7739477157592773
Batch 6/64 loss: -2.656060218811035
Batch 7/64 loss: -2.296306610107422
Batch 8/64 loss: -2.4466466903686523
Batch 9/64 loss: -2.540104866027832
Batch 10/64 loss: -2.5646352767944336
Batch 11/64 loss: -2.3301219940185547
Batch 12/64 loss: -2.862940788269043
Batch 13/64 loss: -2.5802230834960938
Batch 14/64 loss: -2.518252372741699
Batch 15/64 loss: -2.5077896118164062
Batch 16/64 loss: -2.782907485961914
Batch 17/64 loss: -2.272449493408203
Batch 18/64 loss: -2.6887435913085938
Batch 19/64 loss: -2.5224218368530273
Batch 20/64 loss: -2.86025333404541
Batch 21/64 loss: -2.757044792175293
Batch 22/64 loss: -2.5943946838378906
Batch 23/64 loss: -2.454761505126953
Batch 24/64 loss: -2.7620010375976562
Batch 25/64 loss: -2.6483373641967773
Batch 26/64 loss: -2.4934329986572266
Batch 27/64 loss: -2.584909439086914
Batch 28/64 loss: -2.058605194091797
Batch 29/64 loss: -2.5842247009277344
Batch 30/64 loss: -2.6468582153320312
Batch 31/64 loss: -2.4334211349487305
Batch 32/64 loss: -2.198502540588379
Batch 33/64 loss: -2.4121742248535156
Batch 34/64 loss: -2.6270675659179688
Batch 35/64 loss: -2.5518016815185547
Batch 36/64 loss: -2.347262382507324
Batch 37/64 loss: -2.595470428466797
Batch 38/64 loss: -2.2296018600463867
Batch 39/64 loss: -2.4223852157592773
Batch 40/64 loss: -2.6367931365966797
Batch 41/64 loss: -2.6501340866088867
Batch 42/64 loss: -2.3526697158813477
Batch 43/64 loss: -2.186896324157715
Batch 44/64 loss: -2.3268299102783203
Batch 45/64 loss: -2.5679683685302734
Batch 46/64 loss: -2.5290441513061523
Batch 47/64 loss: -2.608126640319824
Batch 48/64 loss: -2.3627824783325195
Batch 49/64 loss: -2.521974563598633
Batch 50/64 loss: -2.312429428100586
Batch 51/64 loss: -2.4343204498291016
Batch 52/64 loss: -2.7055187225341797
Batch 53/64 loss: -2.5764970779418945
Batch 54/64 loss: -2.4821157455444336
Batch 55/64 loss: -2.4089956283569336
Batch 56/64 loss: -2.6094417572021484
Batch 57/64 loss: -2.6277551651000977
Batch 58/64 loss: -2.2892684936523438
Batch 59/64 loss: -2.396913528442383
Batch 60/64 loss: -2.5969228744506836
Batch 61/64 loss: -2.7714805603027344
Batch 62/64 loss: -2.7034435272216797
Batch 63/64 loss: -2.616273880004883
Batch 64/64 loss: -6.990240573883057
Epoch 239  Train loss: -2.5786007282780665  Val loss: -2.627151554802439
Epoch 240
-------------------------------
Batch 1/64 loss: -2.7513046264648438
Batch 2/64 loss: -2.6968603134155273
Batch 3/64 loss: -2.7274351119995117
Batch 4/64 loss: -2.4690914154052734
Batch 5/64 loss: -2.3710336685180664
Batch 6/64 loss: -2.3795671463012695
Batch 7/64 loss: -2.5951642990112305
Batch 8/64 loss: -2.8307981491088867
Batch 9/64 loss: -2.2490711212158203
Batch 10/64 loss: -2.1644229888916016
Batch 11/64 loss: -2.402035713195801
Batch 12/64 loss: -2.154006004333496
Batch 13/64 loss: -2.3436098098754883
Batch 14/64 loss: -2.776765823364258
Batch 15/64 loss: -2.5701656341552734
Batch 16/64 loss: -2.7286062240600586
Batch 17/64 loss: -2.5595455169677734
Batch 18/64 loss: -2.78281307220459
Batch 19/64 loss: -2.3008127212524414
Batch 20/64 loss: -2.6473073959350586
Batch 21/64 loss: -2.554694175720215
Batch 22/64 loss: -2.701261520385742
Batch 23/64 loss: -2.5384693145751953
Batch 24/64 loss: -2.5988054275512695
Batch 25/64 loss: -2.5887451171875
Batch 26/64 loss: -2.3075380325317383
Batch 27/64 loss: -2.6229381561279297
Batch 28/64 loss: -2.586061477661133
Batch 29/64 loss: -2.59512996673584
Batch 30/64 loss: -2.613936424255371
Batch 31/64 loss: -2.6948843002319336
Batch 32/64 loss: -2.319093704223633
Batch 33/64 loss: -2.7426652908325195
Batch 34/64 loss: -2.634479522705078
Batch 35/64 loss: -2.7680816650390625
Batch 36/64 loss: -2.8862876892089844
Batch 37/64 loss: -2.4829063415527344
Batch 38/64 loss: -2.554353713989258
Batch 39/64 loss: -2.5444326400756836
Batch 40/64 loss: -2.6201257705688477
Batch 41/64 loss: -2.76918888092041
Batch 42/64 loss: -2.551464080810547
Batch 43/64 loss: -2.630255699157715
Batch 44/64 loss: -2.6374082565307617
Batch 45/64 loss: -2.63992977142334
Batch 46/64 loss: -2.337553024291992
Batch 47/64 loss: -2.518228530883789
Batch 48/64 loss: -2.349222183227539
Batch 49/64 loss: -2.749002456665039
Batch 50/64 loss: -2.655303955078125
Batch 51/64 loss: -2.5845537185668945
Batch 52/64 loss: -2.512211799621582
Batch 53/64 loss: -2.768460273742676
Batch 54/64 loss: -2.6215524673461914
Batch 55/64 loss: -2.9066152572631836
Batch 56/64 loss: -2.54150390625
Batch 57/64 loss: -2.71066951751709
Batch 58/64 loss: -2.689061164855957
Batch 59/64 loss: -2.495976448059082
Batch 60/64 loss: -2.5618677139282227
Batch 61/64 loss: -2.6771507263183594
Batch 62/64 loss: -2.6305837631225586
Batch 63/64 loss: -2.837322235107422
Batch 64/64 loss: -6.993858814239502
Epoch 240  Train loss: -2.6364829325208476  Val loss: -2.9574295515866624
Epoch 241
-------------------------------
Batch 1/64 loss: -2.837925910949707
Batch 2/64 loss: -2.8106441497802734
Batch 3/64 loss: -2.758265495300293
Batch 4/64 loss: -2.3989858627319336
Batch 5/64 loss: -2.4935302734375
Batch 6/64 loss: -2.5397253036499023
Batch 7/64 loss: -2.106800079345703
Batch 8/64 loss: -2.819695472717285
Batch 9/64 loss: -2.418363571166992
Batch 10/64 loss: -2.8691024780273438
Batch 11/64 loss: -2.7651443481445312
Batch 12/64 loss: -2.604495048522949
Batch 13/64 loss: -2.7837133407592773
Batch 14/64 loss: -2.723194122314453
Batch 15/64 loss: -2.866586685180664
Batch 16/64 loss: -2.7349891662597656
Batch 17/64 loss: -2.5319833755493164
Batch 18/64 loss: -2.754458427429199
Batch 19/64 loss: -2.478856086730957
Batch 20/64 loss: -2.807718276977539
Batch 21/64 loss: -2.7182254791259766
Batch 22/64 loss: -2.657402992248535
Batch 23/64 loss: -2.2986936569213867
Batch 24/64 loss: -2.4856348037719727
Batch 25/64 loss: -2.4078245162963867
Batch 26/64 loss: -2.4830265045166016
Batch 27/64 loss: -2.6144285202026367
Batch 28/64 loss: -2.746962547302246
Batch 29/64 loss: -2.3999156951904297
Batch 30/64 loss: -2.7336254119873047
Batch 31/64 loss: -2.456829071044922
Batch 32/64 loss: -2.4383888244628906
Batch 33/64 loss: -2.629631996154785
Batch 34/64 loss: -2.430609703063965
Batch 35/64 loss: -2.6689939498901367
Batch 36/64 loss: -2.7471933364868164
Batch 37/64 loss: -2.6227893829345703
Batch 38/64 loss: -2.6801633834838867
Batch 39/64 loss: -2.536454200744629
Batch 40/64 loss: -2.324437141418457
Batch 41/64 loss: -2.5476207733154297
Batch 42/64 loss: -2.425715446472168
Batch 43/64 loss: -2.6458396911621094
Batch 44/64 loss: -2.7734375
Batch 45/64 loss: -2.8143348693847656
Batch 46/64 loss: -2.4809370040893555
Batch 47/64 loss: -2.605510711669922
Batch 48/64 loss: -2.598590850830078
Batch 49/64 loss: -2.3030929565429688
Batch 50/64 loss: -2.6523170471191406
Batch 51/64 loss: -2.4516658782958984
Batch 52/64 loss: -2.686579704284668
Batch 53/64 loss: -2.555267333984375
Batch 54/64 loss: -2.8075332641601562
Batch 55/64 loss: -2.752346992492676
Batch 56/64 loss: -2.586742401123047
Batch 57/64 loss: -2.8612327575683594
Batch 58/64 loss: -2.563690185546875
Batch 59/64 loss: -2.573367118835449
Batch 60/64 loss: -2.312755584716797
Batch 61/64 loss: -2.595050811767578
Batch 62/64 loss: -2.6437206268310547
Batch 63/64 loss: -2.496706962585449
Batch 64/64 loss: -7.058897972106934
Epoch 241  Train loss: -2.654331585005218  Val loss: -2.93668487391521
Epoch 242
-------------------------------
Batch 1/64 loss: -2.3708620071411133
Batch 2/64 loss: -2.7303810119628906
Batch 3/64 loss: -2.628854751586914
Batch 4/64 loss: -2.562314033508301
Batch 5/64 loss: -2.354994773864746
Batch 6/64 loss: -2.6570816040039062
Batch 7/64 loss: -2.4517393112182617
Batch 8/64 loss: -2.6378393173217773
Batch 9/64 loss: -2.684255599975586
Batch 10/64 loss: -2.6409711837768555
Batch 11/64 loss: -2.5959396362304688
Batch 12/64 loss: -2.587327003479004
Batch 13/64 loss: -2.6390199661254883
Batch 14/64 loss: -2.599302291870117
Batch 15/64 loss: -2.556828498840332
Batch 16/64 loss: -2.5098390579223633
Batch 17/64 loss: -2.5267372131347656
Batch 18/64 loss: -2.741885185241699
Batch 19/64 loss: -2.581592559814453
Batch 20/64 loss: -2.8848142623901367
Batch 21/64 loss: -2.71096134185791
Batch 22/64 loss: -2.817096710205078
Batch 23/64 loss: -2.6098384857177734
Batch 24/64 loss: -2.4853477478027344
Batch 25/64 loss: -2.7057275772094727
Batch 26/64 loss: -2.664287567138672
Batch 27/64 loss: -2.3560848236083984
Batch 28/64 loss: -2.6324501037597656
Batch 29/64 loss: -2.6192169189453125
Batch 30/64 loss: -2.583451271057129
Batch 31/64 loss: -2.702803611755371
Batch 32/64 loss: -2.743562698364258
Batch 33/64 loss: -2.6093626022338867
Batch 34/64 loss: -2.600473403930664
Batch 35/64 loss: -2.5325660705566406
Batch 36/64 loss: -2.626967430114746
Batch 37/64 loss: -2.2486886978149414
Batch 38/64 loss: -2.65286922454834
Batch 39/64 loss: -2.6603317260742188
Batch 40/64 loss: -2.9216575622558594
Batch 41/64 loss: -2.3564023971557617
Batch 42/64 loss: -2.5566043853759766
Batch 43/64 loss: -2.543118476867676
Batch 44/64 loss: -2.7905988693237305
Batch 45/64 loss: -2.449244499206543
Batch 46/64 loss: -2.6723928451538086
Batch 47/64 loss: -2.7153759002685547
Batch 48/64 loss: -2.278656005859375
Batch 49/64 loss: -2.3422069549560547
Batch 50/64 loss: -2.663516044616699
Batch 51/64 loss: -2.4861831665039062
Batch 52/64 loss: -2.232346534729004
Batch 53/64 loss: -2.738032341003418
Batch 54/64 loss: -2.831536293029785
Batch 55/64 loss: -2.4796857833862305
Batch 56/64 loss: -2.6690244674682617
Batch 57/64 loss: -2.4326562881469727
Batch 58/64 loss: -2.8163070678710938
Batch 59/64 loss: -2.7986059188842773
Batch 60/64 loss: -2.637044906616211
Batch 61/64 loss: -2.5936756134033203
Batch 62/64 loss: -2.7602720260620117
Batch 63/64 loss: -2.7969560623168945
Batch 64/64 loss: -7.21818208694458
Epoch 242  Train loss: -2.65851614521999  Val loss: -2.867587938341488
Epoch 243
-------------------------------
Batch 1/64 loss: -2.6843366622924805
Batch 2/64 loss: -2.4384498596191406
Batch 3/64 loss: -2.6678714752197266
Batch 4/64 loss: -2.2722597122192383
Batch 5/64 loss: -2.293828010559082
Batch 6/64 loss: -2.6023712158203125
Batch 7/64 loss: -2.3552846908569336
Batch 8/64 loss: -2.6113014221191406
Batch 9/64 loss: -2.672694206237793
Batch 10/64 loss: -2.377800941467285
Batch 11/64 loss: -2.5654706954956055
Batch 12/64 loss: -2.4608707427978516
Batch 13/64 loss: -2.6296510696411133
Batch 14/64 loss: -2.6555776596069336
Batch 15/64 loss: -2.4703311920166016
Batch 16/64 loss: -2.7494258880615234
Batch 17/64 loss: -2.6247243881225586
Batch 18/64 loss: -2.714174270629883
Batch 19/64 loss: -2.720486640930176
Batch 20/64 loss: -2.5880203247070312
Batch 21/64 loss: -2.405470848083496
Batch 22/64 loss: -2.670938491821289
Batch 23/64 loss: -2.7817821502685547
Batch 24/64 loss: -2.810853958129883
Batch 25/64 loss: -2.6637563705444336
Batch 26/64 loss: -2.6685380935668945
Batch 27/64 loss: -2.779256820678711
Batch 28/64 loss: -2.1755456924438477
Batch 29/64 loss: -2.7810916900634766
Batch 30/64 loss: -2.607844352722168
Batch 31/64 loss: -2.61881160736084
Batch 32/64 loss: -2.669168472290039
Batch 33/64 loss: -2.8994007110595703
Batch 34/64 loss: -2.5878381729125977
Batch 35/64 loss: -2.7903404235839844
Batch 36/64 loss: -2.804720878601074
Batch 37/64 loss: -2.2645606994628906
Batch 38/64 loss: -2.487471580505371
Batch 39/64 loss: -2.6575822830200195
Batch 40/64 loss: -2.7496604919433594
Batch 41/64 loss: -2.6038742065429688
Batch 42/64 loss: -2.188882827758789
Batch 43/64 loss: -2.1495561599731445
Batch 44/64 loss: -2.4580955505371094
Batch 45/64 loss: -2.353212356567383
Batch 46/64 loss: -2.5562686920166016
Batch 47/64 loss: -2.5562477111816406
Batch 48/64 loss: -2.75197696685791
Batch 49/64 loss: -2.577333450317383
Batch 50/64 loss: -2.6666221618652344
Batch 51/64 loss: -2.49777889251709
Batch 52/64 loss: -2.8432769775390625
Batch 53/64 loss: -2.5500965118408203
Batch 54/64 loss: -2.569599151611328
Batch 55/64 loss: -2.4344778060913086
Batch 56/64 loss: -2.4429492950439453
Batch 57/64 loss: -2.7470340728759766
Batch 58/64 loss: -2.552262306213379
Batch 59/64 loss: -2.576953887939453
Batch 60/64 loss: -2.5601882934570312
Batch 61/64 loss: -2.6317129135131836
Batch 62/64 loss: -2.464024543762207
Batch 63/64 loss: -2.678945541381836
Batch 64/64 loss: -6.831030368804932
Epoch 243  Train loss: -2.628458163317512  Val loss: -2.933070349939091
Epoch 244
-------------------------------
Batch 1/64 loss: -2.293717384338379
Batch 2/64 loss: -2.6729116439819336
Batch 3/64 loss: -2.7128219604492188
Batch 4/64 loss: -2.712508201599121
Batch 5/64 loss: -2.607560157775879
Batch 6/64 loss: -2.750248908996582
Batch 7/64 loss: -2.641299247741699
Batch 8/64 loss: -2.5807456970214844
Batch 9/64 loss: -2.3170108795166016
Batch 10/64 loss: -2.845212936401367
Batch 11/64 loss: -2.8036813735961914
Batch 12/64 loss: -2.7739133834838867
Batch 13/64 loss: -2.6302642822265625
Batch 14/64 loss: -2.6133689880371094
Batch 15/64 loss: -2.2299861907958984
Batch 16/64 loss: -2.7762928009033203
Batch 17/64 loss: -2.653301239013672
Batch 18/64 loss: -2.736708641052246
Batch 19/64 loss: -2.45052433013916
Batch 20/64 loss: -2.4384965896606445
Batch 21/64 loss: -2.481938362121582
Batch 22/64 loss: -2.9379348754882812
Batch 23/64 loss: -2.786487579345703
Batch 24/64 loss: -2.592373847961426
Batch 25/64 loss: -2.8223915100097656
Batch 26/64 loss: -2.664480209350586
Batch 27/64 loss: -2.53936767578125
Batch 28/64 loss: -2.7424564361572266
Batch 29/64 loss: -2.4048643112182617
Batch 30/64 loss: -2.685962677001953
Batch 31/64 loss: -2.4649972915649414
Batch 32/64 loss: -2.475606918334961
Batch 33/64 loss: -2.605923652648926
Batch 34/64 loss: -2.2616682052612305
Batch 35/64 loss: -2.652043342590332
Batch 36/64 loss: -2.703113555908203
Batch 37/64 loss: -2.844597816467285
Batch 38/64 loss: -2.3333215713500977
Batch 39/64 loss: -2.897493362426758
Batch 40/64 loss: -2.6395416259765625
Batch 41/64 loss: -2.4500646591186523
Batch 42/64 loss: -2.6043319702148438
Batch 43/64 loss: -2.7363576889038086
Batch 44/64 loss: -2.4235172271728516
Batch 45/64 loss: -2.373628616333008
Batch 46/64 loss: -2.491191864013672
Batch 47/64 loss: -2.6070470809936523
Batch 48/64 loss: -2.698850631713867
Batch 49/64 loss: -2.8333005905151367
Batch 50/64 loss: -2.687373161315918
Batch 51/64 loss: -2.4148378372192383
Batch 52/64 loss: -2.736988067626953
Batch 53/64 loss: -2.6448144912719727
Batch 54/64 loss: -2.2206192016601562
Batch 55/64 loss: -2.58273983001709
Batch 56/64 loss: -2.724416732788086
Batch 57/64 loss: -2.7450265884399414
Batch 58/64 loss: -2.480121612548828
Batch 59/64 loss: -2.629911422729492
Batch 60/64 loss: -2.1723756790161133
Batch 61/64 loss: -2.7159061431884766
Batch 62/64 loss: -2.6660985946655273
Batch 63/64 loss: -2.5132579803466797
Batch 64/64 loss: -7.118344306945801
Epoch 244  Train loss: -2.655194910834817  Val loss: -2.8287193455646946
Epoch 245
-------------------------------
Batch 1/64 loss: -2.6129350662231445
Batch 2/64 loss: -2.7254638671875
Batch 3/64 loss: -2.4163427352905273
Batch 4/64 loss: -2.719719886779785
Batch 5/64 loss: -2.5511226654052734
Batch 6/64 loss: -2.7964649200439453
Batch 7/64 loss: -2.6015987396240234
Batch 8/64 loss: -2.659510612487793
Batch 9/64 loss: -2.437631607055664
Batch 10/64 loss: -2.4465789794921875
Batch 11/64 loss: -2.687652587890625
Batch 12/64 loss: -2.315117835998535
Batch 13/64 loss: -2.506258964538574
Batch 14/64 loss: -2.7047624588012695
Batch 15/64 loss: -2.5887069702148438
Batch 16/64 loss: -2.74825382232666
Batch 17/64 loss: -2.2400741577148438
Batch 18/64 loss: -2.7026166915893555
Batch 19/64 loss: -2.612213134765625
Batch 20/64 loss: -2.583817481994629
Batch 21/64 loss: -2.182231903076172
Batch 22/64 loss: -2.6484336853027344
Batch 23/64 loss: -2.5253915786743164
Batch 24/64 loss: -2.7209653854370117
Batch 25/64 loss: -2.486703872680664
Batch 26/64 loss: -2.521575927734375
Batch 27/64 loss: -2.8304691314697266
Batch 28/64 loss: -2.118863105773926
Batch 29/64 loss: -2.791240692138672
Batch 30/64 loss: -2.5514631271362305
Batch 31/64 loss: -2.652423858642578
Batch 32/64 loss: -2.723507881164551
Batch 33/64 loss: -2.67327880859375
Batch 34/64 loss: -2.660442352294922
Batch 35/64 loss: -2.3762893676757812
Batch 36/64 loss: -2.670124053955078
Batch 37/64 loss: -2.7057113647460938
Batch 38/64 loss: -2.7820358276367188
Batch 39/64 loss: -2.7343530654907227
Batch 40/64 loss: -2.6868133544921875
Batch 41/64 loss: -2.3694372177124023
Batch 42/64 loss: -2.6094894409179688
Batch 43/64 loss: -2.6083154678344727
Batch 44/64 loss: -2.9056529998779297
Batch 45/64 loss: -2.345992088317871
Batch 46/64 loss: -2.5648727416992188
Batch 47/64 loss: -2.6447792053222656
Batch 48/64 loss: -2.1794586181640625
Batch 49/64 loss: -2.771672248840332
Batch 50/64 loss: -2.6763057708740234
Batch 51/64 loss: -2.794344902038574
Batch 52/64 loss: -2.7715625762939453
Batch 53/64 loss: -2.713921546936035
Batch 54/64 loss: -2.6723222732543945
Batch 55/64 loss: -2.8049964904785156
Batch 56/64 loss: -2.5892391204833984
Batch 57/64 loss: -2.554668426513672
Batch 58/64 loss: -2.5778350830078125
Batch 59/64 loss: -2.1968793869018555
Batch 60/64 loss: -2.545490264892578
Batch 61/64 loss: -2.339097023010254
Batch 62/64 loss: -2.3409690856933594
Batch 63/64 loss: -2.369473457336426
Batch 64/64 loss: -7.1782660484313965
Epoch 245  Train loss: -2.6357590039571126  Val loss: -2.932184933796781
Epoch 246
-------------------------------
Batch 1/64 loss: -2.7122182846069336
Batch 2/64 loss: -2.703131675720215
Batch 3/64 loss: -2.593897819519043
Batch 4/64 loss: -2.787611961364746
Batch 5/64 loss: -2.6336374282836914
Batch 6/64 loss: -2.2155447006225586
Batch 7/64 loss: -2.850520133972168
Batch 8/64 loss: -2.775111198425293
Batch 9/64 loss: -2.511974334716797
Batch 10/64 loss: -2.392756462097168
Batch 11/64 loss: -2.632817268371582
Batch 12/64 loss: -2.0891761779785156
Batch 13/64 loss: -2.5969362258911133
Batch 14/64 loss: -2.4503984451293945
Batch 15/64 loss: -2.662102699279785
Batch 16/64 loss: -2.584364891052246
Batch 17/64 loss: -2.485198974609375
Batch 18/64 loss: -2.438302993774414
Batch 19/64 loss: -2.568202018737793
Batch 20/64 loss: -2.441758155822754
Batch 21/64 loss: -2.5899810791015625
Batch 22/64 loss: -2.5552425384521484
Batch 23/64 loss: -2.7813711166381836
Batch 24/64 loss: -2.73111629486084
Batch 25/64 loss: -2.610968589782715
Batch 26/64 loss: -2.450058937072754
Batch 27/64 loss: -2.7639474868774414
Batch 28/64 loss: -2.570723533630371
Batch 29/64 loss: -2.6571226119995117
Batch 30/64 loss: -2.380671501159668
Batch 31/64 loss: -2.6358346939086914
Batch 32/64 loss: -2.6330699920654297
Batch 33/64 loss: -2.5279979705810547
Batch 34/64 loss: -2.662250518798828
Batch 35/64 loss: -2.6280527114868164
Batch 36/64 loss: -2.764622688293457
Batch 37/64 loss: -2.733668327331543
Batch 38/64 loss: -2.632351875305176
Batch 39/64 loss: -2.7374401092529297
Batch 40/64 loss: -2.453765869140625
Batch 41/64 loss: -2.7219676971435547
Batch 42/64 loss: -2.899293899536133
Batch 43/64 loss: -2.7458362579345703
Batch 44/64 loss: -2.7349939346313477
Batch 45/64 loss: -2.7381715774536133
Batch 46/64 loss: -2.850252151489258
Batch 47/64 loss: -2.426267623901367
Batch 48/64 loss: -2.568561553955078
Batch 49/64 loss: -2.461261749267578
Batch 50/64 loss: -2.7818708419799805
Batch 51/64 loss: -2.709273338317871
Batch 52/64 loss: -2.5788183212280273
Batch 53/64 loss: -2.6894378662109375
Batch 54/64 loss: -2.7777538299560547
Batch 55/64 loss: -2.673961639404297
Batch 56/64 loss: -2.580904960632324
Batch 57/64 loss: -2.565300941467285
Batch 58/64 loss: -2.8036956787109375
Batch 59/64 loss: -2.8774681091308594
Batch 60/64 loss: -2.8331708908081055
Batch 61/64 loss: -2.8329105377197266
Batch 62/64 loss: -2.6796875
Batch 63/64 loss: -2.4607629776000977
Batch 64/64 loss: -7.048816680908203
Epoch 246  Train loss: -2.6808495166254978  Val loss: -2.978358435876591
Epoch 247
-------------------------------
Batch 1/64 loss: -2.7555007934570312
Batch 2/64 loss: -2.4711036682128906
Batch 3/64 loss: -2.812664031982422
Batch 4/64 loss: -2.462679862976074
Batch 5/64 loss: -2.607187271118164
Batch 6/64 loss: -2.580333709716797
Batch 7/64 loss: -2.820326805114746
Batch 8/64 loss: -2.5109472274780273
Batch 9/64 loss: -2.659604072570801
Batch 10/64 loss: -2.7546911239624023
Batch 11/64 loss: -2.504640579223633
Batch 12/64 loss: -2.511795997619629
Batch 13/64 loss: -2.2019786834716797
Batch 14/64 loss: -2.499606132507324
Batch 15/64 loss: -2.517854690551758
Batch 16/64 loss: -2.384963035583496
Batch 17/64 loss: -2.4815902709960938
Batch 18/64 loss: -2.368014335632324
Batch 19/64 loss: -2.5301151275634766
Batch 20/64 loss: -2.5501089096069336
Batch 21/64 loss: -2.704540252685547
Batch 22/64 loss: -2.5292444229125977
Batch 23/64 loss: -2.43411922454834
Batch 24/64 loss: -2.7468671798706055
Batch 25/64 loss: -2.5644731521606445
Batch 26/64 loss: -2.582310676574707
Batch 27/64 loss: -2.797987937927246
Batch 28/64 loss: -2.820441246032715
Batch 29/64 loss: -2.6871213912963867
Batch 30/64 loss: -2.6699161529541016
Batch 31/64 loss: -2.669178009033203
Batch 32/64 loss: -2.759793281555176
Batch 33/64 loss: -2.602646827697754
Batch 34/64 loss: -2.740595817565918
Batch 35/64 loss: -2.632359504699707
Batch 36/64 loss: -2.633197784423828
Batch 37/64 loss: -2.7569923400878906
Batch 38/64 loss: -2.7246551513671875
Batch 39/64 loss: -2.741438865661621
Batch 40/64 loss: -2.4313201904296875
Batch 41/64 loss: -2.778496742248535
Batch 42/64 loss: -2.5306577682495117
Batch 43/64 loss: -2.4362173080444336
Batch 44/64 loss: -2.8447132110595703
Batch 45/64 loss: -2.54642391204834
Batch 46/64 loss: -2.599209785461426
Batch 47/64 loss: -2.6469497680664062
Batch 48/64 loss: -2.55342960357666
Batch 49/64 loss: -2.627605438232422
Batch 50/64 loss: -2.6159420013427734
Batch 51/64 loss: -2.5460052490234375
Batch 52/64 loss: -2.4980239868164062
Batch 53/64 loss: -2.717625617980957
Batch 54/64 loss: -2.7798080444335938
Batch 55/64 loss: -2.760739326477051
Batch 56/64 loss: -2.727750778198242
Batch 57/64 loss: -2.720015525817871
Batch 58/64 loss: -2.4549341201782227
Batch 59/64 loss: -2.4801244735717773
Batch 60/64 loss: -2.530061721801758
Batch 61/64 loss: -2.8704099655151367
Batch 62/64 loss: -2.61163330078125
Batch 63/64 loss: -2.8074159622192383
Batch 64/64 loss: -7.266485691070557
Epoch 247  Train loss: -2.6721406057769177  Val loss: -2.902977933588716
Epoch 248
-------------------------------
Batch 1/64 loss: -2.798110008239746
Batch 2/64 loss: -2.821949005126953
Batch 3/64 loss: -2.539773941040039
Batch 4/64 loss: -2.709077835083008
Batch 5/64 loss: -2.3995418548583984
Batch 6/64 loss: -2.5362300872802734
Batch 7/64 loss: -2.742814064025879
Batch 8/64 loss: -2.6625452041625977
Batch 9/64 loss: -2.7840518951416016
Batch 10/64 loss: -2.231100082397461
Batch 11/64 loss: -2.8414106369018555
Batch 12/64 loss: -2.6870040893554688
Batch 13/64 loss: -2.842362403869629
Batch 14/64 loss: -2.6097030639648438
Batch 15/64 loss: -2.463934898376465
Batch 16/64 loss: -2.649561882019043
Batch 17/64 loss: -2.8611297607421875
Batch 18/64 loss: -2.5082216262817383
Batch 19/64 loss: -2.6637954711914062
Batch 20/64 loss: -2.830430030822754
Batch 21/64 loss: -2.545886993408203
Batch 22/64 loss: -2.2030725479125977
Batch 23/64 loss: -2.61704158782959
Batch 24/64 loss: -2.6126937866210938
Batch 25/64 loss: -2.5600461959838867
Batch 26/64 loss: -2.7364912033081055
Batch 27/64 loss: -2.582082748413086
Batch 28/64 loss: -2.6750431060791016
Batch 29/64 loss: -2.4028167724609375
Batch 30/64 loss: -2.8594131469726562
Batch 31/64 loss: -2.7615270614624023
Batch 32/64 loss: -2.455164909362793
Batch 33/64 loss: -2.399876594543457
Batch 34/64 loss: -2.5570554733276367
Batch 35/64 loss: -2.738642692565918
Batch 36/64 loss: -2.4221038818359375
Batch 37/64 loss: -2.845743179321289
Batch 38/64 loss: -2.612710952758789
Batch 39/64 loss: -2.8700971603393555
Batch 40/64 loss: -2.715996742248535
Batch 41/64 loss: -2.627748489379883
Batch 42/64 loss: -2.796442985534668
Batch 43/64 loss: -2.7494611740112305
Batch 44/64 loss: -2.7014169692993164
Batch 45/64 loss: -2.81374454498291
Batch 46/64 loss: -2.5779266357421875
Batch 47/64 loss: -2.4498233795166016
Batch 48/64 loss: -2.564337730407715
Batch 49/64 loss: -2.5400266647338867
Batch 50/64 loss: -2.9876604080200195
Batch 51/64 loss: -2.7370986938476562
Batch 52/64 loss: -2.511892318725586
Batch 53/64 loss: -2.6941146850585938
Batch 54/64 loss: -2.6557979583740234
Batch 55/64 loss: -2.4687910079956055
Batch 56/64 loss: -2.7964515686035156
Batch 57/64 loss: -2.7347192764282227
Batch 58/64 loss: -2.6917572021484375
Batch 59/64 loss: -2.5604772567749023
Batch 60/64 loss: -2.3689823150634766
Batch 61/64 loss: -2.853361129760742
Batch 62/64 loss: -2.5561752319335938
Batch 63/64 loss: -2.5811328887939453
Batch 64/64 loss: -6.301747798919678
Epoch 248  Train loss: -2.6839514657562855  Val loss: -2.9137125179120353
Epoch 249
-------------------------------
Batch 1/64 loss: -2.4793920516967773
Batch 2/64 loss: -2.5792598724365234
Batch 3/64 loss: -2.70035457611084
Batch 4/64 loss: -2.6916685104370117
Batch 5/64 loss: -2.4668970108032227
Batch 6/64 loss: -2.643810272216797
Batch 7/64 loss: -2.631502151489258
Batch 8/64 loss: -2.7549819946289062
Batch 9/64 loss: -2.716043472290039
Batch 10/64 loss: -2.700209617614746
Batch 11/64 loss: -2.3921165466308594
Batch 12/64 loss: -2.845256805419922
Batch 13/64 loss: -2.7547645568847656
Batch 14/64 loss: -2.3795318603515625
Batch 15/64 loss: -2.836827278137207
Batch 16/64 loss: -2.5059385299682617
Batch 17/64 loss: -2.5345239639282227
Batch 18/64 loss: -2.7433977127075195
Batch 19/64 loss: -2.6446332931518555
Batch 20/64 loss: -2.73947811126709
Batch 21/64 loss: -2.670283317565918
Batch 22/64 loss: -2.6843461990356445
Batch 23/64 loss: -2.7125625610351562
Batch 24/64 loss: -2.447798728942871
Batch 25/64 loss: -2.916609764099121
Batch 26/64 loss: -2.7048959732055664
Batch 27/64 loss: -2.364818572998047
Batch 28/64 loss: -2.7476987838745117
Batch 29/64 loss: -2.6668596267700195
Batch 30/64 loss: -2.7372798919677734
Batch 31/64 loss: -2.816455841064453
Batch 32/64 loss: -2.785403251647949
Batch 33/64 loss: -2.528397560119629
Batch 34/64 loss: -2.76479434967041
Batch 35/64 loss: -2.5854978561401367
Batch 36/64 loss: -2.61403751373291
Batch 37/64 loss: -2.6067447662353516
Batch 38/64 loss: -2.7000732421875
Batch 39/64 loss: -2.590831756591797
Batch 40/64 loss: -2.853734016418457
Batch 41/64 loss: -2.584111213684082
Batch 42/64 loss: -2.5291614532470703
Batch 43/64 loss: -2.79642391204834
Batch 44/64 loss: -2.3520612716674805
Batch 45/64 loss: -2.1574792861938477
Batch 46/64 loss: -2.7300024032592773
Batch 47/64 loss: -2.5711212158203125
Batch 48/64 loss: -2.3614330291748047
Batch 49/64 loss: -2.8030481338500977
Batch 50/64 loss: -2.4408693313598633
Batch 51/64 loss: -2.7800168991088867
Batch 52/64 loss: -2.843691825866699
Batch 53/64 loss: -2.6727170944213867
Batch 54/64 loss: -2.5360469818115234
Batch 55/64 loss: -2.384632110595703
Batch 56/64 loss: -2.7224769592285156
Batch 57/64 loss: -2.4013547897338867
Batch 58/64 loss: -2.7952985763549805
Batch 59/64 loss: -2.7005748748779297
Batch 60/64 loss: -2.8237829208374023
Batch 61/64 loss: -2.5596485137939453
Batch 62/64 loss: -2.2240991592407227
Batch 63/64 loss: -2.667509078979492
Batch 64/64 loss: -7.349947452545166
Epoch 249  Train loss: -2.6853291511535646  Val loss: -2.7994940452968953
Epoch 250
-------------------------------
Batch 1/64 loss: -2.345269203186035
Batch 2/64 loss: -2.7861766815185547
Batch 3/64 loss: -2.613780975341797
Batch 4/64 loss: -2.4006214141845703
Batch 5/64 loss: -2.58740234375
Batch 6/64 loss: -2.7252588272094727
Batch 7/64 loss: -2.66475772857666
Batch 8/64 loss: -2.597723960876465
Batch 9/64 loss: -2.692244529724121
Batch 10/64 loss: -2.404799461364746
Batch 11/64 loss: -2.58719539642334
Batch 12/64 loss: -2.6724605560302734
Batch 13/64 loss: -2.817509651184082
Batch 14/64 loss: -2.4586849212646484
Batch 15/64 loss: -2.6789464950561523
Batch 16/64 loss: -2.6330432891845703
Batch 17/64 loss: -2.8256759643554688
Batch 18/64 loss: -2.69161319732666
Batch 19/64 loss: -2.7328014373779297
Batch 20/64 loss: -2.4678144454956055
Batch 21/64 loss: -2.7271690368652344
Batch 22/64 loss: -2.7314529418945312
Batch 23/64 loss: -2.476957321166992
Batch 24/64 loss: -2.5306692123413086
Batch 25/64 loss: -2.506380081176758
Batch 26/64 loss: -2.7531538009643555
Batch 27/64 loss: -2.618804931640625
Batch 28/64 loss: -2.7110605239868164
Batch 29/64 loss: -2.6009960174560547
Batch 30/64 loss: -2.757195472717285
Batch 31/64 loss: -2.82570743560791
Batch 32/64 loss: -2.6069679260253906
Batch 33/64 loss: -2.8058557510375977
Batch 34/64 loss: -2.4340906143188477
Batch 35/64 loss: -2.7228851318359375
Batch 36/64 loss: -2.550686836242676
Batch 37/64 loss: -2.563966751098633
Batch 38/64 loss: -2.9611120223999023
Batch 39/64 loss: -2.773378372192383
Batch 40/64 loss: -2.7915029525756836
Batch 41/64 loss: -2.7324914932250977
Batch 42/64 loss: -2.52474308013916
Batch 43/64 loss: -2.731565475463867
Batch 44/64 loss: -2.6824207305908203
Batch 45/64 loss: -2.412379264831543
Batch 46/64 loss: -2.6526737213134766
Batch 47/64 loss: -2.521639823913574
Batch 48/64 loss: -2.726655960083008
Batch 49/64 loss: -2.92739200592041
Batch 50/64 loss: -2.4256210327148438
Batch 51/64 loss: -2.7220420837402344
Batch 52/64 loss: -2.5807266235351562
Batch 53/64 loss: -2.757512092590332
Batch 54/64 loss: -2.6669530868530273
Batch 55/64 loss: -2.5722904205322266
Batch 56/64 loss: -2.725048065185547
Batch 57/64 loss: -2.3368988037109375
Batch 58/64 loss: -2.6571788787841797
Batch 59/64 loss: -2.7645702362060547
Batch 60/64 loss: -2.686093330383301
Batch 61/64 loss: -2.560940742492676
Batch 62/64 loss: -2.8672075271606445
Batch 63/64 loss: -2.7772293090820312
Batch 64/64 loss: -7.292128086090088
Epoch 250  Train loss: -2.7029826426038555  Val loss: -2.922702225622852
Epoch 251
-------------------------------
Batch 1/64 loss: -2.8877458572387695
Batch 2/64 loss: -2.19210147857666
Batch 3/64 loss: -2.6475563049316406
Batch 4/64 loss: -2.573214530944824
Batch 5/64 loss: -2.7455196380615234
Batch 6/64 loss: -2.5664920806884766
Batch 7/64 loss: -2.5690927505493164
Batch 8/64 loss: -2.8687944412231445
Batch 9/64 loss: -2.6140642166137695
Batch 10/64 loss: -2.7181873321533203
Batch 11/64 loss: -2.8043136596679688
Batch 12/64 loss: -2.6947574615478516
Batch 13/64 loss: -2.853364944458008
Batch 14/64 loss: -2.6585655212402344
Batch 15/64 loss: -2.852768898010254
Batch 16/64 loss: -2.7463884353637695
Batch 17/64 loss: -2.917452812194824
Batch 18/64 loss: -2.6861696243286133
Batch 19/64 loss: -2.826596260070801
Batch 20/64 loss: -2.5156373977661133
Batch 21/64 loss: -2.94586181640625
Batch 22/64 loss: -2.4846153259277344
Batch 23/64 loss: -2.8183469772338867
Batch 24/64 loss: -2.629441261291504
Batch 25/64 loss: -2.428537368774414
Batch 26/64 loss: -2.8794384002685547
Batch 27/64 loss: -2.3960304260253906
Batch 28/64 loss: -2.547154426574707
Batch 29/64 loss: -2.7796802520751953
Batch 30/64 loss: -2.561215400695801
Batch 31/64 loss: -2.4096803665161133
Batch 32/64 loss: -2.5989809036254883
Batch 33/64 loss: -2.6950292587280273
Batch 34/64 loss: -2.578871726989746
Batch 35/64 loss: -2.6882619857788086
Batch 36/64 loss: -2.7503013610839844
Batch 37/64 loss: -2.642293930053711
Batch 38/64 loss: -2.5337562561035156
Batch 39/64 loss: -2.668651580810547
Batch 40/64 loss: -2.7806806564331055
Batch 41/64 loss: -2.4440393447875977
Batch 42/64 loss: -2.787081718444824
Batch 43/64 loss: -2.438382148742676
Batch 44/64 loss: -2.6477441787719727
Batch 45/64 loss: -2.58756160736084
Batch 46/64 loss: -2.4249868392944336
Batch 47/64 loss: -2.7273244857788086
Batch 48/64 loss: -2.8505868911743164
Batch 49/64 loss: -2.7093887329101562
Batch 50/64 loss: -2.3166418075561523
Batch 51/64 loss: -2.6875438690185547
Batch 52/64 loss: -2.836848258972168
Batch 53/64 loss: -2.738140106201172
Batch 54/64 loss: -2.541266441345215
Batch 55/64 loss: -2.653874397277832
Batch 56/64 loss: -2.638455390930176
Batch 57/64 loss: -2.505586624145508
Batch 58/64 loss: -2.6333770751953125
Batch 59/64 loss: -2.805173873901367
Batch 60/64 loss: -2.666651725769043
Batch 61/64 loss: -2.770479202270508
Batch 62/64 loss: -2.488541603088379
Batch 63/64 loss: -2.765133857727051
Batch 64/64 loss: -7.320042610168457
Epoch 251  Train loss: -2.7123208700441848  Val loss: -2.8107653090224645
Epoch 252
-------------------------------
Batch 1/64 loss: -2.7834672927856445
Batch 2/64 loss: -2.654757499694824
Batch 3/64 loss: -2.5826311111450195
Batch 4/64 loss: -2.6604385375976562
Batch 5/64 loss: -2.8219738006591797
Batch 6/64 loss: -2.8037824630737305
Batch 7/64 loss: -2.810270309448242
Batch 8/64 loss: -2.851515769958496
Batch 9/64 loss: -2.651638984680176
Batch 10/64 loss: -2.521439552307129
Batch 11/64 loss: -2.4880123138427734
Batch 12/64 loss: -2.7779035568237305
Batch 13/64 loss: -2.8941736221313477
Batch 14/64 loss: -2.9029884338378906
Batch 15/64 loss: -2.802875518798828
Batch 16/64 loss: -2.5495338439941406
Batch 17/64 loss: -2.538890838623047
Batch 18/64 loss: -2.6401166915893555
Batch 19/64 loss: -2.7616405487060547
Batch 20/64 loss: -2.7030792236328125
Batch 21/64 loss: -2.8449220657348633
Batch 22/64 loss: -2.8740034103393555
Batch 23/64 loss: -2.7138071060180664
Batch 24/64 loss: -2.8393802642822266
Batch 25/64 loss: -2.428816795349121
Batch 26/64 loss: -2.755146026611328
Batch 27/64 loss: -2.6293725967407227
Batch 28/64 loss: -2.567030906677246
Batch 29/64 loss: -2.7256460189819336
Batch 30/64 loss: -2.778477668762207
Batch 31/64 loss: -2.4047117233276367
Batch 32/64 loss: -2.605719566345215
Batch 33/64 loss: -2.7071218490600586
Batch 34/64 loss: -2.757866859436035
Batch 35/64 loss: -2.7116498947143555
Batch 36/64 loss: -2.4099998474121094
Batch 37/64 loss: -2.773906707763672
Batch 38/64 loss: -2.6826486587524414
Batch 39/64 loss: -2.7196388244628906
Batch 40/64 loss: -2.6675682067871094
Batch 41/64 loss: -2.526752471923828
Batch 42/64 loss: -2.6790895462036133
Batch 43/64 loss: -2.41473388671875
Batch 44/64 loss: -2.4397201538085938
Batch 45/64 loss: -2.5235719680786133
Batch 46/64 loss: -2.4762325286865234
Batch 47/64 loss: -2.7815780639648438
Batch 48/64 loss: -2.5469589233398438
Batch 49/64 loss: -2.536165237426758
Batch 50/64 loss: -2.9047603607177734
Batch 51/64 loss: -2.615973472595215
Batch 52/64 loss: -2.796520233154297
Batch 53/64 loss: -2.9558000564575195
Batch 54/64 loss: -2.5909433364868164
Batch 55/64 loss: -2.7527685165405273
Batch 56/64 loss: -2.8113632202148438
Batch 57/64 loss: -2.8526124954223633
Batch 58/64 loss: -2.851546287536621
Batch 59/64 loss: -2.7025442123413086
Batch 60/64 loss: -2.252899169921875
Batch 61/64 loss: -2.5945959091186523
Batch 62/64 loss: -2.733353614807129
Batch 63/64 loss: -2.7509593963623047
Batch 64/64 loss: -6.833944320678711
Epoch 252  Train loss: -2.7296543719721775  Val loss: -2.8389359831400345
Epoch 253
-------------------------------
Batch 1/64 loss: -2.5038747787475586
Batch 2/64 loss: -2.9027156829833984
Batch 3/64 loss: -2.8115291595458984
Batch 4/64 loss: -2.47946834564209
Batch 5/64 loss: -2.351181983947754
Batch 6/64 loss: -2.3189449310302734
Batch 7/64 loss: -2.5956668853759766
Batch 8/64 loss: -2.6407766342163086
Batch 9/64 loss: -2.6557159423828125
Batch 10/64 loss: -2.1973562240600586
Batch 11/64 loss: -2.6567535400390625
Batch 12/64 loss: -2.5774383544921875
Batch 13/64 loss: -2.720517158508301
Batch 14/64 loss: -2.8353500366210938
Batch 15/64 loss: -2.5063772201538086
Batch 16/64 loss: -2.572869300842285
Batch 17/64 loss: -2.468264579772949
Batch 18/64 loss: -2.712911605834961
Batch 19/64 loss: -2.097219467163086
Batch 20/64 loss: -2.4760618209838867
Batch 21/64 loss: -2.537215232849121
Batch 22/64 loss: -2.5137081146240234
Batch 23/64 loss: -2.4782886505126953
Batch 24/64 loss: -2.519425392150879
Batch 25/64 loss: -2.729705810546875
Batch 26/64 loss: -2.913754463195801
Batch 27/64 loss: -2.5912675857543945
Batch 28/64 loss: -2.3825035095214844
Batch 29/64 loss: -2.8389768600463867
Batch 30/64 loss: -2.5739850997924805
Batch 31/64 loss: -2.659526824951172
Batch 32/64 loss: -2.7365760803222656
Batch 33/64 loss: -2.7372446060180664
Batch 34/64 loss: -2.6626243591308594
Batch 35/64 loss: -2.6243906021118164
Batch 36/64 loss: -2.57657527923584
Batch 37/64 loss: -2.6442832946777344
Batch 38/64 loss: -2.6944541931152344
Batch 39/64 loss: -2.71630859375
Batch 40/64 loss: -2.907430648803711
Batch 41/64 loss: -2.820572853088379
Batch 42/64 loss: -2.657541275024414
Batch 43/64 loss: -2.7466506958007812
Batch 44/64 loss: -2.6630096435546875
Batch 45/64 loss: -2.600541114807129
Batch 46/64 loss: -2.6747655868530273
Batch 47/64 loss: -2.6431922912597656
Batch 48/64 loss: -2.5646371841430664
Batch 49/64 loss: -2.659402847290039
Batch 50/64 loss: -2.5207910537719727
Batch 51/64 loss: -2.6055173873901367
Batch 52/64 loss: -2.753373146057129
Batch 53/64 loss: -2.8127384185791016
Batch 54/64 loss: -2.8002614974975586
Batch 55/64 loss: -2.7737741470336914
Batch 56/64 loss: -2.874403953552246
Batch 57/64 loss: -2.6246938705444336
Batch 58/64 loss: -2.4564132690429688
Batch 59/64 loss: -2.7146005630493164
Batch 60/64 loss: -2.638035774230957
Batch 61/64 loss: -2.497605323791504
Batch 62/64 loss: -2.6484766006469727
Batch 63/64 loss: -2.8127851486206055
Batch 64/64 loss: -6.954989433288574
Epoch 253  Train loss: -2.680772777632171  Val loss: -2.9730385718067076
Epoch 254
-------------------------------
Batch 1/64 loss: -2.8398523330688477
Batch 2/64 loss: -2.749630928039551
Batch 3/64 loss: -2.6030750274658203
Batch 4/64 loss: -2.6050453186035156
Batch 5/64 loss: -2.798351287841797
Batch 6/64 loss: -2.3606605529785156
Batch 7/64 loss: -2.387575149536133
Batch 8/64 loss: -2.6970300674438477
Batch 9/64 loss: -2.236344337463379
Batch 10/64 loss: -2.8428945541381836
Batch 11/64 loss: -2.290207862854004
Batch 12/64 loss: -2.5987281799316406
Batch 13/64 loss: -2.6443405151367188
Batch 14/64 loss: -2.6118850708007812
Batch 15/64 loss: -2.6262760162353516
Batch 16/64 loss: -2.57381534576416
Batch 17/64 loss: -2.4268016815185547
Batch 18/64 loss: -2.773055076599121
Batch 19/64 loss: -2.521883010864258
Batch 20/64 loss: -2.777756690979004
Batch 21/64 loss: -2.7182884216308594
Batch 22/64 loss: -2.59810733795166
Batch 23/64 loss: -2.1802444458007812
Batch 24/64 loss: -2.1763343811035156
Batch 25/64 loss: -2.3401718139648438
Batch 26/64 loss: -2.6660776138305664
Batch 27/64 loss: -2.5327281951904297
Batch 28/64 loss: -2.430159568786621
Batch 29/64 loss: -2.6917724609375
Batch 30/64 loss: -2.5784740447998047
Batch 31/64 loss: -2.702580451965332
Batch 32/64 loss: -2.728883743286133
Batch 33/64 loss: -2.4731597900390625
Batch 34/64 loss: -2.816433906555176
Batch 35/64 loss: -2.5687103271484375
Batch 36/64 loss: -2.4618024826049805
Batch 37/64 loss: -2.5127649307250977
Batch 38/64 loss: -2.4997406005859375
Batch 39/64 loss: -2.816227912902832
Batch 40/64 loss: -2.656033515930176
Batch 41/64 loss: -2.1952104568481445
Batch 42/64 loss: -2.786052703857422
Batch 43/64 loss: -2.4022016525268555
Batch 44/64 loss: -2.8555898666381836
Batch 45/64 loss: -2.6703453063964844
Batch 46/64 loss: -2.7166242599487305
Batch 47/64 loss: -2.791132926940918
Batch 48/64 loss: -2.887263298034668
Batch 49/64 loss: -2.326864242553711
Batch 50/64 loss: -2.8600072860717773
Batch 51/64 loss: -2.7252960205078125
Batch 52/64 loss: -2.781744956970215
Batch 53/64 loss: -2.5197906494140625
Batch 54/64 loss: -2.885356903076172
Batch 55/64 loss: -2.817366600036621
Batch 56/64 loss: -2.726414680480957
Batch 57/64 loss: -2.745288848876953
Batch 58/64 loss: -2.4713172912597656
Batch 59/64 loss: -2.8092126846313477
Batch 60/64 loss: -2.5707225799560547
Batch 61/64 loss: -2.880033493041992
Batch 62/64 loss: -2.8937978744506836
Batch 63/64 loss: -2.8901290893554688
Batch 64/64 loss: -7.171916961669922
Epoch 254  Train loss: -2.6776565701353783  Val loss: -2.8951908780127456
Epoch 255
-------------------------------
Batch 1/64 loss: -2.7361621856689453
Batch 2/64 loss: -2.7521142959594727
Batch 3/64 loss: -2.6073808670043945
Batch 4/64 loss: -2.8551111221313477
Batch 5/64 loss: -2.463613510131836
Batch 6/64 loss: -2.7799482345581055
Batch 7/64 loss: -2.527461051940918
Batch 8/64 loss: -2.6599302291870117
Batch 9/64 loss: -2.867342948913574
Batch 10/64 loss: -2.5850095748901367
Batch 11/64 loss: -2.756753921508789
Batch 12/64 loss: -2.6194992065429688
Batch 13/64 loss: -2.5358591079711914
Batch 14/64 loss: -2.9092721939086914
Batch 15/64 loss: -2.6510820388793945
Batch 16/64 loss: -2.4754867553710938
Batch 17/64 loss: -2.5607662200927734
Batch 18/64 loss: -2.714305877685547
Batch 19/64 loss: -2.5289268493652344
Batch 20/64 loss: -2.7773256301879883
Batch 21/64 loss: -2.701854705810547
Batch 22/64 loss: -2.8345537185668945
Batch 23/64 loss: -2.5548877716064453
Batch 24/64 loss: -2.610088348388672
Batch 25/64 loss: -2.8400964736938477
Batch 26/64 loss: -2.7855520248413086
Batch 27/64 loss: -2.7202682495117188
Batch 28/64 loss: -2.7811927795410156
Batch 29/64 loss: -2.7203969955444336
Batch 30/64 loss: -2.772045135498047
Batch 31/64 loss: -2.5636825561523438
Batch 32/64 loss: -2.5083303451538086
Batch 33/64 loss: -2.7073354721069336
Batch 34/64 loss: -2.623523712158203
Batch 35/64 loss: -2.8521060943603516
Batch 36/64 loss: -2.468099594116211
Batch 37/64 loss: -2.564040184020996
Batch 38/64 loss: -2.779789924621582
Batch 39/64 loss: -2.7554054260253906
Batch 40/64 loss: -2.8268699645996094
Batch 41/64 loss: -2.471817970275879
Batch 42/64 loss: -2.7960147857666016
Batch 43/64 loss: -2.486125946044922
Batch 44/64 loss: -2.572751998901367
Batch 45/64 loss: -2.747012138366699
Batch 46/64 loss: -2.611654281616211
Batch 47/64 loss: -2.654646873474121
Batch 48/64 loss: -2.650655746459961
Batch 49/64 loss: -2.782355308532715
Batch 50/64 loss: -2.240359306335449
Batch 51/64 loss: -2.7854557037353516
Batch 52/64 loss: -2.7569284439086914
Batch 53/64 loss: -2.5241498947143555
Batch 54/64 loss: -2.492094039916992
Batch 55/64 loss: -2.734373092651367
Batch 56/64 loss: -2.484792709350586
Batch 57/64 loss: -2.760477066040039
Batch 58/64 loss: -2.5106019973754883
Batch 59/64 loss: -2.366396903991699
Batch 60/64 loss: -2.675689697265625
Batch 61/64 loss: -2.5855484008789062
Batch 62/64 loss: -2.520236015319824
Batch 63/64 loss: -2.7933406829833984
Batch 64/64 loss: -6.836076259613037
Epoch 255  Train loss: -2.7053177646562165  Val loss: -2.889672767665378
Epoch 256
-------------------------------
Batch 1/64 loss: -2.618358612060547
Batch 2/64 loss: -2.4455976486206055
Batch 3/64 loss: -2.8004446029663086
Batch 4/64 loss: -2.6704206466674805
Batch 5/64 loss: -2.772523880004883
Batch 6/64 loss: -2.7269134521484375
Batch 7/64 loss: -2.6195907592773438
Batch 8/64 loss: -2.4127273559570312
Batch 9/64 loss: -2.395200729370117
Batch 10/64 loss: -2.5498714447021484
Batch 11/64 loss: -2.885843276977539
Batch 12/64 loss: -2.698866844177246
Batch 13/64 loss: -2.4822921752929688
Batch 14/64 loss: -2.647311210632324
Batch 15/64 loss: -2.7702856063842773
Batch 16/64 loss: -2.7757034301757812
Batch 17/64 loss: -2.726573944091797
Batch 18/64 loss: -2.9326343536376953
Batch 19/64 loss: -2.578878402709961
Batch 20/64 loss: -2.71921443939209
Batch 21/64 loss: -2.782632827758789
Batch 22/64 loss: -2.7398576736450195
Batch 23/64 loss: -2.7211856842041016
Batch 24/64 loss: -2.8836631774902344
Batch 25/64 loss: -2.7295608520507812
Batch 26/64 loss: -2.7150259017944336
Batch 27/64 loss: -2.641730308532715
Batch 28/64 loss: -2.7301254272460938
Batch 29/64 loss: -2.5563249588012695
Batch 30/64 loss: -2.808107376098633
Batch 31/64 loss: -2.522250175476074
Batch 32/64 loss: -2.868006706237793
Batch 33/64 loss: -2.6720542907714844
Batch 34/64 loss: -2.6193857192993164
Batch 35/64 loss: -2.6354246139526367
Batch 36/64 loss: -2.776968002319336
Batch 37/64 loss: -2.5692272186279297
Batch 38/64 loss: -2.972661018371582
Batch 39/64 loss: -2.7040252685546875
Batch 40/64 loss: -2.700840950012207
Batch 41/64 loss: -2.619596481323242
Batch 42/64 loss: -2.859663963317871
Batch 43/64 loss: -2.7833614349365234
Batch 44/64 loss: -2.9463043212890625
Batch 45/64 loss: -2.7172069549560547
Batch 46/64 loss: -2.6787099838256836
Batch 47/64 loss: -2.621579170227051
Batch 48/64 loss: -2.782528877258301
Batch 49/64 loss: -2.7044477462768555
Batch 50/64 loss: -2.7634010314941406
Batch 51/64 loss: -2.629519462585449
Batch 52/64 loss: -2.70534610748291
Batch 53/64 loss: -2.695119857788086
Batch 54/64 loss: -2.686293601989746
Batch 55/64 loss: -2.8147287368774414
Batch 56/64 loss: -2.515133857727051
Batch 57/64 loss: -2.8068647384643555
Batch 58/64 loss: -2.7579870223999023
Batch 59/64 loss: -2.7060699462890625
Batch 60/64 loss: -2.4944324493408203
Batch 61/64 loss: -2.7896480560302734
Batch 62/64 loss: -2.744011878967285
Batch 63/64 loss: -2.7196083068847656
Batch 64/64 loss: -7.277076721191406
Epoch 256  Train loss: -2.754159725413603  Val loss: -3.0458652063743354
Saving best model, epoch: 256
Epoch 257
-------------------------------
Batch 1/64 loss: -2.7060394287109375
Batch 2/64 loss: -2.495281219482422
Batch 3/64 loss: -2.8738346099853516
Batch 4/64 loss: -2.664365768432617
Batch 5/64 loss: -2.631039619445801
Batch 6/64 loss: -2.4768848419189453
Batch 7/64 loss: -2.6140012741088867
Batch 8/64 loss: -2.818767547607422
Batch 9/64 loss: -2.836977005004883
Batch 10/64 loss: -2.657094955444336
Batch 11/64 loss: -2.611332893371582
Batch 12/64 loss: -2.9077987670898438
Batch 13/64 loss: -2.670334815979004
Batch 14/64 loss: -2.627565383911133
Batch 15/64 loss: -2.6140193939208984
Batch 16/64 loss: -2.618316650390625
Batch 17/64 loss: -2.306669235229492
Batch 18/64 loss: -2.664125442504883
Batch 19/64 loss: -2.6891679763793945
Batch 20/64 loss: -2.8521623611450195
Batch 21/64 loss: -2.6770849227905273
Batch 22/64 loss: -2.785552978515625
Batch 23/64 loss: -2.826237678527832
Batch 24/64 loss: -2.773087501525879
Batch 25/64 loss: -2.506258964538574
Batch 26/64 loss: -2.780609130859375
Batch 27/64 loss: -2.7244672775268555
Batch 28/64 loss: -2.768202781677246
Batch 29/64 loss: -2.8762731552124023
Batch 30/64 loss: -2.658571243286133
Batch 31/64 loss: -2.7336196899414062
Batch 32/64 loss: -2.8760480880737305
Batch 33/64 loss: -2.899111747741699
Batch 34/64 loss: -2.616403579711914
Batch 35/64 loss: -2.637190818786621
Batch 36/64 loss: -2.7084312438964844
Batch 37/64 loss: -2.803384780883789
Batch 38/64 loss: -2.7252063751220703
Batch 39/64 loss: -2.830702781677246
Batch 40/64 loss: -2.684372901916504
Batch 41/64 loss: -2.1714324951171875
Batch 42/64 loss: -2.5910253524780273
Batch 43/64 loss: -2.7806034088134766
Batch 44/64 loss: -2.6450719833374023
Batch 45/64 loss: -2.9838762283325195
Batch 46/64 loss: -2.4937314987182617
Batch 47/64 loss: -2.8437414169311523
Batch 48/64 loss: -2.8305864334106445
Batch 49/64 loss: -2.8159523010253906
Batch 50/64 loss: -2.6210670471191406
Batch 51/64 loss: -2.4974241256713867
Batch 52/64 loss: -2.59332275390625
Batch 53/64 loss: -2.7339487075805664
Batch 54/64 loss: -2.635608673095703
Batch 55/64 loss: -2.761471748352051
Batch 56/64 loss: -2.6485939025878906
Batch 57/64 loss: -2.4630117416381836
Batch 58/64 loss: -2.6074962615966797
Batch 59/64 loss: -2.8488988876342773
Batch 60/64 loss: -2.7763280868530273
Batch 61/64 loss: -2.709758758544922
Batch 62/64 loss: -2.8607711791992188
Batch 63/64 loss: -2.4062023162841797
Batch 64/64 loss: -7.139058589935303
Epoch 257  Train loss: -2.7435422130659517  Val loss: -3.001188048792049
Epoch 258
-------------------------------
Batch 1/64 loss: -2.7416458129882812
Batch 2/64 loss: -2.7551212310791016
Batch 3/64 loss: -2.803067207336426
Batch 4/64 loss: -2.5737686157226562
Batch 5/64 loss: -2.886455535888672
Batch 6/64 loss: -2.758066177368164
Batch 7/64 loss: -2.435124397277832
Batch 8/64 loss: -2.7705764770507812
Batch 9/64 loss: -2.7992067337036133
Batch 10/64 loss: -2.6853389739990234
Batch 11/64 loss: -2.739809989929199
Batch 12/64 loss: -2.6360301971435547
Batch 13/64 loss: -2.65195369720459
Batch 14/64 loss: -2.329451560974121
Batch 15/64 loss: -2.4177112579345703
Batch 16/64 loss: -2.597720146179199
Batch 17/64 loss: -2.492076873779297
Batch 18/64 loss: -2.6160669326782227
Batch 19/64 loss: -2.494969367980957
Batch 20/64 loss: -2.685824394226074
Batch 21/64 loss: -2.5884199142456055
Batch 22/64 loss: -2.7779502868652344
Batch 23/64 loss: -2.592442512512207
Batch 24/64 loss: -2.594964027404785
Batch 25/64 loss: -2.5579357147216797
Batch 26/64 loss: -2.8244590759277344
Batch 27/64 loss: -2.758939743041992
Batch 28/64 loss: -2.7294483184814453
Batch 29/64 loss: -2.655339241027832
Batch 30/64 loss: -2.6937007904052734
Batch 31/64 loss: -2.6088552474975586
Batch 32/64 loss: -2.6337928771972656
Batch 33/64 loss: -2.4920644760131836
Batch 34/64 loss: -2.6499757766723633
Batch 35/64 loss: -2.6601686477661133
Batch 36/64 loss: -2.5666494369506836
Batch 37/64 loss: -2.529538154602051
Batch 38/64 loss: -2.670283317565918
Batch 39/64 loss: -2.617431640625
Batch 40/64 loss: -2.7713632583618164
Batch 41/64 loss: -2.768551826477051
Batch 42/64 loss: -2.6095237731933594
Batch 43/64 loss: -2.612455368041992
Batch 44/64 loss: -2.512971878051758
Batch 45/64 loss: -2.5594635009765625
Batch 46/64 loss: -2.464059829711914
Batch 47/64 loss: -2.5233983993530273
Batch 48/64 loss: -2.337984085083008
Batch 49/64 loss: -2.6604251861572266
Batch 50/64 loss: -2.735340118408203
Batch 51/64 loss: -2.738539695739746
Batch 52/64 loss: -2.019002914428711
Batch 53/64 loss: -2.3310155868530273
Batch 54/64 loss: -2.61698055267334
Batch 55/64 loss: -2.420808792114258
Batch 56/64 loss: -2.5803890228271484
Batch 57/64 loss: -2.508970260620117
Batch 58/64 loss: -2.6631832122802734
Batch 59/64 loss: -2.739023208618164
Batch 60/64 loss: -2.6788978576660156
Batch 61/64 loss: -2.7544126510620117
Batch 62/64 loss: -2.440077781677246
Batch 63/64 loss: -2.7496337890625
Batch 64/64 loss: -7.094720840454102
Epoch 258  Train loss: -2.6696448307411345  Val loss: -2.9342032232645043
Epoch 259
-------------------------------
Batch 1/64 loss: -2.5380430221557617
Batch 2/64 loss: -2.406998634338379
Batch 3/64 loss: -2.426114082336426
Batch 4/64 loss: -2.6879043579101562
Batch 5/64 loss: -2.7789440155029297
Batch 6/64 loss: -2.6084470748901367
Batch 7/64 loss: -2.6110801696777344
Batch 8/64 loss: -2.8708858489990234
Batch 9/64 loss: -2.6070327758789062
Batch 10/64 loss: -2.572037696838379
Batch 11/64 loss: -2.7132034301757812
Batch 12/64 loss: -2.5593271255493164
Batch 13/64 loss: -2.6380558013916016
Batch 14/64 loss: -2.656632423400879
Batch 15/64 loss: -2.441391944885254
Batch 16/64 loss: -2.3639001846313477
Batch 17/64 loss: -2.657724380493164
Batch 18/64 loss: -2.3487205505371094
Batch 19/64 loss: -2.331157684326172
Batch 20/64 loss: -2.7996301651000977
Batch 21/64 loss: -2.668301582336426
Batch 22/64 loss: -2.750483512878418
Batch 23/64 loss: -2.9915285110473633
Batch 24/64 loss: -2.517610549926758
Batch 25/64 loss: -2.642911911010742
Batch 26/64 loss: -2.505795478820801
Batch 27/64 loss: -2.7715530395507812
Batch 28/64 loss: -2.6979217529296875
Batch 29/64 loss: -2.6243152618408203
Batch 30/64 loss: -2.722677230834961
Batch 31/64 loss: -2.7516698837280273
Batch 32/64 loss: -2.5077028274536133
Batch 33/64 loss: -2.5843276977539062
Batch 34/64 loss: -2.734384536743164
Batch 35/64 loss: -2.6191816329956055
Batch 36/64 loss: -2.6582813262939453
Batch 37/64 loss: -2.739421844482422
Batch 38/64 loss: -2.839657783508301
Batch 39/64 loss: -2.8268918991088867
Batch 40/64 loss: -2.669713020324707
Batch 41/64 loss: -2.6054086685180664
Batch 42/64 loss: -2.6992130279541016
Batch 43/64 loss: -2.6608781814575195
Batch 44/64 loss: -2.7720136642456055
Batch 45/64 loss: -2.541006088256836
Batch 46/64 loss: -2.623721122741699
Batch 47/64 loss: -2.839625358581543
Batch 48/64 loss: -2.751598358154297
Batch 49/64 loss: -2.7667903900146484
Batch 50/64 loss: -2.6800594329833984
Batch 51/64 loss: -2.3545045852661133
Batch 52/64 loss: -2.791482925415039
Batch 53/64 loss: -2.8380298614501953
Batch 54/64 loss: -2.8077926635742188
Batch 55/64 loss: -2.644083023071289
Batch 56/64 loss: -2.7131166458129883
Batch 57/64 loss: -2.724018096923828
Batch 58/64 loss: -2.653813362121582
Batch 59/64 loss: -2.625521659851074
Batch 60/64 loss: -2.6005449295043945
Batch 61/64 loss: -2.88381290435791
Batch 62/64 loss: -2.344207763671875
Batch 63/64 loss: -2.697812080383301
Batch 64/64 loss: -7.286284446716309
Epoch 259  Train loss: -2.7062796985401825  Val loss: -2.9480698837857067
Epoch 260
-------------------------------
Batch 1/64 loss: -2.700969696044922
Batch 2/64 loss: -2.5616912841796875
Batch 3/64 loss: -2.61245059967041
Batch 4/64 loss: -2.806396484375
Batch 5/64 loss: -2.993382453918457
Batch 6/64 loss: -2.662944793701172
Batch 7/64 loss: -2.665872573852539
Batch 8/64 loss: -2.615738868713379
Batch 9/64 loss: -2.910109519958496
Batch 10/64 loss: -2.647981643676758
Batch 11/64 loss: -2.8515119552612305
Batch 12/64 loss: -2.7625579833984375
Batch 13/64 loss: -2.6745338439941406
Batch 14/64 loss: -2.5183820724487305
Batch 15/64 loss: -2.842766761779785
Batch 16/64 loss: -2.7032556533813477
Batch 17/64 loss: -2.9519777297973633
Batch 18/64 loss: -2.8273820877075195
Batch 19/64 loss: -2.418351173400879
Batch 20/64 loss: -2.754375457763672
Batch 21/64 loss: -2.721470832824707
Batch 22/64 loss: -2.813143730163574
Batch 23/64 loss: -2.7249765396118164
Batch 24/64 loss: -2.636821746826172
Batch 25/64 loss: -2.6341753005981445
Batch 26/64 loss: -2.755189895629883
Batch 27/64 loss: -2.789137840270996
Batch 28/64 loss: -2.8873682022094727
Batch 29/64 loss: -2.7536563873291016
Batch 30/64 loss: -2.6471481323242188
Batch 31/64 loss: -2.7903289794921875
Batch 32/64 loss: -2.8376588821411133
Batch 33/64 loss: -2.826207160949707
Batch 34/64 loss: -2.8306102752685547
Batch 35/64 loss: -2.809925079345703
Batch 36/64 loss: -2.319716453552246
Batch 37/64 loss: -2.6337385177612305
Batch 38/64 loss: -2.536325454711914
Batch 39/64 loss: -2.612245559692383
Batch 40/64 loss: -2.51560115814209
Batch 41/64 loss: -2.8986682891845703
Batch 42/64 loss: -2.6461753845214844
Batch 43/64 loss: -2.814265251159668
Batch 44/64 loss: -2.740978240966797
Batch 45/64 loss: -2.8226003646850586
Batch 46/64 loss: -2.6587114334106445
Batch 47/64 loss: -2.7597951889038086
Batch 48/64 loss: -2.8090248107910156
Batch 49/64 loss: -2.5435791015625
Batch 50/64 loss: -2.7348251342773438
Batch 51/64 loss: -2.7017831802368164
Batch 52/64 loss: -2.615856170654297
Batch 53/64 loss: -2.5304079055786133
Batch 54/64 loss: -2.563351631164551
Batch 55/64 loss: -2.849559783935547
Batch 56/64 loss: -2.487997055053711
Batch 57/64 loss: -2.893199920654297
Batch 58/64 loss: -2.8169050216674805
Batch 59/64 loss: -2.67757511138916
Batch 60/64 loss: -2.830866813659668
Batch 61/64 loss: -2.6632299423217773
Batch 62/64 loss: -2.7251968383789062
Batch 63/64 loss: -2.534912109375
Batch 64/64 loss: -7.074120998382568
Epoch 260  Train loss: -2.763657007030412  Val loss: -3.068369809704548
Saving best model, epoch: 260
Epoch 261
-------------------------------
Batch 1/64 loss: -2.8294286727905273
Batch 2/64 loss: -2.893588066101074
Batch 3/64 loss: -2.763747215270996
Batch 4/64 loss: -2.679366111755371
Batch 5/64 loss: -2.8135757446289062
Batch 6/64 loss: -2.788633346557617
Batch 7/64 loss: -2.8703155517578125
Batch 8/64 loss: -2.5341482162475586
Batch 9/64 loss: -2.771334648132324
Batch 10/64 loss: -2.471907615661621
Batch 11/64 loss: -2.843280792236328
Batch 12/64 loss: -2.62221622467041
Batch 13/64 loss: -2.8082427978515625
Batch 14/64 loss: -2.7782888412475586
Batch 15/64 loss: -2.747849464416504
Batch 16/64 loss: -2.850881576538086
Batch 17/64 loss: -2.828497886657715
Batch 18/64 loss: -2.4225101470947266
Batch 19/64 loss: -2.848918914794922
Batch 20/64 loss: -2.721670150756836
Batch 21/64 loss: -2.8667898178100586
Batch 22/64 loss: -2.6408891677856445
Batch 23/64 loss: -2.9514036178588867
Batch 24/64 loss: -2.547384262084961
Batch 25/64 loss: -2.705066680908203
Batch 26/64 loss: -2.5193214416503906
Batch 27/64 loss: -2.621882438659668
Batch 28/64 loss: -2.6366806030273438
Batch 29/64 loss: -2.8363752365112305
Batch 30/64 loss: -2.5805139541625977
Batch 31/64 loss: -2.8571901321411133
Batch 32/64 loss: -2.7727832794189453
Batch 33/64 loss: -2.9505653381347656
Batch 34/64 loss: -2.9973087310791016
Batch 35/64 loss: -2.77349853515625
Batch 36/64 loss: -2.4633054733276367
Batch 37/64 loss: -2.754206657409668
Batch 38/64 loss: -2.5843000411987305
Batch 39/64 loss: -2.642056465148926
Batch 40/64 loss: -2.6580896377563477
Batch 41/64 loss: -2.6565675735473633
Batch 42/64 loss: -2.680805206298828
Batch 43/64 loss: -2.814089775085449
Batch 44/64 loss: -2.821181297302246
Batch 45/64 loss: -2.2920150756835938
Batch 46/64 loss: -2.806264877319336
Batch 47/64 loss: -2.7276172637939453
Batch 48/64 loss: -2.426971435546875
Batch 49/64 loss: -2.6188840866088867
Batch 50/64 loss: -2.4901180267333984
Batch 51/64 loss: -2.6767282485961914
Batch 52/64 loss: -2.544544219970703
Batch 53/64 loss: -2.345438003540039
Batch 54/64 loss: -2.748021125793457
Batch 55/64 loss: -2.776169776916504
Batch 56/64 loss: -2.4666433334350586
Batch 57/64 loss: -2.6582603454589844
Batch 58/64 loss: -2.765291213989258
Batch 59/64 loss: -2.448925018310547
Batch 60/64 loss: -2.6530990600585938
Batch 61/64 loss: -2.749669075012207
Batch 62/64 loss: -2.5904293060302734
Batch 63/64 loss: -2.50374698638916
Batch 64/64 loss: -7.089034080505371
Epoch 261  Train loss: -2.7423728531482174  Val loss: -2.959318416634786
Epoch 262
-------------------------------
Batch 1/64 loss: -2.5760364532470703
Batch 2/64 loss: -2.681412696838379
Batch 3/64 loss: -2.5615882873535156
Batch 4/64 loss: -2.5433435440063477
Batch 5/64 loss: -2.5741729736328125
Batch 6/64 loss: -2.7966976165771484
Batch 7/64 loss: -2.699308395385742
Batch 8/64 loss: -2.693164825439453
Batch 9/64 loss: -2.6989259719848633
Batch 10/64 loss: -2.495528221130371
Batch 11/64 loss: -2.452998161315918
Batch 12/64 loss: -2.479024887084961
Batch 13/64 loss: -2.683150291442871
Batch 14/64 loss: -2.7264890670776367
Batch 15/64 loss: -2.7320938110351562
Batch 16/64 loss: -2.677212715148926
Batch 17/64 loss: -2.6251449584960938
Batch 18/64 loss: -2.6065855026245117
Batch 19/64 loss: -2.553068161010742
Batch 20/64 loss: -2.7116079330444336
Batch 21/64 loss: -2.7466421127319336
Batch 22/64 loss: -2.585723876953125
Batch 23/64 loss: -2.6515703201293945
Batch 24/64 loss: -2.7210235595703125
Batch 25/64 loss: -2.5016517639160156
Batch 26/64 loss: -2.6580982208251953
Batch 27/64 loss: -2.779460906982422
Batch 28/64 loss: -2.6645803451538086
Batch 29/64 loss: -2.5558853149414062
Batch 30/64 loss: -2.6139869689941406
Batch 31/64 loss: -2.52060604095459
Batch 32/64 loss: -1.9353008270263672
Batch 33/64 loss: -2.5712738037109375
Batch 34/64 loss: -2.6140193939208984
Batch 35/64 loss: -2.702877998352051
Batch 36/64 loss: -2.6759300231933594
Batch 37/64 loss: -2.5366783142089844
Batch 38/64 loss: -2.7256126403808594
Batch 39/64 loss: -2.6034164428710938
Batch 40/64 loss: -2.812562942504883
Batch 41/64 loss: -2.734884262084961
Batch 42/64 loss: -2.889131546020508
Batch 43/64 loss: -2.7984514236450195
Batch 44/64 loss: -2.765340805053711
Batch 45/64 loss: -2.596902847290039
Batch 46/64 loss: -2.725050926208496
Batch 47/64 loss: -2.8268566131591797
Batch 48/64 loss: -2.431650161743164
Batch 49/64 loss: -2.5224294662475586
Batch 50/64 loss: -2.552936553955078
Batch 51/64 loss: -2.63607120513916
Batch 52/64 loss: -2.6441526412963867
Batch 53/64 loss: -2.7333831787109375
Batch 54/64 loss: -2.6659536361694336
Batch 55/64 loss: -2.4687814712524414
Batch 56/64 loss: -2.694460868835449
Batch 57/64 loss: -2.683621406555176
Batch 58/64 loss: -2.701146125793457
Batch 59/64 loss: -2.678217887878418
Batch 60/64 loss: -2.4495811462402344
Batch 61/64 loss: -2.875051498413086
Batch 62/64 loss: -2.7301769256591797
Batch 63/64 loss: -2.690047264099121
Batch 64/64 loss: -7.270960807800293
Epoch 262  Train loss: -2.6932071648392024  Val loss: -2.880161560687822
Epoch 263
-------------------------------
Batch 1/64 loss: -2.350663185119629
Batch 2/64 loss: -2.596670150756836
Batch 3/64 loss: -2.672356605529785
Batch 4/64 loss: -2.82729434967041
Batch 5/64 loss: -2.674654960632324
Batch 6/64 loss: -2.668783187866211
Batch 7/64 loss: -2.6593875885009766
Batch 8/64 loss: -2.692537307739258
Batch 9/64 loss: -2.5927963256835938
Batch 10/64 loss: -2.6867494583129883
Batch 11/64 loss: -2.8039932250976562
Batch 12/64 loss: -2.652566909790039
Batch 13/64 loss: -2.4185094833374023
Batch 14/64 loss: -2.778580665588379
Batch 15/64 loss: -2.667290687561035
Batch 16/64 loss: -2.693070411682129
Batch 17/64 loss: -2.709334373474121
Batch 18/64 loss: -2.671450614929199
Batch 19/64 loss: -2.8620386123657227
Batch 20/64 loss: -2.600733757019043
Batch 21/64 loss: -2.655855178833008
Batch 22/64 loss: -2.7160701751708984
Batch 23/64 loss: -2.7018842697143555
Batch 24/64 loss: -2.59366512298584
Batch 25/64 loss: -2.648752212524414
Batch 26/64 loss: -2.78664493560791
Batch 27/64 loss: -2.6440134048461914
Batch 28/64 loss: -2.7481937408447266
Batch 29/64 loss: -2.4676856994628906
Batch 30/64 loss: -2.613994598388672
Batch 31/64 loss: -2.7466955184936523
Batch 32/64 loss: -2.625995635986328
Batch 33/64 loss: -2.6967926025390625
Batch 34/64 loss: -2.7953033447265625
Batch 35/64 loss: -2.6612939834594727
Batch 36/64 loss: -2.587430953979492
Batch 37/64 loss: -2.864474296569824
Batch 38/64 loss: -2.6923751831054688
Batch 39/64 loss: -2.4056215286254883
Batch 40/64 loss: -2.528308868408203
Batch 41/64 loss: -2.865870475769043
Batch 42/64 loss: -2.575101852416992
Batch 43/64 loss: -2.776956558227539
Batch 44/64 loss: -2.661616325378418
Batch 45/64 loss: -2.745389938354492
Batch 46/64 loss: -2.6273088455200195
Batch 47/64 loss: -2.6478023529052734
Batch 48/64 loss: -2.687100410461426
Batch 49/64 loss: -2.806987762451172
Batch 50/64 loss: -2.1107912063598633
Batch 51/64 loss: -2.626422882080078
Batch 52/64 loss: -2.5258359909057617
Batch 53/64 loss: -2.6853513717651367
Batch 54/64 loss: -2.902883529663086
Batch 55/64 loss: -2.686227798461914
Batch 56/64 loss: -2.804950714111328
Batch 57/64 loss: -2.819546699523926
Batch 58/64 loss: -2.7037534713745117
Batch 59/64 loss: -2.7258615493774414
Batch 60/64 loss: -2.5966033935546875
Batch 61/64 loss: -2.631829261779785
Batch 62/64 loss: -2.298006057739258
Batch 63/64 loss: -2.810336112976074
Batch 64/64 loss: -7.1185808181762695
Epoch 263  Train loss: -2.7156389535642136  Val loss: -2.845288463474549
Epoch 264
-------------------------------
Batch 1/64 loss: -2.662808418273926
Batch 2/64 loss: -2.7740516662597656
Batch 3/64 loss: -2.601437568664551
Batch 4/64 loss: -2.591851234436035
Batch 5/64 loss: -2.6897382736206055
Batch 6/64 loss: -2.5639915466308594
Batch 7/64 loss: -2.755901336669922
Batch 8/64 loss: -2.743318557739258
Batch 9/64 loss: -2.536834716796875
Batch 10/64 loss: -2.459465980529785
Batch 11/64 loss: -2.796232223510742
Batch 12/64 loss: -2.7884626388549805
Batch 13/64 loss: -2.281949996948242
Batch 14/64 loss: -2.860520362854004
Batch 15/64 loss: -2.6327476501464844
Batch 16/64 loss: -2.6713943481445312
Batch 17/64 loss: -2.6681442260742188
Batch 18/64 loss: -2.754331588745117
Batch 19/64 loss: -2.7346315383911133
Batch 20/64 loss: -2.7211532592773438
Batch 21/64 loss: -2.387557029724121
Batch 22/64 loss: -2.6001100540161133
Batch 23/64 loss: -2.537996292114258
Batch 24/64 loss: -2.673525810241699
Batch 25/64 loss: -2.553119659423828
Batch 26/64 loss: -2.6426944732666016
Batch 27/64 loss: -2.6570262908935547
Batch 28/64 loss: -2.489129066467285
Batch 29/64 loss: -2.7378149032592773
Batch 30/64 loss: -2.7799482345581055
Batch 31/64 loss: -2.817974090576172
Batch 32/64 loss: -2.627290725708008
Batch 33/64 loss: -2.440582275390625
Batch 34/64 loss: -2.938321113586426
Batch 35/64 loss: -2.925265312194824
Batch 36/64 loss: -2.677487373352051
Batch 37/64 loss: -2.42156982421875
Batch 38/64 loss: -2.7664947509765625
Batch 39/64 loss: -2.809864044189453
Batch 40/64 loss: -2.6331281661987305
Batch 41/64 loss: -2.80228328704834
Batch 42/64 loss: -2.8588476181030273
Batch 43/64 loss: -2.5234155654907227
Batch 44/64 loss: -2.960866928100586
Batch 45/64 loss: -2.591679573059082
Batch 46/64 loss: -2.513524055480957
Batch 47/64 loss: -2.8001022338867188
Batch 48/64 loss: -2.825899124145508
Batch 49/64 loss: -2.692337989807129
Batch 50/64 loss: -2.8242950439453125
Batch 51/64 loss: -2.782970428466797
Batch 52/64 loss: -2.77401065826416
Batch 53/64 loss: -2.3620691299438477
Batch 54/64 loss: -2.6370601654052734
Batch 55/64 loss: -2.8403759002685547
Batch 56/64 loss: -2.6550521850585938
Batch 57/64 loss: -2.661701202392578
Batch 58/64 loss: -2.6440868377685547
Batch 59/64 loss: -2.6830215454101562
Batch 60/64 loss: -2.9321393966674805
Batch 61/64 loss: -2.8270626068115234
Batch 62/64 loss: -2.7253189086914062
Batch 63/64 loss: -2.7304258346557617
Batch 64/64 loss: -7.244348526000977
Epoch 264  Train loss: -2.737061556647806  Val loss: -3.07755421117409
Saving best model, epoch: 264
Epoch 265
-------------------------------
Batch 1/64 loss: -2.7848997116088867
Batch 2/64 loss: -2.8636789321899414
Batch 3/64 loss: -2.8568344116210938
Batch 4/64 loss: -2.7317590713500977
Batch 5/64 loss: -2.8983945846557617
Batch 6/64 loss: -2.7434749603271484
Batch 7/64 loss: -2.8037338256835938
Batch 8/64 loss: -2.713089942932129
Batch 9/64 loss: -2.7805261611938477
Batch 10/64 loss: -2.82913875579834
Batch 11/64 loss: -2.6807613372802734
Batch 12/64 loss: -2.796550750732422
Batch 13/64 loss: -2.689178466796875
Batch 14/64 loss: -2.827214241027832
Batch 15/64 loss: -2.500673294067383
Batch 16/64 loss: -2.603886604309082
Batch 17/64 loss: -2.678537368774414
Batch 18/64 loss: -2.594456672668457
Batch 19/64 loss: -2.566159248352051
Batch 20/64 loss: -2.4929819107055664
Batch 21/64 loss: -2.7586288452148438
Batch 22/64 loss: -2.6037158966064453
Batch 23/64 loss: -2.579159736633301
Batch 24/64 loss: -2.9623279571533203
Batch 25/64 loss: -2.8008346557617188
Batch 26/64 loss: -2.6339073181152344
Batch 27/64 loss: -2.8574113845825195
Batch 28/64 loss: -2.6657180786132812
Batch 29/64 loss: -2.9915027618408203
Batch 30/64 loss: -2.684459686279297
Batch 31/64 loss: -2.6064796447753906
Batch 32/64 loss: -2.8112993240356445
Batch 33/64 loss: -2.4646387100219727
Batch 34/64 loss: -2.7991552352905273
Batch 35/64 loss: -2.6802282333374023
Batch 36/64 loss: -2.520075798034668
Batch 37/64 loss: -2.787665367126465
Batch 38/64 loss: -2.910428047180176
Batch 39/64 loss: -2.4620513916015625
Batch 40/64 loss: -2.66951847076416
Batch 41/64 loss: -2.7501516342163086
Batch 42/64 loss: -2.2853689193725586
Batch 43/64 loss: -2.4102468490600586
Batch 44/64 loss: -2.7564868927001953
Batch 45/64 loss: -2.5161609649658203
Batch 46/64 loss: -2.838115692138672
Batch 47/64 loss: -2.8657894134521484
Batch 48/64 loss: -2.730274200439453
Batch 49/64 loss: -2.829629898071289
Batch 50/64 loss: -2.80117130279541
Batch 51/64 loss: -2.6757678985595703
Batch 52/64 loss: -2.786806106567383
Batch 53/64 loss: -2.9285593032836914
Batch 54/64 loss: -2.742201805114746
Batch 55/64 loss: -2.9038143157958984
Batch 56/64 loss: -2.5082550048828125
Batch 57/64 loss: -2.6613426208496094
Batch 58/64 loss: -2.8145933151245117
Batch 59/64 loss: -2.519552230834961
Batch 60/64 loss: -2.698230743408203
Batch 61/64 loss: -2.675565719604492
Batch 62/64 loss: -2.424968719482422
Batch 63/64 loss: -2.886871337890625
Batch 64/64 loss: -7.157517433166504
Epoch 265  Train loss: -2.7617756824867397  Val loss: -3.1074126594255063
Saving best model, epoch: 265
Epoch 266
-------------------------------
Batch 1/64 loss: -2.839972496032715
Batch 2/64 loss: -2.7793092727661133
Batch 3/64 loss: -2.6438722610473633
Batch 4/64 loss: -2.8323707580566406
Batch 5/64 loss: -2.7434797286987305
Batch 6/64 loss: -2.442824363708496
Batch 7/64 loss: -2.825453758239746
Batch 8/64 loss: -2.6941423416137695
Batch 9/64 loss: -2.6697568893432617
Batch 10/64 loss: -2.5736083984375
Batch 11/64 loss: -2.914247512817383
Batch 12/64 loss: -2.7781829833984375
Batch 13/64 loss: -2.210103988647461
Batch 14/64 loss: -2.78548526763916
Batch 15/64 loss: -2.293292999267578
Batch 16/64 loss: -2.65484619140625
Batch 17/64 loss: -2.7063512802124023
Batch 18/64 loss: -2.639963150024414
Batch 19/64 loss: -2.4116439819335938
Batch 20/64 loss: -2.231879234313965
Batch 21/64 loss: -2.3547487258911133
Batch 22/64 loss: -2.242276191711426
Batch 23/64 loss: -2.6762237548828125
Batch 24/64 loss: -2.6028194427490234
Batch 25/64 loss: -2.760204315185547
Batch 26/64 loss: -2.3925275802612305
Batch 27/64 loss: -2.598590850830078
Batch 28/64 loss: -2.5651416778564453
Batch 29/64 loss: -2.5678176879882812
Batch 30/64 loss: -2.528031349182129
Batch 31/64 loss: -2.606431007385254
Batch 32/64 loss: -2.351398468017578
Batch 33/64 loss: -2.674798011779785
Batch 34/64 loss: -2.6864805221557617
Batch 35/64 loss: -2.6410160064697266
Batch 36/64 loss: -2.631866455078125
Batch 37/64 loss: -2.5846214294433594
Batch 38/64 loss: -2.500054359436035
Batch 39/64 loss: -2.304173469543457
Batch 40/64 loss: -2.442000389099121
Batch 41/64 loss: -2.325784683227539
Batch 42/64 loss: -2.311833381652832
Batch 43/64 loss: -2.599419593811035
Batch 44/64 loss: -2.6867103576660156
Batch 45/64 loss: -2.497788429260254
Batch 46/64 loss: -2.512460708618164
Batch 47/64 loss: -2.666842460632324
Batch 48/64 loss: -2.2998037338256836
Batch 49/64 loss: -2.7274694442749023
Batch 50/64 loss: -2.3830490112304688
Batch 51/64 loss: -2.1497278213500977
Batch 52/64 loss: -2.3141584396362305
Batch 53/64 loss: -2.721327781677246
Batch 54/64 loss: -2.6956682205200195
Batch 55/64 loss: -2.763397216796875
Batch 56/64 loss: -2.613920211791992
Batch 57/64 loss: -2.7183570861816406
Batch 58/64 loss: -2.5219860076904297
Batch 59/64 loss: -2.6438350677490234
Batch 60/64 loss: -2.4933300018310547
Batch 61/64 loss: -2.5982065200805664
Batch 62/64 loss: -2.038214683532715
Batch 63/64 loss: -1.9967041015625
Batch 64/64 loss: -7.0290961265563965
Epoch 266  Train loss: -2.602883539012834  Val loss: -2.6265088766301212
Epoch 267
-------------------------------
Batch 1/64 loss: -2.385037422180176
Batch 2/64 loss: -2.272218704223633
Batch 3/64 loss: -2.597012519836426
Batch 4/64 loss: -2.4682512283325195
Batch 5/64 loss: -2.0332422256469727
Batch 6/64 loss: -2.887995719909668
Batch 7/64 loss: -2.3932981491088867
Batch 8/64 loss: -2.4918603897094727
Batch 9/64 loss: -2.668262481689453
Batch 10/64 loss: -2.3865556716918945
Batch 11/64 loss: -2.4403762817382812
Batch 12/64 loss: -2.337942123413086
Batch 13/64 loss: -2.343036651611328
Batch 14/64 loss: -2.427290916442871
Batch 15/64 loss: -2.578944206237793
Batch 16/64 loss: -2.2319421768188477
Batch 17/64 loss: -2.3507261276245117
Batch 18/64 loss: -2.7586746215820312
Batch 19/64 loss: -2.470126152038574
Batch 20/64 loss: -2.7531309127807617
Batch 21/64 loss: -2.7527713775634766
Batch 22/64 loss: -2.548007011413574
Batch 23/64 loss: -2.7439327239990234
Batch 24/64 loss: -2.680850028991699
Batch 25/64 loss: -2.8927841186523438
Batch 26/64 loss: -2.688338279724121
Batch 27/64 loss: -2.464122772216797
Batch 28/64 loss: -2.5516223907470703
Batch 29/64 loss: -2.8392019271850586
Batch 30/64 loss: -2.443497657775879
Batch 31/64 loss: -2.016702651977539
Batch 32/64 loss: -2.2961111068725586
Batch 33/64 loss: -2.64139461517334
Batch 34/64 loss: -2.6377363204956055
Batch 35/64 loss: -2.420954704284668
Batch 36/64 loss: -2.446042060852051
Batch 37/64 loss: -2.4799585342407227
Batch 38/64 loss: -2.520533561706543
Batch 39/64 loss: -2.3972768783569336
Batch 40/64 loss: -2.662088394165039
Batch 41/64 loss: -2.5589170455932617
Batch 42/64 loss: -2.345322608947754
Batch 43/64 loss: -2.8951663970947266
Batch 44/64 loss: -2.5008544921875
Batch 45/64 loss: -2.4670658111572266
Batch 46/64 loss: -2.466374397277832
Batch 47/64 loss: -2.133347511291504
Batch 48/64 loss: -1.3788776397705078
Batch 49/64 loss: -2.3600120544433594
Batch 50/64 loss: -2.8685903549194336
Batch 51/64 loss: -2.3917007446289062
Batch 52/64 loss: -2.532503128051758
Batch 53/64 loss: -2.5623531341552734
Batch 54/64 loss: -2.57025146484375
Batch 55/64 loss: -2.69149112701416
Batch 56/64 loss: -2.4989471435546875
Batch 57/64 loss: -2.4059438705444336
Batch 58/64 loss: -2.3676834106445312
Batch 59/64 loss: -2.656613349914551
Batch 60/64 loss: -2.609910011291504
Batch 61/64 loss: -2.6131982803344727
Batch 62/64 loss: -2.5620927810668945
Batch 63/64 loss: -2.701298713684082
Batch 64/64 loss: -6.797847747802734
Epoch 267  Train loss: -2.551164754231771  Val loss: -2.754728022309923
Epoch 268
-------------------------------
Batch 1/64 loss: -2.6830339431762695
Batch 2/64 loss: -1.97930908203125
Batch 3/64 loss: -2.4043350219726562
Batch 4/64 loss: -2.5055770874023438
Batch 5/64 loss: -2.726424217224121
Batch 6/64 loss: -2.713261604309082
Batch 7/64 loss: -2.549640655517578
Batch 8/64 loss: -2.5722084045410156
Batch 9/64 loss: -2.6439332962036133
Batch 10/64 loss: -2.7177610397338867
Batch 11/64 loss: -2.857217788696289
Batch 12/64 loss: -2.639286994934082
Batch 13/64 loss: -2.835622787475586
Batch 14/64 loss: -2.5809831619262695
Batch 15/64 loss: -2.7071027755737305
Batch 16/64 loss: -2.6951465606689453
Batch 17/64 loss: -2.3427295684814453
Batch 18/64 loss: -2.420010566711426
Batch 19/64 loss: -2.725926399230957
Batch 20/64 loss: -2.7604598999023438
Batch 21/64 loss: -2.4752988815307617
Batch 22/64 loss: -2.4164562225341797
Batch 23/64 loss: -2.635610580444336
Batch 24/64 loss: -2.440248489379883
Batch 25/64 loss: -2.8020858764648438
Batch 26/64 loss: -2.491497039794922
Batch 27/64 loss: -2.2520523071289062
Batch 28/64 loss: -2.2766761779785156
Batch 29/64 loss: -1.8115949630737305
Batch 30/64 loss: -2.61376953125
Batch 31/64 loss: -2.4600648880004883
Batch 32/64 loss: -1.796248435974121
Batch 33/64 loss: -2.569852828979492
Batch 34/64 loss: -2.6619224548339844
Batch 35/64 loss: -2.377084732055664
Batch 36/64 loss: -2.526658058166504
Batch 37/64 loss: -2.7513580322265625
Batch 38/64 loss: -1.4431953430175781
Batch 39/64 loss: -2.7128095626831055
Batch 40/64 loss: -2.350832939147949
Batch 41/64 loss: -2.812737464904785
Batch 42/64 loss: -2.6277170181274414
Batch 43/64 loss: -2.5783491134643555
Batch 44/64 loss: -2.185577392578125
Batch 45/64 loss: -2.496919631958008
Batch 46/64 loss: -2.5516138076782227
Batch 47/64 loss: -2.721804618835449
Batch 48/64 loss: -2.6449880599975586
Batch 49/64 loss: -2.5645103454589844
Batch 50/64 loss: -2.542304039001465
Batch 51/64 loss: -2.5868043899536133
Batch 52/64 loss: -2.2395687103271484
Batch 53/64 loss: -2.692904472351074
Batch 54/64 loss: -2.4079980850219727
Batch 55/64 loss: -2.4369421005249023
Batch 56/64 loss: -2.4856252670288086
Batch 57/64 loss: -2.79547119140625
Batch 58/64 loss: -2.115536689758301
Batch 59/64 loss: -2.4898672103881836
Batch 60/64 loss: -2.5635128021240234
Batch 61/64 loss: -2.741349220275879
Batch 62/64 loss: -2.743753433227539
Batch 63/64 loss: -2.1252689361572266
Batch 64/64 loss: -7.120041847229004
Epoch 268  Train loss: -2.5633951935113646  Val loss: -2.7648646823319374
Epoch 269
-------------------------------
Batch 1/64 loss: -2.4395761489868164
Batch 2/64 loss: -2.4829654693603516
Batch 3/64 loss: -2.0622167587280273
Batch 4/64 loss: -2.3808727264404297
Batch 5/64 loss: -2.052762031555176
Batch 6/64 loss: -2.678485870361328
Batch 7/64 loss: -2.5469369888305664
Batch 8/64 loss: -2.333280563354492
Batch 9/64 loss: -2.629354476928711
Batch 10/64 loss: -2.395437240600586
Batch 11/64 loss: -2.3094024658203125
Batch 12/64 loss: -2.521383285522461
Batch 13/64 loss: -2.4654970169067383
Batch 14/64 loss: -2.1582202911376953
Batch 15/64 loss: -2.670466423034668
Batch 16/64 loss: -2.785641670227051
Batch 17/64 loss: -2.749844551086426
Batch 18/64 loss: -2.7204809188842773
Batch 19/64 loss: -2.3348255157470703
Batch 20/64 loss: -2.8542089462280273
Batch 21/64 loss: -2.700124740600586
Batch 22/64 loss: -2.488241195678711
Batch 23/64 loss: -2.688920021057129
Batch 24/64 loss: -2.831075668334961
Batch 25/64 loss: -2.339940071105957
Batch 26/64 loss: -2.7768707275390625
Batch 27/64 loss: -2.7997474670410156
Batch 28/64 loss: -2.577935218811035
Batch 29/64 loss: -2.308608055114746
Batch 30/64 loss: -2.8395137786865234
Batch 31/64 loss: -2.835783004760742
Batch 32/64 loss: -2.824129104614258
Batch 33/64 loss: -2.657322883605957
Batch 34/64 loss: -2.6065263748168945
Batch 35/64 loss: -2.2184906005859375
Batch 36/64 loss: -2.6716737747192383
Batch 37/64 loss: -2.487154006958008
Batch 38/64 loss: -2.817373275756836
Batch 39/64 loss: -2.798558235168457
Batch 40/64 loss: -2.4726924896240234
Batch 41/64 loss: -2.6904964447021484
Batch 42/64 loss: -2.5536251068115234
Batch 43/64 loss: -2.813076972961426
Batch 44/64 loss: -2.52667236328125
Batch 45/64 loss: -2.4778289794921875
Batch 46/64 loss: -2.5781993865966797
Batch 47/64 loss: -2.526949882507324
Batch 48/64 loss: -2.6508617401123047
Batch 49/64 loss: -2.762056350708008
Batch 50/64 loss: -2.6743688583374023
Batch 51/64 loss: -2.72946834564209
Batch 52/64 loss: -2.8616371154785156
Batch 53/64 loss: -2.6087656021118164
Batch 54/64 loss: -2.111452102661133
Batch 55/64 loss: -2.7831573486328125
Batch 56/64 loss: -2.6791648864746094
Batch 57/64 loss: -2.7764978408813477
Batch 58/64 loss: -1.7936983108520508
Batch 59/64 loss: -2.869481086730957
Batch 60/64 loss: -2.1429967880249023
Batch 61/64 loss: -2.769688606262207
Batch 62/64 loss: -2.631596565246582
Batch 63/64 loss: -2.5118350982666016
Batch 64/64 loss: -7.214585304260254
Epoch 269  Train loss: -2.6234832127888996  Val loss: -2.7888000593152653
Epoch 270
-------------------------------
Batch 1/64 loss: -2.724123001098633
Batch 2/64 loss: -2.4267120361328125
Batch 3/64 loss: -2.646416664123535
Batch 4/64 loss: -2.369363784790039
Batch 5/64 loss: -2.705202102661133
Batch 6/64 loss: -2.4319276809692383
Batch 7/64 loss: -2.0385475158691406
Batch 8/64 loss: -2.7728137969970703
Batch 9/64 loss: -2.665055274963379
Batch 10/64 loss: -2.6242446899414062
Batch 11/64 loss: -2.5695619583129883
Batch 12/64 loss: -2.4081249237060547
Batch 13/64 loss: -2.2794551849365234
Batch 14/64 loss: -2.5698633193969727
Batch 15/64 loss: -2.3204355239868164
Batch 16/64 loss: -1.4317255020141602
Batch 17/64 loss: -2.483473777770996
Batch 18/64 loss: -2.6171836853027344
Batch 19/64 loss: -2.4127635955810547
Batch 20/64 loss: -2.5359325408935547
Batch 21/64 loss: -2.5602664947509766
Batch 22/64 loss: -2.6517086029052734
Batch 23/64 loss: -2.650027275085449
Batch 24/64 loss: -2.7215347290039062
Batch 25/64 loss: -2.7297286987304688
Batch 26/64 loss: -2.2574052810668945
Batch 27/64 loss: -2.7323379516601562
Batch 28/64 loss: -2.7120494842529297
Batch 29/64 loss: -2.1241989135742188
Batch 30/64 loss: -2.4732160568237305
Batch 31/64 loss: -2.42916202545166
Batch 32/64 loss: -2.2247934341430664
Batch 33/64 loss: -2.2381982803344727
Batch 34/64 loss: -2.639275550842285
Batch 35/64 loss: -2.640315055847168
Batch 36/64 loss: -2.4105138778686523
Batch 37/64 loss: -2.801227569580078
Batch 38/64 loss: -2.947024345397949
Batch 39/64 loss: -2.6813039779663086
Batch 40/64 loss: -2.5084877014160156
Batch 41/64 loss: -2.8636302947998047
Batch 42/64 loss: -2.6996536254882812
Batch 43/64 loss: -2.6066207885742188
Batch 44/64 loss: -2.600208282470703
Batch 45/64 loss: -2.5159835815429688
Batch 46/64 loss: -2.003633499145508
Batch 47/64 loss: -2.653292655944824
Batch 48/64 loss: -2.8301734924316406
Batch 49/64 loss: -2.415299415588379
Batch 50/64 loss: -2.299574851989746
Batch 51/64 loss: -1.8891849517822266
Batch 52/64 loss: -2.530707359313965
Batch 53/64 loss: -2.4260778427124023
Batch 54/64 loss: -2.6126232147216797
Batch 55/64 loss: -2.5666427612304688
Batch 56/64 loss: -2.6324462890625
Batch 57/64 loss: -1.988266944885254
Batch 58/64 loss: -2.49688720703125
Batch 59/64 loss: -2.679462432861328
Batch 60/64 loss: -2.326162338256836
Batch 61/64 loss: -2.369687080383301
Batch 62/64 loss: -2.5267114639282227
Batch 63/64 loss: -2.5227737426757812
Batch 64/64 loss: -7.216752052307129
Epoch 270  Train loss: -2.5511210983874753  Val loss: -2.991531555595267
Epoch 271
-------------------------------
Batch 1/64 loss: -2.7597131729125977
Batch 2/64 loss: -2.6408863067626953
Batch 3/64 loss: -2.710442543029785
Batch 4/64 loss: -2.2661619186401367
Batch 5/64 loss: -2.4510087966918945
Batch 6/64 loss: -2.855274200439453
Batch 7/64 loss: -2.6570234298706055
Batch 8/64 loss: -2.568195343017578
Batch 9/64 loss: -2.0375747680664062
Batch 10/64 loss: -2.80755615234375
Batch 11/64 loss: -2.823444366455078
Batch 12/64 loss: -2.663701057434082
Batch 13/64 loss: -2.6786279678344727
Batch 14/64 loss: -2.821216583251953
Batch 15/64 loss: -2.453782081604004
Batch 16/64 loss: -2.8821792602539062
Batch 17/64 loss: -2.716122627258301
Batch 18/64 loss: -2.7787704467773438
Batch 19/64 loss: -2.5862245559692383
Batch 20/64 loss: -2.6213855743408203
Batch 21/64 loss: -2.8882217407226562
Batch 22/64 loss: -2.8365707397460938
Batch 23/64 loss: -2.6330175399780273
Batch 24/64 loss: -2.751361846923828
Batch 25/64 loss: -2.6644392013549805
Batch 26/64 loss: -2.5503549575805664
Batch 27/64 loss: -1.7159404754638672
Batch 28/64 loss: -2.7217979431152344
Batch 29/64 loss: -2.7882823944091797
Batch 30/64 loss: -2.5994338989257812
Batch 31/64 loss: -2.343637466430664
Batch 32/64 loss: -2.4612226486206055
Batch 33/64 loss: -2.637481689453125
Batch 34/64 loss: -2.591200828552246
Batch 35/64 loss: -2.481891632080078
Batch 36/64 loss: -2.587495803833008
Batch 37/64 loss: -2.877960205078125
Batch 38/64 loss: -1.8967790603637695
Batch 39/64 loss: -2.7985239028930664
Batch 40/64 loss: -2.7097463607788086
Batch 41/64 loss: -2.7573909759521484
Batch 42/64 loss: -2.6561851501464844
Batch 43/64 loss: -2.753406524658203
Batch 44/64 loss: -2.30953311920166
Batch 45/64 loss: -2.376466751098633
Batch 46/64 loss: -2.69870662689209
Batch 47/64 loss: -2.31227970123291
Batch 48/64 loss: -2.787353515625
Batch 49/64 loss: -2.7422828674316406
Batch 50/64 loss: -2.7843809127807617
Batch 51/64 loss: -2.712386131286621
Batch 52/64 loss: -2.5203428268432617
Batch 53/64 loss: -2.5627479553222656
Batch 54/64 loss: -2.0130014419555664
Batch 55/64 loss: -2.6492919921875
Batch 56/64 loss: -2.415128707885742
Batch 57/64 loss: -2.717860221862793
Batch 58/64 loss: -2.5662660598754883
Batch 59/64 loss: -2.0810298919677734
Batch 60/64 loss: -2.30352783203125
Batch 61/64 loss: -2.309307098388672
Batch 62/64 loss: -2.7732582092285156
Batch 63/64 loss: -2.5763587951660156
Batch 64/64 loss: -7.114757061004639
Epoch 271  Train loss: -2.635752354416193  Val loss: -2.860063139925298
Epoch 272
-------------------------------
Batch 1/64 loss: -2.5890703201293945
Batch 2/64 loss: -2.6329545974731445
Batch 3/64 loss: -2.692211151123047
Batch 4/64 loss: -2.8081817626953125
Batch 5/64 loss: -2.368535041809082
Batch 6/64 loss: -2.2453107833862305
Batch 7/64 loss: -2.8040084838867188
Batch 8/64 loss: -2.4925804138183594
Batch 9/64 loss: -2.6379852294921875
Batch 10/64 loss: -2.674327850341797
Batch 11/64 loss: -2.700739860534668
Batch 12/64 loss: -2.579538345336914
Batch 13/64 loss: -2.580681800842285
Batch 14/64 loss: -2.5276622772216797
Batch 15/64 loss: -2.4159345626831055
Batch 16/64 loss: -2.485177993774414
Batch 17/64 loss: -2.4527854919433594
Batch 18/64 loss: -2.66226863861084
Batch 19/64 loss: -2.4190492630004883
Batch 20/64 loss: -2.8872127532958984
Batch 21/64 loss: -2.4001712799072266
Batch 22/64 loss: -2.9239044189453125
Batch 23/64 loss: -2.788224220275879
Batch 24/64 loss: -2.5576000213623047
Batch 25/64 loss: -2.45644474029541
Batch 26/64 loss: -2.805739402770996
Batch 27/64 loss: -2.8378467559814453
Batch 28/64 loss: -2.532383918762207
Batch 29/64 loss: -2.8168258666992188
Batch 30/64 loss: -2.868414878845215
Batch 31/64 loss: -2.494607925415039
Batch 32/64 loss: -2.531259536743164
Batch 33/64 loss: -2.5849390029907227
Batch 34/64 loss: -2.8555917739868164
Batch 35/64 loss: -2.800264358520508
Batch 36/64 loss: -2.732954978942871
Batch 37/64 loss: -1.925619125366211
Batch 38/64 loss: -2.8028078079223633
Batch 39/64 loss: -2.7139711380004883
Batch 40/64 loss: -2.570124626159668
Batch 41/64 loss: -2.7276535034179688
Batch 42/64 loss: -2.6598434448242188
Batch 43/64 loss: -2.712477684020996
Batch 44/64 loss: -2.956110954284668
Batch 45/64 loss: -2.8045787811279297
Batch 46/64 loss: -2.556675910949707
Batch 47/64 loss: -2.675251007080078
Batch 48/64 loss: -2.737791061401367
Batch 49/64 loss: -2.683680534362793
Batch 50/64 loss: -2.7014970779418945
Batch 51/64 loss: -2.7081480026245117
Batch 52/64 loss: -2.0716686248779297
Batch 53/64 loss: -2.3910560607910156
Batch 54/64 loss: -1.7928485870361328
Batch 55/64 loss: -2.5379104614257812
Batch 56/64 loss: -2.4498720169067383
Batch 57/64 loss: -2.750382423400879
Batch 58/64 loss: -2.69559383392334
Batch 59/64 loss: -2.327054023742676
Batch 60/64 loss: -2.416928291320801
Batch 61/64 loss: -2.0871047973632812
Batch 62/64 loss: -2.6021833419799805
Batch 63/64 loss: -2.6608142852783203
Batch 64/64 loss: -7.147907733917236
Epoch 272  Train loss: -2.6466504770166734  Val loss: -2.7703872234960603
Epoch 273
-------------------------------
Batch 1/64 loss: -2.69244384765625
Batch 2/64 loss: -2.45143985748291
Batch 3/64 loss: -2.710848808288574
Batch 4/64 loss: -2.4693593978881836
Batch 5/64 loss: -2.6698293685913086
Batch 6/64 loss: -2.2047767639160156
Batch 7/64 loss: -2.447328567504883
Batch 8/64 loss: -2.399054527282715
Batch 9/64 loss: -2.73492431640625
Batch 10/64 loss: -2.633993148803711
Batch 11/64 loss: -2.5075607299804688
Batch 12/64 loss: -2.8297204971313477
Batch 13/64 loss: -2.3732547760009766
Batch 14/64 loss: -2.6770992279052734
Batch 15/64 loss: -2.4989423751831055
Batch 16/64 loss: -2.5298728942871094
Batch 17/64 loss: -2.4105873107910156
Batch 18/64 loss: -2.693488121032715
Batch 19/64 loss: -2.762990951538086
Batch 20/64 loss: -2.454822540283203
Batch 21/64 loss: -2.7936201095581055
Batch 22/64 loss: -2.585277557373047
Batch 23/64 loss: -1.9381513595581055
Batch 24/64 loss: -2.7718868255615234
Batch 25/64 loss: -2.6354751586914062
Batch 26/64 loss: -2.643326759338379
Batch 27/64 loss: -2.5916357040405273
Batch 28/64 loss: -2.7324819564819336
Batch 29/64 loss: -2.490377426147461
Batch 30/64 loss: -2.541351318359375
Batch 31/64 loss: -2.8521947860717773
Batch 32/64 loss: -2.580092430114746
Batch 33/64 loss: -2.175426483154297
Batch 34/64 loss: -2.631331443786621
Batch 35/64 loss: -2.770199775695801
Batch 36/64 loss: -2.7793989181518555
Batch 37/64 loss: -2.603238105773926
Batch 38/64 loss: -2.8086156845092773
Batch 39/64 loss: -2.779336929321289
Batch 40/64 loss: -2.514324188232422
Batch 41/64 loss: -2.646026611328125
Batch 42/64 loss: -2.661876678466797
Batch 43/64 loss: -2.0929317474365234
Batch 44/64 loss: -2.936847686767578
Batch 45/64 loss: -2.511244773864746
Batch 46/64 loss: -2.642841339111328
Batch 47/64 loss: -2.304783821105957
Batch 48/64 loss: -2.789255142211914
Batch 49/64 loss: -2.812826156616211
Batch 50/64 loss: -2.781987190246582
Batch 51/64 loss: -2.326687812805176
Batch 52/64 loss: -2.8734922409057617
Batch 53/64 loss: -2.666393280029297
Batch 54/64 loss: -2.2081308364868164
Batch 55/64 loss: -2.542490005493164
Batch 56/64 loss: -2.614396095275879
Batch 57/64 loss: -2.533296585083008
Batch 58/64 loss: -2.768263816833496
Batch 59/64 loss: -2.7223739624023438
Batch 60/64 loss: -2.5096826553344727
Batch 61/64 loss: -2.838125228881836
Batch 62/64 loss: -2.7835283279418945
Batch 63/64 loss: -2.645282745361328
Batch 64/64 loss: -7.267300128936768
Epoch 273  Train loss: -2.6515030711304908  Val loss: -2.8730354440171286
Epoch 274
-------------------------------
Batch 1/64 loss: -2.337503433227539
Batch 2/64 loss: -2.629611015319824
Batch 3/64 loss: -2.6813087463378906
Batch 4/64 loss: -2.539261817932129
Batch 5/64 loss: -2.5676822662353516
Batch 6/64 loss: -2.5420217514038086
Batch 7/64 loss: -2.4024362564086914
Batch 8/64 loss: -2.92391300201416
Batch 9/64 loss: -2.8006839752197266
Batch 10/64 loss: -2.7955322265625
Batch 11/64 loss: -2.611849784851074
Batch 12/64 loss: -2.624497413635254
Batch 13/64 loss: -2.7106266021728516
Batch 14/64 loss: -2.6980409622192383
Batch 15/64 loss: -2.8091506958007812
Batch 16/64 loss: -2.301497459411621
Batch 17/64 loss: -2.6723785400390625
Batch 18/64 loss: -2.7818098068237305
Batch 19/64 loss: -2.750056266784668
Batch 20/64 loss: -2.7898025512695312
Batch 21/64 loss: -2.66912841796875
Batch 22/64 loss: -2.8000307083129883
Batch 23/64 loss: -2.6762447357177734
Batch 24/64 loss: -2.8123226165771484
Batch 25/64 loss: -2.7422895431518555
Batch 26/64 loss: -2.4321422576904297
Batch 27/64 loss: -2.8407506942749023
Batch 28/64 loss: -2.510557174682617
Batch 29/64 loss: -2.709902763366699
Batch 30/64 loss: -2.47446346282959
Batch 31/64 loss: -2.7708053588867188
Batch 32/64 loss: -2.579106330871582
Batch 33/64 loss: -2.18581485748291
Batch 34/64 loss: -2.419208526611328
Batch 35/64 loss: -2.4676218032836914
Batch 36/64 loss: -1.2812347412109375
Batch 37/64 loss: -2.6621055603027344
Batch 38/64 loss: -2.0280609130859375
Batch 39/64 loss: -2.389044761657715
Batch 40/64 loss: -2.7919797897338867
Batch 41/64 loss: -2.163421630859375
Batch 42/64 loss: -2.748440742492676
Batch 43/64 loss: -2.670792579650879
Batch 44/64 loss: -2.722332000732422
Batch 45/64 loss: -2.777498245239258
Batch 46/64 loss: -2.82767391204834
Batch 47/64 loss: -2.5745410919189453
Batch 48/64 loss: -2.728978157043457
Batch 49/64 loss: -2.1222753524780273
Batch 50/64 loss: -2.6259803771972656
Batch 51/64 loss: -2.9044370651245117
Batch 52/64 loss: -2.689518928527832
Batch 53/64 loss: -2.7628297805786133
Batch 54/64 loss: -2.7468643188476562
Batch 55/64 loss: -2.547626495361328
Batch 56/64 loss: -2.62445068359375
Batch 57/64 loss: -2.5045480728149414
Batch 58/64 loss: -2.9083023071289062
Batch 59/64 loss: -2.439946174621582
Batch 60/64 loss: -2.5389156341552734
Batch 61/64 loss: -2.7694549560546875
Batch 62/64 loss: -2.6598453521728516
Batch 63/64 loss: -2.5126466751098633
Batch 64/64 loss: -7.367963790893555
Epoch 274  Train loss: -2.6558395759732116  Val loss: -2.8395467148613682
Epoch 275
-------------------------------
Batch 1/64 loss: -2.826542854309082
Batch 2/64 loss: -2.6705760955810547
Batch 3/64 loss: -2.0901317596435547
Batch 4/64 loss: -2.683696746826172
Batch 5/64 loss: -2.6424379348754883
Batch 6/64 loss: -2.759946823120117
Batch 7/64 loss: -2.5058393478393555
Batch 8/64 loss: -2.8625621795654297
Batch 9/64 loss: -2.627425193786621
Batch 10/64 loss: -2.590315818786621
Batch 11/64 loss: -2.5588998794555664
Batch 12/64 loss: -2.1598596572875977
Batch 13/64 loss: -2.3597888946533203
Batch 14/64 loss: -2.722245216369629
Batch 15/64 loss: -2.757460594177246
Batch 16/64 loss: -2.3896169662475586
Batch 17/64 loss: -2.8494491577148438
Batch 18/64 loss: -2.3322439193725586
Batch 19/64 loss: -2.4553117752075195
Batch 20/64 loss: -2.597871780395508
Batch 21/64 loss: -2.573760986328125
Batch 22/64 loss: -2.235933303833008
Batch 23/64 loss: -2.628750801086426
Batch 24/64 loss: -2.838287353515625
Batch 25/64 loss: -2.8060007095336914
Batch 26/64 loss: -2.6593093872070312
Batch 27/64 loss: -2.4526376724243164
Batch 28/64 loss: -2.7222185134887695
Batch 29/64 loss: -2.6273574829101562
Batch 30/64 loss: -2.7334823608398438
Batch 31/64 loss: -2.6847238540649414
Batch 32/64 loss: -2.7112350463867188
Batch 33/64 loss: -2.631612777709961
Batch 34/64 loss: -2.7433547973632812
Batch 35/64 loss: -2.1307601928710938
Batch 36/64 loss: -2.741771697998047
Batch 37/64 loss: -2.6597328186035156
Batch 38/64 loss: -2.68320369720459
Batch 39/64 loss: -2.768552780151367
Batch 40/64 loss: -2.7335681915283203
Batch 41/64 loss: -2.5964584350585938
Batch 42/64 loss: -2.977972984313965
Batch 43/64 loss: -2.6546287536621094
Batch 44/64 loss: -2.682002067565918
Batch 45/64 loss: -2.8383264541625977
Batch 46/64 loss: -2.912616729736328
Batch 47/64 loss: -2.4566164016723633
Batch 48/64 loss: -2.58608341217041
Batch 49/64 loss: -2.6959915161132812
Batch 50/64 loss: -2.8022279739379883
Batch 51/64 loss: -2.3043384552001953
Batch 52/64 loss: -2.5253124237060547
Batch 53/64 loss: -2.681979179382324
Batch 54/64 loss: -2.720372200012207
Batch 55/64 loss: -2.647280693054199
Batch 56/64 loss: -2.5443668365478516
Batch 57/64 loss: -2.41896915435791
Batch 58/64 loss: -2.38287353515625
Batch 59/64 loss: -2.504213333129883
Batch 60/64 loss: -2.6115713119506836
Batch 61/64 loss: -2.406454086303711
Batch 62/64 loss: -2.504214286804199
Batch 63/64 loss: -2.603994369506836
Batch 64/64 loss: -7.39284610748291
Epoch 275  Train loss: -2.6637172736373604  Val loss: -2.8220585826336313
Epoch 276
-------------------------------
Batch 1/64 loss: -2.84348201751709
Batch 2/64 loss: -2.5798768997192383
Batch 3/64 loss: -2.6923561096191406
Batch 4/64 loss: -2.6338796615600586
Batch 5/64 loss: -2.3900060653686523
Batch 6/64 loss: -2.8209362030029297
Batch 7/64 loss: -2.5139427185058594
Batch 8/64 loss: -2.748004913330078
Batch 9/64 loss: -2.4378890991210938
Batch 10/64 loss: -2.638887405395508
Batch 11/64 loss: -2.7431249618530273
Batch 12/64 loss: -2.7511367797851562
Batch 13/64 loss: -2.573969841003418
Batch 14/64 loss: -2.6964712142944336
Batch 15/64 loss: -2.383316993713379
Batch 16/64 loss: -2.919497489929199
Batch 17/64 loss: -2.773357391357422
Batch 18/64 loss: -2.5768795013427734
Batch 19/64 loss: -2.550417900085449
Batch 20/64 loss: -2.6375255584716797
Batch 21/64 loss: -2.5461254119873047
Batch 22/64 loss: -1.875091552734375
Batch 23/64 loss: -2.561788558959961
Batch 24/64 loss: -2.4548168182373047
Batch 25/64 loss: -2.653810501098633
Batch 26/64 loss: -2.3808422088623047
Batch 27/64 loss: -2.38299560546875
Batch 28/64 loss: -2.6375865936279297
Batch 29/64 loss: -2.4275083541870117
Batch 30/64 loss: -2.741806983947754
Batch 31/64 loss: -2.6778297424316406
Batch 32/64 loss: -2.799633026123047
Batch 33/64 loss: -1.9468994140625
Batch 34/64 loss: -2.828907012939453
Batch 35/64 loss: -2.4693212509155273
Batch 36/64 loss: -2.703847885131836
Batch 37/64 loss: -2.600400924682617
Batch 38/64 loss: -2.6026220321655273
Batch 39/64 loss: -2.08743953704834
Batch 40/64 loss: -2.3205995559692383
Batch 41/64 loss: -2.2494630813598633
Batch 42/64 loss: -2.4564085006713867
Batch 43/64 loss: -1.8523588180541992
Batch 44/64 loss: -2.6648359298706055
Batch 45/64 loss: -2.315373420715332
Batch 46/64 loss: -2.473421096801758
Batch 47/64 loss: -2.694204330444336
Batch 48/64 loss: -2.805276870727539
Batch 49/64 loss: -2.383336067199707
Batch 50/64 loss: -2.822622299194336
Batch 51/64 loss: -2.6657886505126953
Batch 52/64 loss: -2.7567615509033203
Batch 53/64 loss: -2.688638687133789
Batch 54/64 loss: -2.637681007385254
Batch 55/64 loss: -2.1593828201293945
Batch 56/64 loss: -2.5865964889526367
Batch 57/64 loss: -2.5441484451293945
Batch 58/64 loss: -2.6941213607788086
Batch 59/64 loss: -2.5831661224365234
Batch 60/64 loss: -2.7643814086914062
Batch 61/64 loss: -2.558652877807617
Batch 62/64 loss: -2.888155937194824
Batch 63/64 loss: -2.607832908630371
Batch 64/64 loss: -6.3277387619018555
Epoch 276  Train loss: -2.6071097168267943  Val loss: -2.8460361048118354
Epoch 277
-------------------------------
Batch 1/64 loss: -2.4858903884887695
Batch 2/64 loss: -2.6512975692749023
Batch 3/64 loss: -2.5713109970092773
Batch 4/64 loss: -2.903837203979492
Batch 5/64 loss: -2.3385744094848633
Batch 6/64 loss: -1.8633861541748047
Batch 7/64 loss: -2.6648616790771484
Batch 8/64 loss: -2.745333671569824
Batch 9/64 loss: -2.4357452392578125
Batch 10/64 loss: -2.929598808288574
Batch 11/64 loss: -2.653738021850586
Batch 12/64 loss: -2.7807750701904297
Batch 13/64 loss: -2.728374481201172
Batch 14/64 loss: -2.684332847595215
Batch 15/64 loss: -2.7056093215942383
Batch 16/64 loss: -2.557267189025879
Batch 17/64 loss: -2.6744308471679688
Batch 18/64 loss: -2.8046112060546875
Batch 19/64 loss: -2.2174301147460938
Batch 20/64 loss: -2.4684066772460938
Batch 21/64 loss: -2.7965097427368164
Batch 22/64 loss: -2.273770332336426
Batch 23/64 loss: -2.7385053634643555
Batch 24/64 loss: -2.972702980041504
Batch 25/64 loss: -2.5191516876220703
Batch 26/64 loss: -2.7320480346679688
Batch 27/64 loss: -2.6224918365478516
Batch 28/64 loss: -2.732272148132324
Batch 29/64 loss: -2.7474985122680664
Batch 30/64 loss: -2.6115684509277344
Batch 31/64 loss: -2.1899871826171875
Batch 32/64 loss: -1.9879274368286133
Batch 33/64 loss: -2.5246896743774414
Batch 34/64 loss: -2.6516952514648438
Batch 35/64 loss: -2.2996129989624023
Batch 36/64 loss: -2.492341995239258
Batch 37/64 loss: -2.290313720703125
Batch 38/64 loss: -2.559279441833496
Batch 39/64 loss: -2.258357048034668
Batch 40/64 loss: -2.283304214477539
Batch 41/64 loss: -2.7333192825317383
Batch 42/64 loss: -2.698474884033203
Batch 43/64 loss: -2.627260208129883
Batch 44/64 loss: -2.354161262512207
Batch 45/64 loss: -2.165299415588379
Batch 46/64 loss: -2.23909854888916
Batch 47/64 loss: -2.7088966369628906
Batch 48/64 loss: -2.6558914184570312
Batch 49/64 loss: -2.8172874450683594
Batch 50/64 loss: -2.785512924194336
Batch 51/64 loss: -2.8277177810668945
Batch 52/64 loss: -2.352447509765625
Batch 53/64 loss: -2.64693546295166
Batch 54/64 loss: -2.4242019653320312
Batch 55/64 loss: -2.785867691040039
Batch 56/64 loss: -2.594423294067383
Batch 57/64 loss: -2.6561622619628906
Batch 58/64 loss: -2.6874446868896484
Batch 59/64 loss: -2.2351455688476562
Batch 60/64 loss: -2.771608352661133
Batch 61/64 loss: -1.2487030029296875
Batch 62/64 loss: -2.661123275756836
Batch 63/64 loss: -2.5187177658081055
Batch 64/64 loss: -6.414836406707764
Epoch 277  Train loss: -2.5906771435457117  Val loss: -2.66591122551882
Epoch 278
-------------------------------
Batch 1/64 loss: -2.5532684326171875
Batch 2/64 loss: -2.473672866821289
Batch 3/64 loss: -2.0212392807006836
Batch 4/64 loss: -2.7099475860595703
Batch 5/64 loss: -2.760526657104492
Batch 6/64 loss: -2.6276559829711914
Batch 7/64 loss: 0.3448152542114258
Batch 8/64 loss: -1.6117191314697266
Batch 9/64 loss: -2.2365522384643555
Batch 10/64 loss: -2.713364601135254
Batch 11/64 loss: -2.786191940307617
Batch 12/64 loss: -0.9436826705932617
Batch 13/64 loss: -2.477330207824707
Batch 14/64 loss: -2.3976573944091797
Batch 15/64 loss: -2.614786148071289
Batch 16/64 loss: -2.49794864654541
Batch 17/64 loss: -2.1838998794555664
Batch 18/64 loss: -2.548609733581543
Batch 19/64 loss: -2.087925910949707
Batch 20/64 loss: -2.5651988983154297
Batch 21/64 loss: -2.607400894165039
Batch 22/64 loss: -2.717818260192871
Batch 23/64 loss: -2.622713088989258
Batch 24/64 loss: -2.072418212890625
Batch 25/64 loss: -2.4964895248413086
Batch 26/64 loss: -2.798922538757324
Batch 27/64 loss: -2.655947685241699
Batch 28/64 loss: -2.5927228927612305
Batch 29/64 loss: -2.3815879821777344
Batch 30/64 loss: -2.68515682220459
Batch 31/64 loss: -2.635106086730957
Batch 32/64 loss: -2.597903251647949
Batch 33/64 loss: -2.5030908584594727
Batch 34/64 loss: -2.773695945739746
Batch 35/64 loss: -2.7963266372680664
Batch 36/64 loss: -2.813488006591797
Batch 37/64 loss: -2.4980268478393555
Batch 38/64 loss: -2.7522687911987305
Batch 39/64 loss: -2.2348718643188477
Batch 40/64 loss: -2.876157760620117
Batch 41/64 loss: -2.721266746520996
Batch 42/64 loss: -2.7062950134277344
Batch 43/64 loss: -2.2438507080078125
Batch 44/64 loss: -2.248872756958008
Batch 45/64 loss: -2.699770927429199
Batch 46/64 loss: -2.491276741027832
Batch 47/64 loss: -2.560208320617676
Batch 48/64 loss: -2.510525703430176
Batch 49/64 loss: -2.5562267303466797
Batch 50/64 loss: -2.605785369873047
Batch 51/64 loss: -2.2277488708496094
Batch 52/64 loss: -2.5759239196777344
Batch 53/64 loss: -2.6921463012695312
Batch 54/64 loss: -2.6299829483032227
Batch 55/64 loss: -2.7301034927368164
Batch 56/64 loss: -2.6113595962524414
Batch 57/64 loss: -2.0655651092529297
Batch 58/64 loss: -2.6884326934814453
Batch 59/64 loss: -2.715940475463867
Batch 60/64 loss: -2.4020071029663086
Batch 61/64 loss: -2.4370546340942383
Batch 62/64 loss: -2.5779638290405273
Batch 63/64 loss: -2.956414222717285
Batch 64/64 loss: -7.366923809051514
Epoch 278  Train loss: -2.521700266295788  Val loss: -2.866170234286908
Epoch 279
-------------------------------
Batch 1/64 loss: -2.7537384033203125
Batch 2/64 loss: -2.703958511352539
Batch 3/64 loss: -2.674571990966797
Batch 4/64 loss: -2.5331220626831055
Batch 5/64 loss: -2.387094497680664
Batch 6/64 loss: -2.5128278732299805
Batch 7/64 loss: -2.5459518432617188
Batch 8/64 loss: -1.6469154357910156
Batch 9/64 loss: -2.68692684173584
Batch 10/64 loss: -2.468327522277832
Batch 11/64 loss: -2.733388900756836
Batch 12/64 loss: -2.469602584838867
Batch 13/64 loss: -2.8389968872070312
Batch 14/64 loss: -2.62697696685791
Batch 15/64 loss: -2.5257186889648438
Batch 16/64 loss: -2.489248275756836
Batch 17/64 loss: -2.651535987854004
Batch 18/64 loss: -2.577151298522949
Batch 19/64 loss: -2.1382761001586914
Batch 20/64 loss: -2.806529998779297
Batch 21/64 loss: -2.4604530334472656
Batch 22/64 loss: -2.2432098388671875
Batch 23/64 loss: -1.6759319305419922
Batch 24/64 loss: -2.7348203659057617
Batch 25/64 loss: -2.074831962585449
Batch 26/64 loss: -2.6464033126831055
Batch 27/64 loss: -2.583634376525879
Batch 28/64 loss: -2.6416893005371094
Batch 29/64 loss: -2.4559059143066406
Batch 30/64 loss: -2.672983169555664
Batch 31/64 loss: -2.759016990661621
Batch 32/64 loss: -2.253610610961914
Batch 33/64 loss: -2.693185806274414
Batch 34/64 loss: -2.8301525115966797
Batch 35/64 loss: -2.573833465576172
Batch 36/64 loss: -2.755782127380371
Batch 37/64 loss: -2.77957820892334
Batch 38/64 loss: -2.5475921630859375
Batch 39/64 loss: -2.3660078048706055
Batch 40/64 loss: -2.429910659790039
Batch 41/64 loss: -2.531796455383301
Batch 42/64 loss: -2.7033205032348633
Batch 43/64 loss: -2.755692481994629
Batch 44/64 loss: -0.9590835571289062
Batch 45/64 loss: -2.6248245239257812
Batch 46/64 loss: -2.846737861633301
Batch 47/64 loss: -2.6897754669189453
Batch 48/64 loss: -2.708099365234375
Batch 49/64 loss: -2.3152637481689453
Batch 50/64 loss: -2.8964319229125977
Batch 51/64 loss: -2.7945556640625
Batch 52/64 loss: -2.8117828369140625
Batch 53/64 loss: -2.084575653076172
Batch 54/64 loss: -2.6119260787963867
Batch 55/64 loss: -2.252267837524414
Batch 56/64 loss: -2.71219539642334
Batch 57/64 loss: -2.553976058959961
Batch 58/64 loss: -2.0362768173217773
Batch 59/64 loss: -2.2606630325317383
Batch 60/64 loss: -2.6958541870117188
Batch 61/64 loss: -2.390653610229492
Batch 62/64 loss: -2.904965400695801
Batch 63/64 loss: -2.563882827758789
Batch 64/64 loss: -7.099893093109131
Epoch 279  Train loss: -2.5722182797450643  Val loss: -2.3338205265425325
Epoch 280
-------------------------------
Batch 1/64 loss: -2.617330551147461
Batch 2/64 loss: -2.516432762145996
Batch 3/64 loss: -1.818375587463379
Batch 4/64 loss: -2.5803298950195312
Batch 5/64 loss: -1.8905906677246094
Batch 6/64 loss: -2.493075370788574
Batch 7/64 loss: -2.534029006958008
Batch 8/64 loss: -2.3913326263427734
Batch 9/64 loss: -2.609654426574707
Batch 10/64 loss: -2.485978126525879
Batch 11/64 loss: -2.4753217697143555
Batch 12/64 loss: -2.669313430786133
Batch 13/64 loss: -2.421402931213379
Batch 14/64 loss: -2.6968088150024414
Batch 15/64 loss: -2.203526496887207
Batch 16/64 loss: -2.7189207077026367
Batch 17/64 loss: -2.348761558532715
Batch 18/64 loss: -2.2147817611694336
Batch 19/64 loss: -2.490584373474121
Batch 20/64 loss: -2.1078367233276367
Batch 21/64 loss: -2.444321632385254
Batch 22/64 loss: -2.382378578186035
Batch 23/64 loss: -2.5817813873291016
Batch 24/64 loss: -2.605640411376953
Batch 25/64 loss: -2.5897340774536133
Batch 26/64 loss: -2.3152894973754883
Batch 27/64 loss: -2.602301597595215
Batch 28/64 loss: -2.5424604415893555
Batch 29/64 loss: -2.4856491088867188
Batch 30/64 loss: -2.39023494720459
Batch 31/64 loss: -2.458505630493164
Batch 32/64 loss: -2.571438789367676
Batch 33/64 loss: -2.394733428955078
Batch 34/64 loss: -2.5857467651367188
Batch 35/64 loss: -2.312070846557617
Batch 36/64 loss: -2.7098846435546875
Batch 37/64 loss: -2.6104421615600586
Batch 38/64 loss: -2.6191015243530273
Batch 39/64 loss: -2.188333511352539
Batch 40/64 loss: -2.537135124206543
Batch 41/64 loss: -2.2745370864868164
Batch 42/64 loss: -2.590695381164551
Batch 43/64 loss: -2.3825387954711914
Batch 44/64 loss: -2.1012144088745117
Batch 45/64 loss: -2.3947830200195312
Batch 46/64 loss: -2.525493621826172
Batch 47/64 loss: -2.7094907760620117
Batch 48/64 loss: -2.348705291748047
Batch 49/64 loss: -2.668466567993164
Batch 50/64 loss: -2.175273895263672
Batch 51/64 loss: -2.7596330642700195
Batch 52/64 loss: -1.7772760391235352
Batch 53/64 loss: -2.3282318115234375
Batch 54/64 loss: -2.2212915420532227
Batch 55/64 loss: -2.649226188659668
Batch 56/64 loss: -2.7983083724975586
Batch 57/64 loss: -2.702450752258301
Batch 58/64 loss: -2.7842350006103516
Batch 59/64 loss: -2.5698471069335938
Batch 60/64 loss: -2.757152557373047
Batch 61/64 loss: -2.7711143493652344
Batch 62/64 loss: -2.643838882446289
Batch 63/64 loss: -2.4974117279052734
Batch 64/64 loss: -7.103377342224121
Epoch 280  Train loss: -2.5250246421963563  Val loss: -2.9356138747172666
Epoch 281
-------------------------------
Batch 1/64 loss: -2.827908515930176
Batch 2/64 loss: -2.7983102798461914
Batch 3/64 loss: -2.7459917068481445
Batch 4/64 loss: -2.853837013244629
Batch 5/64 loss: -2.54556941986084
Batch 6/64 loss: -2.670103073120117
Batch 7/64 loss: -2.580327033996582
Batch 8/64 loss: -2.763120651245117
Batch 9/64 loss: -2.8219032287597656
Batch 10/64 loss: -2.89229679107666
Batch 11/64 loss: -2.2684621810913086
Batch 12/64 loss: -2.7812700271606445
Batch 13/64 loss: -2.502330780029297
Batch 14/64 loss: -2.837876319885254
Batch 15/64 loss: -2.5675554275512695
Batch 16/64 loss: -2.6761341094970703
Batch 17/64 loss: -2.152385711669922
Batch 18/64 loss: -2.5315093994140625
Batch 19/64 loss: -2.6319580078125
Batch 20/64 loss: -2.416295051574707
Batch 21/64 loss: -2.408061981201172
Batch 22/64 loss: -2.5268125534057617
Batch 23/64 loss: -2.2738752365112305
Batch 24/64 loss: -2.7988643646240234
Batch 25/64 loss: -2.8491125106811523
Batch 26/64 loss: -2.8274431228637695
Batch 27/64 loss: -2.853907585144043
Batch 28/64 loss: -2.8401880264282227
Batch 29/64 loss: -2.5764808654785156
Batch 30/64 loss: -2.6427507400512695
Batch 31/64 loss: -2.479785919189453
Batch 32/64 loss: -2.488297462463379
Batch 33/64 loss: -2.5084266662597656
Batch 34/64 loss: -2.3720998764038086
Batch 35/64 loss: -2.54677677154541
Batch 36/64 loss: -2.6439123153686523
Batch 37/64 loss: -2.603854179382324
Batch 38/64 loss: -2.0886497497558594
Batch 39/64 loss: -2.5256471633911133
Batch 40/64 loss: -2.5613021850585938
Batch 41/64 loss: -1.756103515625
Batch 42/64 loss: -2.50815486907959
Batch 43/64 loss: -2.6054821014404297
Batch 44/64 loss: -2.8029069900512695
Batch 45/64 loss: -2.496455192565918
Batch 46/64 loss: -2.7118988037109375
Batch 47/64 loss: -2.5414581298828125
Batch 48/64 loss: -2.794984817504883
Batch 49/64 loss: -2.419208526611328
Batch 50/64 loss: -2.7643213272094727
Batch 51/64 loss: -2.532106399536133
Batch 52/64 loss: -1.9532461166381836
Batch 53/64 loss: -2.8127098083496094
Batch 54/64 loss: -2.2637939453125
Batch 55/64 loss: -2.703615188598633
Batch 56/64 loss: -2.6094837188720703
Batch 57/64 loss: -2.6440887451171875
Batch 58/64 loss: -2.6704540252685547
Batch 59/64 loss: -2.43997859954834
Batch 60/64 loss: -2.550387382507324
Batch 61/64 loss: -2.723966598510742
Batch 62/64 loss: -2.513843536376953
Batch 63/64 loss: -2.516498565673828
Batch 64/64 loss: -7.04826021194458
Epoch 281  Train loss: -2.633768408906226  Val loss: -2.739900700415123
Epoch 282
-------------------------------
Batch 1/64 loss: -2.665090560913086
Batch 2/64 loss: -2.608157157897949
Batch 3/64 loss: -2.461920738220215
Batch 4/64 loss: -2.5677928924560547
Batch 5/64 loss: -2.5127954483032227
Batch 6/64 loss: -1.7777948379516602
Batch 7/64 loss: -2.743741035461426
Batch 8/64 loss: -2.5484180450439453
Batch 9/64 loss: -2.479182243347168
Batch 10/64 loss: -2.6722116470336914
Batch 11/64 loss: -2.7532644271850586
Batch 12/64 loss: -2.1884193420410156
Batch 13/64 loss: -2.377643585205078
Batch 14/64 loss: -2.3116912841796875
Batch 15/64 loss: -2.548259735107422
Batch 16/64 loss: -2.5766563415527344
Batch 17/64 loss: -2.7059593200683594
Batch 18/64 loss: -2.3819732666015625
Batch 19/64 loss: -2.0933837890625
Batch 20/64 loss: -2.236124038696289
Batch 21/64 loss: -2.522536277770996
Batch 22/64 loss: -2.6885242462158203
Batch 23/64 loss: -2.750997543334961
Batch 24/64 loss: -2.9184789657592773
Batch 25/64 loss: -2.71712589263916
Batch 26/64 loss: -2.629850387573242
Batch 27/64 loss: -2.672456741333008
Batch 28/64 loss: -2.4233617782592773
Batch 29/64 loss: -2.2850475311279297
Batch 30/64 loss: -2.809549331665039
Batch 31/64 loss: -2.2125463485717773
Batch 32/64 loss: -2.734434127807617
Batch 33/64 loss: -2.6844959259033203
Batch 34/64 loss: -2.714618682861328
Batch 35/64 loss: -2.7544336318969727
Batch 36/64 loss: -2.7415246963500977
Batch 37/64 loss: -2.713886260986328
Batch 38/64 loss: -2.5770063400268555
Batch 39/64 loss: -2.834209442138672
Batch 40/64 loss: -2.5130577087402344
Batch 41/64 loss: -2.8264007568359375
Batch 42/64 loss: -2.656524658203125
Batch 43/64 loss: -2.641739845275879
Batch 44/64 loss: -2.6493844985961914
Batch 45/64 loss: -2.6190338134765625
Batch 46/64 loss: -2.805295944213867
Batch 47/64 loss: -2.072002410888672
Batch 48/64 loss: -2.2333602905273438
Batch 49/64 loss: -2.5336055755615234
Batch 50/64 loss: -2.8109331130981445
Batch 51/64 loss: -2.4673547744750977
Batch 52/64 loss: -2.766543388366699
Batch 53/64 loss: -2.5693302154541016
Batch 54/64 loss: -2.7434816360473633
Batch 55/64 loss: -2.2772035598754883
Batch 56/64 loss: -2.821671485900879
Batch 57/64 loss: -2.6260766983032227
Batch 58/64 loss: -2.4351110458374023
Batch 59/64 loss: -2.7749862670898438
Batch 60/64 loss: -2.218414306640625
Batch 61/64 loss: -2.575161933898926
Batch 62/64 loss: -2.449491500854492
Batch 63/64 loss: -2.430145263671875
Batch 64/64 loss: -6.835002899169922
Epoch 282  Train loss: -2.6076568902707566  Val loss: -2.8167596010817695
Epoch 283
-------------------------------
Batch 1/64 loss: -2.385045051574707
Batch 2/64 loss: -2.3980636596679688
Batch 3/64 loss: -2.6079864501953125
Batch 4/64 loss: -2.8306074142456055
Batch 5/64 loss: -1.712895393371582
Batch 6/64 loss: -2.607147216796875
Batch 7/64 loss: -2.5535669326782227
Batch 8/64 loss: -2.5608272552490234
Batch 9/64 loss: -2.6918554306030273
Batch 10/64 loss: -2.7014970779418945
Batch 11/64 loss: -2.447525978088379
Batch 12/64 loss: -2.6977710723876953
Batch 13/64 loss: -2.5633726119995117
Batch 14/64 loss: -2.5580272674560547
Batch 15/64 loss: -2.3324365615844727
Batch 16/64 loss: -2.563124656677246
Batch 17/64 loss: -2.859808921813965
Batch 18/64 loss: -2.504793167114258
Batch 19/64 loss: -2.6780567169189453
Batch 20/64 loss: -2.7667675018310547
Batch 21/64 loss: -2.58573055267334
Batch 22/64 loss: -2.037652015686035
Batch 23/64 loss: -2.401193618774414
Batch 24/64 loss: -2.577763557434082
Batch 25/64 loss: -2.7714929580688477
Batch 26/64 loss: -2.519350051879883
Batch 27/64 loss: -2.700315475463867
Batch 28/64 loss: -2.759307861328125
Batch 29/64 loss: -2.4624195098876953
Batch 30/64 loss: -2.498342514038086
Batch 31/64 loss: -2.528322219848633
Batch 32/64 loss: -2.594118118286133
Batch 33/64 loss: -2.9174118041992188
Batch 34/64 loss: -2.664036750793457
Batch 35/64 loss: -2.5406532287597656
Batch 36/64 loss: -2.638031005859375
Batch 37/64 loss: -2.7233009338378906
Batch 38/64 loss: -2.475846290588379
Batch 39/64 loss: -2.53269100189209
Batch 40/64 loss: -2.7365541458129883
Batch 41/64 loss: -2.457577705383301
Batch 42/64 loss: -2.585052490234375
Batch 43/64 loss: -2.8271560668945312
Batch 44/64 loss: -2.7468461990356445
Batch 45/64 loss: -2.543764114379883
Batch 46/64 loss: -2.6209945678710938
Batch 47/64 loss: -2.597052574157715
Batch 48/64 loss: -2.8745861053466797
Batch 49/64 loss: -2.541834831237793
Batch 50/64 loss: -2.8579769134521484
Batch 51/64 loss: -2.716519355773926
Batch 52/64 loss: -2.3677291870117188
Batch 53/64 loss: -2.725431442260742
Batch 54/64 loss: -2.667962074279785
Batch 55/64 loss: -1.5847606658935547
Batch 56/64 loss: -2.7365245819091797
Batch 57/64 loss: -2.78035831451416
Batch 58/64 loss: -2.73763370513916
Batch 59/64 loss: -2.5002269744873047
Batch 60/64 loss: -2.6515722274780273
Batch 61/64 loss: -2.686202049255371
Batch 62/64 loss: -2.620049476623535
Batch 63/64 loss: -2.2728872299194336
Batch 64/64 loss: -7.045353889465332
Epoch 283  Train loss: -2.6301243015364104  Val loss: -2.8550744335266325
Epoch 284
-------------------------------
Batch 1/64 loss: -2.558102607727051
Batch 2/64 loss: -2.6035032272338867
Batch 3/64 loss: -2.1255569458007812
Batch 4/64 loss: -2.9220705032348633
Batch 5/64 loss: -2.8000707626342773
Batch 6/64 loss: -2.7619800567626953
Batch 7/64 loss: -2.3545541763305664
Batch 8/64 loss: -2.7500667572021484
Batch 9/64 loss: -2.757251739501953
Batch 10/64 loss: -2.770669937133789
Batch 11/64 loss: -3.0404605865478516
Batch 12/64 loss: -2.673128128051758
Batch 13/64 loss: -1.4907474517822266
Batch 14/64 loss: -2.4604177474975586
Batch 15/64 loss: -2.201249122619629
Batch 16/64 loss: -2.6931629180908203
Batch 17/64 loss: -2.628683090209961
Batch 18/64 loss: -2.5735387802124023
Batch 19/64 loss: -2.3503522872924805
Batch 20/64 loss: -2.6060495376586914
Batch 21/64 loss: -2.189822196960449
Batch 22/64 loss: -2.6457509994506836
Batch 23/64 loss: -2.610283851623535
Batch 24/64 loss: -2.423090934753418
Batch 25/64 loss: -2.7181644439697266
Batch 26/64 loss: -2.756730079650879
Batch 27/64 loss: -2.5118398666381836
Batch 28/64 loss: -2.6935644149780273
Batch 29/64 loss: -2.786663055419922
Batch 30/64 loss: -2.7661266326904297
Batch 31/64 loss: -2.490995407104492
Batch 32/64 loss: -2.0956315994262695
Batch 33/64 loss: -2.7276058197021484
Batch 34/64 loss: -2.559375762939453
Batch 35/64 loss: -2.2862939834594727
Batch 36/64 loss: -2.398861885070801
Batch 37/64 loss: -2.6575193405151367
Batch 38/64 loss: -2.144404411315918
Batch 39/64 loss: -2.4554548263549805
Batch 40/64 loss: -2.548712730407715
Batch 41/64 loss: -2.5683231353759766
Batch 42/64 loss: -2.493931770324707
Batch 43/64 loss: -2.467116355895996
Batch 44/64 loss: -2.367375373840332
Batch 45/64 loss: -2.6357173919677734
Batch 46/64 loss: -2.809494972229004
Batch 47/64 loss: -2.092291831970215
Batch 48/64 loss: -2.4150161743164062
Batch 49/64 loss: -2.4924917221069336
Batch 50/64 loss: -2.3912296295166016
Batch 51/64 loss: -2.614291191101074
Batch 52/64 loss: -2.698225975036621
Batch 53/64 loss: -2.2723493576049805
Batch 54/64 loss: -1.6997785568237305
Batch 55/64 loss: -2.803267478942871
Batch 56/64 loss: -2.2711849212646484
Batch 57/64 loss: -2.5294103622436523
Batch 58/64 loss: -2.393021583557129
Batch 59/64 loss: -2.455803871154785
Batch 60/64 loss: -2.0864791870117188
Batch 61/64 loss: -2.778165817260742
Batch 62/64 loss: -2.6066274642944336
Batch 63/64 loss: -2.336268424987793
Batch 64/64 loss: -6.840342044830322
Epoch 284  Train loss: -2.5568098460926727  Val loss: -2.8723382196065894
Epoch 285
-------------------------------
Batch 1/64 loss: -2.6131134033203125
Batch 2/64 loss: -2.6889820098876953
Batch 3/64 loss: -2.626972198486328
Batch 4/64 loss: -2.5835447311401367
Batch 5/64 loss: -2.031804084777832
Batch 6/64 loss: -2.641826629638672
Batch 7/64 loss: -2.630446434020996
Batch 8/64 loss: -2.5079574584960938
Batch 9/64 loss: -2.7480669021606445
Batch 10/64 loss: -2.6839914321899414
Batch 11/64 loss: -2.1435375213623047
Batch 12/64 loss: -2.854276657104492
Batch 13/64 loss: -2.6479434967041016
Batch 14/64 loss: -2.752960205078125
Batch 15/64 loss: -1.7206239700317383
Batch 16/64 loss: -1.9042854309082031
Batch 17/64 loss: -2.5779571533203125
Batch 18/64 loss: -2.6274852752685547
Batch 19/64 loss: -2.7804555892944336
Batch 20/64 loss: -2.520040512084961
Batch 21/64 loss: -2.509296417236328
Batch 22/64 loss: -2.549245834350586
Batch 23/64 loss: -2.7548904418945312
Batch 24/64 loss: -2.5937910079956055
Batch 25/64 loss: -2.4804859161376953
Batch 26/64 loss: -2.7618064880371094
Batch 27/64 loss: -2.8046140670776367
Batch 28/64 loss: -2.468796730041504
Batch 29/64 loss: -2.4668502807617188
Batch 30/64 loss: -2.275461196899414
Batch 31/64 loss: -2.7894668579101562
Batch 32/64 loss: -2.073666572570801
Batch 33/64 loss: -2.6873931884765625
Batch 34/64 loss: -2.4345340728759766
Batch 35/64 loss: -2.5234766006469727
Batch 36/64 loss: -1.7303791046142578
Batch 37/64 loss: -2.7620973587036133
Batch 38/64 loss: -2.2927560806274414
Batch 39/64 loss: -2.1560401916503906
Batch 40/64 loss: -2.6823034286499023
Batch 41/64 loss: -2.308412551879883
Batch 42/64 loss: -2.6747941970825195
Batch 43/64 loss: -2.614839553833008
Batch 44/64 loss: -2.3405017852783203
Batch 45/64 loss: -2.418543815612793
Batch 46/64 loss: -2.6432857513427734
Batch 47/64 loss: -2.432485580444336
Batch 48/64 loss: -2.682162284851074
Batch 49/64 loss: -2.1524486541748047
Batch 50/64 loss: -2.3310508728027344
Batch 51/64 loss: -2.142324447631836
Batch 52/64 loss: -2.167591094970703
Batch 53/64 loss: -2.310481071472168
Batch 54/64 loss: -2.626185417175293
Batch 55/64 loss: -2.0709095001220703
Batch 56/64 loss: -2.556063652038574
Batch 57/64 loss: -2.4954614639282227
Batch 58/64 loss: -2.4639081954956055
Batch 59/64 loss: -2.5681819915771484
Batch 60/64 loss: -2.372542381286621
Batch 61/64 loss: -2.4268598556518555
Batch 62/64 loss: -2.6749134063720703
Batch 63/64 loss: -2.6935338973999023
Batch 64/64 loss: -7.097285270690918
Epoch 285  Train loss: -2.534495189143162  Val loss: -2.8380917945678292
Epoch 286
-------------------------------
Batch 1/64 loss: -2.836453437805176
Batch 2/64 loss: -2.5326128005981445
Batch 3/64 loss: -2.526266098022461
Batch 4/64 loss: -2.319782257080078
Batch 5/64 loss: -2.592254638671875
Batch 6/64 loss: -2.597736358642578
Batch 7/64 loss: -2.7108240127563477
Batch 8/64 loss: -2.3056421279907227
Batch 9/64 loss: -2.445204734802246
Batch 10/64 loss: -2.3620529174804688
Batch 11/64 loss: -2.6862316131591797
Batch 12/64 loss: -1.6430635452270508
Batch 13/64 loss: -2.1485042572021484
Batch 14/64 loss: -2.544525146484375
Batch 15/64 loss: -2.586883544921875
Batch 16/64 loss: -2.7328414916992188
Batch 17/64 loss: -2.3710527420043945
Batch 18/64 loss: -2.3452329635620117
Batch 19/64 loss: -2.606234550476074
Batch 20/64 loss: -2.5076465606689453
Batch 21/64 loss: -2.6038331985473633
Batch 22/64 loss: -2.737137794494629
Batch 23/64 loss: -2.530423164367676
Batch 24/64 loss: -2.683016777038574
Batch 25/64 loss: -2.5770301818847656
Batch 26/64 loss: -2.6818408966064453
Batch 27/64 loss: -2.320955276489258
Batch 28/64 loss: -2.603762626647949
Batch 29/64 loss: -2.5151405334472656
Batch 30/64 loss: -2.5496578216552734
Batch 31/64 loss: -2.404179573059082
Batch 32/64 loss: -2.570206642150879
Batch 33/64 loss: -2.5182676315307617
Batch 34/64 loss: -2.2966079711914062
Batch 35/64 loss: -2.660853385925293
Batch 36/64 loss: -2.745863914489746
Batch 37/64 loss: -2.6431169509887695
Batch 38/64 loss: -2.2033767700195312
Batch 39/64 loss: -2.738971710205078
Batch 40/64 loss: -2.5996551513671875
Batch 41/64 loss: -2.4771556854248047
Batch 42/64 loss: -2.44687557220459
Batch 43/64 loss: -2.3189697265625
Batch 44/64 loss: -2.6829967498779297
Batch 45/64 loss: -2.3733367919921875
Batch 46/64 loss: -2.731904983520508
Batch 47/64 loss: -2.52095890045166
Batch 48/64 loss: -2.683868408203125
Batch 49/64 loss: -2.6658973693847656
Batch 50/64 loss: -2.2737865447998047
Batch 51/64 loss: -2.682453155517578
Batch 52/64 loss: -2.491726875305176
Batch 53/64 loss: -2.54329776763916
Batch 54/64 loss: -2.4941396713256836
Batch 55/64 loss: -2.134823799133301
Batch 56/64 loss: -2.770814895629883
Batch 57/64 loss: -2.3060150146484375
Batch 58/64 loss: -2.716097831726074
Batch 59/64 loss: -1.8808660507202148
Batch 60/64 loss: -2.446168899536133
Batch 61/64 loss: -2.296772003173828
Batch 62/64 loss: -2.372368812561035
Batch 63/64 loss: -2.6345109939575195
Batch 64/64 loss: -6.889746189117432
Epoch 286  Train loss: -2.5521264300626867  Val loss: -2.732157913679929
Epoch 287
-------------------------------
Batch 1/64 loss: -2.431796073913574
Batch 2/64 loss: -2.558417320251465
Batch 3/64 loss: -2.3578271865844727
Batch 4/64 loss: -2.3605051040649414
Batch 5/64 loss: -2.577652931213379
Batch 6/64 loss: -2.2696609497070312
Batch 7/64 loss: -2.558429718017578
Batch 8/64 loss: -2.5279598236083984
Batch 9/64 loss: -2.711353302001953
Batch 10/64 loss: -1.9382877349853516
Batch 11/64 loss: -2.4510326385498047
Batch 12/64 loss: -2.502035140991211
Batch 13/64 loss: -2.171571731567383
Batch 14/64 loss: -2.617511749267578
Batch 15/64 loss: -2.505429267883301
Batch 16/64 loss: -2.458123207092285
Batch 17/64 loss: -2.34250545501709
Batch 18/64 loss: -1.7654266357421875
Batch 19/64 loss: -2.5280838012695312
Batch 20/64 loss: -2.449896812438965
Batch 21/64 loss: -2.6808319091796875
Batch 22/64 loss: -2.2678260803222656
Batch 23/64 loss: -2.6165075302124023
Batch 24/64 loss: -2.4738845825195312
Batch 25/64 loss: -2.4097843170166016
Batch 26/64 loss: -2.810098648071289
Batch 27/64 loss: -2.5058364868164062
Batch 28/64 loss: -2.64548397064209
Batch 29/64 loss: -2.3188276290893555
Batch 30/64 loss: -2.4218692779541016
Batch 31/64 loss: -2.585023880004883
Batch 32/64 loss: -2.619725227355957
Batch 33/64 loss: -2.544107437133789
Batch 34/64 loss: -2.1912403106689453
Batch 35/64 loss: -2.507049560546875
Batch 36/64 loss: -2.7953386306762695
Batch 37/64 loss: -2.68862247467041
Batch 38/64 loss: -2.54266357421875
Batch 39/64 loss: -2.598794937133789
Batch 40/64 loss: -2.5209760665893555
Batch 41/64 loss: -1.9986019134521484
Batch 42/64 loss: -2.1244468688964844
Batch 43/64 loss: -2.5765295028686523
Batch 44/64 loss: -2.488780975341797
Batch 45/64 loss: -2.5711259841918945
Batch 46/64 loss: -2.5380449295043945
Batch 47/64 loss: -2.4855613708496094
Batch 48/64 loss: -2.4758472442626953
Batch 49/64 loss: -2.6807775497436523
Batch 50/64 loss: -2.4738969802856445
Batch 51/64 loss: -2.3289613723754883
Batch 52/64 loss: -2.6592721939086914
Batch 53/64 loss: -2.548398017883301
Batch 54/64 loss: -2.4357919692993164
Batch 55/64 loss: -2.598672866821289
Batch 56/64 loss: -2.6293821334838867
Batch 57/64 loss: -2.581430435180664
Batch 58/64 loss: -2.515472412109375
Batch 59/64 loss: -2.6700897216796875
Batch 60/64 loss: -2.4863929748535156
Batch 61/64 loss: -1.8905792236328125
Batch 62/64 loss: -2.5987701416015625
Batch 63/64 loss: -2.655454635620117
Batch 64/64 loss: -6.772867202758789
Epoch 287  Train loss: -2.5242342107436238  Val loss: -2.866796919570346
Epoch 288
-------------------------------
Batch 1/64 loss: -2.549053192138672
Batch 2/64 loss: -2.3892154693603516
Batch 3/64 loss: -2.549558639526367
Batch 4/64 loss: -2.738633155822754
Batch 5/64 loss: -2.6761245727539062
Batch 6/64 loss: -2.4206762313842773
Batch 7/64 loss: -2.5984182357788086
Batch 8/64 loss: -2.4682846069335938
Batch 9/64 loss: -2.6984100341796875
Batch 10/64 loss: -2.6754465103149414
Batch 11/64 loss: -2.226358413696289
Batch 12/64 loss: -2.217622756958008
Batch 13/64 loss: -2.706028938293457
Batch 14/64 loss: -2.673318862915039
Batch 15/64 loss: -2.706467628479004
Batch 16/64 loss: -2.505352020263672
Batch 17/64 loss: -2.447972297668457
Batch 18/64 loss: -2.6393871307373047
Batch 19/64 loss: -2.714418411254883
Batch 20/64 loss: -2.601071357727051
Batch 21/64 loss: -2.4721174240112305
Batch 22/64 loss: -2.3964223861694336
Batch 23/64 loss: -2.8231821060180664
Batch 24/64 loss: -2.6209592819213867
Batch 25/64 loss: -2.764741897583008
Batch 26/64 loss: -2.56418514251709
Batch 27/64 loss: -2.6812658309936523
Batch 28/64 loss: -2.6035118103027344
Batch 29/64 loss: -2.7239980697631836
Batch 30/64 loss: -2.148686408996582
Batch 31/64 loss: -2.6721267700195312
Batch 32/64 loss: -2.645975112915039
Batch 33/64 loss: -2.117363929748535
Batch 34/64 loss: -2.425434112548828
Batch 35/64 loss: -2.609574317932129
Batch 36/64 loss: -2.617856979370117
Batch 37/64 loss: -2.679081916809082
Batch 38/64 loss: -2.69442081451416
Batch 39/64 loss: -2.1655235290527344
Batch 40/64 loss: -2.5447540283203125
Batch 41/64 loss: -1.6334810256958008
Batch 42/64 loss: -2.0097293853759766
Batch 43/64 loss: -2.6627674102783203
Batch 44/64 loss: -2.1785402297973633
Batch 45/64 loss: -2.527742385864258
Batch 46/64 loss: -2.6946048736572266
Batch 47/64 loss: -2.465376853942871
Batch 48/64 loss: -2.578017234802246
Batch 49/64 loss: -2.505535125732422
Batch 50/64 loss: -2.680055618286133
Batch 51/64 loss: -2.209596633911133
Batch 52/64 loss: -2.1676177978515625
Batch 53/64 loss: -2.9097394943237305
Batch 54/64 loss: -2.436720848083496
Batch 55/64 loss: -2.7797327041625977
Batch 56/64 loss: -2.4378719329833984
Batch 57/64 loss: -2.545583724975586
Batch 58/64 loss: -2.7306671142578125
Batch 59/64 loss: -2.434122085571289
Batch 60/64 loss: -2.5181350708007812
Batch 61/64 loss: -2.647843360900879
Batch 62/64 loss: -2.637284278869629
Batch 63/64 loss: -2.5427350997924805
Batch 64/64 loss: -7.2362189292907715
Epoch 288  Train loss: -2.5809202325110343  Val loss: -2.9319851799928855
Epoch 289
-------------------------------
Batch 1/64 loss: -2.700847625732422
Batch 2/64 loss: -2.6281604766845703
Batch 3/64 loss: -2.915522575378418
Batch 4/64 loss: -2.523488998413086
Batch 5/64 loss: -2.662778854370117
Batch 6/64 loss: -2.621504783630371
Batch 7/64 loss: -2.621278762817383
Batch 8/64 loss: -2.7983789443969727
Batch 9/64 loss: -2.298063278198242
Batch 10/64 loss: -2.6018409729003906
Batch 11/64 loss: -2.576279640197754
Batch 12/64 loss: -2.6049747467041016
Batch 13/64 loss: -2.580111503601074
Batch 14/64 loss: -2.6923723220825195
Batch 15/64 loss: -2.7809553146362305
Batch 16/64 loss: -2.514636993408203
Batch 17/64 loss: -2.8790626525878906
Batch 18/64 loss: -2.5882434844970703
Batch 19/64 loss: -2.8495559692382812
Batch 20/64 loss: -2.49410343170166
Batch 21/64 loss: -2.2356910705566406
Batch 22/64 loss: -2.6669435501098633
Batch 23/64 loss: -2.8259992599487305
Batch 24/64 loss: -2.624373435974121
Batch 25/64 loss: -2.671200752258301
Batch 26/64 loss: -2.4251928329467773
Batch 27/64 loss: -2.480311393737793
Batch 28/64 loss: -2.629086494445801
Batch 29/64 loss: -2.662172317504883
Batch 30/64 loss: -2.6939210891723633
Batch 31/64 loss: -2.7522048950195312
Batch 32/64 loss: -2.6980628967285156
Batch 33/64 loss: -2.5239667892456055
Batch 34/64 loss: -2.839118003845215
Batch 35/64 loss: -2.8665008544921875
Batch 36/64 loss: -2.833932876586914
Batch 37/64 loss: -2.558661460876465
Batch 38/64 loss: -2.626938819885254
Batch 39/64 loss: -2.5353479385375977
Batch 40/64 loss: -2.654269218444824
Batch 41/64 loss: -2.727479934692383
Batch 42/64 loss: -2.20493221282959
Batch 43/64 loss: -2.684781074523926
Batch 44/64 loss: -2.4527530670166016
Batch 45/64 loss: -2.7461137771606445
Batch 46/64 loss: -2.7733564376831055
Batch 47/64 loss: -2.808408737182617
Batch 48/64 loss: -2.7878875732421875
Batch 49/64 loss: -2.670964241027832
Batch 50/64 loss: -2.8495187759399414
Batch 51/64 loss: -2.5238685607910156
Batch 52/64 loss: -2.792416572570801
Batch 53/64 loss: -1.8103837966918945
Batch 54/64 loss: -2.708700180053711
Batch 55/64 loss: -2.560847282409668
Batch 56/64 loss: -2.600722312927246
Batch 57/64 loss: -1.9882526397705078
Batch 58/64 loss: -2.4702072143554688
Batch 59/64 loss: -2.7076826095581055
Batch 60/64 loss: -2.1277828216552734
Batch 61/64 loss: -2.8070297241210938
Batch 62/64 loss: -2.7796506881713867
Batch 63/64 loss: -2.573910713195801
Batch 64/64 loss: -7.017652988433838
Epoch 289  Train loss: -2.669128595613966  Val loss: -2.8539311517145216
Epoch 290
-------------------------------
Batch 1/64 loss: -2.8049325942993164
Batch 2/64 loss: -2.540630340576172
Batch 3/64 loss: -2.737553596496582
Batch 4/64 loss: -2.5806331634521484
Batch 5/64 loss: -2.7258481979370117
Batch 6/64 loss: -2.5549840927124023
Batch 7/64 loss: -2.4751815795898438
Batch 8/64 loss: -2.731276512145996
Batch 9/64 loss: -2.3836612701416016
Batch 10/64 loss: -2.708226203918457
Batch 11/64 loss: -2.471146583557129
Batch 12/64 loss: -2.8531980514526367
Batch 13/64 loss: -2.5726499557495117
Batch 14/64 loss: -1.7977867126464844
Batch 15/64 loss: -2.7980403900146484
Batch 16/64 loss: -2.633026123046875
Batch 17/64 loss: -2.3136558532714844
Batch 18/64 loss: -2.948759078979492
Batch 19/64 loss: -2.771498680114746
Batch 20/64 loss: -2.7808361053466797
Batch 21/64 loss: -2.7241439819335938
Batch 22/64 loss: -2.8082733154296875
Batch 23/64 loss: -2.6748275756835938
Batch 24/64 loss: -2.7132768630981445
Batch 25/64 loss: -2.7488317489624023
Batch 26/64 loss: -2.8500757217407227
Batch 27/64 loss: -2.6088857650756836
Batch 28/64 loss: -2.761350631713867
Batch 29/64 loss: -2.90969181060791
Batch 30/64 loss: -2.5784482955932617
Batch 31/64 loss: -2.862346649169922
Batch 32/64 loss: -2.531444549560547
Batch 33/64 loss: -1.978928565979004
Batch 34/64 loss: -2.792189598083496
Batch 35/64 loss: -2.471165657043457
Batch 36/64 loss: -2.8268213272094727
Batch 37/64 loss: -2.6844444274902344
Batch 38/64 loss: -2.8525829315185547
Batch 39/64 loss: -2.6789636611938477
Batch 40/64 loss: -2.3803367614746094
Batch 41/64 loss: -2.446305274963379
Batch 42/64 loss: -2.680792808532715
Batch 43/64 loss: -2.610044479370117
Batch 44/64 loss: -2.5940160751342773
Batch 45/64 loss: -2.575887680053711
Batch 46/64 loss: -2.146115303039551
Batch 47/64 loss: -2.339968681335449
Batch 48/64 loss: -2.624746322631836
Batch 49/64 loss: -2.384218215942383
Batch 50/64 loss: -2.2510900497436523
Batch 51/64 loss: -2.7594566345214844
Batch 52/64 loss: -2.483210563659668
Batch 53/64 loss: -2.776447296142578
Batch 54/64 loss: -2.4412641525268555
Batch 55/64 loss: -2.6379165649414062
Batch 56/64 loss: -2.512120246887207
Batch 57/64 loss: -2.454287528991699
Batch 58/64 loss: -2.7910690307617188
Batch 59/64 loss: -2.8078880310058594
Batch 60/64 loss: -2.7417640686035156
Batch 61/64 loss: -2.806838035583496
Batch 62/64 loss: -2.814345359802246
Batch 63/64 loss: -2.5099716186523438
Batch 64/64 loss: -7.0204997062683105
Epoch 290  Train loss: -2.667854019239837  Val loss: -2.926836492269719
Epoch 291
-------------------------------
Batch 1/64 loss: -2.858163833618164
Batch 2/64 loss: -2.778641700744629
Batch 3/64 loss: -2.588931083679199
Batch 4/64 loss: -2.3182296752929688
Batch 5/64 loss: -2.6703004837036133
Batch 6/64 loss: -2.340643882751465
Batch 7/64 loss: -2.3601884841918945
Batch 8/64 loss: -2.5923051834106445
Batch 9/64 loss: -2.8487062454223633
Batch 10/64 loss: -2.3352136611938477
Batch 11/64 loss: -2.437053680419922
Batch 12/64 loss: -2.7545604705810547
Batch 13/64 loss: -2.611173629760742
Batch 14/64 loss: -2.7174768447875977
Batch 15/64 loss: -2.4947757720947266
Batch 16/64 loss: -2.7561912536621094
Batch 17/64 loss: -2.66068172454834
Batch 18/64 loss: -2.1492223739624023
Batch 19/64 loss: -2.359773635864258
Batch 20/64 loss: -2.0528202056884766
Batch 21/64 loss: -2.6331043243408203
Batch 22/64 loss: -2.3442420959472656
Batch 23/64 loss: -2.3443593978881836
Batch 24/64 loss: -2.7496204376220703
Batch 25/64 loss: -2.737978935241699
Batch 26/64 loss: -2.6438655853271484
Batch 27/64 loss: -2.8123559951782227
Batch 28/64 loss: -2.851382255554199
Batch 29/64 loss: -2.8026885986328125
Batch 30/64 loss: -3.026360511779785
Batch 31/64 loss: -1.752833366394043
Batch 32/64 loss: -2.6376657485961914
Batch 33/64 loss: -2.6659412384033203
Batch 34/64 loss: -2.7537899017333984
Batch 35/64 loss: -2.7120704650878906
Batch 36/64 loss: -2.5176267623901367
Batch 37/64 loss: -2.73726749420166
Batch 38/64 loss: -2.869570732116699
Batch 39/64 loss: -2.792069435119629
Batch 40/64 loss: -2.8279218673706055
Batch 41/64 loss: -2.817441940307617
Batch 42/64 loss: -2.8632354736328125
Batch 43/64 loss: -2.940919876098633
Batch 44/64 loss: -2.496699333190918
Batch 45/64 loss: -2.5521392822265625
Batch 46/64 loss: -2.8992929458618164
Batch 47/64 loss: -2.7795848846435547
Batch 48/64 loss: -2.700002670288086
Batch 49/64 loss: -2.665872573852539
Batch 50/64 loss: -2.5580244064331055
Batch 51/64 loss: -2.42537784576416
Batch 52/64 loss: -2.675774574279785
Batch 53/64 loss: -2.4329395294189453
Batch 54/64 loss: -2.724846839904785
Batch 55/64 loss: -2.7376012802124023
Batch 56/64 loss: -2.3993635177612305
Batch 57/64 loss: -2.759733200073242
Batch 58/64 loss: -2.81838321685791
Batch 59/64 loss: -2.6158227920532227
Batch 60/64 loss: -2.448657989501953
Batch 61/64 loss: -2.4593372344970703
Batch 62/64 loss: -2.7397775650024414
Batch 63/64 loss: -2.720240592956543
Batch 64/64 loss: -7.07132625579834
Epoch 291  Train loss: -2.6734483644074083  Val loss: -2.9558716606848017
Epoch 292
-------------------------------
Batch 1/64 loss: -2.5186939239501953
Batch 2/64 loss: -2.033876419067383
Batch 3/64 loss: -2.3304672241210938
Batch 4/64 loss: -2.705881118774414
Batch 5/64 loss: -2.699742317199707
Batch 6/64 loss: -2.7576093673706055
Batch 7/64 loss: -2.5642242431640625
Batch 8/64 loss: -2.629988670349121
Batch 9/64 loss: -2.5518617630004883
Batch 10/64 loss: -2.759458541870117
Batch 11/64 loss: -2.5300798416137695
Batch 12/64 loss: -2.553215980529785
Batch 13/64 loss: -2.6954050064086914
Batch 14/64 loss: -2.693113327026367
Batch 15/64 loss: -2.6120481491088867
Batch 16/64 loss: -2.8968067169189453
Batch 17/64 loss: -2.642043113708496
Batch 18/64 loss: -2.428558349609375
Batch 19/64 loss: -2.8223323822021484
Batch 20/64 loss: -2.5634593963623047
Batch 21/64 loss: -2.5688915252685547
Batch 22/64 loss: -2.7247438430786133
Batch 23/64 loss: -2.684140205383301
Batch 24/64 loss: -2.7096920013427734
Batch 25/64 loss: -2.862391471862793
Batch 26/64 loss: -2.5940027236938477
Batch 27/64 loss: -2.7105884552001953
Batch 28/64 loss: -2.717235565185547
Batch 29/64 loss: -2.6668319702148438
Batch 30/64 loss: -2.764054298400879
Batch 31/64 loss: -2.7057905197143555
Batch 32/64 loss: -2.690671920776367
Batch 33/64 loss: -2.757723808288574
Batch 34/64 loss: -2.454789161682129
Batch 35/64 loss: -2.2149181365966797
Batch 36/64 loss: -2.839715003967285
Batch 37/64 loss: -2.365966796875
Batch 38/64 loss: -2.0620803833007812
Batch 39/64 loss: -2.609917640686035
Batch 40/64 loss: -2.582268714904785
Batch 41/64 loss: -2.1129045486450195
Batch 42/64 loss: -2.6804656982421875
Batch 43/64 loss: -2.815462112426758
Batch 44/64 loss: -2.4285154342651367
Batch 45/64 loss: -2.8520498275756836
Batch 46/64 loss: -2.7944202423095703
Batch 47/64 loss: -2.526630401611328
Batch 48/64 loss: -2.6294517517089844
Batch 49/64 loss: -2.734842300415039
Batch 50/64 loss: -2.4546260833740234
Batch 51/64 loss: -2.726146697998047
Batch 52/64 loss: -2.723480224609375
Batch 53/64 loss: -2.51651668548584
Batch 54/64 loss: -2.741034507751465
Batch 55/64 loss: -2.6198301315307617
Batch 56/64 loss: -2.857452392578125
Batch 57/64 loss: -2.849163055419922
Batch 58/64 loss: -2.7393674850463867
Batch 59/64 loss: -2.835163116455078
Batch 60/64 loss: -2.822957992553711
Batch 61/64 loss: -2.462235450744629
Batch 62/64 loss: -2.5462121963500977
Batch 63/64 loss: -2.892216682434082
Batch 64/64 loss: -7.387768745422363
Epoch 292  Train loss: -2.685133358076507  Val loss: -2.9756228784515275
Epoch 293
-------------------------------
Batch 1/64 loss: -2.7584142684936523
Batch 2/64 loss: -2.7257699966430664
Batch 3/64 loss: -2.411322593688965
Batch 4/64 loss: -2.785048484802246
Batch 5/64 loss: -2.6604061126708984
Batch 6/64 loss: -2.655545234680176
Batch 7/64 loss: -2.6280593872070312
Batch 8/64 loss: -2.625852584838867
Batch 9/64 loss: -2.7091474533081055
Batch 10/64 loss: -2.7164688110351562
Batch 11/64 loss: -2.670095443725586
Batch 12/64 loss: -2.757314682006836
Batch 13/64 loss: -2.49166202545166
Batch 14/64 loss: -2.9008684158325195
Batch 15/64 loss: -2.080021858215332
Batch 16/64 loss: -2.7679738998413086
Batch 17/64 loss: -2.866636276245117
Batch 18/64 loss: -2.7665624618530273
Batch 19/64 loss: -2.7255325317382812
Batch 20/64 loss: -2.5515356063842773
Batch 21/64 loss: -2.8924570083618164
Batch 22/64 loss: -2.791402816772461
Batch 23/64 loss: -2.0895814895629883
Batch 24/64 loss: -2.8398094177246094
Batch 25/64 loss: -2.6449480056762695
Batch 26/64 loss: -2.5790767669677734
Batch 27/64 loss: -2.7543296813964844
Batch 28/64 loss: -2.734468460083008
Batch 29/64 loss: -2.610624313354492
Batch 30/64 loss: -2.4010066986083984
Batch 31/64 loss: -2.5407238006591797
Batch 32/64 loss: -2.797518730163574
Batch 33/64 loss: -2.7085437774658203
Batch 34/64 loss: -2.597309112548828
Batch 35/64 loss: -2.6030397415161133
Batch 36/64 loss: -2.705463409423828
Batch 37/64 loss: -2.665884017944336
Batch 38/64 loss: -2.581101417541504
Batch 39/64 loss: -2.6789932250976562
Batch 40/64 loss: -2.47103214263916
Batch 41/64 loss: -2.7413272857666016
Batch 42/64 loss: -2.308460235595703
Batch 43/64 loss: -2.4342079162597656
Batch 44/64 loss: -2.670085906982422
Batch 45/64 loss: -2.713775634765625
Batch 46/64 loss: -2.6622133255004883
Batch 47/64 loss: -2.740720748901367
Batch 48/64 loss: -2.730611801147461
Batch 49/64 loss: -2.8265838623046875
Batch 50/64 loss: -2.6732654571533203
Batch 51/64 loss: -2.8661317825317383
Batch 52/64 loss: -2.6637725830078125
Batch 53/64 loss: -2.795858383178711
Batch 54/64 loss: -2.750509262084961
Batch 55/64 loss: -2.3660736083984375
Batch 56/64 loss: -2.7023305892944336
Batch 57/64 loss: -2.439634323120117
Batch 58/64 loss: -2.833256721496582
Batch 59/64 loss: -2.4659194946289062
Batch 60/64 loss: -2.4507102966308594
Batch 61/64 loss: -2.517289161682129
Batch 62/64 loss: -2.2449960708618164
Batch 63/64 loss: -2.845097541809082
Batch 64/64 loss: -7.203704833984375
Epoch 293  Train loss: -2.6947005926393994  Val loss: -2.9735777943404678
Epoch 294
-------------------------------
Batch 1/64 loss: -2.841506004333496
Batch 2/64 loss: -2.422149658203125
Batch 3/64 loss: -2.6054935455322266
Batch 4/64 loss: -2.476620674133301
Batch 5/64 loss: -2.8736495971679688
Batch 6/64 loss: -2.654987335205078
Batch 7/64 loss: -2.707550048828125
Batch 8/64 loss: -2.3833398818969727
Batch 9/64 loss: -2.2846288681030273
Batch 10/64 loss: -2.7375974655151367
Batch 11/64 loss: -2.423098564147949
Batch 12/64 loss: -2.749979019165039
Batch 13/64 loss: -2.5689620971679688
Batch 14/64 loss: -2.719423294067383
Batch 15/64 loss: -2.7036867141723633
Batch 16/64 loss: -2.902313232421875
Batch 17/64 loss: -2.777219772338867
Batch 18/64 loss: -2.556171417236328
Batch 19/64 loss: -2.930492401123047
Batch 20/64 loss: -2.969637870788574
Batch 21/64 loss: -2.735104560852051
Batch 22/64 loss: -2.751483917236328
Batch 23/64 loss: -2.5505905151367188
Batch 24/64 loss: -2.570453643798828
Batch 25/64 loss: -2.605208396911621
Batch 26/64 loss: -2.8522939682006836
Batch 27/64 loss: -2.7036895751953125
Batch 28/64 loss: -2.5631513595581055
Batch 29/64 loss: -2.6854658126831055
Batch 30/64 loss: -2.7353038787841797
Batch 31/64 loss: -2.4151153564453125
Batch 32/64 loss: -2.7499313354492188
Batch 33/64 loss: -2.613615036010742
Batch 34/64 loss: -2.793100357055664
Batch 35/64 loss: -2.6073102951049805
Batch 36/64 loss: -2.7068557739257812
Batch 37/64 loss: -2.519411087036133
Batch 38/64 loss: -2.5480823516845703
Batch 39/64 loss: -2.778183937072754
Batch 40/64 loss: -2.4762039184570312
Batch 41/64 loss: -2.6514902114868164
Batch 42/64 loss: -2.6560792922973633
Batch 43/64 loss: -2.7004709243774414
Batch 44/64 loss: -2.5952062606811523
Batch 45/64 loss: -2.6717958450317383
Batch 46/64 loss: -2.4240264892578125
Batch 47/64 loss: -2.6325483322143555
Batch 48/64 loss: -2.841111183166504
Batch 49/64 loss: -2.806171417236328
Batch 50/64 loss: -2.564082145690918
Batch 51/64 loss: -2.698150634765625
Batch 52/64 loss: -2.7251462936401367
Batch 53/64 loss: -2.7315921783447266
Batch 54/64 loss: -2.703780174255371
Batch 55/64 loss: -2.6321516036987305
Batch 56/64 loss: -2.6321964263916016
Batch 57/64 loss: -2.1577043533325195
Batch 58/64 loss: -2.148160934448242
Batch 59/64 loss: -2.5781049728393555
Batch 60/64 loss: -2.804619789123535
Batch 61/64 loss: -1.9263906478881836
Batch 62/64 loss: -2.349454879760742
Batch 63/64 loss: -2.695486068725586
Batch 64/64 loss: -7.0916595458984375
Epoch 294  Train loss: -2.6806859334309894  Val loss: -2.85165468196279
Epoch 295
-------------------------------
Batch 1/64 loss: -2.726809501647949
Batch 2/64 loss: -2.548130989074707
Batch 3/64 loss: -2.722471237182617
Batch 4/64 loss: -2.7777671813964844
Batch 5/64 loss: -2.251429557800293
Batch 6/64 loss: -2.166274070739746
Batch 7/64 loss: -2.6152076721191406
Batch 8/64 loss: -2.587254524230957
Batch 9/64 loss: -2.4444141387939453
Batch 10/64 loss: -2.7962284088134766
Batch 11/64 loss: -2.3087711334228516
Batch 12/64 loss: -2.635411262512207
Batch 13/64 loss: -2.6767663955688477
Batch 14/64 loss: -2.713071823120117
Batch 15/64 loss: -2.7768030166625977
Batch 16/64 loss: -2.298107147216797
Batch 17/64 loss: -2.251370429992676
Batch 18/64 loss: -2.81247615814209
Batch 19/64 loss: -2.5482187271118164
Batch 20/64 loss: -2.6511850357055664
Batch 21/64 loss: -2.4514760971069336
Batch 22/64 loss: -2.592665672302246
Batch 23/64 loss: -2.6781387329101562
Batch 24/64 loss: -2.4791946411132812
Batch 25/64 loss: -2.7243289947509766
Batch 26/64 loss: -2.6069087982177734
Batch 27/64 loss: -2.678452491760254
Batch 28/64 loss: -2.683807373046875
Batch 29/64 loss: -2.41201114654541
Batch 30/64 loss: -2.456514358520508
Batch 31/64 loss: -2.7165565490722656
Batch 32/64 loss: -2.679729461669922
Batch 33/64 loss: -2.702115058898926
Batch 34/64 loss: -2.6150856018066406
Batch 35/64 loss: -2.172125816345215
Batch 36/64 loss: -2.332146644592285
Batch 37/64 loss: -2.2331714630126953
Batch 38/64 loss: -2.063166618347168
Batch 39/64 loss: -2.6184473037719727
Batch 40/64 loss: -1.7364730834960938
Batch 41/64 loss: -2.733938217163086
Batch 42/64 loss: -2.631270408630371
Batch 43/64 loss: -2.400604248046875
Batch 44/64 loss: -2.668219566345215
Batch 45/64 loss: -2.512007713317871
Batch 46/64 loss: -2.648159980773926
Batch 47/64 loss: -2.803403854370117
Batch 48/64 loss: -2.774783134460449
Batch 49/64 loss: -2.740018844604492
Batch 50/64 loss: -2.579681396484375
Batch 51/64 loss: -2.6802749633789062
Batch 52/64 loss: -2.192171096801758
Batch 53/64 loss: -2.6193342208862305
Batch 54/64 loss: -2.4168968200683594
Batch 55/64 loss: -2.5637588500976562
Batch 56/64 loss: -2.3005685806274414
Batch 57/64 loss: -2.551525115966797
Batch 58/64 loss: -2.419879913330078
Batch 59/64 loss: -2.3050127029418945
Batch 60/64 loss: -2.535712242126465
Batch 61/64 loss: -2.7222108840942383
Batch 62/64 loss: -1.5719366073608398
Batch 63/64 loss: -2.571162223815918
Batch 64/64 loss: -7.195708751678467
Epoch 295  Train loss: -2.576941136752858  Val loss: -2.892333224057332
Epoch 296
-------------------------------
Batch 1/64 loss: -2.7008466720581055
Batch 2/64 loss: -2.7215747833251953
Batch 3/64 loss: -2.2902984619140625
Batch 4/64 loss: -2.7870044708251953
Batch 5/64 loss: -1.3424139022827148
Batch 6/64 loss: -2.4915771484375
Batch 7/64 loss: -2.2893199920654297
Batch 8/64 loss: -2.5515518188476562
Batch 9/64 loss: -2.5015182495117188
Batch 10/64 loss: -2.6377248764038086
Batch 11/64 loss: -2.197744369506836
Batch 12/64 loss: -2.7378501892089844
Batch 13/64 loss: -2.8150291442871094
Batch 14/64 loss: -2.578333854675293
Batch 15/64 loss: -2.7367868423461914
Batch 16/64 loss: -2.1796646118164062
Batch 17/64 loss: -2.013092041015625
Batch 18/64 loss: -2.406693458557129
Batch 19/64 loss: -2.4659318923950195
Batch 20/64 loss: -2.106353759765625
Batch 21/64 loss: -2.6071319580078125
Batch 22/64 loss: -2.5066089630126953
Batch 23/64 loss: -2.388810157775879
Batch 24/64 loss: -2.4054975509643555
Batch 25/64 loss: -2.0644969940185547
Batch 26/64 loss: -2.362630844116211
Batch 27/64 loss: -2.363043785095215
Batch 28/64 loss: -2.6039981842041016
Batch 29/64 loss: -2.485356330871582
Batch 30/64 loss: -2.6732587814331055
Batch 31/64 loss: -2.787766456604004
Batch 32/64 loss: -2.7224435806274414
Batch 33/64 loss: -2.472625732421875
Batch 34/64 loss: -2.480426788330078
Batch 35/64 loss: -2.6836986541748047
Batch 36/64 loss: -1.5257225036621094
Batch 37/64 loss: -2.648487091064453
Batch 38/64 loss: -2.6686782836914062
Batch 39/64 loss: -2.7057037353515625
Batch 40/64 loss: -2.4070167541503906
Batch 41/64 loss: -2.671314239501953
Batch 42/64 loss: -2.667989730834961
Batch 43/64 loss: -2.549696922302246
Batch 44/64 loss: -2.4870071411132812
Batch 45/64 loss: -2.3427953720092773
Batch 46/64 loss: -2.617429733276367
Batch 47/64 loss: -2.730290412902832
Batch 48/64 loss: -2.3880977630615234
Batch 49/64 loss: -2.776494026184082
Batch 50/64 loss: -2.2626514434814453
Batch 51/64 loss: -2.782668113708496
Batch 52/64 loss: -2.3368091583251953
Batch 53/64 loss: -2.736506462097168
Batch 54/64 loss: -2.4582033157348633
Batch 55/64 loss: -2.549886703491211
Batch 56/64 loss: -2.474210739135742
Batch 57/64 loss: -2.2283315658569336
Batch 58/64 loss: -2.7241439819335938
Batch 59/64 loss: -2.8093652725219727
Batch 60/64 loss: -2.488964080810547
Batch 61/64 loss: -2.5493202209472656
Batch 62/64 loss: -2.6868858337402344
Batch 63/64 loss: -2.7632617950439453
Batch 64/64 loss: -7.201321601867676
Epoch 296  Train loss: -2.55055731605081  Val loss: -2.871329264952145
Epoch 297
-------------------------------
Batch 1/64 loss: -2.804279327392578
Batch 2/64 loss: -2.699676513671875
Batch 3/64 loss: -2.7747926712036133
Batch 4/64 loss: -2.681899070739746
Batch 5/64 loss: -2.5880584716796875
Batch 6/64 loss: -2.5995540618896484
Batch 7/64 loss: -2.5433950424194336
Batch 8/64 loss: -2.803464889526367
Batch 9/64 loss: -2.75283145904541
Batch 10/64 loss: -2.734745979309082
Batch 11/64 loss: -2.7347888946533203
Batch 12/64 loss: -2.713555335998535
Batch 13/64 loss: -2.6254453659057617
Batch 14/64 loss: -2.8636674880981445
Batch 15/64 loss: -2.67299747467041
Batch 16/64 loss: -1.8113117218017578
Batch 17/64 loss: -2.7572059631347656
Batch 18/64 loss: -2.3587942123413086
Batch 19/64 loss: -2.5057640075683594
Batch 20/64 loss: -2.7539567947387695
Batch 21/64 loss: -2.805307388305664
Batch 22/64 loss: -2.3689308166503906
Batch 23/64 loss: -2.4941043853759766
Batch 24/64 loss: -2.6882572174072266
Batch 25/64 loss: -2.5073299407958984
Batch 26/64 loss: -2.778285026550293
Batch 27/64 loss: -2.583859443664551
Batch 28/64 loss: -2.2287206649780273
Batch 29/64 loss: -2.443958282470703
Batch 30/64 loss: -2.6069278717041016
Batch 31/64 loss: -2.5796022415161133
Batch 32/64 loss: -2.7916336059570312
Batch 33/64 loss: -2.8719615936279297
Batch 34/64 loss: -2.625629425048828
Batch 35/64 loss: -2.5196475982666016
Batch 36/64 loss: -2.5883359909057617
Batch 37/64 loss: -2.4826488494873047
Batch 38/64 loss: -2.8644590377807617
Batch 39/64 loss: -2.155644416809082
Batch 40/64 loss: -2.574751853942871
Batch 41/64 loss: -2.8016014099121094
Batch 42/64 loss: -2.656282424926758
Batch 43/64 loss: -2.4951610565185547
Batch 44/64 loss: -2.9534072875976562
Batch 45/64 loss: -2.6868505477905273
Batch 46/64 loss: -2.8429059982299805
Batch 47/64 loss: -2.4072694778442383
Batch 48/64 loss: -2.65169620513916
Batch 49/64 loss: -2.572718620300293
Batch 50/64 loss: -2.890549659729004
Batch 51/64 loss: -2.5798873901367188
Batch 52/64 loss: -2.74997615814209
Batch 53/64 loss: -2.5570240020751953
Batch 54/64 loss: -2.801577568054199
Batch 55/64 loss: -2.727961540222168
Batch 56/64 loss: -2.2669801712036133
Batch 57/64 loss: -2.671417236328125
Batch 58/64 loss: -2.769820213317871
Batch 59/64 loss: -2.8330745697021484
Batch 60/64 loss: -2.5659074783325195
Batch 61/64 loss: -2.745206832885742
Batch 62/64 loss: -2.7170019149780273
Batch 63/64 loss: -1.8589839935302734
Batch 64/64 loss: -7.083047866821289
Epoch 297  Train loss: -2.6738153420242607  Val loss: -3.006006666884799
Epoch 298
-------------------------------
Batch 1/64 loss: -2.8408775329589844
Batch 2/64 loss: -2.8198118209838867
Batch 3/64 loss: -2.583033561706543
Batch 4/64 loss: -2.509511947631836
Batch 5/64 loss: -2.8128442764282227
Batch 6/64 loss: -2.4872283935546875
Batch 7/64 loss: -2.8556909561157227
Batch 8/64 loss: -2.426589012145996
Batch 9/64 loss: -2.485459327697754
Batch 10/64 loss: -2.7538528442382812
Batch 11/64 loss: -2.9210033416748047
Batch 12/64 loss: -2.470296859741211
Batch 13/64 loss: -1.9484663009643555
Batch 14/64 loss: -2.6988439559936523
Batch 15/64 loss: -2.2407102584838867
Batch 16/64 loss: -2.502195358276367
Batch 17/64 loss: -2.7304868698120117
Batch 18/64 loss: -2.6835365295410156
Batch 19/64 loss: -2.610342025756836
Batch 20/64 loss: -2.640732765197754
Batch 21/64 loss: -2.679560661315918
Batch 22/64 loss: -2.719548225402832
Batch 23/64 loss: -2.716975212097168
Batch 24/64 loss: -2.7840633392333984
Batch 25/64 loss: -2.848952293395996
Batch 26/64 loss: -2.6028099060058594
Batch 27/64 loss: -2.564377784729004
Batch 28/64 loss: -2.598372459411621
Batch 29/64 loss: -2.910564422607422
Batch 30/64 loss: -2.9464502334594727
Batch 31/64 loss: -2.5750732421875
Batch 32/64 loss: -2.4901208877563477
Batch 33/64 loss: -2.747410774230957
Batch 34/64 loss: -2.6400232315063477
Batch 35/64 loss: -2.7527284622192383
Batch 36/64 loss: -2.867115020751953
Batch 37/64 loss: -2.739513397216797
Batch 38/64 loss: -2.765561103820801
Batch 39/64 loss: -2.8309621810913086
Batch 40/64 loss: -2.641019821166992
Batch 41/64 loss: -2.7273874282836914
Batch 42/64 loss: -2.6105966567993164
Batch 43/64 loss: -2.519308090209961
Batch 44/64 loss: -2.973430633544922
Batch 45/64 loss: -2.8271827697753906
Batch 46/64 loss: -2.760875701904297
Batch 47/64 loss: -2.967487335205078
Batch 48/64 loss: -2.721550941467285
Batch 49/64 loss: -2.8529434204101562
Batch 50/64 loss: -2.3907737731933594
Batch 51/64 loss: -2.472269058227539
Batch 52/64 loss: -2.7633256912231445
Batch 53/64 loss: -2.820953369140625
Batch 54/64 loss: -2.498040199279785
Batch 55/64 loss: -2.8257675170898438
Batch 56/64 loss: -2.653726577758789
Batch 57/64 loss: -2.5573911666870117
Batch 58/64 loss: -2.8573055267333984
Batch 59/64 loss: -2.142364501953125
Batch 60/64 loss: -2.9057435989379883
Batch 61/64 loss: -2.5590591430664062
Batch 62/64 loss: -2.841218948364258
Batch 63/64 loss: -2.3488874435424805
Batch 64/64 loss: -7.103081226348877
Epoch 298  Train loss: -2.7194920315462  Val loss: -2.9590762030218065
Epoch 299
-------------------------------
Batch 1/64 loss: -2.6933727264404297
Batch 2/64 loss: -2.865245819091797
Batch 3/64 loss: -2.8113012313842773
Batch 4/64 loss: -2.235489845275879
Batch 5/64 loss: -2.6880416870117188
Batch 6/64 loss: -2.567676544189453
Batch 7/64 loss: -2.5453529357910156
Batch 8/64 loss: -2.7695093154907227
Batch 9/64 loss: -2.4823532104492188
Batch 10/64 loss: -2.916196823120117
Batch 11/64 loss: -2.8492822647094727
Batch 12/64 loss: -2.531132698059082
Batch 13/64 loss: -2.7080698013305664
Batch 14/64 loss: -2.6460886001586914
Batch 15/64 loss: -2.820481300354004
Batch 16/64 loss: -2.7126951217651367
Batch 17/64 loss: -2.137753486633301
Batch 18/64 loss: -2.9918394088745117
Batch 19/64 loss: -2.747117042541504
Batch 20/64 loss: -2.61746883392334
Batch 21/64 loss: -2.8104991912841797
Batch 22/64 loss: -2.9142465591430664
Batch 23/64 loss: -2.8647851943969727
Batch 24/64 loss: -2.8613786697387695
Batch 25/64 loss: -2.854320526123047
Batch 26/64 loss: -2.6507158279418945
Batch 27/64 loss: -2.5128793716430664
Batch 28/64 loss: -2.806971549987793
Batch 29/64 loss: -2.7898759841918945
Batch 30/64 loss: -2.7757272720336914
Batch 31/64 loss: -2.5862932205200195
Batch 32/64 loss: -2.7513790130615234
Batch 33/64 loss: -2.6634016036987305
Batch 34/64 loss: -2.7036170959472656
Batch 35/64 loss: -2.0668249130249023
Batch 36/64 loss: -2.4698915481567383
Batch 37/64 loss: -2.6559019088745117
Batch 38/64 loss: -2.7986268997192383
Batch 39/64 loss: -2.4306936264038086
Batch 40/64 loss: -3.034865379333496
Batch 41/64 loss: -2.8331966400146484
Batch 42/64 loss: -2.753183364868164
Batch 43/64 loss: -2.9391002655029297
Batch 44/64 loss: -2.6629676818847656
Batch 45/64 loss: -2.4697799682617188
Batch 46/64 loss: -2.7013378143310547
Batch 47/64 loss: -2.5938825607299805
Batch 48/64 loss: -2.929933547973633
Batch 49/64 loss: -2.132594108581543
Batch 50/64 loss: -2.8147382736206055
Batch 51/64 loss: -2.65781307220459
Batch 52/64 loss: -2.460463523864746
Batch 53/64 loss: -2.7415103912353516
Batch 54/64 loss: -2.644685745239258
Batch 55/64 loss: -2.353330612182617
Batch 56/64 loss: -2.7376956939697266
Batch 57/64 loss: -2.8528833389282227
Batch 58/64 loss: -2.9855756759643555
Batch 59/64 loss: -2.7561731338500977
Batch 60/64 loss: -2.8910093307495117
Batch 61/64 loss: -2.7132654190063477
Batch 62/64 loss: -2.8668413162231445
Batch 63/64 loss: -2.8338537216186523
Batch 64/64 loss: -7.458076000213623
Epoch 299  Train loss: -2.7491566471025055  Val loss: -3.071748871164224
Epoch 300
-------------------------------
Batch 1/64 loss: -2.2562732696533203
Batch 2/64 loss: -2.734224319458008
Batch 3/64 loss: -2.375582695007324
Batch 4/64 loss: -2.527268409729004
Batch 5/64 loss: -2.7272138595581055
Batch 6/64 loss: -2.793217658996582
Batch 7/64 loss: -2.8375797271728516
Batch 8/64 loss: -2.5795764923095703
Batch 9/64 loss: -2.882234573364258
Batch 10/64 loss: -2.857823371887207
Batch 11/64 loss: -2.5777158737182617
Batch 12/64 loss: -2.8015918731689453
Batch 13/64 loss: -2.2970809936523438
Batch 14/64 loss: -2.759469985961914
Batch 15/64 loss: -2.846785545349121
Batch 16/64 loss: -2.829098701477051
Batch 17/64 loss: -2.7790451049804688
Batch 18/64 loss: -2.8033275604248047
Batch 19/64 loss: -2.979276657104492
Batch 20/64 loss: -2.5029163360595703
Batch 21/64 loss: -2.4772109985351562
Batch 22/64 loss: -2.48915958404541
Batch 23/64 loss: -2.693798065185547
Batch 24/64 loss: -2.675143241882324
Batch 25/64 loss: -2.7676267623901367
Batch 26/64 loss: -2.844684600830078
Batch 27/64 loss: -2.64105224609375
Batch 28/64 loss: -2.1635799407958984
Batch 29/64 loss: -2.496845245361328
Batch 30/64 loss: -2.633707046508789
Batch 31/64 loss: -2.588428497314453
Batch 32/64 loss: -2.662997245788574
Batch 33/64 loss: -2.6374778747558594
Batch 34/64 loss: -2.7580204010009766
Batch 35/64 loss: -2.8550729751586914
Batch 36/64 loss: -2.9203977584838867
Batch 37/64 loss: -2.2690792083740234
Batch 38/64 loss: -2.533050537109375
Batch 39/64 loss: -2.9116458892822266
Batch 40/64 loss: -2.6538476943969727
Batch 41/64 loss: -2.692389488220215
Batch 42/64 loss: -2.8445749282836914
Batch 43/64 loss: -2.773214340209961
Batch 44/64 loss: -2.6766786575317383
Batch 45/64 loss: -2.5377330780029297
Batch 46/64 loss: -2.5549535751342773
Batch 47/64 loss: -2.629589080810547
Batch 48/64 loss: -2.384235382080078
Batch 49/64 loss: -2.4672937393188477
Batch 50/64 loss: -2.2043561935424805
Batch 51/64 loss: -2.7433366775512695
Batch 52/64 loss: -2.7226991653442383
Batch 53/64 loss: -2.5283632278442383
Batch 54/64 loss: -2.8757457733154297
Batch 55/64 loss: -2.517375946044922
Batch 56/64 loss: -2.95613956451416
Batch 57/64 loss: -2.737752914428711
Batch 58/64 loss: -2.6664819717407227
Batch 59/64 loss: -2.7617874145507812
Batch 60/64 loss: -2.6012773513793945
Batch 61/64 loss: -2.804889678955078
Batch 62/64 loss: -2.493152618408203
Batch 63/64 loss: -2.62052059173584
Batch 64/64 loss: -7.20652961730957
Epoch 300  Train loss: -2.7077579199099073  Val loss: -2.8845640621644115
Epoch 301
-------------------------------
Batch 1/64 loss: -2.670222282409668
Batch 2/64 loss: -2.8445968627929688
Batch 3/64 loss: -2.839789390563965
Batch 4/64 loss: -2.7887420654296875
Batch 5/64 loss: -2.511028289794922
Batch 6/64 loss: -2.6096324920654297
Batch 7/64 loss: -2.0073556900024414
Batch 8/64 loss: -2.819808006286621
Batch 9/64 loss: -2.6309938430786133
Batch 10/64 loss: -2.738462448120117
Batch 11/64 loss: -1.9407901763916016
Batch 12/64 loss: -2.5738887786865234
Batch 13/64 loss: -2.7864065170288086
Batch 14/64 loss: -2.362605094909668
Batch 15/64 loss: -2.3279829025268555
Batch 16/64 loss: -2.53134822845459
Batch 17/64 loss: -2.5279312133789062
Batch 18/64 loss: -2.7234296798706055
Batch 19/64 loss: -2.854647636413574
Batch 20/64 loss: -2.4573240280151367
Batch 21/64 loss: -2.619466781616211
Batch 22/64 loss: -2.7072668075561523
Batch 23/64 loss: -2.7350597381591797
Batch 24/64 loss: -2.457761764526367
Batch 25/64 loss: -2.624056816101074
Batch 26/64 loss: -2.681595802307129
Batch 27/64 loss: -2.8066673278808594
Batch 28/64 loss: -2.721409797668457
Batch 29/64 loss: -2.7314653396606445
Batch 30/64 loss: -2.8006505966186523
Batch 31/64 loss: -2.6428213119506836
Batch 32/64 loss: -2.6981124877929688
Batch 33/64 loss: -2.58010196685791
Batch 34/64 loss: -2.7311525344848633
Batch 35/64 loss: -2.680088996887207
Batch 36/64 loss: -2.7673254013061523
Batch 37/64 loss: -2.4323511123657227
Batch 38/64 loss: -2.866384506225586
Batch 39/64 loss: -2.6642074584960938
Batch 40/64 loss: -2.7880191802978516
Batch 41/64 loss: -2.4477434158325195
Batch 42/64 loss: -2.781160354614258
Batch 43/64 loss: -2.654073715209961
Batch 44/64 loss: -2.6954574584960938
Batch 45/64 loss: -2.791025161743164
Batch 46/64 loss: -2.5126953125
Batch 47/64 loss: -2.6634130477905273
Batch 48/64 loss: -2.8326377868652344
Batch 49/64 loss: -2.71978759765625
Batch 50/64 loss: -2.6920166015625
Batch 51/64 loss: -2.623567581176758
Batch 52/64 loss: -2.728388786315918
Batch 53/64 loss: -2.9296875
Batch 54/64 loss: -2.807035446166992
Batch 55/64 loss: -2.386336326599121
Batch 56/64 loss: -2.122342109680176
Batch 57/64 loss: -2.899043083190918
Batch 58/64 loss: -2.6396141052246094
Batch 59/64 loss: -2.1272544860839844
Batch 60/64 loss: -2.668755531311035
Batch 61/64 loss: -2.90653133392334
Batch 62/64 loss: -2.638418197631836
Batch 63/64 loss: -2.8264331817626953
Batch 64/64 loss: -7.410739421844482
Epoch 301  Train loss: -2.6970105732188507  Val loss: -2.9360427200999046
Epoch 302
-------------------------------
Batch 1/64 loss: -2.7335004806518555
Batch 2/64 loss: -2.6298465728759766
Batch 3/64 loss: -2.3956985473632812
Batch 4/64 loss: -2.8329010009765625
Batch 5/64 loss: -2.7988977432250977
Batch 6/64 loss: -2.7642030715942383
Batch 7/64 loss: -2.631908416748047
Batch 8/64 loss: -2.5835037231445312
Batch 9/64 loss: -2.631093978881836
Batch 10/64 loss: -2.8093605041503906
Batch 11/64 loss: -2.6863956451416016
Batch 12/64 loss: -2.7534923553466797
Batch 13/64 loss: -2.526669502258301
Batch 14/64 loss: -2.6251821517944336
Batch 15/64 loss: -2.669717788696289
Batch 16/64 loss: -2.7894744873046875
Batch 17/64 loss: -2.6872310638427734
Batch 18/64 loss: -2.792875289916992
Batch 19/64 loss: -2.6679582595825195
Batch 20/64 loss: -2.7211904525756836
Batch 21/64 loss: -2.074199676513672
Batch 22/64 loss: -2.8170242309570312
Batch 23/64 loss: -2.6380043029785156
Batch 24/64 loss: -2.511763572692871
Batch 25/64 loss: -2.860158920288086
Batch 26/64 loss: -2.8053808212280273
Batch 27/64 loss: -2.7811269760131836
Batch 28/64 loss: -2.6066951751708984
Batch 29/64 loss: -2.965547561645508
Batch 30/64 loss: -2.0441455841064453
Batch 31/64 loss: -2.6670103073120117
Batch 32/64 loss: -2.7874975204467773
Batch 33/64 loss: -2.757227897644043
Batch 34/64 loss: -2.5687074661254883
Batch 35/64 loss: -2.638697624206543
Batch 36/64 loss: -2.4627885818481445
Batch 37/64 loss: -2.6466379165649414
Batch 38/64 loss: -2.7269248962402344
Batch 39/64 loss: -2.8169126510620117
Batch 40/64 loss: -2.4464235305786133
Batch 41/64 loss: -2.7225046157836914
Batch 42/64 loss: -2.4423933029174805
Batch 43/64 loss: -2.8958444595336914
Batch 44/64 loss: -2.5646352767944336
Batch 45/64 loss: -2.4043445587158203
Batch 46/64 loss: -2.426608085632324
Batch 47/64 loss: -2.788501739501953
Batch 48/64 loss: -2.847079277038574
Batch 49/64 loss: -1.8424835205078125
Batch 50/64 loss: -2.6162290573120117
Batch 51/64 loss: -2.499868392944336
Batch 52/64 loss: -2.6151561737060547
Batch 53/64 loss: -2.562023162841797
Batch 54/64 loss: -2.838756561279297
Batch 55/64 loss: -2.6296024322509766
Batch 56/64 loss: -2.712190628051758
Batch 57/64 loss: -2.6161575317382812
Batch 58/64 loss: -2.658700942993164
Batch 59/64 loss: -2.591920852661133
Batch 60/64 loss: -2.6635265350341797
Batch 61/64 loss: -1.8315849304199219
Batch 62/64 loss: -2.772153854370117
Batch 63/64 loss: -2.771881103515625
Batch 64/64 loss: -7.305426597595215
Epoch 302  Train loss: -2.684661854014677  Val loss: -2.974659516639316
Epoch 303
-------------------------------
Batch 1/64 loss: -2.6484928131103516
Batch 2/64 loss: -2.6124448776245117
Batch 3/64 loss: -2.6817569732666016
Batch 4/64 loss: -2.6158037185668945
Batch 5/64 loss: -2.543485641479492
Batch 6/64 loss: -2.759370803833008
Batch 7/64 loss: -2.4461498260498047
Batch 8/64 loss: -2.730961799621582
Batch 9/64 loss: -2.6883955001831055
Batch 10/64 loss: -2.4536190032958984
Batch 11/64 loss: -2.223461151123047
Batch 12/64 loss: -2.5574235916137695
Batch 13/64 loss: -2.716836929321289
Batch 14/64 loss: -2.791584014892578
Batch 15/64 loss: -2.6666946411132812
Batch 16/64 loss: -2.6787548065185547
Batch 17/64 loss: -2.6788206100463867
Batch 18/64 loss: -2.58974552154541
Batch 19/64 loss: -2.7148990631103516
Batch 20/64 loss: -2.598134994506836
Batch 21/64 loss: -2.428093910217285
Batch 22/64 loss: -2.81378173828125
Batch 23/64 loss: -2.412430763244629
Batch 24/64 loss: -2.597799301147461
Batch 25/64 loss: -2.8733205795288086
Batch 26/64 loss: -2.6425466537475586
Batch 27/64 loss: -2.453415870666504
Batch 28/64 loss: -2.582369804382324
Batch 29/64 loss: -2.57546329498291
Batch 30/64 loss: -2.7742271423339844
Batch 31/64 loss: -2.820427894592285
Batch 32/64 loss: -2.7316904067993164
Batch 33/64 loss: -2.6314687728881836
Batch 34/64 loss: -2.910414695739746
Batch 35/64 loss: -2.79819393157959
Batch 36/64 loss: -2.53701114654541
Batch 37/64 loss: -2.6742849349975586
Batch 38/64 loss: -2.114604949951172
Batch 39/64 loss: -2.704190254211426
Batch 40/64 loss: -2.9189558029174805
Batch 41/64 loss: -2.7042083740234375
Batch 42/64 loss: -2.6217145919799805
Batch 43/64 loss: -2.61651611328125
Batch 44/64 loss: -2.912686347961426
Batch 45/64 loss: -2.3756093978881836
Batch 46/64 loss: -2.1033878326416016
Batch 47/64 loss: -2.9036474227905273
Batch 48/64 loss: -2.72860050201416
Batch 49/64 loss: -2.4740638732910156
Batch 50/64 loss: -2.8701295852661133
Batch 51/64 loss: -2.604328155517578
Batch 52/64 loss: -2.5495071411132812
Batch 53/64 loss: -2.77431583404541
Batch 54/64 loss: -2.835543632507324
Batch 55/64 loss: -2.611729621887207
Batch 56/64 loss: -2.768096923828125
Batch 57/64 loss: -2.636831283569336
Batch 58/64 loss: -2.7886219024658203
Batch 59/64 loss: -2.0354251861572266
Batch 60/64 loss: -2.995695114135742
Batch 61/64 loss: -2.742650032043457
Batch 62/64 loss: -2.9070730209350586
Batch 63/64 loss: -2.9467811584472656
Batch 64/64 loss: -7.263236999511719
Epoch 303  Train loss: -2.703468532188266  Val loss: -3.0163449815048793
Epoch 304
-------------------------------
Batch 1/64 loss: -2.2237014770507812
Batch 2/64 loss: -2.6767311096191406
Batch 3/64 loss: -2.859349250793457
Batch 4/64 loss: -2.5935163497924805
Batch 5/64 loss: -2.8939390182495117
Batch 6/64 loss: -2.726287841796875
Batch 7/64 loss: -2.763547897338867
Batch 8/64 loss: -2.78775691986084
Batch 9/64 loss: -2.4771013259887695
Batch 10/64 loss: -2.467740058898926
Batch 11/64 loss: -2.7706193923950195
Batch 12/64 loss: -2.7895450592041016
Batch 13/64 loss: -1.7628746032714844
Batch 14/64 loss: -2.478473663330078
Batch 15/64 loss: -2.717283248901367
Batch 16/64 loss: -2.5824155807495117
Batch 17/64 loss: -2.3438777923583984
Batch 18/64 loss: -2.4144058227539062
Batch 19/64 loss: -2.7223730087280273
Batch 20/64 loss: -2.8125648498535156
Batch 21/64 loss: -2.862616539001465
Batch 22/64 loss: -2.5851831436157227
Batch 23/64 loss: -2.6924095153808594
Batch 24/64 loss: -2.7081823348999023
Batch 25/64 loss: -2.486628532409668
Batch 26/64 loss: -2.6908273696899414
Batch 27/64 loss: -2.70546817779541
Batch 28/64 loss: -2.4052629470825195
Batch 29/64 loss: -2.625485420227051
Batch 30/64 loss: -2.6819257736206055
Batch 31/64 loss: -2.3984689712524414
Batch 32/64 loss: -2.930133819580078
Batch 33/64 loss: -2.7692508697509766
Batch 34/64 loss: -2.4920969009399414
Batch 35/64 loss: -2.661391258239746
Batch 36/64 loss: -2.358778953552246
Batch 37/64 loss: -2.8881940841674805
Batch 38/64 loss: -2.8434534072875977
Batch 39/64 loss: -2.6834516525268555
Batch 40/64 loss: -2.3132286071777344
Batch 41/64 loss: -2.550511360168457
Batch 42/64 loss: -2.2140159606933594
Batch 43/64 loss: -2.7840280532836914
Batch 44/64 loss: -2.8789520263671875
Batch 45/64 loss: -2.367156982421875
Batch 46/64 loss: -2.6980857849121094
Batch 47/64 loss: -2.1248884201049805
Batch 48/64 loss: -2.6548004150390625
Batch 49/64 loss: -2.948948860168457
Batch 50/64 loss: -2.645925521850586
Batch 51/64 loss: -2.621750831604004
Batch 52/64 loss: -2.417003631591797
Batch 53/64 loss: -1.5399408340454102
Batch 54/64 loss: -2.330813407897949
Batch 55/64 loss: -2.6262617111206055
Batch 56/64 loss: -2.6567373275756836
Batch 57/64 loss: -2.645376205444336
Batch 58/64 loss: -2.737791061401367
Batch 59/64 loss: -2.634685516357422
Batch 60/64 loss: -2.305845260620117
Batch 61/64 loss: -2.711782455444336
Batch 62/64 loss: -2.4847326278686523
Batch 63/64 loss: -2.7600231170654297
Batch 64/64 loss: -7.276796340942383
Epoch 304  Train loss: -2.642261916515874  Val loss: -3.0025688905486536
Epoch 305
-------------------------------
Batch 1/64 loss: -2.6649675369262695
Batch 2/64 loss: -2.3310956954956055
Batch 3/64 loss: -2.838046073913574
Batch 4/64 loss: -2.448195457458496
Batch 5/64 loss: -2.875979423522949
Batch 6/64 loss: -2.895634651184082
Batch 7/64 loss: -2.7024059295654297
Batch 8/64 loss: -1.753767967224121
Batch 9/64 loss: -2.930788993835449
Batch 10/64 loss: -2.615971565246582
Batch 11/64 loss: -2.8182506561279297
Batch 12/64 loss: -2.7731714248657227
Batch 13/64 loss: -2.7285194396972656
Batch 14/64 loss: -2.8101272583007812
Batch 15/64 loss: -2.915520668029785
Batch 16/64 loss: -2.755709648132324
Batch 17/64 loss: -2.4966983795166016
Batch 18/64 loss: -2.5476646423339844
Batch 19/64 loss: -2.657878875732422
Batch 20/64 loss: -2.79929256439209
Batch 21/64 loss: -2.471841812133789
Batch 22/64 loss: -2.84053897857666
Batch 23/64 loss: -2.712721824645996
Batch 24/64 loss: -2.8434066772460938
Batch 25/64 loss: -2.387510299682617
Batch 26/64 loss: -2.419478416442871
Batch 27/64 loss: -2.53586483001709
Batch 28/64 loss: -1.9938297271728516
Batch 29/64 loss: -2.659475326538086
Batch 30/64 loss: -2.6458120346069336
Batch 31/64 loss: -2.85452938079834
Batch 32/64 loss: -2.630899429321289
Batch 33/64 loss: -2.778731346130371
Batch 34/64 loss: -2.4565505981445312
Batch 35/64 loss: -2.1783981323242188
Batch 36/64 loss: -2.8556337356567383
Batch 37/64 loss: -2.916606903076172
Batch 38/64 loss: -2.80142879486084
Batch 39/64 loss: -2.36179256439209
Batch 40/64 loss: -2.6550254821777344
Batch 41/64 loss: -2.323375701904297
Batch 42/64 loss: -2.774951934814453
Batch 43/64 loss: -2.797194480895996
Batch 44/64 loss: -2.53928279876709
Batch 45/64 loss: -2.6580562591552734
Batch 46/64 loss: -2.708807945251465
Batch 47/64 loss: -2.6966848373413086
Batch 48/64 loss: -2.5715646743774414
Batch 49/64 loss: -2.7638912200927734
Batch 50/64 loss: -2.6852989196777344
Batch 51/64 loss: -2.2975168228149414
Batch 52/64 loss: -2.854659080505371
Batch 53/64 loss: -2.6981468200683594
Batch 54/64 loss: -2.419719696044922
Batch 55/64 loss: -2.8597068786621094
Batch 56/64 loss: -2.699308395385742
Batch 57/64 loss: -2.689751625061035
Batch 58/64 loss: -2.6714296340942383
Batch 59/64 loss: -2.6318349838256836
Batch 60/64 loss: -2.7650394439697266
Batch 61/64 loss: -2.3483142852783203
Batch 62/64 loss: -2.7875194549560547
Batch 63/64 loss: -2.8908653259277344
Batch 64/64 loss: -7.220728874206543
Epoch 305  Train loss: -2.696599702274098  Val loss: -3.030196579870899
Epoch 306
-------------------------------
Batch 1/64 loss: -2.7159719467163086
Batch 2/64 loss: -2.7798948287963867
Batch 3/64 loss: -2.7418556213378906
Batch 4/64 loss: -2.731739044189453
Batch 5/64 loss: -2.600865364074707
Batch 6/64 loss: -2.897523880004883
Batch 7/64 loss: -2.818819046020508
Batch 8/64 loss: -2.748720169067383
Batch 9/64 loss: -2.8972949981689453
Batch 10/64 loss: -2.8183088302612305
Batch 11/64 loss: -2.7792482376098633
Batch 12/64 loss: -2.7358970642089844
Batch 13/64 loss: -2.7458038330078125
Batch 14/64 loss: -2.6655044555664062
Batch 15/64 loss: -2.471689224243164
Batch 16/64 loss: -2.378298759460449
Batch 17/64 loss: -2.6626758575439453
Batch 18/64 loss: -2.750332832336426
Batch 19/64 loss: -2.754002571105957
Batch 20/64 loss: -2.7809972763061523
Batch 21/64 loss: -2.4621429443359375
Batch 22/64 loss: -2.8006229400634766
Batch 23/64 loss: -2.552297592163086
Batch 24/64 loss: -2.4761343002319336
Batch 25/64 loss: -2.7541160583496094
Batch 26/64 loss: -2.6648807525634766
Batch 27/64 loss: -2.774531364440918
Batch 28/64 loss: -2.297647476196289
Batch 29/64 loss: -2.731243133544922
Batch 30/64 loss: -2.7340126037597656
Batch 31/64 loss: -2.823812484741211
Batch 32/64 loss: -2.950932502746582
Batch 33/64 loss: -2.959061622619629
Batch 34/64 loss: -2.4558839797973633
Batch 35/64 loss: -2.6319265365600586
Batch 36/64 loss: -2.6750612258911133
Batch 37/64 loss: -2.8638792037963867
Batch 38/64 loss: -2.987545967102051
Batch 39/64 loss: -2.6169557571411133
Batch 40/64 loss: -2.6352767944335938
Batch 41/64 loss: -2.931558609008789
Batch 42/64 loss: -2.5157957077026367
Batch 43/64 loss: -2.8430604934692383
Batch 44/64 loss: -2.827115058898926
Batch 45/64 loss: -2.784054756164551
Batch 46/64 loss: -2.3645105361938477
Batch 47/64 loss: -2.718036651611328
Batch 48/64 loss: -2.5054492950439453
Batch 49/64 loss: -2.574512481689453
Batch 50/64 loss: -2.7736711502075195
Batch 51/64 loss: -2.659914970397949
Batch 52/64 loss: -2.7628231048583984
Batch 53/64 loss: -2.6677770614624023
Batch 54/64 loss: -2.657867431640625
Batch 55/64 loss: -2.56455135345459
Batch 56/64 loss: -2.5855283737182617
Batch 57/64 loss: -2.7068119049072266
Batch 58/64 loss: -2.5854625701904297
Batch 59/64 loss: -2.270751953125
Batch 60/64 loss: -2.8745994567871094
Batch 61/64 loss: -2.8393239974975586
Batch 62/64 loss: -2.8104047775268555
Batch 63/64 loss: -2.1051340103149414
Batch 64/64 loss: -7.311511993408203
Epoch 306  Train loss: -2.740953078924441  Val loss: -3.085481388052714
Epoch 307
-------------------------------
Batch 1/64 loss: -2.7438220977783203
Batch 2/64 loss: -2.671563148498535
Batch 3/64 loss: -2.629596710205078
Batch 4/64 loss: -2.552145004272461
Batch 5/64 loss: -2.792717933654785
Batch 6/64 loss: -2.8204126358032227
Batch 7/64 loss: -2.6861743927001953
Batch 8/64 loss: -2.7728891372680664
Batch 9/64 loss: -2.6659154891967773
Batch 10/64 loss: -2.844761848449707
Batch 11/64 loss: -2.7850780487060547
Batch 12/64 loss: -2.6439809799194336
Batch 13/64 loss: -2.5034828186035156
Batch 14/64 loss: -2.9179744720458984
Batch 15/64 loss: -2.1725826263427734
Batch 16/64 loss: -2.5450143814086914
Batch 17/64 loss: -2.7379016876220703
Batch 18/64 loss: -2.591742515563965
Batch 19/64 loss: -3.0781631469726562
Batch 20/64 loss: -2.46419620513916
Batch 21/64 loss: -2.6730098724365234
Batch 22/64 loss: -2.5768308639526367
Batch 23/64 loss: -2.958247184753418
Batch 24/64 loss: -2.533501625061035
Batch 25/64 loss: -2.7141551971435547
Batch 26/64 loss: -2.8019981384277344
Batch 27/64 loss: -2.789051055908203
Batch 28/64 loss: -2.996143341064453
Batch 29/64 loss: -2.710629463195801
Batch 30/64 loss: -2.8348169326782227
Batch 31/64 loss: -2.3715744018554688
Batch 32/64 loss: -2.8379430770874023
Batch 33/64 loss: -1.6063718795776367
Batch 34/64 loss: -2.623509407043457
Batch 35/64 loss: -2.6093034744262695
Batch 36/64 loss: -2.468719482421875
Batch 37/64 loss: -2.1982507705688477
Batch 38/64 loss: -2.794856071472168
Batch 39/64 loss: -2.666781425476074
Batch 40/64 loss: -2.4343137741088867
Batch 41/64 loss: -2.8717498779296875
Batch 42/64 loss: -2.875326156616211
Batch 43/64 loss: -2.710369110107422
Batch 44/64 loss: -2.6161203384399414
Batch 45/64 loss: -2.8337326049804688
Batch 46/64 loss: -2.8293209075927734
Batch 47/64 loss: -2.7570066452026367
Batch 48/64 loss: -2.91854190826416
Batch 49/64 loss: -2.7913036346435547
Batch 50/64 loss: -2.7813167572021484
Batch 51/64 loss: -2.780393600463867
Batch 52/64 loss: -2.7234678268432617
Batch 53/64 loss: -2.480642318725586
Batch 54/64 loss: -2.750655174255371
Batch 55/64 loss: -2.2964630126953125
Batch 56/64 loss: -2.8216495513916016
Batch 57/64 loss: -2.555105209350586
Batch 58/64 loss: -2.706234931945801
Batch 59/64 loss: -2.4404783248901367
Batch 60/64 loss: -2.958226203918457
Batch 61/64 loss: -2.5761966705322266
Batch 62/64 loss: -2.3550872802734375
Batch 63/64 loss: -2.9147396087646484
Batch 64/64 loss: -7.270920276641846
Epoch 307  Train loss: -2.7234108326481836  Val loss: -3.0028726767838205
Epoch 308
-------------------------------
Batch 1/64 loss: -2.2765016555786133
Batch 2/64 loss: -2.9185562133789062
Batch 3/64 loss: -2.898922920227051
Batch 4/64 loss: -2.5250244140625
Batch 5/64 loss: -2.7285842895507812
Batch 6/64 loss: -2.575672149658203
Batch 7/64 loss: -2.6746177673339844
Batch 8/64 loss: -2.6995201110839844
Batch 9/64 loss: -2.6725006103515625
Batch 10/64 loss: -2.1931676864624023
Batch 11/64 loss: -2.4286231994628906
Batch 12/64 loss: -2.7476158142089844
Batch 13/64 loss: -2.8580894470214844
Batch 14/64 loss: -2.7343578338623047
Batch 15/64 loss: -2.4935550689697266
Batch 16/64 loss: -2.7470531463623047
Batch 17/64 loss: -2.5233030319213867
Batch 18/64 loss: -2.7345972061157227
Batch 19/64 loss: -2.633331298828125
Batch 20/64 loss: -2.7157554626464844
Batch 21/64 loss: -2.315913200378418
Batch 22/64 loss: -2.6136865615844727
Batch 23/64 loss: -2.9864864349365234
Batch 24/64 loss: -2.5249643325805664
Batch 25/64 loss: -2.681887626647949
Batch 26/64 loss: -2.897364616394043
Batch 27/64 loss: -2.7212114334106445
Batch 28/64 loss: -2.8450746536254883
Batch 29/64 loss: -2.269028663635254
Batch 30/64 loss: -2.6252145767211914
Batch 31/64 loss: -2.8378429412841797
Batch 32/64 loss: -2.9893789291381836
Batch 33/64 loss: -2.5034093856811523
Batch 34/64 loss: -2.577960968017578
Batch 35/64 loss: -2.7806453704833984
Batch 36/64 loss: -2.8076705932617188
Batch 37/64 loss: -2.910416603088379
Batch 38/64 loss: -2.6671152114868164
Batch 39/64 loss: -2.70790958404541
Batch 40/64 loss: -2.5662364959716797
Batch 41/64 loss: -2.6932477951049805
Batch 42/64 loss: -2.022017478942871
Batch 43/64 loss: -2.7683353424072266
Batch 44/64 loss: -2.540332794189453
Batch 45/64 loss: -2.786837577819824
Batch 46/64 loss: -2.849346160888672
Batch 47/64 loss: -2.8406057357788086
Batch 48/64 loss: -2.808587074279785
Batch 49/64 loss: -2.4958620071411133
Batch 50/64 loss: -2.854461669921875
Batch 51/64 loss: -2.753480911254883
Batch 52/64 loss: -2.5895586013793945
Batch 53/64 loss: -2.0110034942626953
Batch 54/64 loss: -2.611790657043457
Batch 55/64 loss: -2.2164411544799805
Batch 56/64 loss: -2.801093101501465
Batch 57/64 loss: -2.3185224533081055
Batch 58/64 loss: -2.538789749145508
Batch 59/64 loss: -2.526116371154785
Batch 60/64 loss: -2.425352096557617
Batch 61/64 loss: -2.639216423034668
Batch 62/64 loss: -2.620647430419922
Batch 63/64 loss: -2.514559745788574
Batch 64/64 loss: -7.008151531219482
Epoch 308  Train loss: -2.6837817566067566  Val loss: -2.9149832971317253
Epoch 309
-------------------------------
Batch 1/64 loss: -2.440638542175293
Batch 2/64 loss: -2.683133125305176
Batch 3/64 loss: -2.7737932205200195
Batch 4/64 loss: -2.6101436614990234
Batch 5/64 loss: -2.357137680053711
Batch 6/64 loss: -2.6657094955444336
Batch 7/64 loss: -2.637371063232422
Batch 8/64 loss: -2.271890640258789
Batch 9/64 loss: -2.7343406677246094
Batch 10/64 loss: -2.6721506118774414
Batch 11/64 loss: -2.343111038208008
Batch 12/64 loss: -2.394937515258789
Batch 13/64 loss: -2.4508914947509766
Batch 14/64 loss: -2.4948673248291016
Batch 15/64 loss: -2.381619453430176
Batch 16/64 loss: -2.2116689682006836
Batch 17/64 loss: -2.47861385345459
Batch 18/64 loss: -2.7286081314086914
Batch 19/64 loss: -2.7674102783203125
Batch 20/64 loss: -2.165790557861328
Batch 21/64 loss: -2.716451644897461
Batch 22/64 loss: -2.363748550415039
Batch 23/64 loss: -2.3048248291015625
Batch 24/64 loss: -2.660114288330078
Batch 25/64 loss: -2.675124168395996
Batch 26/64 loss: -2.6115903854370117
Batch 27/64 loss: -2.729673385620117
Batch 28/64 loss: -2.462625503540039
Batch 29/64 loss: -2.636103630065918
Batch 30/64 loss: -2.8738574981689453
Batch 31/64 loss: -2.6387176513671875
Batch 32/64 loss: -2.6656570434570312
Batch 33/64 loss: -2.57645320892334
Batch 34/64 loss: -2.274571418762207
Batch 35/64 loss: -2.38541316986084
Batch 36/64 loss: -2.7846479415893555
Batch 37/64 loss: -2.769190788269043
Batch 38/64 loss: -2.7213125228881836
Batch 39/64 loss: -2.6493539810180664
Batch 40/64 loss: -2.59588623046875
Batch 41/64 loss: -2.6370649337768555
Batch 42/64 loss: -2.743149757385254
Batch 43/64 loss: -2.8015432357788086
Batch 44/64 loss: -2.73575496673584
Batch 45/64 loss: -2.660154342651367
Batch 46/64 loss: -2.6898908615112305
Batch 47/64 loss: -2.626856803894043
Batch 48/64 loss: -2.5065975189208984
Batch 49/64 loss: -2.620631217956543
Batch 50/64 loss: -2.693117141723633
Batch 51/64 loss: -2.986575126647949
Batch 52/64 loss: -2.4544906616210938
Batch 53/64 loss: -2.708995819091797
Batch 54/64 loss: -2.866506576538086
Batch 55/64 loss: -2.574398994445801
Batch 56/64 loss: -2.352937698364258
Batch 57/64 loss: -2.717193603515625
Batch 58/64 loss: -2.676997184753418
Batch 59/64 loss: -2.816904067993164
Batch 60/64 loss: -2.753993034362793
Batch 61/64 loss: -2.755011558532715
Batch 62/64 loss: -2.173233985900879
Batch 63/64 loss: -2.618368148803711
Batch 64/64 loss: -6.1776275634765625
Epoch 309  Train loss: -2.637846793380438  Val loss: -2.935029675460763
Epoch 310
-------------------------------
Batch 1/64 loss: -2.7319889068603516
Batch 2/64 loss: -2.728867530822754
Batch 3/64 loss: -2.311354637145996
Batch 4/64 loss: -2.6702194213867188
Batch 5/64 loss: -2.877481460571289
Batch 6/64 loss: -2.3005456924438477
Batch 7/64 loss: -2.547793388366699
Batch 8/64 loss: -2.674532890319824
Batch 9/64 loss: -2.780925750732422
Batch 10/64 loss: -2.6051387786865234
Batch 11/64 loss: -2.6708450317382812
Batch 12/64 loss: -2.688300132751465
Batch 13/64 loss: -2.4920730590820312
Batch 14/64 loss: -2.7343549728393555
Batch 15/64 loss: -2.626772880554199
Batch 16/64 loss: -2.882004737854004
Batch 17/64 loss: -2.5639686584472656
Batch 18/64 loss: -2.345867156982422
Batch 19/64 loss: -2.638986587524414
Batch 20/64 loss: -2.5868310928344727
Batch 21/64 loss: -2.761019706726074
Batch 22/64 loss: -2.9195785522460938
Batch 23/64 loss: -2.7356252670288086
Batch 24/64 loss: -2.5717687606811523
Batch 25/64 loss: -2.6316375732421875
Batch 26/64 loss: -2.426396369934082
Batch 27/64 loss: -2.36727237701416
Batch 28/64 loss: -2.8423614501953125
Batch 29/64 loss: -2.5325822830200195
Batch 30/64 loss: -2.7743711471557617
Batch 31/64 loss: -2.8737449645996094
Batch 32/64 loss: -2.7367849349975586
Batch 33/64 loss: -2.1976804733276367
Batch 34/64 loss: -2.826756477355957
Batch 35/64 loss: -2.5503149032592773
Batch 36/64 loss: -2.76076602935791
Batch 37/64 loss: -2.7945423126220703
Batch 38/64 loss: -2.750678062438965
Batch 39/64 loss: -2.965752601623535
Batch 40/64 loss: -2.939737319946289
Batch 41/64 loss: -2.59228515625
Batch 42/64 loss: -2.92340087890625
Batch 43/64 loss: -2.8558225631713867
Batch 44/64 loss: -2.958038330078125
Batch 45/64 loss: -2.623943328857422
Batch 46/64 loss: -2.716616630554199
Batch 47/64 loss: -1.992685317993164
Batch 48/64 loss: -2.828179359436035
Batch 49/64 loss: -2.82904052734375
Batch 50/64 loss: -2.703587532043457
Batch 51/64 loss: -2.867945671081543
Batch 52/64 loss: -2.84456729888916
Batch 53/64 loss: -2.4902162551879883
Batch 54/64 loss: -2.6934432983398438
Batch 55/64 loss: -2.409499168395996
Batch 56/64 loss: -2.777716636657715
Batch 57/64 loss: -2.92990779876709
Batch 58/64 loss: -2.9155731201171875
Batch 59/64 loss: -2.2910423278808594
Batch 60/64 loss: -2.68084716796875
Batch 61/64 loss: -2.667881965637207
Batch 62/64 loss: -2.700037956237793
Batch 63/64 loss: -2.7518348693847656
Batch 64/64 loss: -7.4740681648254395
Epoch 310  Train loss: -2.7304766841963226  Val loss: -2.9605662683441056
Epoch 311
-------------------------------
Batch 1/64 loss: -2.744630813598633
Batch 2/64 loss: -2.981311798095703
Batch 3/64 loss: -2.483217239379883
Batch 4/64 loss: -2.818634033203125
Batch 5/64 loss: -2.802983283996582
Batch 6/64 loss: -2.6619081497192383
Batch 7/64 loss: -2.709994316101074
Batch 8/64 loss: -2.898733139038086
Batch 9/64 loss: -2.7365341186523438
Batch 10/64 loss: -2.6764469146728516
Batch 11/64 loss: -2.7994823455810547
Batch 12/64 loss: -2.8899154663085938
Batch 13/64 loss: -2.7709712982177734
Batch 14/64 loss: -2.603970527648926
Batch 15/64 loss: -2.799466133117676
Batch 16/64 loss: -2.9175310134887695
Batch 17/64 loss: -2.8480424880981445
Batch 18/64 loss: -2.6515016555786133
Batch 19/64 loss: -2.7025976181030273
Batch 20/64 loss: -2.793745994567871
Batch 21/64 loss: -2.5282535552978516
Batch 22/64 loss: -2.829146385192871
Batch 23/64 loss: -2.712405204772949
Batch 24/64 loss: -2.918219566345215
Batch 25/64 loss: -2.8183746337890625
Batch 26/64 loss: -2.5847883224487305
Batch 27/64 loss: -2.6937828063964844
Batch 28/64 loss: -2.852044105529785
Batch 29/64 loss: -2.6936769485473633
Batch 30/64 loss: -2.537327766418457
Batch 31/64 loss: -2.061084747314453
Batch 32/64 loss: -2.824655532836914
Batch 33/64 loss: -2.954395294189453
Batch 34/64 loss: -2.6412038803100586
Batch 35/64 loss: -2.8026247024536133
Batch 36/64 loss: -2.2138242721557617
Batch 37/64 loss: -2.6979265213012695
Batch 38/64 loss: -2.9601640701293945
Batch 39/64 loss: -2.67002010345459
Batch 40/64 loss: -2.775263786315918
Batch 41/64 loss: -2.727222442626953
Batch 42/64 loss: -2.6729249954223633
Batch 43/64 loss: -2.6922988891601562
Batch 44/64 loss: -2.886943817138672
Batch 45/64 loss: -2.504505157470703
Batch 46/64 loss: -2.6582584381103516
Batch 47/64 loss: -2.5240612030029297
Batch 48/64 loss: -2.561551094055176
Batch 49/64 loss: -2.0785598754882812
Batch 50/64 loss: -2.4519872665405273
Batch 51/64 loss: -2.6111364364624023
Batch 52/64 loss: -2.6209096908569336
Batch 53/64 loss: -2.708444595336914
Batch 54/64 loss: -2.4460582733154297
Batch 55/64 loss: -2.72786808013916
Batch 56/64 loss: -2.8437814712524414
Batch 57/64 loss: -2.6286182403564453
Batch 58/64 loss: -2.662923812866211
Batch 59/64 loss: -2.718491554260254
Batch 60/64 loss: -2.8125219345092773
Batch 61/64 loss: -2.6132707595825195
Batch 62/64 loss: -2.7030887603759766
Batch 63/64 loss: -2.6790924072265625
Batch 64/64 loss: -7.293299198150635
Epoch 311  Train loss: -2.7461222611221614  Val loss: -3.054702103342797
Epoch 312
-------------------------------
Batch 1/64 loss: -2.7999629974365234
Batch 2/64 loss: -2.8762693405151367
Batch 3/64 loss: -2.722757339477539
Batch 4/64 loss: -2.9311580657958984
Batch 5/64 loss: -2.7224273681640625
Batch 6/64 loss: -2.8201980590820312
Batch 7/64 loss: -2.434408187866211
Batch 8/64 loss: -2.6236743927001953
Batch 9/64 loss: -2.798600196838379
Batch 10/64 loss: -2.5974245071411133
Batch 11/64 loss: -2.798956871032715
Batch 12/64 loss: -2.823927879333496
Batch 13/64 loss: -2.656540870666504
Batch 14/64 loss: -2.725168228149414
Batch 15/64 loss: -2.816220283508301
Batch 16/64 loss: -2.1661453247070312
Batch 17/64 loss: -2.9423961639404297
Batch 18/64 loss: -2.699793815612793
Batch 19/64 loss: -1.9361982345581055
Batch 20/64 loss: -2.8864803314208984
Batch 21/64 loss: -2.882382392883301
Batch 22/64 loss: -2.7822351455688477
Batch 23/64 loss: -2.715306282043457
Batch 24/64 loss: -2.265594482421875
Batch 25/64 loss: -2.3650503158569336
Batch 26/64 loss: -2.5839920043945312
Batch 27/64 loss: -2.7372426986694336
Batch 28/64 loss: -2.896303176879883
Batch 29/64 loss: -2.6779298782348633
Batch 30/64 loss: -2.8321285247802734
Batch 31/64 loss: -2.3373775482177734
Batch 32/64 loss: -2.897472381591797
Batch 33/64 loss: -2.6501455307006836
Batch 34/64 loss: -2.758636474609375
Batch 35/64 loss: -2.7866077423095703
Batch 36/64 loss: -2.7843685150146484
Batch 37/64 loss: -2.771042823791504
Batch 38/64 loss: -2.6962804794311523
Batch 39/64 loss: -2.991156578063965
Batch 40/64 loss: -2.7383861541748047
Batch 41/64 loss: -2.7182703018188477
Batch 42/64 loss: -2.7143173217773438
Batch 43/64 loss: -2.6621007919311523
Batch 44/64 loss: -2.9136695861816406
Batch 45/64 loss: -2.7299013137817383
Batch 46/64 loss: -2.369889259338379
Batch 47/64 loss: -2.87924861907959
Batch 48/64 loss: -2.2765722274780273
Batch 49/64 loss: -2.7127418518066406
Batch 50/64 loss: -2.816740036010742
Batch 51/64 loss: -2.565657615661621
Batch 52/64 loss: -2.438142776489258
Batch 53/64 loss: -2.8522329330444336
Batch 54/64 loss: -2.6859703063964844
Batch 55/64 loss: -2.7315616607666016
Batch 56/64 loss: -2.699313163757324
Batch 57/64 loss: -2.8655319213867188
Batch 58/64 loss: -2.5240230560302734
Batch 59/64 loss: -2.954275131225586
Batch 60/64 loss: -2.47939395904541
Batch 61/64 loss: -2.607879638671875
Batch 62/64 loss: -2.926654815673828
Batch 63/64 loss: -2.451584815979004
Batch 64/64 loss: -7.312893390655518
Epoch 312  Train loss: -2.744920638963288  Val loss: -3.0961215618959406
Epoch 313
-------------------------------
Batch 1/64 loss: -3.021012306213379
Batch 2/64 loss: -2.7898035049438477
Batch 3/64 loss: -2.864826202392578
Batch 4/64 loss: -2.610581398010254
Batch 5/64 loss: -2.761000633239746
Batch 6/64 loss: -2.8415069580078125
Batch 7/64 loss: -2.9245786666870117
Batch 8/64 loss: -2.918670654296875
Batch 9/64 loss: -2.6835546493530273
Batch 10/64 loss: -2.8694581985473633
Batch 11/64 loss: -2.7949695587158203
Batch 12/64 loss: -2.8914995193481445
Batch 13/64 loss: -2.809072494506836
Batch 14/64 loss: -2.748885154724121
Batch 15/64 loss: -2.0794944763183594
Batch 16/64 loss: -2.5573034286499023
Batch 17/64 loss: -2.828968048095703
Batch 18/64 loss: -2.7873640060424805
Batch 19/64 loss: -2.135683059692383
Batch 20/64 loss: -2.7721633911132812
Batch 21/64 loss: -2.558804512023926
Batch 22/64 loss: -2.3867626190185547
Batch 23/64 loss: -2.7982330322265625
Batch 24/64 loss: -2.9783830642700195
Batch 25/64 loss: -2.723421096801758
Batch 26/64 loss: -2.705937385559082
Batch 27/64 loss: -2.9807729721069336
Batch 28/64 loss: -2.8183717727661133
Batch 29/64 loss: -2.6810293197631836
Batch 30/64 loss: -2.5907020568847656
Batch 31/64 loss: -2.8090343475341797
Batch 32/64 loss: -2.7096376419067383
Batch 33/64 loss: -2.8000917434692383
Batch 34/64 loss: -2.5713977813720703
Batch 35/64 loss: -2.562479019165039
Batch 36/64 loss: -2.6192455291748047
Batch 37/64 loss: -2.6384592056274414
Batch 38/64 loss: -2.6991701126098633
Batch 39/64 loss: -2.769015312194824
Batch 40/64 loss: -2.8049659729003906
Batch 41/64 loss: -2.640909194946289
Batch 42/64 loss: -2.457794189453125
Batch 43/64 loss: -2.5089120864868164
Batch 44/64 loss: -2.80352783203125
Batch 45/64 loss: -2.7568092346191406
Batch 46/64 loss: -2.690732955932617
Batch 47/64 loss: -2.1975135803222656
Batch 48/64 loss: -2.477527618408203
Batch 49/64 loss: -2.681795120239258
Batch 50/64 loss: -2.596165657043457
Batch 51/64 loss: -2.6278982162475586
Batch 52/64 loss: -3.0244064331054688
Batch 53/64 loss: -2.8379154205322266
Batch 54/64 loss: -2.580655097961426
Batch 55/64 loss: -2.6429481506347656
Batch 56/64 loss: -2.6573190689086914
Batch 57/64 loss: -2.5272741317749023
Batch 58/64 loss: -2.6803550720214844
Batch 59/64 loss: -2.410284996032715
Batch 60/64 loss: -2.7495241165161133
Batch 61/64 loss: -2.710627555847168
Batch 62/64 loss: -2.678847312927246
Batch 63/64 loss: -2.8091182708740234
Batch 64/64 loss: -6.315766334533691
Epoch 313  Train loss: -2.7354038724712297  Val loss: -3.0124841539310836
Epoch 314
-------------------------------
Batch 1/64 loss: -2.781597137451172
Batch 2/64 loss: -2.0512466430664062
Batch 3/64 loss: -2.7264299392700195
Batch 4/64 loss: -2.76981258392334
Batch 5/64 loss: -2.8452768325805664
Batch 6/64 loss: -2.8271045684814453
Batch 7/64 loss: -2.786820411682129
Batch 8/64 loss: -2.93619441986084
Batch 9/64 loss: -2.630162239074707
Batch 10/64 loss: -2.7213191986083984
Batch 11/64 loss: -2.2213125228881836
Batch 12/64 loss: -2.755878448486328
Batch 13/64 loss: -2.8097047805786133
Batch 14/64 loss: -2.955120086669922
Batch 15/64 loss: -2.68422794342041
Batch 16/64 loss: -2.739077568054199
Batch 17/64 loss: -2.7513952255249023
Batch 18/64 loss: -2.6535463333129883
Batch 19/64 loss: -2.4741554260253906
Batch 20/64 loss: -2.7902774810791016
Batch 21/64 loss: -2.5749292373657227
Batch 22/64 loss: -2.812234878540039
Batch 23/64 loss: -2.8946352005004883
Batch 24/64 loss: -2.9626951217651367
Batch 25/64 loss: -2.7584056854248047
Batch 26/64 loss: -2.638434410095215
Batch 27/64 loss: -2.9641952514648438
Batch 28/64 loss: -2.772891044616699
Batch 29/64 loss: -2.9499216079711914
Batch 30/64 loss: -2.6528244018554688
Batch 31/64 loss: -2.5555667877197266
Batch 32/64 loss: -2.3972253799438477
Batch 33/64 loss: -2.970911979675293
Batch 34/64 loss: -2.219738006591797
Batch 35/64 loss: -2.6479711532592773
Batch 36/64 loss: -2.3547935485839844
Batch 37/64 loss: -2.9367589950561523
Batch 38/64 loss: -2.843679428100586
Batch 39/64 loss: -2.6597890853881836
Batch 40/64 loss: -2.736858367919922
Batch 41/64 loss: -2.739222526550293
Batch 42/64 loss: -2.700895309448242
Batch 43/64 loss: -2.4059677124023438
Batch 44/64 loss: -2.827373504638672
Batch 45/64 loss: -2.6714792251586914
Batch 46/64 loss: -2.699085235595703
Batch 47/64 loss: -2.4749460220336914
Batch 48/64 loss: -3.094667434692383
Batch 49/64 loss: -2.763134002685547
Batch 50/64 loss: -2.882817268371582
Batch 51/64 loss: -2.9786863327026367
Batch 52/64 loss: -2.6250648498535156
Batch 53/64 loss: -2.577573776245117
Batch 54/64 loss: -2.6898746490478516
Batch 55/64 loss: -2.7702102661132812
Batch 56/64 loss: -2.9525136947631836
Batch 57/64 loss: -3.056412696838379
Batch 58/64 loss: -2.7876386642456055
Batch 59/64 loss: -2.7472238540649414
Batch 60/64 loss: -2.788130760192871
Batch 61/64 loss: -2.815519332885742
Batch 62/64 loss: -2.7333498001098633
Batch 63/64 loss: -2.7775917053222656
Batch 64/64 loss: -7.107876777648926
Epoch 314  Train loss: -2.778124008926691  Val loss: -3.026669164703474
Epoch 315
-------------------------------
Batch 1/64 loss: -2.895753860473633
Batch 2/64 loss: -2.7118396759033203
Batch 3/64 loss: -2.9037580490112305
Batch 4/64 loss: -2.8292579650878906
Batch 5/64 loss: -2.7397689819335938
Batch 6/64 loss: -2.31350040435791
Batch 7/64 loss: -2.7651100158691406
Batch 8/64 loss: -2.8776779174804688
Batch 9/64 loss: -2.9760961532592773
Batch 10/64 loss: -2.7020206451416016
Batch 11/64 loss: -2.7866477966308594
Batch 12/64 loss: -2.232428550720215
Batch 13/64 loss: -2.900043487548828
Batch 14/64 loss: -2.668682098388672
Batch 15/64 loss: -2.8157758712768555
Batch 16/64 loss: -2.578434944152832
Batch 17/64 loss: -2.9308385848999023
Batch 18/64 loss: -2.2353010177612305
Batch 19/64 loss: -2.509449005126953
Batch 20/64 loss: -2.177351951599121
Batch 21/64 loss: -2.8107213973999023
Batch 22/64 loss: -1.8161096572875977
Batch 23/64 loss: -2.672788619995117
Batch 24/64 loss: -2.6465768814086914
Batch 25/64 loss: -2.784198760986328
Batch 26/64 loss: -2.615231513977051
Batch 27/64 loss: -2.9216880798339844
Batch 28/64 loss: -2.60111141204834
Batch 29/64 loss: -2.5359668731689453
Batch 30/64 loss: -2.8068532943725586
Batch 31/64 loss: -2.7342071533203125
Batch 32/64 loss: -2.6747846603393555
Batch 33/64 loss: -2.630965232849121
Batch 34/64 loss: -2.55776309967041
Batch 35/64 loss: -2.562562942504883
Batch 36/64 loss: -2.074871063232422
Batch 37/64 loss: -2.637763023376465
Batch 38/64 loss: -2.3839941024780273
Batch 39/64 loss: -2.9701080322265625
Batch 40/64 loss: -2.675417900085449
Batch 41/64 loss: -2.629826545715332
Batch 42/64 loss: -2.6409378051757812
Batch 43/64 loss: -2.4638471603393555
Batch 44/64 loss: -2.5892744064331055
Batch 45/64 loss: -2.6077356338500977
Batch 46/64 loss: -2.6617202758789062
Batch 47/64 loss: -2.4392404556274414
Batch 48/64 loss: -2.9319372177124023
Batch 49/64 loss: -2.6520252227783203
Batch 50/64 loss: -2.842921257019043
Batch 51/64 loss: -2.6445274353027344
Batch 52/64 loss: -2.7257261276245117
Batch 53/64 loss: -2.7222185134887695
Batch 54/64 loss: -2.7911720275878906
Batch 55/64 loss: -2.704324722290039
Batch 56/64 loss: -2.9118967056274414
Batch 57/64 loss: -2.7874984741210938
Batch 58/64 loss: -2.797163963317871
Batch 59/64 loss: -2.9791574478149414
Batch 60/64 loss: -2.5931663513183594
Batch 61/64 loss: -2.679323196411133
Batch 62/64 loss: -2.76700496673584
Batch 63/64 loss: -2.475762367248535
Batch 64/64 loss: -7.176357269287109
Epoch 315  Train loss: -2.7150446573893228  Val loss: -2.980581630955857
Epoch 316
-------------------------------
Batch 1/64 loss: -2.2136125564575195
Batch 2/64 loss: -2.629131317138672
Batch 3/64 loss: -2.4573488235473633
Batch 4/64 loss: -2.5928955078125
Batch 5/64 loss: -2.770059585571289
Batch 6/64 loss: -2.783670425415039
Batch 7/64 loss: -2.791017532348633
Batch 8/64 loss: -2.621875762939453
Batch 9/64 loss: -2.764369010925293
Batch 10/64 loss: -2.295055389404297
Batch 11/64 loss: -2.827486038208008
Batch 12/64 loss: -2.6928606033325195
Batch 13/64 loss: -1.6626911163330078
Batch 14/64 loss: -2.8665552139282227
Batch 15/64 loss: -2.5349884033203125
Batch 16/64 loss: -2.645345687866211
Batch 17/64 loss: -1.850417137145996
Batch 18/64 loss: -2.714384078979492
Batch 19/64 loss: -2.721160888671875
Batch 20/64 loss: -2.495147705078125
Batch 21/64 loss: -2.481368064880371
Batch 22/64 loss: -2.7725772857666016
Batch 23/64 loss: -2.7112388610839844
Batch 24/64 loss: -2.71488094329834
Batch 25/64 loss: -2.7985172271728516
Batch 26/64 loss: -2.5080833435058594
Batch 27/64 loss: -2.920901298522949
Batch 28/64 loss: -2.403858184814453
Batch 29/64 loss: -2.7648181915283203
Batch 30/64 loss: -2.6837387084960938
Batch 31/64 loss: -2.6499691009521484
Batch 32/64 loss: -2.9711713790893555
Batch 33/64 loss: -2.940774917602539
Batch 34/64 loss: -2.9806785583496094
Batch 35/64 loss: -2.7387161254882812
Batch 36/64 loss: -2.626962661743164
Batch 37/64 loss: -2.5433616638183594
Batch 38/64 loss: -2.6800222396850586
Batch 39/64 loss: -2.767704963684082
Batch 40/64 loss: -2.5832576751708984
Batch 41/64 loss: -2.872523307800293
Batch 42/64 loss: -2.6778268814086914
Batch 43/64 loss: -2.3936767578125
Batch 44/64 loss: -2.8715744018554688
Batch 45/64 loss: -2.867119789123535
Batch 46/64 loss: -2.5241079330444336
Batch 47/64 loss: -2.647756576538086
Batch 48/64 loss: -2.66937255859375
Batch 49/64 loss: -2.4553890228271484
Batch 50/64 loss: -2.640247344970703
Batch 51/64 loss: -2.7034072875976562
Batch 52/64 loss: -2.666752815246582
Batch 53/64 loss: -2.621941566467285
Batch 54/64 loss: -2.5626049041748047
Batch 55/64 loss: -2.735902786254883
Batch 56/64 loss: -2.841756820678711
Batch 57/64 loss: -2.7664060592651367
Batch 58/64 loss: -2.9005165100097656
Batch 59/64 loss: -2.7666521072387695
Batch 60/64 loss: -2.309157371520996
Batch 61/64 loss: -2.7910423278808594
Batch 62/64 loss: -2.649622917175293
Batch 63/64 loss: -2.6898374557495117
Batch 64/64 loss: -7.522517204284668
Epoch 316  Train loss: -2.7049373738905964  Val loss: -3.002269836635524
Epoch 317
-------------------------------
Batch 1/64 loss: -2.4507951736450195
Batch 2/64 loss: -2.7298574447631836
Batch 3/64 loss: -2.4958648681640625
Batch 4/64 loss: -2.8517379760742188
Batch 5/64 loss: -2.6993112564086914
Batch 6/64 loss: -2.5938892364501953
Batch 7/64 loss: -2.8342113494873047
Batch 8/64 loss: -2.1857995986938477
Batch 9/64 loss: -2.876718521118164
Batch 10/64 loss: -2.82340145111084
Batch 11/64 loss: -2.920980453491211
Batch 12/64 loss: -2.814912796020508
Batch 13/64 loss: -2.784086227416992
Batch 14/64 loss: -2.7778968811035156
Batch 15/64 loss: -2.726469039916992
Batch 16/64 loss: -2.689356803894043
Batch 17/64 loss: -2.7561168670654297
Batch 18/64 loss: -2.887417793273926
Batch 19/64 loss: -2.555842399597168
Batch 20/64 loss: -2.80145263671875
Batch 21/64 loss: -2.7774295806884766
Batch 22/64 loss: -2.7893848419189453
Batch 23/64 loss: -2.5761308670043945
Batch 24/64 loss: -2.7243146896362305
Batch 25/64 loss: -2.750758171081543
Batch 26/64 loss: -2.7277488708496094
Batch 27/64 loss: -2.676626205444336
Batch 28/64 loss: -2.823235511779785
Batch 29/64 loss: -2.647200584411621
Batch 30/64 loss: -2.5323104858398438
Batch 31/64 loss: -2.9149560928344727
Batch 32/64 loss: -2.5790109634399414
Batch 33/64 loss: -2.5778064727783203
Batch 34/64 loss: -2.825331687927246
Batch 35/64 loss: -2.7132558822631836
Batch 36/64 loss: -2.629635810852051
Batch 37/64 loss: -2.313617706298828
Batch 38/64 loss: -2.1449012756347656
Batch 39/64 loss: -2.7466001510620117
Batch 40/64 loss: -2.671259880065918
Batch 41/64 loss: -2.67901611328125
Batch 42/64 loss: -2.853515625
Batch 43/64 loss: -2.4777402877807617
Batch 44/64 loss: -2.903533935546875
Batch 45/64 loss: -2.5691051483154297
Batch 46/64 loss: -2.862856864929199
Batch 47/64 loss: -3.033123016357422
Batch 48/64 loss: -2.6977834701538086
Batch 49/64 loss: -2.9457082748413086
Batch 50/64 loss: -2.7838878631591797
Batch 51/64 loss: -2.858732223510742
Batch 52/64 loss: -2.645740509033203
Batch 53/64 loss: -2.854372978210449
Batch 54/64 loss: -2.0592899322509766
Batch 55/64 loss: -2.8404455184936523
Batch 56/64 loss: -2.7648305892944336
Batch 57/64 loss: -2.726994514465332
Batch 58/64 loss: -2.6590147018432617
Batch 59/64 loss: -2.8188905715942383
Batch 60/64 loss: -2.7081594467163086
Batch 61/64 loss: -2.7001123428344727
Batch 62/64 loss: -2.3206377029418945
Batch 63/64 loss: -2.958867073059082
Batch 64/64 loss: -7.035796165466309
Epoch 317  Train loss: -2.7513229856304093  Val loss: -3.048827233593079
Epoch 318
-------------------------------
Batch 1/64 loss: -2.5693321228027344
Batch 2/64 loss: -2.8222951889038086
Batch 3/64 loss: -2.7972965240478516
Batch 4/64 loss: -2.889476776123047
Batch 5/64 loss: -2.673090934753418
Batch 6/64 loss: -2.062760353088379
Batch 7/64 loss: -2.8218994140625
Batch 8/64 loss: -2.707766532897949
Batch 9/64 loss: -2.642068862915039
Batch 10/64 loss: -2.924666404724121
Batch 11/64 loss: -2.446661949157715
Batch 12/64 loss: -2.7002735137939453
Batch 13/64 loss: -2.589726448059082
Batch 14/64 loss: -2.4685773849487305
Batch 15/64 loss: -2.6299123764038086
Batch 16/64 loss: -2.964611053466797
Batch 17/64 loss: -2.8703203201293945
Batch 18/64 loss: -2.8737077713012695
Batch 19/64 loss: -2.7943382263183594
Batch 20/64 loss: -2.7447023391723633
Batch 21/64 loss: -2.6398887634277344
Batch 22/64 loss: -2.666606903076172
Batch 23/64 loss: -2.865550994873047
Batch 24/64 loss: -3.0765466690063477
Batch 25/64 loss: -2.825314521789551
Batch 26/64 loss: -2.6643571853637695
Batch 27/64 loss: -2.5581283569335938
Batch 28/64 loss: -2.8236770629882812
Batch 29/64 loss: -2.8002986907958984
Batch 30/64 loss: -2.9446725845336914
Batch 31/64 loss: -2.8035144805908203
Batch 32/64 loss: -2.604677200317383
Batch 33/64 loss: -2.3595476150512695
Batch 34/64 loss: -2.7934722900390625
Batch 35/64 loss: -2.7936811447143555
Batch 36/64 loss: -2.662008285522461
Batch 37/64 loss: -2.7565765380859375
Batch 38/64 loss: -2.791187286376953
Batch 39/64 loss: -2.3339881896972656
Batch 40/64 loss: -2.7262964248657227
Batch 41/64 loss: -2.553020477294922
Batch 42/64 loss: -2.4714794158935547
Batch 43/64 loss: -2.4401254653930664
Batch 44/64 loss: -2.778745651245117
Batch 45/64 loss: -2.6777191162109375
Batch 46/64 loss: -1.4977178573608398
Batch 47/64 loss: -2.553006172180176
Batch 48/64 loss: -2.6258249282836914
Batch 49/64 loss: -2.7012367248535156
Batch 50/64 loss: -2.369945526123047
Batch 51/64 loss: -2.4237098693847656
Batch 52/64 loss: -2.7003297805786133
Batch 53/64 loss: -2.62398624420166
Batch 54/64 loss: -2.485161781311035
Batch 55/64 loss: -0.5867528915405273
Batch 56/64 loss: -2.456488609313965
Batch 57/64 loss: -2.3851099014282227
Batch 58/64 loss: -2.152226448059082
Batch 59/64 loss: -2.7852048873901367
Batch 60/64 loss: -2.1510133743286133
Batch 61/64 loss: -2.724882125854492
Batch 62/64 loss: -2.7560176849365234
Batch 63/64 loss: -2.5205984115600586
Batch 64/64 loss: -7.027186393737793
Epoch 318  Train loss: -2.6537124521592084  Val loss: -2.4243041887316097
Epoch 319
-------------------------------
Batch 1/64 loss: -2.5280961990356445
Batch 2/64 loss: -2.418240547180176
Batch 3/64 loss: -2.335529327392578
Batch 4/64 loss: -2.5546798706054688
Batch 5/64 loss: -2.6965579986572266
Batch 6/64 loss: -2.616548538208008
Batch 7/64 loss: -2.386063575744629
Batch 8/64 loss: -2.6470861434936523
Batch 9/64 loss: -2.6538801193237305
Batch 10/64 loss: -2.6470251083374023
Batch 11/64 loss: -2.6539392471313477
Batch 12/64 loss: -2.3433990478515625
Batch 13/64 loss: -2.649555206298828
Batch 14/64 loss: -2.6448068618774414
Batch 15/64 loss: -2.5391550064086914
Batch 16/64 loss: -2.5539588928222656
Batch 17/64 loss: -2.3588905334472656
Batch 18/64 loss: -2.72098445892334
Batch 19/64 loss: -2.327460289001465
Batch 20/64 loss: -2.7413434982299805
Batch 21/64 loss: -2.6178245544433594
Batch 22/64 loss: -2.1526880264282227
Batch 23/64 loss: -2.650541305541992
Batch 24/64 loss: -1.8141775131225586
Batch 25/64 loss: -2.4710769653320312
Batch 26/64 loss: -1.7703752517700195
Batch 27/64 loss: -2.879134178161621
Batch 28/64 loss: -2.6080942153930664
Batch 29/64 loss: -2.120730400085449
Batch 30/64 loss: -2.7932863235473633
Batch 31/64 loss: -2.438140869140625
Batch 32/64 loss: -2.7751474380493164
Batch 33/64 loss: -2.5732040405273438
Batch 34/64 loss: -2.675436019897461
Batch 35/64 loss: -2.385723114013672
Batch 36/64 loss: -2.8553552627563477
Batch 37/64 loss: -2.663060188293457
Batch 38/64 loss: -2.469156265258789
Batch 39/64 loss: -2.5486679077148438
Batch 40/64 loss: -2.527009963989258
Batch 41/64 loss: -2.7325878143310547
Batch 42/64 loss: -2.681532859802246
Batch 43/64 loss: -2.955495834350586
Batch 44/64 loss: -2.5624141693115234
Batch 45/64 loss: -2.7796077728271484
Batch 46/64 loss: -2.8413400650024414
Batch 47/64 loss: -2.6883411407470703
Batch 48/64 loss: -2.4007139205932617
Batch 49/64 loss: -2.717696189880371
Batch 50/64 loss: -2.805567741394043
Batch 51/64 loss: -2.760770797729492
Batch 52/64 loss: -2.939603805541992
Batch 53/64 loss: -2.961716651916504
Batch 54/64 loss: -2.767827033996582
Batch 55/64 loss: -2.459932327270508
Batch 56/64 loss: -1.9781713485717773
Batch 57/64 loss: -2.7642555236816406
Batch 58/64 loss: -2.968928337097168
Batch 59/64 loss: -2.977090835571289
Batch 60/64 loss: -1.860219955444336
Batch 61/64 loss: -2.7350759506225586
Batch 62/64 loss: -2.575958251953125
Batch 63/64 loss: -2.505364418029785
Batch 64/64 loss: -7.276790142059326
Epoch 319  Train loss: -2.6303346764807607  Val loss: -3.0137584594516817
Epoch 320
-------------------------------
Batch 1/64 loss: -2.8789548873901367
Batch 2/64 loss: -2.915363311767578
Batch 3/64 loss: -2.677670478820801
Batch 4/64 loss: -2.557790756225586
Batch 5/64 loss: -2.72139835357666
Batch 6/64 loss: -2.805624008178711
Batch 7/64 loss: -2.6474552154541016
Batch 8/64 loss: -2.7613754272460938
Batch 9/64 loss: -2.4735774993896484
Batch 10/64 loss: -2.6370763778686523
Batch 11/64 loss: -2.7034454345703125
Batch 12/64 loss: -2.7501325607299805
Batch 13/64 loss: -2.6650266647338867
Batch 14/64 loss: -2.8850412368774414
Batch 15/64 loss: -2.884079933166504
Batch 16/64 loss: -2.4226818084716797
Batch 17/64 loss: -2.57358455657959
Batch 18/64 loss: -2.5777158737182617
Batch 19/64 loss: -2.8183345794677734
Batch 20/64 loss: -2.565248489379883
Batch 21/64 loss: -2.614140510559082
Batch 22/64 loss: -2.8407373428344727
Batch 23/64 loss: -2.773259162902832
Batch 24/64 loss: -2.6677722930908203
Batch 25/64 loss: -2.774733543395996
Batch 26/64 loss: -2.9730844497680664
Batch 27/64 loss: -2.290238380432129
Batch 28/64 loss: -2.5151729583740234
Batch 29/64 loss: -2.720033645629883
Batch 30/64 loss: -2.636920928955078
Batch 31/64 loss: -2.810945510864258
Batch 32/64 loss: -2.854522705078125
Batch 33/64 loss: -2.8313941955566406
Batch 34/64 loss: -2.88482666015625
Batch 35/64 loss: -1.2731704711914062
Batch 36/64 loss: -2.575946807861328
Batch 37/64 loss: -2.8024187088012695
Batch 38/64 loss: -2.330110549926758
Batch 39/64 loss: -2.829707145690918
Batch 40/64 loss: -2.7960681915283203
Batch 41/64 loss: -2.776106834411621
Batch 42/64 loss: -2.573240280151367
Batch 43/64 loss: -2.8912477493286133
Batch 44/64 loss: -2.7194900512695312
Batch 45/64 loss: -2.7571277618408203
Batch 46/64 loss: -2.6203603744506836
Batch 47/64 loss: -2.687302589416504
Batch 48/64 loss: -2.8151588439941406
Batch 49/64 loss: -2.612666130065918
Batch 50/64 loss: -2.857659339904785
Batch 51/64 loss: -2.883970260620117
Batch 52/64 loss: -2.7608251571655273
Batch 53/64 loss: -2.658834457397461
Batch 54/64 loss: -2.5542030334472656
Batch 55/64 loss: -2.8016414642333984
Batch 56/64 loss: -2.6779956817626953
Batch 57/64 loss: -2.6931562423706055
Batch 58/64 loss: -2.685847282409668
Batch 59/64 loss: -2.968273162841797
Batch 60/64 loss: -2.69283390045166
Batch 61/64 loss: -2.767864227294922
Batch 62/64 loss: -2.8253631591796875
Batch 63/64 loss: -2.86529541015625
Batch 64/64 loss: -7.259832859039307
Epoch 320  Train loss: -2.749931288700478  Val loss: -2.844729512008195
Epoch 321
-------------------------------
Batch 1/64 loss: -2.5938234329223633
Batch 2/64 loss: -2.8150548934936523
Batch 3/64 loss: -2.7701616287231445
Batch 4/64 loss: -2.7845096588134766
Batch 5/64 loss: -2.6289634704589844
Batch 6/64 loss: -2.0200023651123047
Batch 7/64 loss: -2.843862533569336
Batch 8/64 loss: -2.862809181213379
Batch 9/64 loss: -2.7676563262939453
Batch 10/64 loss: -2.5371580123901367
Batch 11/64 loss: -2.4481449127197266
Batch 12/64 loss: -2.026947021484375
Batch 13/64 loss: -2.6133508682250977
Batch 14/64 loss: -2.940863609313965
Batch 15/64 loss: -2.5187339782714844
Batch 16/64 loss: -2.7513628005981445
Batch 17/64 loss: -2.9240598678588867
Batch 18/64 loss: -2.9441347122192383
Batch 19/64 loss: -2.7784862518310547
Batch 20/64 loss: -2.5619239807128906
Batch 21/64 loss: -2.8306283950805664
Batch 22/64 loss: -2.330331802368164
Batch 23/64 loss: -2.608613967895508
Batch 24/64 loss: -2.7483348846435547
Batch 25/64 loss: -2.70242977142334
Batch 26/64 loss: -2.4019460678100586
Batch 27/64 loss: -2.694429397583008
Batch 28/64 loss: -2.3218822479248047
Batch 29/64 loss: -2.5647077560424805
Batch 30/64 loss: -2.670680046081543
Batch 31/64 loss: -2.642930030822754
Batch 32/64 loss: -2.8131017684936523
Batch 33/64 loss: -2.9289026260375977
Batch 34/64 loss: -2.8253002166748047
Batch 35/64 loss: -2.751154899597168
Batch 36/64 loss: -2.6692867279052734
Batch 37/64 loss: -2.8724489212036133
Batch 38/64 loss: -2.7713842391967773
Batch 39/64 loss: -2.818317413330078
Batch 40/64 loss: -2.2910614013671875
Batch 41/64 loss: -2.8927125930786133
Batch 42/64 loss: -2.7972917556762695
Batch 43/64 loss: -2.735772132873535
Batch 44/64 loss: -2.8834609985351562
Batch 45/64 loss: -2.778657913208008
Batch 46/64 loss: -2.7684078216552734
Batch 47/64 loss: -2.6018295288085938
Batch 48/64 loss: -2.5845155715942383
Batch 49/64 loss: -2.8573522567749023
Batch 50/64 loss: -2.9500770568847656
Batch 51/64 loss: -2.761237144470215
Batch 52/64 loss: -2.926828384399414
Batch 53/64 loss: -2.774810791015625
Batch 54/64 loss: -2.7928619384765625
Batch 55/64 loss: -2.7203636169433594
Batch 56/64 loss: -2.432802200317383
Batch 57/64 loss: -2.9241933822631836
Batch 58/64 loss: -2.883096694946289
Batch 59/64 loss: -2.6027679443359375
Batch 60/64 loss: -2.888652801513672
Batch 61/64 loss: -2.3291778564453125
Batch 62/64 loss: -2.7429866790771484
Batch 63/64 loss: -2.8753814697265625
Batch 64/64 loss: -7.426973342895508
Epoch 321  Train loss: -2.7523976569082222  Val loss: -3.0639153575569495
Epoch 322
-------------------------------
Batch 1/64 loss: -2.14717960357666
Batch 2/64 loss: -2.7647933959960938
Batch 3/64 loss: -2.7294960021972656
Batch 4/64 loss: -2.3797359466552734
Batch 5/64 loss: -2.8953447341918945
Batch 6/64 loss: -2.4716672897338867
Batch 7/64 loss: -2.7084503173828125
Batch 8/64 loss: -2.7269906997680664
Batch 9/64 loss: -2.813084602355957
Batch 10/64 loss: -2.5226240158081055
Batch 11/64 loss: -2.948507308959961
Batch 12/64 loss: -2.727275848388672
Batch 13/64 loss: -2.872934341430664
Batch 14/64 loss: -2.55417537689209
Batch 15/64 loss: -2.602372169494629
Batch 16/64 loss: -2.6420488357543945
Batch 17/64 loss: -2.693307876586914
Batch 18/64 loss: -2.5509939193725586
Batch 19/64 loss: -2.6569786071777344
Batch 20/64 loss: -2.673405647277832
Batch 21/64 loss: -2.6038284301757812
Batch 22/64 loss: -2.903622627258301
Batch 23/64 loss: -2.6000986099243164
Batch 24/64 loss: -2.751821517944336
Batch 25/64 loss: -2.696446418762207
Batch 26/64 loss: -2.765237808227539
Batch 27/64 loss: -2.6879405975341797
Batch 28/64 loss: -2.837146759033203
Batch 29/64 loss: -2.2699718475341797
Batch 30/64 loss: -2.5035409927368164
Batch 31/64 loss: -2.907090187072754
Batch 32/64 loss: -2.6464080810546875
Batch 33/64 loss: -2.8821325302124023
Batch 34/64 loss: -2.5397825241088867
Batch 35/64 loss: -2.7786951065063477
Batch 36/64 loss: -2.4132747650146484
Batch 37/64 loss: -2.6580591201782227
Batch 38/64 loss: -2.811918258666992
Batch 39/64 loss: -2.8816261291503906
Batch 40/64 loss: -2.7127485275268555
Batch 41/64 loss: -2.589512825012207
Batch 42/64 loss: -2.710341453552246
Batch 43/64 loss: -2.6782398223876953
Batch 44/64 loss: -2.6861181259155273
Batch 45/64 loss: -2.7972211837768555
Batch 46/64 loss: -2.7697267532348633
Batch 47/64 loss: -2.603081703186035
Batch 48/64 loss: -2.7123794555664062
Batch 49/64 loss: -2.856783866882324
Batch 50/64 loss: -2.7926559448242188
Batch 51/64 loss: -2.767559051513672
Batch 52/64 loss: -2.6168956756591797
Batch 53/64 loss: -2.7505922317504883
Batch 54/64 loss: -2.4474363327026367
Batch 55/64 loss: -2.7072324752807617
Batch 56/64 loss: -2.855684280395508
Batch 57/64 loss: -2.715460777282715
Batch 58/64 loss: -2.592672348022461
Batch 59/64 loss: -2.6417465209960938
Batch 60/64 loss: -2.3407506942749023
Batch 61/64 loss: -2.633389472961426
Batch 62/64 loss: -2.6162052154541016
Batch 63/64 loss: -2.699221611022949
Batch 64/64 loss: -6.994102478027344
Epoch 322  Train loss: -2.7256351695341223  Val loss: -2.8870214481943663
Epoch 323
-------------------------------
Batch 1/64 loss: -2.425225257873535
Batch 2/64 loss: -2.4145870208740234
Batch 3/64 loss: -2.7790660858154297
Batch 4/64 loss: -2.658029556274414
Batch 5/64 loss: -2.899557113647461
Batch 6/64 loss: -2.491535186767578
Batch 7/64 loss: -2.77626895904541
Batch 8/64 loss: -2.7087221145629883
Batch 9/64 loss: -2.1038122177124023
Batch 10/64 loss: -2.3074703216552734
Batch 11/64 loss: -2.9117565155029297
Batch 12/64 loss: -1.625685691833496
Batch 13/64 loss: -2.284886360168457
Batch 14/64 loss: -2.4551124572753906
Batch 15/64 loss: -2.6870508193969727
Batch 16/64 loss: -2.6331071853637695
Batch 17/64 loss: -2.8398170471191406
Batch 18/64 loss: -2.6916465759277344
Batch 19/64 loss: -1.9363412857055664
Batch 20/64 loss: -2.206411361694336
Batch 21/64 loss: -2.2360429763793945
Batch 22/64 loss: -2.447930335998535
Batch 23/64 loss: -2.4055633544921875
Batch 24/64 loss: -2.475653648376465
Batch 25/64 loss: -2.4697799682617188
Batch 26/64 loss: -2.4245262145996094
Batch 27/64 loss: -2.3334274291992188
Batch 28/64 loss: -1.8793973922729492
Batch 29/64 loss: -2.528965950012207
Batch 30/64 loss: -2.718729019165039
Batch 31/64 loss: -2.506753921508789
Batch 32/64 loss: -2.6527767181396484
Batch 33/64 loss: -1.7612018585205078
Batch 34/64 loss: -2.6208744049072266
Batch 35/64 loss: -2.494856834411621
Batch 36/64 loss: -2.125990867614746
Batch 37/64 loss: -2.500189781188965
Batch 38/64 loss: -2.4623889923095703
Batch 39/64 loss: -2.2690420150756836
Batch 40/64 loss: -2.6790876388549805
Batch 41/64 loss: -2.4230289459228516
Batch 42/64 loss: -2.608757972717285
Batch 43/64 loss: -2.445690155029297
Batch 44/64 loss: -2.54201602935791
Batch 45/64 loss: -2.4192771911621094
Batch 46/64 loss: -2.7577896118164062
Batch 47/64 loss: -2.506834030151367
Batch 48/64 loss: -1.984522819519043
Batch 49/64 loss: -2.72506046295166
Batch 50/64 loss: -2.499530792236328
Batch 51/64 loss: -2.5144214630126953
Batch 52/64 loss: -2.361757278442383
Batch 53/64 loss: -2.704094886779785
Batch 54/64 loss: -2.5070953369140625
Batch 55/64 loss: -2.6367244720458984
Batch 56/64 loss: -2.3558616638183594
Batch 57/64 loss: -2.381429672241211
Batch 58/64 loss: -2.588329315185547
Batch 59/64 loss: -2.7250423431396484
Batch 60/64 loss: -2.381256103515625
Batch 61/64 loss: -2.553055763244629
Batch 62/64 loss: -2.673619270324707
Batch 63/64 loss: -2.646221160888672
Batch 64/64 loss: -7.346446990966797
Epoch 323  Train loss: -2.5298905166925167  Val loss: -2.830308579906975
Epoch 324
-------------------------------
Batch 1/64 loss: -2.4592132568359375
Batch 2/64 loss: -2.5649919509887695
Batch 3/64 loss: -2.6667346954345703
Batch 4/64 loss: -2.7863264083862305
Batch 5/64 loss: -2.4751710891723633
Batch 6/64 loss: -2.5020360946655273
Batch 7/64 loss: -2.786574363708496
Batch 8/64 loss: -2.1926183700561523
Batch 9/64 loss: -2.125896453857422
Batch 10/64 loss: -2.392120361328125
Batch 11/64 loss: -2.7014074325561523
Batch 12/64 loss: -2.636117935180664
Batch 13/64 loss: -2.6783828735351562
Batch 14/64 loss: -2.48684024810791
Batch 15/64 loss: -2.4432497024536133
Batch 16/64 loss: -2.4963417053222656
Batch 17/64 loss: -2.8309030532836914
Batch 18/64 loss: -2.5570363998413086
Batch 19/64 loss: -2.2553911209106445
Batch 20/64 loss: -2.684816360473633
Batch 21/64 loss: -2.619518280029297
Batch 22/64 loss: -2.7294578552246094
Batch 23/64 loss: -2.3253774642944336
Batch 24/64 loss: -2.6180076599121094
Batch 25/64 loss: -2.2378721237182617
Batch 26/64 loss: -2.630350112915039
Batch 27/64 loss: -2.4331369400024414
Batch 28/64 loss: -2.5042381286621094
Batch 29/64 loss: -2.505709648132324
Batch 30/64 loss: -2.6503849029541016
Batch 31/64 loss: -2.2047414779663086
Batch 32/64 loss: -1.7338457107543945
Batch 33/64 loss: -2.7701644897460938
Batch 34/64 loss: -2.5488672256469727
Batch 35/64 loss: -2.5099639892578125
Batch 36/64 loss: -2.5075111389160156
Batch 37/64 loss: -2.6362409591674805
Batch 38/64 loss: -2.7690839767456055
Batch 39/64 loss: -2.7832508087158203
Batch 40/64 loss: -2.748605728149414
Batch 41/64 loss: -2.0796279907226562
Batch 42/64 loss: -2.644746780395508
Batch 43/64 loss: -2.7694272994995117
Batch 44/64 loss: -2.5401153564453125
Batch 45/64 loss: -2.6137704849243164
Batch 46/64 loss: -2.676912307739258
Batch 47/64 loss: -2.7789249420166016
Batch 48/64 loss: -2.722813606262207
Batch 49/64 loss: -2.5818214416503906
Batch 50/64 loss: -2.595627784729004
Batch 51/64 loss: -2.6713638305664062
Batch 52/64 loss: -2.685251235961914
Batch 53/64 loss: -2.456270217895508
Batch 54/64 loss: -2.5811843872070312
Batch 55/64 loss: -2.3667898178100586
Batch 56/64 loss: -1.3121585845947266
Batch 57/64 loss: -2.230915069580078
Batch 58/64 loss: -2.354686737060547
Batch 59/64 loss: -2.6756038665771484
Batch 60/64 loss: -2.2920618057250977
Batch 61/64 loss: -2.7526111602783203
Batch 62/64 loss: -2.6453561782836914
Batch 63/64 loss: -2.542510986328125
Batch 64/64 loss: -7.251126289367676
Epoch 324  Train loss: -2.57564541311825  Val loss: -2.8620024743358705
Epoch 325
-------------------------------
Batch 1/64 loss: -2.628324508666992
Batch 2/64 loss: -2.4643049240112305
Batch 3/64 loss: -2.8515024185180664
Batch 4/64 loss: -2.4185781478881836
Batch 5/64 loss: -2.8410825729370117
Batch 6/64 loss: -2.7282323837280273
Batch 7/64 loss: -2.526357650756836
Batch 8/64 loss: -2.7387237548828125
Batch 9/64 loss: -2.3609256744384766
Batch 10/64 loss: -2.7007999420166016
Batch 11/64 loss: -2.4850711822509766
Batch 12/64 loss: -2.678044319152832
Batch 13/64 loss: -2.7214231491088867
Batch 14/64 loss: -2.841136932373047
Batch 15/64 loss: -2.1307010650634766
Batch 16/64 loss: -2.7005128860473633
Batch 17/64 loss: -2.296977996826172
Batch 18/64 loss: -2.608095169067383
Batch 19/64 loss: -2.706361770629883
Batch 20/64 loss: -2.481842041015625
Batch 21/64 loss: -2.6649246215820312
Batch 22/64 loss: -2.8350353240966797
Batch 23/64 loss: -2.7643213272094727
Batch 24/64 loss: -2.522139549255371
Batch 25/64 loss: -2.5804405212402344
Batch 26/64 loss: -2.873811721801758
Batch 27/64 loss: -2.5313472747802734
Batch 28/64 loss: -2.8612442016601562
Batch 29/64 loss: -2.6405029296875
Batch 30/64 loss: -2.567272186279297
Batch 31/64 loss: -2.4776830673217773
Batch 32/64 loss: -2.582552909851074
Batch 33/64 loss: -2.3106164932250977
Batch 34/64 loss: -2.788280487060547
Batch 35/64 loss: -2.6231164932250977
Batch 36/64 loss: -2.498847007751465
Batch 37/64 loss: -2.5965652465820312
Batch 38/64 loss: -2.750460624694824
Batch 39/64 loss: -2.6473493576049805
Batch 40/64 loss: -2.836777687072754
Batch 41/64 loss: -2.674637794494629
Batch 42/64 loss: -2.9008617401123047
Batch 43/64 loss: -2.533355712890625
Batch 44/64 loss: -2.846355438232422
Batch 45/64 loss: -2.1576480865478516
Batch 46/64 loss: -2.852445602416992
Batch 47/64 loss: -2.6886472702026367
Batch 48/64 loss: -2.5526504516601562
Batch 49/64 loss: -2.7677316665649414
Batch 50/64 loss: -2.8613805770874023
Batch 51/64 loss: -2.663527488708496
Batch 52/64 loss: -2.0045318603515625
Batch 53/64 loss: -2.550853729248047
Batch 54/64 loss: -2.5842247009277344
Batch 55/64 loss: -2.8231897354125977
Batch 56/64 loss: -2.4467086791992188
Batch 57/64 loss: -2.5660009384155273
Batch 58/64 loss: -2.556285858154297
Batch 59/64 loss: -2.344369888305664
Batch 60/64 loss: -2.173921585083008
Batch 61/64 loss: -2.8083438873291016
Batch 62/64 loss: -2.5966796875
Batch 63/64 loss: -2.4234180450439453
Batch 64/64 loss: -7.270827770233154
Epoch 325  Train loss: -2.661853784673354  Val loss: -2.856604494180057
Epoch 326
-------------------------------
Batch 1/64 loss: -2.5632104873657227
Batch 2/64 loss: -2.7411861419677734
Batch 3/64 loss: -2.7078638076782227
Batch 4/64 loss: -2.6408653259277344
Batch 5/64 loss: -2.7573976516723633
Batch 6/64 loss: -2.4684104919433594
Batch 7/64 loss: -2.5777788162231445
Batch 8/64 loss: -2.6676692962646484
Batch 9/64 loss: -2.6708879470825195
Batch 10/64 loss: -2.2580556869506836
Batch 11/64 loss: -2.623734474182129
Batch 12/64 loss: -2.8851547241210938
Batch 13/64 loss: -2.4196548461914062
Batch 14/64 loss: -2.837418556213379
Batch 15/64 loss: -2.568495750427246
Batch 16/64 loss: -2.7586889266967773
Batch 17/64 loss: -2.4156246185302734
Batch 18/64 loss: -2.3954925537109375
Batch 19/64 loss: -2.709660530090332
Batch 20/64 loss: -2.2271957397460938
Batch 21/64 loss: -2.5576820373535156
Batch 22/64 loss: -2.6578969955444336
Batch 23/64 loss: -2.37075138092041
Batch 24/64 loss: -2.3491392135620117
Batch 25/64 loss: -2.0504579544067383
Batch 26/64 loss: -2.694488525390625
Batch 27/64 loss: -2.745713233947754
Batch 28/64 loss: -2.5446348190307617
Batch 29/64 loss: -2.3083276748657227
Batch 30/64 loss: -2.498615264892578
Batch 31/64 loss: -2.816854476928711
Batch 32/64 loss: -2.592763900756836
Batch 33/64 loss: -2.8148317337036133
Batch 34/64 loss: -2.2242565155029297
Batch 35/64 loss: -2.7333459854125977
Batch 36/64 loss: -1.9408292770385742
Batch 37/64 loss: -2.7606611251831055
Batch 38/64 loss: -2.8533191680908203
Batch 39/64 loss: -2.704209327697754
Batch 40/64 loss: -2.833224296569824
Batch 41/64 loss: -2.466403007507324
Batch 42/64 loss: -2.611819267272949
Batch 43/64 loss: -2.836179733276367
Batch 44/64 loss: -2.4782161712646484
Batch 45/64 loss: -2.586477279663086
Batch 46/64 loss: -2.7518253326416016
Batch 47/64 loss: -2.6170310974121094
Batch 48/64 loss: -2.7284603118896484
Batch 49/64 loss: -2.222195625305176
Batch 50/64 loss: -2.855902671813965
Batch 51/64 loss: -2.7687835693359375
Batch 52/64 loss: -2.6969566345214844
Batch 53/64 loss: -2.555985450744629
Batch 54/64 loss: -2.7056665420532227
Batch 55/64 loss: -2.2368993759155273
Batch 56/64 loss: -2.736588478088379
Batch 57/64 loss: -2.570664405822754
Batch 58/64 loss: -2.3912124633789062
Batch 59/64 loss: -2.7328357696533203
Batch 60/64 loss: -2.7309207916259766
Batch 61/64 loss: -2.714705467224121
Batch 62/64 loss: -2.59661865234375
Batch 63/64 loss: -2.4664907455444336
Batch 64/64 loss: -7.342411041259766
Epoch 326  Train loss: -2.6433270024318323  Val loss: -2.8640200428127014
Epoch 327
-------------------------------
Batch 1/64 loss: -2.537470817565918
Batch 2/64 loss: -2.7477102279663086
Batch 3/64 loss: -2.652693748474121
Batch 4/64 loss: -2.0552072525024414
Batch 5/64 loss: -1.9342050552368164
Batch 6/64 loss: -2.6541433334350586
Batch 7/64 loss: -2.50815486907959
Batch 8/64 loss: -2.2498788833618164
Batch 9/64 loss: -2.594752311706543
Batch 10/64 loss: -2.4926414489746094
Batch 11/64 loss: -2.045591354370117
Batch 12/64 loss: -2.48403263092041
Batch 13/64 loss: -2.889352798461914
Batch 14/64 loss: -2.705453872680664
Batch 15/64 loss: -2.466893196105957
Batch 16/64 loss: -2.560894012451172
Batch 17/64 loss: -2.918553352355957
Batch 18/64 loss: -2.334348678588867
Batch 19/64 loss: -2.6698379516601562
Batch 20/64 loss: -2.880094528198242
Batch 21/64 loss: -2.5051040649414062
Batch 22/64 loss: -2.4553747177124023
Batch 23/64 loss: -2.805293083190918
Batch 24/64 loss: -2.8774662017822266
Batch 25/64 loss: -2.974907875061035
Batch 26/64 loss: -2.558584213256836
Batch 27/64 loss: -2.779446601867676
Batch 28/64 loss: -2.7726354598999023
Batch 29/64 loss: -2.7821474075317383
Batch 30/64 loss: -2.810823440551758
Batch 31/64 loss: -2.839663505554199
Batch 32/64 loss: -2.949094772338867
Batch 33/64 loss: -2.66439151763916
Batch 34/64 loss: -2.708338737487793
Batch 35/64 loss: -2.8213376998901367
Batch 36/64 loss: -2.5259084701538086
Batch 37/64 loss: -2.7477054595947266
Batch 38/64 loss: -2.462651252746582
Batch 39/64 loss: -2.6843643188476562
Batch 40/64 loss: -2.9019737243652344
Batch 41/64 loss: -2.6836471557617188
Batch 42/64 loss: -2.782390594482422
Batch 43/64 loss: -2.8970937728881836
Batch 44/64 loss: -2.6834259033203125
Batch 45/64 loss: -1.8560724258422852
Batch 46/64 loss: -2.850870132446289
Batch 47/64 loss: -2.4353294372558594
Batch 48/64 loss: -2.7662086486816406
Batch 49/64 loss: -2.6330909729003906
Batch 50/64 loss: -2.776437759399414
Batch 51/64 loss: -2.694864273071289
Batch 52/64 loss: -2.629779815673828
Batch 53/64 loss: -2.850576400756836
Batch 54/64 loss: -2.7567319869995117
Batch 55/64 loss: -2.607163429260254
Batch 56/64 loss: -2.782564163208008
Batch 57/64 loss: -2.8105506896972656
Batch 58/64 loss: -2.7425155639648438
Batch 59/64 loss: -2.916201591491699
Batch 60/64 loss: -2.7222137451171875
Batch 61/64 loss: -2.5982866287231445
Batch 62/64 loss: -2.5090904235839844
Batch 63/64 loss: -2.8858089447021484
Batch 64/64 loss: -7.506028652191162
Epoch 327  Train loss: -2.706032294853061  Val loss: -2.9814810605393243
Epoch 328
-------------------------------
Batch 1/64 loss: -2.993281364440918
Batch 2/64 loss: -2.8877792358398438
Batch 3/64 loss: -2.8371782302856445
Batch 4/64 loss: -2.750028610229492
Batch 5/64 loss: -2.4385290145874023
Batch 6/64 loss: -2.4149904251098633
Batch 7/64 loss: -2.7091569900512695
Batch 8/64 loss: -2.7296533584594727
Batch 9/64 loss: -2.6711206436157227
Batch 10/64 loss: -2.658510208129883
Batch 11/64 loss: -2.712794303894043
Batch 12/64 loss: -2.9599618911743164
Batch 13/64 loss: -2.806673049926758
Batch 14/64 loss: -2.772188186645508
Batch 15/64 loss: -2.78456974029541
Batch 16/64 loss: -2.734619140625
Batch 17/64 loss: -2.6546220779418945
Batch 18/64 loss: -2.706390380859375
Batch 19/64 loss: -2.711939811706543
Batch 20/64 loss: -2.6085357666015625
Batch 21/64 loss: -2.8483428955078125
Batch 22/64 loss: -2.657172203063965
Batch 23/64 loss: -2.655374526977539
Batch 24/64 loss: -2.5622005462646484
Batch 25/64 loss: -2.8369436264038086
Batch 26/64 loss: -2.7427473068237305
Batch 27/64 loss: -2.9756603240966797
Batch 28/64 loss: -2.900578498840332
Batch 29/64 loss: -2.7762279510498047
Batch 30/64 loss: -2.7087182998657227
Batch 31/64 loss: -2.6531782150268555
Batch 32/64 loss: -2.8882875442504883
Batch 33/64 loss: -2.9326953887939453
Batch 34/64 loss: -2.6069412231445312
Batch 35/64 loss: -2.7984933853149414
Batch 36/64 loss: -2.2263307571411133
Batch 37/64 loss: -2.602240562438965
Batch 38/64 loss: -2.785080909729004
Batch 39/64 loss: -2.994884490966797
Batch 40/64 loss: -2.3510961532592773
Batch 41/64 loss: -2.5497217178344727
Batch 42/64 loss: -2.466519355773926
Batch 43/64 loss: -1.9548559188842773
Batch 44/64 loss: -2.67746639251709
Batch 45/64 loss: -1.9813385009765625
Batch 46/64 loss: -2.7780141830444336
Batch 47/64 loss: -2.832836151123047
Batch 48/64 loss: -2.652402877807617
Batch 49/64 loss: -2.643148422241211
Batch 50/64 loss: -2.76214599609375
Batch 51/64 loss: -2.1915111541748047
Batch 52/64 loss: -2.1841793060302734
Batch 53/64 loss: -2.764346122741699
Batch 54/64 loss: -2.8763322830200195
Batch 55/64 loss: -2.7509050369262695
Batch 56/64 loss: -2.7920732498168945
Batch 57/64 loss: -2.866145133972168
Batch 58/64 loss: -2.801759719848633
Batch 59/64 loss: -2.957819938659668
Batch 60/64 loss: -2.9430131912231445
Batch 61/64 loss: -2.770623207092285
Batch 62/64 loss: -2.741924285888672
Batch 63/64 loss: -2.49857234954834
Batch 64/64 loss: -7.233527183532715
Epoch 328  Train loss: -2.743663013682646  Val loss: -3.095606813725737
Epoch 329
-------------------------------
Batch 1/64 loss: -2.9756221771240234
Batch 2/64 loss: -2.7195043563842773
Batch 3/64 loss: -2.7675371170043945
Batch 4/64 loss: -2.929558753967285
Batch 5/64 loss: -2.801727294921875
Batch 6/64 loss: -2.8828020095825195
Batch 7/64 loss: -2.611874580383301
Batch 8/64 loss: -2.6959705352783203
Batch 9/64 loss: -2.756784439086914
Batch 10/64 loss: -2.268218994140625
Batch 11/64 loss: -2.81911563873291
Batch 12/64 loss: -2.7516021728515625
Batch 13/64 loss: -2.247495651245117
Batch 14/64 loss: -2.8135480880737305
Batch 15/64 loss: -2.558405876159668
Batch 16/64 loss: -2.865536689758301
Batch 17/64 loss: -2.864370346069336
Batch 18/64 loss: -2.6666393280029297
Batch 19/64 loss: -2.2653446197509766
Batch 20/64 loss: -3.033564567565918
Batch 21/64 loss: -2.7789430618286133
Batch 22/64 loss: -2.6932668685913086
Batch 23/64 loss: -2.3862972259521484
Batch 24/64 loss: -2.7643022537231445
Batch 25/64 loss: -3.0881471633911133
Batch 26/64 loss: -2.8449525833129883
Batch 27/64 loss: -2.7907543182373047
Batch 28/64 loss: -2.2241525650024414
Batch 29/64 loss: -2.798208236694336
Batch 30/64 loss: -2.3739967346191406
Batch 31/64 loss: -2.9243202209472656
Batch 32/64 loss: -2.665358543395996
Batch 33/64 loss: -2.9722909927368164
Batch 34/64 loss: -2.8987226486206055
Batch 35/64 loss: -2.938089370727539
Batch 36/64 loss: -2.661097526550293
Batch 37/64 loss: -2.85797119140625
Batch 38/64 loss: -2.860529899597168
Batch 39/64 loss: -2.8832712173461914
Batch 40/64 loss: -2.7792739868164062
Batch 41/64 loss: -2.7876272201538086
Batch 42/64 loss: -2.9336280822753906
Batch 43/64 loss: -2.5860719680786133
Batch 44/64 loss: -3.0319862365722656
Batch 45/64 loss: -2.6264257431030273
Batch 46/64 loss: -2.6475982666015625
Batch 47/64 loss: -2.96285343170166
Batch 48/64 loss: -2.7796754837036133
Batch 49/64 loss: -2.8461246490478516
Batch 50/64 loss: -2.839570999145508
Batch 51/64 loss: -2.9989500045776367
Batch 52/64 loss: -2.6295080184936523
Batch 53/64 loss: -2.6546030044555664
Batch 54/64 loss: -2.5405941009521484
Batch 55/64 loss: -2.197596549987793
Batch 56/64 loss: -2.8230791091918945
Batch 57/64 loss: -2.768033027648926
Batch 58/64 loss: -2.6672897338867188
Batch 59/64 loss: -2.8727054595947266
Batch 60/64 loss: -2.964506149291992
Batch 61/64 loss: -2.8709564208984375
Batch 62/64 loss: -2.691555976867676
Batch 63/64 loss: -2.9224853515625
Batch 64/64 loss: -7.189435005187988
Epoch 329  Train loss: -2.8002301347021965  Val loss: -3.1481355883411526
Saving best model, epoch: 329
Epoch 330
-------------------------------
Batch 1/64 loss: -2.8835220336914062
Batch 2/64 loss: -2.936185836791992
Batch 3/64 loss: -2.7650375366210938
Batch 4/64 loss: -2.778834342956543
Batch 5/64 loss: -2.779789924621582
Batch 6/64 loss: -3.011948585510254
Batch 7/64 loss: -2.778550148010254
Batch 8/64 loss: -2.755636215209961
Batch 9/64 loss: -2.6815662384033203
Batch 10/64 loss: -2.907794952392578
Batch 11/64 loss: -2.2960205078125
Batch 12/64 loss: -2.91428279876709
Batch 13/64 loss: -2.432680130004883
Batch 14/64 loss: -2.547933578491211
Batch 15/64 loss: -2.991464614868164
Batch 16/64 loss: -2.4947023391723633
Batch 17/64 loss: -2.724000930786133
Batch 18/64 loss: -2.6843738555908203
Batch 19/64 loss: -2.969463348388672
Batch 20/64 loss: -2.8904333114624023
Batch 21/64 loss: -1.416060447692871
Batch 22/64 loss: -2.63494873046875
Batch 23/64 loss: -2.70709228515625
Batch 24/64 loss: -2.7155227661132812
Batch 25/64 loss: -2.7819156646728516
Batch 26/64 loss: -2.612574577331543
Batch 27/64 loss: -2.8319873809814453
Batch 28/64 loss: -2.8443775177001953
Batch 29/64 loss: -2.8437986373901367
Batch 30/64 loss: -2.6978273391723633
Batch 31/64 loss: -2.9900951385498047
Batch 32/64 loss: -2.767059326171875
Batch 33/64 loss: -2.8753604888916016
Batch 34/64 loss: -2.6517114639282227
Batch 35/64 loss: -2.71555233001709
Batch 36/64 loss: -2.2915658950805664
Batch 37/64 loss: -2.659731864929199
Batch 38/64 loss: -2.7767791748046875
Batch 39/64 loss: -2.86722469329834
Batch 40/64 loss: -2.6262664794921875
Batch 41/64 loss: -2.5583581924438477
Batch 42/64 loss: -2.806974411010742
Batch 43/64 loss: -2.3085479736328125
Batch 44/64 loss: -2.9234752655029297
Batch 45/64 loss: -2.178142547607422
Batch 46/64 loss: -2.6107749938964844
Batch 47/64 loss: -2.730362892150879
Batch 48/64 loss: -2.779940605163574
Batch 49/64 loss: -2.779404640197754
Batch 50/64 loss: -2.5725908279418945
Batch 51/64 loss: -2.8229236602783203
Batch 52/64 loss: -2.6042823791503906
Batch 53/64 loss: -2.8407459259033203
Batch 54/64 loss: -2.7493715286254883
Batch 55/64 loss: -2.315340042114258
Batch 56/64 loss: -2.6715879440307617
Batch 57/64 loss: -2.5667858123779297
Batch 58/64 loss: -2.094358444213867
Batch 59/64 loss: -2.810382843017578
Batch 60/64 loss: -2.739834785461426
Batch 61/64 loss: -2.1223907470703125
Batch 62/64 loss: -2.4093170166015625
Batch 63/64 loss: -2.850311279296875
Batch 64/64 loss: -7.077361106872559
Epoch 330  Train loss: -2.724484690497903  Val loss: -3.0345912684280028
Epoch 331
-------------------------------
Batch 1/64 loss: -2.4784774780273438
Batch 2/64 loss: -2.7911548614501953
Batch 3/64 loss: -2.5869531631469727
Batch 4/64 loss: -2.639407157897949
Batch 5/64 loss: -3.0371932983398438
Batch 6/64 loss: -2.806450843811035
Batch 7/64 loss: -2.906031608581543
Batch 8/64 loss: -2.543118476867676
Batch 9/64 loss: -2.6561050415039062
Batch 10/64 loss: -2.550957679748535
Batch 11/64 loss: -2.8383398056030273
Batch 12/64 loss: -2.728013038635254
Batch 13/64 loss: -2.996718406677246
Batch 14/64 loss: -2.7224807739257812
Batch 15/64 loss: -2.8338327407836914
Batch 16/64 loss: -2.562321662902832
Batch 17/64 loss: -2.8123817443847656
Batch 18/64 loss: -2.746034622192383
Batch 19/64 loss: -2.6894397735595703
Batch 20/64 loss: -2.8934574127197266
Batch 21/64 loss: -2.6924896240234375
Batch 22/64 loss: -2.6733474731445312
Batch 23/64 loss: -2.8305978775024414
Batch 24/64 loss: -2.777194023132324
Batch 25/64 loss: -2.87416934967041
Batch 26/64 loss: -2.598203659057617
Batch 27/64 loss: -2.676772117614746
Batch 28/64 loss: -2.4987363815307617
Batch 29/64 loss: -2.711920738220215
Batch 30/64 loss: -2.9185867309570312
Batch 31/64 loss: -2.6685047149658203
Batch 32/64 loss: -2.798708915710449
Batch 33/64 loss: -2.267239570617676
Batch 34/64 loss: -2.8478260040283203
Batch 35/64 loss: -2.8519630432128906
Batch 36/64 loss: -2.9561710357666016
Batch 37/64 loss: -2.535904884338379
Batch 38/64 loss: -2.5903444290161133
Batch 39/64 loss: -1.6209888458251953
Batch 40/64 loss: -2.6721906661987305
Batch 41/64 loss: -2.864046096801758
Batch 42/64 loss: -2.4195632934570312
Batch 43/64 loss: -2.688295364379883
Batch 44/64 loss: -2.7338762283325195
Batch 45/64 loss: -2.8141250610351562
Batch 46/64 loss: -2.873835563659668
Batch 47/64 loss: -2.7687788009643555
Batch 48/64 loss: -2.778244972229004
Batch 49/64 loss: -2.9025726318359375
Batch 50/64 loss: -2.6477746963500977
Batch 51/64 loss: -2.8182058334350586
Batch 52/64 loss: -2.8392696380615234
Batch 53/64 loss: -2.814512252807617
Batch 54/64 loss: -2.4965410232543945
Batch 55/64 loss: -2.6402149200439453
Batch 56/64 loss: -2.5011167526245117
Batch 57/64 loss: -2.828061103820801
Batch 58/64 loss: -2.8685808181762695
Batch 59/64 loss: -2.312185287475586
Batch 60/64 loss: -2.797175407409668
Batch 61/64 loss: -2.905758857727051
Batch 62/64 loss: -2.563274383544922
Batch 63/64 loss: -2.729231834411621
Batch 64/64 loss: -7.1408467292785645
Epoch 331  Train loss: -2.758299694809259  Val loss: -3.0136105121206174
Epoch 332
-------------------------------
Batch 1/64 loss: -2.658985137939453
Batch 2/64 loss: -2.8431739807128906
Batch 3/64 loss: -2.918872833251953
Batch 4/64 loss: -2.5240278244018555
Batch 5/64 loss: -2.646137237548828
Batch 6/64 loss: -2.5164670944213867
Batch 7/64 loss: -2.7472705841064453
Batch 8/64 loss: -2.7542057037353516
Batch 9/64 loss: -2.8244428634643555
Batch 10/64 loss: -2.7937936782836914
Batch 11/64 loss: -2.846013069152832
Batch 12/64 loss: -2.501331329345703
Batch 13/64 loss: -2.642369270324707
Batch 14/64 loss: -2.699549674987793
Batch 15/64 loss: -1.808272361755371
Batch 16/64 loss: -2.556633949279785
Batch 17/64 loss: -2.9554901123046875
Batch 18/64 loss: -2.8198671340942383
Batch 19/64 loss: -2.8446168899536133
Batch 20/64 loss: -2.7752599716186523
Batch 21/64 loss: -2.4568471908569336
Batch 22/64 loss: -2.5716867446899414
Batch 23/64 loss: -2.699064254760742
Batch 24/64 loss: -2.945248603820801
Batch 25/64 loss: -2.8259658813476562
Batch 26/64 loss: -2.5615577697753906
Batch 27/64 loss: -2.9643430709838867
Batch 28/64 loss: -2.4756879806518555
Batch 29/64 loss: -2.438858985900879
Batch 30/64 loss: -2.714411735534668
Batch 31/64 loss: -2.064685821533203
Batch 32/64 loss: -2.790468215942383
Batch 33/64 loss: -2.597996711730957
Batch 34/64 loss: -2.8701419830322266
Batch 35/64 loss: -2.8114852905273438
Batch 36/64 loss: -2.3610401153564453
Batch 37/64 loss: -2.6952381134033203
Batch 38/64 loss: -2.9240150451660156
Batch 39/64 loss: -2.686652183532715
Batch 40/64 loss: -2.905179023742676
Batch 41/64 loss: -2.7405738830566406
Batch 42/64 loss: -2.7803525924682617
Batch 43/64 loss: -2.843935012817383
Batch 44/64 loss: -2.615407943725586
Batch 45/64 loss: -2.991548538208008
Batch 46/64 loss: -2.807887077331543
Batch 47/64 loss: -2.6361522674560547
Batch 48/64 loss: -2.8909835815429688
Batch 49/64 loss: -2.885989189147949
Batch 50/64 loss: -2.771677017211914
Batch 51/64 loss: -2.696648597717285
Batch 52/64 loss: -2.694149971008301
Batch 53/64 loss: -2.689150810241699
Batch 54/64 loss: -2.6854305267333984
Batch 55/64 loss: -2.82334041595459
Batch 56/64 loss: -2.8491649627685547
Batch 57/64 loss: -2.503244400024414
Batch 58/64 loss: -2.5103302001953125
Batch 59/64 loss: -2.4900102615356445
Batch 60/64 loss: -2.6866254806518555
Batch 61/64 loss: -2.8097152709960938
Batch 62/64 loss: -2.685344696044922
Batch 63/64 loss: -2.7895421981811523
Batch 64/64 loss: -7.198634147644043
Epoch 332  Train loss: -2.7500162498623717  Val loss: -2.906739080894444
Epoch 333
-------------------------------
Batch 1/64 loss: -2.195591926574707
Batch 2/64 loss: -2.6995534896850586
Batch 3/64 loss: -2.7891616821289062
Batch 4/64 loss: -2.353384017944336
Batch 5/64 loss: -2.8597097396850586
Batch 6/64 loss: -2.916116714477539
Batch 7/64 loss: -2.5425586700439453
Batch 8/64 loss: -2.7184085845947266
Batch 9/64 loss: -2.8424482345581055
Batch 10/64 loss: -2.8370065689086914
Batch 11/64 loss: -2.5263242721557617
Batch 12/64 loss: -2.519136428833008
Batch 13/64 loss: -2.4945783615112305
Batch 14/64 loss: -2.915935516357422
Batch 15/64 loss: -2.6905593872070312
Batch 16/64 loss: -2.4962949752807617
Batch 17/64 loss: -2.7268142700195312
Batch 18/64 loss: -2.781680107116699
Batch 19/64 loss: -2.5566816329956055
Batch 20/64 loss: -2.877678871154785
Batch 21/64 loss: -2.556269645690918
Batch 22/64 loss: -2.7338666915893555
Batch 23/64 loss: -2.5109424591064453
Batch 24/64 loss: -2.802501678466797
Batch 25/64 loss: -2.6537256240844727
Batch 26/64 loss: -2.717465400695801
Batch 27/64 loss: -2.5455522537231445
Batch 28/64 loss: -2.7586231231689453
Batch 29/64 loss: -2.4265060424804688
Batch 30/64 loss: -2.2911462783813477
Batch 31/64 loss: -2.226386070251465
Batch 32/64 loss: -2.6333580017089844
Batch 33/64 loss: -2.6470346450805664
Batch 34/64 loss: -2.747006416320801
Batch 35/64 loss: -2.8098440170288086
Batch 36/64 loss: -2.7537479400634766
Batch 37/64 loss: -2.7722129821777344
Batch 38/64 loss: -2.6454219818115234
Batch 39/64 loss: -2.293548583984375
Batch 40/64 loss: -2.810636520385742
Batch 41/64 loss: -2.7485103607177734
Batch 42/64 loss: -2.6870737075805664
Batch 43/64 loss: -2.788188934326172
Batch 44/64 loss: -2.6979169845581055
Batch 45/64 loss: -2.7584409713745117
Batch 46/64 loss: -2.56072998046875
Batch 47/64 loss: -2.077967643737793
Batch 48/64 loss: -2.3817758560180664
Batch 49/64 loss: -2.7573976516723633
Batch 50/64 loss: -2.596980094909668
Batch 51/64 loss: -2.776294708251953
Batch 52/64 loss: -2.918398857116699
Batch 53/64 loss: -2.738072395324707
Batch 54/64 loss: -2.785637855529785
Batch 55/64 loss: -2.5918874740600586
Batch 56/64 loss: -2.38820743560791
Batch 57/64 loss: -1.9814519882202148
Batch 58/64 loss: -2.5659475326538086
Batch 59/64 loss: -2.805683135986328
Batch 60/64 loss: -2.7215137481689453
Batch 61/64 loss: -2.5127620697021484
Batch 62/64 loss: -2.6383094787597656
Batch 63/64 loss: -2.784947395324707
Batch 64/64 loss: -7.1815185546875
Epoch 333  Train loss: -2.687461254643459  Val loss: -3.0556980015076314
Epoch 334
-------------------------------
Batch 1/64 loss: -2.6917877197265625
Batch 2/64 loss: -2.841012954711914
Batch 3/64 loss: -2.701864242553711
Batch 4/64 loss: -2.5907421112060547
Batch 5/64 loss: -2.6187286376953125
Batch 6/64 loss: -2.6991138458251953
Batch 7/64 loss: -2.746095657348633
Batch 8/64 loss: -2.676039695739746
Batch 9/64 loss: -2.4148378372192383
Batch 10/64 loss: -2.8372554779052734
Batch 11/64 loss: -2.6591129302978516
Batch 12/64 loss: -2.5843801498413086
Batch 13/64 loss: -2.641594886779785
Batch 14/64 loss: -2.7178544998168945
Batch 15/64 loss: -2.9107561111450195
Batch 16/64 loss: -2.894211769104004
Batch 17/64 loss: -2.821425437927246
Batch 18/64 loss: -2.8043289184570312
Batch 19/64 loss: -2.559743881225586
Batch 20/64 loss: -2.8721675872802734
Batch 21/64 loss: -2.78017520904541
Batch 22/64 loss: -2.917780876159668
Batch 23/64 loss: -2.37014102935791
Batch 24/64 loss: -2.7255077362060547
Batch 25/64 loss: -2.735995292663574
Batch 26/64 loss: -2.6043500900268555
Batch 27/64 loss: -2.703327178955078
Batch 28/64 loss: -2.2625999450683594
Batch 29/64 loss: -2.539337158203125
Batch 30/64 loss: -2.4357290267944336
Batch 31/64 loss: -2.915475845336914
Batch 32/64 loss: -2.833003044128418
Batch 33/64 loss: -2.640542984008789
Batch 34/64 loss: -2.758167266845703
Batch 35/64 loss: -1.4409475326538086
Batch 36/64 loss: -2.796492576599121
Batch 37/64 loss: -2.659430503845215
Batch 38/64 loss: -2.8443222045898438
Batch 39/64 loss: -2.7095794677734375
Batch 40/64 loss: -2.8243703842163086
Batch 41/64 loss: -2.6382875442504883
Batch 42/64 loss: -1.656132698059082
Batch 43/64 loss: -2.5788068771362305
Batch 44/64 loss: -2.2740182876586914
Batch 45/64 loss: -2.6296157836914062
Batch 46/64 loss: -2.4592370986938477
Batch 47/64 loss: -2.5743865966796875
Batch 48/64 loss: -2.4793405532836914
Batch 49/64 loss: -2.5047388076782227
Batch 50/64 loss: -2.502035140991211
Batch 51/64 loss: -2.69332218170166
Batch 52/64 loss: -2.5189943313598633
Batch 53/64 loss: -2.532278060913086
Batch 54/64 loss: -2.8012351989746094
Batch 55/64 loss: -2.7135868072509766
Batch 56/64 loss: -2.732964515686035
Batch 57/64 loss: -2.466221809387207
Batch 58/64 loss: -2.6425323486328125
Batch 59/64 loss: -2.7911481857299805
Batch 60/64 loss: -2.744710922241211
Batch 61/64 loss: -2.5305967330932617
Batch 62/64 loss: -2.7155656814575195
Batch 63/64 loss: -2.6087799072265625
Batch 64/64 loss: -7.165867328643799
Epoch 334  Train loss: -2.681463000353645  Val loss: -2.902642790804204
Epoch 335
-------------------------------
Batch 1/64 loss: -2.5168981552124023
Batch 2/64 loss: -2.7451114654541016
Batch 3/64 loss: -2.650362968444824
Batch 4/64 loss: -2.3588314056396484
Batch 5/64 loss: -2.435121536254883
Batch 6/64 loss: -2.2705202102661133
Batch 7/64 loss: -2.6048450469970703
Batch 8/64 loss: -2.6718225479125977
Batch 9/64 loss: -2.68808650970459
Batch 10/64 loss: -1.8277921676635742
Batch 11/64 loss: -2.3894948959350586
Batch 12/64 loss: -2.5346412658691406
Batch 13/64 loss: -2.786799430847168
Batch 14/64 loss: -2.864834785461426
Batch 15/64 loss: -2.7379207611083984
Batch 16/64 loss: -2.7769346237182617
Batch 17/64 loss: -2.52817440032959
Batch 18/64 loss: -2.820760726928711
Batch 19/64 loss: -2.780668258666992
Batch 20/64 loss: -2.7627553939819336
Batch 21/64 loss: -2.835129737854004
Batch 22/64 loss: -2.3470115661621094
Batch 23/64 loss: -2.5847787857055664
Batch 24/64 loss: -2.7792978286743164
Batch 25/64 loss: -2.966996192932129
Batch 26/64 loss: -2.18740177154541
Batch 27/64 loss: -2.735288619995117
Batch 28/64 loss: -2.595028877258301
Batch 29/64 loss: -2.647658348083496
Batch 30/64 loss: -2.816068649291992
Batch 31/64 loss: -2.481968879699707
Batch 32/64 loss: -2.6549320220947266
Batch 33/64 loss: -2.1980600357055664
Batch 34/64 loss: -2.3771209716796875
Batch 35/64 loss: -2.6478843688964844
Batch 36/64 loss: -2.823784828186035
Batch 37/64 loss: -2.412175178527832
Batch 38/64 loss: -2.6717376708984375
Batch 39/64 loss: -2.634222984313965
Batch 40/64 loss: -2.6020870208740234
Batch 41/64 loss: -2.4481029510498047
Batch 42/64 loss: -2.7738771438598633
Batch 43/64 loss: -2.765143394470215
Batch 44/64 loss: -2.2452821731567383
Batch 45/64 loss: -2.581547737121582
Batch 46/64 loss: -2.8167495727539062
Batch 47/64 loss: -2.6022396087646484
Batch 48/64 loss: -2.5260868072509766
Batch 49/64 loss: -2.6007423400878906
Batch 50/64 loss: -2.325716972351074
Batch 51/64 loss: -2.8350086212158203
Batch 52/64 loss: -2.6812543869018555
Batch 53/64 loss: -2.847881317138672
Batch 54/64 loss: -2.7289743423461914
Batch 55/64 loss: -2.685892105102539
Batch 56/64 loss: -2.6790332794189453
Batch 57/64 loss: -2.347599983215332
Batch 58/64 loss: -2.842784881591797
Batch 59/64 loss: -2.732542037963867
Batch 60/64 loss: -2.806879997253418
Batch 61/64 loss: -2.605501174926758
Batch 62/64 loss: -2.91217041015625
Batch 63/64 loss: -2.8582210540771484
Batch 64/64 loss: -7.188039779663086
Epoch 335  Train loss: -2.672804282693302  Val loss: -2.923637626097374
Epoch 336
-------------------------------
Batch 1/64 loss: -2.1982173919677734
Batch 2/64 loss: -2.603242874145508
Batch 3/64 loss: -2.642721176147461
Batch 4/64 loss: -2.6326723098754883
Batch 5/64 loss: -2.7154464721679688
Batch 6/64 loss: -2.670294761657715
Batch 7/64 loss: -2.733034133911133
Batch 8/64 loss: -2.7556467056274414
Batch 9/64 loss: -2.744931221008301
Batch 10/64 loss: -2.7648820877075195
Batch 11/64 loss: -2.47934627532959
Batch 12/64 loss: -2.8017005920410156
Batch 13/64 loss: -2.327178955078125
Batch 14/64 loss: -2.66483211517334
Batch 15/64 loss: -2.7313289642333984
Batch 16/64 loss: -2.552623748779297
Batch 17/64 loss: -2.750199317932129
Batch 18/64 loss: -2.3257389068603516
Batch 19/64 loss: -2.79514217376709
Batch 20/64 loss: -2.6859703063964844
Batch 21/64 loss: -2.730794906616211
Batch 22/64 loss: -2.813603401184082
Batch 23/64 loss: -2.791349411010742
Batch 24/64 loss: -2.790189743041992
Batch 25/64 loss: -2.9143295288085938
Batch 26/64 loss: -2.3133440017700195
Batch 27/64 loss: -2.660590171813965
Batch 28/64 loss: -2.3137693405151367
Batch 29/64 loss: -2.907327651977539
Batch 30/64 loss: -2.9345130920410156
Batch 31/64 loss: -2.767491340637207
Batch 32/64 loss: -3.0168113708496094
Batch 33/64 loss: -2.883967399597168
Batch 34/64 loss: -2.0751819610595703
Batch 35/64 loss: -2.756631851196289
Batch 36/64 loss: -2.4824371337890625
Batch 37/64 loss: -2.8133058547973633
Batch 38/64 loss: -2.6145639419555664
Batch 39/64 loss: -2.558736801147461
Batch 40/64 loss: -2.635226249694824
Batch 41/64 loss: -2.642664909362793
Batch 42/64 loss: -2.6015100479125977
Batch 43/64 loss: -2.0966577529907227
Batch 44/64 loss: -2.701467514038086
Batch 45/64 loss: -2.819828987121582
Batch 46/64 loss: -2.68050479888916
Batch 47/64 loss: -2.6472082138061523
Batch 48/64 loss: -2.8899288177490234
Batch 49/64 loss: -2.644186019897461
Batch 50/64 loss: -2.8350830078125
Batch 51/64 loss: -2.826157569885254
Batch 52/64 loss: -2.816497802734375
Batch 53/64 loss: -2.5445070266723633
Batch 54/64 loss: -2.76303768157959
Batch 55/64 loss: -2.5830001831054688
Batch 56/64 loss: -2.6527719497680664
Batch 57/64 loss: -2.8840227127075195
Batch 58/64 loss: -2.3561105728149414
Batch 59/64 loss: -2.625692367553711
Batch 60/64 loss: -2.7694997787475586
Batch 61/64 loss: -2.763564109802246
Batch 62/64 loss: -2.6206960678100586
Batch 63/64 loss: -2.746866226196289
Batch 64/64 loss: -7.296457767486572
Epoch 336  Train loss: -2.7189509503981646  Val loss: -2.9321292732999087
Epoch 337
-------------------------------
Batch 1/64 loss: -2.258991241455078
Batch 2/64 loss: -2.852802276611328
Batch 3/64 loss: -2.123480796813965
Batch 4/64 loss: -2.6448049545288086
Batch 5/64 loss: -2.6650428771972656
Batch 6/64 loss: -2.6979589462280273
Batch 7/64 loss: -2.573929786682129
Batch 8/64 loss: -2.709414482116699
Batch 9/64 loss: -2.698248863220215
Batch 10/64 loss: -2.711348533630371
Batch 11/64 loss: -2.822793960571289
Batch 12/64 loss: -2.6978607177734375
Batch 13/64 loss: -2.7112607955932617
Batch 14/64 loss: -2.8150901794433594
Batch 15/64 loss: -2.703577995300293
Batch 16/64 loss: -2.8018178939819336
Batch 17/64 loss: -2.775867462158203
Batch 18/64 loss: -2.8799257278442383
Batch 19/64 loss: -2.641277313232422
Batch 20/64 loss: -2.6200742721557617
Batch 21/64 loss: -2.7983169555664062
Batch 22/64 loss: -2.631420135498047
Batch 23/64 loss: -2.3684282302856445
Batch 24/64 loss: -2.685293197631836
Batch 25/64 loss: -2.66477108001709
Batch 26/64 loss: -2.857651710510254
Batch 27/64 loss: -2.7185888290405273
Batch 28/64 loss: -2.5132131576538086
Batch 29/64 loss: -2.7716379165649414
Batch 30/64 loss: -2.292308807373047
Batch 31/64 loss: -2.703104019165039
Batch 32/64 loss: -2.5516958236694336
Batch 33/64 loss: -2.8836803436279297
Batch 34/64 loss: -2.589034080505371
Batch 35/64 loss: -2.638674736022949
Batch 36/64 loss: -2.6002817153930664
Batch 37/64 loss: -2.871519088745117
Batch 38/64 loss: -2.6523637771606445
Batch 39/64 loss: -2.8636627197265625
Batch 40/64 loss: -2.7797231674194336
Batch 41/64 loss: -2.4485063552856445
Batch 42/64 loss: -2.6357593536376953
Batch 43/64 loss: -2.830319404602051
Batch 44/64 loss: -2.8667774200439453
Batch 45/64 loss: -2.66082763671875
Batch 46/64 loss: -2.6837539672851562
Batch 47/64 loss: -2.697850227355957
Batch 48/64 loss: -2.8529434204101562
Batch 49/64 loss: -2.3246688842773438
Batch 50/64 loss: -2.5309391021728516
Batch 51/64 loss: -2.6426734924316406
Batch 52/64 loss: -2.535980224609375
Batch 53/64 loss: -2.3199024200439453
Batch 54/64 loss: -2.764719009399414
Batch 55/64 loss: -2.520022392272949
Batch 56/64 loss: -2.8839921951293945
Batch 57/64 loss: -2.3063268661499023
Batch 58/64 loss: -2.684904098510742
Batch 59/64 loss: -1.6055374145507812
Batch 60/64 loss: -2.8298492431640625
Batch 61/64 loss: -2.358234405517578
Batch 62/64 loss: -2.972532272338867
Batch 63/64 loss: -2.491095542907715
Batch 64/64 loss: -7.2950897216796875
Epoch 337  Train loss: -2.6942803326775047  Val loss: -2.9240553551113484
Epoch 338
-------------------------------
Batch 1/64 loss: -1.9491662979125977
Batch 2/64 loss: -2.695850372314453
Batch 3/64 loss: -2.8180017471313477
Batch 4/64 loss: -2.800128936767578
Batch 5/64 loss: -2.7990360260009766
Batch 6/64 loss: -2.7578201293945312
Batch 7/64 loss: -2.635531425476074
Batch 8/64 loss: -2.786625862121582
Batch 9/64 loss: -2.274423599243164
Batch 10/64 loss: -2.883974075317383
Batch 11/64 loss: -2.540254592895508
Batch 12/64 loss: -2.79632568359375
Batch 13/64 loss: -2.7216033935546875
Batch 14/64 loss: -2.998109817504883
Batch 15/64 loss: -2.7365989685058594
Batch 16/64 loss: -2.655961036682129
Batch 17/64 loss: -2.8498411178588867
Batch 18/64 loss: -2.6571760177612305
Batch 19/64 loss: -2.764636993408203
Batch 20/64 loss: -2.809041976928711
Batch 21/64 loss: -2.478038787841797
Batch 22/64 loss: -2.7816619873046875
Batch 23/64 loss: -2.8008127212524414
Batch 24/64 loss: -2.587343215942383
Batch 25/64 loss: -2.607264518737793
Batch 26/64 loss: -2.731642723083496
Batch 27/64 loss: -2.744175910949707
Batch 28/64 loss: -3.026876449584961
Batch 29/64 loss: -2.313192367553711
Batch 30/64 loss: -2.8442935943603516
Batch 31/64 loss: -2.845346450805664
Batch 32/64 loss: -2.726973533630371
Batch 33/64 loss: -2.5716028213500977
Batch 34/64 loss: -2.5716075897216797
Batch 35/64 loss: -2.8756723403930664
Batch 36/64 loss: -2.3113784790039062
Batch 37/64 loss: -2.675337791442871
Batch 38/64 loss: -2.6974029541015625
Batch 39/64 loss: -2.5555715560913086
Batch 40/64 loss: -2.837646484375
Batch 41/64 loss: -2.6852664947509766
Batch 42/64 loss: -2.5490856170654297
Batch 43/64 loss: -2.881443977355957
Batch 44/64 loss: -2.636294364929199
Batch 45/64 loss: -2.660266876220703
Batch 46/64 loss: -2.5603723526000977
Batch 47/64 loss: -2.679454803466797
Batch 48/64 loss: -2.797374725341797
Batch 49/64 loss: -2.709774971008301
Batch 50/64 loss: -2.602499008178711
Batch 51/64 loss: -2.7407655715942383
Batch 52/64 loss: -2.4273910522460938
Batch 53/64 loss: -2.620905876159668
Batch 54/64 loss: -2.725611686706543
Batch 55/64 loss: -2.7380943298339844
Batch 56/64 loss: -2.4929094314575195
Batch 57/64 loss: -2.542266845703125
Batch 58/64 loss: -2.3018836975097656
Batch 59/64 loss: -2.526700973510742
Batch 60/64 loss: -2.3894968032836914
Batch 61/64 loss: -2.774716377258301
Batch 62/64 loss: -2.655484199523926
Batch 63/64 loss: -2.194209098815918
Batch 64/64 loss: -7.192078590393066
Epoch 338  Train loss: -2.710592602748497  Val loss: -3.01174273933332
Epoch 339
-------------------------------
Batch 1/64 loss: -2.7164182662963867
Batch 2/64 loss: -2.6722755432128906
Batch 3/64 loss: -2.7200145721435547
Batch 4/64 loss: -2.5094947814941406
Batch 5/64 loss: -2.7756576538085938
Batch 6/64 loss: -2.7780723571777344
Batch 7/64 loss: -2.665355682373047
Batch 8/64 loss: -2.542398452758789
Batch 9/64 loss: -2.606260299682617
Batch 10/64 loss: -2.86185359954834
Batch 11/64 loss: -2.339719772338867
Batch 12/64 loss: -2.7042484283447266
Batch 13/64 loss: -2.6269750595092773
Batch 14/64 loss: -2.6307220458984375
Batch 15/64 loss: -2.7631540298461914
Batch 16/64 loss: -2.9189233779907227
Batch 17/64 loss: -2.5773983001708984
Batch 18/64 loss: -2.416571617126465
Batch 19/64 loss: -2.570535659790039
Batch 20/64 loss: -2.710376739501953
Batch 21/64 loss: -2.6472244262695312
Batch 22/64 loss: -2.6477861404418945
Batch 23/64 loss: -2.6877927780151367
Batch 24/64 loss: -2.8881540298461914
Batch 25/64 loss: -2.796356201171875
Batch 26/64 loss: -2.801687240600586
Batch 27/64 loss: -2.928508758544922
Batch 28/64 loss: -2.4689159393310547
Batch 29/64 loss: -2.666012763977051
Batch 30/64 loss: -2.538005828857422
Batch 31/64 loss: -2.5996742248535156
Batch 32/64 loss: -2.7744140625
Batch 33/64 loss: -2.950571060180664
Batch 34/64 loss: -2.8617982864379883
Batch 35/64 loss: -2.8487796783447266
Batch 36/64 loss: -2.014371871948242
Batch 37/64 loss: -2.934412956237793
Batch 38/64 loss: -2.6490402221679688
Batch 39/64 loss: -2.592318534851074
Batch 40/64 loss: -2.525157928466797
Batch 41/64 loss: -2.7757883071899414
Batch 42/64 loss: -2.6681594848632812
Batch 43/64 loss: -2.611133575439453
Batch 44/64 loss: -2.4973583221435547
Batch 45/64 loss: -2.514373779296875
Batch 46/64 loss: -2.8437271118164062
Batch 47/64 loss: -2.6022348403930664
Batch 48/64 loss: -2.894015312194824
Batch 49/64 loss: -2.7442541122436523
Batch 50/64 loss: -1.8386993408203125
Batch 51/64 loss: -2.915585517883301
Batch 52/64 loss: -2.5631418228149414
Batch 53/64 loss: -2.848984718322754
Batch 54/64 loss: -2.8806047439575195
Batch 55/64 loss: -2.987116813659668
Batch 56/64 loss: -2.7976865768432617
Batch 57/64 loss: -2.69040584564209
Batch 58/64 loss: -2.806586265563965
Batch 59/64 loss: -2.6669912338256836
Batch 60/64 loss: -2.8528013229370117
Batch 61/64 loss: -2.7845582962036133
Batch 62/64 loss: -2.750356674194336
Batch 63/64 loss: -2.97159481048584
Batch 64/64 loss: -7.3310394287109375
Epoch 339  Train loss: -2.7440289815266925  Val loss: -3.089825174652834
Epoch 340
-------------------------------
Batch 1/64 loss: -2.3286142349243164
Batch 2/64 loss: -2.826785087585449
Batch 3/64 loss: -3.0042572021484375
Batch 4/64 loss: -2.8829469680786133
Batch 5/64 loss: -2.079130172729492
Batch 6/64 loss: -2.763115882873535
Batch 7/64 loss: -2.6316747665405273
Batch 8/64 loss: -2.693800926208496
Batch 9/64 loss: -2.6283226013183594
Batch 10/64 loss: -2.927699089050293
Batch 11/64 loss: -2.832235336303711
Batch 12/64 loss: -2.7642641067504883
Batch 13/64 loss: -2.532944679260254
Batch 14/64 loss: -2.754786491394043
Batch 15/64 loss: -2.0600080490112305
Batch 16/64 loss: -2.774521827697754
Batch 17/64 loss: -2.630941390991211
Batch 18/64 loss: -2.8135852813720703
Batch 19/64 loss: -2.030238151550293
Batch 20/64 loss: -2.817694664001465
Batch 21/64 loss: -2.83089542388916
Batch 22/64 loss: -2.430387496948242
Batch 23/64 loss: -2.735995292663574
Batch 24/64 loss: -2.4916982650756836
Batch 25/64 loss: -2.2364797592163086
Batch 26/64 loss: -2.2053909301757812
Batch 27/64 loss: -2.677276611328125
Batch 28/64 loss: -2.8613576889038086
Batch 29/64 loss: -2.6156234741210938
Batch 30/64 loss: -2.755075454711914
Batch 31/64 loss: -2.682732582092285
Batch 32/64 loss: -2.764267921447754
Batch 33/64 loss: -2.4406328201293945
Batch 34/64 loss: -2.740677833557129
Batch 35/64 loss: -3.086099624633789
Batch 36/64 loss: -2.7480297088623047
Batch 37/64 loss: -2.4959917068481445
Batch 38/64 loss: -2.914944648742676
Batch 39/64 loss: -1.8889474868774414
Batch 40/64 loss: -2.5276308059692383
Batch 41/64 loss: -2.668243408203125
Batch 42/64 loss: -2.8003063201904297
Batch 43/64 loss: -2.4827489852905273
Batch 44/64 loss: -2.6751708984375
Batch 45/64 loss: -2.7253265380859375
Batch 46/64 loss: -2.753824234008789
Batch 47/64 loss: -2.7898597717285156
Batch 48/64 loss: -2.786067008972168
Batch 49/64 loss: -2.8616952896118164
Batch 50/64 loss: -2.7306947708129883
Batch 51/64 loss: -2.5454607009887695
Batch 52/64 loss: -2.361989974975586
Batch 53/64 loss: -2.958026885986328
Batch 54/64 loss: -2.3042030334472656
Batch 55/64 loss: -2.5626068115234375
Batch 56/64 loss: -2.687710762023926
Batch 57/64 loss: -2.5601320266723633
Batch 58/64 loss: -2.6769161224365234
Batch 59/64 loss: -2.414412498474121
Batch 60/64 loss: -2.966329574584961
Batch 61/64 loss: -2.361818313598633
Batch 62/64 loss: -2.6182479858398438
Batch 63/64 loss: -2.774019241333008
Batch 64/64 loss: -6.98666524887085
Epoch 340  Train loss: -2.6857021574880564  Val loss: -3.024540668500658
Epoch 341
-------------------------------
Batch 1/64 loss: -2.0178871154785156
Batch 2/64 loss: -2.7434606552124023
Batch 3/64 loss: -2.655877113342285
Batch 4/64 loss: -2.813295364379883
Batch 5/64 loss: -2.5120439529418945
Batch 6/64 loss: -2.738186836242676
Batch 7/64 loss: -2.8037147521972656
Batch 8/64 loss: -2.6908340454101562
Batch 9/64 loss: -2.6979827880859375
Batch 10/64 loss: -2.679464340209961
Batch 11/64 loss: -2.8743934631347656
Batch 12/64 loss: -2.463009834289551
Batch 13/64 loss: -2.650270462036133
Batch 14/64 loss: -2.447842597961426
Batch 15/64 loss: -2.67138671875
Batch 16/64 loss: -2.2171220779418945
Batch 17/64 loss: -2.613740921020508
Batch 18/64 loss: -2.7862043380737305
Batch 19/64 loss: -2.6466197967529297
Batch 20/64 loss: -2.553915023803711
Batch 21/64 loss: -2.5299339294433594
Batch 22/64 loss: -2.5898685455322266
Batch 23/64 loss: -2.6429100036621094
Batch 24/64 loss: -2.8567562103271484
Batch 25/64 loss: -2.8471908569335938
Batch 26/64 loss: -2.491183280944824
Batch 27/64 loss: -2.763564109802246
Batch 28/64 loss: -2.5168724060058594
Batch 29/64 loss: -2.957796096801758
Batch 30/64 loss: -2.0768117904663086
Batch 31/64 loss: -2.7634458541870117
Batch 32/64 loss: -2.658292770385742
Batch 33/64 loss: -2.7182130813598633
Batch 34/64 loss: -2.7885923385620117
Batch 35/64 loss: -2.8657684326171875
Batch 36/64 loss: -2.808293342590332
Batch 37/64 loss: -2.57936954498291
Batch 38/64 loss: -2.337778091430664
Batch 39/64 loss: -2.428187370300293
Batch 40/64 loss: -2.4703550338745117
Batch 41/64 loss: -2.7727766036987305
Batch 42/64 loss: -2.74649715423584
Batch 43/64 loss: -2.757155418395996
Batch 44/64 loss: -2.72434139251709
Batch 45/64 loss: -2.688755989074707
Batch 46/64 loss: -2.8523387908935547
Batch 47/64 loss: -2.3531484603881836
Batch 48/64 loss: -2.652642250061035
Batch 49/64 loss: -2.67282772064209
Batch 50/64 loss: -2.6525869369506836
Batch 51/64 loss: -2.6056289672851562
Batch 52/64 loss: -2.5928564071655273
Batch 53/64 loss: -2.743037223815918
Batch 54/64 loss: -2.6930885314941406
Batch 55/64 loss: -2.6566286087036133
Batch 56/64 loss: -2.731381416320801
Batch 57/64 loss: -2.5444955825805664
Batch 58/64 loss: -2.250668525695801
Batch 59/64 loss: -2.779059410095215
Batch 60/64 loss: -2.9427356719970703
Batch 61/64 loss: -2.7259511947631836
Batch 62/64 loss: -2.406269073486328
Batch 63/64 loss: -2.719571113586426
Batch 64/64 loss: -7.400145053863525
Epoch 341  Train loss: -2.694635082693661  Val loss: -2.9070410318800675
Epoch 342
-------------------------------
Batch 1/64 loss: -2.1650075912475586
Batch 2/64 loss: -2.588724136352539
Batch 3/64 loss: -2.6908798217773438
Batch 4/64 loss: -2.7034263610839844
Batch 5/64 loss: -2.1746482849121094
Batch 6/64 loss: -2.352476119995117
Batch 7/64 loss: -2.779052734375
Batch 8/64 loss: -2.532602310180664
Batch 9/64 loss: -2.786651611328125
Batch 10/64 loss: -2.6079959869384766
Batch 11/64 loss: -2.5258312225341797
Batch 12/64 loss: -2.5197811126708984
Batch 13/64 loss: -2.8441553115844727
Batch 14/64 loss: -2.7376155853271484
Batch 15/64 loss: -2.2688236236572266
Batch 16/64 loss: -2.337550163269043
Batch 17/64 loss: -2.2422103881835938
Batch 18/64 loss: -2.5580997467041016
Batch 19/64 loss: -2.511977195739746
Batch 20/64 loss: -2.8060083389282227
Batch 21/64 loss: -2.4318485260009766
Batch 22/64 loss: -2.7096128463745117
Batch 23/64 loss: -2.978658676147461
Batch 24/64 loss: -2.5851526260375977
Batch 25/64 loss: -2.6255874633789062
Batch 26/64 loss: -2.707183837890625
Batch 27/64 loss: -2.414271354675293
Batch 28/64 loss: -2.7549304962158203
Batch 29/64 loss: -2.680912971496582
Batch 30/64 loss: -2.755220413208008
Batch 31/64 loss: -2.6601171493530273
Batch 32/64 loss: -2.77382755279541
Batch 33/64 loss: -2.625554084777832
Batch 34/64 loss: -2.469921112060547
Batch 35/64 loss: -2.8258543014526367
Batch 36/64 loss: -2.8507118225097656
Batch 37/64 loss: -2.8005828857421875
Batch 38/64 loss: -2.593438148498535
Batch 39/64 loss: -2.6548919677734375
Batch 40/64 loss: -2.604132652282715
Batch 41/64 loss: -2.6117725372314453
Batch 42/64 loss: -2.6288013458251953
Batch 43/64 loss: -2.4424667358398438
Batch 44/64 loss: -2.644012451171875
Batch 45/64 loss: -2.811903953552246
Batch 46/64 loss: -2.8431568145751953
Batch 47/64 loss: -2.8421735763549805
Batch 48/64 loss: -2.9549598693847656
Batch 49/64 loss: -2.8226747512817383
Batch 50/64 loss: -2.8161563873291016
Batch 51/64 loss: -2.6764965057373047
Batch 52/64 loss: -2.3004446029663086
Batch 53/64 loss: -1.5240068435668945
Batch 54/64 loss: -2.278533935546875
Batch 55/64 loss: -2.76015567779541
Batch 56/64 loss: -2.4885826110839844
Batch 57/64 loss: -2.5053138732910156
Batch 58/64 loss: -2.66318416595459
Batch 59/64 loss: -2.4871950149536133
Batch 60/64 loss: -2.1704206466674805
Batch 61/64 loss: -2.7099761962890625
Batch 62/64 loss: -2.641657829284668
Batch 63/64 loss: -2.5423803329467773
Batch 64/64 loss: -7.010948181152344
Epoch 342  Train loss: -2.6456559424306834  Val loss: -2.930211044259088
Epoch 343
-------------------------------
Batch 1/64 loss: -2.59451961517334
Batch 2/64 loss: -2.5421791076660156
Batch 3/64 loss: -2.7196054458618164
Batch 4/64 loss: -2.7347097396850586
Batch 5/64 loss: -2.6962995529174805
Batch 6/64 loss: -1.495758056640625
Batch 7/64 loss: -2.255099296569824
Batch 8/64 loss: -2.7102184295654297
Batch 9/64 loss: -2.6722803115844727
Batch 10/64 loss: -2.396803855895996
Batch 11/64 loss: -2.668889045715332
Batch 12/64 loss: -2.4807310104370117
Batch 13/64 loss: -2.5784311294555664
Batch 14/64 loss: -2.757786750793457
Batch 15/64 loss: -2.7918691635131836
Batch 16/64 loss: -2.801950454711914
Batch 17/64 loss: -2.728239059448242
Batch 18/64 loss: -2.672300338745117
Batch 19/64 loss: -2.647258758544922
Batch 20/64 loss: -2.515902519226074
Batch 21/64 loss: -1.999532699584961
Batch 22/64 loss: -2.2371721267700195
Batch 23/64 loss: -2.593168258666992
Batch 24/64 loss: -2.0065908432006836
Batch 25/64 loss: -2.7622547149658203
Batch 26/64 loss: -2.6291656494140625
Batch 27/64 loss: -2.7479724884033203
Batch 28/64 loss: -2.269102096557617
Batch 29/64 loss: -2.7632923126220703
Batch 30/64 loss: -2.6771888732910156
Batch 31/64 loss: -2.000181198120117
Batch 32/64 loss: -2.6091489791870117
Batch 33/64 loss: -2.176755905151367
Batch 34/64 loss: -2.006561279296875
Batch 35/64 loss: -2.7655649185180664
Batch 36/64 loss: -2.5911645889282227
Batch 37/64 loss: -2.7232666015625
Batch 38/64 loss: -2.5939083099365234
Batch 39/64 loss: -2.510395050048828
Batch 40/64 loss: -2.7049951553344727
Batch 41/64 loss: -2.755608558654785
Batch 42/64 loss: -2.751654624938965
Batch 43/64 loss: -2.6451454162597656
Batch 44/64 loss: -2.5671615600585938
Batch 45/64 loss: -2.381122589111328
Batch 46/64 loss: -2.680840492248535
Batch 47/64 loss: -2.6861419677734375
Batch 48/64 loss: -2.441594123840332
Batch 49/64 loss: -2.7883338928222656
Batch 50/64 loss: -2.200201988220215
Batch 51/64 loss: -2.740842819213867
Batch 52/64 loss: -2.554560661315918
Batch 53/64 loss: -2.3894100189208984
Batch 54/64 loss: -2.6126785278320312
Batch 55/64 loss: -2.62740421295166
Batch 56/64 loss: -2.344593048095703
Batch 57/64 loss: -2.5230941772460938
Batch 58/64 loss: -2.698394775390625
Batch 59/64 loss: -2.349811553955078
Batch 60/64 loss: -2.4278135299682617
Batch 61/64 loss: -2.5213623046875
Batch 62/64 loss: -2.7584733963012695
Batch 63/64 loss: -2.714977264404297
Batch 64/64 loss: -6.525758743286133
Epoch 343  Train loss: -2.5864118314256856  Val loss: -2.8134020382596043
Epoch 344
-------------------------------
Batch 1/64 loss: -2.1369447708129883
Batch 2/64 loss: -2.580150604248047
Batch 3/64 loss: -2.1294660568237305
Batch 4/64 loss: -2.6451587677001953
Batch 5/64 loss: -2.687371253967285
Batch 6/64 loss: -2.738348960876465
Batch 7/64 loss: -2.5689573287963867
Batch 8/64 loss: -2.5540285110473633
Batch 9/64 loss: -2.714901924133301
Batch 10/64 loss: -2.7385568618774414
Batch 11/64 loss: -2.7091169357299805
Batch 12/64 loss: -2.7146291732788086
Batch 13/64 loss: -2.0659637451171875
Batch 14/64 loss: -2.4604759216308594
Batch 15/64 loss: -2.211233139038086
Batch 16/64 loss: -2.743917465209961
Batch 17/64 loss: -2.820651054382324
Batch 18/64 loss: -2.766648292541504
Batch 19/64 loss: -2.854708671569824
Batch 20/64 loss: -2.6799116134643555
Batch 21/64 loss: -2.8885669708251953
Batch 22/64 loss: -2.470303535461426
Batch 23/64 loss: -2.4667272567749023
Batch 24/64 loss: -2.720296859741211
Batch 25/64 loss: -2.303889274597168
Batch 26/64 loss: -2.1465091705322266
Batch 27/64 loss: -2.7962331771850586
Batch 28/64 loss: -2.591036796569824
Batch 29/64 loss: -2.867116928100586
Batch 30/64 loss: -2.424557685852051
Batch 31/64 loss: -2.499837875366211
Batch 32/64 loss: -2.7124862670898438
Batch 33/64 loss: -2.5260019302368164
Batch 34/64 loss: -2.726893424987793
Batch 35/64 loss: -2.6125926971435547
Batch 36/64 loss: -2.7493677139282227
Batch 37/64 loss: -2.741154670715332
Batch 38/64 loss: -2.860236167907715
Batch 39/64 loss: -2.6457109451293945
Batch 40/64 loss: -2.4509763717651367
Batch 41/64 loss: -2.6847763061523438
Batch 42/64 loss: -2.187375068664551
Batch 43/64 loss: -2.620711326599121
Batch 44/64 loss: -2.845810890197754
Batch 45/64 loss: -2.654552459716797
Batch 46/64 loss: -2.661648750305176
Batch 47/64 loss: -2.829827308654785
Batch 48/64 loss: -2.689311981201172
Batch 49/64 loss: -2.723285675048828
Batch 50/64 loss: -2.548142433166504
Batch 51/64 loss: -2.83682918548584
Batch 52/64 loss: -2.741514205932617
Batch 53/64 loss: -2.5428857803344727
Batch 54/64 loss: -2.570240020751953
Batch 55/64 loss: -2.566342353820801
Batch 56/64 loss: -2.976790428161621
Batch 57/64 loss: -2.541020393371582
Batch 58/64 loss: -2.7392730712890625
Batch 59/64 loss: -2.741985321044922
Batch 60/64 loss: -2.4893436431884766
Batch 61/64 loss: -2.8758039474487305
Batch 62/64 loss: -2.642817497253418
Batch 63/64 loss: -2.7347660064697266
Batch 64/64 loss: -7.365194320678711
Epoch 344  Train loss: -2.677499397128236  Val loss: -3.08236757258779
Epoch 345
-------------------------------
Batch 1/64 loss: -2.7295961380004883
Batch 2/64 loss: -2.5798139572143555
Batch 3/64 loss: -2.723788261413574
Batch 4/64 loss: -2.2890453338623047
Batch 5/64 loss: -2.8009700775146484
Batch 6/64 loss: -2.68157958984375
Batch 7/64 loss: -2.749403953552246
Batch 8/64 loss: -2.218533515930176
Batch 9/64 loss: -2.5702314376831055
Batch 10/64 loss: -2.7472171783447266
Batch 11/64 loss: -2.0489063262939453
Batch 12/64 loss: -2.5423202514648438
Batch 13/64 loss: -2.7304553985595703
Batch 14/64 loss: -2.676316261291504
Batch 15/64 loss: -2.6631126403808594
Batch 16/64 loss: -2.5232467651367188
Batch 17/64 loss: -2.5582752227783203
Batch 18/64 loss: -2.895718574523926
Batch 19/64 loss: -2.574413299560547
Batch 20/64 loss: -2.699711799621582
Batch 21/64 loss: -2.7722177505493164
Batch 22/64 loss: -1.9084272384643555
Batch 23/64 loss: -2.4753952026367188
Batch 24/64 loss: -2.6521472930908203
Batch 25/64 loss: -2.599515914916992
Batch 26/64 loss: -2.7396421432495117
Batch 27/64 loss: -2.7635650634765625
Batch 28/64 loss: -2.771145820617676
Batch 29/64 loss: -2.812591552734375
Batch 30/64 loss: -2.7470712661743164
Batch 31/64 loss: -2.4413022994995117
Batch 32/64 loss: -2.5168943405151367
Batch 33/64 loss: -2.852992057800293
Batch 34/64 loss: -2.6777162551879883
Batch 35/64 loss: -2.5442895889282227
Batch 36/64 loss: -2.8182592391967773
Batch 37/64 loss: -2.8328657150268555
Batch 38/64 loss: -2.7875452041625977
Batch 39/64 loss: -2.538937568664551
Batch 40/64 loss: -2.84464168548584
Batch 41/64 loss: -2.8800525665283203
Batch 42/64 loss: -2.726332664489746
Batch 43/64 loss: -2.9441404342651367
Batch 44/64 loss: -2.8792810440063477
Batch 45/64 loss: -2.9189252853393555
Batch 46/64 loss: -2.759200096130371
Batch 47/64 loss: -2.7268476486206055
Batch 48/64 loss: -2.4280929565429688
Batch 49/64 loss: -2.722750663757324
Batch 50/64 loss: -2.732998847961426
Batch 51/64 loss: -2.8913068771362305
Batch 52/64 loss: -2.495279312133789
Batch 53/64 loss: -2.8922510147094727
Batch 54/64 loss: -2.6539487838745117
Batch 55/64 loss: -2.825469970703125
Batch 56/64 loss: -2.68709659576416
Batch 57/64 loss: -2.0117483139038086
Batch 58/64 loss: -2.893495559692383
Batch 59/64 loss: -2.7381162643432617
Batch 60/64 loss: -2.681802749633789
Batch 61/64 loss: -2.6379919052124023
Batch 62/64 loss: -2.7551660537719727
Batch 63/64 loss: -2.424772262573242
Batch 64/64 loss: -7.165836811065674
Epoch 345  Train loss: -2.7102943476508647  Val loss: -3.0587134869237946
Epoch 346
-------------------------------
Batch 1/64 loss: -2.35538387298584
Batch 2/64 loss: -2.110358238220215
Batch 3/64 loss: -2.7025327682495117
Batch 4/64 loss: -2.828907012939453
Batch 5/64 loss: -2.7111940383911133
Batch 6/64 loss: -2.6687240600585938
Batch 7/64 loss: -2.8598175048828125
Batch 8/64 loss: -2.449435234069824
Batch 9/64 loss: -2.7462902069091797
Batch 10/64 loss: -2.5219078063964844
Batch 11/64 loss: -2.7483034133911133
Batch 12/64 loss: -2.7032718658447266
Batch 13/64 loss: -2.648604393005371
Batch 14/64 loss: -2.917860984802246
Batch 15/64 loss: -2.515125274658203
Batch 16/64 loss: -2.798619270324707
Batch 17/64 loss: -2.5695009231567383
Batch 18/64 loss: -2.874323844909668
Batch 19/64 loss: -2.6233530044555664
Batch 20/64 loss: -2.73712158203125
Batch 21/64 loss: -2.650278091430664
Batch 22/64 loss: -2.4392709732055664
Batch 23/64 loss: -2.871561050415039
Batch 24/64 loss: -2.4967689514160156
Batch 25/64 loss: -2.4957809448242188
Batch 26/64 loss: -2.612154006958008
Batch 27/64 loss: -2.7894630432128906
Batch 28/64 loss: -2.7325878143310547
Batch 29/64 loss: -2.6638002395629883
Batch 30/64 loss: -2.839395523071289
Batch 31/64 loss: -2.2926111221313477
Batch 32/64 loss: -2.5658388137817383
Batch 33/64 loss: -2.511651039123535
Batch 34/64 loss: -2.739591598510742
Batch 35/64 loss: -2.80789852142334
Batch 36/64 loss: -2.855349540710449
Batch 37/64 loss: -2.8750133514404297
Batch 38/64 loss: -2.4685134887695312
Batch 39/64 loss: -2.6864843368530273
Batch 40/64 loss: -2.5983009338378906
Batch 41/64 loss: -2.811513900756836
Batch 42/64 loss: -2.359736442565918
Batch 43/64 loss: -2.915175437927246
Batch 44/64 loss: -2.6153154373168945
Batch 45/64 loss: -2.218430519104004
Batch 46/64 loss: -2.794661521911621
Batch 47/64 loss: -2.6078529357910156
Batch 48/64 loss: -2.800088882446289
Batch 49/64 loss: -2.8707571029663086
Batch 50/64 loss: -2.7914342880249023
Batch 51/64 loss: -2.347522735595703
Batch 52/64 loss: -2.449615478515625
Batch 53/64 loss: -2.665517807006836
Batch 54/64 loss: -2.6588916778564453
Batch 55/64 loss: -2.786759376525879
Batch 56/64 loss: -2.710254669189453
Batch 57/64 loss: -2.724858283996582
Batch 58/64 loss: -2.872929573059082
Batch 59/64 loss: -1.9706001281738281
Batch 60/64 loss: -2.117201805114746
Batch 61/64 loss: -2.628265380859375
Batch 62/64 loss: -2.671797752380371
Batch 63/64 loss: -2.822824478149414
Batch 64/64 loss: -7.279743194580078
Epoch 346  Train loss: -2.6941923403272443  Val loss: -2.84923452528072
Epoch 347
-------------------------------
Batch 1/64 loss: -2.722661018371582
Batch 2/64 loss: -2.3748083114624023
Batch 3/64 loss: -2.6705312728881836
Batch 4/64 loss: -2.6806564331054688
Batch 5/64 loss: -2.629918098449707
Batch 6/64 loss: -2.436964988708496
Batch 7/64 loss: -1.9976215362548828
Batch 8/64 loss: -2.2068653106689453
Batch 9/64 loss: -2.699779510498047
Batch 10/64 loss: -2.7606678009033203
Batch 11/64 loss: -2.72274112701416
Batch 12/64 loss: -2.8646793365478516
Batch 13/64 loss: -2.6806640625
Batch 14/64 loss: -2.561128616333008
Batch 15/64 loss: -2.969914436340332
Batch 16/64 loss: -2.7191667556762695
Batch 17/64 loss: -2.8145952224731445
Batch 18/64 loss: -2.791677474975586
Batch 19/64 loss: -2.526190757751465
Batch 20/64 loss: -2.5871734619140625
Batch 21/64 loss: -2.5782299041748047
Batch 22/64 loss: -2.5777645111083984
Batch 23/64 loss: -2.765692710876465
Batch 24/64 loss: -2.5489940643310547
Batch 25/64 loss: -2.7536563873291016
Batch 26/64 loss: -2.680105209350586
Batch 27/64 loss: -2.5616226196289062
Batch 28/64 loss: -2.498093605041504
Batch 29/64 loss: -2.8435983657836914
Batch 30/64 loss: -2.603156089782715
Batch 31/64 loss: -2.720479965209961
Batch 32/64 loss: -2.262211799621582
Batch 33/64 loss: -2.659975051879883
Batch 34/64 loss: -2.6133317947387695
Batch 35/64 loss: -2.8442258834838867
Batch 36/64 loss: -2.640501022338867
Batch 37/64 loss: -2.3606319427490234
Batch 38/64 loss: -2.720083236694336
Batch 39/64 loss: -2.872251510620117
Batch 40/64 loss: -2.550119400024414
Batch 41/64 loss: -2.179830551147461
Batch 42/64 loss: -2.569896697998047
Batch 43/64 loss: -2.3712644577026367
Batch 44/64 loss: -2.870107650756836
Batch 45/64 loss: -2.9434738159179688
Batch 46/64 loss: -2.8348684310913086
Batch 47/64 loss: -2.5565929412841797
Batch 48/64 loss: -2.822699546813965
Batch 49/64 loss: -2.277362823486328
Batch 50/64 loss: -2.3495750427246094
Batch 51/64 loss: -2.592803955078125
Batch 52/64 loss: -2.6653480529785156
Batch 53/64 loss: -2.471639633178711
Batch 54/64 loss: -2.617478370666504
Batch 55/64 loss: -2.5493717193603516
Batch 56/64 loss: -2.4797000885009766
Batch 57/64 loss: -2.6778316497802734
Batch 58/64 loss: -2.118382453918457
Batch 59/64 loss: -2.2893991470336914
Batch 60/64 loss: -2.4604415893554688
Batch 61/64 loss: -2.534198760986328
Batch 62/64 loss: -2.2980709075927734
Batch 63/64 loss: -2.6444168090820312
Batch 64/64 loss: -7.22905969619751
Epoch 347  Train loss: -2.64579890943041  Val loss: -2.9660403064845764
Epoch 348
-------------------------------
Batch 1/64 loss: -2.4506587982177734
Batch 2/64 loss: -2.6647071838378906
Batch 3/64 loss: -2.6310930252075195
Batch 4/64 loss: -2.737771987915039
Batch 5/64 loss: -2.484583854675293
Batch 6/64 loss: -2.464742660522461
Batch 7/64 loss: -2.81459903717041
Batch 8/64 loss: -2.734574317932129
Batch 9/64 loss: -2.677640914916992
Batch 10/64 loss: -2.8238420486450195
Batch 11/64 loss: -2.8926429748535156
Batch 12/64 loss: -2.4722909927368164
Batch 13/64 loss: -2.094069480895996
Batch 14/64 loss: -2.6281213760375977
Batch 15/64 loss: -2.686983108520508
Batch 16/64 loss: -2.359659194946289
Batch 17/64 loss: -2.7843399047851562
Batch 18/64 loss: -2.8990068435668945
Batch 19/64 loss: -2.50753116607666
Batch 20/64 loss: -2.5466184616088867
Batch 21/64 loss: -2.6426467895507812
Batch 22/64 loss: -2.7524890899658203
Batch 23/64 loss: -2.742377281188965
Batch 24/64 loss: -2.4668712615966797
Batch 25/64 loss: -2.630268096923828
Batch 26/64 loss: -2.742391586303711
Batch 27/64 loss: -2.7410526275634766
Batch 28/64 loss: -2.8489255905151367
Batch 29/64 loss: -2.634521484375
Batch 30/64 loss: -2.962174415588379
Batch 31/64 loss: -2.8854150772094727
Batch 32/64 loss: -2.363780975341797
Batch 33/64 loss: -2.3940114974975586
Batch 34/64 loss: -2.3542137145996094
Batch 35/64 loss: -2.6712589263916016
Batch 36/64 loss: -2.7889060974121094
Batch 37/64 loss: -2.5309667587280273
Batch 38/64 loss: -2.66079044342041
Batch 39/64 loss: -2.610896110534668
Batch 40/64 loss: -2.6818809509277344
Batch 41/64 loss: -2.617154121398926
Batch 42/64 loss: -2.6474485397338867
Batch 43/64 loss: -2.616307258605957
Batch 44/64 loss: -2.6278886795043945
Batch 45/64 loss: -2.760496139526367
Batch 46/64 loss: -2.5392627716064453
Batch 47/64 loss: -2.4545955657958984
Batch 48/64 loss: -2.654033660888672
Batch 49/64 loss: -2.5999011993408203
Batch 50/64 loss: -2.5121822357177734
Batch 51/64 loss: -2.496257781982422
Batch 52/64 loss: -2.6833934783935547
Batch 53/64 loss: -2.606368064880371
Batch 54/64 loss: -2.6689443588256836
Batch 55/64 loss: -2.702359199523926
Batch 56/64 loss: -2.506338119506836
Batch 57/64 loss: -2.225348472595215
Batch 58/64 loss: -2.5110273361206055
Batch 59/64 loss: -2.3770456314086914
Batch 60/64 loss: -1.7802839279174805
Batch 61/64 loss: -2.8935651779174805
Batch 62/64 loss: -2.7006635665893555
Batch 63/64 loss: -2.6831750869750977
Batch 64/64 loss: -7.32234525680542
Epoch 348  Train loss: -2.663797889036291  Val loss: -2.647124995071044
Epoch 349
-------------------------------
Batch 1/64 loss: -2.6518125534057617
Batch 2/64 loss: -2.801363945007324
Batch 3/64 loss: -2.669637680053711
Batch 4/64 loss: -2.5669097900390625
Batch 5/64 loss: -2.8333730697631836
Batch 6/64 loss: -2.608358383178711
Batch 7/64 loss: -2.5555925369262695
Batch 8/64 loss: -2.7436084747314453
Batch 9/64 loss: -2.771042823791504
Batch 10/64 loss: -2.7294750213623047
Batch 11/64 loss: -2.8270559310913086
Batch 12/64 loss: -2.6910152435302734
Batch 13/64 loss: -2.779054641723633
Batch 14/64 loss: -2.7588510513305664
Batch 15/64 loss: -2.831186294555664
Batch 16/64 loss: -2.7773666381835938
Batch 17/64 loss: -2.7180862426757812
Batch 18/64 loss: -2.8004255294799805
Batch 19/64 loss: -2.5406484603881836
Batch 20/64 loss: -2.567911148071289
Batch 21/64 loss: -2.535745620727539
Batch 22/64 loss: -2.7358837127685547
Batch 23/64 loss: -2.710911750793457
Batch 24/64 loss: -3.084773063659668
Batch 25/64 loss: -2.765082359313965
Batch 26/64 loss: -2.7099924087524414
Batch 27/64 loss: -2.619159698486328
Batch 28/64 loss: -2.779566764831543
Batch 29/64 loss: -2.7074832916259766
Batch 30/64 loss: -2.8836421966552734
Batch 31/64 loss: -2.4355010986328125
Batch 32/64 loss: -2.72664737701416
Batch 33/64 loss: -2.443709373474121
Batch 34/64 loss: -2.6764144897460938
Batch 35/64 loss: -2.9356632232666016
Batch 36/64 loss: -2.3289880752563477
Batch 37/64 loss: -2.547011375427246
Batch 38/64 loss: -2.816107749938965
Batch 39/64 loss: -2.7684240341186523
Batch 40/64 loss: -2.734225273132324
Batch 41/64 loss: -2.751694679260254
Batch 42/64 loss: -2.578476905822754
Batch 43/64 loss: -2.1534271240234375
Batch 44/64 loss: -2.667909622192383
Batch 45/64 loss: -2.681952476501465
Batch 46/64 loss: -2.8222646713256836
Batch 47/64 loss: -2.642528533935547
Batch 48/64 loss: -1.8994712829589844
Batch 49/64 loss: -2.7352046966552734
Batch 50/64 loss: -2.6848888397216797
Batch 51/64 loss: -2.598939895629883
Batch 52/64 loss: -2.557297706604004
Batch 53/64 loss: -2.79498291015625
Batch 54/64 loss: -2.651108741760254
Batch 55/64 loss: -2.109689712524414
Batch 56/64 loss: -2.659165382385254
Batch 57/64 loss: -2.6005477905273438
Batch 58/64 loss: -2.677297592163086
Batch 59/64 loss: -2.8978395462036133
Batch 60/64 loss: -2.8842906951904297
Batch 61/64 loss: -2.7320051193237305
Batch 62/64 loss: -2.810405731201172
Batch 63/64 loss: -2.561001777648926
Batch 64/64 loss: -6.829301357269287
Epoch 349  Train loss: -2.7206600133110497  Val loss: -2.9655865934706225
Epoch 350
-------------------------------
Batch 1/64 loss: -2.5886430740356445
Batch 2/64 loss: -2.7911577224731445
Batch 3/64 loss: -2.595627784729004
Batch 4/64 loss: -2.700113296508789
Batch 5/64 loss: -2.7810068130493164
Batch 6/64 loss: -2.7422361373901367
Batch 7/64 loss: -1.7046575546264648
Batch 8/64 loss: -2.660083770751953
Batch 9/64 loss: -2.2934064865112305
Batch 10/64 loss: -2.608811378479004
Batch 11/64 loss: -2.6201467514038086
Batch 12/64 loss: -2.802305221557617
Batch 13/64 loss: -2.6349239349365234
Batch 14/64 loss: -2.5384092330932617
Batch 15/64 loss: -2.8308725357055664
Batch 16/64 loss: -2.3663806915283203
Batch 17/64 loss: -2.59854793548584
Batch 18/64 loss: -2.7280454635620117
Batch 19/64 loss: -2.601597785949707
Batch 20/64 loss: -2.767782211303711
Batch 21/64 loss: -2.34171199798584
Batch 22/64 loss: -2.828704833984375
Batch 23/64 loss: -2.5378541946411133
Batch 24/64 loss: -2.610095977783203
Batch 25/64 loss: -2.520207405090332
Batch 26/64 loss: -2.430363655090332
Batch 27/64 loss: -2.3838939666748047
Batch 28/64 loss: -2.6726818084716797
Batch 29/64 loss: -2.2809362411499023
Batch 30/64 loss: -2.358853340148926
Batch 31/64 loss: -2.8852968215942383
Batch 32/64 loss: -2.200031280517578
Batch 33/64 loss: -2.7238035202026367
Batch 34/64 loss: -2.486517906188965
Batch 35/64 loss: -2.697768211364746
Batch 36/64 loss: -2.6958627700805664
Batch 37/64 loss: -2.5723514556884766
Batch 38/64 loss: -2.7615652084350586
Batch 39/64 loss: -2.586946487426758
Batch 40/64 loss: -2.7450218200683594
Batch 41/64 loss: -2.6108150482177734
Batch 42/64 loss: -2.720060348510742
Batch 43/64 loss: -2.5794897079467773
Batch 44/64 loss: -2.263843536376953
Batch 45/64 loss: -2.646038055419922
Batch 46/64 loss: -2.678285598754883
Batch 47/64 loss: -2.720449447631836
Batch 48/64 loss: -2.631683349609375
Batch 49/64 loss: -2.338913917541504
Batch 50/64 loss: -2.552766799926758
Batch 51/64 loss: -2.425572395324707
Batch 52/64 loss: -2.531702995300293
Batch 53/64 loss: -2.642274856567383
Batch 54/64 loss: -1.7086372375488281
Batch 55/64 loss: -2.5800094604492188
Batch 56/64 loss: -2.6509323120117188
Batch 57/64 loss: -2.460677146911621
Batch 58/64 loss: -2.8785781860351562
Batch 59/64 loss: -2.631999969482422
Batch 60/64 loss: -2.607715606689453
Batch 61/64 loss: -2.2769927978515625
Batch 62/64 loss: -2.805117607116699
Batch 63/64 loss: -2.492365837097168
Batch 64/64 loss: -7.063950538635254
Epoch 350  Train loss: -2.619735055811265  Val loss: -2.831789088822722
Epoch 351
-------------------------------
Batch 1/64 loss: -2.0923357009887695
Batch 2/64 loss: -2.3447399139404297
Batch 3/64 loss: -2.3793954849243164
Batch 4/64 loss: -2.591876983642578
Batch 5/64 loss: -2.7850046157836914
Batch 6/64 loss: -2.0814428329467773
Batch 7/64 loss: -2.4077301025390625
Batch 8/64 loss: -2.4703903198242188
Batch 9/64 loss: -2.5393247604370117
Batch 10/64 loss: -2.554202079772949
Batch 11/64 loss: -2.0580806732177734
Batch 12/64 loss: -2.5700416564941406
Batch 13/64 loss: -2.691438674926758
Batch 14/64 loss: -2.1411972045898438
Batch 15/64 loss: -2.3398170471191406
Batch 16/64 loss: -2.56597900390625
Batch 17/64 loss: -2.497488021850586
Batch 18/64 loss: -2.696974754333496
Batch 19/64 loss: -2.8048601150512695
Batch 20/64 loss: -2.540292739868164
Batch 21/64 loss: -2.630385398864746
Batch 22/64 loss: -2.568526268005371
Batch 23/64 loss: -2.714590072631836
Batch 24/64 loss: -2.513199806213379
Batch 25/64 loss: -2.6028947830200195
Batch 26/64 loss: -2.66098690032959
Batch 27/64 loss: -2.6224937438964844
Batch 28/64 loss: -2.5757808685302734
Batch 29/64 loss: -2.523373603820801
Batch 30/64 loss: -2.603759765625
Batch 31/64 loss: -2.495356559753418
Batch 32/64 loss: -2.5264205932617188
Batch 33/64 loss: -2.567734718322754
Batch 34/64 loss: -2.5603818893432617
Batch 35/64 loss: -2.648101806640625
Batch 36/64 loss: -2.4573841094970703
Batch 37/64 loss: -2.3130998611450195
Batch 38/64 loss: -2.441655158996582
Batch 39/64 loss: -2.322434425354004
Batch 40/64 loss: -2.5494537353515625
Batch 41/64 loss: -2.4813661575317383
Batch 42/64 loss: -2.547140121459961
Batch 43/64 loss: -2.575873374938965
Batch 44/64 loss: -2.33884334564209
Batch 45/64 loss: -2.8736371994018555
Batch 46/64 loss: -2.5332794189453125
Batch 47/64 loss: -2.3283071517944336
Batch 48/64 loss: -2.42842960357666
Batch 49/64 loss: -2.553591728210449
Batch 50/64 loss: -2.70383358001709
Batch 51/64 loss: -2.604501724243164
Batch 52/64 loss: -2.5545654296875
Batch 53/64 loss: -1.551584243774414
Batch 54/64 loss: -2.792417526245117
Batch 55/64 loss: -2.083833694458008
Batch 56/64 loss: -2.762636184692383
Batch 57/64 loss: -2.5543994903564453
Batch 58/64 loss: -2.472370147705078
Batch 59/64 loss: -2.5340728759765625
Batch 60/64 loss: -2.6542558670043945
Batch 61/64 loss: -2.50685977935791
Batch 62/64 loss: -2.3676939010620117
Batch 63/64 loss: -2.8070106506347656
Batch 64/64 loss: -6.989161491394043
Epoch 351  Train loss: -2.555341193255256  Val loss: -2.714291588956957
Epoch 352
-------------------------------
Batch 1/64 loss: -2.715540885925293
Batch 2/64 loss: -2.4088821411132812
Batch 3/64 loss: -2.5009279251098633
Batch 4/64 loss: -2.008599281311035
Batch 5/64 loss: -2.710343360900879
Batch 6/64 loss: -2.5546703338623047
Batch 7/64 loss: -2.7014522552490234
Batch 8/64 loss: -2.4001598358154297
Batch 9/64 loss: -2.5758161544799805
Batch 10/64 loss: -2.4725265502929688
Batch 11/64 loss: -2.6538467407226562
Batch 12/64 loss: -1.8687124252319336
Batch 13/64 loss: -2.680421829223633
Batch 14/64 loss: -2.4335899353027344
Batch 15/64 loss: -2.905069351196289
Batch 16/64 loss: -2.1588497161865234
Batch 17/64 loss: -2.569350242614746
Batch 18/64 loss: -2.5507383346557617
Batch 19/64 loss: -2.691615104675293
Batch 20/64 loss: -2.715579032897949
Batch 21/64 loss: -2.490727424621582
Batch 22/64 loss: -2.705836296081543
Batch 23/64 loss: -2.642301559448242
Batch 24/64 loss: -2.806123733520508
Batch 25/64 loss: -2.6809825897216797
Batch 26/64 loss: -2.704570770263672
Batch 27/64 loss: -2.6638660430908203
Batch 28/64 loss: -2.525162696838379
Batch 29/64 loss: -2.7167348861694336
Batch 30/64 loss: -2.821378707885742
Batch 31/64 loss: -2.62802791595459
Batch 32/64 loss: -2.758554458618164
Batch 33/64 loss: -2.670060157775879
Batch 34/64 loss: -2.6344690322875977
Batch 35/64 loss: -2.080453872680664
Batch 36/64 loss: -2.455254554748535
Batch 37/64 loss: -2.7603282928466797
Batch 38/64 loss: -2.68831729888916
Batch 39/64 loss: -2.5077390670776367
Batch 40/64 loss: -2.5892257690429688
Batch 41/64 loss: -2.5056285858154297
Batch 42/64 loss: -2.438298225402832
Batch 43/64 loss: -2.773167610168457
Batch 44/64 loss: -2.6971960067749023
Batch 45/64 loss: -2.5218849182128906
Batch 46/64 loss: -2.5754566192626953
Batch 47/64 loss: -2.7619094848632812
Batch 48/64 loss: -2.45607852935791
Batch 49/64 loss: -2.6216983795166016
Batch 50/64 loss: -2.872783660888672
Batch 51/64 loss: -2.618393898010254
Batch 52/64 loss: -2.655087471008301
Batch 53/64 loss: -2.5729780197143555
Batch 54/64 loss: -2.754892349243164
Batch 55/64 loss: -1.9228849411010742
Batch 56/64 loss: -2.6841907501220703
Batch 57/64 loss: -2.589043617248535
Batch 58/64 loss: -2.8119983673095703
Batch 59/64 loss: -2.313544273376465
Batch 60/64 loss: -2.937436103820801
Batch 61/64 loss: -2.840524673461914
Batch 62/64 loss: -2.713974952697754
Batch 63/64 loss: -2.6363525390625
Batch 64/64 loss: -7.163991451263428
Epoch 352  Train loss: -2.642434574575985  Val loss: -2.980129818736073
Epoch 353
-------------------------------
Batch 1/64 loss: -2.7869930267333984
Batch 2/64 loss: -2.627009391784668
Batch 3/64 loss: -2.658426284790039
Batch 4/64 loss: -2.83461856842041
Batch 5/64 loss: -2.8187150955200195
Batch 6/64 loss: -2.819957733154297
Batch 7/64 loss: -2.7461605072021484
Batch 8/64 loss: -2.670042037963867
Batch 9/64 loss: -2.3721094131469727
Batch 10/64 loss: -2.6017704010009766
Batch 11/64 loss: -2.7926597595214844
Batch 12/64 loss: -2.805689811706543
Batch 13/64 loss: -2.8293142318725586
Batch 14/64 loss: -2.5940847396850586
Batch 15/64 loss: -2.7954835891723633
Batch 16/64 loss: -2.723814010620117
Batch 17/64 loss: -2.292339324951172
Batch 18/64 loss: -2.9074325561523438
Batch 19/64 loss: -2.1284875869750977
Batch 20/64 loss: -2.6694488525390625
Batch 21/64 loss: -2.822922706604004
Batch 22/64 loss: -2.710698127746582
Batch 23/64 loss: -2.8747663497924805
Batch 24/64 loss: -2.634251594543457
Batch 25/64 loss: -2.741607666015625
Batch 26/64 loss: -2.535186767578125
Batch 27/64 loss: -2.6530895233154297
Batch 28/64 loss: -2.400115966796875
Batch 29/64 loss: -2.7162914276123047
Batch 30/64 loss: -2.767141342163086
Batch 31/64 loss: -2.81787109375
Batch 32/64 loss: -2.603647232055664
Batch 33/64 loss: -2.4252395629882812
Batch 34/64 loss: -2.45821475982666
Batch 35/64 loss: -1.8770742416381836
Batch 36/64 loss: -2.6432151794433594
Batch 37/64 loss: -2.779902458190918
Batch 38/64 loss: -2.863466262817383
Batch 39/64 loss: -2.8662776947021484
Batch 40/64 loss: -2.693099021911621
Batch 41/64 loss: -2.7994909286499023
Batch 42/64 loss: -2.665003776550293
Batch 43/64 loss: -2.53969669342041
Batch 44/64 loss: -2.510624885559082
Batch 45/64 loss: -2.8241891860961914
Batch 46/64 loss: -2.7791290283203125
Batch 47/64 loss: -2.6871795654296875
Batch 48/64 loss: -2.61599063873291
Batch 49/64 loss: -2.807003974914551
Batch 50/64 loss: -2.380812644958496
Batch 51/64 loss: -2.719292640686035
Batch 52/64 loss: -2.5200109481811523
Batch 53/64 loss: -2.5860462188720703
Batch 54/64 loss: -2.6567020416259766
Batch 55/64 loss: -2.6297531127929688
Batch 56/64 loss: -2.7820520401000977
Batch 57/64 loss: -2.8758058547973633
Batch 58/64 loss: -3.016180992126465
Batch 59/64 loss: -2.8469648361206055
Batch 60/64 loss: -2.8425283432006836
Batch 61/64 loss: -2.7754030227661133
Batch 62/64 loss: -2.478046417236328
Batch 63/64 loss: -2.9742355346679688
Batch 64/64 loss: -7.092582702636719
Epoch 353  Train loss: -2.729258294199027  Val loss: -3.029208481516625
Epoch 354
-------------------------------
Batch 1/64 loss: -2.5710744857788086
Batch 2/64 loss: -2.469082832336426
Batch 3/64 loss: -2.6438980102539062
Batch 4/64 loss: -2.7873334884643555
Batch 5/64 loss: -2.7101192474365234
Batch 6/64 loss: -2.808810234069824
Batch 7/64 loss: -2.454298973083496
Batch 8/64 loss: -2.405327796936035
Batch 9/64 loss: -2.7626914978027344
Batch 10/64 loss: -2.527730941772461
Batch 11/64 loss: -2.7729454040527344
Batch 12/64 loss: -2.2972984313964844
Batch 13/64 loss: -2.909330368041992
Batch 14/64 loss: -2.7666616439819336
Batch 15/64 loss: -2.686502456665039
Batch 16/64 loss: -2.857182502746582
Batch 17/64 loss: -2.8336400985717773
Batch 18/64 loss: -2.5976438522338867
Batch 19/64 loss: -2.9264965057373047
Batch 20/64 loss: -2.5383806228637695
Batch 21/64 loss: -2.652742385864258
Batch 22/64 loss: -2.503451347351074
Batch 23/64 loss: -2.7109756469726562
Batch 24/64 loss: -2.649235725402832
Batch 25/64 loss: -2.9527664184570312
Batch 26/64 loss: -2.335881233215332
Batch 27/64 loss: -2.4769325256347656
Batch 28/64 loss: -2.7546348571777344
Batch 29/64 loss: -2.858684539794922
Batch 30/64 loss: -2.826923370361328
Batch 31/64 loss: -3.0371055603027344
Batch 32/64 loss: -2.312802314758301
Batch 33/64 loss: -2.6448402404785156
Batch 34/64 loss: -2.907792091369629
Batch 35/64 loss: -2.9935617446899414
Batch 36/64 loss: -2.7713470458984375
Batch 37/64 loss: -2.6115970611572266
Batch 38/64 loss: -2.613804817199707
Batch 39/64 loss: -2.614889144897461
Batch 40/64 loss: -2.891996383666992
Batch 41/64 loss: -2.8423023223876953
Batch 42/64 loss: -2.7920713424682617
Batch 43/64 loss: -2.7817630767822266
Batch 44/64 loss: -2.933041572570801
Batch 45/64 loss: -2.809844970703125
Batch 46/64 loss: -2.7862043380737305
Batch 47/64 loss: -2.691390037536621
Batch 48/64 loss: -2.884775161743164
Batch 49/64 loss: -2.58286190032959
Batch 50/64 loss: -2.5345325469970703
Batch 51/64 loss: -2.498678207397461
Batch 52/64 loss: -2.8173789978027344
Batch 53/64 loss: -2.5625648498535156
Batch 54/64 loss: -2.780162811279297
Batch 55/64 loss: -2.2110424041748047
Batch 56/64 loss: -2.914912223815918
Batch 57/64 loss: -2.702350616455078
Batch 58/64 loss: -2.822864532470703
Batch 59/64 loss: -2.6888694763183594
Batch 60/64 loss: -2.8124465942382812
Batch 61/64 loss: -2.807352066040039
Batch 62/64 loss: -2.9934072494506836
Batch 63/64 loss: -2.8185157775878906
Batch 64/64 loss: -7.101955413818359
Epoch 354  Train loss: -2.7583406036975338  Val loss: -3.0608849541837815
Epoch 355
-------------------------------
Batch 1/64 loss: -2.6389150619506836
Batch 2/64 loss: -2.609745979309082
Batch 3/64 loss: -2.6613121032714844
Batch 4/64 loss: -2.7904129028320312
Batch 5/64 loss: -2.049160957336426
Batch 6/64 loss: -2.851785659790039
Batch 7/64 loss: -2.7344589233398438
Batch 8/64 loss: -2.7775449752807617
Batch 9/64 loss: -2.8032922744750977
Batch 10/64 loss: -2.532571792602539
Batch 11/64 loss: -2.674046516418457
Batch 12/64 loss: -2.874089241027832
Batch 13/64 loss: -2.864368438720703
Batch 14/64 loss: -2.670745849609375
Batch 15/64 loss: -2.737799644470215
Batch 16/64 loss: -2.931399345397949
Batch 17/64 loss: -2.875814437866211
Batch 18/64 loss: -2.4717159271240234
Batch 19/64 loss: -2.923900604248047
Batch 20/64 loss: -2.7851686477661133
Batch 21/64 loss: -2.6935653686523438
Batch 22/64 loss: -2.50881290435791
Batch 23/64 loss: -2.650575637817383
Batch 24/64 loss: -2.809685707092285
Batch 25/64 loss: -2.6682748794555664
Batch 26/64 loss: -2.888453483581543
Batch 27/64 loss: -2.934645652770996
Batch 28/64 loss: -2.9059505462646484
Batch 29/64 loss: -2.924776077270508
Batch 30/64 loss: -2.934432029724121
Batch 31/64 loss: -2.559720993041992
Batch 32/64 loss: -2.575751304626465
Batch 33/64 loss: -2.7316083908081055
Batch 34/64 loss: -2.8182249069213867
Batch 35/64 loss: -2.6461496353149414
Batch 36/64 loss: -2.8241891860961914
Batch 37/64 loss: -2.9602317810058594
Batch 38/64 loss: -2.6765880584716797
Batch 39/64 loss: -2.578803062438965
Batch 40/64 loss: -2.345425605773926
Batch 41/64 loss: -2.37502384185791
Batch 42/64 loss: -2.7361249923706055
Batch 43/64 loss: -2.8901071548461914
Batch 44/64 loss: -2.7513294219970703
Batch 45/64 loss: -2.885894775390625
Batch 46/64 loss: -2.46065616607666
Batch 47/64 loss: -2.5244016647338867
Batch 48/64 loss: -2.5039892196655273
Batch 49/64 loss: -2.4511146545410156
Batch 50/64 loss: -2.782534599304199
Batch 51/64 loss: -2.741580009460449
Batch 52/64 loss: -2.8097143173217773
Batch 53/64 loss: -2.8292646408081055
Batch 54/64 loss: -2.7823963165283203
Batch 55/64 loss: -2.620009422302246
Batch 56/64 loss: -2.6866044998168945
Batch 57/64 loss: -2.3423891067504883
Batch 58/64 loss: -2.7732200622558594
Batch 59/64 loss: -2.451343536376953
Batch 60/64 loss: -2.55423641204834
Batch 61/64 loss: -2.887868881225586
Batch 62/64 loss: -2.5228490829467773
Batch 63/64 loss: -2.588141441345215
Batch 64/64 loss: -7.168951034545898
Epoch 355  Train loss: -2.7485744625914332  Val loss: -2.9864318952527653
Epoch 356
-------------------------------
Batch 1/64 loss: -2.523470878601074
Batch 2/64 loss: -2.8070316314697266
Batch 3/64 loss: -2.7965545654296875
Batch 4/64 loss: -2.6065359115600586
Batch 5/64 loss: -2.8873109817504883
Batch 6/64 loss: -2.7053327560424805
Batch 7/64 loss: -2.3301925659179688
Batch 8/64 loss: -2.458253860473633
Batch 9/64 loss: -2.2129087448120117
Batch 10/64 loss: -2.686391830444336
Batch 11/64 loss: -2.825502395629883
Batch 12/64 loss: -2.759638786315918
Batch 13/64 loss: -2.8929004669189453
Batch 14/64 loss: -2.2683591842651367
Batch 15/64 loss: -2.739482879638672
Batch 16/64 loss: -2.429250717163086
Batch 17/64 loss: -2.7121810913085938
Batch 18/64 loss: -2.6479320526123047
Batch 19/64 loss: -2.4951066970825195
Batch 20/64 loss: -2.7914533615112305
Batch 21/64 loss: -2.833038330078125
Batch 22/64 loss: -2.222914695739746
Batch 23/64 loss: -2.461972236633301
Batch 24/64 loss: -2.538454055786133
Batch 25/64 loss: -2.7520675659179688
Batch 26/64 loss: -2.5637102127075195
Batch 27/64 loss: -2.7834978103637695
Batch 28/64 loss: -2.7645740509033203
Batch 29/64 loss: -2.5543642044067383
Batch 30/64 loss: -2.8324575424194336
Batch 31/64 loss: -2.6280927658081055
Batch 32/64 loss: -2.7626590728759766
Batch 33/64 loss: -2.733011245727539
Batch 34/64 loss: -2.784958839416504
Batch 35/64 loss: -2.7730064392089844
Batch 36/64 loss: -2.7567739486694336
Batch 37/64 loss: -2.369089126586914
Batch 38/64 loss: -2.6485414505004883
Batch 39/64 loss: -2.7906885147094727
Batch 40/64 loss: -2.661365509033203
Batch 41/64 loss: -2.369701385498047
Batch 42/64 loss: -2.7861709594726562
Batch 43/64 loss: -2.753948211669922
Batch 44/64 loss: -2.5983543395996094
Batch 45/64 loss: -2.691194534301758
Batch 46/64 loss: -2.5113000869750977
Batch 47/64 loss: -2.564716339111328
Batch 48/64 loss: -2.7427539825439453
Batch 49/64 loss: -2.7418289184570312
Batch 50/64 loss: -2.6093015670776367
Batch 51/64 loss: -2.889312744140625
Batch 52/64 loss: -2.858952522277832
Batch 53/64 loss: -2.569626808166504
Batch 54/64 loss: -2.561311721801758
Batch 55/64 loss: -2.7988691329956055
Batch 56/64 loss: -2.7074289321899414
Batch 57/64 loss: -2.5866899490356445
Batch 58/64 loss: -2.5633316040039062
Batch 59/64 loss: -1.9885263442993164
Batch 60/64 loss: -2.967228889465332
Batch 61/64 loss: -2.625655174255371
Batch 62/64 loss: -2.934056282043457
Batch 63/64 loss: -2.766526222229004
Batch 64/64 loss: -6.979784965515137
Epoch 356  Train loss: -2.7013749702304017  Val loss: -2.8139855427430667
Epoch 357
-------------------------------
Batch 1/64 loss: -2.502751350402832
Batch 2/64 loss: -2.5886898040771484
Batch 3/64 loss: -2.814558982849121
Batch 4/64 loss: -2.75478458404541
Batch 5/64 loss: -2.9176979064941406
Batch 6/64 loss: -2.61142635345459
Batch 7/64 loss: -2.874140739440918
Batch 8/64 loss: -2.7882308959960938
Batch 9/64 loss: -2.7755727767944336
Batch 10/64 loss: -2.632139205932617
Batch 11/64 loss: -2.7111663818359375
Batch 12/64 loss: -2.9675064086914062
Batch 13/64 loss: -2.1489477157592773
Batch 14/64 loss: -2.0776071548461914
Batch 15/64 loss: -2.001925468444824
Batch 16/64 loss: -2.8259105682373047
Batch 17/64 loss: -2.6103515625
Batch 18/64 loss: -2.341233253479004
Batch 19/64 loss: -2.81191349029541
Batch 20/64 loss: -2.7781801223754883
Batch 21/64 loss: -2.6812973022460938
Batch 22/64 loss: -2.7084312438964844
Batch 23/64 loss: -2.691638946533203
Batch 24/64 loss: -2.6860294342041016
Batch 25/64 loss: -2.8002395629882812
Batch 26/64 loss: -2.749448776245117
Batch 27/64 loss: -2.7290220260620117
Batch 28/64 loss: -2.641458511352539
Batch 29/64 loss: -2.57489013671875
Batch 30/64 loss: -2.6466751098632812
Batch 31/64 loss: -2.635854721069336
Batch 32/64 loss: -2.877804756164551
Batch 33/64 loss: -2.7324419021606445
Batch 34/64 loss: -2.700143814086914
Batch 35/64 loss: -2.2439613342285156
Batch 36/64 loss: -2.723635673522949
Batch 37/64 loss: -2.830838203430176
Batch 38/64 loss: -2.7194910049438477
Batch 39/64 loss: -2.157865524291992
Batch 40/64 loss: -2.7176923751831055
Batch 41/64 loss: -2.732494354248047
Batch 42/64 loss: -2.738274574279785
Batch 43/64 loss: -2.716364860534668
Batch 44/64 loss: -2.600797653198242
Batch 45/64 loss: -2.8298187255859375
Batch 46/64 loss: -2.5091753005981445
Batch 47/64 loss: -2.7245893478393555
Batch 48/64 loss: -2.709702491760254
Batch 49/64 loss: -2.816117286682129
Batch 50/64 loss: -2.5873641967773438
Batch 51/64 loss: -2.8776731491088867
Batch 52/64 loss: -2.5647544860839844
Batch 53/64 loss: -2.76605224609375
Batch 54/64 loss: -2.9793262481689453
Batch 55/64 loss: -2.7098073959350586
Batch 56/64 loss: -2.732809066772461
Batch 57/64 loss: -2.7135181427001953
Batch 58/64 loss: -2.5759944915771484
Batch 59/64 loss: -2.733011245727539
Batch 60/64 loss: -2.773916244506836
Batch 61/64 loss: -2.830629348754883
Batch 62/64 loss: -2.5474472045898438
Batch 63/64 loss: -2.5142621994018555
Batch 64/64 loss: -6.867548942565918
Epoch 357  Train loss: -2.7171475616155885  Val loss: -2.9063111007008766
Epoch 358
-------------------------------
Batch 1/64 loss: -2.9308958053588867
Batch 2/64 loss: -2.874386787414551
Batch 3/64 loss: -2.6943931579589844
Batch 4/64 loss: -2.690664291381836
Batch 5/64 loss: -2.5496225357055664
Batch 6/64 loss: -2.825942039489746
Batch 7/64 loss: -2.451244354248047
Batch 8/64 loss: -2.234349250793457
Batch 9/64 loss: -2.7181320190429688
Batch 10/64 loss: -2.513461112976074
Batch 11/64 loss: -2.5670576095581055
Batch 12/64 loss: -2.650973320007324
Batch 13/64 loss: -2.6759767532348633
Batch 14/64 loss: -2.7137651443481445
Batch 15/64 loss: -2.6014633178710938
Batch 16/64 loss: -2.597874641418457
Batch 17/64 loss: -2.8729944229125977
Batch 18/64 loss: -2.79366397857666
Batch 19/64 loss: -2.68082332611084
Batch 20/64 loss: -2.883424758911133
Batch 21/64 loss: -2.799985885620117
Batch 22/64 loss: -2.240262985229492
Batch 23/64 loss: -2.653963088989258
Batch 24/64 loss: -2.5907182693481445
Batch 25/64 loss: -2.628438949584961
Batch 26/64 loss: -2.857189178466797
Batch 27/64 loss: -2.7002058029174805
Batch 28/64 loss: -2.270406723022461
Batch 29/64 loss: -2.9941301345825195
Batch 30/64 loss: -2.7089948654174805
Batch 31/64 loss: -2.636789321899414
Batch 32/64 loss: -2.710601806640625
Batch 33/64 loss: -2.491591453552246
Batch 34/64 loss: -2.73960018157959
Batch 35/64 loss: -2.944727897644043
Batch 36/64 loss: -2.9653186798095703
Batch 37/64 loss: -2.5897884368896484
Batch 38/64 loss: -2.997983932495117
Batch 39/64 loss: -2.7658023834228516
Batch 40/64 loss: -2.7852048873901367
Batch 41/64 loss: -2.8182716369628906
Batch 42/64 loss: -2.5799331665039062
Batch 43/64 loss: -2.692628860473633
Batch 44/64 loss: -2.687901496887207
Batch 45/64 loss: -2.8113460540771484
Batch 46/64 loss: -2.866208076477051
Batch 47/64 loss: -2.2879133224487305
Batch 48/64 loss: -2.725571632385254
Batch 49/64 loss: -2.476411819458008
Batch 50/64 loss: -2.961618423461914
Batch 51/64 loss: -2.684708595275879
Batch 52/64 loss: -2.4097557067871094
Batch 53/64 loss: -3.009441375732422
Batch 54/64 loss: -2.850417137145996
Batch 55/64 loss: -2.689944267272949
Batch 56/64 loss: -2.1964759826660156
Batch 57/64 loss: -2.7243833541870117
Batch 58/64 loss: -2.7536191940307617
Batch 59/64 loss: -2.4733076095581055
Batch 60/64 loss: -2.6448850631713867
Batch 61/64 loss: -2.6571388244628906
Batch 62/64 loss: -2.763437271118164
Batch 63/64 loss: -2.8964834213256836
Batch 64/64 loss: -7.279271602630615
Epoch 358  Train loss: -2.7406128546770883  Val loss: -2.9590297056637267
Epoch 359
-------------------------------
Batch 1/64 loss: -2.6299400329589844
Batch 2/64 loss: -2.696282386779785
Batch 3/64 loss: -2.737274169921875
Batch 4/64 loss: -2.360030174255371
Batch 5/64 loss: -2.618746757507324
Batch 6/64 loss: -2.5228147506713867
Batch 7/64 loss: -2.7558727264404297
Batch 8/64 loss: -2.4382619857788086
Batch 9/64 loss: -2.3191375732421875
Batch 10/64 loss: -2.8345088958740234
Batch 11/64 loss: -2.2891082763671875
Batch 12/64 loss: -2.1794939041137695
Batch 13/64 loss: -2.714008331298828
Batch 14/64 loss: -2.560519218444824
Batch 15/64 loss: -2.494029998779297
Batch 16/64 loss: -2.659788131713867
Batch 17/64 loss: -2.445537567138672
Batch 18/64 loss: -2.48946475982666
Batch 19/64 loss: -2.6308116912841797
Batch 20/64 loss: -2.8442459106445312
Batch 21/64 loss: -2.5133743286132812
Batch 22/64 loss: -2.9314680099487305
Batch 23/64 loss: -2.1390485763549805
Batch 24/64 loss: -2.5140113830566406
Batch 25/64 loss: -2.8640289306640625
Batch 26/64 loss: -2.707427978515625
Batch 27/64 loss: -2.6174449920654297
Batch 28/64 loss: -2.771261215209961
Batch 29/64 loss: -2.343893051147461
Batch 30/64 loss: -2.7666711807250977
Batch 31/64 loss: -2.6058053970336914
Batch 32/64 loss: -2.201859474182129
Batch 33/64 loss: -2.610189437866211
Batch 34/64 loss: -2.9103946685791016
Batch 35/64 loss: -2.781102180480957
Batch 36/64 loss: -2.7189340591430664
Batch 37/64 loss: -2.54245662689209
Batch 38/64 loss: -2.631453514099121
Batch 39/64 loss: -2.511728286743164
Batch 40/64 loss: -2.3349390029907227
Batch 41/64 loss: -2.6556949615478516
Batch 42/64 loss: -2.7873382568359375
Batch 43/64 loss: -2.6290979385375977
Batch 44/64 loss: -2.5522871017456055
Batch 45/64 loss: -2.4720754623413086
Batch 46/64 loss: -2.6797094345092773
Batch 47/64 loss: -2.7654266357421875
Batch 48/64 loss: -2.616971969604492
Batch 49/64 loss: -2.81203556060791
Batch 50/64 loss: -2.524679183959961
Batch 51/64 loss: -2.6685924530029297
Batch 52/64 loss: -2.654110908508301
Batch 53/64 loss: -2.879148483276367
Batch 54/64 loss: -2.377591133117676
Batch 55/64 loss: -2.4724855422973633
Batch 56/64 loss: -2.6973066329956055
Batch 57/64 loss: -2.636691093444824
Batch 58/64 loss: -2.631381034851074
Batch 59/64 loss: -2.7121973037719727
Batch 60/64 loss: -2.502988815307617
Batch 61/64 loss: -2.715451240539551
Batch 62/64 loss: -2.855013847351074
Batch 63/64 loss: -2.790499687194824
Batch 64/64 loss: -6.412140846252441
Epoch 359  Train loss: -2.6531019584805358  Val loss: -2.8721246883221916
Epoch 360
-------------------------------
Batch 1/64 loss: -2.746156692504883
Batch 2/64 loss: -2.63925838470459
Batch 3/64 loss: -2.560980796813965
Batch 4/64 loss: -2.904229164123535
Batch 5/64 loss: -2.737269401550293
Batch 6/64 loss: -2.705063819885254
Batch 7/64 loss: -2.791409492492676
Batch 8/64 loss: -2.577627182006836
Batch 9/64 loss: -2.832667350769043
Batch 10/64 loss: -2.535919189453125
Batch 11/64 loss: -2.9388370513916016
Batch 12/64 loss: -2.5243101119995117
Batch 13/64 loss: -2.6598596572875977
Batch 14/64 loss: -2.567622184753418
Batch 15/64 loss: -2.7227535247802734
Batch 16/64 loss: -2.5854759216308594
Batch 17/64 loss: -2.650576591491699
Batch 18/64 loss: -2.692439079284668
Batch 19/64 loss: -2.7442712783813477
Batch 20/64 loss: -2.754574775695801
Batch 21/64 loss: -2.4299497604370117
Batch 22/64 loss: -2.58013916015625
Batch 23/64 loss: -2.729458808898926
Batch 24/64 loss: -2.8193016052246094
Batch 25/64 loss: -1.6469354629516602
Batch 26/64 loss: -2.5348730087280273
Batch 27/64 loss: -2.58388614654541
Batch 28/64 loss: -2.4770774841308594
Batch 29/64 loss: -2.6946916580200195
Batch 30/64 loss: -2.61334228515625
Batch 31/64 loss: -2.5142383575439453
Batch 32/64 loss: -2.8194408416748047
Batch 33/64 loss: -2.9460391998291016
Batch 34/64 loss: -2.2735795974731445
Batch 35/64 loss: -2.704456329345703
Batch 36/64 loss: -2.4297895431518555
Batch 37/64 loss: -2.5971431732177734
Batch 38/64 loss: -2.6741104125976562
Batch 39/64 loss: -2.1812314987182617
Batch 40/64 loss: -2.8454666137695312
Batch 41/64 loss: -2.7976245880126953
Batch 42/64 loss: -2.704896926879883
Batch 43/64 loss: -2.688814163208008
Batch 44/64 loss: -2.6892051696777344
Batch 45/64 loss: -2.7646541595458984
Batch 46/64 loss: -2.66237735748291
Batch 47/64 loss: -2.5264711380004883
Batch 48/64 loss: -2.2950687408447266
Batch 49/64 loss: -2.7040090560913086
Batch 50/64 loss: -2.6874332427978516
Batch 51/64 loss: -2.4282026290893555
Batch 52/64 loss: -2.6184263229370117
Batch 53/64 loss: -2.8950281143188477
Batch 54/64 loss: -2.637331962585449
Batch 55/64 loss: -2.565171241760254
Batch 56/64 loss: -2.5297985076904297
Batch 57/64 loss: -2.659369468688965
Batch 58/64 loss: -2.9105701446533203
Batch 59/64 loss: -2.679558753967285
Batch 60/64 loss: -2.069573402404785
Batch 61/64 loss: -2.8206653594970703
Batch 62/64 loss: -2.680905342102051
Batch 63/64 loss: -2.827472686767578
Batch 64/64 loss: -7.227402210235596
Epoch 360  Train loss: -2.6859550232980767  Val loss: -2.9275271622176025
Epoch 361
-------------------------------
Batch 1/64 loss: -2.4714603424072266
Batch 2/64 loss: -2.280032157897949
Batch 3/64 loss: -2.521245002746582
Batch 4/64 loss: -2.605365753173828
Batch 5/64 loss: -2.8287248611450195
Batch 6/64 loss: -2.658148765563965
Batch 7/64 loss: -2.958345413208008
Batch 8/64 loss: -2.721141815185547
Batch 9/64 loss: -2.688408851623535
Batch 10/64 loss: -2.84822940826416
Batch 11/64 loss: -2.6064205169677734
Batch 12/64 loss: -2.6352968215942383
Batch 13/64 loss: -2.4740352630615234
Batch 14/64 loss: -2.5160322189331055
Batch 15/64 loss: -2.6525392532348633
Batch 16/64 loss: -2.9303178787231445
Batch 17/64 loss: -2.612894058227539
Batch 18/64 loss: -2.8603925704956055
Batch 19/64 loss: -2.759406089782715
Batch 20/64 loss: -2.8019943237304688
Batch 21/64 loss: -2.7484188079833984
Batch 22/64 loss: -2.679377555847168
Batch 23/64 loss: -2.977078437805176
Batch 24/64 loss: -2.7225875854492188
Batch 25/64 loss: -2.936345100402832
Batch 26/64 loss: -2.5139732360839844
Batch 27/64 loss: -2.659769058227539
Batch 28/64 loss: -2.47305965423584
Batch 29/64 loss: -2.6629505157470703
Batch 30/64 loss: -2.793745994567871
Batch 31/64 loss: -2.761216163635254
Batch 32/64 loss: -2.864699363708496
Batch 33/64 loss: -2.866863250732422
Batch 34/64 loss: -2.806981086730957
Batch 35/64 loss: -2.816619873046875
Batch 36/64 loss: -2.168259620666504
Batch 37/64 loss: -2.6779937744140625
Batch 38/64 loss: -2.704446792602539
Batch 39/64 loss: -2.8362550735473633
Batch 40/64 loss: -2.5226306915283203
Batch 41/64 loss: -2.7916765213012695
Batch 42/64 loss: -2.891446113586426
Batch 43/64 loss: -2.3857221603393555
Batch 44/64 loss: -2.998396873474121
Batch 45/64 loss: -2.677694320678711
Batch 46/64 loss: -2.84317684173584
Batch 47/64 loss: -2.6851816177368164
Batch 48/64 loss: -2.368718147277832
Batch 49/64 loss: -2.7607994079589844
Batch 50/64 loss: -2.8108386993408203
Batch 51/64 loss: -2.4573278427124023
Batch 52/64 loss: -3.0376758575439453
Batch 53/64 loss: -2.9078054428100586
Batch 54/64 loss: -2.577427864074707
Batch 55/64 loss: -2.8783740997314453
Batch 56/64 loss: -2.7563562393188477
Batch 57/64 loss: -2.674703598022461
Batch 58/64 loss: -2.3990306854248047
Batch 59/64 loss: -2.92221736907959
Batch 60/64 loss: -2.970712661743164
Batch 61/64 loss: -1.7709102630615234
Batch 62/64 loss: -2.7919607162475586
Batch 63/64 loss: -2.4577884674072266
Batch 64/64 loss: -7.121829032897949
Epoch 361  Train loss: -2.7416630053052717  Val loss: -3.0563155891969034
Epoch 362
-------------------------------
Batch 1/64 loss: -2.668429374694824
Batch 2/64 loss: -2.3859119415283203
Batch 3/64 loss: -2.87728214263916
Batch 4/64 loss: -2.646214485168457
Batch 5/64 loss: -2.5432138442993164
Batch 6/64 loss: -2.856940269470215
Batch 7/64 loss: -2.3816003799438477
Batch 8/64 loss: -2.6510820388793945
Batch 9/64 loss: -2.7905988693237305
Batch 10/64 loss: -2.81020450592041
Batch 11/64 loss: -2.871748924255371
Batch 12/64 loss: -2.9371414184570312
Batch 13/64 loss: -2.76461124420166
Batch 14/64 loss: -2.5041322708129883
Batch 15/64 loss: -2.8015289306640625
Batch 16/64 loss: -2.51583194732666
Batch 17/64 loss: -2.616800308227539
Batch 18/64 loss: -2.8132715225219727
Batch 19/64 loss: -2.723658561706543
Batch 20/64 loss: -2.9965505599975586
Batch 21/64 loss: -2.3784046173095703
Batch 22/64 loss: -2.768326759338379
Batch 23/64 loss: -2.5700511932373047
Batch 24/64 loss: -3.001689910888672
Batch 25/64 loss: -2.8562822341918945
Batch 26/64 loss: -2.746760368347168
Batch 27/64 loss: -2.907306671142578
Batch 28/64 loss: -2.88199520111084
Batch 29/64 loss: -2.71486759185791
Batch 30/64 loss: -2.977351188659668
Batch 31/64 loss: -3.0138607025146484
Batch 32/64 loss: -2.89990234375
Batch 33/64 loss: -2.905613899230957
Batch 34/64 loss: -2.828770637512207
Batch 35/64 loss: -2.5813493728637695
Batch 36/64 loss: -2.8704614639282227
Batch 37/64 loss: -2.0857114791870117
Batch 38/64 loss: -2.997243881225586
Batch 39/64 loss: -2.441282272338867
Batch 40/64 loss: -2.873842239379883
Batch 41/64 loss: -2.831024169921875
Batch 42/64 loss: -2.794363021850586
Batch 43/64 loss: -2.985414505004883
Batch 44/64 loss: -2.9078454971313477
Batch 45/64 loss: -2.7170143127441406
Batch 46/64 loss: -2.676036834716797
Batch 47/64 loss: -2.966733932495117
Batch 48/64 loss: -2.8881540298461914
Batch 49/64 loss: -2.9779272079467773
Batch 50/64 loss: -2.699254035949707
Batch 51/64 loss: -2.8396129608154297
Batch 52/64 loss: -2.806581497192383
Batch 53/64 loss: -2.809969902038574
Batch 54/64 loss: -2.9607925415039062
Batch 55/64 loss: -2.1995363235473633
Batch 56/64 loss: -2.6522388458251953
Batch 57/64 loss: -2.7895097732543945
Batch 58/64 loss: -2.4727020263671875
Batch 59/64 loss: -2.0985469818115234
Batch 60/64 loss: -2.1571788787841797
Batch 61/64 loss: -2.6709022521972656
Batch 62/64 loss: -2.662700653076172
Batch 63/64 loss: -2.8861465454101562
Batch 64/64 loss: -7.432692527770996
Epoch 362  Train loss: -2.7840397442088407  Val loss: -3.0757172574702
Epoch 363
-------------------------------
Batch 1/64 loss: -2.6066884994506836
Batch 2/64 loss: -2.6482276916503906
Batch 3/64 loss: -2.9416418075561523
Batch 4/64 loss: -2.684596061706543
Batch 5/64 loss: -3.0430593490600586
Batch 6/64 loss: -2.434027671813965
Batch 7/64 loss: -3.0045166015625
Batch 8/64 loss: -2.97696590423584
Batch 9/64 loss: -2.8587656021118164
Batch 10/64 loss: -2.695553779602051
Batch 11/64 loss: -2.450444221496582
Batch 12/64 loss: -2.7278337478637695
Batch 13/64 loss: -2.814337730407715
Batch 14/64 loss: -2.77500057220459
Batch 15/64 loss: -2.862668037414551
Batch 16/64 loss: -2.7187633514404297
Batch 17/64 loss: -2.8206491470336914
Batch 18/64 loss: -2.69974422454834
Batch 19/64 loss: -2.881192207336426
Batch 20/64 loss: -2.7252683639526367
Batch 21/64 loss: -2.9532012939453125
Batch 22/64 loss: -3.0521602630615234
Batch 23/64 loss: -3.032350540161133
Batch 24/64 loss: -2.5837316513061523
Batch 25/64 loss: -2.569944381713867
Batch 26/64 loss: -2.8255481719970703
Batch 27/64 loss: -2.5758676528930664
Batch 28/64 loss: -2.2354536056518555
Batch 29/64 loss: -2.795381546020508
Batch 30/64 loss: -2.7083091735839844
Batch 31/64 loss: -3.0505428314208984
Batch 32/64 loss: -2.557662010192871
Batch 33/64 loss: -2.310148239135742
Batch 34/64 loss: -2.678133964538574
Batch 35/64 loss: -2.3823795318603516
Batch 36/64 loss: -2.600771903991699
Batch 37/64 loss: -2.6097841262817383
Batch 38/64 loss: -2.6293039321899414
Batch 39/64 loss: -2.7146596908569336
Batch 40/64 loss: -2.202317237854004
Batch 41/64 loss: -2.775846481323242
Batch 42/64 loss: -2.869691848754883
Batch 43/64 loss: -2.529740333557129
Batch 44/64 loss: -2.4854822158813477
Batch 45/64 loss: -2.81038761138916
Batch 46/64 loss: -2.8378543853759766
Batch 47/64 loss: -2.870281219482422
Batch 48/64 loss: -2.8640365600585938
Batch 49/64 loss: -2.706904411315918
Batch 50/64 loss: -2.74847412109375
Batch 51/64 loss: -2.7988548278808594
Batch 52/64 loss: -2.6586618423461914
Batch 53/64 loss: -2.6519203186035156
Batch 54/64 loss: -2.4363279342651367
Batch 55/64 loss: -2.7205495834350586
Batch 56/64 loss: -1.997152328491211
Batch 57/64 loss: -2.839482307434082
Batch 58/64 loss: -2.621140480041504
Batch 59/64 loss: -2.6486501693725586
Batch 60/64 loss: -2.8035593032836914
Batch 61/64 loss: -2.929401397705078
Batch 62/64 loss: -2.6940793991088867
Batch 63/64 loss: -2.6524829864501953
Batch 64/64 loss: -7.451762676239014
Epoch 363  Train loss: -2.7604294963911467  Val loss: -3.0599953431853724
Epoch 364
-------------------------------
Batch 1/64 loss: -2.725858688354492
Batch 2/64 loss: -2.5404653549194336
Batch 3/64 loss: -2.6862478256225586
Batch 4/64 loss: -2.9451723098754883
Batch 5/64 loss: -2.6555986404418945
Batch 6/64 loss: -2.7081756591796875
Batch 7/64 loss: -2.792978286743164
Batch 8/64 loss: -2.087100028991699
Batch 9/64 loss: -2.6870975494384766
Batch 10/64 loss: -2.6208267211914062
Batch 11/64 loss: -2.766021728515625
Batch 12/64 loss: -2.7612552642822266
Batch 13/64 loss: -2.678262710571289
Batch 14/64 loss: -2.6028804779052734
Batch 15/64 loss: -2.807432174682617
Batch 16/64 loss: -1.8294658660888672
Batch 17/64 loss: -2.8334999084472656
Batch 18/64 loss: -2.625631332397461
Batch 19/64 loss: -2.5966148376464844
Batch 20/64 loss: -2.574978828430176
Batch 21/64 loss: -2.6873998641967773
Batch 22/64 loss: -2.7723731994628906
Batch 23/64 loss: -2.62192440032959
Batch 24/64 loss: -2.7358922958374023
Batch 25/64 loss: -2.6105871200561523
Batch 26/64 loss: -2.8112077713012695
Batch 27/64 loss: -2.668764114379883
Batch 28/64 loss: -2.637394905090332
Batch 29/64 loss: -2.9591150283813477
Batch 30/64 loss: -2.7844886779785156
Batch 31/64 loss: -2.4797372817993164
Batch 32/64 loss: -2.61379337310791
Batch 33/64 loss: -2.836050033569336
Batch 34/64 loss: -2.7435379028320312
Batch 35/64 loss: -2.248565673828125
Batch 36/64 loss: -2.8851327896118164
Batch 37/64 loss: -2.9282331466674805
Batch 38/64 loss: -2.293720245361328
Batch 39/64 loss: -2.752896308898926
Batch 40/64 loss: -2.646245002746582
Batch 41/64 loss: -2.5651769638061523
Batch 42/64 loss: -2.9626636505126953
Batch 43/64 loss: -2.7294178009033203
Batch 44/64 loss: -2.858346939086914
Batch 45/64 loss: -2.8641090393066406
Batch 46/64 loss: -2.8298988342285156
Batch 47/64 loss: -2.8712100982666016
Batch 48/64 loss: -3.019987106323242
Batch 49/64 loss: -2.850773811340332
Batch 50/64 loss: -2.7483654022216797
Batch 51/64 loss: -2.8140878677368164
Batch 52/64 loss: -2.8533687591552734
Batch 53/64 loss: -2.804208755493164
Batch 54/64 loss: -2.9652462005615234
Batch 55/64 loss: -2.857616424560547
Batch 56/64 loss: -2.6830196380615234
Batch 57/64 loss: -2.5364770889282227
Batch 58/64 loss: -2.858966827392578
Batch 59/64 loss: -2.7935895919799805
Batch 60/64 loss: -2.659939765930176
Batch 61/64 loss: -3.0100202560424805
Batch 62/64 loss: -2.7404394149780273
Batch 63/64 loss: -2.230854034423828
Batch 64/64 loss: -6.900875568389893
Epoch 364  Train loss: -2.7533500278697294  Val loss: -3.0667139426949097
Epoch 365
-------------------------------
Batch 1/64 loss: -2.525602340698242
Batch 2/64 loss: -2.664212226867676
Batch 3/64 loss: -2.710972785949707
Batch 4/64 loss: -2.570201873779297
Batch 5/64 loss: -2.440095901489258
Batch 6/64 loss: -2.9256372451782227
Batch 7/64 loss: -2.561614990234375
Batch 8/64 loss: -2.803908348083496
Batch 9/64 loss: -2.5484704971313477
Batch 10/64 loss: -2.970968246459961
Batch 11/64 loss: -2.6469335556030273
Batch 12/64 loss: -2.7305831909179688
Batch 13/64 loss: -2.65462589263916
Batch 14/64 loss: -2.713343620300293
Batch 15/64 loss: -2.7107715606689453
Batch 16/64 loss: -2.9020214080810547
Batch 17/64 loss: -2.8162384033203125
Batch 18/64 loss: -2.7578182220458984
Batch 19/64 loss: -2.5241384506225586
Batch 20/64 loss: -2.8712081909179688
Batch 21/64 loss: -2.8937482833862305
Batch 22/64 loss: -2.844437599182129
Batch 23/64 loss: -2.8078136444091797
Batch 24/64 loss: -2.9893856048583984
Batch 25/64 loss: -1.8468780517578125
Batch 26/64 loss: -2.6615848541259766
Batch 27/64 loss: -2.8581409454345703
Batch 28/64 loss: -3.009549140930176
Batch 29/64 loss: -2.797123908996582
Batch 30/64 loss: -2.5982589721679688
Batch 31/64 loss: -2.65985107421875
Batch 32/64 loss: -2.745817184448242
Batch 33/64 loss: -2.0908565521240234
Batch 34/64 loss: -2.678277015686035
Batch 35/64 loss: -2.8607177734375
Batch 36/64 loss: -2.566483497619629
Batch 37/64 loss: -2.9042768478393555
Batch 38/64 loss: -2.6210508346557617
Batch 39/64 loss: -2.5834312438964844
Batch 40/64 loss: -3.0007753372192383
Batch 41/64 loss: -2.7933826446533203
Batch 42/64 loss: -2.3893861770629883
Batch 43/64 loss: -2.704836845397949
Batch 44/64 loss: -2.7703723907470703
Batch 45/64 loss: -2.9526567459106445
Batch 46/64 loss: -2.7729148864746094
Batch 47/64 loss: -2.783341407775879
Batch 48/64 loss: -2.620011329650879
Batch 49/64 loss: -2.724597930908203
Batch 50/64 loss: -2.771221160888672
Batch 51/64 loss: -2.779269218444824
Batch 52/64 loss: -2.572262763977051
Batch 53/64 loss: -2.6316452026367188
Batch 54/64 loss: -2.746718406677246
Batch 55/64 loss: -2.8009939193725586
Batch 56/64 loss: -2.746140480041504
Batch 57/64 loss: -2.657735824584961
Batch 58/64 loss: -2.807750701904297
Batch 59/64 loss: -2.9409780502319336
Batch 60/64 loss: -2.6603565216064453
Batch 61/64 loss: -2.797178268432617
Batch 62/64 loss: -2.773257255554199
Batch 63/64 loss: -2.6668434143066406
Batch 64/64 loss: -7.368831634521484
Epoch 365  Train loss: -2.7679733425963158  Val loss: -3.137192886719589
Epoch 366
-------------------------------
Batch 1/64 loss: -2.8872814178466797
Batch 2/64 loss: -2.7196693420410156
Batch 3/64 loss: -2.9844846725463867
Batch 4/64 loss: -2.87203311920166
Batch 5/64 loss: -2.8017330169677734
Batch 6/64 loss: -2.8759613037109375
Batch 7/64 loss: -2.668034553527832
Batch 8/64 loss: -2.7450780868530273
Batch 9/64 loss: -2.0772323608398438
Batch 10/64 loss: -2.7778091430664062
Batch 11/64 loss: -3.0191965103149414
Batch 12/64 loss: -2.956437110900879
Batch 13/64 loss: -2.621723175048828
Batch 14/64 loss: -2.868250846862793
Batch 15/64 loss: -2.8481483459472656
Batch 16/64 loss: -2.874004364013672
Batch 17/64 loss: -2.734044075012207
Batch 18/64 loss: -2.8119020462036133
Batch 19/64 loss: -2.8868408203125
Batch 20/64 loss: -2.8339929580688477
Batch 21/64 loss: -2.598055839538574
Batch 22/64 loss: -2.878458023071289
Batch 23/64 loss: -2.5092334747314453
Batch 24/64 loss: -2.8253860473632812
Batch 25/64 loss: -2.228780746459961
Batch 26/64 loss: -2.835331916809082
Batch 27/64 loss: -2.741328239440918
Batch 28/64 loss: -2.8168392181396484
Batch 29/64 loss: -2.944499969482422
Batch 30/64 loss: -2.8428468704223633
Batch 31/64 loss: -2.972166061401367
Batch 32/64 loss: -2.838533401489258
Batch 33/64 loss: -2.7828245162963867
Batch 34/64 loss: -2.7270565032958984
Batch 35/64 loss: -2.9032459259033203
Batch 36/64 loss: -2.8579235076904297
Batch 37/64 loss: -2.557522773742676
Batch 38/64 loss: -2.9103546142578125
Batch 39/64 loss: -2.740690231323242
Batch 40/64 loss: -2.764143943786621
Batch 41/64 loss: -2.625515937805176
Batch 42/64 loss: -2.789679527282715
Batch 43/64 loss: -2.670844078063965
Batch 44/64 loss: -2.9324827194213867
Batch 45/64 loss: -2.8986282348632812
Batch 46/64 loss: -2.4521484375
Batch 47/64 loss: -2.6311168670654297
Batch 48/64 loss: -2.7697553634643555
Batch 49/64 loss: -2.76239013671875
Batch 50/64 loss: -2.7301206588745117
Batch 51/64 loss: -2.772833824157715
Batch 52/64 loss: -2.870321273803711
Batch 53/64 loss: -2.9303321838378906
Batch 54/64 loss: -2.1930360794067383
Batch 55/64 loss: -2.8175954818725586
Batch 56/64 loss: -2.54506778717041
Batch 57/64 loss: -2.6144094467163086
Batch 58/64 loss: -2.719803810119629
Batch 59/64 loss: -2.8902740478515625
Batch 60/64 loss: -2.712430953979492
Batch 61/64 loss: -2.948920249938965
Batch 62/64 loss: -2.393429756164551
Batch 63/64 loss: -2.7780895233154297
Batch 64/64 loss: -7.244184970855713
Epoch 366  Train loss: -2.808179516885795  Val loss: -3.1242194945869577
Epoch 367
-------------------------------
Batch 1/64 loss: -3.009079933166504
Batch 2/64 loss: -2.894918441772461
Batch 3/64 loss: -2.823160171508789
Batch 4/64 loss: -2.626004219055176
Batch 5/64 loss: -2.8537559509277344
Batch 6/64 loss: -2.8368406295776367
Batch 7/64 loss: -2.74733829498291
Batch 8/64 loss: -3.0162582397460938
Batch 9/64 loss: -2.818263053894043
Batch 10/64 loss: -2.859508514404297
Batch 11/64 loss: -2.5309572219848633
Batch 12/64 loss: -2.8009824752807617
Batch 13/64 loss: -2.7449331283569336
Batch 14/64 loss: -2.8827457427978516
Batch 15/64 loss: -2.921825408935547
Batch 16/64 loss: -2.6353063583374023
Batch 17/64 loss: -1.9674596786499023
Batch 18/64 loss: -2.6241416931152344
Batch 19/64 loss: -2.787199020385742
Batch 20/64 loss: -2.577524185180664
Batch 21/64 loss: -2.5784835815429688
Batch 22/64 loss: -2.8657655715942383
Batch 23/64 loss: -2.97664737701416
Batch 24/64 loss: -2.757190704345703
Batch 25/64 loss: -2.672532081604004
Batch 26/64 loss: -2.6841344833374023
Batch 27/64 loss: -2.7756032943725586
Batch 28/64 loss: -2.889399528503418
Batch 29/64 loss: -2.804880142211914
Batch 30/64 loss: -2.816211700439453
Batch 31/64 loss: -2.752223014831543
Batch 32/64 loss: -2.881450653076172
Batch 33/64 loss: -2.506500244140625
Batch 34/64 loss: -2.252354621887207
Batch 35/64 loss: -2.9383668899536133
Batch 36/64 loss: -2.599907875061035
Batch 37/64 loss: -2.48226261138916
Batch 38/64 loss: -2.7734107971191406
Batch 39/64 loss: -2.605912208557129
Batch 40/64 loss: -2.6630659103393555
Batch 41/64 loss: -2.761061668395996
Batch 42/64 loss: -2.607142448425293
Batch 43/64 loss: -2.714236259460449
Batch 44/64 loss: -2.2747936248779297
Batch 45/64 loss: -2.7338333129882812
Batch 46/64 loss: -2.74545955657959
Batch 47/64 loss: -2.551755905151367
Batch 48/64 loss: -2.76633358001709
Batch 49/64 loss: -2.756596565246582
Batch 50/64 loss: -2.610483169555664
Batch 51/64 loss: -2.5585756301879883
Batch 52/64 loss: -2.916436195373535
Batch 53/64 loss: -2.5461654663085938
Batch 54/64 loss: -2.9284887313842773
Batch 55/64 loss: -1.994807243347168
Batch 56/64 loss: -2.491631507873535
Batch 57/64 loss: -2.6489391326904297
Batch 58/64 loss: -2.6215648651123047
Batch 59/64 loss: -1.9504270553588867
Batch 60/64 loss: -2.832174301147461
Batch 61/64 loss: -2.651200294494629
Batch 62/64 loss: -2.64239501953125
Batch 63/64 loss: -2.602937698364258
Batch 64/64 loss: -7.144414901733398
Epoch 367  Train loss: -2.737258918612611  Val loss: -2.909512719747537
Epoch 368
-------------------------------
Batch 1/64 loss: -2.8286399841308594
Batch 2/64 loss: -2.8518218994140625
Batch 3/64 loss: -2.8054685592651367
Batch 4/64 loss: -2.6813974380493164
Batch 5/64 loss: -2.7470197677612305
Batch 6/64 loss: -2.788158416748047
Batch 7/64 loss: -2.899844169616699
Batch 8/64 loss: -2.4988622665405273
Batch 9/64 loss: -2.7118444442749023
Batch 10/64 loss: -2.46502685546875
Batch 11/64 loss: -2.8053789138793945
Batch 12/64 loss: -2.2925310134887695
Batch 13/64 loss: -2.73122501373291
Batch 14/64 loss: -2.806638717651367
Batch 15/64 loss: -2.342818260192871
Batch 16/64 loss: -2.853976249694824
Batch 17/64 loss: -2.6325950622558594
Batch 18/64 loss: -2.294236183166504
Batch 19/64 loss: -2.6668167114257812
Batch 20/64 loss: -2.6041440963745117
Batch 21/64 loss: -2.6054019927978516
Batch 22/64 loss: -2.7660884857177734
Batch 23/64 loss: -2.9378280639648438
Batch 24/64 loss: -2.869359016418457
Batch 25/64 loss: -2.690885543823242
Batch 26/64 loss: -2.70889949798584
Batch 27/64 loss: -2.8465185165405273
Batch 28/64 loss: -2.6988611221313477
Batch 29/64 loss: -2.5353994369506836
Batch 30/64 loss: -2.5476207733154297
Batch 31/64 loss: -2.5503129959106445
Batch 32/64 loss: -2.7941818237304688
Batch 33/64 loss: -2.552412986755371
Batch 34/64 loss: -2.863528251647949
Batch 35/64 loss: -2.6668128967285156
Batch 36/64 loss: -2.7248268127441406
Batch 37/64 loss: -2.854175567626953
Batch 38/64 loss: -2.824352264404297
Batch 39/64 loss: -2.3866758346557617
Batch 40/64 loss: -2.8194494247436523
Batch 41/64 loss: -2.299288749694824
Batch 42/64 loss: -2.7499828338623047
Batch 43/64 loss: -2.698942184448242
Batch 44/64 loss: -2.949939727783203
Batch 45/64 loss: -2.7375173568725586
Batch 46/64 loss: -2.894986152648926
Batch 47/64 loss: -2.498708724975586
Batch 48/64 loss: -2.7511520385742188
Batch 49/64 loss: -2.7735729217529297
Batch 50/64 loss: -2.018937110900879
Batch 51/64 loss: -2.7583913803100586
Batch 52/64 loss: -2.8515987396240234
Batch 53/64 loss: -2.489161491394043
Batch 54/64 loss: -2.9075136184692383
Batch 55/64 loss: -2.8507556915283203
Batch 56/64 loss: -2.5434207916259766
Batch 57/64 loss: -2.116684913635254
Batch 58/64 loss: -2.579669952392578
Batch 59/64 loss: -2.6747474670410156
Batch 60/64 loss: -2.723722457885742
Batch 61/64 loss: -2.8404712677001953
Batch 62/64 loss: -2.780592918395996
Batch 63/64 loss: -2.4506101608276367
Batch 64/64 loss: -6.9243245124816895
Epoch 368  Train loss: -2.724480743034213  Val loss: -3.029466596256007
Epoch 369
-------------------------------
Batch 1/64 loss: -2.8069353103637695
Batch 2/64 loss: -2.841130256652832
Batch 3/64 loss: -2.451920509338379
Batch 4/64 loss: -2.711915969848633
Batch 5/64 loss: -1.8965511322021484
Batch 6/64 loss: -2.57354736328125
Batch 7/64 loss: -2.860367774963379
Batch 8/64 loss: -3.004542350769043
Batch 9/64 loss: -2.6596336364746094
Batch 10/64 loss: -2.7038755416870117
Batch 11/64 loss: -2.792414665222168
Batch 12/64 loss: -2.8219308853149414
Batch 13/64 loss: -2.7811460494995117
Batch 14/64 loss: -2.6976003646850586
Batch 15/64 loss: -2.91268253326416
Batch 16/64 loss: -2.704920768737793
Batch 17/64 loss: -2.772526741027832
Batch 18/64 loss: -2.8386669158935547
Batch 19/64 loss: -2.8884220123291016
Batch 20/64 loss: -2.4201412200927734
Batch 21/64 loss: -2.4558019638061523
Batch 22/64 loss: -2.7726993560791016
Batch 23/64 loss: -2.785672187805176
Batch 24/64 loss: -2.9331445693969727
Batch 25/64 loss: -2.7206907272338867
Batch 26/64 loss: -2.7113800048828125
Batch 27/64 loss: -2.1937456130981445
Batch 28/64 loss: -2.8049192428588867
Batch 29/64 loss: -2.4485416412353516
Batch 30/64 loss: -2.5871400833129883
Batch 31/64 loss: -2.9029855728149414
Batch 32/64 loss: -2.1143035888671875
Batch 33/64 loss: -2.706467628479004
Batch 34/64 loss: -2.7216081619262695
Batch 35/64 loss: -2.578561782836914
Batch 36/64 loss: -2.520401954650879
Batch 37/64 loss: -2.8934717178344727
Batch 38/64 loss: -2.67724609375
Batch 39/64 loss: -2.61270809173584
Batch 40/64 loss: -2.5564050674438477
Batch 41/64 loss: -2.8631467819213867
Batch 42/64 loss: -2.616000175476074
Batch 43/64 loss: -2.4887008666992188
Batch 44/64 loss: -2.685286521911621
Batch 45/64 loss: -2.77496337890625
Batch 46/64 loss: -2.584615707397461
Batch 47/64 loss: -2.667384147644043
Batch 48/64 loss: -2.490960121154785
Batch 49/64 loss: -2.4497108459472656
Batch 50/64 loss: -2.471116065979004
Batch 51/64 loss: -2.5347137451171875
Batch 52/64 loss: -2.646822929382324
Batch 53/64 loss: -2.446812629699707
Batch 54/64 loss: -2.495659828186035
Batch 55/64 loss: -2.637606620788574
Batch 56/64 loss: -2.7692337036132812
Batch 57/64 loss: -2.796280860900879
Batch 58/64 loss: -2.5544776916503906
Batch 59/64 loss: -2.78826904296875
Batch 60/64 loss: -2.72189998626709
Batch 61/64 loss: -2.6784448623657227
Batch 62/64 loss: -2.7747554779052734
Batch 63/64 loss: -2.6584672927856445
Batch 64/64 loss: -7.218830108642578
Epoch 369  Train loss: -2.711344610476026  Val loss: -3.0559236192211663
Epoch 370
-------------------------------
Batch 1/64 loss: -2.6012163162231445
Batch 2/64 loss: -2.7000045776367188
Batch 3/64 loss: -2.856356620788574
Batch 4/64 loss: -2.5847015380859375
Batch 5/64 loss: -3.002091407775879
Batch 6/64 loss: -2.656752586364746
Batch 7/64 loss: -2.460160255432129
Batch 8/64 loss: -2.8388757705688477
Batch 9/64 loss: -2.8289403915405273
Batch 10/64 loss: -2.8292627334594727
Batch 11/64 loss: -2.8299560546875
Batch 12/64 loss: -2.6657066345214844
Batch 13/64 loss: -2.43654727935791
Batch 14/64 loss: -2.790827751159668
Batch 15/64 loss: -2.73297119140625
Batch 16/64 loss: -2.7355422973632812
Batch 17/64 loss: -2.9323959350585938
Batch 18/64 loss: -2.7201623916625977
Batch 19/64 loss: -2.96810245513916
Batch 20/64 loss: -2.870570182800293
Batch 21/64 loss: -2.766085624694824
Batch 22/64 loss: -2.624335289001465
Batch 23/64 loss: -2.7671852111816406
Batch 24/64 loss: -2.2955827713012695
Batch 25/64 loss: -2.622812271118164
Batch 26/64 loss: -2.347808837890625
Batch 27/64 loss: -2.902010917663574
Batch 28/64 loss: -2.7624006271362305
Batch 29/64 loss: -2.848417282104492
Batch 30/64 loss: -2.8882150650024414
Batch 31/64 loss: -2.756977081298828
Batch 32/64 loss: -2.4463186264038086
Batch 33/64 loss: -2.95670223236084
Batch 34/64 loss: -2.668198585510254
Batch 35/64 loss: -2.649974822998047
Batch 36/64 loss: -2.6073102951049805
Batch 37/64 loss: -2.562633514404297
Batch 38/64 loss: -2.8715648651123047
Batch 39/64 loss: -2.5416955947875977
Batch 40/64 loss: -2.6448678970336914
Batch 41/64 loss: -2.963168144226074
Batch 42/64 loss: -2.7446155548095703
Batch 43/64 loss: -2.971493721008301
Batch 44/64 loss: -2.6427736282348633
Batch 45/64 loss: -2.6740360260009766
Batch 46/64 loss: -2.726787567138672
Batch 47/64 loss: -2.724514961242676
Batch 48/64 loss: -2.8137331008911133
Batch 49/64 loss: -2.32009220123291
Batch 50/64 loss: -2.586658477783203
Batch 51/64 loss: -2.5734004974365234
Batch 52/64 loss: -2.2696523666381836
Batch 53/64 loss: -2.9503297805786133
Batch 54/64 loss: -2.56732177734375
Batch 55/64 loss: -2.777608871459961
Batch 56/64 loss: -2.6818952560424805
Batch 57/64 loss: -2.4033937454223633
Batch 58/64 loss: -2.712831497192383
Batch 59/64 loss: -2.8604278564453125
Batch 60/64 loss: -2.188365936279297
Batch 61/64 loss: -2.7593460083007812
Batch 62/64 loss: -2.5117130279541016
Batch 63/64 loss: -2.6700143814086914
Batch 64/64 loss: -6.62452507019043
Epoch 370  Train loss: -2.739369568170286  Val loss: -2.941489727636383
Epoch 371
-------------------------------
Batch 1/64 loss: -2.6489076614379883
Batch 2/64 loss: -2.1440343856811523
Batch 3/64 loss: -2.7786178588867188
Batch 4/64 loss: -2.3903722763061523
Batch 5/64 loss: -2.6084976196289062
Batch 6/64 loss: -2.6528539657592773
Batch 7/64 loss: -2.815423011779785
Batch 8/64 loss: -2.812954902648926
Batch 9/64 loss: -2.760042190551758
Batch 10/64 loss: -2.5451488494873047
Batch 11/64 loss: -2.792478561401367
Batch 12/64 loss: -2.7873220443725586
Batch 13/64 loss: -2.5143394470214844
Batch 14/64 loss: -2.6456594467163086
Batch 15/64 loss: -1.9437294006347656
Batch 16/64 loss: -2.708613395690918
Batch 17/64 loss: -2.210956573486328
Batch 18/64 loss: -2.7033462524414062
Batch 19/64 loss: -2.6081724166870117
Batch 20/64 loss: -2.924783706665039
Batch 21/64 loss: -2.4293212890625
Batch 22/64 loss: -2.0988426208496094
Batch 23/64 loss: -2.600649833679199
Batch 24/64 loss: -2.7747440338134766
Batch 25/64 loss: -2.7889604568481445
Batch 26/64 loss: -2.5615663528442383
Batch 27/64 loss: -2.5909910202026367
Batch 28/64 loss: -2.8311309814453125
Batch 29/64 loss: -2.7843542098999023
Batch 30/64 loss: -2.7853269577026367
Batch 31/64 loss: -2.746225357055664
Batch 32/64 loss: -2.6474199295043945
Batch 33/64 loss: -2.8434438705444336
Batch 34/64 loss: -2.7462902069091797
Batch 35/64 loss: -2.51153564453125
Batch 36/64 loss: -2.7517051696777344
Batch 37/64 loss: -2.4451942443847656
Batch 38/64 loss: -2.8308868408203125
Batch 39/64 loss: -2.7485427856445312
Batch 40/64 loss: -2.7910947799682617
Batch 41/64 loss: -2.7851133346557617
Batch 42/64 loss: -2.798813819885254
Batch 43/64 loss: -2.602889060974121
Batch 44/64 loss: -2.548159599304199
Batch 45/64 loss: -2.5705833435058594
Batch 46/64 loss: -2.5705080032348633
Batch 47/64 loss: -2.88323974609375
Batch 48/64 loss: -2.6350536346435547
Batch 49/64 loss: -2.9081850051879883
Batch 50/64 loss: -2.794257164001465
Batch 51/64 loss: -2.707437515258789
Batch 52/64 loss: -2.5768442153930664
Batch 53/64 loss: -2.6720151901245117
Batch 54/64 loss: -2.686347007751465
Batch 55/64 loss: -2.7402238845825195
Batch 56/64 loss: -2.7817296981811523
Batch 57/64 loss: -2.8078994750976562
Batch 58/64 loss: -2.5862722396850586
Batch 59/64 loss: -2.261219024658203
Batch 60/64 loss: -2.5523681640625
Batch 61/64 loss: -2.465097427368164
Batch 62/64 loss: -2.708683967590332
Batch 63/64 loss: -2.747450828552246
Batch 64/64 loss: -7.548388481140137
Epoch 371  Train loss: -2.703626090405034  Val loss: -3.109090287251161
Epoch 372
-------------------------------
Batch 1/64 loss: -2.776540756225586
Batch 2/64 loss: -2.2736454010009766
Batch 3/64 loss: -2.7470054626464844
Batch 4/64 loss: -2.851046562194824
Batch 5/64 loss: -2.6807661056518555
Batch 6/64 loss: -2.695431709289551
Batch 7/64 loss: -2.9599428176879883
Batch 8/64 loss: -2.391362190246582
Batch 9/64 loss: -2.6243972778320312
Batch 10/64 loss: -2.654902458190918
Batch 11/64 loss: -2.823629379272461
Batch 12/64 loss: -2.6919078826904297
Batch 13/64 loss: -2.7788753509521484
Batch 14/64 loss: -2.8018131256103516
Batch 15/64 loss: -2.7649974822998047
Batch 16/64 loss: -2.8556747436523438
Batch 17/64 loss: -2.6239709854125977
Batch 18/64 loss: -2.4976072311401367
Batch 19/64 loss: -2.683915138244629
Batch 20/64 loss: -2.5612621307373047
Batch 21/64 loss: -2.6859092712402344
Batch 22/64 loss: -2.5937843322753906
Batch 23/64 loss: -2.6016530990600586
Batch 24/64 loss: -2.624134063720703
Batch 25/64 loss: -2.832378387451172
Batch 26/64 loss: -2.873973846435547
Batch 27/64 loss: -2.8172407150268555
Batch 28/64 loss: -2.739076614379883
Batch 29/64 loss: -2.683596611022949
Batch 30/64 loss: -2.824430465698242
Batch 31/64 loss: -2.802797317504883
Batch 32/64 loss: -2.091372489929199
Batch 33/64 loss: -2.637044906616211
Batch 34/64 loss: -2.65753173828125
Batch 35/64 loss: -2.6871862411499023
Batch 36/64 loss: -2.64249324798584
Batch 37/64 loss: -2.712050437927246
Batch 38/64 loss: -2.7983198165893555
Batch 39/64 loss: -2.337613105773926
Batch 40/64 loss: -2.533644676208496
Batch 41/64 loss: -2.645183563232422
Batch 42/64 loss: -2.8441553115844727
Batch 43/64 loss: -2.550783157348633
Batch 44/64 loss: -2.8009910583496094
Batch 45/64 loss: -2.481198310852051
Batch 46/64 loss: -2.8936567306518555
Batch 47/64 loss: -2.495650291442871
Batch 48/64 loss: -2.8164777755737305
Batch 49/64 loss: -2.7978744506835938
Batch 50/64 loss: -2.749652862548828
Batch 51/64 loss: -2.3777265548706055
Batch 52/64 loss: -2.4691333770751953
Batch 53/64 loss: -2.660677909851074
Batch 54/64 loss: -2.519746780395508
Batch 55/64 loss: -2.8139266967773438
Batch 56/64 loss: -2.6660327911376953
Batch 57/64 loss: -2.693070411682129
Batch 58/64 loss: -2.768390655517578
Batch 59/64 loss: -2.090648651123047
Batch 60/64 loss: -2.4544572830200195
Batch 61/64 loss: -2.484246253967285
Batch 62/64 loss: -2.418245315551758
Batch 63/64 loss: -2.419417381286621
Batch 64/64 loss: -7.2839035987854
Epoch 372  Train loss: -2.702575636845009  Val loss: -2.8723401466186105
Epoch 373
-------------------------------
Batch 1/64 loss: -2.097914695739746
Batch 2/64 loss: -2.769502639770508
Batch 3/64 loss: -2.7305145263671875
Batch 4/64 loss: -2.5659427642822266
Batch 5/64 loss: -2.6087608337402344
Batch 6/64 loss: -2.7180795669555664
Batch 7/64 loss: -2.7150020599365234
Batch 8/64 loss: -2.67647647857666
Batch 9/64 loss: -2.8600168228149414
Batch 10/64 loss: -2.868978500366211
Batch 11/64 loss: -2.920140266418457
Batch 12/64 loss: -2.927201271057129
Batch 13/64 loss: -2.521418571472168
Batch 14/64 loss: -2.555527687072754
Batch 15/64 loss: -2.6879653930664062
Batch 16/64 loss: -2.6067705154418945
Batch 17/64 loss: -2.5425987243652344
Batch 18/64 loss: -2.7212753295898438
Batch 19/64 loss: -2.7763586044311523
Batch 20/64 loss: -2.5815563201904297
Batch 21/64 loss: -2.683849334716797
Batch 22/64 loss: -2.6100969314575195
Batch 23/64 loss: -2.941194534301758
Batch 24/64 loss: -2.5801773071289062
Batch 25/64 loss: -2.93435001373291
Batch 26/64 loss: -2.5208797454833984
Batch 27/64 loss: -1.9248170852661133
Batch 28/64 loss: -2.846817970275879
Batch 29/64 loss: -2.780022621154785
Batch 30/64 loss: -2.6411914825439453
Batch 31/64 loss: -2.755685806274414
Batch 32/64 loss: -2.982619285583496
Batch 33/64 loss: -2.5510778427124023
Batch 34/64 loss: -2.7918310165405273
Batch 35/64 loss: -2.743990898132324
Batch 36/64 loss: -2.8807239532470703
Batch 37/64 loss: -2.8574419021606445
Batch 38/64 loss: -2.734808921813965
Batch 39/64 loss: -2.731387138366699
Batch 40/64 loss: -2.7552452087402344
Batch 41/64 loss: -2.1209592819213867
Batch 42/64 loss: -2.809602737426758
Batch 43/64 loss: -2.1053333282470703
Batch 44/64 loss: -2.6449575424194336
Batch 45/64 loss: -2.887491226196289
Batch 46/64 loss: -2.8695850372314453
Batch 47/64 loss: -2.335916519165039
Batch 48/64 loss: -2.7138776779174805
Batch 49/64 loss: -2.8247289657592773
Batch 50/64 loss: -2.670991897583008
Batch 51/64 loss: -2.8569040298461914
Batch 52/64 loss: -2.7484703063964844
Batch 53/64 loss: -2.8465957641601562
Batch 54/64 loss: -2.3325881958007812
Batch 55/64 loss: -2.661043167114258
Batch 56/64 loss: -2.6425161361694336
Batch 57/64 loss: -2.8355770111083984
Batch 58/64 loss: -2.618223190307617
Batch 59/64 loss: -2.534334182739258
Batch 60/64 loss: -2.8136205673217773
Batch 61/64 loss: -2.8507232666015625
Batch 62/64 loss: -2.5822715759277344
Batch 63/64 loss: -2.845761299133301
Batch 64/64 loss: -7.3678789138793945
Epoch 373  Train loss: -2.735344198638318  Val loss: -2.8596542725448346
Epoch 374
-------------------------------
Batch 1/64 loss: -2.8074846267700195
Batch 2/64 loss: -2.5691022872924805
Batch 3/64 loss: -2.8061656951904297
Batch 4/64 loss: -2.6103172302246094
Batch 5/64 loss: -2.6936912536621094
Batch 6/64 loss: -2.5813140869140625
Batch 7/64 loss: -2.755337715148926
Batch 8/64 loss: -2.825826644897461
Batch 9/64 loss: -2.6585121154785156
Batch 10/64 loss: -2.8619117736816406
Batch 11/64 loss: -2.842435836791992
Batch 12/64 loss: -2.63662052154541
Batch 13/64 loss: -2.8541688919067383
Batch 14/64 loss: -2.6113414764404297
Batch 15/64 loss: -2.789975166320801
Batch 16/64 loss: -2.7942962646484375
Batch 17/64 loss: -2.583921432495117
Batch 18/64 loss: -2.8851308822631836
Batch 19/64 loss: -2.547170639038086
Batch 20/64 loss: -2.866133689880371
Batch 21/64 loss: -2.698131561279297
Batch 22/64 loss: -2.6099510192871094
Batch 23/64 loss: -2.8169679641723633
Batch 24/64 loss: -2.681814193725586
Batch 25/64 loss: -2.3276195526123047
Batch 26/64 loss: -2.8626022338867188
Batch 27/64 loss: -2.799433708190918
Batch 28/64 loss: -2.6651058197021484
Batch 29/64 loss: -2.816409111022949
Batch 30/64 loss: -2.677586555480957
Batch 31/64 loss: -2.8514814376831055
Batch 32/64 loss: -2.774904251098633
Batch 33/64 loss: -2.573322296142578
Batch 34/64 loss: -2.159235954284668
Batch 35/64 loss: -2.688828468322754
Batch 36/64 loss: -2.866299629211426
Batch 37/64 loss: -2.543895721435547
Batch 38/64 loss: -2.875380516052246
Batch 39/64 loss: -2.7036609649658203
Batch 40/64 loss: -2.7464303970336914
Batch 41/64 loss: -2.7732276916503906
Batch 42/64 loss: -2.5913639068603516
Batch 43/64 loss: -2.8795766830444336
Batch 44/64 loss: -2.6621150970458984
Batch 45/64 loss: -2.808513641357422
Batch 46/64 loss: -2.606302261352539
Batch 47/64 loss: -2.447504997253418
Batch 48/64 loss: -2.5890913009643555
Batch 49/64 loss: -2.541696548461914
Batch 50/64 loss: -2.6408262252807617
Batch 51/64 loss: -2.6935129165649414
Batch 52/64 loss: -2.8335018157958984
Batch 53/64 loss: -2.412896156311035
Batch 54/64 loss: -2.555004119873047
Batch 55/64 loss: -2.7208662033081055
Batch 56/64 loss: -2.200894355773926
Batch 57/64 loss: -2.503538131713867
Batch 58/64 loss: -2.480595588684082
Batch 59/64 loss: -2.6531143188476562
Batch 60/64 loss: -2.514113426208496
Batch 61/64 loss: -2.6397714614868164
Batch 62/64 loss: -2.7006969451904297
Batch 63/64 loss: -1.860692024230957
Batch 64/64 loss: -6.454622268676758
Epoch 374  Train loss: -2.705416503607058  Val loss: -2.71622356926043
Epoch 375
-------------------------------
Batch 1/64 loss: -2.6891279220581055
Batch 2/64 loss: -2.5577783584594727
Batch 3/64 loss: -2.5653905868530273
Batch 4/64 loss: -2.7525548934936523
Batch 5/64 loss: -2.5824413299560547
Batch 6/64 loss: -2.7199811935424805
Batch 7/64 loss: -2.744626045227051
Batch 8/64 loss: -2.4812517166137695
Batch 9/64 loss: -2.5602474212646484
Batch 10/64 loss: -2.8011703491210938
Batch 11/64 loss: -2.6411752700805664
Batch 12/64 loss: -2.5384273529052734
Batch 13/64 loss: -2.6597518920898438
Batch 14/64 loss: -2.3606414794921875
Batch 15/64 loss: -2.71407413482666
Batch 16/64 loss: -2.7895994186401367
Batch 17/64 loss: -2.6729164123535156
Batch 18/64 loss: -2.5043764114379883
Batch 19/64 loss: -2.619140625
Batch 20/64 loss: -2.863800048828125
Batch 21/64 loss: -2.771482467651367
Batch 22/64 loss: -2.8040924072265625
Batch 23/64 loss: -2.5149927139282227
Batch 24/64 loss: -2.8212385177612305
Batch 25/64 loss: -2.483530044555664
Batch 26/64 loss: -2.7460756301879883
Batch 27/64 loss: -2.648914337158203
Batch 28/64 loss: -2.798044204711914
Batch 29/64 loss: -2.7831897735595703
Batch 30/64 loss: -2.791290283203125
Batch 31/64 loss: -2.5883703231811523
Batch 32/64 loss: -2.6872806549072266
Batch 33/64 loss: -2.7428722381591797
Batch 34/64 loss: -2.6299619674682617
Batch 35/64 loss: -2.868109703063965
Batch 36/64 loss: -2.806720733642578
Batch 37/64 loss: -2.9345550537109375
Batch 38/64 loss: -2.743925094604492
Batch 39/64 loss: -2.6383867263793945
Batch 40/64 loss: -2.7973175048828125
Batch 41/64 loss: -2.8126182556152344
Batch 42/64 loss: -2.876328468322754
Batch 43/64 loss: -2.681682586669922
Batch 44/64 loss: -2.697904586791992
Batch 45/64 loss: -2.873337745666504
Batch 46/64 loss: -1.9541244506835938
Batch 47/64 loss: -2.6388845443725586
Batch 48/64 loss: -2.8550052642822266
Batch 49/64 loss: -2.2542734146118164
Batch 50/64 loss: -2.463597297668457
Batch 51/64 loss: -2.8500423431396484
Batch 52/64 loss: -2.776059150695801
Batch 53/64 loss: -2.895711898803711
Batch 54/64 loss: -2.887310028076172
Batch 55/64 loss: -2.805304527282715
Batch 56/64 loss: -2.6264705657958984
Batch 57/64 loss: -2.6756439208984375
Batch 58/64 loss: -2.9103822708129883
Batch 59/64 loss: -2.786505699157715
Batch 60/64 loss: -2.6057844161987305
Batch 61/64 loss: -2.917557716369629
Batch 62/64 loss: -2.664133071899414
Batch 63/64 loss: -3.0007877349853516
Batch 64/64 loss: -7.385743141174316
Epoch 375  Train loss: -2.7524326361861884  Val loss: -3.07609126821826
Epoch 376
-------------------------------
Batch 1/64 loss: -2.644329071044922
Batch 2/64 loss: -2.458005905151367
Batch 3/64 loss: -2.6972455978393555
Batch 4/64 loss: -2.6580629348754883
Batch 5/64 loss: -2.78281307220459
Batch 6/64 loss: -2.802250862121582
Batch 7/64 loss: -2.8637189865112305
Batch 8/64 loss: -2.5557165145874023
Batch 9/64 loss: -2.8306636810302734
Batch 10/64 loss: -2.8048648834228516
Batch 11/64 loss: -2.944197654724121
Batch 12/64 loss: -2.789642333984375
Batch 13/64 loss: -2.6029253005981445
Batch 14/64 loss: -2.605621337890625
Batch 15/64 loss: -2.649834632873535
Batch 16/64 loss: -2.9210987091064453
Batch 17/64 loss: -2.5936994552612305
Batch 18/64 loss: -2.724493980407715
Batch 19/64 loss: -2.6300277709960938
Batch 20/64 loss: -2.793182373046875
Batch 21/64 loss: -2.4970312118530273
Batch 22/64 loss: -2.93587589263916
Batch 23/64 loss: -2.4302186965942383
Batch 24/64 loss: -2.6996631622314453
Batch 25/64 loss: -2.7081193923950195
Batch 26/64 loss: -2.8328018188476562
Batch 27/64 loss: -2.7704477310180664
Batch 28/64 loss: -2.6550779342651367
Batch 29/64 loss: -2.7836551666259766
Batch 30/64 loss: -2.445572853088379
Batch 31/64 loss: -2.6827545166015625
Batch 32/64 loss: -2.733384132385254
Batch 33/64 loss: -2.8270559310913086
Batch 34/64 loss: -2.9016590118408203
Batch 35/64 loss: -2.7997913360595703
Batch 36/64 loss: -2.732295036315918
Batch 37/64 loss: -2.7916030883789062
Batch 38/64 loss: -2.581418037414551
Batch 39/64 loss: -2.8320932388305664
Batch 40/64 loss: -2.298661231994629
Batch 41/64 loss: -2.9176464080810547
Batch 42/64 loss: -1.959263801574707
Batch 43/64 loss: -2.8072290420532227
Batch 44/64 loss: -2.891606330871582
Batch 45/64 loss: -2.8261241912841797
Batch 46/64 loss: -2.717012405395508
Batch 47/64 loss: -2.5938425064086914
Batch 48/64 loss: -2.888019561767578
Batch 49/64 loss: -2.7610597610473633
Batch 50/64 loss: -2.9766674041748047
Batch 51/64 loss: -2.442605972290039
Batch 52/64 loss: -2.7546825408935547
Batch 53/64 loss: -2.803159713745117
Batch 54/64 loss: -2.3254289627075195
Batch 55/64 loss: -2.647867202758789
Batch 56/64 loss: -2.7859153747558594
Batch 57/64 loss: -2.736347198486328
Batch 58/64 loss: -2.624635696411133
Batch 59/64 loss: -2.589339256286621
Batch 60/64 loss: -2.9795427322387695
Batch 61/64 loss: -2.9304094314575195
Batch 62/64 loss: -2.772806167602539
Batch 63/64 loss: -2.4044618606567383
Batch 64/64 loss: -7.1323089599609375
Epoch 376  Train loss: -2.757278113271676  Val loss: -2.9993162908914575
Epoch 377
-------------------------------
Batch 1/64 loss: -2.819356918334961
Batch 2/64 loss: -2.9825096130371094
Batch 3/64 loss: -2.675201416015625
Batch 4/64 loss: -2.605184555053711
Batch 5/64 loss: -2.6899490356445312
Batch 6/64 loss: -2.654947280883789
Batch 7/64 loss: -2.4709415435791016
Batch 8/64 loss: -2.5576648712158203
Batch 9/64 loss: -2.761739730834961
Batch 10/64 loss: -2.8724870681762695
Batch 11/64 loss: -2.478163719177246
Batch 12/64 loss: -2.6257858276367188
Batch 13/64 loss: -2.8835344314575195
Batch 14/64 loss: -2.620471954345703
Batch 15/64 loss: -2.87015438079834
Batch 16/64 loss: -2.8812742233276367
Batch 17/64 loss: -2.4036645889282227
Batch 18/64 loss: -2.5187416076660156
Batch 19/64 loss: -2.621882438659668
Batch 20/64 loss: -2.6932687759399414
Batch 21/64 loss: -2.848240852355957
Batch 22/64 loss: -2.510592460632324
Batch 23/64 loss: -2.683116912841797
Batch 24/64 loss: -2.5039453506469727
Batch 25/64 loss: -2.8981761932373047
Batch 26/64 loss: -2.5198230743408203
Batch 27/64 loss: -2.7432022094726562
Batch 28/64 loss: -2.749614715576172
Batch 29/64 loss: -2.703352928161621
Batch 30/64 loss: -2.9678564071655273
Batch 31/64 loss: -2.7251386642456055
Batch 32/64 loss: -2.663640022277832
Batch 33/64 loss: -2.7616329193115234
Batch 34/64 loss: -2.707317352294922
Batch 35/64 loss: -2.7579269409179688
Batch 36/64 loss: -2.744988441467285
Batch 37/64 loss: -2.7407894134521484
Batch 38/64 loss: -2.6977853775024414
Batch 39/64 loss: -2.926769256591797
Batch 40/64 loss: -2.6749801635742188
Batch 41/64 loss: -2.4743785858154297
Batch 42/64 loss: -2.828296661376953
Batch 43/64 loss: -2.53269100189209
Batch 44/64 loss: -2.880016326904297
Batch 45/64 loss: -2.8655643463134766
Batch 46/64 loss: -2.945577621459961
Batch 47/64 loss: -2.8815107345581055
Batch 48/64 loss: -2.5015506744384766
Batch 49/64 loss: -2.665982246398926
Batch 50/64 loss: -2.7301502227783203
Batch 51/64 loss: -2.055853843688965
Batch 52/64 loss: -2.7139101028442383
Batch 53/64 loss: -2.59598445892334
Batch 54/64 loss: -2.8471479415893555
Batch 55/64 loss: -2.6821861267089844
Batch 56/64 loss: -2.885061264038086
Batch 57/64 loss: -1.9585752487182617
Batch 58/64 loss: -2.9658098220825195
Batch 59/64 loss: -2.8094215393066406
Batch 60/64 loss: -2.7478857040405273
Batch 61/64 loss: -2.640538215637207
Batch 62/64 loss: -2.544583320617676
Batch 63/64 loss: -2.590773582458496
Batch 64/64 loss: -7.319622993469238
Epoch 377  Train loss: -2.745866360383875  Val loss: -2.8896187064573935
Epoch 378
-------------------------------
Batch 1/64 loss: -2.8415889739990234
Batch 2/64 loss: -2.8390846252441406
Batch 3/64 loss: -2.5654592514038086
Batch 4/64 loss: -2.719676971435547
Batch 5/64 loss: -2.794388771057129
Batch 6/64 loss: -2.5607681274414062
Batch 7/64 loss: -2.628690719604492
Batch 8/64 loss: -2.54280948638916
Batch 9/64 loss: -2.7473955154418945
Batch 10/64 loss: -2.8795948028564453
Batch 11/64 loss: -2.933051109313965
Batch 12/64 loss: -2.6687116622924805
Batch 13/64 loss: -2.6384668350219727
Batch 14/64 loss: -2.5398550033569336
Batch 15/64 loss: -2.783946990966797
Batch 16/64 loss: -2.7386484146118164
Batch 17/64 loss: -2.7103700637817383
Batch 18/64 loss: -2.7085189819335938
Batch 19/64 loss: -2.2151498794555664
Batch 20/64 loss: -2.475818634033203
Batch 21/64 loss: -2.724612236022949
Batch 22/64 loss: -2.6809730529785156
Batch 23/64 loss: -2.722707748413086
Batch 24/64 loss: -2.650918960571289
Batch 25/64 loss: -2.8325586318969727
Batch 26/64 loss: -2.613091468811035
Batch 27/64 loss: -2.843581199645996
Batch 28/64 loss: -2.9570016860961914
Batch 29/64 loss: -2.705160140991211
Batch 30/64 loss: -2.5997066497802734
Batch 31/64 loss: -2.6841440200805664
Batch 32/64 loss: -1.819981575012207
Batch 33/64 loss: -2.796891212463379
Batch 34/64 loss: -2.8347578048706055
Batch 35/64 loss: -2.727932929992676
Batch 36/64 loss: -2.7503490447998047
Batch 37/64 loss: -2.504105567932129
Batch 38/64 loss: -2.846830368041992
Batch 39/64 loss: -2.5460453033447266
Batch 40/64 loss: -2.706930160522461
Batch 41/64 loss: -2.8046369552612305
Batch 42/64 loss: -2.5976476669311523
Batch 43/64 loss: -2.5782508850097656
Batch 44/64 loss: -2.7322959899902344
Batch 45/64 loss: -2.611393928527832
Batch 46/64 loss: -2.5777101516723633
Batch 47/64 loss: -2.621859550476074
Batch 48/64 loss: -2.7544097900390625
Batch 49/64 loss: -2.6281070709228516
Batch 50/64 loss: -2.702946662902832
Batch 51/64 loss: -2.451798439025879
Batch 52/64 loss: -2.4018211364746094
Batch 53/64 loss: -2.8452396392822266
Batch 54/64 loss: -2.4732770919799805
Batch 55/64 loss: -2.555729866027832
Batch 56/64 loss: -2.514815330505371
Batch 57/64 loss: -2.729161262512207
Batch 58/64 loss: -2.617049217224121
Batch 59/64 loss: -2.782735824584961
Batch 60/64 loss: -2.747028350830078
Batch 61/64 loss: -1.8548641204833984
Batch 62/64 loss: -2.6872072219848633
Batch 63/64 loss: -2.586751937866211
Batch 64/64 loss: -7.195967197418213
Epoch 378  Train loss: -2.7032782442429486  Val loss: -2.9180736738381925
Epoch 379
-------------------------------
Batch 1/64 loss: -2.6624555587768555
Batch 2/64 loss: -2.3598060607910156
Batch 3/64 loss: -2.1545705795288086
Batch 4/64 loss: -2.641200065612793
Batch 5/64 loss: -1.9801673889160156
Batch 6/64 loss: -2.7717323303222656
Batch 7/64 loss: -2.5167160034179688
Batch 8/64 loss: -2.799358367919922
Batch 9/64 loss: -2.556997299194336
Batch 10/64 loss: -2.294118881225586
Batch 11/64 loss: -2.6964311599731445
Batch 12/64 loss: -2.5213890075683594
Batch 13/64 loss: -2.5797548294067383
Batch 14/64 loss: -2.8117265701293945
Batch 15/64 loss: -2.4588918685913086
Batch 16/64 loss: -2.41403865814209
Batch 17/64 loss: -2.3390464782714844
Batch 18/64 loss: -2.7953882217407227
Batch 19/64 loss: -2.4135055541992188
Batch 20/64 loss: -2.8574838638305664
Batch 21/64 loss: -2.623758316040039
Batch 22/64 loss: -1.827347755432129
Batch 23/64 loss: -2.8094959259033203
Batch 24/64 loss: -2.8941593170166016
Batch 25/64 loss: -2.7353925704956055
Batch 26/64 loss: -1.904886245727539
Batch 27/64 loss: -2.678839683532715
Batch 28/64 loss: -2.6218156814575195
Batch 29/64 loss: -2.8487586975097656
Batch 30/64 loss: -2.5755910873413086
Batch 31/64 loss: -2.05499267578125
Batch 32/64 loss: -2.8066329956054688
Batch 33/64 loss: -2.7453107833862305
Batch 34/64 loss: -2.7453908920288086
Batch 35/64 loss: -2.9119625091552734
Batch 36/64 loss: -2.712924003601074
Batch 37/64 loss: -2.7378225326538086
Batch 38/64 loss: -2.812044143676758
Batch 39/64 loss: -2.5822525024414062
Batch 40/64 loss: -2.536105155944824
Batch 41/64 loss: -2.5734052658081055
Batch 42/64 loss: -2.772480010986328
Batch 43/64 loss: -2.7212839126586914
Batch 44/64 loss: -2.8480348587036133
Batch 45/64 loss: -2.369281768798828
Batch 46/64 loss: -2.7711801528930664
Batch 47/64 loss: -2.7957801818847656
Batch 48/64 loss: -2.7422218322753906
Batch 49/64 loss: -2.6311912536621094
Batch 50/64 loss: -2.7208967208862305
Batch 51/64 loss: -3.0207576751708984
Batch 52/64 loss: -2.528679847717285
Batch 53/64 loss: -2.6340484619140625
Batch 54/64 loss: -2.6035289764404297
Batch 55/64 loss: -2.72247314453125
Batch 56/64 loss: -2.8705339431762695
Batch 57/64 loss: -2.8302574157714844
Batch 58/64 loss: -2.6776466369628906
Batch 59/64 loss: -2.8538894653320312
Batch 60/64 loss: -2.5853958129882812
Batch 61/64 loss: -2.6628150939941406
Batch 62/64 loss: -2.795827865600586
Batch 63/64 loss: -2.808380126953125
Batch 64/64 loss: -7.364223480224609
Epoch 379  Train loss: -2.6800536510991115  Val loss: -2.79801425737204
Epoch 380
-------------------------------
Batch 1/64 loss: -2.2781686782836914
Batch 2/64 loss: -2.6829919815063477
Batch 3/64 loss: -2.8374271392822266
Batch 4/64 loss: -1.429020881652832
Batch 5/64 loss: -2.575486183166504
Batch 6/64 loss: -2.8042211532592773
Batch 7/64 loss: -2.874436378479004
Batch 8/64 loss: -2.4279136657714844
Batch 9/64 loss: -2.765109062194824
Batch 10/64 loss: -2.431929588317871
Batch 11/64 loss: -2.5906457901000977
Batch 12/64 loss: -2.6467857360839844
Batch 13/64 loss: -2.41080379486084
Batch 14/64 loss: -2.4666128158569336
Batch 15/64 loss: -2.8071212768554688
Batch 16/64 loss: -2.8255786895751953
Batch 17/64 loss: -2.7542295455932617
Batch 18/64 loss: -2.6811342239379883
Batch 19/64 loss: -2.717026710510254
Batch 20/64 loss: -2.7585840225219727
Batch 21/64 loss: -2.0180625915527344
Batch 22/64 loss: -2.7388086318969727
Batch 23/64 loss: -2.6415958404541016
Batch 24/64 loss: -2.3040027618408203
Batch 25/64 loss: -2.393153190612793
Batch 26/64 loss: -2.256686210632324
Batch 27/64 loss: -2.858804702758789
Batch 28/64 loss: -2.539313316345215
Batch 29/64 loss: -2.8387575149536133
Batch 30/64 loss: -2.5023136138916016
Batch 31/64 loss: -2.612028121948242
Batch 32/64 loss: -2.841938018798828
Batch 33/64 loss: -2.231398582458496
Batch 34/64 loss: -2.781308174133301
Batch 35/64 loss: -2.3143081665039062
Batch 36/64 loss: -2.543765068054199
Batch 37/64 loss: -2.572406768798828
Batch 38/64 loss: -2.6715221405029297
Batch 39/64 loss: -2.4410781860351562
Batch 40/64 loss: -2.3000335693359375
Batch 41/64 loss: -1.964125633239746
Batch 42/64 loss: -2.3759326934814453
Batch 43/64 loss: -2.4098281860351562
Batch 44/64 loss: -2.200913429260254
Batch 45/64 loss: -2.536531448364258
Batch 46/64 loss: -2.7259769439697266
Batch 47/64 loss: -2.509061813354492
Batch 48/64 loss: -2.2358951568603516
Batch 49/64 loss: -2.575042724609375
Batch 50/64 loss: -2.693221092224121
Batch 51/64 loss: -2.7431812286376953
Batch 52/64 loss: -2.669628143310547
Batch 53/64 loss: -2.587108612060547
Batch 54/64 loss: -2.557803153991699
Batch 55/64 loss: -2.5992650985717773
Batch 56/64 loss: -2.738600730895996
Batch 57/64 loss: -2.7164220809936523
Batch 58/64 loss: -2.9763002395629883
Batch 59/64 loss: -2.986708641052246
Batch 60/64 loss: -2.6489572525024414
Batch 61/64 loss: -2.8680238723754883
Batch 62/64 loss: -2.854609489440918
Batch 63/64 loss: -2.3396902084350586
Batch 64/64 loss: -7.1525678634643555
Epoch 380  Train loss: -2.6202943727081895  Val loss: -2.879623085362805
Epoch 381
-------------------------------
Batch 1/64 loss: -2.451626777648926
Batch 2/64 loss: -2.7496118545532227
Batch 3/64 loss: -2.559576988220215
Batch 4/64 loss: -2.760984420776367
Batch 5/64 loss: -2.541440963745117
Batch 6/64 loss: -2.8730392456054688
Batch 7/64 loss: -2.7636337280273438
Batch 8/64 loss: -2.200005531311035
Batch 9/64 loss: -2.893195152282715
Batch 10/64 loss: -2.6552085876464844
Batch 11/64 loss: -2.3121795654296875
Batch 12/64 loss: -2.684628486633301
Batch 13/64 loss: -2.8563528060913086
Batch 14/64 loss: -2.66732120513916
Batch 15/64 loss: -2.7898740768432617
Batch 16/64 loss: -2.852384567260742
Batch 17/64 loss: -2.500947952270508
Batch 18/64 loss: -2.6337976455688477
Batch 19/64 loss: -2.7660341262817383
Batch 20/64 loss: -2.754589080810547
Batch 21/64 loss: -2.467890739440918
Batch 22/64 loss: -2.6883974075317383
Batch 23/64 loss: -2.769317626953125
Batch 24/64 loss: -2.899639129638672
Batch 25/64 loss: -2.8610219955444336
Batch 26/64 loss: -2.6565284729003906
Batch 27/64 loss: -2.507706642150879
Batch 28/64 loss: -2.6394786834716797
Batch 29/64 loss: -2.999462127685547
Batch 30/64 loss: -3.0015506744384766
Batch 31/64 loss: -2.6807546615600586
Batch 32/64 loss: -2.801481246948242
Batch 33/64 loss: -2.7535009384155273
Batch 34/64 loss: -2.732630729675293
Batch 35/64 loss: -1.5521106719970703
Batch 36/64 loss: -2.8419971466064453
Batch 37/64 loss: -2.7507476806640625
Batch 38/64 loss: -2.5428237915039062
Batch 39/64 loss: -2.8850412368774414
Batch 40/64 loss: -2.7674875259399414
Batch 41/64 loss: -2.850653648376465
Batch 42/64 loss: -2.781209945678711
Batch 43/64 loss: -2.642333984375
Batch 44/64 loss: -2.744466781616211
Batch 45/64 loss: -2.6759376525878906
Batch 46/64 loss: -2.6677656173706055
Batch 47/64 loss: -2.565786361694336
Batch 48/64 loss: -2.670358657836914
Batch 49/64 loss: -2.60845947265625
Batch 50/64 loss: -2.6981773376464844
Batch 51/64 loss: -2.703007698059082
Batch 52/64 loss: -2.661942481994629
Batch 53/64 loss: -2.6226253509521484
Batch 54/64 loss: -2.814517021179199
Batch 55/64 loss: -2.7408437728881836
Batch 56/64 loss: -2.1292734146118164
Batch 57/64 loss: -2.799405097961426
Batch 58/64 loss: -2.2910823822021484
Batch 59/64 loss: -2.7468347549438477
Batch 60/64 loss: -2.7785377502441406
Batch 61/64 loss: -2.7005090713500977
Batch 62/64 loss: -2.5070924758911133
Batch 63/64 loss: -2.5984411239624023
Batch 64/64 loss: -7.022459506988525
Epoch 381  Train loss: -2.718935033386829  Val loss: -3.046970170797761
Epoch 382
-------------------------------
Batch 1/64 loss: -2.765915870666504
Batch 2/64 loss: -2.5914125442504883
Batch 3/64 loss: -2.659189224243164
Batch 4/64 loss: -2.522660255432129
Batch 5/64 loss: -1.895340919494629
Batch 6/64 loss: -2.7397518157958984
Batch 7/64 loss: -2.5102758407592773
Batch 8/64 loss: -2.739813804626465
Batch 9/64 loss: -2.6060571670532227
Batch 10/64 loss: -2.634467124938965
Batch 11/64 loss: -2.8145742416381836
Batch 12/64 loss: -2.6833267211914062
Batch 13/64 loss: -2.576374053955078
Batch 14/64 loss: -2.584228515625
Batch 15/64 loss: -2.584933280944824
Batch 16/64 loss: -2.6038293838500977
Batch 17/64 loss: -2.399216651916504
Batch 18/64 loss: -2.7854537963867188
Batch 19/64 loss: -2.901148796081543
Batch 20/64 loss: -2.773540496826172
Batch 21/64 loss: -2.761564254760742
Batch 22/64 loss: -2.6752099990844727
Batch 23/64 loss: -2.773442268371582
Batch 24/64 loss: -2.8259716033935547
Batch 25/64 loss: -2.633953094482422
Batch 26/64 loss: -2.671663284301758
Batch 27/64 loss: -2.5823259353637695
Batch 28/64 loss: -2.831315040588379
Batch 29/64 loss: -2.7776870727539062
Batch 30/64 loss: -2.796229362487793
Batch 31/64 loss: -2.7928600311279297
Batch 32/64 loss: -2.271455764770508
Batch 33/64 loss: -2.6011037826538086
Batch 34/64 loss: -2.581907272338867
Batch 35/64 loss: -2.1160802841186523
Batch 36/64 loss: -2.5025339126586914
Batch 37/64 loss: -2.572193145751953
Batch 38/64 loss: -2.6612167358398438
Batch 39/64 loss: -2.8905029296875
Batch 40/64 loss: -2.5875558853149414
Batch 41/64 loss: -2.74993896484375
Batch 42/64 loss: -2.6409854888916016
Batch 43/64 loss: -2.847696304321289
Batch 44/64 loss: -2.9016313552856445
Batch 45/64 loss: -2.583888053894043
Batch 46/64 loss: -2.7191944122314453
Batch 47/64 loss: -2.7170095443725586
Batch 48/64 loss: -2.85054874420166
Batch 49/64 loss: -2.6850662231445312
Batch 50/64 loss: -2.7102413177490234
Batch 51/64 loss: -2.670048713684082
Batch 52/64 loss: -2.751523971557617
Batch 53/64 loss: -2.590632438659668
Batch 54/64 loss: -2.446613311767578
Batch 55/64 loss: -2.8867712020874023
Batch 56/64 loss: -2.98581600189209
Batch 57/64 loss: -2.914271354675293
Batch 58/64 loss: -2.7188167572021484
Batch 59/64 loss: -2.843583106994629
Batch 60/64 loss: -2.6759214401245117
Batch 61/64 loss: -2.259431838989258
Batch 62/64 loss: -2.6671676635742188
Batch 63/64 loss: -2.7791013717651367
Batch 64/64 loss: -7.34694766998291
Epoch 382  Train loss: -2.7197551764693917  Val loss: -3.080769882988684
Epoch 383
-------------------------------
Batch 1/64 loss: -2.8392763137817383
Batch 2/64 loss: -2.68780517578125
Batch 3/64 loss: -2.6883316040039062
Batch 4/64 loss: -2.556788444519043
Batch 5/64 loss: -2.6813831329345703
Batch 6/64 loss: -2.1949949264526367
Batch 7/64 loss: -2.736964225769043
Batch 8/64 loss: -2.7269182205200195
Batch 9/64 loss: -2.8356637954711914
Batch 10/64 loss: -2.5741653442382812
Batch 11/64 loss: -2.816770553588867
Batch 12/64 loss: -2.988037109375
Batch 13/64 loss: -2.6129398345947266
Batch 14/64 loss: -2.7905969619750977
Batch 15/64 loss: -2.6077919006347656
Batch 16/64 loss: -2.7181148529052734
Batch 17/64 loss: -2.8212289810180664
Batch 18/64 loss: -2.9552459716796875
Batch 19/64 loss: -2.937973976135254
Batch 20/64 loss: -2.774545669555664
Batch 21/64 loss: -2.6750755310058594
Batch 22/64 loss: -2.5519638061523438
Batch 23/64 loss: -2.971646308898926
Batch 24/64 loss: -2.6153297424316406
Batch 25/64 loss: -2.3953781127929688
Batch 26/64 loss: -2.76629638671875
Batch 27/64 loss: -2.525144577026367
Batch 28/64 loss: -2.497441291809082
Batch 29/64 loss: -2.949063301086426
Batch 30/64 loss: -2.8824195861816406
Batch 31/64 loss: -2.7166213989257812
Batch 32/64 loss: -2.5944957733154297
Batch 33/64 loss: -2.842538833618164
Batch 34/64 loss: -2.8859195709228516
Batch 35/64 loss: -2.913461685180664
Batch 36/64 loss: -2.061460494995117
Batch 37/64 loss: -2.872983932495117
Batch 38/64 loss: -2.9123659133911133
Batch 39/64 loss: -2.967526435852051
Batch 40/64 loss: -2.7618932723999023
Batch 41/64 loss: -2.6491317749023438
Batch 42/64 loss: -2.846888542175293
Batch 43/64 loss: -2.899685859680176
Batch 44/64 loss: -2.929013252258301
Batch 45/64 loss: -2.947279930114746
Batch 46/64 loss: -2.791172981262207
Batch 47/64 loss: -2.660768508911133
Batch 48/64 loss: -2.6806716918945312
Batch 49/64 loss: -2.96024227142334
Batch 50/64 loss: -2.852588653564453
Batch 51/64 loss: -2.574252128601074
Batch 52/64 loss: -2.862367630004883
Batch 53/64 loss: -2.7363786697387695
Batch 54/64 loss: -2.7739152908325195
Batch 55/64 loss: -1.966263771057129
Batch 56/64 loss: -2.7208337783813477
Batch 57/64 loss: -2.8115100860595703
Batch 58/64 loss: -2.9051151275634766
Batch 59/64 loss: -2.601133346557617
Batch 60/64 loss: -2.5073604583740234
Batch 61/64 loss: -2.8298816680908203
Batch 62/64 loss: -2.9933290481567383
Batch 63/64 loss: -2.7623729705810547
Batch 64/64 loss: -7.33649206161499
Epoch 383  Train loss: -2.7869661088083304  Val loss: -3.0729362907278577
Epoch 384
-------------------------------
Batch 1/64 loss: -3.0636072158813477
Batch 2/64 loss: -2.571887969970703
Batch 3/64 loss: -2.606595993041992
Batch 4/64 loss: -2.7634754180908203
Batch 5/64 loss: -2.7364301681518555
Batch 6/64 loss: -2.6465578079223633
Batch 7/64 loss: -2.8041858673095703
Batch 8/64 loss: -2.764242172241211
Batch 9/64 loss: -2.791879653930664
Batch 10/64 loss: -2.9254226684570312
Batch 11/64 loss: -2.8510847091674805
Batch 12/64 loss: -2.6787729263305664
Batch 13/64 loss: -2.9898033142089844
Batch 14/64 loss: -2.746689796447754
Batch 15/64 loss: -2.8670711517333984
Batch 16/64 loss: -2.663686752319336
Batch 17/64 loss: -2.372035026550293
Batch 18/64 loss: -2.8131532669067383
Batch 19/64 loss: -2.9715499877929688
Batch 20/64 loss: -2.4585256576538086
Batch 21/64 loss: -2.8866939544677734
Batch 22/64 loss: -2.8260498046875
Batch 23/64 loss: -2.733424186706543
Batch 24/64 loss: -2.798370361328125
Batch 25/64 loss: -2.9386491775512695
Batch 26/64 loss: -2.9635210037231445
Batch 27/64 loss: -2.8277673721313477
Batch 28/64 loss: -2.9112892150878906
Batch 29/64 loss: -2.90140438079834
Batch 30/64 loss: -2.619204521179199
Batch 31/64 loss: -2.8978967666625977
Batch 32/64 loss: -2.7347412109375
Batch 33/64 loss: -2.6441268920898438
Batch 34/64 loss: -2.9871931076049805
Batch 35/64 loss: -2.7857236862182617
Batch 36/64 loss: -2.7104272842407227
Batch 37/64 loss: -2.655980110168457
Batch 38/64 loss: -2.6818017959594727
Batch 39/64 loss: -2.8775930404663086
Batch 40/64 loss: -2.5759668350219727
Batch 41/64 loss: -2.2857742309570312
Batch 42/64 loss: -2.8178234100341797
Batch 43/64 loss: -2.8763198852539062
Batch 44/64 loss: -2.232208251953125
Batch 45/64 loss: -2.712167739868164
Batch 46/64 loss: -2.590865135192871
Batch 47/64 loss: -2.584469795227051
Batch 48/64 loss: -2.7037830352783203
Batch 49/64 loss: -2.8549623489379883
Batch 50/64 loss: -2.73797607421875
Batch 51/64 loss: -2.7512645721435547
Batch 52/64 loss: -2.7525014877319336
Batch 53/64 loss: -2.8273544311523438
Batch 54/64 loss: -2.816287040710449
Batch 55/64 loss: -2.4829254150390625
Batch 56/64 loss: -2.9669923782348633
Batch 57/64 loss: -2.865963935852051
Batch 58/64 loss: -2.5426206588745117
Batch 59/64 loss: -2.648334503173828
Batch 60/64 loss: -2.4490318298339844
Batch 61/64 loss: -2.863933563232422
Batch 62/64 loss: -2.797055244445801
Batch 63/64 loss: -2.660464286804199
Batch 64/64 loss: -6.451749801635742
Epoch 384  Train loss: -2.7875195895924287  Val loss: -3.1063927457095013
Epoch 385
-------------------------------
Batch 1/64 loss: -2.7623863220214844
Batch 2/64 loss: -2.613727569580078
Batch 3/64 loss: -2.743769645690918
Batch 4/64 loss: -2.817258834838867
Batch 5/64 loss: -2.7136898040771484
Batch 6/64 loss: -2.8245344161987305
Batch 7/64 loss: -2.9938230514526367
Batch 8/64 loss: -2.549130439758301
Batch 9/64 loss: -2.8358707427978516
Batch 10/64 loss: -2.54068660736084
Batch 11/64 loss: -2.9962759017944336
Batch 12/64 loss: -2.8176279067993164
Batch 13/64 loss: -2.7666187286376953
Batch 14/64 loss: -2.6457128524780273
Batch 15/64 loss: -2.671602249145508
Batch 16/64 loss: -2.1609067916870117
Batch 17/64 loss: -2.6998167037963867
Batch 18/64 loss: -2.9724578857421875
Batch 19/64 loss: -2.8926963806152344
Batch 20/64 loss: -2.6242570877075195
Batch 21/64 loss: -2.7420272827148438
Batch 22/64 loss: -2.632401466369629
Batch 23/64 loss: -2.87371826171875
Batch 24/64 loss: -2.926443099975586
Batch 25/64 loss: -2.8104944229125977
Batch 26/64 loss: -2.9579973220825195
Batch 27/64 loss: -2.710622787475586
Batch 28/64 loss: -2.8603639602661133
Batch 29/64 loss: -2.804572105407715
Batch 30/64 loss: -2.836562156677246
Batch 31/64 loss: -2.6130008697509766
Batch 32/64 loss: -2.6989078521728516
Batch 33/64 loss: -2.8602495193481445
Batch 34/64 loss: -2.9053831100463867
Batch 35/64 loss: -2.7795543670654297
Batch 36/64 loss: -2.6096181869506836
Batch 37/64 loss: -2.7129974365234375
Batch 38/64 loss: -2.7224111557006836
Batch 39/64 loss: -2.808558464050293
Batch 40/64 loss: -2.4281864166259766
Batch 41/64 loss: -2.6362390518188477
Batch 42/64 loss: -2.955193519592285
Batch 43/64 loss: -2.886869430541992
Batch 44/64 loss: -2.8350086212158203
Batch 45/64 loss: -2.457547187805176
Batch 46/64 loss: -2.9123382568359375
Batch 47/64 loss: -2.4061269760131836
Batch 48/64 loss: -2.926609992980957
Batch 49/64 loss: -2.3019981384277344
Batch 50/64 loss: -2.9997386932373047
Batch 51/64 loss: -2.696352958679199
Batch 52/64 loss: -2.687352180480957
Batch 53/64 loss: -2.6502037048339844
Batch 54/64 loss: -2.893411636352539
Batch 55/64 loss: -2.7998523712158203
Batch 56/64 loss: -2.431488037109375
Batch 57/64 loss: -2.5757036209106445
Batch 58/64 loss: -2.9289722442626953
Batch 59/64 loss: -2.620438575744629
Batch 60/64 loss: -2.3379783630371094
Batch 61/64 loss: -2.8172435760498047
Batch 62/64 loss: -2.9349308013916016
Batch 63/64 loss: -2.4075756072998047
Batch 64/64 loss: -7.245403289794922
Epoch 385  Train loss: -2.7838454302619486  Val loss: -3.0654674149870464
Epoch 386
-------------------------------
Batch 1/64 loss: -2.6803388595581055
Batch 2/64 loss: -2.8294734954833984
Batch 3/64 loss: -2.776937484741211
Batch 4/64 loss: -2.5284271240234375
Batch 5/64 loss: -2.805032730102539
Batch 6/64 loss: -2.797417640686035
Batch 7/64 loss: -2.7989273071289062
Batch 8/64 loss: -2.4489660263061523
Batch 9/64 loss: -2.769895553588867
Batch 10/64 loss: -2.698786735534668
Batch 11/64 loss: -2.5612754821777344
Batch 12/64 loss: -2.6895809173583984
Batch 13/64 loss: -2.538456916809082
Batch 14/64 loss: -2.825625419616699
Batch 15/64 loss: -2.6934614181518555
Batch 16/64 loss: -2.9439926147460938
Batch 17/64 loss: -2.8659448623657227
Batch 18/64 loss: -1.9733448028564453
Batch 19/64 loss: -2.84857177734375
Batch 20/64 loss: -2.9684181213378906
Batch 21/64 loss: -2.904886245727539
Batch 22/64 loss: -2.8036022186279297
Batch 23/64 loss: -2.750354766845703
Batch 24/64 loss: -1.9920063018798828
Batch 25/64 loss: -2.7522239685058594
Batch 26/64 loss: -2.764974594116211
Batch 27/64 loss: -2.6151227951049805
Batch 28/64 loss: -2.4582443237304688
Batch 29/64 loss: -2.7059202194213867
Batch 30/64 loss: -2.738279342651367
Batch 31/64 loss: -2.3303089141845703
Batch 32/64 loss: -2.7861576080322266
Batch 33/64 loss: -2.5908031463623047
Batch 34/64 loss: -2.4168806076049805
Batch 35/64 loss: -2.8116302490234375
Batch 36/64 loss: -2.5467958450317383
Batch 37/64 loss: -2.8066625595092773
Batch 38/64 loss: -2.374401092529297
Batch 39/64 loss: -1.9951543807983398
Batch 40/64 loss: -2.5988168716430664
Batch 41/64 loss: -2.7957963943481445
Batch 42/64 loss: -2.7028675079345703
Batch 43/64 loss: -2.936441421508789
Batch 44/64 loss: -2.561992645263672
Batch 45/64 loss: -2.939413070678711
Batch 46/64 loss: -2.9241724014282227
Batch 47/64 loss: -2.73870849609375
Batch 48/64 loss: -2.684659957885742
Batch 49/64 loss: -2.983035087585449
Batch 50/64 loss: -2.7783937454223633
Batch 51/64 loss: -2.8274621963500977
Batch 52/64 loss: -2.9017505645751953
Batch 53/64 loss: -2.4611692428588867
Batch 54/64 loss: -2.718451499938965
Batch 55/64 loss: -2.5853099822998047
Batch 56/64 loss: -2.677305221557617
Batch 57/64 loss: -2.102524757385254
Batch 58/64 loss: -2.9514083862304688
Batch 59/64 loss: -2.908000946044922
Batch 60/64 loss: -2.6132335662841797
Batch 61/64 loss: -2.7096309661865234
Batch 62/64 loss: -2.5317068099975586
Batch 63/64 loss: -2.8375492095947266
Batch 64/64 loss: -7.045851707458496
Epoch 386  Train loss: -2.7284937129301183  Val loss: -3.081888939506819
Epoch 387
-------------------------------
Batch 1/64 loss: -2.9812498092651367
Batch 2/64 loss: -2.6285972595214844
Batch 3/64 loss: -2.747762680053711
Batch 4/64 loss: -2.689419746398926
Batch 5/64 loss: -2.6101503372192383
Batch 6/64 loss: -2.944070816040039
Batch 7/64 loss: -2.8411426544189453
Batch 8/64 loss: -2.653611183166504
Batch 9/64 loss: -2.7579479217529297
Batch 10/64 loss: -2.8810815811157227
Batch 11/64 loss: -2.6310853958129883
Batch 12/64 loss: -3.0056467056274414
Batch 13/64 loss: -2.8757877349853516
Batch 14/64 loss: -2.4844741821289062
Batch 15/64 loss: -3.0131988525390625
Batch 16/64 loss: -2.880960464477539
Batch 17/64 loss: -2.3634872436523438
Batch 18/64 loss: -2.6144332885742188
Batch 19/64 loss: -2.668498992919922
Batch 20/64 loss: -2.1202163696289062
Batch 21/64 loss: -2.8271522521972656
Batch 22/64 loss: -2.859463691711426
Batch 23/64 loss: -2.6013431549072266
Batch 24/64 loss: -2.8818092346191406
Batch 25/64 loss: -2.6506471633911133
Batch 26/64 loss: -2.894038200378418
Batch 27/64 loss: -2.850724220275879
Batch 28/64 loss: -2.8071327209472656
Batch 29/64 loss: -1.9355754852294922
Batch 30/64 loss: -2.8190555572509766
Batch 31/64 loss: -2.0010881423950195
Batch 32/64 loss: -2.9414100646972656
Batch 33/64 loss: -2.655240058898926
Batch 34/64 loss: -2.8381500244140625
Batch 35/64 loss: -2.7675628662109375
Batch 36/64 loss: -2.4110422134399414
Batch 37/64 loss: -2.839053153991699
Batch 38/64 loss: -2.91943359375
Batch 39/64 loss: -2.8404159545898438
Batch 40/64 loss: -2.5696001052856445
Batch 41/64 loss: -2.723033905029297
Batch 42/64 loss: -2.9045629501342773
Batch 43/64 loss: -2.7839221954345703
Batch 44/64 loss: -2.858644485473633
Batch 45/64 loss: -2.6982831954956055
Batch 46/64 loss: -2.4202280044555664
Batch 47/64 loss: -2.5330991744995117
Batch 48/64 loss: -1.9700870513916016
Batch 49/64 loss: -2.7013607025146484
Batch 50/64 loss: -2.844816207885742
Batch 51/64 loss: -2.920186996459961
Batch 52/64 loss: -2.55983829498291
Batch 53/64 loss: -2.4952993392944336
Batch 54/64 loss: -2.648500442504883
Batch 55/64 loss: -2.8227500915527344
Batch 56/64 loss: -2.6460142135620117
Batch 57/64 loss: -2.603714942932129
Batch 58/64 loss: -2.8597049713134766
Batch 59/64 loss: -2.894852638244629
Batch 60/64 loss: -2.6426429748535156
Batch 61/64 loss: -2.6443939208984375
Batch 62/64 loss: -2.8775711059570312
Batch 63/64 loss: -2.4622201919555664
Batch 64/64 loss: -5.995871543884277
Epoch 387  Train loss: -2.7343591016881605  Val loss: -3.009871964602126
Epoch 388
-------------------------------
Batch 1/64 loss: -2.601820945739746
Batch 2/64 loss: -1.8617467880249023
Batch 3/64 loss: -2.5244646072387695
Batch 4/64 loss: -2.530061721801758
Batch 5/64 loss: -2.786832809448242
Batch 6/64 loss: -2.8374032974243164
Batch 7/64 loss: -2.8837413787841797
Batch 8/64 loss: -2.5033998489379883
Batch 9/64 loss: -2.7112245559692383
Batch 10/64 loss: -2.833568572998047
Batch 11/64 loss: -2.802363395690918
Batch 12/64 loss: -2.53354549407959
Batch 13/64 loss: -2.501352310180664
Batch 14/64 loss: -2.4892778396606445
Batch 15/64 loss: -2.420015335083008
Batch 16/64 loss: -2.655834197998047
Batch 17/64 loss: -2.5222206115722656
Batch 18/64 loss: -2.746487617492676
Batch 19/64 loss: -2.673720359802246
Batch 20/64 loss: -2.7252674102783203
Batch 21/64 loss: -2.854586601257324
Batch 22/64 loss: -2.8902111053466797
Batch 23/64 loss: -2.816375732421875
Batch 24/64 loss: -2.802273750305176
Batch 25/64 loss: -2.7769975662231445
Batch 26/64 loss: -2.6011409759521484
Batch 27/64 loss: -2.7905750274658203
Batch 28/64 loss: -2.8832082748413086
Batch 29/64 loss: -2.7413196563720703
Batch 30/64 loss: -2.625105857849121
Batch 31/64 loss: -2.9203901290893555
Batch 32/64 loss: -2.608365058898926
Batch 33/64 loss: -2.2694473266601562
Batch 34/64 loss: -2.6587600708007812
Batch 35/64 loss: -2.8312549591064453
Batch 36/64 loss: -2.611581802368164
Batch 37/64 loss: -2.6857099533081055
Batch 38/64 loss: -2.9478044509887695
Batch 39/64 loss: -2.60476016998291
Batch 40/64 loss: -2.590277671813965
Batch 41/64 loss: -2.5975704193115234
Batch 42/64 loss: -2.4397830963134766
Batch 43/64 loss: -2.7225112915039062
Batch 44/64 loss: -2.932431221008301
Batch 45/64 loss: -2.4480323791503906
Batch 46/64 loss: -2.8376855850219727
Batch 47/64 loss: -2.8114356994628906
Batch 48/64 loss: -2.637387275695801
Batch 49/64 loss: -2.7631893157958984
Batch 50/64 loss: -2.8845319747924805
Batch 51/64 loss: -2.7274551391601562
Batch 52/64 loss: -2.6658945083618164
Batch 53/64 loss: -2.7074594497680664
Batch 54/64 loss: -2.6924705505371094
Batch 55/64 loss: -2.6833152770996094
Batch 56/64 loss: -2.7611207962036133
Batch 57/64 loss: -2.8098535537719727
Batch 58/64 loss: -2.4356307983398438
Batch 59/64 loss: -2.8099422454833984
Batch 60/64 loss: -2.3453359603881836
Batch 61/64 loss: -2.896303176879883
Batch 62/64 loss: -2.622227668762207
Batch 63/64 loss: -2.771977424621582
Batch 64/64 loss: -7.094976425170898
Epoch 388  Train loss: -2.7290866253422754  Val loss: -3.0849432273419044
Epoch 389
-------------------------------
Batch 1/64 loss: -2.769319534301758
Batch 2/64 loss: -3.0200767517089844
Batch 3/64 loss: -2.8964662551879883
Batch 4/64 loss: -2.7681732177734375
Batch 5/64 loss: -2.7023115158081055
Batch 6/64 loss: -2.6679458618164062
Batch 7/64 loss: -2.8847551345825195
Batch 8/64 loss: -2.717296600341797
Batch 9/64 loss: -2.764751434326172
Batch 10/64 loss: -2.7537527084350586
Batch 11/64 loss: -2.845463752746582
Batch 12/64 loss: -2.7221288681030273
Batch 13/64 loss: -2.7034616470336914
Batch 14/64 loss: -2.7434072494506836
Batch 15/64 loss: -2.7265548706054688
Batch 16/64 loss: -1.9047975540161133
Batch 17/64 loss: -2.7943649291992188
Batch 18/64 loss: -2.615229606628418
Batch 19/64 loss: -2.409365653991699
Batch 20/64 loss: -2.645193099975586
Batch 21/64 loss: -2.7859058380126953
Batch 22/64 loss: -2.8549251556396484
Batch 23/64 loss: -2.7076187133789062
Batch 24/64 loss: -2.6359167098999023
Batch 25/64 loss: -2.4928903579711914
Batch 26/64 loss: -2.965574264526367
Batch 27/64 loss: -2.5336666107177734
Batch 28/64 loss: -2.7897119522094727
Batch 29/64 loss: -2.392247200012207
Batch 30/64 loss: -2.6405563354492188
Batch 31/64 loss: -2.806612968444824
Batch 32/64 loss: -2.498628616333008
Batch 33/64 loss: -2.812244415283203
Batch 34/64 loss: -2.760335922241211
Batch 35/64 loss: -2.6538753509521484
Batch 36/64 loss: -2.653445243835449
Batch 37/64 loss: -2.811587333679199
Batch 38/64 loss: -2.840388298034668
Batch 39/64 loss: -2.588499069213867
Batch 40/64 loss: -1.997004508972168
Batch 41/64 loss: -2.746623992919922
Batch 42/64 loss: -2.808487892150879
Batch 43/64 loss: -2.830946922302246
Batch 44/64 loss: -2.870896339416504
Batch 45/64 loss: -2.687729835510254
Batch 46/64 loss: -2.734617233276367
Batch 47/64 loss: -2.5847463607788086
Batch 48/64 loss: -2.8995590209960938
Batch 49/64 loss: -2.8795166015625
Batch 50/64 loss: -2.8746557235717773
Batch 51/64 loss: -2.6663951873779297
Batch 52/64 loss: -2.6477880477905273
Batch 53/64 loss: -2.1459169387817383
Batch 54/64 loss: -2.8274497985839844
Batch 55/64 loss: -2.788416862487793
Batch 56/64 loss: -2.524566650390625
Batch 57/64 loss: -2.6814823150634766
Batch 58/64 loss: -2.5652647018432617
Batch 59/64 loss: -2.629617691040039
Batch 60/64 loss: -2.8053131103515625
Batch 61/64 loss: -2.7908477783203125
Batch 62/64 loss: -2.891674041748047
Batch 63/64 loss: -2.6869869232177734
Batch 64/64 loss: -7.248656272888184
Epoch 389  Train loss: -2.749528522117465  Val loss: -2.856451762091253
Epoch 390
-------------------------------
Batch 1/64 loss: -2.736581802368164
Batch 2/64 loss: -2.586648941040039
Batch 3/64 loss: -2.853072166442871
Batch 4/64 loss: -2.7107744216918945
Batch 5/64 loss: -2.607232093811035
Batch 6/64 loss: -2.7835607528686523
Batch 7/64 loss: -2.468745231628418
Batch 8/64 loss: -2.786773681640625
Batch 9/64 loss: -2.608147621154785
Batch 10/64 loss: -2.7250890731811523
Batch 11/64 loss: -2.4219179153442383
Batch 12/64 loss: -2.7720088958740234
Batch 13/64 loss: -2.6844472885131836
Batch 14/64 loss: -2.71597957611084
Batch 15/64 loss: -2.442519187927246
Batch 16/64 loss: -2.7083654403686523
Batch 17/64 loss: -2.6499061584472656
Batch 18/64 loss: -2.889852523803711
Batch 19/64 loss: -2.6286516189575195
Batch 20/64 loss: -2.832063674926758
Batch 21/64 loss: -2.8824472427368164
Batch 22/64 loss: -2.56557559967041
Batch 23/64 loss: -2.8799314498901367
Batch 24/64 loss: -3.0017099380493164
Batch 25/64 loss: -2.261235237121582
Batch 26/64 loss: -2.6086416244506836
Batch 27/64 loss: -2.721461296081543
Batch 28/64 loss: -2.9514083862304688
Batch 29/64 loss: -2.7675132751464844
Batch 30/64 loss: -2.7185792922973633
Batch 31/64 loss: -2.64276123046875
Batch 32/64 loss: -2.5281972885131836
Batch 33/64 loss: -2.776089668273926
Batch 34/64 loss: -2.6251277923583984
Batch 35/64 loss: -2.6396217346191406
Batch 36/64 loss: -2.8763418197631836
Batch 37/64 loss: -2.761993408203125
Batch 38/64 loss: -2.89272403717041
Batch 39/64 loss: -2.7840452194213867
Batch 40/64 loss: -2.783184051513672
Batch 41/64 loss: -2.846501350402832
Batch 42/64 loss: -2.464564323425293
Batch 43/64 loss: -2.7511377334594727
Batch 44/64 loss: -2.213931083679199
Batch 45/64 loss: -2.799968719482422
Batch 46/64 loss: -2.63775634765625
Batch 47/64 loss: -2.7229738235473633
Batch 48/64 loss: -2.639333724975586
Batch 49/64 loss: -2.826932907104492
Batch 50/64 loss: -2.6667699813842773
Batch 51/64 loss: -2.4002561569213867
Batch 52/64 loss: -2.8093156814575195
Batch 53/64 loss: -2.5466222763061523
Batch 54/64 loss: -2.287386894226074
Batch 55/64 loss: -2.379073143005371
Batch 56/64 loss: -2.3679513931274414
Batch 57/64 loss: -2.101858139038086
Batch 58/64 loss: -2.526942253112793
Batch 59/64 loss: -2.7222557067871094
Batch 60/64 loss: -2.731241226196289
Batch 61/64 loss: -2.089763641357422
Batch 62/64 loss: -2.673297882080078
Batch 63/64 loss: -2.7262182235717773
Batch 64/64 loss: -7.34354305267334
Epoch 390  Train loss: -2.709343334272796  Val loss: -3.0450623633525624
Epoch 391
-------------------------------
Batch 1/64 loss: -2.6087799072265625
Batch 2/64 loss: -1.8712501525878906
Batch 3/64 loss: -2.852926254272461
Batch 4/64 loss: -2.8368911743164062
Batch 5/64 loss: -2.8252058029174805
Batch 6/64 loss: -2.5306339263916016
Batch 7/64 loss: -2.750178337097168
Batch 8/64 loss: -2.716458320617676
Batch 9/64 loss: -2.6179494857788086
Batch 10/64 loss: -2.639036178588867
Batch 11/64 loss: -2.813504219055176
Batch 12/64 loss: -2.778728485107422
Batch 13/64 loss: -2.0479736328125
Batch 14/64 loss: -2.7128849029541016
Batch 15/64 loss: -2.7989139556884766
Batch 16/64 loss: -2.7879581451416016
Batch 17/64 loss: -2.3481369018554688
Batch 18/64 loss: -2.372084617614746
Batch 19/64 loss: -2.774972915649414
Batch 20/64 loss: -2.8329238891601562
Batch 21/64 loss: -2.590968132019043
Batch 22/64 loss: -2.878800392150879
Batch 23/64 loss: -2.5782289505004883
Batch 24/64 loss: -2.777543067932129
Batch 25/64 loss: -2.7531890869140625
Batch 26/64 loss: -2.7036752700805664
Batch 27/64 loss: -2.8124961853027344
Batch 28/64 loss: -2.391111373901367
Batch 29/64 loss: -2.7334232330322266
Batch 30/64 loss: -2.6484203338623047
Batch 31/64 loss: -2.3732519149780273
Batch 32/64 loss: -2.76129150390625
Batch 33/64 loss: -2.757084846496582
Batch 34/64 loss: -2.5920515060424805
Batch 35/64 loss: -2.7613840103149414
Batch 36/64 loss: -2.5196352005004883
Batch 37/64 loss: -2.6959943771362305
Batch 38/64 loss: -2.5975351333618164
Batch 39/64 loss: -2.603656768798828
Batch 40/64 loss: -2.053058624267578
Batch 41/64 loss: -2.7976064682006836
Batch 42/64 loss: -2.5858640670776367
Batch 43/64 loss: -2.356353759765625
Batch 44/64 loss: -2.5783815383911133
Batch 45/64 loss: -2.744107246398926
Batch 46/64 loss: -2.8724584579467773
Batch 47/64 loss: -2.717428207397461
Batch 48/64 loss: -2.7135095596313477
Batch 49/64 loss: -2.826282501220703
Batch 50/64 loss: -2.933542251586914
Batch 51/64 loss: -2.7812633514404297
Batch 52/64 loss: -2.871511459350586
Batch 53/64 loss: -2.0370359420776367
Batch 54/64 loss: -2.9518251419067383
Batch 55/64 loss: -2.522580146789551
Batch 56/64 loss: -2.781205177307129
Batch 57/64 loss: -2.6042518615722656
Batch 58/64 loss: -2.706650733947754
Batch 59/64 loss: -2.592264175415039
Batch 60/64 loss: -2.7487430572509766
Batch 61/64 loss: -2.665390968322754
Batch 62/64 loss: -2.5961694717407227
Batch 63/64 loss: -2.7065858840942383
Batch 64/64 loss: -7.334317684173584
Epoch 391  Train loss: -2.702618679345823  Val loss: -3.0057846410167994
Epoch 392
-------------------------------
Batch 1/64 loss: -2.5369415283203125
Batch 2/64 loss: -2.867762565612793
Batch 3/64 loss: -2.9079647064208984
Batch 4/64 loss: -2.725855827331543
Batch 5/64 loss: -2.7171802520751953
Batch 6/64 loss: -2.8084373474121094
Batch 7/64 loss: -2.6348838806152344
Batch 8/64 loss: -2.61246395111084
Batch 9/64 loss: -2.6180028915405273
Batch 10/64 loss: -2.7719802856445312
Batch 11/64 loss: -2.9487037658691406
Batch 12/64 loss: -2.565789222717285
Batch 13/64 loss: -2.797244071960449
Batch 14/64 loss: -2.6557788848876953
Batch 15/64 loss: -2.5137710571289062
Batch 16/64 loss: -2.521939277648926
Batch 17/64 loss: -2.567049980163574
Batch 18/64 loss: -2.770284652709961
Batch 19/64 loss: -2.38803768157959
Batch 20/64 loss: -2.680525779724121
Batch 21/64 loss: -2.753997802734375
Batch 22/64 loss: -2.7277421951293945
Batch 23/64 loss: -2.1206398010253906
Batch 24/64 loss: -2.6777772903442383
Batch 25/64 loss: -2.06451416015625
Batch 26/64 loss: -2.769868850708008
Batch 27/64 loss: -2.5773324966430664
Batch 28/64 loss: -3.0413217544555664
Batch 29/64 loss: -2.8662939071655273
Batch 30/64 loss: -2.809520721435547
Batch 31/64 loss: -2.625269889831543
Batch 32/64 loss: -1.9766178131103516
Batch 33/64 loss: -2.506999969482422
Batch 34/64 loss: -2.8059892654418945
Batch 35/64 loss: -2.667835235595703
Batch 36/64 loss: -2.5051498413085938
Batch 37/64 loss: -2.758634567260742
Batch 38/64 loss: -2.863576889038086
Batch 39/64 loss: -2.7017993927001953
Batch 40/64 loss: -2.763805389404297
Batch 41/64 loss: -2.6286001205444336
Batch 42/64 loss: -2.6545448303222656
Batch 43/64 loss: -2.8341121673583984
Batch 44/64 loss: -2.5945281982421875
Batch 45/64 loss: -2.41561222076416
Batch 46/64 loss: -2.423227310180664
Batch 47/64 loss: -2.704094886779785
Batch 48/64 loss: -2.951070785522461
Batch 49/64 loss: -2.5760860443115234
Batch 50/64 loss: -2.816317558288574
Batch 51/64 loss: -2.7149314880371094
Batch 52/64 loss: -2.5566301345825195
Batch 53/64 loss: -2.720921516418457
Batch 54/64 loss: -2.6535911560058594
Batch 55/64 loss: -2.3202953338623047
Batch 56/64 loss: -2.4194936752319336
Batch 57/64 loss: -2.700967788696289
Batch 58/64 loss: -2.5560874938964844
Batch 59/64 loss: -2.518108367919922
Batch 60/64 loss: -2.7429676055908203
Batch 61/64 loss: -2.689091682434082
Batch 62/64 loss: -2.6865224838256836
Batch 63/64 loss: -2.6093883514404297
Batch 64/64 loss: -7.431209564208984
Epoch 392  Train loss: -2.7020530700683594  Val loss: -3.1012104598107615
Epoch 393
-------------------------------
Batch 1/64 loss: -2.740475654602051
Batch 2/64 loss: -2.596188545227051
Batch 3/64 loss: -2.7774181365966797
Batch 4/64 loss: -2.8308286666870117
Batch 5/64 loss: -2.583415985107422
Batch 6/64 loss: -2.805209159851074
Batch 7/64 loss: -2.857583999633789
Batch 8/64 loss: -2.5012474060058594
Batch 9/64 loss: -2.7149744033813477
Batch 10/64 loss: -2.955023765563965
Batch 11/64 loss: -2.8021488189697266
Batch 12/64 loss: -2.866854667663574
Batch 13/64 loss: -2.7071094512939453
Batch 14/64 loss: -2.742755889892578
Batch 15/64 loss: -2.852969169616699
Batch 16/64 loss: -2.7152299880981445
Batch 17/64 loss: -2.7980785369873047
Batch 18/64 loss: -2.637984275817871
Batch 19/64 loss: -3.035212516784668
Batch 20/64 loss: -2.96923828125
Batch 21/64 loss: -2.750187873840332
Batch 22/64 loss: -2.7976293563842773
Batch 23/64 loss: -2.8896522521972656
Batch 24/64 loss: -2.7134456634521484
Batch 25/64 loss: -2.7656774520874023
Batch 26/64 loss: -2.78131103515625
Batch 27/64 loss: -2.029303550720215
Batch 28/64 loss: -2.672959327697754
Batch 29/64 loss: -2.3408994674682617
Batch 30/64 loss: -2.839718818664551
Batch 31/64 loss: -2.5578126907348633
Batch 32/64 loss: -2.8694400787353516
Batch 33/64 loss: -2.8310842514038086
Batch 34/64 loss: -2.6026506423950195
Batch 35/64 loss: -2.767820358276367
Batch 36/64 loss: -2.7537155151367188
Batch 37/64 loss: -2.752007484436035
Batch 38/64 loss: -2.220630645751953
Batch 39/64 loss: -2.6848087310791016
Batch 40/64 loss: -2.8477659225463867
Batch 41/64 loss: -2.7058515548706055
Batch 42/64 loss: -2.9607925415039062
Batch 43/64 loss: -2.3794641494750977
Batch 44/64 loss: -2.630282402038574
Batch 45/64 loss: -2.484768867492676
Batch 46/64 loss: -2.8805551528930664
Batch 47/64 loss: -2.590855598449707
Batch 48/64 loss: -2.863492965698242
Batch 49/64 loss: -2.839797019958496
Batch 50/64 loss: -2.342700958251953
Batch 51/64 loss: -2.7669754028320312
Batch 52/64 loss: -2.8840255737304688
Batch 53/64 loss: -2.764364242553711
Batch 54/64 loss: -2.6418590545654297
Batch 55/64 loss: -2.740285873413086
Batch 56/64 loss: -2.890265464782715
Batch 57/64 loss: -2.5312957763671875
Batch 58/64 loss: -2.6210403442382812
Batch 59/64 loss: -2.5257463455200195
Batch 60/64 loss: -2.801924705505371
Batch 61/64 loss: -2.485372543334961
Batch 62/64 loss: -2.798358917236328
Batch 63/64 loss: -2.5728673934936523
Batch 64/64 loss: -7.222640514373779
Epoch 393  Train loss: -2.7620139869989133  Val loss: -3.103179420392538
Epoch 394
-------------------------------
Batch 1/64 loss: -2.8823652267456055
Batch 2/64 loss: -2.8410587310791016
Batch 3/64 loss: -2.7183189392089844
Batch 4/64 loss: -2.7621936798095703
Batch 5/64 loss: -2.7982349395751953
Batch 6/64 loss: -2.5735559463500977
Batch 7/64 loss: -2.846499443054199
Batch 8/64 loss: -2.8114614486694336
Batch 9/64 loss: -2.9014129638671875
Batch 10/64 loss: -2.723080635070801
Batch 11/64 loss: -2.621767044067383
Batch 12/64 loss: -2.9772214889526367
Batch 13/64 loss: -2.649092674255371
Batch 14/64 loss: -2.7940845489501953
Batch 15/64 loss: -2.7957029342651367
Batch 16/64 loss: -2.947978973388672
Batch 17/64 loss: -2.7432594299316406
Batch 18/64 loss: -2.6533212661743164
Batch 19/64 loss: -2.74749755859375
Batch 20/64 loss: -2.6691513061523438
Batch 21/64 loss: -2.783932685852051
Batch 22/64 loss: -2.720219612121582
Batch 23/64 loss: -2.7723922729492188
Batch 24/64 loss: -2.8504724502563477
Batch 25/64 loss: -2.8825464248657227
Batch 26/64 loss: -2.768747329711914
Batch 27/64 loss: -2.7499380111694336
Batch 28/64 loss: -2.9085187911987305
Batch 29/64 loss: -2.7649927139282227
Batch 30/64 loss: -2.247415542602539
Batch 31/64 loss: -2.8781280517578125
Batch 32/64 loss: -2.7019309997558594
Batch 33/64 loss: -2.8329830169677734
Batch 34/64 loss: -2.6210927963256836
Batch 35/64 loss: -2.837294578552246
Batch 36/64 loss: -2.4992876052856445
Batch 37/64 loss: -2.8229780197143555
Batch 38/64 loss: -2.7777328491210938
Batch 39/64 loss: -2.7009315490722656
Batch 40/64 loss: -2.1028127670288086
Batch 41/64 loss: -2.592165946960449
Batch 42/64 loss: -2.815032958984375
Batch 43/64 loss: -2.8236427307128906
Batch 44/64 loss: -2.8048877716064453
Batch 45/64 loss: -2.9418230056762695
Batch 46/64 loss: -2.92840576171875
Batch 47/64 loss: -2.7668771743774414
Batch 48/64 loss: -2.476365089416504
Batch 49/64 loss: -1.812483787536621
Batch 50/64 loss: -2.765604019165039
Batch 51/64 loss: -2.560129165649414
Batch 52/64 loss: -2.9198360443115234
Batch 53/64 loss: -2.654473304748535
Batch 54/64 loss: -2.7813053131103516
Batch 55/64 loss: -2.831378936767578
Batch 56/64 loss: -3.092447280883789
Batch 57/64 loss: -2.759291648864746
Batch 58/64 loss: -2.7004194259643555
Batch 59/64 loss: -2.7849817276000977
Batch 60/64 loss: -2.877425193786621
Batch 61/64 loss: -2.600583076477051
Batch 62/64 loss: -2.6421852111816406
Batch 63/64 loss: -2.8093748092651367
Batch 64/64 loss: -7.589482307434082
Epoch 394  Train loss: -2.7939582488116095  Val loss: -3.0423962307959487
Epoch 395
-------------------------------
Batch 1/64 loss: -2.777337074279785
Batch 2/64 loss: -1.989297866821289
Batch 3/64 loss: -2.7442493438720703
Batch 4/64 loss: -2.5953493118286133
Batch 5/64 loss: -2.789548873901367
Batch 6/64 loss: -2.5349369049072266
Batch 7/64 loss: -2.8541698455810547
Batch 8/64 loss: -2.912569046020508
Batch 9/64 loss: -2.9721555709838867
Batch 10/64 loss: -2.9665870666503906
Batch 11/64 loss: -2.7558536529541016
Batch 12/64 loss: -2.9313440322875977
Batch 13/64 loss: -2.5173120498657227
Batch 14/64 loss: -2.8222951889038086
Batch 15/64 loss: -2.792673110961914
Batch 16/64 loss: -2.7204694747924805
Batch 17/64 loss: -2.970871925354004
Batch 18/64 loss: -2.710367202758789
Batch 19/64 loss: -2.6527957916259766
Batch 20/64 loss: -2.813854217529297
Batch 21/64 loss: -2.7967281341552734
Batch 22/64 loss: -2.640291213989258
Batch 23/64 loss: -2.5455455780029297
Batch 24/64 loss: -2.7996349334716797
Batch 25/64 loss: -2.641831398010254
Batch 26/64 loss: -2.6023550033569336
Batch 27/64 loss: -2.2081832885742188
Batch 28/64 loss: -2.637345314025879
Batch 29/64 loss: -1.8397254943847656
Batch 30/64 loss: -2.6184682846069336
Batch 31/64 loss: -2.6605405807495117
Batch 32/64 loss: -2.855009078979492
Batch 33/64 loss: -2.75742244720459
Batch 34/64 loss: -2.813357353210449
Batch 35/64 loss: -2.6353330612182617
Batch 36/64 loss: -2.7562332153320312
Batch 37/64 loss: -2.8409881591796875
Batch 38/64 loss: -2.4736833572387695
Batch 39/64 loss: -2.6072072982788086
Batch 40/64 loss: -2.963912010192871
Batch 41/64 loss: -2.9182701110839844
Batch 42/64 loss: -2.2344608306884766
Batch 43/64 loss: -2.5860023498535156
Batch 44/64 loss: -2.9459686279296875
Batch 45/64 loss: -2.9030818939208984
Batch 46/64 loss: -2.298870086669922
Batch 47/64 loss: -2.810352325439453
Batch 48/64 loss: -3.002305030822754
Batch 49/64 loss: -2.8164796829223633
Batch 50/64 loss: -2.7520017623901367
Batch 51/64 loss: -2.685042381286621
Batch 52/64 loss: -2.4300451278686523
Batch 53/64 loss: -2.843780517578125
Batch 54/64 loss: -2.779378890991211
Batch 55/64 loss: -2.351381301879883
Batch 56/64 loss: -2.7896318435668945
Batch 57/64 loss: -2.716205596923828
Batch 58/64 loss: -2.8176441192626953
Batch 59/64 loss: -2.6861085891723633
Batch 60/64 loss: -2.6777849197387695
Batch 61/64 loss: -2.84694766998291
Batch 62/64 loss: -2.6155948638916016
Batch 63/64 loss: -2.8906021118164062
Batch 64/64 loss: -7.269923686981201
Epoch 395  Train loss: -2.7508739789326984  Val loss: -2.9452011527884046
Epoch 396
-------------------------------
Batch 1/64 loss: -2.6489343643188477
Batch 2/64 loss: -2.8050317764282227
Batch 3/64 loss: -2.649747848510742
Batch 4/64 loss: -2.7075929641723633
Batch 5/64 loss: -2.833925247192383
Batch 6/64 loss: -2.7666807174682617
Batch 7/64 loss: -2.828080177307129
Batch 8/64 loss: -2.7552595138549805
Batch 9/64 loss: -2.7867469787597656
Batch 10/64 loss: -2.4900283813476562
Batch 11/64 loss: -2.742814064025879
Batch 12/64 loss: -2.5194320678710938
Batch 13/64 loss: -2.688176155090332
Batch 14/64 loss: -2.6901159286499023
Batch 15/64 loss: -2.7037534713745117
Batch 16/64 loss: -2.21726131439209
Batch 17/64 loss: -2.356170654296875
Batch 18/64 loss: -2.5577392578125
Batch 19/64 loss: -2.7282209396362305
Batch 20/64 loss: -2.4876623153686523
Batch 21/64 loss: -2.6379661560058594
Batch 22/64 loss: -2.191908836364746
Batch 23/64 loss: -2.9090023040771484
Batch 24/64 loss: -2.8040056228637695
Batch 25/64 loss: -2.8288164138793945
Batch 26/64 loss: -2.773798942565918
Batch 27/64 loss: -2.4914512634277344
Batch 28/64 loss: -2.9081172943115234
Batch 29/64 loss: -2.7668094635009766
Batch 30/64 loss: -2.975245475769043
Batch 31/64 loss: -2.974431037902832
Batch 32/64 loss: -2.8217248916625977
Batch 33/64 loss: -2.562983512878418
Batch 34/64 loss: -2.604022979736328
Batch 35/64 loss: -2.878119468688965
Batch 36/64 loss: -1.718526840209961
Batch 37/64 loss: -2.947420120239258
Batch 38/64 loss: -2.887904167175293
Batch 39/64 loss: -2.950258255004883
Batch 40/64 loss: -2.8539581298828125
Batch 41/64 loss: -2.6044769287109375
Batch 42/64 loss: -2.8818979263305664
Batch 43/64 loss: -2.863555908203125
Batch 44/64 loss: -2.878337860107422
Batch 45/64 loss: -2.87160587310791
Batch 46/64 loss: -2.6733617782592773
Batch 47/64 loss: -2.82045841217041
Batch 48/64 loss: -2.760702133178711
Batch 49/64 loss: -2.889354705810547
Batch 50/64 loss: -2.6731061935424805
Batch 51/64 loss: -2.901858329772949
Batch 52/64 loss: -2.924077033996582
Batch 53/64 loss: -2.858572006225586
Batch 54/64 loss: -2.951777458190918
Batch 55/64 loss: -2.7824764251708984
Batch 56/64 loss: -2.7787961959838867
Batch 57/64 loss: -2.9008235931396484
Batch 58/64 loss: -2.6326894760131836
Batch 59/64 loss: -2.8854684829711914
Batch 60/64 loss: -2.3235397338867188
Batch 61/64 loss: -2.6732778549194336
Batch 62/64 loss: -2.834409713745117
Batch 63/64 loss: -2.8783998489379883
Batch 64/64 loss: -6.900214195251465
Epoch 396  Train loss: -2.774400467966117  Val loss: -3.1135584644435608
Epoch 397
-------------------------------
Batch 1/64 loss: -2.718869209289551
Batch 2/64 loss: -2.74025821685791
Batch 3/64 loss: -2.6451683044433594
Batch 4/64 loss: -2.8778858184814453
Batch 5/64 loss: -2.9271364212036133
Batch 6/64 loss: -2.932161331176758
Batch 7/64 loss: -2.835516929626465
Batch 8/64 loss: -2.803959846496582
Batch 9/64 loss: -2.771002769470215
Batch 10/64 loss: -2.469432830810547
Batch 11/64 loss: -2.5643062591552734
Batch 12/64 loss: -2.8132410049438477
Batch 13/64 loss: -2.578372001647949
Batch 14/64 loss: -2.3193883895874023
Batch 15/64 loss: -2.613471031188965
Batch 16/64 loss: -2.8766050338745117
Batch 17/64 loss: -2.864405632019043
Batch 18/64 loss: -2.8040294647216797
Batch 19/64 loss: -2.598170280456543
Batch 20/64 loss: -2.450425148010254
Batch 21/64 loss: -2.5490055084228516
Batch 22/64 loss: -2.813232421875
Batch 23/64 loss: -2.942671775817871
Batch 24/64 loss: -2.891047477722168
Batch 25/64 loss: -2.6881227493286133
Batch 26/64 loss: -2.789914131164551
Batch 27/64 loss: -2.472688674926758
Batch 28/64 loss: -2.8125619888305664
Batch 29/64 loss: -2.581523895263672
Batch 30/64 loss: -2.9636783599853516
Batch 31/64 loss: -2.791492462158203
Batch 32/64 loss: -2.7120018005371094
Batch 33/64 loss: -1.911829948425293
Batch 34/64 loss: -2.79036808013916
Batch 35/64 loss: -2.7238235473632812
Batch 36/64 loss: -2.6185827255249023
Batch 37/64 loss: -2.737407684326172
Batch 38/64 loss: -2.8391942977905273
Batch 39/64 loss: -2.6311492919921875
Batch 40/64 loss: -2.888852119445801
Batch 41/64 loss: -3.0076656341552734
Batch 42/64 loss: -2.7578277587890625
Batch 43/64 loss: -2.714531898498535
Batch 44/64 loss: -2.9129276275634766
Batch 45/64 loss: -2.8029747009277344
Batch 46/64 loss: -2.9144420623779297
Batch 47/64 loss: -1.7551460266113281
Batch 48/64 loss: -2.70552921295166
Batch 49/64 loss: -2.8515405654907227
Batch 50/64 loss: -2.849088668823242
Batch 51/64 loss: -2.7642860412597656
Batch 52/64 loss: -2.4927244186401367
Batch 53/64 loss: -2.52569580078125
Batch 54/64 loss: -2.8783435821533203
Batch 55/64 loss: -2.840972900390625
Batch 56/64 loss: -2.786956787109375
Batch 57/64 loss: -2.619701385498047
Batch 58/64 loss: -2.676851272583008
Batch 59/64 loss: -2.72763729095459
Batch 60/64 loss: -2.6029109954833984
Batch 61/64 loss: -2.810394287109375
Batch 62/64 loss: -2.8476743698120117
Batch 63/64 loss: -2.663722038269043
Batch 64/64 loss: -7.25595760345459
Epoch 397  Train loss: -2.765560288522758  Val loss: -3.023116252676318
Epoch 398
-------------------------------
Batch 1/64 loss: -2.906726837158203
Batch 2/64 loss: -2.7641782760620117
Batch 3/64 loss: -2.6279993057250977
Batch 4/64 loss: -2.732759475708008
Batch 5/64 loss: -2.877077102661133
Batch 6/64 loss: -2.764512062072754
Batch 7/64 loss: -2.9445409774780273
Batch 8/64 loss: -2.5345067977905273
Batch 9/64 loss: -2.677140235900879
Batch 10/64 loss: -2.712822914123535
Batch 11/64 loss: -2.672743797302246
Batch 12/64 loss: -2.333359718322754
Batch 13/64 loss: -2.6649351119995117
Batch 14/64 loss: -2.816958427429199
Batch 15/64 loss: -2.183065414428711
Batch 16/64 loss: -2.3223390579223633
Batch 17/64 loss: -2.6828670501708984
Batch 18/64 loss: -2.813591957092285
Batch 19/64 loss: -2.443020820617676
Batch 20/64 loss: -1.573287010192871
Batch 21/64 loss: -2.705324172973633
Batch 22/64 loss: -2.475679397583008
Batch 23/64 loss: -2.758188247680664
Batch 24/64 loss: -2.9221248626708984
Batch 25/64 loss: -2.5069875717163086
Batch 26/64 loss: -2.8323583602905273
Batch 27/64 loss: -2.7279176712036133
Batch 28/64 loss: -2.8149662017822266
Batch 29/64 loss: -2.7772817611694336
Batch 30/64 loss: -2.745328903198242
Batch 31/64 loss: -2.9314937591552734
Batch 32/64 loss: -2.965475082397461
Batch 33/64 loss: -2.897494316101074
Batch 34/64 loss: -2.863335609436035
Batch 35/64 loss: -2.897383689880371
Batch 36/64 loss: -2.2115697860717773
Batch 37/64 loss: -2.889850616455078
Batch 38/64 loss: -2.8649749755859375
Batch 39/64 loss: -2.8860912322998047
Batch 40/64 loss: -3.0266199111938477
Batch 41/64 loss: -2.8453540802001953
Batch 42/64 loss: -2.784722328186035
Batch 43/64 loss: -2.722217559814453
Batch 44/64 loss: -2.751199722290039
Batch 45/64 loss: -2.7026052474975586
Batch 46/64 loss: -2.8349685668945312
Batch 47/64 loss: -2.7461557388305664
Batch 48/64 loss: -3.0507612228393555
Batch 49/64 loss: -3.000025749206543
Batch 50/64 loss: -2.738459587097168
Batch 51/64 loss: -2.6180830001831055
Batch 52/64 loss: -2.9559106826782227
Batch 53/64 loss: -2.7809267044067383
Batch 54/64 loss: -2.6236953735351562
Batch 55/64 loss: -2.939138412475586
Batch 56/64 loss: -2.7760009765625
Batch 57/64 loss: -2.821117401123047
Batch 58/64 loss: -2.786893844604492
Batch 59/64 loss: -2.4079790115356445
Batch 60/64 loss: -2.6646194458007812
Batch 61/64 loss: -2.903066635131836
Batch 62/64 loss: -2.8194379806518555
Batch 63/64 loss: -2.765674591064453
Batch 64/64 loss: -7.182675361633301
Epoch 398  Train loss: -2.779214099809235  Val loss: -2.9797657707712495
Epoch 399
-------------------------------
Batch 1/64 loss: -2.9637908935546875
Batch 2/64 loss: -2.824099540710449
Batch 3/64 loss: -2.80318546295166
Batch 4/64 loss: -2.864975929260254
Batch 5/64 loss: -2.6347742080688477
Batch 6/64 loss: -2.8513031005859375
Batch 7/64 loss: -2.603102684020996
Batch 8/64 loss: -2.7791318893432617
Batch 9/64 loss: -2.891779899597168
Batch 10/64 loss: -2.5848770141601562
Batch 11/64 loss: -2.6549148559570312
Batch 12/64 loss: -2.9924182891845703
Batch 13/64 loss: -2.865445137023926
Batch 14/64 loss: -2.8625993728637695
Batch 15/64 loss: -2.846811294555664
Batch 16/64 loss: -2.6064939498901367
Batch 17/64 loss: -2.9065351486206055
Batch 18/64 loss: -2.7173290252685547
Batch 19/64 loss: -2.7016820907592773
Batch 20/64 loss: -2.5712385177612305
Batch 21/64 loss: -2.77573299407959
Batch 22/64 loss: -1.9402103424072266
Batch 23/64 loss: -2.5903244018554688
Batch 24/64 loss: -2.3918323516845703
Batch 25/64 loss: -2.385242462158203
Batch 26/64 loss: -2.6893768310546875
Batch 27/64 loss: -2.647383689880371
Batch 28/64 loss: -2.851175308227539
Batch 29/64 loss: -3.051177978515625
Batch 30/64 loss: -3.050929069519043
Batch 31/64 loss: -2.8207902908325195
Batch 32/64 loss: -2.693450927734375
Batch 33/64 loss: -2.9715633392333984
Batch 34/64 loss: -2.9990062713623047
Batch 35/64 loss: -2.592473030090332
Batch 36/64 loss: -2.8975934982299805
Batch 37/64 loss: -2.480982780456543
Batch 38/64 loss: -2.8052330017089844
Batch 39/64 loss: -2.783050537109375
Batch 40/64 loss: -2.857293128967285
Batch 41/64 loss: -2.8324546813964844
Batch 42/64 loss: -2.9008007049560547
Batch 43/64 loss: -2.9146270751953125
Batch 44/64 loss: -2.8096704483032227
Batch 45/64 loss: -2.5381345748901367
Batch 46/64 loss: -2.643948554992676
Batch 47/64 loss: -2.960695266723633
Batch 48/64 loss: -2.805562973022461
Batch 49/64 loss: -2.7922754287719727
Batch 50/64 loss: -2.906604766845703
Batch 51/64 loss: -2.7947235107421875
Batch 52/64 loss: -2.8656444549560547
Batch 53/64 loss: -2.6498308181762695
Batch 54/64 loss: -2.9117183685302734
Batch 55/64 loss: -2.859908103942871
Batch 56/64 loss: -2.8658294677734375
Batch 57/64 loss: -2.799086570739746
Batch 58/64 loss: -2.782076835632324
Batch 59/64 loss: -2.360550880432129
Batch 60/64 loss: -2.903397560119629
Batch 61/64 loss: -3.01619815826416
Batch 62/64 loss: -2.87398624420166
Batch 63/64 loss: -2.809634208679199
Batch 64/64 loss: -7.4322357177734375
Epoch 399  Train loss: -2.8231034821155023  Val loss: -3.2462521582534634
Saving best model, epoch: 399
Epoch 400
-------------------------------
Batch 1/64 loss: -2.8867673873901367
Batch 2/64 loss: -2.551198959350586
Batch 3/64 loss: -2.962491989135742
Batch 4/64 loss: -2.9467716217041016
Batch 5/64 loss: -2.9952783584594727
Batch 6/64 loss: -2.986056327819824
Batch 7/64 loss: -2.718184471130371
Batch 8/64 loss: -2.5386152267456055
Batch 9/64 loss: -2.936098098754883
Batch 10/64 loss: -2.7267112731933594
Batch 11/64 loss: -2.9733047485351562
Batch 12/64 loss: -2.874380111694336
Batch 13/64 loss: -3.026972770690918
Batch 14/64 loss: -2.9763078689575195
Batch 15/64 loss: -2.4171266555786133
Batch 16/64 loss: -2.815885543823242
Batch 17/64 loss: -2.863844871520996
Batch 18/64 loss: -3.1160717010498047
Batch 19/64 loss: -2.74725341796875
Batch 20/64 loss: -2.2476634979248047
Batch 21/64 loss: -2.812516212463379
Batch 22/64 loss: -2.914839744567871
Batch 23/64 loss: -2.8319272994995117
Batch 24/64 loss: -2.810122489929199
Batch 25/64 loss: -2.2406320571899414
Batch 26/64 loss: -2.834242820739746
Batch 27/64 loss: -3.0090579986572266
Batch 28/64 loss: -2.746694564819336
Batch 29/64 loss: -2.8081769943237305
Batch 30/64 loss: -2.6597604751586914
Batch 31/64 loss: -2.8450794219970703
Batch 32/64 loss: -2.863284111022949
Batch 33/64 loss: -2.7633066177368164
Batch 34/64 loss: -2.333230972290039
Batch 35/64 loss: -2.8905086517333984
Batch 36/64 loss: -2.873668670654297
Batch 37/64 loss: -2.8466854095458984
Batch 38/64 loss: -2.8447751998901367
Batch 39/64 loss: -3.011235237121582
Batch 40/64 loss: -2.9359188079833984
Batch 41/64 loss: -2.833780288696289
Batch 42/64 loss: -2.6668949127197266
Batch 43/64 loss: -2.5492677688598633
Batch 44/64 loss: -2.6208839416503906
Batch 45/64 loss: -2.97835636138916
Batch 46/64 loss: -2.6888484954833984
Batch 47/64 loss: -2.982733726501465
Batch 48/64 loss: -2.898911476135254
Batch 49/64 loss: -2.8509750366210938
Batch 50/64 loss: -2.8283166885375977
Batch 51/64 loss: -2.841275215148926
Batch 52/64 loss: -2.8413476943969727
Batch 53/64 loss: -2.7354068756103516
Batch 54/64 loss: -2.843613624572754
Batch 55/64 loss: -2.673521041870117
Batch 56/64 loss: -2.6650333404541016
Batch 57/64 loss: -2.341597557067871
Batch 58/64 loss: -3.0167016983032227
Batch 59/64 loss: -2.8803091049194336
Batch 60/64 loss: -2.5306005477905273
Batch 61/64 loss: -2.6945152282714844
Batch 62/64 loss: -2.838552474975586
Batch 63/64 loss: -3.000349998474121
Batch 64/64 loss: -7.434171676635742
Epoch 400  Train loss: -2.848001106112611  Val loss: -3.212364799787908
Epoch 401
-------------------------------
Batch 1/64 loss: -2.43741512298584
Batch 2/64 loss: -2.6617794036865234
Batch 3/64 loss: -2.8127565383911133
Batch 4/64 loss: -2.8004398345947266
Batch 5/64 loss: -2.7003440856933594
Batch 6/64 loss: -2.8128528594970703
Batch 7/64 loss: -2.677605628967285
Batch 8/64 loss: -2.714914321899414
Batch 9/64 loss: -2.6456127166748047
Batch 10/64 loss: -2.9279136657714844
Batch 11/64 loss: -2.9030370712280273
Batch 12/64 loss: -2.70839786529541
Batch 13/64 loss: -2.7522478103637695
Batch 14/64 loss: -2.9734792709350586
Batch 15/64 loss: -2.8361501693725586
Batch 16/64 loss: -2.842916488647461
Batch 17/64 loss: -2.945219039916992
Batch 18/64 loss: -2.967988967895508
Batch 19/64 loss: -2.9003467559814453
Batch 20/64 loss: -2.9134016036987305
Batch 21/64 loss: -2.933648109436035
Batch 22/64 loss: -3.0351600646972656
Batch 23/64 loss: -2.9577465057373047
Batch 24/64 loss: -2.797184944152832
Batch 25/64 loss: -2.9585256576538086
Batch 26/64 loss: -2.8232603073120117
Batch 27/64 loss: -2.911764144897461
Batch 28/64 loss: -2.62564754486084
Batch 29/64 loss: -2.90927791595459
Batch 30/64 loss: -2.8512020111083984
Batch 31/64 loss: -2.6976118087768555
Batch 32/64 loss: -2.546351432800293
Batch 33/64 loss: -2.87857723236084
Batch 34/64 loss: -2.9513330459594727
Batch 35/64 loss: -2.849125862121582
Batch 36/64 loss: -2.9737119674682617
Batch 37/64 loss: -2.327120780944824
Batch 38/64 loss: -2.91534423828125
Batch 39/64 loss: -2.697660446166992
Batch 40/64 loss: -2.953815460205078
Batch 41/64 loss: -2.410048484802246
Batch 42/64 loss: -2.9949731826782227
Batch 43/64 loss: -2.972165107727051
Batch 44/64 loss: -2.2396163940429688
Batch 45/64 loss: -2.875638961791992
Batch 46/64 loss: -2.804868698120117
Batch 47/64 loss: -2.8507442474365234
Batch 48/64 loss: -2.6863298416137695
Batch 49/64 loss: -2.871387481689453
Batch 50/64 loss: -2.3542442321777344
Batch 51/64 loss: -3.0002527236938477
Batch 52/64 loss: -2.6943769454956055
Batch 53/64 loss: -2.73862361907959
Batch 54/64 loss: -2.840479850769043
Batch 55/64 loss: -2.667738914489746
Batch 56/64 loss: -2.292238235473633
Batch 57/64 loss: -2.812960624694824
Batch 58/64 loss: -2.772167205810547
Batch 59/64 loss: -2.6555538177490234
Batch 60/64 loss: -2.8093032836914062
Batch 61/64 loss: -2.760493278503418
Batch 62/64 loss: -2.905698776245117
Batch 63/64 loss: -2.727227210998535
Batch 64/64 loss: -7.3484063148498535
Epoch 401  Train loss: -2.835722738153794  Val loss: -2.9638501590060207
Epoch 402
-------------------------------
Batch 1/64 loss: -2.758530616760254
Batch 2/64 loss: -2.7423009872436523
Batch 3/64 loss: -2.6284265518188477
Batch 4/64 loss: -2.771503448486328
Batch 5/64 loss: -2.7241249084472656
Batch 6/64 loss: -2.851236343383789
Batch 7/64 loss: -2.964427947998047
Batch 8/64 loss: -2.4456281661987305
Batch 9/64 loss: -2.4759931564331055
Batch 10/64 loss: -2.8736534118652344
Batch 11/64 loss: -2.9229679107666016
Batch 12/64 loss: -2.680544853210449
Batch 13/64 loss: -2.631439208984375
Batch 14/64 loss: -2.645557403564453
Batch 15/64 loss: -2.691800117492676
Batch 16/64 loss: -2.9310035705566406
Batch 17/64 loss: -2.634280204772949
Batch 18/64 loss: -2.8597068786621094
Batch 19/64 loss: -2.171354293823242
Batch 20/64 loss: -2.913802146911621
Batch 21/64 loss: -2.5344457626342773
Batch 22/64 loss: -2.8199386596679688
Batch 23/64 loss: -2.86019229888916
Batch 24/64 loss: -2.6019744873046875
Batch 25/64 loss: -2.5988521575927734
Batch 26/64 loss: -2.493539810180664
Batch 27/64 loss: -2.6272850036621094
Batch 28/64 loss: -2.116609573364258
Batch 29/64 loss: -2.656214714050293
Batch 30/64 loss: -2.471402168273926
Batch 31/64 loss: -2.808762550354004
Batch 32/64 loss: -2.999460220336914
Batch 33/64 loss: -2.389883041381836
Batch 34/64 loss: -2.462617874145508
Batch 35/64 loss: -2.6411895751953125
Batch 36/64 loss: -2.8728017807006836
Batch 37/64 loss: -2.753312110900879
Batch 38/64 loss: -2.581531524658203
Batch 39/64 loss: -2.5690994262695312
Batch 40/64 loss: -2.612124443054199
Batch 41/64 loss: -2.653517723083496
Batch 42/64 loss: -3.0046348571777344
Batch 43/64 loss: -3.02132511138916
Batch 44/64 loss: -2.9981889724731445
Batch 45/64 loss: -2.79843807220459
Batch 46/64 loss: -2.521026611328125
Batch 47/64 loss: -2.7786121368408203
Batch 48/64 loss: -2.6398801803588867
Batch 49/64 loss: -2.8687047958374023
Batch 50/64 loss: -2.7140426635742188
Batch 51/64 loss: -2.8119611740112305
Batch 52/64 loss: -2.641482353210449
Batch 53/64 loss: -2.928683280944824
Batch 54/64 loss: -2.757171630859375
Batch 55/64 loss: -2.965113639831543
Batch 56/64 loss: -2.6593780517578125
Batch 57/64 loss: -2.9633617401123047
Batch 58/64 loss: -2.550686836242676
Batch 59/64 loss: -2.753427505493164
Batch 60/64 loss: -2.3699941635131836
Batch 61/64 loss: -2.98671817779541
Batch 62/64 loss: -2.8980369567871094
Batch 63/64 loss: -2.9256343841552734
Batch 64/64 loss: -7.263360023498535
Epoch 402  Train loss: -2.767797025044759  Val loss: -3.1346828421366584
Epoch 403
-------------------------------
Batch 1/64 loss: -2.9893388748168945
Batch 2/64 loss: -2.705296516418457
Batch 3/64 loss: -2.824795722961426
Batch 4/64 loss: -2.8176040649414062
Batch 5/64 loss: -2.2035160064697266
Batch 6/64 loss: -2.490499496459961
Batch 7/64 loss: -2.8403167724609375
Batch 8/64 loss: -2.7032346725463867
Batch 9/64 loss: -2.433518409729004
Batch 10/64 loss: -2.757570266723633
Batch 11/64 loss: -2.666874885559082
Batch 12/64 loss: -2.9443321228027344
Batch 13/64 loss: -2.8043212890625
Batch 14/64 loss: -2.7911930084228516
Batch 15/64 loss: -2.837169647216797
Batch 16/64 loss: -2.916278839111328
Batch 17/64 loss: -2.8303709030151367
Batch 18/64 loss: -2.7148685455322266
Batch 19/64 loss: -2.832736015319824
Batch 20/64 loss: -2.9221277236938477
Batch 21/64 loss: -2.819573402404785
Batch 22/64 loss: -2.90334415435791
Batch 23/64 loss: -2.8958072662353516
Batch 24/64 loss: -2.9376487731933594
Batch 25/64 loss: -2.8301801681518555
Batch 26/64 loss: -2.761542320251465
Batch 27/64 loss: -2.789088249206543
Batch 28/64 loss: -2.7573928833007812
Batch 29/64 loss: -2.176417350769043
Batch 30/64 loss: -2.8603591918945312
Batch 31/64 loss: -2.883554458618164
Batch 32/64 loss: -2.9234142303466797
Batch 33/64 loss: -2.720907211303711
Batch 34/64 loss: -2.7514171600341797
Batch 35/64 loss: -2.893174171447754
Batch 36/64 loss: -2.887761116027832
Batch 37/64 loss: -2.840944290161133
Batch 38/64 loss: -2.8462133407592773
Batch 39/64 loss: -2.877264976501465
Batch 40/64 loss: -2.965036392211914
Batch 41/64 loss: -2.867465019226074
Batch 42/64 loss: -2.9685821533203125
Batch 43/64 loss: -2.989114761352539
Batch 44/64 loss: -2.7253026962280273
Batch 45/64 loss: -2.4917373657226562
Batch 46/64 loss: -2.7075414657592773
Batch 47/64 loss: -2.7587995529174805
Batch 48/64 loss: -2.4868125915527344
Batch 49/64 loss: -2.746718406677246
Batch 50/64 loss: -2.8749656677246094
Batch 51/64 loss: -2.9643659591674805
Batch 52/64 loss: -2.74269962310791
Batch 53/64 loss: -2.8203134536743164
Batch 54/64 loss: -2.502364158630371
Batch 55/64 loss: -2.738184928894043
Batch 56/64 loss: -2.87424373626709
Batch 57/64 loss: -2.752939224243164
Batch 58/64 loss: -2.841078758239746
Batch 59/64 loss: -2.4727792739868164
Batch 60/64 loss: -2.259852409362793
Batch 61/64 loss: -2.7712554931640625
Batch 62/64 loss: -2.714339256286621
Batch 63/64 loss: -2.613337516784668
Batch 64/64 loss: -7.236813068389893
Epoch 403  Train loss: -2.815049539827833  Val loss: -3.0228668946990442
Epoch 404
-------------------------------
Batch 1/64 loss: -2.714104652404785
Batch 2/64 loss: -2.5149574279785156
Batch 3/64 loss: -2.749262809753418
Batch 4/64 loss: -2.7237625122070312
Batch 5/64 loss: -2.764972686767578
Batch 6/64 loss: -2.70247745513916
Batch 7/64 loss: -2.6305532455444336
Batch 8/64 loss: -2.60683536529541
Batch 9/64 loss: -2.6861953735351562
Batch 10/64 loss: -2.60640811920166
Batch 11/64 loss: -2.752333641052246
Batch 12/64 loss: -2.6471633911132812
Batch 13/64 loss: -2.6803951263427734
Batch 14/64 loss: -2.785785675048828
Batch 15/64 loss: -2.8118181228637695
Batch 16/64 loss: -2.8030176162719727
Batch 17/64 loss: -2.974154472351074
Batch 18/64 loss: -2.930217742919922
Batch 19/64 loss: -2.7068328857421875
Batch 20/64 loss: -2.669501304626465
Batch 21/64 loss: -2.955974578857422
Batch 22/64 loss: -2.8205041885375977
Batch 23/64 loss: -2.904651641845703
Batch 24/64 loss: -2.5509557723999023
Batch 25/64 loss: -2.630364418029785
Batch 26/64 loss: -2.710087776184082
Batch 27/64 loss: -2.3529605865478516
Batch 28/64 loss: -2.830357551574707
Batch 29/64 loss: -2.733546257019043
Batch 30/64 loss: -2.4237232208251953
Batch 31/64 loss: -2.6387882232666016
Batch 32/64 loss: -2.4556007385253906
Batch 33/64 loss: -2.9777441024780273
Batch 34/64 loss: -2.75844669342041
Batch 35/64 loss: -2.7066545486450195
Batch 36/64 loss: -2.650634765625
Batch 37/64 loss: -2.9488134384155273
Batch 38/64 loss: -2.943873405456543
Batch 39/64 loss: -2.250598907470703
Batch 40/64 loss: -2.652157783508301
Batch 41/64 loss: -2.79049015045166
Batch 42/64 loss: -2.897700309753418
Batch 43/64 loss: -2.7802371978759766
Batch 44/64 loss: -2.3649606704711914
Batch 45/64 loss: -2.7710580825805664
Batch 46/64 loss: -2.8676137924194336
Batch 47/64 loss: -2.9642810821533203
Batch 48/64 loss: -2.7547855377197266
Batch 49/64 loss: -2.676039695739746
Batch 50/64 loss: -2.79290771484375
Batch 51/64 loss: -2.981692314147949
Batch 52/64 loss: -2.7428455352783203
Batch 53/64 loss: -2.7390079498291016
Batch 54/64 loss: -2.634352684020996
Batch 55/64 loss: -2.780156135559082
Batch 56/64 loss: -2.604135513305664
Batch 57/64 loss: -2.6777849197387695
Batch 58/64 loss: -2.7915220260620117
Batch 59/64 loss: -2.7312002182006836
Batch 60/64 loss: -2.804110527038574
Batch 61/64 loss: -2.874103546142578
Batch 62/64 loss: -2.5681991577148438
Batch 63/64 loss: -2.665861129760742
Batch 64/64 loss: -7.3185553550720215
Epoch 404  Train loss: -2.7780572648141897  Val loss: -3.07225508542405
Epoch 405
-------------------------------
Batch 1/64 loss: -3.0932445526123047
Batch 2/64 loss: -2.6586523056030273
Batch 3/64 loss: -2.8579139709472656
Batch 4/64 loss: -2.10477352142334
Batch 5/64 loss: -2.627239227294922
Batch 6/64 loss: -3.0558338165283203
Batch 7/64 loss: -2.679966926574707
Batch 8/64 loss: -2.8399829864501953
Batch 9/64 loss: -2.5160598754882812
Batch 10/64 loss: -2.981180191040039
Batch 11/64 loss: -2.790705680847168
Batch 12/64 loss: -2.905384063720703
Batch 13/64 loss: -2.799184799194336
Batch 14/64 loss: -2.8707685470581055
Batch 15/64 loss: -2.6905908584594727
Batch 16/64 loss: -2.9695940017700195
Batch 17/64 loss: -2.843189239501953
Batch 18/64 loss: -2.779147148132324
Batch 19/64 loss: -2.40557861328125
Batch 20/64 loss: -2.9952030181884766
Batch 21/64 loss: -2.8435897827148438
Batch 22/64 loss: -2.696516990661621
Batch 23/64 loss: -2.669261932373047
Batch 24/64 loss: -3.0258750915527344
Batch 25/64 loss: -2.886155128479004
Batch 26/64 loss: -2.857621192932129
Batch 27/64 loss: -2.8791379928588867
Batch 28/64 loss: -2.9847564697265625
Batch 29/64 loss: -2.7060346603393555
Batch 30/64 loss: -2.738748550415039
Batch 31/64 loss: -2.6115169525146484
Batch 32/64 loss: -2.86715030670166
Batch 33/64 loss: -2.8315963745117188
Batch 34/64 loss: -2.6397085189819336
Batch 35/64 loss: -2.638782501220703
Batch 36/64 loss: -2.8123531341552734
Batch 37/64 loss: -2.138690948486328
Batch 38/64 loss: -2.763930320739746
Batch 39/64 loss: -2.7484731674194336
Batch 40/64 loss: -2.8933067321777344
Batch 41/64 loss: -2.398702621459961
Batch 42/64 loss: -2.6694459915161133
Batch 43/64 loss: -2.975719451904297
Batch 44/64 loss: -2.8429031372070312
Batch 45/64 loss: -2.65179443359375
Batch 46/64 loss: -2.9394731521606445
Batch 47/64 loss: -2.759000778198242
Batch 48/64 loss: -2.563325881958008
Batch 49/64 loss: -2.077136993408203
Batch 50/64 loss: -2.833052635192871
Batch 51/64 loss: -2.6169958114624023
Batch 52/64 loss: -2.4568920135498047
Batch 53/64 loss: -2.409515380859375
Batch 54/64 loss: -2.0722665786743164
Batch 55/64 loss: -2.80252742767334
Batch 56/64 loss: -2.9346914291381836
Batch 57/64 loss: -2.8803205490112305
Batch 58/64 loss: -2.437544822692871
Batch 59/64 loss: -2.6059093475341797
Batch 60/64 loss: -3.0738344192504883
Batch 61/64 loss: -2.721372604370117
Batch 62/64 loss: -2.8223342895507812
Batch 63/64 loss: -2.9081907272338867
Batch 64/64 loss: -7.254271507263184
Epoch 405  Train loss: -2.785742026684331  Val loss: -3.024744669596354
Epoch 406
-------------------------------
Batch 1/64 loss: -2.5526418685913086
Batch 2/64 loss: -2.7909536361694336
Batch 3/64 loss: -2.984039306640625
Batch 4/64 loss: -2.7152252197265625
Batch 5/64 loss: -2.758563995361328
Batch 6/64 loss: -2.217317581176758
Batch 7/64 loss: -2.8551883697509766
Batch 8/64 loss: -2.650607109069824
Batch 9/64 loss: -2.7973880767822266
Batch 10/64 loss: -2.4694910049438477
Batch 11/64 loss: -2.0985727310180664
Batch 12/64 loss: -2.8977556228637695
Batch 13/64 loss: -2.3434019088745117
Batch 14/64 loss: -2.964900016784668
Batch 15/64 loss: -2.573598861694336
Batch 16/64 loss: -2.675326347351074
Batch 17/64 loss: -2.6743431091308594
Batch 18/64 loss: -2.688216209411621
Batch 19/64 loss: -2.7697696685791016
Batch 20/64 loss: -2.8506975173950195
Batch 21/64 loss: -2.401158332824707
Batch 22/64 loss: -2.6648292541503906
Batch 23/64 loss: -2.701244354248047
Batch 24/64 loss: -2.8112049102783203
Batch 25/64 loss: -2.5668563842773438
Batch 26/64 loss: -2.748220443725586
Batch 27/64 loss: -2.989410400390625
Batch 28/64 loss: -2.675405502319336
Batch 29/64 loss: -2.8817148208618164
Batch 30/64 loss: -2.636514663696289
Batch 31/64 loss: -2.8131093978881836
Batch 32/64 loss: -2.9713401794433594
Batch 33/64 loss: -2.8252134323120117
Batch 34/64 loss: -2.432147979736328
Batch 35/64 loss: -2.832463264465332
Batch 36/64 loss: -2.919539451599121
Batch 37/64 loss: -2.8797645568847656
Batch 38/64 loss: -2.919196128845215
Batch 39/64 loss: -2.5940914154052734
Batch 40/64 loss: -2.479252815246582
Batch 41/64 loss: -2.672287940979004
Batch 42/64 loss: -2.7598047256469727
Batch 43/64 loss: -2.6947031021118164
Batch 44/64 loss: -2.6929702758789062
Batch 45/64 loss: -2.8191070556640625
Batch 46/64 loss: -2.7386159896850586
Batch 47/64 loss: -2.8156919479370117
Batch 48/64 loss: -2.7524003982543945
Batch 49/64 loss: -2.735513687133789
Batch 50/64 loss: -2.841912269592285
Batch 51/64 loss: -2.9568748474121094
Batch 52/64 loss: -2.8716907501220703
Batch 53/64 loss: -3.0617809295654297
Batch 54/64 loss: -2.7452354431152344
Batch 55/64 loss: -2.9047670364379883
Batch 56/64 loss: -2.820563316345215
Batch 57/64 loss: -2.9470767974853516
Batch 58/64 loss: -2.902968406677246
Batch 59/64 loss: -2.7269744873046875
Batch 60/64 loss: -2.9544763565063477
Batch 61/64 loss: -2.815114974975586
Batch 62/64 loss: -2.949687957763672
Batch 63/64 loss: -2.853984832763672
Batch 64/64 loss: -7.099542617797852
Epoch 406  Train loss: -2.798894687727386  Val loss: -3.021335365845985
Epoch 407
-------------------------------
Batch 1/64 loss: -1.8112926483154297
Batch 2/64 loss: -2.5710582733154297
Batch 3/64 loss: -2.75213623046875
Batch 4/64 loss: -2.795886993408203
Batch 5/64 loss: -2.8583946228027344
Batch 6/64 loss: -2.4114112854003906
Batch 7/64 loss: -2.911593437194824
Batch 8/64 loss: -2.5456466674804688
Batch 9/64 loss: -2.487847328186035
Batch 10/64 loss: -2.576083183288574
Batch 11/64 loss: -2.68243408203125
Batch 12/64 loss: -2.72426700592041
Batch 13/64 loss: -2.8273134231567383
Batch 14/64 loss: -2.8595495223999023
Batch 15/64 loss: -2.6376819610595703
Batch 16/64 loss: -2.761075019836426
Batch 17/64 loss: -2.6762819290161133
Batch 18/64 loss: -2.611581802368164
Batch 19/64 loss: -2.7664146423339844
Batch 20/64 loss: -2.7983322143554688
Batch 21/64 loss: -2.734159469604492
Batch 22/64 loss: -2.960219383239746
Batch 23/64 loss: -2.701889991760254
Batch 24/64 loss: -2.542239189147949
Batch 25/64 loss: -2.758106231689453
Batch 26/64 loss: -2.68157958984375
Batch 27/64 loss: -3.081263542175293
Batch 28/64 loss: -2.8489294052124023
Batch 29/64 loss: -2.894791603088379
Batch 30/64 loss: -2.399367332458496
Batch 31/64 loss: -2.8898019790649414
Batch 32/64 loss: -2.807924270629883
Batch 33/64 loss: -2.9203033447265625
Batch 34/64 loss: -2.8482885360717773
Batch 35/64 loss: -2.5886640548706055
Batch 36/64 loss: -2.930598258972168
Batch 37/64 loss: -2.852147102355957
Batch 38/64 loss: -2.9572038650512695
Batch 39/64 loss: -2.9905529022216797
Batch 40/64 loss: -2.7417478561401367
Batch 41/64 loss: -2.805753707885742
Batch 42/64 loss: -2.832913398742676
Batch 43/64 loss: -2.8474769592285156
Batch 44/64 loss: -2.7904787063598633
Batch 45/64 loss: -2.9283323287963867
Batch 46/64 loss: -2.8560523986816406
Batch 47/64 loss: -2.707181930541992
Batch 48/64 loss: -2.675288200378418
Batch 49/64 loss: -2.8330678939819336
Batch 50/64 loss: -2.7259674072265625
Batch 51/64 loss: -2.781338691711426
Batch 52/64 loss: -2.8153810501098633
Batch 53/64 loss: -2.571857452392578
Batch 54/64 loss: -2.6681785583496094
Batch 55/64 loss: -2.5629167556762695
Batch 56/64 loss: -2.69484806060791
Batch 57/64 loss: -2.5415897369384766
Batch 58/64 loss: -3.0063886642456055
Batch 59/64 loss: -2.7669363021850586
Batch 60/64 loss: -2.9463300704956055
Batch 61/64 loss: -2.8313331604003906
Batch 62/64 loss: -2.900115966796875
Batch 63/64 loss: -2.1758718490600586
Batch 64/64 loss: -7.230123996734619
Epoch 407  Train loss: -2.790341214572682  Val loss: -3.097949090282532
Epoch 408
-------------------------------
Batch 1/64 loss: -2.72348690032959
Batch 2/64 loss: -2.570895195007324
Batch 3/64 loss: -2.720944404602051
Batch 4/64 loss: -2.8125314712524414
Batch 5/64 loss: -2.482746124267578
Batch 6/64 loss: -2.9563817977905273
Batch 7/64 loss: -2.7344417572021484
Batch 8/64 loss: -2.895843505859375
Batch 9/64 loss: -2.7794227600097656
Batch 10/64 loss: -2.7851333618164062
Batch 11/64 loss: -2.51816463470459
Batch 12/64 loss: -2.7146902084350586
Batch 13/64 loss: -2.7689971923828125
Batch 14/64 loss: -2.639824867248535
Batch 15/64 loss: -2.534665107727051
Batch 16/64 loss: -2.2494707107543945
Batch 17/64 loss: -2.72945499420166
Batch 18/64 loss: -2.9217376708984375
Batch 19/64 loss: -2.529207229614258
Batch 20/64 loss: -2.6993541717529297
Batch 21/64 loss: -2.819307327270508
Batch 22/64 loss: -2.7201480865478516
Batch 23/64 loss: -2.8150930404663086
Batch 24/64 loss: -2.824070930480957
Batch 25/64 loss: -2.8695802688598633
Batch 26/64 loss: -2.7975006103515625
Batch 27/64 loss: -2.340240478515625
Batch 28/64 loss: -2.5925025939941406
Batch 29/64 loss: -2.6494102478027344
Batch 30/64 loss: -2.886197090148926
Batch 31/64 loss: -2.9170007705688477
Batch 32/64 loss: -2.822540283203125
Batch 33/64 loss: -2.791658401489258
Batch 34/64 loss: -2.6222715377807617
Batch 35/64 loss: -2.4281511306762695
Batch 36/64 loss: -2.741933822631836
Batch 37/64 loss: -2.8836212158203125
Batch 38/64 loss: -2.727267265319824
Batch 39/64 loss: -2.9510602951049805
Batch 40/64 loss: -2.6732444763183594
Batch 41/64 loss: -2.8009958267211914
Batch 42/64 loss: -2.881340980529785
Batch 43/64 loss: -2.779714584350586
Batch 44/64 loss: -2.9620742797851562
Batch 45/64 loss: -2.637537956237793
Batch 46/64 loss: -3.0004653930664062
Batch 47/64 loss: -2.447246551513672
Batch 48/64 loss: -2.5460147857666016
Batch 49/64 loss: -2.938488006591797
Batch 50/64 loss: -2.824437141418457
Batch 51/64 loss: -2.94034481048584
Batch 52/64 loss: -2.819207191467285
Batch 53/64 loss: -2.722506523132324
Batch 54/64 loss: -2.8298864364624023
Batch 55/64 loss: -2.683140754699707
Batch 56/64 loss: -2.5523128509521484
Batch 57/64 loss: -2.7313270568847656
Batch 58/64 loss: -2.7947826385498047
Batch 59/64 loss: -2.779332160949707
Batch 60/64 loss: -2.8558483123779297
Batch 61/64 loss: -2.891261100769043
Batch 62/64 loss: -2.5042667388916016
Batch 63/64 loss: -2.6295413970947266
Batch 64/64 loss: -7.366392135620117
Epoch 408  Train loss: -2.7877186120725144  Val loss: -3.031859853423338
Epoch 409
-------------------------------
Batch 1/64 loss: -3.0980758666992188
Batch 2/64 loss: -2.399585723876953
Batch 3/64 loss: -2.7440357208251953
Batch 4/64 loss: -2.842097282409668
Batch 5/64 loss: -2.795713424682617
Batch 6/64 loss: -2.796442985534668
Batch 7/64 loss: -2.711700439453125
Batch 8/64 loss: -2.7032957077026367
Batch 9/64 loss: -2.797865867614746
Batch 10/64 loss: -2.9119691848754883
Batch 11/64 loss: -2.9250259399414062
Batch 12/64 loss: -2.8511571884155273
Batch 13/64 loss: -1.8769855499267578
Batch 14/64 loss: -2.7833003997802734
Batch 15/64 loss: -2.8981056213378906
Batch 16/64 loss: -2.393087387084961
Batch 17/64 loss: -2.821627616882324
Batch 18/64 loss: -2.4643516540527344
Batch 19/64 loss: -2.7656478881835938
Batch 20/64 loss: -2.8613204956054688
Batch 21/64 loss: -2.8609533309936523
Batch 22/64 loss: -2.9732112884521484
Batch 23/64 loss: -2.741543769836426
Batch 24/64 loss: -2.7816944122314453
Batch 25/64 loss: -2.8842086791992188
Batch 26/64 loss: -2.8268556594848633
Batch 27/64 loss: -2.4909019470214844
Batch 28/64 loss: -2.9674835205078125
Batch 29/64 loss: -3.0072593688964844
Batch 30/64 loss: -2.5539722442626953
Batch 31/64 loss: -2.6319665908813477
Batch 32/64 loss: -2.851080894470215
Batch 33/64 loss: -2.774168014526367
Batch 34/64 loss: -2.903888702392578
Batch 35/64 loss: -2.8826208114624023
Batch 36/64 loss: -2.700066566467285
Batch 37/64 loss: -3.0907392501831055
Batch 38/64 loss: -2.732424736022949
Batch 39/64 loss: -2.9365921020507812
Batch 40/64 loss: -2.861790657043457
Batch 41/64 loss: -2.4846973419189453
Batch 42/64 loss: -2.87979793548584
Batch 43/64 loss: -2.90122127532959
Batch 44/64 loss: -2.83939266204834
Batch 45/64 loss: -2.8668460845947266
Batch 46/64 loss: -2.1621036529541016
Batch 47/64 loss: -2.8270187377929688
Batch 48/64 loss: -2.5701332092285156
Batch 49/64 loss: -2.807535171508789
Batch 50/64 loss: -2.3315820693969727
Batch 51/64 loss: -3.0312604904174805
Batch 52/64 loss: -2.4472923278808594
Batch 53/64 loss: -2.82791805267334
Batch 54/64 loss: -2.7088260650634766
Batch 55/64 loss: -2.6226606369018555
Batch 56/64 loss: -2.6291656494140625
Batch 57/64 loss: -2.9290103912353516
Batch 58/64 loss: -2.736588478088379
Batch 59/64 loss: -2.732846260070801
Batch 60/64 loss: -2.6600475311279297
Batch 61/64 loss: -2.313103675842285
Batch 62/64 loss: -2.368701934814453
Batch 63/64 loss: -2.722423553466797
Batch 64/64 loss: -7.429144859313965
Epoch 409  Train loss: -2.790068177615895  Val loss: -2.9181315890702186
Epoch 410
-------------------------------
Batch 1/64 loss: -2.8819456100463867
Batch 2/64 loss: -2.851923942565918
Batch 3/64 loss: -1.7116851806640625
Batch 4/64 loss: -2.7635717391967773
Batch 5/64 loss: -2.8234119415283203
Batch 6/64 loss: -2.533053398132324
Batch 7/64 loss: -2.666318893432617
Batch 8/64 loss: -2.495044708251953
Batch 9/64 loss: -2.21315860748291
Batch 10/64 loss: -2.292734146118164
Batch 11/64 loss: -2.6749086380004883
Batch 12/64 loss: -2.5671472549438477
Batch 13/64 loss: -2.466032028198242
Batch 14/64 loss: -2.7070999145507812
Batch 15/64 loss: -2.5094432830810547
Batch 16/64 loss: -2.657012939453125
Batch 17/64 loss: -2.3972482681274414
Batch 18/64 loss: -2.5052480697631836
Batch 19/64 loss: -2.543546676635742
Batch 20/64 loss: -2.9036083221435547
Batch 21/64 loss: -2.5586299896240234
Batch 22/64 loss: -2.1203079223632812
Batch 23/64 loss: -2.6818771362304688
Batch 24/64 loss: -2.781680107116699
Batch 25/64 loss: -2.473217010498047
Batch 26/64 loss: -2.1096038818359375
Batch 27/64 loss: -2.657716751098633
Batch 28/64 loss: -2.848062515258789
Batch 29/64 loss: -2.643259048461914
Batch 30/64 loss: -2.6735734939575195
Batch 31/64 loss: -2.7874326705932617
Batch 32/64 loss: -2.6698427200317383
Batch 33/64 loss: -2.5700321197509766
Batch 34/64 loss: -2.7422056198120117
Batch 35/64 loss: -2.8306665420532227
Batch 36/64 loss: -2.6525087356567383
Batch 37/64 loss: -2.7119693756103516
Batch 38/64 loss: -2.6057825088500977
Batch 39/64 loss: -2.774430274963379
Batch 40/64 loss: -2.894744873046875
Batch 41/64 loss: -2.493968963623047
Batch 42/64 loss: -2.5478906631469727
Batch 43/64 loss: -2.7490158081054688
Batch 44/64 loss: -2.723210334777832
Batch 45/64 loss: -2.7697744369506836
Batch 46/64 loss: -2.419523239135742
Batch 47/64 loss: -2.3578338623046875
Batch 48/64 loss: -2.458144187927246
Batch 49/64 loss: -2.9670162200927734
Batch 50/64 loss: -3.0035934448242188
Batch 51/64 loss: -2.600688934326172
Batch 52/64 loss: -2.989508628845215
Batch 53/64 loss: -2.8762731552124023
Batch 54/64 loss: -2.819119453430176
Batch 55/64 loss: -2.4361228942871094
Batch 56/64 loss: -2.9953861236572266
Batch 57/64 loss: -2.7789554595947266
Batch 58/64 loss: -2.8232736587524414
Batch 59/64 loss: -2.397367477416992
Batch 60/64 loss: -2.593595504760742
Batch 61/64 loss: -2.815610885620117
Batch 62/64 loss: -2.5858373641967773
Batch 63/64 loss: -2.730785369873047
Batch 64/64 loss: -7.3046159744262695
Epoch 410  Train loss: -2.6880414887970567  Val loss: -3.054274686833018
Epoch 411
-------------------------------
Batch 1/64 loss: -2.6493825912475586
Batch 2/64 loss: -2.6689987182617188
Batch 3/64 loss: -2.7477025985717773
Batch 4/64 loss: -2.7526321411132812
Batch 5/64 loss: -2.6332225799560547
Batch 6/64 loss: -2.655280113220215
Batch 7/64 loss: -1.9827861785888672
Batch 8/64 loss: -2.7822160720825195
Batch 9/64 loss: -2.7000207901000977
Batch 10/64 loss: -2.9823036193847656
Batch 11/64 loss: -2.82205867767334
Batch 12/64 loss: -2.66019344329834
Batch 13/64 loss: -2.7961530685424805
Batch 14/64 loss: -2.8065357208251953
Batch 15/64 loss: -2.882338523864746
Batch 16/64 loss: -2.666635513305664
Batch 17/64 loss: -3.0154123306274414
Batch 18/64 loss: -2.8573827743530273
Batch 19/64 loss: -2.67636775970459
Batch 20/64 loss: -2.9800472259521484
Batch 21/64 loss: -2.9304914474487305
Batch 22/64 loss: -2.828754425048828
Batch 23/64 loss: -2.8682260513305664
Batch 24/64 loss: -2.880645751953125
Batch 25/64 loss: -2.5702695846557617
Batch 26/64 loss: -2.812223434448242
Batch 27/64 loss: -2.8480396270751953
Batch 28/64 loss: -2.730288505554199
Batch 29/64 loss: -2.786383628845215
Batch 30/64 loss: -2.813490867614746
Batch 31/64 loss: -2.7353334426879883
Batch 32/64 loss: -2.3978424072265625
Batch 33/64 loss: -2.8052978515625
Batch 34/64 loss: -2.979109764099121
Batch 35/64 loss: -2.942988395690918
Batch 36/64 loss: -2.6032705307006836
Batch 37/64 loss: -2.9120683670043945
Batch 38/64 loss: -2.930487632751465
Batch 39/64 loss: -2.7590274810791016
Batch 40/64 loss: -2.6951112747192383
Batch 41/64 loss: -2.873307228088379
Batch 42/64 loss: -2.794757843017578
Batch 43/64 loss: -2.9930801391601562
Batch 44/64 loss: -2.416060447692871
Batch 45/64 loss: -2.609355926513672
Batch 46/64 loss: -3.021869659423828
Batch 47/64 loss: -2.9325313568115234
Batch 48/64 loss: -2.6913089752197266
Batch 49/64 loss: -2.5630502700805664
Batch 50/64 loss: -2.9836254119873047
Batch 51/64 loss: -2.7778282165527344
Batch 52/64 loss: -2.3942480087280273
Batch 53/64 loss: -2.9334945678710938
Batch 54/64 loss: -2.871997833251953
Batch 55/64 loss: -2.6824798583984375
Batch 56/64 loss: -2.7848691940307617
Batch 57/64 loss: -2.9037551879882812
Batch 58/64 loss: -2.7876510620117188
Batch 59/64 loss: -2.819875717163086
Batch 60/64 loss: -2.7281723022460938
Batch 61/64 loss: -2.83524227142334
Batch 62/64 loss: -2.962251663208008
Batch 63/64 loss: -2.7633285522460938
Batch 64/64 loss: -7.387747764587402
Epoch 411  Train loss: -2.826854485156489  Val loss: -3.2537374725866153
Saving best model, epoch: 411
Epoch 412
-------------------------------
Batch 1/64 loss: -2.8813648223876953
Batch 2/64 loss: -2.5960636138916016
Batch 3/64 loss: -2.9278993606567383
Batch 4/64 loss: -2.377692222595215
Batch 5/64 loss: -2.852306365966797
Batch 6/64 loss: -2.7134828567504883
Batch 7/64 loss: -2.6976308822631836
Batch 8/64 loss: -2.9173803329467773
Batch 9/64 loss: -2.8118858337402344
Batch 10/64 loss: -2.8819169998168945
Batch 11/64 loss: -2.6372299194335938
Batch 12/64 loss: -3.0101919174194336
Batch 13/64 loss: -2.746105194091797
Batch 14/64 loss: -2.9282331466674805
Batch 15/64 loss: -2.7399349212646484
Batch 16/64 loss: -2.697935104370117
Batch 17/64 loss: -3.0463037490844727
Batch 18/64 loss: -2.863567352294922
Batch 19/64 loss: -2.779550552368164
Batch 20/64 loss: -2.755213737487793
Batch 21/64 loss: -3.048910140991211
Batch 22/64 loss: -2.709622383117676
Batch 23/64 loss: -2.987210273742676
Batch 24/64 loss: -2.9971580505371094
Batch 25/64 loss: -2.835402488708496
Batch 26/64 loss: -2.894639015197754
Batch 27/64 loss: -2.9295291900634766
Batch 28/64 loss: -2.7462844848632812
Batch 29/64 loss: -2.992277145385742
Batch 30/64 loss: -2.6199188232421875
Batch 31/64 loss: -2.9759435653686523
Batch 32/64 loss: -2.7818946838378906
Batch 33/64 loss: -2.947596549987793
Batch 34/64 loss: -2.694066047668457
Batch 35/64 loss: -2.9559974670410156
Batch 36/64 loss: -2.7609691619873047
Batch 37/64 loss: -2.989500045776367
Batch 38/64 loss: -2.7545547485351562
Batch 39/64 loss: -2.781346321105957
Batch 40/64 loss: -2.75408935546875
Batch 41/64 loss: -2.857327461242676
Batch 42/64 loss: -2.5848121643066406
Batch 43/64 loss: -2.8880691528320312
Batch 44/64 loss: -2.735006332397461
Batch 45/64 loss: -2.628464698791504
Batch 46/64 loss: -2.952267646789551
Batch 47/64 loss: -2.7870607376098633
Batch 48/64 loss: -2.8975000381469727
Batch 49/64 loss: -2.692960739135742
Batch 50/64 loss: -2.8021888732910156
Batch 51/64 loss: -2.935464859008789
Batch 52/64 loss: -2.8412046432495117
Batch 53/64 loss: -3.0150680541992188
Batch 54/64 loss: -2.708322525024414
Batch 55/64 loss: -2.973443031311035
Batch 56/64 loss: -2.764070510864258
Batch 57/64 loss: -2.880420684814453
Batch 58/64 loss: -2.381612777709961
Batch 59/64 loss: -2.8914546966552734
Batch 60/64 loss: -2.0537967681884766
Batch 61/64 loss: -2.836557388305664
Batch 62/64 loss: -2.4574050903320312
Batch 63/64 loss: -2.9017295837402344
Batch 64/64 loss: -7.3085174560546875
Epoch 412  Train loss: -2.8543748294605926  Val loss: -3.198356969250027
Epoch 413
-------------------------------
Batch 1/64 loss: -2.9308977127075195
Batch 2/64 loss: -3.0843334197998047
Batch 3/64 loss: -2.756045341491699
Batch 4/64 loss: -2.7809982299804688
Batch 5/64 loss: -2.878891944885254
Batch 6/64 loss: -2.7926435470581055
Batch 7/64 loss: -2.735485076904297
Batch 8/64 loss: -2.931497573852539
Batch 9/64 loss: -3.0386791229248047
Batch 10/64 loss: -1.7847814559936523
Batch 11/64 loss: -2.8344268798828125
Batch 12/64 loss: -2.865372657775879
Batch 13/64 loss: -2.805959701538086
Batch 14/64 loss: -2.775998115539551
Batch 15/64 loss: -2.839143753051758
Batch 16/64 loss: -2.9867238998413086
Batch 17/64 loss: -2.5702199935913086
Batch 18/64 loss: -2.539865493774414
Batch 19/64 loss: -2.93447208404541
Batch 20/64 loss: -2.8523311614990234
Batch 21/64 loss: -2.9009180068969727
Batch 22/64 loss: -2.9673585891723633
Batch 23/64 loss: -2.7382287979125977
Batch 24/64 loss: -3.035149574279785
Batch 25/64 loss: -2.75314998626709
Batch 26/64 loss: -2.946225166320801
Batch 27/64 loss: -2.863062858581543
Batch 28/64 loss: -2.950798988342285
Batch 29/64 loss: -3.0420427322387695
Batch 30/64 loss: -2.8711671829223633
Batch 31/64 loss: -2.8834495544433594
Batch 32/64 loss: -2.6389217376708984
Batch 33/64 loss: -3.047041893005371
Batch 34/64 loss: -2.972614288330078
Batch 35/64 loss: -2.8490076065063477
Batch 36/64 loss: -2.662496566772461
Batch 37/64 loss: -3.025196075439453
Batch 38/64 loss: -2.553255081176758
Batch 39/64 loss: -3.0156679153442383
Batch 40/64 loss: -2.7106246948242188
Batch 41/64 loss: -3.071453094482422
Batch 42/64 loss: -2.9922561645507812
Batch 43/64 loss: -2.851177215576172
Batch 44/64 loss: -2.9494247436523438
Batch 45/64 loss: -2.841904640197754
Batch 46/64 loss: -2.7539138793945312
Batch 47/64 loss: -2.494680404663086
Batch 48/64 loss: -2.767096519470215
Batch 49/64 loss: -2.8094120025634766
Batch 50/64 loss: -2.948969841003418
Batch 51/64 loss: -2.6037235260009766
Batch 52/64 loss: -2.975513458251953
Batch 53/64 loss: -2.894343376159668
Batch 54/64 loss: -2.7960338592529297
Batch 55/64 loss: -2.9125232696533203
Batch 56/64 loss: -2.760038375854492
Batch 57/64 loss: -1.8658313751220703
Batch 58/64 loss: -2.7543258666992188
Batch 59/64 loss: -2.8303699493408203
Batch 60/64 loss: -2.6922473907470703
Batch 61/64 loss: -2.7548389434814453
Batch 62/64 loss: -2.676961898803711
Batch 63/64 loss: -2.7732906341552734
Batch 64/64 loss: -7.355131149291992
Epoch 413  Train loss: -2.8616756588804955  Val loss: -3.1980162158454815
Epoch 414
-------------------------------
Batch 1/64 loss: -2.770735740661621
Batch 2/64 loss: -2.895021438598633
Batch 3/64 loss: -3.0278797149658203
Batch 4/64 loss: -2.8583526611328125
Batch 5/64 loss: -2.9081382751464844
Batch 6/64 loss: -2.893601417541504
Batch 7/64 loss: -2.967074394226074
Batch 8/64 loss: -2.785665512084961
Batch 9/64 loss: -2.8634071350097656
Batch 10/64 loss: -2.8361406326293945
Batch 11/64 loss: -2.482110023498535
Batch 12/64 loss: -2.895030975341797
Batch 13/64 loss: -2.970233917236328
Batch 14/64 loss: -2.9433698654174805
Batch 15/64 loss: -2.746148109436035
Batch 16/64 loss: -2.6729507446289062
Batch 17/64 loss: -2.756622314453125
Batch 18/64 loss: -2.6090879440307617
Batch 19/64 loss: -2.905864715576172
Batch 20/64 loss: -2.863509178161621
Batch 21/64 loss: -2.711977958679199
Batch 22/64 loss: -2.6688003540039062
Batch 23/64 loss: -2.6947879791259766
Batch 24/64 loss: -2.6996994018554688
Batch 25/64 loss: -2.8587207794189453
Batch 26/64 loss: -2.7852296829223633
Batch 27/64 loss: -2.8337221145629883
Batch 28/64 loss: -2.812868118286133
Batch 29/64 loss: -2.1050186157226562
Batch 30/64 loss: -2.4780187606811523
Batch 31/64 loss: -2.983163833618164
Batch 32/64 loss: -2.681488037109375
Batch 33/64 loss: -2.7802352905273438
Batch 34/64 loss: -2.833162307739258
Batch 35/64 loss: -2.7327842712402344
Batch 36/64 loss: -2.664523124694824
Batch 37/64 loss: -2.8801403045654297
Batch 38/64 loss: -2.681145668029785
Batch 39/64 loss: -2.6985912322998047
Batch 40/64 loss: -2.834567070007324
Batch 41/64 loss: -2.8140039443969727
Batch 42/64 loss: -2.538153648376465
Batch 43/64 loss: -2.7666244506835938
Batch 44/64 loss: -2.7527284622192383
Batch 45/64 loss: -2.8939132690429688
Batch 46/64 loss: -2.8879480361938477
Batch 47/64 loss: -2.8678903579711914
Batch 48/64 loss: -2.9444332122802734
Batch 49/64 loss: -2.7302379608154297
Batch 50/64 loss: -2.834657669067383
Batch 51/64 loss: -2.832338333129883
Batch 52/64 loss: -2.9185028076171875
Batch 53/64 loss: -2.7374496459960938
Batch 54/64 loss: -2.80472469329834
Batch 55/64 loss: -2.781618118286133
Batch 56/64 loss: -2.188526153564453
Batch 57/64 loss: -2.5353708267211914
Batch 58/64 loss: -2.753960609436035
Batch 59/64 loss: -2.800990104675293
Batch 60/64 loss: -2.833005905151367
Batch 61/64 loss: -2.8902034759521484
Batch 62/64 loss: -2.2897424697875977
Batch 63/64 loss: -2.701566696166992
Batch 64/64 loss: -7.152933597564697
Epoch 414  Train loss: -2.816202049629361  Val loss: -3.075579757952608
Epoch 415
-------------------------------
Batch 1/64 loss: -2.5157060623168945
Batch 2/64 loss: -2.8179941177368164
Batch 3/64 loss: -2.8695545196533203
Batch 4/64 loss: -2.582749366760254
Batch 5/64 loss: -2.432581901550293
Batch 6/64 loss: -2.616024971008301
Batch 7/64 loss: -2.7254552841186523
Batch 8/64 loss: -2.5961484909057617
Batch 9/64 loss: -2.7925806045532227
Batch 10/64 loss: -3.095759391784668
Batch 11/64 loss: -2.6085710525512695
Batch 12/64 loss: -2.5254621505737305
Batch 13/64 loss: -2.6313552856445312
Batch 14/64 loss: -2.463799476623535
Batch 15/64 loss: -2.5028276443481445
Batch 16/64 loss: -2.846212387084961
Batch 17/64 loss: -2.969156265258789
Batch 18/64 loss: -2.9758501052856445
Batch 19/64 loss: -2.799626350402832
Batch 20/64 loss: -2.651430130004883
Batch 21/64 loss: -2.522512435913086
Batch 22/64 loss: -2.6033525466918945
Batch 23/64 loss: -2.895387649536133
Batch 24/64 loss: -2.7969064712524414
Batch 25/64 loss: -2.8301382064819336
Batch 26/64 loss: -2.2599353790283203
Batch 27/64 loss: -2.8894214630126953
Batch 28/64 loss: -2.7666406631469727
Batch 29/64 loss: -2.9828758239746094
Batch 30/64 loss: -2.326848030090332
Batch 31/64 loss: -2.767070770263672
Batch 32/64 loss: -2.513690948486328
Batch 33/64 loss: -2.7558422088623047
Batch 34/64 loss: -2.6798696517944336
Batch 35/64 loss: -2.7955188751220703
Batch 36/64 loss: -2.826047897338867
Batch 37/64 loss: -2.7446203231811523
Batch 38/64 loss: -2.925997734069824
Batch 39/64 loss: -2.9214086532592773
Batch 40/64 loss: -2.879091262817383
Batch 41/64 loss: -2.961996078491211
Batch 42/64 loss: -2.7725095748901367
Batch 43/64 loss: -2.767632484436035
Batch 44/64 loss: -2.1729555130004883
Batch 45/64 loss: -2.902212142944336
Batch 46/64 loss: -2.7733383178710938
Batch 47/64 loss: -2.8121166229248047
Batch 48/64 loss: -2.7949466705322266
Batch 49/64 loss: -2.9098434448242188
Batch 50/64 loss: -2.5785322189331055
Batch 51/64 loss: -2.7131643295288086
Batch 52/64 loss: -2.686282157897949
Batch 53/64 loss: -2.645418167114258
Batch 54/64 loss: -2.56234073638916
Batch 55/64 loss: -2.7182798385620117
Batch 56/64 loss: -2.0968313217163086
Batch 57/64 loss: -2.9812545776367188
Batch 58/64 loss: -2.482603073120117
Batch 59/64 loss: -2.4270381927490234
Batch 60/64 loss: -2.8339128494262695
Batch 61/64 loss: -2.661942481994629
Batch 62/64 loss: -2.833815574645996
Batch 63/64 loss: -3.012327194213867
Batch 64/64 loss: -7.240735054016113
Epoch 415  Train loss: -2.7644528220681583  Val loss: -3.1117258366850233
Epoch 416
-------------------------------
Batch 1/64 loss: -2.809551239013672
Batch 2/64 loss: -2.659402847290039
Batch 3/64 loss: -3.08089542388916
Batch 4/64 loss: -2.1199378967285156
Batch 5/64 loss: -2.9040746688842773
Batch 6/64 loss: -2.9592323303222656
Batch 7/64 loss: -2.9729557037353516
Batch 8/64 loss: -2.606133460998535
Batch 9/64 loss: -2.6529808044433594
Batch 10/64 loss: -2.8995370864868164
Batch 11/64 loss: -2.9325380325317383
Batch 12/64 loss: -2.9065933227539062
Batch 13/64 loss: -2.8769102096557617
Batch 14/64 loss: -2.129847526550293
Batch 15/64 loss: -3.104785919189453
Batch 16/64 loss: -2.608379364013672
Batch 17/64 loss: -2.5797128677368164
Batch 18/64 loss: -2.4242172241210938
Batch 19/64 loss: -2.8100175857543945
Batch 20/64 loss: -2.8565711975097656
Batch 21/64 loss: -2.888401985168457
Batch 22/64 loss: -2.7481136322021484
Batch 23/64 loss: -2.696619987487793
Batch 24/64 loss: -2.6310863494873047
Batch 25/64 loss: -2.6779727935791016
Batch 26/64 loss: -2.8879776000976562
Batch 27/64 loss: -2.7545595169067383
Batch 28/64 loss: -2.429117202758789
Batch 29/64 loss: -2.9632644653320312
Batch 30/64 loss: -2.7155818939208984
Batch 31/64 loss: -2.8977584838867188
Batch 32/64 loss: -2.742044448852539
Batch 33/64 loss: -2.536107063293457
Batch 34/64 loss: -2.869297981262207
Batch 35/64 loss: -2.854890823364258
Batch 36/64 loss: -2.854114532470703
Batch 37/64 loss: -2.848324775695801
Batch 38/64 loss: -2.034587860107422
Batch 39/64 loss: -2.7449264526367188
Batch 40/64 loss: -2.5108394622802734
Batch 41/64 loss: -2.8440942764282227
Batch 42/64 loss: -2.9180221557617188
Batch 43/64 loss: -2.9812498092651367
Batch 44/64 loss: -2.6478023529052734
Batch 45/64 loss: -2.6755638122558594
Batch 46/64 loss: -2.9776229858398438
Batch 47/64 loss: -2.5672760009765625
Batch 48/64 loss: -2.7010889053344727
Batch 49/64 loss: -2.7955408096313477
Batch 50/64 loss: -2.970592498779297
Batch 51/64 loss: -3.0096683502197266
Batch 52/64 loss: -2.6763839721679688
Batch 53/64 loss: -2.8476438522338867
Batch 54/64 loss: -2.0090560913085938
Batch 55/64 loss: -2.72487735748291
Batch 56/64 loss: -2.836907386779785
Batch 57/64 loss: -2.8175649642944336
Batch 58/64 loss: -2.4654970169067383
Batch 59/64 loss: -2.9307594299316406
Batch 60/64 loss: -2.7946109771728516
Batch 61/64 loss: -2.760160446166992
Batch 62/64 loss: -2.7267074584960938
Batch 63/64 loss: -2.743758201599121
Batch 64/64 loss: -7.525162696838379
Epoch 416  Train loss: -2.796018559324975  Val loss: -3.2235722623739864
Epoch 417
-------------------------------
Batch 1/64 loss: -2.9478988647460938
Batch 2/64 loss: -2.856318473815918
Batch 3/64 loss: -2.6978511810302734
Batch 4/64 loss: -2.313408851623535
Batch 5/64 loss: -2.82930850982666
Batch 6/64 loss: -2.9243593215942383
Batch 7/64 loss: -2.90731143951416
Batch 8/64 loss: -2.075298309326172
Batch 9/64 loss: -2.199519157409668
Batch 10/64 loss: -2.725935935974121
Batch 11/64 loss: -2.6986913681030273
Batch 12/64 loss: -2.834162712097168
Batch 13/64 loss: -2.9453125
Batch 14/64 loss: -2.861469268798828
Batch 15/64 loss: -2.8184995651245117
Batch 16/64 loss: -2.8270912170410156
Batch 17/64 loss: -2.5352296829223633
Batch 18/64 loss: -2.8843460083007812
Batch 19/64 loss: -2.6468067169189453
Batch 20/64 loss: -3.0139780044555664
Batch 21/64 loss: -2.876689910888672
Batch 22/64 loss: -2.8132877349853516
Batch 23/64 loss: -2.7333459854125977
Batch 24/64 loss: -2.8217477798461914
Batch 25/64 loss: -2.5751256942749023
Batch 26/64 loss: -2.888941764831543
Batch 27/64 loss: -2.84261417388916
Batch 28/64 loss: -2.9397783279418945
Batch 29/64 loss: -2.130178451538086
Batch 30/64 loss: -2.9572391510009766
Batch 31/64 loss: -2.7575302124023438
Batch 32/64 loss: -2.993779182434082
Batch 33/64 loss: -2.418084144592285
Batch 34/64 loss: -2.547417640686035
Batch 35/64 loss: -2.5339956283569336
Batch 36/64 loss: -2.592625617980957
Batch 37/64 loss: -2.8229598999023438
Batch 38/64 loss: -2.8598737716674805
Batch 39/64 loss: -2.429412841796875
Batch 40/64 loss: -2.580036163330078
Batch 41/64 loss: -2.7479028701782227
Batch 42/64 loss: -2.7039709091186523
Batch 43/64 loss: -2.709599494934082
Batch 44/64 loss: -2.6162586212158203
Batch 45/64 loss: -2.8397817611694336
Batch 46/64 loss: -2.8527956008911133
Batch 47/64 loss: -2.5932369232177734
Batch 48/64 loss: -2.8917741775512695
Batch 49/64 loss: -2.522244453430176
Batch 50/64 loss: -2.7987289428710938
Batch 51/64 loss: -2.5738391876220703
Batch 52/64 loss: -2.842495918273926
Batch 53/64 loss: -2.4309730529785156
Batch 54/64 loss: -2.8847532272338867
Batch 55/64 loss: -2.6582231521606445
Batch 56/64 loss: -2.7950897216796875
Batch 57/64 loss: -2.935917854309082
Batch 58/64 loss: -2.8530378341674805
Batch 59/64 loss: -2.596384048461914
Batch 60/64 loss: -2.6424150466918945
Batch 61/64 loss: -2.799685478210449
Batch 62/64 loss: -2.626495361328125
Batch 63/64 loss: -2.606618881225586
Batch 64/64 loss: -7.319483757019043
Epoch 417  Train loss: -2.7712830824010513  Val loss: -3.0742463967234817
Epoch 418
-------------------------------
Batch 1/64 loss: -2.62929630279541
Batch 2/64 loss: -2.5141468048095703
Batch 3/64 loss: -2.5134925842285156
Batch 4/64 loss: -2.5631046295166016
Batch 5/64 loss: -2.672787666320801
Batch 6/64 loss: -2.845165252685547
Batch 7/64 loss: -2.9606542587280273
Batch 8/64 loss: -2.146822929382324
Batch 9/64 loss: -2.8116378784179688
Batch 10/64 loss: -2.8528079986572266
Batch 11/64 loss: -2.520750045776367
Batch 12/64 loss: -2.7604379653930664
Batch 13/64 loss: -2.9355831146240234
Batch 14/64 loss: -2.623699188232422
Batch 15/64 loss: -2.812129020690918
Batch 16/64 loss: -2.6288442611694336
Batch 17/64 loss: -2.840184211730957
Batch 18/64 loss: -2.8185300827026367
Batch 19/64 loss: -2.9695043563842773
Batch 20/64 loss: -2.8860645294189453
Batch 21/64 loss: -2.68595027923584
Batch 22/64 loss: -2.823246955871582
Batch 23/64 loss: -2.742490768432617
Batch 24/64 loss: -2.7245912551879883
Batch 25/64 loss: -2.942201614379883
Batch 26/64 loss: -2.450873374938965
Batch 27/64 loss: -2.8048954010009766
Batch 28/64 loss: -2.7802352905273438
Batch 29/64 loss: -2.792093276977539
Batch 30/64 loss: -2.8380870819091797
Batch 31/64 loss: -2.993572235107422
Batch 32/64 loss: -2.94370174407959
Batch 33/64 loss: -2.569270133972168
Batch 34/64 loss: -2.1776819229125977
Batch 35/64 loss: -2.5722103118896484
Batch 36/64 loss: -2.800241470336914
Batch 37/64 loss: -2.7641258239746094
Batch 38/64 loss: -2.6793127059936523
Batch 39/64 loss: -2.927753448486328
Batch 40/64 loss: -2.7970657348632812
Batch 41/64 loss: -2.8148727416992188
Batch 42/64 loss: -2.6955699920654297
Batch 43/64 loss: -2.9568490982055664
Batch 44/64 loss: -3.0000181198120117
Batch 45/64 loss: -2.463411331176758
Batch 46/64 loss: -2.774494171142578
Batch 47/64 loss: -2.6291112899780273
Batch 48/64 loss: -2.660628318786621
Batch 49/64 loss: -2.82427978515625
Batch 50/64 loss: -2.396023750305176
Batch 51/64 loss: -2.833375930786133
Batch 52/64 loss: -2.773190498352051
Batch 53/64 loss: -2.629098892211914
Batch 54/64 loss: -2.757502555847168
Batch 55/64 loss: -2.963141441345215
Batch 56/64 loss: -2.6853723526000977
Batch 57/64 loss: -2.692704200744629
Batch 58/64 loss: -2.800328254699707
Batch 59/64 loss: -2.8460464477539062
Batch 60/64 loss: -2.962291717529297
Batch 61/64 loss: -2.866095542907715
Batch 62/64 loss: -2.848539352416992
Batch 63/64 loss: -2.8368005752563477
Batch 64/64 loss: -7.287472724914551
Epoch 418  Train loss: -2.796715212803261  Val loss: -3.0889984733869937
Epoch 419
-------------------------------
Batch 1/64 loss: -2.9718856811523438
Batch 2/64 loss: -2.7774667739868164
Batch 3/64 loss: -2.805636405944824
Batch 4/64 loss: -2.901951789855957
Batch 5/64 loss: -2.709834098815918
Batch 6/64 loss: -2.7575111389160156
Batch 7/64 loss: -2.22845458984375
Batch 8/64 loss: -2.527155876159668
Batch 9/64 loss: -2.8367176055908203
Batch 10/64 loss: -1.6779565811157227
Batch 11/64 loss: -2.0789260864257812
Batch 12/64 loss: -2.879884719848633
Batch 13/64 loss: -2.945683479309082
Batch 14/64 loss: -2.9361696243286133
Batch 15/64 loss: -2.6990652084350586
Batch 16/64 loss: -2.5317153930664062
Batch 17/64 loss: -2.583066940307617
Batch 18/64 loss: -2.8371686935424805
Batch 19/64 loss: -2.938661575317383
Batch 20/64 loss: -2.7587995529174805
Batch 21/64 loss: -2.55332088470459
Batch 22/64 loss: -2.9096670150756836
Batch 23/64 loss: -2.7225866317749023
Batch 24/64 loss: -2.70263671875
Batch 25/64 loss: -2.786996841430664
Batch 26/64 loss: -2.7716569900512695
Batch 27/64 loss: -2.986483573913574
Batch 28/64 loss: -2.86745548248291
Batch 29/64 loss: -2.7378692626953125
Batch 30/64 loss: -2.912051200866699
Batch 31/64 loss: -2.777383804321289
Batch 32/64 loss: -2.669504165649414
Batch 33/64 loss: -2.793684959411621
Batch 34/64 loss: -2.576547622680664
Batch 35/64 loss: -2.9178876876831055
Batch 36/64 loss: -2.5692176818847656
Batch 37/64 loss: -2.810540199279785
Batch 38/64 loss: -2.597156524658203
Batch 39/64 loss: -2.9572324752807617
Batch 40/64 loss: -2.7592830657958984
Batch 41/64 loss: -2.662899971008301
Batch 42/64 loss: -2.252617835998535
Batch 43/64 loss: -2.885629653930664
Batch 44/64 loss: -3.0229129791259766
Batch 45/64 loss: -2.9220876693725586
Batch 46/64 loss: -2.8857812881469727
Batch 47/64 loss: -2.9148740768432617
Batch 48/64 loss: -2.9177560806274414
Batch 49/64 loss: -2.5831823348999023
Batch 50/64 loss: -2.122926712036133
Batch 51/64 loss: -2.7980947494506836
Batch 52/64 loss: -2.7650928497314453
Batch 53/64 loss: -2.8317270278930664
Batch 54/64 loss: -2.773042678833008
Batch 55/64 loss: -2.981268882751465
Batch 56/64 loss: -2.800809860229492
Batch 57/64 loss: -2.8204450607299805
Batch 58/64 loss: -2.9962358474731445
Batch 59/64 loss: -2.645869255065918
Batch 60/64 loss: -2.4026193618774414
Batch 61/64 loss: -2.8634653091430664
Batch 62/64 loss: -2.9635696411132812
Batch 63/64 loss: -2.878742218017578
Batch 64/64 loss: -7.412693977355957
Epoch 419  Train loss: -2.7923771989111805  Val loss: -3.199213204924593
Epoch 420
-------------------------------
Batch 1/64 loss: -2.8298940658569336
Batch 2/64 loss: -2.330167770385742
Batch 3/64 loss: -2.723862648010254
Batch 4/64 loss: -2.939608573913574
Batch 5/64 loss: -2.6459293365478516
Batch 6/64 loss: -2.677785873413086
Batch 7/64 loss: -2.791924476623535
Batch 8/64 loss: -2.455110549926758
Batch 9/64 loss: -2.899672508239746
Batch 10/64 loss: -2.5937509536743164
Batch 11/64 loss: -2.72268009185791
Batch 12/64 loss: -2.980630874633789
Batch 13/64 loss: -2.8381452560424805
Batch 14/64 loss: -2.7698678970336914
Batch 15/64 loss: -2.889561653137207
Batch 16/64 loss: -2.958040237426758
Batch 17/64 loss: -2.91518497467041
Batch 18/64 loss: -2.7172365188598633
Batch 19/64 loss: -2.9591455459594727
Batch 20/64 loss: -2.9843873977661133
Batch 21/64 loss: -2.979654312133789
Batch 22/64 loss: -2.9319725036621094
Batch 23/64 loss: -2.7889938354492188
Batch 24/64 loss: -2.4624624252319336
Batch 25/64 loss: -2.7563304901123047
Batch 26/64 loss: -2.7358484268188477
Batch 27/64 loss: -2.924999237060547
Batch 28/64 loss: -2.889401435852051
Batch 29/64 loss: -2.8396244049072266
Batch 30/64 loss: -2.818171501159668
Batch 31/64 loss: -2.862778663635254
Batch 32/64 loss: -2.705028533935547
Batch 33/64 loss: -2.7452402114868164
Batch 34/64 loss: -2.5729827880859375
Batch 35/64 loss: -2.599024772644043
Batch 36/64 loss: -2.762388229370117
Batch 37/64 loss: -2.8402671813964844
Batch 38/64 loss: -2.936915397644043
Batch 39/64 loss: -2.919679641723633
Batch 40/64 loss: -2.787989616394043
Batch 41/64 loss: -2.5355939865112305
Batch 42/64 loss: -2.801168441772461
Batch 43/64 loss: -2.9589853286743164
Batch 44/64 loss: -2.8130884170532227
Batch 45/64 loss: -3.0020618438720703
Batch 46/64 loss: -2.7030029296875
Batch 47/64 loss: -2.366016387939453
Batch 48/64 loss: -2.9045801162719727
Batch 49/64 loss: -2.930426597595215
Batch 50/64 loss: -2.5632314682006836
Batch 51/64 loss: -2.881134033203125
Batch 52/64 loss: -2.5542469024658203
Batch 53/64 loss: -2.623584747314453
Batch 54/64 loss: -2.7696094512939453
Batch 55/64 loss: -2.9002723693847656
Batch 56/64 loss: -1.9808387756347656
Batch 57/64 loss: -2.867434501647949
Batch 58/64 loss: -2.633364677429199
Batch 59/64 loss: -2.9232559204101562
Batch 60/64 loss: -2.446361541748047
Batch 61/64 loss: -2.8690414428710938
Batch 62/64 loss: -2.6764020919799805
Batch 63/64 loss: -2.655200958251953
Batch 64/64 loss: -7.231351375579834
Epoch 420  Train loss: -2.811996192558139  Val loss: -3.060430310436131
Epoch 421
-------------------------------
Batch 1/64 loss: -2.7551279067993164
Batch 2/64 loss: -2.679157257080078
Batch 3/64 loss: -2.6141300201416016
Batch 4/64 loss: -2.8507728576660156
Batch 5/64 loss: -2.823467254638672
Batch 6/64 loss: -2.797940254211426
Batch 7/64 loss: -2.959096908569336
Batch 8/64 loss: -2.934140205383301
Batch 9/64 loss: -2.8854827880859375
Batch 10/64 loss: -2.6494216918945312
Batch 11/64 loss: -2.982767105102539
Batch 12/64 loss: -2.9115896224975586
Batch 13/64 loss: -2.9641971588134766
Batch 14/64 loss: -2.7212743759155273
Batch 15/64 loss: -2.756732940673828
Batch 16/64 loss: -2.7436466217041016
Batch 17/64 loss: -2.8247194290161133
Batch 18/64 loss: -2.5831336975097656
Batch 19/64 loss: -2.84867000579834
Batch 20/64 loss: -2.8356332778930664
Batch 21/64 loss: -2.526352882385254
Batch 22/64 loss: -2.787440299987793
Batch 23/64 loss: -2.7257680892944336
Batch 24/64 loss: -2.6247634887695312
Batch 25/64 loss: -2.946047782897949
Batch 26/64 loss: -2.9065027236938477
Batch 27/64 loss: -2.9133710861206055
Batch 28/64 loss: -2.7422895431518555
Batch 29/64 loss: -2.7056827545166016
Batch 30/64 loss: -2.7954301834106445
Batch 31/64 loss: -2.507960319519043
Batch 32/64 loss: -2.858248710632324
Batch 33/64 loss: -2.003643035888672
Batch 34/64 loss: -3.0380630493164062
Batch 35/64 loss: -2.902388572692871
Batch 36/64 loss: -2.8839406967163086
Batch 37/64 loss: -2.8096046447753906
Batch 38/64 loss: -2.151498794555664
Batch 39/64 loss: -2.818235397338867
Batch 40/64 loss: -2.7169761657714844
Batch 41/64 loss: -3.03902530670166
Batch 42/64 loss: -2.629349708557129
Batch 43/64 loss: -2.8774003982543945
Batch 44/64 loss: -2.90041446685791
Batch 45/64 loss: -3.1398983001708984
Batch 46/64 loss: -2.64285945892334
Batch 47/64 loss: -2.8454580307006836
Batch 48/64 loss: -2.9574804306030273
Batch 49/64 loss: -3.051197052001953
Batch 50/64 loss: -2.814560890197754
Batch 51/64 loss: -2.9360437393188477
Batch 52/64 loss: -2.9579973220825195
Batch 53/64 loss: -2.9463205337524414
Batch 54/64 loss: -2.867678642272949
Batch 55/64 loss: -2.9520931243896484
Batch 56/64 loss: -2.4897966384887695
Batch 57/64 loss: -2.9775009155273438
Batch 58/64 loss: -2.74273681640625
Batch 59/64 loss: -2.845743179321289
Batch 60/64 loss: -2.5937137603759766
Batch 61/64 loss: -2.8710289001464844
Batch 62/64 loss: -2.798232078552246
Batch 63/64 loss: -2.6391191482543945
Batch 64/64 loss: -7.278975486755371
Epoch 421  Train loss: -2.8464343538471297  Val loss: -3.182377385929278
Epoch 422
-------------------------------
Batch 1/64 loss: -2.951674461364746
Batch 2/64 loss: -2.756967544555664
Batch 3/64 loss: -1.788283348083496
Batch 4/64 loss: -2.771028518676758
Batch 5/64 loss: -2.643437385559082
Batch 6/64 loss: -2.6273603439331055
Batch 7/64 loss: -3.0287160873413086
Batch 8/64 loss: -2.9587173461914062
Batch 9/64 loss: -2.8054771423339844
Batch 10/64 loss: -2.8653507232666016
Batch 11/64 loss: -2.689311981201172
Batch 12/64 loss: -2.8450355529785156
Batch 13/64 loss: -2.8818111419677734
Batch 14/64 loss: -3.033693313598633
Batch 15/64 loss: -2.793956756591797
Batch 16/64 loss: -2.669356346130371
Batch 17/64 loss: -2.7283010482788086
Batch 18/64 loss: -3.012091636657715
Batch 19/64 loss: -2.5035457611083984
Batch 20/64 loss: -2.700249671936035
Batch 21/64 loss: -2.3633193969726562
Batch 22/64 loss: -2.644148826599121
Batch 23/64 loss: -2.9107236862182617
Batch 24/64 loss: -2.291576385498047
Batch 25/64 loss: -2.8868560791015625
Batch 26/64 loss: -2.8036603927612305
Batch 27/64 loss: -2.739995002746582
Batch 28/64 loss: -3.0341672897338867
Batch 29/64 loss: -2.787189483642578
Batch 30/64 loss: -2.9964914321899414
Batch 31/64 loss: -2.607285499572754
Batch 32/64 loss: -2.981128692626953
Batch 33/64 loss: -2.901057243347168
Batch 34/64 loss: -3.08109188079834
Batch 35/64 loss: -2.912933349609375
Batch 36/64 loss: -2.7512149810791016
Batch 37/64 loss: -2.8598880767822266
Batch 38/64 loss: -2.936796188354492
Batch 39/64 loss: -2.7177515029907227
Batch 40/64 loss: -2.84588623046875
Batch 41/64 loss: -2.8060359954833984
Batch 42/64 loss: -2.9164276123046875
Batch 43/64 loss: -2.7605533599853516
Batch 44/64 loss: -2.8578662872314453
Batch 45/64 loss: -2.7504501342773438
Batch 46/64 loss: -2.9135732650756836
Batch 47/64 loss: -2.6862850189208984
Batch 48/64 loss: -2.7143383026123047
Batch 49/64 loss: -2.7807130813598633
Batch 50/64 loss: -2.837479591369629
Batch 51/64 loss: -2.708730697631836
Batch 52/64 loss: -2.8235206604003906
Batch 53/64 loss: -2.553743362426758
Batch 54/64 loss: -2.8988046646118164
Batch 55/64 loss: -2.649949073791504
Batch 56/64 loss: -2.7874584197998047
Batch 57/64 loss: -2.9019031524658203
Batch 58/64 loss: -2.993168830871582
Batch 59/64 loss: -2.8140945434570312
Batch 60/64 loss: -2.8635129928588867
Batch 61/64 loss: -3.019926071166992
Batch 62/64 loss: -2.8223838806152344
Batch 63/64 loss: -2.9520912170410156
Batch 64/64 loss: -7.393006324768066
Epoch 422  Train loss: -2.846514395171521  Val loss: -3.1207384194705083
Epoch 423
-------------------------------
Batch 1/64 loss: -2.8015975952148438
Batch 2/64 loss: -2.7431840896606445
Batch 3/64 loss: -2.981168746948242
Batch 4/64 loss: -2.739302635192871
Batch 5/64 loss: -2.630002021789551
Batch 6/64 loss: -2.6415786743164062
Batch 7/64 loss: -2.7583932876586914
Batch 8/64 loss: -2.9750614166259766
Batch 9/64 loss: -2.871628761291504
Batch 10/64 loss: -2.9700727462768555
Batch 11/64 loss: -2.691082000732422
Batch 12/64 loss: -3.070444107055664
Batch 13/64 loss: -2.7271127700805664
Batch 14/64 loss: -2.887993812561035
Batch 15/64 loss: -2.5950546264648438
Batch 16/64 loss: -2.372288703918457
Batch 17/64 loss: -2.7454118728637695
Batch 18/64 loss: -2.9243574142456055
Batch 19/64 loss: -2.807281494140625
Batch 20/64 loss: -2.7494802474975586
Batch 21/64 loss: -2.704486846923828
Batch 22/64 loss: -2.234354019165039
Batch 23/64 loss: -2.6981687545776367
Batch 24/64 loss: -2.4626502990722656
Batch 25/64 loss: -2.90042781829834
Batch 26/64 loss: -2.943739891052246
Batch 27/64 loss: -2.80279541015625
Batch 28/64 loss: -2.5857162475585938
Batch 29/64 loss: -3.059398651123047
Batch 30/64 loss: -2.514982223510742
Batch 31/64 loss: -2.6598758697509766
Batch 32/64 loss: -2.8722476959228516
Batch 33/64 loss: -2.7371950149536133
Batch 34/64 loss: -2.7133893966674805
Batch 35/64 loss: -2.8258886337280273
Batch 36/64 loss: -2.9369335174560547
Batch 37/64 loss: -2.7838916778564453
Batch 38/64 loss: -2.832087516784668
Batch 39/64 loss: -2.8558473587036133
Batch 40/64 loss: -2.8180789947509766
Batch 41/64 loss: -2.7981605529785156
Batch 42/64 loss: -2.7661447525024414
Batch 43/64 loss: -2.871845245361328
Batch 44/64 loss: -2.521604537963867
Batch 45/64 loss: -2.9683141708374023
Batch 46/64 loss: -2.971076011657715
Batch 47/64 loss: -3.021730422973633
Batch 48/64 loss: -2.5866289138793945
Batch 49/64 loss: -2.999013900756836
Batch 50/64 loss: -2.756289482116699
Batch 51/64 loss: -2.833219528198242
Batch 52/64 loss: -2.7553882598876953
Batch 53/64 loss: -2.541728973388672
Batch 54/64 loss: -2.895456314086914
Batch 55/64 loss: -2.790742874145508
Batch 56/64 loss: -2.4555530548095703
Batch 57/64 loss: -2.993856430053711
Batch 58/64 loss: -2.920948028564453
Batch 59/64 loss: -2.982166290283203
Batch 60/64 loss: -2.703857421875
Batch 61/64 loss: -2.802687644958496
Batch 62/64 loss: -2.8543901443481445
Batch 63/64 loss: -2.767754554748535
Batch 64/64 loss: -7.261346817016602
Epoch 423  Train loss: -2.833399537030388  Val loss: -3.10301093137551
Epoch 424
-------------------------------
Batch 1/64 loss: -2.3716115951538086
Batch 2/64 loss: -2.264432907104492
Batch 3/64 loss: -2.571333885192871
Batch 4/64 loss: -2.872866630554199
Batch 5/64 loss: -2.866973876953125
Batch 6/64 loss: -2.7969913482666016
Batch 7/64 loss: -2.815431594848633
Batch 8/64 loss: -2.4755964279174805
Batch 9/64 loss: -2.742682456970215
Batch 10/64 loss: -2.5035552978515625
Batch 11/64 loss: -2.1100940704345703
Batch 12/64 loss: -2.1440839767456055
Batch 13/64 loss: -2.7359933853149414
Batch 14/64 loss: -2.8543453216552734
Batch 15/64 loss: -2.670567512512207
Batch 16/64 loss: -2.8032188415527344
Batch 17/64 loss: -2.721141815185547
Batch 18/64 loss: -2.8938770294189453
Batch 19/64 loss: -2.576448440551758
Batch 20/64 loss: -2.8423080444335938
Batch 21/64 loss: -2.8037948608398438
Batch 22/64 loss: -2.814901351928711
Batch 23/64 loss: -2.8304548263549805
Batch 24/64 loss: -2.768916130065918
Batch 25/64 loss: -2.944286346435547
Batch 26/64 loss: -2.8765602111816406
Batch 27/64 loss: -2.515347480773926
Batch 28/64 loss: -2.8131113052368164
Batch 29/64 loss: -2.7558813095092773
Batch 30/64 loss: -2.8649282455444336
Batch 31/64 loss: -2.8076162338256836
Batch 32/64 loss: -2.938966751098633
Batch 33/64 loss: -2.959707260131836
Batch 34/64 loss: -2.7983570098876953
Batch 35/64 loss: -2.869861602783203
Batch 36/64 loss: -2.7082786560058594
Batch 37/64 loss: -2.6815948486328125
Batch 38/64 loss: -2.7828617095947266
Batch 39/64 loss: -2.604808807373047
Batch 40/64 loss: -2.853649139404297
Batch 41/64 loss: -2.6947946548461914
Batch 42/64 loss: -2.9680471420288086
Batch 43/64 loss: -2.546224594116211
Batch 44/64 loss: -2.6591358184814453
Batch 45/64 loss: -2.5093002319335938
Batch 46/64 loss: -2.8685407638549805
Batch 47/64 loss: -2.9740304946899414
Batch 48/64 loss: -2.826040267944336
Batch 49/64 loss: -2.758795738220215
Batch 50/64 loss: -2.718461036682129
Batch 51/64 loss: -2.8172683715820312
Batch 52/64 loss: -2.853565216064453
Batch 53/64 loss: -2.8946104049682617
Batch 54/64 loss: -2.8171777725219727
Batch 55/64 loss: -3.000372886657715
Batch 56/64 loss: -2.826427459716797
Batch 57/64 loss: -2.9508800506591797
Batch 58/64 loss: -2.931608200073242
Batch 59/64 loss: -2.8573970794677734
Batch 60/64 loss: -2.5957937240600586
Batch 61/64 loss: -2.7496509552001953
Batch 62/64 loss: -2.578568458557129
Batch 63/64 loss: -2.8675365447998047
Batch 64/64 loss: -7.383131980895996
Epoch 424  Train loss: -2.798886516047459  Val loss: -3.163927687812097
Epoch 425
-------------------------------
Batch 1/64 loss: -2.973526954650879
Batch 2/64 loss: -2.734159469604492
Batch 3/64 loss: -2.843027114868164
Batch 4/64 loss: -2.894937515258789
Batch 5/64 loss: -2.7132091522216797
Batch 6/64 loss: -2.736971855163574
Batch 7/64 loss: -2.872063636779785
Batch 8/64 loss: -2.7064685821533203
Batch 9/64 loss: -2.546769142150879
Batch 10/64 loss: -2.6997146606445312
Batch 11/64 loss: -2.780470848083496
Batch 12/64 loss: -2.8970184326171875
Batch 13/64 loss: -2.5174131393432617
Batch 14/64 loss: -1.6782236099243164
Batch 15/64 loss: -2.887495994567871
Batch 16/64 loss: -2.636259078979492
Batch 17/64 loss: -2.744509696960449
Batch 18/64 loss: -2.834244728088379
Batch 19/64 loss: -2.822972297668457
Batch 20/64 loss: -2.5363283157348633
Batch 21/64 loss: -2.7249794006347656
Batch 22/64 loss: -2.6700191497802734
Batch 23/64 loss: -2.84061336517334
Batch 24/64 loss: -2.525930404663086
Batch 25/64 loss: -2.2285280227661133
Batch 26/64 loss: -2.795132637023926
Batch 27/64 loss: -2.8287363052368164
Batch 28/64 loss: -2.8258275985717773
Batch 29/64 loss: -2.597886085510254
Batch 30/64 loss: -2.7544193267822266
Batch 31/64 loss: -2.8326215744018555
Batch 32/64 loss: -2.747926712036133
Batch 33/64 loss: -2.6352014541625977
Batch 34/64 loss: -2.990236282348633
Batch 35/64 loss: -2.9543914794921875
Batch 36/64 loss: -2.921487808227539
Batch 37/64 loss: -2.5404815673828125
Batch 38/64 loss: -2.757099151611328
Batch 39/64 loss: -2.635784149169922
Batch 40/64 loss: -2.420628547668457
Batch 41/64 loss: -2.638064384460449
Batch 42/64 loss: -2.71762752532959
Batch 43/64 loss: -2.671144485473633
Batch 44/64 loss: -2.779871940612793
Batch 45/64 loss: -2.6026039123535156
Batch 46/64 loss: -2.8192405700683594
Batch 47/64 loss: -2.800044059753418
Batch 48/64 loss: -2.6545534133911133
Batch 49/64 loss: -2.7460765838623047
Batch 50/64 loss: -2.8201255798339844
Batch 51/64 loss: -2.670102119445801
Batch 52/64 loss: -2.7866268157958984
Batch 53/64 loss: -2.8636465072631836
Batch 54/64 loss: -2.823479652404785
Batch 55/64 loss: -2.584662437438965
Batch 56/64 loss: -2.97189998626709
Batch 57/64 loss: -2.908487319946289
Batch 58/64 loss: -2.709733009338379
Batch 59/64 loss: -2.5315065383911133
Batch 60/64 loss: -2.2526426315307617
Batch 61/64 loss: -2.83657169342041
Batch 62/64 loss: -2.8763084411621094
Batch 63/64 loss: -2.7326831817626953
Batch 64/64 loss: -7.297377109527588
Epoch 425  Train loss: -2.7694815822676118  Val loss: -3.051852301633645
Epoch 426
-------------------------------
Batch 1/64 loss: -2.8287792205810547
Batch 2/64 loss: -2.7112531661987305
Batch 3/64 loss: -2.8374385833740234
Batch 4/64 loss: -2.708890914916992
Batch 5/64 loss: -2.800784111022949
Batch 6/64 loss: -2.7462873458862305
Batch 7/64 loss: -2.900829315185547
Batch 8/64 loss: -2.886079788208008
Batch 9/64 loss: -2.545673370361328
Batch 10/64 loss: -2.851909637451172
Batch 11/64 loss: -2.892038345336914
Batch 12/64 loss: -2.746438980102539
Batch 13/64 loss: -2.915186882019043
Batch 14/64 loss: -3.016547203063965
Batch 15/64 loss: -2.6906299591064453
Batch 16/64 loss: -2.8338356018066406
Batch 17/64 loss: -2.9180727005004883
Batch 18/64 loss: -2.7846412658691406
Batch 19/64 loss: -2.8106489181518555
Batch 20/64 loss: -2.7693309783935547
Batch 21/64 loss: -2.7006397247314453
Batch 22/64 loss: -2.905374526977539
Batch 23/64 loss: -2.712888717651367
Batch 24/64 loss: -2.6002626419067383
Batch 25/64 loss: -2.886690139770508
Batch 26/64 loss: -2.7476892471313477
Batch 27/64 loss: -2.7593870162963867
Batch 28/64 loss: -2.6181440353393555
Batch 29/64 loss: -2.5873146057128906
Batch 30/64 loss: -2.7799787521362305
Batch 31/64 loss: -2.1930789947509766
Batch 32/64 loss: -2.621797561645508
Batch 33/64 loss: -2.6138410568237305
Batch 34/64 loss: -2.989560127258301
Batch 35/64 loss: -2.5273818969726562
Batch 36/64 loss: -2.8217077255249023
Batch 37/64 loss: -2.709343910217285
Batch 38/64 loss: -2.8420257568359375
Batch 39/64 loss: -2.830132484436035
Batch 40/64 loss: -2.585932731628418
Batch 41/64 loss: -2.635892868041992
Batch 42/64 loss: -2.6436824798583984
Batch 43/64 loss: -2.73079776763916
Batch 44/64 loss: -2.8622703552246094
Batch 45/64 loss: -2.586761474609375
Batch 46/64 loss: -2.267216682434082
Batch 47/64 loss: -2.895016670227051
Batch 48/64 loss: -2.765719413757324
Batch 49/64 loss: -2.8998937606811523
Batch 50/64 loss: -2.4415483474731445
Batch 51/64 loss: -2.8325042724609375
Batch 52/64 loss: -2.92789363861084
Batch 53/64 loss: -2.8789596557617188
Batch 54/64 loss: -2.852022171020508
Batch 55/64 loss: -2.714252471923828
Batch 56/64 loss: -2.854856491088867
Batch 57/64 loss: -2.106806755065918
Batch 58/64 loss: -2.969183921813965
Batch 59/64 loss: -2.6897897720336914
Batch 60/64 loss: -2.701326370239258
Batch 61/64 loss: -2.83587646484375
Batch 62/64 loss: -2.85550594329834
Batch 63/64 loss: -2.905604362487793
Batch 64/64 loss: -7.283562660217285
Epoch 426  Train loss: -2.8006983850516525  Val loss: -3.148661806821004
Epoch 427
-------------------------------
Batch 1/64 loss: -2.6949872970581055
Batch 2/64 loss: -2.8945770263671875
Batch 3/64 loss: -2.752251625061035
Batch 4/64 loss: -2.760556221008301
Batch 5/64 loss: -2.9006357192993164
Batch 6/64 loss: -2.231318473815918
Batch 7/64 loss: -2.885711669921875
Batch 8/64 loss: -2.964907646179199
Batch 9/64 loss: -2.379378318786621
Batch 10/64 loss: -2.8702192306518555
Batch 11/64 loss: -2.9387922286987305
Batch 12/64 loss: -2.2140274047851562
Batch 13/64 loss: -2.779179573059082
Batch 14/64 loss: -3.0446701049804688
Batch 15/64 loss: -2.7958059310913086
Batch 16/64 loss: -2.92486572265625
Batch 17/64 loss: -2.753335952758789
Batch 18/64 loss: -2.719590187072754
Batch 19/64 loss: -3.0056333541870117
Batch 20/64 loss: -2.844320297241211
Batch 21/64 loss: -2.242799758911133
Batch 22/64 loss: -2.8996267318725586
Batch 23/64 loss: -2.8336172103881836
Batch 24/64 loss: -2.8009538650512695
Batch 25/64 loss: -2.861618995666504
Batch 26/64 loss: -2.6572704315185547
Batch 27/64 loss: -2.704671859741211
Batch 28/64 loss: -2.84674072265625
Batch 29/64 loss: -2.793231964111328
Batch 30/64 loss: -2.9070892333984375
Batch 31/64 loss: -2.7606372833251953
Batch 32/64 loss: -2.8458690643310547
Batch 33/64 loss: -2.595043182373047
Batch 34/64 loss: -2.6517982482910156
Batch 35/64 loss: -2.750290870666504
Batch 36/64 loss: -2.823531150817871
Batch 37/64 loss: -2.5567026138305664
Batch 38/64 loss: -2.689838409423828
Batch 39/64 loss: -2.7745132446289062
Batch 40/64 loss: -2.7316627502441406
Batch 41/64 loss: -2.981013298034668
Batch 42/64 loss: -2.870884895324707
Batch 43/64 loss: -2.784576416015625
Batch 44/64 loss: -2.69516658782959
Batch 45/64 loss: -2.831724166870117
Batch 46/64 loss: -2.7638845443725586
Batch 47/64 loss: -2.877591133117676
Batch 48/64 loss: -2.8562698364257812
Batch 49/64 loss: -2.6787185668945312
Batch 50/64 loss: -2.984834671020508
Batch 51/64 loss: -2.8822555541992188
Batch 52/64 loss: -3.006312370300293
Batch 53/64 loss: -3.0483741760253906
Batch 54/64 loss: -2.5052194595336914
Batch 55/64 loss: -2.958498954772949
Batch 56/64 loss: -2.7937679290771484
Batch 57/64 loss: -2.820124626159668
Batch 58/64 loss: -2.9264822006225586
Batch 59/64 loss: -2.5244264602661133
Batch 60/64 loss: -2.982968330383301
Batch 61/64 loss: -2.382455825805664
Batch 62/64 loss: -2.7153148651123047
Batch 63/64 loss: -2.724149703979492
Batch 64/64 loss: -6.885717391967773
Epoch 427  Train loss: -2.8210443010517197  Val loss: -3.0643178933264874
Epoch 428
-------------------------------
Batch 1/64 loss: -2.7341203689575195
Batch 2/64 loss: -2.8895063400268555
Batch 3/64 loss: -2.8348283767700195
Batch 4/64 loss: -2.274115562438965
Batch 5/64 loss: -2.8750476837158203
Batch 6/64 loss: -2.7482032775878906
Batch 7/64 loss: -2.6662864685058594
Batch 8/64 loss: -2.7613353729248047
Batch 9/64 loss: -2.993143081665039
Batch 10/64 loss: -2.8816423416137695
Batch 11/64 loss: -2.555368423461914
Batch 12/64 loss: -2.8988475799560547
Batch 13/64 loss: -2.553119659423828
Batch 14/64 loss: -2.918668746948242
Batch 15/64 loss: -2.7869749069213867
Batch 16/64 loss: -2.824406623840332
Batch 17/64 loss: -2.9131345748901367
Batch 18/64 loss: -2.8908681869506836
Batch 19/64 loss: -2.577350616455078
Batch 20/64 loss: -3.089750289916992
Batch 21/64 loss: -2.7881040573120117
Batch 22/64 loss: -2.777254104614258
Batch 23/64 loss: -2.992177963256836
Batch 24/64 loss: -2.8372631072998047
Batch 25/64 loss: -2.727938652038574
Batch 26/64 loss: -2.71234130859375
Batch 27/64 loss: -2.8728408813476562
Batch 28/64 loss: -2.957699775695801
Batch 29/64 loss: -2.5119171142578125
Batch 30/64 loss: -2.8947277069091797
Batch 31/64 loss: -2.510751724243164
Batch 32/64 loss: -2.9780960083007812
Batch 33/64 loss: -2.750885009765625
Batch 34/64 loss: -2.7013349533081055
Batch 35/64 loss: -2.071392059326172
Batch 36/64 loss: -2.810516357421875
Batch 37/64 loss: -2.763620376586914
Batch 38/64 loss: -2.874349594116211
Batch 39/64 loss: -2.513620376586914
Batch 40/64 loss: -2.775996208190918
Batch 41/64 loss: -2.860126495361328
Batch 42/64 loss: -2.778740882873535
Batch 43/64 loss: -2.8474035263061523
Batch 44/64 loss: -2.583362579345703
Batch 45/64 loss: -2.699075698852539
Batch 46/64 loss: -2.4726152420043945
Batch 47/64 loss: -2.849468231201172
Batch 48/64 loss: -2.6487817764282227
Batch 49/64 loss: -2.863086700439453
Batch 50/64 loss: -2.7613611221313477
Batch 51/64 loss: -2.9485721588134766
Batch 52/64 loss: -2.8582468032836914
Batch 53/64 loss: -2.9387025833129883
Batch 54/64 loss: -2.902947425842285
Batch 55/64 loss: -2.954690933227539
Batch 56/64 loss: -2.471835136413574
Batch 57/64 loss: -2.6147079467773438
Batch 58/64 loss: -2.7339181900024414
Batch 59/64 loss: -2.7908592224121094
Batch 60/64 loss: -2.587533950805664
Batch 61/64 loss: -2.9223928451538086
Batch 62/64 loss: -2.7389631271362305
Batch 63/64 loss: -2.810892105102539
Batch 64/64 loss: -6.790757179260254
Epoch 428  Train loss: -2.811308210036334  Val loss: -3.0310075373174397
Epoch 429
-------------------------------
Batch 1/64 loss: -2.29550838470459
Batch 2/64 loss: -2.8850831985473633
Batch 3/64 loss: -2.8294410705566406
Batch 4/64 loss: -2.781299591064453
Batch 5/64 loss: -2.6971940994262695
Batch 6/64 loss: -2.744741439819336
Batch 7/64 loss: -2.7597246170043945
Batch 8/64 loss: -2.7709569931030273
Batch 9/64 loss: -2.7647018432617188
Batch 10/64 loss: -2.5905256271362305
Batch 11/64 loss: -2.6598310470581055
Batch 12/64 loss: -2.867137908935547
Batch 13/64 loss: -2.6337080001831055
Batch 14/64 loss: -2.7839651107788086
Batch 15/64 loss: -2.8664731979370117
Batch 16/64 loss: -2.443483352661133
Batch 17/64 loss: -2.209221839904785
Batch 18/64 loss: -2.575423240661621
Batch 19/64 loss: -2.7847118377685547
Batch 20/64 loss: -3.012544631958008
Batch 21/64 loss: -2.759441375732422
Batch 22/64 loss: -2.341130256652832
Batch 23/64 loss: -2.7672119140625
Batch 24/64 loss: -2.6442556381225586
Batch 25/64 loss: -3.010941505432129
Batch 26/64 loss: -2.9060535430908203
Batch 27/64 loss: -2.8663015365600586
Batch 28/64 loss: -2.897197723388672
Batch 29/64 loss: -2.854043960571289
Batch 30/64 loss: -2.6353273391723633
Batch 31/64 loss: -2.8178043365478516
Batch 32/64 loss: -2.768679618835449
Batch 33/64 loss: -2.914555549621582
Batch 34/64 loss: -2.8306350708007812
Batch 35/64 loss: -2.8302078247070312
Batch 36/64 loss: -2.9347124099731445
Batch 37/64 loss: -2.61661434173584
Batch 38/64 loss: -2.7617740631103516
Batch 39/64 loss: -2.908310890197754
Batch 40/64 loss: -2.943418502807617
Batch 41/64 loss: -2.9443445205688477
Batch 42/64 loss: -2.7578125
Batch 43/64 loss: -2.8135414123535156
Batch 44/64 loss: -2.759645462036133
Batch 45/64 loss: -2.9944934844970703
Batch 46/64 loss: -2.904630661010742
Batch 47/64 loss: -2.6511220932006836
Batch 48/64 loss: -2.8809547424316406
Batch 49/64 loss: -2.958014488220215
Batch 50/64 loss: -2.7946853637695312
Batch 51/64 loss: -2.80814266204834
Batch 52/64 loss: -2.8383073806762695
Batch 53/64 loss: -2.1729698181152344
Batch 54/64 loss: -2.8023300170898438
Batch 55/64 loss: -2.7866811752319336
Batch 56/64 loss: -2.8933849334716797
Batch 57/64 loss: -2.826251983642578
Batch 58/64 loss: -2.9285449981689453
Batch 59/64 loss: -2.78926944732666
Batch 60/64 loss: -2.8874711990356445
Batch 61/64 loss: -2.990598678588867
Batch 62/64 loss: -2.8830623626708984
Batch 63/64 loss: -2.7603797912597656
Batch 64/64 loss: -7.182478904724121
Epoch 429  Train loss: -2.826318318236108  Val loss: -3.124580199775827
Epoch 430
-------------------------------
Batch 1/64 loss: -2.7296791076660156
Batch 2/64 loss: -2.886805534362793
Batch 3/64 loss: -2.751089096069336
Batch 4/64 loss: -3.002955436706543
Batch 5/64 loss: -2.8842945098876953
Batch 6/64 loss: -2.9232616424560547
Batch 7/64 loss: -2.924318313598633
Batch 8/64 loss: -2.31417179107666
Batch 9/64 loss: -2.86669921875
Batch 10/64 loss: -2.8458356857299805
Batch 11/64 loss: -2.4227075576782227
Batch 12/64 loss: -3.0613012313842773
Batch 13/64 loss: -2.8799638748168945
Batch 14/64 loss: -2.6949691772460938
Batch 15/64 loss: -3.128045082092285
Batch 16/64 loss: -2.8560104370117188
Batch 17/64 loss: -2.6717910766601562
Batch 18/64 loss: -2.850020408630371
Batch 19/64 loss: -2.9624557495117188
Batch 20/64 loss: -2.8544483184814453
Batch 21/64 loss: -2.800609588623047
Batch 22/64 loss: -2.8837594985961914
Batch 23/64 loss: -2.777338981628418
Batch 24/64 loss: -2.822188377380371
Batch 25/64 loss: -2.840961456298828
Batch 26/64 loss: -2.738051414489746
Batch 27/64 loss: -2.973733901977539
Batch 28/64 loss: -2.7307443618774414
Batch 29/64 loss: -2.9673452377319336
Batch 30/64 loss: -2.8482770919799805
Batch 31/64 loss: -2.95559024810791
Batch 32/64 loss: -2.9011764526367188
Batch 33/64 loss: -2.8893260955810547
Batch 34/64 loss: -2.81070613861084
Batch 35/64 loss: -3.0494213104248047
Batch 36/64 loss: -2.9951248168945312
Batch 37/64 loss: -2.63346004486084
Batch 38/64 loss: -3.0863265991210938
Batch 39/64 loss: -2.879854202270508
Batch 40/64 loss: -3.0386781692504883
Batch 41/64 loss: -2.7034835815429688
Batch 42/64 loss: -2.106687545776367
Batch 43/64 loss: -2.8718652725219727
Batch 44/64 loss: -2.76809024810791
Batch 45/64 loss: -3.013692855834961
Batch 46/64 loss: -2.978710174560547
Batch 47/64 loss: -2.868117332458496
Batch 48/64 loss: -2.2910146713256836
Batch 49/64 loss: -2.6982717514038086
Batch 50/64 loss: -2.6317710876464844
Batch 51/64 loss: -2.918924331665039
Batch 52/64 loss: -2.6107177734375
Batch 53/64 loss: -2.967885971069336
Batch 54/64 loss: -2.784010887145996
Batch 55/64 loss: -2.9188060760498047
Batch 56/64 loss: -2.5072546005249023
Batch 57/64 loss: -2.848041534423828
Batch 58/64 loss: -2.3598623275756836
Batch 59/64 loss: -2.759977340698242
Batch 60/64 loss: -2.895602226257324
Batch 61/64 loss: -2.7461776733398438
Batch 62/64 loss: -2.8888044357299805
Batch 63/64 loss: -2.6574039459228516
Batch 64/64 loss: -6.376138687133789
Epoch 430  Train loss: -2.8503650964475145  Val loss: -3.113415747573695
Epoch 431
-------------------------------
Batch 1/64 loss: -2.815305709838867
Batch 2/64 loss: -2.960333824157715
Batch 3/64 loss: -2.929800033569336
Batch 4/64 loss: -2.6855363845825195
Batch 5/64 loss: -2.604116439819336
Batch 6/64 loss: -2.7450809478759766
Batch 7/64 loss: -2.7348852157592773
Batch 8/64 loss: -2.8321523666381836
Batch 9/64 loss: -2.6832475662231445
Batch 10/64 loss: -2.0634546279907227
Batch 11/64 loss: -2.8615102767944336
Batch 12/64 loss: -2.5682315826416016
Batch 13/64 loss: -2.340325355529785
Batch 14/64 loss: -2.909420967102051
Batch 15/64 loss: -2.905731201171875
Batch 16/64 loss: -2.9151973724365234
Batch 17/64 loss: -2.8334455490112305
Batch 18/64 loss: -3.000938892364502
Batch 19/64 loss: -2.7594738006591797
Batch 20/64 loss: -2.912965774536133
Batch 21/64 loss: -2.8892669677734375
Batch 22/64 loss: -2.477747917175293
Batch 23/64 loss: -2.7012147903442383
Batch 24/64 loss: -2.885695457458496
Batch 25/64 loss: -2.639097213745117
Batch 26/64 loss: -2.746188163757324
Batch 27/64 loss: -2.820897102355957
Batch 28/64 loss: -2.6379899978637695
Batch 29/64 loss: -2.5753068923950195
Batch 30/64 loss: -2.776216506958008
Batch 31/64 loss: -2.765787124633789
Batch 32/64 loss: -2.729001998901367
Batch 33/64 loss: -2.7936363220214844
Batch 34/64 loss: -2.4380664825439453
Batch 35/64 loss: -2.908639907836914
Batch 36/64 loss: -2.9302501678466797
Batch 37/64 loss: -2.4512786865234375
Batch 38/64 loss: -2.641246795654297
Batch 39/64 loss: -2.6842336654663086
Batch 40/64 loss: -2.8463306427001953
Batch 41/64 loss: -2.7265443801879883
Batch 42/64 loss: -2.671426773071289
Batch 43/64 loss: -3.111727714538574
Batch 44/64 loss: -2.80971622467041
Batch 45/64 loss: -2.878206253051758
Batch 46/64 loss: -2.664022445678711
Batch 47/64 loss: -2.8116798400878906
Batch 48/64 loss: -2.903740882873535
Batch 49/64 loss: -2.9171953201293945
Batch 50/64 loss: -2.898599624633789
Batch 51/64 loss: -2.698666572570801
Batch 52/64 loss: -2.6358518600463867
Batch 53/64 loss: -2.8743162155151367
Batch 54/64 loss: -2.8522472381591797
Batch 55/64 loss: -2.889458656311035
Batch 56/64 loss: -2.844449996948242
Batch 57/64 loss: -2.8784685134887695
Batch 58/64 loss: -2.6938343048095703
Batch 59/64 loss: -2.7485475540161133
Batch 60/64 loss: -2.7417097091674805
Batch 61/64 loss: -2.909320831298828
Batch 62/64 loss: -2.786421775817871
Batch 63/64 loss: -2.908323287963867
Batch 64/64 loss: -7.423870086669922
Epoch 431  Train loss: -2.8207313761991615  Val loss: -3.042347164088508
Epoch 432
-------------------------------
Batch 1/64 loss: -2.2586488723754883
Batch 2/64 loss: -2.1397571563720703
Batch 3/64 loss: -2.5966596603393555
Batch 4/64 loss: -2.9071054458618164
Batch 5/64 loss: -2.722341537475586
Batch 6/64 loss: -2.9029321670532227
Batch 7/64 loss: -2.683483123779297
Batch 8/64 loss: -2.596567153930664
Batch 9/64 loss: -2.319148063659668
Batch 10/64 loss: -2.8296499252319336
Batch 11/64 loss: -2.718411445617676
Batch 12/64 loss: -2.839156150817871
Batch 13/64 loss: -2.849534034729004
Batch 14/64 loss: -2.9208593368530273
Batch 15/64 loss: -2.8626251220703125
Batch 16/64 loss: -2.7090253829956055
Batch 17/64 loss: -2.8058719635009766
Batch 18/64 loss: -2.949148178100586
Batch 19/64 loss: -2.993412971496582
Batch 20/64 loss: -2.9092445373535156
Batch 21/64 loss: -2.5926733016967773
Batch 22/64 loss: -2.826197624206543
Batch 23/64 loss: -2.884974479675293
Batch 24/64 loss: -2.9067564010620117
Batch 25/64 loss: -2.9225387573242188
Batch 26/64 loss: -2.6270875930786133
Batch 27/64 loss: -2.650728225708008
Batch 28/64 loss: -2.751405715942383
Batch 29/64 loss: -2.627627372741699
Batch 30/64 loss: -2.7087936401367188
Batch 31/64 loss: -3.095993995666504
Batch 32/64 loss: -2.6719207763671875
Batch 33/64 loss: -2.9945688247680664
Batch 34/64 loss: -2.8913002014160156
Batch 35/64 loss: -2.9327077865600586
Batch 36/64 loss: -2.3808822631835938
Batch 37/64 loss: -2.884819984436035
Batch 38/64 loss: -2.999394416809082
Batch 39/64 loss: -2.929825782775879
Batch 40/64 loss: -2.6869897842407227
Batch 41/64 loss: -2.9476451873779297
Batch 42/64 loss: -2.966592788696289
Batch 43/64 loss: -2.9346752166748047
Batch 44/64 loss: -2.6921253204345703
Batch 45/64 loss: -3.0425214767456055
Batch 46/64 loss: -2.788376808166504
Batch 47/64 loss: -2.8487300872802734
Batch 48/64 loss: -2.740253448486328
Batch 49/64 loss: -2.9393835067749023
Batch 50/64 loss: -2.8319482803344727
Batch 51/64 loss: -2.820326805114746
Batch 52/64 loss: -2.9116411209106445
Batch 53/64 loss: -2.762044906616211
Batch 54/64 loss: -2.742438316345215
Batch 55/64 loss: -2.8532867431640625
Batch 56/64 loss: -2.9368133544921875
Batch 57/64 loss: -2.7467098236083984
Batch 58/64 loss: -2.883268356323242
Batch 59/64 loss: -2.769059181213379
Batch 60/64 loss: -2.7814178466796875
Batch 61/64 loss: -2.756929397583008
Batch 62/64 loss: -2.65435791015625
Batch 63/64 loss: -2.8067541122436523
Batch 64/64 loss: -7.320433139801025
Epoch 432  Train loss: -2.841229709924436  Val loss: -3.1474878632325898
Epoch 433
-------------------------------
Batch 1/64 loss: -2.6182641983032227
Batch 2/64 loss: -2.8971433639526367
Batch 3/64 loss: -2.718189239501953
Batch 4/64 loss: -2.989546775817871
Batch 5/64 loss: -2.763957977294922
Batch 6/64 loss: -2.9436750411987305
Batch 7/64 loss: -2.596306800842285
Batch 8/64 loss: -2.571962356567383
Batch 9/64 loss: -2.8446245193481445
Batch 10/64 loss: -2.9061403274536133
Batch 11/64 loss: -2.8405704498291016
Batch 12/64 loss: -2.8519887924194336
Batch 13/64 loss: -2.362751007080078
Batch 14/64 loss: -2.7942190170288086
Batch 15/64 loss: -2.780231475830078
Batch 16/64 loss: -2.7692689895629883
Batch 17/64 loss: -2.7506532669067383
Batch 18/64 loss: -2.2329978942871094
Batch 19/64 loss: -2.7276554107666016
Batch 20/64 loss: -2.9672250747680664
Batch 21/64 loss: -2.9333906173706055
Batch 22/64 loss: -2.9277210235595703
Batch 23/64 loss: -2.8502044677734375
Batch 24/64 loss: -2.6523895263671875
Batch 25/64 loss: -2.863018035888672
Batch 26/64 loss: -2.5911760330200195
Batch 27/64 loss: -2.2387800216674805
Batch 28/64 loss: -2.7710695266723633
Batch 29/64 loss: -2.8154306411743164
Batch 30/64 loss: -2.4187612533569336
Batch 31/64 loss: -2.765005111694336
Batch 32/64 loss: -2.532517433166504
Batch 33/64 loss: -2.682986259460449
Batch 34/64 loss: -2.7845706939697266
Batch 35/64 loss: -2.7619495391845703
Batch 36/64 loss: -2.665461540222168
Batch 37/64 loss: -2.927859306335449
Batch 38/64 loss: -2.9701318740844727
Batch 39/64 loss: -2.777102470397949
Batch 40/64 loss: -2.6543350219726562
Batch 41/64 loss: -2.724802017211914
Batch 42/64 loss: -2.622836112976074
Batch 43/64 loss: -2.5587635040283203
Batch 44/64 loss: -2.8757095336914062
Batch 45/64 loss: -2.8975486755371094
Batch 46/64 loss: -2.9504547119140625
Batch 47/64 loss: -2.642331123352051
Batch 48/64 loss: -2.9678869247436523
Batch 49/64 loss: -2.7714319229125977
Batch 50/64 loss: -2.837347984313965
Batch 51/64 loss: -2.60872745513916
Batch 52/64 loss: -2.8466033935546875
Batch 53/64 loss: -2.9349794387817383
Batch 54/64 loss: -2.748014450073242
Batch 55/64 loss: -2.7605695724487305
Batch 56/64 loss: -2.7174787521362305
Batch 57/64 loss: -2.5094432830810547
Batch 58/64 loss: -2.9936132431030273
Batch 59/64 loss: -2.68959903717041
Batch 60/64 loss: -2.9875621795654297
Batch 61/64 loss: -2.784181594848633
Batch 62/64 loss: -2.8588199615478516
Batch 63/64 loss: -2.9667224884033203
Batch 64/64 loss: -7.279906749725342
Epoch 433  Train loss: -2.811397487041997  Val loss: -3.035640152868946
Epoch 434
-------------------------------
Batch 1/64 loss: -2.817760467529297
Batch 2/64 loss: -2.9509153366088867
Batch 3/64 loss: -2.6754560470581055
Batch 4/64 loss: -2.743411064147949
Batch 5/64 loss: -2.833974838256836
Batch 6/64 loss: -2.741452217102051
Batch 7/64 loss: -2.854288101196289
Batch 8/64 loss: -2.8301124572753906
Batch 9/64 loss: -2.7429943084716797
Batch 10/64 loss: -2.935208320617676
Batch 11/64 loss: -2.740353584289551
Batch 12/64 loss: -2.670858383178711
Batch 13/64 loss: -2.7079954147338867
Batch 14/64 loss: -2.740520477294922
Batch 15/64 loss: -2.9419422149658203
Batch 16/64 loss: -2.8512258529663086
Batch 17/64 loss: -2.8646745681762695
Batch 18/64 loss: -2.932758331298828
Batch 19/64 loss: -2.747342109680176
Batch 20/64 loss: -2.84000301361084
Batch 21/64 loss: -2.393596649169922
Batch 22/64 loss: -2.83817195892334
Batch 23/64 loss: -2.6977787017822266
Batch 24/64 loss: -2.7710256576538086
Batch 25/64 loss: -2.389951705932617
Batch 26/64 loss: -2.7572021484375
Batch 27/64 loss: -2.4770774841308594
Batch 28/64 loss: -2.597776412963867
Batch 29/64 loss: -2.7818851470947266
Batch 30/64 loss: -2.829054832458496
Batch 31/64 loss: -2.76446533203125
Batch 32/64 loss: -2.618227005004883
Batch 33/64 loss: -2.845639228820801
Batch 34/64 loss: -2.8218345642089844
Batch 35/64 loss: -2.85044002532959
Batch 36/64 loss: -2.0784244537353516
Batch 37/64 loss: -2.7856550216674805
Batch 38/64 loss: -2.924917221069336
Batch 39/64 loss: -2.2632980346679688
Batch 40/64 loss: -2.696460723876953
Batch 41/64 loss: -2.9822778701782227
Batch 42/64 loss: -2.554417610168457
Batch 43/64 loss: -2.761256217956543
Batch 44/64 loss: -2.8155088424682617
Batch 45/64 loss: -2.614455223083496
Batch 46/64 loss: -2.6587209701538086
Batch 47/64 loss: -2.8697729110717773
Batch 48/64 loss: -2.2909460067749023
Batch 49/64 loss: -2.957500457763672
Batch 50/64 loss: -2.6954383850097656
Batch 51/64 loss: -3.0116586685180664
Batch 52/64 loss: -2.7443084716796875
Batch 53/64 loss: -2.848011016845703
Batch 54/64 loss: -2.6212949752807617
Batch 55/64 loss: -2.9818649291992188
Batch 56/64 loss: -2.8770360946655273
Batch 57/64 loss: -2.948598861694336
Batch 58/64 loss: -2.972805976867676
Batch 59/64 loss: -2.9316587448120117
Batch 60/64 loss: -2.745391845703125
Batch 61/64 loss: -3.0542726516723633
Batch 62/64 loss: -2.8850221633911133
Batch 63/64 loss: -2.967165946960449
Batch 64/64 loss: -7.4487996101379395
Epoch 434  Train loss: -2.819170415167715  Val loss: -3.1329314110615
Epoch 435
-------------------------------
Batch 1/64 loss: -2.9464874267578125
Batch 2/64 loss: -2.8857860565185547
Batch 3/64 loss: -2.7935562133789062
Batch 4/64 loss: -2.368130683898926
Batch 5/64 loss: -2.8776493072509766
Batch 6/64 loss: -2.9215965270996094
Batch 7/64 loss: -2.753146171569824
Batch 8/64 loss: -2.9838953018188477
Batch 9/64 loss: -2.9731760025024414
Batch 10/64 loss: -2.951303482055664
Batch 11/64 loss: -3.0026473999023438
Batch 12/64 loss: -2.8669309616088867
Batch 13/64 loss: -2.693756103515625
Batch 14/64 loss: -2.9243736267089844
Batch 15/64 loss: -3.023609161376953
Batch 16/64 loss: -2.7911148071289062
Batch 17/64 loss: -2.578136444091797
Batch 18/64 loss: -2.8849048614501953
Batch 19/64 loss: -2.874272346496582
Batch 20/64 loss: -2.6725854873657227
Batch 21/64 loss: -2.9864397048950195
Batch 22/64 loss: -2.911296844482422
Batch 23/64 loss: -2.9419937133789062
Batch 24/64 loss: -1.836355209350586
Batch 25/64 loss: -2.7347965240478516
Batch 26/64 loss: -2.6018733978271484
Batch 27/64 loss: -2.7200870513916016
Batch 28/64 loss: -2.831636428833008
Batch 29/64 loss: -2.7600879669189453
Batch 30/64 loss: -2.7840633392333984
Batch 31/64 loss: -2.694570541381836
Batch 32/64 loss: -2.8726673126220703
Batch 33/64 loss: -2.9164648056030273
Batch 34/64 loss: -2.848525047302246
Batch 35/64 loss: -2.654481887817383
Batch 36/64 loss: -2.9410295486450195
Batch 37/64 loss: -2.6437463760375977
Batch 38/64 loss: -2.8750438690185547
Batch 39/64 loss: -2.692873954772949
Batch 40/64 loss: -2.8558835983276367
Batch 41/64 loss: -3.117302894592285
Batch 42/64 loss: -2.8959970474243164
Batch 43/64 loss: -2.8995532989501953
Batch 44/64 loss: -2.7107067108154297
Batch 45/64 loss: -2.843092918395996
Batch 46/64 loss: -2.829561233520508
Batch 47/64 loss: -2.8928728103637695
Batch 48/64 loss: -2.8700218200683594
Batch 49/64 loss: -2.794431686401367
Batch 50/64 loss: -3.0197067260742188
Batch 51/64 loss: -2.8058013916015625
Batch 52/64 loss: -2.8583450317382812
Batch 53/64 loss: -2.7479095458984375
Batch 54/64 loss: -2.714109420776367
Batch 55/64 loss: -2.747063636779785
Batch 56/64 loss: -2.9491519927978516
Batch 57/64 loss: -2.640401840209961
Batch 58/64 loss: -2.9218358993530273
Batch 59/64 loss: -2.904210090637207
Batch 60/64 loss: -2.698908805847168
Batch 61/64 loss: -3.0528993606567383
Batch 62/64 loss: -3.0993566513061523
Batch 63/64 loss: -2.999967575073242
Batch 64/64 loss: -6.878266334533691
Epoch 435  Train loss: -2.8712609197579178  Val loss: -3.0839601890328003
Epoch 436
-------------------------------
Batch 1/64 loss: -2.59561824798584
Batch 2/64 loss: -2.8396787643432617
Batch 3/64 loss: -2.825810432434082
Batch 4/64 loss: -2.9251890182495117
Batch 5/64 loss: -2.8671369552612305
Batch 6/64 loss: -2.829800605773926
Batch 7/64 loss: -2.781001091003418
Batch 8/64 loss: -2.9148168563842773
Batch 9/64 loss: -2.84799861907959
Batch 10/64 loss: -2.767892837524414
Batch 11/64 loss: -2.9549665451049805
Batch 12/64 loss: -3.0089616775512695
Batch 13/64 loss: -2.739546775817871
Batch 14/64 loss: -2.9086475372314453
Batch 15/64 loss: -3.037130355834961
Batch 16/64 loss: -3.0845088958740234
Batch 17/64 loss: -2.945362091064453
Batch 18/64 loss: -2.721522331237793
Batch 19/64 loss: -2.5920944213867188
Batch 20/64 loss: -2.775205612182617
Batch 21/64 loss: -2.938612937927246
Batch 22/64 loss: -2.981689453125
Batch 23/64 loss: -2.955312728881836
Batch 24/64 loss: -2.923354148864746
Batch 25/64 loss: -2.6657028198242188
Batch 26/64 loss: -3.017991065979004
Batch 27/64 loss: -2.8639955520629883
Batch 28/64 loss: -2.7314252853393555
Batch 29/64 loss: -2.837803840637207
Batch 30/64 loss: -2.88948917388916
Batch 31/64 loss: -2.8614540100097656
Batch 32/64 loss: -2.8044490814208984
Batch 33/64 loss: -2.887033462524414
Batch 34/64 loss: -3.0221166610717773
Batch 35/64 loss: -2.8868188858032227
Batch 36/64 loss: -2.874509811401367
Batch 37/64 loss: -3.008485794067383
Batch 38/64 loss: -2.7968997955322266
Batch 39/64 loss: -2.5884475708007812
Batch 40/64 loss: -2.504913330078125
Batch 41/64 loss: -2.8868932723999023
Batch 42/64 loss: -2.838754653930664
Batch 43/64 loss: -2.700956344604492
Batch 44/64 loss: -2.3974905014038086
Batch 45/64 loss: -2.1638879776000977
Batch 46/64 loss: -2.874034881591797
Batch 47/64 loss: -2.7679367065429688
Batch 48/64 loss: -2.900411605834961
Batch 49/64 loss: -2.9793710708618164
Batch 50/64 loss: -2.689138412475586
Batch 51/64 loss: -2.934976577758789
Batch 52/64 loss: -2.025944709777832
Batch 53/64 loss: -2.5245237350463867
Batch 54/64 loss: -2.8976125717163086
Batch 55/64 loss: -2.810251235961914
Batch 56/64 loss: -2.612553596496582
Batch 57/64 loss: -2.671417236328125
Batch 58/64 loss: -2.6083269119262695
Batch 59/64 loss: -2.87435245513916
Batch 60/64 loss: -2.574796676635742
Batch 61/64 loss: -2.9761714935302734
Batch 62/64 loss: -2.8751745223999023
Batch 63/64 loss: -2.8694305419921875
Batch 64/64 loss: -7.362896919250488
Epoch 436  Train loss: -2.854587850383684  Val loss: -3.049599349293922
Epoch 437
-------------------------------
Batch 1/64 loss: -2.777372360229492
Batch 2/64 loss: -2.4051952362060547
Batch 3/64 loss: -2.8617238998413086
Batch 4/64 loss: -2.861867904663086
Batch 5/64 loss: -2.785252571105957
Batch 6/64 loss: -2.682903289794922
Batch 7/64 loss: -2.583449363708496
Batch 8/64 loss: -2.95273494720459
Batch 9/64 loss: -2.730030059814453
Batch 10/64 loss: -2.9340858459472656
Batch 11/64 loss: -2.7105274200439453
Batch 12/64 loss: -2.644963264465332
Batch 13/64 loss: -2.7485923767089844
Batch 14/64 loss: -2.874225616455078
Batch 15/64 loss: -2.7943572998046875
Batch 16/64 loss: -2.6781158447265625
Batch 17/64 loss: -2.4584245681762695
Batch 18/64 loss: -2.9368019104003906
Batch 19/64 loss: -2.9077281951904297
Batch 20/64 loss: -3.059680938720703
Batch 21/64 loss: -2.691530227661133
Batch 22/64 loss: -2.9993810653686523
Batch 23/64 loss: -2.8530569076538086
Batch 24/64 loss: -2.9151268005371094
Batch 25/64 loss: -2.744154930114746
Batch 26/64 loss: -2.9012069702148438
Batch 27/64 loss: -2.849930763244629
Batch 28/64 loss: -2.710071563720703
Batch 29/64 loss: -2.9880599975585938
Batch 30/64 loss: -2.782834053039551
Batch 31/64 loss: -2.81402587890625
Batch 32/64 loss: -2.8077774047851562
Batch 33/64 loss: -2.900519371032715
Batch 34/64 loss: -3.004582405090332
Batch 35/64 loss: -2.9764232635498047
Batch 36/64 loss: -2.9729270935058594
Batch 37/64 loss: -2.9085311889648438
Batch 38/64 loss: -2.6545677185058594
Batch 39/64 loss: -2.727328300476074
Batch 40/64 loss: -2.540128707885742
Batch 41/64 loss: -2.6648569107055664
Batch 42/64 loss: -2.964949607849121
Batch 43/64 loss: -3.073267936706543
Batch 44/64 loss: -2.718015670776367
Batch 45/64 loss: -2.7593278884887695
Batch 46/64 loss: -2.9118919372558594
Batch 47/64 loss: -2.7725305557250977
Batch 48/64 loss: -2.3184938430786133
Batch 49/64 loss: -2.9426536560058594
Batch 50/64 loss: -2.76834774017334
Batch 51/64 loss: -3.0429773330688477
Batch 52/64 loss: -2.6742753982543945
Batch 53/64 loss: -3.0874500274658203
Batch 54/64 loss: -2.6747398376464844
Batch 55/64 loss: -2.9495153427124023
Batch 56/64 loss: -2.741487503051758
Batch 57/64 loss: -2.2645177841186523
Batch 58/64 loss: -2.643313407897949
Batch 59/64 loss: -2.628535270690918
Batch 60/64 loss: -2.9893455505371094
Batch 61/64 loss: -2.91762638092041
Batch 62/64 loss: -2.8197851181030273
Batch 63/64 loss: -2.8315954208374023
Batch 64/64 loss: -7.231385231018066
Epoch 437  Train loss: -2.850403710907581  Val loss: -3.2496192119375538
Epoch 438
-------------------------------
Batch 1/64 loss: -2.973918914794922
Batch 2/64 loss: -2.898045539855957
Batch 3/64 loss: -2.8167314529418945
Batch 4/64 loss: -2.3481597900390625
Batch 5/64 loss: -2.318814277648926
Batch 6/64 loss: -2.9136743545532227
Batch 7/64 loss: -2.937227249145508
Batch 8/64 loss: -3.047809600830078
Batch 9/64 loss: -3.10781192779541
Batch 10/64 loss: -2.9806108474731445
Batch 11/64 loss: -2.81564998626709
Batch 12/64 loss: -2.897563934326172
Batch 13/64 loss: -2.9439659118652344
Batch 14/64 loss: -3.00673770904541
Batch 15/64 loss: -2.893069267272949
Batch 16/64 loss: -3.0141239166259766
Batch 17/64 loss: -2.508347511291504
Batch 18/64 loss: -2.8056278228759766
Batch 19/64 loss: -2.84780216217041
Batch 20/64 loss: -2.8939828872680664
Batch 21/64 loss: -2.7532310485839844
Batch 22/64 loss: -2.607778549194336
Batch 23/64 loss: -3.10408878326416
Batch 24/64 loss: -3.0029525756835938
Batch 25/64 loss: -2.758725166320801
Batch 26/64 loss: -2.910808563232422
Batch 27/64 loss: -2.848904609680176
Batch 28/64 loss: -2.944766044616699
Batch 29/64 loss: -2.711254119873047
Batch 30/64 loss: -2.924187660217285
Batch 31/64 loss: -2.8019189834594727
Batch 32/64 loss: -3.11118221282959
Batch 33/64 loss: -2.7021379470825195
Batch 34/64 loss: -3.1224870681762695
Batch 35/64 loss: -3.111973762512207
Batch 36/64 loss: -2.982023239135742
Batch 37/64 loss: -2.570281982421875
Batch 38/64 loss: -2.8155860900878906
Batch 39/64 loss: -2.7917356491088867
Batch 40/64 loss: -2.886983871459961
Batch 41/64 loss: -2.9407968521118164
Batch 42/64 loss: -2.814821243286133
Batch 43/64 loss: -2.764561653137207
Batch 44/64 loss: -2.6917543411254883
Batch 45/64 loss: -2.934720993041992
Batch 46/64 loss: -2.9271860122680664
Batch 47/64 loss: -2.7026853561401367
Batch 48/64 loss: -2.9258460998535156
Batch 49/64 loss: -2.7706775665283203
Batch 50/64 loss: -2.602799415588379
Batch 51/64 loss: -2.718174934387207
Batch 52/64 loss: -2.966456413269043
Batch 53/64 loss: -2.363795280456543
Batch 54/64 loss: -2.635700225830078
Batch 55/64 loss: -2.7590837478637695
Batch 56/64 loss: -2.917837142944336
Batch 57/64 loss: -2.726405143737793
Batch 58/64 loss: -2.7108592987060547
Batch 59/64 loss: -2.81356143951416
Batch 60/64 loss: -2.847576141357422
Batch 61/64 loss: -2.7415895462036133
Batch 62/64 loss: -3.0057191848754883
Batch 63/64 loss: -2.8170461654663086
Batch 64/64 loss: -7.07913875579834
Epoch 438  Train loss: -2.883791235381482  Val loss: -3.1069313259059212
Epoch 439
-------------------------------
Batch 1/64 loss: -2.5037059783935547
Batch 2/64 loss: -2.797170639038086
Batch 3/64 loss: -2.8954334259033203
Batch 4/64 loss: -2.648374557495117
Batch 5/64 loss: -2.7710800170898438
Batch 6/64 loss: -2.9410152435302734
Batch 7/64 loss: -3.061084747314453
Batch 8/64 loss: -2.961833953857422
Batch 9/64 loss: -3.0981922149658203
Batch 10/64 loss: -2.8527793884277344
Batch 11/64 loss: -2.9518308639526367
Batch 12/64 loss: -2.6948890686035156
Batch 13/64 loss: -2.8585548400878906
Batch 14/64 loss: -2.873051643371582
Batch 15/64 loss: -2.8615856170654297
Batch 16/64 loss: -2.8122406005859375
Batch 17/64 loss: -3.0565414428710938
Batch 18/64 loss: -2.3993053436279297
Batch 19/64 loss: -2.8275489807128906
Batch 20/64 loss: -2.565858840942383
Batch 21/64 loss: -2.929718017578125
Batch 22/64 loss: -2.7015695571899414
Batch 23/64 loss: -2.7358570098876953
Batch 24/64 loss: -3.0332794189453125
Batch 25/64 loss: -2.903779983520508
Batch 26/64 loss: -2.8692197799682617
Batch 27/64 loss: -2.8468456268310547
Batch 28/64 loss: -2.8994503021240234
Batch 29/64 loss: -2.269497871398926
Batch 30/64 loss: -2.957681655883789
Batch 31/64 loss: -2.637310028076172
Batch 32/64 loss: -3.017300605773926
Batch 33/64 loss: -3.0074949264526367
Batch 34/64 loss: -2.6569576263427734
Batch 35/64 loss: -3.002603530883789
Batch 36/64 loss: -2.7986526489257812
Batch 37/64 loss: -2.9271602630615234
Batch 38/64 loss: -3.009884834289551
Batch 39/64 loss: -2.531599998474121
Batch 40/64 loss: -2.7630062103271484
Batch 41/64 loss: -2.832540512084961
Batch 42/64 loss: -2.9029035568237305
Batch 43/64 loss: -2.9787187576293945
Batch 44/64 loss: -3.0189952850341797
Batch 45/64 loss: -3.0027341842651367
Batch 46/64 loss: -2.8596057891845703
Batch 47/64 loss: -2.8232383728027344
Batch 48/64 loss: -2.670170783996582
Batch 49/64 loss: -2.8808717727661133
Batch 50/64 loss: -2.684549331665039
Batch 51/64 loss: -2.863224983215332
Batch 52/64 loss: -2.5573339462280273
Batch 53/64 loss: -2.7633914947509766
Batch 54/64 loss: -2.867985725402832
Batch 55/64 loss: -2.582273483276367
Batch 56/64 loss: -2.9471311569213867
Batch 57/64 loss: -2.521817207336426
Batch 58/64 loss: -2.6280393600463867
Batch 59/64 loss: -2.561488151550293
Batch 60/64 loss: -2.987969398498535
Batch 61/64 loss: -2.6678266525268555
Batch 62/64 loss: -2.831186294555664
Batch 63/64 loss: -2.9345455169677734
Batch 64/64 loss: -7.178910732269287
Epoch 439  Train loss: -2.8656262285569136  Val loss: -3.1586177734165255
Epoch 440
-------------------------------
Batch 1/64 loss: -2.8370018005371094
Batch 2/64 loss: -2.848735809326172
Batch 3/64 loss: -2.945277214050293
Batch 4/64 loss: -3.0296993255615234
Batch 5/64 loss: -2.9135818481445312
Batch 6/64 loss: -2.697880744934082
Batch 7/64 loss: -2.7822933197021484
Batch 8/64 loss: -2.827716827392578
Batch 9/64 loss: -2.9605112075805664
Batch 10/64 loss: -2.6483421325683594
Batch 11/64 loss: -2.885329246520996
Batch 12/64 loss: -2.903837203979492
Batch 13/64 loss: -2.8415327072143555
Batch 14/64 loss: -2.585918426513672
Batch 15/64 loss: -2.58297061920166
Batch 16/64 loss: -2.9724817276000977
Batch 17/64 loss: -2.8457183837890625
Batch 18/64 loss: -3.064027786254883
Batch 19/64 loss: -2.8599748611450195
Batch 20/64 loss: -2.9197893142700195
Batch 21/64 loss: -2.9549942016601562
Batch 22/64 loss: -2.834482192993164
Batch 23/64 loss: -1.671574592590332
Batch 24/64 loss: -2.965121269226074
Batch 25/64 loss: -2.964205741882324
Batch 26/64 loss: -2.9040966033935547
Batch 27/64 loss: -3.029585838317871
Batch 28/64 loss: -2.990199089050293
Batch 29/64 loss: -3.0342912673950195
Batch 30/64 loss: -2.713174819946289
Batch 31/64 loss: -2.7316951751708984
Batch 32/64 loss: -2.6402931213378906
Batch 33/64 loss: -2.651477813720703
Batch 34/64 loss: -2.850234031677246
Batch 35/64 loss: -2.018932342529297
Batch 36/64 loss: -2.9103221893310547
Batch 37/64 loss: -2.7667789459228516
Batch 38/64 loss: -2.6812448501586914
Batch 39/64 loss: -2.863912582397461
Batch 40/64 loss: -2.8113584518432617
Batch 41/64 loss: -2.824146270751953
Batch 42/64 loss: -2.8313989639282227
Batch 43/64 loss: -2.781529426574707
Batch 44/64 loss: -3.0290603637695312
Batch 45/64 loss: -2.7281970977783203
Batch 46/64 loss: -2.8702621459960938
Batch 47/64 loss: -2.908602714538574
Batch 48/64 loss: -2.6634273529052734
Batch 49/64 loss: -2.8134584426879883
Batch 50/64 loss: -3.0336952209472656
Batch 51/64 loss: -2.895265579223633
Batch 52/64 loss: -2.5933761596679688
Batch 53/64 loss: -2.6538820266723633
Batch 54/64 loss: -2.8424625396728516
Batch 55/64 loss: -2.92830753326416
Batch 56/64 loss: -2.9331226348876953
Batch 57/64 loss: -2.7064971923828125
Batch 58/64 loss: -2.959200859069824
Batch 59/64 loss: -3.0269603729248047
Batch 60/64 loss: -2.632185935974121
Batch 61/64 loss: -2.791553497314453
Batch 62/64 loss: -2.9078731536865234
Batch 63/64 loss: -3.0989818572998047
Batch 64/64 loss: -7.438867568969727
Epoch 440  Train loss: -2.8701677434584676  Val loss: -3.1478335718109025
Epoch 441
-------------------------------
Batch 1/64 loss: -2.935344696044922
Batch 2/64 loss: -2.8728036880493164
Batch 3/64 loss: -2.774578094482422
Batch 4/64 loss: -3.049403190612793
Batch 5/64 loss: -2.765864372253418
Batch 6/64 loss: -3.0219812393188477
Batch 7/64 loss: -2.6957693099975586
Batch 8/64 loss: -2.9068727493286133
Batch 9/64 loss: -2.881768226623535
Batch 10/64 loss: -2.8267955780029297
Batch 11/64 loss: -2.7194480895996094
Batch 12/64 loss: -2.6372156143188477
Batch 13/64 loss: -2.794574737548828
Batch 14/64 loss: -2.6301612854003906
Batch 15/64 loss: -2.948802947998047
Batch 16/64 loss: -3.0288562774658203
Batch 17/64 loss: -2.48728084564209
Batch 18/64 loss: -2.8074750900268555
Batch 19/64 loss: -2.7385339736938477
Batch 20/64 loss: -2.7456274032592773
Batch 21/64 loss: -2.7228050231933594
Batch 22/64 loss: -2.8807144165039062
Batch 23/64 loss: -2.6207447052001953
Batch 24/64 loss: -2.7942800521850586
Batch 25/64 loss: -2.8405752182006836
Batch 26/64 loss: -2.834209442138672
Batch 27/64 loss: -2.791534423828125
Batch 28/64 loss: -2.7927608489990234
Batch 29/64 loss: -2.98537540435791
Batch 30/64 loss: -2.83447265625
Batch 31/64 loss: -2.881028175354004
Batch 32/64 loss: -2.898099899291992
Batch 33/64 loss: -2.8376636505126953
Batch 34/64 loss: -2.6363391876220703
Batch 35/64 loss: -2.1637582778930664
Batch 36/64 loss: -2.7711448669433594
Batch 37/64 loss: -2.887491226196289
Batch 38/64 loss: -2.684168815612793
Batch 39/64 loss: -2.918811798095703
Batch 40/64 loss: -2.7540388107299805
Batch 41/64 loss: -3.05324649810791
Batch 42/64 loss: -2.7576894760131836
Batch 43/64 loss: -2.691967010498047
Batch 44/64 loss: -3.035447120666504
Batch 45/64 loss: -2.9606428146362305
Batch 46/64 loss: -2.860724449157715
Batch 47/64 loss: -2.8762998580932617
Batch 48/64 loss: -2.5899791717529297
Batch 49/64 loss: -2.8108654022216797
Batch 50/64 loss: -2.9917030334472656
Batch 51/64 loss: -2.872439384460449
Batch 52/64 loss: -1.8239192962646484
Batch 53/64 loss: -2.513082504272461
Batch 54/64 loss: -2.833078384399414
Batch 55/64 loss: -2.96750545501709
Batch 56/64 loss: -2.8716163635253906
Batch 57/64 loss: -2.0231122970581055
Batch 58/64 loss: -2.671483039855957
Batch 59/64 loss: -2.796311378479004
Batch 60/64 loss: -2.789522171020508
Batch 61/64 loss: -2.710033416748047
Batch 62/64 loss: -3.0025758743286133
Batch 63/64 loss: -2.912496566772461
Batch 64/64 loss: -7.270595073699951
Epoch 441  Train loss: -2.83400567185645  Val loss: -3.09773666014786
Epoch 442
-------------------------------
Batch 1/64 loss: -3.033506393432617
Batch 2/64 loss: -2.9578285217285156
Batch 3/64 loss: -2.712404251098633
Batch 4/64 loss: -2.768583297729492
Batch 5/64 loss: -2.892857551574707
Batch 6/64 loss: -2.9477415084838867
Batch 7/64 loss: -2.928129196166992
Batch 8/64 loss: -2.8807544708251953
Batch 9/64 loss: -2.883246421813965
Batch 10/64 loss: -2.936152458190918
Batch 11/64 loss: -2.8814687728881836
Batch 12/64 loss: -2.6764707565307617
Batch 13/64 loss: -2.906540870666504
Batch 14/64 loss: -2.9531517028808594
Batch 15/64 loss: -3.0148162841796875
Batch 16/64 loss: -2.8155412673950195
Batch 17/64 loss: -2.411227226257324
Batch 18/64 loss: -2.830442428588867
Batch 19/64 loss: -2.8253822326660156
Batch 20/64 loss: -2.7274999618530273
Batch 21/64 loss: -2.7538156509399414
Batch 22/64 loss: -2.8791627883911133
Batch 23/64 loss: -2.8288259506225586
Batch 24/64 loss: -2.7447023391723633
Batch 25/64 loss: -2.7472686767578125
Batch 26/64 loss: -2.871541976928711
Batch 27/64 loss: -1.8342370986938477
Batch 28/64 loss: -2.9118404388427734
Batch 29/64 loss: -2.808709144592285
Batch 30/64 loss: -2.7599563598632812
Batch 31/64 loss: -2.8376855850219727
Batch 32/64 loss: -2.1699228286743164
Batch 33/64 loss: -3.061826705932617
Batch 34/64 loss: -2.801825523376465
Batch 35/64 loss: -2.882780075073242
Batch 36/64 loss: -2.86043643951416
Batch 37/64 loss: -2.643397331237793
Batch 38/64 loss: -2.812030792236328
Batch 39/64 loss: -2.9879703521728516
Batch 40/64 loss: -2.751662254333496
Batch 41/64 loss: -2.7514772415161133
Batch 42/64 loss: -2.803506851196289
Batch 43/64 loss: -2.611520767211914
Batch 44/64 loss: -2.73709774017334
Batch 45/64 loss: -2.771352767944336
Batch 46/64 loss: -2.77817440032959
Batch 47/64 loss: -2.5509471893310547
Batch 48/64 loss: -2.9753341674804688
Batch 49/64 loss: -2.8702468872070312
Batch 50/64 loss: -2.7390384674072266
Batch 51/64 loss: -2.909539222717285
Batch 52/64 loss: -2.8300304412841797
Batch 53/64 loss: -2.5933637619018555
Batch 54/64 loss: -2.8708858489990234
Batch 55/64 loss: -2.5829286575317383
Batch 56/64 loss: -2.9808053970336914
Batch 57/64 loss: -2.9006223678588867
Batch 58/64 loss: -2.8381338119506836
Batch 59/64 loss: -2.6090774536132812
Batch 60/64 loss: -2.6081371307373047
Batch 61/64 loss: -2.8651304244995117
Batch 62/64 loss: -2.5243797302246094
Batch 63/64 loss: -2.798257827758789
Batch 64/64 loss: -7.2664947509765625
Epoch 442  Train loss: -2.8373835844152113  Val loss: -3.0868320268454013
Epoch 443
-------------------------------
Batch 1/64 loss: -2.9074440002441406
Batch 2/64 loss: -2.8534412384033203
Batch 3/64 loss: -2.8403024673461914
Batch 4/64 loss: -2.691822052001953
Batch 5/64 loss: -2.8340301513671875
Batch 6/64 loss: -1.9748401641845703
Batch 7/64 loss: -2.8239736557006836
Batch 8/64 loss: -2.544663429260254
Batch 9/64 loss: -2.7283782958984375
Batch 10/64 loss: -2.951763153076172
Batch 11/64 loss: -2.872091293334961
Batch 12/64 loss: -2.4646406173706055
Batch 13/64 loss: -2.678956985473633
Batch 14/64 loss: -2.6793251037597656
Batch 15/64 loss: -2.8711233139038086
Batch 16/64 loss: -2.85552978515625
Batch 17/64 loss: -2.8584251403808594
Batch 18/64 loss: -2.7162513732910156
Batch 19/64 loss: -2.699049949645996
Batch 20/64 loss: -2.528156280517578
Batch 21/64 loss: -2.940744400024414
Batch 22/64 loss: -2.926516532897949
Batch 23/64 loss: -2.719554901123047
Batch 24/64 loss: -2.744565963745117
Batch 25/64 loss: -2.8034181594848633
Batch 26/64 loss: -2.796088218688965
Batch 27/64 loss: -2.8588476181030273
Batch 28/64 loss: -2.804922103881836
Batch 29/64 loss: -2.5677595138549805
Batch 30/64 loss: -2.5255794525146484
Batch 31/64 loss: -2.800840377807617
Batch 32/64 loss: -2.7601919174194336
Batch 33/64 loss: -2.8796825408935547
Batch 34/64 loss: -2.910403251647949
Batch 35/64 loss: -2.3832883834838867
Batch 36/64 loss: -2.9019899368286133
Batch 37/64 loss: -2.6123924255371094
Batch 38/64 loss: -2.5724306106567383
Batch 39/64 loss: -2.784573554992676
Batch 40/64 loss: -2.800729751586914
Batch 41/64 loss: -2.7753705978393555
Batch 42/64 loss: -2.7824249267578125
Batch 43/64 loss: -2.859286308288574
Batch 44/64 loss: -3.0369033813476562
Batch 45/64 loss: -2.854414939880371
Batch 46/64 loss: -2.776381492614746
Batch 47/64 loss: -2.864901542663574
Batch 48/64 loss: -2.511777877807617
Batch 49/64 loss: -2.907815933227539
Batch 50/64 loss: -2.6959800720214844
Batch 51/64 loss: -2.6718854904174805
Batch 52/64 loss: -2.9252328872680664
Batch 53/64 loss: -2.8857831954956055
Batch 54/64 loss: -2.823862075805664
Batch 55/64 loss: -2.855825424194336
Batch 56/64 loss: -2.973386764526367
Batch 57/64 loss: -2.5846786499023438
Batch 58/64 loss: -2.4127817153930664
Batch 59/64 loss: -2.05153751373291
Batch 60/64 loss: -2.813502311706543
Batch 61/64 loss: -2.618210792541504
Batch 62/64 loss: -2.6765851974487305
Batch 63/64 loss: -2.7234392166137695
Batch 64/64 loss: -7.2998857498168945
Epoch 443  Train loss: -2.792558598985859  Val loss: -3.0728138664743745
Epoch 444
-------------------------------
Batch 1/64 loss: -2.8656387329101562
Batch 2/64 loss: -2.82425594329834
Batch 3/64 loss: -2.7862720489501953
Batch 4/64 loss: -2.630457878112793
Batch 5/64 loss: -2.6663084030151367
Batch 6/64 loss: -2.8635120391845703
Batch 7/64 loss: -2.1220178604125977
Batch 8/64 loss: -2.8852081298828125
Batch 9/64 loss: -3.0703163146972656
Batch 10/64 loss: -2.6394052505493164
Batch 11/64 loss: -2.878416061401367
Batch 12/64 loss: -2.5868043899536133
Batch 13/64 loss: -2.766301155090332
Batch 14/64 loss: -3.012118339538574
Batch 15/64 loss: -2.853515625
Batch 16/64 loss: -2.842942237854004
Batch 17/64 loss: -2.8997764587402344
Batch 18/64 loss: -2.6354503631591797
Batch 19/64 loss: -2.870783805847168
Batch 20/64 loss: -2.651961326599121
Batch 21/64 loss: -2.833932876586914
Batch 22/64 loss: -2.9430341720581055
Batch 23/64 loss: -2.804316520690918
Batch 24/64 loss: -3.0308313369750977
Batch 25/64 loss: -2.88478946685791
Batch 26/64 loss: -2.9874629974365234
Batch 27/64 loss: -2.966465950012207
Batch 28/64 loss: -2.4768972396850586
Batch 29/64 loss: -2.5336484909057617
Batch 30/64 loss: -2.58577823638916
Batch 31/64 loss: -2.6951160430908203
Batch 32/64 loss: -2.427699089050293
Batch 33/64 loss: -2.95291805267334
Batch 34/64 loss: -2.676394462585449
Batch 35/64 loss: -2.943134307861328
Batch 36/64 loss: -2.6889915466308594
Batch 37/64 loss: -2.5161333084106445
Batch 38/64 loss: -2.6908178329467773
Batch 39/64 loss: -2.5788822174072266
Batch 40/64 loss: -2.856053352355957
Batch 41/64 loss: -2.9852466583251953
Batch 42/64 loss: -2.9212799072265625
Batch 43/64 loss: -2.6876440048217773
Batch 44/64 loss: -2.530226707458496
Batch 45/64 loss: -2.8470840454101562
Batch 46/64 loss: -2.7504987716674805
Batch 47/64 loss: -2.8134002685546875
Batch 48/64 loss: -2.7782459259033203
Batch 49/64 loss: -2.8159637451171875
Batch 50/64 loss: -2.822368621826172
Batch 51/64 loss: -2.7047910690307617
Batch 52/64 loss: -2.8341007232666016
Batch 53/64 loss: -2.675591468811035
Batch 54/64 loss: -2.645157814025879
Batch 55/64 loss: -2.646803855895996
Batch 56/64 loss: -2.853963851928711
Batch 57/64 loss: -2.966663360595703
Batch 58/64 loss: -2.867158889770508
Batch 59/64 loss: -2.7067346572875977
Batch 60/64 loss: -2.822648048400879
Batch 61/64 loss: -2.2296037673950195
Batch 62/64 loss: -2.789637565612793
Batch 63/64 loss: -2.638578414916992
Batch 64/64 loss: -7.526656150817871
Epoch 444  Train loss: -2.8141669666065887  Val loss: -3.0245475506864463
Epoch 445
-------------------------------
Batch 1/64 loss: -2.638484001159668
Batch 2/64 loss: -2.7182416915893555
Batch 3/64 loss: -2.9102659225463867
Batch 4/64 loss: -2.4034833908081055
Batch 5/64 loss: -2.883047103881836
Batch 6/64 loss: -2.779618263244629
Batch 7/64 loss: -2.6997289657592773
Batch 8/64 loss: -2.6465797424316406
Batch 9/64 loss: -2.56966495513916
Batch 10/64 loss: -2.7577896118164062
Batch 11/64 loss: -2.4621639251708984
Batch 12/64 loss: -2.5604639053344727
Batch 13/64 loss: -2.734762191772461
Batch 14/64 loss: -2.8738012313842773
Batch 15/64 loss: -1.9319124221801758
Batch 16/64 loss: -2.672112464904785
Batch 17/64 loss: -2.8432960510253906
Batch 18/64 loss: -2.6339187622070312
Batch 19/64 loss: -2.8350048065185547
Batch 20/64 loss: -2.820204734802246
Batch 21/64 loss: -2.222230911254883
Batch 22/64 loss: -2.6019487380981445
Batch 23/64 loss: -2.5563812255859375
Batch 24/64 loss: -2.6897974014282227
Batch 25/64 loss: -2.803624153137207
Batch 26/64 loss: -2.8915023803710938
Batch 27/64 loss: -2.7765378952026367
Batch 28/64 loss: -2.837681770324707
Batch 29/64 loss: -2.793642997741699
Batch 30/64 loss: -2.7067508697509766
Batch 31/64 loss: -2.385653495788574
Batch 32/64 loss: -2.721698760986328
Batch 33/64 loss: -2.4384355545043945
Batch 34/64 loss: -2.805116653442383
Batch 35/64 loss: -2.6986684799194336
Batch 36/64 loss: -2.7675046920776367
Batch 37/64 loss: -2.876659393310547
Batch 38/64 loss: -2.8925552368164062
Batch 39/64 loss: -2.267636299133301
Batch 40/64 loss: -2.883708953857422
Batch 41/64 loss: -2.8557701110839844
Batch 42/64 loss: -2.632124900817871
Batch 43/64 loss: -2.8440847396850586
Batch 44/64 loss: -2.6854515075683594
Batch 45/64 loss: -2.753936767578125
Batch 46/64 loss: -2.744328498840332
Batch 47/64 loss: -2.9211950302124023
Batch 48/64 loss: -2.6856002807617188
Batch 49/64 loss: -2.8399057388305664
Batch 50/64 loss: -2.8528566360473633
Batch 51/64 loss: -2.689472198486328
Batch 52/64 loss: -2.850778579711914
Batch 53/64 loss: -2.772951126098633
Batch 54/64 loss: -2.9668140411376953
Batch 55/64 loss: -2.927218437194824
Batch 56/64 loss: -2.8491554260253906
Batch 57/64 loss: -2.8009519577026367
Batch 58/64 loss: -2.870349884033203
Batch 59/64 loss: -2.703690528869629
Batch 60/64 loss: -2.9154300689697266
Batch 61/64 loss: -2.4654369354248047
Batch 62/64 loss: -2.822587013244629
Batch 63/64 loss: -2.846198081970215
Batch 64/64 loss: -7.273128986358643
Epoch 445  Train loss: -2.772445729199578  Val loss: -3.0818745983425284
Epoch 446
-------------------------------
Batch 1/64 loss: -2.774068832397461
Batch 2/64 loss: -2.5563182830810547
Batch 3/64 loss: -2.7850847244262695
Batch 4/64 loss: -2.77724552154541
Batch 5/64 loss: -2.695505142211914
Batch 6/64 loss: -2.8984766006469727
Batch 7/64 loss: -2.878811836242676
Batch 8/64 loss: -2.791860580444336
Batch 9/64 loss: -2.1184396743774414
Batch 10/64 loss: -2.8897571563720703
Batch 11/64 loss: -2.89493465423584
Batch 12/64 loss: -2.7325572967529297
Batch 13/64 loss: -2.779534339904785
Batch 14/64 loss: -2.5477170944213867
Batch 15/64 loss: -2.749746322631836
Batch 16/64 loss: -2.598142623901367
Batch 17/64 loss: -2.436272621154785
Batch 18/64 loss: -2.6507158279418945
Batch 19/64 loss: -2.635939598083496
Batch 20/64 loss: -2.947175979614258
Batch 21/64 loss: -2.638935089111328
Batch 22/64 loss: -2.7745723724365234
Batch 23/64 loss: -2.5848684310913086
Batch 24/64 loss: -2.642477035522461
Batch 25/64 loss: -2.9118824005126953
Batch 26/64 loss: -2.759855270385742
Batch 27/64 loss: -2.7523250579833984
Batch 28/64 loss: -2.0583505630493164
Batch 29/64 loss: -2.7710800170898438
Batch 30/64 loss: -2.6916275024414062
Batch 31/64 loss: -2.8435192108154297
Batch 32/64 loss: -2.389446258544922
Batch 33/64 loss: -3.0083961486816406
Batch 34/64 loss: -2.865509033203125
Batch 35/64 loss: -2.9899024963378906
Batch 36/64 loss: -3.0524702072143555
Batch 37/64 loss: -2.882253646850586
Batch 38/64 loss: -2.877138137817383
Batch 39/64 loss: -2.947920799255371
Batch 40/64 loss: -2.841299057006836
Batch 41/64 loss: -2.7440967559814453
Batch 42/64 loss: -2.7979469299316406
Batch 43/64 loss: -2.5046157836914062
Batch 44/64 loss: -2.7872142791748047
Batch 45/64 loss: -2.8705272674560547
Batch 46/64 loss: -2.9119415283203125
Batch 47/64 loss: -2.7187280654907227
Batch 48/64 loss: -2.9828100204467773
Batch 49/64 loss: -2.877656936645508
Batch 50/64 loss: -2.722423553466797
Batch 51/64 loss: -2.663569450378418
Batch 52/64 loss: -2.8155345916748047
Batch 53/64 loss: -2.881680488586426
Batch 54/64 loss: -2.704678535461426
Batch 55/64 loss: -2.7867422103881836
Batch 56/64 loss: -2.225399971008301
Batch 57/64 loss: -2.925334930419922
Batch 58/64 loss: -3.034914016723633
Batch 59/64 loss: -2.486856460571289
Batch 60/64 loss: -2.8534116744995117
Batch 61/64 loss: -2.641569137573242
Batch 62/64 loss: -2.5466442108154297
Batch 63/64 loss: -2.43560791015625
Batch 64/64 loss: -7.045275688171387
Epoch 446  Train loss: -2.786290116403617  Val loss: -3.1252869805929175
Epoch 447
-------------------------------
Batch 1/64 loss: -2.7711915969848633
Batch 2/64 loss: -2.823678970336914
Batch 3/64 loss: -3.071115493774414
Batch 4/64 loss: -2.705563545227051
Batch 5/64 loss: -2.763970375061035
Batch 6/64 loss: -2.856778144836426
Batch 7/64 loss: -2.574808120727539
Batch 8/64 loss: -2.3886842727661133
Batch 9/64 loss: -2.4819936752319336
Batch 10/64 loss: -2.779500961303711
Batch 11/64 loss: -2.9006567001342773
Batch 12/64 loss: -2.5025129318237305
Batch 13/64 loss: -2.8032970428466797
Batch 14/64 loss: -2.726141929626465
Batch 15/64 loss: -2.866366386413574
Batch 16/64 loss: -2.8846054077148438
Batch 17/64 loss: -2.7657337188720703
Batch 18/64 loss: -2.8092079162597656
Batch 19/64 loss: -2.9170045852661133
Batch 20/64 loss: -2.8678102493286133
Batch 21/64 loss: -2.6348066329956055
Batch 22/64 loss: -2.707866668701172
Batch 23/64 loss: -2.8451051712036133
Batch 24/64 loss: -2.8579320907592773
Batch 25/64 loss: -2.6879539489746094
Batch 26/64 loss: -2.841094970703125
Batch 27/64 loss: -2.8719167709350586
Batch 28/64 loss: -2.0745372772216797
Batch 29/64 loss: -2.821560859680176
Batch 30/64 loss: -2.8469057083129883
Batch 31/64 loss: -2.945113182067871
Batch 32/64 loss: -2.7602272033691406
Batch 33/64 loss: -2.971104621887207
Batch 34/64 loss: -2.283013343811035
Batch 35/64 loss: -2.6612672805786133
Batch 36/64 loss: -2.9022350311279297
Batch 37/64 loss: -2.787628173828125
Batch 38/64 loss: -2.844395637512207
Batch 39/64 loss: -2.6372241973876953
Batch 40/64 loss: -2.8517370223999023
Batch 41/64 loss: -2.6055335998535156
Batch 42/64 loss: -2.9319143295288086
Batch 43/64 loss: -3.010038375854492
Batch 44/64 loss: -2.7407894134521484
Batch 45/64 loss: -2.712491035461426
Batch 46/64 loss: -2.901991844177246
Batch 47/64 loss: -2.7450361251831055
Batch 48/64 loss: -2.8816652297973633
Batch 49/64 loss: -3.1006698608398438
Batch 50/64 loss: -2.5675840377807617
Batch 51/64 loss: -2.885735511779785
Batch 52/64 loss: -2.5049610137939453
Batch 53/64 loss: -2.9321470260620117
Batch 54/64 loss: -2.953923225402832
Batch 55/64 loss: -2.8324718475341797
Batch 56/64 loss: -2.8452415466308594
Batch 57/64 loss: -2.845034599304199
Batch 58/64 loss: -3.0019350051879883
Batch 59/64 loss: -2.9178314208984375
Batch 60/64 loss: -2.889101028442383
Batch 61/64 loss: -2.701265335083008
Batch 62/64 loss: -2.8048791885375977
Batch 63/64 loss: -2.7517480850219727
Batch 64/64 loss: -7.2537126541137695
Epoch 447  Train loss: -2.8329179763793944  Val loss: -3.1548453655439554
Epoch 448
-------------------------------
Batch 1/64 loss: -2.789015769958496
Batch 2/64 loss: -2.833066940307617
Batch 3/64 loss: -2.861722946166992
Batch 4/64 loss: -2.700026512145996
Batch 5/64 loss: -3.013270378112793
Batch 6/64 loss: -2.8569393157958984
Batch 7/64 loss: -3.0286903381347656
Batch 8/64 loss: -2.9966468811035156
Batch 9/64 loss: -2.852658271789551
Batch 10/64 loss: -3.040102958679199
Batch 11/64 loss: -2.9826316833496094
Batch 12/64 loss: -2.812246322631836
Batch 13/64 loss: -2.915773391723633
Batch 14/64 loss: -2.6924219131469727
Batch 15/64 loss: -2.4570255279541016
Batch 16/64 loss: -2.9731578826904297
Batch 17/64 loss: -2.8062782287597656
Batch 18/64 loss: -2.8122549057006836
Batch 19/64 loss: -2.6509103775024414
Batch 20/64 loss: -2.894054412841797
Batch 21/64 loss: -2.7602930068969727
Batch 22/64 loss: -2.9004526138305664
Batch 23/64 loss: -2.896237373352051
Batch 24/64 loss: -2.9450883865356445
Batch 25/64 loss: -2.5451393127441406
Batch 26/64 loss: -2.9302186965942383
Batch 27/64 loss: -2.719907760620117
Batch 28/64 loss: -2.7825393676757812
Batch 29/64 loss: -2.8441390991210938
Batch 30/64 loss: -2.6920995712280273
Batch 31/64 loss: -2.1059627532958984
Batch 32/64 loss: -2.762417793273926
Batch 33/64 loss: -2.8674516677856445
Batch 34/64 loss: -2.840517044067383
Batch 35/64 loss: -2.5389490127563477
Batch 36/64 loss: -2.870542526245117
Batch 37/64 loss: -2.86330509185791
Batch 38/64 loss: -2.808706283569336
Batch 39/64 loss: -2.788299560546875
Batch 40/64 loss: -2.563168525695801
Batch 41/64 loss: -2.7620315551757812
Batch 42/64 loss: -2.882063865661621
Batch 43/64 loss: -2.681515693664551
Batch 44/64 loss: -2.8112287521362305
Batch 45/64 loss: -2.761948585510254
Batch 46/64 loss: -2.796229362487793
Batch 47/64 loss: -2.7847843170166016
Batch 48/64 loss: -2.716841697692871
Batch 49/64 loss: -2.814427375793457
Batch 50/64 loss: -2.175405502319336
Batch 51/64 loss: -2.6035051345825195
Batch 52/64 loss: -2.7934188842773438
Batch 53/64 loss: -2.7257766723632812
Batch 54/64 loss: -2.8858461380004883
Batch 55/64 loss: -2.602353096008301
Batch 56/64 loss: -2.540328025817871
Batch 57/64 loss: -2.9507293701171875
Batch 58/64 loss: -2.8223142623901367
Batch 59/64 loss: -2.8194923400878906
Batch 60/64 loss: -2.649563789367676
Batch 61/64 loss: -2.319459915161133
Batch 62/64 loss: -2.9123640060424805
Batch 63/64 loss: -2.843380928039551
Batch 64/64 loss: -7.427341461181641
Epoch 448  Train loss: -2.8269779728908166  Val loss: -3.1426003315194775
Epoch 449
-------------------------------
Batch 1/64 loss: -2.794365882873535
Batch 2/64 loss: -2.688335418701172
Batch 3/64 loss: -2.823486328125
Batch 4/64 loss: -2.7374649047851562
Batch 5/64 loss: -2.860494613647461
Batch 6/64 loss: -2.555051803588867
Batch 7/64 loss: -2.8389759063720703
Batch 8/64 loss: -2.9527530670166016
Batch 9/64 loss: -2.95743465423584
Batch 10/64 loss: -2.69497013092041
Batch 11/64 loss: -2.9216670989990234
Batch 12/64 loss: -3.034918785095215
Batch 13/64 loss: -2.6627588272094727
Batch 14/64 loss: -2.8528356552124023
Batch 15/64 loss: -2.6607179641723633
Batch 16/64 loss: -2.734238624572754
Batch 17/64 loss: -2.7461557388305664
Batch 18/64 loss: -2.571652412414551
Batch 19/64 loss: -2.8265743255615234
Batch 20/64 loss: -2.082223892211914
Batch 21/64 loss: -2.6953563690185547
Batch 22/64 loss: -3.010373115539551
Batch 23/64 loss: -2.7293167114257812
Batch 24/64 loss: -2.9847211837768555
Batch 25/64 loss: -2.8532791137695312
Batch 26/64 loss: -2.9921865463256836
Batch 27/64 loss: -2.8094282150268555
Batch 28/64 loss: -2.740114212036133
Batch 29/64 loss: -2.7016687393188477
Batch 30/64 loss: -2.850518226623535
Batch 31/64 loss: -2.768172264099121
Batch 32/64 loss: -2.7051000595092773
Batch 33/64 loss: -2.82936954498291
Batch 34/64 loss: -2.8877573013305664
Batch 35/64 loss: -2.782090187072754
Batch 36/64 loss: -2.7515039443969727
Batch 37/64 loss: -2.767719268798828
Batch 38/64 loss: -2.8759689331054688
Batch 39/64 loss: -2.7765588760375977
Batch 40/64 loss: -2.269381523132324
Batch 41/64 loss: -2.728548049926758
Batch 42/64 loss: -2.1871824264526367
Batch 43/64 loss: -2.5694026947021484
Batch 44/64 loss: -2.7256059646606445
Batch 45/64 loss: -2.7597265243530273
Batch 46/64 loss: -2.6932859420776367
Batch 47/64 loss: -2.6383628845214844
Batch 48/64 loss: -2.748053550720215
Batch 49/64 loss: -2.7277002334594727
Batch 50/64 loss: -2.715740203857422
Batch 51/64 loss: -2.5289363861083984
Batch 52/64 loss: -2.6085386276245117
Batch 53/64 loss: -2.7957887649536133
Batch 54/64 loss: -2.714890480041504
Batch 55/64 loss: -2.720796585083008
Batch 56/64 loss: -2.901106834411621
Batch 57/64 loss: -2.865388870239258
Batch 58/64 loss: -2.8319406509399414
Batch 59/64 loss: -2.747471809387207
Batch 60/64 loss: -1.4955081939697266
Batch 61/64 loss: -2.7541751861572266
Batch 62/64 loss: -2.7630701065063477
Batch 63/64 loss: -2.805696487426758
Batch 64/64 loss: -7.010319709777832
Epoch 449  Train loss: -2.7774481193692075  Val loss: -2.8721750790310887
Epoch 450
-------------------------------
Batch 1/64 loss: -2.5852537155151367
Batch 2/64 loss: -2.680069923400879
Batch 3/64 loss: -2.741922378540039
Batch 4/64 loss: -2.672863006591797
Batch 5/64 loss: -2.739269256591797
Batch 6/64 loss: -2.721877098083496
Batch 7/64 loss: -2.5292463302612305
Batch 8/64 loss: -2.8527841567993164
Batch 9/64 loss: -2.6329917907714844
Batch 10/64 loss: -2.7688474655151367
Batch 11/64 loss: -2.799036979675293
Batch 12/64 loss: -2.7318544387817383
Batch 13/64 loss: -2.178091049194336
Batch 14/64 loss: -2.60653018951416
Batch 15/64 loss: -2.844329833984375
Batch 16/64 loss: -2.742386817932129
Batch 17/64 loss: -2.807499885559082
Batch 18/64 loss: -2.784865379333496
Batch 19/64 loss: -2.856743812561035
Batch 20/64 loss: -2.7997379302978516
Batch 21/64 loss: -2.804689407348633
Batch 22/64 loss: -2.7382259368896484
Batch 23/64 loss: -2.774290084838867
Batch 24/64 loss: -2.7623062133789062
Batch 25/64 loss: -2.2526321411132812
Batch 26/64 loss: -3.055936813354492
Batch 27/64 loss: -2.837268829345703
Batch 28/64 loss: -2.7749948501586914
Batch 29/64 loss: -2.7175941467285156
Batch 30/64 loss: -2.735947608947754
Batch 31/64 loss: -2.6410388946533203
Batch 32/64 loss: -2.778620719909668
Batch 33/64 loss: -2.7006454467773438
Batch 34/64 loss: -2.8908843994140625
Batch 35/64 loss: -2.727069854736328
Batch 36/64 loss: -2.4709014892578125
Batch 37/64 loss: -2.891143798828125
Batch 38/64 loss: -2.865100860595703
Batch 39/64 loss: -2.049184799194336
Batch 40/64 loss: -2.719571113586426
Batch 41/64 loss: -2.0724916458129883
Batch 42/64 loss: -2.6221675872802734
Batch 43/64 loss: -2.879855155944824
Batch 44/64 loss: -2.8294153213500977
Batch 45/64 loss: -2.700070381164551
Batch 46/64 loss: -2.7889814376831055
Batch 47/64 loss: -2.796462059020996
Batch 48/64 loss: -2.7648677825927734
Batch 49/64 loss: -2.6981019973754883
Batch 50/64 loss: -2.7127132415771484
Batch 51/64 loss: -2.8769702911376953
Batch 52/64 loss: -2.754031181335449
Batch 53/64 loss: -2.6300525665283203
Batch 54/64 loss: -2.7060747146606445
Batch 55/64 loss: -2.71441650390625
Batch 56/64 loss: -2.8356828689575195
Batch 57/64 loss: -2.4807519912719727
Batch 58/64 loss: -2.699315071105957
Batch 59/64 loss: -2.867445945739746
Batch 60/64 loss: -2.9454259872436523
Batch 61/64 loss: -2.8779449462890625
Batch 62/64 loss: -2.5942726135253906
Batch 63/64 loss: -2.4787979125976562
Batch 64/64 loss: -7.244163990020752
Epoch 450  Train loss: -2.7611557810914285  Val loss: -3.0048354761707006
Epoch 451
-------------------------------
Batch 1/64 loss: -2.8558216094970703
Batch 2/64 loss: -2.864546775817871
Batch 3/64 loss: -2.7310657501220703
Batch 4/64 loss: -2.568187713623047
Batch 5/64 loss: -2.738828659057617
Batch 6/64 loss: -2.0047473907470703
Batch 7/64 loss: -2.7879648208618164
Batch 8/64 loss: -2.928119659423828
Batch 9/64 loss: -2.7563343048095703
Batch 10/64 loss: -2.5400562286376953
Batch 11/64 loss: -2.584506034851074
Batch 12/64 loss: -2.760655403137207
Batch 13/64 loss: -2.680617332458496
Batch 14/64 loss: -2.887401580810547
Batch 15/64 loss: -2.729325294494629
Batch 16/64 loss: -2.9843740463256836
Batch 17/64 loss: -2.8716650009155273
Batch 18/64 loss: -2.806955337524414
Batch 19/64 loss: -2.8659181594848633
Batch 20/64 loss: -2.7723960876464844
Batch 21/64 loss: -2.7610788345336914
Batch 22/64 loss: -2.658188819885254
Batch 23/64 loss: -2.8409423828125
Batch 24/64 loss: -2.635103225708008
Batch 25/64 loss: -2.6743850708007812
Batch 26/64 loss: -2.575847625732422
Batch 27/64 loss: -2.7884092330932617
Batch 28/64 loss: -2.8561506271362305
Batch 29/64 loss: -2.6949844360351562
Batch 30/64 loss: -2.6526193618774414
Batch 31/64 loss: -2.7882204055786133
Batch 32/64 loss: -2.7459144592285156
Batch 33/64 loss: -2.3895978927612305
Batch 34/64 loss: -2.723329544067383
Batch 35/64 loss: -2.726466178894043
Batch 36/64 loss: -2.6552200317382812
Batch 37/64 loss: -2.271360397338867
Batch 38/64 loss: -2.784787178039551
Batch 39/64 loss: -2.810770034790039
Batch 40/64 loss: -2.750208854675293
Batch 41/64 loss: -2.683506965637207
Batch 42/64 loss: -2.5254392623901367
Batch 43/64 loss: -2.610405921936035
Batch 44/64 loss: -2.740290641784668
Batch 45/64 loss: -2.8766355514526367
Batch 46/64 loss: -2.6857337951660156
Batch 47/64 loss: -2.912224769592285
Batch 48/64 loss: -2.1534671783447266
Batch 49/64 loss: -2.6129446029663086
Batch 50/64 loss: -2.496011734008789
Batch 51/64 loss: -2.8761539459228516
Batch 52/64 loss: -2.809110641479492
Batch 53/64 loss: -2.925614356994629
Batch 54/64 loss: -2.855356216430664
Batch 55/64 loss: -2.8347768783569336
Batch 56/64 loss: -2.653646469116211
Batch 57/64 loss: -2.8130931854248047
Batch 58/64 loss: -2.6094284057617188
Batch 59/64 loss: -2.8271961212158203
Batch 60/64 loss: -2.7787532806396484
Batch 61/64 loss: -2.73480224609375
Batch 62/64 loss: -2.7671070098876953
Batch 63/64 loss: -2.6704721450805664
Batch 64/64 loss: -7.412619590759277
Epoch 451  Train loss: -2.7688581616270778  Val loss: -2.9689169945995424
Epoch 452
-------------------------------
Batch 1/64 loss: -2.711353302001953
Batch 2/64 loss: -2.7453269958496094
Batch 3/64 loss: -2.821200370788574
Batch 4/64 loss: -2.8890609741210938
Batch 5/64 loss: -2.6648807525634766
Batch 6/64 loss: -2.65938663482666
Batch 7/64 loss: -3.108844757080078
Batch 8/64 loss: -2.571526527404785
Batch 9/64 loss: -2.7290220260620117
Batch 10/64 loss: -2.8619298934936523
Batch 11/64 loss: -2.8854942321777344
Batch 12/64 loss: -2.697115898132324
Batch 13/64 loss: -2.4351892471313477
Batch 14/64 loss: -2.7084274291992188
Batch 15/64 loss: -2.2008914947509766
Batch 16/64 loss: -2.758390426635742
Batch 17/64 loss: -2.721729278564453
Batch 18/64 loss: -3.006260871887207
Batch 19/64 loss: -2.747049331665039
Batch 20/64 loss: -2.7076845169067383
Batch 21/64 loss: -2.7120437622070312
Batch 22/64 loss: -2.901005744934082
Batch 23/64 loss: -2.231095314025879
Batch 24/64 loss: -2.5649986267089844
Batch 25/64 loss: -2.8793792724609375
Batch 26/64 loss: -2.710599899291992
Batch 27/64 loss: -2.6586523056030273
Batch 28/64 loss: -2.71014404296875
Batch 29/64 loss: -2.5622339248657227
Batch 30/64 loss: -2.772303581237793
Batch 31/64 loss: -2.7873077392578125
Batch 32/64 loss: -2.897976875305176
Batch 33/64 loss: -2.8622217178344727
Batch 34/64 loss: -2.99893856048584
Batch 35/64 loss: -2.809504508972168
Batch 36/64 loss: -2.5785646438598633
Batch 37/64 loss: -2.8531742095947266
Batch 38/64 loss: -2.7488489151000977
Batch 39/64 loss: -2.883575439453125
Batch 40/64 loss: -2.671969413757324
Batch 41/64 loss: -2.7146549224853516
Batch 42/64 loss: -2.700819969177246
Batch 43/64 loss: -2.766472816467285
Batch 44/64 loss: -2.8098630905151367
Batch 45/64 loss: -2.648098945617676
Batch 46/64 loss: -2.77486515045166
Batch 47/64 loss: -2.816847801208496
Batch 48/64 loss: -2.726552963256836
Batch 49/64 loss: -2.78023624420166
Batch 50/64 loss: -2.718017578125
Batch 51/64 loss: -2.8671178817749023
Batch 52/64 loss: -2.942032814025879
Batch 53/64 loss: -2.940776824951172
Batch 54/64 loss: -2.871112823486328
Batch 55/64 loss: -2.7989816665649414
Batch 56/64 loss: -2.8958911895751953
Batch 57/64 loss: -2.876589775085449
Batch 58/64 loss: -2.8545169830322266
Batch 59/64 loss: -2.165546417236328
Batch 60/64 loss: -2.9498510360717773
Batch 61/64 loss: -3.01617431640625
Batch 62/64 loss: -2.8394174575805664
Batch 63/64 loss: -2.7416419982910156
Batch 64/64 loss: -7.327056407928467
Epoch 452  Train loss: -2.809987081265917  Val loss: -2.657243499231502
Epoch 453
-------------------------------
Batch 1/64 loss: -2.8695011138916016
Batch 2/64 loss: -2.730860710144043
Batch 3/64 loss: -1.811030387878418
Batch 4/64 loss: -2.729580879211426
Batch 5/64 loss: -2.5398569107055664
Batch 6/64 loss: -2.5908708572387695
Batch 7/64 loss: -2.5558319091796875
Batch 8/64 loss: -2.6606359481811523
Batch 9/64 loss: -2.643299102783203
Batch 10/64 loss: -2.5541696548461914
Batch 11/64 loss: -2.3691205978393555
Batch 12/64 loss: -2.6567583084106445
Batch 13/64 loss: -2.752714157104492
Batch 14/64 loss: -2.212517738342285
Batch 15/64 loss: -2.6956682205200195
Batch 16/64 loss: -2.5606842041015625
Batch 17/64 loss: -2.704831123352051
Batch 18/64 loss: -1.8722562789916992
Batch 19/64 loss: -2.746525764465332
Batch 20/64 loss: -2.5543155670166016
Batch 21/64 loss: -2.654294967651367
Batch 22/64 loss: -2.5151901245117188
Batch 23/64 loss: -2.768575668334961
Batch 24/64 loss: -2.668506622314453
Batch 25/64 loss: -2.073291778564453
Batch 26/64 loss: -2.6829328536987305
Batch 27/64 loss: -2.3953866958618164
Batch 28/64 loss: -2.7620553970336914
Batch 29/64 loss: -2.6509904861450195
Batch 30/64 loss: -2.7828311920166016
Batch 31/64 loss: -2.737874984741211
Batch 32/64 loss: -2.7179832458496094
Batch 33/64 loss: -2.717395782470703
Batch 34/64 loss: -2.670840263366699
Batch 35/64 loss: -2.741039276123047
Batch 36/64 loss: -2.7812652587890625
Batch 37/64 loss: -2.389263153076172
Batch 38/64 loss: -2.707951545715332
Batch 39/64 loss: -2.876236915588379
Batch 40/64 loss: -2.5271987915039062
Batch 41/64 loss: -2.6822433471679688
Batch 42/64 loss: -2.68450927734375
Batch 43/64 loss: -2.821366310119629
Batch 44/64 loss: -2.6985559463500977
Batch 45/64 loss: -2.67301082611084
Batch 46/64 loss: -2.535654067993164
Batch 47/64 loss: -2.7613697052001953
Batch 48/64 loss: -2.6427059173583984
Batch 49/64 loss: -2.659792900085449
Batch 50/64 loss: -2.5257835388183594
Batch 51/64 loss: -2.7910823822021484
Batch 52/64 loss: -2.775991439819336
Batch 53/64 loss: -2.486212730407715
Batch 54/64 loss: -2.7022018432617188
Batch 55/64 loss: -2.638827323913574
Batch 56/64 loss: -2.9070749282836914
Batch 57/64 loss: -2.641315460205078
Batch 58/64 loss: -2.8611860275268555
Batch 59/64 loss: -2.592165946960449
Batch 60/64 loss: -2.6965103149414062
Batch 61/64 loss: -2.4655895233154297
Batch 62/64 loss: -2.8059329986572266
Batch 63/64 loss: -2.559101104736328
Batch 64/64 loss: -7.310532093048096
Epoch 453  Train loss: -2.6780112528333477  Val loss: -3.072864139202944
Epoch 454
-------------------------------
Batch 1/64 loss: -2.778654098510742
Batch 2/64 loss: -2.8247194290161133
Batch 3/64 loss: -2.746601104736328
Batch 4/64 loss: -2.586857795715332
Batch 5/64 loss: -2.502939224243164
Batch 6/64 loss: -2.7219104766845703
Batch 7/64 loss: -2.7411069869995117
Batch 8/64 loss: -2.8366947174072266
Batch 9/64 loss: -2.6872386932373047
Batch 10/64 loss: -2.253448486328125
Batch 11/64 loss: -2.349654197692871
Batch 12/64 loss: -2.790132522583008
Batch 13/64 loss: -2.7051239013671875
Batch 14/64 loss: -2.2991676330566406
Batch 15/64 loss: -2.4823169708251953
Batch 16/64 loss: -2.8778553009033203
Batch 17/64 loss: -2.8594560623168945
Batch 18/64 loss: -2.7212753295898438
Batch 19/64 loss: -2.7792234420776367
Batch 20/64 loss: -2.7841339111328125
Batch 21/64 loss: -2.646331787109375
Batch 22/64 loss: -2.8155317306518555
Batch 23/64 loss: -2.69014835357666
Batch 24/64 loss: -3.0103988647460938
Batch 25/64 loss: -2.6059961318969727
Batch 26/64 loss: -2.915027618408203
Batch 27/64 loss: -2.8598556518554688
Batch 28/64 loss: -2.644688606262207
Batch 29/64 loss: -2.744821548461914
Batch 30/64 loss: -1.9644145965576172
Batch 31/64 loss: -2.635573387145996
Batch 32/64 loss: -2.6808176040649414
Batch 33/64 loss: -2.7629995346069336
Batch 34/64 loss: -2.8030929565429688
Batch 35/64 loss: -2.6141748428344727
Batch 36/64 loss: -2.725863456726074
Batch 37/64 loss: -2.902528762817383
Batch 38/64 loss: -2.8393373489379883
Batch 39/64 loss: -2.6446380615234375
Batch 40/64 loss: -2.846599578857422
Batch 41/64 loss: -2.8444747924804688
Batch 42/64 loss: -2.7366199493408203
Batch 43/64 loss: -2.6458168029785156
Batch 44/64 loss: -2.9030237197875977
Batch 45/64 loss: -2.4811134338378906
Batch 46/64 loss: -2.7073793411254883
Batch 47/64 loss: -2.819772720336914
Batch 48/64 loss: -3.0229368209838867
Batch 49/64 loss: -2.7277793884277344
Batch 50/64 loss: -2.731595993041992
Batch 51/64 loss: -2.625422477722168
Batch 52/64 loss: -2.684724807739258
Batch 53/64 loss: -2.5102548599243164
Batch 54/64 loss: -2.755979537963867
Batch 55/64 loss: -3.019463539123535
Batch 56/64 loss: -2.6844921112060547
Batch 57/64 loss: -2.8543100357055664
Batch 58/64 loss: -2.6618728637695312
Batch 59/64 loss: -2.997457504272461
Batch 60/64 loss: -2.5491504669189453
Batch 61/64 loss: -2.7825536727905273
Batch 62/64 loss: -2.425039291381836
Batch 63/64 loss: -2.7437124252319336
Batch 64/64 loss: -7.025852680206299
Epoch 454  Train loss: -2.7586774395961386  Val loss: -3.080671041691836
Epoch 455
-------------------------------
Batch 1/64 loss: -2.7699060440063477
Batch 2/64 loss: -2.989199638366699
Batch 3/64 loss: -2.847454071044922
Batch 4/64 loss: -2.114511489868164
Batch 5/64 loss: -2.2957162857055664
Batch 6/64 loss: -2.6679697036743164
Batch 7/64 loss: -2.8893537521362305
Batch 8/64 loss: -2.704897880554199
Batch 9/64 loss: -2.725651741027832
Batch 10/64 loss: -2.795212745666504
Batch 11/64 loss: -2.8488054275512695
Batch 12/64 loss: -2.6528501510620117
Batch 13/64 loss: -2.4298410415649414
Batch 14/64 loss: -2.7133588790893555
Batch 15/64 loss: -2.7982606887817383
Batch 16/64 loss: -2.759091377258301
Batch 17/64 loss: -2.8369226455688477
Batch 18/64 loss: -2.8331565856933594
Batch 19/64 loss: -2.8730993270874023
Batch 20/64 loss: -2.867445945739746
Batch 21/64 loss: -2.8577404022216797
Batch 22/64 loss: -2.925718307495117
Batch 23/64 loss: -2.5486135482788086
Batch 24/64 loss: -2.7648544311523438
Batch 25/64 loss: -2.2061824798583984
Batch 26/64 loss: -2.8273887634277344
Batch 27/64 loss: -2.912984848022461
Batch 28/64 loss: -2.850043296813965
Batch 29/64 loss: -2.5785226821899414
Batch 30/64 loss: -2.8976850509643555
Batch 31/64 loss: -2.96321964263916
Batch 32/64 loss: -2.9349517822265625
Batch 33/64 loss: -2.811166763305664
Batch 34/64 loss: -2.775602340698242
Batch 35/64 loss: -2.8092336654663086
Batch 36/64 loss: -2.6004247665405273
Batch 37/64 loss: -2.6036272048950195
Batch 38/64 loss: -2.823704719543457
Batch 39/64 loss: -3.0118656158447266
Batch 40/64 loss: -2.924633026123047
Batch 41/64 loss: -2.938551902770996
Batch 42/64 loss: -2.7837886810302734
Batch 43/64 loss: -2.9868574142456055
Batch 44/64 loss: -2.988504409790039
Batch 45/64 loss: -3.0847301483154297
Batch 46/64 loss: -2.8841419219970703
Batch 47/64 loss: -2.9947509765625
Batch 48/64 loss: -2.909499168395996
Batch 49/64 loss: -2.8991432189941406
Batch 50/64 loss: -2.5015010833740234
Batch 51/64 loss: -2.4336204528808594
Batch 52/64 loss: -2.7489376068115234
Batch 53/64 loss: -2.8069772720336914
Batch 54/64 loss: -2.558412551879883
Batch 55/64 loss: -2.9167041778564453
Batch 56/64 loss: -2.8275232315063477
Batch 57/64 loss: -2.786458969116211
Batch 58/64 loss: -2.641495704650879
Batch 59/64 loss: -2.965640068054199
Batch 60/64 loss: -2.994318962097168
Batch 61/64 loss: -2.850510597229004
Batch 62/64 loss: -2.7961177825927734
Batch 63/64 loss: -2.7256975173950195
Batch 64/64 loss: -7.3953142166137695
Epoch 455  Train loss: -2.833117462606991  Val loss: -3.1436931177512886
Epoch 456
-------------------------------
Batch 1/64 loss: -3.0330066680908203
Batch 2/64 loss: -3.0092239379882812
Batch 3/64 loss: -2.9353885650634766
Batch 4/64 loss: -2.806722640991211
Batch 5/64 loss: -2.761423110961914
Batch 6/64 loss: -2.9530773162841797
Batch 7/64 loss: -2.909465789794922
Batch 8/64 loss: -2.5755300521850586
Batch 9/64 loss: -2.777538299560547
Batch 10/64 loss: -2.885209083557129
Batch 11/64 loss: -2.8019046783447266
Batch 12/64 loss: -2.929293632507324
Batch 13/64 loss: -2.9095382690429688
Batch 14/64 loss: -2.693291664123535
Batch 15/64 loss: -2.9565534591674805
Batch 16/64 loss: -2.689183235168457
Batch 17/64 loss: -2.7950668334960938
Batch 18/64 loss: -2.5899620056152344
Batch 19/64 loss: -2.7848072052001953
Batch 20/64 loss: -2.7430896759033203
Batch 21/64 loss: -2.035172462463379
Batch 22/64 loss: -2.68190860748291
Batch 23/64 loss: -2.876467704772949
Batch 24/64 loss: -2.6407384872436523
Batch 25/64 loss: -2.9850282669067383
Batch 26/64 loss: -2.9864559173583984
Batch 27/64 loss: -3.059939384460449
Batch 28/64 loss: -2.8876285552978516
Batch 29/64 loss: -2.7677001953125
Batch 30/64 loss: -2.845494270324707
Batch 31/64 loss: -2.878162384033203
Batch 32/64 loss: -2.7225351333618164
Batch 33/64 loss: -2.7707347869873047
Batch 34/64 loss: -2.683704376220703
Batch 35/64 loss: -2.447751045227051
Batch 36/64 loss: -2.8987512588500977
Batch 37/64 loss: -2.8240966796875
Batch 38/64 loss: -2.7343149185180664
Batch 39/64 loss: -2.74224853515625
Batch 40/64 loss: -2.5761356353759766
Batch 41/64 loss: -2.6789636611938477
Batch 42/64 loss: -2.717350959777832
Batch 43/64 loss: -2.8052845001220703
Batch 44/64 loss: -2.605844497680664
Batch 45/64 loss: -3.069584846496582
Batch 46/64 loss: -2.896782875061035
Batch 47/64 loss: -2.9592113494873047
Batch 48/64 loss: -2.441361427307129
Batch 49/64 loss: -2.8819360733032227
Batch 50/64 loss: -3.0396528244018555
Batch 51/64 loss: -2.7623777389526367
Batch 52/64 loss: -2.955986976623535
Batch 53/64 loss: -2.661005973815918
Batch 54/64 loss: -2.6451797485351562
Batch 55/64 loss: -2.4801321029663086
Batch 56/64 loss: -2.7557601928710938
Batch 57/64 loss: -2.920535087585449
Batch 58/64 loss: -2.682201385498047
Batch 59/64 loss: -2.901604652404785
Batch 60/64 loss: -2.600094795227051
Batch 61/64 loss: -2.9472837448120117
Batch 62/64 loss: -2.866565704345703
Batch 63/64 loss: -2.8900022506713867
Batch 64/64 loss: -6.564347267150879
Epoch 456  Train loss: -2.834073859570073  Val loss: -3.129610395923103
Epoch 457
-------------------------------
Batch 1/64 loss: -1.9429988861083984
Batch 2/64 loss: -2.8817853927612305
Batch 3/64 loss: -2.731959342956543
Batch 4/64 loss: -2.954385757446289
Batch 5/64 loss: -2.780552864074707
Batch 6/64 loss: -2.8420534133911133
Batch 7/64 loss: -2.878173828125
Batch 8/64 loss: -2.4790096282958984
Batch 9/64 loss: -2.931987762451172
Batch 10/64 loss: -2.8980770111083984
Batch 11/64 loss: -2.8861522674560547
Batch 12/64 loss: -2.6304101943969727
Batch 13/64 loss: -2.9085235595703125
Batch 14/64 loss: -2.8539466857910156
Batch 15/64 loss: -2.963068962097168
Batch 16/64 loss: -2.9205427169799805
Batch 17/64 loss: -2.6910953521728516
Batch 18/64 loss: -2.832773208618164
Batch 19/64 loss: -2.8763694763183594
Batch 20/64 loss: -2.7453813552856445
Batch 21/64 loss: -2.618435859680176
Batch 22/64 loss: -2.940028190612793
Batch 23/64 loss: -2.743863105773926
Batch 24/64 loss: -2.805689811706543
Batch 25/64 loss: -2.450162887573242
Batch 26/64 loss: -2.1491212844848633
Batch 27/64 loss: -2.625432014465332
Batch 28/64 loss: -2.9660797119140625
Batch 29/64 loss: -2.565610885620117
Batch 30/64 loss: -2.994077682495117
Batch 31/64 loss: -2.611018180847168
Batch 32/64 loss: -2.6549015045166016
Batch 33/64 loss: -2.709874153137207
Batch 34/64 loss: -2.7688827514648438
Batch 35/64 loss: -2.825657844543457
Batch 36/64 loss: -2.800945281982422
Batch 37/64 loss: -2.8887758255004883
Batch 38/64 loss: -2.807307243347168
Batch 39/64 loss: -2.8432865142822266
Batch 40/64 loss: -1.9349737167358398
Batch 41/64 loss: -2.584646224975586
Batch 42/64 loss: -2.880640983581543
Batch 43/64 loss: -2.774251937866211
Batch 44/64 loss: -2.69281005859375
Batch 45/64 loss: -2.75079345703125
Batch 46/64 loss: -2.738994598388672
Batch 47/64 loss: -2.7988052368164062
Batch 48/64 loss: -2.8285083770751953
Batch 49/64 loss: -2.8511266708374023
Batch 50/64 loss: -2.9270009994506836
Batch 51/64 loss: -2.7916975021362305
Batch 52/64 loss: -2.914809226989746
Batch 53/64 loss: -2.5917510986328125
Batch 54/64 loss: -2.9432010650634766
Batch 55/64 loss: -2.859438896179199
Batch 56/64 loss: -2.6703128814697266
Batch 57/64 loss: -2.9345903396606445
Batch 58/64 loss: -2.7225112915039062
Batch 59/64 loss: -2.7855043411254883
Batch 60/64 loss: -2.918119430541992
Batch 61/64 loss: -2.6194581985473633
Batch 62/64 loss: -3.0199851989746094
Batch 63/64 loss: -2.937596321105957
Batch 64/64 loss: -7.369049072265625
Epoch 457  Train loss: -2.814066090303309  Val loss: -3.213900051575756
Epoch 458
-------------------------------
Batch 1/64 loss: -2.842670440673828
Batch 2/64 loss: -2.689682960510254
Batch 3/64 loss: -2.53696346282959
Batch 4/64 loss: -2.884136199951172
Batch 5/64 loss: -2.9718284606933594
Batch 6/64 loss: -2.962264060974121
Batch 7/64 loss: -2.742300033569336
Batch 8/64 loss: -2.7774267196655273
Batch 9/64 loss: -2.8369903564453125
Batch 10/64 loss: -2.6572046279907227
Batch 11/64 loss: -2.953716278076172
Batch 12/64 loss: -2.8196868896484375
Batch 13/64 loss: -2.7752132415771484
Batch 14/64 loss: -2.8961362838745117
Batch 15/64 loss: -2.868283271789551
Batch 16/64 loss: -2.853799819946289
Batch 17/64 loss: -2.965365409851074
Batch 18/64 loss: -2.996748924255371
Batch 19/64 loss: -2.7738800048828125
Batch 20/64 loss: -2.8721208572387695
Batch 21/64 loss: -2.8135080337524414
Batch 22/64 loss: -2.998623847961426
Batch 23/64 loss: -2.9729862213134766
Batch 24/64 loss: -2.863618850708008
Batch 25/64 loss: -2.070063591003418
Batch 26/64 loss: -2.766969680786133
Batch 27/64 loss: -2.6969985961914062
Batch 28/64 loss: -2.7618284225463867
Batch 29/64 loss: -2.7611923217773438
Batch 30/64 loss: -2.6176223754882812
Batch 31/64 loss: -3.003891944885254
Batch 32/64 loss: -2.8051395416259766
Batch 33/64 loss: -2.8202133178710938
Batch 34/64 loss: -2.85500431060791
Batch 35/64 loss: -2.760737419128418
Batch 36/64 loss: -2.636050224304199
Batch 37/64 loss: -2.7223377227783203
Batch 38/64 loss: -2.769136428833008
Batch 39/64 loss: -2.5549325942993164
Batch 40/64 loss: -2.8953466415405273
Batch 41/64 loss: -3.031818389892578
Batch 42/64 loss: -1.7579736709594727
Batch 43/64 loss: -2.8921422958374023
Batch 44/64 loss: -2.847825050354004
Batch 45/64 loss: -2.675631523132324
Batch 46/64 loss: -2.5263662338256836
Batch 47/64 loss: -2.8464155197143555
Batch 48/64 loss: -2.7260961532592773
Batch 49/64 loss: -2.761530876159668
Batch 50/64 loss: -2.846245765686035
Batch 51/64 loss: -2.7473220825195312
Batch 52/64 loss: -2.388859748840332
Batch 53/64 loss: -2.566878318786621
Batch 54/64 loss: -2.602476119995117
Batch 55/64 loss: -2.9187726974487305
Batch 56/64 loss: -2.688579559326172
Batch 57/64 loss: -2.89151668548584
Batch 58/64 loss: -2.831845283508301
Batch 59/64 loss: -2.7701196670532227
Batch 60/64 loss: -2.627455711364746
Batch 61/64 loss: -2.744034767150879
Batch 62/64 loss: -2.9467859268188477
Batch 63/64 loss: -2.742142677307129
Batch 64/64 loss: -7.412307262420654
Epoch 458  Train loss: -2.819775459813137  Val loss: -3.0769770514104784
Epoch 459
-------------------------------
Batch 1/64 loss: -2.527674674987793
Batch 2/64 loss: -1.952362060546875
Batch 3/64 loss: -3.0904932022094727
Batch 4/64 loss: -2.622051239013672
Batch 5/64 loss: -2.6995372772216797
Batch 6/64 loss: -2.7903175354003906
Batch 7/64 loss: -2.771564483642578
Batch 8/64 loss: -2.574472427368164
Batch 9/64 loss: -2.7057723999023438
Batch 10/64 loss: -2.92812442779541
Batch 11/64 loss: -2.72995662689209
Batch 12/64 loss: -2.7250137329101562
Batch 13/64 loss: -2.9783058166503906
Batch 14/64 loss: -2.86849308013916
Batch 15/64 loss: -2.8170461654663086
Batch 16/64 loss: -3.032712936401367
Batch 17/64 loss: -2.70358943939209
Batch 18/64 loss: -2.545538902282715
Batch 19/64 loss: -2.902149200439453
Batch 20/64 loss: -2.4870100021362305
Batch 21/64 loss: -2.2858657836914062
Batch 22/64 loss: -2.6853017807006836
Batch 23/64 loss: -2.727191925048828
Batch 24/64 loss: -2.767767906188965
Batch 25/64 loss: -2.7929277420043945
Batch 26/64 loss: -2.8124351501464844
Batch 27/64 loss: -2.7845191955566406
Batch 28/64 loss: -2.8742809295654297
Batch 29/64 loss: -2.731112480163574
Batch 30/64 loss: -2.8249807357788086
Batch 31/64 loss: -2.7517433166503906
Batch 32/64 loss: -2.723872184753418
Batch 33/64 loss: -2.86777400970459
Batch 34/64 loss: -2.9116010665893555
Batch 35/64 loss: -2.921724319458008
Batch 36/64 loss: -2.923288345336914
Batch 37/64 loss: -2.724215507507324
Batch 38/64 loss: -2.8638734817504883
Batch 39/64 loss: -2.4787540435791016
Batch 40/64 loss: -3.005481719970703
Batch 41/64 loss: -2.8387908935546875
Batch 42/64 loss: -2.915703773498535
Batch 43/64 loss: -2.741750717163086
Batch 44/64 loss: -2.765106201171875
Batch 45/64 loss: -2.978703498840332
Batch 46/64 loss: -2.8276548385620117
Batch 47/64 loss: -2.996373176574707
Batch 48/64 loss: -2.9173717498779297
Batch 49/64 loss: -3.053469657897949
Batch 50/64 loss: -2.7409534454345703
Batch 51/64 loss: -2.986410140991211
Batch 52/64 loss: -1.9879417419433594
Batch 53/64 loss: -2.9329118728637695
Batch 54/64 loss: -2.7543697357177734
Batch 55/64 loss: -2.952991485595703
Batch 56/64 loss: -3.0547971725463867
Batch 57/64 loss: -2.937509536743164
Batch 58/64 loss: -2.827573776245117
Batch 59/64 loss: -2.7438783645629883
Batch 60/64 loss: -3.018970489501953
Batch 61/64 loss: -2.932187080383301
Batch 62/64 loss: -2.5722618103027344
Batch 63/64 loss: -2.9697513580322266
Batch 64/64 loss: -7.444937229156494
Epoch 459  Train loss: -2.8383063952128094  Val loss: -3.188428203674526
Epoch 460
-------------------------------
Batch 1/64 loss: -2.9153881072998047
Batch 2/64 loss: -3.018733024597168
Batch 3/64 loss: -2.9867124557495117
Batch 4/64 loss: -2.8816652297973633
Batch 5/64 loss: -2.8982105255126953
Batch 6/64 loss: -2.867563247680664
Batch 7/64 loss: -2.7462291717529297
Batch 8/64 loss: -2.865327835083008
Batch 9/64 loss: -2.7632179260253906
Batch 10/64 loss: -2.834878921508789
Batch 11/64 loss: -2.8591604232788086
Batch 12/64 loss: -2.942136764526367
Batch 13/64 loss: -2.797266960144043
Batch 14/64 loss: -2.97296142578125
Batch 15/64 loss: -3.071394920349121
Batch 16/64 loss: -2.9489622116088867
Batch 17/64 loss: -2.95438289642334
Batch 18/64 loss: -2.9479007720947266
Batch 19/64 loss: -2.889310836791992
Batch 20/64 loss: -3.0475921630859375
Batch 21/64 loss: -2.9497804641723633
Batch 22/64 loss: -3.0770092010498047
Batch 23/64 loss: -2.5946874618530273
Batch 24/64 loss: -2.2307262420654297
Batch 25/64 loss: -2.724074363708496
Batch 26/64 loss: -2.994551658630371
Batch 27/64 loss: -2.852092742919922
Batch 28/64 loss: -2.841172218322754
Batch 29/64 loss: -2.8305816650390625
Batch 30/64 loss: -2.6564178466796875
Batch 31/64 loss: -2.8864364624023438
Batch 32/64 loss: -2.6848840713500977
Batch 33/64 loss: -2.6952314376831055
Batch 34/64 loss: -2.764617919921875
Batch 35/64 loss: -2.8065109252929688
Batch 36/64 loss: -2.9439868927001953
Batch 37/64 loss: -2.9659719467163086
Batch 38/64 loss: -2.8767356872558594
Batch 39/64 loss: -2.274625778198242
Batch 40/64 loss: -2.842996597290039
Batch 41/64 loss: -2.6348962783813477
Batch 42/64 loss: -2.3139524459838867
Batch 43/64 loss: -2.8535537719726562
Batch 44/64 loss: -2.786365509033203
Batch 45/64 loss: -2.7582149505615234
Batch 46/64 loss: -2.606123924255371
Batch 47/64 loss: -2.8375587463378906
Batch 48/64 loss: -2.7095556259155273
Batch 49/64 loss: -2.9208908081054688
Batch 50/64 loss: -2.8407716751098633
Batch 51/64 loss: -2.826580047607422
Batch 52/64 loss: -2.6406850814819336
Batch 53/64 loss: -2.9757070541381836
Batch 54/64 loss: -2.870105743408203
Batch 55/64 loss: -2.7115230560302734
Batch 56/64 loss: -2.925074577331543
Batch 57/64 loss: -2.830629348754883
Batch 58/64 loss: -2.9652090072631836
Batch 59/64 loss: -2.8577709197998047
Batch 60/64 loss: -2.91400146484375
Batch 61/64 loss: -2.6381759643554688
Batch 62/64 loss: -3.0354843139648438
Batch 63/64 loss: -2.7217559814453125
Batch 64/64 loss: -6.478193283081055
Epoch 460  Train loss: -2.8664363711488012  Val loss: -3.1603459885849574
Epoch 461
-------------------------------
Batch 1/64 loss: -2.53499698638916
Batch 2/64 loss: -2.8985233306884766
Batch 3/64 loss: -2.785673141479492
Batch 4/64 loss: -2.360017776489258
Batch 5/64 loss: -2.897960662841797
Batch 6/64 loss: -2.8153133392333984
Batch 7/64 loss: -2.747979164123535
Batch 8/64 loss: -2.97750186920166
Batch 9/64 loss: -2.0833911895751953
Batch 10/64 loss: -2.9246978759765625
Batch 11/64 loss: -3.041280746459961
Batch 12/64 loss: -2.8985300064086914
Batch 13/64 loss: -2.8172035217285156
Batch 14/64 loss: -2.865757942199707
Batch 15/64 loss: -2.802906036376953
Batch 16/64 loss: -2.578261375427246
Batch 17/64 loss: -2.874476432800293
Batch 18/64 loss: -2.792205810546875
Batch 19/64 loss: -2.3717594146728516
Batch 20/64 loss: -2.6370325088500977
Batch 21/64 loss: -2.9975194931030273
Batch 22/64 loss: -3.076204299926758
Batch 23/64 loss: -2.745854377746582
Batch 24/64 loss: -2.545024871826172
Batch 25/64 loss: -2.677395820617676
Batch 26/64 loss: -2.8370542526245117
Batch 27/64 loss: -2.759521484375
Batch 28/64 loss: -2.847269058227539
Batch 29/64 loss: -2.8372583389282227
Batch 30/64 loss: -2.7526044845581055
Batch 31/64 loss: -2.9807186126708984
Batch 32/64 loss: -2.9105472564697266
Batch 33/64 loss: -3.1014699935913086
Batch 34/64 loss: -2.5958986282348633
Batch 35/64 loss: -2.9043588638305664
Batch 36/64 loss: -2.252988815307617
Batch 37/64 loss: -2.795100212097168
Batch 38/64 loss: -2.8168420791625977
Batch 39/64 loss: -2.896233558654785
Batch 40/64 loss: -2.7785892486572266
Batch 41/64 loss: -2.8603153228759766
Batch 42/64 loss: -2.513233184814453
Batch 43/64 loss: -2.947589874267578
Batch 44/64 loss: -2.9981002807617188
Batch 45/64 loss: -3.0977602005004883
Batch 46/64 loss: -3.029240608215332
Batch 47/64 loss: -2.6327266693115234
Batch 48/64 loss: -2.887082099914551
Batch 49/64 loss: -2.856226921081543
Batch 50/64 loss: -2.994771957397461
Batch 51/64 loss: -2.804800033569336
Batch 52/64 loss: -2.9987125396728516
Batch 53/64 loss: -2.8721485137939453
Batch 54/64 loss: -2.7289352416992188
Batch 55/64 loss: -2.8880910873413086
Batch 56/64 loss: -2.905165672302246
Batch 57/64 loss: -2.771225929260254
Batch 58/64 loss: -2.7478246688842773
Batch 59/64 loss: -2.718069076538086
Batch 60/64 loss: -2.6996259689331055
Batch 61/64 loss: -2.668940544128418
Batch 62/64 loss: -2.759230613708496
Batch 63/64 loss: -2.884934425354004
Batch 64/64 loss: -7.285622596740723
Epoch 461  Train loss: -2.847731627669989  Val loss: -3.113223465857227
Epoch 462
-------------------------------
Batch 1/64 loss: -3.0070858001708984
Batch 2/64 loss: -2.592129707336426
Batch 3/64 loss: -2.723421096801758
Batch 4/64 loss: -2.747629165649414
Batch 5/64 loss: -2.982545852661133
Batch 6/64 loss: -2.7735042572021484
Batch 7/64 loss: -2.747434616088867
Batch 8/64 loss: -2.801239013671875
Batch 9/64 loss: -2.502725601196289
Batch 10/64 loss: -2.449540138244629
Batch 11/64 loss: -1.8415164947509766
Batch 12/64 loss: -2.7449846267700195
Batch 13/64 loss: -2.7566356658935547
Batch 14/64 loss: -2.8947153091430664
Batch 15/64 loss: -2.6883983612060547
Batch 16/64 loss: -2.538511276245117
Batch 17/64 loss: -2.6781129837036133
Batch 18/64 loss: -2.864147186279297
Batch 19/64 loss: -2.6698989868164062
Batch 20/64 loss: -2.471066474914551
Batch 21/64 loss: -2.9344615936279297
Batch 22/64 loss: -2.630481719970703
Batch 23/64 loss: -2.8227643966674805
Batch 24/64 loss: -2.7336654663085938
Batch 25/64 loss: -2.8459386825561523
Batch 26/64 loss: -2.9520435333251953
Batch 27/64 loss: -2.767030715942383
Batch 28/64 loss: -2.7867603302001953
Batch 29/64 loss: -2.3120479583740234
Batch 30/64 loss: -2.7537717819213867
Batch 31/64 loss: -2.7142410278320312
Batch 32/64 loss: -2.476137161254883
Batch 33/64 loss: -2.3225975036621094
Batch 34/64 loss: -2.856050491333008
Batch 35/64 loss: -2.9641036987304688
Batch 36/64 loss: -2.663949966430664
Batch 37/64 loss: -2.966559410095215
Batch 38/64 loss: -2.59792423248291
Batch 39/64 loss: -2.5389013290405273
Batch 40/64 loss: -2.729672431945801
Batch 41/64 loss: -2.7445268630981445
Batch 42/64 loss: -2.7853546142578125
Batch 43/64 loss: -2.909788131713867
Batch 44/64 loss: -2.947643280029297
Batch 45/64 loss: -2.7664928436279297
Batch 46/64 loss: -2.877253532409668
Batch 47/64 loss: -2.7793703079223633
Batch 48/64 loss: -2.8582420349121094
Batch 49/64 loss: -2.967977523803711
Batch 50/64 loss: -2.8795289993286133
Batch 51/64 loss: -2.860926628112793
Batch 52/64 loss: -2.8356409072875977
Batch 53/64 loss: -2.885626792907715
Batch 54/64 loss: -3.061532974243164
Batch 55/64 loss: -2.8683853149414062
Batch 56/64 loss: -2.7379369735717773
Batch 57/64 loss: -2.7003173828125
Batch 58/64 loss: -2.9548473358154297
Batch 59/64 loss: -2.7945775985717773
Batch 60/64 loss: -2.40358829498291
Batch 61/64 loss: -3.041339874267578
Batch 62/64 loss: -2.8774051666259766
Batch 63/64 loss: -2.7872915267944336
Batch 64/64 loss: -7.564786434173584
Epoch 462  Train loss: -2.805388718025357  Val loss: -3.1853000601542365
Epoch 463
-------------------------------
Batch 1/64 loss: -2.341282844543457
Batch 2/64 loss: -2.9024124145507812
Batch 3/64 loss: -2.923982620239258
Batch 4/64 loss: -3.025228500366211
Batch 5/64 loss: -2.9093589782714844
Batch 6/64 loss: -2.9806594848632812
Batch 7/64 loss: -2.645498275756836
Batch 8/64 loss: -3.043185234069824
Batch 9/64 loss: -2.9161252975463867
Batch 10/64 loss: -3.022402763366699
Batch 11/64 loss: -2.9075450897216797
Batch 12/64 loss: -3.041086196899414
Batch 13/64 loss: -2.997248649597168
Batch 14/64 loss: -2.7580223083496094
Batch 15/64 loss: -2.832095146179199
Batch 16/64 loss: -2.8576889038085938
Batch 17/64 loss: -2.927743911743164
Batch 18/64 loss: -2.6068029403686523
Batch 19/64 loss: -2.84829044342041
Batch 20/64 loss: -2.7269983291625977
Batch 21/64 loss: -2.4836673736572266
Batch 22/64 loss: -2.8211488723754883
Batch 23/64 loss: -2.755608558654785
Batch 24/64 loss: -2.9200220108032227
Batch 25/64 loss: -2.271434783935547
Batch 26/64 loss: -2.9438695907592773
Batch 27/64 loss: -2.8980722427368164
Batch 28/64 loss: -2.7829513549804688
Batch 29/64 loss: -2.698288917541504
Batch 30/64 loss: -3.025923728942871
Batch 31/64 loss: -2.970892906188965
Batch 32/64 loss: -2.445096015930176
Batch 33/64 loss: -2.9366073608398438
Batch 34/64 loss: -2.7800445556640625
Batch 35/64 loss: -2.6952714920043945
Batch 36/64 loss: -2.8994626998901367
Batch 37/64 loss: -2.8146286010742188
Batch 38/64 loss: -2.9700279235839844
Batch 39/64 loss: -2.7166385650634766
Batch 40/64 loss: -2.726694107055664
Batch 41/64 loss: -3.0471038818359375
Batch 42/64 loss: -2.775496482849121
Batch 43/64 loss: -2.923651695251465
Batch 44/64 loss: -2.9950714111328125
Batch 45/64 loss: -2.737351417541504
Batch 46/64 loss: -2.79038143157959
Batch 47/64 loss: -2.948719024658203
Batch 48/64 loss: -3.1202611923217773
Batch 49/64 loss: -3.0026140213012695
Batch 50/64 loss: -2.9573135375976562
Batch 51/64 loss: -3.053837776184082
Batch 52/64 loss: -2.2292861938476562
Batch 53/64 loss: -2.9297494888305664
Batch 54/64 loss: -2.9359779357910156
Batch 55/64 loss: -3.049532890319824
Batch 56/64 loss: -2.8365659713745117
Batch 57/64 loss: -2.9877490997314453
Batch 58/64 loss: -2.9798011779785156
Batch 59/64 loss: -2.885356903076172
Batch 60/64 loss: -2.848714828491211
Batch 61/64 loss: -2.716244697570801
Batch 62/64 loss: -3.097517967224121
Batch 63/64 loss: -3.0637683868408203
Batch 64/64 loss: -7.309338569641113
Epoch 463  Train loss: -2.9045346091775333  Val loss: -3.2807935603295815
Saving best model, epoch: 463
Epoch 464
-------------------------------
Batch 1/64 loss: -3.1485815048217773
Batch 2/64 loss: -2.9277114868164062
Batch 3/64 loss: -2.902602195739746
Batch 4/64 loss: -3.0133533477783203
Batch 5/64 loss: -3.017033576965332
Batch 6/64 loss: -2.913825035095215
Batch 7/64 loss: -2.660451889038086
Batch 8/64 loss: -2.946732521057129
Batch 9/64 loss: -2.605706214904785
Batch 10/64 loss: -3.0075111389160156
Batch 11/64 loss: -2.6399316787719727
Batch 12/64 loss: -2.975968360900879
Batch 13/64 loss: -2.996068000793457
Batch 14/64 loss: -3.123906135559082
Batch 15/64 loss: -3.0195817947387695
Batch 16/64 loss: -2.9581832885742188
Batch 17/64 loss: -3.04559326171875
Batch 18/64 loss: -2.8554210662841797
Batch 19/64 loss: -2.6908130645751953
Batch 20/64 loss: -2.4277896881103516
Batch 21/64 loss: -2.5976743698120117
Batch 22/64 loss: -2.938014030456543
Batch 23/64 loss: -2.9115371704101562
Batch 24/64 loss: -2.8180179595947266
Batch 25/64 loss: -2.9629077911376953
Batch 26/64 loss: -3.028651237487793
Batch 27/64 loss: -2.693593978881836
Batch 28/64 loss: -3.0305395126342773
Batch 29/64 loss: -2.8666858673095703
Batch 30/64 loss: -3.050816535949707
Batch 31/64 loss: -2.439732551574707
Batch 32/64 loss: -3.002635955810547
Batch 33/64 loss: -2.8496570587158203
Batch 34/64 loss: -3.1144628524780273
Batch 35/64 loss: -2.746474266052246
Batch 36/64 loss: -2.9650869369506836
Batch 37/64 loss: -2.891681671142578
Batch 38/64 loss: -2.9579858779907227
Batch 39/64 loss: -3.176913261413574
Batch 40/64 loss: -2.851078987121582
Batch 41/64 loss: -2.9995203018188477
Batch 42/64 loss: -2.8121089935302734
Batch 43/64 loss: -2.985743522644043
Batch 44/64 loss: -2.9204444885253906
Batch 45/64 loss: -2.6660070419311523
Batch 46/64 loss: -2.9816904067993164
Batch 47/64 loss: -2.8064441680908203
Batch 48/64 loss: -2.931438446044922
Batch 49/64 loss: -2.2557926177978516
Batch 50/64 loss: -3.0231361389160156
Batch 51/64 loss: -2.9940271377563477
Batch 52/64 loss: -2.8245229721069336
Batch 53/64 loss: -2.8865251541137695
Batch 54/64 loss: -2.977768898010254
Batch 55/64 loss: -2.735210418701172
Batch 56/64 loss: -2.6817150115966797
Batch 57/64 loss: -2.775339126586914
Batch 58/64 loss: -2.9479732513427734
Batch 59/64 loss: -2.66658878326416
Batch 60/64 loss: -2.844672203063965
Batch 61/64 loss: -2.8659658432006836
Batch 62/64 loss: -2.6339902877807617
Batch 63/64 loss: -2.8884401321411133
Batch 64/64 loss: -7.53139066696167
Epoch 464  Train loss: -2.9258748465893314  Val loss: -3.2074757998751613
Epoch 465
-------------------------------
Batch 1/64 loss: -2.724339485168457
Batch 2/64 loss: -3.1139345169067383
Batch 3/64 loss: -2.8822851181030273
Batch 4/64 loss: -2.4259939193725586
Batch 5/64 loss: -2.9902944564819336
Batch 6/64 loss: -2.641132354736328
Batch 7/64 loss: -3.1441402435302734
Batch 8/64 loss: -2.9381771087646484
Batch 9/64 loss: -2.6687631607055664
Batch 10/64 loss: -2.892277717590332
Batch 11/64 loss: -2.890439987182617
Batch 12/64 loss: -2.9164838790893555
Batch 13/64 loss: -2.814657211303711
Batch 14/64 loss: -3.0635604858398438
Batch 15/64 loss: -2.6953487396240234
Batch 16/64 loss: -2.982203483581543
Batch 17/64 loss: -2.303034782409668
Batch 18/64 loss: -3.0929126739501953
Batch 19/64 loss: -2.9904518127441406
Batch 20/64 loss: -2.698291778564453
Batch 21/64 loss: -2.9124698638916016
Batch 22/64 loss: -3.013962745666504
Batch 23/64 loss: -2.536651611328125
Batch 24/64 loss: -3.032306671142578
Batch 25/64 loss: -2.9072608947753906
Batch 26/64 loss: -3.0206832885742188
Batch 27/64 loss: -3.0149145126342773
Batch 28/64 loss: -2.9461774826049805
Batch 29/64 loss: -2.7240467071533203
Batch 30/64 loss: -2.484280586242676
Batch 31/64 loss: -3.0146875381469727
Batch 32/64 loss: -3.1465330123901367
Batch 33/64 loss: -2.9321908950805664
Batch 34/64 loss: -3.1030921936035156
Batch 35/64 loss: -2.022930145263672
Batch 36/64 loss: -2.935370445251465
Batch 37/64 loss: -2.9068479537963867
Batch 38/64 loss: -2.991183280944824
Batch 39/64 loss: -2.8838911056518555
Batch 40/64 loss: -2.752462387084961
Batch 41/64 loss: -2.8992137908935547
Batch 42/64 loss: -2.940690040588379
Batch 43/64 loss: -2.8203468322753906
Batch 44/64 loss: -2.8245973587036133
Batch 45/64 loss: -2.7127504348754883
Batch 46/64 loss: -2.7384681701660156
Batch 47/64 loss: -2.7528467178344727
Batch 48/64 loss: -2.9081268310546875
Batch 49/64 loss: -3.006312370300293
Batch 50/64 loss: -2.8506059646606445
Batch 51/64 loss: -2.790743827819824
Batch 52/64 loss: -2.866109848022461
Batch 53/64 loss: -2.669133186340332
Batch 54/64 loss: -2.602938652038574
Batch 55/64 loss: -2.8269901275634766
Batch 56/64 loss: -3.0367631912231445
Batch 57/64 loss: -2.808230400085449
Batch 58/64 loss: -2.7618179321289062
Batch 59/64 loss: -2.2844324111938477
Batch 60/64 loss: -2.7764768600463867
Batch 61/64 loss: -2.8048601150512695
Batch 62/64 loss: -2.9250431060791016
Batch 63/64 loss: -2.9466772079467773
Batch 64/64 loss: -7.409655570983887
Epoch 465  Train loss: -2.8903856202667835  Val loss: -3.13194685211706
Epoch 466
-------------------------------
Batch 1/64 loss: -2.8536462783813477
Batch 2/64 loss: -2.8715744018554688
Batch 3/64 loss: -2.7351551055908203
Batch 4/64 loss: -3.079988479614258
Batch 5/64 loss: -2.4830636978149414
Batch 6/64 loss: -2.9443588256835938
Batch 7/64 loss: -2.9419422149658203
Batch 8/64 loss: -2.9111757278442383
Batch 9/64 loss: -2.956955909729004
Batch 10/64 loss: -2.9184694290161133
Batch 11/64 loss: -2.768573760986328
Batch 12/64 loss: -2.7481088638305664
Batch 13/64 loss: -2.894139289855957
Batch 14/64 loss: -2.6400556564331055
Batch 15/64 loss: -2.859325408935547
Batch 16/64 loss: -2.911526679992676
Batch 17/64 loss: -2.8355941772460938
Batch 18/64 loss: -2.8284082412719727
Batch 19/64 loss: -2.6872148513793945
Batch 20/64 loss: -2.7473058700561523
Batch 21/64 loss: -2.5455617904663086
Batch 22/64 loss: -2.7969017028808594
Batch 23/64 loss: -2.8643999099731445
Batch 24/64 loss: -2.893568992614746
Batch 25/64 loss: -1.8329486846923828
Batch 26/64 loss: -2.6973876953125
Batch 27/64 loss: -2.981125831604004
Batch 28/64 loss: -3.026905059814453
Batch 29/64 loss: -2.6085948944091797
Batch 30/64 loss: -2.396601676940918
Batch 31/64 loss: -2.715601921081543
Batch 32/64 loss: -2.6360979080200195
Batch 33/64 loss: -2.883734703063965
Batch 34/64 loss: -2.7527923583984375
Batch 35/64 loss: -2.822321891784668
Batch 36/64 loss: -2.9087753295898438
Batch 37/64 loss: -2.841183662414551
Batch 38/64 loss: -3.002777099609375
Batch 39/64 loss: -2.6732311248779297
Batch 40/64 loss: -3.008294105529785
Batch 41/64 loss: -2.8573265075683594
Batch 42/64 loss: -2.9765329360961914
Batch 43/64 loss: -2.828028678894043
Batch 44/64 loss: -2.5492935180664062
Batch 45/64 loss: -2.8713016510009766
Batch 46/64 loss: -2.700439453125
Batch 47/64 loss: -2.864299774169922
Batch 48/64 loss: -2.9031496047973633
Batch 49/64 loss: -3.0303688049316406
Batch 50/64 loss: -2.9131946563720703
Batch 51/64 loss: -2.892209053039551
Batch 52/64 loss: -2.9667911529541016
Batch 53/64 loss: -2.907567024230957
Batch 54/64 loss: -2.492359161376953
Batch 55/64 loss: -2.750143051147461
Batch 56/64 loss: -2.7150726318359375
Batch 57/64 loss: -2.804825782775879
Batch 58/64 loss: -2.785538673400879
Batch 59/64 loss: -2.8496150970458984
Batch 60/64 loss: -2.9688539505004883
Batch 61/64 loss: -2.855666160583496
Batch 62/64 loss: -2.9391021728515625
Batch 63/64 loss: -2.9993696212768555
Batch 64/64 loss: -7.401233196258545
Epoch 466  Train loss: -2.862390011432124  Val loss: -3.2365157923747585
Epoch 467
-------------------------------
Batch 1/64 loss: -2.8112974166870117
Batch 2/64 loss: -3.0380725860595703
Batch 3/64 loss: -2.5488080978393555
Batch 4/64 loss: -2.823441505432129
Batch 5/64 loss: -2.9361133575439453
Batch 6/64 loss: -2.8322343826293945
Batch 7/64 loss: -2.796921730041504
Batch 8/64 loss: -2.569425582885742
Batch 9/64 loss: -2.9689931869506836
Batch 10/64 loss: -2.5927486419677734
Batch 11/64 loss: -2.9335250854492188
Batch 12/64 loss: -2.7255325317382812
Batch 13/64 loss: -2.826629638671875
Batch 14/64 loss: -2.80621337890625
Batch 15/64 loss: -2.597731590270996
Batch 16/64 loss: -2.8375110626220703
Batch 17/64 loss: -2.7424449920654297
Batch 18/64 loss: -2.994462013244629
Batch 19/64 loss: -3.048978805541992
Batch 20/64 loss: -2.7933034896850586
Batch 21/64 loss: -2.7761316299438477
Batch 22/64 loss: -2.8725452423095703
Batch 23/64 loss: -2.76894474029541
Batch 24/64 loss: -2.7272043228149414
Batch 25/64 loss: -2.9004735946655273
Batch 26/64 loss: -2.867258071899414
Batch 27/64 loss: -2.459941864013672
Batch 28/64 loss: -2.3018035888671875
Batch 29/64 loss: -2.713137626647949
Batch 30/64 loss: -2.988339424133301
Batch 31/64 loss: -2.986945152282715
Batch 32/64 loss: -2.759608268737793
Batch 33/64 loss: -2.8605165481567383
Batch 34/64 loss: -2.824382781982422
Batch 35/64 loss: -2.962836265563965
Batch 36/64 loss: -2.2311019897460938
Batch 37/64 loss: -2.9110260009765625
Batch 38/64 loss: -2.822437286376953
Batch 39/64 loss: -2.879749298095703
Batch 40/64 loss: -2.862421989440918
Batch 41/64 loss: -2.915524482727051
Batch 42/64 loss: -2.8229827880859375
Batch 43/64 loss: -3.067624092102051
Batch 44/64 loss: -2.868229866027832
Batch 45/64 loss: -2.7933969497680664
Batch 46/64 loss: -3.010807991027832
Batch 47/64 loss: -2.8702383041381836
Batch 48/64 loss: -2.806443214416504
Batch 49/64 loss: -2.666828155517578
Batch 50/64 loss: -2.668027877807617
Batch 51/64 loss: -2.8627023696899414
Batch 52/64 loss: -2.9377784729003906
Batch 53/64 loss: -3.1107711791992188
Batch 54/64 loss: -3.048534393310547
Batch 55/64 loss: -2.70327091217041
Batch 56/64 loss: -3.037705421447754
Batch 57/64 loss: -2.8371706008911133
Batch 58/64 loss: -2.906693458557129
Batch 59/64 loss: -2.9939098358154297
Batch 60/64 loss: -2.6526079177856445
Batch 61/64 loss: -2.8335695266723633
Batch 62/64 loss: -2.889951705932617
Batch 63/64 loss: -2.795450210571289
Batch 64/64 loss: -7.466498851776123
Epoch 467  Train loss: -2.8768829588796576  Val loss: -3.1969415199306
Epoch 468
-------------------------------
Batch 1/64 loss: -2.85117244720459
Batch 2/64 loss: -2.969085693359375
Batch 3/64 loss: -2.956353187561035
Batch 4/64 loss: -3.039813995361328
Batch 5/64 loss: -2.8115901947021484
Batch 6/64 loss: -1.8528594970703125
Batch 7/64 loss: -2.807065963745117
Batch 8/64 loss: -2.9661989212036133
Batch 9/64 loss: -3.0060195922851562
Batch 10/64 loss: -2.8991756439208984
Batch 11/64 loss: -2.327479362487793
Batch 12/64 loss: -2.9843626022338867
Batch 13/64 loss: -2.928373336791992
Batch 14/64 loss: -3.0283355712890625
Batch 15/64 loss: -2.553990364074707
Batch 16/64 loss: -2.6859521865844727
Batch 17/64 loss: -2.781813621520996
Batch 18/64 loss: -2.7218503952026367
Batch 19/64 loss: -2.9267892837524414
Batch 20/64 loss: -2.9664487838745117
Batch 21/64 loss: -2.961639404296875
Batch 22/64 loss: -2.8331832885742188
Batch 23/64 loss: -2.84368896484375
Batch 24/64 loss: -2.431394577026367
Batch 25/64 loss: -2.840937614440918
Batch 26/64 loss: -2.7467575073242188
Batch 27/64 loss: -2.870913505554199
Batch 28/64 loss: -2.999392509460449
Batch 29/64 loss: -2.841973304748535
Batch 30/64 loss: -3.020435333251953
Batch 31/64 loss: -2.699496269226074
Batch 32/64 loss: -2.830860137939453
Batch 33/64 loss: -2.871297836303711
Batch 34/64 loss: -2.9962081909179688
Batch 35/64 loss: -2.84140682220459
Batch 36/64 loss: -2.674551010131836
Batch 37/64 loss: -2.804539680480957
Batch 38/64 loss: -2.867201805114746
Batch 39/64 loss: -2.7662734985351562
Batch 40/64 loss: -3.0169801712036133
Batch 41/64 loss: -2.804558753967285
Batch 42/64 loss: -2.640909194946289
Batch 43/64 loss: -2.9923973083496094
Batch 44/64 loss: -2.8661251068115234
Batch 45/64 loss: -2.844196319580078
Batch 46/64 loss: -3.0907135009765625
Batch 47/64 loss: -3.1245384216308594
Batch 48/64 loss: -2.2971420288085938
Batch 49/64 loss: -2.827859878540039
Batch 50/64 loss: -2.653101921081543
Batch 51/64 loss: -2.791783332824707
Batch 52/64 loss: -2.7786455154418945
Batch 53/64 loss: -2.8979034423828125
Batch 54/64 loss: -3.051849365234375
Batch 55/64 loss: -2.95125675201416
Batch 56/64 loss: -2.983400344848633
Batch 57/64 loss: -3.0313196182250977
Batch 58/64 loss: -2.808551788330078
Batch 59/64 loss: -2.991039276123047
Batch 60/64 loss: -2.948406219482422
Batch 61/64 loss: -2.8881006240844727
Batch 62/64 loss: -3.043506622314453
Batch 63/64 loss: -2.9365386962890625
Batch 64/64 loss: -7.409785270690918
Epoch 468  Train loss: -2.896079138213513  Val loss: -3.1338577663775573
Epoch 469
-------------------------------
Batch 1/64 loss: -2.8822755813598633
Batch 2/64 loss: -2.7190074920654297
Batch 3/64 loss: -2.9241809844970703
Batch 4/64 loss: -2.5816659927368164
Batch 5/64 loss: -3.023439407348633
Batch 6/64 loss: -2.8563385009765625
Batch 7/64 loss: -2.924884796142578
Batch 8/64 loss: -2.8729076385498047
Batch 9/64 loss: -3.014192581176758
Batch 10/64 loss: -2.8878707885742188
Batch 11/64 loss: -3.1628761291503906
Batch 12/64 loss: -2.9221982955932617
Batch 13/64 loss: -3.0654287338256836
Batch 14/64 loss: -3.0282421112060547
Batch 15/64 loss: -3.0014848709106445
Batch 16/64 loss: -2.88124942779541
Batch 17/64 loss: -2.7994842529296875
Batch 18/64 loss: -2.6782379150390625
Batch 19/64 loss: -2.7365455627441406
Batch 20/64 loss: -2.6840429306030273
Batch 21/64 loss: -2.9575376510620117
Batch 22/64 loss: -2.9715576171875
Batch 23/64 loss: -2.797701835632324
Batch 24/64 loss: -2.7958412170410156
Batch 25/64 loss: -2.922666549682617
Batch 26/64 loss: -2.6935367584228516
Batch 27/64 loss: -2.9457874298095703
Batch 28/64 loss: -2.985025405883789
Batch 29/64 loss: -2.8931007385253906
Batch 30/64 loss: -2.9172582626342773
Batch 31/64 loss: -2.744084358215332
Batch 32/64 loss: -2.892868995666504
Batch 33/64 loss: -2.9080400466918945
Batch 34/64 loss: -2.915353775024414
Batch 35/64 loss: -3.0886878967285156
Batch 36/64 loss: -2.7992544174194336
Batch 37/64 loss: -2.4757843017578125
Batch 38/64 loss: -2.9267988204956055
Batch 39/64 loss: -2.7052345275878906
Batch 40/64 loss: -2.9128074645996094
Batch 41/64 loss: -2.912747383117676
Batch 42/64 loss: -2.957216262817383
Batch 43/64 loss: -2.8443517684936523
Batch 44/64 loss: -2.7614784240722656
Batch 45/64 loss: -2.9368371963500977
Batch 46/64 loss: -2.853374481201172
Batch 47/64 loss: -1.9351625442504883
Batch 48/64 loss: -2.803264617919922
Batch 49/64 loss: -2.7955713272094727
Batch 50/64 loss: -2.5927858352661133
Batch 51/64 loss: -2.8424243927001953
Batch 52/64 loss: -2.915276527404785
Batch 53/64 loss: -2.9938125610351562
Batch 54/64 loss: -2.9053430557250977
Batch 55/64 loss: -2.581277847290039
Batch 56/64 loss: -2.630742073059082
Batch 57/64 loss: -2.82643985748291
Batch 58/64 loss: -2.6848373413085938
Batch 59/64 loss: -2.719681739807129
Batch 60/64 loss: -2.6338281631469727
Batch 61/64 loss: -2.0946006774902344
Batch 62/64 loss: -2.703714370727539
Batch 63/64 loss: -3.0354394912719727
Batch 64/64 loss: -7.426670074462891
Epoch 469  Train loss: -2.877265765620213  Val loss: -3.1443018175891995
Epoch 470
-------------------------------
Batch 1/64 loss: -2.9357471466064453
Batch 2/64 loss: -2.6513328552246094
Batch 3/64 loss: -2.840754508972168
Batch 4/64 loss: -2.662154197692871
Batch 5/64 loss: -2.999720573425293
Batch 6/64 loss: -2.600534439086914
Batch 7/64 loss: -3.074209213256836
Batch 8/64 loss: -3.033614158630371
Batch 9/64 loss: -2.5472545623779297
Batch 10/64 loss: -2.8997135162353516
Batch 11/64 loss: -2.8049440383911133
Batch 12/64 loss: -2.975015640258789
Batch 13/64 loss: -2.5020999908447266
Batch 14/64 loss: -2.3568058013916016
Batch 15/64 loss: -2.9024620056152344
Batch 16/64 loss: -3.0322704315185547
Batch 17/64 loss: -3.085023880004883
Batch 18/64 loss: -2.6034765243530273
Batch 19/64 loss: -2.929263114929199
Batch 20/64 loss: -2.9355249404907227
Batch 21/64 loss: -2.9939279556274414
Batch 22/64 loss: -2.7727785110473633
Batch 23/64 loss: -2.9963417053222656
Batch 24/64 loss: -3.091838836669922
Batch 25/64 loss: -2.9799184799194336
Batch 26/64 loss: -2.995713233947754
Batch 27/64 loss: -2.9601125717163086
Batch 28/64 loss: -2.756458282470703
Batch 29/64 loss: -2.943857192993164
Batch 30/64 loss: -2.819774627685547
Batch 31/64 loss: -2.8044490814208984
Batch 32/64 loss: -2.249805450439453
Batch 33/64 loss: -2.5716733932495117
Batch 34/64 loss: -3.084975242614746
Batch 35/64 loss: -3.016447067260742
Batch 36/64 loss: -2.90248966217041
Batch 37/64 loss: -2.8762598037719727
Batch 38/64 loss: -2.8713865280151367
Batch 39/64 loss: -2.9269142150878906
Batch 40/64 loss: -2.898937225341797
Batch 41/64 loss: -2.49379825592041
Batch 42/64 loss: -2.668140411376953
Batch 43/64 loss: -2.301690101623535
Batch 44/64 loss: -3.022028923034668
Batch 45/64 loss: -2.7428436279296875
Batch 46/64 loss: -2.527935028076172
Batch 47/64 loss: -3.047572135925293
Batch 48/64 loss: -2.98618221282959
Batch 49/64 loss: -3.0901784896850586
Batch 50/64 loss: -3.114992141723633
Batch 51/64 loss: -2.9106359481811523
Batch 52/64 loss: -2.829103469848633
Batch 53/64 loss: -2.9559831619262695
Batch 54/64 loss: -2.7666397094726562
Batch 55/64 loss: -3.0154294967651367
Batch 56/64 loss: -2.6013174057006836
Batch 57/64 loss: -2.7179622650146484
Batch 58/64 loss: -2.9345054626464844
Batch 59/64 loss: -2.922161102294922
Batch 60/64 loss: -2.9890451431274414
Batch 61/64 loss: -2.9111385345458984
Batch 62/64 loss: -2.6783857345581055
Batch 63/64 loss: -2.7651796340942383
Batch 64/64 loss: -7.423839092254639
Epoch 470  Train loss: -2.8932816991619035  Val loss: -3.229603259424164
Epoch 471
-------------------------------
Batch 1/64 loss: -2.825333595275879
Batch 2/64 loss: -3.048750877380371
Batch 3/64 loss: -2.8412952423095703
Batch 4/64 loss: -2.874924659729004
Batch 5/64 loss: -2.6686935424804688
Batch 6/64 loss: -2.9475574493408203
Batch 7/64 loss: -2.374342918395996
Batch 8/64 loss: -2.8451337814331055
Batch 9/64 loss: -2.9547576904296875
Batch 10/64 loss: -2.954686164855957
Batch 11/64 loss: -2.8844680786132812
Batch 12/64 loss: -2.8804006576538086
Batch 13/64 loss: -2.9069557189941406
Batch 14/64 loss: -2.7549171447753906
Batch 15/64 loss: -2.8194589614868164
Batch 16/64 loss: -2.7853164672851562
Batch 17/64 loss: -2.653837203979492
Batch 18/64 loss: -2.6803979873657227
Batch 19/64 loss: -2.7954492568969727
Batch 20/64 loss: -3.102969169616699
Batch 21/64 loss: -2.8260154724121094
Batch 22/64 loss: -2.6411848068237305
Batch 23/64 loss: -2.3114376068115234
Batch 24/64 loss: -2.8499813079833984
Batch 25/64 loss: -2.9821300506591797
Batch 26/64 loss: -2.832125663757324
Batch 27/64 loss: -3.0362491607666016
Batch 28/64 loss: -2.9197025299072266
Batch 29/64 loss: -2.213235855102539
Batch 30/64 loss: -2.7304115295410156
Batch 31/64 loss: -2.7881736755371094
Batch 32/64 loss: -2.9027795791625977
Batch 33/64 loss: -2.899486541748047
Batch 34/64 loss: -2.9352588653564453
Batch 35/64 loss: -2.662050247192383
Batch 36/64 loss: -2.7336130142211914
Batch 37/64 loss: -3.029068946838379
Batch 38/64 loss: -2.8808040618896484
Batch 39/64 loss: -2.6602067947387695
Batch 40/64 loss: -2.943728446960449
Batch 41/64 loss: -2.836231231689453
Batch 42/64 loss: -2.869696617126465
Batch 43/64 loss: -2.945521354675293
Batch 44/64 loss: -2.863706588745117
Batch 45/64 loss: -2.8725156784057617
Batch 46/64 loss: -2.7829885482788086
Batch 47/64 loss: -2.253249168395996
Batch 48/64 loss: -2.592924118041992
Batch 49/64 loss: -2.873507499694824
Batch 50/64 loss: -2.998387336730957
Batch 51/64 loss: -2.618520736694336
Batch 52/64 loss: -3.062480926513672
Batch 53/64 loss: -2.689180374145508
Batch 54/64 loss: -2.8993492126464844
Batch 55/64 loss: -2.661649703979492
Batch 56/64 loss: -2.6817569732666016
Batch 57/64 loss: -2.875324249267578
Batch 58/64 loss: -2.7830734252929688
Batch 59/64 loss: -2.969053268432617
Batch 60/64 loss: -2.9090585708618164
Batch 61/64 loss: -2.9914464950561523
Batch 62/64 loss: -2.385213851928711
Batch 63/64 loss: -3.0673789978027344
Batch 64/64 loss: -7.40504264831543
Epoch 471  Train loss: -2.8613849041508694  Val loss: -3.210317015238234
Epoch 472
-------------------------------
Batch 1/64 loss: -3.1047658920288086
Batch 2/64 loss: -2.681028366088867
Batch 3/64 loss: -2.73883056640625
Batch 4/64 loss: -2.929037094116211
Batch 5/64 loss: -2.465503692626953
Batch 6/64 loss: -2.8972911834716797
Batch 7/64 loss: -2.775546073913574
Batch 8/64 loss: -2.5547943115234375
Batch 9/64 loss: -2.809223175048828
Batch 10/64 loss: -2.928203582763672
Batch 11/64 loss: -2.7768850326538086
Batch 12/64 loss: -2.9028406143188477
Batch 13/64 loss: -2.6545639038085938
Batch 14/64 loss: -2.899076461791992
Batch 15/64 loss: -3.0198049545288086
Batch 16/64 loss: -2.9248008728027344
Batch 17/64 loss: -2.8469505310058594
Batch 18/64 loss: -2.9769296646118164
Batch 19/64 loss: -2.7024621963500977
Batch 20/64 loss: -2.796663284301758
Batch 21/64 loss: -3.06588077545166
Batch 22/64 loss: -2.6028642654418945
Batch 23/64 loss: -2.798084259033203
Batch 24/64 loss: -2.7341480255126953
Batch 25/64 loss: -2.2512807846069336
Batch 26/64 loss: -3.0126075744628906
Batch 27/64 loss: -2.7354278564453125
Batch 28/64 loss: -2.9283485412597656
Batch 29/64 loss: -2.913140296936035
Batch 30/64 loss: -3.123340606689453
Batch 31/64 loss: -2.9702939987182617
Batch 32/64 loss: -3.0292654037475586
Batch 33/64 loss: -2.911975860595703
Batch 34/64 loss: -2.9264869689941406
Batch 35/64 loss: -2.8202333450317383
Batch 36/64 loss: -3.014505386352539
Batch 37/64 loss: -2.9533891677856445
Batch 38/64 loss: -2.93892765045166
Batch 39/64 loss: -2.950174331665039
Batch 40/64 loss: -2.633063316345215
Batch 41/64 loss: -2.2228708267211914
Batch 42/64 loss: -3.124842643737793
Batch 43/64 loss: -3.025533676147461
Batch 44/64 loss: -2.7745361328125
Batch 45/64 loss: -2.8579282760620117
Batch 46/64 loss: -2.7691221237182617
Batch 47/64 loss: -2.8872318267822266
Batch 48/64 loss: -2.6295166015625
Batch 49/64 loss: -3.042984962463379
Batch 50/64 loss: -2.435209274291992
Batch 51/64 loss: -3.0055761337280273
Batch 52/64 loss: -2.633146286010742
Batch 53/64 loss: -3.0442190170288086
Batch 54/64 loss: -2.566049575805664
Batch 55/64 loss: -3.0053558349609375
Batch 56/64 loss: -2.8579025268554688
Batch 57/64 loss: -2.8760299682617188
Batch 58/64 loss: -2.9329633712768555
Batch 59/64 loss: -2.714879035949707
Batch 60/64 loss: -2.9828224182128906
Batch 61/64 loss: -2.925421714782715
Batch 62/64 loss: -3.0831875801086426
Batch 63/64 loss: -2.8062028884887695
Batch 64/64 loss: -7.3005523681640625
Epoch 472  Train loss: -2.892197440652286  Val loss: -3.2337451423566366
Epoch 473
-------------------------------
Batch 1/64 loss: -2.841520309448242
Batch 2/64 loss: -2.828023910522461
Batch 3/64 loss: -2.753933906555176
Batch 4/64 loss: -3.077511787414551
Batch 5/64 loss: -2.8381967544555664
Batch 6/64 loss: -3.0265674591064453
Batch 7/64 loss: -2.7269115447998047
Batch 8/64 loss: -2.9269275665283203
Batch 9/64 loss: -2.837958335876465
Batch 10/64 loss: -3.0619688034057617
Batch 11/64 loss: -2.7181339263916016
Batch 12/64 loss: -3.035250663757324
Batch 13/64 loss: -3.022862434387207
Batch 14/64 loss: -2.958958625793457
Batch 15/64 loss: -2.7247705459594727
Batch 16/64 loss: -3.00289249420166
Batch 17/64 loss: -2.9588747024536133
Batch 18/64 loss: -2.119121551513672
Batch 19/64 loss: -2.7017030715942383
Batch 20/64 loss: -3.01589298248291
Batch 21/64 loss: -2.3796520233154297
Batch 22/64 loss: -2.5391359329223633
Batch 23/64 loss: -2.827474594116211
Batch 24/64 loss: -2.9785547256469727
Batch 25/64 loss: -2.7323532104492188
Batch 26/64 loss: -3.0759191513061523
Batch 27/64 loss: -2.7996597290039062
Batch 28/64 loss: -2.507208824157715
Batch 29/64 loss: -2.485414505004883
Batch 30/64 loss: -2.878175735473633
Batch 31/64 loss: -2.739431381225586
Batch 32/64 loss: -2.9350385665893555
Batch 33/64 loss: -3.0294723510742188
Batch 34/64 loss: -2.819413185119629
Batch 35/64 loss: -2.9268035888671875
Batch 36/64 loss: -3.087301254272461
Batch 37/64 loss: -3.0785980224609375
Batch 38/64 loss: -2.851593017578125
Batch 39/64 loss: -2.9418106079101562
Batch 40/64 loss: -3.025811195373535
Batch 41/64 loss: -2.764638900756836
Batch 42/64 loss: -2.9186153411865234
Batch 43/64 loss: -2.9470443725585938
Batch 44/64 loss: -2.8868560791015625
Batch 45/64 loss: -2.9598207473754883
Batch 46/64 loss: -2.696995735168457
Batch 47/64 loss: -2.8549747467041016
Batch 48/64 loss: -2.362468719482422
Batch 49/64 loss: -2.966855049133301
Batch 50/64 loss: -2.3849105834960938
Batch 51/64 loss: -3.002927780151367
Batch 52/64 loss: -2.833977699279785
Batch 53/64 loss: -2.7872982025146484
Batch 54/64 loss: -2.77304744720459
Batch 55/64 loss: -2.39237117767334
Batch 56/64 loss: -2.95004940032959
Batch 57/64 loss: -2.66304874420166
Batch 58/64 loss: -2.61647891998291
Batch 59/64 loss: -2.687255859375
Batch 60/64 loss: -2.851069450378418
Batch 61/64 loss: -2.922783851623535
Batch 62/64 loss: -2.830141067504883
Batch 63/64 loss: -2.354762077331543
Batch 64/64 loss: -7.405135154724121
Epoch 473  Train loss: -2.8671222948560526  Val loss: -3.1503408110838165
Epoch 474
-------------------------------
Batch 1/64 loss: -3.039793014526367
Batch 2/64 loss: -2.382868766784668
Batch 3/64 loss: -2.960587501525879
Batch 4/64 loss: -2.220867156982422
Batch 5/64 loss: -2.665621757507324
Batch 6/64 loss: -2.644338607788086
Batch 7/64 loss: -2.877321243286133
Batch 8/64 loss: -2.716423988342285
Batch 9/64 loss: -2.8400020599365234
Batch 10/64 loss: -2.898573875427246
Batch 11/64 loss: -2.955441474914551
Batch 12/64 loss: -2.959463119506836
Batch 13/64 loss: -2.92008113861084
Batch 14/64 loss: -2.9741458892822266
Batch 15/64 loss: -2.7584829330444336
Batch 16/64 loss: -2.8447341918945312
Batch 17/64 loss: -2.754384994506836
Batch 18/64 loss: -2.9107542037963867
Batch 19/64 loss: -2.8960494995117188
Batch 20/64 loss: -2.8330488204956055
Batch 21/64 loss: -2.6567087173461914
Batch 22/64 loss: -2.8655738830566406
Batch 23/64 loss: -2.7478256225585938
Batch 24/64 loss: -2.248307228088379
Batch 25/64 loss: -2.8821678161621094
Batch 26/64 loss: -1.9302730560302734
Batch 27/64 loss: -2.5628604888916016
Batch 28/64 loss: -2.7143239974975586
Batch 29/64 loss: -2.8650474548339844
Batch 30/64 loss: -2.8502750396728516
Batch 31/64 loss: -2.509653091430664
Batch 32/64 loss: -2.526426315307617
Batch 33/64 loss: -2.620406150817871
Batch 34/64 loss: -2.5429372787475586
Batch 35/64 loss: -2.9629430770874023
Batch 36/64 loss: -2.8653745651245117
Batch 37/64 loss: -2.8707542419433594
Batch 38/64 loss: -2.7659950256347656
Batch 39/64 loss: -2.947564125061035
Batch 40/64 loss: -2.4266738891601562
Batch 41/64 loss: -2.869424819946289
Batch 42/64 loss: -2.7751893997192383
Batch 43/64 loss: -2.8988828659057617
Batch 44/64 loss: -2.9635868072509766
Batch 45/64 loss: -2.8744468688964844
Batch 46/64 loss: -2.9775447845458984
Batch 47/64 loss: -2.954573631286621
Batch 48/64 loss: -2.8796043395996094
Batch 49/64 loss: -2.742420196533203
Batch 50/64 loss: -2.9335031509399414
Batch 51/64 loss: -2.669672966003418
Batch 52/64 loss: -2.9167098999023438
Batch 53/64 loss: -2.8849830627441406
Batch 54/64 loss: -2.880070686340332
Batch 55/64 loss: -2.824617385864258
Batch 56/64 loss: -2.854557991027832
Batch 57/64 loss: -2.9387617111206055
Batch 58/64 loss: -2.8147430419921875
Batch 59/64 loss: -2.878262519836426
Batch 60/64 loss: -2.8302364349365234
Batch 61/64 loss: -2.716975212097168
Batch 62/64 loss: -2.568878173828125
Batch 63/64 loss: -2.830142021179199
Batch 64/64 loss: -7.4996337890625
Epoch 474  Train loss: -2.8316484488692937  Val loss: -3.140385106666801
Epoch 475
-------------------------------
Batch 1/64 loss: -2.55706787109375
Batch 2/64 loss: -3.0883588790893555
Batch 3/64 loss: -2.6299781799316406
Batch 4/64 loss: -2.757936477661133
Batch 5/64 loss: -2.837557792663574
Batch 6/64 loss: -2.8711042404174805
Batch 7/64 loss: -2.899458885192871
Batch 8/64 loss: -2.627312660217285
Batch 9/64 loss: -2.9807891845703125
Batch 10/64 loss: -2.7145462036132812
Batch 11/64 loss: -2.738532066345215
Batch 12/64 loss: -2.884920120239258
Batch 13/64 loss: -2.7193984985351562
Batch 14/64 loss: -2.3082685470581055
Batch 15/64 loss: -2.9316158294677734
Batch 16/64 loss: -2.8193578720092773
Batch 17/64 loss: -2.920644760131836
Batch 18/64 loss: -2.9329071044921875
Batch 19/64 loss: -2.9344139099121094
Batch 20/64 loss: -2.829082489013672
Batch 21/64 loss: -2.7741241455078125
Batch 22/64 loss: -2.911890983581543
Batch 23/64 loss: -2.8817596435546875
Batch 24/64 loss: -2.6326379776000977
Batch 25/64 loss: -2.327420234680176
Batch 26/64 loss: -3.043269157409668
Batch 27/64 loss: -2.334628105163574
Batch 28/64 loss: -2.612947463989258
Batch 29/64 loss: -2.590489387512207
Batch 30/64 loss: -2.362013816833496
Batch 31/64 loss: -2.8771800994873047
Batch 32/64 loss: -3.056746482849121
Batch 33/64 loss: -2.892735481262207
Batch 34/64 loss: -2.916619300842285
Batch 35/64 loss: -2.979654312133789
Batch 36/64 loss: -2.5404443740844727
Batch 37/64 loss: -2.986074447631836
Batch 38/64 loss: -2.3041982650756836
Batch 39/64 loss: -2.6850528717041016
Batch 40/64 loss: -3.0122995376586914
Batch 41/64 loss: -2.9511289596557617
Batch 42/64 loss: -2.8755340576171875
Batch 43/64 loss: -2.8673715591430664
Batch 44/64 loss: -2.7061824798583984
Batch 45/64 loss: -2.9091787338256836
Batch 46/64 loss: -2.9362220764160156
Batch 47/64 loss: -2.916691780090332
Batch 48/64 loss: -2.842252731323242
Batch 49/64 loss: -2.635098457336426
Batch 50/64 loss: -2.699019432067871
Batch 51/64 loss: -2.823910713195801
Batch 52/64 loss: -2.9807262420654297
Batch 53/64 loss: -2.934293746948242
Batch 54/64 loss: -2.885247230529785
Batch 55/64 loss: -2.8223743438720703
Batch 56/64 loss: -2.862736701965332
Batch 57/64 loss: -2.3855199813842773
Batch 58/64 loss: -2.808460235595703
Batch 59/64 loss: -3.01226806640625
Batch 60/64 loss: -2.6798362731933594
Batch 61/64 loss: -2.955923080444336
Batch 62/64 loss: -2.739988327026367
Batch 63/64 loss: -2.8762998580932617
Batch 64/64 loss: -7.398519992828369
Epoch 475  Train loss: -2.8448720427120433  Val loss: -3.207146529889189
Epoch 476
-------------------------------
Batch 1/64 loss: -2.8719472885131836
Batch 2/64 loss: -2.7210025787353516
Batch 3/64 loss: -2.72280216217041
Batch 4/64 loss: -2.909383773803711
Batch 5/64 loss: -2.8632287979125977
Batch 6/64 loss: -2.9779272079467773
Batch 7/64 loss: -2.6885595321655273
Batch 8/64 loss: -2.92867374420166
Batch 9/64 loss: -2.9673233032226562
Batch 10/64 loss: -2.883342742919922
Batch 11/64 loss: -2.564377784729004
Batch 12/64 loss: -2.8093957901000977
Batch 13/64 loss: -2.579418182373047
Batch 14/64 loss: -2.774991035461426
Batch 15/64 loss: -3.0370559692382812
Batch 16/64 loss: -2.953958511352539
Batch 17/64 loss: -3.0515260696411133
Batch 18/64 loss: -2.885308265686035
Batch 19/64 loss: -2.8797950744628906
Batch 20/64 loss: -3.0183372497558594
Batch 21/64 loss: -2.7704391479492188
Batch 22/64 loss: -3.0140085220336914
Batch 23/64 loss: -2.8555660247802734
Batch 24/64 loss: -2.8876428604125977
Batch 25/64 loss: -3.0028152465820312
Batch 26/64 loss: -2.8411264419555664
Batch 27/64 loss: -2.909578323364258
Batch 28/64 loss: -2.601323127746582
Batch 29/64 loss: -3.0366764068603516
Batch 30/64 loss: -2.910726547241211
Batch 31/64 loss: -2.985873222351074
Batch 32/64 loss: -3.1090211868286133
Batch 33/64 loss: -2.929962158203125
Batch 34/64 loss: -2.8795509338378906
Batch 35/64 loss: -2.681118965148926
Batch 36/64 loss: -2.490706443786621
Batch 37/64 loss: -2.952260971069336
Batch 38/64 loss: -2.785816192626953
Batch 39/64 loss: -2.825460433959961
Batch 40/64 loss: -3.1011533737182617
Batch 41/64 loss: -2.829562187194824
Batch 42/64 loss: -2.9759950637817383
Batch 43/64 loss: -2.7953872680664062
Batch 44/64 loss: -2.974271774291992
Batch 45/64 loss: -2.9247512817382812
Batch 46/64 loss: -2.609132766723633
Batch 47/64 loss: -2.923788070678711
Batch 48/64 loss: -2.973811149597168
Batch 49/64 loss: -2.351046562194824
Batch 50/64 loss: -2.8610363006591797
Batch 51/64 loss: -2.9249420166015625
Batch 52/64 loss: -2.622791290283203
Batch 53/64 loss: -3.008530616760254
Batch 54/64 loss: -2.4328765869140625
Batch 55/64 loss: -2.986233711242676
Batch 56/64 loss: -2.874582290649414
Batch 57/64 loss: -2.9143667221069336
Batch 58/64 loss: -2.759884834289551
Batch 59/64 loss: -2.9267892837524414
Batch 60/64 loss: -2.2934207916259766
Batch 61/64 loss: -2.888235092163086
Batch 62/64 loss: -2.907621383666992
Batch 63/64 loss: -2.627762794494629
Batch 64/64 loss: -7.114553928375244
Epoch 476  Train loss: -2.8922653628330606  Val loss: -3.225121435840515
Epoch 477
-------------------------------
Batch 1/64 loss: -3.000272750854492
Batch 2/64 loss: -2.722026824951172
Batch 3/64 loss: -2.9866867065429688
Batch 4/64 loss: -2.778794288635254
Batch 5/64 loss: -2.955714225769043
Batch 6/64 loss: -2.8170642852783203
Batch 7/64 loss: -2.9040040969848633
Batch 8/64 loss: -2.9662094116210938
Batch 9/64 loss: -2.8518104553222656
Batch 10/64 loss: -2.9774913787841797
Batch 11/64 loss: -2.762017250061035
Batch 12/64 loss: -2.6283998489379883
Batch 13/64 loss: -2.764820098876953
Batch 14/64 loss: -2.737767219543457
Batch 15/64 loss: -2.8058624267578125
Batch 16/64 loss: -2.4950809478759766
Batch 17/64 loss: -2.7554988861083984
Batch 18/64 loss: -2.0053844451904297
Batch 19/64 loss: -2.96651554107666
Batch 20/64 loss: -2.898578643798828
Batch 21/64 loss: -2.7265682220458984
Batch 22/64 loss: -2.9908552169799805
Batch 23/64 loss: -2.85404109954834
Batch 24/64 loss: -2.8733530044555664
Batch 25/64 loss: -2.7896251678466797
Batch 26/64 loss: -2.9884395599365234
Batch 27/64 loss: -2.596414566040039
Batch 28/64 loss: -2.6499195098876953
Batch 29/64 loss: -2.659832000732422
Batch 30/64 loss: -2.604254722595215
Batch 31/64 loss: -2.761630058288574
Batch 32/64 loss: -2.8838138580322266
Batch 33/64 loss: -2.95526123046875
Batch 34/64 loss: -2.731440544128418
Batch 35/64 loss: -2.981443405151367
Batch 36/64 loss: -2.8461341857910156
Batch 37/64 loss: -2.8222885131835938
Batch 38/64 loss: -2.89450740814209
Batch 39/64 loss: -2.954195976257324
Batch 40/64 loss: -2.4324750900268555
Batch 41/64 loss: -2.943788528442383
Batch 42/64 loss: -2.4928789138793945
Batch 43/64 loss: -2.811160087585449
Batch 44/64 loss: -2.5737428665161133
Batch 45/64 loss: -2.754033088684082
Batch 46/64 loss: -2.6805124282836914
Batch 47/64 loss: -3.095608711242676
Batch 48/64 loss: -2.9269943237304688
Batch 49/64 loss: -3.0471086502075195
Batch 50/64 loss: -2.8079452514648438
Batch 51/64 loss: -2.8842668533325195
Batch 52/64 loss: -2.508462905883789
Batch 53/64 loss: -2.6963329315185547
Batch 54/64 loss: -2.9873342514038086
Batch 55/64 loss: -3.03798770904541
Batch 56/64 loss: -2.926363945007324
Batch 57/64 loss: -2.727828025817871
Batch 58/64 loss: -2.860868453979492
Batch 59/64 loss: -3.0394086837768555
Batch 60/64 loss: -3.0602502822875977
Batch 61/64 loss: -3.086393356323242
Batch 62/64 loss: -2.8304433822631836
Batch 63/64 loss: -2.9439010620117188
Batch 64/64 loss: -7.355280876159668
Epoch 477  Train loss: -2.8708481321147845  Val loss: -3.2736129629652932
Epoch 478
-------------------------------
Batch 1/64 loss: -2.9754581451416016
Batch 2/64 loss: -3.0201940536499023
Batch 3/64 loss: -2.86862850189209
Batch 4/64 loss: -2.0043201446533203
Batch 5/64 loss: -2.664656639099121
Batch 6/64 loss: -3.0897350311279297
Batch 7/64 loss: -2.860126495361328
Batch 8/64 loss: -2.995861053466797
Batch 9/64 loss: -2.785116195678711
Batch 10/64 loss: -2.944695472717285
Batch 11/64 loss: -2.760164260864258
Batch 12/64 loss: -2.9235572814941406
Batch 13/64 loss: -2.97808837890625
Batch 14/64 loss: -2.892253875732422
Batch 15/64 loss: -3.0041418075561523
Batch 16/64 loss: -2.8712053298950195
Batch 17/64 loss: -2.2246885299682617
Batch 18/64 loss: -2.897237777709961
Batch 19/64 loss: -2.908824920654297
Batch 20/64 loss: -2.5733108520507812
Batch 21/64 loss: -2.8936891555786133
Batch 22/64 loss: -2.8119544982910156
Batch 23/64 loss: -2.8481388092041016
Batch 24/64 loss: -3.0558042526245117
Batch 25/64 loss: -3.0190858840942383
Batch 26/64 loss: -2.700161933898926
Batch 27/64 loss: -2.863269805908203
Batch 28/64 loss: -3.048079490661621
Batch 29/64 loss: -3.025754928588867
Batch 30/64 loss: -2.6991777420043945
Batch 31/64 loss: -2.5086193084716797
Batch 32/64 loss: -2.939422607421875
Batch 33/64 loss: -2.9770288467407227
Batch 34/64 loss: -2.8165855407714844
Batch 35/64 loss: -2.9457530975341797
Batch 36/64 loss: -3.041982650756836
Batch 37/64 loss: -2.901723861694336
Batch 38/64 loss: -2.769301414489746
Batch 39/64 loss: -2.800395965576172
Batch 40/64 loss: -2.880239486694336
Batch 41/64 loss: -2.8910398483276367
Batch 42/64 loss: -3.010957717895508
Batch 43/64 loss: -2.6171035766601562
Batch 44/64 loss: -2.9508752822875977
Batch 45/64 loss: -2.8698015213012695
Batch 46/64 loss: -3.0205698013305664
Batch 47/64 loss: -3.0615930557250977
Batch 48/64 loss: -3.1876821517944336
Batch 49/64 loss: -2.853257179260254
Batch 50/64 loss: -2.714750289916992
Batch 51/64 loss: -2.919846534729004
Batch 52/64 loss: -2.878087043762207
Batch 53/64 loss: -2.990692138671875
Batch 54/64 loss: -2.875537872314453
Batch 55/64 loss: -2.900278091430664
Batch 56/64 loss: -2.858003616333008
Batch 57/64 loss: -2.3792734146118164
Batch 58/64 loss: -2.7985429763793945
Batch 59/64 loss: -2.9885101318359375
Batch 60/64 loss: -3.0134096145629883
Batch 61/64 loss: -2.74163818359375
Batch 62/64 loss: -2.9255294799804688
Batch 63/64 loss: -3.0024614334106445
Batch 64/64 loss: -7.484323978424072
Epoch 478  Train loss: -2.915311654408773  Val loss: -3.205980766270169
Epoch 479
-------------------------------
Batch 1/64 loss: -2.715510368347168
Batch 2/64 loss: -2.7522096633911133
Batch 3/64 loss: -2.9623517990112305
Batch 4/64 loss: -2.6576433181762695
Batch 5/64 loss: -2.927861213684082
Batch 6/64 loss: -2.963499069213867
Batch 7/64 loss: -2.8960628509521484
Batch 8/64 loss: -3.0357980728149414
Batch 9/64 loss: -3.011155128479004
Batch 10/64 loss: -3.0206823348999023
Batch 11/64 loss: -2.969532012939453
Batch 12/64 loss: -2.234869956970215
Batch 13/64 loss: -3.095433235168457
Batch 14/64 loss: -2.9678268432617188
Batch 15/64 loss: -2.7507553100585938
Batch 16/64 loss: -2.6746482849121094
Batch 17/64 loss: -2.946399688720703
Batch 18/64 loss: -2.2671585083007812
Batch 19/64 loss: -3.0190982818603516
Batch 20/64 loss: -2.8034181594848633
Batch 21/64 loss: -2.592494010925293
Batch 22/64 loss: -2.77571964263916
Batch 23/64 loss: -2.1364879608154297
Batch 24/64 loss: -2.919560432434082
Batch 25/64 loss: -2.8413467407226562
Batch 26/64 loss: -2.9215240478515625
Batch 27/64 loss: -2.976848602294922
Batch 28/64 loss: -2.5501785278320312
Batch 29/64 loss: -1.6663169860839844
Batch 30/64 loss: -2.457858085632324
Batch 31/64 loss: -2.5767688751220703
Batch 32/64 loss: -3.043196678161621
Batch 33/64 loss: -2.968369483947754
Batch 34/64 loss: -2.836777687072754
Batch 35/64 loss: -3.030686378479004
Batch 36/64 loss: -2.823613166809082
Batch 37/64 loss: -2.836897850036621
Batch 38/64 loss: -2.225484848022461
Batch 39/64 loss: -2.510099411010742
Batch 40/64 loss: -2.771052360534668
Batch 41/64 loss: -2.870738983154297
Batch 42/64 loss: -3.0440244674682617
Batch 43/64 loss: -2.5476131439208984
Batch 44/64 loss: -2.8429336547851562
Batch 45/64 loss: -2.884181022644043
Batch 46/64 loss: -3.0961074829101562
Batch 47/64 loss: -2.8427257537841797
Batch 48/64 loss: -2.8392629623413086
Batch 49/64 loss: -2.0779504776000977
Batch 50/64 loss: -2.927565574645996
Batch 51/64 loss: -3.0380678176879883
Batch 52/64 loss: -2.833928108215332
Batch 53/64 loss: -2.881453514099121
Batch 54/64 loss: -2.7491989135742188
Batch 55/64 loss: -2.90126895904541
Batch 56/64 loss: -2.855144500732422
Batch 57/64 loss: -2.9927978515625
Batch 58/64 loss: -2.7434749603271484
Batch 59/64 loss: -2.7246789932250977
Batch 60/64 loss: -2.9108963012695312
Batch 61/64 loss: -2.702082633972168
Batch 62/64 loss: -2.899044990539551
Batch 63/64 loss: -2.685482978820801
Batch 64/64 loss: -7.516003608703613
Epoch 479  Train loss: -2.8338952569400564  Val loss: -3.114087003203192
Epoch 480
-------------------------------
Batch 1/64 loss: -2.9109420776367188
Batch 2/64 loss: -2.8906049728393555
Batch 3/64 loss: -2.8862571716308594
Batch 4/64 loss: -2.764449119567871
Batch 5/64 loss: -2.4880199432373047
Batch 6/64 loss: -2.8979406356811523
Batch 7/64 loss: -2.8124923706054688
Batch 8/64 loss: -2.7247724533081055
Batch 9/64 loss: -2.5628585815429688
Batch 10/64 loss: -2.2710323333740234
Batch 11/64 loss: -2.3067541122436523
Batch 12/64 loss: -2.722576141357422
Batch 13/64 loss: -2.930985450744629
Batch 14/64 loss: -3.0703182220458984
Batch 15/64 loss: -2.8837175369262695
Batch 16/64 loss: -2.875311851501465
Batch 17/64 loss: -3.0116004943847656
Batch 18/64 loss: -3.0449953079223633
Batch 19/64 loss: -2.819042205810547
Batch 20/64 loss: -2.6447505950927734
Batch 21/64 loss: -2.8372011184692383
Batch 22/64 loss: -2.8475522994995117
Batch 23/64 loss: -2.1228342056274414
Batch 24/64 loss: -2.980563163757324
Batch 25/64 loss: -2.6450061798095703
Batch 26/64 loss: -2.8878536224365234
Batch 27/64 loss: -2.870473861694336
Batch 28/64 loss: -3.0306997299194336
Batch 29/64 loss: -2.8800268173217773
Batch 30/64 loss: -3.0008974075317383
Batch 31/64 loss: -2.9828929901123047
Batch 32/64 loss: -2.817702293395996
Batch 33/64 loss: -1.7843513488769531
Batch 34/64 loss: -3.0245094299316406
Batch 35/64 loss: -2.8491010665893555
Batch 36/64 loss: -3.0246992111206055
Batch 37/64 loss: -2.9133501052856445
Batch 38/64 loss: -2.99478816986084
Batch 39/64 loss: -2.365931510925293
Batch 40/64 loss: -2.788206100463867
Batch 41/64 loss: -2.8373613357543945
Batch 42/64 loss: -2.8068161010742188
Batch 43/64 loss: -2.8558835983276367
Batch 44/64 loss: -2.8622522354125977
Batch 45/64 loss: -2.62667179107666
Batch 46/64 loss: -2.6898975372314453
Batch 47/64 loss: -2.7186965942382812
Batch 48/64 loss: -2.919210433959961
Batch 49/64 loss: -2.963716506958008
Batch 50/64 loss: -2.9177026748657227
Batch 51/64 loss: -2.7560815811157227
Batch 52/64 loss: -3.0962963104248047
Batch 53/64 loss: -2.7429161071777344
Batch 54/64 loss: -2.8791894912719727
Batch 55/64 loss: -2.714959144592285
Batch 56/64 loss: -2.9732656478881836
Batch 57/64 loss: -2.9195613861083984
Batch 58/64 loss: -2.767667770385742
Batch 59/64 loss: -3.050844192504883
Batch 60/64 loss: -2.9698219299316406
Batch 61/64 loss: -3.009463310241699
Batch 62/64 loss: -3.0513038635253906
Batch 63/64 loss: -2.831205368041992
Batch 64/64 loss: -7.1801981925964355
Epoch 480  Train loss: -2.862964639476701  Val loss: -3.2110955412035547
Epoch 481
-------------------------------
Batch 1/64 loss: -3.069488525390625
Batch 2/64 loss: -2.671034812927246
Batch 3/64 loss: -3.028017044067383
Batch 4/64 loss: -2.701690673828125
Batch 5/64 loss: -2.904452323913574
Batch 6/64 loss: -2.9238967895507812
Batch 7/64 loss: -2.865070343017578
Batch 8/64 loss: -2.91690731048584
Batch 9/64 loss: -2.9894723892211914
Batch 10/64 loss: -2.8368940353393555
Batch 11/64 loss: -2.862839698791504
Batch 12/64 loss: -2.9394493103027344
Batch 13/64 loss: -2.7153825759887695
Batch 14/64 loss: -2.9960460662841797
Batch 15/64 loss: -2.616046905517578
Batch 16/64 loss: -2.174199104309082
Batch 17/64 loss: -2.2858715057373047
Batch 18/64 loss: -2.9464902877807617
Batch 19/64 loss: -2.854595184326172
Batch 20/64 loss: -2.933919906616211
Batch 21/64 loss: -2.8180150985717773
Batch 22/64 loss: -2.717021942138672
Batch 23/64 loss: -2.839177131652832
Batch 24/64 loss: -2.888888359069824
Batch 25/64 loss: -2.6727724075317383
Batch 26/64 loss: -2.944760322570801
Batch 27/64 loss: -3.0234384536743164
Batch 28/64 loss: -2.8602476119995117
Batch 29/64 loss: -2.922901153564453
Batch 30/64 loss: -2.9376697540283203
Batch 31/64 loss: -2.8639698028564453
Batch 32/64 loss: -2.9421653747558594
Batch 33/64 loss: -3.005645751953125
Batch 34/64 loss: -2.8386545181274414
Batch 35/64 loss: -2.965818405151367
Batch 36/64 loss: -3.0733556747436523
Batch 37/64 loss: -2.7670717239379883
Batch 38/64 loss: -2.388787269592285
Batch 39/64 loss: -2.925508499145508
Batch 40/64 loss: -2.7647953033447266
Batch 41/64 loss: -2.8393115997314453
Batch 42/64 loss: -2.276670455932617
Batch 43/64 loss: -2.895604133605957
Batch 44/64 loss: -2.5671730041503906
Batch 45/64 loss: -2.935732841491699
Batch 46/64 loss: -2.892970085144043
Batch 47/64 loss: -3.0574769973754883
Batch 48/64 loss: -2.8433122634887695
Batch 49/64 loss: -2.9098405838012695
Batch 50/64 loss: -2.8385534286499023
Batch 51/64 loss: -2.7520036697387695
Batch 52/64 loss: -2.9215927124023438
Batch 53/64 loss: -2.8685665130615234
Batch 54/64 loss: -2.948831558227539
Batch 55/64 loss: -2.907670021057129
Batch 56/64 loss: -2.759596824645996
Batch 57/64 loss: -2.7954368591308594
Batch 58/64 loss: -3.05966854095459
Batch 59/64 loss: -3.1771774291992188
Batch 60/64 loss: -3.0340232849121094
Batch 61/64 loss: -3.1447505950927734
Batch 62/64 loss: -2.7862186431884766
Batch 63/64 loss: -2.7975683212280273
Batch 64/64 loss: -7.397620677947998
Epoch 481  Train loss: -2.901182670219272  Val loss: -3.257164722455736
Epoch 482
-------------------------------
Batch 1/64 loss: -2.96820068359375
Batch 2/64 loss: -2.9041595458984375
Batch 3/64 loss: -2.842801094055176
Batch 4/64 loss: -2.858077049255371
Batch 5/64 loss: -2.7387542724609375
Batch 6/64 loss: -2.6586828231811523
Batch 7/64 loss: -3.005474090576172
Batch 8/64 loss: -2.9497222900390625
Batch 9/64 loss: -2.894929885864258
Batch 10/64 loss: -3.0359458923339844
Batch 11/64 loss: -2.6893539428710938
Batch 12/64 loss: -2.3489694595336914
Batch 13/64 loss: -2.838163375854492
Batch 14/64 loss: -2.749897003173828
Batch 15/64 loss: -2.996356964111328
Batch 16/64 loss: -2.902585983276367
Batch 17/64 loss: -2.8613977432250977
Batch 18/64 loss: -2.2069997787475586
Batch 19/64 loss: -2.995152473449707
Batch 20/64 loss: -2.976856231689453
Batch 21/64 loss: -2.8500680923461914
Batch 22/64 loss: -2.881241798400879
Batch 23/64 loss: -3.103264808654785
Batch 24/64 loss: -2.5985450744628906
Batch 25/64 loss: -2.9028501510620117
Batch 26/64 loss: -2.728708267211914
Batch 27/64 loss: -2.9875030517578125
Batch 28/64 loss: -2.7170534133911133
Batch 29/64 loss: -2.8416261672973633
Batch 30/64 loss: -2.639108657836914
Batch 31/64 loss: -2.9198217391967773
Batch 32/64 loss: -2.9289541244506836
Batch 33/64 loss: -2.0022811889648438
Batch 34/64 loss: -2.9320249557495117
Batch 35/64 loss: -2.8571739196777344
Batch 36/64 loss: -2.7924880981445312
Batch 37/64 loss: -3.038555145263672
Batch 38/64 loss: -2.891940116882324
Batch 39/64 loss: -2.9692859649658203
Batch 40/64 loss: -2.582425117492676
Batch 41/64 loss: -2.9210119247436523
Batch 42/64 loss: -2.9554529190063477
Batch 43/64 loss: -2.7599077224731445
Batch 44/64 loss: -2.9853992462158203
Batch 45/64 loss: -2.827694892883301
Batch 46/64 loss: -2.9419078826904297
Batch 47/64 loss: -3.02457332611084
Batch 48/64 loss: -3.062654495239258
Batch 49/64 loss: -2.674534797668457
Batch 50/64 loss: -2.8876218795776367
Batch 51/64 loss: -2.867478370666504
Batch 52/64 loss: -2.783736228942871
Batch 53/64 loss: -2.968024253845215
Batch 54/64 loss: -2.492403984069824
Batch 55/64 loss: -2.950800895690918
Batch 56/64 loss: -2.959723472595215
Batch 57/64 loss: -3.098393440246582
Batch 58/64 loss: -2.8028268814086914
Batch 59/64 loss: -2.6577653884887695
Batch 60/64 loss: -2.924196243286133
Batch 61/64 loss: -2.8688316345214844
Batch 62/64 loss: -2.86184024810791
Batch 63/64 loss: -2.901186943054199
Batch 64/64 loss: -7.380176067352295
Epoch 482  Train loss: -2.8909882283678243  Val loss: -3.2560662731681904
Epoch 483
-------------------------------
Batch 1/64 loss: -2.8408613204956055
Batch 2/64 loss: -2.935683250427246
Batch 3/64 loss: -3.037343978881836
Batch 4/64 loss: -2.7031784057617188
Batch 5/64 loss: -2.8412857055664062
Batch 6/64 loss: -2.7787113189697266
Batch 7/64 loss: -2.823235511779785
Batch 8/64 loss: -3.001997947692871
Batch 9/64 loss: -2.863412857055664
Batch 10/64 loss: -3.0158748626708984
Batch 11/64 loss: -2.7667856216430664
Batch 12/64 loss: -2.820068359375
Batch 13/64 loss: -3.0174407958984375
Batch 14/64 loss: -2.8592920303344727
Batch 15/64 loss: -2.729447364807129
Batch 16/64 loss: -2.73323917388916
Batch 17/64 loss: -2.2385473251342773
Batch 18/64 loss: -2.6834983825683594
Batch 19/64 loss: -2.7665014266967773
Batch 20/64 loss: -2.6374874114990234
Batch 21/64 loss: -2.707376480102539
Batch 22/64 loss: -2.990847587585449
Batch 23/64 loss: -2.8838415145874023
Batch 24/64 loss: -2.9903268814086914
Batch 25/64 loss: -2.800112724304199
Batch 26/64 loss: -2.8530807495117188
Batch 27/64 loss: -2.6826372146606445
Batch 28/64 loss: -2.8074159622192383
Batch 29/64 loss: -2.7036895751953125
Batch 30/64 loss: -2.3593969345092773
Batch 31/64 loss: -2.8425636291503906
Batch 32/64 loss: -2.9199886322021484
Batch 33/64 loss: -2.9572601318359375
Batch 34/64 loss: -2.6203393936157227
Batch 35/64 loss: -2.8172988891601562
Batch 36/64 loss: -2.8114185333251953
Batch 37/64 loss: -2.981419563293457
Batch 38/64 loss: -2.828829765319824
Batch 39/64 loss: -2.9817752838134766
Batch 40/64 loss: -2.897001266479492
Batch 41/64 loss: -2.730276107788086
Batch 42/64 loss: -3.0449838638305664
Batch 43/64 loss: -2.525965690612793
Batch 44/64 loss: -2.9312734603881836
Batch 45/64 loss: -2.873162269592285
Batch 46/64 loss: -2.950350761413574
Batch 47/64 loss: -2.7516603469848633
Batch 48/64 loss: -2.9238452911376953
Batch 49/64 loss: -2.856410026550293
Batch 50/64 loss: -2.8799057006835938
Batch 51/64 loss: -2.9491872787475586
Batch 52/64 loss: -2.978022575378418
Batch 53/64 loss: -2.805065155029297
Batch 54/64 loss: -2.8407201766967773
Batch 55/64 loss: -3.092165946960449
Batch 56/64 loss: -2.824108123779297
Batch 57/64 loss: -3.0174388885498047
Batch 58/64 loss: -2.983860969543457
Batch 59/64 loss: -3.036052703857422
Batch 60/64 loss: -2.911588668823242
Batch 61/64 loss: -3.0050735473632812
Batch 62/64 loss: -2.834172248840332
Batch 63/64 loss: -2.743170738220215
Batch 64/64 loss: -7.1516828536987305
Epoch 483  Train loss: -2.8922782187368354  Val loss: -3.202526380925654
Epoch 484
-------------------------------
Batch 1/64 loss: -2.7902307510375977
Batch 2/64 loss: -3.0020666122436523
Batch 3/64 loss: -3.0044307708740234
Batch 4/64 loss: -3.0204029083251953
Batch 5/64 loss: -2.731609344482422
Batch 6/64 loss: -2.7576866149902344
Batch 7/64 loss: -2.9912729263305664
Batch 8/64 loss: -2.922694206237793
Batch 9/64 loss: -2.6150684356689453
Batch 10/64 loss: -2.9250411987304688
Batch 11/64 loss: -2.966341972351074
Batch 12/64 loss: -2.710789680480957
Batch 13/64 loss: -2.9376888275146484
Batch 14/64 loss: -3.04061222076416
Batch 15/64 loss: -2.900362014770508
Batch 16/64 loss: -2.704578399658203
Batch 17/64 loss: -3.0294361114501953
Batch 18/64 loss: -2.97177791595459
Batch 19/64 loss: -2.899489402770996
Batch 20/64 loss: -3.124594211578369
Batch 21/64 loss: -3.0679359436035156
Batch 22/64 loss: -2.9694528579711914
Batch 23/64 loss: -2.998291015625
Batch 24/64 loss: -2.942927360534668
Batch 25/64 loss: -2.9197282791137695
Batch 26/64 loss: -3.0755558013916016
Batch 27/64 loss: -2.807058334350586
Batch 28/64 loss: -2.895657539367676
Batch 29/64 loss: -2.9095325469970703
Batch 30/64 loss: -2.9089813232421875
Batch 31/64 loss: -2.983748435974121
Batch 32/64 loss: -2.6467885971069336
Batch 33/64 loss: -2.8756637573242188
Batch 34/64 loss: -3.1166086196899414
Batch 35/64 loss: -2.9616451263427734
Batch 36/64 loss: -2.873790740966797
Batch 37/64 loss: -2.682305335998535
Batch 38/64 loss: -2.8720712661743164
Batch 39/64 loss: -2.8787841796875
Batch 40/64 loss: -2.2976064682006836
Batch 41/64 loss: -2.902216911315918
Batch 42/64 loss: -2.8848915100097656
Batch 43/64 loss: -3.0113954544067383
Batch 44/64 loss: -2.847498893737793
Batch 45/64 loss: -2.8810195922851562
Batch 46/64 loss: -2.8543577194213867
Batch 47/64 loss: -2.974344253540039
Batch 48/64 loss: -2.8835086822509766
Batch 49/64 loss: -2.8993844985961914
Batch 50/64 loss: -3.0048656463623047
Batch 51/64 loss: -2.9327516555786133
Batch 52/64 loss: -2.6949377059936523
Batch 53/64 loss: -2.8974857330322266
Batch 54/64 loss: -2.933774948120117
Batch 55/64 loss: -2.9069652557373047
Batch 56/64 loss: -2.9810256958007812
Batch 57/64 loss: -2.7145919799804688
Batch 58/64 loss: -2.787081718444824
Batch 59/64 loss: -2.3454723358154297
Batch 60/64 loss: -2.6472015380859375
Batch 61/64 loss: -3.008970260620117
Batch 62/64 loss: -2.217418670654297
Batch 63/64 loss: -2.8023672103881836
Batch 64/64 loss: -7.573818206787109
Epoch 484  Train loss: -2.924301169900333  Val loss: -3.3032265364918922
Saving best model, epoch: 484
Epoch 485
-------------------------------
Batch 1/64 loss: -2.697011947631836
Batch 2/64 loss: -2.965761184692383
Batch 3/64 loss: -2.9890947341918945
Batch 4/64 loss: -2.959355354309082
Batch 5/64 loss: -3.070558547973633
Batch 6/64 loss: -2.832747459411621
Batch 7/64 loss: -2.680233955383301
Batch 8/64 loss: -2.9241275787353516
Batch 9/64 loss: -3.0223169326782227
Batch 10/64 loss: -3.136164665222168
Batch 11/64 loss: -2.7273082733154297
Batch 12/64 loss: -2.7738046646118164
Batch 13/64 loss: -2.2180395126342773
Batch 14/64 loss: -2.8468618392944336
Batch 15/64 loss: -2.8181915283203125
Batch 16/64 loss: -2.811448097229004
Batch 17/64 loss: -3.055975914001465
Batch 18/64 loss: -3.0540285110473633
Batch 19/64 loss: -2.865298271179199
Batch 20/64 loss: -3.012101173400879
Batch 21/64 loss: -2.87595272064209
Batch 22/64 loss: -3.069094657897949
Batch 23/64 loss: -2.883206367492676
Batch 24/64 loss: -2.5333728790283203
Batch 25/64 loss: -2.85903263092041
Batch 26/64 loss: -2.952439308166504
Batch 27/64 loss: -2.9769420623779297
Batch 28/64 loss: -2.8579893112182617
Batch 29/64 loss: -3.0166015625
Batch 30/64 loss: -2.9903488159179688
Batch 31/64 loss: -2.4312658309936523
Batch 32/64 loss: -2.74771785736084
Batch 33/64 loss: -3.0223474502563477
Batch 34/64 loss: -3.0566492080688477
Batch 35/64 loss: -3.085721969604492
Batch 36/64 loss: -2.717217445373535
Batch 37/64 loss: -2.1785097122192383
Batch 38/64 loss: -3.027956008911133
Batch 39/64 loss: -2.8675098419189453
Batch 40/64 loss: -2.919388771057129
Batch 41/64 loss: -2.812528610229492
Batch 42/64 loss: -2.659562110900879
Batch 43/64 loss: -2.6579980850219727
Batch 44/64 loss: -2.7453088760375977
Batch 45/64 loss: -2.66483211517334
Batch 46/64 loss: -2.64505672454834
Batch 47/64 loss: -2.402292251586914
Batch 48/64 loss: -3.024869918823242
Batch 49/64 loss: -2.9821062088012695
Batch 50/64 loss: -2.971048355102539
Batch 51/64 loss: -2.7827253341674805
Batch 52/64 loss: -3.032663345336914
Batch 53/64 loss: -3.0538949966430664
Batch 54/64 loss: -2.452810287475586
Batch 55/64 loss: -2.9668312072753906
Batch 56/64 loss: -2.750369071960449
Batch 57/64 loss: -2.910183906555176
Batch 58/64 loss: -2.951852798461914
Batch 59/64 loss: -2.767153739929199
Batch 60/64 loss: -2.989288330078125
Batch 61/64 loss: -2.923102378845215
Batch 62/64 loss: -2.92410945892334
Batch 63/64 loss: -2.9541473388671875
Batch 64/64 loss: -7.504452705383301
Epoch 485  Train loss: -2.904827757442699  Val loss: -3.1908169644804754
Epoch 486
-------------------------------
Batch 1/64 loss: -2.81935977935791
Batch 2/64 loss: -2.979031562805176
Batch 3/64 loss: -3.033005714416504
Batch 4/64 loss: -2.853048324584961
Batch 5/64 loss: -2.7956485748291016
Batch 6/64 loss: -2.7411670684814453
Batch 7/64 loss: -2.964080810546875
Batch 8/64 loss: -2.8876266479492188
Batch 9/64 loss: -2.9428577423095703
Batch 10/64 loss: -2.932649612426758
Batch 11/64 loss: -3.0612001419067383
Batch 12/64 loss: -2.8403711318969727
Batch 13/64 loss: -2.8980884552001953
Batch 14/64 loss: -3.145009994506836
Batch 15/64 loss: -2.9402828216552734
Batch 16/64 loss: -2.9731369018554688
Batch 17/64 loss: -2.911604881286621
Batch 18/64 loss: -3.036073684692383
Batch 19/64 loss: -2.0020360946655273
Batch 20/64 loss: -2.8608579635620117
Batch 21/64 loss: -2.986464500427246
Batch 22/64 loss: -3.0364456176757812
Batch 23/64 loss: -2.9607887268066406
Batch 24/64 loss: -3.0704526901245117
Batch 25/64 loss: -2.8422603607177734
Batch 26/64 loss: -2.9432849884033203
Batch 27/64 loss: -2.6979265213012695
Batch 28/64 loss: -3.052448272705078
Batch 29/64 loss: -2.8975048065185547
Batch 30/64 loss: -2.9477710723876953
Batch 31/64 loss: -2.8660354614257812
Batch 32/64 loss: -2.9580135345458984
Batch 33/64 loss: -2.910000801086426
Batch 34/64 loss: -2.853422164916992
Batch 35/64 loss: -2.8357982635498047
Batch 36/64 loss: -2.8146915435791016
Batch 37/64 loss: -2.692418098449707
Batch 38/64 loss: -3.0987491607666016
Batch 39/64 loss: -3.0210018157958984
Batch 40/64 loss: -2.9541149139404297
Batch 41/64 loss: -2.6946802139282227
Batch 42/64 loss: -2.8508100509643555
Batch 43/64 loss: -2.9051036834716797
Batch 44/64 loss: -2.7767724990844727
Batch 45/64 loss: -2.7592363357543945
Batch 46/64 loss: -2.7262983322143555
Batch 47/64 loss: -2.831141471862793
Batch 48/64 loss: -2.940776824951172
Batch 49/64 loss: -2.380817413330078
Batch 50/64 loss: -2.876490592956543
Batch 51/64 loss: -2.97591495513916
Batch 52/64 loss: -3.0392160415649414
Batch 53/64 loss: -2.6368064880371094
Batch 54/64 loss: -2.770169258117676
Batch 55/64 loss: -3.055434226989746
Batch 56/64 loss: -2.531487464904785
Batch 57/64 loss: -3.1015138626098633
Batch 58/64 loss: -2.4553871154785156
Batch 59/64 loss: -2.4565629959106445
Batch 60/64 loss: -3.0376501083374023
Batch 61/64 loss: -3.004765510559082
Batch 62/64 loss: -3.0267953872680664
Batch 63/64 loss: -3.0448999404907227
Batch 64/64 loss: -7.246111869812012
Epoch 486  Train loss: -2.923451700397566  Val loss: -3.193478587566782
Epoch 487
-------------------------------
Batch 1/64 loss: -3.1192140579223633
Batch 2/64 loss: -3.012387275695801
Batch 3/64 loss: -3.0330610275268555
Batch 4/64 loss: -2.9996395111083984
Batch 5/64 loss: -2.925381660461426
Batch 6/64 loss: -2.9188194274902344
Batch 7/64 loss: -2.975834846496582
Batch 8/64 loss: -3.2017292976379395
Batch 9/64 loss: -2.9936914443969727
Batch 10/64 loss: -3.074702262878418
Batch 11/64 loss: -2.3335113525390625
Batch 12/64 loss: -2.570401191711426
Batch 13/64 loss: -2.8705873489379883
Batch 14/64 loss: -2.776007652282715
Batch 15/64 loss: -2.929347038269043
Batch 16/64 loss: -2.9879932403564453
Batch 17/64 loss: -2.9131155014038086
Batch 18/64 loss: -2.9206295013427734
Batch 19/64 loss: -3.146420478820801
Batch 20/64 loss: -2.8457469940185547
Batch 21/64 loss: -2.959362030029297
Batch 22/64 loss: -2.9938859939575195
Batch 23/64 loss: -2.8802433013916016
Batch 24/64 loss: -2.898111343383789
Batch 25/64 loss: -2.8844337463378906
Batch 26/64 loss: -3.066351890563965
Batch 27/64 loss: -2.9874067306518555
Batch 28/64 loss: -2.7705020904541016
Batch 29/64 loss: -2.4210214614868164
Batch 30/64 loss: -3.058992385864258
Batch 31/64 loss: -2.815431594848633
Batch 32/64 loss: -2.9937639236450195
Batch 33/64 loss: -2.9247055053710938
Batch 34/64 loss: -2.8299999237060547
Batch 35/64 loss: -2.9483747482299805
Batch 36/64 loss: -2.5901079177856445
Batch 37/64 loss: -3.150500774383545
Batch 38/64 loss: -2.074345588684082
Batch 39/64 loss: -2.812145233154297
Batch 40/64 loss: -3.099855422973633
Batch 41/64 loss: -3.037734031677246
Batch 42/64 loss: -2.5126428604125977
Batch 43/64 loss: -2.979607582092285
Batch 44/64 loss: -3.065988540649414
Batch 45/64 loss: -2.866177558898926
Batch 46/64 loss: -3.035527229309082
Batch 47/64 loss: -2.9337682723999023
Batch 48/64 loss: -2.889741897583008
Batch 49/64 loss: -2.9736270904541016
Batch 50/64 loss: -2.760258674621582
Batch 51/64 loss: -2.641842842102051
Batch 52/64 loss: -2.930586814880371
Batch 53/64 loss: -3.0750961303710938
Batch 54/64 loss: -3.02199649810791
Batch 55/64 loss: -2.7823410034179688
Batch 56/64 loss: -3.0027122497558594
Batch 57/64 loss: -2.946889877319336
Batch 58/64 loss: -2.941333770751953
Batch 59/64 loss: -2.806118965148926
Batch 60/64 loss: -2.9837875366210938
Batch 61/64 loss: -2.950349807739258
Batch 62/64 loss: -2.9732589721679688
Batch 63/64 loss: -2.751742362976074
Batch 64/64 loss: -7.2132744789123535
Epoch 487  Train loss: -2.948719202303419  Val loss: -3.2862637051192345
Epoch 488
-------------------------------
Batch 1/64 loss: -2.900954246520996
Batch 2/64 loss: -3.073493003845215
Batch 3/64 loss: -2.933553695678711
Batch 4/64 loss: -2.7289161682128906
Batch 5/64 loss: -3.089177131652832
Batch 6/64 loss: -2.870006561279297
Batch 7/64 loss: -2.964679718017578
Batch 8/64 loss: -3.0268192291259766
Batch 9/64 loss: -3.034881591796875
Batch 10/64 loss: -2.542264938354492
Batch 11/64 loss: -3.009718894958496
Batch 12/64 loss: -2.6953134536743164
Batch 13/64 loss: -2.944854736328125
Batch 14/64 loss: -2.9681615829467773
Batch 15/64 loss: -2.291081428527832
Batch 16/64 loss: -2.9644384384155273
Batch 17/64 loss: -2.8689708709716797
Batch 18/64 loss: -3.027181625366211
Batch 19/64 loss: -3.008608818054199
Batch 20/64 loss: -2.8532609939575195
Batch 21/64 loss: -3.079056739807129
Batch 22/64 loss: -3.065585136413574
Batch 23/64 loss: -3.000430107116699
Batch 24/64 loss: -3.082413673400879
Batch 25/64 loss: -2.9938488006591797
Batch 26/64 loss: -3.1061201095581055
Batch 27/64 loss: -2.778306007385254
Batch 28/64 loss: -3.0712976455688477
Batch 29/64 loss: -2.764699935913086
Batch 30/64 loss: -2.8975696563720703
Batch 31/64 loss: -3.067843437194824
Batch 32/64 loss: -2.8749561309814453
Batch 33/64 loss: -2.149092674255371
Batch 34/64 loss: -2.8471879959106445
Batch 35/64 loss: -2.670654296875
Batch 36/64 loss: -2.8690948486328125
Batch 37/64 loss: -2.7854604721069336
Batch 38/64 loss: -2.9146060943603516
Batch 39/64 loss: -2.9155969619750977
Batch 40/64 loss: -2.9325008392333984
Batch 41/64 loss: -2.5835485458374023
Batch 42/64 loss: -2.6151952743530273
Batch 43/64 loss: -2.7878036499023438
Batch 44/64 loss: -2.8417587280273438
Batch 45/64 loss: -2.7438888549804688
Batch 46/64 loss: -3.0384044647216797
Batch 47/64 loss: -3.044525146484375
Batch 48/64 loss: -2.7806663513183594
Batch 49/64 loss: -2.9114580154418945
Batch 50/64 loss: -2.8310070037841797
Batch 51/64 loss: -3.06546688079834
Batch 52/64 loss: -2.8829708099365234
Batch 53/64 loss: -2.834836006164551
Batch 54/64 loss: -2.98270320892334
Batch 55/64 loss: -2.8645381927490234
Batch 56/64 loss: -2.550609588623047
Batch 57/64 loss: -3.0049362182617188
Batch 58/64 loss: -2.747987747192383
Batch 59/64 loss: -2.828338623046875
Batch 60/64 loss: -2.8002424240112305
Batch 61/64 loss: -2.988332748413086
Batch 62/64 loss: -2.530514717102051
Batch 63/64 loss: -2.868986129760742
Batch 64/64 loss: -7.287572860717773
Epoch 488  Train loss: -2.9216793359494675  Val loss: -3.1179021199544272
Epoch 489
-------------------------------
Batch 1/64 loss: -2.65427303314209
Batch 2/64 loss: -2.9338531494140625
Batch 3/64 loss: -2.825436592102051
Batch 4/64 loss: -2.790938377380371
Batch 5/64 loss: -2.8819475173950195
Batch 6/64 loss: -3.045393943786621
Batch 7/64 loss: -2.846083641052246
Batch 8/64 loss: -2.9383935928344727
Batch 9/64 loss: -2.7874889373779297
Batch 10/64 loss: -3.043837547302246
Batch 11/64 loss: -2.7530107498168945
Batch 12/64 loss: -2.815011978149414
Batch 13/64 loss: -2.921428680419922
Batch 14/64 loss: -2.9446001052856445
Batch 15/64 loss: -2.7597503662109375
Batch 16/64 loss: -2.776458740234375
Batch 17/64 loss: -2.803215980529785
Batch 18/64 loss: -2.652463912963867
Batch 19/64 loss: -2.9341917037963867
Batch 20/64 loss: -2.9383668899536133
Batch 21/64 loss: -2.8735408782958984
Batch 22/64 loss: -2.8267555236816406
Batch 23/64 loss: -2.927140235900879
Batch 24/64 loss: -2.641061782836914
Batch 25/64 loss: -3.0223751068115234
Batch 26/64 loss: -2.9274072647094727
Batch 27/64 loss: -2.8102617263793945
Batch 28/64 loss: -2.5175247192382812
Batch 29/64 loss: -2.539339065551758
Batch 30/64 loss: -2.96842098236084
Batch 31/64 loss: -2.339371681213379
Batch 32/64 loss: -2.7386341094970703
Batch 33/64 loss: -2.890475273132324
Batch 34/64 loss: -2.7282028198242188
Batch 35/64 loss: -2.8276357650756836
Batch 36/64 loss: -2.43865966796875
Batch 37/64 loss: -2.8176698684692383
Batch 38/64 loss: -2.8030967712402344
Batch 39/64 loss: -2.7164697647094727
Batch 40/64 loss: -2.8402109146118164
Batch 41/64 loss: -2.7824745178222656
Batch 42/64 loss: -2.905461311340332
Batch 43/64 loss: -3.0600318908691406
Batch 44/64 loss: -3.027298927307129
Batch 45/64 loss: -2.7712345123291016
Batch 46/64 loss: -2.4756240844726562
Batch 47/64 loss: -2.5780982971191406
Batch 48/64 loss: -2.8371810913085938
Batch 49/64 loss: -2.6276626586914062
Batch 50/64 loss: -2.9704933166503906
Batch 51/64 loss: -2.847421646118164
Batch 52/64 loss: -2.8752927780151367
Batch 53/64 loss: -2.817136764526367
Batch 54/64 loss: -3.029353141784668
Batch 55/64 loss: -2.926626205444336
Batch 56/64 loss: -2.904568672180176
Batch 57/64 loss: -2.986997604370117
Batch 58/64 loss: -2.9489307403564453
Batch 59/64 loss: -2.9326467514038086
Batch 60/64 loss: -3.0327539443969727
Batch 61/64 loss: -2.9290781021118164
Batch 62/64 loss: -2.907541275024414
Batch 63/64 loss: -2.9632959365844727
Batch 64/64 loss: -7.495507717132568
Epoch 489  Train loss: -2.8862624991173838  Val loss: -3.189894751584817
Epoch 490
-------------------------------
Batch 1/64 loss: -2.995584487915039
Batch 2/64 loss: -2.9961585998535156
Batch 3/64 loss: -2.895448684692383
Batch 4/64 loss: -2.8509140014648438
Batch 5/64 loss: -3.0623598098754883
Batch 6/64 loss: -2.936964988708496
Batch 7/64 loss: -2.6263246536254883
Batch 8/64 loss: -2.8070297241210938
Batch 9/64 loss: -2.884798049926758
Batch 10/64 loss: -2.916937828063965
Batch 11/64 loss: -1.8661613464355469
Batch 12/64 loss: -2.9408226013183594
Batch 13/64 loss: -2.9589672088623047
Batch 14/64 loss: -2.8710412979125977
Batch 15/64 loss: -2.921823501586914
Batch 16/64 loss: -3.0470027923583984
Batch 17/64 loss: -2.588395118713379
Batch 18/64 loss: -2.7240123748779297
Batch 19/64 loss: -2.983706474304199
Batch 20/64 loss: -2.879638671875
Batch 21/64 loss: -2.6430463790893555
Batch 22/64 loss: -2.807370185852051
Batch 23/64 loss: -2.9141483306884766
Batch 24/64 loss: -2.543931007385254
Batch 25/64 loss: -2.909346580505371
Batch 26/64 loss: -2.850295066833496
Batch 27/64 loss: -1.885030746459961
Batch 28/64 loss: -2.537446975708008
Batch 29/64 loss: -2.6524658203125
Batch 30/64 loss: -2.879397392272949
Batch 31/64 loss: -2.674777030944824
Batch 32/64 loss: -2.8893423080444336
Batch 33/64 loss: -2.787034034729004
Batch 34/64 loss: -3.1017255783081055
Batch 35/64 loss: -2.6058616638183594
Batch 36/64 loss: -2.831888198852539
Batch 37/64 loss: -3.0664567947387695
Batch 38/64 loss: -2.679983139038086
Batch 39/64 loss: -2.879611015319824
Batch 40/64 loss: -2.8498497009277344
Batch 41/64 loss: -2.9553327560424805
Batch 42/64 loss: -2.998638153076172
Batch 43/64 loss: -2.855484962463379
Batch 44/64 loss: -2.7125587463378906
Batch 45/64 loss: -2.441295623779297
Batch 46/64 loss: -2.6319618225097656
Batch 47/64 loss: -2.699526786804199
Batch 48/64 loss: -2.9155654907226562
Batch 49/64 loss: -2.7924327850341797
Batch 50/64 loss: -2.8327646255493164
Batch 51/64 loss: -2.9321346282958984
Batch 52/64 loss: -3.0670833587646484
Batch 53/64 loss: -2.908522605895996
Batch 54/64 loss: -3.1055545806884766
Batch 55/64 loss: -2.9094467163085938
Batch 56/64 loss: -3.086088180541992
Batch 57/64 loss: -2.234726905822754
Batch 58/64 loss: -2.9974842071533203
Batch 59/64 loss: -2.948338508605957
Batch 60/64 loss: -2.2714920043945312
Batch 61/64 loss: -2.9450178146362305
Batch 62/64 loss: -2.5600814819335938
Batch 63/64 loss: -2.4987640380859375
Batch 64/64 loss: -7.549120903015137
Epoch 490  Train loss: -2.850278237286736  Val loss: -3.2462243017871764
Epoch 491
-------------------------------
Batch 1/64 loss: -2.0700244903564453
Batch 2/64 loss: -2.938931465148926
Batch 3/64 loss: -3.076169967651367
Batch 4/64 loss: -3.0964317321777344
Batch 5/64 loss: -3.0110578536987305
Batch 6/64 loss: -3.0229148864746094
Batch 7/64 loss: -2.8562164306640625
Batch 8/64 loss: -3.1110105514526367
Batch 9/64 loss: -2.733865737915039
Batch 10/64 loss: -2.9615392684936523
Batch 11/64 loss: -2.707399368286133
Batch 12/64 loss: -2.983316421508789
Batch 13/64 loss: -2.969292640686035
Batch 14/64 loss: -2.8626785278320312
Batch 15/64 loss: -2.887171745300293
Batch 16/64 loss: -2.8465137481689453
Batch 17/64 loss: -3.116086959838867
Batch 18/64 loss: -3.0208730697631836
Batch 19/64 loss: -2.4435691833496094
Batch 20/64 loss: -2.9268417358398438
Batch 21/64 loss: -2.9103870391845703
Batch 22/64 loss: -2.9828357696533203
Batch 23/64 loss: -2.8478450775146484
Batch 24/64 loss: -2.9000625610351562
Batch 25/64 loss: -2.742938995361328
Batch 26/64 loss: -2.9967031478881836
Batch 27/64 loss: -3.1113128662109375
Batch 28/64 loss: -2.5062026977539062
Batch 29/64 loss: -3.1283140182495117
Batch 30/64 loss: -3.046670913696289
Batch 31/64 loss: -3.15963077545166
Batch 32/64 loss: -3.0666818618774414
Batch 33/64 loss: -3.048947334289551
Batch 34/64 loss: -3.064711570739746
Batch 35/64 loss: -2.9786691665649414
Batch 36/64 loss: -2.8360300064086914
Batch 37/64 loss: -2.9366531372070312
Batch 38/64 loss: -2.666243553161621
Batch 39/64 loss: -3.1506195068359375
Batch 40/64 loss: -2.9904308319091797
Batch 41/64 loss: -3.1077537536621094
Batch 42/64 loss: -3.0007715225219727
Batch 43/64 loss: -2.9310178756713867
Batch 44/64 loss: -2.9819374084472656
Batch 45/64 loss: -2.9148683547973633
Batch 46/64 loss: -2.84027099609375
Batch 47/64 loss: -2.828380584716797
Batch 48/64 loss: -3.0146360397338867
Batch 49/64 loss: -3.0235042572021484
Batch 50/64 loss: -2.7527389526367188
Batch 51/64 loss: -2.762661933898926
Batch 52/64 loss: -2.989919662475586
Batch 53/64 loss: -2.9838171005249023
Batch 54/64 loss: -2.910220146179199
Batch 55/64 loss: -3.029796600341797
Batch 56/64 loss: -2.981290817260742
Batch 57/64 loss: -2.901264190673828
Batch 58/64 loss: -2.8646793365478516
Batch 59/64 loss: -2.926332473754883
Batch 60/64 loss: -2.813535690307617
Batch 61/64 loss: -3.01021671295166
Batch 62/64 loss: -2.678163528442383
Batch 63/64 loss: -2.88330078125
Batch 64/64 loss: -7.298386096954346
Epoch 491  Train loss: -2.969704547582888  Val loss: -3.183144271168922
Epoch 492
-------------------------------
Batch 1/64 loss: -2.8689823150634766
Batch 2/64 loss: -2.9866132736206055
Batch 3/64 loss: -2.6416940689086914
Batch 4/64 loss: -2.9458255767822266
Batch 5/64 loss: -2.814483642578125
Batch 6/64 loss: -2.008319854736328
Batch 7/64 loss: -2.8706674575805664
Batch 8/64 loss: -2.6136932373046875
Batch 9/64 loss: -3.0468311309814453
Batch 10/64 loss: -2.9701032638549805
Batch 11/64 loss: -2.7819929122924805
Batch 12/64 loss: -2.962082862854004
Batch 13/64 loss: -2.8621158599853516
Batch 14/64 loss: -2.9508514404296875
Batch 15/64 loss: -2.9327545166015625
Batch 16/64 loss: -2.8787078857421875
Batch 17/64 loss: -2.1790390014648438
Batch 18/64 loss: -2.9852190017700195
Batch 19/64 loss: -2.612375259399414
Batch 20/64 loss: -2.7411441802978516
Batch 21/64 loss: -2.942580223083496
Batch 22/64 loss: -2.735044479370117
Batch 23/64 loss: -3.1073102951049805
Batch 24/64 loss: -2.8408851623535156
Batch 25/64 loss: -2.903988838195801
Batch 26/64 loss: -2.483684539794922
Batch 27/64 loss: -3.0429258346557617
Batch 28/64 loss: -3.0555105209350586
Batch 29/64 loss: -3.0084638595581055
Batch 30/64 loss: -2.9111509323120117
Batch 31/64 loss: -2.9839515686035156
Batch 32/64 loss: -2.556912422180176
Batch 33/64 loss: -2.651066780090332
Batch 34/64 loss: -2.8541088104248047
Batch 35/64 loss: -3.0212478637695312
Batch 36/64 loss: -2.5150060653686523
Batch 37/64 loss: -2.7407007217407227
Batch 38/64 loss: -3.0244197845458984
Batch 39/64 loss: -3.10770320892334
Batch 40/64 loss: -3.006463050842285
Batch 41/64 loss: -3.13525390625
Batch 42/64 loss: -3.0556650161743164
Batch 43/64 loss: -2.8453359603881836
Batch 44/64 loss: -3.195453643798828
Batch 45/64 loss: -3.0524559020996094
Batch 46/64 loss: -3.0471506118774414
Batch 47/64 loss: -2.964323043823242
Batch 48/64 loss: -2.960360527038574
Batch 49/64 loss: -2.9942331314086914
Batch 50/64 loss: -3.1498641967773438
Batch 51/64 loss: -2.916630744934082
Batch 52/64 loss: -3.044218063354492
Batch 53/64 loss: -2.67458438873291
Batch 54/64 loss: -2.770810127258301
Batch 55/64 loss: -3.006037712097168
Batch 56/64 loss: -2.889995574951172
Batch 57/64 loss: -2.6366920471191406
Batch 58/64 loss: -3.0604944229125977
Batch 59/64 loss: -2.966777801513672
Batch 60/64 loss: -3.0615034103393555
Batch 61/64 loss: -2.92486572265625
Batch 62/64 loss: -2.9397497177124023
Batch 63/64 loss: -2.82254695892334
Batch 64/64 loss: -7.669412612915039
Epoch 492  Train loss: -2.933547981112611  Val loss: -3.3040501047245825
Saving best model, epoch: 492
Epoch 493
-------------------------------
Batch 1/64 loss: -2.9299354553222656
Batch 2/64 loss: -2.7619924545288086
Batch 3/64 loss: -3.1056203842163086
Batch 4/64 loss: -2.90673828125
Batch 5/64 loss: -2.9541797637939453
Batch 6/64 loss: -2.775371551513672
Batch 7/64 loss: -2.8470163345336914
Batch 8/64 loss: -2.485605239868164
Batch 9/64 loss: -2.9624242782592773
Batch 10/64 loss: -2.733860969543457
Batch 11/64 loss: -2.89351749420166
Batch 12/64 loss: -3.034731864929199
Batch 13/64 loss: -2.904129981994629
Batch 14/64 loss: -2.885538101196289
Batch 15/64 loss: -2.9238224029541016
Batch 16/64 loss: -2.8058929443359375
Batch 17/64 loss: -2.2956008911132812
Batch 18/64 loss: -2.821352958679199
Batch 19/64 loss: -3.072625160217285
Batch 20/64 loss: -2.976935386657715
Batch 21/64 loss: -2.9318809509277344
Batch 22/64 loss: -2.94980525970459
Batch 23/64 loss: -2.9750595092773438
Batch 24/64 loss: -2.861682891845703
Batch 25/64 loss: -3.0143299102783203
Batch 26/64 loss: -2.8243484497070312
Batch 27/64 loss: -2.980465888977051
Batch 28/64 loss: -2.8154296875
Batch 29/64 loss: -2.879617691040039
Batch 30/64 loss: -2.686570167541504
Batch 31/64 loss: -2.4600906372070312
Batch 32/64 loss: -2.953275680541992
Batch 33/64 loss: -2.752354621887207
Batch 34/64 loss: -2.186354637145996
Batch 35/64 loss: -3.1346282958984375
Batch 36/64 loss: -3.061530113220215
Batch 37/64 loss: -2.81862735748291
Batch 38/64 loss: -2.9617443084716797
Batch 39/64 loss: -2.8060483932495117
Batch 40/64 loss: -2.9841737747192383
Batch 41/64 loss: -3.04287052154541
Batch 42/64 loss: -2.734646797180176
Batch 43/64 loss: -2.9421844482421875
Batch 44/64 loss: -2.9378299713134766
Batch 45/64 loss: -2.937180519104004
Batch 46/64 loss: -2.711005210876465
Batch 47/64 loss: -2.836851119995117
Batch 48/64 loss: -3.033749580383301
Batch 49/64 loss: -2.553957939147949
Batch 50/64 loss: -2.7825851440429688
Batch 51/64 loss: -2.9650392532348633
Batch 52/64 loss: -3.008969306945801
Batch 53/64 loss: -2.5491771697998047
Batch 54/64 loss: -2.9835987091064453
Batch 55/64 loss: -3.0199508666992188
Batch 56/64 loss: -3.0714426040649414
Batch 57/64 loss: -2.79693603515625
Batch 58/64 loss: -2.9047346115112305
Batch 59/64 loss: -2.5281991958618164
Batch 60/64 loss: -2.9340591430664062
Batch 61/64 loss: -2.9423770904541016
Batch 62/64 loss: -2.7390356063842773
Batch 63/64 loss: -2.835103988647461
Batch 64/64 loss: -7.376574516296387
Epoch 493  Train loss: -2.908844326991661  Val loss: -3.0903183717498255
Epoch 494
-------------------------------
Batch 1/64 loss: -2.9490556716918945
Batch 2/64 loss: -3.046849250793457
Batch 3/64 loss: -3.095365524291992
Batch 4/64 loss: -2.9587326049804688
Batch 5/64 loss: -2.953693389892578
Batch 6/64 loss: -2.9517269134521484
Batch 7/64 loss: -2.668473243713379
Batch 8/64 loss: -2.821702003479004
Batch 9/64 loss: -3.0237321853637695
Batch 10/64 loss: -2.8835935592651367
Batch 11/64 loss: -2.9035844802856445
Batch 12/64 loss: -2.94789981842041
Batch 13/64 loss: -2.9554319381713867
Batch 14/64 loss: -2.865325927734375
Batch 15/64 loss: -2.9954090118408203
Batch 16/64 loss: -2.9368581771850586
Batch 17/64 loss: -2.2644519805908203
Batch 18/64 loss: -2.9788808822631836
Batch 19/64 loss: -3.0158519744873047
Batch 20/64 loss: -3.001230239868164
Batch 21/64 loss: -2.9052467346191406
Batch 22/64 loss: -2.9056882858276367
Batch 23/64 loss: -2.903082847595215
Batch 24/64 loss: -3.1819629669189453
Batch 25/64 loss: -3.01846981048584
Batch 26/64 loss: -2.926219940185547
Batch 27/64 loss: -2.987614631652832
Batch 28/64 loss: -2.892552375793457
Batch 29/64 loss: -2.1811704635620117
Batch 30/64 loss: -3.0701522827148438
Batch 31/64 loss: -3.0742835998535156
Batch 32/64 loss: -3.0358009338378906
Batch 33/64 loss: -2.833268165588379
Batch 34/64 loss: -3.1652889251708984
Batch 35/64 loss: -2.7280263900756836
Batch 36/64 loss: -2.9043960571289062
Batch 37/64 loss: -2.867238998413086
Batch 38/64 loss: -2.8742523193359375
Batch 39/64 loss: -2.7136716842651367
Batch 40/64 loss: -2.9956254959106445
Batch 41/64 loss: -2.716586112976074
Batch 42/64 loss: -3.0579137802124023
Batch 43/64 loss: -2.977457046508789
Batch 44/64 loss: -3.033945083618164
Batch 45/64 loss: -2.873551368713379
Batch 46/64 loss: -2.8836355209350586
Batch 47/64 loss: -2.8831825256347656
Batch 48/64 loss: -2.773212432861328
Batch 49/64 loss: -2.9791736602783203
Batch 50/64 loss: -2.90887451171875
Batch 51/64 loss: -2.895414352416992
Batch 52/64 loss: -2.1178808212280273
Batch 53/64 loss: -3.105879783630371
Batch 54/64 loss: -2.8885746002197266
Batch 55/64 loss: -2.8372011184692383
Batch 56/64 loss: -2.714984893798828
Batch 57/64 loss: -2.343194007873535
Batch 58/64 loss: -2.8877429962158203
Batch 59/64 loss: -3.032975196838379
Batch 60/64 loss: -2.802433967590332
Batch 61/64 loss: -2.831716537475586
Batch 62/64 loss: -3.0752735137939453
Batch 63/64 loss: -2.9232797622680664
Batch 64/64 loss: -7.285702228546143
Epoch 494  Train loss: -2.9394544620139924  Val loss: -3.24507004780458
Epoch 495
-------------------------------
Batch 1/64 loss: -3.0131454467773438
Batch 2/64 loss: -2.913280487060547
Batch 3/64 loss: -2.996641159057617
Batch 4/64 loss: -2.9474658966064453
Batch 5/64 loss: -2.99387264251709
Batch 6/64 loss: -2.659160614013672
Batch 7/64 loss: -2.743204116821289
Batch 8/64 loss: -2.7359046936035156
Batch 9/64 loss: -3.001070022583008
Batch 10/64 loss: -2.721205711364746
Batch 11/64 loss: -3.107184410095215
Batch 12/64 loss: -2.5946226119995117
Batch 13/64 loss: -2.966827392578125
Batch 14/64 loss: -2.9903087615966797
Batch 15/64 loss: -2.802644729614258
Batch 16/64 loss: -2.7953290939331055
Batch 17/64 loss: -3.0310115814208984
Batch 18/64 loss: -2.6973276138305664
Batch 19/64 loss: -2.9390411376953125
Batch 20/64 loss: -2.526620864868164
Batch 21/64 loss: -2.802450180053711
Batch 22/64 loss: -2.718062400817871
Batch 23/64 loss: -2.4016780853271484
Batch 24/64 loss: -2.7527618408203125
Batch 25/64 loss: -2.65579891204834
Batch 26/64 loss: -2.8459529876708984
Batch 27/64 loss: -2.9384822845458984
Batch 28/64 loss: -2.7828922271728516
Batch 29/64 loss: -2.524974822998047
Batch 30/64 loss: -2.9181995391845703
Batch 31/64 loss: -2.931208610534668
Batch 32/64 loss: -2.618039131164551
Batch 33/64 loss: -2.997121810913086
Batch 34/64 loss: -2.558466911315918
Batch 35/64 loss: -2.7268800735473633
Batch 36/64 loss: -2.799894332885742
Batch 37/64 loss: -2.794881820678711
Batch 38/64 loss: -2.789586067199707
Batch 39/64 loss: -2.9957008361816406
Batch 40/64 loss: -2.270688056945801
Batch 41/64 loss: -2.836986541748047
Batch 42/64 loss: -2.8191280364990234
Batch 43/64 loss: -3.0368165969848633
Batch 44/64 loss: -2.748898506164551
Batch 45/64 loss: -3.0062179565429688
Batch 46/64 loss: -3.021122932434082
Batch 47/64 loss: -3.069316864013672
Batch 48/64 loss: -3.0215530395507812
Batch 49/64 loss: -2.7162399291992188
Batch 50/64 loss: -2.7962636947631836
Batch 51/64 loss: -2.3388471603393555
Batch 52/64 loss: -2.778204917907715
Batch 53/64 loss: -2.341517448425293
Batch 54/64 loss: -2.8766469955444336
Batch 55/64 loss: -2.971273422241211
Batch 56/64 loss: -2.989274024963379
Batch 57/64 loss: -2.807811737060547
Batch 58/64 loss: -2.8457489013671875
Batch 59/64 loss: -2.77423095703125
Batch 60/64 loss: -2.7375049591064453
Batch 61/64 loss: -3.054311752319336
Batch 62/64 loss: -3.0439090728759766
Batch 63/64 loss: -3.1117916107177734
Batch 64/64 loss: -7.489483833312988
Epoch 495  Train loss: -2.8762403114169253  Val loss: -3.259416547427882
Epoch 496
-------------------------------
Batch 1/64 loss: -2.8906736373901367
Batch 2/64 loss: -2.45391845703125
Batch 3/64 loss: -2.650832176208496
Batch 4/64 loss: -3.09464168548584
Batch 5/64 loss: -2.8789358139038086
Batch 6/64 loss: -3.0644588470458984
Batch 7/64 loss: -3.027979850769043
Batch 8/64 loss: -1.957479476928711
Batch 9/64 loss: -2.867579460144043
Batch 10/64 loss: -2.9638681411743164
Batch 11/64 loss: -2.973814010620117
Batch 12/64 loss: -2.927731513977051
Batch 13/64 loss: -2.78829288482666
Batch 14/64 loss: -2.810683250427246
Batch 15/64 loss: -2.785794258117676
Batch 16/64 loss: -2.954928398132324
Batch 17/64 loss: -2.981679916381836
Batch 18/64 loss: -3.00897216796875
Batch 19/64 loss: -3.033557891845703
Batch 20/64 loss: -2.8624677658081055
Batch 21/64 loss: -2.882046699523926
Batch 22/64 loss: -2.7813119888305664
Batch 23/64 loss: -3.058255195617676
Batch 24/64 loss: -2.994535446166992
Batch 25/64 loss: -2.8938989639282227
Batch 26/64 loss: -2.7781295776367188
Batch 27/64 loss: -2.622211456298828
Batch 28/64 loss: -2.753891944885254
Batch 29/64 loss: -2.875044822692871
Batch 30/64 loss: -3.092961311340332
Batch 31/64 loss: -2.99727725982666
Batch 32/64 loss: -2.9600887298583984
Batch 33/64 loss: -2.842144012451172
Batch 34/64 loss: -2.6819400787353516
Batch 35/64 loss: -2.877284049987793
Batch 36/64 loss: -3.0211172103881836
Batch 37/64 loss: -2.7204971313476562
Batch 38/64 loss: -3.063016891479492
Batch 39/64 loss: -3.104353904724121
Batch 40/64 loss: -2.9085187911987305
Batch 41/64 loss: -2.865450859069824
Batch 42/64 loss: -3.0332069396972656
Batch 43/64 loss: -2.670980453491211
Batch 44/64 loss: -3.1514205932617188
Batch 45/64 loss: -2.98331356048584
Batch 46/64 loss: -3.035214424133301
Batch 47/64 loss: -2.8253097534179688
Batch 48/64 loss: -3.030233383178711
Batch 49/64 loss: -3.002267837524414
Batch 50/64 loss: -2.9538631439208984
Batch 51/64 loss: -3.0321521759033203
Batch 52/64 loss: -3.01560115814209
Batch 53/64 loss: -2.3191099166870117
Batch 54/64 loss: -2.9035425186157227
Batch 55/64 loss: -2.8211851119995117
Batch 56/64 loss: -2.915755271911621
Batch 57/64 loss: -3.2145328521728516
Batch 58/64 loss: -3.040742874145508
Batch 59/64 loss: -3.0010690689086914
Batch 60/64 loss: -2.829458236694336
Batch 61/64 loss: -3.104403495788574
Batch 62/64 loss: -2.9432525634765625
Batch 63/64 loss: -3.1038570404052734
Batch 64/64 loss: -7.565912246704102
Epoch 496  Train loss: -2.954622313555549  Val loss: -3.284376518013551
Epoch 497
-------------------------------
Batch 1/64 loss: -2.8304367065429688
Batch 2/64 loss: -2.844493865966797
Batch 3/64 loss: -2.6923646926879883
Batch 4/64 loss: -2.991082191467285
Batch 5/64 loss: -2.9524078369140625
Batch 6/64 loss: -2.770872116088867
Batch 7/64 loss: -2.6297006607055664
Batch 8/64 loss: -2.981405258178711
Batch 9/64 loss: -2.45635986328125
Batch 10/64 loss: -2.7810306549072266
Batch 11/64 loss: -2.8888959884643555
Batch 12/64 loss: -3.1213560104370117
Batch 13/64 loss: -2.9766082763671875
Batch 14/64 loss: -2.9521074295043945
Batch 15/64 loss: -3.098073959350586
Batch 16/64 loss: -3.034945487976074
Batch 17/64 loss: -2.957639694213867
Batch 18/64 loss: -2.930154800415039
Batch 19/64 loss: -2.740880012512207
Batch 20/64 loss: -2.852786064147949
Batch 21/64 loss: -2.902545928955078
Batch 22/64 loss: -2.8280439376831055
Batch 23/64 loss: -2.908803939819336
Batch 24/64 loss: -2.9717416763305664
Batch 25/64 loss: -3.1494483947753906
Batch 26/64 loss: -2.9379587173461914
Batch 27/64 loss: -2.7802066802978516
Batch 28/64 loss: -3.028923988342285
Batch 29/64 loss: -2.892873764038086
Batch 30/64 loss: -3.0418033599853516
Batch 31/64 loss: -3.029871940612793
Batch 32/64 loss: -2.974116325378418
Batch 33/64 loss: -3.080965042114258
Batch 34/64 loss: -2.7885284423828125
Batch 35/64 loss: -2.801846504211426
Batch 36/64 loss: -2.845059394836426
Batch 37/64 loss: -2.8128156661987305
Batch 38/64 loss: -3.0364837646484375
Batch 39/64 loss: -3.0640411376953125
Batch 40/64 loss: -2.4982872009277344
Batch 41/64 loss: -2.9637136459350586
Batch 42/64 loss: -2.7680749893188477
Batch 43/64 loss: -2.7963132858276367
Batch 44/64 loss: -3.027499198913574
Batch 45/64 loss: -2.6484785079956055
Batch 46/64 loss: -2.8839330673217773
Batch 47/64 loss: -3.07529354095459
Batch 48/64 loss: -2.447756767272949
Batch 49/64 loss: -2.9584341049194336
Batch 50/64 loss: -3.0876808166503906
Batch 51/64 loss: -3.0319995880126953
Batch 52/64 loss: -3.0721473693847656
Batch 53/64 loss: -3.045978546142578
Batch 54/64 loss: -2.8181419372558594
Batch 55/64 loss: -2.5480480194091797
Batch 56/64 loss: -2.919499397277832
Batch 57/64 loss: -2.810519218444824
Batch 58/64 loss: -2.875415802001953
Batch 59/64 loss: -2.7284908294677734
Batch 60/64 loss: -2.941653251647949
Batch 61/64 loss: -2.9628639221191406
Batch 62/64 loss: -2.952530860900879
Batch 63/64 loss: -2.6957015991210938
Batch 64/64 loss: -7.27489709854126
Epoch 497  Train loss: -2.9392048386966483  Val loss: -3.289652939104952
Epoch 498
-------------------------------
Batch 1/64 loss: -2.9048843383789062
Batch 2/64 loss: -2.945220947265625
Batch 3/64 loss: -2.875213623046875
Batch 4/64 loss: -2.9076595306396484
Batch 5/64 loss: -3.0330867767333984
Batch 6/64 loss: -2.9287261962890625
Batch 7/64 loss: -2.7142410278320312
Batch 8/64 loss: -2.949032783508301
Batch 9/64 loss: -2.8924989700317383
Batch 10/64 loss: -2.940781593322754
Batch 11/64 loss: -2.9322643280029297
Batch 12/64 loss: -3.0198450088500977
Batch 13/64 loss: -3.085603713989258
Batch 14/64 loss: -3.0136070251464844
Batch 15/64 loss: -3.051205635070801
Batch 16/64 loss: -2.8825483322143555
Batch 17/64 loss: -2.618271827697754
Batch 18/64 loss: -2.9678478240966797
Batch 19/64 loss: -3.074530601501465
Batch 20/64 loss: -2.977431297302246
Batch 21/64 loss: -2.10689640045166
Batch 22/64 loss: -2.8598861694335938
Batch 23/64 loss: -3.005094528198242
Batch 24/64 loss: -2.926957130432129
Batch 25/64 loss: -2.9871063232421875
Batch 26/64 loss: -2.8508682250976562
Batch 27/64 loss: -2.9621944427490234
Batch 28/64 loss: -2.996044158935547
Batch 29/64 loss: -2.920071601867676
Batch 30/64 loss: -2.914365768432617
Batch 31/64 loss: -2.811952590942383
Batch 32/64 loss: -2.508913993835449
Batch 33/64 loss: -3.0683202743530273
Batch 34/64 loss: -3.1400957107543945
Batch 35/64 loss: -2.459378242492676
Batch 36/64 loss: -2.6591482162475586
Batch 37/64 loss: -3.1392221450805664
Batch 38/64 loss: -2.4920730590820312
Batch 39/64 loss: -3.0341997146606445
Batch 40/64 loss: -2.9286060333251953
Batch 41/64 loss: -2.95304012298584
Batch 42/64 loss: -2.868170738220215
Batch 43/64 loss: -2.901951789855957
Batch 44/64 loss: -2.9013376235961914
Batch 45/64 loss: -2.994441032409668
Batch 46/64 loss: -2.827737808227539
Batch 47/64 loss: -2.905329704284668
Batch 48/64 loss: -2.9786806106567383
Batch 49/64 loss: -2.9565210342407227
Batch 50/64 loss: -2.6114578247070312
Batch 51/64 loss: -2.8726682662963867
Batch 52/64 loss: -2.6968469619750977
Batch 53/64 loss: -2.7999353408813477
Batch 54/64 loss: -2.7067928314208984
Batch 55/64 loss: -2.781156539916992
Batch 56/64 loss: -2.8386669158935547
Batch 57/64 loss: -2.8274269104003906
Batch 58/64 loss: -2.9028730392456055
Batch 59/64 loss: -2.6471357345581055
Batch 60/64 loss: -2.7983884811401367
Batch 61/64 loss: -3.144759178161621
Batch 62/64 loss: -2.845370292663574
Batch 63/64 loss: -3.021961212158203
Batch 64/64 loss: -7.65612268447876
Epoch 498  Train loss: -2.9335002057692585  Val loss: -3.296433373415183
Epoch 499
-------------------------------
Batch 1/64 loss: -2.8992271423339844
Batch 2/64 loss: -2.9586334228515625
Batch 3/64 loss: -2.221327781677246
Batch 4/64 loss: -2.4772205352783203
Batch 5/64 loss: -2.9496946334838867
Batch 6/64 loss: -2.9275922775268555
Batch 7/64 loss: -3.024534225463867
Batch 8/64 loss: -3.0857772827148438
Batch 9/64 loss: -3.015277862548828
Batch 10/64 loss: -3.0296096801757812
Batch 11/64 loss: -2.7742481231689453
Batch 12/64 loss: -2.8076725006103516
Batch 13/64 loss: -2.695254325866699
Batch 14/64 loss: -2.8682126998901367
Batch 15/64 loss: -2.137345314025879
Batch 16/64 loss: -2.9929428100585938
Batch 17/64 loss: -3.016632080078125
Batch 18/64 loss: -2.9714088439941406
Batch 19/64 loss: -3.1454601287841797
Batch 20/64 loss: -3.0001039505004883
Batch 21/64 loss: -2.6221065521240234
Batch 22/64 loss: -2.609130859375
Batch 23/64 loss: -2.7775869369506836
Batch 24/64 loss: -3.016890525817871
Batch 25/64 loss: -2.6530189514160156
Batch 26/64 loss: -3.064004898071289
Batch 27/64 loss: -2.9350757598876953
Batch 28/64 loss: -2.9049339294433594
Batch 29/64 loss: -2.702239990234375
Batch 30/64 loss: -3.018404006958008
Batch 31/64 loss: -3.0970840454101562
Batch 32/64 loss: -2.7082271575927734
Batch 33/64 loss: -2.9952688217163086
Batch 34/64 loss: -2.82729434967041
Batch 35/64 loss: -2.8618087768554688
Batch 36/64 loss: -2.9954090118408203
Batch 37/64 loss: -2.883456230163574
Batch 38/64 loss: -3.053617477416992
Batch 39/64 loss: -3.043959617614746
Batch 40/64 loss: -3.100393295288086
Batch 41/64 loss: -2.97104549407959
Batch 42/64 loss: -2.8882570266723633
Batch 43/64 loss: -3.0444183349609375
Batch 44/64 loss: -2.9394760131835938
Batch 45/64 loss: -2.907467842102051
Batch 46/64 loss: -2.4138059616088867
Batch 47/64 loss: -3.0192441940307617
Batch 48/64 loss: -2.921980857849121
Batch 49/64 loss: -2.880502700805664
Batch 50/64 loss: -3.0436315536499023
Batch 51/64 loss: -2.974641799926758
Batch 52/64 loss: -2.856485366821289
Batch 53/64 loss: -2.8776941299438477
Batch 54/64 loss: -2.991119384765625
Batch 55/64 loss: -2.6662254333496094
Batch 56/64 loss: -3.0991477966308594
Batch 57/64 loss: -2.9670591354370117
Batch 58/64 loss: -2.8700199127197266
Batch 59/64 loss: -2.9784727096557617
Batch 60/64 loss: -3.0292434692382812
Batch 61/64 loss: -2.4546804428100586
Batch 62/64 loss: -2.7592716217041016
Batch 63/64 loss: -2.929807662963867
Batch 64/64 loss: -7.5006842613220215
Epoch 499  Train loss: -2.932977236953436  Val loss: -3.2744190963273194
Epoch 500
-------------------------------
Batch 1/64 loss: -2.7806787490844727
Batch 2/64 loss: -3.023622512817383
Batch 3/64 loss: -2.6536426544189453
Batch 4/64 loss: -2.7733144760131836
Batch 5/64 loss: -3.028456687927246
Batch 6/64 loss: -2.894984245300293
Batch 7/64 loss: -1.8726978302001953
Batch 8/64 loss: -2.8302688598632812
Batch 9/64 loss: -2.8632001876831055
Batch 10/64 loss: -2.811854362487793
Batch 11/64 loss: -2.9664993286132812
Batch 12/64 loss: -3.0477046966552734
Batch 13/64 loss: -2.8930749893188477
Batch 14/64 loss: -3.07468318939209
Batch 15/64 loss: -2.9340295791625977
Batch 16/64 loss: -2.990138053894043
Batch 17/64 loss: -2.946343421936035
Batch 18/64 loss: -2.45975399017334
Batch 19/64 loss: -2.9602317810058594
Batch 20/64 loss: -2.9304885864257812
Batch 21/64 loss: -2.8675765991210938
Batch 22/64 loss: -2.924224853515625
Batch 23/64 loss: -2.58194637298584
Batch 24/64 loss: -3.073528289794922
Batch 25/64 loss: -3.0113630294799805
Batch 26/64 loss: -2.9938745498657227
Batch 27/64 loss: -2.5629968643188477
Batch 28/64 loss: -3.007685661315918
Batch 29/64 loss: -2.7417964935302734
Batch 30/64 loss: -2.8959293365478516
Batch 31/64 loss: -2.731776237487793
Batch 32/64 loss: -3.001955032348633
Batch 33/64 loss: -2.592897415161133
Batch 34/64 loss: -3.05770206451416
Batch 35/64 loss: -2.9893617630004883
Batch 36/64 loss: -2.6923227310180664
Batch 37/64 loss: -2.6731491088867188
Batch 38/64 loss: -2.9941749572753906
Batch 39/64 loss: -3.0989999771118164
Batch 40/64 loss: -3.038106918334961
Batch 41/64 loss: -2.8368988037109375
Batch 42/64 loss: -2.7281532287597656
Batch 43/64 loss: -2.9325618743896484
Batch 44/64 loss: -2.798107147216797
Batch 45/64 loss: -2.8741283416748047
Batch 46/64 loss: -2.964594841003418
Batch 47/64 loss: -2.4466867446899414
Batch 48/64 loss: -2.808717727661133
Batch 49/64 loss: -2.9945755004882812
Batch 50/64 loss: -2.992616653442383
Batch 51/64 loss: -2.8096094131469727
Batch 52/64 loss: -2.948820114135742
Batch 53/64 loss: -2.923457145690918
Batch 54/64 loss: -2.745713233947754
Batch 55/64 loss: -2.901416778564453
Batch 56/64 loss: -2.879326820373535
Batch 57/64 loss: -2.8581018447875977
Batch 58/64 loss: -2.887537956237793
Batch 59/64 loss: -3.08856201171875
Batch 60/64 loss: -3.070293426513672
Batch 61/64 loss: -2.7962722778320312
Batch 62/64 loss: -3.1350831985473633
Batch 63/64 loss: -3.0596399307250977
Batch 64/64 loss: -7.555456638336182
Epoch 500  Train loss: -2.924149081286262  Val loss: -3.2825475476451755
SLIC undersegmentation error: 0.12412920962199316
SLIC inter-cluster variation: 0.13904419774313004
SLIC number of superpixels: 21483
SLIC superpixels per image: 73.82474226804123
Model loaded
Test metrics:
-3.90387552792264 0.2966323024054982 26.354842919329016 tensor(0.2699, dtype=torch.float64) 0.6498722679534488 2.4988172958652664 21138
Inference time: 0.0037581248791357085 seconds
Relabeled undersegmentation error: 0.11351477663230239
Relabeled inter-cluster variation: 0.09093944319161044
Relabeled mean superpixels count: 181.48453608247422
Original mean superpixels count: 72.63230240549828
Done!
Job id: 488342
Job id: 492267
