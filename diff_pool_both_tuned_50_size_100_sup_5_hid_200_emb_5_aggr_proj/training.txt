Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 4.837264060974121
Batch 2/64 loss: 4.754933834075928
Batch 3/64 loss: 4.538577556610107
Batch 4/64 loss: 4.529972076416016
Batch 5/64 loss: 4.298593521118164
Batch 6/64 loss: 4.15787410736084
Batch 7/64 loss: 4.005510330200195
Batch 8/64 loss: 3.887233257293701
Batch 9/64 loss: 3.7538485527038574
Batch 10/64 loss: 3.671454906463623
Batch 11/64 loss: 3.5677387714385986
Batch 12/64 loss: 3.527695655822754
Batch 13/64 loss: 3.3475661277770996
Batch 14/64 loss: 3.2778053283691406
Batch 15/64 loss: 3.161520004272461
Batch 16/64 loss: 3.118288278579712
Batch 17/64 loss: 3.022336006164551
Batch 18/64 loss: 2.913071870803833
Batch 19/64 loss: 2.894002914428711
Batch 20/64 loss: 2.8897528648376465
Batch 21/64 loss: 2.820310592651367
Batch 22/64 loss: 2.6910758018493652
Batch 23/64 loss: 2.7172696590423584
Batch 24/64 loss: 2.5618414878845215
Batch 25/64 loss: 2.5855705738067627
Batch 26/64 loss: 2.554720878601074
Batch 27/64 loss: 2.603466033935547
Batch 28/64 loss: 2.516810417175293
Batch 29/64 loss: 2.516664981842041
Batch 30/64 loss: 2.396118402481079
Batch 31/64 loss: 2.511320114135742
Batch 32/64 loss: 2.4469404220581055
Batch 33/64 loss: 2.422442674636841
Batch 34/64 loss: 2.5069618225097656
Batch 35/64 loss: 2.3829779624938965
Batch 36/64 loss: 2.375755786895752
Batch 37/64 loss: 2.316372871398926
Batch 38/64 loss: 2.4133925437927246
Batch 39/64 loss: 2.39224910736084
Batch 40/64 loss: 2.3601789474487305
Batch 41/64 loss: 2.3185105323791504
Batch 42/64 loss: 2.370062828063965
Batch 43/64 loss: 2.4217514991760254
Batch 44/64 loss: 2.2717604637145996
Batch 45/64 loss: 2.4004263877868652
Batch 46/64 loss: 2.4113636016845703
Batch 47/64 loss: 2.332106113433838
Batch 48/64 loss: 2.263669967651367
Batch 49/64 loss: 2.344233751296997
Batch 50/64 loss: 2.2877981662750244
Batch 51/64 loss: 2.290513038635254
Batch 52/64 loss: 2.245760917663574
Batch 53/64 loss: 2.2523345947265625
Batch 54/64 loss: 2.2900450229644775
Batch 55/64 loss: 2.2556142807006836
Batch 56/64 loss: 2.2506520748138428
Batch 57/64 loss: 2.1491944789886475
Batch 58/64 loss: 2.2129437923431396
Batch 59/64 loss: 2.156783103942871
Batch 60/64 loss: 2.2256641387939453
Batch 61/64 loss: 2.169811964035034
Batch 62/64 loss: 2.1803202629089355
Batch 63/64 loss: 2.2343592643737793
Batch 64/64 loss: 2.5419161319732666
Epoch 1  Train loss: 2.7998368384791354  Val loss: 2.394533888171219
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 2.177701473236084
Batch 2/64 loss: 2.215345859527588
Batch 3/64 loss: 2.2000346183776855
Batch 4/64 loss: 2.181666612625122
Batch 5/64 loss: 2.1696739196777344
Batch 6/64 loss: 2.2307231426239014
Batch 7/64 loss: 2.1833746433258057
Batch 8/64 loss: 2.1863765716552734
Batch 9/64 loss: 2.161621332168579
Batch 10/64 loss: 2.1557278633117676
Batch 11/64 loss: 2.1697611808776855
Batch 12/64 loss: 2.1877622604370117
Batch 13/64 loss: 2.1969528198242188
Batch 14/64 loss: 2.2248358726501465
Batch 15/64 loss: 2.2011537551879883
Batch 16/64 loss: 2.1598896980285645
Batch 17/64 loss: 2.167367458343506
Batch 18/64 loss: 2.1887083053588867
Batch 19/64 loss: 2.081127643585205
Batch 20/64 loss: 2.077810525894165
Batch 21/64 loss: 2.2130210399627686
Batch 22/64 loss: 2.074948310852051
Batch 23/64 loss: 2.2211122512817383
Batch 24/64 loss: 2.1101787090301514
Batch 25/64 loss: 2.1896071434020996
Batch 26/64 loss: 2.153414726257324
Batch 27/64 loss: 2.09993839263916
Batch 28/64 loss: 2.0958080291748047
Batch 29/64 loss: 2.1148085594177246
Batch 30/64 loss: 2.1691951751708984
Batch 31/64 loss: 2.0749149322509766
Batch 32/64 loss: 2.0957913398742676
Batch 33/64 loss: 2.087512254714966
Batch 34/64 loss: 2.0626027584075928
Batch 35/64 loss: 2.1765408515930176
Batch 36/64 loss: 2.128261089324951
Batch 37/64 loss: 2.0954084396362305
Batch 38/64 loss: 2.0670924186706543
Batch 39/64 loss: 2.1050992012023926
Batch 40/64 loss: 2.0674757957458496
Batch 41/64 loss: 2.0331807136535645
Batch 42/64 loss: 2.0877251625061035
Batch 43/64 loss: 2.08919620513916
Batch 44/64 loss: 2.158040761947632
Batch 45/64 loss: 2.0602986812591553
Batch 46/64 loss: 2.0520198345184326
Batch 47/64 loss: 2.119107246398926
Batch 48/64 loss: 2.1091878414154053
Batch 49/64 loss: 2.0530314445495605
Batch 50/64 loss: 2.044477939605713
Batch 51/64 loss: 2.092851161956787
Batch 52/64 loss: 2.048825740814209
Batch 53/64 loss: 2.057340621948242
Batch 54/64 loss: 2.093580722808838
Batch 55/64 loss: 2.0752904415130615
Batch 56/64 loss: 2.019583225250244
Batch 57/64 loss: 2.0078558921813965
Batch 58/64 loss: 2.0775914192199707
Batch 59/64 loss: 2.0119690895080566
Batch 60/64 loss: 2.077725648880005
Batch 61/64 loss: 2.0866174697875977
Batch 62/64 loss: 2.055941104888916
Batch 63/64 loss: 2.013345241546631
Batch 64/64 loss: 2.262937068939209
Epoch 2  Train loss: 2.1198797394247615  Val loss: 2.094828089487921
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 2.104679822921753
Batch 2/64 loss: 2.124199390411377
Batch 3/64 loss: 2.082463264465332
Batch 4/64 loss: 2.044468641281128
Batch 5/64 loss: 1.99568510055542
Batch 6/64 loss: 2.093682289123535
Batch 7/64 loss: 2.009594440460205
Batch 8/64 loss: 2.056675672531128
Batch 9/64 loss: 2.038977861404419
Batch 10/64 loss: 2.1382291316986084
Batch 11/64 loss: 2.036604166030884
Batch 12/64 loss: 2.0248875617980957
Batch 13/64 loss: 2.0408270359039307
Batch 14/64 loss: 2.059128761291504
Batch 15/64 loss: 2.0490915775299072
Batch 16/64 loss: 2.044254779815674
Batch 17/64 loss: 2.071483850479126
Batch 18/64 loss: 2.0304369926452637
Batch 19/64 loss: 1.997584342956543
Batch 20/64 loss: 2.065225124359131
Batch 21/64 loss: 2.0282437801361084
Batch 22/64 loss: 2.0758309364318848
Batch 23/64 loss: 1.9869341850280762
Batch 24/64 loss: 1.980358362197876
Batch 25/64 loss: 2.0760083198547363
Batch 26/64 loss: 2.009749174118042
Batch 27/64 loss: 1.9986485242843628
Batch 28/64 loss: 2.094935417175293
Batch 29/64 loss: 2.0345494747161865
Batch 30/64 loss: 1.9911426305770874
Batch 31/64 loss: 2.07131290435791
Batch 32/64 loss: 2.0551371574401855
Batch 33/64 loss: 1.9494683742523193
Batch 34/64 loss: 2.0102553367614746
Batch 35/64 loss: 2.164173126220703
Batch 36/64 loss: 1.993788719177246
Batch 37/64 loss: 1.9812085628509521
Batch 38/64 loss: 2.0261881351470947
Batch 39/64 loss: 1.987565279006958
Batch 40/64 loss: 2.0045418739318848
Batch 41/64 loss: 2.0538978576660156
Batch 42/64 loss: 1.9793272018432617
Batch 43/64 loss: 2.0027949810028076
Batch 44/64 loss: 1.9960048198699951
Batch 45/64 loss: 2.018542528152466
Batch 46/64 loss: 1.9749774932861328
Batch 47/64 loss: 1.9485737085342407
Batch 48/64 loss: 2.006152391433716
Batch 49/64 loss: 2.0341222286224365
Batch 50/64 loss: 2.063526153564453
Batch 51/64 loss: 2.0246052742004395
Batch 52/64 loss: 2.016152858734131
Batch 53/64 loss: 1.9639722108840942
Batch 54/64 loss: 2.015058994293213
Batch 55/64 loss: 1.972719430923462
Batch 56/64 loss: 2.021172046661377
Batch 57/64 loss: 1.9961642026901245
Batch 58/64 loss: 1.9993607997894287
Batch 59/64 loss: 1.9400142431259155
Batch 60/64 loss: 1.9998842477798462
Batch 61/64 loss: 1.9541897773742676
Batch 62/64 loss: 1.9712594747543335
Batch 63/64 loss: 2.0805416107177734
Batch 64/64 loss: 2.289154529571533
Epoch 3  Train loss: 2.0294604002260694  Val loss: 2.1655844740851227
Epoch 4
-------------------------------
Batch 1/64 loss: 2.0172486305236816
Batch 2/64 loss: 2.1279845237731934
Batch 3/64 loss: 2.026169538497925
Batch 4/64 loss: 2.00799298286438
Batch 5/64 loss: 2.0164103507995605
Batch 6/64 loss: 2.025723457336426
Batch 7/64 loss: 2.005098819732666
Batch 8/64 loss: 2.007516384124756
Batch 9/64 loss: 1.9812748432159424
Batch 10/64 loss: 1.9950463771820068
Batch 11/64 loss: 2.019937038421631
Batch 12/64 loss: 1.9575517177581787
Batch 13/64 loss: 1.9854322671890259
Batch 14/64 loss: 1.9519339799880981
Batch 15/64 loss: 1.9956550598144531
Batch 16/64 loss: 1.9840037822723389
Batch 17/64 loss: 2.012282609939575
Batch 18/64 loss: 2.0033962726593018
Batch 19/64 loss: 2.0161020755767822
Batch 20/64 loss: 1.9712876081466675
Batch 21/64 loss: 2.048492193222046
Batch 22/64 loss: 2.0032224655151367
Batch 23/64 loss: 2.000652551651001
Batch 24/64 loss: 1.9769362211227417
Batch 25/64 loss: 1.9554775953292847
Batch 26/64 loss: 1.9852867126464844
Batch 27/64 loss: 2.031099796295166
Batch 28/64 loss: 1.972738265991211
Batch 29/64 loss: 1.9565157890319824
Batch 30/64 loss: 2.013197898864746
Batch 31/64 loss: 2.027160406112671
Batch 32/64 loss: 1.9683961868286133
Batch 33/64 loss: 1.9926950931549072
Batch 34/64 loss: 1.9878184795379639
Batch 35/64 loss: 1.9425129890441895
Batch 36/64 loss: 1.944247841835022
Batch 37/64 loss: 1.9637058973312378
Batch 38/64 loss: 1.9620914459228516
Batch 39/64 loss: 1.9879894256591797
Batch 40/64 loss: 1.947303295135498
Batch 41/64 loss: 1.9458914995193481
Batch 42/64 loss: 1.971897840499878
Batch 43/64 loss: 2.0113019943237305
Batch 44/64 loss: 2.029855489730835
Batch 45/64 loss: 1.9998104572296143
Batch 46/64 loss: 1.9558629989624023
Batch 47/64 loss: 2.043360710144043
Batch 48/64 loss: 1.9430224895477295
Batch 49/64 loss: 1.910474419593811
Batch 50/64 loss: 1.9966906309127808
Batch 51/64 loss: 1.9366257190704346
Batch 52/64 loss: 1.919173240661621
Batch 53/64 loss: 1.9357911348342896
Batch 54/64 loss: 1.9592232704162598
Batch 55/64 loss: 1.9868113994598389
Batch 56/64 loss: 1.945866584777832
Batch 57/64 loss: 1.9917244911193848
Batch 58/64 loss: 1.9375131130218506
Batch 59/64 loss: 1.937415599822998
Batch 60/64 loss: 1.933885097503662
Batch 61/64 loss: 1.9855475425720215
Batch 62/64 loss: 1.9589455127716064
Batch 63/64 loss: 1.946955680847168
Batch 64/64 loss: 2.160651445388794
Epoch 4  Train loss: 1.9855643038656197  Val loss: 1.9710396458602852
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 1.9656530618667603
Batch 2/64 loss: 1.9521583318710327
Batch 3/64 loss: 1.8961153030395508
Batch 4/64 loss: 1.9342896938323975
Batch 5/64 loss: 1.9523587226867676
Batch 6/64 loss: 1.9476217031478882
Batch 7/64 loss: 1.9488439559936523
Batch 8/64 loss: 1.9468796253204346
Batch 9/64 loss: 1.9479690790176392
Batch 10/64 loss: 1.9568315744400024
Batch 11/64 loss: 1.8988268375396729
Batch 12/64 loss: 1.9392907619476318
Batch 13/64 loss: 1.9083771705627441
Batch 14/64 loss: 1.9022588729858398
Batch 15/64 loss: 1.9094487428665161
Batch 16/64 loss: 1.9736120700836182
Batch 17/64 loss: 1.913306713104248
Batch 18/64 loss: 1.8929128646850586
Batch 19/64 loss: 1.9303594827651978
Batch 20/64 loss: 1.927262783050537
Batch 21/64 loss: 1.929219126701355
Batch 22/64 loss: 1.955145001411438
Batch 23/64 loss: 1.8928005695343018
Batch 24/64 loss: 1.9530390501022339
Batch 25/64 loss: 1.9290047883987427
Batch 26/64 loss: 1.9363116025924683
Batch 27/64 loss: 1.9146981239318848
Batch 28/64 loss: 1.8989455699920654
Batch 29/64 loss: 1.9314730167388916
Batch 30/64 loss: 1.8808887004852295
Batch 31/64 loss: 1.9084808826446533
Batch 32/64 loss: 1.893568992614746
Batch 33/64 loss: 1.9815514087677002
Batch 34/64 loss: 1.897589921951294
Batch 35/64 loss: 2.016237258911133
Batch 36/64 loss: 1.9074954986572266
Batch 37/64 loss: 1.954188346862793
Batch 38/64 loss: 1.9212814569473267
Batch 39/64 loss: 1.9350296258926392
Batch 40/64 loss: 1.9304715394973755
Batch 41/64 loss: 1.9212913513183594
Batch 42/64 loss: 1.9235683679580688
Batch 43/64 loss: 1.9042445421218872
Batch 44/64 loss: 1.903986930847168
Batch 45/64 loss: 1.9080302715301514
Batch 46/64 loss: 1.942399263381958
Batch 47/64 loss: 1.8961234092712402
Batch 48/64 loss: 1.8908023834228516
Batch 49/64 loss: 1.9362939596176147
Batch 50/64 loss: 1.9028217792510986
Batch 51/64 loss: 1.9518530368804932
Batch 52/64 loss: 1.9004552364349365
Batch 53/64 loss: 1.915779709815979
Batch 54/64 loss: 1.9037933349609375
Batch 55/64 loss: 1.888140320777893
Batch 56/64 loss: 1.879106044769287
Batch 57/64 loss: 1.8626848459243774
Batch 58/64 loss: 1.882714033126831
Batch 59/64 loss: 1.9474133253097534
Batch 60/64 loss: 1.9169317483901978
Batch 61/64 loss: 1.8995273113250732
Batch 62/64 loss: 1.9114515781402588
Batch 63/64 loss: 1.881121039390564
Batch 64/64 loss: 2.248337745666504
Epoch 5  Train loss: 1.9257817249672085  Val loss: 1.9616605342458613
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 1.9385558366775513
Batch 2/64 loss: 1.9288958311080933
Batch 3/64 loss: 1.920088291168213
Batch 4/64 loss: 1.916605830192566
Batch 5/64 loss: 1.8842964172363281
Batch 6/64 loss: 1.8864636421203613
Batch 7/64 loss: 1.8812252283096313
Batch 8/64 loss: 1.9206132888793945
Batch 9/64 loss: 1.8744215965270996
Batch 10/64 loss: 1.886122226715088
Batch 11/64 loss: 1.8650275468826294
Batch 12/64 loss: 1.909467339515686
Batch 13/64 loss: 1.876242995262146
Batch 14/64 loss: 1.872924566268921
Batch 15/64 loss: 1.908791422843933
Batch 16/64 loss: 1.8756567239761353
Batch 17/64 loss: 1.8747291564941406
Batch 18/64 loss: 1.906355619430542
Batch 19/64 loss: 1.8884836435317993
Batch 20/64 loss: 1.8779082298278809
Batch 21/64 loss: 1.8822543621063232
Batch 22/64 loss: 1.936829924583435
Batch 23/64 loss: 1.893986463546753
Batch 24/64 loss: 1.914390206336975
Batch 25/64 loss: 1.922147274017334
Batch 26/64 loss: 1.9230648279190063
Batch 27/64 loss: 1.8849403858184814
Batch 28/64 loss: 1.897446870803833
Batch 29/64 loss: 1.8811516761779785
Batch 30/64 loss: 2.0274791717529297
Batch 31/64 loss: 1.8923228979110718
Batch 32/64 loss: 2.101766586303711
Batch 33/64 loss: 1.9396109580993652
Batch 34/64 loss: 2.2587170600891113
Batch 35/64 loss: 2.015639305114746
Batch 36/64 loss: 1.9721086025238037
Batch 37/64 loss: 1.966912031173706
Batch 38/64 loss: 1.949012041091919
Batch 39/64 loss: 1.9371047019958496
Batch 40/64 loss: 2.037344455718994
Batch 41/64 loss: 2.030430316925049
Batch 42/64 loss: 1.9773108959197998
Batch 43/64 loss: 1.9622772932052612
Batch 44/64 loss: 2.1010823249816895
Batch 45/64 loss: 2.009500503540039
Batch 46/64 loss: 2.049522638320923
Batch 47/64 loss: 1.9883999824523926
Batch 48/64 loss: 1.9851511716842651
Batch 49/64 loss: 2.0045385360717773
Batch 50/64 loss: 1.9726722240447998
Batch 51/64 loss: 1.9559662342071533
Batch 52/64 loss: 2.043180227279663
Batch 53/64 loss: 1.9958674907684326
Batch 54/64 loss: 1.9640436172485352
Batch 55/64 loss: 1.9578297138214111
Batch 56/64 loss: 1.9276061058044434
Batch 57/64 loss: 1.969818115234375
Batch 58/64 loss: 1.995351791381836
Batch 59/64 loss: 1.9415028095245361
Batch 60/64 loss: 1.9167207479476929
Batch 61/64 loss: 1.9539275169372559
Batch 62/64 loss: 1.939859390258789
Batch 63/64 loss: 1.9251810312271118
Batch 64/64 loss: 2.19118332862854
Epoch 6  Train loss: 1.9504036613539153  Val loss: 2.2842075226642833
Epoch 7
-------------------------------
Batch 1/64 loss: 1.9391570091247559
Batch 2/64 loss: 1.9074819087982178
Batch 3/64 loss: 1.9079866409301758
Batch 4/64 loss: 1.9011881351470947
Batch 5/64 loss: 1.8956528902053833
Batch 6/64 loss: 1.906200885772705
Batch 7/64 loss: 1.911342740058899
Batch 8/64 loss: 1.8938050270080566
Batch 9/64 loss: 1.8797271251678467
Batch 10/64 loss: 1.9508123397827148
Batch 11/64 loss: 1.9857397079467773
Batch 12/64 loss: 1.923645257949829
Batch 13/64 loss: 1.8687206506729126
Batch 14/64 loss: 1.8862767219543457
Batch 15/64 loss: 1.9214262962341309
Batch 16/64 loss: 1.903300404548645
Batch 17/64 loss: 1.872398853302002
Batch 18/64 loss: 1.9099143743515015
Batch 19/64 loss: 1.9400348663330078
Batch 20/64 loss: 1.918816089630127
Batch 21/64 loss: 1.892141580581665
Batch 22/64 loss: 1.9424598217010498
Batch 23/64 loss: 1.8825856447219849
Batch 24/64 loss: 1.8832329511642456
Batch 25/64 loss: 1.899266004562378
Batch 26/64 loss: 1.8712687492370605
Batch 27/64 loss: 1.8903883695602417
Batch 28/64 loss: 1.887300729751587
Batch 29/64 loss: 1.8853068351745605
Batch 30/64 loss: 1.8843061923980713
Batch 31/64 loss: 1.87485933303833
Batch 32/64 loss: 1.8767489194869995
Batch 33/64 loss: 1.8819305896759033
Batch 34/64 loss: 1.865041971206665
Batch 35/64 loss: 1.8620067834854126
Batch 36/64 loss: 1.934208869934082
Batch 37/64 loss: 1.8758819103240967
Batch 38/64 loss: 1.8888521194458008
Batch 39/64 loss: 1.8688796758651733
Batch 40/64 loss: 1.8743531703948975
Batch 41/64 loss: 1.8775596618652344
Batch 42/64 loss: 1.8958450555801392
Batch 43/64 loss: 1.9364852905273438
Batch 44/64 loss: 1.8671810626983643
Batch 45/64 loss: 1.8681130409240723
Batch 46/64 loss: 1.8831112384796143
Batch 47/64 loss: 1.8624459505081177
Batch 48/64 loss: 1.8820639848709106
Batch 49/64 loss: 1.8573590517044067
Batch 50/64 loss: 1.9131982326507568
Batch 51/64 loss: 1.889393925666809
Batch 52/64 loss: 1.8649485111236572
Batch 53/64 loss: 1.8672826290130615
Batch 54/64 loss: 1.9093711376190186
Batch 55/64 loss: 1.8582139015197754
Batch 56/64 loss: 1.8795863389968872
Batch 57/64 loss: 1.8518104553222656
Batch 58/64 loss: 1.867280125617981
Batch 59/64 loss: 1.893855333328247
Batch 60/64 loss: 1.850895643234253
Batch 61/64 loss: 1.8693645000457764
Batch 62/64 loss: 1.8714449405670166
Batch 63/64 loss: 2.034547805786133
Batch 64/64 loss: 2.0992226600646973
Epoch 7  Train loss: 1.8960066346561208  Val loss: 1.9255586440620553
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 1.8729310035705566
Batch 2/64 loss: 1.8811683654785156
Batch 3/64 loss: 1.8665342330932617
Batch 4/64 loss: 1.8709336519241333
Batch 5/64 loss: 1.9001386165618896
Batch 6/64 loss: 1.8621611595153809
Batch 7/64 loss: 1.8416855335235596
Batch 8/64 loss: 1.8597636222839355
Batch 9/64 loss: 1.8527261018753052
Batch 10/64 loss: 1.885003685951233
Batch 11/64 loss: 1.8884042501449585
Batch 12/64 loss: 1.8670217990875244
Batch 13/64 loss: 1.8669066429138184
Batch 14/64 loss: 1.8529808521270752
Batch 15/64 loss: 1.8826364278793335
Batch 16/64 loss: 1.8541674613952637
Batch 17/64 loss: 1.8599393367767334
Batch 18/64 loss: 1.8583800792694092
Batch 19/64 loss: 1.8892827033996582
Batch 20/64 loss: 1.8628953695297241
Batch 21/64 loss: 1.8674731254577637
Batch 22/64 loss: 1.8451199531555176
Batch 23/64 loss: 1.868520736694336
Batch 24/64 loss: 1.8519608974456787
Batch 25/64 loss: 1.8753094673156738
Batch 26/64 loss: 1.8980518579483032
Batch 27/64 loss: 1.8606178760528564
Batch 28/64 loss: 1.8589372634887695
Batch 29/64 loss: 1.8553228378295898
Batch 30/64 loss: 1.8529853820800781
Batch 31/64 loss: 1.869284987449646
Batch 32/64 loss: 1.84873628616333
Batch 33/64 loss: 1.8494956493377686
Batch 34/64 loss: 1.8467867374420166
Batch 35/64 loss: 1.8613940477371216
Batch 36/64 loss: 1.8669517040252686
Batch 37/64 loss: 1.8793972730636597
Batch 38/64 loss: 1.859859824180603
Batch 39/64 loss: 1.8563117980957031
Batch 40/64 loss: 1.8540576696395874
Batch 41/64 loss: 1.8477592468261719
Batch 42/64 loss: 1.8574533462524414
Batch 43/64 loss: 1.8517875671386719
Batch 44/64 loss: 1.872362732887268
Batch 45/64 loss: 1.8646146059036255
Batch 46/64 loss: 1.8390151262283325
Batch 47/64 loss: 1.875966191291809
Batch 48/64 loss: 1.8316335678100586
Batch 49/64 loss: 1.8434590101242065
Batch 50/64 loss: 1.8512566089630127
Batch 51/64 loss: 1.878320574760437
Batch 52/64 loss: 1.8492448329925537
Batch 53/64 loss: 1.8580989837646484
Batch 54/64 loss: 1.8565608263015747
Batch 55/64 loss: 1.8627691268920898
Batch 56/64 loss: 1.8598735332489014
Batch 57/64 loss: 1.8386975526809692
Batch 58/64 loss: 1.8518503904342651
Batch 59/64 loss: 1.848741888999939
Batch 60/64 loss: 1.8329956531524658
Batch 61/64 loss: 1.8865633010864258
Batch 62/64 loss: 1.8603624105453491
Batch 63/64 loss: 1.8694924116134644
Batch 64/64 loss: 2.078601360321045
Epoch 8  Train loss: 1.8643147730359844  Val loss: 1.8747278546139956
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 1.8607219457626343
Batch 2/64 loss: 1.8515955209732056
Batch 3/64 loss: 1.8505128622055054
Batch 4/64 loss: 1.8444128036499023
Batch 5/64 loss: 1.837813377380371
Batch 6/64 loss: 1.8448582887649536
Batch 7/64 loss: 1.8418560028076172
Batch 8/64 loss: 1.8572059869766235
Batch 9/64 loss: 1.85028076171875
Batch 10/64 loss: 1.8681483268737793
Batch 11/64 loss: 1.8311994075775146
Batch 12/64 loss: 1.8497393131256104
Batch 13/64 loss: 1.8393336534500122
Batch 14/64 loss: 1.837547779083252
Batch 15/64 loss: 1.8346898555755615
Batch 16/64 loss: 1.8399659395217896
Batch 17/64 loss: 1.8506031036376953
Batch 18/64 loss: 1.8424384593963623
Batch 19/64 loss: 1.8594062328338623
Batch 20/64 loss: 1.842826008796692
Batch 21/64 loss: 1.8395060300827026
Batch 22/64 loss: 1.8464224338531494
Batch 23/64 loss: 1.8423333168029785
Batch 24/64 loss: 1.840501070022583
Batch 25/64 loss: 1.8800427913665771
Batch 26/64 loss: 1.8599742650985718
Batch 27/64 loss: 1.8361730575561523
Batch 28/64 loss: 1.8801870346069336
Batch 29/64 loss: 1.8548798561096191
Batch 30/64 loss: 1.8874011039733887
Batch 31/64 loss: 1.8648582696914673
Batch 32/64 loss: 1.848508596420288
Batch 33/64 loss: 1.8509438037872314
Batch 34/64 loss: 1.8374290466308594
Batch 35/64 loss: 1.859496831893921
Batch 36/64 loss: 1.84292733669281
Batch 37/64 loss: 1.8521647453308105
Batch 38/64 loss: 1.8396916389465332
Batch 39/64 loss: 1.8545851707458496
Batch 40/64 loss: 1.8534427881240845
Batch 41/64 loss: 1.8372290134429932
Batch 42/64 loss: 1.8447294235229492
Batch 43/64 loss: 1.8466687202453613
Batch 44/64 loss: 1.8481698036193848
Batch 45/64 loss: 1.8459453582763672
Batch 46/64 loss: 1.845566749572754
Batch 47/64 loss: 1.8645875453948975
Batch 48/64 loss: 1.8340981006622314
Batch 49/64 loss: 1.8543928861618042
Batch 50/64 loss: 1.847785234451294
Batch 51/64 loss: 1.850572943687439
Batch 52/64 loss: 1.8324476480484009
Batch 53/64 loss: 1.8348493576049805
Batch 54/64 loss: 1.834190845489502
Batch 55/64 loss: 1.8621870279312134
Batch 56/64 loss: 1.832898736000061
Batch 57/64 loss: 1.848142385482788
Batch 58/64 loss: 1.8424830436706543
Batch 59/64 loss: 1.8832234144210815
Batch 60/64 loss: 1.8469700813293457
Batch 61/64 loss: 1.8471451997756958
Batch 62/64 loss: 1.8454768657684326
Batch 63/64 loss: 1.8419053554534912
Batch 64/64 loss: 2.085970163345337
Epoch 9  Train loss: 1.8516512655744366  Val loss: 1.8801039215625357
Epoch 10
-------------------------------
Batch 1/64 loss: 1.835892677307129
Batch 2/64 loss: 1.8615145683288574
Batch 3/64 loss: 1.8469738960266113
Batch 4/64 loss: 1.8415648937225342
Batch 5/64 loss: 1.8761937618255615
Batch 6/64 loss: 1.8562102317810059
Batch 7/64 loss: 1.8314529657363892
Batch 8/64 loss: 1.8361897468566895
Batch 9/64 loss: 1.845310926437378
Batch 10/64 loss: 1.8440378904342651
Batch 11/64 loss: 1.8374781608581543
Batch 12/64 loss: 1.839331030845642
Batch 13/64 loss: 1.8664863109588623
Batch 14/64 loss: 1.8385589122772217
Batch 15/64 loss: 1.8375681638717651
Batch 16/64 loss: 1.8682715892791748
Batch 17/64 loss: 1.8370959758758545
Batch 18/64 loss: 1.829623818397522
Batch 19/64 loss: 1.833266258239746
Batch 20/64 loss: 1.836898684501648
Batch 21/64 loss: 1.8436847925186157
Batch 22/64 loss: 1.8401931524276733
Batch 23/64 loss: 1.836609125137329
Batch 24/64 loss: 1.8318102359771729
Batch 25/64 loss: 1.9094122648239136
Batch 26/64 loss: 1.8379855155944824
Batch 27/64 loss: 1.8410500288009644
Batch 28/64 loss: 1.8491929769515991
Batch 29/64 loss: 1.8313499689102173
Batch 30/64 loss: 1.842281460762024
Batch 31/64 loss: 1.8620824813842773
Batch 32/64 loss: 1.846770167350769
Batch 33/64 loss: 1.864111065864563
Batch 34/64 loss: 1.8508458137512207
Batch 35/64 loss: 1.8560783863067627
Batch 36/64 loss: 1.8379617929458618
Batch 37/64 loss: 1.851027250289917
Batch 38/64 loss: 1.854306936264038
Batch 39/64 loss: 1.8640007972717285
Batch 40/64 loss: 1.8302717208862305
Batch 41/64 loss: 1.8623729944229126
Batch 42/64 loss: 1.8450945615768433
Batch 43/64 loss: 1.8611984252929688
Batch 44/64 loss: 1.8657593727111816
Batch 45/64 loss: 1.8838456869125366
Batch 46/64 loss: 1.8536633253097534
Batch 47/64 loss: 1.8863627910614014
Batch 48/64 loss: 1.8418211936950684
Batch 49/64 loss: 1.8675167560577393
Batch 50/64 loss: 1.84275221824646
Batch 51/64 loss: 1.8635673522949219
Batch 52/64 loss: 1.8461246490478516
Batch 53/64 loss: 1.8377764225006104
Batch 54/64 loss: 1.8533002138137817
Batch 55/64 loss: 1.8400993347167969
Batch 56/64 loss: 1.8393335342407227
Batch 57/64 loss: 1.8291690349578857
Batch 58/64 loss: 1.839483380317688
Batch 59/64 loss: 1.8390926122665405
Batch 60/64 loss: 1.8400481939315796
Batch 61/64 loss: 1.8372423648834229
Batch 62/64 loss: 1.881575107574463
Batch 63/64 loss: 1.8403496742248535
Batch 64/64 loss: 2.111917495727539
Epoch 10  Train loss: 1.8519597446217257  Val loss: 1.9109908682374201
Epoch 11
-------------------------------
Batch 1/64 loss: 1.8412868976593018
Batch 2/64 loss: 1.8380241394042969
Batch 3/64 loss: 1.8459984064102173
Batch 4/64 loss: 1.8654906749725342
Batch 5/64 loss: 1.8439114093780518
Batch 6/64 loss: 1.8385993242263794
Batch 7/64 loss: 1.8548753261566162
Batch 8/64 loss: 1.878934621810913
Batch 9/64 loss: 1.8597874641418457
Batch 10/64 loss: 1.8316116333007812
Batch 11/64 loss: 1.8475816249847412
Batch 12/64 loss: 1.8499386310577393
Batch 13/64 loss: 1.8693530559539795
Batch 14/64 loss: 1.8457937240600586
Batch 15/64 loss: 1.8660857677459717
Batch 16/64 loss: 1.8415193557739258
Batch 17/64 loss: 1.8497397899627686
Batch 18/64 loss: 1.8514245748519897
Batch 19/64 loss: 1.852946400642395
Batch 20/64 loss: 1.8614275455474854
Batch 21/64 loss: 1.8433908224105835
Batch 22/64 loss: 1.8289282321929932
Batch 23/64 loss: 1.8585500717163086
Batch 24/64 loss: 1.8846986293792725
Batch 25/64 loss: 1.872842788696289
Batch 26/64 loss: 1.8494081497192383
Batch 27/64 loss: 1.8587677478790283
Batch 28/64 loss: 1.851027250289917
Batch 29/64 loss: 1.8375823497772217
Batch 30/64 loss: 1.8755810260772705
Batch 31/64 loss: 1.8496298789978027
Batch 32/64 loss: 1.8400046825408936
Batch 33/64 loss: 1.8649183511734009
Batch 34/64 loss: 1.8455278873443604
Batch 35/64 loss: 1.8408241271972656
Batch 36/64 loss: 1.8639552593231201
Batch 37/64 loss: 1.8634848594665527
Batch 38/64 loss: 1.8531570434570312
Batch 39/64 loss: 1.836398720741272
Batch 40/64 loss: 1.8419528007507324
Batch 41/64 loss: 1.8517147302627563
Batch 42/64 loss: 1.8417720794677734
Batch 43/64 loss: 1.8357999324798584
Batch 44/64 loss: 1.830789566040039
Batch 45/64 loss: 1.8514653444290161
Batch 46/64 loss: 1.8500473499298096
Batch 47/64 loss: 1.8270843029022217
Batch 48/64 loss: 1.8335453271865845
Batch 49/64 loss: 1.840682864189148
Batch 50/64 loss: 1.8391306400299072
Batch 51/64 loss: 1.8393422365188599
Batch 52/64 loss: 1.838470458984375
Batch 53/64 loss: 1.8445545434951782
Batch 54/64 loss: 1.8332760334014893
Batch 55/64 loss: 1.8395944833755493
Batch 56/64 loss: 1.8208085298538208
Batch 57/64 loss: 1.8283964395523071
Batch 58/64 loss: 1.8312311172485352
Batch 59/64 loss: 1.8265864849090576
Batch 60/64 loss: 1.8248944282531738
Batch 61/64 loss: 1.8387362957000732
Batch 62/64 loss: 1.8245025873184204
Batch 63/64 loss: 1.8553487062454224
Batch 64/64 loss: 2.071871757507324
Epoch 11  Train loss: 1.849359048581591  Val loss: 1.8788867676790637
Epoch 12
-------------------------------
Batch 1/64 loss: 1.828994631767273
Batch 2/64 loss: 1.8375405073165894
Batch 3/64 loss: 1.8451533317565918
Batch 4/64 loss: 1.8267945051193237
Batch 5/64 loss: 1.8278998136520386
Batch 6/64 loss: 1.8334370851516724
Batch 7/64 loss: 1.830727219581604
Batch 8/64 loss: 1.8251581192016602
Batch 9/64 loss: 1.8688929080963135
Batch 10/64 loss: 1.8190052509307861
Batch 11/64 loss: 1.8403892517089844
Batch 12/64 loss: 1.8297886848449707
Batch 13/64 loss: 1.8287184238433838
Batch 14/64 loss: 1.838261604309082
Batch 15/64 loss: 1.8352566957473755
Batch 16/64 loss: 1.8264540433883667
Batch 17/64 loss: 1.8447585105895996
Batch 18/64 loss: 1.8396687507629395
Batch 19/64 loss: 1.8507506847381592
Batch 20/64 loss: 1.84438157081604
Batch 21/64 loss: 1.8366186618804932
Batch 22/64 loss: 1.8365681171417236
Batch 23/64 loss: 1.8268871307373047
Batch 24/64 loss: 1.8314710855484009
Batch 25/64 loss: 1.8200461864471436
Batch 26/64 loss: 1.8320441246032715
Batch 27/64 loss: 1.8321642875671387
Batch 28/64 loss: 1.835938572883606
Batch 29/64 loss: 1.8244913816452026
Batch 30/64 loss: 1.8407434225082397
Batch 31/64 loss: 1.8325697183609009
Batch 32/64 loss: 1.8252573013305664
Batch 33/64 loss: 1.8337483406066895
Batch 34/64 loss: 1.828657627105713
Batch 35/64 loss: 1.8341237306594849
Batch 36/64 loss: 1.8284964561462402
Batch 37/64 loss: 1.8374834060668945
Batch 38/64 loss: 1.8304208517074585
Batch 39/64 loss: 1.8327302932739258
Batch 40/64 loss: 1.8399888277053833
Batch 41/64 loss: 1.8785831928253174
Batch 42/64 loss: 1.8186885118484497
Batch 43/64 loss: 1.8327100276947021
Batch 44/64 loss: 1.8273658752441406
Batch 45/64 loss: 1.871291995048523
Batch 46/64 loss: 1.8300621509552002
Batch 47/64 loss: 1.8415982723236084
Batch 48/64 loss: 1.8508630990982056
Batch 49/64 loss: 1.8700083494186401
Batch 50/64 loss: 1.8293757438659668
Batch 51/64 loss: 1.8414106369018555
Batch 52/64 loss: 1.84095299243927
Batch 53/64 loss: 1.844801664352417
Batch 54/64 loss: 1.8416376113891602
Batch 55/64 loss: 1.855283498764038
Batch 56/64 loss: 1.8305463790893555
Batch 57/64 loss: 1.832996129989624
Batch 58/64 loss: 1.8340145349502563
Batch 59/64 loss: 1.8588584661483765
Batch 60/64 loss: 1.8397728204727173
Batch 61/64 loss: 1.831062912940979
Batch 62/64 loss: 1.829973816871643
Batch 63/64 loss: 1.818828821182251
Batch 64/64 loss: 2.0703952312469482
Epoch 12  Train loss: 1.8394661183450736  Val loss: 1.9012126431022722
Epoch 13
-------------------------------
Batch 1/64 loss: 1.8386785984039307
Batch 2/64 loss: 1.838653564453125
Batch 3/64 loss: 1.8277109861373901
Batch 4/64 loss: 1.8604750633239746
Batch 5/64 loss: 1.8323664665222168
Batch 6/64 loss: 1.832721471786499
Batch 7/64 loss: 1.8342320919036865
Batch 8/64 loss: 1.8320138454437256
Batch 9/64 loss: 1.8341273069381714
Batch 10/64 loss: 1.8225207328796387
Batch 11/64 loss: 1.8297878503799438
Batch 12/64 loss: 1.826903223991394
Batch 13/64 loss: 1.8269975185394287
Batch 14/64 loss: 1.8321590423583984
Batch 15/64 loss: 1.8345508575439453
Batch 16/64 loss: 1.8337085247039795
Batch 17/64 loss: 1.8538272380828857
Batch 18/64 loss: 1.8242909908294678
Batch 19/64 loss: 1.8283568620681763
Batch 20/64 loss: 1.8300399780273438
Batch 21/64 loss: 1.8389242887496948
Batch 22/64 loss: 1.8227956295013428
Batch 23/64 loss: 1.8195631504058838
Batch 24/64 loss: 1.8343994617462158
Batch 25/64 loss: 1.8414764404296875
Batch 26/64 loss: 1.8387067317962646
Batch 27/64 loss: 1.8350772857666016
Batch 28/64 loss: 1.832438588142395
Batch 29/64 loss: 1.8355226516723633
Batch 30/64 loss: 1.838631510734558
Batch 31/64 loss: 1.8423106670379639
Batch 32/64 loss: 1.827531337738037
Batch 33/64 loss: 1.8375827074050903
Batch 34/64 loss: 1.8466882705688477
Batch 35/64 loss: 1.8314532041549683
Batch 36/64 loss: 1.8361496925354004
Batch 37/64 loss: 1.8221924304962158
Batch 38/64 loss: 1.8326631784439087
Batch 39/64 loss: 1.8647735118865967
Batch 40/64 loss: 1.8515859842300415
Batch 41/64 loss: 1.8453336954116821
Batch 42/64 loss: 1.8465774059295654
Batch 43/64 loss: 1.838088870048523
Batch 44/64 loss: 1.8533000946044922
Batch 45/64 loss: 1.8299996852874756
Batch 46/64 loss: 1.828545331954956
Batch 47/64 loss: 1.821887731552124
Batch 48/64 loss: 1.8256653547286987
Batch 49/64 loss: 1.831369400024414
Batch 50/64 loss: 1.832901954650879
Batch 51/64 loss: 1.8257739543914795
Batch 52/64 loss: 1.8239120244979858
Batch 53/64 loss: 1.8338159322738647
Batch 54/64 loss: 1.8341253995895386
Batch 55/64 loss: 1.8379141092300415
Batch 56/64 loss: 1.8351633548736572
Batch 57/64 loss: 1.8260858058929443
Batch 58/64 loss: 1.819875955581665
Batch 59/64 loss: 1.8416568040847778
Batch 60/64 loss: 1.8236854076385498
Batch 61/64 loss: 1.8188915252685547
Batch 62/64 loss: 1.8256324529647827
Batch 63/64 loss: 1.8371851444244385
Batch 64/64 loss: 2.068925142288208
Epoch 13  Train loss: 1.8367634539510689  Val loss: 1.8623706876617117
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: 1.8258562088012695
Batch 2/64 loss: 1.8273823261260986
Batch 3/64 loss: 1.8334161043167114
Batch 4/64 loss: 1.8212226629257202
Batch 5/64 loss: 1.8352882862091064
Batch 6/64 loss: 1.8259397745132446
Batch 7/64 loss: 1.8277158737182617
Batch 8/64 loss: 1.8280974626541138
Batch 9/64 loss: 1.8312668800354004
Batch 10/64 loss: 1.851161003112793
Batch 11/64 loss: 1.8230305910110474
Batch 12/64 loss: 1.8266388177871704
Batch 13/64 loss: 1.828754186630249
Batch 14/64 loss: 1.834718108177185
Batch 15/64 loss: 1.829179048538208
Batch 16/64 loss: 1.8245849609375
Batch 17/64 loss: 1.8273272514343262
Batch 18/64 loss: 1.8232239484786987
Batch 19/64 loss: 1.8301244974136353
Batch 20/64 loss: 1.82159423828125
Batch 21/64 loss: 1.8324365615844727
Batch 22/64 loss: 1.8383620977401733
Batch 23/64 loss: 1.8309855461120605
Batch 24/64 loss: 1.8566961288452148
Batch 25/64 loss: 1.836201786994934
Batch 26/64 loss: 1.8294641971588135
Batch 27/64 loss: 1.8331266641616821
Batch 28/64 loss: 1.8368268013000488
Batch 29/64 loss: 1.8232645988464355
Batch 30/64 loss: 1.834304928779602
Batch 31/64 loss: 1.8297398090362549
Batch 32/64 loss: 1.8513656854629517
Batch 33/64 loss: 1.8319352865219116
Batch 34/64 loss: 1.8281302452087402
Batch 35/64 loss: 1.8183073997497559
Batch 36/64 loss: 1.8332386016845703
Batch 37/64 loss: 1.8319981098175049
Batch 38/64 loss: 1.8350927829742432
Batch 39/64 loss: 1.8214468955993652
Batch 40/64 loss: 1.823868751525879
Batch 41/64 loss: 1.8285502195358276
Batch 42/64 loss: 1.8218387365341187
Batch 43/64 loss: 1.8281035423278809
Batch 44/64 loss: 1.8343771696090698
Batch 45/64 loss: 1.815010905265808
Batch 46/64 loss: 1.8152347803115845
Batch 47/64 loss: 1.826608657836914
Batch 48/64 loss: 1.8266364336013794
Batch 49/64 loss: 1.8196079730987549
Batch 50/64 loss: 1.8199126720428467
Batch 51/64 loss: 1.823716163635254
Batch 52/64 loss: 1.8153893947601318
Batch 53/64 loss: 1.8217445611953735
Batch 54/64 loss: 1.8334243297576904
Batch 55/64 loss: 1.8175160884857178
Batch 56/64 loss: 1.8233733177185059
Batch 57/64 loss: 1.8185604810714722
Batch 58/64 loss: 1.8241218328475952
Batch 59/64 loss: 1.820512056350708
Batch 60/64 loss: 1.8218348026275635
Batch 61/64 loss: 1.8125253915786743
Batch 62/64 loss: 1.8133950233459473
Batch 63/64 loss: 1.8212511539459229
Batch 64/64 loss: 2.0484912395477295
Epoch 14  Train loss: 1.8301635957231708  Val loss: 1.8568494246178067
Saving best model, epoch: 14
Epoch 15
-------------------------------
Batch 1/64 loss: 1.8323619365692139
Batch 2/64 loss: 1.8209648132324219
Batch 3/64 loss: 1.818233847618103
Batch 4/64 loss: 1.8302688598632812
Batch 5/64 loss: 1.8196299076080322
Batch 6/64 loss: 1.8221659660339355
Batch 7/64 loss: 1.848676323890686
Batch 8/64 loss: 1.8144667148590088
Batch 9/64 loss: 1.8205386400222778
Batch 10/64 loss: 1.8196823596954346
Batch 11/64 loss: 1.8259650468826294
Batch 12/64 loss: 1.813663125038147
Batch 13/64 loss: 1.8765714168548584
Batch 14/64 loss: 1.8349294662475586
Batch 15/64 loss: 1.8140161037445068
Batch 16/64 loss: 1.8240433931350708
Batch 17/64 loss: 1.8328890800476074
Batch 18/64 loss: 1.8357131481170654
Batch 19/64 loss: 1.826602816581726
Batch 20/64 loss: 1.8156535625457764
Batch 21/64 loss: 1.826667308807373
Batch 22/64 loss: 1.8336474895477295
Batch 23/64 loss: 1.815724492073059
Batch 24/64 loss: 1.8284969329833984
Batch 25/64 loss: 1.821424961090088
Batch 26/64 loss: 1.83134925365448
Batch 27/64 loss: 1.813549518585205
Batch 28/64 loss: 1.8637993335723877
Batch 29/64 loss: 1.8242943286895752
Batch 30/64 loss: 1.8214285373687744
Batch 31/64 loss: 1.8263038396835327
Batch 32/64 loss: 1.831318736076355
Batch 33/64 loss: 1.8191910982131958
Batch 34/64 loss: 1.818104863166809
Batch 35/64 loss: 1.8183947801589966
Batch 36/64 loss: 1.8242416381835938
Batch 37/64 loss: 1.8241119384765625
Batch 38/64 loss: 1.8442716598510742
Batch 39/64 loss: 1.8385446071624756
Batch 40/64 loss: 1.8218380212783813
Batch 41/64 loss: 1.8301293849945068
Batch 42/64 loss: 1.8333899974822998
Batch 43/64 loss: 1.8180869817733765
Batch 44/64 loss: 1.8350720405578613
Batch 45/64 loss: 1.8172065019607544
Batch 46/64 loss: 1.8339495658874512
Batch 47/64 loss: 1.8232839107513428
Batch 48/64 loss: 1.8242261409759521
Batch 49/64 loss: 1.8197929859161377
Batch 50/64 loss: 1.8349961042404175
Batch 51/64 loss: 1.810951590538025
Batch 52/64 loss: 1.8134064674377441
Batch 53/64 loss: 1.8244454860687256
Batch 54/64 loss: 1.8308824300765991
Batch 55/64 loss: 1.8273210525512695
Batch 56/64 loss: 1.8312746286392212
Batch 57/64 loss: 1.819548487663269
Batch 58/64 loss: 1.8282804489135742
Batch 59/64 loss: 1.8219791650772095
Batch 60/64 loss: 1.8302958011627197
Batch 61/64 loss: 1.814192295074463
Batch 62/64 loss: 1.8156837224960327
Batch 63/64 loss: 1.8280137777328491
Batch 64/64 loss: 2.0450496673583984
Epoch 15  Train loss: 1.828924487618839  Val loss: 1.851711942567858
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: 1.8099820613861084
Batch 2/64 loss: 1.812406301498413
Batch 3/64 loss: 1.8135044574737549
Batch 4/64 loss: 1.819631814956665
Batch 5/64 loss: 1.8230217695236206
Batch 6/64 loss: 1.8268685340881348
Batch 7/64 loss: 1.8154513835906982
Batch 8/64 loss: 1.8215056657791138
Batch 9/64 loss: 1.8200873136520386
Batch 10/64 loss: 1.8088953495025635
Batch 11/64 loss: 1.8154345750808716
Batch 12/64 loss: 1.8317465782165527
Batch 13/64 loss: 1.8216520547866821
Batch 14/64 loss: 1.8165191411972046
Batch 15/64 loss: 1.825995683670044
Batch 16/64 loss: 1.821846604347229
Batch 17/64 loss: 1.820549726486206
Batch 18/64 loss: 1.8191415071487427
Batch 19/64 loss: 1.8153159618377686
Batch 20/64 loss: 1.814944863319397
Batch 21/64 loss: 1.8275818824768066
Batch 22/64 loss: 1.869258999824524
Batch 23/64 loss: 1.8165706396102905
Batch 24/64 loss: 1.8192579746246338
Batch 25/64 loss: 1.821617841720581
Batch 26/64 loss: 1.821860432624817
Batch 27/64 loss: 1.8233798742294312
Batch 28/64 loss: 1.8137129545211792
Batch 29/64 loss: 1.816191554069519
Batch 30/64 loss: 1.8419160842895508
Batch 31/64 loss: 1.823311686515808
Batch 32/64 loss: 1.8200770616531372
Batch 33/64 loss: 1.8214631080627441
Batch 34/64 loss: 1.809900164604187
Batch 35/64 loss: 1.8683228492736816
Batch 36/64 loss: 1.8214377164840698
Batch 37/64 loss: 1.8209434747695923
Batch 38/64 loss: 1.8115413188934326
Batch 39/64 loss: 1.8248131275177002
Batch 40/64 loss: 1.812549352645874
Batch 41/64 loss: 1.8241287469863892
Batch 42/64 loss: 1.8169138431549072
Batch 43/64 loss: 1.8192846775054932
Batch 44/64 loss: 1.826030969619751
Batch 45/64 loss: 1.8196790218353271
Batch 46/64 loss: 1.8195254802703857
Batch 47/64 loss: 1.8288657665252686
Batch 48/64 loss: 1.8219451904296875
Batch 49/64 loss: 1.8269410133361816
Batch 50/64 loss: 1.8220385313034058
Batch 51/64 loss: 1.8266808986663818
Batch 52/64 loss: 1.8288999795913696
Batch 53/64 loss: 1.818517804145813
Batch 54/64 loss: 1.8492462635040283
Batch 55/64 loss: 1.828458309173584
Batch 56/64 loss: 1.827694058418274
Batch 57/64 loss: 1.825420618057251
Batch 58/64 loss: 1.8221759796142578
Batch 59/64 loss: 1.8164174556732178
Batch 60/64 loss: 1.8190339803695679
Batch 61/64 loss: 1.811314344406128
Batch 62/64 loss: 1.8219406604766846
Batch 63/64 loss: 1.8348989486694336
Batch 64/64 loss: 2.098524332046509
Epoch 16  Train loss: 1.8260416507720947  Val loss: 1.8528917310983455
Epoch 17
-------------------------------
Batch 1/64 loss: 1.8309783935546875
Batch 2/64 loss: 1.830512285232544
Batch 3/64 loss: 1.818804144859314
Batch 4/64 loss: 1.818486213684082
Batch 5/64 loss: 1.834815502166748
Batch 6/64 loss: 1.8159494400024414
Batch 7/64 loss: 1.8291947841644287
Batch 8/64 loss: 1.8309524059295654
Batch 9/64 loss: 1.83506178855896
Batch 10/64 loss: 1.8253235816955566
Batch 11/64 loss: 1.824110507965088
Batch 12/64 loss: 1.8169374465942383
Batch 13/64 loss: 1.8227529525756836
Batch 14/64 loss: 1.8155579566955566
Batch 15/64 loss: 1.8258181810379028
Batch 16/64 loss: 1.8114827871322632
Batch 17/64 loss: 1.814983606338501
Batch 18/64 loss: 1.8219424486160278
Batch 19/64 loss: 1.8240883350372314
Batch 20/64 loss: 1.8088678121566772
Batch 21/64 loss: 1.8141475915908813
Batch 22/64 loss: 1.8529810905456543
Batch 23/64 loss: 1.8325735330581665
Batch 24/64 loss: 1.815372109413147
Batch 25/64 loss: 1.8300940990447998
Batch 26/64 loss: 1.8152337074279785
Batch 27/64 loss: 1.8144468069076538
Batch 28/64 loss: 1.8255903720855713
Batch 29/64 loss: 1.812696933746338
Batch 30/64 loss: 1.819504976272583
Batch 31/64 loss: 1.8303370475769043
Batch 32/64 loss: 1.829125165939331
Batch 33/64 loss: 1.8138601779937744
Batch 34/64 loss: 1.8146367073059082
Batch 35/64 loss: 1.812295913696289
Batch 36/64 loss: 1.823361873626709
Batch 37/64 loss: 1.8235464096069336
Batch 38/64 loss: 1.8328497409820557
Batch 39/64 loss: 1.812610149383545
Batch 40/64 loss: 1.8340307474136353
Batch 41/64 loss: 1.8355131149291992
Batch 42/64 loss: 1.8245681524276733
Batch 43/64 loss: 1.8356218338012695
Batch 44/64 loss: 1.814788818359375
Batch 45/64 loss: 1.8221466541290283
Batch 46/64 loss: 1.8135955333709717
Batch 47/64 loss: 1.824326992034912
Batch 48/64 loss: 1.818422555923462
Batch 49/64 loss: 1.8144792318344116
Batch 50/64 loss: 1.8224467039108276
Batch 51/64 loss: 1.8221228122711182
Batch 52/64 loss: 1.8154160976409912
Batch 53/64 loss: 1.821217656135559
Batch 54/64 loss: 1.8241760730743408
Batch 55/64 loss: 1.8223237991333008
Batch 56/64 loss: 1.8191508054733276
Batch 57/64 loss: 1.8199554681777954
Batch 58/64 loss: 1.8139201402664185
Batch 59/64 loss: 1.8158165216445923
Batch 60/64 loss: 1.8150818347930908
Batch 61/64 loss: 1.8200855255126953
Batch 62/64 loss: 1.8285608291625977
Batch 63/64 loss: 1.8153691291809082
Batch 64/64 loss: 2.0390827655792236
Epoch 17  Train loss: 1.8246954366272572  Val loss: 1.8553673532820238
Epoch 18
-------------------------------
Batch 1/64 loss: 1.811414122581482
Batch 2/64 loss: 1.8231490850448608
Batch 3/64 loss: 1.8132745027542114
Batch 4/64 loss: 1.8239872455596924
Batch 5/64 loss: 1.8092645406723022
Batch 6/64 loss: 1.8142057657241821
Batch 7/64 loss: 1.805530071258545
Batch 8/64 loss: 1.8329856395721436
Batch 9/64 loss: 1.812932014465332
Batch 10/64 loss: 1.81660795211792
Batch 11/64 loss: 1.8265573978424072
Batch 12/64 loss: 1.8148846626281738
Batch 13/64 loss: 1.818273901939392
Batch 14/64 loss: 1.8156594038009644
Batch 15/64 loss: 1.8080248832702637
Batch 16/64 loss: 1.8178603649139404
Batch 17/64 loss: 1.814699649810791
Batch 18/64 loss: 1.81912362575531
Batch 19/64 loss: 1.806625485420227
Batch 20/64 loss: 1.822187066078186
Batch 21/64 loss: 1.8170673847198486
Batch 22/64 loss: 1.8134632110595703
Batch 23/64 loss: 1.8100101947784424
Batch 24/64 loss: 1.8098620176315308
Batch 25/64 loss: 1.8207584619522095
Batch 26/64 loss: 1.8206080198287964
Batch 27/64 loss: 1.810883641242981
Batch 28/64 loss: 1.8106939792633057
Batch 29/64 loss: 1.8135701417922974
Batch 30/64 loss: 1.8113234043121338
Batch 31/64 loss: 1.8139396905899048
Batch 32/64 loss: 1.815361499786377
Batch 33/64 loss: 1.8138172626495361
Batch 34/64 loss: 1.8105400800704956
Batch 35/64 loss: 1.8161542415618896
Batch 36/64 loss: 1.8121678829193115
Batch 37/64 loss: 1.8111858367919922
Batch 38/64 loss: 1.814307451248169
Batch 39/64 loss: 1.8195732831954956
Batch 40/64 loss: 1.8136478662490845
Batch 41/64 loss: 1.8213703632354736
Batch 42/64 loss: 1.8123934268951416
Batch 43/64 loss: 1.8130333423614502
Batch 44/64 loss: 1.8065290451049805
Batch 45/64 loss: 1.8078765869140625
Batch 46/64 loss: 1.8093831539154053
Batch 47/64 loss: 1.8073961734771729
Batch 48/64 loss: 1.8121140003204346
Batch 49/64 loss: 1.810849666595459
Batch 50/64 loss: 1.8241697549819946
Batch 51/64 loss: 1.8195596933364868
Batch 52/64 loss: 1.8348151445388794
Batch 53/64 loss: 1.8247337341308594
Batch 54/64 loss: 1.8187835216522217
Batch 55/64 loss: 1.821197271347046
Batch 56/64 loss: 1.8163264989852905
Batch 57/64 loss: 1.8209588527679443
Batch 58/64 loss: 1.8243427276611328
Batch 59/64 loss: 1.8129366636276245
Batch 60/64 loss: 1.8111826181411743
Batch 61/64 loss: 1.8083977699279785
Batch 62/64 loss: 1.8111679553985596
Batch 63/64 loss: 1.821509599685669
Batch 64/64 loss: 2.044318675994873
Epoch 18  Train loss: 1.818203129487879  Val loss: 1.8464797370622248
Saving best model, epoch: 18
Epoch 19
-------------------------------
Batch 1/64 loss: 1.8089776039123535
Batch 2/64 loss: 1.8186527490615845
Batch 3/64 loss: 1.8177900314331055
Batch 4/64 loss: 1.8093211650848389
Batch 5/64 loss: 1.8223490715026855
Batch 6/64 loss: 1.8060245513916016
Batch 7/64 loss: 1.8050258159637451
Batch 8/64 loss: 1.8209338188171387
Batch 9/64 loss: 1.8106616735458374
Batch 10/64 loss: 1.821610689163208
Batch 11/64 loss: 1.811915636062622
Batch 12/64 loss: 1.8225126266479492
Batch 13/64 loss: 1.8110418319702148
Batch 14/64 loss: 1.8166054487228394
Batch 15/64 loss: 1.817775845527649
Batch 16/64 loss: 1.8152047395706177
Batch 17/64 loss: 1.8074570894241333
Batch 18/64 loss: 1.8213224411010742
Batch 19/64 loss: 1.8104596138000488
Batch 20/64 loss: 1.8064827919006348
Batch 21/64 loss: 1.8291281461715698
Batch 22/64 loss: 1.8130578994750977
Batch 23/64 loss: 1.807976245880127
Batch 24/64 loss: 1.8130897283554077
Batch 25/64 loss: 1.8081448078155518
Batch 26/64 loss: 1.8071743249893188
Batch 27/64 loss: 1.8257060050964355
Batch 28/64 loss: 1.8335472345352173
Batch 29/64 loss: 1.81485116481781
Batch 30/64 loss: 1.8064205646514893
Batch 31/64 loss: 1.8092621564865112
Batch 32/64 loss: 1.813702940940857
Batch 33/64 loss: 1.804394245147705
Batch 34/64 loss: 1.804652214050293
Batch 35/64 loss: 1.8170158863067627
Batch 36/64 loss: 1.812492847442627
Batch 37/64 loss: 1.8468742370605469
Batch 38/64 loss: 1.8168649673461914
Batch 39/64 loss: 1.8140580654144287
Batch 40/64 loss: 1.8200786113739014
Batch 41/64 loss: 1.8185529708862305
Batch 42/64 loss: 1.8133875131607056
Batch 43/64 loss: 1.8085947036743164
Batch 44/64 loss: 1.808046579360962
Batch 45/64 loss: 1.8044958114624023
Batch 46/64 loss: 1.8105889558792114
Batch 47/64 loss: 1.8186662197113037
Batch 48/64 loss: 1.8152008056640625
Batch 49/64 loss: 1.8181748390197754
Batch 50/64 loss: 1.8116986751556396
Batch 51/64 loss: 1.8138835430145264
Batch 52/64 loss: 1.8161736726760864
Batch 53/64 loss: 1.8060145378112793
Batch 54/64 loss: 1.8105621337890625
Batch 55/64 loss: 1.8060691356658936
Batch 56/64 loss: 1.8114278316497803
Batch 57/64 loss: 1.8074802160263062
Batch 58/64 loss: 1.803421974182129
Batch 59/64 loss: 1.816807746887207
Batch 60/64 loss: 1.8100159168243408
Batch 61/64 loss: 1.8047276735305786
Batch 62/64 loss: 1.814792275428772
Batch 63/64 loss: 1.8078209161758423
Batch 64/64 loss: 2.0372941493988037
Epoch 19  Train loss: 1.8162383182376038  Val loss: 1.8384830132382841
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 1.8109655380249023
Batch 2/64 loss: 1.8057727813720703
Batch 3/64 loss: 1.8098728656768799
Batch 4/64 loss: 1.8180853128433228
Batch 5/64 loss: 1.8029998540878296
Batch 6/64 loss: 1.809553861618042
Batch 7/64 loss: 1.8037577867507935
Batch 8/64 loss: 1.808598279953003
Batch 9/64 loss: 1.8044319152832031
Batch 10/64 loss: 1.8074313402175903
Batch 11/64 loss: 1.803921103477478
Batch 12/64 loss: 1.8039379119873047
Batch 13/64 loss: 1.8019514083862305
Batch 14/64 loss: 1.8054300546646118
Batch 15/64 loss: 1.8091269731521606
Batch 16/64 loss: 1.8249292373657227
Batch 17/64 loss: 1.8036465644836426
Batch 18/64 loss: 1.800887942314148
Batch 19/64 loss: 1.7982550859451294
Batch 20/64 loss: 1.808425784111023
Batch 21/64 loss: 1.8090946674346924
Batch 22/64 loss: 1.8170037269592285
Batch 23/64 loss: 1.8050713539123535
Batch 24/64 loss: 1.8051791191101074
Batch 25/64 loss: 1.8078221082687378
Batch 26/64 loss: 1.8086384534835815
Batch 27/64 loss: 1.807503581047058
Batch 28/64 loss: 1.8038424253463745
Batch 29/64 loss: 1.8049501180648804
Batch 30/64 loss: 1.80757474899292
Batch 31/64 loss: 1.8082690238952637
Batch 32/64 loss: 1.8089745044708252
Batch 33/64 loss: 1.8127864599227905
Batch 34/64 loss: 1.8057019710540771
Batch 35/64 loss: 1.8065294027328491
Batch 36/64 loss: 1.8061002492904663
Batch 37/64 loss: 1.8201435804367065
Batch 38/64 loss: 1.8155367374420166
Batch 39/64 loss: 1.8100569248199463
Batch 40/64 loss: 1.8178489208221436
Batch 41/64 loss: 1.804311752319336
Batch 42/64 loss: 1.8018548488616943
Batch 43/64 loss: 1.8115320205688477
Batch 44/64 loss: 1.8111438751220703
Batch 45/64 loss: 1.8035871982574463
Batch 46/64 loss: 1.8056644201278687
Batch 47/64 loss: 1.8053944110870361
Batch 48/64 loss: 1.8004915714263916
Batch 49/64 loss: 1.8024799823760986
Batch 50/64 loss: 1.801912784576416
Batch 51/64 loss: 1.8047164678573608
Batch 52/64 loss: 1.8072563409805298
Batch 53/64 loss: 1.8051865100860596
Batch 54/64 loss: 1.8024718761444092
Batch 55/64 loss: 1.8202165365219116
Batch 56/64 loss: 1.8071707487106323
Batch 57/64 loss: 1.7992064952850342
Batch 58/64 loss: 1.8088642358779907
Batch 59/64 loss: 1.805539608001709
Batch 60/64 loss: 1.8012480735778809
Batch 61/64 loss: 1.8169984817504883
Batch 62/64 loss: 1.8010914325714111
Batch 63/64 loss: 1.8169764280319214
Batch 64/64 loss: 2.0440263748168945
Epoch 20  Train loss: 1.8103364009483187  Val loss: 1.8340771837332814
Saving best model, epoch: 20
Epoch 21
-------------------------------
Batch 1/64 loss: 1.804216980934143
Batch 2/64 loss: 1.805955171585083
Batch 3/64 loss: 1.81118905544281
Batch 4/64 loss: 1.808066964149475
Batch 5/64 loss: 1.8081815242767334
Batch 6/64 loss: 1.815077781677246
Batch 7/64 loss: 1.8103383779525757
Batch 8/64 loss: 1.8086271286010742
Batch 9/64 loss: 1.8029413223266602
Batch 10/64 loss: 1.8131959438323975
Batch 11/64 loss: 1.8028944730758667
Batch 12/64 loss: 1.814629316329956
Batch 13/64 loss: 1.803972601890564
Batch 14/64 loss: 1.8022065162658691
Batch 15/64 loss: 1.8043807744979858
Batch 16/64 loss: 1.8189916610717773
Batch 17/64 loss: 1.8105254173278809
Batch 18/64 loss: 1.80308997631073
Batch 19/64 loss: 1.8249894380569458
Batch 20/64 loss: 1.810840368270874
Batch 21/64 loss: 1.807279348373413
Batch 22/64 loss: 1.8040587902069092
Batch 23/64 loss: 1.8044102191925049
Batch 24/64 loss: 1.8087153434753418
Batch 25/64 loss: 1.8039488792419434
Batch 26/64 loss: 1.805729627609253
Batch 27/64 loss: 1.8066877126693726
Batch 28/64 loss: 1.8030304908752441
Batch 29/64 loss: 1.7966876029968262
Batch 30/64 loss: 1.8029742240905762
Batch 31/64 loss: 1.8056206703186035
Batch 32/64 loss: 1.8048827648162842
Batch 33/64 loss: 1.8050256967544556
Batch 34/64 loss: 1.8145060539245605
Batch 35/64 loss: 1.809391975402832
Batch 36/64 loss: 1.8082635402679443
Batch 37/64 loss: 1.8010032176971436
Batch 38/64 loss: 1.8026795387268066
Batch 39/64 loss: 1.803328275680542
Batch 40/64 loss: 1.8106234073638916
Batch 41/64 loss: 1.80515718460083
Batch 42/64 loss: 1.8028016090393066
Batch 43/64 loss: 1.8025798797607422
Batch 44/64 loss: 1.8174359798431396
Batch 45/64 loss: 1.801409363746643
Batch 46/64 loss: 1.796972393989563
Batch 47/64 loss: 1.80205237865448
Batch 48/64 loss: 1.8070988655090332
Batch 49/64 loss: 1.8006176948547363
Batch 50/64 loss: 1.802765130996704
Batch 51/64 loss: 1.8002468347549438
Batch 52/64 loss: 1.802365779876709
Batch 53/64 loss: 1.8015512228012085
Batch 54/64 loss: 1.7999799251556396
Batch 55/64 loss: 1.8131964206695557
Batch 56/64 loss: 1.8015687465667725
Batch 57/64 loss: 1.7990238666534424
Batch 58/64 loss: 1.802930235862732
Batch 59/64 loss: 1.8057059049606323
Batch 60/64 loss: 1.8010668754577637
Batch 61/64 loss: 1.817304015159607
Batch 62/64 loss: 1.803120493888855
Batch 63/64 loss: 1.8020813465118408
Batch 64/64 loss: 2.025752067565918
Epoch 21  Train loss: 1.8086510489968692  Val loss: 1.829316634083122
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 1.7998318672180176
Batch 2/64 loss: 1.805626392364502
Batch 3/64 loss: 1.8091351985931396
Batch 4/64 loss: 1.7980785369873047
Batch 5/64 loss: 1.8081272840499878
Batch 6/64 loss: 1.8004854917526245
Batch 7/64 loss: 1.80397367477417
Batch 8/64 loss: 1.8044761419296265
Batch 9/64 loss: 1.8002948760986328
Batch 10/64 loss: 1.8036926984786987
Batch 11/64 loss: 1.8018827438354492
Batch 12/64 loss: 1.8013501167297363
Batch 13/64 loss: 1.7996129989624023
Batch 14/64 loss: 1.8162832260131836
Batch 15/64 loss: 1.804661512374878
Batch 16/64 loss: 1.7976199388504028
Batch 17/64 loss: 1.8003398180007935
Batch 18/64 loss: 1.8041435480117798
Batch 19/64 loss: 1.8022633790969849
Batch 20/64 loss: 1.798935055732727
Batch 21/64 loss: 1.8012471199035645
Batch 22/64 loss: 1.8024407625198364
Batch 23/64 loss: 1.7959914207458496
Batch 24/64 loss: 1.8052597045898438
Batch 25/64 loss: 1.796985387802124
Batch 26/64 loss: 1.803182601928711
Batch 27/64 loss: 1.8088130950927734
Batch 28/64 loss: 1.807673454284668
Batch 29/64 loss: 1.8012458086013794
Batch 30/64 loss: 1.800856351852417
Batch 31/64 loss: 1.7974680662155151
Batch 32/64 loss: 1.8038527965545654
Batch 33/64 loss: 1.802575707435608
Batch 34/64 loss: 1.7991573810577393
Batch 35/64 loss: 1.8139076232910156
Batch 36/64 loss: 1.7982527017593384
Batch 37/64 loss: 1.803117275238037
Batch 38/64 loss: 1.794407844543457
Batch 39/64 loss: 1.7989131212234497
Batch 40/64 loss: 1.8071926832199097
Batch 41/64 loss: 1.7976391315460205
Batch 42/64 loss: 1.803544044494629
Batch 43/64 loss: 1.8032569885253906
Batch 44/64 loss: 1.8001186847686768
Batch 45/64 loss: 1.803928017616272
Batch 46/64 loss: 1.8059096336364746
Batch 47/64 loss: 1.8016160726547241
Batch 48/64 loss: 1.8001116514205933
Batch 49/64 loss: 1.8032516241073608
Batch 50/64 loss: 1.8039690256118774
Batch 51/64 loss: 1.8039265871047974
Batch 52/64 loss: 1.8003151416778564
Batch 53/64 loss: 1.8085644245147705
Batch 54/64 loss: 1.8089191913604736
Batch 55/64 loss: 1.8024731874465942
Batch 56/64 loss: 1.8090205192565918
Batch 57/64 loss: 1.8095589876174927
Batch 58/64 loss: 1.7987122535705566
Batch 59/64 loss: 1.8109394311904907
Batch 60/64 loss: 1.8061637878417969
Batch 61/64 loss: 1.8023145198822021
Batch 62/64 loss: 1.799669623374939
Batch 63/64 loss: 1.7994657754898071
Batch 64/64 loss: 2.0260884761810303
Epoch 22  Train loss: 1.8055891775617412  Val loss: 1.8244944528206108
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: 1.7997734546661377
Batch 2/64 loss: 1.8057948350906372
Batch 3/64 loss: 1.8035398721694946
Batch 4/64 loss: 1.8153438568115234
Batch 5/64 loss: 1.7992826700210571
Batch 6/64 loss: 1.800390362739563
Batch 7/64 loss: 1.8199326992034912
Batch 8/64 loss: 1.8063735961914062
Batch 9/64 loss: 1.8078827857971191
Batch 10/64 loss: 1.8012733459472656
Batch 11/64 loss: 1.7984602451324463
Batch 12/64 loss: 1.8066153526306152
Batch 13/64 loss: 1.8010880947113037
Batch 14/64 loss: 1.7991387844085693
Batch 15/64 loss: 1.8064985275268555
Batch 16/64 loss: 1.7956738471984863
Batch 17/64 loss: 1.8018486499786377
Batch 18/64 loss: 1.7998359203338623
Batch 19/64 loss: 1.802147388458252
Batch 20/64 loss: 1.8121609687805176
Batch 21/64 loss: 1.7977001667022705
Batch 22/64 loss: 1.7984344959259033
Batch 23/64 loss: 1.7965718507766724
Batch 24/64 loss: 1.7971516847610474
Batch 25/64 loss: 1.8030027151107788
Batch 26/64 loss: 1.8009411096572876
Batch 27/64 loss: 1.8033047914505005
Batch 28/64 loss: 1.7973620891571045
Batch 29/64 loss: 1.799966812133789
Batch 30/64 loss: 1.7948901653289795
Batch 31/64 loss: 1.8104093074798584
Batch 32/64 loss: 1.794165849685669
Batch 33/64 loss: 1.8001267910003662
Batch 34/64 loss: 1.8040252923965454
Batch 35/64 loss: 1.8008978366851807
Batch 36/64 loss: 1.8111085891723633
Batch 37/64 loss: 1.808994174003601
Batch 38/64 loss: 1.7985960245132446
Batch 39/64 loss: 1.8015923500061035
Batch 40/64 loss: 1.7982860803604126
Batch 41/64 loss: 1.7963409423828125
Batch 42/64 loss: 1.7934222221374512
Batch 43/64 loss: 1.8213577270507812
Batch 44/64 loss: 1.8018734455108643
Batch 45/64 loss: 1.7977323532104492
Batch 46/64 loss: 1.7988712787628174
Batch 47/64 loss: 1.8081214427947998
Batch 48/64 loss: 1.7990522384643555
Batch 49/64 loss: 1.7973185777664185
Batch 50/64 loss: 1.8000587224960327
Batch 51/64 loss: 1.7973511219024658
Batch 52/64 loss: 1.7978955507278442
Batch 53/64 loss: 1.8039946556091309
Batch 54/64 loss: 1.7997424602508545
Batch 55/64 loss: 1.7932276725769043
Batch 56/64 loss: 1.804822325706482
Batch 57/64 loss: 1.8075523376464844
Batch 58/64 loss: 1.7990012168884277
Batch 59/64 loss: 1.7998377084732056
Batch 60/64 loss: 1.802332878112793
Batch 61/64 loss: 1.8046305179595947
Batch 62/64 loss: 1.8026248216629028
Batch 63/64 loss: 1.8006997108459473
Batch 64/64 loss: 2.0296568870544434
Epoch 23  Train loss: 1.8047166749542836  Val loss: 1.842086448702206
Epoch 24
-------------------------------
Batch 1/64 loss: 1.7972993850708008
Batch 2/64 loss: 1.8022942543029785
Batch 3/64 loss: 1.8023446798324585
Batch 4/64 loss: 1.797183871269226
Batch 5/64 loss: 1.8106725215911865
Batch 6/64 loss: 1.8025680780410767
Batch 7/64 loss: 1.8022712469100952
Batch 8/64 loss: 1.7988107204437256
Batch 9/64 loss: 1.8006526231765747
Batch 10/64 loss: 1.8141133785247803
Batch 11/64 loss: 1.813207983970642
Batch 12/64 loss: 1.805279016494751
Batch 13/64 loss: 1.799554467201233
Batch 14/64 loss: 1.7995314598083496
Batch 15/64 loss: 1.8018547296524048
Batch 16/64 loss: 1.8049359321594238
Batch 17/64 loss: 1.793628215789795
Batch 18/64 loss: 1.798707127571106
Batch 19/64 loss: 1.8147691488265991
Batch 20/64 loss: 1.8063552379608154
Batch 21/64 loss: 1.7986778020858765
Batch 22/64 loss: 1.79764986038208
Batch 23/64 loss: 1.8054512739181519
Batch 24/64 loss: 1.7966763973236084
Batch 25/64 loss: 1.7979201078414917
Batch 26/64 loss: 1.807358741760254
Batch 27/64 loss: 1.8000481128692627
Batch 28/64 loss: 1.7981512546539307
Batch 29/64 loss: 1.7998921871185303
Batch 30/64 loss: 1.800129771232605
Batch 31/64 loss: 1.8011049032211304
Batch 32/64 loss: 1.7937861680984497
Batch 33/64 loss: 1.7922985553741455
Batch 34/64 loss: 1.8002984523773193
Batch 35/64 loss: 1.7971019744873047
Batch 36/64 loss: 1.7959648370742798
Batch 37/64 loss: 1.7934240102767944
Batch 38/64 loss: 1.8098511695861816
Batch 39/64 loss: 1.8034780025482178
Batch 40/64 loss: 1.7975678443908691
Batch 41/64 loss: 1.809386968612671
Batch 42/64 loss: 1.8034684658050537
Batch 43/64 loss: 1.7919707298278809
Batch 44/64 loss: 1.8186593055725098
Batch 45/64 loss: 1.8034369945526123
Batch 46/64 loss: 1.8062928915023804
Batch 47/64 loss: 1.807538390159607
Batch 48/64 loss: 1.8026429414749146
Batch 49/64 loss: 1.8019402027130127
Batch 50/64 loss: 1.797214150428772
Batch 51/64 loss: 1.7942250967025757
Batch 52/64 loss: 1.7952755689620972
Batch 53/64 loss: 1.8015921115875244
Batch 54/64 loss: 1.79826819896698
Batch 55/64 loss: 1.795796275138855
Batch 56/64 loss: 1.8032000064849854
Batch 57/64 loss: 1.8013999462127686
Batch 58/64 loss: 1.7914215326309204
Batch 59/64 loss: 1.7944443225860596
Batch 60/64 loss: 1.7981846332550049
Batch 61/64 loss: 1.7994849681854248
Batch 62/64 loss: 1.7991688251495361
Batch 63/64 loss: 1.7966699600219727
Batch 64/64 loss: 2.0289716720581055
Epoch 24  Train loss: 1.8037063018948425  Val loss: 1.824940718326372
Epoch 25
-------------------------------
Batch 1/64 loss: 1.7989404201507568
Batch 2/64 loss: 1.8063968420028687
Batch 3/64 loss: 1.805379867553711
Batch 4/64 loss: 1.7983624935150146
Batch 5/64 loss: 1.8045612573623657
Batch 6/64 loss: 1.7948604822158813
Batch 7/64 loss: 1.7947885990142822
Batch 8/64 loss: 1.796360969543457
Batch 9/64 loss: 1.793452262878418
Batch 10/64 loss: 1.8055347204208374
Batch 11/64 loss: 1.7949634790420532
Batch 12/64 loss: 1.7927494049072266
Batch 13/64 loss: 1.7983499765396118
Batch 14/64 loss: 1.7950034141540527
Batch 15/64 loss: 1.7970987558364868
Batch 16/64 loss: 1.7961101531982422
Batch 17/64 loss: 1.7933907508850098
Batch 18/64 loss: 1.800403118133545
Batch 19/64 loss: 1.7946380376815796
Batch 20/64 loss: 1.795295238494873
Batch 21/64 loss: 1.7930136919021606
Batch 22/64 loss: 1.8224022388458252
Batch 23/64 loss: 1.8021219968795776
Batch 24/64 loss: 1.7969967126846313
Batch 25/64 loss: 1.8128044605255127
Batch 26/64 loss: 1.7949819564819336
Batch 27/64 loss: 1.7959926128387451
Batch 28/64 loss: 1.7988052368164062
Batch 29/64 loss: 1.7950465679168701
Batch 30/64 loss: 1.8124388456344604
Batch 31/64 loss: 1.7963285446166992
Batch 32/64 loss: 1.8015203475952148
Batch 33/64 loss: 1.7969778776168823
Batch 34/64 loss: 1.799079418182373
Batch 35/64 loss: 1.812589168548584
Batch 36/64 loss: 1.79822838306427
Batch 37/64 loss: 1.8006268739700317
Batch 38/64 loss: 1.7990236282348633
Batch 39/64 loss: 1.79954195022583
Batch 40/64 loss: 1.7958648204803467
Batch 41/64 loss: 1.7936742305755615
Batch 42/64 loss: 1.7958276271820068
Batch 43/64 loss: 1.7970361709594727
Batch 44/64 loss: 1.7978681325912476
Batch 45/64 loss: 1.7916041612625122
Batch 46/64 loss: 1.7957159280776978
Batch 47/64 loss: 1.7956069707870483
Batch 48/64 loss: 1.7973003387451172
Batch 49/64 loss: 1.795456886291504
Batch 50/64 loss: 1.7961478233337402
Batch 51/64 loss: 1.7966049909591675
Batch 52/64 loss: 1.8053141832351685
Batch 53/64 loss: 1.7933151721954346
Batch 54/64 loss: 1.7998461723327637
Batch 55/64 loss: 1.7975807189941406
Batch 56/64 loss: 1.796536922454834
Batch 57/64 loss: 1.7987127304077148
Batch 58/64 loss: 1.7994105815887451
Batch 59/64 loss: 1.806692123413086
Batch 60/64 loss: 1.8210430145263672
Batch 61/64 loss: 1.8052505254745483
Batch 62/64 loss: 1.7973825931549072
Batch 63/64 loss: 1.8126293420791626
Batch 64/64 loss: 2.0259358882904053
Epoch 25  Train loss: 1.8021495660146079  Val loss: 1.8734792737207053
Epoch 26
-------------------------------
Batch 1/64 loss: 1.7972489595413208
Batch 2/64 loss: 1.8057670593261719
Batch 3/64 loss: 1.8055992126464844
Batch 4/64 loss: 1.8025782108306885
Batch 5/64 loss: 1.81095552444458
Batch 6/64 loss: 1.803697109222412
Batch 7/64 loss: 1.8049476146697998
Batch 8/64 loss: 1.803446650505066
Batch 9/64 loss: 1.7997221946716309
Batch 10/64 loss: 1.7996776103973389
Batch 11/64 loss: 1.7967373132705688
Batch 12/64 loss: 1.8016667366027832
Batch 13/64 loss: 1.813690185546875
Batch 14/64 loss: 1.79713773727417
Batch 15/64 loss: 1.801232933998108
Batch 16/64 loss: 1.801276445388794
Batch 17/64 loss: 1.8084404468536377
Batch 18/64 loss: 1.8053865432739258
Batch 19/64 loss: 1.8067408800125122
Batch 20/64 loss: 1.8106194734573364
Batch 21/64 loss: 1.8028573989868164
Batch 22/64 loss: 1.7975869178771973
Batch 23/64 loss: 1.7962037324905396
Batch 24/64 loss: 1.7951197624206543
Batch 25/64 loss: 1.8012049198150635
Batch 26/64 loss: 1.8056986331939697
Batch 27/64 loss: 1.7959887981414795
Batch 28/64 loss: 1.804322600364685
Batch 29/64 loss: 1.796079397201538
Batch 30/64 loss: 1.8016997575759888
Batch 31/64 loss: 1.8118832111358643
Batch 32/64 loss: 1.7975358963012695
Batch 33/64 loss: 1.807632327079773
Batch 34/64 loss: 1.8017045259475708
Batch 35/64 loss: 1.7949533462524414
Batch 36/64 loss: 1.797437071800232
Batch 37/64 loss: 1.7949895858764648
Batch 38/64 loss: 1.804137945175171
Batch 39/64 loss: 1.801358699798584
Batch 40/64 loss: 1.7954790592193604
Batch 41/64 loss: 1.8004224300384521
Batch 42/64 loss: 1.8013678789138794
Batch 43/64 loss: 1.7981946468353271
Batch 44/64 loss: 1.8041898012161255
Batch 45/64 loss: 1.7943122386932373
Batch 46/64 loss: 1.7906179428100586
Batch 47/64 loss: 1.7969272136688232
Batch 48/64 loss: 1.794013261795044
Batch 49/64 loss: 1.793318748474121
Batch 50/64 loss: 1.8072395324707031
Batch 51/64 loss: 1.7923307418823242
Batch 52/64 loss: 1.7946515083312988
Batch 53/64 loss: 1.7947440147399902
Batch 54/64 loss: 1.798500418663025
Batch 55/64 loss: 1.7950433492660522
Batch 56/64 loss: 1.7929190397262573
Batch 57/64 loss: 1.7942619323730469
Batch 58/64 loss: 1.7965561151504517
Batch 59/64 loss: 1.7970741987228394
Batch 60/64 loss: 1.7906467914581299
Batch 61/64 loss: 1.789571762084961
Batch 62/64 loss: 1.793786883354187
Batch 63/64 loss: 1.7904260158538818
Batch 64/64 loss: 2.022481918334961
Epoch 26  Train loss: 1.8023281620998008  Val loss: 1.8236434533423984
Saving best model, epoch: 26
Epoch 27
-------------------------------
Batch 1/64 loss: 1.7913687229156494
Batch 2/64 loss: 1.8012957572937012
Batch 3/64 loss: 1.796816349029541
Batch 4/64 loss: 1.7921892404556274
Batch 5/64 loss: 1.8001335859298706
Batch 6/64 loss: 1.8003249168395996
Batch 7/64 loss: 1.812331199645996
Batch 8/64 loss: 1.7903001308441162
Batch 9/64 loss: 1.7934842109680176
Batch 10/64 loss: 1.797417402267456
Batch 11/64 loss: 1.7958985567092896
Batch 12/64 loss: 1.8120301961898804
Batch 13/64 loss: 1.7959009408950806
Batch 14/64 loss: 1.7951723337173462
Batch 15/64 loss: 1.7960493564605713
Batch 16/64 loss: 1.7941322326660156
Batch 17/64 loss: 1.8007583618164062
Batch 18/64 loss: 1.79183828830719
Batch 19/64 loss: 1.79526948928833
Batch 20/64 loss: 1.7976174354553223
Batch 21/64 loss: 1.7955504655838013
Batch 22/64 loss: 1.790423035621643
Batch 23/64 loss: 1.7896745204925537
Batch 24/64 loss: 1.8019284009933472
Batch 25/64 loss: 1.7951918840408325
Batch 26/64 loss: 1.7956719398498535
Batch 27/64 loss: 1.789191722869873
Batch 28/64 loss: 1.8132550716400146
Batch 29/64 loss: 1.7936772108078003
Batch 30/64 loss: 1.7979905605316162
Batch 31/64 loss: 1.7945961952209473
Batch 32/64 loss: 1.797480821609497
Batch 33/64 loss: 1.7935949563980103
Batch 34/64 loss: 1.80429208278656
Batch 35/64 loss: 1.7952898740768433
Batch 36/64 loss: 1.7966198921203613
Batch 37/64 loss: 1.793670415878296
Batch 38/64 loss: 1.7925851345062256
Batch 39/64 loss: 1.7961175441741943
Batch 40/64 loss: 1.8020808696746826
Batch 41/64 loss: 1.7908363342285156
Batch 42/64 loss: 1.799676537513733
Batch 43/64 loss: 1.7905986309051514
Batch 44/64 loss: 1.7986292839050293
Batch 45/64 loss: 1.7926987409591675
Batch 46/64 loss: 1.800580382347107
Batch 47/64 loss: 1.7942261695861816
Batch 48/64 loss: 1.7978092432022095
Batch 49/64 loss: 1.7979336977005005
Batch 50/64 loss: 1.7961416244506836
Batch 51/64 loss: 1.8198639154434204
Batch 52/64 loss: 1.804841160774231
Batch 53/64 loss: 1.8009036779403687
Batch 54/64 loss: 1.7974977493286133
Batch 55/64 loss: 1.8001325130462646
Batch 56/64 loss: 1.8003809452056885
Batch 57/64 loss: 1.7969939708709717
Batch 58/64 loss: 1.8144588470458984
Batch 59/64 loss: 1.7982714176177979
Batch 60/64 loss: 1.7925758361816406
Batch 61/64 loss: 1.7986555099487305
Batch 62/64 loss: 1.7956430912017822
Batch 63/64 loss: 1.797288179397583
Batch 64/64 loss: 2.0185813903808594
Epoch 27  Train loss: 1.800310349931904  Val loss: 1.823963357001236
Epoch 28
-------------------------------
Batch 1/64 loss: 1.799565076828003
Batch 2/64 loss: 1.7991611957550049
Batch 3/64 loss: 1.7953035831451416
Batch 4/64 loss: 1.8021472692489624
Batch 5/64 loss: 1.7912780046463013
Batch 6/64 loss: 1.796692132949829
Batch 7/64 loss: 1.8052407503128052
Batch 8/64 loss: 1.7907918691635132
Batch 9/64 loss: 1.7970702648162842
Batch 10/64 loss: 1.7907365560531616
Batch 11/64 loss: 1.8233696222305298
Batch 12/64 loss: 1.7952303886413574
Batch 13/64 loss: 1.7970391511917114
Batch 14/64 loss: 1.797484278678894
Batch 15/64 loss: 1.7918434143066406
Batch 16/64 loss: 1.7929675579071045
Batch 17/64 loss: 1.7965751886367798
Batch 18/64 loss: 1.7999894618988037
Batch 19/64 loss: 1.7933142185211182
Batch 20/64 loss: 1.807054042816162
Batch 21/64 loss: 1.7907047271728516
Batch 22/64 loss: 1.7930049896240234
Batch 23/64 loss: 1.7874445915222168
Batch 24/64 loss: 1.7975586652755737
Batch 25/64 loss: 1.7942986488342285
Batch 26/64 loss: 1.7902244329452515
Batch 27/64 loss: 1.7988883256912231
Batch 28/64 loss: 1.7957981824874878
Batch 29/64 loss: 1.7937067747116089
Batch 30/64 loss: 1.800920844078064
Batch 31/64 loss: 1.7988297939300537
Batch 32/64 loss: 1.7915445566177368
Batch 33/64 loss: 1.8019850254058838
Batch 34/64 loss: 1.795719861984253
Batch 35/64 loss: 1.7981231212615967
Batch 36/64 loss: 1.7976839542388916
Batch 37/64 loss: 1.7988709211349487
Batch 38/64 loss: 1.7928801774978638
Batch 39/64 loss: 1.7965563535690308
Batch 40/64 loss: 1.7924628257751465
Batch 41/64 loss: 1.7937955856323242
Batch 42/64 loss: 1.7960305213928223
Batch 43/64 loss: 1.7955588102340698
Batch 44/64 loss: 1.7959203720092773
Batch 45/64 loss: 1.7969361543655396
Batch 46/64 loss: 1.805477261543274
Batch 47/64 loss: 1.794154167175293
Batch 48/64 loss: 1.7952269315719604
Batch 49/64 loss: 1.7944130897521973
Batch 50/64 loss: 1.798859715461731
Batch 51/64 loss: 1.7915730476379395
Batch 52/64 loss: 1.7978004217147827
Batch 53/64 loss: 1.7986441850662231
Batch 54/64 loss: 1.787567138671875
Batch 55/64 loss: 1.7941062450408936
Batch 56/64 loss: 1.7959911823272705
Batch 57/64 loss: 1.800500750541687
Batch 58/64 loss: 1.7975072860717773
Batch 59/64 loss: 1.800055742263794
Batch 60/64 loss: 1.7989094257354736
Batch 61/64 loss: 1.7901301383972168
Batch 62/64 loss: 1.79835045337677
Batch 63/64 loss: 1.7957042455673218
Batch 64/64 loss: 2.0148472785949707
Epoch 28  Train loss: 1.799127986384373  Val loss: 1.8312940433672613
Epoch 29
-------------------------------
Batch 1/64 loss: 1.7928686141967773
Batch 2/64 loss: 1.7931585311889648
Batch 3/64 loss: 1.7904866933822632
Batch 4/64 loss: 1.793779969215393
Batch 5/64 loss: 1.7937157154083252
Batch 6/64 loss: 1.7908272743225098
Batch 7/64 loss: 1.7942743301391602
Batch 8/64 loss: 1.8025529384613037
Batch 9/64 loss: 1.802125334739685
Batch 10/64 loss: 1.7941983938217163
Batch 11/64 loss: 1.796518325805664
Batch 12/64 loss: 1.7927807569503784
Batch 13/64 loss: 1.7899010181427002
Batch 14/64 loss: 1.7923297882080078
Batch 15/64 loss: 1.7923645973205566
Batch 16/64 loss: 1.7929973602294922
Batch 17/64 loss: 1.7935984134674072
Batch 18/64 loss: 1.800515055656433
Batch 19/64 loss: 1.7938120365142822
Batch 20/64 loss: 1.7963734865188599
Batch 21/64 loss: 1.7930115461349487
Batch 22/64 loss: 1.7933471202850342
Batch 23/64 loss: 1.7914561033248901
Batch 24/64 loss: 1.7906880378723145
Batch 25/64 loss: 1.7855913639068604
Batch 26/64 loss: 1.7864339351654053
Batch 27/64 loss: 1.7907981872558594
Batch 28/64 loss: 1.7898850440979004
Batch 29/64 loss: 1.7929680347442627
Batch 30/64 loss: 1.791567087173462
Batch 31/64 loss: 1.8031046390533447
Batch 32/64 loss: 1.788042664527893
Batch 33/64 loss: 1.7913703918457031
Batch 34/64 loss: 1.79962158203125
Batch 35/64 loss: 1.7932178974151611
Batch 36/64 loss: 1.8023539781570435
Batch 37/64 loss: 1.7952381372451782
Batch 38/64 loss: 1.7853610515594482
Batch 39/64 loss: 1.7877552509307861
Batch 40/64 loss: 1.7917869091033936
Batch 41/64 loss: 1.8184758424758911
Batch 42/64 loss: 1.7909890413284302
Batch 43/64 loss: 1.7956467866897583
Batch 44/64 loss: 1.8031889200210571
Batch 45/64 loss: 1.7950708866119385
Batch 46/64 loss: 1.7924884557724
Batch 47/64 loss: 1.7983070611953735
Batch 48/64 loss: 1.794002890586853
Batch 49/64 loss: 1.7943633794784546
Batch 50/64 loss: 1.7918543815612793
Batch 51/64 loss: 1.8179905414581299
Batch 52/64 loss: 1.7986621856689453
Batch 53/64 loss: 1.792080044746399
Batch 54/64 loss: 1.7923357486724854
Batch 55/64 loss: 1.7951091527938843
Batch 56/64 loss: 1.7876707315444946
Batch 57/64 loss: 1.7965497970581055
Batch 58/64 loss: 1.7996232509613037
Batch 59/64 loss: 1.7945994138717651
Batch 60/64 loss: 1.798316240310669
Batch 61/64 loss: 1.7996584177017212
Batch 62/64 loss: 1.801655888557434
Batch 63/64 loss: 1.7903220653533936
Batch 64/64 loss: 2.0140092372894287
Epoch 29  Train loss: 1.797368559182859  Val loss: 1.8188631886878783
Saving best model, epoch: 29
Epoch 30
-------------------------------
Batch 1/64 loss: 1.7944103479385376
Batch 2/64 loss: 1.79245126247406
Batch 3/64 loss: 1.7871845960617065
Batch 4/64 loss: 1.7933521270751953
Batch 5/64 loss: 1.7963626384735107
Batch 6/64 loss: 1.7927781343460083
Batch 7/64 loss: 1.7934117317199707
Batch 8/64 loss: 1.7910453081130981
Batch 9/64 loss: 1.7895572185516357
Batch 10/64 loss: 1.7892515659332275
Batch 11/64 loss: 1.787587285041809
Batch 12/64 loss: 1.788723349571228
Batch 13/64 loss: 1.79061758518219
Batch 14/64 loss: 1.7987513542175293
Batch 15/64 loss: 1.79573392868042
Batch 16/64 loss: 1.7871979475021362
Batch 17/64 loss: 1.799107551574707
Batch 18/64 loss: 1.7877074480056763
Batch 19/64 loss: 1.7886557579040527
Batch 20/64 loss: 1.7922863960266113
Batch 21/64 loss: 1.7858442068099976
Batch 22/64 loss: 1.79496431350708
Batch 23/64 loss: 1.794571876525879
Batch 24/64 loss: 1.78908371925354
Batch 25/64 loss: 1.7913072109222412
Batch 26/64 loss: 1.802291750907898
Batch 27/64 loss: 1.8014730215072632
Batch 28/64 loss: 1.7887279987335205
Batch 29/64 loss: 1.789717435836792
Batch 30/64 loss: 1.801674485206604
Batch 31/64 loss: 1.7906501293182373
Batch 32/64 loss: 1.7929106950759888
Batch 33/64 loss: 1.789858341217041
Batch 34/64 loss: 1.7887800931930542
Batch 35/64 loss: 1.7933692932128906
Batch 36/64 loss: 1.79017972946167
Batch 37/64 loss: 1.7944413423538208
Batch 38/64 loss: 1.8026164770126343
Batch 39/64 loss: 1.7934646606445312
Batch 40/64 loss: 1.7911765575408936
Batch 41/64 loss: 1.7897335290908813
Batch 42/64 loss: 1.7899264097213745
Batch 43/64 loss: 1.7963283061981201
Batch 44/64 loss: 1.791916847229004
Batch 45/64 loss: 1.8002748489379883
Batch 46/64 loss: 1.7909108400344849
Batch 47/64 loss: 1.7867530584335327
Batch 48/64 loss: 1.7878626585006714
Batch 49/64 loss: 1.7912726402282715
Batch 50/64 loss: 1.7989734411239624
Batch 51/64 loss: 1.7955347299575806
Batch 52/64 loss: 1.7967054843902588
Batch 53/64 loss: 1.790374994277954
Batch 54/64 loss: 1.7895289659500122
Batch 55/64 loss: 1.791730284690857
Batch 56/64 loss: 1.7869775295257568
Batch 57/64 loss: 1.7926177978515625
Batch 58/64 loss: 1.7890739440917969
Batch 59/64 loss: 1.8026589155197144
Batch 60/64 loss: 1.790582537651062
Batch 61/64 loss: 1.8015083074569702
Batch 62/64 loss: 1.7961829900741577
Batch 63/64 loss: 1.8010121583938599
Batch 64/64 loss: 2.0180561542510986
Epoch 30  Train loss: 1.795533493453381  Val loss: 1.8309106589182955
Epoch 31
-------------------------------
Batch 1/64 loss: 1.8015893697738647
Batch 2/64 loss: 1.7900832891464233
Batch 3/64 loss: 1.792248249053955
Batch 4/64 loss: 1.7898657321929932
Batch 5/64 loss: 1.796785593032837
Batch 6/64 loss: 1.789896845817566
Batch 7/64 loss: 1.7860137224197388
Batch 8/64 loss: 1.7916735410690308
Batch 9/64 loss: 1.7927767038345337
Batch 10/64 loss: 1.7972925901412964
Batch 11/64 loss: 1.7931915521621704
Batch 12/64 loss: 1.7971060276031494
Batch 13/64 loss: 1.7954111099243164
Batch 14/64 loss: 1.7937109470367432
Batch 15/64 loss: 1.7916760444641113
Batch 16/64 loss: 1.7969249486923218
Batch 17/64 loss: 1.7925138473510742
Batch 18/64 loss: 1.794271469116211
Batch 19/64 loss: 1.7953152656555176
Batch 20/64 loss: 1.7954384088516235
Batch 21/64 loss: 1.7876898050308228
Batch 22/64 loss: 1.7908742427825928
Batch 23/64 loss: 1.7866538763046265
Batch 24/64 loss: 1.7833809852600098
Batch 25/64 loss: 1.7898963689804077
Batch 26/64 loss: 1.7868901491165161
Batch 27/64 loss: 1.7846851348876953
Batch 28/64 loss: 1.787672519683838
Batch 29/64 loss: 1.7918933629989624
Batch 30/64 loss: 1.7875391244888306
Batch 31/64 loss: 1.7824602127075195
Batch 32/64 loss: 1.790379285812378
Batch 33/64 loss: 1.7887580394744873
Batch 34/64 loss: 1.7894805669784546
Batch 35/64 loss: 1.7958823442459106
Batch 36/64 loss: 1.7899467945098877
Batch 37/64 loss: 1.7943593263626099
Batch 38/64 loss: 1.79068124294281
Batch 39/64 loss: 1.7925443649291992
Batch 40/64 loss: 1.7928298711776733
Batch 41/64 loss: 1.7987732887268066
Batch 42/64 loss: 1.7952030897140503
Batch 43/64 loss: 1.7927258014678955
Batch 44/64 loss: 1.8037139177322388
Batch 45/64 loss: 1.7978613376617432
Batch 46/64 loss: 1.790831208229065
Batch 47/64 loss: 1.7879819869995117
Batch 48/64 loss: 1.7880921363830566
Batch 49/64 loss: 1.79973304271698
Batch 50/64 loss: 1.7885290384292603
Batch 51/64 loss: 1.8036450147628784
Batch 52/64 loss: 1.7956225872039795
Batch 53/64 loss: 1.7860344648361206
Batch 54/64 loss: 1.7894984483718872
Batch 55/64 loss: 1.7898980379104614
Batch 56/64 loss: 1.7966810464859009
Batch 57/64 loss: 1.7854236364364624
Batch 58/64 loss: 1.788947343826294
Batch 59/64 loss: 1.8060040473937988
Batch 60/64 loss: 1.805327296257019
Batch 61/64 loss: 1.802777886390686
Batch 62/64 loss: 1.7931772470474243
Batch 63/64 loss: 1.7894513607025146
Batch 64/64 loss: 2.0165321826934814
Epoch 31  Train loss: 1.795241023979935  Val loss: 1.8313860401664812
Epoch 32
-------------------------------
Batch 1/64 loss: 1.7986021041870117
Batch 2/64 loss: 1.7974321842193604
Batch 3/64 loss: 1.8011764287948608
Batch 4/64 loss: 1.7947720289230347
Batch 5/64 loss: 1.791396975517273
Batch 6/64 loss: 1.7975432872772217
Batch 7/64 loss: 1.795676827430725
Batch 8/64 loss: 1.787388563156128
Batch 9/64 loss: 1.7857197523117065
Batch 10/64 loss: 1.791847825050354
Batch 11/64 loss: 1.7888623476028442
Batch 12/64 loss: 1.7908717393875122
Batch 13/64 loss: 1.7899645566940308
Batch 14/64 loss: 1.8009190559387207
Batch 15/64 loss: 1.7921395301818848
Batch 16/64 loss: 1.7873761653900146
Batch 17/64 loss: 1.788909912109375
Batch 18/64 loss: 1.8012981414794922
Batch 19/64 loss: 1.7906852960586548
Batch 20/64 loss: 1.795009732246399
Batch 21/64 loss: 1.7907902002334595
Batch 22/64 loss: 1.7941409349441528
Batch 23/64 loss: 1.799051284790039
Batch 24/64 loss: 1.792466640472412
Batch 25/64 loss: 1.7978843450546265
Batch 26/64 loss: 1.7955594062805176
Batch 27/64 loss: 1.7873634099960327
Batch 28/64 loss: 1.8082233667373657
Batch 29/64 loss: 1.798391342163086
Batch 30/64 loss: 1.7899152040481567
Batch 31/64 loss: 1.7878414392471313
Batch 32/64 loss: 1.7856523990631104
Batch 33/64 loss: 1.792140007019043
Batch 34/64 loss: 1.7927744388580322
Batch 35/64 loss: 1.806203842163086
Batch 36/64 loss: 1.78687584400177
Batch 37/64 loss: 1.789223551750183
Batch 38/64 loss: 1.7950315475463867
Batch 39/64 loss: 1.7873048782348633
Batch 40/64 loss: 1.7904391288757324
Batch 41/64 loss: 1.7862581014633179
Batch 42/64 loss: 1.7966325283050537
Batch 43/64 loss: 1.7866685390472412
Batch 44/64 loss: 1.792528510093689
Batch 45/64 loss: 1.7921026945114136
Batch 46/64 loss: 1.7858015298843384
Batch 47/64 loss: 1.7888085842132568
Batch 48/64 loss: 1.788543701171875
Batch 49/64 loss: 1.800736665725708
Batch 50/64 loss: 1.785126805305481
Batch 51/64 loss: 1.7870713472366333
Batch 52/64 loss: 1.784435749053955
Batch 53/64 loss: 1.787642240524292
Batch 54/64 loss: 1.789992094039917
Batch 55/64 loss: 1.7926476001739502
Batch 56/64 loss: 1.8147977590560913
Batch 57/64 loss: 1.7843401432037354
Batch 58/64 loss: 1.788090705871582
Batch 59/64 loss: 1.7934433221817017
Batch 60/64 loss: 1.789257526397705
Batch 61/64 loss: 1.7865592241287231
Batch 62/64 loss: 1.7843542098999023
Batch 63/64 loss: 1.7876044511795044
Batch 64/64 loss: 2.0137083530426025
Epoch 32  Train loss: 1.7948014268688126  Val loss: 1.8149923639199168
Saving best model, epoch: 32
Epoch 33
-------------------------------
Batch 1/64 loss: 1.7916676998138428
Batch 2/64 loss: 1.7864842414855957
Batch 3/64 loss: 1.7924073934555054
Batch 4/64 loss: 1.8009967803955078
Batch 5/64 loss: 1.7920832633972168
Batch 6/64 loss: 1.7903809547424316
Batch 7/64 loss: 1.7906739711761475
Batch 8/64 loss: 1.797416090965271
Batch 9/64 loss: 1.7894701957702637
Batch 10/64 loss: 1.790531873703003
Batch 11/64 loss: 1.790450930595398
Batch 12/64 loss: 1.7810909748077393
Batch 13/64 loss: 1.7971420288085938
Batch 14/64 loss: 1.792436122894287
Batch 15/64 loss: 1.7954282760620117
Batch 16/64 loss: 1.7928228378295898
Batch 17/64 loss: 1.7924106121063232
Batch 18/64 loss: 1.785668134689331
Batch 19/64 loss: 1.7868103981018066
Batch 20/64 loss: 1.7916641235351562
Batch 21/64 loss: 1.7944968938827515
Batch 22/64 loss: 1.7853766679763794
Batch 23/64 loss: 1.8066903352737427
Batch 24/64 loss: 1.787086009979248
Batch 25/64 loss: 1.787397861480713
Batch 26/64 loss: 1.795877456665039
Batch 27/64 loss: 1.7881903648376465
Batch 28/64 loss: 1.7923201322555542
Batch 29/64 loss: 1.7862035036087036
Batch 30/64 loss: 1.7878656387329102
Batch 31/64 loss: 1.7924281358718872
Batch 32/64 loss: 1.7867095470428467
Batch 33/64 loss: 1.7827112674713135
Batch 34/64 loss: 1.7950022220611572
Batch 35/64 loss: 1.7851686477661133
Batch 36/64 loss: 1.7832908630371094
Batch 37/64 loss: 1.7817323207855225
Batch 38/64 loss: 1.7847199440002441
Batch 39/64 loss: 1.7832022905349731
Batch 40/64 loss: 1.7866737842559814
Batch 41/64 loss: 1.786026120185852
Batch 42/64 loss: 1.7882715463638306
Batch 43/64 loss: 1.7871516942977905
Batch 44/64 loss: 1.785089135169983
Batch 45/64 loss: 1.7941460609436035
Batch 46/64 loss: 1.7866020202636719
Batch 47/64 loss: 1.7839105129241943
Batch 48/64 loss: 1.7915427684783936
Batch 49/64 loss: 1.7904917001724243
Batch 50/64 loss: 1.790177822113037
Batch 51/64 loss: 1.790684461593628
Batch 52/64 loss: 1.7857387065887451
Batch 53/64 loss: 1.7916781902313232
Batch 54/64 loss: 1.788494348526001
Batch 55/64 loss: 1.786668300628662
Batch 56/64 loss: 1.794142723083496
Batch 57/64 loss: 1.7917990684509277
Batch 58/64 loss: 1.7956736087799072
Batch 59/64 loss: 1.788495421409607
Batch 60/64 loss: 1.8034656047821045
Batch 61/64 loss: 1.7936996221542358
Batch 62/64 loss: 1.7951184511184692
Batch 63/64 loss: 1.8010284900665283
Batch 64/64 loss: 2.003234624862671
Epoch 33  Train loss: 1.7928424021776985  Val loss: 1.8205399201907653
Epoch 34
-------------------------------
Batch 1/64 loss: 1.7923959493637085
Batch 2/64 loss: 1.7945985794067383
Batch 3/64 loss: 1.7927982807159424
Batch 4/64 loss: 1.7990965843200684
Batch 5/64 loss: 1.7961995601654053
Batch 6/64 loss: 1.7902429103851318
Batch 7/64 loss: 1.7911388874053955
Batch 8/64 loss: 1.7898756265640259
Batch 9/64 loss: 1.7951171398162842
Batch 10/64 loss: 1.7878690958023071
Batch 11/64 loss: 1.7933783531188965
Batch 12/64 loss: 1.7810057401657104
Batch 13/64 loss: 1.7911235094070435
Batch 14/64 loss: 1.8043464422225952
Batch 15/64 loss: 1.7880359888076782
Batch 16/64 loss: 1.7919187545776367
Batch 17/64 loss: 1.7946715354919434
Batch 18/64 loss: 1.7896761894226074
Batch 19/64 loss: 1.7911077737808228
Batch 20/64 loss: 1.79194176197052
Batch 21/64 loss: 1.7840690612792969
Batch 22/64 loss: 1.789492130279541
Batch 23/64 loss: 1.797459363937378
Batch 24/64 loss: 1.7931634187698364
Batch 25/64 loss: 1.7837977409362793
Batch 26/64 loss: 1.782096266746521
Batch 27/64 loss: 1.7944614887237549
Batch 28/64 loss: 1.8056280612945557
Batch 29/64 loss: 1.7898166179656982
Batch 30/64 loss: 1.7977005243301392
Batch 31/64 loss: 1.7956223487854004
Batch 32/64 loss: 1.7924394607543945
Batch 33/64 loss: 1.79230535030365
Batch 34/64 loss: 1.8213088512420654
Batch 35/64 loss: 1.7926726341247559
Batch 36/64 loss: 1.7946308851242065
Batch 37/64 loss: 1.7917120456695557
Batch 38/64 loss: 1.7921218872070312
Batch 39/64 loss: 1.8271175622940063
Batch 40/64 loss: 1.7946968078613281
Batch 41/64 loss: 1.8021364212036133
Batch 42/64 loss: 1.8181231021881104
Batch 43/64 loss: 1.792445182800293
Batch 44/64 loss: 1.799391508102417
Batch 45/64 loss: 1.8097295761108398
Batch 46/64 loss: 1.8045780658721924
Batch 47/64 loss: 1.7943313121795654
Batch 48/64 loss: 1.8162221908569336
Batch 49/64 loss: 1.8405647277832031
Batch 50/64 loss: 1.8083980083465576
Batch 51/64 loss: 1.8029820919036865
Batch 52/64 loss: 1.7955713272094727
Batch 53/64 loss: 1.8004260063171387
Batch 54/64 loss: 1.7958160638809204
Batch 55/64 loss: 1.8189737796783447
Batch 56/64 loss: 1.7934998273849487
Batch 57/64 loss: 1.8010170459747314
Batch 58/64 loss: 1.8016654253005981
Batch 59/64 loss: 1.7953242063522339
Batch 60/64 loss: 1.8056225776672363
Batch 61/64 loss: 1.7967300415039062
Batch 62/64 loss: 1.803870677947998
Batch 63/64 loss: 1.7989845275878906
Batch 64/64 loss: 2.020676374435425
Epoch 34  Train loss: 1.8003256807140275  Val loss: 1.829714615320422
Epoch 35
-------------------------------
Batch 1/64 loss: 1.7957607507705688
Batch 2/64 loss: 1.8075858354568481
Batch 3/64 loss: 1.7949206829071045
Batch 4/64 loss: 1.7947475910186768
Batch 5/64 loss: 1.7940402030944824
Batch 6/64 loss: 1.79645574092865
Batch 7/64 loss: 1.791451334953308
Batch 8/64 loss: 1.7942818403244019
Batch 9/64 loss: 1.7918307781219482
Batch 10/64 loss: 1.8040820360183716
Batch 11/64 loss: 1.796442985534668
Batch 12/64 loss: 1.8000394105911255
Batch 13/64 loss: 1.79341459274292
Batch 14/64 loss: 1.8000081777572632
Batch 15/64 loss: 1.7957078218460083
Batch 16/64 loss: 1.7932491302490234
Batch 17/64 loss: 1.8142733573913574
Batch 18/64 loss: 1.788261890411377
Batch 19/64 loss: 1.795121669769287
Batch 20/64 loss: 1.7963404655456543
Batch 21/64 loss: 1.7971467971801758
Batch 22/64 loss: 1.7904551029205322
Batch 23/64 loss: 1.7941222190856934
Batch 24/64 loss: 1.7924494743347168
Batch 25/64 loss: 1.7868199348449707
Batch 26/64 loss: 1.7902783155441284
Batch 27/64 loss: 1.7942888736724854
Batch 28/64 loss: 1.7878122329711914
Batch 29/64 loss: 1.7838538885116577
Batch 30/64 loss: 1.7836414575576782
Batch 31/64 loss: 1.7887616157531738
Batch 32/64 loss: 1.797287106513977
Batch 33/64 loss: 1.8090672492980957
Batch 34/64 loss: 1.7907637357711792
Batch 35/64 loss: 1.785965085029602
Batch 36/64 loss: 1.7951524257659912
Batch 37/64 loss: 1.7912973165512085
Batch 38/64 loss: 1.787405252456665
Batch 39/64 loss: 1.8016067743301392
Batch 40/64 loss: 1.787306308746338
Batch 41/64 loss: 1.790004014968872
Batch 42/64 loss: 1.805220603942871
Batch 43/64 loss: 1.78988778591156
Batch 44/64 loss: 1.8074616193771362
Batch 45/64 loss: 1.8050525188446045
Batch 46/64 loss: 1.7883141040802002
Batch 47/64 loss: 1.7895410060882568
Batch 48/64 loss: 1.8047881126403809
Batch 49/64 loss: 1.7895262241363525
Batch 50/64 loss: 1.7867295742034912
Batch 51/64 loss: 1.790521264076233
Batch 52/64 loss: 1.800531029701233
Batch 53/64 loss: 1.7877424955368042
Batch 54/64 loss: 1.7913986444473267
Batch 55/64 loss: 1.786234736442566
Batch 56/64 loss: 1.7890756130218506
Batch 57/64 loss: 1.794232964515686
Batch 58/64 loss: 1.7981244325637817
Batch 59/64 loss: 1.7840590476989746
Batch 60/64 loss: 1.8011188507080078
Batch 61/64 loss: 1.789324402809143
Batch 62/64 loss: 1.7859361171722412
Batch 63/64 loss: 1.7876850366592407
Batch 64/64 loss: 2.0023913383483887
Epoch 35  Train loss: 1.7963576653424431  Val loss: 1.8164396933263929
Epoch 36
-------------------------------
Batch 1/64 loss: 1.787528157234192
Batch 2/64 loss: 1.8035292625427246
Batch 3/64 loss: 1.7936302423477173
Batch 4/64 loss: 1.7842358350753784
Batch 5/64 loss: 1.7906721830368042
Batch 6/64 loss: 1.7874767780303955
Batch 7/64 loss: 1.7946972846984863
Batch 8/64 loss: 1.7969545125961304
Batch 9/64 loss: 1.7924983501434326
Batch 10/64 loss: 1.7851098775863647
Batch 11/64 loss: 1.7906357049942017
Batch 12/64 loss: 1.7905080318450928
Batch 13/64 loss: 1.7852658033370972
Batch 14/64 loss: 1.7867690324783325
Batch 15/64 loss: 1.7822000980377197
Batch 16/64 loss: 1.7832993268966675
Batch 17/64 loss: 1.787778615951538
Batch 18/64 loss: 1.7927508354187012
Batch 19/64 loss: 1.785093069076538
Batch 20/64 loss: 1.7853965759277344
Batch 21/64 loss: 1.7892740964889526
Batch 22/64 loss: 1.7847168445587158
Batch 23/64 loss: 1.7829737663269043
Batch 24/64 loss: 1.7982677221298218
Batch 25/64 loss: 1.791266918182373
Batch 26/64 loss: 1.8000670671463013
Batch 27/64 loss: 1.7937517166137695
Batch 28/64 loss: 1.7943410873413086
Batch 29/64 loss: 1.7919743061065674
Batch 30/64 loss: 1.7845529317855835
Batch 31/64 loss: 1.7917776107788086
Batch 32/64 loss: 1.7849980592727661
Batch 33/64 loss: 1.8093942403793335
Batch 34/64 loss: 1.7886090278625488
Batch 35/64 loss: 1.7835115194320679
Batch 36/64 loss: 1.7870539426803589
Batch 37/64 loss: 1.7838211059570312
Batch 38/64 loss: 1.791784405708313
Batch 39/64 loss: 1.782352089881897
Batch 40/64 loss: 1.7877858877182007
Batch 41/64 loss: 1.7899744510650635
Batch 42/64 loss: 1.7830324172973633
Batch 43/64 loss: 1.7833929061889648
Batch 44/64 loss: 1.784917950630188
Batch 45/64 loss: 1.7868316173553467
Batch 46/64 loss: 1.7869772911071777
Batch 47/64 loss: 1.7870115041732788
Batch 48/64 loss: 1.7823623418807983
Batch 49/64 loss: 1.7860409021377563
Batch 50/64 loss: 1.783978819847107
Batch 51/64 loss: 1.7825102806091309
Batch 52/64 loss: 1.7820056676864624
Batch 53/64 loss: 1.7836904525756836
Batch 54/64 loss: 1.7824339866638184
Batch 55/64 loss: 1.7816016674041748
Batch 56/64 loss: 1.793190360069275
Batch 57/64 loss: 1.7869055271148682
Batch 58/64 loss: 1.7824383974075317
Batch 59/64 loss: 1.790144443511963
Batch 60/64 loss: 1.7889094352722168
Batch 61/64 loss: 1.7828049659729004
Batch 62/64 loss: 1.7802586555480957
Batch 63/64 loss: 1.788790225982666
Batch 64/64 loss: 2.0024242401123047
Epoch 36  Train loss: 1.7905933548422421  Val loss: 1.8078645258834682
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: 1.7883474826812744
Batch 2/64 loss: 1.7840793132781982
Batch 3/64 loss: 1.7916167974472046
Batch 4/64 loss: 1.7818307876586914
Batch 5/64 loss: 1.7914760112762451
Batch 6/64 loss: 1.7859336137771606
Batch 7/64 loss: 1.7899680137634277
Batch 8/64 loss: 1.781453013420105
Batch 9/64 loss: 1.7853879928588867
Batch 10/64 loss: 1.7825596332550049
Batch 11/64 loss: 1.7830480337142944
Batch 12/64 loss: 1.787327527999878
Batch 13/64 loss: 1.782122015953064
Batch 14/64 loss: 1.7825032472610474
Batch 15/64 loss: 1.7839596271514893
Batch 16/64 loss: 1.7839781045913696
Batch 17/64 loss: 1.7910795211791992
Batch 18/64 loss: 1.7855929136276245
Batch 19/64 loss: 1.7813136577606201
Batch 20/64 loss: 1.7774498462677002
Batch 21/64 loss: 1.7804447412490845
Batch 22/64 loss: 1.7880845069885254
Batch 23/64 loss: 1.7930079698562622
Batch 24/64 loss: 1.7787463665008545
Batch 25/64 loss: 1.7837417125701904
Batch 26/64 loss: 1.7844794988632202
Batch 27/64 loss: 1.790546178817749
Batch 28/64 loss: 1.7833219766616821
Batch 29/64 loss: 1.798834204673767
Batch 30/64 loss: 1.780402660369873
Batch 31/64 loss: 1.7826319932937622
Batch 32/64 loss: 1.783860683441162
Batch 33/64 loss: 1.7829036712646484
Batch 34/64 loss: 1.7845226526260376
Batch 35/64 loss: 1.7850122451782227
Batch 36/64 loss: 1.7827039957046509
Batch 37/64 loss: 1.7990256547927856
Batch 38/64 loss: 1.7884196043014526
Batch 39/64 loss: 1.7868330478668213
Batch 40/64 loss: 1.7801735401153564
Batch 41/64 loss: 1.7790294885635376
Batch 42/64 loss: 1.7858970165252686
Batch 43/64 loss: 1.7856827974319458
Batch 44/64 loss: 1.7905802726745605
Batch 45/64 loss: 1.7888381481170654
Batch 46/64 loss: 1.804161548614502
Batch 47/64 loss: 1.7796399593353271
Batch 48/64 loss: 1.7837074995040894
Batch 49/64 loss: 1.7851066589355469
Batch 50/64 loss: 1.7879104614257812
Batch 51/64 loss: 1.7849349975585938
Batch 52/64 loss: 1.7882015705108643
Batch 53/64 loss: 1.7824828624725342
Batch 54/64 loss: 1.7864090204238892
Batch 55/64 loss: 1.7843728065490723
Batch 56/64 loss: 1.7866977453231812
Batch 57/64 loss: 1.7855947017669678
Batch 58/64 loss: 1.792208194732666
Batch 59/64 loss: 1.7876851558685303
Batch 60/64 loss: 1.7825992107391357
Batch 61/64 loss: 1.7795748710632324
Batch 62/64 loss: 1.7879538536071777
Batch 63/64 loss: 1.7837598323822021
Batch 64/64 loss: 1.9971332550048828
Epoch 37  Train loss: 1.788229061575497  Val loss: 1.8054667961146824
Saving best model, epoch: 37
Epoch 38
-------------------------------
Batch 1/64 loss: 1.7866568565368652
Batch 2/64 loss: 1.793007493019104
Batch 3/64 loss: 1.7884949445724487
Batch 4/64 loss: 1.7848684787750244
Batch 5/64 loss: 1.7801260948181152
Batch 6/64 loss: 1.7848373651504517
Batch 7/64 loss: 1.7841906547546387
Batch 8/64 loss: 1.7967112064361572
Batch 9/64 loss: 1.7909809350967407
Batch 10/64 loss: 1.7848753929138184
Batch 11/64 loss: 1.7843466997146606
Batch 12/64 loss: 1.7884492874145508
Batch 13/64 loss: 1.7871227264404297
Batch 14/64 loss: 1.782342553138733
Batch 15/64 loss: 1.787186622619629
Batch 16/64 loss: 1.7864506244659424
Batch 17/64 loss: 1.7848937511444092
Batch 18/64 loss: 1.787634253501892
Batch 19/64 loss: 1.789707899093628
Batch 20/64 loss: 1.7801777124404907
Batch 21/64 loss: 1.7927974462509155
Batch 22/64 loss: 1.7886433601379395
Batch 23/64 loss: 1.7892380952835083
Batch 24/64 loss: 1.7881077527999878
Batch 25/64 loss: 1.7870070934295654
Batch 26/64 loss: 1.7874301671981812
Batch 27/64 loss: 1.780454158782959
Batch 28/64 loss: 1.783811330795288
Batch 29/64 loss: 1.7878729104995728
Batch 30/64 loss: 1.7843347787857056
Batch 31/64 loss: 1.790388822555542
Batch 32/64 loss: 1.784165859222412
Batch 33/64 loss: 1.7882460355758667
Batch 34/64 loss: 1.7805979251861572
Batch 35/64 loss: 1.7793173789978027
Batch 36/64 loss: 1.784846305847168
Batch 37/64 loss: 1.7796670198440552
Batch 38/64 loss: 1.7844607830047607
Batch 39/64 loss: 1.7827316522598267
Batch 40/64 loss: 1.7860156297683716
Batch 41/64 loss: 1.7848985195159912
Batch 42/64 loss: 1.7959526777267456
Batch 43/64 loss: 1.7846148014068604
Batch 44/64 loss: 1.789275884628296
Batch 45/64 loss: 1.7843278646469116
Batch 46/64 loss: 1.783560872077942
Batch 47/64 loss: 1.7845585346221924
Batch 48/64 loss: 1.784764051437378
Batch 49/64 loss: 1.7804241180419922
Batch 50/64 loss: 1.790777564048767
Batch 51/64 loss: 1.784447431564331
Batch 52/64 loss: 1.7911213636398315
Batch 53/64 loss: 1.7879972457885742
Batch 54/64 loss: 1.780238151550293
Batch 55/64 loss: 1.7910264730453491
Batch 56/64 loss: 1.781569480895996
Batch 57/64 loss: 1.7820229530334473
Batch 58/64 loss: 1.7866188287734985
Batch 59/64 loss: 1.7870922088623047
Batch 60/64 loss: 1.7843959331512451
Batch 61/64 loss: 1.7901859283447266
Batch 62/64 loss: 1.785430669784546
Batch 63/64 loss: 1.7823396921157837
Batch 64/64 loss: 1.9979586601257324
Epoch 38  Train loss: 1.788538138071696  Val loss: 1.8128060516213225
Epoch 39
-------------------------------
Batch 1/64 loss: 1.784784197807312
Batch 2/64 loss: 1.7822332382202148
Batch 3/64 loss: 1.7904112339019775
Batch 4/64 loss: 1.7827012538909912
Batch 5/64 loss: 1.7810007333755493
Batch 6/64 loss: 1.7902860641479492
Batch 7/64 loss: 1.7786993980407715
Batch 8/64 loss: 1.7923402786254883
Batch 9/64 loss: 1.7865219116210938
Batch 10/64 loss: 1.779386281967163
Batch 11/64 loss: 1.7891865968704224
Batch 12/64 loss: 1.7882262468338013
Batch 13/64 loss: 1.7827279567718506
Batch 14/64 loss: 1.786623239517212
Batch 15/64 loss: 1.8077220916748047
Batch 16/64 loss: 1.7870539426803589
Batch 17/64 loss: 1.7968523502349854
Batch 18/64 loss: 1.7907605171203613
Batch 19/64 loss: 1.785625696182251
Batch 20/64 loss: 1.8036483526229858
Batch 21/64 loss: 1.7887600660324097
Batch 22/64 loss: 1.7899765968322754
Batch 23/64 loss: 1.789353609085083
Batch 24/64 loss: 1.7960138320922852
Batch 25/64 loss: 1.7907308340072632
Batch 26/64 loss: 1.781778335571289
Batch 27/64 loss: 1.7875702381134033
Batch 28/64 loss: 1.7869627475738525
Batch 29/64 loss: 1.7819910049438477
Batch 30/64 loss: 1.7830175161361694
Batch 31/64 loss: 1.7940012216567993
Batch 32/64 loss: 1.7841134071350098
Batch 33/64 loss: 1.7888574600219727
Batch 34/64 loss: 1.7911527156829834
Batch 35/64 loss: 1.7919847965240479
Batch 36/64 loss: 1.808889389038086
Batch 37/64 loss: 1.786879539489746
Batch 38/64 loss: 1.7890704870224
Batch 39/64 loss: 1.7908885478973389
Batch 40/64 loss: 1.7942767143249512
Batch 41/64 loss: 1.8026878833770752
Batch 42/64 loss: 1.7902642488479614
Batch 43/64 loss: 1.7886078357696533
Batch 44/64 loss: 1.7900394201278687
Batch 45/64 loss: 1.7874141931533813
Batch 46/64 loss: 1.7941854000091553
Batch 47/64 loss: 1.7865153551101685
Batch 48/64 loss: 1.7896344661712646
Batch 49/64 loss: 1.8019554615020752
Batch 50/64 loss: 1.7923272848129272
Batch 51/64 loss: 1.8000140190124512
Batch 52/64 loss: 1.7853537797927856
Batch 53/64 loss: 1.7975581884384155
Batch 54/64 loss: 1.795413851737976
Batch 55/64 loss: 1.785326361656189
Batch 56/64 loss: 1.7929818630218506
Batch 57/64 loss: 1.801803469657898
Batch 58/64 loss: 1.7858569622039795
Batch 59/64 loss: 1.7857048511505127
Batch 60/64 loss: 1.793975591659546
Batch 61/64 loss: 1.7815806865692139
Batch 62/64 loss: 1.7933269739151
Batch 63/64 loss: 1.7827441692352295
Batch 64/64 loss: 2.012786388397217
Epoch 39  Train loss: 1.792594866659127  Val loss: 1.8142084084015941
Epoch 40
-------------------------------
Batch 1/64 loss: 1.7917639017105103
Batch 2/64 loss: 1.7928143739700317
Batch 3/64 loss: 1.7867622375488281
Batch 4/64 loss: 1.7873711585998535
Batch 5/64 loss: 1.7961004972457886
Batch 6/64 loss: 1.7935267686843872
Batch 7/64 loss: 1.782698154449463
Batch 8/64 loss: 1.780299186706543
Batch 9/64 loss: 1.7826201915740967
Batch 10/64 loss: 1.7823346853256226
Batch 11/64 loss: 1.797257661819458
Batch 12/64 loss: 1.783922553062439
Batch 13/64 loss: 1.7860300540924072
Batch 14/64 loss: 1.801134467124939
Batch 15/64 loss: 1.7891035079956055
Batch 16/64 loss: 1.7825407981872559
Batch 17/64 loss: 1.7837116718292236
Batch 18/64 loss: 1.784044861793518
Batch 19/64 loss: 1.7824978828430176
Batch 20/64 loss: 1.7961533069610596
Batch 21/64 loss: 1.7841429710388184
Batch 22/64 loss: 1.7909902334213257
Batch 23/64 loss: 1.780698299407959
Batch 24/64 loss: 1.7779219150543213
Batch 25/64 loss: 1.7816784381866455
Batch 26/64 loss: 1.7860918045043945
Batch 27/64 loss: 1.7816712856292725
Batch 28/64 loss: 1.7840609550476074
Batch 29/64 loss: 1.7784619331359863
Batch 30/64 loss: 1.7899008989334106
Batch 31/64 loss: 1.7880464792251587
Batch 32/64 loss: 1.783621072769165
Batch 33/64 loss: 1.7875299453735352
Batch 34/64 loss: 1.7881840467453003
Batch 35/64 loss: 1.781774640083313
Batch 36/64 loss: 1.7876546382904053
Batch 37/64 loss: 1.786403775215149
Batch 38/64 loss: 1.7805474996566772
Batch 39/64 loss: 1.7830252647399902
Batch 40/64 loss: 1.7819797992706299
Batch 41/64 loss: 1.7890000343322754
Batch 42/64 loss: 1.7854522466659546
Batch 43/64 loss: 1.7827812433242798
Batch 44/64 loss: 1.7917308807373047
Batch 45/64 loss: 1.7870784997940063
Batch 46/64 loss: 1.78324556350708
Batch 47/64 loss: 1.7840161323547363
Batch 48/64 loss: 1.790627360343933
Batch 49/64 loss: 1.7844148874282837
Batch 50/64 loss: 1.7841014862060547
Batch 51/64 loss: 1.7797586917877197
Batch 52/64 loss: 1.7835183143615723
Batch 53/64 loss: 1.7989261150360107
Batch 54/64 loss: 1.78569757938385
Batch 55/64 loss: 1.8012272119522095
Batch 56/64 loss: 1.8079135417938232
Batch 57/64 loss: 1.7892779111862183
Batch 58/64 loss: 1.7849514484405518
Batch 59/64 loss: 1.7851682901382446
Batch 60/64 loss: 1.7897422313690186
Batch 61/64 loss: 1.7864737510681152
Batch 62/64 loss: 1.7827260494232178
Batch 63/64 loss: 1.7861487865447998
Batch 64/64 loss: 1.9984828233718872
Epoch 40  Train loss: 1.789331987324883  Val loss: 1.8166973459761577
Epoch 41
-------------------------------
Batch 1/64 loss: 1.7865910530090332
Batch 2/64 loss: 1.7824890613555908
Batch 3/64 loss: 1.7988486289978027
Batch 4/64 loss: 1.7846593856811523
Batch 5/64 loss: 1.785566806793213
Batch 6/64 loss: 1.7816383838653564
Batch 7/64 loss: 1.786805510520935
Batch 8/64 loss: 1.7882415056228638
Batch 9/64 loss: 1.7820223569869995
Batch 10/64 loss: 1.78176748752594
Batch 11/64 loss: 1.78799307346344
Batch 12/64 loss: 1.7839183807373047
Batch 13/64 loss: 1.7809879779815674
Batch 14/64 loss: 1.7838082313537598
Batch 15/64 loss: 1.7866709232330322
Batch 16/64 loss: 1.7972054481506348
Batch 17/64 loss: 1.7955573797225952
Batch 18/64 loss: 1.8011515140533447
Batch 19/64 loss: 1.7799495458602905
Batch 20/64 loss: 1.7840605974197388
Batch 21/64 loss: 1.7863719463348389
Batch 22/64 loss: 1.7887983322143555
Batch 23/64 loss: 1.7843868732452393
Batch 24/64 loss: 1.782659888267517
Batch 25/64 loss: 1.7839605808258057
Batch 26/64 loss: 1.788405418395996
Batch 27/64 loss: 1.7875624895095825
Batch 28/64 loss: 1.7843058109283447
Batch 29/64 loss: 1.789315104484558
Batch 30/64 loss: 1.7856907844543457
Batch 31/64 loss: 1.7833715677261353
Batch 32/64 loss: 1.7786518335342407
Batch 33/64 loss: 1.7799843549728394
Batch 34/64 loss: 1.7820277214050293
Batch 35/64 loss: 1.7901630401611328
Batch 36/64 loss: 1.7820078134536743
Batch 37/64 loss: 1.782957911491394
Batch 38/64 loss: 1.7889645099639893
Batch 39/64 loss: 1.795872688293457
Batch 40/64 loss: 1.7808208465576172
Batch 41/64 loss: 1.7841122150421143
Batch 42/64 loss: 1.7833836078643799
Batch 43/64 loss: 1.7827510833740234
Batch 44/64 loss: 1.785489559173584
Batch 45/64 loss: 1.781150221824646
Batch 46/64 loss: 1.7821521759033203
Batch 47/64 loss: 1.7861520051956177
Batch 48/64 loss: 1.7876038551330566
Batch 49/64 loss: 1.7848602533340454
Batch 50/64 loss: 1.7874932289123535
Batch 51/64 loss: 1.782676339149475
Batch 52/64 loss: 1.7884771823883057
Batch 53/64 loss: 1.7887966632843018
Batch 54/64 loss: 1.7830308675765991
Batch 55/64 loss: 1.7804388999938965
Batch 56/64 loss: 1.783205509185791
Batch 57/64 loss: 1.7797763347625732
Batch 58/64 loss: 1.7915780544281006
Batch 59/64 loss: 1.781114101409912
Batch 60/64 loss: 1.7808544635772705
Batch 61/64 loss: 1.7870972156524658
Batch 62/64 loss: 1.7850171327590942
Batch 63/64 loss: 1.78233802318573
Batch 64/64 loss: 1.9953001737594604
Epoch 41  Train loss: 1.7879566571291756  Val loss: 1.8023558556009405
Saving best model, epoch: 41
Epoch 42
-------------------------------
Batch 1/64 loss: 1.784639835357666
Batch 2/64 loss: 1.7772917747497559
Batch 3/64 loss: 1.7890346050262451
Batch 4/64 loss: 1.7946817874908447
Batch 5/64 loss: 1.7797267436981201
Batch 6/64 loss: 1.784764051437378
Batch 7/64 loss: 1.7819410562515259
Batch 8/64 loss: 1.7831182479858398
Batch 9/64 loss: 1.7790004014968872
Batch 10/64 loss: 1.7824976444244385
Batch 11/64 loss: 1.7877731323242188
Batch 12/64 loss: 1.7805542945861816
Batch 13/64 loss: 1.7784664630889893
Batch 14/64 loss: 1.7807644605636597
Batch 15/64 loss: 1.7798222303390503
Batch 16/64 loss: 1.7863720655441284
Batch 17/64 loss: 1.789872646331787
Batch 18/64 loss: 1.7818998098373413
Batch 19/64 loss: 1.8048945665359497
Batch 20/64 loss: 1.7857353687286377
Batch 21/64 loss: 1.7889018058776855
Batch 22/64 loss: 1.7801669836044312
Batch 23/64 loss: 1.781001091003418
Batch 24/64 loss: 1.7825926542282104
Batch 25/64 loss: 1.782197117805481
Batch 26/64 loss: 1.7813419103622437
Batch 27/64 loss: 1.779295563697815
Batch 28/64 loss: 1.7766093015670776
Batch 29/64 loss: 1.7839713096618652
Batch 30/64 loss: 1.777230978012085
Batch 31/64 loss: 1.7793091535568237
Batch 32/64 loss: 1.7809545993804932
Batch 33/64 loss: 1.779430866241455
Batch 34/64 loss: 1.7765440940856934
Batch 35/64 loss: 1.7799584865570068
Batch 36/64 loss: 1.7789610624313354
Batch 37/64 loss: 1.7796339988708496
Batch 38/64 loss: 1.780969262123108
Batch 39/64 loss: 1.783698558807373
Batch 40/64 loss: 1.784856915473938
Batch 41/64 loss: 1.7871830463409424
Batch 42/64 loss: 1.7864162921905518
Batch 43/64 loss: 1.7984590530395508
Batch 44/64 loss: 1.7798658609390259
Batch 45/64 loss: 1.7828956842422485
Batch 46/64 loss: 1.7977361679077148
Batch 47/64 loss: 1.780295491218567
Batch 48/64 loss: 1.7769103050231934
Batch 49/64 loss: 1.7842950820922852
Batch 50/64 loss: 1.779692530632019
Batch 51/64 loss: 1.7835983037948608
Batch 52/64 loss: 1.7875654697418213
Batch 53/64 loss: 1.7793062925338745
Batch 54/64 loss: 1.7930320501327515
Batch 55/64 loss: 1.7837326526641846
Batch 56/64 loss: 1.7898755073547363
Batch 57/64 loss: 1.7867379188537598
Batch 58/64 loss: 1.7812851667404175
Batch 59/64 loss: 1.7815519571304321
Batch 60/64 loss: 1.7828669548034668
Batch 61/64 loss: 1.7835404872894287
Batch 62/64 loss: 1.7772104740142822
Batch 63/64 loss: 1.77573561668396
Batch 64/64 loss: 1.9968504905700684
Epoch 42  Train loss: 1.7858494609009985  Val loss: 1.811929800256421
Epoch 43
-------------------------------
Batch 1/64 loss: 1.7870758771896362
Batch 2/64 loss: 1.7832238674163818
Batch 3/64 loss: 1.7821718454360962
Batch 4/64 loss: 1.7854721546173096
Batch 5/64 loss: 1.7870500087738037
Batch 6/64 loss: 1.790116786956787
Batch 7/64 loss: 1.7840323448181152
Batch 8/64 loss: 1.782019853591919
Batch 9/64 loss: 1.780394196510315
Batch 10/64 loss: 1.778762936592102
Batch 11/64 loss: 1.7807174921035767
Batch 12/64 loss: 1.7798210382461548
Batch 13/64 loss: 1.7810405492782593
Batch 14/64 loss: 1.785190224647522
Batch 15/64 loss: 1.7853949069976807
Batch 16/64 loss: 1.77997624874115
Batch 17/64 loss: 1.7812507152557373
Batch 18/64 loss: 1.7871372699737549
Batch 19/64 loss: 1.7758598327636719
Batch 20/64 loss: 1.781583547592163
Batch 21/64 loss: 1.7813960313796997
Batch 22/64 loss: 1.7766199111938477
Batch 23/64 loss: 1.780692458152771
Batch 24/64 loss: 1.778192400932312
Batch 25/64 loss: 1.7919838428497314
Batch 26/64 loss: 1.7772011756896973
Batch 27/64 loss: 1.7865232229232788
Batch 28/64 loss: 1.7792364358901978
Batch 29/64 loss: 1.7752163410186768
Batch 30/64 loss: 1.7809298038482666
Batch 31/64 loss: 1.7957828044891357
Batch 32/64 loss: 1.7790508270263672
Batch 33/64 loss: 1.7759792804718018
Batch 34/64 loss: 1.778566598892212
Batch 35/64 loss: 1.7777807712554932
Batch 36/64 loss: 1.7779210805892944
Batch 37/64 loss: 1.777654767036438
Batch 38/64 loss: 1.7819809913635254
Batch 39/64 loss: 1.7844105958938599
Batch 40/64 loss: 1.7810468673706055
Batch 41/64 loss: 1.7901965379714966
Batch 42/64 loss: 1.7784483432769775
Batch 43/64 loss: 1.783536672592163
Batch 44/64 loss: 1.7790706157684326
Batch 45/64 loss: 1.7827627658843994
Batch 46/64 loss: 1.7787995338439941
Batch 47/64 loss: 1.7836928367614746
Batch 48/64 loss: 1.7921544313430786
Batch 49/64 loss: 1.7808674573898315
Batch 50/64 loss: 1.7820827960968018
Batch 51/64 loss: 1.7771568298339844
Batch 52/64 loss: 1.7806810140609741
Batch 53/64 loss: 1.8035626411437988
Batch 54/64 loss: 1.7853028774261475
Batch 55/64 loss: 1.7823076248168945
Batch 56/64 loss: 1.7847355604171753
Batch 57/64 loss: 1.789170503616333
Batch 58/64 loss: 1.787675142288208
Batch 59/64 loss: 1.774145483970642
Batch 60/64 loss: 1.7770410776138306
Batch 61/64 loss: 1.7918195724487305
Batch 62/64 loss: 1.7850110530853271
Batch 63/64 loss: 1.7782914638519287
Batch 64/64 loss: 1.997704029083252
Epoch 43  Train loss: 1.7851490002052457  Val loss: 1.8139776159397925
Epoch 44
-------------------------------
Batch 1/64 loss: 1.7850568294525146
Batch 2/64 loss: 1.8011356592178345
Batch 3/64 loss: 1.7815074920654297
Batch 4/64 loss: 1.7822644710540771
Batch 5/64 loss: 1.7868582010269165
Batch 6/64 loss: 1.7871395349502563
Batch 7/64 loss: 1.7850091457366943
Batch 8/64 loss: 1.7880274057388306
Batch 9/64 loss: 1.7825024127960205
Batch 10/64 loss: 1.7917613983154297
Batch 11/64 loss: 1.7863523960113525
Batch 12/64 loss: 1.7859632968902588
Batch 13/64 loss: 1.7828689813613892
Batch 14/64 loss: 1.7850451469421387
Batch 15/64 loss: 1.7834994792938232
Batch 16/64 loss: 1.776611328125
Batch 17/64 loss: 1.7796231508255005
Batch 18/64 loss: 1.7849066257476807
Batch 19/64 loss: 1.783326506614685
Batch 20/64 loss: 1.7848501205444336
Batch 21/64 loss: 1.785760760307312
Batch 22/64 loss: 1.7845134735107422
Batch 23/64 loss: 1.7851803302764893
Batch 24/64 loss: 1.779563307762146
Batch 25/64 loss: 1.7787349224090576
Batch 26/64 loss: 1.7793922424316406
Batch 27/64 loss: 1.7759863138198853
Batch 28/64 loss: 1.7799311876296997
Batch 29/64 loss: 1.7829371690750122
Batch 30/64 loss: 1.7740099430084229
Batch 31/64 loss: 1.7798084020614624
Batch 32/64 loss: 1.7827019691467285
Batch 33/64 loss: 1.7764623165130615
Batch 34/64 loss: 1.78158700466156
Batch 35/64 loss: 1.7782981395721436
Batch 36/64 loss: 1.7962148189544678
Batch 37/64 loss: 1.7810168266296387
Batch 38/64 loss: 1.7815314531326294
Batch 39/64 loss: 1.7809338569641113
Batch 40/64 loss: 1.7887614965438843
Batch 41/64 loss: 1.7810368537902832
Batch 42/64 loss: 1.7829455137252808
Batch 43/64 loss: 1.7812131643295288
Batch 44/64 loss: 1.780407190322876
Batch 45/64 loss: 1.776702880859375
Batch 46/64 loss: 1.774590253829956
Batch 47/64 loss: 1.7831131219863892
Batch 48/64 loss: 1.7800637483596802
Batch 49/64 loss: 1.7752448320388794
Batch 50/64 loss: 1.783730149269104
Batch 51/64 loss: 1.7766660451889038
Batch 52/64 loss: 1.7780132293701172
Batch 53/64 loss: 1.776827096939087
Batch 54/64 loss: 1.801816701889038
Batch 55/64 loss: 1.7879365682601929
Batch 56/64 loss: 1.7775697708129883
Batch 57/64 loss: 1.7784334421157837
Batch 58/64 loss: 1.7818384170532227
Batch 59/64 loss: 1.7796275615692139
Batch 60/64 loss: 1.7877799272537231
Batch 61/64 loss: 1.783329963684082
Batch 62/64 loss: 1.7753850221633911
Batch 63/64 loss: 1.7789478302001953
Batch 64/64 loss: 1.996404767036438
Epoch 44  Train loss: 1.7850691510181802  Val loss: 1.8093290705861096
Epoch 45
-------------------------------
Batch 1/64 loss: 1.7835897207260132
Batch 2/64 loss: 1.7837796211242676
Batch 3/64 loss: 1.7851817607879639
Batch 4/64 loss: 1.790847897529602
Batch 5/64 loss: 1.7750000953674316
Batch 6/64 loss: 1.7925575971603394
Batch 7/64 loss: 1.779590368270874
Batch 8/64 loss: 1.7784143686294556
Batch 9/64 loss: 1.7762645483016968
Batch 10/64 loss: 1.7938883304595947
Batch 11/64 loss: 1.7770885229110718
Batch 12/64 loss: 1.7838281393051147
Batch 13/64 loss: 1.777285099029541
Batch 14/64 loss: 1.7786922454833984
Batch 15/64 loss: 1.7776098251342773
Batch 16/64 loss: 1.7821558713912964
Batch 17/64 loss: 1.785794734954834
Batch 18/64 loss: 1.7783534526824951
Batch 19/64 loss: 1.7786900997161865
Batch 20/64 loss: 1.7780417203903198
Batch 21/64 loss: 1.77675461769104
Batch 22/64 loss: 1.7743536233901978
Batch 23/64 loss: 1.7768659591674805
Batch 24/64 loss: 1.781044363975525
Batch 25/64 loss: 1.7815320491790771
Batch 26/64 loss: 1.780705213546753
Batch 27/64 loss: 1.7827568054199219
Batch 28/64 loss: 1.790938377380371
Batch 29/64 loss: 1.777034044265747
Batch 30/64 loss: 1.7762296199798584
Batch 31/64 loss: 1.7766934633255005
Batch 32/64 loss: 1.7774887084960938
Batch 33/64 loss: 1.7774415016174316
Batch 34/64 loss: 1.78447425365448
Batch 35/64 loss: 1.780956506729126
Batch 36/64 loss: 1.7793055772781372
Batch 37/64 loss: 1.7784980535507202
Batch 38/64 loss: 1.7765390872955322
Batch 39/64 loss: 1.7761874198913574
Batch 40/64 loss: 1.7815500497817993
Batch 41/64 loss: 1.7810325622558594
Batch 42/64 loss: 1.7869452238082886
Batch 43/64 loss: 1.7802098989486694
Batch 44/64 loss: 1.790290355682373
Batch 45/64 loss: 1.777710199356079
Batch 46/64 loss: 1.7778751850128174
Batch 47/64 loss: 1.7774523496627808
Batch 48/64 loss: 1.781853199005127
Batch 49/64 loss: 1.7799322605133057
Batch 50/64 loss: 1.7789020538330078
Batch 51/64 loss: 1.777483582496643
Batch 52/64 loss: 1.7852137088775635
Batch 53/64 loss: 1.7839584350585938
Batch 54/64 loss: 1.776831865310669
Batch 55/64 loss: 1.7787182331085205
Batch 56/64 loss: 1.7961413860321045
Batch 57/64 loss: 1.78178071975708
Batch 58/64 loss: 1.7798078060150146
Batch 59/64 loss: 1.7796604633331299
Batch 60/64 loss: 1.7891461849212646
Batch 61/64 loss: 1.7876858711242676
Batch 62/64 loss: 1.7807509899139404
Batch 63/64 loss: 1.7817425727844238
Batch 64/64 loss: 1.997015357017517
Epoch 45  Train loss: 1.7837316068948483  Val loss: 1.8147863112774092
Epoch 46
-------------------------------
Batch 1/64 loss: 1.7772536277770996
Batch 2/64 loss: 1.7846571207046509
Batch 3/64 loss: 1.7885197401046753
Batch 4/64 loss: 1.7782570123672485
Batch 5/64 loss: 1.7786006927490234
Batch 6/64 loss: 1.7774611711502075
Batch 7/64 loss: 1.791691541671753
Batch 8/64 loss: 1.7796430587768555
Batch 9/64 loss: 1.7789229154586792
Batch 10/64 loss: 1.7756445407867432
Batch 11/64 loss: 1.7802070379257202
Batch 12/64 loss: 1.776305913925171
Batch 13/64 loss: 1.7756507396697998
Batch 14/64 loss: 1.7753087282180786
Batch 15/64 loss: 1.785940408706665
Batch 16/64 loss: 1.7782399654388428
Batch 17/64 loss: 1.7783243656158447
Batch 18/64 loss: 1.7720153331756592
Batch 19/64 loss: 1.7763773202896118
Batch 20/64 loss: 1.7771753072738647
Batch 21/64 loss: 1.7822664976119995
Batch 22/64 loss: 1.7777140140533447
Batch 23/64 loss: 1.7810715436935425
Batch 24/64 loss: 1.7934285402297974
Batch 25/64 loss: 1.779840350151062
Batch 26/64 loss: 1.7895166873931885
Batch 27/64 loss: 1.7798106670379639
Batch 28/64 loss: 1.7804323434829712
Batch 29/64 loss: 1.7832552194595337
Batch 30/64 loss: 1.7765604257583618
Batch 31/64 loss: 1.7831108570098877
Batch 32/64 loss: 1.7818903923034668
Batch 33/64 loss: 1.7779498100280762
Batch 34/64 loss: 1.7763819694519043
Batch 35/64 loss: 1.7818844318389893
Batch 36/64 loss: 1.7756458520889282
Batch 37/64 loss: 1.7774982452392578
Batch 38/64 loss: 1.7762229442596436
Batch 39/64 loss: 1.7766828536987305
Batch 40/64 loss: 1.7824516296386719
Batch 41/64 loss: 1.7786871194839478
Batch 42/64 loss: 1.7936358451843262
Batch 43/64 loss: 1.7809115648269653
Batch 44/64 loss: 1.775928020477295
Batch 45/64 loss: 1.7793970108032227
Batch 46/64 loss: 1.7843619585037231
Batch 47/64 loss: 1.7749749422073364
Batch 48/64 loss: 1.7826826572418213
Batch 49/64 loss: 1.7811286449432373
Batch 50/64 loss: 1.775888442993164
Batch 51/64 loss: 1.7752879858016968
Batch 52/64 loss: 1.7846426963806152
Batch 53/64 loss: 1.7792351245880127
Batch 54/64 loss: 1.7760206460952759
Batch 55/64 loss: 1.7788046598434448
Batch 56/64 loss: 1.7965209484100342
Batch 57/64 loss: 1.7799715995788574
Batch 58/64 loss: 1.7779947519302368
Batch 59/64 loss: 1.7803151607513428
Batch 60/64 loss: 1.7754089832305908
Batch 61/64 loss: 1.7793279886245728
Batch 62/64 loss: 1.7866681814193726
Batch 63/64 loss: 1.7767349481582642
Batch 64/64 loss: 2.001962184906006
Epoch 46  Train loss: 1.7828362876293706  Val loss: 1.8305812496499918
Epoch 47
-------------------------------
Batch 1/64 loss: 1.780897617340088
Batch 2/64 loss: 1.7864998579025269
Batch 3/64 loss: 1.7867478132247925
Batch 4/64 loss: 1.7870042324066162
Batch 5/64 loss: 1.7911375761032104
Batch 6/64 loss: 1.7950395345687866
Batch 7/64 loss: 1.8119691610336304
Batch 8/64 loss: 1.7836823463439941
Batch 9/64 loss: 1.7769222259521484
Batch 10/64 loss: 1.7792800664901733
Batch 11/64 loss: 1.7811470031738281
Batch 12/64 loss: 1.7763395309448242
Batch 13/64 loss: 1.777451992034912
Batch 14/64 loss: 1.776970624923706
Batch 15/64 loss: 1.7861826419830322
Batch 16/64 loss: 1.780251383781433
Batch 17/64 loss: 1.778670072555542
Batch 18/64 loss: 1.7792829275131226
Batch 19/64 loss: 1.7817243337631226
Batch 20/64 loss: 1.7780300378799438
Batch 21/64 loss: 1.7932932376861572
Batch 22/64 loss: 1.7776950597763062
Batch 23/64 loss: 1.7832666635513306
Batch 24/64 loss: 1.7818936109542847
Batch 25/64 loss: 1.7829158306121826
Batch 26/64 loss: 1.7779107093811035
Batch 27/64 loss: 1.7756054401397705
Batch 28/64 loss: 1.7806940078735352
Batch 29/64 loss: 1.7753000259399414
Batch 30/64 loss: 1.7718827724456787
Batch 31/64 loss: 1.781411051750183
Batch 32/64 loss: 1.7833044528961182
Batch 33/64 loss: 1.7800426483154297
Batch 34/64 loss: 1.7819029092788696
Batch 35/64 loss: 1.7747431993484497
Batch 36/64 loss: 1.7912237644195557
Batch 37/64 loss: 1.7838172912597656
Batch 38/64 loss: 1.7782243490219116
Batch 39/64 loss: 1.7826170921325684
Batch 40/64 loss: 1.7770955562591553
Batch 41/64 loss: 1.773578405380249
Batch 42/64 loss: 1.7745009660720825
Batch 43/64 loss: 1.7757282257080078
Batch 44/64 loss: 1.7810187339782715
Batch 45/64 loss: 1.7758071422576904
Batch 46/64 loss: 1.7748610973358154
Batch 47/64 loss: 1.7736601829528809
Batch 48/64 loss: 1.7753576040267944
Batch 49/64 loss: 1.778426170349121
Batch 50/64 loss: 1.7724578380584717
Batch 51/64 loss: 1.7731870412826538
Batch 52/64 loss: 1.7921030521392822
Batch 53/64 loss: 1.7784398794174194
Batch 54/64 loss: 1.7771011590957642
Batch 55/64 loss: 1.7785221338272095
Batch 56/64 loss: 1.7774834632873535
Batch 57/64 loss: 1.7775359153747559
Batch 58/64 loss: 1.7755686044692993
Batch 59/64 loss: 1.784301519393921
Batch 60/64 loss: 1.7778891324996948
Batch 61/64 loss: 1.7760369777679443
Batch 62/64 loss: 1.793042778968811
Batch 63/64 loss: 1.77538001537323
Batch 64/64 loss: 1.9874378442764282
Epoch 47  Train loss: 1.7831001894146787  Val loss: 1.8026763671861892
Epoch 48
-------------------------------
Batch 1/64 loss: 1.7778911590576172
Batch 2/64 loss: 1.7731276750564575
Batch 3/64 loss: 1.779144048690796
Batch 4/64 loss: 1.778110146522522
Batch 5/64 loss: 1.7849069833755493
Batch 6/64 loss: 1.7783243656158447
Batch 7/64 loss: 1.775766134262085
Batch 8/64 loss: 1.77638578414917
Batch 9/64 loss: 1.7742679119110107
Batch 10/64 loss: 1.7773797512054443
Batch 11/64 loss: 1.7747493982315063
Batch 12/64 loss: 1.7948626279830933
Batch 13/64 loss: 1.7754781246185303
Batch 14/64 loss: 1.7780925035476685
Batch 15/64 loss: 1.782353162765503
Batch 16/64 loss: 1.7765642404556274
Batch 17/64 loss: 1.7808570861816406
Batch 18/64 loss: 1.778182029724121
Batch 19/64 loss: 1.7763549089431763
Batch 20/64 loss: 1.769767165184021
Batch 21/64 loss: 1.7828460931777954
Batch 22/64 loss: 1.774001121520996
Batch 23/64 loss: 1.7739089727401733
Batch 24/64 loss: 1.7755235433578491
Batch 25/64 loss: 1.8038108348846436
Batch 26/64 loss: 1.7793059349060059
Batch 27/64 loss: 1.7773746252059937
Batch 28/64 loss: 1.7751002311706543
Batch 29/64 loss: 1.7799997329711914
Batch 30/64 loss: 1.7797898054122925
Batch 31/64 loss: 1.7737147808074951
Batch 32/64 loss: 1.7805943489074707
Batch 33/64 loss: 1.7718039751052856
Batch 34/64 loss: 1.7795865535736084
Batch 35/64 loss: 1.7771480083465576
Batch 36/64 loss: 1.7863117456436157
Batch 37/64 loss: 1.7781081199645996
Batch 38/64 loss: 1.7761411666870117
Batch 39/64 loss: 1.7759976387023926
Batch 40/64 loss: 1.7776539325714111
Batch 41/64 loss: 1.7790734767913818
Batch 42/64 loss: 1.7793281078338623
Batch 43/64 loss: 1.7915349006652832
Batch 44/64 loss: 1.779476284980774
Batch 45/64 loss: 1.7737176418304443
Batch 46/64 loss: 1.7775044441223145
Batch 47/64 loss: 1.7732356786727905
Batch 48/64 loss: 1.774064302444458
Batch 49/64 loss: 1.7740654945373535
Batch 50/64 loss: 1.7756922245025635
Batch 51/64 loss: 1.7764763832092285
Batch 52/64 loss: 1.7769407033920288
Batch 53/64 loss: 1.781884789466858
Batch 54/64 loss: 1.7773442268371582
Batch 55/64 loss: 1.778273344039917
Batch 56/64 loss: 1.7755260467529297
Batch 57/64 loss: 1.779961109161377
Batch 58/64 loss: 1.774104356765747
Batch 59/64 loss: 1.7709662914276123
Batch 60/64 loss: 1.7737841606140137
Batch 61/64 loss: 1.7860075235366821
Batch 62/64 loss: 1.7731389999389648
Batch 63/64 loss: 1.7739923000335693
Batch 64/64 loss: 1.9911046028137207
Epoch 48  Train loss: 1.7805601194793104  Val loss: 1.801300278234318
Saving best model, epoch: 48
Epoch 49
-------------------------------
Batch 1/64 loss: 1.7793517112731934
Batch 2/64 loss: 1.778039574623108
Batch 3/64 loss: 1.7758352756500244
Batch 4/64 loss: 1.7776811122894287
Batch 5/64 loss: 1.7771575450897217
Batch 6/64 loss: 1.7779114246368408
Batch 7/64 loss: 1.7826416492462158
Batch 8/64 loss: 1.776688575744629
Batch 9/64 loss: 1.7791340351104736
Batch 10/64 loss: 1.7772096395492554
Batch 11/64 loss: 1.7841906547546387
Batch 12/64 loss: 1.7794290781021118
Batch 13/64 loss: 1.7801496982574463
Batch 14/64 loss: 1.7916009426116943
Batch 15/64 loss: 1.780555009841919
Batch 16/64 loss: 1.783706545829773
Batch 17/64 loss: 1.7810728549957275
Batch 18/64 loss: 1.777618646621704
Batch 19/64 loss: 1.7820643186569214
Batch 20/64 loss: 1.7804219722747803
Batch 21/64 loss: 1.7827651500701904
Batch 22/64 loss: 1.7766344547271729
Batch 23/64 loss: 1.775686264038086
Batch 24/64 loss: 1.7752878665924072
Batch 25/64 loss: 1.7755227088928223
Batch 26/64 loss: 1.7757539749145508
Batch 27/64 loss: 1.7772009372711182
Batch 28/64 loss: 1.7751109600067139
Batch 29/64 loss: 1.7829735279083252
Batch 30/64 loss: 1.7764629125595093
Batch 31/64 loss: 1.7843419313430786
Batch 32/64 loss: 1.7762320041656494
Batch 33/64 loss: 1.7753206491470337
Batch 34/64 loss: 1.7793171405792236
Batch 35/64 loss: 1.7813903093338013
Batch 36/64 loss: 1.7769873142242432
Batch 37/64 loss: 1.772352695465088
Batch 38/64 loss: 1.7819604873657227
Batch 39/64 loss: 1.7787463665008545
Batch 40/64 loss: 1.7744605541229248
Batch 41/64 loss: 1.77683687210083
Batch 42/64 loss: 1.7795488834381104
Batch 43/64 loss: 1.7853715419769287
Batch 44/64 loss: 1.7767829895019531
Batch 45/64 loss: 1.7756142616271973
Batch 46/64 loss: 1.7770353555679321
Batch 47/64 loss: 1.7800620794296265
Batch 48/64 loss: 1.7739107608795166
Batch 49/64 loss: 1.7795984745025635
Batch 50/64 loss: 1.775278925895691
Batch 51/64 loss: 1.7728503942489624
Batch 52/64 loss: 1.7721245288848877
Batch 53/64 loss: 1.776218056678772
Batch 54/64 loss: 1.7742974758148193
Batch 55/64 loss: 1.774672031402588
Batch 56/64 loss: 1.7814452648162842
Batch 57/64 loss: 1.7753098011016846
Batch 58/64 loss: 1.7788262367248535
Batch 59/64 loss: 1.7748591899871826
Batch 60/64 loss: 1.778600811958313
Batch 61/64 loss: 1.7902089357376099
Batch 62/64 loss: 1.7895927429199219
Batch 63/64 loss: 1.7815834283828735
Batch 64/64 loss: 1.990100622177124
Epoch 49  Train loss: 1.7811791840721578  Val loss: 1.807031785499599
Epoch 50
-------------------------------
Batch 1/64 loss: 1.779327392578125
Batch 2/64 loss: 1.7778847217559814
Batch 3/64 loss: 1.7780349254608154
Batch 4/64 loss: 1.7773735523223877
Batch 5/64 loss: 1.7781083583831787
Batch 6/64 loss: 1.7792773246765137
Batch 7/64 loss: 1.7792179584503174
Batch 8/64 loss: 1.7743126153945923
Batch 9/64 loss: 1.782052755355835
Batch 10/64 loss: 1.7794095277786255
Batch 11/64 loss: 1.7786122560501099
Batch 12/64 loss: 1.7765541076660156
Batch 13/64 loss: 1.7769876718521118
Batch 14/64 loss: 1.7770578861236572
Batch 15/64 loss: 1.7842165231704712
Batch 16/64 loss: 1.7798889875411987
Batch 17/64 loss: 1.7795281410217285
Batch 18/64 loss: 1.7793210744857788
Batch 19/64 loss: 1.781387448310852
Batch 20/64 loss: 1.7762022018432617
Batch 21/64 loss: 1.776597261428833
Batch 22/64 loss: 1.7796576023101807
Batch 23/64 loss: 1.7727493047714233
Batch 24/64 loss: 1.796940803527832
Batch 25/64 loss: 1.7757587432861328
Batch 26/64 loss: 1.7764995098114014
Batch 27/64 loss: 1.7786486148834229
Batch 28/64 loss: 1.778679609298706
Batch 29/64 loss: 1.775752305984497
Batch 30/64 loss: 1.7860398292541504
Batch 31/64 loss: 1.7776756286621094
Batch 32/64 loss: 1.7794567346572876
Batch 33/64 loss: 1.7774980068206787
Batch 34/64 loss: 1.7753946781158447
Batch 35/64 loss: 1.773966908454895
Batch 36/64 loss: 1.7808561325073242
Batch 37/64 loss: 1.7886953353881836
Batch 38/64 loss: 1.7742477655410767
Batch 39/64 loss: 1.7766385078430176
Batch 40/64 loss: 1.7814619541168213
Batch 41/64 loss: 1.771748661994934
Batch 42/64 loss: 1.7796170711517334
Batch 43/64 loss: 1.774991750717163
Batch 44/64 loss: 1.777942419052124
Batch 45/64 loss: 1.777890682220459
Batch 46/64 loss: 1.7775213718414307
Batch 47/64 loss: 1.7780475616455078
Batch 48/64 loss: 1.7753372192382812
Batch 49/64 loss: 1.7831180095672607
Batch 50/64 loss: 1.782815933227539
Batch 51/64 loss: 1.7765586376190186
Batch 52/64 loss: 1.7779258489608765
Batch 53/64 loss: 1.775113582611084
Batch 54/64 loss: 1.771749496459961
Batch 55/64 loss: 1.7750343084335327
Batch 56/64 loss: 1.7786308526992798
Batch 57/64 loss: 1.7762342691421509
Batch 58/64 loss: 1.7805248498916626
Batch 59/64 loss: 1.7768924236297607
Batch 60/64 loss: 1.7801172733306885
Batch 61/64 loss: 1.7788684368133545
Batch 62/64 loss: 1.7757806777954102
Batch 63/64 loss: 1.7742830514907837
Batch 64/64 loss: 1.9865050315856934
Epoch 50  Train loss: 1.7807779424330767  Val loss: 1.8077244332565885
Epoch 51
-------------------------------
Batch 1/64 loss: 1.7790395021438599
Batch 2/64 loss: 1.7758828401565552
Batch 3/64 loss: 1.7750184535980225
Batch 4/64 loss: 1.779641032218933
Batch 5/64 loss: 1.7794430255889893
Batch 6/64 loss: 1.7788057327270508
Batch 7/64 loss: 1.8020403385162354
Batch 8/64 loss: 1.778388500213623
Batch 9/64 loss: 1.7874739170074463
Batch 10/64 loss: 1.7754216194152832
Batch 11/64 loss: 1.7798888683319092
Batch 12/64 loss: 1.7763683795928955
Batch 13/64 loss: 1.7764407396316528
Batch 14/64 loss: 1.777298927307129
Batch 15/64 loss: 1.7777645587921143
Batch 16/64 loss: 1.7878642082214355
Batch 17/64 loss: 1.7815247774124146
Batch 18/64 loss: 1.7776626348495483
Batch 19/64 loss: 1.776123285293579
Batch 20/64 loss: 1.7781341075897217
Batch 21/64 loss: 1.7786977291107178
Batch 22/64 loss: 1.7761648893356323
Batch 23/64 loss: 1.7821736335754395
Batch 24/64 loss: 1.7803751230239868
Batch 25/64 loss: 1.7787666320800781
Batch 26/64 loss: 1.7790740728378296
Batch 27/64 loss: 1.7837638854980469
Batch 28/64 loss: 1.7752153873443604
Batch 29/64 loss: 1.7813043594360352
Batch 30/64 loss: 1.776989221572876
Batch 31/64 loss: 1.777325987815857
Batch 32/64 loss: 1.7825267314910889
Batch 33/64 loss: 1.7795370817184448
Batch 34/64 loss: 1.7763087749481201
Batch 35/64 loss: 1.776381492614746
Batch 36/64 loss: 1.7749824523925781
Batch 37/64 loss: 1.7714877128601074
Batch 38/64 loss: 1.7783031463623047
Batch 39/64 loss: 1.7801847457885742
Batch 40/64 loss: 1.7792677879333496
Batch 41/64 loss: 1.7772374153137207
Batch 42/64 loss: 1.7814264297485352
Batch 43/64 loss: 1.783136010169983
Batch 44/64 loss: 1.7788348197937012
Batch 45/64 loss: 1.7749688625335693
Batch 46/64 loss: 1.779492735862732
Batch 47/64 loss: 1.772296667098999
Batch 48/64 loss: 1.7747979164123535
Batch 49/64 loss: 1.780759572982788
Batch 50/64 loss: 1.7758245468139648
Batch 51/64 loss: 1.7749890089035034
Batch 52/64 loss: 1.7861380577087402
Batch 53/64 loss: 1.7742929458618164
Batch 54/64 loss: 1.780691146850586
Batch 55/64 loss: 1.7742631435394287
Batch 56/64 loss: 1.7883626222610474
Batch 57/64 loss: 1.771188497543335
Batch 58/64 loss: 1.777678370475769
Batch 59/64 loss: 1.7755733728408813
Batch 60/64 loss: 1.7719405889511108
Batch 61/64 loss: 1.778285264968872
Batch 62/64 loss: 1.774177074432373
Batch 63/64 loss: 1.7822232246398926
Batch 64/64 loss: 1.9917571544647217
Epoch 51  Train loss: 1.7811992542416442  Val loss: 1.7970677880487083
Saving best model, epoch: 51
Epoch 52
-------------------------------
Batch 1/64 loss: 1.7725712060928345
Batch 2/64 loss: 1.775004506111145
Batch 3/64 loss: 1.7819057703018188
Batch 4/64 loss: 1.7755920886993408
Batch 5/64 loss: 1.7766129970550537
Batch 6/64 loss: 1.7717880010604858
Batch 7/64 loss: 1.7726984024047852
Batch 8/64 loss: 1.7744109630584717
Batch 9/64 loss: 1.7775065898895264
Batch 10/64 loss: 1.777552604675293
Batch 11/64 loss: 1.7767460346221924
Batch 12/64 loss: 1.7787288427352905
Batch 13/64 loss: 1.7768027782440186
Batch 14/64 loss: 1.7857613563537598
Batch 15/64 loss: 1.7763830423355103
Batch 16/64 loss: 1.778786063194275
Batch 17/64 loss: 1.7689950466156006
Batch 18/64 loss: 1.7821574211120605
Batch 19/64 loss: 1.7758547067642212
Batch 20/64 loss: 1.7776367664337158
Batch 21/64 loss: 1.7707935571670532
Batch 22/64 loss: 1.7907638549804688
Batch 23/64 loss: 1.7758877277374268
Batch 24/64 loss: 1.7758322954177856
Batch 25/64 loss: 1.774570107460022
Batch 26/64 loss: 1.7712292671203613
Batch 27/64 loss: 1.7757796049118042
Batch 28/64 loss: 1.7763385772705078
Batch 29/64 loss: 1.7741034030914307
Batch 30/64 loss: 1.7770791053771973
Batch 31/64 loss: 1.7771003246307373
Batch 32/64 loss: 1.7742531299591064
Batch 33/64 loss: 1.7734506130218506
Batch 34/64 loss: 1.7751505374908447
Batch 35/64 loss: 1.7771426439285278
Batch 36/64 loss: 1.77593994140625
Batch 37/64 loss: 1.771720290184021
Batch 38/64 loss: 1.7784557342529297
Batch 39/64 loss: 1.7758880853652954
Batch 40/64 loss: 1.7766250371932983
Batch 41/64 loss: 1.7755157947540283
Batch 42/64 loss: 1.7819006443023682
Batch 43/64 loss: 1.7723917961120605
Batch 44/64 loss: 1.7741847038269043
Batch 45/64 loss: 1.770787239074707
Batch 46/64 loss: 1.7826381921768188
Batch 47/64 loss: 1.7724506855010986
Batch 48/64 loss: 1.7732694149017334
Batch 49/64 loss: 1.7943059206008911
Batch 50/64 loss: 1.7778643369674683
Batch 51/64 loss: 1.7761468887329102
Batch 52/64 loss: 1.7787413597106934
Batch 53/64 loss: 1.7759690284729004
Batch 54/64 loss: 1.7759984731674194
Batch 55/64 loss: 1.7728781700134277
Batch 56/64 loss: 1.7689610719680786
Batch 57/64 loss: 1.7726666927337646
Batch 58/64 loss: 1.7745164632797241
Batch 59/64 loss: 1.7757887840270996
Batch 60/64 loss: 1.775320053100586
Batch 61/64 loss: 1.792107343673706
Batch 62/64 loss: 1.7771018743515015
Batch 63/64 loss: 1.7759813070297241
Batch 64/64 loss: 1.986407995223999
Epoch 52  Train loss: 1.7789630001666499  Val loss: 1.8033292580306326
Epoch 53
-------------------------------
Batch 1/64 loss: 1.7758793830871582
Batch 2/64 loss: 1.7741401195526123
Batch 3/64 loss: 1.7940053939819336
Batch 4/64 loss: 1.7750811576843262
Batch 5/64 loss: 1.778666377067566
Batch 6/64 loss: 1.7916370630264282
Batch 7/64 loss: 1.7751586437225342
Batch 8/64 loss: 1.781877875328064
Batch 9/64 loss: 1.7879157066345215
Batch 10/64 loss: 1.7796834707260132
Batch 11/64 loss: 1.7913298606872559
Batch 12/64 loss: 1.7825978994369507
Batch 13/64 loss: 1.7768877744674683
Batch 14/64 loss: 1.7805558443069458
Batch 15/64 loss: 1.7794679403305054
Batch 16/64 loss: 1.7958533763885498
Batch 17/64 loss: 1.7838464975357056
Batch 18/64 loss: 1.776073694229126
Batch 19/64 loss: 1.784561038017273
Batch 20/64 loss: 1.7887401580810547
Batch 21/64 loss: 1.7870771884918213
Batch 22/64 loss: 1.7822706699371338
Batch 23/64 loss: 1.7836579084396362
Batch 24/64 loss: 1.778075933456421
Batch 25/64 loss: 1.791452169418335
Batch 26/64 loss: 1.7774851322174072
Batch 27/64 loss: 1.790184497833252
Batch 28/64 loss: 1.7895572185516357
Batch 29/64 loss: 1.779852032661438
Batch 30/64 loss: 1.7786928415298462
Batch 31/64 loss: 1.7802718877792358
Batch 32/64 loss: 1.7776087522506714
Batch 33/64 loss: 1.77711820602417
Batch 34/64 loss: 1.779722809791565
Batch 35/64 loss: 1.7800920009613037
Batch 36/64 loss: 1.7757387161254883
Batch 37/64 loss: 1.7774105072021484
Batch 38/64 loss: 1.7766427993774414
Batch 39/64 loss: 1.7815978527069092
Batch 40/64 loss: 1.777826189994812
Batch 41/64 loss: 1.7790138721466064
Batch 42/64 loss: 1.7806413173675537
Batch 43/64 loss: 1.7731525897979736
Batch 44/64 loss: 1.7767298221588135
Batch 45/64 loss: 1.7747186422348022
Batch 46/64 loss: 1.7722731828689575
Batch 47/64 loss: 1.7786331176757812
Batch 48/64 loss: 1.7749948501586914
Batch 49/64 loss: 1.7738053798675537
Batch 50/64 loss: 1.7715033292770386
Batch 51/64 loss: 1.7760331630706787
Batch 52/64 loss: 1.7764228582382202
Batch 53/64 loss: 1.7792177200317383
Batch 54/64 loss: 1.7893363237380981
Batch 55/64 loss: 1.7767053842544556
Batch 56/64 loss: 1.7739617824554443
Batch 57/64 loss: 1.7737327814102173
Batch 58/64 loss: 1.7819335460662842
Batch 59/64 loss: 1.772510290145874
Batch 60/64 loss: 1.7719885110855103
Batch 61/64 loss: 1.7786701917648315
Batch 62/64 loss: 1.7755370140075684
Batch 63/64 loss: 1.782854437828064
Batch 64/64 loss: 1.9948601722717285
Epoch 53  Train loss: 1.7825381933474074  Val loss: 1.795486311732289
Saving best model, epoch: 53
Epoch 54
-------------------------------
Batch 1/64 loss: 1.7750840187072754
Batch 2/64 loss: 1.7744686603546143
Batch 3/64 loss: 1.774632215499878
Batch 4/64 loss: 1.7788058519363403
Batch 5/64 loss: 1.7743092775344849
Batch 6/64 loss: 1.7787939310073853
Batch 7/64 loss: 1.7893539667129517
Batch 8/64 loss: 1.7764620780944824
Batch 9/64 loss: 1.7851893901824951
Batch 10/64 loss: 1.7843565940856934
Batch 11/64 loss: 1.773840308189392
Batch 12/64 loss: 1.7791180610656738
Batch 13/64 loss: 1.7850213050842285
Batch 14/64 loss: 1.774685025215149
Batch 15/64 loss: 1.7756425142288208
Batch 16/64 loss: 1.7777409553527832
Batch 17/64 loss: 1.7800105810165405
Batch 18/64 loss: 1.7805771827697754
Batch 19/64 loss: 1.7823421955108643
Batch 20/64 loss: 1.7764164209365845
Batch 21/64 loss: 1.7737891674041748
Batch 22/64 loss: 1.7743425369262695
Batch 23/64 loss: 1.778890609741211
Batch 24/64 loss: 1.7796547412872314
Batch 25/64 loss: 1.7791253328323364
Batch 26/64 loss: 1.7831529378890991
Batch 27/64 loss: 1.7768338918685913
Batch 28/64 loss: 1.7784457206726074
Batch 29/64 loss: 1.7827422618865967
Batch 30/64 loss: 1.7788426876068115
Batch 31/64 loss: 1.785284399986267
Batch 32/64 loss: 1.7833526134490967
Batch 33/64 loss: 1.7873212099075317
Batch 34/64 loss: 1.7861342430114746
Batch 35/64 loss: 1.779712438583374
Batch 36/64 loss: 1.7762906551361084
Batch 37/64 loss: 1.7797160148620605
Batch 38/64 loss: 1.7743257284164429
Batch 39/64 loss: 1.78105890750885
Batch 40/64 loss: 1.778942346572876
Batch 41/64 loss: 1.7795779705047607
Batch 42/64 loss: 1.7835147380828857
Batch 43/64 loss: 1.7773222923278809
Batch 44/64 loss: 1.7877776622772217
Batch 45/64 loss: 1.7735263109207153
Batch 46/64 loss: 1.7770392894744873
Batch 47/64 loss: 1.7833000421524048
Batch 48/64 loss: 1.7823647260665894
Batch 49/64 loss: 1.7785296440124512
Batch 50/64 loss: 1.79188871383667
Batch 51/64 loss: 1.7745404243469238
Batch 52/64 loss: 1.7784258127212524
Batch 53/64 loss: 1.7784911394119263
Batch 54/64 loss: 1.7786242961883545
Batch 55/64 loss: 1.788507342338562
Batch 56/64 loss: 1.7730436325073242
Batch 57/64 loss: 1.7756379842758179
Batch 58/64 loss: 1.7714731693267822
Batch 59/64 loss: 1.7771458625793457
Batch 60/64 loss: 1.7816286087036133
Batch 61/64 loss: 1.7744190692901611
Batch 62/64 loss: 1.7817286252975464
Batch 63/64 loss: 1.795426368713379
Batch 64/64 loss: 1.987593412399292
Epoch 54  Train loss: 1.7821088276657404  Val loss: 1.8054512423748004
Epoch 55
-------------------------------
Batch 1/64 loss: 1.7741808891296387
Batch 2/64 loss: 1.7743957042694092
Batch 3/64 loss: 1.7788525819778442
Batch 4/64 loss: 1.7895509004592896
Batch 5/64 loss: 1.7756811380386353
Batch 6/64 loss: 1.779922604560852
Batch 7/64 loss: 1.7769334316253662
Batch 8/64 loss: 1.7780752182006836
Batch 9/64 loss: 1.7730228900909424
Batch 10/64 loss: 1.7800202369689941
Batch 11/64 loss: 1.7768579721450806
Batch 12/64 loss: 1.7759485244750977
Batch 13/64 loss: 1.776257038116455
Batch 14/64 loss: 1.7793444395065308
Batch 15/64 loss: 1.7744009494781494
Batch 16/64 loss: 1.7722996473312378
Batch 17/64 loss: 1.7803646326065063
Batch 18/64 loss: 1.774668574333191
Batch 19/64 loss: 1.7734942436218262
Batch 20/64 loss: 1.7860397100448608
Batch 21/64 loss: 1.7767572402954102
Batch 22/64 loss: 1.777924656867981
Batch 23/64 loss: 1.7748606204986572
Batch 24/64 loss: 1.774806022644043
Batch 25/64 loss: 1.7705180644989014
Batch 26/64 loss: 1.7887787818908691
Batch 27/64 loss: 1.7758691310882568
Batch 28/64 loss: 1.774623990058899
Batch 29/64 loss: 1.775073766708374
Batch 30/64 loss: 1.7765955924987793
Batch 31/64 loss: 1.774800181388855
Batch 32/64 loss: 1.7746703624725342
Batch 33/64 loss: 1.7755635976791382
Batch 34/64 loss: 1.770332932472229
Batch 35/64 loss: 1.7735017538070679
Batch 36/64 loss: 1.770242691040039
Batch 37/64 loss: 1.7759389877319336
Batch 38/64 loss: 1.773346185684204
Batch 39/64 loss: 1.776265025138855
Batch 40/64 loss: 1.7769883871078491
Batch 41/64 loss: 1.7836886644363403
Batch 42/64 loss: 1.7777326107025146
Batch 43/64 loss: 1.7751424312591553
Batch 44/64 loss: 1.7747437953948975
Batch 45/64 loss: 1.7734129428863525
Batch 46/64 loss: 1.7775747776031494
Batch 47/64 loss: 1.7722582817077637
Batch 48/64 loss: 1.7761797904968262
Batch 49/64 loss: 1.7774907350540161
Batch 50/64 loss: 1.7743494510650635
Batch 51/64 loss: 1.7707206010818481
Batch 52/64 loss: 1.778249979019165
Batch 53/64 loss: 1.7753491401672363
Batch 54/64 loss: 1.7843470573425293
Batch 55/64 loss: 1.7739248275756836
Batch 56/64 loss: 1.8427174091339111
Batch 57/64 loss: 1.776285171508789
Batch 58/64 loss: 1.7770899534225464
Batch 59/64 loss: 1.7819160223007202
Batch 60/64 loss: 1.7962642908096313
Batch 61/64 loss: 1.783584475517273
Batch 62/64 loss: 1.7751597166061401
Batch 63/64 loss: 1.7756547927856445
Batch 64/64 loss: 1.988051414489746
Epoch 55  Train loss: 1.7804336435654584  Val loss: 1.8096298221050668
Epoch 56
-------------------------------
Batch 1/64 loss: 1.7776925563812256
Batch 2/64 loss: 1.7945371866226196
Batch 3/64 loss: 1.7840969562530518
Batch 4/64 loss: 1.7845875024795532
Batch 5/64 loss: 1.7883899211883545
Batch 6/64 loss: 1.7797681093215942
Batch 7/64 loss: 1.7776180505752563
Batch 8/64 loss: 1.7763183116912842
Batch 9/64 loss: 1.7755240201950073
Batch 10/64 loss: 1.7760940790176392
Batch 11/64 loss: 1.777045726776123
Batch 12/64 loss: 1.7771320343017578
Batch 13/64 loss: 1.7751851081848145
Batch 14/64 loss: 1.7752796411514282
Batch 15/64 loss: 1.7769286632537842
Batch 16/64 loss: 1.7717821598052979
Batch 17/64 loss: 1.7810766696929932
Batch 18/64 loss: 1.7740192413330078
Batch 19/64 loss: 1.780121922492981
Batch 20/64 loss: 1.780397891998291
Batch 21/64 loss: 1.7744600772857666
Batch 22/64 loss: 1.7722615003585815
Batch 23/64 loss: 1.7765765190124512
Batch 24/64 loss: 1.777762532234192
Batch 25/64 loss: 1.7779730558395386
Batch 26/64 loss: 1.7780243158340454
Batch 27/64 loss: 1.798151969909668
Batch 28/64 loss: 1.7882578372955322
Batch 29/64 loss: 1.776806354522705
Batch 30/64 loss: 1.7782576084136963
Batch 31/64 loss: 1.7903664112091064
Batch 32/64 loss: 1.7765607833862305
Batch 33/64 loss: 1.7729028463363647
Batch 34/64 loss: 1.7854743003845215
Batch 35/64 loss: 1.7922992706298828
Batch 36/64 loss: 1.780156135559082
Batch 37/64 loss: 1.7904037237167358
Batch 38/64 loss: 1.7799474000930786
Batch 39/64 loss: 1.7746561765670776
Batch 40/64 loss: 1.7812505960464478
Batch 41/64 loss: 1.7816638946533203
Batch 42/64 loss: 1.7862783670425415
Batch 43/64 loss: 1.7789889574050903
Batch 44/64 loss: 1.7885260581970215
Batch 45/64 loss: 1.783329725265503
Batch 46/64 loss: 1.7783550024032593
Batch 47/64 loss: 1.7787586450576782
Batch 48/64 loss: 1.7788878679275513
Batch 49/64 loss: 1.7804183959960938
Batch 50/64 loss: 1.7760696411132812
Batch 51/64 loss: 1.7777013778686523
Batch 52/64 loss: 1.7872262001037598
Batch 53/64 loss: 1.7765942811965942
Batch 54/64 loss: 1.7784476280212402
Batch 55/64 loss: 1.7771104574203491
Batch 56/64 loss: 1.7782824039459229
Batch 57/64 loss: 1.7789359092712402
Batch 58/64 loss: 1.7761695384979248
Batch 59/64 loss: 1.7830203771591187
Batch 60/64 loss: 1.7746491432189941
Batch 61/64 loss: 1.7707687616348267
Batch 62/64 loss: 1.7744276523590088
Batch 63/64 loss: 1.7732982635498047
Batch 64/64 loss: 1.979567050933838
Epoch 56  Train loss: 1.7820977098801556  Val loss: 1.8245987179353065
Epoch 57
-------------------------------
Batch 1/64 loss: 1.7743704319000244
Batch 2/64 loss: 1.771771788597107
Batch 3/64 loss: 1.7734827995300293
Batch 4/64 loss: 1.7939740419387817
Batch 5/64 loss: 1.7775105237960815
Batch 6/64 loss: 1.778812050819397
Batch 7/64 loss: 1.778628945350647
Batch 8/64 loss: 1.780981421470642
Batch 9/64 loss: 1.774519681930542
Batch 10/64 loss: 1.7734079360961914
Batch 11/64 loss: 1.7734863758087158
Batch 12/64 loss: 1.777679443359375
Batch 13/64 loss: 1.7721238136291504
Batch 14/64 loss: 1.7710111141204834
Batch 15/64 loss: 1.7720240354537964
Batch 16/64 loss: 1.770913004875183
Batch 17/64 loss: 1.7695143222808838
Batch 18/64 loss: 1.7785364389419556
Batch 19/64 loss: 1.7732367515563965
Batch 20/64 loss: 1.7729229927062988
Batch 21/64 loss: 1.7733709812164307
Batch 22/64 loss: 1.7743350267410278
Batch 23/64 loss: 1.7747395038604736
Batch 24/64 loss: 1.7736170291900635
Batch 25/64 loss: 1.7717546224594116
Batch 26/64 loss: 1.7690712213516235
Batch 27/64 loss: 1.774064540863037
Batch 28/64 loss: 1.768397569656372
Batch 29/64 loss: 1.7709190845489502
Batch 30/64 loss: 1.7689461708068848
Batch 31/64 loss: 1.7747671604156494
Batch 32/64 loss: 1.7695021629333496
Batch 33/64 loss: 1.7715048789978027
Batch 34/64 loss: 1.770483136177063
Batch 35/64 loss: 1.7733769416809082
Batch 36/64 loss: 1.771496295928955
Batch 37/64 loss: 1.773895025253296
Batch 38/64 loss: 1.7731338739395142
Batch 39/64 loss: 1.7764556407928467
Batch 40/64 loss: 1.77406644821167
Batch 41/64 loss: 1.7809147834777832
Batch 42/64 loss: 1.773837924003601
Batch 43/64 loss: 1.770186424255371
Batch 44/64 loss: 1.7738698720932007
Batch 45/64 loss: 1.7752236127853394
Batch 46/64 loss: 1.7758610248565674
Batch 47/64 loss: 1.7805466651916504
Batch 48/64 loss: 1.7722949981689453
Batch 49/64 loss: 1.7760412693023682
Batch 50/64 loss: 1.7782988548278809
Batch 51/64 loss: 1.7889792919158936
Batch 52/64 loss: 1.7907990217208862
Batch 53/64 loss: 1.777153730392456
Batch 54/64 loss: 1.7734668254852295
Batch 55/64 loss: 1.7743768692016602
Batch 56/64 loss: 1.7750605344772339
Batch 57/64 loss: 1.7777736186981201
Batch 58/64 loss: 1.772887110710144
Batch 59/64 loss: 1.773681402206421
Batch 60/64 loss: 1.772840142250061
Batch 61/64 loss: 1.7720129489898682
Batch 62/64 loss: 1.7727476358413696
Batch 63/64 loss: 1.7700809240341187
Batch 64/64 loss: 1.9792479276657104
Epoch 57  Train loss: 1.7771008103501562  Val loss: 1.7941085612241345
Saving best model, epoch: 57
Epoch 58
-------------------------------
Batch 1/64 loss: 1.7796634435653687
Batch 2/64 loss: 1.773022174835205
Batch 3/64 loss: 1.7766661643981934
Batch 4/64 loss: 1.7743141651153564
Batch 5/64 loss: 1.7687337398529053
Batch 6/64 loss: 1.7701865434646606
Batch 7/64 loss: 1.7729257345199585
Batch 8/64 loss: 1.7757599353790283
Batch 9/64 loss: 1.7777477502822876
Batch 10/64 loss: 1.7702358961105347
Batch 11/64 loss: 1.7808494567871094
Batch 12/64 loss: 1.7723687887191772
Batch 13/64 loss: 1.7824264764785767
Batch 14/64 loss: 1.7756156921386719
Batch 15/64 loss: 1.7713998556137085
Batch 16/64 loss: 1.7828528881072998
Batch 17/64 loss: 1.7714694738388062
Batch 18/64 loss: 1.7748337984085083
Batch 19/64 loss: 1.782321572303772
Batch 20/64 loss: 1.7939863204956055
Batch 21/64 loss: 1.7735600471496582
Batch 22/64 loss: 1.7769088745117188
Batch 23/64 loss: 1.770822525024414
Batch 24/64 loss: 1.774584174156189
Batch 25/64 loss: 1.7778916358947754
Batch 26/64 loss: 1.7693556547164917
Batch 27/64 loss: 1.7732774019241333
Batch 28/64 loss: 1.775691032409668
Batch 29/64 loss: 1.7782697677612305
Batch 30/64 loss: 1.7771409749984741
Batch 31/64 loss: 1.7777295112609863
Batch 32/64 loss: 1.7805277109146118
Batch 33/64 loss: 1.7790474891662598
Batch 34/64 loss: 1.7751960754394531
Batch 35/64 loss: 1.7744107246398926
Batch 36/64 loss: 1.7858967781066895
Batch 37/64 loss: 1.7815196514129639
Batch 38/64 loss: 1.787277102470398
Batch 39/64 loss: 1.7765318155288696
Batch 40/64 loss: 1.7729954719543457
Batch 41/64 loss: 1.7802332639694214
Batch 42/64 loss: 1.779524564743042
Batch 43/64 loss: 1.7867953777313232
Batch 44/64 loss: 1.789048194885254
Batch 45/64 loss: 1.776738166809082
Batch 46/64 loss: 1.7782574892044067
Batch 47/64 loss: 1.7732577323913574
Batch 48/64 loss: 1.7729732990264893
Batch 49/64 loss: 1.7854323387145996
Batch 50/64 loss: 1.7740927934646606
Batch 51/64 loss: 1.775984525680542
Batch 52/64 loss: 1.7824509143829346
Batch 53/64 loss: 1.7712230682373047
Batch 54/64 loss: 1.7754541635513306
Batch 55/64 loss: 1.7785688638687134
Batch 56/64 loss: 1.771351933479309
Batch 57/64 loss: 1.7736914157867432
Batch 58/64 loss: 1.7766656875610352
Batch 59/64 loss: 1.7806904315948486
Batch 60/64 loss: 1.77793550491333
Batch 61/64 loss: 1.7738010883331299
Batch 62/64 loss: 1.7738032341003418
Batch 63/64 loss: 1.778385877609253
Batch 64/64 loss: 1.9798426628112793
Epoch 58  Train loss: 1.7794079406588685  Val loss: 1.79723921182639
Epoch 59
-------------------------------
Batch 1/64 loss: 1.7803664207458496
Batch 2/64 loss: 1.7725350856781006
Batch 3/64 loss: 1.7784852981567383
Batch 4/64 loss: 1.7751705646514893
Batch 5/64 loss: 1.7781805992126465
Batch 6/64 loss: 1.7731561660766602
Batch 7/64 loss: 1.7823086977005005
Batch 8/64 loss: 1.779886245727539
Batch 9/64 loss: 1.772988200187683
Batch 10/64 loss: 1.7723747491836548
Batch 11/64 loss: 1.7739243507385254
Batch 12/64 loss: 1.771347999572754
Batch 13/64 loss: 1.7811191082000732
Batch 14/64 loss: 1.774350881576538
Batch 15/64 loss: 1.786120891571045
Batch 16/64 loss: 1.777499794960022
Batch 17/64 loss: 1.7750121355056763
Batch 18/64 loss: 1.7772289514541626
Batch 19/64 loss: 1.7766867876052856
Batch 20/64 loss: 1.785953164100647
Batch 21/64 loss: 1.775998830795288
Batch 22/64 loss: 1.7787327766418457
Batch 23/64 loss: 1.7888500690460205
Batch 24/64 loss: 1.7791152000427246
Batch 25/64 loss: 1.77521812915802
Batch 26/64 loss: 1.792892336845398
Batch 27/64 loss: 1.7754714488983154
Batch 28/64 loss: 1.7802064418792725
Batch 29/64 loss: 1.7769904136657715
Batch 30/64 loss: 1.7741358280181885
Batch 31/64 loss: 1.780200481414795
Batch 32/64 loss: 1.7746562957763672
Batch 33/64 loss: 1.772239089012146
Batch 34/64 loss: 1.7880308628082275
Batch 35/64 loss: 1.7721850872039795
Batch 36/64 loss: 1.7794588804244995
Batch 37/64 loss: 1.77919602394104
Batch 38/64 loss: 1.7707029581069946
Batch 39/64 loss: 1.7723822593688965
Batch 40/64 loss: 1.7699779272079468
Batch 41/64 loss: 1.778926134109497
Batch 42/64 loss: 1.770313024520874
Batch 43/64 loss: 1.785881519317627
Batch 44/64 loss: 1.7747246026992798
Batch 45/64 loss: 1.7838401794433594
Batch 46/64 loss: 1.777901530265808
Batch 47/64 loss: 1.7790582180023193
Batch 48/64 loss: 1.774211049079895
Batch 49/64 loss: 1.7871618270874023
Batch 50/64 loss: 1.7756617069244385
Batch 51/64 loss: 1.7707103490829468
Batch 52/64 loss: 1.774563193321228
Batch 53/64 loss: 1.7734401226043701
Batch 54/64 loss: 1.7690632343292236
Batch 55/64 loss: 1.769439697265625
Batch 56/64 loss: 1.773723840713501
Batch 57/64 loss: 1.7770189046859741
Batch 58/64 loss: 1.778902530670166
Batch 59/64 loss: 1.776780605316162
Batch 60/64 loss: 1.7720932960510254
Batch 61/64 loss: 1.7725741863250732
Batch 62/64 loss: 1.7694206237792969
Batch 63/64 loss: 1.775657057762146
Batch 64/64 loss: 1.9831604957580566
Epoch 59  Train loss: 1.7792905919692095  Val loss: 1.7988566557566326
Epoch 60
-------------------------------
Batch 1/64 loss: 1.7923203706741333
Batch 2/64 loss: 1.7695502042770386
Batch 3/64 loss: 1.7784372568130493
Batch 4/64 loss: 1.7751123905181885
Batch 5/64 loss: 1.7724980115890503
Batch 6/64 loss: 1.77119779586792
Batch 7/64 loss: 1.7758750915527344
Batch 8/64 loss: 1.7742996215820312
Batch 9/64 loss: 1.7728618383407593
Batch 10/64 loss: 1.771985650062561
Batch 11/64 loss: 1.7711968421936035
Batch 12/64 loss: 1.7811354398727417
Batch 13/64 loss: 1.7750256061553955
Batch 14/64 loss: 1.7716975212097168
Batch 15/64 loss: 1.7722558975219727
Batch 16/64 loss: 1.774505853652954
Batch 17/64 loss: 1.776120901107788
Batch 18/64 loss: 1.7756083011627197
Batch 19/64 loss: 1.7716646194458008
Batch 20/64 loss: 1.7804574966430664
Batch 21/64 loss: 1.7769867181777954
Batch 22/64 loss: 1.7691597938537598
Batch 23/64 loss: 1.772460699081421
Batch 24/64 loss: 1.7695573568344116
Batch 25/64 loss: 1.7747994661331177
Batch 26/64 loss: 1.77055823802948
Batch 27/64 loss: 1.768759846687317
Batch 28/64 loss: 1.7740494012832642
Batch 29/64 loss: 1.7700903415679932
Batch 30/64 loss: 1.7808343172073364
Batch 31/64 loss: 1.770546793937683
Batch 32/64 loss: 1.7737395763397217
Batch 33/64 loss: 1.7716937065124512
Batch 34/64 loss: 1.7700341939926147
Batch 35/64 loss: 1.7727516889572144
Batch 36/64 loss: 1.7866365909576416
Batch 37/64 loss: 1.7776718139648438
Batch 38/64 loss: 1.7699593305587769
Batch 39/64 loss: 1.777867078781128
Batch 40/64 loss: 1.7680505514144897
Batch 41/64 loss: 1.7802619934082031
Batch 42/64 loss: 1.7723503112792969
Batch 43/64 loss: 1.7744404077529907
Batch 44/64 loss: 1.7720069885253906
Batch 45/64 loss: 1.7746882438659668
Batch 46/64 loss: 1.774653434753418
Batch 47/64 loss: 1.7689743041992188
Batch 48/64 loss: 1.7725697755813599
Batch 49/64 loss: 1.7738171815872192
Batch 50/64 loss: 1.7704992294311523
Batch 51/64 loss: 1.771299123764038
Batch 52/64 loss: 1.7698729038238525
Batch 53/64 loss: 1.767499327659607
Batch 54/64 loss: 1.7761434316635132
Batch 55/64 loss: 1.772229790687561
Batch 56/64 loss: 1.7767484188079834
Batch 57/64 loss: 1.7716436386108398
Batch 58/64 loss: 1.770387887954712
Batch 59/64 loss: 1.7777832746505737
Batch 60/64 loss: 1.77321195602417
Batch 61/64 loss: 1.7691776752471924
Batch 62/64 loss: 1.7673813104629517
Batch 63/64 loss: 1.7725332975387573
Batch 64/64 loss: 1.9788782596588135
Epoch 60  Train loss: 1.7760681853574865  Val loss: 1.7941758067337508
Epoch 61
-------------------------------
Batch 1/64 loss: 1.7707343101501465
Batch 2/64 loss: 1.7707319259643555
Batch 3/64 loss: 1.7647976875305176
Batch 4/64 loss: 1.7696363925933838
Batch 5/64 loss: 1.768847942352295
Batch 6/64 loss: 1.7723262310028076
Batch 7/64 loss: 1.7655190229415894
Batch 8/64 loss: 1.7746455669403076
Batch 9/64 loss: 1.7692174911499023
Batch 10/64 loss: 1.7715930938720703
Batch 11/64 loss: 1.7710857391357422
Batch 12/64 loss: 1.7753419876098633
Batch 13/64 loss: 1.776247501373291
Batch 14/64 loss: 1.7723053693771362
Batch 15/64 loss: 1.7659478187561035
Batch 16/64 loss: 1.770963191986084
Batch 17/64 loss: 1.7757664918899536
Batch 18/64 loss: 1.774674415588379
Batch 19/64 loss: 1.7783936262130737
Batch 20/64 loss: 1.7715511322021484
Batch 21/64 loss: 1.7751929759979248
Batch 22/64 loss: 1.7720314264297485
Batch 23/64 loss: 1.7713353633880615
Batch 24/64 loss: 1.7706918716430664
Batch 25/64 loss: 1.77284574508667
Batch 26/64 loss: 1.774125337600708
Batch 27/64 loss: 1.7695751190185547
Batch 28/64 loss: 1.7757086753845215
Batch 29/64 loss: 1.7694638967514038
Batch 30/64 loss: 1.7715191841125488
Batch 31/64 loss: 1.770743727684021
Batch 32/64 loss: 1.7690716981887817
Batch 33/64 loss: 1.7695660591125488
Batch 34/64 loss: 1.773256778717041
Batch 35/64 loss: 1.7677068710327148
Batch 36/64 loss: 1.7686538696289062
Batch 37/64 loss: 1.775086522102356
Batch 38/64 loss: 1.7730265855789185
Batch 39/64 loss: 1.7898828983306885
Batch 40/64 loss: 1.7692997455596924
Batch 41/64 loss: 1.7672462463378906
Batch 42/64 loss: 1.768958568572998
Batch 43/64 loss: 1.7671120166778564
Batch 44/64 loss: 1.76661217212677
Batch 45/64 loss: 1.7880152463912964
Batch 46/64 loss: 1.7698071002960205
Batch 47/64 loss: 1.7705669403076172
Batch 48/64 loss: 1.7717320919036865
Batch 49/64 loss: 1.770293116569519
Batch 50/64 loss: 1.7662087678909302
Batch 51/64 loss: 1.779567003250122
Batch 52/64 loss: 1.7705658674240112
Batch 53/64 loss: 1.7661998271942139
Batch 54/64 loss: 1.7665371894836426
Batch 55/64 loss: 1.7792245149612427
Batch 56/64 loss: 1.7766833305358887
Batch 57/64 loss: 1.77972412109375
Batch 58/64 loss: 1.7682234048843384
Batch 59/64 loss: 1.7694284915924072
Batch 60/64 loss: 1.7666404247283936
Batch 61/64 loss: 1.769853949546814
Batch 62/64 loss: 1.7720348834991455
Batch 63/64 loss: 1.7681055068969727
Batch 64/64 loss: 1.9820520877838135
Epoch 61  Train loss: 1.7741959394193163  Val loss: 1.7972715212307435
Epoch 62
-------------------------------
Batch 1/64 loss: 1.7694482803344727
Batch 2/64 loss: 1.7682883739471436
Batch 3/64 loss: 1.7737798690795898
Batch 4/64 loss: 1.7697235345840454
Batch 5/64 loss: 1.7755215167999268
Batch 6/64 loss: 1.7759640216827393
Batch 7/64 loss: 1.7795943021774292
Batch 8/64 loss: 1.765979290008545
Batch 9/64 loss: 1.7697821855545044
Batch 10/64 loss: 1.7753537893295288
Batch 11/64 loss: 1.7736852169036865
Batch 12/64 loss: 1.7678815126419067
Batch 13/64 loss: 1.7742424011230469
Batch 14/64 loss: 1.7684224843978882
Batch 15/64 loss: 1.7714262008666992
Batch 16/64 loss: 1.7828587293624878
Batch 17/64 loss: 1.7715333700180054
Batch 18/64 loss: 1.7718571424484253
Batch 19/64 loss: 1.7705634832382202
Batch 20/64 loss: 1.772112488746643
Batch 21/64 loss: 1.773956298828125
Batch 22/64 loss: 1.774287223815918
Batch 23/64 loss: 1.7745579481124878
Batch 24/64 loss: 1.7750896215438843
Batch 25/64 loss: 1.7724300622940063
Batch 26/64 loss: 1.7806965112686157
Batch 27/64 loss: 1.7754483222961426
Batch 28/64 loss: 1.7799513339996338
Batch 29/64 loss: 1.7734230756759644
Batch 30/64 loss: 1.7788846492767334
Batch 31/64 loss: 1.7710607051849365
Batch 32/64 loss: 1.773196816444397
Batch 33/64 loss: 1.7706879377365112
Batch 34/64 loss: 1.769045114517212
Batch 35/64 loss: 1.7740453481674194
Batch 36/64 loss: 1.7727327346801758
Batch 37/64 loss: 1.7688088417053223
Batch 38/64 loss: 1.7661786079406738
Batch 39/64 loss: 1.767354130744934
Batch 40/64 loss: 1.7705661058425903
Batch 41/64 loss: 1.7767020463943481
Batch 42/64 loss: 1.7670727968215942
Batch 43/64 loss: 1.7700191736221313
Batch 44/64 loss: 1.7694814205169678
Batch 45/64 loss: 1.7734336853027344
Batch 46/64 loss: 1.7746236324310303
Batch 47/64 loss: 1.7744425535202026
Batch 48/64 loss: 1.7789762020111084
Batch 49/64 loss: 1.7709606885910034
Batch 50/64 loss: 1.775054931640625
Batch 51/64 loss: 1.7705249786376953
Batch 52/64 loss: 1.771744966506958
Batch 53/64 loss: 1.7929670810699463
Batch 54/64 loss: 1.7815748453140259
Batch 55/64 loss: 1.7726160287857056
Batch 56/64 loss: 1.7795498371124268
Batch 57/64 loss: 1.7729816436767578
Batch 58/64 loss: 1.7774465084075928
Batch 59/64 loss: 1.7715840339660645
Batch 60/64 loss: 1.7862895727157593
Batch 61/64 loss: 1.7724089622497559
Batch 62/64 loss: 1.7687547206878662
Batch 63/64 loss: 1.7706449031829834
Batch 64/64 loss: 1.978842854499817
Epoch 62  Train loss: 1.7759122656840904  Val loss: 1.7993511637461554
Epoch 63
-------------------------------
Batch 1/64 loss: 1.7708241939544678
Batch 2/64 loss: 1.788781762123108
Batch 3/64 loss: 1.7701687812805176
Batch 4/64 loss: 1.7734392881393433
Batch 5/64 loss: 1.767256498336792
Batch 6/64 loss: 1.7692842483520508
Batch 7/64 loss: 1.7867703437805176
Batch 8/64 loss: 1.775634527206421
Batch 9/64 loss: 1.7841246128082275
Batch 10/64 loss: 1.7732226848602295
Batch 11/64 loss: 1.7690393924713135
Batch 12/64 loss: 1.7862935066223145
Batch 13/64 loss: 1.7772270441055298
Batch 14/64 loss: 1.7698991298675537
Batch 15/64 loss: 1.7796883583068848
Batch 16/64 loss: 1.7692515850067139
Batch 17/64 loss: 1.7747560739517212
Batch 18/64 loss: 1.7725859880447388
Batch 19/64 loss: 1.7704025506973267
Batch 20/64 loss: 1.7682620286941528
Batch 21/64 loss: 1.7689402103424072
Batch 22/64 loss: 1.7712812423706055
Batch 23/64 loss: 1.7779535055160522
Batch 24/64 loss: 1.7796614170074463
Batch 25/64 loss: 1.7680370807647705
Batch 26/64 loss: 1.766808271408081
Batch 27/64 loss: 1.7662807703018188
Batch 28/64 loss: 1.773176908493042
Batch 29/64 loss: 1.768172264099121
Batch 30/64 loss: 1.7687283754348755
Batch 31/64 loss: 1.7726552486419678
Batch 32/64 loss: 1.7725675106048584
Batch 33/64 loss: 1.76616632938385
Batch 34/64 loss: 1.7645139694213867
Batch 35/64 loss: 1.7685823440551758
Batch 36/64 loss: 1.7726752758026123
Batch 37/64 loss: 1.7687655687332153
Batch 38/64 loss: 1.764775276184082
Batch 39/64 loss: 1.7687814235687256
Batch 40/64 loss: 1.7690171003341675
Batch 41/64 loss: 1.7688616514205933
Batch 42/64 loss: 1.7688794136047363
Batch 43/64 loss: 1.7709518671035767
Batch 44/64 loss: 1.7693960666656494
Batch 45/64 loss: 1.7711910009384155
Batch 46/64 loss: 1.7654049396514893
Batch 47/64 loss: 1.767492413520813
Batch 48/64 loss: 1.7677586078643799
Batch 49/64 loss: 1.7772293090820312
Batch 50/64 loss: 1.7736656665802002
Batch 51/64 loss: 1.7735426425933838
Batch 52/64 loss: 1.7836092710494995
Batch 53/64 loss: 1.774512529373169
Batch 54/64 loss: 1.7671126127243042
Batch 55/64 loss: 1.7674921751022339
Batch 56/64 loss: 1.769092321395874
Batch 57/64 loss: 1.7690434455871582
Batch 58/64 loss: 1.7679044008255005
Batch 59/64 loss: 1.7742111682891846
Batch 60/64 loss: 1.7800040245056152
Batch 61/64 loss: 1.7698559761047363
Batch 62/64 loss: 1.7831311225891113
Batch 63/64 loss: 1.7761993408203125
Batch 64/64 loss: 1.9801688194274902
Epoch 63  Train loss: 1.7746842552633846  Val loss: 1.7970767135882295
Epoch 64
-------------------------------
Batch 1/64 loss: 1.779142141342163
Batch 2/64 loss: 1.7751520872116089
Batch 3/64 loss: 1.7702817916870117
Batch 4/64 loss: 1.7699666023254395
Batch 5/64 loss: 1.7725127935409546
Batch 6/64 loss: 1.7695510387420654
Batch 7/64 loss: 1.7705514430999756
Batch 8/64 loss: 1.7690495252609253
Batch 9/64 loss: 1.7729400396347046
Batch 10/64 loss: 1.7728970050811768
Batch 11/64 loss: 1.7692018747329712
Batch 12/64 loss: 1.7688274383544922
Batch 13/64 loss: 1.7792174816131592
Batch 14/64 loss: 1.7676756381988525
Batch 15/64 loss: 1.7711728811264038
Batch 16/64 loss: 1.773363471031189
Batch 17/64 loss: 1.7697300910949707
Batch 18/64 loss: 1.769806146621704
Batch 19/64 loss: 1.7675203084945679
Batch 20/64 loss: 1.7693250179290771
Batch 21/64 loss: 1.7728432416915894
Batch 22/64 loss: 1.7727408409118652
Batch 23/64 loss: 1.7699710130691528
Batch 24/64 loss: 1.7725865840911865
Batch 25/64 loss: 1.7729008197784424
Batch 26/64 loss: 1.7660436630249023
Batch 27/64 loss: 1.7746686935424805
Batch 28/64 loss: 1.7665338516235352
Batch 29/64 loss: 1.7744799852371216
Batch 30/64 loss: 1.7708501815795898
Batch 31/64 loss: 1.768937349319458
Batch 32/64 loss: 1.7670061588287354
Batch 33/64 loss: 1.771094799041748
Batch 34/64 loss: 1.7753961086273193
Batch 35/64 loss: 1.7868893146514893
Batch 36/64 loss: 1.7705425024032593
Batch 37/64 loss: 1.7754926681518555
Batch 38/64 loss: 1.7679804563522339
Batch 39/64 loss: 1.7665066719055176
Batch 40/64 loss: 1.766685962677002
Batch 41/64 loss: 1.768747091293335
Batch 42/64 loss: 1.7673999071121216
Batch 43/64 loss: 1.769861102104187
Batch 44/64 loss: 1.7684420347213745
Batch 45/64 loss: 1.7711771726608276
Batch 46/64 loss: 1.7681093215942383
Batch 47/64 loss: 1.7679429054260254
Batch 48/64 loss: 1.7719995975494385
Batch 49/64 loss: 1.7707024812698364
Batch 50/64 loss: 1.7658730745315552
Batch 51/64 loss: 1.7743793725967407
Batch 52/64 loss: 1.7701407670974731
Batch 53/64 loss: 1.7757242918014526
Batch 54/64 loss: 1.7766952514648438
Batch 55/64 loss: 1.7754589319229126
Batch 56/64 loss: 1.7708972692489624
Batch 57/64 loss: 1.7819178104400635
Batch 58/64 loss: 1.780624508857727
Batch 59/64 loss: 1.7747453451156616
Batch 60/64 loss: 1.78877592086792
Batch 61/64 loss: 1.7693555355072021
Batch 62/64 loss: 1.7678693532943726
Batch 63/64 loss: 1.7782992124557495
Batch 64/64 loss: 1.9926841259002686
Epoch 64  Train loss: 1.7745519535214294  Val loss: 1.8105883336149131
Epoch 65
-------------------------------
Batch 1/64 loss: 1.7720271348953247
Batch 2/64 loss: 1.7738404273986816
Batch 3/64 loss: 1.7717305421829224
Batch 4/64 loss: 1.7882342338562012
Batch 5/64 loss: 1.7746614217758179
Batch 6/64 loss: 1.776098608970642
Batch 7/64 loss: 1.7746572494506836
Batch 8/64 loss: 1.7722768783569336
Batch 9/64 loss: 1.772857427597046
Batch 10/64 loss: 1.774003505706787
Batch 11/64 loss: 1.778417706489563
Batch 12/64 loss: 1.770216464996338
Batch 13/64 loss: 1.77262282371521
Batch 14/64 loss: 1.7677043676376343
Batch 15/64 loss: 1.7724344730377197
Batch 16/64 loss: 1.7689069509506226
Batch 17/64 loss: 1.7750071287155151
Batch 18/64 loss: 1.7705349922180176
Batch 19/64 loss: 1.767162799835205
Batch 20/64 loss: 1.7700847387313843
Batch 21/64 loss: 1.7743515968322754
Batch 22/64 loss: 1.771124243736267
Batch 23/64 loss: 1.7685171365737915
Batch 24/64 loss: 1.7741049528121948
Batch 25/64 loss: 1.7706129550933838
Batch 26/64 loss: 1.7697702646255493
Batch 27/64 loss: 1.7681360244750977
Batch 28/64 loss: 1.773158073425293
Batch 29/64 loss: 1.7697561979293823
Batch 30/64 loss: 1.7730298042297363
Batch 31/64 loss: 1.7738609313964844
Batch 32/64 loss: 1.767763376235962
Batch 33/64 loss: 1.7837830781936646
Batch 34/64 loss: 1.7841756343841553
Batch 35/64 loss: 1.769234299659729
Batch 36/64 loss: 1.7673656940460205
Batch 37/64 loss: 1.7706947326660156
Batch 38/64 loss: 1.7734047174453735
Batch 39/64 loss: 1.769048810005188
Batch 40/64 loss: 1.7783458232879639
Batch 41/64 loss: 1.7750147581100464
Batch 42/64 loss: 1.769267201423645
Batch 43/64 loss: 1.7685935497283936
Batch 44/64 loss: 1.7731173038482666
Batch 45/64 loss: 1.762012004852295
Batch 46/64 loss: 1.7691572904586792
Batch 47/64 loss: 1.773566484451294
Batch 48/64 loss: 1.7682573795318604
Batch 49/64 loss: 1.7709624767303467
Batch 50/64 loss: 1.7709941864013672
Batch 51/64 loss: 1.7693395614624023
Batch 52/64 loss: 1.769568920135498
Batch 53/64 loss: 1.7739253044128418
Batch 54/64 loss: 1.772716760635376
Batch 55/64 loss: 1.7734030485153198
Batch 56/64 loss: 1.7731974124908447
Batch 57/64 loss: 1.7714390754699707
Batch 58/64 loss: 1.7692219018936157
Batch 59/64 loss: 1.7715038061141968
Batch 60/64 loss: 1.7715336084365845
Batch 61/64 loss: 1.7669683694839478
Batch 62/64 loss: 1.7667152881622314
Batch 63/64 loss: 1.7668529748916626
Batch 64/64 loss: 1.982511281967163
Epoch 65  Train loss: 1.7743989074931426  Val loss: 1.7994897726065515
Epoch 66
-------------------------------
Batch 1/64 loss: 1.7696292400360107
Batch 2/64 loss: 1.7666611671447754
Batch 3/64 loss: 1.765700101852417
Batch 4/64 loss: 1.7699347734451294
Batch 5/64 loss: 1.7686916589736938
Batch 6/64 loss: 1.7726130485534668
Batch 7/64 loss: 1.7745758295059204
Batch 8/64 loss: 1.772597312927246
Batch 9/64 loss: 1.7753716707229614
Batch 10/64 loss: 1.7732442617416382
Batch 11/64 loss: 1.7651833295822144
Batch 12/64 loss: 1.7725555896759033
Batch 13/64 loss: 1.7691198587417603
Batch 14/64 loss: 1.7762283086776733
Batch 15/64 loss: 1.7724106311798096
Batch 16/64 loss: 1.7683522701263428
Batch 17/64 loss: 1.7686675786972046
Batch 18/64 loss: 1.7671427726745605
Batch 19/64 loss: 1.7731961011886597
Batch 20/64 loss: 1.7698994874954224
Batch 21/64 loss: 1.7671685218811035
Batch 22/64 loss: 1.7765398025512695
Batch 23/64 loss: 1.7701163291931152
Batch 24/64 loss: 1.7645983695983887
Batch 25/64 loss: 1.7724394798278809
Batch 26/64 loss: 1.7691874504089355
Batch 27/64 loss: 1.775923252105713
Batch 28/64 loss: 1.768850564956665
Batch 29/64 loss: 1.7746855020523071
Batch 30/64 loss: 1.7725774049758911
Batch 31/64 loss: 1.7707397937774658
Batch 32/64 loss: 1.7744346857070923
Batch 33/64 loss: 1.7751245498657227
Batch 34/64 loss: 1.7740286588668823
Batch 35/64 loss: 1.7721575498580933
Batch 36/64 loss: 1.7966300249099731
Batch 37/64 loss: 1.7714784145355225
Batch 38/64 loss: 1.7748277187347412
Batch 39/64 loss: 1.7709859609603882
Batch 40/64 loss: 1.7797865867614746
Batch 41/64 loss: 1.7841336727142334
Batch 42/64 loss: 1.7759042978286743
Batch 43/64 loss: 1.766884684562683
Batch 44/64 loss: 1.7730858325958252
Batch 45/64 loss: 1.7699235677719116
Batch 46/64 loss: 1.772434949874878
Batch 47/64 loss: 1.770599603652954
Batch 48/64 loss: 1.7742890119552612
Batch 49/64 loss: 1.7688125371932983
Batch 50/64 loss: 1.7681553363800049
Batch 51/64 loss: 1.7680641412734985
Batch 52/64 loss: 1.7699092626571655
Batch 53/64 loss: 1.7672717571258545
Batch 54/64 loss: 1.768222689628601
Batch 55/64 loss: 1.7658573389053345
Batch 56/64 loss: 1.7700027227401733
Batch 57/64 loss: 1.7810871601104736
Batch 58/64 loss: 1.775153398513794
Batch 59/64 loss: 1.769726276397705
Batch 60/64 loss: 1.7755253314971924
Batch 61/64 loss: 1.7690725326538086
Batch 62/64 loss: 1.7722408771514893
Batch 63/64 loss: 1.775219440460205
Batch 64/64 loss: 1.977672815322876
Epoch 66  Train loss: 1.7744139082291548  Val loss: 1.7964676966781878
Epoch 67
-------------------------------
Batch 1/64 loss: 1.771519660949707
Batch 2/64 loss: 1.7878985404968262
Batch 3/64 loss: 1.7698935270309448
Batch 4/64 loss: 1.7731584310531616
Batch 5/64 loss: 1.768446683883667
Batch 6/64 loss: 1.7702137231826782
Batch 7/64 loss: 1.7676877975463867
Batch 8/64 loss: 1.7682321071624756
Batch 9/64 loss: 1.7665269374847412
Batch 10/64 loss: 1.769911289215088
Batch 11/64 loss: 1.769516110420227
Batch 12/64 loss: 1.7690238952636719
Batch 13/64 loss: 1.77072274684906
Batch 14/64 loss: 1.764906406402588
Batch 15/64 loss: 1.7714205980300903
Batch 16/64 loss: 1.7669918537139893
Batch 17/64 loss: 1.767961859703064
Batch 18/64 loss: 1.7708330154418945
Batch 19/64 loss: 1.7835617065429688
Batch 20/64 loss: 1.7669687271118164
Batch 21/64 loss: 1.7674332857131958
Batch 22/64 loss: 1.7717959880828857
Batch 23/64 loss: 1.7704780101776123
Batch 24/64 loss: 1.7684590816497803
Batch 25/64 loss: 1.7674123048782349
Batch 26/64 loss: 1.766312837600708
Batch 27/64 loss: 1.768256425857544
Batch 28/64 loss: 1.7723029851913452
Batch 29/64 loss: 1.7694132328033447
Batch 30/64 loss: 1.7691774368286133
Batch 31/64 loss: 1.7719175815582275
Batch 32/64 loss: 1.7656834125518799
Batch 33/64 loss: 1.7663377523422241
Batch 34/64 loss: 1.7657159566879272
Batch 35/64 loss: 1.7687668800354004
Batch 36/64 loss: 1.7718364000320435
Batch 37/64 loss: 1.774621605873108
Batch 38/64 loss: 1.770477294921875
Batch 39/64 loss: 1.7678762674331665
Batch 40/64 loss: 1.7702088356018066
Batch 41/64 loss: 1.7654551267623901
Batch 42/64 loss: 1.7722406387329102
Batch 43/64 loss: 1.7697317600250244
Batch 44/64 loss: 1.769622564315796
Batch 45/64 loss: 1.7686443328857422
Batch 46/64 loss: 1.7732391357421875
Batch 47/64 loss: 1.7691434621810913
Batch 48/64 loss: 1.7805523872375488
Batch 49/64 loss: 1.7801034450531006
Batch 50/64 loss: 1.7728195190429688
Batch 51/64 loss: 1.774669885635376
Batch 52/64 loss: 1.788123607635498
Batch 53/64 loss: 1.7668519020080566
Batch 54/64 loss: 1.771498441696167
Batch 55/64 loss: 1.7689615488052368
Batch 56/64 loss: 1.7700583934783936
Batch 57/64 loss: 1.7679790258407593
Batch 58/64 loss: 1.7663547992706299
Batch 59/64 loss: 1.765509009361267
Batch 60/64 loss: 1.7665425539016724
Batch 61/64 loss: 1.7653918266296387
Batch 62/64 loss: 1.770727515220642
Batch 63/64 loss: 1.7647936344146729
Batch 64/64 loss: 1.9819936752319336
Epoch 67  Train loss: 1.7727904151467715  Val loss: 1.7920323712719266
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: 1.766930341720581
Batch 2/64 loss: 1.7684526443481445
Batch 3/64 loss: 1.7715940475463867
Batch 4/64 loss: 1.766790747642517
Batch 5/64 loss: 1.7682102918624878
Batch 6/64 loss: 1.7714502811431885
Batch 7/64 loss: 1.7694474458694458
Batch 8/64 loss: 1.767207145690918
Batch 9/64 loss: 1.76869535446167
Batch 10/64 loss: 1.7695798873901367
Batch 11/64 loss: 1.7650128602981567
Batch 12/64 loss: 1.7674493789672852
Batch 13/64 loss: 1.7641912698745728
Batch 14/64 loss: 1.7663815021514893
Batch 15/64 loss: 1.7689284086227417
Batch 16/64 loss: 1.7663021087646484
Batch 17/64 loss: 1.7661306858062744
Batch 18/64 loss: 1.765103816986084
Batch 19/64 loss: 1.7688052654266357
Batch 20/64 loss: 1.767000675201416
Batch 21/64 loss: 1.7680070400238037
Batch 22/64 loss: 1.7672998905181885
Batch 23/64 loss: 1.7681273221969604
Batch 24/64 loss: 1.7755582332611084
Batch 25/64 loss: 1.7669235467910767
Batch 26/64 loss: 1.7683745622634888
Batch 27/64 loss: 1.7647324800491333
Batch 28/64 loss: 1.766175627708435
Batch 29/64 loss: 1.7667591571807861
Batch 30/64 loss: 1.766127109527588
Batch 31/64 loss: 1.7649180889129639
Batch 32/64 loss: 1.7709486484527588
Batch 33/64 loss: 1.7654812335968018
Batch 34/64 loss: 1.7681920528411865
Batch 35/64 loss: 1.7657009363174438
Batch 36/64 loss: 1.772548794746399
Batch 37/64 loss: 1.7684111595153809
Batch 38/64 loss: 1.7833266258239746
Batch 39/64 loss: 1.766469120979309
Batch 40/64 loss: 1.7677901983261108
Batch 41/64 loss: 1.763335943222046
Batch 42/64 loss: 1.7651926279067993
Batch 43/64 loss: 1.7658926248550415
Batch 44/64 loss: 1.7667313814163208
Batch 45/64 loss: 1.7869856357574463
Batch 46/64 loss: 1.7666963338851929
Batch 47/64 loss: 1.7648221254348755
Batch 48/64 loss: 1.7718181610107422
Batch 49/64 loss: 1.772230863571167
Batch 50/64 loss: 1.7645812034606934
Batch 51/64 loss: 1.77034592628479
Batch 52/64 loss: 1.7700830698013306
Batch 53/64 loss: 1.76629638671875
Batch 54/64 loss: 1.7706997394561768
Batch 55/64 loss: 1.7676256895065308
Batch 56/64 loss: 1.7653309106826782
Batch 57/64 loss: 1.7638517618179321
Batch 58/64 loss: 1.7660373449325562
Batch 59/64 loss: 1.769288182258606
Batch 60/64 loss: 1.7687898874282837
Batch 61/64 loss: 1.768725037574768
Batch 62/64 loss: 1.7686424255371094
Batch 63/64 loss: 1.7689440250396729
Batch 64/64 loss: 1.9822720289230347
Epoch 68  Train loss: 1.7707480360479917  Val loss: 1.7896568332750773
Saving best model, epoch: 68
Epoch 69
-------------------------------
Batch 1/64 loss: 1.7659282684326172
Batch 2/64 loss: 1.770761251449585
Batch 3/64 loss: 1.771614670753479
Batch 4/64 loss: 1.7768681049346924
Batch 5/64 loss: 1.764920949935913
Batch 6/64 loss: 1.7655137777328491
Batch 7/64 loss: 1.767709493637085
Batch 8/64 loss: 1.7640330791473389
Batch 9/64 loss: 1.768331527709961
Batch 10/64 loss: 1.7808187007904053
Batch 11/64 loss: 1.7638829946517944
Batch 12/64 loss: 1.7654281854629517
Batch 13/64 loss: 1.7663016319274902
Batch 14/64 loss: 1.7684286832809448
Batch 15/64 loss: 1.7647266387939453
Batch 16/64 loss: 1.7637442350387573
Batch 17/64 loss: 1.7654542922973633
Batch 18/64 loss: 1.7641150951385498
Batch 19/64 loss: 1.7683734893798828
Batch 20/64 loss: 1.7666982412338257
Batch 21/64 loss: 1.7653992176055908
Batch 22/64 loss: 1.763946294784546
Batch 23/64 loss: 1.7692983150482178
Batch 24/64 loss: 1.779334545135498
Batch 25/64 loss: 1.7680704593658447
Batch 26/64 loss: 1.76742422580719
Batch 27/64 loss: 1.7693824768066406
Batch 28/64 loss: 1.7698458433151245
Batch 29/64 loss: 1.7666336297988892
Batch 30/64 loss: 1.7705588340759277
Batch 31/64 loss: 1.7666735649108887
Batch 32/64 loss: 1.767037272453308
Batch 33/64 loss: 1.7627685070037842
Batch 34/64 loss: 1.7723703384399414
Batch 35/64 loss: 1.7698619365692139
Batch 36/64 loss: 1.7772448062896729
Batch 37/64 loss: 1.770094394683838
Batch 38/64 loss: 1.765075445175171
Batch 39/64 loss: 1.772109866142273
Batch 40/64 loss: 1.770937442779541
Batch 41/64 loss: 1.7648264169692993
Batch 42/64 loss: 1.7700847387313843
Batch 43/64 loss: 1.7705433368682861
Batch 44/64 loss: 1.768467903137207
Batch 45/64 loss: 1.766126036643982
Batch 46/64 loss: 1.7688380479812622
Batch 47/64 loss: 1.767364740371704
Batch 48/64 loss: 1.7658724784851074
Batch 49/64 loss: 1.7722270488739014
Batch 50/64 loss: 1.77140474319458
Batch 51/64 loss: 1.7738311290740967
Batch 52/64 loss: 1.7727735042572021
Batch 53/64 loss: 1.7698575258255005
Batch 54/64 loss: 1.762892484664917
Batch 55/64 loss: 1.7672321796417236
Batch 56/64 loss: 1.7706451416015625
Batch 57/64 loss: 1.7723722457885742
Batch 58/64 loss: 1.7860026359558105
Batch 59/64 loss: 1.7722128629684448
Batch 60/64 loss: 1.7659724950790405
Batch 61/64 loss: 1.7796093225479126
Batch 62/64 loss: 1.7664170265197754
Batch 63/64 loss: 1.7718698978424072
Batch 64/64 loss: 1.9812225103378296
Epoch 69  Train loss: 1.7716248086854522  Val loss: 1.788455181515094
Saving best model, epoch: 69
Epoch 70
-------------------------------
Batch 1/64 loss: 1.764451026916504
Batch 2/64 loss: 1.772265076637268
Batch 3/64 loss: 1.766641616821289
Batch 4/64 loss: 1.7725369930267334
Batch 5/64 loss: 1.7698758840560913
Batch 6/64 loss: 1.7661139965057373
Batch 7/64 loss: 1.7680352926254272
Batch 8/64 loss: 1.770230770111084
Batch 9/64 loss: 1.7690184116363525
Batch 10/64 loss: 1.7793197631835938
Batch 11/64 loss: 1.7671931982040405
Batch 12/64 loss: 1.7655853033065796
Batch 13/64 loss: 1.7744439840316772
Batch 14/64 loss: 1.7777506113052368
Batch 15/64 loss: 1.7788351774215698
Batch 16/64 loss: 1.7700767517089844
Batch 17/64 loss: 1.772169828414917
Batch 18/64 loss: 1.7669786214828491
Batch 19/64 loss: 1.7679134607315063
Batch 20/64 loss: 1.7752211093902588
Batch 21/64 loss: 1.7678990364074707
Batch 22/64 loss: 1.7781816720962524
Batch 23/64 loss: 1.7650362253189087
Batch 24/64 loss: 1.771635890007019
Batch 25/64 loss: 1.7683895826339722
Batch 26/64 loss: 1.7698769569396973
Batch 27/64 loss: 1.7666187286376953
Batch 28/64 loss: 1.778673768043518
Batch 29/64 loss: 1.766205906867981
Batch 30/64 loss: 1.76544988155365
Batch 31/64 loss: 1.7740858793258667
Batch 32/64 loss: 1.7672585248947144
Batch 33/64 loss: 1.7707343101501465
Batch 34/64 loss: 1.7653875350952148
Batch 35/64 loss: 1.7668235301971436
Batch 36/64 loss: 1.7671393156051636
Batch 37/64 loss: 1.7707054615020752
Batch 38/64 loss: 1.7705681324005127
Batch 39/64 loss: 1.7659237384796143
Batch 40/64 loss: 1.7655836343765259
Batch 41/64 loss: 1.7711971998214722
Batch 42/64 loss: 1.769284725189209
Batch 43/64 loss: 1.7674362659454346
Batch 44/64 loss: 1.7655701637268066
Batch 45/64 loss: 1.7687221765518188
Batch 46/64 loss: 1.7644965648651123
Batch 47/64 loss: 1.7665433883666992
Batch 48/64 loss: 1.7653284072875977
Batch 49/64 loss: 1.7709474563598633
Batch 50/64 loss: 1.7680590152740479
Batch 51/64 loss: 1.767892837524414
Batch 52/64 loss: 1.7669479846954346
Batch 53/64 loss: 1.7704718112945557
Batch 54/64 loss: 1.765473484992981
Batch 55/64 loss: 1.7750879526138306
Batch 56/64 loss: 1.7695587873458862
Batch 57/64 loss: 1.7906171083450317
Batch 58/64 loss: 1.7678970098495483
Batch 59/64 loss: 1.7680838108062744
Batch 60/64 loss: 1.772275686264038
Batch 61/64 loss: 1.76939857006073
Batch 62/64 loss: 1.7661750316619873
Batch 63/64 loss: 1.7723859548568726
Batch 64/64 loss: 1.9715685844421387
Epoch 70  Train loss: 1.7721625477659937  Val loss: 1.7931893043911333
Epoch 71
-------------------------------
Batch 1/64 loss: 1.766645908355713
Batch 2/64 loss: 1.7682416439056396
Batch 3/64 loss: 1.7684102058410645
Batch 4/64 loss: 1.7665791511535645
Batch 5/64 loss: 1.7657160758972168
Batch 6/64 loss: 1.76486074924469
Batch 7/64 loss: 1.7701480388641357
Batch 8/64 loss: 1.765381932258606
Batch 9/64 loss: 1.770723581314087
Batch 10/64 loss: 1.7764196395874023
Batch 11/64 loss: 1.7730902433395386
Batch 12/64 loss: 1.7863290309906006
Batch 13/64 loss: 1.7712833881378174
Batch 14/64 loss: 1.7773560285568237
Batch 15/64 loss: 1.7743586301803589
Batch 16/64 loss: 1.7742857933044434
Batch 17/64 loss: 1.7769837379455566
Batch 18/64 loss: 1.772628903388977
Batch 19/64 loss: 1.775841474533081
Batch 20/64 loss: 1.7709780931472778
Batch 21/64 loss: 1.7658700942993164
Batch 22/64 loss: 1.772001028060913
Batch 23/64 loss: 1.7653193473815918
Batch 24/64 loss: 1.7740023136138916
Batch 25/64 loss: 1.769098162651062
Batch 26/64 loss: 1.7719426155090332
Batch 27/64 loss: 1.775266408920288
Batch 28/64 loss: 1.7743775844573975
Batch 29/64 loss: 1.766096830368042
Batch 30/64 loss: 1.7810328006744385
Batch 31/64 loss: 1.7706525325775146
Batch 32/64 loss: 1.7658798694610596
Batch 33/64 loss: 1.7697311639785767
Batch 34/64 loss: 1.76460599899292
Batch 35/64 loss: 1.7681783437728882
Batch 36/64 loss: 1.7680182456970215
Batch 37/64 loss: 1.7650178670883179
Batch 38/64 loss: 1.7802973985671997
Batch 39/64 loss: 1.7688977718353271
Batch 40/64 loss: 1.7694883346557617
Batch 41/64 loss: 1.769940733909607
Batch 42/64 loss: 1.7675797939300537
Batch 43/64 loss: 1.7751790285110474
Batch 44/64 loss: 1.7687617540359497
Batch 45/64 loss: 1.7783859968185425
Batch 46/64 loss: 1.7695461511611938
Batch 47/64 loss: 1.7683427333831787
Batch 48/64 loss: 1.768181324005127
Batch 49/64 loss: 1.766880750656128
Batch 50/64 loss: 1.7672343254089355
Batch 51/64 loss: 1.7669825553894043
Batch 52/64 loss: 1.7663394212722778
Batch 53/64 loss: 1.7637114524841309
Batch 54/64 loss: 1.7670152187347412
Batch 55/64 loss: 1.787606954574585
Batch 56/64 loss: 1.7665295600891113
Batch 57/64 loss: 1.7669861316680908
Batch 58/64 loss: 1.7680233716964722
Batch 59/64 loss: 1.7708344459533691
Batch 60/64 loss: 1.766051173210144
Batch 61/64 loss: 1.7704277038574219
Batch 62/64 loss: 1.765796184539795
Batch 63/64 loss: 1.7684271335601807
Batch 64/64 loss: 1.9789248704910278
Epoch 71  Train loss: 1.7728783453212065  Val loss: 1.794880889125706
Epoch 72
-------------------------------
Batch 1/64 loss: 1.767507791519165
Batch 2/64 loss: 1.7706680297851562
Batch 3/64 loss: 1.7637298107147217
Batch 4/64 loss: 1.7658157348632812
Batch 5/64 loss: 1.7648069858551025
Batch 6/64 loss: 1.7655551433563232
Batch 7/64 loss: 1.7755072116851807
Batch 8/64 loss: 1.7902727127075195
Batch 9/64 loss: 1.7709511518478394
Batch 10/64 loss: 1.7703949213027954
Batch 11/64 loss: 1.7676191329956055
Batch 12/64 loss: 1.7683759927749634
Batch 13/64 loss: 1.7676219940185547
Batch 14/64 loss: 1.7659130096435547
Batch 15/64 loss: 1.765552282333374
Batch 16/64 loss: 1.7766202688217163
Batch 17/64 loss: 1.768649935722351
Batch 18/64 loss: 1.7695589065551758
Batch 19/64 loss: 1.769139051437378
Batch 20/64 loss: 1.7698657512664795
Batch 21/64 loss: 1.7806164026260376
Batch 22/64 loss: 1.7674845457077026
Batch 23/64 loss: 1.775402307510376
Batch 24/64 loss: 1.7735388278961182
Batch 25/64 loss: 1.7655036449432373
Batch 26/64 loss: 1.7718156576156616
Batch 27/64 loss: 1.7670789957046509
Batch 28/64 loss: 1.7677630186080933
Batch 29/64 loss: 1.7654634714126587
Batch 30/64 loss: 1.7698193788528442
Batch 31/64 loss: 1.7636895179748535
Batch 32/64 loss: 1.7643368244171143
Batch 33/64 loss: 1.7637686729431152
Batch 34/64 loss: 1.7675107717514038
Batch 35/64 loss: 1.7753559350967407
Batch 36/64 loss: 1.7659879922866821
Batch 37/64 loss: 1.7641525268554688
Batch 38/64 loss: 1.7738659381866455
Batch 39/64 loss: 1.7697312831878662
Batch 40/64 loss: 1.7663111686706543
Batch 41/64 loss: 1.7650818824768066
Batch 42/64 loss: 1.769153118133545
Batch 43/64 loss: 1.767931342124939
Batch 44/64 loss: 1.7618845701217651
Batch 45/64 loss: 1.7691084146499634
Batch 46/64 loss: 1.7658872604370117
Batch 47/64 loss: 1.7698915004730225
Batch 48/64 loss: 1.7653952836990356
Batch 49/64 loss: 1.7689071893692017
Batch 50/64 loss: 1.764462947845459
Batch 51/64 loss: 1.7645161151885986
Batch 52/64 loss: 1.7657222747802734
Batch 53/64 loss: 1.7657983303070068
Batch 54/64 loss: 1.7684067487716675
Batch 55/64 loss: 1.7630717754364014
Batch 56/64 loss: 1.765071988105774
Batch 57/64 loss: 1.7640459537506104
Batch 58/64 loss: 1.764413595199585
Batch 59/64 loss: 1.7620365619659424
Batch 60/64 loss: 1.7674146890640259
Batch 61/64 loss: 1.7689768075942993
Batch 62/64 loss: 1.7665702104568481
Batch 63/64 loss: 1.7683093547821045
Batch 64/64 loss: 1.9719128608703613
Epoch 72  Train loss: 1.7705774943033854  Val loss: 1.796984105585367
Epoch 73
-------------------------------
Batch 1/64 loss: 1.7687019109725952
Batch 2/64 loss: 1.762100338935852
Batch 3/64 loss: 1.7624108791351318
Batch 4/64 loss: 1.7625867128372192
Batch 5/64 loss: 1.771317720413208
Batch 6/64 loss: 1.779024362564087
Batch 7/64 loss: 1.781035304069519
Batch 8/64 loss: 1.7641525268554688
Batch 9/64 loss: 1.7714378833770752
Batch 10/64 loss: 1.7706449031829834
Batch 11/64 loss: 1.7634823322296143
Batch 12/64 loss: 1.7664377689361572
Batch 13/64 loss: 1.7730979919433594
Batch 14/64 loss: 1.7648613452911377
Batch 15/64 loss: 1.764059066772461
Batch 16/64 loss: 1.763013243675232
Batch 17/64 loss: 1.7708848714828491
Batch 18/64 loss: 1.764850378036499
Batch 19/64 loss: 1.7607061862945557
Batch 20/64 loss: 1.765393614768982
Batch 21/64 loss: 1.7665746212005615
Batch 22/64 loss: 1.762439250946045
Batch 23/64 loss: 1.7622820138931274
Batch 24/64 loss: 1.7626529932022095
Batch 25/64 loss: 1.7670971155166626
Batch 26/64 loss: 1.7621549367904663
Batch 27/64 loss: 1.763602614402771
Batch 28/64 loss: 1.7663217782974243
Batch 29/64 loss: 1.761573076248169
Batch 30/64 loss: 1.7615575790405273
Batch 31/64 loss: 1.7649080753326416
Batch 32/64 loss: 1.7730379104614258
Batch 33/64 loss: 1.7636938095092773
Batch 34/64 loss: 1.7617565393447876
Batch 35/64 loss: 1.76510751247406
Batch 36/64 loss: 1.7650293111801147
Batch 37/64 loss: 1.7836745977401733
Batch 38/64 loss: 1.7659242153167725
Batch 39/64 loss: 1.7670563459396362
Batch 40/64 loss: 1.7651550769805908
Batch 41/64 loss: 1.7683378458023071
Batch 42/64 loss: 1.763237714767456
Batch 43/64 loss: 1.7689292430877686
Batch 44/64 loss: 1.7664448022842407
Batch 45/64 loss: 1.7632389068603516
Batch 46/64 loss: 1.7700519561767578
Batch 47/64 loss: 1.7661551237106323
Batch 48/64 loss: 1.7660624980926514
Batch 49/64 loss: 1.7644474506378174
Batch 50/64 loss: 1.7626956701278687
Batch 51/64 loss: 1.760993480682373
Batch 52/64 loss: 1.7653285264968872
Batch 53/64 loss: 1.7648990154266357
Batch 54/64 loss: 1.7651704549789429
Batch 55/64 loss: 1.7645900249481201
Batch 56/64 loss: 1.7629759311676025
Batch 57/64 loss: 1.7676920890808105
Batch 58/64 loss: 1.7645260095596313
Batch 59/64 loss: 1.7642077207565308
Batch 60/64 loss: 1.7649421691894531
Batch 61/64 loss: 1.7621018886566162
Batch 62/64 loss: 1.7640304565429688
Batch 63/64 loss: 1.7650537490844727
Batch 64/64 loss: 1.9736864566802979
Epoch 73  Train loss: 1.7684419809603225  Val loss: 1.7864088479595905
Saving best model, epoch: 73
Epoch 74
-------------------------------
Batch 1/64 loss: 1.7797675132751465
Batch 2/64 loss: 1.7656904458999634
Batch 3/64 loss: 1.7719995975494385
Batch 4/64 loss: 1.7764097452163696
Batch 5/64 loss: 1.7683491706848145
Batch 6/64 loss: 1.7701218128204346
Batch 7/64 loss: 1.7675095796585083
Batch 8/64 loss: 1.7691147327423096
Batch 9/64 loss: 1.7703235149383545
Batch 10/64 loss: 1.7651610374450684
Batch 11/64 loss: 1.7675176858901978
Batch 12/64 loss: 1.7669079303741455
Batch 13/64 loss: 1.7654403448104858
Batch 14/64 loss: 1.7721168994903564
Batch 15/64 loss: 1.7680673599243164
Batch 16/64 loss: 1.773075819015503
Batch 17/64 loss: 1.768188714981079
Batch 18/64 loss: 1.7687265872955322
Batch 19/64 loss: 1.7666651010513306
Batch 20/64 loss: 1.766571283340454
Batch 21/64 loss: 1.7695860862731934
Batch 22/64 loss: 1.7688939571380615
Batch 23/64 loss: 1.7629384994506836
Batch 24/64 loss: 1.7659029960632324
Batch 25/64 loss: 1.7657500505447388
Batch 26/64 loss: 1.7615814208984375
Batch 27/64 loss: 1.7656770944595337
Batch 28/64 loss: 1.762014627456665
Batch 29/64 loss: 1.779538631439209
Batch 30/64 loss: 1.7627034187316895
Batch 31/64 loss: 1.7640376091003418
Batch 32/64 loss: 1.7607779502868652
Batch 33/64 loss: 1.7645642757415771
Batch 34/64 loss: 1.7668135166168213
Batch 35/64 loss: 1.7628016471862793
Batch 36/64 loss: 1.7628635168075562
Batch 37/64 loss: 1.7643308639526367
Batch 38/64 loss: 1.769052267074585
Batch 39/64 loss: 1.7653814554214478
Batch 40/64 loss: 1.7631853818893433
Batch 41/64 loss: 1.766291618347168
Batch 42/64 loss: 1.7666116952896118
Batch 43/64 loss: 1.7649407386779785
Batch 44/64 loss: 1.7654461860656738
Batch 45/64 loss: 1.7641479969024658
Batch 46/64 loss: 1.7708147764205933
Batch 47/64 loss: 1.7631508111953735
Batch 48/64 loss: 1.7831708192825317
Batch 49/64 loss: 1.7689989805221558
Batch 50/64 loss: 1.766622543334961
Batch 51/64 loss: 1.7687660455703735
Batch 52/64 loss: 1.7667973041534424
Batch 53/64 loss: 1.77725088596344
Batch 54/64 loss: 1.7709629535675049
Batch 55/64 loss: 1.767001986503601
Batch 56/64 loss: 1.7649539709091187
Batch 57/64 loss: 1.7677085399627686
Batch 58/64 loss: 1.766364574432373
Batch 59/64 loss: 1.7634872198104858
Batch 60/64 loss: 1.7672641277313232
Batch 61/64 loss: 1.7678419351577759
Batch 62/64 loss: 1.7689927816390991
Batch 63/64 loss: 1.761954426765442
Batch 64/64 loss: 1.9761487245559692
Epoch 74  Train loss: 1.7700043075224932  Val loss: 1.7875587882864516
Epoch 75
-------------------------------
Batch 1/64 loss: 1.768767237663269
Batch 2/64 loss: 1.7646886110305786
Batch 3/64 loss: 1.7639576196670532
Batch 4/64 loss: 1.7647852897644043
Batch 5/64 loss: 1.764554738998413
Batch 6/64 loss: 1.7698100805282593
Batch 7/64 loss: 1.7673243284225464
Batch 8/64 loss: 1.7717512845993042
Batch 9/64 loss: 1.776907205581665
Batch 10/64 loss: 1.7619874477386475
Batch 11/64 loss: 1.766486406326294
Batch 12/64 loss: 1.7653089761734009
Batch 13/64 loss: 1.7669661045074463
Batch 14/64 loss: 1.7712925672531128
Batch 15/64 loss: 1.7660138607025146
Batch 16/64 loss: 1.763303279876709
Batch 17/64 loss: 1.7656680345535278
Batch 18/64 loss: 1.7709383964538574
Batch 19/64 loss: 1.7637642621994019
Batch 20/64 loss: 1.765899896621704
Batch 21/64 loss: 1.7750976085662842
Batch 22/64 loss: 1.7688795328140259
Batch 23/64 loss: 1.7626909017562866
Batch 24/64 loss: 1.7658698558807373
Batch 25/64 loss: 1.7670481204986572
Batch 26/64 loss: 1.76698637008667
Batch 27/64 loss: 1.7663859128952026
Batch 28/64 loss: 1.773325800895691
Batch 29/64 loss: 1.7687679529190063
Batch 30/64 loss: 1.7722489833831787
Batch 31/64 loss: 1.768341302871704
Batch 32/64 loss: 1.7642652988433838
Batch 33/64 loss: 1.7630257606506348
Batch 34/64 loss: 1.765054702758789
Batch 35/64 loss: 1.7728657722473145
Batch 36/64 loss: 1.7663536071777344
Batch 37/64 loss: 1.7679630517959595
Batch 38/64 loss: 1.7705166339874268
Batch 39/64 loss: 1.7637745141983032
Batch 40/64 loss: 1.7680352926254272
Batch 41/64 loss: 1.767270565032959
Batch 42/64 loss: 1.7660212516784668
Batch 43/64 loss: 1.779270887374878
Batch 44/64 loss: 1.7715257406234741
Batch 45/64 loss: 1.7672957181930542
Batch 46/64 loss: 1.7647912502288818
Batch 47/64 loss: 1.7664719820022583
Batch 48/64 loss: 1.7700382471084595
Batch 49/64 loss: 1.768013834953308
Batch 50/64 loss: 1.7655844688415527
Batch 51/64 loss: 1.7685998678207397
Batch 52/64 loss: 1.7807738780975342
Batch 53/64 loss: 1.7689378261566162
Batch 54/64 loss: 1.7683601379394531
Batch 55/64 loss: 1.7831833362579346
Batch 56/64 loss: 1.768906831741333
Batch 57/64 loss: 1.7656861543655396
Batch 58/64 loss: 1.7656842470169067
Batch 59/64 loss: 1.764809489250183
Batch 60/64 loss: 1.7665807008743286
Batch 61/64 loss: 1.7680790424346924
Batch 62/64 loss: 1.768192172050476
Batch 63/64 loss: 1.772689938545227
Batch 64/64 loss: 1.9738218784332275
Epoch 75  Train loss: 1.7705852013008267  Val loss: 1.7917249186342115
Epoch 76
-------------------------------
Batch 1/64 loss: 1.7721030712127686
Batch 2/64 loss: 1.7647472620010376
Batch 3/64 loss: 1.7670857906341553
Batch 4/64 loss: 1.7682271003723145
Batch 5/64 loss: 1.7754976749420166
Batch 6/64 loss: 1.768430233001709
Batch 7/64 loss: 1.765020489692688
Batch 8/64 loss: 1.7636938095092773
Batch 9/64 loss: 1.7630614042282104
Batch 10/64 loss: 1.769939661026001
Batch 11/64 loss: 1.7648091316223145
Batch 12/64 loss: 1.7663464546203613
Batch 13/64 loss: 1.767665982246399
Batch 14/64 loss: 1.7631336450576782
Batch 15/64 loss: 1.7724626064300537
Batch 16/64 loss: 1.7640150785446167
Batch 17/64 loss: 1.7710895538330078
Batch 18/64 loss: 1.7672910690307617
Batch 19/64 loss: 1.767082929611206
Batch 20/64 loss: 1.7653151750564575
Batch 21/64 loss: 1.7664376497268677
Batch 22/64 loss: 1.774653434753418
Batch 23/64 loss: 1.7678436040878296
Batch 24/64 loss: 1.7621492147445679
Batch 25/64 loss: 1.7743350267410278
Batch 26/64 loss: 1.7665014266967773
Batch 27/64 loss: 1.768009901046753
Batch 28/64 loss: 1.7635387182235718
Batch 29/64 loss: 1.7661197185516357
Batch 30/64 loss: 1.7697163820266724
Batch 31/64 loss: 1.7692123651504517
Batch 32/64 loss: 1.7629613876342773
Batch 33/64 loss: 1.7693400382995605
Batch 34/64 loss: 1.769635796546936
Batch 35/64 loss: 1.7695863246917725
Batch 36/64 loss: 1.770002007484436
Batch 37/64 loss: 1.7720973491668701
Batch 38/64 loss: 1.7700634002685547
Batch 39/64 loss: 1.7756619453430176
Batch 40/64 loss: 1.7639769315719604
Batch 41/64 loss: 1.768263578414917
Batch 42/64 loss: 1.768117070198059
Batch 43/64 loss: 1.7681655883789062
Batch 44/64 loss: 1.7693514823913574
Batch 45/64 loss: 1.7680182456970215
Batch 46/64 loss: 1.766901969909668
Batch 47/64 loss: 1.7640094757080078
Batch 48/64 loss: 1.7703227996826172
Batch 49/64 loss: 1.7668709754943848
Batch 50/64 loss: 1.7685507535934448
Batch 51/64 loss: 1.7823328971862793
Batch 52/64 loss: 1.7683480978012085
Batch 53/64 loss: 1.7837921380996704
Batch 54/64 loss: 1.7675985097885132
Batch 55/64 loss: 1.7657703161239624
Batch 56/64 loss: 1.7678855657577515
Batch 57/64 loss: 1.768708348274231
Batch 58/64 loss: 1.7664768695831299
Batch 59/64 loss: 1.7688815593719482
Batch 60/64 loss: 1.7718374729156494
Batch 61/64 loss: 1.7676823139190674
Batch 62/64 loss: 1.7655558586120605
Batch 63/64 loss: 1.7646760940551758
Batch 64/64 loss: 1.981420874595642
Epoch 76  Train loss: 1.7708712844287648  Val loss: 1.7938230160585384
Epoch 77
-------------------------------
Batch 1/64 loss: 1.7682392597198486
Batch 2/64 loss: 1.7699105739593506
Batch 3/64 loss: 1.7726534605026245
Batch 4/64 loss: 1.765209436416626
Batch 5/64 loss: 1.7745716571807861
Batch 6/64 loss: 1.7714874744415283
Batch 7/64 loss: 1.7659244537353516
Batch 8/64 loss: 1.7687205076217651
Batch 9/64 loss: 1.7681587934494019
Batch 10/64 loss: 1.7651082277297974
Batch 11/64 loss: 1.767797827720642
Batch 12/64 loss: 1.7739580869674683
Batch 13/64 loss: 1.7727530002593994
Batch 14/64 loss: 1.7720615863800049
Batch 15/64 loss: 1.7680015563964844
Batch 16/64 loss: 1.7740269899368286
Batch 17/64 loss: 1.7703015804290771
Batch 18/64 loss: 1.7700145244598389
Batch 19/64 loss: 1.7683491706848145
Batch 20/64 loss: 1.767846703529358
Batch 21/64 loss: 1.7669942378997803
Batch 22/64 loss: 1.7667205333709717
Batch 23/64 loss: 1.7752861976623535
Batch 24/64 loss: 1.7655954360961914
Batch 25/64 loss: 1.7693743705749512
Batch 26/64 loss: 1.771867275238037
Batch 27/64 loss: 1.7714121341705322
Batch 28/64 loss: 1.7644107341766357
Batch 29/64 loss: 1.7680085897445679
Batch 30/64 loss: 1.7687873840332031
Batch 31/64 loss: 1.7644768953323364
Batch 32/64 loss: 1.7673912048339844
Batch 33/64 loss: 1.77202570438385
Batch 34/64 loss: 1.7693709135055542
Batch 35/64 loss: 1.7717245817184448
Batch 36/64 loss: 1.7708773612976074
Batch 37/64 loss: 1.7673282623291016
Batch 38/64 loss: 1.7962342500686646
Batch 39/64 loss: 1.7754323482513428
Batch 40/64 loss: 1.7648015022277832
Batch 41/64 loss: 1.7683802843093872
Batch 42/64 loss: 1.7627458572387695
Batch 43/64 loss: 1.7672538757324219
Batch 44/64 loss: 1.7676301002502441
Batch 45/64 loss: 1.7664223909378052
Batch 46/64 loss: 1.7660715579986572
Batch 47/64 loss: 1.7635815143585205
Batch 48/64 loss: 1.7658746242523193
Batch 49/64 loss: 1.7657279968261719
Batch 50/64 loss: 1.767628788948059
Batch 51/64 loss: 1.763289451599121
Batch 52/64 loss: 1.7675737142562866
Batch 53/64 loss: 1.763540267944336
Batch 54/64 loss: 1.7633421421051025
Batch 55/64 loss: 1.7706167697906494
Batch 56/64 loss: 1.7712291479110718
Batch 57/64 loss: 1.7653110027313232
Batch 58/64 loss: 1.7675220966339111
Batch 59/64 loss: 1.7689813375473022
Batch 60/64 loss: 1.7659657001495361
Batch 61/64 loss: 1.7662009000778198
Batch 62/64 loss: 1.7683665752410889
Batch 63/64 loss: 1.766413927078247
Batch 64/64 loss: 1.9827289581298828
Epoch 77  Train loss: 1.7712930436227836  Val loss: 1.7945108585750933
Epoch 78
-------------------------------
Batch 1/64 loss: 1.7688143253326416
Batch 2/64 loss: 1.7724138498306274
Batch 3/64 loss: 1.7679704427719116
Batch 4/64 loss: 1.769487738609314
Batch 5/64 loss: 1.7703943252563477
Batch 6/64 loss: 1.7732765674591064
Batch 7/64 loss: 1.777745246887207
Batch 8/64 loss: 1.765799880027771
Batch 9/64 loss: 1.7700586318969727
Batch 10/64 loss: 1.7671757936477661
Batch 11/64 loss: 1.7714874744415283
Batch 12/64 loss: 1.770512580871582
Batch 13/64 loss: 1.7715035676956177
Batch 14/64 loss: 1.770050287246704
Batch 15/64 loss: 1.7784262895584106
Batch 16/64 loss: 1.7704997062683105
Batch 17/64 loss: 1.76650869846344
Batch 18/64 loss: 1.7733798027038574
Batch 19/64 loss: 1.7647738456726074
Batch 20/64 loss: 1.7691881656646729
Batch 21/64 loss: 1.7682501077651978
Batch 22/64 loss: 1.777055263519287
Batch 23/64 loss: 1.7752790451049805
Batch 24/64 loss: 1.7639347314834595
Batch 25/64 loss: 1.772844672203064
Batch 26/64 loss: 1.76665198802948
Batch 27/64 loss: 1.7677916288375854
Batch 28/64 loss: 1.767811894416809
Batch 29/64 loss: 1.7707675695419312
Batch 30/64 loss: 1.769416332244873
Batch 31/64 loss: 1.7709274291992188
Batch 32/64 loss: 1.7764527797698975
Batch 33/64 loss: 1.7714321613311768
Batch 34/64 loss: 1.77369225025177
Batch 35/64 loss: 1.7768783569335938
Batch 36/64 loss: 1.7714054584503174
Batch 37/64 loss: 1.7727123498916626
Batch 38/64 loss: 1.7698681354522705
Batch 39/64 loss: 1.7838783264160156
Batch 40/64 loss: 1.7697772979736328
Batch 41/64 loss: 1.772711157798767
Batch 42/64 loss: 1.771227478981018
Batch 43/64 loss: 1.7656246423721313
Batch 44/64 loss: 1.7677836418151855
Batch 45/64 loss: 1.7699965238571167
Batch 46/64 loss: 1.768600344657898
Batch 47/64 loss: 1.7665728330612183
Batch 48/64 loss: 1.766170859336853
Batch 49/64 loss: 1.7669841051101685
Batch 50/64 loss: 1.7671504020690918
Batch 51/64 loss: 1.770336389541626
Batch 52/64 loss: 1.7838693857192993
Batch 53/64 loss: 1.7715752124786377
Batch 54/64 loss: 1.7729448080062866
Batch 55/64 loss: 1.7683731317520142
Batch 56/64 loss: 1.768207311630249
Batch 57/64 loss: 1.7777434587478638
Batch 58/64 loss: 1.7668545246124268
Batch 59/64 loss: 1.7677804231643677
Batch 60/64 loss: 1.7704622745513916
Batch 61/64 loss: 1.7666146755218506
Batch 62/64 loss: 1.7704864740371704
Batch 63/64 loss: 1.7692277431488037
Batch 64/64 loss: 1.9706611633300781
Epoch 78  Train loss: 1.7730445282132017  Val loss: 1.7907375355356747
Epoch 79
-------------------------------
Batch 1/64 loss: 1.7667806148529053
Batch 2/64 loss: 1.7651582956314087
Batch 3/64 loss: 1.7663918733596802
Batch 4/64 loss: 1.762238621711731
Batch 5/64 loss: 1.763854742050171
Batch 6/64 loss: 1.7667677402496338
Batch 7/64 loss: 1.766731858253479
Batch 8/64 loss: 1.7666194438934326
Batch 9/64 loss: 1.7692383527755737
Batch 10/64 loss: 1.7694761753082275
Batch 11/64 loss: 1.7673523426055908
Batch 12/64 loss: 1.7684638500213623
Batch 13/64 loss: 1.7641782760620117
Batch 14/64 loss: 1.7705535888671875
Batch 15/64 loss: 1.7698805332183838
Batch 16/64 loss: 1.7734017372131348
Batch 17/64 loss: 1.765453815460205
Batch 18/64 loss: 1.7686058282852173
Batch 19/64 loss: 1.7798874378204346
Batch 20/64 loss: 1.7673598527908325
Batch 21/64 loss: 1.765418529510498
Batch 22/64 loss: 1.7694941759109497
Batch 23/64 loss: 1.7635657787322998
Batch 24/64 loss: 1.766496181488037
Batch 25/64 loss: 1.7661892175674438
Batch 26/64 loss: 1.769768238067627
Batch 27/64 loss: 1.7684340476989746
Batch 28/64 loss: 1.7695025205612183
Batch 29/64 loss: 1.7634950876235962
Batch 30/64 loss: 1.768444538116455
Batch 31/64 loss: 1.7702518701553345
Batch 32/64 loss: 1.7646937370300293
Batch 33/64 loss: 1.7682735919952393
Batch 34/64 loss: 1.7740919589996338
Batch 35/64 loss: 1.7672477960586548
Batch 36/64 loss: 1.7678325176239014
Batch 37/64 loss: 1.7676032781600952
Batch 38/64 loss: 1.7937275171279907
Batch 39/64 loss: 1.7630302906036377
Batch 40/64 loss: 1.770154595375061
Batch 41/64 loss: 1.7682738304138184
Batch 42/64 loss: 1.765733242034912
Batch 43/64 loss: 1.7683603763580322
Batch 44/64 loss: 1.7735947370529175
Batch 45/64 loss: 1.7725799083709717
Batch 46/64 loss: 1.7669755220413208
Batch 47/64 loss: 1.7727559804916382
Batch 48/64 loss: 1.7646931409835815
Batch 49/64 loss: 1.7685434818267822
Batch 50/64 loss: 1.7677738666534424
Batch 51/64 loss: 1.7718675136566162
Batch 52/64 loss: 1.7658047676086426
Batch 53/64 loss: 1.7767620086669922
Batch 54/64 loss: 1.7694015502929688
Batch 55/64 loss: 1.7692477703094482
Batch 56/64 loss: 1.7665220499038696
Batch 57/64 loss: 1.7685832977294922
Batch 58/64 loss: 1.7643910646438599
Batch 59/64 loss: 1.7657933235168457
Batch 60/64 loss: 1.7659212350845337
Batch 61/64 loss: 1.7641808986663818
Batch 62/64 loss: 1.766282320022583
Batch 63/64 loss: 1.7631243467330933
Batch 64/64 loss: 1.9679951667785645
Epoch 79  Train loss: 1.7706552636389639  Val loss: 1.791738641221089
Epoch 80
-------------------------------
Batch 1/64 loss: 1.765275001525879
Batch 2/64 loss: 1.7650978565216064
Batch 3/64 loss: 1.7651469707489014
Batch 4/64 loss: 1.7650548219680786
Batch 5/64 loss: 1.7680554389953613
Batch 6/64 loss: 1.7628676891326904
Batch 7/64 loss: 1.768385648727417
Batch 8/64 loss: 1.7680387496948242
Batch 9/64 loss: 1.7712804079055786
Batch 10/64 loss: 1.7669775485992432
Batch 11/64 loss: 1.7656854391098022
Batch 12/64 loss: 1.7648998498916626
Batch 13/64 loss: 1.7841986417770386
Batch 14/64 loss: 1.771935224533081
Batch 15/64 loss: 1.7667889595031738
Batch 16/64 loss: 1.7718065977096558
Batch 17/64 loss: 1.7651393413543701
Batch 18/64 loss: 1.764060616493225
Batch 19/64 loss: 1.7624510526657104
Batch 20/64 loss: 1.7620247602462769
Batch 21/64 loss: 1.7685573101043701
Batch 22/64 loss: 1.760850191116333
Batch 23/64 loss: 1.7638607025146484
Batch 24/64 loss: 1.7634282112121582
Batch 25/64 loss: 1.7657952308654785
Batch 26/64 loss: 1.7665607929229736
Batch 27/64 loss: 1.7663779258728027
Batch 28/64 loss: 1.7664130926132202
Batch 29/64 loss: 1.7708685398101807
Batch 30/64 loss: 1.7625130414962769
Batch 31/64 loss: 1.7638893127441406
Batch 32/64 loss: 1.7703800201416016
Batch 33/64 loss: 1.762451171875
Batch 34/64 loss: 1.7631220817565918
Batch 35/64 loss: 1.7674334049224854
Batch 36/64 loss: 1.7753196954727173
Batch 37/64 loss: 1.763924479484558
Batch 38/64 loss: 1.7650541067123413
Batch 39/64 loss: 1.767711877822876
Batch 40/64 loss: 1.7704349756240845
Batch 41/64 loss: 1.7687764167785645
Batch 42/64 loss: 1.7640399932861328
Batch 43/64 loss: 1.7657458782196045
Batch 44/64 loss: 1.7634260654449463
Batch 45/64 loss: 1.76486074924469
Batch 46/64 loss: 1.7634615898132324
Batch 47/64 loss: 1.7657709121704102
Batch 48/64 loss: 1.7622331380844116
Batch 49/64 loss: 1.7607769966125488
Batch 50/64 loss: 1.7646563053131104
Batch 51/64 loss: 1.764480710029602
Batch 52/64 loss: 1.767862319946289
Batch 53/64 loss: 1.7689472436904907
Batch 54/64 loss: 1.7641758918762207
Batch 55/64 loss: 1.761975884437561
Batch 56/64 loss: 1.7764241695404053
Batch 57/64 loss: 1.760457992553711
Batch 58/64 loss: 1.7731226682662964
Batch 59/64 loss: 1.784295916557312
Batch 60/64 loss: 1.7686853408813477
Batch 61/64 loss: 1.7729666233062744
Batch 62/64 loss: 1.7842658758163452
Batch 63/64 loss: 1.7709335088729858
Batch 64/64 loss: 1.9761416912078857
Epoch 80  Train loss: 1.7696402390797934  Val loss: 1.7961836893533922
Epoch 81
-------------------------------
Batch 1/64 loss: 1.766852617263794
Batch 2/64 loss: 1.7727104425430298
Batch 3/64 loss: 1.7695591449737549
Batch 4/64 loss: 1.7753374576568604
Batch 5/64 loss: 1.762707233428955
Batch 6/64 loss: 1.7642881870269775
Batch 7/64 loss: 1.7686775922775269
Batch 8/64 loss: 1.7652833461761475
Batch 9/64 loss: 1.7792489528656006
Batch 10/64 loss: 1.7681022882461548
Batch 11/64 loss: 1.7657811641693115
Batch 12/64 loss: 1.770177960395813
Batch 13/64 loss: 1.7659101486206055
Batch 14/64 loss: 1.7619411945343018
Batch 15/64 loss: 1.7627203464508057
Batch 16/64 loss: 1.7642217874526978
Batch 17/64 loss: 1.765376329421997
Batch 18/64 loss: 1.7645641565322876
Batch 19/64 loss: 1.766366958618164
Batch 20/64 loss: 1.763014793395996
Batch 21/64 loss: 1.7611161470413208
Batch 22/64 loss: 1.7630119323730469
Batch 23/64 loss: 1.7698798179626465
Batch 24/64 loss: 1.7683556079864502
Batch 25/64 loss: 1.7680662870407104
Batch 26/64 loss: 1.7771097421646118
Batch 27/64 loss: 1.7703547477722168
Batch 28/64 loss: 1.768390417098999
Batch 29/64 loss: 1.767021894454956
Batch 30/64 loss: 1.768795132637024
Batch 31/64 loss: 1.7666995525360107
Batch 32/64 loss: 1.762899398803711
Batch 33/64 loss: 1.7620141506195068
Batch 34/64 loss: 1.7776566743850708
Batch 35/64 loss: 1.7668665647506714
Batch 36/64 loss: 1.7650940418243408
Batch 37/64 loss: 1.7634694576263428
Batch 38/64 loss: 1.7749940156936646
Batch 39/64 loss: 1.7665528059005737
Batch 40/64 loss: 1.763228416442871
Batch 41/64 loss: 1.7674870491027832
Batch 42/64 loss: 1.7638715505599976
Batch 43/64 loss: 1.7655054330825806
Batch 44/64 loss: 1.7633322477340698
Batch 45/64 loss: 1.7661978006362915
Batch 46/64 loss: 1.7647593021392822
Batch 47/64 loss: 1.762147307395935
Batch 48/64 loss: 1.7643576860427856
Batch 49/64 loss: 1.7626969814300537
Batch 50/64 loss: 1.7601662874221802
Batch 51/64 loss: 1.7712379693984985
Batch 52/64 loss: 1.7636252641677856
Batch 53/64 loss: 1.767469882965088
Batch 54/64 loss: 1.7683250904083252
Batch 55/64 loss: 1.769706130027771
Batch 56/64 loss: 1.7653907537460327
Batch 57/64 loss: 1.767659068107605
Batch 58/64 loss: 1.7623918056488037
Batch 59/64 loss: 1.762736201286316
Batch 60/64 loss: 1.7754112482070923
Batch 61/64 loss: 1.7666436433792114
Batch 62/64 loss: 1.7646279335021973
Batch 63/64 loss: 1.768139123916626
Batch 64/64 loss: 1.9678863286972046
Epoch 81  Train loss: 1.769164226101894  Val loss: 1.7960343074143137
Epoch 82
-------------------------------
Batch 1/64 loss: 1.768621802330017
Batch 2/64 loss: 1.7715917825698853
Batch 3/64 loss: 1.7651829719543457
Batch 4/64 loss: 1.764559030532837
Batch 5/64 loss: 1.7640713453292847
Batch 6/64 loss: 1.765349268913269
Batch 7/64 loss: 1.7695865631103516
Batch 8/64 loss: 1.7672462463378906
Batch 9/64 loss: 1.7688237428665161
Batch 10/64 loss: 1.7708570957183838
Batch 11/64 loss: 1.7715332508087158
Batch 12/64 loss: 1.7691062688827515
Batch 13/64 loss: 1.774956226348877
Batch 14/64 loss: 1.763534665107727
Batch 15/64 loss: 1.7669579982757568
Batch 16/64 loss: 1.7694389820098877
Batch 17/64 loss: 1.7658097743988037
Batch 18/64 loss: 1.7652065753936768
Batch 19/64 loss: 1.7652807235717773
Batch 20/64 loss: 1.7678887844085693
Batch 21/64 loss: 1.7861008644104004
Batch 22/64 loss: 1.767390251159668
Batch 23/64 loss: 1.7835075855255127
Batch 24/64 loss: 1.7728698253631592
Batch 25/64 loss: 1.7651607990264893
Batch 26/64 loss: 1.7664247751235962
Batch 27/64 loss: 1.7678205966949463
Batch 28/64 loss: 1.7694532871246338
Batch 29/64 loss: 1.7745692729949951
Batch 30/64 loss: 1.7674332857131958
Batch 31/64 loss: 1.772638201713562
Batch 32/64 loss: 1.7648061513900757
Batch 33/64 loss: 1.7689169645309448
Batch 34/64 loss: 1.7657591104507446
Batch 35/64 loss: 1.7630549669265747
Batch 36/64 loss: 1.7627683877944946
Batch 37/64 loss: 1.7635149955749512
Batch 38/64 loss: 1.7686430215835571
Batch 39/64 loss: 1.7654955387115479
Batch 40/64 loss: 1.762637734413147
Batch 41/64 loss: 1.7677385807037354
Batch 42/64 loss: 1.7649469375610352
Batch 43/64 loss: 1.7665339708328247
Batch 44/64 loss: 1.7667620182037354
Batch 45/64 loss: 1.7666420936584473
Batch 46/64 loss: 1.7641682624816895
Batch 47/64 loss: 1.7666378021240234
Batch 48/64 loss: 1.7630956172943115
Batch 49/64 loss: 1.763995885848999
Batch 50/64 loss: 1.765587329864502
Batch 51/64 loss: 1.7620282173156738
Batch 52/64 loss: 1.767134189605713
Batch 53/64 loss: 1.7642005681991577
Batch 54/64 loss: 1.7602373361587524
Batch 55/64 loss: 1.767520785331726
Batch 56/64 loss: 1.7650011777877808
Batch 57/64 loss: 1.7663116455078125
Batch 58/64 loss: 1.7596107721328735
Batch 59/64 loss: 1.7647981643676758
Batch 60/64 loss: 1.7612193822860718
Batch 61/64 loss: 1.7628800868988037
Batch 62/64 loss: 1.7607338428497314
Batch 63/64 loss: 1.764349102973938
Batch 64/64 loss: 1.9642170667648315
Epoch 82  Train loss: 1.7692527887867946  Val loss: 1.7857016419217349
Saving best model, epoch: 82
Epoch 83
-------------------------------
Batch 1/64 loss: 1.7616536617279053
Batch 2/64 loss: 1.765447735786438
Batch 3/64 loss: 1.7621833086013794
Batch 4/64 loss: 1.7661218643188477
Batch 5/64 loss: 1.7622642517089844
Batch 6/64 loss: 1.7637242078781128
Batch 7/64 loss: 1.765580654144287
Batch 8/64 loss: 1.76262366771698
Batch 9/64 loss: 1.7663779258728027
Batch 10/64 loss: 1.7625349760055542
Batch 11/64 loss: 1.7681604623794556
Batch 12/64 loss: 1.7647767066955566
Batch 13/64 loss: 1.7636079788208008
Batch 14/64 loss: 1.7657151222229004
Batch 15/64 loss: 1.7657095193862915
Batch 16/64 loss: 1.7673730850219727
Batch 17/64 loss: 1.7723842859268188
Batch 18/64 loss: 1.765302300453186
Batch 19/64 loss: 1.7672369480133057
Batch 20/64 loss: 1.7639909982681274
Batch 21/64 loss: 1.7611855268478394
Batch 22/64 loss: 1.7629327774047852
Batch 23/64 loss: 1.7684597969055176
Batch 24/64 loss: 1.7678771018981934
Batch 25/64 loss: 1.7715808153152466
Batch 26/64 loss: 1.7680423259735107
Batch 27/64 loss: 1.7636151313781738
Batch 28/64 loss: 1.764381766319275
Batch 29/64 loss: 1.7673512697219849
Batch 30/64 loss: 1.766278624534607
Batch 31/64 loss: 1.7596992254257202
Batch 32/64 loss: 1.7654335498809814
Batch 33/64 loss: 1.7642543315887451
Batch 34/64 loss: 1.768763780593872
Batch 35/64 loss: 1.766066074371338
Batch 36/64 loss: 1.7610952854156494
Batch 37/64 loss: 1.7768967151641846
Batch 38/64 loss: 1.763358235359192
Batch 39/64 loss: 1.7612700462341309
Batch 40/64 loss: 1.7625586986541748
Batch 41/64 loss: 1.7784371376037598
Batch 42/64 loss: 1.759841799736023
Batch 43/64 loss: 1.763607382774353
Batch 44/64 loss: 1.7581472396850586
Batch 45/64 loss: 1.7622190713882446
Batch 46/64 loss: 1.7589083909988403
Batch 47/64 loss: 1.7654824256896973
Batch 48/64 loss: 1.7610623836517334
Batch 49/64 loss: 1.7628445625305176
Batch 50/64 loss: 1.7620272636413574
Batch 51/64 loss: 1.7638132572174072
Batch 52/64 loss: 1.764134168624878
Batch 53/64 loss: 1.7696722745895386
Batch 54/64 loss: 1.759785532951355
Batch 55/64 loss: 1.7661902904510498
Batch 56/64 loss: 1.7606202363967896
Batch 57/64 loss: 1.7590547800064087
Batch 58/64 loss: 1.7618871927261353
Batch 59/64 loss: 1.7641702890396118
Batch 60/64 loss: 1.7686538696289062
Batch 61/64 loss: 1.7672491073608398
Batch 62/64 loss: 1.7611165046691895
Batch 63/64 loss: 1.76542329788208
Batch 64/64 loss: 1.9864474534988403
Epoch 83  Train loss: 1.7673420359106624  Val loss: 1.788156743721454
Epoch 84
-------------------------------
Batch 1/64 loss: 1.7665141820907593
Batch 2/64 loss: 1.7636719942092896
Batch 3/64 loss: 1.7681734561920166
Batch 4/64 loss: 1.768165111541748
Batch 5/64 loss: 1.763515830039978
Batch 6/64 loss: 1.7665764093399048
Batch 7/64 loss: 1.7622311115264893
Batch 8/64 loss: 1.7661224603652954
Batch 9/64 loss: 1.7661676406860352
Batch 10/64 loss: 1.7600340843200684
Batch 11/64 loss: 1.7659331560134888
Batch 12/64 loss: 1.7635672092437744
Batch 13/64 loss: 1.7639060020446777
Batch 14/64 loss: 1.764249324798584
Batch 15/64 loss: 1.7629233598709106
Batch 16/64 loss: 1.760895848274231
Batch 17/64 loss: 1.7579295635223389
Batch 18/64 loss: 1.7678253650665283
Batch 19/64 loss: 1.7616157531738281
Batch 20/64 loss: 1.77839994430542
Batch 21/64 loss: 1.7629616260528564
Batch 22/64 loss: 1.764326572418213
Batch 23/64 loss: 1.766911268234253
Batch 24/64 loss: 1.7624940872192383
Batch 25/64 loss: 1.759803295135498
Batch 26/64 loss: 1.773934006690979
Batch 27/64 loss: 1.7590749263763428
Batch 28/64 loss: 1.7596608400344849
Batch 29/64 loss: 1.7633570432662964
Batch 30/64 loss: 1.7605255842208862
Batch 31/64 loss: 1.770645260810852
Batch 32/64 loss: 1.761258602142334
Batch 33/64 loss: 1.7616162300109863
Batch 34/64 loss: 1.7623991966247559
Batch 35/64 loss: 1.7593982219696045
Batch 36/64 loss: 1.7669107913970947
Batch 37/64 loss: 1.7643193006515503
Batch 38/64 loss: 1.760237455368042
Batch 39/64 loss: 1.7646024227142334
Batch 40/64 loss: 1.7614595890045166
Batch 41/64 loss: 1.7616692781448364
Batch 42/64 loss: 1.7617762088775635
Batch 43/64 loss: 1.7642030715942383
Batch 44/64 loss: 1.7711856365203857
Batch 45/64 loss: 1.760619878768921
Batch 46/64 loss: 1.7684577703475952
Batch 47/64 loss: 1.7585369348526
Batch 48/64 loss: 1.764390230178833
Batch 49/64 loss: 1.76128089427948
Batch 50/64 loss: 1.7640483379364014
Batch 51/64 loss: 1.768946647644043
Batch 52/64 loss: 1.7627604007720947
Batch 53/64 loss: 1.7687057256698608
Batch 54/64 loss: 1.761427879333496
Batch 55/64 loss: 1.7644798755645752
Batch 56/64 loss: 1.7635862827301025
Batch 57/64 loss: 1.76197350025177
Batch 58/64 loss: 1.760949730873108
Batch 59/64 loss: 1.7627933025360107
Batch 60/64 loss: 1.7812070846557617
Batch 61/64 loss: 1.773901343345642
Batch 62/64 loss: 1.7665455341339111
Batch 63/64 loss: 1.7611644268035889
Batch 64/64 loss: 1.9646596908569336
Epoch 84  Train loss: 1.7667830411125631  Val loss: 1.7893024400337456
Epoch 85
-------------------------------
Batch 1/64 loss: 1.757843017578125
Batch 2/64 loss: 1.7583627700805664
Batch 3/64 loss: 1.7592816352844238
Batch 4/64 loss: 1.7724440097808838
Batch 5/64 loss: 1.76686429977417
Batch 6/64 loss: 1.7636679410934448
Batch 7/64 loss: 1.7607773542404175
Batch 8/64 loss: 1.766837477684021
Batch 9/64 loss: 1.764573097229004
Batch 10/64 loss: 1.767883539199829
Batch 11/64 loss: 1.765547513961792
Batch 12/64 loss: 1.7653826475143433
Batch 13/64 loss: 1.7652592658996582
Batch 14/64 loss: 1.758948802947998
Batch 15/64 loss: 1.7698888778686523
Batch 16/64 loss: 1.765151023864746
Batch 17/64 loss: 1.763027310371399
Batch 18/64 loss: 1.7647663354873657
Batch 19/64 loss: 1.7622877359390259
Batch 20/64 loss: 1.7653212547302246
Batch 21/64 loss: 1.7601083517074585
Batch 22/64 loss: 1.7617405652999878
Batch 23/64 loss: 1.7635154724121094
Batch 24/64 loss: 1.7604143619537354
Batch 25/64 loss: 1.7605844736099243
Batch 26/64 loss: 1.762220025062561
Batch 27/64 loss: 1.763342261314392
Batch 28/64 loss: 1.7595016956329346
Batch 29/64 loss: 1.763449788093567
Batch 30/64 loss: 1.756786584854126
Batch 31/64 loss: 1.7592514753341675
Batch 32/64 loss: 1.7825390100479126
Batch 33/64 loss: 1.7646898031234741
Batch 34/64 loss: 1.758441686630249
Batch 35/64 loss: 1.7597185373306274
Batch 36/64 loss: 1.7608394622802734
Batch 37/64 loss: 1.7595510482788086
Batch 38/64 loss: 1.7642624378204346
Batch 39/64 loss: 1.7586342096328735
Batch 40/64 loss: 1.7651716470718384
Batch 41/64 loss: 1.7653888463974
Batch 42/64 loss: 1.7593662738800049
Batch 43/64 loss: 1.764769196510315
Batch 44/64 loss: 1.7623056173324585
Batch 45/64 loss: 1.7596158981323242
Batch 46/64 loss: 1.7611479759216309
Batch 47/64 loss: 1.7625877857208252
Batch 48/64 loss: 1.7599753141403198
Batch 49/64 loss: 1.7608267068862915
Batch 50/64 loss: 1.7631540298461914
Batch 51/64 loss: 1.7592114210128784
Batch 52/64 loss: 1.7606606483459473
Batch 53/64 loss: 1.7614922523498535
Batch 54/64 loss: 1.7696750164031982
Batch 55/64 loss: 1.7604602575302124
Batch 56/64 loss: 1.760104775428772
Batch 57/64 loss: 1.7570898532867432
Batch 58/64 loss: 1.7670872211456299
Batch 59/64 loss: 1.7651113271713257
Batch 60/64 loss: 1.7588787078857422
Batch 61/64 loss: 1.7662558555603027
Batch 62/64 loss: 1.7574994564056396
Batch 63/64 loss: 1.7603684663772583
Batch 64/64 loss: 1.9659233093261719
Epoch 85  Train loss: 1.7651192814696068  Val loss: 1.7835270203265947
Saving best model, epoch: 85
Epoch 86
-------------------------------
Batch 1/64 loss: 1.77390456199646
Batch 2/64 loss: 1.7590107917785645
Batch 3/64 loss: 1.7698636054992676
Batch 4/64 loss: 1.7615653276443481
Batch 5/64 loss: 1.7653509378433228
Batch 6/64 loss: 1.768507957458496
Batch 7/64 loss: 1.7666138410568237
Batch 8/64 loss: 1.7661004066467285
Batch 9/64 loss: 1.7647725343704224
Batch 10/64 loss: 1.7649345397949219
Batch 11/64 loss: 1.765089511871338
Batch 12/64 loss: 1.769545555114746
Batch 13/64 loss: 1.7665634155273438
Batch 14/64 loss: 1.7666194438934326
Batch 15/64 loss: 1.7650622129440308
Batch 16/64 loss: 1.7719297409057617
Batch 17/64 loss: 1.766324520111084
Batch 18/64 loss: 1.7620503902435303
Batch 19/64 loss: 1.7653436660766602
Batch 20/64 loss: 1.7594586610794067
Batch 21/64 loss: 1.7623367309570312
Batch 22/64 loss: 1.7585378885269165
Batch 23/64 loss: 1.7628271579742432
Batch 24/64 loss: 1.7591370344161987
Batch 25/64 loss: 1.765800952911377
Batch 26/64 loss: 1.7726207971572876
Batch 27/64 loss: 1.7753136157989502
Batch 28/64 loss: 1.7695101499557495
Batch 29/64 loss: 1.7656517028808594
Batch 30/64 loss: 1.7655103206634521
Batch 31/64 loss: 1.7716630697250366
Batch 32/64 loss: 1.7659986019134521
Batch 33/64 loss: 1.764227032661438
Batch 34/64 loss: 1.7659595012664795
Batch 35/64 loss: 1.766322135925293
Batch 36/64 loss: 1.764998435974121
Batch 37/64 loss: 1.7644741535186768
Batch 38/64 loss: 1.7694289684295654
Batch 39/64 loss: 1.7708995342254639
Batch 40/64 loss: 1.7681469917297363
Batch 41/64 loss: 1.7737488746643066
Batch 42/64 loss: 1.7653894424438477
Batch 43/64 loss: 1.762929081916809
Batch 44/64 loss: 1.7708475589752197
Batch 45/64 loss: 1.763214349746704
Batch 46/64 loss: 1.764257550239563
Batch 47/64 loss: 1.7787752151489258
Batch 48/64 loss: 1.7616057395935059
Batch 49/64 loss: 1.763391375541687
Batch 50/64 loss: 1.7667936086654663
Batch 51/64 loss: 1.762063980102539
Batch 52/64 loss: 1.7710480690002441
Batch 53/64 loss: 1.7627911567687988
Batch 54/64 loss: 1.7633157968521118
Batch 55/64 loss: 1.761598825454712
Batch 56/64 loss: 1.7668124437332153
Batch 57/64 loss: 1.7635762691497803
Batch 58/64 loss: 1.7635431289672852
Batch 59/64 loss: 1.7706109285354614
Batch 60/64 loss: 1.7640800476074219
Batch 61/64 loss: 1.7664400339126587
Batch 62/64 loss: 1.7595858573913574
Batch 63/64 loss: 1.7599849700927734
Batch 64/64 loss: 1.9645347595214844
Epoch 86  Train loss: 1.7682789297664867  Val loss: 1.7870020768077104
Epoch 87
-------------------------------
Batch 1/64 loss: 1.7659934759140015
Batch 2/64 loss: 1.765105128288269
Batch 3/64 loss: 1.7691593170166016
Batch 4/64 loss: 1.7623732089996338
Batch 5/64 loss: 1.760668396949768
Batch 6/64 loss: 1.7621488571166992
Batch 7/64 loss: 1.7584648132324219
Batch 8/64 loss: 1.759222149848938
Batch 9/64 loss: 1.762298583984375
Batch 10/64 loss: 1.7893861532211304
Batch 11/64 loss: 1.7598875761032104
Batch 12/64 loss: 1.7628428936004639
Batch 13/64 loss: 1.766530990600586
Batch 14/64 loss: 1.7600313425064087
Batch 15/64 loss: 1.7625877857208252
Batch 16/64 loss: 1.7608819007873535
Batch 17/64 loss: 1.7583590745925903
Batch 18/64 loss: 1.7640596628189087
Batch 19/64 loss: 1.7634639739990234
Batch 20/64 loss: 1.7616338729858398
Batch 21/64 loss: 1.7638370990753174
Batch 22/64 loss: 1.7618739604949951
Batch 23/64 loss: 1.7602323293685913
Batch 24/64 loss: 1.7608084678649902
Batch 25/64 loss: 1.759615182876587
Batch 26/64 loss: 1.7596814632415771
Batch 27/64 loss: 1.7595161199569702
Batch 28/64 loss: 1.760683536529541
Batch 29/64 loss: 1.7650885581970215
Batch 30/64 loss: 1.757460594177246
Batch 31/64 loss: 1.7575507164001465
Batch 32/64 loss: 1.7613991498947144
Batch 33/64 loss: 1.7576063871383667
Batch 34/64 loss: 1.7582257986068726
Batch 35/64 loss: 1.7635107040405273
Batch 36/64 loss: 1.7626402378082275
Batch 37/64 loss: 1.7676069736480713
Batch 38/64 loss: 1.7598240375518799
Batch 39/64 loss: 1.759454607963562
Batch 40/64 loss: 1.7598469257354736
Batch 41/64 loss: 1.7608758211135864
Batch 42/64 loss: 1.770234227180481
Batch 43/64 loss: 1.7612435817718506
Batch 44/64 loss: 1.7579090595245361
Batch 45/64 loss: 1.7655832767486572
Batch 46/64 loss: 1.7610818147659302
Batch 47/64 loss: 1.7590324878692627
Batch 48/64 loss: 1.7786238193511963
Batch 49/64 loss: 1.7589693069458008
Batch 50/64 loss: 1.7621324062347412
Batch 51/64 loss: 1.759082317352295
Batch 52/64 loss: 1.7641351222991943
Batch 53/64 loss: 1.7638332843780518
Batch 54/64 loss: 1.7606704235076904
Batch 55/64 loss: 1.7730721235275269
Batch 56/64 loss: 1.7693796157836914
Batch 57/64 loss: 1.7641966342926025
Batch 58/64 loss: 1.7638763189315796
Batch 59/64 loss: 1.7669744491577148
Batch 60/64 loss: 1.7615731954574585
Batch 61/64 loss: 1.7637975215911865
Batch 62/64 loss: 1.7615522146224976
Batch 63/64 loss: 1.7657623291015625
Batch 64/64 loss: 1.968405842781067
Epoch 87  Train loss: 1.7653561998816099  Val loss: 1.786314249858004
Epoch 88
-------------------------------
Batch 1/64 loss: 1.760324239730835
Batch 2/64 loss: 1.7613353729248047
Batch 3/64 loss: 1.7673965692520142
Batch 4/64 loss: 1.7614856958389282
Batch 5/64 loss: 1.7655261754989624
Batch 6/64 loss: 1.7749388217926025
Batch 7/64 loss: 1.7605382204055786
Batch 8/64 loss: 1.7659943103790283
Batch 9/64 loss: 1.7686270475387573
Batch 10/64 loss: 1.7756803035736084
Batch 11/64 loss: 1.768743872642517
Batch 12/64 loss: 1.770261526107788
Batch 13/64 loss: 1.7634031772613525
Batch 14/64 loss: 1.7630233764648438
Batch 15/64 loss: 1.7672123908996582
Batch 16/64 loss: 1.761226773262024
Batch 17/64 loss: 1.7605412006378174
Batch 18/64 loss: 1.7626373767852783
Batch 19/64 loss: 1.770211935043335
Batch 20/64 loss: 1.7656612396240234
Batch 21/64 loss: 1.762569546699524
Batch 22/64 loss: 1.7563347816467285
Batch 23/64 loss: 1.7642593383789062
Batch 24/64 loss: 1.7699536085128784
Batch 25/64 loss: 1.767752766609192
Batch 26/64 loss: 1.7597275972366333
Batch 27/64 loss: 1.7622088193893433
Batch 28/64 loss: 1.7628381252288818
Batch 29/64 loss: 1.7621301412582397
Batch 30/64 loss: 1.7605390548706055
Batch 31/64 loss: 1.7754428386688232
Batch 32/64 loss: 1.7633717060089111
Batch 33/64 loss: 1.7611026763916016
Batch 34/64 loss: 1.7621867656707764
Batch 35/64 loss: 1.7618746757507324
Batch 36/64 loss: 1.7599469423294067
Batch 37/64 loss: 1.7596378326416016
Batch 38/64 loss: 1.762129783630371
Batch 39/64 loss: 1.7600594758987427
Batch 40/64 loss: 1.771493911743164
Batch 41/64 loss: 1.7589510679244995
Batch 42/64 loss: 1.7595176696777344
Batch 43/64 loss: 1.7596888542175293
Batch 44/64 loss: 1.7589805126190186
Batch 45/64 loss: 1.7627520561218262
Batch 46/64 loss: 1.7676055431365967
Batch 47/64 loss: 1.7651574611663818
Batch 48/64 loss: 1.7600007057189941
Batch 49/64 loss: 1.7616407871246338
Batch 50/64 loss: 1.7615336179733276
Batch 51/64 loss: 1.7585344314575195
Batch 52/64 loss: 1.7636098861694336
Batch 53/64 loss: 1.7608184814453125
Batch 54/64 loss: 1.760282278060913
Batch 55/64 loss: 1.7600458860397339
Batch 56/64 loss: 1.7579766511917114
Batch 57/64 loss: 1.7612285614013672
Batch 58/64 loss: 1.7612724304199219
Batch 59/64 loss: 1.7616227865219116
Batch 60/64 loss: 1.7584497928619385
Batch 61/64 loss: 1.7620943784713745
Batch 62/64 loss: 1.7597750425338745
Batch 63/64 loss: 1.7605077028274536
Batch 64/64 loss: 1.96518874168396
Epoch 88  Train loss: 1.7655885200874477  Val loss: 1.7817707823723863
Saving best model, epoch: 88
Epoch 89
-------------------------------
Batch 1/64 loss: 1.7583799362182617
Batch 2/64 loss: 1.7595700025558472
Batch 3/64 loss: 1.7589349746704102
Batch 4/64 loss: 1.7613811492919922
Batch 5/64 loss: 1.7574268579483032
Batch 6/64 loss: 1.7570232152938843
Batch 7/64 loss: 1.7594099044799805
Batch 8/64 loss: 1.7566218376159668
Batch 9/64 loss: 1.7615971565246582
Batch 10/64 loss: 1.756532907485962
Batch 11/64 loss: 1.7569702863693237
Batch 12/64 loss: 1.7646774053573608
Batch 13/64 loss: 1.7650690078735352
Batch 14/64 loss: 1.7647767066955566
Batch 15/64 loss: 1.7588510513305664
Batch 16/64 loss: 1.7590452432632446
Batch 17/64 loss: 1.7608938217163086
Batch 18/64 loss: 1.763556718826294
Batch 19/64 loss: 1.7583589553833008
Batch 20/64 loss: 1.7611942291259766
Batch 21/64 loss: 1.7631125450134277
Batch 22/64 loss: 1.7611991167068481
Batch 23/64 loss: 1.759492039680481
Batch 24/64 loss: 1.756922960281372
Batch 25/64 loss: 1.7579309940338135
Batch 26/64 loss: 1.75764799118042
Batch 27/64 loss: 1.7639997005462646
Batch 28/64 loss: 1.7589592933654785
Batch 29/64 loss: 1.7600138187408447
Batch 30/64 loss: 1.7586724758148193
Batch 31/64 loss: 1.7555216550827026
Batch 32/64 loss: 1.7553156614303589
Batch 33/64 loss: 1.761143684387207
Batch 34/64 loss: 1.777129888534546
Batch 35/64 loss: 1.7640050649642944
Batch 36/64 loss: 1.7592346668243408
Batch 37/64 loss: 1.7585543394088745
Batch 38/64 loss: 1.7565447092056274
Batch 39/64 loss: 1.7605102062225342
Batch 40/64 loss: 1.7566289901733398
Batch 41/64 loss: 1.7554805278778076
Batch 42/64 loss: 1.7548537254333496
Batch 43/64 loss: 1.7612311840057373
Batch 44/64 loss: 1.7587909698486328
Batch 45/64 loss: 1.757002592086792
Batch 46/64 loss: 1.7560230493545532
Batch 47/64 loss: 1.7683978080749512
Batch 48/64 loss: 1.7586193084716797
Batch 49/64 loss: 1.7559771537780762
Batch 50/64 loss: 1.7604817152023315
Batch 51/64 loss: 1.7668267488479614
Batch 52/64 loss: 1.7624218463897705
Batch 53/64 loss: 1.75847327709198
Batch 54/64 loss: 1.755767583847046
Batch 55/64 loss: 1.7580702304840088
Batch 56/64 loss: 1.7577168941497803
Batch 57/64 loss: 1.7583791017532349
Batch 58/64 loss: 1.7606525421142578
Batch 59/64 loss: 1.7588598728179932
Batch 60/64 loss: 1.7564806938171387
Batch 61/64 loss: 1.7637684345245361
Batch 62/64 loss: 1.7576838731765747
Batch 63/64 loss: 1.761496663093567
Batch 64/64 loss: 1.9566154479980469
Epoch 89  Train loss: 1.762097702774347  Val loss: 1.7804740982776655
Saving best model, epoch: 89
Epoch 90
-------------------------------
Batch 1/64 loss: 1.7587871551513672
Batch 2/64 loss: 1.76618492603302
Batch 3/64 loss: 1.7577717304229736
Batch 4/64 loss: 1.7569961547851562
Batch 5/64 loss: 1.75734543800354
Batch 6/64 loss: 1.763444423675537
Batch 7/64 loss: 1.7572336196899414
Batch 8/64 loss: 1.7563972473144531
Batch 9/64 loss: 1.7555919885635376
Batch 10/64 loss: 1.755827784538269
Batch 11/64 loss: 1.7572150230407715
Batch 12/64 loss: 1.757612943649292
Batch 13/64 loss: 1.7635626792907715
Batch 14/64 loss: 1.7585605382919312
Batch 15/64 loss: 1.7571744918823242
Batch 16/64 loss: 1.759709119796753
Batch 17/64 loss: 1.7574348449707031
Batch 18/64 loss: 1.763145089149475
Batch 19/64 loss: 1.7631115913391113
Batch 20/64 loss: 1.7761993408203125
Batch 21/64 loss: 1.762420415878296
Batch 22/64 loss: 1.7608729600906372
Batch 23/64 loss: 1.7594579458236694
Batch 24/64 loss: 1.7578166723251343
Batch 25/64 loss: 1.7631292343139648
Batch 26/64 loss: 1.758857011795044
Batch 27/64 loss: 1.7571470737457275
Batch 28/64 loss: 1.7575478553771973
Batch 29/64 loss: 1.7607698440551758
Batch 30/64 loss: 1.7588282823562622
Batch 31/64 loss: 1.7633030414581299
Batch 32/64 loss: 1.7648847103118896
Batch 33/64 loss: 1.7606260776519775
Batch 34/64 loss: 1.759406566619873
Batch 35/64 loss: 1.7597055435180664
Batch 36/64 loss: 1.766121745109558
Batch 37/64 loss: 1.7604953050613403
Batch 38/64 loss: 1.7565041780471802
Batch 39/64 loss: 1.7569968700408936
Batch 40/64 loss: 1.7559490203857422
Batch 41/64 loss: 1.760868787765503
Batch 42/64 loss: 1.7563612461090088
Batch 43/64 loss: 1.7603025436401367
Batch 44/64 loss: 1.7592251300811768
Batch 45/64 loss: 1.7631272077560425
Batch 46/64 loss: 1.7612254619598389
Batch 47/64 loss: 1.7627602815628052
Batch 48/64 loss: 1.7615768909454346
Batch 49/64 loss: 1.7617334127426147
Batch 50/64 loss: 1.7588627338409424
Batch 51/64 loss: 1.7787140607833862
Batch 52/64 loss: 1.7614202499389648
Batch 53/64 loss: 1.7748063802719116
Batch 54/64 loss: 1.7609260082244873
Batch 55/64 loss: 1.7590434551239014
Batch 56/64 loss: 1.7636207342147827
Batch 57/64 loss: 1.7612831592559814
Batch 58/64 loss: 1.7569116353988647
Batch 59/64 loss: 1.7605761289596558
Batch 60/64 loss: 1.7610762119293213
Batch 61/64 loss: 1.7597861289978027
Batch 62/64 loss: 1.7650158405303955
Batch 63/64 loss: 1.7576974630355835
Batch 64/64 loss: 1.970808506011963
Epoch 90  Train loss: 1.7632184159521964  Val loss: 1.7834798183637797
Epoch 91
-------------------------------
Batch 1/64 loss: 1.7602033615112305
Batch 2/64 loss: 1.7602182626724243
Batch 3/64 loss: 1.7599042654037476
Batch 4/64 loss: 1.7596964836120605
Batch 5/64 loss: 1.7577550411224365
Batch 6/64 loss: 1.7644298076629639
Batch 7/64 loss: 1.7614600658416748
Batch 8/64 loss: 1.7589294910430908
Batch 9/64 loss: 1.7650489807128906
Batch 10/64 loss: 1.7607262134552002
Batch 11/64 loss: 1.7592692375183105
Batch 12/64 loss: 1.7582290172576904
Batch 13/64 loss: 1.766756296157837
Batch 14/64 loss: 1.7607073783874512
Batch 15/64 loss: 1.760934829711914
Batch 16/64 loss: 1.7792719602584839
Batch 17/64 loss: 1.7613600492477417
Batch 18/64 loss: 1.779825210571289
Batch 19/64 loss: 1.7669107913970947
Batch 20/64 loss: 1.7701350450515747
Batch 21/64 loss: 1.765002965927124
Batch 22/64 loss: 1.76316237449646
Batch 23/64 loss: 1.762440800666809
Batch 24/64 loss: 1.7649190425872803
Batch 25/64 loss: 1.7657068967819214
Batch 26/64 loss: 1.7630993127822876
Batch 27/64 loss: 1.758819341659546
Batch 28/64 loss: 1.7694966793060303
Batch 29/64 loss: 1.7599759101867676
Batch 30/64 loss: 1.7623672485351562
Batch 31/64 loss: 1.7655740976333618
Batch 32/64 loss: 1.7634211778640747
Batch 33/64 loss: 1.7631516456604004
Batch 34/64 loss: 1.7601162195205688
Batch 35/64 loss: 1.7630670070648193
Batch 36/64 loss: 1.75800359249115
Batch 37/64 loss: 1.7596487998962402
Batch 38/64 loss: 1.76091468334198
Batch 39/64 loss: 1.758423924446106
Batch 40/64 loss: 1.7600425481796265
Batch 41/64 loss: 1.7705130577087402
Batch 42/64 loss: 1.757959246635437
Batch 43/64 loss: 1.7683333158493042
Batch 44/64 loss: 1.7613980770111084
Batch 45/64 loss: 1.758217215538025
Batch 46/64 loss: 1.7586476802825928
Batch 47/64 loss: 1.772047519683838
Batch 48/64 loss: 1.7624624967575073
Batch 49/64 loss: 1.762547492980957
Batch 50/64 loss: 1.775775671005249
Batch 51/64 loss: 1.76517653465271
Batch 52/64 loss: 1.7576755285263062
Batch 53/64 loss: 1.759372353553772
Batch 54/64 loss: 1.762389898300171
Batch 55/64 loss: 1.7611589431762695
Batch 56/64 loss: 1.7633970975875854
Batch 57/64 loss: 1.7640376091003418
Batch 58/64 loss: 1.7679359912872314
Batch 59/64 loss: 1.7613965272903442
Batch 60/64 loss: 1.7673285007476807
Batch 61/64 loss: 1.7634766101837158
Batch 62/64 loss: 1.7648515701293945
Batch 63/64 loss: 1.7651609182357788
Batch 64/64 loss: 1.960195541381836
Epoch 91  Train loss: 1.7656554128609452  Val loss: 1.7836711103563865
Epoch 92
-------------------------------
Batch 1/64 loss: 1.7651340961456299
Batch 2/64 loss: 1.7630820274353027
Batch 3/64 loss: 1.7622848749160767
Batch 4/64 loss: 1.7682191133499146
Batch 5/64 loss: 1.7640501260757446
Batch 6/64 loss: 1.766303300857544
Batch 7/64 loss: 1.765900731086731
Batch 8/64 loss: 1.7668774127960205
Batch 9/64 loss: 1.7669578790664673
Batch 10/64 loss: 1.765702724456787
Batch 11/64 loss: 1.760278582572937
Batch 12/64 loss: 1.760560154914856
Batch 13/64 loss: 1.761033535003662
Batch 14/64 loss: 1.7611397504806519
Batch 15/64 loss: 1.7610737085342407
Batch 16/64 loss: 1.7633998394012451
Batch 17/64 loss: 1.758338212966919
Batch 18/64 loss: 1.7600626945495605
Batch 19/64 loss: 1.7564051151275635
Batch 20/64 loss: 1.7634913921356201
Batch 21/64 loss: 1.7560648918151855
Batch 22/64 loss: 1.7631241083145142
Batch 23/64 loss: 1.7615045309066772
Batch 24/64 loss: 1.7603085041046143
Batch 25/64 loss: 1.7595371007919312
Batch 26/64 loss: 1.7695863246917725
Batch 27/64 loss: 1.7620540857315063
Batch 28/64 loss: 1.7590210437774658
Batch 29/64 loss: 1.7563577890396118
Batch 30/64 loss: 1.7617871761322021
Batch 31/64 loss: 1.7609362602233887
Batch 32/64 loss: 1.7566113471984863
Batch 33/64 loss: 1.7608740329742432
Batch 34/64 loss: 1.7560725212097168
Batch 35/64 loss: 1.7606265544891357
Batch 36/64 loss: 1.7633357048034668
Batch 37/64 loss: 1.7698224782943726
Batch 38/64 loss: 1.758984088897705
Batch 39/64 loss: 1.7692937850952148
Batch 40/64 loss: 1.7641748189926147
Batch 41/64 loss: 1.759535551071167
Batch 42/64 loss: 1.7619929313659668
Batch 43/64 loss: 1.760271430015564
Batch 44/64 loss: 1.776394009590149
Batch 45/64 loss: 1.7578994035720825
Batch 46/64 loss: 1.7611546516418457
Batch 47/64 loss: 1.761091947555542
Batch 48/64 loss: 1.7585177421569824
Batch 49/64 loss: 1.7574498653411865
Batch 50/64 loss: 1.7563897371292114
Batch 51/64 loss: 1.7754462957382202
Batch 52/64 loss: 1.7591501474380493
Batch 53/64 loss: 1.761568307876587
Batch 54/64 loss: 1.7549585103988647
Batch 55/64 loss: 1.7610046863555908
Batch 56/64 loss: 1.7564269304275513
Batch 57/64 loss: 1.7580807209014893
Batch 58/64 loss: 1.757020115852356
Batch 59/64 loss: 1.758210301399231
Batch 60/64 loss: 1.7628748416900635
Batch 61/64 loss: 1.7566096782684326
Batch 62/64 loss: 1.7585967779159546
Batch 63/64 loss: 1.7584178447723389
Batch 64/64 loss: 1.9603209495544434
Epoch 92  Train loss: 1.7639164793725106  Val loss: 1.7868622144063313
Epoch 93
-------------------------------
Batch 1/64 loss: 1.757542371749878
Batch 2/64 loss: 1.7577199935913086
Batch 3/64 loss: 1.7606782913208008
Batch 4/64 loss: 1.7609825134277344
Batch 5/64 loss: 1.7595558166503906
Batch 6/64 loss: 1.7618467807769775
Batch 7/64 loss: 1.7572524547576904
Batch 8/64 loss: 1.757809042930603
Batch 9/64 loss: 1.7796435356140137
Batch 10/64 loss: 1.7613229751586914
Batch 11/64 loss: 1.7660108804702759
Batch 12/64 loss: 1.7618201971054077
Batch 13/64 loss: 1.7620251178741455
Batch 14/64 loss: 1.7631580829620361
Batch 15/64 loss: 1.757190227508545
Batch 16/64 loss: 1.7570356130599976
Batch 17/64 loss: 1.7599246501922607
Batch 18/64 loss: 1.758012056350708
Batch 19/64 loss: 1.7628403902053833
Batch 20/64 loss: 1.761027455329895
Batch 21/64 loss: 1.7583067417144775
Batch 22/64 loss: 1.7620823383331299
Batch 23/64 loss: 1.7580227851867676
Batch 24/64 loss: 1.7625946998596191
Batch 25/64 loss: 1.7628388404846191
Batch 26/64 loss: 1.76133131980896
Batch 27/64 loss: 1.7597267627716064
Batch 28/64 loss: 1.7690632343292236
Batch 29/64 loss: 1.756334900856018
Batch 30/64 loss: 1.7600212097167969
Batch 31/64 loss: 1.7595744132995605
Batch 32/64 loss: 1.754408836364746
Batch 33/64 loss: 1.7577240467071533
Batch 34/64 loss: 1.760334849357605
Batch 35/64 loss: 1.7591111660003662
Batch 36/64 loss: 1.7554582357406616
Batch 37/64 loss: 1.758458137512207
Batch 38/64 loss: 1.7579128742218018
Batch 39/64 loss: 1.7619200944900513
Batch 40/64 loss: 1.7638628482818604
Batch 41/64 loss: 1.7599232196807861
Batch 42/64 loss: 1.7583626508712769
Batch 43/64 loss: 1.7575531005859375
Batch 44/64 loss: 1.7557916641235352
Batch 45/64 loss: 1.757555365562439
Batch 46/64 loss: 1.754319429397583
Batch 47/64 loss: 1.7610480785369873
Batch 48/64 loss: 1.7547309398651123
Batch 49/64 loss: 1.7556660175323486
Batch 50/64 loss: 1.7546885013580322
Batch 51/64 loss: 1.7599416971206665
Batch 52/64 loss: 1.7567484378814697
Batch 53/64 loss: 1.755326747894287
Batch 54/64 loss: 1.7750160694122314
Batch 55/64 loss: 1.7593028545379639
Batch 56/64 loss: 1.7704967260360718
Batch 57/64 loss: 1.7604947090148926
Batch 58/64 loss: 1.7612032890319824
Batch 59/64 loss: 1.7614271640777588
Batch 60/64 loss: 1.7580429315567017
Batch 61/64 loss: 1.764377236366272
Batch 62/64 loss: 1.7582733631134033
Batch 63/64 loss: 1.7592051029205322
Batch 64/64 loss: 1.9645578861236572
Epoch 93  Train loss: 1.7625945175395292  Val loss: 1.7799792863249368
Saving best model, epoch: 93
Epoch 94
-------------------------------
Batch 1/64 loss: 1.7572484016418457
Batch 2/64 loss: 1.7586989402770996
Batch 3/64 loss: 1.7584912776947021
Batch 4/64 loss: 1.759064793586731
Batch 5/64 loss: 1.759250283241272
Batch 6/64 loss: 1.7591572999954224
Batch 7/64 loss: 1.7624163627624512
Batch 8/64 loss: 1.7734366655349731
Batch 9/64 loss: 1.7607535123825073
Batch 10/64 loss: 1.7605094909667969
Batch 11/64 loss: 1.757106900215149
Batch 12/64 loss: 1.7569094896316528
Batch 13/64 loss: 1.758561372756958
Batch 14/64 loss: 1.7580735683441162
Batch 15/64 loss: 1.7622075080871582
Batch 16/64 loss: 1.7587056159973145
Batch 17/64 loss: 1.7570966482162476
Batch 18/64 loss: 1.7568432092666626
Batch 19/64 loss: 1.760327696800232
Batch 20/64 loss: 1.7854671478271484
Batch 21/64 loss: 1.7620632648468018
Batch 22/64 loss: 1.7605262994766235
Batch 23/64 loss: 1.7600209712982178
Batch 24/64 loss: 1.7569524049758911
Batch 25/64 loss: 1.762776255607605
Batch 26/64 loss: 1.7665878534317017
Batch 27/64 loss: 1.766646385192871
Batch 28/64 loss: 1.768654704093933
Batch 29/64 loss: 1.7580230236053467
Batch 30/64 loss: 1.7653075456619263
Batch 31/64 loss: 1.763820767402649
Batch 32/64 loss: 1.7584490776062012
Batch 33/64 loss: 1.7659087181091309
Batch 34/64 loss: 1.7631242275238037
Batch 35/64 loss: 1.7632251977920532
Batch 36/64 loss: 1.7593955993652344
Batch 37/64 loss: 1.7595576047897339
Batch 38/64 loss: 1.7605698108673096
Batch 39/64 loss: 1.7617557048797607
Batch 40/64 loss: 1.7604918479919434
Batch 41/64 loss: 1.7645163536071777
Batch 42/64 loss: 1.758005976676941
Batch 43/64 loss: 1.7642476558685303
Batch 44/64 loss: 1.775404453277588
Batch 45/64 loss: 1.7669851779937744
Batch 46/64 loss: 1.7599812746047974
Batch 47/64 loss: 1.7638602256774902
Batch 48/64 loss: 1.7621312141418457
Batch 49/64 loss: 1.7602497339248657
Batch 50/64 loss: 1.7678645849227905
Batch 51/64 loss: 1.7647455930709839
Batch 52/64 loss: 1.7607922554016113
Batch 53/64 loss: 1.7616479396820068
Batch 54/64 loss: 1.7662804126739502
Batch 55/64 loss: 1.7655353546142578
Batch 56/64 loss: 1.7662878036499023
Batch 57/64 loss: 1.7668405771255493
Batch 58/64 loss: 1.762274980545044
Batch 59/64 loss: 1.7623746395111084
Batch 60/64 loss: 1.7652000188827515
Batch 61/64 loss: 1.7624366283416748
Batch 62/64 loss: 1.7681232690811157
Batch 63/64 loss: 1.7630674839019775
Batch 64/64 loss: 1.968048095703125
Epoch 94  Train loss: 1.7650050686854941  Val loss: 1.7959834218434862
Epoch 95
-------------------------------
Batch 1/64 loss: 1.7726061344146729
Batch 2/64 loss: 1.7645701169967651
Batch 3/64 loss: 1.7672532796859741
Batch 4/64 loss: 1.7689926624298096
Batch 5/64 loss: 1.7644020318984985
Batch 6/64 loss: 1.7622504234313965
Batch 7/64 loss: 1.762544870376587
Batch 8/64 loss: 1.7641360759735107
Batch 9/64 loss: 1.7660503387451172
Batch 10/64 loss: 1.7667139768600464
Batch 11/64 loss: 1.7654160261154175
Batch 12/64 loss: 1.7663296461105347
Batch 13/64 loss: 1.7618598937988281
Batch 14/64 loss: 1.7613471746444702
Batch 15/64 loss: 1.7604689598083496
Batch 16/64 loss: 1.7581347227096558
Batch 17/64 loss: 1.762059211730957
Batch 18/64 loss: 1.7602386474609375
Batch 19/64 loss: 1.7586407661437988
Batch 20/64 loss: 1.7609046697616577
Batch 21/64 loss: 1.7662856578826904
Batch 22/64 loss: 1.7589836120605469
Batch 23/64 loss: 1.7619677782058716
Batch 24/64 loss: 1.7650690078735352
Batch 25/64 loss: 1.7557835578918457
Batch 26/64 loss: 1.7591677904129028
Batch 27/64 loss: 1.7566925287246704
Batch 28/64 loss: 1.758388876914978
Batch 29/64 loss: 1.7640438079833984
Batch 30/64 loss: 1.7606854438781738
Batch 31/64 loss: 1.7619599103927612
Batch 32/64 loss: 1.7601888179779053
Batch 33/64 loss: 1.7597451210021973
Batch 34/64 loss: 1.758151650428772
Batch 35/64 loss: 1.7593958377838135
Batch 36/64 loss: 1.7565189599990845
Batch 37/64 loss: 1.7760140895843506
Batch 38/64 loss: 1.7658889293670654
Batch 39/64 loss: 1.7680714130401611
Batch 40/64 loss: 1.7603533267974854
Batch 41/64 loss: 1.7700117826461792
Batch 42/64 loss: 1.7692232131958008
Batch 43/64 loss: 1.7681338787078857
Batch 44/64 loss: 1.7647348642349243
Batch 45/64 loss: 1.7640961408615112
Batch 46/64 loss: 1.7744513750076294
Batch 47/64 loss: 1.7638115882873535
Batch 48/64 loss: 1.7636185884475708
Batch 49/64 loss: 1.7699341773986816
Batch 50/64 loss: 1.760270595550537
Batch 51/64 loss: 1.7611794471740723
Batch 52/64 loss: 1.7604410648345947
Batch 53/64 loss: 1.7686529159545898
Batch 54/64 loss: 1.7603510618209839
Batch 55/64 loss: 1.7651259899139404
Batch 56/64 loss: 1.7644286155700684
Batch 57/64 loss: 1.784444808959961
Batch 58/64 loss: 1.7651034593582153
Batch 59/64 loss: 1.7605212926864624
Batch 60/64 loss: 1.7815823554992676
Batch 61/64 loss: 1.7630343437194824
Batch 62/64 loss: 1.765448808670044
Batch 63/64 loss: 1.7650967836380005
Batch 64/64 loss: 1.966688871383667
Epoch 95  Train loss: 1.7665410125956815  Val loss: 1.78338144243378
Epoch 96
-------------------------------
Batch 1/64 loss: 1.760680079460144
Batch 2/64 loss: 1.7632704973220825
Batch 3/64 loss: 1.7658581733703613
Batch 4/64 loss: 1.7647062540054321
Batch 5/64 loss: 1.76535165309906
Batch 6/64 loss: 1.762365698814392
Batch 7/64 loss: 1.7643253803253174
Batch 8/64 loss: 1.7698560953140259
Batch 9/64 loss: 1.7885262966156006
Batch 10/64 loss: 1.7616475820541382
Batch 11/64 loss: 1.7614549398422241
Batch 12/64 loss: 1.766799807548523
Batch 13/64 loss: 1.7625797986984253
Batch 14/64 loss: 1.7645385265350342
Batch 15/64 loss: 1.76713228225708
Batch 16/64 loss: 1.7666420936584473
Batch 17/64 loss: 1.761664628982544
Batch 18/64 loss: 1.7716436386108398
Batch 19/64 loss: 1.7659649848937988
Batch 20/64 loss: 1.7645491361618042
Batch 21/64 loss: 1.7718501091003418
Batch 22/64 loss: 1.7622501850128174
Batch 23/64 loss: 1.7632477283477783
Batch 24/64 loss: 1.7642189264297485
Batch 25/64 loss: 1.7671536207199097
Batch 26/64 loss: 1.7756942510604858
Batch 27/64 loss: 1.7657355070114136
Batch 28/64 loss: 1.7634634971618652
Batch 29/64 loss: 1.766658067703247
Batch 30/64 loss: 1.7610925436019897
Batch 31/64 loss: 1.7650365829467773
Batch 32/64 loss: 1.762063980102539
Batch 33/64 loss: 1.7631361484527588
Batch 34/64 loss: 1.7619340419769287
Batch 35/64 loss: 1.7594718933105469
Batch 36/64 loss: 1.7594492435455322
Batch 37/64 loss: 1.7613561153411865
Batch 38/64 loss: 1.7600281238555908
Batch 39/64 loss: 1.7631951570510864
Batch 40/64 loss: 1.7617723941802979
Batch 41/64 loss: 1.7617294788360596
Batch 42/64 loss: 1.7613649368286133
Batch 43/64 loss: 1.7673702239990234
Batch 44/64 loss: 1.7637732028961182
Batch 45/64 loss: 1.7636688947677612
Batch 46/64 loss: 1.7630945444107056
Batch 47/64 loss: 1.7641046047210693
Batch 48/64 loss: 1.7612546682357788
Batch 49/64 loss: 1.7639418840408325
Batch 50/64 loss: 1.7624931335449219
Batch 51/64 loss: 1.760404109954834
Batch 52/64 loss: 1.7643126249313354
Batch 53/64 loss: 1.763377070426941
Batch 54/64 loss: 1.773633599281311
Batch 55/64 loss: 1.7607388496398926
Batch 56/64 loss: 1.7709729671478271
Batch 57/64 loss: 1.7677040100097656
Batch 58/64 loss: 1.7629735469818115
Batch 59/64 loss: 1.7610421180725098
Batch 60/64 loss: 1.758683681488037
Batch 61/64 loss: 1.76350736618042
Batch 62/64 loss: 1.762738585472107
Batch 63/64 loss: 1.7601170539855957
Batch 64/64 loss: 1.9603384733200073
Epoch 96  Train loss: 1.766770520397261  Val loss: 1.7941165461982649
Epoch 97
-------------------------------
Batch 1/64 loss: 1.7795621156692505
Batch 2/64 loss: 1.7592346668243408
Batch 3/64 loss: 1.757481336593628
Batch 4/64 loss: 1.7622406482696533
Batch 5/64 loss: 1.7782082557678223
Batch 6/64 loss: 1.7720643281936646
Batch 7/64 loss: 1.765709638595581
Batch 8/64 loss: 1.758791208267212
Batch 9/64 loss: 1.7615519762039185
Batch 10/64 loss: 1.7590148448944092
Batch 11/64 loss: 1.7598521709442139
Batch 12/64 loss: 1.7593189477920532
Batch 13/64 loss: 1.7578132152557373
Batch 14/64 loss: 1.759294033050537
Batch 15/64 loss: 1.757265329360962
Batch 16/64 loss: 1.7670247554779053
Batch 17/64 loss: 1.759574055671692
Batch 18/64 loss: 1.759206771850586
Batch 19/64 loss: 1.7582842111587524
Batch 20/64 loss: 1.7581863403320312
Batch 21/64 loss: 1.7541825771331787
Batch 22/64 loss: 1.7597354650497437
Batch 23/64 loss: 1.753806233406067
Batch 24/64 loss: 1.7596557140350342
Batch 25/64 loss: 1.7717602252960205
Batch 26/64 loss: 1.7613214254379272
Batch 27/64 loss: 1.759812831878662
Batch 28/64 loss: 1.75957190990448
Batch 29/64 loss: 1.7568072080612183
Batch 30/64 loss: 1.7598810195922852
Batch 31/64 loss: 1.7573795318603516
Batch 32/64 loss: 1.7585960626602173
Batch 33/64 loss: 1.7594523429870605
Batch 34/64 loss: 1.7600570917129517
Batch 35/64 loss: 1.758772850036621
Batch 36/64 loss: 1.7696303129196167
Batch 37/64 loss: 1.7594599723815918
Batch 38/64 loss: 1.7584502696990967
Batch 39/64 loss: 1.759587287902832
Batch 40/64 loss: 1.7580819129943848
Batch 41/64 loss: 1.7674943208694458
Batch 42/64 loss: 1.7642614841461182
Batch 43/64 loss: 1.764934778213501
Batch 44/64 loss: 1.7651820182800293
Batch 45/64 loss: 1.765254020690918
Batch 46/64 loss: 1.7624505758285522
Batch 47/64 loss: 1.767568826675415
Batch 48/64 loss: 1.7562263011932373
Batch 49/64 loss: 1.7571622133255005
Batch 50/64 loss: 1.756521463394165
Batch 51/64 loss: 1.7656298875808716
Batch 52/64 loss: 1.759765386581421
Batch 53/64 loss: 1.7599644660949707
Batch 54/64 loss: 1.759295105934143
Batch 55/64 loss: 1.7609241008758545
Batch 56/64 loss: 1.759404182434082
Batch 57/64 loss: 1.759708285331726
Batch 58/64 loss: 1.759629726409912
Batch 59/64 loss: 1.7672127485275269
Batch 60/64 loss: 1.7580183744430542
Batch 61/64 loss: 1.756440281867981
Batch 62/64 loss: 1.7589913606643677
Batch 63/64 loss: 1.7564218044281006
Batch 64/64 loss: 1.9645875692367554
Epoch 97  Train loss: 1.7635699370328117  Val loss: 1.7886444809510536
Epoch 98
-------------------------------
Batch 1/64 loss: 1.756601333618164
Batch 2/64 loss: 1.75669264793396
Batch 3/64 loss: 1.7565059661865234
Batch 4/64 loss: 1.7552859783172607
Batch 5/64 loss: 1.7601670026779175
Batch 6/64 loss: 1.7597413063049316
Batch 7/64 loss: 1.7568402290344238
Batch 8/64 loss: 1.7624835968017578
Batch 9/64 loss: 1.7655696868896484
Batch 10/64 loss: 1.7708945274353027
Batch 11/64 loss: 1.7634425163269043
Batch 12/64 loss: 1.7636215686798096
Batch 13/64 loss: 1.7587286233901978
Batch 14/64 loss: 1.7615302801132202
Batch 15/64 loss: 1.7563021183013916
Batch 16/64 loss: 1.7596979141235352
Batch 17/64 loss: 1.7594486474990845
Batch 18/64 loss: 1.7565124034881592
Batch 19/64 loss: 1.7608953714370728
Batch 20/64 loss: 1.7593202590942383
Batch 21/64 loss: 1.7611260414123535
Batch 22/64 loss: 1.759969711303711
Batch 23/64 loss: 1.7578591108322144
Batch 24/64 loss: 1.7630447149276733
Batch 25/64 loss: 1.7606253623962402
Batch 26/64 loss: 1.7594934701919556
Batch 27/64 loss: 1.7624202966690063
Batch 28/64 loss: 1.7578356266021729
Batch 29/64 loss: 1.7610385417938232
Batch 30/64 loss: 1.772175908088684
Batch 31/64 loss: 1.7558956146240234
Batch 32/64 loss: 1.7636809349060059
Batch 33/64 loss: 1.7625445127487183
Batch 34/64 loss: 1.755728840827942
Batch 35/64 loss: 1.7603192329406738
Batch 36/64 loss: 1.7596207857131958
Batch 37/64 loss: 1.7583696842193604
Batch 38/64 loss: 1.758751392364502
Batch 39/64 loss: 1.7590553760528564
Batch 40/64 loss: 1.7543790340423584
Batch 41/64 loss: 1.7594003677368164
Batch 42/64 loss: 1.7554347515106201
Batch 43/64 loss: 1.760359525680542
Batch 44/64 loss: 1.7563190460205078
Batch 45/64 loss: 1.7585128545761108
Batch 46/64 loss: 1.7579636573791504
Batch 47/64 loss: 1.762423038482666
Batch 48/64 loss: 1.7612754106521606
Batch 49/64 loss: 1.7629725933074951
Batch 50/64 loss: 1.763494849205017
Batch 51/64 loss: 1.7564136981964111
Batch 52/64 loss: 1.7634148597717285
Batch 53/64 loss: 1.766707420349121
Batch 54/64 loss: 1.7646846771240234
Batch 55/64 loss: 1.7563867568969727
Batch 56/64 loss: 1.7605233192443848
Batch 57/64 loss: 1.758336067199707
Batch 58/64 loss: 1.7587010860443115
Batch 59/64 loss: 1.7592313289642334
Batch 60/64 loss: 1.7603340148925781
Batch 61/64 loss: 1.7690253257751465
Batch 62/64 loss: 1.7582929134368896
Batch 63/64 loss: 1.7574149370193481
Batch 64/64 loss: 1.9603855609893799
Epoch 98  Train loss: 1.762543181812062  Val loss: 1.7860344496789258
Epoch 99
-------------------------------
Batch 1/64 loss: 1.7592699527740479
Batch 2/64 loss: 1.7633929252624512
Batch 3/64 loss: 1.7623810768127441
Batch 4/64 loss: 1.7593492269515991
Batch 5/64 loss: 1.7620471715927124
Batch 6/64 loss: 1.7597954273223877
Batch 7/64 loss: 1.7592655420303345
Batch 8/64 loss: 1.761328935623169
Batch 9/64 loss: 1.76030433177948
Batch 10/64 loss: 1.754644751548767
Batch 11/64 loss: 1.759761095046997
Batch 12/64 loss: 1.7575170993804932
Batch 13/64 loss: 1.7561630010604858
Batch 14/64 loss: 1.7572013139724731
Batch 15/64 loss: 1.7740272283554077
Batch 16/64 loss: 1.7604961395263672
Batch 17/64 loss: 1.7575711011886597
Batch 18/64 loss: 1.7554823160171509
Batch 19/64 loss: 1.7577929496765137
Batch 20/64 loss: 1.7566324472427368
Batch 21/64 loss: 1.754391074180603
Batch 22/64 loss: 1.7585827112197876
Batch 23/64 loss: 1.754723310470581
Batch 24/64 loss: 1.755459189414978
Batch 25/64 loss: 1.7587002515792847
Batch 26/64 loss: 1.758424162864685
Batch 27/64 loss: 1.7545015811920166
Batch 28/64 loss: 1.7585113048553467
Batch 29/64 loss: 1.7616338729858398
Batch 30/64 loss: 1.7713911533355713
Batch 31/64 loss: 1.7554641962051392
Batch 32/64 loss: 1.7605665922164917
Batch 33/64 loss: 1.7573949098587036
Batch 34/64 loss: 1.7576735019683838
Batch 35/64 loss: 1.7656885385513306
Batch 36/64 loss: 1.7578791379928589
Batch 37/64 loss: 1.7533329725265503
Batch 38/64 loss: 1.755936861038208
Batch 39/64 loss: 1.7641081809997559
Batch 40/64 loss: 1.7635917663574219
Batch 41/64 loss: 1.757673740386963
Batch 42/64 loss: 1.758177399635315
Batch 43/64 loss: 1.7568366527557373
Batch 44/64 loss: 1.7595361471176147
Batch 45/64 loss: 1.7568154335021973
Batch 46/64 loss: 1.7557021379470825
Batch 47/64 loss: 1.758446216583252
Batch 48/64 loss: 1.755854845046997
Batch 49/64 loss: 1.7543082237243652
Batch 50/64 loss: 1.7564785480499268
Batch 51/64 loss: 1.7587018013000488
Batch 52/64 loss: 1.7580351829528809
Batch 53/64 loss: 1.7545408010482788
Batch 54/64 loss: 1.7602849006652832
Batch 55/64 loss: 1.7561159133911133
Batch 56/64 loss: 1.7572367191314697
Batch 57/64 loss: 1.7567332983016968
Batch 58/64 loss: 1.7583105564117432
Batch 59/64 loss: 1.7574694156646729
Batch 60/64 loss: 1.7568191289901733
Batch 61/64 loss: 1.7650525569915771
Batch 62/64 loss: 1.759096622467041
Batch 63/64 loss: 1.7557477951049805
Batch 64/64 loss: 1.9626059532165527
Epoch 99  Train loss: 1.7610714949813544  Val loss: 1.7928075577385236
Epoch 100
-------------------------------
Batch 1/64 loss: 1.7588526010513306
Batch 2/64 loss: 1.7571768760681152
Batch 3/64 loss: 1.7576371431350708
Batch 4/64 loss: 1.7693480253219604
Batch 5/64 loss: 1.761143445968628
Batch 6/64 loss: 1.7580273151397705
Batch 7/64 loss: 1.7642898559570312
Batch 8/64 loss: 1.761048674583435
Batch 9/64 loss: 1.756258487701416
Batch 10/64 loss: 1.761880874633789
Batch 11/64 loss: 1.7579227685928345
Batch 12/64 loss: 1.7622913122177124
Batch 13/64 loss: 1.7643660306930542
Batch 14/64 loss: 1.7616630792617798
Batch 15/64 loss: 1.759439468383789
Batch 16/64 loss: 1.7580113410949707
Batch 17/64 loss: 1.7600178718566895
Batch 18/64 loss: 1.758141279220581
Batch 19/64 loss: 1.7578697204589844
Batch 20/64 loss: 1.7561453580856323
Batch 21/64 loss: 1.7543611526489258
Batch 22/64 loss: 1.7575922012329102
Batch 23/64 loss: 1.7547985315322876
Batch 24/64 loss: 1.7566840648651123
Batch 25/64 loss: 1.7597429752349854
Batch 26/64 loss: 1.7596497535705566
Batch 27/64 loss: 1.753111720085144
Batch 28/64 loss: 1.7557228803634644
Batch 29/64 loss: 1.7782365083694458
Batch 30/64 loss: 1.7587336301803589
Batch 31/64 loss: 1.7581232786178589
Batch 32/64 loss: 1.7563443183898926
Batch 33/64 loss: 1.75303053855896
Batch 34/64 loss: 1.7706212997436523
Batch 35/64 loss: 1.7588101625442505
Batch 36/64 loss: 1.7557148933410645
Batch 37/64 loss: 1.7562099695205688
Batch 38/64 loss: 1.7576075792312622
Batch 39/64 loss: 1.7560521364212036
Batch 40/64 loss: 1.7551050186157227
Batch 41/64 loss: 1.754145622253418
Batch 42/64 loss: 1.7575829029083252
Batch 43/64 loss: 1.7529467344284058
Batch 44/64 loss: 1.756052017211914
Batch 45/64 loss: 1.7554378509521484
Batch 46/64 loss: 1.7629283666610718
Batch 47/64 loss: 1.7564797401428223
Batch 48/64 loss: 1.7524807453155518
Batch 49/64 loss: 1.7563978433609009
Batch 50/64 loss: 1.7616833448410034
Batch 51/64 loss: 1.7537075281143188
Batch 52/64 loss: 1.7560099363327026
Batch 53/64 loss: 1.7570760250091553
Batch 54/64 loss: 1.7562012672424316
Batch 55/64 loss: 1.7568621635437012
Batch 56/64 loss: 1.7544342279434204
Batch 57/64 loss: 1.7562154531478882
Batch 58/64 loss: 1.7536579370498657
Batch 59/64 loss: 1.755783200263977
Batch 60/64 loss: 1.7605924606323242
Batch 61/64 loss: 1.7584710121154785
Batch 62/64 loss: 1.7630912065505981
Batch 63/64 loss: 1.7606160640716553
Batch 64/64 loss: 1.956787347793579
Epoch 100  Train loss: 1.7606937773087445  Val loss: 1.777281594030636
Saving best model, epoch: 100
Epoch 101
-------------------------------
Batch 1/64 loss: 1.7629709243774414
Batch 2/64 loss: 1.7563248872756958
Batch 3/64 loss: 1.7586302757263184
Batch 4/64 loss: 1.758312702178955
Batch 5/64 loss: 1.7582911252975464
Batch 6/64 loss: 1.7530416250228882
Batch 7/64 loss: 1.7565569877624512
Batch 8/64 loss: 1.7560757398605347
Batch 9/64 loss: 1.75595223903656
Batch 10/64 loss: 1.7622966766357422
Batch 11/64 loss: 1.7574998140335083
Batch 12/64 loss: 1.755580186843872
Batch 13/64 loss: 1.7638967037200928
Batch 14/64 loss: 1.7570834159851074
Batch 15/64 loss: 1.754943609237671
Batch 16/64 loss: 1.755446195602417
Batch 17/64 loss: 1.7596415281295776
Batch 18/64 loss: 1.7595229148864746
Batch 19/64 loss: 1.7574021816253662
Batch 20/64 loss: 1.7579251527786255
Batch 21/64 loss: 1.7588717937469482
Batch 22/64 loss: 1.757745623588562
Batch 23/64 loss: 1.7554309368133545
Batch 24/64 loss: 1.7577400207519531
Batch 25/64 loss: 1.7567546367645264
Batch 26/64 loss: 1.755971074104309
Batch 27/64 loss: 1.7583118677139282
Batch 28/64 loss: 1.7559345960617065
Batch 29/64 loss: 1.7546930313110352
Batch 30/64 loss: 1.7563470602035522
Batch 31/64 loss: 1.7548952102661133
Batch 32/64 loss: 1.7602717876434326
Batch 33/64 loss: 1.7569670677185059
Batch 34/64 loss: 1.7515592575073242
Batch 35/64 loss: 1.7650067806243896
Batch 36/64 loss: 1.75355863571167
Batch 37/64 loss: 1.7528928518295288
Batch 38/64 loss: 1.7599133253097534
Batch 39/64 loss: 1.757628321647644
Batch 40/64 loss: 1.7528772354125977
Batch 41/64 loss: 1.753788948059082
Batch 42/64 loss: 1.7578132152557373
Batch 43/64 loss: 1.7560852766036987
Batch 44/64 loss: 1.7557716369628906
Batch 45/64 loss: 1.7581675052642822
Batch 46/64 loss: 1.7554316520690918
Batch 47/64 loss: 1.7529767751693726
Batch 48/64 loss: 1.7555720806121826
Batch 49/64 loss: 1.7577208280563354
Batch 50/64 loss: 1.7552120685577393
Batch 51/64 loss: 1.7609754800796509
Batch 52/64 loss: 1.7576138973236084
Batch 53/64 loss: 1.7596255540847778
Batch 54/64 loss: 1.7563129663467407
Batch 55/64 loss: 1.7603285312652588
Batch 56/64 loss: 1.7709007263183594
Batch 57/64 loss: 1.7551336288452148
Batch 58/64 loss: 1.7543256282806396
Batch 59/64 loss: 1.7550299167633057
Batch 60/64 loss: 1.7546720504760742
Batch 61/64 loss: 1.753919243812561
Batch 62/64 loss: 1.7642381191253662
Batch 63/64 loss: 1.7584311962127686
Batch 64/64 loss: 1.956160068511963
Epoch 101  Train loss: 1.759653850630218  Val loss: 1.7828713430162149
Epoch 102
-------------------------------
Batch 1/64 loss: 1.7678420543670654
Batch 2/64 loss: 1.7585409879684448
Batch 3/64 loss: 1.7564948797225952
Batch 4/64 loss: 1.7565925121307373
Batch 5/64 loss: 1.761987328529358
Batch 6/64 loss: 1.7625854015350342
Batch 7/64 loss: 1.7571303844451904
Batch 8/64 loss: 1.7604479789733887
Batch 9/64 loss: 1.762313723564148
Batch 10/64 loss: 1.760648488998413
Batch 11/64 loss: 1.760484218597412
Batch 12/64 loss: 1.7603974342346191
Batch 13/64 loss: 1.7588200569152832
Batch 14/64 loss: 1.7581806182861328
Batch 15/64 loss: 1.7550221681594849
Batch 16/64 loss: 1.7568637132644653
Batch 17/64 loss: 1.7698806524276733
Batch 18/64 loss: 1.765223503112793
Batch 19/64 loss: 1.7577654123306274
Batch 20/64 loss: 1.758398413658142
Batch 21/64 loss: 1.764347791671753
Batch 22/64 loss: 1.7586758136749268
Batch 23/64 loss: 1.7570610046386719
Batch 24/64 loss: 1.7562404870986938
Batch 25/64 loss: 1.7561228275299072
Batch 26/64 loss: 1.7575373649597168
Batch 27/64 loss: 1.7559651136398315
Batch 28/64 loss: 1.7599711418151855
Batch 29/64 loss: 1.7593777179718018
Batch 30/64 loss: 1.7581695318222046
Batch 31/64 loss: 1.7600631713867188
Batch 32/64 loss: 1.76520574092865
Batch 33/64 loss: 1.7599143981933594
Batch 34/64 loss: 1.7563326358795166
Batch 35/64 loss: 1.7542222738265991
Batch 36/64 loss: 1.759059190750122
Batch 37/64 loss: 1.7558543682098389
Batch 38/64 loss: 1.7605681419372559
Batch 39/64 loss: 1.7602989673614502
Batch 40/64 loss: 1.7618403434753418
Batch 41/64 loss: 1.7562885284423828
Batch 42/64 loss: 1.7537888288497925
Batch 43/64 loss: 1.7560386657714844
Batch 44/64 loss: 1.755770206451416
Batch 45/64 loss: 1.7517428398132324
Batch 46/64 loss: 1.7704296112060547
Batch 47/64 loss: 1.7572470903396606
Batch 48/64 loss: 1.7537593841552734
Batch 49/64 loss: 1.7549850940704346
Batch 50/64 loss: 1.7574951648712158
Batch 51/64 loss: 1.7555969953536987
Batch 52/64 loss: 1.7533385753631592
Batch 53/64 loss: 1.7552489042282104
Batch 54/64 loss: 1.7570465803146362
Batch 55/64 loss: 1.7603089809417725
Batch 56/64 loss: 1.7583891153335571
Batch 57/64 loss: 1.7588038444519043
Batch 58/64 loss: 1.752475619316101
Batch 59/64 loss: 1.75449538230896
Batch 60/64 loss: 1.758021593093872
Batch 61/64 loss: 1.7575902938842773
Batch 62/64 loss: 1.756646990776062
Batch 63/64 loss: 1.7616124153137207
Batch 64/64 loss: 1.9562634229660034
Epoch 102  Train loss: 1.760890450664595  Val loss: 1.7786668149876022
Epoch 103
-------------------------------
Batch 1/64 loss: 1.7566840648651123
Batch 2/64 loss: 1.7552297115325928
Batch 3/64 loss: 1.7573132514953613
Batch 4/64 loss: 1.7580617666244507
Batch 5/64 loss: 1.7554874420166016
Batch 6/64 loss: 1.7552789449691772
Batch 7/64 loss: 1.7557071447372437
Batch 8/64 loss: 1.7566719055175781
Batch 9/64 loss: 1.75815749168396
Batch 10/64 loss: 1.7546825408935547
Batch 11/64 loss: 1.7584576606750488
Batch 12/64 loss: 1.7564822435379028
Batch 13/64 loss: 1.7578444480895996
Batch 14/64 loss: 1.7520959377288818
Batch 15/64 loss: 1.7612569332122803
Batch 16/64 loss: 1.7713042497634888
Batch 17/64 loss: 1.7552589178085327
Batch 18/64 loss: 1.7595295906066895
Batch 19/64 loss: 1.7600340843200684
Batch 20/64 loss: 1.7595863342285156
Batch 21/64 loss: 1.7578003406524658
Batch 22/64 loss: 1.7553702592849731
Batch 23/64 loss: 1.757222294807434
Batch 24/64 loss: 1.7701712846755981
Batch 25/64 loss: 1.7548866271972656
Batch 26/64 loss: 1.761615514755249
Batch 27/64 loss: 1.7670954465866089
Batch 28/64 loss: 1.7572582960128784
Batch 29/64 loss: 1.762529969215393
Batch 30/64 loss: 1.7564812898635864
Batch 31/64 loss: 1.7648307085037231
Batch 32/64 loss: 1.7586954832077026
Batch 33/64 loss: 1.7561112642288208
Batch 34/64 loss: 1.7593928575515747
Batch 35/64 loss: 1.7588220834732056
Batch 36/64 loss: 1.7550848722457886
Batch 37/64 loss: 1.7616851329803467
Batch 38/64 loss: 1.7542598247528076
Batch 39/64 loss: 1.7560560703277588
Batch 40/64 loss: 1.763144612312317
Batch 41/64 loss: 1.7567946910858154
Batch 42/64 loss: 1.7646396160125732
Batch 43/64 loss: 1.7583695650100708
Batch 44/64 loss: 1.754212498664856
Batch 45/64 loss: 1.7683972120285034
Batch 46/64 loss: 1.7576290369033813
Batch 47/64 loss: 1.755609393119812
Batch 48/64 loss: 1.7578325271606445
Batch 49/64 loss: 1.7573328018188477
Batch 50/64 loss: 1.7588722705841064
Batch 51/64 loss: 1.7600133419036865
Batch 52/64 loss: 1.761134147644043
Batch 53/64 loss: 1.7598273754119873
Batch 54/64 loss: 1.758753776550293
Batch 55/64 loss: 1.7635259628295898
Batch 56/64 loss: 1.7581291198730469
Batch 57/64 loss: 1.7674827575683594
Batch 58/64 loss: 1.7590703964233398
Batch 59/64 loss: 1.7629690170288086
Batch 60/64 loss: 1.7616937160491943
Batch 61/64 loss: 1.7595107555389404
Batch 62/64 loss: 1.7694480419158936
Batch 63/64 loss: 1.7614095211029053
Batch 64/64 loss: 1.9640450477600098
Epoch 103  Train loss: 1.761714983921425  Val loss: 1.7883048966987847
Epoch 104
-------------------------------
Batch 1/64 loss: 1.7632333040237427
Batch 2/64 loss: 1.7690383195877075
Batch 3/64 loss: 1.7541141510009766
Batch 4/64 loss: 1.760985255241394
Batch 5/64 loss: 1.7607780694961548
Batch 6/64 loss: 1.7591298818588257
Batch 7/64 loss: 1.7638171911239624
Batch 8/64 loss: 1.7633401155471802
Batch 9/64 loss: 1.7591499090194702
Batch 10/64 loss: 1.7605042457580566
Batch 11/64 loss: 1.7669405937194824
Batch 12/64 loss: 1.760897159576416
Batch 13/64 loss: 1.7590620517730713
Batch 14/64 loss: 1.7562459707260132
Batch 15/64 loss: 1.7713775634765625
Batch 16/64 loss: 1.756935954093933
Batch 17/64 loss: 1.759512186050415
Batch 18/64 loss: 1.7560491561889648
Batch 19/64 loss: 1.756156325340271
Batch 20/64 loss: 1.7651679515838623
Batch 21/64 loss: 1.7581875324249268
Batch 22/64 loss: 1.7595973014831543
Batch 23/64 loss: 1.7574095726013184
Batch 24/64 loss: 1.7626038789749146
Batch 25/64 loss: 1.763260841369629
Batch 26/64 loss: 1.7600178718566895
Batch 27/64 loss: 1.759507656097412
Batch 28/64 loss: 1.7570282220840454
Batch 29/64 loss: 1.759924292564392
Batch 30/64 loss: 1.7568449974060059
Batch 31/64 loss: 1.7569968700408936
Batch 32/64 loss: 1.7580175399780273
Batch 33/64 loss: 1.76839280128479
Batch 34/64 loss: 1.7558506727218628
Batch 35/64 loss: 1.7585216760635376
Batch 36/64 loss: 1.757834553718567
Batch 37/64 loss: 1.755882740020752
Batch 38/64 loss: 1.755159616470337
Batch 39/64 loss: 1.762477159500122
Batch 40/64 loss: 1.7601298093795776
Batch 41/64 loss: 1.7580374479293823
Batch 42/64 loss: 1.7600287199020386
Batch 43/64 loss: 1.7623603343963623
Batch 44/64 loss: 1.7589728832244873
Batch 45/64 loss: 1.7575047016143799
Batch 46/64 loss: 1.758274793624878
Batch 47/64 loss: 1.7631384134292603
Batch 48/64 loss: 1.7601318359375
Batch 49/64 loss: 1.7717561721801758
Batch 50/64 loss: 1.7601792812347412
Batch 51/64 loss: 1.7558945417404175
Batch 52/64 loss: 1.7659906148910522
Batch 53/64 loss: 1.7626895904541016
Batch 54/64 loss: 1.7802844047546387
Batch 55/64 loss: 1.7590712308883667
Batch 56/64 loss: 1.7632031440734863
Batch 57/64 loss: 1.7570717334747314
Batch 58/64 loss: 1.7593427896499634
Batch 59/64 loss: 1.758524775505066
Batch 60/64 loss: 1.7592575550079346
Batch 61/64 loss: 1.7587569952011108
Batch 62/64 loss: 1.7659112215042114
Batch 63/64 loss: 1.7596522569656372
Batch 64/64 loss: 1.9660487174987793
Epoch 104  Train loss: 1.7630847519519282  Val loss: 1.7841050518337394
Epoch 105
-------------------------------
Batch 1/64 loss: 1.7590863704681396
Batch 2/64 loss: 1.7574996948242188
Batch 3/64 loss: 1.7563899755477905
Batch 4/64 loss: 1.7610734701156616
Batch 5/64 loss: 1.7597401142120361
Batch 6/64 loss: 1.758375883102417
Batch 7/64 loss: 1.7578359842300415
Batch 8/64 loss: 1.7570010423660278
Batch 9/64 loss: 1.7585957050323486
Batch 10/64 loss: 1.7577309608459473
Batch 11/64 loss: 1.7557591199874878
Batch 12/64 loss: 1.7549022436141968
Batch 13/64 loss: 1.7566157579421997
Batch 14/64 loss: 1.7608715295791626
Batch 15/64 loss: 1.7557618618011475
Batch 16/64 loss: 1.7527281045913696
Batch 17/64 loss: 1.7540346384048462
Batch 18/64 loss: 1.7606438398361206
Batch 19/64 loss: 1.7543530464172363
Batch 20/64 loss: 1.760101079940796
Batch 21/64 loss: 1.7557965517044067
Batch 22/64 loss: 1.7569440603256226
Batch 23/64 loss: 1.757506012916565
Batch 24/64 loss: 1.7586522102355957
Batch 25/64 loss: 1.7574328184127808
Batch 26/64 loss: 1.7603999376296997
Batch 27/64 loss: 1.7689330577850342
Batch 28/64 loss: 1.7607433795928955
Batch 29/64 loss: 1.7533886432647705
Batch 30/64 loss: 1.7525070905685425
Batch 31/64 loss: 1.7661747932434082
Batch 32/64 loss: 1.759054183959961
Batch 33/64 loss: 1.7611463069915771
Batch 34/64 loss: 1.753157138824463
Batch 35/64 loss: 1.7800309658050537
Batch 36/64 loss: 1.7619993686676025
Batch 37/64 loss: 1.7585357427597046
Batch 38/64 loss: 1.7534546852111816
Batch 39/64 loss: 1.7543333768844604
Batch 40/64 loss: 1.7540283203125
Batch 41/64 loss: 1.7555934190750122
Batch 42/64 loss: 1.7528903484344482
Batch 43/64 loss: 1.7545411586761475
Batch 44/64 loss: 1.753463625907898
Batch 45/64 loss: 1.7621405124664307
Batch 46/64 loss: 1.7560837268829346
Batch 47/64 loss: 1.7576074600219727
Batch 48/64 loss: 1.753767490386963
Batch 49/64 loss: 1.7545593976974487
Batch 50/64 loss: 1.760337233543396
Batch 51/64 loss: 1.753395438194275
Batch 52/64 loss: 1.7598189115524292
Batch 53/64 loss: 1.7528462409973145
Batch 54/64 loss: 1.7542396783828735
Batch 55/64 loss: 1.759145736694336
Batch 56/64 loss: 1.7554242610931396
Batch 57/64 loss: 1.7554763555526733
Batch 58/64 loss: 1.7667371034622192
Batch 59/64 loss: 1.7541935443878174
Batch 60/64 loss: 1.7712411880493164
Batch 61/64 loss: 1.757143259048462
Batch 62/64 loss: 1.758109450340271
Batch 63/64 loss: 1.755098819732666
Batch 64/64 loss: 1.9587979316711426
Epoch 105  Train loss: 1.7602552451339422  Val loss: 1.779502565508446
Epoch 106
-------------------------------
Batch 1/64 loss: 1.7595274448394775
Batch 2/64 loss: 1.7602035999298096
Batch 3/64 loss: 1.757242202758789
Batch 4/64 loss: 1.7615528106689453
Batch 5/64 loss: 1.757555365562439
Batch 6/64 loss: 1.7613317966461182
Batch 7/64 loss: 1.7599648237228394
Batch 8/64 loss: 1.7625503540039062
Batch 9/64 loss: 1.7660489082336426
Batch 10/64 loss: 1.768606185913086
Batch 11/64 loss: 1.764634132385254
Batch 12/64 loss: 1.7651047706604004
Batch 13/64 loss: 1.760184407234192
Batch 14/64 loss: 1.761893630027771
Batch 15/64 loss: 1.7645678520202637
Batch 16/64 loss: 1.7615447044372559
Batch 17/64 loss: 1.7588672637939453
Batch 18/64 loss: 1.7616218328475952
Batch 19/64 loss: 1.7592028379440308
Batch 20/64 loss: 1.7596993446350098
Batch 21/64 loss: 1.7582826614379883
Batch 22/64 loss: 1.768330693244934
Batch 23/64 loss: 1.7582420110702515
Batch 24/64 loss: 1.7640730142593384
Batch 25/64 loss: 1.7584301233291626
Batch 26/64 loss: 1.756941318511963
Batch 27/64 loss: 1.7583307027816772
Batch 28/64 loss: 1.774633526802063
Batch 29/64 loss: 1.759987235069275
Batch 30/64 loss: 1.7581019401550293
Batch 31/64 loss: 1.7580734491348267
Batch 32/64 loss: 1.7557289600372314
Batch 33/64 loss: 1.7578544616699219
Batch 34/64 loss: 1.7696533203125
Batch 35/64 loss: 1.7533435821533203
Batch 36/64 loss: 1.7602002620697021
Batch 37/64 loss: 1.7539896965026855
Batch 38/64 loss: 1.7557787895202637
Batch 39/64 loss: 1.7589588165283203
Batch 40/64 loss: 1.7548638582229614
Batch 41/64 loss: 1.7528979778289795
Batch 42/64 loss: 1.7565375566482544
Batch 43/64 loss: 1.7580301761627197
Batch 44/64 loss: 1.7573261260986328
Batch 45/64 loss: 1.7576217651367188
Batch 46/64 loss: 1.755899429321289
Batch 47/64 loss: 1.7586970329284668
Batch 48/64 loss: 1.7721147537231445
Batch 49/64 loss: 1.7702032327651978
Batch 50/64 loss: 1.7607357501983643
Batch 51/64 loss: 1.76645827293396
Batch 52/64 loss: 1.7593796253204346
Batch 53/64 loss: 1.7559181451797485
Batch 54/64 loss: 1.7660133838653564
Batch 55/64 loss: 1.7671425342559814
Batch 56/64 loss: 1.75698721408844
Batch 57/64 loss: 1.7788931131362915
Batch 58/64 loss: 1.759053349494934
Batch 59/64 loss: 1.767230749130249
Batch 60/64 loss: 1.7689383029937744
Batch 61/64 loss: 1.7657849788665771
Batch 62/64 loss: 1.760187029838562
Batch 63/64 loss: 1.7560933828353882
Batch 64/64 loss: 1.9582446813583374
Epoch 106  Train loss: 1.763490667997622  Val loss: 1.7825040063497537
Epoch 107
-------------------------------
Batch 1/64 loss: 1.7543535232543945
Batch 2/64 loss: 1.757940411567688
Batch 3/64 loss: 1.757770299911499
Batch 4/64 loss: 1.7661625146865845
Batch 5/64 loss: 1.759055495262146
Batch 6/64 loss: 1.7600131034851074
Batch 7/64 loss: 1.7583818435668945
Batch 8/64 loss: 1.7689188718795776
Batch 9/64 loss: 1.758375644683838
Batch 10/64 loss: 1.757526159286499
Batch 11/64 loss: 1.758989930152893
Batch 12/64 loss: 1.7604331970214844
Batch 13/64 loss: 1.7583191394805908
Batch 14/64 loss: 1.7614364624023438
Batch 15/64 loss: 1.7602992057800293
Batch 16/64 loss: 1.7595595121383667
Batch 17/64 loss: 1.7565648555755615
Batch 18/64 loss: 1.7645318508148193
Batch 19/64 loss: 1.7604472637176514
Batch 20/64 loss: 1.7554261684417725
Batch 21/64 loss: 1.7552568912506104
Batch 22/64 loss: 1.7643415927886963
Batch 23/64 loss: 1.7547447681427002
Batch 24/64 loss: 1.7634739875793457
Batch 25/64 loss: 1.756106972694397
Batch 26/64 loss: 1.7595970630645752
Batch 27/64 loss: 1.7562215328216553
Batch 28/64 loss: 1.7556238174438477
Batch 29/64 loss: 1.7594776153564453
Batch 30/64 loss: 1.7590973377227783
Batch 31/64 loss: 1.761643886566162
Batch 32/64 loss: 1.7564581632614136
Batch 33/64 loss: 1.7562605142593384
Batch 34/64 loss: 1.761865258216858
Batch 35/64 loss: 1.7618157863616943
Batch 36/64 loss: 1.7653753757476807
Batch 37/64 loss: 1.7577404975891113
Batch 38/64 loss: 1.7598462104797363
Batch 39/64 loss: 1.7597476243972778
Batch 40/64 loss: 1.7562991380691528
Batch 41/64 loss: 1.7582173347473145
Batch 42/64 loss: 1.7809247970581055
Batch 43/64 loss: 1.7564226388931274
Batch 44/64 loss: 1.7657724618911743
Batch 45/64 loss: 1.7571430206298828
Batch 46/64 loss: 1.7595940828323364
Batch 47/64 loss: 1.7601884603500366
Batch 48/64 loss: 1.759486436843872
Batch 49/64 loss: 1.7561755180358887
Batch 50/64 loss: 1.7940183877944946
Batch 51/64 loss: 1.7594258785247803
Batch 52/64 loss: 1.7558355331420898
Batch 53/64 loss: 1.7707046270370483
Batch 54/64 loss: 1.7627955675125122
Batch 55/64 loss: 1.7598527669906616
Batch 56/64 loss: 1.7600690126419067
Batch 57/64 loss: 1.7555538415908813
Batch 58/64 loss: 1.755537748336792
Batch 59/64 loss: 1.7543340921401978
Batch 60/64 loss: 1.7558614015579224
Batch 61/64 loss: 1.7613639831542969
Batch 62/64 loss: 1.7608013153076172
Batch 63/64 loss: 1.7623670101165771
Batch 64/64 loss: 1.9727253913879395
Epoch 107  Train loss: 1.7627841481975481  Val loss: 1.7793085583296837
Epoch 108
-------------------------------
Batch 1/64 loss: 1.7637571096420288
Batch 2/64 loss: 1.7625383138656616
Batch 3/64 loss: 1.7566585540771484
Batch 4/64 loss: 1.7570222616195679
Batch 5/64 loss: 1.7620301246643066
Batch 6/64 loss: 1.7548823356628418
Batch 7/64 loss: 1.758400797843933
Batch 8/64 loss: 1.7573471069335938
Batch 9/64 loss: 1.760521650314331
Batch 10/64 loss: 1.755230188369751
Batch 11/64 loss: 1.7564297914505005
Batch 12/64 loss: 1.7584419250488281
Batch 13/64 loss: 1.7556201219558716
Batch 14/64 loss: 1.7571088075637817
Batch 15/64 loss: 1.7574841976165771
Batch 16/64 loss: 1.7552812099456787
Batch 17/64 loss: 1.755805492401123
Batch 18/64 loss: 1.7562470436096191
Batch 19/64 loss: 1.7537555694580078
Batch 20/64 loss: 1.759662389755249
Batch 21/64 loss: 1.7589619159698486
Batch 22/64 loss: 1.7582005262374878
Batch 23/64 loss: 1.7564398050308228
Batch 24/64 loss: 1.7575554847717285
Batch 25/64 loss: 1.7799806594848633
Batch 26/64 loss: 1.7605128288269043
Batch 27/64 loss: 1.757288932800293
Batch 28/64 loss: 1.759311318397522
Batch 29/64 loss: 1.7595024108886719
Batch 30/64 loss: 1.7577345371246338
Batch 31/64 loss: 1.7644329071044922
Batch 32/64 loss: 1.757262110710144
Batch 33/64 loss: 1.7616459131240845
Batch 34/64 loss: 1.7577697038650513
Batch 35/64 loss: 1.7549221515655518
Batch 36/64 loss: 1.7562737464904785
Batch 37/64 loss: 1.7617743015289307
Batch 38/64 loss: 1.7616617679595947
Batch 39/64 loss: 1.7590360641479492
Batch 40/64 loss: 1.7539455890655518
Batch 41/64 loss: 1.758467674255371
Batch 42/64 loss: 1.7682684659957886
Batch 43/64 loss: 1.7694741487503052
Batch 44/64 loss: 1.7624704837799072
Batch 45/64 loss: 1.7636123895645142
Batch 46/64 loss: 1.763540267944336
Batch 47/64 loss: 1.761230707168579
Batch 48/64 loss: 1.7656105756759644
Batch 49/64 loss: 1.756384253501892
Batch 50/64 loss: 1.76005220413208
Batch 51/64 loss: 1.7610502243041992
Batch 52/64 loss: 1.7602941989898682
Batch 53/64 loss: 1.7577145099639893
Batch 54/64 loss: 1.7783656120300293
Batch 55/64 loss: 1.7590159177780151
Batch 56/64 loss: 1.7607731819152832
Batch 57/64 loss: 1.7584820985794067
Batch 58/64 loss: 1.755735993385315
Batch 59/64 loss: 1.7610623836517334
Batch 60/64 loss: 1.7808951139450073
Batch 61/64 loss: 1.7587404251098633
Batch 62/64 loss: 1.7702707052230835
Batch 63/64 loss: 1.7599023580551147
Batch 64/64 loss: 1.9626035690307617
Epoch 108  Train loss: 1.7626949684292663  Val loss: 1.7873264760086216
Epoch 109
-------------------------------
Batch 1/64 loss: 1.7602452039718628
Batch 2/64 loss: 1.7603352069854736
Batch 3/64 loss: 1.759137511253357
Batch 4/64 loss: 1.7604055404663086
Batch 5/64 loss: 1.755915880203247
Batch 6/64 loss: 1.7573268413543701
Batch 7/64 loss: 1.7787225246429443
Batch 8/64 loss: 1.7565550804138184
Batch 9/64 loss: 1.7545989751815796
Batch 10/64 loss: 1.7588260173797607
Batch 11/64 loss: 1.7597861289978027
Batch 12/64 loss: 1.7581738233566284
Batch 13/64 loss: 1.754774808883667
Batch 14/64 loss: 1.7593278884887695
Batch 15/64 loss: 1.758061170578003
Batch 16/64 loss: 1.7564258575439453
Batch 17/64 loss: 1.7612051963806152
Batch 18/64 loss: 1.7566367387771606
Batch 19/64 loss: 1.7592477798461914
Batch 20/64 loss: 1.7593231201171875
Batch 21/64 loss: 1.7560031414031982
Batch 22/64 loss: 1.755579948425293
Batch 23/64 loss: 1.7571412324905396
Batch 24/64 loss: 1.759642243385315
Batch 25/64 loss: 1.7562932968139648
Batch 26/64 loss: 1.752740740776062
Batch 27/64 loss: 1.7552006244659424
Batch 28/64 loss: 1.7530943155288696
Batch 29/64 loss: 1.7536163330078125
Batch 30/64 loss: 1.7592647075653076
Batch 31/64 loss: 1.7525899410247803
Batch 32/64 loss: 1.7555166482925415
Batch 33/64 loss: 1.7533197402954102
Batch 34/64 loss: 1.754754662513733
Batch 35/64 loss: 1.7579413652420044
Batch 36/64 loss: 1.7706408500671387
Batch 37/64 loss: 1.7577139139175415
Batch 38/64 loss: 1.7561960220336914
Batch 39/64 loss: 1.7565162181854248
Batch 40/64 loss: 1.7777820825576782
Batch 41/64 loss: 1.7525287866592407
Batch 42/64 loss: 1.7727255821228027
Batch 43/64 loss: 1.75650155544281
Batch 44/64 loss: 1.7545167207717896
Batch 45/64 loss: 1.7596873044967651
Batch 46/64 loss: 1.757903814315796
Batch 47/64 loss: 1.7587890625
Batch 48/64 loss: 1.7551442384719849
Batch 49/64 loss: 1.7579073905944824
Batch 50/64 loss: 1.759672999382019
Batch 51/64 loss: 1.7562274932861328
Batch 52/64 loss: 1.7540837526321411
Batch 53/64 loss: 1.7529525756835938
Batch 54/64 loss: 1.7600681781768799
Batch 55/64 loss: 1.7579615116119385
Batch 56/64 loss: 1.7540377378463745
Batch 57/64 loss: 1.7555845975875854
Batch 58/64 loss: 1.761171817779541
Batch 59/64 loss: 1.7571442127227783
Batch 60/64 loss: 1.7627671957015991
Batch 61/64 loss: 1.7630654573440552
Batch 62/64 loss: 1.7571593523025513
Batch 63/64 loss: 1.762294054031372
Batch 64/64 loss: 1.9579156637191772
Epoch 109  Train loss: 1.7607044935226441  Val loss: 1.781759452164378
Epoch 110
-------------------------------
Batch 1/64 loss: 1.767818570137024
Batch 2/64 loss: 1.7712533473968506
Batch 3/64 loss: 1.77128267288208
Batch 4/64 loss: 1.7673689126968384
Batch 5/64 loss: 1.7588882446289062
Batch 6/64 loss: 1.7607605457305908
Batch 7/64 loss: 1.761812448501587
Batch 8/64 loss: 1.76893949508667
Batch 9/64 loss: 1.76065993309021
Batch 10/64 loss: 1.759146809577942
Batch 11/64 loss: 1.7635436058044434
Batch 12/64 loss: 1.7611286640167236
Batch 13/64 loss: 1.7584643363952637
Batch 14/64 loss: 1.7604173421859741
Batch 15/64 loss: 1.761125922203064
Batch 16/64 loss: 1.7726879119873047
Batch 17/64 loss: 1.7566365003585815
Batch 18/64 loss: 1.7628024816513062
Batch 19/64 loss: 1.76167631149292
Batch 20/64 loss: 1.7577579021453857
Batch 21/64 loss: 1.7592833042144775
Batch 22/64 loss: 1.7591302394866943
Batch 23/64 loss: 1.7609397172927856
Batch 24/64 loss: 1.7579574584960938
Batch 25/64 loss: 1.7585034370422363
Batch 26/64 loss: 1.7594720125198364
Batch 27/64 loss: 1.7602951526641846
Batch 28/64 loss: 1.756279706954956
Batch 29/64 loss: 1.7623014450073242
Batch 30/64 loss: 1.759944200515747
Batch 31/64 loss: 1.7605912685394287
Batch 32/64 loss: 1.757589340209961
Batch 33/64 loss: 1.769018530845642
Batch 34/64 loss: 1.765825629234314
Batch 35/64 loss: 1.7585817575454712
Batch 36/64 loss: 1.7587106227874756
Batch 37/64 loss: 1.7684980630874634
Batch 38/64 loss: 1.7648855447769165
Batch 39/64 loss: 1.7584640979766846
Batch 40/64 loss: 1.763296127319336
Batch 41/64 loss: 1.761959433555603
Batch 42/64 loss: 1.7602474689483643
Batch 43/64 loss: 1.7599260807037354
Batch 44/64 loss: 1.770052194595337
Batch 45/64 loss: 1.7551510334014893
Batch 46/64 loss: 1.7555155754089355
Batch 47/64 loss: 1.7594492435455322
Batch 48/64 loss: 1.7586829662322998
Batch 49/64 loss: 1.7610689401626587
Batch 50/64 loss: 1.75901198387146
Batch 51/64 loss: 1.7579988241195679
Batch 52/64 loss: 1.755990982055664
Batch 53/64 loss: 1.7530657052993774
Batch 54/64 loss: 1.7661995887756348
Batch 55/64 loss: 1.7547416687011719
Batch 56/64 loss: 1.7608428001403809
Batch 57/64 loss: 1.7615323066711426
Batch 58/64 loss: 1.7606338262557983
Batch 59/64 loss: 1.7784099578857422
Batch 60/64 loss: 1.7555749416351318
Batch 61/64 loss: 1.7570271492004395
Batch 62/64 loss: 1.75958251953125
Batch 63/64 loss: 1.7571463584899902
Batch 64/64 loss: 1.9597525596618652
Epoch 110  Train loss: 1.7636606366026635  Val loss: 1.781646264787392
Epoch 111
-------------------------------
Batch 1/64 loss: 1.764054298400879
Batch 2/64 loss: 1.7534046173095703
Batch 3/64 loss: 1.7629468441009521
Batch 4/64 loss: 1.759289026260376
Batch 5/64 loss: 1.7568838596343994
Batch 6/64 loss: 1.7641593217849731
Batch 7/64 loss: 1.7642382383346558
Batch 8/64 loss: 1.7625327110290527
Batch 9/64 loss: 1.7595815658569336
Batch 10/64 loss: 1.7589083909988403
Batch 11/64 loss: 1.7755523920059204
Batch 12/64 loss: 1.7557485103607178
Batch 13/64 loss: 1.758724570274353
Batch 14/64 loss: 1.759207010269165
Batch 15/64 loss: 1.7584218978881836
Batch 16/64 loss: 1.7542420625686646
Batch 17/64 loss: 1.7578576803207397
Batch 18/64 loss: 1.7628110647201538
Batch 19/64 loss: 1.7621078491210938
Batch 20/64 loss: 1.7620253562927246
Batch 21/64 loss: 1.758862018585205
Batch 22/64 loss: 1.7577638626098633
Batch 23/64 loss: 1.7561140060424805
Batch 24/64 loss: 1.7593828439712524
Batch 25/64 loss: 1.7620497941970825
Batch 26/64 loss: 1.767720103263855
Batch 27/64 loss: 1.7632685899734497
Batch 28/64 loss: 1.755983591079712
Batch 29/64 loss: 1.755551815032959
Batch 30/64 loss: 1.7621073722839355
Batch 31/64 loss: 1.7597392797470093
Batch 32/64 loss: 1.7562437057495117
Batch 33/64 loss: 1.7533973455429077
Batch 34/64 loss: 1.7694575786590576
Batch 35/64 loss: 1.7570455074310303
Batch 36/64 loss: 1.7571699619293213
Batch 37/64 loss: 1.7589497566223145
Batch 38/64 loss: 1.7555080652236938
Batch 39/64 loss: 1.7563368082046509
Batch 40/64 loss: 1.7621272802352905
Batch 41/64 loss: 1.7628426551818848
Batch 42/64 loss: 1.7590718269348145
Batch 43/64 loss: 1.7581236362457275
Batch 44/64 loss: 1.7581489086151123
Batch 45/64 loss: 1.756399393081665
Batch 46/64 loss: 1.7608642578125
Batch 47/64 loss: 1.7612762451171875
Batch 48/64 loss: 1.7544642686843872
Batch 49/64 loss: 1.7530628442764282
Batch 50/64 loss: 1.7610557079315186
Batch 51/64 loss: 1.76247239112854
Batch 52/64 loss: 1.757219910621643
Batch 53/64 loss: 1.7586772441864014
Batch 54/64 loss: 1.7582201957702637
Batch 55/64 loss: 1.758805274963379
Batch 56/64 loss: 1.7548253536224365
Batch 57/64 loss: 1.7573970556259155
Batch 58/64 loss: 1.759576439857483
Batch 59/64 loss: 1.7544028759002686
Batch 60/64 loss: 1.781052827835083
Batch 61/64 loss: 1.756103754043579
Batch 62/64 loss: 1.7589492797851562
Batch 63/64 loss: 1.769573450088501
Batch 64/64 loss: 1.9615118503570557
Epoch 111  Train loss: 1.7622148429646212  Val loss: 1.7784736451414442
Epoch 112
-------------------------------
Batch 1/64 loss: 1.7631860971450806
Batch 2/64 loss: 1.7590243816375732
Batch 3/64 loss: 1.758691668510437
Batch 4/64 loss: 1.755761981010437
Batch 5/64 loss: 1.7579281330108643
Batch 6/64 loss: 1.7574936151504517
Batch 7/64 loss: 1.7576904296875
Batch 8/64 loss: 1.7568295001983643
Batch 9/64 loss: 1.757919430732727
Batch 10/64 loss: 1.756887674331665
Batch 11/64 loss: 1.7596757411956787
Batch 12/64 loss: 1.7583866119384766
Batch 13/64 loss: 1.7608673572540283
Batch 14/64 loss: 1.753593921661377
Batch 15/64 loss: 1.7573752403259277
Batch 16/64 loss: 1.7544676065444946
Batch 17/64 loss: 1.7613228559494019
Batch 18/64 loss: 1.7717669010162354
Batch 19/64 loss: 1.7572870254516602
Batch 20/64 loss: 1.7621411085128784
Batch 21/64 loss: 1.7551965713500977
Batch 22/64 loss: 1.7647690773010254
Batch 23/64 loss: 1.7557566165924072
Batch 24/64 loss: 1.7566015720367432
Batch 25/64 loss: 1.7545948028564453
Batch 26/64 loss: 1.7582160234451294
Batch 27/64 loss: 1.7595652341842651
Batch 28/64 loss: 1.7640330791473389
Batch 29/64 loss: 1.7599618434906006
Batch 30/64 loss: 1.7576950788497925
Batch 31/64 loss: 1.7716469764709473
Batch 32/64 loss: 1.7548400163650513
Batch 33/64 loss: 1.755927562713623
Batch 34/64 loss: 1.7588882446289062
Batch 35/64 loss: 1.7572177648544312
Batch 36/64 loss: 1.7554292678833008
Batch 37/64 loss: 1.7569642066955566
Batch 38/64 loss: 1.7637324333190918
Batch 39/64 loss: 1.7670937776565552
Batch 40/64 loss: 1.7590014934539795
Batch 41/64 loss: 1.7584829330444336
Batch 42/64 loss: 1.7593425512313843
Batch 43/64 loss: 1.7569293975830078
Batch 44/64 loss: 1.7553319931030273
Batch 45/64 loss: 1.7707748413085938
Batch 46/64 loss: 1.7535325288772583
Batch 47/64 loss: 1.7589116096496582
Batch 48/64 loss: 1.771597981452942
Batch 49/64 loss: 1.7641791105270386
Batch 50/64 loss: 1.7584335803985596
Batch 51/64 loss: 1.7565988302230835
Batch 52/64 loss: 1.763033151626587
Batch 53/64 loss: 1.7581062316894531
Batch 54/64 loss: 1.7609823942184448
Batch 55/64 loss: 1.7607522010803223
Batch 56/64 loss: 1.7543370723724365
Batch 57/64 loss: 1.7566661834716797
Batch 58/64 loss: 1.755537986755371
Batch 59/64 loss: 1.7554235458374023
Batch 60/64 loss: 1.7568933963775635
Batch 61/64 loss: 1.7612473964691162
Batch 62/64 loss: 1.7606511116027832
Batch 63/64 loss: 1.7555463314056396
Batch 64/64 loss: 1.9584510326385498
Epoch 112  Train loss: 1.761530346028945  Val loss: 1.7771127232161583
Saving best model, epoch: 112
Epoch 113
-------------------------------
Batch 1/64 loss: 1.7573014497756958
Batch 2/64 loss: 1.7528934478759766
Batch 3/64 loss: 1.752977728843689
Batch 4/64 loss: 1.7546474933624268
Batch 5/64 loss: 1.756109595298767
Batch 6/64 loss: 1.7585870027542114
Batch 7/64 loss: 1.7561520338058472
Batch 8/64 loss: 1.754704236984253
Batch 9/64 loss: 1.7532325983047485
Batch 10/64 loss: 1.7603411674499512
Batch 11/64 loss: 1.7682589292526245
Batch 12/64 loss: 1.7618820667266846
Batch 13/64 loss: 1.7559723854064941
Batch 14/64 loss: 1.7617721557617188
Batch 15/64 loss: 1.7598282098770142
Batch 16/64 loss: 1.764207124710083
Batch 17/64 loss: 1.7555038928985596
Batch 18/64 loss: 1.753342866897583
Batch 19/64 loss: 1.7596412897109985
Batch 20/64 loss: 1.7602605819702148
Batch 21/64 loss: 1.754600167274475
Batch 22/64 loss: 1.7542275190353394
Batch 23/64 loss: 1.7566545009613037
Batch 24/64 loss: 1.7565529346466064
Batch 25/64 loss: 1.7626852989196777
Batch 26/64 loss: 1.7561043500900269
Batch 27/64 loss: 1.7612078189849854
Batch 28/64 loss: 1.7570408582687378
Batch 29/64 loss: 1.7558403015136719
Batch 30/64 loss: 1.7556450366973877
Batch 31/64 loss: 1.7571346759796143
Batch 32/64 loss: 1.7594578266143799
Batch 33/64 loss: 1.7557318210601807
Batch 34/64 loss: 1.757041573524475
Batch 35/64 loss: 1.776733160018921
Batch 36/64 loss: 1.7563239336013794
Batch 37/64 loss: 1.7534277439117432
Batch 38/64 loss: 1.7516335248947144
Batch 39/64 loss: 1.7553064823150635
Batch 40/64 loss: 1.7568098306655884
Batch 41/64 loss: 1.7603164911270142
Batch 42/64 loss: 1.7587604522705078
Batch 43/64 loss: 1.7540874481201172
Batch 44/64 loss: 1.755603313446045
Batch 45/64 loss: 1.7558907270431519
Batch 46/64 loss: 1.7555357217788696
Batch 47/64 loss: 1.7564857006072998
Batch 48/64 loss: 1.7575969696044922
Batch 49/64 loss: 1.7661912441253662
Batch 50/64 loss: 1.764301061630249
Batch 51/64 loss: 1.7656877040863037
Batch 52/64 loss: 1.757036805152893
Batch 53/64 loss: 1.7592724561691284
Batch 54/64 loss: 1.7560940980911255
Batch 55/64 loss: 1.7579681873321533
Batch 56/64 loss: 1.7594494819641113
Batch 57/64 loss: 1.7600154876708984
Batch 58/64 loss: 1.7552341222763062
Batch 59/64 loss: 1.756068229675293
Batch 60/64 loss: 1.7568814754486084
Batch 61/64 loss: 1.7538660764694214
Batch 62/64 loss: 1.7604420185089111
Batch 63/64 loss: 1.7542906999588013
Batch 64/64 loss: 1.9547799825668335
Epoch 113  Train loss: 1.7601715541353413  Val loss: 1.7744148490355187
Saving best model, epoch: 113
Epoch 114
-------------------------------
Batch 1/64 loss: 1.7561545372009277
Batch 2/64 loss: 1.7566531896591187
Batch 3/64 loss: 1.7561157941818237
Batch 4/64 loss: 1.757004737854004
Batch 5/64 loss: 1.7586802244186401
Batch 6/64 loss: 1.7536507844924927
Batch 7/64 loss: 1.7581995725631714
Batch 8/64 loss: 1.770690679550171
Batch 9/64 loss: 1.7543017864227295
Batch 10/64 loss: 1.756702184677124
Batch 11/64 loss: 1.7570476531982422
Batch 12/64 loss: 1.7591429948806763
Batch 13/64 loss: 1.7604008913040161
Batch 14/64 loss: 1.758705496788025
Batch 15/64 loss: 1.76136314868927
Batch 16/64 loss: 1.7526769638061523
Batch 17/64 loss: 1.76406991481781
Batch 18/64 loss: 1.755252718925476
Batch 19/64 loss: 1.7628182172775269
Batch 20/64 loss: 1.75748610496521
Batch 21/64 loss: 1.7566120624542236
Batch 22/64 loss: 1.759141445159912
Batch 23/64 loss: 1.7663235664367676
Batch 24/64 loss: 1.753873348236084
Batch 25/64 loss: 1.7554110288619995
Batch 26/64 loss: 1.7554913759231567
Batch 27/64 loss: 1.7562874555587769
Batch 28/64 loss: 1.754313349723816
Batch 29/64 loss: 1.7525173425674438
Batch 30/64 loss: 1.762235403060913
Batch 31/64 loss: 1.75799560546875
Batch 32/64 loss: 1.7660374641418457
Batch 33/64 loss: 1.7563592195510864
Batch 34/64 loss: 1.7556407451629639
Batch 35/64 loss: 1.756552815437317
Batch 36/64 loss: 1.758164405822754
Batch 37/64 loss: 1.7584081888198853
Batch 38/64 loss: 1.7746102809906006
Batch 39/64 loss: 1.76337468624115
Batch 40/64 loss: 1.7558215856552124
Batch 41/64 loss: 1.7569119930267334
Batch 42/64 loss: 1.767583966255188
Batch 43/64 loss: 1.764327049255371
Batch 44/64 loss: 1.7598226070404053
Batch 45/64 loss: 1.7611795663833618
Batch 46/64 loss: 1.762208342552185
Batch 47/64 loss: 1.7621300220489502
Batch 48/64 loss: 1.7582635879516602
Batch 49/64 loss: 1.7583580017089844
Batch 50/64 loss: 1.7585604190826416
Batch 51/64 loss: 1.7595689296722412
Batch 52/64 loss: 1.7606557607650757
Batch 53/64 loss: 1.760591983795166
Batch 54/64 loss: 1.7605390548706055
Batch 55/64 loss: 1.7627719640731812
Batch 56/64 loss: 1.7585442066192627
Batch 57/64 loss: 1.7581937313079834
Batch 58/64 loss: 1.7560709714889526
Batch 59/64 loss: 1.75568425655365
Batch 60/64 loss: 1.7554819583892822
Batch 61/64 loss: 1.7580150365829468
Batch 62/64 loss: 1.7532416582107544
Batch 63/64 loss: 1.756813406944275
Batch 64/64 loss: 1.960493803024292
Epoch 114  Train loss: 1.761226318396774  Val loss: 1.777717737807441
Epoch 115
-------------------------------
Batch 1/64 loss: 1.7566124200820923
Batch 2/64 loss: 1.7546864748001099
Batch 3/64 loss: 1.7550641298294067
Batch 4/64 loss: 1.7562854290008545
Batch 5/64 loss: 1.7574952840805054
Batch 6/64 loss: 1.7540509700775146
Batch 7/64 loss: 1.7568049430847168
Batch 8/64 loss: 1.7604742050170898
Batch 9/64 loss: 1.7560817003250122
Batch 10/64 loss: 1.7646406888961792
Batch 11/64 loss: 1.7564365863800049
Batch 12/64 loss: 1.7574454545974731
Batch 13/64 loss: 1.756899118423462
Batch 14/64 loss: 1.7569268941879272
Batch 15/64 loss: 1.758169412612915
Batch 16/64 loss: 1.7573527097702026
Batch 17/64 loss: 1.7574608325958252
Batch 18/64 loss: 1.7617642879486084
Batch 19/64 loss: 1.7568624019622803
Batch 20/64 loss: 1.7577919960021973
Batch 21/64 loss: 1.7562652826309204
Batch 22/64 loss: 1.7626551389694214
Batch 23/64 loss: 1.7543140649795532
Batch 24/64 loss: 1.7556450366973877
Batch 25/64 loss: 1.7587945461273193
Batch 26/64 loss: 1.7535761594772339
Batch 27/64 loss: 1.7534091472625732
Batch 28/64 loss: 1.7566865682601929
Batch 29/64 loss: 1.755418300628662
Batch 30/64 loss: 1.759035587310791
Batch 31/64 loss: 1.7536264657974243
Batch 32/64 loss: 1.7561142444610596
Batch 33/64 loss: 1.7578883171081543
Batch 34/64 loss: 1.7582581043243408
Batch 35/64 loss: 1.7539054155349731
Batch 36/64 loss: 1.7564661502838135
Batch 37/64 loss: 1.7539381980895996
Batch 38/64 loss: 1.7571018934249878
Batch 39/64 loss: 1.7645049095153809
Batch 40/64 loss: 1.7556395530700684
Batch 41/64 loss: 1.7567353248596191
Batch 42/64 loss: 1.7541558742523193
Batch 43/64 loss: 1.7544283866882324
Batch 44/64 loss: 1.7596533298492432
Batch 45/64 loss: 1.7554184198379517
Batch 46/64 loss: 1.7600131034851074
Batch 47/64 loss: 1.7548704147338867
Batch 48/64 loss: 1.7597134113311768
Batch 49/64 loss: 1.7586556673049927
Batch 50/64 loss: 1.7564711570739746
Batch 51/64 loss: 1.7702271938323975
Batch 52/64 loss: 1.7620166540145874
Batch 53/64 loss: 1.7558929920196533
Batch 54/64 loss: 1.7627977132797241
Batch 55/64 loss: 1.7580060958862305
Batch 56/64 loss: 1.7565183639526367
Batch 57/64 loss: 1.7660784721374512
Batch 58/64 loss: 1.7762150764465332
Batch 59/64 loss: 1.7611082792282104
Batch 60/64 loss: 1.7555437088012695
Batch 61/64 loss: 1.7743935585021973
Batch 62/64 loss: 1.761368989944458
Batch 63/64 loss: 1.7572028636932373
Batch 64/64 loss: 1.9628322124481201
Epoch 115  Train loss: 1.7606613056332456  Val loss: 1.7808630777798158
Epoch 116
-------------------------------
Batch 1/64 loss: 1.7585413455963135
Batch 2/64 loss: 1.7616603374481201
Batch 3/64 loss: 1.7612550258636475
Batch 4/64 loss: 1.7664783000946045
Batch 5/64 loss: 1.7577354907989502
Batch 6/64 loss: 1.7561554908752441
Batch 7/64 loss: 1.7711011171340942
Batch 8/64 loss: 1.755305290222168
Batch 9/64 loss: 1.7636072635650635
Batch 10/64 loss: 1.7531299591064453
Batch 11/64 loss: 1.7551944255828857
Batch 12/64 loss: 1.7570841312408447
Batch 13/64 loss: 1.758782148361206
Batch 14/64 loss: 1.757069706916809
Batch 15/64 loss: 1.758494257926941
Batch 16/64 loss: 1.7526369094848633
Batch 17/64 loss: 1.7575982809066772
Batch 18/64 loss: 1.759070873260498
Batch 19/64 loss: 1.7661091089248657
Batch 20/64 loss: 1.7704529762268066
Batch 21/64 loss: 1.7650949954986572
Batch 22/64 loss: 1.7579452991485596
Batch 23/64 loss: 1.7550779581069946
Batch 24/64 loss: 1.7589201927185059
Batch 25/64 loss: 1.7588708400726318
Batch 26/64 loss: 1.7585911750793457
Batch 27/64 loss: 1.7693371772766113
Batch 28/64 loss: 1.7574422359466553
Batch 29/64 loss: 1.7641619443893433
Batch 30/64 loss: 1.760430097579956
Batch 31/64 loss: 1.7566025257110596
Batch 32/64 loss: 1.7563914060592651
Batch 33/64 loss: 1.756998062133789
Batch 34/64 loss: 1.7544865608215332
Batch 35/64 loss: 1.7547789812088013
Batch 36/64 loss: 1.754051685333252
Batch 37/64 loss: 1.7557917833328247
Batch 38/64 loss: 1.7556169033050537
Batch 39/64 loss: 1.7516366243362427
Batch 40/64 loss: 1.7549245357513428
Batch 41/64 loss: 1.7535548210144043
Batch 42/64 loss: 1.758833646774292
Batch 43/64 loss: 1.7545515298843384
Batch 44/64 loss: 1.7550431489944458
Batch 45/64 loss: 1.7577793598175049
Batch 46/64 loss: 1.7599176168441772
Batch 47/64 loss: 1.757235050201416
Batch 48/64 loss: 1.7582473754882812
Batch 49/64 loss: 1.765459656715393
Batch 50/64 loss: 1.7594600915908813
Batch 51/64 loss: 1.7619166374206543
Batch 52/64 loss: 1.7671537399291992
Batch 53/64 loss: 1.7583506107330322
Batch 54/64 loss: 1.7578246593475342
Batch 55/64 loss: 1.755199909210205
Batch 56/64 loss: 1.7581877708435059
Batch 57/64 loss: 1.7566813230514526
Batch 58/64 loss: 1.757423758506775
Batch 59/64 loss: 1.7563211917877197
Batch 60/64 loss: 1.759385108947754
Batch 61/64 loss: 1.7561308145523071
Batch 62/64 loss: 1.7572698593139648
Batch 63/64 loss: 1.759392261505127
Batch 64/64 loss: 1.960095763206482
Epoch 116  Train loss: 1.7610353755015953  Val loss: 1.7838044166564941
Epoch 117
-------------------------------
Batch 1/64 loss: 1.756290078163147
Batch 2/64 loss: 1.7619516849517822
Batch 3/64 loss: 1.7559551000595093
Batch 4/64 loss: 1.7564414739608765
Batch 5/64 loss: 1.7524802684783936
Batch 6/64 loss: 1.7536795139312744
Batch 7/64 loss: 1.7569864988327026
Batch 8/64 loss: 1.7736176252365112
Batch 9/64 loss: 1.762678861618042
Batch 10/64 loss: 1.7616369724273682
Batch 11/64 loss: 1.7784653902053833
Batch 12/64 loss: 1.7606019973754883
Batch 13/64 loss: 1.7648217678070068
Batch 14/64 loss: 1.7591674327850342
Batch 15/64 loss: 1.7580164670944214
Batch 16/64 loss: 1.7573697566986084
Batch 17/64 loss: 1.754991054534912
Batch 18/64 loss: 1.7587357759475708
Batch 19/64 loss: 1.7593774795532227
Batch 20/64 loss: 1.7564356327056885
Batch 21/64 loss: 1.756425380706787
Batch 22/64 loss: 1.7620649337768555
Batch 23/64 loss: 1.7612476348876953
Batch 24/64 loss: 1.7563272714614868
Batch 25/64 loss: 1.756369948387146
Batch 26/64 loss: 1.7548837661743164
Batch 27/64 loss: 1.7616249322891235
Batch 28/64 loss: 1.7568186521530151
Batch 29/64 loss: 1.7802040576934814
Batch 30/64 loss: 1.7606204748153687
Batch 31/64 loss: 1.757521152496338
Batch 32/64 loss: 1.7571810483932495
Batch 33/64 loss: 1.758087396621704
Batch 34/64 loss: 1.7556469440460205
Batch 35/64 loss: 1.762195110321045
Batch 36/64 loss: 1.7666499614715576
Batch 37/64 loss: 1.7680386304855347
Batch 38/64 loss: 1.7600898742675781
Batch 39/64 loss: 1.757333517074585
Batch 40/64 loss: 1.7545537948608398
Batch 41/64 loss: 1.7614941596984863
Batch 42/64 loss: 1.7568349838256836
Batch 43/64 loss: 1.758914589881897
Batch 44/64 loss: 1.7624807357788086
Batch 45/64 loss: 1.7586402893066406
Batch 46/64 loss: 1.7585062980651855
Batch 47/64 loss: 1.758165955543518
Batch 48/64 loss: 1.7687691450119019
Batch 49/64 loss: 1.7567615509033203
Batch 50/64 loss: 1.763274908065796
Batch 51/64 loss: 1.7620972394943237
Batch 52/64 loss: 1.7590305805206299
Batch 53/64 loss: 1.7705700397491455
Batch 54/64 loss: 1.7649686336517334
Batch 55/64 loss: 1.758626103401184
Batch 56/64 loss: 1.7676727771759033
Batch 57/64 loss: 1.7554733753204346
Batch 58/64 loss: 1.7619520425796509
Batch 59/64 loss: 1.7653471231460571
Batch 60/64 loss: 1.7778303623199463
Batch 61/64 loss: 1.761322259902954
Batch 62/64 loss: 1.7688853740692139
Batch 63/64 loss: 1.7653026580810547
Batch 64/64 loss: 1.9720247983932495
Epoch 117  Train loss: 1.7635376486123777  Val loss: 1.779827346506807
Epoch 118
-------------------------------
Batch 1/64 loss: 1.759437084197998
Batch 2/64 loss: 1.7775473594665527
Batch 3/64 loss: 1.7599595785140991
Batch 4/64 loss: 1.7570641040802002
Batch 5/64 loss: 1.7584881782531738
Batch 6/64 loss: 1.7607059478759766
Batch 7/64 loss: 1.7652897834777832
Batch 8/64 loss: 1.759918212890625
Batch 9/64 loss: 1.7625398635864258
Batch 10/64 loss: 1.7630155086517334
Batch 11/64 loss: 1.7589149475097656
Batch 12/64 loss: 1.7676485776901245
Batch 13/64 loss: 1.7661638259887695
Batch 14/64 loss: 1.761411428451538
Batch 15/64 loss: 1.7673592567443848
Batch 16/64 loss: 1.7579320669174194
Batch 17/64 loss: 1.7580296993255615
Batch 18/64 loss: 1.7622946500778198
Batch 19/64 loss: 1.7578660249710083
Batch 20/64 loss: 1.7762418985366821
Batch 21/64 loss: 1.7603473663330078
Batch 22/64 loss: 1.757961630821228
Batch 23/64 loss: 1.7604204416275024
Batch 24/64 loss: 1.7602086067199707
Batch 25/64 loss: 1.7559411525726318
Batch 26/64 loss: 1.7596807479858398
Batch 27/64 loss: 1.7576326131820679
Batch 28/64 loss: 1.7565512657165527
Batch 29/64 loss: 1.7563600540161133
Batch 30/64 loss: 1.7589564323425293
Batch 31/64 loss: 1.7537767887115479
Batch 32/64 loss: 1.7573024034500122
Batch 33/64 loss: 1.7529551982879639
Batch 34/64 loss: 1.7540284395217896
Batch 35/64 loss: 1.7564523220062256
Batch 36/64 loss: 1.756389856338501
Batch 37/64 loss: 1.761691927909851
Batch 38/64 loss: 1.7545976638793945
Batch 39/64 loss: 1.7548965215682983
Batch 40/64 loss: 1.7580323219299316
Batch 41/64 loss: 1.7572598457336426
Batch 42/64 loss: 1.755923867225647
Batch 43/64 loss: 1.7561516761779785
Batch 44/64 loss: 1.753701090812683
Batch 45/64 loss: 1.7541630268096924
Batch 46/64 loss: 1.7546584606170654
Batch 47/64 loss: 1.7529592514038086
Batch 48/64 loss: 1.7579991817474365
Batch 49/64 loss: 1.758051872253418
Batch 50/64 loss: 1.7541708946228027
Batch 51/64 loss: 1.7563239336013794
Batch 52/64 loss: 1.7720441818237305
Batch 53/64 loss: 1.7534575462341309
Batch 54/64 loss: 1.7532603740692139
Batch 55/64 loss: 1.7677491903305054
Batch 56/64 loss: 1.7559529542922974
Batch 57/64 loss: 1.7570126056671143
Batch 58/64 loss: 1.7569308280944824
Batch 59/64 loss: 1.7523884773254395
Batch 60/64 loss: 1.755911946296692
Batch 61/64 loss: 1.755201816558838
Batch 62/64 loss: 1.7537225484848022
Batch 63/64 loss: 1.7570757865905762
Batch 64/64 loss: 1.9559247493743896
Epoch 118  Train loss: 1.7611141438577689  Val loss: 1.7757886857101597
Epoch 119
-------------------------------
Batch 1/64 loss: 1.7548820972442627
Batch 2/64 loss: 1.7571879625320435
Batch 3/64 loss: 1.754353404045105
Batch 4/64 loss: 1.7547392845153809
Batch 5/64 loss: 1.753408432006836
Batch 6/64 loss: 1.758505940437317
Batch 7/64 loss: 1.7551765441894531
Batch 8/64 loss: 1.758157730102539
Batch 9/64 loss: 1.7583138942718506
Batch 10/64 loss: 1.7586621046066284
Batch 11/64 loss: 1.757568597793579
Batch 12/64 loss: 1.755264163017273
Batch 13/64 loss: 1.7545932531356812
Batch 14/64 loss: 1.7703800201416016
Batch 15/64 loss: 1.7535890340805054
Batch 16/64 loss: 1.7537600994110107
Batch 17/64 loss: 1.751906394958496
Batch 18/64 loss: 1.759379267692566
Batch 19/64 loss: 1.7533679008483887
Batch 20/64 loss: 1.7543303966522217
Batch 21/64 loss: 1.7552672624588013
Batch 22/64 loss: 1.7514710426330566
Batch 23/64 loss: 1.7661501169204712
Batch 24/64 loss: 1.7554218769073486
Batch 25/64 loss: 1.7574678659439087
Batch 26/64 loss: 1.772265076637268
Batch 27/64 loss: 1.7669070959091187
Batch 28/64 loss: 1.7610969543457031
Batch 29/64 loss: 1.7623831033706665
Batch 30/64 loss: 1.7529672384262085
Batch 31/64 loss: 1.756919026374817
Batch 32/64 loss: 1.7566770315170288
Batch 33/64 loss: 1.7586497068405151
Batch 34/64 loss: 1.7564480304718018
Batch 35/64 loss: 1.7580235004425049
Batch 36/64 loss: 1.752665400505066
Batch 37/64 loss: 1.75641667842865
Batch 38/64 loss: 1.7610201835632324
Batch 39/64 loss: 1.7543034553527832
Batch 40/64 loss: 1.7513504028320312
Batch 41/64 loss: 1.7568519115447998
Batch 42/64 loss: 1.7544240951538086
Batch 43/64 loss: 1.7527432441711426
Batch 44/64 loss: 1.7615333795547485
Batch 45/64 loss: 1.7532410621643066
Batch 46/64 loss: 1.7579584121704102
Batch 47/64 loss: 1.754073977470398
Batch 48/64 loss: 1.7545607089996338
Batch 49/64 loss: 1.7511513233184814
Batch 50/64 loss: 1.7533941268920898
Batch 51/64 loss: 1.7566741704940796
Batch 52/64 loss: 1.7554486989974976
Batch 53/64 loss: 1.7551839351654053
Batch 54/64 loss: 1.7569308280944824
Batch 55/64 loss: 1.7560805082321167
Batch 56/64 loss: 1.7586268186569214
Batch 57/64 loss: 1.755863904953003
Batch 58/64 loss: 1.7602788209915161
Batch 59/64 loss: 1.756021499633789
Batch 60/64 loss: 1.7536365985870361
Batch 61/64 loss: 1.7608084678649902
Batch 62/64 loss: 1.758215069770813
Batch 63/64 loss: 1.7675639390945435
Batch 64/64 loss: 1.951521396636963
Epoch 119  Train loss: 1.7593145744473326  Val loss: 1.7764416773294665
Epoch 120
-------------------------------
Batch 1/64 loss: 1.7565208673477173
Batch 2/64 loss: 1.756223440170288
Batch 3/64 loss: 1.7537815570831299
Batch 4/64 loss: 1.7523634433746338
Batch 5/64 loss: 1.7709327936172485
Batch 6/64 loss: 1.7543256282806396
Batch 7/64 loss: 1.7555279731750488
Batch 8/64 loss: 1.7548232078552246
Batch 9/64 loss: 1.7601964473724365
Batch 10/64 loss: 1.7601194381713867
Batch 11/64 loss: 1.756725549697876
Batch 12/64 loss: 1.7538429498672485
Batch 13/64 loss: 1.7533576488494873
Batch 14/64 loss: 1.7534737586975098
Batch 15/64 loss: 1.7554447650909424
Batch 16/64 loss: 1.752854347229004
Batch 17/64 loss: 1.7542893886566162
Batch 18/64 loss: 1.7549444437026978
Batch 19/64 loss: 1.753429651260376
Batch 20/64 loss: 1.7570738792419434
Batch 21/64 loss: 1.7577542066574097
Batch 22/64 loss: 1.7668401002883911
Batch 23/64 loss: 1.7548993825912476
Batch 24/64 loss: 1.7568881511688232
Batch 25/64 loss: 1.7595502138137817
Batch 26/64 loss: 1.7725954055786133
Batch 27/64 loss: 1.7629646062850952
Batch 28/64 loss: 1.759178638458252
Batch 29/64 loss: 1.7530908584594727
Batch 30/64 loss: 1.755761981010437
Batch 31/64 loss: 1.7508021593093872
Batch 32/64 loss: 1.754044532775879
Batch 33/64 loss: 1.7535055875778198
Batch 34/64 loss: 1.7560585737228394
Batch 35/64 loss: 1.7560486793518066
Batch 36/64 loss: 1.755149006843567
Batch 37/64 loss: 1.7548798322677612
Batch 38/64 loss: 1.7544856071472168
Batch 39/64 loss: 1.7526452541351318
Batch 40/64 loss: 1.753868579864502
Batch 41/64 loss: 1.754415512084961
Batch 42/64 loss: 1.7543373107910156
Batch 43/64 loss: 1.753983497619629
Batch 44/64 loss: 1.7506992816925049
Batch 45/64 loss: 1.7585644721984863
Batch 46/64 loss: 1.7578155994415283
Batch 47/64 loss: 1.753645420074463
Batch 48/64 loss: 1.7547821998596191
Batch 49/64 loss: 1.7498418092727661
Batch 50/64 loss: 1.7524223327636719
Batch 51/64 loss: 1.7556668519973755
Batch 52/64 loss: 1.75314199924469
Batch 53/64 loss: 1.7595949172973633
Batch 54/64 loss: 1.7558012008666992
Batch 55/64 loss: 1.757591724395752
Batch 56/64 loss: 1.7689687013626099
Batch 57/64 loss: 1.7519906759262085
Batch 58/64 loss: 1.7568672895431519
Batch 59/64 loss: 1.7543033361434937
Batch 60/64 loss: 1.753370761871338
Batch 61/64 loss: 1.7549185752868652
Batch 62/64 loss: 1.7517555952072144
Batch 63/64 loss: 1.753609538078308
Batch 64/64 loss: 1.954714298248291
Epoch 120  Train loss: 1.7583590096118404  Val loss: 1.7778243363108421
Epoch 121
-------------------------------
Batch 1/64 loss: 1.7549870014190674
Batch 2/64 loss: 1.7537833452224731
Batch 3/64 loss: 1.7550560235977173
Batch 4/64 loss: 1.7575552463531494
Batch 5/64 loss: 1.7582204341888428
Batch 6/64 loss: 1.7560129165649414
Batch 7/64 loss: 1.7573397159576416
Batch 8/64 loss: 1.7550537586212158
Batch 9/64 loss: 1.7587226629257202
Batch 10/64 loss: 1.755457878112793
Batch 11/64 loss: 1.7562358379364014
Batch 12/64 loss: 1.7536004781723022
Batch 13/64 loss: 1.7528643608093262
Batch 14/64 loss: 1.759267807006836
Batch 15/64 loss: 1.7526521682739258
Batch 16/64 loss: 1.7570466995239258
Batch 17/64 loss: 1.7573788166046143
Batch 18/64 loss: 1.755600929260254
Batch 19/64 loss: 1.7582478523254395
Batch 20/64 loss: 1.755513072013855
Batch 21/64 loss: 1.7530733346939087
Batch 22/64 loss: 1.7586994171142578
Batch 23/64 loss: 1.7527238130569458
Batch 24/64 loss: 1.7544465065002441
Batch 25/64 loss: 1.7659649848937988
Batch 26/64 loss: 1.754130482673645
Batch 27/64 loss: 1.7554481029510498
Batch 28/64 loss: 1.7587077617645264
Batch 29/64 loss: 1.7536855936050415
Batch 30/64 loss: 1.760411262512207
Batch 31/64 loss: 1.7543385028839111
Batch 32/64 loss: 1.7542355060577393
Batch 33/64 loss: 1.7528877258300781
Batch 34/64 loss: 1.7528479099273682
Batch 35/64 loss: 1.7565470933914185
Batch 36/64 loss: 1.751589298248291
Batch 37/64 loss: 1.75270676612854
Batch 38/64 loss: 1.7534712553024292
Batch 39/64 loss: 1.7533600330352783
Batch 40/64 loss: 1.756018877029419
Batch 41/64 loss: 1.7532427310943604
Batch 42/64 loss: 1.7545192241668701
Batch 43/64 loss: 1.7581055164337158
Batch 44/64 loss: 1.753564476966858
Batch 45/64 loss: 1.7519354820251465
Batch 46/64 loss: 1.7542684078216553
Batch 47/64 loss: 1.7519772052764893
Batch 48/64 loss: 1.7579134702682495
Batch 49/64 loss: 1.7560997009277344
Batch 50/64 loss: 1.7589244842529297
Batch 51/64 loss: 1.7563594579696655
Batch 52/64 loss: 1.7549227476119995
Batch 53/64 loss: 1.7569737434387207
Batch 54/64 loss: 1.7513389587402344
Batch 55/64 loss: 1.7680326700210571
Batch 56/64 loss: 1.7566328048706055
Batch 57/64 loss: 1.757703423500061
Batch 58/64 loss: 1.7558801174163818
Batch 59/64 loss: 1.7731709480285645
Batch 60/64 loss: 1.7560608386993408
Batch 61/64 loss: 1.7580167055130005
Batch 62/64 loss: 1.7626888751983643
Batch 63/64 loss: 1.7558650970458984
Batch 64/64 loss: 1.9565149545669556
Epoch 121  Train loss: 1.7585486201679006  Val loss: 1.7765126195560206
Epoch 122
-------------------------------
Batch 1/64 loss: 1.7540346384048462
Batch 2/64 loss: 1.751876950263977
Batch 3/64 loss: 1.7605969905853271
Batch 4/64 loss: 1.7554270029067993
Batch 5/64 loss: 1.7603859901428223
Batch 6/64 loss: 1.7572112083435059
Batch 7/64 loss: 1.757279396057129
Batch 8/64 loss: 1.7542839050292969
Batch 9/64 loss: 1.7557971477508545
Batch 10/64 loss: 1.752306580543518
Batch 11/64 loss: 1.7555283308029175
Batch 12/64 loss: 1.7528401613235474
Batch 13/64 loss: 1.7519432306289673
Batch 14/64 loss: 1.7520651817321777
Batch 15/64 loss: 1.7594211101531982
Batch 16/64 loss: 1.7532455921173096
Batch 17/64 loss: 1.7575379610061646
Batch 18/64 loss: 1.755190372467041
Batch 19/64 loss: 1.755252480506897
Batch 20/64 loss: 1.753717064857483
Batch 21/64 loss: 1.7538390159606934
Batch 22/64 loss: 1.758225917816162
Batch 23/64 loss: 1.7567559480667114
Batch 24/64 loss: 1.7746710777282715
Batch 25/64 loss: 1.7739477157592773
Batch 26/64 loss: 1.7537078857421875
Batch 27/64 loss: 1.7609996795654297
Batch 28/64 loss: 1.75582754611969
Batch 29/64 loss: 1.7518796920776367
Batch 30/64 loss: 1.7592099905014038
Batch 31/64 loss: 1.7572777271270752
Batch 32/64 loss: 1.7532966136932373
Batch 33/64 loss: 1.7780367136001587
Batch 34/64 loss: 1.7671915292739868
Batch 35/64 loss: 1.7558623552322388
Batch 36/64 loss: 1.7589138746261597
Batch 37/64 loss: 1.7516326904296875
Batch 38/64 loss: 1.7553473711013794
Batch 39/64 loss: 1.7541451454162598
Batch 40/64 loss: 1.752899408340454
Batch 41/64 loss: 1.7549046277999878
Batch 42/64 loss: 1.76070237159729
Batch 43/64 loss: 1.7554585933685303
Batch 44/64 loss: 1.7517980337142944
Batch 45/64 loss: 1.755640983581543
Batch 46/64 loss: 1.7594611644744873
Batch 47/64 loss: 1.754730224609375
Batch 48/64 loss: 1.75376558303833
Batch 49/64 loss: 1.753441333770752
Batch 50/64 loss: 1.7563998699188232
Batch 51/64 loss: 1.7548747062683105
Batch 52/64 loss: 1.7556180953979492
Batch 53/64 loss: 1.7580758333206177
Batch 54/64 loss: 1.7559306621551514
Batch 55/64 loss: 1.751105546951294
Batch 56/64 loss: 1.7521302700042725
Batch 57/64 loss: 1.7529680728912354
Batch 58/64 loss: 1.7540903091430664
Batch 59/64 loss: 1.7505943775177002
Batch 60/64 loss: 1.7508318424224854
Batch 61/64 loss: 1.7588632106781006
Batch 62/64 loss: 1.7545892000198364
Batch 63/64 loss: 1.755624532699585
Batch 64/64 loss: 1.9539278745651245
Epoch 122  Train loss: 1.7586926203148037  Val loss: 1.7796023653954576
Epoch 123
-------------------------------
Batch 1/64 loss: 1.753313660621643
Batch 2/64 loss: 1.7571648359298706
Batch 3/64 loss: 1.756369948387146
Batch 4/64 loss: 1.7584253549575806
Batch 5/64 loss: 1.757920742034912
Batch 6/64 loss: 1.7540698051452637
Batch 7/64 loss: 1.7633378505706787
Batch 8/64 loss: 1.7552207708358765
Batch 9/64 loss: 1.7543680667877197
Batch 10/64 loss: 1.7508723735809326
Batch 11/64 loss: 1.7600083351135254
Batch 12/64 loss: 1.759305477142334
Batch 13/64 loss: 1.7594362497329712
Batch 14/64 loss: 1.752220630645752
Batch 15/64 loss: 1.7670378684997559
Batch 16/64 loss: 1.75791597366333
Batch 17/64 loss: 1.7564022541046143
Batch 18/64 loss: 1.7564852237701416
Batch 19/64 loss: 1.755345344543457
Batch 20/64 loss: 1.7585151195526123
Batch 21/64 loss: 1.7534048557281494
Batch 22/64 loss: 1.7558770179748535
Batch 23/64 loss: 1.7534751892089844
Batch 24/64 loss: 1.7559993267059326
Batch 25/64 loss: 1.7532341480255127
Batch 26/64 loss: 1.7554851770401
Batch 27/64 loss: 1.752289056777954
Batch 28/64 loss: 1.7566944360733032
Batch 29/64 loss: 1.7532626390457153
Batch 30/64 loss: 1.754110336303711
Batch 31/64 loss: 1.7710217237472534
Batch 32/64 loss: 1.7598299980163574
Batch 33/64 loss: 1.7571351528167725
Batch 34/64 loss: 1.754884123802185
Batch 35/64 loss: 1.7541403770446777
Batch 36/64 loss: 1.7536224126815796
Batch 37/64 loss: 1.7555294036865234
Batch 38/64 loss: 1.7523906230926514
Batch 39/64 loss: 1.754359245300293
Batch 40/64 loss: 1.7567027807235718
Batch 41/64 loss: 1.7534092664718628
Batch 42/64 loss: 1.7539360523223877
Batch 43/64 loss: 1.758053183555603
Batch 44/64 loss: 1.7559415102005005
Batch 45/64 loss: 1.760786533355713
Batch 46/64 loss: 1.7510274648666382
Batch 47/64 loss: 1.756608009338379
Batch 48/64 loss: 1.756730079650879
Batch 49/64 loss: 1.7571980953216553
Batch 50/64 loss: 1.7536303997039795
Batch 51/64 loss: 1.7566535472869873
Batch 52/64 loss: 1.7561817169189453
Batch 53/64 loss: 1.756024956703186
Batch 54/64 loss: 1.7514922618865967
Batch 55/64 loss: 1.7554500102996826
Batch 56/64 loss: 1.7578823566436768
Batch 57/64 loss: 1.754198670387268
Batch 58/64 loss: 1.7586331367492676
Batch 59/64 loss: 1.7571511268615723
Batch 60/64 loss: 1.7606675624847412
Batch 61/64 loss: 1.7698460817337036
Batch 62/64 loss: 1.757148027420044
Batch 63/64 loss: 1.7573864459991455
Batch 64/64 loss: 1.9670850038528442
Epoch 123  Train loss: 1.7590358299367568  Val loss: 1.7805815881879878
Epoch 124
-------------------------------
Batch 1/64 loss: 1.7545077800750732
Batch 2/64 loss: 1.752524495124817
Batch 3/64 loss: 1.754515528678894
Batch 4/64 loss: 1.7571728229522705
Batch 5/64 loss: 1.752910852432251
Batch 6/64 loss: 1.7551937103271484
Batch 7/64 loss: 1.7540066242218018
Batch 8/64 loss: 1.7536545991897583
Batch 9/64 loss: 1.7570089101791382
Batch 10/64 loss: 1.755159616470337
Batch 11/64 loss: 1.7521445751190186
Batch 12/64 loss: 1.7560374736785889
Batch 13/64 loss: 1.7531712055206299
Batch 14/64 loss: 1.7620588541030884
Batch 15/64 loss: 1.7528856992721558
Batch 16/64 loss: 1.7555679082870483
Batch 17/64 loss: 1.7522850036621094
Batch 18/64 loss: 1.755020022392273
Batch 19/64 loss: 1.7564066648483276
Batch 20/64 loss: 1.7576076984405518
Batch 21/64 loss: 1.766071081161499
Batch 22/64 loss: 1.7578272819519043
Batch 23/64 loss: 1.7592873573303223
Batch 24/64 loss: 1.7600020170211792
Batch 25/64 loss: 1.7546424865722656
Batch 26/64 loss: 1.7524361610412598
Batch 27/64 loss: 1.758745551109314
Batch 28/64 loss: 1.7539702653884888
Batch 29/64 loss: 1.7537689208984375
Batch 30/64 loss: 1.7567377090454102
Batch 31/64 loss: 1.7583562135696411
Batch 32/64 loss: 1.7593679428100586
Batch 33/64 loss: 1.7562233209609985
Batch 34/64 loss: 1.7544615268707275
Batch 35/64 loss: 1.7685085535049438
Batch 36/64 loss: 1.7552390098571777
Batch 37/64 loss: 1.7581604719161987
Batch 38/64 loss: 1.7530572414398193
Batch 39/64 loss: 1.7556335926055908
Batch 40/64 loss: 1.7551836967468262
Batch 41/64 loss: 1.764723300933838
Batch 42/64 loss: 1.7801001071929932
Batch 43/64 loss: 1.7596917152404785
Batch 44/64 loss: 1.7582275867462158
Batch 45/64 loss: 1.7592177391052246
Batch 46/64 loss: 1.760791540145874
Batch 47/64 loss: 1.7555204629898071
Batch 48/64 loss: 1.7590264081954956
Batch 49/64 loss: 1.7583284378051758
Batch 50/64 loss: 1.7576959133148193
Batch 51/64 loss: 1.7526578903198242
Batch 52/64 loss: 1.7575507164001465
Batch 53/64 loss: 1.753064513206482
Batch 54/64 loss: 1.7525067329406738
Batch 55/64 loss: 1.758168339729309
Batch 56/64 loss: 1.760195255279541
Batch 57/64 loss: 1.7725317478179932
Batch 58/64 loss: 1.762991189956665
Batch 59/64 loss: 1.757090449333191
Batch 60/64 loss: 1.7520447969436646
Batch 61/64 loss: 1.7694388628005981
Batch 62/64 loss: 1.7546052932739258
Batch 63/64 loss: 1.7551651000976562
Batch 64/64 loss: 1.9644765853881836
Epoch 124  Train loss: 1.7598778350680482  Val loss: 1.777228311165092
Epoch 125
-------------------------------
Batch 1/64 loss: 1.7557716369628906
Batch 2/64 loss: 1.7547686100006104
Batch 3/64 loss: 1.7595248222351074
Batch 4/64 loss: 1.7541165351867676
Batch 5/64 loss: 1.7597936391830444
Batch 6/64 loss: 1.7577764987945557
Batch 7/64 loss: 1.7572640180587769
Batch 8/64 loss: 1.7633259296417236
Batch 9/64 loss: 1.7604390382766724
Batch 10/64 loss: 1.772350549697876
Batch 11/64 loss: 1.7562623023986816
Batch 12/64 loss: 1.7613564729690552
Batch 13/64 loss: 1.7540974617004395
Batch 14/64 loss: 1.7557933330535889
Batch 15/64 loss: 1.7562329769134521
Batch 16/64 loss: 1.7545779943466187
Batch 17/64 loss: 1.758202075958252
Batch 18/64 loss: 1.754395604133606
Batch 19/64 loss: 1.755580186843872
Batch 20/64 loss: 1.7575557231903076
Batch 21/64 loss: 1.7591962814331055
Batch 22/64 loss: 1.7594553232192993
Batch 23/64 loss: 1.7691856622695923
Batch 24/64 loss: 1.759657621383667
Batch 25/64 loss: 1.7693434953689575
Batch 26/64 loss: 1.7559304237365723
Batch 27/64 loss: 1.7580698728561401
Batch 28/64 loss: 1.756457805633545
Batch 29/64 loss: 1.7538843154907227
Batch 30/64 loss: 1.7627999782562256
Batch 31/64 loss: 1.7543771266937256
Batch 32/64 loss: 1.759861707687378
Batch 33/64 loss: 1.7554254531860352
Batch 34/64 loss: 1.7623330354690552
Batch 35/64 loss: 1.7650858163833618
Batch 36/64 loss: 1.7600947618484497
Batch 37/64 loss: 1.764714241027832
Batch 38/64 loss: 1.7581982612609863
Batch 39/64 loss: 1.7654683589935303
Batch 40/64 loss: 1.7567071914672852
Batch 41/64 loss: 1.7630934715270996
Batch 42/64 loss: 1.7572283744812012
Batch 43/64 loss: 1.7541502714157104
Batch 44/64 loss: 1.7549093961715698
Batch 45/64 loss: 1.7525196075439453
Batch 46/64 loss: 1.758626103401184
Batch 47/64 loss: 1.757714033126831
Batch 48/64 loss: 1.7555556297302246
Batch 49/64 loss: 1.7546586990356445
Batch 50/64 loss: 1.7556805610656738
Batch 51/64 loss: 1.7534141540527344
Batch 52/64 loss: 1.757436990737915
Batch 53/64 loss: 1.7527990341186523
Batch 54/64 loss: 1.752084493637085
Batch 55/64 loss: 1.7558696269989014
Batch 56/64 loss: 1.7543734312057495
Batch 57/64 loss: 1.7563570737838745
Batch 58/64 loss: 1.7514054775238037
Batch 59/64 loss: 1.7553861141204834
Batch 60/64 loss: 1.7551504373550415
Batch 61/64 loss: 1.7557073831558228
Batch 62/64 loss: 1.7577823400497437
Batch 63/64 loss: 1.7704638242721558
Batch 64/64 loss: 1.9615540504455566
Epoch 125  Train loss: 1.760454340542064  Val loss: 1.7765997455701796
Epoch 126
-------------------------------
Batch 1/64 loss: 1.754652738571167
Batch 2/64 loss: 1.7544487714767456
Batch 3/64 loss: 1.7585265636444092
Batch 4/64 loss: 1.7563509941101074
Batch 5/64 loss: 1.755581021308899
Batch 6/64 loss: 1.752905011177063
Batch 7/64 loss: 1.7553205490112305
Batch 8/64 loss: 1.753376841545105
Batch 9/64 loss: 1.7691807746887207
Batch 10/64 loss: 1.7573668956756592
Batch 11/64 loss: 1.7540948390960693
Batch 12/64 loss: 1.758469581604004
Batch 13/64 loss: 1.7564198970794678
Batch 14/64 loss: 1.7591547966003418
Batch 15/64 loss: 1.7575228214263916
Batch 16/64 loss: 1.7522330284118652
Batch 17/64 loss: 1.7562041282653809
Batch 18/64 loss: 1.750812292098999
Batch 19/64 loss: 1.754965901374817
Batch 20/64 loss: 1.757498025894165
Batch 21/64 loss: 1.757798671722412
Batch 22/64 loss: 1.7497062683105469
Batch 23/64 loss: 1.753989815711975
Batch 24/64 loss: 1.7536845207214355
Batch 25/64 loss: 1.755513310432434
Batch 26/64 loss: 1.7551894187927246
Batch 27/64 loss: 1.7641630172729492
Batch 28/64 loss: 1.750414252281189
Batch 29/64 loss: 1.754260540008545
Batch 30/64 loss: 1.755289077758789
Batch 31/64 loss: 1.7572588920593262
Batch 32/64 loss: 1.7532012462615967
Batch 33/64 loss: 1.7598679065704346
Batch 34/64 loss: 1.7541847229003906
Batch 35/64 loss: 1.7535886764526367
Batch 36/64 loss: 1.7543445825576782
Batch 37/64 loss: 1.7530924081802368
Batch 38/64 loss: 1.7522615194320679
Batch 39/64 loss: 1.7584662437438965
Batch 40/64 loss: 1.7598949670791626
Batch 41/64 loss: 1.7551398277282715
Batch 42/64 loss: 1.772086501121521
Batch 43/64 loss: 1.753145456314087
Batch 44/64 loss: 1.755778431892395
Batch 45/64 loss: 1.7543432712554932
Batch 46/64 loss: 1.757187843322754
Batch 47/64 loss: 1.7584738731384277
Batch 48/64 loss: 1.7574907541275024
Batch 49/64 loss: 1.757400631904602
Batch 50/64 loss: 1.762930154800415
Batch 51/64 loss: 1.7561589479446411
Batch 52/64 loss: 1.756410837173462
Batch 53/64 loss: 1.7560389041900635
Batch 54/64 loss: 1.7615827322006226
Batch 55/64 loss: 1.7638945579528809
Batch 56/64 loss: 1.7595239877700806
Batch 57/64 loss: 1.7572249174118042
Batch 58/64 loss: 1.7715059518814087
Batch 59/64 loss: 1.7708048820495605
Batch 60/64 loss: 1.7637262344360352
Batch 61/64 loss: 1.7592881917953491
Batch 62/64 loss: 1.7578364610671997
Batch 63/64 loss: 1.7577247619628906
Batch 64/64 loss: 1.9596728086471558
Epoch 126  Train loss: 1.7596346392351039  Val loss: 1.7844465516277195
Epoch 127
-------------------------------
Batch 1/64 loss: 1.761027455329895
Batch 2/64 loss: 1.7573904991149902
Batch 3/64 loss: 1.7570428848266602
Batch 4/64 loss: 1.764736533164978
Batch 5/64 loss: 1.7607097625732422
Batch 6/64 loss: 1.7586146593093872
Batch 7/64 loss: 1.7603601217269897
Batch 8/64 loss: 1.781435489654541
Batch 9/64 loss: 1.7611439228057861
Batch 10/64 loss: 1.753234624862671
Batch 11/64 loss: 1.759026288986206
Batch 12/64 loss: 1.7649787664413452
Batch 13/64 loss: 1.767216444015503
Batch 14/64 loss: 1.7578294277191162
Batch 15/64 loss: 1.759314775466919
Batch 16/64 loss: 1.7585995197296143
Batch 17/64 loss: 1.7591229677200317
Batch 18/64 loss: 1.761061668395996
Batch 19/64 loss: 1.7572352886199951
Batch 20/64 loss: 1.7616411447525024
Batch 21/64 loss: 1.7537124156951904
Batch 22/64 loss: 1.7540209293365479
Batch 23/64 loss: 1.7570526599884033
Batch 24/64 loss: 1.7579041719436646
Batch 25/64 loss: 1.763567328453064
Batch 26/64 loss: 1.7564499378204346
Batch 27/64 loss: 1.7590672969818115
Batch 28/64 loss: 1.758481502532959
Batch 29/64 loss: 1.7577903270721436
Batch 30/64 loss: 1.7559930086135864
Batch 31/64 loss: 1.7586052417755127
Batch 32/64 loss: 1.777388572692871
Batch 33/64 loss: 1.7568693161010742
Batch 34/64 loss: 1.7549114227294922
Batch 35/64 loss: 1.7562196254730225
Batch 36/64 loss: 1.7588669061660767
Batch 37/64 loss: 1.7583446502685547
Batch 38/64 loss: 1.756737470626831
Batch 39/64 loss: 1.7575809955596924
Batch 40/64 loss: 1.7587108612060547
Batch 41/64 loss: 1.7554514408111572
Batch 42/64 loss: 1.7542576789855957
Batch 43/64 loss: 1.7564784288406372
Batch 44/64 loss: 1.7646745443344116
Batch 45/64 loss: 1.7553044557571411
Batch 46/64 loss: 1.757988691329956
Batch 47/64 loss: 1.7553720474243164
Batch 48/64 loss: 1.753476858139038
Batch 49/64 loss: 1.7534594535827637
Batch 50/64 loss: 1.7570559978485107
Batch 51/64 loss: 1.7706379890441895
Batch 52/64 loss: 1.7556345462799072
Batch 53/64 loss: 1.752666711807251
Batch 54/64 loss: 1.7609666585922241
Batch 55/64 loss: 1.7727478742599487
Batch 56/64 loss: 1.7591496706008911
Batch 57/64 loss: 1.7573257684707642
Batch 58/64 loss: 1.7667045593261719
Batch 59/64 loss: 1.7567267417907715
Batch 60/64 loss: 1.7623904943466187
Batch 61/64 loss: 1.7785565853118896
Batch 62/64 loss: 1.7655826807022095
Batch 63/64 loss: 1.7558082342147827
Batch 64/64 loss: 1.95628023147583
Epoch 127  Train loss: 1.7621274536731197  Val loss: 1.781408102651642
Epoch 128
-------------------------------
Batch 1/64 loss: 1.7568342685699463
Batch 2/64 loss: 1.7569893598556519
Batch 3/64 loss: 1.7582975625991821
Batch 4/64 loss: 1.7641077041625977
Batch 5/64 loss: 1.7607009410858154
Batch 6/64 loss: 1.7586164474487305
Batch 7/64 loss: 1.7587697505950928
Batch 8/64 loss: 1.7542686462402344
Batch 9/64 loss: 1.7580409049987793
Batch 10/64 loss: 1.7603825330734253
Batch 11/64 loss: 1.7564778327941895
Batch 12/64 loss: 1.7557380199432373
Batch 13/64 loss: 1.7564465999603271
Batch 14/64 loss: 1.7592037916183472
Batch 15/64 loss: 1.75907301902771
Batch 16/64 loss: 1.7544856071472168
Batch 17/64 loss: 1.7679646015167236
Batch 18/64 loss: 1.7555071115493774
Batch 19/64 loss: 1.7589900493621826
Batch 20/64 loss: 1.7561182975769043
Batch 21/64 loss: 1.7594541311264038
Batch 22/64 loss: 1.755189299583435
Batch 23/64 loss: 1.7734293937683105
Batch 24/64 loss: 1.7626066207885742
Batch 25/64 loss: 1.7603228092193604
Batch 26/64 loss: 1.7563591003417969
Batch 27/64 loss: 1.7566629648208618
Batch 28/64 loss: 1.7559330463409424
Batch 29/64 loss: 1.7641377449035645
Batch 30/64 loss: 1.7565338611602783
Batch 31/64 loss: 1.760484218597412
Batch 32/64 loss: 1.757863998413086
Batch 33/64 loss: 1.7550585269927979
Batch 34/64 loss: 1.7570451498031616
Batch 35/64 loss: 1.7592319250106812
Batch 36/64 loss: 1.7718368768692017
Batch 37/64 loss: 1.7537803649902344
Batch 38/64 loss: 1.7565464973449707
Batch 39/64 loss: 1.7560052871704102
Batch 40/64 loss: 1.7542312145233154
Batch 41/64 loss: 1.7561304569244385
Batch 42/64 loss: 1.758597731590271
Batch 43/64 loss: 1.7540655136108398
Batch 44/64 loss: 1.7551989555358887
Batch 45/64 loss: 1.753806233406067
Batch 46/64 loss: 1.752636194229126
Batch 47/64 loss: 1.75310218334198
Batch 48/64 loss: 1.7560982704162598
Batch 49/64 loss: 1.7556334733963013
Batch 50/64 loss: 1.762712836265564
Batch 51/64 loss: 1.7631008625030518
Batch 52/64 loss: 1.7571574449539185
Batch 53/64 loss: 1.754270076751709
Batch 54/64 loss: 1.754237413406372
Batch 55/64 loss: 1.7589082717895508
Batch 56/64 loss: 1.7519636154174805
Batch 57/64 loss: 1.7556273937225342
Batch 58/64 loss: 1.7534401416778564
Batch 59/64 loss: 1.7552639245986938
Batch 60/64 loss: 1.756460189819336
Batch 61/64 loss: 1.7597975730895996
Batch 62/64 loss: 1.7662272453308105
Batch 63/64 loss: 1.7516887187957764
Batch 64/64 loss: 1.9583230018615723
Epoch 128  Train loss: 1.760228910633162  Val loss: 1.7787547570323616
Epoch 129
-------------------------------
Batch 1/64 loss: 1.7639508247375488
Batch 2/64 loss: 1.7581615447998047
Batch 3/64 loss: 1.7614396810531616
Batch 4/64 loss: 1.7667087316513062
Batch 5/64 loss: 1.7673195600509644
Batch 6/64 loss: 1.756638765335083
Batch 7/64 loss: 1.7540899515151978
Batch 8/64 loss: 1.7571828365325928
Batch 9/64 loss: 1.75229811668396
Batch 10/64 loss: 1.757742166519165
Batch 11/64 loss: 1.7525635957717896
Batch 12/64 loss: 1.762829303741455
Batch 13/64 loss: 1.76160728931427
Batch 14/64 loss: 1.7532931566238403
Batch 15/64 loss: 1.7538347244262695
Batch 16/64 loss: 1.7595632076263428
Batch 17/64 loss: 1.754836082458496
Batch 18/64 loss: 1.7614238262176514
Batch 19/64 loss: 1.756892442703247
Batch 20/64 loss: 1.7574740648269653
Batch 21/64 loss: 1.754206657409668
Batch 22/64 loss: 1.7583906650543213
Batch 23/64 loss: 1.7562028169631958
Batch 24/64 loss: 1.7596347332000732
Batch 25/64 loss: 1.7543582916259766
Batch 26/64 loss: 1.7536952495574951
Batch 27/64 loss: 1.7600750923156738
Batch 28/64 loss: 1.7617679834365845
Batch 29/64 loss: 1.7583855390548706
Batch 30/64 loss: 1.7568347454071045
Batch 31/64 loss: 1.7536125183105469
Batch 32/64 loss: 1.7760337591171265
Batch 33/64 loss: 1.7631382942199707
Batch 34/64 loss: 1.7580112218856812
Batch 35/64 loss: 1.7543236017227173
Batch 36/64 loss: 1.7547627687454224
Batch 37/64 loss: 1.7538864612579346
Batch 38/64 loss: 1.7567496299743652
Batch 39/64 loss: 1.752545714378357
Batch 40/64 loss: 1.7540943622589111
Batch 41/64 loss: 1.7546913623809814
Batch 42/64 loss: 1.7526066303253174
Batch 43/64 loss: 1.7541064023971558
Batch 44/64 loss: 1.7580571174621582
Batch 45/64 loss: 1.752710223197937
Batch 46/64 loss: 1.7496734857559204
Batch 47/64 loss: 1.751478672027588
Batch 48/64 loss: 1.7533658742904663
Batch 49/64 loss: 1.7596759796142578
Batch 50/64 loss: 1.7530487775802612
Batch 51/64 loss: 1.7514846324920654
Batch 52/64 loss: 1.7508457899093628
Batch 53/64 loss: 1.7582907676696777
Batch 54/64 loss: 1.7545450925827026
Batch 55/64 loss: 1.7547578811645508
Batch 56/64 loss: 1.7510894536972046
Batch 57/64 loss: 1.7535713911056519
Batch 58/64 loss: 1.7581264972686768
Batch 59/64 loss: 1.7531232833862305
Batch 60/64 loss: 1.7538752555847168
Batch 61/64 loss: 1.7502092123031616
Batch 62/64 loss: 1.7585289478302002
Batch 63/64 loss: 1.7522403001785278
Batch 64/64 loss: 1.9524261951446533
Epoch 129  Train loss: 1.758823257334092  Val loss: 1.778748353322347
Epoch 130
-------------------------------
Batch 1/64 loss: 1.7566519975662231
Batch 2/64 loss: 1.754780650138855
Batch 3/64 loss: 1.7721248865127563
Batch 4/64 loss: 1.7522506713867188
Batch 5/64 loss: 1.7579281330108643
Batch 6/64 loss: 1.7517271041870117
Batch 7/64 loss: 1.7528632879257202
Batch 8/64 loss: 1.7521740198135376
Batch 9/64 loss: 1.7510428428649902
Batch 10/64 loss: 1.7552802562713623
Batch 11/64 loss: 1.757812261581421
Batch 12/64 loss: 1.757629156112671
Batch 13/64 loss: 1.7531664371490479
Batch 14/64 loss: 1.7511767148971558
Batch 15/64 loss: 1.7532225847244263
Batch 16/64 loss: 1.7552189826965332
Batch 17/64 loss: 1.7631852626800537
Batch 18/64 loss: 1.7554768323898315
Batch 19/64 loss: 1.7552863359451294
Batch 20/64 loss: 1.7545233964920044
Batch 21/64 loss: 1.7599430084228516
Batch 22/64 loss: 1.752609372138977
Batch 23/64 loss: 1.7551689147949219
Batch 24/64 loss: 1.752488374710083
Batch 25/64 loss: 1.752713680267334
Batch 26/64 loss: 1.7534795999526978
Batch 27/64 loss: 1.7541968822479248
Batch 28/64 loss: 1.7632946968078613
Batch 29/64 loss: 1.75754714012146
Batch 30/64 loss: 1.7580764293670654
Batch 31/64 loss: 1.752347707748413
Batch 32/64 loss: 1.753490686416626
Batch 33/64 loss: 1.7542470693588257
Batch 34/64 loss: 1.7502145767211914
Batch 35/64 loss: 1.7528693675994873
Batch 36/64 loss: 1.7560571432113647
Batch 37/64 loss: 1.7522963285446167
Batch 38/64 loss: 1.7568844556808472
Batch 39/64 loss: 1.755767822265625
Batch 40/64 loss: 1.751446008682251
Batch 41/64 loss: 1.7552367448806763
Batch 42/64 loss: 1.7522785663604736
Batch 43/64 loss: 1.7536189556121826
Batch 44/64 loss: 1.7618623971939087
Batch 45/64 loss: 1.7525537014007568
Batch 46/64 loss: 1.751246690750122
Batch 47/64 loss: 1.7549855709075928
Batch 48/64 loss: 1.7574775218963623
Batch 49/64 loss: 1.7537651062011719
Batch 50/64 loss: 1.7581462860107422
Batch 51/64 loss: 1.7527501583099365
Batch 52/64 loss: 1.7539440393447876
Batch 53/64 loss: 1.7521569728851318
Batch 54/64 loss: 1.7544928789138794
Batch 55/64 loss: 1.7539762258529663
Batch 56/64 loss: 1.7549173831939697
Batch 57/64 loss: 1.763866662979126
Batch 58/64 loss: 1.7565432786941528
Batch 59/64 loss: 1.7513422966003418
Batch 60/64 loss: 1.7523272037506104
Batch 61/64 loss: 1.7524999380111694
Batch 62/64 loss: 1.7524158954620361
Batch 63/64 loss: 1.7510892152786255
Batch 64/64 loss: 1.962869644165039
Epoch 130  Train loss: 1.757400894165039  Val loss: 1.7731345887855976
Saving best model, epoch: 130
Epoch 131
-------------------------------
Batch 1/64 loss: 1.7549455165863037
Batch 2/64 loss: 1.7615305185317993
Batch 3/64 loss: 1.7515780925750732
Batch 4/64 loss: 1.753442406654358
Batch 5/64 loss: 1.7536364793777466
Batch 6/64 loss: 1.749875783920288
Batch 7/64 loss: 1.7571128606796265
Batch 8/64 loss: 1.7533295154571533
Batch 9/64 loss: 1.7551159858703613
Batch 10/64 loss: 1.7572228908538818
Batch 11/64 loss: 1.7562024593353271
Batch 12/64 loss: 1.763654112815857
Batch 13/64 loss: 1.7536077499389648
Batch 14/64 loss: 1.7520787715911865
Batch 15/64 loss: 1.7629486322402954
Batch 16/64 loss: 1.7519750595092773
Batch 17/64 loss: 1.7548832893371582
Batch 18/64 loss: 1.7529939413070679
Batch 19/64 loss: 1.760817050933838
Batch 20/64 loss: 1.7546135187149048
Batch 21/64 loss: 1.751763939857483
Batch 22/64 loss: 1.7510522603988647
Batch 23/64 loss: 1.7571451663970947
Batch 24/64 loss: 1.7554179430007935
Batch 25/64 loss: 1.751090168952942
Batch 26/64 loss: 1.7540829181671143
Batch 27/64 loss: 1.7526592016220093
Batch 28/64 loss: 1.7579777240753174
Batch 29/64 loss: 1.7584037780761719
Batch 30/64 loss: 1.7516088485717773
Batch 31/64 loss: 1.7517924308776855
Batch 32/64 loss: 1.7554559707641602
Batch 33/64 loss: 1.755150318145752
Batch 34/64 loss: 1.7547491788864136
Batch 35/64 loss: 1.755542278289795
Batch 36/64 loss: 1.7535580396652222
Batch 37/64 loss: 1.7494879961013794
Batch 38/64 loss: 1.7522355318069458
Batch 39/64 loss: 1.7949764728546143
Batch 40/64 loss: 1.7514934539794922
Batch 41/64 loss: 1.7609812021255493
Batch 42/64 loss: 1.7535282373428345
Batch 43/64 loss: 1.7550482749938965
Batch 44/64 loss: 1.7650917768478394
Batch 45/64 loss: 1.7571951150894165
Batch 46/64 loss: 1.7551910877227783
Batch 47/64 loss: 1.7548085451126099
Batch 48/64 loss: 1.7524570226669312
Batch 49/64 loss: 1.766503095626831
Batch 50/64 loss: 1.7554761171340942
Batch 51/64 loss: 1.75296151638031
Batch 52/64 loss: 1.7541708946228027
Batch 53/64 loss: 1.758238434791565
Batch 54/64 loss: 1.751943588256836
Batch 55/64 loss: 1.7561010122299194
Batch 56/64 loss: 1.7610373497009277
Batch 57/64 loss: 1.752611517906189
Batch 58/64 loss: 1.75204598903656
Batch 59/64 loss: 1.7539629936218262
Batch 60/64 loss: 1.753322958946228
Batch 61/64 loss: 1.7581086158752441
Batch 62/64 loss: 1.756836175918579
Batch 63/64 loss: 1.752976417541504
Batch 64/64 loss: 1.9546937942504883
Epoch 131  Train loss: 1.7581776712455002  Val loss: 1.776624911429546
Epoch 132
-------------------------------
Batch 1/64 loss: 1.7521125078201294
Batch 2/64 loss: 1.762385606765747
Batch 3/64 loss: 1.7553153038024902
Batch 4/64 loss: 1.756822943687439
Batch 5/64 loss: 1.7549540996551514
Batch 6/64 loss: 1.7561646699905396
Batch 7/64 loss: 1.7537541389465332
Batch 8/64 loss: 1.7534887790679932
Batch 9/64 loss: 1.766954779624939
Batch 10/64 loss: 1.7532241344451904
Batch 11/64 loss: 1.7559148073196411
Batch 12/64 loss: 1.7535803318023682
Batch 13/64 loss: 1.7507498264312744
Batch 14/64 loss: 1.7529064416885376
Batch 15/64 loss: 1.753757357597351
Batch 16/64 loss: 1.7553883790969849
Batch 17/64 loss: 1.755368947982788
Batch 18/64 loss: 1.752317190170288
Batch 19/64 loss: 1.7524274587631226
Batch 20/64 loss: 1.7535216808319092
Batch 21/64 loss: 1.7533347606658936
Batch 22/64 loss: 1.75568425655365
Batch 23/64 loss: 1.7588222026824951
Batch 24/64 loss: 1.7521209716796875
Batch 25/64 loss: 1.757251501083374
Batch 26/64 loss: 1.7534878253936768
Batch 27/64 loss: 1.7539241313934326
Batch 28/64 loss: 1.7524526119232178
Batch 29/64 loss: 1.7645089626312256
Batch 30/64 loss: 1.7536725997924805
Batch 31/64 loss: 1.752676010131836
Batch 32/64 loss: 1.753894567489624
Batch 33/64 loss: 1.757793664932251
Batch 34/64 loss: 1.7524374723434448
Batch 35/64 loss: 1.7516181468963623
Batch 36/64 loss: 1.7535505294799805
Batch 37/64 loss: 1.753387451171875
Batch 38/64 loss: 1.7520272731781006
Batch 39/64 loss: 1.7519629001617432
Batch 40/64 loss: 1.7583576440811157
Batch 41/64 loss: 1.7518421411514282
Batch 42/64 loss: 1.7701051235198975
Batch 43/64 loss: 1.7550926208496094
Batch 44/64 loss: 1.7503143548965454
Batch 45/64 loss: 1.7580457925796509
Batch 46/64 loss: 1.7553062438964844
Batch 47/64 loss: 1.7532517910003662
Batch 48/64 loss: 1.7497355937957764
Batch 49/64 loss: 1.7537884712219238
Batch 50/64 loss: 1.7551361322402954
Batch 51/64 loss: 1.758094310760498
Batch 52/64 loss: 1.7524703741073608
Batch 53/64 loss: 1.7529855966567993
Batch 54/64 loss: 1.7540664672851562
Batch 55/64 loss: 1.760229468345642
Batch 56/64 loss: 1.7557252645492554
Batch 57/64 loss: 1.75596284866333
Batch 58/64 loss: 1.7545804977416992
Batch 59/64 loss: 1.7544000148773193
Batch 60/64 loss: 1.7540903091430664
Batch 61/64 loss: 1.750511646270752
Batch 62/64 loss: 1.7552762031555176
Batch 63/64 loss: 1.754373550415039
Batch 64/64 loss: 1.9539668560028076
Epoch 132  Train loss: 1.757253879659316  Val loss: 1.7757225241448051
Epoch 133
-------------------------------
Batch 1/64 loss: 1.7527477741241455
Batch 2/64 loss: 1.755068302154541
Batch 3/64 loss: 1.7526814937591553
Batch 4/64 loss: 1.7577769756317139
Batch 5/64 loss: 1.7595151662826538
Batch 6/64 loss: 1.754303216934204
Batch 7/64 loss: 1.7563612461090088
Batch 8/64 loss: 1.7522225379943848
Batch 9/64 loss: 1.755415439605713
Batch 10/64 loss: 1.75593101978302
Batch 11/64 loss: 1.7566014528274536
Batch 12/64 loss: 1.7546749114990234
Batch 13/64 loss: 1.756059169769287
Batch 14/64 loss: 1.7540950775146484
Batch 15/64 loss: 1.7734858989715576
Batch 16/64 loss: 1.753875732421875
Batch 17/64 loss: 1.7637351751327515
Batch 18/64 loss: 1.753103494644165
Batch 19/64 loss: 1.7528011798858643
Batch 20/64 loss: 1.7539621591567993
Batch 21/64 loss: 1.7581945657730103
Batch 22/64 loss: 1.7559452056884766
Batch 23/64 loss: 1.7524586915969849
Batch 24/64 loss: 1.7548786401748657
Batch 25/64 loss: 1.751776933670044
Batch 26/64 loss: 1.7503334283828735
Batch 27/64 loss: 1.7588558197021484
Batch 28/64 loss: 1.7593512535095215
Batch 29/64 loss: 1.751455545425415
Batch 30/64 loss: 1.7505906820297241
Batch 31/64 loss: 1.7569456100463867
Batch 32/64 loss: 1.7576721906661987
Batch 33/64 loss: 1.7562446594238281
Batch 34/64 loss: 1.7559452056884766
Batch 35/64 loss: 1.7545697689056396
Batch 36/64 loss: 1.756292462348938
Batch 37/64 loss: 1.7534289360046387
Batch 38/64 loss: 1.7505067586898804
Batch 39/64 loss: 1.762906551361084
Batch 40/64 loss: 1.766375184059143
Batch 41/64 loss: 1.7588940858840942
Batch 42/64 loss: 1.7528495788574219
Batch 43/64 loss: 1.7548974752426147
Batch 44/64 loss: 1.7755483388900757
Batch 45/64 loss: 1.75602126121521
Batch 46/64 loss: 1.7570760250091553
Batch 47/64 loss: 1.754465937614441
Batch 48/64 loss: 1.7635427713394165
Batch 49/64 loss: 1.7631332874298096
Batch 50/64 loss: 1.7628064155578613
Batch 51/64 loss: 1.759242296218872
Batch 52/64 loss: 1.7682710886001587
Batch 53/64 loss: 1.756137728691101
Batch 54/64 loss: 1.755065679550171
Batch 55/64 loss: 1.7803577184677124
Batch 56/64 loss: 1.7613354921340942
Batch 57/64 loss: 1.7640914916992188
Batch 58/64 loss: 1.7550071477890015
Batch 59/64 loss: 1.7549951076507568
Batch 60/64 loss: 1.7580960988998413
Batch 61/64 loss: 1.755560040473938
Batch 62/64 loss: 1.7530230283737183
Batch 63/64 loss: 1.7521748542785645
Batch 64/64 loss: 1.954651117324829
Epoch 133  Train loss: 1.7596506165523156  Val loss: 1.7817866351596268
Epoch 134
-------------------------------
Batch 1/64 loss: 1.7588834762573242
Batch 2/64 loss: 1.7522218227386475
Batch 3/64 loss: 1.7526135444641113
Batch 4/64 loss: 1.7529618740081787
Batch 5/64 loss: 1.7575595378875732
Batch 6/64 loss: 1.7564046382904053
Batch 7/64 loss: 1.7558746337890625
Batch 8/64 loss: 1.7497501373291016
Batch 9/64 loss: 1.7555137872695923
Batch 10/64 loss: 1.752375602722168
Batch 11/64 loss: 1.7540929317474365
Batch 12/64 loss: 1.753431797027588
Batch 13/64 loss: 1.760728359222412
Batch 14/64 loss: 1.752145767211914
Batch 15/64 loss: 1.759734034538269
Batch 16/64 loss: 1.7525326013565063
Batch 17/64 loss: 1.761807918548584
Batch 18/64 loss: 1.7580713033676147
Batch 19/64 loss: 1.7559142112731934
Batch 20/64 loss: 1.7593759298324585
Batch 21/64 loss: 1.757766604423523
Batch 22/64 loss: 1.7572925090789795
Batch 23/64 loss: 1.7754589319229126
Batch 24/64 loss: 1.7551259994506836
Batch 25/64 loss: 1.7517480850219727
Batch 26/64 loss: 1.7645210027694702
Batch 27/64 loss: 1.7614593505859375
Batch 28/64 loss: 1.7581018209457397
Batch 29/64 loss: 1.7550938129425049
Batch 30/64 loss: 1.7618603706359863
Batch 31/64 loss: 1.755967617034912
Batch 32/64 loss: 1.7565208673477173
Batch 33/64 loss: 1.7569843530654907
Batch 34/64 loss: 1.7590255737304688
Batch 35/64 loss: 1.7583109140396118
Batch 36/64 loss: 1.757370948791504
Batch 37/64 loss: 1.7560772895812988
Batch 38/64 loss: 1.7555878162384033
Batch 39/64 loss: 1.7554290294647217
Batch 40/64 loss: 1.7523648738861084
Batch 41/64 loss: 1.759039282798767
Batch 42/64 loss: 1.7540186643600464
Batch 43/64 loss: 1.7623265981674194
Batch 44/64 loss: 1.7519475221633911
Batch 45/64 loss: 1.7503167390823364
Batch 46/64 loss: 1.7550146579742432
Batch 47/64 loss: 1.7589373588562012
Batch 48/64 loss: 1.7672817707061768
Batch 49/64 loss: 1.7533433437347412
Batch 50/64 loss: 1.7552677392959595
Batch 51/64 loss: 1.755108118057251
Batch 52/64 loss: 1.7554144859313965
Batch 53/64 loss: 1.7519382238388062
Batch 54/64 loss: 1.756466031074524
Batch 55/64 loss: 1.7612115144729614
Batch 56/64 loss: 1.7548635005950928
Batch 57/64 loss: 1.7508717775344849
Batch 58/64 loss: 1.7589367628097534
Batch 59/64 loss: 1.7514944076538086
Batch 60/64 loss: 1.7585424184799194
Batch 61/64 loss: 1.7518792152404785
Batch 62/64 loss: 1.7531933784484863
Batch 63/64 loss: 1.7545695304870605
Batch 64/64 loss: 1.9550520181655884
Epoch 134  Train loss: 1.7587817056506287  Val loss: 1.7759828993544955
Epoch 135
-------------------------------
Batch 1/64 loss: 1.766706943511963
Batch 2/64 loss: 1.75099515914917
Batch 3/64 loss: 1.7549017667770386
Batch 4/64 loss: 1.757369875907898
Batch 5/64 loss: 1.7593374252319336
Batch 6/64 loss: 1.752161979675293
Batch 7/64 loss: 1.7529799938201904
Batch 8/64 loss: 1.7558352947235107
Batch 9/64 loss: 1.7514206171035767
Batch 10/64 loss: 1.7530481815338135
Batch 11/64 loss: 1.7556641101837158
Batch 12/64 loss: 1.7509440183639526
Batch 13/64 loss: 1.7580294609069824
Batch 14/64 loss: 1.755354881286621
Batch 15/64 loss: 1.7518136501312256
Batch 16/64 loss: 1.752128005027771
Batch 17/64 loss: 1.75130033493042
Batch 18/64 loss: 1.7530739307403564
Batch 19/64 loss: 1.7489986419677734
Batch 20/64 loss: 1.7536697387695312
Batch 21/64 loss: 1.7653573751449585
Batch 22/64 loss: 1.751397728919983
Batch 23/64 loss: 1.7547987699508667
Batch 24/64 loss: 1.749165415763855
Batch 25/64 loss: 1.7524161338806152
Batch 26/64 loss: 1.7512212991714478
Batch 27/64 loss: 1.7554866075515747
Batch 28/64 loss: 1.7518248558044434
Batch 29/64 loss: 1.7555513381958008
Batch 30/64 loss: 1.7542049884796143
Batch 31/64 loss: 1.7516884803771973
Batch 32/64 loss: 1.753220796585083
Batch 33/64 loss: 1.7519177198410034
Batch 34/64 loss: 1.7493096590042114
Batch 35/64 loss: 1.7657463550567627
Batch 36/64 loss: 1.754546880722046
Batch 37/64 loss: 1.7510300874710083
Batch 38/64 loss: 1.7548120021820068
Batch 39/64 loss: 1.7549140453338623
Batch 40/64 loss: 1.7570240497589111
Batch 41/64 loss: 1.7545229196548462
Batch 42/64 loss: 1.7545934915542603
Batch 43/64 loss: 1.753697395324707
Batch 44/64 loss: 1.750547170639038
Batch 45/64 loss: 1.7544137239456177
Batch 46/64 loss: 1.7579511404037476
Batch 47/64 loss: 1.7534197568893433
Batch 48/64 loss: 1.7598916292190552
Batch 49/64 loss: 1.7606292963027954
Batch 50/64 loss: 1.7627205848693848
Batch 51/64 loss: 1.7643201351165771
Batch 52/64 loss: 1.7633273601531982
Batch 53/64 loss: 1.7613677978515625
Batch 54/64 loss: 1.75503408908844
Batch 55/64 loss: 1.7617255449295044
Batch 56/64 loss: 1.7539262771606445
Batch 57/64 loss: 1.7548325061798096
Batch 58/64 loss: 1.7597070932388306
Batch 59/64 loss: 1.7508535385131836
Batch 60/64 loss: 1.7565209865570068
Batch 61/64 loss: 1.756470799446106
Batch 62/64 loss: 1.756098985671997
Batch 63/64 loss: 1.7515170574188232
Batch 64/64 loss: 1.9579699039459229
Epoch 135  Train loss: 1.7576146714827594  Val loss: 1.7792661894637694
Epoch 136
-------------------------------
Batch 1/64 loss: 1.756697654724121
Batch 2/64 loss: 1.7580609321594238
Batch 3/64 loss: 1.754422664642334
Batch 4/64 loss: 1.7556333541870117
Batch 5/64 loss: 1.7545422315597534
Batch 6/64 loss: 1.7544186115264893
Batch 7/64 loss: 1.7568097114562988
Batch 8/64 loss: 1.7536981105804443
Batch 9/64 loss: 1.752195954322815
Batch 10/64 loss: 1.7552080154418945
Batch 11/64 loss: 1.755322813987732
Batch 12/64 loss: 1.7592742443084717
Batch 13/64 loss: 1.753566026687622
Batch 14/64 loss: 1.7533822059631348
Batch 15/64 loss: 1.7536752223968506
Batch 16/64 loss: 1.756828784942627
Batch 17/64 loss: 1.7544231414794922
Batch 18/64 loss: 1.7531325817108154
Batch 19/64 loss: 1.7533202171325684
Batch 20/64 loss: 1.7537035942077637
Batch 21/64 loss: 1.7520980834960938
Batch 22/64 loss: 1.753784418106079
Batch 23/64 loss: 1.751755952835083
Batch 24/64 loss: 1.7580851316452026
Batch 25/64 loss: 1.7510031461715698
Batch 26/64 loss: 1.7582752704620361
Batch 27/64 loss: 1.7526650428771973
Batch 28/64 loss: 1.7513275146484375
Batch 29/64 loss: 1.7568632364273071
Batch 30/64 loss: 1.7581863403320312
Batch 31/64 loss: 1.7552698850631714
Batch 32/64 loss: 1.7653255462646484
Batch 33/64 loss: 1.7600735425949097
Batch 34/64 loss: 1.7601697444915771
Batch 35/64 loss: 1.7522467374801636
Batch 36/64 loss: 1.7591052055358887
Batch 37/64 loss: 1.7557733058929443
Batch 38/64 loss: 1.7677433490753174
Batch 39/64 loss: 1.7562904357910156
Batch 40/64 loss: 1.7533988952636719
Batch 41/64 loss: 1.7531182765960693
Batch 42/64 loss: 1.759395718574524
Batch 43/64 loss: 1.7539927959442139
Batch 44/64 loss: 1.7574270963668823
Batch 45/64 loss: 1.7521121501922607
Batch 46/64 loss: 1.7574536800384521
Batch 47/64 loss: 1.7588452100753784
Batch 48/64 loss: 1.754648208618164
Batch 49/64 loss: 1.7532389163970947
Batch 50/64 loss: 1.7699153423309326
Batch 51/64 loss: 1.7589123249053955
Batch 52/64 loss: 1.7563633918762207
Batch 53/64 loss: 1.7552677392959595
Batch 54/64 loss: 1.7590422630310059
Batch 55/64 loss: 1.7562377452850342
Batch 56/64 loss: 1.7519967555999756
Batch 57/64 loss: 1.7697120904922485
Batch 58/64 loss: 1.7566804885864258
Batch 59/64 loss: 1.7712504863739014
Batch 60/64 loss: 1.7618846893310547
Batch 61/64 loss: 1.75423264503479
Batch 62/64 loss: 1.758924126625061
Batch 63/64 loss: 1.7591239213943481
Batch 64/64 loss: 1.9607948064804077
Epoch 136  Train loss: 1.7590294749129052  Val loss: 1.7915618132889475
Epoch 137
-------------------------------
Batch 1/64 loss: 1.7738425731658936
Batch 2/64 loss: 1.755654215812683
Batch 3/64 loss: 1.7570371627807617
Batch 4/64 loss: 1.758497953414917
Batch 5/64 loss: 1.7609448432922363
Batch 6/64 loss: 1.7552101612091064
Batch 7/64 loss: 1.7564444541931152
Batch 8/64 loss: 1.7594224214553833
Batch 9/64 loss: 1.7586349248886108
Batch 10/64 loss: 1.756605863571167
Batch 11/64 loss: 1.7567131519317627
Batch 12/64 loss: 1.7608386278152466
Batch 13/64 loss: 1.7664164304733276
Batch 14/64 loss: 1.758051872253418
Batch 15/64 loss: 1.7595010995864868
Batch 16/64 loss: 1.7668148279190063
Batch 17/64 loss: 1.7693719863891602
Batch 18/64 loss: 1.7543524503707886
Batch 19/64 loss: 1.7566149234771729
Batch 20/64 loss: 1.7582476139068604
Batch 21/64 loss: 1.7550246715545654
Batch 22/64 loss: 1.7589539289474487
Batch 23/64 loss: 1.7570743560791016
Batch 24/64 loss: 1.7543785572052002
Batch 25/64 loss: 1.7576699256896973
Batch 26/64 loss: 1.7561273574829102
Batch 27/64 loss: 1.7525722980499268
Batch 28/64 loss: 1.753251552581787
Batch 29/64 loss: 1.7551050186157227
Batch 30/64 loss: 1.7561066150665283
Batch 31/64 loss: 1.7565281391143799
Batch 32/64 loss: 1.755752682685852
Batch 33/64 loss: 1.7660025358200073
Batch 34/64 loss: 1.7562109231948853
Batch 35/64 loss: 1.7555627822875977
Batch 36/64 loss: 1.7506005764007568
Batch 37/64 loss: 1.7588682174682617
Batch 38/64 loss: 1.7532143592834473
Batch 39/64 loss: 1.7698729038238525
Batch 40/64 loss: 1.7526915073394775
Batch 41/64 loss: 1.751180648803711
Batch 42/64 loss: 1.7663474082946777
Batch 43/64 loss: 1.753775954246521
Batch 44/64 loss: 1.756537914276123
Batch 45/64 loss: 1.7509136199951172
Batch 46/64 loss: 1.7518055438995361
Batch 47/64 loss: 1.7568496465682983
Batch 48/64 loss: 1.753840446472168
Batch 49/64 loss: 1.755100131034851
Batch 50/64 loss: 1.752355694770813
Batch 51/64 loss: 1.7522087097167969
Batch 52/64 loss: 1.7525393962860107
Batch 53/64 loss: 1.7567145824432373
Batch 54/64 loss: 1.7505154609680176
Batch 55/64 loss: 1.753944754600525
Batch 56/64 loss: 1.7506195306777954
Batch 57/64 loss: 1.7567294836044312
Batch 58/64 loss: 1.7545818090438843
Batch 59/64 loss: 1.7552025318145752
Batch 60/64 loss: 1.7555452585220337
Batch 61/64 loss: 1.7579350471496582
Batch 62/64 loss: 1.7624784708023071
Batch 63/64 loss: 1.7546565532684326
Batch 64/64 loss: 1.950289011001587
Epoch 137  Train loss: 1.759307950150733  Val loss: 1.7742082630236125
Epoch 138
-------------------------------
Batch 1/64 loss: 1.7521766424179077
Batch 2/64 loss: 1.7535618543624878
Batch 3/64 loss: 1.7521083354949951
Batch 4/64 loss: 1.7531218528747559
Batch 5/64 loss: 1.752182126045227
Batch 6/64 loss: 1.7548010349273682
Batch 7/64 loss: 1.75333571434021
Batch 8/64 loss: 1.754739761352539
Batch 9/64 loss: 1.7544748783111572
Batch 10/64 loss: 1.7605482339859009
Batch 11/64 loss: 1.7518972158432007
Batch 12/64 loss: 1.7525954246520996
Batch 13/64 loss: 1.7535099983215332
Batch 14/64 loss: 1.751821517944336
Batch 15/64 loss: 1.7599095106124878
Batch 16/64 loss: 1.7552075386047363
Batch 17/64 loss: 1.7556085586547852
Batch 18/64 loss: 1.7524499893188477
Batch 19/64 loss: 1.758569359779358
Batch 20/64 loss: 1.7524707317352295
Batch 21/64 loss: 1.763630986213684
Batch 22/64 loss: 1.760237693786621
Batch 23/64 loss: 1.7533303499221802
Batch 24/64 loss: 1.7576347589492798
Batch 25/64 loss: 1.753157138824463
Batch 26/64 loss: 1.7532973289489746
Batch 27/64 loss: 1.748867392539978
Batch 28/64 loss: 1.7570676803588867
Batch 29/64 loss: 1.749298095703125
Batch 30/64 loss: 1.7563714981079102
Batch 31/64 loss: 1.7537076473236084
Batch 32/64 loss: 1.7591474056243896
Batch 33/64 loss: 1.7559525966644287
Batch 34/64 loss: 1.7554072141647339
Batch 35/64 loss: 1.7625097036361694
Batch 36/64 loss: 1.7558131217956543
Batch 37/64 loss: 1.7553061246871948
Batch 38/64 loss: 1.7681529521942139
Batch 39/64 loss: 1.753230333328247
Batch 40/64 loss: 1.753767728805542
Batch 41/64 loss: 1.756098985671997
Batch 42/64 loss: 1.7548716068267822
Batch 43/64 loss: 1.7526664733886719
Batch 44/64 loss: 1.7671902179718018
Batch 45/64 loss: 1.752478837966919
Batch 46/64 loss: 1.7744585275650024
Batch 47/64 loss: 1.7557060718536377
Batch 48/64 loss: 1.7518596649169922
Batch 49/64 loss: 1.7554742097854614
Batch 50/64 loss: 1.753914713859558
Batch 51/64 loss: 1.7540308237075806
Batch 52/64 loss: 1.7519981861114502
Batch 53/64 loss: 1.7525713443756104
Batch 54/64 loss: 1.750078558921814
Batch 55/64 loss: 1.7518789768218994
Batch 56/64 loss: 1.7509970664978027
Batch 57/64 loss: 1.7550777196884155
Batch 58/64 loss: 1.7516067028045654
Batch 59/64 loss: 1.7643895149230957
Batch 60/64 loss: 1.7536853551864624
Batch 61/64 loss: 1.7535436153411865
Batch 62/64 loss: 1.7507004737854004
Batch 63/64 loss: 1.754564642906189
Batch 64/64 loss: 1.9661352634429932
Epoch 138  Train loss: 1.7577321061901017  Val loss: 1.7727968422407956
Saving best model, epoch: 138
Epoch 139
-------------------------------
Batch 1/64 loss: 1.7517790794372559
Batch 2/64 loss: 1.7498975992202759
Batch 3/64 loss: 1.755044937133789
Batch 4/64 loss: 1.7536628246307373
Batch 5/64 loss: 1.7558598518371582
Batch 6/64 loss: 1.7519502639770508
Batch 7/64 loss: 1.755833625793457
Batch 8/64 loss: 1.7606450319290161
Batch 9/64 loss: 1.7665882110595703
Batch 10/64 loss: 1.7532612085342407
Batch 11/64 loss: 1.7563042640686035
Batch 12/64 loss: 1.754591464996338
Batch 13/64 loss: 1.764424443244934
Batch 14/64 loss: 1.7581264972686768
Batch 15/64 loss: 1.7540359497070312
Batch 16/64 loss: 1.7557302713394165
Batch 17/64 loss: 1.7690876722335815
Batch 18/64 loss: 1.7519954442977905
Batch 19/64 loss: 1.752299427986145
Batch 20/64 loss: 1.7559654712677002
Batch 21/64 loss: 1.7513636350631714
Batch 22/64 loss: 1.756201982498169
Batch 23/64 loss: 1.7559149265289307
Batch 24/64 loss: 1.7556666135787964
Batch 25/64 loss: 1.7540345191955566
Batch 26/64 loss: 1.7587610483169556
Batch 27/64 loss: 1.760143518447876
Batch 28/64 loss: 1.7575565576553345
Batch 29/64 loss: 1.7562355995178223
Batch 30/64 loss: 1.7567938566207886
Batch 31/64 loss: 1.7513692378997803
Batch 32/64 loss: 1.7546087503433228
Batch 33/64 loss: 1.7521905899047852
Batch 34/64 loss: 1.7557196617126465
Batch 35/64 loss: 1.753139853477478
Batch 36/64 loss: 1.759367823600769
Batch 37/64 loss: 1.7550232410430908
Batch 38/64 loss: 1.7533116340637207
Batch 39/64 loss: 1.755300521850586
Batch 40/64 loss: 1.7773139476776123
Batch 41/64 loss: 1.7523329257965088
Batch 42/64 loss: 1.7556487321853638
Batch 43/64 loss: 1.7570022344589233
Batch 44/64 loss: 1.7713252305984497
Batch 45/64 loss: 1.7615418434143066
Batch 46/64 loss: 1.757721185684204
Batch 47/64 loss: 1.7521499395370483
Batch 48/64 loss: 1.7539899349212646
Batch 49/64 loss: 1.753743290901184
Batch 50/64 loss: 1.7528120279312134
Batch 51/64 loss: 1.7531815767288208
Batch 52/64 loss: 1.7536098957061768
Batch 53/64 loss: 1.7607122659683228
Batch 54/64 loss: 1.7531023025512695
Batch 55/64 loss: 1.7584805488586426
Batch 56/64 loss: 1.755207896232605
Batch 57/64 loss: 1.7599163055419922
Batch 58/64 loss: 1.7540321350097656
Batch 59/64 loss: 1.7578725814819336
Batch 60/64 loss: 1.7545065879821777
Batch 61/64 loss: 1.7531954050064087
Batch 62/64 loss: 1.7536940574645996
Batch 63/64 loss: 1.752678632736206
Batch 64/64 loss: 1.9545156955718994
Epoch 139  Train loss: 1.758610907722922  Val loss: 1.7746396335129886
Epoch 140
-------------------------------
Batch 1/64 loss: 1.7540745735168457
Batch 2/64 loss: 1.755205750465393
Batch 3/64 loss: 1.7603025436401367
Batch 4/64 loss: 1.7541826963424683
Batch 5/64 loss: 1.762692928314209
Batch 6/64 loss: 1.7593326568603516
Batch 7/64 loss: 1.759393572807312
Batch 8/64 loss: 1.755815029144287
Batch 9/64 loss: 1.7539198398590088
Batch 10/64 loss: 1.7559850215911865
Batch 11/64 loss: 1.7513675689697266
Batch 12/64 loss: 1.748854398727417
Batch 13/64 loss: 1.7553746700286865
Batch 14/64 loss: 1.7528637647628784
Batch 15/64 loss: 1.760361671447754
Batch 16/64 loss: 1.7571460008621216
Batch 17/64 loss: 1.7545166015625
Batch 18/64 loss: 1.7566773891448975
Batch 19/64 loss: 1.759059190750122
Batch 20/64 loss: 1.7503629922866821
Batch 21/64 loss: 1.7533607482910156
Batch 22/64 loss: 1.7538033723831177
Batch 23/64 loss: 1.752288818359375
Batch 24/64 loss: 1.758054494857788
Batch 25/64 loss: 1.7753549814224243
Batch 26/64 loss: 1.7564486265182495
Batch 27/64 loss: 1.7551194429397583
Batch 28/64 loss: 1.7514785528182983
Batch 29/64 loss: 1.7525599002838135
Batch 30/64 loss: 1.750898003578186
Batch 31/64 loss: 1.7546658515930176
Batch 32/64 loss: 1.7556756734848022
Batch 33/64 loss: 1.7494606971740723
Batch 34/64 loss: 1.748805046081543
Batch 35/64 loss: 1.751833200454712
Batch 36/64 loss: 1.7549521923065186
Batch 37/64 loss: 1.752981185913086
Batch 38/64 loss: 1.7530508041381836
Batch 39/64 loss: 1.757630467414856
Batch 40/64 loss: 1.7544000148773193
Batch 41/64 loss: 1.7555688619613647
Batch 42/64 loss: 1.7604469060897827
Batch 43/64 loss: 1.7532249689102173
Batch 44/64 loss: 1.752971887588501
Batch 45/64 loss: 1.7570079565048218
Batch 46/64 loss: 1.751866102218628
Batch 47/64 loss: 1.755041241645813
Batch 48/64 loss: 1.7540602684020996
Batch 49/64 loss: 1.7503005266189575
Batch 50/64 loss: 1.7509726285934448
Batch 51/64 loss: 1.7635018825531006
Batch 52/64 loss: 1.7506142854690552
Batch 53/64 loss: 1.752098798751831
Batch 54/64 loss: 1.7515552043914795
Batch 55/64 loss: 1.7520232200622559
Batch 56/64 loss: 1.7617555856704712
Batch 57/64 loss: 1.7519888877868652
Batch 58/64 loss: 1.7491668462753296
Batch 59/64 loss: 1.7515841722488403
Batch 60/64 loss: 1.7536734342575073
Batch 61/64 loss: 1.7503998279571533
Batch 62/64 loss: 1.7488175630569458
Batch 63/64 loss: 1.7530053853988647
Batch 64/64 loss: 1.9575660228729248
Epoch 140  Train loss: 1.757021676792818  Val loss: 1.77232813097767
Saving best model, epoch: 140
Epoch 141
-------------------------------
Batch 1/64 loss: 1.752441167831421
Batch 2/64 loss: 1.7498760223388672
Batch 3/64 loss: 1.7514806985855103
Batch 4/64 loss: 1.754149079322815
Batch 5/64 loss: 1.7500903606414795
Batch 6/64 loss: 1.750058889389038
Batch 7/64 loss: 1.7517526149749756
Batch 8/64 loss: 1.7523325681686401
Batch 9/64 loss: 1.7503995895385742
Batch 10/64 loss: 1.7544598579406738
Batch 11/64 loss: 1.7515788078308105
Batch 12/64 loss: 1.7504990100860596
Batch 13/64 loss: 1.7523483037948608
Batch 14/64 loss: 1.7491074800491333
Batch 15/64 loss: 1.755942702293396
Batch 16/64 loss: 1.7621701955795288
Batch 17/64 loss: 1.7502304315567017
Batch 18/64 loss: 1.7559077739715576
Batch 19/64 loss: 1.7533020973205566
Batch 20/64 loss: 1.7548173666000366
Batch 21/64 loss: 1.7495462894439697
Batch 22/64 loss: 1.7507309913635254
Batch 23/64 loss: 1.751185655593872
Batch 24/64 loss: 1.7483575344085693
Batch 25/64 loss: 1.7508010864257812
Batch 26/64 loss: 1.7512884140014648
Batch 27/64 loss: 1.7511155605316162
Batch 28/64 loss: 1.7503314018249512
Batch 29/64 loss: 1.7525124549865723
Batch 30/64 loss: 1.7519956827163696
Batch 31/64 loss: 1.7669588327407837
Batch 32/64 loss: 1.751490831375122
Batch 33/64 loss: 1.7559696435928345
Batch 34/64 loss: 1.7513612508773804
Batch 35/64 loss: 1.7518998384475708
Batch 36/64 loss: 1.7493726015090942
Batch 37/64 loss: 1.7525047063827515
Batch 38/64 loss: 1.7518948316574097
Batch 39/64 loss: 1.755083441734314
Batch 40/64 loss: 1.7569431066513062
Batch 41/64 loss: 1.7574734687805176
Batch 42/64 loss: 1.7518064975738525
Batch 43/64 loss: 1.7535150051116943
Batch 44/64 loss: 1.7546169757843018
Batch 45/64 loss: 1.7488889694213867
Batch 46/64 loss: 1.753065586090088
Batch 47/64 loss: 1.7542834281921387
Batch 48/64 loss: 1.7534868717193604
Batch 49/64 loss: 1.7506554126739502
Batch 50/64 loss: 1.7687450647354126
Batch 51/64 loss: 1.7516424655914307
Batch 52/64 loss: 1.7605252265930176
Batch 53/64 loss: 1.7575006484985352
Batch 54/64 loss: 1.7544686794281006
Batch 55/64 loss: 1.7557592391967773
Batch 56/64 loss: 1.7557460069656372
Batch 57/64 loss: 1.7548456192016602
Batch 58/64 loss: 1.7551170587539673
Batch 59/64 loss: 1.7560282945632935
Batch 60/64 loss: 1.7524223327636719
Batch 61/64 loss: 1.7551324367523193
Batch 62/64 loss: 1.757082223892212
Batch 63/64 loss: 1.7533245086669922
Batch 64/64 loss: 1.9554611444473267
Epoch 141  Train loss: 1.7558747773076975  Val loss: 1.7795019985474263
Epoch 142
-------------------------------
Batch 1/64 loss: 1.7561438083648682
Batch 2/64 loss: 1.7555955648422241
Batch 3/64 loss: 1.753474235534668
Batch 4/64 loss: 1.7611523866653442
Batch 5/64 loss: 1.7535837888717651
Batch 6/64 loss: 1.7580488920211792
Batch 7/64 loss: 1.7550359964370728
Batch 8/64 loss: 1.7509533166885376
Batch 9/64 loss: 1.7606170177459717
Batch 10/64 loss: 1.757407546043396
Batch 11/64 loss: 1.7578734159469604
Batch 12/64 loss: 1.7530268430709839
Batch 13/64 loss: 1.7532997131347656
Batch 14/64 loss: 1.7550327777862549
Batch 15/64 loss: 1.753509759902954
Batch 16/64 loss: 1.7565699815750122
Batch 17/64 loss: 1.7544612884521484
Batch 18/64 loss: 1.7601343393325806
Batch 19/64 loss: 1.7518681287765503
Batch 20/64 loss: 1.7679684162139893
Batch 21/64 loss: 1.7537577152252197
Batch 22/64 loss: 1.7523603439331055
Batch 23/64 loss: 1.751904010772705
Batch 24/64 loss: 1.7714715003967285
Batch 25/64 loss: 1.750516414642334
Batch 26/64 loss: 1.7529549598693848
Batch 27/64 loss: 1.7570819854736328
Batch 28/64 loss: 1.7597371339797974
Batch 29/64 loss: 1.7556171417236328
Batch 30/64 loss: 1.7540357112884521
Batch 31/64 loss: 1.7606127262115479
Batch 32/64 loss: 1.7546361684799194
Batch 33/64 loss: 1.7574844360351562
Batch 34/64 loss: 1.7586063146591187
Batch 35/64 loss: 1.7557975053787231
Batch 36/64 loss: 1.7590453624725342
Batch 37/64 loss: 1.7526638507843018
Batch 38/64 loss: 1.7626606225967407
Batch 39/64 loss: 1.751457929611206
Batch 40/64 loss: 1.7498559951782227
Batch 41/64 loss: 1.750483512878418
Batch 42/64 loss: 1.7546615600585938
Batch 43/64 loss: 1.7507481575012207
Batch 44/64 loss: 1.7507615089416504
Batch 45/64 loss: 1.757241129875183
Batch 46/64 loss: 1.7522940635681152
Batch 47/64 loss: 1.754918098449707
Batch 48/64 loss: 1.7540274858474731
Batch 49/64 loss: 1.7567063570022583
Batch 50/64 loss: 1.7518905401229858
Batch 51/64 loss: 1.753361463546753
Batch 52/64 loss: 1.7548625469207764
Batch 53/64 loss: 1.7538633346557617
Batch 54/64 loss: 1.7524476051330566
Batch 55/64 loss: 1.7519408464431763
Batch 56/64 loss: 1.7635293006896973
Batch 57/64 loss: 1.7544074058532715
Batch 58/64 loss: 1.7691550254821777
Batch 59/64 loss: 1.7557907104492188
Batch 60/64 loss: 1.756133794784546
Batch 61/64 loss: 1.7553880214691162
Batch 62/64 loss: 1.7593036890029907
Batch 63/64 loss: 1.756227731704712
Batch 64/64 loss: 1.9542860984802246
Epoch 142  Train loss: 1.7581784080056584  Val loss: 1.7775416964108182
Epoch 143
-------------------------------
Batch 1/64 loss: 1.7537215948104858
Batch 2/64 loss: 1.7607499361038208
Batch 3/64 loss: 1.755083441734314
Batch 4/64 loss: 1.7616643905639648
Batch 5/64 loss: 1.7642219066619873
Batch 6/64 loss: 1.7549290657043457
Batch 7/64 loss: 1.7615506649017334
Batch 8/64 loss: 1.76475989818573
Batch 9/64 loss: 1.7608370780944824
Batch 10/64 loss: 1.7539104223251343
Batch 11/64 loss: 1.7556408643722534
Batch 12/64 loss: 1.7626410722732544
Batch 13/64 loss: 1.755245327949524
Batch 14/64 loss: 1.756342887878418
Batch 15/64 loss: 1.7620816230773926
Batch 16/64 loss: 1.766213297843933
Batch 17/64 loss: 1.768092393875122
Batch 18/64 loss: 1.7637009620666504
Batch 19/64 loss: 1.764681100845337
Batch 20/64 loss: 1.7620694637298584
Batch 21/64 loss: 1.7580369710922241
Batch 22/64 loss: 1.7586781978607178
Batch 23/64 loss: 1.7658872604370117
Batch 24/64 loss: 1.757891058921814
Batch 25/64 loss: 1.7544111013412476
Batch 26/64 loss: 1.7633721828460693
Batch 27/64 loss: 1.7611052989959717
Batch 28/64 loss: 1.7660744190216064
Batch 29/64 loss: 1.7569875717163086
Batch 30/64 loss: 1.7615768909454346
Batch 31/64 loss: 1.7549982070922852
Batch 32/64 loss: 1.7555532455444336
Batch 33/64 loss: 1.7638344764709473
Batch 34/64 loss: 1.7586685419082642
Batch 35/64 loss: 1.7557172775268555
Batch 36/64 loss: 1.773683786392212
Batch 37/64 loss: 1.755243182182312
Batch 38/64 loss: 1.762529969215393
Batch 39/64 loss: 1.7563177347183228
Batch 40/64 loss: 1.755000352859497
Batch 41/64 loss: 1.7618128061294556
Batch 42/64 loss: 1.7561827898025513
Batch 43/64 loss: 1.7510802745819092
Batch 44/64 loss: 1.7709299325942993
Batch 45/64 loss: 1.7569360733032227
Batch 46/64 loss: 1.7547647953033447
Batch 47/64 loss: 1.7537981271743774
Batch 48/64 loss: 1.7558472156524658
Batch 49/64 loss: 1.7579857110977173
Batch 50/64 loss: 1.7524973154067993
Batch 51/64 loss: 1.7546619176864624
Batch 52/64 loss: 1.7599449157714844
Batch 53/64 loss: 1.7638683319091797
Batch 54/64 loss: 1.7601075172424316
Batch 55/64 loss: 1.7586276531219482
Batch 56/64 loss: 1.765154242515564
Batch 57/64 loss: 1.758680820465088
Batch 58/64 loss: 1.7617915868759155
Batch 59/64 loss: 1.7573882341384888
Batch 60/64 loss: 1.7655879259109497
Batch 61/64 loss: 1.7558883428573608
Batch 62/64 loss: 1.7564464807510376
Batch 63/64 loss: 1.7583855390548706
Batch 64/64 loss: 1.9561500549316406
Epoch 143  Train loss: 1.761869587617762  Val loss: 1.7786246853595746
Epoch 144
-------------------------------
Batch 1/64 loss: 1.7577611207962036
Batch 2/64 loss: 1.7556452751159668
Batch 3/64 loss: 1.7548935413360596
Batch 4/64 loss: 1.7546141147613525
Batch 5/64 loss: 1.7532236576080322
Batch 6/64 loss: 1.7587918043136597
Batch 7/64 loss: 1.7585419416427612
Batch 8/64 loss: 1.7519110441207886
Batch 9/64 loss: 1.75522780418396
Batch 10/64 loss: 1.8161007165908813
Batch 11/64 loss: 1.7582937479019165
Batch 12/64 loss: 1.75466787815094
Batch 13/64 loss: 1.7554571628570557
Batch 14/64 loss: 1.7610830068588257
Batch 15/64 loss: 1.7580697536468506
Batch 16/64 loss: 1.7618458271026611
Batch 17/64 loss: 1.7616117000579834
Batch 18/64 loss: 1.7568180561065674
Batch 19/64 loss: 1.7583993673324585
Batch 20/64 loss: 1.7585550546646118
Batch 21/64 loss: 1.7602635622024536
Batch 22/64 loss: 1.7614080905914307
Batch 23/64 loss: 1.7568355798721313
Batch 24/64 loss: 1.7584469318389893
Batch 25/64 loss: 1.756025791168213
Batch 26/64 loss: 1.7540955543518066
Batch 27/64 loss: 1.7748068571090698
Batch 28/64 loss: 1.7676082849502563
Batch 29/64 loss: 1.7645491361618042
Batch 30/64 loss: 1.7595256567001343
Batch 31/64 loss: 1.7588603496551514
Batch 32/64 loss: 1.7659833431243896
Batch 33/64 loss: 1.7573953866958618
Batch 34/64 loss: 1.7644330263137817
Batch 35/64 loss: 1.7687413692474365
Batch 36/64 loss: 1.760683536529541
Batch 37/64 loss: 1.7569998502731323
Batch 38/64 loss: 1.764155626296997
Batch 39/64 loss: 1.7542240619659424
Batch 40/64 loss: 1.7808772325515747
Batch 41/64 loss: 1.7627760171890259
Batch 42/64 loss: 1.759848952293396
Batch 43/64 loss: 1.7573356628417969
Batch 44/64 loss: 1.7591465711593628
Batch 45/64 loss: 1.7575361728668213
Batch 46/64 loss: 1.7613120079040527
Batch 47/64 loss: 1.7570152282714844
Batch 48/64 loss: 1.7552746534347534
Batch 49/64 loss: 1.759082317352295
Batch 50/64 loss: 1.7630369663238525
Batch 51/64 loss: 1.7530062198638916
Batch 52/64 loss: 1.7631157636642456
Batch 53/64 loss: 1.7536500692367554
Batch 54/64 loss: 1.7560995817184448
Batch 55/64 loss: 1.7557542324066162
Batch 56/64 loss: 1.7567309141159058
Batch 57/64 loss: 1.754062294960022
Batch 58/64 loss: 1.7682427167892456
Batch 59/64 loss: 1.7529124021530151
Batch 60/64 loss: 1.7558153867721558
Batch 61/64 loss: 1.7586567401885986
Batch 62/64 loss: 1.7545830011367798
Batch 63/64 loss: 1.755674123764038
Batch 64/64 loss: 1.953709602355957
Epoch 144  Train loss: 1.7622491294262457  Val loss: 1.7788728791004194
Epoch 145
-------------------------------
Batch 1/64 loss: 1.7634040117263794
Batch 2/64 loss: 1.75343656539917
Batch 3/64 loss: 1.7526674270629883
Batch 4/64 loss: 1.7541120052337646
Batch 5/64 loss: 1.762399435043335
Batch 6/64 loss: 1.7536145448684692
Batch 7/64 loss: 1.7629369497299194
Batch 8/64 loss: 1.754774570465088
Batch 9/64 loss: 1.7522339820861816
Batch 10/64 loss: 1.7673403024673462
Batch 11/64 loss: 1.755871057510376
Batch 12/64 loss: 1.7528060674667358
Batch 13/64 loss: 1.7531989812850952
Batch 14/64 loss: 1.757620930671692
Batch 15/64 loss: 1.7545539140701294
Batch 16/64 loss: 1.7521213293075562
Batch 17/64 loss: 1.7505801916122437
Batch 18/64 loss: 1.7523130178451538
Batch 19/64 loss: 1.7517677545547485
Batch 20/64 loss: 1.751990556716919
Batch 21/64 loss: 1.7547144889831543
Batch 22/64 loss: 1.7544496059417725
Batch 23/64 loss: 1.756348967552185
Batch 24/64 loss: 1.7545372247695923
Batch 25/64 loss: 1.7494232654571533
Batch 26/64 loss: 1.7515335083007812
Batch 27/64 loss: 1.7520203590393066
Batch 28/64 loss: 1.7516272068023682
Batch 29/64 loss: 1.7533977031707764
Batch 30/64 loss: 1.75126051902771
Batch 31/64 loss: 1.752679467201233
Batch 32/64 loss: 1.7529714107513428
Batch 33/64 loss: 1.7503156661987305
Batch 34/64 loss: 1.7647091150283813
Batch 35/64 loss: 1.7517192363739014
Batch 36/64 loss: 1.752548098564148
Batch 37/64 loss: 1.7499781847000122
Batch 38/64 loss: 1.7502062320709229
Batch 39/64 loss: 1.7515028715133667
Batch 40/64 loss: 1.7545552253723145
Batch 41/64 loss: 1.7510002851486206
Batch 42/64 loss: 1.7486076354980469
Batch 43/64 loss: 1.7491754293441772
Batch 44/64 loss: 1.7472978830337524
Batch 45/64 loss: 1.756160020828247
Batch 46/64 loss: 1.7547072172164917
Batch 47/64 loss: 1.7517613172531128
Batch 48/64 loss: 1.7554004192352295
Batch 49/64 loss: 1.7514690160751343
Batch 50/64 loss: 1.749674916267395
Batch 51/64 loss: 1.7498588562011719
Batch 52/64 loss: 1.749470591545105
Batch 53/64 loss: 1.7555941343307495
Batch 54/64 loss: 1.7494714260101318
Batch 55/64 loss: 1.7510288953781128
Batch 56/64 loss: 1.7533597946166992
Batch 57/64 loss: 1.752673864364624
Batch 58/64 loss: 1.7505234479904175
Batch 59/64 loss: 1.7645469903945923
Batch 60/64 loss: 1.7504405975341797
Batch 61/64 loss: 1.7513210773468018
Batch 62/64 loss: 1.7507718801498413
Batch 63/64 loss: 1.7663815021514893
Batch 64/64 loss: 1.9514696598052979
Epoch 145  Train loss: 1.755992806191538  Val loss: 1.7734754060961537
Epoch 146
-------------------------------
Batch 1/64 loss: 1.7516392469406128
Batch 2/64 loss: 1.7505334615707397
Batch 3/64 loss: 1.7492175102233887
Batch 4/64 loss: 1.7579970359802246
Batch 5/64 loss: 1.7507314682006836
Batch 6/64 loss: 1.7524316310882568
Batch 7/64 loss: 1.7517695426940918
Batch 8/64 loss: 1.7501646280288696
Batch 9/64 loss: 1.7494032382965088
Batch 10/64 loss: 1.7534717321395874
Batch 11/64 loss: 1.7537068128585815
Batch 12/64 loss: 1.7521867752075195
Batch 13/64 loss: 1.757876992225647
Batch 14/64 loss: 1.753936529159546
Batch 15/64 loss: 1.7559479475021362
Batch 16/64 loss: 1.7500388622283936
Batch 17/64 loss: 1.7589833736419678
Batch 18/64 loss: 1.7561944723129272
Batch 19/64 loss: 1.7547998428344727
Batch 20/64 loss: 1.7510781288146973
Batch 21/64 loss: 1.7543914318084717
Batch 22/64 loss: 1.7617912292480469
Batch 23/64 loss: 1.752546787261963
Batch 24/64 loss: 1.7585722208023071
Batch 25/64 loss: 1.7631111145019531
Batch 26/64 loss: 1.751469612121582
Batch 27/64 loss: 1.7533602714538574
Batch 28/64 loss: 1.7499384880065918
Batch 29/64 loss: 1.7524540424346924
Batch 30/64 loss: 1.7518706321716309
Batch 31/64 loss: 1.7515342235565186
Batch 32/64 loss: 1.7532637119293213
Batch 33/64 loss: 1.752205729484558
Batch 34/64 loss: 1.7688734531402588
Batch 35/64 loss: 1.7500159740447998
Batch 36/64 loss: 1.7558770179748535
Batch 37/64 loss: 1.7520103454589844
Batch 38/64 loss: 1.7544898986816406
Batch 39/64 loss: 1.7514339685440063
Batch 40/64 loss: 1.7524361610412598
Batch 41/64 loss: 1.7639802694320679
Batch 42/64 loss: 1.7524659633636475
Batch 43/64 loss: 1.7529785633087158
Batch 44/64 loss: 1.7490614652633667
Batch 45/64 loss: 1.7538628578186035
Batch 46/64 loss: 1.750272274017334
Batch 47/64 loss: 1.7495412826538086
Batch 48/64 loss: 1.7547640800476074
Batch 49/64 loss: 1.7512860298156738
Batch 50/64 loss: 1.755918264389038
Batch 51/64 loss: 1.7547962665557861
Batch 52/64 loss: 1.7545326948165894
Batch 53/64 loss: 1.7532163858413696
Batch 54/64 loss: 1.7520250082015991
Batch 55/64 loss: 1.7506425380706787
Batch 56/64 loss: 1.7494326829910278
Batch 57/64 loss: 1.7508453130722046
Batch 58/64 loss: 1.770359754562378
Batch 59/64 loss: 1.7602932453155518
Batch 60/64 loss: 1.7542258501052856
Batch 61/64 loss: 1.7521371841430664
Batch 62/64 loss: 1.7539689540863037
Batch 63/64 loss: 1.7537264823913574
Batch 64/64 loss: 1.9508681297302246
Epoch 146  Train loss: 1.7562547459321864  Val loss: 1.7716327565642156
Saving best model, epoch: 146
Epoch 147
-------------------------------
Batch 1/64 loss: 1.753016471862793
Batch 2/64 loss: 1.7499808073043823
Batch 3/64 loss: 1.7525458335876465
Batch 4/64 loss: 1.7560044527053833
Batch 5/64 loss: 1.754278540611267
Batch 6/64 loss: 1.7529284954071045
Batch 7/64 loss: 1.7523435354232788
Batch 8/64 loss: 1.75238037109375
Batch 9/64 loss: 1.7570762634277344
Batch 10/64 loss: 1.7565644979476929
Batch 11/64 loss: 1.754367709159851
Batch 12/64 loss: 1.7526862621307373
Batch 13/64 loss: 1.7537078857421875
Batch 14/64 loss: 1.755197286605835
Batch 15/64 loss: 1.7516380548477173
Batch 16/64 loss: 1.748387098312378
Batch 17/64 loss: 1.7534617185592651
Batch 18/64 loss: 1.7500537633895874
Batch 19/64 loss: 1.7691845893859863
Batch 20/64 loss: 1.752726674079895
Batch 21/64 loss: 1.7585690021514893
Batch 22/64 loss: 1.7550559043884277
Batch 23/64 loss: 1.751318097114563
Batch 24/64 loss: 1.756408452987671
Batch 25/64 loss: 1.753617525100708
Batch 26/64 loss: 1.753416657447815
Batch 27/64 loss: 1.7663522958755493
Batch 28/64 loss: 1.749692678451538
Batch 29/64 loss: 1.7504160404205322
Batch 30/64 loss: 1.7542457580566406
Batch 31/64 loss: 1.7506228685379028
Batch 32/64 loss: 1.750329613685608
Batch 33/64 loss: 1.75408935546875
Batch 34/64 loss: 1.7539693117141724
Batch 35/64 loss: 1.754854440689087
Batch 36/64 loss: 1.7545275688171387
Batch 37/64 loss: 1.7550363540649414
Batch 38/64 loss: 1.7537890672683716
Batch 39/64 loss: 1.7509082555770874
Batch 40/64 loss: 1.7503695487976074
Batch 41/64 loss: 1.7487972974777222
Batch 42/64 loss: 1.7529222965240479
Batch 43/64 loss: 1.7593661546707153
Batch 44/64 loss: 1.7538703680038452
Batch 45/64 loss: 1.7516822814941406
Batch 46/64 loss: 1.757662296295166
Batch 47/64 loss: 1.7552999258041382
Batch 48/64 loss: 1.7522997856140137
Batch 49/64 loss: 1.7539818286895752
Batch 50/64 loss: 1.7596734762191772
Batch 51/64 loss: 1.7532978057861328
Batch 52/64 loss: 1.7544571161270142
Batch 53/64 loss: 1.7492001056671143
Batch 54/64 loss: 1.753967523574829
Batch 55/64 loss: 1.7501420974731445
Batch 56/64 loss: 1.7594026327133179
Batch 57/64 loss: 1.7525204420089722
Batch 58/64 loss: 1.7548123598098755
Batch 59/64 loss: 1.7649521827697754
Batch 60/64 loss: 1.7517728805541992
Batch 61/64 loss: 1.7480477094650269
Batch 62/64 loss: 1.7547812461853027
Batch 63/64 loss: 1.7562862634658813
Batch 64/64 loss: 1.9479351043701172
Epoch 147  Train loss: 1.7563335923587575  Val loss: 1.7742999853547086
Epoch 148
-------------------------------
Batch 1/64 loss: 1.7531625032424927
Batch 2/64 loss: 1.751284122467041
Batch 3/64 loss: 1.753226399421692
Batch 4/64 loss: 1.7494964599609375
Batch 5/64 loss: 1.7547662258148193
Batch 6/64 loss: 1.7518846988677979
Batch 7/64 loss: 1.7509126663208008
Batch 8/64 loss: 1.7511341571807861
Batch 9/64 loss: 1.7503564357757568
Batch 10/64 loss: 1.7519361972808838
Batch 11/64 loss: 1.7537119388580322
Batch 12/64 loss: 1.7547345161437988
Batch 13/64 loss: 1.753982424736023
Batch 14/64 loss: 1.7521032094955444
Batch 15/64 loss: 1.752495527267456
Batch 16/64 loss: 1.7679048776626587
Batch 17/64 loss: 1.7656546831130981
Batch 18/64 loss: 1.7541940212249756
Batch 19/64 loss: 1.752472162246704
Batch 20/64 loss: 1.7520241737365723
Batch 21/64 loss: 1.7511405944824219
Batch 22/64 loss: 1.7552779912948608
Batch 23/64 loss: 1.75809645652771
Batch 24/64 loss: 1.753076195716858
Batch 25/64 loss: 1.7569326162338257
Batch 26/64 loss: 1.757918119430542
Batch 27/64 loss: 1.7521077394485474
Batch 28/64 loss: 1.7551112174987793
Batch 29/64 loss: 1.7513401508331299
Batch 30/64 loss: 1.7512532472610474
Batch 31/64 loss: 1.7525966167449951
Batch 32/64 loss: 1.7522642612457275
Batch 33/64 loss: 1.7503979206085205
Batch 34/64 loss: 1.7582390308380127
Batch 35/64 loss: 1.7557826042175293
Batch 36/64 loss: 1.7564969062805176
Batch 37/64 loss: 1.7575418949127197
Batch 38/64 loss: 1.7525261640548706
Batch 39/64 loss: 1.754431962966919
Batch 40/64 loss: 1.756709337234497
Batch 41/64 loss: 1.756087303161621
Batch 42/64 loss: 1.7553727626800537
Batch 43/64 loss: 1.758064866065979
Batch 44/64 loss: 1.7525060176849365
Batch 45/64 loss: 1.7691841125488281
Batch 46/64 loss: 1.752610445022583
Batch 47/64 loss: 1.7531293630599976
Batch 48/64 loss: 1.7524670362472534
Batch 49/64 loss: 1.7581391334533691
Batch 50/64 loss: 1.7523084878921509
Batch 51/64 loss: 1.752958059310913
Batch 52/64 loss: 1.7523150444030762
Batch 53/64 loss: 1.7542152404785156
Batch 54/64 loss: 1.750316858291626
Batch 55/64 loss: 1.761070728302002
Batch 56/64 loss: 1.75369393825531
Batch 57/64 loss: 1.7517271041870117
Batch 58/64 loss: 1.7492023706436157
Batch 59/64 loss: 1.7530484199523926
Batch 60/64 loss: 1.752625823020935
Batch 61/64 loss: 1.7518351078033447
Batch 62/64 loss: 1.7490794658660889
Batch 63/64 loss: 1.7504712343215942
Batch 64/64 loss: 1.9523532390594482
Epoch 148  Train loss: 1.7564450553819244  Val loss: 1.772602204195003
Epoch 149
-------------------------------
Batch 1/64 loss: 1.7518370151519775
Batch 2/64 loss: 1.749708890914917
Batch 3/64 loss: 1.7499984502792358
Batch 4/64 loss: 1.7575592994689941
Batch 5/64 loss: 1.752288579940796
Batch 6/64 loss: 1.7515110969543457
Batch 7/64 loss: 1.755530834197998
Batch 8/64 loss: 1.7537001371383667
Batch 9/64 loss: 1.7560218572616577
Batch 10/64 loss: 1.7504016160964966
Batch 11/64 loss: 1.7475128173828125
Batch 12/64 loss: 1.7535202503204346
Batch 13/64 loss: 1.7543752193450928
Batch 14/64 loss: 1.7538275718688965
Batch 15/64 loss: 1.75217866897583
Batch 16/64 loss: 1.7585480213165283
Batch 17/64 loss: 1.751640796661377
Batch 18/64 loss: 1.7535946369171143
Batch 19/64 loss: 1.752091407775879
Batch 20/64 loss: 1.7607818841934204
Batch 21/64 loss: 1.751593828201294
Batch 22/64 loss: 1.7500255107879639
Batch 23/64 loss: 1.7532669305801392
Batch 24/64 loss: 1.752578616142273
Batch 25/64 loss: 1.7544753551483154
Batch 26/64 loss: 1.7543914318084717
Batch 27/64 loss: 1.753117322921753
Batch 28/64 loss: 1.75706148147583
Batch 29/64 loss: 1.7493388652801514
Batch 30/64 loss: 1.754404902458191
Batch 31/64 loss: 1.7529358863830566
Batch 32/64 loss: 1.751258134841919
Batch 33/64 loss: 1.7550930976867676
Batch 34/64 loss: 1.7555031776428223
Batch 35/64 loss: 1.7519670724868774
Batch 36/64 loss: 1.748577356338501
Batch 37/64 loss: 1.7510061264038086
Batch 38/64 loss: 1.7672423124313354
Batch 39/64 loss: 1.7573604583740234
Batch 40/64 loss: 1.7539076805114746
Batch 41/64 loss: 1.7527410984039307
Batch 42/64 loss: 1.752282977104187
Batch 43/64 loss: 1.7572603225708008
Batch 44/64 loss: 1.7689499855041504
Batch 45/64 loss: 1.7623929977416992
Batch 46/64 loss: 1.752110242843628
Batch 47/64 loss: 1.7596819400787354
Batch 48/64 loss: 1.753043293952942
Batch 49/64 loss: 1.7551376819610596
Batch 50/64 loss: 1.7644124031066895
Batch 51/64 loss: 1.7568737268447876
Batch 52/64 loss: 1.7546639442443848
Batch 53/64 loss: 1.75750732421875
Batch 54/64 loss: 1.7760138511657715
Batch 55/64 loss: 1.7608389854431152
Batch 56/64 loss: 1.762083888053894
Batch 57/64 loss: 1.7571144104003906
Batch 58/64 loss: 1.7566274404525757
Batch 59/64 loss: 1.7548365592956543
Batch 60/64 loss: 1.7638258934020996
Batch 61/64 loss: 1.7558140754699707
Batch 62/64 loss: 1.755344271659851
Batch 63/64 loss: 1.7550297975540161
Batch 64/64 loss: 1.952499270439148
Epoch 149  Train loss: 1.7576579790489346  Val loss: 1.7721831347934158
Epoch 150
-------------------------------
Batch 1/64 loss: 1.748382806777954
Batch 2/64 loss: 1.7545247077941895
Batch 3/64 loss: 1.7541661262512207
Batch 4/64 loss: 1.7559118270874023
Batch 5/64 loss: 1.7572017908096313
Batch 6/64 loss: 1.7535245418548584
Batch 7/64 loss: 1.755537509918213
Batch 8/64 loss: 1.753090739250183
Batch 9/64 loss: 1.7635786533355713
Batch 10/64 loss: 1.7542674541473389
Batch 11/64 loss: 1.7499244213104248
Batch 12/64 loss: 1.7545804977416992
Batch 13/64 loss: 1.7498795986175537
Batch 14/64 loss: 1.7564135789871216
Batch 15/64 loss: 1.7582192420959473
Batch 16/64 loss: 1.7551403045654297
Batch 17/64 loss: 1.7528778314590454
Batch 18/64 loss: 1.7522698640823364
Batch 19/64 loss: 1.7501856088638306
Batch 20/64 loss: 1.7564696073532104
Batch 21/64 loss: 1.7487165927886963
Batch 22/64 loss: 1.7534856796264648
Batch 23/64 loss: 1.756247639656067
Batch 24/64 loss: 1.751800537109375
Batch 25/64 loss: 1.756160020828247
Batch 26/64 loss: 1.7514981031417847
Batch 27/64 loss: 1.757421612739563
Batch 28/64 loss: 1.7509998083114624
Batch 29/64 loss: 1.756471872329712
Batch 30/64 loss: 1.7584741115570068
Batch 31/64 loss: 1.7532329559326172
Batch 32/64 loss: 1.7527811527252197
Batch 33/64 loss: 1.7511941194534302
Batch 34/64 loss: 1.7693637609481812
Batch 35/64 loss: 1.755678653717041
Batch 36/64 loss: 1.7499399185180664
Batch 37/64 loss: 1.7533721923828125
Batch 38/64 loss: 1.7547855377197266
Batch 39/64 loss: 1.7547863721847534
Batch 40/64 loss: 1.7544382810592651
Batch 41/64 loss: 1.7512586116790771
Batch 42/64 loss: 1.7498363256454468
Batch 43/64 loss: 1.7566372156143188
Batch 44/64 loss: 1.7618941068649292
Batch 45/64 loss: 1.7541930675506592
Batch 46/64 loss: 1.7525231838226318
Batch 47/64 loss: 1.7572431564331055
Batch 48/64 loss: 1.7604281902313232
Batch 49/64 loss: 1.7523119449615479
Batch 50/64 loss: 1.7706915140151978
Batch 51/64 loss: 1.7490088939666748
Batch 52/64 loss: 1.7525795698165894
Batch 53/64 loss: 1.7496888637542725
Batch 54/64 loss: 1.7535111904144287
Batch 55/64 loss: 1.7570090293884277
Batch 56/64 loss: 1.7535065412521362
Batch 57/64 loss: 1.754215955734253
Batch 58/64 loss: 1.7498464584350586
Batch 59/64 loss: 1.7518343925476074
Batch 60/64 loss: 1.753732442855835
Batch 61/64 loss: 1.7532730102539062
Batch 62/64 loss: 1.7503303289413452
Batch 63/64 loss: 1.7526257038116455
Batch 64/64 loss: 1.9510713815689087
Epoch 150  Train loss: 1.756682021477643  Val loss: 1.7748971378680356
Epoch 151
-------------------------------
Batch 1/64 loss: 1.7528033256530762
Batch 2/64 loss: 1.7516608238220215
Batch 3/64 loss: 1.754462718963623
Batch 4/64 loss: 1.750214695930481
Batch 5/64 loss: 1.7521378993988037
Batch 6/64 loss: 1.7542476654052734
Batch 7/64 loss: 1.7513642311096191
Batch 8/64 loss: 1.7526735067367554
Batch 9/64 loss: 1.7540777921676636
Batch 10/64 loss: 1.7478463649749756
Batch 11/64 loss: 1.7527296543121338
Batch 12/64 loss: 1.7486953735351562
Batch 13/64 loss: 1.7555186748504639
Batch 14/64 loss: 1.7532958984375
Batch 15/64 loss: 1.7520962953567505
Batch 16/64 loss: 1.7485249042510986
Batch 17/64 loss: 1.7507734298706055
Batch 18/64 loss: 1.750434160232544
Batch 19/64 loss: 1.75114107131958
Batch 20/64 loss: 1.7507946491241455
Batch 21/64 loss: 1.7517001628875732
Batch 22/64 loss: 1.7646915912628174
Batch 23/64 loss: 1.7565902471542358
Batch 24/64 loss: 1.7466089725494385
Batch 25/64 loss: 1.7489304542541504
Batch 26/64 loss: 1.757817029953003
Batch 27/64 loss: 1.751251220703125
Batch 28/64 loss: 1.7555761337280273
Batch 29/64 loss: 1.7525737285614014
Batch 30/64 loss: 1.759929895401001
Batch 31/64 loss: 1.7650312185287476
Batch 32/64 loss: 1.7532765865325928
Batch 33/64 loss: 1.7533458471298218
Batch 34/64 loss: 1.7550362348556519
Batch 35/64 loss: 1.7552484273910522
Batch 36/64 loss: 1.7519663572311401
Batch 37/64 loss: 1.751150369644165
Batch 38/64 loss: 1.7519561052322388
Batch 39/64 loss: 1.7540018558502197
Batch 40/64 loss: 1.753568410873413
Batch 41/64 loss: 1.752795696258545
Batch 42/64 loss: 1.752630591392517
Batch 43/64 loss: 1.7594935894012451
Batch 44/64 loss: 1.7558670043945312
Batch 45/64 loss: 1.7523314952850342
Batch 46/64 loss: 1.7526121139526367
Batch 47/64 loss: 1.7518160343170166
Batch 48/64 loss: 1.75072181224823
Batch 49/64 loss: 1.7528071403503418
Batch 50/64 loss: 1.7561525106430054
Batch 51/64 loss: 1.7529975175857544
Batch 52/64 loss: 1.7506588697433472
Batch 53/64 loss: 1.7512658834457397
Batch 54/64 loss: 1.753480315208435
Batch 55/64 loss: 1.7517130374908447
Batch 56/64 loss: 1.7527474164962769
Batch 57/64 loss: 1.7636466026306152
Batch 58/64 loss: 1.7518562078475952
Batch 59/64 loss: 1.7567744255065918
Batch 60/64 loss: 1.7526345252990723
Batch 61/64 loss: 1.7493793964385986
Batch 62/64 loss: 1.7473785877227783
Batch 63/64 loss: 1.749958872795105
Batch 64/64 loss: 1.949344515800476
Epoch 151  Train loss: 1.7554426983291027  Val loss: 1.7726723852845812
Epoch 152
-------------------------------
Batch 1/64 loss: 1.7483749389648438
Batch 2/64 loss: 1.7492916584014893
Batch 3/64 loss: 1.7498083114624023
Batch 4/64 loss: 1.751046061515808
Batch 5/64 loss: 1.7497456073760986
Batch 6/64 loss: 1.7512125968933105
Batch 7/64 loss: 1.747239589691162
Batch 8/64 loss: 1.7510851621627808
Batch 9/64 loss: 1.748429536819458
Batch 10/64 loss: 1.7548117637634277
Batch 11/64 loss: 1.749563217163086
Batch 12/64 loss: 1.7497247457504272
Batch 13/64 loss: 1.7566602230072021
Batch 14/64 loss: 1.75994873046875
Batch 15/64 loss: 1.7530498504638672
Batch 16/64 loss: 1.7538254261016846
Batch 17/64 loss: 1.7499172687530518
Batch 18/64 loss: 1.7870545387268066
Batch 19/64 loss: 1.7667213678359985
Batch 20/64 loss: 1.7969889640808105
Batch 21/64 loss: 1.8065153360366821
Batch 22/64 loss: 1.817787528038025
Batch 23/64 loss: 1.798490047454834
Batch 24/64 loss: 1.7995613813400269
Batch 25/64 loss: 1.7986209392547607
Batch 26/64 loss: 1.7958813905715942
Batch 27/64 loss: 1.7948896884918213
Batch 28/64 loss: 1.8009026050567627
Batch 29/64 loss: 1.8109122514724731
Batch 30/64 loss: 1.7944402694702148
Batch 31/64 loss: 1.788517713546753
Batch 32/64 loss: 1.7914868593215942
Batch 33/64 loss: 1.7859898805618286
Batch 34/64 loss: 1.7841212749481201
Batch 35/64 loss: 1.799156904220581
Batch 36/64 loss: 1.7916653156280518
Batch 37/64 loss: 1.8314406871795654
Batch 38/64 loss: 1.7809412479400635
Batch 39/64 loss: 1.7848378419876099
Batch 40/64 loss: 1.796990156173706
Batch 41/64 loss: 1.7874754667282104
Batch 42/64 loss: 1.7813491821289062
Batch 43/64 loss: 1.7755448818206787
Batch 44/64 loss: 1.772127628326416
Batch 45/64 loss: 1.7749561071395874
Batch 46/64 loss: 1.768688678741455
Batch 47/64 loss: 1.7922160625457764
Batch 48/64 loss: 1.7855560779571533
Batch 49/64 loss: 1.7812283039093018
Batch 50/64 loss: 1.7694199085235596
Batch 51/64 loss: 1.775393009185791
Batch 52/64 loss: 1.770005226135254
Batch 53/64 loss: 1.7746005058288574
Batch 54/64 loss: 1.7701948881149292
Batch 55/64 loss: 1.7661906480789185
Batch 56/64 loss: 1.768153429031372
Batch 57/64 loss: 1.7668375968933105
Batch 58/64 loss: 1.767122745513916
Batch 59/64 loss: 1.7670741081237793
Batch 60/64 loss: 1.7677855491638184
Batch 61/64 loss: 1.7708532810211182
Batch 62/64 loss: 1.7658871412277222
Batch 63/64 loss: 1.7603768110275269
Batch 64/64 loss: 1.9660320281982422
Epoch 152  Train loss: 1.777744472728056  Val loss: 1.78200589340577
Epoch 153
-------------------------------
Batch 1/64 loss: 1.7616981267929077
Batch 2/64 loss: 1.7666497230529785
Batch 3/64 loss: 1.7601356506347656
Batch 4/64 loss: 1.7655965089797974
Batch 5/64 loss: 1.779127836227417
Batch 6/64 loss: 1.765370488166809
Batch 7/64 loss: 1.763931155204773
Batch 8/64 loss: 1.7673242092132568
Batch 9/64 loss: 1.76185142993927
Batch 10/64 loss: 1.7618014812469482
Batch 11/64 loss: 1.7661937475204468
Batch 12/64 loss: 1.7599481344223022
Batch 13/64 loss: 1.7606009244918823
Batch 14/64 loss: 1.7629671096801758
Batch 15/64 loss: 1.7619649171829224
Batch 16/64 loss: 1.7633640766143799
Batch 17/64 loss: 1.7574634552001953
Batch 18/64 loss: 1.7581069469451904
Batch 19/64 loss: 1.7591801881790161
Batch 20/64 loss: 1.7625051736831665
Batch 21/64 loss: 1.761345624923706
Batch 22/64 loss: 1.7590320110321045
Batch 23/64 loss: 1.7586278915405273
Batch 24/64 loss: 1.7566317319869995
Batch 25/64 loss: 1.7601902484893799
Batch 26/64 loss: 1.7551307678222656
Batch 27/64 loss: 1.754202127456665
Batch 28/64 loss: 1.75552499294281
Batch 29/64 loss: 1.7557061910629272
Batch 30/64 loss: 1.7529689073562622
Batch 31/64 loss: 1.7610266208648682
Batch 32/64 loss: 1.7765673398971558
Batch 33/64 loss: 1.7626856565475464
Batch 34/64 loss: 1.777217984199524
Batch 35/64 loss: 1.752362608909607
Batch 36/64 loss: 1.7524701356887817
Batch 37/64 loss: 1.7558904886245728
Batch 38/64 loss: 1.7520818710327148
Batch 39/64 loss: 1.7534000873565674
Batch 40/64 loss: 1.7573633193969727
Batch 41/64 loss: 1.7565815448760986
Batch 42/64 loss: 1.7603603601455688
Batch 43/64 loss: 1.7567493915557861
Batch 44/64 loss: 1.7557281255722046
Batch 45/64 loss: 1.7548491954803467
Batch 46/64 loss: 1.7605509757995605
Batch 47/64 loss: 1.7585173845291138
Batch 48/64 loss: 1.7551857233047485
Batch 49/64 loss: 1.7558417320251465
Batch 50/64 loss: 1.7595521211624146
Batch 51/64 loss: 1.7623412609100342
Batch 52/64 loss: 1.7610840797424316
Batch 53/64 loss: 1.7551681995391846
Batch 54/64 loss: 1.756555199623108
Batch 55/64 loss: 1.751910924911499
Batch 56/64 loss: 1.7530440092086792
Batch 57/64 loss: 1.7553315162658691
Batch 58/64 loss: 1.7573522329330444
Batch 59/64 loss: 1.757239818572998
Batch 60/64 loss: 1.7590198516845703
Batch 61/64 loss: 1.7539246082305908
Batch 62/64 loss: 1.7575750350952148
Batch 63/64 loss: 1.7584956884384155
Batch 64/64 loss: 1.9544692039489746
Epoch 153  Train loss: 1.7618042160482967  Val loss: 1.7794686469835104
Epoch 154
-------------------------------
Batch 1/64 loss: 1.7532048225402832
Batch 2/64 loss: 1.7575093507766724
Batch 3/64 loss: 1.75130295753479
Batch 4/64 loss: 1.754723072052002
Batch 5/64 loss: 1.7550156116485596
Batch 6/64 loss: 1.755906343460083
Batch 7/64 loss: 1.761132001876831
Batch 8/64 loss: 1.754521131515503
Batch 9/64 loss: 1.7565197944641113
Batch 10/64 loss: 1.752225399017334
Batch 11/64 loss: 1.758528709411621
Batch 12/64 loss: 1.7552677392959595
Batch 13/64 loss: 1.7590750455856323
Batch 14/64 loss: 1.7503823041915894
Batch 15/64 loss: 1.752987027168274
Batch 16/64 loss: 1.752028226852417
Batch 17/64 loss: 1.7633135318756104
Batch 18/64 loss: 1.7590421438217163
Batch 19/64 loss: 1.754401445388794
Batch 20/64 loss: 1.7567452192306519
Batch 21/64 loss: 1.7517082691192627
Batch 22/64 loss: 1.7564319372177124
Batch 23/64 loss: 1.7562984228134155
Batch 24/64 loss: 1.7648183107376099
Batch 25/64 loss: 1.754979133605957
Batch 26/64 loss: 1.755528450012207
Batch 27/64 loss: 1.7540239095687866
Batch 28/64 loss: 1.7602649927139282
Batch 29/64 loss: 1.76906156539917
Batch 30/64 loss: 1.754319667816162
Batch 31/64 loss: 1.756692886352539
Batch 32/64 loss: 1.7589105367660522
Batch 33/64 loss: 1.758054494857788
Batch 34/64 loss: 1.7517660856246948
Batch 35/64 loss: 1.756892442703247
Batch 36/64 loss: 1.7495967149734497
Batch 37/64 loss: 1.756109595298767
Batch 38/64 loss: 1.7518136501312256
Batch 39/64 loss: 1.7640635967254639
Batch 40/64 loss: 1.759211778640747
Batch 41/64 loss: 1.7556159496307373
Batch 42/64 loss: 1.7518677711486816
Batch 43/64 loss: 1.7549238204956055
Batch 44/64 loss: 1.7708430290222168
Batch 45/64 loss: 1.75835382938385
Batch 46/64 loss: 1.7525442838668823
Batch 47/64 loss: 1.7537696361541748
Batch 48/64 loss: 1.7578580379486084
Batch 49/64 loss: 1.7535552978515625
Batch 50/64 loss: 1.7672021389007568
Batch 51/64 loss: 1.7533832788467407
Batch 52/64 loss: 1.7560484409332275
Batch 53/64 loss: 1.7548596858978271
Batch 54/64 loss: 1.7644163370132446
Batch 55/64 loss: 1.7586348056793213
Batch 56/64 loss: 1.754427433013916
Batch 57/64 loss: 1.7518974542617798
Batch 58/64 loss: 1.7540295124053955
Batch 59/64 loss: 1.7555646896362305
Batch 60/64 loss: 1.7545830011367798
Batch 61/64 loss: 1.7539949417114258
Batch 62/64 loss: 1.7575809955596924
Batch 63/64 loss: 1.7690240144729614
Batch 64/64 loss: 1.9589033126831055
Epoch 154  Train loss: 1.7590358304042442  Val loss: 1.781533376457765
Epoch 155
-------------------------------
Batch 1/64 loss: 1.7586675882339478
Batch 2/64 loss: 1.7569321393966675
Batch 3/64 loss: 1.760514497756958
Batch 4/64 loss: 1.7553818225860596
Batch 5/64 loss: 1.7545775175094604
Batch 6/64 loss: 1.7519482374191284
Batch 7/64 loss: 1.7531489133834839
Batch 8/64 loss: 1.7549747228622437
Batch 9/64 loss: 1.7585872411727905
Batch 10/64 loss: 1.7523932456970215
Batch 11/64 loss: 1.751936435699463
Batch 12/64 loss: 1.7523038387298584
Batch 13/64 loss: 1.7549818754196167
Batch 14/64 loss: 1.756340742111206
Batch 15/64 loss: 1.7549077272415161
Batch 16/64 loss: 1.754274606704712
Batch 17/64 loss: 1.760148048400879
Batch 18/64 loss: 1.7540805339813232
Batch 19/64 loss: 1.7516758441925049
Batch 20/64 loss: 1.756422996520996
Batch 21/64 loss: 1.755564570426941
Batch 22/64 loss: 1.752106785774231
Batch 23/64 loss: 1.751029133796692
Batch 24/64 loss: 1.7505971193313599
Batch 25/64 loss: 1.7631163597106934
Batch 26/64 loss: 1.7561434507369995
Batch 27/64 loss: 1.7551153898239136
Batch 28/64 loss: 1.7560060024261475
Batch 29/64 loss: 1.755135178565979
Batch 30/64 loss: 1.7591122388839722
Batch 31/64 loss: 1.7574503421783447
Batch 32/64 loss: 1.755462408065796
Batch 33/64 loss: 1.7514967918395996
Batch 34/64 loss: 1.759313702583313
Batch 35/64 loss: 1.765981674194336
Batch 36/64 loss: 1.7558553218841553
Batch 37/64 loss: 1.7573539018630981
Batch 38/64 loss: 1.7553975582122803
Batch 39/64 loss: 1.7512671947479248
Batch 40/64 loss: 1.755009412765503
Batch 41/64 loss: 1.7617480754852295
Batch 42/64 loss: 1.7730967998504639
Batch 43/64 loss: 1.752353549003601
Batch 44/64 loss: 1.766855239868164
Batch 45/64 loss: 1.756291151046753
Batch 46/64 loss: 1.752878189086914
Batch 47/64 loss: 1.7577555179595947
Batch 48/64 loss: 1.7592335939407349
Batch 49/64 loss: 1.758102536201477
Batch 50/64 loss: 1.753737449645996
Batch 51/64 loss: 1.7528444528579712
Batch 52/64 loss: 1.7536592483520508
Batch 53/64 loss: 1.7519323825836182
Batch 54/64 loss: 1.7533248662948608
Batch 55/64 loss: 1.7536619901657104
Batch 56/64 loss: 1.7547938823699951
Batch 57/64 loss: 1.7526839971542358
Batch 58/64 loss: 1.7509634494781494
Batch 59/64 loss: 1.7521538734436035
Batch 60/64 loss: 1.7547476291656494
Batch 61/64 loss: 1.7529600858688354
Batch 62/64 loss: 1.7529008388519287
Batch 63/64 loss: 1.7492510080337524
Batch 64/64 loss: 1.9469614028930664
Epoch 155  Train loss: 1.7578174740660424  Val loss: 1.7698873596912397
Saving best model, epoch: 155
Epoch 156
-------------------------------
Batch 1/64 loss: 1.7490471601486206
Batch 2/64 loss: 1.7487866878509521
Batch 3/64 loss: 1.751865029335022
Batch 4/64 loss: 1.7530044317245483
Batch 5/64 loss: 1.749792218208313
Batch 6/64 loss: 1.7517551183700562
Batch 7/64 loss: 1.7617543935775757
Batch 8/64 loss: 1.7494869232177734
Batch 9/64 loss: 1.750357985496521
Batch 10/64 loss: 1.7563397884368896
Batch 11/64 loss: 1.7474408149719238
Batch 12/64 loss: 1.7486087083816528
Batch 13/64 loss: 1.75425386428833
Batch 14/64 loss: 1.7486038208007812
Batch 15/64 loss: 1.7463552951812744
Batch 16/64 loss: 1.749128818511963
Batch 17/64 loss: 1.746794581413269
Batch 18/64 loss: 1.7515473365783691
Batch 19/64 loss: 1.7579751014709473
Batch 20/64 loss: 1.7492916584014893
Batch 21/64 loss: 1.7492527961730957
Batch 22/64 loss: 1.7496531009674072
Batch 23/64 loss: 1.7495523691177368
Batch 24/64 loss: 1.7531923055648804
Batch 25/64 loss: 1.7463116645812988
Batch 26/64 loss: 1.7498855590820312
Batch 27/64 loss: 1.7486921548843384
Batch 28/64 loss: 1.7479166984558105
Batch 29/64 loss: 1.7510955333709717
Batch 30/64 loss: 1.7493069171905518
Batch 31/64 loss: 1.7537198066711426
Batch 32/64 loss: 1.7520331144332886
Batch 33/64 loss: 1.7510875463485718
Batch 34/64 loss: 1.754859209060669
Batch 35/64 loss: 1.7544550895690918
Batch 36/64 loss: 1.7557792663574219
Batch 37/64 loss: 1.7494189739227295
Batch 38/64 loss: 1.7518360614776611
Batch 39/64 loss: 1.7497082948684692
Batch 40/64 loss: 1.752089262008667
Batch 41/64 loss: 1.7466236352920532
Batch 42/64 loss: 1.7603596448898315
Batch 43/64 loss: 1.7822222709655762
Batch 44/64 loss: 1.755321979522705
Batch 45/64 loss: 1.7533528804779053
Batch 46/64 loss: 1.7496131658554077
Batch 47/64 loss: 1.7534503936767578
Batch 48/64 loss: 1.7526493072509766
Batch 49/64 loss: 1.7512930631637573
Batch 50/64 loss: 1.7500808238983154
Batch 51/64 loss: 1.7505042552947998
Batch 52/64 loss: 1.748093843460083
Batch 53/64 loss: 1.7498419284820557
Batch 54/64 loss: 1.752902865409851
Batch 55/64 loss: 1.750405192375183
Batch 56/64 loss: 1.7512264251708984
Batch 57/64 loss: 1.7549854516983032
Batch 58/64 loss: 1.7507860660552979
Batch 59/64 loss: 1.7528085708618164
Batch 60/64 loss: 1.7514292001724243
Batch 61/64 loss: 1.7542511224746704
Batch 62/64 loss: 1.7494428157806396
Batch 63/64 loss: 1.7537178993225098
Batch 64/64 loss: 1.947208046913147
Epoch 156  Train loss: 1.7541616360346477  Val loss: 1.7742526121565567
Epoch 157
-------------------------------
Batch 1/64 loss: 1.7481688261032104
Batch 2/64 loss: 1.7494596242904663
Batch 3/64 loss: 1.7545040845870972
Batch 4/64 loss: 1.7506401538848877
Batch 5/64 loss: 1.7507328987121582
Batch 6/64 loss: 1.7577749490737915
Batch 7/64 loss: 1.7478984594345093
Batch 8/64 loss: 1.751444697380066
Batch 9/64 loss: 1.7586790323257446
Batch 10/64 loss: 1.7482900619506836
Batch 11/64 loss: 1.7486438751220703
Batch 12/64 loss: 1.7517518997192383
Batch 13/64 loss: 1.7509037256240845
Batch 14/64 loss: 1.751315951347351
Batch 15/64 loss: 1.753506064414978
Batch 16/64 loss: 1.7539483308792114
Batch 17/64 loss: 1.756627082824707
Batch 18/64 loss: 1.7511528730392456
Batch 19/64 loss: 1.7579551935195923
Batch 20/64 loss: 1.7553342580795288
Batch 21/64 loss: 1.7507778406143188
Batch 22/64 loss: 1.7527685165405273
Batch 23/64 loss: 1.7586264610290527
Batch 24/64 loss: 1.7725508213043213
Batch 25/64 loss: 1.761205792427063
Batch 26/64 loss: 1.7527555227279663
Batch 27/64 loss: 1.751534342765808
Batch 28/64 loss: 1.7532881498336792
Batch 29/64 loss: 1.757481336593628
Batch 30/64 loss: 1.7497999668121338
Batch 31/64 loss: 1.75252366065979
Batch 32/64 loss: 1.7550971508026123
Batch 33/64 loss: 1.7516459226608276
Batch 34/64 loss: 1.7515159845352173
Batch 35/64 loss: 1.7665587663650513
Batch 36/64 loss: 1.7534114122390747
Batch 37/64 loss: 1.75044584274292
Batch 38/64 loss: 1.7532103061676025
Batch 39/64 loss: 1.7487356662750244
Batch 40/64 loss: 1.7536486387252808
Batch 41/64 loss: 1.7526715993881226
Batch 42/64 loss: 1.7514348030090332
Batch 43/64 loss: 1.751052975654602
Batch 44/64 loss: 1.7592244148254395
Batch 45/64 loss: 1.7513463497161865
Batch 46/64 loss: 1.75259530544281
Batch 47/64 loss: 1.7500200271606445
Batch 48/64 loss: 1.7530295848846436
Batch 49/64 loss: 1.7532552480697632
Batch 50/64 loss: 1.7487655878067017
Batch 51/64 loss: 1.7752790451049805
Batch 52/64 loss: 1.7543214559555054
Batch 53/64 loss: 1.7491154670715332
Batch 54/64 loss: 1.769106388092041
Batch 55/64 loss: 1.7491838932037354
Batch 56/64 loss: 1.7527656555175781
Batch 57/64 loss: 1.7512322664260864
Batch 58/64 loss: 1.7499284744262695
Batch 59/64 loss: 1.7527334690093994
Batch 60/64 loss: 1.7507414817810059
Batch 61/64 loss: 1.7527601718902588
Batch 62/64 loss: 1.7553787231445312
Batch 63/64 loss: 1.7594212293624878
Batch 64/64 loss: 1.9485645294189453
Epoch 157  Train loss: 1.7561270769904642  Val loss: 1.7758384365396402
Epoch 158
-------------------------------
Batch 1/64 loss: 1.7504651546478271
Batch 2/64 loss: 1.7478822469711304
Batch 3/64 loss: 1.7510573863983154
Batch 4/64 loss: 1.7500756978988647
Batch 5/64 loss: 1.7508106231689453
Batch 6/64 loss: 1.7512917518615723
Batch 7/64 loss: 1.7500964403152466
Batch 8/64 loss: 1.7559287548065186
Batch 9/64 loss: 1.7541266679763794
Batch 10/64 loss: 1.7575304508209229
Batch 11/64 loss: 1.7529770135879517
Batch 12/64 loss: 1.7516684532165527
Batch 13/64 loss: 1.748916745185852
Batch 14/64 loss: 1.7531278133392334
Batch 15/64 loss: 1.7504007816314697
Batch 16/64 loss: 1.753406047821045
Batch 17/64 loss: 1.7483971118927002
Batch 18/64 loss: 1.7473995685577393
Batch 19/64 loss: 1.7502623796463013
Batch 20/64 loss: 1.7486823797225952
Batch 21/64 loss: 1.748664140701294
Batch 22/64 loss: 1.7469210624694824
Batch 23/64 loss: 1.7475006580352783
Batch 24/64 loss: 1.7553166151046753
Batch 25/64 loss: 1.7500739097595215
Batch 26/64 loss: 1.7493854761123657
Batch 27/64 loss: 1.7496235370635986
Batch 28/64 loss: 1.7528398036956787
Batch 29/64 loss: 1.7509288787841797
Batch 30/64 loss: 1.7496107816696167
Batch 31/64 loss: 1.7514991760253906
Batch 32/64 loss: 1.7478739023208618
Batch 33/64 loss: 1.7484731674194336
Batch 34/64 loss: 1.7475674152374268
Batch 35/64 loss: 1.7511560916900635
Batch 36/64 loss: 1.7691662311553955
Batch 37/64 loss: 1.757330060005188
Batch 38/64 loss: 1.7524200677871704
Batch 39/64 loss: 1.756194829940796
Batch 40/64 loss: 1.744492769241333
Batch 41/64 loss: 1.7631268501281738
Batch 42/64 loss: 1.763257622718811
Batch 43/64 loss: 1.749152660369873
Batch 44/64 loss: 1.749342918395996
Batch 45/64 loss: 1.751420021057129
Batch 46/64 loss: 1.748099684715271
Batch 47/64 loss: 1.7499321699142456
Batch 48/64 loss: 1.746692180633545
Batch 49/64 loss: 1.7497366666793823
Batch 50/64 loss: 1.7491586208343506
Batch 51/64 loss: 1.7517712116241455
Batch 52/64 loss: 1.7481871843338013
Batch 53/64 loss: 1.7510992288589478
Batch 54/64 loss: 1.7469537258148193
Batch 55/64 loss: 1.7508656978607178
Batch 56/64 loss: 1.746535062789917
Batch 57/64 loss: 1.7449098825454712
Batch 58/64 loss: 1.751981258392334
Batch 59/64 loss: 1.7447516918182373
Batch 60/64 loss: 1.75102698802948
Batch 61/64 loss: 1.7529304027557373
Batch 62/64 loss: 1.7519416809082031
Batch 63/64 loss: 1.7487752437591553
Batch 64/64 loss: 1.9486346244812012
Epoch 158  Train loss: 1.7533281045801499  Val loss: 1.7703094613511128
Epoch 159
-------------------------------
Batch 1/64 loss: 1.7487694025039673
Batch 2/64 loss: 1.756454348564148
Batch 3/64 loss: 1.7497180700302124
Batch 4/64 loss: 1.7493751049041748
Batch 5/64 loss: 1.7503100633621216
Batch 6/64 loss: 1.750948190689087
Batch 7/64 loss: 1.7609539031982422
Batch 8/64 loss: 1.7508342266082764
Batch 9/64 loss: 1.7497854232788086
Batch 10/64 loss: 1.7480745315551758
Batch 11/64 loss: 1.7512913942337036
Batch 12/64 loss: 1.7485942840576172
Batch 13/64 loss: 1.7505910396575928
Batch 14/64 loss: 1.7503050565719604
Batch 15/64 loss: 1.7467042207717896
Batch 16/64 loss: 1.7518736124038696
Batch 17/64 loss: 1.7482701539993286
Batch 18/64 loss: 1.7508095502853394
Batch 19/64 loss: 1.7471321821212769
Batch 20/64 loss: 1.7509222030639648
Batch 21/64 loss: 1.7484006881713867
Batch 22/64 loss: 1.752837896347046
Batch 23/64 loss: 1.7466305494308472
Batch 24/64 loss: 1.7502223253250122
Batch 25/64 loss: 1.7466027736663818
Batch 26/64 loss: 1.7493765354156494
Batch 27/64 loss: 1.7515121698379517
Batch 28/64 loss: 1.7487995624542236
Batch 29/64 loss: 1.750848650932312
Batch 30/64 loss: 1.7483164072036743
Batch 31/64 loss: 1.7494860887527466
Batch 32/64 loss: 1.771337866783142
Batch 33/64 loss: 1.7478883266448975
Batch 34/64 loss: 1.7630711793899536
Batch 35/64 loss: 1.7528305053710938
Batch 36/64 loss: 1.7519702911376953
Batch 37/64 loss: 1.7509138584136963
Batch 38/64 loss: 1.7514290809631348
Batch 39/64 loss: 1.75131094455719
Batch 40/64 loss: 1.7485647201538086
Batch 41/64 loss: 1.755989909172058
Batch 42/64 loss: 1.7520332336425781
Batch 43/64 loss: 1.7497453689575195
Batch 44/64 loss: 1.7516748905181885
Batch 45/64 loss: 1.75050950050354
Batch 46/64 loss: 1.7524150609970093
Batch 47/64 loss: 1.7507855892181396
Batch 48/64 loss: 1.7498960494995117
Batch 49/64 loss: 1.755974531173706
Batch 50/64 loss: 1.7497951984405518
Batch 51/64 loss: 1.754783034324646
Batch 52/64 loss: 1.7514885663986206
Batch 53/64 loss: 1.7553199529647827
Batch 54/64 loss: 1.760179877281189
Batch 55/64 loss: 1.7552769184112549
Batch 56/64 loss: 1.751325249671936
Batch 57/64 loss: 1.7473212480545044
Batch 58/64 loss: 1.7492108345031738
Batch 59/64 loss: 1.7720378637313843
Batch 60/64 loss: 1.752079963684082
Batch 61/64 loss: 1.7493467330932617
Batch 62/64 loss: 1.7570616006851196
Batch 63/64 loss: 1.7512919902801514
Batch 64/64 loss: 1.946972370147705
Epoch 159  Train loss: 1.7541935658922383  Val loss: 1.7719802594266807
Epoch 160
-------------------------------
Batch 1/64 loss: 1.751171588897705
Batch 2/64 loss: 1.7520278692245483
Batch 3/64 loss: 1.7524847984313965
Batch 4/64 loss: 1.7489755153656006
Batch 5/64 loss: 1.7525690793991089
Batch 6/64 loss: 1.7485387325286865
Batch 7/64 loss: 1.75577974319458
Batch 8/64 loss: 1.7503622770309448
Batch 9/64 loss: 1.7488255500793457
Batch 10/64 loss: 1.7529704570770264
Batch 11/64 loss: 1.7501230239868164
Batch 12/64 loss: 1.7524237632751465
Batch 13/64 loss: 1.7494474649429321
Batch 14/64 loss: 1.7513506412506104
Batch 15/64 loss: 1.749563455581665
Batch 16/64 loss: 1.7533034086227417
Batch 17/64 loss: 1.7533782720565796
Batch 18/64 loss: 1.7527310848236084
Batch 19/64 loss: 1.7582354545593262
Batch 20/64 loss: 1.7512754201889038
Batch 21/64 loss: 1.749052882194519
Batch 22/64 loss: 1.7534328699111938
Batch 23/64 loss: 1.7522186040878296
Batch 24/64 loss: 1.7704898118972778
Batch 25/64 loss: 1.7470159530639648
Batch 26/64 loss: 1.7474770545959473
Batch 27/64 loss: 1.7473078966140747
Batch 28/64 loss: 1.7471373081207275
Batch 29/64 loss: 1.748428463935852
Batch 30/64 loss: 1.7495629787445068
Batch 31/64 loss: 1.7520781755447388
Batch 32/64 loss: 1.7492763996124268
Batch 33/64 loss: 1.7505135536193848
Batch 34/64 loss: 1.749679446220398
Batch 35/64 loss: 1.7501829862594604
Batch 36/64 loss: 1.7507747411727905
Batch 37/64 loss: 1.7497813701629639
Batch 38/64 loss: 1.74726402759552
Batch 39/64 loss: 1.7477566003799438
Batch 40/64 loss: 1.7471245527267456
Batch 41/64 loss: 1.7491676807403564
Batch 42/64 loss: 1.7583692073822021
Batch 43/64 loss: 1.7654590606689453
Batch 44/64 loss: 1.7600375413894653
Batch 45/64 loss: 1.7480340003967285
Batch 46/64 loss: 1.7547427415847778
Batch 47/64 loss: 1.7483550310134888
Batch 48/64 loss: 1.746171236038208
Batch 49/64 loss: 1.752376675605774
Batch 50/64 loss: 1.7471206188201904
Batch 51/64 loss: 1.750004529953003
Batch 52/64 loss: 1.7495689392089844
Batch 53/64 loss: 1.7481675148010254
Batch 54/64 loss: 1.7492313385009766
Batch 55/64 loss: 1.7474651336669922
Batch 56/64 loss: 1.7475321292877197
Batch 57/64 loss: 1.7476850748062134
Batch 58/64 loss: 1.750866413116455
Batch 59/64 loss: 1.7471868991851807
Batch 60/64 loss: 1.754218339920044
Batch 61/64 loss: 1.7507612705230713
Batch 62/64 loss: 1.7511401176452637
Batch 63/64 loss: 1.7496850490570068
Batch 64/64 loss: 1.9483784437179565
Epoch 160  Train loss: 1.7533603710286758  Val loss: 1.7679700482751906
Saving best model, epoch: 160
Epoch 161
-------------------------------
Batch 1/64 loss: 1.752737045288086
Batch 2/64 loss: 1.750309944152832
Batch 3/64 loss: 1.755936861038208
Batch 4/64 loss: 1.7502796649932861
Batch 5/64 loss: 1.754091739654541
Batch 6/64 loss: 1.7533835172653198
Batch 7/64 loss: 1.7545623779296875
Batch 8/64 loss: 1.7523703575134277
Batch 9/64 loss: 1.7481343746185303
Batch 10/64 loss: 1.751651644706726
Batch 11/64 loss: 1.750119686126709
Batch 12/64 loss: 1.7497038841247559
Batch 13/64 loss: 1.7467470169067383
Batch 14/64 loss: 1.7491893768310547
Batch 15/64 loss: 1.7461469173431396
Batch 16/64 loss: 1.750089168548584
Batch 17/64 loss: 1.748580813407898
Batch 18/64 loss: 1.7480493783950806
Batch 19/64 loss: 1.7704192399978638
Batch 20/64 loss: 1.7483439445495605
Batch 21/64 loss: 1.7478262186050415
Batch 22/64 loss: 1.7500486373901367
Batch 23/64 loss: 1.7516943216323853
Batch 24/64 loss: 1.7487491369247437
Batch 25/64 loss: 1.7503647804260254
Batch 26/64 loss: 1.7490421533584595
Batch 27/64 loss: 1.7511013746261597
Batch 28/64 loss: 1.7495605945587158
Batch 29/64 loss: 1.7513983249664307
Batch 30/64 loss: 1.7460066080093384
Batch 31/64 loss: 1.75080406665802
Batch 32/64 loss: 1.7466915845870972
Batch 33/64 loss: 1.762537956237793
Batch 34/64 loss: 1.7464728355407715
Batch 35/64 loss: 1.7498822212219238
Batch 36/64 loss: 1.764912486076355
Batch 37/64 loss: 1.751194953918457
Batch 38/64 loss: 1.7541407346725464
Batch 39/64 loss: 1.7585026025772095
Batch 40/64 loss: 1.7515074014663696
Batch 41/64 loss: 1.7582026720046997
Batch 42/64 loss: 1.7551400661468506
Batch 43/64 loss: 1.7538783550262451
Batch 44/64 loss: 1.7511316537857056
Batch 45/64 loss: 1.7495880126953125
Batch 46/64 loss: 1.7521255016326904
Batch 47/64 loss: 1.7493876218795776
Batch 48/64 loss: 1.7508927583694458
Batch 49/64 loss: 1.757175087928772
Batch 50/64 loss: 1.7536407709121704
Batch 51/64 loss: 1.7525216341018677
Batch 52/64 loss: 1.7491265535354614
Batch 53/64 loss: 1.7537921667099
Batch 54/64 loss: 1.7524409294128418
Batch 55/64 loss: 1.7504258155822754
Batch 56/64 loss: 1.7469971179962158
Batch 57/64 loss: 1.750246524810791
Batch 58/64 loss: 1.7481533288955688
Batch 59/64 loss: 1.7527467012405396
Batch 60/64 loss: 1.750881552696228
Batch 61/64 loss: 1.752845287322998
Batch 62/64 loss: 1.76155424118042
Batch 63/64 loss: 1.750356912612915
Batch 64/64 loss: 1.9503856897354126
Epoch 161  Train loss: 1.754185513421601  Val loss: 1.7781612455230398
Epoch 162
-------------------------------
Batch 1/64 loss: 1.7529159784317017
Batch 2/64 loss: 1.7482092380523682
Batch 3/64 loss: 1.7541134357452393
Batch 4/64 loss: 1.7520508766174316
Batch 5/64 loss: 1.7551237344741821
Batch 6/64 loss: 1.7705879211425781
Batch 7/64 loss: 1.7556252479553223
Batch 8/64 loss: 1.7481029033660889
Batch 9/64 loss: 1.7654131650924683
Batch 10/64 loss: 1.7520015239715576
Batch 11/64 loss: 1.750343680381775
Batch 12/64 loss: 1.7491955757141113
Batch 13/64 loss: 1.7499998807907104
Batch 14/64 loss: 1.7585991621017456
Batch 15/64 loss: 1.7539482116699219
Batch 16/64 loss: 1.751646876335144
Batch 17/64 loss: 1.7576045989990234
Batch 18/64 loss: 1.7492903470993042
Batch 19/64 loss: 1.7500028610229492
Batch 20/64 loss: 1.7547783851623535
Batch 21/64 loss: 1.7636947631835938
Batch 22/64 loss: 1.7559338808059692
Batch 23/64 loss: 1.7518726587295532
Batch 24/64 loss: 1.750772476196289
Batch 25/64 loss: 1.7500793933868408
Batch 26/64 loss: 1.7596296072006226
Batch 27/64 loss: 1.7537224292755127
Batch 28/64 loss: 1.7501184940338135
Batch 29/64 loss: 1.7466319799423218
Batch 30/64 loss: 1.7545664310455322
Batch 31/64 loss: 1.7500044107437134
Batch 32/64 loss: 1.7514158487319946
Batch 33/64 loss: 1.7514845132827759
Batch 34/64 loss: 1.7466611862182617
Batch 35/64 loss: 1.7512072324752808
Batch 36/64 loss: 1.7523865699768066
Batch 37/64 loss: 1.7474018335342407
Batch 38/64 loss: 1.7522590160369873
Batch 39/64 loss: 1.750874638557434
Batch 40/64 loss: 1.7536015510559082
Batch 41/64 loss: 1.7455012798309326
Batch 42/64 loss: 1.7534940242767334
Batch 43/64 loss: 1.74989914894104
Batch 44/64 loss: 1.7539054155349731
Batch 45/64 loss: 1.7540063858032227
Batch 46/64 loss: 1.7480144500732422
Batch 47/64 loss: 1.7511403560638428
Batch 48/64 loss: 1.7528265714645386
Batch 49/64 loss: 1.7501450777053833
Batch 50/64 loss: 1.7468290328979492
Batch 51/64 loss: 1.7475122213363647
Batch 52/64 loss: 1.7497705221176147
Batch 53/64 loss: 1.7476098537445068
Batch 54/64 loss: 1.7565312385559082
Batch 55/64 loss: 1.7568176984786987
Batch 56/64 loss: 1.7503100633621216
Batch 57/64 loss: 1.7537894248962402
Batch 58/64 loss: 1.748046875
Batch 59/64 loss: 1.748392939567566
Batch 60/64 loss: 1.7489699125289917
Batch 61/64 loss: 1.7494975328445435
Batch 62/64 loss: 1.7524333000183105
Batch 63/64 loss: 1.7472939491271973
Batch 64/64 loss: 1.9515808820724487
Epoch 162  Train loss: 1.7545144384982538  Val loss: 1.773882849519605
Epoch 163
-------------------------------
Batch 1/64 loss: 1.7469072341918945
Batch 2/64 loss: 1.7523298263549805
Batch 3/64 loss: 1.7503082752227783
Batch 4/64 loss: 1.7497138977050781
Batch 5/64 loss: 1.7505097389221191
Batch 6/64 loss: 1.750838279724121
Batch 7/64 loss: 1.7518367767333984
Batch 8/64 loss: 1.7480002641677856
Batch 9/64 loss: 1.74867582321167
Batch 10/64 loss: 1.7502617835998535
Batch 11/64 loss: 1.752809762954712
Batch 12/64 loss: 1.7524077892303467
Batch 13/64 loss: 1.7505825757980347
Batch 14/64 loss: 1.7527897357940674
Batch 15/64 loss: 1.7519268989562988
Batch 16/64 loss: 1.7532129287719727
Batch 17/64 loss: 1.7492015361785889
Batch 18/64 loss: 1.7512253522872925
Batch 19/64 loss: 1.7640291452407837
Batch 20/64 loss: 1.7491772174835205
Batch 21/64 loss: 1.7507827281951904
Batch 22/64 loss: 1.7586275339126587
Batch 23/64 loss: 1.7556779384613037
Batch 24/64 loss: 1.7495949268341064
Batch 25/64 loss: 1.7526987791061401
Batch 26/64 loss: 1.7482213973999023
Batch 27/64 loss: 1.753739595413208
Batch 28/64 loss: 1.7518925666809082
Batch 29/64 loss: 1.751299500465393
Batch 30/64 loss: 1.7561163902282715
Batch 31/64 loss: 1.7497601509094238
Batch 32/64 loss: 1.7553508281707764
Batch 33/64 loss: 1.754031777381897
Batch 34/64 loss: 1.7515032291412354
Batch 35/64 loss: 1.7539706230163574
Batch 36/64 loss: 1.7537869215011597
Batch 37/64 loss: 1.7484910488128662
Batch 38/64 loss: 1.7507050037384033
Batch 39/64 loss: 1.758448600769043
Batch 40/64 loss: 1.7516087293624878
Batch 41/64 loss: 1.7574100494384766
Batch 42/64 loss: 1.7517046928405762
Batch 43/64 loss: 1.7784477472305298
Batch 44/64 loss: 1.7480664253234863
Batch 45/64 loss: 1.7552131414413452
Batch 46/64 loss: 1.7479170560836792
Batch 47/64 loss: 1.7479816675186157
Batch 48/64 loss: 1.749772310256958
Batch 49/64 loss: 1.7555654048919678
Batch 50/64 loss: 1.7477556467056274
Batch 51/64 loss: 1.7468167543411255
Batch 52/64 loss: 1.7509636878967285
Batch 53/64 loss: 1.7498414516448975
Batch 54/64 loss: 1.7512766122817993
Batch 55/64 loss: 1.7518621683120728
Batch 56/64 loss: 1.7500519752502441
Batch 57/64 loss: 1.754468321800232
Batch 58/64 loss: 1.7479074001312256
Batch 59/64 loss: 1.7489675283432007
Batch 60/64 loss: 1.7489955425262451
Batch 61/64 loss: 1.7558047771453857
Batch 62/64 loss: 1.7576898336410522
Batch 63/64 loss: 1.7523844242095947
Batch 64/64 loss: 1.9684547185897827
Epoch 163  Train loss: 1.754764843454548  Val loss: 1.7738160931367646
Epoch 164
-------------------------------
Batch 1/64 loss: 1.7561712265014648
Batch 2/64 loss: 1.7521319389343262
Batch 3/64 loss: 1.756447434425354
Batch 4/64 loss: 1.7509828805923462
Batch 5/64 loss: 1.7471555471420288
Batch 6/64 loss: 1.7499754428863525
Batch 7/64 loss: 1.7500097751617432
Batch 8/64 loss: 1.7493352890014648
Batch 9/64 loss: 1.7484350204467773
Batch 10/64 loss: 1.7505780458450317
Batch 11/64 loss: 1.7474068403244019
Batch 12/64 loss: 1.7479777336120605
Batch 13/64 loss: 1.7495486736297607
Batch 14/64 loss: 1.7490942478179932
Batch 15/64 loss: 1.7480902671813965
Batch 16/64 loss: 1.7474361658096313
Batch 17/64 loss: 1.7517120838165283
Batch 18/64 loss: 1.7499507665634155
Batch 19/64 loss: 1.748630404472351
Batch 20/64 loss: 1.7498623132705688
Batch 21/64 loss: 1.7496145963668823
Batch 22/64 loss: 1.7527364492416382
Batch 23/64 loss: 1.7490354776382446
Batch 24/64 loss: 1.7493093013763428
Batch 25/64 loss: 1.7466585636138916
Batch 26/64 loss: 1.7491154670715332
Batch 27/64 loss: 1.7480814456939697
Batch 28/64 loss: 1.7477198839187622
Batch 29/64 loss: 1.7475075721740723
Batch 30/64 loss: 1.7505064010620117
Batch 31/64 loss: 1.746572494506836
Batch 32/64 loss: 1.7469972372055054
Batch 33/64 loss: 1.7484745979309082
Batch 34/64 loss: 1.7557932138442993
Batch 35/64 loss: 1.7593567371368408
Batch 36/64 loss: 1.7474982738494873
Batch 37/64 loss: 1.7695358991622925
Batch 38/64 loss: 1.7468552589416504
Batch 39/64 loss: 1.7484837770462036
Batch 40/64 loss: 1.7533520460128784
Batch 41/64 loss: 1.7499829530715942
Batch 42/64 loss: 1.74678635597229
Batch 43/64 loss: 1.7474836111068726
Batch 44/64 loss: 1.7492201328277588
Batch 45/64 loss: 1.746302604675293
Batch 46/64 loss: 1.7497267723083496
Batch 47/64 loss: 1.7469127178192139
Batch 48/64 loss: 1.7492954730987549
Batch 49/64 loss: 1.7528653144836426
Batch 50/64 loss: 1.7473422288894653
Batch 51/64 loss: 1.755455493927002
Batch 52/64 loss: 1.7681490182876587
Batch 53/64 loss: 1.7516117095947266
Batch 54/64 loss: 1.749421238899231
Batch 55/64 loss: 1.7491179704666138
Batch 56/64 loss: 1.7489253282546997
Batch 57/64 loss: 1.7491129636764526
Batch 58/64 loss: 1.7542122602462769
Batch 59/64 loss: 1.75215482711792
Batch 60/64 loss: 1.7512288093566895
Batch 61/64 loss: 1.748579978942871
Batch 62/64 loss: 1.7474491596221924
Batch 63/64 loss: 1.7517039775848389
Batch 64/64 loss: 1.945947289466858
Epoch 164  Train loss: 1.7527315789578009  Val loss: 1.7674739188754682
Saving best model, epoch: 164
Epoch 165
-------------------------------
Batch 1/64 loss: 1.747313380241394
Batch 2/64 loss: 1.7474817037582397
Batch 3/64 loss: 1.759381890296936
Batch 4/64 loss: 1.7560086250305176
Batch 5/64 loss: 1.747832179069519
Batch 6/64 loss: 1.7515428066253662
Batch 7/64 loss: 1.7479851245880127
Batch 8/64 loss: 1.749338150024414
Batch 9/64 loss: 1.7506424188613892
Batch 10/64 loss: 1.7521469593048096
Batch 11/64 loss: 1.7513182163238525
Batch 12/64 loss: 1.7521233558654785
Batch 13/64 loss: 1.749610185623169
Batch 14/64 loss: 1.7491239309310913
Batch 15/64 loss: 1.7644145488739014
Batch 16/64 loss: 1.7478834390640259
Batch 17/64 loss: 1.7550089359283447
Batch 18/64 loss: 1.7498414516448975
Batch 19/64 loss: 1.7483166456222534
Batch 20/64 loss: 1.7485167980194092
Batch 21/64 loss: 1.7514070272445679
Batch 22/64 loss: 1.7577476501464844
Batch 23/64 loss: 1.7649198770523071
Batch 24/64 loss: 1.7499374151229858
Batch 25/64 loss: 1.7466013431549072
Batch 26/64 loss: 1.7568750381469727
Batch 27/64 loss: 1.7478336095809937
Batch 28/64 loss: 1.7517509460449219
Batch 29/64 loss: 1.7512800693511963
Batch 30/64 loss: 1.7513878345489502
Batch 31/64 loss: 1.7466044425964355
Batch 32/64 loss: 1.7488815784454346
Batch 33/64 loss: 1.7519170045852661
Batch 34/64 loss: 1.7523150444030762
Batch 35/64 loss: 1.7499818801879883
Batch 36/64 loss: 1.7548049688339233
Batch 37/64 loss: 1.7494831085205078
Batch 38/64 loss: 1.7475955486297607
Batch 39/64 loss: 1.7497076988220215
Batch 40/64 loss: 1.7499724626541138
Batch 41/64 loss: 1.7533024549484253
Batch 42/64 loss: 1.7518110275268555
Batch 43/64 loss: 1.7478246688842773
Batch 44/64 loss: 1.7536442279815674
Batch 45/64 loss: 1.7503432035446167
Batch 46/64 loss: 1.756058931350708
Batch 47/64 loss: 1.7491240501403809
Batch 48/64 loss: 1.7483086585998535
Batch 49/64 loss: 1.7536371946334839
Batch 50/64 loss: 1.748042106628418
Batch 51/64 loss: 1.7509387731552124
Batch 52/64 loss: 1.7524957656860352
Batch 53/64 loss: 1.7491250038146973
Batch 54/64 loss: 1.7479596138000488
Batch 55/64 loss: 1.749330997467041
Batch 56/64 loss: 1.747687578201294
Batch 57/64 loss: 1.7492560148239136
Batch 58/64 loss: 1.7541189193725586
Batch 59/64 loss: 1.7501914501190186
Batch 60/64 loss: 1.748261570930481
Batch 61/64 loss: 1.7483855485916138
Batch 62/64 loss: 1.7503137588500977
Batch 63/64 loss: 1.7487928867340088
Batch 64/64 loss: 1.9426288604736328
Epoch 165  Train loss: 1.7532982171750535  Val loss: 1.771316998603008
Epoch 166
-------------------------------
Batch 1/64 loss: 1.7506252527236938
Batch 2/64 loss: 1.7506842613220215
Batch 3/64 loss: 1.753182291984558
Batch 4/64 loss: 1.7479873895645142
Batch 5/64 loss: 1.749847650527954
Batch 6/64 loss: 1.7513176202774048
Batch 7/64 loss: 1.7490419149398804
Batch 8/64 loss: 1.7500940561294556
Batch 9/64 loss: 1.750941514968872
Batch 10/64 loss: 1.7484581470489502
Batch 11/64 loss: 1.7457048892974854
Batch 12/64 loss: 1.7464447021484375
Batch 13/64 loss: 1.7473738193511963
Batch 14/64 loss: 1.7498376369476318
Batch 15/64 loss: 1.7460395097732544
Batch 16/64 loss: 1.7468918561935425
Batch 17/64 loss: 1.749394178390503
Batch 18/64 loss: 1.7476378679275513
Batch 19/64 loss: 1.7462108135223389
Batch 20/64 loss: 1.7480093240737915
Batch 21/64 loss: 1.746865153312683
Batch 22/64 loss: 1.7480926513671875
Batch 23/64 loss: 1.7498981952667236
Batch 24/64 loss: 1.750753402709961
Batch 25/64 loss: 1.748103141784668
Batch 26/64 loss: 1.7461967468261719
Batch 27/64 loss: 1.7498199939727783
Batch 28/64 loss: 1.747040867805481
Batch 29/64 loss: 1.7654452323913574
Batch 30/64 loss: 1.7481672763824463
Batch 31/64 loss: 1.7482081651687622
Batch 32/64 loss: 1.7524323463439941
Batch 33/64 loss: 1.7509114742279053
Batch 34/64 loss: 1.7477778196334839
Batch 35/64 loss: 1.7461798191070557
Batch 36/64 loss: 1.748206377029419
Batch 37/64 loss: 1.749490737915039
Batch 38/64 loss: 1.7508877515792847
Batch 39/64 loss: 1.7488452196121216
Batch 40/64 loss: 1.7482738494873047
Batch 41/64 loss: 1.7498890161514282
Batch 42/64 loss: 1.7481728792190552
Batch 43/64 loss: 1.7466986179351807
Batch 44/64 loss: 1.743631362915039
Batch 45/64 loss: 1.7449427843093872
Batch 46/64 loss: 1.7496111392974854
Batch 47/64 loss: 1.7494133710861206
Batch 48/64 loss: 1.746022343635559
Batch 49/64 loss: 1.7448921203613281
Batch 50/64 loss: 1.7466847896575928
Batch 51/64 loss: 1.7452714443206787
Batch 52/64 loss: 1.7468030452728271
Batch 53/64 loss: 1.747589349746704
Batch 54/64 loss: 1.7619456052780151
Batch 55/64 loss: 1.748720407485962
Batch 56/64 loss: 1.7428840398788452
Batch 57/64 loss: 1.74575674533844
Batch 58/64 loss: 1.7458266019821167
Batch 59/64 loss: 1.7639482021331787
Batch 60/64 loss: 1.7511696815490723
Batch 61/64 loss: 1.7446454763412476
Batch 62/64 loss: 1.7458593845367432
Batch 63/64 loss: 1.7541821002960205
Batch 64/64 loss: 1.9430574178695679
Epoch 166  Train loss: 1.751202737116346  Val loss: 1.766542999195479
Saving best model, epoch: 166
Epoch 167
-------------------------------
Batch 1/64 loss: 1.747914433479309
Batch 2/64 loss: 1.7495381832122803
Batch 3/64 loss: 1.7484443187713623
Batch 4/64 loss: 1.750871181488037
Batch 5/64 loss: 1.7560310363769531
Batch 6/64 loss: 1.7481234073638916
Batch 7/64 loss: 1.7489639520645142
Batch 8/64 loss: 1.749046802520752
Batch 9/64 loss: 1.7473068237304688
Batch 10/64 loss: 1.74715256690979
Batch 11/64 loss: 1.7479233741760254
Batch 12/64 loss: 1.758588433265686
Batch 13/64 loss: 1.751121997833252
Batch 14/64 loss: 1.7498157024383545
Batch 15/64 loss: 1.7449694871902466
Batch 16/64 loss: 1.7464501857757568
Batch 17/64 loss: 1.7476345300674438
Batch 18/64 loss: 1.7442865371704102
Batch 19/64 loss: 1.7462613582611084
Batch 20/64 loss: 1.7458544969558716
Batch 21/64 loss: 1.7471065521240234
Batch 22/64 loss: 1.7440954446792603
Batch 23/64 loss: 1.7496989965438843
Batch 24/64 loss: 1.7518953084945679
Batch 25/64 loss: 1.7470197677612305
Batch 26/64 loss: 1.7441911697387695
Batch 27/64 loss: 1.7472496032714844
Batch 28/64 loss: 1.7502050399780273
Batch 29/64 loss: 1.745491623878479
Batch 30/64 loss: 1.746859073638916
Batch 31/64 loss: 1.7510780096054077
Batch 32/64 loss: 1.7571510076522827
Batch 33/64 loss: 1.7541369199752808
Batch 34/64 loss: 1.7466789484024048
Batch 35/64 loss: 1.745761513710022
Batch 36/64 loss: 1.749347448348999
Batch 37/64 loss: 1.7476897239685059
Batch 38/64 loss: 1.7505570650100708
Batch 39/64 loss: 1.7467987537384033
Batch 40/64 loss: 1.7487890720367432
Batch 41/64 loss: 1.749253273010254
Batch 42/64 loss: 1.749300241470337
Batch 43/64 loss: 1.746846318244934
Batch 44/64 loss: 1.7513011693954468
Batch 45/64 loss: 1.7479830980300903
Batch 46/64 loss: 1.7493822574615479
Batch 47/64 loss: 1.7488017082214355
Batch 48/64 loss: 1.7642822265625
Batch 49/64 loss: 1.7493335008621216
Batch 50/64 loss: 1.7486765384674072
Batch 51/64 loss: 1.7597274780273438
Batch 52/64 loss: 1.7485003471374512
Batch 53/64 loss: 1.7479248046875
Batch 54/64 loss: 1.747617244720459
Batch 55/64 loss: 1.7531415224075317
Batch 56/64 loss: 1.7481001615524292
Batch 57/64 loss: 1.7469594478607178
Batch 58/64 loss: 1.7486661672592163
Batch 59/64 loss: 1.7535922527313232
Batch 60/64 loss: 1.7531321048736572
Batch 61/64 loss: 1.7445224523544312
Batch 62/64 loss: 1.7468181848526
Batch 63/64 loss: 1.7473831176757812
Batch 64/64 loss: 1.943697214126587
Epoch 167  Train loss: 1.7514842098834469  Val loss: 1.7678123200472278
Epoch 168
-------------------------------
Batch 1/64 loss: 1.7473206520080566
Batch 2/64 loss: 1.7483184337615967
Batch 3/64 loss: 1.7478930950164795
Batch 4/64 loss: 1.7543017864227295
Batch 5/64 loss: 1.7507926225662231
Batch 6/64 loss: 1.7521603107452393
Batch 7/64 loss: 1.7548249959945679
Batch 8/64 loss: 1.7520856857299805
Batch 9/64 loss: 1.751630187034607
Batch 10/64 loss: 1.7469247579574585
Batch 11/64 loss: 1.7516937255859375
Batch 12/64 loss: 1.7451192140579224
Batch 13/64 loss: 1.7486428022384644
Batch 14/64 loss: 1.7513529062271118
Batch 15/64 loss: 1.7490925788879395
Batch 16/64 loss: 1.7477209568023682
Batch 17/64 loss: 1.744918942451477
Batch 18/64 loss: 1.7435553073883057
Batch 19/64 loss: 1.7480401992797852
Batch 20/64 loss: 1.7483922243118286
Batch 21/64 loss: 1.7450637817382812
Batch 22/64 loss: 1.7493088245391846
Batch 23/64 loss: 1.744293451309204
Batch 24/64 loss: 1.7479159832000732
Batch 25/64 loss: 1.7440541982650757
Batch 26/64 loss: 1.7441730499267578
Batch 27/64 loss: 1.753145456314087
Batch 28/64 loss: 1.747523307800293
Batch 29/64 loss: 1.744488000869751
Batch 30/64 loss: 1.7449899911880493
Batch 31/64 loss: 1.7530392408370972
Batch 32/64 loss: 1.7635290622711182
Batch 33/64 loss: 1.7452312707901
Batch 34/64 loss: 1.7483830451965332
Batch 35/64 loss: 1.7469329833984375
Batch 36/64 loss: 1.7524124383926392
Batch 37/64 loss: 1.7447056770324707
Batch 38/64 loss: 1.7527458667755127
Batch 39/64 loss: 1.7474260330200195
Batch 40/64 loss: 1.7448325157165527
Batch 41/64 loss: 1.7490671873092651
Batch 42/64 loss: 1.7482802867889404
Batch 43/64 loss: 1.745786190032959
Batch 44/64 loss: 1.759143352508545
Batch 45/64 loss: 1.7439807653427124
Batch 46/64 loss: 1.7449499368667603
Batch 47/64 loss: 1.7484912872314453
Batch 48/64 loss: 1.7459070682525635
Batch 49/64 loss: 1.7482026815414429
Batch 50/64 loss: 1.7458281517028809
Batch 51/64 loss: 1.746442198753357
Batch 52/64 loss: 1.74318528175354
Batch 53/64 loss: 1.749364972114563
Batch 54/64 loss: 1.7446904182434082
Batch 55/64 loss: 1.7489631175994873
Batch 56/64 loss: 1.744204044342041
Batch 57/64 loss: 1.753079891204834
Batch 58/64 loss: 1.747889757156372
Batch 59/64 loss: 1.74798583984375
Batch 60/64 loss: 1.7435729503631592
Batch 61/64 loss: 1.7605469226837158
Batch 62/64 loss: 1.7469054460525513
Batch 63/64 loss: 1.7457973957061768
Batch 64/64 loss: 1.9349267482757568
Epoch 168  Train loss: 1.7506264434141272  Val loss: 1.7645313821707393
Saving best model, epoch: 168
Epoch 169
-------------------------------
Batch 1/64 loss: 1.7517273426055908
Batch 2/64 loss: 1.7429753541946411
Batch 3/64 loss: 1.7508714199066162
Batch 4/64 loss: 1.7489771842956543
Batch 5/64 loss: 1.7453073263168335
Batch 6/64 loss: 1.7485826015472412
Batch 7/64 loss: 1.745755672454834
Batch 8/64 loss: 1.7494083642959595
Batch 9/64 loss: 1.7454133033752441
Batch 10/64 loss: 1.7484829425811768
Batch 11/64 loss: 1.7515709400177002
Batch 12/64 loss: 1.7646132707595825
Batch 13/64 loss: 1.7570531368255615
Batch 14/64 loss: 1.7492743730545044
Batch 15/64 loss: 1.7484626770019531
Batch 16/64 loss: 1.752170443534851
Batch 17/64 loss: 1.7506489753723145
Batch 18/64 loss: 1.745504379272461
Batch 19/64 loss: 1.748700737953186
Batch 20/64 loss: 1.746650218963623
Batch 21/64 loss: 1.746793270111084
Batch 22/64 loss: 1.7496540546417236
Batch 23/64 loss: 1.7471469640731812
Batch 24/64 loss: 1.7483161687850952
Batch 25/64 loss: 1.7530415058135986
Batch 26/64 loss: 1.7485194206237793
Batch 27/64 loss: 1.7498564720153809
Batch 28/64 loss: 1.7453951835632324
Batch 29/64 loss: 1.7491353750228882
Batch 30/64 loss: 1.7485162019729614
Batch 31/64 loss: 1.75093412399292
Batch 32/64 loss: 1.7469923496246338
Batch 33/64 loss: 1.745499849319458
Batch 34/64 loss: 1.7485052347183228
Batch 35/64 loss: 1.7455801963806152
Batch 36/64 loss: 1.748222827911377
Batch 37/64 loss: 1.7552926540374756
Batch 38/64 loss: 1.7481660842895508
Batch 39/64 loss: 1.7461161613464355
Batch 40/64 loss: 1.7461011409759521
Batch 41/64 loss: 1.745705485343933
Batch 42/64 loss: 1.7628600597381592
Batch 43/64 loss: 1.7512962818145752
Batch 44/64 loss: 1.7516707181930542
Batch 45/64 loss: 1.748915672302246
Batch 46/64 loss: 1.7555100917816162
Batch 47/64 loss: 1.7474744319915771
Batch 48/64 loss: 1.7454034090042114
Batch 49/64 loss: 1.7458093166351318
Batch 50/64 loss: 1.748698115348816
Batch 51/64 loss: 1.745976448059082
Batch 52/64 loss: 1.7506506443023682
Batch 53/64 loss: 1.7479441165924072
Batch 54/64 loss: 1.748150110244751
Batch 55/64 loss: 1.746696949005127
Batch 56/64 loss: 1.7484697103500366
Batch 57/64 loss: 1.75191068649292
Batch 58/64 loss: 1.747483253479004
Batch 59/64 loss: 1.7487273216247559
Batch 60/64 loss: 1.7508950233459473
Batch 61/64 loss: 1.7484976053237915
Batch 62/64 loss: 1.7489603757858276
Batch 63/64 loss: 1.7467944622039795
Batch 64/64 loss: 1.9675167798995972
Epoch 169  Train loss: 1.7516874318029367  Val loss: 1.765957124454459
Epoch 170
-------------------------------
Batch 1/64 loss: 1.747866153717041
Batch 2/64 loss: 1.7511478662490845
Batch 3/64 loss: 1.7445182800292969
Batch 4/64 loss: 1.7497506141662598
Batch 5/64 loss: 1.7471842765808105
Batch 6/64 loss: 1.7456846237182617
Batch 7/64 loss: 1.7546864748001099
Batch 8/64 loss: 1.753316879272461
Batch 9/64 loss: 1.7461702823638916
Batch 10/64 loss: 1.7468218803405762
Batch 11/64 loss: 1.7455819845199585
Batch 12/64 loss: 1.7483227252960205
Batch 13/64 loss: 1.748042106628418
Batch 14/64 loss: 1.754239559173584
Batch 15/64 loss: 1.7478135824203491
Batch 16/64 loss: 1.7510371208190918
Batch 17/64 loss: 1.7453806400299072
Batch 18/64 loss: 1.7621101140975952
Batch 19/64 loss: 1.7486228942871094
Batch 20/64 loss: 1.7439039945602417
Batch 21/64 loss: 1.7455812692642212
Batch 22/64 loss: 1.7493089437484741
Batch 23/64 loss: 1.747384786605835
Batch 24/64 loss: 1.7469617128372192
Batch 25/64 loss: 1.7487192153930664
Batch 26/64 loss: 1.7529022693634033
Batch 27/64 loss: 1.748229742050171
Batch 28/64 loss: 1.7457106113433838
Batch 29/64 loss: 1.7504520416259766
Batch 30/64 loss: 1.7457549571990967
Batch 31/64 loss: 1.7652230262756348
Batch 32/64 loss: 1.74871826171875
Batch 33/64 loss: 1.7499229907989502
Batch 34/64 loss: 1.747978925704956
Batch 35/64 loss: 1.7457737922668457
Batch 36/64 loss: 1.749772310256958
Batch 37/64 loss: 1.7497280836105347
Batch 38/64 loss: 1.746399164199829
Batch 39/64 loss: 1.7448378801345825
Batch 40/64 loss: 1.7482541799545288
Batch 41/64 loss: 1.7466400861740112
Batch 42/64 loss: 1.746660828590393
Batch 43/64 loss: 1.748814582824707
Batch 44/64 loss: 1.7443934679031372
Batch 45/64 loss: 1.7481955289840698
Batch 46/64 loss: 1.7460194826126099
Batch 47/64 loss: 1.749250888824463
Batch 48/64 loss: 1.7470393180847168
Batch 49/64 loss: 1.7464118003845215
Batch 50/64 loss: 1.7470792531967163
Batch 51/64 loss: 1.7453148365020752
Batch 52/64 loss: 1.764913558959961
Batch 53/64 loss: 1.7470271587371826
Batch 54/64 loss: 1.7453343868255615
Batch 55/64 loss: 1.7486919164657593
Batch 56/64 loss: 1.747736930847168
Batch 57/64 loss: 1.7478079795837402
Batch 58/64 loss: 1.747996211051941
Batch 59/64 loss: 1.750269889831543
Batch 60/64 loss: 1.7507786750793457
Batch 61/64 loss: 1.74570894241333
Batch 62/64 loss: 1.7500343322753906
Batch 63/64 loss: 1.7462198734283447
Batch 64/64 loss: 1.9440557956695557
Epoch 170  Train loss: 1.75099918421577  Val loss: 1.7686094811691861
Epoch 171
-------------------------------
Batch 1/64 loss: 1.7484352588653564
Batch 2/64 loss: 1.751326322555542
Batch 3/64 loss: 1.7479437589645386
Batch 4/64 loss: 1.767775297164917
Batch 5/64 loss: 1.7516793012619019
Batch 6/64 loss: 1.7473132610321045
Batch 7/64 loss: 1.7524199485778809
Batch 8/64 loss: 1.7472169399261475
Batch 9/64 loss: 1.7549901008605957
Batch 10/64 loss: 1.7507579326629639
Batch 11/64 loss: 1.7480210065841675
Batch 12/64 loss: 1.75077486038208
Batch 13/64 loss: 1.7504169940948486
Batch 14/64 loss: 1.7508432865142822
Batch 15/64 loss: 1.7498695850372314
Batch 16/64 loss: 1.7523010969161987
Batch 17/64 loss: 1.7461826801300049
Batch 18/64 loss: 1.7502859830856323
Batch 19/64 loss: 1.7521613836288452
Batch 20/64 loss: 1.7479333877563477
Batch 21/64 loss: 1.7468342781066895
Batch 22/64 loss: 1.7497200965881348
Batch 23/64 loss: 1.7499747276306152
Batch 24/64 loss: 1.7474623918533325
Batch 25/64 loss: 1.750746726989746
Batch 26/64 loss: 1.7492074966430664
Batch 27/64 loss: 1.7474327087402344
Batch 28/64 loss: 1.7465916872024536
Batch 29/64 loss: 1.747528314590454
Batch 30/64 loss: 1.7491732835769653
Batch 31/64 loss: 1.7432111501693726
Batch 32/64 loss: 1.7500509023666382
Batch 33/64 loss: 1.7467772960662842
Batch 34/64 loss: 1.7484742403030396
Batch 35/64 loss: 1.7473114728927612
Batch 36/64 loss: 1.7496778964996338
Batch 37/64 loss: 1.7518508434295654
Batch 38/64 loss: 1.7468724250793457
Batch 39/64 loss: 1.7459237575531006
Batch 40/64 loss: 1.7485030889511108
Batch 41/64 loss: 1.7521814107894897
Batch 42/64 loss: 1.7486953735351562
Batch 43/64 loss: 1.748732328414917
Batch 44/64 loss: 1.748868703842163
Batch 45/64 loss: 1.7447776794433594
Batch 46/64 loss: 1.7534970045089722
Batch 47/64 loss: 1.748326063156128
Batch 48/64 loss: 1.7553601264953613
Batch 49/64 loss: 1.7463840246200562
Batch 50/64 loss: 1.7610232830047607
Batch 51/64 loss: 1.7646180391311646
Batch 52/64 loss: 1.7458467483520508
Batch 53/64 loss: 1.7455674409866333
Batch 54/64 loss: 1.747389554977417
Batch 55/64 loss: 1.7502740621566772
Batch 56/64 loss: 1.7492988109588623
Batch 57/64 loss: 1.751734733581543
Batch 58/64 loss: 1.7467143535614014
Batch 59/64 loss: 1.7455259561538696
Batch 60/64 loss: 1.7583732604980469
Batch 61/64 loss: 1.7543439865112305
Batch 62/64 loss: 1.7453341484069824
Batch 63/64 loss: 1.7487736940383911
Batch 64/64 loss: 1.942586898803711
Epoch 171  Train loss: 1.7521655550190047  Val loss: 1.766200899668166
Epoch 172
-------------------------------
Batch 1/64 loss: 1.745520830154419
Batch 2/64 loss: 1.748970866203308
Batch 3/64 loss: 1.7475546598434448
Batch 4/64 loss: 1.7502161264419556
Batch 5/64 loss: 1.750805377960205
Batch 6/64 loss: 1.7493116855621338
Batch 7/64 loss: 1.746181607246399
Batch 8/64 loss: 1.7459982633590698
Batch 9/64 loss: 1.7493375539779663
Batch 10/64 loss: 1.7471927404403687
Batch 11/64 loss: 1.746972680091858
Batch 12/64 loss: 1.7460196018218994
Batch 13/64 loss: 1.7477425336837769
Batch 14/64 loss: 1.7497665882110596
Batch 15/64 loss: 1.7597668170928955
Batch 16/64 loss: 1.7513890266418457
Batch 17/64 loss: 1.7503492832183838
Batch 18/64 loss: 1.7532737255096436
Batch 19/64 loss: 1.7488229274749756
Batch 20/64 loss: 1.7663365602493286
Batch 21/64 loss: 1.7484509944915771
Batch 22/64 loss: 1.7503738403320312
Batch 23/64 loss: 1.7484054565429688
Batch 24/64 loss: 1.7481961250305176
Batch 25/64 loss: 1.7517179250717163
Batch 26/64 loss: 1.754304051399231
Batch 27/64 loss: 1.7487716674804688
Batch 28/64 loss: 1.752621054649353
Batch 29/64 loss: 1.7451494932174683
Batch 30/64 loss: 1.7531638145446777
Batch 31/64 loss: 1.7634228467941284
Batch 32/64 loss: 1.7525899410247803
Batch 33/64 loss: 1.7582567930221558
Batch 34/64 loss: 1.746208667755127
Batch 35/64 loss: 1.747900366783142
Batch 36/64 loss: 1.7509737014770508
Batch 37/64 loss: 1.747798204421997
Batch 38/64 loss: 1.7486666440963745
Batch 39/64 loss: 1.749224305152893
Batch 40/64 loss: 1.7486779689788818
Batch 41/64 loss: 1.748646855354309
Batch 42/64 loss: 1.7481718063354492
Batch 43/64 loss: 1.7478671073913574
Batch 44/64 loss: 1.7504193782806396
Batch 45/64 loss: 1.7462294101715088
Batch 46/64 loss: 1.7464126348495483
Batch 47/64 loss: 1.7484418153762817
Batch 48/64 loss: 1.7487845420837402
Batch 49/64 loss: 1.7562566995620728
Batch 50/64 loss: 1.7470088005065918
Batch 51/64 loss: 1.750495195388794
Batch 52/64 loss: 1.767953872680664
Batch 53/64 loss: 1.7526575326919556
Batch 54/64 loss: 1.7499628067016602
Batch 55/64 loss: 1.7516084909439087
Batch 56/64 loss: 1.749754548072815
Batch 57/64 loss: 1.7498717308044434
Batch 58/64 loss: 1.750400185585022
Batch 59/64 loss: 1.7460623979568481
Batch 60/64 loss: 1.7483183145523071
Batch 61/64 loss: 1.7451081275939941
Batch 62/64 loss: 1.7482069730758667
Batch 63/64 loss: 1.7464542388916016
Batch 64/64 loss: 1.9459666013717651
Epoch 172  Train loss: 1.7524858311110851  Val loss: 1.769860210287612
Epoch 173
-------------------------------
Batch 1/64 loss: 1.7483023405075073
Batch 2/64 loss: 1.7482726573944092
Batch 3/64 loss: 1.7547264099121094
Batch 4/64 loss: 1.753166675567627
Batch 5/64 loss: 1.7493799924850464
Batch 6/64 loss: 1.7541301250457764
Batch 7/64 loss: 1.7566760778427124
Batch 8/64 loss: 1.7492396831512451
Batch 9/64 loss: 1.7537245750427246
Batch 10/64 loss: 1.7528175115585327
Batch 11/64 loss: 1.7508182525634766
Batch 12/64 loss: 1.7487064599990845
Batch 13/64 loss: 1.7462254762649536
Batch 14/64 loss: 1.7459304332733154
Batch 15/64 loss: 1.7510159015655518
Batch 16/64 loss: 1.7489516735076904
Batch 17/64 loss: 1.7453864812850952
Batch 18/64 loss: 1.7475477457046509
Batch 19/64 loss: 1.7493176460266113
Batch 20/64 loss: 1.7495051622390747
Batch 21/64 loss: 1.7503159046173096
Batch 22/64 loss: 1.748100757598877
Batch 23/64 loss: 1.7507013082504272
Batch 24/64 loss: 1.749995231628418
Batch 25/64 loss: 1.745511770248413
Batch 26/64 loss: 1.7501475811004639
Batch 27/64 loss: 1.7495801448822021
Batch 28/64 loss: 1.7454242706298828
Batch 29/64 loss: 1.7449102401733398
Batch 30/64 loss: 1.7654290199279785
Batch 31/64 loss: 1.7442864179611206
Batch 32/64 loss: 1.7506159543991089
Batch 33/64 loss: 1.7429852485656738
Batch 34/64 loss: 1.7462431192398071
Batch 35/64 loss: 1.7439407110214233
Batch 36/64 loss: 1.7574923038482666
Batch 37/64 loss: 1.749245524406433
Batch 38/64 loss: 1.7452794313430786
Batch 39/64 loss: 1.747471570968628
Batch 40/64 loss: 1.747840404510498
Batch 41/64 loss: 1.7481063604354858
Batch 42/64 loss: 1.743598461151123
Batch 43/64 loss: 1.7606521844863892
Batch 44/64 loss: 1.7495719194412231
Batch 45/64 loss: 1.7460365295410156
Batch 46/64 loss: 1.743948221206665
Batch 47/64 loss: 1.7456161975860596
Batch 48/64 loss: 1.7462950944900513
Batch 49/64 loss: 1.7446868419647217
Batch 50/64 loss: 1.7459133863449097
Batch 51/64 loss: 1.745260238647461
Batch 52/64 loss: 1.746187686920166
Batch 53/64 loss: 1.7470698356628418
Batch 54/64 loss: 1.7432957887649536
Batch 55/64 loss: 1.7491036653518677
Batch 56/64 loss: 1.7454991340637207
Batch 57/64 loss: 1.7472033500671387
Batch 58/64 loss: 1.7499120235443115
Batch 59/64 loss: 1.7534372806549072
Batch 60/64 loss: 1.7487496137619019
Batch 61/64 loss: 1.7454246282577515
Batch 62/64 loss: 1.7492926120758057
Batch 63/64 loss: 1.7504774332046509
Batch 64/64 loss: 1.9457261562347412
Epoch 173  Train loss: 1.7511214321734858  Val loss: 1.7697621792862095
Epoch 174
-------------------------------
Batch 1/64 loss: 1.7483524084091187
Batch 2/64 loss: 1.7532646656036377
Batch 3/64 loss: 1.7458577156066895
Batch 4/64 loss: 1.748812198638916
Batch 5/64 loss: 1.7498338222503662
Batch 6/64 loss: 1.7475008964538574
Batch 7/64 loss: 1.7473872900009155
Batch 8/64 loss: 1.7515740394592285
Batch 9/64 loss: 1.7547560930252075
Batch 10/64 loss: 1.7615282535552979
Batch 11/64 loss: 1.74847412109375
Batch 12/64 loss: 1.7526642084121704
Batch 13/64 loss: 1.7461166381835938
Batch 14/64 loss: 1.7475199699401855
Batch 15/64 loss: 1.7495906352996826
Batch 16/64 loss: 1.7522153854370117
Batch 17/64 loss: 1.7467899322509766
Batch 18/64 loss: 1.7488458156585693
Batch 19/64 loss: 1.7531230449676514
Batch 20/64 loss: 1.7477997541427612
Batch 21/64 loss: 1.7478859424591064
Batch 22/64 loss: 1.7438201904296875
Batch 23/64 loss: 1.745652198791504
Batch 24/64 loss: 1.748216986656189
Batch 25/64 loss: 1.7524116039276123
Batch 26/64 loss: 1.7461782693862915
Batch 27/64 loss: 1.7442922592163086
Batch 28/64 loss: 1.7433537244796753
Batch 29/64 loss: 1.746016025543213
Batch 30/64 loss: 1.749140739440918
Batch 31/64 loss: 1.7463936805725098
Batch 32/64 loss: 1.7437037229537964
Batch 33/64 loss: 1.744001030921936
Batch 34/64 loss: 1.7487294673919678
Batch 35/64 loss: 1.7453705072402954
Batch 36/64 loss: 1.7482361793518066
Batch 37/64 loss: 1.748703956604004
Batch 38/64 loss: 1.7442312240600586
Batch 39/64 loss: 1.7464011907577515
Batch 40/64 loss: 1.7493356466293335
Batch 41/64 loss: 1.7462072372436523
Batch 42/64 loss: 1.7449688911437988
Batch 43/64 loss: 1.7437560558319092
Batch 44/64 loss: 1.7488681077957153
Batch 45/64 loss: 1.746222972869873
Batch 46/64 loss: 1.7444227933883667
Batch 47/64 loss: 1.7491626739501953
Batch 48/64 loss: 1.7488294839859009
Batch 49/64 loss: 1.7475675344467163
Batch 50/64 loss: 1.747077465057373
Batch 51/64 loss: 1.7505512237548828
Batch 52/64 loss: 1.7557100057601929
Batch 53/64 loss: 1.749499797821045
Batch 54/64 loss: 1.749167799949646
Batch 55/64 loss: 1.7483532428741455
Batch 56/64 loss: 1.7527180910110474
Batch 57/64 loss: 1.746914267539978
Batch 58/64 loss: 1.7626118659973145
Batch 59/64 loss: 1.744063138961792
Batch 60/64 loss: 1.7449910640716553
Batch 61/64 loss: 1.7450380325317383
Batch 62/64 loss: 1.7485721111297607
Batch 63/64 loss: 1.74713933467865
Batch 64/64 loss: 1.9776564836502075
Epoch 174  Train loss: 1.7510546978782204  Val loss: 1.7682510749580933
Epoch 175
-------------------------------
Batch 1/64 loss: 1.748781442642212
Batch 2/64 loss: 1.7474453449249268
Batch 3/64 loss: 1.7460464239120483
Batch 4/64 loss: 1.7579843997955322
Batch 5/64 loss: 1.7458288669586182
Batch 6/64 loss: 1.757672667503357
Batch 7/64 loss: 1.764059066772461
Batch 8/64 loss: 1.7446374893188477
Batch 9/64 loss: 1.742659330368042
Batch 10/64 loss: 1.7479002475738525
Batch 11/64 loss: 1.7456241846084595
Batch 12/64 loss: 1.7432820796966553
Batch 13/64 loss: 1.7468163967132568
Batch 14/64 loss: 1.7433311939239502
Batch 15/64 loss: 1.753308653831482
Batch 16/64 loss: 1.7487835884094238
Batch 17/64 loss: 1.7476412057876587
Batch 18/64 loss: 1.750333547592163
Batch 19/64 loss: 1.7508349418640137
Batch 20/64 loss: 1.7537152767181396
Batch 21/64 loss: 1.7490041255950928
Batch 22/64 loss: 1.7509492635726929
Batch 23/64 loss: 1.7481671571731567
Batch 24/64 loss: 1.7540078163146973
Batch 25/64 loss: 1.744374394416809
Batch 26/64 loss: 1.7492599487304688
Batch 27/64 loss: 1.7498230934143066
Batch 28/64 loss: 1.7474085092544556
Batch 29/64 loss: 1.7478580474853516
Batch 30/64 loss: 1.745072603225708
Batch 31/64 loss: 1.7550673484802246
Batch 32/64 loss: 1.751478672027588
Batch 33/64 loss: 1.7474267482757568
Batch 34/64 loss: 1.750434398651123
Batch 35/64 loss: 1.746241569519043
Batch 36/64 loss: 1.748892068862915
Batch 37/64 loss: 1.7465078830718994
Batch 38/64 loss: 1.7454476356506348
Batch 39/64 loss: 1.7497111558914185
Batch 40/64 loss: 1.7519654035568237
Batch 41/64 loss: 1.7516814470291138
Batch 42/64 loss: 1.7460169792175293
Batch 43/64 loss: 1.745378851890564
Batch 44/64 loss: 1.7480156421661377
Batch 45/64 loss: 1.7470097541809082
Batch 46/64 loss: 1.7461166381835938
Batch 47/64 loss: 1.747235655784607
Batch 48/64 loss: 1.7461382150650024
Batch 49/64 loss: 1.7473304271697998
Batch 50/64 loss: 1.7450757026672363
Batch 51/64 loss: 1.747413158416748
Batch 52/64 loss: 1.7473561763763428
Batch 53/64 loss: 1.747077465057373
Batch 54/64 loss: 1.7485921382904053
Batch 55/64 loss: 1.7446283102035522
Batch 56/64 loss: 1.754662036895752
Batch 57/64 loss: 1.7524079084396362
Batch 58/64 loss: 1.749135971069336
Batch 59/64 loss: 1.747949242591858
Batch 60/64 loss: 1.7485089302062988
Batch 61/64 loss: 1.7483524084091187
Batch 62/64 loss: 1.7510581016540527
Batch 63/64 loss: 1.748176097869873
Batch 64/64 loss: 1.945103645324707
Epoch 175  Train loss: 1.7510577127045277  Val loss: 1.7680802672999012
Epoch 176
-------------------------------
Batch 1/64 loss: 1.7492291927337646
Batch 2/64 loss: 1.747917652130127
Batch 3/64 loss: 1.7499148845672607
Batch 4/64 loss: 1.7564952373504639
Batch 5/64 loss: 1.7515559196472168
Batch 6/64 loss: 1.7480947971343994
Batch 7/64 loss: 1.7494155168533325
Batch 8/64 loss: 1.7508080005645752
Batch 9/64 loss: 1.7491179704666138
Batch 10/64 loss: 1.7450451850891113
Batch 11/64 loss: 1.7476246356964111
Batch 12/64 loss: 1.756550908088684
Batch 13/64 loss: 1.7565994262695312
Batch 14/64 loss: 1.7494337558746338
Batch 15/64 loss: 1.7500746250152588
Batch 16/64 loss: 1.7563129663467407
Batch 17/64 loss: 1.7486344575881958
Batch 18/64 loss: 1.7454941272735596
Batch 19/64 loss: 1.7491440773010254
Batch 20/64 loss: 1.7493878602981567
Batch 21/64 loss: 1.7491297721862793
Batch 22/64 loss: 1.7465105056762695
Batch 23/64 loss: 1.7480100393295288
Batch 24/64 loss: 1.7487682104110718
Batch 25/64 loss: 1.7495887279510498
Batch 26/64 loss: 1.7452898025512695
Batch 27/64 loss: 1.7479897737503052
Batch 28/64 loss: 1.7512763738632202
Batch 29/64 loss: 1.745167851448059
Batch 30/64 loss: 1.7521495819091797
Batch 31/64 loss: 1.7517950534820557
Batch 32/64 loss: 1.745870590209961
Batch 33/64 loss: 1.7527480125427246
Batch 34/64 loss: 1.748501181602478
Batch 35/64 loss: 1.7509899139404297
Batch 36/64 loss: 1.7513982057571411
Batch 37/64 loss: 1.7506334781646729
Batch 38/64 loss: 1.7535134553909302
Batch 39/64 loss: 1.748272180557251
Batch 40/64 loss: 1.7492815256118774
Batch 41/64 loss: 1.7480324506759644
Batch 42/64 loss: 1.7634104490280151
Batch 43/64 loss: 1.7494444847106934
Batch 44/64 loss: 1.7501170635223389
Batch 45/64 loss: 1.7512290477752686
Batch 46/64 loss: 1.7483404874801636
Batch 47/64 loss: 1.746748447418213
Batch 48/64 loss: 1.7511123418807983
Batch 49/64 loss: 1.7551512718200684
Batch 50/64 loss: 1.7487303018569946
Batch 51/64 loss: 1.7553648948669434
Batch 52/64 loss: 1.747854232788086
Batch 53/64 loss: 1.7474284172058105
Batch 54/64 loss: 1.750868320465088
Batch 55/64 loss: 1.7481938600540161
Batch 56/64 loss: 1.7502529621124268
Batch 57/64 loss: 1.7669628858566284
Batch 58/64 loss: 1.7476985454559326
Batch 59/64 loss: 1.7469497919082642
Batch 60/64 loss: 1.75339674949646
Batch 61/64 loss: 1.7477949857711792
Batch 62/64 loss: 1.7556593418121338
Batch 63/64 loss: 1.7501418590545654
Batch 64/64 loss: 1.9397265911102295
Epoch 176  Train loss: 1.7526182520623301  Val loss: 1.7674010570106637
Epoch 177
-------------------------------
Batch 1/64 loss: 1.7459588050842285
Batch 2/64 loss: 1.7476897239685059
Batch 3/64 loss: 1.7547001838684082
Batch 4/64 loss: 1.750701665878296
Batch 5/64 loss: 1.7495017051696777
Batch 6/64 loss: 1.752234697341919
Batch 7/64 loss: 1.7475274801254272
Batch 8/64 loss: 1.7597798109054565
Batch 9/64 loss: 1.7583131790161133
Batch 10/64 loss: 1.7483223676681519
Batch 11/64 loss: 1.748297929763794
Batch 12/64 loss: 1.75105881690979
Batch 13/64 loss: 1.7540311813354492
Batch 14/64 loss: 1.7475227117538452
Batch 15/64 loss: 1.7434463500976562
Batch 16/64 loss: 1.7484116554260254
Batch 17/64 loss: 1.7499525547027588
Batch 18/64 loss: 1.7535481452941895
Batch 19/64 loss: 1.7488763332366943
Batch 20/64 loss: 1.7677667140960693
Batch 21/64 loss: 1.7462961673736572
Batch 22/64 loss: 1.745741367340088
Batch 23/64 loss: 1.751612901687622
Batch 24/64 loss: 1.7527830600738525
Batch 25/64 loss: 1.744168758392334
Batch 26/64 loss: 1.744516134262085
Batch 27/64 loss: 1.7477121353149414
Batch 28/64 loss: 1.7493233680725098
Batch 29/64 loss: 1.7502853870391846
Batch 30/64 loss: 1.7461369037628174
Batch 31/64 loss: 1.751015305519104
Batch 32/64 loss: 1.7475330829620361
Batch 33/64 loss: 1.7445757389068604
Batch 34/64 loss: 1.7501721382141113
Batch 35/64 loss: 1.7485558986663818
Batch 36/64 loss: 1.7482848167419434
Batch 37/64 loss: 1.745908260345459
Batch 38/64 loss: 1.7487547397613525
Batch 39/64 loss: 1.7467601299285889
Batch 40/64 loss: 1.746757984161377
Batch 41/64 loss: 1.7480744123458862
Batch 42/64 loss: 1.7496026754379272
Batch 43/64 loss: 1.7467694282531738
Batch 44/64 loss: 1.7481305599212646
Batch 45/64 loss: 1.7477898597717285
Batch 46/64 loss: 1.7471083402633667
Batch 47/64 loss: 1.750565528869629
Batch 48/64 loss: 1.7498877048492432
Batch 49/64 loss: 1.7498397827148438
Batch 50/64 loss: 1.75551176071167
Batch 51/64 loss: 1.7550302743911743
Batch 52/64 loss: 1.7513415813446045
Batch 53/64 loss: 1.7537859678268433
Batch 54/64 loss: 1.757798194885254
Batch 55/64 loss: 1.74855637550354
Batch 56/64 loss: 1.7460838556289673
Batch 57/64 loss: 1.7639594078063965
Batch 58/64 loss: 1.7487766742706299
Batch 59/64 loss: 1.7518559694290161
Batch 60/64 loss: 1.7521432638168335
Batch 61/64 loss: 1.752225399017334
Batch 62/64 loss: 1.7499022483825684
Batch 63/64 loss: 1.7544152736663818
Batch 64/64 loss: 1.9469516277313232
Epoch 177  Train loss: 1.7525318360796163  Val loss: 1.7702237527395033
Epoch 178
-------------------------------
Batch 1/64 loss: 1.7498551607131958
Batch 2/64 loss: 1.749147653579712
Batch 3/64 loss: 1.752942681312561
Batch 4/64 loss: 1.7504112720489502
Batch 5/64 loss: 1.7512288093566895
Batch 6/64 loss: 1.751380205154419
Batch 7/64 loss: 1.7562856674194336
Batch 8/64 loss: 1.748947262763977
Batch 9/64 loss: 1.7513062953948975
Batch 10/64 loss: 1.7497076988220215
Batch 11/64 loss: 1.7466390132904053
Batch 12/64 loss: 1.747546672821045
Batch 13/64 loss: 1.7512493133544922
Batch 14/64 loss: 1.747450351715088
Batch 15/64 loss: 1.7478920221328735
Batch 16/64 loss: 1.7522464990615845
Batch 17/64 loss: 1.7570364475250244
Batch 18/64 loss: 1.7497003078460693
Batch 19/64 loss: 1.7552634477615356
Batch 20/64 loss: 1.7486447095870972
Batch 21/64 loss: 1.7505311965942383
Batch 22/64 loss: 1.7694437503814697
Batch 23/64 loss: 1.7652143239974976
Batch 24/64 loss: 1.7503390312194824
Batch 25/64 loss: 1.7560838460922241
Batch 26/64 loss: 1.74714195728302
Batch 27/64 loss: 1.7486685514450073
Batch 28/64 loss: 1.7486237287521362
Batch 29/64 loss: 1.750976324081421
Batch 30/64 loss: 1.7488175630569458
Batch 31/64 loss: 1.7514393329620361
Batch 32/64 loss: 1.7448397874832153
Batch 33/64 loss: 1.7603905200958252
Batch 34/64 loss: 1.754530906677246
Batch 35/64 loss: 1.7527174949645996
Batch 36/64 loss: 1.7504045963287354
Batch 37/64 loss: 1.7647161483764648
Batch 38/64 loss: 1.7546718120574951
Batch 39/64 loss: 1.7624444961547852
Batch 40/64 loss: 1.7466192245483398
Batch 41/64 loss: 1.7504668235778809
Batch 42/64 loss: 1.7491434812545776
Batch 43/64 loss: 1.7462245225906372
Batch 44/64 loss: 1.7551374435424805
Batch 45/64 loss: 1.7501201629638672
Batch 46/64 loss: 1.7489185333251953
Batch 47/64 loss: 1.7488340139389038
Batch 48/64 loss: 1.7501102685928345
Batch 49/64 loss: 1.751320719718933
Batch 50/64 loss: 1.7501566410064697
Batch 51/64 loss: 1.759168028831482
Batch 52/64 loss: 1.7568525075912476
Batch 53/64 loss: 1.753456711769104
Batch 54/64 loss: 1.7506496906280518
Batch 55/64 loss: 1.7558979988098145
Batch 56/64 loss: 1.753481149673462
Batch 57/64 loss: 1.7515747547149658
Batch 58/64 loss: 1.753969430923462
Batch 59/64 loss: 1.7572665214538574
Batch 60/64 loss: 1.7649040222167969
Batch 61/64 loss: 1.7599053382873535
Batch 62/64 loss: 1.7501558065414429
Batch 63/64 loss: 1.7514508962631226
Batch 64/64 loss: 1.946303367614746
Epoch 178  Train loss: 1.7548610051472981  Val loss: 1.776285083842851
Epoch 179
-------------------------------
Batch 1/64 loss: 1.7504160404205322
Batch 2/64 loss: 1.750165343284607
Batch 3/64 loss: 1.7483277320861816
Batch 4/64 loss: 1.7558058500289917
Batch 5/64 loss: 1.749516487121582
Batch 6/64 loss: 1.751732587814331
Batch 7/64 loss: 1.7480727434158325
Batch 8/64 loss: 1.749258041381836
Batch 9/64 loss: 1.7491071224212646
Batch 10/64 loss: 1.752131700515747
Batch 11/64 loss: 1.7491028308868408
Batch 12/64 loss: 1.7568517923355103
Batch 13/64 loss: 1.7505489587783813
Batch 14/64 loss: 1.754133939743042
Batch 15/64 loss: 1.7533645629882812
Batch 16/64 loss: 1.750860571861267
Batch 17/64 loss: 1.7523409128189087
Batch 18/64 loss: 1.7562061548233032
Batch 19/64 loss: 1.7527896165847778
Batch 20/64 loss: 1.7538034915924072
Batch 21/64 loss: 1.7513411045074463
Batch 22/64 loss: 1.7530972957611084
Batch 23/64 loss: 1.7726097106933594
Batch 24/64 loss: 1.7452114820480347
Batch 25/64 loss: 1.7510932683944702
Batch 26/64 loss: 1.7509790658950806
Batch 27/64 loss: 1.7547059059143066
Batch 28/64 loss: 1.7603821754455566
Batch 29/64 loss: 1.7509772777557373
Batch 30/64 loss: 1.7514173984527588
Batch 31/64 loss: 1.7488489151000977
Batch 32/64 loss: 1.7556347846984863
Batch 33/64 loss: 1.7533249855041504
Batch 34/64 loss: 1.7546230554580688
Batch 35/64 loss: 1.749085783958435
Batch 36/64 loss: 1.7496609687805176
Batch 37/64 loss: 1.7559586763381958
Batch 38/64 loss: 1.7506637573242188
Batch 39/64 loss: 1.7522003650665283
Batch 40/64 loss: 1.7485198974609375
Batch 41/64 loss: 1.7494280338287354
Batch 42/64 loss: 1.7496678829193115
Batch 43/64 loss: 1.7512712478637695
Batch 44/64 loss: 1.7514218091964722
Batch 45/64 loss: 1.7482136487960815
Batch 46/64 loss: 1.7569687366485596
Batch 47/64 loss: 1.7635328769683838
Batch 48/64 loss: 1.752415418624878
Batch 49/64 loss: 1.7553117275238037
Batch 50/64 loss: 1.7547438144683838
Batch 51/64 loss: 1.7555696964263916
Batch 52/64 loss: 1.749253749847412
Batch 53/64 loss: 1.7515157461166382
Batch 54/64 loss: 1.7557299137115479
Batch 55/64 loss: 1.7526830434799194
Batch 56/64 loss: 1.7520869970321655
Batch 57/64 loss: 1.7513705492019653
Batch 58/64 loss: 1.7521071434020996
Batch 59/64 loss: 1.7475030422210693
Batch 60/64 loss: 1.7466789484024048
Batch 61/64 loss: 1.7510521411895752
Batch 62/64 loss: 1.7499600648880005
Batch 63/64 loss: 1.756832242012024
Batch 64/64 loss: 1.9470949172973633
Epoch 179  Train loss: 1.7546746983247645  Val loss: 1.7771188090347343
Epoch 180
-------------------------------
Batch 1/64 loss: 1.752301812171936
Batch 2/64 loss: 1.7567763328552246
Batch 3/64 loss: 1.7493126392364502
Batch 4/64 loss: 1.7511310577392578
Batch 5/64 loss: 1.7641328573226929
Batch 6/64 loss: 1.760439157485962
Batch 7/64 loss: 1.7538690567016602
Batch 8/64 loss: 1.7510312795639038
Batch 9/64 loss: 1.774124264717102
Batch 10/64 loss: 1.7522363662719727
Batch 11/64 loss: 1.7548463344573975
Batch 12/64 loss: 1.7622932195663452
Batch 13/64 loss: 1.7536715269088745
Batch 14/64 loss: 1.7519028186798096
Batch 15/64 loss: 1.7518364191055298
Batch 16/64 loss: 1.7523057460784912
Batch 17/64 loss: 1.7539366483688354
Batch 18/64 loss: 1.754791259765625
Batch 19/64 loss: 1.7500107288360596
Batch 20/64 loss: 1.753254771232605
Batch 21/64 loss: 1.749566912651062
Batch 22/64 loss: 1.7621636390686035
Batch 23/64 loss: 1.7478442192077637
Batch 24/64 loss: 1.7562756538391113
Batch 25/64 loss: 1.7482678890228271
Batch 26/64 loss: 1.7567092180252075
Batch 27/64 loss: 1.751947283744812
Batch 28/64 loss: 1.7537431716918945
Batch 29/64 loss: 1.7544078826904297
Batch 30/64 loss: 1.7563589811325073
Batch 31/64 loss: 1.750185489654541
Batch 32/64 loss: 1.7627439498901367
Batch 33/64 loss: 1.750046730041504
Batch 34/64 loss: 1.7543401718139648
Batch 35/64 loss: 1.7491934299468994
Batch 36/64 loss: 1.7504539489746094
Batch 37/64 loss: 1.7559030055999756
Batch 38/64 loss: 1.7517046928405762
Batch 39/64 loss: 1.7606770992279053
Batch 40/64 loss: 1.754268765449524
Batch 41/64 loss: 1.7566648721694946
Batch 42/64 loss: 1.7571232318878174
Batch 43/64 loss: 1.7530453205108643
Batch 44/64 loss: 1.749996542930603
Batch 45/64 loss: 1.7517900466918945
Batch 46/64 loss: 1.7511260509490967
Batch 47/64 loss: 1.7468955516815186
Batch 48/64 loss: 1.7512861490249634
Batch 49/64 loss: 1.7524669170379639
Batch 50/64 loss: 1.7543824911117554
Batch 51/64 loss: 1.7542481422424316
Batch 52/64 loss: 1.7489880323410034
Batch 53/64 loss: 1.7514821290969849
Batch 54/64 loss: 1.7517362833023071
Batch 55/64 loss: 1.7512180805206299
Batch 56/64 loss: 1.750423789024353
Batch 57/64 loss: 1.7621731758117676
Batch 58/64 loss: 1.7508362531661987
Batch 59/64 loss: 1.7512080669403076
Batch 60/64 loss: 1.7498418092727661
Batch 61/64 loss: 1.7508597373962402
Batch 62/64 loss: 1.7507508993148804
Batch 63/64 loss: 1.7521921396255493
Batch 64/64 loss: 1.9426605701446533
Epoch 180  Train loss: 1.7559017658233642  Val loss: 1.7826449174651575
Epoch 181
-------------------------------
Batch 1/64 loss: 1.7504891157150269
Batch 2/64 loss: 1.7527575492858887
Batch 3/64 loss: 1.7513316869735718
Batch 4/64 loss: 1.748805046081543
Batch 5/64 loss: 1.7516875267028809
Batch 6/64 loss: 1.7504773139953613
Batch 7/64 loss: 1.7501747608184814
Batch 8/64 loss: 1.7526098489761353
Batch 9/64 loss: 1.7516121864318848
Batch 10/64 loss: 1.750902533531189
Batch 11/64 loss: 1.7512680292129517
Batch 12/64 loss: 1.7536394596099854
Batch 13/64 loss: 1.7541487216949463
Batch 14/64 loss: 1.7587405443191528
Batch 15/64 loss: 1.7509632110595703
Batch 16/64 loss: 1.7535912990570068
Batch 17/64 loss: 1.747738242149353
Batch 18/64 loss: 1.7500630617141724
Batch 19/64 loss: 1.7517828941345215
Batch 20/64 loss: 1.7544687986373901
Batch 21/64 loss: 1.7510156631469727
Batch 22/64 loss: 1.7527754306793213
Batch 23/64 loss: 1.75359308719635
Batch 24/64 loss: 1.7503585815429688
Batch 25/64 loss: 1.7457600831985474
Batch 26/64 loss: 1.7536606788635254
Batch 27/64 loss: 1.7567081451416016
Batch 28/64 loss: 1.774045467376709
Batch 29/64 loss: 1.7602869272232056
Batch 30/64 loss: 1.7534220218658447
Batch 31/64 loss: 1.7540905475616455
Batch 32/64 loss: 1.749462366104126
Batch 33/64 loss: 1.7518603801727295
Batch 34/64 loss: 1.7518223524093628
Batch 35/64 loss: 1.7518119812011719
Batch 36/64 loss: 1.7471226453781128
Batch 37/64 loss: 1.7476414442062378
Batch 38/64 loss: 1.7467586994171143
Batch 39/64 loss: 1.7646064758300781
Batch 40/64 loss: 1.7498774528503418
Batch 41/64 loss: 1.7503573894500732
Batch 42/64 loss: 1.749181866645813
Batch 43/64 loss: 1.7547742128372192
Batch 44/64 loss: 1.7472045421600342
Batch 45/64 loss: 1.7487716674804688
Batch 46/64 loss: 1.7512626647949219
Batch 47/64 loss: 1.7497594356536865
Batch 48/64 loss: 1.747213363647461
Batch 49/64 loss: 1.7469077110290527
Batch 50/64 loss: 1.7536487579345703
Batch 51/64 loss: 1.75007963180542
Batch 52/64 loss: 1.7501134872436523
Batch 53/64 loss: 1.7506325244903564
Batch 54/64 loss: 1.7566640377044678
Batch 55/64 loss: 1.755868673324585
Batch 56/64 loss: 1.7506060600280762
Batch 57/64 loss: 1.7497403621673584
Batch 58/64 loss: 1.7495970726013184
Batch 59/64 loss: 1.743963360786438
Batch 60/64 loss: 1.7472364902496338
Batch 61/64 loss: 1.7570279836654663
Batch 62/64 loss: 1.749864935874939
Batch 63/64 loss: 1.7489004135131836
Batch 64/64 loss: 1.9361016750335693
Epoch 181  Train loss: 1.7539668260836134  Val loss: 1.7712035547826708
Epoch 182
-------------------------------
Batch 1/64 loss: 1.7491575479507446
Batch 2/64 loss: 1.7455456256866455
Batch 3/64 loss: 1.7467522621154785
Batch 4/64 loss: 1.7519850730895996
Batch 5/64 loss: 1.752469778060913
Batch 6/64 loss: 1.7526452541351318
Batch 7/64 loss: 1.7511993646621704
Batch 8/64 loss: 1.749165415763855
Batch 9/64 loss: 1.7482759952545166
Batch 10/64 loss: 1.7489962577819824
Batch 11/64 loss: 1.751854419708252
Batch 12/64 loss: 1.749311923980713
Batch 13/64 loss: 1.7471091747283936
Batch 14/64 loss: 1.7675080299377441
Batch 15/64 loss: 1.745301604270935
Batch 16/64 loss: 1.761494755744934
Batch 17/64 loss: 1.7484321594238281
Batch 18/64 loss: 1.7664719820022583
Batch 19/64 loss: 1.752061128616333
Batch 20/64 loss: 1.7514690160751343
Batch 21/64 loss: 1.7491302490234375
Batch 22/64 loss: 1.7509949207305908
Batch 23/64 loss: 1.7546480894088745
Batch 24/64 loss: 1.745786428451538
Batch 25/64 loss: 1.7510643005371094
Batch 26/64 loss: 1.7479196786880493
Batch 27/64 loss: 1.7494261264801025
Batch 28/64 loss: 1.756157636642456
Batch 29/64 loss: 1.746309757232666
Batch 30/64 loss: 1.7488646507263184
Batch 31/64 loss: 1.7461204528808594
Batch 32/64 loss: 1.7465851306915283
Batch 33/64 loss: 1.7490161657333374
Batch 34/64 loss: 1.7522592544555664
Batch 35/64 loss: 1.7574255466461182
Batch 36/64 loss: 1.7487386465072632
Batch 37/64 loss: 1.752327561378479
Batch 38/64 loss: 1.7474533319473267
Batch 39/64 loss: 1.752018690109253
Batch 40/64 loss: 1.7543977499008179
Batch 41/64 loss: 1.7548779249191284
Batch 42/64 loss: 1.7495548725128174
Batch 43/64 loss: 1.751072883605957
Batch 44/64 loss: 1.7472463846206665
Batch 45/64 loss: 1.751727819442749
Batch 46/64 loss: 1.749154806137085
Batch 47/64 loss: 1.7556266784667969
Batch 48/64 loss: 1.7505180835723877
Batch 49/64 loss: 1.7460507154464722
Batch 50/64 loss: 1.7504945993423462
Batch 51/64 loss: 1.7572811841964722
Batch 52/64 loss: 1.749900460243225
Batch 53/64 loss: 1.7501068115234375
Batch 54/64 loss: 1.751238465309143
Batch 55/64 loss: 1.7471054792404175
Batch 56/64 loss: 1.7503025531768799
Batch 57/64 loss: 1.749997615814209
Batch 58/64 loss: 1.7490218877792358
Batch 59/64 loss: 1.7495136260986328
Batch 60/64 loss: 1.7450706958770752
Batch 61/64 loss: 1.7461159229278564
Batch 62/64 loss: 1.7466992139816284
Batch 63/64 loss: 1.75588858127594
Batch 64/64 loss: 1.9517664909362793
Epoch 182  Train loss: 1.753133227778416  Val loss: 1.7700255269447143
Epoch 183
-------------------------------
Batch 1/64 loss: 1.7505037784576416
Batch 2/64 loss: 1.749075174331665
Batch 3/64 loss: 1.7451496124267578
Batch 4/64 loss: 1.748741626739502
Batch 5/64 loss: 1.7643036842346191
Batch 6/64 loss: 1.7541687488555908
Batch 7/64 loss: 1.7487831115722656
Batch 8/64 loss: 1.7475379705429077
Batch 9/64 loss: 1.7458438873291016
Batch 10/64 loss: 1.747548222541809
Batch 11/64 loss: 1.7495009899139404
Batch 12/64 loss: 1.7489854097366333
Batch 13/64 loss: 1.7489359378814697
Batch 14/64 loss: 1.746361494064331
Batch 15/64 loss: 1.74819016456604
Batch 16/64 loss: 1.7457115650177002
Batch 17/64 loss: 1.748443841934204
Batch 18/64 loss: 1.7482092380523682
Batch 19/64 loss: 1.761313796043396
Batch 20/64 loss: 1.7541488409042358
Batch 21/64 loss: 1.7469592094421387
Batch 22/64 loss: 1.749204397201538
Batch 23/64 loss: 1.7493691444396973
Batch 24/64 loss: 1.7484335899353027
Batch 25/64 loss: 1.7469277381896973
Batch 26/64 loss: 1.754621982574463
Batch 27/64 loss: 1.7492780685424805
Batch 28/64 loss: 1.7504103183746338
Batch 29/64 loss: 1.7488492727279663
Batch 30/64 loss: 1.7487993240356445
Batch 31/64 loss: 1.750938892364502
Batch 32/64 loss: 1.7523783445358276
Batch 33/64 loss: 1.7458934783935547
Batch 34/64 loss: 1.748197317123413
Batch 35/64 loss: 1.7553234100341797
Batch 36/64 loss: 1.7491955757141113
Batch 37/64 loss: 1.748463749885559
Batch 38/64 loss: 1.746890664100647
Batch 39/64 loss: 1.7554848194122314
Batch 40/64 loss: 1.7479496002197266
Batch 41/64 loss: 1.7551175355911255
Batch 42/64 loss: 1.7533375024795532
Batch 43/64 loss: 1.7499345541000366
Batch 44/64 loss: 1.7509825229644775
Batch 45/64 loss: 1.749083399772644
Batch 46/64 loss: 1.752640724182129
Batch 47/64 loss: 1.7559541463851929
Batch 48/64 loss: 1.7569459676742554
Batch 49/64 loss: 1.7568341493606567
Batch 50/64 loss: 1.753537893295288
Batch 51/64 loss: 1.7534890174865723
Batch 52/64 loss: 1.7508141994476318
Batch 53/64 loss: 1.7522274255752563
Batch 54/64 loss: 1.7547030448913574
Batch 55/64 loss: 1.7544281482696533
Batch 56/64 loss: 1.754840612411499
Batch 57/64 loss: 1.7517545223236084
Batch 58/64 loss: 1.7486766576766968
Batch 59/64 loss: 1.765685796737671
Batch 60/64 loss: 1.7503552436828613
Batch 61/64 loss: 1.7502574920654297
Batch 62/64 loss: 1.7482731342315674
Batch 63/64 loss: 1.7513763904571533
Batch 64/64 loss: 1.9433233737945557
Epoch 183  Train loss: 1.753314017314537  Val loss: 1.7715700369110632
Epoch 184
-------------------------------
Batch 1/64 loss: 1.7558550834655762
Batch 2/64 loss: 1.7531282901763916
Batch 3/64 loss: 1.7513422966003418
Batch 4/64 loss: 1.7515337467193604
Batch 5/64 loss: 1.7489837408065796
Batch 6/64 loss: 1.747971534729004
Batch 7/64 loss: 1.7478746175765991
Batch 8/64 loss: 1.745510220527649
Batch 9/64 loss: 1.7440484762191772
Batch 10/64 loss: 1.763486385345459
Batch 11/64 loss: 1.7431159019470215
Batch 12/64 loss: 1.7521770000457764
Batch 13/64 loss: 1.7586194276809692
Batch 14/64 loss: 1.7518274784088135
Batch 15/64 loss: 1.7476693391799927
Batch 16/64 loss: 1.7468831539154053
Batch 17/64 loss: 1.7492282390594482
Batch 18/64 loss: 1.745436668395996
Batch 19/64 loss: 1.7498950958251953
Batch 20/64 loss: 1.7543666362762451
Batch 21/64 loss: 1.7508107423782349
Batch 22/64 loss: 1.7435885667800903
Batch 23/64 loss: 1.7460767030715942
Batch 24/64 loss: 1.7601642608642578
Batch 25/64 loss: 1.7481091022491455
Batch 26/64 loss: 1.7442348003387451
Batch 27/64 loss: 1.7554397583007812
Batch 28/64 loss: 1.7489945888519287
Batch 29/64 loss: 1.7472929954528809
Batch 30/64 loss: 1.745910882949829
Batch 31/64 loss: 1.745539665222168
Batch 32/64 loss: 1.7481142282485962
Batch 33/64 loss: 1.7482672929763794
Batch 34/64 loss: 1.750853180885315
Batch 35/64 loss: 1.7471249103546143
Batch 36/64 loss: 1.749646782875061
Batch 37/64 loss: 1.7572143077850342
Batch 38/64 loss: 1.7508156299591064
Batch 39/64 loss: 1.7472302913665771
Batch 40/64 loss: 1.7532694339752197
Batch 41/64 loss: 1.7456471920013428
Batch 42/64 loss: 1.747039556503296
Batch 43/64 loss: 1.7492973804473877
Batch 44/64 loss: 1.7509644031524658
Batch 45/64 loss: 1.751979112625122
Batch 46/64 loss: 1.7540446519851685
Batch 47/64 loss: 1.7564886808395386
Batch 48/64 loss: 1.7561458349227905
Batch 49/64 loss: 1.7550874948501587
Batch 50/64 loss: 1.7485356330871582
Batch 51/64 loss: 1.7514989376068115
Batch 52/64 loss: 1.7539961338043213
Batch 53/64 loss: 1.7463557720184326
Batch 54/64 loss: 1.7491849660873413
Batch 55/64 loss: 1.749842882156372
Batch 56/64 loss: 1.7504934072494507
Batch 57/64 loss: 1.7459383010864258
Batch 58/64 loss: 1.7476814985275269
Batch 59/64 loss: 1.7469301223754883
Batch 60/64 loss: 1.7457536458969116
Batch 61/64 loss: 1.747485876083374
Batch 62/64 loss: 1.7616209983825684
Batch 63/64 loss: 1.7486181259155273
Batch 64/64 loss: 1.9423046112060547
Epoch 184  Train loss: 1.7523923219418993  Val loss: 1.7709424962702485
Epoch 185
-------------------------------
Batch 1/64 loss: 1.7521005868911743
Batch 2/64 loss: 1.7529696226119995
Batch 3/64 loss: 1.7501847743988037
Batch 4/64 loss: 1.7481199502944946
Batch 5/64 loss: 1.7550151348114014
Batch 6/64 loss: 1.7476365566253662
Batch 7/64 loss: 1.7484090328216553
Batch 8/64 loss: 1.7553168535232544
Batch 9/64 loss: 1.7529385089874268
Batch 10/64 loss: 1.7515158653259277
Batch 11/64 loss: 1.7545740604400635
Batch 12/64 loss: 1.7483482360839844
Batch 13/64 loss: 1.7512482404708862
Batch 14/64 loss: 1.7526755332946777
Batch 15/64 loss: 1.749250054359436
Batch 16/64 loss: 1.7500312328338623
Batch 17/64 loss: 1.7469379901885986
Batch 18/64 loss: 1.747636079788208
Batch 19/64 loss: 1.753182291984558
Batch 20/64 loss: 1.7596476078033447
Batch 21/64 loss: 1.7551517486572266
Batch 22/64 loss: 1.7497082948684692
Batch 23/64 loss: 1.748325228691101
Batch 24/64 loss: 1.7535479068756104
Batch 25/64 loss: 1.7520575523376465
Batch 26/64 loss: 1.7558577060699463
Batch 27/64 loss: 1.7557613849639893
Batch 28/64 loss: 1.7480120658874512
Batch 29/64 loss: 1.7463223934173584
Batch 30/64 loss: 1.7479665279388428
Batch 31/64 loss: 1.7517049312591553
Batch 32/64 loss: 1.7632251977920532
Batch 33/64 loss: 1.749335527420044
Batch 34/64 loss: 1.748823881149292
Batch 35/64 loss: 1.7500633001327515
Batch 36/64 loss: 1.7467262744903564
Batch 37/64 loss: 1.7513151168823242
Batch 38/64 loss: 1.7477786540985107
Batch 39/64 loss: 1.7489876747131348
Batch 40/64 loss: 1.7489755153656006
Batch 41/64 loss: 1.7507072687149048
Batch 42/64 loss: 1.7521108388900757
Batch 43/64 loss: 1.7477805614471436
Batch 44/64 loss: 1.7511439323425293
Batch 45/64 loss: 1.7463557720184326
Batch 46/64 loss: 1.7477635145187378
Batch 47/64 loss: 1.7554694414138794
Batch 48/64 loss: 1.7509400844573975
Batch 49/64 loss: 1.751193642616272
Batch 50/64 loss: 1.7473537921905518
Batch 51/64 loss: 1.750573754310608
Batch 52/64 loss: 1.7465009689331055
Batch 53/64 loss: 1.7482913732528687
Batch 54/64 loss: 1.7618379592895508
Batch 55/64 loss: 1.7478632926940918
Batch 56/64 loss: 1.7484180927276611
Batch 57/64 loss: 1.7518055438995361
Batch 58/64 loss: 1.7504318952560425
Batch 59/64 loss: 1.7455371618270874
Batch 60/64 loss: 1.746088981628418
Batch 61/64 loss: 1.750805139541626
Batch 62/64 loss: 1.745310664176941
Batch 63/64 loss: 1.7474913597106934
Batch 64/64 loss: 1.9496018886566162
Epoch 185  Train loss: 1.7529625341004016  Val loss: 1.7660504157600534
Epoch 186
-------------------------------
Batch 1/64 loss: 1.7465192079544067
Batch 2/64 loss: 1.7474619150161743
Batch 3/64 loss: 1.7485976219177246
Batch 4/64 loss: 1.7449352741241455
Batch 5/64 loss: 1.744152307510376
Batch 6/64 loss: 1.748610258102417
Batch 7/64 loss: 1.7447824478149414
Batch 8/64 loss: 1.751625895500183
Batch 9/64 loss: 1.7463542222976685
Batch 10/64 loss: 1.7589173316955566
Batch 11/64 loss: 1.7472445964813232
Batch 12/64 loss: 1.7451753616333008
Batch 13/64 loss: 1.7485878467559814
Batch 14/64 loss: 1.7520978450775146
Batch 15/64 loss: 1.7476478815078735
Batch 16/64 loss: 1.7510814666748047
Batch 17/64 loss: 1.7455424070358276
Batch 18/64 loss: 1.7467273473739624
Batch 19/64 loss: 1.7458829879760742
Batch 20/64 loss: 1.7501726150512695
Batch 21/64 loss: 1.7503623962402344
Batch 22/64 loss: 1.7627508640289307
Batch 23/64 loss: 1.7632665634155273
Batch 24/64 loss: 1.752038598060608
Batch 25/64 loss: 1.7488294839859009
Batch 26/64 loss: 1.7490124702453613
Batch 27/64 loss: 1.7483582496643066
Batch 28/64 loss: 1.7514126300811768
Batch 29/64 loss: 1.748018503189087
Batch 30/64 loss: 1.7520391941070557
Batch 31/64 loss: 1.7497048377990723
Batch 32/64 loss: 1.7454473972320557
Batch 33/64 loss: 1.748395323753357
Batch 34/64 loss: 1.7479774951934814
Batch 35/64 loss: 1.7466503381729126
Batch 36/64 loss: 1.7443047761917114
Batch 37/64 loss: 1.7447378635406494
Batch 38/64 loss: 1.7467331886291504
Batch 39/64 loss: 1.7449471950531006
Batch 40/64 loss: 1.7457873821258545
Batch 41/64 loss: 1.7453281879425049
Batch 42/64 loss: 1.7478556632995605
Batch 43/64 loss: 1.7438631057739258
Batch 44/64 loss: 1.7444814443588257
Batch 45/64 loss: 1.7453547716140747
Batch 46/64 loss: 1.7471213340759277
Batch 47/64 loss: 1.7437525987625122
Batch 48/64 loss: 1.7457077503204346
Batch 49/64 loss: 1.743849515914917
Batch 50/64 loss: 1.7423456907272339
Batch 51/64 loss: 1.746611475944519
Batch 52/64 loss: 1.7439652681350708
Batch 53/64 loss: 1.7423760890960693
Batch 54/64 loss: 1.745129942893982
Batch 55/64 loss: 1.7464936971664429
Batch 56/64 loss: 1.7441679239273071
Batch 57/64 loss: 1.7455869913101196
Batch 58/64 loss: 1.7453750371932983
Batch 59/64 loss: 1.7474678754806519
Batch 60/64 loss: 1.751556396484375
Batch 61/64 loss: 1.7478336095809937
Batch 62/64 loss: 1.744480848312378
Batch 63/64 loss: 1.7498693466186523
Batch 64/64 loss: 1.9383742809295654
Epoch 186  Train loss: 1.7499175978641883  Val loss: 1.767929401594339
Epoch 187
-------------------------------
Batch 1/64 loss: 1.7489397525787354
Batch 2/64 loss: 1.7460086345672607
Batch 3/64 loss: 1.7507569789886475
Batch 4/64 loss: 1.7638078927993774
Batch 5/64 loss: 1.7631518840789795
Batch 6/64 loss: 1.7514559030532837
Batch 7/64 loss: 1.7478903532028198
Batch 8/64 loss: 1.7492938041687012
Batch 9/64 loss: 1.7475109100341797
Batch 10/64 loss: 1.7501115798950195
Batch 11/64 loss: 1.7478586435317993
Batch 12/64 loss: 1.7473886013031006
Batch 13/64 loss: 1.7482285499572754
Batch 14/64 loss: 1.7469319105148315
Batch 15/64 loss: 1.7471455335617065
Batch 16/64 loss: 1.7490614652633667
Batch 17/64 loss: 1.7505221366882324
Batch 18/64 loss: 1.7434438467025757
Batch 19/64 loss: 1.7473362684249878
Batch 20/64 loss: 1.7487963438034058
Batch 21/64 loss: 1.7524060010910034
Batch 22/64 loss: 1.7488460540771484
Batch 23/64 loss: 1.7474992275238037
Batch 24/64 loss: 1.7499659061431885
Batch 25/64 loss: 1.7559607028961182
Batch 26/64 loss: 1.7539037466049194
Batch 27/64 loss: 1.757270336151123
Batch 28/64 loss: 1.7464518547058105
Batch 29/64 loss: 1.7490284442901611
Batch 30/64 loss: 1.74540376663208
Batch 31/64 loss: 1.7516279220581055
Batch 32/64 loss: 1.747926950454712
Batch 33/64 loss: 1.7495014667510986
Batch 34/64 loss: 1.7487962245941162
Batch 35/64 loss: 1.751142144203186
Batch 36/64 loss: 1.7482531070709229
Batch 37/64 loss: 1.7455129623413086
Batch 38/64 loss: 1.7515311241149902
Batch 39/64 loss: 1.753400444984436
Batch 40/64 loss: 1.7473649978637695
Batch 41/64 loss: 1.7463549375534058
Batch 42/64 loss: 1.746898889541626
Batch 43/64 loss: 1.7454818487167358
Batch 44/64 loss: 1.7431156635284424
Batch 45/64 loss: 1.7475610971450806
Batch 46/64 loss: 1.749263882637024
Batch 47/64 loss: 1.7466245889663696
Batch 48/64 loss: 1.744288444519043
Batch 49/64 loss: 1.747731328010559
Batch 50/64 loss: 1.748057246208191
Batch 51/64 loss: 1.747003436088562
Batch 52/64 loss: 1.7449935674667358
Batch 53/64 loss: 1.7586784362792969
Batch 54/64 loss: 1.7463988065719604
Batch 55/64 loss: 1.7534124851226807
Batch 56/64 loss: 1.7453340291976929
Batch 57/64 loss: 1.7466012239456177
Batch 58/64 loss: 1.7472103834152222
Batch 59/64 loss: 1.7445976734161377
Batch 60/64 loss: 1.7471696138381958
Batch 61/64 loss: 1.745790958404541
Batch 62/64 loss: 1.7509171962738037
Batch 63/64 loss: 1.7468760013580322
Batch 64/64 loss: 1.9391109943389893
Epoch 187  Train loss: 1.7512490880255607  Val loss: 1.7658678739750917
Epoch 188
-------------------------------
Batch 1/64 loss: 1.7463326454162598
Batch 2/64 loss: 1.7451910972595215
Batch 3/64 loss: 1.7526837587356567
Batch 4/64 loss: 1.7448315620422363
Batch 5/64 loss: 1.750776767730713
Batch 6/64 loss: 1.7478588819503784
Batch 7/64 loss: 1.7493536472320557
Batch 8/64 loss: 1.746056318283081
Batch 9/64 loss: 1.7476757764816284
Batch 10/64 loss: 1.7451183795928955
Batch 11/64 loss: 1.7453166246414185
Batch 12/64 loss: 1.746957540512085
Batch 13/64 loss: 1.7460241317749023
Batch 14/64 loss: 1.7498173713684082
Batch 15/64 loss: 1.7463113069534302
Batch 16/64 loss: 1.7466264963150024
Batch 17/64 loss: 1.7482881546020508
Batch 18/64 loss: 1.7492082118988037
Batch 19/64 loss: 1.74668550491333
Batch 20/64 loss: 1.75072181224823
Batch 21/64 loss: 1.7483282089233398
Batch 22/64 loss: 1.7445497512817383
Batch 23/64 loss: 1.7453926801681519
Batch 24/64 loss: 1.7492095232009888
Batch 25/64 loss: 1.7505097389221191
Batch 26/64 loss: 1.7630844116210938
Batch 27/64 loss: 1.7430610656738281
Batch 28/64 loss: 1.746739149093628
Batch 29/64 loss: 1.751380443572998
Batch 30/64 loss: 1.7500379085540771
Batch 31/64 loss: 1.7471749782562256
Batch 32/64 loss: 1.7468751668930054
Batch 33/64 loss: 1.758100152015686
Batch 34/64 loss: 1.746823787689209
Batch 35/64 loss: 1.7458783388137817
Batch 36/64 loss: 1.7449475526809692
Batch 37/64 loss: 1.7449960708618164
Batch 38/64 loss: 1.7461525201797485
Batch 39/64 loss: 1.7429819107055664
Batch 40/64 loss: 1.7465486526489258
Batch 41/64 loss: 1.7450647354125977
Batch 42/64 loss: 1.7452327013015747
Batch 43/64 loss: 1.7446401119232178
Batch 44/64 loss: 1.7440727949142456
Batch 45/64 loss: 1.7463226318359375
Batch 46/64 loss: 1.7476239204406738
Batch 47/64 loss: 1.7475320100784302
Batch 48/64 loss: 1.7463688850402832
Batch 49/64 loss: 1.7488657236099243
Batch 50/64 loss: 1.7594388723373413
Batch 51/64 loss: 1.749039649963379
Batch 52/64 loss: 1.7439371347427368
Batch 53/64 loss: 1.7449233531951904
Batch 54/64 loss: 1.74537992477417
Batch 55/64 loss: 1.745689034461975
Batch 56/64 loss: 1.7439873218536377
Batch 57/64 loss: 1.7420923709869385
Batch 58/64 loss: 1.7432396411895752
Batch 59/64 loss: 1.7523515224456787
Batch 60/64 loss: 1.7480576038360596
Batch 61/64 loss: 1.7479665279388428
Batch 62/64 loss: 1.7464193105697632
Batch 63/64 loss: 1.7446212768554688
Batch 64/64 loss: 1.937225341796875
Epoch 188  Train loss: 1.7496532402786553  Val loss: 1.7665062860115288
Epoch 189
-------------------------------
Batch 1/64 loss: 1.7558786869049072
Batch 2/64 loss: 1.7472808361053467
Batch 3/64 loss: 1.7473797798156738
Batch 4/64 loss: 1.746324062347412
Batch 5/64 loss: 1.7427937984466553
Batch 6/64 loss: 1.7538741827011108
Batch 7/64 loss: 1.7534425258636475
Batch 8/64 loss: 1.747582197189331
Batch 9/64 loss: 1.746829867362976
Batch 10/64 loss: 1.7455437183380127
Batch 11/64 loss: 1.7468575239181519
Batch 12/64 loss: 1.7478413581848145
Batch 13/64 loss: 1.7465407848358154
Batch 14/64 loss: 1.750154733657837
Batch 15/64 loss: 1.7526793479919434
Batch 16/64 loss: 1.7497793436050415
Batch 17/64 loss: 1.7441548109054565
Batch 18/64 loss: 1.7508445978164673
Batch 19/64 loss: 1.7470707893371582
Batch 20/64 loss: 1.7486298084259033
Batch 21/64 loss: 1.7461081743240356
Batch 22/64 loss: 1.7482376098632812
Batch 23/64 loss: 1.748740792274475
Batch 24/64 loss: 1.7429698705673218
Batch 25/64 loss: 1.7480883598327637
Batch 26/64 loss: 1.7438346147537231
Batch 27/64 loss: 1.7439358234405518
Batch 28/64 loss: 1.7420198917388916
Batch 29/64 loss: 1.7427430152893066
Batch 30/64 loss: 1.7445390224456787
Batch 31/64 loss: 1.7438199520111084
Batch 32/64 loss: 1.7447510957717896
Batch 33/64 loss: 1.7423155307769775
Batch 34/64 loss: 1.7681267261505127
Batch 35/64 loss: 1.746561050415039
Batch 36/64 loss: 1.7450416088104248
Batch 37/64 loss: 1.7566094398498535
Batch 38/64 loss: 1.7469146251678467
Batch 39/64 loss: 1.7487149238586426
Batch 40/64 loss: 1.7446898221969604
Batch 41/64 loss: 1.747013807296753
Batch 42/64 loss: 1.744124412536621
Batch 43/64 loss: 1.7467082738876343
Batch 44/64 loss: 1.7433568239212036
Batch 45/64 loss: 1.7465115785598755
Batch 46/64 loss: 1.749049425125122
Batch 47/64 loss: 1.7427902221679688
Batch 48/64 loss: 1.7450687885284424
Batch 49/64 loss: 1.7434594631195068
Batch 50/64 loss: 1.7459568977355957
Batch 51/64 loss: 1.7434910535812378
Batch 52/64 loss: 1.7457075119018555
Batch 53/64 loss: 1.7466926574707031
Batch 54/64 loss: 1.7499314546585083
Batch 55/64 loss: 1.7461529970169067
Batch 56/64 loss: 1.7454890012741089
Batch 57/64 loss: 1.7443327903747559
Batch 58/64 loss: 1.7468684911727905
Batch 59/64 loss: 1.7453665733337402
Batch 60/64 loss: 1.7451494932174683
Batch 61/64 loss: 1.7447344064712524
Batch 62/64 loss: 1.760168194770813
Batch 63/64 loss: 1.747968077659607
Batch 64/64 loss: 1.940024495124817
Epoch 189  Train loss: 1.7495114583595126  Val loss: 1.767246736283974
Epoch 190
-------------------------------
Batch 1/64 loss: 1.7462924718856812
Batch 2/64 loss: 1.7514820098876953
Batch 3/64 loss: 1.745842695236206
Batch 4/64 loss: 1.7411887645721436
Batch 5/64 loss: 1.7528305053710938
Batch 6/64 loss: 1.7467472553253174
Batch 7/64 loss: 1.7460088729858398
Batch 8/64 loss: 1.7500054836273193
Batch 9/64 loss: 1.746712327003479
Batch 10/64 loss: 1.7591652870178223
Batch 11/64 loss: 1.7465436458587646
Batch 12/64 loss: 1.7470576763153076
Batch 13/64 loss: 1.745842456817627
Batch 14/64 loss: 1.743501901626587
Batch 15/64 loss: 1.7448198795318604
Batch 16/64 loss: 1.7643884420394897
Batch 17/64 loss: 1.7431633472442627
Batch 18/64 loss: 1.7459359169006348
Batch 19/64 loss: 1.7430933713912964
Batch 20/64 loss: 1.7445052862167358
Batch 21/64 loss: 1.7435599565505981
Batch 22/64 loss: 1.741553544998169
Batch 23/64 loss: 1.74607515335083
Batch 24/64 loss: 1.742588758468628
Batch 25/64 loss: 1.7417938709259033
Batch 26/64 loss: 1.7497315406799316
Batch 27/64 loss: 1.7500898838043213
Batch 28/64 loss: 1.7473526000976562
Batch 29/64 loss: 1.748124599456787
Batch 30/64 loss: 1.746657371520996
Batch 31/64 loss: 1.7481657266616821
Batch 32/64 loss: 1.746772050857544
Batch 33/64 loss: 1.7538281679153442
Batch 34/64 loss: 1.7446941137313843
Batch 35/64 loss: 1.745932698249817
Batch 36/64 loss: 1.7473483085632324
Batch 37/64 loss: 1.745097279548645
Batch 38/64 loss: 1.7449872493743896
Batch 39/64 loss: 1.7482051849365234
Batch 40/64 loss: 1.75020170211792
Batch 41/64 loss: 1.745272159576416
Batch 42/64 loss: 1.742306113243103
Batch 43/64 loss: 1.7448099851608276
Batch 44/64 loss: 1.7449780702590942
Batch 45/64 loss: 1.7490315437316895
Batch 46/64 loss: 1.7446686029434204
Batch 47/64 loss: 1.7485543489456177
Batch 48/64 loss: 1.743779182434082
Batch 49/64 loss: 1.7490205764770508
Batch 50/64 loss: 1.7426825761795044
Batch 51/64 loss: 1.7440500259399414
Batch 52/64 loss: 1.742296576499939
Batch 53/64 loss: 1.7479199171066284
Batch 54/64 loss: 1.7561814785003662
Batch 55/64 loss: 1.7585322856903076
Batch 56/64 loss: 1.7470954656600952
Batch 57/64 loss: 1.7473289966583252
Batch 58/64 loss: 1.7494728565216064
Batch 59/64 loss: 1.7443954944610596
Batch 60/64 loss: 1.7406681776046753
Batch 61/64 loss: 1.7466261386871338
Batch 62/64 loss: 1.743955135345459
Batch 63/64 loss: 1.746567726135254
Batch 64/64 loss: 1.9377503395080566
Epoch 190  Train loss: 1.749198330149931  Val loss: 1.7656011360207784
Epoch 191
-------------------------------
Batch 1/64 loss: 1.7429335117340088
Batch 2/64 loss: 1.7433995008468628
Batch 3/64 loss: 1.742302417755127
Batch 4/64 loss: 1.7422447204589844
Batch 5/64 loss: 1.7431973218917847
Batch 6/64 loss: 1.744011402130127
Batch 7/64 loss: 1.741295337677002
Batch 8/64 loss: 1.7480018138885498
Batch 9/64 loss: 1.7455593347549438
Batch 10/64 loss: 1.7478177547454834
Batch 11/64 loss: 1.7471203804016113
Batch 12/64 loss: 1.744651198387146
Batch 13/64 loss: 1.7452809810638428
Batch 14/64 loss: 1.7469303607940674
Batch 15/64 loss: 1.7470135688781738
Batch 16/64 loss: 1.7452925443649292
Batch 17/64 loss: 1.7434773445129395
Batch 18/64 loss: 1.7428758144378662
Batch 19/64 loss: 1.7473514080047607
Batch 20/64 loss: 1.7433276176452637
Batch 21/64 loss: 1.7473098039627075
Batch 22/64 loss: 1.747520923614502
Batch 23/64 loss: 1.746444821357727
Batch 24/64 loss: 1.7471582889556885
Batch 25/64 loss: 1.7537124156951904
Batch 26/64 loss: 1.7410227060317993
Batch 27/64 loss: 1.7595607042312622
Batch 28/64 loss: 1.743849754333496
Batch 29/64 loss: 1.7443815469741821
Batch 30/64 loss: 1.744749665260315
Batch 31/64 loss: 1.7478101253509521
Batch 32/64 loss: 1.7495700120925903
Batch 33/64 loss: 1.7473695278167725
Batch 34/64 loss: 1.7436567544937134
Batch 35/64 loss: 1.7460553646087646
Batch 36/64 loss: 1.749758243560791
Batch 37/64 loss: 1.7591331005096436
Batch 38/64 loss: 1.7558660507202148
Batch 39/64 loss: 1.7467422485351562
Batch 40/64 loss: 1.7480233907699585
Batch 41/64 loss: 1.7457804679870605
Batch 42/64 loss: 1.747277021408081
Batch 43/64 loss: 1.7468843460083008
Batch 44/64 loss: 1.7452411651611328
Batch 45/64 loss: 1.7430062294006348
Batch 46/64 loss: 1.7479403018951416
Batch 47/64 loss: 1.7523523569107056
Batch 48/64 loss: 1.7505970001220703
Batch 49/64 loss: 1.7467777729034424
Batch 50/64 loss: 1.7442299127578735
Batch 51/64 loss: 1.743067741394043
Batch 52/64 loss: 1.744926929473877
Batch 53/64 loss: 1.7449548244476318
Batch 54/64 loss: 1.741929531097412
Batch 55/64 loss: 1.7456542253494263
Batch 56/64 loss: 1.7530865669250488
Batch 57/64 loss: 1.7433171272277832
Batch 58/64 loss: 1.7440977096557617
Batch 59/64 loss: 1.7468791007995605
Batch 60/64 loss: 1.7552183866500854
Batch 61/64 loss: 1.7444875240325928
Batch 62/64 loss: 1.7449305057525635
Batch 63/64 loss: 1.7428834438323975
Batch 64/64 loss: 1.939888596534729
Epoch 191  Train loss: 1.7487720223034129  Val loss: 1.7633774641043543
Saving best model, epoch: 191
Epoch 192
-------------------------------
Batch 1/64 loss: 1.7444674968719482
Batch 2/64 loss: 1.7502880096435547
Batch 3/64 loss: 1.7432270050048828
Batch 4/64 loss: 1.7434636354446411
Batch 5/64 loss: 1.7471716403961182
Batch 6/64 loss: 1.744431495666504
Batch 7/64 loss: 1.746194839477539
Batch 8/64 loss: 1.7461315393447876
Batch 9/64 loss: 1.7432873249053955
Batch 10/64 loss: 1.7480370998382568
Batch 11/64 loss: 1.7458983659744263
Batch 12/64 loss: 1.771806240081787
Batch 13/64 loss: 1.741184949874878
Batch 14/64 loss: 1.744368553161621
Batch 15/64 loss: 1.7474174499511719
Batch 16/64 loss: 1.7426948547363281
Batch 17/64 loss: 1.7445210218429565
Batch 18/64 loss: 1.7430286407470703
Batch 19/64 loss: 1.746535062789917
Batch 20/64 loss: 1.7452497482299805
Batch 21/64 loss: 1.7467117309570312
Batch 22/64 loss: 1.7456541061401367
Batch 23/64 loss: 1.7462904453277588
Batch 24/64 loss: 1.7477660179138184
Batch 25/64 loss: 1.7468777894973755
Batch 26/64 loss: 1.7440547943115234
Batch 27/64 loss: 1.7447178363800049
Batch 28/64 loss: 1.7469885349273682
Batch 29/64 loss: 1.7477550506591797
Batch 30/64 loss: 1.744574785232544
Batch 31/64 loss: 1.744377851486206
Batch 32/64 loss: 1.7471657991409302
Batch 33/64 loss: 1.747147798538208
Batch 34/64 loss: 1.7423518896102905
Batch 35/64 loss: 1.7447690963745117
Batch 36/64 loss: 1.7447140216827393
Batch 37/64 loss: 1.7436164617538452
Batch 38/64 loss: 1.7427942752838135
Batch 39/64 loss: 1.7417699098587036
Batch 40/64 loss: 1.742647409439087
Batch 41/64 loss: 1.7432721853256226
Batch 42/64 loss: 1.7628037929534912
Batch 43/64 loss: 1.7429046630859375
Batch 44/64 loss: 1.7426762580871582
Batch 45/64 loss: 1.7421514987945557
Batch 46/64 loss: 1.7416521310806274
Batch 47/64 loss: 1.7407652139663696
Batch 48/64 loss: 1.7432997226715088
Batch 49/64 loss: 1.749065637588501
Batch 50/64 loss: 1.7586312294006348
Batch 51/64 loss: 1.7420068979263306
Batch 52/64 loss: 1.7515997886657715
Batch 53/64 loss: 1.7454423904418945
Batch 54/64 loss: 1.743586540222168
Batch 55/64 loss: 1.7452716827392578
Batch 56/64 loss: 1.7440402507781982
Batch 57/64 loss: 1.7450599670410156
Batch 58/64 loss: 1.7480815649032593
Batch 59/64 loss: 1.7458323240280151
Batch 60/64 loss: 1.7431164979934692
Batch 61/64 loss: 1.7432105541229248
Batch 62/64 loss: 1.7465416193008423
Batch 63/64 loss: 1.744110107421875
Batch 64/64 loss: 1.9439473152160645
Epoch 192  Train loss: 1.7481605267992206  Val loss: 1.7675041857453966
Epoch 193
-------------------------------
Batch 1/64 loss: 1.7431528568267822
Batch 2/64 loss: 1.7479948997497559
Batch 3/64 loss: 1.7439587116241455
Batch 4/64 loss: 1.7542967796325684
Batch 5/64 loss: 1.7469191551208496
Batch 6/64 loss: 1.7469489574432373
Batch 7/64 loss: 1.7416200637817383
Batch 8/64 loss: 1.7602384090423584
Batch 9/64 loss: 1.741609811782837
Batch 10/64 loss: 1.7455469369888306
Batch 11/64 loss: 1.7493969202041626
Batch 12/64 loss: 1.743371844291687
Batch 13/64 loss: 1.7430615425109863
Batch 14/64 loss: 1.7477574348449707
Batch 15/64 loss: 1.7513763904571533
Batch 16/64 loss: 1.745578408241272
Batch 17/64 loss: 1.7431124448776245
Batch 18/64 loss: 1.7459888458251953
Batch 19/64 loss: 1.7433807849884033
Batch 20/64 loss: 1.7551796436309814
Batch 21/64 loss: 1.7496907711029053
Batch 22/64 loss: 1.7429375648498535
Batch 23/64 loss: 1.7459690570831299
Batch 24/64 loss: 1.7432811260223389
Batch 25/64 loss: 1.7421104907989502
Batch 26/64 loss: 1.7416683435440063
Batch 27/64 loss: 1.7384268045425415
Batch 28/64 loss: 1.7449727058410645
Batch 29/64 loss: 1.7434272766113281
Batch 30/64 loss: 1.7444685697555542
Batch 31/64 loss: 1.7480428218841553
Batch 32/64 loss: 1.7420384883880615
Batch 33/64 loss: 1.747389793395996
Batch 34/64 loss: 1.7430613040924072
Batch 35/64 loss: 1.7446759939193726
Batch 36/64 loss: 1.741844654083252
Batch 37/64 loss: 1.745888352394104
Batch 38/64 loss: 1.7448334693908691
Batch 39/64 loss: 1.743401050567627
Batch 40/64 loss: 1.7453504800796509
Batch 41/64 loss: 1.7470296621322632
Batch 42/64 loss: 1.7430267333984375
Batch 43/64 loss: 1.7435846328735352
Batch 44/64 loss: 1.7412676811218262
Batch 45/64 loss: 1.7422670125961304
Batch 46/64 loss: 1.7427787780761719
Batch 47/64 loss: 1.74505615234375
Batch 48/64 loss: 1.7435972690582275
Batch 49/64 loss: 1.7410615682601929
Batch 50/64 loss: 1.7455167770385742
Batch 51/64 loss: 1.7431790828704834
Batch 52/64 loss: 1.7447302341461182
Batch 53/64 loss: 1.7440052032470703
Batch 54/64 loss: 1.745551586151123
Batch 55/64 loss: 1.744104027748108
Batch 56/64 loss: 1.7415330410003662
Batch 57/64 loss: 1.7443931102752686
Batch 58/64 loss: 1.754830002784729
Batch 59/64 loss: 1.7415282726287842
Batch 60/64 loss: 1.7410095930099487
Batch 61/64 loss: 1.7468725442886353
Batch 62/64 loss: 1.7426387071609497
Batch 63/64 loss: 1.742887020111084
Batch 64/64 loss: 1.9602785110473633
Epoch 193  Train loss: 1.7475549417383531  Val loss: 1.7649272250145982
Epoch 194
-------------------------------
Batch 1/64 loss: 1.7448005676269531
Batch 2/64 loss: 1.7422289848327637
Batch 3/64 loss: 1.7464218139648438
Batch 4/64 loss: 1.7643615007400513
Batch 5/64 loss: 1.745983600616455
Batch 6/64 loss: 1.7469202280044556
Batch 7/64 loss: 1.7432639598846436
Batch 8/64 loss: 1.766458511352539
Batch 9/64 loss: 1.7463915348052979
Batch 10/64 loss: 1.7506282329559326
Batch 11/64 loss: 1.7455790042877197
Batch 12/64 loss: 1.7425270080566406
Batch 13/64 loss: 1.7453458309173584
Batch 14/64 loss: 1.74485445022583
Batch 15/64 loss: 1.7454979419708252
Batch 16/64 loss: 1.742418646812439
Batch 17/64 loss: 1.7467396259307861
Batch 18/64 loss: 1.7431679964065552
Batch 19/64 loss: 1.7470639944076538
Batch 20/64 loss: 1.7434900999069214
Batch 21/64 loss: 1.745187759399414
Batch 22/64 loss: 1.7440202236175537
Batch 23/64 loss: 1.7428185939788818
Batch 24/64 loss: 1.744194507598877
Batch 25/64 loss: 1.743689775466919
Batch 26/64 loss: 1.7443618774414062
Batch 27/64 loss: 1.7497941255569458
Batch 28/64 loss: 1.7429912090301514
Batch 29/64 loss: 1.748308777809143
Batch 30/64 loss: 1.7469886541366577
Batch 31/64 loss: 1.743954062461853
Batch 32/64 loss: 1.746069073677063
Batch 33/64 loss: 1.7488975524902344
Batch 34/64 loss: 1.7552013397216797
Batch 35/64 loss: 1.7516593933105469
Batch 36/64 loss: 1.7458093166351318
Batch 37/64 loss: 1.7498279809951782
Batch 38/64 loss: 1.745073914527893
Batch 39/64 loss: 1.7526949644088745
Batch 40/64 loss: 1.746173620223999
Batch 41/64 loss: 1.7445967197418213
Batch 42/64 loss: 1.761405348777771
Batch 43/64 loss: 1.7490276098251343
Batch 44/64 loss: 1.7607755661010742
Batch 45/64 loss: 1.7478985786437988
Batch 46/64 loss: 1.7513750791549683
Batch 47/64 loss: 1.7479921579360962
Batch 48/64 loss: 1.7471556663513184
Batch 49/64 loss: 1.7462011575698853
Batch 50/64 loss: 1.7482025623321533
Batch 51/64 loss: 1.745762586593628
Batch 52/64 loss: 1.7486968040466309
Batch 53/64 loss: 1.744761347770691
Batch 54/64 loss: 1.7459863424301147
Batch 55/64 loss: 1.7453887462615967
Batch 56/64 loss: 1.7471494674682617
Batch 57/64 loss: 1.7450811862945557
Batch 58/64 loss: 1.7433744668960571
Batch 59/64 loss: 1.7420375347137451
Batch 60/64 loss: 1.74308443069458
Batch 61/64 loss: 1.7419240474700928
Batch 62/64 loss: 1.7442690134048462
Batch 63/64 loss: 1.746351957321167
Batch 64/64 loss: 1.9378547668457031
Epoch 194  Train loss: 1.749392152300068  Val loss: 1.7632692441907536
Saving best model, epoch: 194
Epoch 195
-------------------------------
Batch 1/64 loss: 1.7424991130828857
Batch 2/64 loss: 1.745935082435608
Batch 3/64 loss: 1.74532151222229
Batch 4/64 loss: 1.7415879964828491
Batch 5/64 loss: 1.745285987854004
Batch 6/64 loss: 1.7443616390228271
Batch 7/64 loss: 1.7432365417480469
Batch 8/64 loss: 1.742114543914795
Batch 9/64 loss: 1.7464258670806885
Batch 10/64 loss: 1.745096206665039
Batch 11/64 loss: 1.7504435777664185
Batch 12/64 loss: 1.7434396743774414
Batch 13/64 loss: 1.741215467453003
Batch 14/64 loss: 1.7426350116729736
Batch 15/64 loss: 1.7472405433654785
Batch 16/64 loss: 1.7441948652267456
Batch 17/64 loss: 1.7430814504623413
Batch 18/64 loss: 1.7472628355026245
Batch 19/64 loss: 1.7420059442520142
Batch 20/64 loss: 1.745722770690918
Batch 21/64 loss: 1.7477127313613892
Batch 22/64 loss: 1.7444636821746826
Batch 23/64 loss: 1.7429157495498657
Batch 24/64 loss: 1.742089867591858
Batch 25/64 loss: 1.7457507848739624
Batch 26/64 loss: 1.7449172735214233
Batch 27/64 loss: 1.7514889240264893
Batch 28/64 loss: 1.7621054649353027
Batch 29/64 loss: 1.743453025817871
Batch 30/64 loss: 1.745367169380188
Batch 31/64 loss: 1.7428032159805298
Batch 32/64 loss: 1.742250680923462
Batch 33/64 loss: 1.744962453842163
Batch 34/64 loss: 1.7455534934997559
Batch 35/64 loss: 1.7431843280792236
Batch 36/64 loss: 1.743542194366455
Batch 37/64 loss: 1.7404735088348389
Batch 38/64 loss: 1.7419440746307373
Batch 39/64 loss: 1.747441291809082
Batch 40/64 loss: 1.7432632446289062
Batch 41/64 loss: 1.7440969944000244
Batch 42/64 loss: 1.7509963512420654
Batch 43/64 loss: 1.7459670305252075
Batch 44/64 loss: 1.74765944480896
Batch 45/64 loss: 1.741025686264038
Batch 46/64 loss: 1.7566728591918945
Batch 47/64 loss: 1.7460415363311768
Batch 48/64 loss: 1.7434759140014648
Batch 49/64 loss: 1.7475937604904175
Batch 50/64 loss: 1.7444864511489868
Batch 51/64 loss: 1.7448160648345947
Batch 52/64 loss: 1.7537517547607422
Batch 53/64 loss: 1.741562008857727
Batch 54/64 loss: 1.7483323812484741
Batch 55/64 loss: 1.7465918064117432
Batch 56/64 loss: 1.741624355316162
Batch 57/64 loss: 1.7425912618637085
Batch 58/64 loss: 1.7436813116073608
Batch 59/64 loss: 1.7449829578399658
Batch 60/64 loss: 1.7425165176391602
Batch 61/64 loss: 1.744265079498291
Batch 62/64 loss: 1.7432156801223755
Batch 63/64 loss: 1.7419006824493408
Batch 64/64 loss: 1.9380756616592407
Epoch 195  Train loss: 1.7473912851483213  Val loss: 1.76301271726995
Saving best model, epoch: 195
Epoch 196
-------------------------------
Batch 1/64 loss: 1.7534632682800293
Batch 2/64 loss: 1.7438080310821533
Batch 3/64 loss: 1.74496328830719
Batch 4/64 loss: 1.742935299873352
Batch 5/64 loss: 1.7400295734405518
Batch 6/64 loss: 1.7423850297927856
Batch 7/64 loss: 1.7401700019836426
Batch 8/64 loss: 1.7424548864364624
Batch 9/64 loss: 1.7459694147109985
Batch 10/64 loss: 1.7440924644470215
Batch 11/64 loss: 1.7462611198425293
Batch 12/64 loss: 1.7446486949920654
Batch 13/64 loss: 1.7450963258743286
Batch 14/64 loss: 1.7550147771835327
Batch 15/64 loss: 1.7447854280471802
Batch 16/64 loss: 1.745698094367981
Batch 17/64 loss: 1.7438102960586548
Batch 18/64 loss: 1.7474627494812012
Batch 19/64 loss: 1.744024634361267
Batch 20/64 loss: 1.744711995124817
Batch 21/64 loss: 1.7600228786468506
Batch 22/64 loss: 1.7465438842773438
Batch 23/64 loss: 1.7435489892959595
Batch 24/64 loss: 1.7437947988510132
Batch 25/64 loss: 1.7438619136810303
Batch 26/64 loss: 1.747517704963684
Batch 27/64 loss: 1.7431390285491943
Batch 28/64 loss: 1.7442693710327148
Batch 29/64 loss: 1.7463634014129639
Batch 30/64 loss: 1.7485642433166504
Batch 31/64 loss: 1.7428956031799316
Batch 32/64 loss: 1.7454867362976074
Batch 33/64 loss: 1.7548396587371826
Batch 34/64 loss: 1.7414637804031372
Batch 35/64 loss: 1.7430251836776733
Batch 36/64 loss: 1.7614600658416748
Batch 37/64 loss: 1.7417527437210083
Batch 38/64 loss: 1.7447113990783691
Batch 39/64 loss: 1.7405197620391846
Batch 40/64 loss: 1.7452815771102905
Batch 41/64 loss: 1.7426525354385376
Batch 42/64 loss: 1.7393767833709717
Batch 43/64 loss: 1.7408231496810913
Batch 44/64 loss: 1.7425458431243896
Batch 45/64 loss: 1.7424449920654297
Batch 46/64 loss: 1.743861198425293
Batch 47/64 loss: 1.7450861930847168
Batch 48/64 loss: 1.7467420101165771
Batch 49/64 loss: 1.7480831146240234
Batch 50/64 loss: 1.7413113117218018
Batch 51/64 loss: 1.7390180826187134
Batch 52/64 loss: 1.7420709133148193
Batch 53/64 loss: 1.743278980255127
Batch 54/64 loss: 1.7387361526489258
Batch 55/64 loss: 1.7425931692123413
Batch 56/64 loss: 1.7439301013946533
Batch 57/64 loss: 1.7442052364349365
Batch 58/64 loss: 1.7487819194793701
Batch 59/64 loss: 1.7398570775985718
Batch 60/64 loss: 1.7406857013702393
Batch 61/64 loss: 1.7435327768325806
Batch 62/64 loss: 1.7410818338394165
Batch 63/64 loss: 1.7464416027069092
Batch 64/64 loss: 1.934131383895874
Epoch 196  Train loss: 1.7469582323934518  Val loss: 1.7642461630896604
Epoch 197
-------------------------------
Batch 1/64 loss: 1.7412899732589722
Batch 2/64 loss: 1.7430346012115479
Batch 3/64 loss: 1.7462211847305298
Batch 4/64 loss: 1.7573142051696777
Batch 5/64 loss: 1.743298053741455
Batch 6/64 loss: 1.7447049617767334
Batch 7/64 loss: 1.7482686042785645
Batch 8/64 loss: 1.7430870532989502
Batch 9/64 loss: 1.7447675466537476
Batch 10/64 loss: 1.7415452003479004
Batch 11/64 loss: 1.745574712753296
Batch 12/64 loss: 1.7574398517608643
Batch 13/64 loss: 1.7435449361801147
Batch 14/64 loss: 1.7420741319656372
Batch 15/64 loss: 1.7439683675765991
Batch 16/64 loss: 1.7492784261703491
Batch 17/64 loss: 1.7439961433410645
Batch 18/64 loss: 1.7488045692443848
Batch 19/64 loss: 1.7423689365386963
Batch 20/64 loss: 1.744622826576233
Batch 21/64 loss: 1.7468421459197998
Batch 22/64 loss: 1.748161792755127
Batch 23/64 loss: 1.7507423162460327
Batch 24/64 loss: 1.7466093301773071
Batch 25/64 loss: 1.7443504333496094
Batch 26/64 loss: 1.7457351684570312
Batch 27/64 loss: 1.7542413473129272
Batch 28/64 loss: 1.7488269805908203
Batch 29/64 loss: 1.7449440956115723
Batch 30/64 loss: 1.7439099550247192
Batch 31/64 loss: 1.7421138286590576
Batch 32/64 loss: 1.7420871257781982
Batch 33/64 loss: 1.7416383028030396
Batch 34/64 loss: 1.7470213174819946
Batch 35/64 loss: 1.7443268299102783
Batch 36/64 loss: 1.7441997528076172
Batch 37/64 loss: 1.7416586875915527
Batch 38/64 loss: 1.7397760152816772
Batch 39/64 loss: 1.742024540901184
Batch 40/64 loss: 1.7425743341445923
Batch 41/64 loss: 1.7427341938018799
Batch 42/64 loss: 1.7425637245178223
Batch 43/64 loss: 1.7485077381134033
Batch 44/64 loss: 1.7430018186569214
Batch 45/64 loss: 1.7449142932891846
Batch 46/64 loss: 1.745025873184204
Batch 47/64 loss: 1.743836522102356
Batch 48/64 loss: 1.7435410022735596
Batch 49/64 loss: 1.7412760257720947
Batch 50/64 loss: 1.7459263801574707
Batch 51/64 loss: 1.745112419128418
Batch 52/64 loss: 1.762655258178711
Batch 53/64 loss: 1.740574836730957
Batch 54/64 loss: 1.7464468479156494
Batch 55/64 loss: 1.7477655410766602
Batch 56/64 loss: 1.7472400665283203
Batch 57/64 loss: 1.7462596893310547
Batch 58/64 loss: 1.7441613674163818
Batch 59/64 loss: 1.750130295753479
Batch 60/64 loss: 1.7443853616714478
Batch 61/64 loss: 1.7430342435836792
Batch 62/64 loss: 1.7413321733474731
Batch 63/64 loss: 1.7428951263427734
Batch 64/64 loss: 1.931780457496643
Epoch 197  Train loss: 1.7475944271274642  Val loss: 1.7634574695141454
Epoch 198
-------------------------------
Batch 1/64 loss: 1.7421497106552124
Batch 2/64 loss: 1.742483377456665
Batch 3/64 loss: 1.7447035312652588
Batch 4/64 loss: 1.7403860092163086
Batch 5/64 loss: 1.7401002645492554
Batch 6/64 loss: 1.744138240814209
Batch 7/64 loss: 1.7482013702392578
Batch 8/64 loss: 1.7432559728622437
Batch 9/64 loss: 1.745531678199768
Batch 10/64 loss: 1.7425655126571655
Batch 11/64 loss: 1.7564692497253418
Batch 12/64 loss: 1.741218090057373
Batch 13/64 loss: 1.7409720420837402
Batch 14/64 loss: 1.7427978515625
Batch 15/64 loss: 1.7443934679031372
Batch 16/64 loss: 1.7421624660491943
Batch 17/64 loss: 1.7422423362731934
Batch 18/64 loss: 1.7447236776351929
Batch 19/64 loss: 1.7429558038711548
Batch 20/64 loss: 1.744422197341919
Batch 21/64 loss: 1.7417749166488647
Batch 22/64 loss: 1.7431508302688599
Batch 23/64 loss: 1.741368293762207
Batch 24/64 loss: 1.742427110671997
Batch 25/64 loss: 1.7560746669769287
Batch 26/64 loss: 1.7468430995941162
Batch 27/64 loss: 1.7451841831207275
Batch 28/64 loss: 1.744201421737671
Batch 29/64 loss: 1.7440598011016846
Batch 30/64 loss: 1.7646872997283936
Batch 31/64 loss: 1.746569275856018
Batch 32/64 loss: 1.7445472478866577
Batch 33/64 loss: 1.7459245920181274
Batch 34/64 loss: 1.7476469278335571
Batch 35/64 loss: 1.7430704832077026
Batch 36/64 loss: 1.7430922985076904
Batch 37/64 loss: 1.7479549646377563
Batch 38/64 loss: 1.7455143928527832
Batch 39/64 loss: 1.7415664196014404
Batch 40/64 loss: 1.7417585849761963
Batch 41/64 loss: 1.742879867553711
Batch 42/64 loss: 1.7449297904968262
Batch 43/64 loss: 1.7463816404342651
Batch 44/64 loss: 1.7513259649276733
Batch 45/64 loss: 1.7480050325393677
Batch 46/64 loss: 1.7470099925994873
Batch 47/64 loss: 1.7474157810211182
Batch 48/64 loss: 1.743816614151001
Batch 49/64 loss: 1.7459660768508911
Batch 50/64 loss: 1.7448984384536743
Batch 51/64 loss: 1.7432591915130615
Batch 52/64 loss: 1.7467501163482666
Batch 53/64 loss: 1.7434535026550293
Batch 54/64 loss: 1.744342565536499
Batch 55/64 loss: 1.7430880069732666
Batch 56/64 loss: 1.7436697483062744
Batch 57/64 loss: 1.742011308670044
Batch 58/64 loss: 1.7473024129867554
Batch 59/64 loss: 1.7585699558258057
Batch 60/64 loss: 1.7431347370147705
Batch 61/64 loss: 1.7400591373443604
Batch 62/64 loss: 1.741579532623291
Batch 63/64 loss: 1.7419967651367188
Batch 64/64 loss: 1.9291080236434937
Epoch 198  Train loss: 1.7471681075937608  Val loss: 1.7629387616291898
Saving best model, epoch: 198
Epoch 199
-------------------------------
Batch 1/64 loss: 1.7452036142349243
Batch 2/64 loss: 1.7404606342315674
Batch 3/64 loss: 1.7417504787445068
Batch 4/64 loss: 1.746408224105835
Batch 5/64 loss: 1.7422603368759155
Batch 6/64 loss: 1.741134762763977
Batch 7/64 loss: 1.741685390472412
Batch 8/64 loss: 1.7395250797271729
Batch 9/64 loss: 1.741403579711914
Batch 10/64 loss: 1.741649866104126
Batch 11/64 loss: 1.7444102764129639
Batch 12/64 loss: 1.742203950881958
Batch 13/64 loss: 1.754746675491333
Batch 14/64 loss: 1.7431206703186035
Batch 15/64 loss: 1.7435228824615479
Batch 16/64 loss: 1.745520830154419
Batch 17/64 loss: 1.7564172744750977
Batch 18/64 loss: 1.7441720962524414
Batch 19/64 loss: 1.7464027404785156
Batch 20/64 loss: 1.745081901550293
Batch 21/64 loss: 1.7443675994873047
Batch 22/64 loss: 1.7444173097610474
Batch 23/64 loss: 1.7463610172271729
Batch 24/64 loss: 1.7430989742279053
Batch 25/64 loss: 1.7516965866088867
Batch 26/64 loss: 1.7463953495025635
Batch 27/64 loss: 1.746185064315796
Batch 28/64 loss: 1.7473132610321045
Batch 29/64 loss: 1.7443747520446777
Batch 30/64 loss: 1.7462162971496582
Batch 31/64 loss: 1.7450424432754517
Batch 32/64 loss: 1.7491848468780518
Batch 33/64 loss: 1.743723750114441
Batch 34/64 loss: 1.7452278137207031
Batch 35/64 loss: 1.7446147203445435
Batch 36/64 loss: 1.746480107307434
Batch 37/64 loss: 1.7500953674316406
Batch 38/64 loss: 1.7488558292388916
Batch 39/64 loss: 1.7433929443359375
Batch 40/64 loss: 1.7431384325027466
Batch 41/64 loss: 1.7444088459014893
Batch 42/64 loss: 1.7424407005310059
Batch 43/64 loss: 1.744947075843811
Batch 44/64 loss: 1.7433364391326904
Batch 45/64 loss: 1.744847059249878
Batch 46/64 loss: 1.7476989030838013
Batch 47/64 loss: 1.7417114973068237
Batch 48/64 loss: 1.742919921875
Batch 49/64 loss: 1.7419034242630005
Batch 50/64 loss: 1.7464535236358643
Batch 51/64 loss: 1.7403466701507568
Batch 52/64 loss: 1.740372896194458
Batch 53/64 loss: 1.7421396970748901
Batch 54/64 loss: 1.7406678199768066
Batch 55/64 loss: 1.7453670501708984
Batch 56/64 loss: 1.7429208755493164
Batch 57/64 loss: 1.7595497369766235
Batch 58/64 loss: 1.7480990886688232
Batch 59/64 loss: 1.740538239479065
Batch 60/64 loss: 1.744346022605896
Batch 61/64 loss: 1.7469441890716553
Batch 62/64 loss: 1.7414180040359497
Batch 63/64 loss: 1.744888186454773
Batch 64/64 loss: 1.9372673034667969
Epoch 199  Train loss: 1.7471134129692527  Val loss: 1.7618880656986302
Saving best model, epoch: 199
Epoch 200
-------------------------------
Batch 1/64 loss: 1.7407925128936768
Batch 2/64 loss: 1.764143943786621
Batch 3/64 loss: 1.7422921657562256
Batch 4/64 loss: 1.750690221786499
Batch 5/64 loss: 1.7443145513534546
Batch 6/64 loss: 1.7465858459472656
Batch 7/64 loss: 1.7438790798187256
Batch 8/64 loss: 1.7384002208709717
Batch 9/64 loss: 1.7460602521896362
Batch 10/64 loss: 1.7403450012207031
Batch 11/64 loss: 1.755998969078064
Batch 12/64 loss: 1.7442398071289062
Batch 13/64 loss: 1.7424232959747314
Batch 14/64 loss: 1.7494351863861084
Batch 15/64 loss: 1.7450929880142212
Batch 16/64 loss: 1.7479066848754883
Batch 17/64 loss: 1.7416149377822876
Batch 18/64 loss: 1.7410423755645752
Batch 19/64 loss: 1.746168613433838
Batch 20/64 loss: 1.7465825080871582
Batch 21/64 loss: 1.7432997226715088
Batch 22/64 loss: 1.7438205480575562
Batch 23/64 loss: 1.7467353343963623
Batch 24/64 loss: 1.7454555034637451
Batch 25/64 loss: 1.7431564331054688
Batch 26/64 loss: 1.7445874214172363
Batch 27/64 loss: 1.7448997497558594
Batch 28/64 loss: 1.7437937259674072
Batch 29/64 loss: 1.746917486190796
Batch 30/64 loss: 1.747628927230835
Batch 31/64 loss: 1.741852045059204
Batch 32/64 loss: 1.746375560760498
Batch 33/64 loss: 1.746031403541565
Batch 34/64 loss: 1.742067575454712
Batch 35/64 loss: 1.7468900680541992
Batch 36/64 loss: 1.7424160242080688
Batch 37/64 loss: 1.7446284294128418
Batch 38/64 loss: 1.7414642572402954
Batch 39/64 loss: 1.7428399324417114
Batch 40/64 loss: 1.7412420511245728
Batch 41/64 loss: 1.7441805601119995
Batch 42/64 loss: 1.746800422668457
Batch 43/64 loss: 1.7417714595794678
Batch 44/64 loss: 1.7466492652893066
Batch 45/64 loss: 1.7421187162399292
Batch 46/64 loss: 1.7599997520446777
Batch 47/64 loss: 1.7428719997406006
Batch 48/64 loss: 1.740506649017334
Batch 49/64 loss: 1.7411885261535645
Batch 50/64 loss: 1.7487473487854004
Batch 51/64 loss: 1.7436342239379883
Batch 52/64 loss: 1.746636152267456
Batch 53/64 loss: 1.7418580055236816
Batch 54/64 loss: 1.7425167560577393
Batch 55/64 loss: 1.7457911968231201
Batch 56/64 loss: 1.7417411804199219
Batch 57/64 loss: 1.740108609199524
Batch 58/64 loss: 1.7405521869659424
Batch 59/64 loss: 1.7430967092514038
Batch 60/64 loss: 1.74013090133667
Batch 61/64 loss: 1.7422784566879272
Batch 62/64 loss: 1.7415804862976074
Batch 63/64 loss: 1.7440176010131836
Batch 64/64 loss: 1.9300737380981445
Epoch 200  Train loss: 1.7468304914586685  Val loss: 1.7592687541266896
Saving best model, epoch: 200
Epoch 201
-------------------------------
Batch 1/64 loss: 1.7400329113006592
Batch 2/64 loss: 1.7429656982421875
Batch 3/64 loss: 1.7425347566604614
Batch 4/64 loss: 1.7414462566375732
Batch 5/64 loss: 1.740537166595459
Batch 6/64 loss: 1.7402338981628418
Batch 7/64 loss: 1.739778995513916
Batch 8/64 loss: 1.759350061416626
Batch 9/64 loss: 1.740449070930481
Batch 10/64 loss: 1.739546775817871
Batch 11/64 loss: 1.741171956062317
Batch 12/64 loss: 1.7414612770080566
Batch 13/64 loss: 1.7449636459350586
Batch 14/64 loss: 1.7495310306549072
Batch 15/64 loss: 1.746824026107788
Batch 16/64 loss: 1.7419655323028564
Batch 17/64 loss: 1.7565245628356934
Batch 18/64 loss: 1.7453604936599731
Batch 19/64 loss: 1.748043417930603
Batch 20/64 loss: 1.7457189559936523
Batch 21/64 loss: 1.7446751594543457
Batch 22/64 loss: 1.7423691749572754
Batch 23/64 loss: 1.749159336090088
Batch 24/64 loss: 1.7454931735992432
Batch 25/64 loss: 1.7442688941955566
Batch 26/64 loss: 1.7459921836853027
Batch 27/64 loss: 1.7453827857971191
Batch 28/64 loss: 1.7436472177505493
Batch 29/64 loss: 1.745182752609253
Batch 30/64 loss: 1.7418410778045654
Batch 31/64 loss: 1.7519164085388184
Batch 32/64 loss: 1.7430623769760132
Batch 33/64 loss: 1.7407902479171753
Batch 34/64 loss: 1.747558832168579
Batch 35/64 loss: 1.7472668886184692
Batch 36/64 loss: 1.743005394935608
Batch 37/64 loss: 1.7420061826705933
Batch 38/64 loss: 1.7442349195480347
Batch 39/64 loss: 1.7477282285690308
Batch 40/64 loss: 1.7438328266143799
Batch 41/64 loss: 1.7422807216644287
Batch 42/64 loss: 1.7429420948028564
Batch 43/64 loss: 1.7434629201889038
Batch 44/64 loss: 1.7418304681777954
Batch 45/64 loss: 1.752535104751587
Batch 46/64 loss: 1.7455545663833618
Batch 47/64 loss: 1.7420307397842407
Batch 48/64 loss: 1.742464303970337
Batch 49/64 loss: 1.740906000137329
Batch 50/64 loss: 1.7412476539611816
Batch 51/64 loss: 1.7434676885604858
Batch 52/64 loss: 1.7485260963439941
Batch 53/64 loss: 1.740173578262329
Batch 54/64 loss: 1.7572563886642456
Batch 55/64 loss: 1.744225025177002
Batch 56/64 loss: 1.7436888217926025
Batch 57/64 loss: 1.7414624691009521
Batch 58/64 loss: 1.7412853240966797
Batch 59/64 loss: 1.7407796382904053
Batch 60/64 loss: 1.7428996562957764
Batch 61/64 loss: 1.7443273067474365
Batch 62/64 loss: 1.741319179534912
Batch 63/64 loss: 1.743034839630127
Batch 64/64 loss: 1.9316494464874268
Epoch 201  Train loss: 1.746577132916918  Val loss: 1.7659838330704731
Epoch 202
-------------------------------
Batch 1/64 loss: 1.743119239807129
Batch 2/64 loss: 1.7406237125396729
Batch 3/64 loss: 1.7428479194641113
Batch 4/64 loss: 1.7418715953826904
Batch 5/64 loss: 1.7446056604385376
Batch 6/64 loss: 1.7483245134353638
Batch 7/64 loss: 1.744899034500122
Batch 8/64 loss: 1.7427505254745483
Batch 9/64 loss: 1.7395532131195068
Batch 10/64 loss: 1.7479228973388672
Batch 11/64 loss: 1.7490379810333252
Batch 12/64 loss: 1.741410732269287
Batch 13/64 loss: 1.7456997632980347
Batch 14/64 loss: 1.7448923587799072
Batch 15/64 loss: 1.743417501449585
Batch 16/64 loss: 1.7461026906967163
Batch 17/64 loss: 1.7391459941864014
Batch 18/64 loss: 1.7414865493774414
Batch 19/64 loss: 1.7432560920715332
Batch 20/64 loss: 1.7427937984466553
Batch 21/64 loss: 1.7637099027633667
Batch 22/64 loss: 1.74721097946167
Batch 23/64 loss: 1.7409368753433228
Batch 24/64 loss: 1.7452915906906128
Batch 25/64 loss: 1.7435240745544434
Batch 26/64 loss: 1.744165062904358
Batch 27/64 loss: 1.739122748374939
Batch 28/64 loss: 1.7407922744750977
Batch 29/64 loss: 1.742211937904358
Batch 30/64 loss: 1.7410016059875488
Batch 31/64 loss: 1.7567675113677979
Batch 32/64 loss: 1.74232017993927
Batch 33/64 loss: 1.7427730560302734
Batch 34/64 loss: 1.7446744441986084
Batch 35/64 loss: 1.7406872510910034
Batch 36/64 loss: 1.747128963470459
Batch 37/64 loss: 1.7431199550628662
Batch 38/64 loss: 1.740109920501709
Batch 39/64 loss: 1.7421462535858154
Batch 40/64 loss: 1.7588719129562378
Batch 41/64 loss: 1.7422873973846436
Batch 42/64 loss: 1.7458586692810059
Batch 43/64 loss: 1.7477295398712158
Batch 44/64 loss: 1.7426564693450928
Batch 45/64 loss: 1.748032569885254
Batch 46/64 loss: 1.743152141571045
Batch 47/64 loss: 1.7455003261566162
Batch 48/64 loss: 1.7436788082122803
Batch 49/64 loss: 1.7455239295959473
Batch 50/64 loss: 1.743457317352295
Batch 51/64 loss: 1.7433555126190186
Batch 52/64 loss: 1.7405332326889038
Batch 53/64 loss: 1.7482478618621826
Batch 54/64 loss: 1.742728352546692
Batch 55/64 loss: 1.7445381879806519
Batch 56/64 loss: 1.7423279285430908
Batch 57/64 loss: 1.7453668117523193
Batch 58/64 loss: 1.7480406761169434
Batch 59/64 loss: 1.7424736022949219
Batch 60/64 loss: 1.7452991008758545
Batch 61/64 loss: 1.7455759048461914
Batch 62/64 loss: 1.7432258129119873
Batch 63/64 loss: 1.7416895627975464
Batch 64/64 loss: 1.9422893524169922
Epoch 202  Train loss: 1.746797254973767  Val loss: 1.7655124492251997
Epoch 203
-------------------------------
Batch 1/64 loss: 1.746377944946289
Batch 2/64 loss: 1.7513706684112549
Batch 3/64 loss: 1.743718147277832
Batch 4/64 loss: 1.7442476749420166
Batch 5/64 loss: 1.7449297904968262
Batch 6/64 loss: 1.7460620403289795
Batch 7/64 loss: 1.744581937789917
Batch 8/64 loss: 1.7437589168548584
Batch 9/64 loss: 1.7462297677993774
Batch 10/64 loss: 1.742563247680664
Batch 11/64 loss: 1.7472069263458252
Batch 12/64 loss: 1.7442224025726318
Batch 13/64 loss: 1.743933916091919
Batch 14/64 loss: 1.7535778284072876
Batch 15/64 loss: 1.7454664707183838
Batch 16/64 loss: 1.7448575496673584
Batch 17/64 loss: 1.7444961071014404
Batch 18/64 loss: 1.7424485683441162
Batch 19/64 loss: 1.7461638450622559
Batch 20/64 loss: 1.7431237697601318
Batch 21/64 loss: 1.7502148151397705
Batch 22/64 loss: 1.7504479885101318
Batch 23/64 loss: 1.743797779083252
Batch 24/64 loss: 1.7432541847229004
Batch 25/64 loss: 1.7441632747650146
Batch 26/64 loss: 1.7408592700958252
Batch 27/64 loss: 1.7426317930221558
Batch 28/64 loss: 1.7438936233520508
Batch 29/64 loss: 1.74210524559021
Batch 30/64 loss: 1.7590692043304443
Batch 31/64 loss: 1.7391985654830933
Batch 32/64 loss: 1.7456307411193848
Batch 33/64 loss: 1.743859052658081
Batch 34/64 loss: 1.7420237064361572
Batch 35/64 loss: 1.7434992790222168
Batch 36/64 loss: 1.7488996982574463
Batch 37/64 loss: 1.743276596069336
Batch 38/64 loss: 1.7452969551086426
Batch 39/64 loss: 1.7433533668518066
Batch 40/64 loss: 1.741579294204712
Batch 41/64 loss: 1.7403974533081055
Batch 42/64 loss: 1.7379648685455322
Batch 43/64 loss: 1.7401196956634521
Batch 44/64 loss: 1.7418851852416992
Batch 45/64 loss: 1.742794156074524
Batch 46/64 loss: 1.7426847219467163
Batch 47/64 loss: 1.7430484294891357
Batch 48/64 loss: 1.742335319519043
Batch 49/64 loss: 1.7437620162963867
Batch 50/64 loss: 1.7437572479248047
Batch 51/64 loss: 1.741065502166748
Batch 52/64 loss: 1.74398672580719
Batch 53/64 loss: 1.7408853769302368
Batch 54/64 loss: 1.738756537437439
Batch 55/64 loss: 1.7418314218521118
Batch 56/64 loss: 1.7422685623168945
Batch 57/64 loss: 1.7420837879180908
Batch 58/64 loss: 1.7422603368759155
Batch 59/64 loss: 1.7423055171966553
Batch 60/64 loss: 1.7485456466674805
Batch 61/64 loss: 1.7451248168945312
Batch 62/64 loss: 1.7471376657485962
Batch 63/64 loss: 1.7435131072998047
Batch 64/64 loss: 1.9334220886230469
Epoch 203  Train loss: 1.7464309430589864  Val loss: 1.7660046426700973
Epoch 204
-------------------------------
Batch 1/64 loss: 1.7411730289459229
Batch 2/64 loss: 1.7512638568878174
Batch 3/64 loss: 1.7411258220672607
Batch 4/64 loss: 1.7453138828277588
Batch 5/64 loss: 1.7476866245269775
Batch 6/64 loss: 1.7489383220672607
Batch 7/64 loss: 1.7456369400024414
Batch 8/64 loss: 1.7471470832824707
Batch 9/64 loss: 1.7465994358062744
Batch 10/64 loss: 1.7479989528656006
Batch 11/64 loss: 1.744396448135376
Batch 12/64 loss: 1.743805170059204
Batch 13/64 loss: 1.7427992820739746
Batch 14/64 loss: 1.7600278854370117
Batch 15/64 loss: 1.7424737215042114
Batch 16/64 loss: 1.7420589923858643
Batch 17/64 loss: 1.755248785018921
Batch 18/64 loss: 1.7471632957458496
Batch 19/64 loss: 1.7436964511871338
Batch 20/64 loss: 1.7454218864440918
Batch 21/64 loss: 1.7454516887664795
Batch 22/64 loss: 1.7442296743392944
Batch 23/64 loss: 1.7651698589324951
Batch 24/64 loss: 1.7635302543640137
Batch 25/64 loss: 1.7434678077697754
Batch 26/64 loss: 1.7440474033355713
Batch 27/64 loss: 1.7479171752929688
Batch 28/64 loss: 1.7456729412078857
Batch 29/64 loss: 1.746758222579956
Batch 30/64 loss: 1.7468819618225098
Batch 31/64 loss: 1.7430651187896729
Batch 32/64 loss: 1.7430884838104248
Batch 33/64 loss: 1.7507078647613525
Batch 34/64 loss: 1.7444016933441162
Batch 35/64 loss: 1.744105577468872
Batch 36/64 loss: 1.7460880279541016
Batch 37/64 loss: 1.742534875869751
Batch 38/64 loss: 1.7432523965835571
Batch 39/64 loss: 1.7447130680084229
Batch 40/64 loss: 1.7440378665924072
Batch 41/64 loss: 1.7427103519439697
Batch 42/64 loss: 1.7444162368774414
Batch 43/64 loss: 1.749464988708496
Batch 44/64 loss: 1.7441903352737427
Batch 45/64 loss: 1.743852138519287
Batch 46/64 loss: 1.741813063621521
Batch 47/64 loss: 1.7457513809204102
Batch 48/64 loss: 1.743255376815796
Batch 49/64 loss: 1.7423261404037476
Batch 50/64 loss: 1.742732286453247
Batch 51/64 loss: 1.7423352003097534
Batch 52/64 loss: 1.7478759288787842
Batch 53/64 loss: 1.7454981803894043
Batch 54/64 loss: 1.7427791357040405
Batch 55/64 loss: 1.7451565265655518
Batch 56/64 loss: 1.7449615001678467
Batch 57/64 loss: 1.746476173400879
Batch 58/64 loss: 1.7455202341079712
Batch 59/64 loss: 1.7420613765716553
Batch 60/64 loss: 1.7428991794586182
Batch 61/64 loss: 1.7532415390014648
Batch 62/64 loss: 1.7479649782180786
Batch 63/64 loss: 1.742026925086975
Batch 64/64 loss: 1.9316481351852417
Epoch 204  Train loss: 1.7481904801200419  Val loss: 1.7612387806279552
Epoch 205
-------------------------------
Batch 1/64 loss: 1.7418162822723389
Batch 2/64 loss: 1.7426402568817139
Batch 3/64 loss: 1.744560718536377
Batch 4/64 loss: 1.7447139024734497
Batch 5/64 loss: 1.7498910427093506
Batch 6/64 loss: 1.7445380687713623
Batch 7/64 loss: 1.74323570728302
Batch 8/64 loss: 1.7421424388885498
Batch 9/64 loss: 1.7466273307800293
Batch 10/64 loss: 1.7585487365722656
Batch 11/64 loss: 1.7433350086212158
Batch 12/64 loss: 1.7450700998306274
Batch 13/64 loss: 1.744810938835144
Batch 14/64 loss: 1.7487884759902954
Batch 15/64 loss: 1.7428650856018066
Batch 16/64 loss: 1.743028163909912
Batch 17/64 loss: 1.738864541053772
Batch 18/64 loss: 1.7436487674713135
Batch 19/64 loss: 1.7467477321624756
Batch 20/64 loss: 1.7432771921157837
Batch 21/64 loss: 1.761121392250061
Batch 22/64 loss: 1.744287371635437
Batch 23/64 loss: 1.739747166633606
Batch 24/64 loss: 1.741520881652832
Batch 25/64 loss: 1.7422839403152466
Batch 26/64 loss: 1.7418811321258545
Batch 27/64 loss: 1.7411003112792969
Batch 28/64 loss: 1.7433648109436035
Batch 29/64 loss: 1.748738408088684
Batch 30/64 loss: 1.7443017959594727
Batch 31/64 loss: 1.7416000366210938
Batch 32/64 loss: 1.7464120388031006
Batch 33/64 loss: 1.7456085681915283
Batch 34/64 loss: 1.7503361701965332
Batch 35/64 loss: 1.7421162128448486
Batch 36/64 loss: 1.7431275844573975
Batch 37/64 loss: 1.7457975149154663
Batch 38/64 loss: 1.7454819679260254
Batch 39/64 loss: 1.745269536972046
Batch 40/64 loss: 1.7438263893127441
Batch 41/64 loss: 1.746403694152832
Batch 42/64 loss: 1.7435789108276367
Batch 43/64 loss: 1.7439908981323242
Batch 44/64 loss: 1.740403652191162
Batch 45/64 loss: 1.7422220706939697
Batch 46/64 loss: 1.7426553964614868
Batch 47/64 loss: 1.7450060844421387
Batch 48/64 loss: 1.7439417839050293
Batch 49/64 loss: 1.739630937576294
Batch 50/64 loss: 1.7415363788604736
Batch 51/64 loss: 1.7474972009658813
Batch 52/64 loss: 1.7430691719055176
Batch 53/64 loss: 1.742242455482483
Batch 54/64 loss: 1.7441285848617554
Batch 55/64 loss: 1.7474617958068848
Batch 56/64 loss: 1.7436268329620361
Batch 57/64 loss: 1.7527130842208862
Batch 58/64 loss: 1.7422600984573364
Batch 59/64 loss: 1.7444208860397339
Batch 60/64 loss: 1.74257230758667
Batch 61/64 loss: 1.7418911457061768
Batch 62/64 loss: 1.751873254776001
Batch 63/64 loss: 1.7454993724822998
Batch 64/64 loss: 1.9408423900604248
Epoch 205  Train loss: 1.7470012786341649  Val loss: 1.7621856620631267
Epoch 206
-------------------------------
Batch 1/64 loss: 1.7420512437820435
Batch 2/64 loss: 1.7433183193206787
Batch 3/64 loss: 1.7459981441497803
Batch 4/64 loss: 1.7427623271942139
Batch 5/64 loss: 1.7467279434204102
Batch 6/64 loss: 1.7445099353790283
Batch 7/64 loss: 1.742480993270874
Batch 8/64 loss: 1.7443825006484985
Batch 9/64 loss: 1.745859146118164
Batch 10/64 loss: 1.7441195249557495
Batch 11/64 loss: 1.742557406425476
Batch 12/64 loss: 1.7445743083953857
Batch 13/64 loss: 1.7411723136901855
Batch 14/64 loss: 1.7400903701782227
Batch 15/64 loss: 1.7433242797851562
Batch 16/64 loss: 1.742464542388916
Batch 17/64 loss: 1.7439067363739014
Batch 18/64 loss: 1.7411830425262451
Batch 19/64 loss: 1.7479422092437744
Batch 20/64 loss: 1.7495896816253662
Batch 21/64 loss: 1.744532823562622
Batch 22/64 loss: 1.7437334060668945
Batch 23/64 loss: 1.7453033924102783
Batch 24/64 loss: 1.7436437606811523
Batch 25/64 loss: 1.744417667388916
Batch 26/64 loss: 1.7470624446868896
Batch 27/64 loss: 1.7444686889648438
Batch 28/64 loss: 1.743897795677185
Batch 29/64 loss: 1.7498762607574463
Batch 30/64 loss: 1.7536473274230957
Batch 31/64 loss: 1.7418348789215088
Batch 32/64 loss: 1.7528921365737915
Batch 33/64 loss: 1.743888020515442
Batch 34/64 loss: 1.7480467557907104
Batch 35/64 loss: 1.7397480010986328
Batch 36/64 loss: 1.7588458061218262
Batch 37/64 loss: 1.7477627992630005
Batch 38/64 loss: 1.7583258152008057
Batch 39/64 loss: 1.7434320449829102
Batch 40/64 loss: 1.7426838874816895
Batch 41/64 loss: 1.7584421634674072
Batch 42/64 loss: 1.7454169988632202
Batch 43/64 loss: 1.7459949254989624
Batch 44/64 loss: 1.7643623352050781
Batch 45/64 loss: 1.747546911239624
Batch 46/64 loss: 1.7457261085510254
Batch 47/64 loss: 1.7452595233917236
Batch 48/64 loss: 1.7429630756378174
Batch 49/64 loss: 1.7425119876861572
Batch 50/64 loss: 1.7504053115844727
Batch 51/64 loss: 1.7447463274002075
Batch 52/64 loss: 1.7449997663497925
Batch 53/64 loss: 1.757941484451294
Batch 54/64 loss: 1.7468734979629517
Batch 55/64 loss: 1.7454026937484741
Batch 56/64 loss: 1.7441425323486328
Batch 57/64 loss: 1.741881251335144
Batch 58/64 loss: 1.7410564422607422
Batch 59/64 loss: 1.7426130771636963
Batch 60/64 loss: 1.743408441543579
Batch 61/64 loss: 1.7475537061691284
Batch 62/64 loss: 1.7405825853347778
Batch 63/64 loss: 1.7464548349380493
Batch 64/64 loss: 1.9367464780807495
Epoch 206  Train loss: 1.748171051343282  Val loss: 1.7629689088801748
Epoch 207
-------------------------------
Batch 1/64 loss: 1.7395994663238525
Batch 2/64 loss: 1.7410264015197754
Batch 3/64 loss: 1.7474477291107178
Batch 4/64 loss: 1.7406760454177856
Batch 5/64 loss: 1.7438721656799316
Batch 6/64 loss: 1.747307300567627
Batch 7/64 loss: 1.7422242164611816
Batch 8/64 loss: 1.7494451999664307
Batch 9/64 loss: 1.7410856485366821
Batch 10/64 loss: 1.741437554359436
Batch 11/64 loss: 1.7448474168777466
Batch 12/64 loss: 1.7394640445709229
Batch 13/64 loss: 1.7395524978637695
Batch 14/64 loss: 1.74476158618927
Batch 15/64 loss: 1.7451252937316895
Batch 16/64 loss: 1.7555080652236938
Batch 17/64 loss: 1.7408466339111328
Batch 18/64 loss: 1.7405462265014648
Batch 19/64 loss: 1.7462198734283447
Batch 20/64 loss: 1.7398840188980103
Batch 21/64 loss: 1.7407827377319336
Batch 22/64 loss: 1.7390602827072144
Batch 23/64 loss: 1.7403082847595215
Batch 24/64 loss: 1.7387752532958984
Batch 25/64 loss: 1.7400610446929932
Batch 26/64 loss: 1.7423224449157715
Batch 27/64 loss: 1.7408969402313232
Batch 28/64 loss: 1.7569384574890137
Batch 29/64 loss: 1.7423572540283203
Batch 30/64 loss: 1.7531883716583252
Batch 31/64 loss: 1.7448511123657227
Batch 32/64 loss: 1.7455568313598633
Batch 33/64 loss: 1.742598533630371
Batch 34/64 loss: 1.7445564270019531
Batch 35/64 loss: 1.7483913898468018
Batch 36/64 loss: 1.738957405090332
Batch 37/64 loss: 1.746004343032837
Batch 38/64 loss: 1.7443275451660156
Batch 39/64 loss: 1.7432050704956055
Batch 40/64 loss: 1.7434710264205933
Batch 41/64 loss: 1.7417408227920532
Batch 42/64 loss: 1.7406010627746582
Batch 43/64 loss: 1.7603024244308472
Batch 44/64 loss: 1.741233468055725
Batch 45/64 loss: 1.74663507938385
Batch 46/64 loss: 1.7429771423339844
Batch 47/64 loss: 1.7425309419631958
Batch 48/64 loss: 1.7445921897888184
Batch 49/64 loss: 1.7406747341156006
Batch 50/64 loss: 1.73995041847229
Batch 51/64 loss: 1.7424908876419067
Batch 52/64 loss: 1.7440717220306396
Batch 53/64 loss: 1.7404470443725586
Batch 54/64 loss: 1.7394793033599854
Batch 55/64 loss: 1.740074634552002
Batch 56/64 loss: 1.7415516376495361
Batch 57/64 loss: 1.7417044639587402
Batch 58/64 loss: 1.7413415908813477
Batch 59/64 loss: 1.7454710006713867
Batch 60/64 loss: 1.7401785850524902
Batch 61/64 loss: 1.7414295673370361
Batch 62/64 loss: 1.7407760620117188
Batch 63/64 loss: 1.7421430349349976
Batch 64/64 loss: 1.9292316436767578
Epoch 207  Train loss: 1.7455185834099265  Val loss: 1.7604121285205854
Epoch 208
-------------------------------
Batch 1/64 loss: 1.7434887886047363
Batch 2/64 loss: 1.7441561222076416
Batch 3/64 loss: 1.743649959564209
Batch 4/64 loss: 1.7436425685882568
Batch 5/64 loss: 1.7416176795959473
Batch 6/64 loss: 1.740504264831543
Batch 7/64 loss: 1.741102933883667
Batch 8/64 loss: 1.759130835533142
Batch 9/64 loss: 1.742462396621704
Batch 10/64 loss: 1.7458281517028809
Batch 11/64 loss: 1.7437102794647217
Batch 12/64 loss: 1.7454900741577148
Batch 13/64 loss: 1.7451893091201782
Batch 14/64 loss: 1.7442915439605713
Batch 15/64 loss: 1.7421340942382812
Batch 16/64 loss: 1.7404342889785767
Batch 17/64 loss: 1.7443349361419678
Batch 18/64 loss: 1.7432429790496826
Batch 19/64 loss: 1.7395800352096558
Batch 20/64 loss: 1.7625064849853516
Batch 21/64 loss: 1.7476450204849243
Batch 22/64 loss: 1.7438931465148926
Batch 23/64 loss: 1.7504360675811768
Batch 24/64 loss: 1.7423007488250732
Batch 25/64 loss: 1.74296236038208
Batch 26/64 loss: 1.745509147644043
Batch 27/64 loss: 1.7434093952178955
Batch 28/64 loss: 1.743924856185913
Batch 29/64 loss: 1.7440314292907715
Batch 30/64 loss: 1.7413477897644043
Batch 31/64 loss: 1.741100549697876
Batch 32/64 loss: 1.7418360710144043
Batch 33/64 loss: 1.7482830286026
Batch 34/64 loss: 1.7447415590286255
Batch 35/64 loss: 1.7423417568206787
Batch 36/64 loss: 1.744861364364624
Batch 37/64 loss: 1.7427334785461426
Batch 38/64 loss: 1.7426148653030396
Batch 39/64 loss: 1.745781421661377
Batch 40/64 loss: 1.7412753105163574
Batch 41/64 loss: 1.7483913898468018
Batch 42/64 loss: 1.7438936233520508
Batch 43/64 loss: 1.7405164241790771
Batch 44/64 loss: 1.742082118988037
Batch 45/64 loss: 1.7424063682556152
Batch 46/64 loss: 1.7435870170593262
Batch 47/64 loss: 1.7474700212478638
Batch 48/64 loss: 1.7429215908050537
Batch 49/64 loss: 1.7443897724151611
Batch 50/64 loss: 1.742454171180725
Batch 51/64 loss: 1.743645429611206
Batch 52/64 loss: 1.746662974357605
Batch 53/64 loss: 1.7470933198928833
Batch 54/64 loss: 1.7394734621047974
Batch 55/64 loss: 1.7439613342285156
Batch 56/64 loss: 1.740053415298462
Batch 57/64 loss: 1.7385624647140503
Batch 58/64 loss: 1.743741750717163
Batch 59/64 loss: 1.7431044578552246
Batch 60/64 loss: 1.7403932809829712
Batch 61/64 loss: 1.7425938844680786
Batch 62/64 loss: 1.7411916255950928
Batch 63/64 loss: 1.740890383720398
Batch 64/64 loss: 1.935767650604248
Epoch 208  Train loss: 1.7461777743171243  Val loss: 1.7611074906444222
Epoch 209
-------------------------------
Batch 1/64 loss: 1.739901065826416
Batch 2/64 loss: 1.7437456846237183
Batch 3/64 loss: 1.739255428314209
Batch 4/64 loss: 1.7438405752182007
Batch 5/64 loss: 1.745285987854004
Batch 6/64 loss: 1.7418698072433472
Batch 7/64 loss: 1.7429978847503662
Batch 8/64 loss: 1.7414886951446533
Batch 9/64 loss: 1.743139386177063
Batch 10/64 loss: 1.7433626651763916
Batch 11/64 loss: 1.7426955699920654
Batch 12/64 loss: 1.7439254522323608
Batch 13/64 loss: 1.7430671453475952
Batch 14/64 loss: 1.7410733699798584
Batch 15/64 loss: 1.7447030544281006
Batch 16/64 loss: 1.7423138618469238
Batch 17/64 loss: 1.7489068508148193
Batch 18/64 loss: 1.7446107864379883
Batch 19/64 loss: 1.7410675287246704
Batch 20/64 loss: 1.7407294511795044
Batch 21/64 loss: 1.7396845817565918
Batch 22/64 loss: 1.7608494758605957
Batch 23/64 loss: 1.7405182123184204
Batch 24/64 loss: 1.7560725212097168
Batch 25/64 loss: 1.745612621307373
Batch 26/64 loss: 1.7427984476089478
Batch 27/64 loss: 1.7430418729782104
Batch 28/64 loss: 1.7400946617126465
Batch 29/64 loss: 1.7423226833343506
Batch 30/64 loss: 1.7398951053619385
Batch 31/64 loss: 1.7412291765213013
Batch 32/64 loss: 1.7368624210357666
Batch 33/64 loss: 1.740738868713379
Batch 34/64 loss: 1.7436859607696533
Batch 35/64 loss: 1.740422248840332
Batch 36/64 loss: 1.742703914642334
Batch 37/64 loss: 1.7418186664581299
Batch 38/64 loss: 1.7447352409362793
Batch 39/64 loss: 1.7437162399291992
Batch 40/64 loss: 1.7441092729568481
Batch 41/64 loss: 1.7412142753601074
Batch 42/64 loss: 1.7423291206359863
Batch 43/64 loss: 1.7402657270431519
Batch 44/64 loss: 1.741755723953247
Batch 45/64 loss: 1.7436954975128174
Batch 46/64 loss: 1.7455124855041504
Batch 47/64 loss: 1.741004228591919
Batch 48/64 loss: 1.7426562309265137
Batch 49/64 loss: 1.7563443183898926
Batch 50/64 loss: 1.7416565418243408
Batch 51/64 loss: 1.743605613708496
Batch 52/64 loss: 1.7423374652862549
Batch 53/64 loss: 1.7501871585845947
Batch 54/64 loss: 1.7407786846160889
Batch 55/64 loss: 1.7422261238098145
Batch 56/64 loss: 1.7416651248931885
Batch 57/64 loss: 1.7439093589782715
Batch 58/64 loss: 1.7423131465911865
Batch 59/64 loss: 1.7412532567977905
Batch 60/64 loss: 1.743403673171997
Batch 61/64 loss: 1.744763970375061
Batch 62/64 loss: 1.7441638708114624
Batch 63/64 loss: 1.744762897491455
Batch 64/64 loss: 1.9279614686965942
Epoch 209  Train loss: 1.7455163614422666  Val loss: 1.7670308511281752
Epoch 210
-------------------------------
Batch 1/64 loss: 1.7414398193359375
Batch 2/64 loss: 1.745719075202942
Batch 3/64 loss: 1.7400106191635132
Batch 4/64 loss: 1.7434747219085693
Batch 5/64 loss: 1.7399425506591797
Batch 6/64 loss: 1.74078369140625
Batch 7/64 loss: 1.744713544845581
Batch 8/64 loss: 1.7440080642700195
Batch 9/64 loss: 1.7471697330474854
Batch 10/64 loss: 1.7391101121902466
Batch 11/64 loss: 1.7505378723144531
Batch 12/64 loss: 1.7411965131759644
Batch 13/64 loss: 1.741969347000122
Batch 14/64 loss: 1.747185230255127
Batch 15/64 loss: 1.7474441528320312
Batch 16/64 loss: 1.7543987035751343
Batch 17/64 loss: 1.7443923950195312
Batch 18/64 loss: 1.7438174486160278
Batch 19/64 loss: 1.744398832321167
Batch 20/64 loss: 1.7453491687774658
Batch 21/64 loss: 1.7441649436950684
Batch 22/64 loss: 1.746351718902588
Batch 23/64 loss: 1.744602084159851
Batch 24/64 loss: 1.741976261138916
Batch 25/64 loss: 1.739166259765625
Batch 26/64 loss: 1.7419912815093994
Batch 27/64 loss: 1.7420694828033447
Batch 28/64 loss: 1.7593684196472168
Batch 29/64 loss: 1.7447972297668457
Batch 30/64 loss: 1.7422069311141968
Batch 31/64 loss: 1.741654872894287
Batch 32/64 loss: 1.7423624992370605
Batch 33/64 loss: 1.7418867349624634
Batch 34/64 loss: 1.7421269416809082
Batch 35/64 loss: 1.7405874729156494
Batch 36/64 loss: 1.740304708480835
Batch 37/64 loss: 1.7472182512283325
Batch 38/64 loss: 1.7421208620071411
Batch 39/64 loss: 1.7405887842178345
Batch 40/64 loss: 1.7428350448608398
Batch 41/64 loss: 1.7571463584899902
Batch 42/64 loss: 1.739958643913269
Batch 43/64 loss: 1.747575044631958
Batch 44/64 loss: 1.742882490158081
Batch 45/64 loss: 1.747535228729248
Batch 46/64 loss: 1.7407959699630737
Batch 47/64 loss: 1.7439711093902588
Batch 48/64 loss: 1.7423858642578125
Batch 49/64 loss: 1.7384967803955078
Batch 50/64 loss: 1.7414124011993408
Batch 51/64 loss: 1.7470057010650635
Batch 52/64 loss: 1.7475001811981201
Batch 53/64 loss: 1.7396817207336426
Batch 54/64 loss: 1.743865728378296
Batch 55/64 loss: 1.7448503971099854
Batch 56/64 loss: 1.7545444965362549
Batch 57/64 loss: 1.7554420232772827
Batch 58/64 loss: 1.746474027633667
Batch 59/64 loss: 1.743661642074585
Batch 60/64 loss: 1.7422492504119873
Batch 61/64 loss: 1.7417075634002686
Batch 62/64 loss: 1.7419893741607666
Batch 63/64 loss: 1.7418651580810547
Batch 64/64 loss: 1.9382271766662598
Epoch 210  Train loss: 1.746542900683833  Val loss: 1.762351701349737
Epoch 211
-------------------------------
Batch 1/64 loss: 1.7424895763397217
Batch 2/64 loss: 1.746001958847046
Batch 3/64 loss: 1.7438358068466187
Batch 4/64 loss: 1.741624355316162
Batch 5/64 loss: 1.7441802024841309
Batch 6/64 loss: 1.7428193092346191
Batch 7/64 loss: 1.7419465780258179
Batch 8/64 loss: 1.740929126739502
Batch 9/64 loss: 1.7446517944335938
Batch 10/64 loss: 1.7531623840332031
Batch 11/64 loss: 1.746565341949463
Batch 12/64 loss: 1.7421213388442993
Batch 13/64 loss: 1.7402825355529785
Batch 14/64 loss: 1.7448670864105225
Batch 15/64 loss: 1.741581916809082
Batch 16/64 loss: 1.7453296184539795
Batch 17/64 loss: 1.7414350509643555
Batch 18/64 loss: 1.7436085939407349
Batch 19/64 loss: 1.7388641834259033
Batch 20/64 loss: 1.7404415607452393
Batch 21/64 loss: 1.7405033111572266
Batch 22/64 loss: 1.7415831089019775
Batch 23/64 loss: 1.7424960136413574
Batch 24/64 loss: 1.7429096698760986
Batch 25/64 loss: 1.753826379776001
Batch 26/64 loss: 1.741023302078247
Batch 27/64 loss: 1.7480037212371826
Batch 28/64 loss: 1.7450391054153442
Batch 29/64 loss: 1.7381174564361572
Batch 30/64 loss: 1.7435170412063599
Batch 31/64 loss: 1.7396831512451172
Batch 32/64 loss: 1.740250587463379
Batch 33/64 loss: 1.744471549987793
Batch 34/64 loss: 1.7414937019348145
Batch 35/64 loss: 1.7377793788909912
Batch 36/64 loss: 1.747466802597046
Batch 37/64 loss: 1.7405104637145996
Batch 38/64 loss: 1.7405447959899902
Batch 39/64 loss: 1.7413408756256104
Batch 40/64 loss: 1.7410510778427124
Batch 41/64 loss: 1.7424083948135376
Batch 42/64 loss: 1.7439243793487549
Batch 43/64 loss: 1.7622578144073486
Batch 44/64 loss: 1.7446180582046509
Batch 45/64 loss: 1.7437437772750854
Batch 46/64 loss: 1.741518259048462
Batch 47/64 loss: 1.7422165870666504
Batch 48/64 loss: 1.7433459758758545
Batch 49/64 loss: 1.7420742511749268
Batch 50/64 loss: 1.742335557937622
Batch 51/64 loss: 1.7413551807403564
Batch 52/64 loss: 1.741930365562439
Batch 53/64 loss: 1.7430615425109863
Batch 54/64 loss: 1.740865707397461
Batch 55/64 loss: 1.744053602218628
Batch 56/64 loss: 1.7423884868621826
Batch 57/64 loss: 1.741792917251587
Batch 58/64 loss: 1.7427406311035156
Batch 59/64 loss: 1.7426531314849854
Batch 60/64 loss: 1.7411671876907349
Batch 61/64 loss: 1.7434333562850952
Batch 62/64 loss: 1.7410566806793213
Batch 63/64 loss: 1.7468352317810059
Batch 64/64 loss: 1.933195948600769
Epoch 211  Train loss: 1.7454121388641057  Val loss: 1.761760452768647
Epoch 212
-------------------------------
Batch 1/64 loss: 1.7445433139801025
Batch 2/64 loss: 1.7391436100006104
Batch 3/64 loss: 1.7443366050720215
Batch 4/64 loss: 1.7380837202072144
Batch 5/64 loss: 1.7421989440917969
Batch 6/64 loss: 1.7397791147232056
Batch 7/64 loss: 1.7464439868927002
Batch 8/64 loss: 1.7410675287246704
Batch 9/64 loss: 1.7436072826385498
Batch 10/64 loss: 1.7450718879699707
Batch 11/64 loss: 1.7400099039077759
Batch 12/64 loss: 1.7469325065612793
Batch 13/64 loss: 1.7401431798934937
Batch 14/64 loss: 1.7418949604034424
Batch 15/64 loss: 1.7409216165542603
Batch 16/64 loss: 1.7464792728424072
Batch 17/64 loss: 1.7420940399169922
Batch 18/64 loss: 1.7447134256362915
Batch 19/64 loss: 1.745018720626831
Batch 20/64 loss: 1.7448394298553467
Batch 21/64 loss: 1.7422988414764404
Batch 22/64 loss: 1.7517138719558716
Batch 23/64 loss: 1.7433873414993286
Batch 24/64 loss: 1.7439801692962646
Batch 25/64 loss: 1.7459609508514404
Batch 26/64 loss: 1.7439374923706055
Batch 27/64 loss: 1.756113886833191
Batch 28/64 loss: 1.741986632347107
Batch 29/64 loss: 1.7426825761795044
Batch 30/64 loss: 1.7404334545135498
Batch 31/64 loss: 1.7404237985610962
Batch 32/64 loss: 1.7590482234954834
Batch 33/64 loss: 1.7446504831314087
Batch 34/64 loss: 1.745913028717041
Batch 35/64 loss: 1.7464834451675415
Batch 36/64 loss: 1.7610912322998047
Batch 37/64 loss: 1.7418391704559326
Batch 38/64 loss: 1.7411468029022217
Batch 39/64 loss: 1.7436978816986084
Batch 40/64 loss: 1.7439329624176025
Batch 41/64 loss: 1.7480971813201904
Batch 42/64 loss: 1.740679144859314
Batch 43/64 loss: 1.7405154705047607
Batch 44/64 loss: 1.7417302131652832
Batch 45/64 loss: 1.7431402206420898
Batch 46/64 loss: 1.7431522607803345
Batch 47/64 loss: 1.742363691329956
Batch 48/64 loss: 1.741570234298706
Batch 49/64 loss: 1.7407209873199463
Batch 50/64 loss: 1.7420529127120972
Batch 51/64 loss: 1.7425572872161865
Batch 52/64 loss: 1.738567590713501
Batch 53/64 loss: 1.741434097290039
Batch 54/64 loss: 1.7439976930618286
Batch 55/64 loss: 1.7413554191589355
Batch 56/64 loss: 1.7413287162780762
Batch 57/64 loss: 1.7418774366378784
Batch 58/64 loss: 1.741307020187378
Batch 59/64 loss: 1.7471733093261719
Batch 60/64 loss: 1.7398240566253662
Batch 61/64 loss: 1.741485357284546
Batch 62/64 loss: 1.7420058250427246
Batch 63/64 loss: 1.746967077255249
Batch 64/64 loss: 1.9316003322601318
Epoch 212  Train loss: 1.7458925293941123  Val loss: 1.760715185571782
Epoch 213
-------------------------------
Batch 1/64 loss: 1.7396879196166992
Batch 2/64 loss: 1.7403881549835205
Batch 3/64 loss: 1.7426183223724365
Batch 4/64 loss: 1.7425098419189453
Batch 5/64 loss: 1.7424118518829346
Batch 6/64 loss: 1.7420530319213867
Batch 7/64 loss: 1.742902159690857
Batch 8/64 loss: 1.7431857585906982
Batch 9/64 loss: 1.7413890361785889
Batch 10/64 loss: 1.7417018413543701
Batch 11/64 loss: 1.7426260709762573
Batch 12/64 loss: 1.7406880855560303
Batch 13/64 loss: 1.7630078792572021
Batch 14/64 loss: 1.755126714706421
Batch 15/64 loss: 1.7426961660385132
Batch 16/64 loss: 1.7472959756851196
Batch 17/64 loss: 1.7396965026855469
Batch 18/64 loss: 1.7417361736297607
Batch 19/64 loss: 1.7407310009002686
Batch 20/64 loss: 1.746799111366272
Batch 21/64 loss: 1.7422173023223877
Batch 22/64 loss: 1.740410566329956
Batch 23/64 loss: 1.739461064338684
Batch 24/64 loss: 1.7426087856292725
Batch 25/64 loss: 1.743699312210083
Batch 26/64 loss: 1.7569820880889893
Batch 27/64 loss: 1.7418111562728882
Batch 28/64 loss: 1.7461516857147217
Batch 29/64 loss: 1.7420485019683838
Batch 30/64 loss: 1.749269723892212
Batch 31/64 loss: 1.7446757555007935
Batch 32/64 loss: 1.7451543807983398
Batch 33/64 loss: 1.749711513519287
Batch 34/64 loss: 1.7463319301605225
Batch 35/64 loss: 1.7446396350860596
Batch 36/64 loss: 1.7461001873016357
Batch 37/64 loss: 1.7409389019012451
Batch 38/64 loss: 1.751981496810913
Batch 39/64 loss: 1.7524774074554443
Batch 40/64 loss: 1.7454428672790527
Batch 41/64 loss: 1.7491445541381836
Batch 42/64 loss: 1.7398877143859863
Batch 43/64 loss: 1.7388291358947754
Batch 44/64 loss: 1.7438223361968994
Batch 45/64 loss: 1.745234727859497
Batch 46/64 loss: 1.7426620721817017
Batch 47/64 loss: 1.7420552968978882
Batch 48/64 loss: 1.745384931564331
Batch 49/64 loss: 1.7436261177062988
Batch 50/64 loss: 1.7565772533416748
Batch 51/64 loss: 1.7455695867538452
Batch 52/64 loss: 1.7425940036773682
Batch 53/64 loss: 1.747198462486267
Batch 54/64 loss: 1.7458789348602295
Batch 55/64 loss: 1.7424410581588745
Batch 56/64 loss: 1.7471296787261963
Batch 57/64 loss: 1.747211217880249
Batch 58/64 loss: 1.7478611469268799
Batch 59/64 loss: 1.7428123950958252
Batch 60/64 loss: 1.7395621538162231
Batch 61/64 loss: 1.7473104000091553
Batch 62/64 loss: 1.7455731630325317
Batch 63/64 loss: 1.7429594993591309
Batch 64/64 loss: 1.9341505765914917
Epoch 213  Train loss: 1.7470322295731189  Val loss: 1.7607424824508195
Epoch 214
-------------------------------
Batch 1/64 loss: 1.7435405254364014
Batch 2/64 loss: 1.7480106353759766
Batch 3/64 loss: 1.7418192625045776
Batch 4/64 loss: 1.7417216300964355
Batch 5/64 loss: 1.744316577911377
Batch 6/64 loss: 1.75893235206604
Batch 7/64 loss: 1.7441303730010986
Batch 8/64 loss: 1.7430601119995117
Batch 9/64 loss: 1.7426011562347412
Batch 10/64 loss: 1.7510218620300293
Batch 11/64 loss: 1.7450065612792969
Batch 12/64 loss: 1.741071343421936
Batch 13/64 loss: 1.7401151657104492
Batch 14/64 loss: 1.7502055168151855
Batch 15/64 loss: 1.746809959411621
Batch 16/64 loss: 1.7403428554534912
Batch 17/64 loss: 1.7395238876342773
Batch 18/64 loss: 1.740671992301941
Batch 19/64 loss: 1.7410569190979004
Batch 20/64 loss: 1.7410907745361328
Batch 21/64 loss: 1.7397565841674805
Batch 22/64 loss: 1.7400521039962769
Batch 23/64 loss: 1.7414870262145996
Batch 24/64 loss: 1.739119529724121
Batch 25/64 loss: 1.7409512996673584
Batch 26/64 loss: 1.7519217729568481
Batch 27/64 loss: 1.7504096031188965
Batch 28/64 loss: 1.7423865795135498
Batch 29/64 loss: 1.741204023361206
Batch 30/64 loss: 1.7439744472503662
Batch 31/64 loss: 1.744218111038208
Batch 32/64 loss: 1.740154504776001
Batch 33/64 loss: 1.7426998615264893
Batch 34/64 loss: 1.7416253089904785
Batch 35/64 loss: 1.73976731300354
Batch 36/64 loss: 1.7419214248657227
Batch 37/64 loss: 1.7452783584594727
Batch 38/64 loss: 1.7481777667999268
Batch 39/64 loss: 1.7420308589935303
Batch 40/64 loss: 1.740199089050293
Batch 41/64 loss: 1.7408024072647095
Batch 42/64 loss: 1.7440807819366455
Batch 43/64 loss: 1.7415544986724854
Batch 44/64 loss: 1.7413440942764282
Batch 45/64 loss: 1.7415663003921509
Batch 46/64 loss: 1.740859031677246
Batch 47/64 loss: 1.7604176998138428
Batch 48/64 loss: 1.7423588037490845
Batch 49/64 loss: 1.7396718263626099
Batch 50/64 loss: 1.7517526149749756
Batch 51/64 loss: 1.7446906566619873
Batch 52/64 loss: 1.7430661916732788
Batch 53/64 loss: 1.7631218433380127
Batch 54/64 loss: 1.7470712661743164
Batch 55/64 loss: 1.7431312799453735
Batch 56/64 loss: 1.7442855834960938
Batch 57/64 loss: 1.739497184753418
Batch 58/64 loss: 1.741461992263794
Batch 59/64 loss: 1.7475857734680176
Batch 60/64 loss: 1.7432780265808105
Batch 61/64 loss: 1.7424819469451904
Batch 62/64 loss: 1.7388967275619507
Batch 63/64 loss: 1.7429242134094238
Batch 64/64 loss: 1.9322693347930908
Epoch 214  Train loss: 1.746156671000462  Val loss: 1.7612404913427084
Epoch 215
-------------------------------
Batch 1/64 loss: 1.7407162189483643
Batch 2/64 loss: 1.7455084323883057
Batch 3/64 loss: 1.7395892143249512
Batch 4/64 loss: 1.7423597574234009
Batch 5/64 loss: 1.7418835163116455
Batch 6/64 loss: 1.7411689758300781
Batch 7/64 loss: 1.7501503229141235
Batch 8/64 loss: 1.744070053100586
Batch 9/64 loss: 1.742110252380371
Batch 10/64 loss: 1.7411936521530151
Batch 11/64 loss: 1.7461355924606323
Batch 12/64 loss: 1.7420727014541626
Batch 13/64 loss: 1.7467052936553955
Batch 14/64 loss: 1.741276741027832
Batch 15/64 loss: 1.7432756423950195
Batch 16/64 loss: 1.7506318092346191
Batch 17/64 loss: 1.7715036869049072
Batch 18/64 loss: 1.7446784973144531
Batch 19/64 loss: 1.7415900230407715
Batch 20/64 loss: 1.7462356090545654
Batch 21/64 loss: 1.7414305210113525
Batch 22/64 loss: 1.7415742874145508
Batch 23/64 loss: 1.742762565612793
Batch 24/64 loss: 1.7419919967651367
Batch 25/64 loss: 1.7568016052246094
Batch 26/64 loss: 1.7400610446929932
Batch 27/64 loss: 1.741255521774292
Batch 28/64 loss: 1.7395501136779785
Batch 29/64 loss: 1.7536404132843018
Batch 30/64 loss: 1.7398382425308228
Batch 31/64 loss: 1.7402749061584473
Batch 32/64 loss: 1.7411807775497437
Batch 33/64 loss: 1.7486884593963623
Batch 34/64 loss: 1.7423617839813232
Batch 35/64 loss: 1.7602736949920654
Batch 36/64 loss: 1.741740345954895
Batch 37/64 loss: 1.749694585800171
Batch 38/64 loss: 1.7399673461914062
Batch 39/64 loss: 1.7436847686767578
Batch 40/64 loss: 1.7447831630706787
Batch 41/64 loss: 1.739305019378662
Batch 42/64 loss: 1.7468185424804688
Batch 43/64 loss: 1.7462626695632935
Batch 44/64 loss: 1.7407820224761963
Batch 45/64 loss: 1.7512168884277344
Batch 46/64 loss: 1.7519394159317017
Batch 47/64 loss: 1.7392385005950928
Batch 48/64 loss: 1.744152545928955
Batch 49/64 loss: 1.7438228130340576
Batch 50/64 loss: 1.740856409072876
Batch 51/64 loss: 1.7432289123535156
Batch 52/64 loss: 1.7422031164169312
Batch 53/64 loss: 1.741180181503296
Batch 54/64 loss: 1.7428646087646484
Batch 55/64 loss: 1.7412035465240479
Batch 56/64 loss: 1.7401816844940186
Batch 57/64 loss: 1.743107557296753
Batch 58/64 loss: 1.7420281171798706
Batch 59/64 loss: 1.7393314838409424
Batch 60/64 loss: 1.7432174682617188
Batch 61/64 loss: 1.7388371229171753
Batch 62/64 loss: 1.7412545680999756
Batch 63/64 loss: 1.7406692504882812
Batch 64/64 loss: 1.9348816871643066
Epoch 215  Train loss: 1.7463415819055894  Val loss: 1.7623193509799917
Epoch 216
-------------------------------
Batch 1/64 loss: 1.742516040802002
Batch 2/64 loss: 1.7365525960922241
Batch 3/64 loss: 1.7412900924682617
Batch 4/64 loss: 1.7378621101379395
Batch 5/64 loss: 1.7394225597381592
Batch 6/64 loss: 1.7436848878860474
Batch 7/64 loss: 1.7588005065917969
Batch 8/64 loss: 1.7436437606811523
Batch 9/64 loss: 1.7434663772583008
Batch 10/64 loss: 1.7408151626586914
Batch 11/64 loss: 1.7428570985794067
Batch 12/64 loss: 1.7445826530456543
Batch 13/64 loss: 1.7407573461532593
Batch 14/64 loss: 1.7459019422531128
Batch 15/64 loss: 1.7389122247695923
Batch 16/64 loss: 1.7401957511901855
Batch 17/64 loss: 1.7441673278808594
Batch 18/64 loss: 1.7457749843597412
Batch 19/64 loss: 1.742000699043274
Batch 20/64 loss: 1.7439948320388794
Batch 21/64 loss: 1.7420437335968018
Batch 22/64 loss: 1.7409473657608032
Batch 23/64 loss: 1.7502708435058594
Batch 24/64 loss: 1.7407442331314087
Batch 25/64 loss: 1.7410879135131836
Batch 26/64 loss: 1.7466752529144287
Batch 27/64 loss: 1.73984956741333
Batch 28/64 loss: 1.738497257232666
Batch 29/64 loss: 1.743241310119629
Batch 30/64 loss: 1.741516351699829
Batch 31/64 loss: 1.7394959926605225
Batch 32/64 loss: 1.7427256107330322
Batch 33/64 loss: 1.7419910430908203
Batch 34/64 loss: 1.741978406906128
Batch 35/64 loss: 1.7392754554748535
Batch 36/64 loss: 1.7430038452148438
Batch 37/64 loss: 1.7385203838348389
Batch 38/64 loss: 1.7371842861175537
Batch 39/64 loss: 1.7390656471252441
Batch 40/64 loss: 1.7424957752227783
Batch 41/64 loss: 1.7429524660110474
Batch 42/64 loss: 1.7399846315383911
Batch 43/64 loss: 1.7413280010223389
Batch 44/64 loss: 1.7400908470153809
Batch 45/64 loss: 1.7447900772094727
Batch 46/64 loss: 1.7399616241455078
Batch 47/64 loss: 1.7410547733306885
Batch 48/64 loss: 1.7384963035583496
Batch 49/64 loss: 1.768545150756836
Batch 50/64 loss: 1.7400577068328857
Batch 51/64 loss: 1.7438862323760986
Batch 52/64 loss: 1.7473663091659546
Batch 53/64 loss: 1.738816499710083
Batch 54/64 loss: 1.7419555187225342
Batch 55/64 loss: 1.7421952486038208
Batch 56/64 loss: 1.7434804439544678
Batch 57/64 loss: 1.7455990314483643
Batch 58/64 loss: 1.7443466186523438
Batch 59/64 loss: 1.7544639110565186
Batch 60/64 loss: 1.7438251972198486
Batch 61/64 loss: 1.7390024662017822
Batch 62/64 loss: 1.738251805305481
Batch 63/64 loss: 1.742071509361267
Batch 64/64 loss: 1.9305795431137085
Epoch 216  Train loss: 1.7449139805401073  Val loss: 1.758066869683282
Saving best model, epoch: 216
Epoch 217
-------------------------------
Batch 1/64 loss: 1.7486615180969238
Batch 2/64 loss: 1.7427308559417725
Batch 3/64 loss: 1.7386856079101562
Batch 4/64 loss: 1.7421163320541382
Batch 5/64 loss: 1.7377526760101318
Batch 6/64 loss: 1.7515153884887695
Batch 7/64 loss: 1.7396996021270752
Batch 8/64 loss: 1.7392486333847046
Batch 9/64 loss: 1.7388293743133545
Batch 10/64 loss: 1.7376573085784912
Batch 11/64 loss: 1.749690055847168
Batch 12/64 loss: 1.7543690204620361
Batch 13/64 loss: 1.7393667697906494
Batch 14/64 loss: 1.7370638847351074
Batch 15/64 loss: 1.7371704578399658
Batch 16/64 loss: 1.7414584159851074
Batch 17/64 loss: 1.7368488311767578
Batch 18/64 loss: 1.7378485202789307
Batch 19/64 loss: 1.7405661344528198
Batch 20/64 loss: 1.7408792972564697
Batch 21/64 loss: 1.7390975952148438
Batch 22/64 loss: 1.7425220012664795
Batch 23/64 loss: 1.7576829195022583
Batch 24/64 loss: 1.740879774093628
Batch 25/64 loss: 1.7394263744354248
Batch 26/64 loss: 1.7440235614776611
Batch 27/64 loss: 1.7413318157196045
Batch 28/64 loss: 1.741806983947754
Batch 29/64 loss: 1.7397570610046387
Batch 30/64 loss: 1.7416077852249146
Batch 31/64 loss: 1.7403433322906494
Batch 32/64 loss: 1.7395533323287964
Batch 33/64 loss: 1.7458913326263428
Batch 34/64 loss: 1.740124225616455
Batch 35/64 loss: 1.7367770671844482
Batch 36/64 loss: 1.7387750148773193
Batch 37/64 loss: 1.742300271987915
Batch 38/64 loss: 1.7455623149871826
Batch 39/64 loss: 1.7424044609069824
Batch 40/64 loss: 1.740181803703308
Batch 41/64 loss: 1.7428141832351685
Batch 42/64 loss: 1.7421139478683472
Batch 43/64 loss: 1.7453888654708862
Batch 44/64 loss: 1.744992733001709
Batch 45/64 loss: 1.7386423349380493
Batch 46/64 loss: 1.756819725036621
Batch 47/64 loss: 1.7426713705062866
Batch 48/64 loss: 1.7409082651138306
Batch 49/64 loss: 1.7495570182800293
Batch 50/64 loss: 1.7408275604248047
Batch 51/64 loss: 1.7426135540008545
Batch 52/64 loss: 1.746679425239563
Batch 53/64 loss: 1.7416483163833618
Batch 54/64 loss: 1.7472760677337646
Batch 55/64 loss: 1.758355736732483
Batch 56/64 loss: 1.748150110244751
Batch 57/64 loss: 1.7449562549591064
Batch 58/64 loss: 1.7510981559753418
Batch 59/64 loss: 1.751122236251831
Batch 60/64 loss: 1.745987892150879
Batch 61/64 loss: 1.744446039199829
Batch 62/64 loss: 1.7405813932418823
Batch 63/64 loss: 1.744093894958496
Batch 64/64 loss: 1.9281566143035889
Epoch 217  Train loss: 1.7454128667420032  Val loss: 1.7682086520178621
Epoch 218
-------------------------------
Batch 1/64 loss: 1.7408303022384644
Batch 2/64 loss: 1.7389111518859863
Batch 3/64 loss: 1.7395097017288208
Batch 4/64 loss: 1.748817801475525
Batch 5/64 loss: 1.7427845001220703
Batch 6/64 loss: 1.7400166988372803
Batch 7/64 loss: 1.7439885139465332
Batch 8/64 loss: 1.7513127326965332
Batch 9/64 loss: 1.7395058870315552
Batch 10/64 loss: 1.741804599761963
Batch 11/64 loss: 1.7420496940612793
Batch 12/64 loss: 1.7460681200027466
Batch 13/64 loss: 1.7421586513519287
Batch 14/64 loss: 1.7415775060653687
Batch 15/64 loss: 1.7431795597076416
Batch 16/64 loss: 1.7408206462860107
Batch 17/64 loss: 1.7411119937896729
Batch 18/64 loss: 1.742877721786499
Batch 19/64 loss: 1.7437336444854736
Batch 20/64 loss: 1.742506504058838
Batch 21/64 loss: 1.7399919033050537
Batch 22/64 loss: 1.7465424537658691
Batch 23/64 loss: 1.7427918910980225
Batch 24/64 loss: 1.7385261058807373
Batch 25/64 loss: 1.7605931758880615
Batch 26/64 loss: 1.7456625699996948
Batch 27/64 loss: 1.7450611591339111
Batch 28/64 loss: 1.7372112274169922
Batch 29/64 loss: 1.7386757135391235
Batch 30/64 loss: 1.7404735088348389
Batch 31/64 loss: 1.7413136959075928
Batch 32/64 loss: 1.7397065162658691
Batch 33/64 loss: 1.7373695373535156
Batch 34/64 loss: 1.7377479076385498
Batch 35/64 loss: 1.738271713256836
Batch 36/64 loss: 1.742123007774353
Batch 37/64 loss: 1.7432372570037842
Batch 38/64 loss: 1.7409756183624268
Batch 39/64 loss: 1.7386865615844727
Batch 40/64 loss: 1.769429087638855
Batch 41/64 loss: 1.740028738975525
Batch 42/64 loss: 1.7417725324630737
Batch 43/64 loss: 1.7415765523910522
Batch 44/64 loss: 1.7467108964920044
Batch 45/64 loss: 1.7450064420700073
Batch 46/64 loss: 1.7404714822769165
Batch 47/64 loss: 1.7451837062835693
Batch 48/64 loss: 1.7435193061828613
Batch 49/64 loss: 1.7417856454849243
Batch 50/64 loss: 1.7462499141693115
Batch 51/64 loss: 1.7417277097702026
Batch 52/64 loss: 1.7439448833465576
Batch 53/64 loss: 1.7469215393066406
Batch 54/64 loss: 1.746455430984497
Batch 55/64 loss: 1.7416107654571533
Batch 56/64 loss: 1.7408864498138428
Batch 57/64 loss: 1.7438395023345947
Batch 58/64 loss: 1.738521695137024
Batch 59/64 loss: 1.7420541048049927
Batch 60/64 loss: 1.7398513555526733
Batch 61/64 loss: 1.737326741218567
Batch 62/64 loss: 1.7376524209976196
Batch 63/64 loss: 1.7387683391571045
Batch 64/64 loss: 1.9287134408950806
Epoch 218  Train loss: 1.7448840435813455  Val loss: 1.7595404251334594
Epoch 219
-------------------------------
Batch 1/64 loss: 1.740082025527954
Batch 2/64 loss: 1.7427278757095337
Batch 3/64 loss: 1.7381031513214111
Batch 4/64 loss: 1.7455672025680542
Batch 5/64 loss: 1.739223599433899
Batch 6/64 loss: 1.7407042980194092
Batch 7/64 loss: 1.746854543685913
Batch 8/64 loss: 1.760388970375061
Batch 9/64 loss: 1.7433780431747437
Batch 10/64 loss: 1.7412029504776
Batch 11/64 loss: 1.7417021989822388
Batch 12/64 loss: 1.7391020059585571
Batch 13/64 loss: 1.738656759262085
Batch 14/64 loss: 1.7434585094451904
Batch 15/64 loss: 1.744375228881836
Batch 16/64 loss: 1.7406073808670044
Batch 17/64 loss: 1.741621494293213
Batch 18/64 loss: 1.7337188720703125
Batch 19/64 loss: 1.7404582500457764
Batch 20/64 loss: 1.739440679550171
Batch 21/64 loss: 1.7381887435913086
Batch 22/64 loss: 1.738922119140625
Batch 23/64 loss: 1.7375078201293945
Batch 24/64 loss: 1.736550211906433
Batch 25/64 loss: 1.7380173206329346
Batch 26/64 loss: 1.7377064228057861
Batch 27/64 loss: 1.7385621070861816
Batch 28/64 loss: 1.7399449348449707
Batch 29/64 loss: 1.7379226684570312
Batch 30/64 loss: 1.7389742136001587
Batch 31/64 loss: 1.737886905670166
Batch 32/64 loss: 1.735792875289917
Batch 33/64 loss: 1.738147258758545
Batch 34/64 loss: 1.736523151397705
Batch 35/64 loss: 1.7368621826171875
Batch 36/64 loss: 1.7427034378051758
Batch 37/64 loss: 1.739288091659546
Batch 38/64 loss: 1.739880919456482
Batch 39/64 loss: 1.7365961074829102
Batch 40/64 loss: 1.7365798950195312
Batch 41/64 loss: 1.740584135055542
Batch 42/64 loss: 1.7410390377044678
Batch 43/64 loss: 1.7409758567810059
Batch 44/64 loss: 1.7432961463928223
Batch 45/64 loss: 1.7411818504333496
Batch 46/64 loss: 1.7463722229003906
Batch 47/64 loss: 1.7394940853118896
Batch 48/64 loss: 1.7391459941864014
Batch 49/64 loss: 1.7399053573608398
Batch 50/64 loss: 1.75095534324646
Batch 51/64 loss: 1.7434277534484863
Batch 52/64 loss: 1.7384109497070312
Batch 53/64 loss: 1.7378718852996826
Batch 54/64 loss: 1.7424529790878296
Batch 55/64 loss: 1.7381646633148193
Batch 56/64 loss: 1.7440440654754639
Batch 57/64 loss: 1.7396354675292969
Batch 58/64 loss: 1.7389167547225952
Batch 59/64 loss: 1.7398710250854492
Batch 60/64 loss: 1.7424403429031372
Batch 61/64 loss: 1.7402467727661133
Batch 62/64 loss: 1.762962818145752
Batch 63/64 loss: 1.7471461296081543
Batch 64/64 loss: 1.9310002326965332
Epoch 219  Train loss: 1.7432270311841778  Val loss: 1.7600024918100678
Epoch 220
-------------------------------
Batch 1/64 loss: 1.7517979145050049
Batch 2/64 loss: 1.7419172525405884
Batch 3/64 loss: 1.7406165599822998
Batch 4/64 loss: 1.742722749710083
Batch 5/64 loss: 1.7440688610076904
Batch 6/64 loss: 1.7408106327056885
Batch 7/64 loss: 1.744074821472168
Batch 8/64 loss: 1.742273211479187
Batch 9/64 loss: 1.739770531654358
Batch 10/64 loss: 1.738088607788086
Batch 11/64 loss: 1.7394353151321411
Batch 12/64 loss: 1.7391607761383057
Batch 13/64 loss: 1.7462470531463623
Batch 14/64 loss: 1.743607759475708
Batch 15/64 loss: 1.7416794300079346
Batch 16/64 loss: 1.7396399974822998
Batch 17/64 loss: 1.7399945259094238
Batch 18/64 loss: 1.7389119863510132
Batch 19/64 loss: 1.7379508018493652
Batch 20/64 loss: 1.7373415231704712
Batch 21/64 loss: 1.7368583679199219
Batch 22/64 loss: 1.7371549606323242
Batch 23/64 loss: 1.7378020286560059
Batch 24/64 loss: 1.7366435527801514
Batch 25/64 loss: 1.744871973991394
Batch 26/64 loss: 1.7378785610198975
Batch 27/64 loss: 1.7368175983428955
Batch 28/64 loss: 1.7398593425750732
Batch 29/64 loss: 1.7383193969726562
Batch 30/64 loss: 1.7470219135284424
Batch 31/64 loss: 1.7356059551239014
Batch 32/64 loss: 1.738844871520996
Batch 33/64 loss: 1.740391492843628
Batch 34/64 loss: 1.747393250465393
Batch 35/64 loss: 1.73812997341156
Batch 36/64 loss: 1.740311861038208
Batch 37/64 loss: 1.7437512874603271
Batch 38/64 loss: 1.7371985912322998
Batch 39/64 loss: 1.7411975860595703
Batch 40/64 loss: 1.7384958267211914
Batch 41/64 loss: 1.7569677829742432
Batch 42/64 loss: 1.7352409362792969
Batch 43/64 loss: 1.7560677528381348
Batch 44/64 loss: 1.7401783466339111
Batch 45/64 loss: 1.7376351356506348
Batch 46/64 loss: 1.7342257499694824
Batch 47/64 loss: 1.7372779846191406
Batch 48/64 loss: 1.7425912618637085
Batch 49/64 loss: 1.7400482892990112
Batch 50/64 loss: 1.744399070739746
Batch 51/64 loss: 1.736599326133728
Batch 52/64 loss: 1.7401299476623535
Batch 53/64 loss: 1.7422714233398438
Batch 54/64 loss: 1.739304780960083
Batch 55/64 loss: 1.7369325160980225
Batch 56/64 loss: 1.7383549213409424
Batch 57/64 loss: 1.7382795810699463
Batch 58/64 loss: 1.7381830215454102
Batch 59/64 loss: 1.7395226955413818
Batch 60/64 loss: 1.736163854598999
Batch 61/64 loss: 1.7319869995117188
Batch 62/64 loss: 1.7361083030700684
Batch 63/64 loss: 1.736314296722412
Batch 64/64 loss: 1.9293944835662842
Epoch 220  Train loss: 1.7425331536461326  Val loss: 1.7577957197562935
Saving best model, epoch: 220
Epoch 221
-------------------------------
Batch 1/64 loss: 1.7374844551086426
Batch 2/64 loss: 1.740943193435669
Batch 3/64 loss: 1.7420127391815186
Batch 4/64 loss: 1.7391552925109863
Batch 5/64 loss: 1.741484522819519
Batch 6/64 loss: 1.74734628200531
Batch 7/64 loss: 1.7428603172302246
Batch 8/64 loss: 1.7363321781158447
Batch 9/64 loss: 1.7372047901153564
Batch 10/64 loss: 1.7376458644866943
Batch 11/64 loss: 1.7419378757476807
Batch 12/64 loss: 1.7372796535491943
Batch 13/64 loss: 1.7449331283569336
Batch 14/64 loss: 1.7492164373397827
Batch 15/64 loss: 1.7405054569244385
Batch 16/64 loss: 1.7383840084075928
Batch 17/64 loss: 1.7446846961975098
Batch 18/64 loss: 1.7361969947814941
Batch 19/64 loss: 1.7440259456634521
Batch 20/64 loss: 1.739486575126648
Batch 21/64 loss: 1.740858554840088
Batch 22/64 loss: 1.736680269241333
Batch 23/64 loss: 1.7393159866333008
Batch 24/64 loss: 1.7364168167114258
Batch 25/64 loss: 1.7406222820281982
Batch 26/64 loss: 1.736054539680481
Batch 27/64 loss: 1.7372121810913086
Batch 28/64 loss: 1.7383582592010498
Batch 29/64 loss: 1.7440004348754883
Batch 30/64 loss: 1.7585313320159912
Batch 31/64 loss: 1.738796591758728
Batch 32/64 loss: 1.749043345451355
Batch 33/64 loss: 1.7388033866882324
Batch 34/64 loss: 1.7408367395401
Batch 35/64 loss: 1.7379629611968994
Batch 36/64 loss: 1.736249327659607
Batch 37/64 loss: 1.7407135963439941
Batch 38/64 loss: 1.7367627620697021
Batch 39/64 loss: 1.7431089878082275
Batch 40/64 loss: 1.7414640188217163
Batch 41/64 loss: 1.744347095489502
Batch 42/64 loss: 1.742319941520691
Batch 43/64 loss: 1.7376192808151245
Batch 44/64 loss: 1.7369765043258667
Batch 45/64 loss: 1.7603504657745361
Batch 46/64 loss: 1.738813877105713
Batch 47/64 loss: 1.7392218112945557
Batch 48/64 loss: 1.7396405935287476
Batch 49/64 loss: 1.738023281097412
Batch 50/64 loss: 1.7388668060302734
Batch 51/64 loss: 1.7388288974761963
Batch 52/64 loss: 1.7370421886444092
Batch 53/64 loss: 1.739455223083496
Batch 54/64 loss: 1.7364321947097778
Batch 55/64 loss: 1.7408008575439453
Batch 56/64 loss: 1.7411341667175293
Batch 57/64 loss: 1.7401498556137085
Batch 58/64 loss: 1.7386791706085205
Batch 59/64 loss: 1.7600833177566528
Batch 60/64 loss: 1.7396186590194702
Batch 61/64 loss: 1.7388124465942383
Batch 62/64 loss: 1.7368764877319336
Batch 63/64 loss: 1.740922451019287
Batch 64/64 loss: 1.9298546314239502
Epoch 221  Train loss: 1.743110891416961  Val loss: 1.7570534588135396
Saving best model, epoch: 221
Epoch 222
-------------------------------
Batch 1/64 loss: 1.7376909255981445
Batch 2/64 loss: 1.7361034154891968
Batch 3/64 loss: 1.7391541004180908
Batch 4/64 loss: 1.7353324890136719
Batch 5/64 loss: 1.7398157119750977
Batch 6/64 loss: 1.7364351749420166
Batch 7/64 loss: 1.7391986846923828
Batch 8/64 loss: 1.738309621810913
Batch 9/64 loss: 1.7419711351394653
Batch 10/64 loss: 1.734961748123169
Batch 11/64 loss: 1.7403011322021484
Batch 12/64 loss: 1.738821268081665
Batch 13/64 loss: 1.7384369373321533
Batch 14/64 loss: 1.7373324632644653
Batch 15/64 loss: 1.7357103824615479
Batch 16/64 loss: 1.7350530624389648
Batch 17/64 loss: 1.7367417812347412
Batch 18/64 loss: 1.7381922006607056
Batch 19/64 loss: 1.7387142181396484
Batch 20/64 loss: 1.7359492778778076
Batch 21/64 loss: 1.7344192266464233
Batch 22/64 loss: 1.735748291015625
Batch 23/64 loss: 1.7395551204681396
Batch 24/64 loss: 1.7351913452148438
Batch 25/64 loss: 1.739600658416748
Batch 26/64 loss: 1.7445569038391113
Batch 27/64 loss: 1.7394556999206543
Batch 28/64 loss: 1.73526930809021
Batch 29/64 loss: 1.7508654594421387
Batch 30/64 loss: 1.7428001165390015
Batch 31/64 loss: 1.7416362762451172
Batch 32/64 loss: 1.7363965511322021
Batch 33/64 loss: 1.7400848865509033
Batch 34/64 loss: 1.7340446710586548
Batch 35/64 loss: 1.738992691040039
Batch 36/64 loss: 1.73751962184906
Batch 37/64 loss: 1.7354435920715332
Batch 38/64 loss: 1.7572436332702637
Batch 39/64 loss: 1.7547283172607422
Batch 40/64 loss: 1.7362408638000488
Batch 41/64 loss: 1.74065363407135
Batch 42/64 loss: 1.7448846101760864
Batch 43/64 loss: 1.739396572113037
Batch 44/64 loss: 1.7437081336975098
Batch 45/64 loss: 1.7427940368652344
Batch 46/64 loss: 1.7379896640777588
Batch 47/64 loss: 1.740344524383545
Batch 48/64 loss: 1.738655924797058
Batch 49/64 loss: 1.744992971420288
Batch 50/64 loss: 1.736362338066101
Batch 51/64 loss: 1.740088939666748
Batch 52/64 loss: 1.7416795492172241
Batch 53/64 loss: 1.7415413856506348
Batch 54/64 loss: 1.744470477104187
Batch 55/64 loss: 1.7403099536895752
Batch 56/64 loss: 1.73495352268219
Batch 57/64 loss: 1.7352502346038818
Batch 58/64 loss: 1.736701250076294
Batch 59/64 loss: 1.7389030456542969
Batch 60/64 loss: 1.737318515777588
Batch 61/64 loss: 1.7424218654632568
Batch 62/64 loss: 1.7348822355270386
Batch 63/64 loss: 1.7453114986419678
Batch 64/64 loss: 1.930548071861267
Epoch 222  Train loss: 1.7417340376797845  Val loss: 1.757036795730853
Saving best model, epoch: 222
Epoch 223
-------------------------------
Batch 1/64 loss: 1.7371083498001099
Batch 2/64 loss: 1.7407722473144531
Batch 3/64 loss: 1.736520528793335
Batch 4/64 loss: 1.7408015727996826
Batch 5/64 loss: 1.7381563186645508
Batch 6/64 loss: 1.7344681024551392
Batch 7/64 loss: 1.7375246286392212
Batch 8/64 loss: 1.7389745712280273
Batch 9/64 loss: 1.7381706237792969
Batch 10/64 loss: 1.733902931213379
Batch 11/64 loss: 1.7351876497268677
Batch 12/64 loss: 1.7390248775482178
Batch 13/64 loss: 1.7405855655670166
Batch 14/64 loss: 1.7356398105621338
Batch 15/64 loss: 1.7373977899551392
Batch 16/64 loss: 1.7370198965072632
Batch 17/64 loss: 1.7345643043518066
Batch 18/64 loss: 1.7360155582427979
Batch 19/64 loss: 1.7370879650115967
Batch 20/64 loss: 1.738966464996338
Batch 21/64 loss: 1.7355422973632812
Batch 22/64 loss: 1.7352325916290283
Batch 23/64 loss: 1.7398059368133545
Batch 24/64 loss: 1.7372357845306396
Batch 25/64 loss: 1.7405519485473633
Batch 26/64 loss: 1.7382042407989502
Batch 27/64 loss: 1.7365199327468872
Batch 28/64 loss: 1.7381627559661865
Batch 29/64 loss: 1.7569043636322021
Batch 30/64 loss: 1.7371034622192383
Batch 31/64 loss: 1.7409443855285645
Batch 32/64 loss: 1.7383676767349243
Batch 33/64 loss: 1.7422211170196533
Batch 34/64 loss: 1.736440658569336
Batch 35/64 loss: 1.7378294467926025
Batch 36/64 loss: 1.7362701892852783
Batch 37/64 loss: 1.736295223236084
Batch 38/64 loss: 1.7391741275787354
Batch 39/64 loss: 1.7401474714279175
Batch 40/64 loss: 1.7385780811309814
Batch 41/64 loss: 1.740224003791809
Batch 42/64 loss: 1.7405866384506226
Batch 43/64 loss: 1.7407917976379395
Batch 44/64 loss: 1.754946231842041
Batch 45/64 loss: 1.7445259094238281
Batch 46/64 loss: 1.7443398237228394
Batch 47/64 loss: 1.7402117252349854
Batch 48/64 loss: 1.7371114492416382
Batch 49/64 loss: 1.7422693967819214
Batch 50/64 loss: 1.736889362335205
Batch 51/64 loss: 1.7401869297027588
Batch 52/64 loss: 1.7391456365585327
Batch 53/64 loss: 1.7377307415008545
Batch 54/64 loss: 1.7413502931594849
Batch 55/64 loss: 1.739535927772522
Batch 56/64 loss: 1.7413002252578735
Batch 57/64 loss: 1.7368621826171875
Batch 58/64 loss: 1.7376039028167725
Batch 59/64 loss: 1.7418371438980103
Batch 60/64 loss: 1.7432003021240234
Batch 61/64 loss: 1.7399779558181763
Batch 62/64 loss: 1.7590675354003906
Batch 63/64 loss: 1.742240309715271
Batch 64/64 loss: 1.9260756969451904
Epoch 223  Train loss: 1.7417398219015083  Val loss: 1.7581868450256557
Epoch 224
-------------------------------
Batch 1/64 loss: 1.7427343130111694
Batch 2/64 loss: 1.7373247146606445
Batch 3/64 loss: 1.7399163246154785
Batch 4/64 loss: 1.7373425960540771
Batch 5/64 loss: 1.7433899641036987
Batch 6/64 loss: 1.7480571269989014
Batch 7/64 loss: 1.7395975589752197
Batch 8/64 loss: 1.7422549724578857
Batch 9/64 loss: 1.7559348344802856
Batch 10/64 loss: 1.7395572662353516
Batch 11/64 loss: 1.7409281730651855
Batch 12/64 loss: 1.7356055974960327
Batch 13/64 loss: 1.757167100906372
Batch 14/64 loss: 1.7375208139419556
Batch 15/64 loss: 1.739067554473877
Batch 16/64 loss: 1.7388925552368164
Batch 17/64 loss: 1.7393962144851685
Batch 18/64 loss: 1.7410101890563965
Batch 19/64 loss: 1.7390917539596558
Batch 20/64 loss: 1.739248275756836
Batch 21/64 loss: 1.7421767711639404
Batch 22/64 loss: 1.740302562713623
Batch 23/64 loss: 1.7401971817016602
Batch 24/64 loss: 1.7369110584259033
Batch 25/64 loss: 1.7406017780303955
Batch 26/64 loss: 1.7414774894714355
Batch 27/64 loss: 1.7361842393875122
Batch 28/64 loss: 1.7408537864685059
Batch 29/64 loss: 1.7409248352050781
Batch 30/64 loss: 1.7378376722335815
Batch 31/64 loss: 1.7459157705307007
Batch 32/64 loss: 1.7605462074279785
Batch 33/64 loss: 1.7391912937164307
Batch 34/64 loss: 1.7380037307739258
Batch 35/64 loss: 1.7373872995376587
Batch 36/64 loss: 1.7380313873291016
Batch 37/64 loss: 1.7373214960098267
Batch 38/64 loss: 1.7377572059631348
Batch 39/64 loss: 1.7388017177581787
Batch 40/64 loss: 1.7383294105529785
Batch 41/64 loss: 1.7401643991470337
Batch 42/64 loss: 1.7359892129898071
Batch 43/64 loss: 1.737573504447937
Batch 44/64 loss: 1.738505244255066
Batch 45/64 loss: 1.7426049709320068
Batch 46/64 loss: 1.7377115488052368
Batch 47/64 loss: 1.7371714115142822
Batch 48/64 loss: 1.7355806827545166
Batch 49/64 loss: 1.7409143447875977
Batch 50/64 loss: 1.7395564317703247
Batch 51/64 loss: 1.7389166355133057
Batch 52/64 loss: 1.7404334545135498
Batch 53/64 loss: 1.7436045408248901
Batch 54/64 loss: 1.7383582592010498
Batch 55/64 loss: 1.7413687705993652
Batch 56/64 loss: 1.7460486888885498
Batch 57/64 loss: 1.7388522624969482
Batch 58/64 loss: 1.739337682723999
Batch 59/64 loss: 1.7443668842315674
Batch 60/64 loss: 1.7378196716308594
Batch 61/64 loss: 1.7423804998397827
Batch 62/64 loss: 1.743035078048706
Batch 63/64 loss: 1.7395296096801758
Batch 64/64 loss: 1.9268901348114014
Epoch 224  Train loss: 1.74286717153063  Val loss: 1.758890361720344
Epoch 225
-------------------------------
Batch 1/64 loss: 1.7382688522338867
Batch 2/64 loss: 1.7455568313598633
Batch 3/64 loss: 1.7433466911315918
Batch 4/64 loss: 1.7411937713623047
Batch 5/64 loss: 1.7410285472869873
Batch 6/64 loss: 1.7393813133239746
Batch 7/64 loss: 1.7391024827957153
Batch 8/64 loss: 1.7550973892211914
Batch 9/64 loss: 1.7600419521331787
Batch 10/64 loss: 1.7401318550109863
Batch 11/64 loss: 1.7523943185806274
Batch 12/64 loss: 1.7383604049682617
Batch 13/64 loss: 1.7432177066802979
Batch 14/64 loss: 1.7447915077209473
Batch 15/64 loss: 1.7515114545822144
Batch 16/64 loss: 1.7415165901184082
Batch 17/64 loss: 1.7372310161590576
Batch 18/64 loss: 1.7372210025787354
Batch 19/64 loss: 1.740209698677063
Batch 20/64 loss: 1.7375221252441406
Batch 21/64 loss: 1.7392168045043945
Batch 22/64 loss: 1.7390761375427246
Batch 23/64 loss: 1.7369606494903564
Batch 24/64 loss: 1.7398101091384888
Batch 25/64 loss: 1.7383525371551514
Batch 26/64 loss: 1.7348098754882812
Batch 27/64 loss: 1.7398995161056519
Batch 28/64 loss: 1.7340785264968872
Batch 29/64 loss: 1.737683653831482
Batch 30/64 loss: 1.7369720935821533
Batch 31/64 loss: 1.73903226852417
Batch 32/64 loss: 1.7412748336791992
Batch 33/64 loss: 1.74476957321167
Batch 34/64 loss: 1.7363767623901367
Batch 35/64 loss: 1.7416455745697021
Batch 36/64 loss: 1.738821268081665
Batch 37/64 loss: 1.7360320091247559
Batch 38/64 loss: 1.736517071723938
Batch 39/64 loss: 1.7419013977050781
Batch 40/64 loss: 1.7366619110107422
Batch 41/64 loss: 1.737818717956543
Batch 42/64 loss: 1.7368501424789429
Batch 43/64 loss: 1.738864779472351
Batch 44/64 loss: 1.739030361175537
Batch 45/64 loss: 1.736311674118042
Batch 46/64 loss: 1.7354350090026855
Batch 47/64 loss: 1.742422103881836
Batch 48/64 loss: 1.741088628768921
Batch 49/64 loss: 1.740064263343811
Batch 50/64 loss: 1.7375942468643188
Batch 51/64 loss: 1.738966941833496
Batch 52/64 loss: 1.7371232509613037
Batch 53/64 loss: 1.735039472579956
Batch 54/64 loss: 1.7419078350067139
Batch 55/64 loss: 1.7367560863494873
Batch 56/64 loss: 1.740293025970459
Batch 57/64 loss: 1.7357088327407837
Batch 58/64 loss: 1.741215467453003
Batch 59/64 loss: 1.736269474029541
Batch 60/64 loss: 1.7352362871170044
Batch 61/64 loss: 1.7373077869415283
Batch 62/64 loss: 1.7383514642715454
Batch 63/64 loss: 1.739448070526123
Batch 64/64 loss: 1.925652265548706
Epoch 225  Train loss: 1.7421233130436318  Val loss: 1.7559418121154367
Saving best model, epoch: 225
Epoch 226
-------------------------------
Batch 1/64 loss: 1.7374153137207031
Batch 2/64 loss: 1.739720106124878
Batch 3/64 loss: 1.736274242401123
Batch 4/64 loss: 1.7349941730499268
Batch 5/64 loss: 1.7372455596923828
Batch 6/64 loss: 1.7391557693481445
Batch 7/64 loss: 1.7384815216064453
Batch 8/64 loss: 1.735513687133789
Batch 9/64 loss: 1.7356257438659668
Batch 10/64 loss: 1.7356199026107788
Batch 11/64 loss: 1.752160906791687
Batch 12/64 loss: 1.7398279905319214
Batch 13/64 loss: 1.7413005828857422
Batch 14/64 loss: 1.7409716844558716
Batch 15/64 loss: 1.7376340627670288
Batch 16/64 loss: 1.7444955110549927
Batch 17/64 loss: 1.7395238876342773
Batch 18/64 loss: 1.7449616193771362
Batch 19/64 loss: 1.7371577024459839
Batch 20/64 loss: 1.7353463172912598
Batch 21/64 loss: 1.761716604232788
Batch 22/64 loss: 1.7362922430038452
Batch 23/64 loss: 1.742457389831543
Batch 24/64 loss: 1.738688588142395
Batch 25/64 loss: 1.7374513149261475
Batch 26/64 loss: 1.7408561706542969
Batch 27/64 loss: 1.739938735961914
Batch 28/64 loss: 1.7376306056976318
Batch 29/64 loss: 1.7421338558197021
Batch 30/64 loss: 1.737496256828308
Batch 31/64 loss: 1.7363542318344116
Batch 32/64 loss: 1.738270878791809
Batch 33/64 loss: 1.7371718883514404
Batch 34/64 loss: 1.7379263639450073
Batch 35/64 loss: 1.739609718322754
Batch 36/64 loss: 1.743561029434204
Batch 37/64 loss: 1.7396695613861084
Batch 38/64 loss: 1.7421157360076904
Batch 39/64 loss: 1.7410516738891602
Batch 40/64 loss: 1.7440608739852905
Batch 41/64 loss: 1.742989182472229
Batch 42/64 loss: 1.7355257272720337
Batch 43/64 loss: 1.740229845046997
Batch 44/64 loss: 1.7420963048934937
Batch 45/64 loss: 1.7425727844238281
Batch 46/64 loss: 1.7415270805358887
Batch 47/64 loss: 1.7362744808197021
Batch 48/64 loss: 1.745593547821045
Batch 49/64 loss: 1.7414095401763916
Batch 50/64 loss: 1.7385618686676025
Batch 51/64 loss: 1.7357356548309326
Batch 52/64 loss: 1.7412891387939453
Batch 53/64 loss: 1.7354702949523926
Batch 54/64 loss: 1.744917631149292
Batch 55/64 loss: 1.7530407905578613
Batch 56/64 loss: 1.7407197952270508
Batch 57/64 loss: 1.738980770111084
Batch 58/64 loss: 1.7484288215637207
Batch 59/64 loss: 1.7390546798706055
Batch 60/64 loss: 1.7606728076934814
Batch 61/64 loss: 1.7440605163574219
Batch 62/64 loss: 1.7537171840667725
Batch 63/64 loss: 1.746997356414795
Batch 64/64 loss: 1.9253921508789062
Epoch 226  Train loss: 1.7432437634935567  Val loss: 1.7617210751956272
Epoch 227
-------------------------------
Batch 1/64 loss: 1.7413824796676636
Batch 2/64 loss: 1.7438265085220337
Batch 3/64 loss: 1.7379038333892822
Batch 4/64 loss: 1.744253396987915
Batch 5/64 loss: 1.7392370700836182
Batch 6/64 loss: 1.740838885307312
Batch 7/64 loss: 1.738755226135254
Batch 8/64 loss: 1.7428359985351562
Batch 9/64 loss: 1.7371985912322998
Batch 10/64 loss: 1.7494525909423828
Batch 11/64 loss: 1.7391808032989502
Batch 12/64 loss: 1.7371454238891602
Batch 13/64 loss: 1.7428202629089355
Batch 14/64 loss: 1.7359014749526978
Batch 15/64 loss: 1.7373526096343994
Batch 16/64 loss: 1.7423020601272583
Batch 17/64 loss: 1.737799882888794
Batch 18/64 loss: 1.752767562866211
Batch 19/64 loss: 1.7422680854797363
Batch 20/64 loss: 1.7374067306518555
Batch 21/64 loss: 1.7380294799804688
Batch 22/64 loss: 1.7387897968292236
Batch 23/64 loss: 1.736971139907837
Batch 24/64 loss: 1.7410892248153687
Batch 25/64 loss: 1.7369050979614258
Batch 26/64 loss: 1.73575758934021
Batch 27/64 loss: 1.737231969833374
Batch 28/64 loss: 1.7410881519317627
Batch 29/64 loss: 1.7382280826568604
Batch 30/64 loss: 1.7440094947814941
Batch 31/64 loss: 1.742095708847046
Batch 32/64 loss: 1.739119529724121
Batch 33/64 loss: 1.7390050888061523
Batch 34/64 loss: 1.7411675453186035
Batch 35/64 loss: 1.7412033081054688
Batch 36/64 loss: 1.739060401916504
Batch 37/64 loss: 1.7379335165023804
Batch 38/64 loss: 1.7376158237457275
Batch 39/64 loss: 1.7409265041351318
Batch 40/64 loss: 1.7432610988616943
Batch 41/64 loss: 1.7367610931396484
Batch 42/64 loss: 1.739274263381958
Batch 43/64 loss: 1.7360661029815674
Batch 44/64 loss: 1.7379374504089355
Batch 45/64 loss: 1.7358616590499878
Batch 46/64 loss: 1.739872932434082
Batch 47/64 loss: 1.7424170970916748
Batch 48/64 loss: 1.7417969703674316
Batch 49/64 loss: 1.7525291442871094
Batch 50/64 loss: 1.7397578954696655
Batch 51/64 loss: 1.7443537712097168
Batch 52/64 loss: 1.7377210855484009
Batch 53/64 loss: 1.7713782787322998
Batch 54/64 loss: 1.7412678003311157
Batch 55/64 loss: 1.7414259910583496
Batch 56/64 loss: 1.7456902265548706
Batch 57/64 loss: 1.7416993379592896
Batch 58/64 loss: 1.7363628149032593
Batch 59/64 loss: 1.7394839525222778
Batch 60/64 loss: 1.7407469749450684
Batch 61/64 loss: 1.7407341003417969
Batch 62/64 loss: 1.7379212379455566
Batch 63/64 loss: 1.7396045923233032
Batch 64/64 loss: 1.9313013553619385
Epoch 227  Train loss: 1.743047197192323  Val loss: 1.76028367743869
Epoch 228
-------------------------------
Batch 1/64 loss: 1.7364906072616577
Batch 2/64 loss: 1.7404484748840332
Batch 3/64 loss: 1.7421104907989502
Batch 4/64 loss: 1.741137981414795
Batch 5/64 loss: 1.7446545362472534
Batch 6/64 loss: 1.7410036325454712
Batch 7/64 loss: 1.746044635772705
Batch 8/64 loss: 1.748230218887329
Batch 9/64 loss: 1.74503755569458
Batch 10/64 loss: 1.7437567710876465
Batch 11/64 loss: 1.7577741146087646
Batch 12/64 loss: 1.7410720586776733
Batch 13/64 loss: 1.7420082092285156
Batch 14/64 loss: 1.7391194105148315
Batch 15/64 loss: 1.7381477355957031
Batch 16/64 loss: 1.7512989044189453
Batch 17/64 loss: 1.7364972829818726
Batch 18/64 loss: 1.7507452964782715
Batch 19/64 loss: 1.7489928007125854
Batch 20/64 loss: 1.741977572441101
Batch 21/64 loss: 1.7383456230163574
Batch 22/64 loss: 1.7391953468322754
Batch 23/64 loss: 1.7457916736602783
Batch 24/64 loss: 1.7395811080932617
Batch 25/64 loss: 1.7413780689239502
Batch 26/64 loss: 1.739894151687622
Batch 27/64 loss: 1.7466583251953125
Batch 28/64 loss: 1.740271806716919
Batch 29/64 loss: 1.7438035011291504
Batch 30/64 loss: 1.738800287246704
Batch 31/64 loss: 1.7450194358825684
Batch 32/64 loss: 1.767235517501831
Batch 33/64 loss: 1.7475018501281738
Batch 34/64 loss: 1.7411675453186035
Batch 35/64 loss: 1.7460815906524658
Batch 36/64 loss: 1.7412165403366089
Batch 37/64 loss: 1.7438840866088867
Batch 38/64 loss: 1.7409154176712036
Batch 39/64 loss: 1.7427864074707031
Batch 40/64 loss: 1.7447415590286255
Batch 41/64 loss: 1.7476179599761963
Batch 42/64 loss: 1.7469542026519775
Batch 43/64 loss: 1.7431247234344482
Batch 44/64 loss: 1.7425919771194458
Batch 45/64 loss: 1.7488144636154175
Batch 46/64 loss: 1.7496633529663086
Batch 47/64 loss: 1.74246346950531
Batch 48/64 loss: 1.7393577098846436
Batch 49/64 loss: 1.7491905689239502
Batch 50/64 loss: 1.7366724014282227
Batch 51/64 loss: 1.740401029586792
Batch 52/64 loss: 1.7516388893127441
Batch 53/64 loss: 1.7438480854034424
Batch 54/64 loss: 1.7483744621276855
Batch 55/64 loss: 1.7413166761398315
Batch 56/64 loss: 1.7458431720733643
Batch 57/64 loss: 1.7468867301940918
Batch 58/64 loss: 1.7432665824890137
Batch 59/64 loss: 1.7418808937072754
Batch 60/64 loss: 1.7405225038528442
Batch 61/64 loss: 1.7409641742706299
Batch 62/64 loss: 1.7535130977630615
Batch 63/64 loss: 1.7421625852584839
Batch 64/64 loss: 1.9317868947982788
Epoch 228  Train loss: 1.746301615939421  Val loss: 1.7632324089299363
Epoch 229
-------------------------------
Batch 1/64 loss: 1.747255563735962
Batch 2/64 loss: 1.7426180839538574
Batch 3/64 loss: 1.7473260164260864
Batch 4/64 loss: 1.7435595989227295
Batch 5/64 loss: 1.7421462535858154
Batch 6/64 loss: 1.7468576431274414
Batch 7/64 loss: 1.748664379119873
Batch 8/64 loss: 1.7420434951782227
Batch 9/64 loss: 1.7586461305618286
Batch 10/64 loss: 1.7662829160690308
Batch 11/64 loss: 1.7517364025115967
Batch 12/64 loss: 1.764129877090454
Batch 13/64 loss: 1.7493960857391357
Batch 14/64 loss: 1.746870994567871
Batch 15/64 loss: 1.7500165700912476
Batch 16/64 loss: 1.7436635494232178
Batch 17/64 loss: 1.7422404289245605
Batch 18/64 loss: 1.7490572929382324
Batch 19/64 loss: 1.7466771602630615
Batch 20/64 loss: 1.7487766742706299
Batch 21/64 loss: 1.7417387962341309
Batch 22/64 loss: 1.7468593120574951
Batch 23/64 loss: 1.7480463981628418
Batch 24/64 loss: 1.739347219467163
Batch 25/64 loss: 1.7657523155212402
Batch 26/64 loss: 1.7501778602600098
Batch 27/64 loss: 1.7505238056182861
Batch 28/64 loss: 1.7495090961456299
Batch 29/64 loss: 1.7466083765029907
Batch 30/64 loss: 1.7446801662445068
Batch 31/64 loss: 1.7504600286483765
Batch 32/64 loss: 1.7460342645645142
Batch 33/64 loss: 1.757476568222046
Batch 34/64 loss: 1.7428419589996338
Batch 35/64 loss: 1.7484540939331055
Batch 36/64 loss: 1.7520489692687988
Batch 37/64 loss: 1.7618489265441895
Batch 38/64 loss: 1.7472846508026123
Batch 39/64 loss: 1.7463557720184326
Batch 40/64 loss: 1.7451918125152588
Batch 41/64 loss: 1.747399926185608
Batch 42/64 loss: 1.7445399761199951
Batch 43/64 loss: 1.7526921033859253
Batch 44/64 loss: 1.7597229480743408
Batch 45/64 loss: 1.7492907047271729
Batch 46/64 loss: 1.7569199800491333
Batch 47/64 loss: 1.745105504989624
Batch 48/64 loss: 1.746523380279541
Batch 49/64 loss: 1.750053882598877
Batch 50/64 loss: 1.7499561309814453
Batch 51/64 loss: 1.7470407485961914
Batch 52/64 loss: 1.746502161026001
Batch 53/64 loss: 1.741587519645691
Batch 54/64 loss: 1.7431447505950928
Batch 55/64 loss: 1.7545844316482544
Batch 56/64 loss: 1.7419843673706055
Batch 57/64 loss: 1.7423396110534668
Batch 58/64 loss: 1.7439119815826416
Batch 59/64 loss: 1.7444802522659302
Batch 60/64 loss: 1.7447240352630615
Batch 61/64 loss: 1.744182825088501
Batch 62/64 loss: 1.7432971000671387
Batch 63/64 loss: 1.7480089664459229
Batch 64/64 loss: 1.9325543642044067
Epoch 229  Train loss: 1.7505351305007935  Val loss: 1.762409537928211
Epoch 230
-------------------------------
Batch 1/64 loss: 1.7427117824554443
Batch 2/64 loss: 1.745237112045288
Batch 3/64 loss: 1.7496237754821777
Batch 4/64 loss: 1.7463421821594238
Batch 5/64 loss: 1.7441236972808838
Batch 6/64 loss: 1.7428984642028809
Batch 7/64 loss: 1.743227481842041
Batch 8/64 loss: 1.7514092922210693
Batch 9/64 loss: 1.7398085594177246
Batch 10/64 loss: 1.7439424991607666
Batch 11/64 loss: 1.7427875995635986
Batch 12/64 loss: 1.7550606727600098
Batch 13/64 loss: 1.7610440254211426
Batch 14/64 loss: 1.7450597286224365
Batch 15/64 loss: 1.7388198375701904
Batch 16/64 loss: 1.7415249347686768
Batch 17/64 loss: 1.7614459991455078
Batch 18/64 loss: 1.760634183883667
Batch 19/64 loss: 1.7436907291412354
Batch 20/64 loss: 1.7446789741516113
Batch 21/64 loss: 1.743696689605713
Batch 22/64 loss: 1.7433768510818481
Batch 23/64 loss: 1.7456207275390625
Batch 24/64 loss: 1.741581678390503
Batch 25/64 loss: 1.7433416843414307
Batch 26/64 loss: 1.7390062808990479
Batch 27/64 loss: 1.7421965599060059
Batch 28/64 loss: 1.7536202669143677
Batch 29/64 loss: 1.750420093536377
Batch 30/64 loss: 1.7412571907043457
Batch 31/64 loss: 1.7413095235824585
Batch 32/64 loss: 1.738691806793213
Batch 33/64 loss: 1.7437362670898438
Batch 34/64 loss: 1.7446908950805664
Batch 35/64 loss: 1.7406728267669678
Batch 36/64 loss: 1.7393202781677246
Batch 37/64 loss: 1.7395081520080566
Batch 38/64 loss: 1.7395797967910767
Batch 39/64 loss: 1.7452914714813232
Batch 40/64 loss: 1.7408509254455566
Batch 41/64 loss: 1.742577075958252
Batch 42/64 loss: 1.7372379302978516
Batch 43/64 loss: 1.739243745803833
Batch 44/64 loss: 1.7390774488449097
Batch 45/64 loss: 1.7383636236190796
Batch 46/64 loss: 1.7390711307525635
Batch 47/64 loss: 1.750243902206421
Batch 48/64 loss: 1.7429653406143188
Batch 49/64 loss: 1.7433772087097168
Batch 50/64 loss: 1.7374308109283447
Batch 51/64 loss: 1.7376518249511719
Batch 52/64 loss: 1.744443655014038
Batch 53/64 loss: 1.7417935132980347
Batch 54/64 loss: 1.7450177669525146
Batch 55/64 loss: 1.739976167678833
Batch 56/64 loss: 1.7464749813079834
Batch 57/64 loss: 1.7492952346801758
Batch 58/64 loss: 1.737189531326294
Batch 59/64 loss: 1.7421929836273193
Batch 60/64 loss: 1.7388942241668701
Batch 61/64 loss: 1.7499799728393555
Batch 62/64 loss: 1.737868070602417
Batch 63/64 loss: 1.7410733699798584
Batch 64/64 loss: 1.9274301528930664
Epoch 230  Train loss: 1.7460212333529603  Val loss: 1.759397327285452
Epoch 231
-------------------------------
Batch 1/64 loss: 1.7447566986083984
Batch 2/64 loss: 1.7409147024154663
Batch 3/64 loss: 1.7407500743865967
Batch 4/64 loss: 1.7477517127990723
Batch 5/64 loss: 1.740494728088379
Batch 6/64 loss: 1.7436003684997559
Batch 7/64 loss: 1.7464429140090942
Batch 8/64 loss: 1.7402064800262451
Batch 9/64 loss: 1.7409682273864746
Batch 10/64 loss: 1.7403501272201538
Batch 11/64 loss: 1.7425243854522705
Batch 12/64 loss: 1.7379281520843506
Batch 13/64 loss: 1.7402675151824951
Batch 14/64 loss: 1.7426220178604126
Batch 15/64 loss: 1.7518858909606934
Batch 16/64 loss: 1.742477297782898
Batch 17/64 loss: 1.7423408031463623
Batch 18/64 loss: 1.7446203231811523
Batch 19/64 loss: 1.7422873973846436
Batch 20/64 loss: 1.7412075996398926
Batch 21/64 loss: 1.7404448986053467
Batch 22/64 loss: 1.7432726621627808
Batch 23/64 loss: 1.7419068813323975
Batch 24/64 loss: 1.7435357570648193
Batch 25/64 loss: 1.743520736694336
Batch 26/64 loss: 1.7389731407165527
Batch 27/64 loss: 1.7579503059387207
Batch 28/64 loss: 1.7573680877685547
Batch 29/64 loss: 1.7386020421981812
Batch 30/64 loss: 1.73895263671875
Batch 31/64 loss: 1.7412829399108887
Batch 32/64 loss: 1.7442083358764648
Batch 33/64 loss: 1.7407199144363403
Batch 34/64 loss: 1.7418386936187744
Batch 35/64 loss: 1.7400941848754883
Batch 36/64 loss: 1.7449429035186768
Batch 37/64 loss: 1.7428946495056152
Batch 38/64 loss: 1.741174340248108
Batch 39/64 loss: 1.7383668422698975
Batch 40/64 loss: 1.7466926574707031
Batch 41/64 loss: 1.7407907247543335
Batch 42/64 loss: 1.7426766157150269
Batch 43/64 loss: 1.739560842514038
Batch 44/64 loss: 1.7496466636657715
Batch 45/64 loss: 1.738828420639038
Batch 46/64 loss: 1.744588017463684
Batch 47/64 loss: 1.7420178651809692
Batch 48/64 loss: 1.7391893863677979
Batch 49/64 loss: 1.7400083541870117
Batch 50/64 loss: 1.7414156198501587
Batch 51/64 loss: 1.7473220825195312
Batch 52/64 loss: 1.7414603233337402
Batch 53/64 loss: 1.739914059638977
Batch 54/64 loss: 1.7417874336242676
Batch 55/64 loss: 1.7424019575119019
Batch 56/64 loss: 1.742459774017334
Batch 57/64 loss: 1.742803931236267
Batch 58/64 loss: 1.7397801876068115
Batch 59/64 loss: 1.7421224117279053
Batch 60/64 loss: 1.739286184310913
Batch 61/64 loss: 1.7372751235961914
Batch 62/64 loss: 1.7400681972503662
Batch 63/64 loss: 1.739490032196045
Batch 64/64 loss: 1.9278185367584229
Epoch 231  Train loss: 1.7446572257023232  Val loss: 1.759130440217113
Epoch 232
-------------------------------
Batch 1/64 loss: 1.7444897890090942
Batch 2/64 loss: 1.7442046403884888
Batch 3/64 loss: 1.738242506980896
Batch 4/64 loss: 1.7405645847320557
Batch 5/64 loss: 1.7427868843078613
Batch 6/64 loss: 1.7407456636428833
Batch 7/64 loss: 1.7384434938430786
Batch 8/64 loss: 1.7394893169403076
Batch 9/64 loss: 1.7424802780151367
Batch 10/64 loss: 1.7393736839294434
Batch 11/64 loss: 1.7397305965423584
Batch 12/64 loss: 1.743138313293457
Batch 13/64 loss: 1.736748218536377
Batch 14/64 loss: 1.7490599155426025
Batch 15/64 loss: 1.7416412830352783
Batch 16/64 loss: 1.7396135330200195
Batch 17/64 loss: 1.737326741218567
Batch 18/64 loss: 1.738627314567566
Batch 19/64 loss: 1.7364237308502197
Batch 20/64 loss: 1.7361247539520264
Batch 21/64 loss: 1.7393603324890137
Batch 22/64 loss: 1.7367982864379883
Batch 23/64 loss: 1.7422444820404053
Batch 24/64 loss: 1.7369396686553955
Batch 25/64 loss: 1.7540009021759033
Batch 26/64 loss: 1.7393970489501953
Batch 27/64 loss: 1.739664077758789
Batch 28/64 loss: 1.7416064739227295
Batch 29/64 loss: 1.7425153255462646
Batch 30/64 loss: 1.7424945831298828
Batch 31/64 loss: 1.7376463413238525
Batch 32/64 loss: 1.7397406101226807
Batch 33/64 loss: 1.7389394044876099
Batch 34/64 loss: 1.7423691749572754
Batch 35/64 loss: 1.7383441925048828
Batch 36/64 loss: 1.7387588024139404
Batch 37/64 loss: 1.7478667497634888
Batch 38/64 loss: 1.7394845485687256
Batch 39/64 loss: 1.7384047508239746
Batch 40/64 loss: 1.7383049726486206
Batch 41/64 loss: 1.7475416660308838
Batch 42/64 loss: 1.7371050119400024
Batch 43/64 loss: 1.7382501363754272
Batch 44/64 loss: 1.7368426322937012
Batch 45/64 loss: 1.7421834468841553
Batch 46/64 loss: 1.7405802011489868
Batch 47/64 loss: 1.7357826232910156
Batch 48/64 loss: 1.7380125522613525
Batch 49/64 loss: 1.7558990716934204
Batch 50/64 loss: 1.7358952760696411
Batch 51/64 loss: 1.7382606267929077
Batch 52/64 loss: 1.7407522201538086
Batch 53/64 loss: 1.7362695932388306
Batch 54/64 loss: 1.7404851913452148
Batch 55/64 loss: 1.7358384132385254
Batch 56/64 loss: 1.7465145587921143
Batch 57/64 loss: 1.7385852336883545
Batch 58/64 loss: 1.7364145517349243
Batch 59/64 loss: 1.7399412393569946
Batch 60/64 loss: 1.7356927394866943
Batch 61/64 loss: 1.741448163986206
Batch 62/64 loss: 1.7460238933563232
Batch 63/64 loss: 1.7362350225448608
Batch 64/64 loss: 1.9235031604766846
Epoch 232  Train loss: 1.7425461554059796  Val loss: 1.757379002587492
Epoch 233
-------------------------------
Batch 1/64 loss: 1.7387464046478271
Batch 2/64 loss: 1.7381565570831299
Batch 3/64 loss: 1.7389841079711914
Batch 4/64 loss: 1.741131067276001
Batch 5/64 loss: 1.7386322021484375
Batch 6/64 loss: 1.7361023426055908
Batch 7/64 loss: 1.740708351135254
Batch 8/64 loss: 1.7449617385864258
Batch 9/64 loss: 1.736814260482788
Batch 10/64 loss: 1.7373136281967163
Batch 11/64 loss: 1.7378127574920654
Batch 12/64 loss: 1.7417058944702148
Batch 13/64 loss: 1.7377229928970337
Batch 14/64 loss: 1.7370080947875977
Batch 15/64 loss: 1.7376676797866821
Batch 16/64 loss: 1.739802598953247
Batch 17/64 loss: 1.7385475635528564
Batch 18/64 loss: 1.7393978834152222
Batch 19/64 loss: 1.738893747329712
Batch 20/64 loss: 1.7372989654541016
Batch 21/64 loss: 1.7379491329193115
Batch 22/64 loss: 1.7353107929229736
Batch 23/64 loss: 1.7579841613769531
Batch 24/64 loss: 1.7372492551803589
Batch 25/64 loss: 1.7362234592437744
Batch 26/64 loss: 1.7353624105453491
Batch 27/64 loss: 1.7331745624542236
Batch 28/64 loss: 1.736560344696045
Batch 29/64 loss: 1.7378466129302979
Batch 30/64 loss: 1.7344276905059814
Batch 31/64 loss: 1.739834189414978
Batch 32/64 loss: 1.7338447570800781
Batch 33/64 loss: 1.7354979515075684
Batch 34/64 loss: 1.7376000881195068
Batch 35/64 loss: 1.7375259399414062
Batch 36/64 loss: 1.7496025562286377
Batch 37/64 loss: 1.736968755722046
Batch 38/64 loss: 1.7371010780334473
Batch 39/64 loss: 1.7409788370132446
Batch 40/64 loss: 1.7371766567230225
Batch 41/64 loss: 1.739195704460144
Batch 42/64 loss: 1.7380321025848389
Batch 43/64 loss: 1.734763264656067
Batch 44/64 loss: 1.734201431274414
Batch 45/64 loss: 1.7356162071228027
Batch 46/64 loss: 1.7385691404342651
Batch 47/64 loss: 1.745772361755371
Batch 48/64 loss: 1.734655737876892
Batch 49/64 loss: 1.7363817691802979
Batch 50/64 loss: 1.7376357316970825
Batch 51/64 loss: 1.7368576526641846
Batch 52/64 loss: 1.7360022068023682
Batch 53/64 loss: 1.7344746589660645
Batch 54/64 loss: 1.7373547554016113
Batch 55/64 loss: 1.7423845529556274
Batch 56/64 loss: 1.7543516159057617
Batch 57/64 loss: 1.7391201257705688
Batch 58/64 loss: 1.7370613813400269
Batch 59/64 loss: 1.7334181070327759
Batch 60/64 loss: 1.7387601137161255
Batch 61/64 loss: 1.7367511987686157
Batch 62/64 loss: 1.7352931499481201
Batch 63/64 loss: 1.7440650463104248
Batch 64/64 loss: 1.921944499015808
Epoch 233  Train loss: 1.7406714425367467  Val loss: 1.7590800626171414
Epoch 234
-------------------------------
Batch 1/64 loss: 1.7386701107025146
Batch 2/64 loss: 1.7398093938827515
Batch 3/64 loss: 1.7348235845565796
Batch 4/64 loss: 1.7359330654144287
Batch 5/64 loss: 1.736661434173584
Batch 6/64 loss: 1.7359877824783325
Batch 7/64 loss: 1.7344613075256348
Batch 8/64 loss: 1.7366920709609985
Batch 9/64 loss: 1.7410393953323364
Batch 10/64 loss: 1.738016963005066
Batch 11/64 loss: 1.7323553562164307
Batch 12/64 loss: 1.737165927886963
Batch 13/64 loss: 1.7511708736419678
Batch 14/64 loss: 1.7408108711242676
Batch 15/64 loss: 1.7358733415603638
Batch 16/64 loss: 1.7394598722457886
Batch 17/64 loss: 1.7394639253616333
Batch 18/64 loss: 1.7336281538009644
Batch 19/64 loss: 1.7419235706329346
Batch 20/64 loss: 1.750241994857788
Batch 21/64 loss: 1.7332589626312256
Batch 22/64 loss: 1.7530686855316162
Batch 23/64 loss: 1.744292140007019
Batch 24/64 loss: 1.7411863803863525
Batch 25/64 loss: 1.7371549606323242
Batch 26/64 loss: 1.737465262413025
Batch 27/64 loss: 1.739844799041748
Batch 28/64 loss: 1.7398990392684937
Batch 29/64 loss: 1.7375755310058594
Batch 30/64 loss: 1.7390556335449219
Batch 31/64 loss: 1.7338016033172607
Batch 32/64 loss: 1.7397212982177734
Batch 33/64 loss: 1.7397541999816895
Batch 34/64 loss: 1.7366564273834229
Batch 35/64 loss: 1.7409350872039795
Batch 36/64 loss: 1.7385077476501465
Batch 37/64 loss: 1.737898826599121
Batch 38/64 loss: 1.7423088550567627
Batch 39/64 loss: 1.7419848442077637
Batch 40/64 loss: 1.7376258373260498
Batch 41/64 loss: 1.7397921085357666
Batch 42/64 loss: 1.7416915893554688
Batch 43/64 loss: 1.7443007230758667
Batch 44/64 loss: 1.7413866519927979
Batch 45/64 loss: 1.750657558441162
Batch 46/64 loss: 1.7405097484588623
Batch 47/64 loss: 1.7478480339050293
Batch 48/64 loss: 1.7446643114089966
Batch 49/64 loss: 1.7456550598144531
Batch 50/64 loss: 1.7414027452468872
Batch 51/64 loss: 1.7399263381958008
Batch 52/64 loss: 1.7465925216674805
Batch 53/64 loss: 1.745761513710022
Batch 54/64 loss: 1.7408053874969482
Batch 55/64 loss: 1.7396048307418823
Batch 56/64 loss: 1.737734317779541
Batch 57/64 loss: 1.745952844619751
Batch 58/64 loss: 1.743617057800293
Batch 59/64 loss: 1.7397847175598145
Batch 60/64 loss: 1.7392535209655762
Batch 61/64 loss: 1.7474421262741089
Batch 62/64 loss: 1.7393629550933838
Batch 63/64 loss: 1.7417622804641724
Batch 64/64 loss: 1.951997995376587
Epoch 234  Train loss: 1.7429912557788925  Val loss: 1.7635422686940616
Epoch 235
-------------------------------
Batch 1/64 loss: 1.7413098812103271
Batch 2/64 loss: 1.742018461227417
Batch 3/64 loss: 1.7397446632385254
Batch 4/64 loss: 1.7413811683654785
Batch 5/64 loss: 1.738415241241455
Batch 6/64 loss: 1.7376153469085693
Batch 7/64 loss: 1.7373164892196655
Batch 8/64 loss: 1.7394604682922363
Batch 9/64 loss: 1.736579418182373
Batch 10/64 loss: 1.737210988998413
Batch 11/64 loss: 1.7389709949493408
Batch 12/64 loss: 1.742729902267456
Batch 13/64 loss: 1.741133451461792
Batch 14/64 loss: 1.7383465766906738
Batch 15/64 loss: 1.7611987590789795
Batch 16/64 loss: 1.7348301410675049
Batch 17/64 loss: 1.7370855808258057
Batch 18/64 loss: 1.7363394498825073
Batch 19/64 loss: 1.7437810897827148
Batch 20/64 loss: 1.7437753677368164
Batch 21/64 loss: 1.7405025959014893
Batch 22/64 loss: 1.7416982650756836
Batch 23/64 loss: 1.7411293983459473
Batch 24/64 loss: 1.735410451889038
Batch 25/64 loss: 1.736238718032837
Batch 26/64 loss: 1.737523078918457
Batch 27/64 loss: 1.743323564529419
Batch 28/64 loss: 1.735626459121704
Batch 29/64 loss: 1.7359131574630737
Batch 30/64 loss: 1.737093210220337
Batch 31/64 loss: 1.7365667819976807
Batch 32/64 loss: 1.7361805438995361
Batch 33/64 loss: 1.7363324165344238
Batch 34/64 loss: 1.7368005514144897
Batch 35/64 loss: 1.735980749130249
Batch 36/64 loss: 1.7375037670135498
Batch 37/64 loss: 1.7361037731170654
Batch 38/64 loss: 1.7361640930175781
Batch 39/64 loss: 1.7485859394073486
Batch 40/64 loss: 1.7377160787582397
Batch 41/64 loss: 1.7358827590942383
Batch 42/64 loss: 1.7362828254699707
Batch 43/64 loss: 1.735316276550293
Batch 44/64 loss: 1.7353236675262451
Batch 45/64 loss: 1.751059889793396
Batch 46/64 loss: 1.7351408004760742
Batch 47/64 loss: 1.7381830215454102
Batch 48/64 loss: 1.7412667274475098
Batch 49/64 loss: 1.7400625944137573
Batch 50/64 loss: 1.73469877243042
Batch 51/64 loss: 1.7356444597244263
Batch 52/64 loss: 1.7352442741394043
Batch 53/64 loss: 1.735316276550293
Batch 54/64 loss: 1.7358217239379883
Batch 55/64 loss: 1.7409520149230957
Batch 56/64 loss: 1.7418413162231445
Batch 57/64 loss: 1.7444854974746704
Batch 58/64 loss: 1.7345740795135498
Batch 59/64 loss: 1.7375707626342773
Batch 60/64 loss: 1.7475998401641846
Batch 61/64 loss: 1.7414696216583252
Batch 62/64 loss: 1.73700749874115
Batch 63/64 loss: 1.736083745956421
Batch 64/64 loss: 1.9209315776824951
Epoch 235  Train loss: 1.7411633594363343  Val loss: 1.7555086284978283
Saving best model, epoch: 235
Epoch 236
-------------------------------
Batch 1/64 loss: 1.7343316078186035
Batch 2/64 loss: 1.742617130279541
Batch 3/64 loss: 1.7389787435531616
Batch 4/64 loss: 1.748504638671875
Batch 5/64 loss: 1.7388505935668945
Batch 6/64 loss: 1.7500081062316895
Batch 7/64 loss: 1.7396788597106934
Batch 8/64 loss: 1.7398173809051514
Batch 9/64 loss: 1.7386442422866821
Batch 10/64 loss: 1.7415798902511597
Batch 11/64 loss: 1.7405588626861572
Batch 12/64 loss: 1.7373454570770264
Batch 13/64 loss: 1.741031289100647
Batch 14/64 loss: 1.7401435375213623
Batch 15/64 loss: 1.745814323425293
Batch 16/64 loss: 1.7381105422973633
Batch 17/64 loss: 1.741105079650879
Batch 18/64 loss: 1.738340139389038
Batch 19/64 loss: 1.743217945098877
Batch 20/64 loss: 1.7385069131851196
Batch 21/64 loss: 1.7395819425582886
Batch 22/64 loss: 1.7457960844039917
Batch 23/64 loss: 1.7621362209320068
Batch 24/64 loss: 1.738579273223877
Batch 25/64 loss: 1.7423475980758667
Batch 26/64 loss: 1.7461020946502686
Batch 27/64 loss: 1.7408435344696045
Batch 28/64 loss: 1.7355140447616577
Batch 29/64 loss: 1.7399804592132568
Batch 30/64 loss: 1.73605477809906
Batch 31/64 loss: 1.7386326789855957
Batch 32/64 loss: 1.7340507507324219
Batch 33/64 loss: 1.7389518022537231
Batch 34/64 loss: 1.7390427589416504
Batch 35/64 loss: 1.735332727432251
Batch 36/64 loss: 1.7450352907180786
Batch 37/64 loss: 1.7358877658843994
Batch 38/64 loss: 1.7385764122009277
Batch 39/64 loss: 1.7368414402008057
Batch 40/64 loss: 1.7405831813812256
Batch 41/64 loss: 1.738901138305664
Batch 42/64 loss: 1.7372112274169922
Batch 43/64 loss: 1.7392361164093018
Batch 44/64 loss: 1.738438367843628
Batch 45/64 loss: 1.7418166399002075
Batch 46/64 loss: 1.7414495944976807
Batch 47/64 loss: 1.7372971773147583
Batch 48/64 loss: 1.7388687133789062
Batch 49/64 loss: 1.7373764514923096
Batch 50/64 loss: 1.7399680614471436
Batch 51/64 loss: 1.7385847568511963
Batch 52/64 loss: 1.7544386386871338
Batch 53/64 loss: 1.736054539680481
Batch 54/64 loss: 1.7397191524505615
Batch 55/64 loss: 1.7345240116119385
Batch 56/64 loss: 1.736236810684204
Batch 57/64 loss: 1.7344071865081787
Batch 58/64 loss: 1.735870122909546
Batch 59/64 loss: 1.7354683876037598
Batch 60/64 loss: 1.7375068664550781
Batch 61/64 loss: 1.7339366674423218
Batch 62/64 loss: 1.738529920578003
Batch 63/64 loss: 1.7380797863006592
Batch 64/64 loss: 1.9233137369155884
Epoch 236  Train loss: 1.7420150864358042  Val loss: 1.7558620443049164
Epoch 237
-------------------------------
Batch 1/64 loss: 1.7377454042434692
Batch 2/64 loss: 1.7395012378692627
Batch 3/64 loss: 1.739123821258545
Batch 4/64 loss: 1.7409749031066895
Batch 5/64 loss: 1.7394540309906006
Batch 6/64 loss: 1.7351651191711426
Batch 7/64 loss: 1.7368626594543457
Batch 8/64 loss: 1.7348958253860474
Batch 9/64 loss: 1.7356846332550049
Batch 10/64 loss: 1.7361441850662231
Batch 11/64 loss: 1.7347702980041504
Batch 12/64 loss: 1.736453652381897
Batch 13/64 loss: 1.7370017766952515
Batch 14/64 loss: 1.734281063079834
Batch 15/64 loss: 1.735619306564331
Batch 16/64 loss: 1.7329843044281006
Batch 17/64 loss: 1.736265778541565
Batch 18/64 loss: 1.7357397079467773
Batch 19/64 loss: 1.7390339374542236
Batch 20/64 loss: 1.7387887239456177
Batch 21/64 loss: 1.7344374656677246
Batch 22/64 loss: 1.737245798110962
Batch 23/64 loss: 1.7497646808624268
Batch 24/64 loss: 1.7361955642700195
Batch 25/64 loss: 1.7433733940124512
Batch 26/64 loss: 1.7418334484100342
Batch 27/64 loss: 1.7355272769927979
Batch 28/64 loss: 1.742123007774353
Batch 29/64 loss: 1.739781141281128
Batch 30/64 loss: 1.735133409500122
Batch 31/64 loss: 1.7539639472961426
Batch 32/64 loss: 1.7393898963928223
Batch 33/64 loss: 1.7349969148635864
Batch 34/64 loss: 1.736220121383667
Batch 35/64 loss: 1.7371292114257812
Batch 36/64 loss: 1.7378000020980835
Batch 37/64 loss: 1.7370649576187134
Batch 38/64 loss: 1.7361788749694824
Batch 39/64 loss: 1.737437129020691
Batch 40/64 loss: 1.7379757165908813
Batch 41/64 loss: 1.73539137840271
Batch 42/64 loss: 1.734238862991333
Batch 43/64 loss: 1.7358043193817139
Batch 44/64 loss: 1.7369086742401123
Batch 45/64 loss: 1.7360947132110596
Batch 46/64 loss: 1.735349178314209
Batch 47/64 loss: 1.7361249923706055
Batch 48/64 loss: 1.7344022989273071
Batch 49/64 loss: 1.7395856380462646
Batch 50/64 loss: 1.7363452911376953
Batch 51/64 loss: 1.7362875938415527
Batch 52/64 loss: 1.7371728420257568
Batch 53/64 loss: 1.7374814748764038
Batch 54/64 loss: 1.7355386018753052
Batch 55/64 loss: 1.7514113187789917
Batch 56/64 loss: 1.736796259880066
Batch 57/64 loss: 1.7397522926330566
Batch 58/64 loss: 1.7336524724960327
Batch 59/64 loss: 1.7368640899658203
Batch 60/64 loss: 1.7333213090896606
Batch 61/64 loss: 1.7386796474456787
Batch 62/64 loss: 1.7359681129455566
Batch 63/64 loss: 1.7511862516403198
Batch 64/64 loss: 1.9199388027191162
Epoch 237  Train loss: 1.7399901810814353  Val loss: 1.756040944266565
Epoch 238
-------------------------------
Batch 1/64 loss: 1.7426366806030273
Batch 2/64 loss: 1.7337639331817627
Batch 3/64 loss: 1.737617015838623
Batch 4/64 loss: 1.7371714115142822
Batch 5/64 loss: 1.7380213737487793
Batch 6/64 loss: 1.7444300651550293
Batch 7/64 loss: 1.736267328262329
Batch 8/64 loss: 1.734290599822998
Batch 9/64 loss: 1.7582929134368896
Batch 10/64 loss: 1.7374590635299683
Batch 11/64 loss: 1.7444636821746826
Batch 12/64 loss: 1.735853672027588
Batch 13/64 loss: 1.740925908088684
Batch 14/64 loss: 1.743168592453003
Batch 15/64 loss: 1.7366505861282349
Batch 16/64 loss: 1.7421774864196777
Batch 17/64 loss: 1.7381680011749268
Batch 18/64 loss: 1.7358877658843994
Batch 19/64 loss: 1.7369632720947266
Batch 20/64 loss: 1.7364568710327148
Batch 21/64 loss: 1.7383618354797363
Batch 22/64 loss: 1.738746166229248
Batch 23/64 loss: 1.7365244626998901
Batch 24/64 loss: 1.7405357360839844
Batch 25/64 loss: 1.7371418476104736
Batch 26/64 loss: 1.7349584102630615
Batch 27/64 loss: 1.734529733657837
Batch 28/64 loss: 1.7368412017822266
Batch 29/64 loss: 1.7421667575836182
Batch 30/64 loss: 1.7385902404785156
Batch 31/64 loss: 1.7358956336975098
Batch 32/64 loss: 1.7347569465637207
Batch 33/64 loss: 1.7375569343566895
Batch 34/64 loss: 1.7393262386322021
Batch 35/64 loss: 1.7349088191986084
Batch 36/64 loss: 1.7444920539855957
Batch 37/64 loss: 1.7364946603775024
Batch 38/64 loss: 1.7390100955963135
Batch 39/64 loss: 1.7368321418762207
Batch 40/64 loss: 1.7387864589691162
Batch 41/64 loss: 1.7373019456863403
Batch 42/64 loss: 1.738558053970337
Batch 43/64 loss: 1.738541841506958
Batch 44/64 loss: 1.751451015472412
Batch 45/64 loss: 1.736675500869751
Batch 46/64 loss: 1.7468866109848022
Batch 47/64 loss: 1.736302375793457
Batch 48/64 loss: 1.747390627861023
Batch 49/64 loss: 1.738012671470642
Batch 50/64 loss: 1.735242486000061
Batch 51/64 loss: 1.7359611988067627
Batch 52/64 loss: 1.7396433353424072
Batch 53/64 loss: 1.7406666278839111
Batch 54/64 loss: 1.7395063638687134
Batch 55/64 loss: 1.7371933460235596
Batch 56/64 loss: 1.7367794513702393
Batch 57/64 loss: 1.7388584613800049
Batch 58/64 loss: 1.734230637550354
Batch 59/64 loss: 1.7384920120239258
Batch 60/64 loss: 1.742290735244751
Batch 61/64 loss: 1.7421953678131104
Batch 62/64 loss: 1.7370579242706299
Batch 63/64 loss: 1.737899661064148
Batch 64/64 loss: 1.9273271560668945
Epoch 238  Train loss: 1.7411726465412214  Val loss: 1.7558143532153256
Epoch 239
-------------------------------
Batch 1/64 loss: 1.7376596927642822
Batch 2/64 loss: 1.7362875938415527
Batch 3/64 loss: 1.736512541770935
Batch 4/64 loss: 1.7397719621658325
Batch 5/64 loss: 1.7356882095336914
Batch 6/64 loss: 1.738473653793335
Batch 7/64 loss: 1.746055006980896
Batch 8/64 loss: 1.7456028461456299
Batch 9/64 loss: 1.7372338771820068
Batch 10/64 loss: 1.754384994506836
Batch 11/64 loss: 1.7427089214324951
Batch 12/64 loss: 1.7497117519378662
Batch 13/64 loss: 1.7454462051391602
Batch 14/64 loss: 1.737444519996643
Batch 15/64 loss: 1.7397962808609009
Batch 16/64 loss: 1.7360196113586426
Batch 17/64 loss: 1.7394359111785889
Batch 18/64 loss: 1.7408517599105835
Batch 19/64 loss: 1.736337423324585
Batch 20/64 loss: 1.741071343421936
Batch 21/64 loss: 1.735195517539978
Batch 22/64 loss: 1.741233229637146
Batch 23/64 loss: 1.7430295944213867
Batch 24/64 loss: 1.737731695175171
Batch 25/64 loss: 1.7424845695495605
Batch 26/64 loss: 1.7414370775222778
Batch 27/64 loss: 1.7490572929382324
Batch 28/64 loss: 1.7474323511123657
Batch 29/64 loss: 1.740309238433838
Batch 30/64 loss: 1.7397346496582031
Batch 31/64 loss: 1.740319013595581
Batch 32/64 loss: 1.740797996520996
Batch 33/64 loss: 1.7382888793945312
Batch 34/64 loss: 1.7370555400848389
Batch 35/64 loss: 1.7392594814300537
Batch 36/64 loss: 1.7386815547943115
Batch 37/64 loss: 1.7436890602111816
Batch 38/64 loss: 1.7400379180908203
Batch 39/64 loss: 1.7361119985580444
Batch 40/64 loss: 1.7381770610809326
Batch 41/64 loss: 1.739875078201294
Batch 42/64 loss: 1.7359981536865234
Batch 43/64 loss: 1.7394521236419678
Batch 44/64 loss: 1.7403388023376465
Batch 45/64 loss: 1.740088701248169
Batch 46/64 loss: 1.7530769109725952
Batch 47/64 loss: 1.7388694286346436
Batch 48/64 loss: 1.7329061031341553
Batch 49/64 loss: 1.7401584386825562
Batch 50/64 loss: 1.7354121208190918
Batch 51/64 loss: 1.7368137836456299
Batch 52/64 loss: 1.7372616529464722
Batch 53/64 loss: 1.7348880767822266
Batch 54/64 loss: 1.7376348972320557
Batch 55/64 loss: 1.7368850708007812
Batch 56/64 loss: 1.7373712062835693
Batch 57/64 loss: 1.7357721328735352
Batch 58/64 loss: 1.7402613162994385
Batch 59/64 loss: 1.7365716695785522
Batch 60/64 loss: 1.7364890575408936
Batch 61/64 loss: 1.735996127128601
Batch 62/64 loss: 1.7349814176559448
Batch 63/64 loss: 1.7362487316131592
Batch 64/64 loss: 1.9265499114990234
Epoch 239  Train loss: 1.7418795492134842  Val loss: 1.7554187463321227
Saving best model, epoch: 239
Epoch 240
-------------------------------
Batch 1/64 loss: 1.7379810810089111
Batch 2/64 loss: 1.754854440689087
Batch 3/64 loss: 1.7374098300933838
Batch 4/64 loss: 1.7349610328674316
Batch 5/64 loss: 1.738723874092102
Batch 6/64 loss: 1.737534761428833
Batch 7/64 loss: 1.7359083890914917
Batch 8/64 loss: 1.7365036010742188
Batch 9/64 loss: 1.734670639038086
Batch 10/64 loss: 1.7362825870513916
Batch 11/64 loss: 1.7368108034133911
Batch 12/64 loss: 1.7340104579925537
Batch 13/64 loss: 1.7318739891052246
Batch 14/64 loss: 1.7374622821807861
Batch 15/64 loss: 1.7360763549804688
Batch 16/64 loss: 1.742478609085083
Batch 17/64 loss: 1.7356257438659668
Batch 18/64 loss: 1.7344634532928467
Batch 19/64 loss: 1.7365880012512207
Batch 20/64 loss: 1.7345943450927734
Batch 21/64 loss: 1.738508701324463
Batch 22/64 loss: 1.7351391315460205
Batch 23/64 loss: 1.737973928451538
Batch 24/64 loss: 1.7343469858169556
Batch 25/64 loss: 1.738282561302185
Batch 26/64 loss: 1.7378833293914795
Batch 27/64 loss: 1.7397432327270508
Batch 28/64 loss: 1.7395493984222412
Batch 29/64 loss: 1.7355140447616577
Batch 30/64 loss: 1.7363200187683105
Batch 31/64 loss: 1.738588571548462
Batch 32/64 loss: 1.7375376224517822
Batch 33/64 loss: 1.7386059761047363
Batch 34/64 loss: 1.741060733795166
Batch 35/64 loss: 1.7357325553894043
Batch 36/64 loss: 1.737921953201294
Batch 37/64 loss: 1.7408108711242676
Batch 38/64 loss: 1.738898754119873
Batch 39/64 loss: 1.739600419998169
Batch 40/64 loss: 1.7386393547058105
Batch 41/64 loss: 1.7370703220367432
Batch 42/64 loss: 1.7363154888153076
Batch 43/64 loss: 1.746083378791809
Batch 44/64 loss: 1.7370645999908447
Batch 45/64 loss: 1.7433931827545166
Batch 46/64 loss: 1.7426903247833252
Batch 47/64 loss: 1.7380056381225586
Batch 48/64 loss: 1.7398006916046143
Batch 49/64 loss: 1.740272045135498
Batch 50/64 loss: 1.7385077476501465
Batch 51/64 loss: 1.7375891208648682
Batch 52/64 loss: 1.7438883781433105
Batch 53/64 loss: 1.746958613395691
Batch 54/64 loss: 1.7361356019973755
Batch 55/64 loss: 1.739858865737915
Batch 56/64 loss: 1.7378158569335938
Batch 57/64 loss: 1.736839771270752
Batch 58/64 loss: 1.7410967350006104
Batch 59/64 loss: 1.7519927024841309
Batch 60/64 loss: 1.7399845123291016
Batch 61/64 loss: 1.7364284992218018
Batch 62/64 loss: 1.7403876781463623
Batch 63/64 loss: 1.737231969833374
Batch 64/64 loss: 1.9449853897094727
Epoch 240  Train loss: 1.7410136970819212  Val loss: 1.7539375614874142
Saving best model, epoch: 240
Epoch 241
-------------------------------
Batch 1/64 loss: 1.7355122566223145
Batch 2/64 loss: 1.7382047176361084
Batch 3/64 loss: 1.7347290515899658
Batch 4/64 loss: 1.7392405271530151
Batch 5/64 loss: 1.7370054721832275
Batch 6/64 loss: 1.7416659593582153
Batch 7/64 loss: 1.735276699066162
Batch 8/64 loss: 1.7368626594543457
Batch 9/64 loss: 1.7350709438323975
Batch 10/64 loss: 1.7376809120178223
Batch 11/64 loss: 1.7386163473129272
Batch 12/64 loss: 1.7374153137207031
Batch 13/64 loss: 1.7349894046783447
Batch 14/64 loss: 1.7357666492462158
Batch 15/64 loss: 1.73447585105896
Batch 16/64 loss: 1.7359886169433594
Batch 17/64 loss: 1.739275574684143
Batch 18/64 loss: 1.7353595495224
Batch 19/64 loss: 1.7398016452789307
Batch 20/64 loss: 1.7372584342956543
Batch 21/64 loss: 1.7351977825164795
Batch 22/64 loss: 1.755036473274231
Batch 23/64 loss: 1.732585072517395
Batch 24/64 loss: 1.7338677644729614
Batch 25/64 loss: 1.7357127666473389
Batch 26/64 loss: 1.736295461654663
Batch 27/64 loss: 1.736863613128662
Batch 28/64 loss: 1.7373303174972534
Batch 29/64 loss: 1.735189437866211
Batch 30/64 loss: 1.7366955280303955
Batch 31/64 loss: 1.7367064952850342
Batch 32/64 loss: 1.738768458366394
Batch 33/64 loss: 1.739243745803833
Batch 34/64 loss: 1.7350082397460938
Batch 35/64 loss: 1.7366766929626465
Batch 36/64 loss: 1.741815209388733
Batch 37/64 loss: 1.7378439903259277
Batch 38/64 loss: 1.7347018718719482
Batch 39/64 loss: 1.7345013618469238
Batch 40/64 loss: 1.7363173961639404
Batch 41/64 loss: 1.734864592552185
Batch 42/64 loss: 1.7417806386947632
Batch 43/64 loss: 1.732649326324463
Batch 44/64 loss: 1.741356372833252
Batch 45/64 loss: 1.7344133853912354
Batch 46/64 loss: 1.7390373945236206
Batch 47/64 loss: 1.7444396018981934
Batch 48/64 loss: 1.7356951236724854
Batch 49/64 loss: 1.7356014251708984
Batch 50/64 loss: 1.7366435527801514
Batch 51/64 loss: 1.7361656427383423
Batch 52/64 loss: 1.7369086742401123
Batch 53/64 loss: 1.7358274459838867
Batch 54/64 loss: 1.7518928050994873
Batch 55/64 loss: 1.7348496913909912
Batch 56/64 loss: 1.7371814250946045
Batch 57/64 loss: 1.749755859375
Batch 58/64 loss: 1.7355021238327026
Batch 59/64 loss: 1.743117094039917
Batch 60/64 loss: 1.7336256504058838
Batch 61/64 loss: 1.7338461875915527
Batch 62/64 loss: 1.7357845306396484
Batch 63/64 loss: 1.7330151796340942
Batch 64/64 loss: 1.9219400882720947
Epoch 241  Train loss: 1.739638636158962  Val loss: 1.7532972208003408
Saving best model, epoch: 241
Epoch 242
-------------------------------
Batch 1/64 loss: 1.735628604888916
Batch 2/64 loss: 1.7350817918777466
Batch 3/64 loss: 1.739028811454773
Batch 4/64 loss: 1.7357627153396606
Batch 5/64 loss: 1.736643671989441
Batch 6/64 loss: 1.7327133417129517
Batch 7/64 loss: 1.7368754148483276
Batch 8/64 loss: 1.7317627668380737
Batch 9/64 loss: 1.750643253326416
Batch 10/64 loss: 1.7337334156036377
Batch 11/64 loss: 1.7339651584625244
Batch 12/64 loss: 1.7379555702209473
Batch 13/64 loss: 1.7384848594665527
Batch 14/64 loss: 1.7478034496307373
Batch 15/64 loss: 1.7452845573425293
Batch 16/64 loss: 1.7413854598999023
Batch 17/64 loss: 1.738584041595459
Batch 18/64 loss: 1.736156940460205
Batch 19/64 loss: 1.737602710723877
Batch 20/64 loss: 1.7415566444396973
Batch 21/64 loss: 1.7424378395080566
Batch 22/64 loss: 1.748945713043213
Batch 23/64 loss: 1.7422771453857422
Batch 24/64 loss: 1.7447041273117065
Batch 25/64 loss: 1.7409180402755737
Batch 26/64 loss: 1.7490720748901367
Batch 27/64 loss: 1.740748405456543
Batch 28/64 loss: 1.7422813177108765
Batch 29/64 loss: 1.741553783416748
Batch 30/64 loss: 1.7398247718811035
Batch 31/64 loss: 1.7445439100265503
Batch 32/64 loss: 1.7395801544189453
Batch 33/64 loss: 1.7386232614517212
Batch 34/64 loss: 1.7370364665985107
Batch 35/64 loss: 1.7456984519958496
Batch 36/64 loss: 1.7478727102279663
Batch 37/64 loss: 1.7414512634277344
Batch 38/64 loss: 1.7457730770111084
Batch 39/64 loss: 1.7402920722961426
Batch 40/64 loss: 1.7417763471603394
Batch 41/64 loss: 1.7424836158752441
Batch 42/64 loss: 1.7400846481323242
Batch 43/64 loss: 1.7451781034469604
Batch 44/64 loss: 1.7420305013656616
Batch 45/64 loss: 1.74168062210083
Batch 46/64 loss: 1.7477898597717285
Batch 47/64 loss: 1.74617600440979
Batch 48/64 loss: 1.7439453601837158
Batch 49/64 loss: 1.7649388313293457
Batch 50/64 loss: 1.7385244369506836
Batch 51/64 loss: 1.7422431707382202
Batch 52/64 loss: 1.7403926849365234
Batch 53/64 loss: 1.7406060695648193
Batch 54/64 loss: 1.7447905540466309
Batch 55/64 loss: 1.7442197799682617
Batch 56/64 loss: 1.7428853511810303
Batch 57/64 loss: 1.7456190586090088
Batch 58/64 loss: 1.7610559463500977
Batch 59/64 loss: 1.7407615184783936
Batch 60/64 loss: 1.7453641891479492
Batch 61/64 loss: 1.749772548675537
Batch 62/64 loss: 1.7474383115768433
Batch 63/64 loss: 1.7506623268127441
Batch 64/64 loss: 1.927210807800293
Epoch 242  Train loss: 1.74456652099011  Val loss: 1.7689140645908736
Epoch 243
-------------------------------
Batch 1/64 loss: 1.7454426288604736
Batch 2/64 loss: 1.7462831735610962
Batch 3/64 loss: 1.7438576221466064
Batch 4/64 loss: 1.7457962036132812
Batch 5/64 loss: 1.7452678680419922
Batch 6/64 loss: 1.7413841485977173
Batch 7/64 loss: 1.7506823539733887
Batch 8/64 loss: 1.7457959651947021
Batch 9/64 loss: 1.7485476732254028
Batch 10/64 loss: 1.7390084266662598
Batch 11/64 loss: 1.7395830154418945
Batch 12/64 loss: 1.741269588470459
Batch 13/64 loss: 1.7577452659606934
Batch 14/64 loss: 1.7406871318817139
Batch 15/64 loss: 1.740935206413269
Batch 16/64 loss: 1.7391871213912964
Batch 17/64 loss: 1.7406883239746094
Batch 18/64 loss: 1.7423396110534668
Batch 19/64 loss: 1.7440931797027588
Batch 20/64 loss: 1.736057162284851
Batch 21/64 loss: 1.7377355098724365
Batch 22/64 loss: 1.7437663078308105
Batch 23/64 loss: 1.7459917068481445
Batch 24/64 loss: 1.7407249212265015
Batch 25/64 loss: 1.7434368133544922
Batch 26/64 loss: 1.7503900527954102
Batch 27/64 loss: 1.7379298210144043
Batch 28/64 loss: 1.7449722290039062
Batch 29/64 loss: 1.7401360273361206
Batch 30/64 loss: 1.7494938373565674
Batch 31/64 loss: 1.7395893335342407
Batch 32/64 loss: 1.7536256313323975
Batch 33/64 loss: 1.7450377941131592
Batch 34/64 loss: 1.7398433685302734
Batch 35/64 loss: 1.7439650297164917
Batch 36/64 loss: 1.739011287689209
Batch 37/64 loss: 1.7374870777130127
Batch 38/64 loss: 1.747553825378418
Batch 39/64 loss: 1.7382831573486328
Batch 40/64 loss: 1.7380189895629883
Batch 41/64 loss: 1.7412958145141602
Batch 42/64 loss: 1.7374671697616577
Batch 43/64 loss: 1.7408943176269531
Batch 44/64 loss: 1.7607475519180298
Batch 45/64 loss: 1.741560459136963
Batch 46/64 loss: 1.7398290634155273
Batch 47/64 loss: 1.7416774034500122
Batch 48/64 loss: 1.7371551990509033
Batch 49/64 loss: 1.7370493412017822
Batch 50/64 loss: 1.740147352218628
Batch 51/64 loss: 1.7402498722076416
Batch 52/64 loss: 1.740743637084961
Batch 53/64 loss: 1.7431620359420776
Batch 54/64 loss: 1.7423334121704102
Batch 55/64 loss: 1.7426178455352783
Batch 56/64 loss: 1.7375950813293457
Batch 57/64 loss: 1.740649700164795
Batch 58/64 loss: 1.7369922399520874
Batch 59/64 loss: 1.7384271621704102
Batch 60/64 loss: 1.7401888370513916
Batch 61/64 loss: 1.7421151399612427
Batch 62/64 loss: 1.7445123195648193
Batch 63/64 loss: 1.7401623725891113
Batch 64/64 loss: 1.9283251762390137
Epoch 243  Train loss: 1.7447131231719373  Val loss: 1.7615898884448808
Epoch 244
-------------------------------
Batch 1/64 loss: 1.7413842678070068
Batch 2/64 loss: 1.7577570676803589
Batch 3/64 loss: 1.7374706268310547
Batch 4/64 loss: 1.7417869567871094
Batch 5/64 loss: 1.7422757148742676
Batch 6/64 loss: 1.7425869703292847
Batch 7/64 loss: 1.7399952411651611
Batch 8/64 loss: 1.740405559539795
Batch 9/64 loss: 1.7454792261123657
Batch 10/64 loss: 1.7415766716003418
Batch 11/64 loss: 1.738099217414856
Batch 12/64 loss: 1.7497916221618652
Batch 13/64 loss: 1.7429027557373047
Batch 14/64 loss: 1.742480993270874
Batch 15/64 loss: 1.7367053031921387
Batch 16/64 loss: 1.7357311248779297
Batch 17/64 loss: 1.7417657375335693
Batch 18/64 loss: 1.7362728118896484
Batch 19/64 loss: 1.7368913888931274
Batch 20/64 loss: 1.745978832244873
Batch 21/64 loss: 1.7405915260314941
Batch 22/64 loss: 1.741753101348877
Batch 23/64 loss: 1.7365384101867676
Batch 24/64 loss: 1.7403275966644287
Batch 25/64 loss: 1.7452492713928223
Batch 26/64 loss: 1.7586069107055664
Batch 27/64 loss: 1.742722749710083
Batch 28/64 loss: 1.7419967651367188
Batch 29/64 loss: 1.7444381713867188
Batch 30/64 loss: 1.7420772314071655
Batch 31/64 loss: 1.7407746315002441
Batch 32/64 loss: 1.7401907444000244
Batch 33/64 loss: 1.7452406883239746
Batch 34/64 loss: 1.7403353452682495
Batch 35/64 loss: 1.7377078533172607
Batch 36/64 loss: 1.739692211151123
Batch 37/64 loss: 1.763375997543335
Batch 38/64 loss: 1.7475614547729492
Batch 39/64 loss: 1.7419726848602295
Batch 40/64 loss: 1.7447956800460815
Batch 41/64 loss: 1.742587685585022
Batch 42/64 loss: 1.7388806343078613
Batch 43/64 loss: 1.74881911277771
Batch 44/64 loss: 1.7448821067810059
Batch 45/64 loss: 1.7422685623168945
Batch 46/64 loss: 1.7410587072372437
Batch 47/64 loss: 1.7407840490341187
Batch 48/64 loss: 1.7441332340240479
Batch 49/64 loss: 1.7499756813049316
Batch 50/64 loss: 1.7425053119659424
Batch 51/64 loss: 1.7388379573822021
Batch 52/64 loss: 1.744189739227295
Batch 53/64 loss: 1.7413029670715332
Batch 54/64 loss: 1.742537021636963
Batch 55/64 loss: 1.7417676448822021
Batch 56/64 loss: 1.7454416751861572
Batch 57/64 loss: 1.7461378574371338
Batch 58/64 loss: 1.746436595916748
Batch 59/64 loss: 1.7398319244384766
Batch 60/64 loss: 1.7405229806900024
Batch 61/64 loss: 1.7441730499267578
Batch 62/64 loss: 1.7413251399993896
Batch 63/64 loss: 1.7405414581298828
Batch 64/64 loss: 1.9312236309051514
Epoch 244  Train loss: 1.7451081715378107  Val loss: 1.7588102719218461
Epoch 245
-------------------------------
Batch 1/64 loss: 1.739532232284546
Batch 2/64 loss: 1.7558157444000244
Batch 3/64 loss: 1.7363746166229248
Batch 4/64 loss: 1.7455253601074219
Batch 5/64 loss: 1.7380356788635254
Batch 6/64 loss: 1.74616277217865
Batch 7/64 loss: 1.7387897968292236
Batch 8/64 loss: 1.7514418363571167
Batch 9/64 loss: 1.7423614263534546
Batch 10/64 loss: 1.7376147508621216
Batch 11/64 loss: 1.743265151977539
Batch 12/64 loss: 1.7372673749923706
Batch 13/64 loss: 1.7446348667144775
Batch 14/64 loss: 1.7416589260101318
Batch 15/64 loss: 1.7395914793014526
Batch 16/64 loss: 1.736903190612793
Batch 17/64 loss: 1.7405097484588623
Batch 18/64 loss: 1.7380207777023315
Batch 19/64 loss: 1.7365543842315674
Batch 20/64 loss: 1.7403355836868286
Batch 21/64 loss: 1.7341091632843018
Batch 22/64 loss: 1.743133306503296
Batch 23/64 loss: 1.740813970565796
Batch 24/64 loss: 1.7404470443725586
Batch 25/64 loss: 1.739362359046936
Batch 26/64 loss: 1.737919807434082
Batch 27/64 loss: 1.7398701906204224
Batch 28/64 loss: 1.7388949394226074
Batch 29/64 loss: 1.7360036373138428
Batch 30/64 loss: 1.7398852109909058
Batch 31/64 loss: 1.7472412586212158
Batch 32/64 loss: 1.7385210990905762
Batch 33/64 loss: 1.7402836084365845
Batch 34/64 loss: 1.741034746170044
Batch 35/64 loss: 1.7376904487609863
Batch 36/64 loss: 1.7385023832321167
Batch 37/64 loss: 1.736856460571289
Batch 38/64 loss: 1.7383408546447754
Batch 39/64 loss: 1.7368981838226318
Batch 40/64 loss: 1.760849952697754
Batch 41/64 loss: 1.7360236644744873
Batch 42/64 loss: 1.7360494136810303
Batch 43/64 loss: 1.738559603691101
Batch 44/64 loss: 1.7377665042877197
Batch 45/64 loss: 1.739316463470459
Batch 46/64 loss: 1.7337849140167236
Batch 47/64 loss: 1.7358850240707397
Batch 48/64 loss: 1.735610008239746
Batch 49/64 loss: 1.7366580963134766
Batch 50/64 loss: 1.7400587797164917
Batch 51/64 loss: 1.743379831314087
Batch 52/64 loss: 1.7385056018829346
Batch 53/64 loss: 1.7373018264770508
Batch 54/64 loss: 1.736191987991333
Batch 55/64 loss: 1.7382981777191162
Batch 56/64 loss: 1.7385352849960327
Batch 57/64 loss: 1.7355397939682007
Batch 58/64 loss: 1.7398288249969482
Batch 59/64 loss: 1.7378618717193604
Batch 60/64 loss: 1.7385354042053223
Batch 61/64 loss: 1.738905429840088
Batch 62/64 loss: 1.7429313659667969
Batch 63/64 loss: 1.7392607927322388
Batch 64/64 loss: 1.9202380180358887
Epoch 245  Train loss: 1.741992494171741  Val loss: 1.7560599538468824
Epoch 246
-------------------------------
Batch 1/64 loss: 1.7405548095703125
Batch 2/64 loss: 1.7353266477584839
Batch 3/64 loss: 1.7371265888214111
Batch 4/64 loss: 1.736678123474121
Batch 5/64 loss: 1.736342430114746
Batch 6/64 loss: 1.7374149560928345
Batch 7/64 loss: 1.7398912906646729
Batch 8/64 loss: 1.7392396926879883
Batch 9/64 loss: 1.7386335134506226
Batch 10/64 loss: 1.7373507022857666
Batch 11/64 loss: 1.741753101348877
Batch 12/64 loss: 1.736120581626892
Batch 13/64 loss: 1.738495111465454
Batch 14/64 loss: 1.7342712879180908
Batch 15/64 loss: 1.7366511821746826
Batch 16/64 loss: 1.7472093105316162
Batch 17/64 loss: 1.739563226699829
Batch 18/64 loss: 1.740666151046753
Batch 19/64 loss: 1.738795280456543
Batch 20/64 loss: 1.747774362564087
Batch 21/64 loss: 1.7403857707977295
Batch 22/64 loss: 1.7553768157958984
Batch 23/64 loss: 1.7383840084075928
Batch 24/64 loss: 1.7576444149017334
Batch 25/64 loss: 1.7422988414764404
Batch 26/64 loss: 1.7442408800125122
Batch 27/64 loss: 1.7468031644821167
Batch 28/64 loss: 1.743912696838379
Batch 29/64 loss: 1.7387919425964355
Batch 30/64 loss: 1.7391146421432495
Batch 31/64 loss: 1.738247036933899
Batch 32/64 loss: 1.7419321537017822
Batch 33/64 loss: 1.7378900051116943
Batch 34/64 loss: 1.752289056777954
Batch 35/64 loss: 1.741228461265564
Batch 36/64 loss: 1.7386361360549927
Batch 37/64 loss: 1.738580584526062
Batch 38/64 loss: 1.7418417930603027
Batch 39/64 loss: 1.7368710041046143
Batch 40/64 loss: 1.7430016994476318
Batch 41/64 loss: 1.7383756637573242
Batch 42/64 loss: 1.740088939666748
Batch 43/64 loss: 1.7373237609863281
Batch 44/64 loss: 1.7355384826660156
Batch 45/64 loss: 1.7356576919555664
Batch 46/64 loss: 1.7357277870178223
Batch 47/64 loss: 1.736635684967041
Batch 48/64 loss: 1.7366199493408203
Batch 49/64 loss: 1.734218716621399
Batch 50/64 loss: 1.7509441375732422
Batch 51/64 loss: 1.7333898544311523
Batch 52/64 loss: 1.739929437637329
Batch 53/64 loss: 1.7346622943878174
Batch 54/64 loss: 1.7477936744689941
Batch 55/64 loss: 1.7385952472686768
Batch 56/64 loss: 1.7399706840515137
Batch 57/64 loss: 1.7366770505905151
Batch 58/64 loss: 1.7396644353866577
Batch 59/64 loss: 1.735937237739563
Batch 60/64 loss: 1.7382354736328125
Batch 61/64 loss: 1.7400870323181152
Batch 62/64 loss: 1.7362008094787598
Batch 63/64 loss: 1.7413276433944702
Batch 64/64 loss: 1.9264020919799805
Epoch 246  Train loss: 1.7422075720394359  Val loss: 1.7595467395389204
Epoch 247
-------------------------------
Batch 1/64 loss: 1.7386000156402588
Batch 2/64 loss: 1.7397241592407227
Batch 3/64 loss: 1.7392714023590088
Batch 4/64 loss: 1.7573679685592651
Batch 5/64 loss: 1.7360831499099731
Batch 6/64 loss: 1.7391433715820312
Batch 7/64 loss: 1.73823881149292
Batch 8/64 loss: 1.7425565719604492
Batch 9/64 loss: 1.739694356918335
Batch 10/64 loss: 1.7523648738861084
Batch 11/64 loss: 1.739056944847107
Batch 12/64 loss: 1.735806941986084
Batch 13/64 loss: 1.7364449501037598
Batch 14/64 loss: 1.7427167892456055
Batch 15/64 loss: 1.7371015548706055
Batch 16/64 loss: 1.7461802959442139
Batch 17/64 loss: 1.737830400466919
Batch 18/64 loss: 1.7372370958328247
Batch 19/64 loss: 1.7544074058532715
Batch 20/64 loss: 1.7399638891220093
Batch 21/64 loss: 1.7422997951507568
Batch 22/64 loss: 1.73832368850708
Batch 23/64 loss: 1.7416050434112549
Batch 24/64 loss: 1.7416746616363525
Batch 25/64 loss: 1.7377161979675293
Batch 26/64 loss: 1.74370276927948
Batch 27/64 loss: 1.73598051071167
Batch 28/64 loss: 1.7392663955688477
Batch 29/64 loss: 1.7410229444503784
Batch 30/64 loss: 1.7427990436553955
Batch 31/64 loss: 1.7470664978027344
Batch 32/64 loss: 1.7430927753448486
Batch 33/64 loss: 1.741804838180542
Batch 34/64 loss: 1.7371270656585693
Batch 35/64 loss: 1.7407286167144775
Batch 36/64 loss: 1.7375898361206055
Batch 37/64 loss: 1.7410173416137695
Batch 38/64 loss: 1.738990306854248
Batch 39/64 loss: 1.7383708953857422
Batch 40/64 loss: 1.7381986379623413
Batch 41/64 loss: 1.7352473735809326
Batch 42/64 loss: 1.7372231483459473
Batch 43/64 loss: 1.7330113649368286
Batch 44/64 loss: 1.7409658432006836
Batch 45/64 loss: 1.7363187074661255
Batch 46/64 loss: 1.7376738786697388
Batch 47/64 loss: 1.7347068786621094
Batch 48/64 loss: 1.7325173616409302
Batch 49/64 loss: 1.736661434173584
Batch 50/64 loss: 1.7346470355987549
Batch 51/64 loss: 1.7374114990234375
Batch 52/64 loss: 1.7420989274978638
Batch 53/64 loss: 1.7359085083007812
Batch 54/64 loss: 1.7428197860717773
Batch 55/64 loss: 1.7444498538970947
Batch 56/64 loss: 1.7367939949035645
Batch 57/64 loss: 1.7370846271514893
Batch 58/64 loss: 1.738944411277771
Batch 59/64 loss: 1.7351493835449219
Batch 60/64 loss: 1.7371015548706055
Batch 61/64 loss: 1.7382879257202148
Batch 62/64 loss: 1.7363489866256714
Batch 63/64 loss: 1.751021146774292
Batch 64/64 loss: 1.926121711730957
Epoch 247  Train loss: 1.7420416270985324  Val loss: 1.7557493075472383
Epoch 248
-------------------------------
Batch 1/64 loss: 1.7354919910430908
Batch 2/64 loss: 1.735649585723877
Batch 3/64 loss: 1.740434169769287
Batch 4/64 loss: 1.7405712604522705
Batch 5/64 loss: 1.7387571334838867
Batch 6/64 loss: 1.735645055770874
Batch 7/64 loss: 1.7372491359710693
Batch 8/64 loss: 1.7386267185211182
Batch 9/64 loss: 1.744189739227295
Batch 10/64 loss: 1.7396306991577148
Batch 11/64 loss: 1.7391183376312256
Batch 12/64 loss: 1.7398765087127686
Batch 13/64 loss: 1.741586446762085
Batch 14/64 loss: 1.7470345497131348
Batch 15/64 loss: 1.740987777709961
Batch 16/64 loss: 1.7556746006011963
Batch 17/64 loss: 1.739288330078125
Batch 18/64 loss: 1.737992286682129
Batch 19/64 loss: 1.7400457859039307
Batch 20/64 loss: 1.7481427192687988
Batch 21/64 loss: 1.737451195716858
Batch 22/64 loss: 1.7374248504638672
Batch 23/64 loss: 1.7434262037277222
Batch 24/64 loss: 1.7398139238357544
Batch 25/64 loss: 1.7371253967285156
Batch 26/64 loss: 1.738492727279663
Batch 27/64 loss: 1.7393672466278076
Batch 28/64 loss: 1.7338612079620361
Batch 29/64 loss: 1.738093376159668
Batch 30/64 loss: 1.7355698347091675
Batch 31/64 loss: 1.7411965131759644
Batch 32/64 loss: 1.736863613128662
Batch 33/64 loss: 1.738966703414917
Batch 34/64 loss: 1.7347760200500488
Batch 35/64 loss: 1.739343285560608
Batch 36/64 loss: 1.7397958040237427
Batch 37/64 loss: 1.738979458808899
Batch 38/64 loss: 1.7382594347000122
Batch 39/64 loss: 1.7468700408935547
Batch 40/64 loss: 1.737549901008606
Batch 41/64 loss: 1.7330811023712158
Batch 42/64 loss: 1.7373011112213135
Batch 43/64 loss: 1.7347440719604492
Batch 44/64 loss: 1.7390711307525635
Batch 45/64 loss: 1.7358500957489014
Batch 46/64 loss: 1.7419533729553223
Batch 47/64 loss: 1.7489991188049316
Batch 48/64 loss: 1.7358274459838867
Batch 49/64 loss: 1.7359492778778076
Batch 50/64 loss: 1.7390131950378418
Batch 51/64 loss: 1.7405576705932617
Batch 52/64 loss: 1.734687089920044
Batch 53/64 loss: 1.7334654331207275
Batch 54/64 loss: 1.7378716468811035
Batch 55/64 loss: 1.7360382080078125
Batch 56/64 loss: 1.7352988719940186
Batch 57/64 loss: 1.7367591857910156
Batch 58/64 loss: 1.7324681282043457
Batch 59/64 loss: 1.7351531982421875
Batch 60/64 loss: 1.7371907234191895
Batch 61/64 loss: 1.7343610525131226
Batch 62/64 loss: 1.735421895980835
Batch 63/64 loss: 1.7355090379714966
Batch 64/64 loss: 1.9490333795547485
Epoch 248  Train loss: 1.741138300708696  Val loss: 1.7570095922529083
Epoch 249
-------------------------------
Batch 1/64 loss: 1.7574772834777832
Batch 2/64 loss: 1.7375932931900024
Batch 3/64 loss: 1.735708236694336
Batch 4/64 loss: 1.736772060394287
Batch 5/64 loss: 1.7369129657745361
Batch 6/64 loss: 1.7344810962677002
Batch 7/64 loss: 1.7368769645690918
Batch 8/64 loss: 1.737375020980835
Batch 9/64 loss: 1.739796757698059
Batch 10/64 loss: 1.7343313694000244
Batch 11/64 loss: 1.737268090248108
Batch 12/64 loss: 1.7322239875793457
Batch 13/64 loss: 1.7391740083694458
Batch 14/64 loss: 1.7334833145141602
Batch 15/64 loss: 1.7325341701507568
Batch 16/64 loss: 1.7343733310699463
Batch 17/64 loss: 1.7379820346832275
Batch 18/64 loss: 1.7377426624298096
Batch 19/64 loss: 1.7426072359085083
Batch 20/64 loss: 1.7366623878479004
Batch 21/64 loss: 1.735954999923706
Batch 22/64 loss: 1.734114170074463
Batch 23/64 loss: 1.7372627258300781
Batch 24/64 loss: 1.7344374656677246
Batch 25/64 loss: 1.738425612449646
Batch 26/64 loss: 1.7363393306732178
Batch 27/64 loss: 1.740078330039978
Batch 28/64 loss: 1.735304594039917
Batch 29/64 loss: 1.7382354736328125
Batch 30/64 loss: 1.7392055988311768
Batch 31/64 loss: 1.7356749773025513
Batch 32/64 loss: 1.7363030910491943
Batch 33/64 loss: 1.7336252927780151
Batch 34/64 loss: 1.7377216815948486
Batch 35/64 loss: 1.7362112998962402
Batch 36/64 loss: 1.733041524887085
Batch 37/64 loss: 1.7321200370788574
Batch 38/64 loss: 1.7413716316223145
Batch 39/64 loss: 1.7359514236450195
Batch 40/64 loss: 1.734757900238037
Batch 41/64 loss: 1.7382292747497559
Batch 42/64 loss: 1.7349162101745605
Batch 43/64 loss: 1.7356956005096436
Batch 44/64 loss: 1.7385700941085815
Batch 45/64 loss: 1.7456576824188232
Batch 46/64 loss: 1.7337768077850342
Batch 47/64 loss: 1.7337725162506104
Batch 48/64 loss: 1.7346608638763428
Batch 49/64 loss: 1.7338228225708008
Batch 50/64 loss: 1.7334601879119873
Batch 51/64 loss: 1.731152892112732
Batch 52/64 loss: 1.736628770828247
Batch 53/64 loss: 1.7318949699401855
Batch 54/64 loss: 1.7330483198165894
Batch 55/64 loss: 1.749500036239624
Batch 56/64 loss: 1.7354730367660522
Batch 57/64 loss: 1.7374908924102783
Batch 58/64 loss: 1.7474855184555054
Batch 59/64 loss: 1.7336807250976562
Batch 60/64 loss: 1.7366926670074463
Batch 61/64 loss: 1.7367899417877197
Batch 62/64 loss: 1.7436981201171875
Batch 63/64 loss: 1.7346158027648926
Batch 64/64 loss: 1.9217780828475952
Epoch 249  Train loss: 1.7391303646798226  Val loss: 1.7571831224710261
Epoch 250
-------------------------------
Batch 1/64 loss: 1.736013412475586
Batch 2/64 loss: 1.740260124206543
Batch 3/64 loss: 1.7538155317306519
Batch 4/64 loss: 1.734919786453247
Batch 5/64 loss: 1.74088716506958
Batch 6/64 loss: 1.7514528036117554
Batch 7/64 loss: 1.736522912979126
Batch 8/64 loss: 1.7379717826843262
Batch 9/64 loss: 1.7389742136001587
Batch 10/64 loss: 1.7360289096832275
Batch 11/64 loss: 1.7386667728424072
Batch 12/64 loss: 1.7345657348632812
Batch 13/64 loss: 1.7348377704620361
Batch 14/64 loss: 1.733837604522705
Batch 15/64 loss: 1.738214373588562
Batch 16/64 loss: 1.7413933277130127
Batch 17/64 loss: 1.7334108352661133
Batch 18/64 loss: 1.7351908683776855
Batch 19/64 loss: 1.7369292974472046
Batch 20/64 loss: 1.7376757860183716
Batch 21/64 loss: 1.7370706796646118
Batch 22/64 loss: 1.735736608505249
Batch 23/64 loss: 1.7333934307098389
Batch 24/64 loss: 1.7347266674041748
Batch 25/64 loss: 1.735627293586731
Batch 26/64 loss: 1.7320146560668945
Batch 27/64 loss: 1.7354345321655273
Batch 28/64 loss: 1.7345151901245117
Batch 29/64 loss: 1.7380245923995972
Batch 30/64 loss: 1.7361061573028564
Batch 31/64 loss: 1.7345550060272217
Batch 32/64 loss: 1.7393380403518677
Batch 33/64 loss: 1.737196922302246
Batch 34/64 loss: 1.7332117557525635
Batch 35/64 loss: 1.7373050451278687
Batch 36/64 loss: 1.738670825958252
Batch 37/64 loss: 1.7408621311187744
Batch 38/64 loss: 1.736318588256836
Batch 39/64 loss: 1.7520109415054321
Batch 40/64 loss: 1.736161470413208
Batch 41/64 loss: 1.7393651008605957
Batch 42/64 loss: 1.7445175647735596
Batch 43/64 loss: 1.7355942726135254
Batch 44/64 loss: 1.734648585319519
Batch 45/64 loss: 1.7397944927215576
Batch 46/64 loss: 1.746167778968811
Batch 47/64 loss: 1.7406487464904785
Batch 48/64 loss: 1.7354822158813477
Batch 49/64 loss: 1.7358589172363281
Batch 50/64 loss: 1.7424712181091309
Batch 51/64 loss: 1.7390642166137695
Batch 52/64 loss: 1.7348954677581787
Batch 53/64 loss: 1.741133689880371
Batch 54/64 loss: 1.740391492843628
Batch 55/64 loss: 1.7371573448181152
Batch 56/64 loss: 1.738148808479309
Batch 57/64 loss: 1.7376599311828613
Batch 58/64 loss: 1.738288402557373
Batch 59/64 loss: 1.7378443479537964
Batch 60/64 loss: 1.750260353088379
Batch 61/64 loss: 1.738708257675171
Batch 62/64 loss: 1.7340139150619507
Batch 63/64 loss: 1.7336221933364868
Batch 64/64 loss: 1.91908860206604
Epoch 250  Train loss: 1.740312208848841  Val loss: 1.7551905371479153
Epoch 251
-------------------------------
Batch 1/64 loss: 1.7364336252212524
Batch 2/64 loss: 1.734144687652588
Batch 3/64 loss: 1.7352876663208008
Batch 4/64 loss: 1.734898567199707
Batch 5/64 loss: 1.736281394958496
Batch 6/64 loss: 1.7350841760635376
Batch 7/64 loss: 1.7349892854690552
Batch 8/64 loss: 1.7349694967269897
Batch 9/64 loss: 1.736543893814087
Batch 10/64 loss: 1.7394044399261475
Batch 11/64 loss: 1.7389042377471924
Batch 12/64 loss: 1.7392261028289795
Batch 13/64 loss: 1.7343032360076904
Batch 14/64 loss: 1.7339189052581787
Batch 15/64 loss: 1.7325446605682373
Batch 16/64 loss: 1.7369283437728882
Batch 17/64 loss: 1.745455026626587
Batch 18/64 loss: 1.7421398162841797
Batch 19/64 loss: 1.7344894409179688
Batch 20/64 loss: 1.7411463260650635
Batch 21/64 loss: 1.73567533493042
Batch 22/64 loss: 1.7412254810333252
Batch 23/64 loss: 1.7609150409698486
Batch 24/64 loss: 1.737227439880371
Batch 25/64 loss: 1.738682746887207
Batch 26/64 loss: 1.74205482006073
Batch 27/64 loss: 1.7407572269439697
Batch 28/64 loss: 1.7480645179748535
Batch 29/64 loss: 1.742742896080017
Batch 30/64 loss: 1.7367844581604004
Batch 31/64 loss: 1.748443365097046
Batch 32/64 loss: 1.7449781894683838
Batch 33/64 loss: 1.7360048294067383
Batch 34/64 loss: 1.7400004863739014
Batch 35/64 loss: 1.7419660091400146
Batch 36/64 loss: 1.7393540143966675
Batch 37/64 loss: 1.7443578243255615
Batch 38/64 loss: 1.746109962463379
Batch 39/64 loss: 1.7392326593399048
Batch 40/64 loss: 1.7391021251678467
Batch 41/64 loss: 1.7380017042160034
Batch 42/64 loss: 1.7384450435638428
Batch 43/64 loss: 1.733766794204712
Batch 44/64 loss: 1.7393795251846313
Batch 45/64 loss: 1.7407715320587158
Batch 46/64 loss: 1.734290361404419
Batch 47/64 loss: 1.7356692552566528
Batch 48/64 loss: 1.7364871501922607
Batch 49/64 loss: 1.7357876300811768
Batch 50/64 loss: 1.7390649318695068
Batch 51/64 loss: 1.7343289852142334
Batch 52/64 loss: 1.742676019668579
Batch 53/64 loss: 1.7437021732330322
Batch 54/64 loss: 1.7490776777267456
Batch 55/64 loss: 1.7376132011413574
Batch 56/64 loss: 1.7354340553283691
Batch 57/64 loss: 1.7401096820831299
Batch 58/64 loss: 1.738914966583252
Batch 59/64 loss: 1.7374730110168457
Batch 60/64 loss: 1.7386162281036377
Batch 61/64 loss: 1.735790729522705
Batch 62/64 loss: 1.7327075004577637
Batch 63/64 loss: 1.763913631439209
Batch 64/64 loss: 1.9232923984527588
Epoch 251  Train loss: 1.7415727662105187  Val loss: 1.755086318733766
Epoch 252
-------------------------------
Batch 1/64 loss: 1.7382010221481323
Batch 2/64 loss: 1.7393312454223633
Batch 3/64 loss: 1.732891321182251
Batch 4/64 loss: 1.7362382411956787
Batch 5/64 loss: 1.7448866367340088
Batch 6/64 loss: 1.7364895343780518
Batch 7/64 loss: 1.738544225692749
Batch 8/64 loss: 1.7372515201568604
Batch 9/64 loss: 1.7375400066375732
Batch 10/64 loss: 1.7386765480041504
Batch 11/64 loss: 1.733872652053833
Batch 12/64 loss: 1.7378058433532715
Batch 13/64 loss: 1.7364505529403687
Batch 14/64 loss: 1.735694169998169
Batch 15/64 loss: 1.740051031112671
Batch 16/64 loss: 1.7381033897399902
Batch 17/64 loss: 1.7384239435195923
Batch 18/64 loss: 1.7484450340270996
Batch 19/64 loss: 1.735431432723999
Batch 20/64 loss: 1.7379567623138428
Batch 21/64 loss: 1.7365086078643799
Batch 22/64 loss: 1.754583477973938
Batch 23/64 loss: 1.73613440990448
Batch 24/64 loss: 1.7399888038635254
Batch 25/64 loss: 1.7355616092681885
Batch 26/64 loss: 1.739995002746582
Batch 27/64 loss: 1.7365479469299316
Batch 28/64 loss: 1.739811897277832
Batch 29/64 loss: 1.7390856742858887
Batch 30/64 loss: 1.7366774082183838
Batch 31/64 loss: 1.7383884191513062
Batch 32/64 loss: 1.7392220497131348
Batch 33/64 loss: 1.7402105331420898
Batch 34/64 loss: 1.7374119758605957
Batch 35/64 loss: 1.7356764078140259
Batch 36/64 loss: 1.7363544702529907
Batch 37/64 loss: 1.7367947101593018
Batch 38/64 loss: 1.7354859113693237
Batch 39/64 loss: 1.7392160892486572
Batch 40/64 loss: 1.7441543340682983
Batch 41/64 loss: 1.737675666809082
Batch 42/64 loss: 1.7368390560150146
Batch 43/64 loss: 1.741666555404663
Batch 44/64 loss: 1.735461950302124
Batch 45/64 loss: 1.741881012916565
Batch 46/64 loss: 1.7388546466827393
Batch 47/64 loss: 1.736769437789917
Batch 48/64 loss: 1.735985279083252
Batch 49/64 loss: 1.7361111640930176
Batch 50/64 loss: 1.7391564846038818
Batch 51/64 loss: 1.736838698387146
Batch 52/64 loss: 1.7414960861206055
Batch 53/64 loss: 1.7541584968566895
Batch 54/64 loss: 1.73787522315979
Batch 55/64 loss: 1.740121603012085
Batch 56/64 loss: 1.7398470640182495
Batch 57/64 loss: 1.7390117645263672
Batch 58/64 loss: 1.7341313362121582
Batch 59/64 loss: 1.734527826309204
Batch 60/64 loss: 1.7399628162384033
Batch 61/64 loss: 1.7359275817871094
Batch 62/64 loss: 1.7413856983184814
Batch 63/64 loss: 1.7400527000427246
Batch 64/64 loss: 1.9238684177398682
Epoch 252  Train loss: 1.7408428912069283  Val loss: 1.7570128997986258
Epoch 253
-------------------------------
Batch 1/64 loss: 1.735802173614502
Batch 2/64 loss: 1.7369592189788818
Batch 3/64 loss: 1.7549245357513428
Batch 4/64 loss: 1.739311933517456
Batch 5/64 loss: 1.7342815399169922
Batch 6/64 loss: 1.7496576309204102
Batch 7/64 loss: 1.7402877807617188
Batch 8/64 loss: 1.7366665601730347
Batch 9/64 loss: 1.7354607582092285
Batch 10/64 loss: 1.740163803100586
Batch 11/64 loss: 1.7340643405914307
Batch 12/64 loss: 1.7379896640777588
Batch 13/64 loss: 1.736452341079712
Batch 14/64 loss: 1.7374720573425293
Batch 15/64 loss: 1.7386293411254883
Batch 16/64 loss: 1.7390556335449219
Batch 17/64 loss: 1.7379069328308105
Batch 18/64 loss: 1.738210916519165
Batch 19/64 loss: 1.7383785247802734
Batch 20/64 loss: 1.7442097663879395
Batch 21/64 loss: 1.7434654235839844
Batch 22/64 loss: 1.7385382652282715
Batch 23/64 loss: 1.7391009330749512
Batch 24/64 loss: 1.7393395900726318
Batch 25/64 loss: 1.7392022609710693
Batch 26/64 loss: 1.7385025024414062
Batch 27/64 loss: 1.7370526790618896
Batch 28/64 loss: 1.7466500997543335
Batch 29/64 loss: 1.7367745637893677
Batch 30/64 loss: 1.7344796657562256
Batch 31/64 loss: 1.7342636585235596
Batch 32/64 loss: 1.7360281944274902
Batch 33/64 loss: 1.7394030094146729
Batch 34/64 loss: 1.7317359447479248
Batch 35/64 loss: 1.7329474687576294
Batch 36/64 loss: 1.7317605018615723
Batch 37/64 loss: 1.7333874702453613
Batch 38/64 loss: 1.7333848476409912
Batch 39/64 loss: 1.7334188222885132
Batch 40/64 loss: 1.7342827320098877
Batch 41/64 loss: 1.7351160049438477
Batch 42/64 loss: 1.7365193367004395
Batch 43/64 loss: 1.733138918876648
Batch 44/64 loss: 1.7356594800949097
Batch 45/64 loss: 1.7332959175109863
Batch 46/64 loss: 1.7367355823516846
Batch 47/64 loss: 1.7386398315429688
Batch 48/64 loss: 1.732951283454895
Batch 49/64 loss: 1.736022710800171
Batch 50/64 loss: 1.736006736755371
Batch 51/64 loss: 1.736018180847168
Batch 52/64 loss: 1.73358154296875
Batch 53/64 loss: 1.7377488613128662
Batch 54/64 loss: 1.7355098724365234
Batch 55/64 loss: 1.7389137744903564
Batch 56/64 loss: 1.7347383499145508
Batch 57/64 loss: 1.7333563566207886
Batch 58/64 loss: 1.7361838817596436
Batch 59/64 loss: 1.7348312139511108
Batch 60/64 loss: 1.7396790981292725
Batch 61/64 loss: 1.7375767230987549
Batch 62/64 loss: 1.7404649257659912
Batch 63/64 loss: 1.7381134033203125
Batch 64/64 loss: 1.9202947616577148
Epoch 253  Train loss: 1.739460817972819  Val loss: 1.7527494037274234
Saving best model, epoch: 253
Epoch 254
-------------------------------
Batch 1/64 loss: 1.7330060005187988
Batch 2/64 loss: 1.737539291381836
Batch 3/64 loss: 1.73388671875
Batch 4/64 loss: 1.7508801221847534
Batch 5/64 loss: 1.734307885169983
Batch 6/64 loss: 1.7339849472045898
Batch 7/64 loss: 1.7308106422424316
Batch 8/64 loss: 1.7332520484924316
Batch 9/64 loss: 1.731539011001587
Batch 10/64 loss: 1.7368957996368408
Batch 11/64 loss: 1.7375061511993408
Batch 12/64 loss: 1.7336231470108032
Batch 13/64 loss: 1.7322975397109985
Batch 14/64 loss: 1.7370573282241821
Batch 15/64 loss: 1.744943380355835
Batch 16/64 loss: 1.7359693050384521
Batch 17/64 loss: 1.7352015972137451
Batch 18/64 loss: 1.735838770866394
Batch 19/64 loss: 1.733095645904541
Batch 20/64 loss: 1.734670639038086
Batch 21/64 loss: 1.7338199615478516
Batch 22/64 loss: 1.7374966144561768
Batch 23/64 loss: 1.733901023864746
Batch 24/64 loss: 1.7366420030593872
Batch 25/64 loss: 1.733856439590454
Batch 26/64 loss: 1.7347114086151123
Batch 27/64 loss: 1.7344965934753418
Batch 28/64 loss: 1.7328178882598877
Batch 29/64 loss: 1.734630823135376
Batch 30/64 loss: 1.7389333248138428
Batch 31/64 loss: 1.734877586364746
Batch 32/64 loss: 1.7320146560668945
Batch 33/64 loss: 1.7323071956634521
Batch 34/64 loss: 1.7324271202087402
Batch 35/64 loss: 1.7330541610717773
Batch 36/64 loss: 1.736088514328003
Batch 37/64 loss: 1.7339613437652588
Batch 38/64 loss: 1.7569454908370972
Batch 39/64 loss: 1.7335996627807617
Batch 40/64 loss: 1.7384650707244873
Batch 41/64 loss: 1.7415945529937744
Batch 42/64 loss: 1.735891580581665
Batch 43/64 loss: 1.738017201423645
Batch 44/64 loss: 1.7385003566741943
Batch 45/64 loss: 1.7347381114959717
Batch 46/64 loss: 1.7332415580749512
Batch 47/64 loss: 1.731388807296753
Batch 48/64 loss: 1.7347910404205322
Batch 49/64 loss: 1.7359644174575806
Batch 50/64 loss: 1.7344249486923218
Batch 51/64 loss: 1.732499122619629
Batch 52/64 loss: 1.7374413013458252
Batch 53/64 loss: 1.7356178760528564
Batch 54/64 loss: 1.736438274383545
Batch 55/64 loss: 1.7330126762390137
Batch 56/64 loss: 1.7410176992416382
Batch 57/64 loss: 1.7363862991333008
Batch 58/64 loss: 1.735797643661499
Batch 59/64 loss: 1.74207603931427
Batch 60/64 loss: 1.7444498538970947
Batch 61/64 loss: 1.7386345863342285
Batch 62/64 loss: 1.7379611730575562
Batch 63/64 loss: 1.7409969568252563
Batch 64/64 loss: 1.923911690711975
Epoch 254  Train loss: 1.7384340188082528  Val loss: 1.7537501964372457
Epoch 255
-------------------------------
Batch 1/64 loss: 1.7341549396514893
Batch 2/64 loss: 1.7341110706329346
Batch 3/64 loss: 1.7362335920333862
Batch 4/64 loss: 1.734400987625122
Batch 5/64 loss: 1.7362167835235596
Batch 6/64 loss: 1.7356882095336914
Batch 7/64 loss: 1.7341485023498535
Batch 8/64 loss: 1.7336039543151855
Batch 9/64 loss: 1.7340068817138672
Batch 10/64 loss: 1.7346019744873047
Batch 11/64 loss: 1.7345311641693115
Batch 12/64 loss: 1.7336345911026
Batch 13/64 loss: 1.7321455478668213
Batch 14/64 loss: 1.737865686416626
Batch 15/64 loss: 1.733850121498108
Batch 16/64 loss: 1.7344549894332886
Batch 17/64 loss: 1.736748218536377
Batch 18/64 loss: 1.7347720861434937
Batch 19/64 loss: 1.7338000535964966
Batch 20/64 loss: 1.7409062385559082
Batch 21/64 loss: 1.7338604927062988
Batch 22/64 loss: 1.7405550479888916
Batch 23/64 loss: 1.7350397109985352
Batch 24/64 loss: 1.740233302116394
Batch 25/64 loss: 1.734486699104309
Batch 26/64 loss: 1.7339279651641846
Batch 27/64 loss: 1.7371668815612793
Batch 28/64 loss: 1.737107276916504
Batch 29/64 loss: 1.732507586479187
Batch 30/64 loss: 1.7326347827911377
Batch 31/64 loss: 1.733553409576416
Batch 32/64 loss: 1.731999397277832
Batch 33/64 loss: 1.734067678451538
Batch 34/64 loss: 1.7447571754455566
Batch 35/64 loss: 1.7379828691482544
Batch 36/64 loss: 1.7342396974563599
Batch 37/64 loss: 1.7382972240447998
Batch 38/64 loss: 1.7338420152664185
Batch 39/64 loss: 1.7356765270233154
Batch 40/64 loss: 1.736419916152954
Batch 41/64 loss: 1.7471072673797607
Batch 42/64 loss: 1.7335864305496216
Batch 43/64 loss: 1.73561429977417
Batch 44/64 loss: 1.753626823425293
Batch 45/64 loss: 1.7386106252670288
Batch 46/64 loss: 1.7342274188995361
Batch 47/64 loss: 1.7361009120941162
Batch 48/64 loss: 1.7332751750946045
Batch 49/64 loss: 1.732252597808838
Batch 50/64 loss: 1.7352083921432495
Batch 51/64 loss: 1.7343608140945435
Batch 52/64 loss: 1.734783411026001
Batch 53/64 loss: 1.735081672668457
Batch 54/64 loss: 1.7330152988433838
Batch 55/64 loss: 1.7367746829986572
Batch 56/64 loss: 1.7318663597106934
Batch 57/64 loss: 1.7319896221160889
Batch 58/64 loss: 1.7379450798034668
Batch 59/64 loss: 1.7394349575042725
Batch 60/64 loss: 1.7353792190551758
Batch 61/64 loss: 1.7394680976867676
Batch 62/64 loss: 1.734114408493042
Batch 63/64 loss: 1.7476987838745117
Batch 64/64 loss: 1.9202653169631958
Epoch 255  Train loss: 1.7381953346963022  Val loss: 1.7528610835779983
Epoch 256
-------------------------------
Batch 1/64 loss: 1.7328710556030273
Batch 2/64 loss: 1.7343192100524902
Batch 3/64 loss: 1.731539011001587
Batch 4/64 loss: 1.733140468597412
Batch 5/64 loss: 1.732330322265625
Batch 6/64 loss: 1.735032558441162
Batch 7/64 loss: 1.7330681085586548
Batch 8/64 loss: 1.7348802089691162
Batch 9/64 loss: 1.7377257347106934
Batch 10/64 loss: 1.7349843978881836
Batch 11/64 loss: 1.7330479621887207
Batch 12/64 loss: 1.7336177825927734
Batch 13/64 loss: 1.7340482473373413
Batch 14/64 loss: 1.7337548732757568
Batch 15/64 loss: 1.7340648174285889
Batch 16/64 loss: 1.736320972442627
Batch 17/64 loss: 1.7336342334747314
Batch 18/64 loss: 1.7371068000793457
Batch 19/64 loss: 1.731870174407959
Batch 20/64 loss: 1.735793948173523
Batch 21/64 loss: 1.7339293956756592
Batch 22/64 loss: 1.7370175123214722
Batch 23/64 loss: 1.7343800067901611
Batch 24/64 loss: 1.743562936782837
Batch 25/64 loss: 1.734290361404419
Batch 26/64 loss: 1.7340292930603027
Batch 27/64 loss: 1.7348867654800415
Batch 28/64 loss: 1.7472922801971436
Batch 29/64 loss: 1.7334575653076172
Batch 30/64 loss: 1.7342296838760376
Batch 31/64 loss: 1.7320917844772339
Batch 32/64 loss: 1.7366591691970825
Batch 33/64 loss: 1.7361040115356445
Batch 34/64 loss: 1.736322045326233
Batch 35/64 loss: 1.7351267337799072
Batch 36/64 loss: 1.7498451471328735
Batch 37/64 loss: 1.735557198524475
Batch 38/64 loss: 1.733380675315857
Batch 39/64 loss: 1.7366950511932373
Batch 40/64 loss: 1.7561938762664795
Batch 41/64 loss: 1.737978219985962
Batch 42/64 loss: 1.7345798015594482
Batch 43/64 loss: 1.7317147254943848
Batch 44/64 loss: 1.7376327514648438
Batch 45/64 loss: 1.731194257736206
Batch 46/64 loss: 1.7322654724121094
Batch 47/64 loss: 1.7351677417755127
Batch 48/64 loss: 1.7305476665496826
Batch 49/64 loss: 1.7340123653411865
Batch 50/64 loss: 1.734778642654419
Batch 51/64 loss: 1.7334492206573486
Batch 52/64 loss: 1.734557867050171
Batch 53/64 loss: 1.7378897666931152
Batch 54/64 loss: 1.7316334247589111
Batch 55/64 loss: 1.7365528345108032
Batch 56/64 loss: 1.7336443662643433
Batch 57/64 loss: 1.7388052940368652
Batch 58/64 loss: 1.7395579814910889
Batch 59/64 loss: 1.731338620185852
Batch 60/64 loss: 1.7393114566802979
Batch 61/64 loss: 1.738959550857544
Batch 62/64 loss: 1.7362154722213745
Batch 63/64 loss: 1.7351120710372925
Batch 64/64 loss: 1.9215147495269775
Epoch 256  Train loss: 1.7378233414070279  Val loss: 1.7523925230675137
Saving best model, epoch: 256
Epoch 257
-------------------------------
Batch 1/64 loss: 1.738844871520996
Batch 2/64 loss: 1.7399115562438965
Batch 3/64 loss: 1.7387096881866455
Batch 4/64 loss: 1.7352001667022705
Batch 5/64 loss: 1.7347021102905273
Batch 6/64 loss: 1.7345104217529297
Batch 7/64 loss: 1.7342418432235718
Batch 8/64 loss: 1.7487239837646484
Batch 9/64 loss: 1.7346539497375488
Batch 10/64 loss: 1.7345941066741943
Batch 11/64 loss: 1.7350929975509644
Batch 12/64 loss: 1.7327690124511719
Batch 13/64 loss: 1.741101622581482
Batch 14/64 loss: 1.735048770904541
Batch 15/64 loss: 1.7342326641082764
Batch 16/64 loss: 1.7335679531097412
Batch 17/64 loss: 1.7394249439239502
Batch 18/64 loss: 1.735051155090332
Batch 19/64 loss: 1.7341811656951904
Batch 20/64 loss: 1.7355411052703857
Batch 21/64 loss: 1.735905647277832
Batch 22/64 loss: 1.732409954071045
Batch 23/64 loss: 1.7329546213150024
Batch 24/64 loss: 1.7376377582550049
Batch 25/64 loss: 1.7356836795806885
Batch 26/64 loss: 1.7333629131317139
Batch 27/64 loss: 1.7328693866729736
Batch 28/64 loss: 1.7342941761016846
Batch 29/64 loss: 1.7374775409698486
Batch 30/64 loss: 1.7408885955810547
Batch 31/64 loss: 1.7358155250549316
Batch 32/64 loss: 1.7364996671676636
Batch 33/64 loss: 1.7401325702667236
Batch 34/64 loss: 1.751049518585205
Batch 35/64 loss: 1.7359954118728638
Batch 36/64 loss: 1.7413833141326904
Batch 37/64 loss: 1.7396165132522583
Batch 38/64 loss: 1.7362624406814575
Batch 39/64 loss: 1.7345685958862305
Batch 40/64 loss: 1.7344170808792114
Batch 41/64 loss: 1.7561264038085938
Batch 42/64 loss: 1.7374358177185059
Batch 43/64 loss: 1.7339386940002441
Batch 44/64 loss: 1.735083818435669
Batch 45/64 loss: 1.7416126728057861
Batch 46/64 loss: 1.7340162992477417
Batch 47/64 loss: 1.7341883182525635
Batch 48/64 loss: 1.7383321523666382
Batch 49/64 loss: 1.7365550994873047
Batch 50/64 loss: 1.734176516532898
Batch 51/64 loss: 1.7403969764709473
Batch 52/64 loss: 1.7419971227645874
Batch 53/64 loss: 1.7342262268066406
Batch 54/64 loss: 1.738760232925415
Batch 55/64 loss: 1.7372369766235352
Batch 56/64 loss: 1.7376247644424438
Batch 57/64 loss: 1.7381095886230469
Batch 58/64 loss: 1.7384262084960938
Batch 59/64 loss: 1.736748218536377
Batch 60/64 loss: 1.7342979907989502
Batch 61/64 loss: 1.7366223335266113
Batch 62/64 loss: 1.7388863563537598
Batch 63/64 loss: 1.7358043193817139
Batch 64/64 loss: 1.9245936870574951
Epoch 257  Train loss: 1.7393470960504869  Val loss: 1.7571944051591801
Epoch 258
-------------------------------
Batch 1/64 loss: 1.7544023990631104
Batch 2/64 loss: 1.73704195022583
Batch 3/64 loss: 1.7331926822662354
Batch 4/64 loss: 1.734712839126587
Batch 5/64 loss: 1.732115626335144
Batch 6/64 loss: 1.7331721782684326
Batch 7/64 loss: 1.7335652112960815
Batch 8/64 loss: 1.7592291831970215
Batch 9/64 loss: 1.7376097440719604
Batch 10/64 loss: 1.7365787029266357
Batch 11/64 loss: 1.7367230653762817
Batch 12/64 loss: 1.7390296459197998
Batch 13/64 loss: 1.736846685409546
Batch 14/64 loss: 1.7399437427520752
Batch 15/64 loss: 1.7387399673461914
Batch 16/64 loss: 1.7399611473083496
Batch 17/64 loss: 1.7340636253356934
Batch 18/64 loss: 1.7501773834228516
Batch 19/64 loss: 1.738734483718872
Batch 20/64 loss: 1.739046573638916
Batch 21/64 loss: 1.7374639511108398
Batch 22/64 loss: 1.7349414825439453
Batch 23/64 loss: 1.7343071699142456
Batch 24/64 loss: 1.7365752458572388
Batch 25/64 loss: 1.7390258312225342
Batch 26/64 loss: 1.7355210781097412
Batch 27/64 loss: 1.738745927810669
Batch 28/64 loss: 1.7398533821105957
Batch 29/64 loss: 1.7363171577453613
Batch 30/64 loss: 1.7370792627334595
Batch 31/64 loss: 1.7416138648986816
Batch 32/64 loss: 1.7403037548065186
Batch 33/64 loss: 1.7531650066375732
Batch 34/64 loss: 1.7390685081481934
Batch 35/64 loss: 1.737757921218872
Batch 36/64 loss: 1.7405214309692383
Batch 37/64 loss: 1.7377548217773438
Batch 38/64 loss: 1.7403569221496582
Batch 39/64 loss: 1.7395787239074707
Batch 40/64 loss: 1.7379426956176758
Batch 41/64 loss: 1.7413034439086914
Batch 42/64 loss: 1.7418501377105713
Batch 43/64 loss: 1.738016128540039
Batch 44/64 loss: 1.7413291931152344
Batch 45/64 loss: 1.741831660270691
Batch 46/64 loss: 1.736230492591858
Batch 47/64 loss: 1.745788335800171
Batch 48/64 loss: 1.7437764406204224
Batch 49/64 loss: 1.7386059761047363
Batch 50/64 loss: 1.7417244911193848
Batch 51/64 loss: 1.748425006866455
Batch 52/64 loss: 1.739842414855957
Batch 53/64 loss: 1.7379342317581177
Batch 54/64 loss: 1.7388248443603516
Batch 55/64 loss: 1.7362480163574219
Batch 56/64 loss: 1.73637056350708
Batch 57/64 loss: 1.7398416996002197
Batch 58/64 loss: 1.740898609161377
Batch 59/64 loss: 1.7455847263336182
Batch 60/64 loss: 1.7415885925292969
Batch 61/64 loss: 1.7391133308410645
Batch 62/64 loss: 1.7398478984832764
Batch 63/64 loss: 1.7426581382751465
Batch 64/64 loss: 1.919497013092041
Epoch 258  Train loss: 1.7418045193541283  Val loss: 1.760428630199629
Epoch 259
-------------------------------
Batch 1/64 loss: 1.7351455688476562
Batch 2/64 loss: 1.739516019821167
Batch 3/64 loss: 1.7414605617523193
Batch 4/64 loss: 1.7477350234985352
Batch 5/64 loss: 1.7394957542419434
Batch 6/64 loss: 1.774437665939331
Batch 7/64 loss: 1.7465193271636963
Batch 8/64 loss: 1.7388954162597656
Batch 9/64 loss: 1.7395656108856201
Batch 10/64 loss: 1.7413756847381592
Batch 11/64 loss: 1.7425038814544678
Batch 12/64 loss: 1.762998104095459
Batch 13/64 loss: 1.738968849182129
Batch 14/64 loss: 1.7453969717025757
Batch 15/64 loss: 1.7411084175109863
Batch 16/64 loss: 1.7470471858978271
Batch 17/64 loss: 1.7429611682891846
Batch 18/64 loss: 1.7483017444610596
Batch 19/64 loss: 1.7411401271820068
Batch 20/64 loss: 1.7401652336120605
Batch 21/64 loss: 1.7412452697753906
Batch 22/64 loss: 1.742504358291626
Batch 23/64 loss: 1.7431637048721313
Batch 24/64 loss: 1.7385730743408203
Batch 25/64 loss: 1.742755651473999
Batch 26/64 loss: 1.7377272844314575
Batch 27/64 loss: 1.7377421855926514
Batch 28/64 loss: 1.7381505966186523
Batch 29/64 loss: 1.747983455657959
Batch 30/64 loss: 1.7528167963027954
Batch 31/64 loss: 1.737239122390747
Batch 32/64 loss: 1.7428650856018066
Batch 33/64 loss: 1.7376435995101929
Batch 34/64 loss: 1.7406642436981201
Batch 35/64 loss: 1.733471393585205
Batch 36/64 loss: 1.7335487604141235
Batch 37/64 loss: 1.7356083393096924
Batch 38/64 loss: 1.7391688823699951
Batch 39/64 loss: 1.7341437339782715
Batch 40/64 loss: 1.7388699054718018
Batch 41/64 loss: 1.739875316619873
Batch 42/64 loss: 1.736464023590088
Batch 43/64 loss: 1.74021577835083
Batch 44/64 loss: 1.7376714944839478
Batch 45/64 loss: 1.7402749061584473
Batch 46/64 loss: 1.7363022565841675
Batch 47/64 loss: 1.7418605089187622
Batch 48/64 loss: 1.7350527048110962
Batch 49/64 loss: 1.7371022701263428
Batch 50/64 loss: 1.7343559265136719
Batch 51/64 loss: 1.7399506568908691
Batch 52/64 loss: 1.7382285594940186
Batch 53/64 loss: 1.735666036605835
Batch 54/64 loss: 1.7357889413833618
Batch 55/64 loss: 1.7406978607177734
Batch 56/64 loss: 1.7380197048187256
Batch 57/64 loss: 1.735663890838623
Batch 58/64 loss: 1.739332675933838
Batch 59/64 loss: 1.741655707359314
Batch 60/64 loss: 1.7391184568405151
Batch 61/64 loss: 1.7399122714996338
Batch 62/64 loss: 1.7371114492416382
Batch 63/64 loss: 1.733640432357788
Batch 64/64 loss: 1.9307477474212646
Epoch 259  Train loss: 1.7429434729557411  Val loss: 1.7555172140245994
Epoch 260
-------------------------------
Batch 1/64 loss: 1.7387280464172363
Batch 2/64 loss: 1.7374999523162842
Batch 3/64 loss: 1.7374759912490845
Batch 4/64 loss: 1.742607593536377
Batch 5/64 loss: 1.7396873235702515
Batch 6/64 loss: 1.7369956970214844
Batch 7/64 loss: 1.7369229793548584
Batch 8/64 loss: 1.740318775177002
Batch 9/64 loss: 1.7349098920822144
Batch 10/64 loss: 1.7355083227157593
Batch 11/64 loss: 1.7357547283172607
Batch 12/64 loss: 1.7369837760925293
Batch 13/64 loss: 1.7366070747375488
Batch 14/64 loss: 1.7372324466705322
Batch 15/64 loss: 1.7324414253234863
Batch 16/64 loss: 1.7344622611999512
Batch 17/64 loss: 1.7332968711853027
Batch 18/64 loss: 1.736964225769043
Batch 19/64 loss: 1.7331984043121338
Batch 20/64 loss: 1.7363359928131104
Batch 21/64 loss: 1.7386655807495117
Batch 22/64 loss: 1.7374029159545898
Batch 23/64 loss: 1.732324242591858
Batch 24/64 loss: 1.7350918054580688
Batch 25/64 loss: 1.7345848083496094
Batch 26/64 loss: 1.7354320287704468
Batch 27/64 loss: 1.7343602180480957
Batch 28/64 loss: 1.7324764728546143
Batch 29/64 loss: 1.734875202178955
Batch 30/64 loss: 1.7375775575637817
Batch 31/64 loss: 1.7337760925292969
Batch 32/64 loss: 1.7372350692749023
Batch 33/64 loss: 1.7387065887451172
Batch 34/64 loss: 1.7348871231079102
Batch 35/64 loss: 1.736453890800476
Batch 36/64 loss: 1.7321465015411377
Batch 37/64 loss: 1.7387948036193848
Batch 38/64 loss: 1.7344164848327637
Batch 39/64 loss: 1.740290880203247
Batch 40/64 loss: 1.7351353168487549
Batch 41/64 loss: 1.740936279296875
Batch 42/64 loss: 1.7339463233947754
Batch 43/64 loss: 1.7372360229492188
Batch 44/64 loss: 1.7367057800292969
Batch 45/64 loss: 1.7370479106903076
Batch 46/64 loss: 1.734649419784546
Batch 47/64 loss: 1.751059889793396
Batch 48/64 loss: 1.736875295639038
Batch 49/64 loss: 1.7523300647735596
Batch 50/64 loss: 1.737436294555664
Batch 51/64 loss: 1.7355598211288452
Batch 52/64 loss: 1.732405424118042
Batch 53/64 loss: 1.738985300064087
Batch 54/64 loss: 1.7375266551971436
Batch 55/64 loss: 1.7516231536865234
Batch 56/64 loss: 1.7374870777130127
Batch 57/64 loss: 1.7386671304702759
Batch 58/64 loss: 1.738384485244751
Batch 59/64 loss: 1.7342400550842285
Batch 60/64 loss: 1.734997272491455
Batch 61/64 loss: 1.7361634969711304
Batch 62/64 loss: 1.7365727424621582
Batch 63/64 loss: 1.7368056774139404
Batch 64/64 loss: 1.9193058013916016
Epoch 260  Train loss: 1.7392264515745874  Val loss: 1.7570910306320977
Epoch 261
-------------------------------
Batch 1/64 loss: 1.7347968816757202
Batch 2/64 loss: 1.7335946559906006
Batch 3/64 loss: 1.7338497638702393
Batch 4/64 loss: 1.740649700164795
Batch 5/64 loss: 1.7326273918151855
Batch 6/64 loss: 1.7390689849853516
Batch 7/64 loss: 1.7507562637329102
Batch 8/64 loss: 1.7336504459381104
Batch 9/64 loss: 1.7336397171020508
Batch 10/64 loss: 1.7378239631652832
Batch 11/64 loss: 1.7439498901367188
Batch 12/64 loss: 1.7368836402893066
Batch 13/64 loss: 1.7347993850708008
Batch 14/64 loss: 1.7375593185424805
Batch 15/64 loss: 1.7383891344070435
Batch 16/64 loss: 1.7347607612609863
Batch 17/64 loss: 1.7421423196792603
Batch 18/64 loss: 1.745147466659546
Batch 19/64 loss: 1.734864592552185
Batch 20/64 loss: 1.7394682168960571
Batch 21/64 loss: 1.7372772693634033
Batch 22/64 loss: 1.7368900775909424
Batch 23/64 loss: 1.7381858825683594
Batch 24/64 loss: 1.7395803928375244
Batch 25/64 loss: 1.7386882305145264
Batch 26/64 loss: 1.7375833988189697
Batch 27/64 loss: 1.7532877922058105
Batch 28/64 loss: 1.736482858657837
Batch 29/64 loss: 1.7370927333831787
Batch 30/64 loss: 1.7371554374694824
Batch 31/64 loss: 1.7390320301055908
Batch 32/64 loss: 1.7398030757904053
Batch 33/64 loss: 1.7356406450271606
Batch 34/64 loss: 1.7346540689468384
Batch 35/64 loss: 1.7366207838058472
Batch 36/64 loss: 1.7345283031463623
Batch 37/64 loss: 1.7366188764572144
Batch 38/64 loss: 1.7333006858825684
Batch 39/64 loss: 1.7379751205444336
Batch 40/64 loss: 1.735831379890442
Batch 41/64 loss: 1.7542872428894043
Batch 42/64 loss: 1.7407978773117065
Batch 43/64 loss: 1.7365093231201172
Batch 44/64 loss: 1.7352893352508545
Batch 45/64 loss: 1.7357006072998047
Batch 46/64 loss: 1.7373204231262207
Batch 47/64 loss: 1.7351130247116089
Batch 48/64 loss: 1.7415835857391357
Batch 49/64 loss: 1.743638515472412
Batch 50/64 loss: 1.7426297664642334
Batch 51/64 loss: 1.739434003829956
Batch 52/64 loss: 1.7356338500976562
Batch 53/64 loss: 1.7484378814697266
Batch 54/64 loss: 1.7354507446289062
Batch 55/64 loss: 1.7379026412963867
Batch 56/64 loss: 1.74506413936615
Batch 57/64 loss: 1.7362263202667236
Batch 58/64 loss: 1.7403861284255981
Batch 59/64 loss: 1.736299753189087
Batch 60/64 loss: 1.7347522974014282
Batch 61/64 loss: 1.7379963397979736
Batch 62/64 loss: 1.7344844341278076
Batch 63/64 loss: 1.7375054359436035
Batch 64/64 loss: 1.919090747833252
Epoch 261  Train loss: 1.7404927571614583  Val loss: 1.7555241576584755
Epoch 262
-------------------------------
Batch 1/64 loss: 1.7323603630065918
Batch 2/64 loss: 1.7366080284118652
Batch 3/64 loss: 1.7338027954101562
Batch 4/64 loss: 1.7358894348144531
Batch 5/64 loss: 1.7360632419586182
Batch 6/64 loss: 1.7386744022369385
Batch 7/64 loss: 1.7353341579437256
Batch 8/64 loss: 1.7369279861450195
Batch 9/64 loss: 1.7397009134292603
Batch 10/64 loss: 1.732471227645874
Batch 11/64 loss: 1.734124779701233
Batch 12/64 loss: 1.7353441715240479
Batch 13/64 loss: 1.7368310689926147
Batch 14/64 loss: 1.7388660907745361
Batch 15/64 loss: 1.7327821254730225
Batch 16/64 loss: 1.7351996898651123
Batch 17/64 loss: 1.7368342876434326
Batch 18/64 loss: 1.7349836826324463
Batch 19/64 loss: 1.7326613664627075
Batch 20/64 loss: 1.7331645488739014
Batch 21/64 loss: 1.7336548566818237
Batch 22/64 loss: 1.7348599433898926
Batch 23/64 loss: 1.7368266582489014
Batch 24/64 loss: 1.7352449893951416
Batch 25/64 loss: 1.7398555278778076
Batch 26/64 loss: 1.7366116046905518
Batch 27/64 loss: 1.7390177249908447
Batch 28/64 loss: 1.743546962738037
Batch 29/64 loss: 1.7363672256469727
Batch 30/64 loss: 1.7416069507598877
Batch 31/64 loss: 1.7320141792297363
Batch 32/64 loss: 1.7391583919525146
Batch 33/64 loss: 1.7352204322814941
Batch 34/64 loss: 1.7362264394760132
Batch 35/64 loss: 1.7388756275177002
Batch 36/64 loss: 1.7357025146484375
Batch 37/64 loss: 1.7365634441375732
Batch 38/64 loss: 1.7363650798797607
Batch 39/64 loss: 1.7350502014160156
Batch 40/64 loss: 1.7335255146026611
Batch 41/64 loss: 1.7329883575439453
Batch 42/64 loss: 1.751227855682373
Batch 43/64 loss: 1.7352142333984375
Batch 44/64 loss: 1.7397184371948242
Batch 45/64 loss: 1.733438491821289
Batch 46/64 loss: 1.7358014583587646
Batch 47/64 loss: 1.739868402481079
Batch 48/64 loss: 1.7326691150665283
Batch 49/64 loss: 1.7371444702148438
Batch 50/64 loss: 1.7621846199035645
Batch 51/64 loss: 1.7363929748535156
Batch 52/64 loss: 1.7369658946990967
Batch 53/64 loss: 1.7322062253952026
Batch 54/64 loss: 1.736743688583374
Batch 55/64 loss: 1.737609624862671
Batch 56/64 loss: 1.7390668392181396
Batch 57/64 loss: 1.7373707294464111
Batch 58/64 loss: 1.7341477870941162
Batch 59/64 loss: 1.742582082748413
Batch 60/64 loss: 1.7398042678833008
Batch 61/64 loss: 1.7395374774932861
Batch 62/64 loss: 1.73533034324646
Batch 63/64 loss: 1.7365469932556152
Batch 64/64 loss: 1.919111967086792
Epoch 262  Train loss: 1.7391186349532184  Val loss: 1.754051407587897
Epoch 263
-------------------------------
Batch 1/64 loss: 1.7339799404144287
Batch 2/64 loss: 1.7335898876190186
Batch 3/64 loss: 1.7360970973968506
Batch 4/64 loss: 1.7351889610290527
Batch 5/64 loss: 1.7362384796142578
Batch 6/64 loss: 1.747193694114685
Batch 7/64 loss: 1.7345387935638428
Batch 8/64 loss: 1.7381811141967773
Batch 9/64 loss: 1.7325434684753418
Batch 10/64 loss: 1.7535789012908936
Batch 11/64 loss: 1.733672857284546
Batch 12/64 loss: 1.7299048900604248
Batch 13/64 loss: 1.7348021268844604
Batch 14/64 loss: 1.7355016469955444
Batch 15/64 loss: 1.7411861419677734
Batch 16/64 loss: 1.734304666519165
Batch 17/64 loss: 1.7391700744628906
Batch 18/64 loss: 1.734827995300293
Batch 19/64 loss: 1.733553409576416
Batch 20/64 loss: 1.7339987754821777
Batch 21/64 loss: 1.736728549003601
Batch 22/64 loss: 1.7329847812652588
Batch 23/64 loss: 1.7368314266204834
Batch 24/64 loss: 1.7352402210235596
Batch 25/64 loss: 1.7315717935562134
Batch 26/64 loss: 1.736102819442749
Batch 27/64 loss: 1.7318251132965088
Batch 28/64 loss: 1.7421271800994873
Batch 29/64 loss: 1.735527753829956
Batch 30/64 loss: 1.7342150211334229
Batch 31/64 loss: 1.7380690574645996
Batch 32/64 loss: 1.7354878187179565
Batch 33/64 loss: 1.7348978519439697
Batch 34/64 loss: 1.7437083721160889
Batch 35/64 loss: 1.7353427410125732
Batch 36/64 loss: 1.7379580736160278
Batch 37/64 loss: 1.7337994575500488
Batch 38/64 loss: 1.7357720136642456
Batch 39/64 loss: 1.7350986003875732
Batch 40/64 loss: 1.7324753999710083
Batch 41/64 loss: 1.7378034591674805
Batch 42/64 loss: 1.7327051162719727
Batch 43/64 loss: 1.7395401000976562
Batch 44/64 loss: 1.7359719276428223
Batch 45/64 loss: 1.7330098152160645
Batch 46/64 loss: 1.7382278442382812
Batch 47/64 loss: 1.7426543235778809
Batch 48/64 loss: 1.7362442016601562
Batch 49/64 loss: 1.7329477071762085
Batch 50/64 loss: 1.7382090091705322
Batch 51/64 loss: 1.7371101379394531
Batch 52/64 loss: 1.735457420349121
Batch 53/64 loss: 1.7401084899902344
Batch 54/64 loss: 1.7568094730377197
Batch 55/64 loss: 1.7373926639556885
Batch 56/64 loss: 1.735138177871704
Batch 57/64 loss: 1.74826979637146
Batch 58/64 loss: 1.7379446029663086
Batch 59/64 loss: 1.7340433597564697
Batch 60/64 loss: 1.7357217073440552
Batch 61/64 loss: 1.7392258644104004
Batch 62/64 loss: 1.735842227935791
Batch 63/64 loss: 1.7351200580596924
Batch 64/64 loss: 1.9217838048934937
Epoch 263  Train loss: 1.7390533695033952  Val loss: 1.7549747494897483
Epoch 264
-------------------------------
Batch 1/64 loss: 1.7376151084899902
Batch 2/64 loss: 1.74410080909729
Batch 3/64 loss: 1.735425591468811
Batch 4/64 loss: 1.7411088943481445
Batch 5/64 loss: 1.736697793006897
Batch 6/64 loss: 1.7340919971466064
Batch 7/64 loss: 1.7371336221694946
Batch 8/64 loss: 1.7346360683441162
Batch 9/64 loss: 1.739409327507019
Batch 10/64 loss: 1.7345141172409058
Batch 11/64 loss: 1.7377681732177734
Batch 12/64 loss: 1.7400362491607666
Batch 13/64 loss: 1.7332932949066162
Batch 14/64 loss: 1.7417182922363281
Batch 15/64 loss: 1.7399585247039795
Batch 16/64 loss: 1.7348096370697021
Batch 17/64 loss: 1.7370134592056274
Batch 18/64 loss: 1.7341595888137817
Batch 19/64 loss: 1.7332463264465332
Batch 20/64 loss: 1.756725549697876
Batch 21/64 loss: 1.7384369373321533
Batch 22/64 loss: 1.7386410236358643
Batch 23/64 loss: 1.7369307279586792
Batch 24/64 loss: 1.7441062927246094
Batch 25/64 loss: 1.7395930290222168
Batch 26/64 loss: 1.736122965812683
Batch 27/64 loss: 1.7331678867340088
Batch 28/64 loss: 1.7360200881958008
Batch 29/64 loss: 1.7346950769424438
Batch 30/64 loss: 1.7347733974456787
Batch 31/64 loss: 1.7324180603027344
Batch 32/64 loss: 1.735503077507019
Batch 33/64 loss: 1.7361209392547607
Batch 34/64 loss: 1.738950252532959
Batch 35/64 loss: 1.7372238636016846
Batch 36/64 loss: 1.7354179620742798
Batch 37/64 loss: 1.7378950119018555
Batch 38/64 loss: 1.735995888710022
Batch 39/64 loss: 1.7334098815917969
Batch 40/64 loss: 1.737088918685913
Batch 41/64 loss: 1.7351235151290894
Batch 42/64 loss: 1.7325823307037354
Batch 43/64 loss: 1.7345502376556396
Batch 44/64 loss: 1.7475330829620361
Batch 45/64 loss: 1.7481958866119385
Batch 46/64 loss: 1.7379498481750488
Batch 47/64 loss: 1.7337241172790527
Batch 48/64 loss: 1.7338602542877197
Batch 49/64 loss: 1.7352054119110107
Batch 50/64 loss: 1.7328301668167114
Batch 51/64 loss: 1.7353556156158447
Batch 52/64 loss: 1.7365128993988037
Batch 53/64 loss: 1.7356994152069092
Batch 54/64 loss: 1.7348459959030151
Batch 55/64 loss: 1.7377755641937256
Batch 56/64 loss: 1.743048906326294
Batch 57/64 loss: 1.734736680984497
Batch 58/64 loss: 1.7380844354629517
Batch 59/64 loss: 1.737757921218872
Batch 60/64 loss: 1.7351548671722412
Batch 61/64 loss: 1.7326698303222656
Batch 62/64 loss: 1.7346419095993042
Batch 63/64 loss: 1.737911581993103
Batch 64/64 loss: 1.928633451461792
Epoch 264  Train loss: 1.7394227336434758  Val loss: 1.7561080406621559
Epoch 265
-------------------------------
Batch 1/64 loss: 1.7397801876068115
Batch 2/64 loss: 1.7451632022857666
Batch 3/64 loss: 1.736818552017212
Batch 4/64 loss: 1.7382612228393555
Batch 5/64 loss: 1.7370781898498535
Batch 6/64 loss: 1.736296534538269
Batch 7/64 loss: 1.7342233657836914
Batch 8/64 loss: 1.7377243041992188
Batch 9/64 loss: 1.7405189275741577
Batch 10/64 loss: 1.7365890741348267
Batch 11/64 loss: 1.734775424003601
Batch 12/64 loss: 1.7359914779663086
Batch 13/64 loss: 1.7366664409637451
Batch 14/64 loss: 1.7395857572555542
Batch 15/64 loss: 1.7394243478775024
Batch 16/64 loss: 1.735672950744629
Batch 17/64 loss: 1.7369211912155151
Batch 18/64 loss: 1.7365809679031372
Batch 19/64 loss: 1.735100269317627
Batch 20/64 loss: 1.7522039413452148
Batch 21/64 loss: 1.7343158721923828
Batch 22/64 loss: 1.7332416772842407
Batch 23/64 loss: 1.737448811531067
Batch 24/64 loss: 1.7337758541107178
Batch 25/64 loss: 1.7358587980270386
Batch 26/64 loss: 1.73569655418396
Batch 27/64 loss: 1.7395613193511963
Batch 28/64 loss: 1.7368690967559814
Batch 29/64 loss: 1.7388215065002441
Batch 30/64 loss: 1.7347979545593262
Batch 31/64 loss: 1.7344287633895874
Batch 32/64 loss: 1.7359542846679688
Batch 33/64 loss: 1.7380971908569336
Batch 34/64 loss: 1.7344741821289062
Batch 35/64 loss: 1.7349604368209839
Batch 36/64 loss: 1.7351934909820557
Batch 37/64 loss: 1.7361030578613281
Batch 38/64 loss: 1.739791750907898
Batch 39/64 loss: 1.7350491285324097
Batch 40/64 loss: 1.7350952625274658
Batch 41/64 loss: 1.7358176708221436
Batch 42/64 loss: 1.7411839962005615
Batch 43/64 loss: 1.7358322143554688
Batch 44/64 loss: 1.736253261566162
Batch 45/64 loss: 1.7341558933258057
Batch 46/64 loss: 1.7356197834014893
Batch 47/64 loss: 1.7378697395324707
Batch 48/64 loss: 1.7398808002471924
Batch 49/64 loss: 1.736328363418579
Batch 50/64 loss: 1.73483407497406
Batch 51/64 loss: 1.756338119506836
Batch 52/64 loss: 1.7394797801971436
Batch 53/64 loss: 1.7368152141571045
Batch 54/64 loss: 1.753411054611206
Batch 55/64 loss: 1.7349226474761963
Batch 56/64 loss: 1.7363818883895874
Batch 57/64 loss: 1.736195683479309
Batch 58/64 loss: 1.736894130706787
Batch 59/64 loss: 1.7374842166900635
Batch 60/64 loss: 1.7394077777862549
Batch 61/64 loss: 1.7349287271499634
Batch 62/64 loss: 1.7342370748519897
Batch 63/64 loss: 1.7375978231430054
Batch 64/64 loss: 1.930761694908142
Epoch 265  Train loss: 1.7398408239963008  Val loss: 1.754822611399123
Epoch 266
-------------------------------
Batch 1/64 loss: 1.7377848625183105
Batch 2/64 loss: 1.735257625579834
Batch 3/64 loss: 1.735947847366333
Batch 4/64 loss: 1.7374379634857178
Batch 5/64 loss: 1.737719178199768
Batch 6/64 loss: 1.7367475032806396
Batch 7/64 loss: 1.7353352308273315
Batch 8/64 loss: 1.7379717826843262
Batch 9/64 loss: 1.7377328872680664
Batch 10/64 loss: 1.7348151206970215
Batch 11/64 loss: 1.7368628978729248
Batch 12/64 loss: 1.7336498498916626
Batch 13/64 loss: 1.7343113422393799
Batch 14/64 loss: 1.7394758462905884
Batch 15/64 loss: 1.7359451055526733
Batch 16/64 loss: 1.7339375019073486
Batch 17/64 loss: 1.7324771881103516
Batch 18/64 loss: 1.736281394958496
Batch 19/64 loss: 1.7350068092346191
Batch 20/64 loss: 1.7522132396697998
Batch 21/64 loss: 1.734507441520691
Batch 22/64 loss: 1.7336009740829468
Batch 23/64 loss: 1.7376099824905396
Batch 24/64 loss: 1.7353215217590332
Batch 25/64 loss: 1.7368009090423584
Batch 26/64 loss: 1.7414027452468872
Batch 27/64 loss: 1.7406901121139526
Batch 28/64 loss: 1.7368552684783936
Batch 29/64 loss: 1.7370530366897583
Batch 30/64 loss: 1.7383317947387695
Batch 31/64 loss: 1.7381446361541748
Batch 32/64 loss: 1.7399964332580566
Batch 33/64 loss: 1.736191749572754
Batch 34/64 loss: 1.7405760288238525
Batch 35/64 loss: 1.7405850887298584
Batch 36/64 loss: 1.7507386207580566
Batch 37/64 loss: 1.7423837184906006
Batch 38/64 loss: 1.7344636917114258
Batch 39/64 loss: 1.7372803688049316
Batch 40/64 loss: 1.7366931438446045
Batch 41/64 loss: 1.734815239906311
Batch 42/64 loss: 1.7374675273895264
Batch 43/64 loss: 1.7333464622497559
Batch 44/64 loss: 1.737725019454956
Batch 45/64 loss: 1.7344982624053955
Batch 46/64 loss: 1.7384406328201294
Batch 47/64 loss: 1.7376110553741455
Batch 48/64 loss: 1.739708423614502
Batch 49/64 loss: 1.7329728603363037
Batch 50/64 loss: 1.7392815351486206
Batch 51/64 loss: 1.7399942874908447
Batch 52/64 loss: 1.7365440130233765
Batch 53/64 loss: 1.7372604608535767
Batch 54/64 loss: 1.737164855003357
Batch 55/64 loss: 1.7359061241149902
Batch 56/64 loss: 1.7349072694778442
Batch 57/64 loss: 1.756366491317749
Batch 58/64 loss: 1.7382333278656006
Batch 59/64 loss: 1.7357144355773926
Batch 60/64 loss: 1.7347036600112915
Batch 61/64 loss: 1.7366694211959839
Batch 62/64 loss: 1.7353196144104004
Batch 63/64 loss: 1.7343043088912964
Batch 64/64 loss: 1.9238626956939697
Epoch 266  Train loss: 1.7397331882925595  Val loss: 1.7529293163535522
Epoch 267
-------------------------------
Batch 1/64 loss: 1.7374193668365479
Batch 2/64 loss: 1.734712839126587
Batch 3/64 loss: 1.7363090515136719
Batch 4/64 loss: 1.7381219863891602
Batch 5/64 loss: 1.737414836883545
Batch 6/64 loss: 1.7319002151489258
Batch 7/64 loss: 1.7509506940841675
Batch 8/64 loss: 1.7369909286499023
Batch 9/64 loss: 1.7344708442687988
Batch 10/64 loss: 1.738623857498169
Batch 11/64 loss: 1.7375861406326294
Batch 12/64 loss: 1.7376309633255005
Batch 13/64 loss: 1.736143946647644
Batch 14/64 loss: 1.736234426498413
Batch 15/64 loss: 1.7329089641571045
Batch 16/64 loss: 1.732407808303833
Batch 17/64 loss: 1.7332755327224731
Batch 18/64 loss: 1.7379250526428223
Batch 19/64 loss: 1.7346752882003784
Batch 20/64 loss: 1.7359793186187744
Batch 21/64 loss: 1.7350969314575195
Batch 22/64 loss: 1.7363505363464355
Batch 23/64 loss: 1.734102487564087
Batch 24/64 loss: 1.736191749572754
Batch 25/64 loss: 1.7335456609725952
Batch 26/64 loss: 1.7372616529464722
Batch 27/64 loss: 1.7392109632492065
Batch 28/64 loss: 1.735678791999817
Batch 29/64 loss: 1.7397031784057617
Batch 30/64 loss: 1.7387927770614624
Batch 31/64 loss: 1.7346012592315674
Batch 32/64 loss: 1.7339699268341064
Batch 33/64 loss: 1.7346580028533936
Batch 34/64 loss: 1.736184000968933
Batch 35/64 loss: 1.7477660179138184
Batch 36/64 loss: 1.737075686454773
Batch 37/64 loss: 1.7330398559570312
Batch 38/64 loss: 1.7355372905731201
Batch 39/64 loss: 1.7333910465240479
Batch 40/64 loss: 1.7397377490997314
Batch 41/64 loss: 1.734494686126709
Batch 42/64 loss: 1.741899013519287
Batch 43/64 loss: 1.7346444129943848
Batch 44/64 loss: 1.7381150722503662
Batch 45/64 loss: 1.7316861152648926
Batch 46/64 loss: 1.7342541217803955
Batch 47/64 loss: 1.7336714267730713
Batch 48/64 loss: 1.732864260673523
Batch 49/64 loss: 1.7328262329101562
Batch 50/64 loss: 1.735710859298706
Batch 51/64 loss: 1.7328193187713623
Batch 52/64 loss: 1.7337579727172852
Batch 53/64 loss: 1.7354776859283447
Batch 54/64 loss: 1.7379631996154785
Batch 55/64 loss: 1.7504363059997559
Batch 56/64 loss: 1.7334709167480469
Batch 57/64 loss: 1.7354073524475098
Batch 58/64 loss: 1.7325472831726074
Batch 59/64 loss: 1.7307031154632568
Batch 60/64 loss: 1.7311431169509888
Batch 61/64 loss: 1.7353417873382568
Batch 62/64 loss: 1.7330832481384277
Batch 63/64 loss: 1.7352021932601929
Batch 64/64 loss: 1.9166314601898193
Epoch 267  Train loss: 1.738173661512487  Val loss: 1.7529541905393307
Epoch 268
-------------------------------
Batch 1/64 loss: 1.7331256866455078
Batch 2/64 loss: 1.7345030307769775
Batch 3/64 loss: 1.7341694831848145
Batch 4/64 loss: 1.7357802391052246
Batch 5/64 loss: 1.7361118793487549
Batch 6/64 loss: 1.7359462976455688
Batch 7/64 loss: 1.7334158420562744
Batch 8/64 loss: 1.737339735031128
Batch 9/64 loss: 1.7351162433624268
Batch 10/64 loss: 1.7387083768844604
Batch 11/64 loss: 1.7387710809707642
Batch 12/64 loss: 1.748764991760254
Batch 13/64 loss: 1.7417645454406738
Batch 14/64 loss: 1.7397522926330566
Batch 15/64 loss: 1.7361164093017578
Batch 16/64 loss: 1.735520601272583
Batch 17/64 loss: 1.7428685426712036
Batch 18/64 loss: 1.7388060092926025
Batch 19/64 loss: 1.741219401359558
Batch 20/64 loss: 1.7527105808258057
Batch 21/64 loss: 1.7381775379180908
Batch 22/64 loss: 1.7333900928497314
Batch 23/64 loss: 1.735952615737915
Batch 24/64 loss: 1.7376594543457031
Batch 25/64 loss: 1.7404029369354248
Batch 26/64 loss: 1.7348544597625732
Batch 27/64 loss: 1.7339009046554565
Batch 28/64 loss: 1.7347320318222046
Batch 29/64 loss: 1.7362645864486694
Batch 30/64 loss: 1.733642339706421
Batch 31/64 loss: 1.7347049713134766
Batch 32/64 loss: 1.734283447265625
Batch 33/64 loss: 1.7328441143035889
Batch 34/64 loss: 1.7327269315719604
Batch 35/64 loss: 1.7387171983718872
Batch 36/64 loss: 1.733500599861145
Batch 37/64 loss: 1.7392722368240356
Batch 38/64 loss: 1.7342007160186768
Batch 39/64 loss: 1.7339760065078735
Batch 40/64 loss: 1.7512240409851074
Batch 41/64 loss: 1.7348909378051758
Batch 42/64 loss: 1.7360143661499023
Batch 43/64 loss: 1.7435723543167114
Batch 44/64 loss: 1.7347296476364136
Batch 45/64 loss: 1.7343226671218872
Batch 46/64 loss: 1.7347321510314941
Batch 47/64 loss: 1.7425247430801392
Batch 48/64 loss: 1.7377874851226807
Batch 49/64 loss: 1.7336171865463257
Batch 50/64 loss: 1.735779047012329
Batch 51/64 loss: 1.7360339164733887
Batch 52/64 loss: 1.7362942695617676
Batch 53/64 loss: 1.7371591329574585
Batch 54/64 loss: 1.7385213375091553
Batch 55/64 loss: 1.7394487857818604
Batch 56/64 loss: 1.737393856048584
Batch 57/64 loss: 1.7390360832214355
Batch 58/64 loss: 1.739213466644287
Batch 59/64 loss: 1.7362366914749146
Batch 60/64 loss: 1.7372527122497559
Batch 61/64 loss: 1.7369738817214966
Batch 62/64 loss: 1.7406425476074219
Batch 63/64 loss: 1.7352144718170166
Batch 64/64 loss: 1.9229562282562256
Epoch 268  Train loss: 1.7395223122017056  Val loss: 1.7551304949927575
Epoch 269
-------------------------------
Batch 1/64 loss: 1.7340378761291504
Batch 2/64 loss: 1.7383229732513428
Batch 3/64 loss: 1.73616361618042
Batch 4/64 loss: 1.7383248805999756
Batch 5/64 loss: 1.734218955039978
Batch 6/64 loss: 1.7382913827896118
Batch 7/64 loss: 1.7361693382263184
Batch 8/64 loss: 1.737496256828308
Batch 9/64 loss: 1.735811471939087
Batch 10/64 loss: 1.7403759956359863
Batch 11/64 loss: 1.7370402812957764
Batch 12/64 loss: 1.7364810705184937
Batch 13/64 loss: 1.7377910614013672
Batch 14/64 loss: 1.7352173328399658
Batch 15/64 loss: 1.7367041110992432
Batch 16/64 loss: 1.7344505786895752
Batch 17/64 loss: 1.7367233037948608
Batch 18/64 loss: 1.7392796277999878
Batch 19/64 loss: 1.7332427501678467
Batch 20/64 loss: 1.7351460456848145
Batch 21/64 loss: 1.7349185943603516
Batch 22/64 loss: 1.7340357303619385
Batch 23/64 loss: 1.7419217824935913
Batch 24/64 loss: 1.7401080131530762
Batch 25/64 loss: 1.7380578517913818
Batch 26/64 loss: 1.7358241081237793
Batch 27/64 loss: 1.754441261291504
Batch 28/64 loss: 1.7364760637283325
Batch 29/64 loss: 1.735962152481079
Batch 30/64 loss: 1.7339882850646973
Batch 31/64 loss: 1.734826683998108
Batch 32/64 loss: 1.734316110610962
Batch 33/64 loss: 1.7366701364517212
Batch 34/64 loss: 1.7324655055999756
Batch 35/64 loss: 1.7338316440582275
Batch 36/64 loss: 1.7347867488861084
Batch 37/64 loss: 1.736642837524414
Batch 38/64 loss: 1.7333524227142334
Batch 39/64 loss: 1.7379076480865479
Batch 40/64 loss: 1.7346274852752686
Batch 41/64 loss: 1.7420166730880737
Batch 42/64 loss: 1.7407186031341553
Batch 43/64 loss: 1.734273076057434
Batch 44/64 loss: 1.7358589172363281
Batch 45/64 loss: 1.738563060760498
Batch 46/64 loss: 1.7375653982162476
Batch 47/64 loss: 1.7369511127471924
Batch 48/64 loss: 1.7412440776824951
Batch 49/64 loss: 1.7360258102416992
Batch 50/64 loss: 1.756230115890503
Batch 51/64 loss: 1.736738920211792
Batch 52/64 loss: 1.7348651885986328
Batch 53/64 loss: 1.7319164276123047
Batch 54/64 loss: 1.7351384162902832
Batch 55/64 loss: 1.7352442741394043
Batch 56/64 loss: 1.7350956201553345
Batch 57/64 loss: 1.7348134517669678
Batch 58/64 loss: 1.7332751750946045
Batch 59/64 loss: 1.734021544456482
Batch 60/64 loss: 1.7494032382965088
Batch 61/64 loss: 1.7394399642944336
Batch 62/64 loss: 1.7383575439453125
Batch 63/64 loss: 1.7408710718154907
Batch 64/64 loss: 1.925775170326233
Epoch 269  Train loss: 1.73944171035991  Val loss: 1.7549652791105186
Epoch 270
-------------------------------
Batch 1/64 loss: 1.732156753540039
Batch 2/64 loss: 1.7336465120315552
Batch 3/64 loss: 1.73744535446167
Batch 4/64 loss: 1.7346031665802002
Batch 5/64 loss: 1.7372584342956543
Batch 6/64 loss: 1.737326979637146
Batch 7/64 loss: 1.734472632408142
Batch 8/64 loss: 1.7344863414764404
Batch 9/64 loss: 1.7328746318817139
Batch 10/64 loss: 1.7363488674163818
Batch 11/64 loss: 1.7345094680786133
Batch 12/64 loss: 1.7369332313537598
Batch 13/64 loss: 1.7340061664581299
Batch 14/64 loss: 1.7444407939910889
Batch 15/64 loss: 1.7339706420898438
Batch 16/64 loss: 1.7347782850265503
Batch 17/64 loss: 1.7346696853637695
Batch 18/64 loss: 1.737716555595398
Batch 19/64 loss: 1.7367510795593262
Batch 20/64 loss: 1.738631248474121
Batch 21/64 loss: 1.740480899810791
Batch 22/64 loss: 1.738943099975586
Batch 23/64 loss: 1.7370994091033936
Batch 24/64 loss: 1.7389495372772217
Batch 25/64 loss: 1.738776683807373
Batch 26/64 loss: 1.7362220287322998
Batch 27/64 loss: 1.7332453727722168
Batch 28/64 loss: 1.736879825592041
Batch 29/64 loss: 1.735588788986206
Batch 30/64 loss: 1.7369744777679443
Batch 31/64 loss: 1.7370866537094116
Batch 32/64 loss: 1.7374266386032104
Batch 33/64 loss: 1.7373223304748535
Batch 34/64 loss: 1.736575961112976
Batch 35/64 loss: 1.732362985610962
Batch 36/64 loss: 1.7353577613830566
Batch 37/64 loss: 1.7408316135406494
Batch 38/64 loss: 1.7473318576812744
Batch 39/64 loss: 1.7370007038116455
Batch 40/64 loss: 1.7382936477661133
Batch 41/64 loss: 1.7375726699829102
Batch 42/64 loss: 1.7387313842773438
Batch 43/64 loss: 1.7364170551300049
Batch 44/64 loss: 1.7527573108673096
Batch 45/64 loss: 1.7359545230865479
Batch 46/64 loss: 1.7355499267578125
Batch 47/64 loss: 1.7339355945587158
Batch 48/64 loss: 1.7367730140686035
Batch 49/64 loss: 1.7336952686309814
Batch 50/64 loss: 1.7365854978561401
Batch 51/64 loss: 1.7419098615646362
Batch 52/64 loss: 1.736563801765442
Batch 53/64 loss: 1.7353425025939941
Batch 54/64 loss: 1.7354737520217896
Batch 55/64 loss: 1.7326334714889526
Batch 56/64 loss: 1.7331807613372803
Batch 57/64 loss: 1.7358055114746094
Batch 58/64 loss: 1.7359929084777832
Batch 59/64 loss: 1.7367570400238037
Batch 60/64 loss: 1.7332587242126465
Batch 61/64 loss: 1.7371745109558105
Batch 62/64 loss: 1.7322063446044922
Batch 63/64 loss: 1.737650752067566
Batch 64/64 loss: 1.9471523761749268
Epoch 270  Train loss: 1.7391696247400021  Val loss: 1.7528521777018649
Epoch 271
-------------------------------
Batch 1/64 loss: 1.7350847721099854
Batch 2/64 loss: 1.7362537384033203
Batch 3/64 loss: 1.7367770671844482
Batch 4/64 loss: 1.7338879108428955
Batch 5/64 loss: 1.7394020557403564
Batch 6/64 loss: 1.7346994876861572
Batch 7/64 loss: 1.7333505153656006
Batch 8/64 loss: 1.730428695678711
Batch 9/64 loss: 1.7339158058166504
Batch 10/64 loss: 1.7334085702896118
Batch 11/64 loss: 1.733236312866211
Batch 12/64 loss: 1.7350155115127563
Batch 13/64 loss: 1.7373037338256836
Batch 14/64 loss: 1.7334539890289307
Batch 15/64 loss: 1.7349166870117188
Batch 16/64 loss: 1.7378677129745483
Batch 17/64 loss: 1.7333433628082275
Batch 18/64 loss: 1.7342803478240967
Batch 19/64 loss: 1.7493896484375
Batch 20/64 loss: 1.7338967323303223
Batch 21/64 loss: 1.7354182004928589
Batch 22/64 loss: 1.7366571426391602
Batch 23/64 loss: 1.7415111064910889
Batch 24/64 loss: 1.7450780868530273
Batch 25/64 loss: 1.7353713512420654
Batch 26/64 loss: 1.734250783920288
Batch 27/64 loss: 1.7358591556549072
Batch 28/64 loss: 1.7359086275100708
Batch 29/64 loss: 1.7409322261810303
Batch 30/64 loss: 1.7481889724731445
Batch 31/64 loss: 1.7362514734268188
Batch 32/64 loss: 1.7339990139007568
Batch 33/64 loss: 1.7397083044052124
Batch 34/64 loss: 1.7346224784851074
Batch 35/64 loss: 1.73561429977417
Batch 36/64 loss: 1.7332112789154053
Batch 37/64 loss: 1.7353301048278809
Batch 38/64 loss: 1.7372968196868896
Batch 39/64 loss: 1.7348613739013672
Batch 40/64 loss: 1.7368782758712769
Batch 41/64 loss: 1.7415602207183838
Batch 42/64 loss: 1.7364157438278198
Batch 43/64 loss: 1.7360780239105225
Batch 44/64 loss: 1.7335898876190186
Batch 45/64 loss: 1.7357032299041748
Batch 46/64 loss: 1.7376130819320679
Batch 47/64 loss: 1.7371034622192383
Batch 48/64 loss: 1.7381272315979004
Batch 49/64 loss: 1.7419753074645996
Batch 50/64 loss: 1.734837293624878
Batch 51/64 loss: 1.7341253757476807
Batch 52/64 loss: 1.73591148853302
Batch 53/64 loss: 1.7338038682937622
Batch 54/64 loss: 1.7369983196258545
Batch 55/64 loss: 1.7361805438995361
Batch 56/64 loss: 1.742445468902588
Batch 57/64 loss: 1.7399475574493408
Batch 58/64 loss: 1.755507469177246
Batch 59/64 loss: 1.7393732070922852
Batch 60/64 loss: 1.7408370971679688
Batch 61/64 loss: 1.734400987625122
Batch 62/64 loss: 1.7375340461730957
Batch 63/64 loss: 1.7367513179779053
Batch 64/64 loss: 1.9225106239318848
Epoch 271  Train loss: 1.739224547965854  Val loss: 1.7551110519985973
Epoch 272
-------------------------------
Batch 1/64 loss: 1.7378547191619873
Batch 2/64 loss: 1.7383785247802734
Batch 3/64 loss: 1.7370927333831787
Batch 4/64 loss: 1.7399907112121582
Batch 5/64 loss: 1.7374114990234375
Batch 6/64 loss: 1.7373650074005127
Batch 7/64 loss: 1.7343579530715942
Batch 8/64 loss: 1.7363629341125488
Batch 9/64 loss: 1.7361750602722168
Batch 10/64 loss: 1.738539695739746
Batch 11/64 loss: 1.7382586002349854
Batch 12/64 loss: 1.737231969833374
Batch 13/64 loss: 1.7339694499969482
Batch 14/64 loss: 1.7514668703079224
Batch 15/64 loss: 1.7362406253814697
Batch 16/64 loss: 1.7367744445800781
Batch 17/64 loss: 1.734260082244873
Batch 18/64 loss: 1.7360488176345825
Batch 19/64 loss: 1.7355400323867798
Batch 20/64 loss: 1.735350251197815
Batch 21/64 loss: 1.7367534637451172
Batch 22/64 loss: 1.7359635829925537
Batch 23/64 loss: 1.7337653636932373
Batch 24/64 loss: 1.7365899085998535
Batch 25/64 loss: 1.7333405017852783
Batch 26/64 loss: 1.7404284477233887
Batch 27/64 loss: 1.7344484329223633
Batch 28/64 loss: 1.7360458374023438
Batch 29/64 loss: 1.7395262718200684
Batch 30/64 loss: 1.734867811203003
Batch 31/64 loss: 1.7331501245498657
Batch 32/64 loss: 1.7348473072052002
Batch 33/64 loss: 1.7375648021697998
Batch 34/64 loss: 1.7396790981292725
Batch 35/64 loss: 1.7328476905822754
Batch 36/64 loss: 1.741541862487793
Batch 37/64 loss: 1.7429591417312622
Batch 38/64 loss: 1.7338786125183105
Batch 39/64 loss: 1.7369370460510254
Batch 40/64 loss: 1.734607458114624
Batch 41/64 loss: 1.7357062101364136
Batch 42/64 loss: 1.7348992824554443
Batch 43/64 loss: 1.7318669557571411
Batch 44/64 loss: 1.7335968017578125
Batch 45/64 loss: 1.7370495796203613
Batch 46/64 loss: 1.7343209981918335
Batch 47/64 loss: 1.735235333442688
Batch 48/64 loss: 1.7342829704284668
Batch 49/64 loss: 1.7607922554016113
Batch 50/64 loss: 1.7362885475158691
Batch 51/64 loss: 1.7336134910583496
Batch 52/64 loss: 1.7332870960235596
Batch 53/64 loss: 1.7345712184906006
Batch 54/64 loss: 1.73288893699646
Batch 55/64 loss: 1.7380948066711426
Batch 56/64 loss: 1.7357988357543945
Batch 57/64 loss: 1.7348285913467407
Batch 58/64 loss: 1.7499545812606812
Batch 59/64 loss: 1.7337148189544678
Batch 60/64 loss: 1.7363383769989014
Batch 61/64 loss: 1.7350720167160034
Batch 62/64 loss: 1.734816074371338
Batch 63/64 loss: 1.742865800857544
Batch 64/64 loss: 1.926727294921875
Epoch 272  Train loss: 1.7391896752750173  Val loss: 1.7544463639406813
Epoch 273
-------------------------------
Batch 1/64 loss: 1.7375640869140625
Batch 2/64 loss: 1.735710859298706
Batch 3/64 loss: 1.734926462173462
Batch 4/64 loss: 1.7361098527908325
Batch 5/64 loss: 1.7367219924926758
Batch 6/64 loss: 1.7388947010040283
Batch 7/64 loss: 1.7339286804199219
Batch 8/64 loss: 1.7361724376678467
Batch 9/64 loss: 1.7373933792114258
Batch 10/64 loss: 1.7480583190917969
Batch 11/64 loss: 1.7325037717819214
Batch 12/64 loss: 1.7322371006011963
Batch 13/64 loss: 1.7347655296325684
Batch 14/64 loss: 1.7344715595245361
Batch 15/64 loss: 1.7403724193572998
Batch 16/64 loss: 1.7357760667800903
Batch 17/64 loss: 1.7326691150665283
Batch 18/64 loss: 1.7338600158691406
Batch 19/64 loss: 1.732940435409546
Batch 20/64 loss: 1.737199306488037
Batch 21/64 loss: 1.7346303462982178
Batch 22/64 loss: 1.7324466705322266
Batch 23/64 loss: 1.747469186782837
Batch 24/64 loss: 1.732017993927002
Batch 25/64 loss: 1.7344493865966797
Batch 26/64 loss: 1.735138177871704
Batch 27/64 loss: 1.7343806028366089
Batch 28/64 loss: 1.7340960502624512
Batch 29/64 loss: 1.7363250255584717
Batch 30/64 loss: 1.7320826053619385
Batch 31/64 loss: 1.7355601787567139
Batch 32/64 loss: 1.7345898151397705
Batch 33/64 loss: 1.7345585823059082
Batch 34/64 loss: 1.7342474460601807
Batch 35/64 loss: 1.733480453491211
Batch 36/64 loss: 1.7361235618591309
Batch 37/64 loss: 1.734966516494751
Batch 38/64 loss: 1.7328295707702637
Batch 39/64 loss: 1.7342915534973145
Batch 40/64 loss: 1.7340450286865234
Batch 41/64 loss: 1.738281488418579
Batch 42/64 loss: 1.735602855682373
Batch 43/64 loss: 1.7362895011901855
Batch 44/64 loss: 1.7395930290222168
Batch 45/64 loss: 1.7328577041625977
Batch 46/64 loss: 1.735308051109314
Batch 47/64 loss: 1.7340724468231201
Batch 48/64 loss: 1.7347569465637207
Batch 49/64 loss: 1.7373210191726685
Batch 50/64 loss: 1.7359330654144287
Batch 51/64 loss: 1.731375813484192
Batch 52/64 loss: 1.7351210117340088
Batch 53/64 loss: 1.7345112562179565
Batch 54/64 loss: 1.733839750289917
Batch 55/64 loss: 1.7363770008087158
Batch 56/64 loss: 1.7394236326217651
Batch 57/64 loss: 1.7357244491577148
Batch 58/64 loss: 1.7384731769561768
Batch 59/64 loss: 1.7345744371414185
Batch 60/64 loss: 1.7405874729156494
Batch 61/64 loss: 1.734629511833191
Batch 62/64 loss: 1.7364108562469482
Batch 63/64 loss: 1.7532334327697754
Batch 64/64 loss: 1.925627589225769
Epoch 273  Train loss: 1.738172916805043  Val loss: 1.752568595597834
Epoch 274
-------------------------------
Batch 1/64 loss: 1.735959768295288
Batch 2/64 loss: 1.7365037202835083
Batch 3/64 loss: 1.7337660789489746
Batch 4/64 loss: 1.7330350875854492
Batch 5/64 loss: 1.73356032371521
Batch 6/64 loss: 1.7343533039093018
Batch 7/64 loss: 1.7529394626617432
Batch 8/64 loss: 1.733904480934143
Batch 9/64 loss: 1.7362871170043945
Batch 10/64 loss: 1.7398232221603394
Batch 11/64 loss: 1.7371313571929932
Batch 12/64 loss: 1.7429981231689453
Batch 13/64 loss: 1.7322263717651367
Batch 14/64 loss: 1.7368468046188354
Batch 15/64 loss: 1.7619614601135254
Batch 16/64 loss: 1.741955280303955
Batch 17/64 loss: 1.7421108484268188
Batch 18/64 loss: 1.7410242557525635
Batch 19/64 loss: 1.742179274559021
Batch 20/64 loss: 1.744018316268921
Batch 21/64 loss: 1.7437334060668945
Batch 22/64 loss: 1.740253210067749
Batch 23/64 loss: 1.740044355392456
Batch 24/64 loss: 1.7428231239318848
Batch 25/64 loss: 1.742501139640808
Batch 26/64 loss: 1.7441864013671875
Batch 27/64 loss: 1.7439770698547363
Batch 28/64 loss: 1.7403466701507568
Batch 29/64 loss: 1.7381775379180908
Batch 30/64 loss: 1.740495204925537
Batch 31/64 loss: 1.7489755153656006
Batch 32/64 loss: 1.738594889640808
Batch 33/64 loss: 1.7502344846725464
Batch 34/64 loss: 1.7402695417404175
Batch 35/64 loss: 1.7396836280822754
Batch 36/64 loss: 1.7417545318603516
Batch 37/64 loss: 1.7425752878189087
Batch 38/64 loss: 1.7374300956726074
Batch 39/64 loss: 1.73954176902771
Batch 40/64 loss: 1.740884780883789
Batch 41/64 loss: 1.737274408340454
Batch 42/64 loss: 1.749863862991333
Batch 43/64 loss: 1.7399067878723145
Batch 44/64 loss: 1.7543798685073853
Batch 45/64 loss: 1.736721158027649
Batch 46/64 loss: 1.7372055053710938
Batch 47/64 loss: 1.740473985671997
Batch 48/64 loss: 1.7390975952148438
Batch 49/64 loss: 1.7414135932922363
Batch 50/64 loss: 1.7366337776184082
Batch 51/64 loss: 1.7418668270111084
Batch 52/64 loss: 1.7409106492996216
Batch 53/64 loss: 1.7425270080566406
Batch 54/64 loss: 1.7413181066513062
Batch 55/64 loss: 1.7413928508758545
Batch 56/64 loss: 1.7361810207366943
Batch 57/64 loss: 1.7372217178344727
Batch 58/64 loss: 1.7384939193725586
Batch 59/64 loss: 1.7359858751296997
Batch 60/64 loss: 1.7358176708221436
Batch 61/64 loss: 1.7353477478027344
Batch 62/64 loss: 1.736087679862976
Batch 63/64 loss: 1.7493650913238525
Batch 64/64 loss: 1.925261378288269
Epoch 274  Train loss: 1.7427215693043727  Val loss: 1.7554394502410364
Epoch 275
-------------------------------
Batch 1/64 loss: 1.7366576194763184
Batch 2/64 loss: 1.73936128616333
Batch 3/64 loss: 1.7367944717407227
Batch 4/64 loss: 1.739748477935791
Batch 5/64 loss: 1.7380499839782715
Batch 6/64 loss: 1.7381737232208252
Batch 7/64 loss: 1.7395656108856201
Batch 8/64 loss: 1.738261103630066
Batch 9/64 loss: 1.7377296686172485
Batch 10/64 loss: 1.736823320388794
Batch 11/64 loss: 1.7608228921890259
Batch 12/64 loss: 1.741746187210083
Batch 13/64 loss: 1.7372863292694092
Batch 14/64 loss: 1.736649513244629
Batch 15/64 loss: 1.7411882877349854
Batch 16/64 loss: 1.741300106048584
Batch 17/64 loss: 1.7368412017822266
Batch 18/64 loss: 1.7402234077453613
Batch 19/64 loss: 1.7383900880813599
Batch 20/64 loss: 1.7409043312072754
Batch 21/64 loss: 1.7375653982162476
Batch 22/64 loss: 1.7422196865081787
Batch 23/64 loss: 1.7397046089172363
Batch 24/64 loss: 1.7390289306640625
Batch 25/64 loss: 1.7385966777801514
Batch 26/64 loss: 1.7402299642562866
Batch 27/64 loss: 1.741787075996399
Batch 28/64 loss: 1.7436113357543945
Batch 29/64 loss: 1.739274024963379
Batch 30/64 loss: 1.7388103008270264
Batch 31/64 loss: 1.7386813163757324
Batch 32/64 loss: 1.7408421039581299
Batch 33/64 loss: 1.737734317779541
Batch 34/64 loss: 1.73818838596344
Batch 35/64 loss: 1.73903489112854
Batch 36/64 loss: 1.74267578125
Batch 37/64 loss: 1.7389287948608398
Batch 38/64 loss: 1.7475547790527344
Batch 39/64 loss: 1.7406508922576904
Batch 40/64 loss: 1.7429990768432617
Batch 41/64 loss: 1.7426488399505615
Batch 42/64 loss: 1.744126319885254
Batch 43/64 loss: 1.7385523319244385
Batch 44/64 loss: 1.7439169883728027
Batch 45/64 loss: 1.743370771408081
Batch 46/64 loss: 1.76691472530365
Batch 47/64 loss: 1.744346261024475
Batch 48/64 loss: 1.7559034824371338
Batch 49/64 loss: 1.7457382678985596
Batch 50/64 loss: 1.7493503093719482
Batch 51/64 loss: 1.7451128959655762
Batch 52/64 loss: 1.7425106763839722
Batch 53/64 loss: 1.7495307922363281
Batch 54/64 loss: 1.7474782466888428
Batch 55/64 loss: 1.744450330734253
Batch 56/64 loss: 1.7447493076324463
Batch 57/64 loss: 1.7417269945144653
Batch 58/64 loss: 1.7459003925323486
Batch 59/64 loss: 1.7403273582458496
Batch 60/64 loss: 1.746520757675171
Batch 61/64 loss: 1.7432769536972046
Batch 62/64 loss: 1.7460368871688843
Batch 63/64 loss: 1.7680280208587646
Batch 64/64 loss: 1.9388680458068848
Epoch 275  Train loss: 1.7449302729438334  Val loss: 1.764021521991061
Epoch 276
-------------------------------
Batch 1/64 loss: 1.7425694465637207
Batch 2/64 loss: 1.744459629058838
Batch 3/64 loss: 1.745933175086975
Batch 4/64 loss: 1.7463881969451904
Batch 5/64 loss: 1.7411162853240967
Batch 6/64 loss: 1.7444393634796143
Batch 7/64 loss: 1.7437976598739624
Batch 8/64 loss: 1.739815592765808
Batch 9/64 loss: 1.7406100034713745
Batch 10/64 loss: 1.7396204471588135
Batch 11/64 loss: 1.7426273822784424
Batch 12/64 loss: 1.7474431991577148
Batch 13/64 loss: 1.7423326969146729
Batch 14/64 loss: 1.743807315826416
Batch 15/64 loss: 1.7403497695922852
Batch 16/64 loss: 1.7424609661102295
Batch 17/64 loss: 1.7387444972991943
Batch 18/64 loss: 1.7363331317901611
Batch 19/64 loss: 1.740858793258667
Batch 20/64 loss: 1.7440210580825806
Batch 21/64 loss: 1.739274501800537
Batch 22/64 loss: 1.7395710945129395
Batch 23/64 loss: 1.7365055084228516
Batch 24/64 loss: 1.7361010313034058
Batch 25/64 loss: 1.7524765729904175
Batch 26/64 loss: 1.7363076210021973
Batch 27/64 loss: 1.736170768737793
Batch 28/64 loss: 1.7382689714431763
Batch 29/64 loss: 1.7403419017791748
Batch 30/64 loss: 1.7384264469146729
Batch 31/64 loss: 1.7410305738449097
Batch 32/64 loss: 1.7392022609710693
Batch 33/64 loss: 1.7407565116882324
Batch 34/64 loss: 1.740532636642456
Batch 35/64 loss: 1.7399513721466064
Batch 36/64 loss: 1.7620264291763306
Batch 37/64 loss: 1.7390923500061035
Batch 38/64 loss: 1.739766001701355
Batch 39/64 loss: 1.7399699687957764
Batch 40/64 loss: 1.7405644655227661
Batch 41/64 loss: 1.7379159927368164
Batch 42/64 loss: 1.7412104606628418
Batch 43/64 loss: 1.7364578247070312
Batch 44/64 loss: 1.764327049255371
Batch 45/64 loss: 1.7439379692077637
Batch 46/64 loss: 1.7379684448242188
Batch 47/64 loss: 1.7408666610717773
Batch 48/64 loss: 1.7377045154571533
Batch 49/64 loss: 1.740687370300293
Batch 50/64 loss: 1.7451550960540771
Batch 51/64 loss: 1.7418057918548584
Batch 52/64 loss: 1.7409803867340088
Batch 53/64 loss: 1.7379016876220703
Batch 54/64 loss: 1.73695969581604
Batch 55/64 loss: 1.7388455867767334
Batch 56/64 loss: 1.7445857524871826
Batch 57/64 loss: 1.741499900817871
Batch 58/64 loss: 1.7381150722503662
Batch 59/64 loss: 1.7468167543411255
Batch 60/64 loss: 1.735121726989746
Batch 61/64 loss: 1.7415368556976318
Batch 62/64 loss: 1.7388027906417847
Batch 63/64 loss: 1.7369141578674316
Batch 64/64 loss: 1.9220402240753174
Epoch 276  Train loss: 1.743556287241917  Val loss: 1.7601004965936196
Epoch 277
-------------------------------
Batch 1/64 loss: 1.7362500429153442
Batch 2/64 loss: 1.7368407249450684
Batch 3/64 loss: 1.7589881420135498
Batch 4/64 loss: 1.7425463199615479
Batch 5/64 loss: 1.736890435218811
Batch 6/64 loss: 1.7377219200134277
Batch 7/64 loss: 1.7383365631103516
Batch 8/64 loss: 1.7407169342041016
Batch 9/64 loss: 1.7430200576782227
Batch 10/64 loss: 1.740323781967163
Batch 11/64 loss: 1.7370219230651855
Batch 12/64 loss: 1.7404251098632812
Batch 13/64 loss: 1.740492820739746
Batch 14/64 loss: 1.7416969537734985
Batch 15/64 loss: 1.736357569694519
Batch 16/64 loss: 1.7447152137756348
Batch 17/64 loss: 1.7336671352386475
Batch 18/64 loss: 1.7393877506256104
Batch 19/64 loss: 1.7396211624145508
Batch 20/64 loss: 1.7486923933029175
Batch 21/64 loss: 1.7481255531311035
Batch 22/64 loss: 1.743104338645935
Batch 23/64 loss: 1.7413116693496704
Batch 24/64 loss: 1.7421104907989502
Batch 25/64 loss: 1.7402534484863281
Batch 26/64 loss: 1.7400262355804443
Batch 27/64 loss: 1.7432262897491455
Batch 28/64 loss: 1.7424898147583008
Batch 29/64 loss: 1.7440991401672363
Batch 30/64 loss: 1.737736701965332
Batch 31/64 loss: 1.745232105255127
Batch 32/64 loss: 1.7404080629348755
Batch 33/64 loss: 1.7397100925445557
Batch 34/64 loss: 1.741180658340454
Batch 35/64 loss: 1.7403790950775146
Batch 36/64 loss: 1.7377796173095703
Batch 37/64 loss: 1.7415447235107422
Batch 38/64 loss: 1.7399429082870483
Batch 39/64 loss: 1.7358379364013672
Batch 40/64 loss: 1.7517414093017578
Batch 41/64 loss: 1.7459566593170166
Batch 42/64 loss: 1.7366936206817627
Batch 43/64 loss: 1.7476458549499512
Batch 44/64 loss: 1.7435815334320068
Batch 45/64 loss: 1.7394115924835205
Batch 46/64 loss: 1.7549448013305664
Batch 47/64 loss: 1.7414683103561401
Batch 48/64 loss: 1.7497122287750244
Batch 49/64 loss: 1.7482945919036865
Batch 50/64 loss: 1.754450798034668
Batch 51/64 loss: 1.742240071296692
Batch 52/64 loss: 1.7398340702056885
Batch 53/64 loss: 1.7407336235046387
Batch 54/64 loss: 1.7405765056610107
Batch 55/64 loss: 1.7441158294677734
Batch 56/64 loss: 1.7593789100646973
Batch 57/64 loss: 1.7396793365478516
Batch 58/64 loss: 1.7432944774627686
Batch 59/64 loss: 1.7440979480743408
Batch 60/64 loss: 1.7385258674621582
Batch 61/64 loss: 1.7453815937042236
Batch 62/64 loss: 1.7417916059494019
Batch 63/64 loss: 1.7405486106872559
Batch 64/64 loss: 1.9294443130493164
Epoch 277  Train loss: 1.7446179595648075  Val loss: 1.7580308307896775
Epoch 278
-------------------------------
Batch 1/64 loss: 1.7443304061889648
Batch 2/64 loss: 1.7408592700958252
Batch 3/64 loss: 1.7373920679092407
Batch 4/64 loss: 1.7552571296691895
Batch 5/64 loss: 1.7391717433929443
Batch 6/64 loss: 1.7392321825027466
Batch 7/64 loss: 1.7415766716003418
Batch 8/64 loss: 1.7387783527374268
Batch 9/64 loss: 1.734886884689331
Batch 10/64 loss: 1.7375342845916748
Batch 11/64 loss: 1.7377750873565674
Batch 12/64 loss: 1.7386023998260498
Batch 13/64 loss: 1.7357158660888672
Batch 14/64 loss: 1.7345376014709473
Batch 15/64 loss: 1.7553377151489258
Batch 16/64 loss: 1.7451525926589966
Batch 17/64 loss: 1.741827130317688
Batch 18/64 loss: 1.7401909828186035
Batch 19/64 loss: 1.7429560422897339
Batch 20/64 loss: 1.7388088703155518
Batch 21/64 loss: 1.7411518096923828
Batch 22/64 loss: 1.7379740476608276
Batch 23/64 loss: 1.7382612228393555
Batch 24/64 loss: 1.7383627891540527
Batch 25/64 loss: 1.7376375198364258
Batch 26/64 loss: 1.7376441955566406
Batch 27/64 loss: 1.7394520044326782
Batch 28/64 loss: 1.737248182296753
Batch 29/64 loss: 1.7353297472000122
Batch 30/64 loss: 1.736983060836792
Batch 31/64 loss: 1.736534595489502
Batch 32/64 loss: 1.735302448272705
Batch 33/64 loss: 1.734622597694397
Batch 34/64 loss: 1.733696460723877
Batch 35/64 loss: 1.7346866130828857
Batch 36/64 loss: 1.741551399230957
Batch 37/64 loss: 1.7371203899383545
Batch 38/64 loss: 1.734372854232788
Batch 39/64 loss: 1.7337453365325928
Batch 40/64 loss: 1.7567298412322998
Batch 41/64 loss: 1.739466667175293
Batch 42/64 loss: 1.7354919910430908
Batch 43/64 loss: 1.7334041595458984
Batch 44/64 loss: 1.7361907958984375
Batch 45/64 loss: 1.7350561618804932
Batch 46/64 loss: 1.7508805990219116
Batch 47/64 loss: 1.7379560470581055
Batch 48/64 loss: 1.733508586883545
Batch 49/64 loss: 1.734635591506958
Batch 50/64 loss: 1.735985279083252
Batch 51/64 loss: 1.7342278957366943
Batch 52/64 loss: 1.7376692295074463
Batch 53/64 loss: 1.73893141746521
Batch 54/64 loss: 1.7332684993743896
Batch 55/64 loss: 1.7360178232192993
Batch 56/64 loss: 1.7406525611877441
Batch 57/64 loss: 1.7366021871566772
Batch 58/64 loss: 1.734743595123291
Batch 59/64 loss: 1.7369050979614258
Batch 60/64 loss: 1.7390289306640625
Batch 61/64 loss: 1.7374571561813354
Batch 62/64 loss: 1.73221755027771
Batch 63/64 loss: 1.7329981327056885
Batch 64/64 loss: 1.922421932220459
Epoch 278  Train loss: 1.7406030243518307  Val loss: 1.7545747756958008
Epoch 279
-------------------------------
Batch 1/64 loss: 1.7364587783813477
Batch 2/64 loss: 1.736180067062378
Batch 3/64 loss: 1.734001874923706
Batch 4/64 loss: 1.7352964878082275
Batch 5/64 loss: 1.737879991531372
Batch 6/64 loss: 1.7355308532714844
Batch 7/64 loss: 1.7378692626953125
Batch 8/64 loss: 1.7341914176940918
Batch 9/64 loss: 1.7441606521606445
Batch 10/64 loss: 1.744990348815918
Batch 11/64 loss: 1.7409271001815796
Batch 12/64 loss: 1.740565538406372
Batch 13/64 loss: 1.7420551776885986
Batch 14/64 loss: 1.7390154600143433
Batch 15/64 loss: 1.738476276397705
Batch 16/64 loss: 1.7592699527740479
Batch 17/64 loss: 1.7360728979110718
Batch 18/64 loss: 1.7404065132141113
Batch 19/64 loss: 1.73807692527771
Batch 20/64 loss: 1.7456905841827393
Batch 21/64 loss: 1.738182544708252
Batch 22/64 loss: 1.749348759651184
Batch 23/64 loss: 1.742836594581604
Batch 24/64 loss: 1.7478039264678955
Batch 25/64 loss: 1.7378945350646973
Batch 26/64 loss: 1.7425780296325684
Batch 27/64 loss: 1.7378625869750977
Batch 28/64 loss: 1.7458243370056152
Batch 29/64 loss: 1.73527193069458
Batch 30/64 loss: 1.7396785020828247
Batch 31/64 loss: 1.7410067319869995
Batch 32/64 loss: 1.7464370727539062
Batch 33/64 loss: 1.742499589920044
Batch 34/64 loss: 1.7480340003967285
Batch 35/64 loss: 1.7406973838806152
Batch 36/64 loss: 1.7451694011688232
Batch 37/64 loss: 1.743011713027954
Batch 38/64 loss: 1.738715410232544
Batch 39/64 loss: 1.7433892488479614
Batch 40/64 loss: 1.7459540367126465
Batch 41/64 loss: 1.7360093593597412
Batch 42/64 loss: 1.7586230039596558
Batch 43/64 loss: 1.7383010387420654
Batch 44/64 loss: 1.7400010824203491
Batch 45/64 loss: 1.7418626546859741
Batch 46/64 loss: 1.73732590675354
Batch 47/64 loss: 1.7353217601776123
Batch 48/64 loss: 1.7435754537582397
Batch 49/64 loss: 1.742034912109375
Batch 50/64 loss: 1.7366340160369873
Batch 51/64 loss: 1.7389819622039795
Batch 52/64 loss: 1.7394471168518066
Batch 53/64 loss: 1.7403737306594849
Batch 54/64 loss: 1.7379287481307983
Batch 55/64 loss: 1.735451579093933
Batch 56/64 loss: 1.7412428855895996
Batch 57/64 loss: 1.7381149530410767
Batch 58/64 loss: 1.7376457452774048
Batch 59/64 loss: 1.7393770217895508
Batch 60/64 loss: 1.7423157691955566
Batch 61/64 loss: 1.7377660274505615
Batch 62/64 loss: 1.7401059865951538
Batch 63/64 loss: 1.7424170970916748
Batch 64/64 loss: 1.936402440071106
Epoch 279  Train loss: 1.743097602152357  Val loss: 1.7637187770961487
Epoch 280
-------------------------------
Batch 1/64 loss: 1.7448967695236206
Batch 2/64 loss: 1.739866852760315
Batch 3/64 loss: 1.742302656173706
Batch 4/64 loss: 1.7399342060089111
Batch 5/64 loss: 1.7642707824707031
Batch 6/64 loss: 1.7430282831192017
Batch 7/64 loss: 1.744435429573059
Batch 8/64 loss: 1.7431707382202148
Batch 9/64 loss: 1.7391548156738281
Batch 10/64 loss: 1.7396939992904663
Batch 11/64 loss: 1.7390331029891968
Batch 12/64 loss: 1.7378513813018799
Batch 13/64 loss: 1.7372539043426514
Batch 14/64 loss: 1.7352919578552246
Batch 15/64 loss: 1.7361699342727661
Batch 16/64 loss: 1.7385252714157104
Batch 17/64 loss: 1.7351436614990234
Batch 18/64 loss: 1.7512372732162476
Batch 19/64 loss: 1.7379720211029053
Batch 20/64 loss: 1.7421643733978271
Batch 21/64 loss: 1.7367000579833984
Batch 22/64 loss: 1.739997386932373
Batch 23/64 loss: 1.7391505241394043
Batch 24/64 loss: 1.7388468980789185
Batch 25/64 loss: 1.7509500980377197
Batch 26/64 loss: 1.7386033535003662
Batch 27/64 loss: 1.7368013858795166
Batch 28/64 loss: 1.7434544563293457
Batch 29/64 loss: 1.7363770008087158
Batch 30/64 loss: 1.7422704696655273
Batch 31/64 loss: 1.7447521686553955
Batch 32/64 loss: 1.7437047958374023
Batch 33/64 loss: 1.7391247749328613
Batch 34/64 loss: 1.7362724542617798
Batch 35/64 loss: 1.74214768409729
Batch 36/64 loss: 1.741880178451538
Batch 37/64 loss: 1.7366386651992798
Batch 38/64 loss: 1.7375004291534424
Batch 39/64 loss: 1.7427570819854736
Batch 40/64 loss: 1.7372791767120361
Batch 41/64 loss: 1.738796591758728
Batch 42/64 loss: 1.7378818988800049
Batch 43/64 loss: 1.7340426445007324
Batch 44/64 loss: 1.7393085956573486
Batch 45/64 loss: 1.7384836673736572
Batch 46/64 loss: 1.7380273342132568
Batch 47/64 loss: 1.7415497303009033
Batch 48/64 loss: 1.735323429107666
Batch 49/64 loss: 1.741201639175415
Batch 50/64 loss: 1.7379777431488037
Batch 51/64 loss: 1.7464065551757812
Batch 52/64 loss: 1.7386531829833984
Batch 53/64 loss: 1.737662434577942
Batch 54/64 loss: 1.7355232238769531
Batch 55/64 loss: 1.7403018474578857
Batch 56/64 loss: 1.736998200416565
Batch 57/64 loss: 1.7395789623260498
Batch 58/64 loss: 1.737450122833252
Batch 59/64 loss: 1.732991337776184
Batch 60/64 loss: 1.737686038017273
Batch 61/64 loss: 1.7376080751419067
Batch 62/64 loss: 1.7383434772491455
Batch 63/64 loss: 1.7396881580352783
Batch 64/64 loss: 1.9206740856170654
Epoch 280  Train loss: 1.7420956377889596  Val loss: 1.7603273391723633
Epoch 281
-------------------------------
Batch 1/64 loss: 1.7362500429153442
Batch 2/64 loss: 1.754140853881836
Batch 3/64 loss: 1.732640266418457
Batch 4/64 loss: 1.7435013055801392
Batch 5/64 loss: 1.7409294843673706
Batch 6/64 loss: 1.7373255491256714
Batch 7/64 loss: 1.7384157180786133
Batch 8/64 loss: 1.7369564771652222
Batch 9/64 loss: 1.7360284328460693
Batch 10/64 loss: 1.7354142665863037
Batch 11/64 loss: 1.738649845123291
Batch 12/64 loss: 1.733907699584961
Batch 13/64 loss: 1.742354393005371
Batch 14/64 loss: 1.7344353199005127
Batch 15/64 loss: 1.7382409572601318
Batch 16/64 loss: 1.7391035556793213
Batch 17/64 loss: 1.7383567094802856
Batch 18/64 loss: 1.7387545108795166
Batch 19/64 loss: 1.736020803451538
Batch 20/64 loss: 1.7374341487884521
Batch 21/64 loss: 1.7398130893707275
Batch 22/64 loss: 1.7371187210083008
Batch 23/64 loss: 1.7401902675628662
Batch 24/64 loss: 1.7573904991149902
Batch 25/64 loss: 1.7369188070297241
Batch 26/64 loss: 1.745757818222046
Batch 27/64 loss: 1.7498576641082764
Batch 28/64 loss: 1.7391316890716553
Batch 29/64 loss: 1.7357456684112549
Batch 30/64 loss: 1.734250545501709
Batch 31/64 loss: 1.7393219470977783
Batch 32/64 loss: 1.7333972454071045
Batch 33/64 loss: 1.74015212059021
Batch 34/64 loss: 1.74076509475708
Batch 35/64 loss: 1.7365567684173584
Batch 36/64 loss: 1.7366278171539307
Batch 37/64 loss: 1.7355101108551025
Batch 38/64 loss: 1.7364290952682495
Batch 39/64 loss: 1.7410571575164795
Batch 40/64 loss: 1.7339249849319458
Batch 41/64 loss: 1.737007975578308
Batch 42/64 loss: 1.735923171043396
Batch 43/64 loss: 1.7394828796386719
Batch 44/64 loss: 1.7338383197784424
Batch 45/64 loss: 1.7337830066680908
Batch 46/64 loss: 1.7367208003997803
Batch 47/64 loss: 1.7378840446472168
Batch 48/64 loss: 1.734851598739624
Batch 49/64 loss: 1.7351417541503906
Batch 50/64 loss: 1.7379250526428223
Batch 51/64 loss: 1.7351889610290527
Batch 52/64 loss: 1.7340998649597168
Batch 53/64 loss: 1.7344493865966797
Batch 54/64 loss: 1.735969066619873
Batch 55/64 loss: 1.7365171909332275
Batch 56/64 loss: 1.734244704246521
Batch 57/64 loss: 1.7386879920959473
Batch 58/64 loss: 1.7371642589569092
Batch 59/64 loss: 1.7370798587799072
Batch 60/64 loss: 1.7345012426376343
Batch 61/64 loss: 1.7324824333190918
Batch 62/64 loss: 1.753402590751648
Batch 63/64 loss: 1.7369486093521118
Batch 64/64 loss: 1.9219069480895996
Epoch 281  Train loss: 1.7402902341356465  Val loss: 1.7526717693944978
Epoch 282
-------------------------------
Batch 1/64 loss: 1.7325499057769775
Batch 2/64 loss: 1.732027530670166
Batch 3/64 loss: 1.7330524921417236
Batch 4/64 loss: 1.732588529586792
Batch 5/64 loss: 1.7338967323303223
Batch 6/64 loss: 1.7349082231521606
Batch 7/64 loss: 1.7550920248031616
Batch 8/64 loss: 1.735480546951294
Batch 9/64 loss: 1.7421197891235352
Batch 10/64 loss: 1.737122893333435
Batch 11/64 loss: 1.7349390983581543
Batch 12/64 loss: 1.7377746105194092
Batch 13/64 loss: 1.7395299673080444
Batch 14/64 loss: 1.7353472709655762
Batch 15/64 loss: 1.7420703172683716
Batch 16/64 loss: 1.736460566520691
Batch 17/64 loss: 1.7385432720184326
Batch 18/64 loss: 1.7368617057800293
Batch 19/64 loss: 1.7389159202575684
Batch 20/64 loss: 1.7347397804260254
Batch 21/64 loss: 1.7326042652130127
Batch 22/64 loss: 1.735663890838623
Batch 23/64 loss: 1.7414195537567139
Batch 24/64 loss: 1.7465744018554688
Batch 25/64 loss: 1.741936206817627
Batch 26/64 loss: 1.7355607748031616
Batch 27/64 loss: 1.7425336837768555
Batch 28/64 loss: 1.7395195960998535
Batch 29/64 loss: 1.7361438274383545
Batch 30/64 loss: 1.733475923538208
Batch 31/64 loss: 1.7456949949264526
Batch 32/64 loss: 1.732677698135376
Batch 33/64 loss: 1.7416192293167114
Batch 34/64 loss: 1.7364872694015503
Batch 35/64 loss: 1.7361810207366943
Batch 36/64 loss: 1.7415168285369873
Batch 37/64 loss: 1.7352614402770996
Batch 38/64 loss: 1.7353131771087646
Batch 39/64 loss: 1.737318515777588
Batch 40/64 loss: 1.736098051071167
Batch 41/64 loss: 1.7314934730529785
Batch 42/64 loss: 1.739647388458252
Batch 43/64 loss: 1.7377361059188843
Batch 44/64 loss: 1.735567569732666
Batch 45/64 loss: 1.7364957332611084
Batch 46/64 loss: 1.7367181777954102
Batch 47/64 loss: 1.7386281490325928
Batch 48/64 loss: 1.7367768287658691
Batch 49/64 loss: 1.7389726638793945
Batch 50/64 loss: 1.7322421073913574
Batch 51/64 loss: 1.7351295948028564
Batch 52/64 loss: 1.734771966934204
Batch 53/64 loss: 1.7350471019744873
Batch 54/64 loss: 1.7374509572982788
Batch 55/64 loss: 1.7347230911254883
Batch 56/64 loss: 1.7420263290405273
Batch 57/64 loss: 1.741225242614746
Batch 58/64 loss: 1.7415478229522705
Batch 59/64 loss: 1.7415103912353516
Batch 60/64 loss: 1.7413159608840942
Batch 61/64 loss: 1.7369003295898438
Batch 62/64 loss: 1.7434289455413818
Batch 63/64 loss: 1.7518701553344727
Batch 64/64 loss: 1.926267385482788
Epoch 282  Train loss: 1.7401340886658314  Val loss: 1.756225088617646
Epoch 283
-------------------------------
Batch 1/64 loss: 1.746474027633667
Batch 2/64 loss: 1.7373443841934204
Batch 3/64 loss: 1.7398070096969604
Batch 4/64 loss: 1.7386672496795654
Batch 5/64 loss: 1.7401936054229736
Batch 6/64 loss: 1.7393782138824463
Batch 7/64 loss: 1.7372429370880127
Batch 8/64 loss: 1.7408390045166016
Batch 9/64 loss: 1.7361769676208496
Batch 10/64 loss: 1.7355401515960693
Batch 11/64 loss: 1.7335302829742432
Batch 12/64 loss: 1.7317960262298584
Batch 13/64 loss: 1.7357234954833984
Batch 14/64 loss: 1.7364776134490967
Batch 15/64 loss: 1.7348310947418213
Batch 16/64 loss: 1.733755111694336
Batch 17/64 loss: 1.735722541809082
Batch 18/64 loss: 1.737613558769226
Batch 19/64 loss: 1.7354629039764404
Batch 20/64 loss: 1.7338230609893799
Batch 21/64 loss: 1.7433879375457764
Batch 22/64 loss: 1.734691858291626
Batch 23/64 loss: 1.7567806243896484
Batch 24/64 loss: 1.7329907417297363
Batch 25/64 loss: 1.73410165309906
Batch 26/64 loss: 1.735084056854248
Batch 27/64 loss: 1.736424207687378
Batch 28/64 loss: 1.7348116636276245
Batch 29/64 loss: 1.732638955116272
Batch 30/64 loss: 1.736219048500061
Batch 31/64 loss: 1.7324168682098389
Batch 32/64 loss: 1.7409324645996094
Batch 33/64 loss: 1.7351384162902832
Batch 34/64 loss: 1.7363476753234863
Batch 35/64 loss: 1.7379157543182373
Batch 36/64 loss: 1.735503911972046
Batch 37/64 loss: 1.7339742183685303
Batch 38/64 loss: 1.7383363246917725
Batch 39/64 loss: 1.7306606769561768
Batch 40/64 loss: 1.73452889919281
Batch 41/64 loss: 1.731008529663086
Batch 42/64 loss: 1.7313096523284912
Batch 43/64 loss: 1.733928918838501
Batch 44/64 loss: 1.7348902225494385
Batch 45/64 loss: 1.7342987060546875
Batch 46/64 loss: 1.7336373329162598
Batch 47/64 loss: 1.7310550212860107
Batch 48/64 loss: 1.7383699417114258
Batch 49/64 loss: 1.7382514476776123
Batch 50/64 loss: 1.7476509809494019
Batch 51/64 loss: 1.7344800233840942
Batch 52/64 loss: 1.735410213470459
Batch 53/64 loss: 1.7322344779968262
Batch 54/64 loss: 1.758913278579712
Batch 55/64 loss: 1.736898422241211
Batch 56/64 loss: 1.735041618347168
Batch 57/64 loss: 1.7452468872070312
Batch 58/64 loss: 1.7360931634902954
Batch 59/64 loss: 1.7414785623550415
Batch 60/64 loss: 1.741981029510498
Batch 61/64 loss: 1.740626573562622
Batch 62/64 loss: 1.7396039962768555
Batch 63/64 loss: 1.7389514446258545
Batch 64/64 loss: 1.9261423349380493
Epoch 283  Train loss: 1.739439253246083  Val loss: 1.75270372403856
Epoch 284
-------------------------------
Batch 1/64 loss: 1.734598159790039
Batch 2/64 loss: 1.734913945198059
Batch 3/64 loss: 1.739387035369873
Batch 4/64 loss: 1.7405927181243896
Batch 5/64 loss: 1.7347545623779297
Batch 6/64 loss: 1.7487502098083496
Batch 7/64 loss: 1.7342329025268555
Batch 8/64 loss: 1.7349492311477661
Batch 9/64 loss: 1.734276294708252
Batch 10/64 loss: 1.740628957748413
Batch 11/64 loss: 1.7352080345153809
Batch 12/64 loss: 1.733708143234253
Batch 13/64 loss: 1.731024980545044
Batch 14/64 loss: 1.7316476106643677
Batch 15/64 loss: 1.7326040267944336
Batch 16/64 loss: 1.7356679439544678
Batch 17/64 loss: 1.7330763339996338
Batch 18/64 loss: 1.733838438987732
Batch 19/64 loss: 1.7337672710418701
Batch 20/64 loss: 1.7327992916107178
Batch 21/64 loss: 1.732771873474121
Batch 22/64 loss: 1.7363955974578857
Batch 23/64 loss: 1.7342463731765747
Batch 24/64 loss: 1.7345874309539795
Batch 25/64 loss: 1.7301585674285889
Batch 26/64 loss: 1.7444106340408325
Batch 27/64 loss: 1.7334930896759033
Batch 28/64 loss: 1.7336065769195557
Batch 29/64 loss: 1.732515573501587
Batch 30/64 loss: 1.7368484735488892
Batch 31/64 loss: 1.7338356971740723
Batch 32/64 loss: 1.7319023609161377
Batch 33/64 loss: 1.7348557710647583
Batch 34/64 loss: 1.7346429824829102
Batch 35/64 loss: 1.7336335182189941
Batch 36/64 loss: 1.732317566871643
Batch 37/64 loss: 1.7364704608917236
Batch 38/64 loss: 1.7364742755889893
Batch 39/64 loss: 1.7368673086166382
Batch 40/64 loss: 1.7321773767471313
Batch 41/64 loss: 1.7319839000701904
Batch 42/64 loss: 1.7358293533325195
Batch 43/64 loss: 1.7364964485168457
Batch 44/64 loss: 1.7428903579711914
Batch 45/64 loss: 1.7352571487426758
Batch 46/64 loss: 1.7374976873397827
Batch 47/64 loss: 1.7414275407791138
Batch 48/64 loss: 1.7341656684875488
Batch 49/64 loss: 1.7385497093200684
Batch 50/64 loss: 1.7366689443588257
Batch 51/64 loss: 1.7342886924743652
Batch 52/64 loss: 1.7335703372955322
Batch 53/64 loss: 1.7464267015457153
Batch 54/64 loss: 1.7509143352508545
Batch 55/64 loss: 1.7370364665985107
Batch 56/64 loss: 1.7357921600341797
Batch 57/64 loss: 1.7407475709915161
Batch 58/64 loss: 1.7316107749938965
Batch 59/64 loss: 1.730952262878418
Batch 60/64 loss: 1.7318594455718994
Batch 61/64 loss: 1.7308697700500488
Batch 62/64 loss: 1.7321223020553589
Batch 63/64 loss: 1.7349207401275635
Batch 64/64 loss: 1.9222581386566162
Epoch 284  Train loss: 1.737822894489064  Val loss: 1.7550577052270424
Epoch 285
-------------------------------
Batch 1/64 loss: 1.7341580390930176
Batch 2/64 loss: 1.7350142002105713
Batch 3/64 loss: 1.7342872619628906
Batch 4/64 loss: 1.7325661182403564
Batch 5/64 loss: 1.7322726249694824
Batch 6/64 loss: 1.7348058223724365
Batch 7/64 loss: 1.7347228527069092
Batch 8/64 loss: 1.7390508651733398
Batch 9/64 loss: 1.7468013763427734
Batch 10/64 loss: 1.7328304052352905
Batch 11/64 loss: 1.7384825944900513
Batch 12/64 loss: 1.7360069751739502
Batch 13/64 loss: 1.7309777736663818
Batch 14/64 loss: 1.7328003644943237
Batch 15/64 loss: 1.733870029449463
Batch 16/64 loss: 1.7502200603485107
Batch 17/64 loss: 1.735431432723999
Batch 18/64 loss: 1.7333683967590332
Batch 19/64 loss: 1.738849401473999
Batch 20/64 loss: 1.7418208122253418
Batch 21/64 loss: 1.7372643947601318
Batch 22/64 loss: 1.7338536977767944
Batch 23/64 loss: 1.734504222869873
Batch 24/64 loss: 1.7333691120147705
Batch 25/64 loss: 1.7358968257904053
Batch 26/64 loss: 1.743216633796692
Batch 27/64 loss: 1.7349867820739746
Batch 28/64 loss: 1.7392702102661133
Batch 29/64 loss: 1.7332243919372559
Batch 30/64 loss: 1.7343751192092896
Batch 31/64 loss: 1.7351692914962769
Batch 32/64 loss: 1.7312217950820923
Batch 33/64 loss: 1.735579252243042
Batch 34/64 loss: 1.738072395324707
Batch 35/64 loss: 1.7332185506820679
Batch 36/64 loss: 1.7421947717666626
Batch 37/64 loss: 1.7339880466461182
Batch 38/64 loss: 1.7340478897094727
Batch 39/64 loss: 1.7327537536621094
Batch 40/64 loss: 1.7325042486190796
Batch 41/64 loss: 1.7334495782852173
Batch 42/64 loss: 1.7356579303741455
Batch 43/64 loss: 1.7338380813598633
Batch 44/64 loss: 1.736351490020752
Batch 45/64 loss: 1.745378017425537
Batch 46/64 loss: 1.7386789321899414
Batch 47/64 loss: 1.7378839254379272
Batch 48/64 loss: 1.7337968349456787
Batch 49/64 loss: 1.734423279762268
Batch 50/64 loss: 1.7368171215057373
Batch 51/64 loss: 1.73313307762146
Batch 52/64 loss: 1.7345513105392456
Batch 53/64 loss: 1.7318278551101685
Batch 54/64 loss: 1.73569917678833
Batch 55/64 loss: 1.7314188480377197
Batch 56/64 loss: 1.7346889972686768
Batch 57/64 loss: 1.7332777976989746
Batch 58/64 loss: 1.7307891845703125
Batch 59/64 loss: 1.7334589958190918
Batch 60/64 loss: 1.733638882637024
Batch 61/64 loss: 1.7374083995819092
Batch 62/64 loss: 1.736796259880066
Batch 63/64 loss: 1.733374834060669
Batch 64/64 loss: 1.9163248538970947
Epoch 285  Train loss: 1.7377353920656091  Val loss: 1.7509641352388048
Saving best model, epoch: 285
Epoch 286
-------------------------------
Batch 1/64 loss: 1.7362364530563354
Batch 2/64 loss: 1.7349743843078613
Batch 3/64 loss: 1.7336143255233765
Batch 4/64 loss: 1.7316694259643555
Batch 5/64 loss: 1.7361900806427002
Batch 6/64 loss: 1.7359552383422852
Batch 7/64 loss: 1.7328803539276123
Batch 8/64 loss: 1.7339932918548584
Batch 9/64 loss: 1.7323541641235352
Batch 10/64 loss: 1.7466039657592773
Batch 11/64 loss: 1.7423160076141357
Batch 12/64 loss: 1.7327969074249268
Batch 13/64 loss: 1.7337450981140137
Batch 14/64 loss: 1.732017159461975
Batch 15/64 loss: 1.731382966041565
Batch 16/64 loss: 1.7322032451629639
Batch 17/64 loss: 1.7381925582885742
Batch 18/64 loss: 1.7336291074752808
Batch 19/64 loss: 1.7325310707092285
Batch 20/64 loss: 1.7330495119094849
Batch 21/64 loss: 1.751551866531372
Batch 22/64 loss: 1.734965205192566
Batch 23/64 loss: 1.7359118461608887
Batch 24/64 loss: 1.7370288372039795
Batch 25/64 loss: 1.7412910461425781
Batch 26/64 loss: 1.7341388463974
Batch 27/64 loss: 1.7377405166625977
Batch 28/64 loss: 1.7378489971160889
Batch 29/64 loss: 1.7374619245529175
Batch 30/64 loss: 1.736077070236206
Batch 31/64 loss: 1.7393438816070557
Batch 32/64 loss: 1.7377128601074219
Batch 33/64 loss: 1.7377372980117798
Batch 34/64 loss: 1.73760187625885
Batch 35/64 loss: 1.7361966371536255
Batch 36/64 loss: 1.737022876739502
Batch 37/64 loss: 1.7380919456481934
Batch 38/64 loss: 1.7326807975769043
Batch 39/64 loss: 1.7371784448623657
Batch 40/64 loss: 1.7369334697723389
Batch 41/64 loss: 1.73435378074646
Batch 42/64 loss: 1.7330141067504883
Batch 43/64 loss: 1.7366305589675903
Batch 44/64 loss: 1.7338576316833496
Batch 45/64 loss: 1.7365562915802002
Batch 46/64 loss: 1.7366992235183716
Batch 47/64 loss: 1.7401565313339233
Batch 48/64 loss: 1.7324076890945435
Batch 49/64 loss: 1.7389864921569824
Batch 50/64 loss: 1.735642910003662
Batch 51/64 loss: 1.7368104457855225
Batch 52/64 loss: 1.7338929176330566
Batch 53/64 loss: 1.7426611185073853
Batch 54/64 loss: 1.7328050136566162
Batch 55/64 loss: 1.7511136531829834
Batch 56/64 loss: 1.7385356426239014
Batch 57/64 loss: 1.7333409786224365
Batch 58/64 loss: 1.735156536102295
Batch 59/64 loss: 1.7369581460952759
Batch 60/64 loss: 1.7346246242523193
Batch 61/64 loss: 1.737707257270813
Batch 62/64 loss: 1.735461950302124
Batch 63/64 loss: 1.7352781295776367
Batch 64/64 loss: 1.9235162734985352
Epoch 286  Train loss: 1.738606123830758  Val loss: 1.7547478053168333
Epoch 287
-------------------------------
Batch 1/64 loss: 1.734806776046753
Batch 2/64 loss: 1.7389874458312988
Batch 3/64 loss: 1.7374703884124756
Batch 4/64 loss: 1.737046241760254
Batch 5/64 loss: 1.735443353652954
Batch 6/64 loss: 1.7356504201889038
Batch 7/64 loss: 1.7381277084350586
Batch 8/64 loss: 1.7383564710617065
Batch 9/64 loss: 1.7355785369873047
Batch 10/64 loss: 1.7353582382202148
Batch 11/64 loss: 1.737068772315979
Batch 12/64 loss: 1.735406756401062
Batch 13/64 loss: 1.7415273189544678
Batch 14/64 loss: 1.7381770610809326
Batch 15/64 loss: 1.7410765886306763
Batch 16/64 loss: 1.7348229885101318
Batch 17/64 loss: 1.738490104675293
Batch 18/64 loss: 1.7328100204467773
Batch 19/64 loss: 1.743814468383789
Batch 20/64 loss: 1.7415666580200195
Batch 21/64 loss: 1.7377500534057617
Batch 22/64 loss: 1.7389154434204102
Batch 23/64 loss: 1.7380616664886475
Batch 24/64 loss: 1.736628770828247
Batch 25/64 loss: 1.7397584915161133
Batch 26/64 loss: 1.7385451793670654
Batch 27/64 loss: 1.7366864681243896
Batch 28/64 loss: 1.7392420768737793
Batch 29/64 loss: 1.7395752668380737
Batch 30/64 loss: 1.734144687652588
Batch 31/64 loss: 1.7333402633666992
Batch 32/64 loss: 1.7415282726287842
Batch 33/64 loss: 1.7329213619232178
Batch 34/64 loss: 1.7395644187927246
Batch 35/64 loss: 1.7323286533355713
Batch 36/64 loss: 1.7318211793899536
Batch 37/64 loss: 1.7501940727233887
Batch 38/64 loss: 1.735291600227356
Batch 39/64 loss: 1.738577127456665
Batch 40/64 loss: 1.734900951385498
Batch 41/64 loss: 1.730938196182251
Batch 42/64 loss: 1.7351200580596924
Batch 43/64 loss: 1.732790231704712
Batch 44/64 loss: 1.732792615890503
Batch 45/64 loss: 1.7364329099655151
Batch 46/64 loss: 1.734745979309082
Batch 47/64 loss: 1.7379382848739624
Batch 48/64 loss: 1.7319560050964355
Batch 49/64 loss: 1.7335137128829956
Batch 50/64 loss: 1.7359323501586914
Batch 51/64 loss: 1.7331899404525757
Batch 52/64 loss: 1.7362550497055054
Batch 53/64 loss: 1.7396751642227173
Batch 54/64 loss: 1.7358946800231934
Batch 55/64 loss: 1.7361054420471191
Batch 56/64 loss: 1.7374361753463745
Batch 57/64 loss: 1.7352654933929443
Batch 58/64 loss: 1.7368712425231934
Batch 59/64 loss: 1.7438135147094727
Batch 60/64 loss: 1.7365126609802246
Batch 61/64 loss: 1.7453314065933228
Batch 62/64 loss: 1.740457534790039
Batch 63/64 loss: 1.7347052097320557
Batch 64/64 loss: 1.9227375984191895
Epoch 287  Train loss: 1.7392484608818504  Val loss: 1.7512943146564706
Epoch 288
-------------------------------
Batch 1/64 loss: 1.7331844568252563
Batch 2/64 loss: 1.7376201152801514
Batch 3/64 loss: 1.7332088947296143
Batch 4/64 loss: 1.7329092025756836
Batch 5/64 loss: 1.7416253089904785
Batch 6/64 loss: 1.7334802150726318
Batch 7/64 loss: 1.7379522323608398
Batch 8/64 loss: 1.733017921447754
Batch 9/64 loss: 1.7327296733856201
Batch 10/64 loss: 1.7380027770996094
Batch 11/64 loss: 1.7340102195739746
Batch 12/64 loss: 1.734823226928711
Batch 13/64 loss: 1.7339887619018555
Batch 14/64 loss: 1.7328495979309082
Batch 15/64 loss: 1.7328643798828125
Batch 16/64 loss: 1.7426698207855225
Batch 17/64 loss: 1.7361855506896973
Batch 18/64 loss: 1.7464756965637207
Batch 19/64 loss: 1.7335903644561768
Batch 20/64 loss: 1.7339301109313965
Batch 21/64 loss: 1.7343418598175049
Batch 22/64 loss: 1.7373626232147217
Batch 23/64 loss: 1.7361087799072266
Batch 24/64 loss: 1.7346609830856323
Batch 25/64 loss: 1.7368699312210083
Batch 26/64 loss: 1.7375426292419434
Batch 27/64 loss: 1.7332472801208496
Batch 28/64 loss: 1.739867091178894
Batch 29/64 loss: 1.7361273765563965
Batch 30/64 loss: 1.7369234561920166
Batch 31/64 loss: 1.7358732223510742
Batch 32/64 loss: 1.7369194030761719
Batch 33/64 loss: 1.7403024435043335
Batch 34/64 loss: 1.7448363304138184
Batch 35/64 loss: 1.7335659265518188
Batch 36/64 loss: 1.7361116409301758
Batch 37/64 loss: 1.7349119186401367
Batch 38/64 loss: 1.7382203340530396
Batch 39/64 loss: 1.735206127166748
Batch 40/64 loss: 1.7327988147735596
Batch 41/64 loss: 1.7358994483947754
Batch 42/64 loss: 1.7321102619171143
Batch 43/64 loss: 1.7537260055541992
Batch 44/64 loss: 1.737863540649414
Batch 45/64 loss: 1.7359529733657837
Batch 46/64 loss: 1.736210823059082
Batch 47/64 loss: 1.7355690002441406
Batch 48/64 loss: 1.7321358919143677
Batch 49/64 loss: 1.7345020771026611
Batch 50/64 loss: 1.7347124814987183
Batch 51/64 loss: 1.7350568771362305
Batch 52/64 loss: 1.7340543270111084
Batch 53/64 loss: 1.736795425415039
Batch 54/64 loss: 1.730787992477417
Batch 55/64 loss: 1.735408067703247
Batch 56/64 loss: 1.733410120010376
Batch 57/64 loss: 1.7320263385772705
Batch 58/64 loss: 1.7370312213897705
Batch 59/64 loss: 1.7356207370758057
Batch 60/64 loss: 1.7372486591339111
Batch 61/64 loss: 1.7390618324279785
Batch 62/64 loss: 1.7350163459777832
Batch 63/64 loss: 1.734344482421875
Batch 64/64 loss: 1.916924238204956
Epoch 288  Train loss: 1.7381828205258238  Val loss: 1.752263717225327
Epoch 289
-------------------------------
Batch 1/64 loss: 1.7355374097824097
Batch 2/64 loss: 1.7322185039520264
Batch 3/64 loss: 1.736020565032959
Batch 4/64 loss: 1.743236780166626
Batch 5/64 loss: 1.7314636707305908
Batch 6/64 loss: 1.736665964126587
Batch 7/64 loss: 1.7330142259597778
Batch 8/64 loss: 1.735518455505371
Batch 9/64 loss: 1.7297050952911377
Batch 10/64 loss: 1.7338584661483765
Batch 11/64 loss: 1.7329916954040527
Batch 12/64 loss: 1.734206199645996
Batch 13/64 loss: 1.7338134050369263
Batch 14/64 loss: 1.7323778867721558
Batch 15/64 loss: 1.7362098693847656
Batch 16/64 loss: 1.7359633445739746
Batch 17/64 loss: 1.734419345855713
Batch 18/64 loss: 1.7351090908050537
Batch 19/64 loss: 1.7366222143173218
Batch 20/64 loss: 1.736283302307129
Batch 21/64 loss: 1.7332165241241455
Batch 22/64 loss: 1.7497029304504395
Batch 23/64 loss: 1.7507193088531494
Batch 24/64 loss: 1.7305842638015747
Batch 25/64 loss: 1.7311078310012817
Batch 26/64 loss: 1.735075831413269
Batch 27/64 loss: 1.7334632873535156
Batch 28/64 loss: 1.7322579622268677
Batch 29/64 loss: 1.7331955432891846
Batch 30/64 loss: 1.733018159866333
Batch 31/64 loss: 1.7334555387496948
Batch 32/64 loss: 1.7375470399856567
Batch 33/64 loss: 1.7354302406311035
Batch 34/64 loss: 1.7315828800201416
Batch 35/64 loss: 1.7393862009048462
Batch 36/64 loss: 1.732680320739746
Batch 37/64 loss: 1.7346611022949219
Batch 38/64 loss: 1.7345619201660156
Batch 39/64 loss: 1.7357430458068848
Batch 40/64 loss: 1.7341856956481934
Batch 41/64 loss: 1.7348182201385498
Batch 42/64 loss: 1.7375409603118896
Batch 43/64 loss: 1.7336318492889404
Batch 44/64 loss: 1.7326338291168213
Batch 45/64 loss: 1.7365200519561768
Batch 46/64 loss: 1.7393052577972412
Batch 47/64 loss: 1.7323503494262695
Batch 48/64 loss: 1.7366297245025635
Batch 49/64 loss: 1.731334924697876
Batch 50/64 loss: 1.7382166385650635
Batch 51/64 loss: 1.7334458827972412
Batch 52/64 loss: 1.7326067686080933
Batch 53/64 loss: 1.7378828525543213
Batch 54/64 loss: 1.7389552593231201
Batch 55/64 loss: 1.735039234161377
Batch 56/64 loss: 1.73783540725708
Batch 57/64 loss: 1.735224723815918
Batch 58/64 loss: 1.731673240661621
Batch 59/64 loss: 1.7334511280059814
Batch 60/64 loss: 1.735077977180481
Batch 61/64 loss: 1.735290288925171
Batch 62/64 loss: 1.7401049137115479
Batch 63/64 loss: 1.7348082065582275
Batch 64/64 loss: 1.9202666282653809
Epoch 289  Train loss: 1.7374335494695925  Val loss: 1.7529511222314997
Epoch 290
-------------------------------
Batch 1/64 loss: 1.731400489807129
Batch 2/64 loss: 1.7361425161361694
Batch 3/64 loss: 1.7339259386062622
Batch 4/64 loss: 1.7382397651672363
Batch 5/64 loss: 1.7367708683013916
Batch 6/64 loss: 1.7368254661560059
Batch 7/64 loss: 1.7361501455307007
Batch 8/64 loss: 1.7328624725341797
Batch 9/64 loss: 1.7327487468719482
Batch 10/64 loss: 1.7374452352523804
Batch 11/64 loss: 1.7352099418640137
Batch 12/64 loss: 1.73845636844635
Batch 13/64 loss: 1.7363173961639404
Batch 14/64 loss: 1.7358002662658691
Batch 15/64 loss: 1.7358129024505615
Batch 16/64 loss: 1.7530512809753418
Batch 17/64 loss: 1.7328253984451294
Batch 18/64 loss: 1.7329480648040771
Batch 19/64 loss: 1.7340060472488403
Batch 20/64 loss: 1.7345609664916992
Batch 21/64 loss: 1.7377713918685913
Batch 22/64 loss: 1.7334554195404053
Batch 23/64 loss: 1.7318452596664429
Batch 24/64 loss: 1.7321690320968628
Batch 25/64 loss: 1.7343995571136475
Batch 26/64 loss: 1.7311047315597534
Batch 27/64 loss: 1.7363605499267578
Batch 28/64 loss: 1.7372292280197144
Batch 29/64 loss: 1.7307794094085693
Batch 30/64 loss: 1.7355918884277344
Batch 31/64 loss: 1.7352834939956665
Batch 32/64 loss: 1.73138427734375
Batch 33/64 loss: 1.7344989776611328
Batch 34/64 loss: 1.7350692749023438
Batch 35/64 loss: 1.734787940979004
Batch 36/64 loss: 1.740213394165039
Batch 37/64 loss: 1.7344017028808594
Batch 38/64 loss: 1.7395788431167603
Batch 39/64 loss: 1.7334649562835693
Batch 40/64 loss: 1.7376282215118408
Batch 41/64 loss: 1.7353436946868896
Batch 42/64 loss: 1.7365121841430664
Batch 43/64 loss: 1.7332491874694824
Batch 44/64 loss: 1.7362267971038818
Batch 45/64 loss: 1.7342522144317627
Batch 46/64 loss: 1.764955759048462
Batch 47/64 loss: 1.7375332117080688
Batch 48/64 loss: 1.7319884300231934
Batch 49/64 loss: 1.7398557662963867
Batch 50/64 loss: 1.7320137023925781
Batch 51/64 loss: 1.7402958869934082
Batch 52/64 loss: 1.7323484420776367
Batch 53/64 loss: 1.7360115051269531
Batch 54/64 loss: 1.7294723987579346
Batch 55/64 loss: 1.73569917678833
Batch 56/64 loss: 1.7352566719055176
Batch 57/64 loss: 1.7368003129959106
Batch 58/64 loss: 1.7353787422180176
Batch 59/64 loss: 1.7390685081481934
Batch 60/64 loss: 1.7347192764282227
Batch 61/64 loss: 1.738045334815979
Batch 62/64 loss: 1.7325825691223145
Batch 63/64 loss: 1.7351943254470825
Batch 64/64 loss: 1.9198415279388428
Epoch 290  Train loss: 1.7380580874050364  Val loss: 1.7529827737316643
Epoch 291
-------------------------------
Batch 1/64 loss: 1.7376506328582764
Batch 2/64 loss: 1.7356579303741455
Batch 3/64 loss: 1.7350976467132568
Batch 4/64 loss: 1.736783742904663
Batch 5/64 loss: 1.739063024520874
Batch 6/64 loss: 1.7369412183761597
Batch 7/64 loss: 1.7391375303268433
Batch 8/64 loss: 1.738027811050415
Batch 9/64 loss: 1.7388098239898682
Batch 10/64 loss: 1.7461563348770142
Batch 11/64 loss: 1.741385817527771
Batch 12/64 loss: 1.742742896080017
Batch 13/64 loss: 1.7381749153137207
Batch 14/64 loss: 1.7382559776306152
Batch 15/64 loss: 1.7357224225997925
Batch 16/64 loss: 1.747715711593628
Batch 17/64 loss: 1.7427868843078613
Batch 18/64 loss: 1.7392926216125488
Batch 19/64 loss: 1.7485114336013794
Batch 20/64 loss: 1.7392938137054443
Batch 21/64 loss: 1.7469282150268555
Batch 22/64 loss: 1.7538549900054932
Batch 23/64 loss: 1.7418113946914673
Batch 24/64 loss: 1.7380287647247314
Batch 25/64 loss: 1.7413955926895142
Batch 26/64 loss: 1.7352213859558105
Batch 27/64 loss: 1.7573716640472412
Batch 28/64 loss: 1.7638767957687378
Batch 29/64 loss: 1.7381377220153809
Batch 30/64 loss: 1.739595651626587
Batch 31/64 loss: 1.7379238605499268
Batch 32/64 loss: 1.7409236431121826
Batch 33/64 loss: 1.738316535949707
Batch 34/64 loss: 1.7340126037597656
Batch 35/64 loss: 1.7390472888946533
Batch 36/64 loss: 1.7377400398254395
Batch 37/64 loss: 1.7364156246185303
Batch 38/64 loss: 1.7372846603393555
Batch 39/64 loss: 1.737053394317627
Batch 40/64 loss: 1.7374283075332642
Batch 41/64 loss: 1.7389508485794067
Batch 42/64 loss: 1.7370269298553467
Batch 43/64 loss: 1.73117196559906
Batch 44/64 loss: 1.736177921295166
Batch 45/64 loss: 1.7555656433105469
Batch 46/64 loss: 1.7379333972930908
Batch 47/64 loss: 1.7345341444015503
Batch 48/64 loss: 1.7376470565795898
Batch 49/64 loss: 1.7358250617980957
Batch 50/64 loss: 1.7337274551391602
Batch 51/64 loss: 1.7432940006256104
Batch 52/64 loss: 1.7349951267242432
Batch 53/64 loss: 1.7383604049682617
Batch 54/64 loss: 1.7389721870422363
Batch 55/64 loss: 1.7379980087280273
Batch 56/64 loss: 1.736973524093628
Batch 57/64 loss: 1.7364051342010498
Batch 58/64 loss: 1.7354207038879395
Batch 59/64 loss: 1.733661413192749
Batch 60/64 loss: 1.735490322113037
Batch 61/64 loss: 1.7337409257888794
Batch 62/64 loss: 1.7326302528381348
Batch 63/64 loss: 1.7350146770477295
Batch 64/64 loss: 1.918454647064209
Epoch 291  Train loss: 1.7414891673069375  Val loss: 1.7522663488420833
Epoch 292
-------------------------------
Batch 1/64 loss: 1.742963433265686
Batch 2/64 loss: 1.7346129417419434
Batch 3/64 loss: 1.7334505319595337
Batch 4/64 loss: 1.733764410018921
Batch 5/64 loss: 1.7372291088104248
Batch 6/64 loss: 1.733492374420166
Batch 7/64 loss: 1.735978126525879
Batch 8/64 loss: 1.730664610862732
Batch 9/64 loss: 1.735635757446289
Batch 10/64 loss: 1.7338292598724365
Batch 11/64 loss: 1.7325809001922607
Batch 12/64 loss: 1.7356133460998535
Batch 13/64 loss: 1.7345582246780396
Batch 14/64 loss: 1.7322953939437866
Batch 15/64 loss: 1.734269380569458
Batch 16/64 loss: 1.7325081825256348
Batch 17/64 loss: 1.730839729309082
Batch 18/64 loss: 1.7345826625823975
Batch 19/64 loss: 1.7324872016906738
Batch 20/64 loss: 1.7345279455184937
Batch 21/64 loss: 1.7331156730651855
Batch 22/64 loss: 1.7324154376983643
Batch 23/64 loss: 1.7317302227020264
Batch 24/64 loss: 1.7309744358062744
Batch 25/64 loss: 1.7385790348052979
Batch 26/64 loss: 1.7319002151489258
Batch 27/64 loss: 1.7334975004196167
Batch 28/64 loss: 1.735119104385376
Batch 29/64 loss: 1.7462587356567383
Batch 30/64 loss: 1.7398183345794678
Batch 31/64 loss: 1.7358776330947876
Batch 32/64 loss: 1.7367513179779053
Batch 33/64 loss: 1.7329216003417969
Batch 34/64 loss: 1.7372018098831177
Batch 35/64 loss: 1.7363543510437012
Batch 36/64 loss: 1.7350611686706543
Batch 37/64 loss: 1.7352197170257568
Batch 38/64 loss: 1.7325031757354736
Batch 39/64 loss: 1.7363340854644775
Batch 40/64 loss: 1.7344727516174316
Batch 41/64 loss: 1.7359404563903809
Batch 42/64 loss: 1.7462207078933716
Batch 43/64 loss: 1.7341370582580566
Batch 44/64 loss: 1.7319773435592651
Batch 45/64 loss: 1.735300064086914
Batch 46/64 loss: 1.736504077911377
Batch 47/64 loss: 1.7457996606826782
Batch 48/64 loss: 1.7349298000335693
Batch 49/64 loss: 1.7372369766235352
Batch 50/64 loss: 1.734230399131775
Batch 51/64 loss: 1.7506542205810547
Batch 52/64 loss: 1.7317497730255127
Batch 53/64 loss: 1.736860990524292
Batch 54/64 loss: 1.7352397441864014
Batch 55/64 loss: 1.736777901649475
Batch 56/64 loss: 1.7348403930664062
Batch 57/64 loss: 1.7341856956481934
Batch 58/64 loss: 1.7409234046936035
Batch 59/64 loss: 1.735923171043396
Batch 60/64 loss: 1.7320306301116943
Batch 61/64 loss: 1.7368892431259155
Batch 62/64 loss: 1.7349789142608643
Batch 63/64 loss: 1.7349128723144531
Batch 64/64 loss: 1.9240731000900269
Epoch 292  Train loss: 1.7377770690356984  Val loss: 1.7529187087750517
Epoch 293
-------------------------------
Batch 1/64 loss: 1.733708143234253
Batch 2/64 loss: 1.7382044792175293
Batch 3/64 loss: 1.7326438426971436
Batch 4/64 loss: 1.728809118270874
Batch 5/64 loss: 1.7445383071899414
Batch 6/64 loss: 1.7336034774780273
Batch 7/64 loss: 1.7348260879516602
Batch 8/64 loss: 1.736434817314148
Batch 9/64 loss: 1.7357666492462158
Batch 10/64 loss: 1.7347204685211182
Batch 11/64 loss: 1.7481328248977661
Batch 12/64 loss: 1.7331204414367676
Batch 13/64 loss: 1.7379295825958252
Batch 14/64 loss: 1.7351047992706299
Batch 15/64 loss: 1.7346336841583252
Batch 16/64 loss: 1.745168924331665
Batch 17/64 loss: 1.7390704154968262
Batch 18/64 loss: 1.7321598529815674
Batch 19/64 loss: 1.7325915098190308
Batch 20/64 loss: 1.7350701093673706
Batch 21/64 loss: 1.7366008758544922
Batch 22/64 loss: 1.735870599746704
Batch 23/64 loss: 1.7404968738555908
Batch 24/64 loss: 1.7352638244628906
Batch 25/64 loss: 1.733182430267334
Batch 26/64 loss: 1.7348707914352417
Batch 27/64 loss: 1.7348153591156006
Batch 28/64 loss: 1.7371525764465332
Batch 29/64 loss: 1.7376255989074707
Batch 30/64 loss: 1.7390592098236084
Batch 31/64 loss: 1.734537124633789
Batch 32/64 loss: 1.7384600639343262
Batch 33/64 loss: 1.73929762840271
Batch 34/64 loss: 1.7448310852050781
Batch 35/64 loss: 1.7384059429168701
Batch 36/64 loss: 1.7365036010742188
Batch 37/64 loss: 1.7377116680145264
Batch 38/64 loss: 1.737377405166626
Batch 39/64 loss: 1.7364799976348877
Batch 40/64 loss: 1.740279197692871
Batch 41/64 loss: 1.743419885635376
Batch 42/64 loss: 1.739549160003662
Batch 43/64 loss: 1.7370991706848145
Batch 44/64 loss: 1.7341840267181396
Batch 45/64 loss: 1.739223837852478
Batch 46/64 loss: 1.7415776252746582
Batch 47/64 loss: 1.736297369003296
Batch 48/64 loss: 1.73738431930542
Batch 49/64 loss: 1.7449971437454224
Batch 50/64 loss: 1.7533800601959229
Batch 51/64 loss: 1.738086462020874
Batch 52/64 loss: 1.7486636638641357
Batch 53/64 loss: 1.7597373723983765
Batch 54/64 loss: 1.7464420795440674
Batch 55/64 loss: 1.7478994131088257
Batch 56/64 loss: 1.7473526000976562
Batch 57/64 loss: 1.741947889328003
Batch 58/64 loss: 1.745464563369751
Batch 59/64 loss: 1.7415950298309326
Batch 60/64 loss: 1.7407090663909912
Batch 61/64 loss: 1.7417657375335693
Batch 62/64 loss: 1.7441984415054321
Batch 63/64 loss: 1.7457597255706787
Batch 64/64 loss: 1.9292941093444824
Epoch 293  Train loss: 1.74147081749112  Val loss: 1.7626512050628662
Epoch 294
-------------------------------
Batch 1/64 loss: 1.7451037168502808
Batch 2/64 loss: 1.7531585693359375
Batch 3/64 loss: 1.7481188774108887
Batch 4/64 loss: 1.7457906007766724
Batch 5/64 loss: 1.744460940361023
Batch 6/64 loss: 1.7456800937652588
Batch 7/64 loss: 1.7428346872329712
Batch 8/64 loss: 1.7414281368255615
Batch 9/64 loss: 1.7518916130065918
Batch 10/64 loss: 1.7460317611694336
Batch 11/64 loss: 1.7561640739440918
Batch 12/64 loss: 1.7486695051193237
Batch 13/64 loss: 1.7402393817901611
Batch 14/64 loss: 1.7427356243133545
Batch 15/64 loss: 1.7539896965026855
Batch 16/64 loss: 1.7388887405395508
Batch 17/64 loss: 1.7510370016098022
Batch 18/64 loss: 1.7527333498001099
Batch 19/64 loss: 1.7416110038757324
Batch 20/64 loss: 1.737844705581665
Batch 21/64 loss: 1.744971513748169
Batch 22/64 loss: 1.744858980178833
Batch 23/64 loss: 1.7477755546569824
Batch 24/64 loss: 1.7425661087036133
Batch 25/64 loss: 1.747097373008728
Batch 26/64 loss: 1.7446154356002808
Batch 27/64 loss: 1.7434492111206055
Batch 28/64 loss: 1.7412986755371094
Batch 29/64 loss: 1.7411818504333496
Batch 30/64 loss: 1.756838083267212
Batch 31/64 loss: 1.742889165878296
Batch 32/64 loss: 1.7454087734222412
Batch 33/64 loss: 1.7402503490447998
Batch 34/64 loss: 1.742307424545288
Batch 35/64 loss: 1.7453498840332031
Batch 36/64 loss: 1.7394893169403076
Batch 37/64 loss: 1.7396069765090942
Batch 38/64 loss: 1.7383837699890137
Batch 39/64 loss: 1.7381203174591064
Batch 40/64 loss: 1.7383919954299927
Batch 41/64 loss: 1.737828254699707
Batch 42/64 loss: 1.7568641901016235
Batch 43/64 loss: 1.7417458295822144
Batch 44/64 loss: 1.746960163116455
Batch 45/64 loss: 1.7413256168365479
Batch 46/64 loss: 1.737417459487915
Batch 47/64 loss: 1.738342046737671
Batch 48/64 loss: 1.7447456121444702
Batch 49/64 loss: 1.7409838438034058
Batch 50/64 loss: 1.7405836582183838
Batch 51/64 loss: 1.737576961517334
Batch 52/64 loss: 1.7369393110275269
Batch 53/64 loss: 1.7384421825408936
Batch 54/64 loss: 1.7376151084899902
Batch 55/64 loss: 1.739055871963501
Batch 56/64 loss: 1.735002040863037
Batch 57/64 loss: 1.7380486726760864
Batch 58/64 loss: 1.7359873056411743
Batch 59/64 loss: 1.7353620529174805
Batch 60/64 loss: 1.7375731468200684
Batch 61/64 loss: 1.7356773614883423
Batch 62/64 loss: 1.7358018159866333
Batch 63/64 loss: 1.7390668392181396
Batch 64/64 loss: 1.920792579650879
Epoch 294  Train loss: 1.744985139136221  Val loss: 1.7542346203859729
Epoch 295
-------------------------------
Batch 1/64 loss: 1.7352796792984009
Batch 2/64 loss: 1.7378995418548584
Batch 3/64 loss: 1.7352056503295898
Batch 4/64 loss: 1.74509596824646
Batch 5/64 loss: 1.7392466068267822
Batch 6/64 loss: 1.7327467203140259
Batch 7/64 loss: 1.7352631092071533
Batch 8/64 loss: 1.734894037246704
Batch 9/64 loss: 1.7343370914459229
Batch 10/64 loss: 1.7325615882873535
Batch 11/64 loss: 1.7351593971252441
Batch 12/64 loss: 1.7346343994140625
Batch 13/64 loss: 1.7365403175354004
Batch 14/64 loss: 1.7351146936416626
Batch 15/64 loss: 1.7380270957946777
Batch 16/64 loss: 1.7357308864593506
Batch 17/64 loss: 1.7376816272735596
Batch 18/64 loss: 1.7371501922607422
Batch 19/64 loss: 1.7369747161865234
Batch 20/64 loss: 1.7352123260498047
Batch 21/64 loss: 1.7374906539916992
Batch 22/64 loss: 1.7339439392089844
Batch 23/64 loss: 1.7371536493301392
Batch 24/64 loss: 1.734647274017334
Batch 25/64 loss: 1.7364946603775024
Batch 26/64 loss: 1.7382266521453857
Batch 27/64 loss: 1.7340922355651855
Batch 28/64 loss: 1.739066243171692
Batch 29/64 loss: 1.736161708831787
Batch 30/64 loss: 1.7345097064971924
Batch 31/64 loss: 1.7367467880249023
Batch 32/64 loss: 1.7463792562484741
Batch 33/64 loss: 1.7450875043869019
Batch 34/64 loss: 1.7354971170425415
Batch 35/64 loss: 1.7372331619262695
Batch 36/64 loss: 1.7343316078186035
Batch 37/64 loss: 1.734394907951355
Batch 38/64 loss: 1.734409213066101
Batch 39/64 loss: 1.733543872833252
Batch 40/64 loss: 1.7358741760253906
Batch 41/64 loss: 1.7358922958374023
Batch 42/64 loss: 1.7335867881774902
Batch 43/64 loss: 1.7393014430999756
Batch 44/64 loss: 1.7328760623931885
Batch 45/64 loss: 1.7363216876983643
Batch 46/64 loss: 1.737818717956543
Batch 47/64 loss: 1.7316826581954956
Batch 48/64 loss: 1.7329297065734863
Batch 49/64 loss: 1.733686923980713
Batch 50/64 loss: 1.7399883270263672
Batch 51/64 loss: 1.7508115768432617
Batch 52/64 loss: 1.734574317932129
Batch 53/64 loss: 1.734494924545288
Batch 54/64 loss: 1.7319653034210205
Batch 55/64 loss: 1.75093412399292
Batch 56/64 loss: 1.7343964576721191
Batch 57/64 loss: 1.7377064228057861
Batch 58/64 loss: 1.7334967851638794
Batch 59/64 loss: 1.7337095737457275
Batch 60/64 loss: 1.7419450283050537
Batch 61/64 loss: 1.734757423400879
Batch 62/64 loss: 1.7340456247329712
Batch 63/64 loss: 1.7378098964691162
Batch 64/64 loss: 1.923436164855957
Epoch 295  Train loss: 1.7387819477156097  Val loss: 1.7545770402626484
Epoch 296
-------------------------------
Batch 1/64 loss: 1.738979458808899
Batch 2/64 loss: 1.7351844310760498
Batch 3/64 loss: 1.7374110221862793
Batch 4/64 loss: 1.7338740825653076
Batch 5/64 loss: 1.731703758239746
Batch 6/64 loss: 1.7328696250915527
Batch 7/64 loss: 1.7326455116271973
Batch 8/64 loss: 1.7368085384368896
Batch 9/64 loss: 1.7365577220916748
Batch 10/64 loss: 1.7327091693878174
Batch 11/64 loss: 1.7353380918502808
Batch 12/64 loss: 1.7369472980499268
Batch 13/64 loss: 1.7338453531265259
Batch 14/64 loss: 1.733771562576294
Batch 15/64 loss: 1.7342609167099
Batch 16/64 loss: 1.7365432977676392
Batch 17/64 loss: 1.733670949935913
Batch 18/64 loss: 1.7380701303482056
Batch 19/64 loss: 1.7347755432128906
Batch 20/64 loss: 1.7358336448669434
Batch 21/64 loss: 1.7338361740112305
Batch 22/64 loss: 1.7323992252349854
Batch 23/64 loss: 1.7341742515563965
Batch 24/64 loss: 1.73604416847229
Batch 25/64 loss: 1.7362821102142334
Batch 26/64 loss: 1.7335870265960693
Batch 27/64 loss: 1.7328550815582275
Batch 28/64 loss: 1.7372503280639648
Batch 29/64 loss: 1.7406806945800781
Batch 30/64 loss: 1.7371759414672852
Batch 31/64 loss: 1.7354716062545776
Batch 32/64 loss: 1.7370007038116455
Batch 33/64 loss: 1.7306935787200928
Batch 34/64 loss: 1.7339153289794922
Batch 35/64 loss: 1.7409340143203735
Batch 36/64 loss: 1.737011432647705
Batch 37/64 loss: 1.7360115051269531
Batch 38/64 loss: 1.7350292205810547
Batch 39/64 loss: 1.7391571998596191
Batch 40/64 loss: 1.7344131469726562
Batch 41/64 loss: 1.7338242530822754
Batch 42/64 loss: 1.7375582456588745
Batch 43/64 loss: 1.7388919591903687
Batch 44/64 loss: 1.7331751585006714
Batch 45/64 loss: 1.7313928604125977
Batch 46/64 loss: 1.7317774295806885
Batch 47/64 loss: 1.7336490154266357
Batch 48/64 loss: 1.736171007156372
Batch 49/64 loss: 1.7323648929595947
Batch 50/64 loss: 1.746780276298523
Batch 51/64 loss: 1.7384922504425049
Batch 52/64 loss: 1.7348870038986206
Batch 53/64 loss: 1.7609634399414062
Batch 54/64 loss: 1.7352073192596436
Batch 55/64 loss: 1.733839511871338
Batch 56/64 loss: 1.7323896884918213
Batch 57/64 loss: 1.7335467338562012
Batch 58/64 loss: 1.7445236444473267
Batch 59/64 loss: 1.7318519353866577
Batch 60/64 loss: 1.7373062372207642
Batch 61/64 loss: 1.7356362342834473
Batch 62/64 loss: 1.7324073314666748
Batch 63/64 loss: 1.7332737445831299
Batch 64/64 loss: 1.9170141220092773
Epoch 296  Train loss: 1.7379355860691446  Val loss: 1.7516036713655871
Epoch 297
-------------------------------
Batch 1/64 loss: 1.7397069931030273
Batch 2/64 loss: 1.7353113889694214
Batch 3/64 loss: 1.7324962615966797
Batch 4/64 loss: 1.741742491722107
Batch 5/64 loss: 1.732443928718567
Batch 6/64 loss: 1.7338958978652954
Batch 7/64 loss: 1.7355132102966309
Batch 8/64 loss: 1.7355952262878418
Batch 9/64 loss: 1.7349754571914673
Batch 10/64 loss: 1.7338244915008545
Batch 11/64 loss: 1.7332816123962402
Batch 12/64 loss: 1.7381500005722046
Batch 13/64 loss: 1.7412638664245605
Batch 14/64 loss: 1.7334175109863281
Batch 15/64 loss: 1.7360966205596924
Batch 16/64 loss: 1.734554409980774
Batch 17/64 loss: 1.7409391403198242
Batch 18/64 loss: 1.73524808883667
Batch 19/64 loss: 1.7335985898971558
Batch 20/64 loss: 1.7395142316818237
Batch 21/64 loss: 1.737176775932312
Batch 22/64 loss: 1.7353647947311401
Batch 23/64 loss: 1.7355382442474365
Batch 24/64 loss: 1.7346253395080566
Batch 25/64 loss: 1.732499361038208
Batch 26/64 loss: 1.7361888885498047
Batch 27/64 loss: 1.7354536056518555
Batch 28/64 loss: 1.7559936046600342
Batch 29/64 loss: 1.7390180826187134
Batch 30/64 loss: 1.7350233793258667
Batch 31/64 loss: 1.7367184162139893
Batch 32/64 loss: 1.7375959157943726
Batch 33/64 loss: 1.7439346313476562
Batch 34/64 loss: 1.7370482683181763
Batch 35/64 loss: 1.737546443939209
Batch 36/64 loss: 1.7420132160186768
Batch 37/64 loss: 1.7342338562011719
Batch 38/64 loss: 1.742508888244629
Batch 39/64 loss: 1.7383835315704346
Batch 40/64 loss: 1.7374787330627441
Batch 41/64 loss: 1.7360434532165527
Batch 42/64 loss: 1.7398849725723267
Batch 43/64 loss: 1.738109827041626
Batch 44/64 loss: 1.7478008270263672
Batch 45/64 loss: 1.7332878112792969
Batch 46/64 loss: 1.7413294315338135
Batch 47/64 loss: 1.7357559204101562
Batch 48/64 loss: 1.7378489971160889
Batch 49/64 loss: 1.7419239282608032
Batch 50/64 loss: 1.7375271320343018
Batch 51/64 loss: 1.7319667339324951
Batch 52/64 loss: 1.7322872877120972
Batch 53/64 loss: 1.7320945262908936
Batch 54/64 loss: 1.7341482639312744
Batch 55/64 loss: 1.7368561029434204
Batch 56/64 loss: 1.733431100845337
Batch 57/64 loss: 1.7341375350952148
Batch 58/64 loss: 1.7375895977020264
Batch 59/64 loss: 1.734255075454712
Batch 60/64 loss: 1.732180118560791
Batch 61/64 loss: 1.736342191696167
Batch 62/64 loss: 1.7460830211639404
Batch 63/64 loss: 1.7361962795257568
Batch 64/64 loss: 1.924170732498169
Epoch 297  Train loss: 1.739233279695698  Val loss: 1.7555017913739706
Epoch 298
-------------------------------
Batch 1/64 loss: 1.753760814666748
Batch 2/64 loss: 1.7387664318084717
Batch 3/64 loss: 1.7350921630859375
Batch 4/64 loss: 1.7371635437011719
Batch 5/64 loss: 1.7392380237579346
Batch 6/64 loss: 1.7359179258346558
Batch 7/64 loss: 1.7318270206451416
Batch 8/64 loss: 1.7360759973526
Batch 9/64 loss: 1.7357492446899414
Batch 10/64 loss: 1.731381893157959
Batch 11/64 loss: 1.735109806060791
Batch 12/64 loss: 1.733209252357483
Batch 13/64 loss: 1.7423961162567139
Batch 14/64 loss: 1.7341291904449463
Batch 15/64 loss: 1.7351188659667969
Batch 16/64 loss: 1.7418785095214844
Batch 17/64 loss: 1.735661506652832
Batch 18/64 loss: 1.7525697946548462
Batch 19/64 loss: 1.7349638938903809
Batch 20/64 loss: 1.7338266372680664
Batch 21/64 loss: 1.7352588176727295
Batch 22/64 loss: 1.7353514432907104
Batch 23/64 loss: 1.7331290245056152
Batch 24/64 loss: 1.7337572574615479
Batch 25/64 loss: 1.7337126731872559
Batch 26/64 loss: 1.7373020648956299
Batch 27/64 loss: 1.7366958856582642
Batch 28/64 loss: 1.7310646772384644
Batch 29/64 loss: 1.7330985069274902
Batch 30/64 loss: 1.7382533550262451
Batch 31/64 loss: 1.7367526292800903
Batch 32/64 loss: 1.7359001636505127
Batch 33/64 loss: 1.7354737520217896
Batch 34/64 loss: 1.7359800338745117
Batch 35/64 loss: 1.740168571472168
Batch 36/64 loss: 1.7333347797393799
Batch 37/64 loss: 1.7345227003097534
Batch 38/64 loss: 1.735560417175293
Batch 39/64 loss: 1.7326407432556152
Batch 40/64 loss: 1.734637975692749
Batch 41/64 loss: 1.7304749488830566
Batch 42/64 loss: 1.7325451374053955
Batch 43/64 loss: 1.7318072319030762
Batch 44/64 loss: 1.7351590394973755
Batch 45/64 loss: 1.7341259717941284
Batch 46/64 loss: 1.732741117477417
Batch 47/64 loss: 1.7338924407958984
Batch 48/64 loss: 1.732204556465149
Batch 49/64 loss: 1.7328591346740723
Batch 50/64 loss: 1.732213020324707
Batch 51/64 loss: 1.7327685356140137
Batch 52/64 loss: 1.7317736148834229
Batch 53/64 loss: 1.736344337463379
Batch 54/64 loss: 1.7329274415969849
Batch 55/64 loss: 1.7322291135787964
Batch 56/64 loss: 1.743226170539856
Batch 57/64 loss: 1.7307021617889404
Batch 58/64 loss: 1.7360702753067017
Batch 59/64 loss: 1.732114315032959
Batch 60/64 loss: 1.7279579639434814
Batch 61/64 loss: 1.7392842769622803
Batch 62/64 loss: 1.7317733764648438
Batch 63/64 loss: 1.730151653289795
Batch 64/64 loss: 1.9192250967025757
Epoch 298  Train loss: 1.73743053744821  Val loss: 1.7481137534597075
Saving best model, epoch: 298
Epoch 299
-------------------------------
Batch 1/64 loss: 1.7341679334640503
Batch 2/64 loss: 1.7432034015655518
Batch 3/64 loss: 1.7343486547470093
Batch 4/64 loss: 1.7340145111083984
Batch 5/64 loss: 1.7332302331924438
Batch 6/64 loss: 1.731318473815918
Batch 7/64 loss: 1.733079433441162
Batch 8/64 loss: 1.7398804426193237
Batch 9/64 loss: 1.7331500053405762
Batch 10/64 loss: 1.7349133491516113
Batch 11/64 loss: 1.7333040237426758
Batch 12/64 loss: 1.7331238985061646
Batch 13/64 loss: 1.733194351196289
Batch 14/64 loss: 1.7321829795837402
Batch 15/64 loss: 1.730992317199707
Batch 16/64 loss: 1.7357300519943237
Batch 17/64 loss: 1.73421049118042
Batch 18/64 loss: 1.734830379486084
Batch 19/64 loss: 1.734145164489746
Batch 20/64 loss: 1.7366241216659546
Batch 21/64 loss: 1.735119342803955
Batch 22/64 loss: 1.738311767578125
Batch 23/64 loss: 1.7370493412017822
Batch 24/64 loss: 1.737227439880371
Batch 25/64 loss: 1.731589436531067
Batch 26/64 loss: 1.7340514659881592
Batch 27/64 loss: 1.751113772392273
Batch 28/64 loss: 1.7325029373168945
Batch 29/64 loss: 1.733041763305664
Batch 30/64 loss: 1.7318329811096191
Batch 31/64 loss: 1.734370470046997
Batch 32/64 loss: 1.7322921752929688
Batch 33/64 loss: 1.7361817359924316
Batch 34/64 loss: 1.7311203479766846
Batch 35/64 loss: 1.7333624362945557
Batch 36/64 loss: 1.73282790184021
Batch 37/64 loss: 1.7343835830688477
Batch 38/64 loss: 1.7335789203643799
Batch 39/64 loss: 1.7338178157806396
Batch 40/64 loss: 1.7356302738189697
Batch 41/64 loss: 1.7354683876037598
Batch 42/64 loss: 1.735585331916809
Batch 43/64 loss: 1.734580159187317
Batch 44/64 loss: 1.7403185367584229
Batch 45/64 loss: 1.7329275608062744
Batch 46/64 loss: 1.7350090742111206
Batch 47/64 loss: 1.733893632888794
Batch 48/64 loss: 1.7492687702178955
Batch 49/64 loss: 1.7339324951171875
Batch 50/64 loss: 1.7357466220855713
Batch 51/64 loss: 1.7307145595550537
Batch 52/64 loss: 1.737121343612671
Batch 53/64 loss: 1.7366284132003784
Batch 54/64 loss: 1.731954574584961
Batch 55/64 loss: 1.7356977462768555
Batch 56/64 loss: 1.7358760833740234
Batch 57/64 loss: 1.7377970218658447
Batch 58/64 loss: 1.7317101955413818
Batch 59/64 loss: 1.7367708683013916
Batch 60/64 loss: 1.733952522277832
Batch 61/64 loss: 1.7365156412124634
Batch 62/64 loss: 1.742126226425171
Batch 63/64 loss: 1.7323453426361084
Batch 64/64 loss: 1.9224014282226562
Epoch 299  Train loss: 1.737361447951373  Val loss: 1.7521730993211884
Epoch 300
-------------------------------
Batch 1/64 loss: 1.7394908666610718
Batch 2/64 loss: 1.7330902814865112
Batch 3/64 loss: 1.7401223182678223
Batch 4/64 loss: 1.733792781829834
Batch 5/64 loss: 1.733246088027954
Batch 6/64 loss: 1.7317588329315186
Batch 7/64 loss: 1.736692190170288
Batch 8/64 loss: 1.7327461242675781
Batch 9/64 loss: 1.7322090864181519
Batch 10/64 loss: 1.733675479888916
Batch 11/64 loss: 1.7345759868621826
Batch 12/64 loss: 1.7316502332687378
Batch 13/64 loss: 1.7314904928207397
Batch 14/64 loss: 1.733572006225586
Batch 15/64 loss: 1.7329742908477783
Batch 16/64 loss: 1.7417511940002441
Batch 17/64 loss: 1.7338714599609375
Batch 18/64 loss: 1.73264741897583
Batch 19/64 loss: 1.7316498756408691
Batch 20/64 loss: 1.7355526685714722
Batch 21/64 loss: 1.7305967807769775
Batch 22/64 loss: 1.7325377464294434
Batch 23/64 loss: 1.735910177230835
Batch 24/64 loss: 1.7331796884536743
Batch 25/64 loss: 1.7377766370773315
Batch 26/64 loss: 1.7344329357147217
Batch 27/64 loss: 1.7362583875656128
Batch 28/64 loss: 1.736093521118164
Batch 29/64 loss: 1.732025384902954
Batch 30/64 loss: 1.7344449758529663
Batch 31/64 loss: 1.7356281280517578
Batch 32/64 loss: 1.7311168909072876
Batch 33/64 loss: 1.7336359024047852
Batch 34/64 loss: 1.7487739324569702
Batch 35/64 loss: 1.7327091693878174
Batch 36/64 loss: 1.7314860820770264
Batch 37/64 loss: 1.7356925010681152
Batch 38/64 loss: 1.738065242767334
Batch 39/64 loss: 1.7324416637420654
Batch 40/64 loss: 1.7554113864898682
Batch 41/64 loss: 1.735257625579834
Batch 42/64 loss: 1.7339999675750732
Batch 43/64 loss: 1.7371371984481812
Batch 44/64 loss: 1.7351491451263428
Batch 45/64 loss: 1.7396243810653687
Batch 46/64 loss: 1.7359139919281006
Batch 47/64 loss: 1.7331106662750244
Batch 48/64 loss: 1.7349393367767334
Batch 49/64 loss: 1.7364633083343506
Batch 50/64 loss: 1.740352749824524
Batch 51/64 loss: 1.7361528873443604
Batch 52/64 loss: 1.7368988990783691
Batch 53/64 loss: 1.7405498027801514
Batch 54/64 loss: 1.7370498180389404
Batch 55/64 loss: 1.73738431930542
Batch 56/64 loss: 1.7380266189575195
Batch 57/64 loss: 1.7344577312469482
Batch 58/64 loss: 1.735039234161377
Batch 59/64 loss: 1.7352867126464844
Batch 60/64 loss: 1.7371442317962646
Batch 61/64 loss: 1.7438547611236572
Batch 62/64 loss: 1.7329840660095215
Batch 63/64 loss: 1.7365479469299316
Batch 64/64 loss: 1.9211833477020264
Epoch 300  Train loss: 1.7378665054545683  Val loss: 1.7554937867364524
Epoch 301
-------------------------------
Batch 1/64 loss: 1.7344350814819336
Batch 2/64 loss: 1.7538206577301025
Batch 3/64 loss: 1.7359668016433716
Batch 4/64 loss: 1.7385883331298828
Batch 5/64 loss: 1.7360056638717651
Batch 6/64 loss: 1.7370383739471436
Batch 7/64 loss: 1.7425940036773682
Batch 8/64 loss: 1.7409377098083496
Batch 9/64 loss: 1.7349331378936768
Batch 10/64 loss: 1.7324531078338623
Batch 11/64 loss: 1.732375979423523
Batch 12/64 loss: 1.7467243671417236
Batch 13/64 loss: 1.7340128421783447
Batch 14/64 loss: 1.7359521389007568
Batch 15/64 loss: 1.7347981929779053
Batch 16/64 loss: 1.7336620092391968
Batch 17/64 loss: 1.7331624031066895
Batch 18/64 loss: 1.7401137351989746
Batch 19/64 loss: 1.7306435108184814
Batch 20/64 loss: 1.7359766960144043
Batch 21/64 loss: 1.732111930847168
Batch 22/64 loss: 1.734684705734253
Batch 23/64 loss: 1.733895182609558
Batch 24/64 loss: 1.7386374473571777
Batch 25/64 loss: 1.7333059310913086
Batch 26/64 loss: 1.7345566749572754
Batch 27/64 loss: 1.734165906906128
Batch 28/64 loss: 1.7330254316329956
Batch 29/64 loss: 1.7319940328598022
Batch 30/64 loss: 1.7318358421325684
Batch 31/64 loss: 1.7323652505874634
Batch 32/64 loss: 1.7371370792388916
Batch 33/64 loss: 1.7330548763275146
Batch 34/64 loss: 1.7336101531982422
Batch 35/64 loss: 1.7359044551849365
Batch 36/64 loss: 1.7329027652740479
Batch 37/64 loss: 1.7330303192138672
Batch 38/64 loss: 1.732128381729126
Batch 39/64 loss: 1.740371823310852
Batch 40/64 loss: 1.7364485263824463
Batch 41/64 loss: 1.7337747812271118
Batch 42/64 loss: 1.7341495752334595
Batch 43/64 loss: 1.7334272861480713
Batch 44/64 loss: 1.7361385822296143
Batch 45/64 loss: 1.732939600944519
Batch 46/64 loss: 1.7359023094177246
Batch 47/64 loss: 1.7340792417526245
Batch 48/64 loss: 1.7395694255828857
Batch 49/64 loss: 1.7343217134475708
Batch 50/64 loss: 1.7389007806777954
Batch 51/64 loss: 1.7339661121368408
Batch 52/64 loss: 1.7322782278060913
Batch 53/64 loss: 1.7367780208587646
Batch 54/64 loss: 1.7317452430725098
Batch 55/64 loss: 1.73310124874115
Batch 56/64 loss: 1.735572338104248
Batch 57/64 loss: 1.7318856716156006
Batch 58/64 loss: 1.7332558631896973
Batch 59/64 loss: 1.7310354709625244
Batch 60/64 loss: 1.7312742471694946
Batch 61/64 loss: 1.7322392463684082
Batch 62/64 loss: 1.747973918914795
Batch 63/64 loss: 1.7320632934570312
Batch 64/64 loss: 1.9314887523651123
Epoch 301  Train loss: 1.7376368662890267  Val loss: 1.751342857006899
Epoch 302
-------------------------------
Batch 1/64 loss: 1.738511085510254
Batch 2/64 loss: 1.7323849201202393
Batch 3/64 loss: 1.733055830001831
Batch 4/64 loss: 1.7348618507385254
Batch 5/64 loss: 1.735649585723877
Batch 6/64 loss: 1.7366654872894287
Batch 7/64 loss: 1.733946681022644
Batch 8/64 loss: 1.7337157726287842
Batch 9/64 loss: 1.731170415878296
Batch 10/64 loss: 1.7334468364715576
Batch 11/64 loss: 1.7346625328063965
Batch 12/64 loss: 1.734933614730835
Batch 13/64 loss: 1.7350785732269287
Batch 14/64 loss: 1.7339227199554443
Batch 15/64 loss: 1.732114553451538
Batch 16/64 loss: 1.735504150390625
Batch 17/64 loss: 1.732541561126709
Batch 18/64 loss: 1.7415056228637695
Batch 19/64 loss: 1.7376251220703125
Batch 20/64 loss: 1.7354509830474854
Batch 21/64 loss: 1.7341690063476562
Batch 22/64 loss: 1.7419674396514893
Batch 23/64 loss: 1.731870412826538
Batch 24/64 loss: 1.7391983270645142
Batch 25/64 loss: 1.7367432117462158
Batch 26/64 loss: 1.7361788749694824
Batch 27/64 loss: 1.733963131904602
Batch 28/64 loss: 1.7354329824447632
Batch 29/64 loss: 1.736443281173706
Batch 30/64 loss: 1.7368395328521729
Batch 31/64 loss: 1.737605333328247
Batch 32/64 loss: 1.734276533126831
Batch 33/64 loss: 1.7473719120025635
Batch 34/64 loss: 1.7372455596923828
Batch 35/64 loss: 1.7362209558486938
Batch 36/64 loss: 1.7348045110702515
Batch 37/64 loss: 1.734792947769165
Batch 38/64 loss: 1.7337987422943115
Batch 39/64 loss: 1.735345482826233
Batch 40/64 loss: 1.7780828475952148
Batch 41/64 loss: 1.7418937683105469
Batch 42/64 loss: 1.733708143234253
Batch 43/64 loss: 1.7336540222167969
Batch 44/64 loss: 1.7371935844421387
Batch 45/64 loss: 1.7355282306671143
Batch 46/64 loss: 1.7385413646697998
Batch 47/64 loss: 1.7366762161254883
Batch 48/64 loss: 1.734740138053894
Batch 49/64 loss: 1.7347993850708008
Batch 50/64 loss: 1.7330710887908936
Batch 51/64 loss: 1.732048511505127
Batch 52/64 loss: 1.7354509830474854
Batch 53/64 loss: 1.7323071956634521
Batch 54/64 loss: 1.730822205543518
Batch 55/64 loss: 1.733379602432251
Batch 56/64 loss: 1.7332987785339355
Batch 57/64 loss: 1.7330355644226074
Batch 58/64 loss: 1.7312901020050049
Batch 59/64 loss: 1.7320716381072998
Batch 60/64 loss: 1.7305186986923218
Batch 61/64 loss: 1.7300517559051514
Batch 62/64 loss: 1.7325751781463623
Batch 63/64 loss: 1.7308142185211182
Batch 64/64 loss: 1.9172604084014893
Epoch 302  Train loss: 1.7377963075450822  Val loss: 1.7497313489618989
Epoch 303
-------------------------------
Batch 1/64 loss: 1.7345478534698486
Batch 2/64 loss: 1.7335963249206543
Batch 3/64 loss: 1.7321949005126953
Batch 4/64 loss: 1.7318410873413086
Batch 5/64 loss: 1.7305810451507568
Batch 6/64 loss: 1.731799840927124
Batch 7/64 loss: 1.7315053939819336
Batch 8/64 loss: 1.7332568168640137
Batch 9/64 loss: 1.7380337715148926
Batch 10/64 loss: 1.733703374862671
Batch 11/64 loss: 1.7341248989105225
Batch 12/64 loss: 1.7385627031326294
Batch 13/64 loss: 1.7314765453338623
Batch 14/64 loss: 1.7295087575912476
Batch 15/64 loss: 1.7328331470489502
Batch 16/64 loss: 1.7316563129425049
Batch 17/64 loss: 1.732923984527588
Batch 18/64 loss: 1.73502779006958
Batch 19/64 loss: 1.7362418174743652
Batch 20/64 loss: 1.7351863384246826
Batch 21/64 loss: 1.732741117477417
Batch 22/64 loss: 1.7337219715118408
Batch 23/64 loss: 1.7445073127746582
Batch 24/64 loss: 1.7315423488616943
Batch 25/64 loss: 1.7305406332015991
Batch 26/64 loss: 1.7363595962524414
Batch 27/64 loss: 1.7340136766433716
Batch 28/64 loss: 1.7376062870025635
Batch 29/64 loss: 1.7326085567474365
Batch 30/64 loss: 1.7305123805999756
Batch 31/64 loss: 1.737855076789856
Batch 32/64 loss: 1.7325332164764404
Batch 33/64 loss: 1.7370593547821045
Batch 34/64 loss: 1.7501391172409058
Batch 35/64 loss: 1.7358742952346802
Batch 36/64 loss: 1.7385246753692627
Batch 37/64 loss: 1.736173391342163
Batch 38/64 loss: 1.7367334365844727
Batch 39/64 loss: 1.7366529703140259
Batch 40/64 loss: 1.7367939949035645
Batch 41/64 loss: 1.7353414297103882
Batch 42/64 loss: 1.741049885749817
Batch 43/64 loss: 1.7380837202072144
Batch 44/64 loss: 1.7367174625396729
Batch 45/64 loss: 1.735893726348877
Batch 46/64 loss: 1.7367734909057617
Batch 47/64 loss: 1.7366575002670288
Batch 48/64 loss: 1.7344125509262085
Batch 49/64 loss: 1.7367156744003296
Batch 50/64 loss: 1.7359670400619507
Batch 51/64 loss: 1.7356547117233276
Batch 52/64 loss: 1.7363743782043457
Batch 53/64 loss: 1.7327107191085815
Batch 54/64 loss: 1.7361135482788086
Batch 55/64 loss: 1.7345526218414307
Batch 56/64 loss: 1.7334043979644775
Batch 57/64 loss: 1.7347077131271362
Batch 58/64 loss: 1.7398438453674316
Batch 59/64 loss: 1.7360854148864746
Batch 60/64 loss: 1.7519681453704834
Batch 61/64 loss: 1.7357492446899414
Batch 62/64 loss: 1.7339388132095337
Batch 63/64 loss: 1.7338833808898926
Batch 64/64 loss: 1.9209238290786743
Epoch 303  Train loss: 1.7376374651403987  Val loss: 1.7534212787536412
Epoch 304
-------------------------------
Batch 1/64 loss: 1.734535574913025
Batch 2/64 loss: 1.7382380962371826
Batch 3/64 loss: 1.7375037670135498
Batch 4/64 loss: 1.7342426776885986
Batch 5/64 loss: 1.7337312698364258
Batch 6/64 loss: 1.746659278869629
Batch 7/64 loss: 1.738008737564087
Batch 8/64 loss: 1.7319724559783936
Batch 9/64 loss: 1.7366468906402588
Batch 10/64 loss: 1.7323884963989258
Batch 11/64 loss: 1.7342169284820557
Batch 12/64 loss: 1.7309048175811768
Batch 13/64 loss: 1.736350417137146
Batch 14/64 loss: 1.7301061153411865
Batch 15/64 loss: 1.7332830429077148
Batch 16/64 loss: 1.7299693822860718
Batch 17/64 loss: 1.7325645685195923
Batch 18/64 loss: 1.7328290939331055
Batch 19/64 loss: 1.7345595359802246
Batch 20/64 loss: 1.7345980405807495
Batch 21/64 loss: 1.7339255809783936
Batch 22/64 loss: 1.7335920333862305
Batch 23/64 loss: 1.7340525388717651
Batch 24/64 loss: 1.732783317565918
Batch 25/64 loss: 1.733339548110962
Batch 26/64 loss: 1.7324614524841309
Batch 27/64 loss: 1.7509126663208008
Batch 28/64 loss: 1.7407985925674438
Batch 29/64 loss: 1.7352149486541748
Batch 30/64 loss: 1.743154764175415
Batch 31/64 loss: 1.7343080043792725
Batch 32/64 loss: 1.734419822692871
Batch 33/64 loss: 1.7349464893341064
Batch 34/64 loss: 1.7329869270324707
Batch 35/64 loss: 1.736154556274414
Batch 36/64 loss: 1.7322217226028442
Batch 37/64 loss: 1.7466118335723877
Batch 38/64 loss: 1.733955979347229
Batch 39/64 loss: 1.7329983711242676
Batch 40/64 loss: 1.7329535484313965
Batch 41/64 loss: 1.7351229190826416
Batch 42/64 loss: 1.7306134700775146
Batch 43/64 loss: 1.7345157861709595
Batch 44/64 loss: 1.731959342956543
Batch 45/64 loss: 1.7337565422058105
Batch 46/64 loss: 1.7312722206115723
Batch 47/64 loss: 1.733152151107788
Batch 48/64 loss: 1.7343266010284424
Batch 49/64 loss: 1.7339409589767456
Batch 50/64 loss: 1.7331631183624268
Batch 51/64 loss: 1.7344623804092407
Batch 52/64 loss: 1.7336227893829346
Batch 53/64 loss: 1.7314648628234863
Batch 54/64 loss: 1.7307718992233276
Batch 55/64 loss: 1.7336788177490234
Batch 56/64 loss: 1.730523943901062
Batch 57/64 loss: 1.7321898937225342
Batch 58/64 loss: 1.7318671941757202
Batch 59/64 loss: 1.7305470705032349
Batch 60/64 loss: 1.7352490425109863
Batch 61/64 loss: 1.73283052444458
Batch 62/64 loss: 1.7314337491989136
Batch 63/64 loss: 1.7366336584091187
Batch 64/64 loss: 1.920820713043213
Epoch 304  Train loss: 1.7366716291390214  Val loss: 1.7504761743381672
Epoch 305
-------------------------------
Batch 1/64 loss: 1.7383333444595337
Batch 2/64 loss: 1.7306756973266602
Batch 3/64 loss: 1.742474913597107
Batch 4/64 loss: 1.7326240539550781
Batch 5/64 loss: 1.7306013107299805
Batch 6/64 loss: 1.7284190654754639
Batch 7/64 loss: 1.7317864894866943
Batch 8/64 loss: 1.7323601245880127
Batch 9/64 loss: 1.733583927154541
Batch 10/64 loss: 1.7346463203430176
Batch 11/64 loss: 1.7318050861358643
Batch 12/64 loss: 1.7368276119232178
Batch 13/64 loss: 1.7344200611114502
Batch 14/64 loss: 1.7416318655014038
Batch 15/64 loss: 1.7336854934692383
Batch 16/64 loss: 1.734928011894226
Batch 17/64 loss: 1.7328622341156006
Batch 18/64 loss: 1.738460898399353
Batch 19/64 loss: 1.7331149578094482
Batch 20/64 loss: 1.7331476211547852
Batch 21/64 loss: 1.7469384670257568
Batch 22/64 loss: 1.7315049171447754
Batch 23/64 loss: 1.7407562732696533
Batch 24/64 loss: 1.770595908164978
Batch 25/64 loss: 1.7404861450195312
Batch 26/64 loss: 1.7336865663528442
Batch 27/64 loss: 1.7338286638259888
Batch 28/64 loss: 1.7356369495391846
Batch 29/64 loss: 1.7318094968795776
Batch 30/64 loss: 1.7366199493408203
Batch 31/64 loss: 1.739743947982788
Batch 32/64 loss: 1.7331969738006592
Batch 33/64 loss: 1.734632134437561
Batch 34/64 loss: 1.734238624572754
Batch 35/64 loss: 1.7328910827636719
Batch 36/64 loss: 1.7375807762145996
Batch 37/64 loss: 1.7342700958251953
Batch 38/64 loss: 1.7327945232391357
Batch 39/64 loss: 1.7356162071228027
Batch 40/64 loss: 1.7310250997543335
Batch 41/64 loss: 1.7368760108947754
Batch 42/64 loss: 1.7334928512573242
Batch 43/64 loss: 1.7371442317962646
Batch 44/64 loss: 1.7342889308929443
Batch 45/64 loss: 1.731755018234253
Batch 46/64 loss: 1.731892704963684
Batch 47/64 loss: 1.7322006225585938
Batch 48/64 loss: 1.731644630432129
Batch 49/64 loss: 1.7354803085327148
Batch 50/64 loss: 1.7343032360076904
Batch 51/64 loss: 1.7304205894470215
Batch 52/64 loss: 1.7399308681488037
Batch 53/64 loss: 1.7325316667556763
Batch 54/64 loss: 1.734405279159546
Batch 55/64 loss: 1.7323694229125977
Batch 56/64 loss: 1.7330200672149658
Batch 57/64 loss: 1.7384333610534668
Batch 58/64 loss: 1.7403523921966553
Batch 59/64 loss: 1.7375338077545166
Batch 60/64 loss: 1.7345166206359863
Batch 61/64 loss: 1.7363474369049072
Batch 62/64 loss: 1.7337641716003418
Batch 63/64 loss: 1.7332029342651367
Batch 64/64 loss: 1.9432203769683838
Epoch 305  Train loss: 1.7378441464667227  Val loss: 1.756964785126886
Epoch 306
-------------------------------
Batch 1/64 loss: 1.7315735816955566
Batch 2/64 loss: 1.7351784706115723
Batch 3/64 loss: 1.7355289459228516
Batch 4/64 loss: 1.736264944076538
Batch 5/64 loss: 1.7365320920944214
Batch 6/64 loss: 1.7353087663650513
Batch 7/64 loss: 1.7366547584533691
Batch 8/64 loss: 1.738981008529663
Batch 9/64 loss: 1.7355480194091797
Batch 10/64 loss: 1.7363238334655762
Batch 11/64 loss: 1.7411757707595825
Batch 12/64 loss: 1.7361540794372559
Batch 13/64 loss: 1.7410653829574585
Batch 14/64 loss: 1.7529281377792358
Batch 15/64 loss: 1.7391202449798584
Batch 16/64 loss: 1.7346047163009644
Batch 17/64 loss: 1.7388291358947754
Batch 18/64 loss: 1.741236925125122
Batch 19/64 loss: 1.7340548038482666
Batch 20/64 loss: 1.7319412231445312
Batch 21/64 loss: 1.732450246810913
Batch 22/64 loss: 1.7340292930603027
Batch 23/64 loss: 1.7336066961288452
Batch 24/64 loss: 1.730360746383667
Batch 25/64 loss: 1.7464909553527832
Batch 26/64 loss: 1.7364943027496338
Batch 27/64 loss: 1.736804723739624
Batch 28/64 loss: 1.730586290359497
Batch 29/64 loss: 1.7300307750701904
Batch 30/64 loss: 1.732438087463379
Batch 31/64 loss: 1.73384690284729
Batch 32/64 loss: 1.732001543045044
Batch 33/64 loss: 1.7309207916259766
Batch 34/64 loss: 1.7342504262924194
Batch 35/64 loss: 1.733486533164978
Batch 36/64 loss: 1.7326964139938354
Batch 37/64 loss: 1.73372220993042
Batch 38/64 loss: 1.730148434638977
Batch 39/64 loss: 1.7310791015625
Batch 40/64 loss: 1.732665777206421
Batch 41/64 loss: 1.7299394607543945
Batch 42/64 loss: 1.7314376831054688
Batch 43/64 loss: 1.7340095043182373
Batch 44/64 loss: 1.7320950031280518
Batch 45/64 loss: 1.7320356369018555
Batch 46/64 loss: 1.7429921627044678
Batch 47/64 loss: 1.734710693359375
Batch 48/64 loss: 1.7318141460418701
Batch 49/64 loss: 1.7332606315612793
Batch 50/64 loss: 1.7299706935882568
Batch 51/64 loss: 1.7416248321533203
Batch 52/64 loss: 1.7334457635879517
Batch 53/64 loss: 1.731346607208252
Batch 54/64 loss: 1.7337201833724976
Batch 55/64 loss: 1.7334785461425781
Batch 56/64 loss: 1.7295492887496948
Batch 57/64 loss: 1.732079267501831
Batch 58/64 loss: 1.7372090816497803
Batch 59/64 loss: 1.7306768894195557
Batch 60/64 loss: 1.7338111400604248
Batch 61/64 loss: 1.7359516620635986
Batch 62/64 loss: 1.7352039813995361
Batch 63/64 loss: 1.7356388568878174
Batch 64/64 loss: 1.9159722328186035
Epoch 306  Train loss: 1.7369426820792404  Val loss: 1.7508185270316003
Epoch 307
-------------------------------
Batch 1/64 loss: 1.7365732192993164
Batch 2/64 loss: 1.7300422191619873
Batch 3/64 loss: 1.7438530921936035
Batch 4/64 loss: 1.7294261455535889
Batch 5/64 loss: 1.7311028242111206
Batch 6/64 loss: 1.7370799779891968
Batch 7/64 loss: 1.7323994636535645
Batch 8/64 loss: 1.7316555976867676
Batch 9/64 loss: 1.7399595975875854
Batch 10/64 loss: 1.733116865158081
Batch 11/64 loss: 1.7323083877563477
Batch 12/64 loss: 1.7352776527404785
Batch 13/64 loss: 1.7331821918487549
Batch 14/64 loss: 1.7414417266845703
Batch 15/64 loss: 1.7345643043518066
Batch 16/64 loss: 1.735935926437378
Batch 17/64 loss: 1.7365138530731201
Batch 18/64 loss: 1.7340260744094849
Batch 19/64 loss: 1.7320706844329834
Batch 20/64 loss: 1.7338687181472778
Batch 21/64 loss: 1.7367045879364014
Batch 22/64 loss: 1.730417251586914
Batch 23/64 loss: 1.737700343132019
Batch 24/64 loss: 1.734070062637329
Batch 25/64 loss: 1.730571985244751
Batch 26/64 loss: 1.7303866147994995
Batch 27/64 loss: 1.7345149517059326
Batch 28/64 loss: 1.7326006889343262
Batch 29/64 loss: 1.747694492340088
Batch 30/64 loss: 1.7340055704116821
Batch 31/64 loss: 1.7579963207244873
Batch 32/64 loss: 1.7345635890960693
Batch 33/64 loss: 1.7313271760940552
Batch 34/64 loss: 1.7366217374801636
Batch 35/64 loss: 1.7343990802764893
Batch 36/64 loss: 1.730823278427124
Batch 37/64 loss: 1.731292963027954
Batch 38/64 loss: 1.736372709274292
Batch 39/64 loss: 1.7326302528381348
Batch 40/64 loss: 1.7350209951400757
Batch 41/64 loss: 1.7344393730163574
Batch 42/64 loss: 1.7351415157318115
Batch 43/64 loss: 1.7311921119689941
Batch 44/64 loss: 1.7342443466186523
Batch 45/64 loss: 1.7378637790679932
Batch 46/64 loss: 1.733391284942627
Batch 47/64 loss: 1.7416043281555176
Batch 48/64 loss: 1.7345452308654785
Batch 49/64 loss: 1.733586311340332
Batch 50/64 loss: 1.7469719648361206
Batch 51/64 loss: 1.733701229095459
Batch 52/64 loss: 1.7323758602142334
Batch 53/64 loss: 1.7329192161560059
Batch 54/64 loss: 1.7309203147888184
Batch 55/64 loss: 1.7332905530929565
Batch 56/64 loss: 1.731514573097229
Batch 57/64 loss: 1.732717752456665
Batch 58/64 loss: 1.7344560623168945
Batch 59/64 loss: 1.7350378036499023
Batch 60/64 loss: 1.7366338968276978
Batch 61/64 loss: 1.7344107627868652
Batch 62/64 loss: 1.7300186157226562
Batch 63/64 loss: 1.7316644191741943
Batch 64/64 loss: 1.916186809539795
Epoch 307  Train loss: 1.7370022680245194  Val loss: 1.7539980976851945
Epoch 308
-------------------------------
Batch 1/64 loss: 1.7461909055709839
Batch 2/64 loss: 1.73500394821167
Batch 3/64 loss: 1.7327982187271118
Batch 4/64 loss: 1.733469009399414
Batch 5/64 loss: 1.7316534519195557
Batch 6/64 loss: 1.7317183017730713
Batch 7/64 loss: 1.7345242500305176
Batch 8/64 loss: 1.7311674356460571
Batch 9/64 loss: 1.7292495965957642
Batch 10/64 loss: 1.7335224151611328
Batch 11/64 loss: 1.7357420921325684
Batch 12/64 loss: 1.7317979335784912
Batch 13/64 loss: 1.7336714267730713
Batch 14/64 loss: 1.7354042530059814
Batch 15/64 loss: 1.7326903343200684
Batch 16/64 loss: 1.73248291015625
Batch 17/64 loss: 1.734522819519043
Batch 18/64 loss: 1.7464631795883179
Batch 19/64 loss: 1.7457661628723145
Batch 20/64 loss: 1.7351186275482178
Batch 21/64 loss: 1.7313250303268433
Batch 22/64 loss: 1.7331831455230713
Batch 23/64 loss: 1.7294116020202637
Batch 24/64 loss: 1.7326741218566895
Batch 25/64 loss: 1.732998013496399
Batch 26/64 loss: 1.7304037809371948
Batch 27/64 loss: 1.729789137840271
Batch 28/64 loss: 1.7288384437561035
Batch 29/64 loss: 1.7308366298675537
Batch 30/64 loss: 1.7316340208053589
Batch 31/64 loss: 1.7326366901397705
Batch 32/64 loss: 1.7302895784378052
Batch 33/64 loss: 1.7312698364257812
Batch 34/64 loss: 1.731534481048584
Batch 35/64 loss: 1.73056960105896
Batch 36/64 loss: 1.7334394454956055
Batch 37/64 loss: 1.7330373525619507
Batch 38/64 loss: 1.7300317287445068
Batch 39/64 loss: 1.7335453033447266
Batch 40/64 loss: 1.7288293838500977
Batch 41/64 loss: 1.7323414087295532
Batch 42/64 loss: 1.7344897985458374
Batch 43/64 loss: 1.7340327501296997
Batch 44/64 loss: 1.7323007583618164
Batch 45/64 loss: 1.7370529174804688
Batch 46/64 loss: 1.7328698635101318
Batch 47/64 loss: 1.7319401502609253
Batch 48/64 loss: 1.7376117706298828
Batch 49/64 loss: 1.7354373931884766
Batch 50/64 loss: 1.7327837944030762
Batch 51/64 loss: 1.7351508140563965
Batch 52/64 loss: 1.7337934970855713
Batch 53/64 loss: 1.7349181175231934
Batch 54/64 loss: 1.7344377040863037
Batch 55/64 loss: 1.7383813858032227
Batch 56/64 loss: 1.733210563659668
Batch 57/64 loss: 1.7346103191375732
Batch 58/64 loss: 1.7356966733932495
Batch 59/64 loss: 1.7371541261672974
Batch 60/64 loss: 1.736423373222351
Batch 61/64 loss: 1.7309532165527344
Batch 62/64 loss: 1.730639934539795
Batch 63/64 loss: 1.7367000579833984
Batch 64/64 loss: 1.9179600477218628
Epoch 308  Train loss: 1.7358530984205358  Val loss: 1.7549715402609705
Epoch 309
-------------------------------
Batch 1/64 loss: 1.7362089157104492
Batch 2/64 loss: 1.7371106147766113
Batch 3/64 loss: 1.7315294742584229
Batch 4/64 loss: 1.7323338985443115
Batch 5/64 loss: 1.7325035333633423
Batch 6/64 loss: 1.7464549541473389
Batch 7/64 loss: 1.7334160804748535
Batch 8/64 loss: 1.7362191677093506
Batch 9/64 loss: 1.732708215713501
Batch 10/64 loss: 1.7328271865844727
Batch 11/64 loss: 1.7536810636520386
Batch 12/64 loss: 1.7326874732971191
Batch 13/64 loss: 1.7323722839355469
Batch 14/64 loss: 1.7358124256134033
Batch 15/64 loss: 1.734013319015503
Batch 16/64 loss: 1.731006145477295
Batch 17/64 loss: 1.7337826490402222
Batch 18/64 loss: 1.7386082410812378
Batch 19/64 loss: 1.7331570386886597
Batch 20/64 loss: 1.7362947463989258
Batch 21/64 loss: 1.7344284057617188
Batch 22/64 loss: 1.736492395401001
Batch 23/64 loss: 1.7317461967468262
Batch 24/64 loss: 1.7362501621246338
Batch 25/64 loss: 1.7339718341827393
Batch 26/64 loss: 1.746565580368042
Batch 27/64 loss: 1.735194206237793
Batch 28/64 loss: 1.7320650815963745
Batch 29/64 loss: 1.7332409620285034
Batch 30/64 loss: 1.7322096824645996
Batch 31/64 loss: 1.7375431060791016
Batch 32/64 loss: 1.732839822769165
Batch 33/64 loss: 1.7313051223754883
Batch 34/64 loss: 1.7359267473220825
Batch 35/64 loss: 1.7327308654785156
Batch 36/64 loss: 1.730402946472168
Batch 37/64 loss: 1.7362823486328125
Batch 38/64 loss: 1.7338038682937622
Batch 39/64 loss: 1.7284080982208252
Batch 40/64 loss: 1.7292509078979492
Batch 41/64 loss: 1.7337653636932373
Batch 42/64 loss: 1.7399959564208984
Batch 43/64 loss: 1.7337546348571777
Batch 44/64 loss: 1.7305891513824463
Batch 45/64 loss: 1.736435890197754
Batch 46/64 loss: 1.7322380542755127
Batch 47/64 loss: 1.7321444749832153
Batch 48/64 loss: 1.7340456247329712
Batch 49/64 loss: 1.7322193384170532
Batch 50/64 loss: 1.7312757968902588
Batch 51/64 loss: 1.7329013347625732
Batch 52/64 loss: 1.7318663597106934
Batch 53/64 loss: 1.7336716651916504
Batch 54/64 loss: 1.7302745580673218
Batch 55/64 loss: 1.7312841415405273
Batch 56/64 loss: 1.7336146831512451
Batch 57/64 loss: 1.7324084043502808
Batch 58/64 loss: 1.7339396476745605
Batch 59/64 loss: 1.7336246967315674
Batch 60/64 loss: 1.73280668258667
Batch 61/64 loss: 1.732487678527832
Batch 62/64 loss: 1.7347267866134644
Batch 63/64 loss: 1.7315349578857422
Batch 64/64 loss: 1.9188437461853027
Epoch 309  Train loss: 1.736378422905417  Val loss: 1.7533498924622422
Epoch 310
-------------------------------
Batch 1/64 loss: 1.7314202785491943
Batch 2/64 loss: 1.734097957611084
Batch 3/64 loss: 1.7335445880889893
Batch 4/64 loss: 1.731110692024231
Batch 5/64 loss: 1.7382392883300781
Batch 6/64 loss: 1.7305071353912354
Batch 7/64 loss: 1.7328393459320068
Batch 8/64 loss: 1.7332193851470947
Batch 9/64 loss: 1.7337095737457275
Batch 10/64 loss: 1.7330665588378906
Batch 11/64 loss: 1.7334485054016113
Batch 12/64 loss: 1.734753131866455
Batch 13/64 loss: 1.732029676437378
Batch 14/64 loss: 1.7323365211486816
Batch 15/64 loss: 1.7348458766937256
Batch 16/64 loss: 1.7352161407470703
Batch 17/64 loss: 1.7347474098205566
Batch 18/64 loss: 1.7488715648651123
Batch 19/64 loss: 1.7300301790237427
Batch 20/64 loss: 1.7365779876708984
Batch 21/64 loss: 1.732722520828247
Batch 22/64 loss: 1.7337720394134521
Batch 23/64 loss: 1.731723427772522
Batch 24/64 loss: 1.7324180603027344
Batch 25/64 loss: 1.731919765472412
Batch 26/64 loss: 1.7333743572235107
Batch 27/64 loss: 1.7307666540145874
Batch 28/64 loss: 1.7399826049804688
Batch 29/64 loss: 1.738320231437683
Batch 30/64 loss: 1.7365832328796387
Batch 31/64 loss: 1.754685878753662
Batch 32/64 loss: 1.7331702709197998
Batch 33/64 loss: 1.7347180843353271
Batch 34/64 loss: 1.7360544204711914
Batch 35/64 loss: 1.7367640733718872
Batch 36/64 loss: 1.733649730682373
Batch 37/64 loss: 1.735029935836792
Batch 38/64 loss: 1.736090898513794
Batch 39/64 loss: 1.736550211906433
Batch 40/64 loss: 1.7308921813964844
Batch 41/64 loss: 1.730992078781128
Batch 42/64 loss: 1.7343835830688477
Batch 43/64 loss: 1.7502086162567139
Batch 44/64 loss: 1.732640027999878
Batch 45/64 loss: 1.7360937595367432
Batch 46/64 loss: 1.7361748218536377
Batch 47/64 loss: 1.7408214807510376
Batch 48/64 loss: 1.7442121505737305
Batch 49/64 loss: 1.738297700881958
Batch 50/64 loss: 1.7374804019927979
Batch 51/64 loss: 1.735656976699829
Batch 52/64 loss: 1.7361531257629395
Batch 53/64 loss: 1.737438440322876
Batch 54/64 loss: 1.7373754978179932
Batch 55/64 loss: 1.7399945259094238
Batch 56/64 loss: 1.7554564476013184
Batch 57/64 loss: 1.7359259128570557
Batch 58/64 loss: 1.7349092960357666
Batch 59/64 loss: 1.7346124649047852
Batch 60/64 loss: 1.737732172012329
Batch 61/64 loss: 1.732520580291748
Batch 62/64 loss: 1.7348653078079224
Batch 63/64 loss: 1.7361769676208496
Batch 64/64 loss: 1.9231538772583008
Epoch 310  Train loss: 1.7381378529118556  Val loss: 1.7545971174010706
Epoch 311
-------------------------------
Batch 1/64 loss: 1.734616756439209
Batch 2/64 loss: 1.7369379997253418
Batch 3/64 loss: 1.7359845638275146
Batch 4/64 loss: 1.7334095239639282
Batch 5/64 loss: 1.735011100769043
Batch 6/64 loss: 1.7332717180252075
Batch 7/64 loss: 1.7349357604980469
Batch 8/64 loss: 1.7356696128845215
Batch 9/64 loss: 1.737557291984558
Batch 10/64 loss: 1.7311644554138184
Batch 11/64 loss: 1.7312098741531372
Batch 12/64 loss: 1.7344586849212646
Batch 13/64 loss: 1.731357455253601
Batch 14/64 loss: 1.7348554134368896
Batch 15/64 loss: 1.7328110933303833
Batch 16/64 loss: 1.7362186908721924
Batch 17/64 loss: 1.7325843572616577
Batch 18/64 loss: 1.7393476963043213
Batch 19/64 loss: 1.7484755516052246
Batch 20/64 loss: 1.7328886985778809
Batch 21/64 loss: 1.732820749282837
Batch 22/64 loss: 1.732712984085083
Batch 23/64 loss: 1.73517644405365
Batch 24/64 loss: 1.7363022565841675
Batch 25/64 loss: 1.7347408533096313
Batch 26/64 loss: 1.736618995666504
Batch 27/64 loss: 1.7340772151947021
Batch 28/64 loss: 1.7300220727920532
Batch 29/64 loss: 1.7297918796539307
Batch 30/64 loss: 1.7329161167144775
Batch 31/64 loss: 1.7296514511108398
Batch 32/64 loss: 1.7330536842346191
Batch 33/64 loss: 1.7318739891052246
Batch 34/64 loss: 1.7318346500396729
Batch 35/64 loss: 1.7318623065948486
Batch 36/64 loss: 1.7315521240234375
Batch 37/64 loss: 1.732182502746582
Batch 38/64 loss: 1.7345242500305176
Batch 39/64 loss: 1.735703706741333
Batch 40/64 loss: 1.73136305809021
Batch 41/64 loss: 1.7328765392303467
Batch 42/64 loss: 1.7308640480041504
Batch 43/64 loss: 1.7463600635528564
Batch 44/64 loss: 1.7318906784057617
Batch 45/64 loss: 1.7329213619232178
Batch 46/64 loss: 1.7307603359222412
Batch 47/64 loss: 1.7339081764221191
Batch 48/64 loss: 1.7296576499938965
Batch 49/64 loss: 1.7308789491653442
Batch 50/64 loss: 1.7363927364349365
Batch 51/64 loss: 1.7341017723083496
Batch 52/64 loss: 1.7337565422058105
Batch 53/64 loss: 1.7400637865066528
Batch 54/64 loss: 1.7313244342803955
Batch 55/64 loss: 1.739052653312683
Batch 56/64 loss: 1.753830075263977
Batch 57/64 loss: 1.7362918853759766
Batch 58/64 loss: 1.7341340780258179
Batch 59/64 loss: 1.7377450466156006
Batch 60/64 loss: 1.733847975730896
Batch 61/64 loss: 1.733339786529541
Batch 62/64 loss: 1.7392194271087646
Batch 63/64 loss: 1.73564612865448
Batch 64/64 loss: 1.9283192157745361
Epoch 311  Train loss: 1.736888645209518  Val loss: 1.7534425684676547
Epoch 312
-------------------------------
Batch 1/64 loss: 1.737050175666809
Batch 2/64 loss: 1.7319244146347046
Batch 3/64 loss: 1.7347817420959473
Batch 4/64 loss: 1.7336146831512451
Batch 5/64 loss: 1.7318308353424072
Batch 6/64 loss: 1.7377028465270996
Batch 7/64 loss: 1.7339539527893066
Batch 8/64 loss: 1.7357101440429688
Batch 9/64 loss: 1.7341113090515137
Batch 10/64 loss: 1.7336504459381104
Batch 11/64 loss: 1.730538249015808
Batch 12/64 loss: 1.7327425479888916
Batch 13/64 loss: 1.7320277690887451
Batch 14/64 loss: 1.730750560760498
Batch 15/64 loss: 1.7474596500396729
Batch 16/64 loss: 1.7307062149047852
Batch 17/64 loss: 1.7364948987960815
Batch 18/64 loss: 1.73465895652771
Batch 19/64 loss: 1.7330448627471924
Batch 20/64 loss: 1.732596516609192
Batch 21/64 loss: 1.7310569286346436
Batch 22/64 loss: 1.7317196130752563
Batch 23/64 loss: 1.7394487857818604
Batch 24/64 loss: 1.7403597831726074
Batch 25/64 loss: 1.736485481262207
Batch 26/64 loss: 1.7326866388320923
Batch 27/64 loss: 1.7352571487426758
Batch 28/64 loss: 1.7357789278030396
Batch 29/64 loss: 1.7325290441513062
Batch 30/64 loss: 1.7334325313568115
Batch 31/64 loss: 1.7338383197784424
Batch 32/64 loss: 1.7318921089172363
Batch 33/64 loss: 1.735597848892212
Batch 34/64 loss: 1.7330453395843506
Batch 35/64 loss: 1.7325770854949951
Batch 36/64 loss: 1.7329199314117432
Batch 37/64 loss: 1.733088731765747
Batch 38/64 loss: 1.734194278717041
Batch 39/64 loss: 1.7515537738800049
Batch 40/64 loss: 1.734403133392334
Batch 41/64 loss: 1.7369236946105957
Batch 42/64 loss: 1.7351012229919434
Batch 43/64 loss: 1.7323479652404785
Batch 44/64 loss: 1.7335081100463867
Batch 45/64 loss: 1.7437255382537842
Batch 46/64 loss: 1.7397137880325317
Batch 47/64 loss: 1.7341971397399902
Batch 48/64 loss: 1.7342255115509033
Batch 49/64 loss: 1.7359304428100586
Batch 50/64 loss: 1.7346503734588623
Batch 51/64 loss: 1.7355830669403076
Batch 52/64 loss: 1.7387888431549072
Batch 53/64 loss: 1.7340655326843262
Batch 54/64 loss: 1.7321271896362305
Batch 55/64 loss: 1.7337212562561035
Batch 56/64 loss: 1.7545228004455566
Batch 57/64 loss: 1.7343425750732422
Batch 58/64 loss: 1.73666512966156
Batch 59/64 loss: 1.7345530986785889
Batch 60/64 loss: 1.7357304096221924
Batch 61/64 loss: 1.7355105876922607
Batch 62/64 loss: 1.7354919910430908
Batch 63/64 loss: 1.7391512393951416
Batch 64/64 loss: 1.9172322750091553
Epoch 312  Train loss: 1.7375014576257444  Val loss: 1.7559035627293014
Epoch 313
-------------------------------
Batch 1/64 loss: 1.7361335754394531
Batch 2/64 loss: 1.7323839664459229
Batch 3/64 loss: 1.7328786849975586
Batch 4/64 loss: 1.7371715307235718
Batch 5/64 loss: 1.7398573160171509
Batch 6/64 loss: 1.7346863746643066
Batch 7/64 loss: 1.734870195388794
Batch 8/64 loss: 1.75150465965271
Batch 9/64 loss: 1.7312413454055786
Batch 10/64 loss: 1.7378288507461548
Batch 11/64 loss: 1.733790636062622
Batch 12/64 loss: 1.732378363609314
Batch 13/64 loss: 1.7366714477539062
Batch 14/64 loss: 1.7337359189987183
Batch 15/64 loss: 1.7284016609191895
Batch 16/64 loss: 1.731356143951416
Batch 17/64 loss: 1.7476086616516113
Batch 18/64 loss: 1.7315552234649658
Batch 19/64 loss: 1.7304978370666504
Batch 20/64 loss: 1.7331795692443848
Batch 21/64 loss: 1.7337883710861206
Batch 22/64 loss: 1.7342541217803955
Batch 23/64 loss: 1.7312097549438477
Batch 24/64 loss: 1.7350059747695923
Batch 25/64 loss: 1.7336996793746948
Batch 26/64 loss: 1.7347936630249023
Batch 27/64 loss: 1.7323684692382812
Batch 28/64 loss: 1.7335906028747559
Batch 29/64 loss: 1.739060878753662
Batch 30/64 loss: 1.7358298301696777
Batch 31/64 loss: 1.734495759010315
Batch 32/64 loss: 1.7347803115844727
Batch 33/64 loss: 1.734290361404419
Batch 34/64 loss: 1.7349236011505127
Batch 35/64 loss: 1.7385826110839844
Batch 36/64 loss: 1.7557435035705566
Batch 37/64 loss: 1.7320916652679443
Batch 38/64 loss: 1.7357531785964966
Batch 39/64 loss: 1.7306058406829834
Batch 40/64 loss: 1.7340114116668701
Batch 41/64 loss: 1.7367130517959595
Batch 42/64 loss: 1.7339777946472168
Batch 43/64 loss: 1.7324035167694092
Batch 44/64 loss: 1.730494737625122
Batch 45/64 loss: 1.740394115447998
Batch 46/64 loss: 1.7360336780548096
Batch 47/64 loss: 1.7337193489074707
Batch 48/64 loss: 1.7296433448791504
Batch 49/64 loss: 1.7327933311462402
Batch 50/64 loss: 1.7333413362503052
Batch 51/64 loss: 1.7339401245117188
Batch 52/64 loss: 1.7300069332122803
Batch 53/64 loss: 1.736912488937378
Batch 54/64 loss: 1.7374638319015503
Batch 55/64 loss: 1.730440378189087
Batch 56/64 loss: 1.7299153804779053
Batch 57/64 loss: 1.7316956520080566
Batch 58/64 loss: 1.7286113500595093
Batch 59/64 loss: 1.7348458766937256
Batch 60/64 loss: 1.7327537536621094
Batch 61/64 loss: 1.733922004699707
Batch 62/64 loss: 1.7395110130310059
Batch 63/64 loss: 1.729790449142456
Batch 64/64 loss: 1.9262442588806152
Epoch 313  Train loss: 1.7369508743286133  Val loss: 1.7507865035656802
Epoch 314
-------------------------------
Batch 1/64 loss: 1.7282991409301758
Batch 2/64 loss: 1.7302157878875732
Batch 3/64 loss: 1.7336738109588623
Batch 4/64 loss: 1.7320497035980225
Batch 5/64 loss: 1.7345807552337646
Batch 6/64 loss: 1.7350654602050781
Batch 7/64 loss: 1.7324795722961426
Batch 8/64 loss: 1.7346848249435425
Batch 9/64 loss: 1.7297325134277344
Batch 10/64 loss: 1.7308464050292969
Batch 11/64 loss: 1.7331702709197998
Batch 12/64 loss: 1.7338923215866089
Batch 13/64 loss: 1.7436537742614746
Batch 14/64 loss: 1.7304341793060303
Batch 15/64 loss: 1.7288382053375244
Batch 16/64 loss: 1.7351834774017334
Batch 17/64 loss: 1.7311877012252808
Batch 18/64 loss: 1.7512593269348145
Batch 19/64 loss: 1.735431432723999
Batch 20/64 loss: 1.7324986457824707
Batch 21/64 loss: 1.730486273765564
Batch 22/64 loss: 1.7280433177947998
Batch 23/64 loss: 1.7304575443267822
Batch 24/64 loss: 1.729236364364624
Batch 25/64 loss: 1.7301945686340332
Batch 26/64 loss: 1.7321619987487793
Batch 27/64 loss: 1.7351243495941162
Batch 28/64 loss: 1.7352006435394287
Batch 29/64 loss: 1.7325963973999023
Batch 30/64 loss: 1.7286626100540161
Batch 31/64 loss: 1.7350811958312988
Batch 32/64 loss: 1.7325193881988525
Batch 33/64 loss: 1.7393181324005127
Batch 34/64 loss: 1.7302026748657227
Batch 35/64 loss: 1.7357747554779053
Batch 36/64 loss: 1.7318034172058105
Batch 37/64 loss: 1.7366650104522705
Batch 38/64 loss: 1.7325904369354248
Batch 39/64 loss: 1.7289092540740967
Batch 40/64 loss: 1.7320551872253418
Batch 41/64 loss: 1.7293195724487305
Batch 42/64 loss: 1.729588270187378
Batch 43/64 loss: 1.7343460321426392
Batch 44/64 loss: 1.7374286651611328
Batch 45/64 loss: 1.7322940826416016
Batch 46/64 loss: 1.7374937534332275
Batch 47/64 loss: 1.7365691661834717
Batch 48/64 loss: 1.7316339015960693
Batch 49/64 loss: 1.7342541217803955
Batch 50/64 loss: 1.7315431833267212
Batch 51/64 loss: 1.7302149534225464
Batch 52/64 loss: 1.731285572052002
Batch 53/64 loss: 1.7338099479675293
Batch 54/64 loss: 1.7288854122161865
Batch 55/64 loss: 1.7375352382659912
Batch 56/64 loss: 1.7348864078521729
Batch 57/64 loss: 1.7322367429733276
Batch 58/64 loss: 1.7352705001831055
Batch 59/64 loss: 1.731940746307373
Batch 60/64 loss: 1.7314395904541016
Batch 61/64 loss: 1.7526556253433228
Batch 62/64 loss: 1.733032464981079
Batch 63/64 loss: 1.7348346710205078
Batch 64/64 loss: 1.918253779411316
Epoch 314  Train loss: 1.7356148986255422  Val loss: 1.7528763980799933
Epoch 315
-------------------------------
Batch 1/64 loss: 1.7315969467163086
Batch 2/64 loss: 1.7314887046813965
Batch 3/64 loss: 1.7453534603118896
Batch 4/64 loss: 1.7321994304656982
Batch 5/64 loss: 1.7323552370071411
Batch 6/64 loss: 1.742278814315796
Batch 7/64 loss: 1.7324602603912354
Batch 8/64 loss: 1.7454841136932373
Batch 9/64 loss: 1.730742335319519
Batch 10/64 loss: 1.7318323850631714
Batch 11/64 loss: 1.7346835136413574
Batch 12/64 loss: 1.7347190380096436
Batch 13/64 loss: 1.730510950088501
Batch 14/64 loss: 1.7370414733886719
Batch 15/64 loss: 1.7310826778411865
Batch 16/64 loss: 1.7295019626617432
Batch 17/64 loss: 1.7508795261383057
Batch 18/64 loss: 1.736189365386963
Batch 19/64 loss: 1.731952428817749
Batch 20/64 loss: 1.7322027683258057
Batch 21/64 loss: 1.7320168018341064
Batch 22/64 loss: 1.7332175970077515
Batch 23/64 loss: 1.7418439388275146
Batch 24/64 loss: 1.7361483573913574
Batch 25/64 loss: 1.7348359823226929
Batch 26/64 loss: 1.7354587316513062
Batch 27/64 loss: 1.732028603553772
Batch 28/64 loss: 1.7345077991485596
Batch 29/64 loss: 1.7413197755813599
Batch 30/64 loss: 1.7367680072784424
Batch 31/64 loss: 1.7340149879455566
Batch 32/64 loss: 1.7361972332000732
Batch 33/64 loss: 1.7359143495559692
Batch 34/64 loss: 1.7356019020080566
Batch 35/64 loss: 1.7411730289459229
Batch 36/64 loss: 1.7392561435699463
Batch 37/64 loss: 1.7451400756835938
Batch 38/64 loss: 1.7373985052108765
Batch 39/64 loss: 1.7322735786437988
Batch 40/64 loss: 1.7378932237625122
Batch 41/64 loss: 1.7347691059112549
Batch 42/64 loss: 1.7350656986236572
Batch 43/64 loss: 1.7384064197540283
Batch 44/64 loss: 1.7352815866470337
Batch 45/64 loss: 1.7368180751800537
Batch 46/64 loss: 1.7369122505187988
Batch 47/64 loss: 1.7400941848754883
Batch 48/64 loss: 1.735337257385254
Batch 49/64 loss: 1.732049822807312
Batch 50/64 loss: 1.7299213409423828
Batch 51/64 loss: 1.7323881387710571
Batch 52/64 loss: 1.7391948699951172
Batch 53/64 loss: 1.7296465635299683
Batch 54/64 loss: 1.7327489852905273
Batch 55/64 loss: 1.732390284538269
Batch 56/64 loss: 1.7299706935882568
Batch 57/64 loss: 1.7296578884124756
Batch 58/64 loss: 1.734131097793579
Batch 59/64 loss: 1.7330152988433838
Batch 60/64 loss: 1.7345495223999023
Batch 61/64 loss: 1.7313711643218994
Batch 62/64 loss: 1.7325557470321655
Batch 63/64 loss: 1.7323517799377441
Batch 64/64 loss: 1.916408896446228
Epoch 315  Train loss: 1.7373097798403572  Val loss: 1.749868861588416
Epoch 316
-------------------------------
Batch 1/64 loss: 1.7298927307128906
Batch 2/64 loss: 1.7323713302612305
Batch 3/64 loss: 1.7481026649475098
Batch 4/64 loss: 1.730832815170288
Batch 5/64 loss: 1.73395836353302
Batch 6/64 loss: 1.7349495887756348
Batch 7/64 loss: 1.7335205078125
Batch 8/64 loss: 1.7341243028640747
Batch 9/64 loss: 1.7300946712493896
Batch 10/64 loss: 1.730621576309204
Batch 11/64 loss: 1.7291347980499268
Batch 12/64 loss: 1.7367687225341797
Batch 13/64 loss: 1.7309842109680176
Batch 14/64 loss: 1.7297321557998657
Batch 15/64 loss: 1.732452154159546
Batch 16/64 loss: 1.7322968244552612
Batch 17/64 loss: 1.7278690338134766
Batch 18/64 loss: 1.7325063943862915
Batch 19/64 loss: 1.7302968502044678
Batch 20/64 loss: 1.7327494621276855
Batch 21/64 loss: 1.7316635847091675
Batch 22/64 loss: 1.73341965675354
Batch 23/64 loss: 1.7295303344726562
Batch 24/64 loss: 1.7296264171600342
Batch 25/64 loss: 1.733629822731018
Batch 26/64 loss: 1.7313026189804077
Batch 27/64 loss: 1.7295984029769897
Batch 28/64 loss: 1.7336636781692505
Batch 29/64 loss: 1.7323753833770752
Batch 30/64 loss: 1.7317652702331543
Batch 31/64 loss: 1.7314529418945312
Batch 32/64 loss: 1.740135908126831
Batch 33/64 loss: 1.7335776090621948
Batch 34/64 loss: 1.7382713556289673
Batch 35/64 loss: 1.7308931350708008
Batch 36/64 loss: 1.7332284450531006
Batch 37/64 loss: 1.7340123653411865
Batch 38/64 loss: 1.7318438291549683
Batch 39/64 loss: 1.734886884689331
Batch 40/64 loss: 1.7300913333892822
Batch 41/64 loss: 1.7355570793151855
Batch 42/64 loss: 1.7305903434753418
Batch 43/64 loss: 1.7331221103668213
Batch 44/64 loss: 1.7283543348312378
Batch 45/64 loss: 1.7293730974197388
Batch 46/64 loss: 1.7327641248703003
Batch 47/64 loss: 1.7331316471099854
Batch 48/64 loss: 1.7313129901885986
Batch 49/64 loss: 1.734818696975708
Batch 50/64 loss: 1.730743169784546
Batch 51/64 loss: 1.7304511070251465
Batch 52/64 loss: 1.7302923202514648
Batch 53/64 loss: 1.730778694152832
Batch 54/64 loss: 1.7288308143615723
Batch 55/64 loss: 1.7427515983581543
Batch 56/64 loss: 1.735353708267212
Batch 57/64 loss: 1.73333740234375
Batch 58/64 loss: 1.7301878929138184
Batch 59/64 loss: 1.7303663492202759
Batch 60/64 loss: 1.7305916547775269
Batch 61/64 loss: 1.7305173873901367
Batch 62/64 loss: 1.744145393371582
Batch 63/64 loss: 1.733991026878357
Batch 64/64 loss: 1.915391206741333
Epoch 316  Train loss: 1.7348413252363017  Val loss: 1.7480953829394992
Saving best model, epoch: 316
Epoch 317
-------------------------------
Batch 1/64 loss: 1.734809160232544
Batch 2/64 loss: 1.734187364578247
Batch 3/64 loss: 1.7287406921386719
Batch 4/64 loss: 1.7304468154907227
Batch 5/64 loss: 1.7309156656265259
Batch 6/64 loss: 1.7342190742492676
Batch 7/64 loss: 1.7291676998138428
Batch 8/64 loss: 1.733838677406311
Batch 9/64 loss: 1.7304036617279053
Batch 10/64 loss: 1.7310450077056885
Batch 11/64 loss: 1.7333961725234985
Batch 12/64 loss: 1.7314369678497314
Batch 13/64 loss: 1.732168197631836
Batch 14/64 loss: 1.7341442108154297
Batch 15/64 loss: 1.730712652206421
Batch 16/64 loss: 1.732527256011963
Batch 17/64 loss: 1.7290682792663574
Batch 18/64 loss: 1.7449853420257568
Batch 19/64 loss: 1.73818039894104
Batch 20/64 loss: 1.7307426929473877
Batch 21/64 loss: 1.7347180843353271
Batch 22/64 loss: 1.7357203960418701
Batch 23/64 loss: 1.730571985244751
Batch 24/64 loss: 1.7373988628387451
Batch 25/64 loss: 1.7464628219604492
Batch 26/64 loss: 1.729095697402954
Batch 27/64 loss: 1.7317173480987549
Batch 28/64 loss: 1.7333893775939941
Batch 29/64 loss: 1.7340502738952637
Batch 30/64 loss: 1.750394344329834
Batch 31/64 loss: 1.7359580993652344
Batch 32/64 loss: 1.742311954498291
Batch 33/64 loss: 1.732590675354004
Batch 34/64 loss: 1.7381476163864136
Batch 35/64 loss: 1.7310689687728882
Batch 36/64 loss: 1.7324823141098022
Batch 37/64 loss: 1.7393391132354736
Batch 38/64 loss: 1.7329736948013306
Batch 39/64 loss: 1.7316808700561523
Batch 40/64 loss: 1.7329602241516113
Batch 41/64 loss: 1.730217695236206
Batch 42/64 loss: 1.7311309576034546
Batch 43/64 loss: 1.7335577011108398
Batch 44/64 loss: 1.7305961847305298
Batch 45/64 loss: 1.7293987274169922
Batch 46/64 loss: 1.7313530445098877
Batch 47/64 loss: 1.7293736934661865
Batch 48/64 loss: 1.729701280593872
Batch 49/64 loss: 1.7299946546554565
Batch 50/64 loss: 1.7307751178741455
Batch 51/64 loss: 1.7332172393798828
Batch 52/64 loss: 1.7280608415603638
Batch 53/64 loss: 1.7315983772277832
Batch 54/64 loss: 1.7296833992004395
Batch 55/64 loss: 1.731259822845459
Batch 56/64 loss: 1.7296063899993896
Batch 57/64 loss: 1.7328364849090576
Batch 58/64 loss: 1.7351922988891602
Batch 59/64 loss: 1.7319388389587402
Batch 60/64 loss: 1.7291405200958252
Batch 61/64 loss: 1.7293561697006226
Batch 62/64 loss: 1.7357186079025269
Batch 63/64 loss: 1.736726999282837
Batch 64/64 loss: 1.914054274559021
Epoch 317  Train loss: 1.7352806974859798  Val loss: 1.7490920528923113
Epoch 318
-------------------------------
Batch 1/64 loss: 1.735226035118103
Batch 2/64 loss: 1.7307512760162354
Batch 3/64 loss: 1.7333953380584717
Batch 4/64 loss: 1.7321407794952393
Batch 5/64 loss: 1.7297544479370117
Batch 6/64 loss: 1.7315101623535156
Batch 7/64 loss: 1.7307281494140625
Batch 8/64 loss: 1.729270100593567
Batch 9/64 loss: 1.7421345710754395
Batch 10/64 loss: 1.730016827583313
Batch 11/64 loss: 1.7288014888763428
Batch 12/64 loss: 1.7281708717346191
Batch 13/64 loss: 1.7303647994995117
Batch 14/64 loss: 1.7294788360595703
Batch 15/64 loss: 1.728065013885498
Batch 16/64 loss: 1.7321101427078247
Batch 17/64 loss: 1.7317302227020264
Batch 18/64 loss: 1.7406291961669922
Batch 19/64 loss: 1.7338846921920776
Batch 20/64 loss: 1.7319540977478027
Batch 21/64 loss: 1.7356042861938477
Batch 22/64 loss: 1.730701208114624
Batch 23/64 loss: 1.7354717254638672
Batch 24/64 loss: 1.7314915657043457
Batch 25/64 loss: 1.7306063175201416
Batch 26/64 loss: 1.7292749881744385
Batch 27/64 loss: 1.7318446636199951
Batch 28/64 loss: 1.7289437055587769
Batch 29/64 loss: 1.7349750995635986
Batch 30/64 loss: 1.7311396598815918
Batch 31/64 loss: 1.7312852144241333
Batch 32/64 loss: 1.7361171245574951
Batch 33/64 loss: 1.7366410493850708
Batch 34/64 loss: 1.7331879138946533
Batch 35/64 loss: 1.7287664413452148
Batch 36/64 loss: 1.7353699207305908
Batch 37/64 loss: 1.7376792430877686
Batch 38/64 loss: 1.7349121570587158
Batch 39/64 loss: 1.735154628753662
Batch 40/64 loss: 1.732961893081665
Batch 41/64 loss: 1.743329405784607
Batch 42/64 loss: 1.736890196800232
Batch 43/64 loss: 1.7320924997329712
Batch 44/64 loss: 1.7353084087371826
Batch 45/64 loss: 1.7358638048171997
Batch 46/64 loss: 1.7320375442504883
Batch 47/64 loss: 1.740272045135498
Batch 48/64 loss: 1.732810139656067
Batch 49/64 loss: 1.7317068576812744
Batch 50/64 loss: 1.7352769374847412
Batch 51/64 loss: 1.7401833534240723
Batch 52/64 loss: 1.7345619201660156
Batch 53/64 loss: 1.7469462156295776
Batch 54/64 loss: 1.7313733100891113
Batch 55/64 loss: 1.7386554479599
Batch 56/64 loss: 1.7484571933746338
Batch 57/64 loss: 1.733513355255127
Batch 58/64 loss: 1.732022762298584
Batch 59/64 loss: 1.7326765060424805
Batch 60/64 loss: 1.732446551322937
Batch 61/64 loss: 1.737269401550293
Batch 62/64 loss: 1.732847809791565
Batch 63/64 loss: 1.731222152709961
Batch 64/64 loss: 1.920072078704834
Epoch 318  Train loss: 1.7360009997498755  Val loss: 1.7497009272427904
Epoch 319
-------------------------------
Batch 1/64 loss: 1.7318875789642334
Batch 2/64 loss: 1.731557846069336
Batch 3/64 loss: 1.7352683544158936
Batch 4/64 loss: 1.7301870584487915
Batch 5/64 loss: 1.7326323986053467
Batch 6/64 loss: 1.7335683107376099
Batch 7/64 loss: 1.7440179586410522
Batch 8/64 loss: 1.7318553924560547
Batch 9/64 loss: 1.7377498149871826
Batch 10/64 loss: 1.7353465557098389
Batch 11/64 loss: 1.7303619384765625
Batch 12/64 loss: 1.7346312999725342
Batch 13/64 loss: 1.7302348613739014
Batch 14/64 loss: 1.7338385581970215
Batch 15/64 loss: 1.732210636138916
Batch 16/64 loss: 1.7338652610778809
Batch 17/64 loss: 1.7321081161499023
Batch 18/64 loss: 1.73629629611969
Batch 19/64 loss: 1.7290642261505127
Batch 20/64 loss: 1.733710527420044
Batch 21/64 loss: 1.7304422855377197
Batch 22/64 loss: 1.7335551977157593
Batch 23/64 loss: 1.7294883728027344
Batch 24/64 loss: 1.7293181419372559
Batch 25/64 loss: 1.7301923036575317
Batch 26/64 loss: 1.743379831314087
Batch 27/64 loss: 1.7354841232299805
Batch 28/64 loss: 1.729363203048706
Batch 29/64 loss: 1.73095703125
Batch 30/64 loss: 1.7289981842041016
Batch 31/64 loss: 1.728564977645874
Batch 32/64 loss: 1.730623483657837
Batch 33/64 loss: 1.7307429313659668
Batch 34/64 loss: 1.7316814661026
Batch 35/64 loss: 1.7314801216125488
Batch 36/64 loss: 1.7344281673431396
Batch 37/64 loss: 1.7284151315689087
Batch 38/64 loss: 1.7326974868774414
Batch 39/64 loss: 1.729565143585205
Batch 40/64 loss: 1.7291452884674072
Batch 41/64 loss: 1.7323790788650513
Batch 42/64 loss: 1.7334868907928467
Batch 43/64 loss: 1.7323180437088013
Batch 44/64 loss: 1.7333292961120605
Batch 45/64 loss: 1.7327024936676025
Batch 46/64 loss: 1.7338385581970215
Batch 47/64 loss: 1.7318992614746094
Batch 48/64 loss: 1.7315680980682373
Batch 49/64 loss: 1.7326152324676514
Batch 50/64 loss: 1.7326738834381104
Batch 51/64 loss: 1.7325153350830078
Batch 52/64 loss: 1.7551147937774658
Batch 53/64 loss: 1.7348895072937012
Batch 54/64 loss: 1.734065294265747
Batch 55/64 loss: 1.734551191329956
Batch 56/64 loss: 1.7373766899108887
Batch 57/64 loss: 1.737065076828003
Batch 58/64 loss: 1.7416062355041504
Batch 59/64 loss: 1.732982873916626
Batch 60/64 loss: 1.7364166975021362
Batch 61/64 loss: 1.7329307794570923
Batch 62/64 loss: 1.7316653728485107
Batch 63/64 loss: 1.7404797077178955
Batch 64/64 loss: 1.9204022884368896
Epoch 319  Train loss: 1.7356500073975207  Val loss: 1.7498949876765615
Epoch 320
-------------------------------
Batch 1/64 loss: 1.7321078777313232
Batch 2/64 loss: 1.7498691082000732
Batch 3/64 loss: 1.732930302619934
Batch 4/64 loss: 1.7313975095748901
Batch 5/64 loss: 1.7322494983673096
Batch 6/64 loss: 1.7324621677398682
Batch 7/64 loss: 1.735023856163025
Batch 8/64 loss: 1.7311999797821045
Batch 9/64 loss: 1.736083745956421
Batch 10/64 loss: 1.729304313659668
Batch 11/64 loss: 1.7303667068481445
Batch 12/64 loss: 1.7283787727355957
Batch 13/64 loss: 1.7348015308380127
Batch 14/64 loss: 1.73109769821167
Batch 15/64 loss: 1.731014609336853
Batch 16/64 loss: 1.72886061668396
Batch 17/64 loss: 1.7304348945617676
Batch 18/64 loss: 1.7301290035247803
Batch 19/64 loss: 1.726621150970459
Batch 20/64 loss: 1.7302806377410889
Batch 21/64 loss: 1.7291374206542969
Batch 22/64 loss: 1.7326507568359375
Batch 23/64 loss: 1.730431079864502
Batch 24/64 loss: 1.7315222024917603
Batch 25/64 loss: 1.7440707683563232
Batch 26/64 loss: 1.7391430139541626
Batch 27/64 loss: 1.7314362525939941
Batch 28/64 loss: 1.7303403615951538
Batch 29/64 loss: 1.7343751192092896
Batch 30/64 loss: 1.7298094034194946
Batch 31/64 loss: 1.7335340976715088
Batch 32/64 loss: 1.730644702911377
Batch 33/64 loss: 1.7316627502441406
Batch 34/64 loss: 1.7325786352157593
Batch 35/64 loss: 1.729668378829956
Batch 36/64 loss: 1.731581449508667
Batch 37/64 loss: 1.739311933517456
Batch 38/64 loss: 1.729506015777588
Batch 39/64 loss: 1.7429049015045166
Batch 40/64 loss: 1.7341396808624268
Batch 41/64 loss: 1.7322416305541992
Batch 42/64 loss: 1.7366259098052979
Batch 43/64 loss: 1.730694055557251
Batch 44/64 loss: 1.7367832660675049
Batch 45/64 loss: 1.733805537223816
Batch 46/64 loss: 1.7329349517822266
Batch 47/64 loss: 1.732783555984497
Batch 48/64 loss: 1.7322864532470703
Batch 49/64 loss: 1.7358486652374268
Batch 50/64 loss: 1.7399053573608398
Batch 51/64 loss: 1.7338173389434814
Batch 52/64 loss: 1.7341127395629883
Batch 53/64 loss: 1.7352925539016724
Batch 54/64 loss: 1.731621265411377
Batch 55/64 loss: 1.7338533401489258
Batch 56/64 loss: 1.7337589263916016
Batch 57/64 loss: 1.732527732849121
Batch 58/64 loss: 1.7342944145202637
Batch 59/64 loss: 1.7398476600646973
Batch 60/64 loss: 1.7309377193450928
Batch 61/64 loss: 1.732248306274414
Batch 62/64 loss: 1.731203556060791
Batch 63/64 loss: 1.7314987182617188
Batch 64/64 loss: 1.9227850437164307
Epoch 320  Train loss: 1.7354364759781782  Val loss: 1.7518556027887613
Epoch 321
-------------------------------
Batch 1/64 loss: 1.7364109754562378
Batch 2/64 loss: 1.7321563959121704
Batch 3/64 loss: 1.7356160879135132
Batch 4/64 loss: 1.733220100402832
Batch 5/64 loss: 1.7348552942276
Batch 6/64 loss: 1.7410211563110352
Batch 7/64 loss: 1.7335243225097656
Batch 8/64 loss: 1.7367751598358154
Batch 9/64 loss: 1.734809398651123
Batch 10/64 loss: 1.737505316734314
Batch 11/64 loss: 1.7350573539733887
Batch 12/64 loss: 1.7344720363616943
Batch 13/64 loss: 1.73813796043396
Batch 14/64 loss: 1.7334239482879639
Batch 15/64 loss: 1.7412748336791992
Batch 16/64 loss: 1.7311186790466309
Batch 17/64 loss: 1.7311747074127197
Batch 18/64 loss: 1.737114429473877
Batch 19/64 loss: 1.753753423690796
Batch 20/64 loss: 1.7358224391937256
Batch 21/64 loss: 1.733978271484375
Batch 22/64 loss: 1.7324604988098145
Batch 23/64 loss: 1.7356436252593994
Batch 24/64 loss: 1.7372756004333496
Batch 25/64 loss: 1.7327749729156494
Batch 26/64 loss: 1.7305173873901367
Batch 27/64 loss: 1.7340922355651855
Batch 28/64 loss: 1.73260498046875
Batch 29/64 loss: 1.7316057682037354
Batch 30/64 loss: 1.7339675426483154
Batch 31/64 loss: 1.7313798666000366
Batch 32/64 loss: 1.7357723712921143
Batch 33/64 loss: 1.7355968952178955
Batch 34/64 loss: 1.7404205799102783
Batch 35/64 loss: 1.7312414646148682
Batch 36/64 loss: 1.748545527458191
Batch 37/64 loss: 1.7324635982513428
Batch 38/64 loss: 1.7304339408874512
Batch 39/64 loss: 1.732478141784668
Batch 40/64 loss: 1.73146653175354
Batch 41/64 loss: 1.732567310333252
Batch 42/64 loss: 1.728702187538147
Batch 43/64 loss: 1.744959831237793
Batch 44/64 loss: 1.7324161529541016
Batch 45/64 loss: 1.7309448719024658
Batch 46/64 loss: 1.7329692840576172
Batch 47/64 loss: 1.7296106815338135
Batch 48/64 loss: 1.7343063354492188
Batch 49/64 loss: 1.7320387363433838
Batch 50/64 loss: 1.734982967376709
Batch 51/64 loss: 1.73221755027771
Batch 52/64 loss: 1.7311389446258545
Batch 53/64 loss: 1.7293109893798828
Batch 54/64 loss: 1.728279709815979
Batch 55/64 loss: 1.7322717905044556
Batch 56/64 loss: 1.730196475982666
Batch 57/64 loss: 1.7334096431732178
Batch 58/64 loss: 1.732243537902832
Batch 59/64 loss: 1.7298940420150757
Batch 60/64 loss: 1.7296316623687744
Batch 61/64 loss: 1.729008674621582
Batch 62/64 loss: 1.7312219142913818
Batch 63/64 loss: 1.7299753427505493
Batch 64/64 loss: 1.923188328742981
Epoch 321  Train loss: 1.7362612345639397  Val loss: 1.7508558973004318
Epoch 322
-------------------------------
Batch 1/64 loss: 1.7303457260131836
Batch 2/64 loss: 1.7330281734466553
Batch 3/64 loss: 1.7333459854125977
Batch 4/64 loss: 1.7316066026687622
Batch 5/64 loss: 1.7303681373596191
Batch 6/64 loss: 1.7297114133834839
Batch 7/64 loss: 1.7280696630477905
Batch 8/64 loss: 1.7479051351547241
Batch 9/64 loss: 1.7312514781951904
Batch 10/64 loss: 1.738386631011963
Batch 11/64 loss: 1.7334420680999756
Batch 12/64 loss: 1.7351922988891602
Batch 13/64 loss: 1.7294378280639648
Batch 14/64 loss: 1.733245849609375
Batch 15/64 loss: 1.7350314855575562
Batch 16/64 loss: 1.7312016487121582
Batch 17/64 loss: 1.731810212135315
Batch 18/64 loss: 1.7314598560333252
Batch 19/64 loss: 1.7313323020935059
Batch 20/64 loss: 1.7291457653045654
Batch 21/64 loss: 1.7327492237091064
Batch 22/64 loss: 1.7349342107772827
Batch 23/64 loss: 1.7424043416976929
Batch 24/64 loss: 1.7341198921203613
Batch 25/64 loss: 1.7383317947387695
Batch 26/64 loss: 1.730678915977478
Batch 27/64 loss: 1.7309656143188477
Batch 28/64 loss: 1.7340843677520752
Batch 29/64 loss: 1.7312747240066528
Batch 30/64 loss: 1.7310280799865723
Batch 31/64 loss: 1.7297139167785645
Batch 32/64 loss: 1.7349642515182495
Batch 33/64 loss: 1.7535690069198608
Batch 34/64 loss: 1.7343337535858154
Batch 35/64 loss: 1.7320218086242676
Batch 36/64 loss: 1.730273962020874
Batch 37/64 loss: 1.7318029403686523
Batch 38/64 loss: 1.7305991649627686
Batch 39/64 loss: 1.734359622001648
Batch 40/64 loss: 1.7403876781463623
Batch 41/64 loss: 1.733999490737915
Batch 42/64 loss: 1.7324854135513306
Batch 43/64 loss: 1.7343049049377441
Batch 44/64 loss: 1.7315433025360107
Batch 45/64 loss: 1.7460700273513794
Batch 46/64 loss: 1.7348532676696777
Batch 47/64 loss: 1.73813796043396
Batch 48/64 loss: 1.7351722717285156
Batch 49/64 loss: 1.7323607206344604
Batch 50/64 loss: 1.7407913208007812
Batch 51/64 loss: 1.7322468757629395
Batch 52/64 loss: 1.7348136901855469
Batch 53/64 loss: 1.7332146167755127
Batch 54/64 loss: 1.7294209003448486
Batch 55/64 loss: 1.7322895526885986
Batch 56/64 loss: 1.7293798923492432
Batch 57/64 loss: 1.7343518733978271
Batch 58/64 loss: 1.730658769607544
Batch 59/64 loss: 1.732771873474121
Batch 60/64 loss: 1.7503225803375244
Batch 61/64 loss: 1.7326472997665405
Batch 62/64 loss: 1.7330551147460938
Batch 63/64 loss: 1.7319763898849487
Batch 64/64 loss: 1.9165269136428833
Epoch 322  Train loss: 1.736191040394353  Val loss: 1.7510006427764893
Epoch 323
-------------------------------
Batch 1/64 loss: 1.7309086322784424
Batch 2/64 loss: 1.7313947677612305
Batch 3/64 loss: 1.7334275245666504
Batch 4/64 loss: 1.7304846048355103
Batch 5/64 loss: 1.7386481761932373
Batch 6/64 loss: 1.7296736240386963
Batch 7/64 loss: 1.7312510013580322
Batch 8/64 loss: 1.7334306240081787
Batch 9/64 loss: 1.7328970432281494
Batch 10/64 loss: 1.728299617767334
Batch 11/64 loss: 1.7359468936920166
Batch 12/64 loss: 1.7375173568725586
Batch 13/64 loss: 1.734532117843628
Batch 14/64 loss: 1.7349896430969238
Batch 15/64 loss: 1.7365696430206299
Batch 16/64 loss: 1.7310876846313477
Batch 17/64 loss: 1.7378979921340942
Batch 18/64 loss: 1.7309514284133911
Batch 19/64 loss: 1.7382159233093262
Batch 20/64 loss: 1.7324540615081787
Batch 21/64 loss: 1.7310738563537598
Batch 22/64 loss: 1.7348839044570923
Batch 23/64 loss: 1.7289459705352783
Batch 24/64 loss: 1.7333984375
Batch 25/64 loss: 1.7299880981445312
Batch 26/64 loss: 1.7356046438217163
Batch 27/64 loss: 1.7316224575042725
Batch 28/64 loss: 1.7357628345489502
Batch 29/64 loss: 1.7320897579193115
Batch 30/64 loss: 1.75343656539917
Batch 31/64 loss: 1.7475595474243164
Batch 32/64 loss: 1.7311631441116333
Batch 33/64 loss: 1.728938102722168
Batch 34/64 loss: 1.7304919958114624
Batch 35/64 loss: 1.7374892234802246
Batch 36/64 loss: 1.7328343391418457
Batch 37/64 loss: 1.7325631380081177
Batch 38/64 loss: 1.731384515762329
Batch 39/64 loss: 1.7333450317382812
Batch 40/64 loss: 1.7308781147003174
Batch 41/64 loss: 1.7391095161437988
Batch 42/64 loss: 1.731568694114685
Batch 43/64 loss: 1.7306690216064453
Batch 44/64 loss: 1.730489730834961
Batch 45/64 loss: 1.729823350906372
Batch 46/64 loss: 1.738419771194458
Batch 47/64 loss: 1.7298614978790283
Batch 48/64 loss: 1.7303521633148193
Batch 49/64 loss: 1.731776475906372
Batch 50/64 loss: 1.734290599822998
Batch 51/64 loss: 1.7308024168014526
Batch 52/64 loss: 1.7312049865722656
Batch 53/64 loss: 1.7325243949890137
Batch 54/64 loss: 1.7369728088378906
Batch 55/64 loss: 1.73333740234375
Batch 56/64 loss: 1.734867811203003
Batch 57/64 loss: 1.7297595739364624
Batch 58/64 loss: 1.7322536706924438
Batch 59/64 loss: 1.7303706407546997
Batch 60/64 loss: 1.7335149049758911
Batch 61/64 loss: 1.7340502738952637
Batch 62/64 loss: 1.7314045429229736
Batch 63/64 loss: 1.7486027479171753
Batch 64/64 loss: 1.9124952554702759
Epoch 323  Train loss: 1.7357557722166472  Val loss: 1.7535712415819724
Epoch 324
-------------------------------
Batch 1/64 loss: 1.7309703826904297
Batch 2/64 loss: 1.7508251667022705
Batch 3/64 loss: 1.7365403175354004
Batch 4/64 loss: 1.7318534851074219
Batch 5/64 loss: 1.7316088676452637
Batch 6/64 loss: 1.7305374145507812
Batch 7/64 loss: 1.733247995376587
Batch 8/64 loss: 1.7404742240905762
Batch 9/64 loss: 1.735386848449707
Batch 10/64 loss: 1.7303483486175537
Batch 11/64 loss: 1.7352614402770996
Batch 12/64 loss: 1.731269359588623
Batch 13/64 loss: 1.737746238708496
Batch 14/64 loss: 1.7358165979385376
Batch 15/64 loss: 1.7329297065734863
Batch 16/64 loss: 1.732445240020752
Batch 17/64 loss: 1.7430202960968018
Batch 18/64 loss: 1.7332696914672852
Batch 19/64 loss: 1.7342894077301025
Batch 20/64 loss: 1.7342967987060547
Batch 21/64 loss: 1.732431173324585
Batch 22/64 loss: 1.7333122491836548
Batch 23/64 loss: 1.7353699207305908
Batch 24/64 loss: 1.731752872467041
Batch 25/64 loss: 1.7309467792510986
Batch 26/64 loss: 1.7318758964538574
Batch 27/64 loss: 1.733206868171692
Batch 28/64 loss: 1.7322537899017334
Batch 29/64 loss: 1.7360785007476807
Batch 30/64 loss: 1.746777057647705
Batch 31/64 loss: 1.7349251508712769
Batch 32/64 loss: 1.7307653427124023
Batch 33/64 loss: 1.7322041988372803
Batch 34/64 loss: 1.733307123184204
Batch 35/64 loss: 1.7308998107910156
Batch 36/64 loss: 1.7333886623382568
Batch 37/64 loss: 1.7322955131530762
Batch 38/64 loss: 1.736130952835083
Batch 39/64 loss: 1.7331922054290771
Batch 40/64 loss: 1.7370389699935913
Batch 41/64 loss: 1.7332782745361328
Batch 42/64 loss: 1.7331193685531616
Batch 43/64 loss: 1.7302777767181396
Batch 44/64 loss: 1.7318634986877441
Batch 45/64 loss: 1.734450101852417
Batch 46/64 loss: 1.7309739589691162
Batch 47/64 loss: 1.7300546169281006
Batch 48/64 loss: 1.730332374572754
Batch 49/64 loss: 1.729871392250061
Batch 50/64 loss: 1.7369545698165894
Batch 51/64 loss: 1.732987642288208
Batch 52/64 loss: 1.7335422039031982
Batch 53/64 loss: 1.7354649305343628
Batch 54/64 loss: 1.7312755584716797
Batch 55/64 loss: 1.7488312721252441
Batch 56/64 loss: 1.7331669330596924
Batch 57/64 loss: 1.7330384254455566
Batch 58/64 loss: 1.7336788177490234
Batch 59/64 loss: 1.730786681175232
Batch 60/64 loss: 1.7321891784667969
Batch 61/64 loss: 1.7354726791381836
Batch 62/64 loss: 1.730721116065979
Batch 63/64 loss: 1.7294279336929321
Batch 64/64 loss: 1.9182162284851074
Epoch 324  Train loss: 1.736168036741369  Val loss: 1.7500945161708032
Epoch 325
-------------------------------
Batch 1/64 loss: 1.7460218667984009
Batch 2/64 loss: 1.7322819232940674
Batch 3/64 loss: 1.7311002016067505
Batch 4/64 loss: 1.7319824695587158
Batch 5/64 loss: 1.7312036752700806
Batch 6/64 loss: 1.7322232723236084
Batch 7/64 loss: 1.7328906059265137
Batch 8/64 loss: 1.733757495880127
Batch 9/64 loss: 1.732558250427246
Batch 10/64 loss: 1.7385635375976562
Batch 11/64 loss: 1.7314441204071045
Batch 12/64 loss: 1.7309699058532715
Batch 13/64 loss: 1.7329118251800537
Batch 14/64 loss: 1.7321255207061768
Batch 15/64 loss: 1.7284787893295288
Batch 16/64 loss: 1.7314530611038208
Batch 17/64 loss: 1.7318005561828613
Batch 18/64 loss: 1.7313640117645264
Batch 19/64 loss: 1.7318400144577026
Batch 20/64 loss: 1.7292449474334717
Batch 21/64 loss: 1.730635643005371
Batch 22/64 loss: 1.7318252325057983
Batch 23/64 loss: 1.7278523445129395
Batch 24/64 loss: 1.7289228439331055
Batch 25/64 loss: 1.7294503450393677
Batch 26/64 loss: 1.7322776317596436
Batch 27/64 loss: 1.7286851406097412
Batch 28/64 loss: 1.7345112562179565
Batch 29/64 loss: 1.7443289756774902
Batch 30/64 loss: 1.7301311492919922
Batch 31/64 loss: 1.730638027191162
Batch 32/64 loss: 1.7305521965026855
Batch 33/64 loss: 1.7321393489837646
Batch 34/64 loss: 1.7322192192077637
Batch 35/64 loss: 1.735013723373413
Batch 36/64 loss: 1.7317044734954834
Batch 37/64 loss: 1.7417665719985962
Batch 38/64 loss: 1.7334517240524292
Batch 39/64 loss: 1.7342841625213623
Batch 40/64 loss: 1.7329246997833252
Batch 41/64 loss: 1.738492488861084
Batch 42/64 loss: 1.7321720123291016
Batch 43/64 loss: 1.73274827003479
Batch 44/64 loss: 1.7314400672912598
Batch 45/64 loss: 1.7329652309417725
Batch 46/64 loss: 1.7296686172485352
Batch 47/64 loss: 1.7259025573730469
Batch 48/64 loss: 1.7299542427062988
Batch 49/64 loss: 1.7283344268798828
Batch 50/64 loss: 1.7440409660339355
Batch 51/64 loss: 1.732651710510254
Batch 52/64 loss: 1.7302367687225342
Batch 53/64 loss: 1.7304991483688354
Batch 54/64 loss: 1.7307707071304321
Batch 55/64 loss: 1.729194164276123
Batch 56/64 loss: 1.7327204942703247
Batch 57/64 loss: 1.754849910736084
Batch 58/64 loss: 1.730905294418335
Batch 59/64 loss: 1.736757516860962
Batch 60/64 loss: 1.731177568435669
Batch 61/64 loss: 1.7359358072280884
Batch 62/64 loss: 1.7335288524627686
Batch 63/64 loss: 1.7346200942993164
Batch 64/64 loss: 1.9166969060897827
Epoch 325  Train loss: 1.7351312997294408  Val loss: 1.7501481488807915
Epoch 326
-------------------------------
Batch 1/64 loss: 1.7302076816558838
Batch 2/64 loss: 1.731454849243164
Batch 3/64 loss: 1.7427618503570557
Batch 4/64 loss: 1.7348601818084717
Batch 5/64 loss: 1.732947587966919
Batch 6/64 loss: 1.7386949062347412
Batch 7/64 loss: 1.7308886051177979
Batch 8/64 loss: 1.7321796417236328
Batch 9/64 loss: 1.7304989099502563
Batch 10/64 loss: 1.7315844297409058
Batch 11/64 loss: 1.73073410987854
Batch 12/64 loss: 1.7314870357513428
Batch 13/64 loss: 1.7350692749023438
Batch 14/64 loss: 1.7373160123825073
Batch 15/64 loss: 1.7313988208770752
Batch 16/64 loss: 1.7276109457015991
Batch 17/64 loss: 1.7303128242492676
Batch 18/64 loss: 1.7331089973449707
Batch 19/64 loss: 1.729597806930542
Batch 20/64 loss: 1.7307169437408447
Batch 21/64 loss: 1.7463347911834717
Batch 22/64 loss: 1.7314770221710205
Batch 23/64 loss: 1.7319586277008057
Batch 24/64 loss: 1.736504316329956
Batch 25/64 loss: 1.7316055297851562
Batch 26/64 loss: 1.7306567430496216
Batch 27/64 loss: 1.7359188795089722
Batch 28/64 loss: 1.732724666595459
Batch 29/64 loss: 1.7367675304412842
Batch 30/64 loss: 1.7388758659362793
Batch 31/64 loss: 1.734865665435791
Batch 32/64 loss: 1.7320507764816284
Batch 33/64 loss: 1.730569839477539
Batch 34/64 loss: 1.7323055267333984
Batch 35/64 loss: 1.7383136749267578
Batch 36/64 loss: 1.7309825420379639
Batch 37/64 loss: 1.7313289642333984
Batch 38/64 loss: 1.7300105094909668
Batch 39/64 loss: 1.7316203117370605
Batch 40/64 loss: 1.7303262948989868
Batch 41/64 loss: 1.733343482017517
Batch 42/64 loss: 1.7338961362838745
Batch 43/64 loss: 1.7310404777526855
Batch 44/64 loss: 1.7298943996429443
Batch 45/64 loss: 1.7344725131988525
Batch 46/64 loss: 1.738742709159851
Batch 47/64 loss: 1.7361024618148804
Batch 48/64 loss: 1.7310364246368408
Batch 49/64 loss: 1.7309167385101318
Batch 50/64 loss: 1.7349591255187988
Batch 51/64 loss: 1.7303292751312256
Batch 52/64 loss: 1.7321468591690063
Batch 53/64 loss: 1.7321712970733643
Batch 54/64 loss: 1.7314908504486084
Batch 55/64 loss: 1.7334246635437012
Batch 56/64 loss: 1.735257863998413
Batch 57/64 loss: 1.7359732389450073
Batch 58/64 loss: 1.729377269744873
Batch 59/64 loss: 1.7465806007385254
Batch 60/64 loss: 1.72915518283844
Batch 61/64 loss: 1.7325201034545898
Batch 62/64 loss: 1.7334818840026855
Batch 63/64 loss: 1.7278972864151
Batch 64/64 loss: 1.9421331882476807
Epoch 326  Train loss: 1.7356774937872794  Val loss: 1.7503258206999999
Epoch 327
-------------------------------
Batch 1/64 loss: 1.73218834400177
Batch 2/64 loss: 1.7340328693389893
Batch 3/64 loss: 1.728609561920166
Batch 4/64 loss: 1.7311360836029053
Batch 5/64 loss: 1.7303671836853027
Batch 6/64 loss: 1.7301232814788818
Batch 7/64 loss: 1.7638719081878662
Batch 8/64 loss: 1.7315549850463867
Batch 9/64 loss: 1.7329649925231934
Batch 10/64 loss: 1.7353440523147583
Batch 11/64 loss: 1.7314393520355225
Batch 12/64 loss: 1.730294942855835
Batch 13/64 loss: 1.727461338043213
Batch 14/64 loss: 1.7285206317901611
Batch 15/64 loss: 1.7298743724822998
Batch 16/64 loss: 1.7340476512908936
Batch 17/64 loss: 1.731305480003357
Batch 18/64 loss: 1.7308728694915771
Batch 19/64 loss: 1.7303354740142822
Batch 20/64 loss: 1.7342605590820312
Batch 21/64 loss: 1.7319130897521973
Batch 22/64 loss: 1.7325751781463623
Batch 23/64 loss: 1.7289409637451172
Batch 24/64 loss: 1.7302055358886719
Batch 25/64 loss: 1.7314326763153076
Batch 26/64 loss: 1.7293827533721924
Batch 27/64 loss: 1.7328040599822998
Batch 28/64 loss: 1.729982614517212
Batch 29/64 loss: 1.7294745445251465
Batch 30/64 loss: 1.7305560111999512
Batch 31/64 loss: 1.732725977897644
Batch 32/64 loss: 1.732120394706726
Batch 33/64 loss: 1.7312674522399902
Batch 34/64 loss: 1.7309398651123047
Batch 35/64 loss: 1.7311731576919556
Batch 36/64 loss: 1.730485200881958
Batch 37/64 loss: 1.729162335395813
Batch 38/64 loss: 1.7310584783554077
Batch 39/64 loss: 1.7322447299957275
Batch 40/64 loss: 1.7302680015563965
Batch 41/64 loss: 1.7345483303070068
Batch 42/64 loss: 1.729551076889038
Batch 43/64 loss: 1.7298086881637573
Batch 44/64 loss: 1.7305152416229248
Batch 45/64 loss: 1.7309684753417969
Batch 46/64 loss: 1.7288987636566162
Batch 47/64 loss: 1.7503573894500732
Batch 48/64 loss: 1.7323436737060547
Batch 49/64 loss: 1.73065185546875
Batch 50/64 loss: 1.7301021814346313
Batch 51/64 loss: 1.736910343170166
Batch 52/64 loss: 1.7344743013381958
Batch 53/64 loss: 1.7324800491333008
Batch 54/64 loss: 1.7288469076156616
Batch 55/64 loss: 1.733386516571045
Batch 56/64 loss: 1.7341983318328857
Batch 57/64 loss: 1.7321803569793701
Batch 58/64 loss: 1.7334476709365845
Batch 59/64 loss: 1.7332744598388672
Batch 60/64 loss: 1.7454490661621094
Batch 61/64 loss: 1.7418508529663086
Batch 62/64 loss: 1.7329583168029785
Batch 63/64 loss: 1.7323216199874878
Batch 64/64 loss: 1.9116990566253662
Epoch 327  Train loss: 1.7347547877068612  Val loss: 1.7488139519576764
Epoch 328
-------------------------------
Batch 1/64 loss: 1.7270057201385498
Batch 2/64 loss: 1.7343864440917969
Batch 3/64 loss: 1.7300546169281006
Batch 4/64 loss: 1.728521466255188
Batch 5/64 loss: 1.7314140796661377
Batch 6/64 loss: 1.7338999509811401
Batch 7/64 loss: 1.7318181991577148
Batch 8/64 loss: 1.7303622961044312
Batch 9/64 loss: 1.7285895347595215
Batch 10/64 loss: 1.7340911626815796
Batch 11/64 loss: 1.72823166847229
Batch 12/64 loss: 1.73051917552948
Batch 13/64 loss: 1.7479424476623535
Batch 14/64 loss: 1.7326056957244873
Batch 15/64 loss: 1.7309637069702148
Batch 16/64 loss: 1.7330855131149292
Batch 17/64 loss: 1.7293248176574707
Batch 18/64 loss: 1.730054497718811
Batch 19/64 loss: 1.7340208292007446
Batch 20/64 loss: 1.7319903373718262
Batch 21/64 loss: 1.7301528453826904
Batch 22/64 loss: 1.7308499813079834
Batch 23/64 loss: 1.7298321723937988
Batch 24/64 loss: 1.7365535497665405
Batch 25/64 loss: 1.7301461696624756
Batch 26/64 loss: 1.7298834323883057
Batch 27/64 loss: 1.7318763732910156
Batch 28/64 loss: 1.7288708686828613
Batch 29/64 loss: 1.7305426597595215
Batch 30/64 loss: 1.7318687438964844
Batch 31/64 loss: 1.7303874492645264
Batch 32/64 loss: 1.7302472591400146
Batch 33/64 loss: 1.7330009937286377
Batch 34/64 loss: 1.7294743061065674
Batch 35/64 loss: 1.7295466661453247
Batch 36/64 loss: 1.7285324335098267
Batch 37/64 loss: 1.7264866828918457
Batch 38/64 loss: 1.7329652309417725
Batch 39/64 loss: 1.729237675666809
Batch 40/64 loss: 1.7386308908462524
Batch 41/64 loss: 1.729851484298706
Batch 42/64 loss: 1.733703374862671
Batch 43/64 loss: 1.7331361770629883
Batch 44/64 loss: 1.731968879699707
Batch 45/64 loss: 1.7304577827453613
Batch 46/64 loss: 1.731224536895752
Batch 47/64 loss: 1.7287001609802246
Batch 48/64 loss: 1.7277926206588745
Batch 49/64 loss: 1.7290899753570557
Batch 50/64 loss: 1.7414602041244507
Batch 51/64 loss: 1.731102466583252
Batch 52/64 loss: 1.729126214981079
Batch 53/64 loss: 1.7276136875152588
Batch 54/64 loss: 1.730250597000122
Batch 55/64 loss: 1.731081485748291
Batch 56/64 loss: 1.7302672863006592
Batch 57/64 loss: 1.731091022491455
Batch 58/64 loss: 1.7298362255096436
Batch 59/64 loss: 1.7314424514770508
Batch 60/64 loss: 1.734537124633789
Batch 61/64 loss: 1.7494666576385498
Batch 62/64 loss: 1.7288615703582764
Batch 63/64 loss: 1.7320237159729004
Batch 64/64 loss: 1.9104928970336914
Epoch 328  Train loss: 1.7337242967942181  Val loss: 1.7475678650374264
Saving best model, epoch: 328
Epoch 329
-------------------------------
Batch 1/64 loss: 1.7366516590118408
Batch 2/64 loss: 1.7271440029144287
Batch 3/64 loss: 1.7340986728668213
Batch 4/64 loss: 1.730464220046997
Batch 5/64 loss: 1.7338277101516724
Batch 6/64 loss: 1.731123685836792
Batch 7/64 loss: 1.7356226444244385
Batch 8/64 loss: 1.7479925155639648
Batch 9/64 loss: 1.7280457019805908
Batch 10/64 loss: 1.7301983833312988
Batch 11/64 loss: 1.7319705486297607
Batch 12/64 loss: 1.7303059101104736
Batch 13/64 loss: 1.7293152809143066
Batch 14/64 loss: 1.7339013814926147
Batch 15/64 loss: 1.7290595769882202
Batch 16/64 loss: 1.7298588752746582
Batch 17/64 loss: 1.7297282218933105
Batch 18/64 loss: 1.7309834957122803
Batch 19/64 loss: 1.7311530113220215
Batch 20/64 loss: 1.7293970584869385
Batch 21/64 loss: 1.7281767129898071
Batch 22/64 loss: 1.730796456336975
Batch 23/64 loss: 1.7395622730255127
Batch 24/64 loss: 1.7277196645736694
Batch 25/64 loss: 1.7308298349380493
Batch 26/64 loss: 1.7274351119995117
Batch 27/64 loss: 1.7260106801986694
Batch 28/64 loss: 1.7280257940292358
Batch 29/64 loss: 1.7291040420532227
Batch 30/64 loss: 1.7335251569747925
Batch 31/64 loss: 1.7338218688964844
Batch 32/64 loss: 1.7361775636672974
Batch 33/64 loss: 1.7313295602798462
Batch 34/64 loss: 1.7311062812805176
Batch 35/64 loss: 1.731856346130371
Batch 36/64 loss: 1.7343993186950684
Batch 37/64 loss: 1.7335596084594727
Batch 38/64 loss: 1.74845552444458
Batch 39/64 loss: 1.7375025749206543
Batch 40/64 loss: 1.7316489219665527
Batch 41/64 loss: 1.7284541130065918
Batch 42/64 loss: 1.7280781269073486
Batch 43/64 loss: 1.7480089664459229
Batch 44/64 loss: 1.7331119775772095
Batch 45/64 loss: 1.731045126914978
Batch 46/64 loss: 1.726621150970459
Batch 47/64 loss: 1.733133316040039
Batch 48/64 loss: 1.7349655628204346
Batch 49/64 loss: 1.7280778884887695
Batch 50/64 loss: 1.7314355373382568
Batch 51/64 loss: 1.7308802604675293
Batch 52/64 loss: 1.728347659111023
Batch 53/64 loss: 1.7348026037216187
Batch 54/64 loss: 1.734163522720337
Batch 55/64 loss: 1.7337896823883057
Batch 56/64 loss: 1.7284435033798218
Batch 57/64 loss: 1.7314138412475586
Batch 58/64 loss: 1.7307449579238892
Batch 59/64 loss: 1.7313196659088135
Batch 60/64 loss: 1.7292370796203613
Batch 61/64 loss: 1.731518268585205
Batch 62/64 loss: 1.7268304824829102
Batch 63/64 loss: 1.7323358058929443
Batch 64/64 loss: 1.9168344736099243
Epoch 329  Train loss: 1.7342160126742194  Val loss: 1.7501067140258055
Epoch 330
-------------------------------
Batch 1/64 loss: 1.7330498695373535
Batch 2/64 loss: 1.728991150856018
Batch 3/64 loss: 1.7531366348266602
Batch 4/64 loss: 1.7283034324645996
Batch 5/64 loss: 1.729994297027588
Batch 6/64 loss: 1.7297910451889038
Batch 7/64 loss: 1.7290840148925781
Batch 8/64 loss: 1.7330576181411743
Batch 9/64 loss: 1.73104989528656
Batch 10/64 loss: 1.7312484979629517
Batch 11/64 loss: 1.732111930847168
Batch 12/64 loss: 1.7284842729568481
Batch 13/64 loss: 1.7301769256591797
Batch 14/64 loss: 1.7310359477996826
Batch 15/64 loss: 1.730372667312622
Batch 16/64 loss: 1.7285869121551514
Batch 17/64 loss: 1.7304565906524658
Batch 18/64 loss: 1.7297356128692627
Batch 19/64 loss: 1.7303398847579956
Batch 20/64 loss: 1.7327593564987183
Batch 21/64 loss: 1.7309596538543701
Batch 22/64 loss: 1.7284321784973145
Batch 23/64 loss: 1.7364684343338013
Batch 24/64 loss: 1.7319954633712769
Batch 25/64 loss: 1.7322328090667725
Batch 26/64 loss: 1.7311046123504639
Batch 27/64 loss: 1.7308095693588257
Batch 28/64 loss: 1.7418981790542603
Batch 29/64 loss: 1.729067325592041
Batch 30/64 loss: 1.732471227645874
Batch 31/64 loss: 1.7499452829360962
Batch 32/64 loss: 1.7302639484405518
Batch 33/64 loss: 1.727724552154541
Batch 34/64 loss: 1.7327547073364258
Batch 35/64 loss: 1.728474736213684
Batch 36/64 loss: 1.7334412336349487
Batch 37/64 loss: 1.7361538410186768
Batch 38/64 loss: 1.730788230895996
Batch 39/64 loss: 1.7304465770721436
Batch 40/64 loss: 1.7406736612319946
Batch 41/64 loss: 1.7281525135040283
Batch 42/64 loss: 1.7287722826004028
Batch 43/64 loss: 1.729708194732666
Batch 44/64 loss: 1.733060598373413
Batch 45/64 loss: 1.73325514793396
Batch 46/64 loss: 1.727632761001587
Batch 47/64 loss: 1.7309858798980713
Batch 48/64 loss: 1.7321875095367432
Batch 49/64 loss: 1.7328048944473267
Batch 50/64 loss: 1.7310473918914795
Batch 51/64 loss: 1.7354762554168701
Batch 52/64 loss: 1.7309850454330444
Batch 53/64 loss: 1.7325772047042847
Batch 54/64 loss: 1.7309950590133667
Batch 55/64 loss: 1.737281322479248
Batch 56/64 loss: 1.729886531829834
Batch 57/64 loss: 1.7280068397521973
Batch 58/64 loss: 1.7293707132339478
Batch 59/64 loss: 1.7310073375701904
Batch 60/64 loss: 1.7308635711669922
Batch 61/64 loss: 1.7299106121063232
Batch 62/64 loss: 1.743420958518982
Batch 63/64 loss: 1.7348334789276123
Batch 64/64 loss: 1.9108577966690063
Epoch 330  Train loss: 1.7343253056208292  Val loss: 1.7508258000272245
Epoch 331
-------------------------------
Batch 1/64 loss: 1.7282564640045166
Batch 2/64 loss: 1.7275798320770264
Batch 3/64 loss: 1.7304723262786865
Batch 4/64 loss: 1.7308526039123535
Batch 5/64 loss: 1.7296574115753174
Batch 6/64 loss: 1.730114221572876
Batch 7/64 loss: 1.733687400817871
Batch 8/64 loss: 1.7330255508422852
Batch 9/64 loss: 1.7482361793518066
Batch 10/64 loss: 1.7303787469863892
Batch 11/64 loss: 1.733152151107788
Batch 12/64 loss: 1.7330334186553955
Batch 13/64 loss: 1.7313826084136963
Batch 14/64 loss: 1.7301502227783203
Batch 15/64 loss: 1.7285372018814087
Batch 16/64 loss: 1.735097885131836
Batch 17/64 loss: 1.729119062423706
Batch 18/64 loss: 1.7305585145950317
Batch 19/64 loss: 1.7343623638153076
Batch 20/64 loss: 1.73189377784729
Batch 21/64 loss: 1.7263946533203125
Batch 22/64 loss: 1.7292200326919556
Batch 23/64 loss: 1.7299935817718506
Batch 24/64 loss: 1.7281062602996826
Batch 25/64 loss: 1.7263035774230957
Batch 26/64 loss: 1.7269096374511719
Batch 27/64 loss: 1.7279984951019287
Batch 28/64 loss: 1.7309014797210693
Batch 29/64 loss: 1.7307872772216797
Batch 30/64 loss: 1.72900390625
Batch 31/64 loss: 1.727701187133789
Batch 32/64 loss: 1.7291518449783325
Batch 33/64 loss: 1.728670358657837
Batch 34/64 loss: 1.7303893566131592
Batch 35/64 loss: 1.7294955253601074
Batch 36/64 loss: 1.7295277118682861
Batch 37/64 loss: 1.7265241146087646
Batch 38/64 loss: 1.7285879850387573
Batch 39/64 loss: 1.7305078506469727
Batch 40/64 loss: 1.7326602935791016
Batch 41/64 loss: 1.7292120456695557
Batch 42/64 loss: 1.7283793687820435
Batch 43/64 loss: 1.7308738231658936
Batch 44/64 loss: 1.7331874370574951
Batch 45/64 loss: 1.7342371940612793
Batch 46/64 loss: 1.728050947189331
Batch 47/64 loss: 1.7271479368209839
Batch 48/64 loss: 1.7264103889465332
Batch 49/64 loss: 1.7303261756896973
Batch 50/64 loss: 1.7321581840515137
Batch 51/64 loss: 1.7308440208435059
Batch 52/64 loss: 1.732086420059204
Batch 53/64 loss: 1.729561686515808
Batch 54/64 loss: 1.7329375743865967
Batch 55/64 loss: 1.7305248975753784
Batch 56/64 loss: 1.7301762104034424
Batch 57/64 loss: 1.732040286064148
Batch 58/64 loss: 1.7439461946487427
Batch 59/64 loss: 1.7313851118087769
Batch 60/64 loss: 1.7426952123641968
Batch 61/64 loss: 1.729353904724121
Batch 62/64 loss: 1.7360279560089111
Batch 63/64 loss: 1.733055591583252
Batch 64/64 loss: 1.9155112504959106
Epoch 331  Train loss: 1.7331707463544959  Val loss: 1.7478558795968282
Epoch 332
-------------------------------
Batch 1/64 loss: 1.7320533990859985
Batch 2/64 loss: 1.7444052696228027
Batch 3/64 loss: 1.730945348739624
Batch 4/64 loss: 1.7321269512176514
Batch 5/64 loss: 1.7317500114440918
Batch 6/64 loss: 1.7348804473876953
Batch 7/64 loss: 1.7350214719772339
Batch 8/64 loss: 1.7319934368133545
Batch 9/64 loss: 1.729067325592041
Batch 10/64 loss: 1.737241268157959
Batch 11/64 loss: 1.7313926219940186
Batch 12/64 loss: 1.7303787469863892
Batch 13/64 loss: 1.7281675338745117
Batch 14/64 loss: 1.7298133373260498
Batch 15/64 loss: 1.728027105331421
Batch 16/64 loss: 1.7432911396026611
Batch 17/64 loss: 1.7332663536071777
Batch 18/64 loss: 1.7279016971588135
Batch 19/64 loss: 1.7305595874786377
Batch 20/64 loss: 1.7283844947814941
Batch 21/64 loss: 1.7324397563934326
Batch 22/64 loss: 1.728502631187439
Batch 23/64 loss: 1.7293181419372559
Batch 24/64 loss: 1.734283447265625
Batch 25/64 loss: 1.7303056716918945
Batch 26/64 loss: 1.731738567352295
Batch 27/64 loss: 1.7330703735351562
Batch 28/64 loss: 1.7258093357086182
Batch 29/64 loss: 1.732559084892273
Batch 30/64 loss: 1.729224681854248
Batch 31/64 loss: 1.727691650390625
Batch 32/64 loss: 1.7301368713378906
Batch 33/64 loss: 1.7436306476593018
Batch 34/64 loss: 1.7290515899658203
Batch 35/64 loss: 1.7294375896453857
Batch 36/64 loss: 1.7271099090576172
Batch 37/64 loss: 1.730846643447876
Batch 38/64 loss: 1.729263186454773
Batch 39/64 loss: 1.7374215126037598
Batch 40/64 loss: 1.7274861335754395
Batch 41/64 loss: 1.730090856552124
Batch 42/64 loss: 1.730055809020996
Batch 43/64 loss: 1.7304587364196777
Batch 44/64 loss: 1.7295739650726318
Batch 45/64 loss: 1.7301933765411377
Batch 46/64 loss: 1.7302026748657227
Batch 47/64 loss: 1.7273218631744385
Batch 48/64 loss: 1.7293729782104492
Batch 49/64 loss: 1.7275428771972656
Batch 50/64 loss: 1.7269818782806396
Batch 51/64 loss: 1.7270228862762451
Batch 52/64 loss: 1.7287867069244385
Batch 53/64 loss: 1.7291799783706665
Batch 54/64 loss: 1.7297906875610352
Batch 55/64 loss: 1.726881980895996
Batch 56/64 loss: 1.730201005935669
Batch 57/64 loss: 1.729944109916687
Batch 58/64 loss: 1.7276644706726074
Batch 59/64 loss: 1.728562593460083
Batch 60/64 loss: 1.72862708568573
Batch 61/64 loss: 1.7287994623184204
Batch 62/64 loss: 1.7267096042633057
Batch 63/64 loss: 1.7279834747314453
Batch 64/64 loss: 1.9049851894378662
Epoch 332  Train loss: 1.7327165949578378  Val loss: 1.7463107977536125
Saving best model, epoch: 332
Epoch 333
-------------------------------
Batch 1/64 loss: 1.7344657182693481
Batch 2/64 loss: 1.7284910678863525
Batch 3/64 loss: 1.7288711071014404
Batch 4/64 loss: 1.729649543762207
Batch 5/64 loss: 1.7276504039764404
Batch 6/64 loss: 1.7283399105072021
Batch 7/64 loss: 1.7289936542510986
Batch 8/64 loss: 1.7321381568908691
Batch 9/64 loss: 1.730542540550232
Batch 10/64 loss: 1.732284665107727
Batch 11/64 loss: 1.7282371520996094
Batch 12/64 loss: 1.7291290760040283
Batch 13/64 loss: 1.727312445640564
Batch 14/64 loss: 1.750688910484314
Batch 15/64 loss: 1.737191081047058
Batch 16/64 loss: 1.7296870946884155
Batch 17/64 loss: 1.7289495468139648
Batch 18/64 loss: 1.7292046546936035
Batch 19/64 loss: 1.728302001953125
Batch 20/64 loss: 1.7317891120910645
Batch 21/64 loss: 1.7303485870361328
Batch 22/64 loss: 1.7286839485168457
Batch 23/64 loss: 1.7318416833877563
Batch 24/64 loss: 1.728262186050415
Batch 25/64 loss: 1.7326000928878784
Batch 26/64 loss: 1.7287029027938843
Batch 27/64 loss: 1.7295324802398682
Batch 28/64 loss: 1.7298078536987305
Batch 29/64 loss: 1.7295652627944946
Batch 30/64 loss: 1.7273924350738525
Batch 31/64 loss: 1.725128173828125
Batch 32/64 loss: 1.7410120964050293
Batch 33/64 loss: 1.7342742681503296
Batch 34/64 loss: 1.730773687362671
Batch 35/64 loss: 1.725083589553833
Batch 36/64 loss: 1.7263567447662354
Batch 37/64 loss: 1.7271320819854736
Batch 38/64 loss: 1.7264740467071533
Batch 39/64 loss: 1.7305594682693481
Batch 40/64 loss: 1.7446937561035156
Batch 41/64 loss: 1.727589726448059
Batch 42/64 loss: 1.738661527633667
Batch 43/64 loss: 1.728867769241333
Batch 44/64 loss: 1.727005958557129
Batch 45/64 loss: 1.7291464805603027
Batch 46/64 loss: 1.7362626791000366
Batch 47/64 loss: 1.7280329465866089
Batch 48/64 loss: 1.7305753231048584
Batch 49/64 loss: 1.7262194156646729
Batch 50/64 loss: 1.7271891832351685
Batch 51/64 loss: 1.7301480770111084
Batch 52/64 loss: 1.7294363975524902
Batch 53/64 loss: 1.7304463386535645
Batch 54/64 loss: 1.7305530309677124
Batch 55/64 loss: 1.7291840314865112
Batch 56/64 loss: 1.725829839706421
Batch 57/64 loss: 1.7319073677062988
Batch 58/64 loss: 1.7268729209899902
Batch 59/64 loss: 1.7268246412277222
Batch 60/64 loss: 1.7298915386199951
Batch 61/64 loss: 1.7291927337646484
Batch 62/64 loss: 1.7307004928588867
Batch 63/64 loss: 1.7299840450286865
Batch 64/64 loss: 1.914682149887085
Epoch 333  Train loss: 1.7324968983145321  Val loss: 1.7466108151727526
Epoch 334
-------------------------------
Batch 1/64 loss: 1.7326483726501465
Batch 2/64 loss: 1.7274054288864136
Batch 3/64 loss: 1.729468822479248
Batch 4/64 loss: 1.729687213897705
Batch 5/64 loss: 1.7322962284088135
Batch 6/64 loss: 1.727226734161377
Batch 7/64 loss: 1.7292752265930176
Batch 8/64 loss: 1.7276793718338013
Batch 9/64 loss: 1.737548589706421
Batch 10/64 loss: 1.7313259840011597
Batch 11/64 loss: 1.728279948234558
Batch 12/64 loss: 1.7282369136810303
Batch 13/64 loss: 1.730468511581421
Batch 14/64 loss: 1.7293450832366943
Batch 15/64 loss: 1.7425687313079834
Batch 16/64 loss: 1.73386549949646
Batch 17/64 loss: 1.7315125465393066
Batch 18/64 loss: 1.7281626462936401
Batch 19/64 loss: 1.7294421195983887
Batch 20/64 loss: 1.7296572923660278
Batch 21/64 loss: 1.727399230003357
Batch 22/64 loss: 1.726958990097046
Batch 23/64 loss: 1.7293806076049805
Batch 24/64 loss: 1.7279596328735352
Batch 25/64 loss: 1.7285525798797607
Batch 26/64 loss: 1.7278296947479248
Batch 27/64 loss: 1.7291786670684814
Batch 28/64 loss: 1.7315993309020996
Batch 29/64 loss: 1.7294678688049316
Batch 30/64 loss: 1.7312277555465698
Batch 31/64 loss: 1.7301576137542725
Batch 32/64 loss: 1.7315075397491455
Batch 33/64 loss: 1.730402946472168
Batch 34/64 loss: 1.7487461566925049
Batch 35/64 loss: 1.7340342998504639
Batch 36/64 loss: 1.7314953804016113
Batch 37/64 loss: 1.7286145687103271
Batch 38/64 loss: 1.733436107635498
Batch 39/64 loss: 1.7291369438171387
Batch 40/64 loss: 1.7301896810531616
Batch 41/64 loss: 1.730461835861206
Batch 42/64 loss: 1.735332727432251
Batch 43/64 loss: 1.728841781616211
Batch 44/64 loss: 1.7285380363464355
Batch 45/64 loss: 1.7269450426101685
Batch 46/64 loss: 1.729053020477295
Batch 47/64 loss: 1.7293827533721924
Batch 48/64 loss: 1.7329912185668945
Batch 49/64 loss: 1.7266151905059814
Batch 50/64 loss: 1.727594017982483
Batch 51/64 loss: 1.7318801879882812
Batch 52/64 loss: 1.7265535593032837
Batch 53/64 loss: 1.7285460233688354
Batch 54/64 loss: 1.7313498258590698
Batch 55/64 loss: 1.7410825490951538
Batch 56/64 loss: 1.7336211204528809
Batch 57/64 loss: 1.7300209999084473
Batch 58/64 loss: 1.7318718433380127
Batch 59/64 loss: 1.728312373161316
Batch 60/64 loss: 1.7301650047302246
Batch 61/64 loss: 1.7307573556900024
Batch 62/64 loss: 1.7289206981658936
Batch 63/64 loss: 1.7310881614685059
Batch 64/64 loss: 1.9127273559570312
Epoch 334  Train loss: 1.7328289836060766  Val loss: 1.7458702805116004
Saving best model, epoch: 334
Epoch 335
-------------------------------
Batch 1/64 loss: 1.7284088134765625
Batch 2/64 loss: 1.727858543395996
Batch 3/64 loss: 1.727284550666809
Batch 4/64 loss: 1.725339412689209
Batch 5/64 loss: 1.7320339679718018
Batch 6/64 loss: 1.7304128408432007
Batch 7/64 loss: 1.732942819595337
Batch 8/64 loss: 1.7406575679779053
Batch 9/64 loss: 1.7304582595825195
Batch 10/64 loss: 1.729066252708435
Batch 11/64 loss: 1.7282501459121704
Batch 12/64 loss: 1.72812819480896
Batch 13/64 loss: 1.7287582159042358
Batch 14/64 loss: 1.731278419494629
Batch 15/64 loss: 1.7315466403961182
Batch 16/64 loss: 1.7304166555404663
Batch 17/64 loss: 1.74613618850708
Batch 18/64 loss: 1.7321710586547852
Batch 19/64 loss: 1.7362122535705566
Batch 20/64 loss: 1.7284584045410156
Batch 21/64 loss: 1.7278861999511719
Batch 22/64 loss: 1.7292665243148804
Batch 23/64 loss: 1.7328386306762695
Batch 24/64 loss: 1.7308052778244019
Batch 25/64 loss: 1.7302409410476685
Batch 26/64 loss: 1.7294305562973022
Batch 27/64 loss: 1.7333643436431885
Batch 28/64 loss: 1.7275142669677734
Batch 29/64 loss: 1.7336113452911377
Batch 30/64 loss: 1.7322168350219727
Batch 31/64 loss: 1.7286601066589355
Batch 32/64 loss: 1.727275013923645
Batch 33/64 loss: 1.7301218509674072
Batch 34/64 loss: 1.7315192222595215
Batch 35/64 loss: 1.7285369634628296
Batch 36/64 loss: 1.7313897609710693
Batch 37/64 loss: 1.728136420249939
Batch 38/64 loss: 1.7338725328445435
Batch 39/64 loss: 1.7326879501342773
Batch 40/64 loss: 1.7307071685791016
Batch 41/64 loss: 1.7276923656463623
Batch 42/64 loss: 1.7301852703094482
Batch 43/64 loss: 1.7289340496063232
Batch 44/64 loss: 1.729738712310791
Batch 45/64 loss: 1.728973388671875
Batch 46/64 loss: 1.7288695573806763
Batch 47/64 loss: 1.7339533567428589
Batch 48/64 loss: 1.7270474433898926
Batch 49/64 loss: 1.7279677391052246
Batch 50/64 loss: 1.7276862859725952
Batch 51/64 loss: 1.7307449579238892
Batch 52/64 loss: 1.730292797088623
Batch 53/64 loss: 1.7271692752838135
Batch 54/64 loss: 1.7301729917526245
Batch 55/64 loss: 1.7280874252319336
Batch 56/64 loss: 1.7303574085235596
Batch 57/64 loss: 1.727837324142456
Batch 58/64 loss: 1.725877046585083
Batch 59/64 loss: 1.7303669452667236
Batch 60/64 loss: 1.7436001300811768
Batch 61/64 loss: 1.7266011238098145
Batch 62/64 loss: 1.7417837381362915
Batch 63/64 loss: 1.7270286083221436
Batch 64/64 loss: 1.9079360961914062
Epoch 335  Train loss: 1.732671704011805  Val loss: 1.7466531651945867
Epoch 336
-------------------------------
Batch 1/64 loss: 1.7438254356384277
Batch 2/64 loss: 1.7321668863296509
Batch 3/64 loss: 1.731198787689209
Batch 4/64 loss: 1.7294740676879883
Batch 5/64 loss: 1.7333046197891235
Batch 6/64 loss: 1.7351913452148438
Batch 7/64 loss: 1.7286640405654907
Batch 8/64 loss: 1.7303736209869385
Batch 9/64 loss: 1.7291319370269775
Batch 10/64 loss: 1.7283389568328857
Batch 11/64 loss: 1.7270877361297607
Batch 12/64 loss: 1.7280292510986328
Batch 13/64 loss: 1.7274317741394043
Batch 14/64 loss: 1.7397568225860596
Batch 15/64 loss: 1.733729362487793
Batch 16/64 loss: 1.7313718795776367
Batch 17/64 loss: 1.7296080589294434
Batch 18/64 loss: 1.7361798286437988
Batch 19/64 loss: 1.731353998184204
Batch 20/64 loss: 1.7309236526489258
Batch 21/64 loss: 1.7306649684906006
Batch 22/64 loss: 1.7295722961425781
Batch 23/64 loss: 1.7332712411880493
Batch 24/64 loss: 1.7290432453155518
Batch 25/64 loss: 1.7291094064712524
Batch 26/64 loss: 1.730879306793213
Batch 27/64 loss: 1.7291932106018066
Batch 28/64 loss: 1.7271044254302979
Batch 29/64 loss: 1.7275488376617432
Batch 30/64 loss: 1.7293357849121094
Batch 31/64 loss: 1.728163480758667
Batch 32/64 loss: 1.7261269092559814
Batch 33/64 loss: 1.7278443574905396
Batch 34/64 loss: 1.7255070209503174
Batch 35/64 loss: 1.7289994955062866
Batch 36/64 loss: 1.7281687259674072
Batch 37/64 loss: 1.7270565032958984
Batch 38/64 loss: 1.7279069423675537
Batch 39/64 loss: 1.7287565469741821
Batch 40/64 loss: 1.727919578552246
Batch 41/64 loss: 1.7310709953308105
Batch 42/64 loss: 1.7276291847229004
Batch 43/64 loss: 1.7255144119262695
Batch 44/64 loss: 1.7270703315734863
Batch 45/64 loss: 1.727545976638794
Batch 46/64 loss: 1.7275111675262451
Batch 47/64 loss: 1.7284929752349854
Batch 48/64 loss: 1.7289305925369263
Batch 49/64 loss: 1.727668285369873
Batch 50/64 loss: 1.7293050289154053
Batch 51/64 loss: 1.7297947406768799
Batch 52/64 loss: 1.7458300590515137
Batch 53/64 loss: 1.7298274040222168
Batch 54/64 loss: 1.7305161952972412
Batch 55/64 loss: 1.7344962358474731
Batch 56/64 loss: 1.72878897190094
Batch 57/64 loss: 1.7276623249053955
Batch 58/64 loss: 1.7326254844665527
Batch 59/64 loss: 1.731818675994873
Batch 60/64 loss: 1.7354600429534912
Batch 61/64 loss: 1.7288453578948975
Batch 62/64 loss: 1.729870319366455
Batch 63/64 loss: 1.7283034324645996
Batch 64/64 loss: 1.9127745628356934
Epoch 336  Train loss: 1.732368211185231  Val loss: 1.7458216578690047
Saving best model, epoch: 336
Epoch 337
-------------------------------
Batch 1/64 loss: 1.7281370162963867
Batch 2/64 loss: 1.7272162437438965
Batch 3/64 loss: 1.7311453819274902
Batch 4/64 loss: 1.7306385040283203
Batch 5/64 loss: 1.7317426204681396
Batch 6/64 loss: 1.727132797241211
Batch 7/64 loss: 1.7312698364257812
Batch 8/64 loss: 1.7273375988006592
Batch 9/64 loss: 1.7303930521011353
Batch 10/64 loss: 1.7298274040222168
Batch 11/64 loss: 1.728484869003296
Batch 12/64 loss: 1.738661289215088
Batch 13/64 loss: 1.7275716066360474
Batch 14/64 loss: 1.728127360343933
Batch 15/64 loss: 1.7288787364959717
Batch 16/64 loss: 1.727449893951416
Batch 17/64 loss: 1.727663516998291
Batch 18/64 loss: 1.7317068576812744
Batch 19/64 loss: 1.7324910163879395
Batch 20/64 loss: 1.730072021484375
Batch 21/64 loss: 1.7239348888397217
Batch 22/64 loss: 1.7301218509674072
Batch 23/64 loss: 1.7293789386749268
Batch 24/64 loss: 1.7258754968643188
Batch 25/64 loss: 1.7290258407592773
Batch 26/64 loss: 1.7275729179382324
Batch 27/64 loss: 1.7330533266067505
Batch 28/64 loss: 1.727773666381836
Batch 29/64 loss: 1.7273578643798828
Batch 30/64 loss: 1.7298641204833984
Batch 31/64 loss: 1.7272882461547852
Batch 32/64 loss: 1.729871153831482
Batch 33/64 loss: 1.729125738143921
Batch 34/64 loss: 1.7302324771881104
Batch 35/64 loss: 1.7282421588897705
Batch 36/64 loss: 1.7308225631713867
Batch 37/64 loss: 1.7293481826782227
Batch 38/64 loss: 1.7312748432159424
Batch 39/64 loss: 1.7292677164077759
Batch 40/64 loss: 1.7312779426574707
Batch 41/64 loss: 1.728316068649292
Batch 42/64 loss: 1.7304965257644653
Batch 43/64 loss: 1.7309844493865967
Batch 44/64 loss: 1.727914810180664
Batch 45/64 loss: 1.7511249780654907
Batch 46/64 loss: 1.731518268585205
Batch 47/64 loss: 1.7291409969329834
Batch 48/64 loss: 1.7308106422424316
Batch 49/64 loss: 1.729112148284912
Batch 50/64 loss: 1.730250358581543
Batch 51/64 loss: 1.7284486293792725
Batch 52/64 loss: 1.7290499210357666
Batch 53/64 loss: 1.7307446002960205
Batch 54/64 loss: 1.7303810119628906
Batch 55/64 loss: 1.7313228845596313
Batch 56/64 loss: 1.7367440462112427
Batch 57/64 loss: 1.743776798248291
Batch 58/64 loss: 1.7322423458099365
Batch 59/64 loss: 1.7284820079803467
Batch 60/64 loss: 1.7260825634002686
Batch 61/64 loss: 1.725684642791748
Batch 62/64 loss: 1.7281149625778198
Batch 63/64 loss: 1.7435009479522705
Batch 64/64 loss: 1.9132541418075562
Epoch 337  Train loss: 1.7324838081995646  Val loss: 1.748085096529669
Epoch 338
-------------------------------
Batch 1/64 loss: 1.7315655946731567
Batch 2/64 loss: 1.7322893142700195
Batch 3/64 loss: 1.729369878768921
Batch 4/64 loss: 1.7291371822357178
Batch 5/64 loss: 1.7303422689437866
Batch 6/64 loss: 1.7295087575912476
Batch 7/64 loss: 1.7321827411651611
Batch 8/64 loss: 1.7270336151123047
Batch 9/64 loss: 1.7294888496398926
Batch 10/64 loss: 1.7293269634246826
Batch 11/64 loss: 1.728865385055542
Batch 12/64 loss: 1.72969388961792
Batch 13/64 loss: 1.7258481979370117
Batch 14/64 loss: 1.742767333984375
Batch 15/64 loss: 1.730076551437378
Batch 16/64 loss: 1.7330739498138428
Batch 17/64 loss: 1.7299015522003174
Batch 18/64 loss: 1.737677812576294
Batch 19/64 loss: 1.7320936918258667
Batch 20/64 loss: 1.7311986684799194
Batch 21/64 loss: 1.7312281131744385
Batch 22/64 loss: 1.7263472080230713
Batch 23/64 loss: 1.7301195859909058
Batch 24/64 loss: 1.7276952266693115
Batch 25/64 loss: 1.735502004623413
Batch 26/64 loss: 1.7323718070983887
Batch 27/64 loss: 1.731581211090088
Batch 28/64 loss: 1.7325811386108398
Batch 29/64 loss: 1.7290812730789185
Batch 30/64 loss: 1.7304295301437378
Batch 31/64 loss: 1.7320680618286133
Batch 32/64 loss: 1.726995825767517
Batch 33/64 loss: 1.735973834991455
Batch 34/64 loss: 1.7322523593902588
Batch 35/64 loss: 1.732809066772461
Batch 36/64 loss: 1.7301872968673706
Batch 37/64 loss: 1.7309136390686035
Batch 38/64 loss: 1.7358602285385132
Batch 39/64 loss: 1.729440450668335
Batch 40/64 loss: 1.7301115989685059
Batch 41/64 loss: 1.7300283908843994
Batch 42/64 loss: 1.746584177017212
Batch 43/64 loss: 1.7306286096572876
Batch 44/64 loss: 1.729851484298706
Batch 45/64 loss: 1.729166030883789
Batch 46/64 loss: 1.7329730987548828
Batch 47/64 loss: 1.7284188270568848
Batch 48/64 loss: 1.7319258451461792
Batch 49/64 loss: 1.7338160276412964
Batch 50/64 loss: 1.7319929599761963
Batch 51/64 loss: 1.7325372695922852
Batch 52/64 loss: 1.732102394104004
Batch 53/64 loss: 1.729621171951294
Batch 54/64 loss: 1.7301175594329834
Batch 55/64 loss: 1.7367992401123047
Batch 56/64 loss: 1.7349724769592285
Batch 57/64 loss: 1.735058069229126
Batch 58/64 loss: 1.7314198017120361
Batch 59/64 loss: 1.7453889846801758
Batch 60/64 loss: 1.7325973510742188
Batch 61/64 loss: 1.732572078704834
Batch 62/64 loss: 1.7335178852081299
Batch 63/64 loss: 1.7318849563598633
Batch 64/64 loss: 1.9203433990478516
Epoch 338  Train loss: 1.734105472938687  Val loss: 1.7535280476730715
Epoch 339
-------------------------------
Batch 1/64 loss: 1.7326675653457642
Batch 2/64 loss: 1.7329959869384766
Batch 3/64 loss: 1.7342485189437866
Batch 4/64 loss: 1.7392349243164062
Batch 5/64 loss: 1.7348424196243286
Batch 6/64 loss: 1.7352631092071533
Batch 7/64 loss: 1.7315218448638916
Batch 8/64 loss: 1.7319358587265015
Batch 9/64 loss: 1.7336645126342773
Batch 10/64 loss: 1.7352973222732544
Batch 11/64 loss: 1.7314543724060059
Batch 12/64 loss: 1.7459640502929688
Batch 13/64 loss: 1.7339625358581543
Batch 14/64 loss: 1.7338778972625732
Batch 15/64 loss: 1.7311651706695557
Batch 16/64 loss: 1.7286732196807861
Batch 17/64 loss: 1.7336487770080566
Batch 18/64 loss: 1.7303736209869385
Batch 19/64 loss: 1.7304913997650146
Batch 20/64 loss: 1.7292332649230957
Batch 21/64 loss: 1.729635238647461
Batch 22/64 loss: 1.732619285583496
Batch 23/64 loss: 1.7422171831130981
Batch 24/64 loss: 1.7315471172332764
Batch 25/64 loss: 1.7285223007202148
Batch 26/64 loss: 1.7290877103805542
Batch 27/64 loss: 1.7275784015655518
Batch 28/64 loss: 1.73052978515625
Batch 29/64 loss: 1.7284221649169922
Batch 30/64 loss: 1.7314541339874268
Batch 31/64 loss: 1.7316200733184814
Batch 32/64 loss: 1.7307404279708862
Batch 33/64 loss: 1.731675386428833
Batch 34/64 loss: 1.7294723987579346
Batch 35/64 loss: 1.7289276123046875
Batch 36/64 loss: 1.729158878326416
Batch 37/64 loss: 1.7476632595062256
Batch 38/64 loss: 1.7319167852401733
Batch 39/64 loss: 1.7265005111694336
Batch 40/64 loss: 1.7294809818267822
Batch 41/64 loss: 1.7450186014175415
Batch 42/64 loss: 1.7304937839508057
Batch 43/64 loss: 1.7271037101745605
Batch 44/64 loss: 1.7268375158309937
Batch 45/64 loss: 1.7279045581817627
Batch 46/64 loss: 1.733832597732544
Batch 47/64 loss: 1.728816270828247
Batch 48/64 loss: 1.7264049053192139
Batch 49/64 loss: 1.7309958934783936
Batch 50/64 loss: 1.7270550727844238
Batch 51/64 loss: 1.7304885387420654
Batch 52/64 loss: 1.728446125984192
Batch 53/64 loss: 1.7389429807662964
Batch 54/64 loss: 1.7303558588027954
Batch 55/64 loss: 1.7279307842254639
Batch 56/64 loss: 1.7334914207458496
Batch 57/64 loss: 1.7286059856414795
Batch 58/64 loss: 1.729434609413147
Batch 59/64 loss: 1.7272469997406006
Batch 60/64 loss: 1.7245393991470337
Batch 61/64 loss: 1.7263697385787964
Batch 62/64 loss: 1.7294738292694092
Batch 63/64 loss: 1.7301383018493652
Batch 64/64 loss: 1.9116014242172241
Epoch 339  Train loss: 1.7336927773905735  Val loss: 1.7473214975337392
Epoch 340
-------------------------------
Batch 1/64 loss: 1.7274682521820068
Batch 2/64 loss: 1.7281789779663086
Batch 3/64 loss: 1.7285691499710083
Batch 4/64 loss: 1.7267887592315674
Batch 5/64 loss: 1.727805256843567
Batch 6/64 loss: 1.7263274192810059
Batch 7/64 loss: 1.7261396646499634
Batch 8/64 loss: 1.7255218029022217
Batch 9/64 loss: 1.7268919944763184
Batch 10/64 loss: 1.7261152267456055
Batch 11/64 loss: 1.7273614406585693
Batch 12/64 loss: 1.745948314666748
Batch 13/64 loss: 1.7277045249938965
Batch 14/64 loss: 1.7279176712036133
Batch 15/64 loss: 1.729942798614502
Batch 16/64 loss: 1.7310073375701904
Batch 17/64 loss: 1.726633071899414
Batch 18/64 loss: 1.7292335033416748
Batch 19/64 loss: 1.7268967628479004
Batch 20/64 loss: 1.7295098304748535
Batch 21/64 loss: 1.7275097370147705
Batch 22/64 loss: 1.7255046367645264
Batch 23/64 loss: 1.7272682189941406
Batch 24/64 loss: 1.7263236045837402
Batch 25/64 loss: 1.728686809539795
Batch 26/64 loss: 1.7311365604400635
Batch 27/64 loss: 1.7294042110443115
Batch 28/64 loss: 1.731187105178833
Batch 29/64 loss: 1.7305891513824463
Batch 30/64 loss: 1.729219675064087
Batch 31/64 loss: 1.7282700538635254
Batch 32/64 loss: 1.7283703088760376
Batch 33/64 loss: 1.7308928966522217
Batch 34/64 loss: 1.7341216802597046
Batch 35/64 loss: 1.7295277118682861
Batch 36/64 loss: 1.7281628847122192
Batch 37/64 loss: 1.727386236190796
Batch 38/64 loss: 1.7259635925292969
Batch 39/64 loss: 1.7293214797973633
Batch 40/64 loss: 1.7270246744155884
Batch 41/64 loss: 1.7260123491287231
Batch 42/64 loss: 1.7292319536209106
Batch 43/64 loss: 1.738842248916626
Batch 44/64 loss: 1.7285246849060059
Batch 45/64 loss: 1.7304332256317139
Batch 46/64 loss: 1.734605312347412
Batch 47/64 loss: 1.7279167175292969
Batch 48/64 loss: 1.72709321975708
Batch 49/64 loss: 1.7302049398422241
Batch 50/64 loss: 1.7316522598266602
Batch 51/64 loss: 1.725957989692688
Batch 52/64 loss: 1.7293567657470703
Batch 53/64 loss: 1.732967734336853
Batch 54/64 loss: 1.7280941009521484
Batch 55/64 loss: 1.7288668155670166
Batch 56/64 loss: 1.7364975214004517
Batch 57/64 loss: 1.728365182876587
Batch 58/64 loss: 1.7303955554962158
Batch 59/64 loss: 1.7279314994812012
Batch 60/64 loss: 1.722841739654541
Batch 61/64 loss: 1.730098009109497
Batch 62/64 loss: 1.7422308921813965
Batch 63/64 loss: 1.7279064655303955
Batch 64/64 loss: 1.932457447052002
Epoch 340  Train loss: 1.7316580903296377  Val loss: 1.7480879796739297
Epoch 341
-------------------------------
Batch 1/64 loss: 1.731471300125122
Batch 2/64 loss: 1.7287518978118896
Batch 3/64 loss: 1.7324814796447754
Batch 4/64 loss: 1.726521372795105
Batch 5/64 loss: 1.7273633480072021
Batch 6/64 loss: 1.7289142608642578
Batch 7/64 loss: 1.728074550628662
Batch 8/64 loss: 1.7284965515136719
Batch 9/64 loss: 1.7277663946151733
Batch 10/64 loss: 1.7295963764190674
Batch 11/64 loss: 1.7270841598510742
Batch 12/64 loss: 1.7266372442245483
Batch 13/64 loss: 1.7289857864379883
Batch 14/64 loss: 1.7264587879180908
Batch 15/64 loss: 1.7279579639434814
Batch 16/64 loss: 1.7315261363983154
Batch 17/64 loss: 1.7336903810501099
Batch 18/64 loss: 1.7310669422149658
Batch 19/64 loss: 1.726367473602295
Batch 20/64 loss: 1.7292847633361816
Batch 21/64 loss: 1.7278308868408203
Batch 22/64 loss: 1.7274069786071777
Batch 23/64 loss: 1.7266706228256226
Batch 24/64 loss: 1.7252362966537476
Batch 25/64 loss: 1.72770357131958
Batch 26/64 loss: 1.7329754829406738
Batch 27/64 loss: 1.7290699481964111
Batch 28/64 loss: 1.72560715675354
Batch 29/64 loss: 1.7278728485107422
Batch 30/64 loss: 1.7265117168426514
Batch 31/64 loss: 1.727199673652649
Batch 32/64 loss: 1.7321994304656982
Batch 33/64 loss: 1.7299435138702393
Batch 34/64 loss: 1.728590965270996
Batch 35/64 loss: 1.727917194366455
Batch 36/64 loss: 1.7356747388839722
Batch 37/64 loss: 1.729123830795288
Batch 38/64 loss: 1.7303500175476074
Batch 39/64 loss: 1.731895923614502
Batch 40/64 loss: 1.729475736618042
Batch 41/64 loss: 1.7278035879135132
Batch 42/64 loss: 1.7319591045379639
Batch 43/64 loss: 1.7305556535720825
Batch 44/64 loss: 1.7275187969207764
Batch 45/64 loss: 1.7414699792861938
Batch 46/64 loss: 1.7289280891418457
Batch 47/64 loss: 1.7325359582901
Batch 48/64 loss: 1.7348476648330688
Batch 49/64 loss: 1.7282655239105225
Batch 50/64 loss: 1.7485477924346924
Batch 51/64 loss: 1.7338358163833618
Batch 52/64 loss: 1.7288901805877686
Batch 53/64 loss: 1.741888165473938
Batch 54/64 loss: 1.7347811460494995
Batch 55/64 loss: 1.7317582368850708
Batch 56/64 loss: 1.7295411825180054
Batch 57/64 loss: 1.7299151420593262
Batch 58/64 loss: 1.731126070022583
Batch 59/64 loss: 1.730112910270691
Batch 60/64 loss: 1.728466272354126
Batch 61/64 loss: 1.7303683757781982
Batch 62/64 loss: 1.7335946559906006
Batch 63/64 loss: 1.7346097230911255
Batch 64/64 loss: 1.9115641117095947
Epoch 341  Train loss: 1.7324352442049513  Val loss: 1.7456020932017322
Saving best model, epoch: 341
Epoch 342
-------------------------------
Batch 1/64 loss: 1.7290120124816895
Batch 2/64 loss: 1.7262468338012695
Batch 3/64 loss: 1.7249863147735596
Batch 4/64 loss: 1.728374719619751
Batch 5/64 loss: 1.7349933385849
Batch 6/64 loss: 1.7286474704742432
Batch 7/64 loss: 1.7322559356689453
Batch 8/64 loss: 1.744936227798462
Batch 9/64 loss: 1.7350424528121948
Batch 10/64 loss: 1.725351095199585
Batch 11/64 loss: 1.7289133071899414
Batch 12/64 loss: 1.7266054153442383
Batch 13/64 loss: 1.728179931640625
Batch 14/64 loss: 1.731020450592041
Batch 15/64 loss: 1.7271521091461182
Batch 16/64 loss: 1.7292976379394531
Batch 17/64 loss: 1.7263871431350708
Batch 18/64 loss: 1.7299529314041138
Batch 19/64 loss: 1.730168342590332
Batch 20/64 loss: 1.727225422859192
Batch 21/64 loss: 1.72757887840271
Batch 22/64 loss: 1.7329258918762207
Batch 23/64 loss: 1.7277158498764038
Batch 24/64 loss: 1.7315001487731934
Batch 25/64 loss: 1.728360652923584
Batch 26/64 loss: 1.730456829071045
Batch 27/64 loss: 1.7275810241699219
Batch 28/64 loss: 1.7298072576522827
Batch 29/64 loss: 1.7273757457733154
Batch 30/64 loss: 1.7298390865325928
Batch 31/64 loss: 1.7277021408081055
Batch 32/64 loss: 1.7294807434082031
Batch 33/64 loss: 1.7303540706634521
Batch 34/64 loss: 1.7329334020614624
Batch 35/64 loss: 1.7297124862670898
Batch 36/64 loss: 1.7308462858200073
Batch 37/64 loss: 1.7326050996780396
Batch 38/64 loss: 1.728006362915039
Batch 39/64 loss: 1.7312371730804443
Batch 40/64 loss: 1.7320629358291626
Batch 41/64 loss: 1.7271640300750732
Batch 42/64 loss: 1.7326031923294067
Batch 43/64 loss: 1.729621171951294
Batch 44/64 loss: 1.728663682937622
Batch 45/64 loss: 1.7287828922271729
Batch 46/64 loss: 1.7314386367797852
Batch 47/64 loss: 1.7336821556091309
Batch 48/64 loss: 1.734688639640808
Batch 49/64 loss: 1.7289910316467285
Batch 50/64 loss: 1.7297470569610596
Batch 51/64 loss: 1.746253490447998
Batch 52/64 loss: 1.7290809154510498
Batch 53/64 loss: 1.728778600692749
Batch 54/64 loss: 1.7517642974853516
Batch 55/64 loss: 1.7326648235321045
Batch 56/64 loss: 1.729228138923645
Batch 57/64 loss: 1.7301673889160156
Batch 58/64 loss: 1.728177547454834
Batch 59/64 loss: 1.729201078414917
Batch 60/64 loss: 1.7301499843597412
Batch 61/64 loss: 1.7341220378875732
Batch 62/64 loss: 1.7309904098510742
Batch 63/64 loss: 1.7324581146240234
Batch 64/64 loss: 1.9121363162994385
Epoch 342  Train loss: 1.7327898464950862  Val loss: 1.7465368742795335
Epoch 343
-------------------------------
Batch 1/64 loss: 1.728018879890442
Batch 2/64 loss: 1.7339451313018799
Batch 3/64 loss: 1.7423732280731201
Batch 4/64 loss: 1.731628179550171
Batch 5/64 loss: 1.728426456451416
Batch 6/64 loss: 1.730268955230713
Batch 7/64 loss: 1.7287054061889648
Batch 8/64 loss: 1.7294853925704956
Batch 9/64 loss: 1.7311816215515137
Batch 10/64 loss: 1.7271544933319092
Batch 11/64 loss: 1.7287297248840332
Batch 12/64 loss: 1.7323145866394043
Batch 13/64 loss: 1.7247687578201294
Batch 14/64 loss: 1.7266075611114502
Batch 15/64 loss: 1.7290539741516113
Batch 16/64 loss: 1.7270617485046387
Batch 17/64 loss: 1.7295799255371094
Batch 18/64 loss: 1.7273943424224854
Batch 19/64 loss: 1.7467150688171387
Batch 20/64 loss: 1.7307264804840088
Batch 21/64 loss: 1.7309406995773315
Batch 22/64 loss: 1.7264080047607422
Batch 23/64 loss: 1.7287261486053467
Batch 24/64 loss: 1.7279138565063477
Batch 25/64 loss: 1.729383111000061
Batch 26/64 loss: 1.7336554527282715
Batch 27/64 loss: 1.7319450378417969
Batch 28/64 loss: 1.743128776550293
Batch 29/64 loss: 1.739534616470337
Batch 30/64 loss: 1.7305386066436768
Batch 31/64 loss: 1.7296829223632812
Batch 32/64 loss: 1.7278578281402588
Batch 33/64 loss: 1.7279363870620728
Batch 34/64 loss: 1.7366554737091064
Batch 35/64 loss: 1.7291114330291748
Batch 36/64 loss: 1.740545392036438
Batch 37/64 loss: 1.7364931106567383
Batch 38/64 loss: 1.7401893138885498
Batch 39/64 loss: 1.7364705801010132
Batch 40/64 loss: 1.7311010360717773
Batch 41/64 loss: 1.7347501516342163
Batch 42/64 loss: 1.7325968742370605
Batch 43/64 loss: 1.733109712600708
Batch 44/64 loss: 1.7287006378173828
Batch 45/64 loss: 1.7281012535095215
Batch 46/64 loss: 1.7428644895553589
Batch 47/64 loss: 1.7291547060012817
Batch 48/64 loss: 1.7292330265045166
Batch 49/64 loss: 1.7273476123809814
Batch 50/64 loss: 1.7281928062438965
Batch 51/64 loss: 1.731703281402588
Batch 52/64 loss: 1.7261772155761719
Batch 53/64 loss: 1.7289848327636719
Batch 54/64 loss: 1.7321914434432983
Batch 55/64 loss: 1.7301403284072876
Batch 56/64 loss: 1.7353012561798096
Batch 57/64 loss: 1.7292299270629883
Batch 58/64 loss: 1.7285752296447754
Batch 59/64 loss: 1.7317372560501099
Batch 60/64 loss: 1.7294931411743164
Batch 61/64 loss: 1.7291061878204346
Batch 62/64 loss: 1.7321484088897705
Batch 63/64 loss: 1.7313156127929688
Batch 64/64 loss: 1.9072544574737549
Epoch 343  Train loss: 1.7335365323459402  Val loss: 1.7464071360650342
Epoch 344
-------------------------------
Batch 1/64 loss: 1.7339422702789307
Batch 2/64 loss: 1.7300643920898438
Batch 3/64 loss: 1.7275214195251465
Batch 4/64 loss: 1.7329896688461304
Batch 5/64 loss: 1.7361536026000977
Batch 6/64 loss: 1.7280489206314087
Batch 7/64 loss: 1.7270621061325073
Batch 8/64 loss: 1.7300856113433838
Batch 9/64 loss: 1.7307190895080566
Batch 10/64 loss: 1.7287626266479492
Batch 11/64 loss: 1.7285959720611572
Batch 12/64 loss: 1.7286186218261719
Batch 13/64 loss: 1.7291616201400757
Batch 14/64 loss: 1.728499174118042
Batch 15/64 loss: 1.734297752380371
Batch 16/64 loss: 1.7298967838287354
Batch 17/64 loss: 1.7268617153167725
Batch 18/64 loss: 1.7297446727752686
Batch 19/64 loss: 1.7293694019317627
Batch 20/64 loss: 1.7300968170166016
Batch 21/64 loss: 1.727752685546875
Batch 22/64 loss: 1.7256697416305542
Batch 23/64 loss: 1.7317272424697876
Batch 24/64 loss: 1.7304120063781738
Batch 25/64 loss: 1.728973388671875
Batch 26/64 loss: 1.7291362285614014
Batch 27/64 loss: 1.7285079956054688
Batch 28/64 loss: 1.7296866178512573
Batch 29/64 loss: 1.728529691696167
Batch 30/64 loss: 1.729957103729248
Batch 31/64 loss: 1.727066993713379
Batch 32/64 loss: 1.727895736694336
Batch 33/64 loss: 1.7304480075836182
Batch 34/64 loss: 1.7276086807250977
Batch 35/64 loss: 1.727705478668213
Batch 36/64 loss: 1.7326762676239014
Batch 37/64 loss: 1.7267777919769287
Batch 38/64 loss: 1.7268381118774414
Batch 39/64 loss: 1.7276484966278076
Batch 40/64 loss: 1.7293567657470703
Batch 41/64 loss: 1.743039846420288
Batch 42/64 loss: 1.731893539428711
Batch 43/64 loss: 1.7440812587738037
Batch 44/64 loss: 1.7288219928741455
Batch 45/64 loss: 1.7292399406433105
Batch 46/64 loss: 1.7349615097045898
Batch 47/64 loss: 1.742292881011963
Batch 48/64 loss: 1.737877368927002
Batch 49/64 loss: 1.7299370765686035
Batch 50/64 loss: 1.7300195693969727
Batch 51/64 loss: 1.7319415807724
Batch 52/64 loss: 1.7280466556549072
Batch 53/64 loss: 1.7306629419326782
Batch 54/64 loss: 1.7278802394866943
Batch 55/64 loss: 1.7311229705810547
Batch 56/64 loss: 1.728539228439331
Batch 57/64 loss: 1.737806797027588
Batch 58/64 loss: 1.7302155494689941
Batch 59/64 loss: 1.7244651317596436
Batch 60/64 loss: 1.7474358081817627
Batch 61/64 loss: 1.7309370040893555
Batch 62/64 loss: 1.727299451828003
Batch 63/64 loss: 1.7285196781158447
Batch 64/64 loss: 1.9054725170135498
Epoch 344  Train loss: 1.732721720489801  Val loss: 1.748626347669621
Epoch 345
-------------------------------
Batch 1/64 loss: 1.7270548343658447
Batch 2/64 loss: 1.7311217784881592
Batch 3/64 loss: 1.729670763015747
Batch 4/64 loss: 1.7269713878631592
Batch 5/64 loss: 1.7299153804779053
Batch 6/64 loss: 1.7299680709838867
Batch 7/64 loss: 1.7286477088928223
Batch 8/64 loss: 1.7285257577896118
Batch 9/64 loss: 1.7302985191345215
Batch 10/64 loss: 1.7286286354064941
Batch 11/64 loss: 1.7320492267608643
Batch 12/64 loss: 1.7279953956604004
Batch 13/64 loss: 1.7310211658477783
Batch 14/64 loss: 1.742548942565918
Batch 15/64 loss: 1.7296503782272339
Batch 16/64 loss: 1.732417106628418
Batch 17/64 loss: 1.7293682098388672
Batch 18/64 loss: 1.7310384511947632
Batch 19/64 loss: 1.7293769121170044
Batch 20/64 loss: 1.7274746894836426
Batch 21/64 loss: 1.7304366827011108
Batch 22/64 loss: 1.7299761772155762
Batch 23/64 loss: 1.7252318859100342
Batch 24/64 loss: 1.7331647872924805
Batch 25/64 loss: 1.7284331321716309
Batch 26/64 loss: 1.7316324710845947
Batch 27/64 loss: 1.7275943756103516
Batch 28/64 loss: 1.7297794818878174
Batch 29/64 loss: 1.7292699813842773
Batch 30/64 loss: 1.7262632846832275
Batch 31/64 loss: 1.7317824363708496
Batch 32/64 loss: 1.7262998819351196
Batch 33/64 loss: 1.7288315296173096
Batch 34/64 loss: 1.7264702320098877
Batch 35/64 loss: 1.7267427444458008
Batch 36/64 loss: 1.7292299270629883
Batch 37/64 loss: 1.7290972471237183
Batch 38/64 loss: 1.7286162376403809
Batch 39/64 loss: 1.7302662134170532
Batch 40/64 loss: 1.7262603044509888
Batch 41/64 loss: 1.726887583732605
Batch 42/64 loss: 1.7452322244644165
Batch 43/64 loss: 1.7266254425048828
Batch 44/64 loss: 1.7255860567092896
Batch 45/64 loss: 1.7297444343566895
Batch 46/64 loss: 1.7262945175170898
Batch 47/64 loss: 1.727308988571167
Batch 48/64 loss: 1.7260468006134033
Batch 49/64 loss: 1.7273054122924805
Batch 50/64 loss: 1.7324724197387695
Batch 51/64 loss: 1.7290942668914795
Batch 52/64 loss: 1.7276034355163574
Batch 53/64 loss: 1.7278485298156738
Batch 54/64 loss: 1.7308390140533447
Batch 55/64 loss: 1.7289092540740967
Batch 56/64 loss: 1.7409130334854126
Batch 57/64 loss: 1.7290840148925781
Batch 58/64 loss: 1.7267104387283325
Batch 59/64 loss: 1.7345829010009766
Batch 60/64 loss: 1.7309825420379639
Batch 61/64 loss: 1.7276453971862793
Batch 62/64 loss: 1.7271902561187744
Batch 63/64 loss: 1.7286105155944824
Batch 64/64 loss: 1.908674716949463
Epoch 345  Train loss: 1.7316728760214413  Val loss: 1.7449950704869537
Saving best model, epoch: 345
Epoch 346
-------------------------------
Batch 1/64 loss: 1.7319254875183105
Batch 2/64 loss: 1.7270019054412842
Batch 3/64 loss: 1.7270394563674927
Batch 4/64 loss: 1.7290937900543213
Batch 5/64 loss: 1.7432845830917358
Batch 6/64 loss: 1.7269508838653564
Batch 7/64 loss: 1.7274284362792969
Batch 8/64 loss: 1.7252330780029297
Batch 9/64 loss: 1.7379624843597412
Batch 10/64 loss: 1.7299296855926514
Batch 11/64 loss: 1.7272884845733643
Batch 12/64 loss: 1.7285583019256592
Batch 13/64 loss: 1.737303614616394
Batch 14/64 loss: 1.7296664714813232
Batch 15/64 loss: 1.7264838218688965
Batch 16/64 loss: 1.7336251735687256
Batch 17/64 loss: 1.7297160625457764
Batch 18/64 loss: 1.7325690984725952
Batch 19/64 loss: 1.731017827987671
Batch 20/64 loss: 1.7298862934112549
Batch 21/64 loss: 1.7268311977386475
Batch 22/64 loss: 1.7286731004714966
Batch 23/64 loss: 1.7292671203613281
Batch 24/64 loss: 1.7268434762954712
Batch 25/64 loss: 1.7272260189056396
Batch 26/64 loss: 1.7395212650299072
Batch 27/64 loss: 1.7274444103240967
Batch 28/64 loss: 1.7273070812225342
Batch 29/64 loss: 1.7264055013656616
Batch 30/64 loss: 1.7255134582519531
Batch 31/64 loss: 1.7289930582046509
Batch 32/64 loss: 1.7238430976867676
Batch 33/64 loss: 1.729048252105713
Batch 34/64 loss: 1.7277909517288208
Batch 35/64 loss: 1.7270742654800415
Batch 36/64 loss: 1.7235767841339111
Batch 37/64 loss: 1.7273790836334229
Batch 38/64 loss: 1.7280006408691406
Batch 39/64 loss: 1.7473225593566895
Batch 40/64 loss: 1.7286560535430908
Batch 41/64 loss: 1.7254974842071533
Batch 42/64 loss: 1.7258594036102295
Batch 43/64 loss: 1.7282793521881104
Batch 44/64 loss: 1.7293715476989746
Batch 45/64 loss: 1.7276992797851562
Batch 46/64 loss: 1.7278223037719727
Batch 47/64 loss: 1.7259889841079712
Batch 48/64 loss: 1.7276941537857056
Batch 49/64 loss: 1.7250545024871826
Batch 50/64 loss: 1.7262109518051147
Batch 51/64 loss: 1.7268798351287842
Batch 52/64 loss: 1.7268468141555786
Batch 53/64 loss: 1.7260699272155762
Batch 54/64 loss: 1.7255079746246338
Batch 55/64 loss: 1.7289633750915527
Batch 56/64 loss: 1.7254626750946045
Batch 57/64 loss: 1.7270698547363281
Batch 58/64 loss: 1.72963547706604
Batch 59/64 loss: 1.7345564365386963
Batch 60/64 loss: 1.726342797279358
Batch 61/64 loss: 1.7276136875152588
Batch 62/64 loss: 1.727595567703247
Batch 63/64 loss: 1.7293000221252441
Batch 64/64 loss: 1.9140515327453613
Epoch 346  Train loss: 1.731067347059063  Val loss: 1.7444349949302542
Saving best model, epoch: 346
Epoch 347
-------------------------------
Batch 1/64 loss: 1.7273305654525757
Batch 2/64 loss: 1.726205825805664
Batch 3/64 loss: 1.7269493341445923
Batch 4/64 loss: 1.7273199558258057
Batch 5/64 loss: 1.7322838306427002
Batch 6/64 loss: 1.7294584512710571
Batch 7/64 loss: 1.730142593383789
Batch 8/64 loss: 1.7289292812347412
Batch 9/64 loss: 1.7275581359863281
Batch 10/64 loss: 1.7262647151947021
Batch 11/64 loss: 1.7300257682800293
Batch 12/64 loss: 1.729416012763977
Batch 13/64 loss: 1.7304251194000244
Batch 14/64 loss: 1.7291574478149414
Batch 15/64 loss: 1.7240499258041382
Batch 16/64 loss: 1.7281032800674438
Batch 17/64 loss: 1.7281534671783447
Batch 18/64 loss: 1.731797695159912
Batch 19/64 loss: 1.7269734144210815
Batch 20/64 loss: 1.7291330099105835
Batch 21/64 loss: 1.7315113544464111
Batch 22/64 loss: 1.728224277496338
Batch 23/64 loss: 1.7265186309814453
Batch 24/64 loss: 1.7463269233703613
Batch 25/64 loss: 1.7256510257720947
Batch 26/64 loss: 1.7298465967178345
Batch 27/64 loss: 1.7249698638916016
Batch 28/64 loss: 1.726644515991211
Batch 29/64 loss: 1.7282226085662842
Batch 30/64 loss: 1.7266806364059448
Batch 31/64 loss: 1.7275328636169434
Batch 32/64 loss: 1.7300612926483154
Batch 33/64 loss: 1.729175329208374
Batch 34/64 loss: 1.730004906654358
Batch 35/64 loss: 1.728769302368164
Batch 36/64 loss: 1.7339487075805664
Batch 37/64 loss: 1.7328126430511475
Batch 38/64 loss: 1.7270300388336182
Batch 39/64 loss: 1.7298601865768433
Batch 40/64 loss: 1.7269036769866943
Batch 41/64 loss: 1.7305421829223633
Batch 42/64 loss: 1.729408621788025
Batch 43/64 loss: 1.727858543395996
Batch 44/64 loss: 1.72627854347229
Batch 45/64 loss: 1.728803277015686
Batch 46/64 loss: 1.7255916595458984
Batch 47/64 loss: 1.7261123657226562
Batch 48/64 loss: 1.7328128814697266
Batch 49/64 loss: 1.727056860923767
Batch 50/64 loss: 1.7274699211120605
Batch 51/64 loss: 1.7282487154006958
Batch 52/64 loss: 1.7269675731658936
Batch 53/64 loss: 1.7277569770812988
Batch 54/64 loss: 1.7253243923187256
Batch 55/64 loss: 1.7291226387023926
Batch 56/64 loss: 1.7439846992492676
Batch 57/64 loss: 1.7311817407608032
Batch 58/64 loss: 1.7291865348815918
Batch 59/64 loss: 1.7304233312606812
Batch 60/64 loss: 1.7283403873443604
Batch 61/64 loss: 1.7314850091934204
Batch 62/64 loss: 1.732441782951355
Batch 63/64 loss: 1.7417948246002197
Batch 64/64 loss: 1.9115326404571533
Epoch 347  Train loss: 1.7314857436161415  Val loss: 1.7483906000340517
Epoch 348
-------------------------------
Batch 1/64 loss: 1.7292182445526123
Batch 2/64 loss: 1.7444097995758057
Batch 3/64 loss: 1.7290337085723877
Batch 4/64 loss: 1.728595495223999
Batch 5/64 loss: 1.730705738067627
Batch 6/64 loss: 1.7301244735717773
Batch 7/64 loss: 1.734358787536621
Batch 8/64 loss: 1.729113221168518
Batch 9/64 loss: 1.7306921482086182
Batch 10/64 loss: 1.7287836074829102
Batch 11/64 loss: 1.7279421091079712
Batch 12/64 loss: 1.7313029766082764
Batch 13/64 loss: 1.72987961769104
Batch 14/64 loss: 1.7313868999481201
Batch 15/64 loss: 1.7317718267440796
Batch 16/64 loss: 1.7270293235778809
Batch 17/64 loss: 1.7277178764343262
Batch 18/64 loss: 1.7272158861160278
Batch 19/64 loss: 1.7285115718841553
Batch 20/64 loss: 1.7288516759872437
Batch 21/64 loss: 1.7325116395950317
Batch 22/64 loss: 1.730391025543213
Batch 23/64 loss: 1.728684902191162
Batch 24/64 loss: 1.748507022857666
Batch 25/64 loss: 1.728372573852539
Batch 26/64 loss: 1.7352664470672607
Batch 27/64 loss: 1.7280797958374023
Batch 28/64 loss: 1.7256003618240356
Batch 29/64 loss: 1.7282384634017944
Batch 30/64 loss: 1.7328561544418335
Batch 31/64 loss: 1.7291076183319092
Batch 32/64 loss: 1.7406516075134277
Batch 33/64 loss: 1.7289397716522217
Batch 34/64 loss: 1.7265286445617676
Batch 35/64 loss: 1.7315711975097656
Batch 36/64 loss: 1.7316805124282837
Batch 37/64 loss: 1.728251576423645
Batch 38/64 loss: 1.7257496118545532
Batch 39/64 loss: 1.7259410619735718
Batch 40/64 loss: 1.7283469438552856
Batch 41/64 loss: 1.7271653413772583
Batch 42/64 loss: 1.7277281284332275
Batch 43/64 loss: 1.731134057044983
Batch 44/64 loss: 1.7269766330718994
Batch 45/64 loss: 1.740260362625122
Batch 46/64 loss: 1.7277894020080566
Batch 47/64 loss: 1.7301230430603027
Batch 48/64 loss: 1.727780818939209
Batch 49/64 loss: 1.7304141521453857
Batch 50/64 loss: 1.7347958087921143
Batch 51/64 loss: 1.7300523519515991
Batch 52/64 loss: 1.7299549579620361
Batch 53/64 loss: 1.728555679321289
Batch 54/64 loss: 1.727905035018921
Batch 55/64 loss: 1.7282710075378418
Batch 56/64 loss: 1.730536937713623
Batch 57/64 loss: 1.7327277660369873
Batch 58/64 loss: 1.7285850048065186
Batch 59/64 loss: 1.7291401624679565
Batch 60/64 loss: 1.7283344268798828
Batch 61/64 loss: 1.7313125133514404
Batch 62/64 loss: 1.7258819341659546
Batch 63/64 loss: 1.727440357208252
Batch 64/64 loss: 1.9060267210006714
Epoch 348  Train loss: 1.7323028681324977  Val loss: 1.7460516408546685
Epoch 349
-------------------------------
Batch 1/64 loss: 1.7259143590927124
Batch 2/64 loss: 1.728166103363037
Batch 3/64 loss: 1.7292803525924683
Batch 4/64 loss: 1.7283475399017334
Batch 5/64 loss: 1.7270886898040771
Batch 6/64 loss: 1.7374780178070068
Batch 7/64 loss: 1.726711630821228
Batch 8/64 loss: 1.726379632949829
Batch 9/64 loss: 1.7273986339569092
Batch 10/64 loss: 1.727551817893982
Batch 11/64 loss: 1.7282533645629883
Batch 12/64 loss: 1.7284682989120483
Batch 13/64 loss: 1.7310500144958496
Batch 14/64 loss: 1.7299659252166748
Batch 15/64 loss: 1.7269034385681152
Batch 16/64 loss: 1.7275322675704956
Batch 17/64 loss: 1.7291550636291504
Batch 18/64 loss: 1.7296963930130005
Batch 19/64 loss: 1.7427725791931152
Batch 20/64 loss: 1.7269651889801025
Batch 21/64 loss: 1.7345091104507446
Batch 22/64 loss: 1.7456350326538086
Batch 23/64 loss: 1.7293317317962646
Batch 24/64 loss: 1.7302502393722534
Batch 25/64 loss: 1.7290740013122559
Batch 26/64 loss: 1.7332205772399902
Batch 27/64 loss: 1.7298636436462402
Batch 28/64 loss: 1.7460644245147705
Batch 29/64 loss: 1.7288439273834229
Batch 30/64 loss: 1.7303173542022705
Batch 31/64 loss: 1.732193946838379
Batch 32/64 loss: 1.7305734157562256
Batch 33/64 loss: 1.730124592781067
Batch 34/64 loss: 1.7266814708709717
Batch 35/64 loss: 1.732694149017334
Batch 36/64 loss: 1.7271907329559326
Batch 37/64 loss: 1.7329342365264893
Batch 38/64 loss: 1.7347257137298584
Batch 39/64 loss: 1.7288579940795898
Batch 40/64 loss: 1.7295023202896118
Batch 41/64 loss: 1.734767198562622
Batch 42/64 loss: 1.7288486957550049
Batch 43/64 loss: 1.7293624877929688
Batch 44/64 loss: 1.727750539779663
Batch 45/64 loss: 1.7299199104309082
Batch 46/64 loss: 1.732743263244629
Batch 47/64 loss: 1.7286559343338013
Batch 48/64 loss: 1.7300755977630615
Batch 49/64 loss: 1.7278926372528076
Batch 50/64 loss: 1.7271870374679565
Batch 51/64 loss: 1.7286497354507446
Batch 52/64 loss: 1.7259800434112549
Batch 53/64 loss: 1.7331111431121826
Batch 54/64 loss: 1.7325687408447266
Batch 55/64 loss: 1.7328029870986938
Batch 56/64 loss: 1.7278335094451904
Batch 57/64 loss: 1.728863000869751
Batch 58/64 loss: 1.72976815700531
Batch 59/64 loss: 1.7312498092651367
Batch 60/64 loss: 1.728806495666504
Batch 61/64 loss: 1.7275946140289307
Batch 62/64 loss: 1.728116512298584
Batch 63/64 loss: 1.7284612655639648
Batch 64/64 loss: 1.910632610321045
Epoch 349  Train loss: 1.7324180659125834  Val loss: 1.7471582602799143
Epoch 350
-------------------------------
Batch 1/64 loss: 1.7246867418289185
Batch 2/64 loss: 1.7323272228240967
Batch 3/64 loss: 1.7293423414230347
Batch 4/64 loss: 1.729672908782959
Batch 5/64 loss: 1.7439883947372437
Batch 6/64 loss: 1.7294752597808838
Batch 7/64 loss: 1.7273519039154053
Batch 8/64 loss: 1.7299145460128784
Batch 9/64 loss: 1.731541395187378
Batch 10/64 loss: 1.733614206314087
Batch 11/64 loss: 1.7323787212371826
Batch 12/64 loss: 1.7296295166015625
Batch 13/64 loss: 1.7261921167373657
Batch 14/64 loss: 1.7280521392822266
Batch 15/64 loss: 1.7340368032455444
Batch 16/64 loss: 1.7293158769607544
Batch 17/64 loss: 1.748513102531433
Batch 18/64 loss: 1.7250598669052124
Batch 19/64 loss: 1.7377333641052246
Batch 20/64 loss: 1.7309350967407227
Batch 21/64 loss: 1.7271661758422852
Batch 22/64 loss: 1.7248432636260986
Batch 23/64 loss: 1.7296055555343628
Batch 24/64 loss: 1.728814959526062
Batch 25/64 loss: 1.726592779159546
Batch 26/64 loss: 1.730921745300293
Batch 27/64 loss: 1.7290821075439453
Batch 28/64 loss: 1.7289738655090332
Batch 29/64 loss: 1.7340446710586548
Batch 30/64 loss: 1.7275373935699463
Batch 31/64 loss: 1.7301744222640991
Batch 32/64 loss: 1.7299232482910156
Batch 33/64 loss: 1.7274534702301025
Batch 34/64 loss: 1.7332879304885864
Batch 35/64 loss: 1.7309702634811401
Batch 36/64 loss: 1.7292766571044922
Batch 37/64 loss: 1.7284982204437256
Batch 38/64 loss: 1.730539083480835
Batch 39/64 loss: 1.7255245447158813
Batch 40/64 loss: 1.731238842010498
Batch 41/64 loss: 1.73038911819458
Batch 42/64 loss: 1.7321844100952148
Batch 43/64 loss: 1.7294700145721436
Batch 44/64 loss: 1.7261441946029663
Batch 45/64 loss: 1.7283953428268433
Batch 46/64 loss: 1.7304579019546509
Batch 47/64 loss: 1.7337870597839355
Batch 48/64 loss: 1.7334027290344238
Batch 49/64 loss: 1.7282918691635132
Batch 50/64 loss: 1.731694221496582
Batch 51/64 loss: 1.7334516048431396
Batch 52/64 loss: 1.728474736213684
Batch 53/64 loss: 1.7285103797912598
Batch 54/64 loss: 1.7372267246246338
Batch 55/64 loss: 1.730760097503662
Batch 56/64 loss: 1.733292818069458
Batch 57/64 loss: 1.7312991619110107
Batch 58/64 loss: 1.7295374870300293
Batch 59/64 loss: 1.729144811630249
Batch 60/64 loss: 1.7494540214538574
Batch 61/64 loss: 1.7311062812805176
Batch 62/64 loss: 1.7323799133300781
Batch 63/64 loss: 1.7326021194458008
Batch 64/64 loss: 1.914252758026123
Epoch 350  Train loss: 1.7331039578306908  Val loss: 1.7492019859785886
Epoch 351
-------------------------------
Batch 1/64 loss: 1.7394683361053467
Batch 2/64 loss: 1.7340705394744873
Batch 3/64 loss: 1.731767177581787
Batch 4/64 loss: 1.7321979999542236
Batch 5/64 loss: 1.7290563583374023
Batch 6/64 loss: 1.7288179397583008
Batch 7/64 loss: 1.7400518655776978
Batch 8/64 loss: 1.7299597263336182
Batch 9/64 loss: 1.7325141429901123
Batch 10/64 loss: 1.732114553451538
Batch 11/64 loss: 1.7284467220306396
Batch 12/64 loss: 1.7309296131134033
Batch 13/64 loss: 1.73116135597229
Batch 14/64 loss: 1.7287213802337646
Batch 15/64 loss: 1.7360975742340088
Batch 16/64 loss: 1.7334768772125244
Batch 17/64 loss: 1.7321860790252686
Batch 18/64 loss: 1.7320787906646729
Batch 19/64 loss: 1.7285592555999756
Batch 20/64 loss: 1.728562831878662
Batch 21/64 loss: 1.7321817874908447
Batch 22/64 loss: 1.7293787002563477
Batch 23/64 loss: 1.729621410369873
Batch 24/64 loss: 1.7312159538269043
Batch 25/64 loss: 1.7316312789916992
Batch 26/64 loss: 1.7315961122512817
Batch 27/64 loss: 1.730057954788208
Batch 28/64 loss: 1.7324076890945435
Batch 29/64 loss: 1.7289962768554688
Batch 30/64 loss: 1.7382187843322754
Batch 31/64 loss: 1.7304160594940186
Batch 32/64 loss: 1.7295727729797363
Batch 33/64 loss: 1.732642412185669
Batch 34/64 loss: 1.7272119522094727
Batch 35/64 loss: 1.7297093868255615
Batch 36/64 loss: 1.7293238639831543
Batch 37/64 loss: 1.7340025901794434
Batch 38/64 loss: 1.7278575897216797
Batch 39/64 loss: 1.7267167568206787
Batch 40/64 loss: 1.7324175834655762
Batch 41/64 loss: 1.729936122894287
Batch 42/64 loss: 1.7440842390060425
Batch 43/64 loss: 1.7469905614852905
Batch 44/64 loss: 1.727620005607605
Batch 45/64 loss: 1.7277973890304565
Batch 46/64 loss: 1.7323269844055176
Batch 47/64 loss: 1.7324094772338867
Batch 48/64 loss: 1.7308423519134521
Batch 49/64 loss: 1.73013436794281
Batch 50/64 loss: 1.7267541885375977
Batch 51/64 loss: 1.7404975891113281
Batch 52/64 loss: 1.729429006576538
Batch 53/64 loss: 1.7293744087219238
Batch 54/64 loss: 1.7323943376541138
Batch 55/64 loss: 1.7378923892974854
Batch 56/64 loss: 1.7308766841888428
Batch 57/64 loss: 1.728236436843872
Batch 58/64 loss: 1.726816177368164
Batch 59/64 loss: 1.7291615009307861
Batch 60/64 loss: 1.7265852689743042
Batch 61/64 loss: 1.7259838581085205
Batch 62/64 loss: 1.7312840223312378
Batch 63/64 loss: 1.7266793251037598
Batch 64/64 loss: 1.9051904678344727
Epoch 351  Train loss: 1.73346534242817  Val loss: 1.75009026969831
Epoch 352
-------------------------------
Batch 1/64 loss: 1.7320473194122314
Batch 2/64 loss: 1.7293719053268433
Batch 3/64 loss: 1.7271662950515747
Batch 4/64 loss: 1.7327640056610107
Batch 5/64 loss: 1.7280099391937256
Batch 6/64 loss: 1.733206033706665
Batch 7/64 loss: 1.7314386367797852
Batch 8/64 loss: 1.734426736831665
Batch 9/64 loss: 1.7302207946777344
Batch 10/64 loss: 1.7345104217529297
Batch 11/64 loss: 1.7357306480407715
Batch 12/64 loss: 1.7321877479553223
Batch 13/64 loss: 1.7321709394454956
Batch 14/64 loss: 1.7383325099945068
Batch 15/64 loss: 1.730182409286499
Batch 16/64 loss: 1.7324879169464111
Batch 17/64 loss: 1.7376165390014648
Batch 18/64 loss: 1.7342146635055542
Batch 19/64 loss: 1.7279692888259888
Batch 20/64 loss: 1.7327221632003784
Batch 21/64 loss: 1.733137845993042
Batch 22/64 loss: 1.730837106704712
Batch 23/64 loss: 1.7305922508239746
Batch 24/64 loss: 1.7479016780853271
Batch 25/64 loss: 1.7296843528747559
Batch 26/64 loss: 1.7328920364379883
Batch 27/64 loss: 1.731616497039795
Batch 28/64 loss: 1.7298574447631836
Batch 29/64 loss: 1.7301220893859863
Batch 30/64 loss: 1.728811264038086
Batch 31/64 loss: 1.7328839302062988
Batch 32/64 loss: 1.728908896446228
Batch 33/64 loss: 1.7282209396362305
Batch 34/64 loss: 1.7281266450881958
Batch 35/64 loss: 1.7296916246414185
Batch 36/64 loss: 1.7287012338638306
Batch 37/64 loss: 1.7395212650299072
Batch 38/64 loss: 1.7312778234481812
Batch 39/64 loss: 1.7297612428665161
Batch 40/64 loss: 1.7279868125915527
Batch 41/64 loss: 1.7298994064331055
Batch 42/64 loss: 1.7292627096176147
Batch 43/64 loss: 1.7469518184661865
Batch 44/64 loss: 1.7327256202697754
Batch 45/64 loss: 1.7311937808990479
Batch 46/64 loss: 1.7297184467315674
Batch 47/64 loss: 1.7309834957122803
Batch 48/64 loss: 1.7309215068817139
Batch 49/64 loss: 1.7314465045928955
Batch 50/64 loss: 1.7268493175506592
Batch 51/64 loss: 1.7318980693817139
Batch 52/64 loss: 1.7308571338653564
Batch 53/64 loss: 1.730772852897644
Batch 54/64 loss: 1.734067678451538
Batch 55/64 loss: 1.7443947792053223
Batch 56/64 loss: 1.730172038078308
Batch 57/64 loss: 1.734503984451294
Batch 58/64 loss: 1.7312588691711426
Batch 59/64 loss: 1.7269338369369507
Batch 60/64 loss: 1.728521466255188
Batch 61/64 loss: 1.7336505651474
Batch 62/64 loss: 1.7253986597061157
Batch 63/64 loss: 1.7501842975616455
Batch 64/64 loss: 1.9110095500946045
Epoch 352  Train loss: 1.7343236689474069  Val loss: 1.7515626838526774
Epoch 353
-------------------------------
Batch 1/64 loss: 1.7312124967575073
Batch 2/64 loss: 1.7312767505645752
Batch 3/64 loss: 1.7317863702774048
Batch 4/64 loss: 1.7322101593017578
Batch 5/64 loss: 1.7314608097076416
Batch 6/64 loss: 1.731325626373291
Batch 7/64 loss: 1.7331862449645996
Batch 8/64 loss: 1.7278047800064087
Batch 9/64 loss: 1.7309942245483398
Batch 10/64 loss: 1.731305480003357
Batch 11/64 loss: 1.728926420211792
Batch 12/64 loss: 1.728722095489502
Batch 13/64 loss: 1.7331459522247314
Batch 14/64 loss: 1.7291510105133057
Batch 15/64 loss: 1.7385027408599854
Batch 16/64 loss: 1.7299389839172363
Batch 17/64 loss: 1.7270358800888062
Batch 18/64 loss: 1.7332258224487305
Batch 19/64 loss: 1.7279717922210693
Batch 20/64 loss: 1.7355213165283203
Batch 21/64 loss: 1.7263203859329224
Batch 22/64 loss: 1.7308695316314697
Batch 23/64 loss: 1.7253468036651611
Batch 24/64 loss: 1.7258098125457764
Batch 25/64 loss: 1.7293992042541504
Batch 26/64 loss: 1.7316457033157349
Batch 27/64 loss: 1.7295372486114502
Batch 28/64 loss: 1.7440561056137085
Batch 29/64 loss: 1.7281835079193115
Batch 30/64 loss: 1.7262229919433594
Batch 31/64 loss: 1.7293574810028076
Batch 32/64 loss: 1.7307853698730469
Batch 33/64 loss: 1.7270921468734741
Batch 34/64 loss: 1.7298834323883057
Batch 35/64 loss: 1.7303833961486816
Batch 36/64 loss: 1.7452433109283447
Batch 37/64 loss: 1.726555347442627
Batch 38/64 loss: 1.7278857231140137
Batch 39/64 loss: 1.727413535118103
Batch 40/64 loss: 1.7269502878189087
Batch 41/64 loss: 1.725898265838623
Batch 42/64 loss: 1.7351088523864746
Batch 43/64 loss: 1.7273162603378296
Batch 44/64 loss: 1.7284281253814697
Batch 45/64 loss: 1.7379372119903564
Batch 46/64 loss: 1.7293200492858887
Batch 47/64 loss: 1.7313554286956787
Batch 48/64 loss: 1.7287983894348145
Batch 49/64 loss: 1.7283437252044678
Batch 50/64 loss: 1.72904372215271
Batch 51/64 loss: 1.7271966934204102
Batch 52/64 loss: 1.7343230247497559
Batch 53/64 loss: 1.730573058128357
Batch 54/64 loss: 1.7335162162780762
Batch 55/64 loss: 1.7307629585266113
Batch 56/64 loss: 1.7311515808105469
Batch 57/64 loss: 1.727551817893982
Batch 58/64 loss: 1.729026198387146
Batch 59/64 loss: 1.7316725254058838
Batch 60/64 loss: 1.743177890777588
Batch 61/64 loss: 1.7358534336090088
Batch 62/64 loss: 1.7291531562805176
Batch 63/64 loss: 1.7328517436981201
Batch 64/64 loss: 1.9152469635009766
Epoch 353  Train loss: 1.7329951660305847  Val loss: 1.7500951937383802
Epoch 354
-------------------------------
Batch 1/64 loss: 1.7265427112579346
Batch 2/64 loss: 1.734431505203247
Batch 3/64 loss: 1.7357635498046875
Batch 4/64 loss: 1.7280620336532593
Batch 5/64 loss: 1.737511157989502
Batch 6/64 loss: 1.7437000274658203
Batch 7/64 loss: 1.7326359748840332
Batch 8/64 loss: 1.7352250814437866
Batch 9/64 loss: 1.7311375141143799
Batch 10/64 loss: 1.7298061847686768
Batch 11/64 loss: 1.7300961017608643
Batch 12/64 loss: 1.7277593612670898
Batch 13/64 loss: 1.7307955026626587
Batch 14/64 loss: 1.7283296585083008
Batch 15/64 loss: 1.7285797595977783
Batch 16/64 loss: 1.7307647466659546
Batch 17/64 loss: 1.7287657260894775
Batch 18/64 loss: 1.731586217880249
Batch 19/64 loss: 1.7298812866210938
Batch 20/64 loss: 1.7291018962860107
Batch 21/64 loss: 1.7301493883132935
Batch 22/64 loss: 1.730900526046753
Batch 23/64 loss: 1.7270519733428955
Batch 24/64 loss: 1.7296710014343262
Batch 25/64 loss: 1.7290271520614624
Batch 26/64 loss: 1.7336894273757935
Batch 27/64 loss: 1.7617340087890625
Batch 28/64 loss: 1.7313275337219238
Batch 29/64 loss: 1.730476975440979
Batch 30/64 loss: 1.7411258220672607
Batch 31/64 loss: 1.7272512912750244
Batch 32/64 loss: 1.7301082611083984
Batch 33/64 loss: 1.7364897727966309
Batch 34/64 loss: 1.7315773963928223
Batch 35/64 loss: 1.7310476303100586
Batch 36/64 loss: 1.7301557064056396
Batch 37/64 loss: 1.7332792282104492
Batch 38/64 loss: 1.731641411781311
Batch 39/64 loss: 1.7297793626785278
Batch 40/64 loss: 1.7307761907577515
Batch 41/64 loss: 1.7386561632156372
Batch 42/64 loss: 1.7338767051696777
Batch 43/64 loss: 1.7333024740219116
Batch 44/64 loss: 1.7351590394973755
Batch 45/64 loss: 1.736086368560791
Batch 46/64 loss: 1.7396905422210693
Batch 47/64 loss: 1.7303314208984375
Batch 48/64 loss: 1.7332282066345215
Batch 49/64 loss: 1.7373627424240112
Batch 50/64 loss: 1.7338930368423462
Batch 51/64 loss: 1.7316876649856567
Batch 52/64 loss: 1.732914924621582
Batch 53/64 loss: 1.7337113618850708
Batch 54/64 loss: 1.7315611839294434
Batch 55/64 loss: 1.7330491542816162
Batch 56/64 loss: 1.7323572635650635
Batch 57/64 loss: 1.7334129810333252
Batch 58/64 loss: 1.730133056640625
Batch 59/64 loss: 1.7408043146133423
Batch 60/64 loss: 1.726517677307129
Batch 61/64 loss: 1.7321053743362427
Batch 62/64 loss: 1.7474725246429443
Batch 63/64 loss: 1.7310359477996826
Batch 64/64 loss: 1.9124810695648193
Epoch 354  Train loss: 1.735065835129981  Val loss: 1.7484184138963312
Epoch 355
-------------------------------
Batch 1/64 loss: 1.7513141632080078
Batch 2/64 loss: 1.733991265296936
Batch 3/64 loss: 1.7271091938018799
Batch 4/64 loss: 1.7310879230499268
Batch 5/64 loss: 1.7365492582321167
Batch 6/64 loss: 1.7301673889160156
Batch 7/64 loss: 1.7301619052886963
Batch 8/64 loss: 1.7277719974517822
Batch 9/64 loss: 1.7289175987243652
Batch 10/64 loss: 1.7318055629730225
Batch 11/64 loss: 1.7302510738372803
Batch 12/64 loss: 1.7301466464996338
Batch 13/64 loss: 1.7296758890151978
Batch 14/64 loss: 1.7280919551849365
Batch 15/64 loss: 1.7354375123977661
Batch 16/64 loss: 1.7330820560455322
Batch 17/64 loss: 1.7273077964782715
Batch 18/64 loss: 1.7276794910430908
Batch 19/64 loss: 1.7305009365081787
Batch 20/64 loss: 1.7318192720413208
Batch 21/64 loss: 1.7320995330810547
Batch 22/64 loss: 1.727622628211975
Batch 23/64 loss: 1.7276606559753418
Batch 24/64 loss: 1.735503077507019
Batch 25/64 loss: 1.7306548357009888
Batch 26/64 loss: 1.7289949655532837
Batch 27/64 loss: 1.730602741241455
Batch 28/64 loss: 1.7306408882141113
Batch 29/64 loss: 1.7325350046157837
Batch 30/64 loss: 1.7330658435821533
Batch 31/64 loss: 1.7263264656066895
Batch 32/64 loss: 1.7304710149765015
Batch 33/64 loss: 1.7312259674072266
Batch 34/64 loss: 1.729339599609375
Batch 35/64 loss: 1.735419750213623
Batch 36/64 loss: 1.7299518585205078
Batch 37/64 loss: 1.732131004333496
Batch 38/64 loss: 1.7286288738250732
Batch 39/64 loss: 1.7295918464660645
Batch 40/64 loss: 1.728417158126831
Batch 41/64 loss: 1.728705883026123
Batch 42/64 loss: 1.7259759902954102
Batch 43/64 loss: 1.7266712188720703
Batch 44/64 loss: 1.7338032722473145
Batch 45/64 loss: 1.7280317544937134
Batch 46/64 loss: 1.7333426475524902
Batch 47/64 loss: 1.7268675565719604
Batch 48/64 loss: 1.7286828756332397
Batch 49/64 loss: 1.7426964044570923
Batch 50/64 loss: 1.7279199361801147
Batch 51/64 loss: 1.7299301624298096
Batch 52/64 loss: 1.7314579486846924
Batch 53/64 loss: 1.72899329662323
Batch 54/64 loss: 1.7265233993530273
Batch 55/64 loss: 1.7313207387924194
Batch 56/64 loss: 1.7291836738586426
Batch 57/64 loss: 1.729809045791626
Batch 58/64 loss: 1.729207992553711
Batch 59/64 loss: 1.7304596900939941
Batch 60/64 loss: 1.7263872623443604
Batch 61/64 loss: 1.7305610179901123
Batch 62/64 loss: 1.7292425632476807
Batch 63/64 loss: 1.7288479804992676
Batch 64/64 loss: 1.929183006286621
Epoch 355  Train loss: 1.7329452888638366  Val loss: 1.7448991606735282
Epoch 356
-------------------------------
Batch 1/64 loss: 1.7320525646209717
Batch 2/64 loss: 1.7269097566604614
Batch 3/64 loss: 1.7274447679519653
Batch 4/64 loss: 1.7285425662994385
Batch 5/64 loss: 1.7282923460006714
Batch 6/64 loss: 1.7269487380981445
Batch 7/64 loss: 1.7287638187408447
Batch 8/64 loss: 1.72724187374115
Batch 9/64 loss: 1.7287126779556274
Batch 10/64 loss: 1.7414567470550537
Batch 11/64 loss: 1.729156255722046
Batch 12/64 loss: 1.7288974523544312
Batch 13/64 loss: 1.7260634899139404
Batch 14/64 loss: 1.728324055671692
Batch 15/64 loss: 1.7308707237243652
Batch 16/64 loss: 1.7275400161743164
Batch 17/64 loss: 1.7282581329345703
Batch 18/64 loss: 1.7302738428115845
Batch 19/64 loss: 1.730393409729004
Batch 20/64 loss: 1.7293323278427124
Batch 21/64 loss: 1.731539249420166
Batch 22/64 loss: 1.7285139560699463
Batch 23/64 loss: 1.7276339530944824
Batch 24/64 loss: 1.7290011644363403
Batch 25/64 loss: 1.7281615734100342
Batch 26/64 loss: 1.72768235206604
Batch 27/64 loss: 1.7447837591171265
Batch 28/64 loss: 1.731011152267456
Batch 29/64 loss: 1.72940993309021
Batch 30/64 loss: 1.7274575233459473
Batch 31/64 loss: 1.7263593673706055
Batch 32/64 loss: 1.7274142503738403
Batch 33/64 loss: 1.729258418083191
Batch 34/64 loss: 1.7265923023223877
Batch 35/64 loss: 1.7264459133148193
Batch 36/64 loss: 1.729119062423706
Batch 37/64 loss: 1.7308504581451416
Batch 38/64 loss: 1.729553461074829
Batch 39/64 loss: 1.7305532693862915
Batch 40/64 loss: 1.7302435636520386
Batch 41/64 loss: 1.732165813446045
Batch 42/64 loss: 1.7290947437286377
Batch 43/64 loss: 1.7280378341674805
Batch 44/64 loss: 1.730516791343689
Batch 45/64 loss: 1.7304449081420898
Batch 46/64 loss: 1.7512624263763428
Batch 47/64 loss: 1.72853684425354
Batch 48/64 loss: 1.7318236827850342
Batch 49/64 loss: 1.7284951210021973
Batch 50/64 loss: 1.726611614227295
Batch 51/64 loss: 1.7280129194259644
Batch 52/64 loss: 1.7291557788848877
Batch 53/64 loss: 1.727691888809204
Batch 54/64 loss: 1.7262521982192993
Batch 55/64 loss: 1.7279911041259766
Batch 56/64 loss: 1.729193925857544
Batch 57/64 loss: 1.7275079488754272
Batch 58/64 loss: 1.7240077257156372
Batch 59/64 loss: 1.7269550561904907
Batch 60/64 loss: 1.7270264625549316
Batch 61/64 loss: 1.727993369102478
Batch 62/64 loss: 1.7302794456481934
Batch 63/64 loss: 1.7275874614715576
Batch 64/64 loss: 1.9183417558670044
Epoch 356  Train loss: 1.7316464569054397  Val loss: 1.7446585250474334
Epoch 357
-------------------------------
Batch 1/64 loss: 1.7310343980789185
Batch 2/64 loss: 1.726056694984436
Batch 3/64 loss: 1.725644588470459
Batch 4/64 loss: 1.7279722690582275
Batch 5/64 loss: 1.728322982788086
Batch 6/64 loss: 1.7265973091125488
Batch 7/64 loss: 1.727590560913086
Batch 8/64 loss: 1.7264928817749023
Batch 9/64 loss: 1.7283267974853516
Batch 10/64 loss: 1.7296757698059082
Batch 11/64 loss: 1.7437269687652588
Batch 12/64 loss: 1.7289330959320068
Batch 13/64 loss: 1.7264145612716675
Batch 14/64 loss: 1.7289719581604004
Batch 15/64 loss: 1.7294175624847412
Batch 16/64 loss: 1.725961685180664
Batch 17/64 loss: 1.7269837856292725
Batch 18/64 loss: 1.724708914756775
Batch 19/64 loss: 1.7276136875152588
Batch 20/64 loss: 1.7268517017364502
Batch 21/64 loss: 1.7262790203094482
Batch 22/64 loss: 1.7326936721801758
Batch 23/64 loss: 1.7271029949188232
Batch 24/64 loss: 1.7455159425735474
Batch 25/64 loss: 1.7319285869598389
Batch 26/64 loss: 1.7289912700653076
Batch 27/64 loss: 1.7269798517227173
Batch 28/64 loss: 1.7407429218292236
Batch 29/64 loss: 1.7261087894439697
Batch 30/64 loss: 1.728773832321167
Batch 31/64 loss: 1.726792812347412
Batch 32/64 loss: 1.7292208671569824
Batch 33/64 loss: 1.726957082748413
Batch 34/64 loss: 1.7287944555282593
Batch 35/64 loss: 1.7293517589569092
Batch 36/64 loss: 1.7293102741241455
Batch 37/64 loss: 1.7269647121429443
Batch 38/64 loss: 1.7308838367462158
Batch 39/64 loss: 1.734583854675293
Batch 40/64 loss: 1.7257020473480225
Batch 41/64 loss: 1.7292511463165283
Batch 42/64 loss: 1.726335883140564
Batch 43/64 loss: 1.7271578311920166
Batch 44/64 loss: 1.7284929752349854
Batch 45/64 loss: 1.725321650505066
Batch 46/64 loss: 1.7276268005371094
Batch 47/64 loss: 1.7260792255401611
Batch 48/64 loss: 1.7244744300842285
Batch 49/64 loss: 1.7312352657318115
Batch 50/64 loss: 1.726578950881958
Batch 51/64 loss: 1.7281062602996826
Batch 52/64 loss: 1.7247554063796997
Batch 53/64 loss: 1.7322652339935303
Batch 54/64 loss: 1.7358335256576538
Batch 55/64 loss: 1.7290806770324707
Batch 56/64 loss: 1.7270128726959229
Batch 57/64 loss: 1.7274982929229736
Batch 58/64 loss: 1.7252845764160156
Batch 59/64 loss: 1.7281825542449951
Batch 60/64 loss: 1.7279901504516602
Batch 61/64 loss: 1.725888967514038
Batch 62/64 loss: 1.728212594985962
Batch 63/64 loss: 1.7346237897872925
Batch 64/64 loss: 1.9091603755950928
Epoch 357  Train loss: 1.7309825270783668  Val loss: 1.7462138097310804
Epoch 358
-------------------------------
Batch 1/64 loss: 1.732975721359253
Batch 2/64 loss: 1.7258033752441406
Batch 3/64 loss: 1.72906494140625
Batch 4/64 loss: 1.7277286052703857
Batch 5/64 loss: 1.7291486263275146
Batch 6/64 loss: 1.7273081541061401
Batch 7/64 loss: 1.7300008535385132
Batch 8/64 loss: 1.7302169799804688
Batch 9/64 loss: 1.7306700944900513
Batch 10/64 loss: 1.748823642730713
Batch 11/64 loss: 1.731933355331421
Batch 12/64 loss: 1.734554648399353
Batch 13/64 loss: 1.7312039136886597
Batch 14/64 loss: 1.7302093505859375
Batch 15/64 loss: 1.7332946062088013
Batch 16/64 loss: 1.729917287826538
Batch 17/64 loss: 1.726593255996704
Batch 18/64 loss: 1.733826756477356
Batch 19/64 loss: 1.7286031246185303
Batch 20/64 loss: 1.7292330265045166
Batch 21/64 loss: 1.7293881177902222
Batch 22/64 loss: 1.7284610271453857
Batch 23/64 loss: 1.7290241718292236
Batch 24/64 loss: 1.7337056398391724
Batch 25/64 loss: 1.7253837585449219
Batch 26/64 loss: 1.7277522087097168
Batch 27/64 loss: 1.729032039642334
Batch 28/64 loss: 1.7288792133331299
Batch 29/64 loss: 1.7282147407531738
Batch 30/64 loss: 1.7267436981201172
Batch 31/64 loss: 1.7322124242782593
Batch 32/64 loss: 1.7252830266952515
Batch 33/64 loss: 1.729771614074707
Batch 34/64 loss: 1.7252578735351562
Batch 35/64 loss: 1.726450800895691
Batch 36/64 loss: 1.7248811721801758
Batch 37/64 loss: 1.725520372390747
Batch 38/64 loss: 1.727015495300293
Batch 39/64 loss: 1.7263604402542114
Batch 40/64 loss: 1.724894642829895
Batch 41/64 loss: 1.7272944450378418
Batch 42/64 loss: 1.7321140766143799
Batch 43/64 loss: 1.7251843214035034
Batch 44/64 loss: 1.7256076335906982
Batch 45/64 loss: 1.7396560907363892
Batch 46/64 loss: 1.7268164157867432
Batch 47/64 loss: 1.7258412837982178
Batch 48/64 loss: 1.7248036861419678
Batch 49/64 loss: 1.7280685901641846
Batch 50/64 loss: 1.7340428829193115
Batch 51/64 loss: 1.7253873348236084
Batch 52/64 loss: 1.7272398471832275
Batch 53/64 loss: 1.7255852222442627
Batch 54/64 loss: 1.7260875701904297
Batch 55/64 loss: 1.725661039352417
Batch 56/64 loss: 1.7284494638442993
Batch 57/64 loss: 1.7280330657958984
Batch 58/64 loss: 1.7279894351959229
Batch 59/64 loss: 1.7250652313232422
Batch 60/64 loss: 1.724951982498169
Batch 61/64 loss: 1.7454917430877686
Batch 62/64 loss: 1.7271053791046143
Batch 63/64 loss: 1.7249836921691895
Batch 64/64 loss: 1.9096040725708008
Epoch 358  Train loss: 1.7311216672261556  Val loss: 1.7431798194282244
Saving best model, epoch: 358
Epoch 359
-------------------------------
Batch 1/64 loss: 1.7274138927459717
Batch 2/64 loss: 1.7331302165985107
Batch 3/64 loss: 1.7404191493988037
Batch 4/64 loss: 1.7264453172683716
Batch 5/64 loss: 1.7278116941452026
Batch 6/64 loss: 1.7268481254577637
Batch 7/64 loss: 1.7268985509872437
Batch 8/64 loss: 1.7306305170059204
Batch 9/64 loss: 1.7267463207244873
Batch 10/64 loss: 1.729036569595337
Batch 11/64 loss: 1.7280374765396118
Batch 12/64 loss: 1.729478120803833
Batch 13/64 loss: 1.724916934967041
Batch 14/64 loss: 1.726776123046875
Batch 15/64 loss: 1.728689432144165
Batch 16/64 loss: 1.7266523838043213
Batch 17/64 loss: 1.7308259010314941
Batch 18/64 loss: 1.7294058799743652
Batch 19/64 loss: 1.729230284690857
Batch 20/64 loss: 1.729297161102295
Batch 21/64 loss: 1.7278120517730713
Batch 22/64 loss: 1.725944995880127
Batch 23/64 loss: 1.7262866497039795
Batch 24/64 loss: 1.731480598449707
Batch 25/64 loss: 1.7251036167144775
Batch 26/64 loss: 1.7268160581588745
Batch 27/64 loss: 1.7290983200073242
Batch 28/64 loss: 1.7296712398529053
Batch 29/64 loss: 1.7275364398956299
Batch 30/64 loss: 1.727489709854126
Batch 31/64 loss: 1.7315971851348877
Batch 32/64 loss: 1.7474098205566406
Batch 33/64 loss: 1.727541208267212
Batch 34/64 loss: 1.7272365093231201
Batch 35/64 loss: 1.728761911392212
Batch 36/64 loss: 1.731867790222168
Batch 37/64 loss: 1.7267991304397583
Batch 38/64 loss: 1.7264103889465332
Batch 39/64 loss: 1.7424652576446533
Batch 40/64 loss: 1.7274720668792725
Batch 41/64 loss: 1.7304385900497437
Batch 42/64 loss: 1.7321140766143799
Batch 43/64 loss: 1.7297041416168213
Batch 44/64 loss: 1.7267156839370728
Batch 45/64 loss: 1.736083984375
Batch 46/64 loss: 1.7275701761245728
Batch 47/64 loss: 1.7262732982635498
Batch 48/64 loss: 1.729898452758789
Batch 49/64 loss: 1.728412389755249
Batch 50/64 loss: 1.7279863357543945
Batch 51/64 loss: 1.7262327671051025
Batch 52/64 loss: 1.7294039726257324
Batch 53/64 loss: 1.7300662994384766
Batch 54/64 loss: 1.730794906616211
Batch 55/64 loss: 1.7281001806259155
Batch 56/64 loss: 1.728442907333374
Batch 57/64 loss: 1.7267264127731323
Batch 58/64 loss: 1.7286434173583984
Batch 59/64 loss: 1.731433629989624
Batch 60/64 loss: 1.7291406393051147
Batch 61/64 loss: 1.727715253829956
Batch 62/64 loss: 1.72412109375
Batch 63/64 loss: 1.7310069799423218
Batch 64/64 loss: 1.910618543624878
Epoch 359  Train loss: 1.7313487137065213  Val loss: 1.7465745394991845
Epoch 360
-------------------------------
Batch 1/64 loss: 1.7262754440307617
Batch 2/64 loss: 1.7319512367248535
Batch 3/64 loss: 1.731036901473999
Batch 4/64 loss: 1.7291007041931152
Batch 5/64 loss: 1.730745792388916
Batch 6/64 loss: 1.728359341621399
Batch 7/64 loss: 1.7365288734436035
Batch 8/64 loss: 1.7291280031204224
Batch 9/64 loss: 1.7280755043029785
Batch 10/64 loss: 1.7283555269241333
Batch 11/64 loss: 1.7298402786254883
Batch 12/64 loss: 1.7295931577682495
Batch 13/64 loss: 1.737236499786377
Batch 14/64 loss: 1.730616569519043
Batch 15/64 loss: 1.7307144403457642
Batch 16/64 loss: 1.7248270511627197
Batch 17/64 loss: 1.728686809539795
Batch 18/64 loss: 1.727295160293579
Batch 19/64 loss: 1.7280486822128296
Batch 20/64 loss: 1.7465083599090576
Batch 21/64 loss: 1.7297015190124512
Batch 22/64 loss: 1.7280985116958618
Batch 23/64 loss: 1.7379975318908691
Batch 24/64 loss: 1.7291343212127686
Batch 25/64 loss: 1.731682538986206
Batch 26/64 loss: 1.730109691619873
Batch 27/64 loss: 1.7319366931915283
Batch 28/64 loss: 1.7281999588012695
Batch 29/64 loss: 1.7324007749557495
Batch 30/64 loss: 1.7330029010772705
Batch 31/64 loss: 1.7268478870391846
Batch 32/64 loss: 1.748450517654419
Batch 33/64 loss: 1.7272820472717285
Batch 34/64 loss: 1.7295615673065186
Batch 35/64 loss: 1.7279300689697266
Batch 36/64 loss: 1.7283828258514404
Batch 37/64 loss: 1.7257282733917236
Batch 38/64 loss: 1.7438015937805176
Batch 39/64 loss: 1.730682373046875
Batch 40/64 loss: 1.7285895347595215
Batch 41/64 loss: 1.7289350032806396
Batch 42/64 loss: 1.7269444465637207
Batch 43/64 loss: 1.72991144657135
Batch 44/64 loss: 1.7363646030426025
Batch 45/64 loss: 1.7351384162902832
Batch 46/64 loss: 1.727709412574768
Batch 47/64 loss: 1.7302649021148682
Batch 48/64 loss: 1.7252488136291504
Batch 49/64 loss: 1.7274523973464966
Batch 50/64 loss: 1.7278780937194824
Batch 51/64 loss: 1.7276479005813599
Batch 52/64 loss: 1.725657343864441
Batch 53/64 loss: 1.7289350032806396
Batch 54/64 loss: 1.7297266721725464
Batch 55/64 loss: 1.7289013862609863
Batch 56/64 loss: 1.729292869567871
Batch 57/64 loss: 1.7297130823135376
Batch 58/64 loss: 1.7264388799667358
Batch 59/64 loss: 1.7270147800445557
Batch 60/64 loss: 1.727898120880127
Batch 61/64 loss: 1.726158857345581
Batch 62/64 loss: 1.7266740798950195
Batch 63/64 loss: 1.7265024185180664
Batch 64/64 loss: 1.9046502113342285
Epoch 360  Train loss: 1.7321936008976955  Val loss: 1.745953761425215
Epoch 361
-------------------------------
Batch 1/64 loss: 1.7264363765716553
Batch 2/64 loss: 1.728847622871399
Batch 3/64 loss: 1.7265233993530273
Batch 4/64 loss: 1.7397971153259277
Batch 5/64 loss: 1.7265264987945557
Batch 6/64 loss: 1.7255678176879883
Batch 7/64 loss: 1.7271728515625
Batch 8/64 loss: 1.7283995151519775
Batch 9/64 loss: 1.7272456884384155
Batch 10/64 loss: 1.7255239486694336
Batch 11/64 loss: 1.7271337509155273
Batch 12/64 loss: 1.7280511856079102
Batch 13/64 loss: 1.7245771884918213
Batch 14/64 loss: 1.7235054969787598
Batch 15/64 loss: 1.7256114482879639
Batch 16/64 loss: 1.7461609840393066
Batch 17/64 loss: 1.7265323400497437
Batch 18/64 loss: 1.7284412384033203
Batch 19/64 loss: 1.7301182746887207
Batch 20/64 loss: 1.7315576076507568
Batch 21/64 loss: 1.727099061012268
Batch 22/64 loss: 1.7264323234558105
Batch 23/64 loss: 1.7283951044082642
Batch 24/64 loss: 1.7312147617340088
Batch 25/64 loss: 1.7269973754882812
Batch 26/64 loss: 1.7251238822937012
Batch 27/64 loss: 1.7311007976531982
Batch 28/64 loss: 1.726112723350525
Batch 29/64 loss: 1.7264097929000854
Batch 30/64 loss: 1.7241992950439453
Batch 31/64 loss: 1.7275724411010742
Batch 32/64 loss: 1.7277851104736328
Batch 33/64 loss: 1.7264946699142456
Batch 34/64 loss: 1.7266170978546143
Batch 35/64 loss: 1.7282600402832031
Batch 36/64 loss: 1.7254302501678467
Batch 37/64 loss: 1.748600959777832
Batch 38/64 loss: 1.7321486473083496
Batch 39/64 loss: 1.727471113204956
Batch 40/64 loss: 1.7276735305786133
Batch 41/64 loss: 1.7294665575027466
Batch 42/64 loss: 1.724327802658081
Batch 43/64 loss: 1.7249257564544678
Batch 44/64 loss: 1.7266876697540283
Batch 45/64 loss: 1.728398084640503
Batch 46/64 loss: 1.7263529300689697
Batch 47/64 loss: 1.727109432220459
Batch 48/64 loss: 1.724785327911377
Batch 49/64 loss: 1.7274503707885742
Batch 50/64 loss: 1.7310469150543213
Batch 51/64 loss: 1.7272298336029053
Batch 52/64 loss: 1.7302289009094238
Batch 53/64 loss: 1.7272815704345703
Batch 54/64 loss: 1.7391705513000488
Batch 55/64 loss: 1.7276486158370972
Batch 56/64 loss: 1.7271392345428467
Batch 57/64 loss: 1.7370073795318604
Batch 58/64 loss: 1.7284507751464844
Batch 59/64 loss: 1.7309496402740479
Batch 60/64 loss: 1.7268503904342651
Batch 61/64 loss: 1.730835199356079
Batch 62/64 loss: 1.7274974584579468
Batch 63/64 loss: 1.7294080257415771
Batch 64/64 loss: 1.9076026678085327
Epoch 361  Train loss: 1.7307579568788116  Val loss: 1.7441465207391589
Epoch 362
-------------------------------
Batch 1/64 loss: 1.7302799224853516
Batch 2/64 loss: 1.7297899723052979
Batch 3/64 loss: 1.727902889251709
Batch 4/64 loss: 1.729738712310791
Batch 5/64 loss: 1.7280833721160889
Batch 6/64 loss: 1.7334444522857666
Batch 7/64 loss: 1.726194977760315
Batch 8/64 loss: 1.7266393899917603
Batch 9/64 loss: 1.7285664081573486
Batch 10/64 loss: 1.7278542518615723
Batch 11/64 loss: 1.7287349700927734
Batch 12/64 loss: 1.7327885627746582
Batch 13/64 loss: 1.7332744598388672
Batch 14/64 loss: 1.7310001850128174
Batch 15/64 loss: 1.7321687936782837
Batch 16/64 loss: 1.7290022373199463
Batch 17/64 loss: 1.727808952331543
Batch 18/64 loss: 1.7264041900634766
Batch 19/64 loss: 1.7294353246688843
Batch 20/64 loss: 1.7285456657409668
Batch 21/64 loss: 1.7260243892669678
Batch 22/64 loss: 1.7284387350082397
Batch 23/64 loss: 1.7277231216430664
Batch 24/64 loss: 1.7256910800933838
Batch 25/64 loss: 1.7280598878860474
Batch 26/64 loss: 1.7260663509368896
Batch 27/64 loss: 1.7259595394134521
Batch 28/64 loss: 1.742997646331787
Batch 29/64 loss: 1.726334810256958
Batch 30/64 loss: 1.727986454963684
Batch 31/64 loss: 1.7269260883331299
Batch 32/64 loss: 1.7258665561676025
Batch 33/64 loss: 1.726260781288147
Batch 34/64 loss: 1.726654052734375
Batch 35/64 loss: 1.726812481880188
Batch 36/64 loss: 1.7290689945220947
Batch 37/64 loss: 1.724642038345337
Batch 38/64 loss: 1.7252256870269775
Batch 39/64 loss: 1.7273600101470947
Batch 40/64 loss: 1.726177453994751
Batch 41/64 loss: 1.7275915145874023
Batch 42/64 loss: 1.7273105382919312
Batch 43/64 loss: 1.7313768863677979
Batch 44/64 loss: 1.7254939079284668
Batch 45/64 loss: 1.7255932092666626
Batch 46/64 loss: 1.726097583770752
Batch 47/64 loss: 1.7247958183288574
Batch 48/64 loss: 1.7303473949432373
Batch 49/64 loss: 1.723560094833374
Batch 50/64 loss: 1.7262426614761353
Batch 51/64 loss: 1.726662039756775
Batch 52/64 loss: 1.728954553604126
Batch 53/64 loss: 1.7457525730133057
Batch 54/64 loss: 1.728609561920166
Batch 55/64 loss: 1.7277252674102783
Batch 56/64 loss: 1.728734016418457
Batch 57/64 loss: 1.7341266870498657
Batch 58/64 loss: 1.7271013259887695
Batch 59/64 loss: 1.7301819324493408
Batch 60/64 loss: 1.7473344802856445
Batch 61/64 loss: 1.7274247407913208
Batch 62/64 loss: 1.7283344268798828
Batch 63/64 loss: 1.7366442680358887
Batch 64/64 loss: 1.9130454063415527
Epoch 362  Train loss: 1.7311170727598901  Val loss: 1.7474111478353285
Epoch 363
-------------------------------
Batch 1/64 loss: 1.7268202304840088
Batch 2/64 loss: 1.7285922765731812
Batch 3/64 loss: 1.730140209197998
Batch 4/64 loss: 1.7291817665100098
Batch 5/64 loss: 1.7331759929656982
Batch 6/64 loss: 1.727705955505371
Batch 7/64 loss: 1.7285460233688354
Batch 8/64 loss: 1.7303447723388672
Batch 9/64 loss: 1.7284117937088013
Batch 10/64 loss: 1.7300145626068115
Batch 11/64 loss: 1.7269737720489502
Batch 12/64 loss: 1.7282297611236572
Batch 13/64 loss: 1.7340410947799683
Batch 14/64 loss: 1.728847622871399
Batch 15/64 loss: 1.733116626739502
Batch 16/64 loss: 1.7261463403701782
Batch 17/64 loss: 1.7278211116790771
Batch 18/64 loss: 1.7254986763000488
Batch 19/64 loss: 1.7374882698059082
Batch 20/64 loss: 1.7277108430862427
Batch 21/64 loss: 1.7284904718399048
Batch 22/64 loss: 1.7254765033721924
Batch 23/64 loss: 1.728589653968811
Batch 24/64 loss: 1.727168083190918
Batch 25/64 loss: 1.7301294803619385
Batch 26/64 loss: 1.728682041168213
Batch 27/64 loss: 1.7297123670578003
Batch 28/64 loss: 1.731210470199585
Batch 29/64 loss: 1.743679165840149
Batch 30/64 loss: 1.732154130935669
Batch 31/64 loss: 1.7348475456237793
Batch 32/64 loss: 1.7273178100585938
Batch 33/64 loss: 1.734349250793457
Batch 34/64 loss: 1.7291755676269531
Batch 35/64 loss: 1.7308322191238403
Batch 36/64 loss: 1.7303061485290527
Batch 37/64 loss: 1.729369878768921
Batch 38/64 loss: 1.7314339876174927
Batch 39/64 loss: 1.7304987907409668
Batch 40/64 loss: 1.7266266345977783
Batch 41/64 loss: 1.7285704612731934
Batch 42/64 loss: 1.7260653972625732
Batch 43/64 loss: 1.7414494752883911
Batch 44/64 loss: 1.7301955223083496
Batch 45/64 loss: 1.7280992269515991
Batch 46/64 loss: 1.7443046569824219
Batch 47/64 loss: 1.7276980876922607
Batch 48/64 loss: 1.7254003286361694
Batch 49/64 loss: 1.726714849472046
Batch 50/64 loss: 1.727036952972412
Batch 51/64 loss: 1.7246230840682983
Batch 52/64 loss: 1.7268638610839844
Batch 53/64 loss: 1.7262340784072876
Batch 54/64 loss: 1.7265896797180176
Batch 55/64 loss: 1.7268226146697998
Batch 56/64 loss: 1.726535439491272
Batch 57/64 loss: 1.7264623641967773
Batch 58/64 loss: 1.7282358407974243
Batch 59/64 loss: 1.726069688796997
Batch 60/64 loss: 1.72847580909729
Batch 61/64 loss: 1.728215217590332
Batch 62/64 loss: 1.7268400192260742
Batch 63/64 loss: 1.7277560234069824
Batch 64/64 loss: 1.9137232303619385
Epoch 363  Train loss: 1.7315985726375205  Val loss: 1.7454894908105385
Epoch 364
-------------------------------
Batch 1/64 loss: 1.7311582565307617
Batch 2/64 loss: 1.7287559509277344
Batch 3/64 loss: 1.7292351722717285
Batch 4/64 loss: 1.7324657440185547
Batch 5/64 loss: 1.729055643081665
Batch 6/64 loss: 1.728013038635254
Batch 7/64 loss: 1.7266511917114258
Batch 8/64 loss: 1.7331889867782593
Batch 9/64 loss: 1.7301137447357178
Batch 10/64 loss: 1.7302449941635132
Batch 11/64 loss: 1.7291051149368286
Batch 12/64 loss: 1.724863886833191
Batch 13/64 loss: 1.7310954332351685
Batch 14/64 loss: 1.7256169319152832
Batch 15/64 loss: 1.7277252674102783
Batch 16/64 loss: 1.7274625301361084
Batch 17/64 loss: 1.7393012046813965
Batch 18/64 loss: 1.7274755239486694
Batch 19/64 loss: 1.7272666692733765
Batch 20/64 loss: 1.7268621921539307
Batch 21/64 loss: 1.723719596862793
Batch 22/64 loss: 1.7279115915298462
Batch 23/64 loss: 1.7294385433197021
Batch 24/64 loss: 1.7496877908706665
Batch 25/64 loss: 1.7260260581970215
Batch 26/64 loss: 1.7290536165237427
Batch 27/64 loss: 1.7278037071228027
Batch 28/64 loss: 1.7260043621063232
Batch 29/64 loss: 1.7290616035461426
Batch 30/64 loss: 1.7283031940460205
Batch 31/64 loss: 1.7322008609771729
Batch 32/64 loss: 1.725433349609375
Batch 33/64 loss: 1.727036476135254
Batch 34/64 loss: 1.724808931350708
Batch 35/64 loss: 1.7308355569839478
Batch 36/64 loss: 1.7265334129333496
Batch 37/64 loss: 1.727173089981079
Batch 38/64 loss: 1.73102605342865
Batch 39/64 loss: 1.7281463146209717
Batch 40/64 loss: 1.7321786880493164
Batch 41/64 loss: 1.728926420211792
Batch 42/64 loss: 1.7241421937942505
Batch 43/64 loss: 1.7409858703613281
Batch 44/64 loss: 1.7268941402435303
Batch 45/64 loss: 1.7272980213165283
Batch 46/64 loss: 1.72979736328125
Batch 47/64 loss: 1.7306969165802002
Batch 48/64 loss: 1.7307796478271484
Batch 49/64 loss: 1.7274608612060547
Batch 50/64 loss: 1.7292451858520508
Batch 51/64 loss: 1.7266809940338135
Batch 52/64 loss: 1.7272385358810425
Batch 53/64 loss: 1.7275211811065674
Batch 54/64 loss: 1.7336628437042236
Batch 55/64 loss: 1.728056788444519
Batch 56/64 loss: 1.7283039093017578
Batch 57/64 loss: 1.7283176183700562
Batch 58/64 loss: 1.7306523323059082
Batch 59/64 loss: 1.7267138957977295
Batch 60/64 loss: 1.7289271354675293
Batch 61/64 loss: 1.7283754348754883
Batch 62/64 loss: 1.728535771369934
Batch 63/64 loss: 1.7275631427764893
Batch 64/64 loss: 1.905579924583435
Epoch 364  Train loss: 1.7312000223234587  Val loss: 1.7454814943660986
Epoch 365
-------------------------------
Batch 1/64 loss: 1.7294411659240723
Batch 2/64 loss: 1.730003833770752
Batch 3/64 loss: 1.7288678884506226
Batch 4/64 loss: 1.72634756565094
Batch 5/64 loss: 1.7291996479034424
Batch 6/64 loss: 1.727942705154419
Batch 7/64 loss: 1.7292757034301758
Batch 8/64 loss: 1.7269666194915771
Batch 9/64 loss: 1.728333830833435
Batch 10/64 loss: 1.729621410369873
Batch 11/64 loss: 1.7289658784866333
Batch 12/64 loss: 1.7309823036193848
Batch 13/64 loss: 1.7297353744506836
Batch 14/64 loss: 1.7309671640396118
Batch 15/64 loss: 1.7277568578720093
Batch 16/64 loss: 1.731853723526001
Batch 17/64 loss: 1.7284094095230103
Batch 18/64 loss: 1.7283961772918701
Batch 19/64 loss: 1.7298442125320435
Batch 20/64 loss: 1.7263246774673462
Batch 21/64 loss: 1.728531002998352
Batch 22/64 loss: 1.7289001941680908
Batch 23/64 loss: 1.7303383350372314
Batch 24/64 loss: 1.7477169036865234
Batch 25/64 loss: 1.729341745376587
Batch 26/64 loss: 1.727481484413147
Batch 27/64 loss: 1.7284945249557495
Batch 28/64 loss: 1.731313943862915
Batch 29/64 loss: 1.7257742881774902
Batch 30/64 loss: 1.7295944690704346
Batch 31/64 loss: 1.7343425750732422
Batch 32/64 loss: 1.7283174991607666
Batch 33/64 loss: 1.725543737411499
Batch 34/64 loss: 1.7297227382659912
Batch 35/64 loss: 1.7305223941802979
Batch 36/64 loss: 1.7331888675689697
Batch 37/64 loss: 1.7421329021453857
Batch 38/64 loss: 1.7284116744995117
Batch 39/64 loss: 1.7257916927337646
Batch 40/64 loss: 1.7267855405807495
Batch 41/64 loss: 1.726670265197754
Batch 42/64 loss: 1.7278732061386108
Batch 43/64 loss: 1.7282871007919312
Batch 44/64 loss: 1.727766513824463
Batch 45/64 loss: 1.7318435907363892
Batch 46/64 loss: 1.7318432331085205
Batch 47/64 loss: 1.7281928062438965
Batch 48/64 loss: 1.7290639877319336
Batch 49/64 loss: 1.727811574935913
Batch 50/64 loss: 1.7299981117248535
Batch 51/64 loss: 1.7315407991409302
Batch 52/64 loss: 1.7290706634521484
Batch 53/64 loss: 1.7304692268371582
Batch 54/64 loss: 1.7326468229293823
Batch 55/64 loss: 1.7295172214508057
Batch 56/64 loss: 1.7298235893249512
Batch 57/64 loss: 1.7311630249023438
Batch 58/64 loss: 1.7299786806106567
Batch 59/64 loss: 1.7287960052490234
Batch 60/64 loss: 1.731138825416565
Batch 61/64 loss: 1.7347195148468018
Batch 62/64 loss: 1.7464290857315063
Batch 63/64 loss: 1.7337346076965332
Batch 64/64 loss: 1.9116015434265137
Epoch 365  Train loss: 1.7322911729999617  Val loss: 1.744902599308499
Epoch 366
-------------------------------
Batch 1/64 loss: 1.73060941696167
Batch 2/64 loss: 1.7288172245025635
Batch 3/64 loss: 1.7281010150909424
Batch 4/64 loss: 1.728912115097046
Batch 5/64 loss: 1.7309417724609375
Batch 6/64 loss: 1.7276346683502197
Batch 7/64 loss: 1.7365078926086426
Batch 8/64 loss: 1.7297112941741943
Batch 9/64 loss: 1.7347118854522705
Batch 10/64 loss: 1.7281239032745361
Batch 11/64 loss: 1.73331618309021
Batch 12/64 loss: 1.7278660535812378
Batch 13/64 loss: 1.754680871963501
Batch 14/64 loss: 1.730395793914795
Batch 15/64 loss: 1.7285881042480469
Batch 16/64 loss: 1.7294989824295044
Batch 17/64 loss: 1.7314636707305908
Batch 18/64 loss: 1.727653980255127
Batch 19/64 loss: 1.7292275428771973
Batch 20/64 loss: 1.7299919128417969
Batch 21/64 loss: 1.7302676439285278
Batch 22/64 loss: 1.7292916774749756
Batch 23/64 loss: 1.727297306060791
Batch 24/64 loss: 1.7298624515533447
Batch 25/64 loss: 1.7350294589996338
Batch 26/64 loss: 1.7273786067962646
Batch 27/64 loss: 1.7282087802886963
Batch 28/64 loss: 1.7273237705230713
Batch 29/64 loss: 1.731276035308838
Batch 30/64 loss: 1.731807827949524
Batch 31/64 loss: 1.7333364486694336
Batch 32/64 loss: 1.726301908493042
Batch 33/64 loss: 1.7286258935928345
Batch 34/64 loss: 1.7258979082107544
Batch 35/64 loss: 1.7280347347259521
Batch 36/64 loss: 1.7277534008026123
Batch 37/64 loss: 1.7287951707839966
Batch 38/64 loss: 1.7300825119018555
Batch 39/64 loss: 1.7277615070343018
Batch 40/64 loss: 1.7312153577804565
Batch 41/64 loss: 1.7321627140045166
Batch 42/64 loss: 1.727790355682373
Batch 43/64 loss: 1.7268476486206055
Batch 44/64 loss: 1.725820779800415
Batch 45/64 loss: 1.741814136505127
Batch 46/64 loss: 1.7319248914718628
Batch 47/64 loss: 1.7276266813278198
Batch 48/64 loss: 1.7285058498382568
Batch 49/64 loss: 1.7264879941940308
Batch 50/64 loss: 1.7298789024353027
Batch 51/64 loss: 1.7312523126602173
Batch 52/64 loss: 1.7302865982055664
Batch 53/64 loss: 1.7342352867126465
Batch 54/64 loss: 1.7290959358215332
Batch 55/64 loss: 1.7265894412994385
Batch 56/64 loss: 1.733330249786377
Batch 57/64 loss: 1.7258915901184082
Batch 58/64 loss: 1.7302207946777344
Batch 59/64 loss: 1.7420201301574707
Batch 60/64 loss: 1.7280659675598145
Batch 61/64 loss: 1.7273778915405273
Batch 62/64 loss: 1.7322020530700684
Batch 63/64 loss: 1.7283469438552856
Batch 64/64 loss: 1.9112389087677002
Epoch 366  Train loss: 1.7324471688738057  Val loss: 1.7556704401560255
Epoch 367
-------------------------------
Batch 1/64 loss: 1.7310700416564941
Batch 2/64 loss: 1.730792760848999
Batch 3/64 loss: 1.7317612171173096
Batch 4/64 loss: 1.7340630292892456
Batch 5/64 loss: 1.7324795722961426
Batch 6/64 loss: 1.729062795639038
Batch 7/64 loss: 1.7387018203735352
Batch 8/64 loss: 1.7287755012512207
Batch 9/64 loss: 1.727694034576416
Batch 10/64 loss: 1.7255206108093262
Batch 11/64 loss: 1.7277921438217163
Batch 12/64 loss: 1.7301576137542725
Batch 13/64 loss: 1.728008508682251
Batch 14/64 loss: 1.7298907041549683
Batch 15/64 loss: 1.7317698001861572
Batch 16/64 loss: 1.7297356128692627
Batch 17/64 loss: 1.7286187410354614
Batch 18/64 loss: 1.7297511100769043
Batch 19/64 loss: 1.7282155752182007
Batch 20/64 loss: 1.7266381978988647
Batch 21/64 loss: 1.7292110919952393
Batch 22/64 loss: 1.7275772094726562
Batch 23/64 loss: 1.7288317680358887
Batch 24/64 loss: 1.7269856929779053
Batch 25/64 loss: 1.727492332458496
Batch 26/64 loss: 1.7265727519989014
Batch 27/64 loss: 1.7267651557922363
Batch 28/64 loss: 1.7279280424118042
Batch 29/64 loss: 1.728994607925415
Batch 30/64 loss: 1.7260760068893433
Batch 31/64 loss: 1.7457141876220703
Batch 32/64 loss: 1.7262568473815918
Batch 33/64 loss: 1.7274709939956665
Batch 34/64 loss: 1.7290518283843994
Batch 35/64 loss: 1.7285995483398438
Batch 36/64 loss: 1.726555585861206
Batch 37/64 loss: 1.7283579111099243
Batch 38/64 loss: 1.7299113273620605
Batch 39/64 loss: 1.7299264669418335
Batch 40/64 loss: 1.7251274585723877
Batch 41/64 loss: 1.726961612701416
Batch 42/64 loss: 1.728284239768982
Batch 43/64 loss: 1.7259153127670288
Batch 44/64 loss: 1.725904107093811
Batch 45/64 loss: 1.728128433227539
Batch 46/64 loss: 1.7316780090332031
Batch 47/64 loss: 1.7287952899932861
Batch 48/64 loss: 1.728271484375
Batch 49/64 loss: 1.729853868484497
Batch 50/64 loss: 1.7288424968719482
Batch 51/64 loss: 1.7254416942596436
Batch 52/64 loss: 1.725609540939331
Batch 53/64 loss: 1.7279280424118042
Batch 54/64 loss: 1.725719690322876
Batch 55/64 loss: 1.7284133434295654
Batch 56/64 loss: 1.7322325706481934
Batch 57/64 loss: 1.7269001007080078
Batch 58/64 loss: 1.7260189056396484
Batch 59/64 loss: 1.728912591934204
Batch 60/64 loss: 1.7257193326950073
Batch 61/64 loss: 1.7302284240722656
Batch 62/64 loss: 1.7314422130584717
Batch 63/64 loss: 1.7393267154693604
Batch 64/64 loss: 1.9247291088104248
Epoch 367  Train loss: 1.7313565656250598  Val loss: 1.7441145366000146
Epoch 368
-------------------------------
Batch 1/64 loss: 1.7279596328735352
Batch 2/64 loss: 1.7293040752410889
Batch 3/64 loss: 1.7244970798492432
Batch 4/64 loss: 1.7266944646835327
Batch 5/64 loss: 1.7271108627319336
Batch 6/64 loss: 1.7289032936096191
Batch 7/64 loss: 1.7272694110870361
Batch 8/64 loss: 1.7274147272109985
Batch 9/64 loss: 1.7277021408081055
Batch 10/64 loss: 1.7311909198760986
Batch 11/64 loss: 1.7299153804779053
Batch 12/64 loss: 1.7281208038330078
Batch 13/64 loss: 1.7288670539855957
Batch 14/64 loss: 1.7260611057281494
Batch 15/64 loss: 1.7291795015335083
Batch 16/64 loss: 1.7335844039916992
Batch 17/64 loss: 1.7295200824737549
Batch 18/64 loss: 1.731247901916504
Batch 19/64 loss: 1.7297002077102661
Batch 20/64 loss: 1.7277134656906128
Batch 21/64 loss: 1.7324326038360596
Batch 22/64 loss: 1.7303119897842407
Batch 23/64 loss: 1.7292745113372803
Batch 24/64 loss: 1.7311017513275146
Batch 25/64 loss: 1.7483162879943848
Batch 26/64 loss: 1.726532220840454
Batch 27/64 loss: 1.732569694519043
Batch 28/64 loss: 1.7271864414215088
Batch 29/64 loss: 1.726098656654358
Batch 30/64 loss: 1.731353998184204
Batch 31/64 loss: 1.7304941415786743
Batch 32/64 loss: 1.7263866662979126
Batch 33/64 loss: 1.7332812547683716
Batch 34/64 loss: 1.7292842864990234
Batch 35/64 loss: 1.7328300476074219
Batch 36/64 loss: 1.7296068668365479
Batch 37/64 loss: 1.7420895099639893
Batch 38/64 loss: 1.7315107583999634
Batch 39/64 loss: 1.731216549873352
Batch 40/64 loss: 1.7284280061721802
Batch 41/64 loss: 1.7273175716400146
Batch 42/64 loss: 1.7384068965911865
Batch 43/64 loss: 1.728775978088379
Batch 44/64 loss: 1.7309436798095703
Batch 45/64 loss: 1.7272859811782837
Batch 46/64 loss: 1.7296371459960938
Batch 47/64 loss: 1.7259886264801025
Batch 48/64 loss: 1.7314376831054688
Batch 49/64 loss: 1.7273023128509521
Batch 50/64 loss: 1.739076852798462
Batch 51/64 loss: 1.7281486988067627
Batch 52/64 loss: 1.7277711629867554
Batch 53/64 loss: 1.7501068115234375
Batch 54/64 loss: 1.7361741065979004
Batch 55/64 loss: 1.7288920879364014
Batch 56/64 loss: 1.7279696464538574
Batch 57/64 loss: 1.7305097579956055
Batch 58/64 loss: 1.727512001991272
Batch 59/64 loss: 1.7426953315734863
Batch 60/64 loss: 1.728353500366211
Batch 61/64 loss: 1.728567123413086
Batch 62/64 loss: 1.734252691268921
Batch 63/64 loss: 1.7324082851409912
Batch 64/64 loss: 1.9161666631698608
Epoch 368  Train loss: 1.732845830449871  Val loss: 1.7495329584862358
Epoch 369
-------------------------------
Batch 1/64 loss: 1.728827714920044
Batch 2/64 loss: 1.731818437576294
Batch 3/64 loss: 1.7339630126953125
Batch 4/64 loss: 1.7281339168548584
Batch 5/64 loss: 1.7323400974273682
Batch 6/64 loss: 1.7539467811584473
Batch 7/64 loss: 1.7405362129211426
Batch 8/64 loss: 1.7324531078338623
Batch 9/64 loss: 1.7293422222137451
Batch 10/64 loss: 1.729391098022461
Batch 11/64 loss: 1.7311863899230957
Batch 12/64 loss: 1.7294354438781738
Batch 13/64 loss: 1.730992317199707
Batch 14/64 loss: 1.7310974597930908
Batch 15/64 loss: 1.7367274761199951
Batch 16/64 loss: 1.735569953918457
Batch 17/64 loss: 1.7281403541564941
Batch 18/64 loss: 1.727724552154541
Batch 19/64 loss: 1.7299530506134033
Batch 20/64 loss: 1.7304911613464355
Batch 21/64 loss: 1.7282626628875732
Batch 22/64 loss: 1.7260668277740479
Batch 23/64 loss: 1.732025384902954
Batch 24/64 loss: 1.726626992225647
Batch 25/64 loss: 1.731633186340332
Batch 26/64 loss: 1.730596899986267
Batch 27/64 loss: 1.7285888195037842
Batch 28/64 loss: 1.7277997732162476
Batch 29/64 loss: 1.7287192344665527
Batch 30/64 loss: 1.7290105819702148
Batch 31/64 loss: 1.7301589250564575
Batch 32/64 loss: 1.7270361185073853
Batch 33/64 loss: 1.7281818389892578
Batch 34/64 loss: 1.7439000606536865
Batch 35/64 loss: 1.730668544769287
Batch 36/64 loss: 1.7307021617889404
Batch 37/64 loss: 1.7283542156219482
Batch 38/64 loss: 1.7272793054580688
Batch 39/64 loss: 1.7260305881500244
Batch 40/64 loss: 1.7273870706558228
Batch 41/64 loss: 1.7266603708267212
Batch 42/64 loss: 1.726100206375122
Batch 43/64 loss: 1.7333183288574219
Batch 44/64 loss: 1.7263273000717163
Batch 45/64 loss: 1.7316638231277466
Batch 46/64 loss: 1.728332281112671
Batch 47/64 loss: 1.7286103963851929
Batch 48/64 loss: 1.7274304628372192
Batch 49/64 loss: 1.7292985916137695
Batch 50/64 loss: 1.7267839908599854
Batch 51/64 loss: 1.7267334461212158
Batch 52/64 loss: 1.7277348041534424
Batch 53/64 loss: 1.7282156944274902
Batch 54/64 loss: 1.7272716760635376
Batch 55/64 loss: 1.727827548980713
Batch 56/64 loss: 1.7245347499847412
Batch 57/64 loss: 1.736018180847168
Batch 58/64 loss: 1.729597806930542
Batch 59/64 loss: 1.728248119354248
Batch 60/64 loss: 1.7295799255371094
Batch 61/64 loss: 1.727829933166504
Batch 62/64 loss: 1.7289783954620361
Batch 63/64 loss: 1.7257423400878906
Batch 64/64 loss: 1.9146058559417725
Epoch 369  Train loss: 1.732233611275168  Val loss: 1.748519597594271
Epoch 370
-------------------------------
Batch 1/64 loss: 1.732098937034607
Batch 2/64 loss: 1.7292125225067139
Batch 3/64 loss: 1.7324562072753906
Batch 4/64 loss: 1.729240894317627
Batch 5/64 loss: 1.728374719619751
Batch 6/64 loss: 1.7320244312286377
Batch 7/64 loss: 1.7269508838653564
Batch 8/64 loss: 1.7304179668426514
Batch 9/64 loss: 1.7286324501037598
Batch 10/64 loss: 1.7293851375579834
Batch 11/64 loss: 1.7271897792816162
Batch 12/64 loss: 1.7305655479431152
Batch 13/64 loss: 1.7290513515472412
Batch 14/64 loss: 1.745300054550171
Batch 15/64 loss: 1.7306392192840576
Batch 16/64 loss: 1.72515869140625
Batch 17/64 loss: 1.7272735834121704
Batch 18/64 loss: 1.725651741027832
Batch 19/64 loss: 1.7306790351867676
Batch 20/64 loss: 1.7330262660980225
Batch 21/64 loss: 1.7287660837173462
Batch 22/64 loss: 1.727560043334961
Batch 23/64 loss: 1.7314190864562988
Batch 24/64 loss: 1.7290706634521484
Batch 25/64 loss: 1.7485246658325195
Batch 26/64 loss: 1.7270317077636719
Batch 27/64 loss: 1.7253484725952148
Batch 28/64 loss: 1.7335426807403564
Batch 29/64 loss: 1.7286090850830078
Batch 30/64 loss: 1.726280689239502
Batch 31/64 loss: 1.7254412174224854
Batch 32/64 loss: 1.742699384689331
Batch 33/64 loss: 1.7239623069763184
Batch 34/64 loss: 1.7270989418029785
Batch 35/64 loss: 1.731088638305664
Batch 36/64 loss: 1.735970139503479
Batch 37/64 loss: 1.7265172004699707
Batch 38/64 loss: 1.7313334941864014
Batch 39/64 loss: 1.727738618850708
Batch 40/64 loss: 1.733317255973816
Batch 41/64 loss: 1.7337775230407715
Batch 42/64 loss: 1.7289628982543945
Batch 43/64 loss: 1.7267870903015137
Batch 44/64 loss: 1.7298129796981812
Batch 45/64 loss: 1.7283813953399658
Batch 46/64 loss: 1.7262351512908936
Batch 47/64 loss: 1.72800874710083
Batch 48/64 loss: 1.7333581447601318
Batch 49/64 loss: 1.7337069511413574
Batch 50/64 loss: 1.7330795526504517
Batch 51/64 loss: 1.7309942245483398
Batch 52/64 loss: 1.726015567779541
Batch 53/64 loss: 1.7287800312042236
Batch 54/64 loss: 1.7307337522506714
Batch 55/64 loss: 1.7305729389190674
Batch 56/64 loss: 1.726935863494873
Batch 57/64 loss: 1.7276115417480469
Batch 58/64 loss: 1.7276544570922852
Batch 59/64 loss: 1.7306584119796753
Batch 60/64 loss: 1.7299647331237793
Batch 61/64 loss: 1.7260334491729736
Batch 62/64 loss: 1.728378415107727
Batch 63/64 loss: 1.7260198593139648
Batch 64/64 loss: 1.9133858680725098
Epoch 370  Train loss: 1.7321122019898658  Val loss: 1.747132010476286
Epoch 371
-------------------------------
Batch 1/64 loss: 1.7261638641357422
Batch 2/64 loss: 1.7449578046798706
Batch 3/64 loss: 1.728198766708374
Batch 4/64 loss: 1.734431505203247
Batch 5/64 loss: 1.7274608612060547
Batch 6/64 loss: 1.7294985055923462
Batch 7/64 loss: 1.7312862873077393
Batch 8/64 loss: 1.7253108024597168
Batch 9/64 loss: 1.725447177886963
Batch 10/64 loss: 1.7279874086380005
Batch 11/64 loss: 1.726563811302185
Batch 12/64 loss: 1.7261762619018555
Batch 13/64 loss: 1.7265307903289795
Batch 14/64 loss: 1.7310177087783813
Batch 15/64 loss: 1.728123426437378
Batch 16/64 loss: 1.728095531463623
Batch 17/64 loss: 1.730531930923462
Batch 18/64 loss: 1.7254856824874878
Batch 19/64 loss: 1.726059913635254
Batch 20/64 loss: 1.7279484272003174
Batch 21/64 loss: 1.7311540842056274
Batch 22/64 loss: 1.727545976638794
Batch 23/64 loss: 1.7304596900939941
Batch 24/64 loss: 1.7385873794555664
Batch 25/64 loss: 1.7322094440460205
Batch 26/64 loss: 1.7256121635437012
Batch 27/64 loss: 1.7262064218521118
Batch 28/64 loss: 1.7286052703857422
Batch 29/64 loss: 1.7264153957366943
Batch 30/64 loss: 1.7273931503295898
Batch 31/64 loss: 1.7261948585510254
Batch 32/64 loss: 1.7293848991394043
Batch 33/64 loss: 1.7254741191864014
Batch 34/64 loss: 1.7308932542800903
Batch 35/64 loss: 1.7331074476242065
Batch 36/64 loss: 1.7431640625
Batch 37/64 loss: 1.7263259887695312
Batch 38/64 loss: 1.7262811660766602
Batch 39/64 loss: 1.7285165786743164
Batch 40/64 loss: 1.728658676147461
Batch 41/64 loss: 1.7273657321929932
Batch 42/64 loss: 1.7287139892578125
Batch 43/64 loss: 1.7314372062683105
Batch 44/64 loss: 1.7318658828735352
Batch 45/64 loss: 1.7264139652252197
Batch 46/64 loss: 1.7288212776184082
Batch 47/64 loss: 1.7290027141571045
Batch 48/64 loss: 1.7281728982925415
Batch 49/64 loss: 1.728032112121582
Batch 50/64 loss: 1.7256379127502441
Batch 51/64 loss: 1.7272660732269287
Batch 52/64 loss: 1.7263001203536987
Batch 53/64 loss: 1.7284743785858154
Batch 54/64 loss: 1.7268352508544922
Batch 55/64 loss: 1.7249364852905273
Batch 56/64 loss: 1.7286181449890137
Batch 57/64 loss: 1.7270641326904297
Batch 58/64 loss: 1.734431266784668
Batch 59/64 loss: 1.7254412174224854
Batch 60/64 loss: 1.727302074432373
Batch 61/64 loss: 1.728377103805542
Batch 62/64 loss: 1.7254196405410767
Batch 63/64 loss: 1.7271678447723389
Batch 64/64 loss: 1.9056589603424072
Epoch 371  Train loss: 1.7308518923965155  Val loss: 1.7467165411133128
Epoch 372
-------------------------------
Batch 1/64 loss: 1.7260453701019287
Batch 2/64 loss: 1.7262294292449951
Batch 3/64 loss: 1.7464390993118286
Batch 4/64 loss: 1.727081298828125
Batch 5/64 loss: 1.7317252159118652
Batch 6/64 loss: 1.7253007888793945
Batch 7/64 loss: 1.7282047271728516
Batch 8/64 loss: 1.7417625188827515
Batch 9/64 loss: 1.725144386291504
Batch 10/64 loss: 1.7286009788513184
Batch 11/64 loss: 1.7248225212097168
Batch 12/64 loss: 1.7259180545806885
Batch 13/64 loss: 1.7498323917388916
Batch 14/64 loss: 1.7290735244750977
Batch 15/64 loss: 1.7290751934051514
Batch 16/64 loss: 1.726712942123413
Batch 17/64 loss: 1.7242751121520996
Batch 18/64 loss: 1.7306487560272217
Batch 19/64 loss: 1.7241802215576172
Batch 20/64 loss: 1.7251288890838623
Batch 21/64 loss: 1.723374843597412
Batch 22/64 loss: 1.7275497913360596
Batch 23/64 loss: 1.7287096977233887
Batch 24/64 loss: 1.7265995740890503
Batch 25/64 loss: 1.72416090965271
Batch 26/64 loss: 1.7249672412872314
Batch 27/64 loss: 1.7278978824615479
Batch 28/64 loss: 1.7285233736038208
Batch 29/64 loss: 1.7287352085113525
Batch 30/64 loss: 1.7286860942840576
Batch 31/64 loss: 1.7276875972747803
Batch 32/64 loss: 1.726564645767212
Batch 33/64 loss: 1.7318525314331055
Batch 34/64 loss: 1.725525140762329
Batch 35/64 loss: 1.727166771888733
Batch 36/64 loss: 1.727912425994873
Batch 37/64 loss: 1.7286992073059082
Batch 38/64 loss: 1.7276946306228638
Batch 39/64 loss: 1.731270432472229
Batch 40/64 loss: 1.7267382144927979
Batch 41/64 loss: 1.7255382537841797
Batch 42/64 loss: 1.7274830341339111
Batch 43/64 loss: 1.7308847904205322
Batch 44/64 loss: 1.728310465812683
Batch 45/64 loss: 1.7286455631256104
Batch 46/64 loss: 1.7263953685760498
Batch 47/64 loss: 1.726975917816162
Batch 48/64 loss: 1.7288997173309326
Batch 49/64 loss: 1.7259547710418701
Batch 50/64 loss: 1.7285099029541016
Batch 51/64 loss: 1.7264735698699951
Batch 52/64 loss: 1.7249841690063477
Batch 53/64 loss: 1.724818468093872
Batch 54/64 loss: 1.7256345748901367
Batch 55/64 loss: 1.7287390232086182
Batch 56/64 loss: 1.726668357849121
Batch 57/64 loss: 1.7325464487075806
Batch 58/64 loss: 1.727658987045288
Batch 59/64 loss: 1.7279043197631836
Batch 60/64 loss: 1.7269072532653809
Batch 61/64 loss: 1.7284226417541504
Batch 62/64 loss: 1.727631688117981
Batch 63/64 loss: 1.7315237522125244
Batch 64/64 loss: 1.9087128639221191
Epoch 372  Train loss: 1.7304402089586446  Val loss: 1.7447897855358845
Epoch 373
-------------------------------
Batch 1/64 loss: 1.727306842803955
Batch 2/64 loss: 1.729416012763977
Batch 3/64 loss: 1.7260416746139526
Batch 4/64 loss: 1.7351850271224976
Batch 5/64 loss: 1.7270138263702393
Batch 6/64 loss: 1.729467511177063
Batch 7/64 loss: 1.7268900871276855
Batch 8/64 loss: 1.7335474491119385
Batch 9/64 loss: 1.734481930732727
Batch 10/64 loss: 1.726379632949829
Batch 11/64 loss: 1.7288702726364136
Batch 12/64 loss: 1.7289328575134277
Batch 13/64 loss: 1.7285807132720947
Batch 14/64 loss: 1.726880669593811
Batch 15/64 loss: 1.7279751300811768
Batch 16/64 loss: 1.7340917587280273
Batch 17/64 loss: 1.7289271354675293
Batch 18/64 loss: 1.7308038473129272
Batch 19/64 loss: 1.7267982959747314
Batch 20/64 loss: 1.7313694953918457
Batch 21/64 loss: 1.7428970336914062
Batch 22/64 loss: 1.7274898290634155
Batch 23/64 loss: 1.7295904159545898
Batch 24/64 loss: 1.7270134687423706
Batch 25/64 loss: 1.727970004081726
Batch 26/64 loss: 1.7275816202163696
Batch 27/64 loss: 1.7307753562927246
Batch 28/64 loss: 1.7302552461624146
Batch 29/64 loss: 1.7274203300476074
Batch 30/64 loss: 1.7233965396881104
Batch 31/64 loss: 1.7270234823226929
Batch 32/64 loss: 1.7299505472183228
Batch 33/64 loss: 1.7284694910049438
Batch 34/64 loss: 1.7328194379806519
Batch 35/64 loss: 1.728360891342163
Batch 36/64 loss: 1.7293661832809448
Batch 37/64 loss: 1.7313653230667114
Batch 38/64 loss: 1.72831392288208
Batch 39/64 loss: 1.7283692359924316
Batch 40/64 loss: 1.7299525737762451
Batch 41/64 loss: 1.73398756980896
Batch 42/64 loss: 1.7280552387237549
Batch 43/64 loss: 1.7277565002441406
Batch 44/64 loss: 1.7278251647949219
Batch 45/64 loss: 1.7272295951843262
Batch 46/64 loss: 1.7300299406051636
Batch 47/64 loss: 1.7274982929229736
Batch 48/64 loss: 1.7318410873413086
Batch 49/64 loss: 1.727515459060669
Batch 50/64 loss: 1.7282240390777588
Batch 51/64 loss: 1.7309390306472778
Batch 52/64 loss: 1.731187105178833
Batch 53/64 loss: 1.7333667278289795
Batch 54/64 loss: 1.728065848350525
Batch 55/64 loss: 1.7278690338134766
Batch 56/64 loss: 1.7294785976409912
Batch 57/64 loss: 1.7469851970672607
Batch 58/64 loss: 1.7283308506011963
Batch 59/64 loss: 1.7261855602264404
Batch 60/64 loss: 1.725814938545227
Batch 61/64 loss: 1.7277069091796875
Batch 62/64 loss: 1.7453185319900513
Batch 63/64 loss: 1.7259552478790283
Batch 64/64 loss: 1.9061954021453857
Epoch 373  Train loss: 1.7318298685784432  Val loss: 1.7492949938036733
Epoch 374
-------------------------------
Batch 1/64 loss: 1.7256965637207031
Batch 2/64 loss: 1.7294695377349854
Batch 3/64 loss: 1.7257676124572754
Batch 4/64 loss: 1.7259325981140137
Batch 5/64 loss: 1.7274717092514038
Batch 6/64 loss: 1.725459098815918
Batch 7/64 loss: 1.7253344058990479
Batch 8/64 loss: 1.7263685464859009
Batch 9/64 loss: 1.7251887321472168
Batch 10/64 loss: 1.7264087200164795
Batch 11/64 loss: 1.7308356761932373
Batch 12/64 loss: 1.725722074508667
Batch 13/64 loss: 1.7258193492889404
Batch 14/64 loss: 1.7252991199493408
Batch 15/64 loss: 1.7234649658203125
Batch 16/64 loss: 1.7261526584625244
Batch 17/64 loss: 1.7251993417739868
Batch 18/64 loss: 1.7256296873092651
Batch 19/64 loss: 1.7272443771362305
Batch 20/64 loss: 1.7257914543151855
Batch 21/64 loss: 1.7268037796020508
Batch 22/64 loss: 1.7272356748580933
Batch 23/64 loss: 1.73743736743927
Batch 24/64 loss: 1.7247471809387207
Batch 25/64 loss: 1.7252495288848877
Batch 26/64 loss: 1.7308993339538574
Batch 27/64 loss: 1.7315363883972168
Batch 28/64 loss: 1.7556036710739136
Batch 29/64 loss: 1.7313902378082275
Batch 30/64 loss: 1.7352490425109863
Batch 31/64 loss: 1.7443406581878662
Batch 32/64 loss: 1.730398416519165
Batch 33/64 loss: 1.7291271686553955
Batch 34/64 loss: 1.730900764465332
Batch 35/64 loss: 1.7271785736083984
Batch 36/64 loss: 1.7265870571136475
Batch 37/64 loss: 1.7310799360275269
Batch 38/64 loss: 1.72904372215271
Batch 39/64 loss: 1.725830078125
Batch 40/64 loss: 1.730173110961914
Batch 41/64 loss: 1.7263593673706055
Batch 42/64 loss: 1.7248138189315796
Batch 43/64 loss: 1.7337323427200317
Batch 44/64 loss: 1.7297272682189941
Batch 45/64 loss: 1.7253614664077759
Batch 46/64 loss: 1.7248003482818604
Batch 47/64 loss: 1.7354544401168823
Batch 48/64 loss: 1.7280206680297852
Batch 49/64 loss: 1.7270421981811523
Batch 50/64 loss: 1.732470154762268
Batch 51/64 loss: 1.746178150177002
Batch 52/64 loss: 1.7275375127792358
Batch 53/64 loss: 1.729172945022583
Batch 54/64 loss: 1.727208137512207
Batch 55/64 loss: 1.7305933237075806
Batch 56/64 loss: 1.7268550395965576
Batch 57/64 loss: 1.7282428741455078
Batch 58/64 loss: 1.733243703842163
Batch 59/64 loss: 1.7242900133132935
Batch 60/64 loss: 1.7269554138183594
Batch 61/64 loss: 1.7287646532058716
Batch 62/64 loss: 1.7304044961929321
Batch 63/64 loss: 1.7267975807189941
Batch 64/64 loss: 1.9075249433517456
Epoch 374  Train loss: 1.7311331379647348  Val loss: 1.7453367988678188
Epoch 375
-------------------------------
Batch 1/64 loss: 1.7263100147247314
Batch 2/64 loss: 1.7298226356506348
Batch 3/64 loss: 1.730926275253296
Batch 4/64 loss: 1.7313430309295654
Batch 5/64 loss: 1.7344691753387451
Batch 6/64 loss: 1.7289326190948486
Batch 7/64 loss: 1.728432536125183
Batch 8/64 loss: 1.7273283004760742
Batch 9/64 loss: 1.7522790431976318
Batch 10/64 loss: 1.7287211418151855
Batch 11/64 loss: 1.726829171180725
Batch 12/64 loss: 1.7287180423736572
Batch 13/64 loss: 1.7253174781799316
Batch 14/64 loss: 1.7245349884033203
Batch 15/64 loss: 1.7301663160324097
Batch 16/64 loss: 1.7299351692199707
Batch 17/64 loss: 1.726621389389038
Batch 18/64 loss: 1.728546142578125
Batch 19/64 loss: 1.7262665033340454
Batch 20/64 loss: 1.7255451679229736
Batch 21/64 loss: 1.7248330116271973
Batch 22/64 loss: 1.742923617362976
Batch 23/64 loss: 1.730400800704956
Batch 24/64 loss: 1.7268602848052979
Batch 25/64 loss: 1.7272298336029053
Batch 26/64 loss: 1.7296884059906006
Batch 27/64 loss: 1.725130558013916
Batch 28/64 loss: 1.7262071371078491
Batch 29/64 loss: 1.7308766841888428
Batch 30/64 loss: 1.7265186309814453
Batch 31/64 loss: 1.729264497756958
Batch 32/64 loss: 1.7267520427703857
Batch 33/64 loss: 1.7268915176391602
Batch 34/64 loss: 1.7252357006072998
Batch 35/64 loss: 1.7286691665649414
Batch 36/64 loss: 1.724856972694397
Batch 37/64 loss: 1.7250418663024902
Batch 38/64 loss: 1.7271794080734253
Batch 39/64 loss: 1.7356274127960205
Batch 40/64 loss: 1.725290060043335
Batch 41/64 loss: 1.7253994941711426
Batch 42/64 loss: 1.7253293991088867
Batch 43/64 loss: 1.729745626449585
Batch 44/64 loss: 1.727257251739502
Batch 45/64 loss: 1.7280323505401611
Batch 46/64 loss: 1.7280519008636475
Batch 47/64 loss: 1.7313305139541626
Batch 48/64 loss: 1.7314338684082031
Batch 49/64 loss: 1.7267584800720215
Batch 50/64 loss: 1.729947566986084
Batch 51/64 loss: 1.7299546003341675
Batch 52/64 loss: 1.7273286581039429
Batch 53/64 loss: 1.7298964262008667
Batch 54/64 loss: 1.7256379127502441
Batch 55/64 loss: 1.7273236513137817
Batch 56/64 loss: 1.7315597534179688
Batch 57/64 loss: 1.734513282775879
Batch 58/64 loss: 1.7260470390319824
Batch 59/64 loss: 1.7283265590667725
Batch 60/64 loss: 1.7336804866790771
Batch 61/64 loss: 1.7264699935913086
Batch 62/64 loss: 1.7397937774658203
Batch 63/64 loss: 1.7275285720825195
Batch 64/64 loss: 1.9063713550567627
Epoch 375  Train loss: 1.7311003675647811  Val loss: 1.7483349231510228
Epoch 376
-------------------------------
Batch 1/64 loss: 1.727393627166748
Batch 2/64 loss: 1.7298736572265625
Batch 3/64 loss: 1.728229284286499
Batch 4/64 loss: 1.733896017074585
Batch 5/64 loss: 1.7295750379562378
Batch 6/64 loss: 1.7311594486236572
Batch 7/64 loss: 1.7475513219833374
Batch 8/64 loss: 1.7495615482330322
Batch 9/64 loss: 1.7314033508300781
Batch 10/64 loss: 1.726747751235962
Batch 11/64 loss: 1.7319235801696777
Batch 12/64 loss: 1.7285096645355225
Batch 13/64 loss: 1.7281420230865479
Batch 14/64 loss: 1.7319477796554565
Batch 15/64 loss: 1.7290083169937134
Batch 16/64 loss: 1.7292027473449707
Batch 17/64 loss: 1.7280353307724
Batch 18/64 loss: 1.727031946182251
Batch 19/64 loss: 1.7274768352508545
Batch 20/64 loss: 1.7274277210235596
Batch 21/64 loss: 1.7275867462158203
Batch 22/64 loss: 1.7266740798950195
Batch 23/64 loss: 1.7280690670013428
Batch 24/64 loss: 1.7281889915466309
Batch 25/64 loss: 1.7244576215744019
Batch 26/64 loss: 1.7271767854690552
Batch 27/64 loss: 1.7264819145202637
Batch 28/64 loss: 1.726182460784912
Batch 29/64 loss: 1.7333252429962158
Batch 30/64 loss: 1.7274353504180908
Batch 31/64 loss: 1.7267725467681885
Batch 32/64 loss: 1.725104570388794
Batch 33/64 loss: 1.7285900115966797
Batch 34/64 loss: 1.726584553718567
Batch 35/64 loss: 1.728459358215332
Batch 36/64 loss: 1.727706789970398
Batch 37/64 loss: 1.726609230041504
Batch 38/64 loss: 1.7309560775756836
Batch 39/64 loss: 1.7261103391647339
Batch 40/64 loss: 1.7265660762786865
Batch 41/64 loss: 1.727222204208374
Batch 42/64 loss: 1.7260143756866455
Batch 43/64 loss: 1.72548508644104
Batch 44/64 loss: 1.7276191711425781
Batch 45/64 loss: 1.743741750717163
Batch 46/64 loss: 1.728156328201294
Batch 47/64 loss: 1.7266466617584229
Batch 48/64 loss: 1.7315964698791504
Batch 49/64 loss: 1.7326955795288086
Batch 50/64 loss: 1.731505036354065
Batch 51/64 loss: 1.7272682189941406
Batch 52/64 loss: 1.7272032499313354
Batch 53/64 loss: 1.7346605062484741
Batch 54/64 loss: 1.7583054304122925
Batch 55/64 loss: 1.7366231679916382
Batch 56/64 loss: 1.7323356866836548
Batch 57/64 loss: 1.7274304628372192
Batch 58/64 loss: 1.7332127094268799
Batch 59/64 loss: 1.7303444147109985
Batch 60/64 loss: 1.7301840782165527
Batch 61/64 loss: 1.728145718574524
Batch 62/64 loss: 1.7352113723754883
Batch 63/64 loss: 1.7309324741363525
Batch 64/64 loss: 1.9062198400497437
Epoch 376  Train loss: 1.7323190562865314  Val loss: 1.7491719812871664
Epoch 377
-------------------------------
Batch 1/64 loss: 1.7278671264648438
Batch 2/64 loss: 1.7283027172088623
Batch 3/64 loss: 1.729156732559204
Batch 4/64 loss: 1.7295918464660645
Batch 5/64 loss: 1.7302398681640625
Batch 6/64 loss: 1.7260968685150146
Batch 7/64 loss: 1.7278389930725098
Batch 8/64 loss: 1.7259671688079834
Batch 9/64 loss: 1.725092887878418
Batch 10/64 loss: 1.7285614013671875
Batch 11/64 loss: 1.7287005186080933
Batch 12/64 loss: 1.7309997081756592
Batch 13/64 loss: 1.728368878364563
Batch 14/64 loss: 1.7310450077056885
Batch 15/64 loss: 1.7259137630462646
Batch 16/64 loss: 1.7265832424163818
Batch 17/64 loss: 1.727299690246582
Batch 18/64 loss: 1.7292416095733643
Batch 19/64 loss: 1.7226204872131348
Batch 20/64 loss: 1.7289754152297974
Batch 21/64 loss: 1.7271485328674316
Batch 22/64 loss: 1.746319055557251
Batch 23/64 loss: 1.7326741218566895
Batch 24/64 loss: 1.732201337814331
Batch 25/64 loss: 1.7292338609695435
Batch 26/64 loss: 1.7288868427276611
Batch 27/64 loss: 1.7469044923782349
Batch 28/64 loss: 1.729651927947998
Batch 29/64 loss: 1.7350010871887207
Batch 30/64 loss: 1.7287487983703613
Batch 31/64 loss: 1.7304809093475342
Batch 32/64 loss: 1.7301623821258545
Batch 33/64 loss: 1.7265948057174683
Batch 34/64 loss: 1.729679822921753
Batch 35/64 loss: 1.7442291975021362
Batch 36/64 loss: 1.7304545640945435
Batch 37/64 loss: 1.7339866161346436
Batch 38/64 loss: 1.7293235063552856
Batch 39/64 loss: 1.729660987854004
Batch 40/64 loss: 1.7325760126113892
Batch 41/64 loss: 1.733768105506897
Batch 42/64 loss: 1.728556513786316
Batch 43/64 loss: 1.732734203338623
Batch 44/64 loss: 1.732661485671997
Batch 45/64 loss: 1.7281694412231445
Batch 46/64 loss: 1.7261757850646973
Batch 47/64 loss: 1.7291804552078247
Batch 48/64 loss: 1.7277288436889648
Batch 49/64 loss: 1.725238561630249
Batch 50/64 loss: 1.7267566919326782
Batch 51/64 loss: 1.7290072441101074
Batch 52/64 loss: 1.7251241207122803
Batch 53/64 loss: 1.724894404411316
Batch 54/64 loss: 1.7281525135040283
Batch 55/64 loss: 1.7278525829315186
Batch 56/64 loss: 1.724663496017456
Batch 57/64 loss: 1.728830099105835
Batch 58/64 loss: 1.7334520816802979
Batch 59/64 loss: 1.7248210906982422
Batch 60/64 loss: 1.730475664138794
Batch 61/64 loss: 1.7274250984191895
Batch 62/64 loss: 1.7270636558532715
Batch 63/64 loss: 1.7252843379974365
Batch 64/64 loss: 1.910761833190918
Epoch 377  Train loss: 1.7316622846266803  Val loss: 1.7438798344012387
Epoch 378
-------------------------------
Batch 1/64 loss: 1.7288047075271606
Batch 2/64 loss: 1.7273046970367432
Batch 3/64 loss: 1.7267920970916748
Batch 4/64 loss: 1.725884199142456
Batch 5/64 loss: 1.7264487743377686
Batch 6/64 loss: 1.725806713104248
Batch 7/64 loss: 1.7246991395950317
Batch 8/64 loss: 1.7275927066802979
Batch 9/64 loss: 1.7252346277236938
Batch 10/64 loss: 1.7256757020950317
Batch 11/64 loss: 1.724966287612915
Batch 12/64 loss: 1.723717212677002
Batch 13/64 loss: 1.7274723052978516
Batch 14/64 loss: 1.7261226177215576
Batch 15/64 loss: 1.7261704206466675
Batch 16/64 loss: 1.7236040830612183
Batch 17/64 loss: 1.7279155254364014
Batch 18/64 loss: 1.7289382219314575
Batch 19/64 loss: 1.728287935256958
Batch 20/64 loss: 1.7237489223480225
Batch 21/64 loss: 1.7226240634918213
Batch 22/64 loss: 1.72405207157135
Batch 23/64 loss: 1.7236663103103638
Batch 24/64 loss: 1.7259182929992676
Batch 25/64 loss: 1.7251229286193848
Batch 26/64 loss: 1.727116584777832
Batch 27/64 loss: 1.728271245956421
Batch 28/64 loss: 1.7334141731262207
Batch 29/64 loss: 1.724804401397705
Batch 30/64 loss: 1.723828911781311
Batch 31/64 loss: 1.738180160522461
Batch 32/64 loss: 1.7241874933242798
Batch 33/64 loss: 1.7262344360351562
Batch 34/64 loss: 1.7251956462860107
Batch 35/64 loss: 1.7254817485809326
Batch 36/64 loss: 1.7257883548736572
Batch 37/64 loss: 1.7238178253173828
Batch 38/64 loss: 1.7282140254974365
Batch 39/64 loss: 1.7273757457733154
Batch 40/64 loss: 1.7230956554412842
Batch 41/64 loss: 1.7253350019454956
Batch 42/64 loss: 1.7287883758544922
Batch 43/64 loss: 1.7246291637420654
Batch 44/64 loss: 1.7228862047195435
Batch 45/64 loss: 1.7230076789855957
Batch 46/64 loss: 1.7259845733642578
Batch 47/64 loss: 1.726900339126587
Batch 48/64 loss: 1.7228279113769531
Batch 49/64 loss: 1.7264604568481445
Batch 50/64 loss: 1.7266144752502441
Batch 51/64 loss: 1.7255802154541016
Batch 52/64 loss: 1.726991891860962
Batch 53/64 loss: 1.722456455230713
Batch 54/64 loss: 1.729316234588623
Batch 55/64 loss: 1.7248506546020508
Batch 56/64 loss: 1.727245807647705
Batch 57/64 loss: 1.7432599067687988
Batch 58/64 loss: 1.7240180969238281
Batch 59/64 loss: 1.730664610862732
Batch 60/64 loss: 1.7264108657836914
Batch 61/64 loss: 1.7395188808441162
Batch 62/64 loss: 1.726752519607544
Batch 63/64 loss: 1.7347548007965088
Batch 64/64 loss: 1.9153616428375244
Epoch 378  Train loss: 1.7289937776677748  Val loss: 1.7470865028420675
Epoch 379
-------------------------------
Batch 1/64 loss: 1.7270896434783936
Batch 2/64 loss: 1.7313913106918335
Batch 3/64 loss: 1.7278724908828735
Batch 4/64 loss: 1.7290637493133545
Batch 5/64 loss: 1.7307862043380737
Batch 6/64 loss: 1.7273545265197754
Batch 7/64 loss: 1.7300605773925781
Batch 8/64 loss: 1.732059359550476
Batch 9/64 loss: 1.7285096645355225
Batch 10/64 loss: 1.7295913696289062
Batch 11/64 loss: 1.727333664894104
Batch 12/64 loss: 1.7313190698623657
Batch 13/64 loss: 1.7265921831130981
Batch 14/64 loss: 1.7286708354949951
Batch 15/64 loss: 1.7302987575531006
Batch 16/64 loss: 1.7284190654754639
Batch 17/64 loss: 1.7276995182037354
Batch 18/64 loss: 1.7265926599502563
Batch 19/64 loss: 1.7264978885650635
Batch 20/64 loss: 1.7429836988449097
Batch 21/64 loss: 1.7279200553894043
Batch 22/64 loss: 1.7243293523788452
Batch 23/64 loss: 1.7253046035766602
Batch 24/64 loss: 1.726536750793457
Batch 25/64 loss: 1.730783462524414
Batch 26/64 loss: 1.726006031036377
Batch 27/64 loss: 1.730468988418579
Batch 28/64 loss: 1.7276482582092285
Batch 29/64 loss: 1.728851079940796
Batch 30/64 loss: 1.7256081104278564
Batch 31/64 loss: 1.7281098365783691
Batch 32/64 loss: 1.7296607494354248
Batch 33/64 loss: 1.7291014194488525
Batch 34/64 loss: 1.724553108215332
Batch 35/64 loss: 1.7285864353179932
Batch 36/64 loss: 1.7277277708053589
Batch 37/64 loss: 1.7268251180648804
Batch 38/64 loss: 1.7268683910369873
Batch 39/64 loss: 1.7236478328704834
Batch 40/64 loss: 1.72786283493042
Batch 41/64 loss: 1.7247499227523804
Batch 42/64 loss: 1.725503921508789
Batch 43/64 loss: 1.7265903949737549
Batch 44/64 loss: 1.7265605926513672
Batch 45/64 loss: 1.7263078689575195
Batch 46/64 loss: 1.725087285041809
Batch 47/64 loss: 1.7491552829742432
Batch 48/64 loss: 1.7283799648284912
Batch 49/64 loss: 1.727160930633545
Batch 50/64 loss: 1.7283947467803955
Batch 51/64 loss: 1.7291624546051025
Batch 52/64 loss: 1.7335293292999268
Batch 53/64 loss: 1.746875524520874
Batch 54/64 loss: 1.734304428100586
Batch 55/64 loss: 1.729416847229004
Batch 56/64 loss: 1.7275471687316895
Batch 57/64 loss: 1.7272677421569824
Batch 58/64 loss: 1.726540207862854
Batch 59/64 loss: 1.7291349172592163
Batch 60/64 loss: 1.7294049263000488
Batch 61/64 loss: 1.7275983095169067
Batch 62/64 loss: 1.7278215885162354
Batch 63/64 loss: 1.7292734384536743
Batch 64/64 loss: 1.9035930633544922
Epoch 379  Train loss: 1.7309811610801547  Val loss: 1.7471404722875745
Epoch 380
-------------------------------
Batch 1/64 loss: 1.7276322841644287
Batch 2/64 loss: 1.7279467582702637
Batch 3/64 loss: 1.7269392013549805
Batch 4/64 loss: 1.7254157066345215
Batch 5/64 loss: 1.7275569438934326
Batch 6/64 loss: 1.742903470993042
Batch 7/64 loss: 1.7372162342071533
Batch 8/64 loss: 1.7284667491912842
Batch 9/64 loss: 1.7281087636947632
Batch 10/64 loss: 1.7260169982910156
Batch 11/64 loss: 1.7259876728057861
Batch 12/64 loss: 1.727856159210205
Batch 13/64 loss: 1.7290353775024414
Batch 14/64 loss: 1.7276020050048828
Batch 15/64 loss: 1.7267708778381348
Batch 16/64 loss: 1.7255178689956665
Batch 17/64 loss: 1.7355473041534424
Batch 18/64 loss: 1.7266616821289062
Batch 19/64 loss: 1.727431058883667
Batch 20/64 loss: 1.7288234233856201
Batch 21/64 loss: 1.7259702682495117
Batch 22/64 loss: 1.7254242897033691
Batch 23/64 loss: 1.7258524894714355
Batch 24/64 loss: 1.7293815612792969
Batch 25/64 loss: 1.7250027656555176
Batch 26/64 loss: 1.7287461757659912
Batch 27/64 loss: 1.7259712219238281
Batch 28/64 loss: 1.7272807359695435
Batch 29/64 loss: 1.7271363735198975
Batch 30/64 loss: 1.7232614755630493
Batch 31/64 loss: 1.7277517318725586
Batch 32/64 loss: 1.7268328666687012
Batch 33/64 loss: 1.7247989177703857
Batch 34/64 loss: 1.7231500148773193
Batch 35/64 loss: 1.7246828079223633
Batch 36/64 loss: 1.7263495922088623
Batch 37/64 loss: 1.7267102003097534
Batch 38/64 loss: 1.7250704765319824
Batch 39/64 loss: 1.7241802215576172
Batch 40/64 loss: 1.7243456840515137
Batch 41/64 loss: 1.7259984016418457
Batch 42/64 loss: 1.743929386138916
Batch 43/64 loss: 1.7242541313171387
Batch 44/64 loss: 1.7285412549972534
Batch 45/64 loss: 1.7254726886749268
Batch 46/64 loss: 1.722861647605896
Batch 47/64 loss: 1.7277121543884277
Batch 48/64 loss: 1.7254242897033691
Batch 49/64 loss: 1.7453465461730957
Batch 50/64 loss: 1.7277438640594482
Batch 51/64 loss: 1.7251722812652588
Batch 52/64 loss: 1.7253236770629883
Batch 53/64 loss: 1.722975492477417
Batch 54/64 loss: 1.726556658744812
Batch 55/64 loss: 1.7253419160842896
Batch 56/64 loss: 1.7300981283187866
Batch 57/64 loss: 1.7269983291625977
Batch 58/64 loss: 1.7279244661331177
Batch 59/64 loss: 1.729635238647461
Batch 60/64 loss: 1.7264738082885742
Batch 61/64 loss: 1.7254942655563354
Batch 62/64 loss: 1.7270724773406982
Batch 63/64 loss: 1.723987102508545
Batch 64/64 loss: 1.904198169708252
Epoch 380  Train loss: 1.7296599724713493  Val loss: 1.7503353058267705
Epoch 381
-------------------------------
Batch 1/64 loss: 1.7426915168762207
Batch 2/64 loss: 1.7243956327438354
Batch 3/64 loss: 1.72779381275177
Batch 4/64 loss: 1.7248024940490723
Batch 5/64 loss: 1.7257254123687744
Batch 6/64 loss: 1.728337049484253
Batch 7/64 loss: 1.7300159931182861
Batch 8/64 loss: 1.7280211448669434
Batch 9/64 loss: 1.724314570426941
Batch 10/64 loss: 1.726149082183838
Batch 11/64 loss: 1.7268749475479126
Batch 12/64 loss: 1.7264119386672974
Batch 13/64 loss: 1.7270376682281494
Batch 14/64 loss: 1.7261977195739746
Batch 15/64 loss: 1.7271032333374023
Batch 16/64 loss: 1.7242494821548462
Batch 17/64 loss: 1.7274502515792847
Batch 18/64 loss: 1.7347803115844727
Batch 19/64 loss: 1.7262077331542969
Batch 20/64 loss: 1.726332426071167
Batch 21/64 loss: 1.7222797870635986
Batch 22/64 loss: 1.7247754335403442
Batch 23/64 loss: 1.7262388467788696
Batch 24/64 loss: 1.724273681640625
Batch 25/64 loss: 1.7265757322311401
Batch 26/64 loss: 1.7248647212982178
Batch 27/64 loss: 1.72332763671875
Batch 28/64 loss: 1.7318918704986572
Batch 29/64 loss: 1.72898530960083
Batch 30/64 loss: 1.7249221801757812
Batch 31/64 loss: 1.7291343212127686
Batch 32/64 loss: 1.737276554107666
Batch 33/64 loss: 1.7256382703781128
Batch 34/64 loss: 1.7519636154174805
Batch 35/64 loss: 1.7459583282470703
Batch 36/64 loss: 1.7297561168670654
Batch 37/64 loss: 1.723294734954834
Batch 38/64 loss: 1.7297532558441162
Batch 39/64 loss: 1.7271225452423096
Batch 40/64 loss: 1.7271671295166016
Batch 41/64 loss: 1.726277470588684
Batch 42/64 loss: 1.7309675216674805
Batch 43/64 loss: 1.726444125175476
Batch 44/64 loss: 1.7301511764526367
Batch 45/64 loss: 1.7253761291503906
Batch 46/64 loss: 1.7261838912963867
Batch 47/64 loss: 1.7305541038513184
Batch 48/64 loss: 1.7356172800064087
Batch 49/64 loss: 1.727940559387207
Batch 50/64 loss: 1.727613091468811
Batch 51/64 loss: 1.7257297039031982
Batch 52/64 loss: 1.7343491315841675
Batch 53/64 loss: 1.7292523384094238
Batch 54/64 loss: 1.7294669151306152
Batch 55/64 loss: 1.7275683879852295
Batch 56/64 loss: 1.7288029193878174
Batch 57/64 loss: 1.7262681722640991
Batch 58/64 loss: 1.7296178340911865
Batch 59/64 loss: 1.7300913333892822
Batch 60/64 loss: 1.7273005247116089
Batch 61/64 loss: 1.7268831729888916
Batch 62/64 loss: 1.7291793823242188
Batch 63/64 loss: 1.7303217649459839
Batch 64/64 loss: 1.9205620288848877
Epoch 381  Train loss: 1.730862289316514  Val loss: 1.7479297967301202
Epoch 382
-------------------------------
Batch 1/64 loss: 1.7308905124664307
Batch 2/64 loss: 1.727114200592041
Batch 3/64 loss: 1.727698802947998
Batch 4/64 loss: 1.7299916744232178
Batch 5/64 loss: 1.7291526794433594
Batch 6/64 loss: 1.7301969528198242
Batch 7/64 loss: 1.726015329360962
Batch 8/64 loss: 1.7287685871124268
Batch 9/64 loss: 1.725508213043213
Batch 10/64 loss: 1.7278237342834473
Batch 11/64 loss: 1.7265868186950684
Batch 12/64 loss: 1.7290387153625488
Batch 13/64 loss: 1.7277960777282715
Batch 14/64 loss: 1.7297606468200684
Batch 15/64 loss: 1.7260539531707764
Batch 16/64 loss: 1.726453185081482
Batch 17/64 loss: 1.7444278001785278
Batch 18/64 loss: 1.726135015487671
Batch 19/64 loss: 1.728715419769287
Batch 20/64 loss: 1.7257452011108398
Batch 21/64 loss: 1.754499912261963
Batch 22/64 loss: 1.7290347814559937
Batch 23/64 loss: 1.7265727519989014
Batch 24/64 loss: 1.7258977890014648
Batch 25/64 loss: 1.7274236679077148
Batch 26/64 loss: 1.726339340209961
Batch 27/64 loss: 1.7235746383666992
Batch 28/64 loss: 1.729690670967102
Batch 29/64 loss: 1.7307546138763428
Batch 30/64 loss: 1.7249846458435059
Batch 31/64 loss: 1.726672649383545
Batch 32/64 loss: 1.7366681098937988
Batch 33/64 loss: 1.7293113470077515
Batch 34/64 loss: 1.7281739711761475
Batch 35/64 loss: 1.7304044961929321
Batch 36/64 loss: 1.7268999814987183
Batch 37/64 loss: 1.7247205972671509
Batch 38/64 loss: 1.73500394821167
Batch 39/64 loss: 1.7314385175704956
Batch 40/64 loss: 1.7351930141448975
Batch 41/64 loss: 1.7278248071670532
Batch 42/64 loss: 1.7260825634002686
Batch 43/64 loss: 1.7294336557388306
Batch 44/64 loss: 1.7256615161895752
Batch 45/64 loss: 1.7268247604370117
Batch 46/64 loss: 1.726957082748413
Batch 47/64 loss: 1.729029893875122
Batch 48/64 loss: 1.726723551750183
Batch 49/64 loss: 1.7294566631317139
Batch 50/64 loss: 1.7280534505844116
Batch 51/64 loss: 1.7285101413726807
Batch 52/64 loss: 1.72576105594635
Batch 53/64 loss: 1.7274479866027832
Batch 54/64 loss: 1.7305188179016113
Batch 55/64 loss: 1.728650689125061
Batch 56/64 loss: 1.7278766632080078
Batch 57/64 loss: 1.731325387954712
Batch 58/64 loss: 1.728595495223999
Batch 59/64 loss: 1.7261202335357666
Batch 60/64 loss: 1.7307780981063843
Batch 61/64 loss: 1.7300207614898682
Batch 62/64 loss: 1.7297780513763428
Batch 63/64 loss: 1.726794719696045
Batch 64/64 loss: 1.906093716621399
Epoch 382  Train loss: 1.7310577144809798  Val loss: 1.7460782052725041
Epoch 383
-------------------------------
Batch 1/64 loss: 1.7258224487304688
Batch 2/64 loss: 1.7267765998840332
Batch 3/64 loss: 1.734939694404602
Batch 4/64 loss: 1.725339651107788
Batch 5/64 loss: 1.7329803705215454
Batch 6/64 loss: 1.7314268350601196
Batch 7/64 loss: 1.725658893585205
Batch 8/64 loss: 1.7372934818267822
Batch 9/64 loss: 1.7250633239746094
Batch 10/64 loss: 1.7276368141174316
Batch 11/64 loss: 1.7280337810516357
Batch 12/64 loss: 1.7276415824890137
Batch 13/64 loss: 1.7322165966033936
Batch 14/64 loss: 1.7273635864257812
Batch 15/64 loss: 1.7235300540924072
Batch 16/64 loss: 1.7332136631011963
Batch 17/64 loss: 1.7294297218322754
Batch 18/64 loss: 1.7296936511993408
Batch 19/64 loss: 1.726808786392212
Batch 20/64 loss: 1.728487253189087
Batch 21/64 loss: 1.7288023233413696
Batch 22/64 loss: 1.7277089357376099
Batch 23/64 loss: 1.726172685623169
Batch 24/64 loss: 1.7243759632110596
Batch 25/64 loss: 1.7264385223388672
Batch 26/64 loss: 1.7322558164596558
Batch 27/64 loss: 1.7263432741165161
Batch 28/64 loss: 1.7265609502792358
Batch 29/64 loss: 1.73796808719635
Batch 30/64 loss: 1.7282793521881104
Batch 31/64 loss: 1.7244356870651245
Batch 32/64 loss: 1.7259198427200317
Batch 33/64 loss: 1.735968828201294
Batch 34/64 loss: 1.7294516563415527
Batch 35/64 loss: 1.744391918182373
Batch 36/64 loss: 1.7245962619781494
Batch 37/64 loss: 1.733720302581787
Batch 38/64 loss: 1.730542778968811
Batch 39/64 loss: 1.7307738065719604
Batch 40/64 loss: 1.727210283279419
Batch 41/64 loss: 1.7245056629180908
Batch 42/64 loss: 1.7319209575653076
Batch 43/64 loss: 1.724877119064331
Batch 44/64 loss: 1.7305575609207153
Batch 45/64 loss: 1.741229772567749
Batch 46/64 loss: 1.734405755996704
Batch 47/64 loss: 1.7282540798187256
Batch 48/64 loss: 1.7263939380645752
Batch 49/64 loss: 1.7354180812835693
Batch 50/64 loss: 1.7286715507507324
Batch 51/64 loss: 1.7277809381484985
Batch 52/64 loss: 1.7278212308883667
Batch 53/64 loss: 1.7296416759490967
Batch 54/64 loss: 1.7349987030029297
Batch 55/64 loss: 1.7290022373199463
Batch 56/64 loss: 1.7272024154663086
Batch 57/64 loss: 1.7317665815353394
Batch 58/64 loss: 1.7277252674102783
Batch 59/64 loss: 1.7275011539459229
Batch 60/64 loss: 1.7281594276428223
Batch 61/64 loss: 1.7336056232452393
Batch 62/64 loss: 1.7252777814865112
Batch 63/64 loss: 1.7265868186950684
Batch 64/64 loss: 1.9568092823028564
Epoch 383  Train loss: 1.7321127115511428  Val loss: 1.752013262194866
Epoch 384
-------------------------------
Batch 1/64 loss: 1.7295165061950684
Batch 2/64 loss: 1.7340024709701538
Batch 3/64 loss: 1.7268579006195068
Batch 4/64 loss: 1.732607364654541
Batch 5/64 loss: 1.7280738353729248
Batch 6/64 loss: 1.7280783653259277
Batch 7/64 loss: 1.7283775806427002
Batch 8/64 loss: 1.734093427658081
Batch 9/64 loss: 1.7292670011520386
Batch 10/64 loss: 1.7263206243515015
Batch 11/64 loss: 1.7291611433029175
Batch 12/64 loss: 1.7515254020690918
Batch 13/64 loss: 1.7254830598831177
Batch 14/64 loss: 1.7364447116851807
Batch 15/64 loss: 1.7295808792114258
Batch 16/64 loss: 1.7356902360916138
Batch 17/64 loss: 1.7335662841796875
Batch 18/64 loss: 1.733417272567749
Batch 19/64 loss: 1.727223515510559
Batch 20/64 loss: 1.7310538291931152
Batch 21/64 loss: 1.728400707244873
Batch 22/64 loss: 1.7322890758514404
Batch 23/64 loss: 1.7318615913391113
Batch 24/64 loss: 1.7305971384048462
Batch 25/64 loss: 1.731652021408081
Batch 26/64 loss: 1.727254033088684
Batch 27/64 loss: 1.7325223684310913
Batch 28/64 loss: 1.745540738105774
Batch 29/64 loss: 1.734910011291504
Batch 30/64 loss: 1.729202151298523
Batch 31/64 loss: 1.7302508354187012
Batch 32/64 loss: 1.727471113204956
Batch 33/64 loss: 1.7339389324188232
Batch 34/64 loss: 1.7390432357788086
Batch 35/64 loss: 1.7431973218917847
Batch 36/64 loss: 1.7320772409439087
Batch 37/64 loss: 1.7263422012329102
Batch 38/64 loss: 1.7323687076568604
Batch 39/64 loss: 1.7282906770706177
Batch 40/64 loss: 1.728395700454712
Batch 41/64 loss: 1.727705478668213
Batch 42/64 loss: 1.731368064880371
Batch 43/64 loss: 1.732757329940796
Batch 44/64 loss: 1.7259162664413452
Batch 45/64 loss: 1.731529951095581
Batch 46/64 loss: 1.7311394214630127
Batch 47/64 loss: 1.7284042835235596
Batch 48/64 loss: 1.7481344938278198
Batch 49/64 loss: 1.730811595916748
Batch 50/64 loss: 1.7294278144836426
Batch 51/64 loss: 1.732574701309204
Batch 52/64 loss: 1.731229543685913
Batch 53/64 loss: 1.7300353050231934
Batch 54/64 loss: 1.730132818222046
Batch 55/64 loss: 1.732074499130249
Batch 56/64 loss: 1.7401559352874756
Batch 57/64 loss: 1.7309316396713257
Batch 58/64 loss: 1.7341282367706299
Batch 59/64 loss: 1.7280948162078857
Batch 60/64 loss: 1.7265944480895996
Batch 61/64 loss: 1.7306599617004395
Batch 62/64 loss: 1.729932427406311
Batch 63/64 loss: 1.7355667352676392
Batch 64/64 loss: 1.9128187894821167
Epoch 384  Train loss: 1.7339586991889804  Val loss: 1.7478457267341745
Epoch 385
-------------------------------
Batch 1/64 loss: 1.7327533960342407
Batch 2/64 loss: 1.732093334197998
Batch 3/64 loss: 1.7309813499450684
Batch 4/64 loss: 1.7322828769683838
Batch 5/64 loss: 1.7310516834259033
Batch 6/64 loss: 1.7313740253448486
Batch 7/64 loss: 1.73030424118042
Batch 8/64 loss: 1.7307010889053345
Batch 9/64 loss: 1.7295918464660645
Batch 10/64 loss: 1.7424767017364502
Batch 11/64 loss: 1.728661060333252
Batch 12/64 loss: 1.7295620441436768
Batch 13/64 loss: 1.7342579364776611
Batch 14/64 loss: 1.7398343086242676
Batch 15/64 loss: 1.7276115417480469
Batch 16/64 loss: 1.72905695438385
Batch 17/64 loss: 1.7324784994125366
Batch 18/64 loss: 1.7300950288772583
Batch 19/64 loss: 1.7490736246109009
Batch 20/64 loss: 1.7322415113449097
Batch 21/64 loss: 1.7280088663101196
Batch 22/64 loss: 1.7374281883239746
Batch 23/64 loss: 1.7388590574264526
Batch 24/64 loss: 1.726654052734375
Batch 25/64 loss: 1.7293903827667236
Batch 26/64 loss: 1.7297627925872803
Batch 27/64 loss: 1.7340649366378784
Batch 28/64 loss: 1.7309129238128662
Batch 29/64 loss: 1.7355215549468994
Batch 30/64 loss: 1.7421687841415405
Batch 31/64 loss: 1.729430913925171
Batch 32/64 loss: 1.727308988571167
Batch 33/64 loss: 1.7418574094772339
Batch 34/64 loss: 1.7303236722946167
Batch 35/64 loss: 1.726569414138794
Batch 36/64 loss: 1.7277032136917114
Batch 37/64 loss: 1.7351869344711304
Batch 38/64 loss: 1.7280213832855225
Batch 39/64 loss: 1.7284256219863892
Batch 40/64 loss: 1.7294433116912842
Batch 41/64 loss: 1.7311420440673828
Batch 42/64 loss: 1.7282536029815674
Batch 43/64 loss: 1.7309656143188477
Batch 44/64 loss: 1.732569694519043
Batch 45/64 loss: 1.7281067371368408
Batch 46/64 loss: 1.7312641143798828
Batch 47/64 loss: 1.7293133735656738
Batch 48/64 loss: 1.7330842018127441
Batch 49/64 loss: 1.7309021949768066
Batch 50/64 loss: 1.7333967685699463
Batch 51/64 loss: 1.7327938079833984
Batch 52/64 loss: 1.7300434112548828
Batch 53/64 loss: 1.7302062511444092
Batch 54/64 loss: 1.7283886671066284
Batch 55/64 loss: 1.729146957397461
Batch 56/64 loss: 1.7289748191833496
Batch 57/64 loss: 1.729522466659546
Batch 58/64 loss: 1.7306228876113892
Batch 59/64 loss: 1.7323415279388428
Batch 60/64 loss: 1.7254388332366943
Batch 61/64 loss: 1.7256126403808594
Batch 62/64 loss: 1.7326650619506836
Batch 63/64 loss: 1.7296091318130493
Batch 64/64 loss: 1.9067842960357666
Epoch 385  Train loss: 1.733615348853317  Val loss: 1.7495910318446732
Epoch 386
-------------------------------
Batch 1/64 loss: 1.7289304733276367
Batch 2/64 loss: 1.729154109954834
Batch 3/64 loss: 1.7288672924041748
Batch 4/64 loss: 1.734879970550537
Batch 5/64 loss: 1.7288845777511597
Batch 6/64 loss: 1.7275629043579102
Batch 7/64 loss: 1.7311038970947266
Batch 8/64 loss: 1.728522539138794
Batch 9/64 loss: 1.7288624048233032
Batch 10/64 loss: 1.7300314903259277
Batch 11/64 loss: 1.7265230417251587
Batch 12/64 loss: 1.7278175354003906
Batch 13/64 loss: 1.7266733646392822
Batch 14/64 loss: 1.7301881313323975
Batch 15/64 loss: 1.730107069015503
Batch 16/64 loss: 1.737958550453186
Batch 17/64 loss: 1.7301833629608154
Batch 18/64 loss: 1.73008394241333
Batch 19/64 loss: 1.7291243076324463
Batch 20/64 loss: 1.728772521018982
Batch 21/64 loss: 1.7278141975402832
Batch 22/64 loss: 1.7384955883026123
Batch 23/64 loss: 1.7328426837921143
Batch 24/64 loss: 1.727278470993042
Batch 25/64 loss: 1.734729528427124
Batch 26/64 loss: 1.7551864385604858
Batch 27/64 loss: 1.7347900867462158
Batch 28/64 loss: 1.733382225036621
Batch 29/64 loss: 1.736786127090454
Batch 30/64 loss: 1.729297399520874
Batch 31/64 loss: 1.731410026550293
Batch 32/64 loss: 1.7303366661071777
Batch 33/64 loss: 1.733614206314087
Batch 34/64 loss: 1.728667974472046
Batch 35/64 loss: 1.732145071029663
Batch 36/64 loss: 1.7506849765777588
Batch 37/64 loss: 1.7367713451385498
Batch 38/64 loss: 1.7320795059204102
Batch 39/64 loss: 1.7394782304763794
Batch 40/64 loss: 1.7322406768798828
Batch 41/64 loss: 1.7348846197128296
Batch 42/64 loss: 1.7316752672195435
Batch 43/64 loss: 1.7320152521133423
Batch 44/64 loss: 1.7312965393066406
Batch 45/64 loss: 1.745150089263916
Batch 46/64 loss: 1.728582501411438
Batch 47/64 loss: 1.7347471714019775
Batch 48/64 loss: 1.7346837520599365
Batch 49/64 loss: 1.7314198017120361
Batch 50/64 loss: 1.7381715774536133
Batch 51/64 loss: 1.7325396537780762
Batch 52/64 loss: 1.7292256355285645
Batch 53/64 loss: 1.7300975322723389
Batch 54/64 loss: 1.7322734594345093
Batch 55/64 loss: 1.7302844524383545
Batch 56/64 loss: 1.7330013513565063
Batch 57/64 loss: 1.7437472343444824
Batch 58/64 loss: 1.735383152961731
Batch 59/64 loss: 1.732534646987915
Batch 60/64 loss: 1.7312724590301514
Batch 61/64 loss: 1.7332763671875
Batch 62/64 loss: 1.7333904504776
Batch 63/64 loss: 1.7338579893112183
Batch 64/64 loss: 1.9156688451766968
Epoch 386  Train loss: 1.7349415765089147  Val loss: 1.7481781764538427
Epoch 387
-------------------------------
Batch 1/64 loss: 1.729966402053833
Batch 2/64 loss: 1.7296397686004639
Batch 3/64 loss: 1.730941653251648
Batch 4/64 loss: 1.7298296689987183
Batch 5/64 loss: 1.7317423820495605
Batch 6/64 loss: 1.7308152914047241
Batch 7/64 loss: 1.7291834354400635
Batch 8/64 loss: 1.7343333959579468
Batch 9/64 loss: 1.728322148323059
Batch 10/64 loss: 1.7276078462600708
Batch 11/64 loss: 1.7333860397338867
Batch 12/64 loss: 1.7300596237182617
Batch 13/64 loss: 1.7443512678146362
Batch 14/64 loss: 1.7293986082077026
Batch 15/64 loss: 1.728668451309204
Batch 16/64 loss: 1.7264046669006348
Batch 17/64 loss: 1.728103518486023
Batch 18/64 loss: 1.7315294742584229
Batch 19/64 loss: 1.729612946510315
Batch 20/64 loss: 1.728323221206665
Batch 21/64 loss: 1.730055809020996
Batch 22/64 loss: 1.7575485706329346
Batch 23/64 loss: 1.7282483577728271
Batch 24/64 loss: 1.7310030460357666
Batch 25/64 loss: 1.7318975925445557
Batch 26/64 loss: 1.729405164718628
Batch 27/64 loss: 1.7381205558776855
Batch 28/64 loss: 1.731184959411621
Batch 29/64 loss: 1.7332184314727783
Batch 30/64 loss: 1.7333495616912842
Batch 31/64 loss: 1.731074333190918
Batch 32/64 loss: 1.732795000076294
Batch 33/64 loss: 1.7490732669830322
Batch 34/64 loss: 1.7370566129684448
Batch 35/64 loss: 1.7336094379425049
Batch 36/64 loss: 1.729995846748352
Batch 37/64 loss: 1.7309761047363281
Batch 38/64 loss: 1.7286229133605957
Batch 39/64 loss: 1.7319092750549316
Batch 40/64 loss: 1.7271369695663452
Batch 41/64 loss: 1.733802318572998
Batch 42/64 loss: 1.730552077293396
Batch 43/64 loss: 1.7331727743148804
Batch 44/64 loss: 1.7385973930358887
Batch 45/64 loss: 1.7291924953460693
Batch 46/64 loss: 1.7301573753356934
Batch 47/64 loss: 1.7468159198760986
Batch 48/64 loss: 1.7293710708618164
Batch 49/64 loss: 1.732633352279663
Batch 50/64 loss: 1.7295774221420288
Batch 51/64 loss: 1.7314300537109375
Batch 52/64 loss: 1.7289633750915527
Batch 53/64 loss: 1.7323553562164307
Batch 54/64 loss: 1.729947566986084
Batch 55/64 loss: 1.734196662902832
Batch 56/64 loss: 1.7291655540466309
Batch 57/64 loss: 1.7267985343933105
Batch 58/64 loss: 1.731337547302246
Batch 59/64 loss: 1.736168622970581
Batch 60/64 loss: 1.7314789295196533
Batch 61/64 loss: 1.7279548645019531
Batch 62/64 loss: 1.729964256286621
Batch 63/64 loss: 1.7338578701019287
Batch 64/64 loss: 1.913535237312317
Epoch 387  Train loss: 1.7342924618253521  Val loss: 1.7460220073096941
Epoch 388
-------------------------------
Batch 1/64 loss: 1.7306466102600098
Batch 2/64 loss: 1.728658676147461
Batch 3/64 loss: 1.727001428604126
Batch 4/64 loss: 1.72709059715271
Batch 5/64 loss: 1.730532169342041
Batch 6/64 loss: 1.7283728122711182
Batch 7/64 loss: 1.727670431137085
Batch 8/64 loss: 1.7310729026794434
Batch 9/64 loss: 1.7293765544891357
Batch 10/64 loss: 1.73267662525177
Batch 11/64 loss: 1.7315776348114014
Batch 12/64 loss: 1.7292102575302124
Batch 13/64 loss: 1.7298216819763184
Batch 14/64 loss: 1.741160273551941
Batch 15/64 loss: 1.7287081480026245
Batch 16/64 loss: 1.7305625677108765
Batch 17/64 loss: 1.73056161403656
Batch 18/64 loss: 1.730114459991455
Batch 19/64 loss: 1.732337474822998
Batch 20/64 loss: 1.7424371242523193
Batch 21/64 loss: 1.729090690612793
Batch 22/64 loss: 1.7289016246795654
Batch 23/64 loss: 1.7265689373016357
Batch 24/64 loss: 1.7318869829177856
Batch 25/64 loss: 1.7248597145080566
Batch 26/64 loss: 1.7254549264907837
Batch 27/64 loss: 1.7275246381759644
Batch 28/64 loss: 1.7286655902862549
Batch 29/64 loss: 1.7271922826766968
Batch 30/64 loss: 1.7266099452972412
Batch 31/64 loss: 1.7254085540771484
Batch 32/64 loss: 1.728213906288147
Batch 33/64 loss: 1.73248291015625
Batch 34/64 loss: 1.725592851638794
Batch 35/64 loss: 1.7327197790145874
Batch 36/64 loss: 1.7268426418304443
Batch 37/64 loss: 1.7305870056152344
Batch 38/64 loss: 1.7433674335479736
Batch 39/64 loss: 1.729490041732788
Batch 40/64 loss: 1.72798752784729
Batch 41/64 loss: 1.7293412685394287
Batch 42/64 loss: 1.7297606468200684
Batch 43/64 loss: 1.7267818450927734
Batch 44/64 loss: 1.7303822040557861
Batch 45/64 loss: 1.730952262878418
Batch 46/64 loss: 1.7290675640106201
Batch 47/64 loss: 1.7275437116622925
Batch 48/64 loss: 1.7280203104019165
Batch 49/64 loss: 1.7320609092712402
Batch 50/64 loss: 1.7295479774475098
Batch 51/64 loss: 1.7332209348678589
Batch 52/64 loss: 1.7292879819869995
Batch 53/64 loss: 1.7303359508514404
Batch 54/64 loss: 1.7309967279434204
Batch 55/64 loss: 1.7315959930419922
Batch 56/64 loss: 1.7325459718704224
Batch 57/64 loss: 1.7276852130889893
Batch 58/64 loss: 1.7320058345794678
Batch 59/64 loss: 1.7476401329040527
Batch 60/64 loss: 1.7306163311004639
Batch 61/64 loss: 1.7302510738372803
Batch 62/64 loss: 1.7278006076812744
Batch 63/64 loss: 1.7306547164916992
Batch 64/64 loss: 1.903209924697876
Epoch 388  Train loss: 1.7323065355712293  Val loss: 1.7475005556217993
Epoch 389
-------------------------------
Batch 1/64 loss: 1.733440637588501
Batch 2/64 loss: 1.7522978782653809
Batch 3/64 loss: 1.7422617673873901
Batch 4/64 loss: 1.730473279953003
Batch 5/64 loss: 1.729799509048462
Batch 6/64 loss: 1.7256395816802979
Batch 7/64 loss: 1.7285524606704712
Batch 8/64 loss: 1.7258753776550293
Batch 9/64 loss: 1.7307010889053345
Batch 10/64 loss: 1.7305271625518799
Batch 11/64 loss: 1.7277076244354248
Batch 12/64 loss: 1.7346739768981934
Batch 13/64 loss: 1.7247469425201416
Batch 14/64 loss: 1.7339963912963867
Batch 15/64 loss: 1.729082465171814
Batch 16/64 loss: 1.7304896116256714
Batch 17/64 loss: 1.7477624416351318
Batch 18/64 loss: 1.727031946182251
Batch 19/64 loss: 1.7292225360870361
Batch 20/64 loss: 1.7322033643722534
Batch 21/64 loss: 1.7267606258392334
Batch 22/64 loss: 1.7301716804504395
Batch 23/64 loss: 1.7269749641418457
Batch 24/64 loss: 1.728856086730957
Batch 25/64 loss: 1.7282655239105225
Batch 26/64 loss: 1.7271308898925781
Batch 27/64 loss: 1.7292345762252808
Batch 28/64 loss: 1.7300068140029907
Batch 29/64 loss: 1.7286157608032227
Batch 30/64 loss: 1.7277300357818604
Batch 31/64 loss: 1.7280287742614746
Batch 32/64 loss: 1.7285935878753662
Batch 33/64 loss: 1.728132724761963
Batch 34/64 loss: 1.7329068183898926
Batch 35/64 loss: 1.727839708328247
Batch 36/64 loss: 1.72709059715271
Batch 37/64 loss: 1.7389239072799683
Batch 38/64 loss: 1.7294230461120605
Batch 39/64 loss: 1.7304261922836304
Batch 40/64 loss: 1.7269396781921387
Batch 41/64 loss: 1.7316440343856812
Batch 42/64 loss: 1.730621099472046
Batch 43/64 loss: 1.7292077541351318
Batch 44/64 loss: 1.7316631078720093
Batch 45/64 loss: 1.730648398399353
Batch 46/64 loss: 1.730891466140747
Batch 47/64 loss: 1.7315418720245361
Batch 48/64 loss: 1.7315171957015991
Batch 49/64 loss: 1.732151985168457
Batch 50/64 loss: 1.7280738353729248
Batch 51/64 loss: 1.7275265455245972
Batch 52/64 loss: 1.7274677753448486
Batch 53/64 loss: 1.7268400192260742
Batch 54/64 loss: 1.7270747423171997
Batch 55/64 loss: 1.7245122194290161
Batch 56/64 loss: 1.7301502227783203
Batch 57/64 loss: 1.7280360460281372
Batch 58/64 loss: 1.7311513423919678
Batch 59/64 loss: 1.72833251953125
Batch 60/64 loss: 1.7290091514587402
Batch 61/64 loss: 1.729443073272705
Batch 62/64 loss: 1.727766990661621
Batch 63/64 loss: 1.7288912534713745
Batch 64/64 loss: 1.90846848487854
Epoch 389  Train loss: 1.7322988556880576  Val loss: 1.7439369991472906
Epoch 390
-------------------------------
Batch 1/64 loss: 1.7286195755004883
Batch 2/64 loss: 1.7269084453582764
Batch 3/64 loss: 1.7281551361083984
Batch 4/64 loss: 1.727773666381836
Batch 5/64 loss: 1.7296421527862549
Batch 6/64 loss: 1.7274376153945923
Batch 7/64 loss: 1.726728081703186
Batch 8/64 loss: 1.7264928817749023
Batch 9/64 loss: 1.7283916473388672
Batch 10/64 loss: 1.7266156673431396
Batch 11/64 loss: 1.7264811992645264
Batch 12/64 loss: 1.7419859170913696
Batch 13/64 loss: 1.7281639575958252
Batch 14/64 loss: 1.7268877029418945
Batch 15/64 loss: 1.726905345916748
Batch 16/64 loss: 1.7278512716293335
Batch 17/64 loss: 1.72520112991333
Batch 18/64 loss: 1.7249904870986938
Batch 19/64 loss: 1.727156639099121
Batch 20/64 loss: 1.7277965545654297
Batch 21/64 loss: 1.7249420881271362
Batch 22/64 loss: 1.728538990020752
Batch 23/64 loss: 1.7263211011886597
Batch 24/64 loss: 1.7278807163238525
Batch 25/64 loss: 1.7258875370025635
Batch 26/64 loss: 1.7291643619537354
Batch 27/64 loss: 1.7274032831192017
Batch 28/64 loss: 1.7270289659500122
Batch 29/64 loss: 1.7259633541107178
Batch 30/64 loss: 1.7295644283294678
Batch 31/64 loss: 1.7324676513671875
Batch 32/64 loss: 1.7268002033233643
Batch 33/64 loss: 1.7313644886016846
Batch 34/64 loss: 1.7306509017944336
Batch 35/64 loss: 1.729414939880371
Batch 36/64 loss: 1.7330963611602783
Batch 37/64 loss: 1.7302770614624023
Batch 38/64 loss: 1.7322986125946045
Batch 39/64 loss: 1.738326072692871
Batch 40/64 loss: 1.7470229864120483
Batch 41/64 loss: 1.7387745380401611
Batch 42/64 loss: 1.727708339691162
Batch 43/64 loss: 1.730437994003296
Batch 44/64 loss: 1.7279927730560303
Batch 45/64 loss: 1.735300064086914
Batch 46/64 loss: 1.7284784317016602
Batch 47/64 loss: 1.728489875793457
Batch 48/64 loss: 1.7296998500823975
Batch 49/64 loss: 1.734055995941162
Batch 50/64 loss: 1.728121280670166
Batch 51/64 loss: 1.728888988494873
Batch 52/64 loss: 1.7414977550506592
Batch 53/64 loss: 1.7328804731369019
Batch 54/64 loss: 1.7409400939941406
Batch 55/64 loss: 1.7299742698669434
Batch 56/64 loss: 1.7319066524505615
Batch 57/64 loss: 1.7272989749908447
Batch 58/64 loss: 1.7347331047058105
Batch 59/64 loss: 1.7335480451583862
Batch 60/64 loss: 1.7335407733917236
Batch 61/64 loss: 1.735093116760254
Batch 62/64 loss: 1.7368335723876953
Batch 63/64 loss: 1.7347047328948975
Batch 64/64 loss: 1.923720121383667
Epoch 390  Train loss: 1.7326790426291672  Val loss: 1.7563124735330797
Epoch 391
-------------------------------
Batch 1/64 loss: 1.7355952262878418
Batch 2/64 loss: 1.7289811372756958
Batch 3/64 loss: 1.7483136653900146
Batch 4/64 loss: 1.7310841083526611
Batch 5/64 loss: 1.7317034006118774
Batch 6/64 loss: 1.7348501682281494
Batch 7/64 loss: 1.732121229171753
Batch 8/64 loss: 1.7285778522491455
Batch 9/64 loss: 1.7358214855194092
Batch 10/64 loss: 1.7321856021881104
Batch 11/64 loss: 1.7406543493270874
Batch 12/64 loss: 1.728752613067627
Batch 13/64 loss: 1.7262699604034424
Batch 14/64 loss: 1.7309660911560059
Batch 15/64 loss: 1.7304034233093262
Batch 16/64 loss: 1.7300941944122314
Batch 17/64 loss: 1.729360580444336
Batch 18/64 loss: 1.7293812036514282
Batch 19/64 loss: 1.7297930717468262
Batch 20/64 loss: 1.7293424606323242
Batch 21/64 loss: 1.7408877611160278
Batch 22/64 loss: 1.7277846336364746
Batch 23/64 loss: 1.730464220046997
Batch 24/64 loss: 1.7430627346038818
Batch 25/64 loss: 1.7290284633636475
Batch 26/64 loss: 1.7367490530014038
Batch 27/64 loss: 1.731215000152588
Batch 28/64 loss: 1.7331154346466064
Batch 29/64 loss: 1.7303255796432495
Batch 30/64 loss: 1.7294598817825317
Batch 31/64 loss: 1.7321884632110596
Batch 32/64 loss: 1.7269926071166992
Batch 33/64 loss: 1.7284120321273804
Batch 34/64 loss: 1.7295548915863037
Batch 35/64 loss: 1.7297838926315308
Batch 36/64 loss: 1.7281591892242432
Batch 37/64 loss: 1.7287373542785645
Batch 38/64 loss: 1.7293795347213745
Batch 39/64 loss: 1.729459285736084
Batch 40/64 loss: 1.7287249565124512
Batch 41/64 loss: 1.7270162105560303
Batch 42/64 loss: 1.7287921905517578
Batch 43/64 loss: 1.728367805480957
Batch 44/64 loss: 1.7283482551574707
Batch 45/64 loss: 1.7320054769515991
Batch 46/64 loss: 1.7333333492279053
Batch 47/64 loss: 1.727369785308838
Batch 48/64 loss: 1.728498935699463
Batch 49/64 loss: 1.724635124206543
Batch 50/64 loss: 1.7288177013397217
Batch 51/64 loss: 1.7279424667358398
Batch 52/64 loss: 1.7278690338134766
Batch 53/64 loss: 1.7463047504425049
Batch 54/64 loss: 1.7284753322601318
Batch 55/64 loss: 1.7317932844161987
Batch 56/64 loss: 1.726106882095337
Batch 57/64 loss: 1.7288191318511963
Batch 58/64 loss: 1.7273766994476318
Batch 59/64 loss: 1.730351448059082
Batch 60/64 loss: 1.7299758195877075
Batch 61/64 loss: 1.7300336360931396
Batch 62/64 loss: 1.7288899421691895
Batch 63/64 loss: 1.7268496751785278
Batch 64/64 loss: 1.9089913368225098
Epoch 391  Train loss: 1.73297965853822  Val loss: 1.7469373208141
Epoch 392
-------------------------------
Batch 1/64 loss: 1.728041172027588
Batch 2/64 loss: 1.7288806438446045
Batch 3/64 loss: 1.726968765258789
Batch 4/64 loss: 1.727006196975708
Batch 5/64 loss: 1.7313706874847412
Batch 6/64 loss: 1.7282686233520508
Batch 7/64 loss: 1.7250125408172607
Batch 8/64 loss: 1.7257308959960938
Batch 9/64 loss: 1.7285505533218384
Batch 10/64 loss: 1.7288429737091064
Batch 11/64 loss: 1.726853847503662
Batch 12/64 loss: 1.7312402725219727
Batch 13/64 loss: 1.7295970916748047
Batch 14/64 loss: 1.72981595993042
Batch 15/64 loss: 1.7305936813354492
Batch 16/64 loss: 1.7242469787597656
Batch 17/64 loss: 1.7284492254257202
Batch 18/64 loss: 1.7279772758483887
Batch 19/64 loss: 1.7262585163116455
Batch 20/64 loss: 1.7346632480621338
Batch 21/64 loss: 1.7254109382629395
Batch 22/64 loss: 1.733943223953247
Batch 23/64 loss: 1.7277852296829224
Batch 24/64 loss: 1.727236270904541
Batch 25/64 loss: 1.7287617921829224
Batch 26/64 loss: 1.7283583879470825
Batch 27/64 loss: 1.7330944538116455
Batch 28/64 loss: 1.7284624576568604
Batch 29/64 loss: 1.7301297187805176
Batch 30/64 loss: 1.7461934089660645
Batch 31/64 loss: 1.7279109954833984
Batch 32/64 loss: 1.726001501083374
Batch 33/64 loss: 1.735346794128418
Batch 34/64 loss: 1.7280925512313843
Batch 35/64 loss: 1.7285966873168945
Batch 36/64 loss: 1.7280702590942383
Batch 37/64 loss: 1.7284399271011353
Batch 38/64 loss: 1.7313835620880127
Batch 39/64 loss: 1.7254130840301514
Batch 40/64 loss: 1.729935884475708
Batch 41/64 loss: 1.729224443435669
Batch 42/64 loss: 1.7305715084075928
Batch 43/64 loss: 1.72487473487854
Batch 44/64 loss: 1.7284867763519287
Batch 45/64 loss: 1.7268047332763672
Batch 46/64 loss: 1.728643536567688
Batch 47/64 loss: 1.735282301902771
Batch 48/64 loss: 1.729137897491455
Batch 49/64 loss: 1.7411651611328125
Batch 50/64 loss: 1.7435100078582764
Batch 51/64 loss: 1.7285559177398682
Batch 52/64 loss: 1.7275407314300537
Batch 53/64 loss: 1.7301074266433716
Batch 54/64 loss: 1.7442207336425781
Batch 55/64 loss: 1.733129858970642
Batch 56/64 loss: 1.7287333011627197
Batch 57/64 loss: 1.734590768814087
Batch 58/64 loss: 1.733415126800537
Batch 59/64 loss: 1.7287440299987793
Batch 60/64 loss: 1.7289328575134277
Batch 61/64 loss: 1.7291202545166016
Batch 62/64 loss: 1.7310864925384521
Batch 63/64 loss: 1.7277400493621826
Batch 64/64 loss: 1.9127060174942017
Epoch 392  Train loss: 1.7321581873239256  Val loss: 1.7477896803433133
Epoch 393
-------------------------------
Batch 1/64 loss: 1.7278406620025635
Batch 2/64 loss: 1.7318007946014404
Batch 3/64 loss: 1.7276924848556519
Batch 4/64 loss: 1.726269006729126
Batch 5/64 loss: 1.7267446517944336
Batch 6/64 loss: 1.7298059463500977
Batch 7/64 loss: 1.7301011085510254
Batch 8/64 loss: 1.7307369709014893
Batch 9/64 loss: 1.7343993186950684
Batch 10/64 loss: 1.7349727153778076
Batch 11/64 loss: 1.7306153774261475
Batch 12/64 loss: 1.736512541770935
Batch 13/64 loss: 1.7339270114898682
Batch 14/64 loss: 1.7318254709243774
Batch 15/64 loss: 1.744868278503418
Batch 16/64 loss: 1.728522777557373
Batch 17/64 loss: 1.7300629615783691
Batch 18/64 loss: 1.7299801111221313
Batch 19/64 loss: 1.7294973134994507
Batch 20/64 loss: 1.728087067604065
Batch 21/64 loss: 1.726948618888855
Batch 22/64 loss: 1.7284736633300781
Batch 23/64 loss: 1.728739619255066
Batch 24/64 loss: 1.7310078144073486
Batch 25/64 loss: 1.732844591140747
Batch 26/64 loss: 1.7286992073059082
Batch 27/64 loss: 1.7390248775482178
Batch 28/64 loss: 1.729657769203186
Batch 29/64 loss: 1.729634404182434
Batch 30/64 loss: 1.7347915172576904
Batch 31/64 loss: 1.7367273569107056
Batch 32/64 loss: 1.7316479682922363
Batch 33/64 loss: 1.7305989265441895
Batch 34/64 loss: 1.7305998802185059
Batch 35/64 loss: 1.7413549423217773
Batch 36/64 loss: 1.7318652868270874
Batch 37/64 loss: 1.728851556777954
Batch 38/64 loss: 1.7310259342193604
Batch 39/64 loss: 1.7284631729125977
Batch 40/64 loss: 1.7274974584579468
Batch 41/64 loss: 1.7254679203033447
Batch 42/64 loss: 1.7310335636138916
Batch 43/64 loss: 1.7277605533599854
Batch 44/64 loss: 1.7276946306228638
Batch 45/64 loss: 1.727340579032898
Batch 46/64 loss: 1.7274068593978882
Batch 47/64 loss: 1.7274038791656494
Batch 48/64 loss: 1.7293329238891602
Batch 49/64 loss: 1.7282965183258057
Batch 50/64 loss: 1.7251476049423218
Batch 51/64 loss: 1.7271368503570557
Batch 52/64 loss: 1.7274998426437378
Batch 53/64 loss: 1.7311893701553345
Batch 54/64 loss: 1.7277686595916748
Batch 55/64 loss: 1.7297728061676025
Batch 56/64 loss: 1.7247982025146484
Batch 57/64 loss: 1.7406322956085205
Batch 58/64 loss: 1.724958896636963
Batch 59/64 loss: 1.7275259494781494
Batch 60/64 loss: 1.7472829818725586
Batch 61/64 loss: 1.7279026508331299
Batch 62/64 loss: 1.7255980968475342
Batch 63/64 loss: 1.7317090034484863
Batch 64/64 loss: 1.9065842628479004
Epoch 393  Train loss: 1.7326010348750096  Val loss: 1.7462839752538097
Epoch 394
-------------------------------
Batch 1/64 loss: 1.7257635593414307
Batch 2/64 loss: 1.7287657260894775
Batch 3/64 loss: 1.7308650016784668
Batch 4/64 loss: 1.7585792541503906
Batch 5/64 loss: 1.732743501663208
Batch 6/64 loss: 1.7265543937683105
Batch 7/64 loss: 1.7283869981765747
Batch 8/64 loss: 1.7333605289459229
Batch 9/64 loss: 1.7300374507904053
Batch 10/64 loss: 1.7264997959136963
Batch 11/64 loss: 1.7347581386566162
Batch 12/64 loss: 1.7352896928787231
Batch 13/64 loss: 1.730329990386963
Batch 14/64 loss: 1.7267165184020996
Batch 15/64 loss: 1.7276363372802734
Batch 16/64 loss: 1.7298057079315186
Batch 17/64 loss: 1.7278070449829102
Batch 18/64 loss: 1.73215651512146
Batch 19/64 loss: 1.7257444858551025
Batch 20/64 loss: 1.7284374237060547
Batch 21/64 loss: 1.7300190925598145
Batch 22/64 loss: 1.7291224002838135
Batch 23/64 loss: 1.735100269317627
Batch 24/64 loss: 1.728156328201294
Batch 25/64 loss: 1.727530598640442
Batch 26/64 loss: 1.7312711477279663
Batch 27/64 loss: 1.7298610210418701
Batch 28/64 loss: 1.7303872108459473
Batch 29/64 loss: 1.741980791091919
Batch 30/64 loss: 1.731175422668457
Batch 31/64 loss: 1.7300057411193848
Batch 32/64 loss: 1.7319992780685425
Batch 33/64 loss: 1.7264585494995117
Batch 34/64 loss: 1.726794958114624
Batch 35/64 loss: 1.7273805141448975
Batch 36/64 loss: 1.7331016063690186
Batch 37/64 loss: 1.7276105880737305
Batch 38/64 loss: 1.731929063796997
Batch 39/64 loss: 1.7333910465240479
Batch 40/64 loss: 1.7302541732788086
Batch 41/64 loss: 1.7291239500045776
Batch 42/64 loss: 1.7277039289474487
Batch 43/64 loss: 1.7272768020629883
Batch 44/64 loss: 1.727393627166748
Batch 45/64 loss: 1.7411160469055176
Batch 46/64 loss: 1.7248615026474
Batch 47/64 loss: 1.7251014709472656
Batch 48/64 loss: 1.7277309894561768
Batch 49/64 loss: 1.7323625087738037
Batch 50/64 loss: 1.7287908792495728
Batch 51/64 loss: 1.730102300643921
Batch 52/64 loss: 1.7303797006607056
Batch 53/64 loss: 1.7250945568084717
Batch 54/64 loss: 1.7323496341705322
Batch 55/64 loss: 1.730265498161316
Batch 56/64 loss: 1.727416753768921
Batch 57/64 loss: 1.7270735502243042
Batch 58/64 loss: 1.72993803024292
Batch 59/64 loss: 1.7322676181793213
Batch 60/64 loss: 1.726898431777954
Batch 61/64 loss: 1.7268297672271729
Batch 62/64 loss: 1.7259724140167236
Batch 63/64 loss: 1.72739839553833
Batch 64/64 loss: 1.9062105417251587
Epoch 394  Train loss: 1.732186260877871  Val loss: 1.7464852308489613
Epoch 395
-------------------------------
Batch 1/64 loss: 1.7274084091186523
Batch 2/64 loss: 1.7263975143432617
Batch 3/64 loss: 1.7302250862121582
Batch 4/64 loss: 1.7280890941619873
Batch 5/64 loss: 1.7305214405059814
Batch 6/64 loss: 1.726365327835083
Batch 7/64 loss: 1.7271687984466553
Batch 8/64 loss: 1.7281842231750488
Batch 9/64 loss: 1.7399206161499023
Batch 10/64 loss: 1.7264842987060547
Batch 11/64 loss: 1.73172926902771
Batch 12/64 loss: 1.732269287109375
Batch 13/64 loss: 1.7323927879333496
Batch 14/64 loss: 1.742928147315979
Batch 15/64 loss: 1.7313244342803955
Batch 16/64 loss: 1.7274160385131836
Batch 17/64 loss: 1.7283048629760742
Batch 18/64 loss: 1.7321605682373047
Batch 19/64 loss: 1.7277956008911133
Batch 20/64 loss: 1.7268445491790771
Batch 21/64 loss: 1.7329492568969727
Batch 22/64 loss: 1.7284057140350342
Batch 23/64 loss: 1.7317306995391846
Batch 24/64 loss: 1.7329782247543335
Batch 25/64 loss: 1.726454734802246
Batch 26/64 loss: 1.7284040451049805
Batch 27/64 loss: 1.7277644872665405
Batch 28/64 loss: 1.7252962589263916
Batch 29/64 loss: 1.7268476486206055
Batch 30/64 loss: 1.7278763055801392
Batch 31/64 loss: 1.7263058423995972
Batch 32/64 loss: 1.7264841794967651
Batch 33/64 loss: 1.7257096767425537
Batch 34/64 loss: 1.7276654243469238
Batch 35/64 loss: 1.7268526554107666
Batch 36/64 loss: 1.7321380376815796
Batch 37/64 loss: 1.731065273284912
Batch 38/64 loss: 1.728729248046875
Batch 39/64 loss: 1.7290492057800293
Batch 40/64 loss: 1.728044033050537
Batch 41/64 loss: 1.7344168424606323
Batch 42/64 loss: 1.7292568683624268
Batch 43/64 loss: 1.7333714962005615
Batch 44/64 loss: 1.7303974628448486
Batch 45/64 loss: 1.7351354360580444
Batch 46/64 loss: 1.7265958786010742
Batch 47/64 loss: 1.726063847541809
Batch 48/64 loss: 1.7312145233154297
Batch 49/64 loss: 1.7269501686096191
Batch 50/64 loss: 1.7282350063323975
Batch 51/64 loss: 1.7331719398498535
Batch 52/64 loss: 1.726501703262329
Batch 53/64 loss: 1.727675199508667
Batch 54/64 loss: 1.7296442985534668
Batch 55/64 loss: 1.7296414375305176
Batch 56/64 loss: 1.7276384830474854
Batch 57/64 loss: 1.7455464601516724
Batch 58/64 loss: 1.729274034500122
Batch 59/64 loss: 1.7275629043579102
Batch 60/64 loss: 1.7260785102844238
Batch 61/64 loss: 1.7343015670776367
Batch 62/64 loss: 1.728007435798645
Batch 63/64 loss: 1.726938247680664
Batch 64/64 loss: 1.9070427417755127
Epoch 395  Train loss: 1.7317424802219166  Val loss: 1.745509151740582
Epoch 396
-------------------------------
Batch 1/64 loss: 1.7270052433013916
Batch 2/64 loss: 1.7243739366531372
Batch 3/64 loss: 1.7316410541534424
Batch 4/64 loss: 1.7266712188720703
Batch 5/64 loss: 1.7243552207946777
Batch 6/64 loss: 1.7349460124969482
Batch 7/64 loss: 1.7326782941818237
Batch 8/64 loss: 1.7297627925872803
Batch 9/64 loss: 1.7291110754013062
Batch 10/64 loss: 1.7362027168273926
Batch 11/64 loss: 1.7280406951904297
Batch 12/64 loss: 1.7258648872375488
Batch 13/64 loss: 1.7286505699157715
Batch 14/64 loss: 1.727522373199463
Batch 15/64 loss: 1.7329641580581665
Batch 16/64 loss: 1.7300128936767578
Batch 17/64 loss: 1.7288837432861328
Batch 18/64 loss: 1.7296665906906128
Batch 19/64 loss: 1.7263193130493164
Batch 20/64 loss: 1.726648211479187
Batch 21/64 loss: 1.7317354679107666
Batch 22/64 loss: 1.725167989730835
Batch 23/64 loss: 1.728595495223999
Batch 24/64 loss: 1.7243201732635498
Batch 25/64 loss: 1.7330690622329712
Batch 26/64 loss: 1.7251310348510742
Batch 27/64 loss: 1.7288525104522705
Batch 28/64 loss: 1.748563528060913
Batch 29/64 loss: 1.7284142971038818
Batch 30/64 loss: 1.725279688835144
Batch 31/64 loss: 1.728116512298584
Batch 32/64 loss: 1.7275842428207397
Batch 33/64 loss: 1.7260408401489258
Batch 34/64 loss: 1.726247787475586
Batch 35/64 loss: 1.7254054546356201
Batch 36/64 loss: 1.726994276046753
Batch 37/64 loss: 1.7279208898544312
Batch 38/64 loss: 1.7273237705230713
Batch 39/64 loss: 1.7286522388458252
Batch 40/64 loss: 1.729049563407898
Batch 41/64 loss: 1.7295939922332764
Batch 42/64 loss: 1.7291864156723022
Batch 43/64 loss: 1.7310761213302612
Batch 44/64 loss: 1.7297061681747437
Batch 45/64 loss: 1.73233163356781
Batch 46/64 loss: 1.7265126705169678
Batch 47/64 loss: 1.7240504026412964
Batch 48/64 loss: 1.7302463054656982
Batch 49/64 loss: 1.7275768518447876
Batch 50/64 loss: 1.7360095977783203
Batch 51/64 loss: 1.7347553968429565
Batch 52/64 loss: 1.7316336631774902
Batch 53/64 loss: 1.7358570098876953
Batch 54/64 loss: 1.7338783740997314
Batch 55/64 loss: 1.7287938594818115
Batch 56/64 loss: 1.7345468997955322
Batch 57/64 loss: 1.737330436706543
Batch 58/64 loss: 1.7281103134155273
Batch 59/64 loss: 1.7538541555404663
Batch 60/64 loss: 1.7318308353424072
Batch 61/64 loss: 1.7330563068389893
Batch 62/64 loss: 1.7321594953536987
Batch 63/64 loss: 1.7398664951324463
Batch 64/64 loss: 1.9279420375823975
Epoch 396  Train loss: 1.7325757765302472  Val loss: 1.752795701174392
Epoch 397
-------------------------------
Batch 1/64 loss: 1.73640775680542
Batch 2/64 loss: 1.7301647663116455
Batch 3/64 loss: 1.735426664352417
Batch 4/64 loss: 1.742408275604248
Batch 5/64 loss: 1.730464220046997
Batch 6/64 loss: 1.7376034259796143
Batch 7/64 loss: 1.7313882112503052
Batch 8/64 loss: 1.744613766670227
Batch 9/64 loss: 1.7292066812515259
Batch 10/64 loss: 1.7358038425445557
Batch 11/64 loss: 1.7341423034667969
Batch 12/64 loss: 1.7337110042572021
Batch 13/64 loss: 1.7321679592132568
Batch 14/64 loss: 1.7374303340911865
Batch 15/64 loss: 1.748850703239441
Batch 16/64 loss: 1.7365305423736572
Batch 17/64 loss: 1.7332028150558472
Batch 18/64 loss: 1.7375433444976807
Batch 19/64 loss: 1.7301816940307617
Batch 20/64 loss: 1.7347753047943115
Batch 21/64 loss: 1.7292479276657104
Batch 22/64 loss: 1.7355647087097168
Batch 23/64 loss: 1.7338283061981201
Batch 24/64 loss: 1.7390031814575195
Batch 25/64 loss: 1.7303028106689453
Batch 26/64 loss: 1.7291252613067627
Batch 27/64 loss: 1.7311718463897705
Batch 28/64 loss: 1.7279934883117676
Batch 29/64 loss: 1.7321832180023193
Batch 30/64 loss: 1.7355233430862427
Batch 31/64 loss: 1.7308989763259888
Batch 32/64 loss: 1.7289154529571533
Batch 33/64 loss: 1.731567144393921
Batch 34/64 loss: 1.7251064777374268
Batch 35/64 loss: 1.7409932613372803
Batch 36/64 loss: 1.7558391094207764
Batch 37/64 loss: 1.739372968673706
Batch 38/64 loss: 1.7285313606262207
Batch 39/64 loss: 1.7327382564544678
Batch 40/64 loss: 1.728757619857788
Batch 41/64 loss: 1.7309274673461914
Batch 42/64 loss: 1.7288506031036377
Batch 43/64 loss: 1.7286598682403564
Batch 44/64 loss: 1.734985589981079
Batch 45/64 loss: 1.7278668880462646
Batch 46/64 loss: 1.7306698560714722
Batch 47/64 loss: 1.73452627658844
Batch 48/64 loss: 1.7450523376464844
Batch 49/64 loss: 1.7288930416107178
Batch 50/64 loss: 1.7444982528686523
Batch 51/64 loss: 1.731856346130371
Batch 52/64 loss: 1.7272698879241943
Batch 53/64 loss: 1.730283498764038
Batch 54/64 loss: 1.7422661781311035
Batch 55/64 loss: 1.7392988204956055
Batch 56/64 loss: 1.7465871572494507
Batch 57/64 loss: 1.7356774806976318
Batch 58/64 loss: 1.727116346359253
Batch 59/64 loss: 1.7426214218139648
Batch 60/64 loss: 1.7290397882461548
Batch 61/64 loss: 1.7282941341400146
Batch 62/64 loss: 1.7363038063049316
Batch 63/64 loss: 1.7294230461120605
Batch 64/64 loss: 1.9218852519989014
Epoch 397  Train loss: 1.7364873783261168  Val loss: 1.7544791469049617
Epoch 398
-------------------------------
Batch 1/64 loss: 1.7515859603881836
Batch 2/64 loss: 1.7357439994812012
Batch 3/64 loss: 1.7261852025985718
Batch 4/64 loss: 1.7331750392913818
Batch 5/64 loss: 1.7301905155181885
Batch 6/64 loss: 1.7329130172729492
Batch 7/64 loss: 1.7300312519073486
Batch 8/64 loss: 1.734025239944458
Batch 9/64 loss: 1.7296669483184814
Batch 10/64 loss: 1.7338460683822632
Batch 11/64 loss: 1.7385443449020386
Batch 12/64 loss: 1.7322849035263062
Batch 13/64 loss: 1.7280431985855103
Batch 14/64 loss: 1.728171467781067
Batch 15/64 loss: 1.7279375791549683
Batch 16/64 loss: 1.7277928590774536
Batch 17/64 loss: 1.7583101987838745
Batch 18/64 loss: 1.7300519943237305
Batch 19/64 loss: 1.7287273406982422
Batch 20/64 loss: 1.7320547103881836
Batch 21/64 loss: 1.7346389293670654
Batch 22/64 loss: 1.7311371564865112
Batch 23/64 loss: 1.7332853078842163
Batch 24/64 loss: 1.7305004596710205
Batch 25/64 loss: 1.7254023551940918
Batch 26/64 loss: 1.727819800376892
Batch 27/64 loss: 1.732000470161438
Batch 28/64 loss: 1.7290714979171753
Batch 29/64 loss: 1.746535301208496
Batch 30/64 loss: 1.7277565002441406
Batch 31/64 loss: 1.7242096662521362
Batch 32/64 loss: 1.734740972518921
Batch 33/64 loss: 1.7436840534210205
Batch 34/64 loss: 1.7324318885803223
Batch 35/64 loss: 1.7295805215835571
Batch 36/64 loss: 1.7325400114059448
Batch 37/64 loss: 1.7287120819091797
Batch 38/64 loss: 1.7291004657745361
Batch 39/64 loss: 1.7258083820343018
Batch 40/64 loss: 1.7264983654022217
Batch 41/64 loss: 1.7572726011276245
Batch 42/64 loss: 1.7262288331985474
Batch 43/64 loss: 1.7258539199829102
Batch 44/64 loss: 1.727554440498352
Batch 45/64 loss: 1.7296819686889648
Batch 46/64 loss: 1.7278412580490112
Batch 47/64 loss: 1.731231451034546
Batch 48/64 loss: 1.7277964353561401
Batch 49/64 loss: 1.7340312004089355
Batch 50/64 loss: 1.726447343826294
Batch 51/64 loss: 1.728184700012207
Batch 52/64 loss: 1.7278541326522827
Batch 53/64 loss: 1.7249939441680908
Batch 54/64 loss: 1.7252774238586426
Batch 55/64 loss: 1.7300193309783936
Batch 56/64 loss: 1.7331738471984863
Batch 57/64 loss: 1.7239363193511963
Batch 58/64 loss: 1.7293143272399902
Batch 59/64 loss: 1.740917682647705
Batch 60/64 loss: 1.7282027006149292
Batch 61/64 loss: 1.7248785495758057
Batch 62/64 loss: 1.7298033237457275
Batch 63/64 loss: 1.72760009765625
Batch 64/64 loss: 1.9045578241348267
Epoch 398  Train loss: 1.7335098074931725  Val loss: 1.7451486972599095
Epoch 399
-------------------------------
Batch 1/64 loss: 1.7285492420196533
Batch 2/64 loss: 1.7258927822113037
Batch 3/64 loss: 1.7235658168792725
Batch 4/64 loss: 1.7257039546966553
Batch 5/64 loss: 1.7257673740386963
Batch 6/64 loss: 1.7465722560882568
Batch 7/64 loss: 1.7231335639953613
Batch 8/64 loss: 1.7287601232528687
Batch 9/64 loss: 1.734950304031372
Batch 10/64 loss: 1.738630771636963
Batch 11/64 loss: 1.7245354652404785
Batch 12/64 loss: 1.7267670631408691
Batch 13/64 loss: 1.7231842279434204
Batch 14/64 loss: 1.7253056764602661
Batch 15/64 loss: 1.7296911478042603
Batch 16/64 loss: 1.7282012701034546
Batch 17/64 loss: 1.7267595529556274
Batch 18/64 loss: 1.7262731790542603
Batch 19/64 loss: 1.7269701957702637
Batch 20/64 loss: 1.7249014377593994
Batch 21/64 loss: 1.729806900024414
Batch 22/64 loss: 1.7249001264572144
Batch 23/64 loss: 1.742614507675171
Batch 24/64 loss: 1.7262802124023438
Batch 25/64 loss: 1.7266863584518433
Batch 26/64 loss: 1.7258079051971436
Batch 27/64 loss: 1.727232813835144
Batch 28/64 loss: 1.728927731513977
Batch 29/64 loss: 1.7254467010498047
Batch 30/64 loss: 1.7261279821395874
Batch 31/64 loss: 1.726607084274292
Batch 32/64 loss: 1.7284636497497559
Batch 33/64 loss: 1.7261910438537598
Batch 34/64 loss: 1.7252633571624756
Batch 35/64 loss: 1.7280080318450928
Batch 36/64 loss: 1.7266557216644287
Batch 37/64 loss: 1.723719835281372
Batch 38/64 loss: 1.73110032081604
Batch 39/64 loss: 1.7233664989471436
Batch 40/64 loss: 1.7245068550109863
Batch 41/64 loss: 1.7468775510787964
Batch 42/64 loss: 1.742456078529358
Batch 43/64 loss: 1.7275608777999878
Batch 44/64 loss: 1.731201410293579
Batch 45/64 loss: 1.7276195287704468
Batch 46/64 loss: 1.7296645641326904
Batch 47/64 loss: 1.7312185764312744
Batch 48/64 loss: 1.732654333114624
Batch 49/64 loss: 1.7294917106628418
Batch 50/64 loss: 1.7288587093353271
Batch 51/64 loss: 1.7291861772537231
Batch 52/64 loss: 1.7302886247634888
Batch 53/64 loss: 1.7271088361740112
Batch 54/64 loss: 1.7284832000732422
Batch 55/64 loss: 1.7299067974090576
Batch 56/64 loss: 1.7297500371932983
Batch 57/64 loss: 1.734729290008545
Batch 58/64 loss: 1.7311439514160156
Batch 59/64 loss: 1.7300093173980713
Batch 60/64 loss: 1.7304669618606567
Batch 61/64 loss: 1.725914716720581
Batch 62/64 loss: 1.732623815536499
Batch 63/64 loss: 1.72626793384552
Batch 64/64 loss: 1.9029090404510498
Epoch 399  Train loss: 1.731019510942347  Val loss: 1.7467216322921806
Epoch 400
-------------------------------
Batch 1/64 loss: 1.7527960538864136
Batch 2/64 loss: 1.7291462421417236
Batch 3/64 loss: 1.7317264080047607
Batch 4/64 loss: 1.7271888256072998
Batch 5/64 loss: 1.7250163555145264
Batch 6/64 loss: 1.7291706800460815
Batch 7/64 loss: 1.7257602214813232
Batch 8/64 loss: 1.7290574312210083
Batch 9/64 loss: 1.7259364128112793
Batch 10/64 loss: 1.736100673675537
Batch 11/64 loss: 1.7264701128005981
Batch 12/64 loss: 1.7322468757629395
Batch 13/64 loss: 1.7319421768188477
Batch 14/64 loss: 1.7376627922058105
Batch 15/64 loss: 1.7299264669418335
Batch 16/64 loss: 1.7312321662902832
Batch 17/64 loss: 1.7263264656066895
Batch 18/64 loss: 1.7287672758102417
Batch 19/64 loss: 1.726198434829712
Batch 20/64 loss: 1.7487043142318726
Batch 21/64 loss: 1.7256402969360352
Batch 22/64 loss: 1.7266680002212524
Batch 23/64 loss: 1.7325444221496582
Batch 24/64 loss: 1.728844165802002
Batch 25/64 loss: 1.7275731563568115
Batch 26/64 loss: 1.7277171611785889
Batch 27/64 loss: 1.7243322134017944
Batch 28/64 loss: 1.725273609161377
Batch 29/64 loss: 1.7272453308105469
Batch 30/64 loss: 1.7263171672821045
Batch 31/64 loss: 1.726576805114746
Batch 32/64 loss: 1.7239806652069092
Batch 33/64 loss: 1.7237681150436401
Batch 34/64 loss: 1.7367565631866455
Batch 35/64 loss: 1.7282447814941406
Batch 36/64 loss: 1.7280484437942505
Batch 37/64 loss: 1.7223408222198486
Batch 38/64 loss: 1.7441520690917969
Batch 39/64 loss: 1.7268192768096924
Batch 40/64 loss: 1.732041835784912
Batch 41/64 loss: 1.7239404916763306
Batch 42/64 loss: 1.7350738048553467
Batch 43/64 loss: 1.7312517166137695
Batch 44/64 loss: 1.7248344421386719
Batch 45/64 loss: 1.7261683940887451
Batch 46/64 loss: 1.7350796461105347
Batch 47/64 loss: 1.7287406921386719
Batch 48/64 loss: 1.73063325881958
Batch 49/64 loss: 1.7289929389953613
Batch 50/64 loss: 1.7274775505065918
Batch 51/64 loss: 1.7314709424972534
Batch 52/64 loss: 1.7255444526672363
Batch 53/64 loss: 1.7254847288131714
Batch 54/64 loss: 1.7271270751953125
Batch 55/64 loss: 1.7265136241912842
Batch 56/64 loss: 1.7317008972167969
Batch 57/64 loss: 1.7268497943878174
Batch 58/64 loss: 1.7292282581329346
Batch 59/64 loss: 1.7282686233520508
Batch 60/64 loss: 1.7280807495117188
Batch 61/64 loss: 1.736133337020874
Batch 62/64 loss: 1.7278761863708496
Batch 63/64 loss: 1.7280974388122559
Batch 64/64 loss: 1.9087468385696411
Epoch 400  Train loss: 1.7316453405455048  Val loss: 1.7473936769151197
Epoch 401
-------------------------------
Batch 1/64 loss: 1.7264152765274048
Batch 2/64 loss: 1.7293474674224854
Batch 3/64 loss: 1.730184555053711
Batch 4/64 loss: 1.7290318012237549
Batch 5/64 loss: 1.7272069454193115
Batch 6/64 loss: 1.7331430912017822
Batch 7/64 loss: 1.731748104095459
Batch 8/64 loss: 1.726807713508606
Batch 9/64 loss: 1.731689691543579
Batch 10/64 loss: 1.7296457290649414
Batch 11/64 loss: 1.7275387048721313
Batch 12/64 loss: 1.7293016910552979
Batch 13/64 loss: 1.7272429466247559
Batch 14/64 loss: 1.7322918176651
Batch 15/64 loss: 1.7330293655395508
Batch 16/64 loss: 1.7243523597717285
Batch 17/64 loss: 1.7271318435668945
Batch 18/64 loss: 1.7309200763702393
Batch 19/64 loss: 1.728323221206665
Batch 20/64 loss: 1.7310773134231567
Batch 21/64 loss: 1.7279161214828491
Batch 22/64 loss: 1.7295584678649902
Batch 23/64 loss: 1.7315821647644043
Batch 24/64 loss: 1.728197693824768
Batch 25/64 loss: 1.7291826009750366
Batch 26/64 loss: 1.7271122932434082
Batch 27/64 loss: 1.74170982837677
Batch 28/64 loss: 1.730533242225647
Batch 29/64 loss: 1.7297008037567139
Batch 30/64 loss: 1.7322008609771729
Batch 31/64 loss: 1.72868013381958
Batch 32/64 loss: 1.7282971143722534
Batch 33/64 loss: 1.728585958480835
Batch 34/64 loss: 1.728150725364685
Batch 35/64 loss: 1.7305617332458496
Batch 36/64 loss: 1.7289390563964844
Batch 37/64 loss: 1.731644630432129
Batch 38/64 loss: 1.731829047203064
Batch 39/64 loss: 1.7366650104522705
Batch 40/64 loss: 1.7267332077026367
Batch 41/64 loss: 1.7329363822937012
Batch 42/64 loss: 1.7299730777740479
Batch 43/64 loss: 1.7414627075195312
Batch 44/64 loss: 1.728968620300293
Batch 45/64 loss: 1.7307336330413818
Batch 46/64 loss: 1.7376389503479004
Batch 47/64 loss: 1.7308895587921143
Batch 48/64 loss: 1.727211833000183
Batch 49/64 loss: 1.731519103050232
Batch 50/64 loss: 1.747502088546753
Batch 51/64 loss: 1.7282702922821045
Batch 52/64 loss: 1.7276495695114136
Batch 53/64 loss: 1.7369723320007324
Batch 54/64 loss: 1.7345740795135498
Batch 55/64 loss: 1.7257202863693237
Batch 56/64 loss: 1.729824185371399
Batch 57/64 loss: 1.7282657623291016
Batch 58/64 loss: 1.729412317276001
Batch 59/64 loss: 1.726012110710144
Batch 60/64 loss: 1.7314577102661133
Batch 61/64 loss: 1.7302212715148926
Batch 62/64 loss: 1.7266926765441895
Batch 63/64 loss: 1.7406294345855713
Batch 64/64 loss: 1.9118949174880981
Epoch 401  Train loss: 1.7327477581360762  Val loss: 1.7459510511549068
Epoch 402
-------------------------------
Batch 1/64 loss: 1.7278110980987549
Batch 2/64 loss: 1.7245850563049316
Batch 3/64 loss: 1.7276369333267212
Batch 4/64 loss: 1.7255363464355469
Batch 5/64 loss: 1.7396022081375122
Batch 6/64 loss: 1.7255204916000366
Batch 7/64 loss: 1.7269632816314697
Batch 8/64 loss: 1.7306294441223145
Batch 9/64 loss: 1.7279853820800781
Batch 10/64 loss: 1.7294491529464722
Batch 11/64 loss: 1.7302978038787842
Batch 12/64 loss: 1.7365069389343262
Batch 13/64 loss: 1.7235627174377441
Batch 14/64 loss: 1.7263247966766357
Batch 15/64 loss: 1.7360200881958008
Batch 16/64 loss: 1.7260241508483887
Batch 17/64 loss: 1.72751784324646
Batch 18/64 loss: 1.7273063659667969
Batch 19/64 loss: 1.7326910495758057
Batch 20/64 loss: 1.7352910041809082
Batch 21/64 loss: 1.7316052913665771
Batch 22/64 loss: 1.7282741069793701
Batch 23/64 loss: 1.7275946140289307
Batch 24/64 loss: 1.7327096462249756
Batch 25/64 loss: 1.729258418083191
Batch 26/64 loss: 1.7295567989349365
Batch 27/64 loss: 1.7440662384033203
Batch 28/64 loss: 1.7264058589935303
Batch 29/64 loss: 1.7276278734207153
Batch 30/64 loss: 1.7281066179275513
Batch 31/64 loss: 1.7421340942382812
Batch 32/64 loss: 1.727440595626831
Batch 33/64 loss: 1.7276926040649414
Batch 34/64 loss: 1.7271642684936523
Batch 35/64 loss: 1.7269197702407837
Batch 36/64 loss: 1.726536512374878
Batch 37/64 loss: 1.7280327081680298
Batch 38/64 loss: 1.7260680198669434
Batch 39/64 loss: 1.7286591529846191
Batch 40/64 loss: 1.728910207748413
Batch 41/64 loss: 1.7290735244750977
Batch 42/64 loss: 1.729840874671936
Batch 43/64 loss: 1.7250640392303467
Batch 44/64 loss: 1.7293145656585693
Batch 45/64 loss: 1.7296940088272095
Batch 46/64 loss: 1.7266197204589844
Batch 47/64 loss: 1.7288506031036377
Batch 48/64 loss: 1.7461588382720947
Batch 49/64 loss: 1.724134922027588
Batch 50/64 loss: 1.727123498916626
Batch 51/64 loss: 1.724838137626648
Batch 52/64 loss: 1.7244436740875244
Batch 53/64 loss: 1.725829839706421
Batch 54/64 loss: 1.7261130809783936
Batch 55/64 loss: 1.7250819206237793
Batch 56/64 loss: 1.7268106937408447
Batch 57/64 loss: 1.7281475067138672
Batch 58/64 loss: 1.727980136871338
Batch 59/64 loss: 1.731227159500122
Batch 60/64 loss: 1.7258362770080566
Batch 61/64 loss: 1.728400707244873
Batch 62/64 loss: 1.7263531684875488
Batch 63/64 loss: 1.7254600524902344
Batch 64/64 loss: 1.9067691564559937
Epoch 402  Train loss: 1.7310509705076031  Val loss: 1.7455491200345488
Epoch 403
-------------------------------
Batch 1/64 loss: 1.7288360595703125
Batch 2/64 loss: 1.7263879776000977
Batch 3/64 loss: 1.7257554531097412
Batch 4/64 loss: 1.7261089086532593
Batch 5/64 loss: 1.7268991470336914
Batch 6/64 loss: 1.7326529026031494
Batch 7/64 loss: 1.7248502969741821
Batch 8/64 loss: 1.727816104888916
Batch 9/64 loss: 1.7284996509552002
Batch 10/64 loss: 1.7276252508163452
Batch 11/64 loss: 1.7312161922454834
Batch 12/64 loss: 1.7322945594787598
Batch 13/64 loss: 1.7466611862182617
Batch 14/64 loss: 1.7260217666625977
Batch 15/64 loss: 1.7272725105285645
Batch 16/64 loss: 1.728905439376831
Batch 17/64 loss: 1.7417775392532349
Batch 18/64 loss: 1.7294018268585205
Batch 19/64 loss: 1.7270007133483887
Batch 20/64 loss: 1.730531930923462
Batch 21/64 loss: 1.7285635471343994
Batch 22/64 loss: 1.730794906616211
Batch 23/64 loss: 1.725905418395996
Batch 24/64 loss: 1.7319860458374023
Batch 25/64 loss: 1.7307744026184082
Batch 26/64 loss: 1.7258634567260742
Batch 27/64 loss: 1.7251418828964233
Batch 28/64 loss: 1.7281816005706787
Batch 29/64 loss: 1.726953387260437
Batch 30/64 loss: 1.7286577224731445
Batch 31/64 loss: 1.7292463779449463
Batch 32/64 loss: 1.7381329536437988
Batch 33/64 loss: 1.7308568954467773
Batch 34/64 loss: 1.7282652854919434
Batch 35/64 loss: 1.7282460927963257
Batch 36/64 loss: 1.7273378372192383
Batch 37/64 loss: 1.7315661907196045
Batch 38/64 loss: 1.7251818180084229
Batch 39/64 loss: 1.7326233386993408
Batch 40/64 loss: 1.73183012008667
Batch 41/64 loss: 1.7290937900543213
Batch 42/64 loss: 1.7290821075439453
Batch 43/64 loss: 1.7260626554489136
Batch 44/64 loss: 1.7244884967803955
Batch 45/64 loss: 1.7296602725982666
Batch 46/64 loss: 1.7333879470825195
Batch 47/64 loss: 1.7259235382080078
Batch 48/64 loss: 1.7318274974822998
Batch 49/64 loss: 1.7327277660369873
Batch 50/64 loss: 1.7300862073898315
Batch 51/64 loss: 1.730016827583313
Batch 52/64 loss: 1.7294719219207764
Batch 53/64 loss: 1.7263028621673584
Batch 54/64 loss: 1.7460365295410156
Batch 55/64 loss: 1.7244985103607178
Batch 56/64 loss: 1.7291479110717773
Batch 57/64 loss: 1.726304531097412
Batch 58/64 loss: 1.7260239124298096
Batch 59/64 loss: 1.7333261966705322
Batch 60/64 loss: 1.7290968894958496
Batch 61/64 loss: 1.7257376909255981
Batch 62/64 loss: 1.734910011291504
Batch 63/64 loss: 1.7254281044006348
Batch 64/64 loss: 1.9069217443466187
Epoch 403  Train loss: 1.731630716604345  Val loss: 1.7474246164367782
Epoch 404
-------------------------------
Batch 1/64 loss: 1.7286436557769775
Batch 2/64 loss: 1.7330657243728638
Batch 3/64 loss: 1.7275221347808838
Batch 4/64 loss: 1.7543895244598389
Batch 5/64 loss: 1.730422019958496
Batch 6/64 loss: 1.725832223892212
Batch 7/64 loss: 1.7282471656799316
Batch 8/64 loss: 1.7327616214752197
Batch 9/64 loss: 1.7298275232315063
Batch 10/64 loss: 1.7311148643493652
Batch 11/64 loss: 1.7262649536132812
Batch 12/64 loss: 1.7341468334197998
Batch 13/64 loss: 1.7273838520050049
Batch 14/64 loss: 1.7272133827209473
Batch 15/64 loss: 1.73033607006073
Batch 16/64 loss: 1.72798752784729
Batch 17/64 loss: 1.7329225540161133
Batch 18/64 loss: 1.7276012897491455
Batch 19/64 loss: 1.729266881942749
Batch 20/64 loss: 1.7293742895126343
Batch 21/64 loss: 1.7271356582641602
Batch 22/64 loss: 1.7323945760726929
Batch 23/64 loss: 1.731255292892456
Batch 24/64 loss: 1.7293717861175537
Batch 25/64 loss: 1.7298579216003418
Batch 26/64 loss: 1.7267131805419922
Batch 27/64 loss: 1.7285730838775635
Batch 28/64 loss: 1.7297906875610352
Batch 29/64 loss: 1.730886459350586
Batch 30/64 loss: 1.7259814739227295
Batch 31/64 loss: 1.723965048789978
Batch 32/64 loss: 1.7330172061920166
Batch 33/64 loss: 1.726983666419983
Batch 34/64 loss: 1.729849100112915
Batch 35/64 loss: 1.7268483638763428
Batch 36/64 loss: 1.7241394519805908
Batch 37/64 loss: 1.7282638549804688
Batch 38/64 loss: 1.7393841743469238
Batch 39/64 loss: 1.7291638851165771
Batch 40/64 loss: 1.7386964559555054
Batch 41/64 loss: 1.7295241355895996
Batch 42/64 loss: 1.726309061050415
Batch 43/64 loss: 1.7489218711853027
Batch 44/64 loss: 1.7289211750030518
Batch 45/64 loss: 1.7407938241958618
Batch 46/64 loss: 1.7294237613677979
Batch 47/64 loss: 1.7276813983917236
Batch 48/64 loss: 1.7284979820251465
Batch 49/64 loss: 1.7278003692626953
Batch 50/64 loss: 1.7266931533813477
Batch 51/64 loss: 1.7288764715194702
Batch 52/64 loss: 1.7295129299163818
Batch 53/64 loss: 1.7362339496612549
Batch 54/64 loss: 1.7268630266189575
Batch 55/64 loss: 1.725743055343628
Batch 56/64 loss: 1.725260615348816
Batch 57/64 loss: 1.7268328666687012
Batch 58/64 loss: 1.7398176193237305
Batch 59/64 loss: 1.7294838428497314
Batch 60/64 loss: 1.7278838157653809
Batch 61/64 loss: 1.7257206439971924
Batch 62/64 loss: 1.7282578945159912
Batch 63/64 loss: 1.7277960777282715
Batch 64/64 loss: 1.9163670539855957
Epoch 404  Train loss: 1.7323407098358752  Val loss: 1.7468480334658802
Epoch 405
-------------------------------
Batch 1/64 loss: 1.7258477210998535
Batch 2/64 loss: 1.7256203889846802
Batch 3/64 loss: 1.7279458045959473
Batch 4/64 loss: 1.7278239727020264
Batch 5/64 loss: 1.7284901142120361
Batch 6/64 loss: 1.72540283203125
Batch 7/64 loss: 1.7295153141021729
Batch 8/64 loss: 1.7407798767089844
Batch 9/64 loss: 1.727867603302002
Batch 10/64 loss: 1.7310353517532349
Batch 11/64 loss: 1.7295091152191162
Batch 12/64 loss: 1.7285411357879639
Batch 13/64 loss: 1.726265788078308
Batch 14/64 loss: 1.7270855903625488
Batch 15/64 loss: 1.7271161079406738
Batch 16/64 loss: 1.725757122039795
Batch 17/64 loss: 1.7306983470916748
Batch 18/64 loss: 1.729272484779358
Batch 19/64 loss: 1.7261054515838623
Batch 20/64 loss: 1.7293226718902588
Batch 21/64 loss: 1.7272069454193115
Batch 22/64 loss: 1.7304044961929321
Batch 23/64 loss: 1.7308542728424072
Batch 24/64 loss: 1.7279260158538818
Batch 25/64 loss: 1.730391025543213
Batch 26/64 loss: 1.7303407192230225
Batch 27/64 loss: 1.7270458936691284
Batch 28/64 loss: 1.7294872999191284
Batch 29/64 loss: 1.7302814722061157
Batch 30/64 loss: 1.7305982112884521
Batch 31/64 loss: 1.7275629043579102
Batch 32/64 loss: 1.7260488271713257
Batch 33/64 loss: 1.7255593538284302
Batch 34/64 loss: 1.7241966724395752
Batch 35/64 loss: 1.7299120426177979
Batch 36/64 loss: 1.7324320077896118
Batch 37/64 loss: 1.7272990942001343
Batch 38/64 loss: 1.7285971641540527
Batch 39/64 loss: 1.7269494533538818
Batch 40/64 loss: 1.7264618873596191
Batch 41/64 loss: 1.7294645309448242
Batch 42/64 loss: 1.7364234924316406
Batch 43/64 loss: 1.72789466381073
Batch 44/64 loss: 1.7268824577331543
Batch 45/64 loss: 1.7331002950668335
Batch 46/64 loss: 1.7297987937927246
Batch 47/64 loss: 1.7543061971664429
Batch 48/64 loss: 1.7378026247024536
Batch 49/64 loss: 1.730462670326233
Batch 50/64 loss: 1.7295315265655518
Batch 51/64 loss: 1.727644443511963
Batch 52/64 loss: 1.7329246997833252
Batch 53/64 loss: 1.7286067008972168
Batch 54/64 loss: 1.732359528541565
Batch 55/64 loss: 1.7453391551971436
Batch 56/64 loss: 1.7268011569976807
Batch 57/64 loss: 1.732445478439331
Batch 58/64 loss: 1.7346268892288208
Batch 59/64 loss: 1.7346982955932617
Batch 60/64 loss: 1.7275903224945068
Batch 61/64 loss: 1.7312700748443604
Batch 62/64 loss: 1.7383071184158325
Batch 63/64 loss: 1.7378216981887817
Batch 64/64 loss: 1.9102537631988525
Epoch 405  Train loss: 1.7323663010316737  Val loss: 1.749410181111077
Epoch 406
-------------------------------
Batch 1/64 loss: 1.7355506420135498
Batch 2/64 loss: 1.7324802875518799
Batch 3/64 loss: 1.7340712547302246
Batch 4/64 loss: 1.7305285930633545
Batch 5/64 loss: 1.7293139696121216
Batch 6/64 loss: 1.7405260801315308
Batch 7/64 loss: 1.7289552688598633
Batch 8/64 loss: 1.7504806518554688
Batch 9/64 loss: 1.750553846359253
Batch 10/64 loss: 1.7355835437774658
Batch 11/64 loss: 1.7309761047363281
Batch 12/64 loss: 1.7324966192245483
Batch 13/64 loss: 1.731745958328247
Batch 14/64 loss: 1.7336472272872925
Batch 15/64 loss: 1.7450240850448608
Batch 16/64 loss: 1.7289981842041016
Batch 17/64 loss: 1.729797601699829
Batch 18/64 loss: 1.7329134941101074
Batch 19/64 loss: 1.7334165573120117
Batch 20/64 loss: 1.728621482849121
Batch 21/64 loss: 1.7279376983642578
Batch 22/64 loss: 1.7292685508728027
Batch 23/64 loss: 1.7303109169006348
Batch 24/64 loss: 1.7278119325637817
Batch 25/64 loss: 1.7293612957000732
Batch 26/64 loss: 1.7260239124298096
Batch 27/64 loss: 1.724686861038208
Batch 28/64 loss: 1.7271051406860352
Batch 29/64 loss: 1.7281856536865234
Batch 30/64 loss: 1.7336549758911133
Batch 31/64 loss: 1.7329654693603516
Batch 32/64 loss: 1.725839614868164
Batch 33/64 loss: 1.7256224155426025
Batch 34/64 loss: 1.7265554666519165
Batch 35/64 loss: 1.7235819101333618
Batch 36/64 loss: 1.733174204826355
Batch 37/64 loss: 1.7287442684173584
Batch 38/64 loss: 1.7290875911712646
Batch 39/64 loss: 1.7249683141708374
Batch 40/64 loss: 1.726938009262085
Batch 41/64 loss: 1.726273775100708
Batch 42/64 loss: 1.7279689311981201
Batch 43/64 loss: 1.7306896448135376
Batch 44/64 loss: 1.729507327079773
Batch 45/64 loss: 1.7278993129730225
Batch 46/64 loss: 1.7269926071166992
Batch 47/64 loss: 1.7299144268035889
Batch 48/64 loss: 1.7283689975738525
Batch 49/64 loss: 1.7259678840637207
Batch 50/64 loss: 1.7254739999771118
Batch 51/64 loss: 1.724506139755249
Batch 52/64 loss: 1.7305216789245605
Batch 53/64 loss: 1.7298035621643066
Batch 54/64 loss: 1.7246148586273193
Batch 55/64 loss: 1.7300257682800293
Batch 56/64 loss: 1.7272861003875732
Batch 57/64 loss: 1.7268654108047485
Batch 58/64 loss: 1.7252225875854492
Batch 59/64 loss: 1.7255476713180542
Batch 60/64 loss: 1.7263025045394897
Batch 61/64 loss: 1.728145718574524
Batch 62/64 loss: 1.729912281036377
Batch 63/64 loss: 1.7320537567138672
Batch 64/64 loss: 1.9066920280456543
Epoch 406  Train loss: 1.7321943470076018  Val loss: 1.7454680216681098
Epoch 407
-------------------------------
Batch 1/64 loss: 1.7318634986877441
Batch 2/64 loss: 1.726444125175476
Batch 3/64 loss: 1.7295238971710205
Batch 4/64 loss: 1.7292218208312988
Batch 5/64 loss: 1.7246533632278442
Batch 6/64 loss: 1.7275776863098145
Batch 7/64 loss: 1.7242484092712402
Batch 8/64 loss: 1.7416837215423584
Batch 9/64 loss: 1.7287119626998901
Batch 10/64 loss: 1.7442595958709717
Batch 11/64 loss: 1.738877296447754
Batch 12/64 loss: 1.7258223295211792
Batch 13/64 loss: 1.7326070070266724
Batch 14/64 loss: 1.7298643589019775
Batch 15/64 loss: 1.7310173511505127
Batch 16/64 loss: 1.7295784950256348
Batch 17/64 loss: 1.7282872200012207
Batch 18/64 loss: 1.7256925106048584
Batch 19/64 loss: 1.7239816188812256
Batch 20/64 loss: 1.7279918193817139
Batch 21/64 loss: 1.7434639930725098
Batch 22/64 loss: 1.7282013893127441
Batch 23/64 loss: 1.7252334356307983
Batch 24/64 loss: 1.7261314392089844
Batch 25/64 loss: 1.7275440692901611
Batch 26/64 loss: 1.7254352569580078
Batch 27/64 loss: 1.731688380241394
Batch 28/64 loss: 1.7307751178741455
Batch 29/64 loss: 1.725470781326294
Batch 30/64 loss: 1.7323205471038818
Batch 31/64 loss: 1.7271974086761475
Batch 32/64 loss: 1.7273828983306885
Batch 33/64 loss: 1.7255403995513916
Batch 34/64 loss: 1.7263561487197876
Batch 35/64 loss: 1.7287986278533936
Batch 36/64 loss: 1.7291420698165894
Batch 37/64 loss: 1.7295470237731934
Batch 38/64 loss: 1.7240869998931885
Batch 39/64 loss: 1.7305495738983154
Batch 40/64 loss: 1.7278251647949219
Batch 41/64 loss: 1.7298071384429932
Batch 42/64 loss: 1.7293951511383057
Batch 43/64 loss: 1.7266449928283691
Batch 44/64 loss: 1.72956120967865
Batch 45/64 loss: 1.7262330055236816
Batch 46/64 loss: 1.7236406803131104
Batch 47/64 loss: 1.7275209426879883
Batch 48/64 loss: 1.7276830673217773
Batch 49/64 loss: 1.7290136814117432
Batch 50/64 loss: 1.7288928031921387
Batch 51/64 loss: 1.7274798154830933
Batch 52/64 loss: 1.727367639541626
Batch 53/64 loss: 1.7253987789154053
Batch 54/64 loss: 1.7398879528045654
Batch 55/64 loss: 1.7285678386688232
Batch 56/64 loss: 1.7279174327850342
Batch 57/64 loss: 1.7295722961425781
Batch 58/64 loss: 1.7287964820861816
Batch 59/64 loss: 1.7274421453475952
Batch 60/64 loss: 1.735507845878601
Batch 61/64 loss: 1.732937216758728
Batch 62/64 loss: 1.7295937538146973
Batch 63/64 loss: 1.7257587909698486
Batch 64/64 loss: 1.9072036743164062
Epoch 407  Train loss: 1.7312881918514476  Val loss: 1.7490732743568027
Epoch 408
-------------------------------
Batch 1/64 loss: 1.7306091785430908
Batch 2/64 loss: 1.7278286218643188
Batch 3/64 loss: 1.7294684648513794
Batch 4/64 loss: 1.7346285581588745
Batch 5/64 loss: 1.7329814434051514
Batch 6/64 loss: 1.7303102016448975
Batch 7/64 loss: 1.7257049083709717
Batch 8/64 loss: 1.730358362197876
Batch 9/64 loss: 1.7293341159820557
Batch 10/64 loss: 1.7266700267791748
Batch 11/64 loss: 1.7284886837005615
Batch 12/64 loss: 1.7486424446105957
Batch 13/64 loss: 1.727873682975769
Batch 14/64 loss: 1.7289376258850098
Batch 15/64 loss: 1.7286314964294434
Batch 16/64 loss: 1.7355191707611084
Batch 17/64 loss: 1.7292582988739014
Batch 18/64 loss: 1.7325294017791748
Batch 19/64 loss: 1.7350616455078125
Batch 20/64 loss: 1.7253468036651611
Batch 21/64 loss: 1.7271357774734497
Batch 22/64 loss: 1.7290903329849243
Batch 23/64 loss: 1.7336479425430298
Batch 24/64 loss: 1.7254993915557861
Batch 25/64 loss: 1.7278847694396973
Batch 26/64 loss: 1.7272489070892334
Batch 27/64 loss: 1.7270293235778809
Batch 28/64 loss: 1.7258350849151611
Batch 29/64 loss: 1.739450216293335
Batch 30/64 loss: 1.7290925979614258
Batch 31/64 loss: 1.729351282119751
Batch 32/64 loss: 1.7279884815216064
Batch 33/64 loss: 1.730966567993164
Batch 34/64 loss: 1.7252708673477173
Batch 35/64 loss: 1.7311477661132812
Batch 36/64 loss: 1.7281451225280762
Batch 37/64 loss: 1.732234001159668
Batch 38/64 loss: 1.729043960571289
Batch 39/64 loss: 1.7260730266571045
Batch 40/64 loss: 1.724640130996704
Batch 41/64 loss: 1.7282836437225342
Batch 42/64 loss: 1.7288920879364014
Batch 43/64 loss: 1.7282264232635498
Batch 44/64 loss: 1.7304823398590088
Batch 45/64 loss: 1.7269885540008545
Batch 46/64 loss: 1.7262325286865234
Batch 47/64 loss: 1.7295516729354858
Batch 48/64 loss: 1.7452788352966309
Batch 49/64 loss: 1.7250357866287231
Batch 50/64 loss: 1.7293696403503418
Batch 51/64 loss: 1.726853370666504
Batch 52/64 loss: 1.7305725812911987
Batch 53/64 loss: 1.7256121635437012
Batch 54/64 loss: 1.7262285947799683
Batch 55/64 loss: 1.7266159057617188
Batch 56/64 loss: 1.7267787456512451
Batch 57/64 loss: 1.7328870296478271
Batch 58/64 loss: 1.736145257949829
Batch 59/64 loss: 1.7280347347259521
Batch 60/64 loss: 1.7264564037322998
Batch 61/64 loss: 1.7288031578063965
Batch 62/64 loss: 1.7319049835205078
Batch 63/64 loss: 1.728000521659851
Batch 64/64 loss: 1.910520315170288
Epoch 408  Train loss: 1.7317817080254647  Val loss: 1.7496227382384624
Epoch 409
-------------------------------
Batch 1/64 loss: 1.7311174869537354
Batch 2/64 loss: 1.7315654754638672
Batch 3/64 loss: 1.7334588766098022
Batch 4/64 loss: 1.7277584075927734
Batch 5/64 loss: 1.727323293685913
Batch 6/64 loss: 1.7427568435668945
Batch 7/64 loss: 1.731696367263794
Batch 8/64 loss: 1.736785888671875
Batch 9/64 loss: 1.7315282821655273
Batch 10/64 loss: 1.7351741790771484
Batch 11/64 loss: 1.728501558303833
Batch 12/64 loss: 1.7583085298538208
Batch 13/64 loss: 1.7293341159820557
Batch 14/64 loss: 1.735646367073059
Batch 15/64 loss: 1.7295465469360352
Batch 16/64 loss: 1.7317781448364258
Batch 17/64 loss: 1.7289984226226807
Batch 18/64 loss: 1.731287956237793
Batch 19/64 loss: 1.7312889099121094
Batch 20/64 loss: 1.7299048900604248
Batch 21/64 loss: 1.7305564880371094
Batch 22/64 loss: 1.726318359375
Batch 23/64 loss: 1.730100393295288
Batch 24/64 loss: 1.7275310754776
Batch 25/64 loss: 1.742085576057434
Batch 26/64 loss: 1.7293262481689453
Batch 27/64 loss: 1.734142541885376
Batch 28/64 loss: 1.7315582036972046
Batch 29/64 loss: 1.7288498878479004
Batch 30/64 loss: 1.7295595407485962
Batch 31/64 loss: 1.7302000522613525
Batch 32/64 loss: 1.7416284084320068
Batch 33/64 loss: 1.726514220237732
Batch 34/64 loss: 1.751704454421997
Batch 35/64 loss: 1.7267663478851318
Batch 36/64 loss: 1.7452213764190674
Batch 37/64 loss: 1.7393243312835693
Batch 38/64 loss: 1.7309536933898926
Batch 39/64 loss: 1.7324237823486328
Batch 40/64 loss: 1.7305803298950195
Batch 41/64 loss: 1.7282360792160034
Batch 42/64 loss: 1.72892427444458
Batch 43/64 loss: 1.7285411357879639
Batch 44/64 loss: 1.726609706878662
Batch 45/64 loss: 1.7371349334716797
Batch 46/64 loss: 1.728175163269043
Batch 47/64 loss: 1.7245798110961914
Batch 48/64 loss: 1.7237143516540527
Batch 49/64 loss: 1.730544090270996
Batch 50/64 loss: 1.727853536605835
Batch 51/64 loss: 1.7251367568969727
Batch 52/64 loss: 1.7283692359924316
Batch 53/64 loss: 1.7446807622909546
Batch 54/64 loss: 1.742781162261963
Batch 55/64 loss: 1.7286078929901123
Batch 56/64 loss: 1.7266623973846436
Batch 57/64 loss: 1.7272348403930664
Batch 58/64 loss: 1.7276721000671387
Batch 59/64 loss: 1.7269880771636963
Batch 60/64 loss: 1.7253031730651855
Batch 61/64 loss: 1.7295845746994019
Batch 62/64 loss: 1.7254109382629395
Batch 63/64 loss: 1.729140043258667
Batch 64/64 loss: 1.9123092889785767
Epoch 409  Train loss: 1.7338858487559299  Val loss: 1.7472868866936857
Epoch 410
-------------------------------
Batch 1/64 loss: 1.7308931350708008
Batch 2/64 loss: 1.7295105457305908
Batch 3/64 loss: 1.7331598997116089
Batch 4/64 loss: 1.729079008102417
Batch 5/64 loss: 1.725398063659668
Batch 6/64 loss: 1.746764898300171
Batch 7/64 loss: 1.7321768999099731
Batch 8/64 loss: 1.7381024360656738
Batch 9/64 loss: 1.7433255910873413
Batch 10/64 loss: 1.728171467781067
Batch 11/64 loss: 1.7317391633987427
Batch 12/64 loss: 1.729919672012329
Batch 13/64 loss: 1.7473220825195312
Batch 14/64 loss: 1.7287737131118774
Batch 15/64 loss: 1.7498750686645508
Batch 16/64 loss: 1.7331328392028809
Batch 17/64 loss: 1.7301688194274902
Batch 18/64 loss: 1.7333629131317139
Batch 19/64 loss: 1.7355806827545166
Batch 20/64 loss: 1.7284932136535645
Batch 21/64 loss: 1.7377023696899414
Batch 22/64 loss: 1.7290122509002686
Batch 23/64 loss: 1.7297513484954834
Batch 24/64 loss: 1.7338920831680298
Batch 25/64 loss: 1.735687017440796
Batch 26/64 loss: 1.738452672958374
Batch 27/64 loss: 1.7256407737731934
Batch 28/64 loss: 1.7298369407653809
Batch 29/64 loss: 1.7322320938110352
Batch 30/64 loss: 1.729463815689087
Batch 31/64 loss: 1.7300188541412354
Batch 32/64 loss: 1.7288237810134888
Batch 33/64 loss: 1.7388834953308105
Batch 34/64 loss: 1.7285422086715698
Batch 35/64 loss: 1.7309703826904297
Batch 36/64 loss: 1.733511209487915
Batch 37/64 loss: 1.731399655342102
Batch 38/64 loss: 1.7363804578781128
Batch 39/64 loss: 1.729041337966919
Batch 40/64 loss: 1.731459140777588
Batch 41/64 loss: 1.7278051376342773
Batch 42/64 loss: 1.7342123985290527
Batch 43/64 loss: 1.729132890701294
Batch 44/64 loss: 1.7334469556808472
Batch 45/64 loss: 1.7328494787216187
Batch 46/64 loss: 1.7353147268295288
Batch 47/64 loss: 1.7281522750854492
Batch 48/64 loss: 1.7317230701446533
Batch 49/64 loss: 1.7314307689666748
Batch 50/64 loss: 1.7295300960540771
Batch 51/64 loss: 1.7274682521820068
Batch 52/64 loss: 1.730825424194336
Batch 53/64 loss: 1.730096697807312
Batch 54/64 loss: 1.7336349487304688
Batch 55/64 loss: 1.7274072170257568
Batch 56/64 loss: 1.7307990789413452
Batch 57/64 loss: 1.742210865020752
Batch 58/64 loss: 1.7337727546691895
Batch 59/64 loss: 1.727888584136963
Batch 60/64 loss: 1.7302221059799194
Batch 61/64 loss: 1.7283179759979248
Batch 62/64 loss: 1.7283861637115479
Batch 63/64 loss: 1.732896327972412
Batch 64/64 loss: 1.913304328918457
Epoch 410  Train loss: 1.734559285406973  Val loss: 1.7506246648703243
Epoch 411
-------------------------------
Batch 1/64 loss: 1.7283505201339722
Batch 2/64 loss: 1.729581594467163
Batch 3/64 loss: 1.7312860488891602
Batch 4/64 loss: 1.729064702987671
Batch 5/64 loss: 1.7312870025634766
Batch 6/64 loss: 1.7287163734436035
Batch 7/64 loss: 1.7357566356658936
Batch 8/64 loss: 1.7320761680603027
Batch 9/64 loss: 1.7337183952331543
Batch 10/64 loss: 1.730173110961914
Batch 11/64 loss: 1.7294580936431885
Batch 12/64 loss: 1.7280957698822021
Batch 13/64 loss: 1.7318758964538574
Batch 14/64 loss: 1.7313494682312012
Batch 15/64 loss: 1.7316629886627197
Batch 16/64 loss: 1.7318503856658936
Batch 17/64 loss: 1.730315923690796
Batch 18/64 loss: 1.7320892810821533
Batch 19/64 loss: 1.7285284996032715
Batch 20/64 loss: 1.7301812171936035
Batch 21/64 loss: 1.7284306287765503
Batch 22/64 loss: 1.7525458335876465
Batch 23/64 loss: 1.7285325527191162
Batch 24/64 loss: 1.7300883531570435
Batch 25/64 loss: 1.7301563024520874
Batch 26/64 loss: 1.7488462924957275
Batch 27/64 loss: 1.7285141944885254
Batch 28/64 loss: 1.7275688648223877
Batch 29/64 loss: 1.7276153564453125
Batch 30/64 loss: 1.7287886142730713
Batch 31/64 loss: 1.7284057140350342
Batch 32/64 loss: 1.7318394184112549
Batch 33/64 loss: 1.729665994644165
Batch 34/64 loss: 1.7285772562026978
Batch 35/64 loss: 1.7311402559280396
Batch 36/64 loss: 1.7356882095336914
Batch 37/64 loss: 1.7281699180603027
Batch 38/64 loss: 1.726564884185791
Batch 39/64 loss: 1.727413535118103
Batch 40/64 loss: 1.7303414344787598
Batch 41/64 loss: 1.7260921001434326
Batch 42/64 loss: 1.7300879955291748
Batch 43/64 loss: 1.726808786392212
Batch 44/64 loss: 1.7245221138000488
Batch 45/64 loss: 1.726776123046875
Batch 46/64 loss: 1.7267482280731201
Batch 47/64 loss: 1.7275023460388184
Batch 48/64 loss: 1.7238166332244873
Batch 49/64 loss: 1.725581407546997
Batch 50/64 loss: 1.7268109321594238
Batch 51/64 loss: 1.727354884147644
Batch 52/64 loss: 1.7366416454315186
Batch 53/64 loss: 1.726737380027771
Batch 54/64 loss: 1.7247871160507202
Batch 55/64 loss: 1.7228190898895264
Batch 56/64 loss: 1.7276742458343506
Batch 57/64 loss: 1.7278122901916504
Batch 58/64 loss: 1.7249491214752197
Batch 59/64 loss: 1.7257463932037354
Batch 60/64 loss: 1.7247519493103027
Batch 61/64 loss: 1.7289345264434814
Batch 62/64 loss: 1.7275316715240479
Batch 63/64 loss: 1.7251763343811035
Batch 64/64 loss: 1.905602216720581
Epoch 411  Train loss: 1.7315949281056722  Val loss: 1.744251680538007
Epoch 412
-------------------------------
Batch 1/64 loss: 1.7285007238388062
Batch 2/64 loss: 1.7244994640350342
Batch 3/64 loss: 1.7282142639160156
Batch 4/64 loss: 1.7254865169525146
Batch 5/64 loss: 1.7249755859375
Batch 6/64 loss: 1.730832576751709
Batch 7/64 loss: 1.7258450984954834
Batch 8/64 loss: 1.7391780614852905
Batch 9/64 loss: 1.7262122631072998
Batch 10/64 loss: 1.7258546352386475
Batch 11/64 loss: 1.7252650260925293
Batch 12/64 loss: 1.730247974395752
Batch 13/64 loss: 1.7279515266418457
Batch 14/64 loss: 1.7264511585235596
Batch 15/64 loss: 1.7287685871124268
Batch 16/64 loss: 1.7258529663085938
Batch 17/64 loss: 1.742803931236267
Batch 18/64 loss: 1.728306770324707
Batch 19/64 loss: 1.7280638217926025
Batch 20/64 loss: 1.7279092073440552
Batch 21/64 loss: 1.727851152420044
Batch 22/64 loss: 1.726087212562561
Batch 23/64 loss: 1.7257344722747803
Batch 24/64 loss: 1.722676157951355
Batch 25/64 loss: 1.7256181240081787
Batch 26/64 loss: 1.7293832302093506
Batch 27/64 loss: 1.7249400615692139
Batch 28/64 loss: 1.7355009317398071
Batch 29/64 loss: 1.7507681846618652
Batch 30/64 loss: 1.7250158786773682
Batch 31/64 loss: 1.7287757396697998
Batch 32/64 loss: 1.7259278297424316
Batch 33/64 loss: 1.7297730445861816
Batch 34/64 loss: 1.7257461547851562
Batch 35/64 loss: 1.7331655025482178
Batch 36/64 loss: 1.7252295017242432
Batch 37/64 loss: 1.727313756942749
Batch 38/64 loss: 1.7262568473815918
Batch 39/64 loss: 1.7292747497558594
Batch 40/64 loss: 1.7269268035888672
Batch 41/64 loss: 1.7286722660064697
Batch 42/64 loss: 1.72588050365448
Batch 43/64 loss: 1.7278997898101807
Batch 44/64 loss: 1.7285118103027344
Batch 45/64 loss: 1.731370210647583
Batch 46/64 loss: 1.7291224002838135
Batch 47/64 loss: 1.7341684103012085
Batch 48/64 loss: 1.7331149578094482
Batch 49/64 loss: 1.7302720546722412
Batch 50/64 loss: 1.73216712474823
Batch 51/64 loss: 1.729139804840088
Batch 52/64 loss: 1.7344696521759033
Batch 53/64 loss: 1.7313356399536133
Batch 54/64 loss: 1.73024582862854
Batch 55/64 loss: 1.7297674417495728
Batch 56/64 loss: 1.7290825843811035
Batch 57/64 loss: 1.7422291040420532
Batch 58/64 loss: 1.7325453758239746
Batch 59/64 loss: 1.731557011604309
Batch 60/64 loss: 1.7322869300842285
Batch 61/64 loss: 1.7307220697402954
Batch 62/64 loss: 1.7345879077911377
Batch 63/64 loss: 1.7308696508407593
Batch 64/64 loss: 1.9113593101501465
Epoch 412  Train loss: 1.7317133099425073  Val loss: 1.7477803680904953
Epoch 413
-------------------------------
Batch 1/64 loss: 1.730424165725708
Batch 2/64 loss: 1.7304439544677734
Batch 3/64 loss: 1.7285404205322266
Batch 4/64 loss: 1.7289185523986816
Batch 5/64 loss: 1.7276090383529663
Batch 6/64 loss: 1.7269155979156494
Batch 7/64 loss: 1.7284584045410156
Batch 8/64 loss: 1.728249192237854
Batch 9/64 loss: 1.7271397113800049
Batch 10/64 loss: 1.7420231103897095
Batch 11/64 loss: 1.7253391742706299
Batch 12/64 loss: 1.7260940074920654
Batch 13/64 loss: 1.7271277904510498
Batch 14/64 loss: 1.7275316715240479
Batch 15/64 loss: 1.7253763675689697
Batch 16/64 loss: 1.732994794845581
Batch 17/64 loss: 1.728956937789917
Batch 18/64 loss: 1.7430404424667358
Batch 19/64 loss: 1.7310609817504883
Batch 20/64 loss: 1.73002028465271
Batch 21/64 loss: 1.7302896976470947
Batch 22/64 loss: 1.7295258045196533
Batch 23/64 loss: 1.7360143661499023
Batch 24/64 loss: 1.7285468578338623
Batch 25/64 loss: 1.7340655326843262
Batch 26/64 loss: 1.7269216775894165
Batch 27/64 loss: 1.7322428226470947
Batch 28/64 loss: 1.7276397943496704
Batch 29/64 loss: 1.72663414478302
Batch 30/64 loss: 1.7339088916778564
Batch 31/64 loss: 1.7250008583068848
Batch 32/64 loss: 1.7280685901641846
Batch 33/64 loss: 1.7255768775939941
Batch 34/64 loss: 1.7271690368652344
Batch 35/64 loss: 1.727540135383606
Batch 36/64 loss: 1.7262831926345825
Batch 37/64 loss: 1.7288075685501099
Batch 38/64 loss: 1.7271394729614258
Batch 39/64 loss: 1.7312265634536743
Batch 40/64 loss: 1.7293519973754883
Batch 41/64 loss: 1.7241146564483643
Batch 42/64 loss: 1.7266745567321777
Batch 43/64 loss: 1.7287981510162354
Batch 44/64 loss: 1.7276606559753418
Batch 45/64 loss: 1.7297825813293457
Batch 46/64 loss: 1.7292733192443848
Batch 47/64 loss: 1.7286384105682373
Batch 48/64 loss: 1.7279552221298218
Batch 49/64 loss: 1.7234419584274292
Batch 50/64 loss: 1.727298378944397
Batch 51/64 loss: 1.7326635122299194
Batch 52/64 loss: 1.728947639465332
Batch 53/64 loss: 1.728865385055542
Batch 54/64 loss: 1.7249891757965088
Batch 55/64 loss: 1.7274975776672363
Batch 56/64 loss: 1.7273623943328857
Batch 57/64 loss: 1.7400506734848022
Batch 58/64 loss: 1.7255427837371826
Batch 59/64 loss: 1.7282955646514893
Batch 60/64 loss: 1.7258212566375732
Batch 61/64 loss: 1.726819634437561
Batch 62/64 loss: 1.7268328666687012
Batch 63/64 loss: 1.7268322706222534
Batch 64/64 loss: 1.908433198928833
Epoch 413  Train loss: 1.7310384628819484  Val loss: 1.7446611156987981
Epoch 414
-------------------------------
Batch 1/64 loss: 1.7279937267303467
Batch 2/64 loss: 1.72806978225708
Batch 3/64 loss: 1.732856273651123
Batch 4/64 loss: 1.729569673538208
Batch 5/64 loss: 1.7302422523498535
Batch 6/64 loss: 1.7248103618621826
Batch 7/64 loss: 1.7286076545715332
Batch 8/64 loss: 1.7318089008331299
Batch 9/64 loss: 1.7242345809936523
Batch 10/64 loss: 1.7255520820617676
Batch 11/64 loss: 1.7414697408676147
Batch 12/64 loss: 1.732274055480957
Batch 13/64 loss: 1.746816873550415
Batch 14/64 loss: 1.7283544540405273
Batch 15/64 loss: 1.7297589778900146
Batch 16/64 loss: 1.7283086776733398
Batch 17/64 loss: 1.725832223892212
Batch 18/64 loss: 1.7298039197921753
Batch 19/64 loss: 1.726670742034912
Batch 20/64 loss: 1.7274196147918701
Batch 21/64 loss: 1.7265777587890625
Batch 22/64 loss: 1.7298095226287842
Batch 23/64 loss: 1.7304049730300903
Batch 24/64 loss: 1.7301769256591797
Batch 25/64 loss: 1.7276172637939453
Batch 26/64 loss: 1.7434163093566895
Batch 27/64 loss: 1.726322889328003
Batch 28/64 loss: 1.7291522026062012
Batch 29/64 loss: 1.7270129919052124
Batch 30/64 loss: 1.727508306503296
Batch 31/64 loss: 1.7290810346603394
Batch 32/64 loss: 1.726042628288269
Batch 33/64 loss: 1.73079252243042
Batch 34/64 loss: 1.7263942956924438
Batch 35/64 loss: 1.732722520828247
Batch 36/64 loss: 1.7312097549438477
Batch 37/64 loss: 1.7270491123199463
Batch 38/64 loss: 1.7280433177947998
Batch 39/64 loss: 1.7279891967773438
Batch 40/64 loss: 1.7265567779541016
Batch 41/64 loss: 1.7250828742980957
Batch 42/64 loss: 1.7262818813323975
Batch 43/64 loss: 1.730352520942688
Batch 44/64 loss: 1.7276184558868408
Batch 45/64 loss: 1.7265300750732422
Batch 46/64 loss: 1.724888801574707
Batch 47/64 loss: 1.7248915433883667
Batch 48/64 loss: 1.725489854812622
Batch 49/64 loss: 1.7275307178497314
Batch 50/64 loss: 1.72825288772583
Batch 51/64 loss: 1.7270400524139404
Batch 52/64 loss: 1.7266850471496582
Batch 53/64 loss: 1.7314703464508057
Batch 54/64 loss: 1.725982427597046
Batch 55/64 loss: 1.730699062347412
Batch 56/64 loss: 1.7282804250717163
Batch 57/64 loss: 1.7324745655059814
Batch 58/64 loss: 1.729957103729248
Batch 59/64 loss: 1.7279729843139648
Batch 60/64 loss: 1.7283064126968384
Batch 61/64 loss: 1.7267019748687744
Batch 62/64 loss: 1.7275633811950684
Batch 63/64 loss: 1.7256793975830078
Batch 64/64 loss: 1.9134187698364258
Epoch 414  Train loss: 1.7310608901229558  Val loss: 1.74493965987897
Epoch 415
-------------------------------
Batch 1/64 loss: 1.7293765544891357
Batch 2/64 loss: 1.7264412641525269
Batch 3/64 loss: 1.7326939105987549
Batch 4/64 loss: 1.7268671989440918
Batch 5/64 loss: 1.7264299392700195
Batch 6/64 loss: 1.7233257293701172
Batch 7/64 loss: 1.7289166450500488
Batch 8/64 loss: 1.726324439048767
Batch 9/64 loss: 1.7256065607070923
Batch 10/64 loss: 1.724631667137146
Batch 11/64 loss: 1.7275384664535522
Batch 12/64 loss: 1.7255520820617676
Batch 13/64 loss: 1.727611780166626
Batch 14/64 loss: 1.7271032333374023
Batch 15/64 loss: 1.7276623249053955
Batch 16/64 loss: 1.7245380878448486
Batch 17/64 loss: 1.7469818592071533
Batch 18/64 loss: 1.7279052734375
Batch 19/64 loss: 1.723954439163208
Batch 20/64 loss: 1.727651596069336
Batch 21/64 loss: 1.731079339981079
Batch 22/64 loss: 1.72737455368042
Batch 23/64 loss: 1.7281467914581299
Batch 24/64 loss: 1.7280739545822144
Batch 25/64 loss: 1.7250268459320068
Batch 26/64 loss: 1.7276911735534668
Batch 27/64 loss: 1.7284059524536133
Batch 28/64 loss: 1.7265031337738037
Batch 29/64 loss: 1.728417158126831
Batch 30/64 loss: 1.7292776107788086
Batch 31/64 loss: 1.7303351163864136
Batch 32/64 loss: 1.7248866558074951
Batch 33/64 loss: 1.7234736680984497
Batch 34/64 loss: 1.72514009475708
Batch 35/64 loss: 1.7233858108520508
Batch 36/64 loss: 1.7225451469421387
Batch 37/64 loss: 1.742983102798462
Batch 38/64 loss: 1.7270011901855469
Batch 39/64 loss: 1.7296864986419678
Batch 40/64 loss: 1.724672555923462
Batch 41/64 loss: 1.7242118120193481
Batch 42/64 loss: 1.72679603099823
Batch 43/64 loss: 1.7259182929992676
Batch 44/64 loss: 1.728456735610962
Batch 45/64 loss: 1.7252511978149414
Batch 46/64 loss: 1.7273385524749756
Batch 47/64 loss: 1.741826057434082
Batch 48/64 loss: 1.729020118713379
Batch 49/64 loss: 1.7254319190979004
Batch 50/64 loss: 1.7240899801254272
Batch 51/64 loss: 1.7265396118164062
Batch 52/64 loss: 1.7412199974060059
Batch 53/64 loss: 1.7251229286193848
Batch 54/64 loss: 1.7250330448150635
Batch 55/64 loss: 1.7292392253875732
Batch 56/64 loss: 1.7256786823272705
Batch 57/64 loss: 1.728247046470642
Batch 58/64 loss: 1.7238285541534424
Batch 59/64 loss: 1.7249760627746582
Batch 60/64 loss: 1.725191354751587
Batch 61/64 loss: 1.728515625
Batch 62/64 loss: 1.727365255355835
Batch 63/64 loss: 1.7270468473434448
Batch 64/64 loss: 1.911658525466919
Epoch 415  Train loss: 1.729902874254713  Val loss: 1.7460956794699443
Epoch 416
-------------------------------
Batch 1/64 loss: 1.7289692163467407
Batch 2/64 loss: 1.7318850755691528
Batch 3/64 loss: 1.7244911193847656
Batch 4/64 loss: 1.728581428527832
Batch 5/64 loss: 1.728393316268921
Batch 6/64 loss: 1.7295663356781006
Batch 7/64 loss: 1.7245192527770996
Batch 8/64 loss: 1.7271610498428345
Batch 9/64 loss: 1.7343562841415405
Batch 10/64 loss: 1.7272833585739136
Batch 11/64 loss: 1.7282261848449707
Batch 12/64 loss: 1.7413010597229004
Batch 13/64 loss: 1.7289259433746338
Batch 14/64 loss: 1.731736183166504
Batch 15/64 loss: 1.7259089946746826
Batch 16/64 loss: 1.7285045385360718
Batch 17/64 loss: 1.7281105518341064
Batch 18/64 loss: 1.7305833101272583
Batch 19/64 loss: 1.7325966358184814
Batch 20/64 loss: 1.7300341129302979
Batch 21/64 loss: 1.7311748266220093
Batch 22/64 loss: 1.7258493900299072
Batch 23/64 loss: 1.727129578590393
Batch 24/64 loss: 1.726632833480835
Batch 25/64 loss: 1.7274081707000732
Batch 26/64 loss: 1.7275586128234863
Batch 27/64 loss: 1.725475788116455
Batch 28/64 loss: 1.7524877786636353
Batch 29/64 loss: 1.749027132987976
Batch 30/64 loss: 1.7312419414520264
Batch 31/64 loss: 1.727295994758606
Batch 32/64 loss: 1.727442979812622
Batch 33/64 loss: 1.7254191637039185
Batch 34/64 loss: 1.7287611961364746
Batch 35/64 loss: 1.728142499923706
Batch 36/64 loss: 1.7266898155212402
Batch 37/64 loss: 1.7258567810058594
Batch 38/64 loss: 1.732975959777832
Batch 39/64 loss: 1.724499225616455
Batch 40/64 loss: 1.7308982610702515
Batch 41/64 loss: 1.7266004085540771
Batch 42/64 loss: 1.727431058883667
Batch 43/64 loss: 1.7301909923553467
Batch 44/64 loss: 1.7331695556640625
Batch 45/64 loss: 1.7272608280181885
Batch 46/64 loss: 1.7246899604797363
Batch 47/64 loss: 1.7344348430633545
Batch 48/64 loss: 1.727506399154663
Batch 49/64 loss: 1.7278060913085938
Batch 50/64 loss: 1.7285399436950684
Batch 51/64 loss: 1.7259719371795654
Batch 52/64 loss: 1.7347123622894287
Batch 53/64 loss: 1.7277997732162476
Batch 54/64 loss: 1.726703405380249
Batch 55/64 loss: 1.7261340618133545
Batch 56/64 loss: 1.729358434677124
Batch 57/64 loss: 1.7286665439605713
Batch 58/64 loss: 1.7286930084228516
Batch 59/64 loss: 1.7327780723571777
Batch 60/64 loss: 1.7278337478637695
Batch 61/64 loss: 1.726322889328003
Batch 62/64 loss: 1.7244391441345215
Batch 63/64 loss: 1.7284079790115356
Batch 64/64 loss: 1.9040189981460571
Epoch 416  Train loss: 1.7313971383898865  Val loss: 1.7476002498181005
Epoch 417
-------------------------------
Batch 1/64 loss: 1.7288730144500732
Batch 2/64 loss: 1.7261900901794434
Batch 3/64 loss: 1.7276883125305176
Batch 4/64 loss: 1.7314114570617676
Batch 5/64 loss: 1.7267014980316162
Batch 6/64 loss: 1.7252988815307617
Batch 7/64 loss: 1.7268292903900146
Batch 8/64 loss: 1.7300571203231812
Batch 9/64 loss: 1.7314839363098145
Batch 10/64 loss: 1.735750436782837
Batch 11/64 loss: 1.7279818058013916
Batch 12/64 loss: 1.7370731830596924
Batch 13/64 loss: 1.7283995151519775
Batch 14/64 loss: 1.7287265062332153
Batch 15/64 loss: 1.7285351753234863
Batch 16/64 loss: 1.729943871498108
Batch 17/64 loss: 1.730264663696289
Batch 18/64 loss: 1.7280458211898804
Batch 19/64 loss: 1.7288286685943604
Batch 20/64 loss: 1.7271499633789062
Batch 21/64 loss: 1.7317568063735962
Batch 22/64 loss: 1.7341736555099487
Batch 23/64 loss: 1.7271349430084229
Batch 24/64 loss: 1.7266783714294434
Batch 25/64 loss: 1.735701084136963
Batch 26/64 loss: 1.727616786956787
Batch 27/64 loss: 1.7283196449279785
Batch 28/64 loss: 1.7250196933746338
Batch 29/64 loss: 1.7274017333984375
Batch 30/64 loss: 1.7256317138671875
Batch 31/64 loss: 1.7240548133850098
Batch 32/64 loss: 1.7263283729553223
Batch 33/64 loss: 1.7257832288742065
Batch 34/64 loss: 1.721665382385254
Batch 35/64 loss: 1.737029790878296
Batch 36/64 loss: 1.7248358726501465
Batch 37/64 loss: 1.7243682146072388
Batch 38/64 loss: 1.727500081062317
Batch 39/64 loss: 1.7316608428955078
Batch 40/64 loss: 1.7293787002563477
Batch 41/64 loss: 1.7241746187210083
Batch 42/64 loss: 1.7262442111968994
Batch 43/64 loss: 1.7275110483169556
Batch 44/64 loss: 1.724778652191162
Batch 45/64 loss: 1.7265247106552124
Batch 46/64 loss: 1.725407361984253
Batch 47/64 loss: 1.7255796194076538
Batch 48/64 loss: 1.740287184715271
Batch 49/64 loss: 1.7240535020828247
Batch 50/64 loss: 1.7322652339935303
Batch 51/64 loss: 1.7294740676879883
Batch 52/64 loss: 1.7280664443969727
Batch 53/64 loss: 1.7293671369552612
Batch 54/64 loss: 1.7263927459716797
Batch 55/64 loss: 1.7315369844436646
Batch 56/64 loss: 1.7273931503295898
Batch 57/64 loss: 1.7485105991363525
Batch 58/64 loss: 1.7283356189727783
Batch 59/64 loss: 1.7296299934387207
Batch 60/64 loss: 1.7251195907592773
Batch 61/64 loss: 1.7285079956054688
Batch 62/64 loss: 1.7243967056274414
Batch 63/64 loss: 1.7352752685546875
Batch 64/64 loss: 1.905790090560913
Epoch 417  Train loss: 1.730908987568874  Val loss: 1.74406898963902
Epoch 418
-------------------------------
Batch 1/64 loss: 1.7302508354187012
Batch 2/64 loss: 1.724825143814087
Batch 3/64 loss: 1.74233078956604
Batch 4/64 loss: 1.7311475276947021
Batch 5/64 loss: 1.7246580123901367
Batch 6/64 loss: 1.7299110889434814
Batch 7/64 loss: 1.726135015487671
Batch 8/64 loss: 1.7270804643630981
Batch 9/64 loss: 1.725050926208496
Batch 10/64 loss: 1.7261152267456055
Batch 11/64 loss: 1.7280917167663574
Batch 12/64 loss: 1.7280818223953247
Batch 13/64 loss: 1.7252157926559448
Batch 14/64 loss: 1.7272791862487793
Batch 15/64 loss: 1.725778341293335
Batch 16/64 loss: 1.7314960956573486
Batch 17/64 loss: 1.7260339260101318
Batch 18/64 loss: 1.7266860008239746
Batch 19/64 loss: 1.727265477180481
Batch 20/64 loss: 1.7246025800704956
Batch 21/64 loss: 1.7248976230621338
Batch 22/64 loss: 1.7266812324523926
Batch 23/64 loss: 1.7284902334213257
Batch 24/64 loss: 1.725292682647705
Batch 25/64 loss: 1.7259447574615479
Batch 26/64 loss: 1.7233710289001465
Batch 27/64 loss: 1.728717565536499
Batch 28/64 loss: 1.7252286672592163
Batch 29/64 loss: 1.7295243740081787
Batch 30/64 loss: 1.7462832927703857
Batch 31/64 loss: 1.7319669723510742
Batch 32/64 loss: 1.7265245914459229
Batch 33/64 loss: 1.727465033531189
Batch 34/64 loss: 1.7273881435394287
Batch 35/64 loss: 1.7298551797866821
Batch 36/64 loss: 1.7323205471038818
Batch 37/64 loss: 1.7407760620117188
Batch 38/64 loss: 1.7269508838653564
Batch 39/64 loss: 1.7262632846832275
Batch 40/64 loss: 1.7267334461212158
Batch 41/64 loss: 1.727370023727417
Batch 42/64 loss: 1.7256381511688232
Batch 43/64 loss: 1.731269359588623
Batch 44/64 loss: 1.7254178524017334
Batch 45/64 loss: 1.7281808853149414
Batch 46/64 loss: 1.7225391864776611
Batch 47/64 loss: 1.7307298183441162
Batch 48/64 loss: 1.7368874549865723
Batch 49/64 loss: 1.7242567539215088
Batch 50/64 loss: 1.7231135368347168
Batch 51/64 loss: 1.7250092029571533
Batch 52/64 loss: 1.7260549068450928
Batch 53/64 loss: 1.7267956733703613
Batch 54/64 loss: 1.7293330430984497
Batch 55/64 loss: 1.7264206409454346
Batch 56/64 loss: 1.724437952041626
Batch 57/64 loss: 1.7259256839752197
Batch 58/64 loss: 1.7247005701065063
Batch 59/64 loss: 1.726266622543335
Batch 60/64 loss: 1.7294442653656006
Batch 61/64 loss: 1.730541706085205
Batch 62/64 loss: 1.7287042140960693
Batch 63/64 loss: 1.7272653579711914
Batch 64/64 loss: 1.905473232269287
Epoch 418  Train loss: 1.7301038330676508  Val loss: 1.7461639794287402
Epoch 419
-------------------------------
Batch 1/64 loss: 1.7271897792816162
Batch 2/64 loss: 1.7315905094146729
Batch 3/64 loss: 1.7245845794677734
Batch 4/64 loss: 1.7288551330566406
Batch 5/64 loss: 1.7357513904571533
Batch 6/64 loss: 1.7261929512023926
Batch 7/64 loss: 1.730351209640503
Batch 8/64 loss: 1.723022222518921
Batch 9/64 loss: 1.7273571491241455
Batch 10/64 loss: 1.7279518842697144
Batch 11/64 loss: 1.7260677814483643
Batch 12/64 loss: 1.7262548208236694
Batch 13/64 loss: 1.725130319595337
Batch 14/64 loss: 1.7291409969329834
Batch 15/64 loss: 1.7258291244506836
Batch 16/64 loss: 1.7302687168121338
Batch 17/64 loss: 1.7253847122192383
Batch 18/64 loss: 1.7267639636993408
Batch 19/64 loss: 1.7257859706878662
Batch 20/64 loss: 1.7281031608581543
Batch 21/64 loss: 1.7252068519592285
Batch 22/64 loss: 1.7241432666778564
Batch 23/64 loss: 1.7252566814422607
Batch 24/64 loss: 1.7277052402496338
Batch 25/64 loss: 1.7244999408721924
Batch 26/64 loss: 1.7288154363632202
Batch 27/64 loss: 1.7260394096374512
Batch 28/64 loss: 1.728498101234436
Batch 29/64 loss: 1.7279108762741089
Batch 30/64 loss: 1.7230641841888428
Batch 31/64 loss: 1.729006052017212
Batch 32/64 loss: 1.7254884243011475
Batch 33/64 loss: 1.72636079788208
Batch 34/64 loss: 1.7285385131835938
Batch 35/64 loss: 1.7277579307556152
Batch 36/64 loss: 1.721071720123291
Batch 37/64 loss: 1.7294833660125732
Batch 38/64 loss: 1.7498350143432617
Batch 39/64 loss: 1.72615385055542
Batch 40/64 loss: 1.7256228923797607
Batch 41/64 loss: 1.725163459777832
Batch 42/64 loss: 1.7308521270751953
Batch 43/64 loss: 1.723171353340149
Batch 44/64 loss: 1.756211280822754
Batch 45/64 loss: 1.7254080772399902
Batch 46/64 loss: 1.724361777305603
Batch 47/64 loss: 1.7296457290649414
Batch 48/64 loss: 1.7253563404083252
Batch 49/64 loss: 1.732292890548706
Batch 50/64 loss: 1.726255178451538
Batch 51/64 loss: 1.7269058227539062
Batch 52/64 loss: 1.7292466163635254
Batch 53/64 loss: 1.7250018119812012
Batch 54/64 loss: 1.72542405128479
Batch 55/64 loss: 1.734952449798584
Batch 56/64 loss: 1.7269618511199951
Batch 57/64 loss: 1.727109670639038
Batch 58/64 loss: 1.7283217906951904
Batch 59/64 loss: 1.7259771823883057
Batch 60/64 loss: 1.7262275218963623
Batch 61/64 loss: 1.7253599166870117
Batch 62/64 loss: 1.7268701791763306
Batch 63/64 loss: 1.7273893356323242
Batch 64/64 loss: 1.9065383672714233
Epoch 419  Train loss: 1.729982825354034  Val loss: 1.7430051659390688
Saving best model, epoch: 419
Epoch 420
-------------------------------
Batch 1/64 loss: 1.7254211902618408
Batch 2/64 loss: 1.725921869277954
Batch 3/64 loss: 1.7312242984771729
Batch 4/64 loss: 1.7252707481384277
Batch 5/64 loss: 1.7259142398834229
Batch 6/64 loss: 1.7281160354614258
Batch 7/64 loss: 1.7250925302505493
Batch 8/64 loss: 1.7271640300750732
Batch 9/64 loss: 1.727264165878296
Batch 10/64 loss: 1.7252084016799927
Batch 11/64 loss: 1.7268339395523071
Batch 12/64 loss: 1.730865716934204
Batch 13/64 loss: 1.7270643711090088
Batch 14/64 loss: 1.7255749702453613
Batch 15/64 loss: 1.7451627254486084
Batch 16/64 loss: 1.7252047061920166
Batch 17/64 loss: 1.7280051708221436
Batch 18/64 loss: 1.7246983051300049
Batch 19/64 loss: 1.7255706787109375
Batch 20/64 loss: 1.7269245386123657
Batch 21/64 loss: 1.7285020351409912
Batch 22/64 loss: 1.7265849113464355
Batch 23/64 loss: 1.7320375442504883
Batch 24/64 loss: 1.7263641357421875
Batch 25/64 loss: 1.728695034980774
Batch 26/64 loss: 1.7309343814849854
Batch 27/64 loss: 1.7256991863250732
Batch 28/64 loss: 1.7235736846923828
Batch 29/64 loss: 1.7240338325500488
Batch 30/64 loss: 1.7259068489074707
Batch 31/64 loss: 1.729256510734558
Batch 32/64 loss: 1.725300669670105
Batch 33/64 loss: 1.7255644798278809
Batch 34/64 loss: 1.7407581806182861
Batch 35/64 loss: 1.7247166633605957
Batch 36/64 loss: 1.725769281387329
Batch 37/64 loss: 1.7247780561447144
Batch 38/64 loss: 1.7255990505218506
Batch 39/64 loss: 1.7257769107818604
Batch 40/64 loss: 1.7287288904190063
Batch 41/64 loss: 1.7284026145935059
Batch 42/64 loss: 1.7287943363189697
Batch 43/64 loss: 1.7244762182235718
Batch 44/64 loss: 1.7293975353240967
Batch 45/64 loss: 1.7246520519256592
Batch 46/64 loss: 1.722398281097412
Batch 47/64 loss: 1.740354061126709
Batch 48/64 loss: 1.7267494201660156
Batch 49/64 loss: 1.7263498306274414
Batch 50/64 loss: 1.7273671627044678
Batch 51/64 loss: 1.7312371730804443
Batch 52/64 loss: 1.7228755950927734
Batch 53/64 loss: 1.727763295173645
Batch 54/64 loss: 1.7306984663009644
Batch 55/64 loss: 1.7268610000610352
Batch 56/64 loss: 1.7293858528137207
Batch 57/64 loss: 1.7276537418365479
Batch 58/64 loss: 1.731896162033081
Batch 59/64 loss: 1.726872444152832
Batch 60/64 loss: 1.7289314270019531
Batch 61/64 loss: 1.7281110286712646
Batch 62/64 loss: 1.726641297340393
Batch 63/64 loss: 1.7290103435516357
Batch 64/64 loss: 1.9049795866012573
Epoch 420  Train loss: 1.7298305403952505  Val loss: 1.7437480716770868
Epoch 421
-------------------------------
Batch 1/64 loss: 1.7290534973144531
Batch 2/64 loss: 1.7277164459228516
Batch 3/64 loss: 1.7287088632583618
Batch 4/64 loss: 1.727635145187378
Batch 5/64 loss: 1.7274962663650513
Batch 6/64 loss: 1.7257308959960938
Batch 7/64 loss: 1.7300032377243042
Batch 8/64 loss: 1.7293381690979004
Batch 9/64 loss: 1.7286629676818848
Batch 10/64 loss: 1.7463699579238892
Batch 11/64 loss: 1.7262225151062012
Batch 12/64 loss: 1.7273876667022705
Batch 13/64 loss: 1.7277541160583496
Batch 14/64 loss: 1.731292486190796
Batch 15/64 loss: 1.7316172122955322
Batch 16/64 loss: 1.7295489311218262
Batch 17/64 loss: 1.7282294034957886
Batch 18/64 loss: 1.7298465967178345
Batch 19/64 loss: 1.7308071851730347
Batch 20/64 loss: 1.7266910076141357
Batch 21/64 loss: 1.7275505065917969
Batch 22/64 loss: 1.7284832000732422
Batch 23/64 loss: 1.728236436843872
Batch 24/64 loss: 1.7259690761566162
Batch 25/64 loss: 1.7349088191986084
Batch 26/64 loss: 1.7252204418182373
Batch 27/64 loss: 1.7290058135986328
Batch 28/64 loss: 1.727752447128296
Batch 29/64 loss: 1.727898359298706
Batch 30/64 loss: 1.7294127941131592
Batch 31/64 loss: 1.7279131412506104
Batch 32/64 loss: 1.7288148403167725
Batch 33/64 loss: 1.7340384721755981
Batch 34/64 loss: 1.728888988494873
Batch 35/64 loss: 1.7271780967712402
Batch 36/64 loss: 1.7278029918670654
Batch 37/64 loss: 1.726866364479065
Batch 38/64 loss: 1.7279359102249146
Batch 39/64 loss: 1.9070336818695068
Batch 40/64 loss: 1.741722583770752
Batch 41/64 loss: 1.7392131090164185
Batch 42/64 loss: 1.7430708408355713
Batch 43/64 loss: 1.7449712753295898
Batch 44/64 loss: 1.7357113361358643
Batch 45/64 loss: 1.7417197227478027
Batch 46/64 loss: 1.739640712738037
Batch 47/64 loss: 1.7365481853485107
Batch 48/64 loss: 1.739995002746582
Batch 49/64 loss: 1.7362116575241089
Batch 50/64 loss: 1.7349976301193237
Batch 51/64 loss: 1.7381622791290283
Batch 52/64 loss: 1.7369887828826904
Batch 53/64 loss: 1.734866738319397
Batch 54/64 loss: 1.7534458637237549
Batch 55/64 loss: 1.7414591312408447
Batch 56/64 loss: 1.7376949787139893
Batch 57/64 loss: 1.7379932403564453
Batch 58/64 loss: 1.746917486190796
Batch 59/64 loss: 1.7362966537475586
Batch 60/64 loss: 1.7360907793045044
Batch 61/64 loss: 1.7330279350280762
Batch 62/64 loss: 1.7358185052871704
Batch 63/64 loss: 1.742419719696045
Batch 64/64 loss: 1.934554100036621
Epoch 421  Train loss: 1.7381478066537894  Val loss: 1.7556860086434485
Epoch 422
-------------------------------
Batch 1/64 loss: 1.7363742589950562
Batch 2/64 loss: 1.74688720703125
Batch 3/64 loss: 1.736944556236267
Batch 4/64 loss: 1.7381290197372437
Batch 5/64 loss: 1.7419750690460205
Batch 6/64 loss: 1.7449302673339844
Batch 7/64 loss: 1.7432355880737305
Batch 8/64 loss: 1.7378146648406982
Batch 9/64 loss: 1.7788474559783936
Batch 10/64 loss: 1.7548203468322754
Batch 11/64 loss: 1.7414506673812866
Batch 12/64 loss: 1.756676197052002
Batch 13/64 loss: 1.7657839059829712
Batch 14/64 loss: 1.753386378288269
Batch 15/64 loss: 1.7544550895690918
Batch 16/64 loss: 1.7457715272903442
Batch 17/64 loss: 1.7636100053787231
Batch 18/64 loss: 1.75669264793396
Batch 19/64 loss: 1.7379823923110962
Batch 20/64 loss: 1.7403385639190674
Batch 21/64 loss: 1.7454378604888916
Batch 22/64 loss: 1.7354907989501953
Batch 23/64 loss: 1.7455434799194336
Batch 24/64 loss: 1.7446637153625488
Batch 25/64 loss: 1.745151400566101
Batch 26/64 loss: 1.7411023378372192
Batch 27/64 loss: 1.7364614009857178
Batch 28/64 loss: 1.7434920072555542
Batch 29/64 loss: 1.7494943141937256
Batch 30/64 loss: 1.7377827167510986
Batch 31/64 loss: 1.7656502723693848
Batch 32/64 loss: 1.7414259910583496
Batch 33/64 loss: 1.7563762664794922
Batch 34/64 loss: 1.734339952468872
Batch 35/64 loss: 1.7381088733673096
Batch 36/64 loss: 1.7625291347503662
Batch 37/64 loss: 1.7392159700393677
Batch 38/64 loss: 1.7387335300445557
Batch 39/64 loss: 1.7348201274871826
Batch 40/64 loss: 1.7387127876281738
Batch 41/64 loss: 1.7408607006072998
Batch 42/64 loss: 1.7344424724578857
Batch 43/64 loss: 1.7329998016357422
Batch 44/64 loss: 1.7336167097091675
Batch 45/64 loss: 1.7420096397399902
Batch 46/64 loss: 1.7323851585388184
Batch 47/64 loss: 1.7478210926055908
Batch 48/64 loss: 1.7430856227874756
Batch 49/64 loss: 1.7401509284973145
Batch 50/64 loss: 1.7463648319244385
Batch 51/64 loss: 1.7450944185256958
Batch 52/64 loss: 1.7334502935409546
Batch 53/64 loss: 1.7397429943084717
Batch 54/64 loss: 1.732209324836731
Batch 55/64 loss: 1.7382209300994873
Batch 56/64 loss: 1.7319796085357666
Batch 57/64 loss: 1.7351925373077393
Batch 58/64 loss: 1.7363975048065186
Batch 59/64 loss: 1.7380836009979248
Batch 60/64 loss: 1.7362589836120605
Batch 61/64 loss: 1.7342441082000732
Batch 62/64 loss: 1.7338811159133911
Batch 63/64 loss: 1.7483131885528564
Batch 64/64 loss: 1.9194343090057373
Epoch 422  Train loss: 1.7453650203405642  Val loss: 1.7512099152987766
Epoch 423
-------------------------------
Batch 1/64 loss: 1.7345528602600098
Batch 2/64 loss: 1.7452635765075684
Batch 3/64 loss: 1.7322540283203125
Batch 4/64 loss: 1.7505266666412354
Batch 5/64 loss: 1.7331113815307617
Batch 6/64 loss: 1.7324302196502686
Batch 7/64 loss: 1.7312356233596802
Batch 8/64 loss: 1.7472319602966309
Batch 9/64 loss: 1.732065200805664
Batch 10/64 loss: 1.7329944372177124
Batch 11/64 loss: 1.7321035861968994
Batch 12/64 loss: 1.7314741611480713
Batch 13/64 loss: 1.7338159084320068
Batch 14/64 loss: 1.7321662902832031
Batch 15/64 loss: 1.7315342426300049
Batch 16/64 loss: 1.7266151905059814
Batch 17/64 loss: 1.729635238647461
Batch 18/64 loss: 1.7317314147949219
Batch 19/64 loss: 1.7324440479278564
Batch 20/64 loss: 1.7349095344543457
Batch 21/64 loss: 1.728602647781372
Batch 22/64 loss: 1.7289960384368896
Batch 23/64 loss: 1.729471206665039
Batch 24/64 loss: 1.7359325885772705
Batch 25/64 loss: 1.7288100719451904
Batch 26/64 loss: 1.7300307750701904
Batch 27/64 loss: 1.7338306903839111
Batch 28/64 loss: 1.731109857559204
Batch 29/64 loss: 1.7296581268310547
Batch 30/64 loss: 1.7282376289367676
Batch 31/64 loss: 1.768261432647705
Batch 32/64 loss: 1.7305463552474976
Batch 33/64 loss: 1.733234167098999
Batch 34/64 loss: 1.7321175336837769
Batch 35/64 loss: 1.7300286293029785
Batch 36/64 loss: 1.7325444221496582
Batch 37/64 loss: 1.7345181703567505
Batch 38/64 loss: 1.7358558177947998
Batch 39/64 loss: 1.74857497215271
Batch 40/64 loss: 1.733749270439148
Batch 41/64 loss: 1.7319914102554321
Batch 42/64 loss: 1.729363203048706
Batch 43/64 loss: 1.7381229400634766
Batch 44/64 loss: 1.7325949668884277
Batch 45/64 loss: 1.732109546661377
Batch 46/64 loss: 1.7373113632202148
Batch 47/64 loss: 1.7328753471374512
Batch 48/64 loss: 1.745615005493164
Batch 49/64 loss: 1.739501953125
Batch 50/64 loss: 1.7315200567245483
Batch 51/64 loss: 1.7286487817764282
Batch 52/64 loss: 1.7341570854187012
Batch 53/64 loss: 1.7313997745513916
Batch 54/64 loss: 1.7440533638000488
Batch 55/64 loss: 1.7311650514602661
Batch 56/64 loss: 1.7353415489196777
Batch 57/64 loss: 1.7341814041137695
Batch 58/64 loss: 1.7312700748443604
Batch 59/64 loss: 1.7280237674713135
Batch 60/64 loss: 1.7444589138031006
Batch 61/64 loss: 1.7322092056274414
Batch 62/64 loss: 1.7313008308410645
Batch 63/64 loss: 1.7390241622924805
Batch 64/64 loss: 1.9095557928085327
Epoch 423  Train loss: 1.7364801972520119  Val loss: 1.749090494568815
Epoch 424
-------------------------------
Batch 1/64 loss: 1.7337791919708252
Batch 2/64 loss: 1.730647087097168
Batch 3/64 loss: 1.729691982269287
Batch 4/64 loss: 1.728816032409668
Batch 5/64 loss: 1.7441469430923462
Batch 6/64 loss: 1.7296273708343506
Batch 7/64 loss: 1.733938217163086
Batch 8/64 loss: 1.7448339462280273
Batch 9/64 loss: 1.7334935665130615
Batch 10/64 loss: 1.740321159362793
Batch 11/64 loss: 1.7269171476364136
Batch 12/64 loss: 1.7386908531188965
Batch 13/64 loss: 1.7307755947113037
Batch 14/64 loss: 1.7367217540740967
Batch 15/64 loss: 1.742269515991211
Batch 16/64 loss: 1.7286142110824585
Batch 17/64 loss: 1.7262779474258423
Batch 18/64 loss: 1.7314040660858154
Batch 19/64 loss: 1.7296109199523926
Batch 20/64 loss: 1.7292518615722656
Batch 21/64 loss: 1.7350449562072754
Batch 22/64 loss: 1.7420575618743896
Batch 23/64 loss: 1.7272319793701172
Batch 24/64 loss: 1.7313644886016846
Batch 25/64 loss: 1.730529546737671
Batch 26/64 loss: 1.7314410209655762
Batch 27/64 loss: 1.7376867532730103
Batch 28/64 loss: 1.7299740314483643
Batch 29/64 loss: 1.7300394773483276
Batch 30/64 loss: 1.729943037033081
Batch 31/64 loss: 1.7314479351043701
Batch 32/64 loss: 1.7302082777023315
Batch 33/64 loss: 1.7254310846328735
Batch 34/64 loss: 1.728122353553772
Batch 35/64 loss: 1.7272112369537354
Batch 36/64 loss: 1.726567029953003
Batch 37/64 loss: 1.7255926132202148
Batch 38/64 loss: 1.7273170948028564
Batch 39/64 loss: 1.7268697023391724
Batch 40/64 loss: 1.7274820804595947
Batch 41/64 loss: 1.7288222312927246
Batch 42/64 loss: 1.7276723384857178
Batch 43/64 loss: 1.7259716987609863
Batch 44/64 loss: 1.7296099662780762
Batch 45/64 loss: 1.7274658679962158
Batch 46/64 loss: 1.7277332544326782
Batch 47/64 loss: 1.7292556762695312
Batch 48/64 loss: 1.7287776470184326
Batch 49/64 loss: 1.727351188659668
Batch 50/64 loss: 1.7288708686828613
Batch 51/64 loss: 1.7272844314575195
Batch 52/64 loss: 1.726860761642456
Batch 53/64 loss: 1.7255151271820068
Batch 54/64 loss: 1.7468335628509521
Batch 55/64 loss: 1.7319443225860596
Batch 56/64 loss: 1.7298928499221802
Batch 57/64 loss: 1.7270381450653076
Batch 58/64 loss: 1.7285664081573486
Batch 59/64 loss: 1.7282202243804932
Batch 60/64 loss: 1.7256567478179932
Batch 61/64 loss: 1.7273647785186768
Batch 62/64 loss: 1.7271910905838013
Batch 63/64 loss: 1.7314400672912598
Batch 64/64 loss: 1.9071645736694336
Epoch 424  Train loss: 1.7328173226001216  Val loss: 1.746787960177025
Epoch 425
-------------------------------
Batch 1/64 loss: 1.730369210243225
Batch 2/64 loss: 1.728378176689148
Batch 3/64 loss: 1.7242077589035034
Batch 4/64 loss: 1.7296723127365112
Batch 5/64 loss: 1.728405237197876
Batch 6/64 loss: 1.7227643728256226
Batch 7/64 loss: 1.727869987487793
Batch 8/64 loss: 1.7314543724060059
Batch 9/64 loss: 1.7312806844711304
Batch 10/64 loss: 1.725106954574585
Batch 11/64 loss: 1.7309346199035645
Batch 12/64 loss: 1.7286369800567627
Batch 13/64 loss: 1.72537362575531
Batch 14/64 loss: 1.729713797569275
Batch 15/64 loss: 1.7276527881622314
Batch 16/64 loss: 1.725898027420044
Batch 17/64 loss: 1.7268428802490234
Batch 18/64 loss: 1.732548713684082
Batch 19/64 loss: 1.746320128440857
Batch 20/64 loss: 1.7489216327667236
Batch 21/64 loss: 1.728163242340088
Batch 22/64 loss: 1.7369780540466309
Batch 23/64 loss: 1.7282086610794067
Batch 24/64 loss: 1.728684902191162
Batch 25/64 loss: 1.7299429178237915
Batch 26/64 loss: 1.728467583656311
Batch 27/64 loss: 1.7254078388214111
Batch 28/64 loss: 1.7257882356643677
Batch 29/64 loss: 1.7288239002227783
Batch 30/64 loss: 1.727874755859375
Batch 31/64 loss: 1.7270519733428955
Batch 32/64 loss: 1.7370680570602417
Batch 33/64 loss: 1.72810697555542
Batch 34/64 loss: 1.7273192405700684
Batch 35/64 loss: 1.734668254852295
Batch 36/64 loss: 1.735598087310791
Batch 37/64 loss: 1.7289339303970337
Batch 38/64 loss: 1.732412576675415
Batch 39/64 loss: 1.7347091436386108
Batch 40/64 loss: 1.750131607055664
Batch 41/64 loss: 1.7320293188095093
Batch 42/64 loss: 1.729186773300171
Batch 43/64 loss: 1.7313439846038818
Batch 44/64 loss: 1.7302049398422241
Batch 45/64 loss: 1.7297025918960571
Batch 46/64 loss: 1.7336006164550781
Batch 47/64 loss: 1.7297812700271606
Batch 48/64 loss: 1.7300599813461304
Batch 49/64 loss: 1.7300701141357422
Batch 50/64 loss: 1.729722499847412
Batch 51/64 loss: 1.7293646335601807
Batch 52/64 loss: 1.7323029041290283
Batch 53/64 loss: 1.728814959526062
Batch 54/64 loss: 1.7300658226013184
Batch 55/64 loss: 1.7433528900146484
Batch 56/64 loss: 1.7309796810150146
Batch 57/64 loss: 1.732461929321289
Batch 58/64 loss: 1.7357760667800903
Batch 59/64 loss: 1.7306318283081055
Batch 60/64 loss: 1.7287688255310059
Batch 61/64 loss: 1.7288165092468262
Batch 62/64 loss: 1.7266638278961182
Batch 63/64 loss: 1.7387428283691406
Batch 64/64 loss: 1.908825397491455
Epoch 425  Train loss: 1.733031467362946  Val loss: 1.745195189702142
Epoch 426
-------------------------------
Batch 1/64 loss: 1.7272186279296875
Batch 2/64 loss: 1.7298656702041626
Batch 3/64 loss: 1.726930856704712
Batch 4/64 loss: 1.7498492002487183
Batch 5/64 loss: 1.728666067123413
Batch 6/64 loss: 1.7314414978027344
Batch 7/64 loss: 1.7286696434020996
Batch 8/64 loss: 1.7270084619522095
Batch 9/64 loss: 1.7270913124084473
Batch 10/64 loss: 1.7433903217315674
Batch 11/64 loss: 1.7263610363006592
Batch 12/64 loss: 1.7299586534500122
Batch 13/64 loss: 1.7436940670013428
Batch 14/64 loss: 1.7336328029632568
Batch 15/64 loss: 1.7306996583938599
Batch 16/64 loss: 1.7305858135223389
Batch 17/64 loss: 1.7265875339508057
Batch 18/64 loss: 1.7296662330627441
Batch 19/64 loss: 1.736369252204895
Batch 20/64 loss: 1.7267346382141113
Batch 21/64 loss: 1.7296274900436401
Batch 22/64 loss: 1.732844591140747
Batch 23/64 loss: 1.7258599996566772
Batch 24/64 loss: 1.73414945602417
Batch 25/64 loss: 1.728129267692566
Batch 26/64 loss: 1.7322232723236084
Batch 27/64 loss: 1.7337913513183594
Batch 28/64 loss: 1.7289440631866455
Batch 29/64 loss: 1.7304980754852295
Batch 30/64 loss: 1.7268562316894531
Batch 31/64 loss: 1.7259968519210815
Batch 32/64 loss: 1.726671814918518
Batch 33/64 loss: 1.7289798259735107
Batch 34/64 loss: 1.735594630241394
Batch 35/64 loss: 1.730219841003418
Batch 36/64 loss: 1.729589819908142
Batch 37/64 loss: 1.7328901290893555
Batch 38/64 loss: 1.7333314418792725
Batch 39/64 loss: 1.753108024597168
Batch 40/64 loss: 1.7307664155960083
Batch 41/64 loss: 1.728318691253662
Batch 42/64 loss: 1.7315728664398193
Batch 43/64 loss: 1.728551983833313
Batch 44/64 loss: 1.7317805290222168
Batch 45/64 loss: 1.7260982990264893
Batch 46/64 loss: 1.7299820184707642
Batch 47/64 loss: 1.729907751083374
Batch 48/64 loss: 1.7299394607543945
Batch 49/64 loss: 1.7296892404556274
Batch 50/64 loss: 1.7271207571029663
Batch 51/64 loss: 1.7341418266296387
Batch 52/64 loss: 1.728698492050171
Batch 53/64 loss: 1.733373761177063
Batch 54/64 loss: 1.7278940677642822
Batch 55/64 loss: 1.7277915477752686
Batch 56/64 loss: 1.7285621166229248
Batch 57/64 loss: 1.7304487228393555
Batch 58/64 loss: 1.7300186157226562
Batch 59/64 loss: 1.726003885269165
Batch 60/64 loss: 1.7351067066192627
Batch 61/64 loss: 1.7358324527740479
Batch 62/64 loss: 1.7360293865203857
Batch 63/64 loss: 1.7310398817062378
Batch 64/64 loss: 1.908571720123291
Epoch 426  Train loss: 1.7332364830316283  Val loss: 1.7463720492071302
Epoch 427
-------------------------------
Batch 1/64 loss: 1.7299270629882812
Batch 2/64 loss: 1.7256932258605957
Batch 3/64 loss: 1.7420330047607422
Batch 4/64 loss: 1.7267687320709229
Batch 5/64 loss: 1.7302528619766235
Batch 6/64 loss: 1.7306582927703857
Batch 7/64 loss: 1.7292401790618896
Batch 8/64 loss: 1.7285820245742798
Batch 9/64 loss: 1.7350387573242188
Batch 10/64 loss: 1.7270426750183105
Batch 11/64 loss: 1.7264485359191895
Batch 12/64 loss: 1.7318960428237915
Batch 13/64 loss: 1.7285637855529785
Batch 14/64 loss: 1.7273311614990234
Batch 15/64 loss: 1.7282683849334717
Batch 16/64 loss: 1.7267674207687378
Batch 17/64 loss: 1.724339246749878
Batch 18/64 loss: 1.7268537282943726
Batch 19/64 loss: 1.7249057292938232
Batch 20/64 loss: 1.7298005819320679
Batch 21/64 loss: 1.726914882659912
Batch 22/64 loss: 1.7293062210083008
Batch 23/64 loss: 1.7277969121932983
Batch 24/64 loss: 1.7283334732055664
Batch 25/64 loss: 1.7248928546905518
Batch 26/64 loss: 1.7372641563415527
Batch 27/64 loss: 1.7288031578063965
Batch 28/64 loss: 1.7324068546295166
Batch 29/64 loss: 1.7259101867675781
Batch 30/64 loss: 1.7298787832260132
Batch 31/64 loss: 1.729749083518982
Batch 32/64 loss: 1.734209656715393
Batch 33/64 loss: 1.7383767366409302
Batch 34/64 loss: 1.7269303798675537
Batch 35/64 loss: 1.7341207265853882
Batch 36/64 loss: 1.7312078475952148
Batch 37/64 loss: 1.7421895265579224
Batch 38/64 loss: 1.7498652935028076
Batch 39/64 loss: 1.730473518371582
Batch 40/64 loss: 1.7275385856628418
Batch 41/64 loss: 1.7396423816680908
Batch 42/64 loss: 1.72941255569458
Batch 43/64 loss: 1.7336326837539673
Batch 44/64 loss: 1.7275872230529785
Batch 45/64 loss: 1.7274658679962158
Batch 46/64 loss: 1.7286748886108398
Batch 47/64 loss: 1.7316055297851562
Batch 48/64 loss: 1.7491365671157837
Batch 49/64 loss: 1.7323853969573975
Batch 50/64 loss: 1.7245100736618042
Batch 51/64 loss: 1.729910135269165
Batch 52/64 loss: 1.7276289463043213
Batch 53/64 loss: 1.7325899600982666
Batch 54/64 loss: 1.7294895648956299
Batch 55/64 loss: 1.7297712564468384
Batch 56/64 loss: 1.7277240753173828
Batch 57/64 loss: 1.7316219806671143
Batch 58/64 loss: 1.7299201488494873
Batch 59/64 loss: 1.727522373199463
Batch 60/64 loss: 1.734678030014038
Batch 61/64 loss: 1.7278845310211182
Batch 62/64 loss: 1.7294297218322754
Batch 63/64 loss: 1.7300260066986084
Batch 64/64 loss: 1.9060907363891602
Epoch 427  Train loss: 1.7326807564380122  Val loss: 1.746274744112467
Epoch 428
-------------------------------
Batch 1/64 loss: 1.7299964427947998
Batch 2/64 loss: 1.7309837341308594
Batch 3/64 loss: 1.7296490669250488
Batch 4/64 loss: 1.7285916805267334
Batch 5/64 loss: 1.7291772365570068
Batch 6/64 loss: 1.7294914722442627
Batch 7/64 loss: 1.7289063930511475
Batch 8/64 loss: 1.7284560203552246
Batch 9/64 loss: 1.7269423007965088
Batch 10/64 loss: 1.7305834293365479
Batch 11/64 loss: 1.7391152381896973
Batch 12/64 loss: 1.7372336387634277
Batch 13/64 loss: 1.7322356700897217
Batch 14/64 loss: 1.7310829162597656
Batch 15/64 loss: 1.7269141674041748
Batch 16/64 loss: 1.7274342775344849
Batch 17/64 loss: 1.7285516262054443
Batch 18/64 loss: 1.7260844707489014
Batch 19/64 loss: 1.7251219749450684
Batch 20/64 loss: 1.7375717163085938
Batch 21/64 loss: 1.7369602918624878
Batch 22/64 loss: 1.7272560596466064
Batch 23/64 loss: 1.7311909198760986
Batch 24/64 loss: 1.7317240238189697
Batch 25/64 loss: 1.7287954092025757
Batch 26/64 loss: 1.7333769798278809
Batch 27/64 loss: 1.7334904670715332
Batch 28/64 loss: 1.7275018692016602
Batch 29/64 loss: 1.72676682472229
Batch 30/64 loss: 1.7298252582550049
Batch 31/64 loss: 1.7308497428894043
Batch 32/64 loss: 1.7284011840820312
Batch 33/64 loss: 1.7258955240249634
Batch 34/64 loss: 1.7358375787734985
Batch 35/64 loss: 1.729182481765747
Batch 36/64 loss: 1.7250614166259766
Batch 37/64 loss: 1.7297195196151733
Batch 38/64 loss: 1.731377363204956
Batch 39/64 loss: 1.7315956354141235
Batch 40/64 loss: 1.7274837493896484
Batch 41/64 loss: 1.7422902584075928
Batch 42/64 loss: 1.7294878959655762
Batch 43/64 loss: 1.7334797382354736
Batch 44/64 loss: 1.7279382944107056
Batch 45/64 loss: 1.7304761409759521
Batch 46/64 loss: 1.7307507991790771
Batch 47/64 loss: 1.7326990365982056
Batch 48/64 loss: 1.7296829223632812
Batch 49/64 loss: 1.7338573932647705
Batch 50/64 loss: 1.7394946813583374
Batch 51/64 loss: 1.7305970191955566
Batch 52/64 loss: 1.7330201864242554
Batch 53/64 loss: 1.759239673614502
Batch 54/64 loss: 1.7297019958496094
Batch 55/64 loss: 1.7323843240737915
Batch 56/64 loss: 1.7390272617340088
Batch 57/64 loss: 1.7279465198516846
Batch 58/64 loss: 1.7289456129074097
Batch 59/64 loss: 1.7285841703414917
Batch 60/64 loss: 1.7282568216323853
Batch 61/64 loss: 1.7295994758605957
Batch 62/64 loss: 1.7282240390777588
Batch 63/64 loss: 1.7308059930801392
Batch 64/64 loss: 1.9101815223693848
Epoch 428  Train loss: 1.733263406566545  Val loss: 1.7499454963657863
Epoch 429
-------------------------------
Batch 1/64 loss: 1.7295119762420654
Batch 2/64 loss: 1.7322149276733398
Batch 3/64 loss: 1.7313017845153809
Batch 4/64 loss: 1.730039358139038
Batch 5/64 loss: 1.7349228858947754
Batch 6/64 loss: 1.7316913604736328
Batch 7/64 loss: 1.7342764139175415
Batch 8/64 loss: 1.725395679473877
Batch 9/64 loss: 1.730614423751831
Batch 10/64 loss: 1.7269904613494873
Batch 11/64 loss: 1.7335739135742188
Batch 12/64 loss: 1.7284326553344727
Batch 13/64 loss: 1.7313116788864136
Batch 14/64 loss: 1.7285263538360596
Batch 15/64 loss: 1.7293723821640015
Batch 16/64 loss: 1.7299818992614746
Batch 17/64 loss: 1.7311798334121704
Batch 18/64 loss: 1.7278244495391846
Batch 19/64 loss: 1.731600046157837
Batch 20/64 loss: 1.7306857109069824
Batch 21/64 loss: 1.7361897230148315
Batch 22/64 loss: 1.7289175987243652
Batch 23/64 loss: 1.7291450500488281
Batch 24/64 loss: 1.7309833765029907
Batch 25/64 loss: 1.7251049280166626
Batch 26/64 loss: 1.7266846895217896
Batch 27/64 loss: 1.7262492179870605
Batch 28/64 loss: 1.7274036407470703
Batch 29/64 loss: 1.7256479263305664
Batch 30/64 loss: 1.7252050638198853
Batch 31/64 loss: 1.747954249382019
Batch 32/64 loss: 1.7284241914749146
Batch 33/64 loss: 1.727015733718872
Batch 34/64 loss: 1.7277315855026245
Batch 35/64 loss: 1.7293282747268677
Batch 36/64 loss: 1.727553367614746
Batch 37/64 loss: 1.729306697845459
Batch 38/64 loss: 1.726423740386963
Batch 39/64 loss: 1.7353997230529785
Batch 40/64 loss: 1.7254204750061035
Batch 41/64 loss: 1.7252289056777954
Batch 42/64 loss: 1.731504201889038
Batch 43/64 loss: 1.725239872932434
Batch 44/64 loss: 1.740236520767212
Batch 45/64 loss: 1.7426927089691162
Batch 46/64 loss: 1.731202483177185
Batch 47/64 loss: 1.7303595542907715
Batch 48/64 loss: 1.7279295921325684
Batch 49/64 loss: 1.7281363010406494
Batch 50/64 loss: 1.7253553867340088
Batch 51/64 loss: 1.726819634437561
Batch 52/64 loss: 1.7286605834960938
Batch 53/64 loss: 1.7300680875778198
Batch 54/64 loss: 1.7314274311065674
Batch 55/64 loss: 1.7287335395812988
Batch 56/64 loss: 1.7301123142242432
Batch 57/64 loss: 1.7267483472824097
Batch 58/64 loss: 1.7295483350753784
Batch 59/64 loss: 1.733262538909912
Batch 60/64 loss: 1.7308355569839478
Batch 61/64 loss: 1.730832815170288
Batch 62/64 loss: 1.7346575260162354
Batch 63/64 loss: 1.7270176410675049
Batch 64/64 loss: 1.912707805633545
Epoch 429  Train loss: 1.7321831871481503  Val loss: 1.7467320571650344
Epoch 430
-------------------------------
Batch 1/64 loss: 1.732077956199646
Batch 2/64 loss: 1.7335811853408813
Batch 3/64 loss: 1.7297027111053467
Batch 4/64 loss: 1.7296499013900757
Batch 5/64 loss: 1.7281215190887451
Batch 6/64 loss: 1.7258648872375488
Batch 7/64 loss: 1.72902250289917
Batch 8/64 loss: 1.7283906936645508
Batch 9/64 loss: 1.727649211883545
Batch 10/64 loss: 1.7316818237304688
Batch 11/64 loss: 1.7250070571899414
Batch 12/64 loss: 1.7266249656677246
Batch 13/64 loss: 1.7279021739959717
Batch 14/64 loss: 1.7324542999267578
Batch 15/64 loss: 1.7313287258148193
Batch 16/64 loss: 1.7307755947113037
Batch 17/64 loss: 1.7318549156188965
Batch 18/64 loss: 1.7278022766113281
Batch 19/64 loss: 1.7274258136749268
Batch 20/64 loss: 1.729257583618164
Batch 21/64 loss: 1.7252761125564575
Batch 22/64 loss: 1.7320300340652466
Batch 23/64 loss: 1.7269301414489746
Batch 24/64 loss: 1.7284905910491943
Batch 25/64 loss: 1.7276616096496582
Batch 26/64 loss: 1.7279281616210938
Batch 27/64 loss: 1.7451187372207642
Batch 28/64 loss: 1.7277028560638428
Batch 29/64 loss: 1.7273082733154297
Batch 30/64 loss: 1.7270691394805908
Batch 31/64 loss: 1.7254376411437988
Batch 32/64 loss: 1.7281172275543213
Batch 33/64 loss: 1.7297687530517578
Batch 34/64 loss: 1.7333734035491943
Batch 35/64 loss: 1.7297029495239258
Batch 36/64 loss: 1.733382225036621
Batch 37/64 loss: 1.727118968963623
Batch 38/64 loss: 1.7263954877853394
Batch 39/64 loss: 1.726881980895996
Batch 40/64 loss: 1.7350623607635498
Batch 41/64 loss: 1.748360276222229
Batch 42/64 loss: 1.7414071559906006
Batch 43/64 loss: 1.7275002002716064
Batch 44/64 loss: 1.7291953563690186
Batch 45/64 loss: 1.7261581420898438
Batch 46/64 loss: 1.7274823188781738
Batch 47/64 loss: 1.7273445129394531
Batch 48/64 loss: 1.7336947917938232
Batch 49/64 loss: 1.7302793264389038
Batch 50/64 loss: 1.7275347709655762
Batch 51/64 loss: 1.7256591320037842
Batch 52/64 loss: 1.7303080558776855
Batch 53/64 loss: 1.7324053049087524
Batch 54/64 loss: 1.7284197807312012
Batch 55/64 loss: 1.7273948192596436
Batch 56/64 loss: 1.727181077003479
Batch 57/64 loss: 1.734546184539795
Batch 58/64 loss: 1.7268567085266113
Batch 59/64 loss: 1.728198766708374
Batch 60/64 loss: 1.7343213558197021
Batch 61/64 loss: 1.7271153926849365
Batch 62/64 loss: 1.725990653038025
Batch 63/64 loss: 1.7343159914016724
Batch 64/64 loss: 1.9105610847473145
Epoch 430  Train loss: 1.7319454641903147  Val loss: 1.7461453631161825
Epoch 431
-------------------------------
Batch 1/64 loss: 1.7278602123260498
Batch 2/64 loss: 1.7277568578720093
Batch 3/64 loss: 1.730571985244751
Batch 4/64 loss: 1.7260076999664307
Batch 5/64 loss: 1.7324730157852173
Batch 6/64 loss: 1.7325836420059204
Batch 7/64 loss: 1.726161003112793
Batch 8/64 loss: 1.726641297340393
Batch 9/64 loss: 1.7295255661010742
Batch 10/64 loss: 1.7246625423431396
Batch 11/64 loss: 1.731276512145996
Batch 12/64 loss: 1.7257814407348633
Batch 13/64 loss: 1.7278475761413574
Batch 14/64 loss: 1.7274081707000732
Batch 15/64 loss: 1.7289435863494873
Batch 16/64 loss: 1.7334656715393066
Batch 17/64 loss: 1.7273869514465332
Batch 18/64 loss: 1.729783535003662
Batch 19/64 loss: 1.7287236452102661
Batch 20/64 loss: 1.7284982204437256
Batch 21/64 loss: 1.728151559829712
Batch 22/64 loss: 1.7280182838439941
Batch 23/64 loss: 1.7265973091125488
Batch 24/64 loss: 1.7292859554290771
Batch 25/64 loss: 1.7349300384521484
Batch 26/64 loss: 1.7313337326049805
Batch 27/64 loss: 1.7265597581863403
Batch 28/64 loss: 1.7275879383087158
Batch 29/64 loss: 1.7290468215942383
Batch 30/64 loss: 1.72467041015625
Batch 31/64 loss: 1.7262003421783447
Batch 32/64 loss: 1.7257740497589111
Batch 33/64 loss: 1.7257728576660156
Batch 34/64 loss: 1.7242565155029297
Batch 35/64 loss: 1.7317469120025635
Batch 36/64 loss: 1.7265040874481201
Batch 37/64 loss: 1.7298051118850708
Batch 38/64 loss: 1.7288529872894287
Batch 39/64 loss: 1.733008861541748
Batch 40/64 loss: 1.7420318126678467
Batch 41/64 loss: 1.727745771408081
Batch 42/64 loss: 1.7296078205108643
Batch 43/64 loss: 1.7311110496520996
Batch 44/64 loss: 1.735960841178894
Batch 45/64 loss: 1.730605125427246
Batch 46/64 loss: 1.7289748191833496
Batch 47/64 loss: 1.7431946992874146
Batch 48/64 loss: 1.7270119190216064
Batch 49/64 loss: 1.7329130172729492
Batch 50/64 loss: 1.7328081130981445
Batch 51/64 loss: 1.7289235591888428
Batch 52/64 loss: 1.7276642322540283
Batch 53/64 loss: 1.729385256767273
Batch 54/64 loss: 1.7308764457702637
Batch 55/64 loss: 1.7302364110946655
Batch 56/64 loss: 1.7287393808364868
Batch 57/64 loss: 1.7335714101791382
Batch 58/64 loss: 1.7284259796142578
Batch 59/64 loss: 1.747058629989624
Batch 60/64 loss: 1.730905532836914
Batch 61/64 loss: 1.7300549745559692
Batch 62/64 loss: 1.7322273254394531
Batch 63/64 loss: 1.7307645082473755
Batch 64/64 loss: 1.924903154373169
Epoch 431  Train loss: 1.7321715869155585  Val loss: 1.7488492665831576
Epoch 432
-------------------------------
Batch 1/64 loss: 1.7301965951919556
Batch 2/64 loss: 1.7371535301208496
Batch 3/64 loss: 1.7331464290618896
Batch 4/64 loss: 1.7314995527267456
Batch 5/64 loss: 1.7286386489868164
Batch 6/64 loss: 1.7320871353149414
Batch 7/64 loss: 1.7319612503051758
Batch 8/64 loss: 1.7326762676239014
Batch 9/64 loss: 1.7338595390319824
Batch 10/64 loss: 1.728906273841858
Batch 11/64 loss: 1.7320303916931152
Batch 12/64 loss: 1.731501817703247
Batch 13/64 loss: 1.7261344194412231
Batch 14/64 loss: 1.727747917175293
Batch 15/64 loss: 1.7264974117279053
Batch 16/64 loss: 1.7269999980926514
Batch 17/64 loss: 1.7255573272705078
Batch 18/64 loss: 1.7293646335601807
Batch 19/64 loss: 1.7336266040802002
Batch 20/64 loss: 1.731006145477295
Batch 21/64 loss: 1.732798457145691
Batch 22/64 loss: 1.7288342714309692
Batch 23/64 loss: 1.731558918952942
Batch 24/64 loss: 1.727418065071106
Batch 25/64 loss: 1.7281315326690674
Batch 26/64 loss: 1.7359728813171387
Batch 27/64 loss: 1.728522539138794
Batch 28/64 loss: 1.7312180995941162
Batch 29/64 loss: 1.7289693355560303
Batch 30/64 loss: 1.7277209758758545
Batch 31/64 loss: 1.7360289096832275
Batch 32/64 loss: 1.7291030883789062
Batch 33/64 loss: 1.7285100221633911
Batch 34/64 loss: 1.7287821769714355
Batch 35/64 loss: 1.7271389961242676
Batch 36/64 loss: 1.7351139783859253
Batch 37/64 loss: 1.7349518537521362
Batch 38/64 loss: 1.728687047958374
Batch 39/64 loss: 1.7300057411193848
Batch 40/64 loss: 1.7262823581695557
Batch 41/64 loss: 1.7308194637298584
Batch 42/64 loss: 1.72606360912323
Batch 43/64 loss: 1.7251802682876587
Batch 44/64 loss: 1.7266759872436523
Batch 45/64 loss: 1.7355046272277832
Batch 46/64 loss: 1.7284948825836182
Batch 47/64 loss: 1.7256131172180176
Batch 48/64 loss: 1.7277086973190308
Batch 49/64 loss: 1.7393152713775635
Batch 50/64 loss: 1.7286107540130615
Batch 51/64 loss: 1.7424497604370117
Batch 52/64 loss: 1.7272679805755615
Batch 53/64 loss: 1.7259042263031006
Batch 54/64 loss: 1.736262321472168
Batch 55/64 loss: 1.726698875427246
Batch 56/64 loss: 1.7269866466522217
Batch 57/64 loss: 1.7267152070999146
Batch 58/64 loss: 1.7281315326690674
Batch 59/64 loss: 1.7236638069152832
Batch 60/64 loss: 1.7252917289733887
Batch 61/64 loss: 1.7316677570343018
Batch 62/64 loss: 1.7287421226501465
Batch 63/64 loss: 1.7469370365142822
Batch 64/64 loss: 1.9081213474273682
Epoch 432  Train loss: 1.7323629463420194  Val loss: 1.745974853686041
Epoch 433
-------------------------------
Batch 1/64 loss: 1.731999397277832
Batch 2/64 loss: 1.7280032634735107
Batch 3/64 loss: 1.7276296615600586
Batch 4/64 loss: 1.7312568426132202
Batch 5/64 loss: 1.7271655797958374
Batch 6/64 loss: 1.7318408489227295
Batch 7/64 loss: 1.727683663368225
Batch 8/64 loss: 1.7258660793304443
Batch 9/64 loss: 1.7377618551254272
Batch 10/64 loss: 1.7276806831359863
Batch 11/64 loss: 1.728689432144165
Batch 12/64 loss: 1.728525161743164
Batch 13/64 loss: 1.7240018844604492
Batch 14/64 loss: 1.7272956371307373
Batch 15/64 loss: 1.7403357028961182
Batch 16/64 loss: 1.7310106754302979
Batch 17/64 loss: 1.728003978729248
Batch 18/64 loss: 1.7283682823181152
Batch 19/64 loss: 1.7245960235595703
Batch 20/64 loss: 1.7304856777191162
Batch 21/64 loss: 1.728068470954895
Batch 22/64 loss: 1.7356514930725098
Batch 23/64 loss: 1.728333830833435
Batch 24/64 loss: 1.7351100444793701
Batch 25/64 loss: 1.7274000644683838
Batch 26/64 loss: 1.7272069454193115
Batch 27/64 loss: 1.729900598526001
Batch 28/64 loss: 1.7250211238861084
Batch 29/64 loss: 1.7291250228881836
Batch 30/64 loss: 1.7311089038848877
Batch 31/64 loss: 1.7267372608184814
Batch 32/64 loss: 1.725522518157959
Batch 33/64 loss: 1.7277239561080933
Batch 34/64 loss: 1.7257753610610962
Batch 35/64 loss: 1.741515874862671
Batch 36/64 loss: 1.731784462928772
Batch 37/64 loss: 1.7251646518707275
Batch 38/64 loss: 1.7335922718048096
Batch 39/64 loss: 1.7258771657943726
Batch 40/64 loss: 1.7323148250579834
Batch 41/64 loss: 1.7302486896514893
Batch 42/64 loss: 1.7266831398010254
Batch 43/64 loss: 1.7275612354278564
Batch 44/64 loss: 1.728703498840332
Batch 45/64 loss: 1.726889967918396
Batch 46/64 loss: 1.7244336605072021
Batch 47/64 loss: 1.7260081768035889
Batch 48/64 loss: 1.7261555194854736
Batch 49/64 loss: 1.7247376441955566
Batch 50/64 loss: 1.7285830974578857
Batch 51/64 loss: 1.7275011539459229
Batch 52/64 loss: 1.724604845046997
Batch 53/64 loss: 1.7277287244796753
Batch 54/64 loss: 1.7295928001403809
Batch 55/64 loss: 1.7282384634017944
Batch 56/64 loss: 1.7307955026626587
Batch 57/64 loss: 1.7257394790649414
Batch 58/64 loss: 1.727752447128296
Batch 59/64 loss: 1.7331604957580566
Batch 60/64 loss: 1.7286885976791382
Batch 61/64 loss: 1.7300922870635986
Batch 62/64 loss: 1.7317748069763184
Batch 63/64 loss: 1.7438080310821533
Batch 64/64 loss: 1.9108221530914307
Epoch 433  Train loss: 1.7313526910894057  Val loss: 1.748426099823103
Epoch 434
-------------------------------
Batch 1/64 loss: 1.727410078048706
Batch 2/64 loss: 1.7294771671295166
Batch 3/64 loss: 1.7293469905853271
Batch 4/64 loss: 1.72576904296875
Batch 5/64 loss: 1.7283440828323364
Batch 6/64 loss: 1.725102424621582
Batch 7/64 loss: 1.7384512424468994
Batch 8/64 loss: 1.7267253398895264
Batch 9/64 loss: 1.7244501113891602
Batch 10/64 loss: 1.7305502891540527
Batch 11/64 loss: 1.7307820320129395
Batch 12/64 loss: 1.730374813079834
Batch 13/64 loss: 1.7377046346664429
Batch 14/64 loss: 1.7279071807861328
Batch 15/64 loss: 1.7306556701660156
Batch 16/64 loss: 1.7538654804229736
Batch 17/64 loss: 1.740753412246704
Batch 18/64 loss: 1.7306907176971436
Batch 19/64 loss: 1.7425353527069092
Batch 20/64 loss: 1.7250738143920898
Batch 21/64 loss: 1.7277297973632812
Batch 22/64 loss: 1.7277967929840088
Batch 23/64 loss: 1.7304487228393555
Batch 24/64 loss: 1.7261145114898682
Batch 25/64 loss: 1.7284716367721558
Batch 26/64 loss: 1.729010820388794
Batch 27/64 loss: 1.7286829948425293
Batch 28/64 loss: 1.7283706665039062
Batch 29/64 loss: 1.7306417226791382
Batch 30/64 loss: 1.727118968963623
Batch 31/64 loss: 1.725581169128418
Batch 32/64 loss: 1.7276359796524048
Batch 33/64 loss: 1.726445198059082
Batch 34/64 loss: 1.7266709804534912
Batch 35/64 loss: 1.72623872756958
Batch 36/64 loss: 1.7274656295776367
Batch 37/64 loss: 1.7244539260864258
Batch 38/64 loss: 1.7265300750732422
Batch 39/64 loss: 1.7268528938293457
Batch 40/64 loss: 1.7258703708648682
Batch 41/64 loss: 1.7264460325241089
Batch 42/64 loss: 1.7252788543701172
Batch 43/64 loss: 1.7290308475494385
Batch 44/64 loss: 1.7281062602996826
Batch 45/64 loss: 1.7262862920761108
Batch 46/64 loss: 1.7249106168746948
Batch 47/64 loss: 1.7282044887542725
Batch 48/64 loss: 1.727268934249878
Batch 49/64 loss: 1.7312612533569336
Batch 50/64 loss: 1.72772216796875
Batch 51/64 loss: 1.726770043373108
Batch 52/64 loss: 1.7246804237365723
Batch 53/64 loss: 1.7323375940322876
Batch 54/64 loss: 1.7288542985916138
Batch 55/64 loss: 1.7296350002288818
Batch 56/64 loss: 1.7281091213226318
Batch 57/64 loss: 1.7259225845336914
Batch 58/64 loss: 1.7259823083877563
Batch 59/64 loss: 1.7258195877075195
Batch 60/64 loss: 1.7241921424865723
Batch 61/64 loss: 1.7301440238952637
Batch 62/64 loss: 1.731330156326294
Batch 63/64 loss: 1.7249972820281982
Batch 64/64 loss: 1.9171528816223145
Epoch 434  Train loss: 1.7310628460902793  Val loss: 1.7466996092976574
Epoch 435
-------------------------------
Batch 1/64 loss: 1.7284905910491943
Batch 2/64 loss: 1.729405164718628
Batch 3/64 loss: 1.7300255298614502
Batch 4/64 loss: 1.7452681064605713
Batch 5/64 loss: 1.7273499965667725
Batch 6/64 loss: 1.735887050628662
Batch 7/64 loss: 1.7280980348587036
Batch 8/64 loss: 1.7280821800231934
Batch 9/64 loss: 1.729201316833496
Batch 10/64 loss: 1.7278598546981812
Batch 11/64 loss: 1.7261857986450195
Batch 12/64 loss: 1.7293200492858887
Batch 13/64 loss: 1.7279305458068848
Batch 14/64 loss: 1.7289886474609375
Batch 15/64 loss: 1.7278132438659668
Batch 16/64 loss: 1.729606032371521
Batch 17/64 loss: 1.7256110906600952
Batch 18/64 loss: 1.7285776138305664
Batch 19/64 loss: 1.724898099899292
Batch 20/64 loss: 1.7320044040679932
Batch 21/64 loss: 1.7483322620391846
Batch 22/64 loss: 1.730536699295044
Batch 23/64 loss: 1.7299392223358154
Batch 24/64 loss: 1.7280350923538208
Batch 25/64 loss: 1.7285200357437134
Batch 26/64 loss: 1.7277357578277588
Batch 27/64 loss: 1.7330877780914307
Batch 28/64 loss: 1.7240170240402222
Batch 29/64 loss: 1.727066993713379
Batch 30/64 loss: 1.7284374237060547
Batch 31/64 loss: 1.7256044149398804
Batch 32/64 loss: 1.7308348417282104
Batch 33/64 loss: 1.7307000160217285
Batch 34/64 loss: 1.728501558303833
Batch 35/64 loss: 1.7252988815307617
Batch 36/64 loss: 1.7275643348693848
Batch 37/64 loss: 1.7264509201049805
Batch 38/64 loss: 1.727905035018921
Batch 39/64 loss: 1.7314674854278564
Batch 40/64 loss: 1.7253167629241943
Batch 41/64 loss: 1.7302671670913696
Batch 42/64 loss: 1.7301675081253052
Batch 43/64 loss: 1.7279081344604492
Batch 44/64 loss: 1.726476788520813
Batch 45/64 loss: 1.7289215326309204
Batch 46/64 loss: 1.7331407070159912
Batch 47/64 loss: 1.7429230213165283
Batch 48/64 loss: 1.7290191650390625
Batch 49/64 loss: 1.728965401649475
Batch 50/64 loss: 1.729020357131958
Batch 51/64 loss: 1.726807951927185
Batch 52/64 loss: 1.7280769348144531
Batch 53/64 loss: 1.726722002029419
Batch 54/64 loss: 1.7243683338165283
Batch 55/64 loss: 1.7279655933380127
Batch 56/64 loss: 1.7272837162017822
Batch 57/64 loss: 1.734136939048767
Batch 58/64 loss: 1.7246568202972412
Batch 59/64 loss: 1.7267892360687256
Batch 60/64 loss: 1.725039005279541
Batch 61/64 loss: 1.725926160812378
Batch 62/64 loss: 1.7298166751861572
Batch 63/64 loss: 1.7276027202606201
Batch 64/64 loss: 1.905881643295288
Epoch 435  Train loss: 1.7312528469983268  Val loss: 1.7430143020407032
Epoch 436
-------------------------------
Batch 1/64 loss: 1.726002812385559
Batch 2/64 loss: 1.726658821105957
Batch 3/64 loss: 1.7285337448120117
Batch 4/64 loss: 1.725805401802063
Batch 5/64 loss: 1.7306554317474365
Batch 6/64 loss: 1.72572660446167
Batch 7/64 loss: 1.7272517681121826
Batch 8/64 loss: 1.7249722480773926
Batch 9/64 loss: 1.7257624864578247
Batch 10/64 loss: 1.7258023023605347
Batch 11/64 loss: 1.7254257202148438
Batch 12/64 loss: 1.7258268594741821
Batch 13/64 loss: 1.727050542831421
Batch 14/64 loss: 1.7281156778335571
Batch 15/64 loss: 1.7441871166229248
Batch 16/64 loss: 1.7267467975616455
Batch 17/64 loss: 1.72690749168396
Batch 18/64 loss: 1.7261453866958618
Batch 19/64 loss: 1.72743558883667
Batch 20/64 loss: 1.726115107536316
Batch 21/64 loss: 1.72706937789917
Batch 22/64 loss: 1.7273750305175781
Batch 23/64 loss: 1.7264496088027954
Batch 24/64 loss: 1.7267186641693115
Batch 25/64 loss: 1.726401448249817
Batch 26/64 loss: 1.723241925239563
Batch 27/64 loss: 1.726744294166565
Batch 28/64 loss: 1.7268633842468262
Batch 29/64 loss: 1.7263331413269043
Batch 30/64 loss: 1.7264702320098877
Batch 31/64 loss: 1.7279982566833496
Batch 32/64 loss: 1.7240993976593018
Batch 33/64 loss: 1.7241920232772827
Batch 34/64 loss: 1.727874994277954
Batch 35/64 loss: 1.725387454032898
Batch 36/64 loss: 1.7266895771026611
Batch 37/64 loss: 1.7237058877944946
Batch 38/64 loss: 1.7278180122375488
Batch 39/64 loss: 1.731553077697754
Batch 40/64 loss: 1.72874116897583
Batch 41/64 loss: 1.7284021377563477
Batch 42/64 loss: 1.72629714012146
Batch 43/64 loss: 1.7334762811660767
Batch 44/64 loss: 1.726849913597107
Batch 45/64 loss: 1.728635311126709
Batch 46/64 loss: 1.7267415523529053
Batch 47/64 loss: 1.729064702987671
Batch 48/64 loss: 1.7294780015945435
Batch 49/64 loss: 1.7453477382659912
Batch 50/64 loss: 1.7427499294281006
Batch 51/64 loss: 1.7334829568862915
Batch 52/64 loss: 1.7271263599395752
Batch 53/64 loss: 1.7356688976287842
Batch 54/64 loss: 1.7283216714859009
Batch 55/64 loss: 1.7243163585662842
Batch 56/64 loss: 1.7251298427581787
Batch 57/64 loss: 1.7270238399505615
Batch 58/64 loss: 1.7305567264556885
Batch 59/64 loss: 1.7289650440216064
Batch 60/64 loss: 1.7289841175079346
Batch 61/64 loss: 1.7270461320877075
Batch 62/64 loss: 1.7357358932495117
Batch 63/64 loss: 1.728851318359375
Batch 64/64 loss: 1.9067409038543701
Epoch 436  Train loss: 1.7303711750928092  Val loss: 1.7455538736585898
Epoch 437
-------------------------------
Batch 1/64 loss: 1.7438714504241943
Batch 2/64 loss: 1.743283748626709
Batch 3/64 loss: 1.7257810831069946
Batch 4/64 loss: 1.7275733947753906
Batch 5/64 loss: 1.7301371097564697
Batch 6/64 loss: 1.7277553081512451
Batch 7/64 loss: 1.7341053485870361
Batch 8/64 loss: 1.7298450469970703
Batch 9/64 loss: 1.7291369438171387
Batch 10/64 loss: 1.7287702560424805
Batch 11/64 loss: 1.7258036136627197
Batch 12/64 loss: 1.7421785593032837
Batch 13/64 loss: 1.727269172668457
Batch 14/64 loss: 1.73395574092865
Batch 15/64 loss: 1.7269251346588135
Batch 16/64 loss: 1.7275676727294922
Batch 17/64 loss: 1.7277599573135376
Batch 18/64 loss: 1.7309722900390625
Batch 19/64 loss: 1.7290840148925781
Batch 20/64 loss: 1.7271686792373657
Batch 21/64 loss: 1.7299859523773193
Batch 22/64 loss: 1.7289958000183105
Batch 23/64 loss: 1.7314352989196777
Batch 24/64 loss: 1.7278099060058594
Batch 25/64 loss: 1.7276852130889893
Batch 26/64 loss: 1.7291686534881592
Batch 27/64 loss: 1.7292312383651733
Batch 28/64 loss: 1.7274702787399292
Batch 29/64 loss: 1.7278861999511719
Batch 30/64 loss: 1.7258820533752441
Batch 31/64 loss: 1.727562427520752
Batch 32/64 loss: 1.7302738428115845
Batch 33/64 loss: 1.7320427894592285
Batch 34/64 loss: 1.7273099422454834
Batch 35/64 loss: 1.7253016233444214
Batch 36/64 loss: 1.7335107326507568
Batch 37/64 loss: 1.7263729572296143
Batch 38/64 loss: 1.728102445602417
Batch 39/64 loss: 1.7263975143432617
Batch 40/64 loss: 1.7260560989379883
Batch 41/64 loss: 1.7238664627075195
Batch 42/64 loss: 1.726775050163269
Batch 43/64 loss: 1.7279940843582153
Batch 44/64 loss: 1.7222926616668701
Batch 45/64 loss: 1.732862949371338
Batch 46/64 loss: 1.7269068956375122
Batch 47/64 loss: 1.7261981964111328
Batch 48/64 loss: 1.725541114807129
Batch 49/64 loss: 1.7284653186798096
Batch 50/64 loss: 1.7255901098251343
Batch 51/64 loss: 1.7260463237762451
Batch 52/64 loss: 1.7273457050323486
Batch 53/64 loss: 1.729295015335083
Batch 54/64 loss: 1.725351095199585
Batch 55/64 loss: 1.7294745445251465
Batch 56/64 loss: 1.728136658668518
Batch 57/64 loss: 1.7265617847442627
Batch 58/64 loss: 1.7261699438095093
Batch 59/64 loss: 1.7281761169433594
Batch 60/64 loss: 1.7280499935150146
Batch 61/64 loss: 1.7241415977478027
Batch 62/64 loss: 1.7326340675354004
Batch 63/64 loss: 1.7283680438995361
Batch 64/64 loss: 1.905990719795227
Epoch 437  Train loss: 1.7308731336219638  Val loss: 1.7441295889235033
Epoch 438
-------------------------------
Batch 1/64 loss: 1.7286911010742188
Batch 2/64 loss: 1.7281864881515503
Batch 3/64 loss: 1.7269048690795898
Batch 4/64 loss: 1.729527235031128
Batch 5/64 loss: 1.7306699752807617
Batch 6/64 loss: 1.7461501359939575
Batch 7/64 loss: 1.7251684665679932
Batch 8/64 loss: 1.7272368669509888
Batch 9/64 loss: 1.7283589839935303
Batch 10/64 loss: 1.7264201641082764
Batch 11/64 loss: 1.7423224449157715
Batch 12/64 loss: 1.7268550395965576
Batch 13/64 loss: 1.7288575172424316
Batch 14/64 loss: 1.7286136150360107
Batch 15/64 loss: 1.723587989807129
Batch 16/64 loss: 1.7319843769073486
Batch 17/64 loss: 1.7253670692443848
Batch 18/64 loss: 1.7273237705230713
Batch 19/64 loss: 1.7265560626983643
Batch 20/64 loss: 1.7277894020080566
Batch 21/64 loss: 1.7307863235473633
Batch 22/64 loss: 1.7274417877197266
Batch 23/64 loss: 1.7278720140457153
Batch 24/64 loss: 1.7258126735687256
Batch 25/64 loss: 1.725904941558838
Batch 26/64 loss: 1.7323648929595947
Batch 27/64 loss: 1.7462043762207031
Batch 28/64 loss: 1.7245264053344727
Batch 29/64 loss: 1.7292110919952393
Batch 30/64 loss: 1.7265187501907349
Batch 31/64 loss: 1.727181077003479
Batch 32/64 loss: 1.7271878719329834
Batch 33/64 loss: 1.7276337146759033
Batch 34/64 loss: 1.7323637008666992
Batch 35/64 loss: 1.727933406829834
Batch 36/64 loss: 1.73252272605896
Batch 37/64 loss: 1.7288603782653809
Batch 38/64 loss: 1.726580262184143
Batch 39/64 loss: 1.7260286808013916
Batch 40/64 loss: 1.7279738187789917
Batch 41/64 loss: 1.7270314693450928
Batch 42/64 loss: 1.728971242904663
Batch 43/64 loss: 1.7282016277313232
Batch 44/64 loss: 1.7293996810913086
Batch 45/64 loss: 1.7251567840576172
Batch 46/64 loss: 1.7309536933898926
Batch 47/64 loss: 1.7301238775253296
Batch 48/64 loss: 1.7270519733428955
Batch 49/64 loss: 1.729258418083191
Batch 50/64 loss: 1.7308571338653564
Batch 51/64 loss: 1.726416826248169
Batch 52/64 loss: 1.7272369861602783
Batch 53/64 loss: 1.7244510650634766
Batch 54/64 loss: 1.7259626388549805
Batch 55/64 loss: 1.7260091304779053
Batch 56/64 loss: 1.7265329360961914
Batch 57/64 loss: 1.7241610288619995
Batch 58/64 loss: 1.7317755222320557
Batch 59/64 loss: 1.7293403148651123
Batch 60/64 loss: 1.7267894744873047
Batch 61/64 loss: 1.7264430522918701
Batch 62/64 loss: 1.7296087741851807
Batch 63/64 loss: 1.7292819023132324
Batch 64/64 loss: 1.9047613143920898
Epoch 438  Train loss: 1.7307775216944077  Val loss: 1.7451079645517356
Epoch 439
-------------------------------
Batch 1/64 loss: 1.7240606546401978
Batch 2/64 loss: 1.7271877527236938
Batch 3/64 loss: 1.7270457744598389
Batch 4/64 loss: 1.738247275352478
Batch 5/64 loss: 1.7278083562850952
Batch 6/64 loss: 1.7276372909545898
Batch 7/64 loss: 1.728439211845398
Batch 8/64 loss: 1.7292046546936035
Batch 9/64 loss: 1.7270011901855469
Batch 10/64 loss: 1.7307257652282715
Batch 11/64 loss: 1.731854796409607
Batch 12/64 loss: 1.7301197052001953
Batch 13/64 loss: 1.726391077041626
Batch 14/64 loss: 1.732088565826416
Batch 15/64 loss: 1.7299928665161133
Batch 16/64 loss: 1.7295489311218262
Batch 17/64 loss: 1.7288241386413574
Batch 18/64 loss: 1.7297189235687256
Batch 19/64 loss: 1.7302868366241455
Batch 20/64 loss: 1.7323585748672485
Batch 21/64 loss: 1.7345186471939087
Batch 22/64 loss: 1.7287485599517822
Batch 23/64 loss: 1.7273244857788086
Batch 24/64 loss: 1.730781078338623
Batch 25/64 loss: 1.7273495197296143
Batch 26/64 loss: 1.7334760427474976
Batch 27/64 loss: 1.731499433517456
Batch 28/64 loss: 1.7428462505340576
Batch 29/64 loss: 1.7295632362365723
Batch 30/64 loss: 1.72816801071167
Batch 31/64 loss: 1.730422019958496
Batch 32/64 loss: 1.7285895347595215
Batch 33/64 loss: 1.7283227443695068
Batch 34/64 loss: 1.7453489303588867
Batch 35/64 loss: 1.7339301109313965
Batch 36/64 loss: 1.7278778553009033
Batch 37/64 loss: 1.7277419567108154
Batch 38/64 loss: 1.7303240299224854
Batch 39/64 loss: 1.7288951873779297
Batch 40/64 loss: 1.729642391204834
Batch 41/64 loss: 1.7280914783477783
Batch 42/64 loss: 1.7282836437225342
Batch 43/64 loss: 1.7265386581420898
Batch 44/64 loss: 1.734856128692627
Batch 45/64 loss: 1.731168508529663
Batch 46/64 loss: 1.7286049127578735
Batch 47/64 loss: 1.727755069732666
Batch 48/64 loss: 1.7292697429656982
Batch 49/64 loss: 1.7306106090545654
Batch 50/64 loss: 1.7333626747131348
Batch 51/64 loss: 1.7343140840530396
Batch 52/64 loss: 1.73282790184021
Batch 53/64 loss: 1.7302111387252808
Batch 54/64 loss: 1.7316739559173584
Batch 55/64 loss: 1.7280499935150146
Batch 56/64 loss: 1.7316917181015015
Batch 57/64 loss: 1.7317233085632324
Batch 58/64 loss: 1.731286644935608
Batch 59/64 loss: 1.7306959629058838
Batch 60/64 loss: 1.7299736738204956
Batch 61/64 loss: 1.73160982131958
Batch 62/64 loss: 1.7295911312103271
Batch 63/64 loss: 1.734633207321167
Batch 64/64 loss: 1.9104859828948975
Epoch 439  Train loss: 1.7326055031196743  Val loss: 1.7503326692941672
Epoch 440
-------------------------------
Batch 1/64 loss: 1.7318501472473145
Batch 2/64 loss: 1.7316296100616455
Batch 3/64 loss: 1.7276170253753662
Batch 4/64 loss: 1.7277708053588867
Batch 5/64 loss: 1.7318850755691528
Batch 6/64 loss: 1.7277050018310547
Batch 7/64 loss: 1.732937216758728
Batch 8/64 loss: 1.736021637916565
Batch 9/64 loss: 1.7297632694244385
Batch 10/64 loss: 1.7270392179489136
Batch 11/64 loss: 1.7308602333068848
Batch 12/64 loss: 1.7304890155792236
Batch 13/64 loss: 1.7309491634368896
Batch 14/64 loss: 1.7304952144622803
Batch 15/64 loss: 1.7281043529510498
Batch 16/64 loss: 1.7291404008865356
Batch 17/64 loss: 1.7295972108840942
Batch 18/64 loss: 1.7326397895812988
Batch 19/64 loss: 1.7485663890838623
Batch 20/64 loss: 1.7277472019195557
Batch 21/64 loss: 1.7335506677627563
Batch 22/64 loss: 1.7320709228515625
Batch 23/64 loss: 1.729607105255127
Batch 24/64 loss: 1.7307405471801758
Batch 25/64 loss: 1.7285066843032837
Batch 26/64 loss: 1.7318333387374878
Batch 27/64 loss: 1.7361072301864624
Batch 28/64 loss: 1.7289869785308838
Batch 29/64 loss: 1.7311756610870361
Batch 30/64 loss: 1.7324881553649902
Batch 31/64 loss: 1.7306296825408936
Batch 32/64 loss: 1.7302141189575195
Batch 33/64 loss: 1.7339469194412231
Batch 34/64 loss: 1.7307469844818115
Batch 35/64 loss: 1.7344813346862793
Batch 36/64 loss: 1.7263026237487793
Batch 37/64 loss: 1.731404423713684
Batch 38/64 loss: 1.7275691032409668
Batch 39/64 loss: 1.7281931638717651
Batch 40/64 loss: 1.72676420211792
Batch 41/64 loss: 1.7300745248794556
Batch 42/64 loss: 1.7326624393463135
Batch 43/64 loss: 1.734696865081787
Batch 44/64 loss: 1.7278022766113281
Batch 45/64 loss: 1.7343249320983887
Batch 46/64 loss: 1.7312548160552979
Batch 47/64 loss: 1.7293422222137451
Batch 48/64 loss: 1.729150414466858
Batch 49/64 loss: 1.7351102828979492
Batch 50/64 loss: 1.7279646396636963
Batch 51/64 loss: 1.7298619747161865
Batch 52/64 loss: 1.746232032775879
Batch 53/64 loss: 1.7324416637420654
Batch 54/64 loss: 1.7321889400482178
Batch 55/64 loss: 1.7316300868988037
Batch 56/64 loss: 1.7277544736862183
Batch 57/64 loss: 1.730006456375122
Batch 58/64 loss: 1.7298556566238403
Batch 59/64 loss: 1.7308140993118286
Batch 60/64 loss: 1.7287392616271973
Batch 61/64 loss: 1.7294001579284668
Batch 62/64 loss: 1.7436779737472534
Batch 63/64 loss: 1.7317593097686768
Batch 64/64 loss: 1.9104818105697632
Epoch 440  Train loss: 1.7334546617433138  Val loss: 1.7489685520683367
Epoch 441
-------------------------------
Batch 1/64 loss: 1.7372534275054932
Batch 2/64 loss: 1.7317554950714111
Batch 3/64 loss: 1.7264459133148193
Batch 4/64 loss: 1.730101466178894
Batch 5/64 loss: 1.730514645576477
Batch 6/64 loss: 1.7277261018753052
Batch 7/64 loss: 1.7320479154586792
Batch 8/64 loss: 1.7451646327972412
Batch 9/64 loss: 1.7293354272842407
Batch 10/64 loss: 1.734647512435913
Batch 11/64 loss: 1.7314931154251099
Batch 12/64 loss: 1.7363429069519043
Batch 13/64 loss: 1.7371220588684082
Batch 14/64 loss: 1.7354931831359863
Batch 15/64 loss: 1.7398526668548584
Batch 16/64 loss: 1.733361840248108
Batch 17/64 loss: 1.7355643510818481
Batch 18/64 loss: 1.7317016124725342
Batch 19/64 loss: 1.7314735651016235
Batch 20/64 loss: 1.7494384050369263
Batch 21/64 loss: 1.7303918600082397
Batch 22/64 loss: 1.7336820363998413
Batch 23/64 loss: 1.7309881448745728
Batch 24/64 loss: 1.728588581085205
Batch 25/64 loss: 1.7299867868423462
Batch 26/64 loss: 1.7303740978240967
Batch 27/64 loss: 1.7332179546356201
Batch 28/64 loss: 1.730708122253418
Batch 29/64 loss: 1.728771448135376
Batch 30/64 loss: 1.7315772771835327
Batch 31/64 loss: 1.729367733001709
Batch 32/64 loss: 1.731001615524292
Batch 33/64 loss: 1.7303317785263062
Batch 34/64 loss: 1.7267115116119385
Batch 35/64 loss: 1.7278698682785034
Batch 36/64 loss: 1.728835105895996
Batch 37/64 loss: 1.7297475337982178
Batch 38/64 loss: 1.738777995109558
Batch 39/64 loss: 1.7269995212554932
Batch 40/64 loss: 1.7276053428649902
Batch 41/64 loss: 1.7277092933654785
Batch 42/64 loss: 1.7295758724212646
Batch 43/64 loss: 1.7260996103286743
Batch 44/64 loss: 1.727825403213501
Batch 45/64 loss: 1.7332000732421875
Batch 46/64 loss: 1.7251355648040771
Batch 47/64 loss: 1.729251503944397
Batch 48/64 loss: 1.7288354635238647
Batch 49/64 loss: 1.7453649044036865
Batch 50/64 loss: 1.7293397188186646
Batch 51/64 loss: 1.729178786277771
Batch 52/64 loss: 1.7263033390045166
Batch 53/64 loss: 1.7262362241744995
Batch 54/64 loss: 1.7259886264801025
Batch 55/64 loss: 1.7294080257415771
Batch 56/64 loss: 1.7261054515838623
Batch 57/64 loss: 1.7298659086227417
Batch 58/64 loss: 1.7273368835449219
Batch 59/64 loss: 1.7291237115859985
Batch 60/64 loss: 1.7254092693328857
Batch 61/64 loss: 1.730976939201355
Batch 62/64 loss: 1.7299952507019043
Batch 63/64 loss: 1.7263067960739136
Batch 64/64 loss: 1.9093947410583496
Epoch 441  Train loss: 1.7331606154348336  Val loss: 1.7479313902838534
Epoch 442
-------------------------------
Batch 1/64 loss: 1.726110816001892
Batch 2/64 loss: 1.7298951148986816
Batch 3/64 loss: 1.7317698001861572
Batch 4/64 loss: 1.7294098138809204
Batch 5/64 loss: 1.7275333404541016
Batch 6/64 loss: 1.7263786792755127
Batch 7/64 loss: 1.727327585220337
Batch 8/64 loss: 1.7308706045150757
Batch 9/64 loss: 1.7256090641021729
Batch 10/64 loss: 1.727913737297058
Batch 11/64 loss: 1.7342703342437744
Batch 12/64 loss: 1.7260394096374512
Batch 13/64 loss: 1.728357195854187
Batch 14/64 loss: 1.7298144102096558
Batch 15/64 loss: 1.7337536811828613
Batch 16/64 loss: 1.7270667552947998
Batch 17/64 loss: 1.7317094802856445
Batch 18/64 loss: 1.729345440864563
Batch 19/64 loss: 1.7269678115844727
Batch 20/64 loss: 1.735379934310913
Batch 21/64 loss: 1.729072093963623
Batch 22/64 loss: 1.7283092737197876
Batch 23/64 loss: 1.7428255081176758
Batch 24/64 loss: 1.733434796333313
Batch 25/64 loss: 1.7363795042037964
Batch 26/64 loss: 1.728116750717163
Batch 27/64 loss: 1.741577386856079
Batch 28/64 loss: 1.7317984104156494
Batch 29/64 loss: 1.7302547693252563
Batch 30/64 loss: 1.7324620485305786
Batch 31/64 loss: 1.729318380355835
Batch 32/64 loss: 1.72953462600708
Batch 33/64 loss: 1.7285165786743164
Batch 34/64 loss: 1.7323609590530396
Batch 35/64 loss: 1.7281972169876099
Batch 36/64 loss: 1.7279326915740967
Batch 37/64 loss: 1.7234950065612793
Batch 38/64 loss: 1.726923942565918
Batch 39/64 loss: 1.7321925163269043
Batch 40/64 loss: 1.7296141386032104
Batch 41/64 loss: 1.729295015335083
Batch 42/64 loss: 1.7355084419250488
Batch 43/64 loss: 1.7274603843688965
Batch 44/64 loss: 1.7293052673339844
Batch 45/64 loss: 1.7262284755706787
Batch 46/64 loss: 1.7291209697723389
Batch 47/64 loss: 1.728667974472046
Batch 48/64 loss: 1.7269902229309082
Batch 49/64 loss: 1.7275677919387817
Batch 50/64 loss: 1.7268476486206055
Batch 51/64 loss: 1.7299834489822388
Batch 52/64 loss: 1.7395522594451904
Batch 53/64 loss: 1.7279303073883057
Batch 54/64 loss: 1.729555606842041
Batch 55/64 loss: 1.7253845930099487
Batch 56/64 loss: 1.7269418239593506
Batch 57/64 loss: 1.7263779640197754
Batch 58/64 loss: 1.7266080379486084
Batch 59/64 loss: 1.7284796237945557
Batch 60/64 loss: 1.7268786430358887
Batch 61/64 loss: 1.7296829223632812
Batch 62/64 loss: 1.7493314743041992
Batch 63/64 loss: 1.725498914718628
Batch 64/64 loss: 1.9089933633804321
Epoch 442  Train loss: 1.7320593324362064  Val loss: 1.7443370679809465
Epoch 443
-------------------------------
Batch 1/64 loss: 1.724777102470398
Batch 2/64 loss: 1.725226879119873
Batch 3/64 loss: 1.7297377586364746
Batch 4/64 loss: 1.7268617153167725
Batch 5/64 loss: 1.7286672592163086
Batch 6/64 loss: 1.7401766777038574
Batch 7/64 loss: 1.7270112037658691
Batch 8/64 loss: 1.7270857095718384
Batch 9/64 loss: 1.7252826690673828
Batch 10/64 loss: 1.7246627807617188
Batch 11/64 loss: 1.7262904644012451
Batch 12/64 loss: 1.7253665924072266
Batch 13/64 loss: 1.7270033359527588
Batch 14/64 loss: 1.7300269603729248
Batch 15/64 loss: 1.7261388301849365
Batch 16/64 loss: 1.7240803241729736
Batch 17/64 loss: 1.7261643409729004
Batch 18/64 loss: 1.7273380756378174
Batch 19/64 loss: 1.7304211854934692
Batch 20/64 loss: 1.726760983467102
Batch 21/64 loss: 1.7407748699188232
Batch 22/64 loss: 1.724578857421875
Batch 23/64 loss: 1.7285256385803223
Batch 24/64 loss: 1.726507306098938
Batch 25/64 loss: 1.726316213607788
Batch 26/64 loss: 1.7243425846099854
Batch 27/64 loss: 1.7234442234039307
Batch 28/64 loss: 1.7244555950164795
Batch 29/64 loss: 1.7235369682312012
Batch 30/64 loss: 1.728818655014038
Batch 31/64 loss: 1.7255845069885254
Batch 32/64 loss: 1.725423812866211
Batch 33/64 loss: 1.7284455299377441
Batch 34/64 loss: 1.7263851165771484
Batch 35/64 loss: 1.7226994037628174
Batch 36/64 loss: 1.7255957126617432
Batch 37/64 loss: 1.724306583404541
Batch 38/64 loss: 1.7261364459991455
Batch 39/64 loss: 1.7262904644012451
Batch 40/64 loss: 1.7291288375854492
Batch 41/64 loss: 1.7269458770751953
Batch 42/64 loss: 1.726867914199829
Batch 43/64 loss: 1.7262022495269775
Batch 44/64 loss: 1.7252647876739502
Batch 45/64 loss: 1.7277131080627441
Batch 46/64 loss: 1.7429039478302002
Batch 47/64 loss: 1.7248454093933105
Batch 48/64 loss: 1.7245815992355347
Batch 49/64 loss: 1.7253108024597168
Batch 50/64 loss: 1.7302325963974
Batch 51/64 loss: 1.7240245342254639
Batch 52/64 loss: 1.7252708673477173
Batch 53/64 loss: 1.7269314527511597
Batch 54/64 loss: 1.7288939952850342
Batch 55/64 loss: 1.731187343597412
Batch 56/64 loss: 1.7279272079467773
Batch 57/64 loss: 1.7251009941101074
Batch 58/64 loss: 1.7322341203689575
Batch 59/64 loss: 1.7257412672042847
Batch 60/64 loss: 1.727623701095581
Batch 61/64 loss: 1.7275588512420654
Batch 62/64 loss: 1.72294020652771
Batch 63/64 loss: 1.733368992805481
Batch 64/64 loss: 1.903674840927124
Epoch 443  Train loss: 1.7293773510876824  Val loss: 1.7451183664839702
Epoch 444
-------------------------------
Batch 1/64 loss: 1.7541930675506592
Batch 2/64 loss: 1.7246558666229248
Batch 3/64 loss: 1.7264087200164795
Batch 4/64 loss: 1.7243294715881348
Batch 5/64 loss: 1.7295421361923218
Batch 6/64 loss: 1.7265229225158691
Batch 7/64 loss: 1.7355396747589111
Batch 8/64 loss: 1.7293477058410645
Batch 9/64 loss: 1.728890061378479
Batch 10/64 loss: 1.7253193855285645
Batch 11/64 loss: 1.7245267629623413
Batch 12/64 loss: 1.7254618406295776
Batch 13/64 loss: 1.7257131338119507
Batch 14/64 loss: 1.724187970161438
Batch 15/64 loss: 1.7344880104064941
Batch 16/64 loss: 1.7283496856689453
Batch 17/64 loss: 1.7227122783660889
Batch 18/64 loss: 1.7262362241744995
Batch 19/64 loss: 1.7253921031951904
Batch 20/64 loss: 1.731910228729248
Batch 21/64 loss: 1.7241144180297852
Batch 22/64 loss: 1.723999261856079
Batch 23/64 loss: 1.725167989730835
Batch 24/64 loss: 1.7252682447433472
Batch 25/64 loss: 1.7261109352111816
Batch 26/64 loss: 1.7263035774230957
Batch 27/64 loss: 1.7247507572174072
Batch 28/64 loss: 1.7429332733154297
Batch 29/64 loss: 1.7267168760299683
Batch 30/64 loss: 1.7248408794403076
Batch 31/64 loss: 1.731603741645813
Batch 32/64 loss: 1.7242357730865479
Batch 33/64 loss: 1.7264783382415771
Batch 34/64 loss: 1.728278398513794
Batch 35/64 loss: 1.7394468784332275
Batch 36/64 loss: 1.7283673286437988
Batch 37/64 loss: 1.7257976531982422
Batch 38/64 loss: 1.7253820896148682
Batch 39/64 loss: 1.7253280878067017
Batch 40/64 loss: 1.7283351421356201
Batch 41/64 loss: 1.7262816429138184
Batch 42/64 loss: 1.7247098684310913
Batch 43/64 loss: 1.72397780418396
Batch 44/64 loss: 1.7259745597839355
Batch 45/64 loss: 1.7248971462249756
Batch 46/64 loss: 1.7235527038574219
Batch 47/64 loss: 1.7258431911468506
Batch 48/64 loss: 1.72868013381958
Batch 49/64 loss: 1.726081132888794
Batch 50/64 loss: 1.7279689311981201
Batch 51/64 loss: 1.724797248840332
Batch 52/64 loss: 1.7266993522644043
Batch 53/64 loss: 1.7284526824951172
Batch 54/64 loss: 1.7291297912597656
Batch 55/64 loss: 1.7263517379760742
Batch 56/64 loss: 1.727698802947998
Batch 57/64 loss: 1.7280898094177246
Batch 58/64 loss: 1.7255325317382812
Batch 59/64 loss: 1.727894902229309
Batch 60/64 loss: 1.7254629135131836
Batch 61/64 loss: 1.7297828197479248
Batch 62/64 loss: 1.7286570072174072
Batch 63/64 loss: 1.7262718677520752
Batch 64/64 loss: 1.9080350399017334
Epoch 444  Train loss: 1.7297412040186864  Val loss: 1.7459503752259455
Epoch 445
-------------------------------
Batch 1/64 loss: 1.7280545234680176
Batch 2/64 loss: 1.7272740602493286
Batch 3/64 loss: 1.7266792058944702
Batch 4/64 loss: 1.7305519580841064
Batch 5/64 loss: 1.7264156341552734
Batch 6/64 loss: 1.7265000343322754
Batch 7/64 loss: 1.7255293130874634
Batch 8/64 loss: 1.7270290851593018
Batch 9/64 loss: 1.7239934206008911
Batch 10/64 loss: 1.7262189388275146
Batch 11/64 loss: 1.7255500555038452
Batch 12/64 loss: 1.7264213562011719
Batch 13/64 loss: 1.7299845218658447
Batch 14/64 loss: 1.7262656688690186
Batch 15/64 loss: 1.726107120513916
Batch 16/64 loss: 1.730600357055664
Batch 17/64 loss: 1.7267223596572876
Batch 18/64 loss: 1.7287497520446777
Batch 19/64 loss: 1.7278311252593994
Batch 20/64 loss: 1.7343957424163818
Batch 21/64 loss: 1.7284176349639893
Batch 22/64 loss: 1.7262784242630005
Batch 23/64 loss: 1.7259068489074707
Batch 24/64 loss: 1.72579824924469
Batch 25/64 loss: 1.7269923686981201
Batch 26/64 loss: 1.7252373695373535
Batch 27/64 loss: 1.7242741584777832
Batch 28/64 loss: 1.7278790473937988
Batch 29/64 loss: 1.7391682863235474
Batch 30/64 loss: 1.725473403930664
Batch 31/64 loss: 1.7249438762664795
Batch 32/64 loss: 1.7253656387329102
Batch 33/64 loss: 1.7289412021636963
Batch 34/64 loss: 1.7247486114501953
Batch 35/64 loss: 1.7241272926330566
Batch 36/64 loss: 1.7419040203094482
Batch 37/64 loss: 1.7241201400756836
Batch 38/64 loss: 1.7262604236602783
Batch 39/64 loss: 1.7245210409164429
Batch 40/64 loss: 1.7321369647979736
Batch 41/64 loss: 1.743403434753418
Batch 42/64 loss: 1.7273108959197998
Batch 43/64 loss: 1.7313038110733032
Batch 44/64 loss: 1.7275683879852295
Batch 45/64 loss: 1.724815845489502
Batch 46/64 loss: 1.7267072200775146
Batch 47/64 loss: 1.7287216186523438
Batch 48/64 loss: 1.7263648509979248
Batch 49/64 loss: 1.7258431911468506
Batch 50/64 loss: 1.729994773864746
Batch 51/64 loss: 1.7254831790924072
Batch 52/64 loss: 1.7275333404541016
Batch 53/64 loss: 1.729163646697998
Batch 54/64 loss: 1.726167917251587
Batch 55/64 loss: 1.7290120124816895
Batch 56/64 loss: 1.7254846096038818
Batch 57/64 loss: 1.7261786460876465
Batch 58/64 loss: 1.728543996810913
Batch 59/64 loss: 1.729873538017273
Batch 60/64 loss: 1.7305395603179932
Batch 61/64 loss: 1.7295951843261719
Batch 62/64 loss: 1.7325385808944702
Batch 63/64 loss: 1.72693932056427
Batch 64/64 loss: 1.9058125019073486
Epoch 445  Train loss: 1.730067704705631  Val loss: 1.7459696969625467
Epoch 446
-------------------------------
Batch 1/64 loss: 1.7336581945419312
Batch 2/64 loss: 1.7229468822479248
Batch 3/64 loss: 1.7263734340667725
Batch 4/64 loss: 1.7260346412658691
Batch 5/64 loss: 1.7269480228424072
Batch 6/64 loss: 1.7274646759033203
Batch 7/64 loss: 1.7268760204315186
Batch 8/64 loss: 1.7252671718597412
Batch 9/64 loss: 1.728538990020752
Batch 10/64 loss: 1.728888988494873
Batch 11/64 loss: 1.728691816329956
Batch 12/64 loss: 1.7242872714996338
Batch 13/64 loss: 1.7259197235107422
Batch 14/64 loss: 1.7239980697631836
Batch 15/64 loss: 1.729520559310913
Batch 16/64 loss: 1.7249890565872192
Batch 17/64 loss: 1.7267296314239502
Batch 18/64 loss: 1.7297801971435547
Batch 19/64 loss: 1.7237262725830078
Batch 20/64 loss: 1.7242947816848755
Batch 21/64 loss: 1.7294566631317139
Batch 22/64 loss: 1.7258235216140747
Batch 23/64 loss: 1.7250005006790161
Batch 24/64 loss: 1.733986258506775
Batch 25/64 loss: 1.7255730628967285
Batch 26/64 loss: 1.7242200374603271
Batch 27/64 loss: 1.7255620956420898
Batch 28/64 loss: 1.7228672504425049
Batch 29/64 loss: 1.7274055480957031
Batch 30/64 loss: 1.727575421333313
Batch 31/64 loss: 1.7260031700134277
Batch 32/64 loss: 1.7251696586608887
Batch 33/64 loss: 1.7495046854019165
Batch 34/64 loss: 1.7402889728546143
Batch 35/64 loss: 1.7258577346801758
Batch 36/64 loss: 1.72585129737854
Batch 37/64 loss: 1.7232351303100586
Batch 38/64 loss: 1.7292811870574951
Batch 39/64 loss: 1.7279903888702393
Batch 40/64 loss: 1.726147174835205
Batch 41/64 loss: 1.7262459993362427
Batch 42/64 loss: 1.7300260066986084
Batch 43/64 loss: 1.7270379066467285
Batch 44/64 loss: 1.7272557020187378
Batch 45/64 loss: 1.7254059314727783
Batch 46/64 loss: 1.725650429725647
Batch 47/64 loss: 1.7266685962677002
Batch 48/64 loss: 1.7301056385040283
Batch 49/64 loss: 1.7258669137954712
Batch 50/64 loss: 1.7292604446411133
Batch 51/64 loss: 1.7249608039855957
Batch 52/64 loss: 1.7233085632324219
Batch 53/64 loss: 1.7242751121520996
Batch 54/64 loss: 1.7249326705932617
Batch 55/64 loss: 1.7252166271209717
Batch 56/64 loss: 1.7404272556304932
Batch 57/64 loss: 1.7289483547210693
Batch 58/64 loss: 1.724818229675293
Batch 59/64 loss: 1.7270900011062622
Batch 60/64 loss: 1.7230958938598633
Batch 61/64 loss: 1.7288997173309326
Batch 62/64 loss: 1.7288302183151245
Batch 63/64 loss: 1.7317368984222412
Batch 64/64 loss: 1.9019241333007812
Epoch 446  Train loss: 1.7295410380643956  Val loss: 1.7447235969333714
Epoch 447
-------------------------------
Batch 1/64 loss: 1.7274210453033447
Batch 2/64 loss: 1.7280867099761963
Batch 3/64 loss: 1.7266645431518555
Batch 4/64 loss: 1.7280538082122803
Batch 5/64 loss: 1.7273502349853516
Batch 6/64 loss: 1.7275758981704712
Batch 7/64 loss: 1.7272449731826782
Batch 8/64 loss: 1.726011872291565
Batch 9/64 loss: 1.7291234731674194
Batch 10/64 loss: 1.7278859615325928
Batch 11/64 loss: 1.7293661832809448
Batch 12/64 loss: 1.729098916053772
Batch 13/64 loss: 1.7270879745483398
Batch 14/64 loss: 1.7252695560455322
Batch 15/64 loss: 1.7320576906204224
Batch 16/64 loss: 1.7233420610427856
Batch 17/64 loss: 1.7273194789886475
Batch 18/64 loss: 1.730405330657959
Batch 19/64 loss: 1.7382327318191528
Batch 20/64 loss: 1.7258460521697998
Batch 21/64 loss: 1.7281856536865234
Batch 22/64 loss: 1.72678542137146
Batch 23/64 loss: 1.7281100749969482
Batch 24/64 loss: 1.728868007659912
Batch 25/64 loss: 1.7285676002502441
Batch 26/64 loss: 1.7305010557174683
Batch 27/64 loss: 1.7256407737731934
Batch 28/64 loss: 1.7274421453475952
Batch 29/64 loss: 1.7254810333251953
Batch 30/64 loss: 1.7249248027801514
Batch 31/64 loss: 1.7259052991867065
Batch 32/64 loss: 1.726326584815979
Batch 33/64 loss: 1.7325843572616577
Batch 34/64 loss: 1.7279850244522095
Batch 35/64 loss: 1.725434422492981
Batch 36/64 loss: 1.7465565204620361
Batch 37/64 loss: 1.7369482517242432
Batch 38/64 loss: 1.7282688617706299
Batch 39/64 loss: 1.7286646366119385
Batch 40/64 loss: 1.7245302200317383
Batch 41/64 loss: 1.7256226539611816
Batch 42/64 loss: 1.728013038635254
Batch 43/64 loss: 1.7275545597076416
Batch 44/64 loss: 1.7263574600219727
Batch 45/64 loss: 1.7281239032745361
Batch 46/64 loss: 1.726203441619873
Batch 47/64 loss: 1.726850986480713
Batch 48/64 loss: 1.7251214981079102
Batch 49/64 loss: 1.7468092441558838
Batch 50/64 loss: 1.7248622179031372
Batch 51/64 loss: 1.7290656566619873
Batch 52/64 loss: 1.7302682399749756
Batch 53/64 loss: 1.734362244606018
Batch 54/64 loss: 1.731762409210205
Batch 55/64 loss: 1.7397181987762451
Batch 56/64 loss: 1.7300608158111572
Batch 57/64 loss: 1.7248015403747559
Batch 58/64 loss: 1.7245612144470215
Batch 59/64 loss: 1.7275972366333008
Batch 60/64 loss: 1.7271431684494019
Batch 61/64 loss: 1.7256556749343872
Batch 62/64 loss: 1.724888563156128
Batch 63/64 loss: 1.7242648601531982
Batch 64/64 loss: 1.906709909439087
Epoch 447  Train loss: 1.7306801019930371  Val loss: 1.746161488732931
Epoch 448
-------------------------------
Batch 1/64 loss: 1.729172706604004
Batch 2/64 loss: 1.7383027076721191
Batch 3/64 loss: 1.726147174835205
Batch 4/64 loss: 1.7270307540893555
Batch 5/64 loss: 1.7297019958496094
Batch 6/64 loss: 1.7279794216156006
Batch 7/64 loss: 1.7440855503082275
Batch 8/64 loss: 1.7254748344421387
Batch 9/64 loss: 1.727808952331543
Batch 10/64 loss: 1.727313756942749
Batch 11/64 loss: 1.7294628620147705
Batch 12/64 loss: 1.729061484336853
Batch 13/64 loss: 1.7253884077072144
Batch 14/64 loss: 1.7275540828704834
Batch 15/64 loss: 1.7318830490112305
Batch 16/64 loss: 1.7259807586669922
Batch 17/64 loss: 1.7297356128692627
Batch 18/64 loss: 1.7294299602508545
Batch 19/64 loss: 1.728071689605713
Batch 20/64 loss: 1.7250289916992188
Batch 21/64 loss: 1.7347078323364258
Batch 22/64 loss: 1.7289254665374756
Batch 23/64 loss: 1.7294126749038696
Batch 24/64 loss: 1.7275158166885376
Batch 25/64 loss: 1.727583885192871
Batch 26/64 loss: 1.728661060333252
Batch 27/64 loss: 1.733913540840149
Batch 28/64 loss: 1.7298543453216553
Batch 29/64 loss: 1.7253986597061157
Batch 30/64 loss: 1.727567195892334
Batch 31/64 loss: 1.730679988861084
Batch 32/64 loss: 1.7285810708999634
Batch 33/64 loss: 1.7270135879516602
Batch 34/64 loss: 1.7261265516281128
Batch 35/64 loss: 1.7351016998291016
Batch 36/64 loss: 1.7244672775268555
Batch 37/64 loss: 1.7293915748596191
Batch 38/64 loss: 1.7459912300109863
Batch 39/64 loss: 1.726632833480835
Batch 40/64 loss: 1.7280174493789673
Batch 41/64 loss: 1.7233257293701172
Batch 42/64 loss: 1.7263145446777344
Batch 43/64 loss: 1.7242577075958252
Batch 44/64 loss: 1.7261793613433838
Batch 45/64 loss: 1.7241096496582031
Batch 46/64 loss: 1.7258317470550537
Batch 47/64 loss: 1.7252107858657837
Batch 48/64 loss: 1.730738878250122
Batch 49/64 loss: 1.7273499965667725
Batch 50/64 loss: 1.7277417182922363
Batch 51/64 loss: 1.7256054878234863
Batch 52/64 loss: 1.7254502773284912
Batch 53/64 loss: 1.734148621559143
Batch 54/64 loss: 1.735464096069336
Batch 55/64 loss: 1.726438283920288
Batch 56/64 loss: 1.7265417575836182
Batch 57/64 loss: 1.7276298999786377
Batch 58/64 loss: 1.7244892120361328
Batch 59/64 loss: 1.7260923385620117
Batch 60/64 loss: 1.727693796157837
Batch 61/64 loss: 1.7256340980529785
Batch 62/64 loss: 1.7282298803329468
Batch 63/64 loss: 1.732344388961792
Batch 64/64 loss: 1.9150614738464355
Epoch 448  Train loss: 1.7308749311110552  Val loss: 1.7487283867249375
Epoch 449
-------------------------------
Batch 1/64 loss: 1.7451388835906982
Batch 2/64 loss: 1.7261197566986084
Batch 3/64 loss: 1.7442731857299805
Batch 4/64 loss: 1.7268949747085571
Batch 5/64 loss: 1.7307205200195312
Batch 6/64 loss: 1.7377583980560303
Batch 7/64 loss: 1.7264413833618164
Batch 8/64 loss: 1.7261306047439575
Batch 9/64 loss: 1.726574182510376
Batch 10/64 loss: 1.728754997253418
Batch 11/64 loss: 1.7286653518676758
Batch 12/64 loss: 1.7270822525024414
Batch 13/64 loss: 1.7252771854400635
Batch 14/64 loss: 1.7269272804260254
Batch 15/64 loss: 1.7237625122070312
Batch 16/64 loss: 1.7267097234725952
Batch 17/64 loss: 1.727644443511963
Batch 18/64 loss: 1.7280099391937256
Batch 19/64 loss: 1.7327972650527954
Batch 20/64 loss: 1.7293585538864136
Batch 21/64 loss: 1.7249085903167725
Batch 22/64 loss: 1.726973533630371
Batch 23/64 loss: 1.7287826538085938
Batch 24/64 loss: 1.726534128189087
Batch 25/64 loss: 1.7372106313705444
Batch 26/64 loss: 1.729163408279419
Batch 27/64 loss: 1.724756121635437
Batch 28/64 loss: 1.7295424938201904
Batch 29/64 loss: 1.724590539932251
Batch 30/64 loss: 1.7249162197113037
Batch 31/64 loss: 1.7438280582427979
Batch 32/64 loss: 1.7239243984222412
Batch 33/64 loss: 1.731367588043213
Batch 34/64 loss: 1.7249711751937866
Batch 35/64 loss: 1.725921869277954
Batch 36/64 loss: 1.7246613502502441
Batch 37/64 loss: 1.7315634489059448
Batch 38/64 loss: 1.7271769046783447
Batch 39/64 loss: 1.7243454456329346
Batch 40/64 loss: 1.727487564086914
Batch 41/64 loss: 1.7302546501159668
Batch 42/64 loss: 1.727942943572998
Batch 43/64 loss: 1.7274346351623535
Batch 44/64 loss: 1.7253315448760986
Batch 45/64 loss: 1.726416826248169
Batch 46/64 loss: 1.7289918661117554
Batch 47/64 loss: 1.727306604385376
Batch 48/64 loss: 1.7261245250701904
Batch 49/64 loss: 1.7239279747009277
Batch 50/64 loss: 1.7266643047332764
Batch 51/64 loss: 1.7307443618774414
Batch 52/64 loss: 1.7332336902618408
Batch 53/64 loss: 1.725067138671875
Batch 54/64 loss: 1.7278984785079956
Batch 55/64 loss: 1.731942892074585
Batch 56/64 loss: 1.7262609004974365
Batch 57/64 loss: 1.731482982635498
Batch 58/64 loss: 1.7294468879699707
Batch 59/64 loss: 1.7282886505126953
Batch 60/64 loss: 1.7300550937652588
Batch 61/64 loss: 1.7292428016662598
Batch 62/64 loss: 1.726016640663147
Batch 63/64 loss: 1.7273905277252197
Batch 64/64 loss: 1.9059643745422363
Epoch 449  Train loss: 1.7307389446333343  Val loss: 1.7425648289447797
Saving best model, epoch: 449
Epoch 450
-------------------------------
Batch 1/64 loss: 1.7260031700134277
Batch 2/64 loss: 1.7272779941558838
Batch 3/64 loss: 1.7252466678619385
Batch 4/64 loss: 1.7275668382644653
Batch 5/64 loss: 1.7303409576416016
Batch 6/64 loss: 1.724853754043579
Batch 7/64 loss: 1.7358283996582031
Batch 8/64 loss: 1.7255916595458984
Batch 9/64 loss: 1.7262341976165771
Batch 10/64 loss: 1.7266054153442383
Batch 11/64 loss: 1.730552315711975
Batch 12/64 loss: 1.726578950881958
Batch 13/64 loss: 1.7227683067321777
Batch 14/64 loss: 1.727982997894287
Batch 15/64 loss: 1.7304624319076538
Batch 16/64 loss: 1.7247557640075684
Batch 17/64 loss: 1.744868516921997
Batch 18/64 loss: 1.7283358573913574
Batch 19/64 loss: 1.727213978767395
Batch 20/64 loss: 1.725328803062439
Batch 21/64 loss: 1.7285575866699219
Batch 22/64 loss: 1.7267627716064453
Batch 23/64 loss: 1.7239367961883545
Batch 24/64 loss: 1.7317934036254883
Batch 25/64 loss: 1.7303848266601562
Batch 26/64 loss: 1.726263403892517
Batch 27/64 loss: 1.7367761135101318
Batch 28/64 loss: 1.7287648916244507
Batch 29/64 loss: 1.7304129600524902
Batch 30/64 loss: 1.7388925552368164
Batch 31/64 loss: 1.7365443706512451
Batch 32/64 loss: 1.739529013633728
Batch 33/64 loss: 1.7257678508758545
Batch 34/64 loss: 1.7248369455337524
Batch 35/64 loss: 1.7284698486328125
Batch 36/64 loss: 1.7264422178268433
Batch 37/64 loss: 1.73081636428833
Batch 38/64 loss: 1.7267018556594849
Batch 39/64 loss: 1.7264039516448975
Batch 40/64 loss: 1.7243913412094116
Batch 41/64 loss: 1.7246650457382202
Batch 42/64 loss: 1.7255754470825195
Batch 43/64 loss: 1.7236741781234741
Batch 44/64 loss: 1.7250266075134277
Batch 45/64 loss: 1.7271026372909546
Batch 46/64 loss: 1.7237646579742432
Batch 47/64 loss: 1.7256191968917847
Batch 48/64 loss: 1.7273613214492798
Batch 49/64 loss: 1.725679874420166
Batch 50/64 loss: 1.725719690322876
Batch 51/64 loss: 1.726448655128479
Batch 52/64 loss: 1.7259533405303955
Batch 53/64 loss: 1.7236237525939941
Batch 54/64 loss: 1.7258894443511963
Batch 55/64 loss: 1.7246456146240234
Batch 56/64 loss: 1.725156307220459
Batch 57/64 loss: 1.7271482944488525
Batch 58/64 loss: 1.7295199632644653
Batch 59/64 loss: 1.7272591590881348
Batch 60/64 loss: 1.7255935668945312
Batch 61/64 loss: 1.7264937162399292
Batch 62/64 loss: 1.7281486988067627
Batch 63/64 loss: 1.7255586385726929
Batch 64/64 loss: 1.9027358293533325
Epoch 450  Train loss: 1.7298749133652331  Val loss: 1.7429412869653342
Epoch 451
-------------------------------
Batch 1/64 loss: 1.725704312324524
Batch 2/64 loss: 1.7297887802124023
Batch 3/64 loss: 1.7265695333480835
Batch 4/64 loss: 1.7259514331817627
Batch 5/64 loss: 1.727242112159729
Batch 6/64 loss: 1.7276976108551025
Batch 7/64 loss: 1.7253912687301636
Batch 8/64 loss: 1.7234641313552856
Batch 9/64 loss: 1.723285436630249
Batch 10/64 loss: 1.7249064445495605
Batch 11/64 loss: 1.7264702320098877
Batch 12/64 loss: 1.725217342376709
Batch 13/64 loss: 1.724205493927002
Batch 14/64 loss: 1.7266621589660645
Batch 15/64 loss: 1.7265088558197021
Batch 16/64 loss: 1.7238287925720215
Batch 17/64 loss: 1.7247285842895508
Batch 18/64 loss: 1.730297327041626
Batch 19/64 loss: 1.7232506275177002
Batch 20/64 loss: 1.724420428276062
Batch 21/64 loss: 1.7264562845230103
Batch 22/64 loss: 1.7240679264068604
Batch 23/64 loss: 1.7252137660980225
Batch 24/64 loss: 1.7251307964324951
Batch 25/64 loss: 1.724596381187439
Batch 26/64 loss: 1.724257230758667
Batch 27/64 loss: 1.7251298427581787
Batch 28/64 loss: 1.725583553314209
Batch 29/64 loss: 1.7241528034210205
Batch 30/64 loss: 1.7292537689208984
Batch 31/64 loss: 1.7255759239196777
Batch 32/64 loss: 1.7256656885147095
Batch 33/64 loss: 1.732315182685852
Batch 34/64 loss: 1.7309784889221191
Batch 35/64 loss: 1.7334829568862915
Batch 36/64 loss: 1.7434656620025635
Batch 37/64 loss: 1.7258155345916748
Batch 38/64 loss: 1.7428221702575684
Batch 39/64 loss: 1.7286266088485718
Batch 40/64 loss: 1.7473208904266357
Batch 41/64 loss: 1.734167456626892
Batch 42/64 loss: 1.7346950769424438
Batch 43/64 loss: 1.73659086227417
Batch 44/64 loss: 1.7358167171478271
Batch 45/64 loss: 1.7306309938430786
Batch 46/64 loss: 1.7301137447357178
Batch 47/64 loss: 1.7265965938568115
Batch 48/64 loss: 1.7266011238098145
Batch 49/64 loss: 1.729503870010376
Batch 50/64 loss: 1.724785327911377
Batch 51/64 loss: 1.7283673286437988
Batch 52/64 loss: 1.7424240112304688
Batch 53/64 loss: 1.7299818992614746
Batch 54/64 loss: 1.7273383140563965
Batch 55/64 loss: 1.7277753353118896
Batch 56/64 loss: 1.7275257110595703
Batch 57/64 loss: 1.7300431728363037
Batch 58/64 loss: 1.7312047481536865
Batch 59/64 loss: 1.7319233417510986
Batch 60/64 loss: 1.727817416191101
Batch 61/64 loss: 1.7308018207550049
Batch 62/64 loss: 1.7323622703552246
Batch 63/64 loss: 1.7291243076324463
Batch 64/64 loss: 1.9033377170562744
Epoch 451  Train loss: 1.7308109348895504  Val loss: 1.7477515014176517
Epoch 452
-------------------------------
Batch 1/64 loss: 1.7279773950576782
Batch 2/64 loss: 1.7315237522125244
Batch 3/64 loss: 1.726085901260376
Batch 4/64 loss: 1.7322802543640137
Batch 5/64 loss: 1.7350068092346191
Batch 6/64 loss: 1.7329579591751099
Batch 7/64 loss: 1.7295197248458862
Batch 8/64 loss: 1.7319214344024658
Batch 9/64 loss: 1.7302106618881226
Batch 10/64 loss: 1.723712682723999
Batch 11/64 loss: 1.7287969589233398
Batch 12/64 loss: 1.7294130325317383
Batch 13/64 loss: 1.7305346727371216
Batch 14/64 loss: 1.7283713817596436
Batch 15/64 loss: 1.7321107387542725
Batch 16/64 loss: 1.7347280979156494
Batch 17/64 loss: 1.732284426689148
Batch 18/64 loss: 1.7323265075683594
Batch 19/64 loss: 1.7354750633239746
Batch 20/64 loss: 1.7448787689208984
Batch 21/64 loss: 1.729142427444458
Batch 22/64 loss: 1.7325479984283447
Batch 23/64 loss: 1.730360746383667
Batch 24/64 loss: 1.727501630783081
Batch 25/64 loss: 1.7287583351135254
Batch 26/64 loss: 1.7303519248962402
Batch 27/64 loss: 1.735714077949524
Batch 28/64 loss: 1.7343683242797852
Batch 29/64 loss: 1.7254633903503418
Batch 30/64 loss: 1.731483817100525
Batch 31/64 loss: 1.7279529571533203
Batch 32/64 loss: 1.7288384437561035
Batch 33/64 loss: 1.741088628768921
Batch 34/64 loss: 1.729940414428711
Batch 35/64 loss: 1.7316025495529175
Batch 36/64 loss: 1.727968692779541
Batch 37/64 loss: 1.7382663488388062
Batch 38/64 loss: 1.7302970886230469
Batch 39/64 loss: 1.7292782068252563
Batch 40/64 loss: 1.7288628816604614
Batch 41/64 loss: 1.7288167476654053
Batch 42/64 loss: 1.7306808233261108
Batch 43/64 loss: 1.7299472093582153
Batch 44/64 loss: 1.7308733463287354
Batch 45/64 loss: 1.7277042865753174
Batch 46/64 loss: 1.7297523021697998
Batch 47/64 loss: 1.729636549949646
Batch 48/64 loss: 1.7302391529083252
Batch 49/64 loss: 1.7325537204742432
Batch 50/64 loss: 1.7327377796173096
Batch 51/64 loss: 1.731175422668457
Batch 52/64 loss: 1.7278411388397217
Batch 53/64 loss: 1.733377456665039
Batch 54/64 loss: 1.7258732318878174
Batch 55/64 loss: 1.729123830795288
Batch 56/64 loss: 1.743783950805664
Batch 57/64 loss: 1.7311556339263916
Batch 58/64 loss: 1.7271357774734497
Batch 59/64 loss: 1.7360098361968994
Batch 60/64 loss: 1.732527732849121
Batch 61/64 loss: 1.7313318252563477
Batch 62/64 loss: 1.7381718158721924
Batch 63/64 loss: 1.7385079860687256
Batch 64/64 loss: 1.9124006032943726
Epoch 452  Train loss: 1.7335398136400708  Val loss: 1.7571833092732119
Epoch 453
-------------------------------
Batch 1/64 loss: 1.73269784450531
Batch 2/64 loss: 1.7479666471481323
Batch 3/64 loss: 1.7393193244934082
Batch 4/64 loss: 1.7306355237960815
Batch 5/64 loss: 1.735954999923706
Batch 6/64 loss: 1.7395262718200684
Batch 7/64 loss: 1.727280855178833
Batch 8/64 loss: 1.731117844581604
Batch 9/64 loss: 1.7328227758407593
Batch 10/64 loss: 1.7318028211593628
Batch 11/64 loss: 1.746069073677063
Batch 12/64 loss: 1.7288886308670044
Batch 13/64 loss: 1.7289543151855469
Batch 14/64 loss: 1.7437663078308105
Batch 15/64 loss: 1.7317028045654297
Batch 16/64 loss: 1.7339677810668945
Batch 17/64 loss: 1.7300992012023926
Batch 18/64 loss: 1.727484107017517
Batch 19/64 loss: 1.7252461910247803
Batch 20/64 loss: 1.7280606031417847
Batch 21/64 loss: 1.7315539121627808
Batch 22/64 loss: 1.735031008720398
Batch 23/64 loss: 1.7271230220794678
Batch 24/64 loss: 1.7329858541488647
Batch 25/64 loss: 1.726813554763794
Batch 26/64 loss: 1.7286996841430664
Batch 27/64 loss: 1.7257121801376343
Batch 28/64 loss: 1.7301783561706543
Batch 29/64 loss: 1.7269604206085205
Batch 30/64 loss: 1.7288260459899902
Batch 31/64 loss: 1.726423740386963
Batch 32/64 loss: 1.7321290969848633
Batch 33/64 loss: 1.7232736349105835
Batch 34/64 loss: 1.7300570011138916
Batch 35/64 loss: 1.7264920473098755
Batch 36/64 loss: 1.7252986431121826
Batch 37/64 loss: 1.7241630554199219
Batch 38/64 loss: 1.7290232181549072
Batch 39/64 loss: 1.7270488739013672
Batch 40/64 loss: 1.7248001098632812
Batch 41/64 loss: 1.7293903827667236
Batch 42/64 loss: 1.7279818058013916
Batch 43/64 loss: 1.7262074947357178
Batch 44/64 loss: 1.7326403856277466
Batch 45/64 loss: 1.7317636013031006
Batch 46/64 loss: 1.7297534942626953
Batch 47/64 loss: 1.725970983505249
Batch 48/64 loss: 1.72597074508667
Batch 49/64 loss: 1.7282037734985352
Batch 50/64 loss: 1.7307475805282593
Batch 51/64 loss: 1.7262468338012695
Batch 52/64 loss: 1.7253384590148926
Batch 53/64 loss: 1.7267146110534668
Batch 54/64 loss: 1.7279075384140015
Batch 55/64 loss: 1.7277140617370605
Batch 56/64 loss: 1.729234218597412
Batch 57/64 loss: 1.723658561706543
Batch 58/64 loss: 1.7282838821411133
Batch 59/64 loss: 1.7244054079055786
Batch 60/64 loss: 1.7272157669067383
Batch 61/64 loss: 1.728369951248169
Batch 62/64 loss: 1.7263355255126953
Batch 63/64 loss: 1.7434828281402588
Batch 64/64 loss: 1.9177063703536987
Epoch 453  Train loss: 1.7322003930222754  Val loss: 1.7440348376113524
Epoch 454
-------------------------------
Batch 1/64 loss: 1.7306957244873047
Batch 2/64 loss: 1.7274843454360962
Batch 3/64 loss: 1.7336091995239258
Batch 4/64 loss: 1.7266608476638794
Batch 5/64 loss: 1.7256152629852295
Batch 6/64 loss: 1.728416919708252
Batch 7/64 loss: 1.7302520275115967
Batch 8/64 loss: 1.727245569229126
Batch 9/64 loss: 1.724178671836853
Batch 10/64 loss: 1.7272326946258545
Batch 11/64 loss: 1.7270820140838623
Batch 12/64 loss: 1.7242810726165771
Batch 13/64 loss: 1.7265987396240234
Batch 14/64 loss: 1.7285171747207642
Batch 15/64 loss: 1.7249031066894531
Batch 16/64 loss: 1.7269755601882935
Batch 17/64 loss: 1.728692650794983
Batch 18/64 loss: 1.7266262769699097
Batch 19/64 loss: 1.7406034469604492
Batch 20/64 loss: 1.7245652675628662
Batch 21/64 loss: 1.7253026962280273
Batch 22/64 loss: 1.7451941967010498
Batch 23/64 loss: 1.723928689956665
Batch 24/64 loss: 1.7247817516326904
Batch 25/64 loss: 1.727287769317627
Batch 26/64 loss: 1.7292702198028564
Batch 27/64 loss: 1.74446439743042
Batch 28/64 loss: 1.7230584621429443
Batch 29/64 loss: 1.7244133949279785
Batch 30/64 loss: 1.728248119354248
Batch 31/64 loss: 1.7246191501617432
Batch 32/64 loss: 1.7300881147384644
Batch 33/64 loss: 1.7261979579925537
Batch 34/64 loss: 1.7270946502685547
Batch 35/64 loss: 1.724879503250122
Batch 36/64 loss: 1.7239829301834106
Batch 37/64 loss: 1.7278234958648682
Batch 38/64 loss: 1.7258821725845337
Batch 39/64 loss: 1.7257840633392334
Batch 40/64 loss: 1.723780870437622
Batch 41/64 loss: 1.725172758102417
Batch 42/64 loss: 1.7235578298568726
Batch 43/64 loss: 1.724522352218628
Batch 44/64 loss: 1.7279340028762817
Batch 45/64 loss: 1.7232788801193237
Batch 46/64 loss: 1.7252211570739746
Batch 47/64 loss: 1.722651720046997
Batch 48/64 loss: 1.724669098854065
Batch 49/64 loss: 1.7248247861862183
Batch 50/64 loss: 1.7267282009124756
Batch 51/64 loss: 1.7254629135131836
Batch 52/64 loss: 1.7290196418762207
Batch 53/64 loss: 1.7290737628936768
Batch 54/64 loss: 1.725982427597046
Batch 55/64 loss: 1.7251065969467163
Batch 56/64 loss: 1.7278597354888916
Batch 57/64 loss: 1.7248735427856445
Batch 58/64 loss: 1.7339909076690674
Batch 59/64 loss: 1.7256696224212646
Batch 60/64 loss: 1.7298485040664673
Batch 61/64 loss: 1.727745771408081
Batch 62/64 loss: 1.7277241945266724
Batch 63/64 loss: 1.7270441055297852
Batch 64/64 loss: 1.917900562286377
Epoch 454  Train loss: 1.7296110919877594  Val loss: 1.7456893462086052
Epoch 455
-------------------------------
Batch 1/64 loss: 1.728334903717041
Batch 2/64 loss: 1.7249364852905273
Batch 3/64 loss: 1.7290042638778687
Batch 4/64 loss: 1.7274999618530273
Batch 5/64 loss: 1.7286148071289062
Batch 6/64 loss: 1.7276172637939453
Batch 7/64 loss: 1.7256720066070557
Batch 8/64 loss: 1.7262389659881592
Batch 9/64 loss: 1.728351354598999
Batch 10/64 loss: 1.7260088920593262
Batch 11/64 loss: 1.7274589538574219
Batch 12/64 loss: 1.7288851737976074
Batch 13/64 loss: 1.7323880195617676
Batch 14/64 loss: 1.7268667221069336
Batch 15/64 loss: 1.7291052341461182
Batch 16/64 loss: 1.7268528938293457
Batch 17/64 loss: 1.7263729572296143
Batch 18/64 loss: 1.74020254611969
Batch 19/64 loss: 1.731318473815918
Batch 20/64 loss: 1.7313734292984009
Batch 21/64 loss: 1.7247390747070312
Batch 22/64 loss: 1.7271811962127686
Batch 23/64 loss: 1.72969388961792
Batch 24/64 loss: 1.7275378704071045
Batch 25/64 loss: 1.7273820638656616
Batch 26/64 loss: 1.7248847484588623
Batch 27/64 loss: 1.7277151346206665
Batch 28/64 loss: 1.7276562452316284
Batch 29/64 loss: 1.727258563041687
Batch 30/64 loss: 1.7256603240966797
Batch 31/64 loss: 1.7284646034240723
Batch 32/64 loss: 1.7317848205566406
Batch 33/64 loss: 1.7306574583053589
Batch 34/64 loss: 1.7288036346435547
Batch 35/64 loss: 1.7311238050460815
Batch 36/64 loss: 1.72781503200531
Batch 37/64 loss: 1.7286887168884277
Batch 38/64 loss: 1.7334617376327515
Batch 39/64 loss: 1.7293381690979004
Batch 40/64 loss: 1.728971242904663
Batch 41/64 loss: 1.730718970298767
Batch 42/64 loss: 1.7273887395858765
Batch 43/64 loss: 1.7294549942016602
Batch 44/64 loss: 1.7477468252182007
Batch 45/64 loss: 1.7333523035049438
Batch 46/64 loss: 1.7297409772872925
Batch 47/64 loss: 1.7263984680175781
Batch 48/64 loss: 1.7278268337249756
Batch 49/64 loss: 1.7308340072631836
Batch 50/64 loss: 1.7263745069503784
Batch 51/64 loss: 1.74196195602417
Batch 52/64 loss: 1.7258363962173462
Batch 53/64 loss: 1.7301673889160156
Batch 54/64 loss: 1.7274490594863892
Batch 55/64 loss: 1.7354168891906738
Batch 56/64 loss: 1.727095365524292
Batch 57/64 loss: 1.7344110012054443
Batch 58/64 loss: 1.728883981704712
Batch 59/64 loss: 1.7273014783859253
Batch 60/64 loss: 1.7264108657836914
Batch 61/64 loss: 1.7310796976089478
Batch 62/64 loss: 1.730872631072998
Batch 63/64 loss: 1.7309472560882568
Batch 64/64 loss: 1.9071508646011353
Epoch 455  Train loss: 1.7314502804887062  Val loss: 1.7449099968389137
Epoch 456
-------------------------------
Batch 1/64 loss: 1.7277246713638306
Batch 2/64 loss: 1.7255383729934692
Batch 3/64 loss: 1.7261439561843872
Batch 4/64 loss: 1.7289471626281738
Batch 5/64 loss: 1.727544903755188
Batch 6/64 loss: 1.7284753322601318
Batch 7/64 loss: 1.7254045009613037
Batch 8/64 loss: 1.7283309698104858
Batch 9/64 loss: 1.7289137840270996
Batch 10/64 loss: 1.732964277267456
Batch 11/64 loss: 1.727874517440796
Batch 12/64 loss: 1.730217695236206
Batch 13/64 loss: 1.7252644300460815
Batch 14/64 loss: 1.7255982160568237
Batch 15/64 loss: 1.7263243198394775
Batch 16/64 loss: 1.72699773311615
Batch 17/64 loss: 1.7288897037506104
Batch 18/64 loss: 1.7248659133911133
Batch 19/64 loss: 1.7267189025878906
Batch 20/64 loss: 1.727813959121704
Batch 21/64 loss: 1.725846767425537
Batch 22/64 loss: 1.7246780395507812
Batch 23/64 loss: 1.7248343229293823
Batch 24/64 loss: 1.7229461669921875
Batch 25/64 loss: 1.726057767868042
Batch 26/64 loss: 1.7402153015136719
Batch 27/64 loss: 1.7296370267868042
Batch 28/64 loss: 1.7261018753051758
Batch 29/64 loss: 1.7260996103286743
Batch 30/64 loss: 1.722222924232483
Batch 31/64 loss: 1.7285131216049194
Batch 32/64 loss: 1.7301349639892578
Batch 33/64 loss: 1.7493349313735962
Batch 34/64 loss: 1.7259013652801514
Batch 35/64 loss: 1.7316310405731201
Batch 36/64 loss: 1.727654218673706
Batch 37/64 loss: 1.731508493423462
Batch 38/64 loss: 1.7258992195129395
Batch 39/64 loss: 1.7240312099456787
Batch 40/64 loss: 1.726802110671997
Batch 41/64 loss: 1.723501205444336
Batch 42/64 loss: 1.7319647073745728
Batch 43/64 loss: 1.7266855239868164
Batch 44/64 loss: 1.7282981872558594
Batch 45/64 loss: 1.723630666732788
Batch 46/64 loss: 1.7263538837432861
Batch 47/64 loss: 1.7271161079406738
Batch 48/64 loss: 1.7273437976837158
Batch 49/64 loss: 1.7253315448760986
Batch 50/64 loss: 1.7250081300735474
Batch 51/64 loss: 1.7230160236358643
Batch 52/64 loss: 1.726844072341919
Batch 53/64 loss: 1.7313129901885986
Batch 54/64 loss: 1.724018931388855
Batch 55/64 loss: 1.7267192602157593
Batch 56/64 loss: 1.7247700691223145
Batch 57/64 loss: 1.7261831760406494
Batch 58/64 loss: 1.7249534130096436
Batch 59/64 loss: 1.7260682582855225
Batch 60/64 loss: 1.7415052652359009
Batch 61/64 loss: 1.72678804397583
Batch 62/64 loss: 1.7282437086105347
Batch 63/64 loss: 1.7267200946807861
Batch 64/64 loss: 1.9033780097961426
Epoch 456  Train loss: 1.7297335587295832  Val loss: 1.7448320913150959
Epoch 457
-------------------------------
Batch 1/64 loss: 1.7283241748809814
Batch 2/64 loss: 1.7260195016860962
Batch 3/64 loss: 1.7254912853240967
Batch 4/64 loss: 1.7255313396453857
Batch 5/64 loss: 1.7257232666015625
Batch 6/64 loss: 1.7375767230987549
Batch 7/64 loss: 1.7269190549850464
Batch 8/64 loss: 1.724721908569336
Batch 9/64 loss: 1.7244153022766113
Batch 10/64 loss: 1.731091022491455
Batch 11/64 loss: 1.7248339653015137
Batch 12/64 loss: 1.7274905443191528
Batch 13/64 loss: 1.7239229679107666
Batch 14/64 loss: 1.728654146194458
Batch 15/64 loss: 1.724440097808838
Batch 16/64 loss: 1.7243807315826416
Batch 17/64 loss: 1.7230513095855713
Batch 18/64 loss: 1.7343754768371582
Batch 19/64 loss: 1.7252423763275146
Batch 20/64 loss: 1.723764181137085
Batch 21/64 loss: 1.7284855842590332
Batch 22/64 loss: 1.7262063026428223
Batch 23/64 loss: 1.7270777225494385
Batch 24/64 loss: 1.7263331413269043
Batch 25/64 loss: 1.7301616668701172
Batch 26/64 loss: 1.72919762134552
Batch 27/64 loss: 1.7287964820861816
Batch 28/64 loss: 1.72991144657135
Batch 29/64 loss: 1.7326092720031738
Batch 30/64 loss: 1.728354811668396
Batch 31/64 loss: 1.7265450954437256
Batch 32/64 loss: 1.728818416595459
Batch 33/64 loss: 1.728874683380127
Batch 34/64 loss: 1.7285698652267456
Batch 35/64 loss: 1.7270045280456543
Batch 36/64 loss: 1.7261567115783691
Batch 37/64 loss: 1.7289729118347168
Batch 38/64 loss: 1.7239784002304077
Batch 39/64 loss: 1.7251108884811401
Batch 40/64 loss: 1.726402759552002
Batch 41/64 loss: 1.738378643989563
Batch 42/64 loss: 1.7251999378204346
Batch 43/64 loss: 1.7260428667068481
Batch 44/64 loss: 1.7262673377990723
Batch 45/64 loss: 1.7267191410064697
Batch 46/64 loss: 1.7339869737625122
Batch 47/64 loss: 1.726886510848999
Batch 48/64 loss: 1.7285518646240234
Batch 49/64 loss: 1.7249476909637451
Batch 50/64 loss: 1.728888750076294
Batch 51/64 loss: 1.7269312143325806
Batch 52/64 loss: 1.7263374328613281
Batch 53/64 loss: 1.7253663539886475
Batch 54/64 loss: 1.7323050498962402
Batch 55/64 loss: 1.732985258102417
Batch 56/64 loss: 1.746678113937378
Batch 57/64 loss: 1.728698968887329
Batch 58/64 loss: 1.7257585525512695
Batch 59/64 loss: 1.7283231019973755
Batch 60/64 loss: 1.7256371974945068
Batch 61/64 loss: 1.7275562286376953
Batch 62/64 loss: 1.72605299949646
Batch 63/64 loss: 1.7266302108764648
Batch 64/64 loss: 1.9108657836914062
Epoch 457  Train loss: 1.7300677243401021  Val loss: 1.744485152955727
Epoch 458
-------------------------------
Batch 1/64 loss: 1.727083444595337
Batch 2/64 loss: 1.7287609577178955
Batch 3/64 loss: 1.7274141311645508
Batch 4/64 loss: 1.7286860942840576
Batch 5/64 loss: 1.7259540557861328
Batch 6/64 loss: 1.747546672821045
Batch 7/64 loss: 1.7262003421783447
Batch 8/64 loss: 1.7304227352142334
Batch 9/64 loss: 1.7280579805374146
Batch 10/64 loss: 1.7253544330596924
Batch 11/64 loss: 1.730116605758667
Batch 12/64 loss: 1.728224277496338
Batch 13/64 loss: 1.7289800643920898
Batch 14/64 loss: 1.7301753759384155
Batch 15/64 loss: 1.7258286476135254
Batch 16/64 loss: 1.7260913848876953
Batch 17/64 loss: 1.7277562618255615
Batch 18/64 loss: 1.7294788360595703
Batch 19/64 loss: 1.7281150817871094
Batch 20/64 loss: 1.7269468307495117
Batch 21/64 loss: 1.728737235069275
Batch 22/64 loss: 1.7258048057556152
Batch 23/64 loss: 1.726076602935791
Batch 24/64 loss: 1.7261508703231812
Batch 25/64 loss: 1.7291189432144165
Batch 26/64 loss: 1.725467324256897
Batch 27/64 loss: 1.7247920036315918
Batch 28/64 loss: 1.726179599761963
Batch 29/64 loss: 1.7363102436065674
Batch 30/64 loss: 1.725715160369873
Batch 31/64 loss: 1.730231761932373
Batch 32/64 loss: 1.7275779247283936
Batch 33/64 loss: 1.7373251914978027
Batch 34/64 loss: 1.7262346744537354
Batch 35/64 loss: 1.7267611026763916
Batch 36/64 loss: 1.7269830703735352
Batch 37/64 loss: 1.7286434173583984
Batch 38/64 loss: 1.731688141822815
Batch 39/64 loss: 1.7275290489196777
Batch 40/64 loss: 1.727496862411499
Batch 41/64 loss: 1.7249207496643066
Batch 42/64 loss: 1.725811243057251
Batch 43/64 loss: 1.728517770767212
Batch 44/64 loss: 1.7263855934143066
Batch 45/64 loss: 1.7279675006866455
Batch 46/64 loss: 1.7281913757324219
Batch 47/64 loss: 1.729682207107544
Batch 48/64 loss: 1.7386151552200317
Batch 49/64 loss: 1.7276369333267212
Batch 50/64 loss: 1.7286224365234375
Batch 51/64 loss: 1.7248198986053467
Batch 52/64 loss: 1.7278988361358643
Batch 53/64 loss: 1.7403814792633057
Batch 54/64 loss: 1.7263603210449219
Batch 55/64 loss: 1.723853588104248
Batch 56/64 loss: 1.733530879020691
Batch 57/64 loss: 1.7271671295166016
Batch 58/64 loss: 1.7269984483718872
Batch 59/64 loss: 1.7263855934143066
Batch 60/64 loss: 1.725832462310791
Batch 61/64 loss: 1.729629635810852
Batch 62/64 loss: 1.7288165092468262
Batch 63/64 loss: 1.7305009365081787
Batch 64/64 loss: 1.9098284244537354
Epoch 458  Train loss: 1.7307124109829173  Val loss: 1.7444500726522858
Epoch 459
-------------------------------
Batch 1/64 loss: 1.7258378267288208
Batch 2/64 loss: 1.7268922328948975
Batch 3/64 loss: 1.7243263721466064
Batch 4/64 loss: 1.72857666015625
Batch 5/64 loss: 1.7284832000732422
Batch 6/64 loss: 1.7250007390975952
Batch 7/64 loss: 1.7276381254196167
Batch 8/64 loss: 1.7289013862609863
Batch 9/64 loss: 1.728563904762268
Batch 10/64 loss: 1.7296671867370605
Batch 11/64 loss: 1.7298943996429443
Batch 12/64 loss: 1.7253108024597168
Batch 13/64 loss: 1.7274150848388672
Batch 14/64 loss: 1.7268168926239014
Batch 15/64 loss: 1.7229079008102417
Batch 16/64 loss: 1.7258546352386475
Batch 17/64 loss: 1.7238925695419312
Batch 18/64 loss: 1.7247755527496338
Batch 19/64 loss: 1.7277107238769531
Batch 20/64 loss: 1.725903034210205
Batch 21/64 loss: 1.7457252740859985
Batch 22/64 loss: 1.7252532243728638
Batch 23/64 loss: 1.7248679399490356
Batch 24/64 loss: 1.7273914813995361
Batch 25/64 loss: 1.7286086082458496
Batch 26/64 loss: 1.7241984605789185
Batch 27/64 loss: 1.7264423370361328
Batch 28/64 loss: 1.7294316291809082
Batch 29/64 loss: 1.7255144119262695
Batch 30/64 loss: 1.7241663932800293
Batch 31/64 loss: 1.7266590595245361
Batch 32/64 loss: 1.7249929904937744
Batch 33/64 loss: 1.7313363552093506
Batch 34/64 loss: 1.7234996557235718
Batch 35/64 loss: 1.7279994487762451
Batch 36/64 loss: 1.7231621742248535
Batch 37/64 loss: 1.7235370874404907
Batch 38/64 loss: 1.725421667098999
Batch 39/64 loss: 1.7258648872375488
Batch 40/64 loss: 1.7250003814697266
Batch 41/64 loss: 1.724391222000122
Batch 42/64 loss: 1.7236976623535156
Batch 43/64 loss: 1.72300124168396
Batch 44/64 loss: 1.725745439529419
Batch 45/64 loss: 1.7239203453063965
Batch 46/64 loss: 1.7259423732757568
Batch 47/64 loss: 1.7229883670806885
Batch 48/64 loss: 1.751357078552246
Batch 49/64 loss: 1.730218529701233
Batch 50/64 loss: 1.7273703813552856
Batch 51/64 loss: 1.726891040802002
Batch 52/64 loss: 1.7253367900848389
Batch 53/64 loss: 1.7302923202514648
Batch 54/64 loss: 1.7274432182312012
Batch 55/64 loss: 1.725872278213501
Batch 56/64 loss: 1.7251050472259521
Batch 57/64 loss: 1.725463628768921
Batch 58/64 loss: 1.7297649383544922
Batch 59/64 loss: 1.7247157096862793
Batch 60/64 loss: 1.731600284576416
Batch 61/64 loss: 1.7307796478271484
Batch 62/64 loss: 1.7285434007644653
Batch 63/64 loss: 1.7255282402038574
Batch 64/64 loss: 1.9030019044876099
Epoch 459  Train loss: 1.729202561752469  Val loss: 1.7447459197945612
Epoch 460
-------------------------------
Batch 1/64 loss: 1.7246620655059814
Batch 2/64 loss: 1.7270593643188477
Batch 3/64 loss: 1.7271833419799805
Batch 4/64 loss: 1.7260758876800537
Batch 5/64 loss: 1.7255946397781372
Batch 6/64 loss: 1.7277500629425049
Batch 7/64 loss: 1.725496530532837
Batch 8/64 loss: 1.726939082145691
Batch 9/64 loss: 1.7275389432907104
Batch 10/64 loss: 1.7235846519470215
Batch 11/64 loss: 1.7305136919021606
Batch 12/64 loss: 1.7249748706817627
Batch 13/64 loss: 1.7299426794052124
Batch 14/64 loss: 1.724310278892517
Batch 15/64 loss: 1.726533055305481
Batch 16/64 loss: 1.7272391319274902
Batch 17/64 loss: 1.7248733043670654
Batch 18/64 loss: 1.723478078842163
Batch 19/64 loss: 1.7286183834075928
Batch 20/64 loss: 1.7311197519302368
Batch 21/64 loss: 1.7241640090942383
Batch 22/64 loss: 1.728929042816162
Batch 23/64 loss: 1.7382367849349976
Batch 24/64 loss: 1.725071907043457
Batch 25/64 loss: 1.7256834506988525
Batch 26/64 loss: 1.725619912147522
Batch 27/64 loss: 1.7228765487670898
Batch 28/64 loss: 1.7280187606811523
Batch 29/64 loss: 1.7231791019439697
Batch 30/64 loss: 1.725632667541504
Batch 31/64 loss: 1.7253973484039307
Batch 32/64 loss: 1.7214781045913696
Batch 33/64 loss: 1.7233552932739258
Batch 34/64 loss: 1.723179578781128
Batch 35/64 loss: 1.7250380516052246
Batch 36/64 loss: 1.723629117012024
Batch 37/64 loss: 1.7248868942260742
Batch 38/64 loss: 1.7263472080230713
Batch 39/64 loss: 1.7270879745483398
Batch 40/64 loss: 1.7230572700500488
Batch 41/64 loss: 1.724583387374878
Batch 42/64 loss: 1.7260987758636475
Batch 43/64 loss: 1.724253535270691
Batch 44/64 loss: 1.726190209388733
Batch 45/64 loss: 1.724247694015503
Batch 46/64 loss: 1.740195631980896
Batch 47/64 loss: 1.7233964204788208
Batch 48/64 loss: 1.7267394065856934
Batch 49/64 loss: 1.724353313446045
Batch 50/64 loss: 1.72259521484375
Batch 51/64 loss: 1.725245714187622
Batch 52/64 loss: 1.7224793434143066
Batch 53/64 loss: 1.740980625152588
Batch 54/64 loss: 1.7247976064682007
Batch 55/64 loss: 1.7249963283538818
Batch 56/64 loss: 1.7236475944519043
Batch 57/64 loss: 1.7309423685073853
Batch 58/64 loss: 1.7280728816986084
Batch 59/64 loss: 1.7220630645751953
Batch 60/64 loss: 1.7217508554458618
Batch 61/64 loss: 1.7236464023590088
Batch 62/64 loss: 1.7294912338256836
Batch 63/64 loss: 1.7256581783294678
Batch 64/64 loss: 1.9050207138061523
Epoch 460  Train loss: 1.7283066375582825  Val loss: 1.7426882076918875
Epoch 461
-------------------------------
Batch 1/64 loss: 1.7231173515319824
Batch 2/64 loss: 1.7335840463638306
Batch 3/64 loss: 1.7229105234146118
Batch 4/64 loss: 1.725501298904419
Batch 5/64 loss: 1.7234070301055908
Batch 6/64 loss: 1.73701810836792
Batch 7/64 loss: 1.7256288528442383
Batch 8/64 loss: 1.7253994941711426
Batch 9/64 loss: 1.7272096872329712
Batch 10/64 loss: 1.7289724349975586
Batch 11/64 loss: 1.7248663902282715
Batch 12/64 loss: 1.723764181137085
Batch 13/64 loss: 1.726966381072998
Batch 14/64 loss: 1.7266201972961426
Batch 15/64 loss: 1.726118803024292
Batch 16/64 loss: 1.7282850742340088
Batch 17/64 loss: 1.7245304584503174
Batch 18/64 loss: 1.7256922721862793
Batch 19/64 loss: 1.722830891609192
Batch 20/64 loss: 1.7264621257781982
Batch 21/64 loss: 1.7301558256149292
Batch 22/64 loss: 1.728109359741211
Batch 23/64 loss: 1.7271382808685303
Batch 24/64 loss: 1.726498007774353
Batch 25/64 loss: 1.7323728799819946
Batch 26/64 loss: 1.726341724395752
Batch 27/64 loss: 1.7261632680892944
Batch 28/64 loss: 1.748171329498291
Batch 29/64 loss: 1.7260663509368896
Batch 30/64 loss: 1.7286343574523926
Batch 31/64 loss: 1.7265145778656006
Batch 32/64 loss: 1.7278671264648438
Batch 33/64 loss: 1.724639654159546
Batch 34/64 loss: 1.728266954421997
Batch 35/64 loss: 1.7463431358337402
Batch 36/64 loss: 1.7296711206436157
Batch 37/64 loss: 1.7249133586883545
Batch 38/64 loss: 1.7249135971069336
Batch 39/64 loss: 1.7261075973510742
Batch 40/64 loss: 1.7254204750061035
Batch 41/64 loss: 1.7278074026107788
Batch 42/64 loss: 1.7268041372299194
Batch 43/64 loss: 1.730394959449768
Batch 44/64 loss: 1.7261865139007568
Batch 45/64 loss: 1.7281479835510254
Batch 46/64 loss: 1.7253313064575195
Batch 47/64 loss: 1.7269575595855713
Batch 48/64 loss: 1.7236826419830322
Batch 49/64 loss: 1.7271795272827148
Batch 50/64 loss: 1.735715627670288
Batch 51/64 loss: 1.7338143587112427
Batch 52/64 loss: 1.7281756401062012
Batch 53/64 loss: 1.729726791381836
Batch 54/64 loss: 1.7306478023529053
Batch 55/64 loss: 1.7269145250320435
Batch 56/64 loss: 1.7272179126739502
Batch 57/64 loss: 1.724745273590088
Batch 58/64 loss: 1.7280313968658447
Batch 59/64 loss: 1.7245694398880005
Batch 60/64 loss: 1.7276458740234375
Batch 61/64 loss: 1.735693097114563
Batch 62/64 loss: 1.7289564609527588
Batch 63/64 loss: 1.7338627576828003
Batch 64/64 loss: 1.9069393873214722
Epoch 461  Train loss: 1.730221303771524  Val loss: 1.7466817336393796
Epoch 462
-------------------------------
Batch 1/64 loss: 1.7263926267623901
Batch 2/64 loss: 1.7273056507110596
Batch 3/64 loss: 1.7277822494506836
Batch 4/64 loss: 1.7262780666351318
Batch 5/64 loss: 1.7350378036499023
Batch 6/64 loss: 1.727046251296997
Batch 7/64 loss: 1.7281341552734375
Batch 8/64 loss: 1.7266976833343506
Batch 9/64 loss: 1.7273340225219727
Batch 10/64 loss: 1.7276277542114258
Batch 11/64 loss: 1.729796290397644
Batch 12/64 loss: 1.7304744720458984
Batch 13/64 loss: 1.7256776094436646
Batch 14/64 loss: 1.7316901683807373
Batch 15/64 loss: 1.7276594638824463
Batch 16/64 loss: 1.7248032093048096
Batch 17/64 loss: 1.7250839471817017
Batch 18/64 loss: 1.7234632968902588
Batch 19/64 loss: 1.7478080987930298
Batch 20/64 loss: 1.7258055210113525
Batch 21/64 loss: 1.7249884605407715
Batch 22/64 loss: 1.7280635833740234
Batch 23/64 loss: 1.743005633354187
Batch 24/64 loss: 1.7246103286743164
Batch 25/64 loss: 1.7242859601974487
Batch 26/64 loss: 1.7281928062438965
Batch 27/64 loss: 1.7271732091903687
Batch 28/64 loss: 1.7233660221099854
Batch 29/64 loss: 1.7245450019836426
Batch 30/64 loss: 1.7254626750946045
Batch 31/64 loss: 1.7248194217681885
Batch 32/64 loss: 1.7272202968597412
Batch 33/64 loss: 1.7317332029342651
Batch 34/64 loss: 1.727260708808899
Batch 35/64 loss: 1.7280970811843872
Batch 36/64 loss: 1.723153829574585
Batch 37/64 loss: 1.7288625240325928
Batch 38/64 loss: 1.725386142730713
Batch 39/64 loss: 1.7227778434753418
Batch 40/64 loss: 1.7252585887908936
Batch 41/64 loss: 1.722642183303833
Batch 42/64 loss: 1.7229422330856323
Batch 43/64 loss: 1.7253361940383911
Batch 44/64 loss: 1.7215583324432373
Batch 45/64 loss: 1.723158836364746
Batch 46/64 loss: 1.724683165550232
Batch 47/64 loss: 1.7234389781951904
Batch 48/64 loss: 1.7254018783569336
Batch 49/64 loss: 1.7234647274017334
Batch 50/64 loss: 1.7225558757781982
Batch 51/64 loss: 1.7238209247589111
Batch 52/64 loss: 1.7245845794677734
Batch 53/64 loss: 1.7263933420181274
Batch 54/64 loss: 1.728235125541687
Batch 55/64 loss: 1.7275195121765137
Batch 56/64 loss: 1.7253882884979248
Batch 57/64 loss: 1.7345576286315918
Batch 58/64 loss: 1.7241291999816895
Batch 59/64 loss: 1.7236688137054443
Batch 60/64 loss: 1.723785400390625
Batch 61/64 loss: 1.7241504192352295
Batch 62/64 loss: 1.7306928634643555
Batch 63/64 loss: 1.7217504978179932
Batch 64/64 loss: 1.9058871269226074
Epoch 462  Train loss: 1.7288382118823482  Val loss: 1.7441659989635558
Epoch 463
-------------------------------
Batch 1/64 loss: 1.7257720232009888
Batch 2/64 loss: 1.7270927429199219
Batch 3/64 loss: 1.7263870239257812
Batch 4/64 loss: 1.727583885192871
Batch 5/64 loss: 1.7273528575897217
Batch 6/64 loss: 1.7297780513763428
Batch 7/64 loss: 1.7255167961120605
Batch 8/64 loss: 1.7260489463806152
Batch 9/64 loss: 1.7249598503112793
Batch 10/64 loss: 1.7270305156707764
Batch 11/64 loss: 1.7257719039916992
Batch 12/64 loss: 1.743259072303772
Batch 13/64 loss: 1.727384090423584
Batch 14/64 loss: 1.7260849475860596
Batch 15/64 loss: 1.7264680862426758
Batch 16/64 loss: 1.7235214710235596
Batch 17/64 loss: 1.7279850244522095
Batch 18/64 loss: 1.7305173873901367
Batch 19/64 loss: 1.7248059511184692
Batch 20/64 loss: 1.726280689239502
Batch 21/64 loss: 1.7269127368927002
Batch 22/64 loss: 1.7255704402923584
Batch 23/64 loss: 1.727268099784851
Batch 24/64 loss: 1.728029727935791
Batch 25/64 loss: 1.7387757301330566
Batch 26/64 loss: 1.733504056930542
Batch 27/64 loss: 1.7277779579162598
Batch 28/64 loss: 1.7270638942718506
Batch 29/64 loss: 1.726813554763794
Batch 30/64 loss: 1.7321395874023438
Batch 31/64 loss: 1.7280232906341553
Batch 32/64 loss: 1.7255961894989014
Batch 33/64 loss: 1.724280595779419
Batch 34/64 loss: 1.7306209802627563
Batch 35/64 loss: 1.7252614498138428
Batch 36/64 loss: 1.7246863842010498
Batch 37/64 loss: 1.7242512702941895
Batch 38/64 loss: 1.7261580228805542
Batch 39/64 loss: 1.7253828048706055
Batch 40/64 loss: 1.725358486175537
Batch 41/64 loss: 1.7303019762039185
Batch 42/64 loss: 1.7267999649047852
Batch 43/64 loss: 1.7265961170196533
Batch 44/64 loss: 1.7271158695220947
Batch 45/64 loss: 1.7269359827041626
Batch 46/64 loss: 1.7268787622451782
Batch 47/64 loss: 1.7287460565567017
Batch 48/64 loss: 1.726402997970581
Batch 49/64 loss: 1.7283692359924316
Batch 50/64 loss: 1.729158639907837
Batch 51/64 loss: 1.7310476303100586
Batch 52/64 loss: 1.7274181842803955
Batch 53/64 loss: 1.7402894496917725
Batch 54/64 loss: 1.7317793369293213
Batch 55/64 loss: 1.726099967956543
Batch 56/64 loss: 1.7258391380310059
Batch 57/64 loss: 1.72493577003479
Batch 58/64 loss: 1.7229375839233398
Batch 59/64 loss: 1.7256064414978027
Batch 60/64 loss: 1.726086139678955
Batch 61/64 loss: 1.725204348564148
Batch 62/64 loss: 1.7269126176834106
Batch 63/64 loss: 1.7265363931655884
Batch 64/64 loss: 1.9048707485198975
Epoch 463  Train loss: 1.729721227346682  Val loss: 1.7428214918706835
Epoch 464
-------------------------------
Batch 1/64 loss: 1.7264678478240967
Batch 2/64 loss: 1.7250797748565674
Batch 3/64 loss: 1.7232600450515747
Batch 4/64 loss: 1.7245564460754395
Batch 5/64 loss: 1.722426176071167
Batch 6/64 loss: 1.725464105606079
Batch 7/64 loss: 1.7224597930908203
Batch 8/64 loss: 1.7250992059707642
Batch 9/64 loss: 1.7317602634429932
Batch 10/64 loss: 1.7276732921600342
Batch 11/64 loss: 1.726822853088379
Batch 12/64 loss: 1.7286500930786133
Batch 13/64 loss: 1.7282938957214355
Batch 14/64 loss: 1.7243027687072754
Batch 15/64 loss: 1.724804401397705
Batch 16/64 loss: 1.724470615386963
Batch 17/64 loss: 1.726320505142212
Batch 18/64 loss: 1.7264575958251953
Batch 19/64 loss: 1.7265400886535645
Batch 20/64 loss: 1.7245728969573975
Batch 21/64 loss: 1.7283799648284912
Batch 22/64 loss: 1.7232615947723389
Batch 23/64 loss: 1.7248518466949463
Batch 24/64 loss: 1.7263948917388916
Batch 25/64 loss: 1.7214388847351074
Batch 26/64 loss: 1.7227154970169067
Batch 27/64 loss: 1.7251553535461426
Batch 28/64 loss: 1.7225874662399292
Batch 29/64 loss: 1.725475788116455
Batch 30/64 loss: 1.7260594367980957
Batch 31/64 loss: 1.7229825258255005
Batch 32/64 loss: 1.7262449264526367
Batch 33/64 loss: 1.7238943576812744
Batch 34/64 loss: 1.7214128971099854
Batch 35/64 loss: 1.723010540008545
Batch 36/64 loss: 1.7232520580291748
Batch 37/64 loss: 1.723894476890564
Batch 38/64 loss: 1.7236865758895874
Batch 39/64 loss: 1.7210564613342285
Batch 40/64 loss: 1.7573626041412354
Batch 41/64 loss: 1.7352142333984375
Batch 42/64 loss: 1.7242300510406494
Batch 43/64 loss: 1.7232089042663574
Batch 44/64 loss: 1.7281125783920288
Batch 45/64 loss: 1.725618839263916
Batch 46/64 loss: 1.72495436668396
Batch 47/64 loss: 1.7228765487670898
Batch 48/64 loss: 1.7229704856872559
Batch 49/64 loss: 1.7241123914718628
Batch 50/64 loss: 1.7239444255828857
Batch 51/64 loss: 1.7228567600250244
Batch 52/64 loss: 1.7240835428237915
Batch 53/64 loss: 1.721224069595337
Batch 54/64 loss: 1.724036455154419
Batch 55/64 loss: 1.7264972925186157
Batch 56/64 loss: 1.7226958274841309
Batch 57/64 loss: 1.7242454290390015
Batch 58/64 loss: 1.721894383430481
Batch 59/64 loss: 1.7243461608886719
Batch 60/64 loss: 1.7282023429870605
Batch 61/64 loss: 1.729008436203003
Batch 62/64 loss: 1.7252516746520996
Batch 63/64 loss: 1.7268738746643066
Batch 64/64 loss: 1.901052713394165
Epoch 464  Train loss: 1.7275427360160678  Val loss: 1.7399955328387493
Saving best model, epoch: 464
Epoch 465
-------------------------------
Batch 1/64 loss: 1.723435878753662
Batch 2/64 loss: 1.7243542671203613
Batch 3/64 loss: 1.7228055000305176
Batch 4/64 loss: 1.7215795516967773
Batch 5/64 loss: 1.7227027416229248
Batch 6/64 loss: 1.7219500541687012
Batch 7/64 loss: 1.7252566814422607
Batch 8/64 loss: 1.726200819015503
Batch 9/64 loss: 1.722425937652588
Batch 10/64 loss: 1.7222765684127808
Batch 11/64 loss: 1.7247872352600098
Batch 12/64 loss: 1.7281193733215332
Batch 13/64 loss: 1.7232582569122314
Batch 14/64 loss: 1.7235660552978516
Batch 15/64 loss: 1.7268704175949097
Batch 16/64 loss: 1.7234325408935547
Batch 17/64 loss: 1.7252047061920166
Batch 18/64 loss: 1.7240612506866455
Batch 19/64 loss: 1.7397031784057617
Batch 20/64 loss: 1.7289360761642456
Batch 21/64 loss: 1.7253170013427734
Batch 22/64 loss: 1.726146936416626
Batch 23/64 loss: 1.7265695333480835
Batch 24/64 loss: 1.7242746353149414
Batch 25/64 loss: 1.7283005714416504
Batch 26/64 loss: 1.7270293235778809
Batch 27/64 loss: 1.7231533527374268
Batch 28/64 loss: 1.724696397781372
Batch 29/64 loss: 1.7289955615997314
Batch 30/64 loss: 1.7250010967254639
Batch 31/64 loss: 1.731672763824463
Batch 32/64 loss: 1.7280466556549072
Batch 33/64 loss: 1.722301721572876
Batch 34/64 loss: 1.7297654151916504
Batch 35/64 loss: 1.7252388000488281
Batch 36/64 loss: 1.7286096811294556
Batch 37/64 loss: 1.7415134906768799
Batch 38/64 loss: 1.725003719329834
Batch 39/64 loss: 1.7238211631774902
Batch 40/64 loss: 1.7231009006500244
Batch 41/64 loss: 1.7267683744430542
Batch 42/64 loss: 1.72234046459198
Batch 43/64 loss: 1.7223434448242188
Batch 44/64 loss: 1.7255988121032715
Batch 45/64 loss: 1.7233388423919678
Batch 46/64 loss: 1.7225282192230225
Batch 47/64 loss: 1.7252403497695923
Batch 48/64 loss: 1.7235255241394043
Batch 49/64 loss: 1.7261371612548828
Batch 50/64 loss: 1.7248417139053345
Batch 51/64 loss: 1.7300243377685547
Batch 52/64 loss: 1.7264939546585083
Batch 53/64 loss: 1.7309207916259766
Batch 54/64 loss: 1.7272510528564453
Batch 55/64 loss: 1.7238073348999023
Batch 56/64 loss: 1.7254068851470947
Batch 57/64 loss: 1.7281148433685303
Batch 58/64 loss: 1.725079894065857
Batch 59/64 loss: 1.7230169773101807
Batch 60/64 loss: 1.7276310920715332
Batch 61/64 loss: 1.7253146171569824
Batch 62/64 loss: 1.7378302812576294
Batch 63/64 loss: 1.7240500450134277
Batch 64/64 loss: 1.9062316417694092
Epoch 465  Train loss: 1.7281061107037115  Val loss: 1.7419914453709657
Epoch 466
-------------------------------
Batch 1/64 loss: 1.7264771461486816
Batch 2/64 loss: 1.7230823040008545
Batch 3/64 loss: 1.724243402481079
Batch 4/64 loss: 1.72360360622406
Batch 5/64 loss: 1.724703311920166
Batch 6/64 loss: 1.722644329071045
Batch 7/64 loss: 1.7223963737487793
Batch 8/64 loss: 1.729482650756836
Batch 9/64 loss: 1.7219517230987549
Batch 10/64 loss: 1.7227414846420288
Batch 11/64 loss: 1.7258951663970947
Batch 12/64 loss: 1.7251219749450684
Batch 13/64 loss: 1.7239348888397217
Batch 14/64 loss: 1.7252089977264404
Batch 15/64 loss: 1.7251949310302734
Batch 16/64 loss: 1.7234059572219849
Batch 17/64 loss: 1.7245852947235107
Batch 18/64 loss: 1.724027395248413
Batch 19/64 loss: 1.7281136512756348
Batch 20/64 loss: 1.7268760204315186
Batch 21/64 loss: 1.7420837879180908
Batch 22/64 loss: 1.7255507707595825
Batch 23/64 loss: 1.725982904434204
Batch 24/64 loss: 1.7256669998168945
Batch 25/64 loss: 1.7267252206802368
Batch 26/64 loss: 1.7251166105270386
Batch 27/64 loss: 1.7294968366622925
Batch 28/64 loss: 1.7270543575286865
Batch 29/64 loss: 1.7400752305984497
Batch 30/64 loss: 1.7254624366760254
Batch 31/64 loss: 1.7244248390197754
Batch 32/64 loss: 1.7326390743255615
Batch 33/64 loss: 1.7266887426376343
Batch 34/64 loss: 1.7247228622436523
Batch 35/64 loss: 1.7242693901062012
Batch 36/64 loss: 1.7320921421051025
Batch 37/64 loss: 1.7281348705291748
Batch 38/64 loss: 1.7245826721191406
Batch 39/64 loss: 1.7267557382583618
Batch 40/64 loss: 1.7314541339874268
Batch 41/64 loss: 1.7295770645141602
Batch 42/64 loss: 1.7265243530273438
Batch 43/64 loss: 1.730442762374878
Batch 44/64 loss: 1.7259960174560547
Batch 45/64 loss: 1.7289388179779053
Batch 46/64 loss: 1.7256295680999756
Batch 47/64 loss: 1.7272733449935913
Batch 48/64 loss: 1.7253742218017578
Batch 49/64 loss: 1.7249689102172852
Batch 50/64 loss: 1.7287266254425049
Batch 51/64 loss: 1.741957187652588
Batch 52/64 loss: 1.7305898666381836
Batch 53/64 loss: 1.726729154586792
Batch 54/64 loss: 1.7259504795074463
Batch 55/64 loss: 1.7259126901626587
Batch 56/64 loss: 1.7233312129974365
Batch 57/64 loss: 1.72574782371521
Batch 58/64 loss: 1.7267394065856934
Batch 59/64 loss: 1.7277295589447021
Batch 60/64 loss: 1.7254447937011719
Batch 61/64 loss: 1.7247421741485596
Batch 62/64 loss: 1.7280211448669434
Batch 63/64 loss: 1.7276928424835205
Batch 64/64 loss: 1.9073240756988525
Epoch 466  Train loss: 1.7290541695613486  Val loss: 1.7450276232257331
Epoch 467
-------------------------------
Batch 1/64 loss: 1.7258741855621338
Batch 2/64 loss: 1.7289235591888428
Batch 3/64 loss: 1.72731614112854
Batch 4/64 loss: 1.7266428470611572
Batch 5/64 loss: 1.7251312732696533
Batch 6/64 loss: 1.7279672622680664
Batch 7/64 loss: 1.7247353792190552
Batch 8/64 loss: 1.7249424457550049
Batch 9/64 loss: 1.7308834791183472
Batch 10/64 loss: 1.7260193824768066
Batch 11/64 loss: 1.72554349899292
Batch 12/64 loss: 1.726977825164795
Batch 13/64 loss: 1.7261531352996826
Batch 14/64 loss: 1.7241140604019165
Batch 15/64 loss: 1.7265520095825195
Batch 16/64 loss: 1.7234151363372803
Batch 17/64 loss: 1.723036766052246
Batch 18/64 loss: 1.7237650156021118
Batch 19/64 loss: 1.727283239364624
Batch 20/64 loss: 1.7263758182525635
Batch 21/64 loss: 1.7259852886199951
Batch 22/64 loss: 1.7229588031768799
Batch 23/64 loss: 1.72383451461792
Batch 24/64 loss: 1.7325292825698853
Batch 25/64 loss: 1.7400014400482178
Batch 26/64 loss: 1.7244892120361328
Batch 27/64 loss: 1.7309610843658447
Batch 28/64 loss: 1.723257064819336
Batch 29/64 loss: 1.7217427492141724
Batch 30/64 loss: 1.7262214422225952
Batch 31/64 loss: 1.7271919250488281
Batch 32/64 loss: 1.7213118076324463
Batch 33/64 loss: 1.7240757942199707
Batch 34/64 loss: 1.7240360975265503
Batch 35/64 loss: 1.724218487739563
Batch 36/64 loss: 1.7256208658218384
Batch 37/64 loss: 1.7246898412704468
Batch 38/64 loss: 1.7317341566085815
Batch 39/64 loss: 1.7240948677062988
Batch 40/64 loss: 1.7250053882598877
Batch 41/64 loss: 1.7250710725784302
Batch 42/64 loss: 1.7226755619049072
Batch 43/64 loss: 1.725951910018921
Batch 44/64 loss: 1.7251651287078857
Batch 45/64 loss: 1.7231148481369019
Batch 46/64 loss: 1.7244967222213745
Batch 47/64 loss: 1.7226961851119995
Batch 48/64 loss: 1.7234914302825928
Batch 49/64 loss: 1.7243716716766357
Batch 50/64 loss: 1.7229106426239014
Batch 51/64 loss: 1.7301549911499023
Batch 52/64 loss: 1.7256147861480713
Batch 53/64 loss: 1.7225505113601685
Batch 54/64 loss: 1.7245278358459473
Batch 55/64 loss: 1.7239314317703247
Batch 56/64 loss: 1.723374605178833
Batch 57/64 loss: 1.7250875234603882
Batch 58/64 loss: 1.726402997970581
Batch 59/64 loss: 1.739469051361084
Batch 60/64 loss: 1.7286856174468994
Batch 61/64 loss: 1.7280560731887817
Batch 62/64 loss: 1.7455573081970215
Batch 63/64 loss: 1.7260345220565796
Batch 64/64 loss: 1.9091036319732666
Epoch 467  Train loss: 1.7284209055059097  Val loss: 1.7450076157284766
Epoch 468
-------------------------------
Batch 1/64 loss: 1.7286250591278076
Batch 2/64 loss: 1.7282267808914185
Batch 3/64 loss: 1.7255582809448242
Batch 4/64 loss: 1.7306654453277588
Batch 5/64 loss: 1.7266004085540771
Batch 6/64 loss: 1.7355200052261353
Batch 7/64 loss: 1.7276008129119873
Batch 8/64 loss: 1.7399464845657349
Batch 9/64 loss: 1.7255616188049316
Batch 10/64 loss: 1.7261178493499756
Batch 11/64 loss: 1.7311205863952637
Batch 12/64 loss: 1.7324893474578857
Batch 13/64 loss: 1.7253422737121582
Batch 14/64 loss: 1.7465946674346924
Batch 15/64 loss: 1.7244725227355957
Batch 16/64 loss: 1.726731538772583
Batch 17/64 loss: 1.7271137237548828
Batch 18/64 loss: 1.7259137630462646
Batch 19/64 loss: 1.7318527698516846
Batch 20/64 loss: 1.7277798652648926
Batch 21/64 loss: 1.7272236347198486
Batch 22/64 loss: 1.7295827865600586
Batch 23/64 loss: 1.7271804809570312
Batch 24/64 loss: 1.723689317703247
Batch 25/64 loss: 1.735715627670288
Batch 26/64 loss: 1.72612726688385
Batch 27/64 loss: 1.7283096313476562
Batch 28/64 loss: 1.7273848056793213
Batch 29/64 loss: 1.7300162315368652
Batch 30/64 loss: 1.7251381874084473
Batch 31/64 loss: 1.724543809890747
Batch 32/64 loss: 1.7285981178283691
Batch 33/64 loss: 1.7247443199157715
Batch 34/64 loss: 1.726082682609558
Batch 35/64 loss: 1.7247209548950195
Batch 36/64 loss: 1.7273838520050049
Batch 37/64 loss: 1.7266085147857666
Batch 38/64 loss: 1.7259100675582886
Batch 39/64 loss: 1.7260842323303223
Batch 40/64 loss: 1.7245378494262695
Batch 41/64 loss: 1.7252838611602783
Batch 42/64 loss: 1.7236862182617188
Batch 43/64 loss: 1.7385586500167847
Batch 44/64 loss: 1.7237505912780762
Batch 45/64 loss: 1.728082537651062
Batch 46/64 loss: 1.7231404781341553
Batch 47/64 loss: 1.7280323505401611
Batch 48/64 loss: 1.724261999130249
Batch 49/64 loss: 1.733368158340454
Batch 50/64 loss: 1.7328472137451172
Batch 51/64 loss: 1.7266972064971924
Batch 52/64 loss: 1.7313926219940186
Batch 53/64 loss: 1.7255940437316895
Batch 54/64 loss: 1.726038932800293
Batch 55/64 loss: 1.7240917682647705
Batch 56/64 loss: 1.725543737411499
Batch 57/64 loss: 1.7291338443756104
Batch 58/64 loss: 1.7250049114227295
Batch 59/64 loss: 1.7307300567626953
Batch 60/64 loss: 1.7250765562057495
Batch 61/64 loss: 1.7224122285842896
Batch 62/64 loss: 1.727344036102295
Batch 63/64 loss: 1.7232208251953125
Batch 64/64 loss: 1.902449369430542
Epoch 468  Train loss: 1.7299379769493552  Val loss: 1.740609035459171
Epoch 469
-------------------------------
Batch 1/64 loss: 1.7293024063110352
Batch 2/64 loss: 1.7242817878723145
Batch 3/64 loss: 1.7393544912338257
Batch 4/64 loss: 1.7248204946517944
Batch 5/64 loss: 1.7233654260635376
Batch 6/64 loss: 1.7289965152740479
Batch 7/64 loss: 1.7245359420776367
Batch 8/64 loss: 1.725665807723999
Batch 9/64 loss: 1.7261099815368652
Batch 10/64 loss: 1.729346752166748
Batch 11/64 loss: 1.7459089756011963
Batch 12/64 loss: 1.7270894050598145
Batch 13/64 loss: 1.722412109375
Batch 14/64 loss: 1.722477674484253
Batch 15/64 loss: 1.7223021984100342
Batch 16/64 loss: 1.7260382175445557
Batch 17/64 loss: 1.7284483909606934
Batch 18/64 loss: 1.7262845039367676
Batch 19/64 loss: 1.72472083568573
Batch 20/64 loss: 1.7253328561782837
Batch 21/64 loss: 1.7304004430770874
Batch 22/64 loss: 1.7249524593353271
Batch 23/64 loss: 1.7226650714874268
Batch 24/64 loss: 1.7256628274917603
Batch 25/64 loss: 1.7255966663360596
Batch 26/64 loss: 1.7253341674804688
Batch 27/64 loss: 1.7243067026138306
Batch 28/64 loss: 1.7259609699249268
Batch 29/64 loss: 1.7289724349975586
Batch 30/64 loss: 1.7228412628173828
Batch 31/64 loss: 1.7256022691726685
Batch 32/64 loss: 1.7364490032196045
Batch 33/64 loss: 1.7251462936401367
Batch 34/64 loss: 1.723806381225586
Batch 35/64 loss: 1.7310185432434082
Batch 36/64 loss: 1.722931146621704
Batch 37/64 loss: 1.7250704765319824
Batch 38/64 loss: 1.7259750366210938
Batch 39/64 loss: 1.7240564823150635
Batch 40/64 loss: 1.7230207920074463
Batch 41/64 loss: 1.7229485511779785
Batch 42/64 loss: 1.7227367162704468
Batch 43/64 loss: 1.7297358512878418
Batch 44/64 loss: 1.7240955829620361
Batch 45/64 loss: 1.7234411239624023
Batch 46/64 loss: 1.7283896207809448
Batch 47/64 loss: 1.7293293476104736
Batch 48/64 loss: 1.7258117198944092
Batch 49/64 loss: 1.724820852279663
Batch 50/64 loss: 1.724130630493164
Batch 51/64 loss: 1.7268836498260498
Batch 52/64 loss: 1.728546380996704
Batch 53/64 loss: 1.7344765663146973
Batch 54/64 loss: 1.7258422374725342
Batch 55/64 loss: 1.7279045581817627
Batch 56/64 loss: 1.7304811477661133
Batch 57/64 loss: 1.7288193702697754
Batch 58/64 loss: 1.7266762256622314
Batch 59/64 loss: 1.7235116958618164
Batch 60/64 loss: 1.7245880365371704
Batch 61/64 loss: 1.7284510135650635
Batch 62/64 loss: 1.7251465320587158
Batch 63/64 loss: 1.734013319015503
Batch 64/64 loss: 1.9007606506347656
Epoch 469  Train loss: 1.7288300458122703  Val loss: 1.7449139975190573
Epoch 470
-------------------------------
Batch 1/64 loss: 1.7246203422546387
Batch 2/64 loss: 1.7257554531097412
Batch 3/64 loss: 1.7282209396362305
Batch 4/64 loss: 1.726574182510376
Batch 5/64 loss: 1.724989652633667
Batch 6/64 loss: 1.7250592708587646
Batch 7/64 loss: 1.72720205783844
Batch 8/64 loss: 1.7371811866760254
Batch 9/64 loss: 1.7246294021606445
Batch 10/64 loss: 1.727067470550537
Batch 11/64 loss: 1.724158763885498
Batch 12/64 loss: 1.7236454486846924
Batch 13/64 loss: 1.7249388694763184
Batch 14/64 loss: 1.725642442703247
Batch 15/64 loss: 1.7259814739227295
Batch 16/64 loss: 1.7228565216064453
Batch 17/64 loss: 1.726579189300537
Batch 18/64 loss: 1.723292589187622
Batch 19/64 loss: 1.7237849235534668
Batch 20/64 loss: 1.7256946563720703
Batch 21/64 loss: 1.7227528095245361
Batch 22/64 loss: 1.7234103679656982
Batch 23/64 loss: 1.721541404724121
Batch 24/64 loss: 1.7267532348632812
Batch 25/64 loss: 1.7264002561569214
Batch 26/64 loss: 1.7230366468429565
Batch 27/64 loss: 1.72452712059021
Batch 28/64 loss: 1.7268695831298828
Batch 29/64 loss: 1.7256218194961548
Batch 30/64 loss: 1.7350049018859863
Batch 31/64 loss: 1.7255176305770874
Batch 32/64 loss: 1.7258398532867432
Batch 33/64 loss: 1.7265270948410034
Batch 34/64 loss: 1.724336862564087
Batch 35/64 loss: 1.7405383586883545
Batch 36/64 loss: 1.722801685333252
Batch 37/64 loss: 1.7227752208709717
Batch 38/64 loss: 1.7301130294799805
Batch 39/64 loss: 1.7258398532867432
Batch 40/64 loss: 1.7226393222808838
Batch 41/64 loss: 1.7227566242218018
Batch 42/64 loss: 1.7268047332763672
Batch 43/64 loss: 1.72601318359375
Batch 44/64 loss: 1.724938988685608
Batch 45/64 loss: 1.7244973182678223
Batch 46/64 loss: 1.7248603105545044
Batch 47/64 loss: 1.726102352142334
Batch 48/64 loss: 1.723578691482544
Batch 49/64 loss: 1.7224326133728027
Batch 50/64 loss: 1.7297252416610718
Batch 51/64 loss: 1.7258387804031372
Batch 52/64 loss: 1.7259669303894043
Batch 53/64 loss: 1.7255899906158447
Batch 54/64 loss: 1.7276315689086914
Batch 55/64 loss: 1.7290570735931396
Batch 56/64 loss: 1.7291700839996338
Batch 57/64 loss: 1.7262234687805176
Batch 58/64 loss: 1.7247508764266968
Batch 59/64 loss: 1.7244395017623901
Batch 60/64 loss: 1.7464385032653809
Batch 61/64 loss: 1.7239941358566284
Batch 62/64 loss: 1.7235302925109863
Batch 63/64 loss: 1.7262258529663086
Batch 64/64 loss: 1.9005987644195557
Epoch 470  Train loss: 1.7282625581703934  Val loss: 1.7418232193517522
Epoch 471
-------------------------------
Batch 1/64 loss: 1.7255793809890747
Batch 2/64 loss: 1.726407527923584
Batch 3/64 loss: 1.7250316143035889
Batch 4/64 loss: 1.722815752029419
Batch 5/64 loss: 1.726048469543457
Batch 6/64 loss: 1.7246830463409424
Batch 7/64 loss: 1.7294533252716064
Batch 8/64 loss: 1.7239539623260498
Batch 9/64 loss: 1.729517936706543
Batch 10/64 loss: 1.7222707271575928
Batch 11/64 loss: 1.722859501838684
Batch 12/64 loss: 1.7250797748565674
Batch 13/64 loss: 1.7316502332687378
Batch 14/64 loss: 1.7229893207550049
Batch 15/64 loss: 1.7211557626724243
Batch 16/64 loss: 1.72469162940979
Batch 17/64 loss: 1.7235743999481201
Batch 18/64 loss: 1.7216753959655762
Batch 19/64 loss: 1.7250065803527832
Batch 20/64 loss: 1.7268497943878174
Batch 21/64 loss: 1.727292776107788
Batch 22/64 loss: 1.7248932123184204
Batch 23/64 loss: 1.7232327461242676
Batch 24/64 loss: 1.7272288799285889
Batch 25/64 loss: 1.7232778072357178
Batch 26/64 loss: 1.7222850322723389
Batch 27/64 loss: 1.7232294082641602
Batch 28/64 loss: 1.723636507987976
Batch 29/64 loss: 1.7256145477294922
Batch 30/64 loss: 1.7233316898345947
Batch 31/64 loss: 1.7229595184326172
Batch 32/64 loss: 1.7289314270019531
Batch 33/64 loss: 1.7239928245544434
Batch 34/64 loss: 1.7289016246795654
Batch 35/64 loss: 1.720344066619873
Batch 36/64 loss: 1.7242375612258911
Batch 37/64 loss: 1.7230396270751953
Batch 38/64 loss: 1.7225210666656494
Batch 39/64 loss: 1.7243062257766724
Batch 40/64 loss: 1.7219363451004028
Batch 41/64 loss: 1.7323044538497925
Batch 42/64 loss: 1.7253363132476807
Batch 43/64 loss: 1.7252492904663086
Batch 44/64 loss: 1.7244243621826172
Batch 45/64 loss: 1.7244073152542114
Batch 46/64 loss: 1.7346456050872803
Batch 47/64 loss: 1.7439608573913574
Batch 48/64 loss: 1.7260282039642334
Batch 49/64 loss: 1.7231192588806152
Batch 50/64 loss: 1.722031831741333
Batch 51/64 loss: 1.724668025970459
Batch 52/64 loss: 1.7298808097839355
Batch 53/64 loss: 1.7225310802459717
Batch 54/64 loss: 1.7232304811477661
Batch 55/64 loss: 1.727848768234253
Batch 56/64 loss: 1.7251338958740234
Batch 57/64 loss: 1.724311351776123
Batch 58/64 loss: 1.7269091606140137
Batch 59/64 loss: 1.723228931427002
Batch 60/64 loss: 1.7272841930389404
Batch 61/64 loss: 1.7244374752044678
Batch 62/64 loss: 1.7255222797393799
Batch 63/64 loss: 1.7244489192962646
Batch 64/64 loss: 1.9054255485534668
Epoch 471  Train loss: 1.72747449500888  Val loss: 1.7412598796726502
Epoch 472
-------------------------------
Batch 1/64 loss: 1.7271084785461426
Batch 2/64 loss: 1.7254862785339355
Batch 3/64 loss: 1.7253639698028564
Batch 4/64 loss: 1.728190302848816
Batch 5/64 loss: 1.7259521484375
Batch 6/64 loss: 1.7246259450912476
Batch 7/64 loss: 1.7232321500778198
Batch 8/64 loss: 1.727806806564331
Batch 9/64 loss: 1.7286683320999146
Batch 10/64 loss: 1.7249393463134766
Batch 11/64 loss: 1.72628653049469
Batch 12/64 loss: 1.7255678176879883
Batch 13/64 loss: 1.7238743305206299
Batch 14/64 loss: 1.725490927696228
Batch 15/64 loss: 1.7218517065048218
Batch 16/64 loss: 1.7243165969848633
Batch 17/64 loss: 1.7267286777496338
Batch 18/64 loss: 1.7274147272109985
Batch 19/64 loss: 1.7232530117034912
Batch 20/64 loss: 1.724430799484253
Batch 21/64 loss: 1.7269041538238525
Batch 22/64 loss: 1.7243789434432983
Batch 23/64 loss: 1.7227774858474731
Batch 24/64 loss: 1.7223542928695679
Batch 25/64 loss: 1.724839448928833
Batch 26/64 loss: 1.7278519868850708
Batch 27/64 loss: 1.7238883972167969
Batch 28/64 loss: 1.7259323596954346
Batch 29/64 loss: 1.7253901958465576
Batch 30/64 loss: 1.7221553325653076
Batch 31/64 loss: 1.7235949039459229
Batch 32/64 loss: 1.726752519607544
Batch 33/64 loss: 1.7265419960021973
Batch 34/64 loss: 1.7243359088897705
Batch 35/64 loss: 1.7244848012924194
Batch 36/64 loss: 1.7268539667129517
Batch 37/64 loss: 1.7281275987625122
Batch 38/64 loss: 1.7255427837371826
Batch 39/64 loss: 1.7254951000213623
Batch 40/64 loss: 1.7226569652557373
Batch 41/64 loss: 1.7415339946746826
Batch 42/64 loss: 1.7228598594665527
Batch 43/64 loss: 1.725587010383606
Batch 44/64 loss: 1.7232050895690918
Batch 45/64 loss: 1.7378088235855103
Batch 46/64 loss: 1.7232520580291748
Batch 47/64 loss: 1.7240108251571655
Batch 48/64 loss: 1.7214853763580322
Batch 49/64 loss: 1.7234278917312622
Batch 50/64 loss: 1.722269058227539
Batch 51/64 loss: 1.7235682010650635
Batch 52/64 loss: 1.7226676940917969
Batch 53/64 loss: 1.72198486328125
Batch 54/64 loss: 1.7220096588134766
Batch 55/64 loss: 1.721595048904419
Batch 56/64 loss: 1.7384191751480103
Batch 57/64 loss: 1.7218989133834839
Batch 58/64 loss: 1.7216696739196777
Batch 59/64 loss: 1.7233281135559082
Batch 60/64 loss: 1.7228198051452637
Batch 61/64 loss: 1.7265040874481201
Batch 62/64 loss: 1.7208954095840454
Batch 63/64 loss: 1.7296472787857056
Batch 64/64 loss: 1.8987860679626465
Epoch 472  Train loss: 1.7273409488154392  Val loss: 1.7382902050346034
Saving best model, epoch: 472
Epoch 473
-------------------------------
Batch 1/64 loss: 1.7233476638793945
Batch 2/64 loss: 1.7220704555511475
Batch 3/64 loss: 1.7204850912094116
Batch 4/64 loss: 1.7235702276229858
Batch 5/64 loss: 1.7221202850341797
Batch 6/64 loss: 1.721258521080017
Batch 7/64 loss: 1.7229392528533936
Batch 8/64 loss: 1.7225967645645142
Batch 9/64 loss: 1.7252602577209473
Batch 10/64 loss: 1.7223782539367676
Batch 11/64 loss: 1.7222641706466675
Batch 12/64 loss: 1.7221379280090332
Batch 13/64 loss: 1.7213661670684814
Batch 14/64 loss: 1.7229831218719482
Batch 15/64 loss: 1.7230923175811768
Batch 16/64 loss: 1.7286930084228516
Batch 17/64 loss: 1.724581003189087
Batch 18/64 loss: 1.7268731594085693
Batch 19/64 loss: 1.733877182006836
Batch 20/64 loss: 1.722582459449768
Batch 21/64 loss: 1.7265057563781738
Batch 22/64 loss: 1.7225711345672607
Batch 23/64 loss: 1.722028374671936
Batch 24/64 loss: 1.7225806713104248
Batch 25/64 loss: 1.7274012565612793
Batch 26/64 loss: 1.7252181768417358
Batch 27/64 loss: 1.723694086074829
Batch 28/64 loss: 1.7229621410369873
Batch 29/64 loss: 1.7294116020202637
Batch 30/64 loss: 1.7228920459747314
Batch 31/64 loss: 1.7216088771820068
Batch 32/64 loss: 1.7235517501831055
Batch 33/64 loss: 1.7222915887832642
Batch 34/64 loss: 1.730811357498169
Batch 35/64 loss: 1.7198987007141113
Batch 36/64 loss: 1.7372808456420898
Batch 37/64 loss: 1.723832368850708
Batch 38/64 loss: 1.7209970951080322
Batch 39/64 loss: 1.725867748260498
Batch 40/64 loss: 1.7382980585098267
Batch 41/64 loss: 1.7225215435028076
Batch 42/64 loss: 1.7238197326660156
Batch 43/64 loss: 1.7224366664886475
Batch 44/64 loss: 1.7226028442382812
Batch 45/64 loss: 1.7239978313446045
Batch 46/64 loss: 1.726759433746338
Batch 47/64 loss: 1.7265503406524658
Batch 48/64 loss: 1.7205066680908203
Batch 49/64 loss: 1.723893404006958
Batch 50/64 loss: 1.7342301607131958
Batch 51/64 loss: 1.7240500450134277
Batch 52/64 loss: 1.7222217321395874
Batch 53/64 loss: 1.7246348857879639
Batch 54/64 loss: 1.7209467887878418
Batch 55/64 loss: 1.7226827144622803
Batch 56/64 loss: 1.725348711013794
Batch 57/64 loss: 1.7222821712493896
Batch 58/64 loss: 1.7230724096298218
Batch 59/64 loss: 1.7220423221588135
Batch 60/64 loss: 1.7264342308044434
Batch 61/64 loss: 1.7244443893432617
Batch 62/64 loss: 1.7230788469314575
Batch 63/64 loss: 1.722226858139038
Batch 64/64 loss: 1.9117348194122314
Epoch 473  Train loss: 1.7265688905528946  Val loss: 1.741235773997618
Epoch 474
-------------------------------
Batch 1/64 loss: 1.7225515842437744
Batch 2/64 loss: 1.723718285560608
Batch 3/64 loss: 1.7232582569122314
Batch 4/64 loss: 1.7216579914093018
Batch 5/64 loss: 1.7262718677520752
Batch 6/64 loss: 1.7217113971710205
Batch 7/64 loss: 1.7221572399139404
Batch 8/64 loss: 1.7225494384765625
Batch 9/64 loss: 1.721710443496704
Batch 10/64 loss: 1.724717617034912
Batch 11/64 loss: 1.7264933586120605
Batch 12/64 loss: 1.722785472869873
Batch 13/64 loss: 1.7420964241027832
Batch 14/64 loss: 1.7267096042633057
Batch 15/64 loss: 1.737687349319458
Batch 16/64 loss: 1.7213444709777832
Batch 17/64 loss: 1.7245181798934937
Batch 18/64 loss: 1.72865629196167
Batch 19/64 loss: 1.720405101776123
Batch 20/64 loss: 1.7249910831451416
Batch 21/64 loss: 1.7211309671401978
Batch 22/64 loss: 1.7262904644012451
Batch 23/64 loss: 1.7210631370544434
Batch 24/64 loss: 1.7232568264007568
Batch 25/64 loss: 1.7233896255493164
Batch 26/64 loss: 1.7234110832214355
Batch 27/64 loss: 1.7325763702392578
Batch 28/64 loss: 1.7251368761062622
Batch 29/64 loss: 1.7386445999145508
Batch 30/64 loss: 1.7221615314483643
Batch 31/64 loss: 1.7219843864440918
Batch 32/64 loss: 1.7223851680755615
Batch 33/64 loss: 1.7218586206436157
Batch 34/64 loss: 1.7232768535614014
Batch 35/64 loss: 1.7192625999450684
Batch 36/64 loss: 1.7213743925094604
Batch 37/64 loss: 1.726824164390564
Batch 38/64 loss: 1.7231266498565674
Batch 39/64 loss: 1.7224246263504028
Batch 40/64 loss: 1.7235082387924194
Batch 41/64 loss: 1.7236919403076172
Batch 42/64 loss: 1.7223434448242188
Batch 43/64 loss: 1.7217977046966553
Batch 44/64 loss: 1.7303698062896729
Batch 45/64 loss: 1.7219688892364502
Batch 46/64 loss: 1.7219953536987305
Batch 47/64 loss: 1.721026062965393
Batch 48/64 loss: 1.7229552268981934
Batch 49/64 loss: 1.7232002019882202
Batch 50/64 loss: 1.7222521305084229
Batch 51/64 loss: 1.724387288093567
Batch 52/64 loss: 1.721010446548462
Batch 53/64 loss: 1.7205719947814941
Batch 54/64 loss: 1.722797155380249
Batch 55/64 loss: 1.7210479974746704
Batch 56/64 loss: 1.7290623188018799
Batch 57/64 loss: 1.7224013805389404
Batch 58/64 loss: 1.7227243185043335
Batch 59/64 loss: 1.7278625965118408
Batch 60/64 loss: 1.7213897705078125
Batch 61/64 loss: 1.7226512432098389
Batch 62/64 loss: 1.7235187292099
Batch 63/64 loss: 1.7234184741973877
Batch 64/64 loss: 1.9018030166625977
Epoch 474  Train loss: 1.7262725549585678  Val loss: 1.7400643129119349
Epoch 475
-------------------------------
Batch 1/64 loss: 1.7307519912719727
Batch 2/64 loss: 1.7409605979919434
Batch 3/64 loss: 1.7255754470825195
Batch 4/64 loss: 1.7294843196868896
Batch 5/64 loss: 1.7368049621582031
Batch 6/64 loss: 1.7225695848464966
Batch 7/64 loss: 1.7225375175476074
Batch 8/64 loss: 1.7245430946350098
Batch 9/64 loss: 1.7249946594238281
Batch 10/64 loss: 1.7223165035247803
Batch 11/64 loss: 1.725077748298645
Batch 12/64 loss: 1.7222840785980225
Batch 13/64 loss: 1.723400354385376
Batch 14/64 loss: 1.7206758260726929
Batch 15/64 loss: 1.7245707511901855
Batch 16/64 loss: 1.722082495689392
Batch 17/64 loss: 1.7239160537719727
Batch 18/64 loss: 1.7230689525604248
Batch 19/64 loss: 1.724721908569336
Batch 20/64 loss: 1.723954677581787
Batch 21/64 loss: 1.7223682403564453
Batch 22/64 loss: 1.7226457595825195
Batch 23/64 loss: 1.723983645439148
Batch 24/64 loss: 1.7249515056610107
Batch 25/64 loss: 1.7229962348937988
Batch 26/64 loss: 1.7236987352371216
Batch 27/64 loss: 1.7254458665847778
Batch 28/64 loss: 1.73016357421875
Batch 29/64 loss: 1.7260277271270752
Batch 30/64 loss: 1.7303857803344727
Batch 31/64 loss: 1.7213689088821411
Batch 32/64 loss: 1.7215075492858887
Batch 33/64 loss: 1.7229740619659424
Batch 34/64 loss: 1.7229746580123901
Batch 35/64 loss: 1.72406005859375
Batch 36/64 loss: 1.726064682006836
Batch 37/64 loss: 1.7245088815689087
Batch 38/64 loss: 1.724107265472412
Batch 39/64 loss: 1.7263836860656738
Batch 40/64 loss: 1.7251251935958862
Batch 41/64 loss: 1.7214922904968262
Batch 42/64 loss: 1.7238273620605469
Batch 43/64 loss: 1.723259449005127
Batch 44/64 loss: 1.7221810817718506
Batch 45/64 loss: 1.7242305278778076
Batch 46/64 loss: 1.724851369857788
Batch 47/64 loss: 1.7230720520019531
Batch 48/64 loss: 1.7249183654785156
Batch 49/64 loss: 1.725800633430481
Batch 50/64 loss: 1.722348690032959
Batch 51/64 loss: 1.7231245040893555
Batch 52/64 loss: 1.7264115810394287
Batch 53/64 loss: 1.7325198650360107
Batch 54/64 loss: 1.7233458757400513
Batch 55/64 loss: 1.7252237796783447
Batch 56/64 loss: 1.7218424081802368
Batch 57/64 loss: 1.7230117321014404
Batch 58/64 loss: 1.7274830341339111
Batch 59/64 loss: 1.7231203317642212
Batch 60/64 loss: 1.7387149333953857
Batch 61/64 loss: 1.732224464416504
Batch 62/64 loss: 1.7268990278244019
Batch 63/64 loss: 1.7263596057891846
Batch 64/64 loss: 1.9037058353424072
Epoch 475  Train loss: 1.7273737393173516  Val loss: 1.7441534471675701
Epoch 476
-------------------------------
Batch 1/64 loss: 1.7282664775848389
Batch 2/64 loss: 1.727299690246582
Batch 3/64 loss: 1.7256605625152588
Batch 4/64 loss: 1.7251882553100586
Batch 5/64 loss: 1.7259827852249146
Batch 6/64 loss: 1.7256144285202026
Batch 7/64 loss: 1.7460992336273193
Batch 8/64 loss: 1.725041389465332
Batch 9/64 loss: 1.7250276803970337
Batch 10/64 loss: 1.7317883968353271
Batch 11/64 loss: 1.7232623100280762
Batch 12/64 loss: 1.7258785963058472
Batch 13/64 loss: 1.7364492416381836
Batch 14/64 loss: 1.7275781631469727
Batch 15/64 loss: 1.7245423793792725
Batch 16/64 loss: 1.7232880592346191
Batch 17/64 loss: 1.7224478721618652
Batch 18/64 loss: 1.7263914346694946
Batch 19/64 loss: 1.7224173545837402
Batch 20/64 loss: 1.7264182567596436
Batch 21/64 loss: 1.7280876636505127
Batch 22/64 loss: 1.7231440544128418
Batch 23/64 loss: 1.7242426872253418
Batch 24/64 loss: 1.724153995513916
Batch 25/64 loss: 1.7230712175369263
Batch 26/64 loss: 1.7290936708450317
Batch 27/64 loss: 1.7265081405639648
Batch 28/64 loss: 1.7242283821105957
Batch 29/64 loss: 1.7266950607299805
Batch 30/64 loss: 1.7247434854507446
Batch 31/64 loss: 1.7258810997009277
Batch 32/64 loss: 1.7271251678466797
Batch 33/64 loss: 1.7261402606964111
Batch 34/64 loss: 1.722005009651184
Batch 35/64 loss: 1.7248042821884155
Batch 36/64 loss: 1.732172966003418
Batch 37/64 loss: 1.725011944770813
Batch 38/64 loss: 1.7269493341445923
Batch 39/64 loss: 1.7231212854385376
Batch 40/64 loss: 1.7246453762054443
Batch 41/64 loss: 1.7264641523361206
Batch 42/64 loss: 1.7254585027694702
Batch 43/64 loss: 1.7283419370651245
Batch 44/64 loss: 1.7235522270202637
Batch 45/64 loss: 1.7240650653839111
Batch 46/64 loss: 1.7248599529266357
Batch 47/64 loss: 1.7258951663970947
Batch 48/64 loss: 1.724794626235962
Batch 49/64 loss: 1.7265610694885254
Batch 50/64 loss: 1.7240288257598877
Batch 51/64 loss: 1.729318618774414
Batch 52/64 loss: 1.735856056213379
Batch 53/64 loss: 1.7272979021072388
Batch 54/64 loss: 1.7271366119384766
Batch 55/64 loss: 1.7244668006896973
Batch 56/64 loss: 1.7260637283325195
Batch 57/64 loss: 1.7267591953277588
Batch 58/64 loss: 1.7400641441345215
Batch 59/64 loss: 1.72837233543396
Batch 60/64 loss: 1.7286226749420166
Batch 61/64 loss: 1.7297239303588867
Batch 62/64 loss: 1.7307651042938232
Batch 63/64 loss: 1.7258446216583252
Batch 64/64 loss: 1.902740478515625
Epoch 476  Train loss: 1.7289072354634603  Val loss: 1.7483443951688682
Epoch 477
-------------------------------
Batch 1/64 loss: 1.7259548902511597
Batch 2/64 loss: 1.7257291078567505
Batch 3/64 loss: 1.7278363704681396
Batch 4/64 loss: 1.7248587608337402
Batch 5/64 loss: 1.729528546333313
Batch 6/64 loss: 1.7248220443725586
Batch 7/64 loss: 1.7259100675582886
Batch 8/64 loss: 1.7305212020874023
Batch 9/64 loss: 1.7250730991363525
Batch 10/64 loss: 1.7324650287628174
Batch 11/64 loss: 1.7297688722610474
Batch 12/64 loss: 1.7296299934387207
Batch 13/64 loss: 1.7371323108673096
Batch 14/64 loss: 1.7525367736816406
Batch 15/64 loss: 1.729248285293579
Batch 16/64 loss: 1.7247123718261719
Batch 17/64 loss: 1.7245826721191406
Batch 18/64 loss: 1.7293047904968262
Batch 19/64 loss: 1.7261388301849365
Batch 20/64 loss: 1.7299182415008545
Batch 21/64 loss: 1.7324670553207397
Batch 22/64 loss: 1.7253235578536987
Batch 23/64 loss: 1.7362127304077148
Batch 24/64 loss: 1.7250759601593018
Batch 25/64 loss: 1.7274178266525269
Batch 26/64 loss: 1.731931447982788
Batch 27/64 loss: 1.727789282798767
Batch 28/64 loss: 1.7296191453933716
Batch 29/64 loss: 1.7286813259124756
Batch 30/64 loss: 1.7257561683654785
Batch 31/64 loss: 1.7380493879318237
Batch 32/64 loss: 1.7359849214553833
Batch 33/64 loss: 1.7286993265151978
Batch 34/64 loss: 1.7445464134216309
Batch 35/64 loss: 1.7332470417022705
Batch 36/64 loss: 1.7268335819244385
Batch 37/64 loss: 1.7287043333053589
Batch 38/64 loss: 1.7272614240646362
Batch 39/64 loss: 1.7393369674682617
Batch 40/64 loss: 1.7416539192199707
Batch 41/64 loss: 1.7251064777374268
Batch 42/64 loss: 1.7337017059326172
Batch 43/64 loss: 1.7384233474731445
Batch 44/64 loss: 1.7272658348083496
Batch 45/64 loss: 1.7287929058074951
Batch 46/64 loss: 1.7284687757492065
Batch 47/64 loss: 1.7284326553344727
Batch 48/64 loss: 1.7252955436706543
Batch 49/64 loss: 1.736278772354126
Batch 50/64 loss: 1.7257907390594482
Batch 51/64 loss: 1.7236918210983276
Batch 52/64 loss: 1.7245765924453735
Batch 53/64 loss: 1.7228853702545166
Batch 54/64 loss: 1.7271007299423218
Batch 55/64 loss: 1.7237069606781006
Batch 56/64 loss: 1.723024606704712
Batch 57/64 loss: 1.7303035259246826
Batch 58/64 loss: 1.726047158241272
Batch 59/64 loss: 1.7243366241455078
Batch 60/64 loss: 1.7263087034225464
Batch 61/64 loss: 1.7283332347869873
Batch 62/64 loss: 1.7248003482818604
Batch 63/64 loss: 1.7274174690246582
Batch 64/64 loss: 1.9065492153167725
Epoch 477  Train loss: 1.731455151240031  Val loss: 1.742022761774227
Epoch 478
-------------------------------
Batch 1/64 loss: 1.725682020187378
Batch 2/64 loss: 1.7279367446899414
Batch 3/64 loss: 1.7261648178100586
Batch 4/64 loss: 1.7299772500991821
Batch 5/64 loss: 1.7255504131317139
Batch 6/64 loss: 1.725464940071106
Batch 7/64 loss: 1.724841594696045
Batch 8/64 loss: 1.723101258277893
Batch 9/64 loss: 1.723196029663086
Batch 10/64 loss: 1.7237204313278198
Batch 11/64 loss: 1.7245707511901855
Batch 12/64 loss: 1.7247743606567383
Batch 13/64 loss: 1.7240116596221924
Batch 14/64 loss: 1.7216699123382568
Batch 15/64 loss: 1.7219624519348145
Batch 16/64 loss: 1.725057601928711
Batch 17/64 loss: 1.7242496013641357
Batch 18/64 loss: 1.721040964126587
Batch 19/64 loss: 1.723813533782959
Batch 20/64 loss: 1.723069190979004
Batch 21/64 loss: 1.7221777439117432
Batch 22/64 loss: 1.7235569953918457
Batch 23/64 loss: 1.724656105041504
Batch 24/64 loss: 1.724118947982788
Batch 25/64 loss: 1.7462427616119385
Batch 26/64 loss: 1.721877098083496
Batch 27/64 loss: 1.7244127988815308
Batch 28/64 loss: 1.7228143215179443
Batch 29/64 loss: 1.7256890535354614
Batch 30/64 loss: 1.725602149963379
Batch 31/64 loss: 1.7372491359710693
Batch 32/64 loss: 1.7241251468658447
Batch 33/64 loss: 1.7272989749908447
Batch 34/64 loss: 1.7242929935455322
Batch 35/64 loss: 1.723056674003601
Batch 36/64 loss: 1.7250394821166992
Batch 37/64 loss: 1.7329102754592896
Batch 38/64 loss: 1.7293286323547363
Batch 39/64 loss: 1.7263216972351074
Batch 40/64 loss: 1.7280614376068115
Batch 41/64 loss: 1.7277474403381348
Batch 42/64 loss: 1.7237000465393066
Batch 43/64 loss: 1.7294821739196777
Batch 44/64 loss: 1.7383649349212646
Batch 45/64 loss: 1.7252832651138306
Batch 46/64 loss: 1.728772521018982
Batch 47/64 loss: 1.7246760129928589
Batch 48/64 loss: 1.7242591381072998
Batch 49/64 loss: 1.7261316776275635
Batch 50/64 loss: 1.7259252071380615
Batch 51/64 loss: 1.7247314453125
Batch 52/64 loss: 1.7275068759918213
Batch 53/64 loss: 1.7279517650604248
Batch 54/64 loss: 1.7336890697479248
Batch 55/64 loss: 1.7261239290237427
Batch 56/64 loss: 1.7257378101348877
Batch 57/64 loss: 1.7275078296661377
Batch 58/64 loss: 1.7309331893920898
Batch 59/64 loss: 1.7236028909683228
Batch 60/64 loss: 1.7258780002593994
Batch 61/64 loss: 1.7277342081069946
Batch 62/64 loss: 1.7291460037231445
Batch 63/64 loss: 1.7308573722839355
Batch 64/64 loss: 1.9125192165374756
Epoch 478  Train loss: 1.72860894390181  Val loss: 1.7433002388354428
Epoch 479
-------------------------------
Batch 1/64 loss: 1.7266218662261963
Batch 2/64 loss: 1.7265154123306274
Batch 3/64 loss: 1.7271088361740112
Batch 4/64 loss: 1.7254564762115479
Batch 5/64 loss: 1.727303147315979
Batch 6/64 loss: 1.7237427234649658
Batch 7/64 loss: 1.722781777381897
Batch 8/64 loss: 1.7270314693450928
Batch 9/64 loss: 1.729280948638916
Batch 10/64 loss: 1.724886178970337
Batch 11/64 loss: 1.723707914352417
Batch 12/64 loss: 1.7244353294372559
Batch 13/64 loss: 1.7224102020263672
Batch 14/64 loss: 1.724756121635437
Batch 15/64 loss: 1.7237908840179443
Batch 16/64 loss: 1.724237084388733
Batch 17/64 loss: 1.7257850170135498
Batch 18/64 loss: 1.7235649824142456
Batch 19/64 loss: 1.7236344814300537
Batch 20/64 loss: 1.7294188737869263
Batch 21/64 loss: 1.7246882915496826
Batch 22/64 loss: 1.7262523174285889
Batch 23/64 loss: 1.7276556491851807
Batch 24/64 loss: 1.7246055603027344
Batch 25/64 loss: 1.7243846654891968
Batch 26/64 loss: 1.7289056777954102
Batch 27/64 loss: 1.7242827415466309
Batch 28/64 loss: 1.725294828414917
Batch 29/64 loss: 1.7256567478179932
Batch 30/64 loss: 1.7246530055999756
Batch 31/64 loss: 1.7252264022827148
Batch 32/64 loss: 1.7221494913101196
Batch 33/64 loss: 1.7231202125549316
Batch 34/64 loss: 1.72526216506958
Batch 35/64 loss: 1.7228639125823975
Batch 36/64 loss: 1.721637487411499
Batch 37/64 loss: 1.7281651496887207
Batch 38/64 loss: 1.7235585451126099
Batch 39/64 loss: 1.7241359949111938
Batch 40/64 loss: 1.7241265773773193
Batch 41/64 loss: 1.7247822284698486
Batch 42/64 loss: 1.72501802444458
Batch 43/64 loss: 1.7282954454421997
Batch 44/64 loss: 1.7254289388656616
Batch 45/64 loss: 1.7246694564819336
Batch 46/64 loss: 1.7394745349884033
Batch 47/64 loss: 1.725968837738037
Batch 48/64 loss: 1.7418239116668701
Batch 49/64 loss: 1.7230634689331055
Batch 50/64 loss: 1.7229681015014648
Batch 51/64 loss: 1.7217886447906494
Batch 52/64 loss: 1.7378920316696167
Batch 53/64 loss: 1.7256271839141846
Batch 54/64 loss: 1.723976969718933
Batch 55/64 loss: 1.7247111797332764
Batch 56/64 loss: 1.7237260341644287
Batch 57/64 loss: 1.7228041887283325
Batch 58/64 loss: 1.721923828125
Batch 59/64 loss: 1.7294055223464966
Batch 60/64 loss: 1.7228989601135254
Batch 61/64 loss: 1.7256169319152832
Batch 62/64 loss: 1.7243311405181885
Batch 63/64 loss: 1.7247692346572876
Batch 64/64 loss: 1.902338981628418
Epoch 479  Train loss: 1.7276990460414512  Val loss: 1.7415875249711918
Epoch 480
-------------------------------
Batch 1/64 loss: 1.725229024887085
Batch 2/64 loss: 1.726083517074585
Batch 3/64 loss: 1.7224061489105225
Batch 4/64 loss: 1.7257996797561646
Batch 5/64 loss: 1.7271054983139038
Batch 6/64 loss: 1.7251843214035034
Batch 7/64 loss: 1.7252964973449707
Batch 8/64 loss: 1.72275972366333
Batch 9/64 loss: 1.7237708568572998
Batch 10/64 loss: 1.7253202199935913
Batch 11/64 loss: 1.7224273681640625
Batch 12/64 loss: 1.7231383323669434
Batch 13/64 loss: 1.7222652435302734
Batch 14/64 loss: 1.7228662967681885
Batch 15/64 loss: 1.7244975566864014
Batch 16/64 loss: 1.7213070392608643
Batch 17/64 loss: 1.7242517471313477
Batch 18/64 loss: 1.7237827777862549
Batch 19/64 loss: 1.7434577941894531
Batch 20/64 loss: 1.726254940032959
Batch 21/64 loss: 1.7237863540649414
Batch 22/64 loss: 1.7233576774597168
Batch 23/64 loss: 1.7221014499664307
Batch 24/64 loss: 1.7237398624420166
Batch 25/64 loss: 1.723771095275879
Batch 26/64 loss: 1.7224031686782837
Batch 27/64 loss: 1.724448323249817
Batch 28/64 loss: 1.7193784713745117
Batch 29/64 loss: 1.7197105884552002
Batch 30/64 loss: 1.7275999784469604
Batch 31/64 loss: 1.7229831218719482
Batch 32/64 loss: 1.7248709201812744
Batch 33/64 loss: 1.7351560592651367
Batch 34/64 loss: 1.7309293746948242
Batch 35/64 loss: 1.7252793312072754
Batch 36/64 loss: 1.7221832275390625
Batch 37/64 loss: 1.7261701822280884
Batch 38/64 loss: 1.7247192859649658
Batch 39/64 loss: 1.7225332260131836
Batch 40/64 loss: 1.72611403465271
Batch 41/64 loss: 1.7240734100341797
Batch 42/64 loss: 1.7241559028625488
Batch 43/64 loss: 1.7257866859436035
Batch 44/64 loss: 1.7211079597473145
Batch 45/64 loss: 1.7233926057815552
Batch 46/64 loss: 1.727877140045166
Batch 47/64 loss: 1.7228093147277832
Batch 48/64 loss: 1.7218055725097656
Batch 49/64 loss: 1.7226992845535278
Batch 50/64 loss: 1.7248386144638062
Batch 51/64 loss: 1.7220534086227417
Batch 52/64 loss: 1.7223491668701172
Batch 53/64 loss: 1.721526861190796
Batch 54/64 loss: 1.7216414213180542
Batch 55/64 loss: 1.724122405052185
Batch 56/64 loss: 1.7217020988464355
Batch 57/64 loss: 1.7240376472473145
Batch 58/64 loss: 1.723602533340454
Batch 59/64 loss: 1.7228384017944336
Batch 60/64 loss: 1.741038203239441
Batch 61/64 loss: 1.7225110530853271
Batch 62/64 loss: 1.7242506742477417
Batch 63/64 loss: 1.7220319509506226
Batch 64/64 loss: 1.8952951431274414
Epoch 480  Train loss: 1.72655943515254  Val loss: 1.739317549872644
Epoch 481
-------------------------------
Batch 1/64 loss: 1.722525954246521
Batch 2/64 loss: 1.7432618141174316
Batch 3/64 loss: 1.7256996631622314
Batch 4/64 loss: 1.7232012748718262
Batch 5/64 loss: 1.722933053970337
Batch 6/64 loss: 1.7238860130310059
Batch 7/64 loss: 1.7220661640167236
Batch 8/64 loss: 1.7213644981384277
Batch 9/64 loss: 1.7222769260406494
Batch 10/64 loss: 1.72230863571167
Batch 11/64 loss: 1.7392258644104004
Batch 12/64 loss: 1.7275161743164062
Batch 13/64 loss: 1.7227636575698853
Batch 14/64 loss: 1.723003625869751
Batch 15/64 loss: 1.73045015335083
Batch 16/64 loss: 1.727227807044983
Batch 17/64 loss: 1.7284231185913086
Batch 18/64 loss: 1.7262825965881348
Batch 19/64 loss: 1.7276618480682373
Batch 20/64 loss: 1.7259767055511475
Batch 21/64 loss: 1.725536584854126
Batch 22/64 loss: 1.725172519683838
Batch 23/64 loss: 1.7399587631225586
Batch 24/64 loss: 1.7254555225372314
Batch 25/64 loss: 1.7223577499389648
Batch 26/64 loss: 1.7245559692382812
Batch 27/64 loss: 1.7239633798599243
Batch 28/64 loss: 1.7247934341430664
Batch 29/64 loss: 1.724945068359375
Batch 30/64 loss: 1.7242625951766968
Batch 31/64 loss: 1.723860740661621
Batch 32/64 loss: 1.7224547863006592
Batch 33/64 loss: 1.7230148315429688
Batch 34/64 loss: 1.7210031747817993
Batch 35/64 loss: 1.7208538055419922
Batch 36/64 loss: 1.7252423763275146
Batch 37/64 loss: 1.7244906425476074
Batch 38/64 loss: 1.726572871208191
Batch 39/64 loss: 1.7263505458831787
Batch 40/64 loss: 1.7228138446807861
Batch 41/64 loss: 1.725914478302002
Batch 42/64 loss: 1.7249000072479248
Batch 43/64 loss: 1.7224065065383911
Batch 44/64 loss: 1.7259467840194702
Batch 45/64 loss: 1.723144292831421
Batch 46/64 loss: 1.7211666107177734
Batch 47/64 loss: 1.7311753034591675
Batch 48/64 loss: 1.7225298881530762
Batch 49/64 loss: 1.725829005241394
Batch 50/64 loss: 1.7266685962677002
Batch 51/64 loss: 1.725219964981079
Batch 52/64 loss: 1.721752643585205
Batch 53/64 loss: 1.7226464748382568
Batch 54/64 loss: 1.7332665920257568
Batch 55/64 loss: 1.7271199226379395
Batch 56/64 loss: 1.724868655204773
Batch 57/64 loss: 1.7239649295806885
Batch 58/64 loss: 1.7229485511779785
Batch 59/64 loss: 1.7225451469421387
Batch 60/64 loss: 1.7249144315719604
Batch 61/64 loss: 1.7245581150054932
Batch 62/64 loss: 1.7208623886108398
Batch 63/64 loss: 1.7250114679336548
Batch 64/64 loss: 1.8986493349075317
Epoch 481  Train loss: 1.7273578433429493  Val loss: 1.7441472925271366
Epoch 482
-------------------------------
Batch 1/64 loss: 1.7221965789794922
Batch 2/64 loss: 1.7249287366867065
Batch 3/64 loss: 1.7246558666229248
Batch 4/64 loss: 1.7231500148773193
Batch 5/64 loss: 1.7295966148376465
Batch 6/64 loss: 1.7233617305755615
Batch 7/64 loss: 1.7243940830230713
Batch 8/64 loss: 1.7255913019180298
Batch 9/64 loss: 1.7268706560134888
Batch 10/64 loss: 1.7249572277069092
Batch 11/64 loss: 1.7235243320465088
Batch 12/64 loss: 1.723093032836914
Batch 13/64 loss: 1.7235968112945557
Batch 14/64 loss: 1.7411401271820068
Batch 15/64 loss: 1.7205380201339722
Batch 16/64 loss: 1.7227864265441895
Batch 17/64 loss: 1.7238937616348267
Batch 18/64 loss: 1.7209792137145996
Batch 19/64 loss: 1.724692463874817
Batch 20/64 loss: 1.7220057249069214
Batch 21/64 loss: 1.7225230932235718
Batch 22/64 loss: 1.724547266960144
Batch 23/64 loss: 1.7229671478271484
Batch 24/64 loss: 1.7256968021392822
Batch 25/64 loss: 1.7387235164642334
Batch 26/64 loss: 1.7241301536560059
Batch 27/64 loss: 1.725698709487915
Batch 28/64 loss: 1.7225627899169922
Batch 29/64 loss: 1.724166750907898
Batch 30/64 loss: 1.7215077877044678
Batch 31/64 loss: 1.7231676578521729
Batch 32/64 loss: 1.7213075160980225
Batch 33/64 loss: 1.7264575958251953
Batch 34/64 loss: 1.7375344038009644
Batch 35/64 loss: 1.7201666831970215
Batch 36/64 loss: 1.7226157188415527
Batch 37/64 loss: 1.729046106338501
Batch 38/64 loss: 1.7225162982940674
Batch 39/64 loss: 1.7240705490112305
Batch 40/64 loss: 1.7224966287612915
Batch 41/64 loss: 1.7243403196334839
Batch 42/64 loss: 1.7251698970794678
Batch 43/64 loss: 1.7291419506072998
Batch 44/64 loss: 1.7331585884094238
Batch 45/64 loss: 1.722990870475769
Batch 46/64 loss: 1.72291898727417
Batch 47/64 loss: 1.7226766347885132
Batch 48/64 loss: 1.7274701595306396
Batch 49/64 loss: 1.7256240844726562
Batch 50/64 loss: 1.725142240524292
Batch 51/64 loss: 1.7255213260650635
Batch 52/64 loss: 1.7247264385223389
Batch 53/64 loss: 1.7265911102294922
Batch 54/64 loss: 1.7283151149749756
Batch 55/64 loss: 1.7226358652114868
Batch 56/64 loss: 1.7238726615905762
Batch 57/64 loss: 1.7235989570617676
Batch 58/64 loss: 1.7241672277450562
Batch 59/64 loss: 1.7251965999603271
Batch 60/64 loss: 1.726912498474121
Batch 61/64 loss: 1.7221931219100952
Batch 62/64 loss: 1.725276231765747
Batch 63/64 loss: 1.7243366241455078
Batch 64/64 loss: 1.9038374423980713
Epoch 482  Train loss: 1.7271797881406896  Val loss: 1.7437932581426352
Epoch 483
-------------------------------
Batch 1/64 loss: 1.72550368309021
Batch 2/64 loss: 1.7285579442977905
Batch 3/64 loss: 1.7234548330307007
Batch 4/64 loss: 1.726945400238037
Batch 5/64 loss: 1.723455548286438
Batch 6/64 loss: 1.7268660068511963
Batch 7/64 loss: 1.7301599979400635
Batch 8/64 loss: 1.7242766618728638
Batch 9/64 loss: 1.7277175188064575
Batch 10/64 loss: 1.7254276275634766
Batch 11/64 loss: 1.7277624607086182
Batch 12/64 loss: 1.7232916355133057
Batch 13/64 loss: 1.7353483438491821
Batch 14/64 loss: 1.7278648614883423
Batch 15/64 loss: 1.7235465049743652
Batch 16/64 loss: 1.7291617393493652
Batch 17/64 loss: 1.7255334854125977
Batch 18/64 loss: 1.7256542444229126
Batch 19/64 loss: 1.724484920501709
Batch 20/64 loss: 1.7230684757232666
Batch 21/64 loss: 1.7247861623764038
Batch 22/64 loss: 1.744101881980896
Batch 23/64 loss: 1.7281733751296997
Batch 24/64 loss: 1.7339900732040405
Batch 25/64 loss: 1.724671483039856
Batch 26/64 loss: 1.7266805171966553
Batch 27/64 loss: 1.7233935594558716
Batch 28/64 loss: 1.7243753671646118
Batch 29/64 loss: 1.733318567276001
Batch 30/64 loss: 1.7249906063079834
Batch 31/64 loss: 1.721982479095459
Batch 32/64 loss: 1.7249575853347778
Batch 33/64 loss: 1.7229881286621094
Batch 34/64 loss: 1.724597692489624
Batch 35/64 loss: 1.7287766933441162
Batch 36/64 loss: 1.7232029438018799
Batch 37/64 loss: 1.7295805215835571
Batch 38/64 loss: 1.7269458770751953
Batch 39/64 loss: 1.7282363176345825
Batch 40/64 loss: 1.7240409851074219
Batch 41/64 loss: 1.723535180091858
Batch 42/64 loss: 1.7242860794067383
Batch 43/64 loss: 1.726120114326477
Batch 44/64 loss: 1.7286977767944336
Batch 45/64 loss: 1.7232586145401
Batch 46/64 loss: 1.7233176231384277
Batch 47/64 loss: 1.7220745086669922
Batch 48/64 loss: 1.7245116233825684
Batch 49/64 loss: 1.7218081951141357
Batch 50/64 loss: 1.7245521545410156
Batch 51/64 loss: 1.722576379776001
Batch 52/64 loss: 1.722320556640625
Batch 53/64 loss: 1.726093053817749
Batch 54/64 loss: 1.721237301826477
Batch 55/64 loss: 1.7227294445037842
Batch 56/64 loss: 1.7254385948181152
Batch 57/64 loss: 1.7244846820831299
Batch 58/64 loss: 1.725149154663086
Batch 59/64 loss: 1.7253880500793457
Batch 60/64 loss: 1.7414216995239258
Batch 61/64 loss: 1.7232630252838135
Batch 62/64 loss: 1.72616708278656
Batch 63/64 loss: 1.7216687202453613
Batch 64/64 loss: 1.9070143699645996
Epoch 483  Train loss: 1.7281918918385226  Val loss: 1.7401289448295671
Epoch 484
-------------------------------
Batch 1/64 loss: 1.7323790788650513
Batch 2/64 loss: 1.7222461700439453
Batch 3/64 loss: 1.7244765758514404
Batch 4/64 loss: 1.722679615020752
Batch 5/64 loss: 1.721204161643982
Batch 6/64 loss: 1.7228926420211792
Batch 7/64 loss: 1.7224557399749756
Batch 8/64 loss: 1.723550796508789
Batch 9/64 loss: 1.7378230094909668
Batch 10/64 loss: 1.7223284244537354
Batch 11/64 loss: 1.7361438274383545
Batch 12/64 loss: 1.7274904251098633
Batch 13/64 loss: 1.7268542051315308
Batch 14/64 loss: 1.7323849201202393
Batch 15/64 loss: 1.727052092552185
Batch 16/64 loss: 1.7248467206954956
Batch 17/64 loss: 1.7258834838867188
Batch 18/64 loss: 1.7242326736450195
Batch 19/64 loss: 1.7242764234542847
Batch 20/64 loss: 1.7223763465881348
Batch 21/64 loss: 1.7228400707244873
Batch 22/64 loss: 1.7222261428833008
Batch 23/64 loss: 1.722778558731079
Batch 24/64 loss: 1.72718346118927
Batch 25/64 loss: 1.7239290475845337
Batch 26/64 loss: 1.7269129753112793
Batch 27/64 loss: 1.721977710723877
Batch 28/64 loss: 1.7218127250671387
Batch 29/64 loss: 1.7264671325683594
Batch 30/64 loss: 1.7225730419158936
Batch 31/64 loss: 1.7252278327941895
Batch 32/64 loss: 1.7243340015411377
Batch 33/64 loss: 1.7242175340652466
Batch 34/64 loss: 1.7241089344024658
Batch 35/64 loss: 1.7420380115509033
Batch 36/64 loss: 1.725298285484314
Batch 37/64 loss: 1.72141695022583
Batch 38/64 loss: 1.7247939109802246
Batch 39/64 loss: 1.726388692855835
Batch 40/64 loss: 1.7231812477111816
Batch 41/64 loss: 1.723790168762207
Batch 42/64 loss: 1.723213791847229
Batch 43/64 loss: 1.7330975532531738
Batch 44/64 loss: 1.7230348587036133
Batch 45/64 loss: 1.724165678024292
Batch 46/64 loss: 1.7216687202453613
Batch 47/64 loss: 1.7285139560699463
Batch 48/64 loss: 1.7218073606491089
Batch 49/64 loss: 1.7252117395401
Batch 50/64 loss: 1.7243629693984985
Batch 51/64 loss: 1.7251075506210327
Batch 52/64 loss: 1.7291463613510132
Batch 53/64 loss: 1.7236876487731934
Batch 54/64 loss: 1.7246620655059814
Batch 55/64 loss: 1.7224713563919067
Batch 56/64 loss: 1.7249565124511719
Batch 57/64 loss: 1.7248862981796265
Batch 58/64 loss: 1.7261369228363037
Batch 59/64 loss: 1.7233304977416992
Batch 60/64 loss: 1.7254996299743652
Batch 61/64 loss: 1.7245527505874634
Batch 62/64 loss: 1.7207777500152588
Batch 63/64 loss: 1.7217886447906494
Batch 64/64 loss: 1.8989012241363525
Epoch 484  Train loss: 1.7272679263470219  Val loss: 1.7421648723562968
Epoch 485
-------------------------------
Batch 1/64 loss: 1.7272348403930664
Batch 2/64 loss: 1.7227060794830322
Batch 3/64 loss: 1.7249329090118408
Batch 4/64 loss: 1.7256799936294556
Batch 5/64 loss: 1.7213995456695557
Batch 6/64 loss: 1.7242786884307861
Batch 7/64 loss: 1.73030686378479
Batch 8/64 loss: 1.7252702713012695
Batch 9/64 loss: 1.7310525178909302
Batch 10/64 loss: 1.7243149280548096
Batch 11/64 loss: 1.7245473861694336
Batch 12/64 loss: 1.7507929801940918
Batch 13/64 loss: 1.7242518663406372
Batch 14/64 loss: 1.723338007926941
Batch 15/64 loss: 1.7250436544418335
Batch 16/64 loss: 1.7258777618408203
Batch 17/64 loss: 1.739341139793396
Batch 18/64 loss: 1.734768271446228
Batch 19/64 loss: 1.7218806743621826
Batch 20/64 loss: 1.7252025604248047
Batch 21/64 loss: 1.7264764308929443
Batch 22/64 loss: 1.7235782146453857
Batch 23/64 loss: 1.727094292640686
Batch 24/64 loss: 1.7237024307250977
Batch 25/64 loss: 1.723869800567627
Batch 26/64 loss: 1.7258152961730957
Batch 27/64 loss: 1.7277284860610962
Batch 28/64 loss: 1.7269971370697021
Batch 29/64 loss: 1.7236231565475464
Batch 30/64 loss: 1.7212328910827637
Batch 31/64 loss: 1.726543664932251
Batch 32/64 loss: 1.7296401262283325
Batch 33/64 loss: 1.724170446395874
Batch 34/64 loss: 1.7268052101135254
Batch 35/64 loss: 1.7287952899932861
Batch 36/64 loss: 1.724890947341919
Batch 37/64 loss: 1.7240548133850098
Batch 38/64 loss: 1.7222635746002197
Batch 39/64 loss: 1.7235956192016602
Batch 40/64 loss: 1.7223860025405884
Batch 41/64 loss: 1.7257392406463623
Batch 42/64 loss: 1.726999282836914
Batch 43/64 loss: 1.7465651035308838
Batch 44/64 loss: 1.7253130674362183
Batch 45/64 loss: 1.7249772548675537
Batch 46/64 loss: 1.7243144512176514
Batch 47/64 loss: 1.7238633632659912
Batch 48/64 loss: 1.725832223892212
Batch 49/64 loss: 1.722324252128601
Batch 50/64 loss: 1.7225840091705322
Batch 51/64 loss: 1.7291498184204102
Batch 52/64 loss: 1.7258751392364502
Batch 53/64 loss: 1.7231030464172363
Batch 54/64 loss: 1.723193645477295
Batch 55/64 loss: 1.7237069606781006
Batch 56/64 loss: 1.726044774055481
Batch 57/64 loss: 1.7239729166030884
Batch 58/64 loss: 1.7277514934539795
Batch 59/64 loss: 1.7258635759353638
Batch 60/64 loss: 1.7251039743423462
Batch 61/64 loss: 1.7236244678497314
Batch 62/64 loss: 1.7236244678497314
Batch 63/64 loss: 1.7251451015472412
Batch 64/64 loss: 1.9058473110198975
Epoch 485  Train loss: 1.7283065393859265  Val loss: 1.7411906416063865
Epoch 486
-------------------------------
Batch 1/64 loss: 1.725279688835144
Batch 2/64 loss: 1.7227109670639038
Batch 3/64 loss: 1.7243900299072266
Batch 4/64 loss: 1.7226126194000244
Batch 5/64 loss: 1.7264982461929321
Batch 6/64 loss: 1.7274372577667236
Batch 7/64 loss: 1.729418396949768
Batch 8/64 loss: 1.7295458316802979
Batch 9/64 loss: 1.7228658199310303
Batch 10/64 loss: 1.7266077995300293
Batch 11/64 loss: 1.7261269092559814
Batch 12/64 loss: 1.7236883640289307
Batch 13/64 loss: 1.7227363586425781
Batch 14/64 loss: 1.7281640768051147
Batch 15/64 loss: 1.7255241870880127
Batch 16/64 loss: 1.7215814590454102
Batch 17/64 loss: 1.7239818572998047
Batch 18/64 loss: 1.7475073337554932
Batch 19/64 loss: 1.7256765365600586
Batch 20/64 loss: 1.7252981662750244
Batch 21/64 loss: 1.7247600555419922
Batch 22/64 loss: 1.7228405475616455
Batch 23/64 loss: 1.7266325950622559
Batch 24/64 loss: 1.724176287651062
Batch 25/64 loss: 1.726280927658081
Batch 26/64 loss: 1.725658893585205
Batch 27/64 loss: 1.7226049900054932
Batch 28/64 loss: 1.7301852703094482
Batch 29/64 loss: 1.7262276411056519
Batch 30/64 loss: 1.7251014709472656
Batch 31/64 loss: 1.7260743379592896
Batch 32/64 loss: 1.7272846698760986
Batch 33/64 loss: 1.7262544631958008
Batch 34/64 loss: 1.725015640258789
Batch 35/64 loss: 1.723917007446289
Batch 36/64 loss: 1.7303378582000732
Batch 37/64 loss: 1.7353603839874268
Batch 38/64 loss: 1.7392711639404297
Batch 39/64 loss: 1.72377347946167
Batch 40/64 loss: 1.7282733917236328
Batch 41/64 loss: 1.7250897884368896
Batch 42/64 loss: 1.726548194885254
Batch 43/64 loss: 1.724470853805542
Batch 44/64 loss: 1.7256351709365845
Batch 45/64 loss: 1.7293715476989746
Batch 46/64 loss: 1.7298107147216797
Batch 47/64 loss: 1.7258121967315674
Batch 48/64 loss: 1.728339433670044
Batch 49/64 loss: 1.7244919538497925
Batch 50/64 loss: 1.7251328229904175
Batch 51/64 loss: 1.728257656097412
Batch 52/64 loss: 1.7225186824798584
Batch 53/64 loss: 1.7281737327575684
Batch 54/64 loss: 1.7252588272094727
Batch 55/64 loss: 1.7271246910095215
Batch 56/64 loss: 1.7249293327331543
Batch 57/64 loss: 1.7254505157470703
Batch 58/64 loss: 1.7229464054107666
Batch 59/64 loss: 1.723021388053894
Batch 60/64 loss: 1.7270264625549316
Batch 61/64 loss: 1.7327147722244263
Batch 62/64 loss: 1.7249128818511963
Batch 63/64 loss: 1.7283759117126465
Batch 64/64 loss: 1.9032691717147827
Epoch 486  Train loss: 1.7286360595740524  Val loss: 1.7456181467193919
Epoch 487
-------------------------------
Batch 1/64 loss: 1.7236063480377197
Batch 2/64 loss: 1.7229266166687012
Batch 3/64 loss: 1.7278454303741455
Batch 4/64 loss: 1.73404860496521
Batch 5/64 loss: 1.7285856008529663
Batch 6/64 loss: 1.7246291637420654
Batch 7/64 loss: 1.7251449823379517
Batch 8/64 loss: 1.7272117137908936
Batch 9/64 loss: 1.7256722450256348
Batch 10/64 loss: 1.7269854545593262
Batch 11/64 loss: 1.725328803062439
Batch 12/64 loss: 1.726414442062378
Batch 13/64 loss: 1.7230627536773682
Batch 14/64 loss: 1.7269134521484375
Batch 15/64 loss: 1.7281382083892822
Batch 16/64 loss: 1.7267065048217773
Batch 17/64 loss: 1.7414357662200928
Batch 18/64 loss: 1.7238556146621704
Batch 19/64 loss: 1.725995421409607
Batch 20/64 loss: 1.728381633758545
Batch 21/64 loss: 1.7244443893432617
Batch 22/64 loss: 1.7281219959259033
Batch 23/64 loss: 1.7273565530776978
Batch 24/64 loss: 1.727573275566101
Batch 25/64 loss: 1.7234225273132324
Batch 26/64 loss: 1.7251126766204834
Batch 27/64 loss: 1.725694179534912
Batch 28/64 loss: 1.724103569984436
Batch 29/64 loss: 1.7232897281646729
Batch 30/64 loss: 1.7246482372283936
Batch 31/64 loss: 1.7243620157241821
Batch 32/64 loss: 1.7250757217407227
Batch 33/64 loss: 1.722303032875061
Batch 34/64 loss: 1.7316869497299194
Batch 35/64 loss: 1.7252895832061768
Batch 36/64 loss: 1.7414582967758179
Batch 37/64 loss: 1.7312451601028442
Batch 38/64 loss: 1.7249797582626343
Batch 39/64 loss: 1.7236526012420654
Batch 40/64 loss: 1.7242491245269775
Batch 41/64 loss: 1.7247233390808105
Batch 42/64 loss: 1.7282077074050903
Batch 43/64 loss: 1.7255909442901611
Batch 44/64 loss: 1.7251535654067993
Batch 45/64 loss: 1.7279975414276123
Batch 46/64 loss: 1.722482442855835
Batch 47/64 loss: 1.7383489608764648
Batch 48/64 loss: 1.7305067777633667
Batch 49/64 loss: 1.7275623083114624
Batch 50/64 loss: 1.7273117303848267
Batch 51/64 loss: 1.7261521816253662
Batch 52/64 loss: 1.7242302894592285
Batch 53/64 loss: 1.7266719341278076
Batch 54/64 loss: 1.7280559539794922
Batch 55/64 loss: 1.7318509817123413
Batch 56/64 loss: 1.7240077257156372
Batch 57/64 loss: 1.7270991802215576
Batch 58/64 loss: 1.7283968925476074
Batch 59/64 loss: 1.7241613864898682
Batch 60/64 loss: 1.7250630855560303
Batch 61/64 loss: 1.722123384475708
Batch 62/64 loss: 1.7238514423370361
Batch 63/64 loss: 1.7241218090057373
Batch 64/64 loss: 1.9044334888458252
Epoch 487  Train loss: 1.7288306638306263  Val loss: 1.741508116017502
Epoch 488
-------------------------------
Batch 1/64 loss: 1.726815938949585
Batch 2/64 loss: 1.7218151092529297
Batch 3/64 loss: 1.722243070602417
Batch 4/64 loss: 1.7246387004852295
Batch 5/64 loss: 1.7210761308670044
Batch 6/64 loss: 1.7267730236053467
Batch 7/64 loss: 1.7249022722244263
Batch 8/64 loss: 1.7234692573547363
Batch 9/64 loss: 1.7221986055374146
Batch 10/64 loss: 1.7208307981491089
Batch 11/64 loss: 1.7242556810379028
Batch 12/64 loss: 1.7254993915557861
Batch 13/64 loss: 1.721468448638916
Batch 14/64 loss: 1.7256665229797363
Batch 15/64 loss: 1.727919340133667
Batch 16/64 loss: 1.7231595516204834
Batch 17/64 loss: 1.7303314208984375
Batch 18/64 loss: 1.721595287322998
Batch 19/64 loss: 1.7254040241241455
Batch 20/64 loss: 1.7236942052841187
Batch 21/64 loss: 1.7220611572265625
Batch 22/64 loss: 1.7207894325256348
Batch 23/64 loss: 1.7225085496902466
Batch 24/64 loss: 1.7427666187286377
Batch 25/64 loss: 1.7249317169189453
Batch 26/64 loss: 1.7242398262023926
Batch 27/64 loss: 1.7218120098114014
Batch 28/64 loss: 1.7207765579223633
Batch 29/64 loss: 1.7218382358551025
Batch 30/64 loss: 1.726799726486206
Batch 31/64 loss: 1.7245171070098877
Batch 32/64 loss: 1.725097894668579
Batch 33/64 loss: 1.7253339290618896
Batch 34/64 loss: 1.7241849899291992
Batch 35/64 loss: 1.735917329788208
Batch 36/64 loss: 1.7307276725769043
Batch 37/64 loss: 1.7300471067428589
Batch 38/64 loss: 1.7244384288787842
Batch 39/64 loss: 1.7277400493621826
Batch 40/64 loss: 1.7307214736938477
Batch 41/64 loss: 1.7419366836547852
Batch 42/64 loss: 1.7274574041366577
Batch 43/64 loss: 1.7314205169677734
Batch 44/64 loss: 1.726956844329834
Batch 45/64 loss: 1.7279053926467896
Batch 46/64 loss: 1.7280123233795166
Batch 47/64 loss: 1.7293744087219238
Batch 48/64 loss: 1.7250792980194092
Batch 49/64 loss: 1.7256513833999634
Batch 50/64 loss: 1.7251250743865967
Batch 51/64 loss: 1.7257931232452393
Batch 52/64 loss: 1.7273327112197876
Batch 53/64 loss: 1.7286536693572998
Batch 54/64 loss: 1.728015661239624
Batch 55/64 loss: 1.7219395637512207
Batch 56/64 loss: 1.7256693840026855
Batch 57/64 loss: 1.726689100265503
Batch 58/64 loss: 1.725520133972168
Batch 59/64 loss: 1.731872320175171
Batch 60/64 loss: 1.7247986793518066
Batch 61/64 loss: 1.7274235486984253
Batch 62/64 loss: 1.7255401611328125
Batch 63/64 loss: 1.7262954711914062
Batch 64/64 loss: 1.9011919498443604
Epoch 488  Train loss: 1.7281782496209237  Val loss: 1.7460833292236853
Epoch 489
-------------------------------
Batch 1/64 loss: 1.7283451557159424
Batch 2/64 loss: 1.7274093627929688
Batch 3/64 loss: 1.725102186203003
Batch 4/64 loss: 1.7282538414001465
Batch 5/64 loss: 1.7243504524230957
Batch 6/64 loss: 1.7252249717712402
Batch 7/64 loss: 1.7275896072387695
Batch 8/64 loss: 1.7248787879943848
Batch 9/64 loss: 1.7229132652282715
Batch 10/64 loss: 1.7279789447784424
Batch 11/64 loss: 1.7328801155090332
Batch 12/64 loss: 1.725026249885559
Batch 13/64 loss: 1.7259223461151123
Batch 14/64 loss: 1.7282958030700684
Batch 15/64 loss: 1.7266438007354736
Batch 16/64 loss: 1.7261370420455933
Batch 17/64 loss: 1.7228387594223022
Batch 18/64 loss: 1.7231992483139038
Batch 19/64 loss: 1.7250878810882568
Batch 20/64 loss: 1.7235395908355713
Batch 21/64 loss: 1.7259032726287842
Batch 22/64 loss: 1.7220797538757324
Batch 23/64 loss: 1.7225592136383057
Batch 24/64 loss: 1.7217442989349365
Batch 25/64 loss: 1.724319577217102
Batch 26/64 loss: 1.729297399520874
Batch 27/64 loss: 1.7301371097564697
Batch 28/64 loss: 1.7258081436157227
Batch 29/64 loss: 1.7257356643676758
Batch 30/64 loss: 1.7274246215820312
Batch 31/64 loss: 1.7212915420532227
Batch 32/64 loss: 1.7249300479888916
Batch 33/64 loss: 1.7207947969436646
Batch 34/64 loss: 1.7216899394989014
Batch 35/64 loss: 1.7210681438446045
Batch 36/64 loss: 1.7209402322769165
Batch 37/64 loss: 1.722951889038086
Batch 38/64 loss: 1.7245151996612549
Batch 39/64 loss: 1.728797197341919
Batch 40/64 loss: 1.7236889600753784
Batch 41/64 loss: 1.720886468887329
Batch 42/64 loss: 1.7273826599121094
Batch 43/64 loss: 1.728126049041748
Batch 44/64 loss: 1.7250409126281738
Batch 45/64 loss: 1.7251142263412476
Batch 46/64 loss: 1.73427414894104
Batch 47/64 loss: 1.7458012104034424
Batch 48/64 loss: 1.721156120300293
Batch 49/64 loss: 1.7229636907577515
Batch 50/64 loss: 1.7239179611206055
Batch 51/64 loss: 1.725731372833252
Batch 52/64 loss: 1.723813772201538
Batch 53/64 loss: 1.7284493446350098
Batch 54/64 loss: 1.725250482559204
Batch 55/64 loss: 1.722745656967163
Batch 56/64 loss: 1.72579026222229
Batch 57/64 loss: 1.72585129737854
Batch 58/64 loss: 1.7236100435256958
Batch 59/64 loss: 1.7271456718444824
Batch 60/64 loss: 1.727226734161377
Batch 61/64 loss: 1.7241557836532593
Batch 62/64 loss: 1.7250609397888184
Batch 63/64 loss: 1.7409389019012451
Batch 64/64 loss: 1.9041657447814941
Epoch 489  Train loss: 1.7279349401885389  Val loss: 1.7429407634276295
Epoch 490
-------------------------------
Batch 1/64 loss: 1.726932406425476
Batch 2/64 loss: 1.7241737842559814
Batch 3/64 loss: 1.7238826751708984
Batch 4/64 loss: 1.7246248722076416
Batch 5/64 loss: 1.723449945449829
Batch 6/64 loss: 1.723052740097046
Batch 7/64 loss: 1.72580885887146
Batch 8/64 loss: 1.7252473831176758
Batch 9/64 loss: 1.724708914756775
Batch 10/64 loss: 1.7265516519546509
Batch 11/64 loss: 1.7239909172058105
Batch 12/64 loss: 1.7240508794784546
Batch 13/64 loss: 1.7216250896453857
Batch 14/64 loss: 1.7282042503356934
Batch 15/64 loss: 1.7241506576538086
Batch 16/64 loss: 1.7538280487060547
Batch 17/64 loss: 1.7289175987243652
Batch 18/64 loss: 1.7219599485397339
Batch 19/64 loss: 1.7256312370300293
Batch 20/64 loss: 1.7321585416793823
Batch 21/64 loss: 1.7319202423095703
Batch 22/64 loss: 1.7224059104919434
Batch 23/64 loss: 1.7248904705047607
Batch 24/64 loss: 1.725250005722046
Batch 25/64 loss: 1.7229046821594238
Batch 26/64 loss: 1.7312772274017334
Batch 27/64 loss: 1.723771333694458
Batch 28/64 loss: 1.7218867540359497
Batch 29/64 loss: 1.7264354228973389
Batch 30/64 loss: 1.7232937812805176
Batch 31/64 loss: 1.7251904010772705
Batch 32/64 loss: 1.7301247119903564
Batch 33/64 loss: 1.7272754907608032
Batch 34/64 loss: 1.7225714921951294
Batch 35/64 loss: 1.7268788814544678
Batch 36/64 loss: 1.7242705821990967
Batch 37/64 loss: 1.7255182266235352
Batch 38/64 loss: 1.7235791683197021
Batch 39/64 loss: 1.7294833660125732
Batch 40/64 loss: 1.7363379001617432
Batch 41/64 loss: 1.7215943336486816
Batch 42/64 loss: 1.7253004312515259
Batch 43/64 loss: 1.7252670526504517
Batch 44/64 loss: 1.7234416007995605
Batch 45/64 loss: 1.7232935428619385
Batch 46/64 loss: 1.7257050275802612
Batch 47/64 loss: 1.7212016582489014
Batch 48/64 loss: 1.7260749340057373
Batch 49/64 loss: 1.7213599681854248
Batch 50/64 loss: 1.7357611656188965
Batch 51/64 loss: 1.727175235748291
Batch 52/64 loss: 1.7228039503097534
Batch 53/64 loss: 1.7296855449676514
Batch 54/64 loss: 1.7255043983459473
Batch 55/64 loss: 1.723724603652954
Batch 56/64 loss: 1.7230908870697021
Batch 57/64 loss: 1.7224832773208618
Batch 58/64 loss: 1.7241547107696533
Batch 59/64 loss: 1.7252635955810547
Batch 60/64 loss: 1.7257320880889893
Batch 61/64 loss: 1.7228021621704102
Batch 62/64 loss: 1.745086669921875
Batch 63/64 loss: 1.7239949703216553
Batch 64/64 loss: 1.899218201637268
Epoch 490  Train loss: 1.7282059907913208  Val loss: 1.7402499664280422
Epoch 491
-------------------------------
Batch 1/64 loss: 1.7262897491455078
Batch 2/64 loss: 1.7231248617172241
Batch 3/64 loss: 1.7232580184936523
Batch 4/64 loss: 1.7220818996429443
Batch 5/64 loss: 1.7302069664001465
Batch 6/64 loss: 1.7217639684677124
Batch 7/64 loss: 1.7254137992858887
Batch 8/64 loss: 1.7383246421813965
Batch 9/64 loss: 1.7283952236175537
Batch 10/64 loss: 1.7288649082183838
Batch 11/64 loss: 1.7259174585342407
Batch 12/64 loss: 1.7255663871765137
Batch 13/64 loss: 1.7254319190979004
Batch 14/64 loss: 1.7328397035598755
Batch 15/64 loss: 1.7252943515777588
Batch 16/64 loss: 1.7234888076782227
Batch 17/64 loss: 1.7244139909744263
Batch 18/64 loss: 1.724442720413208
Batch 19/64 loss: 1.7242038249969482
Batch 20/64 loss: 1.7233161926269531
Batch 21/64 loss: 1.7262718677520752
Batch 22/64 loss: 1.725213885307312
Batch 23/64 loss: 1.7242732048034668
Batch 24/64 loss: 1.7277569770812988
Batch 25/64 loss: 1.7364614009857178
Batch 26/64 loss: 1.7246133089065552
Batch 27/64 loss: 1.7434883117675781
Batch 28/64 loss: 1.72322416305542
Batch 29/64 loss: 1.7229443788528442
Batch 30/64 loss: 1.7231389284133911
Batch 31/64 loss: 1.7254605293273926
Batch 32/64 loss: 1.7232301235198975
Batch 33/64 loss: 1.7221887111663818
Batch 34/64 loss: 1.7244406938552856
Batch 35/64 loss: 1.723605990409851
Batch 36/64 loss: 1.7228469848632812
Batch 37/64 loss: 1.722491979598999
Batch 38/64 loss: 1.7221715450286865
Batch 39/64 loss: 1.7265985012054443
Batch 40/64 loss: 1.72468900680542
Batch 41/64 loss: 1.724074363708496
Batch 42/64 loss: 1.7223354578018188
Batch 43/64 loss: 1.7248672246932983
Batch 44/64 loss: 1.723687767982483
Batch 45/64 loss: 1.7273355722427368
Batch 46/64 loss: 1.7242510318756104
Batch 47/64 loss: 1.7249000072479248
Batch 48/64 loss: 1.7225964069366455
Batch 49/64 loss: 1.7258391380310059
Batch 50/64 loss: 1.72466242313385
Batch 51/64 loss: 1.7241947650909424
Batch 52/64 loss: 1.723634958267212
Batch 53/64 loss: 1.7223572731018066
Batch 54/64 loss: 1.7223117351531982
Batch 55/64 loss: 1.722851037979126
Batch 56/64 loss: 1.7271945476531982
Batch 57/64 loss: 1.7239229679107666
Batch 58/64 loss: 1.723247766494751
Batch 59/64 loss: 1.7210893630981445
Batch 60/64 loss: 1.7234830856323242
Batch 61/64 loss: 1.7225700616836548
Batch 62/64 loss: 1.7310490608215332
Batch 63/64 loss: 1.7212227582931519
Batch 64/64 loss: 1.9034065008163452
Epoch 491  Train loss: 1.727356604501313  Val loss: 1.741017462052021
Epoch 492
-------------------------------
Batch 1/64 loss: 1.7203278541564941
Batch 2/64 loss: 1.7223409414291382
Batch 3/64 loss: 1.7241921424865723
Batch 4/64 loss: 1.7207272052764893
Batch 5/64 loss: 1.7210876941680908
Batch 6/64 loss: 1.7234288454055786
Batch 7/64 loss: 1.720024824142456
Batch 8/64 loss: 1.7215824127197266
Batch 9/64 loss: 1.7221719026565552
Batch 10/64 loss: 1.7211263179779053
Batch 11/64 loss: 1.7262462377548218
Batch 12/64 loss: 1.7226719856262207
Batch 13/64 loss: 1.7219853401184082
Batch 14/64 loss: 1.721030831336975
Batch 15/64 loss: 1.7254998683929443
Batch 16/64 loss: 1.725087285041809
Batch 17/64 loss: 1.7371406555175781
Batch 18/64 loss: 1.7221225500106812
Batch 19/64 loss: 1.721721887588501
Batch 20/64 loss: 1.7208961248397827
Batch 21/64 loss: 1.7214829921722412
Batch 22/64 loss: 1.7213491201400757
Batch 23/64 loss: 1.7243287563323975
Batch 24/64 loss: 1.7236578464508057
Batch 25/64 loss: 1.7210026979446411
Batch 26/64 loss: 1.7259900569915771
Batch 27/64 loss: 1.7222033739089966
Batch 28/64 loss: 1.7233318090438843
Batch 29/64 loss: 1.7256927490234375
Batch 30/64 loss: 1.7204936742782593
Batch 31/64 loss: 1.722899317741394
Batch 32/64 loss: 1.719458818435669
Batch 33/64 loss: 1.7246737480163574
Batch 34/64 loss: 1.7258843183517456
Batch 35/64 loss: 1.72174072265625
Batch 36/64 loss: 1.724571943283081
Batch 37/64 loss: 1.720632791519165
Batch 38/64 loss: 1.7395656108856201
Batch 39/64 loss: 1.723819613456726
Batch 40/64 loss: 1.7301056385040283
Batch 41/64 loss: 1.722379446029663
Batch 42/64 loss: 1.7244181632995605
Batch 43/64 loss: 1.7237509489059448
Batch 44/64 loss: 1.7279208898544312
Batch 45/64 loss: 1.720780611038208
Batch 46/64 loss: 1.734977126121521
Batch 47/64 loss: 1.7213478088378906
Batch 48/64 loss: 1.7236316204071045
Batch 49/64 loss: 1.724846363067627
Batch 50/64 loss: 1.7253652811050415
Batch 51/64 loss: 1.7223820686340332
Batch 52/64 loss: 1.724352478981018
Batch 53/64 loss: 1.7412457466125488
Batch 54/64 loss: 1.7251948118209839
Batch 55/64 loss: 1.7261035442352295
Batch 56/64 loss: 1.7239185571670532
Batch 57/64 loss: 1.722937822341919
Batch 58/64 loss: 1.7267653942108154
Batch 59/64 loss: 1.7225909233093262
Batch 60/64 loss: 1.723392367362976
Batch 61/64 loss: 1.723785400390625
Batch 62/64 loss: 1.7259501218795776
Batch 63/64 loss: 1.7227377891540527
Batch 64/64 loss: 1.9015843868255615
Epoch 492  Train loss: 1.7262943071477554  Val loss: 1.7419806952329027
Epoch 493
-------------------------------
Batch 1/64 loss: 1.7210967540740967
Batch 2/64 loss: 1.7409389019012451
Batch 3/64 loss: 1.7258131504058838
Batch 4/64 loss: 1.7233595848083496
Batch 5/64 loss: 1.7225929498672485
Batch 6/64 loss: 1.7240111827850342
Batch 7/64 loss: 1.7388701438903809
Batch 8/64 loss: 1.72230863571167
Batch 9/64 loss: 1.7242790460586548
Batch 10/64 loss: 1.7276277542114258
Batch 11/64 loss: 1.7220206260681152
Batch 12/64 loss: 1.7222208976745605
Batch 13/64 loss: 1.7218759059906006
Batch 14/64 loss: 1.7192044258117676
Batch 15/64 loss: 1.72532057762146
Batch 16/64 loss: 1.722867727279663
Batch 17/64 loss: 1.72361159324646
Batch 18/64 loss: 1.7235667705535889
Batch 19/64 loss: 1.7232367992401123
Batch 20/64 loss: 1.7247474193572998
Batch 21/64 loss: 1.7245008945465088
Batch 22/64 loss: 1.7306275367736816
Batch 23/64 loss: 1.7241958379745483
Batch 24/64 loss: 1.7265074253082275
Batch 25/64 loss: 1.7366104125976562
Batch 26/64 loss: 1.721143126487732
Batch 27/64 loss: 1.7228362560272217
Batch 28/64 loss: 1.7227859497070312
Batch 29/64 loss: 1.7231738567352295
Batch 30/64 loss: 1.7257286310195923
Batch 31/64 loss: 1.7271513938903809
Batch 32/64 loss: 1.7241079807281494
Batch 33/64 loss: 1.727135419845581
Batch 34/64 loss: 1.7223039865493774
Batch 35/64 loss: 1.7232643365859985
Batch 36/64 loss: 1.723267912864685
Batch 37/64 loss: 1.7222414016723633
Batch 38/64 loss: 1.720705270767212
Batch 39/64 loss: 1.7273691892623901
Batch 40/64 loss: 1.7232866287231445
Batch 41/64 loss: 1.725921869277954
Batch 42/64 loss: 1.7225358486175537
Batch 43/64 loss: 1.7246228456497192
Batch 44/64 loss: 1.724319338798523
Batch 45/64 loss: 1.7343477010726929
Batch 46/64 loss: 1.7222328186035156
Batch 47/64 loss: 1.7238702774047852
Batch 48/64 loss: 1.7246040105819702
Batch 49/64 loss: 1.7215516567230225
Batch 50/64 loss: 1.7264130115509033
Batch 51/64 loss: 1.721651315689087
Batch 52/64 loss: 1.72239089012146
Batch 53/64 loss: 1.7226219177246094
Batch 54/64 loss: 1.7221112251281738
Batch 55/64 loss: 1.723954677581787
Batch 56/64 loss: 1.7286138534545898
Batch 57/64 loss: 1.719653606414795
Batch 58/64 loss: 1.7272695302963257
Batch 59/64 loss: 1.7222535610198975
Batch 60/64 loss: 1.7277207374572754
Batch 61/64 loss: 1.7222397327423096
Batch 62/64 loss: 1.7215955257415771
Batch 63/64 loss: 1.7220797538757324
Batch 64/64 loss: 1.8997273445129395
Epoch 493  Train loss: 1.726711929545683  Val loss: 1.7407711207661842
Epoch 494
-------------------------------
Batch 1/64 loss: 1.7226488590240479
Batch 2/64 loss: 1.7349036931991577
Batch 3/64 loss: 1.720808982849121
Batch 4/64 loss: 1.7213640213012695
Batch 5/64 loss: 1.7226319313049316
Batch 6/64 loss: 1.719191551208496
Batch 7/64 loss: 1.72440505027771
Batch 8/64 loss: 1.7246192693710327
Batch 9/64 loss: 1.7238682508468628
Batch 10/64 loss: 1.7242194414138794
Batch 11/64 loss: 1.7216414213180542
Batch 12/64 loss: 1.7246830463409424
Batch 13/64 loss: 1.7219486236572266
Batch 14/64 loss: 1.7317416667938232
Batch 15/64 loss: 1.7250405550003052
Batch 16/64 loss: 1.7238574028015137
Batch 17/64 loss: 1.7241628170013428
Batch 18/64 loss: 1.7216575145721436
Batch 19/64 loss: 1.7229182720184326
Batch 20/64 loss: 1.7255656719207764
Batch 21/64 loss: 1.7210588455200195
Batch 22/64 loss: 1.7244250774383545
Batch 23/64 loss: 1.720179557800293
Batch 24/64 loss: 1.7209515571594238
Batch 25/64 loss: 1.7258892059326172
Batch 26/64 loss: 1.722301721572876
Batch 27/64 loss: 1.7390908002853394
Batch 28/64 loss: 1.7274597883224487
Batch 29/64 loss: 1.7202105522155762
Batch 30/64 loss: 1.7247378826141357
Batch 31/64 loss: 1.7227979898452759
Batch 32/64 loss: 1.7283408641815186
Batch 33/64 loss: 1.7235091924667358
Batch 34/64 loss: 1.722465991973877
Batch 35/64 loss: 1.7244240045547485
Batch 36/64 loss: 1.7236542701721191
Batch 37/64 loss: 1.725733995437622
Batch 38/64 loss: 1.7211692333221436
Batch 39/64 loss: 1.7230162620544434
Batch 40/64 loss: 1.7212178707122803
Batch 41/64 loss: 1.7213799953460693
Batch 42/64 loss: 1.724442720413208
Batch 43/64 loss: 1.7222323417663574
Batch 44/64 loss: 1.7204172611236572
Batch 45/64 loss: 1.7244343757629395
Batch 46/64 loss: 1.7207473516464233
Batch 47/64 loss: 1.7240345478057861
Batch 48/64 loss: 1.7223494052886963
Batch 49/64 loss: 1.7211971282958984
Batch 50/64 loss: 1.7249653339385986
Batch 51/64 loss: 1.7253797054290771
Batch 52/64 loss: 1.7236104011535645
Batch 53/64 loss: 1.7411171197891235
Batch 54/64 loss: 1.7217094898223877
Batch 55/64 loss: 1.7344064712524414
Batch 56/64 loss: 1.7220423221588135
Batch 57/64 loss: 1.7275056838989258
Batch 58/64 loss: 1.7254347801208496
Batch 59/64 loss: 1.722598910331726
Batch 60/64 loss: 1.7201812267303467
Batch 61/64 loss: 1.726209282875061
Batch 62/64 loss: 1.721102237701416
Batch 63/64 loss: 1.7273590564727783
Batch 64/64 loss: 1.8984441757202148
Epoch 494  Train loss: 1.7263247527328192  Val loss: 1.7397639464676584
Epoch 495
-------------------------------
Batch 1/64 loss: 1.7241426706314087
Batch 2/64 loss: 1.7247116565704346
Batch 3/64 loss: 1.7405104637145996
Batch 4/64 loss: 1.7221858501434326
Batch 5/64 loss: 1.7235298156738281
Batch 6/64 loss: 1.7258896827697754
Batch 7/64 loss: 1.7225732803344727
Batch 8/64 loss: 1.7230808734893799
Batch 9/64 loss: 1.7250561714172363
Batch 10/64 loss: 1.724714756011963
Batch 11/64 loss: 1.7235050201416016
Batch 12/64 loss: 1.7232863903045654
Batch 13/64 loss: 1.727545976638794
Batch 14/64 loss: 1.7304565906524658
Batch 15/64 loss: 1.7297990322113037
Batch 16/64 loss: 1.7273447513580322
Batch 17/64 loss: 1.7224056720733643
Batch 18/64 loss: 1.727764368057251
Batch 19/64 loss: 1.7240660190582275
Batch 20/64 loss: 1.7258129119873047
Batch 21/64 loss: 1.7228543758392334
Batch 22/64 loss: 1.721912145614624
Batch 23/64 loss: 1.7289583683013916
Batch 24/64 loss: 1.7270548343658447
Batch 25/64 loss: 1.7218607664108276
Batch 26/64 loss: 1.7239350080490112
Batch 27/64 loss: 1.7221554517745972
Batch 28/64 loss: 1.7223742008209229
Batch 29/64 loss: 1.7207053899765015
Batch 30/64 loss: 1.724519968032837
Batch 31/64 loss: 1.723454475402832
Batch 32/64 loss: 1.721726655960083
Batch 33/64 loss: 1.7232964038848877
Batch 34/64 loss: 1.7291573286056519
Batch 35/64 loss: 1.7218329906463623
Batch 36/64 loss: 1.7235419750213623
Batch 37/64 loss: 1.7237637042999268
Batch 38/64 loss: 1.7236520051956177
Batch 39/64 loss: 1.721903681755066
Batch 40/64 loss: 1.7280946969985962
Batch 41/64 loss: 1.7250182628631592
Batch 42/64 loss: 1.7236511707305908
Batch 43/64 loss: 1.722242832183838
Batch 44/64 loss: 1.7214117050170898
Batch 45/64 loss: 1.7275934219360352
Batch 46/64 loss: 1.724881887435913
Batch 47/64 loss: 1.7217769622802734
Batch 48/64 loss: 1.7203569412231445
Batch 49/64 loss: 1.7241394519805908
Batch 50/64 loss: 1.7238738536834717
Batch 51/64 loss: 1.7236557006835938
Batch 52/64 loss: 1.7341077327728271
Batch 53/64 loss: 1.7234089374542236
Batch 54/64 loss: 1.7213842868804932
Batch 55/64 loss: 1.723203182220459
Batch 56/64 loss: 1.7339723110198975
Batch 57/64 loss: 1.7314648628234863
Batch 58/64 loss: 1.7237690687179565
Batch 59/64 loss: 1.7251155376434326
Batch 60/64 loss: 1.723347544670105
Batch 61/64 loss: 1.721928358078003
Batch 62/64 loss: 1.7215681076049805
Batch 63/64 loss: 1.7205206155776978
Batch 64/64 loss: 1.9010264873504639
Epoch 495  Train loss: 1.7267968467637604  Val loss: 1.7416722258341681
Epoch 496
-------------------------------
Batch 1/64 loss: 1.7267173528671265
Batch 2/64 loss: 1.723331093788147
Batch 3/64 loss: 1.7246397733688354
Batch 4/64 loss: 1.7238590717315674
Batch 5/64 loss: 1.7236566543579102
Batch 6/64 loss: 1.7211380004882812
Batch 7/64 loss: 1.7216780185699463
Batch 8/64 loss: 1.722605586051941
Batch 9/64 loss: 1.723780870437622
Batch 10/64 loss: 1.723116159439087
Batch 11/64 loss: 1.7262362241744995
Batch 12/64 loss: 1.7250146865844727
Batch 13/64 loss: 1.7222334146499634
Batch 14/64 loss: 1.7244884967803955
Batch 15/64 loss: 1.7249774932861328
Batch 16/64 loss: 1.7246263027191162
Batch 17/64 loss: 1.7227729558944702
Batch 18/64 loss: 1.728360652923584
Batch 19/64 loss: 1.722712755203247
Batch 20/64 loss: 1.7283098697662354
Batch 21/64 loss: 1.728362798690796
Batch 22/64 loss: 1.7266217470169067
Batch 23/64 loss: 1.7281465530395508
Batch 24/64 loss: 1.7229819297790527
Batch 25/64 loss: 1.7281379699707031
Batch 26/64 loss: 1.7286710739135742
Batch 27/64 loss: 1.7225788831710815
Batch 28/64 loss: 1.728135108947754
Batch 29/64 loss: 1.725311279296875
Batch 30/64 loss: 1.739603042602539
Batch 31/64 loss: 1.724302053451538
Batch 32/64 loss: 1.729398488998413
Batch 33/64 loss: 1.7234362363815308
Batch 34/64 loss: 1.7239105701446533
Batch 35/64 loss: 1.7353914976119995
Batch 36/64 loss: 1.7300748825073242
Batch 37/64 loss: 1.7247065305709839
Batch 38/64 loss: 1.7267897129058838
Batch 39/64 loss: 1.726428508758545
Batch 40/64 loss: 1.7231085300445557
Batch 41/64 loss: 1.727125883102417
Batch 42/64 loss: 1.7272424697875977
Batch 43/64 loss: 1.744358777999878
Batch 44/64 loss: 1.726021647453308
Batch 45/64 loss: 1.7302405834197998
Batch 46/64 loss: 1.7293471097946167
Batch 47/64 loss: 1.7274705171585083
Batch 48/64 loss: 1.728968620300293
Batch 49/64 loss: 1.7430531978607178
Batch 50/64 loss: 1.7292699813842773
Batch 51/64 loss: 1.7253336906433105
Batch 52/64 loss: 1.7324022054672241
Batch 53/64 loss: 1.7223631143569946
Batch 54/64 loss: 1.7290095090866089
Batch 55/64 loss: 1.7230172157287598
Batch 56/64 loss: 1.7284045219421387
Batch 57/64 loss: 1.7262790203094482
Batch 58/64 loss: 1.7259244918823242
Batch 59/64 loss: 1.7310831546783447
Batch 60/64 loss: 1.7285919189453125
Batch 61/64 loss: 1.7262024879455566
Batch 62/64 loss: 1.722759485244751
Batch 63/64 loss: 1.720837116241455
Batch 64/64 loss: 1.9079697132110596
Epoch 496  Train loss: 1.7288884209651574  Val loss: 1.7431759277160226
Epoch 497
-------------------------------
Batch 1/64 loss: 1.7296723127365112
Batch 2/64 loss: 1.7236158847808838
Batch 3/64 loss: 1.741768717765808
Batch 4/64 loss: 1.7246125936508179
Batch 5/64 loss: 1.7270288467407227
Batch 6/64 loss: 1.7224206924438477
Batch 7/64 loss: 1.725701093673706
Batch 8/64 loss: 1.7248022556304932
Batch 9/64 loss: 1.7212260961532593
Batch 10/64 loss: 1.7291905879974365
Batch 11/64 loss: 1.727630853652954
Batch 12/64 loss: 1.7283074855804443
Batch 13/64 loss: 1.7308214902877808
Batch 14/64 loss: 1.724952220916748
Batch 15/64 loss: 1.7287585735321045
Batch 16/64 loss: 1.7252213954925537
Batch 17/64 loss: 1.7339792251586914
Batch 18/64 loss: 1.7305889129638672
Batch 19/64 loss: 1.7224469184875488
Batch 20/64 loss: 1.7274057865142822
Batch 21/64 loss: 1.7249531745910645
Batch 22/64 loss: 1.7245287895202637
Batch 23/64 loss: 1.7323507070541382
Batch 24/64 loss: 1.7287300825119019
Batch 25/64 loss: 1.7356882095336914
Batch 26/64 loss: 1.7272436618804932
Batch 27/64 loss: 1.7273728847503662
Batch 28/64 loss: 1.7227545976638794
Batch 29/64 loss: 1.7242271900177002
Batch 30/64 loss: 1.7235758304595947
Batch 31/64 loss: 1.725137710571289
Batch 32/64 loss: 1.7235711812973022
Batch 33/64 loss: 1.737595558166504
Batch 34/64 loss: 1.7274689674377441
Batch 35/64 loss: 1.7239288091659546
Batch 36/64 loss: 1.7264957427978516
Batch 37/64 loss: 1.7217456102371216
Batch 38/64 loss: 1.7262639999389648
Batch 39/64 loss: 1.724677324295044
Batch 40/64 loss: 1.7222950458526611
Batch 41/64 loss: 1.7294199466705322
Batch 42/64 loss: 1.7253201007843018
Batch 43/64 loss: 1.7264293432235718
Batch 44/64 loss: 1.7265543937683105
Batch 45/64 loss: 1.7226834297180176
Batch 46/64 loss: 1.7250148057937622
Batch 47/64 loss: 1.7260198593139648
Batch 48/64 loss: 1.7259042263031006
Batch 49/64 loss: 1.7253656387329102
Batch 50/64 loss: 1.7262506484985352
Batch 51/64 loss: 1.7221744060516357
Batch 52/64 loss: 1.7221404314041138
Batch 53/64 loss: 1.7434771060943604
Batch 54/64 loss: 1.7216585874557495
Batch 55/64 loss: 1.723505973815918
Batch 56/64 loss: 1.7264769077301025
Batch 57/64 loss: 1.7217117547988892
Batch 58/64 loss: 1.72340989112854
Batch 59/64 loss: 1.7221813201904297
Batch 60/64 loss: 1.724088191986084
Batch 61/64 loss: 1.7226331233978271
Batch 62/64 loss: 1.7231590747833252
Batch 63/64 loss: 1.7235429286956787
Batch 64/64 loss: 1.8962795734405518
Epoch 497  Train loss: 1.7283464908599853  Val loss: 1.741285024230013
Epoch 498
-------------------------------
Batch 1/64 loss: 1.7233551740646362
Batch 2/64 loss: 1.7259657382965088
Batch 3/64 loss: 1.7244091033935547
Batch 4/64 loss: 1.7225600481033325
Batch 5/64 loss: 1.725753903388977
Batch 6/64 loss: 1.7229444980621338
Batch 7/64 loss: 1.7249560356140137
Batch 8/64 loss: 1.7349430322647095
Batch 9/64 loss: 1.7243849039077759
Batch 10/64 loss: 1.7323981523513794
Batch 11/64 loss: 1.7208943367004395
Batch 12/64 loss: 1.7226786613464355
Batch 13/64 loss: 1.7223107814788818
Batch 14/64 loss: 1.7265701293945312
Batch 15/64 loss: 1.7235692739486694
Batch 16/64 loss: 1.7234365940093994
Batch 17/64 loss: 1.7313729524612427
Batch 18/64 loss: 1.7445619106292725
Batch 19/64 loss: 1.7234196662902832
Batch 20/64 loss: 1.7248200178146362
Batch 21/64 loss: 1.7186493873596191
Batch 22/64 loss: 1.7323600053787231
Batch 23/64 loss: 1.7235335111618042
Batch 24/64 loss: 1.7270158529281616
Batch 25/64 loss: 1.7242050170898438
Batch 26/64 loss: 1.7250232696533203
Batch 27/64 loss: 1.723703384399414
Batch 28/64 loss: 1.7223137617111206
Batch 29/64 loss: 1.7228283882141113
Batch 30/64 loss: 1.725167989730835
Batch 31/64 loss: 1.726067066192627
Batch 32/64 loss: 1.7237083911895752
Batch 33/64 loss: 1.7332030534744263
Batch 34/64 loss: 1.7241015434265137
Batch 35/64 loss: 1.7249839305877686
Batch 36/64 loss: 1.7390304803848267
Batch 37/64 loss: 1.7305939197540283
Batch 38/64 loss: 1.7299169301986694
Batch 39/64 loss: 1.7248139381408691
Batch 40/64 loss: 1.7244880199432373
Batch 41/64 loss: 1.7270374298095703
Batch 42/64 loss: 1.7227332592010498
Batch 43/64 loss: 1.7286256551742554
Batch 44/64 loss: 1.7248671054840088
Batch 45/64 loss: 1.7263591289520264
Batch 46/64 loss: 1.7239391803741455
Batch 47/64 loss: 1.7269763946533203
Batch 48/64 loss: 1.7258360385894775
Batch 49/64 loss: 1.7270104885101318
Batch 50/64 loss: 1.7265160083770752
Batch 51/64 loss: 1.725109577178955
Batch 52/64 loss: 1.736626148223877
Batch 53/64 loss: 1.7203173637390137
Batch 54/64 loss: 1.723877191543579
Batch 55/64 loss: 1.7280024290084839
Batch 56/64 loss: 1.7247955799102783
Batch 57/64 loss: 1.7251548767089844
Batch 58/64 loss: 1.7217885255813599
Batch 59/64 loss: 1.725822925567627
Batch 60/64 loss: 1.7233710289001465
Batch 61/64 loss: 1.722316861152649
Batch 62/64 loss: 1.7231295108795166
Batch 63/64 loss: 1.72359299659729
Batch 64/64 loss: 1.9020702838897705
Epoch 498  Train loss: 1.7280215085721484  Val loss: 1.744813391433139
Epoch 499
-------------------------------
Batch 1/64 loss: 1.7240831851959229
Batch 2/64 loss: 1.7349094152450562
Batch 3/64 loss: 1.72389554977417
Batch 4/64 loss: 1.7230793237686157
Batch 5/64 loss: 1.7229392528533936
Batch 6/64 loss: 1.7268600463867188
Batch 7/64 loss: 1.729846477508545
Batch 8/64 loss: 1.7264020442962646
Batch 9/64 loss: 1.7282748222351074
Batch 10/64 loss: 1.726550817489624
Batch 11/64 loss: 1.7264803647994995
Batch 12/64 loss: 1.725358486175537
Batch 13/64 loss: 1.7256020307540894
Batch 14/64 loss: 1.7249140739440918
Batch 15/64 loss: 1.7237751483917236
Batch 16/64 loss: 1.7255463600158691
Batch 17/64 loss: 1.727607011795044
Batch 18/64 loss: 1.7241411209106445
Batch 19/64 loss: 1.724962592124939
Batch 20/64 loss: 1.7215397357940674
Batch 21/64 loss: 1.7217053174972534
Batch 22/64 loss: 1.7438933849334717
Batch 23/64 loss: 1.7246208190917969
Batch 24/64 loss: 1.734979510307312
Batch 25/64 loss: 1.723006248474121
Batch 26/64 loss: 1.7298294305801392
Batch 27/64 loss: 1.7228574752807617
Batch 28/64 loss: 1.7269678115844727
Batch 29/64 loss: 1.7210698127746582
Batch 30/64 loss: 1.7214438915252686
Batch 31/64 loss: 1.72255277633667
Batch 32/64 loss: 1.7212731838226318
Batch 33/64 loss: 1.7264881134033203
Batch 34/64 loss: 1.7268364429473877
Batch 35/64 loss: 1.7241036891937256
Batch 36/64 loss: 1.7209076881408691
Batch 37/64 loss: 1.7246630191802979
Batch 38/64 loss: 1.7228736877441406
Batch 39/64 loss: 1.7269563674926758
Batch 40/64 loss: 1.7257685661315918
Batch 41/64 loss: 1.7288603782653809
Batch 42/64 loss: 1.7236219644546509
Batch 43/64 loss: 1.7237117290496826
Batch 44/64 loss: 1.724652886390686
Batch 45/64 loss: 1.7220678329467773
Batch 46/64 loss: 1.7231080532073975
Batch 47/64 loss: 1.7215461730957031
Batch 48/64 loss: 1.7249243259429932
Batch 49/64 loss: 1.7327606678009033
Batch 50/64 loss: 1.7232197523117065
Batch 51/64 loss: 1.7235857248306274
Batch 52/64 loss: 1.7246525287628174
Batch 53/64 loss: 1.7229080200195312
Batch 54/64 loss: 1.7248058319091797
Batch 55/64 loss: 1.7246873378753662
Batch 56/64 loss: 1.7226200103759766
Batch 57/64 loss: 1.7224189043045044
Batch 58/64 loss: 1.7224340438842773
Batch 59/64 loss: 1.7230103015899658
Batch 60/64 loss: 1.7234715223312378
Batch 61/64 loss: 1.7246006727218628
Batch 62/64 loss: 1.7244210243225098
Batch 63/64 loss: 1.7274866104125977
Batch 64/64 loss: 1.9064545631408691
Epoch 499  Train loss: 1.7273565853343291  Val loss: 1.740173823235371
Epoch 500
-------------------------------
Batch 1/64 loss: 1.725477933883667
Batch 2/64 loss: 1.7238444089889526
Batch 3/64 loss: 1.72605299949646
Batch 4/64 loss: 1.7234219312667847
Batch 5/64 loss: 1.7243623733520508
Batch 6/64 loss: 1.725445032119751
Batch 7/64 loss: 1.7285563945770264
Batch 8/64 loss: 1.7269444465637207
Batch 9/64 loss: 1.729499340057373
Batch 10/64 loss: 1.7243595123291016
Batch 11/64 loss: 1.7271063327789307
Batch 12/64 loss: 1.7217204570770264
Batch 13/64 loss: 1.7258336544036865
Batch 14/64 loss: 1.7229630947113037
Batch 15/64 loss: 1.726736307144165
Batch 16/64 loss: 1.725534439086914
Batch 17/64 loss: 1.7253825664520264
Batch 18/64 loss: 1.723511815071106
Batch 19/64 loss: 1.7412830591201782
Batch 20/64 loss: 1.723928451538086
Batch 21/64 loss: 1.7269799709320068
Batch 22/64 loss: 1.7240214347839355
Batch 23/64 loss: 1.7233364582061768
Batch 24/64 loss: 1.7233326435089111
Batch 25/64 loss: 1.7264935970306396
Batch 26/64 loss: 1.722461223602295
Batch 27/64 loss: 1.7253975868225098
Batch 28/64 loss: 1.7230587005615234
Batch 29/64 loss: 1.7253565788269043
Batch 30/64 loss: 1.7233755588531494
Batch 31/64 loss: 1.72516667842865
Batch 32/64 loss: 1.724003791809082
Batch 33/64 loss: 1.7272592782974243
Batch 34/64 loss: 1.728675365447998
Batch 35/64 loss: 1.7213728427886963
Batch 36/64 loss: 1.726102590560913
Batch 37/64 loss: 1.7217803001403809
Batch 38/64 loss: 1.724853277206421
Batch 39/64 loss: 1.7222819328308105
Batch 40/64 loss: 1.7228624820709229
Batch 41/64 loss: 1.7201848030090332
Batch 42/64 loss: 1.7226293087005615
Batch 43/64 loss: 1.7220388650894165
Batch 44/64 loss: 1.7239878177642822
Batch 45/64 loss: 1.7218573093414307
Batch 46/64 loss: 1.7365965843200684
Batch 47/64 loss: 1.7217469215393066
Batch 48/64 loss: 1.723336100578308
Batch 49/64 loss: 1.7236058712005615
Batch 50/64 loss: 1.721463918685913
Batch 51/64 loss: 1.7262712717056274
Batch 52/64 loss: 1.7264214754104614
Batch 53/64 loss: 1.725493311882019
Batch 54/64 loss: 1.7216804027557373
Batch 55/64 loss: 1.736236333847046
Batch 56/64 loss: 1.7209093570709229
Batch 57/64 loss: 1.7235240936279297
Batch 58/64 loss: 1.726083755493164
Batch 59/64 loss: 1.7263245582580566
Batch 60/64 loss: 1.7241506576538086
Batch 61/64 loss: 1.7294957637786865
Batch 62/64 loss: 1.7230769395828247
Batch 63/64 loss: 1.7242929935455322
Batch 64/64 loss: 1.9025781154632568
Epoch 500  Train loss: 1.7271918250065224  Val loss: 1.7450763277991121
SLIC undersegmentation error: 0.12412920962199316
SLIC inter-cluster variation: 0.13904419774313004
SLIC number of superpixels: 21483
SLIC superpixels per image: 73.82474226804123
Model loaded
Test metrics:
1.7484631489232643 0.4852096219931271 56.95769779834831 tensor(0.9053, dtype=torch.float64) 1.0 58.642826460481096 4656
Inference time: 0.003650869290853284 seconds
Relabeled undersegmentation error: 0.06548865979381441
Relabeled inter-cluster variation: 0.011292668505208598
Relabeled mean superpixels count: 938.2233676975945
Original mean superpixels count: 16.0
Done!
Job id: 488308
