Started preprocessing dataset
Number of training samples: 2040
Number of validation samples: 582
Number of testing samples: 291
Using cuda device
Epoch 1
-------------------------------
Batch 1/64 loss: 4.637779235839844
Batch 2/64 loss: 4.672276020050049
Batch 3/64 loss: 4.624330043792725
Batch 4/64 loss: 4.618496894836426
Batch 5/64 loss: 4.61434268951416
Batch 6/64 loss: 4.612131595611572
Batch 7/64 loss: 4.600951194763184
Batch 8/64 loss: 4.596563339233398
Batch 9/64 loss: 4.591557502746582
Batch 10/64 loss: 4.590556621551514
Batch 11/64 loss: 4.589426517486572
Batch 12/64 loss: 4.586727142333984
Batch 13/64 loss: 4.585679054260254
Batch 14/64 loss: 4.586019515991211
Batch 15/64 loss: 4.584025859832764
Batch 16/64 loss: 4.581164360046387
Batch 17/64 loss: 4.581454753875732
Batch 18/64 loss: 4.581049919128418
Batch 19/64 loss: 4.582937240600586
Batch 20/64 loss: 4.579637050628662
Batch 21/64 loss: 4.580719947814941
Batch 22/64 loss: 4.578918933868408
Batch 23/64 loss: 4.57968282699585
Batch 24/64 loss: 4.580296039581299
Batch 25/64 loss: 4.5795135498046875
Batch 26/64 loss: 4.577944755554199
Batch 27/64 loss: 4.579699516296387
Batch 28/64 loss: 4.577085971832275
Batch 29/64 loss: 4.577968120574951
Batch 30/64 loss: 4.577672481536865
Batch 31/64 loss: 4.577088356018066
Batch 32/64 loss: 4.57724666595459
Batch 33/64 loss: 4.575831413269043
Batch 34/64 loss: 4.57616662979126
Batch 35/64 loss: 4.575094223022461
Batch 36/64 loss: 4.575213432312012
Batch 37/64 loss: 4.576592922210693
Batch 38/64 loss: 4.576870441436768
Batch 39/64 loss: 4.573224067687988
Batch 40/64 loss: 4.572925090789795
Batch 41/64 loss: 4.573793411254883
Batch 42/64 loss: 4.572304725646973
Batch 43/64 loss: 4.576354026794434
Batch 44/64 loss: 4.573074817657471
Batch 45/64 loss: 4.570711135864258
Batch 46/64 loss: 4.569821834564209
Batch 47/64 loss: 4.56867790222168
Batch 48/64 loss: 4.570133209228516
Batch 49/64 loss: 4.56840181350708
Batch 50/64 loss: 4.567941665649414
Batch 51/64 loss: 4.570438861846924
Batch 52/64 loss: 4.566308498382568
Batch 53/64 loss: 4.564784526824951
Batch 54/64 loss: 4.566812038421631
Batch 55/64 loss: 4.560546398162842
Batch 56/64 loss: 4.560330867767334
Batch 57/64 loss: 4.561219692230225
Batch 58/64 loss: 4.55495023727417
Batch 59/64 loss: 4.554152488708496
Batch 60/64 loss: 4.55302095413208
Batch 61/64 loss: 4.555099010467529
Batch 62/64 loss: 4.550118923187256
Batch 63/64 loss: 4.549919605255127
Batch 64/64 loss: 3.73020339012146
Epoch 1  Train loss: 4.5697165666842  Val loss: 4.54308886298609
Saving best model, epoch: 1
Epoch 2
-------------------------------
Batch 1/64 loss: 4.5426201820373535
Batch 2/64 loss: 4.5335917472839355
Batch 3/64 loss: 4.533555507659912
Batch 4/64 loss: 4.5384063720703125
Batch 5/64 loss: 4.541589736938477
Batch 6/64 loss: 4.5357537269592285
Batch 7/64 loss: 4.517678260803223
Batch 8/64 loss: 4.516434192657471
Batch 9/64 loss: 4.53032922744751
Batch 10/64 loss: 4.515845775604248
Batch 11/64 loss: 4.523294448852539
Batch 12/64 loss: 4.507611274719238
Batch 13/64 loss: 4.485729217529297
Batch 14/64 loss: 4.492722034454346
Batch 15/64 loss: 4.492092132568359
Batch 16/64 loss: 4.511373519897461
Batch 17/64 loss: 4.488985538482666
Batch 18/64 loss: 4.49936056137085
Batch 19/64 loss: 4.4811859130859375
Batch 20/64 loss: 4.457183361053467
Batch 21/64 loss: 4.464545249938965
Batch 22/64 loss: 4.4831767082214355
Batch 23/64 loss: 4.438409805297852
Batch 24/64 loss: 4.4079461097717285
Batch 25/64 loss: 4.419578552246094
Batch 26/64 loss: 4.381256103515625
Batch 27/64 loss: 4.388705730438232
Batch 28/64 loss: 4.367528915405273
Batch 29/64 loss: 4.3605523109436035
Batch 30/64 loss: 4.408572196960449
Batch 31/64 loss: 4.531611442565918
Batch 32/64 loss: 4.381862163543701
Batch 33/64 loss: 4.433498859405518
Batch 34/64 loss: 4.4353861808776855
Batch 35/64 loss: 4.454653739929199
Batch 36/64 loss: 4.393793106079102
Batch 37/64 loss: 4.43026065826416
Batch 38/64 loss: 4.366950511932373
Batch 39/64 loss: 4.357754707336426
Batch 40/64 loss: 4.365396022796631
Batch 41/64 loss: 4.352341651916504
Batch 42/64 loss: 4.327763080596924
Batch 43/64 loss: 4.415951728820801
Batch 44/64 loss: 4.395715713500977
Batch 45/64 loss: 4.3566508293151855
Batch 46/64 loss: 4.356557846069336
Batch 47/64 loss: 4.324214935302734
Batch 48/64 loss: 4.309739589691162
Batch 49/64 loss: 4.3883256912231445
Batch 50/64 loss: 4.300827980041504
Batch 51/64 loss: 4.329222679138184
Batch 52/64 loss: 4.293379306793213
Batch 53/64 loss: 4.269324779510498
Batch 54/64 loss: 4.2797369956970215
Batch 55/64 loss: 4.2964372634887695
Batch 56/64 loss: 4.379448413848877
Batch 57/64 loss: 4.231855869293213
Batch 58/64 loss: 4.312142372131348
Batch 59/64 loss: 4.292018890380859
Batch 60/64 loss: 4.207491874694824
Batch 61/64 loss: 4.268836498260498
Batch 62/64 loss: 4.224535942077637
Batch 63/64 loss: 4.175501346588135
Batch 64/64 loss: 3.237562656402588
Epoch 2  Train loss: 4.39267411886477  Val loss: 4.388958058406398
Saving best model, epoch: 2
Epoch 3
-------------------------------
Batch 1/64 loss: 4.24033260345459
Batch 2/64 loss: 4.295444488525391
Batch 3/64 loss: 4.264650344848633
Batch 4/64 loss: 4.208765983581543
Batch 5/64 loss: 4.2299485206604
Batch 6/64 loss: 4.179793357849121
Batch 7/64 loss: 4.192225456237793
Batch 8/64 loss: 4.1579060554504395
Batch 9/64 loss: 4.215281963348389
Batch 10/64 loss: 4.205628395080566
Batch 11/64 loss: 4.15329122543335
Batch 12/64 loss: 4.179083824157715
Batch 13/64 loss: 4.149985313415527
Batch 14/64 loss: 4.080623149871826
Batch 15/64 loss: 4.123521327972412
Batch 16/64 loss: 4.182480335235596
Batch 17/64 loss: 4.188289642333984
Batch 18/64 loss: 4.1126275062561035
Batch 19/64 loss: 4.116048336029053
Batch 20/64 loss: 4.126890182495117
Batch 21/64 loss: 4.107639789581299
Batch 22/64 loss: 4.1609601974487305
Batch 23/64 loss: 4.049700736999512
Batch 24/64 loss: 4.078444004058838
Batch 25/64 loss: 3.9996957778930664
Batch 26/64 loss: 4.202846050262451
Batch 27/64 loss: 4.19209098815918
Batch 28/64 loss: 4.031487941741943
Batch 29/64 loss: 4.376984596252441
Batch 30/64 loss: 4.050107479095459
Batch 31/64 loss: 4.0380964279174805
Batch 32/64 loss: 4.010436534881592
Batch 33/64 loss: 4.085965156555176
Batch 34/64 loss: 3.9919281005859375
Batch 35/64 loss: 3.963202953338623
Batch 36/64 loss: 3.922617197036743
Batch 37/64 loss: 3.9260897636413574
Batch 38/64 loss: 3.931579828262329
Batch 39/64 loss: 3.91819429397583
Batch 40/64 loss: 4.006546974182129
Batch 41/64 loss: 3.977837085723877
Batch 42/64 loss: 3.8661465644836426
Batch 43/64 loss: 4.007132530212402
Batch 44/64 loss: 3.9363913536071777
Batch 45/64 loss: 3.8487839698791504
Batch 46/64 loss: 4.009246349334717
Batch 47/64 loss: 3.862952709197998
Batch 48/64 loss: 3.9302947521209717
Batch 49/64 loss: 3.684511184692383
Batch 50/64 loss: 3.7728934288024902
Batch 51/64 loss: 4.000392913818359
Batch 52/64 loss: 3.807276725769043
Batch 53/64 loss: 3.7535219192504883
Batch 54/64 loss: 3.8344569206237793
Batch 55/64 loss: 3.8695874214172363
Batch 56/64 loss: 3.8811655044555664
Batch 57/64 loss: 3.8677375316619873
Batch 58/64 loss: 3.781433582305908
Batch 59/64 loss: 3.791189193725586
Batch 60/64 loss: 3.7206592559814453
Batch 61/64 loss: 3.810924530029297
Batch 62/64 loss: 4.077115535736084
Batch 63/64 loss: 3.949340343475342
Batch 64/64 loss: 2.4771857261657715
Epoch 3  Train loss: 4.008569622039795  Val loss: 3.869574917141105
Saving best model, epoch: 3
Epoch 4
-------------------------------
Batch 1/64 loss: 3.871084451675415
Batch 2/64 loss: 3.966542959213257
Batch 3/64 loss: 3.7715089321136475
Batch 4/64 loss: 3.659294605255127
Batch 5/64 loss: 3.843173027038574
Batch 6/64 loss: 3.64322566986084
Batch 7/64 loss: 3.7231154441833496
Batch 8/64 loss: 3.9211392402648926
Batch 9/64 loss: 3.806643009185791
Batch 10/64 loss: 3.885075092315674
Batch 11/64 loss: 3.8432202339172363
Batch 12/64 loss: 3.8011555671691895
Batch 13/64 loss: 3.6995840072631836
Batch 14/64 loss: 3.758634328842163
Batch 15/64 loss: 3.6865668296813965
Batch 16/64 loss: 3.732388973236084
Batch 17/64 loss: 3.581632375717163
Batch 18/64 loss: 3.6744627952575684
Batch 19/64 loss: 3.4667699337005615
Batch 20/64 loss: 3.588179349899292
Batch 21/64 loss: 3.5168521404266357
Batch 22/64 loss: 3.465243339538574
Batch 23/64 loss: 3.483823776245117
Batch 24/64 loss: 3.8324241638183594
Batch 25/64 loss: 3.566591501235962
Batch 26/64 loss: 3.5402963161468506
Batch 27/64 loss: 3.727107286453247
Batch 28/64 loss: 3.880702495574951
Batch 29/64 loss: 3.5796597003936768
Batch 30/64 loss: 3.4519243240356445
Batch 31/64 loss: 3.4657979011535645
Batch 32/64 loss: 3.4810492992401123
Batch 33/64 loss: 3.675272226333618
Batch 34/64 loss: 3.5352697372436523
Batch 35/64 loss: 3.5547702312469482
Batch 36/64 loss: 3.474215030670166
Batch 37/64 loss: 3.6788127422332764
Batch 38/64 loss: 3.4706170558929443
Batch 39/64 loss: 3.638087272644043
Batch 40/64 loss: 3.589373826980591
Batch 41/64 loss: 3.4242641925811768
Batch 42/64 loss: 3.436552047729492
Batch 43/64 loss: 3.3726699352264404
Batch 44/64 loss: 3.3565428256988525
Batch 45/64 loss: 3.608586072921753
Batch 46/64 loss: 3.3294172286987305
Batch 47/64 loss: 3.4563920497894287
Batch 48/64 loss: 3.5385024547576904
Batch 49/64 loss: 3.4669435024261475
Batch 50/64 loss: 3.374610662460327
Batch 51/64 loss: 3.342132568359375
Batch 52/64 loss: 3.346479654312134
Batch 53/64 loss: 3.210858106613159
Batch 54/64 loss: 3.3515377044677734
Batch 55/64 loss: 3.2760257720947266
Batch 56/64 loss: 3.683156967163086
Batch 57/64 loss: 3.4726076126098633
Batch 58/64 loss: 3.3694610595703125
Batch 59/64 loss: 3.1927924156188965
Batch 60/64 loss: 3.230419635772705
Batch 61/64 loss: 3.2269835472106934
Batch 62/64 loss: 3.643475294113159
Batch 63/64 loss: 3.4148917198181152
Batch 64/64 loss: 1.6787309646606445
Epoch 4  Train loss: 3.543774720734241  Val loss: 3.5732946625280215
Saving best model, epoch: 4
Epoch 5
-------------------------------
Batch 1/64 loss: 3.3288605213165283
Batch 2/64 loss: 3.6220178604125977
Batch 3/64 loss: 3.1516976356506348
Batch 4/64 loss: 3.3498947620391846
Batch 5/64 loss: 3.316129684448242
Batch 6/64 loss: 3.9499340057373047
Batch 7/64 loss: 3.5788214206695557
Batch 8/64 loss: 3.4031317234039307
Batch 9/64 loss: 3.3321211338043213
Batch 10/64 loss: 3.5063202381134033
Batch 11/64 loss: 3.4343185424804688
Batch 12/64 loss: 3.4567654132843018
Batch 13/64 loss: 3.5288257598876953
Batch 14/64 loss: 3.4062557220458984
Batch 15/64 loss: 3.3156557083129883
Batch 16/64 loss: 3.252786874771118
Batch 17/64 loss: 3.3390002250671387
Batch 18/64 loss: 3.4250645637512207
Batch 19/64 loss: 3.5437662601470947
Batch 20/64 loss: 3.4816946983337402
Batch 21/64 loss: 3.5443153381347656
Batch 22/64 loss: 3.2888002395629883
Batch 23/64 loss: 3.3392174243927
Batch 24/64 loss: 3.2959110736846924
Batch 25/64 loss: 3.38494873046875
Batch 26/64 loss: 3.1198577880859375
Batch 27/64 loss: 3.1310505867004395
Batch 28/64 loss: 3.2631585597991943
Batch 29/64 loss: 3.053363561630249
Batch 30/64 loss: 3.185669422149658
Batch 31/64 loss: 3.377244234085083
Batch 32/64 loss: 3.1178555488586426
Batch 33/64 loss: 3.093113899230957
Batch 34/64 loss: 3.332296848297119
Batch 35/64 loss: 3.08581280708313
Batch 36/64 loss: 3.1837339401245117
Batch 37/64 loss: 3.1217987537384033
Batch 38/64 loss: 3.3666391372680664
Batch 39/64 loss: 3.021174907684326
Batch 40/64 loss: 3.360271692276001
Batch 41/64 loss: 3.1707332134246826
Batch 42/64 loss: 2.956437110900879
Batch 43/64 loss: 3.234302043914795
Batch 44/64 loss: 3.047159433364868
Batch 45/64 loss: 3.0850555896759033
Batch 46/64 loss: 3.0783884525299072
Batch 47/64 loss: 2.824636459350586
Batch 48/64 loss: 2.79194974899292
Batch 49/64 loss: 3.223252058029175
Batch 50/64 loss: 3.0628662109375
Batch 51/64 loss: 2.893760919570923
Batch 52/64 loss: 3.0069422721862793
Batch 53/64 loss: 3.030219316482544
Batch 54/64 loss: 3.031736135482788
Batch 55/64 loss: 2.710099935531616
Batch 56/64 loss: 2.927140951156616
Batch 57/64 loss: 3.0926222801208496
Batch 58/64 loss: 2.946509599685669
Batch 59/64 loss: 2.9884684085845947
Batch 60/64 loss: 2.8900601863861084
Batch 61/64 loss: 2.8023276329040527
Batch 62/64 loss: 3.0442709922790527
Batch 63/64 loss: 3.059316873550415
Batch 64/64 loss: 0.8442120552062988
Epoch 5  Train loss: 3.1830699939353795  Val loss: 2.9698482264358153
Saving best model, epoch: 5
Epoch 6
-------------------------------
Batch 1/64 loss: 5.235586643218994
Batch 2/64 loss: 2.834559440612793
Batch 3/64 loss: 3.0936214923858643
Batch 4/64 loss: 3.4689531326293945
Batch 5/64 loss: 3.359996795654297
Batch 6/64 loss: 2.8362486362457275
Batch 7/64 loss: 2.9824774265289307
Batch 8/64 loss: 2.851850986480713
Batch 9/64 loss: 3.1483612060546875
Batch 10/64 loss: 2.9163787364959717
Batch 11/64 loss: 2.9804134368896484
Batch 12/64 loss: 3.0305144786834717
Batch 13/64 loss: 2.9388961791992188
Batch 14/64 loss: 3.0671682357788086
Batch 15/64 loss: 3.3315865993499756
Batch 16/64 loss: 3.0496764183044434
Batch 17/64 loss: 3.2921268939971924
Batch 18/64 loss: 3.183006525039673
Batch 19/64 loss: 2.915743589401245
Batch 20/64 loss: 2.9630255699157715
Batch 21/64 loss: 2.8632476329803467
Batch 22/64 loss: 2.980206251144409
Batch 23/64 loss: 2.8960835933685303
Batch 24/64 loss: 3.033236265182495
Batch 25/64 loss: 2.8849973678588867
Batch 26/64 loss: 2.6598174571990967
Batch 27/64 loss: 2.850776433944702
Batch 28/64 loss: 2.9058005809783936
Batch 29/64 loss: 2.90812611579895
Batch 30/64 loss: 2.930974245071411
Batch 31/64 loss: 2.8775408267974854
Batch 32/64 loss: 3.0379533767700195
Batch 33/64 loss: 2.8743600845336914
Batch 34/64 loss: 3.0250871181488037
Batch 35/64 loss: 2.7331602573394775
Batch 36/64 loss: 2.728532075881958
Batch 37/64 loss: 2.8171119689941406
Batch 38/64 loss: 2.828824281692505
Batch 39/64 loss: 2.731977939605713
Batch 40/64 loss: 2.5421671867370605
Batch 41/64 loss: 3.135843276977539
Batch 42/64 loss: 2.9244682788848877
Batch 43/64 loss: 2.839928150177002
Batch 44/64 loss: 2.76432204246521
Batch 45/64 loss: 2.8109850883483887
Batch 46/64 loss: 2.5583865642547607
Batch 47/64 loss: 2.587803840637207
Batch 48/64 loss: 2.6111972332000732
Batch 49/64 loss: 2.724402904510498
Batch 50/64 loss: 2.6492197513580322
Batch 51/64 loss: 2.7210354804992676
Batch 52/64 loss: 2.515071392059326
Batch 53/64 loss: 2.6045732498168945
Batch 54/64 loss: 2.866024971008301
Batch 55/64 loss: 2.339592456817627
Batch 56/64 loss: 3.0463943481445312
Batch 57/64 loss: 2.5330638885498047
Batch 58/64 loss: 2.524083137512207
Batch 59/64 loss: 2.3550853729248047
Batch 60/64 loss: 2.563077449798584
Batch 61/64 loss: 2.2756433486938477
Batch 62/64 loss: 2.7070865631103516
Batch 63/64 loss: 2.3657960891723633
Batch 64/64 loss: 0.21253395080566406
Epoch 6  Train loss: 2.8513358247046376  Val loss: 2.546128515525372
Saving best model, epoch: 6
Epoch 7
-------------------------------
Batch 1/64 loss: 2.621415138244629
Batch 2/64 loss: 2.4061074256896973
Batch 3/64 loss: 2.7010459899902344
Batch 4/64 loss: 2.410881519317627
Batch 5/64 loss: 2.441342353820801
Batch 6/64 loss: 2.505807876586914
Batch 7/64 loss: 2.7736005783081055
Batch 8/64 loss: 2.5824551582336426
Batch 9/64 loss: 2.444443702697754
Batch 10/64 loss: 2.4869842529296875
Batch 11/64 loss: 2.339515209197998
Batch 12/64 loss: 2.332146167755127
Batch 13/64 loss: 2.206508159637451
Batch 14/64 loss: 2.4846878051757812
Batch 15/64 loss: 2.4946446418762207
Batch 16/64 loss: 2.3271427154541016
Batch 17/64 loss: 2.3541932106018066
Batch 18/64 loss: 2.3981785774230957
Batch 19/64 loss: 2.4289846420288086
Batch 20/64 loss: 2.3272948265075684
Batch 21/64 loss: 2.4884557723999023
Batch 22/64 loss: 2.2651987075805664
Batch 23/64 loss: 2.1890320777893066
Batch 24/64 loss: 2.2276172637939453
Batch 25/64 loss: 2.1392931938171387
Batch 26/64 loss: 3.168595314025879
Batch 27/64 loss: 2.510101795196533
Batch 28/64 loss: 2.6067099571228027
Batch 29/64 loss: 2.7603507041931152
Batch 30/64 loss: 2.7845396995544434
Batch 31/64 loss: 2.4989614486694336
Batch 32/64 loss: 2.3295602798461914
Batch 33/64 loss: 2.4065299034118652
Batch 34/64 loss: 2.3327760696411133
Batch 35/64 loss: 2.3826074600219727
Batch 36/64 loss: 2.0406479835510254
Batch 37/64 loss: 2.440549373626709
Batch 38/64 loss: 2.189847946166992
Batch 39/64 loss: 2.1015758514404297
Batch 40/64 loss: 2.2849059104919434
Batch 41/64 loss: 2.1750588417053223
Batch 42/64 loss: 2.2854132652282715
Batch 43/64 loss: 2.297524929046631
Batch 44/64 loss: 2.4899377822875977
Batch 45/64 loss: 2.391169548034668
Batch 46/64 loss: 1.9969477653503418
Batch 47/64 loss: 2.479825019836426
Batch 48/64 loss: 2.363658905029297
Batch 49/64 loss: 2.3066163063049316
Batch 50/64 loss: 2.358139991760254
Batch 51/64 loss: 2.415802001953125
Batch 52/64 loss: 2.0839052200317383
Batch 53/64 loss: 2.2698802947998047
Batch 54/64 loss: 2.8844408988952637
Batch 55/64 loss: 2.378690719604492
Batch 56/64 loss: 2.191805362701416
Batch 57/64 loss: 2.10209321975708
Batch 58/64 loss: 2.2280964851379395
Batch 59/64 loss: 2.2303638458251953
Batch 60/64 loss: 2.2883172035217285
Batch 61/64 loss: 2.606278419494629
Batch 62/64 loss: 2.2334704399108887
Batch 63/64 loss: 1.8954615592956543
Batch 64/64 loss: -0.2691993713378906
Epoch 7  Train loss: 2.352411531934551  Val loss: 2.347373654342599
Saving best model, epoch: 7
Epoch 8
-------------------------------
Batch 1/64 loss: 2.189967155456543
Batch 2/64 loss: 2.416110038757324
Batch 3/64 loss: 2.1397547721862793
Batch 4/64 loss: 2.09299898147583
Batch 5/64 loss: 2.207254409790039
Batch 6/64 loss: 2.072330951690674
Batch 7/64 loss: 2.118910312652588
Batch 8/64 loss: 1.9990324974060059
Batch 9/64 loss: 2.5070505142211914
Batch 10/64 loss: 2.34976863861084
Batch 11/64 loss: 2.1867542266845703
Batch 12/64 loss: 2.1374454498291016
Batch 13/64 loss: 2.165243148803711
Batch 14/64 loss: 2.2857909202575684
Batch 15/64 loss: 2.465463638305664
Batch 16/64 loss: 1.8147506713867188
Batch 17/64 loss: 2.5188403129577637
Batch 18/64 loss: 2.1446547508239746
Batch 19/64 loss: 2.040681838989258
Batch 20/64 loss: 2.301903247833252
Batch 21/64 loss: 2.08843994140625
Batch 22/64 loss: 1.9948358535766602
Batch 23/64 loss: 2.0230422019958496
Batch 24/64 loss: 2.5178685188293457
Batch 25/64 loss: 2.1826696395874023
Batch 26/64 loss: 2.3023061752319336
Batch 27/64 loss: 2.4318127632141113
Batch 28/64 loss: 1.984814167022705
Batch 29/64 loss: 2.083352565765381
Batch 30/64 loss: 2.000943660736084
Batch 31/64 loss: 1.9368228912353516
Batch 32/64 loss: 1.9253978729248047
Batch 33/64 loss: 1.9987225532531738
Batch 34/64 loss: 1.9243402481079102
Batch 35/64 loss: 1.9836831092834473
Batch 36/64 loss: 2.0811266899108887
Batch 37/64 loss: 2.0070881843566895
Batch 38/64 loss: 1.8824701309204102
Batch 39/64 loss: 2.235535144805908
Batch 40/64 loss: 1.7259206771850586
Batch 41/64 loss: 1.9142889976501465
Batch 42/64 loss: 2.220977306365967
Batch 43/64 loss: 2.1160364151000977
Batch 44/64 loss: 1.9614434242248535
Batch 45/64 loss: 2.0200586318969727
Batch 46/64 loss: 1.967463493347168
Batch 47/64 loss: 1.694322109222412
Batch 48/64 loss: 1.770981788635254
Batch 49/64 loss: 1.8493738174438477
Batch 50/64 loss: 1.8440427780151367
Batch 51/64 loss: 1.9564924240112305
Batch 52/64 loss: 1.6391682624816895
Batch 53/64 loss: 1.9948921203613281
Batch 54/64 loss: 1.8122801780700684
Batch 55/64 loss: 1.9218673706054688
Batch 56/64 loss: 1.6948938369750977
Batch 57/64 loss: 2.167119026184082
Batch 58/64 loss: 1.9372549057006836
Batch 59/64 loss: 1.8014111518859863
Batch 60/64 loss: 1.673691749572754
Batch 61/64 loss: 1.5626707077026367
Batch 62/64 loss: 1.8700776100158691
Batch 63/64 loss: 1.626720905303955
Batch 64/64 loss: -0.9712176322937012
Epoch 8  Train loss: 2.004000239278756  Val loss: 1.917062739736026
Saving best model, epoch: 8
Epoch 9
-------------------------------
Batch 1/64 loss: 1.5483341217041016
Batch 2/64 loss: 1.7899665832519531
Batch 3/64 loss: 1.8679733276367188
Batch 4/64 loss: 1.6190052032470703
Batch 5/64 loss: 1.6031064987182617
Batch 6/64 loss: 1.9569950103759766
Batch 7/64 loss: 1.8621716499328613
Batch 8/64 loss: 1.909219741821289
Batch 9/64 loss: 1.6659765243530273
Batch 10/64 loss: 1.369028091430664
Batch 11/64 loss: 1.5860400199890137
Batch 12/64 loss: 1.8869109153747559
Batch 13/64 loss: 1.9285674095153809
Batch 14/64 loss: 1.7766289710998535
Batch 15/64 loss: 1.564323902130127
Batch 16/64 loss: 1.6395201683044434
Batch 17/64 loss: 1.7926406860351562
Batch 18/64 loss: 1.4604477882385254
Batch 19/64 loss: 1.7711529731750488
Batch 20/64 loss: 1.763442039489746
Batch 21/64 loss: 1.637087345123291
Batch 22/64 loss: 1.34492826461792
Batch 23/64 loss: 1.8169279098510742
Batch 24/64 loss: 1.57489013671875
Batch 25/64 loss: 1.8891730308532715
Batch 26/64 loss: 1.8324685096740723
Batch 27/64 loss: 1.6570439338684082
Batch 28/64 loss: 1.5598878860473633
Batch 29/64 loss: 1.6505846977233887
Batch 30/64 loss: 1.7566041946411133
Batch 31/64 loss: 1.267866611480713
Batch 32/64 loss: 1.5216498374938965
Batch 33/64 loss: 2.487710952758789
Batch 34/64 loss: 1.6626992225646973
Batch 35/64 loss: 1.5553364753723145
Batch 36/64 loss: 1.4951767921447754
Batch 37/64 loss: 1.6239910125732422
Batch 38/64 loss: 1.6998028755187988
Batch 39/64 loss: 1.7627592086791992
Batch 40/64 loss: 2.0074682235717773
Batch 41/64 loss: 1.462541103363037
Batch 42/64 loss: 1.4950714111328125
Batch 43/64 loss: 1.4305105209350586
Batch 44/64 loss: 3.9010448455810547
Batch 45/64 loss: 2.002044677734375
Batch 46/64 loss: 1.6311278343200684
Batch 47/64 loss: 1.9243173599243164
Batch 48/64 loss: 2.1214094161987305
Batch 49/64 loss: 1.6418275833129883
Batch 50/64 loss: 2.4100708961486816
Batch 51/64 loss: 1.8603496551513672
Batch 52/64 loss: 1.851208209991455
Batch 53/64 loss: 2.16990327835083
Batch 54/64 loss: 2.502793312072754
Batch 55/64 loss: 1.8897290229797363
Batch 56/64 loss: 2.663219451904297
Batch 57/64 loss: 2.4309334754943848
Batch 58/64 loss: 1.5754766464233398
Batch 59/64 loss: 2.0005903244018555
Batch 60/64 loss: 1.7479915618896484
Batch 61/64 loss: 1.901761531829834
Batch 62/64 loss: 2.0382471084594727
Batch 63/64 loss: 2.0136117935180664
Batch 64/64 loss: -1.1689515113830566
Epoch 9  Train loss: 1.7875227628969679  Val loss: 1.78195695123312
Saving best model, epoch: 9
Epoch 10
-------------------------------
Batch 1/64 loss: 1.5861101150512695
Batch 2/64 loss: 2.333716869354248
Batch 3/64 loss: 1.9410266876220703
Batch 4/64 loss: 1.9367551803588867
Batch 5/64 loss: 2.0058846473693848
Batch 6/64 loss: 1.8027763366699219
Batch 7/64 loss: 2.1156110763549805
Batch 8/64 loss: 1.6981511116027832
Batch 9/64 loss: 1.9984169006347656
Batch 10/64 loss: 1.8685541152954102
Batch 11/64 loss: 1.5987215042114258
Batch 12/64 loss: 1.918919563293457
Batch 13/64 loss: 2.1283631324768066
Batch 14/64 loss: 1.6126012802124023
Batch 15/64 loss: 1.656904697418213
Batch 16/64 loss: 1.6611404418945312
Batch 17/64 loss: 1.4535536766052246
Batch 18/64 loss: 1.5419340133666992
Batch 19/64 loss: 1.6299657821655273
Batch 20/64 loss: 1.437516689300537
Batch 21/64 loss: 1.6868700981140137
Batch 22/64 loss: 1.8147082328796387
Batch 23/64 loss: 2.297391414642334
Batch 24/64 loss: 1.4971671104431152
Batch 25/64 loss: 1.789259433746338
Batch 26/64 loss: 2.098661422729492
Batch 27/64 loss: 2.109905242919922
Batch 28/64 loss: 1.6894521713256836
Batch 29/64 loss: 1.7915325164794922
Batch 30/64 loss: 2.007267951965332
Batch 31/64 loss: 2.1280832290649414
Batch 32/64 loss: 2.0487022399902344
Batch 33/64 loss: 1.7462348937988281
Batch 34/64 loss: 1.996899127960205
Batch 35/64 loss: 1.469390869140625
Batch 36/64 loss: 1.5744452476501465
Batch 37/64 loss: 1.5225811004638672
Batch 38/64 loss: 1.8847241401672363
Batch 39/64 loss: 1.6342110633850098
Batch 40/64 loss: 1.846865177154541
Batch 41/64 loss: 1.6467790603637695
Batch 42/64 loss: 1.4880857467651367
Batch 43/64 loss: 1.6162996292114258
Batch 44/64 loss: 1.6816463470458984
Batch 45/64 loss: 1.642052173614502
Batch 46/64 loss: 1.47023344039917
Batch 47/64 loss: 1.5623021125793457
Batch 48/64 loss: 1.8934946060180664
Batch 49/64 loss: 2.0859622955322266
Batch 50/64 loss: 1.4979667663574219
Batch 51/64 loss: 1.7928972244262695
Batch 52/64 loss: 1.301053524017334
Batch 53/64 loss: 2.553706645965576
Batch 54/64 loss: 1.616912841796875
Batch 55/64 loss: 1.7610416412353516
Batch 56/64 loss: 1.6065936088562012
Batch 57/64 loss: 2.0236525535583496
Batch 58/64 loss: 1.7038049697875977
Batch 59/64 loss: 1.703813076019287
Batch 60/64 loss: 1.7466645240783691
Batch 61/64 loss: 1.5159311294555664
Batch 62/64 loss: 1.567880630493164
Batch 63/64 loss: 1.4718451499938965
Batch 64/64 loss: -1.2154383659362793
Epoch 10  Train loss: 1.734902234170951  Val loss: 1.4934566143861752
Saving best model, epoch: 10
Epoch 11
-------------------------------
Batch 1/64 loss: 1.3613543510437012
Batch 2/64 loss: 1.662060260772705
Batch 3/64 loss: 1.459078311920166
Batch 4/64 loss: 1.327197551727295
Batch 5/64 loss: 1.131333827972412
Batch 6/64 loss: 1.6479401588439941
Batch 7/64 loss: 2.249424934387207
Batch 8/64 loss: 1.7372064590454102
Batch 9/64 loss: 1.627397060394287
Batch 10/64 loss: 1.3906569480895996
Batch 11/64 loss: 1.4739866256713867
Batch 12/64 loss: 1.4980454444885254
Batch 13/64 loss: 1.4421024322509766
Batch 14/64 loss: 1.3692445755004883
Batch 15/64 loss: 1.500669002532959
Batch 16/64 loss: 1.059941291809082
Batch 17/64 loss: 1.2413268089294434
Batch 18/64 loss: 1.5322256088256836
Batch 19/64 loss: 1.6572585105895996
Batch 20/64 loss: 1.4484119415283203
Batch 21/64 loss: 1.1085057258605957
Batch 22/64 loss: 1.2646808624267578
Batch 23/64 loss: 1.2734489440917969
Batch 24/64 loss: 1.4901905059814453
Batch 25/64 loss: 1.5965566635131836
Batch 26/64 loss: 1.4465880393981934
Batch 27/64 loss: 1.424278736114502
Batch 28/64 loss: 1.355722427368164
Batch 29/64 loss: 2.07681941986084
Batch 30/64 loss: 1.4569487571716309
Batch 31/64 loss: 1.365860939025879
Batch 32/64 loss: 1.148618221282959
Batch 33/64 loss: 1.394484043121338
Batch 34/64 loss: 1.5510435104370117
Batch 35/64 loss: 1.0969643592834473
Batch 36/64 loss: 1.3294458389282227
Batch 37/64 loss: 0.925544261932373
Batch 38/64 loss: 1.5420212745666504
Batch 39/64 loss: 1.3469672203063965
Batch 40/64 loss: 1.1521048545837402
Batch 41/64 loss: 1.4518680572509766
Batch 42/64 loss: 1.7791085243225098
Batch 43/64 loss: 1.6404304504394531
Batch 44/64 loss: 1.482004165649414
Batch 45/64 loss: 1.4715800285339355
Batch 46/64 loss: 1.5520868301391602
Batch 47/64 loss: 1.4241557121276855
Batch 48/64 loss: 1.1993374824523926
Batch 49/64 loss: 1.1989593505859375
Batch 50/64 loss: 1.2847590446472168
Batch 51/64 loss: 1.1045498847961426
Batch 52/64 loss: 1.0565147399902344
Batch 53/64 loss: 1.0486035346984863
Batch 54/64 loss: 1.305640697479248
Batch 55/64 loss: 1.1850838661193848
Batch 56/64 loss: 1.468034267425537
Batch 57/64 loss: 1.7193808555603027
Batch 58/64 loss: 1.2870969772338867
Batch 59/64 loss: 1.545964241027832
Batch 60/64 loss: 1.0683417320251465
Batch 61/64 loss: 1.120706558227539
Batch 62/64 loss: 1.5506305694580078
Batch 63/64 loss: 1.2692346572875977
Batch 64/64 loss: -2.5552425384521484
Epoch 11  Train loss: 1.3562556397681143  Val loss: 1.139849895464186
Saving best model, epoch: 11
Epoch 12
-------------------------------
Batch 1/64 loss: 1.3133268356323242
Batch 2/64 loss: 1.1596174240112305
Batch 3/64 loss: 1.0437932014465332
Batch 4/64 loss: 1.5117554664611816
Batch 5/64 loss: 1.1333355903625488
Batch 6/64 loss: 0.9652142524719238
Batch 7/64 loss: 1.0409526824951172
Batch 8/64 loss: 1.1602716445922852
Batch 9/64 loss: 1.1400270462036133
Batch 10/64 loss: 1.6493539810180664
Batch 11/64 loss: 1.4636726379394531
Batch 12/64 loss: 1.1532764434814453
Batch 13/64 loss: 0.9178605079650879
Batch 14/64 loss: 1.1853156089782715
Batch 15/64 loss: 1.6354646682739258
Batch 16/64 loss: 1.2251935005187988
Batch 17/64 loss: 1.22084379196167
Batch 18/64 loss: 1.9231390953063965
Batch 19/64 loss: 0.9559206962585449
Batch 20/64 loss: 1.0803947448730469
Batch 21/64 loss: 1.5296378135681152
Batch 22/64 loss: 1.3871102333068848
Batch 23/64 loss: 1.3045639991760254
Batch 24/64 loss: 1.0686120986938477
Batch 25/64 loss: 1.1177959442138672
Batch 26/64 loss: 1.3215785026550293
Batch 27/64 loss: 1.7653303146362305
Batch 28/64 loss: 1.1616520881652832
Batch 29/64 loss: 1.2711482048034668
Batch 30/64 loss: 1.0147013664245605
Batch 31/64 loss: 1.160046100616455
Batch 32/64 loss: 1.3716387748718262
Batch 33/64 loss: 1.23121976852417
Batch 34/64 loss: 1.165557861328125
Batch 35/64 loss: 1.0587687492370605
Batch 36/64 loss: 0.8318886756896973
Batch 37/64 loss: 1.4150190353393555
Batch 38/64 loss: 0.8215761184692383
Batch 39/64 loss: 1.2669477462768555
Batch 40/64 loss: 1.3236083984375
Batch 41/64 loss: 1.1349711418151855
Batch 42/64 loss: 1.455355167388916
Batch 43/64 loss: 1.3778347969055176
Batch 44/64 loss: 1.0613412857055664
Batch 45/64 loss: 0.9482789039611816
Batch 46/64 loss: 1.4052753448486328
Batch 47/64 loss: 1.2364587783813477
Batch 48/64 loss: 1.0575556755065918
Batch 49/64 loss: 1.1501197814941406
Batch 50/64 loss: 1.4595260620117188
Batch 51/64 loss: 1.3931708335876465
Batch 52/64 loss: 1.1320180892944336
Batch 53/64 loss: 1.1482954025268555
Batch 54/64 loss: 1.488034725189209
Batch 55/64 loss: 1.2619123458862305
Batch 56/64 loss: 1.1792120933532715
Batch 57/64 loss: 1.385429859161377
Batch 58/64 loss: 1.3302888870239258
Batch 59/64 loss: 1.0183825492858887
Batch 60/64 loss: 1.4701461791992188
Batch 61/64 loss: 1.0144762992858887
Batch 62/64 loss: 1.2360377311706543
Batch 63/64 loss: 1.1095013618469238
Batch 64/64 loss: -2.284848213195801
Epoch 12  Train loss: 1.1954057843077417  Val loss: 1.1920686636593743
Epoch 13
-------------------------------
Batch 1/64 loss: 0.9666628837585449
Batch 2/64 loss: 1.1123476028442383
Batch 3/64 loss: 0.929652214050293
Batch 4/64 loss: 1.0102219581604004
Batch 5/64 loss: 1.2317323684692383
Batch 6/64 loss: 1.06565523147583
Batch 7/64 loss: 1.2610359191894531
Batch 8/64 loss: 0.6887526512145996
Batch 9/64 loss: 1.1753129959106445
Batch 10/64 loss: 1.4051685333251953
Batch 11/64 loss: 1.1651482582092285
Batch 12/64 loss: 0.8790798187255859
Batch 13/64 loss: 0.9979743957519531
Batch 14/64 loss: 1.2405552864074707
Batch 15/64 loss: 1.0040955543518066
Batch 16/64 loss: 1.1821279525756836
Batch 17/64 loss: 1.2563719749450684
Batch 18/64 loss: 1.0472640991210938
Batch 19/64 loss: 0.9223065376281738
Batch 20/64 loss: 0.778632640838623
Batch 21/64 loss: 0.9841194152832031
Batch 22/64 loss: 0.8889274597167969
Batch 23/64 loss: 0.9617509841918945
Batch 24/64 loss: 1.3343052864074707
Batch 25/64 loss: 0.6794352531433105
Batch 26/64 loss: 0.6537570953369141
Batch 27/64 loss: 1.0125174522399902
Batch 28/64 loss: 0.9683656692504883
Batch 29/64 loss: 0.6633896827697754
Batch 30/64 loss: 0.9376692771911621
Batch 31/64 loss: 0.8722071647644043
Batch 32/64 loss: 1.138474464416504
Batch 33/64 loss: 0.8765954971313477
Batch 34/64 loss: 1.3131589889526367
Batch 35/64 loss: 1.0395584106445312
Batch 36/64 loss: 1.7457284927368164
Batch 37/64 loss: 1.5728917121887207
Batch 38/64 loss: 1.3848199844360352
Batch 39/64 loss: 1.0077567100524902
Batch 40/64 loss: 0.7400474548339844
Batch 41/64 loss: 1.6608362197875977
Batch 42/64 loss: 1.1692705154418945
Batch 43/64 loss: 0.8824911117553711
Batch 44/64 loss: 1.232865810394287
Batch 45/64 loss: 0.9564399719238281
Batch 46/64 loss: 1.164036750793457
Batch 47/64 loss: 1.410853385925293
Batch 48/64 loss: 1.1515040397644043
Batch 49/64 loss: 1.2360296249389648
Batch 50/64 loss: 1.139153003692627
Batch 51/64 loss: 1.2489476203918457
Batch 52/64 loss: 0.7364406585693359
Batch 53/64 loss: 1.5825061798095703
Batch 54/64 loss: 0.9851698875427246
Batch 55/64 loss: 1.1374292373657227
Batch 56/64 loss: 1.0375933647155762
Batch 57/64 loss: 0.7989902496337891
Batch 58/64 loss: 1.1602721214294434
Batch 59/64 loss: 0.9002480506896973
Batch 60/64 loss: 1.2247285842895508
Batch 61/64 loss: 1.0321741104125977
Batch 62/64 loss: 1.0002689361572266
Batch 63/64 loss: 0.9553899765014648
Batch 64/64 loss: -2.693021774291992
Epoch 13  Train loss: 1.0334031123741  Val loss: 0.993938387054758
Saving best model, epoch: 13
Epoch 14
-------------------------------
Batch 1/64 loss: 1.1587576866149902
Batch 2/64 loss: 1.3768534660339355
Batch 3/64 loss: 1.0310673713684082
Batch 4/64 loss: 1.2405734062194824
Batch 5/64 loss: 0.9924211502075195
Batch 6/64 loss: 0.6435232162475586
Batch 7/64 loss: 1.2278695106506348
Batch 8/64 loss: 1.4571304321289062
Batch 9/64 loss: 0.6268577575683594
Batch 10/64 loss: 0.7772116661071777
Batch 11/64 loss: 1.0387206077575684
Batch 12/64 loss: 0.5488533973693848
Batch 13/64 loss: 0.7547845840454102
Batch 14/64 loss: 1.3849573135375977
Batch 15/64 loss: 1.0372018814086914
Batch 16/64 loss: 0.7361459732055664
Batch 17/64 loss: 0.6551108360290527
Batch 18/64 loss: 1.2083826065063477
Batch 19/64 loss: 1.2281622886657715
Batch 20/64 loss: 0.8247051239013672
Batch 21/64 loss: 0.7119603157043457
Batch 22/64 loss: 0.9971671104431152
Batch 23/64 loss: 0.6593742370605469
Batch 24/64 loss: 0.8848342895507812
Batch 25/64 loss: 0.9200916290283203
Batch 26/64 loss: 0.8105831146240234
Batch 27/64 loss: 0.6089925765991211
Batch 28/64 loss: 1.0351581573486328
Batch 29/64 loss: 0.8105568885803223
Batch 30/64 loss: 1.3406295776367188
Batch 31/64 loss: 0.7769808769226074
Batch 32/64 loss: 1.0975170135498047
Batch 33/64 loss: 0.873143196105957
Batch 34/64 loss: 1.1532936096191406
Batch 35/64 loss: 1.090738296508789
Batch 36/64 loss: 0.549830436706543
Batch 37/64 loss: 0.614504337310791
Batch 38/64 loss: 0.5428738594055176
Batch 39/64 loss: 1.3953914642333984
Batch 40/64 loss: 0.9466185569763184
Batch 41/64 loss: 1.3829317092895508
Batch 42/64 loss: 0.9416322708129883
Batch 43/64 loss: 0.5837578773498535
Batch 44/64 loss: 0.6896085739135742
Batch 45/64 loss: 1.2063422203063965
Batch 46/64 loss: 0.7826476097106934
Batch 47/64 loss: 0.7778987884521484
Batch 48/64 loss: 0.8978452682495117
Batch 49/64 loss: 0.5797867774963379
Batch 50/64 loss: 0.7048282623291016
Batch 51/64 loss: 1.0474262237548828
Batch 52/64 loss: 0.7205142974853516
Batch 53/64 loss: 0.6809005737304688
Batch 54/64 loss: 0.9247961044311523
Batch 55/64 loss: 2.0498180389404297
Batch 56/64 loss: 1.1782441139221191
Batch 57/64 loss: 1.7530517578125
Batch 58/64 loss: 1.6618280410766602
Batch 59/64 loss: 1.9761905670166016
Batch 60/64 loss: 1.7042956352233887
Batch 61/64 loss: 1.7306270599365234
Batch 62/64 loss: 1.8668699264526367
Batch 63/64 loss: 1.2907814979553223
Batch 64/64 loss: -1.8588237762451172
Epoch 14  Train loss: 0.9962044734580844  Val loss: 1.7797940834281372
Epoch 15
-------------------------------
Batch 1/64 loss: 1.5647344589233398
Batch 2/64 loss: 1.298689842224121
Batch 3/64 loss: 1.2754502296447754
Batch 4/64 loss: 1.3410649299621582
Batch 5/64 loss: 1.4136643409729004
Batch 6/64 loss: 1.7057719230651855
Batch 7/64 loss: 1.4485783576965332
Batch 8/64 loss: 1.002767562866211
Batch 9/64 loss: 1.1462225914001465
Batch 10/64 loss: 1.3386554718017578
Batch 11/64 loss: 1.0935182571411133
Batch 12/64 loss: 1.066483497619629
Batch 13/64 loss: 1.2536754608154297
Batch 14/64 loss: 0.7432198524475098
Batch 15/64 loss: 1.0648994445800781
Batch 16/64 loss: 0.5952486991882324
Batch 17/64 loss: 1.3840618133544922
Batch 18/64 loss: 1.3428359031677246
Batch 19/64 loss: 1.3964653015136719
Batch 20/64 loss: 0.9984979629516602
Batch 21/64 loss: 1.2493691444396973
Batch 22/64 loss: 0.8865442276000977
Batch 23/64 loss: 0.8185386657714844
Batch 24/64 loss: 1.3840384483337402
Batch 25/64 loss: 1.3679871559143066
Batch 26/64 loss: 1.054286003112793
Batch 27/64 loss: 1.4512691497802734
Batch 28/64 loss: 1.1135191917419434
Batch 29/64 loss: 0.6467299461364746
Batch 30/64 loss: 0.8724212646484375
Batch 31/64 loss: 1.1003246307373047
Batch 32/64 loss: 1.202174186706543
Batch 33/64 loss: 0.8835492134094238
Batch 34/64 loss: 1.508070945739746
Batch 35/64 loss: 1.2121219635009766
Batch 36/64 loss: 1.493697166442871
Batch 37/64 loss: 0.9500851631164551
Batch 38/64 loss: 1.4603238105773926
Batch 39/64 loss: 0.5817456245422363
Batch 40/64 loss: 1.4840660095214844
Batch 41/64 loss: 1.2457194328308105
Batch 42/64 loss: 1.3918137550354004
Batch 43/64 loss: 1.057253360748291
Batch 44/64 loss: 0.8691654205322266
Batch 45/64 loss: 1.2313294410705566
Batch 46/64 loss: 1.2975587844848633
Batch 47/64 loss: 0.660973072052002
Batch 48/64 loss: 0.7120413780212402
Batch 49/64 loss: 1.3175373077392578
Batch 50/64 loss: 0.7858686447143555
Batch 51/64 loss: 0.9785900115966797
Batch 52/64 loss: 0.6580367088317871
Batch 53/64 loss: 0.9056782722473145
Batch 54/64 loss: 0.9810218811035156
Batch 55/64 loss: 1.0878305435180664
Batch 56/64 loss: 0.9426660537719727
Batch 57/64 loss: 1.088740348815918
Batch 58/64 loss: 1.395561695098877
Batch 59/64 loss: 1.345344066619873
Batch 60/64 loss: 1.1883153915405273
Batch 61/64 loss: 1.0742802619934082
Batch 62/64 loss: 0.792661190032959
Batch 63/64 loss: 1.3386845588684082
Batch 64/64 loss: -2.3249425888061523
Epoch 15  Train loss: 1.0948758031807693  Val loss: 0.7972767230161687
Saving best model, epoch: 15
Epoch 16
-------------------------------
Batch 1/64 loss: 0.8172836303710938
Batch 2/64 loss: 1.2440972328186035
Batch 3/64 loss: 1.0167646408081055
Batch 4/64 loss: 1.4320764541625977
Batch 5/64 loss: 0.849830150604248
Batch 6/64 loss: 0.8583459854125977
Batch 7/64 loss: 1.2315077781677246
Batch 8/64 loss: 0.8711066246032715
Batch 9/64 loss: 0.616816520690918
Batch 10/64 loss: 0.572812557220459
Batch 11/64 loss: 0.8022356033325195
Batch 12/64 loss: 0.6180939674377441
Batch 13/64 loss: 1.7701091766357422
Batch 14/64 loss: 0.7753996849060059
Batch 15/64 loss: 1.232370376586914
Batch 16/64 loss: 1.6358308792114258
Batch 17/64 loss: 0.8178367614746094
Batch 18/64 loss: 0.994722843170166
Batch 19/64 loss: 0.7448081970214844
Batch 20/64 loss: 0.703514575958252
Batch 21/64 loss: 1.01365327835083
Batch 22/64 loss: 0.5252265930175781
Batch 23/64 loss: 0.7323746681213379
Batch 24/64 loss: 1.0998687744140625
Batch 25/64 loss: 0.6722774505615234
Batch 26/64 loss: 0.4197878837585449
Batch 27/64 loss: 0.65020751953125
Batch 28/64 loss: 1.0274958610534668
Batch 29/64 loss: 0.7771000862121582
Batch 30/64 loss: 0.8001317977905273
Batch 31/64 loss: 0.5842099189758301
Batch 32/64 loss: 1.189742088317871
Batch 33/64 loss: 0.9699420928955078
Batch 34/64 loss: 1.0848674774169922
Batch 35/64 loss: 0.5984706878662109
Batch 36/64 loss: 0.5707578659057617
Batch 37/64 loss: 0.8469276428222656
Batch 38/64 loss: 0.7153677940368652
Batch 39/64 loss: 0.6177139282226562
Batch 40/64 loss: 1.359621524810791
Batch 41/64 loss: 1.069481372833252
Batch 42/64 loss: 1.361515998840332
Batch 43/64 loss: 1.0116214752197266
Batch 44/64 loss: 0.6208095550537109
Batch 45/64 loss: 0.37398576736450195
Batch 46/64 loss: 1.1511249542236328
Batch 47/64 loss: 0.9223394393920898
Batch 48/64 loss: 0.8056182861328125
Batch 49/64 loss: 0.9368772506713867
Batch 50/64 loss: 1.1626520156860352
Batch 51/64 loss: 1.52842378616333
Batch 52/64 loss: 0.7854399681091309
Batch 53/64 loss: 1.0210161209106445
Batch 54/64 loss: 1.048006534576416
Batch 55/64 loss: 0.7386593818664551
Batch 56/64 loss: 0.5563631057739258
Batch 57/64 loss: 0.9455523490905762
Batch 58/64 loss: 0.30918359756469727
Batch 59/64 loss: 0.6630892753601074
Batch 60/64 loss: 0.652900218963623
Batch 61/64 loss: 1.136430263519287
Batch 62/64 loss: 1.109222412109375
Batch 63/64 loss: 0.6879410743713379
Batch 64/64 loss: -2.29876708984375
Epoch 16  Train loss: 0.8585958817425896  Val loss: 0.6834436855774975
Saving best model, epoch: 16
Epoch 17
-------------------------------
Batch 1/64 loss: 1.568227767944336
Batch 2/64 loss: 0.9546051025390625
Batch 3/64 loss: 0.8854241371154785
Batch 4/64 loss: 1.455606460571289
Batch 5/64 loss: 0.7953214645385742
Batch 6/64 loss: 1.2105159759521484
Batch 7/64 loss: 1.3543658256530762
Batch 8/64 loss: 0.9985909461975098
Batch 9/64 loss: 1.020197868347168
Batch 10/64 loss: 0.7494277954101562
Batch 11/64 loss: 1.3492889404296875
Batch 12/64 loss: 0.9289331436157227
Batch 13/64 loss: 0.8497824668884277
Batch 14/64 loss: 1.2300300598144531
Batch 15/64 loss: 0.7089204788208008
Batch 16/64 loss: 1.6825523376464844
Batch 17/64 loss: 1.08378267288208
Batch 18/64 loss: 0.8151407241821289
Batch 19/64 loss: 0.9972491264343262
Batch 20/64 loss: 1.1835484504699707
Batch 21/64 loss: 0.8015017509460449
Batch 22/64 loss: 0.9888248443603516
Batch 23/64 loss: 1.2314491271972656
Batch 24/64 loss: 0.8466334342956543
Batch 25/64 loss: 1.0693697929382324
Batch 26/64 loss: 1.2420358657836914
Batch 27/64 loss: 0.9062442779541016
Batch 28/64 loss: 0.7701072692871094
Batch 29/64 loss: 0.7438802719116211
Batch 30/64 loss: 1.5404248237609863
Batch 31/64 loss: 0.8272004127502441
Batch 32/64 loss: 0.6263680458068848
Batch 33/64 loss: 1.1383056640625
Batch 34/64 loss: 0.8091106414794922
Batch 35/64 loss: 0.6957492828369141
Batch 36/64 loss: 1.2498493194580078
Batch 37/64 loss: 0.6223230361938477
Batch 38/64 loss: 0.45313549041748047
Batch 39/64 loss: 0.7609539031982422
Batch 40/64 loss: 0.6501426696777344
Batch 41/64 loss: 0.5853672027587891
Batch 42/64 loss: 0.6845273971557617
Batch 43/64 loss: 1.120152473449707
Batch 44/64 loss: 0.8087878227233887
Batch 45/64 loss: 0.6576986312866211
Batch 46/64 loss: 0.7644705772399902
Batch 47/64 loss: 0.4606289863586426
Batch 48/64 loss: 0.5410404205322266
Batch 49/64 loss: 0.3828873634338379
Batch 50/64 loss: 0.6868047714233398
Batch 51/64 loss: 0.5773754119873047
Batch 52/64 loss: 0.9305214881896973
Batch 53/64 loss: 0.6291346549987793
Batch 54/64 loss: 1.1068925857543945
Batch 55/64 loss: 0.6030054092407227
Batch 56/64 loss: 0.8169760704040527
Batch 57/64 loss: 0.9191217422485352
Batch 58/64 loss: 1.0914936065673828
Batch 59/64 loss: 0.8940773010253906
Batch 60/64 loss: 0.5942606925964355
Batch 61/64 loss: 0.5469279289245605
Batch 62/64 loss: 0.8936772346496582
Batch 63/64 loss: 0.5392398834228516
Batch 64/64 loss: -2.89778995513916
Epoch 17  Train loss: 0.8542250801535214  Val loss: 0.639392761020726
Saving best model, epoch: 17
Epoch 18
-------------------------------
Batch 1/64 loss: 0.811955451965332
Batch 2/64 loss: 0.7764577865600586
Batch 3/64 loss: 0.6960244178771973
Batch 4/64 loss: 0.8608026504516602
Batch 5/64 loss: 0.8242335319519043
Batch 6/64 loss: 0.5889496803283691
Batch 7/64 loss: 1.0203943252563477
Batch 8/64 loss: 0.5460109710693359
Batch 9/64 loss: 0.3185157775878906
Batch 10/64 loss: 0.6183466911315918
Batch 11/64 loss: 0.9724760055541992
Batch 12/64 loss: 0.5272464752197266
Batch 13/64 loss: 0.8197007179260254
Batch 14/64 loss: 0.4308133125305176
Batch 15/64 loss: 0.9292941093444824
Batch 16/64 loss: 0.7826285362243652
Batch 17/64 loss: 0.8688793182373047
Batch 18/64 loss: 0.6890907287597656
Batch 19/64 loss: 1.0666451454162598
Batch 20/64 loss: 0.656193733215332
Batch 21/64 loss: 0.5563859939575195
Batch 22/64 loss: 0.8062839508056641
Batch 23/64 loss: 0.8972625732421875
Batch 24/64 loss: 1.0035700798034668
Batch 25/64 loss: 0.7323284149169922
Batch 26/64 loss: 0.4648714065551758
Batch 27/64 loss: 0.8843059539794922
Batch 28/64 loss: 0.5726661682128906
Batch 29/64 loss: 1.0279455184936523
Batch 30/64 loss: 0.7037339210510254
Batch 31/64 loss: 0.48482561111450195
Batch 32/64 loss: 0.32616519927978516
Batch 33/64 loss: 0.5403742790222168
Batch 34/64 loss: 0.9783549308776855
Batch 35/64 loss: 0.6398983001708984
Batch 36/64 loss: 0.7103419303894043
Batch 37/64 loss: 0.9701294898986816
Batch 38/64 loss: 0.5396237373352051
Batch 39/64 loss: 1.0956196784973145
Batch 40/64 loss: 1.4723896980285645
Batch 41/64 loss: 0.39342832565307617
Batch 42/64 loss: 1.1675052642822266
Batch 43/64 loss: 0.6072573661804199
Batch 44/64 loss: 1.144484043121338
Batch 45/64 loss: 1.0122442245483398
Batch 46/64 loss: 0.5500383377075195
Batch 47/64 loss: 1.0683059692382812
Batch 48/64 loss: 0.8038311004638672
Batch 49/64 loss: 0.6715373992919922
Batch 50/64 loss: 0.7590532302856445
Batch 51/64 loss: 1.4405360221862793
Batch 52/64 loss: 0.5197224617004395
Batch 53/64 loss: 0.38153505325317383
Batch 54/64 loss: 0.3717813491821289
Batch 55/64 loss: 0.7082123756408691
Batch 56/64 loss: 0.6997909545898438
Batch 57/64 loss: 0.24210119247436523
Batch 58/64 loss: 1.0224089622497559
Batch 59/64 loss: 0.8457808494567871
Batch 60/64 loss: 1.1606812477111816
Batch 61/64 loss: 1.3542304039001465
Batch 62/64 loss: 1.690819263458252
Batch 63/64 loss: 0.8036165237426758
Batch 64/64 loss: -2.4942173957824707
Epoch 18  Train loss: 0.7491760796191645  Val loss: 0.8213481182085279
Epoch 19
-------------------------------
Batch 1/64 loss: 0.7819976806640625
Batch 2/64 loss: 0.767085075378418
Batch 3/64 loss: 0.772648811340332
Batch 4/64 loss: 1.3143224716186523
Batch 5/64 loss: 0.8014469146728516
Batch 6/64 loss: 1.0070734024047852
Batch 7/64 loss: 0.7688798904418945
Batch 8/64 loss: 0.9972257614135742
Batch 9/64 loss: 0.7768502235412598
Batch 10/64 loss: 0.7690587043762207
Batch 11/64 loss: 0.7445788383483887
Batch 12/64 loss: 0.6938738822937012
Batch 13/64 loss: 0.2870364189147949
Batch 14/64 loss: 0.7950172424316406
Batch 15/64 loss: 0.8610262870788574
Batch 16/64 loss: 0.7975869178771973
Batch 17/64 loss: 0.7100391387939453
Batch 18/64 loss: 1.0788254737854004
Batch 19/64 loss: 0.7216634750366211
Batch 20/64 loss: 1.0670757293701172
Batch 21/64 loss: 1.1884827613830566
Batch 22/64 loss: 0.581362247467041
Batch 23/64 loss: 0.5632967948913574
Batch 24/64 loss: 0.5322046279907227
Batch 25/64 loss: 0.4555635452270508
Batch 26/64 loss: 0.6242341995239258
Batch 27/64 loss: 0.8579668998718262
Batch 28/64 loss: 0.6884069442749023
Batch 29/64 loss: 1.087489128112793
Batch 30/64 loss: 0.23314428329467773
Batch 31/64 loss: 0.6874332427978516
Batch 32/64 loss: 0.4707770347595215
Batch 33/64 loss: 0.4963846206665039
Batch 34/64 loss: 1.1897354125976562
Batch 35/64 loss: 0.5652270317077637
Batch 36/64 loss: 1.1477527618408203
Batch 37/64 loss: 0.6659202575683594
Batch 38/64 loss: 0.8574705123901367
Batch 39/64 loss: 0.4090461730957031
Batch 40/64 loss: 0.5041360855102539
Batch 41/64 loss: 0.780665397644043
Batch 42/64 loss: 0.6111249923706055
Batch 43/64 loss: 0.6318759918212891
Batch 44/64 loss: 0.8243942260742188
Batch 45/64 loss: 0.6699562072753906
Batch 46/64 loss: 0.36304378509521484
Batch 47/64 loss: 0.3180656433105469
Batch 48/64 loss: 0.39540767669677734
Batch 49/64 loss: 1.0070276260375977
Batch 50/64 loss: 0.4482440948486328
Batch 51/64 loss: 0.3326454162597656
Batch 52/64 loss: 0.6865067481994629
Batch 53/64 loss: 0.6711702346801758
Batch 54/64 loss: 0.7865104675292969
Batch 55/64 loss: 0.7196540832519531
Batch 56/64 loss: 1.075812816619873
Batch 57/64 loss: 0.6263136863708496
Batch 58/64 loss: 0.6906204223632812
Batch 59/64 loss: 0.7692933082580566
Batch 60/64 loss: 0.31666088104248047
Batch 61/64 loss: 0.8731474876403809
Batch 62/64 loss: 0.3664393424987793
Batch 63/64 loss: 0.9781970977783203
Batch 64/64 loss: -3.121274948120117
Epoch 19  Train loss: 0.6732732286640242  Val loss: 0.5153967473924774
Saving best model, epoch: 19
Epoch 20
-------------------------------
Batch 1/64 loss: 0.1642918586730957
Batch 2/64 loss: 0.44596385955810547
Batch 3/64 loss: 0.5341477394104004
Batch 4/64 loss: 0.9002881050109863
Batch 5/64 loss: 0.4763026237487793
Batch 6/64 loss: 1.0624427795410156
Batch 7/64 loss: 0.7809648513793945
Batch 8/64 loss: 0.5023007392883301
Batch 9/64 loss: 0.8300166130065918
Batch 10/64 loss: 0.805394172668457
Batch 11/64 loss: 1.254652500152588
Batch 12/64 loss: 0.4475126266479492
Batch 13/64 loss: 0.9626302719116211
Batch 14/64 loss: 0.5619769096374512
Batch 15/64 loss: 0.6349616050720215
Batch 16/64 loss: 0.6864986419677734
Batch 17/64 loss: 0.6352324485778809
Batch 18/64 loss: 0.2945394515991211
Batch 19/64 loss: 0.5541863441467285
Batch 20/64 loss: 0.8928370475769043
Batch 21/64 loss: 1.0030627250671387
Batch 22/64 loss: 0.3824286460876465
Batch 23/64 loss: 0.28743553161621094
Batch 24/64 loss: 0.0905141830444336
Batch 25/64 loss: 0.56536865234375
Batch 26/64 loss: 1.003370761871338
Batch 27/64 loss: 0.6071572303771973
Batch 28/64 loss: 0.74627685546875
Batch 29/64 loss: 0.44162893295288086
Batch 30/64 loss: 0.7457194328308105
Batch 31/64 loss: 0.5459141731262207
Batch 32/64 loss: 0.6287741661071777
Batch 33/64 loss: 0.3511629104614258
Batch 34/64 loss: 0.5923609733581543
Batch 35/64 loss: 0.45319223403930664
Batch 36/64 loss: 0.4143185615539551
Batch 37/64 loss: 0.6583929061889648
Batch 38/64 loss: 0.9242391586303711
Batch 39/64 loss: 1.8447527885437012
Batch 40/64 loss: 0.7528538703918457
Batch 41/64 loss: 0.8563966751098633
Batch 42/64 loss: 0.6733083724975586
Batch 43/64 loss: 0.48563432693481445
Batch 44/64 loss: 0.8945932388305664
Batch 45/64 loss: 0.7723293304443359
Batch 46/64 loss: 0.4040994644165039
Batch 47/64 loss: 0.47429466247558594
Batch 48/64 loss: 0.8298397064208984
Batch 49/64 loss: 0.7828636169433594
Batch 50/64 loss: 0.3527188301086426
Batch 51/64 loss: 1.3154892921447754
Batch 52/64 loss: 0.9688735008239746
Batch 53/64 loss: 0.7513589859008789
Batch 54/64 loss: 0.7000160217285156
Batch 55/64 loss: 0.9073576927185059
Batch 56/64 loss: 0.5282020568847656
Batch 57/64 loss: 0.6933088302612305
Batch 58/64 loss: 0.35464000701904297
Batch 59/64 loss: 1.0186519622802734
Batch 60/64 loss: 0.9430537223815918
Batch 61/64 loss: 0.6490111351013184
Batch 62/64 loss: 1.0880684852600098
Batch 63/64 loss: 0.6469030380249023
Batch 64/64 loss: -2.968113422393799
Epoch 20  Train loss: 0.6483293140635771  Val loss: 0.5629606345265182
Epoch 21
-------------------------------
Batch 1/64 loss: 0.7641000747680664
Batch 2/64 loss: 0.7600626945495605
Batch 3/64 loss: 0.6709704399108887
Batch 4/64 loss: 0.8682646751403809
Batch 5/64 loss: 0.5951728820800781
Batch 6/64 loss: 0.6894588470458984
Batch 7/64 loss: 0.3871169090270996
Batch 8/64 loss: 1.1252565383911133
Batch 9/64 loss: 0.9010634422302246
Batch 10/64 loss: 1.0140838623046875
Batch 11/64 loss: 0.7388720512390137
Batch 12/64 loss: 0.3607797622680664
Batch 13/64 loss: 0.7013382911682129
Batch 14/64 loss: 0.5668606758117676
Batch 15/64 loss: 0.38823795318603516
Batch 16/64 loss: 0.6660561561584473
Batch 17/64 loss: 0.5802836418151855
Batch 18/64 loss: 0.5620889663696289
Batch 19/64 loss: 0.6216335296630859
Batch 20/64 loss: 0.7254829406738281
Batch 21/64 loss: 0.9024810791015625
Batch 22/64 loss: 0.3208298683166504
Batch 23/64 loss: 0.4176764488220215
Batch 24/64 loss: 0.32319211959838867
Batch 25/64 loss: 0.2148609161376953
Batch 26/64 loss: 0.9089655876159668
Batch 27/64 loss: 0.4969320297241211
Batch 28/64 loss: 1.0309524536132812
Batch 29/64 loss: 1.3987746238708496
Batch 30/64 loss: 0.3259286880493164
Batch 31/64 loss: 0.5051350593566895
Batch 32/64 loss: 0.3817424774169922
Batch 33/64 loss: 1.1420903205871582
Batch 34/64 loss: 0.6770467758178711
Batch 35/64 loss: 0.5657463073730469
Batch 36/64 loss: 0.2613401412963867
Batch 37/64 loss: 0.8652024269104004
Batch 38/64 loss: 0.2943305969238281
Batch 39/64 loss: 0.9346837997436523
Batch 40/64 loss: 0.3654189109802246
Batch 41/64 loss: 0.849482536315918
Batch 42/64 loss: 0.37856531143188477
Batch 43/64 loss: 0.5294570922851562
Batch 44/64 loss: 0.5807356834411621
Batch 45/64 loss: 0.5832557678222656
Batch 46/64 loss: 0.5586709976196289
Batch 47/64 loss: 1.018951416015625
Batch 48/64 loss: 0.912269115447998
Batch 49/64 loss: 0.9704937934875488
Batch 50/64 loss: 0.8478741645812988
Batch 51/64 loss: 0.4303889274597168
Batch 52/64 loss: 0.4747633934020996
Batch 53/64 loss: 0.41971349716186523
Batch 54/64 loss: 0.3658633232116699
Batch 55/64 loss: 0.45223426818847656
Batch 56/64 loss: 0.17722272872924805
Batch 57/64 loss: 0.5191144943237305
Batch 58/64 loss: 0.39678478240966797
Batch 59/64 loss: 0.7779192924499512
Batch 60/64 loss: 0.7070879936218262
Batch 61/64 loss: 0.6640753746032715
Batch 62/64 loss: 0.9647960662841797
Batch 63/64 loss: 0.3646378517150879
Batch 64/64 loss: -2.165221691131592
Epoch 21  Train loss: 0.6014267697053797  Val loss: 0.48410899368758054
Saving best model, epoch: 21
Epoch 22
-------------------------------
Batch 1/64 loss: 0.2803964614868164
Batch 2/64 loss: 0.5953540802001953
Batch 3/64 loss: 0.7417469024658203
Batch 4/64 loss: 0.6535778045654297
Batch 5/64 loss: 0.4628877639770508
Batch 6/64 loss: 0.20984649658203125
Batch 7/64 loss: 0.7947969436645508
Batch 8/64 loss: 0.6433110237121582
Batch 9/64 loss: 0.3864293098449707
Batch 10/64 loss: 0.7345280647277832
Batch 11/64 loss: 0.6744804382324219
Batch 12/64 loss: 1.0323915481567383
Batch 13/64 loss: 0.4762840270996094
Batch 14/64 loss: 1.250502109527588
Batch 15/64 loss: 0.3620281219482422
Batch 16/64 loss: 0.3328700065612793
Batch 17/64 loss: 1.0268216133117676
Batch 18/64 loss: 0.3194088935852051
Batch 19/64 loss: 0.7490386962890625
Batch 20/64 loss: 0.3066368103027344
Batch 21/64 loss: 0.8618035316467285
Batch 22/64 loss: 0.7085719108581543
Batch 23/64 loss: 0.5637316703796387
Batch 24/64 loss: 0.436704158782959
Batch 25/64 loss: 0.22945690155029297
Batch 26/64 loss: 0.4387693405151367
Batch 27/64 loss: 0.9073982238769531
Batch 28/64 loss: 0.3254814147949219
Batch 29/64 loss: 0.7682404518127441
Batch 30/64 loss: 0.21772289276123047
Batch 31/64 loss: 0.4264564514160156
Batch 32/64 loss: 0.6473007202148438
Batch 33/64 loss: 1.1324267387390137
Batch 34/64 loss: 0.40030860900878906
Batch 35/64 loss: 0.8140444755554199
Batch 36/64 loss: 0.9454479217529297
Batch 37/64 loss: 0.41074037551879883
Batch 38/64 loss: 0.7132210731506348
Batch 39/64 loss: 0.4995718002319336
Batch 40/64 loss: 0.05451774597167969
Batch 41/64 loss: 0.2929806709289551
Batch 42/64 loss: 0.5311956405639648
Batch 43/64 loss: 0.2951183319091797
Batch 44/64 loss: 0.9687490463256836
Batch 45/64 loss: 0.7540245056152344
Batch 46/64 loss: 0.8287310600280762
Batch 47/64 loss: 0.2804732322692871
Batch 48/64 loss: 0.5048913955688477
Batch 49/64 loss: 0.5740838050842285
Batch 50/64 loss: 0.5852766036987305
Batch 51/64 loss: 0.7465729713439941
Batch 52/64 loss: 0.4466366767883301
Batch 53/64 loss: 0.6691460609436035
Batch 54/64 loss: 0.0612483024597168
Batch 55/64 loss: 0.4922184944152832
Batch 56/64 loss: 0.535191535949707
Batch 57/64 loss: 0.4378995895385742
Batch 58/64 loss: 0.6904535293579102
Batch 59/64 loss: 0.7988858222961426
Batch 60/64 loss: 0.6227679252624512
Batch 61/64 loss: 0.3450336456298828
Batch 62/64 loss: 0.3896641731262207
Batch 63/64 loss: 0.5538802146911621
Batch 64/64 loss: -3.557711601257324
Epoch 22  Train loss: 0.5219151852177638  Val loss: 0.4059308238865174
Saving best model, epoch: 22
Epoch 23
-------------------------------
Batch 1/64 loss: 0.6610622406005859
Batch 2/64 loss: 0.3122272491455078
Batch 3/64 loss: 0.17305660247802734
Batch 4/64 loss: 0.409578800201416
Batch 5/64 loss: 0.13817119598388672
Batch 6/64 loss: 0.5917887687683105
Batch 7/64 loss: 0.4175434112548828
Batch 8/64 loss: 0.6186599731445312
Batch 9/64 loss: 0.21800470352172852
Batch 10/64 loss: 1.2736191749572754
Batch 11/64 loss: 0.39751243591308594
Batch 12/64 loss: 0.6119809150695801
Batch 13/64 loss: 0.3000507354736328
Batch 14/64 loss: 0.7199268341064453
Batch 15/64 loss: 0.7431106567382812
Batch 16/64 loss: 0.6045589447021484
Batch 17/64 loss: 0.19324827194213867
Batch 18/64 loss: -0.07747888565063477
Batch 19/64 loss: 1.620572566986084
Batch 20/64 loss: 0.008583545684814453
Batch 21/64 loss: 0.5721025466918945
Batch 22/64 loss: 0.39151620864868164
Batch 23/64 loss: 0.4432663917541504
Batch 24/64 loss: 0.6379656791687012
Batch 25/64 loss: 0.3608980178833008
Batch 26/64 loss: 0.4945812225341797
Batch 27/64 loss: 0.5993294715881348
Batch 28/64 loss: 0.45410871505737305
Batch 29/64 loss: 0.5279159545898438
Batch 30/64 loss: 0.1491537094116211
Batch 31/64 loss: 0.672978401184082
Batch 32/64 loss: 0.4067249298095703
Batch 33/64 loss: 0.6133260726928711
Batch 34/64 loss: 0.8801970481872559
Batch 35/64 loss: 0.501121997833252
Batch 36/64 loss: 0.03611135482788086
Batch 37/64 loss: 0.2900056838989258
Batch 38/64 loss: 0.6830525398254395
Batch 39/64 loss: 1.1334023475646973
Batch 40/64 loss: 0.08596134185791016
Batch 41/64 loss: 0.5465817451477051
Batch 42/64 loss: 0.4228501319885254
Batch 43/64 loss: 0.4510331153869629
Batch 44/64 loss: 0.5812673568725586
Batch 45/64 loss: 0.5286059379577637
Batch 46/64 loss: 0.31284046173095703
Batch 47/64 loss: 0.32647037506103516
Batch 48/64 loss: 0.445587158203125
Batch 49/64 loss: 0.4936976432800293
Batch 50/64 loss: 0.8982396125793457
Batch 51/64 loss: 0.25409507751464844
Batch 52/64 loss: 0.38818979263305664
Batch 53/64 loss: 0.4828495979309082
Batch 54/64 loss: 0.25896167755126953
Batch 55/64 loss: 0.37783336639404297
Batch 56/64 loss: 0.8451423645019531
Batch 57/64 loss: 0.2365880012512207
Batch 58/64 loss: 1.012220859527588
Batch 59/64 loss: 0.2390761375427246
Batch 60/64 loss: 0.5384888648986816
Batch 61/64 loss: 0.07566213607788086
Batch 62/64 loss: 0.6336379051208496
Batch 63/64 loss: 0.18191003799438477
Batch 64/64 loss: -3.0268678665161133
Epoch 23  Train loss: 0.44127335267908435  Val loss: 0.5575956102089374
Epoch 24
-------------------------------
Batch 1/64 loss: 0.007527828216552734
Batch 2/64 loss: 0.3941330909729004
Batch 3/64 loss: 1.0656061172485352
Batch 4/64 loss: 0.6142101287841797
Batch 5/64 loss: 0.649479866027832
Batch 6/64 loss: 0.5958008766174316
Batch 7/64 loss: 0.747431755065918
Batch 8/64 loss: 0.6218891143798828
Batch 9/64 loss: 2.067326068878174
Batch 10/64 loss: 0.5724701881408691
Batch 11/64 loss: 1.0856552124023438
Batch 12/64 loss: 0.6330165863037109
Batch 13/64 loss: 1.0315933227539062
Batch 14/64 loss: 1.0180892944335938
Batch 15/64 loss: 1.6855401992797852
Batch 16/64 loss: 0.9534621238708496
Batch 17/64 loss: 1.2927303314208984
Batch 18/64 loss: 0.7498664855957031
Batch 19/64 loss: 1.0528440475463867
Batch 20/64 loss: 0.6676540374755859
Batch 21/64 loss: 0.7848634719848633
Batch 22/64 loss: 0.5745606422424316
Batch 23/64 loss: 0.8456940650939941
Batch 24/64 loss: 0.7030024528503418
Batch 25/64 loss: 0.49535465240478516
Batch 26/64 loss: 0.7683801651000977
Batch 27/64 loss: 0.5908188819885254
Batch 28/64 loss: 0.5411992073059082
Batch 29/64 loss: 0.4119296073913574
Batch 30/64 loss: 0.5222835540771484
Batch 31/64 loss: 0.48443603515625
Batch 32/64 loss: 0.5377068519592285
Batch 33/64 loss: 0.9314107894897461
Batch 34/64 loss: 0.19442987442016602
Batch 35/64 loss: 1.2517890930175781
Batch 36/64 loss: 0.37021970748901367
Batch 37/64 loss: 0.6772713661193848
Batch 38/64 loss: 0.5553174018859863
Batch 39/64 loss: 0.49646759033203125
Batch 40/64 loss: 0.3981466293334961
Batch 41/64 loss: 0.6855087280273438
Batch 42/64 loss: 0.3626275062561035
Batch 43/64 loss: 0.37344980239868164
Batch 44/64 loss: 0.29987621307373047
Batch 45/64 loss: 0.4437565803527832
Batch 46/64 loss: 0.09316635131835938
Batch 47/64 loss: 1.1121835708618164
Batch 48/64 loss: 0.723452091217041
Batch 49/64 loss: 0.8952693939208984
Batch 50/64 loss: 0.3886756896972656
Batch 51/64 loss: 0.47933530807495117
Batch 52/64 loss: 1.1908392906188965
Batch 53/64 loss: 0.5928411483764648
Batch 54/64 loss: 0.5470399856567383
Batch 55/64 loss: 0.8839178085327148
Batch 56/64 loss: 0.38222742080688477
Batch 57/64 loss: 0.5319538116455078
Batch 58/64 loss: 0.8458347320556641
Batch 59/64 loss: 0.3372645378112793
Batch 60/64 loss: 0.7029438018798828
Batch 61/64 loss: 0.17844247817993164
Batch 62/64 loss: 0.45762109756469727
Batch 63/64 loss: 0.506129264831543
Batch 64/64 loss: -3.1910018920898438
Epoch 24  Train loss: 0.6315719828886144  Val loss: 0.39367784585330085
Saving best model, epoch: 24
Epoch 25
-------------------------------
Batch 1/64 loss: 0.15041446685791016
Batch 2/64 loss: 0.6440491676330566
Batch 3/64 loss: 0.8010797500610352
Batch 4/64 loss: 0.5199618339538574
Batch 5/64 loss: 0.11254215240478516
Batch 6/64 loss: 0.4131784439086914
Batch 7/64 loss: -0.02161693572998047
Batch 8/64 loss: 0.3113217353820801
Batch 9/64 loss: 1.044877052307129
Batch 10/64 loss: 0.6771092414855957
Batch 11/64 loss: 0.6395387649536133
Batch 12/64 loss: 0.7976012229919434
Batch 13/64 loss: 0.5742635726928711
Batch 14/64 loss: 0.46269702911376953
Batch 15/64 loss: 0.9465031623840332
Batch 16/64 loss: 0.5539536476135254
Batch 17/64 loss: 0.09795999526977539
Batch 18/64 loss: 0.4681363105773926
Batch 19/64 loss: 0.4033322334289551
Batch 20/64 loss: 0.34973812103271484
Batch 21/64 loss: 0.3383827209472656
Batch 22/64 loss: 0.31766748428344727
Batch 23/64 loss: 0.0524749755859375
Batch 24/64 loss: 0.928257942199707
Batch 25/64 loss: 0.2903175354003906
Batch 26/64 loss: 0.0977640151977539
Batch 27/64 loss: 0.2447061538696289
Batch 28/64 loss: 0.2726912498474121
Batch 29/64 loss: 0.6811771392822266
Batch 30/64 loss: 0.658994197845459
Batch 31/64 loss: 0.5371332168579102
Batch 32/64 loss: 0.7192282676696777
Batch 33/64 loss: 0.2581639289855957
Batch 34/64 loss: 0.4398531913757324
Batch 35/64 loss: 0.6099433898925781
Batch 36/64 loss: 0.7508130073547363
Batch 37/64 loss: 0.09579706192016602
Batch 38/64 loss: 0.8565778732299805
Batch 39/64 loss: 0.41883087158203125
Batch 40/64 loss: 1.216322898864746
Batch 41/64 loss: 0.3645973205566406
Batch 42/64 loss: 0.06295442581176758
Batch 43/64 loss: 0.7156448364257812
Batch 44/64 loss: 1.6214685440063477
Batch 45/64 loss: 0.5265393257141113
Batch 46/64 loss: 0.15869760513305664
Batch 47/64 loss: 0.8814659118652344
Batch 48/64 loss: 0.19471502304077148
Batch 49/64 loss: 0.4533982276916504
Batch 50/64 loss: 0.7276568412780762
Batch 51/64 loss: 0.8363075256347656
Batch 52/64 loss: 0.3606996536254883
Batch 53/64 loss: 1.170267105102539
Batch 54/64 loss: 0.3305530548095703
Batch 55/64 loss: 0.5007061958312988
Batch 56/64 loss: 0.25997447967529297
Batch 57/64 loss: 0.6634106636047363
Batch 58/64 loss: -0.05832386016845703
Batch 59/64 loss: 0.09378576278686523
Batch 60/64 loss: 0.5061869621276855
Batch 61/64 loss: 0.5466303825378418
Batch 62/64 loss: 0.9251875877380371
Batch 63/64 loss: 0.07234048843383789
Batch 64/64 loss: -3.5380172729492188
Epoch 25  Train loss: 0.4547935560637829  Val loss: 0.3855180642039506
Saving best model, epoch: 25
Epoch 26
-------------------------------
Batch 1/64 loss: 1.0447759628295898
Batch 2/64 loss: 0.025916099548339844
Batch 3/64 loss: 0.28380680084228516
Batch 4/64 loss: 0.6155781745910645
Batch 5/64 loss: 0.42479896545410156
Batch 6/64 loss: 0.1083383560180664
Batch 7/64 loss: 0.42005014419555664
Batch 8/64 loss: 0.39452600479125977
Batch 9/64 loss: 0.20682621002197266
Batch 10/64 loss: 0.192840576171875
Batch 11/64 loss: 0.36023712158203125
Batch 12/64 loss: 0.3993840217590332
Batch 13/64 loss: 0.4187192916870117
Batch 14/64 loss: 0.1649951934814453
Batch 15/64 loss: 0.3744196891784668
Batch 16/64 loss: 0.236236572265625
Batch 17/64 loss: 0.710350513458252
Batch 18/64 loss: 0.02690744400024414
Batch 19/64 loss: 0.18400096893310547
Batch 20/64 loss: 0.30061864852905273
Batch 21/64 loss: 0.1681509017944336
Batch 22/64 loss: 0.5451130867004395
Batch 23/64 loss: 0.4307436943054199
Batch 24/64 loss: 0.6110439300537109
Batch 25/64 loss: 0.4405198097229004
Batch 26/64 loss: 0.5105056762695312
Batch 27/64 loss: 0.40053510665893555
Batch 28/64 loss: 0.1994924545288086
Batch 29/64 loss: 0.3271780014038086
Batch 30/64 loss: 0.4229598045349121
Batch 31/64 loss: 0.2916741371154785
Batch 32/64 loss: 0.3811182975769043
Batch 33/64 loss: 0.7480196952819824
Batch 34/64 loss: 1.0956225395202637
Batch 35/64 loss: 0.20654535293579102
Batch 36/64 loss: 0.49176645278930664
Batch 37/64 loss: 0.4674215316772461
Batch 38/64 loss: 0.2806282043457031
Batch 39/64 loss: 0.6867499351501465
Batch 40/64 loss: 0.11427736282348633
Batch 41/64 loss: 0.39685678482055664
Batch 42/64 loss: 0.36020326614379883
Batch 43/64 loss: 0.3795795440673828
Batch 44/64 loss: 0.3505067825317383
Batch 45/64 loss: 1.3002729415893555
Batch 46/64 loss: 0.2124185562133789
Batch 47/64 loss: 0.09596967697143555
Batch 48/64 loss: 0.21986103057861328
Batch 49/64 loss: 0.7687439918518066
Batch 50/64 loss: 0.6596980094909668
Batch 51/64 loss: -0.0054264068603515625
Batch 52/64 loss: 0.48786401748657227
Batch 53/64 loss: 0.24112558364868164
Batch 54/64 loss: 0.7555041313171387
Batch 55/64 loss: 0.7159886360168457
Batch 56/64 loss: 0.1696319580078125
Batch 57/64 loss: 0.4281501770019531
Batch 58/64 loss: 0.6846141815185547
Batch 59/64 loss: 0.4539613723754883
Batch 60/64 loss: 0.3576936721801758
Batch 61/64 loss: -0.22626447677612305
Batch 62/64 loss: 0.4067964553833008
Batch 63/64 loss: 0.5139636993408203
Batch 64/64 loss: -3.517868995666504
Epoch 26  Train loss: 0.35768948349298213  Val loss: 0.40762412998684494
Epoch 27
-------------------------------
Batch 1/64 loss: 1.8595576286315918
Batch 2/64 loss: 0.2062511444091797
Batch 3/64 loss: 0.3085646629333496
Batch 4/64 loss: 1.0272679328918457
Batch 5/64 loss: 0.10920381546020508
Batch 6/64 loss: 0.7710609436035156
Batch 7/64 loss: 0.5791373252868652
Batch 8/64 loss: 0.44603729248046875
Batch 9/64 loss: 0.3222675323486328
Batch 10/64 loss: 0.7573757171630859
Batch 11/64 loss: 0.31536293029785156
Batch 12/64 loss: 0.10085248947143555
Batch 13/64 loss: 0.22819948196411133
Batch 14/64 loss: 0.2053203582763672
Batch 15/64 loss: -0.17595148086547852
Batch 16/64 loss: 0.5727396011352539
Batch 17/64 loss: 0.055884361267089844
Batch 18/64 loss: 0.3589663505554199
Batch 19/64 loss: 0.25613975524902344
Batch 20/64 loss: 0.0990447998046875
Batch 21/64 loss: 0.0400390625
Batch 22/64 loss: 0.4341297149658203
Batch 23/64 loss: 0.3725013732910156
Batch 24/64 loss: 0.22220563888549805
Batch 25/64 loss: 0.36595916748046875
Batch 26/64 loss: 0.38247203826904297
Batch 27/64 loss: 0.5347781181335449
Batch 28/64 loss: 0.12733793258666992
Batch 29/64 loss: 0.4107632637023926
Batch 30/64 loss: 0.9976925849914551
Batch 31/64 loss: 1.003568172454834
Batch 32/64 loss: 0.3446083068847656
Batch 33/64 loss: 0.02803659439086914
Batch 34/64 loss: 0.2631344795227051
Batch 35/64 loss: 0.37450504302978516
Batch 36/64 loss: 0.10258769989013672
Batch 37/64 loss: 0.5398859977722168
Batch 38/64 loss: 1.073824405670166
Batch 39/64 loss: 0.6606664657592773
Batch 40/64 loss: -0.13121604919433594
Batch 41/64 loss: 0.1058955192565918
Batch 42/64 loss: 0.12314939498901367
Batch 43/64 loss: 0.3327813148498535
Batch 44/64 loss: 0.1756134033203125
Batch 45/64 loss: 0.37439537048339844
Batch 46/64 loss: 0.31910085678100586
Batch 47/64 loss: 0.645167350769043
Batch 48/64 loss: 0.18820762634277344
Batch 49/64 loss: 0.4047112464904785
Batch 50/64 loss: 0.3258085250854492
Batch 51/64 loss: 0.5427632331848145
Batch 52/64 loss: 0.01284170150756836
Batch 53/64 loss: 0.6530303955078125
Batch 54/64 loss: 0.46756792068481445
Batch 55/64 loss: 0.28638696670532227
Batch 56/64 loss: 0.37880754470825195
Batch 57/64 loss: 0.3558673858642578
Batch 58/64 loss: 0.35039615631103516
Batch 59/64 loss: 0.451810359954834
Batch 60/64 loss: 0.09434032440185547
Batch 61/64 loss: 0.6740503311157227
Batch 62/64 loss: 0.1661381721496582
Batch 63/64 loss: 0.16352081298828125
Batch 64/64 loss: -3.7268600463867188
Epoch 27  Train loss: 0.3348701103060853  Val loss: 0.211415595615033
Saving best model, epoch: 27
Epoch 28
-------------------------------
Batch 1/64 loss: 1.5626411437988281
Batch 2/64 loss: 0.09657049179077148
Batch 3/64 loss: 0.15981435775756836
Batch 4/64 loss: 0.7251825332641602
Batch 5/64 loss: 0.5342245101928711
Batch 6/64 loss: 0.38741016387939453
Batch 7/64 loss: 0.5797324180603027
Batch 8/64 loss: 0.8224048614501953
Batch 9/64 loss: 0.7691445350646973
Batch 10/64 loss: 0.8757410049438477
Batch 11/64 loss: 0.8608288764953613
Batch 12/64 loss: 0.04877901077270508
Batch 13/64 loss: -0.025628089904785156
Batch 14/64 loss: 0.1580491065979004
Batch 15/64 loss: 0.4829277992248535
Batch 16/64 loss: 0.5681853294372559
Batch 17/64 loss: 0.7950897216796875
Batch 18/64 loss: 0.5615549087524414
Batch 19/64 loss: 1.0202488899230957
Batch 20/64 loss: 1.1277074813842773
Batch 21/64 loss: 1.0056695938110352
Batch 22/64 loss: 0.745509147644043
Batch 23/64 loss: 1.0757842063903809
Batch 24/64 loss: 0.480898380279541
Batch 25/64 loss: 0.6251726150512695
Batch 26/64 loss: 0.34352731704711914
Batch 27/64 loss: 0.027225494384765625
Batch 28/64 loss: 0.4921121597290039
Batch 29/64 loss: 1.2642173767089844
Batch 30/64 loss: 0.7550740242004395
Batch 31/64 loss: 0.23959732055664062
Batch 32/64 loss: 0.42185211181640625
Batch 33/64 loss: 0.5356287956237793
Batch 34/64 loss: -0.02971029281616211
Batch 35/64 loss: 0.8613324165344238
Batch 36/64 loss: 0.256929874420166
Batch 37/64 loss: 0.4323849678039551
Batch 38/64 loss: 0.2108001708984375
Batch 39/64 loss: 0.12229442596435547
Batch 40/64 loss: 0.6721158027648926
Batch 41/64 loss: 0.10328006744384766
Batch 42/64 loss: 0.717557430267334
Batch 43/64 loss: 0.7687258720397949
Batch 44/64 loss: 0.4003748893737793
Batch 45/64 loss: 0.22206544876098633
Batch 46/64 loss: 0.41538095474243164
Batch 47/64 loss: 0.48378753662109375
Batch 48/64 loss: 0.19614791870117188
Batch 49/64 loss: 0.43003273010253906
Batch 50/64 loss: 0.012792110443115234
Batch 51/64 loss: 0.12889957427978516
Batch 52/64 loss: 0.38143062591552734
Batch 53/64 loss: 0.49305105209350586
Batch 54/64 loss: 0.9676833152770996
Batch 55/64 loss: 0.5096406936645508
Batch 56/64 loss: 0.5773844718933105
Batch 57/64 loss: 0.1386408805847168
Batch 58/64 loss: 0.05952167510986328
Batch 59/64 loss: 0.19711971282958984
Batch 60/64 loss: 0.4252190589904785
Batch 61/64 loss: 0.7044229507446289
Batch 62/64 loss: 0.5145206451416016
Batch 63/64 loss: 0.09359169006347656
Batch 64/64 loss: -3.740593910217285
Epoch 28  Train loss: 0.45152707193412034  Val loss: 0.19775437817131122
Saving best model, epoch: 28
Epoch 29
-------------------------------
Batch 1/64 loss: 0.47745800018310547
Batch 2/64 loss: 0.6691546440124512
Batch 3/64 loss: -0.13413381576538086
Batch 4/64 loss: 0.3680543899536133
Batch 5/64 loss: 0.7046332359313965
Batch 6/64 loss: 0.2058854103088379
Batch 7/64 loss: 0.03194427490234375
Batch 8/64 loss: 0.12313508987426758
Batch 9/64 loss: 0.15900468826293945
Batch 10/64 loss: 0.07975053787231445
Batch 11/64 loss: 0.616610050201416
Batch 12/64 loss: 0.4743938446044922
Batch 13/64 loss: 0.6360559463500977
Batch 14/64 loss: 0.3707094192504883
Batch 15/64 loss: 0.05306720733642578
Batch 16/64 loss: 0.31972169876098633
Batch 17/64 loss: 1.2674307823181152
Batch 18/64 loss: 0.5164623260498047
Batch 19/64 loss: 0.2353076934814453
Batch 20/64 loss: 0.80902099609375
Batch 21/64 loss: 0.40470027923583984
Batch 22/64 loss: 0.3646693229675293
Batch 23/64 loss: 0.12308120727539062
Batch 24/64 loss: 0.6115636825561523
Batch 25/64 loss: 0.753201961517334
Batch 26/64 loss: 0.14835119247436523
Batch 27/64 loss: 0.2714052200317383
Batch 28/64 loss: 0.6539020538330078
Batch 29/64 loss: 0.3967857360839844
Batch 30/64 loss: -0.01360940933227539
Batch 31/64 loss: 0.11317300796508789
Batch 32/64 loss: 0.10730171203613281
Batch 33/64 loss: 0.17310476303100586
Batch 34/64 loss: 0.7494039535522461
Batch 35/64 loss: 0.2704191207885742
Batch 36/64 loss: 0.2184453010559082
Batch 37/64 loss: 0.0728607177734375
Batch 38/64 loss: 0.3171195983886719
Batch 39/64 loss: 0.3093719482421875
Batch 40/64 loss: 0.7021870613098145
Batch 41/64 loss: 0.5654749870300293
Batch 42/64 loss: 0.5094871520996094
Batch 43/64 loss: 0.28649377822875977
Batch 44/64 loss: 0.19437885284423828
Batch 45/64 loss: 0.41524410247802734
Batch 46/64 loss: 0.9408912658691406
Batch 47/64 loss: 0.5719094276428223
Batch 48/64 loss: 1.0219616889953613
Batch 49/64 loss: -0.017871379852294922
Batch 50/64 loss: 0.40650510787963867
Batch 51/64 loss: 0.24086904525756836
Batch 52/64 loss: 0.28038835525512695
Batch 53/64 loss: 0.21192502975463867
Batch 54/64 loss: 0.5336251258850098
Batch 55/64 loss: 0.5128164291381836
Batch 56/64 loss: 0.6060090065002441
Batch 57/64 loss: 0.14194774627685547
Batch 58/64 loss: 0.8218321800231934
Batch 59/64 loss: 0.1110219955444336
Batch 60/64 loss: 0.33793067932128906
Batch 61/64 loss: 0.4823465347290039
Batch 62/64 loss: 0.03815412521362305
Batch 63/64 loss: 0.19838476181030273
Batch 64/64 loss: -3.5805540084838867
Epoch 29  Train loss: 0.3365869073306813  Val loss: 0.1693337823926788
Saving best model, epoch: 29
Epoch 30
-------------------------------
Batch 1/64 loss: 0.6774134635925293
Batch 2/64 loss: 0.07962179183959961
Batch 3/64 loss: 0.5394473075866699
Batch 4/64 loss: 0.7426576614379883
Batch 5/64 loss: 0.5931839942932129
Batch 6/64 loss: 0.0625920295715332
Batch 7/64 loss: 0.908383846282959
Batch 8/64 loss: 0.7681174278259277
Batch 9/64 loss: -0.13811206817626953
Batch 10/64 loss: 0.09573078155517578
Batch 11/64 loss: 0.5524334907531738
Batch 12/64 loss: 0.34085559844970703
Batch 13/64 loss: -0.26312875747680664
Batch 14/64 loss: 0.027420997619628906
Batch 15/64 loss: 0.532294750213623
Batch 16/64 loss: 0.26186132431030273
Batch 17/64 loss: 0.48998403549194336
Batch 18/64 loss: 0.9210658073425293
Batch 19/64 loss: 0.6886563301086426
Batch 20/64 loss: 0.15996551513671875
Batch 21/64 loss: 0.13096857070922852
Batch 22/64 loss: -0.06866455078125
Batch 23/64 loss: 0.07817220687866211
Batch 24/64 loss: 0.07631206512451172
Batch 25/64 loss: 0.041626930236816406
Batch 26/64 loss: 0.31612348556518555
Batch 27/64 loss: 0.3925333023071289
Batch 28/64 loss: 0.4058060646057129
Batch 29/64 loss: 0.19411420822143555
Batch 30/64 loss: 0.3969578742980957
Batch 31/64 loss: -0.05197334289550781
Batch 32/64 loss: 0.3178133964538574
Batch 33/64 loss: -0.07574987411499023
Batch 34/64 loss: 0.315218448638916
Batch 35/64 loss: 0.5081348419189453
Batch 36/64 loss: 0.2738800048828125
Batch 37/64 loss: 0.13772058486938477
Batch 38/64 loss: -0.030478477478027344
Batch 39/64 loss: -0.04868650436401367
Batch 40/64 loss: 0.10720062255859375
Batch 41/64 loss: 0.46730470657348633
Batch 42/64 loss: 0.11515569686889648
Batch 43/64 loss: 0.5341377258300781
Batch 44/64 loss: 0.1489582061767578
Batch 45/64 loss: 0.13152790069580078
Batch 46/64 loss: 0.4388008117675781
Batch 47/64 loss: 0.05848503112792969
Batch 48/64 loss: 1.0792946815490723
Batch 49/64 loss: 0.2348947525024414
Batch 50/64 loss: 0.4690232276916504
Batch 51/64 loss: 0.22356510162353516
Batch 52/64 loss: 0.8403992652893066
Batch 53/64 loss: 0.26389408111572266
Batch 54/64 loss: 0.3040189743041992
Batch 55/64 loss: -0.04635810852050781
Batch 56/64 loss: 0.16507387161254883
Batch 57/64 loss: 0.2913479804992676
Batch 58/64 loss: 0.29404163360595703
Batch 59/64 loss: 0.019073486328125
Batch 60/64 loss: 0.043752193450927734
Batch 61/64 loss: 0.06905937194824219
Batch 62/64 loss: 0.6151461601257324
Batch 63/64 loss: -0.3124070167541504
Batch 64/64 loss: -3.637373447418213
Epoch 30  Train loss: 0.23808054643518783  Val loss: 0.12627447593662747
Saving best model, epoch: 30
Epoch 31
-------------------------------
Batch 1/64 loss: 0.07267427444458008
Batch 2/64 loss: 0.1887378692626953
Batch 3/64 loss: 0.08934688568115234
Batch 4/64 loss: 0.04728364944458008
Batch 5/64 loss: 0.24618244171142578
Batch 6/64 loss: 0.3488197326660156
Batch 7/64 loss: 0.11529827117919922
Batch 8/64 loss: 0.43039560317993164
Batch 9/64 loss: 0.1063385009765625
Batch 10/64 loss: 0.2435760498046875
Batch 11/64 loss: 0.22555208206176758
Batch 12/64 loss: 0.37906789779663086
Batch 13/64 loss: 0.2608675956726074
Batch 14/64 loss: 0.33310890197753906
Batch 15/64 loss: 0.11492252349853516
Batch 16/64 loss: 0.6491632461547852
Batch 17/64 loss: 0.39954566955566406
Batch 18/64 loss: 0.09488582611083984
Batch 19/64 loss: -0.15205097198486328
Batch 20/64 loss: 0.1480717658996582
Batch 21/64 loss: 0.4339466094970703
Batch 22/64 loss: 0.34151458740234375
Batch 23/64 loss: 0.13545465469360352
Batch 24/64 loss: -0.13330698013305664
Batch 25/64 loss: 0.23848915100097656
Batch 26/64 loss: -0.14453506469726562
Batch 27/64 loss: 0.13919448852539062
Batch 28/64 loss: 0.5877609252929688
Batch 29/64 loss: 0.05714988708496094
Batch 30/64 loss: 0.47553396224975586
Batch 31/64 loss: 0.07482147216796875
Batch 32/64 loss: 0.25433921813964844
Batch 33/64 loss: -0.2896575927734375
Batch 34/64 loss: -0.23298883438110352
Batch 35/64 loss: 0.5303034782409668
Batch 36/64 loss: 0.2489614486694336
Batch 37/64 loss: 0.46832799911499023
Batch 38/64 loss: -0.03591489791870117
Batch 39/64 loss: 0.20415830612182617
Batch 40/64 loss: 0.28853416442871094
Batch 41/64 loss: -0.20091581344604492
Batch 42/64 loss: 0.23479843139648438
Batch 43/64 loss: 0.24237680435180664
Batch 44/64 loss: 0.3966050148010254
Batch 45/64 loss: 0.16749858856201172
Batch 46/64 loss: 0.12647581100463867
Batch 47/64 loss: 0.23795318603515625
Batch 48/64 loss: -0.1436009407043457
Batch 49/64 loss: -0.08174848556518555
Batch 50/64 loss: 0.35790443420410156
Batch 51/64 loss: -0.020678997039794922
Batch 52/64 loss: 0.09771442413330078
Batch 53/64 loss: 1.0679163932800293
Batch 54/64 loss: 0.6194925308227539
Batch 55/64 loss: 0.19214582443237305
Batch 56/64 loss: 0.881584644317627
Batch 57/64 loss: 0.5641436576843262
Batch 58/64 loss: -0.09362268447875977
Batch 59/64 loss: 0.3928098678588867
Batch 60/64 loss: 0.553718090057373
Batch 61/64 loss: 0.05072164535522461
Batch 62/64 loss: -0.05363798141479492
Batch 63/64 loss: 0.31258535385131836
Batch 64/64 loss: -3.5308990478515625
Epoch 31  Train loss: 0.17628141664991193  Val loss: 0.15542323318953366
Epoch 32
-------------------------------
Batch 1/64 loss: 0.21587800979614258
Batch 2/64 loss: -0.2188892364501953
Batch 3/64 loss: 0.10826873779296875
Batch 4/64 loss: 0.5098171234130859
Batch 5/64 loss: 0.5658316612243652
Batch 6/64 loss: 0.12274885177612305
Batch 7/64 loss: 0.1989278793334961
Batch 8/64 loss: 0.21007108688354492
Batch 9/64 loss: 0.0024957656860351562
Batch 10/64 loss: -0.22632646560668945
Batch 11/64 loss: 0.11966753005981445
Batch 12/64 loss: 0.12608671188354492
Batch 13/64 loss: 0.16518783569335938
Batch 14/64 loss: 0.7629990577697754
Batch 15/64 loss: 0.5352630615234375
Batch 16/64 loss: 0.2151632308959961
Batch 17/64 loss: -0.00644683837890625
Batch 18/64 loss: -0.18798303604125977
Batch 19/64 loss: 0.3049650192260742
Batch 20/64 loss: 0.5161361694335938
Batch 21/64 loss: 0.39464759826660156
Batch 22/64 loss: 0.20754194259643555
Batch 23/64 loss: 0.3071408271789551
Batch 24/64 loss: 0.1430988311767578
Batch 25/64 loss: 0.061470985412597656
Batch 26/64 loss: 0.7224225997924805
Batch 27/64 loss: 0.5193061828613281
Batch 28/64 loss: 0.08749580383300781
Batch 29/64 loss: -0.022281646728515625
Batch 30/64 loss: 0.2929372787475586
Batch 31/64 loss: 0.1980433464050293
Batch 32/64 loss: 0.20781278610229492
Batch 33/64 loss: -0.2109055519104004
Batch 34/64 loss: -0.12248563766479492
Batch 35/64 loss: 0.2381119728088379
Batch 36/64 loss: 0.3719949722290039
Batch 37/64 loss: 0.20678424835205078
Batch 38/64 loss: 0.0605621337890625
Batch 39/64 loss: 0.36429691314697266
Batch 40/64 loss: -0.31354618072509766
Batch 41/64 loss: 0.26065492630004883
Batch 42/64 loss: 0.2234487533569336
Batch 43/64 loss: 0.17455482482910156
Batch 44/64 loss: -0.08448410034179688
Batch 45/64 loss: 0.2772974967956543
Batch 46/64 loss: 0.02131366729736328
Batch 47/64 loss: 0.03995656967163086
Batch 48/64 loss: -0.22535228729248047
Batch 49/64 loss: 0.26180171966552734
Batch 50/64 loss: 0.4495849609375
Batch 51/64 loss: 0.0730128288269043
Batch 52/64 loss: 0.4424591064453125
Batch 53/64 loss: -0.00116729736328125
Batch 54/64 loss: 0.6666150093078613
Batch 55/64 loss: 0.012005329132080078
Batch 56/64 loss: 0.06825447082519531
Batch 57/64 loss: 0.21162843704223633
Batch 58/64 loss: 0.6475305557250977
Batch 59/64 loss: -0.09192991256713867
Batch 60/64 loss: 0.21610593795776367
Batch 61/64 loss: 0.1689777374267578
Batch 62/64 loss: 0.010615825653076172
Batch 63/64 loss: 0.2607417106628418
Batch 64/64 loss: -2.9444828033447266
Epoch 32  Train loss: 0.15105216830384496  Val loss: 0.156458235278572
Epoch 33
-------------------------------
Batch 1/64 loss: -0.15618562698364258
Batch 2/64 loss: 0.043853759765625
Batch 3/64 loss: 0.8997368812561035
Batch 4/64 loss: -0.10848808288574219
Batch 5/64 loss: 0.18385934829711914
Batch 6/64 loss: 0.013278007507324219
Batch 7/64 loss: 0.2574753761291504
Batch 8/64 loss: 0.36258363723754883
Batch 9/64 loss: 0.568260669708252
Batch 10/64 loss: 1.0161843299865723
Batch 11/64 loss: -0.03620481491088867
Batch 12/64 loss: 0.40454816818237305
Batch 13/64 loss: 0.2494487762451172
Batch 14/64 loss: 0.18529462814331055
Batch 15/64 loss: 0.36224365234375
Batch 16/64 loss: 0.25631093978881836
Batch 17/64 loss: 1.3315563201904297
Batch 18/64 loss: 0.02593708038330078
Batch 19/64 loss: 0.159515380859375
Batch 20/64 loss: 0.3524818420410156
Batch 21/64 loss: 0.5688481330871582
Batch 22/64 loss: 0.3242769241333008
Batch 23/64 loss: 0.7054805755615234
Batch 24/64 loss: 0.3762993812561035
Batch 25/64 loss: -0.1287703514099121
Batch 26/64 loss: 0.6388130187988281
Batch 27/64 loss: 0.16048717498779297
Batch 28/64 loss: 0.15828895568847656
Batch 29/64 loss: 0.20731210708618164
Batch 30/64 loss: -0.13641929626464844
Batch 31/64 loss: -0.17633438110351562
Batch 32/64 loss: 0.08948612213134766
Batch 33/64 loss: 0.1849350929260254
Batch 34/64 loss: -0.27208995819091797
Batch 35/64 loss: 0.002357006072998047
Batch 36/64 loss: 0.2108163833618164
Batch 37/64 loss: -0.20967817306518555
Batch 38/64 loss: 0.2665119171142578
Batch 39/64 loss: 0.39302825927734375
Batch 40/64 loss: 0.46870851516723633
Batch 41/64 loss: 0.4171109199523926
Batch 42/64 loss: 0.32039737701416016
Batch 43/64 loss: 0.16791343688964844
Batch 44/64 loss: -0.3001832962036133
Batch 45/64 loss: -0.058814048767089844
Batch 46/64 loss: -0.08992528915405273
Batch 47/64 loss: 0.16754579544067383
Batch 48/64 loss: -0.10175418853759766
Batch 49/64 loss: 0.43398189544677734
Batch 50/64 loss: -0.05659294128417969
Batch 51/64 loss: 0.19908523559570312
Batch 52/64 loss: -0.040862083435058594
Batch 53/64 loss: -0.23214197158813477
Batch 54/64 loss: 0.08823251724243164
Batch 55/64 loss: 0.8267078399658203
Batch 56/64 loss: 0.18222904205322266
Batch 57/64 loss: 0.15960311889648438
Batch 58/64 loss: -0.1753373146057129
Batch 59/64 loss: 0.45487165451049805
Batch 60/64 loss: 0.1470317840576172
Batch 61/64 loss: 0.21483325958251953
Batch 62/64 loss: 0.2486581802368164
Batch 63/64 loss: -0.2806086540222168
Batch 64/64 loss: -3.510540008544922
Epoch 33  Train loss: 0.16099019518085556  Val loss: -0.021129516391819696
Saving best model, epoch: 33
Epoch 34
-------------------------------
Batch 1/64 loss: 0.029912948608398438
Batch 2/64 loss: 0.10683631896972656
Batch 3/64 loss: -0.19396305084228516
Batch 4/64 loss: -0.18460941314697266
Batch 5/64 loss: -0.03453826904296875
Batch 6/64 loss: 0.36110496520996094
Batch 7/64 loss: 0.3766059875488281
Batch 8/64 loss: 0.20073652267456055
Batch 9/64 loss: 0.8908238410949707
Batch 10/64 loss: 0.09322214126586914
Batch 11/64 loss: 0.19862079620361328
Batch 12/64 loss: 0.3866419792175293
Batch 13/64 loss: 0.29021358489990234
Batch 14/64 loss: 0.05909872055053711
Batch 15/64 loss: 0.18808317184448242
Batch 16/64 loss: -0.029007911682128906
Batch 17/64 loss: 0.14122438430786133
Batch 18/64 loss: 0.5115690231323242
Batch 19/64 loss: 0.25422143936157227
Batch 20/64 loss: 0.11633014678955078
Batch 21/64 loss: 0.06372261047363281
Batch 22/64 loss: 0.044025421142578125
Batch 23/64 loss: -0.29273176193237305
Batch 24/64 loss: -0.38587522506713867
Batch 25/64 loss: -0.4715747833251953
Batch 26/64 loss: 0.41236209869384766
Batch 27/64 loss: -0.13983917236328125
Batch 28/64 loss: -0.12948846817016602
Batch 29/64 loss: 0.12713146209716797
Batch 30/64 loss: 0.4363694190979004
Batch 31/64 loss: -0.06082344055175781
Batch 32/64 loss: -0.23627567291259766
Batch 33/64 loss: -0.03404092788696289
Batch 34/64 loss: 0.5236859321594238
Batch 35/64 loss: 0.4333648681640625
Batch 36/64 loss: 0.47078418731689453
Batch 37/64 loss: 0.4189114570617676
Batch 38/64 loss: -0.05674409866333008
Batch 39/64 loss: 0.37029409408569336
Batch 40/64 loss: 0.5202770233154297
Batch 41/64 loss: -0.07569122314453125
Batch 42/64 loss: -0.30210256576538086
Batch 43/64 loss: 0.04539966583251953
Batch 44/64 loss: 0.08054161071777344
Batch 45/64 loss: -0.12766170501708984
Batch 46/64 loss: -0.039067745208740234
Batch 47/64 loss: -0.42191600799560547
Batch 48/64 loss: -0.15878772735595703
Batch 49/64 loss: 0.0890040397644043
Batch 50/64 loss: 0.2974114418029785
Batch 51/64 loss: 0.2675495147705078
Batch 52/64 loss: 0.1067662239074707
Batch 53/64 loss: 0.3081698417663574
Batch 54/64 loss: -0.49953365325927734
Batch 55/64 loss: 0.19473695755004883
Batch 56/64 loss: -0.15979576110839844
Batch 57/64 loss: 0.7212944030761719
Batch 58/64 loss: 0.5662431716918945
Batch 59/64 loss: 0.14762306213378906
Batch 60/64 loss: 0.32657575607299805
Batch 61/64 loss: 0.06576061248779297
Batch 62/64 loss: -0.1478281021118164
Batch 63/64 loss: 0.3114171028137207
Batch 64/64 loss: -3.608377456665039
Epoch 34  Train loss: 0.07319981444115732  Val loss: 0.001360706447326031
Epoch 35
-------------------------------
Batch 1/64 loss: 0.06901168823242188
Batch 2/64 loss: 0.5336780548095703
Batch 3/64 loss: 0.531766414642334
Batch 4/64 loss: 0.03056955337524414
Batch 5/64 loss: 0.3077125549316406
Batch 6/64 loss: 0.36363935470581055
Batch 7/64 loss: -0.13985013961791992
Batch 8/64 loss: 1.0318026542663574
Batch 9/64 loss: 0.09353923797607422
Batch 10/64 loss: 0.2940101623535156
Batch 11/64 loss: 0.13033342361450195
Batch 12/64 loss: -0.13736629486083984
Batch 13/64 loss: 0.08390283584594727
Batch 14/64 loss: 0.4359908103942871
Batch 15/64 loss: 0.2567276954650879
Batch 16/64 loss: -0.13212203979492188
Batch 17/64 loss: 0.16324090957641602
Batch 18/64 loss: -0.1616349220275879
Batch 19/64 loss: 0.0893697738647461
Batch 20/64 loss: -0.33423423767089844
Batch 21/64 loss: 0.42389822006225586
Batch 22/64 loss: 0.25892210006713867
Batch 23/64 loss: 0.3377528190612793
Batch 24/64 loss: -0.09342575073242188
Batch 25/64 loss: -0.14405441284179688
Batch 26/64 loss: -0.14804410934448242
Batch 27/64 loss: -0.15997028350830078
Batch 28/64 loss: 0.0011210441589355469
Batch 29/64 loss: 0.45255374908447266
Batch 30/64 loss: 0.2059321403503418
Batch 31/64 loss: -0.11734628677368164
Batch 32/64 loss: -0.22740602493286133
Batch 33/64 loss: 0.00428009033203125
Batch 34/64 loss: -0.011285781860351562
Batch 35/64 loss: -0.11541223526000977
Batch 36/64 loss: -0.18017292022705078
Batch 37/64 loss: -0.12288761138916016
Batch 38/64 loss: 0.01094675064086914
Batch 39/64 loss: 0.10696220397949219
Batch 40/64 loss: 0.24576759338378906
Batch 41/64 loss: 0.03549385070800781
Batch 42/64 loss: 0.6328120231628418
Batch 43/64 loss: 0.07389688491821289
Batch 44/64 loss: -0.12755346298217773
Batch 45/64 loss: 0.33694934844970703
Batch 46/64 loss: 0.10604667663574219
Batch 47/64 loss: -0.20863008499145508
Batch 48/64 loss: 1.3842401504516602
Batch 49/64 loss: -0.07217788696289062
Batch 50/64 loss: 0.3056783676147461
Batch 51/64 loss: 0.05777454376220703
Batch 52/64 loss: 0.1473550796508789
Batch 53/64 loss: 0.29745054244995117
Batch 54/64 loss: 0.14743709564208984
Batch 55/64 loss: 0.06111907958984375
Batch 56/64 loss: 0.5119524002075195
Batch 57/64 loss: 0.724672794342041
Batch 58/64 loss: 0.16269826889038086
Batch 59/64 loss: 0.9584112167358398
Batch 60/64 loss: 0.18835926055908203
Batch 61/64 loss: 0.7469830513000488
Batch 62/64 loss: -0.07890462875366211
Batch 63/64 loss: 0.4474506378173828
Batch 64/64 loss: -3.51400089263916
Epoch 35  Train loss: 0.13242718939687692  Val loss: 0.12448518628516968
Epoch 36
-------------------------------
Batch 1/64 loss: 0.2718973159790039
Batch 2/64 loss: 0.33678627014160156
Batch 3/64 loss: -0.08924150466918945
Batch 4/64 loss: 0.3179497718811035
Batch 5/64 loss: 0.28186988830566406
Batch 6/64 loss: -0.11044168472290039
Batch 7/64 loss: 1.0115346908569336
Batch 8/64 loss: 0.0007815361022949219
Batch 9/64 loss: 0.7293996810913086
Batch 10/64 loss: 0.20864295959472656
Batch 11/64 loss: 0.07798004150390625
Batch 12/64 loss: -0.1666879653930664
Batch 13/64 loss: 0.36528968811035156
Batch 14/64 loss: 0.08833646774291992
Batch 15/64 loss: -0.07730627059936523
Batch 16/64 loss: -0.002971649169921875
Batch 17/64 loss: 0.13544797897338867
Batch 18/64 loss: 0.30976009368896484
Batch 19/64 loss: 0.24254417419433594
Batch 20/64 loss: 0.46115875244140625
Batch 21/64 loss: -0.23082923889160156
Batch 22/64 loss: 0.31903982162475586
Batch 23/64 loss: 0.0743856430053711
Batch 24/64 loss: -0.1112070083618164
Batch 25/64 loss: -0.027299880981445312
Batch 26/64 loss: -0.04373598098754883
Batch 27/64 loss: 0.02237224578857422
Batch 28/64 loss: -0.2526988983154297
Batch 29/64 loss: -0.1617732048034668
Batch 30/64 loss: -0.16446399688720703
Batch 31/64 loss: -0.10915613174438477
Batch 32/64 loss: 0.3457622528076172
Batch 33/64 loss: -0.2353510856628418
Batch 34/64 loss: 0.45136451721191406
Batch 35/64 loss: -0.17309093475341797
Batch 36/64 loss: -0.03019237518310547
Batch 37/64 loss: -0.10190439224243164
Batch 38/64 loss: -0.09624576568603516
Batch 39/64 loss: -0.25327062606811523
Batch 40/64 loss: 0.28194618225097656
Batch 41/64 loss: -0.17392253875732422
Batch 42/64 loss: 0.043670654296875
Batch 43/64 loss: 0.00211334228515625
Batch 44/64 loss: 0.23405075073242188
Batch 45/64 loss: 0.15658998489379883
Batch 46/64 loss: -0.14392375946044922
Batch 47/64 loss: 0.5260171890258789
Batch 48/64 loss: 0.2245311737060547
Batch 49/64 loss: 0.0948953628540039
Batch 50/64 loss: 0.07377815246582031
Batch 51/64 loss: 0.0433197021484375
Batch 52/64 loss: 0.15966176986694336
Batch 53/64 loss: 0.17722415924072266
Batch 54/64 loss: -0.16089916229248047
Batch 55/64 loss: 0.4416389465332031
Batch 56/64 loss: 0.6203103065490723
Batch 57/64 loss: -0.3496208190917969
Batch 58/64 loss: 0.24245643615722656
Batch 59/64 loss: 0.0651388168334961
Batch 60/64 loss: -0.44469261169433594
Batch 61/64 loss: 0.19583415985107422
Batch 62/64 loss: 0.1423778533935547
Batch 63/64 loss: 0.5107598304748535
Batch 64/64 loss: -3.2555999755859375
Epoch 36  Train loss: 0.0648782917097503  Val loss: -0.08708445231119792
Saving best model, epoch: 36
Epoch 37
-------------------------------
Batch 1/64 loss: -0.14073848724365234
Batch 2/64 loss: 0.24633264541625977
Batch 3/64 loss: 0.1722097396850586
Batch 4/64 loss: -0.011016845703125
Batch 5/64 loss: 0.5777239799499512
Batch 6/64 loss: 0.19537973403930664
Batch 7/64 loss: 0.2536005973815918
Batch 8/64 loss: 0.49910449981689453
Batch 9/64 loss: -0.3019132614135742
Batch 10/64 loss: -0.21477317810058594
Batch 11/64 loss: -0.015686988830566406
Batch 12/64 loss: 0.13575458526611328
Batch 13/64 loss: 0.08331918716430664
Batch 14/64 loss: -0.31215667724609375
Batch 15/64 loss: -0.11890697479248047
Batch 16/64 loss: -0.21493244171142578
Batch 17/64 loss: -0.031429290771484375
Batch 18/64 loss: -0.2391796112060547
Batch 19/64 loss: -0.1156463623046875
Batch 20/64 loss: -0.31145763397216797
Batch 21/64 loss: 0.20133638381958008
Batch 22/64 loss: 0.05790090560913086
Batch 23/64 loss: 0.5554423332214355
Batch 24/64 loss: 0.20957660675048828
Batch 25/64 loss: 0.5637626647949219
Batch 26/64 loss: 0.14669084548950195
Batch 27/64 loss: -0.529292106628418
Batch 28/64 loss: -0.1385211944580078
Batch 29/64 loss: -0.2355823516845703
Batch 30/64 loss: 0.1571054458618164
Batch 31/64 loss: 0.5705270767211914
Batch 32/64 loss: -0.49449729919433594
Batch 33/64 loss: 0.24234724044799805
Batch 34/64 loss: 0.005999565124511719
Batch 35/64 loss: 0.9000124931335449
Batch 36/64 loss: 0.46790599822998047
Batch 37/64 loss: -0.11962080001831055
Batch 38/64 loss: -0.2004261016845703
Batch 39/64 loss: -0.18254423141479492
Batch 40/64 loss: -0.10633468627929688
Batch 41/64 loss: -0.27335643768310547
Batch 42/64 loss: 0.35515403747558594
Batch 43/64 loss: 0.12501955032348633
Batch 44/64 loss: 0.18817520141601562
Batch 45/64 loss: -0.1755681037902832
Batch 46/64 loss: -0.2348175048828125
Batch 47/64 loss: -0.03840970993041992
Batch 48/64 loss: -0.21859359741210938
Batch 49/64 loss: 0.13019514083862305
Batch 50/64 loss: -0.03549671173095703
Batch 51/64 loss: -0.030037403106689453
Batch 52/64 loss: 0.1480121612548828
Batch 53/64 loss: 0.7562546730041504
Batch 54/64 loss: 0.004927158355712891
Batch 55/64 loss: -0.2726588249206543
Batch 56/64 loss: 0.3408384323120117
Batch 57/64 loss: 0.13444900512695312
Batch 58/64 loss: -0.03216743469238281
Batch 59/64 loss: -0.18442201614379883
Batch 60/64 loss: -0.14424800872802734
Batch 61/64 loss: -0.06794500350952148
Batch 62/64 loss: -0.0008535385131835938
Batch 63/64 loss: 0.6408953666687012
Batch 64/64 loss: -3.956110954284668
Epoch 37  Train loss: 0.005578654420142081  Val loss: -0.10645714985955622
Saving best model, epoch: 37
Epoch 38
-------------------------------
Batch 1/64 loss: 0.09299039840698242
Batch 2/64 loss: 0.36257266998291016
Batch 3/64 loss: 0.14725208282470703
Batch 4/64 loss: -0.06692028045654297
Batch 5/64 loss: 0.5766863822937012
Batch 6/64 loss: -0.17821788787841797
Batch 7/64 loss: -0.05599546432495117
Batch 8/64 loss: 0.4319944381713867
Batch 9/64 loss: 0.0727992057800293
Batch 10/64 loss: -0.2958650588989258
Batch 11/64 loss: 0.13504505157470703
Batch 12/64 loss: -0.2365245819091797
Batch 13/64 loss: -0.02326345443725586
Batch 14/64 loss: -0.2286396026611328
Batch 15/64 loss: 0.15283441543579102
Batch 16/64 loss: -0.1630396842956543
Batch 17/64 loss: -0.07620382308959961
Batch 18/64 loss: -0.1930398941040039
Batch 19/64 loss: 0.12952518463134766
Batch 20/64 loss: -0.14382648468017578
Batch 21/64 loss: -0.07779884338378906
Batch 22/64 loss: 0.13251495361328125
Batch 23/64 loss: 0.028127670288085938
Batch 24/64 loss: -0.1504673957824707
Batch 25/64 loss: -0.04309368133544922
Batch 26/64 loss: 0.23029804229736328
Batch 27/64 loss: -0.5151224136352539
Batch 28/64 loss: -0.18745899200439453
Batch 29/64 loss: 0.08274173736572266
Batch 30/64 loss: 0.05461692810058594
Batch 31/64 loss: 0.09657669067382812
Batch 32/64 loss: -0.34284400939941406
Batch 33/64 loss: 0.31981849670410156
Batch 34/64 loss: 0.2829923629760742
Batch 35/64 loss: 0.012903690338134766
Batch 36/64 loss: -0.20161914825439453
Batch 37/64 loss: 0.034603118896484375
Batch 38/64 loss: 0.024425029754638672
Batch 39/64 loss: 0.027787208557128906
Batch 40/64 loss: -0.09733390808105469
Batch 41/64 loss: 0.11130142211914062
Batch 42/64 loss: 0.10621261596679688
Batch 43/64 loss: 0.006343364715576172
Batch 44/64 loss: 0.1809101104736328
Batch 45/64 loss: -0.13074207305908203
Batch 46/64 loss: 0.03416299819946289
Batch 47/64 loss: -0.27974891662597656
Batch 48/64 loss: -0.05254030227661133
Batch 49/64 loss: -0.23424243927001953
Batch 50/64 loss: -0.09314489364624023
Batch 51/64 loss: -0.3032870292663574
Batch 52/64 loss: -0.30516624450683594
Batch 53/64 loss: 0.14805364608764648
Batch 54/64 loss: -0.06824541091918945
Batch 55/64 loss: 0.3675355911254883
Batch 56/64 loss: 0.06235218048095703
Batch 57/64 loss: 0.4037361145019531
Batch 58/64 loss: 0.39162158966064453
Batch 59/64 loss: 0.08361148834228516
Batch 60/64 loss: 0.6149086952209473
Batch 61/64 loss: 0.009393692016601562
Batch 62/64 loss: -0.1637887954711914
Batch 63/64 loss: 0.28978490829467773
Batch 64/64 loss: -3.315591335296631
Epoch 38  Train loss: -0.018130824145148782  Val loss: -0.06909996373546902
Epoch 39
-------------------------------
Batch 1/64 loss: 0.5416812896728516
Batch 2/64 loss: 0.05076122283935547
Batch 3/64 loss: 0.22708749771118164
Batch 4/64 loss: -0.20717430114746094
Batch 5/64 loss: 0.08832263946533203
Batch 6/64 loss: -0.2835254669189453
Batch 7/64 loss: 0.4464263916015625
Batch 8/64 loss: 0.3463597297668457
Batch 9/64 loss: 0.06151103973388672
Batch 10/64 loss: 0.8160481452941895
Batch 11/64 loss: -0.26627540588378906
Batch 12/64 loss: -0.22082233428955078
Batch 13/64 loss: 0.07521677017211914
Batch 14/64 loss: 0.23323774337768555
Batch 15/64 loss: -0.1608448028564453
Batch 16/64 loss: 0.03449440002441406
Batch 17/64 loss: -0.3481607437133789
Batch 18/64 loss: 0.2677898406982422
Batch 19/64 loss: 0.37208032608032227
Batch 20/64 loss: -0.4713783264160156
Batch 21/64 loss: 0.28835535049438477
Batch 22/64 loss: 0.16361379623413086
Batch 23/64 loss: 0.12054729461669922
Batch 24/64 loss: 0.02868366241455078
Batch 25/64 loss: -0.3673820495605469
Batch 26/64 loss: 0.2274174690246582
Batch 27/64 loss: -0.2440929412841797
Batch 28/64 loss: 0.3684811592102051
Batch 29/64 loss: 0.12429475784301758
Batch 30/64 loss: -0.3436312675476074
Batch 31/64 loss: 0.25693702697753906
Batch 32/64 loss: 0.10212135314941406
Batch 33/64 loss: 0.010890483856201172
Batch 34/64 loss: -0.023932933807373047
Batch 35/64 loss: -0.07393026351928711
Batch 36/64 loss: -0.46816205978393555
Batch 37/64 loss: 0.1269207000732422
Batch 38/64 loss: -0.23241281509399414
Batch 39/64 loss: 0.12851190567016602
Batch 40/64 loss: 0.18081188201904297
Batch 41/64 loss: -0.46024084091186523
Batch 42/64 loss: -0.27587890625
Batch 43/64 loss: 0.19140625
Batch 44/64 loss: -0.3898038864135742
Batch 45/64 loss: -0.25049304962158203
Batch 46/64 loss: 0.6903848648071289
Batch 47/64 loss: 0.06756877899169922
Batch 48/64 loss: 0.17580699920654297
Batch 49/64 loss: -0.08973217010498047
Batch 50/64 loss: -0.0507969856262207
Batch 51/64 loss: 0.2162456512451172
Batch 52/64 loss: -0.08269548416137695
Batch 53/64 loss: -0.0478978157043457
Batch 54/64 loss: 0.011339664459228516
Batch 55/64 loss: 0.13440847396850586
Batch 56/64 loss: -0.09830713272094727
Batch 57/64 loss: -0.10132789611816406
Batch 58/64 loss: 0.3186192512512207
Batch 59/64 loss: -0.02501964569091797
Batch 60/64 loss: 0.3843240737915039
Batch 61/64 loss: 0.5140423774719238
Batch 62/64 loss: 0.5667500495910645
Batch 63/64 loss: 0.091400146484375
Batch 64/64 loss: -3.6165809631347656
Epoch 39  Train loss: 0.011836003322227328  Val loss: -0.04171024073440185
Epoch 40
-------------------------------
Batch 1/64 loss: 0.021828651428222656
Batch 2/64 loss: 0.3395524024963379
Batch 3/64 loss: 0.1533069610595703
Batch 4/64 loss: 0.09517383575439453
Batch 5/64 loss: 0.30387115478515625
Batch 6/64 loss: 0.7262673377990723
Batch 7/64 loss: 0.07463359832763672
Batch 8/64 loss: 0.054270267486572266
Batch 9/64 loss: 0.016429901123046875
Batch 10/64 loss: 0.11671638488769531
Batch 11/64 loss: 0.17471647262573242
Batch 12/64 loss: 0.535398006439209
Batch 13/64 loss: -0.42014074325561523
Batch 14/64 loss: 0.24281597137451172
Batch 15/64 loss: -0.01851511001586914
Batch 16/64 loss: -0.10334491729736328
Batch 17/64 loss: 0.537320613861084
Batch 18/64 loss: 0.0186614990234375
Batch 19/64 loss: 0.038083553314208984
Batch 20/64 loss: -0.012390613555908203
Batch 21/64 loss: 0.2576560974121094
Batch 22/64 loss: -0.22286748886108398
Batch 23/64 loss: -0.020669937133789062
Batch 24/64 loss: 0.16836261749267578
Batch 25/64 loss: 0.07890176773071289
Batch 26/64 loss: 0.12979698181152344
Batch 27/64 loss: -0.2555198669433594
Batch 28/64 loss: -0.37325572967529297
Batch 29/64 loss: -0.2581205368041992
Batch 30/64 loss: 0.14737892150878906
Batch 31/64 loss: -0.055269718170166016
Batch 32/64 loss: -0.44188737869262695
Batch 33/64 loss: 0.06910228729248047
Batch 34/64 loss: -0.011457443237304688
Batch 35/64 loss: -0.05732107162475586
Batch 36/64 loss: 0.28489017486572266
Batch 37/64 loss: 0.14041805267333984
Batch 38/64 loss: -0.22096824645996094
Batch 39/64 loss: -0.2556266784667969
Batch 40/64 loss: 0.05270671844482422
Batch 41/64 loss: 0.21591567993164062
Batch 42/64 loss: 0.521090030670166
Batch 43/64 loss: 0.10570096969604492
Batch 44/64 loss: -0.10494709014892578
Batch 45/64 loss: -0.08553171157836914
Batch 46/64 loss: -0.29647207260131836
Batch 47/64 loss: 0.20796823501586914
Batch 48/64 loss: 0.29520750045776367
Batch 49/64 loss: -0.16084766387939453
Batch 50/64 loss: 0.4100823402404785
Batch 51/64 loss: 0.0944981575012207
Batch 52/64 loss: 0.5603652000427246
Batch 53/64 loss: -0.1432647705078125
Batch 54/64 loss: -0.10972118377685547
Batch 55/64 loss: -0.18997669219970703
Batch 56/64 loss: -0.2367863655090332
Batch 57/64 loss: 0.49140071868896484
Batch 58/64 loss: 0.10116863250732422
Batch 59/64 loss: 0.0023288726806640625
Batch 60/64 loss: 0.2687110900878906
Batch 61/64 loss: 0.27683305740356445
Batch 62/64 loss: 0.1414499282836914
Batch 63/64 loss: -0.36498260498046875
Batch 64/64 loss: -3.778167247772217
Epoch 40  Train loss: 0.01909756192974016  Val loss: -0.22463145043022445
Saving best model, epoch: 40
Epoch 41
-------------------------------
Batch 1/64 loss: -0.2964954376220703
Batch 2/64 loss: 0.3975377082824707
Batch 3/64 loss: 0.21934986114501953
Batch 4/64 loss: 0.03820514678955078
Batch 5/64 loss: 0.7189803123474121
Batch 6/64 loss: 0.5027170181274414
Batch 7/64 loss: -0.07843875885009766
Batch 8/64 loss: 0.1573772430419922
Batch 9/64 loss: -0.4203815460205078
Batch 10/64 loss: -0.10903167724609375
Batch 11/64 loss: 0.21790695190429688
Batch 12/64 loss: -0.09477806091308594
Batch 13/64 loss: 0.046072959899902344
Batch 14/64 loss: -0.06058025360107422
Batch 15/64 loss: 0.3695716857910156
Batch 16/64 loss: 0.2214374542236328
Batch 17/64 loss: 0.21968984603881836
Batch 18/64 loss: 0.24036407470703125
Batch 19/64 loss: 0.550349235534668
Batch 20/64 loss: 0.2499094009399414
Batch 21/64 loss: -0.3192472457885742
Batch 22/64 loss: -0.36772918701171875
Batch 23/64 loss: -0.39286231994628906
Batch 24/64 loss: 0.33234500885009766
Batch 25/64 loss: 0.4471144676208496
Batch 26/64 loss: 0.051674842834472656
Batch 27/64 loss: -0.2230691909790039
Batch 28/64 loss: -0.03574562072753906
Batch 29/64 loss: -0.23059415817260742
Batch 30/64 loss: 0.09911012649536133
Batch 31/64 loss: -0.11390209197998047
Batch 32/64 loss: -0.08500385284423828
Batch 33/64 loss: -0.4312877655029297
Batch 34/64 loss: -0.2127513885498047
Batch 35/64 loss: -0.7481613159179688
Batch 36/64 loss: -0.18351268768310547
Batch 37/64 loss: -0.09103107452392578
Batch 38/64 loss: 0.7584781646728516
Batch 39/64 loss: 0.48412179946899414
Batch 40/64 loss: 0.17560768127441406
Batch 41/64 loss: 0.026984691619873047
Batch 42/64 loss: 0.36054134368896484
Batch 43/64 loss: 0.217529296875
Batch 44/64 loss: -0.25261735916137695
Batch 45/64 loss: -0.3263559341430664
Batch 46/64 loss: 0.1940302848815918
Batch 47/64 loss: -0.03263282775878906
Batch 48/64 loss: 0.12644147872924805
Batch 49/64 loss: -0.5448179244995117
Batch 50/64 loss: 0.2993793487548828
Batch 51/64 loss: 0.041739463806152344
Batch 52/64 loss: -0.2991762161254883
Batch 53/64 loss: -0.26151514053344727
Batch 54/64 loss: 0.04692363739013672
Batch 55/64 loss: -0.39199066162109375
Batch 56/64 loss: 0.29720449447631836
Batch 57/64 loss: -0.5353298187255859
Batch 58/64 loss: 0.4437413215637207
Batch 59/64 loss: 0.46205854415893555
Batch 60/64 loss: 0.5114669799804688
Batch 61/64 loss: -0.24268722534179688
Batch 62/64 loss: -0.18669605255126953
Batch 63/64 loss: -0.04077959060668945
Batch 64/64 loss: -3.997195243835449
Epoch 41  Train loss: -0.016959010853486903  Val loss: -0.06828118026051734
Epoch 42
-------------------------------
Batch 1/64 loss: -0.41576719284057617
Batch 2/64 loss: 0.5901408195495605
Batch 3/64 loss: -0.40425729751586914
Batch 4/64 loss: 0.03163576126098633
Batch 5/64 loss: 0.6826987266540527
Batch 6/64 loss: -0.0029582977294921875
Batch 7/64 loss: -0.22395992279052734
Batch 8/64 loss: -0.0756993293762207
Batch 9/64 loss: 0.543281078338623
Batch 10/64 loss: 0.020000934600830078
Batch 11/64 loss: -0.4945859909057617
Batch 12/64 loss: -0.22502422332763672
Batch 13/64 loss: 0.5337677001953125
Batch 14/64 loss: -0.016450881958007812
Batch 15/64 loss: 0.06512737274169922
Batch 16/64 loss: 0.16646194458007812
Batch 17/64 loss: 0.08938407897949219
Batch 18/64 loss: -0.14009857177734375
Batch 19/64 loss: 0.05122232437133789
Batch 20/64 loss: -0.07289314270019531
Batch 21/64 loss: 0.07216072082519531
Batch 22/64 loss: -0.05731487274169922
Batch 23/64 loss: 0.38771629333496094
Batch 24/64 loss: 0.23141956329345703
Batch 25/64 loss: 0.07596397399902344
Batch 26/64 loss: 0.2809300422668457
Batch 27/64 loss: -0.23660945892333984
Batch 28/64 loss: 0.17928028106689453
Batch 29/64 loss: -0.15840530395507812
Batch 30/64 loss: 0.16573572158813477
Batch 31/64 loss: -0.030005455017089844
Batch 32/64 loss: -0.011371612548828125
Batch 33/64 loss: -0.2408742904663086
Batch 34/64 loss: -0.26665592193603516
Batch 35/64 loss: -0.2474956512451172
Batch 36/64 loss: -0.3996438980102539
Batch 37/64 loss: 0.031183719635009766
Batch 38/64 loss: -0.40629005432128906
Batch 39/64 loss: -0.1484231948852539
Batch 40/64 loss: 0.3149375915527344
Batch 41/64 loss: -0.2536954879760742
Batch 42/64 loss: 0.31099796295166016
Batch 43/64 loss: -0.2530641555786133
Batch 44/64 loss: -0.26133012771606445
Batch 45/64 loss: 0.8714056015014648
Batch 46/64 loss: -0.11837196350097656
Batch 47/64 loss: 0.18915748596191406
Batch 48/64 loss: 0.4558887481689453
Batch 49/64 loss: 0.051592350006103516
Batch 50/64 loss: -0.3099813461303711
Batch 51/64 loss: 0.118011474609375
Batch 52/64 loss: 0.3508572578430176
Batch 53/64 loss: 0.2764277458190918
Batch 54/64 loss: 0.18613958358764648
Batch 55/64 loss: 0.21427011489868164
Batch 56/64 loss: -0.05431175231933594
Batch 57/64 loss: 0.3424506187438965
Batch 58/64 loss: -0.15572786331176758
Batch 59/64 loss: -0.4197549819946289
Batch 60/64 loss: 0.16882896423339844
Batch 61/64 loss: -0.13681745529174805
Batch 62/64 loss: -0.04538917541503906
Batch 63/64 loss: 0.14409208297729492
Batch 64/64 loss: -2.697072982788086
Epoch 42  Train loss: -0.0017704309201708028  Val loss: -0.164848969974059
Epoch 43
-------------------------------
Batch 1/64 loss: 0.06039762496948242
Batch 2/64 loss: 0.020096778869628906
Batch 3/64 loss: -0.2973756790161133
Batch 4/64 loss: -0.3141312599182129
Batch 5/64 loss: 0.045525550842285156
Batch 6/64 loss: 0.34229564666748047
Batch 7/64 loss: -0.26154184341430664
Batch 8/64 loss: 0.2473282814025879
Batch 9/64 loss: -0.32913780212402344
Batch 10/64 loss: 0.12312126159667969
Batch 11/64 loss: 0.055075645446777344
Batch 12/64 loss: 0.2357783317565918
Batch 13/64 loss: 0.1318669319152832
Batch 14/64 loss: -0.07244443893432617
Batch 15/64 loss: -0.12189865112304688
Batch 16/64 loss: 0.1127920150756836
Batch 17/64 loss: 0.36159181594848633
Batch 18/64 loss: 0.018244266510009766
Batch 19/64 loss: 0.028140544891357422
Batch 20/64 loss: -0.14234018325805664
Batch 21/64 loss: -0.12725162506103516
Batch 22/64 loss: -0.1910572052001953
Batch 23/64 loss: -0.21842002868652344
Batch 24/64 loss: -0.4020357131958008
Batch 25/64 loss: -0.41692161560058594
Batch 26/64 loss: -0.07103443145751953
Batch 27/64 loss: 0.2430276870727539
Batch 28/64 loss: 0.033286094665527344
Batch 29/64 loss: 0.13437461853027344
Batch 30/64 loss: 0.41629505157470703
Batch 31/64 loss: 0.08691978454589844
Batch 32/64 loss: 0.43413305282592773
Batch 33/64 loss: 0.20255470275878906
Batch 34/64 loss: 0.10888051986694336
Batch 35/64 loss: 0.4991340637207031
Batch 36/64 loss: -0.40953731536865234
Batch 37/64 loss: 0.4206275939941406
Batch 38/64 loss: -0.33241796493530273
Batch 39/64 loss: -0.04988384246826172
Batch 40/64 loss: 0.13618040084838867
Batch 41/64 loss: 0.00966644287109375
Batch 42/64 loss: -0.11628866195678711
Batch 43/64 loss: 0.3617234230041504
Batch 44/64 loss: -0.18270540237426758
Batch 45/64 loss: -0.21817636489868164
Batch 46/64 loss: -0.051006317138671875
Batch 47/64 loss: -0.058351993560791016
Batch 48/64 loss: -0.16833829879760742
Batch 49/64 loss: -0.21340703964233398
Batch 50/64 loss: -0.10131263732910156
Batch 51/64 loss: 0.15418767929077148
Batch 52/64 loss: 0.6720056533813477
Batch 53/64 loss: 0.11932659149169922
Batch 54/64 loss: -0.13509368896484375
Batch 55/64 loss: -0.3376131057739258
Batch 56/64 loss: 0.012362480163574219
Batch 57/64 loss: -0.3329181671142578
Batch 58/64 loss: -0.09310722351074219
Batch 59/64 loss: 0.06687068939208984
Batch 60/64 loss: 0.906989574432373
Batch 61/64 loss: 0.4929823875427246
Batch 62/64 loss: -0.14589309692382812
Batch 63/64 loss: 0.09596776962280273
Batch 64/64 loss: -4.149081230163574
Epoch 43  Train loss: -0.025626691182454427  Val loss: -0.06336120395725946
Epoch 44
-------------------------------
Batch 1/64 loss: 0.17189788818359375
Batch 2/64 loss: -0.059561729431152344
Batch 3/64 loss: -0.18326568603515625
Batch 4/64 loss: -0.21270179748535156
Batch 5/64 loss: -0.3725719451904297
Batch 6/64 loss: -0.40641117095947266
Batch 7/64 loss: -0.09464168548583984
Batch 8/64 loss: -0.30311012268066406
Batch 9/64 loss: 0.6335229873657227
Batch 10/64 loss: 0.34732818603515625
Batch 11/64 loss: -0.3577289581298828
Batch 12/64 loss: -0.2692604064941406
Batch 13/64 loss: -0.10398292541503906
Batch 14/64 loss: 0.7629885673522949
Batch 15/64 loss: -0.3483004570007324
Batch 16/64 loss: -0.018503189086914062
Batch 17/64 loss: 0.0020051002502441406
Batch 18/64 loss: -0.049489498138427734
Batch 19/64 loss: -0.14065265655517578
Batch 20/64 loss: 0.36993837356567383
Batch 21/64 loss: -0.17992448806762695
Batch 22/64 loss: 0.09502315521240234
Batch 23/64 loss: -0.06909990310668945
Batch 24/64 loss: 0.04719972610473633
Batch 25/64 loss: -0.10698080062866211
Batch 26/64 loss: -0.1294422149658203
Batch 27/64 loss: 0.12657976150512695
Batch 28/64 loss: 0.04885053634643555
Batch 29/64 loss: 0.19640159606933594
Batch 30/64 loss: 0.1986064910888672
Batch 31/64 loss: -0.40257835388183594
Batch 32/64 loss: -0.0324254035949707
Batch 33/64 loss: -0.1822037696838379
Batch 34/64 loss: -0.3023195266723633
Batch 35/64 loss: 0.08425569534301758
Batch 36/64 loss: -0.21128177642822266
Batch 37/64 loss: 0.15012025833129883
Batch 38/64 loss: 0.1892404556274414
Batch 39/64 loss: -0.15909624099731445
Batch 40/64 loss: -0.4863777160644531
Batch 41/64 loss: -0.13030576705932617
Batch 42/64 loss: -0.3364982604980469
Batch 43/64 loss: -0.10145092010498047
Batch 44/64 loss: -0.28058528900146484
Batch 45/64 loss: -0.3701043128967285
Batch 46/64 loss: -0.20178747177124023
Batch 47/64 loss: -0.5857830047607422
Batch 48/64 loss: -0.028359413146972656
Batch 49/64 loss: 0.44638776779174805
Batch 50/64 loss: -0.6477737426757812
Batch 51/64 loss: 0.18122482299804688
Batch 52/64 loss: 0.023200035095214844
Batch 53/64 loss: 0.7143220901489258
Batch 54/64 loss: 0.05310869216918945
Batch 55/64 loss: -0.07747364044189453
Batch 56/64 loss: 0.18807506561279297
Batch 57/64 loss: -0.2855253219604492
Batch 58/64 loss: 0.24802875518798828
Batch 59/64 loss: 0.21219682693481445
Batch 60/64 loss: 0.17217540740966797
Batch 61/64 loss: 0.0037856101989746094
Batch 62/64 loss: -0.01621866226196289
Batch 63/64 loss: -0.06247091293334961
Batch 64/64 loss: -3.519761562347412
Epoch 44  Train loss: -0.08281735625921512  Val loss: -0.05365940631460078
Epoch 45
-------------------------------
Batch 1/64 loss: -0.2362508773803711
Batch 2/64 loss: 0.05726146697998047
Batch 3/64 loss: 0.1208963394165039
Batch 4/64 loss: 0.28436756134033203
Batch 5/64 loss: -0.1774916648864746
Batch 6/64 loss: -0.5076742172241211
Batch 7/64 loss: -0.09091997146606445
Batch 8/64 loss: 0.08341360092163086
Batch 9/64 loss: -0.03682279586791992
Batch 10/64 loss: -0.2227792739868164
Batch 11/64 loss: -0.38012027740478516
Batch 12/64 loss: -0.226104736328125
Batch 13/64 loss: -0.0006651878356933594
Batch 14/64 loss: -0.018593311309814453
Batch 15/64 loss: -0.09582328796386719
Batch 16/64 loss: -0.11922693252563477
Batch 17/64 loss: 0.19842243194580078
Batch 18/64 loss: 0.06273698806762695
Batch 19/64 loss: -0.3607363700866699
Batch 20/64 loss: -0.34221458435058594
Batch 21/64 loss: -0.11051750183105469
Batch 22/64 loss: -0.3889608383178711
Batch 23/64 loss: -0.3268318176269531
Batch 24/64 loss: -0.47937774658203125
Batch 25/64 loss: -0.4315481185913086
Batch 26/64 loss: 0.057460784912109375
Batch 27/64 loss: -0.38056182861328125
Batch 28/64 loss: -0.25238513946533203
Batch 29/64 loss: -0.30786991119384766
Batch 30/64 loss: 0.11179256439208984
Batch 31/64 loss: 0.027912139892578125
Batch 32/64 loss: -0.21414947509765625
Batch 33/64 loss: 1.5920143127441406
Batch 34/64 loss: 0.1558084487915039
Batch 35/64 loss: -0.10038042068481445
Batch 36/64 loss: -0.006709098815917969
Batch 37/64 loss: -0.022260665893554688
Batch 38/64 loss: 0.05883455276489258
Batch 39/64 loss: 0.11427688598632812
Batch 40/64 loss: 0.010307788848876953
Batch 41/64 loss: -0.03068256378173828
Batch 42/64 loss: 0.849210262298584
Batch 43/64 loss: 0.3742671012878418
Batch 44/64 loss: -0.1033315658569336
Batch 45/64 loss: 0.2158799171447754
Batch 46/64 loss: 0.17815923690795898
Batch 47/64 loss: 0.39705562591552734
Batch 48/64 loss: 0.007895946502685547
Batch 49/64 loss: 0.916928768157959
Batch 50/64 loss: -0.024687767028808594
Batch 51/64 loss: -0.20654726028442383
Batch 52/64 loss: -0.08431339263916016
Batch 53/64 loss: -0.4750838279724121
Batch 54/64 loss: 0.5966038703918457
Batch 55/64 loss: -0.3460674285888672
Batch 56/64 loss: -0.22766542434692383
Batch 57/64 loss: 0.00038909912109375
Batch 58/64 loss: -0.25044870376586914
Batch 59/64 loss: 0.039168357849121094
Batch 60/64 loss: -0.3248405456542969
Batch 61/64 loss: 0.026156902313232422
Batch 62/64 loss: -0.3532581329345703
Batch 63/64 loss: -0.2945828437805176
Batch 64/64 loss: -3.9121646881103516
Epoch 45  Train loss: -0.07773157755533854  Val loss: -0.34952965962518123
Saving best model, epoch: 45
Epoch 46
-------------------------------
Batch 1/64 loss: -0.5316486358642578
Batch 2/64 loss: 0.19213438034057617
Batch 3/64 loss: 0.003670215606689453
Batch 4/64 loss: -0.09159612655639648
Batch 5/64 loss: -0.07732200622558594
Batch 6/64 loss: -0.3151254653930664
Batch 7/64 loss: -0.13987445831298828
Batch 8/64 loss: 0.09885978698730469
Batch 9/64 loss: 0.2714118957519531
Batch 10/64 loss: -0.4116983413696289
Batch 11/64 loss: -0.4839153289794922
Batch 12/64 loss: -0.18230533599853516
Batch 13/64 loss: -0.2366161346435547
Batch 14/64 loss: -0.5997190475463867
Batch 15/64 loss: -0.11922359466552734
Batch 16/64 loss: -0.26078128814697266
Batch 17/64 loss: -0.34032154083251953
Batch 18/64 loss: -0.17606163024902344
Batch 19/64 loss: -0.013867378234863281
Batch 20/64 loss: 0.11712646484375
Batch 21/64 loss: -0.11064434051513672
Batch 22/64 loss: -0.5450782775878906
Batch 23/64 loss: -0.1836090087890625
Batch 24/64 loss: -0.26957035064697266
Batch 25/64 loss: 0.31406211853027344
Batch 26/64 loss: -0.11526298522949219
Batch 27/64 loss: 0.21618986129760742
Batch 28/64 loss: 0.9617314338684082
Batch 29/64 loss: -0.011141300201416016
Batch 30/64 loss: 0.13808822631835938
Batch 31/64 loss: 0.08039093017578125
Batch 32/64 loss: 0.33385562896728516
Batch 33/64 loss: 0.034008026123046875
Batch 34/64 loss: 0.4243168830871582
Batch 35/64 loss: -0.09001493453979492
Batch 36/64 loss: -0.008582592010498047
Batch 37/64 loss: 0.04486370086669922
Batch 38/64 loss: -0.2877955436706543
Batch 39/64 loss: 0.05400705337524414
Batch 40/64 loss: 0.5910382270812988
Batch 41/64 loss: -0.09909391403198242
Batch 42/64 loss: 0.0901937484741211
Batch 43/64 loss: -0.17563199996948242
Batch 44/64 loss: -0.14304733276367188
Batch 45/64 loss: 0.03949689865112305
Batch 46/64 loss: -0.33800315856933594
Batch 47/64 loss: -0.1770782470703125
Batch 48/64 loss: 0.22533655166625977
Batch 49/64 loss: -0.37572288513183594
Batch 50/64 loss: 0.5657901763916016
Batch 51/64 loss: 0.2404031753540039
Batch 52/64 loss: 0.43400096893310547
Batch 53/64 loss: -0.2940330505371094
Batch 54/64 loss: -0.5186119079589844
Batch 55/64 loss: -0.17629241943359375
Batch 56/64 loss: -0.05950736999511719
Batch 57/64 loss: -0.020021438598632812
Batch 58/64 loss: -0.3149876594543457
Batch 59/64 loss: 0.8471298217773438
Batch 60/64 loss: -0.20415592193603516
Batch 61/64 loss: -0.3648042678833008
Batch 62/64 loss: -0.1824040412902832
Batch 63/64 loss: -0.09402227401733398
Batch 64/64 loss: -4.140957832336426
Epoch 46  Train loss: -0.09296950171975528  Val loss: -0.22339540986261008
Epoch 47
-------------------------------
Batch 1/64 loss: 0.12231302261352539
Batch 2/64 loss: -0.022251129150390625
Batch 3/64 loss: 0.06603384017944336
Batch 4/64 loss: -0.23446941375732422
Batch 5/64 loss: -0.12119102478027344
Batch 6/64 loss: -0.2801389694213867
Batch 7/64 loss: -0.34564971923828125
Batch 8/64 loss: 0.4629826545715332
Batch 9/64 loss: -0.2589082717895508
Batch 10/64 loss: -0.3756732940673828
Batch 11/64 loss: -0.09044981002807617
Batch 12/64 loss: 0.0037975311279296875
Batch 13/64 loss: 0.18946361541748047
Batch 14/64 loss: -0.035880088806152344
Batch 15/64 loss: -0.3711557388305664
Batch 16/64 loss: 0.0769643783569336
Batch 17/64 loss: 0.1098175048828125
Batch 18/64 loss: 0.16662120819091797
Batch 19/64 loss: 0.09859085083007812
Batch 20/64 loss: -0.09841489791870117
Batch 21/64 loss: -0.47892093658447266
Batch 22/64 loss: -0.6766901016235352
Batch 23/64 loss: -0.4085674285888672
Batch 24/64 loss: -0.3939828872680664
Batch 25/64 loss: -0.26465415954589844
Batch 26/64 loss: 0.06938457489013672
Batch 27/64 loss: -0.1589493751525879
Batch 28/64 loss: 0.07252264022827148
Batch 29/64 loss: -0.015984058380126953
Batch 30/64 loss: 0.5153937339782715
Batch 31/64 loss: -0.12777376174926758
Batch 32/64 loss: 0.3310389518737793
Batch 33/64 loss: 0.4604802131652832
Batch 34/64 loss: -0.27428340911865234
Batch 35/64 loss: 0.8323321342468262
Batch 36/64 loss: -0.12806081771850586
Batch 37/64 loss: -0.30994415283203125
Batch 38/64 loss: 0.11168336868286133
Batch 39/64 loss: -0.284149169921875
Batch 40/64 loss: -0.3846397399902344
Batch 41/64 loss: 0.00024890899658203125
Batch 42/64 loss: -0.29367923736572266
Batch 43/64 loss: -0.3500490188598633
Batch 44/64 loss: -0.2611842155456543
Batch 45/64 loss: 0.30776309967041016
Batch 46/64 loss: 0.6236152648925781
Batch 47/64 loss: -0.09864044189453125
Batch 48/64 loss: -0.1227731704711914
Batch 49/64 loss: -0.17325544357299805
Batch 50/64 loss: -0.22437810897827148
Batch 51/64 loss: 0.09457540512084961
Batch 52/64 loss: 0.22426795959472656
Batch 53/64 loss: -0.13442325592041016
Batch 54/64 loss: -0.037583351135253906
Batch 55/64 loss: -0.3243246078491211
Batch 56/64 loss: -0.30660247802734375
Batch 57/64 loss: 0.0346527099609375
Batch 58/64 loss: -0.32900142669677734
Batch 59/64 loss: -0.2602996826171875
Batch 60/64 loss: -0.6674413681030273
Batch 61/64 loss: 0.11338615417480469
Batch 62/64 loss: -0.20219850540161133
Batch 63/64 loss: 0.45000743865966797
Batch 64/64 loss: -4.034061431884766
Epoch 47  Train loss: -0.11630157769895068  Val loss: -0.23401493714847105
Epoch 48
-------------------------------
Batch 1/64 loss: -0.2567253112792969
Batch 2/64 loss: -0.3540372848510742
Batch 3/64 loss: -0.30449771881103516
Batch 4/64 loss: -0.15157508850097656
Batch 5/64 loss: -0.13221263885498047
Batch 6/64 loss: 0.1658802032470703
Batch 7/64 loss: -0.10859155654907227
Batch 8/64 loss: -0.06668281555175781
Batch 9/64 loss: -0.1925220489501953
Batch 10/64 loss: -0.050425052642822266
Batch 11/64 loss: -0.3303089141845703
Batch 12/64 loss: -0.08723831176757812
Batch 13/64 loss: -0.020229339599609375
Batch 14/64 loss: -0.509002685546875
Batch 15/64 loss: -0.0996713638305664
Batch 16/64 loss: -0.18941497802734375
Batch 17/64 loss: 0.14756536483764648
Batch 18/64 loss: -0.16381168365478516
Batch 19/64 loss: -0.10798263549804688
Batch 20/64 loss: -0.3642101287841797
Batch 21/64 loss: -0.4576716423034668
Batch 22/64 loss: -0.17193126678466797
Batch 23/64 loss: -0.0753622055053711
Batch 24/64 loss: -0.41919612884521484
Batch 25/64 loss: -0.27066993713378906
Batch 26/64 loss: 0.3847823143005371
Batch 27/64 loss: -0.547398567199707
Batch 28/64 loss: 0.1674785614013672
Batch 29/64 loss: -0.14116859436035156
Batch 30/64 loss: -0.19393062591552734
Batch 31/64 loss: -0.43677425384521484
Batch 32/64 loss: 0.07689571380615234
Batch 33/64 loss: 0.0590052604675293
Batch 34/64 loss: 0.47771310806274414
Batch 35/64 loss: -0.19183731079101562
Batch 36/64 loss: -0.22427606582641602
Batch 37/64 loss: -0.38144493103027344
Batch 38/64 loss: 0.0850672721862793
Batch 39/64 loss: -0.011404991149902344
Batch 40/64 loss: -0.14366388320922852
Batch 41/64 loss: 0.15761089324951172
Batch 42/64 loss: -0.5144062042236328
Batch 43/64 loss: -0.22182416915893555
Batch 44/64 loss: -0.12630081176757812
Batch 45/64 loss: -0.39484500885009766
Batch 46/64 loss: -0.09885120391845703
Batch 47/64 loss: -0.059174537658691406
Batch 48/64 loss: -0.5583925247192383
Batch 49/64 loss: -0.45848560333251953
Batch 50/64 loss: -0.2531766891479492
Batch 51/64 loss: 0.5590753555297852
Batch 52/64 loss: 0.730186939239502
Batch 53/64 loss: -0.2141284942626953
Batch 54/64 loss: -0.2938814163208008
Batch 55/64 loss: -0.07720661163330078
Batch 56/64 loss: -0.17268848419189453
Batch 57/64 loss: 0.17997360229492188
Batch 58/64 loss: 0.31294775009155273
Batch 59/64 loss: -0.010953903198242188
Batch 60/64 loss: -0.136322021484375
Batch 61/64 loss: -0.012300968170166016
Batch 62/64 loss: -0.19741249084472656
Batch 63/64 loss: 0.41666364669799805
Batch 64/64 loss: -4.0225749015808105
Epoch 48  Train loss: -0.15768323599123488  Val loss: -0.3487247060664331
Epoch 49
-------------------------------
Batch 1/64 loss: -0.3811311721801758
Batch 2/64 loss: 0.007221698760986328
Batch 3/64 loss: -0.16937923431396484
Batch 4/64 loss: -0.15491676330566406
Batch 5/64 loss: 0.07935523986816406
Batch 6/64 loss: -0.18488311767578125
Batch 7/64 loss: -0.3944120407104492
Batch 8/64 loss: -0.2687349319458008
Batch 9/64 loss: 0.036425113677978516
Batch 10/64 loss: -0.25525665283203125
Batch 11/64 loss: -0.22492599487304688
Batch 12/64 loss: -0.4910621643066406
Batch 13/64 loss: -0.3957338333129883
Batch 14/64 loss: -0.1360797882080078
Batch 15/64 loss: 0.12770462036132812
Batch 16/64 loss: -0.18291378021240234
Batch 17/64 loss: -0.40837955474853516
Batch 18/64 loss: -0.0477752685546875
Batch 19/64 loss: 0.1488809585571289
Batch 20/64 loss: -0.4778127670288086
Batch 21/64 loss: -0.38329410552978516
Batch 22/64 loss: 0.0018205642700195312
Batch 23/64 loss: 0.37976884841918945
Batch 24/64 loss: -0.15445232391357422
Batch 25/64 loss: -0.5899820327758789
Batch 26/64 loss: -0.44827938079833984
Batch 27/64 loss: -0.2346038818359375
Batch 28/64 loss: -0.420654296875
Batch 29/64 loss: -0.4787874221801758
Batch 30/64 loss: -0.39143848419189453
Batch 31/64 loss: -0.06962394714355469
Batch 32/64 loss: -0.001224517822265625
Batch 33/64 loss: -0.17767047882080078
Batch 34/64 loss: -0.03241920471191406
Batch 35/64 loss: -0.3842506408691406
Batch 36/64 loss: -0.21276187896728516
Batch 37/64 loss: 0.4635896682739258
Batch 38/64 loss: 0.34113311767578125
Batch 39/64 loss: 0.9014678001403809
Batch 40/64 loss: -0.28213024139404297
Batch 41/64 loss: -0.14386749267578125
Batch 42/64 loss: -0.16670751571655273
Batch 43/64 loss: -0.07936716079711914
Batch 44/64 loss: -0.07151412963867188
Batch 45/64 loss: 0.46707725524902344
Batch 46/64 loss: 0.04636430740356445
Batch 47/64 loss: 0.07222652435302734
Batch 48/64 loss: -0.20234251022338867
Batch 49/64 loss: 0.038213253021240234
Batch 50/64 loss: -0.12552833557128906
Batch 51/64 loss: -0.01653432846069336
Batch 52/64 loss: -0.13721799850463867
Batch 53/64 loss: 0.04762458801269531
Batch 54/64 loss: -0.29488134384155273
Batch 55/64 loss: -0.4055910110473633
Batch 56/64 loss: 0.05381917953491211
Batch 57/64 loss: -0.21766996383666992
Batch 58/64 loss: -0.27105045318603516
Batch 59/64 loss: -0.1740865707397461
Batch 60/64 loss: 0.16239643096923828
Batch 61/64 loss: 0.2622232437133789
Batch 62/64 loss: 0.10996532440185547
Batch 63/64 loss: -0.1306772232055664
Batch 64/64 loss: -3.857664108276367
Epoch 49  Train loss: -0.15714472602395452  Val loss: -0.22864592771759557
Epoch 50
-------------------------------
Batch 1/64 loss: -0.5575509071350098
Batch 2/64 loss: -0.21233320236206055
Batch 3/64 loss: 0.05174827575683594
Batch 4/64 loss: -0.32019901275634766
Batch 5/64 loss: -0.25365543365478516
Batch 6/64 loss: 0.05697441101074219
Batch 7/64 loss: -0.3014411926269531
Batch 8/64 loss: -0.1684260368347168
Batch 9/64 loss: -0.19481945037841797
Batch 10/64 loss: 0.4375162124633789
Batch 11/64 loss: 0.2576603889465332
Batch 12/64 loss: 0.3863825798034668
Batch 13/64 loss: -0.24656391143798828
Batch 14/64 loss: -0.06463623046875
Batch 15/64 loss: -0.3120841979980469
Batch 16/64 loss: -0.44632625579833984
Batch 17/64 loss: 0.06749677658081055
Batch 18/64 loss: 0.6042566299438477
Batch 19/64 loss: -0.2885580062866211
Batch 20/64 loss: -0.30666446685791016
Batch 21/64 loss: -0.5472631454467773
Batch 22/64 loss: -0.3578310012817383
Batch 23/64 loss: -0.1683335304260254
Batch 24/64 loss: -0.22295475006103516
Batch 25/64 loss: -0.002898693084716797
Batch 26/64 loss: -0.2461719512939453
Batch 27/64 loss: 0.11070823669433594
Batch 28/64 loss: -0.24645328521728516
Batch 29/64 loss: -0.2399139404296875
Batch 30/64 loss: -0.49704456329345703
Batch 31/64 loss: -0.03223609924316406
Batch 32/64 loss: -0.30054569244384766
Batch 33/64 loss: -0.016083717346191406
Batch 34/64 loss: 0.1531963348388672
Batch 35/64 loss: -0.3072338104248047
Batch 36/64 loss: -0.05296134948730469
Batch 37/64 loss: -0.47711849212646484
Batch 38/64 loss: -0.2579689025878906
Batch 39/64 loss: -0.22745800018310547
Batch 40/64 loss: -0.11793756484985352
Batch 41/64 loss: -0.1540994644165039
Batch 42/64 loss: -0.1872396469116211
Batch 43/64 loss: -0.171844482421875
Batch 44/64 loss: -0.4078512191772461
Batch 45/64 loss: -0.38077878952026367
Batch 46/64 loss: -0.2736320495605469
Batch 47/64 loss: -0.15918588638305664
Batch 48/64 loss: -0.01590871810913086
Batch 49/64 loss: 0.06410074234008789
Batch 50/64 loss: -0.29897022247314453
Batch 51/64 loss: -0.17280960083007812
Batch 52/64 loss: 0.005306243896484375
Batch 53/64 loss: -0.33353137969970703
Batch 54/64 loss: 0.28812646865844727
Batch 55/64 loss: -0.10961532592773438
Batch 56/64 loss: -0.02838420867919922
Batch 57/64 loss: -0.0471649169921875
Batch 58/64 loss: -0.46091699600219727
Batch 59/64 loss: 0.2210979461669922
Batch 60/64 loss: 0.007633686065673828
Batch 61/64 loss: -0.18773269653320312
Batch 62/64 loss: -0.1976180076599121
Batch 63/64 loss: -0.21015548706054688
Batch 64/64 loss: -3.8858227729797363
Epoch 50  Train loss: -0.1880983221764658  Val loss: -0.36326225516722377
Saving best model, epoch: 50
Epoch 51
-------------------------------
Batch 1/64 loss: -0.07558012008666992
Batch 2/64 loss: -0.36112213134765625
Batch 3/64 loss: -0.2811298370361328
Batch 4/64 loss: -0.2957592010498047
Batch 5/64 loss: -0.1898174285888672
Batch 6/64 loss: -0.22748470306396484
Batch 7/64 loss: 0.12983083724975586
Batch 8/64 loss: 0.0551300048828125
Batch 9/64 loss: -0.47084522247314453
Batch 10/64 loss: -0.14754104614257812
Batch 11/64 loss: -0.5320186614990234
Batch 12/64 loss: 0.27150440216064453
Batch 13/64 loss: 0.2012629508972168
Batch 14/64 loss: 0.017868995666503906
Batch 15/64 loss: -0.10468578338623047
Batch 16/64 loss: 0.3621954917907715
Batch 17/64 loss: -0.25164318084716797
Batch 18/64 loss: -0.16978693008422852
Batch 19/64 loss: 0.02228260040283203
Batch 20/64 loss: 0.15157699584960938
Batch 21/64 loss: -0.029243946075439453
Batch 22/64 loss: 0.2292613983154297
Batch 23/64 loss: -0.5810518264770508
Batch 24/64 loss: 0.22848987579345703
Batch 25/64 loss: -0.18782806396484375
Batch 26/64 loss: 0.3350944519042969
Batch 27/64 loss: -0.1566333770751953
Batch 28/64 loss: -0.20008087158203125
Batch 29/64 loss: -0.2860283851623535
Batch 30/64 loss: -0.4146146774291992
Batch 31/64 loss: -0.5039758682250977
Batch 32/64 loss: -0.37985897064208984
Batch 33/64 loss: -0.3244171142578125
Batch 34/64 loss: -0.5188875198364258
Batch 35/64 loss: 0.032662391662597656
Batch 36/64 loss: -0.3895235061645508
Batch 37/64 loss: -0.10127878189086914
Batch 38/64 loss: 0.689061164855957
Batch 39/64 loss: -0.6793851852416992
Batch 40/64 loss: -0.49044227600097656
Batch 41/64 loss: -0.33391284942626953
Batch 42/64 loss: -0.3883819580078125
Batch 43/64 loss: -0.1558361053466797
Batch 44/64 loss: -0.24638700485229492
Batch 45/64 loss: 0.10219955444335938
Batch 46/64 loss: -0.20912933349609375
Batch 47/64 loss: -0.47109127044677734
Batch 48/64 loss: -0.3997182846069336
Batch 49/64 loss: -0.1940469741821289
Batch 50/64 loss: -0.40657520294189453
Batch 51/64 loss: -0.6529207229614258
Batch 52/64 loss: -0.13225269317626953
Batch 53/64 loss: 0.040493011474609375
Batch 54/64 loss: -0.056145668029785156
Batch 55/64 loss: -0.4795188903808594
Batch 56/64 loss: -0.17021751403808594
Batch 57/64 loss: -0.14944219589233398
Batch 58/64 loss: -0.2707071304321289
Batch 59/64 loss: -0.036136627197265625
Batch 60/64 loss: -0.2666950225830078
Batch 61/64 loss: -0.11898660659790039
Batch 62/64 loss: -0.40335559844970703
Batch 63/64 loss: 0.020473003387451172
Batch 64/64 loss: -3.9544477462768555
Epoch 51  Train loss: -0.21911483839446422  Val loss: -0.032262664480307665
Epoch 52
-------------------------------
Batch 1/64 loss: -0.26225852966308594
Batch 2/64 loss: -0.11159610748291016
Batch 3/64 loss: 0.25669384002685547
Batch 4/64 loss: 0.18482208251953125
Batch 5/64 loss: -0.016556739807128906
Batch 6/64 loss: 0.6505274772644043
Batch 7/64 loss: -0.09424066543579102
Batch 8/64 loss: -0.4555826187133789
Batch 9/64 loss: -0.3735618591308594
Batch 10/64 loss: -0.2045154571533203
Batch 11/64 loss: 0.2862119674682617
Batch 12/64 loss: -0.2588386535644531
Batch 13/64 loss: -0.2529296875
Batch 14/64 loss: -0.5364837646484375
Batch 15/64 loss: -0.09103107452392578
Batch 16/64 loss: 0.2435626983642578
Batch 17/64 loss: 0.22742176055908203
Batch 18/64 loss: -0.5072832107543945
Batch 19/64 loss: -0.4183998107910156
Batch 20/64 loss: -0.18072891235351562
Batch 21/64 loss: 0.18263721466064453
Batch 22/64 loss: -0.27445316314697266
Batch 23/64 loss: 0.03881072998046875
Batch 24/64 loss: -0.11785173416137695
Batch 25/64 loss: 0.02192401885986328
Batch 26/64 loss: -0.26621055603027344
Batch 27/64 loss: -0.4221763610839844
Batch 28/64 loss: -0.2881011962890625
Batch 29/64 loss: -0.032021522521972656
Batch 30/64 loss: -0.4147148132324219
Batch 31/64 loss: -0.41838836669921875
Batch 32/64 loss: -0.3413267135620117
Batch 33/64 loss: -0.3701963424682617
Batch 34/64 loss: -0.33312225341796875
Batch 35/64 loss: 0.23073625564575195
Batch 36/64 loss: 0.047057151794433594
Batch 37/64 loss: -0.27750396728515625
Batch 38/64 loss: -0.1990509033203125
Batch 39/64 loss: 0.049696922302246094
Batch 40/64 loss: -0.4299945831298828
Batch 41/64 loss: -0.41372108459472656
Batch 42/64 loss: -0.5097942352294922
Batch 43/64 loss: -0.2593269348144531
Batch 44/64 loss: -0.4924898147583008
Batch 45/64 loss: -0.2799549102783203
Batch 46/64 loss: -0.13651609420776367
Batch 47/64 loss: 0.010072708129882812
Batch 48/64 loss: -0.1988983154296875
Batch 49/64 loss: -0.34958553314208984
Batch 50/64 loss: 0.27602243423461914
Batch 51/64 loss: -0.3031158447265625
Batch 52/64 loss: -0.43065309524536133
Batch 53/64 loss: -0.046271324157714844
Batch 54/64 loss: -0.35892486572265625
Batch 55/64 loss: -0.2513446807861328
Batch 56/64 loss: -0.18923664093017578
Batch 57/64 loss: -0.2883872985839844
Batch 58/64 loss: -0.6905488967895508
Batch 59/64 loss: -0.22359371185302734
Batch 60/64 loss: -0.1567831039428711
Batch 61/64 loss: -0.49386119842529297
Batch 62/64 loss: -0.18125629425048828
Batch 63/64 loss: -0.3350677490234375
Batch 64/64 loss: -4.217928409576416
Epoch 52  Train loss: -0.2352266704334932  Val loss: -0.4292567144964159
Saving best model, epoch: 52
Epoch 53
-------------------------------
Batch 1/64 loss: -0.10257434844970703
Batch 2/64 loss: -0.5618791580200195
Batch 3/64 loss: -0.3055706024169922
Batch 4/64 loss: -0.411590576171875
Batch 5/64 loss: -0.43080997467041016
Batch 6/64 loss: 0.06160736083984375
Batch 7/64 loss: -0.27277469635009766
Batch 8/64 loss: -0.2660255432128906
Batch 9/64 loss: -0.4716300964355469
Batch 10/64 loss: -0.5400428771972656
Batch 11/64 loss: -0.100128173828125
Batch 12/64 loss: -0.08366870880126953
Batch 13/64 loss: -0.4890718460083008
Batch 14/64 loss: 0.06615543365478516
Batch 15/64 loss: -0.018530845642089844
Batch 16/64 loss: 0.5589017868041992
Batch 17/64 loss: 0.29747772216796875
Batch 18/64 loss: 0.12394428253173828
Batch 19/64 loss: -0.15539836883544922
Batch 20/64 loss: -0.16495800018310547
Batch 21/64 loss: 0.04204082489013672
Batch 22/64 loss: -0.1239023208618164
Batch 23/64 loss: -0.04986095428466797
Batch 24/64 loss: -0.37385082244873047
Batch 25/64 loss: 0.1662425994873047
Batch 26/64 loss: -0.3921031951904297
Batch 27/64 loss: -0.1771259307861328
Batch 28/64 loss: -0.04639577865600586
Batch 29/64 loss: -0.5599241256713867
Batch 30/64 loss: -0.4723787307739258
Batch 31/64 loss: -0.5204172134399414
Batch 32/64 loss: -0.4846668243408203
Batch 33/64 loss: 0.02371501922607422
Batch 34/64 loss: 0.16991281509399414
Batch 35/64 loss: -0.01768016815185547
Batch 36/64 loss: -0.3112220764160156
Batch 37/64 loss: -0.31187915802001953
Batch 38/64 loss: 0.27984046936035156
Batch 39/64 loss: -0.5172004699707031
Batch 40/64 loss: -0.18472671508789062
Batch 41/64 loss: -0.08405208587646484
Batch 42/64 loss: -0.10782241821289062
Batch 43/64 loss: -0.6504497528076172
Batch 44/64 loss: -0.7915096282958984
Batch 45/64 loss: 0.5715370178222656
Batch 46/64 loss: -0.5636072158813477
Batch 47/64 loss: -0.31429004669189453
Batch 48/64 loss: -0.06356334686279297
Batch 49/64 loss: 0.06456851959228516
Batch 50/64 loss: -0.1956653594970703
Batch 51/64 loss: 0.0022954940795898438
Batch 52/64 loss: -0.4373159408569336
Batch 53/64 loss: -0.015390396118164062
Batch 54/64 loss: -0.2552223205566406
Batch 55/64 loss: 0.19473743438720703
Batch 56/64 loss: -0.5008077621459961
Batch 57/64 loss: 0.009308815002441406
Batch 58/64 loss: -0.42037391662597656
Batch 59/64 loss: 0.09950637817382812
Batch 60/64 loss: -0.4412670135498047
Batch 61/64 loss: -0.42125988006591797
Batch 62/64 loss: -0.44650840759277344
Batch 63/64 loss: -0.3688945770263672
Batch 64/64 loss: -4.355562210083008
Epoch 53  Train loss: -0.24362145966174556  Val loss: -0.1484242075497342
Epoch 54
-------------------------------
Batch 1/64 loss: 0.040924072265625
Batch 2/64 loss: -0.294189453125
Batch 3/64 loss: -0.2149209976196289
Batch 4/64 loss: -0.3609762191772461
Batch 5/64 loss: -0.845372200012207
Batch 6/64 loss: -0.2444772720336914
Batch 7/64 loss: -0.4695320129394531
Batch 8/64 loss: 0.22239923477172852
Batch 9/64 loss: -0.34065914154052734
Batch 10/64 loss: -0.10335540771484375
Batch 11/64 loss: -0.6578769683837891
Batch 12/64 loss: 0.18561077117919922
Batch 13/64 loss: -0.33052921295166016
Batch 14/64 loss: -0.17823028564453125
Batch 15/64 loss: -0.4105224609375
Batch 16/64 loss: -0.16650867462158203
Batch 17/64 loss: 0.05508995056152344
Batch 18/64 loss: -0.4077110290527344
Batch 19/64 loss: -0.18634033203125
Batch 20/64 loss: -0.42046451568603516
Batch 21/64 loss: -0.5968112945556641
Batch 22/64 loss: -0.35277462005615234
Batch 23/64 loss: -0.12495136260986328
Batch 24/64 loss: 0.2467641830444336
Batch 25/64 loss: -0.16340923309326172
Batch 26/64 loss: 0.016493797302246094
Batch 27/64 loss: 0.27264404296875
Batch 28/64 loss: -0.35402774810791016
Batch 29/64 loss: 0.46227169036865234
Batch 30/64 loss: 0.13693952560424805
Batch 31/64 loss: -0.05664348602294922
Batch 32/64 loss: -0.29352855682373047
Batch 33/64 loss: -0.1318960189819336
Batch 34/64 loss: 0.0665121078491211
Batch 35/64 loss: 0.06922435760498047
Batch 36/64 loss: -0.299163818359375
Batch 37/64 loss: 0.030769824981689453
Batch 38/64 loss: -0.1093130111694336
Batch 39/64 loss: -0.6171112060546875
Batch 40/64 loss: -0.31508731842041016
Batch 41/64 loss: -0.06319904327392578
Batch 42/64 loss: -0.3208637237548828
Batch 43/64 loss: 0.02435302734375
Batch 44/64 loss: -0.21310091018676758
Batch 45/64 loss: -0.0864100456237793
Batch 46/64 loss: -0.6682262420654297
Batch 47/64 loss: -0.40947723388671875
Batch 48/64 loss: -0.1447892189025879
Batch 49/64 loss: 0.0826563835144043
Batch 50/64 loss: 0.2578091621398926
Batch 51/64 loss: -0.34518909454345703
Batch 52/64 loss: -0.33118247985839844
Batch 53/64 loss: -0.4738616943359375
Batch 54/64 loss: -0.14629554748535156
Batch 55/64 loss: -0.31854724884033203
Batch 56/64 loss: -0.43213844299316406
Batch 57/64 loss: -0.24592018127441406
Batch 58/64 loss: -0.6666193008422852
Batch 59/64 loss: -0.10146045684814453
Batch 60/64 loss: -0.2179880142211914
Batch 61/64 loss: -0.272705078125
Batch 62/64 loss: -0.2105245590209961
Batch 63/64 loss: -0.21670150756835938
Batch 64/64 loss: -4.247304916381836
Epoch 54  Train loss: -0.25014275195551855  Val loss: 0.04848139392551278
Epoch 55
-------------------------------
Batch 1/64 loss: -0.47011566162109375
Batch 2/64 loss: -0.4274168014526367
Batch 3/64 loss: 0.07431983947753906
Batch 4/64 loss: -0.27268314361572266
Batch 5/64 loss: -0.4260292053222656
Batch 6/64 loss: 0.7617321014404297
Batch 7/64 loss: -0.12493038177490234
Batch 8/64 loss: 0.20008277893066406
Batch 9/64 loss: -0.24133777618408203
Batch 10/64 loss: -0.04955101013183594
Batch 11/64 loss: -0.2023448944091797
Batch 12/64 loss: 0.029303550720214844
Batch 13/64 loss: 0.367311954498291
Batch 14/64 loss: -0.47701263427734375
Batch 15/64 loss: 0.39109134674072266
Batch 16/64 loss: -0.01569652557373047
Batch 17/64 loss: 0.06502056121826172
Batch 18/64 loss: -0.47298431396484375
Batch 19/64 loss: -0.6654434204101562
Batch 20/64 loss: -0.4885396957397461
Batch 21/64 loss: -0.5149660110473633
Batch 22/64 loss: -0.42687416076660156
Batch 23/64 loss: -0.48548221588134766
Batch 24/64 loss: -0.28301048278808594
Batch 25/64 loss: -0.41728973388671875
Batch 26/64 loss: -0.686274528503418
Batch 27/64 loss: 0.27511024475097656
Batch 28/64 loss: -0.3486747741699219
Batch 29/64 loss: -0.3617534637451172
Batch 30/64 loss: -0.30046653747558594
Batch 31/64 loss: -0.15289783477783203
Batch 32/64 loss: -0.2463979721069336
Batch 33/64 loss: -0.3557167053222656
Batch 34/64 loss: -0.3075876235961914
Batch 35/64 loss: -0.12595462799072266
Batch 36/64 loss: -0.3905973434448242
Batch 37/64 loss: -0.523524284362793
Batch 38/64 loss: -0.05243110656738281
Batch 39/64 loss: -0.16359424591064453
Batch 40/64 loss: 0.2817654609680176
Batch 41/64 loss: -0.21498584747314453
Batch 42/64 loss: -0.3164024353027344
Batch 43/64 loss: 0.23962783813476562
Batch 44/64 loss: 0.33721065521240234
Batch 45/64 loss: 0.14988040924072266
Batch 46/64 loss: -0.3070821762084961
Batch 47/64 loss: -0.047107696533203125
Batch 48/64 loss: -0.2338695526123047
Batch 49/64 loss: 0.27254390716552734
Batch 50/64 loss: -0.1935443878173828
Batch 51/64 loss: -0.09951972961425781
Batch 52/64 loss: -0.02062225341796875
Batch 53/64 loss: -0.3887815475463867
Batch 54/64 loss: -0.06961584091186523
Batch 55/64 loss: -0.2816162109375
Batch 56/64 loss: -0.23384571075439453
Batch 57/64 loss: -0.22003841400146484
Batch 58/64 loss: -0.3436746597290039
Batch 59/64 loss: -0.34766483306884766
Batch 60/64 loss: -0.3205561637878418
Batch 61/64 loss: -0.5938520431518555
Batch 62/64 loss: -0.6569595336914062
Batch 63/64 loss: -0.45935535430908203
Batch 64/64 loss: -4.059642314910889
Epoch 55  Train loss: -0.2419828171823539  Val loss: -0.47452338044995707
Saving best model, epoch: 55
Epoch 56
-------------------------------
Batch 1/64 loss: -0.38398265838623047
Batch 2/64 loss: -0.38488292694091797
Batch 3/64 loss: 0.34282636642456055
Batch 4/64 loss: -0.426361083984375
Batch 5/64 loss: -0.19315719604492188
Batch 6/64 loss: -0.20612525939941406
Batch 7/64 loss: 0.13428640365600586
Batch 8/64 loss: -0.3946084976196289
Batch 9/64 loss: -0.33667659759521484
Batch 10/64 loss: -0.2515134811401367
Batch 11/64 loss: -0.47559165954589844
Batch 12/64 loss: 0.5005912780761719
Batch 13/64 loss: -0.44079017639160156
Batch 14/64 loss: -0.17418766021728516
Batch 15/64 loss: -0.36141395568847656
Batch 16/64 loss: -0.24414920806884766
Batch 17/64 loss: -0.5828266143798828
Batch 18/64 loss: -0.3019704818725586
Batch 19/64 loss: -0.21980857849121094
Batch 20/64 loss: -0.3150348663330078
Batch 21/64 loss: 0.10877084732055664
Batch 22/64 loss: 0.005869388580322266
Batch 23/64 loss: -0.5323066711425781
Batch 24/64 loss: -0.25675201416015625
Batch 25/64 loss: -0.5320987701416016
Batch 26/64 loss: -0.24461078643798828
Batch 27/64 loss: -0.6933813095092773
Batch 28/64 loss: -0.46373844146728516
Batch 29/64 loss: 0.03598499298095703
Batch 30/64 loss: -0.5132083892822266
Batch 31/64 loss: -0.4880809783935547
Batch 32/64 loss: -0.08322334289550781
Batch 33/64 loss: -0.14289283752441406
Batch 34/64 loss: -0.1538839340209961
Batch 35/64 loss: -0.3457374572753906
Batch 36/64 loss: -0.47779369354248047
Batch 37/64 loss: -0.8549795150756836
Batch 38/64 loss: -0.5151071548461914
Batch 39/64 loss: -0.10397911071777344
Batch 40/64 loss: -0.2785911560058594
Batch 41/64 loss: -0.4682579040527344
Batch 42/64 loss: -0.4870586395263672
Batch 43/64 loss: -0.623661994934082
Batch 44/64 loss: -0.019118309020996094
Batch 45/64 loss: -0.11331367492675781
Batch 46/64 loss: -0.5167360305786133
Batch 47/64 loss: -0.051753997802734375
Batch 48/64 loss: 0.1812601089477539
Batch 49/64 loss: -0.5838966369628906
Batch 50/64 loss: -0.7657995223999023
Batch 51/64 loss: -0.2850017547607422
Batch 52/64 loss: -0.7055015563964844
Batch 53/64 loss: -0.033504486083984375
Batch 54/64 loss: -0.29082489013671875
Batch 55/64 loss: 0.1438465118408203
Batch 56/64 loss: 0.04781627655029297
Batch 57/64 loss: 0.22738885879516602
Batch 58/64 loss: -0.4647178649902344
Batch 59/64 loss: -0.3190011978149414
Batch 60/64 loss: -0.19323348999023438
Batch 61/64 loss: -0.6392345428466797
Batch 62/64 loss: 0.1754751205444336
Batch 63/64 loss: -0.4790477752685547
Batch 64/64 loss: -3.8209738731384277
Epoch 56  Train loss: -0.3196035291634354  Val loss: -0.46732132377493424
Epoch 57
-------------------------------
Batch 1/64 loss: -0.3224763870239258
Batch 2/64 loss: -0.5935764312744141
Batch 3/64 loss: -0.4384641647338867
Batch 4/64 loss: -0.4096822738647461
Batch 5/64 loss: -0.5444850921630859
Batch 6/64 loss: -0.006257057189941406
Batch 7/64 loss: -0.42203330993652344
Batch 8/64 loss: -0.39759063720703125
Batch 9/64 loss: -0.4542694091796875
Batch 10/64 loss: 0.2496175765991211
Batch 11/64 loss: -0.05021858215332031
Batch 12/64 loss: -0.28580284118652344
Batch 13/64 loss: -0.005733489990234375
Batch 14/64 loss: -0.09266138076782227
Batch 15/64 loss: -0.15864086151123047
Batch 16/64 loss: 0.04245710372924805
Batch 17/64 loss: 0.14208507537841797
Batch 18/64 loss: 0.5677556991577148
Batch 19/64 loss: -0.4698457717895508
Batch 20/64 loss: -0.0697178840637207
Batch 21/64 loss: -0.1279306411743164
Batch 22/64 loss: -0.27956438064575195
Batch 23/64 loss: 0.07996320724487305
Batch 24/64 loss: -0.5872459411621094
Batch 25/64 loss: -0.16147804260253906
Batch 26/64 loss: -0.37899351119995117
Batch 27/64 loss: -0.3145880699157715
Batch 28/64 loss: -0.5381073951721191
Batch 29/64 loss: -0.4939241409301758
Batch 30/64 loss: -0.10591697692871094
Batch 31/64 loss: -0.47110557556152344
Batch 32/64 loss: -0.21377849578857422
Batch 33/64 loss: -0.31635570526123047
Batch 34/64 loss: -0.17438507080078125
Batch 35/64 loss: -0.1564788818359375
Batch 36/64 loss: -0.6224336624145508
Batch 37/64 loss: -0.12383556365966797
Batch 38/64 loss: 0.48397159576416016
Batch 39/64 loss: -0.025682449340820312
Batch 40/64 loss: -0.5167026519775391
Batch 41/64 loss: 0.40598011016845703
Batch 42/64 loss: -0.2782602310180664
Batch 43/64 loss: 0.013477325439453125
Batch 44/64 loss: -0.11035442352294922
Batch 45/64 loss: -0.12869739532470703
Batch 46/64 loss: 0.20462703704833984
Batch 47/64 loss: -0.5332155227661133
Batch 48/64 loss: -0.208343505859375
Batch 49/64 loss: -0.5689506530761719
Batch 50/64 loss: -0.3429269790649414
Batch 51/64 loss: 0.18438053131103516
Batch 52/64 loss: -0.515777587890625
Batch 53/64 loss: -0.4518594741821289
Batch 54/64 loss: 0.4557981491088867
Batch 55/64 loss: -0.8131790161132812
Batch 56/64 loss: -0.33351707458496094
Batch 57/64 loss: -0.4265899658203125
Batch 58/64 loss: -0.7072286605834961
Batch 59/64 loss: -0.0707101821899414
Batch 60/64 loss: -0.07412052154541016
Batch 61/64 loss: -0.8289823532104492
Batch 62/64 loss: -0.31101322174072266
Batch 63/64 loss: 0.22067546844482422
Batch 64/64 loss: -4.227719306945801
Epoch 57  Train loss: -0.2690774917602539  Val loss: -0.4032207239944091
Epoch 58
-------------------------------
Batch 1/64 loss: -0.2679119110107422
Batch 2/64 loss: -0.09213924407958984
Batch 3/64 loss: -0.30966854095458984
Batch 4/64 loss: -0.1865081787109375
Batch 5/64 loss: -0.26654052734375
Batch 6/64 loss: -0.7452173233032227
Batch 7/64 loss: -0.8275432586669922
Batch 8/64 loss: -0.5222282409667969
Batch 9/64 loss: -0.5725917816162109
Batch 10/64 loss: -0.2979393005371094
Batch 11/64 loss: -0.3370361328125
Batch 12/64 loss: 0.014977455139160156
Batch 13/64 loss: -0.3311195373535156
Batch 14/64 loss: -0.10708045959472656
Batch 15/64 loss: -0.6130952835083008
Batch 16/64 loss: 0.0621795654296875
Batch 17/64 loss: -0.06815910339355469
Batch 18/64 loss: -0.39789581298828125
Batch 19/64 loss: 0.29294872283935547
Batch 20/64 loss: 0.06057310104370117
Batch 21/64 loss: -0.4626016616821289
Batch 22/64 loss: -0.12331485748291016
Batch 23/64 loss: -0.30822181701660156
Batch 24/64 loss: 0.4101700782775879
Batch 25/64 loss: -0.42841434478759766
Batch 26/64 loss: 0.04785585403442383
Batch 27/64 loss: -0.18584728240966797
Batch 28/64 loss: -0.15911626815795898
Batch 29/64 loss: -0.30098915100097656
Batch 30/64 loss: -0.1763620376586914
Batch 31/64 loss: -0.20503616333007812
Batch 32/64 loss: -0.35283374786376953
Batch 33/64 loss: -0.6158599853515625
Batch 34/64 loss: -0.36696529388427734
Batch 35/64 loss: -0.34181785583496094
Batch 36/64 loss: -0.23482513427734375
Batch 37/64 loss: -0.2733726501464844
Batch 38/64 loss: -0.22247314453125
Batch 39/64 loss: -0.09650516510009766
Batch 40/64 loss: -0.3398866653442383
Batch 41/64 loss: -0.4283761978149414
Batch 42/64 loss: -0.5721874237060547
Batch 43/64 loss: -0.23254156112670898
Batch 44/64 loss: 0.16170740127563477
Batch 45/64 loss: -0.08133506774902344
Batch 46/64 loss: -0.19266605377197266
Batch 47/64 loss: -0.44603919982910156
Batch 48/64 loss: -0.2051553726196289
Batch 49/64 loss: -0.18787288665771484
Batch 50/64 loss: 0.09446430206298828
Batch 51/64 loss: -0.33278751373291016
Batch 52/64 loss: -0.4711732864379883
Batch 53/64 loss: -0.4282855987548828
Batch 54/64 loss: -0.15059471130371094
Batch 55/64 loss: -0.3711709976196289
Batch 56/64 loss: -0.47202205657958984
Batch 57/64 loss: -0.3794078826904297
Batch 58/64 loss: -0.4423408508300781
Batch 59/64 loss: -0.13771724700927734
Batch 60/64 loss: -0.18774032592773438
Batch 61/64 loss: -0.1838855743408203
Batch 62/64 loss: 0.01192474365234375
Batch 63/64 loss: 0.0027027130126953125
Batch 64/64 loss: -4.517221450805664
Epoch 58  Train loss: -0.30225615407906326  Val loss: -0.5269441637386572
Saving best model, epoch: 58
Epoch 59
-------------------------------
Batch 1/64 loss: -0.4981956481933594
Batch 2/64 loss: -0.14875125885009766
Batch 3/64 loss: -0.2568359375
Batch 4/64 loss: -0.10138416290283203
Batch 5/64 loss: -0.4818267822265625
Batch 6/64 loss: -0.203277587890625
Batch 7/64 loss: -0.6090602874755859
Batch 8/64 loss: -0.12989044189453125
Batch 9/64 loss: -0.613520622253418
Batch 10/64 loss: -0.1294717788696289
Batch 11/64 loss: -0.4124755859375
Batch 12/64 loss: -0.5288658142089844
Batch 13/64 loss: -0.6104955673217773
Batch 14/64 loss: -0.07270145416259766
Batch 15/64 loss: -0.6393985748291016
Batch 16/64 loss: -0.8400640487670898
Batch 17/64 loss: -0.6904067993164062
Batch 18/64 loss: -0.5184726715087891
Batch 19/64 loss: 0.3060188293457031
Batch 20/64 loss: -0.5626707077026367
Batch 21/64 loss: -0.7540445327758789
Batch 22/64 loss: -0.8130474090576172
Batch 23/64 loss: -0.28348445892333984
Batch 24/64 loss: -0.01965618133544922
Batch 25/64 loss: 0.37114810943603516
Batch 26/64 loss: -0.9607076644897461
Batch 27/64 loss: -0.5328693389892578
Batch 28/64 loss: -0.1876049041748047
Batch 29/64 loss: -0.5359411239624023
Batch 30/64 loss: -0.022674560546875
Batch 31/64 loss: -0.4826383590698242
Batch 32/64 loss: -0.29869556427001953
Batch 33/64 loss: -0.12221145629882812
Batch 34/64 loss: -0.5908451080322266
Batch 35/64 loss: -0.23946189880371094
Batch 36/64 loss: -0.3812570571899414
Batch 37/64 loss: -0.4312467575073242
Batch 38/64 loss: -0.43054676055908203
Batch 39/64 loss: -0.7427282333374023
Batch 40/64 loss: -0.0499267578125
Batch 41/64 loss: 0.02979278564453125
Batch 42/64 loss: -0.554194450378418
Batch 43/64 loss: -0.2787361145019531
Batch 44/64 loss: -0.3409433364868164
Batch 45/64 loss: -0.6084051132202148
Batch 46/64 loss: -0.5916070938110352
Batch 47/64 loss: 0.0900564193725586
Batch 48/64 loss: -0.45715904235839844
Batch 49/64 loss: -0.1580343246459961
Batch 50/64 loss: -0.13368797302246094
Batch 51/64 loss: -0.5259647369384766
Batch 52/64 loss: -0.34015846252441406
Batch 53/64 loss: -0.5607423782348633
Batch 54/64 loss: -0.3841133117675781
Batch 55/64 loss: -0.18859004974365234
Batch 56/64 loss: -0.1714954376220703
Batch 57/64 loss: -0.5157337188720703
Batch 58/64 loss: -0.6104898452758789
Batch 59/64 loss: 0.18465232849121094
Batch 60/64 loss: -0.24112319946289062
Batch 61/64 loss: -0.5030879974365234
Batch 62/64 loss: -0.1191701889038086
Batch 63/64 loss: -0.08798027038574219
Batch 64/64 loss: -3.41300106048584
Epoch 59  Train loss: -0.3902251486684762  Val loss: -0.5283597834741127
Saving best model, epoch: 59
Epoch 60
-------------------------------
Batch 1/64 loss: -0.7361116409301758
Batch 2/64 loss: -0.7643413543701172
Batch 3/64 loss: -0.27106666564941406
Batch 4/64 loss: -0.5982112884521484
Batch 5/64 loss: -0.24541187286376953
Batch 6/64 loss: -0.4822502136230469
Batch 7/64 loss: 0.004498481750488281
Batch 8/64 loss: -0.07730674743652344
Batch 9/64 loss: -0.5925703048706055
Batch 10/64 loss: -0.5733013153076172
Batch 11/64 loss: -0.5484895706176758
Batch 12/64 loss: -0.4660148620605469
Batch 13/64 loss: -0.11090087890625
Batch 14/64 loss: -0.1832275390625
Batch 15/64 loss: -0.753870964050293
Batch 16/64 loss: 0.03338623046875
Batch 17/64 loss: -0.2706928253173828
Batch 18/64 loss: -0.2662467956542969
Batch 19/64 loss: -0.5768985748291016
Batch 20/64 loss: -0.5887842178344727
Batch 21/64 loss: -0.27260780334472656
Batch 22/64 loss: -0.14121055603027344
Batch 23/64 loss: -0.556396484375
Batch 24/64 loss: -0.3485736846923828
Batch 25/64 loss: -0.6565561294555664
Batch 26/64 loss: -0.4286184310913086
Batch 27/64 loss: -0.29958057403564453
Batch 28/64 loss: -0.2184429168701172
Batch 29/64 loss: 0.019888877868652344
Batch 30/64 loss: -0.5437936782836914
Batch 31/64 loss: 0.03743934631347656
Batch 32/64 loss: 0.09552192687988281
Batch 33/64 loss: -0.46926403045654297
Batch 34/64 loss: -0.8566598892211914
Batch 35/64 loss: -0.42841148376464844
Batch 36/64 loss: -0.43923377990722656
Batch 37/64 loss: -0.05119037628173828
Batch 38/64 loss: -0.29409027099609375
Batch 39/64 loss: -0.54248046875
Batch 40/64 loss: -0.23177146911621094
Batch 41/64 loss: -0.2412395477294922
Batch 42/64 loss: -0.5635910034179688
Batch 43/64 loss: -0.6137943267822266
Batch 44/64 loss: 0.25472545623779297
Batch 45/64 loss: -0.7911539077758789
Batch 46/64 loss: 0.003696441650390625
Batch 47/64 loss: -0.5838422775268555
Batch 48/64 loss: -0.10268163681030273
Batch 49/64 loss: -0.22882652282714844
Batch 50/64 loss: -0.35258007049560547
Batch 51/64 loss: 0.28000307083129883
Batch 52/64 loss: -0.11740779876708984
Batch 53/64 loss: -0.6193151473999023
Batch 54/64 loss: -0.4188547134399414
Batch 55/64 loss: -0.23174571990966797
Batch 56/64 loss: -0.27185535430908203
Batch 57/64 loss: -0.6204051971435547
Batch 58/64 loss: -0.2525625228881836
Batch 59/64 loss: 0.06483697891235352
Batch 60/64 loss: -0.09414386749267578
Batch 61/64 loss: -0.07299995422363281
Batch 62/64 loss: -0.41934871673583984
Batch 63/64 loss: -0.42621707916259766
Batch 64/64 loss: -3.5566272735595703
Epoch 60  Train loss: -0.373029312432981  Val loss: -0.5414067428955918
Saving best model, epoch: 60
Epoch 61
-------------------------------
Batch 1/64 loss: -0.3959798812866211
Batch 2/64 loss: -0.3415660858154297
Batch 3/64 loss: -0.3856773376464844
Batch 4/64 loss: -0.16982269287109375
Batch 5/64 loss: -0.7196369171142578
Batch 6/64 loss: -0.6408424377441406
Batch 7/64 loss: 0.2685403823852539
Batch 8/64 loss: -0.5020055770874023
Batch 9/64 loss: -0.38113927841186523
Batch 10/64 loss: -0.19701623916625977
Batch 11/64 loss: -0.6096725463867188
Batch 12/64 loss: -0.6200180053710938
Batch 13/64 loss: 0.03662919998168945
Batch 14/64 loss: -0.3635845184326172
Batch 15/64 loss: -0.577427864074707
Batch 16/64 loss: -0.43206310272216797
Batch 17/64 loss: -0.4858255386352539
Batch 18/64 loss: -0.5009860992431641
Batch 19/64 loss: -0.47781944274902344
Batch 20/64 loss: -0.26184940338134766
Batch 21/64 loss: -0.6659984588623047
Batch 22/64 loss: -0.5503149032592773
Batch 23/64 loss: -0.15818405151367188
Batch 24/64 loss: -0.6026287078857422
Batch 25/64 loss: -0.6937999725341797
Batch 26/64 loss: -0.46719837188720703
Batch 27/64 loss: -0.26428890228271484
Batch 28/64 loss: -0.2988882064819336
Batch 29/64 loss: 0.3349418640136719
Batch 30/64 loss: -0.12668132781982422
Batch 31/64 loss: -0.42623329162597656
Batch 32/64 loss: -0.5632352828979492
Batch 33/64 loss: -0.3294076919555664
Batch 34/64 loss: 0.01758861541748047
Batch 35/64 loss: -0.12092208862304688
Batch 36/64 loss: 0.25611209869384766
Batch 37/64 loss: -0.15120315551757812
Batch 38/64 loss: 0.17565250396728516
Batch 39/64 loss: -0.11673641204833984
Batch 40/64 loss: 0.5433077812194824
Batch 41/64 loss: -0.502232551574707
Batch 42/64 loss: 0.056537628173828125
Batch 43/64 loss: 0.044234275817871094
Batch 44/64 loss: -0.4622821807861328
Batch 45/64 loss: -0.4496955871582031
Batch 46/64 loss: -0.18349647521972656
Batch 47/64 loss: -0.5265188217163086
Batch 48/64 loss: -0.4560518264770508
Batch 49/64 loss: -0.5005979537963867
Batch 50/64 loss: -0.4943399429321289
Batch 51/64 loss: -0.27620697021484375
Batch 52/64 loss: -0.5958271026611328
Batch 53/64 loss: -0.5780487060546875
Batch 54/64 loss: -0.6283159255981445
Batch 55/64 loss: -0.2469196319580078
Batch 56/64 loss: 0.11625194549560547
Batch 57/64 loss: -0.4605998992919922
Batch 58/64 loss: -0.32784557342529297
Batch 59/64 loss: -0.27491283416748047
Batch 60/64 loss: -0.3588123321533203
Batch 61/64 loss: -0.20264339447021484
Batch 62/64 loss: -0.7384805679321289
Batch 63/64 loss: -0.1530160903930664
Batch 64/64 loss: -3.600574493408203
Epoch 61  Train loss: -0.35868443507774206  Val loss: -0.5345770714618906
Epoch 62
-------------------------------
Batch 1/64 loss: -0.5991621017456055
Batch 2/64 loss: -0.5439186096191406
Batch 3/64 loss: -0.27213096618652344
Batch 4/64 loss: -0.18428421020507812
Batch 5/64 loss: -0.4539327621459961
Batch 6/64 loss: -0.14643478393554688
Batch 7/64 loss: -0.07419681549072266
Batch 8/64 loss: -0.3783454895019531
Batch 9/64 loss: -0.20860004425048828
Batch 10/64 loss: -0.6126222610473633
Batch 11/64 loss: -0.39055728912353516
Batch 12/64 loss: -0.08826684951782227
Batch 13/64 loss: -0.4796772003173828
Batch 14/64 loss: -0.7423105239868164
Batch 15/64 loss: -0.4220085144042969
Batch 16/64 loss: -0.45991039276123047
Batch 17/64 loss: -0.671015739440918
Batch 18/64 loss: -0.5544595718383789
Batch 19/64 loss: 0.1601085662841797
Batch 20/64 loss: -0.2810945510864258
Batch 21/64 loss: -0.4867830276489258
Batch 22/64 loss: -0.9366846084594727
Batch 23/64 loss: -0.3291797637939453
Batch 24/64 loss: -0.23436355590820312
Batch 25/64 loss: -0.2926511764526367
Batch 26/64 loss: -0.31978702545166016
Batch 27/64 loss: -0.2902050018310547
Batch 28/64 loss: 0.10979461669921875
Batch 29/64 loss: -0.5470466613769531
Batch 30/64 loss: -0.26868629455566406
Batch 31/64 loss: -0.28600502014160156
Batch 32/64 loss: -0.28980541229248047
Batch 33/64 loss: -0.12656021118164062
Batch 34/64 loss: -0.17313575744628906
Batch 35/64 loss: -0.3972921371459961
Batch 36/64 loss: -0.5196027755737305
Batch 37/64 loss: -0.4264240264892578
Batch 38/64 loss: -0.1624317169189453
Batch 39/64 loss: -0.7505731582641602
Batch 40/64 loss: -0.633152961730957
Batch 41/64 loss: -0.6764135360717773
Batch 42/64 loss: -0.5808000564575195
Batch 43/64 loss: -0.1552143096923828
Batch 44/64 loss: 0.244415283203125
Batch 45/64 loss: -0.11773204803466797
Batch 46/64 loss: -0.1471853256225586
Batch 47/64 loss: -0.12371349334716797
Batch 48/64 loss: -0.4706144332885742
Batch 49/64 loss: -0.39005470275878906
Batch 50/64 loss: -0.17514896392822266
Batch 51/64 loss: -0.5425052642822266
Batch 52/64 loss: -0.7619190216064453
Batch 53/64 loss: -0.7571372985839844
Batch 54/64 loss: -0.3455772399902344
Batch 55/64 loss: -0.06820201873779297
Batch 56/64 loss: -0.20736980438232422
Batch 57/64 loss: 0.1870098114013672
Batch 58/64 loss: -0.21558666229248047
Batch 59/64 loss: -0.5160379409790039
Batch 60/64 loss: -0.7608766555786133
Batch 61/64 loss: 0.0070819854736328125
Batch 62/64 loss: -0.5623245239257812
Batch 63/64 loss: -0.35468578338623047
Batch 64/64 loss: -4.226165771484375
Epoch 62  Train loss: -0.39880175871007584  Val loss: -0.39916585810815347
Epoch 63
-------------------------------
Batch 1/64 loss: -0.48441505432128906
Batch 2/64 loss: -0.42598915100097656
Batch 3/64 loss: -0.6410655975341797
Batch 4/64 loss: -0.5247411727905273
Batch 5/64 loss: -0.0006990432739257812
Batch 6/64 loss: -0.4595527648925781
Batch 7/64 loss: -0.3959064483642578
Batch 8/64 loss: -0.445404052734375
Batch 9/64 loss: -0.29471302032470703
Batch 10/64 loss: -0.2528982162475586
Batch 11/64 loss: -0.19141674041748047
Batch 12/64 loss: -0.17791223526000977
Batch 13/64 loss: -0.6117563247680664
Batch 14/64 loss: -0.508580207824707
Batch 15/64 loss: -0.3578338623046875
Batch 16/64 loss: -0.3935127258300781
Batch 17/64 loss: -0.3639688491821289
Batch 18/64 loss: 0.18645286560058594
Batch 19/64 loss: -0.5194530487060547
Batch 20/64 loss: 0.05869007110595703
Batch 21/64 loss: -0.49694156646728516
Batch 22/64 loss: 0.12163925170898438
Batch 23/64 loss: -0.5093555450439453
Batch 24/64 loss: -0.4160146713256836
Batch 25/64 loss: -0.41612911224365234
Batch 26/64 loss: -0.7769765853881836
Batch 27/64 loss: -0.16833114624023438
Batch 28/64 loss: -0.49373531341552734
Batch 29/64 loss: -0.4095621109008789
Batch 30/64 loss: -0.19293689727783203
Batch 31/64 loss: -0.4399147033691406
Batch 32/64 loss: -0.30222129821777344
Batch 33/64 loss: -0.23952770233154297
Batch 34/64 loss: -0.21187734603881836
Batch 35/64 loss: 0.016518115997314453
Batch 36/64 loss: -0.2948427200317383
Batch 37/64 loss: -0.8784008026123047
Batch 38/64 loss: -0.18658828735351562
Batch 39/64 loss: -0.66070556640625
Batch 40/64 loss: -0.50848388671875
Batch 41/64 loss: -0.5818920135498047
Batch 42/64 loss: -0.24274492263793945
Batch 43/64 loss: -0.7124958038330078
Batch 44/64 loss: -0.2674722671508789
Batch 45/64 loss: -0.3979215621948242
Batch 46/64 loss: -0.36049461364746094
Batch 47/64 loss: -0.3371877670288086
Batch 48/64 loss: -0.35845375061035156
Batch 49/64 loss: -0.3280668258666992
Batch 50/64 loss: -0.3763599395751953
Batch 51/64 loss: -0.03753376007080078
Batch 52/64 loss: -0.3914918899536133
Batch 53/64 loss: -0.8655405044555664
Batch 54/64 loss: -0.29486083984375
Batch 55/64 loss: 0.061267852783203125
Batch 56/64 loss: -0.5141496658325195
Batch 57/64 loss: -0.27614879608154297
Batch 58/64 loss: -0.5890798568725586
Batch 59/64 loss: -0.6181831359863281
Batch 60/64 loss: -0.2416543960571289
Batch 61/64 loss: -0.7310953140258789
Batch 62/64 loss: -0.3141765594482422
Batch 63/64 loss: -0.4981966018676758
Batch 64/64 loss: -4.368987560272217
Epoch 63  Train loss: -0.42070175806681315  Val loss: -0.48703259864623605
Epoch 64
-------------------------------
Batch 1/64 loss: -0.23825836181640625
Batch 2/64 loss: -0.3739128112792969
Batch 3/64 loss: -0.5993528366088867
Batch 4/64 loss: -0.7689504623413086
Batch 5/64 loss: -0.30908775329589844
Batch 6/64 loss: -0.17978668212890625
Batch 7/64 loss: -0.6482858657836914
Batch 8/64 loss: -0.5915155410766602
Batch 9/64 loss: -0.6341543197631836
Batch 10/64 loss: -0.4760169982910156
Batch 11/64 loss: -0.9607686996459961
Batch 12/64 loss: -0.3890380859375
Batch 13/64 loss: 0.039188385009765625
Batch 14/64 loss: -0.6333503723144531
Batch 15/64 loss: -0.5879402160644531
Batch 16/64 loss: -0.4748353958129883
Batch 17/64 loss: -0.41108131408691406
Batch 18/64 loss: -0.9610109329223633
Batch 19/64 loss: -0.5458698272705078
Batch 20/64 loss: -0.2841634750366211
Batch 21/64 loss: 0.22072219848632812
Batch 22/64 loss: -0.1932363510131836
Batch 23/64 loss: -0.2178192138671875
Batch 24/64 loss: -0.41576671600341797
Batch 25/64 loss: -0.39110660552978516
Batch 26/64 loss: 0.021242618560791016
Batch 27/64 loss: -0.23997879028320312
Batch 28/64 loss: -0.32646846771240234
Batch 29/64 loss: -0.23604631423950195
Batch 30/64 loss: -0.5440549850463867
Batch 31/64 loss: -0.2651505470275879
Batch 32/64 loss: -0.1941690444946289
Batch 33/64 loss: -0.25194644927978516
Batch 34/64 loss: 0.018595218658447266
Batch 35/64 loss: -0.5072774887084961
Batch 36/64 loss: -0.5855216979980469
Batch 37/64 loss: 0.1538553237915039
Batch 38/64 loss: -0.6762609481811523
Batch 39/64 loss: -0.06322765350341797
Batch 40/64 loss: -0.2731618881225586
Batch 41/64 loss: -0.6197748184204102
Batch 42/64 loss: -0.3182048797607422
Batch 43/64 loss: 0.11486673355102539
Batch 44/64 loss: -0.19046783447265625
Batch 45/64 loss: -0.5505743026733398
Batch 46/64 loss: -0.15575218200683594
Batch 47/64 loss: 0.3461880683898926
Batch 48/64 loss: -0.32468223571777344
Batch 49/64 loss: 0.25000476837158203
Batch 50/64 loss: -0.4135303497314453
Batch 51/64 loss: -0.3508014678955078
Batch 52/64 loss: -0.2744331359863281
Batch 53/64 loss: 0.18255233764648438
Batch 54/64 loss: 0.05363750457763672
Batch 55/64 loss: -0.41986656188964844
Batch 56/64 loss: -0.29910755157470703
Batch 57/64 loss: -0.20543384552001953
Batch 58/64 loss: -0.6907339096069336
Batch 59/64 loss: -0.023911476135253906
Batch 60/64 loss: -0.6247663497924805
Batch 61/64 loss: -0.5126676559448242
Batch 62/64 loss: 0.2620229721069336
Batch 63/64 loss: -0.4256610870361328
Batch 64/64 loss: -4.260291576385498
Epoch 64  Train loss: -0.3667652597614363  Val loss: -0.39161730631929903
Epoch 65
-------------------------------
Batch 1/64 loss: -0.3078899383544922
Batch 2/64 loss: -0.33849334716796875
Batch 3/64 loss: -0.07401180267333984
Batch 4/64 loss: -0.2753591537475586
Batch 5/64 loss: 0.020438194274902344
Batch 6/64 loss: -0.34441280364990234
Batch 7/64 loss: -0.4015388488769531
Batch 8/64 loss: -0.23438262939453125
Batch 9/64 loss: -0.5948305130004883
Batch 10/64 loss: -0.8192663192749023
Batch 11/64 loss: -0.4322471618652344
Batch 12/64 loss: 0.00234222412109375
Batch 13/64 loss: -0.15157604217529297
Batch 14/64 loss: -0.20015525817871094
Batch 15/64 loss: -0.4192028045654297
Batch 16/64 loss: 0.048206329345703125
Batch 17/64 loss: 0.5654449462890625
Batch 18/64 loss: -0.28757762908935547
Batch 19/64 loss: -0.7861356735229492
Batch 20/64 loss: -0.28212738037109375
Batch 21/64 loss: -0.07941436767578125
Batch 22/64 loss: -0.08345365524291992
Batch 23/64 loss: -0.6169900894165039
Batch 24/64 loss: -0.46897268295288086
Batch 25/64 loss: -0.37363624572753906
Batch 26/64 loss: -0.15665340423583984
Batch 27/64 loss: -0.43790435791015625
Batch 28/64 loss: -0.5027008056640625
Batch 29/64 loss: -0.3204154968261719
Batch 30/64 loss: -0.3229055404663086
Batch 31/64 loss: -0.6010456085205078
Batch 32/64 loss: -0.03355121612548828
Batch 33/64 loss: -0.4092845916748047
Batch 34/64 loss: -0.6036043167114258
Batch 35/64 loss: -0.2124013900756836
Batch 36/64 loss: -0.6073312759399414
Batch 37/64 loss: -0.15754270553588867
Batch 38/64 loss: -0.26233959197998047
Batch 39/64 loss: -0.7044744491577148
Batch 40/64 loss: 0.11052560806274414
Batch 41/64 loss: -0.5032110214233398
Batch 42/64 loss: 0.09111690521240234
Batch 43/64 loss: -0.31694698333740234
Batch 44/64 loss: 0.11550140380859375
Batch 45/64 loss: -0.23625898361206055
Batch 46/64 loss: -0.21811866760253906
Batch 47/64 loss: 0.10358047485351562
Batch 48/64 loss: -0.41760826110839844
Batch 49/64 loss: -0.22325515747070312
Batch 50/64 loss: -0.35679149627685547
Batch 51/64 loss: -0.7047624588012695
Batch 52/64 loss: -0.05472755432128906
Batch 53/64 loss: -0.16956806182861328
Batch 54/64 loss: -0.5685739517211914
Batch 55/64 loss: -0.040277957916259766
Batch 56/64 loss: -0.23865747451782227
Batch 57/64 loss: -0.30928897857666016
Batch 58/64 loss: -0.0444793701171875
Batch 59/64 loss: -0.30615997314453125
Batch 60/64 loss: -0.3684272766113281
Batch 61/64 loss: -0.30996227264404297
Batch 62/64 loss: -0.10233783721923828
Batch 63/64 loss: -0.3456296920776367
Batch 64/64 loss: -4.602419376373291
Epoch 65  Train loss: -0.331506368225696  Val loss: -0.4848776879589173
Epoch 66
-------------------------------
Batch 1/64 loss: -0.1266794204711914
Batch 2/64 loss: -0.5544033050537109
Batch 3/64 loss: -0.15642642974853516
Batch 4/64 loss: -0.16060161590576172
Batch 5/64 loss: 0.07744359970092773
Batch 6/64 loss: -0.21561908721923828
Batch 7/64 loss: -0.3682546615600586
Batch 8/64 loss: -0.2116832733154297
Batch 9/64 loss: -0.33248138427734375
Batch 10/64 loss: -0.6403865814208984
Batch 11/64 loss: -0.3351297378540039
Batch 12/64 loss: -0.5013761520385742
Batch 13/64 loss: -0.34107112884521484
Batch 14/64 loss: -0.4951057434082031
Batch 15/64 loss: -0.23678112030029297
Batch 16/64 loss: -0.7428779602050781
Batch 17/64 loss: 0.1570415496826172
Batch 18/64 loss: -0.5016107559204102
Batch 19/64 loss: 0.15275001525878906
Batch 20/64 loss: -0.5065803527832031
Batch 21/64 loss: -0.6162443161010742
Batch 22/64 loss: -0.26064205169677734
Batch 23/64 loss: 0.648918628692627
Batch 24/64 loss: -0.35830020904541016
Batch 25/64 loss: -0.45589160919189453
Batch 26/64 loss: -0.52264404296875
Batch 27/64 loss: -0.38811206817626953
Batch 28/64 loss: -0.21774673461914062
Batch 29/64 loss: -0.47977685928344727
Batch 30/64 loss: -0.40746116638183594
Batch 31/64 loss: -0.47589778900146484
Batch 32/64 loss: 0.35568714141845703
Batch 33/64 loss: -0.5072050094604492
Batch 34/64 loss: -0.4468107223510742
Batch 35/64 loss: -0.2769598960876465
Batch 36/64 loss: -0.3901071548461914
Batch 37/64 loss: -0.5906534194946289
Batch 38/64 loss: -0.6731662750244141
Batch 39/64 loss: -0.8032770156860352
Batch 40/64 loss: -0.9312429428100586
Batch 41/64 loss: -0.21985864639282227
Batch 42/64 loss: -0.44098567962646484
Batch 43/64 loss: -0.49104881286621094
Batch 44/64 loss: -0.7260379791259766
Batch 45/64 loss: -0.1615915298461914
Batch 46/64 loss: -0.7671022415161133
Batch 47/64 loss: -0.12115907669067383
Batch 48/64 loss: -0.8045377731323242
Batch 49/64 loss: -0.13868141174316406
Batch 50/64 loss: -0.27606201171875
Batch 51/64 loss: -0.6722269058227539
Batch 52/64 loss: -0.3098573684692383
Batch 53/64 loss: -0.7132892608642578
Batch 54/64 loss: -0.27672863006591797
Batch 55/64 loss: -0.1835622787475586
Batch 56/64 loss: -0.3097114562988281
Batch 57/64 loss: -0.7981224060058594
Batch 58/64 loss: -0.36853885650634766
Batch 59/64 loss: -0.6461515426635742
Batch 60/64 loss: -0.21279525756835938
Batch 61/64 loss: -0.20618629455566406
Batch 62/64 loss: -1.0084733963012695
Batch 63/64 loss: -0.6392011642456055
Batch 64/64 loss: -4.500612735748291
Epoch 66  Train loss: -0.4345841033785951  Val loss: -0.6392244293108019
Saving best model, epoch: 66
Epoch 67
-------------------------------
Batch 1/64 loss: -0.5690317153930664
Batch 2/64 loss: -0.4836301803588867
Batch 3/64 loss: -0.5334548950195312
Batch 4/64 loss: -0.7353839874267578
Batch 5/64 loss: -0.34816455841064453
Batch 6/64 loss: -0.40612316131591797
Batch 7/64 loss: 0.24312400817871094
Batch 8/64 loss: -0.41776561737060547
Batch 9/64 loss: -0.5185651779174805
Batch 10/64 loss: -0.47538185119628906
Batch 11/64 loss: 0.03935718536376953
Batch 12/64 loss: -0.430328369140625
Batch 13/64 loss: -0.19847774505615234
Batch 14/64 loss: -0.5513639450073242
Batch 15/64 loss: -0.4077796936035156
Batch 16/64 loss: -0.35697078704833984
Batch 17/64 loss: -0.6915273666381836
Batch 18/64 loss: 0.05343055725097656
Batch 19/64 loss: -0.522374153137207
Batch 20/64 loss: -0.2056722640991211
Batch 21/64 loss: 0.613433837890625
Batch 22/64 loss: -0.4926910400390625
Batch 23/64 loss: -1.0362796783447266
Batch 24/64 loss: -0.6534919738769531
Batch 25/64 loss: -0.4276857376098633
Batch 26/64 loss: -0.6639785766601562
Batch 27/64 loss: -0.2965526580810547
Batch 28/64 loss: -0.6908979415893555
Batch 29/64 loss: -0.49266529083251953
Batch 30/64 loss: -0.5566892623901367
Batch 31/64 loss: -0.8694057464599609
Batch 32/64 loss: -0.2819995880126953
Batch 33/64 loss: -0.38759613037109375
Batch 34/64 loss: -0.36621570587158203
Batch 35/64 loss: -0.6881399154663086
Batch 36/64 loss: -0.31195831298828125
Batch 37/64 loss: -0.5641098022460938
Batch 38/64 loss: -0.2945070266723633
Batch 39/64 loss: -0.3702821731567383
Batch 40/64 loss: -0.4685535430908203
Batch 41/64 loss: -0.4515857696533203
Batch 42/64 loss: -0.14892959594726562
Batch 43/64 loss: -0.13261795043945312
Batch 44/64 loss: -0.6487913131713867
Batch 45/64 loss: 0.043740272521972656
Batch 46/64 loss: -0.6432828903198242
Batch 47/64 loss: -0.5630912780761719
Batch 48/64 loss: -0.753809928894043
Batch 49/64 loss: -0.35986804962158203
Batch 50/64 loss: -0.5806303024291992
Batch 51/64 loss: -0.5066709518432617
Batch 52/64 loss: -0.4042015075683594
Batch 53/64 loss: -0.8219547271728516
Batch 54/64 loss: -0.6859283447265625
Batch 55/64 loss: -0.2267589569091797
Batch 56/64 loss: -0.5595855712890625
Batch 57/64 loss: -0.9243068695068359
Batch 58/64 loss: 0.13092994689941406
Batch 59/64 loss: -0.1919708251953125
Batch 60/64 loss: -0.781855583190918
Batch 61/64 loss: -0.7094497680664062
Batch 62/64 loss: -0.4414825439453125
Batch 63/64 loss: -0.3401670455932617
Batch 64/64 loss: -4.387198448181152
Epoch 67  Train loss: -0.48327871958414714  Val loss: -0.6455203708504483
Saving best model, epoch: 67
Epoch 68
-------------------------------
Batch 1/64 loss: -0.5548801422119141
Batch 2/64 loss: -0.2461996078491211
Batch 3/64 loss: -0.5027437210083008
Batch 4/64 loss: -0.8064117431640625
Batch 5/64 loss: -0.8043956756591797
Batch 6/64 loss: -0.4942960739135742
Batch 7/64 loss: -0.4896974563598633
Batch 8/64 loss: -0.5124807357788086
Batch 9/64 loss: -0.4376077651977539
Batch 10/64 loss: -0.9017715454101562
Batch 11/64 loss: -0.6847763061523438
Batch 12/64 loss: 0.17218303680419922
Batch 13/64 loss: -0.22878646850585938
Batch 14/64 loss: -0.32515621185302734
Batch 15/64 loss: -0.5137853622436523
Batch 16/64 loss: -0.18569564819335938
Batch 17/64 loss: -0.3681449890136719
Batch 18/64 loss: -0.49828529357910156
Batch 19/64 loss: -0.3937244415283203
Batch 20/64 loss: -0.31099891662597656
Batch 21/64 loss: -0.34459829330444336
Batch 22/64 loss: -0.6999778747558594
Batch 23/64 loss: -0.6889028549194336
Batch 24/64 loss: -0.4674673080444336
Batch 25/64 loss: -0.5126180648803711
Batch 26/64 loss: -0.567103385925293
Batch 27/64 loss: -0.2820758819580078
Batch 28/64 loss: -0.3222236633300781
Batch 29/64 loss: -0.7131109237670898
Batch 30/64 loss: -0.3696136474609375
Batch 31/64 loss: -0.23886775970458984
Batch 32/64 loss: -0.6575736999511719
Batch 33/64 loss: -0.4723825454711914
Batch 34/64 loss: -0.7016506195068359
Batch 35/64 loss: -0.28049373626708984
Batch 36/64 loss: -0.5466289520263672
Batch 37/64 loss: -0.24994277954101562
Batch 38/64 loss: -0.28793907165527344
Batch 39/64 loss: -0.5560684204101562
Batch 40/64 loss: -0.7307071685791016
Batch 41/64 loss: -0.6017999649047852
Batch 42/64 loss: -0.6775197982788086
Batch 43/64 loss: -0.4846172332763672
Batch 44/64 loss: -0.2868232727050781
Batch 45/64 loss: -0.6943283081054688
Batch 46/64 loss: -0.02914714813232422
Batch 47/64 loss: -0.18227291107177734
Batch 48/64 loss: -0.5088119506835938
Batch 49/64 loss: 0.004084587097167969
Batch 50/64 loss: -0.5431127548217773
Batch 51/64 loss: -0.5863018035888672
Batch 52/64 loss: -0.7890291213989258
Batch 53/64 loss: 0.2631406784057617
Batch 54/64 loss: -0.2897472381591797
Batch 55/64 loss: -0.684819221496582
Batch 56/64 loss: -0.6478166580200195
Batch 57/64 loss: -0.4198122024536133
Batch 58/64 loss: -0.2115039825439453
Batch 59/64 loss: -0.09034252166748047
Batch 60/64 loss: 0.025304794311523438
Batch 61/64 loss: -0.19761085510253906
Batch 62/64 loss: -0.23256969451904297
Batch 63/64 loss: -0.45362377166748047
Batch 64/64 loss: -3.447683334350586
Epoch 68  Train loss: -0.46560697368547027  Val loss: -0.4633406150791653
Epoch 69
-------------------------------
Batch 1/64 loss: -0.5185766220092773
Batch 2/64 loss: -0.4457111358642578
Batch 3/64 loss: -0.64373779296875
Batch 4/64 loss: -0.25897884368896484
Batch 5/64 loss: -0.012605667114257812
Batch 6/64 loss: -0.4925880432128906
Batch 7/64 loss: -0.06205558776855469
Batch 8/64 loss: -0.7958354949951172
Batch 9/64 loss: -0.5964326858520508
Batch 10/64 loss: -0.8359823226928711
Batch 11/64 loss: -0.6723251342773438
Batch 12/64 loss: -0.5390214920043945
Batch 13/64 loss: -0.2777080535888672
Batch 14/64 loss: -0.4815711975097656
Batch 15/64 loss: -0.6136131286621094
Batch 16/64 loss: -0.5338115692138672
Batch 17/64 loss: -0.1250314712524414
Batch 18/64 loss: -0.637904167175293
Batch 19/64 loss: -0.06282329559326172
Batch 20/64 loss: -0.4246711730957031
Batch 21/64 loss: 0.14204788208007812
Batch 22/64 loss: 0.16354751586914062
Batch 23/64 loss: -0.329864501953125
Batch 24/64 loss: -0.6832180023193359
Batch 25/64 loss: -0.6035137176513672
Batch 26/64 loss: -0.4895963668823242
Batch 27/64 loss: -0.4955005645751953
Batch 28/64 loss: -0.18775653839111328
Batch 29/64 loss: -0.7589130401611328
Batch 30/64 loss: -0.31200695037841797
Batch 31/64 loss: -0.345001220703125
Batch 32/64 loss: -0.3657236099243164
Batch 33/64 loss: -0.7174644470214844
Batch 34/64 loss: -0.670292854309082
Batch 35/64 loss: -0.46337318420410156
Batch 36/64 loss: 0.2889738082885742
Batch 37/64 loss: -0.5138664245605469
Batch 38/64 loss: -0.40073299407958984
Batch 39/64 loss: -1.0142555236816406
Batch 40/64 loss: -0.3227405548095703
Batch 41/64 loss: -0.7385406494140625
Batch 42/64 loss: -0.4425029754638672
Batch 43/64 loss: -0.9053201675415039
Batch 44/64 loss: -0.43631553649902344
Batch 45/64 loss: -0.4322776794433594
Batch 46/64 loss: 0.1841907501220703
Batch 47/64 loss: -0.31917762756347656
Batch 48/64 loss: -0.2368488311767578
Batch 49/64 loss: -0.10876655578613281
Batch 50/64 loss: -0.08934211730957031
Batch 51/64 loss: -0.4062929153442383
Batch 52/64 loss: -0.15642738342285156
Batch 53/64 loss: -0.8065347671508789
Batch 54/64 loss: -0.7493982315063477
Batch 55/64 loss: -0.7796993255615234
Batch 56/64 loss: -0.616999626159668
Batch 57/64 loss: 0.3572988510131836
Batch 58/64 loss: -0.41567230224609375
Batch 59/64 loss: -0.16418838500976562
Batch 60/64 loss: -0.6529607772827148
Batch 61/64 loss: -0.6806917190551758
Batch 62/64 loss: -0.6944437026977539
Batch 63/64 loss: -0.7423610687255859
Batch 64/64 loss: -4.426590442657471
Epoch 69  Train loss: -0.4778580665588379  Val loss: -0.3714284077542754
Epoch 70
-------------------------------
Batch 1/64 loss: -0.24347496032714844
Batch 2/64 loss: -0.23465633392333984
Batch 3/64 loss: -0.5704193115234375
Batch 4/64 loss: 1.1225996017456055
Batch 5/64 loss: -0.39481353759765625
Batch 6/64 loss: -0.21075725555419922
Batch 7/64 loss: -0.5382633209228516
Batch 8/64 loss: -0.14340496063232422
Batch 9/64 loss: -0.3771066665649414
Batch 10/64 loss: -0.5894298553466797
Batch 11/64 loss: -0.043227195739746094
Batch 12/64 loss: -0.7728176116943359
Batch 13/64 loss: -0.5054225921630859
Batch 14/64 loss: -0.18726253509521484
Batch 15/64 loss: -0.538477897644043
Batch 16/64 loss: -0.2503213882446289
Batch 17/64 loss: -0.7750682830810547
Batch 18/64 loss: -0.7511930465698242
Batch 19/64 loss: -0.6416540145874023
Batch 20/64 loss: -0.8562707901000977
Batch 21/64 loss: -0.6008310317993164
Batch 22/64 loss: -0.3952035903930664
Batch 23/64 loss: -0.1733074188232422
Batch 24/64 loss: -0.5652256011962891
Batch 25/64 loss: -0.3728818893432617
Batch 26/64 loss: -0.9051427841186523
Batch 27/64 loss: -0.7408275604248047
Batch 28/64 loss: -0.23952865600585938
Batch 29/64 loss: -0.6478977203369141
Batch 30/64 loss: -0.8902664184570312
Batch 31/64 loss: -0.6848106384277344
Batch 32/64 loss: -0.9195451736450195
Batch 33/64 loss: -0.8563480377197266
Batch 34/64 loss: -0.3721456527709961
Batch 35/64 loss: -0.4813251495361328
Batch 36/64 loss: -0.11479902267456055
Batch 37/64 loss: -0.30391597747802734
Batch 38/64 loss: -0.3007345199584961
Batch 39/64 loss: -0.99786376953125
Batch 40/64 loss: -0.11349678039550781
Batch 41/64 loss: -0.9219341278076172
Batch 42/64 loss: -0.6090927124023438
Batch 43/64 loss: -0.550868034362793
Batch 44/64 loss: -0.5591697692871094
Batch 45/64 loss: -0.48692798614501953
Batch 46/64 loss: -0.6251935958862305
Batch 47/64 loss: -0.7939329147338867
Batch 48/64 loss: 0.020326614379882812
Batch 49/64 loss: 0.031095504760742188
Batch 50/64 loss: -0.7799654006958008
Batch 51/64 loss: -0.2620677947998047
Batch 52/64 loss: -0.34677696228027344
Batch 53/64 loss: -0.7414827346801758
Batch 54/64 loss: -0.5730705261230469
Batch 55/64 loss: -0.3252372741699219
Batch 56/64 loss: 0.005276679992675781
Batch 57/64 loss: -0.831273078918457
Batch 58/64 loss: -0.2917900085449219
Batch 59/64 loss: -0.25812530517578125
Batch 60/64 loss: -0.4776935577392578
Batch 61/64 loss: -0.7241239547729492
Batch 62/64 loss: -0.18744945526123047
Batch 63/64 loss: -0.7712955474853516
Batch 64/64 loss: -4.042283058166504
Epoch 70  Train loss: -0.5061964483822093  Val loss: -0.5730854178622007
Epoch 71
-------------------------------
Batch 1/64 loss: -0.28426361083984375
Batch 2/64 loss: -0.33333396911621094
Batch 3/64 loss: -0.8413019180297852
Batch 4/64 loss: -0.6577653884887695
Batch 5/64 loss: -0.6233654022216797
Batch 6/64 loss: -0.5832290649414062
Batch 7/64 loss: -0.6262884140014648
Batch 8/64 loss: -0.41423988342285156
Batch 9/64 loss: -0.2244100570678711
Batch 10/64 loss: -0.7235240936279297
Batch 11/64 loss: -0.1945333480834961
Batch 12/64 loss: -0.7421817779541016
Batch 13/64 loss: -0.3233795166015625
Batch 14/64 loss: -0.45323848724365234
Batch 15/64 loss: -0.35266590118408203
Batch 16/64 loss: -0.4238095283508301
Batch 17/64 loss: -1.0120010375976562
Batch 18/64 loss: -0.28917503356933594
Batch 19/64 loss: -0.49680423736572266
Batch 20/64 loss: -0.44559574127197266
Batch 21/64 loss: -0.548893928527832
Batch 22/64 loss: -0.6849918365478516
Batch 23/64 loss: -0.4690561294555664
Batch 24/64 loss: -0.38851118087768555
Batch 25/64 loss: -0.11415863037109375
Batch 26/64 loss: -0.5632352828979492
Batch 27/64 loss: -0.008933067321777344
Batch 28/64 loss: -0.6537580490112305
Batch 29/64 loss: -0.13919925689697266
Batch 30/64 loss: -0.4703826904296875
Batch 31/64 loss: -0.5509061813354492
Batch 32/64 loss: -0.6716337203979492
Batch 33/64 loss: -0.6180524826049805
Batch 34/64 loss: -0.4525871276855469
Batch 35/64 loss: -0.5056638717651367
Batch 36/64 loss: -0.58795166015625
Batch 37/64 loss: -0.4834413528442383
Batch 38/64 loss: -0.9243707656860352
Batch 39/64 loss: -0.3641090393066406
Batch 40/64 loss: -0.902618408203125
Batch 41/64 loss: -0.17786407470703125
Batch 42/64 loss: -0.6279821395874023
Batch 43/64 loss: -0.9646186828613281
Batch 44/64 loss: -0.22093868255615234
Batch 45/64 loss: 0.2241954803466797
Batch 46/64 loss: -0.7143659591674805
Batch 47/64 loss: -0.20605945587158203
Batch 48/64 loss: -0.8782691955566406
Batch 49/64 loss: -0.7483930587768555
Batch 50/64 loss: -0.4405860900878906
Batch 51/64 loss: -0.4875020980834961
Batch 52/64 loss: -0.6598348617553711
Batch 53/64 loss: -0.4856386184692383
Batch 54/64 loss: -0.49655914306640625
Batch 55/64 loss: -0.48238277435302734
Batch 56/64 loss: -0.5184516906738281
Batch 57/64 loss: -0.3481025695800781
Batch 58/64 loss: -0.04278373718261719
Batch 59/64 loss: -0.8055887222290039
Batch 60/64 loss: -0.8122949600219727
Batch 61/64 loss: -0.5806169509887695
Batch 62/64 loss: -0.5707588195800781
Batch 63/64 loss: -0.5664520263671875
Batch 64/64 loss: -4.655126094818115
Epoch 71  Train loss: -0.5529530113818599  Val loss: -0.7314949560001544
Saving best model, epoch: 71
Epoch 72
-------------------------------
Batch 1/64 loss: -0.7882890701293945
Batch 2/64 loss: -0.8218297958374023
Batch 3/64 loss: -0.23542118072509766
Batch 4/64 loss: -0.5639505386352539
Batch 5/64 loss: -0.11065673828125
Batch 6/64 loss: -0.6527290344238281
Batch 7/64 loss: 0.004185676574707031
Batch 8/64 loss: -0.5710420608520508
Batch 9/64 loss: -0.7766304016113281
Batch 10/64 loss: -0.971989631652832
Batch 11/64 loss: -0.38800048828125
Batch 12/64 loss: -0.7750167846679688
Batch 13/64 loss: -0.8469381332397461
Batch 14/64 loss: -0.6148958206176758
Batch 15/64 loss: -1.0492448806762695
Batch 16/64 loss: -0.11681365966796875
Batch 17/64 loss: -0.6829891204833984
Batch 18/64 loss: -0.4345550537109375
Batch 19/64 loss: -0.5159626007080078
Batch 20/64 loss: -0.34048938751220703
Batch 21/64 loss: -0.30550670623779297
Batch 22/64 loss: -0.36080455780029297
Batch 23/64 loss: -0.13265323638916016
Batch 24/64 loss: -0.3493766784667969
Batch 25/64 loss: -0.5238571166992188
Batch 26/64 loss: -0.7699909210205078
Batch 27/64 loss: -0.8100109100341797
Batch 28/64 loss: -0.4022207260131836
Batch 29/64 loss: -0.47499752044677734
Batch 30/64 loss: -0.2925376892089844
Batch 31/64 loss: -0.604095458984375
Batch 32/64 loss: -0.5407676696777344
Batch 33/64 loss: -0.672083854675293
Batch 34/64 loss: -0.46738243103027344
Batch 35/64 loss: -0.7092208862304688
Batch 36/64 loss: -0.4473104476928711
Batch 37/64 loss: -0.42754077911376953
Batch 38/64 loss: -0.26058387756347656
Batch 39/64 loss: -0.7098283767700195
Batch 40/64 loss: -0.49900245666503906
Batch 41/64 loss: -0.3578958511352539
Batch 42/64 loss: -0.8851127624511719
Batch 43/64 loss: -0.06880855560302734
Batch 44/64 loss: -0.558253288269043
Batch 45/64 loss: -0.5790185928344727
Batch 46/64 loss: -0.28163623809814453
Batch 47/64 loss: -0.5912103652954102
Batch 48/64 loss: -0.6332788467407227
Batch 49/64 loss: -0.7423801422119141
Batch 50/64 loss: -0.22398948669433594
Batch 51/64 loss: -0.4179954528808594
Batch 52/64 loss: -0.27779388427734375
Batch 53/64 loss: -0.6391086578369141
Batch 54/64 loss: -0.564539909362793
Batch 55/64 loss: -0.3346843719482422
Batch 56/64 loss: -0.0576019287109375
Batch 57/64 loss: -0.5348930358886719
Batch 58/64 loss: -0.42517757415771484
Batch 59/64 loss: -0.802180290222168
Batch 60/64 loss: -0.6755037307739258
Batch 61/64 loss: -0.039793968200683594
Batch 62/64 loss: -0.42617321014404297
Batch 63/64 loss: -0.48543643951416016
Batch 64/64 loss: -4.097011566162109
Epoch 72  Train loss: -0.5441295100193397  Val loss: -0.5299637391395176
Epoch 73
-------------------------------
Batch 1/64 loss: -0.44783687591552734
Batch 2/64 loss: -0.5806570053100586
Batch 3/64 loss: 0.18013858795166016
Batch 4/64 loss: -0.44599437713623047
Batch 5/64 loss: -0.6690797805786133
Batch 6/64 loss: -0.19237804412841797
Batch 7/64 loss: -0.5877161026000977
Batch 8/64 loss: -0.06709575653076172
Batch 9/64 loss: 0.025861740112304688
Batch 10/64 loss: -0.1875925064086914
Batch 11/64 loss: -0.22211456298828125
Batch 12/64 loss: 0.6132926940917969
Batch 13/64 loss: -0.24908065795898438
Batch 14/64 loss: -0.15180206298828125
Batch 15/64 loss: -0.4175996780395508
Batch 16/64 loss: -0.4664773941040039
Batch 17/64 loss: -0.4883995056152344
Batch 18/64 loss: -0.3295106887817383
Batch 19/64 loss: -0.6227092742919922
Batch 20/64 loss: 0.1372203826904297
Batch 21/64 loss: -0.3713197708129883
Batch 22/64 loss: -0.48706722259521484
Batch 23/64 loss: -0.5603313446044922
Batch 24/64 loss: -0.8605365753173828
Batch 25/64 loss: -0.7398262023925781
Batch 26/64 loss: -0.3851633071899414
Batch 27/64 loss: -0.3232603073120117
Batch 28/64 loss: -0.12307453155517578
Batch 29/64 loss: -0.19510269165039062
Batch 30/64 loss: -0.6305103302001953
Batch 31/64 loss: -0.6822624206542969
Batch 32/64 loss: 0.0016183853149414062
Batch 33/64 loss: -0.5443191528320312
Batch 34/64 loss: -0.5484237670898438
Batch 35/64 loss: -0.6100187301635742
Batch 36/64 loss: -0.7954959869384766
Batch 37/64 loss: 0.17241191864013672
Batch 38/64 loss: -0.6012277603149414
Batch 39/64 loss: -0.44486331939697266
Batch 40/64 loss: -0.20401477813720703
Batch 41/64 loss: -0.16577816009521484
Batch 42/64 loss: -0.2634153366088867
Batch 43/64 loss: -0.8953361511230469
Batch 44/64 loss: -0.5167751312255859
Batch 45/64 loss: -0.3841133117675781
Batch 46/64 loss: -0.18424224853515625
Batch 47/64 loss: -0.6769704818725586
Batch 48/64 loss: -0.5130090713500977
Batch 49/64 loss: -0.6451206207275391
Batch 50/64 loss: -0.8677148818969727
Batch 51/64 loss: -0.5482912063598633
Batch 52/64 loss: -0.39641761779785156
Batch 53/64 loss: -0.4738187789916992
Batch 54/64 loss: -0.7221651077270508
Batch 55/64 loss: -0.731633186340332
Batch 56/64 loss: -0.7742500305175781
Batch 57/64 loss: -0.901641845703125
Batch 58/64 loss: -0.4709310531616211
Batch 59/64 loss: -0.4117307662963867
Batch 60/64 loss: -0.7452230453491211
Batch 61/64 loss: -0.5334949493408203
Batch 62/64 loss: -0.7298507690429688
Batch 63/64 loss: -0.5973930358886719
Batch 64/64 loss: -3.877650737762451
Epoch 73  Train loss: -0.473096056545482  Val loss: -0.5903487320208468
Epoch 74
-------------------------------
Batch 1/64 loss: -0.7500228881835938
Batch 2/64 loss: -0.8000059127807617
Batch 3/64 loss: -0.6164321899414062
Batch 4/64 loss: -0.8230953216552734
Batch 5/64 loss: -0.4205598831176758
Batch 6/64 loss: -0.08951473236083984
Batch 7/64 loss: -0.5118370056152344
Batch 8/64 loss: -0.7280426025390625
Batch 9/64 loss: -0.6680126190185547
Batch 10/64 loss: -0.728266716003418
Batch 11/64 loss: -0.26702404022216797
Batch 12/64 loss: -0.899357795715332
Batch 13/64 loss: -0.5925636291503906
Batch 14/64 loss: -0.2606182098388672
Batch 15/64 loss: -0.5266132354736328
Batch 16/64 loss: -0.49739837646484375
Batch 17/64 loss: 0.2036457061767578
Batch 18/64 loss: -0.40531444549560547
Batch 19/64 loss: 0.006103992462158203
Batch 20/64 loss: -0.9184017181396484
Batch 21/64 loss: -0.42863941192626953
Batch 22/64 loss: -0.44818687438964844
Batch 23/64 loss: -0.3905010223388672
Batch 24/64 loss: -0.4516410827636719
Batch 25/64 loss: -0.7032861709594727
Batch 26/64 loss: 0.28235530853271484
Batch 27/64 loss: -0.3899564743041992
Batch 28/64 loss: -0.2446908950805664
Batch 29/64 loss: -0.5665903091430664
Batch 30/64 loss: -0.687556266784668
Batch 31/64 loss: -0.18193912506103516
Batch 32/64 loss: -0.6138381958007812
Batch 33/64 loss: -0.36673545837402344
Batch 34/64 loss: -0.3426952362060547
Batch 35/64 loss: -0.4416542053222656
Batch 36/64 loss: -0.711735725402832
Batch 37/64 loss: -0.33159542083740234
Batch 38/64 loss: -0.4485921859741211
Batch 39/64 loss: -0.5904664993286133
Batch 40/64 loss: -0.26331329345703125
Batch 41/64 loss: -0.8139915466308594
Batch 42/64 loss: -0.6014604568481445
Batch 43/64 loss: -0.3433704376220703
Batch 44/64 loss: -0.6271572113037109
Batch 45/64 loss: -0.37439441680908203
Batch 46/64 loss: -0.17780780792236328
Batch 47/64 loss: -0.32127952575683594
Batch 48/64 loss: -0.6787004470825195
Batch 49/64 loss: 0.1953434944152832
Batch 50/64 loss: -0.8005447387695312
Batch 51/64 loss: -0.4298877716064453
Batch 52/64 loss: -0.611363410949707
Batch 53/64 loss: -0.5568981170654297
Batch 54/64 loss: -0.1290302276611328
Batch 55/64 loss: -0.4632902145385742
Batch 56/64 loss: -0.6463193893432617
Batch 57/64 loss: -0.2438955307006836
Batch 58/64 loss: -0.05592536926269531
Batch 59/64 loss: -0.40602588653564453
Batch 60/64 loss: -0.018324851989746094
Batch 61/64 loss: -0.04230976104736328
Batch 62/64 loss: -0.6435298919677734
Batch 63/64 loss: -0.5422286987304688
Batch 64/64 loss: -4.518431663513184
Epoch 74  Train loss: -0.49154205696255554  Val loss: -0.675168538830944
Epoch 75
-------------------------------
Batch 1/64 loss: -0.8368148803710938
Batch 2/64 loss: -0.18442916870117188
Batch 3/64 loss: -0.7853469848632812
Batch 4/64 loss: -0.23830795288085938
Batch 5/64 loss: -0.5374135971069336
Batch 6/64 loss: -0.05594635009765625
Batch 7/64 loss: -0.8192110061645508
Batch 8/64 loss: -0.6911697387695312
Batch 9/64 loss: -0.41883087158203125
Batch 10/64 loss: -0.43409061431884766
Batch 11/64 loss: -0.43416881561279297
Batch 12/64 loss: -0.6458597183227539
Batch 13/64 loss: -0.6877250671386719
Batch 14/64 loss: -0.1464366912841797
Batch 15/64 loss: -0.5230789184570312
Batch 16/64 loss: -0.6886625289916992
Batch 17/64 loss: -0.540349006652832
Batch 18/64 loss: -0.6872930526733398
Batch 19/64 loss: -0.5807695388793945
Batch 20/64 loss: -0.595677375793457
Batch 21/64 loss: -0.5754232406616211
Batch 22/64 loss: -0.7164430618286133
Batch 23/64 loss: -0.49149227142333984
Batch 24/64 loss: -0.11498069763183594
Batch 25/64 loss: -0.4038219451904297
Batch 26/64 loss: -0.6009073257446289
Batch 27/64 loss: -0.49413394927978516
Batch 28/64 loss: -0.38697338104248047
Batch 29/64 loss: -0.8163843154907227
Batch 30/64 loss: -0.9037752151489258
Batch 31/64 loss: -0.298675537109375
Batch 32/64 loss: -0.4118680953979492
Batch 33/64 loss: -0.41240978240966797
Batch 34/64 loss: -0.1951761245727539
Batch 35/64 loss: -0.9110965728759766
Batch 36/64 loss: 0.048729896545410156
Batch 37/64 loss: -0.46262073516845703
Batch 38/64 loss: -0.5368289947509766
Batch 39/64 loss: -0.724705696105957
Batch 40/64 loss: -0.6683778762817383
Batch 41/64 loss: -0.1576690673828125
Batch 42/64 loss: -0.629119873046875
Batch 43/64 loss: -0.5592412948608398
Batch 44/64 loss: -0.4467611312866211
Batch 45/64 loss: -0.4829521179199219
Batch 46/64 loss: -0.187469482421875
Batch 47/64 loss: -0.48354434967041016
Batch 48/64 loss: -0.6025590896606445
Batch 49/64 loss: -0.7283706665039062
Batch 50/64 loss: -0.6874523162841797
Batch 51/64 loss: -0.6417264938354492
Batch 52/64 loss: -0.2508964538574219
Batch 53/64 loss: -0.6854686737060547
Batch 54/64 loss: -0.8559989929199219
Batch 55/64 loss: 0.028163909912109375
Batch 56/64 loss: -0.5561923980712891
Batch 57/64 loss: -0.7014303207397461
Batch 58/64 loss: -0.5996437072753906
Batch 59/64 loss: -0.4627876281738281
Batch 60/64 loss: -0.9085683822631836
Batch 61/64 loss: -0.3560676574707031
Batch 62/64 loss: -0.8078508377075195
Batch 63/64 loss: -0.6922388076782227
Batch 64/64 loss: -4.733099937438965
Epoch 75  Train loss: -0.5743469425276214  Val loss: -0.7491741245964548
Saving best model, epoch: 75
Epoch 76
-------------------------------
Batch 1/64 loss: -0.9072360992431641
Batch 2/64 loss: -0.6778154373168945
Batch 3/64 loss: -0.5404176712036133
Batch 4/64 loss: -0.517857551574707
Batch 5/64 loss: -0.5316076278686523
Batch 6/64 loss: -0.561772346496582
Batch 7/64 loss: -0.4968118667602539
Batch 8/64 loss: -0.47196388244628906
Batch 9/64 loss: -1.0631160736083984
Batch 10/64 loss: -0.9294290542602539
Batch 11/64 loss: -0.6145238876342773
Batch 12/64 loss: -0.5559701919555664
Batch 13/64 loss: -0.5855865478515625
Batch 14/64 loss: -0.5433368682861328
Batch 15/64 loss: -0.4513540267944336
Batch 16/64 loss: -0.5794715881347656
Batch 17/64 loss: -0.5215978622436523
Batch 18/64 loss: -0.7332658767700195
Batch 19/64 loss: 0.3397555351257324
Batch 20/64 loss: -0.8579530715942383
Batch 21/64 loss: -0.39044857025146484
Batch 22/64 loss: -0.6341142654418945
Batch 23/64 loss: -0.4858694076538086
Batch 24/64 loss: -0.3470907211303711
Batch 25/64 loss: -0.7476816177368164
Batch 26/64 loss: -0.4265613555908203
Batch 27/64 loss: -0.2203655242919922
Batch 28/64 loss: -0.5884380340576172
Batch 29/64 loss: -0.6953630447387695
Batch 30/64 loss: -0.815180778503418
Batch 31/64 loss: -0.47902488708496094
Batch 32/64 loss: -0.4348430633544922
Batch 33/64 loss: -0.9663143157958984
Batch 34/64 loss: -0.7640380859375
Batch 35/64 loss: 0.007359504699707031
Batch 36/64 loss: -0.2976217269897461
Batch 37/64 loss: -0.34951305389404297
Batch 38/64 loss: -0.7499561309814453
Batch 39/64 loss: -0.6672849655151367
Batch 40/64 loss: -0.5371618270874023
Batch 41/64 loss: -0.6744050979614258
Batch 42/64 loss: -0.3613576889038086
Batch 43/64 loss: -0.2701253890991211
Batch 44/64 loss: -0.5968828201293945
Batch 45/64 loss: -0.6651535034179688
Batch 46/64 loss: -0.6437520980834961
Batch 47/64 loss: -0.6630258560180664
Batch 48/64 loss: -0.4359874725341797
Batch 49/64 loss: -0.08199501037597656
Batch 50/64 loss: -0.22367238998413086
Batch 51/64 loss: -0.6441364288330078
Batch 52/64 loss: -0.7948198318481445
Batch 53/64 loss: -0.4142026901245117
Batch 54/64 loss: -0.3441276550292969
Batch 55/64 loss: -0.6987056732177734
Batch 56/64 loss: -0.3845491409301758
Batch 57/64 loss: -0.648716926574707
Batch 58/64 loss: -0.2536163330078125
Batch 59/64 loss: -0.6492700576782227
Batch 60/64 loss: -0.5293655395507812
Batch 61/64 loss: -0.7283124923706055
Batch 62/64 loss: -0.6718616485595703
Batch 63/64 loss: -0.4123649597167969
Batch 64/64 loss: -4.728435516357422
Epoch 76  Train loss: -0.5918051326976103  Val loss: -0.6479041502647793
Epoch 77
-------------------------------
Batch 1/64 loss: 0.03084564208984375
Batch 2/64 loss: -0.3104839324951172
Batch 3/64 loss: -0.8827362060546875
Batch 4/64 loss: -0.14400672912597656
Batch 5/64 loss: -0.6595926284790039
Batch 6/64 loss: -0.5686092376708984
Batch 7/64 loss: -0.5663166046142578
Batch 8/64 loss: -0.3155708312988281
Batch 9/64 loss: -0.040851593017578125
Batch 10/64 loss: -0.6332902908325195
Batch 11/64 loss: -0.8560962677001953
Batch 12/64 loss: -0.25797176361083984
Batch 13/64 loss: -0.6039199829101562
Batch 14/64 loss: -0.6312255859375
Batch 15/64 loss: -0.9153232574462891
Batch 16/64 loss: -0.3132343292236328
Batch 17/64 loss: -0.7358169555664062
Batch 18/64 loss: -0.5749177932739258
Batch 19/64 loss: -0.6261806488037109
Batch 20/64 loss: -0.8969049453735352
Batch 21/64 loss: -0.8001861572265625
Batch 22/64 loss: -0.6499118804931641
Batch 23/64 loss: -0.43623924255371094
Batch 24/64 loss: -0.2585000991821289
Batch 25/64 loss: -0.798187255859375
Batch 26/64 loss: -0.8452425003051758
Batch 27/64 loss: -0.7815055847167969
Batch 28/64 loss: -0.4792823791503906
Batch 29/64 loss: -0.47527408599853516
Batch 30/64 loss: -0.8327436447143555
Batch 31/64 loss: -0.4721088409423828
Batch 32/64 loss: -0.08687591552734375
Batch 33/64 loss: -0.36252498626708984
Batch 34/64 loss: -0.5664567947387695
Batch 35/64 loss: -0.6989459991455078
Batch 36/64 loss: -0.4390592575073242
Batch 37/64 loss: -0.4610891342163086
Batch 38/64 loss: -0.8456125259399414
Batch 39/64 loss: -0.6660556793212891
Batch 40/64 loss: -0.6411504745483398
Batch 41/64 loss: -0.5222911834716797
Batch 42/64 loss: -0.77691650390625
Batch 43/64 loss: -0.16264057159423828
Batch 44/64 loss: -0.9308662414550781
Batch 45/64 loss: -0.7098064422607422
Batch 46/64 loss: -0.34351444244384766
Batch 47/64 loss: -0.45473766326904297
Batch 48/64 loss: -0.44801902770996094
Batch 49/64 loss: -0.32988929748535156
Batch 50/64 loss: -0.3275270462036133
Batch 51/64 loss: -0.3320598602294922
Batch 52/64 loss: -0.7928619384765625
Batch 53/64 loss: -0.9014549255371094
Batch 54/64 loss: -0.4933300018310547
Batch 55/64 loss: -0.2889127731323242
Batch 56/64 loss: -0.22080707550048828
Batch 57/64 loss: -0.3409910202026367
Batch 58/64 loss: -0.1842784881591797
Batch 59/64 loss: -0.6204433441162109
Batch 60/64 loss: -0.761143684387207
Batch 61/64 loss: -0.503504753112793
Batch 62/64 loss: -0.46997547149658203
Batch 63/64 loss: -0.7192716598510742
Batch 64/64 loss: -4.651377201080322
Epoch 77  Train loss: -0.5838891403347838  Val loss: -0.5372622643959072
Epoch 78
-------------------------------
Batch 1/64 loss: -0.6239032745361328
Batch 2/64 loss: -0.0434722900390625
Batch 3/64 loss: -0.5676126480102539
Batch 4/64 loss: -0.5677957534790039
Batch 5/64 loss: -0.2932395935058594
Batch 6/64 loss: -0.19114017486572266
Batch 7/64 loss: -0.3909454345703125
Batch 8/64 loss: -0.4914083480834961
Batch 9/64 loss: -0.284456729888916
Batch 10/64 loss: -0.5532217025756836
Batch 11/64 loss: -0.34491443634033203
Batch 12/64 loss: -0.34673118591308594
Batch 13/64 loss: -0.2234630584716797
Batch 14/64 loss: -0.48099422454833984
Batch 15/64 loss: -0.42800235748291016
Batch 16/64 loss: -0.4548177719116211
Batch 17/64 loss: -0.25390625
Batch 18/64 loss: -0.7908430099487305
Batch 19/64 loss: 0.25904178619384766
Batch 20/64 loss: -0.12895727157592773
Batch 21/64 loss: -0.5832023620605469
Batch 22/64 loss: -0.7070121765136719
Batch 23/64 loss: -0.6796131134033203
Batch 24/64 loss: -0.5238876342773438
Batch 25/64 loss: -0.35207176208496094
Batch 26/64 loss: -0.88677978515625
Batch 27/64 loss: -0.8034496307373047
Batch 28/64 loss: -0.6782493591308594
Batch 29/64 loss: -0.6042327880859375
Batch 30/64 loss: -0.8676919937133789
Batch 31/64 loss: -0.5741100311279297
Batch 32/64 loss: -0.5793294906616211
Batch 33/64 loss: -0.2755403518676758
Batch 34/64 loss: -0.2501544952392578
Batch 35/64 loss: -0.5049018859863281
Batch 36/64 loss: -0.6772499084472656
Batch 37/64 loss: -0.868290901184082
Batch 38/64 loss: -0.6253795623779297
Batch 39/64 loss: -0.7345762252807617
Batch 40/64 loss: -0.13730239868164062
Batch 41/64 loss: -0.5052204132080078
Batch 42/64 loss: -0.71527099609375
Batch 43/64 loss: -0.006343364715576172
Batch 44/64 loss: -0.4009847640991211
Batch 45/64 loss: -0.35605716705322266
Batch 46/64 loss: -0.7052183151245117
Batch 47/64 loss: -0.5719952583312988
Batch 48/64 loss: -0.8102474212646484
Batch 49/64 loss: -0.7526350021362305
Batch 50/64 loss: -0.41069698333740234
Batch 51/64 loss: -0.437255859375
Batch 52/64 loss: -0.06636810302734375
Batch 53/64 loss: -0.46233367919921875
Batch 54/64 loss: -0.7328710556030273
Batch 55/64 loss: -0.5798606872558594
Batch 56/64 loss: -0.48679018020629883
Batch 57/64 loss: -0.20727920532226562
Batch 58/64 loss: -0.8749580383300781
Batch 59/64 loss: -0.25621700286865234
Batch 60/64 loss: -0.6632423400878906
Batch 61/64 loss: -0.8374814987182617
Batch 62/64 loss: -0.2996377944946289
Batch 63/64 loss: -0.5195589065551758
Batch 64/64 loss: -4.6163740158081055
Epoch 78  Train loss: -0.5370135550405465  Val loss: -0.41539053900545
Epoch 79
-------------------------------
Batch 1/64 loss: -0.6058788299560547
Batch 2/64 loss: -0.42478466033935547
Batch 3/64 loss: -0.4643669128417969
Batch 4/64 loss: -0.547154426574707
Batch 5/64 loss: -0.4385223388671875
Batch 6/64 loss: -0.47014808654785156
Batch 7/64 loss: -0.9394044876098633
Batch 8/64 loss: -0.6757383346557617
Batch 9/64 loss: -0.002994060516357422
Batch 10/64 loss: 0.10590314865112305
Batch 11/64 loss: -0.5109004974365234
Batch 12/64 loss: -0.7878570556640625
Batch 13/64 loss: -0.2725238800048828
Batch 14/64 loss: -0.7093830108642578
Batch 15/64 loss: -0.5475711822509766
Batch 16/64 loss: -0.17087411880493164
Batch 17/64 loss: -0.67279052734375
Batch 18/64 loss: -0.5502786636352539
Batch 19/64 loss: -0.7107791900634766
Batch 20/64 loss: -0.9290924072265625
Batch 21/64 loss: -0.7155656814575195
Batch 22/64 loss: -0.4687643051147461
Batch 23/64 loss: -0.7209577560424805
Batch 24/64 loss: -0.5857734680175781
Batch 25/64 loss: -0.29508495330810547
Batch 26/64 loss: -0.5943784713745117
Batch 27/64 loss: -0.36003684997558594
Batch 28/64 loss: -0.05290794372558594
Batch 29/64 loss: -0.4328336715698242
Batch 30/64 loss: -0.2819509506225586
Batch 31/64 loss: -0.24404621124267578
Batch 32/64 loss: -0.10486555099487305
Batch 33/64 loss: -0.4731483459472656
Batch 34/64 loss: -0.6779098510742188
Batch 35/64 loss: -0.5800466537475586
Batch 36/64 loss: -0.8892765045166016
Batch 37/64 loss: -0.5101475715637207
Batch 38/64 loss: -0.6620960235595703
Batch 39/64 loss: -0.38703441619873047
Batch 40/64 loss: -0.34043312072753906
Batch 41/64 loss: -0.752716064453125
Batch 42/64 loss: -0.39026927947998047
Batch 43/64 loss: -0.48912906646728516
Batch 44/64 loss: -0.6825494766235352
Batch 45/64 loss: -0.36635494232177734
Batch 46/64 loss: -0.4505729675292969
Batch 47/64 loss: -0.2848367691040039
Batch 48/64 loss: -0.9990930557250977
Batch 49/64 loss: -0.08985328674316406
Batch 50/64 loss: -0.8707447052001953
Batch 51/64 loss: -0.37997913360595703
Batch 52/64 loss: -0.9362173080444336
Batch 53/64 loss: -0.4433774948120117
Batch 54/64 loss: -0.8805456161499023
Batch 55/64 loss: -0.39171695709228516
Batch 56/64 loss: -0.8549785614013672
Batch 57/64 loss: -0.5717229843139648
Batch 58/64 loss: -0.8071794509887695
Batch 59/64 loss: -0.32567882537841797
Batch 60/64 loss: -0.9396438598632812
Batch 61/64 loss: -0.46924495697021484
Batch 62/64 loss: -0.6885986328125
Batch 63/64 loss: -0.798130989074707
Batch 64/64 loss: -4.32349967956543
Epoch 79  Train loss: -0.577382854386872  Val loss: -0.7688491008535693
Saving best model, epoch: 79
Epoch 80
-------------------------------
Batch 1/64 loss: -0.3969440460205078
Batch 2/64 loss: -0.6591176986694336
Batch 3/64 loss: -0.44141292572021484
Batch 4/64 loss: -0.43555259704589844
Batch 5/64 loss: -0.46056652069091797
Batch 6/64 loss: -0.9351768493652344
Batch 7/64 loss: -0.239227294921875
Batch 8/64 loss: -0.7269229888916016
Batch 9/64 loss: -0.7305335998535156
Batch 10/64 loss: -0.5874223709106445
Batch 11/64 loss: -0.4978456497192383
Batch 12/64 loss: -0.2757530212402344
Batch 13/64 loss: -0.6531229019165039
Batch 14/64 loss: -0.6402368545532227
Batch 15/64 loss: -0.5551328659057617
Batch 16/64 loss: -0.7084493637084961
Batch 17/64 loss: -0.8416643142700195
Batch 18/64 loss: -0.8054351806640625
Batch 19/64 loss: -0.5729351043701172
Batch 20/64 loss: -0.7175817489624023
Batch 21/64 loss: -0.6494197845458984
Batch 22/64 loss: -0.7113027572631836
Batch 23/64 loss: -0.9655923843383789
Batch 24/64 loss: -0.7391672134399414
Batch 25/64 loss: -0.3882160186767578
Batch 26/64 loss: -0.6203603744506836
Batch 27/64 loss: -0.7368507385253906
Batch 28/64 loss: -0.14596271514892578
Batch 29/64 loss: -0.7022848129272461
Batch 30/64 loss: -0.8265314102172852
Batch 31/64 loss: -0.6079530715942383
Batch 32/64 loss: -0.9348039627075195
Batch 33/64 loss: -0.6594524383544922
Batch 34/64 loss: -0.7526397705078125
Batch 35/64 loss: -0.41788768768310547
Batch 36/64 loss: -0.9383811950683594
Batch 37/64 loss: -0.5479860305786133
Batch 38/64 loss: -0.8064470291137695
Batch 39/64 loss: -0.77935791015625
Batch 40/64 loss: -0.8777761459350586
Batch 41/64 loss: -0.8032054901123047
Batch 42/64 loss: -0.5253925323486328
Batch 43/64 loss: -0.7944803237915039
Batch 44/64 loss: -0.028740882873535156
Batch 45/64 loss: -0.6710233688354492
Batch 46/64 loss: -0.5395994186401367
Batch 47/64 loss: -0.7643356323242188
Batch 48/64 loss: -1.06005859375
Batch 49/64 loss: -0.8354425430297852
Batch 50/64 loss: -0.16794395446777344
Batch 51/64 loss: -0.29905223846435547
Batch 52/64 loss: -0.20376014709472656
Batch 53/64 loss: -0.36925506591796875
Batch 54/64 loss: -0.47029685974121094
Batch 55/64 loss: -1.0320587158203125
Batch 56/64 loss: -0.30327510833740234
Batch 57/64 loss: -0.6336593627929688
Batch 58/64 loss: -0.7041435241699219
Batch 59/64 loss: -0.7367830276489258
Batch 60/64 loss: -0.20604228973388672
Batch 61/64 loss: -0.3740568161010742
Batch 62/64 loss: -0.6912851333618164
Batch 63/64 loss: -0.37677764892578125
Batch 64/64 loss: -4.65724515914917
Epoch 80  Train loss: -0.6552629003337785  Val loss: -0.7486647510856288
Epoch 81
-------------------------------
Batch 1/64 loss: -0.36180782318115234
Batch 2/64 loss: -0.5285778045654297
Batch 3/64 loss: -0.34252166748046875
Batch 4/64 loss: -0.5718421936035156
Batch 5/64 loss: -0.2853355407714844
Batch 6/64 loss: -0.7578334808349609
Batch 7/64 loss: -0.72039794921875
Batch 8/64 loss: -0.431154727935791
Batch 9/64 loss: -0.6090126037597656
Batch 10/64 loss: -0.935943603515625
Batch 11/64 loss: -0.9791011810302734
Batch 12/64 loss: -0.8010883331298828
Batch 13/64 loss: -0.7681303024291992
Batch 14/64 loss: -0.7829713821411133
Batch 15/64 loss: 0.13557910919189453
Batch 16/64 loss: -0.4197378158569336
Batch 17/64 loss: -0.5130882263183594
Batch 18/64 loss: -0.7159585952758789
Batch 19/64 loss: -0.6508646011352539
Batch 20/64 loss: -0.7313432693481445
Batch 21/64 loss: -0.5328903198242188
Batch 22/64 loss: -0.7814741134643555
Batch 23/64 loss: -0.4288291931152344
Batch 24/64 loss: -0.5966596603393555
Batch 25/64 loss: -0.5169200897216797
Batch 26/64 loss: -0.9383955001831055
Batch 27/64 loss: -0.8842592239379883
Batch 28/64 loss: -0.767979621887207
Batch 29/64 loss: -0.3863716125488281
Batch 30/64 loss: -0.6406650543212891
Batch 31/64 loss: -0.4499502182006836
Batch 32/64 loss: -0.49499034881591797
Batch 33/64 loss: -0.6896867752075195
Batch 34/64 loss: -0.8455333709716797
Batch 35/64 loss: -0.7237920761108398
Batch 36/64 loss: -0.9536914825439453
Batch 37/64 loss: -0.11286735534667969
Batch 38/64 loss: -0.9854869842529297
Batch 39/64 loss: -0.5359745025634766
Batch 40/64 loss: -0.7923927307128906
Batch 41/64 loss: -0.8883504867553711
Batch 42/64 loss: -0.8993310928344727
Batch 43/64 loss: -0.9324722290039062
Batch 44/64 loss: -0.8098316192626953
Batch 45/64 loss: -0.81011962890625
Batch 46/64 loss: -0.6176691055297852
Batch 47/64 loss: -0.6407947540283203
Batch 48/64 loss: -0.775813102722168
Batch 49/64 loss: -0.10394001007080078
Batch 50/64 loss: -0.6839809417724609
Batch 51/64 loss: -0.4532356262207031
Batch 52/64 loss: -0.677189826965332
Batch 53/64 loss: -0.866206169128418
Batch 54/64 loss: -0.02408599853515625
Batch 55/64 loss: -0.519221305847168
Batch 56/64 loss: -0.08411979675292969
Batch 57/64 loss: -0.699030876159668
Batch 58/64 loss: -0.4538888931274414
Batch 59/64 loss: -0.5481929779052734
Batch 60/64 loss: -0.7628860473632812
Batch 61/64 loss: -0.5564908981323242
Batch 62/64 loss: -0.5330238342285156
Batch 63/64 loss: -0.5387115478515625
Batch 64/64 loss: -4.17969274520874
Epoch 81  Train loss: -0.6563654675203211  Val loss: -0.527893616981113
Epoch 82
-------------------------------
Batch 1/64 loss: -0.568878173828125
Batch 2/64 loss: -0.772705078125
Batch 3/64 loss: -0.29386425018310547
Batch 4/64 loss: -0.8624076843261719
Batch 5/64 loss: -0.864802360534668
Batch 6/64 loss: -0.43353843688964844
Batch 7/64 loss: -0.7214994430541992
Batch 8/64 loss: -0.7325687408447266
Batch 9/64 loss: -0.41550254821777344
Batch 10/64 loss: -0.4243459701538086
Batch 11/64 loss: -0.7954835891723633
Batch 12/64 loss: -0.8354644775390625
Batch 13/64 loss: -0.9227705001831055
Batch 14/64 loss: -0.8985462188720703
Batch 15/64 loss: -0.5779542922973633
Batch 16/64 loss: -0.3559083938598633
Batch 17/64 loss: -0.7071828842163086
Batch 18/64 loss: -0.5992097854614258
Batch 19/64 loss: -0.6313791275024414
Batch 20/64 loss: -0.8073883056640625
Batch 21/64 loss: -0.3840789794921875
Batch 22/64 loss: -0.7693862915039062
Batch 23/64 loss: -0.5269298553466797
Batch 24/64 loss: -0.6438407897949219
Batch 25/64 loss: -0.6433219909667969
Batch 26/64 loss: -0.7972965240478516
Batch 27/64 loss: -0.7424430847167969
Batch 28/64 loss: -0.35956287384033203
Batch 29/64 loss: -0.8454418182373047
Batch 30/64 loss: -0.7528457641601562
Batch 31/64 loss: -0.5532894134521484
Batch 32/64 loss: -0.9205532073974609
Batch 33/64 loss: -0.6708946228027344
Batch 34/64 loss: -0.5859756469726562
Batch 35/64 loss: -0.7832441329956055
Batch 36/64 loss: -0.41254711151123047
Batch 37/64 loss: -0.8975133895874023
Batch 38/64 loss: -0.6139802932739258
Batch 39/64 loss: -0.17554950714111328
Batch 40/64 loss: -0.4326753616333008
Batch 41/64 loss: -0.36330509185791016
Batch 42/64 loss: -0.5493459701538086
Batch 43/64 loss: -0.4930849075317383
Batch 44/64 loss: -0.5804300308227539
Batch 45/64 loss: -0.5512228012084961
Batch 46/64 loss: -0.42483997344970703
Batch 47/64 loss: -0.6789131164550781
Batch 48/64 loss: -0.5457372665405273
Batch 49/64 loss: -0.13608455657958984
Batch 50/64 loss: -0.5323305130004883
Batch 51/64 loss: -0.13295555114746094
Batch 52/64 loss: -0.15157127380371094
Batch 53/64 loss: -0.44823265075683594
Batch 54/64 loss: -0.7165946960449219
Batch 55/64 loss: -0.9683160781860352
Batch 56/64 loss: -0.5801801681518555
Batch 57/64 loss: -0.5245447158813477
Batch 58/64 loss: -0.6393194198608398
Batch 59/64 loss: -0.6366682052612305
Batch 60/64 loss: -0.30712413787841797
Batch 61/64 loss: -0.6597661972045898
Batch 62/64 loss: -0.7354230880737305
Batch 63/64 loss: -0.7093849182128906
Batch 64/64 loss: -4.43398380279541
Epoch 82  Train loss: -0.645076613332711  Val loss: -0.655673574336206
Epoch 83
-------------------------------
Batch 1/64 loss: -0.44362354278564453
Batch 2/64 loss: -0.8433856964111328
Batch 3/64 loss: -0.8833093643188477
Batch 4/64 loss: -0.5494899749755859
Batch 5/64 loss: -0.670069694519043
Batch 6/64 loss: -0.2951059341430664
Batch 7/64 loss: -0.787388801574707
Batch 8/64 loss: -0.5368413925170898
Batch 9/64 loss: -0.19254779815673828
Batch 10/64 loss: -0.9210853576660156
Batch 11/64 loss: -0.8040847778320312
Batch 12/64 loss: 0.006575584411621094
Batch 13/64 loss: -0.12076282501220703
Batch 14/64 loss: -0.7733497619628906
Batch 15/64 loss: -0.6911678314208984
Batch 16/64 loss: -0.44561195373535156
Batch 17/64 loss: -0.5301456451416016
Batch 18/64 loss: -1.0426206588745117
Batch 19/64 loss: -0.7134685516357422
Batch 20/64 loss: -0.6997823715209961
Batch 21/64 loss: -0.20769882202148438
Batch 22/64 loss: -0.7272434234619141
Batch 23/64 loss: -0.5644407272338867
Batch 24/64 loss: -0.3875560760498047
Batch 25/64 loss: -0.6417427062988281
Batch 26/64 loss: -0.3990926742553711
Batch 27/64 loss: -0.643336296081543
Batch 28/64 loss: -0.7189855575561523
Batch 29/64 loss: -0.8791170120239258
Batch 30/64 loss: -0.5180530548095703
Batch 31/64 loss: -0.6356363296508789
Batch 32/64 loss: -0.7224655151367188
Batch 33/64 loss: -0.6052227020263672
Batch 34/64 loss: -0.6077966690063477
Batch 35/64 loss: -0.27463722229003906
Batch 36/64 loss: -0.5081987380981445
Batch 37/64 loss: -0.6364059448242188
Batch 38/64 loss: -0.8278713226318359
Batch 39/64 loss: -0.33069419860839844
Batch 40/64 loss: -0.7859611511230469
Batch 41/64 loss: -0.9943952560424805
Batch 42/64 loss: -0.3885936737060547
Batch 43/64 loss: -0.14983081817626953
Batch 44/64 loss: -1.0072460174560547
Batch 45/64 loss: -0.7395353317260742
Batch 46/64 loss: -0.8256673812866211
Batch 47/64 loss: -0.6302576065063477
Batch 48/64 loss: -0.41544437408447266
Batch 49/64 loss: -1.0333080291748047
Batch 50/64 loss: -0.54559326171875
Batch 51/64 loss: -0.7825632095336914
Batch 52/64 loss: -0.4521770477294922
Batch 53/64 loss: -0.36449241638183594
Batch 54/64 loss: -0.45952415466308594
Batch 55/64 loss: -0.9245977401733398
Batch 56/64 loss: -0.9204339981079102
Batch 57/64 loss: -0.5992317199707031
Batch 58/64 loss: -0.4694538116455078
Batch 59/64 loss: -0.9932165145874023
Batch 60/64 loss: -0.8951921463012695
Batch 61/64 loss: -0.3452463150024414
Batch 62/64 loss: -0.4185028076171875
Batch 63/64 loss: -0.824127197265625
Batch 64/64 loss: -3.997317314147949
Epoch 83  Train loss: -0.6546830009011662  Val loss: -0.7587143809525008
Epoch 84
-------------------------------
Batch 1/64 loss: -0.758275032043457
Batch 2/64 loss: -0.8338298797607422
Batch 3/64 loss: -0.7035512924194336
Batch 4/64 loss: -0.7115926742553711
Batch 5/64 loss: -0.6384963989257812
Batch 6/64 loss: -0.7189340591430664
Batch 7/64 loss: -0.7641582489013672
Batch 8/64 loss: -0.749873161315918
Batch 9/64 loss: -0.2669229507446289
Batch 10/64 loss: -0.6821565628051758
Batch 11/64 loss: -0.9550914764404297
Batch 12/64 loss: -0.5464897155761719
Batch 13/64 loss: -0.30048274993896484
Batch 14/64 loss: -0.6833400726318359
Batch 15/64 loss: -0.6340923309326172
Batch 16/64 loss: 0.09344673156738281
Batch 17/64 loss: -0.8574686050415039
Batch 18/64 loss: -0.9308490753173828
Batch 19/64 loss: -0.2796497344970703
Batch 20/64 loss: -0.22594261169433594
Batch 21/64 loss: -0.46629905700683594
Batch 22/64 loss: -0.48415374755859375
Batch 23/64 loss: -0.5737075805664062
Batch 24/64 loss: -0.7389163970947266
Batch 25/64 loss: -0.5844650268554688
Batch 26/64 loss: -0.5326366424560547
Batch 27/64 loss: -0.5261173248291016
Batch 28/64 loss: -0.9104347229003906
Batch 29/64 loss: -0.6678552627563477
Batch 30/64 loss: -0.8780374526977539
Batch 31/64 loss: -0.9642229080200195
Batch 32/64 loss: -0.17392921447753906
Batch 33/64 loss: -0.3070659637451172
Batch 34/64 loss: -0.3131103515625
Batch 35/64 loss: -0.4959688186645508
Batch 36/64 loss: -0.7846002578735352
Batch 37/64 loss: -0.3760223388671875
Batch 38/64 loss: -0.4310331344604492
Batch 39/64 loss: -0.7912750244140625
Batch 40/64 loss: -0.6562223434448242
Batch 41/64 loss: -0.3982353210449219
Batch 42/64 loss: -0.6510343551635742
Batch 43/64 loss: -1.0498676300048828
Batch 44/64 loss: -1.0010051727294922
Batch 45/64 loss: -0.6267633438110352
Batch 46/64 loss: -0.8996305465698242
Batch 47/64 loss: -0.4423227310180664
Batch 48/64 loss: -0.03737163543701172
Batch 49/64 loss: -0.4648733139038086
Batch 50/64 loss: -0.6895475387573242
Batch 51/64 loss: -0.7388286590576172
Batch 52/64 loss: -0.6258401870727539
Batch 53/64 loss: -0.6575164794921875
Batch 54/64 loss: -0.7019662857055664
Batch 55/64 loss: -0.1250438690185547
Batch 56/64 loss: -0.8107547760009766
Batch 57/64 loss: -0.6473569869995117
Batch 58/64 loss: -0.22819995880126953
Batch 59/64 loss: -0.8364353179931641
Batch 60/64 loss: -0.8441858291625977
Batch 61/64 loss: -0.37355709075927734
Batch 62/64 loss: -0.45394325256347656
Batch 63/64 loss: -0.13405513763427734
Batch 64/64 loss: -4.532331466674805
Epoch 84  Train loss: -0.637512274349437  Val loss: -0.48559302890423645
Epoch 85
-------------------------------
Batch 1/64 loss: -0.6366853713989258
Batch 2/64 loss: -0.3962411880493164
Batch 3/64 loss: -0.560328483581543
Batch 4/64 loss: -0.007699012756347656
Batch 5/64 loss: -0.5709972381591797
Batch 6/64 loss: -0.8516607284545898
Batch 7/64 loss: -0.4603099822998047
Batch 8/64 loss: -0.8919668197631836
Batch 9/64 loss: -0.8013401031494141
Batch 10/64 loss: -0.22182846069335938
Batch 11/64 loss: -0.23818302154541016
Batch 12/64 loss: -0.8389015197753906
Batch 13/64 loss: -0.6936922073364258
Batch 14/64 loss: -0.28545570373535156
Batch 15/64 loss: -0.9321756362915039
Batch 16/64 loss: -0.2732410430908203
Batch 17/64 loss: -0.3590993881225586
Batch 18/64 loss: -0.41559696197509766
Batch 19/64 loss: -0.5176219940185547
Batch 20/64 loss: -0.42960643768310547
Batch 21/64 loss: -0.8161954879760742
Batch 22/64 loss: -0.15117549896240234
Batch 23/64 loss: 0.010182380676269531
Batch 24/64 loss: -0.34464550018310547
Batch 25/64 loss: -0.733180046081543
Batch 26/64 loss: -0.5582637786865234
Batch 27/64 loss: -0.7021274566650391
Batch 28/64 loss: -0.19514751434326172
Batch 29/64 loss: -0.33682823181152344
Batch 30/64 loss: -0.8392581939697266
Batch 31/64 loss: -0.6738157272338867
Batch 32/64 loss: -0.8911361694335938
Batch 33/64 loss: -0.43152713775634766
Batch 34/64 loss: -0.6248540878295898
Batch 35/64 loss: -0.7508163452148438
Batch 36/64 loss: -0.6572370529174805
Batch 37/64 loss: -0.8444614410400391
Batch 38/64 loss: -0.557887077331543
Batch 39/64 loss: -0.40749645233154297
Batch 40/64 loss: -0.3303060531616211
Batch 41/64 loss: -0.5568370819091797
Batch 42/64 loss: -0.35051536560058594
Batch 43/64 loss: -0.6015281677246094
Batch 44/64 loss: -0.4605855941772461
Batch 45/64 loss: -0.9003791809082031
Batch 46/64 loss: -0.7306928634643555
Batch 47/64 loss: -0.8361482620239258
Batch 48/64 loss: -0.4319629669189453
Batch 49/64 loss: -0.8776941299438477
Batch 50/64 loss: -0.3994417190551758
Batch 51/64 loss: -0.3651752471923828
Batch 52/64 loss: -0.6280269622802734
Batch 53/64 loss: -0.6459074020385742
Batch 54/64 loss: -0.7351083755493164
Batch 55/64 loss: -0.5970859527587891
Batch 56/64 loss: -0.5774898529052734
Batch 57/64 loss: -0.9758234024047852
Batch 58/64 loss: -0.7275047302246094
Batch 59/64 loss: -0.6766605377197266
Batch 60/64 loss: -0.6724672317504883
Batch 61/64 loss: -0.7891550064086914
Batch 62/64 loss: -0.40944766998291016
Batch 63/64 loss: -0.9656887054443359
Batch 64/64 loss: -4.44865608215332
Epoch 85  Train loss: -0.6190843395158356  Val loss: -0.6876904464669243
Epoch 86
-------------------------------
Batch 1/64 loss: -0.7286844253540039
Batch 2/64 loss: -0.9473543167114258
Batch 3/64 loss: -0.29599571228027344
Batch 4/64 loss: -0.7014989852905273
Batch 5/64 loss: -0.7473831176757812
Batch 6/64 loss: -0.9389123916625977
Batch 7/64 loss: -0.46903228759765625
Batch 8/64 loss: -0.5500078201293945
Batch 9/64 loss: -0.7879762649536133
Batch 10/64 loss: -0.5872650146484375
Batch 11/64 loss: -0.9910449981689453
Batch 12/64 loss: 0.06191539764404297
Batch 13/64 loss: -0.7165451049804688
Batch 14/64 loss: -0.8448648452758789
Batch 15/64 loss: -0.40665626525878906
Batch 16/64 loss: -0.22196102142333984
Batch 17/64 loss: -0.6392412185668945
Batch 18/64 loss: -1.0851049423217773
Batch 19/64 loss: -0.18724727630615234
Batch 20/64 loss: -0.6405506134033203
Batch 21/64 loss: -0.42502784729003906
Batch 22/64 loss: -0.5168914794921875
Batch 23/64 loss: -0.9425592422485352
Batch 24/64 loss: -0.685603141784668
Batch 25/64 loss: -0.7877130508422852
Batch 26/64 loss: -0.5870990753173828
Batch 27/64 loss: -0.5390720367431641
Batch 28/64 loss: -0.697840690612793
Batch 29/64 loss: -0.6739025115966797
Batch 30/64 loss: -0.7185420989990234
Batch 31/64 loss: -0.30316877365112305
Batch 32/64 loss: -0.842106819152832
Batch 33/64 loss: -0.45619916915893555
Batch 34/64 loss: -0.35962772369384766
Batch 35/64 loss: -0.6526870727539062
Batch 36/64 loss: -0.6455907821655273
Batch 37/64 loss: -0.6016340255737305
Batch 38/64 loss: -0.8222904205322266
Batch 39/64 loss: -1.1475811004638672
Batch 40/64 loss: -0.5351219177246094
Batch 41/64 loss: -0.9567775726318359
Batch 42/64 loss: -0.7173471450805664
Batch 43/64 loss: -0.5069561004638672
Batch 44/64 loss: -0.93316650390625
Batch 45/64 loss: -0.6362762451171875
Batch 46/64 loss: -0.7561655044555664
Batch 47/64 loss: -0.43921947479248047
Batch 48/64 loss: -0.2042093276977539
Batch 49/64 loss: -0.3754386901855469
Batch 50/64 loss: -0.43099021911621094
Batch 51/64 loss: -0.4609966278076172
Batch 52/64 loss: -0.5134725570678711
Batch 53/64 loss: -0.5108442306518555
Batch 54/64 loss: 0.18666839599609375
Batch 55/64 loss: -0.19916629791259766
Batch 56/64 loss: -0.7135858535766602
Batch 57/64 loss: -0.4694948196411133
Batch 58/64 loss: -0.3376893997192383
Batch 59/64 loss: -0.40407466888427734
Batch 60/64 loss: -0.9436988830566406
Batch 61/64 loss: -0.7493648529052734
Batch 62/64 loss: -0.741826057434082
Batch 63/64 loss: -0.6609306335449219
Batch 64/64 loss: -3.8550100326538086
Epoch 86  Train loss: -0.6389325646793141  Val loss: -0.5858549793151646
Epoch 87
-------------------------------
Batch 1/64 loss: -0.6133890151977539
Batch 2/64 loss: -0.6683998107910156
Batch 3/64 loss: -0.7397804260253906
Batch 4/64 loss: -0.11021804809570312
Batch 5/64 loss: -0.6163139343261719
Batch 6/64 loss: -0.16680240631103516
Batch 7/64 loss: -0.5944175720214844
Batch 8/64 loss: -0.4623451232910156
Batch 9/64 loss: -0.3910398483276367
Batch 10/64 loss: -0.25196266174316406
Batch 11/64 loss: -0.13097858428955078
Batch 12/64 loss: -0.2603006362915039
Batch 13/64 loss: -0.7730960845947266
Batch 14/64 loss: -0.04187488555908203
Batch 15/64 loss: -0.5934352874755859
Batch 16/64 loss: -0.6894073486328125
Batch 17/64 loss: -0.36794090270996094
Batch 18/64 loss: -0.932866096496582
Batch 19/64 loss: -0.7633123397827148
Batch 20/64 loss: -0.7650566101074219
Batch 21/64 loss: -0.5129947662353516
Batch 22/64 loss: -0.9991950988769531
Batch 23/64 loss: -0.27877235412597656
Batch 24/64 loss: -0.5016193389892578
Batch 25/64 loss: -0.8742666244506836
Batch 26/64 loss: -0.7840518951416016
Batch 27/64 loss: -0.5128049850463867
Batch 28/64 loss: -0.9586400985717773
Batch 29/64 loss: -0.859527587890625
Batch 30/64 loss: -0.8404569625854492
Batch 31/64 loss: -0.8312253952026367
Batch 32/64 loss: -0.40657901763916016
Batch 33/64 loss: -0.7989273071289062
Batch 34/64 loss: -0.22505950927734375
Batch 35/64 loss: -0.7787885665893555
Batch 36/64 loss: -0.7527742385864258
Batch 37/64 loss: -0.8893890380859375
Batch 38/64 loss: -0.37439632415771484
Batch 39/64 loss: -0.9311180114746094
Batch 40/64 loss: -0.35612010955810547
Batch 41/64 loss: -0.435699462890625
Batch 42/64 loss: -0.28107452392578125
Batch 43/64 loss: -0.8218221664428711
Batch 44/64 loss: -1.0635700225830078
Batch 45/64 loss: -0.47554874420166016
Batch 46/64 loss: -0.9885473251342773
Batch 47/64 loss: -0.18650245666503906
Batch 48/64 loss: -0.6958580017089844
Batch 49/64 loss: -0.6416788101196289
Batch 50/64 loss: -0.3394956588745117
Batch 51/64 loss: -0.6683740615844727
Batch 52/64 loss: -0.7514839172363281
Batch 53/64 loss: -0.9205722808837891
Batch 54/64 loss: -0.6289253234863281
Batch 55/64 loss: -0.7319459915161133
Batch 56/64 loss: -0.6106863021850586
Batch 57/64 loss: -0.5373153686523438
Batch 58/64 loss: -0.28464412689208984
Batch 59/64 loss: -0.7042169570922852
Batch 60/64 loss: -0.9652690887451172
Batch 61/64 loss: -0.8890199661254883
Batch 62/64 loss: -0.9061346054077148
Batch 63/64 loss: -0.7230968475341797
Batch 64/64 loss: -3.949197769165039
Epoch 87  Train loss: -0.6527533362893497  Val loss: -0.8089065158490053
Saving best model, epoch: 87
Epoch 88
-------------------------------
Batch 1/64 loss: -0.5779018402099609
Batch 2/64 loss: -0.8433809280395508
Batch 3/64 loss: -0.8960437774658203
Batch 4/64 loss: -0.49944400787353516
Batch 5/64 loss: -0.70355224609375
Batch 6/64 loss: -0.6530780792236328
Batch 7/64 loss: -0.3670024871826172
Batch 8/64 loss: 0.2482461929321289
Batch 9/64 loss: -0.34418201446533203
Batch 10/64 loss: -0.7859077453613281
Batch 11/64 loss: -0.4324064254760742
Batch 12/64 loss: -0.6240835189819336
Batch 13/64 loss: -0.9961795806884766
Batch 14/64 loss: -0.9272832870483398
Batch 15/64 loss: -0.33985424041748047
Batch 16/64 loss: -0.7145166397094727
Batch 17/64 loss: -0.4438924789428711
Batch 18/64 loss: -0.5322780609130859
Batch 19/64 loss: -0.39569759368896484
Batch 20/64 loss: -0.7468938827514648
Batch 21/64 loss: -0.7438249588012695
Batch 22/64 loss: -0.43431854248046875
Batch 23/64 loss: -0.6100301742553711
Batch 24/64 loss: -0.7583332061767578
Batch 25/64 loss: -0.45676708221435547
Batch 26/64 loss: -0.4760169982910156
Batch 27/64 loss: -1.0310468673706055
Batch 28/64 loss: -0.7078542709350586
Batch 29/64 loss: -0.957484245300293
Batch 30/64 loss: -0.5440902709960938
Batch 31/64 loss: -0.6014318466186523
Batch 32/64 loss: -0.4185047149658203
Batch 33/64 loss: -0.2194666862487793
Batch 34/64 loss: -0.4276771545410156
Batch 35/64 loss: -0.4679594039916992
Batch 36/64 loss: -0.36504268646240234
Batch 37/64 loss: -0.8816976547241211
Batch 38/64 loss: -0.9303789138793945
Batch 39/64 loss: -0.2981834411621094
Batch 40/64 loss: -0.8052635192871094
Batch 41/64 loss: -0.7781276702880859
Batch 42/64 loss: -0.2250804901123047
Batch 43/64 loss: -0.6101827621459961
Batch 44/64 loss: -0.6109800338745117
Batch 45/64 loss: -0.9138402938842773
Batch 46/64 loss: -0.7777471542358398
Batch 47/64 loss: -0.8767719268798828
Batch 48/64 loss: -0.6258373260498047
Batch 49/64 loss: -0.7075204849243164
Batch 50/64 loss: -0.7825765609741211
Batch 51/64 loss: -0.2219524383544922
Batch 52/64 loss: -0.21007728576660156
Batch 53/64 loss: -1.0651378631591797
Batch 54/64 loss: -0.865056037902832
Batch 55/64 loss: -0.9960184097290039
Batch 56/64 loss: -0.6666669845581055
Batch 57/64 loss: -0.8314476013183594
Batch 58/64 loss: -0.7248697280883789
Batch 59/64 loss: -0.5198659896850586
Batch 60/64 loss: -0.5057239532470703
Batch 61/64 loss: -0.6806249618530273
Batch 62/64 loss: -0.3867454528808594
Batch 63/64 loss: -0.7453203201293945
Batch 64/64 loss: -4.590914249420166
Epoch 88  Train loss: -0.6663852972142836  Val loss: -0.6400602412797332
Epoch 89
-------------------------------
Batch 1/64 loss: -0.04091310501098633
Batch 2/64 loss: -0.7347316741943359
Batch 3/64 loss: -0.5933446884155273
Batch 4/64 loss: -0.8645343780517578
Batch 5/64 loss: -0.7994709014892578
Batch 6/64 loss: -0.6746549606323242
Batch 7/64 loss: -0.7314376831054688
Batch 8/64 loss: -0.8913669586181641
Batch 9/64 loss: -0.3142681121826172
Batch 10/64 loss: 0.08826255798339844
Batch 11/64 loss: -0.6166610717773438
Batch 12/64 loss: 0.04248523712158203
Batch 13/64 loss: -0.5119609832763672
Batch 14/64 loss: -0.2142810821533203
Batch 15/64 loss: -1.0000896453857422
Batch 16/64 loss: -0.781987190246582
Batch 17/64 loss: -1.0862360000610352
Batch 18/64 loss: -0.3614044189453125
Batch 19/64 loss: -0.9536142349243164
Batch 20/64 loss: -0.7370500564575195
Batch 21/64 loss: -0.42795467376708984
Batch 22/64 loss: -0.6520729064941406
Batch 23/64 loss: -0.2026081085205078
Batch 24/64 loss: -0.24552345275878906
Batch 25/64 loss: -0.38092613220214844
Batch 26/64 loss: -0.7345161437988281
Batch 27/64 loss: -0.5219669342041016
Batch 28/64 loss: -1.3365859985351562
Batch 29/64 loss: -1.0481071472167969
Batch 30/64 loss: -0.5563583374023438
Batch 31/64 loss: -0.9229297637939453
Batch 32/64 loss: -0.635584831237793
Batch 33/64 loss: -0.9505758285522461
Batch 34/64 loss: -0.5684118270874023
Batch 35/64 loss: -0.5616931915283203
Batch 36/64 loss: -0.5943155288696289
Batch 37/64 loss: -0.9068489074707031
Batch 38/64 loss: -0.4802083969116211
Batch 39/64 loss: -0.4631328582763672
Batch 40/64 loss: -0.29134654998779297
Batch 41/64 loss: -0.8094930648803711
Batch 42/64 loss: -0.9221410751342773
Batch 43/64 loss: -0.942901611328125
Batch 44/64 loss: -0.7313470840454102
Batch 45/64 loss: -0.24700546264648438
Batch 46/64 loss: -0.7893409729003906
Batch 47/64 loss: -0.8404426574707031
Batch 48/64 loss: -1.1660566329956055
Batch 49/64 loss: -0.35092592239379883
Batch 50/64 loss: -0.6548748016357422
Batch 51/64 loss: -0.8931303024291992
Batch 52/64 loss: -0.861210823059082
Batch 53/64 loss: -0.3461475372314453
Batch 54/64 loss: -0.5597610473632812
Batch 55/64 loss: -0.7283592224121094
Batch 56/64 loss: -0.41999244689941406
Batch 57/64 loss: -0.630157470703125
Batch 58/64 loss: -0.7865171432495117
Batch 59/64 loss: -1.0449419021606445
Batch 60/64 loss: -0.4277677536010742
Batch 61/64 loss: -0.17258071899414062
Batch 62/64 loss: -0.7481155395507812
Batch 63/64 loss: -0.7160682678222656
Batch 64/64 loss: -4.161309719085693
Epoch 89  Train loss: -0.6771637430378035  Val loss: -0.7770987441859294
Epoch 90
-------------------------------
Batch 1/64 loss: -0.8273105621337891
Batch 2/64 loss: -0.7394485473632812
Batch 3/64 loss: -0.8180980682373047
Batch 4/64 loss: -0.36595821380615234
Batch 5/64 loss: -0.46085548400878906
Batch 6/64 loss: -0.13421154022216797
Batch 7/64 loss: -0.7342443466186523
Batch 8/64 loss: -0.2133922576904297
Batch 9/64 loss: -0.5415430068969727
Batch 10/64 loss: -0.790064811706543
Batch 11/64 loss: -0.7165212631225586
Batch 12/64 loss: -0.35259056091308594
Batch 13/64 loss: -0.4436941146850586
Batch 14/64 loss: -0.7245903015136719
Batch 15/64 loss: -0.7895708084106445
Batch 16/64 loss: -0.8105897903442383
Batch 17/64 loss: -0.744410514831543
Batch 18/64 loss: -1.1915006637573242
Batch 19/64 loss: -0.6371908187866211
Batch 20/64 loss: -0.5647525787353516
Batch 21/64 loss: -0.2713170051574707
Batch 22/64 loss: -0.9332265853881836
Batch 23/64 loss: -0.848536491394043
Batch 24/64 loss: -0.9445199966430664
Batch 25/64 loss: -0.7303075790405273
Batch 26/64 loss: -0.6336088180541992
Batch 27/64 loss: -0.014091014862060547
Batch 28/64 loss: -0.5592918395996094
Batch 29/64 loss: -0.5235462188720703
Batch 30/64 loss: -1.0986442565917969
Batch 31/64 loss: -0.8292770385742188
Batch 32/64 loss: -0.7845869064331055
Batch 33/64 loss: -0.6586675643920898
Batch 34/64 loss: -0.5202646255493164
Batch 35/64 loss: -0.5853700637817383
Batch 36/64 loss: -0.6123199462890625
Batch 37/64 loss: -0.9169101715087891
Batch 38/64 loss: -0.5783634185791016
Batch 39/64 loss: -1.0439434051513672
Batch 40/64 loss: -0.6043548583984375
Batch 41/64 loss: -0.6461286544799805
Batch 42/64 loss: -0.4993247985839844
Batch 43/64 loss: -0.6863527297973633
Batch 44/64 loss: -0.9712343215942383
Batch 45/64 loss: -0.8087320327758789
Batch 46/64 loss: -0.878108024597168
Batch 47/64 loss: -0.6677169799804688
Batch 48/64 loss: -0.8278379440307617
Batch 49/64 loss: -0.9243288040161133
Batch 50/64 loss: -0.5832300186157227
Batch 51/64 loss: -0.5042057037353516
Batch 52/64 loss: -0.7014560699462891
Batch 53/64 loss: -0.7219057083129883
Batch 54/64 loss: -0.34677886962890625
Batch 55/64 loss: -0.7234954833984375
Batch 56/64 loss: -0.8438968658447266
Batch 57/64 loss: -0.8802719116210938
Batch 58/64 loss: -0.8103809356689453
Batch 59/64 loss: -0.6826314926147461
Batch 60/64 loss: -0.8330020904541016
Batch 61/64 loss: -0.17266845703125
Batch 62/64 loss: -0.7244501113891602
Batch 63/64 loss: -0.5759239196777344
Batch 64/64 loss: -4.673384666442871
Epoch 90  Train loss: -0.7186005723242667  Val loss: -0.7213770024145592
Epoch 91
-------------------------------
Batch 1/64 loss: -0.601292610168457
Batch 2/64 loss: -0.5939168930053711
Batch 3/64 loss: -0.744471549987793
Batch 4/64 loss: -0.6007289886474609
Batch 5/64 loss: -0.7806339263916016
Batch 6/64 loss: -0.6797685623168945
Batch 7/64 loss: -0.5046262741088867
Batch 8/64 loss: -0.6175241470336914
Batch 9/64 loss: -0.6936578750610352
Batch 10/64 loss: -0.5160212516784668
Batch 11/64 loss: -0.9615964889526367
Batch 12/64 loss: -0.693293571472168
Batch 13/64 loss: -0.7123022079467773
Batch 14/64 loss: -0.7612104415893555
Batch 15/64 loss: -1.0378437042236328
Batch 16/64 loss: -0.721461296081543
Batch 17/64 loss: -0.8596639633178711
Batch 18/64 loss: -0.6334877014160156
Batch 19/64 loss: -0.7893199920654297
Batch 20/64 loss: -0.32532215118408203
Batch 21/64 loss: -0.4730539321899414
Batch 22/64 loss: -0.9210681915283203
Batch 23/64 loss: -0.6569175720214844
Batch 24/64 loss: -0.5694303512573242
Batch 25/64 loss: -1.1001720428466797
Batch 26/64 loss: -0.2637791633605957
Batch 27/64 loss: -0.929356575012207
Batch 28/64 loss: -0.5932693481445312
Batch 29/64 loss: -0.8411216735839844
Batch 30/64 loss: -0.5529050827026367
Batch 31/64 loss: -0.5414886474609375
Batch 32/64 loss: -0.7312002182006836
Batch 33/64 loss: -0.6277527809143066
Batch 34/64 loss: -0.9381752014160156
Batch 35/64 loss: -0.5833139419555664
Batch 36/64 loss: -0.6997833251953125
Batch 37/64 loss: -0.760162353515625
Batch 38/64 loss: -1.0015945434570312
Batch 39/64 loss: -0.6868677139282227
Batch 40/64 loss: -0.4649791717529297
Batch 41/64 loss: -0.6417131423950195
Batch 42/64 loss: -0.8075523376464844
Batch 43/64 loss: -0.7136974334716797
Batch 44/64 loss: -0.7152481079101562
Batch 45/64 loss: -0.5449018478393555
Batch 46/64 loss: -0.7870798110961914
Batch 47/64 loss: -1.0581331253051758
Batch 48/64 loss: -0.854426383972168
Batch 49/64 loss: -0.9763336181640625
Batch 50/64 loss: -0.8067636489868164
Batch 51/64 loss: -0.5287342071533203
Batch 52/64 loss: -0.5896682739257812
Batch 53/64 loss: -0.8403682708740234
Batch 54/64 loss: -0.7491722106933594
Batch 55/64 loss: -0.8761396408081055
Batch 56/64 loss: -0.0338287353515625
Batch 57/64 loss: -0.6765623092651367
Batch 58/64 loss: -0.9284486770629883
Batch 59/64 loss: -0.5894346237182617
Batch 60/64 loss: -0.45450305938720703
Batch 61/64 loss: -0.5832300186157227
Batch 62/64 loss: -0.8777637481689453
Batch 63/64 loss: -0.982335090637207
Batch 64/64 loss: -4.396036148071289
Epoch 91  Train loss: -0.7478839350681679  Val loss: -0.8240137264081293
Saving best model, epoch: 91
Epoch 92
-------------------------------
Batch 1/64 loss: -0.35358715057373047
Batch 2/64 loss: -0.9804143905639648
Batch 3/64 loss: -0.6390695571899414
Batch 4/64 loss: -1.1435651779174805
Batch 5/64 loss: -0.9462690353393555
Batch 6/64 loss: -0.7451200485229492
Batch 7/64 loss: -0.6316890716552734
Batch 8/64 loss: -0.4600687026977539
Batch 9/64 loss: -0.6880226135253906
Batch 10/64 loss: -0.9334325790405273
Batch 11/64 loss: -0.5547113418579102
Batch 12/64 loss: -0.9904727935791016
Batch 13/64 loss: -0.5807657241821289
Batch 14/64 loss: -0.9444684982299805
Batch 15/64 loss: -0.6380138397216797
Batch 16/64 loss: -0.6100311279296875
Batch 17/64 loss: -0.6268119812011719
Batch 18/64 loss: -0.7538223266601562
Batch 19/64 loss: -0.8046531677246094
Batch 20/64 loss: -0.4473247528076172
Batch 21/64 loss: -0.7283296585083008
Batch 22/64 loss: -0.506495475769043
Batch 23/64 loss: -0.6892518997192383
Batch 24/64 loss: -0.7358808517456055
Batch 25/64 loss: -0.7288789749145508
Batch 26/64 loss: -0.6316823959350586
Batch 27/64 loss: -0.8336982727050781
Batch 28/64 loss: -1.0040931701660156
Batch 29/64 loss: -0.4327535629272461
Batch 30/64 loss: -0.4464731216430664
Batch 31/64 loss: -0.8814477920532227
Batch 32/64 loss: -0.5048961639404297
Batch 33/64 loss: -0.820037841796875
Batch 34/64 loss: -0.7215890884399414
Batch 35/64 loss: -0.5122532844543457
Batch 36/64 loss: -0.5758333206176758
Batch 37/64 loss: -0.8676605224609375
Batch 38/64 loss: -0.4779958724975586
Batch 39/64 loss: -0.5285129547119141
Batch 40/64 loss: -0.6839361190795898
Batch 41/64 loss: -0.9090681076049805
Batch 42/64 loss: -0.7087669372558594
Batch 43/64 loss: -0.5217580795288086
Batch 44/64 loss: -0.6737022399902344
Batch 45/64 loss: -0.670750617980957
Batch 46/64 loss: -0.9436435699462891
Batch 47/64 loss: 0.08707332611083984
Batch 48/64 loss: 0.22756099700927734
Batch 49/64 loss: -0.25340938568115234
Batch 50/64 loss: -0.11537551879882812
Batch 51/64 loss: -0.8274469375610352
Batch 52/64 loss: -0.2936067581176758
Batch 53/64 loss: -0.4517402648925781
Batch 54/64 loss: -0.7640209197998047
Batch 55/64 loss: -0.7357873916625977
Batch 56/64 loss: -0.5619363784790039
Batch 57/64 loss: -0.6169967651367188
Batch 58/64 loss: -0.6611967086791992
Batch 59/64 loss: -0.7724723815917969
Batch 60/64 loss: -0.8138561248779297
Batch 61/64 loss: -0.4131202697753906
Batch 62/64 loss: -0.8047065734863281
Batch 63/64 loss: -0.8317975997924805
Batch 64/64 loss: -4.734794616699219
Epoch 92  Train loss: -0.6959315356086282  Val loss: -0.746156384445138
Epoch 93
-------------------------------
Batch 1/64 loss: -0.17965316772460938
Batch 2/64 loss: -0.5132541656494141
Batch 3/64 loss: -0.6319408416748047
Batch 4/64 loss: -0.7987728118896484
Batch 5/64 loss: -0.5317115783691406
Batch 6/64 loss: -0.9791955947875977
Batch 7/64 loss: -0.578181266784668
Batch 8/64 loss: 0.24227523803710938
Batch 9/64 loss: -0.6950845718383789
Batch 10/64 loss: -0.8057031631469727
Batch 11/64 loss: -0.32956886291503906
Batch 12/64 loss: -0.49570274353027344
Batch 13/64 loss: -0.9528398513793945
Batch 14/64 loss: -0.8949251174926758
Batch 15/64 loss: -0.6148557662963867
Batch 16/64 loss: -0.24008703231811523
Batch 17/64 loss: -0.8138313293457031
Batch 18/64 loss: -0.3504958152770996
Batch 19/64 loss: -0.41171932220458984
Batch 20/64 loss: -0.4987974166870117
Batch 21/64 loss: -0.7767934799194336
Batch 22/64 loss: -0.2884960174560547
Batch 23/64 loss: -0.7092494964599609
Batch 24/64 loss: -0.2400369644165039
Batch 25/64 loss: -0.7499122619628906
Batch 26/64 loss: -0.617828369140625
Batch 27/64 loss: -0.7948522567749023
Batch 28/64 loss: -0.6639184951782227
Batch 29/64 loss: -0.8090877532958984
Batch 30/64 loss: -0.7821207046508789
Batch 31/64 loss: -0.6595315933227539
Batch 32/64 loss: -0.6501712799072266
Batch 33/64 loss: -0.9901103973388672
Batch 34/64 loss: -0.8616676330566406
Batch 35/64 loss: -0.5723886489868164
Batch 36/64 loss: -0.8159713745117188
Batch 37/64 loss: -0.5393972396850586
Batch 38/64 loss: -1.0067920684814453
Batch 39/64 loss: -0.7161722183227539
Batch 40/64 loss: -0.7409992218017578
Batch 41/64 loss: -0.37119197845458984
Batch 42/64 loss: -0.8342733383178711
Batch 43/64 loss: -0.22197723388671875
Batch 44/64 loss: -0.5600147247314453
Batch 45/64 loss: -0.3413515090942383
Batch 46/64 loss: -0.7697954177856445
Batch 47/64 loss: -0.8468790054321289
Batch 48/64 loss: -0.773280143737793
Batch 49/64 loss: -0.5166873931884766
Batch 50/64 loss: -0.36099720001220703
Batch 51/64 loss: -1.0067033767700195
Batch 52/64 loss: -0.8479671478271484
Batch 53/64 loss: -0.7989892959594727
Batch 54/64 loss: -0.7318668365478516
Batch 55/64 loss: -0.7083358764648438
Batch 56/64 loss: -0.7526130676269531
Batch 57/64 loss: -0.5066213607788086
Batch 58/64 loss: -0.7810888290405273
Batch 59/64 loss: -0.9007816314697266
Batch 60/64 loss: -0.8676185607910156
Batch 61/64 loss: -0.23208236694335938
Batch 62/64 loss: -0.7806453704833984
Batch 63/64 loss: -0.8469219207763672
Batch 64/64 loss: -4.220724105834961
Epoch 93  Train loss: -0.6836669697481044  Val loss: -0.6822281277056822
Epoch 94
-------------------------------
Batch 1/64 loss: -0.6551895141601562
Batch 2/64 loss: -0.6354341506958008
Batch 3/64 loss: -0.9801187515258789
Batch 4/64 loss: -0.94683837890625
Batch 5/64 loss: -1.0535526275634766
Batch 6/64 loss: -1.1294441223144531
Batch 7/64 loss: -1.1437549591064453
Batch 8/64 loss: -0.6614599227905273
Batch 9/64 loss: 0.026640892028808594
Batch 10/64 loss: -0.78338623046875
Batch 11/64 loss: -0.6992902755737305
Batch 12/64 loss: -0.4531383514404297
Batch 13/64 loss: -0.8425140380859375
Batch 14/64 loss: -0.6532478332519531
Batch 15/64 loss: -0.601959228515625
Batch 16/64 loss: -0.5382184982299805
Batch 17/64 loss: -0.7923994064331055
Batch 18/64 loss: -0.8420381546020508
Batch 19/64 loss: -0.4091510772705078
Batch 20/64 loss: -0.7663612365722656
Batch 21/64 loss: -1.0278663635253906
Batch 22/64 loss: -0.6802587509155273
Batch 23/64 loss: -0.9604387283325195
Batch 24/64 loss: -0.3567962646484375
Batch 25/64 loss: -0.16106176376342773
Batch 26/64 loss: -0.8299636840820312
Batch 27/64 loss: -0.7172126770019531
Batch 28/64 loss: -0.725285530090332
Batch 29/64 loss: -0.8495016098022461
Batch 30/64 loss: -0.7117671966552734
Batch 31/64 loss: -0.8561334609985352
Batch 32/64 loss: -0.6257143020629883
Batch 33/64 loss: -0.9875011444091797
Batch 34/64 loss: -0.6554422378540039
Batch 35/64 loss: -0.2776508331298828
Batch 36/64 loss: -0.7396259307861328
Batch 37/64 loss: -0.4986133575439453
Batch 38/64 loss: -0.6122264862060547
Batch 39/64 loss: -0.7685213088989258
Batch 40/64 loss: -1.0378608703613281
Batch 41/64 loss: -0.7159938812255859
Batch 42/64 loss: -0.8625421524047852
Batch 43/64 loss: -1.060394287109375
Batch 44/64 loss: -0.9190969467163086
Batch 45/64 loss: -0.6077260971069336
Batch 46/64 loss: -0.9477758407592773
Batch 47/64 loss: -0.5719413757324219
Batch 48/64 loss: -0.2999534606933594
Batch 49/64 loss: -0.6704130172729492
Batch 50/64 loss: -0.7244577407836914
Batch 51/64 loss: -1.034597396850586
Batch 52/64 loss: -0.5543012619018555
Batch 53/64 loss: -0.7659311294555664
Batch 54/64 loss: -1.041259765625
Batch 55/64 loss: -1.0020713806152344
Batch 56/64 loss: -0.8677492141723633
Batch 57/64 loss: -0.8121337890625
Batch 58/64 loss: -0.3911447525024414
Batch 59/64 loss: -0.42175865173339844
Batch 60/64 loss: -0.07137680053710938
Batch 61/64 loss: -0.8194770812988281
Batch 62/64 loss: -0.44847774505615234
Batch 63/64 loss: -0.4273262023925781
Batch 64/64 loss: -4.601541519165039
Epoch 94  Train loss: -0.754970266304764  Val loss: -0.6230943424185527
Epoch 95
-------------------------------
Batch 1/64 loss: -0.7130355834960938
Batch 2/64 loss: -0.7669582366943359
Batch 3/64 loss: 0.1889820098876953
Batch 4/64 loss: -0.9696187973022461
Batch 5/64 loss: -0.5942668914794922
Batch 6/64 loss: -0.5108728408813477
Batch 7/64 loss: -0.6857757568359375
Batch 8/64 loss: -0.20205116271972656
Batch 9/64 loss: -0.6930866241455078
Batch 10/64 loss: -0.45395946502685547
Batch 11/64 loss: -0.4573535919189453
Batch 12/64 loss: -0.4132957458496094
Batch 13/64 loss: -0.7077817916870117
Batch 14/64 loss: -0.6542949676513672
Batch 15/64 loss: -0.6405277252197266
Batch 16/64 loss: -0.7895965576171875
Batch 17/64 loss: -0.8520755767822266
Batch 18/64 loss: -0.3988838195800781
Batch 19/64 loss: -0.8028497695922852
Batch 20/64 loss: -0.7071447372436523
Batch 21/64 loss: -0.2063426971435547
Batch 22/64 loss: -0.6111507415771484
Batch 23/64 loss: -0.9065027236938477
Batch 24/64 loss: 0.011500358581542969
Batch 25/64 loss: -1.0728521347045898
Batch 26/64 loss: -0.9038562774658203
Batch 27/64 loss: -0.425048828125
Batch 28/64 loss: -0.9404010772705078
Batch 29/64 loss: -0.4437265396118164
Batch 30/64 loss: -0.9734706878662109
Batch 31/64 loss: -0.8844900131225586
Batch 32/64 loss: -0.5059089660644531
Batch 33/64 loss: -0.7444486618041992
Batch 34/64 loss: -0.9729318618774414
Batch 35/64 loss: -0.5540437698364258
Batch 36/64 loss: -0.8763065338134766
Batch 37/64 loss: -0.8280782699584961
Batch 38/64 loss: -0.7948617935180664
Batch 39/64 loss: -0.810664176940918
Batch 40/64 loss: -1.0157489776611328
Batch 41/64 loss: -0.7270946502685547
Batch 42/64 loss: -1.0473623275756836
Batch 43/64 loss: -0.7363672256469727
Batch 44/64 loss: -0.5671615600585938
Batch 45/64 loss: 0.5608749389648438
Batch 46/64 loss: -0.5914020538330078
Batch 47/64 loss: -0.38961029052734375
Batch 48/64 loss: -0.9966535568237305
Batch 49/64 loss: -0.8488359451293945
Batch 50/64 loss: -0.6192121505737305
Batch 51/64 loss: -0.6879644393920898
Batch 52/64 loss: -0.9697542190551758
Batch 53/64 loss: -0.4384593963623047
Batch 54/64 loss: -0.5411844253540039
Batch 55/64 loss: -0.4497518539428711
Batch 56/64 loss: -0.5448884963989258
Batch 57/64 loss: -0.43666839599609375
Batch 58/64 loss: -0.7979249954223633
Batch 59/64 loss: -0.3624706268310547
Batch 60/64 loss: -0.7397937774658203
Batch 61/64 loss: -0.9259805679321289
Batch 62/64 loss: -0.6255073547363281
Batch 63/64 loss: -0.9243259429931641
Batch 64/64 loss: -4.217879295349121
Epoch 95  Train loss: -0.6879167182772767  Val loss: -0.7891110554593536
Epoch 96
-------------------------------
Batch 1/64 loss: -1.066084861755371
Batch 2/64 loss: -0.6458253860473633
Batch 3/64 loss: -0.8765830993652344
Batch 4/64 loss: -0.6248750686645508
Batch 5/64 loss: -0.8220672607421875
Batch 6/64 loss: -0.5444011688232422
Batch 7/64 loss: -0.6366596221923828
Batch 8/64 loss: -0.4992694854736328
Batch 9/64 loss: -0.7773885726928711
Batch 10/64 loss: -0.7478914260864258
Batch 11/64 loss: -0.6884336471557617
Batch 12/64 loss: -0.553309440612793
Batch 13/64 loss: -1.0852251052856445
Batch 14/64 loss: -0.6284074783325195
Batch 15/64 loss: -0.37874603271484375
Batch 16/64 loss: -0.7258548736572266
Batch 17/64 loss: -0.5753002166748047
Batch 18/64 loss: -0.8932294845581055
Batch 19/64 loss: -0.6178960800170898
Batch 20/64 loss: -0.9137020111083984
Batch 21/64 loss: -0.746851921081543
Batch 22/64 loss: -0.8679256439208984
Batch 23/64 loss: -0.8619346618652344
Batch 24/64 loss: -0.6773967742919922
Batch 25/64 loss: -0.806065559387207
Batch 26/64 loss: -0.6602277755737305
Batch 27/64 loss: -0.7609434127807617
Batch 28/64 loss: -0.5595474243164062
Batch 29/64 loss: -0.45518970489501953
Batch 30/64 loss: -0.7300395965576172
Batch 31/64 loss: -0.5384798049926758
Batch 32/64 loss: -0.08306694030761719
Batch 33/64 loss: -0.6917791366577148
Batch 34/64 loss: -0.3702812194824219
Batch 35/64 loss: -0.8453264236450195
Batch 36/64 loss: -0.5025081634521484
Batch 37/64 loss: -0.6096429824829102
Batch 38/64 loss: -0.7963132858276367
Batch 39/64 loss: -0.8980302810668945
Batch 40/64 loss: -0.8109016418457031
Batch 41/64 loss: -0.6544876098632812
Batch 42/64 loss: -0.4635772705078125
Batch 43/64 loss: -0.5673141479492188
Batch 44/64 loss: -0.7367916107177734
Batch 45/64 loss: -0.35230255126953125
Batch 46/64 loss: -0.8381252288818359
Batch 47/64 loss: -1.0014238357543945
Batch 48/64 loss: -0.6690177917480469
Batch 49/64 loss: -0.5588932037353516
Batch 50/64 loss: -0.633702278137207
Batch 51/64 loss: -0.4147367477416992
Batch 52/64 loss: -0.842559814453125
Batch 53/64 loss: -0.2933473587036133
Batch 54/64 loss: -0.5970544815063477
Batch 55/64 loss: -0.9656143188476562
Batch 56/64 loss: -0.5874814987182617
Batch 57/64 loss: -0.7220268249511719
Batch 58/64 loss: -0.7610864639282227
Batch 59/64 loss: -0.7183237075805664
Batch 60/64 loss: -0.5593223571777344
Batch 61/64 loss: -0.5996494293212891
Batch 62/64 loss: -0.6644086837768555
Batch 63/64 loss: -0.9006271362304688
Batch 64/64 loss: -4.35650634765625
Epoch 96  Train loss: -0.7206722633511412  Val loss: -0.9039207274971139
Saving best model, epoch: 96
Epoch 97
-------------------------------
Batch 1/64 loss: -0.9607181549072266
Batch 2/64 loss: -0.5373563766479492
Batch 3/64 loss: -0.1576557159423828
Batch 4/64 loss: -0.9872941970825195
Batch 5/64 loss: -0.9454231262207031
Batch 6/64 loss: -0.6188201904296875
Batch 7/64 loss: -0.5549392700195312
Batch 8/64 loss: -0.9220190048217773
Batch 9/64 loss: -0.2141580581665039
Batch 10/64 loss: -0.9084053039550781
Batch 11/64 loss: -0.9969367980957031
Batch 12/64 loss: -0.7951173782348633
Batch 13/64 loss: -0.4022855758666992
Batch 14/64 loss: -0.5663223266601562
Batch 15/64 loss: -0.9075031280517578
Batch 16/64 loss: -1.1726341247558594
Batch 17/64 loss: -0.8479576110839844
Batch 18/64 loss: -0.8891525268554688
Batch 19/64 loss: -0.5825033187866211
Batch 20/64 loss: -0.559417724609375
Batch 21/64 loss: -0.48493289947509766
Batch 22/64 loss: -0.4712247848510742
Batch 23/64 loss: -1.127242088317871
Batch 24/64 loss: -0.5938882827758789
Batch 25/64 loss: -0.470794677734375
Batch 26/64 loss: -0.5142898559570312
Batch 27/64 loss: -0.8436450958251953
Batch 28/64 loss: -0.83355712890625
Batch 29/64 loss: -0.9774293899536133
Batch 30/64 loss: -1.004201889038086
Batch 31/64 loss: -0.7519140243530273
Batch 32/64 loss: -0.9886789321899414
Batch 33/64 loss: -0.5946121215820312
Batch 34/64 loss: -0.7040109634399414
Batch 35/64 loss: -0.6377077102661133
Batch 36/64 loss: -0.6239261627197266
Batch 37/64 loss: -0.6268558502197266
Batch 38/64 loss: -0.4375734329223633
Batch 39/64 loss: -0.9155139923095703
Batch 40/64 loss: -0.6166105270385742
Batch 41/64 loss: -0.5469570159912109
Batch 42/64 loss: -0.5174198150634766
Batch 43/64 loss: -0.9516429901123047
Batch 44/64 loss: -0.8515567779541016
Batch 45/64 loss: -0.6686201095581055
Batch 46/64 loss: -0.3428945541381836
Batch 47/64 loss: -0.8583030700683594
Batch 48/64 loss: -1.0564842224121094
Batch 49/64 loss: -0.7094440460205078
Batch 50/64 loss: -0.6765785217285156
Batch 51/64 loss: -0.7725000381469727
Batch 52/64 loss: -0.836369514465332
Batch 53/64 loss: -0.6891794204711914
Batch 54/64 loss: -0.8317394256591797
Batch 55/64 loss: -0.5538473129272461
Batch 56/64 loss: -0.6929216384887695
Batch 57/64 loss: -0.6001148223876953
Batch 58/64 loss: -0.5489177703857422
Batch 59/64 loss: -0.4878082275390625
Batch 60/64 loss: -0.3427867889404297
Batch 61/64 loss: -0.9143161773681641
Batch 62/64 loss: -0.9054603576660156
Batch 63/64 loss: -0.6705026626586914
Batch 64/64 loss: -4.577905178070068
Epoch 97  Train loss: -0.756157237408208  Val loss: -0.7798715702856529
Epoch 98
-------------------------------
Batch 1/64 loss: -0.34426403045654297
Batch 2/64 loss: -0.7775173187255859
Batch 3/64 loss: -0.9431867599487305
Batch 4/64 loss: -0.8213005065917969
Batch 5/64 loss: -0.5801897048950195
Batch 6/64 loss: -0.8628950119018555
Batch 7/64 loss: -0.9520139694213867
Batch 8/64 loss: -1.0056676864624023
Batch 9/64 loss: -0.5731668472290039
Batch 10/64 loss: -0.8883514404296875
Batch 11/64 loss: -0.3645963668823242
Batch 12/64 loss: -0.5885705947875977
Batch 13/64 loss: -0.7264833450317383
Batch 14/64 loss: -0.7521162033081055
Batch 15/64 loss: -0.9277839660644531
Batch 16/64 loss: -0.6729059219360352
Batch 17/64 loss: -0.6929407119750977
Batch 18/64 loss: -0.28668975830078125
Batch 19/64 loss: -0.7357330322265625
Batch 20/64 loss: -0.5614566802978516
Batch 21/64 loss: -0.6268577575683594
Batch 22/64 loss: -0.2983217239379883
Batch 23/64 loss: -0.9880056381225586
Batch 24/64 loss: -0.6923589706420898
Batch 25/64 loss: -0.6911945343017578
Batch 26/64 loss: -1.215010643005371
Batch 27/64 loss: -0.5333900451660156
Batch 28/64 loss: -0.8394985198974609
Batch 29/64 loss: -0.3529071807861328
Batch 30/64 loss: -0.5598154067993164
Batch 31/64 loss: -0.5926113128662109
Batch 32/64 loss: -0.6738834381103516
Batch 33/64 loss: -1.1462345123291016
Batch 34/64 loss: -1.0607719421386719
Batch 35/64 loss: -0.7654609680175781
Batch 36/64 loss: -0.8203229904174805
Batch 37/64 loss: -0.6494274139404297
Batch 38/64 loss: -1.0165224075317383
Batch 39/64 loss: -0.7374362945556641
Batch 40/64 loss: -0.7434921264648438
Batch 41/64 loss: -0.7978973388671875
Batch 42/64 loss: -0.8245458602905273
Batch 43/64 loss: -0.4124135971069336
Batch 44/64 loss: -1.219655990600586
Batch 45/64 loss: -0.46581363677978516
Batch 46/64 loss: -0.8149423599243164
Batch 47/64 loss: -0.9441366195678711
Batch 48/64 loss: -0.5935792922973633
Batch 49/64 loss: -0.9714298248291016
Batch 50/64 loss: -0.9428281784057617
Batch 51/64 loss: -0.9556112289428711
Batch 52/64 loss: -0.5610942840576172
Batch 53/64 loss: -0.35440826416015625
Batch 54/64 loss: -0.9341602325439453
Batch 55/64 loss: -0.4451580047607422
Batch 56/64 loss: -0.8272619247436523
Batch 57/64 loss: -0.37960052490234375
Batch 58/64 loss: -1.0194883346557617
Batch 59/64 loss: -1.0209054946899414
Batch 60/64 loss: -0.8433599472045898
Batch 61/64 loss: -0.9127464294433594
Batch 62/64 loss: -0.7064590454101562
Batch 63/64 loss: -1.0949735641479492
Batch 64/64 loss: -4.122437477111816
Epoch 98  Train loss: -0.7873827728570676  Val loss: -0.8772477218785237
Epoch 99
-------------------------------
Batch 1/64 loss: -0.7159852981567383
Batch 2/64 loss: -0.6883201599121094
Batch 3/64 loss: -1.130859375
Batch 4/64 loss: -0.5140628814697266
Batch 5/64 loss: -0.759185791015625
Batch 6/64 loss: -0.6350479125976562
Batch 7/64 loss: -0.6216001510620117
Batch 8/64 loss: -0.6704292297363281
Batch 9/64 loss: -0.9789962768554688
Batch 10/64 loss: -0.603912353515625
Batch 11/64 loss: -1.030487060546875
Batch 12/64 loss: -0.6146402359008789
Batch 13/64 loss: -1.2035045623779297
Batch 14/64 loss: -0.8832025527954102
Batch 15/64 loss: -0.7039995193481445
Batch 16/64 loss: -0.3915987014770508
Batch 17/64 loss: -1.1275053024291992
Batch 18/64 loss: -0.9052600860595703
Batch 19/64 loss: -0.927891731262207
Batch 20/64 loss: -0.8130979537963867
Batch 21/64 loss: -0.5282258987426758
Batch 22/64 loss: -0.5913591384887695
Batch 23/64 loss: -0.9609737396240234
Batch 24/64 loss: -1.0984745025634766
Batch 25/64 loss: -0.4226083755493164
Batch 26/64 loss: -1.3400611877441406
Batch 27/64 loss: -0.7421894073486328
Batch 28/64 loss: -0.534092903137207
Batch 29/64 loss: -0.18549060821533203
Batch 30/64 loss: -0.8735227584838867
Batch 31/64 loss: -0.9372014999389648
Batch 32/64 loss: -0.5160961151123047
Batch 33/64 loss: -0.4925575256347656
Batch 34/64 loss: -0.9375810623168945
Batch 35/64 loss: -0.9597692489624023
Batch 36/64 loss: -0.8654994964599609
Batch 37/64 loss: -1.1173095703125
Batch 38/64 loss: -0.6411190032958984
Batch 39/64 loss: -1.1180496215820312
Batch 40/64 loss: -0.5416402816772461
Batch 41/64 loss: -1.1090726852416992
Batch 42/64 loss: -0.5805234909057617
Batch 43/64 loss: -0.1605815887451172
Batch 44/64 loss: -0.8677396774291992
Batch 45/64 loss: -0.3538017272949219
Batch 46/64 loss: -0.7315158843994141
Batch 47/64 loss: -0.8315019607543945
Batch 48/64 loss: -0.5762157440185547
Batch 49/64 loss: -0.48400402069091797
Batch 50/64 loss: -1.0229406356811523
Batch 51/64 loss: -0.5300149917602539
Batch 52/64 loss: -0.7955493927001953
Batch 53/64 loss: -0.8253717422485352
Batch 54/64 loss: -0.7217330932617188
Batch 55/64 loss: -0.5147647857666016
Batch 56/64 loss: -0.5791120529174805
Batch 57/64 loss: -0.6904783248901367
Batch 58/64 loss: -0.5364418029785156
Batch 59/64 loss: -1.0636234283447266
Batch 60/64 loss: -0.8642196655273438
Batch 61/64 loss: -0.45641040802001953
Batch 62/64 loss: -0.42121124267578125
Batch 63/64 loss: -0.8861732482910156
Batch 64/64 loss: -4.406748294830322
Epoch 99  Train loss: -0.7879446571948482  Val loss: -0.6613349521283022
Epoch 100
-------------------------------
Batch 1/64 loss: -0.9803228378295898
Batch 2/64 loss: -0.7908964157104492
Batch 3/64 loss: -0.7047576904296875
Batch 4/64 loss: -1.1002168655395508
Batch 5/64 loss: -0.5563163757324219
Batch 6/64 loss: -0.4697866439819336
Batch 7/64 loss: -1.0713109970092773
Batch 8/64 loss: -0.8435821533203125
Batch 9/64 loss: -0.37688446044921875
Batch 10/64 loss: -0.6261119842529297
Batch 11/64 loss: -0.3501138687133789
Batch 12/64 loss: -0.3293008804321289
Batch 13/64 loss: -1.0019845962524414
Batch 14/64 loss: -0.20595645904541016
Batch 15/64 loss: -1.0466642379760742
Batch 16/64 loss: -1.1951913833618164
Batch 17/64 loss: -0.7385311126708984
Batch 18/64 loss: -0.8178262710571289
Batch 19/64 loss: -0.806218147277832
Batch 20/64 loss: -1.1391544342041016
Batch 21/64 loss: -0.5294914245605469
Batch 22/64 loss: -0.5665369033813477
Batch 23/64 loss: -0.5576791763305664
Batch 24/64 loss: -0.908055305480957
Batch 25/64 loss: -0.8117351531982422
Batch 26/64 loss: -0.8924703598022461
Batch 27/64 loss: -0.740239143371582
Batch 28/64 loss: -0.6439189910888672
Batch 29/64 loss: -1.003056526184082
Batch 30/64 loss: -0.9482975006103516
Batch 31/64 loss: -1.0184345245361328
Batch 32/64 loss: -0.871953010559082
Batch 33/64 loss: -1.1070795059204102
Batch 34/64 loss: -0.43594932556152344
Batch 35/64 loss: -0.7208890914916992
Batch 36/64 loss: -0.581059455871582
Batch 37/64 loss: -1.0441656112670898
Batch 38/64 loss: -0.792607307434082
Batch 39/64 loss: -0.6056327819824219
Batch 40/64 loss: -0.7692632675170898
Batch 41/64 loss: -0.5883684158325195
Batch 42/64 loss: -0.5947360992431641
Batch 43/64 loss: -0.7724781036376953
Batch 44/64 loss: -1.2766456604003906
Batch 45/64 loss: -0.9472084045410156
Batch 46/64 loss: -0.39249324798583984
Batch 47/64 loss: -0.5942401885986328
Batch 48/64 loss: -0.3332691192626953
Batch 49/64 loss: -0.9219560623168945
Batch 50/64 loss: -0.71820068359375
Batch 51/64 loss: -0.6455669403076172
Batch 52/64 loss: -0.9106616973876953
Batch 53/64 loss: -0.8530778884887695
Batch 54/64 loss: -0.6502532958984375
Batch 55/64 loss: -1.098459243774414
Batch 56/64 loss: -0.7543535232543945
Batch 57/64 loss: -0.9221410751342773
Batch 58/64 loss: -0.596257209777832
Batch 59/64 loss: -0.4684925079345703
Batch 60/64 loss: -0.3437337875366211
Batch 61/64 loss: -0.9912939071655273
Batch 62/64 loss: -0.9037342071533203
Batch 63/64 loss: -0.9505958557128906
Batch 64/64 loss: -4.311749458312988
Epoch 100  Train loss: -0.8025360219618853  Val loss: -0.8193099293921822
Epoch 101
-------------------------------
Batch 1/64 loss: -0.7217807769775391
Batch 2/64 loss: -0.4590463638305664
Batch 3/64 loss: -0.8488883972167969
Batch 4/64 loss: -0.7880678176879883
Batch 5/64 loss: -0.901057243347168
Batch 6/64 loss: -1.1504850387573242
Batch 7/64 loss: -0.7376937866210938
Batch 8/64 loss: -0.9578742980957031
Batch 9/64 loss: -0.9435186386108398
Batch 10/64 loss: -0.9490194320678711
Batch 11/64 loss: -0.9239139556884766
Batch 12/64 loss: -0.48326873779296875
Batch 13/64 loss: -0.7596273422241211
Batch 14/64 loss: -0.8101367950439453
Batch 15/64 loss: -0.8440885543823242
Batch 16/64 loss: -0.2137308120727539
Batch 17/64 loss: -0.8663358688354492
Batch 18/64 loss: -0.8521022796630859
Batch 19/64 loss: -0.873042106628418
Batch 20/64 loss: -0.7847127914428711
Batch 21/64 loss: -0.8734664916992188
Batch 22/64 loss: -0.2769327163696289
Batch 23/64 loss: -0.9843950271606445
Batch 24/64 loss: -0.8939590454101562
Batch 25/64 loss: -0.5948448181152344
Batch 26/64 loss: -1.0947999954223633
Batch 27/64 loss: -0.5062065124511719
Batch 28/64 loss: -0.8922204971313477
Batch 29/64 loss: -0.2958192825317383
Batch 30/64 loss: -0.650120735168457
Batch 31/64 loss: -0.4897470474243164
Batch 32/64 loss: -0.998204231262207
Batch 33/64 loss: -0.8542976379394531
Batch 34/64 loss: -0.5431022644042969
Batch 35/64 loss: -1.0729427337646484
Batch 36/64 loss: -0.9004554748535156
Batch 37/64 loss: -0.9548635482788086
Batch 38/64 loss: -0.7943992614746094
Batch 39/64 loss: -0.4293489456176758
Batch 40/64 loss: -0.6316814422607422
Batch 41/64 loss: -0.7889213562011719
Batch 42/64 loss: -0.3473081588745117
Batch 43/64 loss: -0.7153511047363281
Batch 44/64 loss: -1.1267337799072266
Batch 45/64 loss: -0.9219484329223633
Batch 46/64 loss: -0.6875410079956055
Batch 47/64 loss: -0.7605113983154297
Batch 48/64 loss: -0.7914800643920898
Batch 49/64 loss: -0.9013900756835938
Batch 50/64 loss: -0.9211912155151367
Batch 51/64 loss: -0.2094440460205078
Batch 52/64 loss: -0.7043027877807617
Batch 53/64 loss: -0.916046142578125
Batch 54/64 loss: -0.7845869064331055
Batch 55/64 loss: -0.7651453018188477
Batch 56/64 loss: -0.7167682647705078
Batch 57/64 loss: -0.4870786666870117
Batch 58/64 loss: -0.8394412994384766
Batch 59/64 loss: -0.9556941986083984
Batch 60/64 loss: -1.042348861694336
Batch 61/64 loss: 0.7106924057006836
Batch 62/64 loss: -0.3797931671142578
Batch 63/64 loss: -0.7678670883178711
Batch 64/64 loss: -4.791372299194336
Epoch 101  Train loss: -0.7845322178859336  Val loss: -0.7953322236890236
Epoch 102
-------------------------------
Batch 1/64 loss: -0.693079948425293
Batch 2/64 loss: -0.2796602249145508
Batch 3/64 loss: -0.7920017242431641
Batch 4/64 loss: -0.4989166259765625
Batch 5/64 loss: -0.8273258209228516
Batch 6/64 loss: -0.8841781616210938
Batch 7/64 loss: -0.7531938552856445
Batch 8/64 loss: -0.7939424514770508
Batch 9/64 loss: -0.6692285537719727
Batch 10/64 loss: -0.3348093032836914
Batch 11/64 loss: -0.9704828262329102
Batch 12/64 loss: -0.7610015869140625
Batch 13/64 loss: -0.7337760925292969
Batch 14/64 loss: -0.753021240234375
Batch 15/64 loss: -0.6524171829223633
Batch 16/64 loss: -0.4774017333984375
Batch 17/64 loss: -0.9394636154174805
Batch 18/64 loss: -0.9418535232543945
Batch 19/64 loss: -0.8876028060913086
Batch 20/64 loss: -0.5280189514160156
Batch 21/64 loss: -0.35735607147216797
Batch 22/64 loss: -0.8651275634765625
Batch 23/64 loss: -0.502838134765625
Batch 24/64 loss: -0.2761802673339844
Batch 25/64 loss: -1.0481672286987305
Batch 26/64 loss: -0.8761301040649414
Batch 27/64 loss: -0.4693183898925781
Batch 28/64 loss: -0.9088068008422852
Batch 29/64 loss: -1.152669906616211
Batch 30/64 loss: -0.8825960159301758
Batch 31/64 loss: -0.9417133331298828
Batch 32/64 loss: -0.763859748840332
Batch 33/64 loss: -0.10271263122558594
Batch 34/64 loss: -1.1688308715820312
Batch 35/64 loss: -0.6274118423461914
Batch 36/64 loss: -0.6346769332885742
Batch 37/64 loss: -0.4881172180175781
Batch 38/64 loss: -0.5106544494628906
Batch 39/64 loss: -0.8219099044799805
Batch 40/64 loss: -0.8631515502929688
Batch 41/64 loss: -0.898040771484375
Batch 42/64 loss: -0.6282463073730469
Batch 43/64 loss: -0.3002195358276367
Batch 44/64 loss: -0.5722122192382812
Batch 45/64 loss: -0.7170648574829102
Batch 46/64 loss: -0.9121532440185547
Batch 47/64 loss: -0.7546796798706055
Batch 48/64 loss: -0.944676399230957
Batch 49/64 loss: -0.8367347717285156
Batch 50/64 loss: -0.6702404022216797
Batch 51/64 loss: -0.5192937850952148
Batch 52/64 loss: -0.8854284286499023
Batch 53/64 loss: -0.8882160186767578
Batch 54/64 loss: -0.639897346496582
Batch 55/64 loss: -0.6742820739746094
Batch 56/64 loss: -0.780583381652832
Batch 57/64 loss: -1.0320491790771484
Batch 58/64 loss: -0.9621133804321289
Batch 59/64 loss: -0.5530319213867188
Batch 60/64 loss: -1.0408620834350586
Batch 61/64 loss: -0.8876323699951172
Batch 62/64 loss: -0.4336061477661133
Batch 63/64 loss: -0.8760671615600586
Batch 64/64 loss: -4.881887435913086
Epoch 102  Train loss: -0.7765074860815908  Val loss: -0.8875291175449017
Epoch 103
-------------------------------
Batch 1/64 loss: -0.7001714706420898
Batch 2/64 loss: -0.7789640426635742
Batch 3/64 loss: -0.9679374694824219
Batch 4/64 loss: -0.9372663497924805
Batch 5/64 loss: -0.8734054565429688
Batch 6/64 loss: -0.619471549987793
Batch 7/64 loss: -0.7738275527954102
Batch 8/64 loss: -0.8698225021362305
Batch 9/64 loss: -0.27823638916015625
Batch 10/64 loss: -0.7917270660400391
Batch 11/64 loss: -0.6603527069091797
Batch 12/64 loss: -0.7456426620483398
Batch 13/64 loss: -0.7500705718994141
Batch 14/64 loss: -0.9093828201293945
Batch 15/64 loss: -0.7867012023925781
Batch 16/64 loss: -0.9866819381713867
Batch 17/64 loss: -0.8860607147216797
Batch 18/64 loss: -0.6226921081542969
Batch 19/64 loss: -1.0096769332885742
Batch 20/64 loss: -0.9979152679443359
Batch 21/64 loss: -0.6870861053466797
Batch 22/64 loss: -0.43033599853515625
Batch 23/64 loss: -0.4227590560913086
Batch 24/64 loss: -0.36309242248535156
Batch 25/64 loss: -0.5024499893188477
Batch 26/64 loss: -0.6092567443847656
Batch 27/64 loss: -0.2374582290649414
Batch 28/64 loss: -0.3554248809814453
Batch 29/64 loss: -0.8852090835571289
Batch 30/64 loss: -0.7196645736694336
Batch 31/64 loss: -0.886530876159668
Batch 32/64 loss: -0.27196407318115234
Batch 33/64 loss: -0.3043689727783203
Batch 34/64 loss: -0.802708625793457
Batch 35/64 loss: -1.0520458221435547
Batch 36/64 loss: -0.23326539993286133
Batch 37/64 loss: -1.189408302307129
Batch 38/64 loss: -0.6925516128540039
Batch 39/64 loss: -0.6664361953735352
Batch 40/64 loss: -0.9217815399169922
Batch 41/64 loss: -0.8362054824829102
Batch 42/64 loss: -0.6635150909423828
Batch 43/64 loss: -0.8176279067993164
Batch 44/64 loss: -0.6279573440551758
Batch 45/64 loss: -0.45328712463378906
Batch 46/64 loss: -0.35874462127685547
Batch 47/64 loss: -0.8464460372924805
Batch 48/64 loss: -0.5173368453979492
Batch 49/64 loss: -1.2413711547851562
Batch 50/64 loss: -0.9842548370361328
Batch 51/64 loss: -0.6967191696166992
Batch 52/64 loss: -0.7301511764526367
Batch 53/64 loss: -0.6423797607421875
Batch 54/64 loss: -0.9152116775512695
Batch 55/64 loss: -1.312464714050293
Batch 56/64 loss: -0.7579622268676758
Batch 57/64 loss: -0.5774564743041992
Batch 58/64 loss: -0.9740619659423828
Batch 59/64 loss: -0.8754453659057617
Batch 60/64 loss: -0.7409801483154297
Batch 61/64 loss: -1.1089582443237305
Batch 62/64 loss: -0.6082305908203125
Batch 63/64 loss: -0.7758121490478516
Batch 64/64 loss: -4.760460376739502
Epoch 103  Train loss: -0.7813761673721613  Val loss: -0.915553902432681
Saving best model, epoch: 103
Epoch 104
-------------------------------
Batch 1/64 loss: -0.626795768737793
Batch 2/64 loss: -0.9250879287719727
Batch 3/64 loss: -0.7283878326416016
Batch 4/64 loss: -0.7636375427246094
Batch 5/64 loss: -0.9212961196899414
Batch 6/64 loss: -0.8829574584960938
Batch 7/64 loss: -0.2980527877807617
Batch 8/64 loss: -0.8444795608520508
Batch 9/64 loss: -0.7269010543823242
Batch 10/64 loss: -0.7977304458618164
Batch 11/64 loss: -0.9064092636108398
Batch 12/64 loss: -0.7688026428222656
Batch 13/64 loss: -1.108942985534668
Batch 14/64 loss: -0.9898414611816406
Batch 15/64 loss: -0.9165687561035156
Batch 16/64 loss: -0.8439922332763672
Batch 17/64 loss: -0.8856582641601562
Batch 18/64 loss: -0.9192705154418945
Batch 19/64 loss: -0.013521194458007812
Batch 20/64 loss: -1.0291833877563477
Batch 21/64 loss: -0.8284683227539062
Batch 22/64 loss: -0.4704732894897461
Batch 23/64 loss: -0.9578628540039062
Batch 24/64 loss: -0.9387292861938477
Batch 25/64 loss: -0.9653158187866211
Batch 26/64 loss: -0.9146671295166016
Batch 27/64 loss: -0.5656557083129883
Batch 28/64 loss: -1.0292673110961914
Batch 29/64 loss: -0.14798831939697266
Batch 30/64 loss: -0.690281867980957
Batch 31/64 loss: -0.6912975311279297
Batch 32/64 loss: -0.7713689804077148
Batch 33/64 loss: -0.7721118927001953
Batch 34/64 loss: -0.9796762466430664
Batch 35/64 loss: -0.50146484375
Batch 36/64 loss: -0.5259552001953125
Batch 37/64 loss: -0.7031002044677734
Batch 38/64 loss: -0.6375055313110352
Batch 39/64 loss: -0.8561000823974609
Batch 40/64 loss: -0.5965347290039062
Batch 41/64 loss: -0.17825698852539062
Batch 42/64 loss: -0.6474456787109375
Batch 43/64 loss: -1.0849552154541016
Batch 44/64 loss: -1.1007232666015625
Batch 45/64 loss: -0.8122463226318359
Batch 46/64 loss: -0.9192714691162109
Batch 47/64 loss: -0.23605918884277344
Batch 48/64 loss: -0.7166528701782227
Batch 49/64 loss: -0.6380519866943359
Batch 50/64 loss: -0.515955924987793
Batch 51/64 loss: -0.7578983306884766
Batch 52/64 loss: -1.0020618438720703
Batch 53/64 loss: -0.8194169998168945
Batch 54/64 loss: -0.8606224060058594
Batch 55/64 loss: -0.7939233779907227
Batch 56/64 loss: -0.9239187240600586
Batch 57/64 loss: -0.6624126434326172
Batch 58/64 loss: -0.8422346115112305
Batch 59/64 loss: -0.41007137298583984
Batch 60/64 loss: -0.4150209426879883
Batch 61/64 loss: -0.6058454513549805
Batch 62/64 loss: -1.1000843048095703
Batch 63/64 loss: -0.4502582550048828
Batch 64/64 loss: -5.096494674682617
Epoch 104  Train loss: -0.7961898280125038  Val loss: -0.825023991955105
Epoch 105
-------------------------------
Batch 1/64 loss: -0.8473920822143555
Batch 2/64 loss: -0.30998706817626953
Batch 3/64 loss: -0.3742809295654297
Batch 4/64 loss: -0.838287353515625
Batch 5/64 loss: -1.019735336303711
Batch 6/64 loss: -0.8815774917602539
Batch 7/64 loss: -0.7641887664794922
Batch 8/64 loss: -0.5927524566650391
Batch 9/64 loss: -1.0583677291870117
Batch 10/64 loss: -0.5633668899536133
Batch 11/64 loss: -0.8784055709838867
Batch 12/64 loss: -0.7738142013549805
Batch 13/64 loss: -0.035475730895996094
Batch 14/64 loss: -0.8969745635986328
Batch 15/64 loss: -0.7909717559814453
Batch 16/64 loss: -0.7761449813842773
Batch 17/64 loss: -1.0268573760986328
Batch 18/64 loss: -1.048396110534668
Batch 19/64 loss: -1.0756759643554688
Batch 20/64 loss: -0.8023796081542969
Batch 21/64 loss: -0.37221813201904297
Batch 22/64 loss: -1.037017822265625
Batch 23/64 loss: -0.7287836074829102
Batch 24/64 loss: -0.9351263046264648
Batch 25/64 loss: -0.7365903854370117
Batch 26/64 loss: -0.3603181838989258
Batch 27/64 loss: -0.9669008255004883
Batch 28/64 loss: -0.6709318161010742
Batch 29/64 loss: -1.0755281448364258
Batch 30/64 loss: -0.798213005065918
Batch 31/64 loss: -0.758173942565918
Batch 32/64 loss: -0.43619441986083984
Batch 33/64 loss: -0.8143749237060547
Batch 34/64 loss: -0.697352409362793
Batch 35/64 loss: -0.6698055267333984
Batch 36/64 loss: -0.7463817596435547
Batch 37/64 loss: -0.8477849960327148
Batch 38/64 loss: -0.7008295059204102
Batch 39/64 loss: -0.7023029327392578
Batch 40/64 loss: -0.9516429901123047
Batch 41/64 loss: -0.49752235412597656
Batch 42/64 loss: -0.4413490295410156
Batch 43/64 loss: -0.8112993240356445
Batch 44/64 loss: -0.7733621597290039
Batch 45/64 loss: -0.5912818908691406
Batch 46/64 loss: -0.7067031860351562
Batch 47/64 loss: -0.3834686279296875
Batch 48/64 loss: -1.1128597259521484
Batch 49/64 loss: -0.8861351013183594
Batch 50/64 loss: -0.6176891326904297
Batch 51/64 loss: -0.7564620971679688
Batch 52/64 loss: -0.8681097030639648
Batch 53/64 loss: -1.0754451751708984
Batch 54/64 loss: -1.106247901916504
Batch 55/64 loss: -1.105459213256836
Batch 56/64 loss: -0.9833621978759766
Batch 57/64 loss: -0.9061441421508789
Batch 58/64 loss: -0.558110237121582
Batch 59/64 loss: -0.9781703948974609
Batch 60/64 loss: -0.5222845077514648
Batch 61/64 loss: -0.37232208251953125
Batch 62/64 loss: -0.7545385360717773
Batch 63/64 loss: -0.3120756149291992
Batch 64/64 loss: -4.913575172424316
Epoch 105  Train loss: -0.8026209775139304  Val loss: -0.8769596401358798
Epoch 106
-------------------------------
Batch 1/64 loss: -0.7668876647949219
Batch 2/64 loss: -1.0174579620361328
Batch 3/64 loss: -0.5651206970214844
Batch 4/64 loss: -0.8548421859741211
Batch 5/64 loss: -0.6686296463012695
Batch 6/64 loss: -1.010702133178711
Batch 7/64 loss: -0.9759683609008789
Batch 8/64 loss: -0.6983451843261719
Batch 9/64 loss: -0.7796449661254883
Batch 10/64 loss: -0.9180746078491211
Batch 11/64 loss: -0.9323358535766602
Batch 12/64 loss: -0.9221057891845703
Batch 13/64 loss: -0.6327590942382812
Batch 14/64 loss: -0.1755228042602539
Batch 15/64 loss: -0.6790838241577148
Batch 16/64 loss: -0.9557857513427734
Batch 17/64 loss: -0.972559928894043
Batch 18/64 loss: -0.3432893753051758
Batch 19/64 loss: -0.6960363388061523
Batch 20/64 loss: -1.0851259231567383
Batch 21/64 loss: -1.1334114074707031
Batch 22/64 loss: -0.9007606506347656
Batch 23/64 loss: -1.1034231185913086
Batch 24/64 loss: -1.0305862426757812
Batch 25/64 loss: -0.6477975845336914
Batch 26/64 loss: -0.8232250213623047
Batch 27/64 loss: -0.6507740020751953
Batch 28/64 loss: -0.7662191390991211
Batch 29/64 loss: -1.1546144485473633
Batch 30/64 loss: -0.7309417724609375
Batch 31/64 loss: -1.1977043151855469
Batch 32/64 loss: -0.6337451934814453
Batch 33/64 loss: -0.5833444595336914
Batch 34/64 loss: -0.48140716552734375
Batch 35/64 loss: -0.7910671234130859
Batch 36/64 loss: -0.7195873260498047
Batch 37/64 loss: -0.7597055435180664
Batch 38/64 loss: -0.6745014190673828
Batch 39/64 loss: -0.706578254699707
Batch 40/64 loss: -0.8215065002441406
Batch 41/64 loss: -0.7616491317749023
Batch 42/64 loss: -0.9935722351074219
Batch 43/64 loss: -0.9657754898071289
Batch 44/64 loss: -0.8025484085083008
Batch 45/64 loss: -0.8148097991943359
Batch 46/64 loss: -0.9168605804443359
Batch 47/64 loss: -0.6986083984375
Batch 48/64 loss: -0.6901683807373047
Batch 49/64 loss: -0.6666622161865234
Batch 50/64 loss: -1.099320411682129
Batch 51/64 loss: -0.9054241180419922
Batch 52/64 loss: -1.0464048385620117
Batch 53/64 loss: -0.5989446640014648
Batch 54/64 loss: -0.9616889953613281
Batch 55/64 loss: -0.3474102020263672
Batch 56/64 loss: -0.5603036880493164
Batch 57/64 loss: -1.1441211700439453
Batch 58/64 loss: -1.157867431640625
Batch 59/64 loss: -0.8575592041015625
Batch 60/64 loss: -0.3539295196533203
Batch 61/64 loss: -0.517756462097168
Batch 62/64 loss: -0.7359619140625
Batch 63/64 loss: -0.5512247085571289
Batch 64/64 loss: -4.592714309692383
Epoch 106  Train loss: -0.8400672389011757  Val loss: -0.9465830039322581
Saving best model, epoch: 106
Epoch 107
-------------------------------
Batch 1/64 loss: -0.7306137084960938
Batch 2/64 loss: -1.0416088104248047
Batch 3/64 loss: -0.9696617126464844
Batch 4/64 loss: -0.9963655471801758
Batch 5/64 loss: -0.46531105041503906
Batch 6/64 loss: -1.0265140533447266
Batch 7/64 loss: -1.01239013671875
Batch 8/64 loss: -0.9995431900024414
Batch 9/64 loss: -0.3724956512451172
Batch 10/64 loss: -0.8393144607543945
Batch 11/64 loss: -0.7120609283447266
Batch 12/64 loss: -1.0137100219726562
Batch 13/64 loss: -1.0614662170410156
Batch 14/64 loss: -0.6975078582763672
Batch 15/64 loss: -0.7559537887573242
Batch 16/64 loss: -0.9648475646972656
Batch 17/64 loss: -0.8158016204833984
Batch 18/64 loss: -0.8863344192504883
Batch 19/64 loss: -0.9661340713500977
Batch 20/64 loss: -0.32938194274902344
Batch 21/64 loss: -0.9444894790649414
Batch 22/64 loss: -0.7884387969970703
Batch 23/64 loss: -0.9768829345703125
Batch 24/64 loss: -0.6291208267211914
Batch 25/64 loss: -0.3212270736694336
Batch 26/64 loss: -0.5737419128417969
Batch 27/64 loss: -0.9242420196533203
Batch 28/64 loss: -0.5700454711914062
Batch 29/64 loss: -0.7137842178344727
Batch 30/64 loss: -0.8415517807006836
Batch 31/64 loss: -0.4649968147277832
Batch 32/64 loss: -0.3740234375
Batch 33/64 loss: -0.7237281799316406
Batch 34/64 loss: -0.9581117630004883
Batch 35/64 loss: -0.8073310852050781
Batch 36/64 loss: -0.9377918243408203
Batch 37/64 loss: -0.8711366653442383
Batch 38/64 loss: -0.6504945755004883
Batch 39/64 loss: -0.6631650924682617
Batch 40/64 loss: -0.868809700012207
Batch 41/64 loss: -0.9177703857421875
Batch 42/64 loss: -1.109323501586914
Batch 43/64 loss: -0.9810657501220703
Batch 44/64 loss: -0.27095890045166016
Batch 45/64 loss: -1.200026512145996
Batch 46/64 loss: -0.925236701965332
Batch 47/64 loss: -0.4498882293701172
Batch 48/64 loss: -0.9104528427124023
Batch 49/64 loss: -1.155447006225586
Batch 50/64 loss: -0.6543178558349609
Batch 51/64 loss: -1.101827621459961
Batch 52/64 loss: -0.7953586578369141
Batch 53/64 loss: -0.8260421752929688
Batch 54/64 loss: -0.8733692169189453
Batch 55/64 loss: -0.5682010650634766
Batch 56/64 loss: -0.9238224029541016
Batch 57/64 loss: -0.7977361679077148
Batch 58/64 loss: -0.7810373306274414
Batch 59/64 loss: -0.6548118591308594
Batch 60/64 loss: -1.0497961044311523
Batch 61/64 loss: -0.8498315811157227
Batch 62/64 loss: -1.1058034896850586
Batch 63/64 loss: -0.7687845230102539
Batch 64/64 loss: -4.835590839385986
Epoch 107  Train loss: -0.8558075830048206  Val loss: -1.007553965775008
Saving best model, epoch: 107
Epoch 108
-------------------------------
Batch 1/64 loss: -1.2249345779418945
Batch 2/64 loss: -0.777888298034668
Batch 3/64 loss: -0.8728704452514648
Batch 4/64 loss: -1.1346540451049805
Batch 5/64 loss: -1.1547298431396484
Batch 6/64 loss: -0.5265674591064453
Batch 7/64 loss: -0.73114013671875
Batch 8/64 loss: -0.9207515716552734
Batch 9/64 loss: -0.9504585266113281
Batch 10/64 loss: -0.9149551391601562
Batch 11/64 loss: -0.9599428176879883
Batch 12/64 loss: -0.9059610366821289
Batch 13/64 loss: -0.5038824081420898
Batch 14/64 loss: -0.9305076599121094
Batch 15/64 loss: -1.0464668273925781
Batch 16/64 loss: -0.6890382766723633
Batch 17/64 loss: -1.078704833984375
Batch 18/64 loss: -0.9159126281738281
Batch 19/64 loss: -1.0818119049072266
Batch 20/64 loss: -0.8417291641235352
Batch 21/64 loss: -0.9613628387451172
Batch 22/64 loss: -1.083460807800293
Batch 23/64 loss: -1.013838768005371
Batch 24/64 loss: -0.8453550338745117
Batch 25/64 loss: -0.8386764526367188
Batch 26/64 loss: -1.1876373291015625
Batch 27/64 loss: -0.6662073135375977
Batch 28/64 loss: -0.8406572341918945
Batch 29/64 loss: -0.8260650634765625
Batch 30/64 loss: -0.6970148086547852
Batch 31/64 loss: -0.7957725524902344
Batch 32/64 loss: -0.5114736557006836
Batch 33/64 loss: -0.9865531921386719
Batch 34/64 loss: -0.8607683181762695
Batch 35/64 loss: -0.9085121154785156
Batch 36/64 loss: -0.28218555450439453
Batch 37/64 loss: -0.8230743408203125
Batch 38/64 loss: -0.9531545639038086
Batch 39/64 loss: -0.9367284774780273
Batch 40/64 loss: -0.9021682739257812
Batch 41/64 loss: -0.7951765060424805
Batch 42/64 loss: -0.9587421417236328
Batch 43/64 loss: -0.9375247955322266
Batch 44/64 loss: -0.6469316482543945
Batch 45/64 loss: -0.9350509643554688
Batch 46/64 loss: -1.0018196105957031
Batch 47/64 loss: -0.8418684005737305
Batch 48/64 loss: -0.5992937088012695
Batch 49/64 loss: -0.6103248596191406
Batch 50/64 loss: -0.22771835327148438
Batch 51/64 loss: -1.2643260955810547
Batch 52/64 loss: -0.9429283142089844
Batch 53/64 loss: -0.7604455947875977
Batch 54/64 loss: -0.6362085342407227
Batch 55/64 loss: -0.6682672500610352
Batch 56/64 loss: -0.8527164459228516
Batch 57/64 loss: -1.1095218658447266
Batch 58/64 loss: -0.9465398788452148
Batch 59/64 loss: -0.8394098281860352
Batch 60/64 loss: -0.8753461837768555
Batch 61/64 loss: -0.5677671432495117
Batch 62/64 loss: -0.8851585388183594
Batch 63/64 loss: -0.46894264221191406
Batch 64/64 loss: -5.380175590515137
Epoch 108  Train loss: -0.901815455567603  Val loss: -1.0215985144126867
Saving best model, epoch: 108
Epoch 109
-------------------------------
Batch 1/64 loss: -1.0275545120239258
Batch 2/64 loss: -0.853816032409668
Batch 3/64 loss: -0.6975650787353516
Batch 4/64 loss: -1.1034879684448242
Batch 5/64 loss: -0.6967287063598633
Batch 6/64 loss: -1.2871589660644531
Batch 7/64 loss: -0.7008657455444336
Batch 8/64 loss: -0.9149675369262695
Batch 9/64 loss: -0.9784488677978516
Batch 10/64 loss: -1.0067462921142578
Batch 11/64 loss: -0.9990463256835938
Batch 12/64 loss: -0.9291305541992188
Batch 13/64 loss: -0.8138513565063477
Batch 14/64 loss: -0.7580852508544922
Batch 15/64 loss: -1.1336431503295898
Batch 16/64 loss: -1.1816377639770508
Batch 17/64 loss: -0.7990245819091797
Batch 18/64 loss: -0.20956897735595703
Batch 19/64 loss: -0.6241645812988281
Batch 20/64 loss: 0.06633949279785156
Batch 21/64 loss: -1.0174951553344727
Batch 22/64 loss: -1.1893844604492188
Batch 23/64 loss: -0.8746585845947266
Batch 24/64 loss: -0.6361188888549805
Batch 25/64 loss: -1.1558952331542969
Batch 26/64 loss: -1.1365270614624023
Batch 27/64 loss: -0.5542564392089844
Batch 28/64 loss: -0.6220998764038086
Batch 29/64 loss: -0.057280540466308594
Batch 30/64 loss: -1.2631521224975586
Batch 31/64 loss: -0.3967552185058594
Batch 32/64 loss: -1.1446046829223633
Batch 33/64 loss: -1.0301504135131836
Batch 34/64 loss: -1.0691547393798828
Batch 35/64 loss: -0.9265928268432617
Batch 36/64 loss: -0.4396076202392578
Batch 37/64 loss: -0.40314531326293945
Batch 38/64 loss: -0.847407341003418
Batch 39/64 loss: -1.0012187957763672
Batch 40/64 loss: -1.1215076446533203
Batch 41/64 loss: -0.9265375137329102
Batch 42/64 loss: -0.8820629119873047
Batch 43/64 loss: -0.7033329010009766
Batch 44/64 loss: -0.5141353607177734
Batch 45/64 loss: -0.8261899948120117
Batch 46/64 loss: -0.9538536071777344
Batch 47/64 loss: -1.101536750793457
Batch 48/64 loss: -0.8214330673217773
Batch 49/64 loss: -0.536250114440918
Batch 50/64 loss: -0.4659128189086914
Batch 51/64 loss: -0.666926383972168
Batch 52/64 loss: -0.9951620101928711
Batch 53/64 loss: -0.7216873168945312
Batch 54/64 loss: -0.8929233551025391
Batch 55/64 loss: -1.043910026550293
Batch 56/64 loss: -0.6256694793701172
Batch 57/64 loss: -0.5713338851928711
Batch 58/64 loss: -1.254124641418457
Batch 59/64 loss: -0.7349834442138672
Batch 60/64 loss: -0.9340686798095703
Batch 61/64 loss: -0.89154052734375
Batch 62/64 loss: -1.0335454940795898
Batch 63/64 loss: -0.7986326217651367
Batch 64/64 loss: -5.177972793579102
Epoch 109  Train loss: -0.8833787955489814  Val loss: -0.9030306839041694
Epoch 110
-------------------------------
Batch 1/64 loss: -1.1572704315185547
Batch 2/64 loss: -0.993769645690918
Batch 3/64 loss: -0.9183597564697266
Batch 4/64 loss: -1.0951805114746094
Batch 5/64 loss: -0.7590675354003906
Batch 6/64 loss: -0.6451702117919922
Batch 7/64 loss: -1.1502294540405273
Batch 8/64 loss: -0.6959190368652344
Batch 9/64 loss: -0.9391822814941406
Batch 10/64 loss: -0.9972381591796875
Batch 11/64 loss: -0.8871364593505859
Batch 12/64 loss: -0.8525209426879883
Batch 13/64 loss: -1.0081043243408203
Batch 14/64 loss: -1.0906810760498047
Batch 15/64 loss: -0.5712051391601562
Batch 16/64 loss: -0.6129913330078125
Batch 17/64 loss: -0.6650323867797852
Batch 18/64 loss: -1.2170629501342773
Batch 19/64 loss: -0.5422868728637695
Batch 20/64 loss: -1.167353630065918
Batch 21/64 loss: -0.8565511703491211
Batch 22/64 loss: -0.9633340835571289
Batch 23/64 loss: -0.7272100448608398
Batch 24/64 loss: -1.0144538879394531
Batch 25/64 loss: -0.8617057800292969
Batch 26/64 loss: -0.9879417419433594
Batch 27/64 loss: -1.1342830657958984
Batch 28/64 loss: -0.7678260803222656
Batch 29/64 loss: -0.904109001159668
Batch 30/64 loss: -0.6856098175048828
Batch 31/64 loss: -0.5710353851318359
Batch 32/64 loss: -0.7653436660766602
Batch 33/64 loss: -0.8516941070556641
Batch 34/64 loss: -1.0161075592041016
Batch 35/64 loss: -1.1341819763183594
Batch 36/64 loss: -0.8120279312133789
Batch 37/64 loss: -0.9097080230712891
Batch 38/64 loss: -0.8346033096313477
Batch 39/64 loss: -0.8827009201049805
Batch 40/64 loss: -0.8915214538574219
Batch 41/64 loss: -0.8341541290283203
Batch 42/64 loss: -1.0949983596801758
Batch 43/64 loss: -1.2179555892944336
Batch 44/64 loss: -0.969304084777832
Batch 45/64 loss: -0.6357564926147461
Batch 46/64 loss: -0.5582275390625
Batch 47/64 loss: -0.08555936813354492
Batch 48/64 loss: -0.7531557083129883
Batch 49/64 loss: -1.1346015930175781
Batch 50/64 loss: -0.848689079284668
Batch 51/64 loss: -0.7127246856689453
Batch 52/64 loss: -0.3551902770996094
Batch 53/64 loss: -0.9075326919555664
Batch 54/64 loss: -0.9951982498168945
Batch 55/64 loss: -0.694890022277832
Batch 56/64 loss: -0.9640254974365234
Batch 57/64 loss: -1.0324811935424805
Batch 58/64 loss: -0.598475456237793
Batch 59/64 loss: -0.9792194366455078
Batch 60/64 loss: -0.7514791488647461
Batch 61/64 loss: -0.8235092163085938
Batch 62/64 loss: -1.0973405838012695
Batch 63/64 loss: -0.9102697372436523
Batch 64/64 loss: -4.539146900177002
Epoch 110  Train loss: -0.9081852464114919  Val loss: -0.97855792750198
Epoch 111
-------------------------------
Batch 1/64 loss: -1.1030044555664062
Batch 2/64 loss: -1.0397348403930664
Batch 3/64 loss: -0.9516811370849609
Batch 4/64 loss: -0.9835977554321289
Batch 5/64 loss: -1.1362676620483398
Batch 6/64 loss: -0.7885036468505859
Batch 7/64 loss: -0.24965858459472656
Batch 8/64 loss: -0.6260814666748047
Batch 9/64 loss: -1.0649738311767578
Batch 10/64 loss: -0.9549350738525391
Batch 11/64 loss: -0.6994991302490234
Batch 12/64 loss: -0.8342323303222656
Batch 13/64 loss: -0.6750278472900391
Batch 14/64 loss: -0.5863275527954102
Batch 15/64 loss: -0.8395223617553711
Batch 16/64 loss: -0.8354606628417969
Batch 17/64 loss: -0.9959230422973633
Batch 18/64 loss: -0.9015522003173828
Batch 19/64 loss: -0.6331377029418945
Batch 20/64 loss: -0.7659244537353516
Batch 21/64 loss: -0.9484214782714844
Batch 22/64 loss: -0.7678861618041992
Batch 23/64 loss: -0.7449111938476562
Batch 24/64 loss: -0.9303226470947266
Batch 25/64 loss: -0.4981870651245117
Batch 26/64 loss: -0.25969791412353516
Batch 27/64 loss: -0.5178365707397461
Batch 28/64 loss: -0.37973451614379883
Batch 29/64 loss: -0.6744222640991211
Batch 30/64 loss: -1.0134572982788086
Batch 31/64 loss: -0.4090299606323242
Batch 32/64 loss: -0.7833328247070312
Batch 33/64 loss: -0.8436403274536133
Batch 34/64 loss: -0.7289361953735352
Batch 35/64 loss: -0.5748062133789062
Batch 36/64 loss: -0.8828601837158203
Batch 37/64 loss: -0.4171609878540039
Batch 38/64 loss: -1.1856002807617188
Batch 39/64 loss: -1.0816287994384766
Batch 40/64 loss: -1.0275468826293945
Batch 41/64 loss: -0.621525764465332
Batch 42/64 loss: -0.9823970794677734
Batch 43/64 loss: -0.9904584884643555
Batch 44/64 loss: -0.9472208023071289
Batch 45/64 loss: -1.033285140991211
Batch 46/64 loss: -0.6963262557983398
Batch 47/64 loss: -0.7211952209472656
Batch 48/64 loss: -0.4167757034301758
Batch 49/64 loss: -0.5524940490722656
Batch 50/64 loss: -0.5258369445800781
Batch 51/64 loss: -1.1832151412963867
Batch 52/64 loss: -1.0257987976074219
Batch 53/64 loss: -0.7218046188354492
Batch 54/64 loss: -0.4193696975708008
Batch 55/64 loss: -1.2210283279418945
Batch 56/64 loss: -1.201624870300293
Batch 57/64 loss: -0.928131103515625
Batch 58/64 loss: -0.6227941513061523
Batch 59/64 loss: -1.0724782943725586
Batch 60/64 loss: -0.9746294021606445
Batch 61/64 loss: -0.8862123489379883
Batch 62/64 loss: -1.1497526168823242
Batch 63/64 loss: -1.041853904724121
Batch 64/64 loss: -5.058913230895996
Epoch 111  Train loss: -0.8637624964994542  Val loss: -1.0002883832479261
Epoch 112
-------------------------------
Batch 1/64 loss: -0.11262989044189453
Batch 2/64 loss: -0.976353645324707
Batch 3/64 loss: -0.9203882217407227
Batch 4/64 loss: -1.0688304901123047
Batch 5/64 loss: -0.9000024795532227
Batch 6/64 loss: -0.9860458374023438
Batch 7/64 loss: -1.0857534408569336
Batch 8/64 loss: -0.8665666580200195
Batch 9/64 loss: -0.5294227600097656
Batch 10/64 loss: -1.0942726135253906
Batch 11/64 loss: -0.7950811386108398
Batch 12/64 loss: -0.7816762924194336
Batch 13/64 loss: -0.7781801223754883
Batch 14/64 loss: -1.1595268249511719
Batch 15/64 loss: -1.1074247360229492
Batch 16/64 loss: -0.4295845031738281
Batch 17/64 loss: -1.0367984771728516
Batch 18/64 loss: -1.1468324661254883
Batch 19/64 loss: -1.3829841613769531
Batch 20/64 loss: -0.9234123229980469
Batch 21/64 loss: -0.8929328918457031
Batch 22/64 loss: -1.0385408401489258
Batch 23/64 loss: -0.8163642883300781
Batch 24/64 loss: -1.1305265426635742
Batch 25/64 loss: -1.0287599563598633
Batch 26/64 loss: -0.9264917373657227
Batch 27/64 loss: -0.6421422958374023
Batch 28/64 loss: -0.9612054824829102
Batch 29/64 loss: -0.8288946151733398
Batch 30/64 loss: -0.9843311309814453
Batch 31/64 loss: -0.8521032333374023
Batch 32/64 loss: -0.8498134613037109
Batch 33/64 loss: -0.9989147186279297
Batch 34/64 loss: -1.007939338684082
Batch 35/64 loss: -1.129237174987793
Batch 36/64 loss: -0.8257122039794922
Batch 37/64 loss: -0.9942245483398438
Batch 38/64 loss: -1.1593246459960938
Batch 39/64 loss: -0.6867179870605469
Batch 40/64 loss: -0.8108177185058594
Batch 41/64 loss: -0.7318458557128906
Batch 42/64 loss: -0.6195812225341797
Batch 43/64 loss: -0.637822151184082
Batch 44/64 loss: -1.0264301300048828
Batch 45/64 loss: -0.8171939849853516
Batch 46/64 loss: -0.9534235000610352
Batch 47/64 loss: -0.5633049011230469
Batch 48/64 loss: -0.5671262741088867
Batch 49/64 loss: -0.9912624359130859
Batch 50/64 loss: -1.2129402160644531
Batch 51/64 loss: -1.004216194152832
Batch 52/64 loss: -1.0665922164916992
Batch 53/64 loss: -0.4542074203491211
Batch 54/64 loss: -0.7352304458618164
Batch 55/64 loss: -0.8026866912841797
Batch 56/64 loss: -1.1031475067138672
Batch 57/64 loss: -0.6290178298950195
Batch 58/64 loss: -0.9447755813598633
Batch 59/64 loss: -0.9849882125854492
Batch 60/64 loss: -0.6385908126831055
Batch 61/64 loss: -0.7832813262939453
Batch 62/64 loss: -1.1571197509765625
Batch 63/64 loss: -0.9637231826782227
Batch 64/64 loss: -4.7830071449279785
Epoch 112  Train loss: -0.9352552956225826  Val loss: -1.0260904449777506
Saving best model, epoch: 112
Epoch 113
-------------------------------
Batch 1/64 loss: -1.023024559020996
Batch 2/64 loss: -0.27471065521240234
Batch 3/64 loss: -0.677739143371582
Batch 4/64 loss: -0.7509222030639648
Batch 5/64 loss: -0.6636581420898438
Batch 6/64 loss: -0.9028806686401367
Batch 7/64 loss: -0.8288688659667969
Batch 8/64 loss: -1.153055191040039
Batch 9/64 loss: -0.5175848007202148
Batch 10/64 loss: -1.2578163146972656
Batch 11/64 loss: -0.8976497650146484
Batch 12/64 loss: -0.7377805709838867
Batch 13/64 loss: -0.9769706726074219
Batch 14/64 loss: -0.7729959487915039
Batch 15/64 loss: -1.3815221786499023
Batch 16/64 loss: -0.5857276916503906
Batch 17/64 loss: -0.8977460861206055
Batch 18/64 loss: -1.1041479110717773
Batch 19/64 loss: -0.3993549346923828
Batch 20/64 loss: -1.0996770858764648
Batch 21/64 loss: -0.7528514862060547
Batch 22/64 loss: -0.8623800277709961
Batch 23/64 loss: -1.1499624252319336
Batch 24/64 loss: -0.9388084411621094
Batch 25/64 loss: -0.9859552383422852
Batch 26/64 loss: -1.020242691040039
Batch 27/64 loss: -0.7945575714111328
Batch 28/64 loss: -0.7845544815063477
Batch 29/64 loss: -1.0981683731079102
Batch 30/64 loss: -0.9476413726806641
Batch 31/64 loss: -1.0142707824707031
Batch 32/64 loss: -0.3721170425415039
Batch 33/64 loss: -0.9904928207397461
Batch 34/64 loss: -0.9034128189086914
Batch 35/64 loss: -0.657597541809082
Batch 36/64 loss: -1.2272357940673828
Batch 37/64 loss: -0.5555534362792969
Batch 38/64 loss: -0.27662086486816406
Batch 39/64 loss: -0.51531982421875
Batch 40/64 loss: -1.0916051864624023
Batch 41/64 loss: -0.8384847640991211
Batch 42/64 loss: -0.6163330078125
Batch 43/64 loss: -1.2087984085083008
Batch 44/64 loss: -0.8508815765380859
Batch 45/64 loss: -1.3689250946044922
Batch 46/64 loss: -0.9492597579956055
Batch 47/64 loss: -0.9103212356567383
Batch 48/64 loss: -0.670109748840332
Batch 49/64 loss: -1.2081537246704102
Batch 50/64 loss: -1.0166072845458984
Batch 51/64 loss: -0.8168735504150391
Batch 52/64 loss: -1.3860998153686523
Batch 53/64 loss: -1.2178287506103516
Batch 54/64 loss: -0.9735326766967773
Batch 55/64 loss: -1.0588665008544922
Batch 56/64 loss: -0.6665983200073242
Batch 57/64 loss: -0.66412353515625
Batch 58/64 loss: -1.1551380157470703
Batch 59/64 loss: -0.5012130737304688
Batch 60/64 loss: -0.879847526550293
Batch 61/64 loss: -0.6385898590087891
Batch 62/64 loss: -0.9715051651000977
Batch 63/64 loss: -1.003387451171875
Batch 64/64 loss: -4.544192314147949
Epoch 113  Train loss: -0.9227106617946251  Val loss: -0.8288643433875644
Epoch 114
-------------------------------
Batch 1/64 loss: -1.0766935348510742
Batch 2/64 loss: -0.6991024017333984
Batch 3/64 loss: -0.9332618713378906
Batch 4/64 loss: -0.9386396408081055
Batch 5/64 loss: -0.9014310836791992
Batch 6/64 loss: -0.9295673370361328
Batch 7/64 loss: -0.81182861328125
Batch 8/64 loss: -0.8690128326416016
Batch 9/64 loss: -0.7980327606201172
Batch 10/64 loss: -1.1378059387207031
Batch 11/64 loss: -0.5970697402954102
Batch 12/64 loss: -0.9088916778564453
Batch 13/64 loss: -1.0288190841674805
Batch 14/64 loss: -1.3100194931030273
Batch 15/64 loss: -0.9055442810058594
Batch 16/64 loss: -1.0281753540039062
Batch 17/64 loss: -0.61651611328125
Batch 18/64 loss: -0.5077676773071289
Batch 19/64 loss: -0.38167285919189453
Batch 20/64 loss: -0.6966381072998047
Batch 21/64 loss: -0.6151027679443359
Batch 22/64 loss: -0.28595542907714844
Batch 23/64 loss: -0.8506431579589844
Batch 24/64 loss: -0.9925756454467773
Batch 25/64 loss: -0.3988027572631836
Batch 26/64 loss: -1.077824592590332
Batch 27/64 loss: -0.9731006622314453
Batch 28/64 loss: -1.1152763366699219
Batch 29/64 loss: -0.8498811721801758
Batch 30/64 loss: -0.30075645446777344
Batch 31/64 loss: -0.7981939315795898
Batch 32/64 loss: -1.0906591415405273
Batch 33/64 loss: -0.6735363006591797
Batch 34/64 loss: -0.9534263610839844
Batch 35/64 loss: -0.6430501937866211
Batch 36/64 loss: -1.3577098846435547
Batch 37/64 loss: -0.7475957870483398
Batch 38/64 loss: -1.1590299606323242
Batch 39/64 loss: -0.9847135543823242
Batch 40/64 loss: -0.6206197738647461
Batch 41/64 loss: -0.7710113525390625
Batch 42/64 loss: -0.5364084243774414
Batch 43/64 loss: -0.6056528091430664
Batch 44/64 loss: -1.3123455047607422
Batch 45/64 loss: -0.22432899475097656
Batch 46/64 loss: -0.6081171035766602
Batch 47/64 loss: -0.981053352355957
Batch 48/64 loss: -0.9651765823364258
Batch 49/64 loss: -1.0134563446044922
Batch 50/64 loss: -0.9280433654785156
Batch 51/64 loss: -0.8763008117675781
Batch 52/64 loss: -1.0158491134643555
Batch 53/64 loss: -1.214590072631836
Batch 54/64 loss: -1.3000249862670898
Batch 55/64 loss: -0.8849515914916992
Batch 56/64 loss: -0.8574399948120117
Batch 57/64 loss: -0.7646560668945312
Batch 58/64 loss: -0.8811502456665039
Batch 59/64 loss: -1.0363702774047852
Batch 60/64 loss: -1.1507186889648438
Batch 61/64 loss: -0.9728727340698242
Batch 62/64 loss: -1.0252799987792969
Batch 63/64 loss: -0.9723930358886719
Batch 64/64 loss: -4.568838596343994
Epoch 114  Train loss: -0.9080747398675657  Val loss: -0.9297027850069132
Epoch 115
-------------------------------
Batch 1/64 loss: -1.154658317565918
Batch 2/64 loss: -0.8099737167358398
Batch 3/64 loss: -0.6822681427001953
Batch 4/64 loss: -0.6175260543823242
Batch 5/64 loss: -0.8548669815063477
Batch 6/64 loss: -0.3561983108520508
Batch 7/64 loss: -0.8014984130859375
Batch 8/64 loss: -1.0079889297485352
Batch 9/64 loss: -0.811981201171875
Batch 10/64 loss: -0.9835634231567383
Batch 11/64 loss: -1.0921258926391602
Batch 12/64 loss: -0.7324333190917969
Batch 13/64 loss: -0.9074811935424805
Batch 14/64 loss: -0.9608469009399414
Batch 15/64 loss: -1.0636663436889648
Batch 16/64 loss: -0.9299898147583008
Batch 17/64 loss: -0.8666887283325195
Batch 18/64 loss: -1.139688491821289
Batch 19/64 loss: -0.8333940505981445
Batch 20/64 loss: -0.5683774948120117
Batch 21/64 loss: -0.6064233779907227
Batch 22/64 loss: -0.5713624954223633
Batch 23/64 loss: -0.7240705490112305
Batch 24/64 loss: -0.8680076599121094
Batch 25/64 loss: -0.39803314208984375
Batch 26/64 loss: -0.9485511779785156
Batch 27/64 loss: -0.9791393280029297
Batch 28/64 loss: -0.7516679763793945
Batch 29/64 loss: -0.6916427612304688
Batch 30/64 loss: -0.679255485534668
Batch 31/64 loss: -0.9345541000366211
Batch 32/64 loss: -0.9937839508056641
Batch 33/64 loss: -0.9223785400390625
Batch 34/64 loss: -1.1695375442504883
Batch 35/64 loss: -1.0764408111572266
Batch 36/64 loss: -1.0671377182006836
Batch 37/64 loss: -0.746373176574707
Batch 38/64 loss: -0.8988656997680664
Batch 39/64 loss: -0.5467739105224609
Batch 40/64 loss: -0.7295646667480469
Batch 41/64 loss: -1.026031494140625
Batch 42/64 loss: -0.866485595703125
Batch 43/64 loss: -0.5207118988037109
Batch 44/64 loss: -0.6509990692138672
Batch 45/64 loss: -0.9257221221923828
Batch 46/64 loss: -0.8551397323608398
Batch 47/64 loss: -0.4398174285888672
Batch 48/64 loss: -0.667633056640625
Batch 49/64 loss: -0.7957754135131836
Batch 50/64 loss: -0.6721735000610352
Batch 51/64 loss: -1.1344966888427734
Batch 52/64 loss: -1.0141639709472656
Batch 53/64 loss: -0.9246482849121094
Batch 54/64 loss: -1.0227699279785156
Batch 55/64 loss: -0.8875722885131836
Batch 56/64 loss: -0.5846385955810547
Batch 57/64 loss: -0.9096012115478516
Batch 58/64 loss: -0.9086647033691406
Batch 59/64 loss: -1.1639947891235352
Batch 60/64 loss: -1.1178522109985352
Batch 61/64 loss: -0.7732629776000977
Batch 62/64 loss: -0.7422246932983398
Batch 63/64 loss: -1.2262954711914062
Batch 64/64 loss: -4.459875583648682
Epoch 115  Train loss: -0.888695868323831  Val loss: -1.0720348161520417
Saving best model, epoch: 115
Epoch 116
-------------------------------
Batch 1/64 loss: -0.7201719284057617
Batch 2/64 loss: -0.8009023666381836
Batch 3/64 loss: -0.7684030532836914
Batch 4/64 loss: -0.8834466934204102
Batch 5/64 loss: -1.0410385131835938
Batch 6/64 loss: -0.7315464019775391
Batch 7/64 loss: -1.0322093963623047
Batch 8/64 loss: -0.4616222381591797
Batch 9/64 loss: -0.9931650161743164
Batch 10/64 loss: -0.09727001190185547
Batch 11/64 loss: -0.7798328399658203
Batch 12/64 loss: -1.326298713684082
Batch 13/64 loss: -0.9559993743896484
Batch 14/64 loss: -0.75048828125
Batch 15/64 loss: -1.1069021224975586
Batch 16/64 loss: -1.2819328308105469
Batch 17/64 loss: -1.1655397415161133
Batch 18/64 loss: -0.9757289886474609
Batch 19/64 loss: -1.0337753295898438
Batch 20/64 loss: -0.9384298324584961
Batch 21/64 loss: -0.9444704055786133
Batch 22/64 loss: -0.9493322372436523
Batch 23/64 loss: -1.0335378646850586
Batch 24/64 loss: -0.6107139587402344
Batch 25/64 loss: -0.8641700744628906
Batch 26/64 loss: -0.8023643493652344
Batch 27/64 loss: -1.0766115188598633
Batch 28/64 loss: -0.8578166961669922
Batch 29/64 loss: -1.1120147705078125
Batch 30/64 loss: -0.8523492813110352
Batch 31/64 loss: -1.0559368133544922
Batch 32/64 loss: -0.9294376373291016
Batch 33/64 loss: -1.1139039993286133
Batch 34/64 loss: -0.3208198547363281
Batch 35/64 loss: -0.8209009170532227
Batch 36/64 loss: -1.0952072143554688
Batch 37/64 loss: -0.8996419906616211
Batch 38/64 loss: -1.0893802642822266
Batch 39/64 loss: -0.9568576812744141
Batch 40/64 loss: -1.0222053527832031
Batch 41/64 loss: -1.1625022888183594
Batch 42/64 loss: -0.8117580413818359
Batch 43/64 loss: -1.0789165496826172
Batch 44/64 loss: -0.7955760955810547
Batch 45/64 loss: -0.7129077911376953
Batch 46/64 loss: -0.9656963348388672
Batch 47/64 loss: -1.0949344635009766
Batch 48/64 loss: -1.044851303100586
Batch 49/64 loss: -0.909489631652832
Batch 50/64 loss: -0.788783073425293
Batch 51/64 loss: -0.8269834518432617
Batch 52/64 loss: -0.4458799362182617
Batch 53/64 loss: -1.0041542053222656
Batch 54/64 loss: -0.5983991622924805
Batch 55/64 loss: -1.0492115020751953
Batch 56/64 loss: -0.7672300338745117
Batch 57/64 loss: -0.8683767318725586
Batch 58/64 loss: -0.8945817947387695
Batch 59/64 loss: -0.9895172119140625
Batch 60/64 loss: -0.6611461639404297
Batch 61/64 loss: -1.1268882751464844
Batch 62/64 loss: -0.8164405822753906
Batch 63/64 loss: -0.6916370391845703
Batch 64/64 loss: -4.857071399688721
Epoch 116  Train loss: -0.9411928120781393  Val loss: -0.9881188828510927
Epoch 117
-------------------------------
Batch 1/64 loss: -0.5886507034301758
Batch 2/64 loss: -1.2526779174804688
Batch 3/64 loss: -0.6724205017089844
Batch 4/64 loss: -0.9239730834960938
Batch 5/64 loss: -0.7639532089233398
Batch 6/64 loss: -0.6300077438354492
Batch 7/64 loss: -1.1904563903808594
Batch 8/64 loss: -0.9578170776367188
Batch 9/64 loss: -0.9888515472412109
Batch 10/64 loss: -0.7965555191040039
Batch 11/64 loss: -0.5020771026611328
Batch 12/64 loss: -1.122793197631836
Batch 13/64 loss: -1.0323238372802734
Batch 14/64 loss: -1.116302490234375
Batch 15/64 loss: -1.2295255661010742
Batch 16/64 loss: -1.0346717834472656
Batch 17/64 loss: -0.7403087615966797
Batch 18/64 loss: -1.0056304931640625
Batch 19/64 loss: -0.9201173782348633
Batch 20/64 loss: -0.7440280914306641
Batch 21/64 loss: -1.0182743072509766
Batch 22/64 loss: -0.8663101196289062
Batch 23/64 loss: -0.7933149337768555
Batch 24/64 loss: -0.5920124053955078
Batch 25/64 loss: -0.7030391693115234
Batch 26/64 loss: -0.8976478576660156
Batch 27/64 loss: -0.6340703964233398
Batch 28/64 loss: -1.0028448104858398
Batch 29/64 loss: -0.8020315170288086
Batch 30/64 loss: -0.8937740325927734
Batch 31/64 loss: -0.43840885162353516
Batch 32/64 loss: -0.8087301254272461
Batch 33/64 loss: -0.9609642028808594
Batch 34/64 loss: -0.5543031692504883
Batch 35/64 loss: -0.8923845291137695
Batch 36/64 loss: -0.806640625
Batch 37/64 loss: -0.7386417388916016
Batch 38/64 loss: -0.612030029296875
Batch 39/64 loss: -0.9801874160766602
Batch 40/64 loss: -0.8527097702026367
Batch 41/64 loss: -1.1190223693847656
Batch 42/64 loss: -1.0059328079223633
Batch 43/64 loss: -0.6488380432128906
Batch 44/64 loss: -0.6762752532958984
Batch 45/64 loss: -1.100564956665039
Batch 46/64 loss: -0.8411617279052734
Batch 47/64 loss: -0.8111743927001953
Batch 48/64 loss: -0.6414127349853516
Batch 49/64 loss: -1.2585878372192383
Batch 50/64 loss: -0.9732913970947266
Batch 51/64 loss: -1.1451168060302734
Batch 52/64 loss: -1.0853080749511719
Batch 53/64 loss: -0.7698822021484375
Batch 54/64 loss: -0.8043622970581055
Batch 55/64 loss: -1.0519142150878906
Batch 56/64 loss: -1.2266530990600586
Batch 57/64 loss: -0.8045625686645508
Batch 58/64 loss: -1.2405939102172852
Batch 59/64 loss: -0.9580307006835938
Batch 60/64 loss: -0.9711265563964844
Batch 61/64 loss: -1.0205049514770508
Batch 62/64 loss: -0.7162971496582031
Batch 63/64 loss: -0.9475479125976562
Batch 64/64 loss: -4.975064277648926
Epoch 117  Train loss: -0.9350732952940698  Val loss: -0.9923930872756591
Epoch 118
-------------------------------
Batch 1/64 loss: -0.9540481567382812
Batch 2/64 loss: -1.0790739059448242
Batch 3/64 loss: -1.1074542999267578
Batch 4/64 loss: -0.47036075592041016
Batch 5/64 loss: -0.9721174240112305
Batch 6/64 loss: -0.9008064270019531
Batch 7/64 loss: -0.5922117233276367
Batch 8/64 loss: -0.7604217529296875
Batch 9/64 loss: -0.8891992568969727
Batch 10/64 loss: -0.8723478317260742
Batch 11/64 loss: -1.0480079650878906
Batch 12/64 loss: -1.010359764099121
Batch 13/64 loss: -0.5769548416137695
Batch 14/64 loss: -0.6183795928955078
Batch 15/64 loss: -1.1278152465820312
Batch 16/64 loss: -1.1784582138061523
Batch 17/64 loss: -0.9225358963012695
Batch 18/64 loss: -1.146162986755371
Batch 19/64 loss: -0.595362663269043
Batch 20/64 loss: -0.7994546890258789
Batch 21/64 loss: -0.5319595336914062
Batch 22/64 loss: -0.8955955505371094
Batch 23/64 loss: -0.8589458465576172
Batch 24/64 loss: -0.6514654159545898
Batch 25/64 loss: -0.7176923751831055
Batch 26/64 loss: -0.8272609710693359
Batch 27/64 loss: -0.821965217590332
Batch 28/64 loss: -1.0512161254882812
Batch 29/64 loss: -1.0609369277954102
Batch 30/64 loss: -0.6958122253417969
Batch 31/64 loss: -0.8943843841552734
Batch 32/64 loss: -1.1249570846557617
Batch 33/64 loss: -1.075531005859375
Batch 34/64 loss: -0.6381006240844727
Batch 35/64 loss: -0.6304845809936523
Batch 36/64 loss: -0.6929006576538086
Batch 37/64 loss: -1.0013713836669922
Batch 38/64 loss: -0.8615226745605469
Batch 39/64 loss: -1.1780023574829102
Batch 40/64 loss: -0.48494911193847656
Batch 41/64 loss: -0.8089637756347656
Batch 42/64 loss: -0.7538232803344727
Batch 43/64 loss: -0.3499565124511719
Batch 44/64 loss: -0.7991485595703125
Batch 45/64 loss: -0.5522832870483398
Batch 46/64 loss: -0.9608573913574219
Batch 47/64 loss: -0.9292078018188477
Batch 48/64 loss: -0.9646291732788086
Batch 49/64 loss: -0.7158899307250977
Batch 50/64 loss: -0.961395263671875
Batch 51/64 loss: -0.6149625778198242
Batch 52/64 loss: -0.8585872650146484
Batch 53/64 loss: -0.9173860549926758
Batch 54/64 loss: -1.1622133255004883
Batch 55/64 loss: -0.9801607131958008
Batch 56/64 loss: -0.9764919281005859
Batch 57/64 loss: -0.6398277282714844
Batch 58/64 loss: -0.7868366241455078
Batch 59/64 loss: -0.6987676620483398
Batch 60/64 loss: -0.8130340576171875
Batch 61/64 loss: -1.0471277236938477
Batch 62/64 loss: -1.0506248474121094
Batch 63/64 loss: -1.0890378952026367
Batch 64/64 loss: -4.915492057800293
Epoch 118  Train loss: -0.9009320763980642  Val loss: -0.9581307873283464
Epoch 119
-------------------------------
Batch 1/64 loss: -0.850071907043457
Batch 2/64 loss: -1.278275489807129
Batch 3/64 loss: -1.088007926940918
Batch 4/64 loss: -0.8315868377685547
Batch 5/64 loss: -0.7318849563598633
Batch 6/64 loss: -0.6130943298339844
Batch 7/64 loss: -0.3400993347167969
Batch 8/64 loss: -0.6530265808105469
Batch 9/64 loss: -1.0734004974365234
Batch 10/64 loss: -0.6406450271606445
Batch 11/64 loss: -0.9586915969848633
Batch 12/64 loss: -0.7950029373168945
Batch 13/64 loss: -1.1700668334960938
Batch 14/64 loss: -0.7909326553344727
Batch 15/64 loss: -1.1288423538208008
Batch 16/64 loss: -1.1478500366210938
Batch 17/64 loss: -0.9408750534057617
Batch 18/64 loss: -0.49019336700439453
Batch 19/64 loss: -0.6226921081542969
Batch 20/64 loss: -0.9813785552978516
Batch 21/64 loss: -0.4718303680419922
Batch 22/64 loss: -0.8207416534423828
Batch 23/64 loss: -0.6421651840209961
Batch 24/64 loss: -0.9975690841674805
Batch 25/64 loss: -1.186793327331543
Batch 26/64 loss: -0.8746414184570312
Batch 27/64 loss: -0.7309856414794922
Batch 28/64 loss: -0.6980724334716797
Batch 29/64 loss: -0.7250137329101562
Batch 30/64 loss: -1.3562383651733398
Batch 31/64 loss: -1.0685148239135742
Batch 32/64 loss: -0.9934005737304688
Batch 33/64 loss: -0.5632772445678711
Batch 34/64 loss: -0.9800910949707031
Batch 35/64 loss: -0.910222053527832
Batch 36/64 loss: -1.0653886795043945
Batch 37/64 loss: -1.1275262832641602
Batch 38/64 loss: -0.46763038635253906
Batch 39/64 loss: -0.4418630599975586
Batch 40/64 loss: -0.6545801162719727
Batch 41/64 loss: -0.7303657531738281
Batch 42/64 loss: -1.0555553436279297
Batch 43/64 loss: -0.7925205230712891
Batch 44/64 loss: -1.0968255996704102
Batch 45/64 loss: -0.7011995315551758
Batch 46/64 loss: -1.1850671768188477
Batch 47/64 loss: -0.952794075012207
Batch 48/64 loss: -0.8865032196044922
Batch 49/64 loss: -0.8191118240356445
Batch 50/64 loss: -0.6585474014282227
Batch 51/64 loss: -0.8253030776977539
Batch 52/64 loss: -0.9114875793457031
Batch 53/64 loss: -0.8450069427490234
Batch 54/64 loss: -1.0609636306762695
Batch 55/64 loss: -0.6856784820556641
Batch 56/64 loss: -1.061997413635254
Batch 57/64 loss: -0.8275375366210938
Batch 58/64 loss: -1.1144084930419922
Batch 59/64 loss: -1.0217866897583008
Batch 60/64 loss: -0.7218246459960938
Batch 61/64 loss: -1.1368227005004883
Batch 62/64 loss: -0.9437227249145508
Batch 63/64 loss: -0.7302961349487305
Batch 64/64 loss: -4.904384136199951
Epoch 119  Train loss: -0.9152435845019771  Val loss: -1.0732891567793907
Saving best model, epoch: 119
Epoch 120
-------------------------------
Batch 1/64 loss: -1.129953384399414
Batch 2/64 loss: -0.6803789138793945
Batch 3/64 loss: -0.8478069305419922
Batch 4/64 loss: -1.0265932083129883
Batch 5/64 loss: -0.8617963790893555
Batch 6/64 loss: -0.5982198715209961
Batch 7/64 loss: -1.0754508972167969
Batch 8/64 loss: -1.1894245147705078
Batch 9/64 loss: -0.9701461791992188
Batch 10/64 loss: -0.4929323196411133
Batch 11/64 loss: -0.34183502197265625
Batch 12/64 loss: -0.9791183471679688
Batch 13/64 loss: -0.5072393417358398
Batch 14/64 loss: -0.8440341949462891
Batch 15/64 loss: -1.0574541091918945
Batch 16/64 loss: -0.8058719635009766
Batch 17/64 loss: -0.4492816925048828
Batch 18/64 loss: -0.5915470123291016
Batch 19/64 loss: -0.7777080535888672
Batch 20/64 loss: -0.578608512878418
Batch 21/64 loss: -0.8192167282104492
Batch 22/64 loss: -0.8414115905761719
Batch 23/64 loss: -0.9642848968505859
Batch 24/64 loss: -0.8165512084960938
Batch 25/64 loss: -0.28179359436035156
Batch 26/64 loss: -1.1916675567626953
Batch 27/64 loss: -0.7611055374145508
Batch 28/64 loss: -0.8539876937866211
Batch 29/64 loss: -0.7110509872436523
Batch 30/64 loss: -0.8036222457885742
Batch 31/64 loss: -0.7567033767700195
Batch 32/64 loss: -0.7801904678344727
Batch 33/64 loss: -0.8578367233276367
Batch 34/64 loss: -1.1377267837524414
Batch 35/64 loss: -0.6309328079223633
Batch 36/64 loss: -1.1383495330810547
Batch 37/64 loss: -1.3624801635742188
Batch 38/64 loss: -0.6121253967285156
Batch 39/64 loss: -0.2539682388305664
Batch 40/64 loss: -0.7949600219726562
Batch 41/64 loss: -0.5092334747314453
Batch 42/64 loss: -0.7789773941040039
Batch 43/64 loss: -1.0543346405029297
Batch 44/64 loss: -1.0018129348754883
Batch 45/64 loss: -0.8818788528442383
Batch 46/64 loss: -0.7662448883056641
Batch 47/64 loss: -0.9917135238647461
Batch 48/64 loss: -0.7140026092529297
Batch 49/64 loss: -0.5318670272827148
Batch 50/64 loss: -0.7535638809204102
Batch 51/64 loss: -0.7625417709350586
Batch 52/64 loss: -0.9100236892700195
Batch 53/64 loss: -0.8148069381713867
Batch 54/64 loss: -1.3077049255371094
Batch 55/64 loss: -0.8982582092285156
Batch 56/64 loss: -0.4882802963256836
Batch 57/64 loss: -0.9917173385620117
Batch 58/64 loss: -0.7967300415039062
Batch 59/64 loss: -0.7740869522094727
Batch 60/64 loss: -0.8093662261962891
Batch 61/64 loss: -1.0570716857910156
Batch 62/64 loss: -0.7910604476928711
Batch 63/64 loss: -1.3699531555175781
Batch 64/64 loss: -5.250868797302246
Epoch 120  Train loss: -0.8763725318160711  Val loss: -1.0069477304150558
Epoch 121
-------------------------------
Batch 1/64 loss: -0.6511807441711426
Batch 2/64 loss: -0.8611850738525391
Batch 3/64 loss: -0.9949016571044922
Batch 4/64 loss: -1.0999364852905273
Batch 5/64 loss: -1.1368274688720703
Batch 6/64 loss: -0.8631448745727539
Batch 7/64 loss: -0.9152650833129883
Batch 8/64 loss: -0.7212400436401367
Batch 9/64 loss: -0.37755393981933594
Batch 10/64 loss: -1.0174493789672852
Batch 11/64 loss: -1.1023931503295898
Batch 12/64 loss: -0.9071884155273438
Batch 13/64 loss: -0.5211696624755859
Batch 14/64 loss: -0.4220762252807617
Batch 15/64 loss: -0.9977216720581055
Batch 16/64 loss: -0.9829654693603516
Batch 17/64 loss: -1.0766801834106445
Batch 18/64 loss: -0.5562191009521484
Batch 19/64 loss: -0.011393547058105469
Batch 20/64 loss: -0.4252195358276367
Batch 21/64 loss: -0.46774768829345703
Batch 22/64 loss: -1.1382951736450195
Batch 23/64 loss: -0.7832651138305664
Batch 24/64 loss: -0.8020954132080078
Batch 25/64 loss: -1.0267009735107422
Batch 26/64 loss: -0.9305553436279297
Batch 27/64 loss: -0.6597614288330078
Batch 28/64 loss: -0.29156017303466797
Batch 29/64 loss: -1.0520210266113281
Batch 30/64 loss: -0.9872703552246094
Batch 31/64 loss: -0.6833820343017578
Batch 32/64 loss: -0.9384822845458984
Batch 33/64 loss: -0.96826171875
Batch 34/64 loss: -0.6552133560180664
Batch 35/64 loss: -0.9301090240478516
Batch 36/64 loss: -0.8276681900024414
Batch 37/64 loss: -1.1347789764404297
Batch 38/64 loss: -1.163813591003418
Batch 39/64 loss: -0.8670406341552734
Batch 40/64 loss: -1.0138511657714844
Batch 41/64 loss: -0.6744213104248047
Batch 42/64 loss: -1.1358747482299805
Batch 43/64 loss: -0.8987541198730469
Batch 44/64 loss: -1.0359230041503906
Batch 45/64 loss: -0.7577886581420898
Batch 46/64 loss: -1.2734460830688477
Batch 47/64 loss: -0.9078159332275391
Batch 48/64 loss: -0.9615621566772461
Batch 49/64 loss: -0.9919919967651367
Batch 50/64 loss: -0.5144252777099609
Batch 51/64 loss: -0.6425600051879883
Batch 52/64 loss: -1.335317611694336
Batch 53/64 loss: -0.8513393402099609
Batch 54/64 loss: -0.9829912185668945
Batch 55/64 loss: -1.054779052734375
Batch 56/64 loss: -1.1789321899414062
Batch 57/64 loss: -0.6657600402832031
Batch 58/64 loss: -1.2170438766479492
Batch 59/64 loss: -1.161301612854004
Batch 60/64 loss: -1.045304298400879
Batch 61/64 loss: -0.9533710479736328
Batch 62/64 loss: -0.9743585586547852
Batch 63/64 loss: -0.6091690063476562
Batch 64/64 loss: -4.207204818725586
Epoch 121  Train loss: -0.908913257075291  Val loss: -0.7769161368563413
Epoch 122
-------------------------------
Batch 1/64 loss: -1.0580778121948242
Batch 2/64 loss: -1.110036849975586
Batch 3/64 loss: -0.4289979934692383
Batch 4/64 loss: -0.6858997344970703
Batch 5/64 loss: -0.9448204040527344
Batch 6/64 loss: -0.8609914779663086
Batch 7/64 loss: -0.7088680267333984
Batch 8/64 loss: -1.18463134765625
Batch 9/64 loss: -0.6662817001342773
Batch 10/64 loss: -1.018239974975586
Batch 11/64 loss: -1.1508092880249023
Batch 12/64 loss: -0.9099531173706055
Batch 13/64 loss: -0.7297286987304688
Batch 14/64 loss: -0.5099935531616211
Batch 15/64 loss: -0.9806861877441406
Batch 16/64 loss: -1.3781909942626953
Batch 17/64 loss: -0.9113473892211914
Batch 18/64 loss: -0.9070234298706055
Batch 19/64 loss: -0.7583246231079102
Batch 20/64 loss: -1.062173843383789
Batch 21/64 loss: -0.9393558502197266
Batch 22/64 loss: -0.7116241455078125
Batch 23/64 loss: -0.5961732864379883
Batch 24/64 loss: -1.110417366027832
Batch 25/64 loss: -0.9363222122192383
Batch 26/64 loss: 0.045418739318847656
Batch 27/64 loss: -0.9146175384521484
Batch 28/64 loss: -1.1022396087646484
Batch 29/64 loss: 0.05528068542480469
Batch 30/64 loss: -1.0712270736694336
Batch 31/64 loss: -1.0047941207885742
Batch 32/64 loss: -0.8088579177856445
Batch 33/64 loss: -1.1908636093139648
Batch 34/64 loss: -0.9810237884521484
Batch 35/64 loss: -0.648991584777832
Batch 36/64 loss: -1.003000259399414
Batch 37/64 loss: -0.9171209335327148
Batch 38/64 loss: -0.9370594024658203
Batch 39/64 loss: -0.8720207214355469
Batch 40/64 loss: -0.7395706176757812
Batch 41/64 loss: -1.0064468383789062
Batch 42/64 loss: -0.6998462677001953
Batch 43/64 loss: -0.93743896484375
Batch 44/64 loss: -0.9245195388793945
Batch 45/64 loss: -0.8267030715942383
Batch 46/64 loss: -0.9419260025024414
Batch 47/64 loss: -0.9785890579223633
Batch 48/64 loss: -1.0485496520996094
Batch 49/64 loss: -0.9403238296508789
Batch 50/64 loss: -1.0669317245483398
Batch 51/64 loss: -0.8296957015991211
Batch 52/64 loss: -0.3335132598876953
Batch 53/64 loss: -1.1842279434204102
Batch 54/64 loss: -1.0224285125732422
Batch 55/64 loss: -0.5807352066040039
Batch 56/64 loss: -1.1629266738891602
Batch 57/64 loss: -0.7351884841918945
Batch 58/64 loss: -0.9881525039672852
Batch 59/64 loss: -0.8781194686889648
Batch 60/64 loss: -0.9240303039550781
Batch 61/64 loss: -1.0623369216918945
Batch 62/64 loss: -0.9183235168457031
Batch 63/64 loss: -0.8185110092163086
Batch 64/64 loss: -4.790798664093018
Epoch 122  Train loss: -0.921603459002925  Val loss: -0.8913633208913901
Epoch 123
-------------------------------
Batch 1/64 loss: -0.6833219528198242
Batch 2/64 loss: -0.9528512954711914
Batch 3/64 loss: -1.0219593048095703
Batch 4/64 loss: -0.672245979309082
Batch 5/64 loss: -0.8814935684204102
Batch 6/64 loss: -1.0877418518066406
Batch 7/64 loss: -0.44770145416259766
Batch 8/64 loss: -0.5926790237426758
Batch 9/64 loss: -0.6573247909545898
Batch 10/64 loss: -0.9461212158203125
Batch 11/64 loss: -0.9033899307250977
Batch 12/64 loss: -0.7337284088134766
Batch 13/64 loss: -0.751399040222168
Batch 14/64 loss: -0.950775146484375
Batch 15/64 loss: -0.800440788269043
Batch 16/64 loss: -0.4669780731201172
Batch 17/64 loss: -1.152512550354004
Batch 18/64 loss: -1.1196775436401367
Batch 19/64 loss: -1.117685317993164
Batch 20/64 loss: -0.8924808502197266
Batch 21/64 loss: -1.0983695983886719
Batch 22/64 loss: -1.2351398468017578
Batch 23/64 loss: -1.138962745666504
Batch 24/64 loss: -0.9470815658569336
Batch 25/64 loss: -0.8867988586425781
Batch 26/64 loss: -1.2782058715820312
Batch 27/64 loss: -1.0315361022949219
Batch 28/64 loss: -1.216750144958496
Batch 29/64 loss: -0.46854400634765625
Batch 30/64 loss: -1.1001319885253906
Batch 31/64 loss: -0.7282295227050781
Batch 32/64 loss: -0.8327617645263672
Batch 33/64 loss: -1.0224075317382812
Batch 34/64 loss: -0.875701904296875
Batch 35/64 loss: -0.749506950378418
Batch 36/64 loss: -1.2425575256347656
Batch 37/64 loss: -0.703948974609375
Batch 38/64 loss: -0.8390350341796875
Batch 39/64 loss: -1.1692047119140625
Batch 40/64 loss: -0.6796360015869141
Batch 41/64 loss: -1.252945899963379
Batch 42/64 loss: -1.1077375411987305
Batch 43/64 loss: -1.0660943984985352
Batch 44/64 loss: -0.7679986953735352
Batch 45/64 loss: -0.8336982727050781
Batch 46/64 loss: -1.042027473449707
Batch 47/64 loss: -0.9756927490234375
Batch 48/64 loss: -1.0875663757324219
Batch 49/64 loss: -1.1221609115600586
Batch 50/64 loss: -1.0839309692382812
Batch 51/64 loss: -1.1637401580810547
Batch 52/64 loss: -1.2671442031860352
Batch 53/64 loss: -1.0805702209472656
Batch 54/64 loss: -0.8350839614868164
Batch 55/64 loss: -0.47238731384277344
Batch 56/64 loss: -1.0360240936279297
Batch 57/64 loss: -0.7857913970947266
Batch 58/64 loss: -1.256394386291504
Batch 59/64 loss: -0.8539953231811523
Batch 60/64 loss: -1.0584325790405273
Batch 61/64 loss: -0.6231870651245117
Batch 62/64 loss: -0.6986970901489258
Batch 63/64 loss: -0.6287498474121094
Batch 64/64 loss: -4.966188430786133
Epoch 123  Train loss: -0.9710072311700559  Val loss: -1.011059567690715
Epoch 124
-------------------------------
Batch 1/64 loss: -1.3272829055786133
Batch 2/64 loss: -0.9038009643554688
Batch 3/64 loss: -0.9127569198608398
Batch 4/64 loss: -0.9774017333984375
Batch 5/64 loss: -0.9629850387573242
Batch 6/64 loss: -0.41400146484375
Batch 7/64 loss: -0.8541774749755859
Batch 8/64 loss: -0.7271451950073242
Batch 9/64 loss: -1.1736326217651367
Batch 10/64 loss: -1.3259973526000977
Batch 11/64 loss: -0.8462200164794922
Batch 12/64 loss: -0.9781770706176758
Batch 13/64 loss: -1.1708307266235352
Batch 14/64 loss: -0.754664421081543
Batch 15/64 loss: -0.7954015731811523
Batch 16/64 loss: -1.1668071746826172
Batch 17/64 loss: -0.7358694076538086
Batch 18/64 loss: -0.5638933181762695
Batch 19/64 loss: -1.1795649528503418
Batch 20/64 loss: -0.9519500732421875
Batch 21/64 loss: -0.949127197265625
Batch 22/64 loss: -1.1278343200683594
Batch 23/64 loss: -1.171330451965332
Batch 24/64 loss: -1.3677797317504883
Batch 25/64 loss: -0.869720458984375
Batch 26/64 loss: -1.1210908889770508
Batch 27/64 loss: -0.8027124404907227
Batch 28/64 loss: -0.8628463745117188
Batch 29/64 loss: -0.6576175689697266
Batch 30/64 loss: -1.0187139511108398
Batch 31/64 loss: -0.9063949584960938
Batch 32/64 loss: -0.8989162445068359
Batch 33/64 loss: -0.7104310989379883
Batch 34/64 loss: -1.1965560913085938
Batch 35/64 loss: -1.150045394897461
Batch 36/64 loss: -1.2091522216796875
Batch 37/64 loss: -1.3049163818359375
Batch 38/64 loss: -0.8029289245605469
Batch 39/64 loss: -0.9852533340454102
Batch 40/64 loss: -1.0453767776489258
Batch 41/64 loss: -0.9980497360229492
Batch 42/64 loss: -0.9156827926635742
Batch 43/64 loss: -0.89593505859375
Batch 44/64 loss: -1.1744565963745117
Batch 45/64 loss: -0.8289670944213867
Batch 46/64 loss: -1.0549993515014648
Batch 47/64 loss: -0.9640703201293945
Batch 48/64 loss: -1.064310073852539
Batch 49/64 loss: -0.8299694061279297
Batch 50/64 loss: -0.5989103317260742
Batch 51/64 loss: -0.8084745407104492
Batch 52/64 loss: -0.7683200836181641
Batch 53/64 loss: -0.9514493942260742
Batch 54/64 loss: -0.8457393646240234
Batch 55/64 loss: -0.8152561187744141
Batch 56/64 loss: -1.0532150268554688
Batch 57/64 loss: -1.0112075805664062
Batch 58/64 loss: -1.1115140914916992
Batch 59/64 loss: -1.5064573287963867
Batch 60/64 loss: -0.7738265991210938
Batch 61/64 loss: -1.2544794082641602
Batch 62/64 loss: -0.67572021484375
Batch 63/64 loss: -0.8604354858398438
Batch 64/64 loss: -4.648062705993652
Epoch 124  Train loss: -1.0059419332766066  Val loss: -1.0275024335408949
Epoch 125
-------------------------------
Batch 1/64 loss: -0.9668655395507812
Batch 2/64 loss: -1.1911439895629883
Batch 3/64 loss: -1.104701042175293
Batch 4/64 loss: -1.0872716903686523
Batch 5/64 loss: -0.86895751953125
Batch 6/64 loss: -0.8035116195678711
Batch 7/64 loss: -1.1528701782226562
Batch 8/64 loss: -0.8208341598510742
Batch 9/64 loss: -0.717686653137207
Batch 10/64 loss: -1.1803503036499023
Batch 11/64 loss: -0.9530744552612305
Batch 12/64 loss: -0.8287324905395508
Batch 13/64 loss: -0.9022598266601562
Batch 14/64 loss: -1.180227279663086
Batch 15/64 loss: -0.509739875793457
Batch 16/64 loss: -1.3927078247070312
Batch 17/64 loss: -0.8123407363891602
Batch 18/64 loss: -1.0702667236328125
Batch 19/64 loss: -1.2616186141967773
Batch 20/64 loss: -0.7615337371826172
Batch 21/64 loss: -1.3487539291381836
Batch 22/64 loss: -1.1789007186889648
Batch 23/64 loss: -1.401742935180664
Batch 24/64 loss: -1.2799043655395508
Batch 25/64 loss: -1.1552839279174805
Batch 26/64 loss: -1.1891803741455078
Batch 27/64 loss: -0.4810523986816406
Batch 28/64 loss: -0.6576824188232422
Batch 29/64 loss: -0.859074592590332
Batch 30/64 loss: -1.374359130859375
Batch 31/64 loss: -0.9420623779296875
Batch 32/64 loss: -0.7176551818847656
Batch 33/64 loss: -0.7090415954589844
Batch 34/64 loss: -1.287348747253418
Batch 35/64 loss: -0.6608943939208984
Batch 36/64 loss: -1.1014738082885742
Batch 37/64 loss: -1.1045007705688477
Batch 38/64 loss: -0.9793901443481445
Batch 39/64 loss: -1.31475830078125
Batch 40/64 loss: -0.9183168411254883
Batch 41/64 loss: -0.6858196258544922
Batch 42/64 loss: -1.0166692733764648
Batch 43/64 loss: -0.7941560745239258
Batch 44/64 loss: -1.0994577407836914
Batch 45/64 loss: -1.099595069885254
Batch 46/64 loss: -1.0701398849487305
Batch 47/64 loss: -0.7089757919311523
Batch 48/64 loss: -0.8970508575439453
Batch 49/64 loss: -1.2763710021972656
Batch 50/64 loss: -1.0664005279541016
Batch 51/64 loss: -0.809478759765625
Batch 52/64 loss: -0.7656335830688477
Batch 53/64 loss: -0.6309566497802734
Batch 54/64 loss: -1.3102712631225586
Batch 55/64 loss: -0.8211307525634766
Batch 56/64 loss: -0.8072395324707031
Batch 57/64 loss: -0.9674663543701172
Batch 58/64 loss: -0.9285497665405273
Batch 59/64 loss: -0.4730796813964844
Batch 60/64 loss: -1.214700698852539
Batch 61/64 loss: -0.7193975448608398
Batch 62/64 loss: -1.2825212478637695
Batch 63/64 loss: -1.319157600402832
Batch 64/64 loss: -5.143487453460693
Epoch 125  Train loss: -1.0329397033242618  Val loss: -1.1092085690842461
Saving best model, epoch: 125
Epoch 126
-------------------------------
Batch 1/64 loss: -0.6332292556762695
Batch 2/64 loss: -0.7885980606079102
Batch 3/64 loss: -1.1781187057495117
Batch 4/64 loss: -1.0969305038452148
Batch 5/64 loss: -1.061680793762207
Batch 6/64 loss: -1.3216066360473633
Batch 7/64 loss: -0.7919473648071289
Batch 8/64 loss: -0.6191253662109375
Batch 9/64 loss: -1.2017755508422852
Batch 10/64 loss: -1.0791168212890625
Batch 11/64 loss: -0.6135177612304688
Batch 12/64 loss: -0.5395584106445312
Batch 13/64 loss: -0.6202802658081055
Batch 14/64 loss: -1.022841453552246
Batch 15/64 loss: -0.893183708190918
Batch 16/64 loss: -1.214127540588379
Batch 17/64 loss: -1.0891523361206055
Batch 18/64 loss: -1.1473159790039062
Batch 19/64 loss: -1.3253355026245117
Batch 20/64 loss: -1.069657325744629
Batch 21/64 loss: -1.1298255920410156
Batch 22/64 loss: -1.122147560119629
Batch 23/64 loss: -0.5352096557617188
Batch 24/64 loss: -0.4326486587524414
Batch 25/64 loss: -1.1413135528564453
Batch 26/64 loss: -0.8287954330444336
Batch 27/64 loss: -0.9660730361938477
Batch 28/64 loss: -1.0503969192504883
Batch 29/64 loss: -0.8512516021728516
Batch 30/64 loss: -0.9012861251831055
Batch 31/64 loss: -0.823455810546875
Batch 32/64 loss: -0.6314888000488281
Batch 33/64 loss: -1.1972379684448242
Batch 34/64 loss: -0.9757223129272461
Batch 35/64 loss: -1.181502342224121
Batch 36/64 loss: -0.8416299819946289
Batch 37/64 loss: -0.7386445999145508
Batch 38/64 loss: -0.9310941696166992
Batch 39/64 loss: -1.2492198944091797
Batch 40/64 loss: -0.6861400604248047
Batch 41/64 loss: -1.0021905899047852
Batch 42/64 loss: -1.096466064453125
Batch 43/64 loss: -0.9417572021484375
Batch 44/64 loss: -1.113992691040039
Batch 45/64 loss: -1.0280961990356445
Batch 46/64 loss: -1.4043636322021484
Batch 47/64 loss: -1.234323501586914
Batch 48/64 loss: -1.0265560150146484
Batch 49/64 loss: -1.3025102615356445
Batch 50/64 loss: -0.41889190673828125
Batch 51/64 loss: -0.3726654052734375
Batch 52/64 loss: -1.4578704833984375
Batch 53/64 loss: -1.039414405822754
Batch 54/64 loss: -1.0412225723266602
Batch 55/64 loss: -1.0883712768554688
Batch 56/64 loss: -1.4186735153198242
Batch 57/64 loss: -0.7381982803344727
Batch 58/64 loss: -0.7096481323242188
Batch 59/64 loss: -0.8935632705688477
Batch 60/64 loss: -1.1091184616088867
Batch 61/64 loss: -0.6246433258056641
Batch 62/64 loss: -1.1173133850097656
Batch 63/64 loss: -1.0162792205810547
Batch 64/64 loss: -5.1221513748168945
Epoch 126  Train loss: -1.0127047333062864  Val loss: -1.0935605104846233
Epoch 127
-------------------------------
Batch 1/64 loss: -1.0053653717041016
Batch 2/64 loss: -1.2420234680175781
Batch 3/64 loss: -0.6299324035644531
Batch 4/64 loss: -0.7200431823730469
Batch 5/64 loss: -1.01446533203125
Batch 6/64 loss: -1.295517921447754
Batch 7/64 loss: -1.0233745574951172
Batch 8/64 loss: -1.0258960723876953
Batch 9/64 loss: -1.1857290267944336
Batch 10/64 loss: -0.6307964324951172
Batch 11/64 loss: -0.28583812713623047
Batch 12/64 loss: -0.819025993347168
Batch 13/64 loss: -0.8010549545288086
Batch 14/64 loss: -1.0944738388061523
Batch 15/64 loss: -1.0142335891723633
Batch 16/64 loss: -0.1363544464111328
Batch 17/64 loss: -0.9300622940063477
Batch 18/64 loss: -0.20861434936523438
Batch 19/64 loss: -1.077981948852539
Batch 20/64 loss: -0.7781171798706055
Batch 21/64 loss: -0.9274482727050781
Batch 22/64 loss: -1.0008745193481445
Batch 23/64 loss: -0.8121051788330078
Batch 24/64 loss: -1.1835708618164062
Batch 25/64 loss: -0.967310905456543
Batch 26/64 loss: -0.9259681701660156
Batch 27/64 loss: -0.9255447387695312
Batch 28/64 loss: -0.9820880889892578
Batch 29/64 loss: -0.999079704284668
Batch 30/64 loss: -1.1495037078857422
Batch 31/64 loss: -0.9825553894042969
Batch 32/64 loss: -1.1579771041870117
Batch 33/64 loss: -0.8141279220581055
Batch 34/64 loss: -0.7442531585693359
Batch 35/64 loss: -0.5799636840820312
Batch 36/64 loss: -1.0517644882202148
Batch 37/64 loss: -1.2654037475585938
Batch 38/64 loss: -1.023636817932129
Batch 39/64 loss: -1.1739540100097656
Batch 40/64 loss: -0.9475622177124023
Batch 41/64 loss: -0.9779386520385742
Batch 42/64 loss: -1.3988037109375
Batch 43/64 loss: -1.4225683212280273
Batch 44/64 loss: -0.971440315246582
Batch 45/64 loss: -0.6037359237670898
Batch 46/64 loss: -1.3123226165771484
Batch 47/64 loss: -0.9979009628295898
Batch 48/64 loss: -0.5932216644287109
Batch 49/64 loss: -0.9572525024414062
Batch 50/64 loss: -1.3510513305664062
Batch 51/64 loss: -1.389246940612793
Batch 52/64 loss: -0.873906135559082
Batch 53/64 loss: -0.8901576995849609
Batch 54/64 loss: -0.5448112487792969
Batch 55/64 loss: -1.1669464111328125
Batch 56/64 loss: -0.44390201568603516
Batch 57/64 loss: -1.2349319458007812
Batch 58/64 loss: -0.9061870574951172
Batch 59/64 loss: -0.9522333145141602
Batch 60/64 loss: -1.2965526580810547
Batch 61/64 loss: -0.6492700576782227
Batch 62/64 loss: -1.1673097610473633
Batch 63/64 loss: -1.173579216003418
Batch 64/64 loss: -5.0119805335998535
Epoch 127  Train loss: -0.9971427300397088  Val loss: -1.0912512946374637
Epoch 128
-------------------------------
Batch 1/64 loss: -0.6818246841430664
Batch 2/64 loss: -0.4950532913208008
Batch 3/64 loss: -1.1892328262329102
Batch 4/64 loss: -1.1847095489501953
Batch 5/64 loss: -0.91741943359375
Batch 6/64 loss: -0.843785285949707
Batch 7/64 loss: -0.8525810241699219
Batch 8/64 loss: -0.8178205490112305
Batch 9/64 loss: -1.0584192276000977
Batch 10/64 loss: -0.6739072799682617
Batch 11/64 loss: -0.5298986434936523
Batch 12/64 loss: -1.1668195724487305
Batch 13/64 loss: -1.1520490646362305
Batch 14/64 loss: -1.3147525787353516
Batch 15/64 loss: -1.0096921920776367
Batch 16/64 loss: -0.9857196807861328
Batch 17/64 loss: -0.2802896499633789
Batch 18/64 loss: -1.0220861434936523
Batch 19/64 loss: -0.9713678359985352
Batch 20/64 loss: -0.7415828704833984
Batch 21/64 loss: -0.7679691314697266
Batch 22/64 loss: -1.1747026443481445
Batch 23/64 loss: -1.0100440979003906
Batch 24/64 loss: -1.0545272827148438
Batch 25/64 loss: -0.8917579650878906
Batch 26/64 loss: -0.9646053314208984
Batch 27/64 loss: -1.0302667617797852
Batch 28/64 loss: -0.9616079330444336
Batch 29/64 loss: -0.8705883026123047
Batch 30/64 loss: -0.7895307540893555
Batch 31/64 loss: -1.2241735458374023
Batch 32/64 loss: -0.9949188232421875
Batch 33/64 loss: -0.740900993347168
Batch 34/64 loss: -0.8063478469848633
Batch 35/64 loss: -0.6106014251708984
Batch 36/64 loss: -1.1340999603271484
Batch 37/64 loss: -1.0616579055786133
Batch 38/64 loss: -0.9448308944702148
Batch 39/64 loss: -1.0982837677001953
Batch 40/64 loss: -1.211507797241211
Batch 41/64 loss: -1.1263151168823242
Batch 42/64 loss: -1.2541570663452148
Batch 43/64 loss: -0.9656705856323242
Batch 44/64 loss: -0.39861297607421875
Batch 45/64 loss: -0.30640602111816406
Batch 46/64 loss: -0.7689390182495117
Batch 47/64 loss: -1.1453590393066406
Batch 48/64 loss: -1.194167137145996
Batch 49/64 loss: -1.1859521865844727
Batch 50/64 loss: -1.085972785949707
Batch 51/64 loss: -0.9971609115600586
Batch 52/64 loss: -0.9181499481201172
Batch 53/64 loss: -0.8878641128540039
Batch 54/64 loss: -0.6741962432861328
Batch 55/64 loss: -0.5490074157714844
Batch 56/64 loss: -0.7223720550537109
Batch 57/64 loss: -0.7854642868041992
Batch 58/64 loss: -0.8736038208007812
Batch 59/64 loss: -0.8179168701171875
Batch 60/64 loss: -0.6551733016967773
Batch 61/64 loss: -1.1838302612304688
Batch 62/64 loss: -0.8796405792236328
Batch 63/64 loss: -1.0517873764038086
Batch 64/64 loss: -5.030083179473877
Epoch 128  Train loss: -0.9636426046782849  Val loss: -1.060333553458407
Epoch 129
-------------------------------
Batch 1/64 loss: -0.974492073059082
Batch 2/64 loss: -0.6898946762084961
Batch 3/64 loss: -1.1527481079101562
Batch 4/64 loss: -1.0560522079467773
Batch 5/64 loss: -0.7173805236816406
Batch 6/64 loss: -1.1382923126220703
Batch 7/64 loss: -1.034083366394043
Batch 8/64 loss: -0.9953880310058594
Batch 9/64 loss: -1.1972265243530273
Batch 10/64 loss: -1.101384162902832
Batch 11/64 loss: -1.2730045318603516
Batch 12/64 loss: -1.4469366073608398
Batch 13/64 loss: -1.0460758209228516
Batch 14/64 loss: -0.4004192352294922
Batch 15/64 loss: -0.7234888076782227
Batch 16/64 loss: -0.941584587097168
Batch 17/64 loss: -0.6988859176635742
Batch 18/64 loss: -1.2467632293701172
Batch 19/64 loss: -0.8281488418579102
Batch 20/64 loss: -1.0742874145507812
Batch 21/64 loss: -1.0017776489257812
Batch 22/64 loss: -1.193497657775879
Batch 23/64 loss: -1.2503986358642578
Batch 24/64 loss: -1.0775518417358398
Batch 25/64 loss: -1.1032800674438477
Batch 26/64 loss: -1.0164060592651367
Batch 27/64 loss: -0.7877464294433594
Batch 28/64 loss: -1.1612625122070312
Batch 29/64 loss: -0.8967523574829102
Batch 30/64 loss: -1.3386287689208984
Batch 31/64 loss: -0.7408447265625
Batch 32/64 loss: -1.0041313171386719
Batch 33/64 loss: -0.41770362854003906
Batch 34/64 loss: -0.9741973876953125
Batch 35/64 loss: -0.8545627593994141
Batch 36/64 loss: -1.199387550354004
Batch 37/64 loss: -0.9992866516113281
Batch 38/64 loss: -0.9369583129882812
Batch 39/64 loss: -1.1644115447998047
Batch 40/64 loss: -1.2198429107666016
Batch 41/64 loss: -0.7544870376586914
Batch 42/64 loss: -0.8686628341674805
Batch 43/64 loss: -1.0044326782226562
Batch 44/64 loss: -0.9218463897705078
Batch 45/64 loss: -0.7526607513427734
Batch 46/64 loss: -1.2571821212768555
Batch 47/64 loss: -0.2912168502807617
Batch 48/64 loss: -0.6360006332397461
Batch 49/64 loss: -0.9585781097412109
Batch 50/64 loss: -1.112471580505371
Batch 51/64 loss: -0.9756879806518555
Batch 52/64 loss: -0.42381858825683594
Batch 53/64 loss: -1.0248279571533203
Batch 54/64 loss: -1.032292366027832
Batch 55/64 loss: -0.6001205444335938
Batch 56/64 loss: -0.9444293975830078
Batch 57/64 loss: -0.9548664093017578
Batch 58/64 loss: -1.1562280654907227
Batch 59/64 loss: -0.6848745346069336
Batch 60/64 loss: -1.265472412109375
Batch 61/64 loss: -0.8587322235107422
Batch 62/64 loss: -0.8238000869750977
Batch 63/64 loss: -0.7596035003662109
Batch 64/64 loss: -4.324082851409912
Epoch 129  Train loss: -0.9942042500365014  Val loss: -1.1039824862660412
Epoch 130
-------------------------------
Batch 1/64 loss: -1.0219335556030273
Batch 2/64 loss: -1.0543928146362305
Batch 3/64 loss: -1.3275279998779297
Batch 4/64 loss: -1.2588186264038086
Batch 5/64 loss: -1.2974834442138672
Batch 6/64 loss: -1.2924480438232422
Batch 7/64 loss: -0.7289543151855469
Batch 8/64 loss: -0.4071779251098633
Batch 9/64 loss: -1.3978242874145508
Batch 10/64 loss: -1.0148200988769531
Batch 11/64 loss: -1.3320178985595703
Batch 12/64 loss: -1.1591053009033203
Batch 13/64 loss: -0.7722816467285156
Batch 14/64 loss: -0.8158884048461914
Batch 15/64 loss: -1.1637191772460938
Batch 16/64 loss: -0.9438180923461914
Batch 17/64 loss: -1.1079645156860352
Batch 18/64 loss: -1.0961456298828125
Batch 19/64 loss: -1.079808235168457
Batch 20/64 loss: -0.8762521743774414
Batch 21/64 loss: -1.1421804428100586
Batch 22/64 loss: -0.531557559967041
Batch 23/64 loss: -1.044041633605957
Batch 24/64 loss: -0.6295366287231445
Batch 25/64 loss: -1.100743293762207
Batch 26/64 loss: -1.0417795181274414
Batch 27/64 loss: -0.8995599746704102
Batch 28/64 loss: -0.6969003677368164
Batch 29/64 loss: -1.2620649337768555
Batch 30/64 loss: -0.6841049194335938
Batch 31/64 loss: -0.8840541839599609
Batch 32/64 loss: -1.2265710830688477
Batch 33/64 loss: -1.1129894256591797
Batch 34/64 loss: -1.0941162109375
Batch 35/64 loss: -1.1502628326416016
Batch 36/64 loss: -0.8649711608886719
Batch 37/64 loss: -1.0669918060302734
Batch 38/64 loss: -1.0948467254638672
Batch 39/64 loss: -1.1041021347045898
Batch 40/64 loss: -0.8858699798583984
Batch 41/64 loss: -1.0139217376708984
Batch 42/64 loss: -0.6649951934814453
Batch 43/64 loss: -0.7350149154663086
Batch 44/64 loss: -0.7523880004882812
Batch 45/64 loss: -0.8594160079956055
Batch 46/64 loss: -0.12717151641845703
Batch 47/64 loss: -0.8025941848754883
Batch 48/64 loss: -0.6465721130371094
Batch 49/64 loss: -0.8082294464111328
Batch 50/64 loss: -1.2185001373291016
Batch 51/64 loss: -1.0737743377685547
Batch 52/64 loss: -1.4405946731567383
Batch 53/64 loss: -1.118642807006836
Batch 54/64 loss: -1.1557044982910156
Batch 55/64 loss: -0.9970073699951172
Batch 56/64 loss: -1.1998462677001953
Batch 57/64 loss: -1.1912097930908203
Batch 58/64 loss: -0.7833147048950195
Batch 59/64 loss: -1.1068410873413086
Batch 60/64 loss: -1.068507194519043
Batch 61/64 loss: -0.8668661117553711
Batch 62/64 loss: -0.4575328826904297
Batch 63/64 loss: -0.32906532287597656
Batch 64/64 loss: -4.799330711364746
Epoch 130  Train loss: -1.0146327112235276  Val loss: -1.053643085702588
Epoch 131
-------------------------------
Batch 1/64 loss: -0.6231822967529297
Batch 2/64 loss: -1.418349266052246
Batch 3/64 loss: -0.9917240142822266
Batch 4/64 loss: -0.8628501892089844
Batch 5/64 loss: -1.3105812072753906
Batch 6/64 loss: -1.3286895751953125
Batch 7/64 loss: -0.9102745056152344
Batch 8/64 loss: -1.2834320068359375
Batch 9/64 loss: -1.3298702239990234
Batch 10/64 loss: -1.0911569595336914
Batch 11/64 loss: -0.7496681213378906
Batch 12/64 loss: -0.9176473617553711
Batch 13/64 loss: -0.8616886138916016
Batch 14/64 loss: -0.36895751953125
Batch 15/64 loss: -0.5783119201660156
Batch 16/64 loss: -1.1414794921875
Batch 17/64 loss: -0.9596004486083984
Batch 18/64 loss: -1.139967918395996
Batch 19/64 loss: -1.105351448059082
Batch 20/64 loss: -0.8634233474731445
Batch 21/64 loss: -0.7484540939331055
Batch 22/64 loss: -0.9817008972167969
Batch 23/64 loss: -0.18296146392822266
Batch 24/64 loss: -1.000432014465332
Batch 25/64 loss: -1.246774673461914
Batch 26/64 loss: -1.099259376525879
Batch 27/64 loss: -1.387868881225586
Batch 28/64 loss: -0.9829044342041016
Batch 29/64 loss: -0.8066091537475586
Batch 30/64 loss: -1.0149908065795898
Batch 31/64 loss: -1.3186073303222656
Batch 32/64 loss: -1.0316410064697266
Batch 33/64 loss: -0.5329961776733398
Batch 34/64 loss: -1.2574081420898438
Batch 35/64 loss: -0.9923782348632812
Batch 36/64 loss: -1.1980667114257812
Batch 37/64 loss: -0.9509248733520508
Batch 38/64 loss: -0.8861608505249023
Batch 39/64 loss: -0.9404592514038086
Batch 40/64 loss: -0.31265830993652344
Batch 41/64 loss: -0.6967639923095703
Batch 42/64 loss: -0.45729923248291016
Batch 43/64 loss: -1.147679328918457
Batch 44/64 loss: -1.389512062072754
Batch 45/64 loss: -1.1733293533325195
Batch 46/64 loss: -1.0962343215942383
Batch 47/64 loss: -1.2712984085083008
Batch 48/64 loss: -1.2695283889770508
Batch 49/64 loss: -1.0629377365112305
Batch 50/64 loss: -1.0867462158203125
Batch 51/64 loss: -1.3133306503295898
Batch 52/64 loss: -1.1197500228881836
Batch 53/64 loss: -0.8366556167602539
Batch 54/64 loss: -0.6742134094238281
Batch 55/64 loss: -1.0793647766113281
Batch 56/64 loss: -1.3250322341918945
Batch 57/64 loss: -0.5463542938232422
Batch 58/64 loss: -0.8454656600952148
Batch 59/64 loss: -0.9185609817504883
Batch 60/64 loss: -0.8436555862426758
Batch 61/64 loss: -1.2349157333374023
Batch 62/64 loss: -1.0857353210449219
Batch 63/64 loss: -0.9518404006958008
Batch 64/64 loss: -4.647433280944824
Epoch 131  Train loss: -1.0293528126735314  Val loss: -1.1006422665520632
Epoch 132
-------------------------------
Batch 1/64 loss: -1.0707874298095703
Batch 2/64 loss: -0.8094654083251953
Batch 3/64 loss: -1.124258041381836
Batch 4/64 loss: -1.1856327056884766
Batch 5/64 loss: -0.8441009521484375
Batch 6/64 loss: -0.9149675369262695
Batch 7/64 loss: -1.1553964614868164
Batch 8/64 loss: -0.6499061584472656
Batch 9/64 loss: -0.7663545608520508
Batch 10/64 loss: -1.2883520126342773
Batch 11/64 loss: -0.8372802734375
Batch 12/64 loss: -1.1863231658935547
Batch 13/64 loss: -1.0074777603149414
Batch 14/64 loss: -1.4392566680908203
Batch 15/64 loss: -0.6951007843017578
Batch 16/64 loss: -0.7086315155029297
Batch 17/64 loss: -0.8568134307861328
Batch 18/64 loss: -0.7761316299438477
Batch 19/64 loss: -1.1648311614990234
Batch 20/64 loss: -1.2523126602172852
Batch 21/64 loss: -1.2446575164794922
Batch 22/64 loss: -1.0805015563964844
Batch 23/64 loss: -1.3235702514648438
Batch 24/64 loss: -1.1513948440551758
Batch 25/64 loss: -1.0402641296386719
Batch 26/64 loss: -1.1666851043701172
Batch 27/64 loss: -1.151749610900879
Batch 28/64 loss: -0.8970632553100586
Batch 29/64 loss: -0.7830619812011719
Batch 30/64 loss: -0.8301706314086914
Batch 31/64 loss: -1.038564682006836
Batch 32/64 loss: -0.9649181365966797
Batch 33/64 loss: -1.102865219116211
Batch 34/64 loss: -1.2327470779418945
Batch 35/64 loss: -1.3042488098144531
Batch 36/64 loss: -1.0438518524169922
Batch 37/64 loss: -0.9073066711425781
Batch 38/64 loss: -1.0351495742797852
Batch 39/64 loss: -1.0461416244506836
Batch 40/64 loss: -0.9348382949829102
Batch 41/64 loss: -1.205526351928711
Batch 42/64 loss: -0.7752199172973633
Batch 43/64 loss: -0.5945205688476562
Batch 44/64 loss: -1.1331167221069336
Batch 45/64 loss: -0.8905878067016602
Batch 46/64 loss: -0.8651208877563477
Batch 47/64 loss: -1.2240924835205078
Batch 48/64 loss: -1.138432502746582
Batch 49/64 loss: -0.9451456069946289
Batch 50/64 loss: -1.1942424774169922
Batch 51/64 loss: -0.9943094253540039
Batch 52/64 loss: -0.5012235641479492
Batch 53/64 loss: -1.2998685836791992
Batch 54/64 loss: -0.6108922958374023
Batch 55/64 loss: -0.9225263595581055
Batch 56/64 loss: -0.998316764831543
Batch 57/64 loss: -0.6068048477172852
Batch 58/64 loss: -1.060896873474121
Batch 59/64 loss: -0.4676084518432617
Batch 60/64 loss: -1.0186223983764648
Batch 61/64 loss: -0.9596786499023438
Batch 62/64 loss: -0.9180974960327148
Batch 63/64 loss: -0.8372459411621094
Batch 64/64 loss: -5.039862155914307
Epoch 132  Train loss: -1.034590191934623  Val loss: -0.9565647164570916
Epoch 133
-------------------------------
Batch 1/64 loss: -1.033158302307129
Batch 2/64 loss: -1.1838655471801758
Batch 3/64 loss: -1.2159490585327148
Batch 4/64 loss: -0.9031000137329102
Batch 5/64 loss: -0.7311944961547852
Batch 6/64 loss: -1.06231689453125
Batch 7/64 loss: -1.069009780883789
Batch 8/64 loss: -1.1789350509643555
Batch 9/64 loss: -1.0920944213867188
Batch 10/64 loss: -0.9513702392578125
Batch 11/64 loss: -1.1739654541015625
Batch 12/64 loss: -1.0297765731811523
Batch 13/64 loss: -1.0065803527832031
Batch 14/64 loss: -1.2165184020996094
Batch 15/64 loss: -1.209519386291504
Batch 16/64 loss: -1.3907136917114258
Batch 17/64 loss: -1.1866989135742188
Batch 18/64 loss: -1.0016555786132812
Batch 19/64 loss: -1.4398612976074219
Batch 20/64 loss: -1.4056644439697266
Batch 21/64 loss: -0.9114627838134766
Batch 22/64 loss: -1.2608880996704102
Batch 23/64 loss: -1.0878572463989258
Batch 24/64 loss: -0.8595314025878906
Batch 25/64 loss: -0.8311986923217773
Batch 26/64 loss: -1.253199577331543
Batch 27/64 loss: -0.9512853622436523
Batch 28/64 loss: -0.9565029144287109
Batch 29/64 loss: -0.9896574020385742
Batch 30/64 loss: -0.9607343673706055
Batch 31/64 loss: -0.7287826538085938
Batch 32/64 loss: -1.0394554138183594
Batch 33/64 loss: -0.9805879592895508
Batch 34/64 loss: -0.9899444580078125
Batch 35/64 loss: -0.7180967330932617
Batch 36/64 loss: -1.0396032333374023
Batch 37/64 loss: -1.2575883865356445
Batch 38/64 loss: -1.0187368392944336
Batch 39/64 loss: -0.9734554290771484
Batch 40/64 loss: -1.3025665283203125
Batch 41/64 loss: -0.4502420425415039
Batch 42/64 loss: -0.8286819458007812
Batch 43/64 loss: -0.9650516510009766
Batch 44/64 loss: -0.723602294921875
Batch 45/64 loss: -0.9804439544677734
Batch 46/64 loss: -0.6619110107421875
Batch 47/64 loss: -1.1114816665649414
Batch 48/64 loss: -1.0918941497802734
Batch 49/64 loss: -0.9951353073120117
Batch 50/64 loss: -1.2468528747558594
Batch 51/64 loss: -1.0583553314208984
Batch 52/64 loss: -1.2110328674316406
Batch 53/64 loss: -1.0644598007202148
Batch 54/64 loss: -0.7340545654296875
Batch 55/64 loss: -1.121516227722168
Batch 56/64 loss: -1.159536361694336
Batch 57/64 loss: -0.9336357116699219
Batch 58/64 loss: -1.2858819961547852
Batch 59/64 loss: -0.5464515686035156
Batch 60/64 loss: -1.294651985168457
Batch 61/64 loss: -1.0526189804077148
Batch 62/64 loss: -1.1887083053588867
Batch 63/64 loss: -0.8181781768798828
Batch 64/64 loss: -4.646894454956055
Epoch 133  Train loss: -1.0761197333242378  Val loss: -1.2398987996209527
Saving best model, epoch: 133
Epoch 134
-------------------------------
Batch 1/64 loss: -1.1184778213500977
Batch 2/64 loss: -1.2148160934448242
Batch 3/64 loss: -1.1915712356567383
Batch 4/64 loss: -0.7761468887329102
Batch 5/64 loss: -1.0882673263549805
Batch 6/64 loss: -0.9023170471191406
Batch 7/64 loss: -1.1612129211425781
Batch 8/64 loss: -0.9860820770263672
Batch 9/64 loss: -0.9996557235717773
Batch 10/64 loss: -0.8460683822631836
Batch 11/64 loss: -1.1076335906982422
Batch 12/64 loss: -1.0469646453857422
Batch 13/64 loss: -0.978022575378418
Batch 14/64 loss: -1.3821754455566406
Batch 15/64 loss: -0.9574384689331055
Batch 16/64 loss: -0.9649362564086914
Batch 17/64 loss: -0.5423784255981445
Batch 18/64 loss: -1.2855510711669922
Batch 19/64 loss: -0.9504423141479492
Batch 20/64 loss: -0.9835538864135742
Batch 21/64 loss: -1.1137924194335938
Batch 22/64 loss: -0.8249359130859375
Batch 23/64 loss: -1.268998146057129
Batch 24/64 loss: -0.9069509506225586
Batch 25/64 loss: -1.0895576477050781
Batch 26/64 loss: -0.7434444427490234
Batch 27/64 loss: -0.8128528594970703
Batch 28/64 loss: -1.0034770965576172
Batch 29/64 loss: -1.1290264129638672
Batch 30/64 loss: -0.8110361099243164
Batch 31/64 loss: -1.079096794128418
Batch 32/64 loss: -1.2041044235229492
Batch 33/64 loss: -0.6117973327636719
Batch 34/64 loss: -0.5788860321044922
Batch 35/64 loss: -1.3106498718261719
Batch 36/64 loss: -1.10205078125
Batch 37/64 loss: -1.1607904434204102
Batch 38/64 loss: -0.8709716796875
Batch 39/64 loss: -1.09295654296875
Batch 40/64 loss: -1.005523681640625
Batch 41/64 loss: -1.3752002716064453
Batch 42/64 loss: -1.4143409729003906
Batch 43/64 loss: -1.1052837371826172
Batch 44/64 loss: -0.9628582000732422
Batch 45/64 loss: -0.7403469085693359
Batch 46/64 loss: -1.0764694213867188
Batch 47/64 loss: -1.250814437866211
Batch 48/64 loss: -0.8442535400390625
Batch 49/64 loss: -1.274423599243164
Batch 50/64 loss: -1.0005149841308594
Batch 51/64 loss: -1.0930280685424805
Batch 52/64 loss: -0.8241147994995117
Batch 53/64 loss: -0.9808053970336914
Batch 54/64 loss: -1.2276840209960938
Batch 55/64 loss: -0.900700569152832
Batch 56/64 loss: -0.9720487594604492
Batch 57/64 loss: -1.2454509735107422
Batch 58/64 loss: -1.0068178176879883
Batch 59/64 loss: -0.8504228591918945
Batch 60/64 loss: -1.011946678161621
Batch 61/64 loss: -1.3077421188354492
Batch 62/64 loss: -1.1005678176879883
Batch 63/64 loss: -1.5242300033569336
Batch 64/64 loss: -4.796111106872559
Epoch 134  Train loss: -1.08065507552203  Val loss: -1.1152726923886853
Epoch 135
-------------------------------
Batch 1/64 loss: -0.6165904998779297
Batch 2/64 loss: -1.2823171615600586
Batch 3/64 loss: -1.0757169723510742
Batch 4/64 loss: -0.8001012802124023
Batch 5/64 loss: -0.7770986557006836
Batch 6/64 loss: -1.08197021484375
Batch 7/64 loss: -0.8910055160522461
Batch 8/64 loss: -1.0349149703979492
Batch 9/64 loss: -1.254526138305664
Batch 10/64 loss: -0.8693056106567383
Batch 11/64 loss: -1.0865116119384766
Batch 12/64 loss: -1.1196784973144531
Batch 13/64 loss: -0.8745269775390625
Batch 14/64 loss: -0.7891340255737305
Batch 15/64 loss: -0.5686283111572266
Batch 16/64 loss: -0.9711599349975586
Batch 17/64 loss: -0.9604625701904297
Batch 18/64 loss: -1.193467140197754
Batch 19/64 loss: -1.268296241760254
Batch 20/64 loss: -0.7717084884643555
Batch 21/64 loss: -1.3542547225952148
Batch 22/64 loss: -1.181532859802246
Batch 23/64 loss: -0.8799524307250977
Batch 24/64 loss: -1.243551254272461
Batch 25/64 loss: -1.1860160827636719
Batch 26/64 loss: -1.054011344909668
Batch 27/64 loss: -0.7237033843994141
Batch 28/64 loss: -1.2135648727416992
Batch 29/64 loss: -1.081827163696289
Batch 30/64 loss: -0.8456554412841797
Batch 31/64 loss: -1.2267446517944336
Batch 32/64 loss: -1.106797218322754
Batch 33/64 loss: -0.8168668746948242
Batch 34/64 loss: -0.9406509399414062
Batch 35/64 loss: -1.2981719970703125
Batch 36/64 loss: -0.6838054656982422
Batch 37/64 loss: -1.0007429122924805
Batch 38/64 loss: -1.2096242904663086
Batch 39/64 loss: -1.1336383819580078
Batch 40/64 loss: -0.9195384979248047
Batch 41/64 loss: -0.6738672256469727
Batch 42/64 loss: -1.3738250732421875
Batch 43/64 loss: -1.1916751861572266
Batch 44/64 loss: -0.8944778442382812
Batch 45/64 loss: -1.256216049194336
Batch 46/64 loss: -1.159419059753418
Batch 47/64 loss: -0.8296775817871094
Batch 48/64 loss: -1.2025108337402344
Batch 49/64 loss: -1.154012680053711
Batch 50/64 loss: -1.4924402236938477
Batch 51/64 loss: -1.2857208251953125
Batch 52/64 loss: -1.2024297714233398
Batch 53/64 loss: -0.6234102249145508
Batch 54/64 loss: -1.065058708190918
Batch 55/64 loss: -1.291961669921875
Batch 56/64 loss: -0.5847978591918945
Batch 57/64 loss: -1.0555400848388672
Batch 58/64 loss: -1.0851211547851562
Batch 59/64 loss: -1.2491750717163086
Batch 60/64 loss: -1.1653594970703125
Batch 61/64 loss: -1.2097978591918945
Batch 62/64 loss: -1.088334083557129
Batch 63/64 loss: -0.9367847442626953
Batch 64/64 loss: -5.67739200592041
Epoch 135  Train loss: -1.0936067281984816  Val loss: -1.1621029254087467
Epoch 136
-------------------------------
Batch 1/64 loss: -0.8363971710205078
Batch 2/64 loss: -1.088181495666504
Batch 3/64 loss: -0.7403154373168945
Batch 4/64 loss: -1.407334327697754
Batch 5/64 loss: -0.8988828659057617
Batch 6/64 loss: -1.2219362258911133
Batch 7/64 loss: -1.0884637832641602
Batch 8/64 loss: -1.080179214477539
Batch 9/64 loss: -1.3925600051879883
Batch 10/64 loss: -1.1944684982299805
Batch 11/64 loss: -1.2112407684326172
Batch 12/64 loss: -0.6854448318481445
Batch 13/64 loss: -1.2273931503295898
Batch 14/64 loss: -1.370905876159668
Batch 15/64 loss: -0.8388242721557617
Batch 16/64 loss: -0.5798110961914062
Batch 17/64 loss: -1.2053146362304688
Batch 18/64 loss: -0.9869108200073242
Batch 19/64 loss: -1.0225181579589844
Batch 20/64 loss: -1.1795320510864258
Batch 21/64 loss: -1.0503053665161133
Batch 22/64 loss: -0.9698724746704102
Batch 23/64 loss: -0.8609867095947266
Batch 24/64 loss: -1.143178939819336
Batch 25/64 loss: -1.160654067993164
Batch 26/64 loss: -0.9750089645385742
Batch 27/64 loss: -0.6372718811035156
Batch 28/64 loss: -0.6546726226806641
Batch 29/64 loss: -1.1600522994995117
Batch 30/64 loss: -1.1456670761108398
Batch 31/64 loss: -0.7637691497802734
Batch 32/64 loss: -0.5875234603881836
Batch 33/64 loss: -0.9108295440673828
Batch 34/64 loss: -1.3445024490356445
Batch 35/64 loss: -1.2157011032104492
Batch 36/64 loss: -1.1092748641967773
Batch 37/64 loss: -0.9160213470458984
Batch 38/64 loss: -0.637202262878418
Batch 39/64 loss: -0.41907787322998047
Batch 40/64 loss: -1.1663684844970703
Batch 41/64 loss: -0.7126188278198242
Batch 42/64 loss: -1.0279245376586914
Batch 43/64 loss: -0.9325313568115234
Batch 44/64 loss: -1.5457534790039062
Batch 45/64 loss: -1.2332220077514648
Batch 46/64 loss: -1.1761388778686523
Batch 47/64 loss: -1.3180389404296875
Batch 48/64 loss: -1.0970630645751953
Batch 49/64 loss: -0.9340333938598633
Batch 50/64 loss: -0.7709770202636719
Batch 51/64 loss: -1.5454273223876953
Batch 52/64 loss: -1.1654529571533203
Batch 53/64 loss: -1.308701515197754
Batch 54/64 loss: -1.054718017578125
Batch 55/64 loss: -1.312483787536621
Batch 56/64 loss: -0.7958898544311523
Batch 57/64 loss: -1.0623607635498047
Batch 58/64 loss: -1.1867008209228516
Batch 59/64 loss: -1.0631208419799805
Batch 60/64 loss: -0.9865264892578125
Batch 61/64 loss: -0.6809005737304688
Batch 62/64 loss: -0.3722038269042969
Batch 63/64 loss: -0.8595457077026367
Batch 64/64 loss: -5.395140171051025
Epoch 136  Train loss: -1.0709528586443733  Val loss: -1.184580747204548
Epoch 137
-------------------------------
Batch 1/64 loss: -0.7507333755493164
Batch 2/64 loss: -1.257223129272461
Batch 3/64 loss: -0.813654899597168
Batch 4/64 loss: -0.9541215896606445
Batch 5/64 loss: -1.1644706726074219
Batch 6/64 loss: -0.9597930908203125
Batch 7/64 loss: -1.3488750457763672
Batch 8/64 loss: -1.2543392181396484
Batch 9/64 loss: -1.0386877059936523
Batch 10/64 loss: -0.556793212890625
Batch 11/64 loss: -1.081395149230957
Batch 12/64 loss: -1.3588743209838867
Batch 13/64 loss: -1.2407817840576172
Batch 14/64 loss: -0.9762716293334961
Batch 15/64 loss: -1.097773551940918
Batch 16/64 loss: -0.9030799865722656
Batch 17/64 loss: -0.7113685607910156
Batch 18/64 loss: -0.7230873107910156
Batch 19/64 loss: -1.0006561279296875
Batch 20/64 loss: -1.4842309951782227
Batch 21/64 loss: -0.8563022613525391
Batch 22/64 loss: -1.200693130493164
Batch 23/64 loss: -1.0376062393188477
Batch 24/64 loss: -0.9131927490234375
Batch 25/64 loss: -0.8610029220581055
Batch 26/64 loss: -1.0715160369873047
Batch 27/64 loss: -1.1627082824707031
Batch 28/64 loss: -0.9802379608154297
Batch 29/64 loss: -1.2677011489868164
Batch 30/64 loss: -1.273183822631836
Batch 31/64 loss: -1.3412504196166992
Batch 32/64 loss: -0.9993982315063477
Batch 33/64 loss: -1.153794288635254
Batch 34/64 loss: -0.7373180389404297
Batch 35/64 loss: -0.9613838195800781
Batch 36/64 loss: -1.0820531845092773
Batch 37/64 loss: -1.3952598571777344
Batch 38/64 loss: -0.8475713729858398
Batch 39/64 loss: -1.0564699172973633
Batch 40/64 loss: -1.3880987167358398
Batch 41/64 loss: -1.3866968154907227
Batch 42/64 loss: -0.9156808853149414
Batch 43/64 loss: -1.5447444915771484
Batch 44/64 loss: -0.85650634765625
Batch 45/64 loss: -1.3079166412353516
Batch 46/64 loss: -1.3280210494995117
Batch 47/64 loss: -0.641261100769043
Batch 48/64 loss: -0.9364070892333984
Batch 49/64 loss: -0.7762842178344727
Batch 50/64 loss: -1.1818733215332031
Batch 51/64 loss: -1.1771783828735352
Batch 52/64 loss: -1.4850006103515625
Batch 53/64 loss: -1.0220670700073242
Batch 54/64 loss: -1.0337209701538086
Batch 55/64 loss: -1.1980257034301758
Batch 56/64 loss: -0.8773488998413086
Batch 57/64 loss: -1.16741943359375
Batch 58/64 loss: -1.2478694915771484
Batch 59/64 loss: -0.4375448226928711
Batch 60/64 loss: -1.072281837463379
Batch 61/64 loss: -1.2002973556518555
Batch 62/64 loss: -0.7130556106567383
Batch 63/64 loss: -1.3426227569580078
Batch 64/64 loss: -5.208029747009277
Epoch 137  Train loss: -1.1140204074336033  Val loss: -1.228990522037257
Epoch 138
-------------------------------
Batch 1/64 loss: -1.0406179428100586
Batch 2/64 loss: -1.371591567993164
Batch 3/64 loss: -1.0153913497924805
Batch 4/64 loss: -1.0011510848999023
Batch 5/64 loss: -1.1345205307006836
Batch 6/64 loss: -1.138315200805664
Batch 7/64 loss: -1.1803979873657227
Batch 8/64 loss: -1.195648193359375
Batch 9/64 loss: -1.355637550354004
Batch 10/64 loss: -0.9994440078735352
Batch 11/64 loss: -1.1558170318603516
Batch 12/64 loss: -1.1634397506713867
Batch 13/64 loss: -1.363530158996582
Batch 14/64 loss: -0.8166942596435547
Batch 15/64 loss: -1.0997047424316406
Batch 16/64 loss: -0.8067588806152344
Batch 17/64 loss: -1.1817665100097656
Batch 18/64 loss: -1.0111141204833984
Batch 19/64 loss: -1.0470705032348633
Batch 20/64 loss: -1.0578947067260742
Batch 21/64 loss: -1.1360054016113281
Batch 22/64 loss: -0.8283414840698242
Batch 23/64 loss: -1.2698116302490234
Batch 24/64 loss: -1.2443218231201172
Batch 25/64 loss: -1.2936391830444336
Batch 26/64 loss: -0.8159713745117188
Batch 27/64 loss: -1.017359733581543
Batch 28/64 loss: -1.0546398162841797
Batch 29/64 loss: -1.1994686126708984
Batch 30/64 loss: -0.9279470443725586
Batch 31/64 loss: -1.4472579956054688
Batch 32/64 loss: -1.3137197494506836
Batch 33/64 loss: -1.0884227752685547
Batch 34/64 loss: -1.2515735626220703
Batch 35/64 loss: -1.0221738815307617
Batch 36/64 loss: -0.8860225677490234
Batch 37/64 loss: -1.0096492767333984
Batch 38/64 loss: -0.7670574188232422
Batch 39/64 loss: -0.6885061264038086
Batch 40/64 loss: -1.2785911560058594
Batch 41/64 loss: -1.1919174194335938
Batch 42/64 loss: -0.8201494216918945
Batch 43/64 loss: -0.9735927581787109
Batch 44/64 loss: -1.0774784088134766
Batch 45/64 loss: -0.9262332916259766
Batch 46/64 loss: -1.1206960678100586
Batch 47/64 loss: -0.9240341186523438
Batch 48/64 loss: -0.7943058013916016
Batch 49/64 loss: -1.3778610229492188
Batch 50/64 loss: -1.0687408447265625
Batch 51/64 loss: -0.5334310531616211
Batch 52/64 loss: -1.1690473556518555
Batch 53/64 loss: -0.943913459777832
Batch 54/64 loss: -0.878941535949707
Batch 55/64 loss: -1.0132770538330078
Batch 56/64 loss: -0.9954195022583008
Batch 57/64 loss: -1.1550798416137695
Batch 58/64 loss: -1.2031373977661133
Batch 59/64 loss: -0.9076557159423828
Batch 60/64 loss: -0.9791259765625
Batch 61/64 loss: -1.1095752716064453
Batch 62/64 loss: -1.0636072158813477
Batch 63/64 loss: -0.6685009002685547
Batch 64/64 loss: -4.947059631347656
Epoch 138  Train loss: -1.1024784761316635  Val loss: -1.1139895383435017
Epoch 139
-------------------------------
Batch 1/64 loss: -1.2585420608520508
Batch 2/64 loss: -0.9405479431152344
Batch 3/64 loss: -1.0661439895629883
Batch 4/64 loss: -1.1623201370239258
Batch 5/64 loss: -0.8436069488525391
Batch 6/64 loss: -1.0914764404296875
Batch 7/64 loss: -1.4585180282592773
Batch 8/64 loss: -1.2051239013671875
Batch 9/64 loss: -0.8427448272705078
Batch 10/64 loss: -0.807774543762207
Batch 11/64 loss: -1.0571365356445312
Batch 12/64 loss: -0.8140678405761719
Batch 13/64 loss: -1.2222614288330078
Batch 14/64 loss: -1.066981315612793
Batch 15/64 loss: -1.2845745086669922
Batch 16/64 loss: -0.7280073165893555
Batch 17/64 loss: -1.2696924209594727
Batch 18/64 loss: -1.0834026336669922
Batch 19/64 loss: -1.372939109802246
Batch 20/64 loss: -1.1233654022216797
Batch 21/64 loss: -1.2738103866577148
Batch 22/64 loss: -0.5627317428588867
Batch 23/64 loss: -1.0756359100341797
Batch 24/64 loss: -1.029642105102539
Batch 25/64 loss: -0.7736244201660156
Batch 26/64 loss: -1.0906610488891602
Batch 27/64 loss: -1.0293159484863281
Batch 28/64 loss: -1.2995262145996094
Batch 29/64 loss: -0.5983924865722656
Batch 30/64 loss: -1.2268037796020508
Batch 31/64 loss: -1.238081932067871
Batch 32/64 loss: -1.0004816055297852
Batch 33/64 loss: -1.2297182083129883
Batch 34/64 loss: -0.879216194152832
Batch 35/64 loss: -1.1577577590942383
Batch 36/64 loss: -1.3940839767456055
Batch 37/64 loss: -0.9671945571899414
Batch 38/64 loss: -1.1771879196166992
Batch 39/64 loss: -1.154709815979004
Batch 40/64 loss: -0.6979217529296875
Batch 41/64 loss: -1.1321477890014648
Batch 42/64 loss: -1.2555646896362305
Batch 43/64 loss: -1.3432064056396484
Batch 44/64 loss: -1.0016298294067383
Batch 45/64 loss: -0.769047737121582
Batch 46/64 loss: -0.9807205200195312
Batch 47/64 loss: -0.9728307723999023
Batch 48/64 loss: -1.2703161239624023
Batch 49/64 loss: -1.2856111526489258
Batch 50/64 loss: -0.9153890609741211
Batch 51/64 loss: -0.677393913269043
Batch 52/64 loss: -1.0924053192138672
Batch 53/64 loss: -0.6345195770263672
Batch 54/64 loss: -1.0631170272827148
Batch 55/64 loss: -1.098982810974121
Batch 56/64 loss: -0.7862234115600586
Batch 57/64 loss: -0.9562883377075195
Batch 58/64 loss: -0.8379106521606445
Batch 59/64 loss: -0.8988370895385742
Batch 60/64 loss: -0.8383111953735352
Batch 61/64 loss: -1.2188386917114258
Batch 62/64 loss: -1.1770601272583008
Batch 63/64 loss: -1.1659088134765625
Batch 64/64 loss: -5.253888130187988
Epoch 139  Train loss: -1.095974937139773  Val loss: -1.2611989155667753
Saving best model, epoch: 139
Epoch 140
-------------------------------
Batch 1/64 loss: -1.4624700546264648
Batch 2/64 loss: -1.2463560104370117
Batch 3/64 loss: -0.37492942810058594
Batch 4/64 loss: -1.007242202758789
Batch 5/64 loss: -1.390364646911621
Batch 6/64 loss: -1.2694816589355469
Batch 7/64 loss: -0.9957685470581055
Batch 8/64 loss: -1.0884056091308594
Batch 9/64 loss: -1.3505563735961914
Batch 10/64 loss: -0.945347785949707
Batch 11/64 loss: -1.3126811981201172
Batch 12/64 loss: -1.1400079727172852
Batch 13/64 loss: -0.9132299423217773
Batch 14/64 loss: -1.1925878524780273
Batch 15/64 loss: -1.3739957809448242
Batch 16/64 loss: -1.2883014678955078
Batch 17/64 loss: -0.8482141494750977
Batch 18/64 loss: -0.628718376159668
Batch 19/64 loss: -1.2576560974121094
Batch 20/64 loss: -1.0041351318359375
Batch 21/64 loss: -0.8024911880493164
Batch 22/64 loss: -1.2164602279663086
Batch 23/64 loss: -1.3869256973266602
Batch 24/64 loss: -0.4681243896484375
Batch 25/64 loss: -0.8273048400878906
Batch 26/64 loss: -1.237518310546875
Batch 27/64 loss: -1.0564422607421875
Batch 28/64 loss: -1.074106216430664
Batch 29/64 loss: -1.296727180480957
Batch 30/64 loss: -0.9749593734741211
Batch 31/64 loss: -0.5882482528686523
Batch 32/64 loss: -1.1235103607177734
Batch 33/64 loss: -1.2952251434326172
Batch 34/64 loss: -1.0753841400146484
Batch 35/64 loss: -0.9404773712158203
Batch 36/64 loss: -0.6531467437744141
Batch 37/64 loss: -0.6224956512451172
Batch 38/64 loss: -1.2112512588500977
Batch 39/64 loss: -0.9609804153442383
Batch 40/64 loss: -0.8739538192749023
Batch 41/64 loss: -1.1519556045532227
Batch 42/64 loss: -0.8848352432250977
Batch 43/64 loss: -1.1677379608154297
Batch 44/64 loss: -0.9379358291625977
Batch 45/64 loss: -1.1030330657958984
Batch 46/64 loss: -1.398935317993164
Batch 47/64 loss: -0.9815549850463867
Batch 48/64 loss: -1.135869026184082
Batch 49/64 loss: -0.16037273406982422
Batch 50/64 loss: -0.8792209625244141
Batch 51/64 loss: -1.2435007095336914
Batch 52/64 loss: -1.1956396102905273
Batch 53/64 loss: -0.9287796020507812
Batch 54/64 loss: -0.9294099807739258
Batch 55/64 loss: -1.2549057006835938
Batch 56/64 loss: -0.11609745025634766
Batch 57/64 loss: -1.019674301147461
Batch 58/64 loss: -0.6042766571044922
Batch 59/64 loss: -0.6082372665405273
Batch 60/64 loss: -0.33454322814941406
Batch 61/64 loss: -1.2406654357910156
Batch 62/64 loss: -1.206338882446289
Batch 63/64 loss: -0.960301399230957
Batch 64/64 loss: -4.763676166534424
Epoch 140  Train loss: -1.0477295875549317  Val loss: -1.1206842009554203
Epoch 141
-------------------------------
Batch 1/64 loss: -0.9020509719848633
Batch 2/64 loss: -1.2554435729980469
Batch 3/64 loss: -1.2019329071044922
Batch 4/64 loss: -0.8111495971679688
Batch 5/64 loss: -0.9912080764770508
Batch 6/64 loss: -1.1714038848876953
Batch 7/64 loss: -1.103036880493164
Batch 8/64 loss: -0.47293758392333984
Batch 9/64 loss: -1.1440696716308594
Batch 10/64 loss: -1.3678512573242188
Batch 11/64 loss: -1.2351531982421875
Batch 12/64 loss: -1.2115907669067383
Batch 13/64 loss: -1.1123905181884766
Batch 14/64 loss: -0.8084716796875
Batch 15/64 loss: -0.8310613632202148
Batch 16/64 loss: -1.3342370986938477
Batch 17/64 loss: -0.9705677032470703
Batch 18/64 loss: -1.201690673828125
Batch 19/64 loss: -0.8953475952148438
Batch 20/64 loss: -1.1382341384887695
Batch 21/64 loss: -1.2514429092407227
Batch 22/64 loss: -0.6323957443237305
Batch 23/64 loss: -0.7087821960449219
Batch 24/64 loss: -1.3638429641723633
Batch 25/64 loss: -1.113234519958496
Batch 26/64 loss: -0.9010095596313477
Batch 27/64 loss: -1.0667762756347656
Batch 28/64 loss: -1.4655570983886719
Batch 29/64 loss: -1.335087776184082
Batch 30/64 loss: -1.5007543563842773
Batch 31/64 loss: -1.2974767684936523
Batch 32/64 loss: -1.3247709274291992
Batch 33/64 loss: -1.0284671783447266
Batch 34/64 loss: -0.9731178283691406
Batch 35/64 loss: -1.1278619766235352
Batch 36/64 loss: -0.8560523986816406
Batch 37/64 loss: -0.8033666610717773
Batch 38/64 loss: -1.1293096542358398
Batch 39/64 loss: -0.9854450225830078
Batch 40/64 loss: -1.0972700119018555
Batch 41/64 loss: -1.134892463684082
Batch 42/64 loss: -1.0818243026733398
Batch 43/64 loss: -1.4958887100219727
Batch 44/64 loss: -0.9268455505371094
Batch 45/64 loss: -0.9568243026733398
Batch 46/64 loss: -1.1726503372192383
Batch 47/64 loss: -1.2824859619140625
Batch 48/64 loss: -1.245504379272461
Batch 49/64 loss: -1.1203594207763672
Batch 50/64 loss: -1.1078290939331055
Batch 51/64 loss: -1.0379829406738281
Batch 52/64 loss: -0.8332481384277344
Batch 53/64 loss: -0.9211969375610352
Batch 54/64 loss: -0.8526639938354492
Batch 55/64 loss: -1.200216293334961
Batch 56/64 loss: -0.5632123947143555
Batch 57/64 loss: -1.383458137512207
Batch 58/64 loss: -1.2085332870483398
Batch 59/64 loss: -0.7085819244384766
Batch 60/64 loss: -1.2159147262573242
Batch 61/64 loss: -0.9945363998413086
Batch 62/64 loss: -1.2058172225952148
Batch 63/64 loss: -1.03863525390625
Batch 64/64 loss: -4.247294902801514
Epoch 141  Train loss: -1.1136694010566264  Val loss: -1.22230119475794
Epoch 142
-------------------------------
Batch 1/64 loss: -1.3525209426879883
Batch 2/64 loss: -1.2651700973510742
Batch 3/64 loss: -0.915888786315918
Batch 4/64 loss: -1.3566503524780273
Batch 5/64 loss: -0.6417360305786133
Batch 6/64 loss: -0.7015790939331055
Batch 7/64 loss: -1.3551692962646484
Batch 8/64 loss: -0.8487911224365234
Batch 9/64 loss: -0.5957889556884766
Batch 10/64 loss: -1.0140762329101562
Batch 11/64 loss: -1.2738151550292969
Batch 12/64 loss: -1.3604545593261719
Batch 13/64 loss: -0.9139518737792969
Batch 14/64 loss: -1.1518611907958984
Batch 15/64 loss: -0.819279670715332
Batch 16/64 loss: -0.7176141738891602
Batch 17/64 loss: -1.361811637878418
Batch 18/64 loss: -0.8038597106933594
Batch 19/64 loss: -0.8236980438232422
Batch 20/64 loss: -0.9313497543334961
Batch 21/64 loss: -1.0429668426513672
Batch 22/64 loss: -0.8789472579956055
Batch 23/64 loss: -1.2690763473510742
Batch 24/64 loss: -1.294764518737793
Batch 25/64 loss: -0.8859462738037109
Batch 26/64 loss: -1.1801214218139648
Batch 27/64 loss: -1.2290973663330078
Batch 28/64 loss: -1.1579217910766602
Batch 29/64 loss: -0.9184627532958984
Batch 30/64 loss: -1.138981819152832
Batch 31/64 loss: -1.3732919692993164
Batch 32/64 loss: -1.2666549682617188
Batch 33/64 loss: -1.0452098846435547
Batch 34/64 loss: -1.2600288391113281
Batch 35/64 loss: -1.0187416076660156
Batch 36/64 loss: -1.0613489151000977
Batch 37/64 loss: -0.5203790664672852
Batch 38/64 loss: -1.1553478240966797
Batch 39/64 loss: -1.155085563659668
Batch 40/64 loss: -1.3494377136230469
Batch 41/64 loss: -1.0768470764160156
Batch 42/64 loss: -1.0459966659545898
Batch 43/64 loss: -1.2923831939697266
Batch 44/64 loss: -1.2119560241699219
Batch 45/64 loss: -1.182703971862793
Batch 46/64 loss: -1.106515884399414
Batch 47/64 loss: -0.7903327941894531
Batch 48/64 loss: -0.8915214538574219
Batch 49/64 loss: -1.134190559387207
Batch 50/64 loss: -0.46755027770996094
Batch 51/64 loss: -0.9923524856567383
Batch 52/64 loss: -0.865452766418457
Batch 53/64 loss: -1.2988958358764648
Batch 54/64 loss: -0.9283990859985352
Batch 55/64 loss: -1.1458911895751953
Batch 56/64 loss: -1.2469348907470703
Batch 57/64 loss: -1.180403709411621
Batch 58/64 loss: -0.4153099060058594
Batch 59/64 loss: -1.035414695739746
Batch 60/64 loss: -1.0689773559570312
Batch 61/64 loss: -0.9085912704467773
Batch 62/64 loss: -0.991114616394043
Batch 63/64 loss: -0.7001791000366211
Batch 64/64 loss: -5.2525634765625
Epoch 142  Train loss: -1.0874386955710018  Val loss: -1.0748548081650358
Epoch 143
-------------------------------
Batch 1/64 loss: -0.9720335006713867
Batch 2/64 loss: -0.989893913269043
Batch 3/64 loss: -1.0447454452514648
Batch 4/64 loss: -1.1673688888549805
Batch 5/64 loss: -1.168217658996582
Batch 6/64 loss: -1.1235628128051758
Batch 7/64 loss: -0.9919672012329102
Batch 8/64 loss: -1.0598869323730469
Batch 9/64 loss: -0.9090862274169922
Batch 10/64 loss: -1.1484832763671875
Batch 11/64 loss: -1.2307415008544922
Batch 12/64 loss: -1.3217992782592773
Batch 13/64 loss: -0.5544891357421875
Batch 14/64 loss: -1.2970294952392578
Batch 15/64 loss: -1.1891984939575195
Batch 16/64 loss: -1.01153564453125
Batch 17/64 loss: -1.1351995468139648
Batch 18/64 loss: -1.0314245223999023
Batch 19/64 loss: -1.1480693817138672
Batch 20/64 loss: -1.2563552856445312
Batch 21/64 loss: -0.8483076095581055
Batch 22/64 loss: -1.3868122100830078
Batch 23/64 loss: -1.2324752807617188
Batch 24/64 loss: -1.0796079635620117
Batch 25/64 loss: -1.0317497253417969
Batch 26/64 loss: -0.648554801940918
Batch 27/64 loss: -1.3707408905029297
Batch 28/64 loss: -1.2853021621704102
Batch 29/64 loss: -1.1878576278686523
Batch 30/64 loss: -0.9309291839599609
Batch 31/64 loss: -0.8318147659301758
Batch 32/64 loss: -1.3180627822875977
Batch 33/64 loss: -0.9054412841796875
Batch 34/64 loss: -1.3549318313598633
Batch 35/64 loss: -1.107426643371582
Batch 36/64 loss: -1.5599966049194336
Batch 37/64 loss: -0.8338193893432617
Batch 38/64 loss: -0.9866466522216797
Batch 39/64 loss: -1.4114208221435547
Batch 40/64 loss: -1.1715259552001953
Batch 41/64 loss: -0.9032802581787109
Batch 42/64 loss: -1.174759864807129
Batch 43/64 loss: -1.1706218719482422
Batch 44/64 loss: -0.9856595993041992
Batch 45/64 loss: -1.0651016235351562
Batch 46/64 loss: -1.0332355499267578
Batch 47/64 loss: -0.8856267929077148
Batch 48/64 loss: -0.3234272003173828
Batch 49/64 loss: -1.0490036010742188
Batch 50/64 loss: -0.9593658447265625
Batch 51/64 loss: -1.301569938659668
Batch 52/64 loss: -0.8376779556274414
Batch 53/64 loss: -1.345210075378418
Batch 54/64 loss: -0.8660116195678711
Batch 55/64 loss: -0.4320087432861328
Batch 56/64 loss: -1.2895126342773438
Batch 57/64 loss: -0.8151683807373047
Batch 58/64 loss: -1.2301864624023438
Batch 59/64 loss: -1.4888296127319336
Batch 60/64 loss: -1.1108522415161133
Batch 61/64 loss: -1.402857780456543
Batch 62/64 loss: -1.0391826629638672
Batch 63/64 loss: -1.0332002639770508
Batch 64/64 loss: -5.00778865814209
Epoch 143  Train loss: -1.1252188925649607  Val loss: -1.135517500520162
Epoch 144
-------------------------------
Batch 1/64 loss: -1.4311847686767578
Batch 2/64 loss: -0.8802413940429688
Batch 3/64 loss: -1.0415611267089844
Batch 4/64 loss: -1.0489091873168945
Batch 5/64 loss: -1.234604835510254
Batch 6/64 loss: -1.3150310516357422
Batch 7/64 loss: -1.1187162399291992
Batch 8/64 loss: -0.7590541839599609
Batch 9/64 loss: -0.9945354461669922
Batch 10/64 loss: -1.2558774948120117
Batch 11/64 loss: -1.0209236145019531
Batch 12/64 loss: -0.8496761322021484
Batch 13/64 loss: -1.3318414688110352
Batch 14/64 loss: -1.3460664749145508
Batch 15/64 loss: -1.448542594909668
Batch 16/64 loss: -0.6336488723754883
Batch 17/64 loss: -0.6596403121948242
Batch 18/64 loss: -1.143010139465332
Batch 19/64 loss: -1.163970947265625
Batch 20/64 loss: -1.0824241638183594
Batch 21/64 loss: -0.9171371459960938
Batch 22/64 loss: -1.0204315185546875
Batch 23/64 loss: -0.7905874252319336
Batch 24/64 loss: -1.139052391052246
Batch 25/64 loss: -1.1994953155517578
Batch 26/64 loss: -1.2039422988891602
Batch 27/64 loss: -1.3476638793945312
Batch 28/64 loss: -1.2720623016357422
Batch 29/64 loss: -1.1982669830322266
Batch 30/64 loss: -0.8198118209838867
Batch 31/64 loss: -1.3307056427001953
Batch 32/64 loss: -1.0705156326293945
Batch 33/64 loss: -0.7773666381835938
Batch 34/64 loss: -0.7740459442138672
Batch 35/64 loss: -1.1010189056396484
Batch 36/64 loss: -1.0050411224365234
Batch 37/64 loss: -1.4191341400146484
Batch 38/64 loss: -1.3052749633789062
Batch 39/64 loss: -1.1771354675292969
Batch 40/64 loss: -1.3764076232910156
Batch 41/64 loss: -0.8954982757568359
Batch 42/64 loss: -1.5137395858764648
Batch 43/64 loss: -1.1810369491577148
Batch 44/64 loss: -1.0209884643554688
Batch 45/64 loss: -1.1244583129882812
Batch 46/64 loss: -0.9169321060180664
Batch 47/64 loss: -1.2124319076538086
Batch 48/64 loss: -1.348130226135254
Batch 49/64 loss: -1.0077037811279297
Batch 50/64 loss: -1.0361976623535156
Batch 51/64 loss: -0.8276805877685547
Batch 52/64 loss: -1.0839309692382812
Batch 53/64 loss: -0.8382396697998047
Batch 54/64 loss: -1.0078601837158203
Batch 55/64 loss: -1.0463857650756836
Batch 56/64 loss: -1.055084228515625
Batch 57/64 loss: -1.2166976928710938
Batch 58/64 loss: -1.3520889282226562
Batch 59/64 loss: -1.2900276184082031
Batch 60/64 loss: -1.14288330078125
Batch 61/64 loss: -1.3911161422729492
Batch 62/64 loss: -1.0929937362670898
Batch 63/64 loss: -1.3611421585083008
Batch 64/64 loss: -5.214081764221191
Epoch 144  Train loss: -1.1588763480092965  Val loss: -1.2726082031669486
Saving best model, epoch: 144
Epoch 145
-------------------------------
Batch 1/64 loss: -1.2778997421264648
Batch 2/64 loss: -1.213266372680664
Batch 3/64 loss: -1.0799102783203125
Batch 4/64 loss: -0.9822578430175781
Batch 5/64 loss: -0.9789180755615234
Batch 6/64 loss: -1.3294553756713867
Batch 7/64 loss: -1.1441326141357422
Batch 8/64 loss: -0.7937965393066406
Batch 9/64 loss: -1.0825796127319336
Batch 10/64 loss: -1.197932243347168
Batch 11/64 loss: -0.6924047470092773
Batch 12/64 loss: -1.1789636611938477
Batch 13/64 loss: -0.9075498580932617
Batch 14/64 loss: -1.344045639038086
Batch 15/64 loss: -1.1730756759643555
Batch 16/64 loss: -0.9839344024658203
Batch 17/64 loss: -0.9696569442749023
Batch 18/64 loss: -1.0591983795166016
Batch 19/64 loss: -0.7424440383911133
Batch 20/64 loss: -1.1407527923583984
Batch 21/64 loss: -1.0646018981933594
Batch 22/64 loss: -0.9492158889770508
Batch 23/64 loss: -1.0591211318969727
Batch 24/64 loss: -0.5571222305297852
Batch 25/64 loss: -0.6300249099731445
Batch 26/64 loss: -1.2142963409423828
Batch 27/64 loss: -1.2905597686767578
Batch 28/64 loss: -1.2681455612182617
Batch 29/64 loss: -1.1014719009399414
Batch 30/64 loss: -0.9756526947021484
Batch 31/64 loss: -0.6963129043579102
Batch 32/64 loss: -1.1102046966552734
Batch 33/64 loss: -0.27092838287353516
Batch 34/64 loss: -1.2762460708618164
Batch 35/64 loss: -1.0560388565063477
Batch 36/64 loss: -0.7752742767333984
Batch 37/64 loss: -1.177769660949707
Batch 38/64 loss: -1.0875673294067383
Batch 39/64 loss: -0.8979625701904297
Batch 40/64 loss: -0.5204677581787109
Batch 41/64 loss: -0.6701517105102539
Batch 42/64 loss: -1.1829195022583008
Batch 43/64 loss: -1.2584600448608398
Batch 44/64 loss: -0.563380241394043
Batch 45/64 loss: -1.0898332595825195
Batch 46/64 loss: -1.1497220993041992
Batch 47/64 loss: -1.348550796508789
Batch 48/64 loss: -1.0063228607177734
Batch 49/64 loss: -1.3084659576416016
Batch 50/64 loss: -0.8407258987426758
Batch 51/64 loss: -1.4182939529418945
Batch 52/64 loss: -1.0301628112792969
Batch 53/64 loss: -0.9594697952270508
Batch 54/64 loss: -1.241424560546875
Batch 55/64 loss: -1.0121078491210938
Batch 56/64 loss: -1.1978073120117188
Batch 57/64 loss: -1.0856037139892578
Batch 58/64 loss: -1.2558374404907227
Batch 59/64 loss: -0.5718421936035156
Batch 60/64 loss: -1.4841432571411133
Batch 61/64 loss: -0.920074462890625
Batch 62/64 loss: -1.1822795867919922
Batch 63/64 loss: -1.0372962951660156
Batch 64/64 loss: -4.891022205352783
Epoch 145  Train loss: -1.0781851282306747  Val loss: -1.0978558071700157
Epoch 146
-------------------------------
Batch 1/64 loss: -1.0180082321166992
Batch 2/64 loss: -1.1784353256225586
Batch 3/64 loss: -1.2915992736816406
Batch 4/64 loss: -0.9558706283569336
Batch 5/64 loss: -0.8794803619384766
Batch 6/64 loss: -0.9841814041137695
Batch 7/64 loss: -0.9620990753173828
Batch 8/64 loss: -1.0681381225585938
Batch 9/64 loss: -1.1875858306884766
Batch 10/64 loss: -1.2618331909179688
Batch 11/64 loss: -0.9427995681762695
Batch 12/64 loss: -1.231271743774414
Batch 13/64 loss: -0.940277099609375
Batch 14/64 loss: -0.9749011993408203
Batch 15/64 loss: -0.908686637878418
Batch 16/64 loss: -0.9661235809326172
Batch 17/64 loss: -1.1885147094726562
Batch 18/64 loss: -1.2649250030517578
Batch 19/64 loss: -0.9779233932495117
Batch 20/64 loss: -0.766322135925293
Batch 21/64 loss: -1.4038105010986328
Batch 22/64 loss: -0.9361581802368164
Batch 23/64 loss: -0.9979248046875
Batch 24/64 loss: -1.126704216003418
Batch 25/64 loss: -1.0641632080078125
Batch 26/64 loss: -0.6161975860595703
Batch 27/64 loss: -1.077890396118164
Batch 28/64 loss: -1.1023378372192383
Batch 29/64 loss: -1.4522905349731445
Batch 30/64 loss: -1.0472774505615234
Batch 31/64 loss: -0.6549186706542969
Batch 32/64 loss: -0.8318958282470703
Batch 33/64 loss: -1.3368206024169922
Batch 34/64 loss: -1.1881446838378906
Batch 35/64 loss: -1.177321434020996
Batch 36/64 loss: -1.030914306640625
Batch 37/64 loss: -0.7381429672241211
Batch 38/64 loss: -1.1311330795288086
Batch 39/64 loss: -0.9342069625854492
Batch 40/64 loss: -1.143019676208496
Batch 41/64 loss: -1.5231437683105469
Batch 42/64 loss: -0.7739143371582031
Batch 43/64 loss: -1.230250358581543
Batch 44/64 loss: -0.7014055252075195
Batch 45/64 loss: -1.2715063095092773
Batch 46/64 loss: -1.186875343322754
Batch 47/64 loss: -1.213343620300293
Batch 48/64 loss: -1.1402130126953125
Batch 49/64 loss: -0.9862794876098633
Batch 50/64 loss: -1.1783943176269531
Batch 51/64 loss: -1.2763662338256836
Batch 52/64 loss: -0.9446611404418945
Batch 53/64 loss: -1.0773563385009766
Batch 54/64 loss: -1.0717363357543945
Batch 55/64 loss: -0.9483156204223633
Batch 56/64 loss: -1.044377326965332
Batch 57/64 loss: -1.2594051361083984
Batch 58/64 loss: -1.4304838180541992
Batch 59/64 loss: -0.6804533004760742
Batch 60/64 loss: -1.0021581649780273
Batch 61/64 loss: -1.1350383758544922
Batch 62/64 loss: -1.2251901626586914
Batch 63/64 loss: -1.1579399108886719
Batch 64/64 loss: -4.768204689025879
Epoch 146  Train loss: -1.1133366416482364  Val loss: -1.0852432906422829
Epoch 147
-------------------------------
Batch 1/64 loss: -1.1860361099243164
Batch 2/64 loss: -1.0623455047607422
Batch 3/64 loss: -0.7272243499755859
Batch 4/64 loss: -1.0338983535766602
Batch 5/64 loss: -1.2045507431030273
Batch 6/64 loss: -0.9484033584594727
Batch 7/64 loss: -0.9556198120117188
Batch 8/64 loss: -0.9499998092651367
Batch 9/64 loss: -1.1298885345458984
Batch 10/64 loss: -0.846074104309082
Batch 11/64 loss: -0.9238862991333008
Batch 12/64 loss: -0.9285411834716797
Batch 13/64 loss: -1.093404769897461
Batch 14/64 loss: -0.9906740188598633
Batch 15/64 loss: -1.3029403686523438
Batch 16/64 loss: -1.052006721496582
Batch 17/64 loss: -0.7600440979003906
Batch 18/64 loss: -0.7882299423217773
Batch 19/64 loss: -1.1632537841796875
Batch 20/64 loss: -1.456085205078125
Batch 21/64 loss: -1.154789924621582
Batch 22/64 loss: -1.2123537063598633
Batch 23/64 loss: -1.0202054977416992
Batch 24/64 loss: -1.1450138092041016
Batch 25/64 loss: -1.4035959243774414
Batch 26/64 loss: -1.090470314025879
Batch 27/64 loss: -0.5819711685180664
Batch 28/64 loss: -1.005824089050293
Batch 29/64 loss: -1.3050966262817383
Batch 30/64 loss: -1.1098356246948242
Batch 31/64 loss: -0.6764516830444336
Batch 32/64 loss: -0.8691635131835938
Batch 33/64 loss: -1.1730642318725586
Batch 34/64 loss: -1.0148334503173828
Batch 35/64 loss: -1.0888710021972656
Batch 36/64 loss: -1.2143611907958984
Batch 37/64 loss: -0.9132900238037109
Batch 38/64 loss: -1.2644376754760742
Batch 39/64 loss: -0.8663997650146484
Batch 40/64 loss: -1.5199670791625977
Batch 41/64 loss: -1.0705986022949219
Batch 42/64 loss: -1.0361747741699219
Batch 43/64 loss: -0.8113985061645508
Batch 44/64 loss: -1.3620939254760742
Batch 45/64 loss: -1.0892152786254883
Batch 46/64 loss: -1.2132081985473633
Batch 47/64 loss: -1.143254280090332
Batch 48/64 loss: -0.918243408203125
Batch 49/64 loss: -1.2575130462646484
Batch 50/64 loss: -0.9989709854125977
Batch 51/64 loss: -0.9733915328979492
Batch 52/64 loss: -0.8702926635742188
Batch 53/64 loss: -1.1338462829589844
Batch 54/64 loss: -0.9957561492919922
Batch 55/64 loss: -1.2627201080322266
Batch 56/64 loss: -1.0685958862304688
Batch 57/64 loss: -1.1098270416259766
Batch 58/64 loss: -1.2860736846923828
Batch 59/64 loss: -1.2745399475097656
Batch 60/64 loss: -0.9299240112304688
Batch 61/64 loss: -1.0466222763061523
Batch 62/64 loss: -0.9977254867553711
Batch 63/64 loss: -1.0958824157714844
Batch 64/64 loss: -4.699302673339844
Epoch 147  Train loss: -1.107505080279182  Val loss: -1.067233973762014
Epoch 148
-------------------------------
Batch 1/64 loss: -1.1466779708862305
Batch 2/64 loss: -1.0478286743164062
Batch 3/64 loss: -1.386195182800293
Batch 4/64 loss: -1.0796918869018555
Batch 5/64 loss: -1.0036048889160156
Batch 6/64 loss: -0.815556526184082
Batch 7/64 loss: -0.669499397277832
Batch 8/64 loss: -1.2257909774780273
Batch 9/64 loss: -1.367919921875
Batch 10/64 loss: -1.1210498809814453
Batch 11/64 loss: -1.1819257736206055
Batch 12/64 loss: -0.4076380729675293
Batch 13/64 loss: -0.48281192779541016
Batch 14/64 loss: -0.8809518814086914
Batch 15/64 loss: -0.9078283309936523
Batch 16/64 loss: -1.278909683227539
Batch 17/64 loss: -1.4215087890625
Batch 18/64 loss: -1.3754205703735352
Batch 19/64 loss: -0.899932861328125
Batch 20/64 loss: -0.9770736694335938
Batch 21/64 loss: -1.3050346374511719
Batch 22/64 loss: -1.2031898498535156
Batch 23/64 loss: -1.1332130432128906
Batch 24/64 loss: -1.2010364532470703
Batch 25/64 loss: -1.3023996353149414
Batch 26/64 loss: -1.0014238357543945
Batch 27/64 loss: -0.817626953125
Batch 28/64 loss: -0.9593706130981445
Batch 29/64 loss: -1.1389999389648438
Batch 30/64 loss: -1.1074533462524414
Batch 31/64 loss: -0.39105987548828125
Batch 32/64 loss: -1.1568965911865234
Batch 33/64 loss: -1.2712793350219727
Batch 34/64 loss: -0.7863569259643555
Batch 35/64 loss: -1.212890625
Batch 36/64 loss: -1.1938714981079102
Batch 37/64 loss: -1.4575862884521484
Batch 38/64 loss: -1.2886285781860352
Batch 39/64 loss: -1.3571643829345703
Batch 40/64 loss: -1.2462081909179688
Batch 41/64 loss: -1.407379150390625
Batch 42/64 loss: -1.0193672180175781
Batch 43/64 loss: -1.1939363479614258
Batch 44/64 loss: -0.9145441055297852
Batch 45/64 loss: -1.0359621047973633
Batch 46/64 loss: -0.7105789184570312
Batch 47/64 loss: -1.0361337661743164
Batch 48/64 loss: -1.212458610534668
Batch 49/64 loss: -1.3736658096313477
Batch 50/64 loss: -0.8951091766357422
Batch 51/64 loss: -1.2282238006591797
Batch 52/64 loss: -1.0371103286743164
Batch 53/64 loss: -0.8910884857177734
Batch 54/64 loss: -1.1468544006347656
Batch 55/64 loss: -1.1405982971191406
Batch 56/64 loss: -1.232940673828125
Batch 57/64 loss: -1.1409912109375
Batch 58/64 loss: -1.1134920120239258
Batch 59/64 loss: -0.6919765472412109
Batch 60/64 loss: -0.9886407852172852
Batch 61/64 loss: -1.2930173873901367
Batch 62/64 loss: -1.2417736053466797
Batch 63/64 loss: -0.8244724273681641
Batch 64/64 loss: -5.0648908615112305
Epoch 148  Train loss: -1.125937110302495  Val loss: -1.3116851229847912
Saving best model, epoch: 148
Epoch 149
-------------------------------
Batch 1/64 loss: -1.5793704986572266
Batch 2/64 loss: -1.2374467849731445
Batch 3/64 loss: -1.471221923828125
Batch 4/64 loss: -1.0144367218017578
Batch 5/64 loss: -0.9911317825317383
Batch 6/64 loss: -1.3325529098510742
Batch 7/64 loss: -0.9517946243286133
Batch 8/64 loss: -0.7940349578857422
Batch 9/64 loss: -1.342193603515625
Batch 10/64 loss: -1.275003433227539
Batch 11/64 loss: -1.1710033416748047
Batch 12/64 loss: -0.9014949798583984
Batch 13/64 loss: -1.017683982849121
Batch 14/64 loss: -1.2807350158691406
Batch 15/64 loss: -0.9902458190917969
Batch 16/64 loss: -0.8813581466674805
Batch 17/64 loss: -1.124476432800293
Batch 18/64 loss: -1.1663312911987305
Batch 19/64 loss: -1.031538963317871
Batch 20/64 loss: -1.0130672454833984
Batch 21/64 loss: -0.6529569625854492
Batch 22/64 loss: -0.7322330474853516
Batch 23/64 loss: -0.9741716384887695
Batch 24/64 loss: -1.0234508514404297
Batch 25/64 loss: -0.8188943862915039
Batch 26/64 loss: -1.0303335189819336
Batch 27/64 loss: -0.8120298385620117
Batch 28/64 loss: -1.000178337097168
Batch 29/64 loss: -1.0392580032348633
Batch 30/64 loss: -1.098210334777832
Batch 31/64 loss: -1.092371940612793
Batch 32/64 loss: -0.9309539794921875
Batch 33/64 loss: -1.281956672668457
Batch 34/64 loss: -0.7514944076538086
Batch 35/64 loss: -1.0364437103271484
Batch 36/64 loss: -1.3069496154785156
Batch 37/64 loss: -0.6719436645507812
Batch 38/64 loss: -0.9353876113891602
Batch 39/64 loss: -0.9751052856445312
Batch 40/64 loss: -1.1882944107055664
Batch 41/64 loss: -1.0100374221801758
Batch 42/64 loss: -0.7827272415161133
Batch 43/64 loss: -1.1453657150268555
Batch 44/64 loss: -1.2725553512573242
Batch 45/64 loss: -1.0145025253295898
Batch 46/64 loss: -1.0074443817138672
Batch 47/64 loss: -0.8551568984985352
Batch 48/64 loss: -0.8446569442749023
Batch 49/64 loss: -0.9768409729003906
Batch 50/64 loss: -1.3013067245483398
Batch 51/64 loss: -1.2115659713745117
Batch 52/64 loss: -1.1557998657226562
Batch 53/64 loss: -1.118180274963379
Batch 54/64 loss: -1.229355812072754
Batch 55/64 loss: -1.3448944091796875
Batch 56/64 loss: -0.9563322067260742
Batch 57/64 loss: -1.215733528137207
Batch 58/64 loss: -1.182687759399414
Batch 59/64 loss: -1.069352149963379
Batch 60/64 loss: -1.3165321350097656
Batch 61/64 loss: -1.4105663299560547
Batch 62/64 loss: -1.1747941970825195
Batch 63/64 loss: -1.3700437545776367
Batch 64/64 loss: -5.336526870727539
Epoch 149  Train loss: -1.127663818060183  Val loss: -1.1044647111925472
Epoch 150
-------------------------------
Batch 1/64 loss: -1.558645248413086
Batch 2/64 loss: -1.3442392349243164
Batch 3/64 loss: -1.2892141342163086
Batch 4/64 loss: -1.0175352096557617
Batch 5/64 loss: -1.3425569534301758
Batch 6/64 loss: -0.5245771408081055
Batch 7/64 loss: -1.291825294494629
Batch 8/64 loss: -1.1179494857788086
Batch 9/64 loss: -1.3094196319580078
Batch 10/64 loss: -1.4022941589355469
Batch 11/64 loss: -1.0186548233032227
Batch 12/64 loss: -1.0471954345703125
Batch 13/64 loss: -1.2013235092163086
Batch 14/64 loss: -1.0901241302490234
Batch 15/64 loss: -0.8268547058105469
Batch 16/64 loss: -1.3201789855957031
Batch 17/64 loss: -1.0439138412475586
Batch 18/64 loss: -1.2479934692382812
Batch 19/64 loss: -1.1331748962402344
Batch 20/64 loss: -1.08905029296875
Batch 21/64 loss: -1.1356210708618164
Batch 22/64 loss: -1.4345312118530273
Batch 23/64 loss: -1.158595085144043
Batch 24/64 loss: -0.8547582626342773
Batch 25/64 loss: -0.9237899780273438
Batch 26/64 loss: -1.2151517868041992
Batch 27/64 loss: -1.220998764038086
Batch 28/64 loss: -0.7858648300170898
Batch 29/64 loss: -1.102400779724121
Batch 30/64 loss: -0.9261388778686523
Batch 31/64 loss: -1.1059942245483398
Batch 32/64 loss: -1.2730417251586914
Batch 33/64 loss: -1.1909074783325195
Batch 34/64 loss: -1.2250423431396484
Batch 35/64 loss: -1.1325607299804688
Batch 36/64 loss: -1.1748895645141602
Batch 37/64 loss: -1.4243040084838867
Batch 38/64 loss: -1.064295768737793
Batch 39/64 loss: -1.0947132110595703
Batch 40/64 loss: -1.1094770431518555
Batch 41/64 loss: -1.1006765365600586
Batch 42/64 loss: -1.0202226638793945
Batch 43/64 loss: -1.1661920547485352
Batch 44/64 loss: -1.1153831481933594
Batch 45/64 loss: -0.7522411346435547
Batch 46/64 loss: -1.0718050003051758
Batch 47/64 loss: -1.2183609008789062
Batch 48/64 loss: -0.989405632019043
Batch 49/64 loss: -1.5082101821899414
Batch 50/64 loss: -1.0318050384521484
Batch 51/64 loss: -1.0701961517333984
Batch 52/64 loss: -1.3536434173583984
Batch 53/64 loss: -0.9952516555786133
Batch 54/64 loss: -0.9110984802246094
Batch 55/64 loss: -0.956904411315918
Batch 56/64 loss: -1.2738466262817383
Batch 57/64 loss: -0.9228410720825195
Batch 58/64 loss: -0.4537639617919922
Batch 59/64 loss: -0.8433837890625
Batch 60/64 loss: -1.1839208602905273
Batch 61/64 loss: -1.42303466796875
Batch 62/64 loss: -1.0786819458007812
Batch 63/64 loss: -1.0352449417114258
Batch 64/64 loss: -5.140051364898682
Epoch 150  Train loss: -1.1623678450490915  Val loss: -1.0817500111163687
Epoch 151
-------------------------------
Batch 1/64 loss: -1.0984764099121094
Batch 2/64 loss: -0.9608583450317383
Batch 3/64 loss: -0.9335803985595703
Batch 4/64 loss: -0.5636672973632812
Batch 5/64 loss: -1.3663768768310547
Batch 6/64 loss: -1.2610254287719727
Batch 7/64 loss: -1.1395225524902344
Batch 8/64 loss: -1.370626449584961
Batch 9/64 loss: -1.221623420715332
Batch 10/64 loss: -1.4085445404052734
Batch 11/64 loss: -1.068272590637207
Batch 12/64 loss: -1.516164779663086
Batch 13/64 loss: -1.3476285934448242
Batch 14/64 loss: -1.082819938659668
Batch 15/64 loss: -0.46063232421875
Batch 16/64 loss: -1.227860450744629
Batch 17/64 loss: -1.0095672607421875
Batch 18/64 loss: -0.8114042282104492
Batch 19/64 loss: -1.3263559341430664
Batch 20/64 loss: -1.0191373825073242
Batch 21/64 loss: -0.855504035949707
Batch 22/64 loss: -0.9981489181518555
Batch 23/64 loss: -1.5444250106811523
Batch 24/64 loss: -1.2974367141723633
Batch 25/64 loss: -0.8545846939086914
Batch 26/64 loss: -1.0663566589355469
Batch 27/64 loss: -1.1943473815917969
Batch 28/64 loss: -0.8856773376464844
Batch 29/64 loss: -1.1915302276611328
Batch 30/64 loss: -1.076798439025879
Batch 31/64 loss: -1.394993782043457
Batch 32/64 loss: -1.1007890701293945
Batch 33/64 loss: -1.1103239059448242
Batch 34/64 loss: -1.0810422897338867
Batch 35/64 loss: -1.015934944152832
Batch 36/64 loss: -1.2387323379516602
Batch 37/64 loss: -0.9832229614257812
Batch 38/64 loss: -1.1244573593139648
Batch 39/64 loss: -1.085799217224121
Batch 40/64 loss: -1.227534294128418
Batch 41/64 loss: -0.9735021591186523
Batch 42/64 loss: -0.9087629318237305
Batch 43/64 loss: -1.398763656616211
Batch 44/64 loss: -1.2847909927368164
Batch 45/64 loss: -1.0679044723510742
Batch 46/64 loss: -0.9314346313476562
Batch 47/64 loss: -1.513361930847168
Batch 48/64 loss: -1.1321954727172852
Batch 49/64 loss: -1.0896759033203125
Batch 50/64 loss: -0.9380731582641602
Batch 51/64 loss: -1.229090690612793
Batch 52/64 loss: -1.1358871459960938
Batch 53/64 loss: -1.452016830444336
Batch 54/64 loss: -1.21282958984375
Batch 55/64 loss: -0.8001213073730469
Batch 56/64 loss: -1.31500244140625
Batch 57/64 loss: -1.474752426147461
Batch 58/64 loss: -1.3809404373168945
Batch 59/64 loss: -1.3689851760864258
Batch 60/64 loss: -1.0040616989135742
Batch 61/64 loss: -0.8495054244995117
Batch 62/64 loss: -1.3630523681640625
Batch 63/64 loss: -0.8836536407470703
Batch 64/64 loss: -5.201629161834717
Epoch 151  Train loss: -1.17853131200753  Val loss: -1.2594868243764765
Epoch 152
-------------------------------
Batch 1/64 loss: -1.4441900253295898
Batch 2/64 loss: -1.1339311599731445
Batch 3/64 loss: -1.1656665802001953
Batch 4/64 loss: -1.5092716217041016
Batch 5/64 loss: -1.3975048065185547
Batch 6/64 loss: -0.9393424987792969
Batch 7/64 loss: -1.4643974304199219
Batch 8/64 loss: -0.5200271606445312
Batch 9/64 loss: -1.074936866760254
Batch 10/64 loss: -0.8444547653198242
Batch 11/64 loss: -0.5512714385986328
Batch 12/64 loss: -1.255645751953125
Batch 13/64 loss: -1.3168869018554688
Batch 14/64 loss: -1.0478191375732422
Batch 15/64 loss: -0.8684568405151367
Batch 16/64 loss: -0.8609657287597656
Batch 17/64 loss: -1.274186134338379
Batch 18/64 loss: -0.8772602081298828
Batch 19/64 loss: -1.2677316665649414
Batch 20/64 loss: -1.0516471862792969
Batch 21/64 loss: -1.4659843444824219
Batch 22/64 loss: -1.4915103912353516
Batch 23/64 loss: -0.7606496810913086
Batch 24/64 loss: -1.008148193359375
Batch 25/64 loss: -1.1664257049560547
Batch 26/64 loss: -1.2512521743774414
Batch 27/64 loss: -0.7788887023925781
Batch 28/64 loss: -0.9393444061279297
Batch 29/64 loss: -1.2228469848632812
Batch 30/64 loss: -1.2170343399047852
Batch 31/64 loss: -0.8932828903198242
Batch 32/64 loss: -1.3649587631225586
Batch 33/64 loss: -0.8346481323242188
Batch 34/64 loss: -0.4995536804199219
Batch 35/64 loss: -1.1374788284301758
Batch 36/64 loss: -1.3312978744506836
Batch 37/64 loss: -0.7466459274291992
Batch 38/64 loss: -1.2992324829101562
Batch 39/64 loss: -0.9590778350830078
Batch 40/64 loss: -0.8359270095825195
Batch 41/64 loss: -0.8542308807373047
Batch 42/64 loss: -1.3437871932983398
Batch 43/64 loss: -1.171762466430664
Batch 44/64 loss: -0.5896205902099609
Batch 45/64 loss: -1.1347455978393555
Batch 46/64 loss: -1.0975513458251953
Batch 47/64 loss: -0.9321403503417969
Batch 48/64 loss: -1.3757944107055664
Batch 49/64 loss: -0.9180498123168945
Batch 50/64 loss: -1.1179800033569336
Batch 51/64 loss: -0.011780738830566406
Batch 52/64 loss: -1.0773487091064453
Batch 53/64 loss: -0.9002590179443359
Batch 54/64 loss: -1.1125669479370117
Batch 55/64 loss: -1.2626886367797852
Batch 56/64 loss: -1.1350727081298828
Batch 57/64 loss: -1.1393976211547852
Batch 58/64 loss: -1.033738136291504
Batch 59/64 loss: -1.2279720306396484
Batch 60/64 loss: -1.153609275817871
Batch 61/64 loss: -1.3290252685546875
Batch 62/64 loss: -1.1180315017700195
Batch 63/64 loss: -1.3093385696411133
Batch 64/64 loss: -4.662696838378906
Epoch 152  Train loss: -1.1123654384239048  Val loss: -1.1321110676244361
Epoch 153
-------------------------------
Batch 1/64 loss: -1.124593734741211
Batch 2/64 loss: -0.7514801025390625
Batch 3/64 loss: -1.1613750457763672
Batch 4/64 loss: -0.9608173370361328
Batch 5/64 loss: -1.3010292053222656
Batch 6/64 loss: -1.0170507431030273
Batch 7/64 loss: -1.291956901550293
Batch 8/64 loss: -0.9488468170166016
Batch 9/64 loss: -1.3427667617797852
Batch 10/64 loss: -0.9840145111083984
Batch 11/64 loss: -0.9175882339477539
Batch 12/64 loss: -1.100616455078125
Batch 13/64 loss: -0.8245735168457031
Batch 14/64 loss: -0.7540798187255859
Batch 15/64 loss: -0.6718969345092773
Batch 16/64 loss: -0.807774543762207
Batch 17/64 loss: -1.227381706237793
Batch 18/64 loss: -0.8638792037963867
Batch 19/64 loss: -1.0733518600463867
Batch 20/64 loss: -1.2479963302612305
Batch 21/64 loss: -1.3529596328735352
Batch 22/64 loss: -1.0450057983398438
Batch 23/64 loss: -0.7059917449951172
Batch 24/64 loss: -1.2290277481079102
Batch 25/64 loss: -1.4105768203735352
Batch 26/64 loss: -1.1601533889770508
Batch 27/64 loss: -1.287734031677246
Batch 28/64 loss: -1.1655540466308594
Batch 29/64 loss: -1.1125736236572266
Batch 30/64 loss: -1.136460304260254
Batch 31/64 loss: -1.0692062377929688
Batch 32/64 loss: -1.3881244659423828
Batch 33/64 loss: -0.8896598815917969
Batch 34/64 loss: -0.7269268035888672
Batch 35/64 loss: -0.6147365570068359
Batch 36/64 loss: -1.318730354309082
Batch 37/64 loss: -0.7093467712402344
Batch 38/64 loss: -1.0060253143310547
Batch 39/64 loss: -1.0745115280151367
Batch 40/64 loss: -1.4438867568969727
Batch 41/64 loss: -0.9647045135498047
Batch 42/64 loss: -1.20843505859375
Batch 43/64 loss: -1.280125617980957
Batch 44/64 loss: -1.1244010925292969
Batch 45/64 loss: -1.538569450378418
Batch 46/64 loss: -1.210526466369629
Batch 47/64 loss: -1.3238897323608398
Batch 48/64 loss: -1.0268535614013672
Batch 49/64 loss: -1.0030994415283203
Batch 50/64 loss: -0.8354406356811523
Batch 51/64 loss: -1.0945014953613281
Batch 52/64 loss: -1.2989616394042969
Batch 53/64 loss: -1.2733259201049805
Batch 54/64 loss: -1.3191137313842773
Batch 55/64 loss: -1.6127071380615234
Batch 56/64 loss: -1.1573028564453125
Batch 57/64 loss: -1.3287162780761719
Batch 58/64 loss: -1.4236230850219727
Batch 59/64 loss: -0.8075408935546875
Batch 60/64 loss: -1.2929697036743164
Batch 61/64 loss: -1.2203245162963867
Batch 62/64 loss: -1.024031639099121
Batch 63/64 loss: -1.2627153396606445
Batch 64/64 loss: -5.559268474578857
Epoch 153  Train loss: -1.1611230233136345  Val loss: -1.218687365554862
Epoch 154
-------------------------------
Batch 1/64 loss: -0.8773469924926758
Batch 2/64 loss: -1.1240415573120117
Batch 3/64 loss: -0.9887638092041016
Batch 4/64 loss: -1.1839513778686523
Batch 5/64 loss: -1.3079395294189453
Batch 6/64 loss: -1.2938499450683594
Batch 7/64 loss: -1.4149866104125977
Batch 8/64 loss: -0.9396228790283203
Batch 9/64 loss: -0.47287559509277344
Batch 10/64 loss: -1.1228046417236328
Batch 11/64 loss: -1.0262460708618164
Batch 12/64 loss: -1.2565135955810547
Batch 13/64 loss: -0.8872556686401367
Batch 14/64 loss: -0.7285537719726562
Batch 15/64 loss: -0.8084945678710938
Batch 16/64 loss: -0.9202194213867188
Batch 17/64 loss: -1.212392807006836
Batch 18/64 loss: -1.0514135360717773
Batch 19/64 loss: -1.0806894302368164
Batch 20/64 loss: -1.3347902297973633
Batch 21/64 loss: -0.9511127471923828
Batch 22/64 loss: -1.2585458755493164
Batch 23/64 loss: -1.1382532119750977
Batch 24/64 loss: -1.4105091094970703
Batch 25/64 loss: -1.4488048553466797
Batch 26/64 loss: -1.3212556838989258
Batch 27/64 loss: -1.0925941467285156
Batch 28/64 loss: -0.8141822814941406
Batch 29/64 loss: -0.8580350875854492
Batch 30/64 loss: -1.2799186706542969
Batch 31/64 loss: -1.177988052368164
Batch 32/64 loss: -1.0749826431274414
Batch 33/64 loss: -1.1898469924926758
Batch 34/64 loss: -0.7167434692382812
Batch 35/64 loss: -0.6261787414550781
Batch 36/64 loss: -1.3585844039916992
Batch 37/64 loss: -1.2665843963623047
Batch 38/64 loss: -1.552022933959961
Batch 39/64 loss: -1.4702520370483398
Batch 40/64 loss: -1.2242250442504883
Batch 41/64 loss: -1.281686782836914
Batch 42/64 loss: -1.0856075286865234
Batch 43/64 loss: -1.4465227127075195
Batch 44/64 loss: -0.8072652816772461
Batch 45/64 loss: -0.8991765975952148
Batch 46/64 loss: -0.8352079391479492
Batch 47/64 loss: -1.2515907287597656
Batch 48/64 loss: -0.7993640899658203
Batch 49/64 loss: -1.132080078125
Batch 50/64 loss: -1.3633537292480469
Batch 51/64 loss: -0.8447837829589844
Batch 52/64 loss: -1.1566219329833984
Batch 53/64 loss: -0.9111146926879883
Batch 54/64 loss: -1.3426456451416016
Batch 55/64 loss: -1.4147796630859375
Batch 56/64 loss: -1.042841911315918
Batch 57/64 loss: -0.9885692596435547
Batch 58/64 loss: -1.1783761978149414
Batch 59/64 loss: -1.2827415466308594
Batch 60/64 loss: -1.3848800659179688
Batch 61/64 loss: -0.9783010482788086
Batch 62/64 loss: -1.0326108932495117
Batch 63/64 loss: -0.5156955718994141
Batch 64/64 loss: -5.149094581604004
Epoch 154  Train loss: -1.1466825260835536  Val loss: -1.1240687812726522
Epoch 155
-------------------------------
Batch 1/64 loss: -0.9879064559936523
Batch 2/64 loss: -1.2244606018066406
Batch 3/64 loss: -0.6462774276733398
Batch 4/64 loss: -1.3176088333129883
Batch 5/64 loss: -1.4009265899658203
Batch 6/64 loss: -1.3708829879760742
Batch 7/64 loss: -1.1265316009521484
Batch 8/64 loss: -1.010910987854004
Batch 9/64 loss: -1.169529914855957
Batch 10/64 loss: -1.3002519607543945
Batch 11/64 loss: -0.8146219253540039
Batch 12/64 loss: -0.996551513671875
Batch 13/64 loss: -1.2856569290161133
Batch 14/64 loss: -1.1787223815917969
Batch 15/64 loss: -0.866847038269043
Batch 16/64 loss: -0.6723661422729492
Batch 17/64 loss: -1.043614387512207
Batch 18/64 loss: -1.4200849533081055
Batch 19/64 loss: -1.304854393005371
Batch 20/64 loss: -1.170201301574707
Batch 21/64 loss: -1.1566095352172852
Batch 22/64 loss: -1.0850000381469727
Batch 23/64 loss: -1.2963457107543945
Batch 24/64 loss: -1.3516759872436523
Batch 25/64 loss: -1.0335559844970703
Batch 26/64 loss: -1.1153450012207031
Batch 27/64 loss: -0.9769392013549805
Batch 28/64 loss: -1.0488643646240234
Batch 29/64 loss: -1.2941112518310547
Batch 30/64 loss: -1.0453824996948242
Batch 31/64 loss: -1.1219205856323242
Batch 32/64 loss: -1.3688316345214844
Batch 33/64 loss: -0.5679149627685547
Batch 34/64 loss: -1.2629737854003906
Batch 35/64 loss: -1.1962757110595703
Batch 36/64 loss: -1.0330810546875
Batch 37/64 loss: -1.1791925430297852
Batch 38/64 loss: -1.0295915603637695
Batch 39/64 loss: -1.0265769958496094
Batch 40/64 loss: -0.026246070861816406
Batch 41/64 loss: -0.9022483825683594
Batch 42/64 loss: -1.049128532409668
Batch 43/64 loss: -1.060441017150879
Batch 44/64 loss: -1.338505744934082
Batch 45/64 loss: -1.0936250686645508
Batch 46/64 loss: -1.1126441955566406
Batch 47/64 loss: -1.270339012145996
Batch 48/64 loss: -1.0382108688354492
Batch 49/64 loss: -1.1047897338867188
Batch 50/64 loss: -1.447402000427246
Batch 51/64 loss: -1.2484006881713867
Batch 52/64 loss: -0.6967849731445312
Batch 53/64 loss: -0.47623157501220703
Batch 54/64 loss: -1.1211223602294922
Batch 55/64 loss: -1.3510456085205078
Batch 56/64 loss: -1.1580810546875
Batch 57/64 loss: -1.3733320236206055
Batch 58/64 loss: -1.049844741821289
Batch 59/64 loss: -1.3380317687988281
Batch 60/64 loss: -1.3199872970581055
Batch 61/64 loss: -1.5571413040161133
Batch 62/64 loss: -1.0750932693481445
Batch 63/64 loss: -0.7485551834106445
Batch 64/64 loss: -5.0961408615112305
Epoch 155  Train loss: -1.1494640761730717  Val loss: -1.2710406640960588
Epoch 156
-------------------------------
Batch 1/64 loss: -1.0656204223632812
Batch 2/64 loss: -0.8202447891235352
Batch 3/64 loss: -1.0884857177734375
Batch 4/64 loss: -0.9415044784545898
Batch 5/64 loss: -0.5216903686523438
Batch 6/64 loss: -1.2848377227783203
Batch 7/64 loss: -0.8762702941894531
Batch 8/64 loss: -1.223292350769043
Batch 9/64 loss: -1.2803993225097656
Batch 10/64 loss: -1.5433111190795898
Batch 11/64 loss: -1.4578218460083008
Batch 12/64 loss: -1.0979480743408203
Batch 13/64 loss: -0.49642372131347656
Batch 14/64 loss: -1.1437597274780273
Batch 15/64 loss: -1.2928857803344727
Batch 16/64 loss: -1.3048391342163086
Batch 17/64 loss: -1.045731544494629
Batch 18/64 loss: -0.9306697845458984
Batch 19/64 loss: -1.15643310546875
Batch 20/64 loss: -0.917724609375
Batch 21/64 loss: -1.2585763931274414
Batch 22/64 loss: -1.181427001953125
Batch 23/64 loss: -1.166982650756836
Batch 24/64 loss: -1.3904352188110352
Batch 25/64 loss: -0.8000679016113281
Batch 26/64 loss: -0.8294897079467773
Batch 27/64 loss: -1.3146123886108398
Batch 28/64 loss: -0.9323196411132812
Batch 29/64 loss: -1.4235153198242188
Batch 30/64 loss: -1.0989961624145508
Batch 31/64 loss: -1.1268348693847656
Batch 32/64 loss: -0.9306936264038086
Batch 33/64 loss: -0.8704137802124023
Batch 34/64 loss: -1.1351327896118164
Batch 35/64 loss: -1.0219507217407227
Batch 36/64 loss: -1.2440462112426758
Batch 37/64 loss: -1.3352460861206055
Batch 38/64 loss: -1.6114025115966797
Batch 39/64 loss: -1.081125259399414
Batch 40/64 loss: -1.1819610595703125
Batch 41/64 loss: -1.3222246170043945
Batch 42/64 loss: -1.341670036315918
Batch 43/64 loss: -1.2298507690429688
Batch 44/64 loss: -1.2379798889160156
Batch 45/64 loss: -0.9801387786865234
Batch 46/64 loss: -1.5077018737792969
Batch 47/64 loss: -1.317678451538086
Batch 48/64 loss: -0.9295578002929688
Batch 49/64 loss: -1.1561346054077148
Batch 50/64 loss: -1.5678009986877441
Batch 51/64 loss: -1.0058813095092773
Batch 52/64 loss: -1.371591567993164
Batch 53/64 loss: -0.9960660934448242
Batch 54/64 loss: -1.5042495727539062
Batch 55/64 loss: -1.0058727264404297
Batch 56/64 loss: -1.0437164306640625
Batch 57/64 loss: -0.6139984130859375
Batch 58/64 loss: -1.031961441040039
Batch 59/64 loss: -1.3348894119262695
Batch 60/64 loss: -1.0458650588989258
Batch 61/64 loss: -1.1811723709106445
Batch 62/64 loss: -1.0157861709594727
Batch 63/64 loss: -1.2030601501464844
Batch 64/64 loss: -5.057944297790527
Epoch 156  Train loss: -1.179034195694269  Val loss: -1.2750888313214803
Epoch 157
-------------------------------
Batch 1/64 loss: -0.8841524124145508
Batch 2/64 loss: -1.3608627319335938
Batch 3/64 loss: -1.2862977981567383
Batch 4/64 loss: -0.6457729339599609
Batch 5/64 loss: -0.9866609573364258
Batch 6/64 loss: -0.8380403518676758
Batch 7/64 loss: -1.4502878189086914
Batch 8/64 loss: -0.8721599578857422
Batch 9/64 loss: -1.1900310516357422
Batch 10/64 loss: -1.3379526138305664
Batch 11/64 loss: -1.1972017288208008
Batch 12/64 loss: -0.7396669387817383
Batch 13/64 loss: -0.9851655960083008
Batch 14/64 loss: -1.1156120300292969
Batch 15/64 loss: -0.9903144836425781
Batch 16/64 loss: -0.8819894790649414
Batch 17/64 loss: -1.0299997329711914
Batch 18/64 loss: -1.262904167175293
Batch 19/64 loss: -0.7853679656982422
Batch 20/64 loss: -0.751927375793457
Batch 21/64 loss: -1.2578868865966797
Batch 22/64 loss: -1.1779937744140625
Batch 23/64 loss: -1.0042610168457031
Batch 24/64 loss: -1.2427501678466797
Batch 25/64 loss: -1.0508718490600586
Batch 26/64 loss: -1.1045293807983398
Batch 27/64 loss: -0.8111839294433594
Batch 28/64 loss: -0.8859491348266602
Batch 29/64 loss: -1.2900257110595703
Batch 30/64 loss: -1.3928461074829102
Batch 31/64 loss: -1.1572446823120117
Batch 32/64 loss: -1.3029870986938477
Batch 33/64 loss: -1.2013874053955078
Batch 34/64 loss: -1.3121013641357422
Batch 35/64 loss: -1.3497581481933594
Batch 36/64 loss: -1.2418861389160156
Batch 37/64 loss: -1.169022560119629
Batch 38/64 loss: -1.1020851135253906
Batch 39/64 loss: -1.2288236618041992
Batch 40/64 loss: -1.4453840255737305
Batch 41/64 loss: -0.9011163711547852
Batch 42/64 loss: -1.1715507507324219
Batch 43/64 loss: -0.9853763580322266
Batch 44/64 loss: -0.9772663116455078
Batch 45/64 loss: -0.892024040222168
Batch 46/64 loss: -1.2479190826416016
Batch 47/64 loss: -1.0223388671875
Batch 48/64 loss: -1.48345947265625
Batch 49/64 loss: -0.659759521484375
Batch 50/64 loss: -1.1281251907348633
Batch 51/64 loss: -1.4682292938232422
Batch 52/64 loss: -1.0896339416503906
Batch 53/64 loss: -1.506546974182129
Batch 54/64 loss: -0.8080196380615234
Batch 55/64 loss: -1.0063810348510742
Batch 56/64 loss: -1.1653413772583008
Batch 57/64 loss: -1.1536645889282227
Batch 58/64 loss: -0.920649528503418
Batch 59/64 loss: -1.257476806640625
Batch 60/64 loss: -1.2001056671142578
Batch 61/64 loss: -0.9957380294799805
Batch 62/64 loss: -1.1564960479736328
Batch 63/64 loss: -1.134099006652832
Batch 64/64 loss: -4.973824501037598
Epoch 157  Train loss: -1.1511063931035062  Val loss: -1.318257426887853
Saving best model, epoch: 157
Epoch 158
-------------------------------
Batch 1/64 loss: -1.4035463333129883
Batch 2/64 loss: -1.386124610900879
Batch 3/64 loss: -1.247995376586914
Batch 4/64 loss: -0.893589973449707
Batch 5/64 loss: -1.1928300857543945
Batch 6/64 loss: -1.0965604782104492
Batch 7/64 loss: -1.3492794036865234
Batch 8/64 loss: -1.0364036560058594
Batch 9/64 loss: -1.2543258666992188
Batch 10/64 loss: -0.9408683776855469
Batch 11/64 loss: -1.1714019775390625
Batch 12/64 loss: -1.3284196853637695
Batch 13/64 loss: -1.1955986022949219
Batch 14/64 loss: -1.2743854522705078
Batch 15/64 loss: -0.889373779296875
Batch 16/64 loss: -1.136580467224121
Batch 17/64 loss: -1.116023063659668
Batch 18/64 loss: -1.5985040664672852
Batch 19/64 loss: -1.298666000366211
Batch 20/64 loss: -0.8168354034423828
Batch 21/64 loss: -1.1155595779418945
Batch 22/64 loss: -1.0288972854614258
Batch 23/64 loss: -1.0867462158203125
Batch 24/64 loss: -1.2437915802001953
Batch 25/64 loss: -1.3929319381713867
Batch 26/64 loss: -1.330514907836914
Batch 27/64 loss: -0.9123525619506836
Batch 28/64 loss: -1.4758901596069336
Batch 29/64 loss: -0.9983787536621094
Batch 30/64 loss: -1.1789350509643555
Batch 31/64 loss: -1.1706056594848633
Batch 32/64 loss: -1.6806697845458984
Batch 33/64 loss: -0.7922573089599609
Batch 34/64 loss: -1.4187746047973633
Batch 35/64 loss: -1.3610448837280273
Batch 36/64 loss: -1.2583465576171875
Batch 37/64 loss: -1.3444414138793945
Batch 38/64 loss: -1.2119503021240234
Batch 39/64 loss: -1.4599294662475586
Batch 40/64 loss: -1.1492557525634766
Batch 41/64 loss: -1.054727554321289
Batch 42/64 loss: -1.1489696502685547
Batch 43/64 loss: -0.7335577011108398
Batch 44/64 loss: -1.1189298629760742
Batch 45/64 loss: -1.1719131469726562
Batch 46/64 loss: -1.5034542083740234
Batch 47/64 loss: -0.8315601348876953
Batch 48/64 loss: -1.2187881469726562
Batch 49/64 loss: -1.4266881942749023
Batch 50/64 loss: -1.388986587524414
Batch 51/64 loss: -1.2921247482299805
Batch 52/64 loss: -1.1174144744873047
Batch 53/64 loss: -1.2015876770019531
Batch 54/64 loss: -0.7830972671508789
Batch 55/64 loss: -1.3394489288330078
Batch 56/64 loss: -1.1909351348876953
Batch 57/64 loss: -1.0669059753417969
Batch 58/64 loss: -0.9476470947265625
Batch 59/64 loss: -1.0898590087890625
Batch 60/64 loss: -1.2219066619873047
Batch 61/64 loss: -1.5408868789672852
Batch 62/64 loss: -1.1092357635498047
Batch 63/64 loss: -1.131789207458496
Batch 64/64 loss: -5.53980827331543
Epoch 158  Train loss: -1.2395899080762676  Val loss: -1.2544308691909634
Epoch 159
-------------------------------
Batch 1/64 loss: -1.112351417541504
Batch 2/64 loss: -1.2237424850463867
Batch 3/64 loss: -1.3799753189086914
Batch 4/64 loss: -1.1430225372314453
Batch 5/64 loss: -1.1473808288574219
Batch 6/64 loss: -1.2865819931030273
Batch 7/64 loss: -1.2928619384765625
Batch 8/64 loss: -1.150186538696289
Batch 9/64 loss: -1.109487533569336
Batch 10/64 loss: -1.209425926208496
Batch 11/64 loss: -1.3216114044189453
Batch 12/64 loss: -1.395050048828125
Batch 13/64 loss: -1.3683109283447266
Batch 14/64 loss: -0.9827814102172852
Batch 15/64 loss: -1.449599266052246
Batch 16/64 loss: -1.067068099975586
Batch 17/64 loss: -1.0899629592895508
Batch 18/64 loss: -1.2576122283935547
Batch 19/64 loss: -1.282425880432129
Batch 20/64 loss: -1.1125478744506836
Batch 21/64 loss: -1.1037168502807617
Batch 22/64 loss: -1.634251594543457
Batch 23/64 loss: -1.2108383178710938
Batch 24/64 loss: -1.478226661682129
Batch 25/64 loss: -1.1924619674682617
Batch 26/64 loss: -1.111374855041504
Batch 27/64 loss: -0.9928140640258789
Batch 28/64 loss: -1.2049446105957031
Batch 29/64 loss: -0.5644712448120117
Batch 30/64 loss: -1.390420913696289
Batch 31/64 loss: -1.3471269607543945
Batch 32/64 loss: -1.2769956588745117
Batch 33/64 loss: -1.5143632888793945
Batch 34/64 loss: -1.2120485305786133
Batch 35/64 loss: -0.9171915054321289
Batch 36/64 loss: -1.0982990264892578
Batch 37/64 loss: -1.3648920059204102
Batch 38/64 loss: -1.4142951965332031
Batch 39/64 loss: -1.2776269912719727
Batch 40/64 loss: -1.1253538131713867
Batch 41/64 loss: -1.0564031600952148
Batch 42/64 loss: -1.1047239303588867
Batch 43/64 loss: -1.2650423049926758
Batch 44/64 loss: -1.4722404479980469
Batch 45/64 loss: -1.37939453125
Batch 46/64 loss: -1.4742746353149414
Batch 47/64 loss: -1.1292915344238281
Batch 48/64 loss: -1.5909929275512695
Batch 49/64 loss: -1.3413276672363281
Batch 50/64 loss: -1.2176885604858398
Batch 51/64 loss: -1.1843509674072266
Batch 52/64 loss: -1.1943378448486328
Batch 53/64 loss: -1.1638011932373047
Batch 54/64 loss: -0.8201713562011719
Batch 55/64 loss: -0.9304733276367188
Batch 56/64 loss: -0.9710817337036133
Batch 57/64 loss: -1.386448860168457
Batch 58/64 loss: -1.1414051055908203
Batch 59/64 loss: -1.1068735122680664
Batch 60/64 loss: -1.3382549285888672
Batch 61/64 loss: -1.1026191711425781
Batch 62/64 loss: -1.1337213516235352
Batch 63/64 loss: -1.3450450897216797
Batch 64/64 loss: -5.281661033630371
Epoch 159  Train loss: -1.2647044798907112  Val loss: -1.26644792589535
Epoch 160
-------------------------------
Batch 1/64 loss: -1.1310997009277344
Batch 2/64 loss: -0.32914066314697266
Batch 3/64 loss: -1.1149282455444336
Batch 4/64 loss: -1.4802942276000977
Batch 5/64 loss: -1.1159448623657227
Batch 6/64 loss: -0.9600133895874023
Batch 7/64 loss: -1.2247657775878906
Batch 8/64 loss: -1.3707456588745117
Batch 9/64 loss: -1.1426944732666016
Batch 10/64 loss: -1.2521047592163086
Batch 11/64 loss: -1.3389472961425781
Batch 12/64 loss: -0.6120901107788086
Batch 13/64 loss: -1.1627769470214844
Batch 14/64 loss: -1.1136655807495117
Batch 15/64 loss: -0.8626308441162109
Batch 16/64 loss: -1.1195287704467773
Batch 17/64 loss: -1.466486930847168
Batch 18/64 loss: -1.2000226974487305
Batch 19/64 loss: -1.1964492797851562
Batch 20/64 loss: -0.9739627838134766
Batch 21/64 loss: -1.1963977813720703
Batch 22/64 loss: -1.1978588104248047
Batch 23/64 loss: -1.0446147918701172
Batch 24/64 loss: -0.8044300079345703
Batch 25/64 loss: -0.851597785949707
Batch 26/64 loss: -1.5575265884399414
Batch 27/64 loss: -1.3063554763793945
Batch 28/64 loss: -1.321197509765625
Batch 29/64 loss: -1.2142200469970703
Batch 30/64 loss: -1.4676313400268555
Batch 31/64 loss: -1.1052255630493164
Batch 32/64 loss: -1.5104103088378906
Batch 33/64 loss: -1.27935791015625
Batch 34/64 loss: -1.5281057357788086
Batch 35/64 loss: -1.462510108947754
Batch 36/64 loss: -1.3859167098999023
Batch 37/64 loss: -1.3058958053588867
Batch 38/64 loss: -1.0315265655517578
Batch 39/64 loss: -1.239293098449707
Batch 40/64 loss: -0.8459529876708984
Batch 41/64 loss: -1.2331371307373047
Batch 42/64 loss: -1.0920448303222656
Batch 43/64 loss: -0.9612054824829102
Batch 44/64 loss: -1.2599859237670898
Batch 45/64 loss: -1.1757726669311523
Batch 46/64 loss: -0.9536542892456055
Batch 47/64 loss: -1.1748332977294922
Batch 48/64 loss: -1.2407779693603516
Batch 49/64 loss: -1.031778335571289
Batch 50/64 loss: -0.8519477844238281
Batch 51/64 loss: -0.5846958160400391
Batch 52/64 loss: -1.0391120910644531
Batch 53/64 loss: -1.3164081573486328
Batch 54/64 loss: -1.1650018692016602
Batch 55/64 loss: -1.2528533935546875
Batch 56/64 loss: -1.1703472137451172
Batch 57/64 loss: -0.7759475708007812
Batch 58/64 loss: -1.1514263153076172
Batch 59/64 loss: -1.3048105239868164
Batch 60/64 loss: -1.1442193984985352
Batch 61/64 loss: -1.2301225662231445
Batch 62/64 loss: -0.9624490737915039
Batch 63/64 loss: -1.0384407043457031
Batch 64/64 loss: -5.0969109535217285
Epoch 160  Train loss: -1.1883603694392186  Val loss: -1.2538934425799708
Epoch 161
-------------------------------
Batch 1/64 loss: -1.3435821533203125
Batch 2/64 loss: -1.0120172500610352
Batch 3/64 loss: -0.912287712097168
Batch 4/64 loss: -1.2033109664916992
Batch 5/64 loss: -1.146820068359375
Batch 6/64 loss: -1.1384897232055664
Batch 7/64 loss: -0.6824398040771484
Batch 8/64 loss: -1.1502742767333984
Batch 9/64 loss: -1.4456281661987305
Batch 10/64 loss: -1.2183008193969727
Batch 11/64 loss: -0.909428596496582
Batch 12/64 loss: -1.0230693817138672
Batch 13/64 loss: -1.3572044372558594
Batch 14/64 loss: -1.365011215209961
Batch 15/64 loss: -1.5289344787597656
Batch 16/64 loss: -0.9709930419921875
Batch 17/64 loss: -1.206313133239746
Batch 18/64 loss: -1.1202478408813477
Batch 19/64 loss: -1.285231590270996
Batch 20/64 loss: -1.589491844177246
Batch 21/64 loss: -1.1595478057861328
Batch 22/64 loss: -0.7961692810058594
Batch 23/64 loss: -0.9198780059814453
Batch 24/64 loss: -1.3211078643798828
Batch 25/64 loss: -0.3263425827026367
Batch 26/64 loss: -0.9504203796386719
Batch 27/64 loss: -1.1811294555664062
Batch 28/64 loss: -1.118361473083496
Batch 29/64 loss: -0.8221464157104492
Batch 30/64 loss: -1.06884765625
Batch 31/64 loss: -1.0327491760253906
Batch 32/64 loss: -1.0550079345703125
Batch 33/64 loss: -1.4732122421264648
Batch 34/64 loss: -1.241164207458496
Batch 35/64 loss: -1.4622011184692383
Batch 36/64 loss: -1.3609371185302734
Batch 37/64 loss: -1.1735916137695312
Batch 38/64 loss: -0.6067209243774414
Batch 39/64 loss: -0.9762067794799805
Batch 40/64 loss: -1.2804193496704102
Batch 41/64 loss: -1.1408491134643555
Batch 42/64 loss: -1.435938835144043
Batch 43/64 loss: -0.8268756866455078
Batch 44/64 loss: -1.0453577041625977
Batch 45/64 loss: -1.315751075744629
Batch 46/64 loss: -0.9741010665893555
Batch 47/64 loss: -0.9925985336303711
Batch 48/64 loss: -1.388895034790039
Batch 49/64 loss: -1.435542106628418
Batch 50/64 loss: -0.8460674285888672
Batch 51/64 loss: -1.4997386932373047
Batch 52/64 loss: -1.2111310958862305
Batch 53/64 loss: -1.1284284591674805
Batch 54/64 loss: -1.4757232666015625
Batch 55/64 loss: -1.1437644958496094
Batch 56/64 loss: -1.337850570678711
Batch 57/64 loss: -1.159398078918457
Batch 58/64 loss: -1.3738603591918945
Batch 59/64 loss: -1.0943756103515625
Batch 60/64 loss: -1.3691635131835938
Batch 61/64 loss: -1.0894193649291992
Batch 62/64 loss: -1.4342451095581055
Batch 63/64 loss: -0.7551450729370117
Batch 64/64 loss: -5.262266159057617
Epoch 161  Train loss: -1.1977436514461741  Val loss: -1.372276358588045
Saving best model, epoch: 161
Epoch 162
-------------------------------
Batch 1/64 loss: -0.9323358535766602
Batch 2/64 loss: -1.3974075317382812
Batch 3/64 loss: -1.4693384170532227
Batch 4/64 loss: -1.2434921264648438
Batch 5/64 loss: -1.3912715911865234
Batch 6/64 loss: -1.211623191833496
Batch 7/64 loss: -1.3979825973510742
Batch 8/64 loss: -0.6965579986572266
Batch 9/64 loss: -1.0849609375
Batch 10/64 loss: -1.2413139343261719
Batch 11/64 loss: -1.4784555435180664
Batch 12/64 loss: -1.407567024230957
Batch 13/64 loss: -1.3159685134887695
Batch 14/64 loss: -1.394516944885254
Batch 15/64 loss: -1.4798650741577148
Batch 16/64 loss: -1.4066381454467773
Batch 17/64 loss: -1.123641014099121
Batch 18/64 loss: -1.3713970184326172
Batch 19/64 loss: -1.480616569519043
Batch 20/64 loss: -1.2996253967285156
Batch 21/64 loss: -1.3722295761108398
Batch 22/64 loss: -1.2191925048828125
Batch 23/64 loss: -1.0988597869873047
Batch 24/64 loss: -0.8178520202636719
Batch 25/64 loss: -1.1858797073364258
Batch 26/64 loss: -1.113046646118164
Batch 27/64 loss: -1.2877178192138672
Batch 28/64 loss: -0.9185733795166016
Batch 29/64 loss: -1.4361629486083984
Batch 30/64 loss: -1.2463569641113281
Batch 31/64 loss: -0.8886852264404297
Batch 32/64 loss: -1.3417768478393555
Batch 33/64 loss: -0.835392951965332
Batch 34/64 loss: -1.1385602951049805
Batch 35/64 loss: -1.2405023574829102
Batch 36/64 loss: -1.4203786849975586
Batch 37/64 loss: -1.2606687545776367
Batch 38/64 loss: -1.2468557357788086
Batch 39/64 loss: -0.8456850051879883
Batch 40/64 loss: -0.8964405059814453
Batch 41/64 loss: -1.264470100402832
Batch 42/64 loss: -1.3212270736694336
Batch 43/64 loss: -1.2357673645019531
Batch 44/64 loss: -1.0924739837646484
Batch 45/64 loss: -1.369807243347168
Batch 46/64 loss: -0.95892333984375
Batch 47/64 loss: -1.0851116180419922
Batch 48/64 loss: -0.8847780227661133
Batch 49/64 loss: -0.7842588424682617
Batch 50/64 loss: -1.4092512130737305
Batch 51/64 loss: -0.9692649841308594
Batch 52/64 loss: -1.0587778091430664
Batch 53/64 loss: -0.8557291030883789
Batch 54/64 loss: -1.5926685333251953
Batch 55/64 loss: -1.3547430038452148
Batch 56/64 loss: -1.0504779815673828
Batch 57/64 loss: -1.1515064239501953
Batch 58/64 loss: -1.3238592147827148
Batch 59/64 loss: -1.272369384765625
Batch 60/64 loss: -1.0773544311523438
Batch 61/64 loss: -1.2700042724609375
Batch 62/64 loss: -1.1848773956298828
Batch 63/64 loss: -0.9817380905151367
Batch 64/64 loss: -5.392800807952881
Epoch 162  Train loss: -1.2428146381004184  Val loss: -1.3538195292154949
Epoch 163
-------------------------------
Batch 1/64 loss: -1.2420787811279297
Batch 2/64 loss: -1.1218023300170898
Batch 3/64 loss: -1.065155029296875
Batch 4/64 loss: -1.286294937133789
Batch 5/64 loss: -1.3403615951538086
Batch 6/64 loss: -1.2717504501342773
Batch 7/64 loss: -1.041703224182129
Batch 8/64 loss: -1.1744251251220703
Batch 9/64 loss: -1.028726577758789
Batch 10/64 loss: -1.2402162551879883
Batch 11/64 loss: -0.9353303909301758
Batch 12/64 loss: -1.2616157531738281
Batch 13/64 loss: -1.3615961074829102
Batch 14/64 loss: -1.061422348022461
Batch 15/64 loss: -1.0546188354492188
Batch 16/64 loss: -1.4137020111083984
Batch 17/64 loss: -1.2196044921875
Batch 18/64 loss: -0.4796257019042969
Batch 19/64 loss: -0.7077713012695312
Batch 20/64 loss: -1.272444725036621
Batch 21/64 loss: -1.2548017501831055
Batch 22/64 loss: -1.247096061706543
Batch 23/64 loss: -1.3208379745483398
Batch 24/64 loss: -1.5551033020019531
Batch 25/64 loss: -1.145193099975586
Batch 26/64 loss: -1.0551748275756836
Batch 27/64 loss: -1.2736425399780273
Batch 28/64 loss: -1.2523679733276367
Batch 29/64 loss: -1.3587360382080078
Batch 30/64 loss: -1.2037382125854492
Batch 31/64 loss: -1.4610166549682617
Batch 32/64 loss: -1.0013971328735352
Batch 33/64 loss: -0.9670896530151367
Batch 34/64 loss: -1.0802421569824219
Batch 35/64 loss: -1.465611457824707
Batch 36/64 loss: -0.9092302322387695
Batch 37/64 loss: -1.256216049194336
Batch 38/64 loss: -1.073298454284668
Batch 39/64 loss: -1.2323875427246094
Batch 40/64 loss: -1.2859888076782227
Batch 41/64 loss: -1.0873327255249023
Batch 42/64 loss: -0.9465599060058594
Batch 43/64 loss: -1.2042932510375977
Batch 44/64 loss: -1.1268463134765625
Batch 45/64 loss: -1.3582277297973633
Batch 46/64 loss: -0.75689697265625
Batch 47/64 loss: -1.127716064453125
Batch 48/64 loss: -1.1628227233886719
Batch 49/64 loss: -0.8840446472167969
Batch 50/64 loss: -1.1479825973510742
Batch 51/64 loss: -1.000020980834961
Batch 52/64 loss: -1.0406160354614258
Batch 53/64 loss: -0.9932136535644531
Batch 54/64 loss: -1.3377084732055664
Batch 55/64 loss: -1.056422233581543
Batch 56/64 loss: -1.4411191940307617
Batch 57/64 loss: -1.3527193069458008
Batch 58/64 loss: -1.6768512725830078
Batch 59/64 loss: -1.1976203918457031
Batch 60/64 loss: -1.2953643798828125
Batch 61/64 loss: -0.6583251953125
Batch 62/64 loss: -1.2430667877197266
Batch 63/64 loss: -1.6907663345336914
Batch 64/64 loss: -5.325979709625244
Epoch 163  Train loss: -1.2197715740577848  Val loss: -1.1832049523841883
Epoch 164
-------------------------------
Batch 1/64 loss: -1.3740348815917969
Batch 2/64 loss: -1.4017457962036133
Batch 3/64 loss: -1.2639408111572266
Batch 4/64 loss: -1.1156129837036133
Batch 5/64 loss: -1.0372991561889648
Batch 6/64 loss: -1.012751579284668
Batch 7/64 loss: -1.1503448486328125
Batch 8/64 loss: -0.9836978912353516
Batch 9/64 loss: -1.3792171478271484
Batch 10/64 loss: -1.3449907302856445
Batch 11/64 loss: -1.1593742370605469
Batch 12/64 loss: -1.0611066818237305
Batch 13/64 loss: -1.1717042922973633
Batch 14/64 loss: -1.3801345825195312
Batch 15/64 loss: -1.0369033813476562
Batch 16/64 loss: -1.3139095306396484
Batch 17/64 loss: -1.2339715957641602
Batch 18/64 loss: -1.0830812454223633
Batch 19/64 loss: -1.2017545700073242
Batch 20/64 loss: -1.1304988861083984
Batch 21/64 loss: -1.1131515502929688
Batch 22/64 loss: -1.2415142059326172
Batch 23/64 loss: -1.1116905212402344
Batch 24/64 loss: -1.410745620727539
Batch 25/64 loss: -1.2085142135620117
Batch 26/64 loss: -1.4474658966064453
Batch 27/64 loss: -1.3740968704223633
Batch 28/64 loss: -0.4477577209472656
Batch 29/64 loss: -1.1441755294799805
Batch 30/64 loss: -1.5413665771484375
Batch 31/64 loss: -1.0516424179077148
Batch 32/64 loss: -1.0757713317871094
Batch 33/64 loss: -0.4433469772338867
Batch 34/64 loss: -1.2741756439208984
Batch 35/64 loss: -1.079763412475586
Batch 36/64 loss: -0.9039716720581055
Batch 37/64 loss: -1.3217105865478516
Batch 38/64 loss: -0.9209747314453125
Batch 39/64 loss: -0.9139947891235352
Batch 40/64 loss: -1.278707504272461
Batch 41/64 loss: -1.1099281311035156
Batch 42/64 loss: -1.2641677856445312
Batch 43/64 loss: -1.3063364028930664
Batch 44/64 loss: -1.2443103790283203
Batch 45/64 loss: -0.8476495742797852
Batch 46/64 loss: -1.0127553939819336
Batch 47/64 loss: -0.8594512939453125
Batch 48/64 loss: -1.2044858932495117
Batch 49/64 loss: -0.8120212554931641
Batch 50/64 loss: -1.2179622650146484
Batch 51/64 loss: -1.1388673782348633
Batch 52/64 loss: -1.2813329696655273
Batch 53/64 loss: -0.5978670120239258
Batch 54/64 loss: -1.2231874465942383
Batch 55/64 loss: -1.332566261291504
Batch 56/64 loss: -0.9325332641601562
Batch 57/64 loss: -0.5861577987670898
Batch 58/64 loss: -1.4048223495483398
Batch 59/64 loss: -1.342646598815918
Batch 60/64 loss: -1.0542001724243164
Batch 61/64 loss: -1.39752197265625
Batch 62/64 loss: -0.7159528732299805
Batch 63/64 loss: -1.4280385971069336
Batch 64/64 loss: -5.094912052154541
Epoch 164  Train loss: -1.1808087797725901  Val loss: -1.2833715746902519
Epoch 165
-------------------------------
Batch 1/64 loss: -1.0648975372314453
Batch 2/64 loss: -1.1685209274291992
Batch 3/64 loss: -1.6187429428100586
Batch 4/64 loss: -0.8826313018798828
Batch 5/64 loss: -0.8207206726074219
Batch 6/64 loss: -1.4481401443481445
Batch 7/64 loss: -1.2672853469848633
Batch 8/64 loss: -1.1776018142700195
Batch 9/64 loss: -0.7694234848022461
Batch 10/64 loss: -0.9949474334716797
Batch 11/64 loss: -0.8091182708740234
Batch 12/64 loss: -0.8373880386352539
Batch 13/64 loss: -0.9509286880493164
Batch 14/64 loss: -1.2844562530517578
Batch 15/64 loss: -1.0940065383911133
Batch 16/64 loss: -1.359267234802246
Batch 17/64 loss: -1.1594533920288086
Batch 18/64 loss: -1.2934293746948242
Batch 19/64 loss: -1.3312139511108398
Batch 20/64 loss: -0.8822736740112305
Batch 21/64 loss: -1.3318367004394531
Batch 22/64 loss: -1.1543703079223633
Batch 23/64 loss: -1.0508766174316406
Batch 24/64 loss: -1.373225212097168
Batch 25/64 loss: -1.3458232879638672
Batch 26/64 loss: -0.8567771911621094
Batch 27/64 loss: -1.1253833770751953
Batch 28/64 loss: -1.3316535949707031
Batch 29/64 loss: -1.2067594528198242
Batch 30/64 loss: -0.39936065673828125
Batch 31/64 loss: -1.0310688018798828
Batch 32/64 loss: -1.4355182647705078
Batch 33/64 loss: -1.232100486755371
Batch 34/64 loss: -1.129659652709961
Batch 35/64 loss: -1.1690587997436523
Batch 36/64 loss: -1.0318965911865234
Batch 37/64 loss: -1.3000965118408203
Batch 38/64 loss: -1.4050674438476562
Batch 39/64 loss: -0.8554859161376953
Batch 40/64 loss: -1.0656156539916992
Batch 41/64 loss: -1.1600255966186523
Batch 42/64 loss: -1.095686912536621
Batch 43/64 loss: -1.0797863006591797
Batch 44/64 loss: -1.5006380081176758
Batch 45/64 loss: -0.9531335830688477
Batch 46/64 loss: -1.2121667861938477
Batch 47/64 loss: -1.1613283157348633
Batch 48/64 loss: -0.5739212036132812
Batch 49/64 loss: -1.4843645095825195
Batch 50/64 loss: -0.9240045547485352
Batch 51/64 loss: -1.4522504806518555
Batch 52/64 loss: -1.0102291107177734
Batch 53/64 loss: -0.8565216064453125
Batch 54/64 loss: -1.2988739013671875
Batch 55/64 loss: -0.4591817855834961
Batch 56/64 loss: -1.063380241394043
Batch 57/64 loss: -1.1645755767822266
Batch 58/64 loss: -1.3179855346679688
Batch 59/64 loss: -1.0480918884277344
Batch 60/64 loss: -1.4121589660644531
Batch 61/64 loss: -0.9062776565551758
Batch 62/64 loss: -0.8086271286010742
Batch 63/64 loss: -1.4909944534301758
Batch 64/64 loss: -5.487321853637695
Epoch 165  Train loss: -1.170129835839365  Val loss: -1.2559025820178265
Epoch 166
-------------------------------
Batch 1/64 loss: -1.0504875183105469
Batch 2/64 loss: -1.3709535598754883
Batch 3/64 loss: -0.9078273773193359
Batch 4/64 loss: -1.1834831237792969
Batch 5/64 loss: -1.111680030822754
Batch 6/64 loss: -1.1174097061157227
Batch 7/64 loss: -1.2996292114257812
Batch 8/64 loss: -1.5129108428955078
Batch 9/64 loss: -1.2573432922363281
Batch 10/64 loss: -1.3467426300048828
Batch 11/64 loss: -1.3384284973144531
Batch 12/64 loss: -0.8824310302734375
Batch 13/64 loss: -1.3741464614868164
Batch 14/64 loss: -0.9790563583374023
Batch 15/64 loss: -1.2419166564941406
Batch 16/64 loss: -1.0796394348144531
Batch 17/64 loss: -1.2817888259887695
Batch 18/64 loss: -0.9683599472045898
Batch 19/64 loss: -0.9669246673583984
Batch 20/64 loss: -0.940216064453125
Batch 21/64 loss: -1.1261539459228516
Batch 22/64 loss: -1.2300033569335938
Batch 23/64 loss: -0.9110603332519531
Batch 24/64 loss: -0.8899965286254883
Batch 25/64 loss: -1.2965326309204102
Batch 26/64 loss: -1.226323127746582
Batch 27/64 loss: -1.2849836349487305
Batch 28/64 loss: -1.3585615158081055
Batch 29/64 loss: -0.8148136138916016
Batch 30/64 loss: -0.815587043762207
Batch 31/64 loss: -1.3830804824829102
Batch 32/64 loss: -1.0235776901245117
Batch 33/64 loss: -1.2120494842529297
Batch 34/64 loss: -1.3281354904174805
Batch 35/64 loss: -1.2036399841308594
Batch 36/64 loss: -1.2352285385131836
Batch 37/64 loss: -1.3833131790161133
Batch 38/64 loss: -1.3478736877441406
Batch 39/64 loss: -0.9895925521850586
Batch 40/64 loss: -0.7226762771606445
Batch 41/64 loss: -1.0557336807250977
Batch 42/64 loss: -1.0610227584838867
Batch 43/64 loss: -1.1643400192260742
Batch 44/64 loss: -0.8221845626831055
Batch 45/64 loss: -1.1199817657470703
Batch 46/64 loss: -1.346989631652832
Batch 47/64 loss: -1.1096630096435547
Batch 48/64 loss: -1.0799016952514648
Batch 49/64 loss: -0.8811550140380859
Batch 50/64 loss: -1.292475700378418
Batch 51/64 loss: -1.3631553649902344
Batch 52/64 loss: -0.9898614883422852
Batch 53/64 loss: -1.281611442565918
Batch 54/64 loss: -1.5587100982666016
Batch 55/64 loss: -1.2843589782714844
Batch 56/64 loss: -1.3326797485351562
Batch 57/64 loss: -1.0581159591674805
Batch 58/64 loss: -1.1555967330932617
Batch 59/64 loss: -1.343703269958496
Batch 60/64 loss: -1.339299201965332
Batch 61/64 loss: -1.462998390197754
Batch 62/64 loss: -1.2760839462280273
Batch 63/64 loss: -1.051595687866211
Batch 64/64 loss: -5.31632137298584
Epoch 166  Train loss: -1.2143218433155734  Val loss: -1.3666587908243395
Epoch 167
-------------------------------
Batch 1/64 loss: -1.3107061386108398
Batch 2/64 loss: -1.4039316177368164
Batch 3/64 loss: -1.3437519073486328
Batch 4/64 loss: -0.5886955261230469
Batch 5/64 loss: -1.387826919555664
Batch 6/64 loss: -0.8893394470214844
Batch 7/64 loss: -1.3624143600463867
Batch 8/64 loss: -0.9709072113037109
Batch 9/64 loss: -0.8597593307495117
Batch 10/64 loss: -1.284775733947754
Batch 11/64 loss: -1.1937179565429688
Batch 12/64 loss: -1.1329374313354492
Batch 13/64 loss: -1.2816505432128906
Batch 14/64 loss: -1.4152164459228516
Batch 15/64 loss: -1.5132474899291992
Batch 16/64 loss: -0.846949577331543
Batch 17/64 loss: -1.1682262420654297
Batch 18/64 loss: -1.5744237899780273
Batch 19/64 loss: -1.378767967224121
Batch 20/64 loss: -1.4943456649780273
Batch 21/64 loss: -1.4823074340820312
Batch 22/64 loss: -1.1289176940917969
Batch 23/64 loss: -1.2593793869018555
Batch 24/64 loss: -1.355001449584961
Batch 25/64 loss: -1.4841842651367188
Batch 26/64 loss: -1.5185661315917969
Batch 27/64 loss: -0.8011560440063477
Batch 28/64 loss: -1.454751968383789
Batch 29/64 loss: -0.9744243621826172
Batch 30/64 loss: -1.3358564376831055
Batch 31/64 loss: -1.40838623046875
Batch 32/64 loss: -1.2799291610717773
Batch 33/64 loss: -1.315464973449707
Batch 34/64 loss: -1.3808374404907227
Batch 35/64 loss: -1.3619813919067383
Batch 36/64 loss: -0.5898847579956055
Batch 37/64 loss: -1.234797477722168
Batch 38/64 loss: -1.2406806945800781
Batch 39/64 loss: -0.9847393035888672
Batch 40/64 loss: -0.8225135803222656
Batch 41/64 loss: -0.8840131759643555
Batch 42/64 loss: -1.2684412002563477
Batch 43/64 loss: -1.1674423217773438
Batch 44/64 loss: -1.0148382186889648
Batch 45/64 loss: -1.4219636917114258
Batch 46/64 loss: -0.8015995025634766
Batch 47/64 loss: -1.1739692687988281
Batch 48/64 loss: -1.132246971130371
Batch 49/64 loss: -1.1678848266601562
Batch 50/64 loss: -1.2706317901611328
Batch 51/64 loss: -0.9449491500854492
Batch 52/64 loss: -1.2593584060668945
Batch 53/64 loss: -0.991236686706543
Batch 54/64 loss: -1.2926311492919922
Batch 55/64 loss: -0.7120456695556641
Batch 56/64 loss: -1.0282602310180664
Batch 57/64 loss: -1.3145246505737305
Batch 58/64 loss: -1.156773567199707
Batch 59/64 loss: -1.1967954635620117
Batch 60/64 loss: -1.0862751007080078
Batch 61/64 loss: -1.027318000793457
Batch 62/64 loss: -1.2815885543823242
Batch 63/64 loss: -0.6369485855102539
Batch 64/64 loss: -5.275877952575684
Epoch 167  Train loss: -1.2235920962165383  Val loss: -1.2662520130065709
Epoch 168
-------------------------------
Batch 1/64 loss: -0.9011878967285156
Batch 2/64 loss: -0.5007467269897461
Batch 3/64 loss: -1.2937631607055664
Batch 4/64 loss: -1.3944950103759766
Batch 5/64 loss: -1.2058782577514648
Batch 6/64 loss: -1.3053865432739258
Batch 7/64 loss: -0.8675823211669922
Batch 8/64 loss: -0.9990558624267578
Batch 9/64 loss: -1.240950584411621
Batch 10/64 loss: -1.3282012939453125
Batch 11/64 loss: -0.36711978912353516
Batch 12/64 loss: -1.0505504608154297
Batch 13/64 loss: -1.3066883087158203
Batch 14/64 loss: -1.114212989807129
Batch 15/64 loss: -0.8758831024169922
Batch 16/64 loss: -1.5873537063598633
Batch 17/64 loss: -1.2921743392944336
Batch 18/64 loss: -0.9112977981567383
Batch 19/64 loss: -0.7133512496948242
Batch 20/64 loss: -1.184269905090332
Batch 21/64 loss: -1.5159940719604492
Batch 22/64 loss: -1.3312149047851562
Batch 23/64 loss: -1.2226848602294922
Batch 24/64 loss: -0.7890348434448242
Batch 25/64 loss: -0.7107505798339844
Batch 26/64 loss: -0.6940937042236328
Batch 27/64 loss: -1.242079734802246
Batch 28/64 loss: -1.5286540985107422
Batch 29/64 loss: -1.245284080505371
Batch 30/64 loss: -1.1829919815063477
Batch 31/64 loss: -1.1371698379516602
Batch 32/64 loss: -0.887913703918457
Batch 33/64 loss: -1.3053579330444336
Batch 34/64 loss: -1.2005081176757812
Batch 35/64 loss: -1.0248832702636719
Batch 36/64 loss: -1.2270641326904297
Batch 37/64 loss: -1.2454090118408203
Batch 38/64 loss: -1.297623634338379
Batch 39/64 loss: -1.625136375427246
Batch 40/64 loss: -1.1288175582885742
Batch 41/64 loss: -1.2638559341430664
Batch 42/64 loss: -1.4079179763793945
Batch 43/64 loss: -1.535782814025879
Batch 44/64 loss: -1.075021743774414
Batch 45/64 loss: -1.3346681594848633
Batch 46/64 loss: -1.1800966262817383
Batch 47/64 loss: -1.4546022415161133
Batch 48/64 loss: -1.2059955596923828
Batch 49/64 loss: -1.073378562927246
Batch 50/64 loss: -1.456099510192871
Batch 51/64 loss: -1.2019834518432617
Batch 52/64 loss: -1.138564109802246
Batch 53/64 loss: -1.21527099609375
Batch 54/64 loss: -1.517867088317871
Batch 55/64 loss: -1.172368049621582
Batch 56/64 loss: -0.8979434967041016
Batch 57/64 loss: -1.086747169494629
Batch 58/64 loss: -1.490248680114746
Batch 59/64 loss: -1.1211557388305664
Batch 60/64 loss: -0.9889726638793945
Batch 61/64 loss: -1.0595998764038086
Batch 62/64 loss: -0.9631185531616211
Batch 63/64 loss: -1.4658069610595703
Batch 64/64 loss: -5.432621002197266
Epoch 168  Train loss: -1.213558391496247  Val loss: -1.3554653154615683
Epoch 169
-------------------------------
Batch 1/64 loss: -1.3484086990356445
Batch 2/64 loss: -1.2712469100952148
Batch 3/64 loss: -1.277592658996582
Batch 4/64 loss: -1.2851324081420898
Batch 5/64 loss: -1.1236791610717773
Batch 6/64 loss: -1.3003349304199219
Batch 7/64 loss: -1.1967267990112305
Batch 8/64 loss: -1.1458768844604492
Batch 9/64 loss: -1.3302059173583984
Batch 10/64 loss: -1.5329828262329102
Batch 11/64 loss: -1.2400293350219727
Batch 12/64 loss: -1.2646980285644531
Batch 13/64 loss: -1.3212671279907227
Batch 14/64 loss: -1.4432792663574219
Batch 15/64 loss: -1.3611087799072266
Batch 16/64 loss: -1.5673255920410156
Batch 17/64 loss: -1.1737518310546875
Batch 18/64 loss: -1.2262210845947266
Batch 19/64 loss: -1.3918952941894531
Batch 20/64 loss: -1.0082969665527344
Batch 21/64 loss: -1.129145622253418
Batch 22/64 loss: -1.0313663482666016
Batch 23/64 loss: -1.4570865631103516
Batch 24/64 loss: -1.4166345596313477
Batch 25/64 loss: -1.1864290237426758
Batch 26/64 loss: -1.2198724746704102
Batch 27/64 loss: -0.9459228515625
Batch 28/64 loss: -1.4894161224365234
Batch 29/64 loss: -1.0325803756713867
Batch 30/64 loss: -1.3897018432617188
Batch 31/64 loss: -0.9653129577636719
Batch 32/64 loss: -1.4193077087402344
Batch 33/64 loss: -1.0192365646362305
Batch 34/64 loss: -1.619643211364746
Batch 35/64 loss: -1.1012287139892578
Batch 36/64 loss: -0.7186851501464844
Batch 37/64 loss: -1.239633560180664
Batch 38/64 loss: -1.3005990982055664
Batch 39/64 loss: -1.4705209732055664
Batch 40/64 loss: -0.8961334228515625
Batch 41/64 loss: -1.4473180770874023
Batch 42/64 loss: -1.1377506256103516
Batch 43/64 loss: -1.3108797073364258
Batch 44/64 loss: -1.3194942474365234
Batch 45/64 loss: -1.6128101348876953
Batch 46/64 loss: -1.484156608581543
Batch 47/64 loss: -1.2466707229614258
Batch 48/64 loss: -1.4389123916625977
Batch 49/64 loss: -1.0302610397338867
Batch 50/64 loss: -1.472372055053711
Batch 51/64 loss: -0.9502239227294922
Batch 52/64 loss: -1.0712699890136719
Batch 53/64 loss: -1.0933799743652344
Batch 54/64 loss: -1.419032096862793
Batch 55/64 loss: -1.0792818069458008
Batch 56/64 loss: -1.4074363708496094
Batch 57/64 loss: -1.515141487121582
Batch 58/64 loss: -1.2499275207519531
Batch 59/64 loss: -0.9767942428588867
Batch 60/64 loss: -0.9182405471801758
Batch 61/64 loss: -0.8401737213134766
Batch 62/64 loss: -1.2355079650878906
Batch 63/64 loss: -1.261378288269043
Batch 64/64 loss: -5.512185096740723
Epoch 169  Train loss: -1.2942912943222944  Val loss: -1.358508591799392
Epoch 170
-------------------------------
Batch 1/64 loss: -1.3542022705078125
Batch 2/64 loss: -0.6916007995605469
Batch 3/64 loss: -1.3720283508300781
Batch 4/64 loss: -1.0727453231811523
Batch 5/64 loss: -1.3018808364868164
Batch 6/64 loss: -1.0895261764526367
Batch 7/64 loss: -0.705500602722168
Batch 8/64 loss: -1.1253337860107422
Batch 9/64 loss: -1.3194999694824219
Batch 10/64 loss: -1.345952033996582
Batch 11/64 loss: -1.3715896606445312
Batch 12/64 loss: -1.3942832946777344
Batch 13/64 loss: -1.4584646224975586
Batch 14/64 loss: -0.9073667526245117
Batch 15/64 loss: -1.0596790313720703
Batch 16/64 loss: -0.899139404296875
Batch 17/64 loss: -0.9572877883911133
Batch 18/64 loss: -1.3062772750854492
Batch 19/64 loss: -1.3038625717163086
Batch 20/64 loss: -1.2512903213500977
Batch 21/64 loss: -1.504380226135254
Batch 22/64 loss: -1.507338523864746
Batch 23/64 loss: -1.119394302368164
Batch 24/64 loss: -1.0715522766113281
Batch 25/64 loss: -1.1706113815307617
Batch 26/64 loss: -1.5782537460327148
Batch 27/64 loss: -0.7298421859741211
Batch 28/64 loss: -1.2870712280273438
Batch 29/64 loss: -1.0896129608154297
Batch 30/64 loss: -1.4206247329711914
Batch 31/64 loss: -1.5003128051757812
Batch 32/64 loss: -1.3652582168579102
Batch 33/64 loss: -1.1456079483032227
Batch 34/64 loss: -1.5400009155273438
Batch 35/64 loss: -1.4576377868652344
Batch 36/64 loss: -0.45643043518066406
Batch 37/64 loss: -1.3040571212768555
Batch 38/64 loss: -0.8466243743896484
Batch 39/64 loss: -1.0488348007202148
Batch 40/64 loss: -1.273360252380371
Batch 41/64 loss: -1.2659006118774414
Batch 42/64 loss: -1.3942060470581055
Batch 43/64 loss: -1.309600830078125
Batch 44/64 loss: -1.2260160446166992
Batch 45/64 loss: -1.0244293212890625
Batch 46/64 loss: -1.1065912246704102
Batch 47/64 loss: -1.1398448944091797
Batch 48/64 loss: -0.9879121780395508
Batch 49/64 loss: -1.0183525085449219
Batch 50/64 loss: -1.2064247131347656
Batch 51/64 loss: -1.43017578125
Batch 52/64 loss: -1.398087501525879
Batch 53/64 loss: -1.2423439025878906
Batch 54/64 loss: -1.2534656524658203
Batch 55/64 loss: -1.055318832397461
Batch 56/64 loss: -1.235849380493164
Batch 57/64 loss: -1.3825035095214844
Batch 58/64 loss: -1.0831422805786133
Batch 59/64 loss: -1.1367387771606445
Batch 60/64 loss: -1.1980342864990234
Batch 61/64 loss: -1.4617080688476562
Batch 62/64 loss: -1.0128583908081055
Batch 63/64 loss: -1.2235631942749023
Batch 64/64 loss: -5.458273410797119
Epoch 170  Train loss: -1.2484876875783883  Val loss: -1.2266500938389309
Epoch 171
-------------------------------
Batch 1/64 loss: -1.0433454513549805
Batch 2/64 loss: -1.248988151550293
Batch 3/64 loss: -1.4177303314208984
Batch 4/64 loss: -1.516876220703125
Batch 5/64 loss: -1.4668779373168945
Batch 6/64 loss: -0.6539735794067383
Batch 7/64 loss: -1.147085189819336
Batch 8/64 loss: -1.2738046646118164
Batch 9/64 loss: -0.9060602188110352
Batch 10/64 loss: -1.317215919494629
Batch 11/64 loss: -1.228957176208496
Batch 12/64 loss: -1.0179204940795898
Batch 13/64 loss: -0.8351535797119141
Batch 14/64 loss: -1.4848861694335938
Batch 15/64 loss: -1.0808935165405273
Batch 16/64 loss: -1.5721750259399414
Batch 17/64 loss: -1.196507453918457
Batch 18/64 loss: -1.329115867614746
Batch 19/64 loss: -1.065190315246582
Batch 20/64 loss: -1.1349544525146484
Batch 21/64 loss: -1.3866443634033203
Batch 22/64 loss: -1.576456069946289
Batch 23/64 loss: -1.2510995864868164
Batch 24/64 loss: -1.1289291381835938
Batch 25/64 loss: -1.1982812881469727
Batch 26/64 loss: -0.6815404891967773
Batch 27/64 loss: -0.983067512512207
Batch 28/64 loss: -1.1675796508789062
Batch 29/64 loss: -1.175252914428711
Batch 30/64 loss: -1.464665412902832
Batch 31/64 loss: -1.2745752334594727
Batch 32/64 loss: -0.9426689147949219
Batch 33/64 loss: -1.650914192199707
Batch 34/64 loss: -1.0139760971069336
Batch 35/64 loss: -0.9820337295532227
Batch 36/64 loss: -1.2418651580810547
Batch 37/64 loss: -1.0702495574951172
Batch 38/64 loss: -1.07958984375
Batch 39/64 loss: -1.2775182723999023
Batch 40/64 loss: -1.2568302154541016
Batch 41/64 loss: -0.976832389831543
Batch 42/64 loss: -1.432943344116211
Batch 43/64 loss: -1.2978391647338867
Batch 44/64 loss: -1.182877540588379
Batch 45/64 loss: -1.52923583984375
Batch 46/64 loss: -0.5231866836547852
Batch 47/64 loss: -1.3954153060913086
Batch 48/64 loss: -1.3853321075439453
Batch 49/64 loss: -1.1855268478393555
Batch 50/64 loss: -0.5631084442138672
Batch 51/64 loss: -1.2864151000976562
Batch 52/64 loss: -1.2463512420654297
Batch 53/64 loss: -1.0001916885375977
Batch 54/64 loss: -0.8996763229370117
Batch 55/64 loss: -1.419778823852539
Batch 56/64 loss: -1.2787466049194336
Batch 57/64 loss: -1.3070392608642578
Batch 58/64 loss: -0.7290134429931641
Batch 59/64 loss: -1.0665712356567383
Batch 60/64 loss: -0.9651699066162109
Batch 61/64 loss: -1.3866119384765625
Batch 62/64 loss: -0.9345731735229492
Batch 63/64 loss: -1.263899803161621
Batch 64/64 loss: -5.260085105895996
Epoch 171  Train loss: -1.2226329317279891  Val loss: -1.3251111925262766
Epoch 172
-------------------------------
Batch 1/64 loss: -1.1250762939453125
Batch 2/64 loss: -0.9787712097167969
Batch 3/64 loss: -1.2488880157470703
Batch 4/64 loss: -0.9448347091674805
Batch 5/64 loss: -1.1789846420288086
Batch 6/64 loss: -1.3080415725708008
Batch 7/64 loss: -0.9363737106323242
Batch 8/64 loss: -1.279256820678711
Batch 9/64 loss: -1.2261457443237305
Batch 10/64 loss: -1.470503807067871
Batch 11/64 loss: -1.4150705337524414
Batch 12/64 loss: -1.1151742935180664
Batch 13/64 loss: -1.4086055755615234
Batch 14/64 loss: -1.3790559768676758
Batch 15/64 loss: -1.0516834259033203
Batch 16/64 loss: -1.0378608703613281
Batch 17/64 loss: -1.2722063064575195
Batch 18/64 loss: -1.3371028900146484
Batch 19/64 loss: -1.3164377212524414
Batch 20/64 loss: -1.5198287963867188
Batch 21/64 loss: -1.4946985244750977
Batch 22/64 loss: -0.6497287750244141
Batch 23/64 loss: -1.2265949249267578
Batch 24/64 loss: -1.195343017578125
Batch 25/64 loss: -0.9355440139770508
Batch 26/64 loss: -0.8097572326660156
Batch 27/64 loss: -0.874516487121582
Batch 28/64 loss: -0.8805809020996094
Batch 29/64 loss: -1.437774658203125
Batch 30/64 loss: -1.2493476867675781
Batch 31/64 loss: -1.3020906448364258
Batch 32/64 loss: -1.347010612487793
Batch 33/64 loss: -0.7979507446289062
Batch 34/64 loss: -1.5301694869995117
Batch 35/64 loss: -1.367781639099121
Batch 36/64 loss: -0.9968814849853516
Batch 37/64 loss: -1.3919553756713867
Batch 38/64 loss: -1.3060321807861328
Batch 39/64 loss: -1.4275789260864258
Batch 40/64 loss: -1.5442886352539062
Batch 41/64 loss: -1.3720903396606445
Batch 42/64 loss: -1.5113153457641602
Batch 43/64 loss: -1.6971731185913086
Batch 44/64 loss: -0.8247995376586914
Batch 45/64 loss: -1.1254692077636719
Batch 46/64 loss: -1.3154163360595703
Batch 47/64 loss: -0.9531164169311523
Batch 48/64 loss: -1.0711431503295898
Batch 49/64 loss: -1.0513887405395508
Batch 50/64 loss: -1.291748046875
Batch 51/64 loss: -1.2567329406738281
Batch 52/64 loss: -1.4114990234375
Batch 53/64 loss: -1.2733917236328125
Batch 54/64 loss: -1.426802635192871
Batch 55/64 loss: -1.0732307434082031
Batch 56/64 loss: -1.3099174499511719
Batch 57/64 loss: -1.063553810119629
Batch 58/64 loss: -1.0172624588012695
Batch 59/64 loss: -1.069991111755371
Batch 60/64 loss: -0.8027772903442383
Batch 61/64 loss: -1.1868953704833984
Batch 62/64 loss: -1.33038330078125
Batch 63/64 loss: -1.1709012985229492
Batch 64/64 loss: -5.278093338012695
Epoch 172  Train loss: -1.2530368356143726  Val loss: -1.2360049899910734
Epoch 173
-------------------------------
Batch 1/64 loss: -1.3808517456054688
Batch 2/64 loss: -1.1194143295288086
Batch 3/64 loss: -1.0352935791015625
Batch 4/64 loss: -1.5188636779785156
Batch 5/64 loss: -1.4195442199707031
Batch 6/64 loss: -1.3303146362304688
Batch 7/64 loss: -1.1450281143188477
Batch 8/64 loss: -1.170914649963379
Batch 9/64 loss: -1.200531005859375
Batch 10/64 loss: -1.008432388305664
Batch 11/64 loss: -1.392317771911621
Batch 12/64 loss: -1.4525203704833984
Batch 13/64 loss: -1.2512741088867188
Batch 14/64 loss: -0.9169340133666992
Batch 15/64 loss: -1.410421371459961
Batch 16/64 loss: -1.5343341827392578
Batch 17/64 loss: -1.6041288375854492
Batch 18/64 loss: -1.3815727233886719
Batch 19/64 loss: -1.1689863204956055
Batch 20/64 loss: -0.7054166793823242
Batch 21/64 loss: -1.17401123046875
Batch 22/64 loss: -1.5068073272705078
Batch 23/64 loss: -1.0879535675048828
Batch 24/64 loss: -1.0894298553466797
Batch 25/64 loss: -1.2986059188842773
Batch 26/64 loss: -1.3729562759399414
Batch 27/64 loss: -1.518345832824707
Batch 28/64 loss: -1.3355388641357422
Batch 29/64 loss: -1.1867551803588867
Batch 30/64 loss: -1.2223491668701172
Batch 31/64 loss: -1.1182003021240234
Batch 32/64 loss: -1.4953947067260742
Batch 33/64 loss: -1.1500396728515625
Batch 34/64 loss: -1.2215185165405273
Batch 35/64 loss: -1.5764236450195312
Batch 36/64 loss: -1.1772117614746094
Batch 37/64 loss: -1.0532779693603516
Batch 38/64 loss: -0.9978628158569336
Batch 39/64 loss: -1.295013427734375
Batch 40/64 loss: -1.0719890594482422
Batch 41/64 loss: -1.11700439453125
Batch 42/64 loss: -1.4051198959350586
Batch 43/64 loss: -1.2963676452636719
Batch 44/64 loss: -1.4252567291259766
Batch 45/64 loss: -1.5098648071289062
Batch 46/64 loss: -1.3186931610107422
Batch 47/64 loss: -1.2745161056518555
Batch 48/64 loss: -1.3471050262451172
Batch 49/64 loss: -1.4081764221191406
Batch 50/64 loss: -1.527994155883789
Batch 51/64 loss: -0.9706439971923828
Batch 52/64 loss: -1.091226577758789
Batch 53/64 loss: -1.0202693939208984
Batch 54/64 loss: -1.1944160461425781
Batch 55/64 loss: -1.4417657852172852
Batch 56/64 loss: -1.3231773376464844
Batch 57/64 loss: -1.181605339050293
Batch 58/64 loss: -1.347433090209961
Batch 59/64 loss: -1.1518192291259766
Batch 60/64 loss: -1.126021385192871
Batch 61/64 loss: -1.229018211364746
Batch 62/64 loss: -1.1480388641357422
Batch 63/64 loss: -0.9767599105834961
Batch 64/64 loss: -5.476228713989258
Epoch 173  Train loss: -1.3025293312820734  Val loss: -1.4189366868271451
Saving best model, epoch: 173
Epoch 174
-------------------------------
Batch 1/64 loss: -1.3221321105957031
Batch 2/64 loss: -1.089024543762207
Batch 3/64 loss: -1.115616798400879
Batch 4/64 loss: -1.2266731262207031
Batch 5/64 loss: -1.441472053527832
Batch 6/64 loss: -1.1236982345581055
Batch 7/64 loss: -1.1525535583496094
Batch 8/64 loss: -1.2582874298095703
Batch 9/64 loss: -1.2378625869750977
Batch 10/64 loss: -0.886418342590332
Batch 11/64 loss: -1.1621170043945312
Batch 12/64 loss: -1.5145454406738281
Batch 13/64 loss: -1.5340356826782227
Batch 14/64 loss: -1.3943595886230469
Batch 15/64 loss: -1.3464326858520508
Batch 16/64 loss: -1.534677505493164
Batch 17/64 loss: -1.6314668655395508
Batch 18/64 loss: -1.1550254821777344
Batch 19/64 loss: -1.5046062469482422
Batch 20/64 loss: -1.2582025527954102
Batch 21/64 loss: -1.4554643630981445
Batch 22/64 loss: -1.2220592498779297
Batch 23/64 loss: -1.029271125793457
Batch 24/64 loss: -1.3288335800170898
Batch 25/64 loss: -0.31923389434814453
Batch 26/64 loss: -1.1377153396606445
Batch 27/64 loss: -1.2720518112182617
Batch 28/64 loss: -0.9702720642089844
Batch 29/64 loss: -1.2889490127563477
Batch 30/64 loss: -1.2133121490478516
Batch 31/64 loss: -1.2085113525390625
Batch 32/64 loss: -1.1327695846557617
Batch 33/64 loss: -1.1432132720947266
Batch 34/64 loss: -0.8765411376953125
Batch 35/64 loss: -1.3089838027954102
Batch 36/64 loss: -0.8817214965820312
Batch 37/64 loss: -1.2874536514282227
Batch 38/64 loss: -1.3130340576171875
Batch 39/64 loss: -1.3048334121704102
Batch 40/64 loss: -1.0347785949707031
Batch 41/64 loss: -0.9748849868774414
Batch 42/64 loss: -1.0993947982788086
Batch 43/64 loss: -1.2266836166381836
Batch 44/64 loss: -1.3935918807983398
Batch 45/64 loss: -0.9081258773803711
Batch 46/64 loss: -0.9571638107299805
Batch 47/64 loss: -0.8601484298706055
Batch 48/64 loss: -1.0973844528198242
Batch 49/64 loss: -0.8945798873901367
Batch 50/64 loss: -1.198573112487793
Batch 51/64 loss: -0.8715753555297852
Batch 52/64 loss: -1.1203718185424805
Batch 53/64 loss: -1.1140375137329102
Batch 54/64 loss: -1.3514595031738281
Batch 55/64 loss: -1.0697784423828125
Batch 56/64 loss: -1.0071001052856445
Batch 57/64 loss: -0.8011980056762695
Batch 58/64 loss: -1.076970100402832
Batch 59/64 loss: -1.1239500045776367
Batch 60/64 loss: -1.3852424621582031
Batch 61/64 loss: -1.1726293563842773
Batch 62/64 loss: -1.0474395751953125
Batch 63/64 loss: -0.6278524398803711
Batch 64/64 loss: -5.505888938903809
Epoch 174  Train loss: -1.2098472632613837  Val loss: -1.4540944181357052
Saving best model, epoch: 174
Epoch 175
-------------------------------
Batch 1/64 loss: -1.2803678512573242
Batch 2/64 loss: -1.0070304870605469
Batch 3/64 loss: -1.3004140853881836
Batch 4/64 loss: -1.3263921737670898
Batch 5/64 loss: -1.012735366821289
Batch 6/64 loss: -0.8359651565551758
Batch 7/64 loss: -1.3953218460083008
Batch 8/64 loss: -1.536916732788086
Batch 9/64 loss: -1.3353118896484375
Batch 10/64 loss: -1.3413028717041016
Batch 11/64 loss: -1.1032838821411133
Batch 12/64 loss: -1.1190309524536133
Batch 13/64 loss: -0.8819694519042969
Batch 14/64 loss: -1.0703506469726562
Batch 15/64 loss: -1.227595329284668
Batch 16/64 loss: -1.5534420013427734
Batch 17/64 loss: -1.1363019943237305
Batch 18/64 loss: -1.4177589416503906
Batch 19/64 loss: -1.4752607345581055
Batch 20/64 loss: -1.0151233673095703
Batch 21/64 loss: -1.2979192733764648
Batch 22/64 loss: -1.2959938049316406
Batch 23/64 loss: -1.3011884689331055
Batch 24/64 loss: -1.084376335144043
Batch 25/64 loss: -1.3067703247070312
Batch 26/64 loss: -1.3952770233154297
Batch 27/64 loss: -1.3578119277954102
Batch 28/64 loss: -1.2038021087646484
Batch 29/64 loss: -0.7317399978637695
Batch 30/64 loss: -1.2848262786865234
Batch 31/64 loss: -1.1972131729125977
Batch 32/64 loss: -1.4561576843261719
Batch 33/64 loss: -1.0905895233154297
Batch 34/64 loss: -1.0486717224121094
Batch 35/64 loss: -1.2610225677490234
Batch 36/64 loss: -1.3107824325561523
Batch 37/64 loss: -1.6276211738586426
Batch 38/64 loss: -1.305912971496582
Batch 39/64 loss: -1.280095100402832
Batch 40/64 loss: -1.2268743515014648
Batch 41/64 loss: -0.9401226043701172
Batch 42/64 loss: -0.9724750518798828
Batch 43/64 loss: -1.4941949844360352
Batch 44/64 loss: -1.4003686904907227
Batch 45/64 loss: -1.1725635528564453
Batch 46/64 loss: -1.2711219787597656
Batch 47/64 loss: -1.028019905090332
Batch 48/64 loss: -1.3101005554199219
Batch 49/64 loss: -1.2309303283691406
Batch 50/64 loss: -1.2038536071777344
Batch 51/64 loss: -0.6906719207763672
Batch 52/64 loss: -0.9723625183105469
Batch 53/64 loss: -1.2713546752929688
Batch 54/64 loss: -1.2856178283691406
Batch 55/64 loss: -0.8156375885009766
Batch 56/64 loss: -1.1672906875610352
Batch 57/64 loss: -1.2809743881225586
Batch 58/64 loss: -1.003922462463379
Batch 59/64 loss: -1.6101913452148438
Batch 60/64 loss: -1.5150537490844727
Batch 61/64 loss: -1.4650745391845703
Batch 62/64 loss: -1.3714323043823242
Batch 63/64 loss: -1.381495475769043
Batch 64/64 loss: -5.236273765563965
Epoch 175  Train loss: -1.2740165972242168  Val loss: -1.3451017923781143
Epoch 176
-------------------------------
Batch 1/64 loss: -1.0400505065917969
Batch 2/64 loss: -1.2940740585327148
Batch 3/64 loss: -1.576350212097168
Batch 4/64 loss: -1.0944557189941406
Batch 5/64 loss: -1.4615497589111328
Batch 6/64 loss: -1.1784334182739258
Batch 7/64 loss: -1.3127126693725586
Batch 8/64 loss: -1.4038524627685547
Batch 9/64 loss: 1.473893165588379
Batch 10/64 loss: -1.3933887481689453
Batch 11/64 loss: -0.9329681396484375
Batch 12/64 loss: -1.4348745346069336
Batch 13/64 loss: -1.3223886489868164
Batch 14/64 loss: -0.8173141479492188
Batch 15/64 loss: -1.6790685653686523
Batch 16/64 loss: -1.114415168762207
Batch 17/64 loss: -0.6533889770507812
Batch 18/64 loss: -1.4085750579833984
Batch 19/64 loss: -1.2943801879882812
Batch 20/64 loss: -1.2022943496704102
Batch 21/64 loss: -0.8126859664916992
Batch 22/64 loss: -1.3536109924316406
Batch 23/64 loss: -1.228501319885254
Batch 24/64 loss: -1.3213958740234375
Batch 25/64 loss: -1.3193073272705078
Batch 26/64 loss: -0.9162473678588867
Batch 27/64 loss: -1.0489635467529297
Batch 28/64 loss: -1.0886554718017578
Batch 29/64 loss: -1.5935497283935547
Batch 30/64 loss: -1.0236625671386719
Batch 31/64 loss: -1.2088890075683594
Batch 32/64 loss: -1.0184497833251953
Batch 33/64 loss: -1.2972345352172852
Batch 34/64 loss: -1.2470340728759766
Batch 35/64 loss: -0.9132986068725586
Batch 36/64 loss: -1.017228126525879
Batch 37/64 loss: -1.5953712463378906
Batch 38/64 loss: -1.2832584381103516
Batch 39/64 loss: -1.0563850402832031
Batch 40/64 loss: -1.2296380996704102
Batch 41/64 loss: -1.1169767379760742
Batch 42/64 loss: -1.3828563690185547
Batch 43/64 loss: -1.339137077331543
Batch 44/64 loss: -1.371403694152832
Batch 45/64 loss: -1.4199085235595703
Batch 46/64 loss: -1.1944494247436523
Batch 47/64 loss: -1.080887794494629
Batch 48/64 loss: -1.0269489288330078
Batch 49/64 loss: -1.4685087203979492
Batch 50/64 loss: -1.0870304107666016
Batch 51/64 loss: -1.1821660995483398
Batch 52/64 loss: -1.5341777801513672
Batch 53/64 loss: -1.433974266052246
Batch 54/64 loss: -1.270151138305664
Batch 55/64 loss: -1.2409143447875977
Batch 56/64 loss: -1.5676641464233398
Batch 57/64 loss: -1.2748289108276367
Batch 58/64 loss: -1.1813726425170898
Batch 59/64 loss: -1.5429353713989258
Batch 60/64 loss: -1.2227487564086914
Batch 61/64 loss: -1.2544403076171875
Batch 62/64 loss: -1.3575859069824219
Batch 63/64 loss: -1.1105213165283203
Batch 64/64 loss: -5.126512050628662
Epoch 176  Train loss: -1.2426742273218492  Val loss: -1.3128451055677486
Epoch 177
-------------------------------
Batch 1/64 loss: -1.489323616027832
Batch 2/64 loss: -1.012660026550293
Batch 3/64 loss: -1.4133167266845703
Batch 4/64 loss: -1.1063051223754883
Batch 5/64 loss: -0.6299829483032227
Batch 6/64 loss: -1.419875144958496
Batch 7/64 loss: -1.3303594589233398
Batch 8/64 loss: -1.2997217178344727
Batch 9/64 loss: -1.252242088317871
Batch 10/64 loss: -1.3948163986206055
Batch 11/64 loss: -1.2055835723876953
Batch 12/64 loss: -1.4491996765136719
Batch 13/64 loss: -1.4935331344604492
Batch 14/64 loss: -1.4825716018676758
Batch 15/64 loss: -0.8655176162719727
Batch 16/64 loss: -1.2317924499511719
Batch 17/64 loss: -1.247549057006836
Batch 18/64 loss: -1.4611406326293945
Batch 19/64 loss: -1.334442138671875
Batch 20/64 loss: -1.1095390319824219
Batch 21/64 loss: -1.3756580352783203
Batch 22/64 loss: -1.0742816925048828
Batch 23/64 loss: -1.236276626586914
Batch 24/64 loss: -1.2018966674804688
Batch 25/64 loss: -1.286707878112793
Batch 26/64 loss: -1.4782524108886719
Batch 27/64 loss: -1.0848827362060547
Batch 28/64 loss: -1.1767635345458984
Batch 29/64 loss: -1.14617919921875
Batch 30/64 loss: -1.25262451171875
Batch 31/64 loss: -1.4882421493530273
Batch 32/64 loss: -1.3760900497436523
Batch 33/64 loss: -0.9396114349365234
Batch 34/64 loss: -0.9769792556762695
Batch 35/64 loss: -1.4240646362304688
Batch 36/64 loss: -1.0590858459472656
Batch 37/64 loss: -0.5166721343994141
Batch 38/64 loss: -1.2215328216552734
Batch 39/64 loss: -1.4753332138061523
Batch 40/64 loss: -1.332087516784668
Batch 41/64 loss: -1.5297651290893555
Batch 42/64 loss: -1.2827224731445312
Batch 43/64 loss: -1.271963119506836
Batch 44/64 loss: -0.8514614105224609
Batch 45/64 loss: -1.3265657424926758
Batch 46/64 loss: -1.2574882507324219
Batch 47/64 loss: -1.1900205612182617
Batch 48/64 loss: -1.5680313110351562
Batch 49/64 loss: -1.0593643188476562
Batch 50/64 loss: -0.0049915313720703125
Batch 51/64 loss: -0.41356372833251953
Batch 52/64 loss: -1.212916374206543
Batch 53/64 loss: -0.8152618408203125
Batch 54/64 loss: -1.2033586502075195
Batch 55/64 loss: -0.9870758056640625
Batch 56/64 loss: -1.0958309173583984
Batch 57/64 loss: -1.2295818328857422
Batch 58/64 loss: -1.2527379989624023
Batch 59/64 loss: -1.2934017181396484
Batch 60/64 loss: -1.0936698913574219
Batch 61/64 loss: -1.2753839492797852
Batch 62/64 loss: -0.9280061721801758
Batch 63/64 loss: -1.070420265197754
Batch 64/64 loss: -5.331090927124023
Epoch 177  Train loss: -1.232385814891142  Val loss: -1.2918499032246697
Epoch 178
-------------------------------
Batch 1/64 loss: -1.2373991012573242
Batch 2/64 loss: -1.190232276916504
Batch 3/64 loss: -0.804020881652832
Batch 4/64 loss: -1.3310613632202148
Batch 5/64 loss: -1.1023550033569336
Batch 6/64 loss: -0.9115743637084961
Batch 7/64 loss: -1.4848995208740234
Batch 8/64 loss: -1.2188119888305664
Batch 9/64 loss: -1.2773866653442383
Batch 10/64 loss: -1.1913347244262695
Batch 11/64 loss: -1.4600200653076172
Batch 12/64 loss: -1.0668096542358398
Batch 13/64 loss: -1.0455141067504883
Batch 14/64 loss: -1.5179624557495117
Batch 15/64 loss: -1.5123300552368164
Batch 16/64 loss: -1.2895259857177734
Batch 17/64 loss: -1.1822738647460938
Batch 18/64 loss: -1.671128273010254
Batch 19/64 loss: -1.4381561279296875
Batch 20/64 loss: -1.2450647354125977
Batch 21/64 loss: -0.7850475311279297
Batch 22/64 loss: -1.2531394958496094
Batch 23/64 loss: -1.2883291244506836
Batch 24/64 loss: -1.3063793182373047
Batch 25/64 loss: -1.191415786743164
Batch 26/64 loss: -1.3919010162353516
Batch 27/64 loss: -1.5140199661254883
Batch 28/64 loss: -1.4212617874145508
Batch 29/64 loss: -1.4474420547485352
Batch 30/64 loss: -1.1522760391235352
Batch 31/64 loss: -1.4072265625
Batch 32/64 loss: -1.1761665344238281
Batch 33/64 loss: -1.3898868560791016
Batch 34/64 loss: -1.029627799987793
Batch 35/64 loss: -1.073105812072754
Batch 36/64 loss: -0.966583251953125
Batch 37/64 loss: -1.288222312927246
Batch 38/64 loss: -1.0252676010131836
Batch 39/64 loss: -1.2309646606445312
Batch 40/64 loss: -0.9953861236572266
Batch 41/64 loss: -1.1252937316894531
Batch 42/64 loss: -0.9501829147338867
Batch 43/64 loss: -0.8211565017700195
Batch 44/64 loss: -1.132443904876709
Batch 45/64 loss: -1.4070520401000977
Batch 46/64 loss: -1.1125507354736328
Batch 47/64 loss: -0.8218250274658203
Batch 48/64 loss: -1.3527498245239258
Batch 49/64 loss: -1.307784080505371
Batch 50/64 loss: -1.1813011169433594
Batch 51/64 loss: -0.8235263824462891
Batch 52/64 loss: -1.2926130294799805
Batch 53/64 loss: -1.1128244400024414
Batch 54/64 loss: -0.36106395721435547
Batch 55/64 loss: -1.3630084991455078
Batch 56/64 loss: -1.0082931518554688
Batch 57/64 loss: -1.192214012145996
Batch 58/64 loss: -1.5083112716674805
Batch 59/64 loss: -0.6916608810424805
Batch 60/64 loss: -1.2168693542480469
Batch 61/64 loss: -1.3626956939697266
Batch 62/64 loss: -1.088068962097168
Batch 63/64 loss: -0.601994514465332
Batch 64/64 loss: -4.932085990905762
Epoch 178  Train loss: -1.224251911686916  Val loss: -1.2719067314646089
Epoch 179
-------------------------------
Batch 1/64 loss: -1.329298973083496
Batch 2/64 loss: -0.8639020919799805
Batch 3/64 loss: -1.2673730850219727
Batch 4/64 loss: -1.1463117599487305
Batch 5/64 loss: -1.3512210845947266
Batch 6/64 loss: -1.6016359329223633
Batch 7/64 loss: -1.3336620330810547
Batch 8/64 loss: -1.0686559677124023
Batch 9/64 loss: -1.2026710510253906
Batch 10/64 loss: -1.4313879013061523
Batch 11/64 loss: -1.3461685180664062
Batch 12/64 loss: -1.334024429321289
Batch 13/64 loss: -1.5006132125854492
Batch 14/64 loss: -1.2625837326049805
Batch 15/64 loss: -1.3780622482299805
Batch 16/64 loss: -0.9794464111328125
Batch 17/64 loss: -1.0567235946655273
Batch 18/64 loss: -0.8211755752563477
Batch 19/64 loss: -1.1033306121826172
Batch 20/64 loss: -1.0754146575927734
Batch 21/64 loss: -1.2420063018798828
Batch 22/64 loss: -1.0451936721801758
Batch 23/64 loss: -1.5973196029663086
Batch 24/64 loss: -1.3218955993652344
Batch 25/64 loss: -1.1828670501708984
Batch 26/64 loss: -1.5731124877929688
Batch 27/64 loss: -1.2318296432495117
Batch 28/64 loss: -1.0197057723999023
Batch 29/64 loss: -1.3217658996582031
Batch 30/64 loss: -1.4099206924438477
Batch 31/64 loss: -0.9260282516479492
Batch 32/64 loss: -1.3877553939819336
Batch 33/64 loss: -1.4691200256347656
Batch 34/64 loss: -1.048161506652832
Batch 35/64 loss: -1.2344856262207031
Batch 36/64 loss: -0.9083700180053711
Batch 37/64 loss: -1.3251075744628906
Batch 38/64 loss: -1.4300460815429688
Batch 39/64 loss: -1.356618881225586
Batch 40/64 loss: -1.029653549194336
Batch 41/64 loss: -1.3870296478271484
Batch 42/64 loss: -1.2366695404052734
Batch 43/64 loss: -1.0923023223876953
Batch 44/64 loss: -1.439657211303711
Batch 45/64 loss: -1.365950584411621
Batch 46/64 loss: -1.3041152954101562
Batch 47/64 loss: -1.2505159378051758
Batch 48/64 loss: -1.504434585571289
Batch 49/64 loss: -1.423365592956543
Batch 50/64 loss: -1.339879035949707
Batch 51/64 loss: -1.5105504989624023
Batch 52/64 loss: -1.209120750427246
Batch 53/64 loss: -0.8309755325317383
Batch 54/64 loss: -1.2303247451782227
Batch 55/64 loss: -1.4965457916259766
Batch 56/64 loss: -0.738037109375
Batch 57/64 loss: -1.2542686462402344
Batch 58/64 loss: -1.1885499954223633
Batch 59/64 loss: -1.5292682647705078
Batch 60/64 loss: -1.2963190078735352
Batch 61/64 loss: -0.9749984741210938
Batch 62/64 loss: -0.8898210525512695
Batch 63/64 loss: -1.0817079544067383
Batch 64/64 loss: -4.759980201721191
Epoch 179  Train loss: -1.280925791871314  Val loss: -1.269900279356442
Epoch 180
-------------------------------
Batch 1/64 loss: -1.549830436706543
Batch 2/64 loss: -1.2234277725219727
Batch 3/64 loss: -1.0537853240966797
Batch 4/64 loss: -1.0060691833496094
Batch 5/64 loss: -1.3348932266235352
Batch 6/64 loss: -1.1502819061279297
Batch 7/64 loss: -1.3488988876342773
Batch 8/64 loss: -1.1470041275024414
Batch 9/64 loss: -1.0474729537963867
Batch 10/64 loss: -1.2168340682983398
Batch 11/64 loss: -1.1399974822998047
Batch 12/64 loss: -1.4776887893676758
Batch 13/64 loss: -1.235713005065918
Batch 14/64 loss: -1.3963708877563477
Batch 15/64 loss: -1.13665771484375
Batch 16/64 loss: -1.3270349502563477
Batch 17/64 loss: -1.263554573059082
Batch 18/64 loss: -1.4158973693847656
Batch 19/64 loss: -1.2822704315185547
Batch 20/64 loss: -1.3840665817260742
Batch 21/64 loss: -1.359206199645996
Batch 22/64 loss: -1.624678611755371
Batch 23/64 loss: -1.365279197692871
Batch 24/64 loss: -1.3505992889404297
Batch 25/64 loss: -1.081045150756836
Batch 26/64 loss: -0.8229742050170898
Batch 27/64 loss: -1.3407011032104492
Batch 28/64 loss: -0.9562826156616211
Batch 29/64 loss: -1.230015754699707
Batch 30/64 loss: -1.3865032196044922
Batch 31/64 loss: -1.3338623046875
Batch 32/64 loss: -1.002131462097168
Batch 33/64 loss: -1.0358600616455078
Batch 34/64 loss: -1.5473127365112305
Batch 35/64 loss: -1.0887985229492188
Batch 36/64 loss: -1.3026933670043945
Batch 37/64 loss: -0.7693872451782227
Batch 38/64 loss: -1.4765405654907227
Batch 39/64 loss: -1.2850370407104492
Batch 40/64 loss: -1.3018455505371094
Batch 41/64 loss: -1.165975570678711
Batch 42/64 loss: -1.6831026077270508
Batch 43/64 loss: -1.2593507766723633
Batch 44/64 loss: -1.329376220703125
Batch 45/64 loss: -1.434281349182129
Batch 46/64 loss: -1.3519315719604492
Batch 47/64 loss: -1.5091629028320312
Batch 48/64 loss: -1.503890037536621
Batch 49/64 loss: -1.333521842956543
Batch 50/64 loss: -1.3093528747558594
Batch 51/64 loss: -1.037856101989746
Batch 52/64 loss: -1.0422372817993164
Batch 53/64 loss: -1.0746593475341797
Batch 54/64 loss: -1.2232789993286133
Batch 55/64 loss: -1.199467658996582
Batch 56/64 loss: -1.6584348678588867
Batch 57/64 loss: -1.2480688095092773
Batch 58/64 loss: -1.1346406936645508
Batch 59/64 loss: -1.2106170654296875
Batch 60/64 loss: -1.550522804260254
Batch 61/64 loss: -1.1429738998413086
Batch 62/64 loss: -0.8617382049560547
Batch 63/64 loss: -1.1606159210205078
Batch 64/64 loss: -4.837772369384766
Epoch 180  Train loss: -1.2996374990425859  Val loss: -1.3413693142920424
Epoch 181
-------------------------------
Batch 1/64 loss: -1.3975181579589844
Batch 2/64 loss: -1.4729366302490234
Batch 3/64 loss: -1.2017364501953125
Batch 4/64 loss: -1.6418590545654297
Batch 5/64 loss: -1.130441665649414
Batch 6/64 loss: -1.2141046524047852
Batch 7/64 loss: -1.4176263809204102
Batch 8/64 loss: -1.3144073486328125
Batch 9/64 loss: -1.4009199142456055
Batch 10/64 loss: -1.0428638458251953
Batch 11/64 loss: -0.8936452865600586
Batch 12/64 loss: -1.3116636276245117
Batch 13/64 loss: -0.7185907363891602
Batch 14/64 loss: -1.1150636672973633
Batch 15/64 loss: -1.4082231521606445
Batch 16/64 loss: -1.506150245666504
Batch 17/64 loss: -1.3486013412475586
Batch 18/64 loss: -1.5459556579589844
Batch 19/64 loss: -1.3157997131347656
Batch 20/64 loss: -1.3202276229858398
Batch 21/64 loss: -1.3770666122436523
Batch 22/64 loss: -1.4569292068481445
Batch 23/64 loss: -1.1378278732299805
Batch 24/64 loss: -1.0989446640014648
Batch 25/64 loss: -0.7213726043701172
Batch 26/64 loss: -0.9256925582885742
Batch 27/64 loss: -1.369675636291504
Batch 28/64 loss: -1.508927345275879
Batch 29/64 loss: -0.9991979598999023
Batch 30/64 loss: -1.5302314758300781
Batch 31/64 loss: -1.6492838859558105
Batch 32/64 loss: -1.058542251586914
Batch 33/64 loss: -1.475560188293457
Batch 34/64 loss: -1.412043571472168
Batch 35/64 loss: -1.4118709564208984
Batch 36/64 loss: -0.8376092910766602
Batch 37/64 loss: -1.2470178604125977
Batch 38/64 loss: -1.3817310333251953
Batch 39/64 loss: -1.283940315246582
Batch 40/64 loss: -0.9586811065673828
Batch 41/64 loss: -1.6966676712036133
Batch 42/64 loss: -1.4214849472045898
Batch 43/64 loss: -1.0451154708862305
Batch 44/64 loss: -1.238905906677246
Batch 45/64 loss: -1.2685565948486328
Batch 46/64 loss: -1.3646326065063477
Batch 47/64 loss: -1.3160934448242188
Batch 48/64 loss: -1.1672096252441406
Batch 49/64 loss: -1.3652362823486328
Batch 50/64 loss: -1.2765893936157227
Batch 51/64 loss: -1.3522224426269531
Batch 52/64 loss: -1.5272769927978516
Batch 53/64 loss: -1.548452377319336
Batch 54/64 loss: -1.4797468185424805
Batch 55/64 loss: -0.677978515625
Batch 56/64 loss: -1.2395448684692383
Batch 57/64 loss: -1.5161428451538086
Batch 58/64 loss: -1.4890508651733398
Batch 59/64 loss: -1.1191225051879883
Batch 60/64 loss: -0.8190708160400391
Batch 61/64 loss: -1.3688297271728516
Batch 62/64 loss: -0.4057960510253906
Batch 63/64 loss: -1.1981019973754883
Batch 64/64 loss: -5.483976364135742
Epoch 181  Train loss: -1.310984981761259  Val loss: -1.4746007755449957
Saving best model, epoch: 181
Epoch 182
-------------------------------
Batch 1/64 loss: -1.2281513214111328
Batch 2/64 loss: -1.4052581787109375
Batch 3/64 loss: -1.2241859436035156
Batch 4/64 loss: -1.4327306747436523
Batch 5/64 loss: -1.5685091018676758
Batch 6/64 loss: -1.3799076080322266
Batch 7/64 loss: -1.5105104446411133
Batch 8/64 loss: -1.3951997756958008
Batch 9/64 loss: -1.6737041473388672
Batch 10/64 loss: -0.8950185775756836
Batch 11/64 loss: -1.4502840042114258
Batch 12/64 loss: -1.40533447265625
Batch 13/64 loss: -1.2586297988891602
Batch 14/64 loss: -1.302968978881836
Batch 15/64 loss: -1.343083381652832
Batch 16/64 loss: -1.0511016845703125
Batch 17/64 loss: -1.454838752746582
Batch 18/64 loss: -1.0513696670532227
Batch 19/64 loss: -1.4918193817138672
Batch 20/64 loss: -1.415679931640625
Batch 21/64 loss: -1.589268684387207
Batch 22/64 loss: -1.3652305603027344
Batch 23/64 loss: -0.941990852355957
Batch 24/64 loss: -1.137969970703125
Batch 25/64 loss: -1.3494243621826172
Batch 26/64 loss: -1.4968175888061523
Batch 27/64 loss: -1.3460874557495117
Batch 28/64 loss: -1.2433996200561523
Batch 29/64 loss: -1.6706867218017578
Batch 30/64 loss: -1.3673505783081055
Batch 31/64 loss: -1.4131536483764648
Batch 32/64 loss: -1.4267454147338867
Batch 33/64 loss: -1.2393465042114258
Batch 34/64 loss: -1.4366960525512695
Batch 35/64 loss: -1.4523706436157227
Batch 36/64 loss: -1.0727720260620117
Batch 37/64 loss: -0.931279182434082
Batch 38/64 loss: -0.7703075408935547
Batch 39/64 loss: -1.0597810745239258
Batch 40/64 loss: -1.193547248840332
Batch 41/64 loss: -1.3524837493896484
Batch 42/64 loss: -1.164297103881836
Batch 43/64 loss: -1.5936975479125977
Batch 44/64 loss: -1.3623981475830078
Batch 45/64 loss: -1.220015525817871
Batch 46/64 loss: -1.444392204284668
Batch 47/64 loss: -1.231898307800293
Batch 48/64 loss: -1.4522409439086914
Batch 49/64 loss: -0.6300239562988281
Batch 50/64 loss: -1.258575439453125
Batch 51/64 loss: -1.2437744140625
Batch 52/64 loss: -0.9178667068481445
Batch 53/64 loss: -0.571436882019043
Batch 54/64 loss: -0.7876596450805664
Batch 55/64 loss: -1.1833171844482422
Batch 56/64 loss: -1.2640800476074219
Batch 57/64 loss: -1.2555255889892578
Batch 58/64 loss: -1.209303855895996
Batch 59/64 loss: -1.3901491165161133
Batch 60/64 loss: -1.4839763641357422
Batch 61/64 loss: -1.3140573501586914
Batch 62/64 loss: -1.141866683959961
Batch 63/64 loss: -1.5311431884765625
Batch 64/64 loss: -5.441165924072266
Epoch 182  Train loss: -1.325922603233188  Val loss: -1.4718390395960856
Epoch 183
-------------------------------
Batch 1/64 loss: -1.1430625915527344
Batch 2/64 loss: -1.4453134536743164
Batch 3/64 loss: -1.3930931091308594
Batch 4/64 loss: -1.3721227645874023
Batch 5/64 loss: -1.3796415328979492
Batch 6/64 loss: -1.2894659042358398
Batch 7/64 loss: -1.471029281616211
Batch 8/64 loss: -1.1956110000610352
Batch 9/64 loss: -1.1629762649536133
Batch 10/64 loss: -1.0134944915771484
Batch 11/64 loss: -1.3124313354492188
Batch 12/64 loss: -0.934504508972168
Batch 13/64 loss: -1.3927373886108398
Batch 14/64 loss: -1.2115440368652344
Batch 15/64 loss: -0.8583345413208008
Batch 16/64 loss: -0.9581985473632812
Batch 17/64 loss: -1.5809803009033203
Batch 18/64 loss: -1.0670795440673828
Batch 19/64 loss: -1.5954885482788086
Batch 20/64 loss: -1.1208744049072266
Batch 21/64 loss: -1.4795188903808594
Batch 22/64 loss: -1.223240852355957
Batch 23/64 loss: -1.4879398345947266
Batch 24/64 loss: -1.3252630233764648
Batch 25/64 loss: -0.7940435409545898
Batch 26/64 loss: -1.3318119049072266
Batch 27/64 loss: -1.2801990509033203
Batch 28/64 loss: -1.4773063659667969
Batch 29/64 loss: -1.5458135604858398
Batch 30/64 loss: -1.6272544860839844
Batch 31/64 loss: -0.9699716567993164
Batch 32/64 loss: -1.1636543273925781
Batch 33/64 loss: -1.4878063201904297
Batch 34/64 loss: -1.1211576461791992
Batch 35/64 loss: -1.3459367752075195
Batch 36/64 loss: -1.2600507736206055
Batch 37/64 loss: -1.3926973342895508
Batch 38/64 loss: -1.188054084777832
Batch 39/64 loss: -1.4309415817260742
Batch 40/64 loss: -0.908111572265625
Batch 41/64 loss: -1.3098020553588867
Batch 42/64 loss: -1.2912368774414062
Batch 43/64 loss: -1.6440372467041016
Batch 44/64 loss: -1.432682991027832
Batch 45/64 loss: -1.0252466201782227
Batch 46/64 loss: -1.4467153549194336
Batch 47/64 loss: -1.413003921508789
Batch 48/64 loss: -1.5029239654541016
Batch 49/64 loss: -1.0450820922851562
Batch 50/64 loss: -1.5584192276000977
Batch 51/64 loss: -1.4408588409423828
Batch 52/64 loss: -1.4572868347167969
Batch 53/64 loss: -1.4717636108398438
Batch 54/64 loss: -1.4052448272705078
Batch 55/64 loss: -1.4738492965698242
Batch 56/64 loss: -1.3328962326049805
Batch 57/64 loss: -1.4805707931518555
Batch 58/64 loss: -0.9341096878051758
Batch 59/64 loss: -0.9021625518798828
Batch 60/64 loss: -1.1241788864135742
Batch 61/64 loss: -1.2003965377807617
Batch 62/64 loss: -1.2816247940063477
Batch 63/64 loss: -1.5263090133666992
Batch 64/64 loss: -5.215980529785156
Epoch 183  Train loss: -1.3388414869121477  Val loss: -1.4227671934566957
Epoch 184
-------------------------------
Batch 1/64 loss: -1.3306541442871094
Batch 2/64 loss: -1.670858383178711
Batch 3/64 loss: -1.236903190612793
Batch 4/64 loss: -1.5815839767456055
Batch 5/64 loss: -1.3348445892333984
Batch 6/64 loss: -1.2371892929077148
Batch 7/64 loss: -1.3533220291137695
Batch 8/64 loss: -1.443934440612793
Batch 9/64 loss: -1.421586036682129
Batch 10/64 loss: -1.4462690353393555
Batch 11/64 loss: -0.8576488494873047
Batch 12/64 loss: -1.1615161895751953
Batch 13/64 loss: -0.9656400680541992
Batch 14/64 loss: -1.494492530822754
Batch 15/64 loss: -1.113077163696289
Batch 16/64 loss: -1.402151107788086
Batch 17/64 loss: -1.0554208755493164
Batch 18/64 loss: -1.1558055877685547
Batch 19/64 loss: -1.181971549987793
Batch 20/64 loss: -1.1729812622070312
Batch 21/64 loss: -1.4010686874389648
Batch 22/64 loss: -1.3449230194091797
Batch 23/64 loss: -1.0295543670654297
Batch 24/64 loss: -1.0937929153442383
Batch 25/64 loss: -1.495305061340332
Batch 26/64 loss: -1.5092535018920898
Batch 27/64 loss: -1.2620553970336914
Batch 28/64 loss: -0.888026237487793
Batch 29/64 loss: -0.5913295745849609
Batch 30/64 loss: -1.6258459091186523
Batch 31/64 loss: -1.604222297668457
Batch 32/64 loss: -1.5192604064941406
Batch 33/64 loss: -1.2474384307861328
Batch 34/64 loss: -1.0722064971923828
Batch 35/64 loss: -1.0591917037963867
Batch 36/64 loss: -1.1128616333007812
Batch 37/64 loss: -1.3437061309814453
Batch 38/64 loss: -1.187234878540039
Batch 39/64 loss: -1.2901182174682617
Batch 40/64 loss: -1.1763362884521484
Batch 41/64 loss: -1.102646827697754
Batch 42/64 loss: -0.5744714736938477
Batch 43/64 loss: -1.061579704284668
Batch 44/64 loss: -1.254730224609375
Batch 45/64 loss: -0.3647027015686035
Batch 46/64 loss: -0.9080009460449219
Batch 47/64 loss: -1.3763790130615234
Batch 48/64 loss: -0.8266067504882812
Batch 49/64 loss: -1.0492353439331055
Batch 50/64 loss: -1.1865415573120117
Batch 51/64 loss: -1.123368263244629
Batch 52/64 loss: -1.4532194137573242
Batch 53/64 loss: -1.1242809295654297
Batch 54/64 loss: -1.4594287872314453
Batch 55/64 loss: -0.9839410781860352
Batch 56/64 loss: -1.3377151489257812
Batch 57/64 loss: -1.2978734970092773
Batch 58/64 loss: -1.2932281494140625
Batch 59/64 loss: -1.4742660522460938
Batch 60/64 loss: -1.3069524765014648
Batch 61/64 loss: -1.3130683898925781
Batch 62/64 loss: -1.4861221313476562
Batch 63/64 loss: -1.0638103485107422
Batch 64/64 loss: -5.484426975250244
Epoch 184  Train loss: -1.270699151357015  Val loss: -1.332694430531505
Epoch 185
-------------------------------
Batch 1/64 loss: -1.1784172058105469
Batch 2/64 loss: -1.4169206619262695
Batch 3/64 loss: -1.6070489883422852
Batch 4/64 loss: -1.4142169952392578
Batch 5/64 loss: -1.1150083541870117
Batch 6/64 loss: -1.176070213317871
Batch 7/64 loss: -1.6014270782470703
Batch 8/64 loss: -1.0749807357788086
Batch 9/64 loss: -0.9472360610961914
Batch 10/64 loss: -1.6201658248901367
Batch 11/64 loss: -1.1973028182983398
Batch 12/64 loss: -1.370650291442871
Batch 13/64 loss: -1.2793283462524414
Batch 14/64 loss: -1.203995704650879
Batch 15/64 loss: -0.5959510803222656
Batch 16/64 loss: -1.4015893936157227
Batch 17/64 loss: -1.4296083450317383
Batch 18/64 loss: -1.3626489639282227
Batch 19/64 loss: -1.4240150451660156
Batch 20/64 loss: -1.5542144775390625
Batch 21/64 loss: -1.221358299255371
Batch 22/64 loss: -1.3624639511108398
Batch 23/64 loss: -0.9731950759887695
Batch 24/64 loss: -0.740595817565918
Batch 25/64 loss: -1.231368064880371
Batch 26/64 loss: -1.0881843566894531
Batch 27/64 loss: -1.4529504776000977
Batch 28/64 loss: -1.1554975509643555
Batch 29/64 loss: -1.1307373046875
Batch 30/64 loss: -1.0785331726074219
Batch 31/64 loss: -1.2476940155029297
Batch 32/64 loss: -1.3364877700805664
Batch 33/64 loss: -1.4413528442382812
Batch 34/64 loss: -1.0682754516601562
Batch 35/64 loss: -1.2762784957885742
Batch 36/64 loss: -1.1978731155395508
Batch 37/64 loss: -1.1226129531860352
Batch 38/64 loss: -1.114455223083496
Batch 39/64 loss: -1.0002202987670898
Batch 40/64 loss: -1.335550308227539
Batch 41/64 loss: -1.4672327041625977
Batch 42/64 loss: -1.1654186248779297
Batch 43/64 loss: -1.4964618682861328
Batch 44/64 loss: -1.3515615463256836
Batch 45/64 loss: -1.5992431640625
Batch 46/64 loss: -1.5764379501342773
Batch 47/64 loss: -1.010660171508789
Batch 48/64 loss: -1.1207141876220703
Batch 49/64 loss: -1.3411493301391602
Batch 50/64 loss: -1.3447351455688477
Batch 51/64 loss: -1.023721694946289
Batch 52/64 loss: -1.2447919845581055
Batch 53/64 loss: -0.9658708572387695
Batch 54/64 loss: -1.10931396484375
Batch 55/64 loss: -1.3531341552734375
Batch 56/64 loss: -1.3063430786132812
Batch 57/64 loss: -1.5931129455566406
Batch 58/64 loss: -1.1771535873413086
Batch 59/64 loss: -1.5010786056518555
Batch 60/64 loss: -0.9704160690307617
Batch 61/64 loss: -1.6736822128295898
Batch 62/64 loss: -1.1961135864257812
Batch 63/64 loss: -0.6246509552001953
Batch 64/64 loss: -5.538450241088867
Epoch 185  Train loss: -1.3006010541728898  Val loss: -1.3792568744253046
Epoch 186
-------------------------------
Batch 1/64 loss: -1.1249628067016602
Batch 2/64 loss: -1.1510772705078125
Batch 3/64 loss: -1.334935188293457
Batch 4/64 loss: -1.5507879257202148
Batch 5/64 loss: -1.0475788116455078
Batch 6/64 loss: -1.677236557006836
Batch 7/64 loss: -1.3876838684082031
Batch 8/64 loss: -1.2141180038452148
Batch 9/64 loss: -1.2954845428466797
Batch 10/64 loss: -1.7054147720336914
Batch 11/64 loss: -1.1251802444458008
Batch 12/64 loss: -1.4633445739746094
Batch 13/64 loss: -1.125478744506836
Batch 14/64 loss: -1.4365530014038086
Batch 15/64 loss: -1.3715744018554688
Batch 16/64 loss: -0.8504829406738281
Batch 17/64 loss: -1.3020896911621094
Batch 18/64 loss: -1.523116111755371
Batch 19/64 loss: -0.7896175384521484
Batch 20/64 loss: -1.4182090759277344
Batch 21/64 loss: -1.3241901397705078
Batch 22/64 loss: -1.3158483505249023
Batch 23/64 loss: -1.4125614166259766
Batch 24/64 loss: -0.5863552093505859
Batch 25/64 loss: -1.4319839477539062
Batch 26/64 loss: -1.468642234802246
Batch 27/64 loss: -1.1774425506591797
Batch 28/64 loss: -1.3870353698730469
Batch 29/64 loss: -1.2667007446289062
Batch 30/64 loss: -1.508087158203125
Batch 31/64 loss: -1.5553712844848633
Batch 32/64 loss: -1.5337743759155273
Batch 33/64 loss: -1.3346176147460938
Batch 34/64 loss: -1.303746223449707
Batch 35/64 loss: -1.4735307693481445
Batch 36/64 loss: -1.2478065490722656
Batch 37/64 loss: -1.5210399627685547
Batch 38/64 loss: -1.2010068893432617
Batch 39/64 loss: -1.2550601959228516
Batch 40/64 loss: -1.3476552963256836
Batch 41/64 loss: -1.4944162368774414
Batch 42/64 loss: -1.0320329666137695
Batch 43/64 loss: -0.6844825744628906
Batch 44/64 loss: -1.1828737258911133
Batch 45/64 loss: -1.5146446228027344
Batch 46/64 loss: -0.9318752288818359
Batch 47/64 loss: -1.3644275665283203
Batch 48/64 loss: -1.5145578384399414
Batch 49/64 loss: -1.5625782012939453
Batch 50/64 loss: -0.9488792419433594
Batch 51/64 loss: -1.3941383361816406
Batch 52/64 loss: -0.9891548156738281
Batch 53/64 loss: -1.3324155807495117
Batch 54/64 loss: -1.5796327590942383
Batch 55/64 loss: -0.9582223892211914
Batch 56/64 loss: -1.2934198379516602
Batch 57/64 loss: -1.1904029846191406
Batch 58/64 loss: -1.1536931991577148
Batch 59/64 loss: -1.3425111770629883
Batch 60/64 loss: -1.2059707641601562
Batch 61/64 loss: -1.2151498794555664
Batch 62/64 loss: -0.9057426452636719
Batch 63/64 loss: -0.9477787017822266
Batch 64/64 loss: -5.444561958312988
Epoch 186  Train loss: -1.3234479230992935  Val loss: -1.4100744896328326
Epoch 187
-------------------------------
Batch 1/64 loss: -0.7597522735595703
Batch 2/64 loss: -1.3451223373413086
Batch 3/64 loss: -1.440596580505371
Batch 4/64 loss: -1.2984733581542969
Batch 5/64 loss: -1.3551139831542969
Batch 6/64 loss: -1.2188949584960938
Batch 7/64 loss: -1.3932838439941406
Batch 8/64 loss: -1.3397512435913086
Batch 9/64 loss: -1.6158199310302734
Batch 10/64 loss: -1.383066177368164
Batch 11/64 loss: -1.6311254501342773
Batch 12/64 loss: -1.3417930603027344
Batch 13/64 loss: -1.1454191207885742
Batch 14/64 loss: -1.409581184387207
Batch 15/64 loss: -1.1090164184570312
Batch 16/64 loss: -1.5109376907348633
Batch 17/64 loss: -1.1760797500610352
Batch 18/64 loss: -1.1608495712280273
Batch 19/64 loss: -0.8507204055786133
Batch 20/64 loss: -1.2913389205932617
Batch 21/64 loss: -1.1093788146972656
Batch 22/64 loss: -1.3932561874389648
Batch 23/64 loss: -1.1589794158935547
Batch 24/64 loss: -1.2697410583496094
Batch 25/64 loss: -0.8540668487548828
Batch 26/64 loss: -1.4099178314208984
Batch 27/64 loss: -1.594527244567871
Batch 28/64 loss: -1.4038505554199219
Batch 29/64 loss: -1.4965314865112305
Batch 30/64 loss: -1.1948013305664062
Batch 31/64 loss: -1.1533632278442383
Batch 32/64 loss: -1.1578950881958008
Batch 33/64 loss: -1.217524528503418
Batch 34/64 loss: -1.1878700256347656
Batch 35/64 loss: -1.121267318725586
Batch 36/64 loss: -1.246443748474121
Batch 37/64 loss: -1.248185157775879
Batch 38/64 loss: -1.1846981048583984
Batch 39/64 loss: -1.2776031494140625
Batch 40/64 loss: -0.789729118347168
Batch 41/64 loss: -1.2733068466186523
Batch 42/64 loss: -0.4963207244873047
Batch 43/64 loss: -1.6197099685668945
Batch 44/64 loss: -1.0484628677368164
Batch 45/64 loss: -1.2900619506835938
Batch 46/64 loss: -1.3896818161010742
Batch 47/64 loss: -0.8392362594604492
Batch 48/64 loss: -1.2938308715820312
Batch 49/64 loss: -1.2181005477905273
Batch 50/64 loss: -1.3162221908569336
Batch 51/64 loss: -1.289048194885254
Batch 52/64 loss: -1.3957719802856445
Batch 53/64 loss: -1.4256696701049805
Batch 54/64 loss: -1.5568828582763672
Batch 55/64 loss: -1.5013580322265625
Batch 56/64 loss: -1.5275030136108398
Batch 57/64 loss: -1.0263967514038086
Batch 58/64 loss: -1.1218500137329102
Batch 59/64 loss: -1.491999626159668
Batch 60/64 loss: -0.8576078414916992
Batch 61/64 loss: -1.2703638076782227
Batch 62/64 loss: -1.362950325012207
Batch 63/64 loss: -1.1282949447631836
Batch 64/64 loss: -5.377049922943115
Epoch 187  Train loss: -1.3022711379855287  Val loss: -1.3093444457168841
Epoch 188
-------------------------------
Batch 1/64 loss: -1.5280399322509766
Batch 2/64 loss: -1.3651952743530273
Batch 3/64 loss: -1.3442983627319336
Batch 4/64 loss: -1.1524600982666016
Batch 5/64 loss: -1.197957992553711
Batch 6/64 loss: -1.2406797409057617
Batch 7/64 loss: -1.0391244888305664
Batch 8/64 loss: -1.0675926208496094
Batch 9/64 loss: -1.4270095825195312
Batch 10/64 loss: -1.336848258972168
Batch 11/64 loss: -1.452829360961914
Batch 12/64 loss: -1.2296323776245117
Batch 13/64 loss: -1.515481948852539
Batch 14/64 loss: -0.8656835556030273
Batch 15/64 loss: -1.3887414932250977
Batch 16/64 loss: -1.3751153945922852
Batch 17/64 loss: -1.4860448837280273
Batch 18/64 loss: -1.2545394897460938
Batch 19/64 loss: -1.3768234252929688
Batch 20/64 loss: -1.5016164779663086
Batch 21/64 loss: -1.3158235549926758
Batch 22/64 loss: -1.311685562133789
Batch 23/64 loss: -1.5460119247436523
Batch 24/64 loss: -1.3978147506713867
Batch 25/64 loss: -0.5047225952148438
Batch 26/64 loss: -0.9039306640625
Batch 27/64 loss: -1.3754606246948242
Batch 28/64 loss: -1.1994361877441406
Batch 29/64 loss: -1.446847915649414
Batch 30/64 loss: -1.4443016052246094
Batch 31/64 loss: -1.2628173828125
Batch 32/64 loss: -1.5545663833618164
Batch 33/64 loss: -0.9006118774414062
Batch 34/64 loss: -1.4947090148925781
Batch 35/64 loss: -1.3915348052978516
Batch 36/64 loss: -1.4992570877075195
Batch 37/64 loss: -1.1376304626464844
Batch 38/64 loss: -1.581913948059082
Batch 39/64 loss: -1.1660547256469727
Batch 40/64 loss: -1.592428207397461
Batch 41/64 loss: -1.5142602920532227
Batch 42/64 loss: -1.3676204681396484
Batch 43/64 loss: -1.0413179397583008
Batch 44/64 loss: -1.4301977157592773
Batch 45/64 loss: -1.3914966583251953
Batch 46/64 loss: -1.4014205932617188
Batch 47/64 loss: -0.7238359451293945
Batch 48/64 loss: -1.517746925354004
Batch 49/64 loss: -1.4409847259521484
Batch 50/64 loss: -1.409550666809082
Batch 51/64 loss: -1.4828205108642578
Batch 52/64 loss: -1.0744342803955078
Batch 53/64 loss: -1.1263647079467773
Batch 54/64 loss: -1.3081731796264648
Batch 55/64 loss: -0.4265451431274414
Batch 56/64 loss: -1.2208070755004883
Batch 57/64 loss: -1.115910530090332
Batch 58/64 loss: -0.8313465118408203
Batch 59/64 loss: -0.9729127883911133
Batch 60/64 loss: -1.4119024276733398
Batch 61/64 loss: -1.5412979125976562
Batch 62/64 loss: -0.8928442001342773
Batch 63/64 loss: -1.022658348083496
Batch 64/64 loss: -5.288797378540039
Epoch 188  Train loss: -1.3146089666029985  Val loss: -1.40369767913294
Epoch 189
-------------------------------
Batch 1/64 loss: -1.3735227584838867
Batch 2/64 loss: -1.3544921875
Batch 3/64 loss: -1.3182544708251953
Batch 4/64 loss: -1.2086753845214844
Batch 5/64 loss: -0.6565284729003906
Batch 6/64 loss: -1.1411361694335938
Batch 7/64 loss: -1.368058204650879
Batch 8/64 loss: -1.5334720611572266
Batch 9/64 loss: -1.3360652923583984
Batch 10/64 loss: -1.5585203170776367
Batch 11/64 loss: -1.3242368698120117
Batch 12/64 loss: -0.9612092971801758
Batch 13/64 loss: -1.3566913604736328
Batch 14/64 loss: -1.7567787170410156
Batch 15/64 loss: -1.3482131958007812
Batch 16/64 loss: -0.7745914459228516
Batch 17/64 loss: -1.5955591201782227
Batch 18/64 loss: -1.3386363983154297
Batch 19/64 loss: -1.2256641387939453
Batch 20/64 loss: -1.271845817565918
Batch 21/64 loss: -0.9711713790893555
Batch 22/64 loss: -1.007965087890625
Batch 23/64 loss: -1.3584842681884766
Batch 24/64 loss: -1.071608543395996
Batch 25/64 loss: -1.491358757019043
Batch 26/64 loss: -0.9608135223388672
Batch 27/64 loss: -1.2505807876586914
Batch 28/64 loss: -0.9979543685913086
Batch 29/64 loss: -1.4056100845336914
Batch 30/64 loss: -0.8816728591918945
Batch 31/64 loss: -1.3661699295043945
Batch 32/64 loss: -1.2315616607666016
Batch 33/64 loss: -1.1646862030029297
Batch 34/64 loss: -1.3088798522949219
Batch 35/64 loss: -1.428267478942871
Batch 36/64 loss: -1.218073844909668
Batch 37/64 loss: -1.212214469909668
Batch 38/64 loss: -1.4303092956542969
Batch 39/64 loss: -1.3063287734985352
Batch 40/64 loss: -1.2595300674438477
Batch 41/64 loss: -1.6738471984863281
Batch 42/64 loss: -1.3444843292236328
Batch 43/64 loss: -1.1346054077148438
Batch 44/64 loss: -1.336334228515625
Batch 45/64 loss: -1.3523445129394531
Batch 46/64 loss: -1.2332639694213867
Batch 47/64 loss: -1.3406572341918945
Batch 48/64 loss: -1.368178367614746
Batch 49/64 loss: -1.0593414306640625
Batch 50/64 loss: -1.4370088577270508
Batch 51/64 loss: -1.3972482681274414
Batch 52/64 loss: -1.642399787902832
Batch 53/64 loss: -1.2786951065063477
Batch 54/64 loss: -1.1765918731689453
Batch 55/64 loss: -0.9894504547119141
Batch 56/64 loss: -1.1612358093261719
Batch 57/64 loss: -0.9364128112792969
Batch 58/64 loss: -1.4714641571044922
Batch 59/64 loss: -1.0380315780639648
Batch 60/64 loss: -0.9982442855834961
Batch 61/64 loss: -1.1181879043579102
Batch 62/64 loss: -1.2176551818847656
Batch 63/64 loss: -1.4247140884399414
Batch 64/64 loss: -4.916043281555176
Epoch 189  Train loss: -1.3010638779284907  Val loss: -1.2780828443179835
Epoch 190
-------------------------------
Batch 1/64 loss: -1.4381170272827148
Batch 2/64 loss: -1.0223779678344727
Batch 3/64 loss: -0.9330453872680664
Batch 4/64 loss: -1.4960508346557617
Batch 5/64 loss: -1.4455804824829102
Batch 6/64 loss: -1.3704242706298828
Batch 7/64 loss: -1.5572538375854492
Batch 8/64 loss: -1.5178709030151367
Batch 9/64 loss: -0.9517974853515625
Batch 10/64 loss: -1.4409189224243164
Batch 11/64 loss: -0.9035892486572266
Batch 12/64 loss: -1.5631933212280273
Batch 13/64 loss: -1.4324874877929688
Batch 14/64 loss: -1.1962099075317383
Batch 15/64 loss: -1.6484012603759766
Batch 16/64 loss: -1.0781822204589844
Batch 17/64 loss: -1.6361360549926758
Batch 18/64 loss: -1.4945573806762695
Batch 19/64 loss: -1.4755496978759766
Batch 20/64 loss: -1.2536020278930664
Batch 21/64 loss: -1.3858766555786133
Batch 22/64 loss: -1.1912717819213867
Batch 23/64 loss: -1.0401897430419922
Batch 24/64 loss: -1.3926382064819336
Batch 25/64 loss: -1.5732355117797852
Batch 26/64 loss: -1.3538875579833984
Batch 27/64 loss: -1.0700855255126953
Batch 28/64 loss: -1.4017400741577148
Batch 29/64 loss: -1.5065488815307617
Batch 30/64 loss: -1.3719768524169922
Batch 31/64 loss: -0.7513208389282227
Batch 32/64 loss: -1.5054035186767578
Batch 33/64 loss: -1.1001920700073242
Batch 34/64 loss: -1.637014389038086
Batch 35/64 loss: -1.230337142944336
Batch 36/64 loss: -1.3486804962158203
Batch 37/64 loss: -1.3687677383422852
Batch 38/64 loss: -1.4692811965942383
Batch 39/64 loss: -1.1994266510009766
Batch 40/64 loss: -1.364858627319336
Batch 41/64 loss: -1.4252347946166992
Batch 42/64 loss: -1.1386957168579102
Batch 43/64 loss: -1.3632535934448242
Batch 44/64 loss: -0.5925474166870117
Batch 45/64 loss: -0.5114336013793945
Batch 46/64 loss: -1.5805339813232422
Batch 47/64 loss: -1.3047332763671875
Batch 48/64 loss: -1.231156349182129
Batch 49/64 loss: -1.1261682510375977
Batch 50/64 loss: -1.1045465469360352
Batch 51/64 loss: -1.1248054504394531
Batch 52/64 loss: -1.344252586364746
Batch 53/64 loss: -1.3617057800292969
Batch 54/64 loss: -1.166367530822754
Batch 55/64 loss: -1.0732927322387695
Batch 56/64 loss: -1.6031980514526367
Batch 57/64 loss: -1.1473960876464844
Batch 58/64 loss: -1.4171524047851562
Batch 59/64 loss: -1.0179443359375
Batch 60/64 loss: -1.4337940216064453
Batch 61/64 loss: -1.44818115234375
Batch 62/64 loss: -1.6526861190795898
Batch 63/64 loss: -1.3038558959960938
Batch 64/64 loss: -5.193657875061035
Epoch 190  Train loss: -1.3409609140134324  Val loss: -1.4697309539899794
Epoch 191
-------------------------------
Batch 1/64 loss: -1.3548336029052734
Batch 2/64 loss: -1.5115013122558594
Batch 3/64 loss: -1.4423160552978516
Batch 4/64 loss: -1.3810615539550781
Batch 5/64 loss: -1.526535987854004
Batch 6/64 loss: -1.4557304382324219
Batch 7/64 loss: -1.3742332458496094
Batch 8/64 loss: -1.3414268493652344
Batch 9/64 loss: -1.135568618774414
Batch 10/64 loss: -1.5594968795776367
Batch 11/64 loss: -0.8774948120117188
Batch 12/64 loss: -1.489501953125
Batch 13/64 loss: -1.164423942565918
Batch 14/64 loss: -0.8859882354736328
Batch 15/64 loss: -1.0810279846191406
Batch 16/64 loss: -1.427978515625
Batch 17/64 loss: -1.2638130187988281
Batch 18/64 loss: -1.2536592483520508
Batch 19/64 loss: -1.2338476181030273
Batch 20/64 loss: -1.308065414428711
Batch 21/64 loss: -1.5683040618896484
Batch 22/64 loss: -0.8535270690917969
Batch 23/64 loss: -1.4509429931640625
Batch 24/64 loss: -1.5013341903686523
Batch 25/64 loss: -1.3260889053344727
Batch 26/64 loss: -1.5789403915405273
Batch 27/64 loss: -1.2815752029418945
Batch 28/64 loss: -1.2019929885864258
Batch 29/64 loss: -1.2737207412719727
Batch 30/64 loss: -0.7002096176147461
Batch 31/64 loss: -1.5476255416870117
Batch 32/64 loss: -1.3409795761108398
Batch 33/64 loss: -1.2770671844482422
Batch 34/64 loss: -1.0266246795654297
Batch 35/64 loss: -1.2602081298828125
Batch 36/64 loss: -1.0266590118408203
Batch 37/64 loss: -1.3161115646362305
Batch 38/64 loss: -0.981287956237793
Batch 39/64 loss: -1.5287656784057617
Batch 40/64 loss: -1.3225078582763672
Batch 41/64 loss: -1.4231252670288086
Batch 42/64 loss: -1.5779590606689453
Batch 43/64 loss: -1.4352054595947266
Batch 44/64 loss: -1.2947101593017578
Batch 45/64 loss: -1.3149871826171875
Batch 46/64 loss: -1.2551031112670898
Batch 47/64 loss: -1.3840112686157227
Batch 48/64 loss: -1.4338130950927734
Batch 49/64 loss: -1.5182113647460938
Batch 50/64 loss: -1.6231422424316406
Batch 51/64 loss: -1.1457252502441406
Batch 52/64 loss: -1.4899253845214844
Batch 53/64 loss: -1.250391960144043
Batch 54/64 loss: -1.204564094543457
Batch 55/64 loss: -1.1937360763549805
Batch 56/64 loss: -1.4597539901733398
Batch 57/64 loss: -1.2607488632202148
Batch 58/64 loss: -1.2758159637451172
Batch 59/64 loss: -1.3911008834838867
Batch 60/64 loss: -1.2946481704711914
Batch 61/64 loss: -1.559453010559082
Batch 62/64 loss: -0.9751749038696289
Batch 63/64 loss: -1.4016656875610352
Batch 64/64 loss: -5.25808048248291
Epoch 191  Train loss: -1.3574825324264228  Val loss: -1.0497342401353764
Epoch 192
-------------------------------
Batch 1/64 loss: -0.9908027648925781
Batch 2/64 loss: -1.1477737426757812
Batch 3/64 loss: -1.3171138763427734
Batch 4/64 loss: -1.1859636306762695
Batch 5/64 loss: -1.244466781616211
Batch 6/64 loss: -1.3889045715332031
Batch 7/64 loss: -1.2845335006713867
Batch 8/64 loss: -1.4733915328979492
Batch 9/64 loss: -1.4477481842041016
Batch 10/64 loss: -1.2441787719726562
Batch 11/64 loss: -1.030858039855957
Batch 12/64 loss: -1.2895746231079102
Batch 13/64 loss: -0.9868946075439453
Batch 14/64 loss: -1.3902654647827148
Batch 15/64 loss: -1.4821300506591797
Batch 16/64 loss: -1.5538339614868164
Batch 17/64 loss: -1.5451850891113281
Batch 18/64 loss: -1.1538219451904297
Batch 19/64 loss: -1.5636892318725586
Batch 20/64 loss: -0.9548425674438477
Batch 21/64 loss: -0.7763080596923828
Batch 22/64 loss: -1.6251020431518555
Batch 23/64 loss: -1.1869640350341797
Batch 24/64 loss: -1.401773452758789
Batch 25/64 loss: -1.144073486328125
Batch 26/64 loss: -1.401930809020996
Batch 27/64 loss: -0.8451805114746094
Batch 28/64 loss: -1.6367321014404297
Batch 29/64 loss: -1.6622486114501953
Batch 30/64 loss: -1.320962905883789
Batch 31/64 loss: -1.0721120834350586
Batch 32/64 loss: -1.6080284118652344
Batch 33/64 loss: -1.4459075927734375
Batch 34/64 loss: -1.1867218017578125
Batch 35/64 loss: -1.2822608947753906
Batch 36/64 loss: -1.2808208465576172
Batch 37/64 loss: -1.2272272109985352
Batch 38/64 loss: -1.1915092468261719
Batch 39/64 loss: -1.6629838943481445
Batch 40/64 loss: -1.552769660949707
Batch 41/64 loss: -1.0700149536132812
Batch 42/64 loss: -1.2548341751098633
Batch 43/64 loss: -1.3516311645507812
Batch 44/64 loss: -1.2121257781982422
Batch 45/64 loss: -1.3297138214111328
Batch 46/64 loss: -1.6417980194091797
Batch 47/64 loss: -0.9849367141723633
Batch 48/64 loss: -0.9441032409667969
Batch 49/64 loss: -0.7600002288818359
Batch 50/64 loss: -1.423257827758789
Batch 51/64 loss: -1.2945985794067383
Batch 52/64 loss: -1.5852994918823242
Batch 53/64 loss: -1.6928730010986328
Batch 54/64 loss: -1.4777307510375977
Batch 55/64 loss: -1.056879997253418
Batch 56/64 loss: -1.1617803573608398
Batch 57/64 loss: -1.3128528594970703
Batch 58/64 loss: -1.2894411087036133
Batch 59/64 loss: -1.6133594512939453
Batch 60/64 loss: -1.5702056884765625
Batch 61/64 loss: -1.3541088104248047
Batch 62/64 loss: -1.3500308990478516
Batch 63/64 loss: -1.0180377960205078
Batch 64/64 loss: -5.361494541168213
Epoch 192  Train loss: -1.3483659014982337  Val loss: -1.4228396333779667
Epoch 193
-------------------------------
Batch 1/64 loss: -1.0680599212646484
Batch 2/64 loss: -1.3582391738891602
Batch 3/64 loss: -1.4130878448486328
Batch 4/64 loss: -1.069340705871582
Batch 5/64 loss: -1.4021520614624023
Batch 6/64 loss: -1.4955072402954102
Batch 7/64 loss: -1.3646173477172852
Batch 8/64 loss: -1.5382719039916992
Batch 9/64 loss: -0.8979158401489258
Batch 10/64 loss: -1.5995922088623047
Batch 11/64 loss: -1.4874629974365234
Batch 12/64 loss: -1.4801855087280273
Batch 13/64 loss: -1.3691511154174805
Batch 14/64 loss: -1.320037841796875
Batch 15/64 loss: -0.8804216384887695
Batch 16/64 loss: -1.3410606384277344
Batch 17/64 loss: -1.3992528915405273
Batch 18/64 loss: -1.1594181060791016
Batch 19/64 loss: -1.5275774002075195
Batch 20/64 loss: -1.6318302154541016
Batch 21/64 loss: -1.5037517547607422
Batch 22/64 loss: -1.4249744415283203
Batch 23/64 loss: -1.2232666015625
Batch 24/64 loss: -1.431680679321289
Batch 25/64 loss: -0.8905391693115234
Batch 26/64 loss: -1.4287004470825195
Batch 27/64 loss: -1.3643407821655273
Batch 28/64 loss: -0.9261693954467773
Batch 29/64 loss: -1.6859540939331055
Batch 30/64 loss: -0.7293300628662109
Batch 31/64 loss: -1.0034170150756836
Batch 32/64 loss: -1.2443294525146484
Batch 33/64 loss: -1.3589239120483398
Batch 34/64 loss: -1.5333213806152344
Batch 35/64 loss: -1.705190658569336
Batch 36/64 loss: -1.3843584060668945
Batch 37/64 loss: -0.9486665725708008
Batch 38/64 loss: -0.9486894607543945
Batch 39/64 loss: -1.4717903137207031
Batch 40/64 loss: -1.5361251831054688
Batch 41/64 loss: -1.027069091796875
Batch 42/64 loss: -1.5252857208251953
Batch 43/64 loss: -1.5897436141967773
Batch 44/64 loss: -1.2804641723632812
Batch 45/64 loss: -1.656876564025879
Batch 46/64 loss: -1.8436765670776367
Batch 47/64 loss: -1.5871648788452148
Batch 48/64 loss: -1.5542726516723633
Batch 49/64 loss: -1.1350936889648438
Batch 50/64 loss: -1.0167779922485352
Batch 51/64 loss: -1.0187921524047852
Batch 52/64 loss: -1.1344127655029297
Batch 53/64 loss: -1.5891914367675781
Batch 54/64 loss: -0.9832000732421875
Batch 55/64 loss: -1.7270565032958984
Batch 56/64 loss: -1.6187572479248047
Batch 57/64 loss: -1.156224250793457
Batch 58/64 loss: -1.229182243347168
Batch 59/64 loss: -1.6758604049682617
Batch 60/64 loss: -1.593043327331543
Batch 61/64 loss: -1.399418830871582
Batch 62/64 loss: -1.5720911026000977
Batch 63/64 loss: -1.387782096862793
Batch 64/64 loss: -4.964138507843018
Epoch 193  Train loss: -1.3893528414707559  Val loss: -1.4139759286572433
Epoch 194
-------------------------------
Batch 1/64 loss: -1.4329242706298828
Batch 2/64 loss: -1.3600921630859375
Batch 3/64 loss: -1.451460838317871
Batch 4/64 loss: -1.5807151794433594
Batch 5/64 loss: -1.186004638671875
Batch 6/64 loss: -1.4433164596557617
Batch 7/64 loss: -1.371851921081543
Batch 8/64 loss: -1.6302490234375
Batch 9/64 loss: -0.955876350402832
Batch 10/64 loss: -1.576981544494629
Batch 11/64 loss: -1.5098161697387695
Batch 12/64 loss: -1.536646842956543
Batch 13/64 loss: -1.125844955444336
Batch 14/64 loss: -1.4799079895019531
Batch 15/64 loss: -1.4369287490844727
Batch 16/64 loss: -1.5092315673828125
Batch 17/64 loss: -1.2787303924560547
Batch 18/64 loss: -1.2962141036987305
Batch 19/64 loss: -1.3945531845092773
Batch 20/64 loss: -1.5871734619140625
Batch 21/64 loss: -1.3640108108520508
Batch 22/64 loss: -1.3855161666870117
Batch 23/64 loss: -1.6478748321533203
Batch 24/64 loss: -1.0879955291748047
Batch 25/64 loss: -1.1541786193847656
Batch 26/64 loss: -1.490736961364746
Batch 27/64 loss: -1.5115842819213867
Batch 28/64 loss: -1.4808082580566406
Batch 29/64 loss: -1.4513177871704102
Batch 30/64 loss: -1.6120319366455078
Batch 31/64 loss: -1.2304115295410156
Batch 32/64 loss: -1.239832878112793
Batch 33/64 loss: -1.466832160949707
Batch 34/64 loss: -1.7310590744018555
Batch 35/64 loss: -1.4124250411987305
Batch 36/64 loss: -1.3772811889648438
Batch 37/64 loss: -1.7446703910827637
Batch 38/64 loss: -1.3279733657836914
Batch 39/64 loss: -1.2612018585205078
Batch 40/64 loss: -0.8044471740722656
Batch 41/64 loss: -1.4267339706420898
Batch 42/64 loss: -1.0701675415039062
Batch 43/64 loss: -1.338235855102539
Batch 44/64 loss: -1.1510028839111328
Batch 45/64 loss: -1.127608299255371
Batch 46/64 loss: -1.1534290313720703
Batch 47/64 loss: -1.3077392578125
Batch 48/64 loss: -1.4853572845458984
Batch 49/64 loss: -1.1268253326416016
Batch 50/64 loss: -1.469010353088379
Batch 51/64 loss: -1.5666933059692383
Batch 52/64 loss: -0.6033573150634766
Batch 53/64 loss: -0.08995246887207031
Batch 54/64 loss: -1.5613889694213867
Batch 55/64 loss: -1.373849868774414
Batch 56/64 loss: -1.3234281539916992
Batch 57/64 loss: -1.5533323287963867
Batch 58/64 loss: -1.4167413711547852
Batch 59/64 loss: -1.2483282089233398
Batch 60/64 loss: -1.5268564224243164
Batch 61/64 loss: -1.1613054275512695
Batch 62/64 loss: -1.1856575012207031
Batch 63/64 loss: -1.0577774047851562
Batch 64/64 loss: -5.046553611755371
Epoch 194  Train loss: -1.3809631908641142  Val loss: -1.4840761033939742
Saving best model, epoch: 194
Epoch 195
-------------------------------
Batch 1/64 loss: -1.5148448944091797
Batch 2/64 loss: -1.0967912673950195
Batch 3/64 loss: -1.4456243515014648
Batch 4/64 loss: -1.0448675155639648
Batch 5/64 loss: -1.5744123458862305
Batch 6/64 loss: -1.1438980102539062
Batch 7/64 loss: -1.5497798919677734
Batch 8/64 loss: -1.4546318054199219
Batch 9/64 loss: -1.5888614654541016
Batch 10/64 loss: -1.2918014526367188
Batch 11/64 loss: -1.2824821472167969
Batch 12/64 loss: -1.0171232223510742
Batch 13/64 loss: -1.1083698272705078
Batch 14/64 loss: -1.066014289855957
Batch 15/64 loss: -1.2897863388061523
Batch 16/64 loss: -1.3121070861816406
Batch 17/64 loss: -1.335881233215332
Batch 18/64 loss: -1.3433160781860352
Batch 19/64 loss: -1.3160200119018555
Batch 20/64 loss: -1.1832799911499023
Batch 21/64 loss: -1.1851682662963867
Batch 22/64 loss: -1.2151165008544922
Batch 23/64 loss: -1.2904510498046875
Batch 24/64 loss: -1.3960485458374023
Batch 25/64 loss: -1.314427375793457
Batch 26/64 loss: -1.3953361511230469
Batch 27/64 loss: -1.3574237823486328
Batch 28/64 loss: -0.9941940307617188
Batch 29/64 loss: -1.3523311614990234
Batch 30/64 loss: -1.271805763244629
Batch 31/64 loss: -1.553689956665039
Batch 32/64 loss: -1.3784112930297852
Batch 33/64 loss: -1.2818269729614258
Batch 34/64 loss: -1.058659553527832
Batch 35/64 loss: -1.397160530090332
Batch 36/64 loss: -1.394430160522461
Batch 37/64 loss: -1.464829444885254
Batch 38/64 loss: -0.6957473754882812
Batch 39/64 loss: -1.5335988998413086
Batch 40/64 loss: -1.4273223876953125
Batch 41/64 loss: -0.8058977127075195
Batch 42/64 loss: -1.4715995788574219
Batch 43/64 loss: -1.363943099975586
Batch 44/64 loss: -1.580291748046875
Batch 45/64 loss: -1.2016611099243164
Batch 46/64 loss: -1.2174139022827148
Batch 47/64 loss: -1.2410039901733398
Batch 48/64 loss: -1.016118049621582
Batch 49/64 loss: -1.3192777633666992
Batch 50/64 loss: -1.3252363204956055
Batch 51/64 loss: -1.4016227722167969
Batch 52/64 loss: -1.3794927597045898
Batch 53/64 loss: -1.1669549942016602
Batch 54/64 loss: -1.0352067947387695
Batch 55/64 loss: -1.3473577499389648
Batch 56/64 loss: -1.017289161682129
Batch 57/64 loss: -1.466562271118164
Batch 58/64 loss: -1.2134208679199219
Batch 59/64 loss: -1.4296197891235352
Batch 60/64 loss: -0.9888839721679688
Batch 61/64 loss: -1.2088899612426758
Batch 62/64 loss: -1.3656845092773438
Batch 63/64 loss: -1.4570741653442383
Batch 64/64 loss: -4.867319107055664
Epoch 195  Train loss: -1.3268841537774778  Val loss: -1.5110474812615777
Saving best model, epoch: 195
Epoch 196
-------------------------------
Batch 1/64 loss: -1.4278068542480469
Batch 2/64 loss: -1.3031673431396484
Batch 3/64 loss: -1.106389045715332
Batch 4/64 loss: -1.064859390258789
Batch 5/64 loss: -1.3592109680175781
Batch 6/64 loss: -0.7925100326538086
Batch 7/64 loss: -1.6109504699707031
Batch 8/64 loss: -0.949763298034668
Batch 9/64 loss: -1.4081525802612305
Batch 10/64 loss: -1.5014123916625977
Batch 11/64 loss: -1.4258880615234375
Batch 12/64 loss: -1.004359245300293
Batch 13/64 loss: -1.4190073013305664
Batch 14/64 loss: -1.285048484802246
Batch 15/64 loss: -1.1741924285888672
Batch 16/64 loss: -1.3599071502685547
Batch 17/64 loss: -1.328394889831543
Batch 18/64 loss: -1.3060846328735352
Batch 19/64 loss: -1.435338020324707
Batch 20/64 loss: -1.679062843322754
Batch 21/64 loss: -1.6684904098510742
Batch 22/64 loss: -1.3776264190673828
Batch 23/64 loss: -1.2445793151855469
Batch 24/64 loss: -1.4014263153076172
Batch 25/64 loss: -1.5818662643432617
Batch 26/64 loss: -1.5458087921142578
Batch 27/64 loss: -1.3019418716430664
Batch 28/64 loss: -1.1540355682373047
Batch 29/64 loss: -1.4458532333374023
Batch 30/64 loss: -1.5315866470336914
Batch 31/64 loss: -1.2921171188354492
Batch 32/64 loss: -1.481562614440918
Batch 33/64 loss: -1.0485591888427734
Batch 34/64 loss: -0.8138875961303711
Batch 35/64 loss: -1.430769920349121
Batch 36/64 loss: -1.6287240982055664
Batch 37/64 loss: -1.775313377380371
Batch 38/64 loss: -1.1888236999511719
Batch 39/64 loss: -1.59141206741333
Batch 40/64 loss: -1.5012903213500977
Batch 41/64 loss: -1.2068510055541992
Batch 42/64 loss: -1.2873725891113281
Batch 43/64 loss: -1.200082778930664
Batch 44/64 loss: -1.5164642333984375
Batch 45/64 loss: -1.4536113739013672
Batch 46/64 loss: -1.529444694519043
Batch 47/64 loss: -1.2134695053100586
Batch 48/64 loss: -1.1535978317260742
Batch 49/64 loss: -1.5123786926269531
Batch 50/64 loss: -1.3529434204101562
Batch 51/64 loss: -1.1785860061645508
Batch 52/64 loss: -1.4946269989013672
Batch 53/64 loss: -1.3933401107788086
Batch 54/64 loss: -1.3920354843139648
Batch 55/64 loss: -1.4267387390136719
Batch 56/64 loss: -1.1004009246826172
Batch 57/64 loss: -1.279296875
Batch 58/64 loss: -1.4475250244140625
Batch 59/64 loss: -1.0466976165771484
Batch 60/64 loss: -1.6094927787780762
Batch 61/64 loss: -1.2153825759887695
Batch 62/64 loss: -1.5562524795532227
Batch 63/64 loss: -1.2739582061767578
Batch 64/64 loss: -5.870267868041992
Epoch 196  Train loss: -1.399065586164886  Val loss: -1.556463667617221
Saving best model, epoch: 196
Epoch 197
-------------------------------
Batch 1/64 loss: -1.2500295639038086
Batch 2/64 loss: -1.418726921081543
Batch 3/64 loss: -1.3714122772216797
Batch 4/64 loss: -1.6217966079711914
Batch 5/64 loss: -1.3283500671386719
Batch 6/64 loss: -1.5806760787963867
Batch 7/64 loss: -1.3928375244140625
Batch 8/64 loss: -1.345677375793457
Batch 9/64 loss: -1.6146469116210938
Batch 10/64 loss: -1.7121152877807617
Batch 11/64 loss: -1.4711036682128906
Batch 12/64 loss: -1.0433158874511719
Batch 13/64 loss: -1.602309226989746
Batch 14/64 loss: -1.158432960510254
Batch 15/64 loss: -1.710261344909668
Batch 16/64 loss: -1.6023197174072266
Batch 17/64 loss: -1.3126897811889648
Batch 18/64 loss: -1.4359416961669922
Batch 19/64 loss: -0.9658069610595703
Batch 20/64 loss: -1.3925580978393555
Batch 21/64 loss: -1.3257884979248047
Batch 22/64 loss: -1.3453540802001953
Batch 23/64 loss: -1.8078670501708984
Batch 24/64 loss: -1.3623247146606445
Batch 25/64 loss: -1.606898307800293
Batch 26/64 loss: -1.4427528381347656
Batch 27/64 loss: -1.6053781509399414
Batch 28/64 loss: -1.6528825759887695
Batch 29/64 loss: -1.3652153015136719
Batch 30/64 loss: -1.6409292221069336
Batch 31/64 loss: -1.7260322570800781
Batch 32/64 loss: -1.5464143753051758
Batch 33/64 loss: -0.7812623977661133
Batch 34/64 loss: -1.2684831619262695
Batch 35/64 loss: -1.4682598114013672
Batch 36/64 loss: -1.1780815124511719
Batch 37/64 loss: -1.5381450653076172
Batch 38/64 loss: -1.5806303024291992
Batch 39/64 loss: -1.5416269302368164
Batch 40/64 loss: -1.378861427307129
Batch 41/64 loss: -1.516209602355957
Batch 42/64 loss: -1.7182388305664062
Batch 43/64 loss: -0.9794321060180664
Batch 44/64 loss: -1.3993196487426758
Batch 45/64 loss: -1.2503528594970703
Batch 46/64 loss: -1.3464727401733398
Batch 47/64 loss: -1.6325368881225586
Batch 48/64 loss: -0.9870576858520508
Batch 49/64 loss: -1.619563102722168
Batch 50/64 loss: -1.5068931579589844
Batch 51/64 loss: -1.387228012084961
Batch 52/64 loss: -1.4738903045654297
Batch 53/64 loss: -0.9159955978393555
Batch 54/64 loss: -1.1385164260864258
Batch 55/64 loss: -1.3500242233276367
Batch 56/64 loss: -1.312962532043457
Batch 57/64 loss: -0.9180507659912109
Batch 58/64 loss: -0.7432518005371094
Batch 59/64 loss: -1.4326353073120117
Batch 60/64 loss: -1.6203460693359375
Batch 61/64 loss: -1.1831045150756836
Batch 62/64 loss: -1.2426261901855469
Batch 63/64 loss: -1.45050048828125
Batch 64/64 loss: -5.489242076873779
Epoch 197  Train loss: -1.4390013545167213  Val loss: -1.4968847032265156
Epoch 198
-------------------------------
Batch 1/64 loss: -1.5705041885375977
Batch 2/64 loss: -1.4686908721923828
Batch 3/64 loss: -1.405014991760254
Batch 4/64 loss: -1.067723274230957
Batch 5/64 loss: -1.4930925369262695
Batch 6/64 loss: -1.5305204391479492
Batch 7/64 loss: -1.5563831329345703
Batch 8/64 loss: -1.5547046661376953
Batch 9/64 loss: -1.250387191772461
Batch 10/64 loss: -1.6626558303833008
Batch 11/64 loss: -1.4543590545654297
Batch 12/64 loss: -1.3163337707519531
Batch 13/64 loss: -1.549337387084961
Batch 14/64 loss: -1.2214975357055664
Batch 15/64 loss: -1.4849700927734375
Batch 16/64 loss: -1.6579170227050781
Batch 17/64 loss: -1.3411016464233398
Batch 18/64 loss: -1.2823286056518555
Batch 19/64 loss: -0.9261550903320312
Batch 20/64 loss: -1.3644847869873047
Batch 21/64 loss: -1.71490478515625
Batch 22/64 loss: -1.2341070175170898
Batch 23/64 loss: -1.6626548767089844
Batch 24/64 loss: -1.4322166442871094
Batch 25/64 loss: -1.2915678024291992
Batch 26/64 loss: -1.4249324798583984
Batch 27/64 loss: -1.3613290786743164
Batch 28/64 loss: -1.1636686325073242
Batch 29/64 loss: -1.160231590270996
Batch 30/64 loss: -1.394007682800293
Batch 31/64 loss: -1.0529680252075195
Batch 32/64 loss: -1.5579195022583008
Batch 33/64 loss: -1.4365930557250977
Batch 34/64 loss: -0.9727659225463867
Batch 35/64 loss: -1.1548967361450195
Batch 36/64 loss: -1.0730714797973633
Batch 37/64 loss: -1.378676414489746
Batch 38/64 loss: -1.1207199096679688
Batch 39/64 loss: -0.7976007461547852
Batch 40/64 loss: -1.630340576171875
Batch 41/64 loss: -1.3827238082885742
Batch 42/64 loss: -0.8506860733032227
Batch 43/64 loss: -1.3336362838745117
Batch 44/64 loss: -1.1809329986572266
Batch 45/64 loss: -0.7682819366455078
Batch 46/64 loss: -1.6464204788208008
Batch 47/64 loss: -1.3129491806030273
Batch 48/64 loss: -1.076115608215332
Batch 49/64 loss: -1.1832571029663086
Batch 50/64 loss: -1.423233985900879
Batch 51/64 loss: -1.7144584655761719
Batch 52/64 loss: -1.129622459411621
Batch 53/64 loss: -1.5188350677490234
Batch 54/64 loss: -1.5462827682495117
Batch 55/64 loss: -1.6200590133666992
Batch 56/64 loss: -0.9974822998046875
Batch 57/64 loss: -1.3531723022460938
Batch 58/64 loss: -1.7317266464233398
Batch 59/64 loss: -1.4182538986206055
Batch 60/64 loss: -1.2842292785644531
Batch 61/64 loss: -1.2675161361694336
Batch 62/64 loss: -0.8140649795532227
Batch 63/64 loss: -1.5404043197631836
Batch 64/64 loss: -5.682287216186523
Epoch 198  Train loss: -1.3886964012594785  Val loss: -1.5131043896232683
Epoch 199
-------------------------------
Batch 1/64 loss: -1.3277530670166016
Batch 2/64 loss: -1.6717729568481445
Batch 3/64 loss: -1.0980005264282227
Batch 4/64 loss: -0.9792385101318359
Batch 5/64 loss: -0.8982744216918945
Batch 6/64 loss: -0.9547672271728516
Batch 7/64 loss: -1.1603574752807617
Batch 8/64 loss: -1.5630521774291992
Batch 9/64 loss: -1.202627182006836
Batch 10/64 loss: -1.0623836517333984
Batch 11/64 loss: -1.2251434326171875
Batch 12/64 loss: -1.4608898162841797
Batch 13/64 loss: -1.2937040328979492
Batch 14/64 loss: -1.4676618576049805
Batch 15/64 loss: -1.2978029251098633
Batch 16/64 loss: -1.3298778533935547
Batch 17/64 loss: -1.6259145736694336
Batch 18/64 loss: -1.619795799255371
Batch 19/64 loss: -1.1406917572021484
Batch 20/64 loss: -1.5348825454711914
Batch 21/64 loss: -1.3948078155517578
Batch 22/64 loss: -1.4914531707763672
Batch 23/64 loss: -1.3460359573364258
Batch 24/64 loss: -1.0583381652832031
Batch 25/64 loss: -1.6340885162353516
Batch 26/64 loss: -1.1101140975952148
Batch 27/64 loss: -1.4622259140014648
Batch 28/64 loss: -1.0815668106079102
Batch 29/64 loss: -1.437826156616211
Batch 30/64 loss: -1.1273889541625977
Batch 31/64 loss: -1.304966926574707
Batch 32/64 loss: -1.6974859237670898
Batch 33/64 loss: -1.4772567749023438
Batch 34/64 loss: -1.4426507949829102
Batch 35/64 loss: -1.5266542434692383
Batch 36/64 loss: -1.461583137512207
Batch 37/64 loss: -1.356485366821289
Batch 38/64 loss: -1.4438247680664062
Batch 39/64 loss: -1.2450675964355469
Batch 40/64 loss: -1.3489389419555664
Batch 41/64 loss: -1.5623712539672852
Batch 42/64 loss: -1.3318328857421875
Batch 43/64 loss: -1.4807682037353516
Batch 44/64 loss: -1.6891260147094727
Batch 45/64 loss: -1.338449478149414
Batch 46/64 loss: -1.087087631225586
Batch 47/64 loss: -1.6075849533081055
Batch 48/64 loss: -1.5760650634765625
Batch 49/64 loss: -1.6427011489868164
Batch 50/64 loss: -0.7555122375488281
Batch 51/64 loss: -1.492966651916504
Batch 52/64 loss: -1.5321416854858398
Batch 53/64 loss: -1.3292465209960938
Batch 54/64 loss: -1.6461000442504883
Batch 55/64 loss: -1.3447275161743164
Batch 56/64 loss: -1.5316543579101562
Batch 57/64 loss: -1.2298269271850586
Batch 58/64 loss: -1.4935836791992188
Batch 59/64 loss: -1.3653583526611328
Batch 60/64 loss: -1.514887809753418
Batch 61/64 loss: -1.101700782775879
Batch 62/64 loss: -1.2838268280029297
Batch 63/64 loss: -1.2081174850463867
Batch 64/64 loss: -5.231149673461914
Epoch 199  Train loss: -1.4028604170855354  Val loss: -1.525348873072883
Epoch 200
-------------------------------
Batch 1/64 loss: -1.6416330337524414
Batch 2/64 loss: -1.5982561111450195
Batch 3/64 loss: -1.5558881759643555
Batch 4/64 loss: -1.6195316314697266
Batch 5/64 loss: -1.4868364334106445
Batch 6/64 loss: -0.8272848129272461
Batch 7/64 loss: -1.2448320388793945
Batch 8/64 loss: -1.484562873840332
Batch 9/64 loss: -1.25146484375
Batch 10/64 loss: -1.4139204025268555
Batch 11/64 loss: -1.337606430053711
Batch 12/64 loss: -1.3451290130615234
Batch 13/64 loss: -1.4635944366455078
Batch 14/64 loss: -1.2799386978149414
Batch 15/64 loss: -1.2715320587158203
Batch 16/64 loss: -1.3910636901855469
Batch 17/64 loss: -1.053060531616211
Batch 18/64 loss: -1.7289409637451172
Batch 19/64 loss: -1.4890289306640625
Batch 20/64 loss: -1.3415021896362305
Batch 21/64 loss: -1.0677947998046875
Batch 22/64 loss: -1.6163311004638672
Batch 23/64 loss: -1.1661767959594727
Batch 24/64 loss: -1.5085105895996094
Batch 25/64 loss: -1.453791618347168
Batch 26/64 loss: -1.0831661224365234
Batch 27/64 loss: -1.4793195724487305
Batch 28/64 loss: -1.1098384857177734
Batch 29/64 loss: -1.5430259704589844
Batch 30/64 loss: -1.3895559310913086
Batch 31/64 loss: -1.419149398803711
Batch 32/64 loss: -1.6592350006103516
Batch 33/64 loss: -1.460740089416504
Batch 34/64 loss: -1.7118158340454102
Batch 35/64 loss: -1.6916704177856445
Batch 36/64 loss: -1.6475000381469727
Batch 37/64 loss: -1.0055818557739258
Batch 38/64 loss: -1.382558822631836
Batch 39/64 loss: -1.4197120666503906
Batch 40/64 loss: -1.5137348175048828
Batch 41/64 loss: -1.5383844375610352
Batch 42/64 loss: -1.3186273574829102
Batch 43/64 loss: -1.2939367294311523
Batch 44/64 loss: -1.3019733428955078
Batch 45/64 loss: -1.5476007461547852
Batch 46/64 loss: -1.0959033966064453
Batch 47/64 loss: -1.3144798278808594
Batch 48/64 loss: -0.6490879058837891
Batch 49/64 loss: -1.6247587203979492
Batch 50/64 loss: -1.4803361892700195
Batch 51/64 loss: -1.5511131286621094
Batch 52/64 loss: -1.3056907653808594
Batch 53/64 loss: -1.4722766876220703
Batch 54/64 loss: -1.516763687133789
Batch 55/64 loss: -1.4059247970581055
Batch 56/64 loss: -1.2993507385253906
Batch 57/64 loss: -1.6282291412353516
Batch 58/64 loss: -1.4251279830932617
Batch 59/64 loss: -1.2958955764770508
Batch 60/64 loss: -1.4597444534301758
Batch 61/64 loss: -1.190169334411621
Batch 62/64 loss: -1.4656076431274414
Batch 63/64 loss: -1.269073486328125
Batch 64/64 loss: -5.046763896942139
Epoch 200  Train loss: -1.4335677745295505  Val loss: -1.5572970544349696
Saving best model, epoch: 200
Epoch 201
-------------------------------
Batch 1/64 loss: -1.5468034744262695
Batch 2/64 loss: -1.4018421173095703
Batch 3/64 loss: -1.389277458190918
Batch 4/64 loss: -1.6992053985595703
Batch 5/64 loss: -1.125807762145996
Batch 6/64 loss: -1.3395557403564453
Batch 7/64 loss: -1.3518342971801758
Batch 8/64 loss: -1.5482168197631836
Batch 9/64 loss: -1.714869499206543
Batch 10/64 loss: -1.6048946380615234
Batch 11/64 loss: -1.7490234375
Batch 12/64 loss: -1.305999755859375
Batch 13/64 loss: -1.3871021270751953
Batch 14/64 loss: -1.1232271194458008
Batch 15/64 loss: -1.3030519485473633
Batch 16/64 loss: -1.5545129776000977
Batch 17/64 loss: -1.5986900329589844
Batch 18/64 loss: -1.111466407775879
Batch 19/64 loss: -1.1944313049316406
Batch 20/64 loss: -1.606266975402832
Batch 21/64 loss: -1.5339021682739258
Batch 22/64 loss: -1.3194084167480469
Batch 23/64 loss: -1.3292961120605469
Batch 24/64 loss: -1.5802507400512695
Batch 25/64 loss: -1.623952865600586
Batch 26/64 loss: -1.5203609466552734
Batch 27/64 loss: -1.1377067565917969
Batch 28/64 loss: -1.3829021453857422
Batch 29/64 loss: -1.0179805755615234
Batch 30/64 loss: -1.4763336181640625
Batch 31/64 loss: -1.668795108795166
Batch 32/64 loss: -1.6715087890625
Batch 33/64 loss: -1.5355615615844727
Batch 34/64 loss: -1.096390724182129
Batch 35/64 loss: -1.5480785369873047
Batch 36/64 loss: -1.5340394973754883
Batch 37/64 loss: -1.4061012268066406
Batch 38/64 loss: -1.7984933853149414
Batch 39/64 loss: -1.481123924255371
Batch 40/64 loss: -1.3281974792480469
Batch 41/64 loss: -1.4315929412841797
Batch 42/64 loss: -1.2672491073608398
Batch 43/64 loss: -1.3633184432983398
Batch 44/64 loss: -1.5726518630981445
Batch 45/64 loss: -1.7015800476074219
Batch 46/64 loss: -1.489821434020996
Batch 47/64 loss: -1.427842140197754
Batch 48/64 loss: -0.8432731628417969
Batch 49/64 loss: -0.9576854705810547
Batch 50/64 loss: -1.0599050521850586
Batch 51/64 loss: -1.2841863632202148
Batch 52/64 loss: -1.2411632537841797
Batch 53/64 loss: -1.1533746719360352
Batch 54/64 loss: -1.2838726043701172
Batch 55/64 loss: -1.0565261840820312
Batch 56/64 loss: -0.8924503326416016
Batch 57/64 loss: -1.4534378051757812
Batch 58/64 loss: -1.3368263244628906
Batch 59/64 loss: -1.5179920196533203
Batch 60/64 loss: -1.0351085662841797
Batch 61/64 loss: -1.318476676940918
Batch 62/64 loss: -1.028778076171875
Batch 63/64 loss: -1.609766960144043
Batch 64/64 loss: -5.139402866363525
Epoch 201  Train loss: -1.4247513023077274  Val loss: -1.6043732240027988
Saving best model, epoch: 201
Epoch 202
-------------------------------
Batch 1/64 loss: -1.6218910217285156
Batch 2/64 loss: -1.6599063873291016
Batch 3/64 loss: -1.1606521606445312
Batch 4/64 loss: -1.1110305786132812
Batch 5/64 loss: -1.377115249633789
Batch 6/64 loss: -1.4985885620117188
Batch 7/64 loss: -1.614954948425293
Batch 8/64 loss: -1.4525041580200195
Batch 9/64 loss: -1.5345697402954102
Batch 10/64 loss: -1.338923454284668
Batch 11/64 loss: -1.6516170501708984
Batch 12/64 loss: -1.3718233108520508
Batch 13/64 loss: -1.4821624755859375
Batch 14/64 loss: -1.4580259323120117
Batch 15/64 loss: -1.578293800354004
Batch 16/64 loss: -1.5517597198486328
Batch 17/64 loss: -1.6287908554077148
Batch 18/64 loss: -1.4312448501586914
Batch 19/64 loss: -1.0940618515014648
Batch 20/64 loss: -0.6038475036621094
Batch 21/64 loss: -1.4047527313232422
Batch 22/64 loss: -1.5122408866882324
Batch 23/64 loss: -1.3917322158813477
Batch 24/64 loss: -0.8637971878051758
Batch 25/64 loss: -1.4101343154907227
Batch 26/64 loss: -1.7571601867675781
Batch 27/64 loss: -1.4714689254760742
Batch 28/64 loss: -1.4046945571899414
Batch 29/64 loss: -1.3464603424072266
Batch 30/64 loss: -1.5963134765625
Batch 31/64 loss: -1.466714859008789
Batch 32/64 loss: -1.0826396942138672
Batch 33/64 loss: -1.5528926849365234
Batch 34/64 loss: -1.6089706420898438
Batch 35/64 loss: -1.4762210845947266
Batch 36/64 loss: -1.314432144165039
Batch 37/64 loss: -1.5229568481445312
Batch 38/64 loss: -1.1531047821044922
Batch 39/64 loss: -1.502486228942871
Batch 40/64 loss: -1.70281982421875
Batch 41/64 loss: -1.53515625
Batch 42/64 loss: -1.074711799621582
Batch 43/64 loss: -1.650472640991211
Batch 44/64 loss: -1.4129762649536133
Batch 45/64 loss: -1.407639503479004
Batch 46/64 loss: -1.5543451309204102
Batch 47/64 loss: -1.2409143447875977
Batch 48/64 loss: -1.4067230224609375
Batch 49/64 loss: -1.3036527633666992
Batch 50/64 loss: -1.4773645401000977
Batch 51/64 loss: -1.6070117950439453
Batch 52/64 loss: -1.1966629028320312
Batch 53/64 loss: -1.5280780792236328
Batch 54/64 loss: -1.4384336471557617
Batch 55/64 loss: -0.9817953109741211
Batch 56/64 loss: -1.3491277694702148
Batch 57/64 loss: -1.2480049133300781
Batch 58/64 loss: -1.4486198425292969
Batch 59/64 loss: -1.324502944946289
Batch 60/64 loss: -1.5901546478271484
Batch 61/64 loss: -1.343937873840332
Batch 62/64 loss: -1.2412700653076172
Batch 63/64 loss: -0.8841056823730469
Batch 64/64 loss: -5.672746181488037
Epoch 202  Train loss: -1.4472780956941493  Val loss: -1.4261423353477032
Epoch 203
-------------------------------
Batch 1/64 loss: -1.6345272064208984
Batch 2/64 loss: -1.1808605194091797
Batch 3/64 loss: -1.2849082946777344
Batch 4/64 loss: -1.5610074996948242
Batch 5/64 loss: -1.1387081146240234
Batch 6/64 loss: -0.6818370819091797
Batch 7/64 loss: -1.2408981323242188
Batch 8/64 loss: -1.2679872512817383
Batch 9/64 loss: -1.3510093688964844
Batch 10/64 loss: -1.175516128540039
Batch 11/64 loss: -0.9089269638061523
Batch 12/64 loss: -1.5886192321777344
Batch 13/64 loss: -1.4529304504394531
Batch 14/64 loss: -1.3136024475097656
Batch 15/64 loss: -1.4042539596557617
Batch 16/64 loss: -1.5312156677246094
Batch 17/64 loss: -1.276224136352539
Batch 18/64 loss: -1.4765024185180664
Batch 19/64 loss: -1.2313604354858398
Batch 20/64 loss: -1.2991409301757812
Batch 21/64 loss: -1.4177093505859375
Batch 22/64 loss: -1.2262096405029297
Batch 23/64 loss: -1.4453706741333008
Batch 24/64 loss: -1.2716779708862305
Batch 25/64 loss: -1.2667808532714844
Batch 26/64 loss: -0.9995670318603516
Batch 27/64 loss: -1.4797286987304688
Batch 28/64 loss: -1.4504165649414062
Batch 29/64 loss: -1.091841697692871
Batch 30/64 loss: -1.297698974609375
Batch 31/64 loss: -1.5446176528930664
Batch 32/64 loss: -1.063471794128418
Batch 33/64 loss: -1.176748275756836
Batch 34/64 loss: -0.9980430603027344
Batch 35/64 loss: -1.4201889038085938
Batch 36/64 loss: -1.1206598281860352
Batch 37/64 loss: -1.292501449584961
Batch 38/64 loss: -1.6780967712402344
Batch 39/64 loss: -1.2384834289550781
Batch 40/64 loss: -1.4423065185546875
Batch 41/64 loss: -1.3237543106079102
Batch 42/64 loss: -1.2011442184448242
Batch 43/64 loss: -1.481210708618164
Batch 44/64 loss: -1.6795330047607422
Batch 45/64 loss: -1.3409719467163086
Batch 46/64 loss: -1.01141357421875
Batch 47/64 loss: -0.953831672668457
Batch 48/64 loss: -1.5143499374389648
Batch 49/64 loss: -1.2326555252075195
Batch 50/64 loss: -1.510239601135254
Batch 51/64 loss: -1.415313720703125
Batch 52/64 loss: -1.3114347457885742
Batch 53/64 loss: -1.388218879699707
Batch 54/64 loss: -1.2983436584472656
Batch 55/64 loss: -1.7039527893066406
Batch 56/64 loss: -0.8347234725952148
Batch 57/64 loss: -1.4062623977661133
Batch 58/64 loss: -1.4291553497314453
Batch 59/64 loss: -1.0889167785644531
Batch 60/64 loss: -1.2486906051635742
Batch 61/64 loss: -1.1349201202392578
Batch 62/64 loss: -1.3591489791870117
Batch 63/64 loss: -1.1724328994750977
Batch 64/64 loss: -5.131005764007568
Epoch 203  Train loss: -1.3460553505841424  Val loss: -1.496022358792754
Epoch 204
-------------------------------
Batch 1/64 loss: -1.1534833908081055
Batch 2/64 loss: -1.3906383514404297
Batch 3/64 loss: -1.3726253509521484
Batch 4/64 loss: -1.4665765762329102
Batch 5/64 loss: -1.2817392349243164
Batch 6/64 loss: -1.4787187576293945
Batch 7/64 loss: -1.0080204010009766
Batch 8/64 loss: -0.9589090347290039
Batch 9/64 loss: -1.3977375030517578
Batch 10/64 loss: -1.0460138320922852
Batch 11/64 loss: -1.3600215911865234
Batch 12/64 loss: -1.3108892440795898
Batch 13/64 loss: -1.5621376037597656
Batch 14/64 loss: -1.5751667022705078
Batch 15/64 loss: -1.4870109558105469
Batch 16/64 loss: -1.5190343856811523
Batch 17/64 loss: -1.4811296463012695
Batch 18/64 loss: -1.1290655136108398
Batch 19/64 loss: -0.6234769821166992
Batch 20/64 loss: -1.4308223724365234
Batch 21/64 loss: -1.5022640228271484
Batch 22/64 loss: -0.9807510375976562
Batch 23/64 loss: -1.343252182006836
Batch 24/64 loss: -1.1890296936035156
Batch 25/64 loss: -1.5790786743164062
Batch 26/64 loss: -1.2397785186767578
Batch 27/64 loss: -1.2559833526611328
Batch 28/64 loss: -1.1751174926757812
Batch 29/64 loss: -1.7082080841064453
Batch 30/64 loss: -1.271188735961914
Batch 31/64 loss: -1.6007671356201172
Batch 32/64 loss: -1.461247444152832
Batch 33/64 loss: -1.4747629165649414
Batch 34/64 loss: -1.5464191436767578
Batch 35/64 loss: -1.4708271026611328
Batch 36/64 loss: -1.5070810317993164
Batch 37/64 loss: -1.4105987548828125
Batch 38/64 loss: -1.6129770278930664
Batch 39/64 loss: -1.555501937866211
Batch 40/64 loss: -0.7975921630859375
Batch 41/64 loss: -1.5061969757080078
Batch 42/64 loss: -1.6769723892211914
Batch 43/64 loss: -1.5474815368652344
Batch 44/64 loss: -1.3757362365722656
Batch 45/64 loss: -1.211151123046875
Batch 46/64 loss: -1.5015192031860352
Batch 47/64 loss: -1.3963403701782227
Batch 48/64 loss: -1.2509479522705078
Batch 49/64 loss: -0.9997358322143555
Batch 50/64 loss: -1.7327499389648438
Batch 51/64 loss: -1.6313047409057617
Batch 52/64 loss: -1.73939847946167
Batch 53/64 loss: -1.2344903945922852
Batch 54/64 loss: -1.5421600341796875
Batch 55/64 loss: -1.1990413665771484
Batch 56/64 loss: -1.4651212692260742
Batch 57/64 loss: -1.6375322341918945
Batch 58/64 loss: -1.7465848922729492
Batch 59/64 loss: -1.345418930053711
Batch 60/64 loss: -1.428985595703125
Batch 61/64 loss: -1.0509147644042969
Batch 62/64 loss: -1.5277538299560547
Batch 63/64 loss: -1.7452526092529297
Batch 64/64 loss: -4.6359782218933105
Epoch 204  Train loss: -1.4225163646772796  Val loss: -1.5714576957152062
Epoch 205
-------------------------------
Batch 1/64 loss: -0.7322244644165039
Batch 2/64 loss: -1.4690380096435547
Batch 3/64 loss: -1.4705209732055664
Batch 4/64 loss: -1.2925291061401367
Batch 5/64 loss: -1.4110870361328125
Batch 6/64 loss: -1.4754018783569336
Batch 7/64 loss: -1.3455495834350586
Batch 8/64 loss: -1.3586311340332031
Batch 9/64 loss: -1.3509960174560547
Batch 10/64 loss: -0.9464044570922852
Batch 11/64 loss: -1.4573249816894531
Batch 12/64 loss: -1.1492681503295898
Batch 13/64 loss: -1.336838722229004
Batch 14/64 loss: -0.9422206878662109
Batch 15/64 loss: -1.2185382843017578
Batch 16/64 loss: -1.7476320266723633
Batch 17/64 loss: -1.2704639434814453
Batch 18/64 loss: -1.498544692993164
Batch 19/64 loss: -1.441025733947754
Batch 20/64 loss: -1.4750356674194336
Batch 21/64 loss: -1.0848121643066406
Batch 22/64 loss: -1.545344352722168
Batch 23/64 loss: -1.5640745162963867
Batch 24/64 loss: -1.4845046997070312
Batch 25/64 loss: -1.2068443298339844
Batch 26/64 loss: -1.2255735397338867
Batch 27/64 loss: -1.5082054138183594
Batch 28/64 loss: -1.5401325225830078
Batch 29/64 loss: -1.703566551208496
Batch 30/64 loss: -1.365799903869629
Batch 31/64 loss: -1.2041854858398438
Batch 32/64 loss: -1.4490680694580078
Batch 33/64 loss: -1.5055532455444336
Batch 34/64 loss: -1.2416954040527344
Batch 35/64 loss: -1.5328855514526367
Batch 36/64 loss: -1.4450483322143555
Batch 37/64 loss: -1.1465845108032227
Batch 38/64 loss: -1.3368587493896484
Batch 39/64 loss: -1.607919692993164
Batch 40/64 loss: -1.2414989471435547
Batch 41/64 loss: -1.4281396865844727
Batch 42/64 loss: -1.2035484313964844
Batch 43/64 loss: -0.9140052795410156
Batch 44/64 loss: -1.2036066055297852
Batch 45/64 loss: -1.3816118240356445
Batch 46/64 loss: -1.4362421035766602
Batch 47/64 loss: -1.49365234375
Batch 48/64 loss: -1.2799091339111328
Batch 49/64 loss: -1.3026018142700195
Batch 50/64 loss: -1.6193513870239258
Batch 51/64 loss: -1.3563098907470703
Batch 52/64 loss: -1.3287076950073242
Batch 53/64 loss: -1.1158638000488281
Batch 54/64 loss: -1.6065006256103516
Batch 55/64 loss: -1.1420602798461914
Batch 56/64 loss: -1.628413200378418
Batch 57/64 loss: -1.279775619506836
Batch 58/64 loss: -1.3278913497924805
Batch 59/64 loss: -1.2863388061523438
Batch 60/64 loss: -0.8251371383666992
Batch 61/64 loss: -1.390101432800293
Batch 62/64 loss: -1.392777442932129
Batch 63/64 loss: -1.3404197692871094
Batch 64/64 loss: -5.402685165405273
Epoch 205  Train loss: -1.390814291262159  Val loss: -1.466780331536257
Epoch 206
-------------------------------
Batch 1/64 loss: -1.5331697463989258
Batch 2/64 loss: -1.2731504440307617
Batch 3/64 loss: -1.517435073852539
Batch 4/64 loss: -1.6134414672851562
Batch 5/64 loss: -1.3552074432373047
Batch 6/64 loss: -1.694075584411621
Batch 7/64 loss: -0.9308137893676758
Batch 8/64 loss: -1.5383186340332031
Batch 9/64 loss: -0.9501228332519531
Batch 10/64 loss: -1.4947338104248047
Batch 11/64 loss: -1.157491683959961
Batch 12/64 loss: -1.2389745712280273
Batch 13/64 loss: -1.4128656387329102
Batch 14/64 loss: -1.1669092178344727
Batch 15/64 loss: -1.3688173294067383
Batch 16/64 loss: -1.275895118713379
Batch 17/64 loss: -1.1465568542480469
Batch 18/64 loss: -1.204941749572754
Batch 19/64 loss: -1.6256866455078125
Batch 20/64 loss: -1.427321434020996
Batch 21/64 loss: -1.4011306762695312
Batch 22/64 loss: -1.2935523986816406
Batch 23/64 loss: -1.1369876861572266
Batch 24/64 loss: -1.228224754333496
Batch 25/64 loss: -1.0767803192138672
Batch 26/64 loss: -1.384552001953125
Batch 27/64 loss: -1.5305604934692383
Batch 28/64 loss: -1.5875911712646484
Batch 29/64 loss: -1.5770111083984375
Batch 30/64 loss: -1.257589340209961
Batch 31/64 loss: -1.0775823593139648
Batch 32/64 loss: -1.6862449645996094
Batch 33/64 loss: -1.3236207962036133
Batch 34/64 loss: -1.4715185165405273
Batch 35/64 loss: -1.1221113204956055
Batch 36/64 loss: -1.3822917938232422
Batch 37/64 loss: -1.5683584213256836
Batch 38/64 loss: -1.3664369583129883
Batch 39/64 loss: -1.180826187133789
Batch 40/64 loss: -0.8334922790527344
Batch 41/64 loss: -1.5972204208374023
Batch 42/64 loss: -1.4989700317382812
Batch 43/64 loss: -1.2863521575927734
Batch 44/64 loss: -1.560225486755371
Batch 45/64 loss: -1.014908790588379
Batch 46/64 loss: -1.6019067764282227
Batch 47/64 loss: -1.3599529266357422
Batch 48/64 loss: -1.5618610382080078
Batch 49/64 loss: -1.5363292694091797
Batch 50/64 loss: -1.2038679122924805
Batch 51/64 loss: -1.615264892578125
Batch 52/64 loss: -1.530482292175293
Batch 53/64 loss: -1.6579017639160156
Batch 54/64 loss: -1.413299560546875
Batch 55/64 loss: -1.3840007781982422
Batch 56/64 loss: -1.1685619354248047
Batch 57/64 loss: -1.2508249282836914
Batch 58/64 loss: -1.571014404296875
Batch 59/64 loss: -1.2025556564331055
Batch 60/64 loss: -1.471120834350586
Batch 61/64 loss: -1.56231689453125
Batch 62/64 loss: -1.433119773864746
Batch 63/64 loss: -0.6828269958496094
Batch 64/64 loss: -5.258879661560059
Epoch 206  Train loss: -1.404257849151013  Val loss: -1.5566365219063776
Epoch 207
-------------------------------
Batch 1/64 loss: -1.2434005737304688
Batch 2/64 loss: -0.7067251205444336
Batch 3/64 loss: -1.3702068328857422
Batch 4/64 loss: -1.3824043273925781
Batch 5/64 loss: -1.240401268005371
Batch 6/64 loss: -1.3412961959838867
Batch 7/64 loss: -1.3266611099243164
Batch 8/64 loss: -1.3935489654541016
Batch 9/64 loss: -1.59063720703125
Batch 10/64 loss: -1.3297128677368164
Batch 11/64 loss: -1.3531742095947266
Batch 12/64 loss: -1.5837774276733398
Batch 13/64 loss: -1.6769170761108398
Batch 14/64 loss: -1.2971925735473633
Batch 15/64 loss: -1.1253528594970703
Batch 16/64 loss: -1.6361150741577148
Batch 17/64 loss: -1.6543893814086914
Batch 18/64 loss: -1.8633499145507812
Batch 19/64 loss: -1.4643096923828125
Batch 20/64 loss: -1.5846567153930664
Batch 21/64 loss: -1.2185859680175781
Batch 22/64 loss: -0.9344091415405273
Batch 23/64 loss: -1.3578052520751953
Batch 24/64 loss: -1.700383186340332
Batch 25/64 loss: -1.6058025360107422
Batch 26/64 loss: -1.4488487243652344
Batch 27/64 loss: -1.6364946365356445
Batch 28/64 loss: -1.5190629959106445
Batch 29/64 loss: -1.1911792755126953
Batch 30/64 loss: -1.3236474990844727
Batch 31/64 loss: -1.5839662551879883
Batch 32/64 loss: -1.081618309020996
Batch 33/64 loss: -1.4727821350097656
Batch 34/64 loss: -1.0612831115722656
Batch 35/64 loss: -1.4631109237670898
Batch 36/64 loss: -1.772486686706543
Batch 37/64 loss: -1.5330448150634766
Batch 38/64 loss: -1.361968994140625
Batch 39/64 loss: -1.2578926086425781
Batch 40/64 loss: -1.5018434524536133
Batch 41/64 loss: -1.7156600952148438
Batch 42/64 loss: -1.5431175231933594
Batch 43/64 loss: -1.6429710388183594
Batch 44/64 loss: -1.4498844146728516
Batch 45/64 loss: -1.2530736923217773
Batch 46/64 loss: -1.2425117492675781
Batch 47/64 loss: -1.576925277709961
Batch 48/64 loss: -1.4924468994140625
Batch 49/64 loss: -0.996063232421875
Batch 50/64 loss: -1.5600147247314453
Batch 51/64 loss: -1.489288330078125
Batch 52/64 loss: -1.5824594497680664
Batch 53/64 loss: -1.584855079650879
Batch 54/64 loss: -1.5491523742675781
Batch 55/64 loss: -1.4388961791992188
Batch 56/64 loss: -1.2727737426757812
Batch 57/64 loss: -1.5419120788574219
Batch 58/64 loss: -0.9138584136962891
Batch 59/64 loss: -0.7674188613891602
Batch 60/64 loss: -1.4572248458862305
Batch 61/64 loss: -1.417668342590332
Batch 62/64 loss: -1.5924348831176758
Batch 63/64 loss: -1.286616325378418
Batch 64/64 loss: -5.709033966064453
Epoch 207  Train loss: -1.4563050812365963  Val loss: -1.6629596592224751
Saving best model, epoch: 207
Epoch 208
-------------------------------
Batch 1/64 loss: -1.5990209579467773
Batch 2/64 loss: -1.1463823318481445
Batch 3/64 loss: -1.767561912536621
Batch 4/64 loss: -1.4981966018676758
Batch 5/64 loss: -1.1869182586669922
Batch 6/64 loss: -1.8045272827148438
Batch 7/64 loss: -1.159754753112793
Batch 8/64 loss: -1.5027809143066406
Batch 9/64 loss: -1.7164907455444336
Batch 10/64 loss: -1.3306608200073242
Batch 11/64 loss: -1.636002540588379
Batch 12/64 loss: -1.4343223571777344
Batch 13/64 loss: -1.6137752532958984
Batch 14/64 loss: -1.5232067108154297
Batch 15/64 loss: -1.6195240020751953
Batch 16/64 loss: -1.4728727340698242
Batch 17/64 loss: -0.9753313064575195
Batch 18/64 loss: -1.424081802368164
Batch 19/64 loss: -1.0858631134033203
Batch 20/64 loss: -1.1844329833984375
Batch 21/64 loss: -1.2897911071777344
Batch 22/64 loss: -1.7345094680786133
Batch 23/64 loss: -1.622117042541504
Batch 24/64 loss: -1.5463895797729492
Batch 25/64 loss: -1.230586051940918
Batch 26/64 loss: -1.6401920318603516
Batch 27/64 loss: -1.5324468612670898
Batch 28/64 loss: -1.3816747665405273
Batch 29/64 loss: -1.185011863708496
Batch 30/64 loss: -1.0957927703857422
Batch 31/64 loss: -1.5355358123779297
Batch 32/64 loss: -1.4901437759399414
Batch 33/64 loss: -1.426833152770996
Batch 34/64 loss: -1.4682559967041016
Batch 35/64 loss: -1.191192626953125
Batch 36/64 loss: -1.3633317947387695
Batch 37/64 loss: -1.506856918334961
Batch 38/64 loss: -1.5447921752929688
Batch 39/64 loss: -1.4665679931640625
Batch 40/64 loss: -1.6641855239868164
Batch 41/64 loss: -1.7331171035766602
Batch 42/64 loss: -1.6783294677734375
Batch 43/64 loss: -1.7148799896240234
Batch 44/64 loss: -1.1922550201416016
Batch 45/64 loss: -1.4574460983276367
Batch 46/64 loss: -1.6007499694824219
Batch 47/64 loss: -1.2468032836914062
Batch 48/64 loss: -1.6274023056030273
Batch 49/64 loss: -1.054168701171875
Batch 50/64 loss: -1.5754814147949219
Batch 51/64 loss: -1.5152301788330078
Batch 52/64 loss: -1.3714570999145508
Batch 53/64 loss: -1.1206302642822266
Batch 54/64 loss: -1.686518669128418
Batch 55/64 loss: -1.279860496520996
Batch 56/64 loss: -1.616506576538086
Batch 57/64 loss: -1.6415958404541016
Batch 58/64 loss: -0.8174505233764648
Batch 59/64 loss: -1.2373170852661133
Batch 60/64 loss: -1.5877351760864258
Batch 61/64 loss: -1.7542777061462402
Batch 62/64 loss: -1.4807891845703125
Batch 63/64 loss: -1.1352357864379883
Batch 64/64 loss: -5.8343048095703125
Epoch 208  Train loss: -1.4917471567789713  Val loss: -1.64501363223361
Epoch 209
-------------------------------
Batch 1/64 loss: -1.0726404190063477
Batch 2/64 loss: -1.4225568771362305
Batch 3/64 loss: -1.1600885391235352
Batch 4/64 loss: -1.2939453125
Batch 5/64 loss: -1.545578956604004
Batch 6/64 loss: -1.6501617431640625
Batch 7/64 loss: -1.1656999588012695
Batch 8/64 loss: -1.79160737991333
Batch 9/64 loss: -1.5627861022949219
Batch 10/64 loss: -1.5650997161865234
Batch 11/64 loss: -1.3493728637695312
Batch 12/64 loss: -1.3796806335449219
Batch 13/64 loss: -1.525467872619629
Batch 14/64 loss: -1.6400279998779297
Batch 15/64 loss: -1.5346012115478516
Batch 16/64 loss: -1.1145191192626953
Batch 17/64 loss: -1.2198476791381836
Batch 18/64 loss: -1.5557613372802734
Batch 19/64 loss: -1.4035301208496094
Batch 20/64 loss: -1.4422111511230469
Batch 21/64 loss: -1.559239387512207
Batch 22/64 loss: -1.4297847747802734
Batch 23/64 loss: -1.5345144271850586
Batch 24/64 loss: -1.2106056213378906
Batch 25/64 loss: -1.054244041442871
Batch 26/64 loss: -1.3006267547607422
Batch 27/64 loss: -1.1123638153076172
Batch 28/64 loss: -1.2291879653930664
Batch 29/64 loss: -1.69647216796875
Batch 30/64 loss: -1.5050601959228516
Batch 31/64 loss: -1.345254898071289
Batch 32/64 loss: -1.3400917053222656
Batch 33/64 loss: -1.3667278289794922
Batch 34/64 loss: -1.524068832397461
Batch 35/64 loss: -1.15966796875
Batch 36/64 loss: -1.2042455673217773
Batch 37/64 loss: -1.6667203903198242
Batch 38/64 loss: -1.6593589782714844
Batch 39/64 loss: -1.5210742950439453
Batch 40/64 loss: -1.6272554397583008
Batch 41/64 loss: -1.409388542175293
Batch 42/64 loss: -1.473465919494629
Batch 43/64 loss: -1.3745994567871094
Batch 44/64 loss: -1.6412153244018555
Batch 45/64 loss: -1.5331945419311523
Batch 46/64 loss: -1.4564552307128906
Batch 47/64 loss: -1.3852195739746094
Batch 48/64 loss: -0.579345703125
Batch 49/64 loss: -1.3044757843017578
Batch 50/64 loss: -1.4406042098999023
Batch 51/64 loss: -1.521677017211914
Batch 52/64 loss: -1.6271963119506836
Batch 53/64 loss: -1.7866616249084473
Batch 54/64 loss: -1.499643325805664
Batch 55/64 loss: -1.5017290115356445
Batch 56/64 loss: -1.5443305969238281
Batch 57/64 loss: -1.3011837005615234
Batch 58/64 loss: -1.530454158782959
Batch 59/64 loss: -1.1426658630371094
Batch 60/64 loss: -1.362539291381836
Batch 61/64 loss: -1.582296371459961
Batch 62/64 loss: -1.7071070671081543
Batch 63/64 loss: -1.425257682800293
Batch 64/64 loss: -5.534141540527344
Epoch 209  Train loss: -1.4701656865138633  Val loss: -1.6608425022400533
Epoch 210
-------------------------------
Batch 1/64 loss: -1.3199090957641602
Batch 2/64 loss: -1.6581144332885742
Batch 3/64 loss: -1.4522294998168945
Batch 4/64 loss: -1.633173942565918
Batch 5/64 loss: -1.6184959411621094
Batch 6/64 loss: -1.6812763214111328
Batch 7/64 loss: -1.1211223602294922
Batch 8/64 loss: -1.6411991119384766
Batch 9/64 loss: -1.2622737884521484
Batch 10/64 loss: -1.634016990661621
Batch 11/64 loss: -1.7044916152954102
Batch 12/64 loss: -1.473301887512207
Batch 13/64 loss: -1.3333673477172852
Batch 14/64 loss: -1.435603141784668
Batch 15/64 loss: -1.3176765441894531
Batch 16/64 loss: -1.4152612686157227
Batch 17/64 loss: -1.5436725616455078
Batch 18/64 loss: -1.6508378982543945
Batch 19/64 loss: -1.7532892227172852
Batch 20/64 loss: -1.217940330505371
Batch 21/64 loss: -1.1016721725463867
Batch 22/64 loss: -1.441514015197754
Batch 23/64 loss: -1.4428033828735352
Batch 24/64 loss: -1.1851024627685547
Batch 25/64 loss: -1.4401931762695312
Batch 26/64 loss: -1.3294057846069336
Batch 27/64 loss: -1.3551454544067383
Batch 28/64 loss: -1.7136411666870117
Batch 29/64 loss: -1.5767030715942383
Batch 30/64 loss: -1.5732951164245605
Batch 31/64 loss: -1.5108871459960938
Batch 32/64 loss: -1.3918657302856445
Batch 33/64 loss: -1.3910636901855469
Batch 34/64 loss: -1.31683349609375
Batch 35/64 loss: -1.410491943359375
Batch 36/64 loss: -1.593855857849121
Batch 37/64 loss: -1.8279619216918945
Batch 38/64 loss: -1.0092554092407227
Batch 39/64 loss: -1.5572004318237305
Batch 40/64 loss: -1.591928482055664
Batch 41/64 loss: -1.5484046936035156
Batch 42/64 loss: -1.1877002716064453
Batch 43/64 loss: -1.7008056640625
Batch 44/64 loss: -1.2943029403686523
Batch 45/64 loss: -1.6299219131469727
Batch 46/64 loss: -1.536844253540039
Batch 47/64 loss: -1.7926397323608398
Batch 48/64 loss: -1.378087043762207
Batch 49/64 loss: -1.4838228225708008
Batch 50/64 loss: -1.3520221710205078
Batch 51/64 loss: -1.541762351989746
Batch 52/64 loss: -1.6400871276855469
Batch 53/64 loss: -1.2818050384521484
Batch 54/64 loss: -1.5075664520263672
Batch 55/64 loss: -1.2363033294677734
Batch 56/64 loss: -1.7140240669250488
Batch 57/64 loss: -1.8320627212524414
Batch 58/64 loss: -1.3222169876098633
Batch 59/64 loss: -1.498042106628418
Batch 60/64 loss: -0.45307445526123047
Batch 61/64 loss: -1.822129249572754
Batch 62/64 loss: -1.2325067520141602
Batch 63/64 loss: -1.4854536056518555
Batch 64/64 loss: -5.978433132171631
Epoch 210  Train loss: -1.5150350402383244  Val loss: -1.7155931479332782
Saving best model, epoch: 210
Epoch 211
-------------------------------
Batch 1/64 loss: -1.504098892211914
Batch 2/64 loss: -1.4018363952636719
Batch 3/64 loss: -1.590418815612793
Batch 4/64 loss: -1.414968490600586
Batch 5/64 loss: -1.6965055465698242
Batch 6/64 loss: -1.3247976303100586
Batch 7/64 loss: -1.164433479309082
Batch 8/64 loss: -1.7183961868286133
Batch 9/64 loss: -1.319880485534668
Batch 10/64 loss: -1.051248550415039
Batch 11/64 loss: -1.3865652084350586
Batch 12/64 loss: -1.2499465942382812
Batch 13/64 loss: -1.499654769897461
Batch 14/64 loss: -1.4800100326538086
Batch 15/64 loss: -1.4181528091430664
Batch 16/64 loss: -1.3819513320922852
Batch 17/64 loss: -1.4642343521118164
Batch 18/64 loss: -1.574483871459961
Batch 19/64 loss: -1.5994462966918945
Batch 20/64 loss: -1.1078662872314453
Batch 21/64 loss: -1.5879268646240234
Batch 22/64 loss: -1.430924415588379
Batch 23/64 loss: -1.1074752807617188
Batch 24/64 loss: -1.2199907302856445
Batch 25/64 loss: -1.4134016036987305
Batch 26/64 loss: -1.3291702270507812
Batch 27/64 loss: -1.5561819076538086
Batch 28/64 loss: -1.426309585571289
Batch 29/64 loss: -0.7910518646240234
Batch 30/64 loss: -1.4617462158203125
Batch 31/64 loss: -1.5971403121948242
Batch 32/64 loss: -1.274129867553711
Batch 33/64 loss: -0.9678964614868164
Batch 34/64 loss: -1.1664857864379883
Batch 35/64 loss: -1.2254447937011719
Batch 36/64 loss: -1.2878408432006836
Batch 37/64 loss: -1.3244438171386719
Batch 38/64 loss: -1.2639446258544922
Batch 39/64 loss: -1.475341796875
Batch 40/64 loss: -1.3219566345214844
Batch 41/64 loss: -1.5532894134521484
Batch 42/64 loss: -1.7101612091064453
Batch 43/64 loss: -1.2077836990356445
Batch 44/64 loss: -1.2053585052490234
Batch 45/64 loss: -1.690877914428711
Batch 46/64 loss: -1.4448976516723633
Batch 47/64 loss: -1.4932594299316406
Batch 48/64 loss: -1.552628517150879
Batch 49/64 loss: -1.615311622619629
Batch 50/64 loss: -1.4647703170776367
Batch 51/64 loss: -1.6253156661987305
Batch 52/64 loss: -1.1274442672729492
Batch 53/64 loss: -1.2388191223144531
Batch 54/64 loss: -1.5380611419677734
Batch 55/64 loss: -1.105910301208496
Batch 56/64 loss: -1.4119997024536133
Batch 57/64 loss: -1.2603216171264648
Batch 58/64 loss: -1.213761329650879
Batch 59/64 loss: -1.4412870407104492
Batch 60/64 loss: -1.4585819244384766
Batch 61/64 loss: -1.3873138427734375
Batch 62/64 loss: -1.619776725769043
Batch 63/64 loss: -0.7580623626708984
Batch 64/64 loss: -5.11965274810791
Epoch 211  Train loss: -1.4202734517116173  Val loss: -1.3868497999263383
Epoch 212
-------------------------------
Batch 1/64 loss: -1.2206830978393555
Batch 2/64 loss: -1.5323143005371094
Batch 3/64 loss: -1.666600227355957
Batch 4/64 loss: -1.0831804275512695
Batch 5/64 loss: -1.2811155319213867
Batch 6/64 loss: -1.478154182434082
Batch 7/64 loss: -1.4343757629394531
Batch 8/64 loss: -1.3591785430908203
Batch 9/64 loss: -1.1304082870483398
Batch 10/64 loss: -1.553030014038086
Batch 11/64 loss: -0.9932317733764648
Batch 12/64 loss: -1.2066164016723633
Batch 13/64 loss: -1.0064010620117188
Batch 14/64 loss: -1.5726089477539062
Batch 15/64 loss: -1.4870014190673828
Batch 16/64 loss: -1.7659530639648438
Batch 17/64 loss: -1.5889768600463867
Batch 18/64 loss: -1.5453109741210938
Batch 19/64 loss: -1.6271467208862305
Batch 20/64 loss: -1.370417594909668
Batch 21/64 loss: -1.0961980819702148
Batch 22/64 loss: -1.4785356521606445
Batch 23/64 loss: -1.2756967544555664
Batch 24/64 loss: -1.188929557800293
Batch 25/64 loss: -0.8443622589111328
Batch 26/64 loss: -1.3901309967041016
Batch 27/64 loss: -1.8155913352966309
Batch 28/64 loss: -1.6002769470214844
Batch 29/64 loss: -1.3924837112426758
Batch 30/64 loss: -1.1349878311157227
Batch 31/64 loss: -1.6184329986572266
Batch 32/64 loss: -1.2052373886108398
Batch 33/64 loss: -1.6765003204345703
Batch 34/64 loss: -1.475851058959961
Batch 35/64 loss: -0.7152280807495117
Batch 36/64 loss: -1.5240707397460938
Batch 37/64 loss: -1.4473695755004883
Batch 38/64 loss: -1.6220006942749023
Batch 39/64 loss: -1.6660966873168945
Batch 40/64 loss: -1.6909980773925781
Batch 41/64 loss: -1.0664939880371094
Batch 42/64 loss: -1.436471939086914
Batch 43/64 loss: -1.419306755065918
Batch 44/64 loss: -1.7118549346923828
Batch 45/64 loss: -1.4682502746582031
Batch 46/64 loss: -1.3656244277954102
Batch 47/64 loss: -1.5520133972167969
Batch 48/64 loss: -1.5090065002441406
Batch 49/64 loss: -1.3869333267211914
Batch 50/64 loss: -1.5170116424560547
Batch 51/64 loss: -1.5724983215332031
Batch 52/64 loss: -1.5265274047851562
Batch 53/64 loss: -0.8622245788574219
Batch 54/64 loss: -1.6010427474975586
Batch 55/64 loss: -0.9111928939819336
Batch 56/64 loss: -1.5869359970092773
Batch 57/64 loss: -1.6113100051879883
Batch 58/64 loss: -1.2283201217651367
Batch 59/64 loss: -1.4098658561706543
Batch 60/64 loss: -1.5221471786499023
Batch 61/64 loss: -0.8944520950317383
Batch 62/64 loss: -1.6341590881347656
Batch 63/64 loss: -1.6124849319458008
Batch 64/64 loss: -5.305701732635498
Epoch 212  Train loss: -1.445444527794333  Val loss: -1.5853990640017586
Epoch 213
-------------------------------
Batch 1/64 loss: -1.6996612548828125
Batch 2/64 loss: -1.4350080490112305
Batch 3/64 loss: -1.6344680786132812
Batch 4/64 loss: -1.4980106353759766
Batch 5/64 loss: -1.413060188293457
Batch 6/64 loss: -1.5956602096557617
Batch 7/64 loss: -1.0792169570922852
Batch 8/64 loss: -1.8332290649414062
Batch 9/64 loss: -1.4844980239868164
Batch 10/64 loss: -1.6245746612548828
Batch 11/64 loss: -1.6922359466552734
Batch 12/64 loss: -1.7238492965698242
Batch 13/64 loss: -1.3731374740600586
Batch 14/64 loss: -1.461806297302246
Batch 15/64 loss: -1.5396356582641602
Batch 16/64 loss: -1.4628105163574219
Batch 17/64 loss: -1.1547975540161133
Batch 18/64 loss: -1.5832490921020508
Batch 19/64 loss: -1.2781429290771484
Batch 20/64 loss: -1.4034013748168945
Batch 21/64 loss: -1.5982179641723633
Batch 22/64 loss: -1.107661247253418
Batch 23/64 loss: -1.1916217803955078
Batch 24/64 loss: -1.435145378112793
Batch 25/64 loss: -1.3649187088012695
Batch 26/64 loss: -1.7321653366088867
Batch 27/64 loss: -1.5556812286376953
Batch 28/64 loss: -1.276503562927246
Batch 29/64 loss: -1.6354522705078125
Batch 30/64 loss: -1.111104965209961
Batch 31/64 loss: -1.4387788772583008
Batch 32/64 loss: -1.496577262878418
Batch 33/64 loss: -1.3371639251708984
Batch 34/64 loss: -1.5988082885742188
Batch 35/64 loss: -1.5943679809570312
Batch 36/64 loss: -1.394002914428711
Batch 37/64 loss: -1.2479324340820312
Batch 38/64 loss: -1.492030143737793
Batch 39/64 loss: -1.3442659378051758
Batch 40/64 loss: -1.544968605041504
Batch 41/64 loss: -1.3282289505004883
Batch 42/64 loss: -1.3574514389038086
Batch 43/64 loss: -1.7335290908813477
Batch 44/64 loss: -1.319025993347168
Batch 45/64 loss: -1.5784940719604492
Batch 46/64 loss: -1.342010498046875
Batch 47/64 loss: -1.5351524353027344
Batch 48/64 loss: -1.1903648376464844
Batch 49/64 loss: -1.3937664031982422
Batch 50/64 loss: -0.7585887908935547
Batch 51/64 loss: -1.1929311752319336
Batch 52/64 loss: -1.3432245254516602
Batch 53/64 loss: -1.403778076171875
Batch 54/64 loss: -1.3941354751586914
Batch 55/64 loss: -1.4983129501342773
Batch 56/64 loss: -1.085322380065918
Batch 57/64 loss: -1.3365259170532227
Batch 58/64 loss: -1.4300775527954102
Batch 59/64 loss: -1.1449861526489258
Batch 60/64 loss: -1.4238662719726562
Batch 61/64 loss: -1.6421518325805664
Batch 62/64 loss: -1.546431541442871
Batch 63/64 loss: -0.8089199066162109
Batch 64/64 loss: -5.595470428466797
Epoch 213  Train loss: -1.4659090378705193  Val loss: -1.5086134553365282
Epoch 214
-------------------------------
Batch 1/64 loss: -0.9487676620483398
Batch 2/64 loss: -1.221170425415039
Batch 3/64 loss: -1.4068412780761719
Batch 4/64 loss: -0.9926719665527344
Batch 5/64 loss: -1.4780073165893555
Batch 6/64 loss: -1.4498062133789062
Batch 7/64 loss: -1.7146196365356445
Batch 8/64 loss: -1.1271286010742188
Batch 9/64 loss: -1.4558391571044922
Batch 10/64 loss: -1.5132474899291992
Batch 11/64 loss: -1.637624740600586
Batch 12/64 loss: -1.3868789672851562
Batch 13/64 loss: -1.6368770599365234
Batch 14/64 loss: -1.274428367614746
Batch 15/64 loss: -1.3698434829711914
Batch 16/64 loss: -1.4312009811401367
Batch 17/64 loss: -1.5229310989379883
Batch 18/64 loss: -1.412637710571289
Batch 19/64 loss: -0.9098272323608398
Batch 20/64 loss: -1.3966522216796875
Batch 21/64 loss: -1.2711400985717773
Batch 22/64 loss: -1.291482925415039
Batch 23/64 loss: -1.8032584190368652
Batch 24/64 loss: -1.4413671493530273
Batch 25/64 loss: -1.6575431823730469
Batch 26/64 loss: -1.3840179443359375
Batch 27/64 loss: -1.302459716796875
Batch 28/64 loss: -1.5423974990844727
Batch 29/64 loss: -1.5034408569335938
Batch 30/64 loss: -1.421173095703125
Batch 31/64 loss: -1.1794376373291016
Batch 32/64 loss: -1.1389541625976562
Batch 33/64 loss: -1.3870210647583008
Batch 34/64 loss: -1.2615461349487305
Batch 35/64 loss: -1.232813835144043
Batch 36/64 loss: -1.5434646606445312
Batch 37/64 loss: -1.4926567077636719
Batch 38/64 loss: -1.446080207824707
Batch 39/64 loss: -1.3717374801635742
Batch 40/64 loss: -1.3931760787963867
Batch 41/64 loss: -1.685450553894043
Batch 42/64 loss: -1.5839996337890625
Batch 43/64 loss: -1.0928630828857422
Batch 44/64 loss: -1.4323358535766602
Batch 45/64 loss: -1.2043895721435547
Batch 46/64 loss: -1.3489351272583008
Batch 47/64 loss: -1.5002555847167969
Batch 48/64 loss: -1.2836017608642578
Batch 49/64 loss: -1.514643669128418
Batch 50/64 loss: -1.4649991989135742
Batch 51/64 loss: -1.1983346939086914
Batch 52/64 loss: -1.4732780456542969
Batch 53/64 loss: -1.2142877578735352
Batch 54/64 loss: -1.6467933654785156
Batch 55/64 loss: -1.0444984436035156
Batch 56/64 loss: -1.4442424774169922
Batch 57/64 loss: -1.2557449340820312
Batch 58/64 loss: -1.5527801513671875
Batch 59/64 loss: -1.5732927322387695
Batch 60/64 loss: -1.6784486770629883
Batch 61/64 loss: -1.6010704040527344
Batch 62/64 loss: -1.1016063690185547
Batch 63/64 loss: -1.327042579650879
Batch 64/64 loss: -5.330291748046875
Epoch 214  Train loss: -1.4364358266194661  Val loss: -1.5339076904087132
Epoch 215
-------------------------------
Batch 1/64 loss: -1.5573301315307617
Batch 2/64 loss: -1.5620508193969727
Batch 3/64 loss: -1.3318510055541992
Batch 4/64 loss: -1.670577049255371
Batch 5/64 loss: -1.3034648895263672
Batch 6/64 loss: -1.6944303512573242
Batch 7/64 loss: -1.3057136535644531
Batch 8/64 loss: -1.3968830108642578
Batch 9/64 loss: -1.6374149322509766
Batch 10/64 loss: -1.436065673828125
Batch 11/64 loss: -1.0995979309082031
Batch 12/64 loss: -1.4057693481445312
Batch 13/64 loss: -1.5070953369140625
Batch 14/64 loss: -1.1634674072265625
Batch 15/64 loss: -0.8375825881958008
Batch 16/64 loss: -1.8303194046020508
Batch 17/64 loss: -1.523172378540039
Batch 18/64 loss: -1.3970661163330078
Batch 19/64 loss: -1.3580036163330078
Batch 20/64 loss: -1.5621929168701172
Batch 21/64 loss: -0.9269580841064453
Batch 22/64 loss: -1.6327204704284668
Batch 23/64 loss: -1.6030073165893555
Batch 24/64 loss: -1.3291606903076172
Batch 25/64 loss: -1.5685710906982422
Batch 26/64 loss: -1.5467729568481445
Batch 27/64 loss: -1.7027254104614258
Batch 28/64 loss: -1.642568588256836
Batch 29/64 loss: -1.7075185775756836
Batch 30/64 loss: -1.3586502075195312
Batch 31/64 loss: -1.539240837097168
Batch 32/64 loss: -1.4928264617919922
Batch 33/64 loss: -1.3480653762817383
Batch 34/64 loss: -1.3774948120117188
Batch 35/64 loss: -1.407710075378418
Batch 36/64 loss: -1.5471067428588867
Batch 37/64 loss: -1.5099477767944336
Batch 38/64 loss: -1.2427091598510742
Batch 39/64 loss: -1.588749885559082
Batch 40/64 loss: -1.7554426193237305
Batch 41/64 loss: -1.726578712463379
Batch 42/64 loss: -1.0423030853271484
Batch 43/64 loss: -1.6764850616455078
Batch 44/64 loss: -1.6935091018676758
Batch 45/64 loss: -1.2534103393554688
Batch 46/64 loss: -1.372309684753418
Batch 47/64 loss: -1.411306381225586
Batch 48/64 loss: -1.6135540008544922
Batch 49/64 loss: -1.2196321487426758
Batch 50/64 loss: -1.528874397277832
Batch 51/64 loss: -1.2372407913208008
Batch 52/64 loss: -1.353372573852539
Batch 53/64 loss: -1.579355239868164
Batch 54/64 loss: -1.5976829528808594
Batch 55/64 loss: -0.8441133499145508
Batch 56/64 loss: -1.3191032409667969
Batch 57/64 loss: -1.4380760192871094
Batch 58/64 loss: -1.0176763534545898
Batch 59/64 loss: -1.5108299255371094
Batch 60/64 loss: -1.5265789031982422
Batch 61/64 loss: -1.2420845031738281
Batch 62/64 loss: -1.4027299880981445
Batch 63/64 loss: -1.2379608154296875
Batch 64/64 loss: -5.555369853973389
Epoch 215  Train loss: -1.4810869123421464  Val loss: -1.5205666322478724
Epoch 216
-------------------------------
Batch 1/64 loss: -1.3796415328979492
Batch 2/64 loss: -1.5240707397460938
Batch 3/64 loss: -1.403895378112793
Batch 4/64 loss: -1.0078620910644531
Batch 5/64 loss: -1.6134767532348633
Batch 6/64 loss: -1.4665136337280273
Batch 7/64 loss: -1.4467802047729492
Batch 8/64 loss: -1.5599651336669922
Batch 9/64 loss: -1.6208734512329102
Batch 10/64 loss: -1.370748519897461
Batch 11/64 loss: -1.4169807434082031
Batch 12/64 loss: -1.374420166015625
Batch 13/64 loss: -1.5048065185546875
Batch 14/64 loss: -1.2399396896362305
Batch 15/64 loss: -1.4691715240478516
Batch 16/64 loss: -1.6601648330688477
Batch 17/64 loss: -1.460702896118164
Batch 18/64 loss: -1.4267463684082031
Batch 19/64 loss: -1.073533058166504
Batch 20/64 loss: -1.7082586288452148
Batch 21/64 loss: -1.352982521057129
Batch 22/64 loss: -1.5269947052001953
Batch 23/64 loss: -1.622201919555664
Batch 24/64 loss: -1.5389928817749023
Batch 25/64 loss: -1.4361076354980469
Batch 26/64 loss: -1.2389631271362305
Batch 27/64 loss: -1.5356903076171875
Batch 28/64 loss: -1.1053905487060547
Batch 29/64 loss: -1.625462532043457
Batch 30/64 loss: -1.536092758178711
Batch 31/64 loss: -1.479217529296875
Batch 32/64 loss: -1.4818696975708008
Batch 33/64 loss: -1.3633403778076172
Batch 34/64 loss: -1.5125293731689453
Batch 35/64 loss: -1.5063018798828125
Batch 36/64 loss: -1.7065200805664062
Batch 37/64 loss: -1.4234561920166016
Batch 38/64 loss: -1.0253686904907227
Batch 39/64 loss: -1.5496749877929688
Batch 40/64 loss: -1.108978271484375
Batch 41/64 loss: -1.5124664306640625
Batch 42/64 loss: -1.518864631652832
Batch 43/64 loss: -1.6385860443115234
Batch 44/64 loss: -1.5609683990478516
Batch 45/64 loss: -1.616159439086914
Batch 46/64 loss: -1.1941051483154297
Batch 47/64 loss: -1.4740657806396484
Batch 48/64 loss: -1.3332147598266602
Batch 49/64 loss: -1.6229524612426758
Batch 50/64 loss: -1.556121826171875
Batch 51/64 loss: -1.5014381408691406
Batch 52/64 loss: -1.3790855407714844
Batch 53/64 loss: -1.5336008071899414
Batch 54/64 loss: -1.0299348831176758
Batch 55/64 loss: -1.3971967697143555
Batch 56/64 loss: -1.2767038345336914
Batch 57/64 loss: -1.491145133972168
Batch 58/64 loss: -1.6108617782592773
Batch 59/64 loss: -1.6756410598754883
Batch 60/64 loss: -1.3032951354980469
Batch 61/64 loss: -1.0078163146972656
Batch 62/64 loss: -1.6269330978393555
Batch 63/64 loss: -1.4616432189941406
Batch 64/64 loss: -5.639916896820068
Epoch 216  Train loss: -1.4895282539666868  Val loss: -1.591031156454709
Epoch 217
-------------------------------
Batch 1/64 loss: -1.5005779266357422
Batch 2/64 loss: -1.6169862747192383
Batch 3/64 loss: -1.12518310546875
Batch 4/64 loss: -1.7170848846435547
Batch 5/64 loss: -0.9747428894042969
Batch 6/64 loss: -1.6260004043579102
Batch 7/64 loss: -1.5772428512573242
Batch 8/64 loss: -1.5943622589111328
Batch 9/64 loss: -1.4332218170166016
Batch 10/64 loss: -1.5973386764526367
Batch 11/64 loss: -0.91510009765625
Batch 12/64 loss: -1.450021743774414
Batch 13/64 loss: -1.7006864547729492
Batch 14/64 loss: -1.652475357055664
Batch 15/64 loss: -1.5462770462036133
Batch 16/64 loss: -1.4963245391845703
Batch 17/64 loss: -1.3627233505249023
Batch 18/64 loss: -1.587533950805664
Batch 19/64 loss: -1.5374116897583008
Batch 20/64 loss: -0.979583740234375
Batch 21/64 loss: -1.6246528625488281
Batch 22/64 loss: -1.434269905090332
Batch 23/64 loss: -1.7262802124023438
Batch 24/64 loss: -1.7180461883544922
Batch 25/64 loss: -1.7406282424926758
Batch 26/64 loss: -1.6055717468261719
Batch 27/64 loss: -1.529404640197754
Batch 28/64 loss: -1.3419122695922852
Batch 29/64 loss: -1.2392911911010742
Batch 30/64 loss: -1.7116193771362305
Batch 31/64 loss: -1.173060417175293
Batch 32/64 loss: -1.468149185180664
Batch 33/64 loss: -1.5775299072265625
Batch 34/64 loss: -1.298685073852539
Batch 35/64 loss: -1.5218381881713867
Batch 36/64 loss: -1.5385074615478516
Batch 37/64 loss: -1.3556556701660156
Batch 38/64 loss: -1.041569709777832
Batch 39/64 loss: -1.7682456970214844
Batch 40/64 loss: -1.3368053436279297
Batch 41/64 loss: -1.9108333587646484
Batch 42/64 loss: -1.6455678939819336
Batch 43/64 loss: -1.436488151550293
Batch 44/64 loss: -1.4779033660888672
Batch 45/64 loss: -0.8915042877197266
Batch 46/64 loss: -1.4201011657714844
Batch 47/64 loss: -1.0920352935791016
Batch 48/64 loss: -1.1981687545776367
Batch 49/64 loss: -1.1660566329956055
Batch 50/64 loss: -1.7124929428100586
Batch 51/64 loss: -1.0646467208862305
Batch 52/64 loss: -1.3036394119262695
Batch 53/64 loss: -1.655538558959961
Batch 54/64 loss: -1.5650348663330078
Batch 55/64 loss: -1.6196517944335938
Batch 56/64 loss: -1.5384550094604492
Batch 57/64 loss: -0.9758596420288086
Batch 58/64 loss: -0.9817037582397461
Batch 59/64 loss: -1.5745048522949219
Batch 60/64 loss: -1.5667190551757812
Batch 61/64 loss: -0.9842004776000977
Batch 62/64 loss: -1.7500762939453125
Batch 63/64 loss: -1.6160078048706055
Batch 64/64 loss: -4.598724365234375
Epoch 217  Train loss: -1.479824873980354  Val loss: -1.6644139240697486
Epoch 218
-------------------------------
Batch 1/64 loss: -1.7422380447387695
Batch 2/64 loss: -1.0753211975097656
Batch 3/64 loss: -1.4500102996826172
Batch 4/64 loss: -1.7304601669311523
Batch 5/64 loss: -1.243117332458496
Batch 6/64 loss: -1.6393423080444336
Batch 7/64 loss: -1.6831464767456055
Batch 8/64 loss: -1.633310317993164
Batch 9/64 loss: -1.0380802154541016
Batch 10/64 loss: -1.7557830810546875
Batch 11/64 loss: -1.4223833084106445
Batch 12/64 loss: -1.4922571182250977
Batch 13/64 loss: -1.5347890853881836
Batch 14/64 loss: -1.4025297164916992
Batch 15/64 loss: -0.9938573837280273
Batch 16/64 loss: -1.5102081298828125
Batch 17/64 loss: -1.8108930587768555
Batch 18/64 loss: -1.4967079162597656
Batch 19/64 loss: -1.5222806930541992
Batch 20/64 loss: -1.417856216430664
Batch 21/64 loss: -1.689077377319336
Batch 22/64 loss: -0.9194517135620117
Batch 23/64 loss: -1.5989933013916016
Batch 24/64 loss: -1.100468635559082
Batch 25/64 loss: -1.2937469482421875
Batch 26/64 loss: -1.663041114807129
Batch 27/64 loss: -1.7444658279418945
Batch 28/64 loss: -1.3781242370605469
Batch 29/64 loss: -1.2497682571411133
Batch 30/64 loss: -1.7301654815673828
Batch 31/64 loss: -1.5328102111816406
Batch 32/64 loss: -1.2852630615234375
Batch 33/64 loss: -1.7142152786254883
Batch 34/64 loss: -1.4754676818847656
Batch 35/64 loss: -1.650101661682129
Batch 36/64 loss: -1.599043846130371
Batch 37/64 loss: -1.7595233917236328
Batch 38/64 loss: -1.175018310546875
Batch 39/64 loss: -1.0015277862548828
Batch 40/64 loss: -1.7495064735412598
Batch 41/64 loss: -1.4498882293701172
Batch 42/64 loss: -1.4235429763793945
Batch 43/64 loss: -1.4114179611206055
Batch 44/64 loss: -1.4570159912109375
Batch 45/64 loss: -1.3351755142211914
Batch 46/64 loss: -1.3813066482543945
Batch 47/64 loss: -1.4793262481689453
Batch 48/64 loss: -1.1975879669189453
Batch 49/64 loss: -1.4006500244140625
Batch 50/64 loss: -1.3273134231567383
Batch 51/64 loss: -1.6665210723876953
Batch 52/64 loss: -1.3471307754516602
Batch 53/64 loss: -1.4703607559204102
Batch 54/64 loss: -1.4880475997924805
Batch 55/64 loss: -1.3495988845825195
Batch 56/64 loss: -0.7732172012329102
Batch 57/64 loss: -1.5859899520874023
Batch 58/64 loss: -1.6158380508422852
Batch 59/64 loss: -1.587092399597168
Batch 60/64 loss: -0.9193897247314453
Batch 61/64 loss: -1.0986061096191406
Batch 62/64 loss: -1.368112564086914
Batch 63/64 loss: -1.132615089416504
Batch 64/64 loss: -5.156209945678711
Epoch 218  Train loss: -1.4750942005830652  Val loss: -1.600189798886014
Epoch 219
-------------------------------
Batch 1/64 loss: -1.6396656036376953
Batch 2/64 loss: -1.4161653518676758
Batch 3/64 loss: -1.6648292541503906
Batch 4/64 loss: -1.0951919555664062
Batch 5/64 loss: -1.5211105346679688
Batch 6/64 loss: -1.3234062194824219
Batch 7/64 loss: -1.2731256484985352
Batch 8/64 loss: -1.5764198303222656
Batch 9/64 loss: -1.569570541381836
Batch 10/64 loss: -1.8202037811279297
Batch 11/64 loss: -0.9171590805053711
Batch 12/64 loss: -1.4465579986572266
Batch 13/64 loss: -1.4831762313842773
Batch 14/64 loss: -1.3860626220703125
Batch 15/64 loss: -1.4203996658325195
Batch 16/64 loss: -1.531167984008789
Batch 17/64 loss: -1.383284568786621
Batch 18/64 loss: -1.6253747940063477
Batch 19/64 loss: -1.0883140563964844
Batch 20/64 loss: -0.6946029663085938
Batch 21/64 loss: -1.3070402145385742
Batch 22/64 loss: -0.9192438125610352
Batch 23/64 loss: -1.2329521179199219
Batch 24/64 loss: -0.8141288757324219
Batch 25/64 loss: -1.4534873962402344
Batch 26/64 loss: -1.4586858749389648
Batch 27/64 loss: -1.363957405090332
Batch 28/64 loss: -1.3697643280029297
Batch 29/64 loss: -1.4670076370239258
Batch 30/64 loss: -1.0618410110473633
Batch 31/64 loss: -1.4763202667236328
Batch 32/64 loss: -0.916010856628418
Batch 33/64 loss: -1.1612844467163086
Batch 34/64 loss: -1.5132818222045898
Batch 35/64 loss: -1.2776966094970703
Batch 36/64 loss: -1.3752756118774414
Batch 37/64 loss: -0.9741897583007812
Batch 38/64 loss: -1.3011474609375
Batch 39/64 loss: -1.4430160522460938
Batch 40/64 loss: -1.170638084411621
Batch 41/64 loss: -1.258413314819336
Batch 42/64 loss: -1.0956497192382812
Batch 43/64 loss: -1.3494434356689453
Batch 44/64 loss: -1.4469366073608398
Batch 45/64 loss: -1.268843650817871
Batch 46/64 loss: -1.472975730895996
Batch 47/64 loss: -1.6883630752563477
Batch 48/64 loss: -1.2965335845947266
Batch 49/64 loss: -1.5651254653930664
Batch 50/64 loss: -1.5443878173828125
Batch 51/64 loss: -1.282400131225586
Batch 52/64 loss: -1.219635009765625
Batch 53/64 loss: -0.7186479568481445
Batch 54/64 loss: -1.2892580032348633
Batch 55/64 loss: -0.7798871994018555
Batch 56/64 loss: -1.3981647491455078
Batch 57/64 loss: -1.498490333557129
Batch 58/64 loss: -1.089522361755371
Batch 59/64 loss: -1.070826530456543
Batch 60/64 loss: -1.0218191146850586
Batch 61/64 loss: -1.4111700057983398
Batch 62/64 loss: -1.4089603424072266
Batch 63/64 loss: -1.7375988960266113
Batch 64/64 loss: -5.072171688079834
Epoch 219  Train loss: -1.3592147471858005  Val loss: -1.5379599082920559
Epoch 220
-------------------------------
Batch 1/64 loss: -1.2244834899902344
Batch 2/64 loss: -1.333444595336914
Batch 3/64 loss: -1.1430768966674805
Batch 4/64 loss: -1.3624649047851562
Batch 5/64 loss: -1.6358575820922852
Batch 6/64 loss: -1.287567138671875
Batch 7/64 loss: -1.452784538269043
Batch 8/64 loss: -1.3886299133300781
Batch 9/64 loss: -1.2860746383666992
Batch 10/64 loss: -1.6250457763671875
Batch 11/64 loss: -1.464411735534668
Batch 12/64 loss: -1.4708051681518555
Batch 13/64 loss: -0.9287729263305664
Batch 14/64 loss: -1.481679916381836
Batch 15/64 loss: -1.4640159606933594
Batch 16/64 loss: -1.0607194900512695
Batch 17/64 loss: -1.8032197952270508
Batch 18/64 loss: -1.3837909698486328
Batch 19/64 loss: -1.473836898803711
Batch 20/64 loss: -1.599954605102539
Batch 21/64 loss: -1.5045709609985352
Batch 22/64 loss: -1.6461105346679688
Batch 23/64 loss: -1.4421062469482422
Batch 24/64 loss: -1.2730188369750977
Batch 25/64 loss: -1.0640335083007812
Batch 26/64 loss: -1.2360496520996094
Batch 27/64 loss: -1.4371166229248047
Batch 28/64 loss: -1.7673473358154297
Batch 29/64 loss: -1.426772117614746
Batch 30/64 loss: -1.308436393737793
Batch 31/64 loss: -1.2909259796142578
Batch 32/64 loss: -1.584019660949707
Batch 33/64 loss: -1.6253023147583008
Batch 34/64 loss: -1.2312726974487305
Batch 35/64 loss: -1.3357620239257812
Batch 36/64 loss: -0.7586984634399414
Batch 37/64 loss: -1.6226444244384766
Batch 38/64 loss: -1.6408004760742188
Batch 39/64 loss: -1.117323875427246
Batch 40/64 loss: -0.6406745910644531
Batch 41/64 loss: -1.6530966758728027
Batch 42/64 loss: -1.458089828491211
Batch 43/64 loss: -1.434112548828125
Batch 44/64 loss: -1.4955110549926758
Batch 45/64 loss: -1.4538116455078125
Batch 46/64 loss: -1.5373125076293945
Batch 47/64 loss: -1.7373228073120117
Batch 48/64 loss: -1.1684656143188477
Batch 49/64 loss: -1.696864128112793
Batch 50/64 loss: -1.5075654983520508
Batch 51/64 loss: -1.5061874389648438
Batch 52/64 loss: -1.154245376586914
Batch 53/64 loss: -1.1767702102661133
Batch 54/64 loss: -1.1651725769042969
Batch 55/64 loss: -1.158853530883789
Batch 56/64 loss: -1.4963083267211914
Batch 57/64 loss: -1.7086200714111328
Batch 58/64 loss: -1.5937652587890625
Batch 59/64 loss: -1.4407262802124023
Batch 60/64 loss: -1.0160188674926758
Batch 61/64 loss: -1.392923355102539
Batch 62/64 loss: -1.5210504531860352
Batch 63/64 loss: -1.418914794921875
Batch 64/64 loss: -5.048754692077637
Epoch 220  Train loss: -1.4353238984650256  Val loss: -1.5750063473416358
Epoch 221
-------------------------------
Batch 1/64 loss: -1.5909109115600586
Batch 2/64 loss: -1.4878225326538086
Batch 3/64 loss: -1.4792070388793945
Batch 4/64 loss: -1.533315658569336
Batch 5/64 loss: -1.0593671798706055
Batch 6/64 loss: -1.1381959915161133
Batch 7/64 loss: -1.4312467575073242
Batch 8/64 loss: -1.4742841720581055
Batch 9/64 loss: -1.6886978149414062
Batch 10/64 loss: -1.6147289276123047
Batch 11/64 loss: -1.5111169815063477
Batch 12/64 loss: -1.4374780654907227
Batch 13/64 loss: -1.621546745300293
Batch 14/64 loss: -1.4256963729858398
Batch 15/64 loss: -1.5072174072265625
Batch 16/64 loss: -1.5221471786499023
Batch 17/64 loss: -1.1539268493652344
Batch 18/64 loss: -1.516122817993164
Batch 19/64 loss: -1.6004772186279297
Batch 20/64 loss: -0.8478603363037109
Batch 21/64 loss: -1.438572883605957
Batch 22/64 loss: -1.5756940841674805
Batch 23/64 loss: -1.7513093948364258
Batch 24/64 loss: -1.7103776931762695
Batch 25/64 loss: -1.764267921447754
Batch 26/64 loss: -1.3576536178588867
Batch 27/64 loss: -1.3148870468139648
Batch 28/64 loss: -1.456796646118164
Batch 29/64 loss: -1.5690793991088867
Batch 30/64 loss: -1.7353110313415527
Batch 31/64 loss: -1.4413995742797852
Batch 32/64 loss: -1.2152738571166992
Batch 33/64 loss: -1.587747573852539
Batch 34/64 loss: -1.3854560852050781
Batch 35/64 loss: -1.3155202865600586
Batch 36/64 loss: -1.2892885208129883
Batch 37/64 loss: -1.5279359817504883
Batch 38/64 loss: -1.5458621978759766
Batch 39/64 loss: -1.3090143203735352
Batch 40/64 loss: -1.2733564376831055
Batch 41/64 loss: -1.2766523361206055
Batch 42/64 loss: -1.6463871002197266
Batch 43/64 loss: -1.293076515197754
Batch 44/64 loss: -1.4564037322998047
Batch 45/64 loss: -0.901371955871582
Batch 46/64 loss: -1.5864934921264648
Batch 47/64 loss: -1.3678646087646484
Batch 48/64 loss: -1.3123817443847656
Batch 49/64 loss: -1.084024429321289
Batch 50/64 loss: -1.473057746887207
Batch 51/64 loss: -1.3374853134155273
Batch 52/64 loss: -1.4536685943603516
Batch 53/64 loss: -1.5640239715576172
Batch 54/64 loss: -1.3631305694580078
Batch 55/64 loss: -1.4950542449951172
Batch 56/64 loss: -1.2760324478149414
Batch 57/64 loss: -1.170973777770996
Batch 58/64 loss: -1.437546730041504
Batch 59/64 loss: -1.5386896133422852
Batch 60/64 loss: -0.9070501327514648
Batch 61/64 loss: -1.0306529998779297
Batch 62/64 loss: -1.4143619537353516
Batch 63/64 loss: -1.3044977188110352
Batch 64/64 loss: -5.683961391448975
Epoch 221  Train loss: -1.461333714279474  Val loss: -1.4766702422571345
Epoch 222
-------------------------------
Batch 1/64 loss: -0.6953086853027344
Batch 2/64 loss: -1.1157522201538086
Batch 3/64 loss: -1.2579412460327148
Batch 4/64 loss: -1.0322751998901367
Batch 5/64 loss: -1.5347843170166016
Batch 6/64 loss: -1.3215694427490234
Batch 7/64 loss: -1.4783153533935547
Batch 8/64 loss: -1.4486103057861328
Batch 9/64 loss: -1.541213035583496
Batch 10/64 loss: -1.5153837203979492
Batch 11/64 loss: -1.3389863967895508
Batch 12/64 loss: -1.509695053100586
Batch 13/64 loss: -1.337632179260254
Batch 14/64 loss: -1.2964801788330078
Batch 15/64 loss: -0.6598281860351562
Batch 16/64 loss: -1.4250965118408203
Batch 17/64 loss: -1.6527633666992188
Batch 18/64 loss: -1.3651237487792969
Batch 19/64 loss: -1.5230627059936523
Batch 20/64 loss: -1.468374252319336
Batch 21/64 loss: -1.4881505966186523
Batch 22/64 loss: -1.4075918197631836
Batch 23/64 loss: -1.4710674285888672
Batch 24/64 loss: -1.6322546005249023
Batch 25/64 loss: -1.0279722213745117
Batch 26/64 loss: -1.5019617080688477
Batch 27/64 loss: -1.5089397430419922
Batch 28/64 loss: -1.3973388671875
Batch 29/64 loss: -0.8795022964477539
Batch 30/64 loss: -1.5454959869384766
Batch 31/64 loss: -1.3075571060180664
Batch 32/64 loss: -1.4336557388305664
Batch 33/64 loss: -1.1860408782958984
Batch 34/64 loss: -1.2517271041870117
Batch 35/64 loss: -1.4227056503295898
Batch 36/64 loss: -0.9843454360961914
Batch 37/64 loss: -1.1816520690917969
Batch 38/64 loss: -1.5327301025390625
Batch 39/64 loss: -1.3703193664550781
Batch 40/64 loss: -1.310333251953125
Batch 41/64 loss: -1.2018022537231445
Batch 42/64 loss: -1.6981210708618164
Batch 43/64 loss: -1.4149494171142578
Batch 44/64 loss: -1.6791229248046875
Batch 45/64 loss: -1.618234634399414
Batch 46/64 loss: -1.518575668334961
Batch 47/64 loss: -1.4831361770629883
Batch 48/64 loss: -1.4728727340698242
Batch 49/64 loss: -1.2074661254882812
Batch 50/64 loss: -1.4242916107177734
Batch 51/64 loss: -1.7106828689575195
Batch 52/64 loss: -1.5061321258544922
Batch 53/64 loss: -1.3311100006103516
Batch 54/64 loss: -1.6977806091308594
Batch 55/64 loss: -1.7163591384887695
Batch 56/64 loss: -1.5935983657836914
Batch 57/64 loss: -1.247584342956543
Batch 58/64 loss: -1.3883066177368164
Batch 59/64 loss: -0.9425201416015625
Batch 60/64 loss: -1.2579383850097656
Batch 61/64 loss: -1.6991147994995117
Batch 62/64 loss: -1.2859878540039062
Batch 63/64 loss: -1.2726173400878906
Batch 64/64 loss: -5.228273391723633
Epoch 222  Train loss: -1.4219458561317593  Val loss: -1.6416739106587939
Epoch 223
-------------------------------
Batch 1/64 loss: -1.4289073944091797
Batch 2/64 loss: -1.7093172073364258
Batch 3/64 loss: -1.4207067489624023
Batch 4/64 loss: -1.5039520263671875
Batch 5/64 loss: -1.3756523132324219
Batch 6/64 loss: -1.1566219329833984
Batch 7/64 loss: -1.6929998397827148
Batch 8/64 loss: -1.5298919677734375
Batch 9/64 loss: -1.1809444427490234
Batch 10/64 loss: -1.4683599472045898
Batch 11/64 loss: -1.4172124862670898
Batch 12/64 loss: -1.5614862442016602
Batch 13/64 loss: -1.4861793518066406
Batch 14/64 loss: -1.5697755813598633
Batch 15/64 loss: -1.5707368850708008
Batch 16/64 loss: -1.4732379913330078
Batch 17/64 loss: -1.4152545928955078
Batch 18/64 loss: -1.5502138137817383
Batch 19/64 loss: -1.4054040908813477
Batch 20/64 loss: -1.435586929321289
Batch 21/64 loss: -1.0559940338134766
Batch 22/64 loss: -1.4716053009033203
Batch 23/64 loss: -1.5405874252319336
Batch 24/64 loss: -1.2975387573242188
Batch 25/64 loss: -1.7280759811401367
Batch 26/64 loss: -1.747063159942627
Batch 27/64 loss: -1.4249629974365234
Batch 28/64 loss: -1.535679817199707
Batch 29/64 loss: -1.278752326965332
Batch 30/64 loss: -1.4434175491333008
Batch 31/64 loss: -1.807858943939209
Batch 32/64 loss: -1.3792829513549805
Batch 33/64 loss: -1.692464828491211
Batch 34/64 loss: -1.1539497375488281
Batch 35/64 loss: -1.1996259689331055
Batch 36/64 loss: -0.7460126876831055
Batch 37/64 loss: -1.5553789138793945
Batch 38/64 loss: -1.353475570678711
Batch 39/64 loss: -1.3764972686767578
Batch 40/64 loss: -1.4483604431152344
Batch 41/64 loss: -1.4563446044921875
Batch 42/64 loss: -1.3647146224975586
Batch 43/64 loss: -1.245133399963379
Batch 44/64 loss: -1.282546043395996
Batch 45/64 loss: -1.1765241622924805
Batch 46/64 loss: -1.5648527145385742
Batch 47/64 loss: -1.2652626037597656
Batch 48/64 loss: -1.3637800216674805
Batch 49/64 loss: -1.0942745208740234
Batch 50/64 loss: -1.5241575241088867
Batch 51/64 loss: -1.6976423263549805
Batch 52/64 loss: -1.7801427841186523
Batch 53/64 loss: -1.6002826690673828
Batch 54/64 loss: -0.947230339050293
Batch 55/64 loss: -1.4487552642822266
Batch 56/64 loss: -1.6055879592895508
Batch 57/64 loss: -1.602468490600586
Batch 58/64 loss: -1.0986738204956055
Batch 59/64 loss: -1.5453424453735352
Batch 60/64 loss: -1.4546260833740234
Batch 61/64 loss: -1.1906557083129883
Batch 62/64 loss: -1.5806455612182617
Batch 63/64 loss: -1.6013984680175781
Batch 64/64 loss: -4.846941947937012
Epoch 223  Train loss: -1.4700435301836798  Val loss: -1.5759421410839172
Epoch 224
-------------------------------
Batch 1/64 loss: -1.45684814453125
Batch 2/64 loss: -1.4751520156860352
Batch 3/64 loss: -1.4628715515136719
Batch 4/64 loss: -1.1085443496704102
Batch 5/64 loss: -1.1620635986328125
Batch 6/64 loss: -1.4892749786376953
Batch 7/64 loss: -1.5713253021240234
Batch 8/64 loss: -1.5099449157714844
Batch 9/64 loss: -1.1999435424804688
Batch 10/64 loss: -1.298975944519043
Batch 11/64 loss: -1.0187253952026367
Batch 12/64 loss: -1.3554401397705078
Batch 13/64 loss: -1.153630256652832
Batch 14/64 loss: -1.4610958099365234
Batch 15/64 loss: -1.527573585510254
Batch 16/64 loss: -1.3747129440307617
Batch 17/64 loss: -1.6937341690063477
Batch 18/64 loss: -1.731302261352539
Batch 19/64 loss: -1.4020166397094727
Batch 20/64 loss: -1.1283931732177734
Batch 21/64 loss: -1.6408944129943848
Batch 22/64 loss: -1.4212617874145508
Batch 23/64 loss: -1.602452278137207
Batch 24/64 loss: -1.5130462646484375
Batch 25/64 loss: -1.5621366500854492
Batch 26/64 loss: -1.3170862197875977
Batch 27/64 loss: -1.1288185119628906
Batch 28/64 loss: -1.4987993240356445
Batch 29/64 loss: -1.3672819137573242
Batch 30/64 loss: -1.8778371810913086
Batch 31/64 loss: -1.0740480422973633
Batch 32/64 loss: -1.149496078491211
Batch 33/64 loss: -1.1657905578613281
Batch 34/64 loss: -1.5832576751708984
Batch 35/64 loss: -1.2406644821166992
Batch 36/64 loss: -1.5066337585449219
Batch 37/64 loss: -1.5071592330932617
Batch 38/64 loss: -1.5742321014404297
Batch 39/64 loss: -1.549067497253418
Batch 40/64 loss: -1.0408496856689453
Batch 41/64 loss: -1.520599365234375
Batch 42/64 loss: -1.6684751510620117
Batch 43/64 loss: -1.2874860763549805
Batch 44/64 loss: -1.593320369720459
Batch 45/64 loss: -1.5814971923828125
Batch 46/64 loss: -1.1983203887939453
Batch 47/64 loss: -1.584981918334961
Batch 48/64 loss: -1.4371213912963867
Batch 49/64 loss: -1.3724336624145508
Batch 50/64 loss: -1.7163972854614258
Batch 51/64 loss: -1.213592529296875
Batch 52/64 loss: -1.2333879470825195
Batch 53/64 loss: -1.6161518096923828
Batch 54/64 loss: -1.1047239303588867
Batch 55/64 loss: -1.5113677978515625
Batch 56/64 loss: -1.484537124633789
Batch 57/64 loss: -1.4854888916015625
Batch 58/64 loss: -1.4393978118896484
Batch 59/64 loss: -1.6006460189819336
Batch 60/64 loss: -1.518960952758789
Batch 61/64 loss: -1.251408576965332
Batch 62/64 loss: -1.5115299224853516
Batch 63/64 loss: -1.6750173568725586
Batch 64/64 loss: -5.655487537384033
Epoch 224  Train loss: -1.4706014352686265  Val loss: -1.5765269171331346
Epoch 225
-------------------------------
Batch 1/64 loss: -1.4466791152954102
Batch 2/64 loss: -1.5005874633789062
Batch 3/64 loss: -1.6443281173706055
Batch 4/64 loss: -1.5521783828735352
Batch 5/64 loss: -1.0659809112548828
Batch 6/64 loss: -1.1555309295654297
Batch 7/64 loss: -1.542898178100586
Batch 8/64 loss: -1.7135133743286133
Batch 9/64 loss: -1.6179914474487305
Batch 10/64 loss: -1.251901626586914
Batch 11/64 loss: -1.395787239074707
Batch 12/64 loss: -1.1888093948364258
Batch 13/64 loss: -1.3346529006958008
Batch 14/64 loss: -1.208876609802246
Batch 15/64 loss: -1.0101451873779297
Batch 16/64 loss: -1.6180229187011719
Batch 17/64 loss: -1.4921302795410156
Batch 18/64 loss: -1.6048908233642578
Batch 19/64 loss: -1.269205093383789
Batch 20/64 loss: -1.2703886032104492
Batch 21/64 loss: -1.4847440719604492
Batch 22/64 loss: -1.5412254333496094
Batch 23/64 loss: -1.592855453491211
Batch 24/64 loss: -1.3951482772827148
Batch 25/64 loss: -1.5451421737670898
Batch 26/64 loss: -1.550966739654541
Batch 27/64 loss: -1.603318214416504
Batch 28/64 loss: -0.9858179092407227
Batch 29/64 loss: -1.6810922622680664
Batch 30/64 loss: -1.5957460403442383
Batch 31/64 loss: -1.4795360565185547
Batch 32/64 loss: -1.6685643196105957
Batch 33/64 loss: -1.3776960372924805
Batch 34/64 loss: -1.4344134330749512
Batch 35/64 loss: -0.8656015396118164
Batch 36/64 loss: -1.424351692199707
Batch 37/64 loss: -1.618147850036621
Batch 38/64 loss: -1.356095314025879
Batch 39/64 loss: -1.180891990661621
Batch 40/64 loss: -1.4532403945922852
Batch 41/64 loss: -1.5970172882080078
Batch 42/64 loss: -1.5130252838134766
Batch 43/64 loss: -1.4578781127929688
Batch 44/64 loss: -1.6583857536315918
Batch 45/64 loss: -1.2703227996826172
Batch 46/64 loss: -1.5020580291748047
Batch 47/64 loss: -1.4623422622680664
Batch 48/64 loss: -1.2442541122436523
Batch 49/64 loss: -1.2088336944580078
Batch 50/64 loss: -1.3848981857299805
Batch 51/64 loss: -1.0138473510742188
Batch 52/64 loss: -1.4640703201293945
Batch 53/64 loss: -1.8610715866088867
Batch 54/64 loss: -1.534285545349121
Batch 55/64 loss: -1.305837631225586
Batch 56/64 loss: -1.4204750061035156
Batch 57/64 loss: -1.3002700805664062
Batch 58/64 loss: -1.310262680053711
Batch 59/64 loss: -1.7522163391113281
Batch 60/64 loss: -1.5772895812988281
Batch 61/64 loss: -1.2354850769042969
Batch 62/64 loss: -1.5808143615722656
Batch 63/64 loss: -1.2821693420410156
Batch 64/64 loss: -4.868095874786377
Epoch 225  Train loss: -1.4636435471329035  Val loss: -1.5747373653031707
Epoch 226
-------------------------------
Batch 1/64 loss: -1.5623998641967773
Batch 2/64 loss: -1.5848455429077148
Batch 3/64 loss: -1.6312065124511719
Batch 4/64 loss: -1.3453044891357422
Batch 5/64 loss: -1.59527587890625
Batch 6/64 loss: -1.422861099243164
Batch 7/64 loss: -1.3164281845092773
Batch 8/64 loss: -1.459202766418457
Batch 9/64 loss: -1.6713037490844727
Batch 10/64 loss: -1.3993759155273438
Batch 11/64 loss: -1.4171037673950195
Batch 12/64 loss: -1.3660869598388672
Batch 13/64 loss: -1.159341812133789
Batch 14/64 loss: -1.407175064086914
Batch 15/64 loss: -1.2379531860351562
Batch 16/64 loss: -1.230299949645996
Batch 17/64 loss: -1.6175031661987305
Batch 18/64 loss: -1.5567779541015625
Batch 19/64 loss: -1.8051471710205078
Batch 20/64 loss: -1.329493522644043
Batch 21/64 loss: -1.6510887145996094
Batch 22/64 loss: -1.1133089065551758
Batch 23/64 loss: -1.7570123672485352
Batch 24/64 loss: -1.6059837341308594
Batch 25/64 loss: -1.6322879791259766
Batch 26/64 loss: -1.2889642715454102
Batch 27/64 loss: -0.8732662200927734
Batch 28/64 loss: -1.34161376953125
Batch 29/64 loss: -1.699509620666504
Batch 30/64 loss: -1.5832853317260742
Batch 31/64 loss: -1.5803003311157227
Batch 32/64 loss: -1.4361934661865234
Batch 33/64 loss: -1.5997323989868164
Batch 34/64 loss: -0.9615144729614258
Batch 35/64 loss: -1.6247458457946777
Batch 36/64 loss: -1.6709442138671875
Batch 37/64 loss: -1.2968378067016602
Batch 38/64 loss: -1.7467670440673828
Batch 39/64 loss: -1.7885866165161133
Batch 40/64 loss: -1.5754785537719727
Batch 41/64 loss: -1.4974746704101562
Batch 42/64 loss: -1.3710613250732422
Batch 43/64 loss: -1.2705793380737305
Batch 44/64 loss: -1.3871631622314453
Batch 45/64 loss: -1.307760238647461
Batch 46/64 loss: -1.1563348770141602
Batch 47/64 loss: -1.6458253860473633
Batch 48/64 loss: -1.4558372497558594
Batch 49/64 loss: -1.4568605422973633
Batch 50/64 loss: -1.3823356628417969
Batch 51/64 loss: -1.6077356338500977
Batch 52/64 loss: -1.3794374465942383
Batch 53/64 loss: -1.248213768005371
Batch 54/64 loss: -1.3799457550048828
Batch 55/64 loss: -1.5030031204223633
Batch 56/64 loss: -1.3916807174682617
Batch 57/64 loss: -1.4213933944702148
Batch 58/64 loss: -1.1120271682739258
Batch 59/64 loss: -1.6525869369506836
Batch 60/64 loss: -1.685633659362793
Batch 61/64 loss: -1.480703353881836
Batch 62/64 loss: -1.487095832824707
Batch 63/64 loss: -1.5497722625732422
Batch 64/64 loss: -5.242045879364014
Epoch 226  Train loss: -1.5012471236434637  Val loss: -1.5012409957413821
Epoch 227
-------------------------------
Batch 1/64 loss: -1.5298643112182617
Batch 2/64 loss: -1.4266529083251953
Batch 3/64 loss: -1.446746826171875
Batch 4/64 loss: -1.1919355392456055
Batch 5/64 loss: -1.3853139877319336
Batch 6/64 loss: -1.1154022216796875
Batch 7/64 loss: -1.2600030899047852
Batch 8/64 loss: -1.6242694854736328
Batch 9/64 loss: -1.4783000946044922
Batch 10/64 loss: -0.6996135711669922
Batch 11/64 loss: -1.3617792129516602
Batch 12/64 loss: -1.2818412780761719
Batch 13/64 loss: -1.3534975051879883
Batch 14/64 loss: -1.394118309020996
Batch 15/64 loss: -1.2273950576782227
Batch 16/64 loss: -1.4605693817138672
Batch 17/64 loss: -1.204580307006836
Batch 18/64 loss: -1.568206787109375
Batch 19/64 loss: -1.1030235290527344
Batch 20/64 loss: -1.549886703491211
Batch 21/64 loss: -1.0834436416625977
Batch 22/64 loss: -1.6229019165039062
Batch 23/64 loss: -1.5657148361206055
Batch 24/64 loss: -1.2219209671020508
Batch 25/64 loss: -1.4157114028930664
Batch 26/64 loss: -1.7210063934326172
Batch 27/64 loss: -1.600935935974121
Batch 28/64 loss: -1.269038200378418
Batch 29/64 loss: -0.8246669769287109
Batch 30/64 loss: -1.2853422164916992
Batch 31/64 loss: -1.2284965515136719
Batch 32/64 loss: -1.1049394607543945
Batch 33/64 loss: -1.4821748733520508
Batch 34/64 loss: -1.6819696426391602
Batch 35/64 loss: -1.5039043426513672
Batch 36/64 loss: -1.4113941192626953
Batch 37/64 loss: -0.6411752700805664
Batch 38/64 loss: -1.624711036682129
Batch 39/64 loss: -1.3056211471557617
Batch 40/64 loss: -1.5524539947509766
Batch 41/64 loss: -1.5064926147460938
Batch 42/64 loss: -1.486459732055664
Batch 43/64 loss: -1.5372333526611328
Batch 44/64 loss: -1.4415006637573242
Batch 45/64 loss: -1.7305974960327148
Batch 46/64 loss: -1.3366374969482422
Batch 47/64 loss: -1.2315540313720703
Batch 48/64 loss: -1.3150882720947266
Batch 49/64 loss: -1.0919179916381836
Batch 50/64 loss: -1.3654289245605469
Batch 51/64 loss: -1.8192710876464844
Batch 52/64 loss: -1.2187557220458984
Batch 53/64 loss: -1.1925115585327148
Batch 54/64 loss: -1.5897026062011719
Batch 55/64 loss: -1.5136127471923828
Batch 56/64 loss: -1.305318832397461
Batch 57/64 loss: -1.7173738479614258
Batch 58/64 loss: -1.4315242767333984
Batch 59/64 loss: -0.6150951385498047
Batch 60/64 loss: -1.655876636505127
Batch 61/64 loss: -1.4729537963867188
Batch 62/64 loss: -1.655935287475586
Batch 63/64 loss: -1.4154386520385742
Batch 64/64 loss: -5.652075290679932
Epoch 227  Train loss: -1.4226801610460469  Val loss: -1.6339560964263182
Epoch 228
-------------------------------
Batch 1/64 loss: -1.5731821060180664
Batch 2/64 loss: -1.5732078552246094
Batch 3/64 loss: -1.3199834823608398
Batch 4/64 loss: -1.473158836364746
Batch 5/64 loss: -1.6337547302246094
Batch 6/64 loss: -1.6084871292114258
Batch 7/64 loss: -1.4003381729125977
Batch 8/64 loss: -1.4696121215820312
Batch 9/64 loss: -1.4025869369506836
Batch 10/64 loss: -1.4971857070922852
Batch 11/64 loss: -1.4190750122070312
Batch 12/64 loss: -1.493391990661621
Batch 13/64 loss: -1.5616779327392578
Batch 14/64 loss: -1.4339942932128906
Batch 15/64 loss: -1.6944360733032227
Batch 16/64 loss: -1.4291467666625977
Batch 17/64 loss: -1.4161310195922852
Batch 18/64 loss: -1.113572120666504
Batch 19/64 loss: -1.3651599884033203
Batch 20/64 loss: -1.6797981262207031
Batch 21/64 loss: -1.2905445098876953
Batch 22/64 loss: -1.3451528549194336
Batch 23/64 loss: -1.2735090255737305
Batch 24/64 loss: -1.2747125625610352
Batch 25/64 loss: -1.0446052551269531
Batch 26/64 loss: -1.1778240203857422
Batch 27/64 loss: -1.4765863418579102
Batch 28/64 loss: -1.395559310913086
Batch 29/64 loss: -1.547933578491211
Batch 30/64 loss: -1.4459104537963867
Batch 31/64 loss: -1.2204389572143555
Batch 32/64 loss: -1.3787612915039062
Batch 33/64 loss: -1.5964202880859375
Batch 34/64 loss: -1.0360393524169922
Batch 35/64 loss: -1.8006458282470703
Batch 36/64 loss: -1.2542076110839844
Batch 37/64 loss: -1.8092575073242188
Batch 38/64 loss: -1.5806503295898438
Batch 39/64 loss: -1.1362380981445312
Batch 40/64 loss: -1.484567642211914
Batch 41/64 loss: -1.4567899703979492
Batch 42/64 loss: -1.5037059783935547
Batch 43/64 loss: -1.2741641998291016
Batch 44/64 loss: -1.1649789810180664
Batch 45/64 loss: -1.4171810150146484
Batch 46/64 loss: -1.848637580871582
Batch 47/64 loss: -0.8880271911621094
Batch 48/64 loss: -1.4908113479614258
Batch 49/64 loss: -1.4097280502319336
Batch 50/64 loss: -1.4647960662841797
Batch 51/64 loss: -1.170588493347168
Batch 52/64 loss: -1.0708131790161133
Batch 53/64 loss: -1.3205070495605469
Batch 54/64 loss: -1.1563358306884766
Batch 55/64 loss: -0.9456663131713867
Batch 56/64 loss: -1.7443017959594727
Batch 57/64 loss: -1.6787195205688477
Batch 58/64 loss: -1.359476089477539
Batch 59/64 loss: -1.5652122497558594
Batch 60/64 loss: -1.4116096496582031
Batch 61/64 loss: -1.3487567901611328
Batch 62/64 loss: -1.5271949768066406
Batch 63/64 loss: -1.092747688293457
Batch 64/64 loss: -5.70794153213501
Epoch 228  Train loss: -1.4544180608263202  Val loss: -1.538559182812668
Epoch 229
-------------------------------
Batch 1/64 loss: -1.2286529541015625
Batch 2/64 loss: -1.6637458801269531
Batch 3/64 loss: -1.6661949157714844
Batch 4/64 loss: -1.5660638809204102
Batch 5/64 loss: -1.328099250793457
Batch 6/64 loss: -1.717885971069336
Batch 7/64 loss: -1.514693260192871
Batch 8/64 loss: -1.5159788131713867
Batch 9/64 loss: -1.790013313293457
Batch 10/64 loss: -1.4062700271606445
Batch 11/64 loss: -1.1118049621582031
Batch 12/64 loss: -1.6305522918701172
Batch 13/64 loss: -1.2510528564453125
Batch 14/64 loss: -1.4853363037109375
Batch 15/64 loss: -1.4752750396728516
Batch 16/64 loss: -0.8937129974365234
Batch 17/64 loss: -1.1292762756347656
Batch 18/64 loss: -1.4542827606201172
Batch 19/64 loss: -1.943554401397705
Batch 20/64 loss: -1.464177131652832
Batch 21/64 loss: -1.3850584030151367
Batch 22/64 loss: -1.7696380615234375
Batch 23/64 loss: -1.8220624923706055
Batch 24/64 loss: -1.5879707336425781
Batch 25/64 loss: -1.56134033203125
Batch 26/64 loss: -1.5667266845703125
Batch 27/64 loss: -1.4060192108154297
Batch 28/64 loss: -1.316786766052246
Batch 29/64 loss: -1.5703716278076172
Batch 30/64 loss: -1.8231067657470703
Batch 31/64 loss: -1.4171113967895508
Batch 32/64 loss: -1.180109977722168
Batch 33/64 loss: -1.6054954528808594
Batch 34/64 loss: -1.7853727340698242
Batch 35/64 loss: -1.4536495208740234
Batch 36/64 loss: -1.2264556884765625
Batch 37/64 loss: -1.6052894592285156
Batch 38/64 loss: -1.5423555374145508
Batch 39/64 loss: -1.484217643737793
Batch 40/64 loss: -1.431715965270996
Batch 41/64 loss: -1.4139900207519531
Batch 42/64 loss: -0.6976585388183594
Batch 43/64 loss: -1.450282096862793
Batch 44/64 loss: -1.830470085144043
Batch 45/64 loss: -1.1283893585205078
Batch 46/64 loss: -1.1860265731811523
Batch 47/64 loss: -1.687528133392334
Batch 48/64 loss: -1.5533990859985352
Batch 49/64 loss: -1.282958984375
Batch 50/64 loss: -1.076080322265625
Batch 51/64 loss: -1.5643510818481445
Batch 52/64 loss: -0.9907369613647461
Batch 53/64 loss: -1.3136262893676758
Batch 54/64 loss: -1.4145145416259766
Batch 55/64 loss: -1.802891731262207
Batch 56/64 loss: -1.5393590927124023
Batch 57/64 loss: -1.2473535537719727
Batch 58/64 loss: -1.7621936798095703
Batch 59/64 loss: -1.5317134857177734
Batch 60/64 loss: -1.3625011444091797
Batch 61/64 loss: -1.402857780456543
Batch 62/64 loss: -1.2736949920654297
Batch 63/64 loss: -1.3770771026611328
Batch 64/64 loss: -4.549877166748047
Epoch 229  Train loss: -1.4914437686695772  Val loss: -1.705335059936104
Epoch 230
-------------------------------
Batch 1/64 loss: -1.8833556175231934
Batch 2/64 loss: -1.4414138793945312
Batch 3/64 loss: -1.532444953918457
Batch 4/64 loss: -1.6332101821899414
Batch 5/64 loss: -1.411787986755371
Batch 6/64 loss: -1.1868896484375
Batch 7/64 loss: -1.7180919647216797
Batch 8/64 loss: -1.4386234283447266
Batch 9/64 loss: -1.3469009399414062
Batch 10/64 loss: -1.6165275573730469
Batch 11/64 loss: -1.5964651107788086
Batch 12/64 loss: -1.5643548965454102
Batch 13/64 loss: -1.0828170776367188
Batch 14/64 loss: -1.5008392333984375
Batch 15/64 loss: -1.3060951232910156
Batch 16/64 loss: -1.4810500144958496
Batch 17/64 loss: -1.349599838256836
Batch 18/64 loss: -1.6508774757385254
Batch 19/64 loss: -1.389836311340332
Batch 20/64 loss: -1.3917016983032227
Batch 21/64 loss: -1.2284517288208008
Batch 22/64 loss: -1.589263916015625
Batch 23/64 loss: -1.2061405181884766
Batch 24/64 loss: -1.138829231262207
Batch 25/64 loss: -1.3714914321899414
Batch 26/64 loss: -1.6557483673095703
Batch 27/64 loss: -1.5969438552856445
Batch 28/64 loss: -1.5437583923339844
Batch 29/64 loss: -1.314509391784668
Batch 30/64 loss: -1.6913223266601562
Batch 31/64 loss: -1.358750343322754
Batch 32/64 loss: -1.1615829467773438
Batch 33/64 loss: -0.9850959777832031
Batch 34/64 loss: -0.9545364379882812
Batch 35/64 loss: -1.3551816940307617
Batch 36/64 loss: -1.563431739807129
Batch 37/64 loss: -1.3087701797485352
Batch 38/64 loss: -1.368729591369629
Batch 39/64 loss: -1.249619483947754
Batch 40/64 loss: -1.2909269332885742
Batch 41/64 loss: -1.0885848999023438
Batch 42/64 loss: -1.0084714889526367
Batch 43/64 loss: -1.0994081497192383
Batch 44/64 loss: -1.100473403930664
Batch 45/64 loss: -1.261713981628418
Batch 46/64 loss: -1.3559675216674805
Batch 47/64 loss: -1.147639274597168
Batch 48/64 loss: -1.393392562866211
Batch 49/64 loss: -1.3988304138183594
Batch 50/64 loss: -1.407876968383789
Batch 51/64 loss: -1.399435043334961
Batch 52/64 loss: -1.466604232788086
Batch 53/64 loss: -1.674494743347168
Batch 54/64 loss: -1.108572006225586
Batch 55/64 loss: -1.4343109130859375
Batch 56/64 loss: -1.718846321105957
Batch 57/64 loss: -1.199270248413086
Batch 58/64 loss: -1.5096216201782227
Batch 59/64 loss: -1.363133430480957
Batch 60/64 loss: -1.2129859924316406
Batch 61/64 loss: -1.4805841445922852
Batch 62/64 loss: -1.450826644897461
Batch 63/64 loss: -1.2443046569824219
Batch 64/64 loss: -5.669734001159668
Epoch 230  Train loss: -1.4311155543607823  Val loss: -1.57681295388343
Epoch 231
-------------------------------
Batch 1/64 loss: -1.8327550888061523
Batch 2/64 loss: -1.5701990127563477
Batch 3/64 loss: -1.4524097442626953
Batch 4/64 loss: -1.4997358322143555
Batch 5/64 loss: -1.601210594177246
Batch 6/64 loss: -1.5983924865722656
Batch 7/64 loss: -1.215611457824707
Batch 8/64 loss: -1.5101900100708008
Batch 9/64 loss: -1.4467964172363281
Batch 10/64 loss: -1.5054206848144531
Batch 11/64 loss: -1.6609668731689453
Batch 12/64 loss: -1.5757503509521484
Batch 13/64 loss: -1.5178375244140625
Batch 14/64 loss: -1.2167444229125977
Batch 15/64 loss: -1.4602956771850586
Batch 16/64 loss: -1.297943115234375
Batch 17/64 loss: -1.709991455078125
Batch 18/64 loss: -1.4753656387329102
Batch 19/64 loss: -1.6693296432495117
Batch 20/64 loss: -1.7988500595092773
Batch 21/64 loss: -0.9308710098266602
Batch 22/64 loss: -1.292384147644043
Batch 23/64 loss: -1.2324094772338867
Batch 24/64 loss: -1.653158187866211
Batch 25/64 loss: -1.393960952758789
Batch 26/64 loss: -1.6345329284667969
Batch 27/64 loss: -1.3933687210083008
Batch 28/64 loss: -1.586848258972168
Batch 29/64 loss: -1.470449447631836
Batch 30/64 loss: -1.0344200134277344
Batch 31/64 loss: -1.3422260284423828
Batch 32/64 loss: -1.805776596069336
Batch 33/64 loss: -1.3894062042236328
Batch 34/64 loss: -1.7246284484863281
Batch 35/64 loss: -1.5794010162353516
Batch 36/64 loss: -1.7644014358520508
Batch 37/64 loss: -1.3900890350341797
Batch 38/64 loss: -1.8278141021728516
Batch 39/64 loss: -1.760934829711914
Batch 40/64 loss: -1.7567291259765625
Batch 41/64 loss: -1.5863800048828125
Batch 42/64 loss: -1.2533950805664062
Batch 43/64 loss: -1.315659523010254
Batch 44/64 loss: -1.5902996063232422
Batch 45/64 loss: -1.4682035446166992
Batch 46/64 loss: -1.4595222473144531
Batch 47/64 loss: -1.3179855346679688
Batch 48/64 loss: -1.6740179061889648
Batch 49/64 loss: -1.409688949584961
Batch 50/64 loss: -0.6790199279785156
Batch 51/64 loss: -1.6462068557739258
Batch 52/64 loss: -1.8346729278564453
Batch 53/64 loss: -1.5994558334350586
Batch 54/64 loss: -1.6885433197021484
Batch 55/64 loss: -1.5093345642089844
Batch 56/64 loss: -1.5657033920288086
Batch 57/64 loss: -1.3172760009765625
Batch 58/64 loss: -1.3599023818969727
Batch 59/64 loss: -1.700357437133789
Batch 60/64 loss: -1.3350858688354492
Batch 61/64 loss: -1.7037134170532227
Batch 62/64 loss: -1.4159440994262695
Batch 63/64 loss: -1.1971893310546875
Batch 64/64 loss: -5.437032699584961
Epoch 231  Train loss: -1.5417245229085286  Val loss: -1.698389977523961
Epoch 232
-------------------------------
Batch 1/64 loss: -1.8282108306884766
Batch 2/64 loss: -0.9819526672363281
Batch 3/64 loss: -1.6334314346313477
Batch 4/64 loss: -1.5708036422729492
Batch 5/64 loss: -1.042266845703125
Batch 6/64 loss: -1.2012262344360352
Batch 7/64 loss: -1.2398433685302734
Batch 8/64 loss: -1.6471548080444336
Batch 9/64 loss: -1.864659309387207
Batch 10/64 loss: -1.4202470779418945
Batch 11/64 loss: -1.4491252899169922
Batch 12/64 loss: -1.4882888793945312
Batch 13/64 loss: -1.5909757614135742
Batch 14/64 loss: -1.3652057647705078
Batch 15/64 loss: -1.45550537109375
Batch 16/64 loss: -1.7859339714050293
Batch 17/64 loss: -1.6698589324951172
Batch 18/64 loss: -1.628392219543457
Batch 19/64 loss: -1.5743989944458008
Batch 20/64 loss: -1.5833492279052734
Batch 21/64 loss: -1.3217763900756836
Batch 22/64 loss: -1.7116479873657227
Batch 23/64 loss: -1.2253990173339844
Batch 24/64 loss: -1.445439338684082
Batch 25/64 loss: -1.4716863632202148
Batch 26/64 loss: -1.569462776184082
Batch 27/64 loss: -1.4770917892456055
Batch 28/64 loss: -1.6435213088989258
Batch 29/64 loss: -1.4679880142211914
Batch 30/64 loss: -1.1860570907592773
Batch 31/64 loss: -1.629389762878418
Batch 32/64 loss: -1.5988798141479492
Batch 33/64 loss: -1.146885871887207
Batch 34/64 loss: -1.6014080047607422
Batch 35/64 loss: -1.6166887283325195
Batch 36/64 loss: -1.5175199508666992
Batch 37/64 loss: -1.1117095947265625
Batch 38/64 loss: -1.5485153198242188
Batch 39/64 loss: -1.6683111190795898
Batch 40/64 loss: -1.5613651275634766
Batch 41/64 loss: -1.1482629776000977
Batch 42/64 loss: -1.7106218338012695
Batch 43/64 loss: -1.726125717163086
Batch 44/64 loss: -1.5162324905395508
Batch 45/64 loss: -1.6236686706542969
Batch 46/64 loss: -1.6452808380126953
Batch 47/64 loss: -1.7469120025634766
Batch 48/64 loss: -1.2225914001464844
Batch 49/64 loss: -1.5131721496582031
Batch 50/64 loss: -1.776261329650879
Batch 51/64 loss: -1.6305694580078125
Batch 52/64 loss: -1.836613655090332
Batch 53/64 loss: -1.6464815139770508
Batch 54/64 loss: -1.6383914947509766
Batch 55/64 loss: -1.6558685302734375
Batch 56/64 loss: -1.2227439880371094
Batch 57/64 loss: -1.4742059707641602
Batch 58/64 loss: -1.449188232421875
Batch 59/64 loss: -1.3273181915283203
Batch 60/64 loss: -1.5573348999023438
Batch 61/64 loss: -1.3079204559326172
Batch 62/64 loss: -1.690403938293457
Batch 63/64 loss: -1.7734556198120117
Batch 64/64 loss: -5.528186798095703
Epoch 232  Train loss: -1.5612131679759307  Val loss: -1.6040094906521827
Epoch 233
-------------------------------
Batch 1/64 loss: -1.6006879806518555
Batch 2/64 loss: -1.5816011428833008
Batch 3/64 loss: -1.4725866317749023
Batch 4/64 loss: -1.2927303314208984
Batch 5/64 loss: -1.6342334747314453
Batch 6/64 loss: -1.5527534484863281
Batch 7/64 loss: -1.263932228088379
Batch 8/64 loss: -1.3593997955322266
Batch 9/64 loss: -1.592921257019043
Batch 10/64 loss: -1.4722280502319336
Batch 11/64 loss: -1.5537047386169434
Batch 12/64 loss: -1.2677745819091797
Batch 13/64 loss: -1.3198928833007812
Batch 14/64 loss: -1.6732368469238281
Batch 15/64 loss: -1.5924758911132812
Batch 16/64 loss: -1.736246109008789
Batch 17/64 loss: -1.1334848403930664
Batch 18/64 loss: -1.8582658767700195
Batch 19/64 loss: -1.5842514038085938
Batch 20/64 loss: -1.8308954238891602
Batch 21/64 loss: -0.9378261566162109
Batch 22/64 loss: -1.5543441772460938
Batch 23/64 loss: -1.6571025848388672
Batch 24/64 loss: -1.4879426956176758
Batch 25/64 loss: -1.494333267211914
Batch 26/64 loss: -1.3354425430297852
Batch 27/64 loss: -1.2109746932983398
Batch 28/64 loss: -1.2461071014404297
Batch 29/64 loss: -1.1051063537597656
Batch 30/64 loss: -0.9499454498291016
Batch 31/64 loss: -1.6052513122558594
Batch 32/64 loss: -1.379861831665039
Batch 33/64 loss: -1.1003789901733398
Batch 34/64 loss: -1.8330779075622559
Batch 35/64 loss: -1.5999698638916016
Batch 36/64 loss: -1.6469011306762695
Batch 37/64 loss: -1.2683334350585938
Batch 38/64 loss: -1.2722387313842773
Batch 39/64 loss: -1.5340156555175781
Batch 40/64 loss: -1.4679641723632812
Batch 41/64 loss: -1.7813177108764648
Batch 42/64 loss: -1.2624387741088867
Batch 43/64 loss: -1.5549440383911133
Batch 44/64 loss: -1.7062902450561523
Batch 45/64 loss: -1.6759252548217773
Batch 46/64 loss: -1.3990378379821777
Batch 47/64 loss: -1.5395336151123047
Batch 48/64 loss: -1.7211012840270996
Batch 49/64 loss: -1.155548095703125
Batch 50/64 loss: -1.2046175003051758
Batch 51/64 loss: -1.0635852813720703
Batch 52/64 loss: -1.1334047317504883
Batch 53/64 loss: -1.418919563293457
Batch 54/64 loss: -1.771836280822754
Batch 55/64 loss: -1.3603954315185547
Batch 56/64 loss: -1.382948875427246
Batch 57/64 loss: -1.3700618743896484
Batch 58/64 loss: -1.7534465789794922
Batch 59/64 loss: -1.6672048568725586
Batch 60/64 loss: -1.5928592681884766
Batch 61/64 loss: -1.5952749252319336
Batch 62/64 loss: -1.4693307876586914
Batch 63/64 loss: -1.3402175903320312
Batch 64/64 loss: -5.716894626617432
Epoch 233  Train loss: -1.5100914880341174  Val loss: -1.6848927396269597
Epoch 234
-------------------------------
Batch 1/64 loss: -1.5367889404296875
Batch 2/64 loss: -0.9386863708496094
Batch 3/64 loss: -1.704279899597168
Batch 4/64 loss: -1.6384820938110352
Batch 5/64 loss: -1.5104589462280273
Batch 6/64 loss: -1.578786849975586
Batch 7/64 loss: -1.6763496398925781
Batch 8/64 loss: -1.499399185180664
Batch 9/64 loss: -1.422379493713379
Batch 10/64 loss: -1.620375633239746
Batch 11/64 loss: -1.5307483673095703
Batch 12/64 loss: -1.5257930755615234
Batch 13/64 loss: -1.5321245193481445
Batch 14/64 loss: -1.1996955871582031
Batch 15/64 loss: -1.430887222290039
Batch 16/64 loss: -1.774322509765625
Batch 17/64 loss: -1.6444568634033203
Batch 18/64 loss: -1.661982536315918
Batch 19/64 loss: -1.1264228820800781
Batch 20/64 loss: -1.774998664855957
Batch 21/64 loss: -1.5562419891357422
Batch 22/64 loss: -1.5521507263183594
Batch 23/64 loss: -1.5638675689697266
Batch 24/64 loss: -1.2714204788208008
Batch 25/64 loss: -1.3890266418457031
Batch 26/64 loss: -1.4822921752929688
Batch 27/64 loss: -1.4022636413574219
Batch 28/64 loss: -1.4702644348144531
Batch 29/64 loss: -1.744485855102539
Batch 30/64 loss: -1.830845832824707
Batch 31/64 loss: -1.176243782043457
Batch 32/64 loss: -1.461165428161621
Batch 33/64 loss: -1.283900260925293
Batch 34/64 loss: -1.3963861465454102
Batch 35/64 loss: -1.7174310684204102
Batch 36/64 loss: -1.5551252365112305
Batch 37/64 loss: -1.3066787719726562
Batch 38/64 loss: -1.542017936706543
Batch 39/64 loss: -1.206801414489746
Batch 40/64 loss: -1.4433469772338867
Batch 41/64 loss: -1.5773029327392578
Batch 42/64 loss: -1.6786108016967773
Batch 43/64 loss: -1.6549453735351562
Batch 44/64 loss: -1.7998199462890625
Batch 45/64 loss: -1.5784997940063477
Batch 46/64 loss: -1.3736438751220703
Batch 47/64 loss: -1.1884641647338867
Batch 48/64 loss: -1.542698860168457
Batch 49/64 loss: -1.4446659088134766
Batch 50/64 loss: -1.5555009841918945
Batch 51/64 loss: -1.3254585266113281
Batch 52/64 loss: -1.7568082809448242
Batch 53/64 loss: -1.4525108337402344
Batch 54/64 loss: -1.5418195724487305
Batch 55/64 loss: -1.7880277633666992
Batch 56/64 loss: -1.5709991455078125
Batch 57/64 loss: -1.5177850723266602
Batch 58/64 loss: -1.6476621627807617
Batch 59/64 loss: -1.3796415328979492
Batch 60/64 loss: -1.7791624069213867
Batch 61/64 loss: -1.1365585327148438
Batch 62/64 loss: -1.5099849700927734
Batch 63/64 loss: -1.383432388305664
Batch 64/64 loss: -5.939611911773682
Epoch 234  Train loss: -1.557930798624076  Val loss: -1.627568746350475
Epoch 235
-------------------------------
Batch 1/64 loss: -1.6771354675292969
Batch 2/64 loss: -1.8060026168823242
Batch 3/64 loss: -1.4362354278564453
Batch 4/64 loss: -1.5863990783691406
Batch 5/64 loss: -1.6870594024658203
Batch 6/64 loss: -1.870107650756836
Batch 7/64 loss: -1.691960334777832
Batch 8/64 loss: -1.5554332733154297
Batch 9/64 loss: -1.7327795028686523
Batch 10/64 loss: -0.9712867736816406
Batch 11/64 loss: -1.242807388305664
Batch 12/64 loss: -1.9533624649047852
Batch 13/64 loss: -1.7667598724365234
Batch 14/64 loss: -1.9101781845092773
Batch 15/64 loss: -1.4428167343139648
Batch 16/64 loss: -1.3430233001708984
Batch 17/64 loss: -1.4172239303588867
Batch 18/64 loss: -1.1825027465820312
Batch 19/64 loss: -1.4499883651733398
Batch 20/64 loss: -1.8194046020507812
Batch 21/64 loss: -1.6300487518310547
Batch 22/64 loss: -1.3677978515625
Batch 23/64 loss: -1.575124740600586
Batch 24/64 loss: -1.6898307800292969
Batch 25/64 loss: -1.5645866394042969
Batch 26/64 loss: -1.792759895324707
Batch 27/64 loss: -0.9651327133178711
Batch 28/64 loss: -0.9498481750488281
Batch 29/64 loss: -1.3392562866210938
Batch 30/64 loss: -1.5822019577026367
Batch 31/64 loss: -1.6105661392211914
Batch 32/64 loss: -1.120931625366211
Batch 33/64 loss: -1.4840755462646484
Batch 34/64 loss: -1.3814668655395508
Batch 35/64 loss: -1.5481586456298828
Batch 36/64 loss: -1.5737066268920898
Batch 37/64 loss: -1.4312934875488281
Batch 38/64 loss: -1.3569927215576172
Batch 39/64 loss: -1.6956052780151367
Batch 40/64 loss: -1.4053430557250977
Batch 41/64 loss: -1.6447858810424805
Batch 42/64 loss: -1.7300310134887695
Batch 43/64 loss: -1.3991546630859375
Batch 44/64 loss: -1.613795280456543
Batch 45/64 loss: -1.3783807754516602
Batch 46/64 loss: -1.278092384338379
Batch 47/64 loss: -1.196619987487793
Batch 48/64 loss: -1.3901262283325195
Batch 49/64 loss: -1.6943511962890625
Batch 50/64 loss: -1.432755470275879
Batch 51/64 loss: -0.907099723815918
Batch 52/64 loss: -1.328810691833496
Batch 53/64 loss: -1.1757535934448242
Batch 54/64 loss: -1.327402114868164
Batch 55/64 loss: -1.182504653930664
Batch 56/64 loss: -0.8874998092651367
Batch 57/64 loss: -1.4069910049438477
Batch 58/64 loss: -1.673386573791504
Batch 59/64 loss: -1.386763572692871
Batch 60/64 loss: -1.412388801574707
Batch 61/64 loss: -1.3497371673583984
Batch 62/64 loss: -1.2999095916748047
Batch 63/64 loss: -1.213460922241211
Batch 64/64 loss: -5.6745076179504395
Epoch 235  Train loss: -1.508594144559374  Val loss: -1.3806291167269047
Epoch 236
-------------------------------
Batch 1/64 loss: -1.0684537887573242
Batch 2/64 loss: -1.1881036758422852
Batch 3/64 loss: -1.517496109008789
Batch 4/64 loss: -1.4423255920410156
Batch 5/64 loss: -1.4344196319580078
Batch 6/64 loss: -1.360818862915039
Batch 7/64 loss: -1.2879228591918945
Batch 8/64 loss: -1.3204774856567383
Batch 9/64 loss: -1.545492172241211
Batch 10/64 loss: -0.8684310913085938
Batch 11/64 loss: -1.4281177520751953
Batch 12/64 loss: -1.5773115158081055
Batch 13/64 loss: -1.6938295364379883
Batch 14/64 loss: -1.517618179321289
Batch 15/64 loss: -1.6966238021850586
Batch 16/64 loss: -1.1443376541137695
Batch 17/64 loss: -1.5915336608886719
Batch 18/64 loss: -1.6112489700317383
Batch 19/64 loss: -1.578169822692871
Batch 20/64 loss: -1.5930967330932617
Batch 21/64 loss: -0.9405403137207031
Batch 22/64 loss: -1.0028247833251953
Batch 23/64 loss: -1.5611648559570312
Batch 24/64 loss: -1.643014907836914
Batch 25/64 loss: -1.552811622619629
Batch 26/64 loss: -1.4403972625732422
Batch 27/64 loss: -1.4505558013916016
Batch 28/64 loss: -1.2963361740112305
Batch 29/64 loss: -1.430729866027832
Batch 30/64 loss: -1.2588386535644531
Batch 31/64 loss: -1.4528589248657227
Batch 32/64 loss: -1.702193260192871
Batch 33/64 loss: -1.8263959884643555
Batch 34/64 loss: -1.1721162796020508
Batch 35/64 loss: -1.4707088470458984
Batch 36/64 loss: -1.0573997497558594
Batch 37/64 loss: -1.5924949645996094
Batch 38/64 loss: -1.2456693649291992
Batch 39/64 loss: -1.421976089477539
Batch 40/64 loss: -1.7325868606567383
Batch 41/64 loss: -1.1260805130004883
Batch 42/64 loss: -1.2733755111694336
Batch 43/64 loss: -1.4588041305541992
Batch 44/64 loss: -1.583174705505371
Batch 45/64 loss: -1.3711633682250977
Batch 46/64 loss: -1.4613828659057617
Batch 47/64 loss: -1.7618799209594727
Batch 48/64 loss: -1.109990119934082
Batch 49/64 loss: -0.7516155242919922
Batch 50/64 loss: -1.9198827743530273
Batch 51/64 loss: -1.687525749206543
Batch 52/64 loss: -1.710362434387207
Batch 53/64 loss: -1.4204063415527344
Batch 54/64 loss: -1.6145458221435547
Batch 55/64 loss: -1.3787174224853516
Batch 56/64 loss: -1.5624608993530273
Batch 57/64 loss: -1.7127742767333984
Batch 58/64 loss: -1.4759788513183594
Batch 59/64 loss: -1.809399127960205
Batch 60/64 loss: -1.2926149368286133
Batch 61/64 loss: -1.564828872680664
Batch 62/64 loss: -1.3824396133422852
Batch 63/64 loss: -1.2401809692382812
Batch 64/64 loss: -5.747587203979492
Epoch 236  Train loss: -1.4854544097302007  Val loss: -1.7911563230953675
Saving best model, epoch: 236
Epoch 237
-------------------------------
Batch 1/64 loss: -1.4915437698364258
Batch 2/64 loss: -1.2657222747802734
Batch 3/64 loss: -1.5845088958740234
Batch 4/64 loss: -1.5801830291748047
Batch 5/64 loss: -1.5829458236694336
Batch 6/64 loss: -1.6820306777954102
Batch 7/64 loss: -1.8615646362304688
Batch 8/64 loss: -1.7164726257324219
Batch 9/64 loss: -1.2433099746704102
Batch 10/64 loss: -1.114633560180664
Batch 11/64 loss: -1.7629308700561523
Batch 12/64 loss: -1.506373405456543
Batch 13/64 loss: -1.0934085845947266
Batch 14/64 loss: -1.257232666015625
Batch 15/64 loss: -1.5580644607543945
Batch 16/64 loss: -1.1897039413452148
Batch 17/64 loss: -1.4944572448730469
Batch 18/64 loss: -1.797067642211914
Batch 19/64 loss: -1.6315374374389648
Batch 20/64 loss: -1.3952722549438477
Batch 21/64 loss: -1.5427732467651367
Batch 22/64 loss: -1.8459043502807617
Batch 23/64 loss: -1.7470579147338867
Batch 24/64 loss: -1.7739181518554688
Batch 25/64 loss: -1.5846891403198242
Batch 26/64 loss: -1.2549362182617188
Batch 27/64 loss: -1.3711776733398438
Batch 28/64 loss: -1.521561622619629
Batch 29/64 loss: -0.696162223815918
Batch 30/64 loss: -1.5347175598144531
Batch 31/64 loss: -1.4671220779418945
Batch 32/64 loss: -1.350717544555664
Batch 33/64 loss: -1.3629732131958008
Batch 34/64 loss: -1.1867504119873047
Batch 35/64 loss: -1.3469257354736328
Batch 36/64 loss: -1.3904285430908203
Batch 37/64 loss: -1.825638771057129
Batch 38/64 loss: -1.383406639099121
Batch 39/64 loss: -1.5552444458007812
Batch 40/64 loss: -1.2184181213378906
Batch 41/64 loss: -1.6072196960449219
Batch 42/64 loss: -1.6954364776611328
Batch 43/64 loss: -1.2863445281982422
Batch 44/64 loss: -1.2584257125854492
Batch 45/64 loss: -1.6666326522827148
Batch 46/64 loss: -1.4325294494628906
Batch 47/64 loss: -1.7636489868164062
Batch 48/64 loss: -1.5346498489379883
Batch 49/64 loss: -1.6442079544067383
Batch 50/64 loss: -1.6787214279174805
Batch 51/64 loss: -1.494436264038086
Batch 52/64 loss: -1.4777088165283203
Batch 53/64 loss: -1.5469989776611328
Batch 54/64 loss: -1.6168832778930664
Batch 55/64 loss: -1.4985570907592773
Batch 56/64 loss: -1.175278663635254
Batch 57/64 loss: -1.4483747482299805
Batch 58/64 loss: -1.7018260955810547
Batch 59/64 loss: -1.556070327758789
Batch 60/64 loss: -1.5726346969604492
Batch 61/64 loss: -1.1758670806884766
Batch 62/64 loss: -1.7499618530273438
Batch 63/64 loss: -1.6294498443603516
Batch 64/64 loss: -5.4893012046813965
Epoch 237  Train loss: -1.5387972981322044  Val loss: -1.7690793984534405
Epoch 238
-------------------------------
Batch 1/64 loss: -1.24017333984375
Batch 2/64 loss: -1.6362295150756836
Batch 3/64 loss: -1.3646049499511719
Batch 4/64 loss: -1.2933635711669922
Batch 5/64 loss: -1.4806604385375977
Batch 6/64 loss: -1.788996696472168
Batch 7/64 loss: -1.434493064880371
Batch 8/64 loss: -0.8964929580688477
Batch 9/64 loss: -1.5119943618774414
Batch 10/64 loss: -1.4757604598999023
Batch 11/64 loss: -1.685917854309082
Batch 12/64 loss: -1.3452606201171875
Batch 13/64 loss: -1.7832012176513672
Batch 14/64 loss: -1.733475685119629
Batch 15/64 loss: -1.6343421936035156
Batch 16/64 loss: -1.270711898803711
Batch 17/64 loss: -1.4355964660644531
Batch 18/64 loss: -1.736771583557129
Batch 19/64 loss: -1.9734439849853516
Batch 20/64 loss: -1.4645452499389648
Batch 21/64 loss: -0.40439510345458984
Batch 22/64 loss: -1.7477331161499023
Batch 23/64 loss: -1.5133352279663086
Batch 24/64 loss: -1.6542730331420898
Batch 25/64 loss: -1.8137941360473633
Batch 26/64 loss: -1.3422212600708008
Batch 27/64 loss: -1.5429267883300781
Batch 28/64 loss: -1.5707893371582031
Batch 29/64 loss: -1.8049993515014648
Batch 30/64 loss: -1.681112289428711
Batch 31/64 loss: -1.570082664489746
Batch 32/64 loss: -1.7214584350585938
Batch 33/64 loss: -1.1020336151123047
Batch 34/64 loss: -1.570413589477539
Batch 35/64 loss: -1.471247673034668
Batch 36/64 loss: -1.467482566833496
Batch 37/64 loss: -1.5231876373291016
Batch 38/64 loss: -1.8532285690307617
Batch 39/64 loss: -1.5948352813720703
Batch 40/64 loss: -1.7763996124267578
Batch 41/64 loss: -1.6542673110961914
Batch 42/64 loss: -1.4127779006958008
Batch 43/64 loss: -1.4823598861694336
Batch 44/64 loss: -1.672119140625
Batch 45/64 loss: -1.5060548782348633
Batch 46/64 loss: -1.399728775024414
Batch 47/64 loss: -1.4533634185791016
Batch 48/64 loss: -1.5290374755859375
Batch 49/64 loss: -1.6475543975830078
Batch 50/64 loss: -1.7654924392700195
Batch 51/64 loss: -1.9126653671264648
Batch 52/64 loss: -1.6170077323913574
Batch 53/64 loss: -0.5854759216308594
Batch 54/64 loss: -1.468698501586914
Batch 55/64 loss: -1.4280672073364258
Batch 56/64 loss: -1.995361328125
Batch 57/64 loss: -1.682387351989746
Batch 58/64 loss: -1.3347177505493164
Batch 59/64 loss: -1.6607351303100586
Batch 60/64 loss: -1.580246925354004
Batch 61/64 loss: -1.7752742767333984
Batch 62/64 loss: -1.3070526123046875
Batch 63/64 loss: -1.4827890396118164
Batch 64/64 loss: -5.760916233062744
Epoch 238  Train loss: -1.5778181543537215  Val loss: -1.7119508068176479
Epoch 239
-------------------------------
Batch 1/64 loss: -1.4030075073242188
Batch 2/64 loss: -1.422877311706543
Batch 3/64 loss: -1.902318000793457
Batch 4/64 loss: -1.806711196899414
Batch 5/64 loss: -1.525120735168457
Batch 6/64 loss: -1.5636072158813477
Batch 7/64 loss: -1.5629053115844727
Batch 8/64 loss: -1.672379493713379
Batch 9/64 loss: -1.4659767150878906
Batch 10/64 loss: -1.2743606567382812
Batch 11/64 loss: -1.674107551574707
Batch 12/64 loss: -1.666696548461914
Batch 13/64 loss: -1.743098258972168
Batch 14/64 loss: -1.4163627624511719
Batch 15/64 loss: -1.47900390625
Batch 16/64 loss: -1.3915519714355469
Batch 17/64 loss: -1.2151985168457031
Batch 18/64 loss: -1.322402000427246
Batch 19/64 loss: -1.6318702697753906
Batch 20/64 loss: -1.590383529663086
Batch 21/64 loss: -1.5704517364501953
Batch 22/64 loss: -1.3812885284423828
Batch 23/64 loss: -1.6842708587646484
Batch 24/64 loss: -1.6103487014770508
Batch 25/64 loss: -1.6575145721435547
Batch 26/64 loss: -1.4733028411865234
Batch 27/64 loss: -1.7306489944458008
Batch 28/64 loss: -1.6472043991088867
Batch 29/64 loss: -1.59033203125
Batch 30/64 loss: -1.6227970123291016
Batch 31/64 loss: -1.7466773986816406
Batch 32/64 loss: -1.3895578384399414
Batch 33/64 loss: -1.420135498046875
Batch 34/64 loss: -1.5105924606323242
Batch 35/64 loss: -1.4762372970581055
Batch 36/64 loss: -1.594161033630371
Batch 37/64 loss: -1.6707048416137695
Batch 38/64 loss: -1.6892871856689453
Batch 39/64 loss: -1.6187810897827148
Batch 40/64 loss: -1.286026954650879
Batch 41/64 loss: -1.4772701263427734
Batch 42/64 loss: -0.9649124145507812
Batch 43/64 loss: -1.3751001358032227
Batch 44/64 loss: -1.4073572158813477
Batch 45/64 loss: -1.4922590255737305
Batch 46/64 loss: -1.595545768737793
Batch 47/64 loss: -1.3402938842773438
Batch 48/64 loss: -1.4740886688232422
Batch 49/64 loss: -1.5947074890136719
Batch 50/64 loss: -1.386368751525879
Batch 51/64 loss: -1.5615167617797852
Batch 52/64 loss: -1.6076898574829102
Batch 53/64 loss: -1.952394962310791
Batch 54/64 loss: -1.6312198638916016
Batch 55/64 loss: -1.6437454223632812
Batch 56/64 loss: -1.3711881637573242
Batch 57/64 loss: -1.7447071075439453
Batch 58/64 loss: -1.4720230102539062
Batch 59/64 loss: -1.436746597290039
Batch 60/64 loss: -1.2994279861450195
Batch 61/64 loss: -1.7861738204956055
Batch 62/64 loss: -1.434610366821289
Batch 63/64 loss: -1.2259340286254883
Batch 64/64 loss: -5.511230945587158
Epoch 239  Train loss: -1.5766112215378705  Val loss: -1.6543576348688185
Epoch 240
-------------------------------
Batch 1/64 loss: -1.547947883605957
Batch 2/64 loss: -1.3606128692626953
Batch 3/64 loss: -1.2948484420776367
Batch 4/64 loss: -1.7703437805175781
Batch 5/64 loss: -1.5198860168457031
Batch 6/64 loss: -1.7785568237304688
Batch 7/64 loss: -1.6149883270263672
Batch 8/64 loss: -1.3501930236816406
Batch 9/64 loss: -1.5356388092041016
Batch 10/64 loss: -1.3862743377685547
Batch 11/64 loss: -1.5342340469360352
Batch 12/64 loss: -1.4799795150756836
Batch 13/64 loss: -1.5375642776489258
Batch 14/64 loss: -1.4752626419067383
Batch 15/64 loss: -1.7407197952270508
Batch 16/64 loss: -1.4757404327392578
Batch 17/64 loss: -1.3957223892211914
Batch 18/64 loss: -1.508382797241211
Batch 19/64 loss: -1.6115045547485352
Batch 20/64 loss: -1.499176025390625
Batch 21/64 loss: -1.385213851928711
Batch 22/64 loss: -1.4872722625732422
Batch 23/64 loss: -1.7517356872558594
Batch 24/64 loss: -1.5685882568359375
Batch 25/64 loss: -0.9129762649536133
Batch 26/64 loss: -1.2949638366699219
Batch 27/64 loss: -1.4913597106933594
Batch 28/64 loss: -1.3648719787597656
Batch 29/64 loss: -1.597381591796875
Batch 30/64 loss: -1.4480791091918945
Batch 31/64 loss: -1.56201171875
Batch 32/64 loss: -1.493906021118164
Batch 33/64 loss: -1.3650531768798828
Batch 34/64 loss: -1.3951330184936523
Batch 35/64 loss: -1.4808349609375
Batch 36/64 loss: -1.198446273803711
Batch 37/64 loss: -1.4903392791748047
Batch 38/64 loss: -1.2832374572753906
Batch 39/64 loss: -0.8628835678100586
Batch 40/64 loss: -1.5872430801391602
Batch 41/64 loss: -1.3505058288574219
Batch 42/64 loss: -1.7094488143920898
Batch 43/64 loss: -1.172372817993164
Batch 44/64 loss: -1.3694677352905273
Batch 45/64 loss: -1.5604496002197266
Batch 46/64 loss: -1.752685546875
Batch 47/64 loss: -1.5786962509155273
Batch 48/64 loss: -1.7009515762329102
Batch 49/64 loss: -1.6006746292114258
Batch 50/64 loss: -1.5702810287475586
Batch 51/64 loss: -1.567612648010254
Batch 52/64 loss: -1.411198616027832
Batch 53/64 loss: -1.5358963012695312
Batch 54/64 loss: -1.2335376739501953
Batch 55/64 loss: -1.3906621932983398
Batch 56/64 loss: -1.5556068420410156
Batch 57/64 loss: -1.472559928894043
Batch 58/64 loss: -1.4021635055541992
Batch 59/64 loss: -1.3966875076293945
Batch 60/64 loss: -1.429880142211914
Batch 61/64 loss: -1.503641128540039
Batch 62/64 loss: -1.5452585220336914
Batch 63/64 loss: -1.7048168182373047
Batch 64/64 loss: -5.5619096755981445
Epoch 240  Train loss: -1.5235387577730066  Val loss: -1.745578569235261
Epoch 241
-------------------------------
Batch 1/64 loss: -1.4539775848388672
Batch 2/64 loss: -1.1546430587768555
Batch 3/64 loss: -1.7520246505737305
Batch 4/64 loss: -1.6004447937011719
Batch 5/64 loss: -1.5115652084350586
Batch 6/64 loss: -1.5845451354980469
Batch 7/64 loss: -1.483475685119629
Batch 8/64 loss: -1.8309526443481445
Batch 9/64 loss: -1.488189697265625
Batch 10/64 loss: -1.668879508972168
Batch 11/64 loss: -0.9014558792114258
Batch 12/64 loss: -1.129511833190918
Batch 13/64 loss: -1.4237937927246094
Batch 14/64 loss: -1.6886210441589355
Batch 15/64 loss: -1.4996309280395508
Batch 16/64 loss: -1.7775239944458008
Batch 17/64 loss: -1.7460079193115234
Batch 18/64 loss: -1.657994270324707
Batch 19/64 loss: -1.5145020484924316
Batch 20/64 loss: -1.5115089416503906
Batch 21/64 loss: -1.5298986434936523
Batch 22/64 loss: -1.5821361541748047
Batch 23/64 loss: -1.7126007080078125
Batch 24/64 loss: -1.6947622299194336
Batch 25/64 loss: -1.7453479766845703
Batch 26/64 loss: -1.3594398498535156
Batch 27/64 loss: -1.439253807067871
Batch 28/64 loss: -1.3507575988769531
Batch 29/64 loss: -1.5625505447387695
Batch 30/64 loss: -1.6027650833129883
Batch 31/64 loss: -1.5806045532226562
Batch 32/64 loss: -1.580122947692871
Batch 33/64 loss: -1.701615333557129
Batch 34/64 loss: -1.0380439758300781
Batch 35/64 loss: -1.5339841842651367
Batch 36/64 loss: -1.189443588256836
Batch 37/64 loss: -1.7166147232055664
Batch 38/64 loss: -1.4716014862060547
Batch 39/64 loss: -1.4126768112182617
Batch 40/64 loss: -1.360428810119629
Batch 41/64 loss: -1.6313819885253906
Batch 42/64 loss: -1.5118045806884766
Batch 43/64 loss: -1.5654449462890625
Batch 44/64 loss: -1.6142873764038086
Batch 45/64 loss: -1.288691520690918
Batch 46/64 loss: -1.4980192184448242
Batch 47/64 loss: -1.7242517471313477
Batch 48/64 loss: -1.4610347747802734
Batch 49/64 loss: -1.480607032775879
Batch 50/64 loss: -1.4040088653564453
Batch 51/64 loss: -1.6990947723388672
Batch 52/64 loss: -1.5133638381958008
Batch 53/64 loss: -1.6319293975830078
Batch 54/64 loss: -1.305058479309082
Batch 55/64 loss: -1.275029182434082
Batch 56/64 loss: -1.6347694396972656
Batch 57/64 loss: -1.4755477905273438
Batch 58/64 loss: -1.2771196365356445
Batch 59/64 loss: -1.473099708557129
Batch 60/64 loss: -1.5446157455444336
Batch 61/64 loss: -1.1070489883422852
Batch 62/64 loss: -0.8114414215087891
Batch 63/64 loss: -1.536768913269043
Batch 64/64 loss: -5.1818695068359375
Epoch 241  Train loss: -1.535603437236711  Val loss: -1.6695639620122222
Epoch 242
-------------------------------
Batch 1/64 loss: -1.5958304405212402
Batch 2/64 loss: -1.5553169250488281
Batch 3/64 loss: -1.4719305038452148
Batch 4/64 loss: -1.747746467590332
Batch 5/64 loss: -1.5990924835205078
Batch 6/64 loss: -1.4641523361206055
Batch 7/64 loss: -1.658884048461914
Batch 8/64 loss: -1.6910037994384766
Batch 9/64 loss: -1.3336420059204102
Batch 10/64 loss: -1.1675119400024414
Batch 11/64 loss: -1.198801040649414
Batch 12/64 loss: -1.3110227584838867
Batch 13/64 loss: -1.813356876373291
Batch 14/64 loss: -1.8405447006225586
Batch 15/64 loss: -1.3128128051757812
Batch 16/64 loss: -1.0654296875
Batch 17/64 loss: -1.603668212890625
Batch 18/64 loss: -1.5279216766357422
Batch 19/64 loss: -1.7497339248657227
Batch 20/64 loss: -1.6102190017700195
Batch 21/64 loss: -1.318770408630371
Batch 22/64 loss: -1.595306396484375
Batch 23/64 loss: -1.6102066040039062
Batch 24/64 loss: -1.801243782043457
Batch 25/64 loss: -1.7060766220092773
Batch 26/64 loss: -1.214125633239746
Batch 27/64 loss: -1.464116096496582
Batch 28/64 loss: -1.528543472290039
Batch 29/64 loss: -1.6429052352905273
Batch 30/64 loss: -1.475667953491211
Batch 31/64 loss: -1.7449970245361328
Batch 32/64 loss: -1.5001211166381836
Batch 33/64 loss: -1.4017133712768555
Batch 34/64 loss: -1.560511589050293
Batch 35/64 loss: -1.4333124160766602
Batch 36/64 loss: -1.7285199165344238
Batch 37/64 loss: -1.208846092224121
Batch 38/64 loss: -1.6706857681274414
Batch 39/64 loss: -1.8662805557250977
Batch 40/64 loss: -1.216634750366211
Batch 41/64 loss: -1.805710792541504
Batch 42/64 loss: -1.388310432434082
Batch 43/64 loss: -1.5716333389282227
Batch 44/64 loss: -1.6164436340332031
Batch 45/64 loss: -1.650843620300293
Batch 46/64 loss: -1.5966205596923828
Batch 47/64 loss: -1.8459811210632324
Batch 48/64 loss: -1.7868375778198242
Batch 49/64 loss: -1.092081069946289
Batch 50/64 loss: -1.7560153007507324
Batch 51/64 loss: -1.3508729934692383
Batch 52/64 loss: -1.5365066528320312
Batch 53/64 loss: -1.343174934387207
Batch 54/64 loss: -1.5145597457885742
Batch 55/64 loss: -1.3996353149414062
Batch 56/64 loss: -1.7663888931274414
Batch 57/64 loss: -1.4701595306396484
Batch 58/64 loss: -0.570587158203125
Batch 59/64 loss: -1.2260408401489258
Batch 60/64 loss: -1.6138486862182617
Batch 61/64 loss: -1.3634281158447266
Batch 62/64 loss: -1.2649250030517578
Batch 63/64 loss: -1.420548439025879
Batch 64/64 loss: -5.585991859436035
Epoch 242  Train loss: -1.555260456309599  Val loss: -1.5894412404483127
Epoch 243
-------------------------------
Batch 1/64 loss: -1.4366064071655273
Batch 2/64 loss: -1.1589202880859375
Batch 3/64 loss: -1.594437599182129
Batch 4/64 loss: -1.7038803100585938
Batch 5/64 loss: -1.6539897918701172
Batch 6/64 loss: -1.3406171798706055
Batch 7/64 loss: -1.5687370300292969
Batch 8/64 loss: -1.2269439697265625
Batch 9/64 loss: -1.510817527770996
Batch 10/64 loss: -1.5928926467895508
Batch 11/64 loss: -1.725473403930664
Batch 12/64 loss: -1.7458295822143555
Batch 13/64 loss: -1.5362720489501953
Batch 14/64 loss: -1.8323774337768555
Batch 15/64 loss: -1.4025764465332031
Batch 16/64 loss: -1.697519302368164
Batch 17/64 loss: -1.0736417770385742
Batch 18/64 loss: -1.1978435516357422
Batch 19/64 loss: -0.9993991851806641
Batch 20/64 loss: -1.4316434860229492
Batch 21/64 loss: -1.767075538635254
Batch 22/64 loss: -1.5797500610351562
Batch 23/64 loss: -1.3290777206420898
Batch 24/64 loss: -1.5921783447265625
Batch 25/64 loss: -1.8573904037475586
Batch 26/64 loss: -1.512558937072754
Batch 27/64 loss: -1.108102798461914
Batch 28/64 loss: -1.552938461303711
Batch 29/64 loss: -1.4306707382202148
Batch 30/64 loss: -1.622903823852539
Batch 31/64 loss: -1.5888481140136719
Batch 32/64 loss: -1.552109718322754
Batch 33/64 loss: -1.426194190979004
Batch 34/64 loss: -1.3554468154907227
Batch 35/64 loss: -1.3740663528442383
Batch 36/64 loss: -1.398036003112793
Batch 37/64 loss: -1.6150836944580078
Batch 38/64 loss: -1.6567039489746094
Batch 39/64 loss: -1.4055185317993164
Batch 40/64 loss: -1.765620231628418
Batch 41/64 loss: -1.78651762008667
Batch 42/64 loss: -1.0372447967529297
Batch 43/64 loss: -1.5762763023376465
Batch 44/64 loss: -1.8067035675048828
Batch 45/64 loss: -1.951108455657959
Batch 46/64 loss: -1.7108993530273438
Batch 47/64 loss: -1.3639516830444336
Batch 48/64 loss: -1.6498384475708008
Batch 49/64 loss: -1.6261100769042969
Batch 50/64 loss: -1.5305585861206055
Batch 51/64 loss: -1.3727102279663086
Batch 52/64 loss: -1.2303342819213867
Batch 53/64 loss: -1.6761283874511719
Batch 54/64 loss: -1.2207612991333008
Batch 55/64 loss: -1.1132307052612305
Batch 56/64 loss: -1.585540771484375
Batch 57/64 loss: -1.7187585830688477
Batch 58/64 loss: -1.8215904235839844
Batch 59/64 loss: -1.700439453125
Batch 60/64 loss: -1.7569684982299805
Batch 61/64 loss: -1.5081520080566406
Batch 62/64 loss: -1.6852140426635742
Batch 63/64 loss: -1.1248455047607422
Batch 64/64 loss: -5.784119606018066
Epoch 243  Train loss: -1.5656888812196021  Val loss: -1.7774749441245168
Epoch 244
-------------------------------
Batch 1/64 loss: -1.5383195877075195
Batch 2/64 loss: -1.4377756118774414
Batch 3/64 loss: -1.645554542541504
Batch 4/64 loss: -1.4105043411254883
Batch 5/64 loss: -1.709939956665039
Batch 6/64 loss: -1.5129961967468262
Batch 7/64 loss: -1.7004947662353516
Batch 8/64 loss: -1.4853553771972656
Batch 9/64 loss: -1.1702232360839844
Batch 10/64 loss: -1.6243896484375
Batch 11/64 loss: -1.3827886581420898
Batch 12/64 loss: -1.3972711563110352
Batch 13/64 loss: -1.4579553604125977
Batch 14/64 loss: -1.5969228744506836
Batch 15/64 loss: -1.4550743103027344
Batch 16/64 loss: -1.5534591674804688
Batch 17/64 loss: -1.7758798599243164
Batch 18/64 loss: -1.5079231262207031
Batch 19/64 loss: -1.5340795516967773
Batch 20/64 loss: -1.6739349365234375
Batch 21/64 loss: -1.6324825286865234
Batch 22/64 loss: -1.2620391845703125
Batch 23/64 loss: -1.343423843383789
Batch 24/64 loss: -1.5880565643310547
Batch 25/64 loss: -1.6630277633666992
Batch 26/64 loss: -1.3212404251098633
Batch 27/64 loss: -1.4973535537719727
Batch 28/64 loss: -1.7757978439331055
Batch 29/64 loss: -1.5521430969238281
Batch 30/64 loss: -1.7806835174560547
Batch 31/64 loss: -1.6307754516601562
Batch 32/64 loss: -1.5347661972045898
Batch 33/64 loss: -1.3770971298217773
Batch 34/64 loss: -1.8382930755615234
Batch 35/64 loss: -1.507101058959961
Batch 36/64 loss: -1.633772850036621
Batch 37/64 loss: -1.116765022277832
Batch 38/64 loss: -1.4910001754760742
Batch 39/64 loss: -1.6912860870361328
Batch 40/64 loss: -1.6849479675292969
Batch 41/64 loss: -1.4454984664916992
Batch 42/64 loss: -1.716628074645996
Batch 43/64 loss: -1.2345619201660156
Batch 44/64 loss: -1.6731462478637695
Batch 45/64 loss: -1.6448945999145508
Batch 46/64 loss: -1.3033027648925781
Batch 47/64 loss: -1.5076026916503906
Batch 48/64 loss: -1.7876787185668945
Batch 49/64 loss: -1.5059986114501953
Batch 50/64 loss: -1.4818439483642578
Batch 51/64 loss: -0.8936872482299805
Batch 52/64 loss: -1.6252756118774414
Batch 53/64 loss: -1.8298053741455078
Batch 54/64 loss: -1.1846513748168945
Batch 55/64 loss: -1.428410530090332
Batch 56/64 loss: -1.321873664855957
Batch 57/64 loss: -1.6787261962890625
Batch 58/64 loss: -1.590407371520996
Batch 59/64 loss: -1.4849929809570312
Batch 60/64 loss: -1.5351591110229492
Batch 61/64 loss: -1.2488384246826172
Batch 62/64 loss: -1.4073362350463867
Batch 63/64 loss: -1.2713117599487305
Batch 64/64 loss: -5.725658416748047
Epoch 244  Train loss: -1.5621768053840188  Val loss: -1.7209266190676344
Epoch 245
-------------------------------
Batch 1/64 loss: -1.7019481658935547
Batch 2/64 loss: -1.6880903244018555
Batch 3/64 loss: -1.9638543128967285
Batch 4/64 loss: -1.4356346130371094
Batch 5/64 loss: -1.7532539367675781
Batch 6/64 loss: -1.539137840270996
Batch 7/64 loss: -1.3929471969604492
Batch 8/64 loss: -1.4682340621948242
Batch 9/64 loss: -1.0400009155273438
Batch 10/64 loss: -1.5194807052612305
Batch 11/64 loss: -1.673232078552246
Batch 12/64 loss: -1.6380748748779297
Batch 13/64 loss: -1.4782819747924805
Batch 14/64 loss: -1.4060583114624023
Batch 15/64 loss: -1.5631608963012695
Batch 16/64 loss: -1.836522102355957
Batch 17/64 loss: -1.422576904296875
Batch 18/64 loss: -1.4821033477783203
Batch 19/64 loss: -1.510519027709961
Batch 20/64 loss: -1.2414321899414062
Batch 21/64 loss: -1.5964221954345703
Batch 22/64 loss: -1.382441520690918
Batch 23/64 loss: -1.3960485458374023
Batch 24/64 loss: -1.518625259399414
Batch 25/64 loss: -1.1254386901855469
Batch 26/64 loss: -1.5076255798339844
Batch 27/64 loss: -1.592228889465332
Batch 28/64 loss: -1.5843706130981445
Batch 29/64 loss: -1.5510711669921875
Batch 30/64 loss: -1.3578052520751953
Batch 31/64 loss: -1.4013147354125977
Batch 32/64 loss: -1.6682977676391602
Batch 33/64 loss: -1.3356332778930664
Batch 34/64 loss: -1.501835823059082
Batch 35/64 loss: -1.4865684509277344
Batch 36/64 loss: -1.4165058135986328
Batch 37/64 loss: -1.5835857391357422
Batch 38/64 loss: -1.5820484161376953
Batch 39/64 loss: -1.4341888427734375
Batch 40/64 loss: -1.490743637084961
Batch 41/64 loss: -1.8568305969238281
Batch 42/64 loss: -1.5960988998413086
Batch 43/64 loss: -1.6933622360229492
Batch 44/64 loss: -1.5654878616333008
Batch 45/64 loss: -1.5578575134277344
Batch 46/64 loss: -1.5117511749267578
Batch 47/64 loss: -1.0797996520996094
Batch 48/64 loss: -1.3385810852050781
Batch 49/64 loss: -1.5079727172851562
Batch 50/64 loss: -1.3359432220458984
Batch 51/64 loss: -1.4911975860595703
Batch 52/64 loss: -1.5756587982177734
Batch 53/64 loss: -1.5253324508666992
Batch 54/64 loss: -1.736241340637207
Batch 55/64 loss: -1.71429443359375
Batch 56/64 loss: -1.5960607528686523
Batch 57/64 loss: -1.6613044738769531
Batch 58/64 loss: -1.5619583129882812
Batch 59/64 loss: -1.3550872802734375
Batch 60/64 loss: -1.5760321617126465
Batch 61/64 loss: -1.7932252883911133
Batch 62/64 loss: -1.357661247253418
Batch 63/64 loss: -1.2761783599853516
Batch 64/64 loss: -5.70503044128418
Epoch 245  Train loss: -1.5656475964714498  Val loss: -1.699967086110328
Epoch 246
-------------------------------
Batch 1/64 loss: -1.2717103958129883
Batch 2/64 loss: -1.616373062133789
Batch 3/64 loss: -1.20806884765625
Batch 4/64 loss: -1.5909271240234375
Batch 5/64 loss: -1.8391809463500977
Batch 6/64 loss: -1.4710044860839844
Batch 7/64 loss: -1.681396484375
Batch 8/64 loss: -1.3349494934082031
Batch 9/64 loss: -1.7251758575439453
Batch 10/64 loss: -1.2816781997680664
Batch 11/64 loss: -1.8149728775024414
Batch 12/64 loss: -1.1839160919189453
Batch 13/64 loss: -1.4320087432861328
Batch 14/64 loss: -1.5425724983215332
Batch 15/64 loss: -1.6249685287475586
Batch 16/64 loss: -1.4765348434448242
Batch 17/64 loss: -1.1494874954223633
Batch 18/64 loss: -1.7159385681152344
Batch 19/64 loss: -1.5318784713745117
Batch 20/64 loss: -1.7022991180419922
Batch 21/64 loss: -1.5115699768066406
Batch 22/64 loss: -1.3140363693237305
Batch 23/64 loss: -1.437483787536621
Batch 24/64 loss: -1.2414579391479492
Batch 25/64 loss: -1.473872184753418
Batch 26/64 loss: -1.3876533508300781
Batch 27/64 loss: -1.618600845336914
Batch 28/64 loss: -1.4062538146972656
Batch 29/64 loss: -1.0914812088012695
Batch 30/64 loss: -1.7371978759765625
Batch 31/64 loss: -1.466165542602539
Batch 32/64 loss: -0.8504066467285156
Batch 33/64 loss: -1.48626708984375
Batch 34/64 loss: -1.6226778030395508
Batch 35/64 loss: -1.225412368774414
Batch 36/64 loss: -1.6770706176757812
Batch 37/64 loss: -1.7869911193847656
Batch 38/64 loss: -1.83549165725708
Batch 39/64 loss: -1.066253662109375
Batch 40/64 loss: -1.3869733810424805
Batch 41/64 loss: -1.2489643096923828
Batch 42/64 loss: -1.660872459411621
Batch 43/64 loss: -1.6715478897094727
Batch 44/64 loss: -1.706045150756836
Batch 45/64 loss: -1.0863542556762695
Batch 46/64 loss: -1.6221246719360352
Batch 47/64 loss: -1.5519790649414062
Batch 48/64 loss: -1.5799617767333984
Batch 49/64 loss: -1.487828254699707
Batch 50/64 loss: -1.5905838012695312
Batch 51/64 loss: -1.8132410049438477
Batch 52/64 loss: -1.6107206344604492
Batch 53/64 loss: -1.4273805618286133
Batch 54/64 loss: -1.898787021636963
Batch 55/64 loss: -1.2345952987670898
Batch 56/64 loss: -1.3908863067626953
Batch 57/64 loss: -1.420064926147461
Batch 58/64 loss: -1.34332275390625
Batch 59/64 loss: -0.9753055572509766
Batch 60/64 loss: -1.7004175186157227
Batch 61/64 loss: -1.4135656356811523
Batch 62/64 loss: -1.4290657043457031
Batch 63/64 loss: -1.2362403869628906
Batch 64/64 loss: -5.337985992431641
Epoch 246  Train loss: -1.520340452007219  Val loss: -1.5647780952584702
Epoch 247
-------------------------------
Batch 1/64 loss: -1.26483154296875
Batch 2/64 loss: -0.9486007690429688
Batch 3/64 loss: -1.8049907684326172
Batch 4/64 loss: -1.6757745742797852
Batch 5/64 loss: -1.3477001190185547
Batch 6/64 loss: -1.7958250045776367
Batch 7/64 loss: -1.4660329818725586
Batch 8/64 loss: -1.4567937850952148
Batch 9/64 loss: -1.5411033630371094
Batch 10/64 loss: -1.3450336456298828
Batch 11/64 loss: -1.4631004333496094
Batch 12/64 loss: -1.6758489608764648
Batch 13/64 loss: -1.5274162292480469
Batch 14/64 loss: -1.4545974731445312
Batch 15/64 loss: -1.4943475723266602
Batch 16/64 loss: -1.476226806640625
Batch 17/64 loss: -1.5215911865234375
Batch 18/64 loss: -1.8031854629516602
Batch 19/64 loss: -1.5722312927246094
Batch 20/64 loss: -1.74871826171875
Batch 21/64 loss: -1.1621503829956055
Batch 22/64 loss: -1.529444694519043
Batch 23/64 loss: -1.2471370697021484
Batch 24/64 loss: -1.5412569046020508
Batch 25/64 loss: -1.949172019958496
Batch 26/64 loss: -1.270115852355957
Batch 27/64 loss: -1.6182727813720703
Batch 28/64 loss: -1.6404733657836914
Batch 29/64 loss: -1.4318552017211914
Batch 30/64 loss: -1.4344463348388672
Batch 31/64 loss: -1.3902864456176758
Batch 32/64 loss: -1.1358966827392578
Batch 33/64 loss: -1.663839340209961
Batch 34/64 loss: -1.6355295181274414
Batch 35/64 loss: -1.2218027114868164
Batch 36/64 loss: -1.3545713424682617
Batch 37/64 loss: -1.405991554260254
Batch 38/64 loss: -1.6518354415893555
Batch 39/64 loss: -1.2396087646484375
Batch 40/64 loss: -1.6367816925048828
Batch 41/64 loss: -1.4178218841552734
Batch 42/64 loss: -1.8219842910766602
Batch 43/64 loss: -1.3026657104492188
Batch 44/64 loss: -1.3217144012451172
Batch 45/64 loss: -1.6234683990478516
Batch 46/64 loss: -1.614980697631836
Batch 47/64 loss: -1.3751602172851562
Batch 48/64 loss: -1.496358871459961
Batch 49/64 loss: -1.6277360916137695
Batch 50/64 loss: -1.4493741989135742
Batch 51/64 loss: -1.5498847961425781
Batch 52/64 loss: -1.385751724243164
Batch 53/64 loss: -1.461501121520996
Batch 54/64 loss: -1.6071243286132812
Batch 55/64 loss: -1.474496841430664
Batch 56/64 loss: -1.059617042541504
Batch 57/64 loss: -1.1632099151611328
Batch 58/64 loss: -1.398167610168457
Batch 59/64 loss: -1.6792984008789062
Batch 60/64 loss: -1.6179838180541992
Batch 61/64 loss: -1.4740715026855469
Batch 62/64 loss: -1.383946418762207
Batch 63/64 loss: -1.0109014511108398
Batch 64/64 loss: -5.311374187469482
Epoch 247  Train loss: -1.5191399013294893  Val loss: -1.5102258007141323
Epoch 248
-------------------------------
Batch 1/64 loss: -1.731522560119629
Batch 2/64 loss: -1.5519075393676758
Batch 3/64 loss: -1.4085121154785156
Batch 4/64 loss: -1.490804672241211
Batch 5/64 loss: -1.5944490432739258
Batch 6/64 loss: -1.672968864440918
Batch 7/64 loss: -1.7400665283203125
Batch 8/64 loss: -1.3742618560791016
Batch 9/64 loss: -1.6263580322265625
Batch 10/64 loss: -1.3122644424438477
Batch 11/64 loss: -1.5160980224609375
Batch 12/64 loss: -1.8242473602294922
Batch 13/64 loss: -1.7488784790039062
Batch 14/64 loss: -1.5794401168823242
Batch 15/64 loss: -1.5937929153442383
Batch 16/64 loss: -1.426687240600586
Batch 17/64 loss: -1.6843328475952148
Batch 18/64 loss: -1.5160131454467773
Batch 19/64 loss: -1.5976543426513672
Batch 20/64 loss: -1.5010433197021484
Batch 21/64 loss: -1.5664997100830078
Batch 22/64 loss: -1.267862319946289
Batch 23/64 loss: -1.2002363204956055
Batch 24/64 loss: -1.5151605606079102
Batch 25/64 loss: -1.4115514755249023
Batch 26/64 loss: -1.507105827331543
Batch 27/64 loss: -1.1564769744873047
Batch 28/64 loss: -1.2069377899169922
Batch 29/64 loss: -1.565424919128418
Batch 30/64 loss: -1.7431020736694336
Batch 31/64 loss: -1.578232765197754
Batch 32/64 loss: -1.4763412475585938
Batch 33/64 loss: -1.5260438919067383
Batch 34/64 loss: -1.3937606811523438
Batch 35/64 loss: -1.6438961029052734
Batch 36/64 loss: -1.5410423278808594
Batch 37/64 loss: -1.548161506652832
Batch 38/64 loss: -1.507847785949707
Batch 39/64 loss: -1.5086345672607422
Batch 40/64 loss: -1.4699668884277344
Batch 41/64 loss: -1.4703493118286133
Batch 42/64 loss: -1.5701770782470703
Batch 43/64 loss: -1.6041145324707031
Batch 44/64 loss: -1.6085433959960938
Batch 45/64 loss: -1.4367828369140625
Batch 46/64 loss: -1.2847166061401367
Batch 47/64 loss: -0.9257631301879883
Batch 48/64 loss: -1.5299701690673828
Batch 49/64 loss: -1.2834720611572266
Batch 50/64 loss: -1.3959474563598633
Batch 51/64 loss: -1.6641225814819336
Batch 52/64 loss: -1.5921235084533691
Batch 53/64 loss: -1.4266014099121094
Batch 54/64 loss: -1.7084569931030273
Batch 55/64 loss: -1.6738624572753906
Batch 56/64 loss: -1.5732126235961914
Batch 57/64 loss: -1.4620943069458008
Batch 58/64 loss: -1.4738531112670898
Batch 59/64 loss: -1.48358154296875
Batch 60/64 loss: -1.400416374206543
Batch 61/64 loss: -1.5126209259033203
Batch 62/64 loss: -1.5635433197021484
Batch 63/64 loss: -1.212651252746582
Batch 64/64 loss: -5.523107051849365
Epoch 248  Train loss: -1.5501944541931152  Val loss: -1.5638109187489933
Epoch 249
-------------------------------
Batch 1/64 loss: -1.6954097747802734
Batch 2/64 loss: -1.7019472122192383
Batch 3/64 loss: -1.5926008224487305
Batch 4/64 loss: -1.2641706466674805
Batch 5/64 loss: -1.3814640045166016
Batch 6/64 loss: -1.5017881393432617
Batch 7/64 loss: -1.423680305480957
Batch 8/64 loss: -1.5807218551635742
Batch 9/64 loss: -1.3799972534179688
Batch 10/64 loss: -1.4624509811401367
Batch 11/64 loss: -1.5100374221801758
Batch 12/64 loss: -1.2723684310913086
Batch 13/64 loss: -1.558741569519043
Batch 14/64 loss: -1.7397661209106445
Batch 15/64 loss: -1.3566246032714844
Batch 16/64 loss: -0.9837779998779297
Batch 17/64 loss: -1.6735563278198242
Batch 18/64 loss: -1.6813545227050781
Batch 19/64 loss: -1.5377082824707031
Batch 20/64 loss: -1.4549322128295898
Batch 21/64 loss: -1.313751220703125
Batch 22/64 loss: -1.4101152420043945
Batch 23/64 loss: -1.5539684295654297
Batch 24/64 loss: -1.1960821151733398
Batch 25/64 loss: -1.632009506225586
Batch 26/64 loss: -1.6475858688354492
Batch 27/64 loss: -1.2781381607055664
Batch 28/64 loss: -1.4990673065185547
Batch 29/64 loss: -1.771428108215332
Batch 30/64 loss: -1.3183670043945312
Batch 31/64 loss: -1.5684661865234375
Batch 32/64 loss: -1.682591438293457
Batch 33/64 loss: -1.5855417251586914
Batch 34/64 loss: -1.6891937255859375
Batch 35/64 loss: -1.3495187759399414
Batch 36/64 loss: -1.1928024291992188
Batch 37/64 loss: -1.346247673034668
Batch 38/64 loss: -1.6116085052490234
Batch 39/64 loss: -1.6818294525146484
Batch 40/64 loss: -1.4394559860229492
Batch 41/64 loss: -1.3322296142578125
Batch 42/64 loss: -1.701357364654541
Batch 43/64 loss: -1.853856086730957
Batch 44/64 loss: -1.3772249221801758
Batch 45/64 loss: -1.7081079483032227
Batch 46/64 loss: -1.537881851196289
Batch 47/64 loss: -1.5700750350952148
Batch 48/64 loss: -1.522592544555664
Batch 49/64 loss: -1.5632410049438477
Batch 50/64 loss: -1.6656608581542969
Batch 51/64 loss: -1.4417314529418945
Batch 52/64 loss: -1.1920204162597656
Batch 53/64 loss: -1.2897615432739258
Batch 54/64 loss: -1.7844600677490234
Batch 55/64 loss: -1.3601465225219727
Batch 56/64 loss: -1.6831073760986328
Batch 57/64 loss: -1.6235361099243164
Batch 58/64 loss: -1.612828254699707
Batch 59/64 loss: -0.9107027053833008
Batch 60/64 loss: -1.2271041870117188
Batch 61/64 loss: -1.4472570419311523
Batch 62/64 loss: -1.661046028137207
Batch 63/64 loss: -1.8056745529174805
Batch 64/64 loss: -5.690356254577637
Epoch 249  Train loss: -1.5476115769031  Val loss: -1.665755203089763
Epoch 250
-------------------------------
Batch 1/64 loss: -0.9136409759521484
Batch 2/64 loss: -1.705550193786621
Batch 3/64 loss: -1.5257606506347656
Batch 4/64 loss: -1.5627145767211914
Batch 5/64 loss: -1.7309627532958984
Batch 6/64 loss: -1.5335369110107422
Batch 7/64 loss: -1.4744138717651367
Batch 8/64 loss: -1.5463380813598633
Batch 9/64 loss: -1.6473913192749023
Batch 10/64 loss: -1.5664644241333008
Batch 11/64 loss: -1.4178037643432617
Batch 12/64 loss: -1.3863143920898438
Batch 13/64 loss: -1.2106142044067383
Batch 14/64 loss: -1.2996721267700195
Batch 15/64 loss: -1.6020393371582031
Batch 16/64 loss: -1.2231760025024414
Batch 17/64 loss: -1.2095813751220703
Batch 18/64 loss: -1.247767448425293
Batch 19/64 loss: -1.6164369583129883
Batch 20/64 loss: -1.3019075393676758
Batch 21/64 loss: -1.2450876235961914
Batch 22/64 loss: -1.6103601455688477
Batch 23/64 loss: -1.3158349990844727
Batch 24/64 loss: -1.4507675170898438
Batch 25/64 loss: -1.5086078643798828
Batch 26/64 loss: -1.3233518600463867
Batch 27/64 loss: -1.164346694946289
Batch 28/64 loss: -1.4829397201538086
Batch 29/64 loss: -1.6564674377441406
Batch 30/64 loss: -1.6454429626464844
Batch 31/64 loss: -1.500615119934082
Batch 32/64 loss: -1.124725341796875
Batch 33/64 loss: -1.591202735900879
Batch 34/64 loss: -1.3039960861206055
Batch 35/64 loss: -1.4715099334716797
Batch 36/64 loss: -1.3640823364257812
Batch 37/64 loss: -0.6264581680297852
Batch 38/64 loss: -1.408024787902832
Batch 39/64 loss: -1.4213438034057617
Batch 40/64 loss: -1.662867546081543
Batch 41/64 loss: -1.5777359008789062
Batch 42/64 loss: -1.6956825256347656
Batch 43/64 loss: -1.3426542282104492
Batch 44/64 loss: -1.3203649520874023
Batch 45/64 loss: -1.3411235809326172
Batch 46/64 loss: -1.365102767944336
Batch 47/64 loss: -1.601633071899414
Batch 48/64 loss: -1.6009635925292969
Batch 49/64 loss: -1.3708467483520508
Batch 50/64 loss: -1.6276311874389648
Batch 51/64 loss: -1.5690298080444336
Batch 52/64 loss: -1.2311372756958008
Batch 53/64 loss: -1.4859991073608398
Batch 54/64 loss: -1.3695802688598633
Batch 55/64 loss: -1.2256221771240234
Batch 56/64 loss: -1.6806097030639648
Batch 57/64 loss: -1.743474006652832
Batch 58/64 loss: -1.853989601135254
Batch 59/64 loss: -1.4776782989501953
Batch 60/64 loss: -1.4608640670776367
Batch 61/64 loss: -1.8067102432250977
Batch 62/64 loss: -1.2405080795288086
Batch 63/64 loss: -1.3965978622436523
Batch 64/64 loss: -5.512885093688965
Epoch 250  Train loss: -1.4920834896611233  Val loss: -1.5776964430137188
Epoch 251
-------------------------------
Batch 1/64 loss: -1.622044563293457
Batch 2/64 loss: -1.8902339935302734
Batch 3/64 loss: -1.7465295791625977
Batch 4/64 loss: -1.6916999816894531
Batch 5/64 loss: -1.6739387512207031
Batch 6/64 loss: -1.3371200561523438
Batch 7/64 loss: -1.928553581237793
Batch 8/64 loss: -1.5834951400756836
Batch 9/64 loss: -1.5314884185791016
Batch 10/64 loss: -1.5918426513671875
Batch 11/64 loss: -1.2715644836425781
Batch 12/64 loss: -1.5424890518188477
Batch 13/64 loss: -1.366943359375
Batch 14/64 loss: -1.5811071395874023
Batch 15/64 loss: -1.446629524230957
Batch 16/64 loss: -1.8701047897338867
Batch 17/64 loss: -1.8422212600708008
Batch 18/64 loss: -1.5794696807861328
Batch 19/64 loss: -1.5406122207641602
Batch 20/64 loss: -1.3505420684814453
Batch 21/64 loss: -1.660125732421875
Batch 22/64 loss: -1.5597047805786133
Batch 23/64 loss: -1.632333755493164
Batch 24/64 loss: -1.6121492385864258
Batch 25/64 loss: -1.6082935333251953
Batch 26/64 loss: -1.6152572631835938
Batch 27/64 loss: -1.4547348022460938
Batch 28/64 loss: -1.677201271057129
Batch 29/64 loss: -1.4182872772216797
Batch 30/64 loss: -1.9764256477355957
Batch 31/64 loss: -1.4056463241577148
Batch 32/64 loss: -1.4573802947998047
Batch 33/64 loss: -1.7795076370239258
Batch 34/64 loss: -1.780623435974121
Batch 35/64 loss: -1.6725807189941406
Batch 36/64 loss: -1.7012710571289062
Batch 37/64 loss: -1.5577058792114258
Batch 38/64 loss: -1.6697320938110352
Batch 39/64 loss: -1.7046728134155273
Batch 40/64 loss: -1.726384162902832
Batch 41/64 loss: -1.3083620071411133
Batch 42/64 loss: -1.477499008178711
Batch 43/64 loss: -1.4819746017456055
Batch 44/64 loss: -1.7521352767944336
Batch 45/64 loss: -1.683354377746582
Batch 46/64 loss: -1.7427215576171875
Batch 47/64 loss: -1.6486225128173828
Batch 48/64 loss: -1.7251396179199219
Batch 49/64 loss: -1.6843338012695312
Batch 50/64 loss: -1.9083986282348633
Batch 51/64 loss: -1.914388656616211
Batch 52/64 loss: -1.7324399948120117
Batch 53/64 loss: -1.1138315200805664
Batch 54/64 loss: -1.3033266067504883
Batch 55/64 loss: -1.619277000427246
Batch 56/64 loss: -0.8716926574707031
Batch 57/64 loss: -1.5963315963745117
Batch 58/64 loss: -1.503462791442871
Batch 59/64 loss: -1.2506132125854492
Batch 60/64 loss: -1.329808235168457
Batch 61/64 loss: -1.0253677368164062
Batch 62/64 loss: -1.586897850036621
Batch 63/64 loss: -1.6586265563964844
Batch 64/64 loss: -5.170392036437988
Epoch 251  Train loss: -1.6228242799347523  Val loss: -1.717445360426231
Epoch 252
-------------------------------
Batch 1/64 loss: -1.6301765441894531
Batch 2/64 loss: -1.5966606140136719
Batch 3/64 loss: -1.3182554244995117
Batch 4/64 loss: -1.5257368087768555
Batch 5/64 loss: -1.2813043594360352
Batch 6/64 loss: -1.5972318649291992
Batch 7/64 loss: -1.6347827911376953
Batch 8/64 loss: -1.8444151878356934
Batch 9/64 loss: -1.5794997215270996
Batch 10/64 loss: -1.9162397384643555
Batch 11/64 loss: -1.6718626022338867
Batch 12/64 loss: -1.6529593467712402
Batch 13/64 loss: -1.2831687927246094
Batch 14/64 loss: -1.2797613143920898
Batch 15/64 loss: -1.3258247375488281
Batch 16/64 loss: -1.154184341430664
Batch 17/64 loss: -1.5079164505004883
Batch 18/64 loss: -1.926865577697754
Batch 19/64 loss: -1.6535377502441406
Batch 20/64 loss: -1.2302684783935547
Batch 21/64 loss: -1.519655704498291
Batch 22/64 loss: -1.666839599609375
Batch 23/64 loss: -1.6249866485595703
Batch 24/64 loss: -1.353276252746582
Batch 25/64 loss: -1.7590417861938477
Batch 26/64 loss: -1.5541572570800781
Batch 27/64 loss: -1.7467021942138672
Batch 28/64 loss: -1.5882225036621094
Batch 29/64 loss: -1.4036550521850586
Batch 30/64 loss: -1.0725040435791016
Batch 31/64 loss: -1.6505236625671387
Batch 32/64 loss: -1.271697998046875
Batch 33/64 loss: -1.6889381408691406
Batch 34/64 loss: -1.7829523086547852
Batch 35/64 loss: -1.4570350646972656
Batch 36/64 loss: -1.6029729843139648
Batch 37/64 loss: -1.8000450134277344
Batch 38/64 loss: -1.557478904724121
Batch 39/64 loss: -1.8719043731689453
Batch 40/64 loss: -1.2457752227783203
Batch 41/64 loss: -1.6828794479370117
Batch 42/64 loss: -1.4108152389526367
Batch 43/64 loss: -1.6614093780517578
Batch 44/64 loss: -1.371953010559082
Batch 45/64 loss: -1.635838508605957
Batch 46/64 loss: -1.6272392272949219
Batch 47/64 loss: -1.533243179321289
Batch 48/64 loss: -1.7912960052490234
Batch 49/64 loss: -1.521500587463379
Batch 50/64 loss: -1.588475227355957
Batch 51/64 loss: -1.8399410247802734
Batch 52/64 loss: -0.9339132308959961
Batch 53/64 loss: -1.4043283462524414
Batch 54/64 loss: -1.5597467422485352
Batch 55/64 loss: -1.789402961730957
Batch 56/64 loss: -1.3220882415771484
Batch 57/64 loss: -1.8784222602844238
Batch 58/64 loss: -1.8431658744812012
Batch 59/64 loss: -1.4391365051269531
Batch 60/64 loss: -1.8342037200927734
Batch 61/64 loss: -1.7767610549926758
Batch 62/64 loss: -1.482396125793457
Batch 63/64 loss: -1.2029008865356445
Batch 64/64 loss: -5.368488311767578
Epoch 252  Train loss: -1.599787296968348  Val loss: -1.6226204940953206
Epoch 253
-------------------------------
Batch 1/64 loss: -1.6660795211791992
Batch 2/64 loss: -1.3026189804077148
Batch 3/64 loss: -1.646397590637207
Batch 4/64 loss: -1.2145462036132812
Batch 5/64 loss: -1.7742843627929688
Batch 6/64 loss: -1.4050216674804688
Batch 7/64 loss: -1.3674602508544922
Batch 8/64 loss: -1.5808382034301758
Batch 9/64 loss: -0.912419319152832
Batch 10/64 loss: -1.2987613677978516
Batch 11/64 loss: -1.276289939880371
Batch 12/64 loss: -1.5929670333862305
Batch 13/64 loss: -1.627100944519043
Batch 14/64 loss: -1.369887351989746
Batch 15/64 loss: -1.7734870910644531
Batch 16/64 loss: -1.657454490661621
Batch 17/64 loss: -1.7244873046875
Batch 18/64 loss: -1.5961894989013672
Batch 19/64 loss: -1.8238821029663086
Batch 20/64 loss: -1.6418790817260742
Batch 21/64 loss: -1.4963417053222656
Batch 22/64 loss: -1.4202699661254883
Batch 23/64 loss: -1.8571968078613281
Batch 24/64 loss: -1.724106788635254
Batch 25/64 loss: -1.7134580612182617
Batch 26/64 loss: -1.4223651885986328
Batch 27/64 loss: -1.5065364837646484
Batch 28/64 loss: -1.9315900802612305
Batch 29/64 loss: -1.4374732971191406
Batch 30/64 loss: -1.7282238006591797
Batch 31/64 loss: -1.549489974975586
Batch 32/64 loss: -1.6960525512695312
Batch 33/64 loss: -1.1761178970336914
Batch 34/64 loss: -1.5938215255737305
Batch 35/64 loss: -1.6149845123291016
Batch 36/64 loss: -1.5997838973999023
Batch 37/64 loss: -1.6346073150634766
Batch 38/64 loss: -1.6497383117675781
Batch 39/64 loss: -1.5234127044677734
Batch 40/64 loss: -1.339982032775879
Batch 41/64 loss: -1.8536291122436523
Batch 42/64 loss: -1.1905250549316406
Batch 43/64 loss: -1.602259635925293
Batch 44/64 loss: -1.6276874542236328
Batch 45/64 loss: -1.9047579765319824
Batch 46/64 loss: -1.6762752532958984
Batch 47/64 loss: -1.744929313659668
Batch 48/64 loss: -1.7701435089111328
Batch 49/64 loss: -1.7671127319335938
Batch 50/64 loss: -1.5911531448364258
Batch 51/64 loss: -1.7853355407714844
Batch 52/64 loss: -1.7894287109375
Batch 53/64 loss: -1.617624282836914
Batch 54/64 loss: -1.7393083572387695
Batch 55/64 loss: -1.7000980377197266
Batch 56/64 loss: -1.5335321426391602
Batch 57/64 loss: -1.3246688842773438
Batch 58/64 loss: -1.6520576477050781
Batch 59/64 loss: -0.7957448959350586
Batch 60/64 loss: -1.2811450958251953
Batch 61/64 loss: -1.6274614334106445
Batch 62/64 loss: -1.6297492980957031
Batch 63/64 loss: -1.008901596069336
Batch 64/64 loss: -5.692549705505371
Epoch 253  Train loss: -1.6054987701715207  Val loss: -1.5785316519720858
Epoch 254
-------------------------------
Batch 1/64 loss: -1.7116985321044922
Batch 2/64 loss: -1.6538877487182617
Batch 3/64 loss: -1.5847225189208984
Batch 4/64 loss: -1.5888147354125977
Batch 5/64 loss: -1.3645448684692383
Batch 6/64 loss: -1.4729909896850586
Batch 7/64 loss: -1.481710433959961
Batch 8/64 loss: -1.464615821838379
Batch 9/64 loss: -1.4921684265136719
Batch 10/64 loss: -1.6800546646118164
Batch 11/64 loss: -1.4282264709472656
Batch 12/64 loss: -1.5089750289916992
Batch 13/64 loss: -1.663670539855957
Batch 14/64 loss: -1.2585716247558594
Batch 15/64 loss: -1.8137264251708984
Batch 16/64 loss: -1.5607013702392578
Batch 17/64 loss: -1.6032991409301758
Batch 18/64 loss: -1.5270719528198242
Batch 19/64 loss: -1.5191364288330078
Batch 20/64 loss: -1.7945442199707031
Batch 21/64 loss: -1.539459228515625
Batch 22/64 loss: -1.381474494934082
Batch 23/64 loss: -1.3451299667358398
Batch 24/64 loss: -1.4139318466186523
Batch 25/64 loss: -1.6435413360595703
Batch 26/64 loss: -1.6069879531860352
Batch 27/64 loss: -1.7888593673706055
Batch 28/64 loss: -1.955674171447754
Batch 29/64 loss: -1.6697273254394531
Batch 30/64 loss: -1.6455926895141602
Batch 31/64 loss: -1.7488040924072266
Batch 32/64 loss: -1.5688209533691406
Batch 33/64 loss: -1.3775453567504883
Batch 34/64 loss: -1.6514129638671875
Batch 35/64 loss: -1.7200040817260742
Batch 36/64 loss: -1.6551570892333984
Batch 37/64 loss: -1.2403802871704102
Batch 38/64 loss: -1.6748132705688477
Batch 39/64 loss: -1.709702968597412
Batch 40/64 loss: -1.6886911392211914
Batch 41/64 loss: -1.7103347778320312
Batch 42/64 loss: -1.455876350402832
Batch 43/64 loss: -1.745100975036621
Batch 44/64 loss: -1.3111238479614258
Batch 45/64 loss: -1.8197736740112305
Batch 46/64 loss: -1.6216917037963867
Batch 47/64 loss: -1.4867744445800781
Batch 48/64 loss: -1.1254949569702148
Batch 49/64 loss: -1.6546611785888672
Batch 50/64 loss: -1.5029382705688477
Batch 51/64 loss: -1.912757396697998
Batch 52/64 loss: -1.3743677139282227
Batch 53/64 loss: -1.3947410583496094
Batch 54/64 loss: -1.3574771881103516
Batch 55/64 loss: -1.0767641067504883
Batch 56/64 loss: -1.278116226196289
Batch 57/64 loss: -1.2500686645507812
Batch 58/64 loss: -1.7054319381713867
Batch 59/64 loss: -1.6960554122924805
Batch 60/64 loss: -1.1244659423828125
Batch 61/64 loss: -1.5623846054077148
Batch 62/64 loss: -1.3721656799316406
Batch 63/64 loss: -1.5133790969848633
Batch 64/64 loss: -5.662883758544922
Epoch 254  Train loss: -1.592124714570887  Val loss: -1.7254246190651177
Epoch 255
-------------------------------
Batch 1/64 loss: -1.7605681419372559
Batch 2/64 loss: -1.464838981628418
Batch 3/64 loss: -1.289290428161621
Batch 4/64 loss: -1.4471158981323242
Batch 5/64 loss: -1.5294761657714844
Batch 6/64 loss: -1.1443233489990234
Batch 7/64 loss: -1.1239347457885742
Batch 8/64 loss: -1.2463274002075195
Batch 9/64 loss: -1.4494237899780273
Batch 10/64 loss: -1.3734130859375
Batch 11/64 loss: -1.9090466499328613
Batch 12/64 loss: -0.8968429565429688
Batch 13/64 loss: -1.6163358688354492
Batch 14/64 loss: -1.2779836654663086
Batch 15/64 loss: -1.6140623092651367
Batch 16/64 loss: -1.806513786315918
Batch 17/64 loss: -1.6900873184204102
Batch 18/64 loss: -1.6653432846069336
Batch 19/64 loss: -1.6066703796386719
Batch 20/64 loss: -1.6391077041625977
Batch 21/64 loss: -1.8046040534973145
Batch 22/64 loss: -1.5344209671020508
Batch 23/64 loss: -1.6572179794311523
Batch 24/64 loss: -1.8714256286621094
Batch 25/64 loss: -1.5526456832885742
Batch 26/64 loss: -1.5119619369506836
Batch 27/64 loss: -1.3751821517944336
Batch 28/64 loss: -1.218886375427246
Batch 29/64 loss: -1.6648998260498047
Batch 30/64 loss: -1.2948665618896484
Batch 31/64 loss: -1.5986480712890625
Batch 32/64 loss: -1.4238204956054688
Batch 33/64 loss: -1.7294864654541016
Batch 34/64 loss: -1.5481700897216797
Batch 35/64 loss: -1.8431100845336914
Batch 36/64 loss: -1.622899055480957
Batch 37/64 loss: -1.7612247467041016
Batch 38/64 loss: -1.5106449127197266
Batch 39/64 loss: -1.720550537109375
Batch 40/64 loss: -1.6129989624023438
Batch 41/64 loss: -1.6876411437988281
Batch 42/64 loss: -1.7119026184082031
Batch 43/64 loss: -1.347909927368164
Batch 44/64 loss: -1.5995092391967773
Batch 45/64 loss: -1.4704599380493164
Batch 46/64 loss: -1.7294034957885742
Batch 47/64 loss: -1.832789421081543
Batch 48/64 loss: -1.4556751251220703
Batch 49/64 loss: -1.776432991027832
Batch 50/64 loss: -1.3166236877441406
Batch 51/64 loss: -1.7039446830749512
Batch 52/64 loss: -1.5139026641845703
Batch 53/64 loss: -1.8799238204956055
Batch 54/64 loss: -1.6922101974487305
Batch 55/64 loss: -1.7275581359863281
Batch 56/64 loss: -1.5118560791015625
Batch 57/64 loss: -1.6029539108276367
Batch 58/64 loss: -1.157923698425293
Batch 59/64 loss: -1.2501153945922852
Batch 60/64 loss: -1.4535236358642578
Batch 61/64 loss: -1.3464288711547852
Batch 62/64 loss: -1.379190444946289
Batch 63/64 loss: -1.6020755767822266
Batch 64/64 loss: -5.617128372192383
Epoch 255  Train loss: -1.5901360231287338  Val loss: -1.735435118789935
Epoch 256
-------------------------------
Batch 1/64 loss: -1.6710538864135742
Batch 2/64 loss: -1.3280696868896484
Batch 3/64 loss: -1.4241342544555664
Batch 4/64 loss: -1.6002416610717773
Batch 5/64 loss: -1.5381546020507812
Batch 6/64 loss: -1.6896886825561523
Batch 7/64 loss: -1.487025260925293
Batch 8/64 loss: -1.4464111328125
Batch 9/64 loss: -1.3391714096069336
Batch 10/64 loss: -1.5977287292480469
Batch 11/64 loss: -1.6888628005981445
Batch 12/64 loss: -1.5345268249511719
Batch 13/64 loss: -1.5977888107299805
Batch 14/64 loss: -1.8350496292114258
Batch 15/64 loss: -1.8501911163330078
Batch 16/64 loss: -1.3917760848999023
Batch 17/64 loss: -1.4673089981079102
Batch 18/64 loss: -1.4726133346557617
Batch 19/64 loss: -1.348677635192871
Batch 20/64 loss: -1.445577621459961
Batch 21/64 loss: -1.600172996520996
Batch 22/64 loss: -1.2630605697631836
Batch 23/64 loss: -1.3828678131103516
Batch 24/64 loss: -1.4996185302734375
Batch 25/64 loss: -1.8601188659667969
Batch 26/64 loss: -1.3149147033691406
Batch 27/64 loss: -1.571385383605957
Batch 28/64 loss: -1.754572868347168
Batch 29/64 loss: -1.5290470123291016
Batch 30/64 loss: -1.5503301620483398
Batch 31/64 loss: -1.7385587692260742
Batch 32/64 loss: -1.482900619506836
Batch 33/64 loss: -1.6065597534179688
Batch 34/64 loss: -1.5624465942382812
Batch 35/64 loss: -1.485365867614746
Batch 36/64 loss: -1.3425970077514648
Batch 37/64 loss: -1.1880598068237305
Batch 38/64 loss: -1.7085990905761719
Batch 39/64 loss: -1.1218376159667969
Batch 40/64 loss: -1.4261703491210938
Batch 41/64 loss: -1.7029962539672852
Batch 42/64 loss: -0.9652862548828125
Batch 43/64 loss: -1.646897315979004
Batch 44/64 loss: -1.5191631317138672
Batch 45/64 loss: -1.559164047241211
Batch 46/64 loss: -1.6133995056152344
Batch 47/64 loss: -1.4036588668823242
Batch 48/64 loss: -1.4179868698120117
Batch 49/64 loss: -1.795334815979004
Batch 50/64 loss: -1.5342416763305664
Batch 51/64 loss: -1.4763288497924805
Batch 52/64 loss: -1.5967035293579102
Batch 53/64 loss: -1.6626558303833008
Batch 54/64 loss: -1.8187837600708008
Batch 55/64 loss: -1.234933853149414
Batch 56/64 loss: -1.7427091598510742
Batch 57/64 loss: -1.5036792755126953
Batch 58/64 loss: -2.0038657188415527
Batch 59/64 loss: -1.7641491889953613
Batch 60/64 loss: -1.5408811569213867
Batch 61/64 loss: -1.5893945693969727
Batch 62/64 loss: -1.5266036987304688
Batch 63/64 loss: -1.892096996307373
Batch 64/64 loss: -5.355342864990234
Epoch 256  Train loss: -1.588559341430664  Val loss: -1.7390856005481838
Epoch 257
-------------------------------
Batch 1/64 loss: -1.584939956665039
Batch 2/64 loss: -1.712646484375
Batch 3/64 loss: -1.728170394897461
Batch 4/64 loss: -1.2393159866333008
Batch 5/64 loss: -1.9154167175292969
Batch 6/64 loss: -1.8275184631347656
Batch 7/64 loss: -1.5220575332641602
Batch 8/64 loss: -1.4743728637695312
Batch 9/64 loss: -1.1563329696655273
Batch 10/64 loss: -1.7062559127807617
Batch 11/64 loss: -1.8304986953735352
Batch 12/64 loss: -1.5501413345336914
Batch 13/64 loss: -1.4119625091552734
Batch 14/64 loss: -1.5889625549316406
Batch 15/64 loss: -1.7351303100585938
Batch 16/64 loss: -1.6491785049438477
Batch 17/64 loss: -1.287959098815918
Batch 18/64 loss: -1.6732969284057617
Batch 19/64 loss: -1.641636848449707
Batch 20/64 loss: -1.4568681716918945
Batch 21/64 loss: -1.8896145820617676
Batch 22/64 loss: -1.8028230667114258
Batch 23/64 loss: -1.2845792770385742
Batch 24/64 loss: -1.7573661804199219
Batch 25/64 loss: -1.776331901550293
Batch 26/64 loss: -1.7521929740905762
Batch 27/64 loss: -1.6145954132080078
Batch 28/64 loss: -1.5687141418457031
Batch 29/64 loss: -1.2160310745239258
Batch 30/64 loss: -1.7782659530639648
Batch 31/64 loss: -1.6942558288574219
Batch 32/64 loss: -1.6410179138183594
Batch 33/64 loss: -1.4891777038574219
Batch 34/64 loss: -1.5554046630859375
Batch 35/64 loss: -1.7761096954345703
Batch 36/64 loss: -1.5391311645507812
Batch 37/64 loss: -1.7263116836547852
Batch 38/64 loss: -1.5363855361938477
Batch 39/64 loss: -1.6608695983886719
Batch 40/64 loss: -1.670781135559082
Batch 41/64 loss: -1.6588058471679688
Batch 42/64 loss: -1.4663400650024414
Batch 43/64 loss: -1.6155672073364258
Batch 44/64 loss: -1.801527976989746
Batch 45/64 loss: -1.6918506622314453
Batch 46/64 loss: -1.4758195877075195
Batch 47/64 loss: -1.4094343185424805
Batch 48/64 loss: -1.7061185836791992
Batch 49/64 loss: -1.306797981262207
Batch 50/64 loss: -1.2254266738891602
Batch 51/64 loss: -1.6999263763427734
Batch 52/64 loss: -1.8661737442016602
Batch 53/64 loss: -1.7355976104736328
Batch 54/64 loss: -1.8763651847839355
Batch 55/64 loss: -1.427006721496582
Batch 56/64 loss: -1.4145851135253906
Batch 57/64 loss: -1.4784364700317383
Batch 58/64 loss: -1.5902595520019531
Batch 59/64 loss: -1.5454626083374023
Batch 60/64 loss: -1.6171483993530273
Batch 61/64 loss: -1.7629871368408203
Batch 62/64 loss: -1.7213516235351562
Batch 63/64 loss: -1.8285293579101562
Batch 64/64 loss: -5.447434902191162
Epoch 257  Train loss: -1.653799477745505  Val loss: -1.8475865629530444
Saving best model, epoch: 257
Epoch 258
-------------------------------
Batch 1/64 loss: -1.3985366821289062
Batch 2/64 loss: -1.2881202697753906
Batch 3/64 loss: -1.5708599090576172
Batch 4/64 loss: -1.3997106552124023
Batch 5/64 loss: -1.5990171432495117
Batch 6/64 loss: -1.7396554946899414
Batch 7/64 loss: -1.6212167739868164
Batch 8/64 loss: -1.6250009536743164
Batch 9/64 loss: -1.7830991744995117
Batch 10/64 loss: -1.4767169952392578
Batch 11/64 loss: -1.7331466674804688
Batch 12/64 loss: -0.6967048645019531
Batch 13/64 loss: -1.3247852325439453
Batch 14/64 loss: -1.6232633590698242
Batch 15/64 loss: -1.713679313659668
Batch 16/64 loss: -1.2023658752441406
Batch 17/64 loss: -1.524942398071289
Batch 18/64 loss: -1.412785530090332
Batch 19/64 loss: -1.6967906951904297
Batch 20/64 loss: -1.846677303314209
Batch 21/64 loss: -1.5739974975585938
Batch 22/64 loss: -1.9537901878356934
Batch 23/64 loss: -1.6944446563720703
Batch 24/64 loss: -1.8357372283935547
Batch 25/64 loss: -1.663808822631836
Batch 26/64 loss: -1.4381523132324219
Batch 27/64 loss: -1.4873218536376953
Batch 28/64 loss: -1.7099475860595703
Batch 29/64 loss: -1.4982624053955078
Batch 30/64 loss: -1.39080810546875
Batch 31/64 loss: -1.3664064407348633
Batch 32/64 loss: -1.6298232078552246
Batch 33/64 loss: -1.742391586303711
Batch 34/64 loss: -1.6820898056030273
Batch 35/64 loss: -1.693070411682129
Batch 36/64 loss: -0.9704475402832031
Batch 37/64 loss: -1.0986194610595703
Batch 38/64 loss: -1.5466108322143555
Batch 39/64 loss: -1.4544544219970703
Batch 40/64 loss: -1.3623371124267578
Batch 41/64 loss: -1.7210721969604492
Batch 42/64 loss: -1.7842779159545898
Batch 43/64 loss: -1.5175704956054688
Batch 44/64 loss: -1.383749008178711
Batch 45/64 loss: -1.4017152786254883
Batch 46/64 loss: -1.8775668144226074
Batch 47/64 loss: -1.3985042572021484
Batch 48/64 loss: -1.5008058547973633
Batch 49/64 loss: -1.4206161499023438
Batch 50/64 loss: -1.5913524627685547
Batch 51/64 loss: -1.7915630340576172
Batch 52/64 loss: -1.5523748397827148
Batch 53/64 loss: -1.4321651458740234
Batch 54/64 loss: -1.6459388732910156
Batch 55/64 loss: -1.3882942199707031
Batch 56/64 loss: -1.355057716369629
Batch 57/64 loss: -1.6703910827636719
Batch 58/64 loss: -1.463125228881836
Batch 59/64 loss: -1.4457979202270508
Batch 60/64 loss: -1.592350959777832
Batch 61/64 loss: -1.3351516723632812
Batch 62/64 loss: -1.8272037506103516
Batch 63/64 loss: -1.562962532043457
Batch 64/64 loss: -5.376141548156738
Epoch 258  Train loss: -1.58056957394469  Val loss: -1.7669552806316782
Epoch 259
-------------------------------
Batch 1/64 loss: -1.6990766525268555
Batch 2/64 loss: -1.503464698791504
Batch 3/64 loss: -1.6009092330932617
Batch 4/64 loss: -1.544478416442871
Batch 5/64 loss: -1.774637222290039
Batch 6/64 loss: -1.8825511932373047
Batch 7/64 loss: -1.4352245330810547
Batch 8/64 loss: -1.4963722229003906
Batch 9/64 loss: -1.562479019165039
Batch 10/64 loss: -1.8011293411254883
Batch 11/64 loss: -1.4844818115234375
Batch 12/64 loss: -1.1827411651611328
Batch 13/64 loss: -1.430715560913086
Batch 14/64 loss: -1.678349494934082
Batch 15/64 loss: -1.8953533172607422
Batch 16/64 loss: -1.5581512451171875
Batch 17/64 loss: -1.8964967727661133
Batch 18/64 loss: -1.7747697830200195
Batch 19/64 loss: -1.5388908386230469
Batch 20/64 loss: -1.205887794494629
Batch 21/64 loss: -1.6477746963500977
Batch 22/64 loss: -1.6016225814819336
Batch 23/64 loss: -1.3557043075561523
Batch 24/64 loss: -1.8206672668457031
Batch 25/64 loss: -1.5865087509155273
Batch 26/64 loss: -1.47503662109375
Batch 27/64 loss: -1.4000129699707031
Batch 28/64 loss: -1.2897977828979492
Batch 29/64 loss: -1.610692024230957
Batch 30/64 loss: -1.6364774703979492
Batch 31/64 loss: -1.4169273376464844
Batch 32/64 loss: -1.7121086120605469
Batch 33/64 loss: -1.9617891311645508
Batch 34/64 loss: -1.6998233795166016
Batch 35/64 loss: -1.2501115798950195
Batch 36/64 loss: -1.9578638076782227
Batch 37/64 loss: -1.8343229293823242
Batch 38/64 loss: -1.6182289123535156
Batch 39/64 loss: -1.8899765014648438
Batch 40/64 loss: -1.9582853317260742
Batch 41/64 loss: -1.6824731826782227
Batch 42/64 loss: -1.5860404968261719
Batch 43/64 loss: -1.830594539642334
Batch 44/64 loss: -1.7268590927124023
Batch 45/64 loss: -1.4175453186035156
Batch 46/64 loss: -1.4219341278076172
Batch 47/64 loss: -1.5116539001464844
Batch 48/64 loss: -1.25274658203125
Batch 49/64 loss: -1.729769229888916
Batch 50/64 loss: -1.6272125244140625
Batch 51/64 loss: -1.6690597534179688
Batch 52/64 loss: -1.471430778503418
Batch 53/64 loss: -1.7485790252685547
Batch 54/64 loss: -1.6329231262207031
Batch 55/64 loss: -1.314915657043457
Batch 56/64 loss: -1.0901517868041992
Batch 57/64 loss: -1.7793941497802734
Batch 58/64 loss: -1.2429819107055664
Batch 59/64 loss: -1.8112802505493164
Batch 60/64 loss: -1.4310064315795898
Batch 61/64 loss: -1.418208122253418
Batch 62/64 loss: -1.5144882202148438
Batch 63/64 loss: -1.4758882522583008
Batch 64/64 loss: -5.706518173217773
Epoch 259  Train loss: -1.636657527848786  Val loss: -1.7458370116977757
Epoch 260
-------------------------------
Batch 1/64 loss: -1.305119514465332
Batch 2/64 loss: -1.8697824478149414
Batch 3/64 loss: -1.6850805282592773
Batch 4/64 loss: -1.6940383911132812
Batch 5/64 loss: -1.59954833984375
Batch 6/64 loss: -1.214909553527832
Batch 7/64 loss: -1.5549354553222656
Batch 8/64 loss: -1.6956329345703125
Batch 9/64 loss: -1.4262466430664062
Batch 10/64 loss: -1.8166723251342773
Batch 11/64 loss: -1.546586036682129
Batch 12/64 loss: -1.749863624572754
Batch 13/64 loss: -1.6505680084228516
Batch 14/64 loss: -1.5964603424072266
Batch 15/64 loss: -1.600977897644043
Batch 16/64 loss: -1.1736946105957031
Batch 17/64 loss: -1.4920692443847656
Batch 18/64 loss: -1.322535514831543
Batch 19/64 loss: -1.2542390823364258
Batch 20/64 loss: -1.9035396575927734
Batch 21/64 loss: -1.3873319625854492
Batch 22/64 loss: -1.3418693542480469
Batch 23/64 loss: -1.709467887878418
Batch 24/64 loss: -1.8384709358215332
Batch 25/64 loss: -1.7405080795288086
Batch 26/64 loss: -1.7816057205200195
Batch 27/64 loss: -1.4388313293457031
Batch 28/64 loss: -1.2294235229492188
Batch 29/64 loss: -1.165410041809082
Batch 30/64 loss: -1.8654165267944336
Batch 31/64 loss: -1.617532730102539
Batch 32/64 loss: -1.6262950897216797
Batch 33/64 loss: -1.7448101043701172
Batch 34/64 loss: -1.9298648834228516
Batch 35/64 loss: -1.3855867385864258
Batch 36/64 loss: -1.7358312606811523
Batch 37/64 loss: -1.6628074645996094
Batch 38/64 loss: -1.7628297805786133
Batch 39/64 loss: -1.5288896560668945
Batch 40/64 loss: -1.886336326599121
Batch 41/64 loss: -1.7362384796142578
Batch 42/64 loss: -1.6956157684326172
Batch 43/64 loss: -1.707106590270996
Batch 44/64 loss: -1.4191150665283203
Batch 45/64 loss: -1.6985502243041992
Batch 46/64 loss: -1.8028907775878906
Batch 47/64 loss: -1.987985610961914
Batch 48/64 loss: -1.7199716567993164
Batch 49/64 loss: -1.8554697036743164
Batch 50/64 loss: -1.7149505615234375
Batch 51/64 loss: -1.720534324645996
Batch 52/64 loss: -1.7026681900024414
Batch 53/64 loss: -1.6600866317749023
Batch 54/64 loss: -1.7907705307006836
Batch 55/64 loss: -1.7576971054077148
Batch 56/64 loss: -1.5631351470947266
Batch 57/64 loss: -1.5230770111083984
Batch 58/64 loss: -1.980682373046875
Batch 59/64 loss: -0.933685302734375
Batch 60/64 loss: -1.8460311889648438
Batch 61/64 loss: -1.7911224365234375
Batch 62/64 loss: -1.4344615936279297
Batch 63/64 loss: -1.7428550720214844
Batch 64/64 loss: -5.540805816650391
Epoch 260  Train loss: -1.6701478471942977  Val loss: -1.7894522938941353
Epoch 261
-------------------------------
Batch 1/64 loss: -1.727518081665039
Batch 2/64 loss: -1.4839239120483398
Batch 3/64 loss: -1.6146659851074219
Batch 4/64 loss: -1.6207923889160156
Batch 5/64 loss: -1.6986017227172852
Batch 6/64 loss: -1.6081953048706055
Batch 7/64 loss: -1.6141138076782227
Batch 8/64 loss: -1.853013038635254
Batch 9/64 loss: -1.5784378051757812
Batch 10/64 loss: -1.809279441833496
Batch 11/64 loss: -1.8710927963256836
Batch 12/64 loss: -1.6707115173339844
Batch 13/64 loss: -1.8151674270629883
Batch 14/64 loss: -1.7212648391723633
Batch 15/64 loss: -1.4659767150878906
Batch 16/64 loss: -1.6444721221923828
Batch 17/64 loss: -1.6624250411987305
Batch 18/64 loss: -1.1253547668457031
Batch 19/64 loss: -1.6447420120239258
Batch 20/64 loss: -1.6835098266601562
Batch 21/64 loss: -1.4259653091430664
Batch 22/64 loss: -1.1834344863891602
Batch 23/64 loss: -1.514582633972168
Batch 24/64 loss: -1.7741804122924805
Batch 25/64 loss: -1.390620231628418
Batch 26/64 loss: -1.29315185546875
Batch 27/64 loss: -1.605936050415039
Batch 28/64 loss: -1.3319063186645508
Batch 29/64 loss: -1.1552867889404297
Batch 30/64 loss: -1.5623092651367188
Batch 31/64 loss: -1.8794622421264648
Batch 32/64 loss: -1.7571120262145996
Batch 33/64 loss: -1.4439544677734375
Batch 34/64 loss: -1.3328332901000977
Batch 35/64 loss: -1.8486051559448242
Batch 36/64 loss: -1.7168331146240234
Batch 37/64 loss: -1.4212560653686523
Batch 38/64 loss: -1.7945575714111328
Batch 39/64 loss: -1.7846088409423828
Batch 40/64 loss: -1.2545061111450195
Batch 41/64 loss: -1.5491809844970703
Batch 42/64 loss: -1.4468164443969727
Batch 43/64 loss: -1.5616769790649414
Batch 44/64 loss: -1.4797019958496094
Batch 45/64 loss: -1.41302490234375
Batch 46/64 loss: -2.0089120864868164
Batch 47/64 loss: -1.5006837844848633
Batch 48/64 loss: -1.6907148361206055
Batch 49/64 loss: -1.3343238830566406
Batch 50/64 loss: -1.6693305969238281
Batch 51/64 loss: -1.5576295852661133
Batch 52/64 loss: -1.3909263610839844
Batch 53/64 loss: -1.722062110900879
Batch 54/64 loss: -1.670705795288086
Batch 55/64 loss: -1.0525741577148438
Batch 56/64 loss: -1.8027644157409668
Batch 57/64 loss: -1.7281923294067383
Batch 58/64 loss: -1.8702340126037598
Batch 59/64 loss: -1.849073886871338
Batch 60/64 loss: -1.4083881378173828
Batch 61/64 loss: -1.7776780128479004
Batch 62/64 loss: -1.5593366622924805
Batch 63/64 loss: -1.844700813293457
Batch 64/64 loss: -5.244866371154785
Epoch 261  Train loss: -1.634614013223087  Val loss: -1.8407234637597991
Epoch 262
-------------------------------
Batch 1/64 loss: -1.8803129196166992
Batch 2/64 loss: -1.6766815185546875
Batch 3/64 loss: -1.7303237915039062
Batch 4/64 loss: -1.601816177368164
Batch 5/64 loss: -1.5949440002441406
Batch 6/64 loss: -1.741434097290039
Batch 7/64 loss: -1.3691606521606445
Batch 8/64 loss: -1.6119823455810547
Batch 9/64 loss: -1.6895809173583984
Batch 10/64 loss: -1.1922130584716797
Batch 11/64 loss: -1.5580368041992188
Batch 12/64 loss: -1.7129120826721191
Batch 13/64 loss: -1.6084527969360352
Batch 14/64 loss: -1.554123878479004
Batch 15/64 loss: -1.8262748718261719
Batch 16/64 loss: -1.4892148971557617
Batch 17/64 loss: -1.6789345741271973
Batch 18/64 loss: -1.4085702896118164
Batch 19/64 loss: -1.7778339385986328
Batch 20/64 loss: -1.247213363647461
Batch 21/64 loss: -1.6825647354125977
Batch 22/64 loss: -1.7391376495361328
Batch 23/64 loss: -1.9149179458618164
Batch 24/64 loss: -1.468393325805664
Batch 25/64 loss: -1.4668035507202148
Batch 26/64 loss: -1.7507381439208984
Batch 27/64 loss: -1.5941925048828125
Batch 28/64 loss: -1.3260936737060547
Batch 29/64 loss: -1.3605232238769531
Batch 30/64 loss: -1.7843809127807617
Batch 31/64 loss: -1.5726966857910156
Batch 32/64 loss: -1.7092981338500977
Batch 33/64 loss: -1.3680944442749023
Batch 34/64 loss: -1.6213207244873047
Batch 35/64 loss: -1.4484186172485352
Batch 36/64 loss: -1.6967697143554688
Batch 37/64 loss: -1.8217430114746094
Batch 38/64 loss: -1.579432487487793
Batch 39/64 loss: -1.764094352722168
Batch 40/64 loss: -1.1448421478271484
Batch 41/64 loss: -1.2230501174926758
Batch 42/64 loss: -1.700368881225586
Batch 43/64 loss: -1.586552619934082
Batch 44/64 loss: -1.4111242294311523
Batch 45/64 loss: -1.791001319885254
Batch 46/64 loss: -1.8069524765014648
Batch 47/64 loss: -1.929396629333496
Batch 48/64 loss: -1.6488380432128906
Batch 49/64 loss: -1.4582338333129883
Batch 50/64 loss: -1.7560148239135742
Batch 51/64 loss: -1.739053726196289
Batch 52/64 loss: -1.7206487655639648
Batch 53/64 loss: -1.808868408203125
Batch 54/64 loss: -1.8161125183105469
Batch 55/64 loss: -1.8665037155151367
Batch 56/64 loss: -1.419595718383789
Batch 57/64 loss: -1.5912628173828125
Batch 58/64 loss: -1.6284828186035156
Batch 59/64 loss: -1.3966455459594727
Batch 60/64 loss: -1.719040870666504
Batch 61/64 loss: -1.8033185005187988
Batch 62/64 loss: -1.6494932174682617
Batch 63/64 loss: -1.6513795852661133
Batch 64/64 loss: -5.934844970703125
Epoch 262  Train loss: -1.668039935242896  Val loss: -1.8463554251234966
Epoch 263
-------------------------------
Batch 1/64 loss: -1.6892518997192383
Batch 2/64 loss: -1.6040935516357422
Batch 3/64 loss: -1.693009376525879
Batch 4/64 loss: -1.567657470703125
Batch 5/64 loss: -1.3029232025146484
Batch 6/64 loss: -1.6678152084350586
Batch 7/64 loss: -1.8720312118530273
Batch 8/64 loss: -2.0176572799682617
Batch 9/64 loss: -1.646876335144043
Batch 10/64 loss: -1.7659873962402344
Batch 11/64 loss: -1.8574657440185547
Batch 12/64 loss: -1.7591185569763184
Batch 13/64 loss: -1.6209049224853516
Batch 14/64 loss: -1.704061508178711
Batch 15/64 loss: -2.0013699531555176
Batch 16/64 loss: -1.6313457489013672
Batch 17/64 loss: -1.596181869506836
Batch 18/64 loss: -1.8338165283203125
Batch 19/64 loss: -1.755599021911621
Batch 20/64 loss: -1.5476922988891602
Batch 21/64 loss: -1.839289665222168
Batch 22/64 loss: -1.7260961532592773
Batch 23/64 loss: -1.6210393905639648
Batch 24/64 loss: -1.9902362823486328
Batch 25/64 loss: -1.7423067092895508
Batch 26/64 loss: -1.8427047729492188
Batch 27/64 loss: -1.7945947647094727
Batch 28/64 loss: -1.7571792602539062
Batch 29/64 loss: -1.6999773979187012
Batch 30/64 loss: -1.7999958992004395
Batch 31/64 loss: -1.7158784866333008
Batch 32/64 loss: -1.9023189544677734
Batch 33/64 loss: -1.5703067779541016
Batch 34/64 loss: -1.7508735656738281
Batch 35/64 loss: -1.612081527709961
Batch 36/64 loss: -1.7363252639770508
Batch 37/64 loss: -1.4438095092773438
Batch 38/64 loss: -1.7131118774414062
Batch 39/64 loss: -1.614823341369629
Batch 40/64 loss: -1.379755973815918
Batch 41/64 loss: -1.4336223602294922
Batch 42/64 loss: -1.9481873512268066
Batch 43/64 loss: -1.5471715927124023
Batch 44/64 loss: -1.6385107040405273
Batch 45/64 loss: -1.4159584045410156
Batch 46/64 loss: -1.8183746337890625
Batch 47/64 loss: -1.3751907348632812
Batch 48/64 loss: -1.955073356628418
Batch 49/64 loss: -1.6012201309204102
Batch 50/64 loss: -1.1910343170166016
Batch 51/64 loss: -1.6509804725646973
Batch 52/64 loss: -1.7921977043151855
Batch 53/64 loss: -1.60634183883667
Batch 54/64 loss: -1.4076018333435059
Batch 55/64 loss: -1.5714683532714844
Batch 56/64 loss: -1.6041712760925293
Batch 57/64 loss: -1.214289665222168
Batch 58/64 loss: -1.0459327697753906
Batch 59/64 loss: -1.533219814300537
Batch 60/64 loss: -1.4160871505737305
Batch 61/64 loss: -1.5770554542541504
Batch 62/64 loss: -1.5295600891113281
Batch 63/64 loss: -1.6461009979248047
Batch 64/64 loss: -4.875493049621582
Epoch 263  Train loss: -1.6872711443433575  Val loss: -1.6695414146606864
Epoch 264
-------------------------------
Batch 1/64 loss: -1.6080617904663086
Batch 2/64 loss: -1.115213394165039
Batch 3/64 loss: -1.7241020202636719
Batch 4/64 loss: -1.8734893798828125
Batch 5/64 loss: -1.6160144805908203
Batch 6/64 loss: -1.3140439987182617
Batch 7/64 loss: -1.220768928527832
Batch 8/64 loss: -1.5326366424560547
Batch 9/64 loss: -1.0512771606445312
Batch 10/64 loss: -1.6421051025390625
Batch 11/64 loss: -1.1342449188232422
Batch 12/64 loss: -1.2751550674438477
Batch 13/64 loss: -1.985198974609375
Batch 14/64 loss: -1.7235727310180664
Batch 15/64 loss: -1.5435571670532227
Batch 16/64 loss: -1.5205154418945312
Batch 17/64 loss: -1.755223274230957
Batch 18/64 loss: -1.7936630249023438
Batch 19/64 loss: -1.5428800582885742
Batch 20/64 loss: -1.3929777145385742
Batch 21/64 loss: -1.6887993812561035
Batch 22/64 loss: -1.8283309936523438
Batch 23/64 loss: -1.8900623321533203
Batch 24/64 loss: -1.7554740905761719
Batch 25/64 loss: -1.6359367370605469
Batch 26/64 loss: -1.976776123046875
Batch 27/64 loss: -1.3889379501342773
Batch 28/64 loss: -1.5188426971435547
Batch 29/64 loss: -1.6797962188720703
Batch 30/64 loss: -1.9723820686340332
Batch 31/64 loss: -1.1456785202026367
Batch 32/64 loss: -1.4040660858154297
Batch 33/64 loss: -1.4520196914672852
Batch 34/64 loss: -1.584564208984375
Batch 35/64 loss: -1.6491460800170898
Batch 36/64 loss: -1.5873908996582031
Batch 37/64 loss: -1.1190176010131836
Batch 38/64 loss: -1.783024787902832
Batch 39/64 loss: -1.8285284042358398
Batch 40/64 loss: -1.345402717590332
Batch 41/64 loss: -1.5215625762939453
Batch 42/64 loss: -1.2478675842285156
Batch 43/64 loss: -1.6826248168945312
Batch 44/64 loss: -1.5964431762695312
Batch 45/64 loss: -1.5837726593017578
Batch 46/64 loss: -1.5673036575317383
Batch 47/64 loss: -1.3143939971923828
Batch 48/64 loss: -1.5023174285888672
Batch 49/64 loss: -1.6356315612792969
Batch 50/64 loss: -1.7715559005737305
Batch 51/64 loss: -1.6991310119628906
Batch 52/64 loss: -1.601837158203125
Batch 53/64 loss: -1.619307518005371
Batch 54/64 loss: -1.6276378631591797
Batch 55/64 loss: -1.5796117782592773
Batch 56/64 loss: -1.431976318359375
Batch 57/64 loss: -1.4962577819824219
Batch 58/64 loss: -1.218881607055664
Batch 59/64 loss: -1.6614580154418945
Batch 60/64 loss: -1.6882085800170898
Batch 61/64 loss: -1.4659748077392578
Batch 62/64 loss: -1.5500717163085938
Batch 63/64 loss: -1.7778024673461914
Batch 64/64 loss: -5.179357051849365
Epoch 264  Train loss: -1.6050984569624358  Val loss: -1.6260365358332998
Epoch 265
-------------------------------
Batch 1/64 loss: -1.5964288711547852
Batch 2/64 loss: -1.501617431640625
Batch 3/64 loss: -0.5989513397216797
Batch 4/64 loss: -1.5231637954711914
Batch 5/64 loss: -1.389369010925293
Batch 6/64 loss: -1.719985008239746
Batch 7/64 loss: -1.737858772277832
Batch 8/64 loss: -1.5635271072387695
Batch 9/64 loss: -1.525588035583496
Batch 10/64 loss: -1.5201101303100586
Batch 11/64 loss: -1.4726896286010742
Batch 12/64 loss: -1.1397972106933594
Batch 13/64 loss: -1.808441162109375
Batch 14/64 loss: -1.3365592956542969
Batch 15/64 loss: -1.2879371643066406
Batch 16/64 loss: -1.4519872665405273
Batch 17/64 loss: -1.7289667129516602
Batch 18/64 loss: -1.6215791702270508
Batch 19/64 loss: -1.6494836807250977
Batch 20/64 loss: -1.6448659896850586
Batch 21/64 loss: -1.6301708221435547
Batch 22/64 loss: -1.8191242218017578
Batch 23/64 loss: -1.6449861526489258
Batch 24/64 loss: -1.500314712524414
Batch 25/64 loss: -1.533970832824707
Batch 26/64 loss: -1.8387160301208496
Batch 27/64 loss: -1.416259765625
Batch 28/64 loss: -1.6794347763061523
Batch 29/64 loss: -1.0980491638183594
Batch 30/64 loss: -1.7585086822509766
Batch 31/64 loss: -1.883863925933838
Batch 32/64 loss: -1.8549413681030273
Batch 33/64 loss: -1.7547259330749512
Batch 34/64 loss: -1.484299659729004
Batch 35/64 loss: -1.4918031692504883
Batch 36/64 loss: -1.6152162551879883
Batch 37/64 loss: -1.4670734405517578
Batch 38/64 loss: -1.5756807327270508
Batch 39/64 loss: -1.6424407958984375
Batch 40/64 loss: -1.6563129425048828
Batch 41/64 loss: -1.8550777435302734
Batch 42/64 loss: -1.3980369567871094
Batch 43/64 loss: -1.6393613815307617
Batch 44/64 loss: -1.644200325012207
Batch 45/64 loss: -1.6381025314331055
Batch 46/64 loss: -0.9847660064697266
Batch 47/64 loss: -1.5790891647338867
Batch 48/64 loss: -1.7764310836791992
Batch 49/64 loss: -1.7555503845214844
Batch 50/64 loss: -1.4319372177124023
Batch 51/64 loss: -1.811936378479004
Batch 52/64 loss: -1.4954242706298828
Batch 53/64 loss: -1.6948108673095703
Batch 54/64 loss: -1.8360590934753418
Batch 55/64 loss: -1.8448295593261719
Batch 56/64 loss: -1.7340726852416992
Batch 57/64 loss: -1.5992603302001953
Batch 58/64 loss: -1.60357666015625
Batch 59/64 loss: -1.0151739120483398
Batch 60/64 loss: -1.478194236755371
Batch 61/64 loss: -1.7673492431640625
Batch 62/64 loss: -1.9767837524414062
Batch 63/64 loss: -1.4943780899047852
Batch 64/64 loss: -5.655123710632324
Epoch 265  Train loss: -1.6229105070525525  Val loss: -1.7765096684092099
Epoch 266
-------------------------------
Batch 1/64 loss: -1.591665267944336
Batch 2/64 loss: -1.4948759078979492
Batch 3/64 loss: -1.8303909301757812
Batch 4/64 loss: -1.4011964797973633
Batch 5/64 loss: -1.2763824462890625
Batch 6/64 loss: -1.6776123046875
Batch 7/64 loss: -1.5590295791625977
Batch 8/64 loss: -1.2943639755249023
Batch 9/64 loss: -1.431096076965332
Batch 10/64 loss: -1.5948724746704102
Batch 11/64 loss: -0.7875022888183594
Batch 12/64 loss: -1.6724920272827148
Batch 13/64 loss: -1.5731449127197266
Batch 14/64 loss: -1.4522161483764648
Batch 15/64 loss: -1.7630605697631836
Batch 16/64 loss: -1.0634956359863281
Batch 17/64 loss: -1.748849868774414
Batch 18/64 loss: -1.1684818267822266
Batch 19/64 loss: -1.597433090209961
Batch 20/64 loss: -1.4948959350585938
Batch 21/64 loss: -1.6088447570800781
Batch 22/64 loss: -1.8778400421142578
Batch 23/64 loss: -1.6109199523925781
Batch 24/64 loss: -1.5335474014282227
Batch 25/64 loss: -1.3945121765136719
Batch 26/64 loss: -1.5485544204711914
Batch 27/64 loss: -1.726332664489746
Batch 28/64 loss: -1.623307228088379
Batch 29/64 loss: -1.6716508865356445
Batch 30/64 loss: -1.6153268814086914
Batch 31/64 loss: -1.5443096160888672
Batch 32/64 loss: -1.6900396347045898
Batch 33/64 loss: -1.7361478805541992
Batch 34/64 loss: -1.603367805480957
Batch 35/64 loss: -1.560903549194336
Batch 36/64 loss: -1.3268537521362305
Batch 37/64 loss: -0.8305950164794922
Batch 38/64 loss: -1.595545768737793
Batch 39/64 loss: -1.8726329803466797
Batch 40/64 loss: -1.2193470001220703
Batch 41/64 loss: -1.6027097702026367
Batch 42/64 loss: -1.530385971069336
Batch 43/64 loss: -1.729355812072754
Batch 44/64 loss: -1.7939367294311523
Batch 45/64 loss: -1.788069725036621
Batch 46/64 loss: -1.5423641204833984
Batch 47/64 loss: -1.756514549255371
Batch 48/64 loss: -1.6453208923339844
Batch 49/64 loss: -1.6677312850952148
Batch 50/64 loss: -1.2984638214111328
Batch 51/64 loss: -1.8777294158935547
Batch 52/64 loss: -1.8261356353759766
Batch 53/64 loss: -1.6574811935424805
Batch 54/64 loss: -1.7422513961791992
Batch 55/64 loss: -1.3392267227172852
Batch 56/64 loss: -2.0944743156433105
Batch 57/64 loss: -1.5485563278198242
Batch 58/64 loss: -1.5984516143798828
Batch 59/64 loss: -1.7904777526855469
Batch 60/64 loss: -1.652359962463379
Batch 61/64 loss: -1.1914606094360352
Batch 62/64 loss: -1.8618555068969727
Batch 63/64 loss: -1.595937728881836
Batch 64/64 loss: -5.221883773803711
Epoch 266  Train loss: -1.6111576603908164  Val loss: -1.8273837951450413
Epoch 267
-------------------------------
Batch 1/64 loss: -1.545522689819336
Batch 2/64 loss: -1.9496550559997559
Batch 3/64 loss: -1.577505111694336
Batch 4/64 loss: -1.6693716049194336
Batch 5/64 loss: -1.934068202972412
Batch 6/64 loss: -1.9795989990234375
Batch 7/64 loss: -1.6619386672973633
Batch 8/64 loss: -1.6488151550292969
Batch 9/64 loss: -1.2800626754760742
Batch 10/64 loss: -1.6757383346557617
Batch 11/64 loss: -1.4433374404907227
Batch 12/64 loss: -1.336379051208496
Batch 13/64 loss: -1.7211341857910156
Batch 14/64 loss: -1.3739652633666992
Batch 15/64 loss: -1.8405237197875977
Batch 16/64 loss: -1.4291315078735352
Batch 17/64 loss: -1.7414484024047852
Batch 18/64 loss: -1.200119972229004
Batch 19/64 loss: -1.6749744415283203
Batch 20/64 loss: -1.439213752746582
Batch 21/64 loss: -1.8321237564086914
Batch 22/64 loss: -1.828434944152832
Batch 23/64 loss: -1.6076326370239258
Batch 24/64 loss: -1.7140426635742188
Batch 25/64 loss: -1.740243911743164
Batch 26/64 loss: -1.4882125854492188
Batch 27/64 loss: -1.360844612121582
Batch 28/64 loss: -1.4335699081420898
Batch 29/64 loss: -1.7516193389892578
Batch 30/64 loss: -1.6058807373046875
Batch 31/64 loss: -1.8599910736083984
Batch 32/64 loss: -1.897359848022461
Batch 33/64 loss: -1.677800178527832
Batch 34/64 loss: -1.6015310287475586
Batch 35/64 loss: -1.8699779510498047
Batch 36/64 loss: -1.7698392868041992
Batch 37/64 loss: -1.8268861770629883
Batch 38/64 loss: -1.4361200332641602
Batch 39/64 loss: -1.6306428909301758
Batch 40/64 loss: -1.722020149230957
Batch 41/64 loss: -1.779001235961914
Batch 42/64 loss: -1.6700115203857422
Batch 43/64 loss: -1.691390037536621
Batch 44/64 loss: -1.6590471267700195
Batch 45/64 loss: -1.9200358390808105
Batch 46/64 loss: -1.790872573852539
Batch 47/64 loss: -1.8124351501464844
Batch 48/64 loss: -1.6984434127807617
Batch 49/64 loss: -1.5187911987304688
Batch 50/64 loss: -1.4760627746582031
Batch 51/64 loss: -1.1800765991210938
Batch 52/64 loss: -1.8616504669189453
Batch 53/64 loss: -1.4643306732177734
Batch 54/64 loss: -1.7119035720825195
Batch 55/64 loss: -1.7594900131225586
Batch 56/64 loss: -1.422917366027832
Batch 57/64 loss: -1.7710628509521484
Batch 58/64 loss: -1.634119987487793
Batch 59/64 loss: -1.5065984725952148
Batch 60/64 loss: -1.5094852447509766
Batch 61/64 loss: -1.5358095169067383
Batch 62/64 loss: -1.4215211868286133
Batch 63/64 loss: -1.787623405456543
Batch 64/64 loss: -5.611431121826172
Epoch 267  Train loss: -1.6873495139327703  Val loss: -1.7076374067064004
Epoch 268
-------------------------------
Batch 1/64 loss: -1.5651121139526367
Batch 2/64 loss: -1.7538270950317383
Batch 3/64 loss: -1.8554248809814453
Batch 4/64 loss: -1.5065298080444336
Batch 5/64 loss: -1.8626041412353516
Batch 6/64 loss: -1.760812759399414
Batch 7/64 loss: -1.8547544479370117
Batch 8/64 loss: -1.6038732528686523
Batch 9/64 loss: -1.8143539428710938
Batch 10/64 loss: -1.733626365661621
Batch 11/64 loss: -1.5575952529907227
Batch 12/64 loss: -1.854506492614746
Batch 13/64 loss: -1.5565967559814453
Batch 14/64 loss: -1.5050840377807617
Batch 15/64 loss: -1.4325523376464844
Batch 16/64 loss: -1.752669334411621
Batch 17/64 loss: -1.9570183753967285
Batch 18/64 loss: -1.3260822296142578
Batch 19/64 loss: -1.6403837203979492
Batch 20/64 loss: -1.6683788299560547
Batch 21/64 loss: -1.5549917221069336
Batch 22/64 loss: -1.9436063766479492
Batch 23/64 loss: -1.3256111145019531
Batch 24/64 loss: -1.4146089553833008
Batch 25/64 loss: -1.6677303314208984
Batch 26/64 loss: -1.2925329208374023
Batch 27/64 loss: -1.7953758239746094
Batch 28/64 loss: -1.388991355895996
Batch 29/64 loss: -1.6975574493408203
Batch 30/64 loss: -1.9276847839355469
Batch 31/64 loss: -1.7365083694458008
Batch 32/64 loss: -1.737497329711914
Batch 33/64 loss: -1.4527826309204102
Batch 34/64 loss: -1.7715911865234375
Batch 35/64 loss: -1.6934518814086914
Batch 36/64 loss: -1.6549224853515625
Batch 37/64 loss: -1.7347383499145508
Batch 38/64 loss: -1.491074562072754
Batch 39/64 loss: -1.711538314819336
Batch 40/64 loss: -1.5305004119873047
Batch 41/64 loss: -1.5148382186889648
Batch 42/64 loss: -1.8623275756835938
Batch 43/64 loss: -1.4020285606384277
Batch 44/64 loss: -1.2759227752685547
Batch 45/64 loss: -1.6929359436035156
Batch 46/64 loss: -1.628708839416504
Batch 47/64 loss: -1.6133193969726562
Batch 48/64 loss: -1.292454719543457
Batch 49/64 loss: -1.3484010696411133
Batch 50/64 loss: -1.4934024810791016
Batch 51/64 loss: -1.371403694152832
Batch 52/64 loss: -1.6956028938293457
Batch 53/64 loss: -1.4977502822875977
Batch 54/64 loss: -1.6216650009155273
Batch 55/64 loss: -1.5428333282470703
Batch 56/64 loss: -1.4518299102783203
Batch 57/64 loss: -1.3437004089355469
Batch 58/64 loss: -1.8756780624389648
Batch 59/64 loss: -1.0844879150390625
Batch 60/64 loss: -1.7830438613891602
Batch 61/64 loss: -1.5565390586853027
Batch 62/64 loss: -1.7537450790405273
Batch 63/64 loss: -1.4137868881225586
Batch 64/64 loss: -5.636700630187988
Epoch 268  Train loss: -1.653788454392377  Val loss: -1.7248756828177016
Epoch 269
-------------------------------
Batch 1/64 loss: -1.6233110427856445
Batch 2/64 loss: -1.4973907470703125
Batch 3/64 loss: -1.5663461685180664
Batch 4/64 loss: -1.4706077575683594
Batch 5/64 loss: -1.3016128540039062
Batch 6/64 loss: -1.739370346069336
Batch 7/64 loss: -1.7727446556091309
Batch 8/64 loss: -1.1789674758911133
Batch 9/64 loss: -1.9293112754821777
Batch 10/64 loss: -1.7632865905761719
Batch 11/64 loss: -1.5191097259521484
Batch 12/64 loss: -1.4583759307861328
Batch 13/64 loss: -1.4454927444458008
Batch 14/64 loss: -1.8273839950561523
Batch 15/64 loss: -1.250706672668457
Batch 16/64 loss: -1.6850557327270508
Batch 17/64 loss: -1.5610809326171875
Batch 18/64 loss: -1.4944324493408203
Batch 19/64 loss: -1.7649908065795898
Batch 20/64 loss: -1.5847587585449219
Batch 21/64 loss: -1.4225292205810547
Batch 22/64 loss: -1.163717269897461
Batch 23/64 loss: -1.4008874893188477
Batch 24/64 loss: -1.384812355041504
Batch 25/64 loss: -1.7927908897399902
Batch 26/64 loss: -1.7128844261169434
Batch 27/64 loss: -1.4013452529907227
Batch 28/64 loss: -1.5095958709716797
Batch 29/64 loss: -1.6716327667236328
Batch 30/64 loss: -1.6134614944458008
Batch 31/64 loss: -1.5898141860961914
Batch 32/64 loss: -1.4970636367797852
Batch 33/64 loss: -1.564046859741211
Batch 34/64 loss: -1.3231611251831055
Batch 35/64 loss: -1.6290416717529297
Batch 36/64 loss: -1.1926708221435547
Batch 37/64 loss: -1.7282805442810059
Batch 38/64 loss: -1.6187562942504883
Batch 39/64 loss: -1.452143669128418
Batch 40/64 loss: -1.8052406311035156
Batch 41/64 loss: -1.3043193817138672
Batch 42/64 loss: -1.7166624069213867
Batch 43/64 loss: -1.9435200691223145
Batch 44/64 loss: -1.7298088073730469
Batch 45/64 loss: -1.5431127548217773
Batch 46/64 loss: -1.4708786010742188
Batch 47/64 loss: -1.0515079498291016
Batch 48/64 loss: -1.6208572387695312
Batch 49/64 loss: -1.9680118560791016
Batch 50/64 loss: -1.9176139831542969
Batch 51/64 loss: -1.780390739440918
Batch 52/64 loss: -1.6029167175292969
Batch 53/64 loss: -1.506333351135254
Batch 54/64 loss: -1.250091552734375
Batch 55/64 loss: -1.6913442611694336
Batch 56/64 loss: -1.3253793716430664
Batch 57/64 loss: -1.304875373840332
Batch 58/64 loss: -1.8458566665649414
Batch 59/64 loss: -1.6475963592529297
Batch 60/64 loss: -1.8307561874389648
Batch 61/64 loss: -1.709981918334961
Batch 62/64 loss: -1.6821613311767578
Batch 63/64 loss: -1.8658514022827148
Batch 64/64 loss: -5.832598686218262
Epoch 269  Train loss: -1.6249802421121036  Val loss: -1.7889992101085965
Epoch 270
-------------------------------
Batch 1/64 loss: -1.6465673446655273
Batch 2/64 loss: -1.5581779479980469
Batch 3/64 loss: -1.4294939041137695
Batch 4/64 loss: -1.603424072265625
Batch 5/64 loss: -1.690230369567871
Batch 6/64 loss: -1.4311141967773438
Batch 7/64 loss: -1.5873022079467773
Batch 8/64 loss: -1.39154052734375
Batch 9/64 loss: -1.6941766738891602
Batch 10/64 loss: -1.4336795806884766
Batch 11/64 loss: -1.5503253936767578
Batch 12/64 loss: -1.6940488815307617
Batch 13/64 loss: -1.5221595764160156
Batch 14/64 loss: -1.7800178527832031
Batch 15/64 loss: -1.8546690940856934
Batch 16/64 loss: -1.473210334777832
Batch 17/64 loss: -1.8861312866210938
Batch 18/64 loss: -1.3322601318359375
Batch 19/64 loss: -1.6352510452270508
Batch 20/64 loss: -1.986356258392334
Batch 21/64 loss: -1.6240549087524414
Batch 22/64 loss: -1.6561403274536133
Batch 23/64 loss: -1.6863012313842773
Batch 24/64 loss: -1.778700828552246
Batch 25/64 loss: -1.87677001953125
Batch 26/64 loss: -1.7522478103637695
Batch 27/64 loss: -1.3970575332641602
Batch 28/64 loss: -1.7431840896606445
Batch 29/64 loss: -1.9387760162353516
Batch 30/64 loss: -1.9225997924804688
Batch 31/64 loss: -1.7459745407104492
Batch 32/64 loss: -1.5319595336914062
Batch 33/64 loss: -1.446828842163086
Batch 34/64 loss: -1.6570072174072266
Batch 35/64 loss: -1.8193159103393555
Batch 36/64 loss: -1.8841381072998047
Batch 37/64 loss: -1.8274059295654297
Batch 38/64 loss: -1.942713737487793
Batch 39/64 loss: -1.869009017944336
Batch 40/64 loss: -1.5196714401245117
Batch 41/64 loss: -1.3438968658447266
Batch 42/64 loss: -1.471461296081543
Batch 43/64 loss: -1.8297953605651855
Batch 44/64 loss: -1.5516910552978516
Batch 45/64 loss: -1.3581151962280273
Batch 46/64 loss: -1.3134479522705078
Batch 47/64 loss: -1.802469253540039
Batch 48/64 loss: -1.8319759368896484
Batch 49/64 loss: -1.7675447463989258
Batch 50/64 loss: -1.5165815353393555
Batch 51/64 loss: -1.8686256408691406
Batch 52/64 loss: -1.7510156631469727
Batch 53/64 loss: -1.4387149810791016
Batch 54/64 loss: -1.4567947387695312
Batch 55/64 loss: -1.8268918991088867
Batch 56/64 loss: -1.7627716064453125
Batch 57/64 loss: -1.3081741333007812
Batch 58/64 loss: -1.6815986633300781
Batch 59/64 loss: -1.9472684860229492
Batch 60/64 loss: -1.2636613845825195
Batch 61/64 loss: -1.4773139953613281
Batch 62/64 loss: -1.6509513854980469
Batch 63/64 loss: -1.3366470336914062
Batch 64/64 loss: -6.083696365356445
Epoch 270  Train loss: -1.69286548390108  Val loss: -1.8712064081041264
Saving best model, epoch: 270
Epoch 271
-------------------------------
Batch 1/64 loss: -1.6727094650268555
Batch 2/64 loss: -1.479623794555664
Batch 3/64 loss: -1.7232470512390137
Batch 4/64 loss: -1.8854303359985352
Batch 5/64 loss: -1.5850648880004883
Batch 6/64 loss: -1.8276863098144531
Batch 7/64 loss: -1.610316276550293
Batch 8/64 loss: -1.677647590637207
Batch 9/64 loss: -1.8235645294189453
Batch 10/64 loss: -1.797642707824707
Batch 11/64 loss: -1.4352941513061523
Batch 12/64 loss: -1.991748332977295
Batch 13/64 loss: -1.5333690643310547
Batch 14/64 loss: -1.7231035232543945
Batch 15/64 loss: -1.944798469543457
Batch 16/64 loss: -1.489863395690918
Batch 17/64 loss: -1.7474498748779297
Batch 18/64 loss: -1.8710460662841797
Batch 19/64 loss: -1.6621589660644531
Batch 20/64 loss: -1.5551033020019531
Batch 21/64 loss: -1.5464324951171875
Batch 22/64 loss: -1.5377302169799805
Batch 23/64 loss: -1.5775432586669922
Batch 24/64 loss: -1.4671735763549805
Batch 25/64 loss: -1.8060455322265625
Batch 26/64 loss: -1.2492713928222656
Batch 27/64 loss: -1.5271644592285156
Batch 28/64 loss: -1.531808853149414
Batch 29/64 loss: -0.9606723785400391
Batch 30/64 loss: -1.6945476531982422
Batch 31/64 loss: -1.3171615600585938
Batch 32/64 loss: -1.5705909729003906
Batch 33/64 loss: -1.7720913887023926
Batch 34/64 loss: -1.7532262802124023
Batch 35/64 loss: -1.505671501159668
Batch 36/64 loss: -1.6583452224731445
Batch 37/64 loss: -1.713057518005371
Batch 38/64 loss: -1.8676691055297852
Batch 39/64 loss: -1.7639598846435547
Batch 40/64 loss: -1.906783103942871
Batch 41/64 loss: -1.5614099502563477
Batch 42/64 loss: -1.4909634590148926
Batch 43/64 loss: -1.7901220321655273
Batch 44/64 loss: -1.4016404151916504
Batch 45/64 loss: -1.644434928894043
Batch 46/64 loss: -1.6676807403564453
Batch 47/64 loss: -1.8451852798461914
Batch 48/64 loss: -1.831838607788086
Batch 49/64 loss: -1.8634357452392578
Batch 50/64 loss: -1.6241226196289062
Batch 51/64 loss: -1.8710107803344727
Batch 52/64 loss: -1.2816591262817383
Batch 53/64 loss: -1.9067320823669434
Batch 54/64 loss: -1.8421111106872559
Batch 55/64 loss: -1.4401960372924805
Batch 56/64 loss: -1.642765998840332
Batch 57/64 loss: -0.8910360336303711
Batch 58/64 loss: -1.7774405479431152
Batch 59/64 loss: -1.6829557418823242
Batch 60/64 loss: -1.7710490226745605
Batch 61/64 loss: -1.378373146057129
Batch 62/64 loss: -1.8156166076660156
Batch 63/64 loss: -1.1927785873413086
Batch 64/64 loss: -5.145285129547119
Epoch 271  Train loss: -1.675879794476079  Val loss: -1.8739882400355388
Saving best model, epoch: 271
Epoch 272
-------------------------------
Batch 1/64 loss: -1.8198423385620117
Batch 2/64 loss: -1.7023687362670898
Batch 3/64 loss: -1.4596490859985352
Batch 4/64 loss: -1.603128433227539
Batch 5/64 loss: -0.9835376739501953
Batch 6/64 loss: -1.695176124572754
Batch 7/64 loss: -1.5113420486450195
Batch 8/64 loss: -1.8704538345336914
Batch 9/64 loss: -1.341782569885254
Batch 10/64 loss: -1.7076215744018555
Batch 11/64 loss: -1.618429183959961
Batch 12/64 loss: -1.3122930526733398
Batch 13/64 loss: -1.9425654411315918
Batch 14/64 loss: -1.4471921920776367
Batch 15/64 loss: -1.329422950744629
Batch 16/64 loss: -1.1179418563842773
Batch 17/64 loss: -1.6911630630493164
Batch 18/64 loss: -1.8018159866333008
Batch 19/64 loss: -1.6747422218322754
Batch 20/64 loss: -1.80596923828125
Batch 21/64 loss: -1.5336627960205078
Batch 22/64 loss: -1.8041019439697266
Batch 23/64 loss: -1.587747573852539
Batch 24/64 loss: -1.447615623474121
Batch 25/64 loss: -1.6787605285644531
Batch 26/64 loss: -1.3712396621704102
Batch 27/64 loss: -1.5946264266967773
Batch 28/64 loss: -1.8806142807006836
Batch 29/64 loss: -1.5683975219726562
Batch 30/64 loss: -1.3405570983886719
Batch 31/64 loss: -1.411468505859375
Batch 32/64 loss: -1.4390668869018555
Batch 33/64 loss: -0.9752168655395508
Batch 34/64 loss: -1.0328893661499023
Batch 35/64 loss: -1.665207862854004
Batch 36/64 loss: -1.4179282188415527
Batch 37/64 loss: -1.4245357513427734
Batch 38/64 loss: -1.3474864959716797
Batch 39/64 loss: -1.357351303100586
Batch 40/64 loss: -1.7270803451538086
Batch 41/64 loss: -1.1994037628173828
Batch 42/64 loss: -1.3620538711547852
Batch 43/64 loss: -1.5015077590942383
Batch 44/64 loss: -1.3465394973754883
Batch 45/64 loss: -1.6671199798583984
Batch 46/64 loss: -1.764573097229004
Batch 47/64 loss: -1.566537857055664
Batch 48/64 loss: -1.5323781967163086
Batch 49/64 loss: -1.2555065155029297
Batch 50/64 loss: -1.6051712036132812
Batch 51/64 loss: -1.7386064529418945
Batch 52/64 loss: -1.5844879150390625
Batch 53/64 loss: -2.0006823539733887
Batch 54/64 loss: -1.5547752380371094
Batch 55/64 loss: -1.472050666809082
Batch 56/64 loss: -1.5764141082763672
Batch 57/64 loss: -1.6418094635009766
Batch 58/64 loss: -1.6930818557739258
Batch 59/64 loss: -1.4538955688476562
Batch 60/64 loss: -1.6523876190185547
Batch 61/64 loss: -1.579838752746582
Batch 62/64 loss: -1.8392200469970703
Batch 63/64 loss: -1.8975296020507812
Batch 64/64 loss: -6.063580513000488
Epoch 272  Train loss: -1.601180383270862  Val loss: -1.6704134859170292
Epoch 273
-------------------------------
Batch 1/64 loss: -1.7921791076660156
Batch 2/64 loss: -1.670018196105957
Batch 3/64 loss: -1.470754623413086
Batch 4/64 loss: -0.5976228713989258
Batch 5/64 loss: -1.7656126022338867
Batch 6/64 loss: -1.5776443481445312
Batch 7/64 loss: -1.479604721069336
Batch 8/64 loss: -1.540024757385254
Batch 9/64 loss: -1.5616798400878906
Batch 10/64 loss: -0.8356389999389648
Batch 11/64 loss: -1.243342399597168
Batch 12/64 loss: -1.6277027130126953
Batch 13/64 loss: -1.8452520370483398
Batch 14/64 loss: -1.532608985900879
Batch 15/64 loss: -1.5976057052612305
Batch 16/64 loss: -1.5256967544555664
Batch 17/64 loss: -1.6898565292358398
Batch 18/64 loss: -1.6113348007202148
Batch 19/64 loss: -1.3071203231811523
Batch 20/64 loss: -1.701502799987793
Batch 21/64 loss: -1.5959529876708984
Batch 22/64 loss: -1.1446094512939453
Batch 23/64 loss: -1.2525568008422852
Batch 24/64 loss: -1.4539499282836914
Batch 25/64 loss: -1.4683527946472168
Batch 26/64 loss: -1.4918408393859863
Batch 27/64 loss: -1.8293695449829102
Batch 28/64 loss: -1.3528108596801758
Batch 29/64 loss: -1.2371788024902344
Batch 30/64 loss: -1.4683837890625
Batch 31/64 loss: -1.8051872253417969
Batch 32/64 loss: -1.7579026222229004
Batch 33/64 loss: -1.594944953918457
Batch 34/64 loss: -1.8267793655395508
Batch 35/64 loss: -1.692220687866211
Batch 36/64 loss: -1.6683340072631836
Batch 37/64 loss: -1.6830005645751953
Batch 38/64 loss: -1.507974624633789
Batch 39/64 loss: -1.769150733947754
Batch 40/64 loss: -1.5263919830322266
Batch 41/64 loss: -1.586411476135254
Batch 42/64 loss: -1.6849889755249023
Batch 43/64 loss: -1.6290063858032227
Batch 44/64 loss: -1.852294921875
Batch 45/64 loss: -1.5068330764770508
Batch 46/64 loss: -1.2590055465698242
Batch 47/64 loss: -1.6974601745605469
Batch 48/64 loss: -1.4875478744506836
Batch 49/64 loss: -1.6623144149780273
Batch 50/64 loss: -1.2323570251464844
Batch 51/64 loss: -1.7221131324768066
Batch 52/64 loss: -1.6920185089111328
Batch 53/64 loss: -1.5903520584106445
Batch 54/64 loss: -1.7016191482543945
Batch 55/64 loss: -1.6653318405151367
Batch 56/64 loss: -1.7170534133911133
Batch 57/64 loss: -1.4134597778320312
Batch 58/64 loss: -1.6572294235229492
Batch 59/64 loss: -1.7598810195922852
Batch 60/64 loss: -1.7878141403198242
Batch 61/64 loss: -1.2792024612426758
Batch 62/64 loss: -1.7979536056518555
Batch 63/64 loss: -1.354085922241211
Batch 64/64 loss: -5.961930751800537
Epoch 273  Train loss: -1.604823185415829  Val loss: -1.790151576405948
Epoch 274
-------------------------------
Batch 1/64 loss: -1.598836898803711
Batch 2/64 loss: -1.8565688133239746
Batch 3/64 loss: -1.5542030334472656
Batch 4/64 loss: -1.666804313659668
Batch 5/64 loss: -1.484588623046875
Batch 6/64 loss: -1.7506628036499023
Batch 7/64 loss: -1.3473100662231445
Batch 8/64 loss: -1.5927705764770508
Batch 9/64 loss: -1.4837627410888672
Batch 10/64 loss: -1.6283750534057617
Batch 11/64 loss: -1.7062358856201172
Batch 12/64 loss: -1.40594482421875
Batch 13/64 loss: -1.6646537780761719
Batch 14/64 loss: -1.8358430862426758
Batch 15/64 loss: -1.6634941101074219
Batch 16/64 loss: -1.3900957107543945
Batch 17/64 loss: -1.3984670639038086
Batch 18/64 loss: -1.380141258239746
Batch 19/64 loss: -1.7627243995666504
Batch 20/64 loss: -1.6132044792175293
Batch 21/64 loss: -2.0254106521606445
Batch 22/64 loss: -1.9459328651428223
Batch 23/64 loss: -1.3656883239746094
Batch 24/64 loss: -1.819868564605713
Batch 25/64 loss: -1.7299270629882812
Batch 26/64 loss: -1.7279596328735352
Batch 27/64 loss: -1.513742446899414
Batch 28/64 loss: -1.6747245788574219
Batch 29/64 loss: -1.7278318405151367
Batch 30/64 loss: -1.1783676147460938
Batch 31/64 loss: -1.3823413848876953
Batch 32/64 loss: -1.5162162780761719
Batch 33/64 loss: -1.6040658950805664
Batch 34/64 loss: -1.8605456352233887
Batch 35/64 loss: -1.636073112487793
Batch 36/64 loss: -1.6882610321044922
Batch 37/64 loss: -1.5093374252319336
Batch 38/64 loss: -1.8856573104858398
Batch 39/64 loss: -1.8535666465759277
Batch 40/64 loss: -1.3845748901367188
Batch 41/64 loss: -1.8112077713012695
Batch 42/64 loss: -1.680994987487793
Batch 43/64 loss: -1.6251459121704102
Batch 44/64 loss: -1.9088349342346191
Batch 45/64 loss: -1.1904096603393555
Batch 46/64 loss: -1.4829235076904297
Batch 47/64 loss: -1.4959650039672852
Batch 48/64 loss: -1.609816551208496
Batch 49/64 loss: -1.5299978256225586
Batch 50/64 loss: -1.8456907272338867
Batch 51/64 loss: -1.5504941940307617
Batch 52/64 loss: -1.8074731826782227
Batch 53/64 loss: -1.6609420776367188
Batch 54/64 loss: -1.7657403945922852
Batch 55/64 loss: -1.1124992370605469
Batch 56/64 loss: -1.6610097885131836
Batch 57/64 loss: -1.6162700653076172
Batch 58/64 loss: -1.755753517150879
Batch 59/64 loss: -1.84033203125
Batch 60/64 loss: -1.4152212142944336
Batch 61/64 loss: -1.7730388641357422
Batch 62/64 loss: -1.6383428573608398
Batch 63/64 loss: -1.363241195678711
Batch 64/64 loss: -5.535265922546387
Epoch 274  Train loss: -1.6644325592938591  Val loss: -1.7690338580469085
Epoch 275
-------------------------------
Batch 1/64 loss: -1.6210556030273438
Batch 2/64 loss: -1.8425755500793457
Batch 3/64 loss: -1.7594680786132812
Batch 4/64 loss: -1.5417537689208984
Batch 5/64 loss: -1.478377342224121
Batch 6/64 loss: -1.7308712005615234
Batch 7/64 loss: -1.5923376083374023
Batch 8/64 loss: -1.3284025192260742
Batch 9/64 loss: -1.1775407791137695
Batch 10/64 loss: -1.8258323669433594
Batch 11/64 loss: -1.5953149795532227
Batch 12/64 loss: -1.7137813568115234
Batch 13/64 loss: -1.726572036743164
Batch 14/64 loss: -1.538029670715332
Batch 15/64 loss: -1.7107467651367188
Batch 16/64 loss: -1.9093084335327148
Batch 17/64 loss: -1.7351045608520508
Batch 18/64 loss: -1.747879981994629
Batch 19/64 loss: -1.7596149444580078
Batch 20/64 loss: -1.6688728332519531
Batch 21/64 loss: -1.8681011199951172
Batch 22/64 loss: -1.9729299545288086
Batch 23/64 loss: -1.765366554260254
Batch 24/64 loss: -1.4753942489624023
Batch 25/64 loss: -1.5884981155395508
Batch 26/64 loss: -1.964818000793457
Batch 27/64 loss: -1.7415904998779297
Batch 28/64 loss: -1.7197027206420898
Batch 29/64 loss: -1.5773935317993164
Batch 30/64 loss: -2.001819133758545
Batch 31/64 loss: -1.6823348999023438
Batch 32/64 loss: -1.2341947555541992
Batch 33/64 loss: -1.4839286804199219
Batch 34/64 loss: -1.5893206596374512
Batch 35/64 loss: -1.7522258758544922
Batch 36/64 loss: -1.5400323867797852
Batch 37/64 loss: -1.589895248413086
Batch 38/64 loss: -1.7152137756347656
Batch 39/64 loss: -1.648763656616211
Batch 40/64 loss: -1.3465757369995117
Batch 41/64 loss: -1.2713146209716797
Batch 42/64 loss: -1.874161720275879
Batch 43/64 loss: -1.8285942077636719
Batch 44/64 loss: -1.1469106674194336
Batch 45/64 loss: -1.7645912170410156
Batch 46/64 loss: -1.6804828643798828
Batch 47/64 loss: -2.005690574645996
Batch 48/64 loss: -1.594456672668457
Batch 49/64 loss: -1.6912126541137695
Batch 50/64 loss: -1.326899528503418
Batch 51/64 loss: -1.8863906860351562
Batch 52/64 loss: -1.701594352722168
Batch 53/64 loss: -1.7219524383544922
Batch 54/64 loss: -1.8813138008117676
Batch 55/64 loss: -1.485086441040039
Batch 56/64 loss: -1.3928489685058594
Batch 57/64 loss: -1.4508905410766602
Batch 58/64 loss: -1.4881353378295898
Batch 59/64 loss: -1.849264144897461
Batch 60/64 loss: -1.106287956237793
Batch 61/64 loss: -1.4099607467651367
Batch 62/64 loss: -1.766993522644043
Batch 63/64 loss: -1.7222185134887695
Batch 64/64 loss: -5.0490031242370605
Epoch 275  Train loss: -1.6799301091362449  Val loss: -1.8030224436337186
Epoch 276
-------------------------------
Batch 1/64 loss: -1.8661231994628906
Batch 2/64 loss: -1.8374595642089844
Batch 3/64 loss: -1.6573944091796875
Batch 4/64 loss: -1.9043970108032227
Batch 5/64 loss: -1.7221860885620117
Batch 6/64 loss: -1.9231367111206055
Batch 7/64 loss: -1.5954408645629883
Batch 8/64 loss: -1.414815902709961
Batch 9/64 loss: -1.7831363677978516
Batch 10/64 loss: -1.6208581924438477
Batch 11/64 loss: -1.6200037002563477
Batch 12/64 loss: -1.4528474807739258
Batch 13/64 loss: -1.5713491439819336
Batch 14/64 loss: -1.8761720657348633
Batch 15/64 loss: -1.490859031677246
Batch 16/64 loss: -1.8516597747802734
Batch 17/64 loss: -1.8600826263427734
Batch 18/64 loss: -1.4185876846313477
Batch 19/64 loss: -1.3158836364746094
Batch 20/64 loss: -1.1101436614990234
Batch 21/64 loss: -1.6460390090942383
Batch 22/64 loss: -1.5537652969360352
Batch 23/64 loss: -1.5923643112182617
Batch 24/64 loss: -1.4699153900146484
Batch 25/64 loss: -1.6772079467773438
Batch 26/64 loss: -1.7229175567626953
Batch 27/64 loss: -1.630681037902832
Batch 28/64 loss: -1.9348487854003906
Batch 29/64 loss: -1.9628920555114746
Batch 30/64 loss: -1.4351072311401367
Batch 31/64 loss: -1.451314926147461
Batch 32/64 loss: -1.5082502365112305
Batch 33/64 loss: -1.6075897216796875
Batch 34/64 loss: -1.723372459411621
Batch 35/64 loss: -1.2502470016479492
Batch 36/64 loss: -1.7791719436645508
Batch 37/64 loss: -1.9181804656982422
Batch 38/64 loss: -2.0037999153137207
Batch 39/64 loss: -1.6514825820922852
Batch 40/64 loss: -1.6062240600585938
Batch 41/64 loss: -1.7896804809570312
Batch 42/64 loss: -1.9638128280639648
Batch 43/64 loss: -1.7208938598632812
Batch 44/64 loss: -1.6038928031921387
Batch 45/64 loss: -1.3423871994018555
Batch 46/64 loss: -2.082882881164551
Batch 47/64 loss: -1.7233562469482422
Batch 48/64 loss: -1.433293342590332
Batch 49/64 loss: -1.7327814102172852
Batch 50/64 loss: -1.7183904647827148
Batch 51/64 loss: -1.7791614532470703
Batch 52/64 loss: -1.7149314880371094
Batch 53/64 loss: -1.752450942993164
Batch 54/64 loss: -1.832200527191162
Batch 55/64 loss: -1.7014389038085938
Batch 56/64 loss: -1.6366405487060547
Batch 57/64 loss: -1.4660282135009766
Batch 58/64 loss: -1.635148048400879
Batch 59/64 loss: -1.6469717025756836
Batch 60/64 loss: -1.7414073944091797
Batch 61/64 loss: -2.049771308898926
Batch 62/64 loss: -1.690739631652832
Batch 63/64 loss: -1.174886703491211
Batch 64/64 loss: -5.89821195602417
Epoch 276  Train loss: -1.7156818258996103  Val loss: -1.8458333228461932
Epoch 277
-------------------------------
Batch 1/64 loss: -1.7254638671875
Batch 2/64 loss: -1.2070093154907227
Batch 3/64 loss: -1.4170503616333008
Batch 4/64 loss: -1.9891510009765625
Batch 5/64 loss: -1.4888086318969727
Batch 6/64 loss: -1.8604154586791992
Batch 7/64 loss: -1.6587591171264648
Batch 8/64 loss: -1.8375511169433594
Batch 9/64 loss: -1.523294448852539
Batch 10/64 loss: -1.5223369598388672
Batch 11/64 loss: -1.5131969451904297
Batch 12/64 loss: -1.7953758239746094
Batch 13/64 loss: -1.7304325103759766
Batch 14/64 loss: -1.8780803680419922
Batch 15/64 loss: -1.7335319519042969
Batch 16/64 loss: -1.955657958984375
Batch 17/64 loss: -1.8983335494995117
Batch 18/64 loss: -1.6381053924560547
Batch 19/64 loss: -1.5959291458129883
Batch 20/64 loss: -1.959132194519043
Batch 21/64 loss: -1.5004043579101562
Batch 22/64 loss: -1.4367170333862305
Batch 23/64 loss: -1.5383949279785156
Batch 24/64 loss: -1.439793586730957
Batch 25/64 loss: -1.5118350982666016
Batch 26/64 loss: -1.7743158340454102
Batch 27/64 loss: -1.2696447372436523
Batch 28/64 loss: -1.7944707870483398
Batch 29/64 loss: -1.248337745666504
Batch 30/64 loss: -1.8283815383911133
Batch 31/64 loss: -1.5291128158569336
Batch 32/64 loss: -1.746927261352539
Batch 33/64 loss: -1.4350214004516602
Batch 34/64 loss: -1.364933967590332
Batch 35/64 loss: -1.505457878112793
Batch 36/64 loss: -1.4072628021240234
Batch 37/64 loss: -1.9008464813232422
Batch 38/64 loss: -1.863555908203125
Batch 39/64 loss: -1.6284523010253906
Batch 40/64 loss: -1.6524267196655273
Batch 41/64 loss: -1.5526008605957031
Batch 42/64 loss: -2.002628803253174
Batch 43/64 loss: -1.2506914138793945
Batch 44/64 loss: -1.7186346054077148
Batch 45/64 loss: -1.834000587463379
Batch 46/64 loss: -1.6393041610717773
Batch 47/64 loss: -1.521632194519043
Batch 48/64 loss: -1.3046150207519531
Batch 49/64 loss: -1.8410348892211914
Batch 50/64 loss: -1.6979789733886719
Batch 51/64 loss: -1.5153923034667969
Batch 52/64 loss: -1.625199317932129
Batch 53/64 loss: -1.5196475982666016
Batch 54/64 loss: -1.5242433547973633
Batch 55/64 loss: -1.3535146713256836
Batch 56/64 loss: -1.7263126373291016
Batch 57/64 loss: -1.745173454284668
Batch 58/64 loss: -1.513758659362793
Batch 59/64 loss: -1.6371994018554688
Batch 60/64 loss: -1.1952934265136719
Batch 61/64 loss: -1.5783939361572266
Batch 62/64 loss: -1.4870624542236328
Batch 63/64 loss: -1.7233152389526367
Batch 64/64 loss: -5.363515853881836
Epoch 277  Train loss: -1.660143908332376  Val loss: -1.8016675968760067
Epoch 278
-------------------------------
Batch 1/64 loss: -1.620396614074707
Batch 2/64 loss: -1.6364545822143555
Batch 3/64 loss: -1.686507225036621
Batch 4/64 loss: -1.534696102142334
Batch 5/64 loss: -1.9689111709594727
Batch 6/64 loss: -1.960416316986084
Batch 7/64 loss: -1.8008909225463867
Batch 8/64 loss: -1.864567756652832
Batch 9/64 loss: -1.7419548034667969
Batch 10/64 loss: -1.4259471893310547
Batch 11/64 loss: -1.6939888000488281
Batch 12/64 loss: -1.7154817581176758
Batch 13/64 loss: -1.6152629852294922
Batch 14/64 loss: -1.8245697021484375
Batch 15/64 loss: -0.8669548034667969
Batch 16/64 loss: -1.5990610122680664
Batch 17/64 loss: -1.9109711647033691
Batch 18/64 loss: -1.7814445495605469
Batch 19/64 loss: -1.710230827331543
Batch 20/64 loss: -1.8128299713134766
Batch 21/64 loss: -1.619328498840332
Batch 22/64 loss: -1.492203712463379
Batch 23/64 loss: -1.5087518692016602
Batch 24/64 loss: -1.4898319244384766
Batch 25/64 loss: -1.4907751083374023
Batch 26/64 loss: -1.47906494140625
Batch 27/64 loss: -1.7482547760009766
Batch 28/64 loss: -1.561131477355957
Batch 29/64 loss: -1.4559650421142578
Batch 30/64 loss: -1.111215591430664
Batch 31/64 loss: -1.4026165008544922
Batch 32/64 loss: -1.623110294342041
Batch 33/64 loss: -1.573826789855957
Batch 34/64 loss: -1.906773567199707
Batch 35/64 loss: -1.428166389465332
Batch 36/64 loss: -1.3514118194580078
Batch 37/64 loss: -1.778106689453125
Batch 38/64 loss: -1.8769159317016602
Batch 39/64 loss: -1.8468637466430664
Batch 40/64 loss: -1.7917423248291016
Batch 41/64 loss: -1.6571931838989258
Batch 42/64 loss: -1.0100679397583008
Batch 43/64 loss: -1.7321767807006836
Batch 44/64 loss: -1.6560726165771484
Batch 45/64 loss: -1.5812606811523438
Batch 46/64 loss: -1.5749282836914062
Batch 47/64 loss: -1.7233390808105469
Batch 48/64 loss: -1.1362390518188477
Batch 49/64 loss: -1.6276540756225586
Batch 50/64 loss: -1.5754060745239258
Batch 51/64 loss: -1.7649307250976562
Batch 52/64 loss: -1.674870491027832
Batch 53/64 loss: -1.6726360321044922
Batch 54/64 loss: -1.769775390625
Batch 55/64 loss: -1.0960474014282227
Batch 56/64 loss: -1.7084894180297852
Batch 57/64 loss: -1.5493946075439453
Batch 58/64 loss: -1.4153776168823242
Batch 59/64 loss: -1.489156723022461
Batch 60/64 loss: -1.5065841674804688
Batch 61/64 loss: -1.754694938659668
Batch 62/64 loss: -1.6983308792114258
Batch 63/64 loss: -1.6313629150390625
Batch 64/64 loss: -5.800538063049316
Epoch 278  Train loss: -1.6574743196076038  Val loss: -1.6991481846550487
Epoch 279
-------------------------------
Batch 1/64 loss: -1.3659648895263672
Batch 2/64 loss: -1.7019548416137695
Batch 3/64 loss: -1.8938560485839844
Batch 4/64 loss: -1.7611637115478516
Batch 5/64 loss: -1.438405990600586
Batch 6/64 loss: -1.6326055526733398
Batch 7/64 loss: -1.5318288803100586
Batch 8/64 loss: -1.4933185577392578
Batch 9/64 loss: -1.6844472885131836
Batch 10/64 loss: -1.6716651916503906
Batch 11/64 loss: -1.2476253509521484
Batch 12/64 loss: -1.8123912811279297
Batch 13/64 loss: -1.5170812606811523
Batch 14/64 loss: -1.5607538223266602
Batch 15/64 loss: -1.961838722229004
Batch 16/64 loss: -1.7962408065795898
Batch 17/64 loss: -1.4345636367797852
Batch 18/64 loss: -1.771376609802246
Batch 19/64 loss: -1.7727861404418945
Batch 20/64 loss: -1.5988941192626953
Batch 21/64 loss: -1.4494590759277344
Batch 22/64 loss: -1.3633203506469727
Batch 23/64 loss: -1.7290678024291992
Batch 24/64 loss: -1.7756915092468262
Batch 25/64 loss: -1.746847152709961
Batch 26/64 loss: -1.5963335037231445
Batch 27/64 loss: -1.459437370300293
Batch 28/64 loss: -1.8465919494628906
Batch 29/64 loss: -1.8100175857543945
Batch 30/64 loss: -1.649174690246582
Batch 31/64 loss: -1.7426743507385254
Batch 32/64 loss: -1.2860078811645508
Batch 33/64 loss: -1.7109956741333008
Batch 34/64 loss: -1.9454665184020996
Batch 35/64 loss: -1.8051824569702148
Batch 36/64 loss: -1.6187009811401367
Batch 37/64 loss: -1.6232070922851562
Batch 38/64 loss: -1.8971772193908691
Batch 39/64 loss: -1.780202865600586
Batch 40/64 loss: -1.5437250137329102
Batch 41/64 loss: -1.3687305450439453
Batch 42/64 loss: -1.541020393371582
Batch 43/64 loss: -1.7173633575439453
Batch 44/64 loss: -1.1894397735595703
Batch 45/64 loss: -1.397994041442871
Batch 46/64 loss: -1.661703109741211
Batch 47/64 loss: -1.2872943878173828
Batch 48/64 loss: -1.5727310180664062
Batch 49/64 loss: -1.9378728866577148
Batch 50/64 loss: -1.5855016708374023
Batch 51/64 loss: -1.7239656448364258
Batch 52/64 loss: -1.3611221313476562
Batch 53/64 loss: -1.569478988647461
Batch 54/64 loss: -1.4193181991577148
Batch 55/64 loss: -1.595576286315918
Batch 56/64 loss: -1.7303218841552734
Batch 57/64 loss: -1.5292186737060547
Batch 58/64 loss: -1.613077163696289
Batch 59/64 loss: -1.6515617370605469
Batch 60/64 loss: -1.7392730712890625
Batch 61/64 loss: -1.670003890991211
Batch 62/64 loss: -1.6133623123168945
Batch 63/64 loss: -1.7929840087890625
Batch 64/64 loss: -5.276474952697754
Epoch 279  Train loss: -1.666734355103736  Val loss: -1.8495802731858086
Epoch 280
-------------------------------
Batch 1/64 loss: -1.3922491073608398
Batch 2/64 loss: -1.7231550216674805
Batch 3/64 loss: -1.6566877365112305
Batch 4/64 loss: -1.845515251159668
Batch 5/64 loss: -1.652719497680664
Batch 6/64 loss: -1.2718420028686523
Batch 7/64 loss: -1.569462776184082
Batch 8/64 loss: -1.682072639465332
Batch 9/64 loss: -1.4607744216918945
Batch 10/64 loss: -1.5689306259155273
Batch 11/64 loss: -1.7232866287231445
Batch 12/64 loss: -1.6168174743652344
Batch 13/64 loss: -1.5774602890014648
Batch 14/64 loss: -1.6144304275512695
Batch 15/64 loss: -1.8523483276367188
Batch 16/64 loss: -1.7933416366577148
Batch 17/64 loss: -1.666748046875
Batch 18/64 loss: -1.8921232223510742
Batch 19/64 loss: -1.6444549560546875
Batch 20/64 loss: -1.7146596908569336
Batch 21/64 loss: -1.7802305221557617
Batch 22/64 loss: -1.46038818359375
Batch 23/64 loss: -1.6352310180664062
Batch 24/64 loss: -1.881699562072754
Batch 25/64 loss: -1.8934087753295898
Batch 26/64 loss: -1.4036693572998047
Batch 27/64 loss: -1.8386988639831543
Batch 28/64 loss: -1.8200740814208984
Batch 29/64 loss: -1.647719383239746
Batch 30/64 loss: -1.780064582824707
Batch 31/64 loss: -1.7809271812438965
Batch 32/64 loss: -1.4656057357788086
Batch 33/64 loss: -1.9269533157348633
Batch 34/64 loss: -1.5596046447753906
Batch 35/64 loss: -1.7267179489135742
Batch 36/64 loss: -1.222172737121582
Batch 37/64 loss: -1.0370264053344727
Batch 38/64 loss: -1.6794118881225586
Batch 39/64 loss: -1.3979578018188477
Batch 40/64 loss: -1.6232376098632812
Batch 41/64 loss: -1.877699851989746
Batch 42/64 loss: -1.7579326629638672
Batch 43/64 loss: -1.5772275924682617
Batch 44/64 loss: -1.554800033569336
Batch 45/64 loss: -1.3757734298706055
Batch 46/64 loss: -1.796159267425537
Batch 47/64 loss: -0.7904720306396484
Batch 48/64 loss: -1.6450729370117188
Batch 49/64 loss: -1.7281064987182617
Batch 50/64 loss: -1.7035975456237793
Batch 51/64 loss: -1.649404525756836
Batch 52/64 loss: -1.6699552536010742
Batch 53/64 loss: -1.6285743713378906
Batch 54/64 loss: -1.5516338348388672
Batch 55/64 loss: -1.7156991958618164
Batch 56/64 loss: -1.7840147018432617
Batch 57/64 loss: -1.7389240264892578
Batch 58/64 loss: -1.6785907745361328
Batch 59/64 loss: -1.6246614456176758
Batch 60/64 loss: -1.7878341674804688
Batch 61/64 loss: -1.67095947265625
Batch 62/64 loss: -1.4609718322753906
Batch 63/64 loss: -1.1789922714233398
Batch 64/64 loss: -5.863275051116943
Epoch 280  Train loss: -1.6756767590840658  Val loss: -1.6693634347817332
Epoch 281
-------------------------------
Batch 1/64 loss: -1.5534906387329102
Batch 2/64 loss: -1.1461219787597656
Batch 3/64 loss: -1.8056221008300781
Batch 4/64 loss: -1.3440885543823242
Batch 5/64 loss: -1.6141462326049805
Batch 6/64 loss: -1.7463293075561523
Batch 7/64 loss: -1.5484552383422852
Batch 8/64 loss: -0.9648933410644531
Batch 9/64 loss: -1.533341407775879
Batch 10/64 loss: -1.780268669128418
Batch 11/64 loss: -1.7084150314331055
Batch 12/64 loss: -1.4158029556274414
Batch 13/64 loss: -1.6333560943603516
Batch 14/64 loss: -1.8533000946044922
Batch 15/64 loss: -1.5633316040039062
Batch 16/64 loss: -1.7559833526611328
Batch 17/64 loss: -1.7400741577148438
Batch 18/64 loss: -1.5795478820800781
Batch 19/64 loss: -1.1019115447998047
Batch 20/64 loss: -1.3682012557983398
Batch 21/64 loss: -1.8881292343139648
Batch 22/64 loss: -1.6908044815063477
Batch 23/64 loss: -1.579136848449707
Batch 24/64 loss: -1.5264530181884766
Batch 25/64 loss: -0.9010086059570312
Batch 26/64 loss: -1.812662124633789
Batch 27/64 loss: -1.4494390487670898
Batch 28/64 loss: -1.4645452499389648
Batch 29/64 loss: -1.6428899765014648
Batch 30/64 loss: -1.3300304412841797
Batch 31/64 loss: -1.896550178527832
Batch 32/64 loss: -1.7673749923706055
Batch 33/64 loss: -1.510676383972168
Batch 34/64 loss: -1.635930061340332
Batch 35/64 loss: -1.4309110641479492
Batch 36/64 loss: -1.7327699661254883
Batch 37/64 loss: -1.682748794555664
Batch 38/64 loss: -1.7540960311889648
Batch 39/64 loss: -1.2699499130249023
Batch 40/64 loss: -1.4327659606933594
Batch 41/64 loss: -1.443044662475586
Batch 42/64 loss: -1.7354326248168945
Batch 43/64 loss: -1.8335371017456055
Batch 44/64 loss: -1.5863037109375
Batch 45/64 loss: -1.6264762878417969
Batch 46/64 loss: -1.5090560913085938
Batch 47/64 loss: -1.3918657302856445
Batch 48/64 loss: -1.3349981307983398
Batch 49/64 loss: -1.589691162109375
Batch 50/64 loss: -1.793747901916504
Batch 51/64 loss: -1.5501995086669922
Batch 52/64 loss: -1.7672061920166016
Batch 53/64 loss: -1.601395606994629
Batch 54/64 loss: -1.456639289855957
Batch 55/64 loss: -1.360015869140625
Batch 56/64 loss: -1.7164926528930664
Batch 57/64 loss: -1.6664724349975586
Batch 58/64 loss: -1.807210922241211
Batch 59/64 loss: -1.8313817977905273
Batch 60/64 loss: -0.9929342269897461
Batch 61/64 loss: -1.9011220932006836
Batch 62/64 loss: -1.7329521179199219
Batch 63/64 loss: -1.5364818572998047
Batch 64/64 loss: -5.798131942749023
Epoch 281  Train loss: -1.6199029137106502  Val loss: -1.7883006748055266
Epoch 282
-------------------------------
Batch 1/64 loss: -1.8058233261108398
Batch 2/64 loss: -1.5507707595825195
Batch 3/64 loss: -1.5118160247802734
Batch 4/64 loss: -1.634866714477539
Batch 5/64 loss: -1.6238861083984375
Batch 6/64 loss: -1.3893604278564453
Batch 7/64 loss: -1.7092781066894531
Batch 8/64 loss: -1.5980730056762695
Batch 9/64 loss: -1.7271490097045898
Batch 10/64 loss: -1.6641502380371094
Batch 11/64 loss: -1.6535959243774414
Batch 12/64 loss: -1.881993293762207
Batch 13/64 loss: -1.7331304550170898
Batch 14/64 loss: -1.9260540008544922
Batch 15/64 loss: -1.6249656677246094
Batch 16/64 loss: -1.9454741477966309
Batch 17/64 loss: -2.0016379356384277
Batch 18/64 loss: -1.647806167602539
Batch 19/64 loss: -1.935201644897461
Batch 20/64 loss: -2.007431983947754
Batch 21/64 loss: -1.4625320434570312
Batch 22/64 loss: -1.3469123840332031
Batch 23/64 loss: -1.848318099975586
Batch 24/64 loss: -1.640202522277832
Batch 25/64 loss: -1.649118423461914
Batch 26/64 loss: -1.918696403503418
Batch 27/64 loss: -1.2047615051269531
Batch 28/64 loss: -1.511775016784668
Batch 29/64 loss: -1.5267248153686523
Batch 30/64 loss: -1.4951543807983398
Batch 31/64 loss: -1.6272087097167969
Batch 32/64 loss: -1.8012590408325195
Batch 33/64 loss: -1.6765375137329102
Batch 34/64 loss: -1.7188339233398438
Batch 35/64 loss: -1.4112415313720703
Batch 36/64 loss: -1.814828872680664
Batch 37/64 loss: -1.6675758361816406
Batch 38/64 loss: -1.090022087097168
Batch 39/64 loss: -1.5829906463623047
Batch 40/64 loss: -1.6539850234985352
Batch 41/64 loss: -1.6949234008789062
Batch 42/64 loss: -1.4722843170166016
Batch 43/64 loss: -1.6087760925292969
Batch 44/64 loss: -1.7401294708251953
Batch 45/64 loss: -1.4371042251586914
Batch 46/64 loss: -1.6051025390625
Batch 47/64 loss: -1.3015365600585938
Batch 48/64 loss: -1.8198661804199219
Batch 49/64 loss: -1.5670967102050781
Batch 50/64 loss: -1.7932462692260742
Batch 51/64 loss: -1.4744434356689453
Batch 52/64 loss: -1.4820337295532227
Batch 53/64 loss: -1.5565929412841797
Batch 54/64 loss: -1.1081428527832031
Batch 55/64 loss: -1.8035602569580078
Batch 56/64 loss: -1.5294189453125
Batch 57/64 loss: -1.7000436782836914
Batch 58/64 loss: -1.3946199417114258
Batch 59/64 loss: -1.859537124633789
Batch 60/64 loss: -1.6383724212646484
Batch 61/64 loss: -1.242325782775879
Batch 62/64 loss: -1.8875360488891602
Batch 63/64 loss: -1.0411434173583984
Batch 64/64 loss: -5.523691177368164
Epoch 282  Train loss: -1.6646548776065602  Val loss: -1.8238200813634289
Epoch 283
-------------------------------
Batch 1/64 loss: -1.5044660568237305
Batch 2/64 loss: -1.1445684432983398
Batch 3/64 loss: -1.6524810791015625
Batch 4/64 loss: -1.7615470886230469
Batch 5/64 loss: -1.5048513412475586
Batch 6/64 loss: -1.471665382385254
Batch 7/64 loss: -1.3850317001342773
Batch 8/64 loss: -1.705021858215332
Batch 9/64 loss: -1.7023258209228516
Batch 10/64 loss: -1.73052978515625
Batch 11/64 loss: -2.016219139099121
Batch 12/64 loss: -1.459054946899414
Batch 13/64 loss: -1.097712516784668
Batch 14/64 loss: -1.747340202331543
Batch 15/64 loss: -1.6204967498779297
Batch 16/64 loss: -1.5711193084716797
Batch 17/64 loss: -1.5203733444213867
Batch 18/64 loss: -1.671809196472168
Batch 19/64 loss: -1.9096088409423828
Batch 20/64 loss: -1.6109237670898438
Batch 21/64 loss: -1.3842487335205078
Batch 22/64 loss: -1.6746807098388672
Batch 23/64 loss: -1.6858110427856445
Batch 24/64 loss: -1.5148134231567383
Batch 25/64 loss: -1.5678339004516602
Batch 26/64 loss: -1.58056640625
Batch 27/64 loss: -1.7217674255371094
Batch 28/64 loss: -1.589569091796875
Batch 29/64 loss: -1.7967405319213867
Batch 30/64 loss: -1.5698261260986328
Batch 31/64 loss: -1.6796865463256836
Batch 32/64 loss: -1.6429901123046875
Batch 33/64 loss: -0.8995628356933594
Batch 34/64 loss: -1.5401725769042969
Batch 35/64 loss: -1.6885395050048828
Batch 36/64 loss: -1.0492334365844727
Batch 37/64 loss: -1.7827777862548828
Batch 38/64 loss: -1.5835561752319336
Batch 39/64 loss: -1.8253393173217773
Batch 40/64 loss: -1.6435203552246094
Batch 41/64 loss: -1.7384681701660156
Batch 42/64 loss: -1.511434555053711
Batch 43/64 loss: -1.0956945419311523
Batch 44/64 loss: -1.8056020736694336
Batch 45/64 loss: -1.8208580017089844
Batch 46/64 loss: -1.9775714874267578
Batch 47/64 loss: -1.6703681945800781
Batch 48/64 loss: -1.9377069473266602
Batch 49/64 loss: -1.6899738311767578
Batch 50/64 loss: -1.9323792457580566
Batch 51/64 loss: -1.1178741455078125
Batch 52/64 loss: -1.890608787536621
Batch 53/64 loss: -1.5007152557373047
Batch 54/64 loss: -1.7130327224731445
Batch 55/64 loss: -1.3344297409057617
Batch 56/64 loss: -1.7691621780395508
Batch 57/64 loss: -1.451216697692871
Batch 58/64 loss: -1.4469661712646484
Batch 59/64 loss: -1.7075214385986328
Batch 60/64 loss: -1.5017709732055664
Batch 61/64 loss: -1.544663429260254
Batch 62/64 loss: -1.7219533920288086
Batch 63/64 loss: -1.8122014999389648
Batch 64/64 loss: -5.923131465911865
Epoch 283  Train loss: -1.6524377205792595  Val loss: -1.875664989563198
Saving best model, epoch: 283
Epoch 284
-------------------------------
Batch 1/64 loss: -1.4836235046386719
Batch 2/64 loss: -1.7954635620117188
Batch 3/64 loss: -1.8437776565551758
Batch 4/64 loss: -1.8497390747070312
Batch 5/64 loss: -1.6483163833618164
Batch 6/64 loss: -1.3203716278076172
Batch 7/64 loss: -1.5190868377685547
Batch 8/64 loss: -1.6156425476074219
Batch 9/64 loss: -1.467860221862793
Batch 10/64 loss: -1.215780258178711
Batch 11/64 loss: -1.3679313659667969
Batch 12/64 loss: -1.6539535522460938
Batch 13/64 loss: -1.4003009796142578
Batch 14/64 loss: -1.2343549728393555
Batch 15/64 loss: -1.5150136947631836
Batch 16/64 loss: -1.498504638671875
Batch 17/64 loss: -1.4104852676391602
Batch 18/64 loss: -1.3184728622436523
Batch 19/64 loss: -1.575277328491211
Batch 20/64 loss: -1.4288673400878906
Batch 21/64 loss: -1.6589317321777344
Batch 22/64 loss: -1.7826247215270996
Batch 23/64 loss: -1.8424830436706543
Batch 24/64 loss: -1.8043231964111328
Batch 25/64 loss: -1.7451972961425781
Batch 26/64 loss: -1.9305830001831055
Batch 27/64 loss: -1.5986137390136719
Batch 28/64 loss: -1.9154367446899414
Batch 29/64 loss: -1.431401252746582
Batch 30/64 loss: -1.8366594314575195
Batch 31/64 loss: -1.9204554557800293
Batch 32/64 loss: -1.4538888931274414
Batch 33/64 loss: -1.716012954711914
Batch 34/64 loss: -1.9202232360839844
Batch 35/64 loss: -0.9639739990234375
Batch 36/64 loss: -1.6307954788208008
Batch 37/64 loss: -1.5966730117797852
Batch 38/64 loss: -1.762603759765625
Batch 39/64 loss: -1.381779670715332
Batch 40/64 loss: -1.9030351638793945
Batch 41/64 loss: -1.1217231750488281
Batch 42/64 loss: -1.5363950729370117
Batch 43/64 loss: -1.5747270584106445
Batch 44/64 loss: -1.7037038803100586
Batch 45/64 loss: -1.4063262939453125
Batch 46/64 loss: -1.623152732849121
Batch 47/64 loss: -1.7927684783935547
Batch 48/64 loss: -1.5868310928344727
Batch 49/64 loss: -1.6796903610229492
Batch 50/64 loss: -1.1118812561035156
Batch 51/64 loss: -1.8761157989501953
Batch 52/64 loss: -1.597712516784668
Batch 53/64 loss: -1.5458126068115234
Batch 54/64 loss: -1.5827322006225586
Batch 55/64 loss: -1.4670448303222656
Batch 56/64 loss: -1.5901851654052734
Batch 57/64 loss: -0.9383316040039062
Batch 58/64 loss: -1.7935681343078613
Batch 59/64 loss: -1.8405752182006836
Batch 60/64 loss: -1.768174171447754
Batch 61/64 loss: -1.5102415084838867
Batch 62/64 loss: -1.7677135467529297
Batch 63/64 loss: -1.3143291473388672
Batch 64/64 loss: -6.023044586181641
Epoch 284  Train loss: -1.6345966862697228  Val loss: -1.8035850131634585
Epoch 285
-------------------------------
Batch 1/64 loss: -1.8414220809936523
Batch 2/64 loss: -1.4249982833862305
Batch 3/64 loss: -1.868821144104004
Batch 4/64 loss: -1.1797819137573242
Batch 5/64 loss: -1.6669330596923828
Batch 6/64 loss: -1.6113901138305664
Batch 7/64 loss: -1.8892922401428223
Batch 8/64 loss: -1.4143295288085938
Batch 9/64 loss: -1.8337717056274414
Batch 10/64 loss: -1.7592458724975586
Batch 11/64 loss: -1.6551971435546875
Batch 12/64 loss: -1.5428104400634766
Batch 13/64 loss: -1.7458992004394531
Batch 14/64 loss: -1.6843547821044922
Batch 15/64 loss: -1.4017829895019531
Batch 16/64 loss: -1.5085906982421875
Batch 17/64 loss: -1.4941282272338867
Batch 18/64 loss: -1.995633602142334
Batch 19/64 loss: -1.6378135681152344
Batch 20/64 loss: -1.5195016860961914
Batch 21/64 loss: -1.5986528396606445
Batch 22/64 loss: -1.1498470306396484
Batch 23/64 loss: -1.878000259399414
Batch 24/64 loss: -1.6082220077514648
Batch 25/64 loss: -1.8315386772155762
Batch 26/64 loss: -1.8457159996032715
Batch 27/64 loss: -1.1211376190185547
Batch 28/64 loss: -1.941568374633789
Batch 29/64 loss: -1.5493106842041016
Batch 30/64 loss: -1.4696779251098633
Batch 31/64 loss: -1.8833284378051758
Batch 32/64 loss: -1.6399602890014648
Batch 33/64 loss: -1.7640976905822754
Batch 34/64 loss: -1.8335752487182617
Batch 35/64 loss: -1.4871587753295898
Batch 36/64 loss: -1.6867485046386719
Batch 37/64 loss: -1.9027457237243652
Batch 38/64 loss: -1.848527431488037
Batch 39/64 loss: -1.5781278610229492
Batch 40/64 loss: -1.1514816284179688
Batch 41/64 loss: -1.8780674934387207
Batch 42/64 loss: -1.4865808486938477
Batch 43/64 loss: -1.4302854537963867
Batch 44/64 loss: -1.4891233444213867
Batch 45/64 loss: -1.3174819946289062
Batch 46/64 loss: -1.4931373596191406
Batch 47/64 loss: -1.5797052383422852
Batch 48/64 loss: -1.3873834609985352
Batch 49/64 loss: -1.7002983093261719
Batch 50/64 loss: -1.5748863220214844
Batch 51/64 loss: -1.3987598419189453
Batch 52/64 loss: -1.3973093032836914
Batch 53/64 loss: -1.7571115493774414
Batch 54/64 loss: -1.4570446014404297
Batch 55/64 loss: -1.9685392379760742
Batch 56/64 loss: -1.470759391784668
Batch 57/64 loss: -1.6442899703979492
Batch 58/64 loss: -1.0909910202026367
Batch 59/64 loss: -1.6344490051269531
Batch 60/64 loss: -1.4929943084716797
Batch 61/64 loss: -1.498779296875
Batch 62/64 loss: -1.488377571105957
Batch 63/64 loss: -1.6469974517822266
Batch 64/64 loss: -6.0471649169921875
Epoch 285  Train loss: -1.6511976055070465  Val loss: -1.9036373780765075
Saving best model, epoch: 285
Epoch 286
-------------------------------
Batch 1/64 loss: -1.8138322830200195
Batch 2/64 loss: -1.551025390625
Batch 3/64 loss: -1.4819879531860352
Batch 4/64 loss: -1.5546255111694336
Batch 5/64 loss: -1.964489459991455
Batch 6/64 loss: -1.7837276458740234
Batch 7/64 loss: -1.766779899597168
Batch 8/64 loss: -1.583725929260254
Batch 9/64 loss: -1.622675895690918
Batch 10/64 loss: -1.4340314865112305
Batch 11/64 loss: -1.3080558776855469
Batch 12/64 loss: -1.7665958404541016
Batch 13/64 loss: -1.636549949645996
Batch 14/64 loss: -1.5273075103759766
Batch 15/64 loss: -1.852248191833496
Batch 16/64 loss: -1.620161533355713
Batch 17/64 loss: -1.4828405380249023
Batch 18/64 loss: -1.7080230712890625
Batch 19/64 loss: -1.6240968704223633
Batch 20/64 loss: -1.909510612487793
Batch 21/64 loss: -1.5833148956298828
Batch 22/64 loss: -1.731762409210205
Batch 23/64 loss: -1.8838253021240234
Batch 24/64 loss: -1.821146011352539
Batch 25/64 loss: -1.5430421829223633
Batch 26/64 loss: -2.0525693893432617
Batch 27/64 loss: -1.6800384521484375
Batch 28/64 loss: -1.302755355834961
Batch 29/64 loss: -1.5266056060791016
Batch 30/64 loss: -1.643000602722168
Batch 31/64 loss: -1.897221565246582
Batch 32/64 loss: -1.520613670349121
Batch 33/64 loss: -1.5993728637695312
Batch 34/64 loss: -1.5256290435791016
Batch 35/64 loss: -1.827610969543457
Batch 36/64 loss: -1.6177949905395508
Batch 37/64 loss: -1.980499267578125
Batch 38/64 loss: -1.553126335144043
Batch 39/64 loss: -1.8068060874938965
Batch 40/64 loss: -1.337550163269043
Batch 41/64 loss: -1.3262205123901367
Batch 42/64 loss: -1.788264274597168
Batch 43/64 loss: -1.7259492874145508
Batch 44/64 loss: -1.4498014450073242
Batch 45/64 loss: -1.5733718872070312
Batch 46/64 loss: -1.7329511642456055
Batch 47/64 loss: -1.598923683166504
Batch 48/64 loss: -1.7805414199829102
Batch 49/64 loss: -1.8145594596862793
Batch 50/64 loss: -1.6390466690063477
Batch 51/64 loss: -1.9829092025756836
Batch 52/64 loss: -1.5325841903686523
Batch 53/64 loss: -1.4888992309570312
Batch 54/64 loss: -1.4387073516845703
Batch 55/64 loss: -1.8893909454345703
Batch 56/64 loss: -1.4769840240478516
Batch 57/64 loss: -1.5303974151611328
Batch 58/64 loss: -2.089358329772949
Batch 59/64 loss: -1.395655632019043
Batch 60/64 loss: -1.8405885696411133
Batch 61/64 loss: -1.6257104873657227
Batch 62/64 loss: -1.8409538269042969
Batch 63/64 loss: -1.9278345108032227
Batch 64/64 loss: -5.805960655212402
Epoch 286  Train loss: -1.7140494215722177  Val loss: -1.8325923251122544
Epoch 287
-------------------------------
Batch 1/64 loss: -1.7180747985839844
Batch 2/64 loss: -1.617161750793457
Batch 3/64 loss: -1.5718088150024414
Batch 4/64 loss: -1.7923259735107422
Batch 5/64 loss: -1.5779218673706055
Batch 6/64 loss: -1.817488670349121
Batch 7/64 loss: -1.7021093368530273
Batch 8/64 loss: -1.8275299072265625
Batch 9/64 loss: -1.7262248992919922
Batch 10/64 loss: -1.787245750427246
Batch 11/64 loss: -1.9303808212280273
Batch 12/64 loss: -1.4501056671142578
Batch 13/64 loss: -1.486318588256836
Batch 14/64 loss: -1.582747459411621
Batch 15/64 loss: -1.6692943572998047
Batch 16/64 loss: -1.8999223709106445
Batch 17/64 loss: -1.4410409927368164
Batch 18/64 loss: -1.6850171089172363
Batch 19/64 loss: -1.4829893112182617
Batch 20/64 loss: -1.894643783569336
Batch 21/64 loss: -1.7251777648925781
Batch 22/64 loss: -1.7586631774902344
Batch 23/64 loss: -1.9211416244506836
Batch 24/64 loss: -1.8664360046386719
Batch 25/64 loss: -1.5774469375610352
Batch 26/64 loss: -1.7348003387451172
Batch 27/64 loss: -1.6788396835327148
Batch 28/64 loss: -1.2672901153564453
Batch 29/64 loss: -1.5163631439208984
Batch 30/64 loss: -1.7048091888427734
Batch 31/64 loss: -1.842294692993164
Batch 32/64 loss: -1.6902341842651367
Batch 33/64 loss: -1.5018854141235352
Batch 34/64 loss: -1.63946533203125
Batch 35/64 loss: -1.720231056213379
Batch 36/64 loss: -1.8148441314697266
Batch 37/64 loss: -1.8222341537475586
Batch 38/64 loss: -1.548415184020996
Batch 39/64 loss: -1.6913566589355469
Batch 40/64 loss: -1.666499137878418
Batch 41/64 loss: -1.574082374572754
Batch 42/64 loss: -1.9041337966918945
Batch 43/64 loss: -1.8811969757080078
Batch 44/64 loss: -1.4970579147338867
Batch 45/64 loss: -1.016683578491211
Batch 46/64 loss: -1.4474334716796875
Batch 47/64 loss: -1.497950553894043
Batch 48/64 loss: -1.7910537719726562
Batch 49/64 loss: -1.4004249572753906
Batch 50/64 loss: -1.779862403869629
Batch 51/64 loss: -1.8090648651123047
Batch 52/64 loss: -1.5474157333374023
Batch 53/64 loss: -1.7285690307617188
Batch 54/64 loss: -1.768662452697754
Batch 55/64 loss: -1.824040412902832
Batch 56/64 loss: -1.771204948425293
Batch 57/64 loss: -1.3103656768798828
Batch 58/64 loss: -1.1650867462158203
Batch 59/64 loss: -1.663987159729004
Batch 60/64 loss: -1.626387596130371
Batch 61/64 loss: -1.7828483581542969
Batch 62/64 loss: -1.6778669357299805
Batch 63/64 loss: -1.78277587890625
Batch 64/64 loss: -5.759227752685547
Epoch 287  Train loss: -1.7084918676638137  Val loss: -1.8234351902073602
Epoch 288
-------------------------------
Batch 1/64 loss: -1.9705047607421875
Batch 2/64 loss: -1.7812166213989258
Batch 3/64 loss: -1.7076139450073242
Batch 4/64 loss: -1.8358416557312012
Batch 5/64 loss: -1.540933609008789
Batch 6/64 loss: -1.3563079833984375
Batch 7/64 loss: -1.7397699356079102
Batch 8/64 loss: -1.8892288208007812
Batch 9/64 loss: -1.5774946212768555
Batch 10/64 loss: -1.774043083190918
Batch 11/64 loss: -1.5363025665283203
Batch 12/64 loss: -1.460679054260254
Batch 13/64 loss: -1.735459327697754
Batch 14/64 loss: -1.8394842147827148
Batch 15/64 loss: -1.8760242462158203
Batch 16/64 loss: -1.6594934463500977
Batch 17/64 loss: -1.5970706939697266
Batch 18/64 loss: -1.784867286682129
Batch 19/64 loss: -1.7298145294189453
Batch 20/64 loss: -1.1159906387329102
Batch 21/64 loss: -1.7976903915405273
Batch 22/64 loss: -1.653106689453125
Batch 23/64 loss: -1.873189926147461
Batch 24/64 loss: -1.4707841873168945
Batch 25/64 loss: -1.6038398742675781
Batch 26/64 loss: -1.7306771278381348
Batch 27/64 loss: -1.8565101623535156
Batch 28/64 loss: -1.967355728149414
Batch 29/64 loss: -1.4698705673217773
Batch 30/64 loss: -1.659658432006836
Batch 31/64 loss: -1.5793142318725586
Batch 32/64 loss: -1.6590147018432617
Batch 33/64 loss: -1.6607308387756348
Batch 34/64 loss: -1.7862663269042969
Batch 35/64 loss: -1.7482481002807617
Batch 36/64 loss: -1.8875107765197754
Batch 37/64 loss: -1.690016746520996
Batch 38/64 loss: -1.7543630599975586
Batch 39/64 loss: -1.5814523696899414
Batch 40/64 loss: -1.6877059936523438
Batch 41/64 loss: -1.3626623153686523
Batch 42/64 loss: -1.5882377624511719
Batch 43/64 loss: -1.5009841918945312
Batch 44/64 loss: -1.6790103912353516
Batch 45/64 loss: -1.831075668334961
Batch 46/64 loss: -1.1656522750854492
Batch 47/64 loss: -1.7763452529907227
Batch 48/64 loss: -1.4500961303710938
Batch 49/64 loss: -1.818166732788086
Batch 50/64 loss: -1.7666645050048828
Batch 51/64 loss: -1.540907859802246
Batch 52/64 loss: -1.3237037658691406
Batch 53/64 loss: -2.0038604736328125
Batch 54/64 loss: -1.810617446899414
Batch 55/64 loss: -1.8893518447875977
Batch 56/64 loss: -1.595881462097168
Batch 57/64 loss: -1.8354549407958984
Batch 58/64 loss: -1.9243860244750977
Batch 59/64 loss: -1.8476381301879883
Batch 60/64 loss: -1.8157930374145508
Batch 61/64 loss: -1.7840776443481445
Batch 62/64 loss: -1.7191057205200195
Batch 63/64 loss: -1.290419578552246
Batch 64/64 loss: -5.287478446960449
Epoch 288  Train loss: -1.7240964590334424  Val loss: -1.8696040517276096
Epoch 289
-------------------------------
Batch 1/64 loss: -1.6611547470092773
Batch 2/64 loss: -1.890542984008789
Batch 3/64 loss: -1.4067602157592773
Batch 4/64 loss: -1.8073968887329102
Batch 5/64 loss: -0.9963493347167969
Batch 6/64 loss: -1.8124618530273438
Batch 7/64 loss: -1.5722455978393555
Batch 8/64 loss: -1.6465587615966797
Batch 9/64 loss: -1.539794921875
Batch 10/64 loss: -1.5758695602416992
Batch 11/64 loss: -1.904393196105957
Batch 12/64 loss: -1.4267921447753906
Batch 13/64 loss: -1.4034290313720703
Batch 14/64 loss: -1.5900449752807617
Batch 15/64 loss: -1.966409683227539
Batch 16/64 loss: -1.2309045791625977
Batch 17/64 loss: -1.7334794998168945
Batch 18/64 loss: -1.9672932624816895
Batch 19/64 loss: -1.6294927597045898
Batch 20/64 loss: -1.918199062347412
Batch 21/64 loss: -1.9691262245178223
Batch 22/64 loss: -1.6066112518310547
Batch 23/64 loss: -1.7315654754638672
Batch 24/64 loss: -1.9324016571044922
Batch 25/64 loss: -1.4758224487304688
Batch 26/64 loss: -1.3025579452514648
Batch 27/64 loss: -1.86932373046875
Batch 28/64 loss: -1.7248773574829102
Batch 29/64 loss: -1.6526212692260742
Batch 30/64 loss: -1.7858352661132812
Batch 31/64 loss: -1.6970586776733398
Batch 32/64 loss: -1.8800907135009766
Batch 33/64 loss: -1.458073616027832
Batch 34/64 loss: -1.3825664520263672
Batch 35/64 loss: -1.6848258972167969
Batch 36/64 loss: -1.7386274337768555
Batch 37/64 loss: -1.5169668197631836
Batch 38/64 loss: -1.6231107711791992
Batch 39/64 loss: -1.7827301025390625
Batch 40/64 loss: -1.708078384399414
Batch 41/64 loss: -1.7176103591918945
Batch 42/64 loss: -1.4037160873413086
Batch 43/64 loss: -1.385538101196289
Batch 44/64 loss: -1.540755271911621
Batch 45/64 loss: -1.5414304733276367
Batch 46/64 loss: -1.6939563751220703
Batch 47/64 loss: -1.5472908020019531
Batch 48/64 loss: -1.834451675415039
Batch 49/64 loss: -1.6949281692504883
Batch 50/64 loss: -1.1624717712402344
Batch 51/64 loss: -1.691655158996582
Batch 52/64 loss: -1.503108024597168
Batch 53/64 loss: -1.705491065979004
Batch 54/64 loss: -1.3008508682250977
Batch 55/64 loss: -1.4891490936279297
Batch 56/64 loss: -1.5346546173095703
Batch 57/64 loss: -1.391615867614746
Batch 58/64 loss: -1.6763172149658203
Batch 59/64 loss: -1.804396629333496
Batch 60/64 loss: -1.5859556198120117
Batch 61/64 loss: -1.2830286026000977
Batch 62/64 loss: -1.7456989288330078
Batch 63/64 loss: -1.7389020919799805
Batch 64/64 loss: -5.943031311035156
Epoch 289  Train loss: -1.672669661278818  Val loss: -1.6857128733212186
Epoch 290
-------------------------------
Batch 1/64 loss: -1.7071075439453125
Batch 2/64 loss: -1.7398414611816406
Batch 3/64 loss: -1.376368522644043
Batch 4/64 loss: -1.613173484802246
Batch 5/64 loss: -1.763596534729004
Batch 6/64 loss: -1.5003395080566406
Batch 7/64 loss: -1.8789567947387695
Batch 8/64 loss: -1.9354653358459473
Batch 9/64 loss: -1.7496681213378906
Batch 10/64 loss: -1.9730138778686523
Batch 11/64 loss: -1.6864585876464844
Batch 12/64 loss: -1.5064287185668945
Batch 13/64 loss: -1.6502552032470703
Batch 14/64 loss: -1.845834732055664
Batch 15/64 loss: -1.5702705383300781
Batch 16/64 loss: -1.5925655364990234
Batch 17/64 loss: -1.6480493545532227
Batch 18/64 loss: -1.5542793273925781
Batch 19/64 loss: -1.5216550827026367
Batch 20/64 loss: -1.9276304244995117
Batch 21/64 loss: -1.345907211303711
Batch 22/64 loss: -1.8032712936401367
Batch 23/64 loss: -1.6497154235839844
Batch 24/64 loss: -1.6123781204223633
Batch 25/64 loss: -1.864344596862793
Batch 26/64 loss: -1.6957159042358398
Batch 27/64 loss: -1.6856517791748047
Batch 28/64 loss: -1.229339599609375
Batch 29/64 loss: -1.3331527709960938
Batch 30/64 loss: -1.8807239532470703
Batch 31/64 loss: -1.7502222061157227
Batch 32/64 loss: -1.504918098449707
Batch 33/64 loss: -1.6441736221313477
Batch 34/64 loss: -1.7894301414489746
Batch 35/64 loss: -1.5986518859863281
Batch 36/64 loss: -1.5746650695800781
Batch 37/64 loss: -1.8871879577636719
Batch 38/64 loss: -1.486989974975586
Batch 39/64 loss: -1.6907997131347656
Batch 40/64 loss: -1.6195087432861328
Batch 41/64 loss: -1.497117042541504
Batch 42/64 loss: -1.827219009399414
Batch 43/64 loss: -1.7661590576171875
Batch 44/64 loss: -1.8337535858154297
Batch 45/64 loss: -1.4459342956542969
Batch 46/64 loss: -1.8158502578735352
Batch 47/64 loss: -1.5700445175170898
Batch 48/64 loss: -1.7050590515136719
Batch 49/64 loss: -1.5682497024536133
Batch 50/64 loss: -1.9328112602233887
Batch 51/64 loss: -1.3621025085449219
Batch 52/64 loss: -1.9545917510986328
Batch 53/64 loss: -0.9541749954223633
Batch 54/64 loss: -1.8837366104125977
Batch 55/64 loss: -1.62516450881958
Batch 56/64 loss: -1.6432924270629883
Batch 57/64 loss: -1.5499458312988281
Batch 58/64 loss: -1.6758842468261719
Batch 59/64 loss: -1.7462806701660156
Batch 60/64 loss: -1.4764947891235352
Batch 61/64 loss: -1.6687040328979492
Batch 62/64 loss: -1.5270357131958008
Batch 63/64 loss: -1.723769187927246
Batch 64/64 loss: -5.564506530761719
Epoch 290  Train loss: -1.6990503797344132  Val loss: -1.689420457558124
Epoch 291
-------------------------------
Batch 1/64 loss: -1.3528690338134766
Batch 2/64 loss: -1.8070802688598633
Batch 3/64 loss: -1.6009140014648438
Batch 4/64 loss: -1.9954910278320312
Batch 5/64 loss: -1.6924138069152832
Batch 6/64 loss: -1.7276930809020996
Batch 7/64 loss: -1.8305177688598633
Batch 8/64 loss: -1.907789707183838
Batch 9/64 loss: -1.8080596923828125
Batch 10/64 loss: -1.8512887954711914
Batch 11/64 loss: -1.7380337715148926
Batch 12/64 loss: -1.985243797302246
Batch 13/64 loss: -1.6933488845825195
Batch 14/64 loss: -0.9669857025146484
Batch 15/64 loss: -1.672844409942627
Batch 16/64 loss: -1.6327838897705078
Batch 17/64 loss: -1.5877923965454102
Batch 18/64 loss: -1.5575895309448242
Batch 19/64 loss: -1.561044692993164
Batch 20/64 loss: -1.6291131973266602
Batch 21/64 loss: -1.6840791702270508
Batch 22/64 loss: -1.7889137268066406
Batch 23/64 loss: -1.7034521102905273
Batch 24/64 loss: -1.7341670989990234
Batch 25/64 loss: -1.9330968856811523
Batch 26/64 loss: -1.6372756958007812
Batch 27/64 loss: -1.5435981750488281
Batch 28/64 loss: -1.820887565612793
Batch 29/64 loss: -1.5524702072143555
Batch 30/64 loss: -1.297755241394043
Batch 31/64 loss: -1.6776466369628906
Batch 32/64 loss: -1.6985998153686523
Batch 33/64 loss: -1.4720134735107422
Batch 34/64 loss: -1.6787853240966797
Batch 35/64 loss: -1.6251835823059082
Batch 36/64 loss: -2.033773422241211
Batch 37/64 loss: -1.37640380859375
Batch 38/64 loss: -1.8627033233642578
Batch 39/64 loss: -1.544053077697754
Batch 40/64 loss: -1.6738901138305664
Batch 41/64 loss: -1.6463804244995117
Batch 42/64 loss: -1.770730972290039
Batch 43/64 loss: -1.336380958557129
Batch 44/64 loss: -1.8592824935913086
Batch 45/64 loss: -1.8059511184692383
Batch 46/64 loss: -1.7390365600585938
Batch 47/64 loss: -1.679152488708496
Batch 48/64 loss: -1.9152154922485352
Batch 49/64 loss: -1.8447866439819336
Batch 50/64 loss: -1.8673524856567383
Batch 51/64 loss: -1.3203325271606445
Batch 52/64 loss: -1.3249225616455078
Batch 53/64 loss: -2.0593528747558594
Batch 54/64 loss: -1.662459373474121
Batch 55/64 loss: -1.6969366073608398
Batch 56/64 loss: -1.6932382583618164
Batch 57/64 loss: -1.516922950744629
Batch 58/64 loss: -1.4293146133422852
Batch 59/64 loss: -1.7726860046386719
Batch 60/64 loss: -1.0621414184570312
Batch 61/64 loss: -1.7613487243652344
Batch 62/64 loss: -1.7914800643920898
Batch 63/64 loss: -1.5858097076416016
Batch 64/64 loss: -5.872391223907471
Epoch 291  Train loss: -1.717382818109849  Val loss: -1.926153438607442
Saving best model, epoch: 291
Epoch 292
-------------------------------
Batch 1/64 loss: -1.7140874862670898
Batch 2/64 loss: -1.5676679611206055
Batch 3/64 loss: -1.7685623168945312
Batch 4/64 loss: -1.7654085159301758
Batch 5/64 loss: -1.465165138244629
Batch 6/64 loss: -1.8246002197265625
Batch 7/64 loss: -1.6578197479248047
Batch 8/64 loss: -1.8645238876342773
Batch 9/64 loss: -1.7110090255737305
Batch 10/64 loss: -1.9288721084594727
Batch 11/64 loss: -1.751699447631836
Batch 12/64 loss: -1.8069639205932617
Batch 13/64 loss: -1.7881927490234375
Batch 14/64 loss: -1.3509893417358398
Batch 15/64 loss: -1.8737659454345703
Batch 16/64 loss: -1.8784542083740234
Batch 17/64 loss: -1.6961030960083008
Batch 18/64 loss: -1.949228286743164
Batch 19/64 loss: -1.5242128372192383
Batch 20/64 loss: -1.801985740661621
Batch 21/64 loss: -1.6729192733764648
Batch 22/64 loss: -1.8672513961791992
Batch 23/64 loss: -1.9619288444519043
Batch 24/64 loss: -1.755265235900879
Batch 25/64 loss: -1.5573749542236328
Batch 26/64 loss: -1.7083473205566406
Batch 27/64 loss: -1.6672019958496094
Batch 28/64 loss: -1.651780128479004
Batch 29/64 loss: -1.3768606185913086
Batch 30/64 loss: -1.5144195556640625
Batch 31/64 loss: -1.330078125
Batch 32/64 loss: -1.5559320449829102
Batch 33/64 loss: -1.954026222229004
Batch 34/64 loss: -1.8412237167358398
Batch 35/64 loss: -1.7095813751220703
Batch 36/64 loss: -1.8436479568481445
Batch 37/64 loss: -1.9158124923706055
Batch 38/64 loss: -1.6683807373046875
Batch 39/64 loss: -1.7597227096557617
Batch 40/64 loss: -1.437234878540039
Batch 41/64 loss: -1.738163948059082
Batch 42/64 loss: -1.527949333190918
Batch 43/64 loss: -1.5989837646484375
Batch 44/64 loss: -1.2228565216064453
Batch 45/64 loss: -1.6429319381713867
Batch 46/64 loss: -1.7713031768798828
Batch 47/64 loss: -1.668839454650879
Batch 48/64 loss: -1.880171775817871
Batch 49/64 loss: -1.6095657348632812
Batch 50/64 loss: -1.7655916213989258
Batch 51/64 loss: -1.8578472137451172
Batch 52/64 loss: -1.9068927764892578
Batch 53/64 loss: -1.610865592956543
Batch 54/64 loss: -1.7332754135131836
Batch 55/64 loss: -1.9549412727355957
Batch 56/64 loss: -1.3776416778564453
Batch 57/64 loss: -1.6016731262207031
Batch 58/64 loss: -1.5085926055908203
Batch 59/64 loss: -1.565114974975586
Batch 60/64 loss: -1.6091423034667969
Batch 61/64 loss: -1.9346704483032227
Batch 62/64 loss: -1.7234668731689453
Batch 63/64 loss: -1.4491987228393555
Batch 64/64 loss: -5.582456588745117
Epoch 292  Train loss: -1.7393697925642424  Val loss: -1.9543320829516013
Saving best model, epoch: 292
Epoch 293
-------------------------------
Batch 1/64 loss: -1.9049220085144043
Batch 2/64 loss: -1.3386507034301758
Batch 3/64 loss: -1.7568378448486328
Batch 4/64 loss: -1.8563008308410645
Batch 5/64 loss: -1.8249311447143555
Batch 6/64 loss: -1.8614697456359863
Batch 7/64 loss: -0.8741350173950195
Batch 8/64 loss: -1.6200408935546875
Batch 9/64 loss: -1.517134666442871
Batch 10/64 loss: -1.8222837448120117
Batch 11/64 loss: -1.7513408660888672
Batch 12/64 loss: -1.9173355102539062
Batch 13/64 loss: -1.970602035522461
Batch 14/64 loss: -1.8389253616333008
Batch 15/64 loss: -1.7110118865966797
Batch 16/64 loss: -1.7028923034667969
Batch 17/64 loss: -1.879903793334961
Batch 18/64 loss: -1.7664813995361328
Batch 19/64 loss: -1.7322454452514648
Batch 20/64 loss: -1.6868925094604492
Batch 21/64 loss: -1.5868711471557617
Batch 22/64 loss: -1.9768686294555664
Batch 23/64 loss: -1.790308952331543
Batch 24/64 loss: -1.8585338592529297
Batch 25/64 loss: -1.4456453323364258
Batch 26/64 loss: -1.3127193450927734
Batch 27/64 loss: -1.9196481704711914
Batch 28/64 loss: -1.9507255554199219
Batch 29/64 loss: -1.786137580871582
Batch 30/64 loss: -1.5899524688720703
Batch 31/64 loss: -1.822702407836914
Batch 32/64 loss: -1.7913408279418945
Batch 33/64 loss: -1.6212263107299805
Batch 34/64 loss: -1.2995166778564453
Batch 35/64 loss: -1.3535737991333008
Batch 36/64 loss: -1.8263931274414062
Batch 37/64 loss: -1.564101219177246
Batch 38/64 loss: -1.9680709838867188
Batch 39/64 loss: -1.4696950912475586
Batch 40/64 loss: -1.8182086944580078
Batch 41/64 loss: -1.6197242736816406
Batch 42/64 loss: -1.4853582382202148
Batch 43/64 loss: -1.7138500213623047
Batch 44/64 loss: -1.8762731552124023
Batch 45/64 loss: -1.9621391296386719
Batch 46/64 loss: -1.3494081497192383
Batch 47/64 loss: -1.9698309898376465
Batch 48/64 loss: -1.6801557540893555
Batch 49/64 loss: -1.8237857818603516
Batch 50/64 loss: -1.218001365661621
Batch 51/64 loss: -1.388472557067871
Batch 52/64 loss: -1.630141258239746
Batch 53/64 loss: -1.7952919006347656
Batch 54/64 loss: -1.662729263305664
Batch 55/64 loss: -1.2618436813354492
Batch 56/64 loss: -1.5119895935058594
Batch 57/64 loss: -1.8130712509155273
Batch 58/64 loss: -1.81514310836792
Batch 59/64 loss: -1.3274860382080078
Batch 60/64 loss: -1.8865032196044922
Batch 61/64 loss: -1.5811176300048828
Batch 62/64 loss: -1.602426528930664
Batch 63/64 loss: -1.5660104751586914
Batch 64/64 loss: -5.812167167663574
Epoch 293  Train loss: -1.7252777510998296  Val loss: -1.8635268850424855
Epoch 294
-------------------------------
Batch 1/64 loss: -1.5707788467407227
Batch 2/64 loss: -2.037281036376953
Batch 3/64 loss: -1.4571189880371094
Batch 4/64 loss: -1.9525012969970703
Batch 5/64 loss: -1.6658086776733398
Batch 6/64 loss: -1.423457145690918
Batch 7/64 loss: -1.5880403518676758
Batch 8/64 loss: -1.7061433792114258
Batch 9/64 loss: -1.5632524490356445
Batch 10/64 loss: -1.6632413864135742
Batch 11/64 loss: -1.3918371200561523
Batch 12/64 loss: -1.8770418167114258
Batch 13/64 loss: -1.389617919921875
Batch 14/64 loss: -1.9199953079223633
Batch 15/64 loss: -1.9555768966674805
Batch 16/64 loss: -1.9060516357421875
Batch 17/64 loss: -1.7227764129638672
Batch 18/64 loss: -1.1139402389526367
Batch 19/64 loss: -1.8765201568603516
Batch 20/64 loss: -1.8664493560791016
Batch 21/64 loss: -1.737320899963379
Batch 22/64 loss: -1.5774850845336914
Batch 23/64 loss: -1.7375316619873047
Batch 24/64 loss: -0.9807300567626953
Batch 25/64 loss: -1.5750350952148438
Batch 26/64 loss: -1.6466007232666016
Batch 27/64 loss: -1.7495384216308594
Batch 28/64 loss: -1.7983036041259766
Batch 29/64 loss: -1.177271842956543
Batch 30/64 loss: -1.845871925354004
Batch 31/64 loss: -1.1560192108154297
Batch 32/64 loss: -1.4261865615844727
Batch 33/64 loss: -1.8764352798461914
Batch 34/64 loss: -1.6108837127685547
Batch 35/64 loss: -1.955225944519043
Batch 36/64 loss: -1.268763542175293
Batch 37/64 loss: -1.8270244598388672
Batch 38/64 loss: -1.326080322265625
Batch 39/64 loss: -1.5391817092895508
Batch 40/64 loss: -1.5386018753051758
Batch 41/64 loss: -1.39459228515625
Batch 42/64 loss: -1.8858356475830078
Batch 43/64 loss: -1.7405576705932617
Batch 44/64 loss: -1.6294317245483398
Batch 45/64 loss: -1.5907001495361328
Batch 46/64 loss: -1.8900628089904785
Batch 47/64 loss: -1.7422451972961426
Batch 48/64 loss: -1.6529645919799805
Batch 49/64 loss: -1.7799053192138672
Batch 50/64 loss: -1.889261245727539
Batch 51/64 loss: -1.6295337677001953
Batch 52/64 loss: -1.4551782608032227
Batch 53/64 loss: -1.8498811721801758
Batch 54/64 loss: -1.4786911010742188
Batch 55/64 loss: -1.7398757934570312
Batch 56/64 loss: -1.8162336349487305
Batch 57/64 loss: -1.9092063903808594
Batch 58/64 loss: -1.8507022857666016
Batch 59/64 loss: -1.4131717681884766
Batch 60/64 loss: -1.853499412536621
Batch 61/64 loss: -1.8930339813232422
Batch 62/64 loss: -1.4902915954589844
Batch 63/64 loss: -1.5893030166625977
Batch 64/64 loss: -5.9434967041015625
Epoch 294  Train loss: -1.7038322149538527  Val loss: -1.857730078942997
Epoch 295
-------------------------------
Batch 1/64 loss: -1.7052106857299805
Batch 2/64 loss: -1.7811098098754883
Batch 3/64 loss: -1.775792121887207
Batch 4/64 loss: -1.7501049041748047
Batch 5/64 loss: -1.8275995254516602
Batch 6/64 loss: -1.5748224258422852
Batch 7/64 loss: -1.4265403747558594
Batch 8/64 loss: -1.8678169250488281
Batch 9/64 loss: -1.3668241500854492
Batch 10/64 loss: -1.8859753608703613
Batch 11/64 loss: -1.4062223434448242
Batch 12/64 loss: -1.8713817596435547
Batch 13/64 loss: -1.5404729843139648
Batch 14/64 loss: -1.8186044692993164
Batch 15/64 loss: -1.5379276275634766
Batch 16/64 loss: -1.925765037536621
Batch 17/64 loss: -1.1641740798950195
Batch 18/64 loss: -1.486678123474121
Batch 19/64 loss: -1.9578704833984375
Batch 20/64 loss: -1.5940179824829102
Batch 21/64 loss: -1.7760210037231445
Batch 22/64 loss: -1.7290573120117188
Batch 23/64 loss: -1.5794992446899414
Batch 24/64 loss: -1.5413551330566406
Batch 25/64 loss: -1.7146339416503906
Batch 26/64 loss: -1.8962326049804688
Batch 27/64 loss: -1.6572070121765137
Batch 28/64 loss: -1.8014211654663086
Batch 29/64 loss: -1.8204970359802246
Batch 30/64 loss: -1.836202621459961
Batch 31/64 loss: -1.6268539428710938
Batch 32/64 loss: -1.6242303848266602
Batch 33/64 loss: -1.7167882919311523
Batch 34/64 loss: -1.6982812881469727
Batch 35/64 loss: -1.946669578552246
Batch 36/64 loss: -1.6221590042114258
Batch 37/64 loss: -1.6366605758666992
Batch 38/64 loss: -1.6758708953857422
Batch 39/64 loss: -1.5560302734375
Batch 40/64 loss: -1.8618249893188477
Batch 41/64 loss: -1.5644397735595703
Batch 42/64 loss: -1.8939971923828125
Batch 43/64 loss: -1.3438806533813477
Batch 44/64 loss: -1.6341800689697266
Batch 45/64 loss: -1.5592374801635742
Batch 46/64 loss: -1.8349113464355469
Batch 47/64 loss: -1.723306655883789
Batch 48/64 loss: -1.7540521621704102
Batch 49/64 loss: -1.6686086654663086
Batch 50/64 loss: -1.8737287521362305
Batch 51/64 loss: -1.642496109008789
Batch 52/64 loss: -1.1195259094238281
Batch 53/64 loss: -1.5538902282714844
Batch 54/64 loss: -1.7395315170288086
Batch 55/64 loss: -1.6511564254760742
Batch 56/64 loss: -1.734130859375
Batch 57/64 loss: -1.4717330932617188
Batch 58/64 loss: -1.7065773010253906
Batch 59/64 loss: -1.684260368347168
Batch 60/64 loss: -1.6600494384765625
Batch 61/64 loss: -1.6447372436523438
Batch 62/64 loss: -1.6666145324707031
Batch 63/64 loss: -1.7532453536987305
Batch 64/64 loss: -5.3823418617248535
Epoch 295  Train loss: -1.7176071372686648  Val loss: -1.8351700379676426
Epoch 296
-------------------------------
Batch 1/64 loss: -1.8888311386108398
Batch 2/64 loss: -1.675307273864746
Batch 3/64 loss: -1.6213350296020508
Batch 4/64 loss: -1.9042224884033203
Batch 5/64 loss: -1.831711769104004
Batch 6/64 loss: -1.5422239303588867
Batch 7/64 loss: -1.7694940567016602
Batch 8/64 loss: -1.6359491348266602
Batch 9/64 loss: -1.5502004623413086
Batch 10/64 loss: -1.919865608215332
Batch 11/64 loss: -1.9858694076538086
Batch 12/64 loss: -1.020033836364746
Batch 13/64 loss: -1.3397912979125977
Batch 14/64 loss: -1.68536376953125
Batch 15/64 loss: -1.2893924713134766
Batch 16/64 loss: -1.5999784469604492
Batch 17/64 loss: -1.6682510375976562
Batch 18/64 loss: -1.669844627380371
Batch 19/64 loss: -1.889805793762207
Batch 20/64 loss: -1.603525161743164
Batch 21/64 loss: -1.4791698455810547
Batch 22/64 loss: -1.7403430938720703
Batch 23/64 loss: -1.8561010360717773
Batch 24/64 loss: -1.6930856704711914
Batch 25/64 loss: -1.8803091049194336
Batch 26/64 loss: -1.7686882019042969
Batch 27/64 loss: -1.4732770919799805
Batch 28/64 loss: -1.5431442260742188
Batch 29/64 loss: -1.6125593185424805
Batch 30/64 loss: -1.7229223251342773
Batch 31/64 loss: -1.218709945678711
Batch 32/64 loss: -1.4213018417358398
Batch 33/64 loss: -1.5945897102355957
Batch 34/64 loss: -1.7500438690185547
Batch 35/64 loss: -1.6230487823486328
Batch 36/64 loss: -1.7813777923583984
Batch 37/64 loss: -1.9468135833740234
Batch 38/64 loss: -1.4250736236572266
Batch 39/64 loss: -1.3112173080444336
Batch 40/64 loss: -1.213022232055664
Batch 41/64 loss: -1.6432867050170898
Batch 42/64 loss: -1.9802632331848145
Batch 43/64 loss: -1.125300407409668
Batch 44/64 loss: -1.7445859909057617
Batch 45/64 loss: -1.6540346145629883
Batch 46/64 loss: -1.699915885925293
Batch 47/64 loss: -1.497849464416504
Batch 48/64 loss: -1.7663984298706055
Batch 49/64 loss: -1.4321556091308594
Batch 50/64 loss: -1.6615686416625977
Batch 51/64 loss: -1.3659276962280273
Batch 52/64 loss: -1.8121795654296875
Batch 53/64 loss: -1.475992202758789
Batch 54/64 loss: -1.5708837509155273
Batch 55/64 loss: -1.5252761840820312
Batch 56/64 loss: -1.3107452392578125
Batch 57/64 loss: -1.7338428497314453
Batch 58/64 loss: -1.6579084396362305
Batch 59/64 loss: -1.6480865478515625
Batch 60/64 loss: -1.3913030624389648
Batch 61/64 loss: -1.6455621719360352
Batch 62/64 loss: -1.6893548965454102
Batch 63/64 loss: -1.4732084274291992
Batch 64/64 loss: -5.813767433166504
Epoch 296  Train loss: -1.6629294264550303  Val loss: -1.7951900049583198
Epoch 297
-------------------------------
Batch 1/64 loss: -1.8191986083984375
Batch 2/64 loss: -1.455214500427246
Batch 3/64 loss: -1.4837465286254883
Batch 4/64 loss: -1.6027231216430664
Batch 5/64 loss: -1.3643646240234375
Batch 6/64 loss: -1.5240869522094727
Batch 7/64 loss: -1.7675962448120117
Batch 8/64 loss: -1.9130735397338867
Batch 9/64 loss: -1.8760595321655273
Batch 10/64 loss: -1.7509641647338867
Batch 11/64 loss: -1.703714370727539
Batch 12/64 loss: -1.8664474487304688
Batch 13/64 loss: -1.937584400177002
Batch 14/64 loss: -1.2039995193481445
Batch 15/64 loss: -1.8152227401733398
Batch 16/64 loss: -1.731679916381836
Batch 17/64 loss: -1.3135061264038086
Batch 18/64 loss: -1.3557872772216797
Batch 19/64 loss: -1.584620475769043
Batch 20/64 loss: -2.0039877891540527
Batch 21/64 loss: -1.524155616760254
Batch 22/64 loss: -1.7517833709716797
Batch 23/64 loss: -1.7565536499023438
Batch 24/64 loss: -1.4153156280517578
Batch 25/64 loss: -1.7918014526367188
Batch 26/64 loss: -1.6785221099853516
Batch 27/64 loss: -1.8042116165161133
Batch 28/64 loss: -1.2757844924926758
Batch 29/64 loss: -1.6120719909667969
Batch 30/64 loss: -1.6389083862304688
Batch 31/64 loss: -1.9919180870056152
Batch 32/64 loss: -1.7011966705322266
Batch 33/64 loss: -1.8694171905517578
Batch 34/64 loss: -1.742152214050293
Batch 35/64 loss: -1.6257963180541992
Batch 36/64 loss: -1.5130796432495117
Batch 37/64 loss: -1.8225021362304688
Batch 38/64 loss: -1.6086463928222656
Batch 39/64 loss: -1.5716896057128906
Batch 40/64 loss: -1.5369043350219727
Batch 41/64 loss: -1.723567008972168
Batch 42/64 loss: -1.8730568885803223
Batch 43/64 loss: -1.5322265625
Batch 44/64 loss: -1.34796142578125
Batch 45/64 loss: -1.8208436965942383
Batch 46/64 loss: -1.5776891708374023
Batch 47/64 loss: -1.356985092163086
Batch 48/64 loss: -1.3937597274780273
Batch 49/64 loss: -1.8160161972045898
Batch 50/64 loss: -1.3883953094482422
Batch 51/64 loss: -1.7073898315429688
Batch 52/64 loss: -1.4032068252563477
Batch 53/64 loss: -1.705122947692871
Batch 54/64 loss: -1.8183746337890625
Batch 55/64 loss: -1.52203369140625
Batch 56/64 loss: -1.977830410003662
Batch 57/64 loss: -1.7654838562011719
Batch 58/64 loss: -1.9140291213989258
Batch 59/64 loss: -1.7605581283569336
Batch 60/64 loss: -1.8390655517578125
Batch 61/64 loss: -1.7128820419311523
Batch 62/64 loss: -1.785262107849121
Batch 63/64 loss: -1.8397331237792969
Batch 64/64 loss: -5.817712783813477
Epoch 297  Train loss: -1.7137372035606235  Val loss: -1.8839291838026537
Epoch 298
-------------------------------
Batch 1/64 loss: -1.7351789474487305
Batch 2/64 loss: -1.642608642578125
Batch 3/64 loss: -1.874678611755371
Batch 4/64 loss: -1.7526588439941406
Batch 5/64 loss: -1.6899423599243164
Batch 6/64 loss: -1.317601203918457
Batch 7/64 loss: -1.7246942520141602
Batch 8/64 loss: -1.7416553497314453
Batch 9/64 loss: -1.7279644012451172
Batch 10/64 loss: -1.7953672409057617
Batch 11/64 loss: -1.5115928649902344
Batch 12/64 loss: -1.5692787170410156
Batch 13/64 loss: -1.9004931449890137
Batch 14/64 loss: -1.612950325012207
Batch 15/64 loss: -1.5081863403320312
Batch 16/64 loss: -1.5794963836669922
Batch 17/64 loss: -1.6270198822021484
Batch 18/64 loss: -1.6774206161499023
Batch 19/64 loss: -1.3603954315185547
Batch 20/64 loss: -1.739518165588379
Batch 21/64 loss: -1.734431266784668
Batch 22/64 loss: -1.528371810913086
Batch 23/64 loss: -1.8864059448242188
Batch 24/64 loss: -1.944441795349121
Batch 25/64 loss: -1.8557381629943848
Batch 26/64 loss: -1.5697832107543945
Batch 27/64 loss: -1.7218389511108398
Batch 28/64 loss: -1.8559856414794922
Batch 29/64 loss: -1.6218299865722656
Batch 30/64 loss: -1.9287900924682617
Batch 31/64 loss: -1.7248387336730957
Batch 32/64 loss: -1.6762008666992188
Batch 33/64 loss: -1.4776687622070312
Batch 34/64 loss: -1.848393440246582
Batch 35/64 loss: -1.7361993789672852
Batch 36/64 loss: -1.8224468231201172
Batch 37/64 loss: -1.5923223495483398
Batch 38/64 loss: -1.8230633735656738
Batch 39/64 loss: -1.733809471130371
Batch 40/64 loss: -1.8856611251831055
Batch 41/64 loss: -1.6001853942871094
Batch 42/64 loss: -2.0280375480651855
Batch 43/64 loss: -1.7672977447509766
Batch 44/64 loss: -1.7839946746826172
Batch 45/64 loss: -1.393986701965332
Batch 46/64 loss: -1.9679656028747559
Batch 47/64 loss: -1.6880683898925781
Batch 48/64 loss: -1.0266342163085938
Batch 49/64 loss: -1.800370216369629
Batch 50/64 loss: -1.784663200378418
Batch 51/64 loss: -1.819814682006836
Batch 52/64 loss: -1.6770057678222656
Batch 53/64 loss: -1.6772871017456055
Batch 54/64 loss: -1.9238920211791992
Batch 55/64 loss: -1.8474664688110352
Batch 56/64 loss: -1.4781408309936523
Batch 57/64 loss: -1.074549674987793
Batch 58/64 loss: -1.9165592193603516
Batch 59/64 loss: -1.5342988967895508
Batch 60/64 loss: -1.703352928161621
Batch 61/64 loss: -1.643265724182129
Batch 62/64 loss: -1.9052481651306152
Batch 63/64 loss: -1.796889305114746
Batch 64/64 loss: -5.721576690673828
Epoch 298  Train loss: -1.7441110573562921  Val loss: -1.968391654417687
Saving best model, epoch: 298
Epoch 299
-------------------------------
Batch 1/64 loss: -1.5209083557128906
Batch 2/64 loss: -1.9089317321777344
Batch 3/64 loss: -1.9833550453186035
Batch 4/64 loss: -1.7425355911254883
Batch 5/64 loss: -1.8553800582885742
Batch 6/64 loss: -1.6031913757324219
Batch 7/64 loss: -1.7807884216308594
Batch 8/64 loss: -1.542496681213379
Batch 9/64 loss: -1.7555322647094727
Batch 10/64 loss: -1.6160402297973633
Batch 11/64 loss: -1.4856042861938477
Batch 12/64 loss: -1.7334423065185547
Batch 13/64 loss: -1.334869384765625
Batch 14/64 loss: -1.9625730514526367
Batch 15/64 loss: -1.5759735107421875
Batch 16/64 loss: -1.6896190643310547
Batch 17/64 loss: -1.8794474601745605
Batch 18/64 loss: -1.8781929016113281
Batch 19/64 loss: -1.6299324035644531
Batch 20/64 loss: -1.6124982833862305
Batch 21/64 loss: -1.7084035873413086
Batch 22/64 loss: -1.518702507019043
Batch 23/64 loss: -1.7401752471923828
Batch 24/64 loss: -1.8227276802062988
Batch 25/64 loss: -1.6132316589355469
Batch 26/64 loss: -1.5830516815185547
Batch 27/64 loss: -1.7806406021118164
Batch 28/64 loss: -1.6898717880249023
Batch 29/64 loss: -1.3645076751708984
Batch 30/64 loss: -1.8352928161621094
Batch 31/64 loss: -1.9653592109680176
Batch 32/64 loss: -1.8234643936157227
Batch 33/64 loss: -1.594146728515625
Batch 34/64 loss: -1.5353021621704102
Batch 35/64 loss: -1.8029813766479492
Batch 36/64 loss: -1.6593399047851562
Batch 37/64 loss: -1.7620697021484375
Batch 38/64 loss: -1.622751235961914
Batch 39/64 loss: -1.3755245208740234
Batch 40/64 loss: -1.152608871459961
Batch 41/64 loss: -1.6181774139404297
Batch 42/64 loss: -1.4588003158569336
Batch 43/64 loss: -1.842005729675293
Batch 44/64 loss: -1.1431083679199219
Batch 45/64 loss: -1.4488153457641602
Batch 46/64 loss: -1.5231409072875977
Batch 47/64 loss: -1.7005033493041992
Batch 48/64 loss: -1.5705604553222656
Batch 49/64 loss: -1.6569337844848633
Batch 50/64 loss: -1.5452699661254883
Batch 51/64 loss: -1.930006980895996
Batch 52/64 loss: -1.8670320510864258
Batch 53/64 loss: -1.358572006225586
Batch 54/64 loss: -2.0699286460876465
Batch 55/64 loss: -1.4328985214233398
Batch 56/64 loss: -1.6903939247131348
Batch 57/64 loss: -2.103181838989258
Batch 58/64 loss: -1.657801628112793
Batch 59/64 loss: -1.7440271377563477
Batch 60/64 loss: -1.8363723754882812
Batch 61/64 loss: -1.7798385620117188
Batch 62/64 loss: -1.0146636962890625
Batch 63/64 loss: -1.8895273208618164
Batch 64/64 loss: -5.992990970611572
Epoch 299  Train loss: -1.7163571656918992  Val loss: -1.8895416390854878
Epoch 300
-------------------------------
Batch 1/64 loss: -1.852224349975586
Batch 2/64 loss: -1.5175132751464844
Batch 3/64 loss: -1.3070287704467773
Batch 4/64 loss: -1.7173376083374023
Batch 5/64 loss: -1.7032699584960938
Batch 6/64 loss: -2.0820059776306152
Batch 7/64 loss: -1.8748435974121094
Batch 8/64 loss: -1.818643569946289
Batch 9/64 loss: -1.5407638549804688
Batch 10/64 loss: -1.8319683074951172
Batch 11/64 loss: -1.6442766189575195
Batch 12/64 loss: -1.8217906951904297
Batch 13/64 loss: -1.1988162994384766
Batch 14/64 loss: -1.8141393661499023
Batch 15/64 loss: -1.8953394889831543
Batch 16/64 loss: -1.7681818008422852
Batch 17/64 loss: -1.6251487731933594
Batch 18/64 loss: -1.6812982559204102
Batch 19/64 loss: -1.873281478881836
Batch 20/64 loss: -1.331721305847168
Batch 21/64 loss: -1.0689077377319336
Batch 22/64 loss: -1.2399063110351562
Batch 23/64 loss: -1.2745590209960938
Batch 24/64 loss: -1.5189695358276367
Batch 25/64 loss: -1.403183937072754
Batch 26/64 loss: -1.511946678161621
Batch 27/64 loss: -1.3581304550170898
Batch 28/64 loss: -1.2925434112548828
Batch 29/64 loss: -1.4616689682006836
Batch 30/64 loss: -1.4374122619628906
Batch 31/64 loss: -1.5710153579711914
Batch 32/64 loss: -1.453017234802246
Batch 33/64 loss: -1.3136463165283203
Batch 34/64 loss: -1.4943609237670898
Batch 35/64 loss: -1.4767866134643555
Batch 36/64 loss: -1.7201261520385742
Batch 37/64 loss: -1.5480289459228516
Batch 38/64 loss: -1.5581159591674805
Batch 39/64 loss: -1.3315248489379883
Batch 40/64 loss: -1.661585807800293
Batch 41/64 loss: -1.2574243545532227
Batch 42/64 loss: -1.5065298080444336
Batch 43/64 loss: -1.4940710067749023
Batch 44/64 loss: -1.297184944152832
Batch 45/64 loss: -1.662740707397461
Batch 46/64 loss: -1.5954933166503906
Batch 47/64 loss: -1.3949260711669922
Batch 48/64 loss: -1.5744457244873047
Batch 49/64 loss: -1.5463838577270508
Batch 50/64 loss: -1.5238275527954102
Batch 51/64 loss: -1.1982879638671875
Batch 52/64 loss: -1.678849220275879
Batch 53/64 loss: -1.4155845642089844
Batch 54/64 loss: -1.7227964401245117
Batch 55/64 loss: -1.4942502975463867
Batch 56/64 loss: -1.7745046615600586
Batch 57/64 loss: -1.4620590209960938
Batch 58/64 loss: -1.5585346221923828
Batch 59/64 loss: -1.744558334350586
Batch 60/64 loss: -1.4857501983642578
Batch 61/64 loss: -1.3676700592041016
Batch 62/64 loss: -1.6234588623046875
Batch 63/64 loss: -1.9708976745605469
Batch 64/64 loss: -5.690343856811523
Epoch 300  Train loss: -1.603341442930932  Val loss: -1.8027670686597268
Epoch 301
-------------------------------
Batch 1/64 loss: -1.63897705078125
Batch 2/64 loss: -1.7110490798950195
Batch 3/64 loss: -1.7949342727661133
Batch 4/64 loss: -2.001615047454834
Batch 5/64 loss: -1.552694320678711
Batch 6/64 loss: -1.5940475463867188
Batch 7/64 loss: -1.701369285583496
Batch 8/64 loss: -1.5793590545654297
Batch 9/64 loss: -1.618398666381836
Batch 10/64 loss: -1.6306514739990234
Batch 11/64 loss: -1.5014362335205078
Batch 12/64 loss: -1.783635139465332
Batch 13/64 loss: -1.6375055313110352
Batch 14/64 loss: -1.5132122039794922
Batch 15/64 loss: -1.5055713653564453
Batch 16/64 loss: -1.8211612701416016
Batch 17/64 loss: -1.7751922607421875
Batch 18/64 loss: -1.5713014602661133
Batch 19/64 loss: -1.6035652160644531
Batch 20/64 loss: -1.9141712188720703
Batch 21/64 loss: -1.8609342575073242
Batch 22/64 loss: -1.3965940475463867
Batch 23/64 loss: -1.8797426223754883
Batch 24/64 loss: -1.7030448913574219
Batch 25/64 loss: -1.802957534790039
Batch 26/64 loss: -1.7430133819580078
Batch 27/64 loss: -1.5519781112670898
Batch 28/64 loss: -1.779226303100586
Batch 29/64 loss: -1.8095769882202148
Batch 30/64 loss: -1.9312372207641602
Batch 31/64 loss: -1.523946762084961
Batch 32/64 loss: -1.3938474655151367
Batch 33/64 loss: -1.5651416778564453
Batch 34/64 loss: -1.8304510116577148
Batch 35/64 loss: -1.9061765670776367
Batch 36/64 loss: -0.9839611053466797
Batch 37/64 loss: -1.96474027633667
Batch 38/64 loss: -1.1216907501220703
Batch 39/64 loss: -1.90277099609375
Batch 40/64 loss: -1.494370460510254
Batch 41/64 loss: -1.8512158393859863
Batch 42/64 loss: -1.6488628387451172
Batch 43/64 loss: -1.3972740173339844
Batch 44/64 loss: -1.4164791107177734
Batch 45/64 loss: -1.768587589263916
Batch 46/64 loss: -1.5174169540405273
Batch 47/64 loss: -1.872481346130371
Batch 48/64 loss: -2.0584163665771484
Batch 49/64 loss: -1.4197940826416016
Batch 50/64 loss: -1.2721271514892578
Batch 51/64 loss: -1.801468849182129
Batch 52/64 loss: -1.9446401596069336
Batch 53/64 loss: -1.316619873046875
Batch 54/64 loss: -1.751657485961914
Batch 55/64 loss: -1.8345823287963867
Batch 56/64 loss: -1.8349061012268066
Batch 57/64 loss: -1.755058765411377
Batch 58/64 loss: -1.6961145401000977
Batch 59/64 loss: -1.5659351348876953
Batch 60/64 loss: -1.829244613647461
Batch 61/64 loss: -1.7418766021728516
Batch 62/64 loss: -2.0657095909118652
Batch 63/64 loss: -1.7213191986083984
Batch 64/64 loss: -5.952861309051514
Epoch 301  Train loss: -1.7277127004137227  Val loss: -1.9870579906345642
Saving best model, epoch: 301
Epoch 302
-------------------------------
Batch 1/64 loss: -1.807558536529541
Batch 2/64 loss: -1.7738895416259766
Batch 3/64 loss: -1.613865852355957
Batch 4/64 loss: -1.802469253540039
Batch 5/64 loss: -2.0856881141662598
Batch 6/64 loss: -1.8345966339111328
Batch 7/64 loss: -1.8027687072753906
Batch 8/64 loss: -1.8246803283691406
Batch 9/64 loss: -1.8153982162475586
Batch 10/64 loss: -1.924565315246582
Batch 11/64 loss: -1.5381889343261719
Batch 12/64 loss: -1.8333377838134766
Batch 13/64 loss: -1.885941505432129
Batch 14/64 loss: -1.7470650672912598
Batch 15/64 loss: -1.8989477157592773
Batch 16/64 loss: -1.8967056274414062
Batch 17/64 loss: -1.5639381408691406
Batch 18/64 loss: -1.7633914947509766
Batch 19/64 loss: -1.3980140686035156
Batch 20/64 loss: -1.7609310150146484
Batch 21/64 loss: -1.6632623672485352
Batch 22/64 loss: -1.9064288139343262
Batch 23/64 loss: -1.8967432975769043
Batch 24/64 loss: -1.885267734527588
Batch 25/64 loss: -1.9002470970153809
Batch 26/64 loss: -1.5334787368774414
Batch 27/64 loss: -1.6364021301269531
Batch 28/64 loss: -1.9560022354125977
Batch 29/64 loss: -1.6639976501464844
Batch 30/64 loss: -1.686446189880371
Batch 31/64 loss: -1.519805908203125
Batch 32/64 loss: -1.832540512084961
Batch 33/64 loss: -1.8002872467041016
Batch 34/64 loss: -1.5623283386230469
Batch 35/64 loss: -1.8402080535888672
Batch 36/64 loss: -1.7761220932006836
Batch 37/64 loss: -1.649287223815918
Batch 38/64 loss: -1.4095392227172852
Batch 39/64 loss: -1.3117094039916992
Batch 40/64 loss: -1.508357048034668
Batch 41/64 loss: -1.7923860549926758
Batch 42/64 loss: -1.7816028594970703
Batch 43/64 loss: -1.4430532455444336
Batch 44/64 loss: -1.7398271560668945
Batch 45/64 loss: -1.8342514038085938
Batch 46/64 loss: -1.4904565811157227
Batch 47/64 loss: -1.7581110000610352
Batch 48/64 loss: -1.7319831848144531
Batch 49/64 loss: -1.477376937866211
Batch 50/64 loss: -1.795151710510254
Batch 51/64 loss: -1.6055669784545898
Batch 52/64 loss: -1.9612998962402344
Batch 53/64 loss: -1.5206289291381836
Batch 54/64 loss: -1.5170621871948242
Batch 55/64 loss: -1.701462745666504
Batch 56/64 loss: -1.6867575645446777
Batch 57/64 loss: -1.245579719543457
Batch 58/64 loss: -1.847299575805664
Batch 59/64 loss: -1.4463491439819336
Batch 60/64 loss: -1.7609267234802246
Batch 61/64 loss: -1.754570484161377
Batch 62/64 loss: -1.4679861068725586
Batch 63/64 loss: -1.7757415771484375
Batch 64/64 loss: -5.511250019073486
Epoch 302  Train loss: -1.7534003519544414  Val loss: -1.8799012698668385
Epoch 303
-------------------------------
Batch 1/64 loss: -1.8811860084533691
Batch 2/64 loss: -1.5302982330322266
Batch 3/64 loss: -2.000115394592285
Batch 4/64 loss: -1.7612714767456055
Batch 5/64 loss: -1.7210540771484375
Batch 6/64 loss: -1.568079948425293
Batch 7/64 loss: -1.3980512619018555
Batch 8/64 loss: -1.2984189987182617
Batch 9/64 loss: -2.0082521438598633
Batch 10/64 loss: -1.7153606414794922
Batch 11/64 loss: -1.6829051971435547
Batch 12/64 loss: -1.5874319076538086
Batch 13/64 loss: -1.5139923095703125
Batch 14/64 loss: -1.793731689453125
Batch 15/64 loss: -1.9298534393310547
Batch 16/64 loss: -1.7691717147827148
Batch 17/64 loss: -0.7731256484985352
Batch 18/64 loss: -1.612161636352539
Batch 19/64 loss: -1.8757848739624023
Batch 20/64 loss: -1.674757957458496
Batch 21/64 loss: -1.7497844696044922
Batch 22/64 loss: -0.9905986785888672
Batch 23/64 loss: -1.9546575546264648
Batch 24/64 loss: -1.8869314193725586
Batch 25/64 loss: -1.6964197158813477
Batch 26/64 loss: -0.2003326416015625
Batch 27/64 loss: 0.3694753646850586
Batch 28/64 loss: -1.514510154724121
Batch 29/64 loss: -1.2639503479003906
Batch 30/64 loss: -1.8897972106933594
Batch 31/64 loss: -1.717020034790039
Batch 32/64 loss: -1.7435245513916016
Batch 33/64 loss: -1.1271772384643555
Batch 34/64 loss: -1.6940727233886719
Batch 35/64 loss: -1.6180391311645508
Batch 36/64 loss: -1.8539037704467773
Batch 37/64 loss: -1.661311149597168
Batch 38/64 loss: -1.8527860641479492
Batch 39/64 loss: -1.621556282043457
Batch 40/64 loss: -0.8798465728759766
Batch 41/64 loss: -1.687708854675293
Batch 42/64 loss: -1.5440454483032227
Batch 43/64 loss: -1.7380142211914062
Batch 44/64 loss: -1.1513967514038086
Batch 45/64 loss: -1.6332778930664062
Batch 46/64 loss: -1.5916662216186523
Batch 47/64 loss: -1.591756820678711
Batch 48/64 loss: -1.2098264694213867
Batch 49/64 loss: -1.4105186462402344
Batch 50/64 loss: -1.7694854736328125
Batch 51/64 loss: -1.3314027786254883
Batch 52/64 loss: -1.3836956024169922
Batch 53/64 loss: -1.4931697845458984
Batch 54/64 loss: -1.464040756225586
Batch 55/64 loss: -1.844630241394043
Batch 56/64 loss: -1.2362174987792969
Batch 57/64 loss: -1.8063430786132812
Batch 58/64 loss: -1.7413349151611328
Batch 59/64 loss: -1.4895658493041992
Batch 60/64 loss: -1.2844734191894531
Batch 61/64 loss: -1.5074100494384766
Batch 62/64 loss: -1.45562744140625
Batch 63/64 loss: -1.4651288986206055
Batch 64/64 loss: -5.595076084136963
Epoch 303  Train loss: -1.5791183228586234  Val loss: -1.6753874841014953
Epoch 304
-------------------------------
Batch 1/64 loss: -1.40606689453125
Batch 2/64 loss: -1.7697925567626953
Batch 3/64 loss: -1.994534969329834
Batch 4/64 loss: -1.515035629272461
Batch 5/64 loss: -1.4938631057739258
Batch 6/64 loss: -1.2433795928955078
Batch 7/64 loss: -1.5185918807983398
Batch 8/64 loss: -1.5263643264770508
Batch 9/64 loss: -1.570882797241211
Batch 10/64 loss: -1.6617622375488281
Batch 11/64 loss: -1.4879059791564941
Batch 12/64 loss: -1.520359992980957
Batch 13/64 loss: -1.4717302322387695
Batch 14/64 loss: -1.5558757781982422
Batch 15/64 loss: -1.6767363548278809
Batch 16/64 loss: -1.5242633819580078
Batch 17/64 loss: -1.606344223022461
Batch 18/64 loss: -1.6946382522583008
Batch 19/64 loss: -1.5125865936279297
Batch 20/64 loss: -1.886124610900879
Batch 21/64 loss: -1.7500743865966797
Batch 22/64 loss: -1.2620325088500977
Batch 23/64 loss: -1.0584220886230469
Batch 24/64 loss: -1.646514892578125
Batch 25/64 loss: -1.4449653625488281
Batch 26/64 loss: -1.158660888671875
Batch 27/64 loss: -1.7585434913635254
Batch 28/64 loss: -1.1462039947509766
Batch 29/64 loss: -1.3691596984863281
Batch 30/64 loss: -0.8909025192260742
Batch 31/64 loss: -1.9572339057922363
Batch 32/64 loss: -1.5324926376342773
Batch 33/64 loss: -1.5307273864746094
Batch 34/64 loss: -1.514516830444336
Batch 35/64 loss: -1.8293166160583496
Batch 36/64 loss: -1.6360893249511719
Batch 37/64 loss: -1.6113462448120117
Batch 38/64 loss: -1.2358951568603516
Batch 39/64 loss: -1.6569843292236328
Batch 40/64 loss: -1.745626449584961
Batch 41/64 loss: -1.5446252822875977
Batch 42/64 loss: -1.787461280822754
Batch 43/64 loss: -1.3851747512817383
Batch 44/64 loss: -1.702855110168457
Batch 45/64 loss: -1.7618484497070312
Batch 46/64 loss: -1.6731328964233398
Batch 47/64 loss: -1.9121294021606445
Batch 48/64 loss: -1.8595972061157227
Batch 49/64 loss: -1.4398374557495117
Batch 50/64 loss: -1.4940109252929688
Batch 51/64 loss: -1.4340543746948242
Batch 52/64 loss: -1.7267484664916992
Batch 53/64 loss: -1.7720813751220703
Batch 54/64 loss: -1.7992115020751953
Batch 55/64 loss: -1.1311912536621094
Batch 56/64 loss: -1.878016471862793
Batch 57/64 loss: -1.7028427124023438
Batch 58/64 loss: -2.049168586730957
Batch 59/64 loss: -1.9420204162597656
Batch 60/64 loss: -1.9283480644226074
Batch 61/64 loss: -1.5889501571655273
Batch 62/64 loss: -1.775838851928711
Batch 63/64 loss: -1.7743606567382812
Batch 64/64 loss: -5.943242073059082
Epoch 304  Train loss: -1.6453880048265643  Val loss: -1.8657043955170411
Epoch 305
-------------------------------
Batch 1/64 loss: -1.7832746505737305
Batch 2/64 loss: -1.6434097290039062
Batch 3/64 loss: -1.8040924072265625
Batch 4/64 loss: -1.5197839736938477
Batch 5/64 loss: -1.7059812545776367
Batch 6/64 loss: -1.9188804626464844
Batch 7/64 loss: -1.862889289855957
Batch 8/64 loss: -1.4151067733764648
Batch 9/64 loss: -1.6939706802368164
Batch 10/64 loss: -1.6066780090332031
Batch 11/64 loss: -1.744964599609375
Batch 12/64 loss: -1.7207202911376953
Batch 13/64 loss: -1.6867847442626953
Batch 14/64 loss: -1.4479970932006836
Batch 15/64 loss: -1.5659656524658203
Batch 16/64 loss: -1.93353271484375
Batch 17/64 loss: -1.7403478622436523
Batch 18/64 loss: -1.7124271392822266
Batch 19/64 loss: -1.4142837524414062
Batch 20/64 loss: -1.7294130325317383
Batch 21/64 loss: -1.8779492378234863
Batch 22/64 loss: -1.640970230102539
Batch 23/64 loss: -1.9366750717163086
Batch 24/64 loss: -1.6718616485595703
Batch 25/64 loss: -2.050586223602295
Batch 26/64 loss: -1.8485755920410156
Batch 27/64 loss: -1.6536903381347656
Batch 28/64 loss: -1.7534780502319336
Batch 29/64 loss: -1.1906232833862305
Batch 30/64 loss: -1.2654600143432617
Batch 31/64 loss: -1.623483657836914
Batch 32/64 loss: -1.851226806640625
Batch 33/64 loss: -1.816843032836914
Batch 34/64 loss: -1.6284303665161133
Batch 35/64 loss: -1.8270845413208008
Batch 36/64 loss: -1.5324974060058594
Batch 37/64 loss: -1.7204275131225586
Batch 38/64 loss: -1.772059440612793
Batch 39/64 loss: -1.842820167541504
Batch 40/64 loss: -1.6985182762145996
Batch 41/64 loss: -1.6733407974243164
Batch 42/64 loss: -1.7816343307495117
Batch 43/64 loss: -1.7995123863220215
Batch 44/64 loss: -1.9517803192138672
Batch 45/64 loss: -2.03403377532959
Batch 46/64 loss: -1.7014780044555664
Batch 47/64 loss: -0.5734128952026367
Batch 48/64 loss: -1.4059057235717773
Batch 49/64 loss: -1.8321638107299805
Batch 50/64 loss: -1.557051658630371
Batch 51/64 loss: -1.358816146850586
Batch 52/64 loss: -1.825922966003418
Batch 53/64 loss: -1.926131248474121
Batch 54/64 loss: -1.888443946838379
Batch 55/64 loss: -1.8975791931152344
Batch 56/64 loss: -1.314753532409668
Batch 57/64 loss: -1.5956611633300781
Batch 58/64 loss: -1.5506820678710938
Batch 59/64 loss: -2.000359535217285
Batch 60/64 loss: -1.7299070358276367
Batch 61/64 loss: -1.443861961364746
Batch 62/64 loss: -1.5911083221435547
Batch 63/64 loss: -1.8355827331542969
Batch 64/64 loss: -5.445442199707031
Epoch 305  Train loss: -1.7287367876838236  Val loss: -1.8287816653956253
Epoch 306
-------------------------------
Batch 1/64 loss: -1.7159290313720703
Batch 2/64 loss: -1.5684576034545898
Batch 3/64 loss: -1.5621070861816406
Batch 4/64 loss: -1.4948854446411133
Batch 5/64 loss: -1.6072978973388672
Batch 6/64 loss: -1.6883306503295898
Batch 7/64 loss: -1.4782772064208984
Batch 8/64 loss: -1.7627840042114258
Batch 9/64 loss: -1.402303695678711
Batch 10/64 loss: -1.7482290267944336
Batch 11/64 loss: -1.750626564025879
Batch 12/64 loss: -1.6135120391845703
Batch 13/64 loss: -1.7457151412963867
Batch 14/64 loss: -1.7418031692504883
Batch 15/64 loss: -1.8271331787109375
Batch 16/64 loss: -1.977569580078125
Batch 17/64 loss: -1.3375911712646484
Batch 18/64 loss: -1.826380729675293
Batch 19/64 loss: -1.9316673278808594
Batch 20/64 loss: -1.6637067794799805
Batch 21/64 loss: -1.725473403930664
Batch 22/64 loss: -1.4413785934448242
Batch 23/64 loss: -1.4575815200805664
Batch 24/64 loss: -1.4827756881713867
Batch 25/64 loss: -1.698526382446289
Batch 26/64 loss: -1.5396766662597656
Batch 27/64 loss: -1.6610689163208008
Batch 28/64 loss: -1.4052915573120117
Batch 29/64 loss: -2.044178009033203
Batch 30/64 loss: -1.7249727249145508
Batch 31/64 loss: -1.8659858703613281
Batch 32/64 loss: -1.7886533737182617
Batch 33/64 loss: -1.735550880432129
Batch 34/64 loss: -1.8847980499267578
Batch 35/64 loss: -2.11806583404541
Batch 36/64 loss: -1.1160097122192383
Batch 37/64 loss: -1.550527572631836
Batch 38/64 loss: -1.741506576538086
Batch 39/64 loss: -1.9031734466552734
Batch 40/64 loss: -1.809901237487793
Batch 41/64 loss: -1.8398871421813965
Batch 42/64 loss: -1.7657890319824219
Batch 43/64 loss: -1.7537012100219727
Batch 44/64 loss: -1.8251428604125977
Batch 45/64 loss: -1.9434828758239746
Batch 46/64 loss: -2.1115617752075195
Batch 47/64 loss: -1.5973529815673828
Batch 48/64 loss: -1.808946132659912
Batch 49/64 loss: -1.375783920288086
Batch 50/64 loss: -1.803074836730957
Batch 51/64 loss: -2.1637024879455566
Batch 52/64 loss: -1.8969388008117676
Batch 53/64 loss: -1.9739274978637695
Batch 54/64 loss: -1.7889251708984375
Batch 55/64 loss: -1.9173502922058105
Batch 56/64 loss: -1.9105777740478516
Batch 57/64 loss: -1.3939762115478516
Batch 58/64 loss: -1.7061691284179688
Batch 59/64 loss: -1.8228797912597656
Batch 60/64 loss: -1.8451652526855469
Batch 61/64 loss: -1.4423370361328125
Batch 62/64 loss: -1.776266098022461
Batch 63/64 loss: -1.5210533142089844
Batch 64/64 loss: -5.196981430053711
Epoch 306  Train loss: -1.7571942123712279  Val loss: -1.903657015246624
Epoch 307
-------------------------------
Batch 1/64 loss: -1.3641090393066406
Batch 2/64 loss: -1.8641138076782227
Batch 3/64 loss: -1.7158050537109375
Batch 4/64 loss: -1.809462547302246
Batch 5/64 loss: -1.6528043746948242
Batch 6/64 loss: -1.7242002487182617
Batch 7/64 loss: -1.9521207809448242
Batch 8/64 loss: -1.6893281936645508
Batch 9/64 loss: -1.8717050552368164
Batch 10/64 loss: -1.903244972229004
Batch 11/64 loss: -1.6053314208984375
Batch 12/64 loss: -1.6816492080688477
Batch 13/64 loss: -1.7454500198364258
Batch 14/64 loss: -1.164628028869629
Batch 15/64 loss: -1.668473243713379
Batch 16/64 loss: -1.5314884185791016
Batch 17/64 loss: -1.5408945083618164
Batch 18/64 loss: -1.8470430374145508
Batch 19/64 loss: -1.6879262924194336
Batch 20/64 loss: -1.5975055694580078
Batch 21/64 loss: -1.7570123672485352
Batch 22/64 loss: -0.887547492980957
Batch 23/64 loss: -1.9537668228149414
Batch 24/64 loss: -1.7004785537719727
Batch 25/64 loss: -1.8609285354614258
Batch 26/64 loss: -1.3996305465698242
Batch 27/64 loss: -1.5619401931762695
Batch 28/64 loss: -1.8582115173339844
Batch 29/64 loss: -1.8208942413330078
Batch 30/64 loss: -1.9524898529052734
Batch 31/64 loss: -1.9178829193115234
Batch 32/64 loss: -1.9223804473876953
Batch 33/64 loss: -1.526747703552246
Batch 34/64 loss: -1.6886577606201172
Batch 35/64 loss: -1.6332464218139648
Batch 36/64 loss: -1.8560237884521484
Batch 37/64 loss: -1.8273420333862305
Batch 38/64 loss: -1.6193389892578125
Batch 39/64 loss: -2.0602922439575195
Batch 40/64 loss: -1.9110498428344727
Batch 41/64 loss: -1.2671585083007812
Batch 42/64 loss: -1.7609834671020508
Batch 43/64 loss: -1.952406883239746
Batch 44/64 loss: -1.7413291931152344
Batch 45/64 loss: -1.4382505416870117
Batch 46/64 loss: -1.705657958984375
Batch 47/64 loss: -1.670663833618164
Batch 48/64 loss: -1.8801727294921875
Batch 49/64 loss: -1.757577896118164
Batch 50/64 loss: -1.527216911315918
Batch 51/64 loss: -1.8669471740722656
Batch 52/64 loss: -1.8297405242919922
Batch 53/64 loss: -1.2878408432006836
Batch 54/64 loss: -2.0833420753479004
Batch 55/64 loss: -1.939103126525879
Batch 56/64 loss: -1.9953794479370117
Batch 57/64 loss: -1.6600732803344727
Batch 58/64 loss: -1.9075212478637695
Batch 59/64 loss: -1.7454195022583008
Batch 60/64 loss: -1.4025239944458008
Batch 61/64 loss: -2.163386344909668
Batch 62/64 loss: -1.7594242095947266
Batch 63/64 loss: -1.8652429580688477
Batch 64/64 loss: -5.949416160583496
Epoch 307  Train loss: -1.7725893469417797  Val loss: -2.0090631963461125
Saving best model, epoch: 307
Epoch 308
-------------------------------
Batch 1/64 loss: -2.011223316192627
Batch 2/64 loss: -2.0792880058288574
Batch 3/64 loss: -1.824319839477539
Batch 4/64 loss: -1.6796979904174805
Batch 5/64 loss: -1.7479133605957031
Batch 6/64 loss: -1.8521318435668945
Batch 7/64 loss: -1.9605226516723633
Batch 8/64 loss: -1.6988029479980469
Batch 9/64 loss: -1.8488407135009766
Batch 10/64 loss: -1.7143669128417969
Batch 11/64 loss: -2.1265869140625
Batch 12/64 loss: -1.7974414825439453
Batch 13/64 loss: -1.644211769104004
Batch 14/64 loss: -1.7880353927612305
Batch 15/64 loss: -1.3354225158691406
Batch 16/64 loss: -1.8928413391113281
Batch 17/64 loss: -1.7284555435180664
Batch 18/64 loss: -1.8119544982910156
Batch 19/64 loss: -1.853243350982666
Batch 20/64 loss: -1.7853021621704102
Batch 21/64 loss: -1.7087211608886719
Batch 22/64 loss: -1.7359132766723633
Batch 23/64 loss: -2.044057846069336
Batch 24/64 loss: -1.9536561965942383
Batch 25/64 loss: -1.9233951568603516
Batch 26/64 loss: -1.841141700744629
Batch 27/64 loss: -1.877227783203125
Batch 28/64 loss: -1.359328269958496
Batch 29/64 loss: -1.7764158248901367
Batch 30/64 loss: -1.9003372192382812
Batch 31/64 loss: -1.8627510070800781
Batch 32/64 loss: -1.654761791229248
Batch 33/64 loss: -1.9381771087646484
Batch 34/64 loss: -1.9482622146606445
Batch 35/64 loss: -1.462681770324707
Batch 36/64 loss: -1.9121942520141602
Batch 37/64 loss: -2.037228584289551
Batch 38/64 loss: -1.5934267044067383
Batch 39/64 loss: -1.8350019454956055
Batch 40/64 loss: -1.7845802307128906
Batch 41/64 loss: -1.881302833557129
Batch 42/64 loss: -1.84269380569458
Batch 43/64 loss: -1.6604156494140625
Batch 44/64 loss: -1.7506909370422363
Batch 45/64 loss: -1.9083600044250488
Batch 46/64 loss: -1.4959726333618164
Batch 47/64 loss: -1.9445257186889648
Batch 48/64 loss: -1.8375988006591797
Batch 49/64 loss: -1.3494443893432617
Batch 50/64 loss: -1.9768085479736328
Batch 51/64 loss: -1.4820547103881836
Batch 52/64 loss: -0.9374485015869141
Batch 53/64 loss: -1.2790050506591797
Batch 54/64 loss: -1.814784049987793
Batch 55/64 loss: -1.828232765197754
Batch 56/64 loss: -1.9085307121276855
Batch 57/64 loss: -1.1427936553955078
Batch 58/64 loss: -1.8301582336425781
Batch 59/64 loss: -1.581212043762207
Batch 60/64 loss: -1.5969352722167969
Batch 61/64 loss: -1.6546292304992676
Batch 62/64 loss: -1.7014570236206055
Batch 63/64 loss: -1.6531896591186523
Batch 64/64 loss: -5.914979457855225
Epoch 308  Train loss: -1.801166139864454  Val loss: -1.9537138135982133
Epoch 309
-------------------------------
Batch 1/64 loss: -1.7666797637939453
Batch 2/64 loss: -1.9678049087524414
Batch 3/64 loss: -1.1239919662475586
Batch 4/64 loss: -1.830388069152832
Batch 5/64 loss: -1.745478630065918
Batch 6/64 loss: -1.1219816207885742
Batch 7/64 loss: -2.0364437103271484
Batch 8/64 loss: -1.7741422653198242
Batch 9/64 loss: -1.858438491821289
Batch 10/64 loss: -1.7802982330322266
Batch 11/64 loss: -1.810281753540039
Batch 12/64 loss: -1.8303356170654297
Batch 13/64 loss: -1.6944961547851562
Batch 14/64 loss: -1.640517234802246
Batch 15/64 loss: -1.7012300491333008
Batch 16/64 loss: -1.8586673736572266
Batch 17/64 loss: -1.7634410858154297
Batch 18/64 loss: -1.549875259399414
Batch 19/64 loss: -1.9842658042907715
Batch 20/64 loss: -1.8890609741210938
Batch 21/64 loss: -1.819234848022461
Batch 22/64 loss: -1.7788734436035156
Batch 23/64 loss: -1.8328609466552734
Batch 24/64 loss: -1.154388427734375
Batch 25/64 loss: -1.6978368759155273
Batch 26/64 loss: -1.7611408233642578
Batch 27/64 loss: -1.8170156478881836
Batch 28/64 loss: -1.7640795707702637
Batch 29/64 loss: -2.0061774253845215
Batch 30/64 loss: -1.8595600128173828
Batch 31/64 loss: -1.4601125717163086
Batch 32/64 loss: -1.9023733139038086
Batch 33/64 loss: -1.7336320877075195
Batch 34/64 loss: -1.562063217163086
Batch 35/64 loss: -1.7698869705200195
Batch 36/64 loss: -1.9166698455810547
Batch 37/64 loss: -1.6503496170043945
Batch 38/64 loss: -1.942960262298584
Batch 39/64 loss: -1.6399831771850586
Batch 40/64 loss: -1.9822688102722168
Batch 41/64 loss: -1.5019102096557617
Batch 42/64 loss: -1.6430912017822266
Batch 43/64 loss: -1.9368047714233398
Batch 44/64 loss: -1.645583152770996
Batch 45/64 loss: -2.0365333557128906
Batch 46/64 loss: -0.9513187408447266
Batch 47/64 loss: -1.6611003875732422
Batch 48/64 loss: -1.228189468383789
Batch 49/64 loss: -1.3629627227783203
Batch 50/64 loss: -1.7422504425048828
Batch 51/64 loss: -1.7845964431762695
Batch 52/64 loss: -1.6439170837402344
Batch 53/64 loss: -1.8757801055908203
Batch 54/64 loss: -1.7394142150878906
Batch 55/64 loss: -1.7669224739074707
Batch 56/64 loss: -1.1897201538085938
Batch 57/64 loss: -1.959010124206543
Batch 58/64 loss: -1.8308000564575195
Batch 59/64 loss: -1.6964616775512695
Batch 60/64 loss: -1.8407979011535645
Batch 61/64 loss: -1.4528255462646484
Batch 62/64 loss: -0.9144983291625977
Batch 63/64 loss: -1.8073139190673828
Batch 64/64 loss: -5.945049285888672
Epoch 309  Train loss: -1.7482333538579007  Val loss: -1.9882419232240658
Epoch 310
-------------------------------
Batch 1/64 loss: -1.7491178512573242
Batch 2/64 loss: -1.8007688522338867
Batch 3/64 loss: -2.013944625854492
Batch 4/64 loss: -1.9623031616210938
Batch 5/64 loss: -2.058356285095215
Batch 6/64 loss: -1.728330135345459
Batch 7/64 loss: -1.635009765625
Batch 8/64 loss: -1.7361459732055664
Batch 9/64 loss: -1.7987031936645508
Batch 10/64 loss: -1.3579225540161133
Batch 11/64 loss: -1.7861900329589844
Batch 12/64 loss: -1.7013158798217773
Batch 13/64 loss: -1.8065404891967773
Batch 14/64 loss: -1.8264780044555664
Batch 15/64 loss: -1.9592833518981934
Batch 16/64 loss: -1.9021949768066406
Batch 17/64 loss: -1.8462095260620117
Batch 18/64 loss: -1.7761402130126953
Batch 19/64 loss: -1.129075050354004
Batch 20/64 loss: -1.524458885192871
Batch 21/64 loss: -1.5415153503417969
Batch 22/64 loss: -1.6991257667541504
Batch 23/64 loss: -1.77716064453125
Batch 24/64 loss: -1.9470739364624023
Batch 25/64 loss: -1.8482046127319336
Batch 26/64 loss: -1.9399652481079102
Batch 27/64 loss: -1.7706799507141113
Batch 28/64 loss: -1.9684057235717773
Batch 29/64 loss: -1.6044921875
Batch 30/64 loss: -1.458099365234375
Batch 31/64 loss: -1.8686599731445312
Batch 32/64 loss: -1.8590450286865234
Batch 33/64 loss: -1.7144203186035156
Batch 34/64 loss: -1.3760108947753906
Batch 35/64 loss: -1.8208184242248535
Batch 36/64 loss: -1.9690418243408203
Batch 37/64 loss: -1.7872600555419922
Batch 38/64 loss: -1.3290815353393555
Batch 39/64 loss: -1.5150270462036133
Batch 40/64 loss: -1.679062843322754
Batch 41/64 loss: -1.8688974380493164
Batch 42/64 loss: -1.513786792755127
Batch 43/64 loss: -1.7208070755004883
Batch 44/64 loss: -1.9707789421081543
Batch 45/64 loss: -1.590188980102539
Batch 46/64 loss: -1.9266676902770996
Batch 47/64 loss: -1.7153863906860352
Batch 48/64 loss: -1.4450435638427734
Batch 49/64 loss: -1.7951650619506836
Batch 50/64 loss: -1.7915372848510742
Batch 51/64 loss: -1.6557741165161133
Batch 52/64 loss: -1.531332015991211
Batch 53/64 loss: -1.7706336975097656
Batch 54/64 loss: -1.4331607818603516
Batch 55/64 loss: -1.8164396286010742
Batch 56/64 loss: -1.890934944152832
Batch 57/64 loss: -1.7517156600952148
Batch 58/64 loss: -1.8542251586914062
Batch 59/64 loss: -2.0615053176879883
Batch 60/64 loss: -1.7353973388671875
Batch 61/64 loss: -1.858149528503418
Batch 62/64 loss: -1.6979217529296875
Batch 63/64 loss: -1.6154165267944336
Batch 64/64 loss: -6.126913070678711
Epoch 310  Train loss: -1.7910225886924593  Val loss: -1.8180916383094394
Epoch 311
-------------------------------
Batch 1/64 loss: -1.553750991821289
Batch 2/64 loss: -1.9107933044433594
Batch 3/64 loss: -1.8553147315979004
Batch 4/64 loss: -1.5907087326049805
Batch 5/64 loss: -1.5899972915649414
Batch 6/64 loss: -1.7879877090454102
Batch 7/64 loss: -1.7227888107299805
Batch 8/64 loss: -1.8241024017333984
Batch 9/64 loss: -1.4965810775756836
Batch 10/64 loss: -1.6133756637573242
Batch 11/64 loss: -1.8148832321166992
Batch 12/64 loss: -1.731898307800293
Batch 13/64 loss: -1.6017179489135742
Batch 14/64 loss: -1.4707403182983398
Batch 15/64 loss: -1.2874221801757812
Batch 16/64 loss: -1.2704439163208008
Batch 17/64 loss: -1.539555549621582
Batch 18/64 loss: -1.7221803665161133
Batch 19/64 loss: -1.4737815856933594
Batch 20/64 loss: -1.7910337448120117
Batch 21/64 loss: -1.6122112274169922
Batch 22/64 loss: -1.8965415954589844
Batch 23/64 loss: -1.9321088790893555
Batch 24/64 loss: -1.7220840454101562
Batch 25/64 loss: -1.9218320846557617
Batch 26/64 loss: -1.3509387969970703
Batch 27/64 loss: -1.7571134567260742
Batch 28/64 loss: -1.7808408737182617
Batch 29/64 loss: -1.4184188842773438
Batch 30/64 loss: -1.6397418975830078
Batch 31/64 loss: -1.158578872680664
Batch 32/64 loss: -1.7125473022460938
Batch 33/64 loss: -1.6404657363891602
Batch 34/64 loss: -1.7005796432495117
Batch 35/64 loss: -1.738077163696289
Batch 36/64 loss: -1.6597614288330078
Batch 37/64 loss: -1.4998712539672852
Batch 38/64 loss: -1.5584383010864258
Batch 39/64 loss: -1.6373729705810547
Batch 40/64 loss: -1.072026252746582
Batch 41/64 loss: -1.577188491821289
Batch 42/64 loss: -1.6917533874511719
Batch 43/64 loss: -1.6700515747070312
Batch 44/64 loss: -1.8835372924804688
Batch 45/64 loss: -1.7679848670959473
Batch 46/64 loss: -1.546616554260254
Batch 47/64 loss: -1.8170623779296875
Batch 48/64 loss: -1.4984874725341797
Batch 49/64 loss: -1.842519760131836
Batch 50/64 loss: -1.6330385208129883
Batch 51/64 loss: -1.7538156509399414
Batch 52/64 loss: -1.9869251251220703
Batch 53/64 loss: -1.832956314086914
Batch 54/64 loss: -1.9174957275390625
Batch 55/64 loss: -1.7455778121948242
Batch 56/64 loss: -2.001469135284424
Batch 57/64 loss: -1.7734870910644531
Batch 58/64 loss: -1.7171192169189453
Batch 59/64 loss: -1.9745521545410156
Batch 60/64 loss: -1.7253618240356445
Batch 61/64 loss: -1.85890531539917
Batch 62/64 loss: -1.7608346939086914
Batch 63/64 loss: -2.0994863510131836
Batch 64/64 loss: -5.851975917816162
Epoch 311  Train loss: -1.7337069361817603  Val loss: -1.8172464534589106
Epoch 312
-------------------------------
Batch 1/64 loss: -1.5740671157836914
Batch 2/64 loss: -1.788717269897461
Batch 3/64 loss: -1.4954490661621094
Batch 4/64 loss: -1.8544187545776367
Batch 5/64 loss: -1.94490385055542
Batch 6/64 loss: -1.6591949462890625
Batch 7/64 loss: -1.9018926620483398
Batch 8/64 loss: -1.1766643524169922
Batch 9/64 loss: -1.4707937240600586
Batch 10/64 loss: -1.4966239929199219
Batch 11/64 loss: -1.5430669784545898
Batch 12/64 loss: -1.5829267501831055
Batch 13/64 loss: -1.2600593566894531
Batch 14/64 loss: -1.5223636627197266
Batch 15/64 loss: -1.7468395233154297
Batch 16/64 loss: -1.9246602058410645
Batch 17/64 loss: -1.5847644805908203
Batch 18/64 loss: -1.4689197540283203
Batch 19/64 loss: -1.4816570281982422
Batch 20/64 loss: -1.615340232849121
Batch 21/64 loss: -1.588639259338379
Batch 22/64 loss: -1.3807106018066406
Batch 23/64 loss: -1.7825374603271484
Batch 24/64 loss: -1.3906230926513672
Batch 25/64 loss: -1.7516670227050781
Batch 26/64 loss: -1.8062448501586914
Batch 27/64 loss: -2.0117530822753906
Batch 28/64 loss: -1.5710077285766602
Batch 29/64 loss: -1.9195246696472168
Batch 30/64 loss: -1.9327392578125
Batch 31/64 loss: -1.3965740203857422
Batch 32/64 loss: -1.8014593124389648
Batch 33/64 loss: -1.8303537368774414
Batch 34/64 loss: -1.9558424949645996
Batch 35/64 loss: -1.730128288269043
Batch 36/64 loss: -2.1210012435913086
Batch 37/64 loss: -1.8866376876831055
Batch 38/64 loss: -1.7549152374267578
Batch 39/64 loss: -1.5726356506347656
Batch 40/64 loss: -1.9106817245483398
Batch 41/64 loss: -1.725499153137207
Batch 42/64 loss: -1.7992172241210938
Batch 43/64 loss: -2.0527501106262207
Batch 44/64 loss: -1.8465824127197266
Batch 45/64 loss: -1.633035659790039
Batch 46/64 loss: -1.6298284530639648
Batch 47/64 loss: -1.7377347946166992
Batch 48/64 loss: -1.2944908142089844
Batch 49/64 loss: -1.6150121688842773
Batch 50/64 loss: -1.6803464889526367
Batch 51/64 loss: -1.8853955268859863
Batch 52/64 loss: -1.6040935516357422
Batch 53/64 loss: -1.8101577758789062
Batch 54/64 loss: -1.949598789215088
Batch 55/64 loss: -1.9066171646118164
Batch 56/64 loss: -1.5606045722961426
Batch 57/64 loss: -1.8830499649047852
Batch 58/64 loss: -1.7646293640136719
Batch 59/64 loss: -1.7371597290039062
Batch 60/64 loss: -1.7599143981933594
Batch 61/64 loss: -1.6091022491455078
Batch 62/64 loss: -1.8259878158569336
Batch 63/64 loss: -2.0711708068847656
Batch 64/64 loss: -5.978138446807861
Epoch 312  Train loss: -1.7577189482894597  Val loss: -1.9899438156704723
Epoch 313
-------------------------------
Batch 1/64 loss: -1.4946985244750977
Batch 2/64 loss: -1.863637924194336
Batch 3/64 loss: -1.4574270248413086
Batch 4/64 loss: -1.9838380813598633
Batch 5/64 loss: -1.9522161483764648
Batch 6/64 loss: -2.0690698623657227
Batch 7/64 loss: -1.8423500061035156
Batch 8/64 loss: -1.7474956512451172
Batch 9/64 loss: -1.2275924682617188
Batch 10/64 loss: -1.864701271057129
Batch 11/64 loss: -1.8909473419189453
Batch 12/64 loss: -1.766596794128418
Batch 13/64 loss: -1.7287988662719727
Batch 14/64 loss: -1.5027751922607422
Batch 15/64 loss: -1.8695783615112305
Batch 16/64 loss: -1.8593053817749023
Batch 17/64 loss: -1.8608007431030273
Batch 18/64 loss: -1.5240497589111328
Batch 19/64 loss: -1.6474180221557617
Batch 20/64 loss: -1.8786201477050781
Batch 21/64 loss: -1.77081298828125
Batch 22/64 loss: -1.608677864074707
Batch 23/64 loss: -1.14031982421875
Batch 24/64 loss: -1.8165864944458008
Batch 25/64 loss: -1.7672100067138672
Batch 26/64 loss: -1.6341915130615234
Batch 27/64 loss: -1.9760656356811523
Batch 28/64 loss: -1.6914443969726562
Batch 29/64 loss: -1.5946903228759766
Batch 30/64 loss: -1.7049179077148438
Batch 31/64 loss: -1.3815374374389648
Batch 32/64 loss: -1.7963171005249023
Batch 33/64 loss: -1.9286365509033203
Batch 34/64 loss: -1.5159997940063477
Batch 35/64 loss: -1.8254985809326172
Batch 36/64 loss: -1.7878484725952148
Batch 37/64 loss: -1.793238639831543
Batch 38/64 loss: -1.4133434295654297
Batch 39/64 loss: -1.8962039947509766
Batch 40/64 loss: -1.9540772438049316
Batch 41/64 loss: -1.628622055053711
Batch 42/64 loss: -1.6696014404296875
Batch 43/64 loss: -1.8493967056274414
Batch 44/64 loss: -1.7545766830444336
Batch 45/64 loss: -1.1098699569702148
Batch 46/64 loss: -1.340010643005371
Batch 47/64 loss: -1.841360092163086
Batch 48/64 loss: -1.6407947540283203
Batch 49/64 loss: -1.8325328826904297
Batch 50/64 loss: -2.1091318130493164
Batch 51/64 loss: -1.5881376266479492
Batch 52/64 loss: -1.7133769989013672
Batch 53/64 loss: -1.7526063919067383
Batch 54/64 loss: -1.8447237014770508
Batch 55/64 loss: -1.7368698120117188
Batch 56/64 loss: -1.9965076446533203
Batch 57/64 loss: -1.8751153945922852
Batch 58/64 loss: -1.6594429016113281
Batch 59/64 loss: -1.9579782485961914
Batch 60/64 loss: -1.974461555480957
Batch 61/64 loss: -1.9439897537231445
Batch 62/64 loss: -1.8353443145751953
Batch 63/64 loss: -1.8697261810302734
Batch 64/64 loss: -5.5962066650390625
Epoch 313  Train loss: -1.784327346203374  Val loss: -1.8773528554595214
Epoch 314
-------------------------------
Batch 1/64 loss: -1.767613410949707
Batch 2/64 loss: -1.9366273880004883
Batch 3/64 loss: -1.9326229095458984
Batch 4/64 loss: -1.770181655883789
Batch 5/64 loss: -1.7438077926635742
Batch 6/64 loss: -1.6837348937988281
Batch 7/64 loss: -1.8093619346618652
Batch 8/64 loss: -1.5364465713500977
Batch 9/64 loss: -1.613037109375
Batch 10/64 loss: -1.6950759887695312
Batch 11/64 loss: -1.6795120239257812
Batch 12/64 loss: -1.7388887405395508
Batch 13/64 loss: -1.9202880859375
Batch 14/64 loss: -1.8747844696044922
Batch 15/64 loss: -1.4963798522949219
Batch 16/64 loss: -1.6757211685180664
Batch 17/64 loss: -1.5825481414794922
Batch 18/64 loss: -1.4844655990600586
Batch 19/64 loss: -1.8083992004394531
Batch 20/64 loss: -1.9406766891479492
Batch 21/64 loss: -1.3193025588989258
Batch 22/64 loss: -1.8037614822387695
Batch 23/64 loss: -1.9644923210144043
Batch 24/64 loss: -1.48291015625
Batch 25/64 loss: -1.635685920715332
Batch 26/64 loss: -1.2700014114379883
Batch 27/64 loss: -1.464883804321289
Batch 28/64 loss: -1.7053375244140625
Batch 29/64 loss: -0.9191999435424805
Batch 30/64 loss: -1.5594053268432617
Batch 31/64 loss: -1.6557798385620117
Batch 32/64 loss: -1.7092103958129883
Batch 33/64 loss: -2.2429161071777344
Batch 34/64 loss: -1.388720989227295
Batch 35/64 loss: -1.8246078491210938
Batch 36/64 loss: -1.2445273399353027
Batch 37/64 loss: -1.5376033782958984
Batch 38/64 loss: -1.7338156700134277
Batch 39/64 loss: -1.5010099411010742
Batch 40/64 loss: -1.9296722412109375
Batch 41/64 loss: -1.9032187461853027
Batch 42/64 loss: -1.5673179626464844
Batch 43/64 loss: -1.629157543182373
Batch 44/64 loss: -1.540837287902832
Batch 45/64 loss: -1.4878883361816406
Batch 46/64 loss: -1.8087716102600098
Batch 47/64 loss: -1.866955280303955
Batch 48/64 loss: -1.8248019218444824
Batch 49/64 loss: -1.4675397872924805
Batch 50/64 loss: -1.8750686645507812
Batch 51/64 loss: -1.9440183639526367
Batch 52/64 loss: -1.7774319648742676
Batch 53/64 loss: -1.692805290222168
Batch 54/64 loss: -1.7823667526245117
Batch 55/64 loss: -1.7960944175720215
Batch 56/64 loss: -1.5956707000732422
Batch 57/64 loss: -1.8743152618408203
Batch 58/64 loss: -2.0919675827026367
Batch 59/64 loss: -1.7987899780273438
Batch 60/64 loss: -1.8885765075683594
Batch 61/64 loss: -1.6744585037231445
Batch 62/64 loss: -1.566141128540039
Batch 63/64 loss: -2.0442676544189453
Batch 64/64 loss: -5.586585998535156
Epoch 314  Train loss: -1.7454340168074065  Val loss: -1.809206880654666
Epoch 315
-------------------------------
Batch 1/64 loss: -1.7987632751464844
Batch 2/64 loss: -1.8511390686035156
Batch 3/64 loss: -1.383357048034668
Batch 4/64 loss: -1.6146602630615234
Batch 5/64 loss: -1.4196844100952148
Batch 6/64 loss: -1.8809404373168945
Batch 7/64 loss: -1.5241270065307617
Batch 8/64 loss: -1.8821163177490234
Batch 9/64 loss: -1.5720548629760742
Batch 10/64 loss: -1.5567054748535156
Batch 11/64 loss: -2.0239458084106445
Batch 12/64 loss: -1.8722753524780273
Batch 13/64 loss: -1.5911808013916016
Batch 14/64 loss: -1.6663541793823242
Batch 15/64 loss: -1.6769466400146484
Batch 16/64 loss: -1.7687463760375977
Batch 17/64 loss: -1.860790729522705
Batch 18/64 loss: -1.8304567337036133
Batch 19/64 loss: -1.588409423828125
Batch 20/64 loss: -1.7021217346191406
Batch 21/64 loss: -1.9510464668273926
Batch 22/64 loss: -1.6540107727050781
Batch 23/64 loss: -1.8414044380187988
Batch 24/64 loss: -1.78656005859375
Batch 25/64 loss: -1.5770416259765625
Batch 26/64 loss: -1.6528329849243164
Batch 27/64 loss: -1.5863752365112305
Batch 28/64 loss: -1.8465595245361328
Batch 29/64 loss: -1.812697410583496
Batch 30/64 loss: -1.5128421783447266
Batch 31/64 loss: -1.64874267578125
Batch 32/64 loss: -1.767958641052246
Batch 33/64 loss: -1.775106430053711
Batch 34/64 loss: -1.3827009201049805
Batch 35/64 loss: -1.9037094116210938
Batch 36/64 loss: -1.5858545303344727
Batch 37/64 loss: -1.7312698364257812
Batch 38/64 loss: -1.5674285888671875
Batch 39/64 loss: -1.5839080810546875
Batch 40/64 loss: -1.699751853942871
Batch 41/64 loss: -1.278524398803711
Batch 42/64 loss: -1.7674331665039062
Batch 43/64 loss: -1.7078914642333984
Batch 44/64 loss: -1.704859733581543
Batch 45/64 loss: -1.9174480438232422
Batch 46/64 loss: -2.0001630783081055
Batch 47/64 loss: -1.8217716217041016
Batch 48/64 loss: -2.0084962844848633
Batch 49/64 loss: -1.4522972106933594
Batch 50/64 loss: -1.8867511749267578
Batch 51/64 loss: -2.0479230880737305
Batch 52/64 loss: -1.4648494720458984
Batch 53/64 loss: -1.918381690979004
Batch 54/64 loss: -1.6734724044799805
Batch 55/64 loss: -1.8230628967285156
Batch 56/64 loss: -1.6669349670410156
Batch 57/64 loss: -1.799138069152832
Batch 58/64 loss: -1.9368362426757812
Batch 59/64 loss: -2.057054042816162
Batch 60/64 loss: -1.9941415786743164
Batch 61/64 loss: -1.6991519927978516
Batch 62/64 loss: -1.267888069152832
Batch 63/64 loss: -1.769845962524414
Batch 64/64 loss: -5.881191253662109
Epoch 315  Train loss: -1.7726711796779258  Val loss: -1.9615827344127537
Epoch 316
-------------------------------
Batch 1/64 loss: -1.7312421798706055
Batch 2/64 loss: -1.9211902618408203
Batch 3/64 loss: -1.9580421447753906
Batch 4/64 loss: -1.7440595626831055
Batch 5/64 loss: -2.0563764572143555
Batch 6/64 loss: -1.7857856750488281
Batch 7/64 loss: -1.5789909362792969
Batch 8/64 loss: -1.7280158996582031
Batch 9/64 loss: -1.3045244216918945
Batch 10/64 loss: -1.521784782409668
Batch 11/64 loss: -1.9191417694091797
Batch 12/64 loss: -1.7502508163452148
Batch 13/64 loss: -1.8378219604492188
Batch 14/64 loss: -1.9347915649414062
Batch 15/64 loss: -1.9604482650756836
Batch 16/64 loss: -1.191537857055664
Batch 17/64 loss: -1.7149543762207031
Batch 18/64 loss: -1.7324934005737305
Batch 19/64 loss: -1.6059350967407227
Batch 20/64 loss: -1.7324333190917969
Batch 21/64 loss: -1.827646255493164
Batch 22/64 loss: -1.6759395599365234
Batch 23/64 loss: -1.9364566802978516
Batch 24/64 loss: -1.6517715454101562
Batch 25/64 loss: -1.80987548828125
Batch 26/64 loss: -1.4611272811889648
Batch 27/64 loss: -1.3998146057128906
Batch 28/64 loss: -1.393331527709961
Batch 29/64 loss: -1.8437089920043945
Batch 30/64 loss: -1.8832778930664062
Batch 31/64 loss: -1.8411798477172852
Batch 32/64 loss: -1.5079870223999023
Batch 33/64 loss: -1.9423151016235352
Batch 34/64 loss: -1.415135383605957
Batch 35/64 loss: -1.7002334594726562
Batch 36/64 loss: -1.4860639572143555
Batch 37/64 loss: -1.7175865173339844
Batch 38/64 loss: -1.7080326080322266
Batch 39/64 loss: -1.9933691024780273
Batch 40/64 loss: -1.8191585540771484
Batch 41/64 loss: -1.8884496688842773
Batch 42/64 loss: -1.798323631286621
Batch 43/64 loss: -1.9394493103027344
Batch 44/64 loss: -2.064546585083008
Batch 45/64 loss: -1.6843128204345703
Batch 46/64 loss: -1.7322425842285156
Batch 47/64 loss: -1.5117549896240234
Batch 48/64 loss: -1.968325138092041
Batch 49/64 loss: -2.0095834732055664
Batch 50/64 loss: -1.8945751190185547
Batch 51/64 loss: -1.9829955101013184
Batch 52/64 loss: -1.8272318840026855
Batch 53/64 loss: -1.9445066452026367
Batch 54/64 loss: -1.7471837997436523
Batch 55/64 loss: -2.0040535926818848
Batch 56/64 loss: -1.7074308395385742
Batch 57/64 loss: -1.8406553268432617
Batch 58/64 loss: -1.8412494659423828
Batch 59/64 loss: -1.6437644958496094
Batch 60/64 loss: -1.699991226196289
Batch 61/64 loss: -1.9406681060791016
Batch 62/64 loss: -1.3739900588989258
Batch 63/64 loss: -1.815591812133789
Batch 64/64 loss: -5.834773063659668
Epoch 316  Train loss: -1.8033064786125632  Val loss: -2.0170958738556433
Saving best model, epoch: 316
Epoch 317
-------------------------------
Batch 1/64 loss: -1.7295560836791992
Batch 2/64 loss: -1.914626121520996
Batch 3/64 loss: -1.9874653816223145
Batch 4/64 loss: -1.750004768371582
Batch 5/64 loss: -1.7756786346435547
Batch 6/64 loss: -2.0164780616760254
Batch 7/64 loss: -1.8387079238891602
Batch 8/64 loss: -1.7918872833251953
Batch 9/64 loss: -1.8364429473876953
Batch 10/64 loss: -1.812739372253418
Batch 11/64 loss: -1.618088722229004
Batch 12/64 loss: -1.7846412658691406
Batch 13/64 loss: -1.8070077896118164
Batch 14/64 loss: -1.6943368911743164
Batch 15/64 loss: -1.4439020156860352
Batch 16/64 loss: -1.9190235137939453
Batch 17/64 loss: -1.9982614517211914
Batch 18/64 loss: -1.8999700546264648
Batch 19/64 loss: -1.642979621887207
Batch 20/64 loss: -1.9629206657409668
Batch 21/64 loss: -0.9954080581665039
Batch 22/64 loss: -1.514908790588379
Batch 23/64 loss: -1.7092618942260742
Batch 24/64 loss: -2.031665802001953
Batch 25/64 loss: -1.7362594604492188
Batch 26/64 loss: -2.0238404273986816
Batch 27/64 loss: -1.587031364440918
Batch 28/64 loss: -1.7054262161254883
Batch 29/64 loss: -1.8724708557128906
Batch 30/64 loss: -2.0164098739624023
Batch 31/64 loss: -1.5566473007202148
Batch 32/64 loss: -1.9657278060913086
Batch 33/64 loss: -2.0277085304260254
Batch 34/64 loss: -1.9200925827026367
Batch 35/64 loss: -1.7292728424072266
Batch 36/64 loss: -1.7147102355957031
Batch 37/64 loss: -1.7612762451171875
Batch 38/64 loss: -1.8886909484863281
Batch 39/64 loss: -1.4514923095703125
Batch 40/64 loss: -1.7700772285461426
Batch 41/64 loss: -1.2458992004394531
Batch 42/64 loss: -1.8167390823364258
Batch 43/64 loss: -1.8618574142456055
Batch 44/64 loss: -1.8525443077087402
Batch 45/64 loss: -1.8451762199401855
Batch 46/64 loss: -1.9682426452636719
Batch 47/64 loss: -1.5946836471557617
Batch 48/64 loss: -1.7044248580932617
Batch 49/64 loss: -1.6146173477172852
Batch 50/64 loss: -1.8890438079833984
Batch 51/64 loss: -1.6670541763305664
Batch 52/64 loss: -1.7860221862792969
Batch 53/64 loss: -1.4738407135009766
Batch 54/64 loss: -1.66009521484375
Batch 55/64 loss: -1.5265941619873047
Batch 56/64 loss: -1.5729923248291016
Batch 57/64 loss: -1.9747915267944336
Batch 58/64 loss: -1.8921499252319336
Batch 59/64 loss: -1.6199951171875
Batch 60/64 loss: -1.703749656677246
Batch 61/64 loss: -1.6281604766845703
Batch 62/64 loss: -1.1758337020874023
Batch 63/64 loss: -1.6506767272949219
Batch 64/64 loss: -5.416382789611816
Epoch 317  Train loss: -1.788087354921827  Val loss: -1.9428741481295975
Epoch 318
-------------------------------
Batch 1/64 loss: -2.0522985458374023
Batch 2/64 loss: -1.860060691833496
Batch 3/64 loss: -1.8456449508666992
Batch 4/64 loss: -1.0530643463134766
Batch 5/64 loss: -1.5675697326660156
Batch 6/64 loss: -1.621230125427246
Batch 7/64 loss: -1.2098655700683594
Batch 8/64 loss: -1.8914985656738281
Batch 9/64 loss: -1.722579002380371
Batch 10/64 loss: -1.6079864501953125
Batch 11/64 loss: -1.2854843139648438
Batch 12/64 loss: -1.9584922790527344
Batch 13/64 loss: -1.8900089263916016
Batch 14/64 loss: -1.8834538459777832
Batch 15/64 loss: -1.9454479217529297
Batch 16/64 loss: -2.1694154739379883
Batch 17/64 loss: -1.6487560272216797
Batch 18/64 loss: -1.6600255966186523
Batch 19/64 loss: -1.6075716018676758
Batch 20/64 loss: -1.8938565254211426
Batch 21/64 loss: -2.0436553955078125
Batch 22/64 loss: -1.867431640625
Batch 23/64 loss: -1.6190109252929688
Batch 24/64 loss: -1.770939826965332
Batch 25/64 loss: -1.8233203887939453
Batch 26/64 loss: -1.4168949127197266
Batch 27/64 loss: -1.9167909622192383
Batch 28/64 loss: -1.829972267150879
Batch 29/64 loss: -1.2414722442626953
Batch 30/64 loss: -1.8019556999206543
Batch 31/64 loss: -1.6247129440307617
Batch 32/64 loss: -1.6543941497802734
Batch 33/64 loss: -1.927823543548584
Batch 34/64 loss: -1.6581573486328125
Batch 35/64 loss: -1.918710708618164
Batch 36/64 loss: -1.959101676940918
Batch 37/64 loss: -1.5201683044433594
Batch 38/64 loss: -1.6265296936035156
Batch 39/64 loss: -1.8262910842895508
Batch 40/64 loss: -1.8061819076538086
Batch 41/64 loss: -1.8447084426879883
Batch 42/64 loss: -1.505716323852539
Batch 43/64 loss: -1.792738914489746
Batch 44/64 loss: -1.6492481231689453
Batch 45/64 loss: -1.9603233337402344
Batch 46/64 loss: -2.017098903656006
Batch 47/64 loss: -2.0413713455200195
Batch 48/64 loss: -1.8175811767578125
Batch 49/64 loss: -1.7535781860351562
Batch 50/64 loss: -1.813899040222168
Batch 51/64 loss: -1.8060789108276367
Batch 52/64 loss: -1.8916034698486328
Batch 53/64 loss: -1.8952865600585938
Batch 54/64 loss: -1.8309659957885742
Batch 55/64 loss: -1.6754779815673828
Batch 56/64 loss: -1.5885391235351562
Batch 57/64 loss: -1.5836315155029297
Batch 58/64 loss: -1.2114219665527344
Batch 59/64 loss: -1.770348072052002
Batch 60/64 loss: -1.1717824935913086
Batch 61/64 loss: -1.2407560348510742
Batch 62/64 loss: -1.7722206115722656
Batch 63/64 loss: -1.527303695678711
Batch 64/64 loss: -5.9129414558410645
Epoch 318  Train loss: -1.7697915675593356  Val loss: -1.7887901489677298
Epoch 319
-------------------------------
Batch 1/64 loss: -1.827066421508789
Batch 2/64 loss: -1.5179738998413086
Batch 3/64 loss: -1.6406488418579102
Batch 4/64 loss: -1.8570404052734375
Batch 5/64 loss: -1.8094854354858398
Batch 6/64 loss: -1.6544923782348633
Batch 7/64 loss: -1.9060215950012207
Batch 8/64 loss: -1.8998956680297852
Batch 9/64 loss: -1.596848487854004
Batch 10/64 loss: -1.8162126541137695
Batch 11/64 loss: -1.6908483505249023
Batch 12/64 loss: -1.81884765625
Batch 13/64 loss: -1.8133487701416016
Batch 14/64 loss: -1.5941953659057617
Batch 15/64 loss: -1.9870023727416992
Batch 16/64 loss: -2.0691165924072266
Batch 17/64 loss: -1.8809280395507812
Batch 18/64 loss: -1.793172836303711
Batch 19/64 loss: -1.649479866027832
Batch 20/64 loss: -1.565913200378418
Batch 21/64 loss: -1.6015920639038086
Batch 22/64 loss: -1.8814802169799805
Batch 23/64 loss: -1.8631582260131836
Batch 24/64 loss: -1.9484992027282715
Batch 25/64 loss: -1.7369680404663086
Batch 26/64 loss: -1.8271818161010742
Batch 27/64 loss: -1.9371204376220703
Batch 28/64 loss: -1.7623710632324219
Batch 29/64 loss: -1.8468103408813477
Batch 30/64 loss: -1.948716163635254
Batch 31/64 loss: -1.780538558959961
Batch 32/64 loss: -1.8915505409240723
Batch 33/64 loss: -2.065828323364258
Batch 34/64 loss: -1.396810531616211
Batch 35/64 loss: -1.7407474517822266
Batch 36/64 loss: -1.8624143600463867
Batch 37/64 loss: -1.9716954231262207
Batch 38/64 loss: -1.8637752532958984
Batch 39/64 loss: -1.4287395477294922
Batch 40/64 loss: -1.809549331665039
Batch 41/64 loss: -1.9591646194458008
Batch 42/64 loss: -1.5484662055969238
Batch 43/64 loss: -1.6459903717041016
Batch 44/64 loss: -1.8269405364990234
Batch 45/64 loss: -1.6091365814208984
Batch 46/64 loss: -1.8274221420288086
Batch 47/64 loss: -1.508035659790039
Batch 48/64 loss: -1.6281671524047852
Batch 49/64 loss: -1.8645811080932617
Batch 50/64 loss: -1.836374282836914
Batch 51/64 loss: -1.7923927307128906
Batch 52/64 loss: -1.3597030639648438
Batch 53/64 loss: -1.7475881576538086
Batch 54/64 loss: -1.9875688552856445
Batch 55/64 loss: -1.6790246963500977
Batch 56/64 loss: -1.755274772644043
Batch 57/64 loss: -1.9674358367919922
Batch 58/64 loss: -1.555318832397461
Batch 59/64 loss: -1.8747682571411133
Batch 60/64 loss: -1.8986239433288574
Batch 61/64 loss: -1.8294801712036133
Batch 62/64 loss: -1.5308313369750977
Batch 63/64 loss: -1.4993019104003906
Batch 64/64 loss: -6.004724979400635
Epoch 319  Train loss: -1.8163015010310155  Val loss: -2.0025269944233584
Epoch 320
-------------------------------
Batch 1/64 loss: -1.8442888259887695
Batch 2/64 loss: -1.8623838424682617
Batch 3/64 loss: -1.6399946212768555
Batch 4/64 loss: -2.193561553955078
Batch 5/64 loss: -1.8307218551635742
Batch 6/64 loss: -2.033346176147461
Batch 7/64 loss: -1.846940040588379
Batch 8/64 loss: -1.9412431716918945
Batch 9/64 loss: -1.7783088684082031
Batch 10/64 loss: -1.664907455444336
Batch 11/64 loss: -1.665433406829834
Batch 12/64 loss: -1.780721664428711
Batch 13/64 loss: -1.7748727798461914
Batch 14/64 loss: -1.994774341583252
Batch 15/64 loss: -1.7389945983886719
Batch 16/64 loss: -1.7855815887451172
Batch 17/64 loss: -1.7692394256591797
Batch 18/64 loss: -1.7717838287353516
Batch 19/64 loss: -1.5135269165039062
Batch 20/64 loss: -1.6647405624389648
Batch 21/64 loss: -1.7615489959716797
Batch 22/64 loss: -1.313033103942871
Batch 23/64 loss: -1.6533708572387695
Batch 24/64 loss: -1.6022758483886719
Batch 25/64 loss: -1.8664865493774414
Batch 26/64 loss: -1.7390727996826172
Batch 27/64 loss: -1.324723243713379
Batch 28/64 loss: -1.6298589706420898
Batch 29/64 loss: -1.700277328491211
Batch 30/64 loss: -1.8855466842651367
Batch 31/64 loss: -1.2599172592163086
Batch 32/64 loss: -1.7371091842651367
Batch 33/64 loss: -2.069148063659668
Batch 34/64 loss: -1.8078241348266602
Batch 35/64 loss: -1.6153526306152344
Batch 36/64 loss: -2.0630006790161133
Batch 37/64 loss: -1.6400394439697266
Batch 38/64 loss: -1.866450309753418
Batch 39/64 loss: -1.445474624633789
Batch 40/64 loss: -1.9532709121704102
Batch 41/64 loss: -1.8451032638549805
Batch 42/64 loss: -2.0214672088623047
Batch 43/64 loss: -1.9222583770751953
Batch 44/64 loss: -1.9261631965637207
Batch 45/64 loss: -2.044217109680176
Batch 46/64 loss: -1.9073553085327148
Batch 47/64 loss: -1.0763864517211914
Batch 48/64 loss: -1.7584772109985352
Batch 49/64 loss: -2.0441951751708984
Batch 50/64 loss: -1.9161062240600586
Batch 51/64 loss: -1.4665040969848633
Batch 52/64 loss: -1.8989601135253906
Batch 53/64 loss: -1.220728874206543
Batch 54/64 loss: -2.0732221603393555
Batch 55/64 loss: -1.5079383850097656
Batch 56/64 loss: -2.0051841735839844
Batch 57/64 loss: -1.772831916809082
Batch 58/64 loss: -1.8625860214233398
Batch 59/64 loss: -1.8976211547851562
Batch 60/64 loss: -1.7987661361694336
Batch 61/64 loss: -1.5918340682983398
Batch 62/64 loss: -1.9676532745361328
Batch 63/64 loss: -1.4320545196533203
Batch 64/64 loss: -6.182651519775391
Epoch 320  Train loss: -1.8137058856440524  Val loss: -1.9581083841749893
Epoch 321
-------------------------------
Batch 1/64 loss: -1.7139482498168945
Batch 2/64 loss: -1.2420854568481445
Batch 3/64 loss: -1.8971281051635742
Batch 4/64 loss: -1.8169002532958984
Batch 5/64 loss: -1.9095325469970703
Batch 6/64 loss: -2.0305862426757812
Batch 7/64 loss: -1.839247703552246
Batch 8/64 loss: -1.8331384658813477
Batch 9/64 loss: -1.3233919143676758
Batch 10/64 loss: -1.6690702438354492
Batch 11/64 loss: -1.8758516311645508
Batch 12/64 loss: -2.0378966331481934
Batch 13/64 loss: -1.3991260528564453
Batch 14/64 loss: -1.9145164489746094
Batch 15/64 loss: -1.7057371139526367
Batch 16/64 loss: -2.0075278282165527
Batch 17/64 loss: -1.8414230346679688
Batch 18/64 loss: -1.9694795608520508
Batch 19/64 loss: -1.8463268280029297
Batch 20/64 loss: -1.847585678100586
Batch 21/64 loss: -1.9314050674438477
Batch 22/64 loss: -1.9808464050292969
Batch 23/64 loss: -1.8669242858886719
Batch 24/64 loss: -1.694972038269043
Batch 25/64 loss: -1.941697120666504
Batch 26/64 loss: -1.5371694564819336
Batch 27/64 loss: -0.9658470153808594
Batch 28/64 loss: -1.8920903205871582
Batch 29/64 loss: -1.8113641738891602
Batch 30/64 loss: -1.9186210632324219
Batch 31/64 loss: -1.972580909729004
Batch 32/64 loss: -1.6788864135742188
Batch 33/64 loss: -1.6849288940429688
Batch 34/64 loss: -1.6912260055541992
Batch 35/64 loss: -1.9979496002197266
Batch 36/64 loss: -1.8465471267700195
Batch 37/64 loss: -1.5009746551513672
Batch 38/64 loss: -1.8214778900146484
Batch 39/64 loss: -1.283792495727539
Batch 40/64 loss: -1.573556900024414
Batch 41/64 loss: -1.6571664810180664
Batch 42/64 loss: -1.556321144104004
Batch 43/64 loss: -1.819575309753418
Batch 44/64 loss: -1.1162595748901367
Batch 45/64 loss: -1.4339704513549805
Batch 46/64 loss: -1.6928701400756836
Batch 47/64 loss: -1.8296146392822266
Batch 48/64 loss: -1.7449865341186523
Batch 49/64 loss: -1.7259254455566406
Batch 50/64 loss: -1.7984294891357422
Batch 51/64 loss: -1.6151504516601562
Batch 52/64 loss: -1.6095476150512695
Batch 53/64 loss: -1.7911367416381836
Batch 54/64 loss: -1.6667461395263672
Batch 55/64 loss: -1.8376131057739258
Batch 56/64 loss: -1.6903572082519531
Batch 57/64 loss: -1.8532800674438477
Batch 58/64 loss: -1.5635309219360352
Batch 59/64 loss: -1.5873832702636719
Batch 60/64 loss: -1.745650291442871
Batch 61/64 loss: -1.9058666229248047
Batch 62/64 loss: -1.8439617156982422
Batch 63/64 loss: -1.9368762969970703
Batch 64/64 loss: -5.433460235595703
Epoch 321  Train loss: -1.7789909437590954  Val loss: -1.8115026598533814
Epoch 322
-------------------------------
Batch 1/64 loss: -1.372410774230957
Batch 2/64 loss: -1.73162841796875
Batch 3/64 loss: -2.0269460678100586
Batch 4/64 loss: -1.9137849807739258
Batch 5/64 loss: -0.5197343826293945
Batch 6/64 loss: -1.643228530883789
Batch 7/64 loss: -1.6177692413330078
Batch 8/64 loss: -1.6648855209350586
Batch 9/64 loss: -1.9873061180114746
Batch 10/64 loss: -2.0457887649536133
Batch 11/64 loss: -1.5719051361083984
Batch 12/64 loss: -1.7522573471069336
Batch 13/64 loss: -1.620314598083496
Batch 14/64 loss: -1.8631677627563477
Batch 15/64 loss: -1.7759904861450195
Batch 16/64 loss: -2.0480403900146484
Batch 17/64 loss: -1.805312156677246
Batch 18/64 loss: -1.6502857208251953
Batch 19/64 loss: -1.3918352127075195
Batch 20/64 loss: -1.5849943161010742
Batch 21/64 loss: -1.7891626358032227
Batch 22/64 loss: -1.8016271591186523
Batch 23/64 loss: -1.3665246963500977
Batch 24/64 loss: -1.858102798461914
Batch 25/64 loss: -1.8013830184936523
Batch 26/64 loss: -1.8993263244628906
Batch 27/64 loss: -1.9817962646484375
Batch 28/64 loss: -1.8796768188476562
Batch 29/64 loss: -1.6029605865478516
Batch 30/64 loss: -1.6562013626098633
Batch 31/64 loss: -1.8402037620544434
Batch 32/64 loss: -1.7532806396484375
Batch 33/64 loss: -1.9177637100219727
Batch 34/64 loss: -1.8594818115234375
Batch 35/64 loss: -1.962148666381836
Batch 36/64 loss: -1.2657718658447266
Batch 37/64 loss: -1.8790950775146484
Batch 38/64 loss: -1.734583854675293
Batch 39/64 loss: -1.7445554733276367
Batch 40/64 loss: -1.9082908630371094
Batch 41/64 loss: -2.173133373260498
Batch 42/64 loss: -1.8817181587219238
Batch 43/64 loss: -1.989889144897461
Batch 44/64 loss: -1.990793228149414
Batch 45/64 loss: -1.9560813903808594
Batch 46/64 loss: -1.8657007217407227
Batch 47/64 loss: -1.8878469467163086
Batch 48/64 loss: -1.886073112487793
Batch 49/64 loss: -1.850550651550293
Batch 50/64 loss: -1.6710920333862305
Batch 51/64 loss: -1.882291316986084
Batch 52/64 loss: -1.743581771850586
Batch 53/64 loss: -1.729170799255371
Batch 54/64 loss: -1.8016242980957031
Batch 55/64 loss: -1.5744247436523438
Batch 56/64 loss: -1.6192102432250977
Batch 57/64 loss: -1.820220947265625
Batch 58/64 loss: -1.663517951965332
Batch 59/64 loss: -1.7848129272460938
Batch 60/64 loss: -1.8989076614379883
Batch 61/64 loss: -1.6147899627685547
Batch 62/64 loss: -1.9616804122924805
Batch 63/64 loss: -1.9308528900146484
Batch 64/64 loss: -6.013092041015625
Epoch 322  Train loss: -1.8161146201339422  Val loss: -1.8731925675959111
Epoch 323
-------------------------------
Batch 1/64 loss: -1.9923148155212402
Batch 2/64 loss: -1.6419954299926758
Batch 3/64 loss: -1.868626594543457
Batch 4/64 loss: -1.8178272247314453
Batch 5/64 loss: -1.555105209350586
Batch 6/64 loss: -1.727987289428711
Batch 7/64 loss: -1.6499881744384766
Batch 8/64 loss: -1.7289609909057617
Batch 9/64 loss: -1.48675537109375
Batch 10/64 loss: -1.8572416305541992
Batch 11/64 loss: -1.6622591018676758
Batch 12/64 loss: -1.758793830871582
Batch 13/64 loss: -1.4526691436767578
Batch 14/64 loss: -1.4984426498413086
Batch 15/64 loss: -1.7228584289550781
Batch 16/64 loss: -1.912459373474121
Batch 17/64 loss: -1.7330284118652344
Batch 18/64 loss: -1.505385398864746
Batch 19/64 loss: -1.9042930603027344
Batch 20/64 loss: -1.717123031616211
Batch 21/64 loss: -1.7538337707519531
Batch 22/64 loss: -1.5755395889282227
Batch 23/64 loss: -1.6953039169311523
Batch 24/64 loss: -1.9723682403564453
Batch 25/64 loss: -1.803135871887207
Batch 26/64 loss: -1.8211250305175781
Batch 27/64 loss: -1.7711763381958008
Batch 28/64 loss: -1.775649070739746
Batch 29/64 loss: -1.662245750427246
Batch 30/64 loss: -1.7161893844604492
Batch 31/64 loss: -1.937408447265625
Batch 32/64 loss: -1.7529773712158203
Batch 33/64 loss: -1.7322254180908203
Batch 34/64 loss: -1.583235740661621
Batch 35/64 loss: -1.80656099319458
Batch 36/64 loss: -1.803318977355957
Batch 37/64 loss: -1.7222537994384766
Batch 38/64 loss: -1.4261512756347656
Batch 39/64 loss: -1.7946834564208984
Batch 40/64 loss: -1.743509292602539
Batch 41/64 loss: -1.135232925415039
Batch 42/64 loss: -1.9588651657104492
Batch 43/64 loss: -1.7506513595581055
Batch 44/64 loss: -1.809473991394043
Batch 45/64 loss: -1.8017997741699219
Batch 46/64 loss: -1.8800926208496094
Batch 47/64 loss: -1.382645606994629
Batch 48/64 loss: -1.7554960250854492
Batch 49/64 loss: -1.7151470184326172
Batch 50/64 loss: -1.7490253448486328
Batch 51/64 loss: -1.6462106704711914
Batch 52/64 loss: -1.3392858505249023
Batch 53/64 loss: -1.1526470184326172
Batch 54/64 loss: -1.6676759719848633
Batch 55/64 loss: -1.6041889190673828
Batch 56/64 loss: -1.8816642761230469
Batch 57/64 loss: -1.5926399230957031
Batch 58/64 loss: -1.6223392486572266
Batch 59/64 loss: -1.8706436157226562
Batch 60/64 loss: -1.9136533737182617
Batch 61/64 loss: -1.1892595291137695
Batch 62/64 loss: -1.9682698249816895
Batch 63/64 loss: -1.6038150787353516
Batch 64/64 loss: -5.926204204559326
Epoch 323  Train loss: -1.7486805205251656  Val loss: -1.9335100888386625
Epoch 324
-------------------------------
Batch 1/64 loss: -1.9794869422912598
Batch 2/64 loss: -1.6064109802246094
Batch 3/64 loss: -1.6310195922851562
Batch 4/64 loss: -1.766688346862793
Batch 5/64 loss: -1.725639820098877
Batch 6/64 loss: -1.939997673034668
Batch 7/64 loss: -1.8460206985473633
Batch 8/64 loss: -1.6424455642700195
Batch 9/64 loss: -2.029280662536621
Batch 10/64 loss: -1.9613666534423828
Batch 11/64 loss: -1.906994342803955
Batch 12/64 loss: -2.04579496383667
Batch 13/64 loss: -1.8599605560302734
Batch 14/64 loss: -1.5830965042114258
Batch 15/64 loss: -1.5963268280029297
Batch 16/64 loss: -1.996142864227295
Batch 17/64 loss: -2.008345603942871
Batch 18/64 loss: -2.07177734375
Batch 19/64 loss: -1.1702146530151367
Batch 20/64 loss: -1.5830745697021484
Batch 21/64 loss: -1.848623275756836
Batch 22/64 loss: -1.9004855155944824
Batch 23/64 loss: -1.815049171447754
Batch 24/64 loss: -2.088559150695801
Batch 25/64 loss: -1.6262712478637695
Batch 26/64 loss: -1.6978893280029297
Batch 27/64 loss: -1.7932071685791016
Batch 28/64 loss: -1.9510879516601562
Batch 29/64 loss: -2.1183085441589355
Batch 30/64 loss: -1.8381166458129883
Batch 31/64 loss: -1.7825145721435547
Batch 32/64 loss: -1.8474712371826172
Batch 33/64 loss: -1.991194725036621
Batch 34/64 loss: -1.5719680786132812
Batch 35/64 loss: -1.6535272598266602
Batch 36/64 loss: -1.5019569396972656
Batch 37/64 loss: -1.4878196716308594
Batch 38/64 loss: -1.9832630157470703
Batch 39/64 loss: -1.775385856628418
Batch 40/64 loss: -1.998786449432373
Batch 41/64 loss: -1.9892387390136719
Batch 42/64 loss: -1.860626220703125
Batch 43/64 loss: -1.792572021484375
Batch 44/64 loss: -1.8130769729614258
Batch 45/64 loss: -1.8050336837768555
Batch 46/64 loss: -1.8750896453857422
Batch 47/64 loss: -1.7925939559936523
Batch 48/64 loss: -1.8336448669433594
Batch 49/64 loss: -1.765665054321289
Batch 50/64 loss: -1.6758852005004883
Batch 51/64 loss: -1.6394720077514648
Batch 52/64 loss: -1.8113651275634766
Batch 53/64 loss: -1.7045831680297852
Batch 54/64 loss: -1.7065792083740234
Batch 55/64 loss: -1.614670753479004
Batch 56/64 loss: -1.8078298568725586
Batch 57/64 loss: -1.8986921310424805
Batch 58/64 loss: -1.1458492279052734
Batch 59/64 loss: -2.0263586044311523
Batch 60/64 loss: -2.0479793548583984
Batch 61/64 loss: -1.5167551040649414
Batch 62/64 loss: -1.824014663696289
Batch 63/64 loss: -1.7583370208740234
Batch 64/64 loss: -5.630881309509277
Epoch 324  Train loss: -1.837657169267243  Val loss: -1.8808586802269585
Epoch 325
-------------------------------
Batch 1/64 loss: -1.7872982025146484
Batch 2/64 loss: -1.9793376922607422
Batch 3/64 loss: -1.7719049453735352
Batch 4/64 loss: -1.9712352752685547
Batch 5/64 loss: -1.7759590148925781
Batch 6/64 loss: -1.7765941619873047
Batch 7/64 loss: -1.5741920471191406
Batch 8/64 loss: -1.7932024002075195
Batch 9/64 loss: -1.5696935653686523
Batch 10/64 loss: -1.964655876159668
Batch 11/64 loss: -1.9949817657470703
Batch 12/64 loss: -1.6121463775634766
Batch 13/64 loss: -1.7003936767578125
Batch 14/64 loss: -1.7859134674072266
Batch 15/64 loss: -1.9664955139160156
Batch 16/64 loss: -1.8780250549316406
Batch 17/64 loss: -1.6497154235839844
Batch 18/64 loss: -1.7984771728515625
Batch 19/64 loss: -1.4313383102416992
Batch 20/64 loss: -1.5190696716308594
Batch 21/64 loss: -1.6856908798217773
Batch 22/64 loss: -1.6902551651000977
Batch 23/64 loss: -1.75238037109375
Batch 24/64 loss: -1.619612693786621
Batch 25/64 loss: -1.5455522537231445
Batch 26/64 loss: -1.5178403854370117
Batch 27/64 loss: -1.6713933944702148
Batch 28/64 loss: -1.8072690963745117
Batch 29/64 loss: -1.794360637664795
Batch 30/64 loss: -1.5971660614013672
Batch 31/64 loss: -1.6208992004394531
Batch 32/64 loss: -1.4876012802124023
Batch 33/64 loss: -1.812551498413086
Batch 34/64 loss: -2.105564594268799
Batch 35/64 loss: -1.7351140975952148
Batch 36/64 loss: -1.2280654907226562
Batch 37/64 loss: -1.867116928100586
Batch 38/64 loss: -1.9865646362304688
Batch 39/64 loss: -1.9420113563537598
Batch 40/64 loss: -1.8521909713745117
Batch 41/64 loss: -1.7819089889526367
Batch 42/64 loss: -1.6247758865356445
Batch 43/64 loss: -1.50958251953125
Batch 44/64 loss: -1.783132553100586
Batch 45/64 loss: -2.1187596321105957
Batch 46/64 loss: -1.5304679870605469
Batch 47/64 loss: -1.5112228393554688
Batch 48/64 loss: -1.6660490036010742
Batch 49/64 loss: -1.5280370712280273
Batch 50/64 loss: -1.7858266830444336
Batch 51/64 loss: -1.8793816566467285
Batch 52/64 loss: -1.6360292434692383
Batch 53/64 loss: -1.99137544631958
Batch 54/64 loss: -1.6178760528564453
Batch 55/64 loss: -1.8678369522094727
Batch 56/64 loss: -1.5206975936889648
Batch 57/64 loss: -1.6208076477050781
Batch 58/64 loss: -1.8358192443847656
Batch 59/64 loss: -1.5801239013671875
Batch 60/64 loss: -1.4222030639648438
Batch 61/64 loss: -1.720646858215332
Batch 62/64 loss: -2.0843000411987305
Batch 63/64 loss: -1.3355865478515625
Batch 64/64 loss: -5.615157127380371
Epoch 325  Train loss: -1.7691552293066886  Val loss: -1.9507136262978886
Epoch 326
-------------------------------
Batch 1/64 loss: -1.9501080513000488
Batch 2/64 loss: -1.9594817161560059
Batch 3/64 loss: -1.5887861251831055
Batch 4/64 loss: -1.7044363021850586
Batch 5/64 loss: -1.7973318099975586
Batch 6/64 loss: -1.4907121658325195
Batch 7/64 loss: -1.5117921829223633
Batch 8/64 loss: -1.7439031600952148
Batch 9/64 loss: -1.8640460968017578
Batch 10/64 loss: -1.30841064453125
Batch 11/64 loss: -1.9928197860717773
Batch 12/64 loss: -2.072916030883789
Batch 13/64 loss: -1.8286809921264648
Batch 14/64 loss: -1.5552024841308594
Batch 15/64 loss: -1.8151025772094727
Batch 16/64 loss: -1.9171037673950195
Batch 17/64 loss: -1.9225139617919922
Batch 18/64 loss: -1.853902816772461
Batch 19/64 loss: -1.4141559600830078
Batch 20/64 loss: -1.788339614868164
Batch 21/64 loss: -1.6417264938354492
Batch 22/64 loss: -1.6634063720703125
Batch 23/64 loss: -1.9598946571350098
Batch 24/64 loss: -1.659480094909668
Batch 25/64 loss: -1.9625215530395508
Batch 26/64 loss: -1.3503408432006836
Batch 27/64 loss: -1.3051061630249023
Batch 28/64 loss: -2.05545711517334
Batch 29/64 loss: -1.7275724411010742
Batch 30/64 loss: -1.7387456893920898
Batch 31/64 loss: -1.8789262771606445
Batch 32/64 loss: -1.9152803421020508
Batch 33/64 loss: -1.745265007019043
Batch 34/64 loss: -1.566202163696289
Batch 35/64 loss: -0.9691085815429688
Batch 36/64 loss: -1.6896028518676758
Batch 37/64 loss: -1.8149385452270508
Batch 38/64 loss: -1.8810997009277344
Batch 39/64 loss: -1.7001562118530273
Batch 40/64 loss: -1.7595577239990234
Batch 41/64 loss: -1.4109125137329102
Batch 42/64 loss: -1.6939363479614258
Batch 43/64 loss: -1.6696815490722656
Batch 44/64 loss: -1.8317089080810547
Batch 45/64 loss: -1.6557254791259766
Batch 46/64 loss: -2.0653514862060547
Batch 47/64 loss: -1.5509796142578125
Batch 48/64 loss: -1.9168787002563477
Batch 49/64 loss: -1.749807357788086
Batch 50/64 loss: -1.7915306091308594
Batch 51/64 loss: -1.7696924209594727
Batch 52/64 loss: -1.5631065368652344
Batch 53/64 loss: -1.689436912536621
Batch 54/64 loss: -1.829787254333496
Batch 55/64 loss: -1.4595327377319336
Batch 56/64 loss: -1.7495617866516113
Batch 57/64 loss: -1.7561416625976562
Batch 58/64 loss: -1.6435365676879883
Batch 59/64 loss: -1.5960931777954102
Batch 60/64 loss: -1.7905712127685547
Batch 61/64 loss: -1.926896572113037
Batch 62/64 loss: -1.7221612930297852
Batch 63/64 loss: -1.9898700714111328
Batch 64/64 loss: -5.344049453735352
Epoch 326  Train loss: -1.7709031048943014  Val loss: -1.9391601405192895
Epoch 327
-------------------------------
Batch 1/64 loss: -1.7225360870361328
Batch 2/64 loss: -1.6271181106567383
Batch 3/64 loss: -1.7570695877075195
Batch 4/64 loss: -1.4554367065429688
Batch 5/64 loss: -1.5912532806396484
Batch 6/64 loss: -1.8192243576049805
Batch 7/64 loss: -1.804398536682129
Batch 8/64 loss: -1.968088150024414
Batch 9/64 loss: -1.879415512084961
Batch 10/64 loss: -1.968454360961914
Batch 11/64 loss: -1.4471635818481445
Batch 12/64 loss: -1.3640108108520508
Batch 13/64 loss: -1.8522539138793945
Batch 14/64 loss: -1.9315237998962402
Batch 15/64 loss: -0.5007114410400391
Batch 16/64 loss: -1.375676155090332
Batch 17/64 loss: -1.6236677169799805
Batch 18/64 loss: -1.9438672065734863
Batch 19/64 loss: -1.7735633850097656
Batch 20/64 loss: -1.751617431640625
Batch 21/64 loss: -1.9088010787963867
Batch 22/64 loss: -1.7411823272705078
Batch 23/64 loss: -1.523472785949707
Batch 24/64 loss: -1.2528181076049805
Batch 25/64 loss: -1.6362533569335938
Batch 26/64 loss: -1.817967414855957
Batch 27/64 loss: -1.7400474548339844
Batch 28/64 loss: -1.5424003601074219
Batch 29/64 loss: -1.475153923034668
Batch 30/64 loss: -1.9481544494628906
Batch 31/64 loss: -1.7068099975585938
Batch 32/64 loss: -1.674581527709961
Batch 33/64 loss: -1.9196081161499023
Batch 34/64 loss: -1.796194076538086
Batch 35/64 loss: -1.6517906188964844
Batch 36/64 loss: -1.7787017822265625
Batch 37/64 loss: -1.6336002349853516
Batch 38/64 loss: -1.8463983535766602
Batch 39/64 loss: -1.4893035888671875
Batch 40/64 loss: -1.8323888778686523
Batch 41/64 loss: -1.4291191101074219
Batch 42/64 loss: -1.792983055114746
Batch 43/64 loss: -1.774461269378662
Batch 44/64 loss: -1.6917123794555664
Batch 45/64 loss: -1.976912498474121
Batch 46/64 loss: -1.680506706237793
Batch 47/64 loss: -1.6763172149658203
Batch 48/64 loss: -1.5441179275512695
Batch 49/64 loss: -1.8261241912841797
Batch 50/64 loss: -1.6953496932983398
Batch 51/64 loss: -1.6797561645507812
Batch 52/64 loss: -2.122385025024414
Batch 53/64 loss: -1.9170799255371094
Batch 54/64 loss: -1.4436864852905273
Batch 55/64 loss: -1.5275249481201172
Batch 56/64 loss: -2.0401554107666016
Batch 57/64 loss: -1.7891454696655273
Batch 58/64 loss: -1.6884193420410156
Batch 59/64 loss: -1.7940025329589844
Batch 60/64 loss: -1.4844074249267578
Batch 61/64 loss: -1.8521451950073242
Batch 62/64 loss: -1.5267877578735352
Batch 63/64 loss: -1.827469825744629
Batch 64/64 loss: -5.557550430297852
Epoch 327  Train loss: -1.7415123285031786  Val loss: -1.8697706137326164
Epoch 328
-------------------------------
Batch 1/64 loss: -1.4997472763061523
Batch 2/64 loss: -1.673792839050293
Batch 3/64 loss: -1.6260910034179688
Batch 4/64 loss: -1.523604393005371
Batch 5/64 loss: -1.9098296165466309
Batch 6/64 loss: -1.378554344177246
Batch 7/64 loss: -1.7590093612670898
Batch 8/64 loss: -1.5773239135742188
Batch 9/64 loss: -1.9718666076660156
Batch 10/64 loss: -1.8530888557434082
Batch 11/64 loss: -1.4803638458251953
Batch 12/64 loss: -1.5178794860839844
Batch 13/64 loss: -1.0786151885986328
Batch 14/64 loss: -1.7499895095825195
Batch 15/64 loss: -1.6561660766601562
Batch 16/64 loss: -1.682840347290039
Batch 17/64 loss: -1.5157642364501953
Batch 18/64 loss: -1.803375244140625
Batch 19/64 loss: -1.601883888244629
Batch 20/64 loss: -1.7175688743591309
Batch 21/64 loss: -1.846151351928711
Batch 22/64 loss: -1.9608683586120605
Batch 23/64 loss: -1.7223787307739258
Batch 24/64 loss: -1.7241616249084473
Batch 25/64 loss: -1.8042469024658203
Batch 26/64 loss: -1.7419323921203613
Batch 27/64 loss: -1.6785211563110352
Batch 28/64 loss: -2.031461238861084
Batch 29/64 loss: -1.3268146514892578
Batch 30/64 loss: -1.649658203125
Batch 31/64 loss: -2.053309440612793
Batch 32/64 loss: -1.6616334915161133
Batch 33/64 loss: -1.8086833953857422
Batch 34/64 loss: -1.4430465698242188
Batch 35/64 loss: -1.3949480056762695
Batch 36/64 loss: -1.9574928283691406
Batch 37/64 loss: -1.3207311630249023
Batch 38/64 loss: -1.7355403900146484
Batch 39/64 loss: -1.676131248474121
Batch 40/64 loss: -1.7196674346923828
Batch 41/64 loss: -1.8304023742675781
Batch 42/64 loss: -1.814591884613037
Batch 43/64 loss: -1.678018569946289
Batch 44/64 loss: -1.8397331237792969
Batch 45/64 loss: -1.5863943099975586
Batch 46/64 loss: -1.9262537956237793
Batch 47/64 loss: -1.5812559127807617
Batch 48/64 loss: -1.7591276168823242
Batch 49/64 loss: -2.0691723823547363
Batch 50/64 loss: -2.0987653732299805
Batch 51/64 loss: -1.6750755310058594
Batch 52/64 loss: -1.9237890243530273
Batch 53/64 loss: -1.867753028869629
Batch 54/64 loss: -1.7221870422363281
Batch 55/64 loss: -1.9328861236572266
Batch 56/64 loss: -1.3645124435424805
Batch 57/64 loss: -1.9490594863891602
Batch 58/64 loss: -1.926858901977539
Batch 59/64 loss: -1.3554744720458984
Batch 60/64 loss: -1.4887475967407227
Batch 61/64 loss: -1.666769027709961
Batch 62/64 loss: -1.4189138412475586
Batch 63/64 loss: -1.657308578491211
Batch 64/64 loss: -5.39772891998291
Epoch 328  Train loss: -1.741428715574975  Val loss: -1.9476757115105174
Epoch 329
-------------------------------
Batch 1/64 loss: -1.7926788330078125
Batch 2/64 loss: -2.0034427642822266
Batch 3/64 loss: -1.5692481994628906
Batch 4/64 loss: -1.8119134902954102
Batch 5/64 loss: -1.7496728897094727
Batch 6/64 loss: -1.7807092666625977
Batch 7/64 loss: -1.8008918762207031
Batch 8/64 loss: -1.3487672805786133
Batch 9/64 loss: -1.7485713958740234
Batch 10/64 loss: -1.6952219009399414
Batch 11/64 loss: -1.6786861419677734
Batch 12/64 loss: -1.656386375427246
Batch 13/64 loss: -1.7429218292236328
Batch 14/64 loss: -1.868809700012207
Batch 15/64 loss: -2.0440564155578613
Batch 16/64 loss: -1.267486572265625
Batch 17/64 loss: -1.4013938903808594
Batch 18/64 loss: -1.5210728645324707
Batch 19/64 loss: -1.6539306640625
Batch 20/64 loss: -1.5708961486816406
Batch 21/64 loss: -1.6332354545593262
Batch 22/64 loss: -1.4531593322753906
Batch 23/64 loss: -1.050710678100586
Batch 24/64 loss: -1.75136137008667
Batch 25/64 loss: -1.8763465881347656
Batch 26/64 loss: -1.6855359077453613
Batch 27/64 loss: -1.8534679412841797
Batch 28/64 loss: -1.6067285537719727
Batch 29/64 loss: -1.413651466369629
Batch 30/64 loss: -1.6653738021850586
Batch 31/64 loss: -1.5679779052734375
Batch 32/64 loss: -1.8504571914672852
Batch 33/64 loss: -1.827439308166504
Batch 34/64 loss: -1.8131904602050781
Batch 35/64 loss: -1.6483373641967773
Batch 36/64 loss: -1.7374963760375977
Batch 37/64 loss: -1.6458196640014648
Batch 38/64 loss: -1.8559694290161133
Batch 39/64 loss: -1.8987560272216797
Batch 40/64 loss: -1.437591552734375
Batch 41/64 loss: -1.5958385467529297
Batch 42/64 loss: -1.924799919128418
Batch 43/64 loss: -1.603602409362793
Batch 44/64 loss: -1.6015729904174805
Batch 45/64 loss: -1.7490205764770508
Batch 46/64 loss: -1.3148279190063477
Batch 47/64 loss: -1.8049936294555664
Batch 48/64 loss: -1.5821752548217773
Batch 49/64 loss: -1.602250099182129
Batch 50/64 loss: -1.5184440612792969
Batch 51/64 loss: -1.7031517028808594
Batch 52/64 loss: -1.83856201171875
Batch 53/64 loss: -1.3789186477661133
Batch 54/64 loss: -1.2720880508422852
Batch 55/64 loss: -1.4570999145507812
Batch 56/64 loss: -1.8765678405761719
Batch 57/64 loss: -1.9766793251037598
Batch 58/64 loss: -1.9309005737304688
Batch 59/64 loss: -1.6969804763793945
Batch 60/64 loss: -1.966567039489746
Batch 61/64 loss: -1.7770442962646484
Batch 62/64 loss: -1.8177156448364258
Batch 63/64 loss: -1.6153030395507812
Batch 64/64 loss: -5.176513195037842
Epoch 329  Train loss: -1.7171271174561744  Val loss: -1.8295653169507424
Epoch 330
-------------------------------
Batch 1/64 loss: -1.3325119018554688
Batch 2/64 loss: -1.7336912155151367
Batch 3/64 loss: -1.8758659362792969
Batch 4/64 loss: -1.9453439712524414
Batch 5/64 loss: -1.787076473236084
Batch 6/64 loss: -1.8986091613769531
Batch 7/64 loss: -1.4483652114868164
Batch 8/64 loss: -1.6277637481689453
Batch 9/64 loss: -1.6920957565307617
Batch 10/64 loss: -2.052804946899414
Batch 11/64 loss: -1.788325309753418
Batch 12/64 loss: -1.4332590103149414
Batch 13/64 loss: -1.741508960723877
Batch 14/64 loss: -1.7905378341674805
Batch 15/64 loss: -1.684168815612793
Batch 16/64 loss: -1.9902067184448242
Batch 17/64 loss: -1.8282470703125
Batch 18/64 loss: -1.4631919860839844
Batch 19/64 loss: -1.3226861953735352
Batch 20/64 loss: -1.6824007034301758
Batch 21/64 loss: -1.5640764236450195
Batch 22/64 loss: -1.9005661010742188
Batch 23/64 loss: -1.8892784118652344
Batch 24/64 loss: -1.3300085067749023
Batch 25/64 loss: -1.6317930221557617
Batch 26/64 loss: -1.9664764404296875
Batch 27/64 loss: -1.5896549224853516
Batch 28/64 loss: -1.1431989669799805
Batch 29/64 loss: -0.9941301345825195
Batch 30/64 loss: -1.5575447082519531
Batch 31/64 loss: -1.8426017761230469
Batch 32/64 loss: -1.9720163345336914
Batch 33/64 loss: -1.6626520156860352
Batch 34/64 loss: -1.8565349578857422
Batch 35/64 loss: -1.7277097702026367
Batch 36/64 loss: -1.6033029556274414
Batch 37/64 loss: -1.6285696029663086
Batch 38/64 loss: -1.85614013671875
Batch 39/64 loss: -1.4830284118652344
Batch 40/64 loss: -1.9750747680664062
Batch 41/64 loss: -1.7994365692138672
Batch 42/64 loss: -1.485276222229004
Batch 43/64 loss: -1.3439826965332031
Batch 44/64 loss: -1.4852724075317383
Batch 45/64 loss: -1.6680641174316406
Batch 46/64 loss: -1.644047737121582
Batch 47/64 loss: -1.5841989517211914
Batch 48/64 loss: -1.5957012176513672
Batch 49/64 loss: -1.8703804016113281
Batch 50/64 loss: -1.9263505935668945
Batch 51/64 loss: -1.7034988403320312
Batch 52/64 loss: -1.5325641632080078
Batch 53/64 loss: -1.555251121520996
Batch 54/64 loss: -1.8708248138427734
Batch 55/64 loss: -1.6998834609985352
Batch 56/64 loss: -1.7796754837036133
Batch 57/64 loss: -1.5957717895507812
Batch 58/64 loss: -2.0124149322509766
Batch 59/64 loss: -1.620513916015625
Batch 60/64 loss: -1.6030559539794922
Batch 61/64 loss: -1.3738775253295898
Batch 62/64 loss: -1.2697086334228516
Batch 63/64 loss: -1.8876142501831055
Batch 64/64 loss: -5.980138778686523
Epoch 330  Train loss: -1.7205566929835898  Val loss: -1.7922544970954817
Epoch 331
-------------------------------
Batch 1/64 loss: -1.6853313446044922
Batch 2/64 loss: -1.84521484375
Batch 3/64 loss: -1.508218765258789
Batch 4/64 loss: -1.8618297576904297
Batch 5/64 loss: -1.7731389999389648
Batch 6/64 loss: -1.6800661087036133
Batch 7/64 loss: -1.847503662109375
Batch 8/64 loss: -1.7883129119873047
Batch 9/64 loss: -1.423110008239746
Batch 10/64 loss: -1.6444015502929688
Batch 11/64 loss: -1.452052116394043
Batch 12/64 loss: -1.149557113647461
Batch 13/64 loss: -1.6901187896728516
Batch 14/64 loss: -1.8506059646606445
Batch 15/64 loss: -1.588449478149414
Batch 16/64 loss: -1.776571273803711
Batch 17/64 loss: -1.4880475997924805
Batch 18/64 loss: -1.9225406646728516
Batch 19/64 loss: -1.6075944900512695
Batch 20/64 loss: -1.4683465957641602
Batch 21/64 loss: -1.6425752639770508
Batch 22/64 loss: -1.3649978637695312
Batch 23/64 loss: -1.4390621185302734
Batch 24/64 loss: -1.9609756469726562
Batch 25/64 loss: -1.578261375427246
Batch 26/64 loss: -1.5388669967651367
Batch 27/64 loss: -1.1767807006835938
Batch 28/64 loss: -1.6137676239013672
Batch 29/64 loss: -1.7919902801513672
Batch 30/64 loss: -1.5995616912841797
Batch 31/64 loss: -1.6641769409179688
Batch 32/64 loss: -1.786818504333496
Batch 33/64 loss: -1.9916810989379883
Batch 34/64 loss: -1.7452726364135742
Batch 35/64 loss: -1.6240520477294922
Batch 36/64 loss: -1.9251108169555664
Batch 37/64 loss: -1.827967643737793
Batch 38/64 loss: -1.4132204055786133
Batch 39/64 loss: -1.6777019500732422
Batch 40/64 loss: -1.4328393936157227
Batch 41/64 loss: -1.2029733657836914
Batch 42/64 loss: -1.559554100036621
Batch 43/64 loss: -1.6022634506225586
Batch 44/64 loss: -1.574955940246582
Batch 45/64 loss: -1.6455802917480469
Batch 46/64 loss: -1.479736328125
Batch 47/64 loss: -1.6991147994995117
Batch 48/64 loss: -1.4656133651733398
Batch 49/64 loss: -1.7419052124023438
Batch 50/64 loss: -1.74859619140625
Batch 51/64 loss: -1.7512006759643555
Batch 52/64 loss: -1.4659605026245117
Batch 53/64 loss: -1.4835491180419922
Batch 54/64 loss: -1.50225830078125
Batch 55/64 loss: -1.484389305114746
Batch 56/64 loss: -1.701822280883789
Batch 57/64 loss: -1.7554521560668945
Batch 58/64 loss: -1.5575752258300781
Batch 59/64 loss: -1.607802391052246
Batch 60/64 loss: -1.6831903457641602
Batch 61/64 loss: -0.9877901077270508
Batch 62/64 loss: -1.4520816802978516
Batch 63/64 loss: -1.6357345581054688
Batch 64/64 loss: -5.452733993530273
Epoch 331  Train loss: -1.6584367565080231  Val loss: -1.7800680337492953
Epoch 332
-------------------------------
Batch 1/64 loss: -1.9023361206054688
Batch 2/64 loss: -1.8300185203552246
Batch 3/64 loss: -1.4907283782958984
Batch 4/64 loss: -1.553182601928711
Batch 5/64 loss: -1.6330881118774414
Batch 6/64 loss: -1.3633222579956055
Batch 7/64 loss: -2.0285701751708984
Batch 8/64 loss: -1.3817243576049805
Batch 9/64 loss: -1.6220273971557617
Batch 10/64 loss: -1.5333795547485352
Batch 11/64 loss: -1.489069938659668
Batch 12/64 loss: -1.647918701171875
Batch 13/64 loss: -1.3716163635253906
Batch 14/64 loss: -1.6392574310302734
Batch 15/64 loss: -1.5030298233032227
Batch 16/64 loss: -1.6903858184814453
Batch 17/64 loss: -1.7999019622802734
Batch 18/64 loss: -1.0667037963867188
Batch 19/64 loss: -1.3404970169067383
Batch 20/64 loss: -1.610595703125
Batch 21/64 loss: -1.4632043838500977
Batch 22/64 loss: -1.5483026504516602
Batch 23/64 loss: -1.645456314086914
Batch 24/64 loss: -1.6829099655151367
Batch 25/64 loss: -1.676011085510254
Batch 26/64 loss: -1.560323715209961
Batch 27/64 loss: -1.6327381134033203
Batch 28/64 loss: -1.48828125
Batch 29/64 loss: -1.469334602355957
Batch 30/64 loss: -1.8428125381469727
Batch 31/64 loss: -1.484633445739746
Batch 32/64 loss: -2.078092575073242
Batch 33/64 loss: -1.1439094543457031
Batch 34/64 loss: -1.7691631317138672
Batch 35/64 loss: -1.6213140487670898
Batch 36/64 loss: -1.8183865547180176
Batch 37/64 loss: -1.8624286651611328
Batch 38/64 loss: -1.737654685974121
Batch 39/64 loss: -1.162008285522461
Batch 40/64 loss: -1.6217708587646484
Batch 41/64 loss: -1.7708892822265625
Batch 42/64 loss: -1.7378997802734375
Batch 43/64 loss: -1.7892837524414062
Batch 44/64 loss: -1.541153907775879
Batch 45/64 loss: -1.9839777946472168
Batch 46/64 loss: -1.7806453704833984
Batch 47/64 loss: -1.7895135879516602
Batch 48/64 loss: -1.4438591003417969
Batch 49/64 loss: -1.1151056289672852
Batch 50/64 loss: -1.675058364868164
Batch 51/64 loss: -1.6133155822753906
Batch 52/64 loss: -1.5386571884155273
Batch 53/64 loss: -1.8111391067504883
Batch 54/64 loss: -1.8481006622314453
Batch 55/64 loss: -1.7499656677246094
Batch 56/64 loss: -1.9034595489501953
Batch 57/64 loss: -1.8287200927734375
Batch 58/64 loss: -1.3146018981933594
Batch 59/64 loss: -1.6146841049194336
Batch 60/64 loss: -1.6632165908813477
Batch 61/64 loss: -1.372544288635254
Batch 62/64 loss: -1.770608901977539
Batch 63/64 loss: -1.790750503540039
Batch 64/64 loss: -5.968593597412109
Epoch 332  Train loss: -1.674191157023112  Val loss: -1.8278172286515384
Epoch 333
-------------------------------
Batch 1/64 loss: -1.7160272598266602
Batch 2/64 loss: -1.9410796165466309
Batch 3/64 loss: -1.3620281219482422
Batch 4/64 loss: -1.827805519104004
Batch 5/64 loss: -1.8761601448059082
Batch 6/64 loss: -1.6065444946289062
Batch 7/64 loss: -1.773604393005371
Batch 8/64 loss: -1.854753017425537
Batch 9/64 loss: -1.7330851554870605
Batch 10/64 loss: -1.6885509490966797
Batch 11/64 loss: -1.8254165649414062
Batch 12/64 loss: -1.8714990615844727
Batch 13/64 loss: -1.7150068283081055
Batch 14/64 loss: -1.8375654220581055
Batch 15/64 loss: -1.5290651321411133
Batch 16/64 loss: -1.7052383422851562
Batch 17/64 loss: -1.924180507659912
Batch 18/64 loss: -1.2621164321899414
Batch 19/64 loss: -1.6242303848266602
Batch 20/64 loss: -2.0066542625427246
Batch 21/64 loss: -1.5982723236083984
Batch 22/64 loss: -1.814901351928711
Batch 23/64 loss: -1.5983428955078125
Batch 24/64 loss: -1.7394380569458008
Batch 25/64 loss: -1.590230941772461
Batch 26/64 loss: -1.422342300415039
Batch 27/64 loss: -1.6074638366699219
Batch 28/64 loss: -1.919295310974121
Batch 29/64 loss: -1.7093524932861328
Batch 30/64 loss: -1.440272331237793
Batch 31/64 loss: -1.8808002471923828
Batch 32/64 loss: -1.7780771255493164
Batch 33/64 loss: -2.053689956665039
Batch 34/64 loss: -1.7325115203857422
Batch 35/64 loss: -1.4911432266235352
Batch 36/64 loss: -1.9341917037963867
Batch 37/64 loss: -1.7102327346801758
Batch 38/64 loss: -1.7856850624084473
Batch 39/64 loss: -1.7998580932617188
Batch 40/64 loss: -1.7278575897216797
Batch 41/64 loss: -1.3785486221313477
Batch 42/64 loss: -1.681584358215332
Batch 43/64 loss: -1.9361186027526855
Batch 44/64 loss: -1.9280118942260742
Batch 45/64 loss: -1.6633272171020508
Batch 46/64 loss: -1.8294448852539062
Batch 47/64 loss: -1.9896001815795898
Batch 48/64 loss: -1.9041633605957031
Batch 49/64 loss: -1.940145492553711
Batch 50/64 loss: -1.787379264831543
Batch 51/64 loss: -1.773972511291504
Batch 52/64 loss: -2.0608654022216797
Batch 53/64 loss: -1.7944040298461914
Batch 54/64 loss: -1.6595344543457031
Batch 55/64 loss: -1.703566551208496
Batch 56/64 loss: -2.0127029418945312
Batch 57/64 loss: -2.0102200508117676
Batch 58/64 loss: -1.826521873474121
Batch 59/64 loss: -1.728322982788086
Batch 60/64 loss: -1.5868234634399414
Batch 61/64 loss: -1.882375717163086
Batch 62/64 loss: -1.6755104064941406
Batch 63/64 loss: -1.6916275024414062
Batch 64/64 loss: -5.706226348876953
Epoch 333  Train loss: -1.7998276430017808  Val loss: -1.992384409167103
Epoch 334
-------------------------------
Batch 1/64 loss: -1.9581036567687988
Batch 2/64 loss: -1.6878719329833984
Batch 3/64 loss: -1.759758472442627
Batch 4/64 loss: -1.0561294555664062
Batch 5/64 loss: -1.4238719940185547
Batch 6/64 loss: -1.9077930450439453
Batch 7/64 loss: -1.7185983657836914
Batch 8/64 loss: -1.9263935089111328
Batch 9/64 loss: -1.7303714752197266
Batch 10/64 loss: -1.692108154296875
Batch 11/64 loss: -1.005528450012207
Batch 12/64 loss: -1.9750404357910156
Batch 13/64 loss: -1.6408357620239258
Batch 14/64 loss: -1.4711942672729492
Batch 15/64 loss: -1.9748353958129883
Batch 16/64 loss: -2.0476369857788086
Batch 17/64 loss: -1.9440865516662598
Batch 18/64 loss: -1.778219223022461
Batch 19/64 loss: -1.8117828369140625
Batch 20/64 loss: -1.6326684951782227
Batch 21/64 loss: -1.9644479751586914
Batch 22/64 loss: -1.8710298538208008
Batch 23/64 loss: -1.7299518585205078
Batch 24/64 loss: -1.701171875
Batch 25/64 loss: -1.6308279037475586
Batch 26/64 loss: -1.9429187774658203
Batch 27/64 loss: -1.5619134902954102
Batch 28/64 loss: -1.8483448028564453
Batch 29/64 loss: -1.3288259506225586
Batch 30/64 loss: -2.140225410461426
Batch 31/64 loss: -1.4618806838989258
Batch 32/64 loss: -1.820540428161621
Batch 33/64 loss: -2.049973964691162
Batch 34/64 loss: -1.2464618682861328
Batch 35/64 loss: -1.8989753723144531
Batch 36/64 loss: -1.9281063079833984
Batch 37/64 loss: -1.7534728050231934
Batch 38/64 loss: -1.5818910598754883
Batch 39/64 loss: -1.92877197265625
Batch 40/64 loss: -2.0440573692321777
Batch 41/64 loss: -1.9519720077514648
Batch 42/64 loss: -1.8485193252563477
Batch 43/64 loss: -1.7557811737060547
Batch 44/64 loss: -1.9222583770751953
Batch 45/64 loss: -1.4861345291137695
Batch 46/64 loss: -1.7259883880615234
Batch 47/64 loss: -1.9017009735107422
Batch 48/64 loss: -1.7532024383544922
Batch 49/64 loss: -1.7422237396240234
Batch 50/64 loss: -1.8531866073608398
Batch 51/64 loss: -1.8956317901611328
Batch 52/64 loss: -1.7199411392211914
Batch 53/64 loss: -1.8073954582214355
Batch 54/64 loss: -1.8710336685180664
Batch 55/64 loss: -1.6094284057617188
Batch 56/64 loss: -1.8937177658081055
Batch 57/64 loss: -1.7765512466430664
Batch 58/64 loss: -1.8581256866455078
Batch 59/64 loss: -2.129596710205078
Batch 60/64 loss: -1.819540023803711
Batch 61/64 loss: -1.6789522171020508
Batch 62/64 loss: -1.8906536102294922
Batch 63/64 loss: -2.1241321563720703
Batch 64/64 loss: -6.210271835327148
Epoch 334  Train loss: -1.8235292472091376  Val loss: -1.9719357703559588
Epoch 335
-------------------------------
Batch 1/64 loss: -2.1124701499938965
Batch 2/64 loss: -1.913747787475586
Batch 3/64 loss: -1.8741989135742188
Batch 4/64 loss: -1.508601188659668
Batch 5/64 loss: -1.830805778503418
Batch 6/64 loss: -1.7758302688598633
Batch 7/64 loss: -1.6223983764648438
Batch 8/64 loss: -1.7464399337768555
Batch 9/64 loss: -1.9961013793945312
Batch 10/64 loss: -1.9883956909179688
Batch 11/64 loss: -1.5528078079223633
Batch 12/64 loss: -1.6860971450805664
Batch 13/64 loss: -1.7035245895385742
Batch 14/64 loss: -1.7793188095092773
Batch 15/64 loss: -1.8630704879760742
Batch 16/64 loss: -1.4480018615722656
Batch 17/64 loss: -2.0457420349121094
Batch 18/64 loss: -0.7695684432983398
Batch 19/64 loss: -2.0219268798828125
Batch 20/64 loss: -1.8618698120117188
Batch 21/64 loss: -1.6187314987182617
Batch 22/64 loss: -1.622757911682129
Batch 23/64 loss: -1.9640793800354004
Batch 24/64 loss: -1.9413299560546875
Batch 25/64 loss: -1.9970707893371582
Batch 26/64 loss: -1.997952938079834
Batch 27/64 loss: -1.1977519989013672
Batch 28/64 loss: -1.8041954040527344
Batch 29/64 loss: -1.9003896713256836
Batch 30/64 loss: -1.9234790802001953
Batch 31/64 loss: -1.7144231796264648
Batch 32/64 loss: -1.5918464660644531
Batch 33/64 loss: -1.7361459732055664
Batch 34/64 loss: -1.5628061294555664
Batch 35/64 loss: -1.6769342422485352
Batch 36/64 loss: -1.5024795532226562
Batch 37/64 loss: -1.6876888275146484
Batch 38/64 loss: -2.062608242034912
Batch 39/64 loss: -2.086916923522949
Batch 40/64 loss: -1.6671648025512695
Batch 41/64 loss: -1.806126594543457
Batch 42/64 loss: -1.696753978729248
Batch 43/64 loss: -1.7584114074707031
Batch 44/64 loss: -1.6923198699951172
Batch 45/64 loss: -1.6686010360717773
Batch 46/64 loss: -1.6917123794555664
Batch 47/64 loss: -1.4202489852905273
Batch 48/64 loss: -1.707087516784668
Batch 49/64 loss: -1.7724370956420898
Batch 50/64 loss: -1.7545137405395508
Batch 51/64 loss: -1.7928390502929688
Batch 52/64 loss: -1.4968395233154297
Batch 53/64 loss: -1.3098869323730469
Batch 54/64 loss: -1.8074064254760742
Batch 55/64 loss: -1.6965618133544922
Batch 56/64 loss: -1.397829532623291
Batch 57/64 loss: -2.0186514854431152
Batch 58/64 loss: -1.6014633178710938
Batch 59/64 loss: -1.8451604843139648
Batch 60/64 loss: -1.6145410537719727
Batch 61/64 loss: -1.6942815780639648
Batch 62/64 loss: -1.7524452209472656
Batch 63/64 loss: -1.955319881439209
Batch 64/64 loss: -5.705078125
Epoch 335  Train loss: -1.7817712596818513  Val loss: -1.8737318687832232
Epoch 336
-------------------------------
Batch 1/64 loss: -1.845724105834961
Batch 2/64 loss: -1.606989860534668
Batch 3/64 loss: -1.4566364288330078
Batch 4/64 loss: -1.5545482635498047
Batch 5/64 loss: -1.8021650314331055
Batch 6/64 loss: -1.526097297668457
Batch 7/64 loss: -1.4869394302368164
Batch 8/64 loss: -1.978489875793457
Batch 9/64 loss: -1.8329949378967285
Batch 10/64 loss: -1.6848421096801758
Batch 11/64 loss: -1.4333009719848633
Batch 12/64 loss: -1.5800971984863281
Batch 13/64 loss: -1.9170503616333008
Batch 14/64 loss: -1.9113550186157227
Batch 15/64 loss: -1.798421859741211
Batch 16/64 loss: -1.9201364517211914
Batch 17/64 loss: -1.6531453132629395
Batch 18/64 loss: -1.9112153053283691
Batch 19/64 loss: -1.7504873275756836
Batch 20/64 loss: -1.6375865936279297
Batch 21/64 loss: -1.6288671493530273
Batch 22/64 loss: -1.557352066040039
Batch 23/64 loss: -1.3756790161132812
Batch 24/64 loss: -1.7138948440551758
Batch 25/64 loss: -1.788008689880371
Batch 26/64 loss: -2.044440746307373
Batch 27/64 loss: -1.67138671875
Batch 28/64 loss: -1.56597900390625
Batch 29/64 loss: -1.4554500579833984
Batch 30/64 loss: -1.4041709899902344
Batch 31/64 loss: -1.650731086730957
Batch 32/64 loss: -1.3709192276000977
Batch 33/64 loss: -1.8387069702148438
Batch 34/64 loss: -1.6206836700439453
Batch 35/64 loss: -1.6792373657226562
Batch 36/64 loss: -1.693532943725586
Batch 37/64 loss: -1.8272862434387207
Batch 38/64 loss: -1.7779464721679688
Batch 39/64 loss: -1.748988151550293
Batch 40/64 loss: -1.785120964050293
Batch 41/64 loss: -1.6485404968261719
Batch 42/64 loss: -1.8734626770019531
Batch 43/64 loss: -1.3943424224853516
Batch 44/64 loss: -1.7733631134033203
Batch 45/64 loss: -1.7502126693725586
Batch 46/64 loss: -1.716099739074707
Batch 47/64 loss: -1.965989112854004
Batch 48/64 loss: -1.8475685119628906
Batch 49/64 loss: -2.068912982940674
Batch 50/64 loss: -1.7869415283203125
Batch 51/64 loss: -2.1121273040771484
Batch 52/64 loss: -1.460860252380371
Batch 53/64 loss: -1.507319450378418
Batch 54/64 loss: -1.6282777786254883
Batch 55/64 loss: -1.0875349044799805
Batch 56/64 loss: -1.6340885162353516
Batch 57/64 loss: -1.9334278106689453
Batch 58/64 loss: -1.9897074699401855
Batch 59/64 loss: -1.727860450744629
Batch 60/64 loss: -1.6521596908569336
Batch 61/64 loss: -1.947718620300293
Batch 62/64 loss: -1.8265771865844727
Batch 63/64 loss: -1.853729248046875
Batch 64/64 loss: -5.618204116821289
Epoch 336  Train loss: -1.7550914689606312  Val loss: -1.8627815246582031
Epoch 337
-------------------------------
Batch 1/64 loss: -1.5865182876586914
Batch 2/64 loss: -1.8038463592529297
Batch 3/64 loss: -1.7933740615844727
Batch 4/64 loss: -1.9102821350097656
Batch 5/64 loss: -1.7187395095825195
Batch 6/64 loss: -1.819270133972168
Batch 7/64 loss: -1.614008903503418
Batch 8/64 loss: -1.4109582901000977
Batch 9/64 loss: -1.6577625274658203
Batch 10/64 loss: -1.9272232055664062
Batch 11/64 loss: -1.959080696105957
Batch 12/64 loss: -1.6092262268066406
Batch 13/64 loss: -1.6285171508789062
Batch 14/64 loss: -1.5964241027832031
Batch 15/64 loss: -1.7645273208618164
Batch 16/64 loss: -1.6660757064819336
Batch 17/64 loss: -1.5318059921264648
Batch 18/64 loss: -1.3309860229492188
Batch 19/64 loss: -2.08331298828125
Batch 20/64 loss: -1.6802587509155273
Batch 21/64 loss: -1.9462718963623047
Batch 22/64 loss: -1.6631832122802734
Batch 23/64 loss: -1.8424263000488281
Batch 24/64 loss: -1.7494821548461914
Batch 25/64 loss: -1.7247886657714844
Batch 26/64 loss: -1.6763458251953125
Batch 27/64 loss: -1.9570837020874023
Batch 28/64 loss: -1.7915210723876953
Batch 29/64 loss: -1.6953611373901367
Batch 30/64 loss: -1.8454875946044922
Batch 31/64 loss: -1.8663091659545898
Batch 32/64 loss: -1.6388530731201172
Batch 33/64 loss: -1.9082632064819336
Batch 34/64 loss: -1.363473892211914
Batch 35/64 loss: -1.9993782043457031
Batch 36/64 loss: -1.4428215026855469
Batch 37/64 loss: -1.867626667022705
Batch 38/64 loss: -2.027374267578125
Batch 39/64 loss: -1.8432021141052246
Batch 40/64 loss: -2.0615687370300293
Batch 41/64 loss: -1.6968297958374023
Batch 42/64 loss: -2.0537471771240234
Batch 43/64 loss: -1.7553339004516602
Batch 44/64 loss: -1.7068309783935547
Batch 45/64 loss: -1.9147863388061523
Batch 46/64 loss: -1.9409942626953125
Batch 47/64 loss: -1.6548576354980469
Batch 48/64 loss: -1.8216218948364258
Batch 49/64 loss: -1.8698835372924805
Batch 50/64 loss: -1.840315818786621
Batch 51/64 loss: -1.8265409469604492
Batch 52/64 loss: -1.8868045806884766
Batch 53/64 loss: -1.6707324981689453
Batch 54/64 loss: -1.6160125732421875
Batch 55/64 loss: -1.7817363739013672
Batch 56/64 loss: -1.5250234603881836
Batch 57/64 loss: -1.7438745498657227
Batch 58/64 loss: -1.964339256286621
Batch 59/64 loss: -1.3833398818969727
Batch 60/64 loss: -1.5427417755126953
Batch 61/64 loss: -1.566690444946289
Batch 62/64 loss: -1.774653434753418
Batch 63/64 loss: -1.532876968383789
Batch 64/64 loss: -5.520148277282715
Epoch 337  Train loss: -1.7915874518600166  Val loss: -1.9963145436290204
Epoch 338
-------------------------------
Batch 1/64 loss: -1.779439926147461
Batch 2/64 loss: -1.8254737854003906
Batch 3/64 loss: -1.7018404006958008
Batch 4/64 loss: -1.5645027160644531
Batch 5/64 loss: -1.5849552154541016
Batch 6/64 loss: -1.4982185363769531
Batch 7/64 loss: -1.4199542999267578
Batch 8/64 loss: -1.3212804794311523
Batch 9/64 loss: -1.7835044860839844
Batch 10/64 loss: -1.6412887573242188
Batch 11/64 loss: -1.3495903015136719
Batch 12/64 loss: -1.4637689590454102
Batch 13/64 loss: -1.757150650024414
Batch 14/64 loss: -1.646230697631836
Batch 15/64 loss: -1.3496894836425781
Batch 16/64 loss: -1.6789922714233398
Batch 17/64 loss: -1.8606758117675781
Batch 18/64 loss: -1.8316354751586914
Batch 19/64 loss: -1.7983074188232422
Batch 20/64 loss: -1.750870704650879
Batch 21/64 loss: -1.7734756469726562
Batch 22/64 loss: -1.7671194076538086
Batch 23/64 loss: -1.4864368438720703
Batch 24/64 loss: -1.6218442916870117
Batch 25/64 loss: -1.7275896072387695
Batch 26/64 loss: -1.5846548080444336
Batch 27/64 loss: -1.8752365112304688
Batch 28/64 loss: -1.8681182861328125
Batch 29/64 loss: -1.9236183166503906
Batch 30/64 loss: -1.8619842529296875
Batch 31/64 loss: -1.4440593719482422
Batch 32/64 loss: -1.7885522842407227
Batch 33/64 loss: -1.99993896484375
Batch 34/64 loss: -1.9470429420471191
Batch 35/64 loss: -1.9003872871398926
Batch 36/64 loss: -1.3147039413452148
Batch 37/64 loss: -1.934779167175293
Batch 38/64 loss: -1.9378414154052734
Batch 39/64 loss: -1.7561922073364258
Batch 40/64 loss: -1.8452305793762207
Batch 41/64 loss: -1.4367265701293945
Batch 42/64 loss: -1.9511642456054688
Batch 43/64 loss: -1.7156057357788086
Batch 44/64 loss: -2.0514330863952637
Batch 45/64 loss: -1.7714710235595703
Batch 46/64 loss: -1.5702543258666992
Batch 47/64 loss: -1.2658405303955078
Batch 48/64 loss: -1.8373937606811523
Batch 49/64 loss: -2.0532760620117188
Batch 50/64 loss: -1.8685894012451172
Batch 51/64 loss: -1.895040512084961
Batch 52/64 loss: -2.0133466720581055
Batch 53/64 loss: -1.9268465042114258
Batch 54/64 loss: -1.8000173568725586
Batch 55/64 loss: -1.392868995666504
Batch 56/64 loss: -1.6150550842285156
Batch 57/64 loss: -1.9437055587768555
Batch 58/64 loss: -1.5965709686279297
Batch 59/64 loss: -1.489126205444336
Batch 60/64 loss: -1.5105400085449219
Batch 61/64 loss: -1.9964675903320312
Batch 62/64 loss: -1.5700912475585938
Batch 63/64 loss: -1.8168010711669922
Batch 64/64 loss: -5.625162124633789
Epoch 338  Train loss: -1.7611494999305874  Val loss: -1.921566206155364
Epoch 339
-------------------------------
Batch 1/64 loss: -1.9752755165100098
Batch 2/64 loss: -1.7894878387451172
Batch 3/64 loss: -1.6997642517089844
Batch 4/64 loss: -1.4787311553955078
Batch 5/64 loss: -1.8114261627197266
Batch 6/64 loss: -1.965592384338379
Batch 7/64 loss: -1.7066316604614258
Batch 8/64 loss: -1.8156414031982422
Batch 9/64 loss: -1.7161550521850586
Batch 10/64 loss: -1.975510597229004
Batch 11/64 loss: -1.9263935089111328
Batch 12/64 loss: -2.0679283142089844
Batch 13/64 loss: -1.3066177368164062
Batch 14/64 loss: -1.9793815612792969
Batch 15/64 loss: -1.6108064651489258
Batch 16/64 loss: -1.3802909851074219
Batch 17/64 loss: -1.5354480743408203
Batch 18/64 loss: -1.527909278869629
Batch 19/64 loss: -1.8184642791748047
Batch 20/64 loss: -1.5087614059448242
Batch 21/64 loss: -2.0773305892944336
Batch 22/64 loss: -1.634516716003418
Batch 23/64 loss: -1.758479118347168
Batch 24/64 loss: -1.8346691131591797
Batch 25/64 loss: -1.5630149841308594
Batch 26/64 loss: -1.717630386352539
Batch 27/64 loss: -1.9095420837402344
Batch 28/64 loss: -1.913313865661621
Batch 29/64 loss: -1.7131261825561523
Batch 30/64 loss: -1.8528661727905273
Batch 31/64 loss: -1.637171745300293
Batch 32/64 loss: -1.8687224388122559
Batch 33/64 loss: -1.9128823280334473
Batch 34/64 loss: -1.5623407363891602
Batch 35/64 loss: -1.7946538925170898
Batch 36/64 loss: -1.4510107040405273
Batch 37/64 loss: -1.6605033874511719
Batch 38/64 loss: -1.6597442626953125
Batch 39/64 loss: -2.1042327880859375
Batch 40/64 loss: -1.87990140914917
Batch 41/64 loss: -1.6217269897460938
Batch 42/64 loss: -1.946563720703125
Batch 43/64 loss: -1.866694450378418
Batch 44/64 loss: -2.004403591156006
Batch 45/64 loss: -1.765019416809082
Batch 46/64 loss: -1.9283504486083984
Batch 47/64 loss: -1.6627254486083984
Batch 48/64 loss: -1.9187259674072266
Batch 49/64 loss: -2.1481447219848633
Batch 50/64 loss: -1.7807350158691406
Batch 51/64 loss: -1.7921853065490723
Batch 52/64 loss: -1.4707527160644531
Batch 53/64 loss: -1.8364710807800293
Batch 54/64 loss: -1.7582283020019531
Batch 55/64 loss: -1.5379209518432617
Batch 56/64 loss: -1.8733329772949219
Batch 57/64 loss: -1.7289791107177734
Batch 58/64 loss: -1.87664794921875
Batch 59/64 loss: -1.8036184310913086
Batch 60/64 loss: -1.627197265625
Batch 61/64 loss: -1.6762275695800781
Batch 62/64 loss: -1.5376958847045898
Batch 63/64 loss: -1.6025075912475586
Batch 64/64 loss: -5.558790683746338
Epoch 339  Train loss: -1.8044834267859367  Val loss: -1.9628700570961863
Epoch 340
-------------------------------
Batch 1/64 loss: -1.8136568069458008
Batch 2/64 loss: -1.7977561950683594
Batch 3/64 loss: -1.839643955230713
Batch 4/64 loss: -1.834310531616211
Batch 5/64 loss: -1.8721280097961426
Batch 6/64 loss: -1.7111263275146484
Batch 7/64 loss: -1.8927688598632812
Batch 8/64 loss: -1.8311333656311035
Batch 9/64 loss: -1.650620937347412
Batch 10/64 loss: -2.0582828521728516
Batch 11/64 loss: -1.8988118171691895
Batch 12/64 loss: -1.7550506591796875
Batch 13/64 loss: -1.7938446998596191
Batch 14/64 loss: -2.1045007705688477
Batch 15/64 loss: -1.6972837448120117
Batch 16/64 loss: -1.908310890197754
Batch 17/64 loss: -1.9778504371643066
Batch 18/64 loss: -1.7548131942749023
Batch 19/64 loss: -1.6715669631958008
Batch 20/64 loss: -2.1257147789001465
Batch 21/64 loss: -1.7437114715576172
Batch 22/64 loss: -1.7668981552124023
Batch 23/64 loss: -1.7690000534057617
Batch 24/64 loss: -1.7384757995605469
Batch 25/64 loss: -1.7724609375
Batch 26/64 loss: -2.002439498901367
Batch 27/64 loss: -1.5876693725585938
Batch 28/64 loss: -1.7541303634643555
Batch 29/64 loss: -2.067903518676758
Batch 30/64 loss: -1.4953718185424805
Batch 31/64 loss: -1.5954008102416992
Batch 32/64 loss: -1.9679207801818848
Batch 33/64 loss: -1.4361839294433594
Batch 34/64 loss: -1.8075933456420898
Batch 35/64 loss: -1.7282285690307617
Batch 36/64 loss: -1.8444228172302246
Batch 37/64 loss: -1.9160146713256836
Batch 38/64 loss: -1.752716064453125
Batch 39/64 loss: -1.575913429260254
Batch 40/64 loss: -1.7347259521484375
Batch 41/64 loss: -1.8151931762695312
Batch 42/64 loss: -1.764796257019043
Batch 43/64 loss: -1.7884626388549805
Batch 44/64 loss: -1.6134834289550781
Batch 45/64 loss: -1.942202091217041
Batch 46/64 loss: -1.7767047882080078
Batch 47/64 loss: -1.6816511154174805
Batch 48/64 loss: -1.828671932220459
Batch 49/64 loss: -1.7309637069702148
Batch 50/64 loss: -1.6764488220214844
Batch 51/64 loss: -1.8906993865966797
Batch 52/64 loss: -1.6970415115356445
Batch 53/64 loss: -1.7853641510009766
Batch 54/64 loss: -2.0294809341430664
Batch 55/64 loss: -2.2627177238464355
Batch 56/64 loss: -1.5333013534545898
Batch 57/64 loss: -1.8666954040527344
Batch 58/64 loss: -1.9789514541625977
Batch 59/64 loss: -2.0062999725341797
Batch 60/64 loss: -1.1436223983764648
Batch 61/64 loss: -1.8485107421875
Batch 62/64 loss: -1.4003190994262695
Batch 63/64 loss: -0.9820003509521484
Batch 64/64 loss: -6.080794334411621
Epoch 340  Train loss: -1.8298123191384708  Val loss: -1.9551081575478886
Epoch 341
-------------------------------
Batch 1/64 loss: -1.5984487533569336
Batch 2/64 loss: -1.3636913299560547
Batch 3/64 loss: -1.7312722206115723
Batch 4/64 loss: -2.0092339515686035
Batch 5/64 loss: -1.640233039855957
Batch 6/64 loss: -1.5311040878295898
Batch 7/64 loss: -1.5517363548278809
Batch 8/64 loss: -1.835099220275879
Batch 9/64 loss: -1.6556291580200195
Batch 10/64 loss: -1.9273567199707031
Batch 11/64 loss: -1.745330810546875
Batch 12/64 loss: -1.558457374572754
Batch 13/64 loss: -1.7260560989379883
Batch 14/64 loss: -1.446913719177246
Batch 15/64 loss: -1.635240077972412
Batch 16/64 loss: -1.4105749130249023
Batch 17/64 loss: -1.4550762176513672
Batch 18/64 loss: -1.6344690322875977
Batch 19/64 loss: -1.5121259689331055
Batch 20/64 loss: -1.5479393005371094
Batch 21/64 loss: -1.9592370986938477
Batch 22/64 loss: -1.6633234024047852
Batch 23/64 loss: -1.5031580924987793
Batch 24/64 loss: -1.6319646835327148
Batch 25/64 loss: -1.846989631652832
Batch 26/64 loss: -1.7653017044067383
Batch 27/64 loss: -1.7813220024108887
Batch 28/64 loss: -1.6859736442565918
Batch 29/64 loss: -1.5028419494628906
Batch 30/64 loss: -1.6032676696777344
Batch 31/64 loss: -1.860255241394043
Batch 32/64 loss: -1.888380527496338
Batch 33/64 loss: -1.0108747482299805
Batch 34/64 loss: -1.8462281227111816
Batch 35/64 loss: -1.5244598388671875
Batch 36/64 loss: -1.8414726257324219
Batch 37/64 loss: -1.922816276550293
Batch 38/64 loss: -1.9966511726379395
Batch 39/64 loss: -1.7155351638793945
Batch 40/64 loss: -1.8871660232543945
Batch 41/64 loss: -1.9188175201416016
Batch 42/64 loss: -1.818023681640625
Batch 43/64 loss: -1.6142683029174805
Batch 44/64 loss: -1.972651481628418
Batch 45/64 loss: -1.6764154434204102
Batch 46/64 loss: -1.6811885833740234
Batch 47/64 loss: -1.6424560546875
Batch 48/64 loss: -1.8811779022216797
Batch 49/64 loss: -1.880584716796875
Batch 50/64 loss: -1.4143314361572266
Batch 51/64 loss: -2.0361080169677734
Batch 52/64 loss: -1.533987045288086
Batch 53/64 loss: -1.7724647521972656
Batch 54/64 loss: -1.9707794189453125
Batch 55/64 loss: -1.8676719665527344
Batch 56/64 loss: -1.612839698791504
Batch 57/64 loss: -1.945220947265625
Batch 58/64 loss: -1.348825454711914
Batch 59/64 loss: -1.8660249710083008
Batch 60/64 loss: -1.8116493225097656
Batch 61/64 loss: -1.8736343383789062
Batch 62/64 loss: -1.6477813720703125
Batch 63/64 loss: -1.4556503295898438
Batch 64/64 loss: -5.671336650848389
Epoch 341  Train loss: -1.748223736706902  Val loss: -1.6965759120036645
Epoch 342
-------------------------------
Batch 1/64 loss: -1.4087305068969727
Batch 2/64 loss: -1.6312360763549805
Batch 3/64 loss: -1.8530216217041016
Batch 4/64 loss: -1.6304292678833008
Batch 5/64 loss: -1.7899055480957031
Batch 6/64 loss: -1.7479801177978516
Batch 7/64 loss: -1.5019712448120117
Batch 8/64 loss: -1.2959003448486328
Batch 9/64 loss: -1.6262845993041992
Batch 10/64 loss: -1.4145212173461914
Batch 11/64 loss: -1.7543392181396484
Batch 12/64 loss: -1.7644309997558594
Batch 13/64 loss: -1.6202716827392578
Batch 14/64 loss: -1.6445302963256836
Batch 15/64 loss: -1.6772832870483398
Batch 16/64 loss: -1.6455974578857422
Batch 17/64 loss: -1.8380756378173828
Batch 18/64 loss: -1.8421053886413574
Batch 19/64 loss: -1.5344018936157227
Batch 20/64 loss: -1.1984567642211914
Batch 21/64 loss: -1.8784165382385254
Batch 22/64 loss: -1.7350196838378906
Batch 23/64 loss: -1.5324745178222656
Batch 24/64 loss: -1.434478759765625
Batch 25/64 loss: -1.8885364532470703
Batch 26/64 loss: -1.644362449645996
Batch 27/64 loss: -1.7163543701171875
Batch 28/64 loss: -1.9413204193115234
Batch 29/64 loss: -2.037278175354004
Batch 30/64 loss: -1.6970586776733398
Batch 31/64 loss: -1.9175119400024414
Batch 32/64 loss: -1.7915029525756836
Batch 33/64 loss: -1.6376152038574219
Batch 34/64 loss: -1.8099346160888672
Batch 35/64 loss: -1.615579605102539
Batch 36/64 loss: -1.7284727096557617
Batch 37/64 loss: -1.5629253387451172
Batch 38/64 loss: -1.9299001693725586
Batch 39/64 loss: -1.873220443725586
Batch 40/64 loss: -1.8926982879638672
Batch 41/64 loss: -1.5682258605957031
Batch 42/64 loss: -1.8266620635986328
Batch 43/64 loss: -1.7134075164794922
Batch 44/64 loss: -1.8028693199157715
Batch 45/64 loss: -1.396902084350586
Batch 46/64 loss: -1.839838981628418
Batch 47/64 loss: -1.510244369506836
Batch 48/64 loss: -1.840174674987793
Batch 49/64 loss: -1.723515510559082
Batch 50/64 loss: -1.7590351104736328
Batch 51/64 loss: -0.7689208984375
Batch 52/64 loss: -1.6300649642944336
Batch 53/64 loss: -1.5137157440185547
Batch 54/64 loss: -1.8094916343688965
Batch 55/64 loss: -1.576939582824707
Batch 56/64 loss: -1.955723762512207
Batch 57/64 loss: -1.811264991760254
Batch 58/64 loss: -1.6461896896362305
Batch 59/64 loss: -1.6637935638427734
Batch 60/64 loss: -1.4882726669311523
Batch 61/64 loss: -1.3051118850708008
Batch 62/64 loss: -1.904576301574707
Batch 63/64 loss: -1.7561006546020508
Batch 64/64 loss: -5.192433834075928
Epoch 342  Train loss: -1.7159137520135617  Val loss: -1.9137769089531653
Epoch 343
-------------------------------
Batch 1/64 loss: -1.7625608444213867
Batch 2/64 loss: -1.660008430480957
Batch 3/64 loss: -1.8218746185302734
Batch 4/64 loss: -1.5972328186035156
Batch 5/64 loss: -1.8897695541381836
Batch 6/64 loss: -2.0032057762145996
Batch 7/64 loss: -1.8511667251586914
Batch 8/64 loss: -1.664628028869629
Batch 9/64 loss: -2.001157760620117
Batch 10/64 loss: -1.466628074645996
Batch 11/64 loss: -1.8277673721313477
Batch 12/64 loss: -1.6034774780273438
Batch 13/64 loss: -1.8523073196411133
Batch 14/64 loss: -1.4795417785644531
Batch 15/64 loss: -1.7195959091186523
Batch 16/64 loss: -1.8874998092651367
Batch 17/64 loss: -1.047114372253418
Batch 18/64 loss: -1.8054819107055664
Batch 19/64 loss: -2.021121025085449
Batch 20/64 loss: -1.863581657409668
Batch 21/64 loss: -1.771383285522461
Batch 22/64 loss: -1.4995946884155273
Batch 23/64 loss: -1.4841384887695312
Batch 24/64 loss: -1.7831230163574219
Batch 25/64 loss: -1.5240540504455566
Batch 26/64 loss: -1.7881526947021484
Batch 27/64 loss: -1.839311122894287
Batch 28/64 loss: -1.782679557800293
Batch 29/64 loss: -1.6202101707458496
Batch 30/64 loss: -1.5848369598388672
Batch 31/64 loss: -1.8682880401611328
Batch 32/64 loss: -1.4528999328613281
Batch 33/64 loss: -1.9001812934875488
Batch 34/64 loss: -1.8355379104614258
Batch 35/64 loss: -1.8126115798950195
Batch 36/64 loss: -1.7364425659179688
Batch 37/64 loss: -1.3720521926879883
Batch 38/64 loss: -2.0052928924560547
Batch 39/64 loss: -1.8802013397216797
Batch 40/64 loss: -1.9231081008911133
Batch 41/64 loss: -1.7571601867675781
Batch 42/64 loss: -2.0175867080688477
Batch 43/64 loss: -1.9596281051635742
Batch 44/64 loss: -1.8715591430664062
Batch 45/64 loss: -1.8301982879638672
Batch 46/64 loss: -1.6526660919189453
Batch 47/64 loss: -1.5186309814453125
Batch 48/64 loss: -2.090114116668701
Batch 49/64 loss: -1.8178901672363281
Batch 50/64 loss: -2.0725631713867188
Batch 51/64 loss: -1.8952226638793945
Batch 52/64 loss: -1.43280029296875
Batch 53/64 loss: -1.2328910827636719
Batch 54/64 loss: -1.9764595031738281
Batch 55/64 loss: -2.045365333557129
Batch 56/64 loss: -2.0879740715026855
Batch 57/64 loss: -1.7467126846313477
Batch 58/64 loss: -1.1065683364868164
Batch 59/64 loss: -1.743764877319336
Batch 60/64 loss: -1.72222900390625
Batch 61/64 loss: -1.9972944259643555
Batch 62/64 loss: -1.8025436401367188
Batch 63/64 loss: -1.6931486129760742
Batch 64/64 loss: -5.361941337585449
Epoch 343  Train loss: -1.7942313512166341  Val loss: -1.8603682239440709
Epoch 344
-------------------------------
Batch 1/64 loss: -1.2817316055297852
Batch 2/64 loss: -1.4790267944335938
Batch 3/64 loss: -1.9250497817993164
Batch 4/64 loss: -1.8037109375
Batch 5/64 loss: -1.775641918182373
Batch 6/64 loss: -2.128457546234131
Batch 7/64 loss: -1.0393257141113281
Batch 8/64 loss: -1.683095932006836
Batch 9/64 loss: -1.8535099029541016
Batch 10/64 loss: -1.6216058731079102
Batch 11/64 loss: -1.6053204536437988
Batch 12/64 loss: -1.6748647689819336
Batch 13/64 loss: -2.0279879570007324
Batch 14/64 loss: -1.701219081878662
Batch 15/64 loss: -1.8840484619140625
Batch 16/64 loss: -1.8892650604248047
Batch 17/64 loss: -1.8070001602172852
Batch 18/64 loss: -1.9714722633361816
Batch 19/64 loss: -1.6686420440673828
Batch 20/64 loss: -1.8855791091918945
Batch 21/64 loss: -1.8056116104125977
Batch 22/64 loss: -1.9219322204589844
Batch 23/64 loss: -1.8457632064819336
Batch 24/64 loss: -1.869877815246582
Batch 25/64 loss: -1.8228864669799805
Batch 26/64 loss: -1.696822166442871
Batch 27/64 loss: -1.8533458709716797
Batch 28/64 loss: -2.044149398803711
Batch 29/64 loss: -1.4846439361572266
Batch 30/64 loss: -1.7172489166259766
Batch 31/64 loss: -2.1707119941711426
Batch 32/64 loss: -1.9382524490356445
Batch 33/64 loss: -1.568263053894043
Batch 34/64 loss: -1.2751989364624023
Batch 35/64 loss: -1.7552108764648438
Batch 36/64 loss: -1.704899787902832
Batch 37/64 loss: -1.685262680053711
Batch 38/64 loss: -1.9512300491333008
Batch 39/64 loss: -1.8579730987548828
Batch 40/64 loss: -1.918344497680664
Batch 41/64 loss: -1.9187746047973633
Batch 42/64 loss: -1.8553571701049805
Batch 43/64 loss: -1.7822561264038086
Batch 44/64 loss: -1.9221611022949219
Batch 45/64 loss: -1.9222774505615234
Batch 46/64 loss: -1.6279659271240234
Batch 47/64 loss: -1.8093137741088867
Batch 48/64 loss: -1.3305625915527344
Batch 49/64 loss: -1.8354554176330566
Batch 50/64 loss: -1.9102363586425781
Batch 51/64 loss: -1.5179948806762695
Batch 52/64 loss: -1.5698671340942383
Batch 53/64 loss: -1.6215476989746094
Batch 54/64 loss: -1.7954940795898438
Batch 55/64 loss: -2.05765438079834
Batch 56/64 loss: -1.5294837951660156
Batch 57/64 loss: -1.9682903289794922
Batch 58/64 loss: -1.7932071685791016
Batch 59/64 loss: -1.4357376098632812
Batch 60/64 loss: -1.9374408721923828
Batch 61/64 loss: -1.9676427841186523
Batch 62/64 loss: -1.9384093284606934
Batch 63/64 loss: -1.706324577331543
Batch 64/64 loss: -5.325049877166748
Epoch 344  Train loss: -1.809277285781561  Val loss: -1.9494324779182775
Epoch 345
-------------------------------
Batch 1/64 loss: -2.0627613067626953
Batch 2/64 loss: -1.7470483779907227
Batch 3/64 loss: -1.6904563903808594
Batch 4/64 loss: -1.7740297317504883
Batch 5/64 loss: -1.5058927536010742
Batch 6/64 loss: -1.5568103790283203
Batch 7/64 loss: -1.848830223083496
Batch 8/64 loss: -1.9168434143066406
Batch 9/64 loss: -2.0723695755004883
Batch 10/64 loss: -1.6043272018432617
Batch 11/64 loss: -1.7430992126464844
Batch 12/64 loss: -1.7548131942749023
Batch 13/64 loss: -1.643106460571289
Batch 14/64 loss: -1.8147573471069336
Batch 15/64 loss: -1.6544675827026367
Batch 16/64 loss: -1.7045812606811523
Batch 17/64 loss: -1.531132698059082
Batch 18/64 loss: -2.06174373626709
Batch 19/64 loss: -1.6228647232055664
Batch 20/64 loss: -1.9825401306152344
Batch 21/64 loss: -1.7127161026000977
Batch 22/64 loss: -1.5022516250610352
Batch 23/64 loss: -1.9866609573364258
Batch 24/64 loss: -1.654052734375
Batch 25/64 loss: -1.855142593383789
Batch 26/64 loss: -1.9767074584960938
Batch 27/64 loss: -1.2307071685791016
Batch 28/64 loss: -1.9049577713012695
Batch 29/64 loss: -1.9362778663635254
Batch 30/64 loss: -1.4286909103393555
Batch 31/64 loss: -2.0237207412719727
Batch 32/64 loss: -1.4014463424682617
Batch 33/64 loss: -1.7492856979370117
Batch 34/64 loss: -1.7993402481079102
Batch 35/64 loss: -1.9296646118164062
Batch 36/64 loss: -1.6843600273132324
Batch 37/64 loss: -1.788374900817871
Batch 38/64 loss: -2.06258487701416
Batch 39/64 loss: -1.7236146926879883
Batch 40/64 loss: -1.5020265579223633
Batch 41/64 loss: -2.0273375511169434
Batch 42/64 loss: -1.9687271118164062
Batch 43/64 loss: -1.7763776779174805
Batch 44/64 loss: -1.6329669952392578
Batch 45/64 loss: -1.852025032043457
Batch 46/64 loss: -1.9668841361999512
Batch 47/64 loss: -1.7959699630737305
Batch 48/64 loss: -1.8531732559204102
Batch 49/64 loss: -1.4503612518310547
Batch 50/64 loss: -1.5767755508422852
Batch 51/64 loss: -1.4271249771118164
Batch 52/64 loss: -1.5764217376708984
Batch 53/64 loss: -1.7358331680297852
Batch 54/64 loss: -1.851348876953125
Batch 55/64 loss: -1.859602928161621
Batch 56/64 loss: -2.020632266998291
Batch 57/64 loss: -1.849797248840332
Batch 58/64 loss: -1.7029056549072266
Batch 59/64 loss: -1.9845924377441406
Batch 60/64 loss: -1.8646998405456543
Batch 61/64 loss: -1.6865696907043457
Batch 62/64 loss: -1.636817455291748
Batch 63/64 loss: -2.074995994567871
Batch 64/64 loss: -6.137070655822754
Epoch 345  Train loss: -1.8183498569563323  Val loss: -1.9576182545665204
Epoch 346
-------------------------------
Batch 1/64 loss: -1.6857213973999023
Batch 2/64 loss: -1.9713664054870605
Batch 3/64 loss: -1.934849739074707
Batch 4/64 loss: -1.7269783020019531
Batch 5/64 loss: -1.800654411315918
Batch 6/64 loss: -1.7328968048095703
Batch 7/64 loss: -1.2449769973754883
Batch 8/64 loss: -1.5817251205444336
Batch 9/64 loss: -1.899099349975586
Batch 10/64 loss: -1.5257635116577148
Batch 11/64 loss: -1.5141515731811523
Batch 12/64 loss: -1.9162425994873047
Batch 13/64 loss: -2.102419376373291
Batch 14/64 loss: -2.1062703132629395
Batch 15/64 loss: -1.5591497421264648
Batch 16/64 loss: -2.032057762145996
Batch 17/64 loss: -1.8755836486816406
Batch 18/64 loss: -1.5370187759399414
Batch 19/64 loss: -1.872675895690918
Batch 20/64 loss: -1.8325471878051758
Batch 21/64 loss: -1.882826805114746
Batch 22/64 loss: -1.6742620468139648
Batch 23/64 loss: -1.8421344757080078
Batch 24/64 loss: -2.0352792739868164
Batch 25/64 loss: -1.726712703704834
Batch 26/64 loss: -1.9582042694091797
Batch 27/64 loss: -1.5193853378295898
Batch 28/64 loss: -1.419377326965332
Batch 29/64 loss: -1.6729621887207031
Batch 30/64 loss: -1.8738250732421875
Batch 31/64 loss: -1.6554327011108398
Batch 32/64 loss: -1.8341073989868164
Batch 33/64 loss: -2.0713181495666504
Batch 34/64 loss: -1.4261784553527832
Batch 35/64 loss: -1.854318618774414
Batch 36/64 loss: -1.5341682434082031
Batch 37/64 loss: -1.8383378982543945
Batch 38/64 loss: -1.8725738525390625
Batch 39/64 loss: -1.822662353515625
Batch 40/64 loss: -1.9730205535888672
Batch 41/64 loss: -1.6246156692504883
Batch 42/64 loss: -1.5574455261230469
Batch 43/64 loss: -1.6439666748046875
Batch 44/64 loss: -1.8223190307617188
Batch 45/64 loss: -1.8746938705444336
Batch 46/64 loss: -1.6485681533813477
Batch 47/64 loss: -1.7399482727050781
Batch 48/64 loss: -1.6611747741699219
Batch 49/64 loss: -1.9132862091064453
Batch 50/64 loss: -1.8632612228393555
Batch 51/64 loss: -1.7388067245483398
Batch 52/64 loss: -1.9546871185302734
Batch 53/64 loss: -1.9345426559448242
Batch 54/64 loss: -1.6541128158569336
Batch 55/64 loss: -1.9811620712280273
Batch 56/64 loss: -1.921609878540039
Batch 57/64 loss: -1.8636913299560547
Batch 58/64 loss: -1.4689569473266602
Batch 59/64 loss: -1.8508720397949219
Batch 60/64 loss: -1.5360307693481445
Batch 61/64 loss: -1.621434211730957
Batch 62/64 loss: -1.688565731048584
Batch 63/64 loss: -1.9217643737792969
Batch 64/64 loss: -5.822965621948242
Epoch 346  Train loss: -1.816344736136642  Val loss: -1.956752724663908
Epoch 347
-------------------------------
Batch 1/64 loss: -1.998131275177002
Batch 2/64 loss: -1.7379379272460938
Batch 3/64 loss: -1.8452444076538086
Batch 4/64 loss: -1.4038677215576172
Batch 5/64 loss: -1.5407133102416992
Batch 6/64 loss: -1.6138505935668945
Batch 7/64 loss: -1.7890958786010742
Batch 8/64 loss: -1.6869525909423828
Batch 9/64 loss: -1.8537817001342773
Batch 10/64 loss: -1.650289535522461
Batch 11/64 loss: -1.8033742904663086
Batch 12/64 loss: -1.9618730545043945
Batch 13/64 loss: -1.6088495254516602
Batch 14/64 loss: -1.9536285400390625
Batch 15/64 loss: -1.929685115814209
Batch 16/64 loss: -1.6680822372436523
Batch 17/64 loss: -2.078439712524414
Batch 18/64 loss: -1.4961071014404297
Batch 19/64 loss: -1.7537508010864258
Batch 20/64 loss: -1.6532773971557617
Batch 21/64 loss: -1.612565040588379
Batch 22/64 loss: -1.8786816596984863
Batch 23/64 loss: -1.5536155700683594
Batch 24/64 loss: -1.5483074188232422
Batch 25/64 loss: -1.8631401062011719
Batch 26/64 loss: -1.1844282150268555
Batch 27/64 loss: -2.019094467163086
Batch 28/64 loss: -1.776078224182129
Batch 29/64 loss: -2.018486976623535
Batch 30/64 loss: -2.171142101287842
Batch 31/64 loss: -2.0304360389709473
Batch 32/64 loss: -1.7702903747558594
Batch 33/64 loss: -1.7807159423828125
Batch 34/64 loss: -1.6668319702148438
Batch 35/64 loss: -2.0234880447387695
Batch 36/64 loss: -1.8551559448242188
Batch 37/64 loss: -2.0082406997680664
Batch 38/64 loss: -1.6506853103637695
Batch 39/64 loss: -1.8163337707519531
Batch 40/64 loss: -1.8976078033447266
Batch 41/64 loss: -2.1117677688598633
Batch 42/64 loss: -1.5942115783691406
Batch 43/64 loss: -2.0984816551208496
Batch 44/64 loss: -1.9702606201171875
Batch 45/64 loss: -2.032318115234375
Batch 46/64 loss: -1.710592269897461
Batch 47/64 loss: -1.5098466873168945
Batch 48/64 loss: -1.7789573669433594
Batch 49/64 loss: -1.9343070983886719
Batch 50/64 loss: -1.7660932540893555
Batch 51/64 loss: -1.747450828552246
Batch 52/64 loss: -1.5489988327026367
Batch 53/64 loss: -1.8857250213623047
Batch 54/64 loss: -1.762674331665039
Batch 55/64 loss: -1.9701166152954102
Batch 56/64 loss: -1.9543066024780273
Batch 57/64 loss: -1.7600221633911133
Batch 58/64 loss: -1.6960248947143555
Batch 59/64 loss: -1.4166088104248047
Batch 60/64 loss: -1.640411376953125
Batch 61/64 loss: -1.7870092391967773
Batch 62/64 loss: -1.6500539779663086
Batch 63/64 loss: -1.9573345184326172
Batch 64/64 loss: -5.720410346984863
Epoch 347  Train loss: -1.8309982711193609  Val loss: -1.882646318153827
Epoch 348
-------------------------------
Batch 1/64 loss: -1.9269781112670898
Batch 2/64 loss: -1.3958511352539062
Batch 3/64 loss: -1.2760028839111328
Batch 4/64 loss: -1.7460203170776367
Batch 5/64 loss: -1.504744529724121
Batch 6/64 loss: -1.922445297241211
Batch 7/64 loss: -1.518834114074707
Batch 8/64 loss: -1.7845945358276367
Batch 9/64 loss: -1.7226648330688477
Batch 10/64 loss: -1.7410564422607422
Batch 11/64 loss: -1.626357078552246
Batch 12/64 loss: -1.537618637084961
Batch 13/64 loss: -1.746755599975586
Batch 14/64 loss: -1.5388851165771484
Batch 15/64 loss: -1.9643669128417969
Batch 16/64 loss: -1.5110807418823242
Batch 17/64 loss: -1.832280158996582
Batch 18/64 loss: -1.6756372451782227
Batch 19/64 loss: -1.456608772277832
Batch 20/64 loss: -1.7707862854003906
Batch 21/64 loss: -1.9125900268554688
Batch 22/64 loss: -1.7368478775024414
Batch 23/64 loss: -1.6656084060668945
Batch 24/64 loss: -1.4951133728027344
Batch 25/64 loss: -1.8888025283813477
Batch 26/64 loss: -1.7272653579711914
Batch 27/64 loss: -1.8196897506713867
Batch 28/64 loss: -1.4307060241699219
Batch 29/64 loss: -1.3912134170532227
Batch 30/64 loss: -1.7139930725097656
Batch 31/64 loss: -1.741776943206787
Batch 32/64 loss: -1.8533754348754883
Batch 33/64 loss: -1.7922143936157227
Batch 34/64 loss: -2.0739316940307617
Batch 35/64 loss: -1.9314541816711426
Batch 36/64 loss: -1.7786645889282227
Batch 37/64 loss: -1.584822654724121
Batch 38/64 loss: -1.6850719451904297
Batch 39/64 loss: -1.6327247619628906
Batch 40/64 loss: -2.2493276596069336
Batch 41/64 loss: -1.9691457748413086
Batch 42/64 loss: -1.736323356628418
Batch 43/64 loss: -1.720703125
Batch 44/64 loss: -1.6537103652954102
Batch 45/64 loss: -1.6950511932373047
Batch 46/64 loss: -1.7220182418823242
Batch 47/64 loss: -1.9005436897277832
Batch 48/64 loss: -1.3508710861206055
Batch 49/64 loss: -1.5666379928588867
Batch 50/64 loss: -1.8991212844848633
Batch 51/64 loss: -1.6995353698730469
Batch 52/64 loss: -1.743910312652588
Batch 53/64 loss: -1.8204641342163086
Batch 54/64 loss: -2.072592258453369
Batch 55/64 loss: -1.6771783828735352
Batch 56/64 loss: -1.878006935119629
Batch 57/64 loss: -1.429922103881836
Batch 58/64 loss: -1.6847286224365234
Batch 59/64 loss: -1.9916133880615234
Batch 60/64 loss: -1.8635492324829102
Batch 61/64 loss: -1.750619888305664
Batch 62/64 loss: -1.9695777893066406
Batch 63/64 loss: -1.8584842681884766
Batch 64/64 loss: -5.100016117095947
Epoch 348  Train loss: -1.7691620976317162  Val loss: -1.9208574589994765
Epoch 349
-------------------------------
Batch 1/64 loss: -1.6180381774902344
Batch 2/64 loss: -1.7849311828613281
Batch 3/64 loss: -1.6507787704467773
Batch 4/64 loss: -1.8698720932006836
Batch 5/64 loss: -2.0307793617248535
Batch 6/64 loss: -1.6900644302368164
Batch 7/64 loss: -1.884261131286621
Batch 8/64 loss: -1.4693336486816406
Batch 9/64 loss: -1.6399860382080078
Batch 10/64 loss: -1.6566886901855469
Batch 11/64 loss: -2.160435676574707
Batch 12/64 loss: -1.8802309036254883
Batch 13/64 loss: -1.4610576629638672
Batch 14/64 loss: -2.0111799240112305
Batch 15/64 loss: -1.295480728149414
Batch 16/64 loss: -1.8136768341064453
Batch 17/64 loss: -1.8689374923706055
Batch 18/64 loss: -2.110213279724121
Batch 19/64 loss: -1.8958463668823242
Batch 20/64 loss: -2.0317325592041016
Batch 21/64 loss: -1.6629447937011719
Batch 22/64 loss: -1.6415090560913086
Batch 23/64 loss: -1.7758874893188477
Batch 24/64 loss: -1.7242250442504883
Batch 25/64 loss: -1.959568977355957
Batch 26/64 loss: -1.9835262298583984
Batch 27/64 loss: -1.9495964050292969
Batch 28/64 loss: -1.371607780456543
Batch 29/64 loss: -1.871633529663086
Batch 30/64 loss: -1.6470403671264648
Batch 31/64 loss: -1.9414777755737305
Batch 32/64 loss: -1.1571273803710938
Batch 33/64 loss: -1.9477806091308594
Batch 34/64 loss: -1.9470834732055664
Batch 35/64 loss: -1.6363372802734375
Batch 36/64 loss: -1.9777002334594727
Batch 37/64 loss: -1.915360927581787
Batch 38/64 loss: -1.4587593078613281
Batch 39/64 loss: -1.5213079452514648
Batch 40/64 loss: -1.7088947296142578
Batch 41/64 loss: -1.270310401916504
Batch 42/64 loss: -1.7604246139526367
Batch 43/64 loss: -1.8210563659667969
Batch 44/64 loss: -1.8522281646728516
Batch 45/64 loss: -1.8562145233154297
Batch 46/64 loss: -1.9768524169921875
Batch 47/64 loss: -1.9816689491271973
Batch 48/64 loss: -1.850088119506836
Batch 49/64 loss: -2.1709723472595215
Batch 50/64 loss: -1.6318016052246094
Batch 51/64 loss: -1.3222322463989258
Batch 52/64 loss: -1.6460094451904297
Batch 53/64 loss: -1.7864885330200195
Batch 54/64 loss: -1.7474594116210938
Batch 55/64 loss: -1.607818603515625
Batch 56/64 loss: -1.7957649230957031
Batch 57/64 loss: -1.869399070739746
Batch 58/64 loss: -1.7009458541870117
Batch 59/64 loss: -2.0184640884399414
Batch 60/64 loss: -1.7846145629882812
Batch 61/64 loss: -1.6930732727050781
Batch 62/64 loss: -1.817314624786377
Batch 63/64 loss: -1.8974981307983398
Batch 64/64 loss: -5.572808742523193
Epoch 349  Train loss: -1.8142933508929084  Val loss: -1.9873947064901136
Epoch 350
-------------------------------
Batch 1/64 loss: -1.956202507019043
Batch 2/64 loss: -1.769331932067871
Batch 3/64 loss: -1.8018522262573242
Batch 4/64 loss: -1.545907974243164
Batch 5/64 loss: -1.5495166778564453
Batch 6/64 loss: -1.8293743133544922
Batch 7/64 loss: -1.7021865844726562
Batch 8/64 loss: -1.9840068817138672
Batch 9/64 loss: -1.9418087005615234
Batch 10/64 loss: -1.7704153060913086
Batch 11/64 loss: -1.9064998626708984
Batch 12/64 loss: -1.8624296188354492
Batch 13/64 loss: -1.8466472625732422
Batch 14/64 loss: -1.5532951354980469
Batch 15/64 loss: -1.6663522720336914
Batch 16/64 loss: -1.7210664749145508
Batch 17/64 loss: -1.8749914169311523
Batch 18/64 loss: -1.7720327377319336
Batch 19/64 loss: -1.7327585220336914
Batch 20/64 loss: -1.8559885025024414
Batch 21/64 loss: -2.006143569946289
Batch 22/64 loss: -2.069766044616699
Batch 23/64 loss: -1.8821678161621094
Batch 24/64 loss: -1.8708171844482422
Batch 25/64 loss: -1.5629339218139648
Batch 26/64 loss: -1.843449592590332
Batch 27/64 loss: -1.188680648803711
Batch 28/64 loss: -1.801309585571289
Batch 29/64 loss: -1.739365577697754
Batch 30/64 loss: -1.8242158889770508
Batch 31/64 loss: -1.874894142150879
Batch 32/64 loss: -1.9983491897583008
Batch 33/64 loss: -1.6431503295898438
Batch 34/64 loss: -1.7161712646484375
Batch 35/64 loss: -1.7229290008544922
Batch 36/64 loss: -1.7687759399414062
Batch 37/64 loss: -2.011744499206543
Batch 38/64 loss: -1.760960578918457
Batch 39/64 loss: -1.7745184898376465
Batch 40/64 loss: -1.9243831634521484
Batch 41/64 loss: -1.7916173934936523
Batch 42/64 loss: -1.691634178161621
Batch 43/64 loss: -1.7898387908935547
Batch 44/64 loss: -1.38104248046875
Batch 45/64 loss: -1.7799644470214844
Batch 46/64 loss: -1.7668285369873047
Batch 47/64 loss: -1.5642070770263672
Batch 48/64 loss: -1.9044933319091797
Batch 49/64 loss: -1.9481487274169922
Batch 50/64 loss: -1.8815698623657227
Batch 51/64 loss: -1.920175552368164
Batch 52/64 loss: -1.9327573776245117
Batch 53/64 loss: -1.8152341842651367
Batch 54/64 loss: -1.870309829711914
Batch 55/64 loss: -1.901871681213379
Batch 56/64 loss: -1.8442869186401367
Batch 57/64 loss: -1.7635440826416016
Batch 58/64 loss: -1.9166984558105469
Batch 59/64 loss: -1.8836545944213867
Batch 60/64 loss: -1.6349248886108398
Batch 61/64 loss: -1.0125713348388672
Batch 62/64 loss: -1.888442039489746
Batch 63/64 loss: -1.7509536743164062
Batch 64/64 loss: -6.05622673034668
Epoch 350  Train loss: -1.8322247972675398  Val loss: -1.8133490388745706
Epoch 351
-------------------------------
Batch 1/64 loss: -1.798126220703125
Batch 2/64 loss: -2.0805916786193848
Batch 3/64 loss: -2.1056771278381348
Batch 4/64 loss: -1.8107337951660156
Batch 5/64 loss: -1.630767822265625
Batch 6/64 loss: -1.9050507545471191
Batch 7/64 loss: -1.8794593811035156
Batch 8/64 loss: -1.9483051300048828
Batch 9/64 loss: -1.876901626586914
Batch 10/64 loss: -1.6997346878051758
Batch 11/64 loss: -1.9040985107421875
Batch 12/64 loss: -1.8865556716918945
Batch 13/64 loss: -1.733062744140625
Batch 14/64 loss: -1.8413019180297852
Batch 15/64 loss: -1.962615966796875
Batch 16/64 loss: -1.2796878814697266
Batch 17/64 loss: -2.0682053565979004
Batch 18/64 loss: -1.6112565994262695
Batch 19/64 loss: -1.7996463775634766
Batch 20/64 loss: -2.0890417098999023
Batch 21/64 loss: -1.8011350631713867
Batch 22/64 loss: -1.5006647109985352
Batch 23/64 loss: -1.8663387298583984
Batch 24/64 loss: -1.909200668334961
Batch 25/64 loss: -1.6373090744018555
Batch 26/64 loss: -1.6450881958007812
Batch 27/64 loss: -1.7643589973449707
Batch 28/64 loss: -1.5112924575805664
Batch 29/64 loss: -1.7564888000488281
Batch 30/64 loss: -1.7239866256713867
Batch 31/64 loss: -1.669947624206543
Batch 32/64 loss: -1.640284538269043
Batch 33/64 loss: -2.1820549964904785
Batch 34/64 loss: -1.5844049453735352
Batch 35/64 loss: -1.9084491729736328
Batch 36/64 loss: -1.8604087829589844
Batch 37/64 loss: -1.9793319702148438
Batch 38/64 loss: -1.7484607696533203
Batch 39/64 loss: -1.7427043914794922
Batch 40/64 loss: -1.8845529556274414
Batch 41/64 loss: -1.7672767639160156
Batch 42/64 loss: -1.9975528717041016
Batch 43/64 loss: -1.5751495361328125
Batch 44/64 loss: -1.3031492233276367
Batch 45/64 loss: -1.875624656677246
Batch 46/64 loss: -1.9831008911132812
Batch 47/64 loss: -1.7456331253051758
Batch 48/64 loss: -1.7042112350463867
Batch 49/64 loss: -1.7793145179748535
Batch 50/64 loss: -1.545466423034668
Batch 51/64 loss: -1.7235984802246094
Batch 52/64 loss: -1.7167778015136719
Batch 53/64 loss: -2.0741820335388184
Batch 54/64 loss: -1.8049750328063965
Batch 55/64 loss: -1.6010847091674805
Batch 56/64 loss: -1.327742576599121
Batch 57/64 loss: -1.9029216766357422
Batch 58/64 loss: -1.8601055145263672
Batch 59/64 loss: -1.9351396560668945
Batch 60/64 loss: -1.119140625
Batch 61/64 loss: -1.8012986183166504
Batch 62/64 loss: -1.4553213119506836
Batch 63/64 loss: -1.6602392196655273
Batch 64/64 loss: -6.037182807922363
Epoch 351  Train loss: -1.81983024372774  Val loss: -1.826980236879329
Epoch 352
-------------------------------
Batch 1/64 loss: -1.920785903930664
Batch 2/64 loss: -1.2747478485107422
Batch 3/64 loss: -1.6117782592773438
Batch 4/64 loss: -1.5284404754638672
Batch 5/64 loss: -1.5367116928100586
Batch 6/64 loss: -1.7240028381347656
Batch 7/64 loss: -1.7077751159667969
Batch 8/64 loss: -2.0149588584899902
Batch 9/64 loss: -1.9015750885009766
Batch 10/64 loss: -1.666640281677246
Batch 11/64 loss: -1.9063339233398438
Batch 12/64 loss: -1.855684757232666
Batch 13/64 loss: -1.6724109649658203
Batch 14/64 loss: -2.1392908096313477
Batch 15/64 loss: -1.6616096496582031
Batch 16/64 loss: -1.8159265518188477
Batch 17/64 loss: -1.872452735900879
Batch 18/64 loss: -1.5673465728759766
Batch 19/64 loss: -1.3954715728759766
Batch 20/64 loss: -1.9932618141174316
Batch 21/64 loss: -1.8423480987548828
Batch 22/64 loss: -1.607015609741211
Batch 23/64 loss: -1.64569091796875
Batch 24/64 loss: -1.6798973083496094
Batch 25/64 loss: -1.9311509132385254
Batch 26/64 loss: -1.9006247520446777
Batch 27/64 loss: -1.268427848815918
Batch 28/64 loss: -1.5608911514282227
Batch 29/64 loss: -1.8637003898620605
Batch 30/64 loss: -1.5533199310302734
Batch 31/64 loss: -1.7161388397216797
Batch 32/64 loss: -1.8951635360717773
Batch 33/64 loss: -1.955735206604004
Batch 34/64 loss: -1.8929328918457031
Batch 35/64 loss: -1.9278640747070312
Batch 36/64 loss: -1.58587646484375
Batch 37/64 loss: -1.6179113388061523
Batch 38/64 loss: -2.0250353813171387
Batch 39/64 loss: -1.7539567947387695
Batch 40/64 loss: -1.9692816734313965
Batch 41/64 loss: -1.6221108436584473
Batch 42/64 loss: -1.5138254165649414
Batch 43/64 loss: -1.715240478515625
Batch 44/64 loss: -1.9422187805175781
Batch 45/64 loss: -1.6456718444824219
Batch 46/64 loss: -1.984781265258789
Batch 47/64 loss: -1.8416714668273926
Batch 48/64 loss: -2.0088090896606445
Batch 49/64 loss: -1.6959867477416992
Batch 50/64 loss: -2.016122817993164
Batch 51/64 loss: -1.6132335662841797
Batch 52/64 loss: -2.0359978675842285
Batch 53/64 loss: -1.765761375427246
Batch 54/64 loss: -1.4727745056152344
Batch 55/64 loss: -1.972402572631836
Batch 56/64 loss: -1.827301025390625
Batch 57/64 loss: -1.6497182846069336
Batch 58/64 loss: -1.4934368133544922
Batch 59/64 loss: -1.4769601821899414
Batch 60/64 loss: -1.5867271423339844
Batch 61/64 loss: -1.8926820755004883
Batch 62/64 loss: -1.5321035385131836
Batch 63/64 loss: -1.6759443283081055
Batch 64/64 loss: -6.011473178863525
Epoch 352  Train loss: -1.7952981294370165  Val loss: -1.9260759779677767
Epoch 353
-------------------------------
Batch 1/64 loss: -1.6354503631591797
Batch 2/64 loss: -1.5208196640014648
Batch 3/64 loss: -2.0475244522094727
Batch 4/64 loss: -1.4433479309082031
Batch 5/64 loss: -1.6740140914916992
Batch 6/64 loss: -1.9232501983642578
Batch 7/64 loss: -1.812143325805664
Batch 8/64 loss: -1.4675273895263672
Batch 9/64 loss: -1.6401948928833008
Batch 10/64 loss: -1.854349136352539
Batch 11/64 loss: -1.9299821853637695
Batch 12/64 loss: -2.0116653442382812
Batch 13/64 loss: -2.042776107788086
Batch 14/64 loss: -1.7387237548828125
Batch 15/64 loss: -1.8187036514282227
Batch 16/64 loss: -1.8110990524291992
Batch 17/64 loss: -2.0392065048217773
Batch 18/64 loss: -2.0347113609313965
Batch 19/64 loss: -1.842599868774414
Batch 20/64 loss: -1.9999685287475586
Batch 21/64 loss: -1.6761846542358398
Batch 22/64 loss: -1.900339126586914
Batch 23/64 loss: -1.643721580505371
Batch 24/64 loss: -1.6739501953125
Batch 25/64 loss: -1.922286033630371
Batch 26/64 loss: -1.8648052215576172
Batch 27/64 loss: -1.8574037551879883
Batch 28/64 loss: -1.7494926452636719
Batch 29/64 loss: -1.7647523880004883
Batch 30/64 loss: -1.4419002532958984
Batch 31/64 loss: -1.6671295166015625
Batch 32/64 loss: -1.626643180847168
Batch 33/64 loss: -1.8629188537597656
Batch 34/64 loss: -1.759115219116211
Batch 35/64 loss: -1.578836441040039
Batch 36/64 loss: -1.2534780502319336
Batch 37/64 loss: -1.881113052368164
Batch 38/64 loss: -1.7627735137939453
Batch 39/64 loss: -1.816690444946289
Batch 40/64 loss: -1.9510269165039062
Batch 41/64 loss: -1.8940038681030273
Batch 42/64 loss: -2.0247926712036133
Batch 43/64 loss: -1.9206433296203613
Batch 44/64 loss: -1.7484054565429688
Batch 45/64 loss: -1.7994422912597656
Batch 46/64 loss: -2.019123077392578
Batch 47/64 loss: -2.0727438926696777
Batch 48/64 loss: -1.9358100891113281
Batch 49/64 loss: -1.7348365783691406
Batch 50/64 loss: -1.6079626083374023
Batch 51/64 loss: -1.4428529739379883
Batch 52/64 loss: -1.7335901260375977
Batch 53/64 loss: -1.847346305847168
Batch 54/64 loss: -1.8063573837280273
Batch 55/64 loss: -1.507577896118164
Batch 56/64 loss: -1.91923189163208
Batch 57/64 loss: -1.9550886154174805
Batch 58/64 loss: -1.7373523712158203
Batch 59/64 loss: -1.978571891784668
Batch 60/64 loss: -1.3141841888427734
Batch 61/64 loss: -2.0152530670166016
Batch 62/64 loss: -1.7493839263916016
Batch 63/64 loss: -1.7188053131103516
Batch 64/64 loss: -5.893272399902344
Epoch 353  Train loss: -1.8328773797727098  Val loss: -1.9417109145331628
Epoch 354
-------------------------------
Batch 1/64 loss: -1.5140457153320312
Batch 2/64 loss: -1.489309310913086
Batch 3/64 loss: -2.0637807846069336
Batch 4/64 loss: -1.7326250076293945
Batch 5/64 loss: -1.8855037689208984
Batch 6/64 loss: -1.7050447463989258
Batch 7/64 loss: -1.9495182037353516
Batch 8/64 loss: -1.6789979934692383
Batch 9/64 loss: -1.649846076965332
Batch 10/64 loss: -1.783003807067871
Batch 11/64 loss: -1.7805805206298828
Batch 12/64 loss: -1.8289070129394531
Batch 13/64 loss: -1.6836252212524414
Batch 14/64 loss: -2.1210556030273438
Batch 15/64 loss: -1.793990135192871
Batch 16/64 loss: -1.8304119110107422
Batch 17/64 loss: -1.9187355041503906
Batch 18/64 loss: -1.9454984664916992
Batch 19/64 loss: -1.7210216522216797
Batch 20/64 loss: -1.7728605270385742
Batch 21/64 loss: -1.9652056694030762
Batch 22/64 loss: -1.9625205993652344
Batch 23/64 loss: -1.7805585861206055
Batch 24/64 loss: -2.0256552696228027
Batch 25/64 loss: -1.7235660552978516
Batch 26/64 loss: -1.805741310119629
Batch 27/64 loss: -1.3170576095581055
Batch 28/64 loss: -1.8556737899780273
Batch 29/64 loss: -1.6997098922729492
Batch 30/64 loss: -1.677872657775879
Batch 31/64 loss: -1.8000907897949219
Batch 32/64 loss: -2.0282068252563477
Batch 33/64 loss: -2.0411057472229004
Batch 34/64 loss: -1.9972758293151855
Batch 35/64 loss: -1.84682035446167
Batch 36/64 loss: -1.8166112899780273
Batch 37/64 loss: -1.596451759338379
Batch 38/64 loss: -1.954254150390625
Batch 39/64 loss: -1.5077400207519531
Batch 40/64 loss: -1.8885221481323242
Batch 41/64 loss: -1.9724960327148438
Batch 42/64 loss: -1.527867317199707
Batch 43/64 loss: -1.8780040740966797
Batch 44/64 loss: -1.3474254608154297
Batch 45/64 loss: -1.9595966339111328
Batch 46/64 loss: -1.7874269485473633
Batch 47/64 loss: -1.8729839324951172
Batch 48/64 loss: -1.6055097579956055
Batch 49/64 loss: -1.0845937728881836
Batch 50/64 loss: -1.7098808288574219
Batch 51/64 loss: -1.89774751663208
Batch 52/64 loss: -1.776291847229004
Batch 53/64 loss: -1.8418664932250977
Batch 54/64 loss: -1.9313421249389648
Batch 55/64 loss: -1.9198188781738281
Batch 56/64 loss: -2.0234432220458984
Batch 57/64 loss: -1.705918312072754
Batch 58/64 loss: -1.7628164291381836
Batch 59/64 loss: -1.9213323593139648
Batch 60/64 loss: -2.0728750228881836
Batch 61/64 loss: -1.8893442153930664
Batch 62/64 loss: -1.7866477966308594
Batch 63/64 loss: -1.70050048828125
Batch 64/64 loss: -6.038132190704346
Epoch 354  Train loss: -1.8453855832417807  Val loss: -1.842269124034344
Epoch 355
-------------------------------
Batch 1/64 loss: -1.6077861785888672
Batch 2/64 loss: -1.7693262100219727
Batch 3/64 loss: -1.8273839950561523
Batch 4/64 loss: -1.8200855255126953
Batch 5/64 loss: -1.8681044578552246
Batch 6/64 loss: -1.8417043685913086
Batch 7/64 loss: -1.4787712097167969
Batch 8/64 loss: -1.4446077346801758
Batch 9/64 loss: -1.781529426574707
Batch 10/64 loss: -1.3420648574829102
Batch 11/64 loss: -1.9568138122558594
Batch 12/64 loss: -1.7804279327392578
Batch 13/64 loss: -1.7388572692871094
Batch 14/64 loss: -1.7998886108398438
Batch 15/64 loss: -1.6909494400024414
Batch 16/64 loss: -1.694727897644043
Batch 17/64 loss: -1.8262615203857422
Batch 18/64 loss: -1.6029396057128906
Batch 19/64 loss: -1.855484962463379
Batch 20/64 loss: -2.026724338531494
Batch 21/64 loss: -1.6826486587524414
Batch 22/64 loss: -1.6861896514892578
Batch 23/64 loss: -1.9064998626708984
Batch 24/64 loss: -1.673543930053711
Batch 25/64 loss: -1.6567068099975586
Batch 26/64 loss: -1.7115135192871094
Batch 27/64 loss: -1.4904451370239258
Batch 28/64 loss: -1.8085832595825195
Batch 29/64 loss: -1.7736692428588867
Batch 30/64 loss: -1.643885612487793
Batch 31/64 loss: -1.826401710510254
Batch 32/64 loss: -1.8062801361083984
Batch 33/64 loss: -1.8688039779663086
Batch 34/64 loss: -1.8761672973632812
Batch 35/64 loss: -1.809657096862793
Batch 36/64 loss: -1.6872539520263672
Batch 37/64 loss: -1.4097318649291992
Batch 38/64 loss: -1.724233627319336
Batch 39/64 loss: -1.5168647766113281
Batch 40/64 loss: -1.6812095642089844
Batch 41/64 loss: -1.8705148696899414
Batch 42/64 loss: -1.4398221969604492
Batch 43/64 loss: -1.538874626159668
Batch 44/64 loss: -1.9185209274291992
Batch 45/64 loss: -1.305084228515625
Batch 46/64 loss: -1.7173271179199219
Batch 47/64 loss: -1.8072023391723633
Batch 48/64 loss: -1.7831659317016602
Batch 49/64 loss: -1.5089750289916992
Batch 50/64 loss: -2.0243968963623047
Batch 51/64 loss: -1.5890741348266602
Batch 52/64 loss: -1.9331693649291992
Batch 53/64 loss: -1.231461524963379
Batch 54/64 loss: -1.865363597869873
Batch 55/64 loss: -1.856100082397461
Batch 56/64 loss: -1.5214576721191406
Batch 57/64 loss: -1.6670465469360352
Batch 58/64 loss: -1.8514938354492188
Batch 59/64 loss: -1.7230234146118164
Batch 60/64 loss: -1.8300895690917969
Batch 61/64 loss: -1.665287971496582
Batch 62/64 loss: -1.8749990463256836
Batch 63/64 loss: -1.6264991760253906
Batch 64/64 loss: -5.4185099601745605
Epoch 355  Train loss: -1.7601186135235956  Val loss: -1.984105559149149
Epoch 356
-------------------------------
Batch 1/64 loss: -1.5547351837158203
Batch 2/64 loss: -1.8517847061157227
Batch 3/64 loss: -1.5400876998901367
Batch 4/64 loss: -1.8308467864990234
Batch 5/64 loss: -1.8126859664916992
Batch 6/64 loss: -1.544203758239746
Batch 7/64 loss: -1.6182889938354492
Batch 8/64 loss: -1.7277030944824219
Batch 9/64 loss: -1.5001001358032227
Batch 10/64 loss: -1.7356758117675781
Batch 11/64 loss: -1.6608715057373047
Batch 12/64 loss: -1.4816999435424805
Batch 13/64 loss: -1.5133857727050781
Batch 14/64 loss: -1.5679426193237305
Batch 15/64 loss: -1.970749855041504
Batch 16/64 loss: -1.7674641609191895
Batch 17/64 loss: -1.9943828582763672
Batch 18/64 loss: -1.6300525665283203
Batch 19/64 loss: -1.9923973083496094
Batch 20/64 loss: -1.9984941482543945
Batch 21/64 loss: -1.5074310302734375
Batch 22/64 loss: -1.9469232559204102
Batch 23/64 loss: -1.5355091094970703
Batch 24/64 loss: -1.4823760986328125
Batch 25/64 loss: -1.8185992240905762
Batch 26/64 loss: -1.5777502059936523
Batch 27/64 loss: -1.3788280487060547
Batch 28/64 loss: -1.427846908569336
Batch 29/64 loss: -1.7244443893432617
Batch 30/64 loss: -1.6296663284301758
Batch 31/64 loss: -1.8790721893310547
Batch 32/64 loss: -2.06486177444458
Batch 33/64 loss: -1.473550796508789
Batch 34/64 loss: -1.5916528701782227
Batch 35/64 loss: -1.9434661865234375
Batch 36/64 loss: -1.9215660095214844
Batch 37/64 loss: -1.7640256881713867
Batch 38/64 loss: -1.539083480834961
Batch 39/64 loss: -1.6571540832519531
Batch 40/64 loss: -2.003420829772949
Batch 41/64 loss: -1.9426698684692383
Batch 42/64 loss: -1.621164321899414
Batch 43/64 loss: -1.3928728103637695
Batch 44/64 loss: -1.4687891006469727
Batch 45/64 loss: -1.9841728210449219
Batch 46/64 loss: -1.7546634674072266
Batch 47/64 loss: -1.8739690780639648
Batch 48/64 loss: -1.783935546875
Batch 49/64 loss: -1.9045062065124512
Batch 50/64 loss: -1.9494132995605469
Batch 51/64 loss: -1.8917913436889648
Batch 52/64 loss: -1.8775286674499512
Batch 53/64 loss: -1.5631961822509766
Batch 54/64 loss: -1.9854459762573242
Batch 55/64 loss: -1.8382248878479004
Batch 56/64 loss: -1.8787150382995605
Batch 57/64 loss: -1.932581901550293
Batch 58/64 loss: -1.8992290496826172
Batch 59/64 loss: -1.7013988494873047
Batch 60/64 loss: -2.156439781188965
Batch 61/64 loss: -1.8462581634521484
Batch 62/64 loss: -1.9078783988952637
Batch 63/64 loss: -2.044276714324951
Batch 64/64 loss: -6.09293270111084
Epoch 356  Train loss: -1.8028172923069374  Val loss: -2.0175161853279033
Saving best model, epoch: 356
Epoch 357
-------------------------------
Batch 1/64 loss: -1.7544021606445312
Batch 2/64 loss: -1.9051084518432617
Batch 3/64 loss: -2.22639799118042
Batch 4/64 loss: -1.6541838645935059
Batch 5/64 loss: -1.686225414276123
Batch 6/64 loss: -1.8057312965393066
Batch 7/64 loss: -2.113917350769043
Batch 8/64 loss: -2.0470128059387207
Batch 9/64 loss: -1.506185531616211
Batch 10/64 loss: -1.925638198852539
Batch 11/64 loss: -1.6432733535766602
Batch 12/64 loss: -1.6346988677978516
Batch 13/64 loss: -2.0761756896972656
Batch 14/64 loss: -1.8492536544799805
Batch 15/64 loss: -1.750950813293457
Batch 16/64 loss: -1.6889429092407227
Batch 17/64 loss: -1.4024858474731445
Batch 18/64 loss: -1.9291048049926758
Batch 19/64 loss: -1.7423381805419922
Batch 20/64 loss: -1.8097000122070312
Batch 21/64 loss: -1.4762353897094727
Batch 22/64 loss: -1.7596445083618164
Batch 23/64 loss: -2.000734806060791
Batch 24/64 loss: -2.092517852783203
Batch 25/64 loss: -1.6312837600708008
Batch 26/64 loss: -1.8333792686462402
Batch 27/64 loss: -1.5936517715454102
Batch 28/64 loss: -1.8758544921875
Batch 29/64 loss: -1.6911125183105469
Batch 30/64 loss: -1.7326774597167969
Batch 31/64 loss: -1.4149866104125977
Batch 32/64 loss: -2.0601611137390137
Batch 33/64 loss: -1.8771934509277344
Batch 34/64 loss: -1.7223310470581055
Batch 35/64 loss: -1.3922882080078125
Batch 36/64 loss: -1.8901939392089844
Batch 37/64 loss: -1.5257844924926758
Batch 38/64 loss: -1.8288774490356445
Batch 39/64 loss: -1.814448356628418
Batch 40/64 loss: -1.8192644119262695
Batch 41/64 loss: -1.6045913696289062
Batch 42/64 loss: -1.823476791381836
Batch 43/64 loss: -1.8402643203735352
Batch 44/64 loss: -2.124886989593506
Batch 45/64 loss: -1.7424488067626953
Batch 46/64 loss: -1.1700048446655273
Batch 47/64 loss: -1.5402946472167969
Batch 48/64 loss: -1.554457664489746
Batch 49/64 loss: -1.849736213684082
Batch 50/64 loss: -1.7450170516967773
Batch 51/64 loss: -1.8576107025146484
Batch 52/64 loss: -1.8544464111328125
Batch 53/64 loss: -1.1001405715942383
Batch 54/64 loss: -1.9154138565063477
Batch 55/64 loss: -1.8956356048583984
Batch 56/64 loss: -1.9484686851501465
Batch 57/64 loss: -1.9803781509399414
Batch 58/64 loss: -1.671046257019043
Batch 59/64 loss: -1.724402904510498
Batch 60/64 loss: -1.5985488891601562
Batch 61/64 loss: -1.614577293395996
Batch 62/64 loss: -1.6470632553100586
Batch 63/64 loss: -1.9695887565612793
Batch 64/64 loss: -5.686036109924316
Epoch 357  Train loss: -1.807394121207443  Val loss: -1.9694330667712026
Epoch 358
-------------------------------
Batch 1/64 loss: -1.7202682495117188
Batch 2/64 loss: -1.792468547821045
Batch 3/64 loss: -1.8180150985717773
Batch 4/64 loss: -1.7690205574035645
Batch 5/64 loss: -1.5860533714294434
Batch 6/64 loss: -1.7515792846679688
Batch 7/64 loss: -1.8207464218139648
Batch 8/64 loss: -1.7769279479980469
Batch 9/64 loss: -1.7949466705322266
Batch 10/64 loss: -1.7323131561279297
Batch 11/64 loss: -1.8230929374694824
Batch 12/64 loss: -1.924100399017334
Batch 13/64 loss: -1.2821578979492188
Batch 14/64 loss: -1.7475481033325195
Batch 15/64 loss: -1.8501477241516113
Batch 16/64 loss: -2.009366035461426
Batch 17/64 loss: -1.823033332824707
Batch 18/64 loss: -2.00286865234375
Batch 19/64 loss: -1.7380142211914062
Batch 20/64 loss: -1.7415571212768555
Batch 21/64 loss: -1.8272199630737305
Batch 22/64 loss: -2.010781764984131
Batch 23/64 loss: -1.8071699142456055
Batch 24/64 loss: -1.8959779739379883
Batch 25/64 loss: -1.5113811492919922
Batch 26/64 loss: -1.8110628128051758
Batch 27/64 loss: -1.9882469177246094
Batch 28/64 loss: -1.7390918731689453
Batch 29/64 loss: -1.7954816818237305
Batch 30/64 loss: -1.3522310256958008
Batch 31/64 loss: -1.6262588500976562
Batch 32/64 loss: -1.9488334655761719
Batch 33/64 loss: -1.5357589721679688
Batch 34/64 loss: -1.678755760192871
Batch 35/64 loss: -1.7813692092895508
Batch 36/64 loss: -1.869546890258789
Batch 37/64 loss: -1.5984325408935547
Batch 38/64 loss: -1.7564187049865723
Batch 39/64 loss: -1.5472078323364258
Batch 40/64 loss: -1.954214096069336
Batch 41/64 loss: -1.7477645874023438
Batch 42/64 loss: -1.3666925430297852
Batch 43/64 loss: -1.886509895324707
Batch 44/64 loss: -1.6913061141967773
Batch 45/64 loss: -1.8790044784545898
Batch 46/64 loss: -2.15116548538208
Batch 47/64 loss: -2.0739588737487793
Batch 48/64 loss: -1.845707893371582
Batch 49/64 loss: -1.8017616271972656
Batch 50/64 loss: -1.7842111587524414
Batch 51/64 loss: -2.1619181632995605
Batch 52/64 loss: -2.0857181549072266
Batch 53/64 loss: -1.693094253540039
Batch 54/64 loss: -1.4776363372802734
Batch 55/64 loss: -1.7475790977478027
Batch 56/64 loss: -1.8150510787963867
Batch 57/64 loss: -1.2377920150756836
Batch 58/64 loss: -1.5721607208251953
Batch 59/64 loss: -1.4670743942260742
Batch 60/64 loss: -1.7500457763671875
Batch 61/64 loss: -1.6788578033447266
Batch 62/64 loss: -1.9226360321044922
Batch 63/64 loss: -2.0031466484069824
Batch 64/64 loss: -5.953960418701172
Epoch 358  Train loss: -1.8171910678639132  Val loss: -2.008396843454682
Epoch 359
-------------------------------
Batch 1/64 loss: -2.1409811973571777
Batch 2/64 loss: -1.7427043914794922
Batch 3/64 loss: -1.6277532577514648
Batch 4/64 loss: -1.7853050231933594
Batch 5/64 loss: -1.8491096496582031
Batch 6/64 loss: -1.7389020919799805
Batch 7/64 loss: -1.8175182342529297
Batch 8/64 loss: -1.4932136535644531
Batch 9/64 loss: -1.9383726119995117
Batch 10/64 loss: -1.7386894226074219
Batch 11/64 loss: -1.912348747253418
Batch 12/64 loss: -2.116426467895508
Batch 13/64 loss: -1.6858148574829102
Batch 14/64 loss: -1.9568328857421875
Batch 15/64 loss: -1.7544012069702148
Batch 16/64 loss: -1.8959989547729492
Batch 17/64 loss: -1.7967510223388672
Batch 18/64 loss: -1.8244237899780273
Batch 19/64 loss: -1.6300325393676758
Batch 20/64 loss: -1.592087745666504
Batch 21/64 loss: -1.8852224349975586
Batch 22/64 loss: -1.9457435607910156
Batch 23/64 loss: -1.529088020324707
Batch 24/64 loss: -1.9730281829833984
Batch 25/64 loss: -1.6066837310791016
Batch 26/64 loss: -1.5067124366760254
Batch 27/64 loss: -1.4106273651123047
Batch 28/64 loss: -1.6371755599975586
Batch 29/64 loss: -1.9118356704711914
Batch 30/64 loss: -1.5993108749389648
Batch 31/64 loss: -2.14080810546875
Batch 32/64 loss: -1.75872802734375
Batch 33/64 loss: -1.7866249084472656
Batch 34/64 loss: -1.9331212043762207
Batch 35/64 loss: -1.9276189804077148
Batch 36/64 loss: -1.9514331817626953
Batch 37/64 loss: -1.6355552673339844
Batch 38/64 loss: -1.7313356399536133
Batch 39/64 loss: -1.6886405944824219
Batch 40/64 loss: -1.6271114349365234
Batch 41/64 loss: -1.9204978942871094
Batch 42/64 loss: -1.706009864807129
Batch 43/64 loss: -1.9511728286743164
Batch 44/64 loss: -2.0273547172546387
Batch 45/64 loss: -1.9833736419677734
Batch 46/64 loss: -1.6108293533325195
Batch 47/64 loss: -2.1062049865722656
Batch 48/64 loss: -1.9374513626098633
Batch 49/64 loss: -1.6205167770385742
Batch 50/64 loss: -1.936532974243164
Batch 51/64 loss: -1.5195674896240234
Batch 52/64 loss: -1.7408857345581055
Batch 53/64 loss: -1.4816322326660156
Batch 54/64 loss: -1.5100889205932617
Batch 55/64 loss: -1.834965705871582
Batch 56/64 loss: -1.2400283813476562
Batch 57/64 loss: -1.8887887001037598
Batch 58/64 loss: -1.1869392395019531
Batch 59/64 loss: -1.9747495651245117
Batch 60/64 loss: -1.773538589477539
Batch 61/64 loss: -1.963162899017334
Batch 62/64 loss: -1.5442285537719727
Batch 63/64 loss: -1.7916383743286133
Batch 64/64 loss: -5.982931613922119
Epoch 359  Train loss: -1.819002830280977  Val loss: -1.9964369678825038
Epoch 360
-------------------------------
Batch 1/64 loss: -1.4504814147949219
Batch 2/64 loss: -1.5842046737670898
Batch 3/64 loss: -1.9038057327270508
Batch 4/64 loss: -1.7727775573730469
Batch 5/64 loss: -1.8846712112426758
Batch 6/64 loss: -1.6495599746704102
Batch 7/64 loss: -2.061692237854004
Batch 8/64 loss: -1.8940544128417969
Batch 9/64 loss: -1.9073867797851562
Batch 10/64 loss: -1.381204605102539
Batch 11/64 loss: -1.5226964950561523
Batch 12/64 loss: -1.5704069137573242
Batch 13/64 loss: -2.197340965270996
Batch 14/64 loss: -1.838724136352539
Batch 15/64 loss: -1.8359098434448242
Batch 16/64 loss: -2.0193405151367188
Batch 17/64 loss: -1.9646539688110352
Batch 18/64 loss: -1.7426271438598633
Batch 19/64 loss: -1.7758092880249023
Batch 20/64 loss: -1.841902732849121
Batch 21/64 loss: -1.7544832229614258
Batch 22/64 loss: -1.7162542343139648
Batch 23/64 loss: -1.6489810943603516
Batch 24/64 loss: -2.137972831726074
Batch 25/64 loss: -1.852795124053955
Batch 26/64 loss: -1.8344926834106445
Batch 27/64 loss: -1.5873098373413086
Batch 28/64 loss: -1.531386375427246
Batch 29/64 loss: -1.8797903060913086
Batch 30/64 loss: -1.786452293395996
Batch 31/64 loss: -1.5569572448730469
Batch 32/64 loss: -1.611501693725586
Batch 33/64 loss: -1.9015874862670898
Batch 34/64 loss: -1.4817075729370117
Batch 35/64 loss: -2.043651580810547
Batch 36/64 loss: -1.6273746490478516
Batch 37/64 loss: -1.7955150604248047
Batch 38/64 loss: -1.6710195541381836
Batch 39/64 loss: -1.7759885787963867
Batch 40/64 loss: -1.7010631561279297
Batch 41/64 loss: -1.91387939453125
Batch 42/64 loss: -1.906087875366211
Batch 43/64 loss: -1.608078956604004
Batch 44/64 loss: -2.005338191986084
Batch 45/64 loss: -1.8832502365112305
Batch 46/64 loss: -1.5661945343017578
Batch 47/64 loss: -1.6066322326660156
Batch 48/64 loss: -1.984461784362793
Batch 49/64 loss: -1.6935997009277344
Batch 50/64 loss: -1.7280168533325195
Batch 51/64 loss: -2.0402517318725586
Batch 52/64 loss: -1.9676876068115234
Batch 53/64 loss: -1.95682954788208
Batch 54/64 loss: -1.7862787246704102
Batch 55/64 loss: -1.4592351913452148
Batch 56/64 loss: -1.970430850982666
Batch 57/64 loss: -1.8154659271240234
Batch 58/64 loss: -1.8712692260742188
Batch 59/64 loss: -1.9699206352233887
Batch 60/64 loss: -1.899460792541504
Batch 61/64 loss: -1.825211524963379
Batch 62/64 loss: -1.7580490112304688
Batch 63/64 loss: -1.781327247619629
Batch 64/64 loss: -6.108475685119629
Epoch 360  Train loss: -1.8395897996191886  Val loss: -2.018544750934614
Saving best model, epoch: 360
Epoch 361
-------------------------------
Batch 1/64 loss: -1.8456635475158691
Batch 2/64 loss: -1.9323453903198242
Batch 3/64 loss: -1.6873502731323242
Batch 4/64 loss: -1.4704113006591797
Batch 5/64 loss: -1.2289724349975586
Batch 6/64 loss: -1.6562299728393555
Batch 7/64 loss: -1.938389778137207
Batch 8/64 loss: -1.8696393966674805
Batch 9/64 loss: -1.6605377197265625
Batch 10/64 loss: -1.9994502067565918
Batch 11/64 loss: -2.0139150619506836
Batch 12/64 loss: -1.970780372619629
Batch 13/64 loss: -1.8179082870483398
Batch 14/64 loss: -1.891183853149414
Batch 15/64 loss: -1.933199405670166
Batch 16/64 loss: -1.5070743560791016
Batch 17/64 loss: -1.772989273071289
Batch 18/64 loss: -1.8593664169311523
Batch 19/64 loss: -1.7792329788208008
Batch 20/64 loss: -2.0692973136901855
Batch 21/64 loss: -1.8964600563049316
Batch 22/64 loss: -1.9381308555603027
Batch 23/64 loss: -1.727987289428711
Batch 24/64 loss: -2.0555601119995117
Batch 25/64 loss: -1.8041977882385254
Batch 26/64 loss: -2.1164727210998535
Batch 27/64 loss: -1.583479881286621
Batch 28/64 loss: -1.4828510284423828
Batch 29/64 loss: -2.0744967460632324
Batch 30/64 loss: -1.8294620513916016
Batch 31/64 loss: -1.8749704360961914
Batch 32/64 loss: -1.6899404525756836
Batch 33/64 loss: -1.660064697265625
Batch 34/64 loss: -2.0085554122924805
Batch 35/64 loss: -1.9295835494995117
Batch 36/64 loss: -1.8880538940429688
Batch 37/64 loss: -1.9385266304016113
Batch 38/64 loss: -1.7400360107421875
Batch 39/64 loss: -1.694122314453125
Batch 40/64 loss: -1.5424613952636719
Batch 41/64 loss: -1.7505807876586914
Batch 42/64 loss: -1.313878059387207
Batch 43/64 loss: -1.8851590156555176
Batch 44/64 loss: -1.7570934295654297
Batch 45/64 loss: -1.8905630111694336
Batch 46/64 loss: -2.095808506011963
Batch 47/64 loss: -1.8805198669433594
Batch 48/64 loss: -1.5363903045654297
Batch 49/64 loss: -1.667189598083496
Batch 50/64 loss: -1.665928840637207
Batch 51/64 loss: -1.9247827529907227
Batch 52/64 loss: -1.678812026977539
Batch 53/64 loss: -1.5844650268554688
Batch 54/64 loss: -1.7492103576660156
Batch 55/64 loss: -1.755256175994873
Batch 56/64 loss: -1.9507322311401367
Batch 57/64 loss: -1.759981632232666
Batch 58/64 loss: -1.813176155090332
Batch 59/64 loss: -1.5826497077941895
Batch 60/64 loss: -1.8066949844360352
Batch 61/64 loss: -1.8419198989868164
Batch 62/64 loss: -1.809539794921875
Batch 63/64 loss: -1.7260932922363281
Batch 64/64 loss: -5.552619934082031
Epoch 361  Train loss: -1.8348273108987248  Val loss: -1.9561323447735448
Epoch 362
-------------------------------
Batch 1/64 loss: -2.0337023735046387
Batch 2/64 loss: -1.5310325622558594
Batch 3/64 loss: -1.6771469116210938
Batch 4/64 loss: -1.539973258972168
Batch 5/64 loss: -1.9014787673950195
Batch 6/64 loss: -1.7988038063049316
Batch 7/64 loss: -1.8552017211914062
Batch 8/64 loss: -1.552267074584961
Batch 9/64 loss: -1.4054374694824219
Batch 10/64 loss: -1.9470691680908203
Batch 11/64 loss: -1.6645698547363281
Batch 12/64 loss: -1.9707369804382324
Batch 13/64 loss: -1.8744516372680664
Batch 14/64 loss: -1.513747215270996
Batch 15/64 loss: -1.6765775680541992
Batch 16/64 loss: -1.7663936614990234
Batch 17/64 loss: -1.5392084121704102
Batch 18/64 loss: -1.6195459365844727
Batch 19/64 loss: -1.431462287902832
Batch 20/64 loss: -1.7686891555786133
Batch 21/64 loss: -1.9218387603759766
Batch 22/64 loss: -1.6803350448608398
Batch 23/64 loss: -1.9023418426513672
Batch 24/64 loss: -1.4653377532958984
Batch 25/64 loss: -1.8451604843139648
Batch 26/64 loss: -2.0557174682617188
Batch 27/64 loss: -1.9136900901794434
Batch 28/64 loss: -1.9377727508544922
Batch 29/64 loss: -1.8069047927856445
Batch 30/64 loss: -1.7176399230957031
Batch 31/64 loss: -1.7990903854370117
Batch 32/64 loss: -1.7327070236206055
Batch 33/64 loss: -1.9081697463989258
Batch 34/64 loss: -1.7713956832885742
Batch 35/64 loss: -1.9031314849853516
Batch 36/64 loss: -1.7571744918823242
Batch 37/64 loss: -1.8700017929077148
Batch 38/64 loss: -2.0028076171875
Batch 39/64 loss: -1.6168861389160156
Batch 40/64 loss: -1.3752508163452148
Batch 41/64 loss: -1.8248786926269531
Batch 42/64 loss: -2.032588481903076
Batch 43/64 loss: -1.8765926361083984
Batch 44/64 loss: -1.8824548721313477
Batch 45/64 loss: -1.9974141120910645
Batch 46/64 loss: -1.270650863647461
Batch 47/64 loss: -1.7151098251342773
Batch 48/64 loss: -2.0158638954162598
Batch 49/64 loss: -1.6321544647216797
Batch 50/64 loss: -1.6850967407226562
Batch 51/64 loss: -1.1049060821533203
Batch 52/64 loss: -1.8463516235351562
Batch 53/64 loss: -1.6644248962402344
Batch 54/64 loss: -1.7904243469238281
Batch 55/64 loss: -1.681443214416504
Batch 56/64 loss: -1.7957353591918945
Batch 57/64 loss: -1.6815299987792969
Batch 58/64 loss: -1.9063949584960938
Batch 59/64 loss: -1.8138675689697266
Batch 60/64 loss: -1.9812088012695312
Batch 61/64 loss: -2.118403434753418
Batch 62/64 loss: -1.678243637084961
Batch 63/64 loss: -1.5745010375976562
Batch 64/64 loss: -5.8714494705200195
Epoch 362  Train loss: -1.8043086519428329  Val loss: -1.80917863092062
Epoch 363
-------------------------------
Batch 1/64 loss: -1.6371097564697266
Batch 2/64 loss: -1.9315123558044434
Batch 3/64 loss: -1.9619269371032715
Batch 4/64 loss: -1.6996650695800781
Batch 5/64 loss: -1.8429145812988281
Batch 6/64 loss: -1.8354473114013672
Batch 7/64 loss: -1.5869226455688477
Batch 8/64 loss: -2.0440926551818848
Batch 9/64 loss: -1.5822162628173828
Batch 10/64 loss: -1.5976486206054688
Batch 11/64 loss: -1.8363122940063477
Batch 12/64 loss: -1.3816308975219727
Batch 13/64 loss: -2.020709991455078
Batch 14/64 loss: -1.954765796661377
Batch 15/64 loss: -1.7986030578613281
Batch 16/64 loss: -1.5534124374389648
Batch 17/64 loss: -1.8261566162109375
Batch 18/64 loss: -1.7777528762817383
Batch 19/64 loss: -1.8808069229125977
Batch 20/64 loss: -1.8915834426879883
Batch 21/64 loss: -1.8993597030639648
Batch 22/64 loss: -2.0408453941345215
Batch 23/64 loss: -1.9816794395446777
Batch 24/64 loss: -1.9457969665527344
Batch 25/64 loss: -1.7465791702270508
Batch 26/64 loss: -2.0285768508911133
Batch 27/64 loss: -1.7687416076660156
Batch 28/64 loss: -1.4619865417480469
Batch 29/64 loss: -1.8136014938354492
Batch 30/64 loss: -2.0752358436584473
Batch 31/64 loss: -1.9126510620117188
Batch 32/64 loss: -1.8311939239501953
Batch 33/64 loss: -1.899688720703125
Batch 34/64 loss: -1.1901226043701172
Batch 35/64 loss: -1.627084732055664
Batch 36/64 loss: -1.7923860549926758
Batch 37/64 loss: -1.5909557342529297
Batch 38/64 loss: -1.5727148056030273
Batch 39/64 loss: -1.6424570083618164
Batch 40/64 loss: -1.7171497344970703
Batch 41/64 loss: -1.925137996673584
Batch 42/64 loss: -1.670933723449707
Batch 43/64 loss: -1.6823596954345703
Batch 44/64 loss: -1.3243446350097656
Batch 45/64 loss: -1.650141716003418
Batch 46/64 loss: -1.8889598846435547
Batch 47/64 loss: -1.519190788269043
Batch 48/64 loss: -1.2188949584960938
Batch 49/64 loss: -1.9459123611450195
Batch 50/64 loss: -1.8778886795043945
Batch 51/64 loss: -1.531266212463379
Batch 52/64 loss: -1.7487430572509766
Batch 53/64 loss: -1.961296558380127
Batch 54/64 loss: -1.8346285820007324
Batch 55/64 loss: -1.6742925643920898
Batch 56/64 loss: -2.0135116577148438
Batch 57/64 loss: -1.385167121887207
Batch 58/64 loss: -1.4494943618774414
Batch 59/64 loss: -1.9525485038757324
Batch 60/64 loss: -1.696584701538086
Batch 61/64 loss: -1.8819122314453125
Batch 62/64 loss: -1.629568099975586
Batch 63/64 loss: -1.9249801635742188
Batch 64/64 loss: -5.412158966064453
Epoch 363  Train loss: -1.7980686337340113  Val loss: -2.0599973750687957
Saving best model, epoch: 363
Epoch 364
-------------------------------
Batch 1/64 loss: -1.955979347229004
Batch 2/64 loss: -1.553288459777832
Batch 3/64 loss: -1.7830243110656738
Batch 4/64 loss: -1.7850208282470703
Batch 5/64 loss: -1.7532777786254883
Batch 6/64 loss: -1.7833261489868164
Batch 7/64 loss: -1.8373804092407227
Batch 8/64 loss: -1.7590670585632324
Batch 9/64 loss: -1.5922751426696777
Batch 10/64 loss: -1.6690006256103516
Batch 11/64 loss: -1.867382526397705
Batch 12/64 loss: -1.97564697265625
Batch 13/64 loss: -1.923095703125
Batch 14/64 loss: -1.7197847366333008
Batch 15/64 loss: -1.5179834365844727
Batch 16/64 loss: -1.4764680862426758
Batch 17/64 loss: -1.5786151885986328
Batch 18/64 loss: -1.8045854568481445
Batch 19/64 loss: -2.1115779876708984
Batch 20/64 loss: -1.9189977645874023
Batch 21/64 loss: -2.1489710807800293
Batch 22/64 loss: -1.6345634460449219
Batch 23/64 loss: -1.8971447944641113
Batch 24/64 loss: -1.5998144149780273
Batch 25/64 loss: -1.9770121574401855
Batch 26/64 loss: -1.9232025146484375
Batch 27/64 loss: -1.883932113647461
Batch 28/64 loss: -1.8051929473876953
Batch 29/64 loss: -1.7680444717407227
Batch 30/64 loss: -1.524397850036621
Batch 31/64 loss: -1.981642723083496
Batch 32/64 loss: -1.8415470123291016
Batch 33/64 loss: -1.4770374298095703
Batch 34/64 loss: -1.8257513046264648
Batch 35/64 loss: -1.9409980773925781
Batch 36/64 loss: -1.586134910583496
Batch 37/64 loss: -2.0043716430664062
Batch 38/64 loss: -1.6880807876586914
Batch 39/64 loss: -1.6023492813110352
Batch 40/64 loss: -1.5047798156738281
Batch 41/64 loss: -1.853078842163086
Batch 42/64 loss: -1.8028945922851562
Batch 43/64 loss: -1.661768913269043
Batch 44/64 loss: -1.5738153457641602
Batch 45/64 loss: -1.781813621520996
Batch 46/64 loss: -1.6470508575439453
Batch 47/64 loss: -2.0002450942993164
Batch 48/64 loss: -1.743891716003418
Batch 49/64 loss: -1.7590599060058594
Batch 50/64 loss: -2.0105762481689453
Batch 51/64 loss: -1.9231929779052734
Batch 52/64 loss: -1.8192386627197266
Batch 53/64 loss: -1.79107666015625
Batch 54/64 loss: -2.1268181800842285
Batch 55/64 loss: -1.2843341827392578
Batch 56/64 loss: -1.9069347381591797
Batch 57/64 loss: -1.5116195678710938
Batch 58/64 loss: -1.612217903137207
Batch 59/64 loss: -1.901257038116455
Batch 60/64 loss: -1.9619927406311035
Batch 61/64 loss: -1.5559453964233398
Batch 62/64 loss: -1.7786164283752441
Batch 63/64 loss: -1.7433958053588867
Batch 64/64 loss: -5.05605936050415
Epoch 364  Train loss: -1.8121353205512551  Val loss: -1.9325410901885671
Epoch 365
-------------------------------
Batch 1/64 loss: -1.8304204940795898
Batch 2/64 loss: -1.522170066833496
Batch 3/64 loss: -1.8376688957214355
Batch 4/64 loss: -1.4064512252807617
Batch 5/64 loss: -1.9869232177734375
Batch 6/64 loss: -1.653855323791504
Batch 7/64 loss: -1.8892269134521484
Batch 8/64 loss: -1.6932926177978516
Batch 9/64 loss: -1.633894920349121
Batch 10/64 loss: -1.9887094497680664
Batch 11/64 loss: -1.8092832565307617
Batch 12/64 loss: -1.9170160293579102
Batch 13/64 loss: -1.942887306213379
Batch 14/64 loss: -1.9584856033325195
Batch 15/64 loss: -1.513686180114746
Batch 16/64 loss: -1.8967971801757812
Batch 17/64 loss: -1.8661823272705078
Batch 18/64 loss: -1.2904281616210938
Batch 19/64 loss: -2.03731107711792
Batch 20/64 loss: -1.4388542175292969
Batch 21/64 loss: -1.8344135284423828
Batch 22/64 loss: -1.6684818267822266
Batch 23/64 loss: -1.6954326629638672
Batch 24/64 loss: -1.6824064254760742
Batch 25/64 loss: -1.6855096817016602
Batch 26/64 loss: -1.645768165588379
Batch 27/64 loss: -1.796548843383789
Batch 28/64 loss: -1.6096744537353516
Batch 29/64 loss: -0.9598970413208008
Batch 30/64 loss: -1.5386943817138672
Batch 31/64 loss: -1.7441654205322266
Batch 32/64 loss: -1.8469972610473633
Batch 33/64 loss: -1.6759943962097168
Batch 34/64 loss: -1.7460079193115234
Batch 35/64 loss: -1.6239748001098633
Batch 36/64 loss: -1.4328117370605469
Batch 37/64 loss: -1.8289341926574707
Batch 38/64 loss: -1.9304399490356445
Batch 39/64 loss: -1.5805301666259766
Batch 40/64 loss: -1.7420692443847656
Batch 41/64 loss: -1.6749258041381836
Batch 42/64 loss: -1.4681196212768555
Batch 43/64 loss: -1.9242658615112305
Batch 44/64 loss: -1.6580705642700195
Batch 45/64 loss: -2.3338279724121094
Batch 46/64 loss: -1.641092300415039
Batch 47/64 loss: -1.4347248077392578
Batch 48/64 loss: -2.1639771461486816
Batch 49/64 loss: -1.896876335144043
Batch 50/64 loss: -1.9207744598388672
Batch 51/64 loss: -1.7265958786010742
Batch 52/64 loss: -1.5276689529418945
Batch 53/64 loss: -1.9858551025390625
Batch 54/64 loss: -1.682204246520996
Batch 55/64 loss: -2.18115234375
Batch 56/64 loss: -2.037618637084961
Batch 57/64 loss: -2.0079593658447266
Batch 58/64 loss: -1.7930822372436523
Batch 59/64 loss: -2.107585906982422
Batch 60/64 loss: -2.0069665908813477
Batch 61/64 loss: -1.8570003509521484
Batch 62/64 loss: -1.6851062774658203
Batch 63/64 loss: -1.8610143661499023
Batch 64/64 loss: -6.2679524421691895
Epoch 365  Train loss: -1.814270212136063  Val loss: -2.03427061100596
Epoch 366
-------------------------------
Batch 1/64 loss: -1.9198427200317383
Batch 2/64 loss: -1.7494325637817383
Batch 3/64 loss: -1.8787946701049805
Batch 4/64 loss: -1.4297571182250977
Batch 5/64 loss: -1.8742704391479492
Batch 6/64 loss: -1.8945159912109375
Batch 7/64 loss: -2.0112037658691406
Batch 8/64 loss: -1.9189949035644531
Batch 9/64 loss: -1.7759180068969727
Batch 10/64 loss: -1.7872772216796875
Batch 11/64 loss: -1.8931255340576172
Batch 12/64 loss: -1.946467399597168
Batch 13/64 loss: -1.699502944946289
Batch 14/64 loss: -1.719895362854004
Batch 15/64 loss: -1.7304601669311523
Batch 16/64 loss: -1.9779109954833984
Batch 17/64 loss: -1.7697925567626953
Batch 18/64 loss: -1.867837905883789
Batch 19/64 loss: -1.7959918975830078
Batch 20/64 loss: -2.061461925506592
Batch 21/64 loss: -1.4413118362426758
Batch 22/64 loss: -1.952651023864746
Batch 23/64 loss: -1.7780065536499023
Batch 24/64 loss: -2.0054240226745605
Batch 25/64 loss: -1.6375751495361328
Batch 26/64 loss: -1.7748832702636719
Batch 27/64 loss: -1.5026960372924805
Batch 28/64 loss: -1.8609166145324707
Batch 29/64 loss: -1.921335220336914
Batch 30/64 loss: -1.841630458831787
Batch 31/64 loss: -1.9383163452148438
Batch 32/64 loss: -1.4387950897216797
Batch 33/64 loss: -1.3557701110839844
Batch 34/64 loss: -2.1587371826171875
Batch 35/64 loss: -2.0045619010925293
Batch 36/64 loss: -1.7899103164672852
Batch 37/64 loss: -1.458932876586914
Batch 38/64 loss: -2.060882568359375
Batch 39/64 loss: -1.4329042434692383
Batch 40/64 loss: -1.6624326705932617
Batch 41/64 loss: -1.6137619018554688
Batch 42/64 loss: -1.5757780075073242
Batch 43/64 loss: -1.6574602127075195
Batch 44/64 loss: -1.7366571426391602
Batch 45/64 loss: -1.6520967483520508
Batch 46/64 loss: -1.4117088317871094
Batch 47/64 loss: -1.6229171752929688
Batch 48/64 loss: -1.7662029266357422
Batch 49/64 loss: -1.2241582870483398
Batch 50/64 loss: -1.8584661483764648
Batch 51/64 loss: -1.6694316864013672
Batch 52/64 loss: -1.6150093078613281
Batch 53/64 loss: -1.478623390197754
Batch 54/64 loss: -1.7624950408935547
Batch 55/64 loss: -1.8976469039916992
Batch 56/64 loss: -1.2782344818115234
Batch 57/64 loss: -1.87554931640625
Batch 58/64 loss: -1.7662973403930664
Batch 59/64 loss: -1.8005428314208984
Batch 60/64 loss: -1.9999752044677734
Batch 61/64 loss: -1.3866815567016602
Batch 62/64 loss: -1.8593826293945312
Batch 63/64 loss: -1.9546265602111816
Batch 64/64 loss: -5.565801620483398
Epoch 366  Train loss: -1.7938538420434091  Val loss: -1.9851827064330636
Epoch 367
-------------------------------
Batch 1/64 loss: -1.9042611122131348
Batch 2/64 loss: -1.9340620040893555
Batch 3/64 loss: -1.8352470397949219
Batch 4/64 loss: -1.7349777221679688
Batch 5/64 loss: -1.5727968215942383
Batch 6/64 loss: -1.8913860321044922
Batch 7/64 loss: -1.173750877380371
Batch 8/64 loss: -1.7070941925048828
Batch 9/64 loss: -1.9070463180541992
Batch 10/64 loss: -1.8318939208984375
Batch 11/64 loss: -1.738546371459961
Batch 12/64 loss: -1.6797761917114258
Batch 13/64 loss: -1.6788911819458008
Batch 14/64 loss: -1.7620725631713867
Batch 15/64 loss: -1.8602609634399414
Batch 16/64 loss: -1.724700927734375
Batch 17/64 loss: -1.6535863876342773
Batch 18/64 loss: -1.676081657409668
Batch 19/64 loss: -1.8441438674926758
Batch 20/64 loss: -1.668722152709961
Batch 21/64 loss: -1.7050180435180664
Batch 22/64 loss: -1.5560550689697266
Batch 23/64 loss: -1.6769447326660156
Batch 24/64 loss: -1.9234619140625
Batch 25/64 loss: -1.4901189804077148
Batch 26/64 loss: -1.7368335723876953
Batch 27/64 loss: -1.5650262832641602
Batch 28/64 loss: -1.8651127815246582
Batch 29/64 loss: -1.5330743789672852
Batch 30/64 loss: -1.7787256240844727
Batch 31/64 loss: -0.902857780456543
Batch 32/64 loss: -1.7714958190917969
Batch 33/64 loss: -1.3319902420043945
Batch 34/64 loss: -1.8053770065307617
Batch 35/64 loss: -1.485687255859375
Batch 36/64 loss: -1.7296924591064453
Batch 37/64 loss: -1.701817512512207
Batch 38/64 loss: -1.8754911422729492
Batch 39/64 loss: -1.8592753410339355
Batch 40/64 loss: -2.0074901580810547
Batch 41/64 loss: -1.7189760208129883
Batch 42/64 loss: -1.9225645065307617
Batch 43/64 loss: -1.6839475631713867
Batch 44/64 loss: -1.6835289001464844
Batch 45/64 loss: -1.9885215759277344
Batch 46/64 loss: -1.4778728485107422
Batch 47/64 loss: -1.8459291458129883
Batch 48/64 loss: -1.61492919921875
Batch 49/64 loss: -1.5593795776367188
Batch 50/64 loss: -1.5894536972045898
Batch 51/64 loss: -1.5799531936645508
Batch 52/64 loss: -1.791670799255371
Batch 53/64 loss: -1.9797182083129883
Batch 54/64 loss: -2.0706048011779785
Batch 55/64 loss: -1.7516374588012695
Batch 56/64 loss: -1.9517812728881836
Batch 57/64 loss: -1.9305543899536133
Batch 58/64 loss: -1.785059928894043
Batch 59/64 loss: -1.8966832160949707
Batch 60/64 loss: -1.6741342544555664
Batch 61/64 loss: -2.060129165649414
Batch 62/64 loss: -1.8680362701416016
Batch 63/64 loss: -1.8311691284179688
Batch 64/64 loss: -5.895912170410156
Epoch 367  Train loss: -1.7844551161223767  Val loss: -2.012672044157572
Epoch 368
-------------------------------
Batch 1/64 loss: -2.0125718116760254
Batch 2/64 loss: -1.9217257499694824
Batch 3/64 loss: -1.73313570022583
Batch 4/64 loss: -2.041224956512451
Batch 5/64 loss: -1.9643750190734863
Batch 6/64 loss: -1.9931058883666992
Batch 7/64 loss: -2.063002109527588
Batch 8/64 loss: -1.7970380783081055
Batch 9/64 loss: -1.858567237854004
Batch 10/64 loss: -1.968193531036377
Batch 11/64 loss: -1.9734201431274414
Batch 12/64 loss: -1.647477149963379
Batch 13/64 loss: -1.8666105270385742
Batch 14/64 loss: -1.6639070510864258
Batch 15/64 loss: -1.6069841384887695
Batch 16/64 loss: -1.7107725143432617
Batch 17/64 loss: -1.654435157775879
Batch 18/64 loss: -1.868159294128418
Batch 19/64 loss: -1.9997425079345703
Batch 20/64 loss: -1.630528450012207
Batch 21/64 loss: -1.8384408950805664
Batch 22/64 loss: -2.0703372955322266
Batch 23/64 loss: -1.879847526550293
Batch 24/64 loss: -1.924245834350586
Batch 25/64 loss: -2.011943817138672
Batch 26/64 loss: -1.4649114608764648
Batch 27/64 loss: -1.7284421920776367
Batch 28/64 loss: -1.6905508041381836
Batch 29/64 loss: -1.6310310363769531
Batch 30/64 loss: -1.878159523010254
Batch 31/64 loss: -1.7206029891967773
Batch 32/64 loss: -2.0081586837768555
Batch 33/64 loss: -1.6483039855957031
Batch 34/64 loss: -1.5395174026489258
Batch 35/64 loss: -2.0394182205200195
Batch 36/64 loss: -1.8798713684082031
Batch 37/64 loss: -1.7765817642211914
Batch 38/64 loss: -1.7782621383666992
Batch 39/64 loss: -1.9980039596557617
Batch 40/64 loss: -1.7968339920043945
Batch 41/64 loss: -1.6411685943603516
Batch 42/64 loss: -1.9179048538208008
Batch 43/64 loss: -1.6996841430664062
Batch 44/64 loss: -1.5316553115844727
Batch 45/64 loss: -2.013155937194824
Batch 46/64 loss: -2.034907341003418
Batch 47/64 loss: -1.6795539855957031
Batch 48/64 loss: -1.6173200607299805
Batch 49/64 loss: -1.6231489181518555
Batch 50/64 loss: -1.4916715621948242
Batch 51/64 loss: -1.516744613647461
Batch 52/64 loss: -1.9077224731445312
Batch 53/64 loss: -1.8198089599609375
Batch 54/64 loss: -1.6341562271118164
Batch 55/64 loss: -1.4997692108154297
Batch 56/64 loss: -1.751906394958496
Batch 57/64 loss: -1.7035541534423828
Batch 58/64 loss: -1.9284710884094238
Batch 59/64 loss: -1.5107927322387695
Batch 60/64 loss: -1.689992904663086
Batch 61/64 loss: -1.8098068237304688
Batch 62/64 loss: -1.7339258193969727
Batch 63/64 loss: -1.7091178894042969
Batch 64/64 loss: -5.769158363342285
Epoch 368  Train loss: -1.8364117753271962  Val loss: -1.8823548280906022
Epoch 369
-------------------------------
Batch 1/64 loss: -1.6112041473388672
Batch 2/64 loss: -1.628732681274414
Batch 3/64 loss: -1.855179786682129
Batch 4/64 loss: -1.6593561172485352
Batch 5/64 loss: -1.6678447723388672
Batch 6/64 loss: -1.8616447448730469
Batch 7/64 loss: -1.8947443962097168
Batch 8/64 loss: -1.8529634475708008
Batch 9/64 loss: -1.5131721496582031
Batch 10/64 loss: -1.8681564331054688
Batch 11/64 loss: -1.9385757446289062
Batch 12/64 loss: -1.4257545471191406
Batch 13/64 loss: -1.6196403503417969
Batch 14/64 loss: -1.670273780822754
Batch 15/64 loss: -2.049661636352539
Batch 16/64 loss: -1.9014854431152344
Batch 17/64 loss: -1.687983512878418
Batch 18/64 loss: -1.8097476959228516
Batch 19/64 loss: -1.799180030822754
Batch 20/64 loss: -1.9229669570922852
Batch 21/64 loss: -1.5659370422363281
Batch 22/64 loss: -1.4223718643188477
Batch 23/64 loss: -1.7566490173339844
Batch 24/64 loss: -1.9080533981323242
Batch 25/64 loss: -1.842576026916504
Batch 26/64 loss: -1.9295768737792969
Batch 27/64 loss: -1.5937080383300781
Batch 28/64 loss: -1.670548439025879
Batch 29/64 loss: -1.8309154510498047
Batch 30/64 loss: -1.738368034362793
Batch 31/64 loss: -1.4539709091186523
Batch 32/64 loss: -1.4972524642944336
Batch 33/64 loss: -2.0358223915100098
Batch 34/64 loss: -1.8168601989746094
Batch 35/64 loss: -2.064358711242676
Batch 36/64 loss: -1.9399595260620117
Batch 37/64 loss: -1.8833560943603516
Batch 38/64 loss: -1.9506793022155762
Batch 39/64 loss: -1.7909393310546875
Batch 40/64 loss: -2.0999512672424316
Batch 41/64 loss: -1.7118816375732422
Batch 42/64 loss: -1.6262626647949219
Batch 43/64 loss: -1.9886646270751953
Batch 44/64 loss: -1.8451824188232422
Batch 45/64 loss: -0.9470853805541992
Batch 46/64 loss: -1.9463815689086914
Batch 47/64 loss: -1.8586602210998535
Batch 48/64 loss: -1.9259748458862305
Batch 49/64 loss: -1.7099618911743164
Batch 50/64 loss: -1.5826749801635742
Batch 51/64 loss: -1.6898012161254883
Batch 52/64 loss: -1.581644058227539
Batch 53/64 loss: -1.8631486892700195
Batch 54/64 loss: -1.7862358093261719
Batch 55/64 loss: -1.3727445602416992
Batch 56/64 loss: -1.786104679107666
Batch 57/64 loss: -1.7910757064819336
Batch 58/64 loss: -1.4233789443969727
Batch 59/64 loss: -2.1030797958374023
Batch 60/64 loss: -1.877525806427002
Batch 61/64 loss: -1.9959068298339844
Batch 62/64 loss: -2.0502185821533203
Batch 63/64 loss: -1.9659786224365234
Batch 64/64 loss: -5.680450439453125
Epoch 369  Train loss: -1.8152162215288947  Val loss: -2.1091462754711663
Saving best model, epoch: 369
Epoch 370
-------------------------------
Batch 1/64 loss: -1.835458755493164
Batch 2/64 loss: -1.8549938201904297
Batch 3/64 loss: -1.2836380004882812
Batch 4/64 loss: -1.6792659759521484
Batch 5/64 loss: -1.8686418533325195
Batch 6/64 loss: -1.6235065460205078
Batch 7/64 loss: -1.746377944946289
Batch 8/64 loss: -1.8956317901611328
Batch 9/64 loss: -1.7552127838134766
Batch 10/64 loss: -1.7922019958496094
Batch 11/64 loss: -1.9439153671264648
Batch 12/64 loss: -1.862985610961914
Batch 13/64 loss: -1.7071056365966797
Batch 14/64 loss: -2.1350350379943848
Batch 15/64 loss: -2.00687313079834
Batch 16/64 loss: -2.037123680114746
Batch 17/64 loss: -1.8964595794677734
Batch 18/64 loss: -1.4351940155029297
Batch 19/64 loss: -1.8995628356933594
Batch 20/64 loss: -1.8729143142700195
Batch 21/64 loss: -1.7670259475708008
Batch 22/64 loss: -1.899362564086914
Batch 23/64 loss: -1.970870018005371
Batch 24/64 loss: -1.9128856658935547
Batch 25/64 loss: -1.9529924392700195
Batch 26/64 loss: -1.2328681945800781
Batch 27/64 loss: -1.5677385330200195
Batch 28/64 loss: -1.635183334350586
Batch 29/64 loss: -1.817845344543457
Batch 30/64 loss: -2.2059688568115234
Batch 31/64 loss: -2.041541576385498
Batch 32/64 loss: -2.185152053833008
Batch 33/64 loss: -1.8244380950927734
Batch 34/64 loss: -1.2594804763793945
Batch 35/64 loss: -1.8851470947265625
Batch 36/64 loss: -2.019195556640625
Batch 37/64 loss: -1.7129011154174805
Batch 38/64 loss: -1.727004051208496
Batch 39/64 loss: -1.8616580963134766
Batch 40/64 loss: -1.8843889236450195
Batch 41/64 loss: -1.8632888793945312
Batch 42/64 loss: -1.838088035583496
Batch 43/64 loss: -1.8111352920532227
Batch 44/64 loss: -1.8753399848937988
Batch 45/64 loss: -1.4510574340820312
Batch 46/64 loss: -1.8444671630859375
Batch 47/64 loss: -1.8242359161376953
Batch 48/64 loss: -1.8390960693359375
Batch 49/64 loss: -1.848376750946045
Batch 50/64 loss: -1.8742432594299316
Batch 51/64 loss: -1.7506332397460938
Batch 52/64 loss: -1.4913110733032227
Batch 53/64 loss: -1.740527629852295
Batch 54/64 loss: -1.7860631942749023
Batch 55/64 loss: -1.9053168296813965
Batch 56/64 loss: -1.8874249458312988
Batch 57/64 loss: -1.6674385070800781
Batch 58/64 loss: -1.6788454055786133
Batch 59/64 loss: -2.2611565589904785
Batch 60/64 loss: -1.8913335800170898
Batch 61/64 loss: -1.704254150390625
Batch 62/64 loss: -1.7552261352539062
Batch 63/64 loss: -2.0290160179138184
Batch 64/64 loss: -6.0762176513671875
Epoch 370  Train loss: -1.8615025239832261  Val loss: -2.0733329143720804
Epoch 371
-------------------------------
Batch 1/64 loss: -2.0191307067871094
Batch 2/64 loss: -1.8561115264892578
Batch 3/64 loss: -1.9008493423461914
Batch 4/64 loss: -1.558095932006836
Batch 5/64 loss: -1.9807319641113281
Batch 6/64 loss: -1.9448609352111816
Batch 7/64 loss: -1.9159302711486816
Batch 8/64 loss: -2.0862817764282227
Batch 9/64 loss: -1.8828754425048828
Batch 10/64 loss: -1.4859399795532227
Batch 11/64 loss: -1.8808040618896484
Batch 12/64 loss: -1.9917173385620117
Batch 13/64 loss: -2.0194597244262695
Batch 14/64 loss: -1.7254552841186523
Batch 15/64 loss: -1.8900518417358398
Batch 16/64 loss: -1.7940521240234375
Batch 17/64 loss: -1.9544439315795898
Batch 18/64 loss: -1.949782371520996
Batch 19/64 loss: -1.742964744567871
Batch 20/64 loss: -1.8504981994628906
Batch 21/64 loss: -1.9772834777832031
Batch 22/64 loss: -1.4112520217895508
Batch 23/64 loss: -1.6870746612548828
Batch 24/64 loss: -2.05203914642334
Batch 25/64 loss: -1.703028678894043
Batch 26/64 loss: -1.68646240234375
Batch 27/64 loss: -1.779771327972412
Batch 28/64 loss: -1.3690814971923828
Batch 29/64 loss: -1.8867039680480957
Batch 30/64 loss: -1.326521873474121
Batch 31/64 loss: -1.6949596405029297
Batch 32/64 loss: -2.0623393058776855
Batch 33/64 loss: -2.0867958068847656
Batch 34/64 loss: -1.6489133834838867
Batch 35/64 loss: -1.9255585670471191
Batch 36/64 loss: -1.3544692993164062
Batch 37/64 loss: -1.7173480987548828
Batch 38/64 loss: -1.4733476638793945
Batch 39/64 loss: -1.2355775833129883
Batch 40/64 loss: -1.7661542892456055
Batch 41/64 loss: -1.799910545349121
Batch 42/64 loss: -1.882467269897461
Batch 43/64 loss: -1.8937797546386719
Batch 44/64 loss: -1.7172012329101562
Batch 45/64 loss: -1.6191835403442383
Batch 46/64 loss: -1.3004570007324219
Batch 47/64 loss: -2.026033878326416
Batch 48/64 loss: -1.942469596862793
Batch 49/64 loss: -2.1285529136657715
Batch 50/64 loss: -2.165684223175049
Batch 51/64 loss: -1.9674720764160156
Batch 52/64 loss: -1.7015180587768555
Batch 53/64 loss: -1.9844722747802734
Batch 54/64 loss: -1.9350242614746094
Batch 55/64 loss: -1.7263212203979492
Batch 56/64 loss: -1.5994071960449219
Batch 57/64 loss: -1.6735773086547852
Batch 58/64 loss: -1.8163213729858398
Batch 59/64 loss: -1.8680849075317383
Batch 60/64 loss: -1.484553337097168
Batch 61/64 loss: -1.8837223052978516
Batch 62/64 loss: -2.0448174476623535
Batch 63/64 loss: -1.82749605178833
Batch 64/64 loss: -5.9098029136657715
Epoch 371  Train loss: -1.8462054925806382  Val loss: -1.9725426349443258
Epoch 372
-------------------------------
Batch 1/64 loss: -1.7076473236083984
Batch 2/64 loss: -1.8923125267028809
Batch 3/64 loss: -2.054539680480957
Batch 4/64 loss: -1.8289031982421875
Batch 5/64 loss: -1.6666193008422852
Batch 6/64 loss: -1.9277801513671875
Batch 7/64 loss: -1.7359285354614258
Batch 8/64 loss: -1.7442350387573242
Batch 9/64 loss: -1.3497514724731445
Batch 10/64 loss: -1.7906460762023926
Batch 11/64 loss: -1.9926528930664062
Batch 12/64 loss: -1.830754280090332
Batch 13/64 loss: -1.7691946029663086
Batch 14/64 loss: -1.9304165840148926
Batch 15/64 loss: -1.8937087059020996
Batch 16/64 loss: -1.8703794479370117
Batch 17/64 loss: -1.7847299575805664
Batch 18/64 loss: -1.9757657051086426
Batch 19/64 loss: -1.471059799194336
Batch 20/64 loss: -1.931309700012207
Batch 21/64 loss: -2.0120372772216797
Batch 22/64 loss: -1.8691034317016602
Batch 23/64 loss: -1.381570816040039
Batch 24/64 loss: -1.524343490600586
Batch 25/64 loss: -2.0356392860412598
Batch 26/64 loss: -1.796708106994629
Batch 27/64 loss: -1.962674617767334
Batch 28/64 loss: -1.678349494934082
Batch 29/64 loss: -1.8356890678405762
Batch 30/64 loss: -2.0094432830810547
Batch 31/64 loss: -1.9481620788574219
Batch 32/64 loss: -1.733271598815918
Batch 33/64 loss: -1.949721336364746
Batch 34/64 loss: -1.7563066482543945
Batch 35/64 loss: -1.7721858024597168
Batch 36/64 loss: -1.4746813774108887
Batch 37/64 loss: -1.903428077697754
Batch 38/64 loss: -1.5484752655029297
Batch 39/64 loss: -2.0953760147094727
Batch 40/64 loss: -1.873417854309082
Batch 41/64 loss: -2.1086297035217285
Batch 42/64 loss: -1.9603819847106934
Batch 43/64 loss: -1.8630752563476562
Batch 44/64 loss: -1.8666467666625977
Batch 45/64 loss: -1.7153778076171875
Batch 46/64 loss: -2.058347702026367
Batch 47/64 loss: -1.7525148391723633
Batch 48/64 loss: -1.9186468124389648
Batch 49/64 loss: -1.7987794876098633
Batch 50/64 loss: -1.8734455108642578
Batch 51/64 loss: -1.6718454360961914
Batch 52/64 loss: -1.8236045837402344
Batch 53/64 loss: -1.9002108573913574
Batch 54/64 loss: -1.0144290924072266
Batch 55/64 loss: -1.9540834426879883
Batch 56/64 loss: -1.4777441024780273
Batch 57/64 loss: -1.8479366302490234
Batch 58/64 loss: -1.9596166610717773
Batch 59/64 loss: -1.8160896301269531
Batch 60/64 loss: -1.9485864639282227
Batch 61/64 loss: -1.7484211921691895
Batch 62/64 loss: -1.9312677383422852
Batch 63/64 loss: -1.782313346862793
Batch 64/64 loss: -5.2910871505737305
Epoch 372  Train loss: -1.8520663579305012  Val loss: -1.9177477859549505
Epoch 373
-------------------------------
Batch 1/64 loss: -1.3471183776855469
Batch 2/64 loss: -1.9018449783325195
Batch 3/64 loss: -1.786736011505127
Batch 4/64 loss: -1.8864555358886719
Batch 5/64 loss: -1.7532329559326172
Batch 6/64 loss: -1.4245872497558594
Batch 7/64 loss: -1.8951005935668945
Batch 8/64 loss: -1.8937101364135742
Batch 9/64 loss: -1.8493270874023438
Batch 10/64 loss: -2.093717575073242
Batch 11/64 loss: -1.967726707458496
Batch 12/64 loss: -1.9908361434936523
Batch 13/64 loss: -1.749826431274414
Batch 14/64 loss: -1.9601521492004395
Batch 15/64 loss: -1.5896024703979492
Batch 16/64 loss: -1.709458351135254
Batch 17/64 loss: -1.8351926803588867
Batch 18/64 loss: -1.677865982055664
Batch 19/64 loss: -1.5833778381347656
Batch 20/64 loss: -1.940073013305664
Batch 21/64 loss: -1.831974983215332
Batch 22/64 loss: -1.9868865013122559
Batch 23/64 loss: -1.4736356735229492
Batch 24/64 loss: -1.675868034362793
Batch 25/64 loss: -2.0528244972229004
Batch 26/64 loss: -1.8763885498046875
Batch 27/64 loss: -1.4636640548706055
Batch 28/64 loss: -1.7147741317749023
Batch 29/64 loss: -1.9591255187988281
Batch 30/64 loss: -1.623560905456543
Batch 31/64 loss: -1.6856603622436523
Batch 32/64 loss: -2.107590675354004
Batch 33/64 loss: -1.9851179122924805
Batch 34/64 loss: -1.925705909729004
Batch 35/64 loss: -1.9234952926635742
Batch 36/64 loss: -1.8118476867675781
Batch 37/64 loss: -2.1819396018981934
Batch 38/64 loss: -1.8326082229614258
Batch 39/64 loss: -1.8389215469360352
Batch 40/64 loss: -1.492218017578125
Batch 41/64 loss: -1.877939224243164
Batch 42/64 loss: -2.0227718353271484
Batch 43/64 loss: -1.6916751861572266
Batch 44/64 loss: -1.9555597305297852
Batch 45/64 loss: -1.5085439682006836
Batch 46/64 loss: -2.0500011444091797
Batch 47/64 loss: -1.816166877746582
Batch 48/64 loss: -1.8530220985412598
Batch 49/64 loss: -1.779266357421875
Batch 50/64 loss: -1.815199851989746
Batch 51/64 loss: -1.9465432167053223
Batch 52/64 loss: -2.1470632553100586
Batch 53/64 loss: -2.074069023132324
Batch 54/64 loss: -1.8279123306274414
Batch 55/64 loss: -1.4336891174316406
Batch 56/64 loss: -1.972801685333252
Batch 57/64 loss: -1.6781730651855469
Batch 58/64 loss: -1.9067087173461914
Batch 59/64 loss: -1.851597785949707
Batch 60/64 loss: -1.8912887573242188
Batch 61/64 loss: -1.7540321350097656
Batch 62/64 loss: -1.7083778381347656
Batch 63/64 loss: -2.0603466033935547
Batch 64/64 loss: -6.065823554992676
Epoch 373  Train loss: -1.873754789315018  Val loss: -1.7654056745706146
Epoch 374
-------------------------------
Batch 1/64 loss: -2.137796401977539
Batch 2/64 loss: -1.8308677673339844
Batch 3/64 loss: -1.7329826354980469
Batch 4/64 loss: -1.717677116394043
Batch 5/64 loss: -2.0363388061523438
Batch 6/64 loss: -1.1820268630981445
Batch 7/64 loss: -2.1663827896118164
Batch 8/64 loss: -1.6221351623535156
Batch 9/64 loss: -2.0613365173339844
Batch 10/64 loss: -1.6964349746704102
Batch 11/64 loss: -1.932703971862793
Batch 12/64 loss: -2.094860553741455
Batch 13/64 loss: -2.0518441200256348
Batch 14/64 loss: -2.0034031867980957
Batch 15/64 loss: -1.9592866897583008
Batch 16/64 loss: -2.1058616638183594
Batch 17/64 loss: -1.6741142272949219
Batch 18/64 loss: -1.962552547454834
Batch 19/64 loss: -2.069380760192871
Batch 20/64 loss: -1.7997126579284668
Batch 21/64 loss: -1.797567367553711
Batch 22/64 loss: -1.7561864852905273
Batch 23/64 loss: -1.651585578918457
Batch 24/64 loss: -1.7402420043945312
Batch 25/64 loss: -1.7912235260009766
Batch 26/64 loss: -1.8450136184692383
Batch 27/64 loss: -1.7941532135009766
Batch 28/64 loss: -1.7434940338134766
Batch 29/64 loss: -1.5961885452270508
Batch 30/64 loss: -1.5486202239990234
Batch 31/64 loss: -1.5319671630859375
Batch 32/64 loss: -1.2880449295043945
Batch 33/64 loss: -1.752018928527832
Batch 34/64 loss: -1.5539216995239258
Batch 35/64 loss: -1.7879705429077148
Batch 36/64 loss: -1.9788885116577148
Batch 37/64 loss: -2.058823585510254
Batch 38/64 loss: -1.9640731811523438
Batch 39/64 loss: -1.7060985565185547
Batch 40/64 loss: -1.7742586135864258
Batch 41/64 loss: -1.6790361404418945
Batch 42/64 loss: -2.027616500854492
Batch 43/64 loss: -1.8338189125061035
Batch 44/64 loss: -1.7437725067138672
Batch 45/64 loss: -1.9999938011169434
Batch 46/64 loss: -2.1053619384765625
Batch 47/64 loss: -1.7990398406982422
Batch 48/64 loss: -1.6977882385253906
Batch 49/64 loss: -2.0234642028808594
Batch 50/64 loss: -1.9790830612182617
Batch 51/64 loss: -1.8405733108520508
Batch 52/64 loss: -1.8018465042114258
Batch 53/64 loss: -1.807389736175537
Batch 54/64 loss: -1.4625415802001953
Batch 55/64 loss: -0.8950185775756836
Batch 56/64 loss: -1.6108245849609375
Batch 57/64 loss: -1.7903404235839844
Batch 58/64 loss: -1.919877052307129
Batch 59/64 loss: -1.6329431533813477
Batch 60/64 loss: -1.9373140335083008
Batch 61/64 loss: -1.9669160842895508
Batch 62/64 loss: -1.8735828399658203
Batch 63/64 loss: -1.7816786766052246
Batch 64/64 loss: -5.869687080383301
Epoch 374  Train loss: -1.8527078703338025  Val loss: -1.9867672084533061
Epoch 375
-------------------------------
Batch 1/64 loss: -1.847691535949707
Batch 2/64 loss: -2.0670714378356934
Batch 3/64 loss: -1.9121723175048828
Batch 4/64 loss: -1.9005355834960938
Batch 5/64 loss: -1.8960375785827637
Batch 6/64 loss: -1.8740663528442383
Batch 7/64 loss: -2.020676612854004
Batch 8/64 loss: -2.1182503700256348
Batch 9/64 loss: -2.062215805053711
Batch 10/64 loss: -1.984701156616211
Batch 11/64 loss: -1.5329303741455078
Batch 12/64 loss: -1.8078432083129883
Batch 13/64 loss: -1.5924205780029297
Batch 14/64 loss: -1.9826164245605469
Batch 15/64 loss: -1.9713878631591797
Batch 16/64 loss: -1.8520374298095703
Batch 17/64 loss: -1.899118423461914
Batch 18/64 loss: -2.1348519325256348
Batch 19/64 loss: -1.835123062133789
Batch 20/64 loss: -1.8436298370361328
Batch 21/64 loss: -1.955000400543213
Batch 22/64 loss: -1.8262758255004883
Batch 23/64 loss: -1.8450860977172852
Batch 24/64 loss: -1.7412519454956055
Batch 25/64 loss: -1.5532140731811523
Batch 26/64 loss: -1.8453359603881836
Batch 27/64 loss: -2.129554271697998
Batch 28/64 loss: -1.9796628952026367
Batch 29/64 loss: -1.233201026916504
Batch 30/64 loss: -1.7305965423583984
Batch 31/64 loss: -1.8014841079711914
Batch 32/64 loss: -2.003622531890869
Batch 33/64 loss: -1.615743637084961
Batch 34/64 loss: -2.0002145767211914
Batch 35/64 loss: -1.8428497314453125
Batch 36/64 loss: -1.967944622039795
Batch 37/64 loss: -2.023223400115967
Batch 38/64 loss: -1.7294635772705078
Batch 39/64 loss: -1.8853521347045898
Batch 40/64 loss: -1.464369773864746
Batch 41/64 loss: -2.1003780364990234
Batch 42/64 loss: -1.5021677017211914
Batch 43/64 loss: -1.524557113647461
Batch 44/64 loss: -1.5628623962402344
Batch 45/64 loss: -2.0822792053222656
Batch 46/64 loss: -1.8802309036254883
Batch 47/64 loss: -2.208683967590332
Batch 48/64 loss: -1.9371976852416992
Batch 49/64 loss: -1.351755142211914
Batch 50/64 loss: -1.7837328910827637
Batch 51/64 loss: -1.713914394378662
Batch 52/64 loss: -1.980362892150879
Batch 53/64 loss: -1.8210625648498535
Batch 54/64 loss: -1.8498048782348633
Batch 55/64 loss: -1.697798728942871
Batch 56/64 loss: -1.8678960800170898
Batch 57/64 loss: -2.0646228790283203
Batch 58/64 loss: -1.9655914306640625
Batch 59/64 loss: -1.6906814575195312
Batch 60/64 loss: -1.974503517150879
Batch 61/64 loss: -1.9411954879760742
Batch 62/64 loss: -1.6735200881958008
Batch 63/64 loss: -1.659834861755371
Batch 64/64 loss: -5.9976959228515625
Epoch 375  Train loss: -1.892419313916973  Val loss: -2.0465032177692426
Epoch 376
-------------------------------
Batch 1/64 loss: -1.6711673736572266
Batch 2/64 loss: -1.9427881240844727
Batch 3/64 loss: -1.6877079010009766
Batch 4/64 loss: -1.816324234008789
Batch 5/64 loss: -1.52740478515625
Batch 6/64 loss: -2.1689252853393555
Batch 7/64 loss: -1.609375
Batch 8/64 loss: -1.6130447387695312
Batch 9/64 loss: -1.8607416152954102
Batch 10/64 loss: -1.4790287017822266
Batch 11/64 loss: -1.708174705505371
Batch 12/64 loss: -1.7388782501220703
Batch 13/64 loss: -1.5996665954589844
Batch 14/64 loss: -1.639862060546875
Batch 15/64 loss: -2.192392349243164
Batch 16/64 loss: -1.8135595321655273
Batch 17/64 loss: -1.9033145904541016
Batch 18/64 loss: -1.7262954711914062
Batch 19/64 loss: -1.889941692352295
Batch 20/64 loss: -1.923861026763916
Batch 21/64 loss: -1.7139387130737305
Batch 22/64 loss: -1.9045062065124512
Batch 23/64 loss: -2.0526857376098633
Batch 24/64 loss: -1.8670687675476074
Batch 25/64 loss: -1.9919137954711914
Batch 26/64 loss: -1.7728948593139648
Batch 27/64 loss: -1.6211137771606445
Batch 28/64 loss: -1.9574356079101562
Batch 29/64 loss: -1.7873096466064453
Batch 30/64 loss: -1.8596677780151367
Batch 31/64 loss: -1.9001359939575195
Batch 32/64 loss: -2.191805362701416
Batch 33/64 loss: -1.9459753036499023
Batch 34/64 loss: -1.6950006484985352
Batch 35/64 loss: -2.076251983642578
Batch 36/64 loss: -1.9281692504882812
Batch 37/64 loss: -1.4189224243164062
Batch 38/64 loss: -1.8097047805786133
Batch 39/64 loss: -1.7114753723144531
Batch 40/64 loss: -1.9122505187988281
Batch 41/64 loss: -1.7009773254394531
Batch 42/64 loss: -1.9392704963684082
Batch 43/64 loss: -1.889425277709961
Batch 44/64 loss: -2.0510783195495605
Batch 45/64 loss: -1.6992120742797852
Batch 46/64 loss: -1.8800983428955078
Batch 47/64 loss: -1.537923812866211
Batch 48/64 loss: -1.9886083602905273
Batch 49/64 loss: -1.7449569702148438
Batch 50/64 loss: -1.878310203552246
Batch 51/64 loss: -2.0566372871398926
Batch 52/64 loss: -1.8985834121704102
Batch 53/64 loss: -2.051982879638672
Batch 54/64 loss: -1.9128327369689941
Batch 55/64 loss: -1.5716562271118164
Batch 56/64 loss: -1.9324274063110352
Batch 57/64 loss: -1.7576074600219727
Batch 58/64 loss: -2.1157326698303223
Batch 59/64 loss: -2.0257062911987305
Batch 60/64 loss: -1.8180999755859375
Batch 61/64 loss: -1.541304588317871
Batch 62/64 loss: -2.072751522064209
Batch 63/64 loss: -1.787764549255371
Batch 64/64 loss: -5.944125175476074
Epoch 376  Train loss: -1.8814387863757565  Val loss: -2.0129099711519745
Epoch 377
-------------------------------
Batch 1/64 loss: -1.926534652709961
Batch 2/64 loss: -1.8150711059570312
Batch 3/64 loss: -1.8802270889282227
Batch 4/64 loss: -1.9092531204223633
Batch 5/64 loss: -1.7911834716796875
Batch 6/64 loss: -1.9855690002441406
Batch 7/64 loss: -1.5173540115356445
Batch 8/64 loss: -2.081742286682129
Batch 9/64 loss: -1.8928842544555664
Batch 10/64 loss: -2.0901126861572266
Batch 11/64 loss: -1.6751747131347656
Batch 12/64 loss: -1.580124855041504
Batch 13/64 loss: -2.141414165496826
Batch 14/64 loss: -2.0501928329467773
Batch 15/64 loss: -1.9470572471618652
Batch 16/64 loss: -1.9929494857788086
Batch 17/64 loss: -1.6856060028076172
Batch 18/64 loss: -1.6503605842590332
Batch 19/64 loss: -1.784834861755371
Batch 20/64 loss: -1.8080759048461914
Batch 21/64 loss: -1.8915843963623047
Batch 22/64 loss: -2.0900444984436035
Batch 23/64 loss: -1.6790695190429688
Batch 24/64 loss: -1.4354958534240723
Batch 25/64 loss: -1.893162727355957
Batch 26/64 loss: -1.7869415283203125
Batch 27/64 loss: -1.6860136985778809
Batch 28/64 loss: -1.8960704803466797
Batch 29/64 loss: -1.6625633239746094
Batch 30/64 loss: -1.9862918853759766
Batch 31/64 loss: -2.037321090698242
Batch 32/64 loss: -1.7846546173095703
Batch 33/64 loss: -2.0102391242980957
Batch 34/64 loss: -1.4263248443603516
Batch 35/64 loss: -1.906564712524414
Batch 36/64 loss: -1.7856664657592773
Batch 37/64 loss: -1.6570520401000977
Batch 38/64 loss: -1.5156841278076172
Batch 39/64 loss: -1.6228399276733398
Batch 40/64 loss: -1.9640655517578125
Batch 41/64 loss: -1.9692907333374023
Batch 42/64 loss: -1.440847396850586
Batch 43/64 loss: -1.2250146865844727
Batch 44/64 loss: -1.9793791770935059
Batch 45/64 loss: -1.878006935119629
Batch 46/64 loss: -2.0866003036499023
Batch 47/64 loss: -1.6140379905700684
Batch 48/64 loss: -1.7801055908203125
Batch 49/64 loss: -2.146389961242676
Batch 50/64 loss: -1.6127738952636719
Batch 51/64 loss: -1.7461013793945312
Batch 52/64 loss: -1.6708364486694336
Batch 53/64 loss: -1.5376310348510742
Batch 54/64 loss: -1.5350608825683594
Batch 55/64 loss: -2.0015172958374023
Batch 56/64 loss: -1.7036733627319336
Batch 57/64 loss: -1.6320781707763672
Batch 58/64 loss: -1.4027938842773438
Batch 59/64 loss: -2.0418386459350586
Batch 60/64 loss: -1.8590335845947266
Batch 61/64 loss: -1.7333736419677734
Batch 62/64 loss: -1.5363731384277344
Batch 63/64 loss: -1.3834943771362305
Batch 64/64 loss: -5.8386149406433105
Epoch 377  Train loss: -1.8324484151952407  Val loss: -1.9269183443993638
Epoch 378
-------------------------------
Batch 1/64 loss: -1.6038074493408203
Batch 2/64 loss: -1.6581592559814453
Batch 3/64 loss: -1.8567280769348145
Batch 4/64 loss: -1.000152587890625
Batch 5/64 loss: -1.7681617736816406
Batch 6/64 loss: -1.8151607513427734
Batch 7/64 loss: -1.5669240951538086
Batch 8/64 loss: -1.7051515579223633
Batch 9/64 loss: -1.7536301612854004
Batch 10/64 loss: -1.9017753601074219
Batch 11/64 loss: -1.6654386520385742
Batch 12/64 loss: -1.8825454711914062
Batch 13/64 loss: -1.6383748054504395
Batch 14/64 loss: -2.1566572189331055
Batch 15/64 loss: -1.7492308616638184
Batch 16/64 loss: -1.7811756134033203
Batch 17/64 loss: -1.8830127716064453
Batch 18/64 loss: -1.2884807586669922
Batch 19/64 loss: -2.04547119140625
Batch 20/64 loss: -2.0004396438598633
Batch 21/64 loss: -1.981959342956543
Batch 22/64 loss: -2.1804051399230957
Batch 23/64 loss: -1.8250188827514648
Batch 24/64 loss: -1.6756925582885742
Batch 25/64 loss: -1.9199533462524414
Batch 26/64 loss: -1.876032829284668
Batch 27/64 loss: -1.6116046905517578
Batch 28/64 loss: -2.0913686752319336
Batch 29/64 loss: -1.7993087768554688
Batch 30/64 loss: -1.814661979675293
Batch 31/64 loss: -1.7125673294067383
Batch 32/64 loss: -2.0033016204833984
Batch 33/64 loss: -2.1165170669555664
Batch 34/64 loss: -2.035153388977051
Batch 35/64 loss: -1.8727846145629883
Batch 36/64 loss: -1.6107149124145508
Batch 37/64 loss: -1.5103473663330078
Batch 38/64 loss: -1.7296571731567383
Batch 39/64 loss: -1.8331375122070312
Batch 40/64 loss: -1.6943120956420898
Batch 41/64 loss: -1.2886343002319336
Batch 42/64 loss: -1.7027549743652344
Batch 43/64 loss: -1.560542106628418
Batch 44/64 loss: -2.07778263092041
Batch 45/64 loss: -1.4487848281860352
Batch 46/64 loss: -1.286233901977539
Batch 47/64 loss: -1.810361385345459
Batch 48/64 loss: -1.463818073272705
Batch 49/64 loss: -1.9188032150268555
Batch 50/64 loss: -1.7977218627929688
Batch 51/64 loss: -1.913543701171875
Batch 52/64 loss: -1.9754400253295898
Batch 53/64 loss: -1.8260126113891602
Batch 54/64 loss: -1.8879384994506836
Batch 55/64 loss: -1.7984704971313477
Batch 56/64 loss: -1.8400039672851562
Batch 57/64 loss: -1.9518141746520996
Batch 58/64 loss: -1.538640022277832
Batch 59/64 loss: -1.8723020553588867
Batch 60/64 loss: -1.724893569946289
Batch 61/64 loss: -1.835927963256836
Batch 62/64 loss: -1.4981098175048828
Batch 63/64 loss: -1.7251558303833008
Batch 64/64 loss: -5.6677045822143555
Epoch 378  Train loss: -1.8134815029069489  Val loss: -1.85899805285267
Epoch 379
-------------------------------
Batch 1/64 loss: -1.8748445510864258
Batch 2/64 loss: -1.766158103942871
Batch 3/64 loss: -1.5790681838989258
Batch 4/64 loss: -1.9438657760620117
Batch 5/64 loss: -2.0847225189208984
Batch 6/64 loss: -2.0162391662597656
Batch 7/64 loss: -1.5383358001708984
Batch 8/64 loss: -1.9964866638183594
Batch 9/64 loss: -1.5046472549438477
Batch 10/64 loss: -1.9692473411560059
Batch 11/64 loss: -1.5267162322998047
Batch 12/64 loss: -1.9414939880371094
Batch 13/64 loss: -1.1225910186767578
Batch 14/64 loss: -2.0808115005493164
Batch 15/64 loss: -1.7669095993041992
Batch 16/64 loss: -1.8679208755493164
Batch 17/64 loss: -1.9338197708129883
Batch 18/64 loss: -2.0168724060058594
Batch 19/64 loss: -1.829472541809082
Batch 20/64 loss: -1.7471227645874023
Batch 21/64 loss: -2.1057910919189453
Batch 22/64 loss: -2.1849522590637207
Batch 23/64 loss: -2.02241849899292
Batch 24/64 loss: -1.3926801681518555
Batch 25/64 loss: -2.0469322204589844
Batch 26/64 loss: -1.7675113677978516
Batch 27/64 loss: -1.7435846328735352
Batch 28/64 loss: -1.8054871559143066
Batch 29/64 loss: -1.3129940032958984
Batch 30/64 loss: -1.8489398956298828
Batch 31/64 loss: -1.7617073059082031
Batch 32/64 loss: -1.8290348052978516
Batch 33/64 loss: -1.4503726959228516
Batch 34/64 loss: -1.9526333808898926
Batch 35/64 loss: -1.7512688636779785
Batch 36/64 loss: -2.046339988708496
Batch 37/64 loss: -1.9698405265808105
Batch 38/64 loss: -1.6124267578125
Batch 39/64 loss: -1.8393478393554688
Batch 40/64 loss: -2.0766286849975586
Batch 41/64 loss: -1.6365251541137695
Batch 42/64 loss: -1.913050651550293
Batch 43/64 loss: -1.6448259353637695
Batch 44/64 loss: -1.9208340644836426
Batch 45/64 loss: -1.9112496376037598
Batch 46/64 loss: -1.869607925415039
Batch 47/64 loss: -1.9291768074035645
Batch 48/64 loss: -1.7454719543457031
Batch 49/64 loss: -2.0129804611206055
Batch 50/64 loss: -1.952073097229004
Batch 51/64 loss: -1.2518930435180664
Batch 52/64 loss: -1.9764227867126465
Batch 53/64 loss: -1.831974983215332
Batch 54/64 loss: -1.9089207649230957
Batch 55/64 loss: -1.6207542419433594
Batch 56/64 loss: -1.6997709274291992
Batch 57/64 loss: -2.0453782081604004
Batch 58/64 loss: -1.9302959442138672
Batch 59/64 loss: -1.1353139877319336
Batch 60/64 loss: -1.5977535247802734
Batch 61/64 loss: -2.0002059936523438
Batch 62/64 loss: -1.8976964950561523
Batch 63/64 loss: -1.9795055389404297
Batch 64/64 loss: -5.87783145904541
Epoch 379  Train loss: -1.8580124537150065  Val loss: -1.8740098566533774
Epoch 380
-------------------------------
Batch 1/64 loss: -1.7221870422363281
Batch 2/64 loss: -1.7446784973144531
Batch 3/64 loss: -2.140416145324707
Batch 4/64 loss: -1.2735519409179688
Batch 5/64 loss: -1.4571475982666016
Batch 6/64 loss: -1.8083305358886719
Batch 7/64 loss: -1.853714942932129
Batch 8/64 loss: -1.8649520874023438
Batch 9/64 loss: -1.940237045288086
Batch 10/64 loss: -1.3419761657714844
Batch 11/64 loss: -2.0327978134155273
Batch 12/64 loss: -2.0728564262390137
Batch 13/64 loss: -2.0792722702026367
Batch 14/64 loss: -1.5919837951660156
Batch 15/64 loss: -1.725667953491211
Batch 16/64 loss: -1.39404296875
Batch 17/64 loss: -1.9527807235717773
Batch 18/64 loss: -1.8654651641845703
Batch 19/64 loss: -1.5692577362060547
Batch 20/64 loss: -1.5340557098388672
Batch 21/64 loss: -1.903721809387207
Batch 22/64 loss: -1.7023162841796875
Batch 23/64 loss: -1.9521732330322266
Batch 24/64 loss: -1.8363008499145508
Batch 25/64 loss: -1.828516960144043
Batch 26/64 loss: -1.796616554260254
Batch 27/64 loss: -1.8310413360595703
Batch 28/64 loss: -1.8927860260009766
Batch 29/64 loss: -1.721482276916504
Batch 30/64 loss: -1.9931039810180664
Batch 31/64 loss: -2.150038719177246
Batch 32/64 loss: -1.117323875427246
Batch 33/64 loss: -1.9676647186279297
Batch 34/64 loss: -1.8642611503601074
Batch 35/64 loss: -1.9035248756408691
Batch 36/64 loss: -1.9053421020507812
Batch 37/64 loss: -1.932344913482666
Batch 38/64 loss: -1.9122447967529297
Batch 39/64 loss: -1.8231539726257324
Batch 40/64 loss: -1.8898324966430664
Batch 41/64 loss: -1.7524528503417969
Batch 42/64 loss: -2.048529624938965
Batch 43/64 loss: -1.304769515991211
Batch 44/64 loss: -1.5484609603881836
Batch 45/64 loss: -1.5907373428344727
Batch 46/64 loss: -1.7715034484863281
Batch 47/64 loss: -1.7588682174682617
Batch 48/64 loss: -1.6547460556030273
Batch 49/64 loss: -1.770634651184082
Batch 50/64 loss: -1.8116798400878906
Batch 51/64 loss: -1.9675521850585938
Batch 52/64 loss: -1.9688167572021484
Batch 53/64 loss: -1.8912858963012695
Batch 54/64 loss: -1.946131706237793
Batch 55/64 loss: -1.7398271560668945
Batch 56/64 loss: -1.7680082321166992
Batch 57/64 loss: -2.1268491744995117
Batch 58/64 loss: -1.7972908020019531
Batch 59/64 loss: -1.564774513244629
Batch 60/64 loss: -1.9040241241455078
Batch 61/64 loss: -1.5813722610473633
Batch 62/64 loss: -1.957127571105957
Batch 63/64 loss: -1.7680597305297852
Batch 64/64 loss: -5.016395568847656
Epoch 380  Train loss: -1.8297249064725989  Val loss: -2.0639088424210694
Epoch 381
-------------------------------
Batch 1/64 loss: -2.0588502883911133
Batch 2/64 loss: -1.7168960571289062
Batch 3/64 loss: -1.8339004516601562
Batch 4/64 loss: -1.9718804359436035
Batch 5/64 loss: -1.576401710510254
Batch 6/64 loss: -1.9519662857055664
Batch 7/64 loss: -2.0555734634399414
Batch 8/64 loss: -1.8730354309082031
Batch 9/64 loss: -2.0146121978759766
Batch 10/64 loss: -1.6922321319580078
Batch 11/64 loss: -1.886091709136963
Batch 12/64 loss: -1.7805843353271484
Batch 13/64 loss: -1.9426536560058594
Batch 14/64 loss: -1.4902667999267578
Batch 15/64 loss: -1.8369455337524414
Batch 16/64 loss: -1.6781911849975586
Batch 17/64 loss: -1.9008941650390625
Batch 18/64 loss: -1.7684612274169922
Batch 19/64 loss: -1.7532663345336914
Batch 20/64 loss: -1.7388010025024414
Batch 21/64 loss: -1.4582023620605469
Batch 22/64 loss: -1.6085710525512695
Batch 23/64 loss: -1.9867048263549805
Batch 24/64 loss: -1.8086271286010742
Batch 25/64 loss: -1.8333101272583008
Batch 26/64 loss: -1.7531805038452148
Batch 27/64 loss: -1.955155372619629
Batch 28/64 loss: -1.917830467224121
Batch 29/64 loss: -2.025217056274414
Batch 30/64 loss: -1.5565824508666992
Batch 31/64 loss: -1.8725042343139648
Batch 32/64 loss: -1.804037094116211
Batch 33/64 loss: -1.9864516258239746
Batch 34/64 loss: -2.114556312561035
Batch 35/64 loss: -1.8169636726379395
Batch 36/64 loss: -1.6271438598632812
Batch 37/64 loss: -2.095250129699707
Batch 38/64 loss: -1.8308439254760742
Batch 39/64 loss: -1.7728891372680664
Batch 40/64 loss: -1.915349006652832
Batch 41/64 loss: -2.1494717597961426
Batch 42/64 loss: -1.5833816528320312
Batch 43/64 loss: -1.881342887878418
Batch 44/64 loss: -2.006119728088379
Batch 45/64 loss: -1.8567886352539062
Batch 46/64 loss: -1.597529411315918
Batch 47/64 loss: -1.496164321899414
Batch 48/64 loss: -1.1869945526123047
Batch 49/64 loss: -1.9637699127197266
Batch 50/64 loss: -1.7926216125488281
Batch 51/64 loss: -1.9490337371826172
Batch 52/64 loss: -1.9531822204589844
Batch 53/64 loss: -1.8557920455932617
Batch 54/64 loss: -2.2304868698120117
Batch 55/64 loss: -1.7249560356140137
Batch 56/64 loss: -2.121762752532959
Batch 57/64 loss: -1.1710643768310547
Batch 58/64 loss: -1.7818317413330078
Batch 59/64 loss: -1.9304876327514648
Batch 60/64 loss: -1.6975479125976562
Batch 61/64 loss: -1.861527442932129
Batch 62/64 loss: -1.543217658996582
Batch 63/64 loss: -1.8831911087036133
Batch 64/64 loss: -6.169857501983643
Epoch 381  Train loss: -1.8683377864314061  Val loss: -1.9936645219416143
Epoch 382
-------------------------------
Batch 1/64 loss: -1.69805908203125
Batch 2/64 loss: -2.016923427581787
Batch 3/64 loss: -1.9289751052856445
Batch 4/64 loss: -1.5617456436157227
Batch 5/64 loss: -1.6767339706420898
Batch 6/64 loss: -1.9542951583862305
Batch 7/64 loss: -2.042677879333496
Batch 8/64 loss: -1.9783926010131836
Batch 9/64 loss: -1.4676704406738281
Batch 10/64 loss: -1.67254638671875
Batch 11/64 loss: -1.8748273849487305
Batch 12/64 loss: -1.8118095397949219
Batch 13/64 loss: -1.8699760437011719
Batch 14/64 loss: -1.89794921875
Batch 15/64 loss: -1.4316587448120117
Batch 16/64 loss: -1.8730340003967285
Batch 17/64 loss: -1.533578872680664
Batch 18/64 loss: -2.146719455718994
Batch 19/64 loss: -1.932218074798584
Batch 20/64 loss: -1.9913225173950195
Batch 21/64 loss: -2.115159511566162
Batch 22/64 loss: -2.0438899993896484
Batch 23/64 loss: -2.1777830123901367
Batch 24/64 loss: -1.4892311096191406
Batch 25/64 loss: -1.7711591720581055
Batch 26/64 loss: -1.9341621398925781
Batch 27/64 loss: -2.005192756652832
Batch 28/64 loss: -1.8232059478759766
Batch 29/64 loss: -2.017228126525879
Batch 30/64 loss: -2.0532913208007812
Batch 31/64 loss: -1.9622516632080078
Batch 32/64 loss: -1.9933719635009766
Batch 33/64 loss: -1.8088140487670898
Batch 34/64 loss: -1.9644193649291992
Batch 35/64 loss: -2.013678550720215
Batch 36/64 loss: -1.7123079299926758
Batch 37/64 loss: -1.7149887084960938
Batch 38/64 loss: -2.0007333755493164
Batch 39/64 loss: -2.0080909729003906
Batch 40/64 loss: -2.1859216690063477
Batch 41/64 loss: -1.9589223861694336
Batch 42/64 loss: -1.7887697219848633
Batch 43/64 loss: -1.9369287490844727
Batch 44/64 loss: -1.8100948333740234
Batch 45/64 loss: -2.0400118827819824
Batch 46/64 loss: -1.8947362899780273
Batch 47/64 loss: -2.029344081878662
Batch 48/64 loss: -1.7567510604858398
Batch 49/64 loss: -1.9296293258666992
Batch 50/64 loss: -1.2440156936645508
Batch 51/64 loss: -2.0393285751342773
Batch 52/64 loss: -2.062380790710449
Batch 53/64 loss: -1.65380859375
Batch 54/64 loss: -2.037877082824707
Batch 55/64 loss: -1.7171316146850586
Batch 56/64 loss: -1.9658112525939941
Batch 57/64 loss: -1.514883041381836
Batch 58/64 loss: -2.160475730895996
Batch 59/64 loss: -1.9682197570800781
Batch 60/64 loss: -1.90911865234375
Batch 61/64 loss: -1.8420648574829102
Batch 62/64 loss: -1.647679328918457
Batch 63/64 loss: -1.9711685180664062
Batch 64/64 loss: -5.769035339355469
Epoch 382  Train loss: -1.9194027171415442  Val loss: -2.0996950156090595
Epoch 383
-------------------------------
Batch 1/64 loss: -1.9443702697753906
Batch 2/64 loss: -2.041090965270996
Batch 3/64 loss: -1.7364625930786133
Batch 4/64 loss: -1.9671058654785156
Batch 5/64 loss: -2.2077856063842773
Batch 6/64 loss: -1.8660268783569336
Batch 7/64 loss: -1.82720947265625
Batch 8/64 loss: -2.0136184692382812
Batch 9/64 loss: -1.928532600402832
Batch 10/64 loss: -1.9658069610595703
Batch 11/64 loss: -1.9681425094604492
Batch 12/64 loss: -1.6446332931518555
Batch 13/64 loss: -1.7471179962158203
Batch 14/64 loss: -1.5322942733764648
Batch 15/64 loss: -1.889012336730957
Batch 16/64 loss: -2.0003557205200195
Batch 17/64 loss: -1.7302055358886719
Batch 18/64 loss: -1.5707683563232422
Batch 19/64 loss: -2.016887664794922
Batch 20/64 loss: -2.043203353881836
Batch 21/64 loss: -1.8283071517944336
Batch 22/64 loss: -1.8566884994506836
Batch 23/64 loss: -1.9700098037719727
Batch 24/64 loss: -1.7629146575927734
Batch 25/64 loss: -2.1324853897094727
Batch 26/64 loss: -2.0563879013061523
Batch 27/64 loss: -1.1446819305419922
Batch 28/64 loss: -1.6909189224243164
Batch 29/64 loss: -2.177750587463379
Batch 30/64 loss: -1.6986875534057617
Batch 31/64 loss: -2.0452356338500977
Batch 32/64 loss: -1.9940834045410156
Batch 33/64 loss: -1.855515480041504
Batch 34/64 loss: -2.123356819152832
Batch 35/64 loss: -1.9151840209960938
Batch 36/64 loss: -2.0070996284484863
Batch 37/64 loss: -2.068234443664551
Batch 38/64 loss: -1.8057632446289062
Batch 39/64 loss: -1.92962646484375
Batch 40/64 loss: -1.78367280960083
Batch 41/64 loss: -2.0008506774902344
Batch 42/64 loss: -1.7111625671386719
Batch 43/64 loss: -1.9088001251220703
Batch 44/64 loss: -2.026512622833252
Batch 45/64 loss: -1.6851396560668945
Batch 46/64 loss: -2.0240607261657715
Batch 47/64 loss: -1.693826675415039
Batch 48/64 loss: -1.769300937652588
Batch 49/64 loss: -1.9313902854919434
Batch 50/64 loss: -1.7951030731201172
Batch 51/64 loss: -1.8005337715148926
Batch 52/64 loss: -1.8508167266845703
Batch 53/64 loss: -1.947265625
Batch 54/64 loss: -1.902778148651123
Batch 55/64 loss: -1.7440204620361328
Batch 56/64 loss: -1.8293514251708984
Batch 57/64 loss: -1.9249191284179688
Batch 58/64 loss: -1.9177894592285156
Batch 59/64 loss: -1.6649036407470703
Batch 60/64 loss: -2.0654096603393555
Batch 61/64 loss: -2.0930967330932617
Batch 62/64 loss: -0.9086484909057617
Batch 63/64 loss: -1.8840627670288086
Batch 64/64 loss: -5.672182559967041
Epoch 383  Train loss: -1.9109194568559236  Val loss: -1.9576837991930776
Epoch 384
-------------------------------
Batch 1/64 loss: -1.8553838729858398
Batch 2/64 loss: -1.7744665145874023
Batch 3/64 loss: -1.9005537033081055
Batch 4/64 loss: -1.7590093612670898
Batch 5/64 loss: -1.8570632934570312
Batch 6/64 loss: -1.80877685546875
Batch 7/64 loss: -1.7869186401367188
Batch 8/64 loss: -1.9646077156066895
Batch 9/64 loss: -1.6575031280517578
Batch 10/64 loss: -1.774174690246582
Batch 11/64 loss: -1.7892513275146484
Batch 12/64 loss: -1.751042366027832
Batch 13/64 loss: -1.6196060180664062
Batch 14/64 loss: -2.0341386795043945
Batch 15/64 loss: -2.003302574157715
Batch 16/64 loss: -2.0162391662597656
Batch 17/64 loss: -1.881169319152832
Batch 18/64 loss: -1.9895715713500977
Batch 19/64 loss: -1.8479700088500977
Batch 20/64 loss: -1.8909492492675781
Batch 21/64 loss: -1.6098880767822266
Batch 22/64 loss: -2.0582027435302734
Batch 23/64 loss: -1.7549982070922852
Batch 24/64 loss: -1.851522445678711
Batch 25/64 loss: -1.7206287384033203
Batch 26/64 loss: -1.9837985038757324
Batch 27/64 loss: -1.5946550369262695
Batch 28/64 loss: -1.8801860809326172
Batch 29/64 loss: -1.926274299621582
Batch 30/64 loss: -2.08225154876709
Batch 31/64 loss: -1.5671968460083008
Batch 32/64 loss: -1.9779934883117676
Batch 33/64 loss: -2.118946075439453
Batch 34/64 loss: -1.8629512786865234
Batch 35/64 loss: -1.7612924575805664
Batch 36/64 loss: -1.9551172256469727
Batch 37/64 loss: -2.0525426864624023
Batch 38/64 loss: -1.3250579833984375
Batch 39/64 loss: -1.923680305480957
Batch 40/64 loss: -2.0207300186157227
Batch 41/64 loss: -1.484013557434082
Batch 42/64 loss: -1.9016685485839844
Batch 43/64 loss: -1.6828546524047852
Batch 44/64 loss: -1.9921131134033203
Batch 45/64 loss: -2.073910713195801
Batch 46/64 loss: -1.8757848739624023
Batch 47/64 loss: -1.9160923957824707
Batch 48/64 loss: -1.831613540649414
Batch 49/64 loss: -1.8546128273010254
Batch 50/64 loss: -1.6169767379760742
Batch 51/64 loss: -1.4584436416625977
Batch 52/64 loss: -2.0141820907592773
Batch 53/64 loss: -1.3591270446777344
Batch 54/64 loss: -2.0092735290527344
Batch 55/64 loss: -2.1164627075195312
Batch 56/64 loss: -1.639472484588623
Batch 57/64 loss: -1.837285041809082
Batch 58/64 loss: -1.9393973350524902
Batch 59/64 loss: -1.7240123748779297
Batch 60/64 loss: -2.016357898712158
Batch 61/64 loss: -1.9165573120117188
Batch 62/64 loss: -1.9867801666259766
Batch 63/64 loss: -1.779646873474121
Batch 64/64 loss: -5.700838088989258
Epoch 384  Train loss: -1.886931453031652  Val loss: -1.9361304712459393
Epoch 385
-------------------------------
Batch 1/64 loss: -1.9468193054199219
Batch 2/64 loss: -1.8136920928955078
Batch 3/64 loss: -1.6937456130981445
Batch 4/64 loss: -1.8081235885620117
Batch 5/64 loss: -1.8255815505981445
Batch 6/64 loss: -2.0986127853393555
Batch 7/64 loss: -1.7397756576538086
Batch 8/64 loss: -1.8062901496887207
Batch 9/64 loss: -1.695481300354004
Batch 10/64 loss: -1.7045421600341797
Batch 11/64 loss: -2.0714855194091797
Batch 12/64 loss: -2.076716899871826
Batch 13/64 loss: -1.598250389099121
Batch 14/64 loss: -1.9053716659545898
Batch 15/64 loss: -2.083950996398926
Batch 16/64 loss: -1.7194499969482422
Batch 17/64 loss: -1.2521467208862305
Batch 18/64 loss: -1.5127983093261719
Batch 19/64 loss: -1.648848533630371
Batch 20/64 loss: -2.217169761657715
Batch 21/64 loss: -1.3750057220458984
Batch 22/64 loss: -1.6750297546386719
Batch 23/64 loss: -1.5647296905517578
Batch 24/64 loss: -1.7467517852783203
Batch 25/64 loss: -1.832789421081543
Batch 26/64 loss: -1.8972978591918945
Batch 27/64 loss: -1.768326759338379
Batch 28/64 loss: -1.7565622329711914
Batch 29/64 loss: -1.8737058639526367
Batch 30/64 loss: -1.842331886291504
Batch 31/64 loss: -2.0630431175231934
Batch 32/64 loss: -1.904496192932129
Batch 33/64 loss: -1.480708122253418
Batch 34/64 loss: -2.064790725708008
Batch 35/64 loss: -1.7015628814697266
Batch 36/64 loss: -1.9551687240600586
Batch 37/64 loss: -1.4812841415405273
Batch 38/64 loss: -2.1035513877868652
Batch 39/64 loss: -1.3818578720092773
Batch 40/64 loss: -1.9327125549316406
Batch 41/64 loss: -1.4483566284179688
Batch 42/64 loss: -1.9390206336975098
Batch 43/64 loss: -1.848428726196289
Batch 44/64 loss: -1.4538068771362305
Batch 45/64 loss: -2.0354700088500977
Batch 46/64 loss: -1.954798698425293
Batch 47/64 loss: -1.8239364624023438
Batch 48/64 loss: -1.4765634536743164
Batch 49/64 loss: -1.618067741394043
Batch 50/64 loss: -1.7268562316894531
Batch 51/64 loss: -1.9054594039916992
Batch 52/64 loss: -2.135374069213867
Batch 53/64 loss: -1.9938220977783203
Batch 54/64 loss: -1.9891047477722168
Batch 55/64 loss: -1.6831636428833008
Batch 56/64 loss: -2.1498565673828125
Batch 57/64 loss: -1.3871335983276367
Batch 58/64 loss: -2.037234306335449
Batch 59/64 loss: -1.9716310501098633
Batch 60/64 loss: -1.925879955291748
Batch 61/64 loss: -1.9692840576171875
Batch 62/64 loss: -1.545731544494629
Batch 63/64 loss: -1.9007396697998047
Batch 64/64 loss: -5.293486595153809
Epoch 385  Train loss: -1.8433003107706705  Val loss: -1.9021696241450883
Epoch 386
-------------------------------
Batch 1/64 loss: -1.9165005683898926
Batch 2/64 loss: -1.8351531028747559
Batch 3/64 loss: -1.8852825164794922
Batch 4/64 loss: -1.8209495544433594
Batch 5/64 loss: -1.8212718963623047
Batch 6/64 loss: -1.7780542373657227
Batch 7/64 loss: -1.7743043899536133
Batch 8/64 loss: -1.9888510704040527
Batch 9/64 loss: -1.8855724334716797
Batch 10/64 loss: -1.997633934020996
Batch 11/64 loss: -1.8372974395751953
Batch 12/64 loss: -2.080885410308838
Batch 13/64 loss: -1.589639663696289
Batch 14/64 loss: -1.6318788528442383
Batch 15/64 loss: -1.7528948783874512
Batch 16/64 loss: -1.9257049560546875
Batch 17/64 loss: -2.0427942276000977
Batch 18/64 loss: -2.077794075012207
Batch 19/64 loss: -1.7831125259399414
Batch 20/64 loss: -2.015254020690918
Batch 21/64 loss: -2.072786331176758
Batch 22/64 loss: -2.149272918701172
Batch 23/64 loss: -1.600691795349121
Batch 24/64 loss: -1.7027082443237305
Batch 25/64 loss: -1.7948598861694336
Batch 26/64 loss: -2.0081324577331543
Batch 27/64 loss: -1.9893646240234375
Batch 28/64 loss: -1.8235650062561035
Batch 29/64 loss: -2.0977888107299805
Batch 30/64 loss: -1.8543357849121094
Batch 31/64 loss: -1.6771697998046875
Batch 32/64 loss: -2.0345611572265625
Batch 33/64 loss: -1.2962303161621094
Batch 34/64 loss: -1.3837080001831055
Batch 35/64 loss: -1.6557979583740234
Batch 36/64 loss: -1.8123588562011719
Batch 37/64 loss: -1.6395273208618164
Batch 38/64 loss: -1.8619790077209473
Batch 39/64 loss: -1.9915046691894531
Batch 40/64 loss: -1.8025178909301758
Batch 41/64 loss: -1.5698614120483398
Batch 42/64 loss: -1.4665565490722656
Batch 43/64 loss: -1.8344011306762695
Batch 44/64 loss: -1.8451166152954102
Batch 45/64 loss: -2.0368471145629883
Batch 46/64 loss: -1.4923324584960938
Batch 47/64 loss: -1.6390695571899414
Batch 48/64 loss: -1.8914175033569336
Batch 49/64 loss: -1.6699028015136719
Batch 50/64 loss: -1.3921852111816406
Batch 51/64 loss: -1.9818401336669922
Batch 52/64 loss: -1.8759565353393555
Batch 53/64 loss: -1.7085752487182617
Batch 54/64 loss: -1.5764970779418945
Batch 55/64 loss: -1.8414382934570312
Batch 56/64 loss: -1.593968391418457
Batch 57/64 loss: -1.775862693786621
Batch 58/64 loss: -1.728555679321289
Batch 59/64 loss: -1.8990678787231445
Batch 60/64 loss: -1.6375350952148438
Batch 61/64 loss: -1.7883672714233398
Batch 62/64 loss: -2.06227445602417
Batch 63/64 loss: -1.7003049850463867
Batch 64/64 loss: -6.156648635864258
Epoch 386  Train loss: -1.8559233123180914  Val loss: -2.069634873432802
Epoch 387
-------------------------------
Batch 1/64 loss: -1.803400993347168
Batch 2/64 loss: -1.9979491233825684
Batch 3/64 loss: -1.851294994354248
Batch 4/64 loss: -1.8066043853759766
Batch 5/64 loss: -1.7644453048706055
Batch 6/64 loss: -1.932518482208252
Batch 7/64 loss: -1.9129400253295898
Batch 8/64 loss: -2.018616199493408
Batch 9/64 loss: -1.4214229583740234
Batch 10/64 loss: -1.6656084060668945
Batch 11/64 loss: -1.8568940162658691
Batch 12/64 loss: -1.7461442947387695
Batch 13/64 loss: -2.0861196517944336
Batch 14/64 loss: -2.0713582038879395
Batch 15/64 loss: -2.0012922286987305
Batch 16/64 loss: -1.8584508895874023
Batch 17/64 loss: -2.1105475425720215
Batch 18/64 loss: -1.99338960647583
Batch 19/64 loss: -1.5856075286865234
Batch 20/64 loss: -1.8244857788085938
Batch 21/64 loss: -1.621973991394043
Batch 22/64 loss: -1.9160423278808594
Batch 23/64 loss: -1.7755389213562012
Batch 24/64 loss: -1.642888069152832
Batch 25/64 loss: -1.8825302124023438
Batch 26/64 loss: -1.8945846557617188
Batch 27/64 loss: -1.9360947608947754
Batch 28/64 loss: -1.910090446472168
Batch 29/64 loss: -1.8665862083435059
Batch 30/64 loss: -1.8869657516479492
Batch 31/64 loss: -1.6054353713989258
Batch 32/64 loss: -1.955495834350586
Batch 33/64 loss: -2.222507953643799
Batch 34/64 loss: -1.4365501403808594
Batch 35/64 loss: -1.805124282836914
Batch 36/64 loss: -1.65045166015625
Batch 37/64 loss: -1.917740821838379
Batch 38/64 loss: -1.94630765914917
Batch 39/64 loss: -2.015972137451172
Batch 40/64 loss: -1.7342357635498047
Batch 41/64 loss: -1.6551189422607422
Batch 42/64 loss: -1.9486007690429688
Batch 43/64 loss: -1.8839192390441895
Batch 44/64 loss: -1.9423770904541016
Batch 45/64 loss: -1.791452407836914
Batch 46/64 loss: -1.5134639739990234
Batch 47/64 loss: -2.019759178161621
Batch 48/64 loss: -1.6279220581054688
Batch 49/64 loss: -1.930694580078125
Batch 50/64 loss: -1.9389219284057617
Batch 51/64 loss: -1.7166881561279297
Batch 52/64 loss: -1.7245492935180664
Batch 53/64 loss: -1.853456974029541
Batch 54/64 loss: -1.7900395393371582
Batch 55/64 loss: -1.6748485565185547
Batch 56/64 loss: -1.397383689880371
Batch 57/64 loss: -1.8197078704833984
Batch 58/64 loss: -1.743032455444336
Batch 59/64 loss: -1.9803647994995117
Batch 60/64 loss: -1.9288663864135742
Batch 61/64 loss: -2.1421008110046387
Batch 62/64 loss: -2.0432567596435547
Batch 63/64 loss: -1.7908477783203125
Batch 64/64 loss: -5.222070693969727
Epoch 387  Train loss: -1.8777432759602866  Val loss: -2.00189628469985
Epoch 388
-------------------------------
Batch 1/64 loss: -1.0190362930297852
Batch 2/64 loss: -1.9695110321044922
Batch 3/64 loss: -1.5421791076660156
Batch 4/64 loss: -1.9670729637145996
Batch 5/64 loss: -1.8446321487426758
Batch 6/64 loss: -1.7163591384887695
Batch 7/64 loss: -2.1878881454467773
Batch 8/64 loss: -1.8114118576049805
Batch 9/64 loss: -1.9591355323791504
Batch 10/64 loss: -2.0367698669433594
Batch 11/64 loss: -1.575850486755371
Batch 12/64 loss: -1.8811769485473633
Batch 13/64 loss: -1.9377870559692383
Batch 14/64 loss: -1.5493688583374023
Batch 15/64 loss: -1.526127815246582
Batch 16/64 loss: -1.8560233116149902
Batch 17/64 loss: -1.5812568664550781
Batch 18/64 loss: -2.045322895050049
Batch 19/64 loss: -1.9120674133300781
Batch 20/64 loss: -2.0069379806518555
Batch 21/64 loss: -1.4398832321166992
Batch 22/64 loss: -1.8235855102539062
Batch 23/64 loss: -1.8646745681762695
Batch 24/64 loss: -1.7768669128417969
Batch 25/64 loss: -2.111243724822998
Batch 26/64 loss: -1.7176704406738281
Batch 27/64 loss: -1.8844819068908691
Batch 28/64 loss: -1.4924840927124023
Batch 29/64 loss: -1.9586081504821777
Batch 30/64 loss: -1.8885693550109863
Batch 31/64 loss: -1.8518595695495605
Batch 32/64 loss: -2.0626349449157715
Batch 33/64 loss: -2.0604352951049805
Batch 34/64 loss: -1.9854202270507812
Batch 35/64 loss: -1.9575128555297852
Batch 36/64 loss: -1.9692397117614746
Batch 37/64 loss: -1.6337852478027344
Batch 38/64 loss: -2.137662887573242
Batch 39/64 loss: -2.044936180114746
Batch 40/64 loss: -1.9966373443603516
Batch 41/64 loss: -1.8921241760253906
Batch 42/64 loss: -1.9148430824279785
Batch 43/64 loss: -1.909529209136963
Batch 44/64 loss: -1.9738593101501465
Batch 45/64 loss: -2.030160427093506
Batch 46/64 loss: -1.583822250366211
Batch 47/64 loss: -1.839944839477539
Batch 48/64 loss: -1.8967561721801758
Batch 49/64 loss: -1.6437559127807617
Batch 50/64 loss: -1.8606786727905273
Batch 51/64 loss: -1.6831378936767578
Batch 52/64 loss: -1.4827041625976562
Batch 53/64 loss: -1.7747564315795898
Batch 54/64 loss: -1.9385619163513184
Batch 55/64 loss: -2.0962352752685547
Batch 56/64 loss: -1.9617929458618164
Batch 57/64 loss: -2.1395297050476074
Batch 58/64 loss: -1.7044353485107422
Batch 59/64 loss: -1.8276844024658203
Batch 60/64 loss: -1.8758563995361328
Batch 61/64 loss: -2.0917325019836426
Batch 62/64 loss: -2.185818672180176
Batch 63/64 loss: -1.6913700103759766
Batch 64/64 loss: -6.192938327789307
Epoch 388  Train loss: -1.9016141386593088  Val loss: -2.12388663275545
Saving best model, epoch: 388
Epoch 389
-------------------------------
Batch 1/64 loss: -1.8197345733642578
Batch 2/64 loss: -1.788090705871582
Batch 3/64 loss: -2.115233898162842
Batch 4/64 loss: -1.661102294921875
Batch 5/64 loss: -0.7311067581176758
Batch 6/64 loss: -1.6214351654052734
Batch 7/64 loss: -1.8302536010742188
Batch 8/64 loss: -1.9975309371948242
Batch 9/64 loss: -1.9185800552368164
Batch 10/64 loss: -2.1433863639831543
Batch 11/64 loss: -1.870687484741211
Batch 12/64 loss: -2.0931806564331055
Batch 13/64 loss: -1.7558555603027344
Batch 14/64 loss: -1.9261178970336914
Batch 15/64 loss: -2.019963264465332
Batch 16/64 loss: -1.8769731521606445
Batch 17/64 loss: -1.7741594314575195
Batch 18/64 loss: -2.050718307495117
Batch 19/64 loss: -1.9624137878417969
Batch 20/64 loss: -1.85247802734375
Batch 21/64 loss: -1.7908015251159668
Batch 22/64 loss: -1.8197097778320312
Batch 23/64 loss: -1.7344112396240234
Batch 24/64 loss: -1.9792356491088867
Batch 25/64 loss: -2.0047121047973633
Batch 26/64 loss: -1.8482098579406738
Batch 27/64 loss: -1.9432411193847656
Batch 28/64 loss: -2.069200038909912
Batch 29/64 loss: -1.7252683639526367
Batch 30/64 loss: -2.0210928916931152
Batch 31/64 loss: -1.868021011352539
Batch 32/64 loss: -2.0204195976257324
Batch 33/64 loss: -1.9090900421142578
Batch 34/64 loss: -2.1662864685058594
Batch 35/64 loss: -1.7637853622436523
Batch 36/64 loss: -2.162813186645508
Batch 37/64 loss: -1.7013130187988281
Batch 38/64 loss: -1.8008556365966797
Batch 39/64 loss: -1.4807252883911133
Batch 40/64 loss: -2.0166096687316895
Batch 41/64 loss: -2.001399040222168
Batch 42/64 loss: -2.0481114387512207
Batch 43/64 loss: -2.0158467292785645
Batch 44/64 loss: -1.7006464004516602
Batch 45/64 loss: -1.7978973388671875
Batch 46/64 loss: -1.6780147552490234
Batch 47/64 loss: -1.7878079414367676
Batch 48/64 loss: -1.7636961936950684
Batch 49/64 loss: -1.8884696960449219
Batch 50/64 loss: -1.7453432083129883
Batch 51/64 loss: -1.8549551963806152
Batch 52/64 loss: -1.927830696105957
Batch 53/64 loss: -1.9657011032104492
Batch 54/64 loss: -2.060635566711426
Batch 55/64 loss: -2.0019593238830566
Batch 56/64 loss: -1.9680914878845215
Batch 57/64 loss: -1.826817512512207
Batch 58/64 loss: -1.781656265258789
Batch 59/64 loss: -1.8669767379760742
Batch 60/64 loss: -1.8638010025024414
Batch 61/64 loss: -1.4850540161132812
Batch 62/64 loss: -1.9215993881225586
Batch 63/64 loss: -1.9048967361450195
Batch 64/64 loss: -5.61569356918335
Epoch 389  Train loss: -1.9090789290035473  Val loss: -2.083168095329783
Epoch 390
-------------------------------
Batch 1/64 loss: -2.2402052879333496
Batch 2/64 loss: -1.6905755996704102
Batch 3/64 loss: -1.959343433380127
Batch 4/64 loss: -1.8237791061401367
Batch 5/64 loss: -1.6996092796325684
Batch 6/64 loss: -2.125570774078369
Batch 7/64 loss: -1.8496026992797852
Batch 8/64 loss: -1.7954988479614258
Batch 9/64 loss: -1.84783935546875
Batch 10/64 loss: -1.8561897277832031
Batch 11/64 loss: -1.6071701049804688
Batch 12/64 loss: -1.9379901885986328
Batch 13/64 loss: -1.5751152038574219
Batch 14/64 loss: -1.961596965789795
Batch 15/64 loss: -1.3151369094848633
Batch 16/64 loss: -1.533024787902832
Batch 17/64 loss: -1.7590999603271484
Batch 18/64 loss: -1.957956314086914
Batch 19/64 loss: -1.9564909934997559
Batch 20/64 loss: -1.9222803115844727
Batch 21/64 loss: -1.9568195343017578
Batch 22/64 loss: -1.7371501922607422
Batch 23/64 loss: -1.7355937957763672
Batch 24/64 loss: -1.9569101333618164
Batch 25/64 loss: -1.9627366065979004
Batch 26/64 loss: -1.7605504989624023
Batch 27/64 loss: -1.7842531204223633
Batch 28/64 loss: -1.9330310821533203
Batch 29/64 loss: -1.7627935409545898
Batch 30/64 loss: -2.0107545852661133
Batch 31/64 loss: -1.867401123046875
Batch 32/64 loss: -1.683537483215332
Batch 33/64 loss: -1.8625965118408203
Batch 34/64 loss: -1.662698745727539
Batch 35/64 loss: -1.6754951477050781
Batch 36/64 loss: -1.9989228248596191
Batch 37/64 loss: -1.6622071266174316
Batch 38/64 loss: -2.231614112854004
Batch 39/64 loss: -1.9294614791870117
Batch 40/64 loss: -2.084639549255371
Batch 41/64 loss: -1.4439754486083984
Batch 42/64 loss: -2.0629806518554688
Batch 43/64 loss: -1.9031248092651367
Batch 44/64 loss: -2.0585241317749023
Batch 45/64 loss: -1.8707475662231445
Batch 46/64 loss: -2.0477023124694824
Batch 47/64 loss: -2.0467305183410645
Batch 48/64 loss: -2.0184106826782227
Batch 49/64 loss: -1.5552082061767578
Batch 50/64 loss: -1.7346858978271484
Batch 51/64 loss: -1.9768877029418945
Batch 52/64 loss: -2.1296443939208984
Batch 53/64 loss: -2.018329620361328
Batch 54/64 loss: -1.5931129455566406
Batch 55/64 loss: -2.1522951126098633
Batch 56/64 loss: -1.9531946182250977
Batch 57/64 loss: -2.044428825378418
Batch 58/64 loss: -1.8830013275146484
Batch 59/64 loss: -2.056509017944336
Batch 60/64 loss: -1.6346111297607422
Batch 61/64 loss: -1.7252864837646484
Batch 62/64 loss: -1.514113426208496
Batch 63/64 loss: -1.0601816177368164
Batch 64/64 loss: -5.82404899597168
Epoch 390  Train loss: -1.8905877057243796  Val loss: -2.0472476867466036
Epoch 391
-------------------------------
Batch 1/64 loss: -2.032464027404785
Batch 2/64 loss: -1.9880199432373047
Batch 3/64 loss: -1.6210699081420898
Batch 4/64 loss: -1.9385480880737305
Batch 5/64 loss: -1.9584808349609375
Batch 6/64 loss: -1.6259374618530273
Batch 7/64 loss: -1.743246078491211
Batch 8/64 loss: -1.6738719940185547
Batch 9/64 loss: -1.8427009582519531
Batch 10/64 loss: -1.9277715682983398
Batch 11/64 loss: -1.8882026672363281
Batch 12/64 loss: -1.8637380599975586
Batch 13/64 loss: -2.0404772758483887
Batch 14/64 loss: -1.922189712524414
Batch 15/64 loss: -1.866621971130371
Batch 16/64 loss: -1.7868876457214355
Batch 17/64 loss: -2.03572940826416
Batch 18/64 loss: -1.8648138046264648
Batch 19/64 loss: -1.6925640106201172
Batch 20/64 loss: -2.0159406661987305
Batch 21/64 loss: -1.7688698768615723
Batch 22/64 loss: -1.9330873489379883
Batch 23/64 loss: -1.3464040756225586
Batch 24/64 loss: -2.046072483062744
Batch 25/64 loss: -2.227142333984375
Batch 26/64 loss: -1.8214540481567383
Batch 27/64 loss: -2.052975654602051
Batch 28/64 loss: -2.0273585319519043
Batch 29/64 loss: -2.1064400672912598
Batch 30/64 loss: -2.016798973083496
Batch 31/64 loss: -1.772719383239746
Batch 32/64 loss: -2.159176826477051
Batch 33/64 loss: -1.8932790756225586
Batch 34/64 loss: -1.9845547676086426
Batch 35/64 loss: -1.8354458808898926
Batch 36/64 loss: -1.8662662506103516
Batch 37/64 loss: -1.854135513305664
Batch 38/64 loss: -1.6855497360229492
Batch 39/64 loss: -1.8191394805908203
Batch 40/64 loss: -1.7087969779968262
Batch 41/64 loss: -2.0084428787231445
Batch 42/64 loss: -1.8713693618774414
Batch 43/64 loss: -1.9543752670288086
Batch 44/64 loss: -1.8994932174682617
Batch 45/64 loss: -1.732686996459961
Batch 46/64 loss: -1.4155569076538086
Batch 47/64 loss: -1.9124135971069336
Batch 48/64 loss: -1.8502330780029297
Batch 49/64 loss: -1.953786849975586
Batch 50/64 loss: -1.2216167449951172
Batch 51/64 loss: -1.8268709182739258
Batch 52/64 loss: -2.0672101974487305
Batch 53/64 loss: -1.824009895324707
Batch 54/64 loss: -1.9059858322143555
Batch 55/64 loss: -1.9482922554016113
Batch 56/64 loss: -1.7805633544921875
Batch 57/64 loss: -1.8300552368164062
Batch 58/64 loss: -1.8354434967041016
Batch 59/64 loss: -1.9382572174072266
Batch 60/64 loss: -1.4844837188720703
Batch 61/64 loss: -1.6964921951293945
Batch 62/64 loss: -1.621652603149414
Batch 63/64 loss: -2.185070514678955
Batch 64/64 loss: -5.885642051696777
Epoch 391  Train loss: -1.9048397999183804  Val loss: -2.016813127445601
Epoch 392
-------------------------------
Batch 1/64 loss: -1.8605546951293945
Batch 2/64 loss: -2.128291130065918
Batch 3/64 loss: -1.9584598541259766
Batch 4/64 loss: -1.6136131286621094
Batch 5/64 loss: -1.9772229194641113
Batch 6/64 loss: -1.9973735809326172
Batch 7/64 loss: -1.8028512001037598
Batch 8/64 loss: -1.5111846923828125
Batch 9/64 loss: -1.5343379974365234
Batch 10/64 loss: -2.0657496452331543
Batch 11/64 loss: -1.7889742851257324
Batch 12/64 loss: -1.5421314239501953
Batch 13/64 loss: -1.976069450378418
Batch 14/64 loss: -1.966379165649414
Batch 15/64 loss: -1.9770240783691406
Batch 16/64 loss: -1.529707908630371
Batch 17/64 loss: -1.5446882247924805
Batch 18/64 loss: -1.7729191780090332
Batch 19/64 loss: -1.658365249633789
Batch 20/64 loss: -1.9013652801513672
Batch 21/64 loss: -2.0963854789733887
Batch 22/64 loss: -1.8089103698730469
Batch 23/64 loss: -2.116856098175049
Batch 24/64 loss: -1.7676372528076172
Batch 25/64 loss: -1.9516549110412598
Batch 26/64 loss: -2.0639309883117676
Batch 27/64 loss: -1.69024658203125
Batch 28/64 loss: -1.8230338096618652
Batch 29/64 loss: -2.082613945007324
Batch 30/64 loss: -2.1743998527526855
Batch 31/64 loss: -1.7538318634033203
Batch 32/64 loss: -1.7215003967285156
Batch 33/64 loss: -1.7488040924072266
Batch 34/64 loss: -2.123988151550293
Batch 35/64 loss: -1.8880987167358398
Batch 36/64 loss: -1.7031364440917969
Batch 37/64 loss: -1.5900888442993164
Batch 38/64 loss: -1.9991416931152344
Batch 39/64 loss: -1.9078359603881836
Batch 40/64 loss: -2.050142288208008
Batch 41/64 loss: -1.777848243713379
Batch 42/64 loss: -1.6273088455200195
Batch 43/64 loss: -1.8791866302490234
Batch 44/64 loss: -1.8811578750610352
Batch 45/64 loss: -1.8627080917358398
Batch 46/64 loss: -2.1275434494018555
Batch 47/64 loss: -1.6740169525146484
Batch 48/64 loss: -2.0550355911254883
Batch 49/64 loss: -2.1853160858154297
Batch 50/64 loss: -2.053129196166992
Batch 51/64 loss: -1.9142913818359375
Batch 52/64 loss: -1.8975648880004883
Batch 53/64 loss: -1.846144676208496
Batch 54/64 loss: -1.735921859741211
Batch 55/64 loss: -1.497786521911621
Batch 56/64 loss: -2.0375852584838867
Batch 57/64 loss: -1.5981178283691406
Batch 58/64 loss: -1.311014175415039
Batch 59/64 loss: -1.270237922668457
Batch 60/64 loss: -1.9130544662475586
Batch 61/64 loss: -1.6709222793579102
Batch 62/64 loss: -1.8151016235351562
Batch 63/64 loss: -1.9560575485229492
Batch 64/64 loss: -6.029341697692871
Epoch 392  Train loss: -1.8867224861593808  Val loss: -1.9128307853777384
Epoch 393
-------------------------------
Batch 1/64 loss: -1.549311637878418
Batch 2/64 loss: -1.6555109024047852
Batch 3/64 loss: -1.4191083908081055
Batch 4/64 loss: -1.6966829299926758
Batch 5/64 loss: -1.4592866897583008
Batch 6/64 loss: -1.72735595703125
Batch 7/64 loss: -1.557448387145996
Batch 8/64 loss: -1.9301233291625977
Batch 9/64 loss: -1.185948371887207
Batch 10/64 loss: -1.5426921844482422
Batch 11/64 loss: -1.9048051834106445
Batch 12/64 loss: -1.5938234329223633
Batch 13/64 loss: -1.627223014831543
Batch 14/64 loss: -1.8626246452331543
Batch 15/64 loss: -1.7952470779418945
Batch 16/64 loss: -1.9439139366149902
Batch 17/64 loss: -1.5522699356079102
Batch 18/64 loss: -1.6675071716308594
Batch 19/64 loss: -1.8150215148925781
Batch 20/64 loss: -2.0767440795898438
Batch 21/64 loss: -1.5552949905395508
Batch 22/64 loss: -2.047205924987793
Batch 23/64 loss: -2.0119848251342773
Batch 24/64 loss: -1.895050048828125
Batch 25/64 loss: -1.8409366607666016
Batch 26/64 loss: -1.692270278930664
Batch 27/64 loss: -1.539546012878418
Batch 28/64 loss: -2.007619857788086
Batch 29/64 loss: -1.6362285614013672
Batch 30/64 loss: -1.7697315216064453
Batch 31/64 loss: -1.556173324584961
Batch 32/64 loss: -1.9322729110717773
Batch 33/64 loss: -1.4904136657714844
Batch 34/64 loss: -1.8724441528320312
Batch 35/64 loss: -2.0316696166992188
Batch 36/64 loss: -2.179443836212158
Batch 37/64 loss: -1.7289133071899414
Batch 38/64 loss: -1.940408706665039
Batch 39/64 loss: -1.8324594497680664
Batch 40/64 loss: -2.109729766845703
Batch 41/64 loss: -1.9983844757080078
Batch 42/64 loss: -2.038867950439453
Batch 43/64 loss: -2.114866256713867
Batch 44/64 loss: -1.993788719177246
Batch 45/64 loss: -1.6735591888427734
Batch 46/64 loss: -1.672994613647461
Batch 47/64 loss: -2.115963935852051
Batch 48/64 loss: -1.7545289993286133
Batch 49/64 loss: -2.0365657806396484
Batch 50/64 loss: -1.770930290222168
Batch 51/64 loss: -2.0745391845703125
Batch 52/64 loss: -1.9739875793457031
Batch 53/64 loss: -1.8757057189941406
Batch 54/64 loss: -2.1792149543762207
Batch 55/64 loss: -1.8716659545898438
Batch 56/64 loss: -2.0439586639404297
Batch 57/64 loss: -2.0665841102600098
Batch 58/64 loss: -2.2106709480285645
Batch 59/64 loss: -2.0322484970092773
Batch 60/64 loss: -2.024786949157715
Batch 61/64 loss: -1.7910261154174805
Batch 62/64 loss: -1.807948112487793
Batch 63/64 loss: -1.589376449584961
Batch 64/64 loss: -5.8529791831970215
Epoch 393  Train loss: -1.871911278892966  Val loss: -1.9985868971782041
Epoch 394
-------------------------------
Batch 1/64 loss: -2.127828598022461
Batch 2/64 loss: -1.640986442565918
Batch 3/64 loss: -1.9749512672424316
Batch 4/64 loss: -1.7656259536743164
Batch 5/64 loss: -1.8896656036376953
Batch 6/64 loss: -2.066634178161621
Batch 7/64 loss: -1.9747648239135742
Batch 8/64 loss: -1.9290103912353516
Batch 9/64 loss: -2.0829758644104004
Batch 10/64 loss: -1.7622265815734863
Batch 11/64 loss: -1.5393190383911133
Batch 12/64 loss: -1.9822182655334473
Batch 13/64 loss: -1.6452741622924805
Batch 14/64 loss: -2.0248050689697266
Batch 15/64 loss: -2.041031837463379
Batch 16/64 loss: -1.7934722900390625
Batch 17/64 loss: -2.04056978225708
Batch 18/64 loss: -1.7742242813110352
Batch 19/64 loss: -1.7298922538757324
Batch 20/64 loss: -1.9998869895935059
Batch 21/64 loss: -2.12821102142334
Batch 22/64 loss: -1.888606071472168
Batch 23/64 loss: -1.791543960571289
Batch 24/64 loss: -2.0655717849731445
Batch 25/64 loss: -1.9279155731201172
Batch 26/64 loss: -1.4799079895019531
Batch 27/64 loss: -1.824040412902832
Batch 28/64 loss: -1.7436332702636719
Batch 29/64 loss: -1.7867746353149414
Batch 30/64 loss: -2.102905750274658
Batch 31/64 loss: -2.0040369033813477
Batch 32/64 loss: -2.0222978591918945
Batch 33/64 loss: -1.9288396835327148
Batch 34/64 loss: -1.4712638854980469
Batch 35/64 loss: -1.7296934127807617
Batch 36/64 loss: -1.982473373413086
Batch 37/64 loss: -1.8915090560913086
Batch 38/64 loss: -2.087608814239502
Batch 39/64 loss: -1.9665517807006836
Batch 40/64 loss: -1.7192249298095703
Batch 41/64 loss: -2.10524845123291
Batch 42/64 loss: -1.6902012825012207
Batch 43/64 loss: -1.4387598037719727
Batch 44/64 loss: -1.9150028228759766
Batch 45/64 loss: -2.157254219055176
Batch 46/64 loss: -2.1284351348876953
Batch 47/64 loss: -1.6969003677368164
Batch 48/64 loss: -1.8598833084106445
Batch 49/64 loss: -1.9397144317626953
Batch 50/64 loss: -1.1657905578613281
Batch 51/64 loss: -1.732330322265625
Batch 52/64 loss: -1.8678264617919922
Batch 53/64 loss: -1.8229670524597168
Batch 54/64 loss: -1.9504437446594238
Batch 55/64 loss: -2.081998825073242
Batch 56/64 loss: -1.9812417030334473
Batch 57/64 loss: -1.8386430740356445
Batch 58/64 loss: -1.746525764465332
Batch 59/64 loss: -1.4237403869628906
Batch 60/64 loss: -1.8574199676513672
Batch 61/64 loss: -1.892181396484375
Batch 62/64 loss: -1.7986950874328613
Batch 63/64 loss: -1.978975772857666
Batch 64/64 loss: -6.186454772949219
Epoch 394  Train loss: -1.9143214880251418  Val loss: -2.1428096024031493
Saving best model, epoch: 394
Epoch 395
-------------------------------
Batch 1/64 loss: -2.1748480796813965
Batch 2/64 loss: -2.019136905670166
Batch 3/64 loss: -1.812748908996582
Batch 4/64 loss: -2.0729684829711914
Batch 5/64 loss: -1.5933027267456055
Batch 6/64 loss: -2.1398777961730957
Batch 7/64 loss: -1.8726472854614258
Batch 8/64 loss: -1.9926881790161133
Batch 9/64 loss: -1.6952872276306152
Batch 10/64 loss: -1.611846923828125
Batch 11/64 loss: -2.006448745727539
Batch 12/64 loss: -1.946146011352539
Batch 13/64 loss: -1.9430437088012695
Batch 14/64 loss: -1.5908222198486328
Batch 15/64 loss: -1.938349723815918
Batch 16/64 loss: -1.5454998016357422
Batch 17/64 loss: -1.9351749420166016
Batch 18/64 loss: -2.0816988945007324
Batch 19/64 loss: -1.6867399215698242
Batch 20/64 loss: -1.6515989303588867
Batch 21/64 loss: -1.9658660888671875
Batch 22/64 loss: -1.6445035934448242
Batch 23/64 loss: -2.0259294509887695
Batch 24/64 loss: -1.7090940475463867
Batch 25/64 loss: -1.8739252090454102
Batch 26/64 loss: -1.753675937652588
Batch 27/64 loss: -2.101710319519043
Batch 28/64 loss: -1.6929512023925781
Batch 29/64 loss: -1.8818950653076172
Batch 30/64 loss: -1.6441946029663086
Batch 31/64 loss: -1.9742794036865234
Batch 32/64 loss: -1.9706969261169434
Batch 33/64 loss: -1.8740968704223633
Batch 34/64 loss: -1.8766450881958008
Batch 35/64 loss: -2.030661106109619
Batch 36/64 loss: -2.0734572410583496
Batch 37/64 loss: -1.659463882446289
Batch 38/64 loss: -1.6355161666870117
Batch 39/64 loss: -1.8384580612182617
Batch 40/64 loss: -2.060722827911377
Batch 41/64 loss: -1.8094415664672852
Batch 42/64 loss: -1.769552230834961
Batch 43/64 loss: -1.8394956588745117
Batch 44/64 loss: -1.9228954315185547
Batch 45/64 loss: -2.0218982696533203
Batch 46/64 loss: -1.7511463165283203
Batch 47/64 loss: -1.9921092987060547
Batch 48/64 loss: -2.0764107704162598
Batch 49/64 loss: -2.0062332153320312
Batch 50/64 loss: -1.8844852447509766
Batch 51/64 loss: -2.1259937286376953
Batch 52/64 loss: -2.090603828430176
Batch 53/64 loss: -2.037470817565918
Batch 54/64 loss: -1.7436723709106445
Batch 55/64 loss: -1.8747358322143555
Batch 56/64 loss: -1.5772600173950195
Batch 57/64 loss: -1.8434514999389648
Batch 58/64 loss: -1.848104476928711
Batch 59/64 loss: -1.7142038345336914
Batch 60/64 loss: -1.5078620910644531
Batch 61/64 loss: -2.09745454788208
Batch 62/64 loss: -1.961390495300293
Batch 63/64 loss: -2.1230807304382324
Batch 64/64 loss: -5.598601341247559
Epoch 395  Train loss: -1.9202591652963676  Val loss: -2.0439716745488012
Epoch 396
-------------------------------
Batch 1/64 loss: -2.0956521034240723
Batch 2/64 loss: -2.2260265350341797
Batch 3/64 loss: -1.8260774612426758
Batch 4/64 loss: -1.4961261749267578
Batch 5/64 loss: -1.618138313293457
Batch 6/64 loss: -1.7204351425170898
Batch 7/64 loss: -2.0759944915771484
Batch 8/64 loss: -1.7541179656982422
Batch 9/64 loss: -2.062216281890869
Batch 10/64 loss: -1.6414155960083008
Batch 11/64 loss: -1.7448196411132812
Batch 12/64 loss: -1.8493056297302246
Batch 13/64 loss: -1.7324323654174805
Batch 14/64 loss: -1.848067283630371
Batch 15/64 loss: -1.951486587524414
Batch 16/64 loss: -1.9020748138427734
Batch 17/64 loss: -1.8623404502868652
Batch 18/64 loss: -2.0267910957336426
Batch 19/64 loss: -1.7319602966308594
Batch 20/64 loss: -2.054837226867676
Batch 21/64 loss: -1.535050392150879
Batch 22/64 loss: -1.8613214492797852
Batch 23/64 loss: -1.717940330505371
Batch 24/64 loss: -2.183438777923584
Batch 25/64 loss: -2.071317195892334
Batch 26/64 loss: -1.733494758605957
Batch 27/64 loss: -1.9152212142944336
Batch 28/64 loss: -1.9754533767700195
Batch 29/64 loss: -2.05418062210083
Batch 30/64 loss: -2.2257609367370605
Batch 31/64 loss: -1.9567375183105469
Batch 32/64 loss: -2.1302123069763184
Batch 33/64 loss: -1.9089469909667969
Batch 34/64 loss: -1.7648687362670898
Batch 35/64 loss: -1.7953195571899414
Batch 36/64 loss: -1.745163917541504
Batch 37/64 loss: -1.9131860733032227
Batch 38/64 loss: -2.1577982902526855
Batch 39/64 loss: -1.9670052528381348
Batch 40/64 loss: -1.9971861839294434
Batch 41/64 loss: -2.0634660720825195
Batch 42/64 loss: -1.740839958190918
Batch 43/64 loss: -1.8549728393554688
Batch 44/64 loss: -1.9569635391235352
Batch 45/64 loss: -1.7127132415771484
Batch 46/64 loss: -1.586526870727539
Batch 47/64 loss: -1.7273082733154297
Batch 48/64 loss: -1.8889427185058594
Batch 49/64 loss: -1.9337153434753418
Batch 50/64 loss: -2.0967931747436523
Batch 51/64 loss: -2.030104637145996
Batch 52/64 loss: -1.9853391647338867
Batch 53/64 loss: -2.164292335510254
Batch 54/64 loss: -1.881901741027832
Batch 55/64 loss: -1.8063535690307617
Batch 56/64 loss: -1.9992179870605469
Batch 57/64 loss: -1.807692527770996
Batch 58/64 loss: -1.4701690673828125
Batch 59/64 loss: -2.043391227722168
Batch 60/64 loss: -1.9867334365844727
Batch 61/64 loss: -1.9124984741210938
Batch 62/64 loss: -1.6756668090820312
Batch 63/64 loss: -2.2381715774536133
Batch 64/64 loss: -5.86098575592041
Epoch 396  Train loss: -1.941795031229655  Val loss: -2.014583666300036
Epoch 397
-------------------------------
Batch 1/64 loss: -1.6542625427246094
Batch 2/64 loss: -2.2279157638549805
Batch 3/64 loss: -1.3551607131958008
Batch 4/64 loss: -1.8866844177246094
Batch 5/64 loss: -2.082394599914551
Batch 6/64 loss: -2.091615676879883
Batch 7/64 loss: -1.8195676803588867
Batch 8/64 loss: -1.9013566970825195
Batch 9/64 loss: -2.056334972381592
Batch 10/64 loss: -1.7646827697753906
Batch 11/64 loss: -1.944028377532959
Batch 12/64 loss: -1.9847440719604492
Batch 13/64 loss: -1.8464832305908203
Batch 14/64 loss: -1.9273648262023926
Batch 15/64 loss: -2.163146495819092
Batch 16/64 loss: -1.7952566146850586
Batch 17/64 loss: -1.899662971496582
Batch 18/64 loss: -1.8733901977539062
Batch 19/64 loss: -1.7145376205444336
Batch 20/64 loss: -1.5911712646484375
Batch 21/64 loss: -2.065722942352295
Batch 22/64 loss: -1.7261247634887695
Batch 23/64 loss: -2.0693483352661133
Batch 24/64 loss: -1.641845703125
Batch 25/64 loss: -1.8326435089111328
Batch 26/64 loss: -1.811997413635254
Batch 27/64 loss: -1.8858938217163086
Batch 28/64 loss: -2.0021276473999023
Batch 29/64 loss: -1.915487289428711
Batch 30/64 loss: -1.5175800323486328
Batch 31/64 loss: -1.8569183349609375
Batch 32/64 loss: -1.7261619567871094
Batch 33/64 loss: -1.9858283996582031
Batch 34/64 loss: -1.812842845916748
Batch 35/64 loss: -2.029418468475342
Batch 36/64 loss: -2.135730266571045
Batch 37/64 loss: -1.8666572570800781
Batch 38/64 loss: -1.9209213256835938
Batch 39/64 loss: -2.1630821228027344
Batch 40/64 loss: -1.6725349426269531
Batch 41/64 loss: -2.0157155990600586
Batch 42/64 loss: -1.8070974349975586
Batch 43/64 loss: -2.3573684692382812
Batch 44/64 loss: -1.773782730102539
Batch 45/64 loss: -2.0145506858825684
Batch 46/64 loss: -1.92879056930542
Batch 47/64 loss: -1.913975715637207
Batch 48/64 loss: -1.801382064819336
Batch 49/64 loss: -1.997875690460205
Batch 50/64 loss: -1.7753190994262695
Batch 51/64 loss: -2.133633613586426
Batch 52/64 loss: -2.076737403869629
Batch 53/64 loss: -1.869532585144043
Batch 54/64 loss: -2.0760316848754883
Batch 55/64 loss: -1.8741846084594727
Batch 56/64 loss: -1.5442523956298828
Batch 57/64 loss: -1.9292335510253906
Batch 58/64 loss: -1.6442899703979492
Batch 59/64 loss: -2.00250244140625
Batch 60/64 loss: -1.5147724151611328
Batch 61/64 loss: -1.773219108581543
Batch 62/64 loss: -2.077791213989258
Batch 63/64 loss: -1.793619155883789
Batch 64/64 loss: -6.250025272369385
Epoch 397  Train loss: -1.9388518595228008  Val loss: -2.0559957838550056
Epoch 398
-------------------------------
Batch 1/64 loss: -2.2493815422058105
Batch 2/64 loss: -2.144951820373535
Batch 3/64 loss: -1.9513936042785645
Batch 4/64 loss: -1.9572219848632812
Batch 5/64 loss: -1.8848609924316406
Batch 6/64 loss: -1.9363374710083008
Batch 7/64 loss: -1.941274642944336
Batch 8/64 loss: -1.8635425567626953
Batch 9/64 loss: -2.074906349182129
Batch 10/64 loss: -1.8613252639770508
Batch 11/64 loss: -1.842803955078125
Batch 12/64 loss: -1.9744815826416016
Batch 13/64 loss: -1.9443140029907227
Batch 14/64 loss: -1.805943489074707
Batch 15/64 loss: -1.8423347473144531
Batch 16/64 loss: -1.835195541381836
Batch 17/64 loss: -2.0645751953125
Batch 18/64 loss: -1.9565629959106445
Batch 19/64 loss: -1.8498659133911133
Batch 20/64 loss: -1.8271980285644531
Batch 21/64 loss: -1.8047666549682617
Batch 22/64 loss: -1.5598783493041992
Batch 23/64 loss: -1.9747743606567383
Batch 24/64 loss: -1.665731430053711
Batch 25/64 loss: -1.9430465698242188
Batch 26/64 loss: -1.9881672859191895
Batch 27/64 loss: -1.9404840469360352
Batch 28/64 loss: -1.8303155899047852
Batch 29/64 loss: -1.971980094909668
Batch 30/64 loss: -1.8181753158569336
Batch 31/64 loss: -1.8631668090820312
Batch 32/64 loss: -1.7974834442138672
Batch 33/64 loss: -1.9195919036865234
Batch 34/64 loss: -1.3946504592895508
Batch 35/64 loss: -1.615250587463379
Batch 36/64 loss: -1.8492097854614258
Batch 37/64 loss: -1.9978938102722168
Batch 38/64 loss: -1.8947114944458008
Batch 39/64 loss: -1.7466163635253906
Batch 40/64 loss: -1.7413129806518555
Batch 41/64 loss: -1.8788394927978516
Batch 42/64 loss: -2.0382180213928223
Batch 43/64 loss: -1.7897968292236328
Batch 44/64 loss: -1.4115753173828125
Batch 45/64 loss: -1.2676076889038086
Batch 46/64 loss: -1.7960996627807617
Batch 47/64 loss: -1.7314233779907227
Batch 48/64 loss: -1.9049482345581055
Batch 49/64 loss: -1.4698657989501953
Batch 50/64 loss: -1.259810447692871
Batch 51/64 loss: -1.9402761459350586
Batch 52/64 loss: -1.8305778503417969
Batch 53/64 loss: -1.9773750305175781
Batch 54/64 loss: -1.838043212890625
Batch 55/64 loss: -2.0267958641052246
Batch 56/64 loss: -1.8263368606567383
Batch 57/64 loss: -1.8261127471923828
Batch 58/64 loss: -1.7916383743286133
Batch 59/64 loss: -1.8837690353393555
Batch 60/64 loss: -1.8936872482299805
Batch 61/64 loss: -1.6758413314819336
Batch 62/64 loss: -1.8941431045532227
Batch 63/64 loss: -1.638925552368164
Batch 64/64 loss: -5.916766166687012
Epoch 398  Train loss: -1.8847836999332204  Val loss: -2.0066560961536526
Epoch 399
-------------------------------
Batch 1/64 loss: -1.8176898956298828
Batch 2/64 loss: -1.9880428314208984
Batch 3/64 loss: -1.9412193298339844
Batch 4/64 loss: -1.5303382873535156
Batch 5/64 loss: -1.6473636627197266
Batch 6/64 loss: -1.8044090270996094
Batch 7/64 loss: -2.0074148178100586
Batch 8/64 loss: -2.0847573280334473
Batch 9/64 loss: -2.044943332672119
Batch 10/64 loss: -1.908041000366211
Batch 11/64 loss: -1.539520263671875
Batch 12/64 loss: -1.5244340896606445
Batch 13/64 loss: -1.7813568115234375
Batch 14/64 loss: -1.8375005722045898
Batch 15/64 loss: -1.9001646041870117
Batch 16/64 loss: -1.823781967163086
Batch 17/64 loss: -1.8884906768798828
Batch 18/64 loss: -2.0747790336608887
Batch 19/64 loss: -1.3914375305175781
Batch 20/64 loss: -2.0046138763427734
Batch 21/64 loss: -2.0129623413085938
Batch 22/64 loss: -1.375849723815918
Batch 23/64 loss: -2.0652875900268555
Batch 24/64 loss: -1.9355230331420898
Batch 25/64 loss: -1.7931957244873047
Batch 26/64 loss: -1.5577678680419922
Batch 27/64 loss: -1.796828269958496
Batch 28/64 loss: -1.099534034729004
Batch 29/64 loss: -1.8008337020874023
Batch 30/64 loss: -1.8802556991577148
Batch 31/64 loss: -1.9372878074645996
Batch 32/64 loss: -1.8411951065063477
Batch 33/64 loss: -1.611252784729004
Batch 34/64 loss: -2.0469627380371094
Batch 35/64 loss: -1.9016609191894531
Batch 36/64 loss: -2.0655837059020996
Batch 37/64 loss: -1.890188217163086
Batch 38/64 loss: -1.8349456787109375
Batch 39/64 loss: -1.8273630142211914
Batch 40/64 loss: -1.969172477722168
Batch 41/64 loss: -1.6592674255371094
Batch 42/64 loss: -2.09531831741333
Batch 43/64 loss: -2.0549182891845703
Batch 44/64 loss: -1.908005714416504
Batch 45/64 loss: -1.6707820892333984
Batch 46/64 loss: -1.8519001007080078
Batch 47/64 loss: -1.9988594055175781
Batch 48/64 loss: -1.9142694473266602
Batch 49/64 loss: -1.5691804885864258
Batch 50/64 loss: -2.049335479736328
Batch 51/64 loss: -2.1554274559020996
Batch 52/64 loss: -2.1523032188415527
Batch 53/64 loss: -1.8423957824707031
Batch 54/64 loss: -1.6663312911987305
Batch 55/64 loss: -1.4618091583251953
Batch 56/64 loss: -2.015695571899414
Batch 57/64 loss: -1.9894013404846191
Batch 58/64 loss: -1.9087409973144531
Batch 59/64 loss: -1.640275001525879
Batch 60/64 loss: -1.8764972686767578
Batch 61/64 loss: -1.7178936004638672
Batch 62/64 loss: -1.9245848655700684
Batch 63/64 loss: -1.6052770614624023
Batch 64/64 loss: -5.764113426208496
Epoch 399  Train loss: -1.8797726088879154  Val loss: -2.117738795853972
Epoch 400
-------------------------------
Batch 1/64 loss: -1.7522544860839844
Batch 2/64 loss: -1.9610838890075684
Batch 3/64 loss: -2.0022478103637695
Batch 4/64 loss: -2.1322412490844727
Batch 5/64 loss: -1.5648927688598633
Batch 6/64 loss: -2.041536808013916
Batch 7/64 loss: -1.4850807189941406
Batch 8/64 loss: -2.1195316314697266
Batch 9/64 loss: -1.794083595275879
Batch 10/64 loss: -2.016002655029297
Batch 11/64 loss: -1.6921348571777344
Batch 12/64 loss: -1.8139533996582031
Batch 13/64 loss: -2.1487951278686523
Batch 14/64 loss: -1.9254322052001953
Batch 15/64 loss: -1.7769031524658203
Batch 16/64 loss: -1.8771095275878906
Batch 17/64 loss: -1.928248405456543
Batch 18/64 loss: -2.0936102867126465
Batch 19/64 loss: -1.8879079818725586
Batch 20/64 loss: -1.560908317565918
Batch 21/64 loss: -1.894057273864746
Batch 22/64 loss: -1.8117685317993164
Batch 23/64 loss: -2.1214780807495117
Batch 24/64 loss: -1.0817985534667969
Batch 25/64 loss: -1.7792024612426758
Batch 26/64 loss: -2.0307769775390625
Batch 27/64 loss: -1.921097755432129
Batch 28/64 loss: -1.8600530624389648
Batch 29/64 loss: -1.6486148834228516
Batch 30/64 loss: -1.789015769958496
Batch 31/64 loss: -1.9579005241394043
Batch 32/64 loss: -1.8420586585998535
Batch 33/64 loss: -1.8707914352416992
Batch 34/64 loss: -1.671940803527832
Batch 35/64 loss: -1.7906303405761719
Batch 36/64 loss: -2.0119781494140625
Batch 37/64 loss: -1.7332868576049805
Batch 38/64 loss: -1.4923696517944336
Batch 39/64 loss: -1.8272838592529297
Batch 40/64 loss: -1.8506569862365723
Batch 41/64 loss: -1.713541030883789
Batch 42/64 loss: -2.0192651748657227
Batch 43/64 loss: -1.6531000137329102
Batch 44/64 loss: -1.5578727722167969
Batch 45/64 loss: -1.9739437103271484
Batch 46/64 loss: -1.8949708938598633
Batch 47/64 loss: -1.5764036178588867
Batch 48/64 loss: -1.8600873947143555
Batch 49/64 loss: -1.5915851593017578
Batch 50/64 loss: -2.0930471420288086
Batch 51/64 loss: -1.4960241317749023
Batch 52/64 loss: -1.9664077758789062
Batch 53/64 loss: -1.6589412689208984
Batch 54/64 loss: -2.066464900970459
Batch 55/64 loss: -1.89617919921875
Batch 56/64 loss: -1.9322013854980469
Batch 57/64 loss: -1.7920122146606445
Batch 58/64 loss: -1.4543547630310059
Batch 59/64 loss: -2.0715255737304688
Batch 60/64 loss: -1.8140878677368164
Batch 61/64 loss: -1.7154474258422852
Batch 62/64 loss: -2.097731113433838
Batch 63/64 loss: -1.9896430969238281
Batch 64/64 loss: -6.041330814361572
Epoch 400  Train loss: -1.881985180050719  Val loss: -1.9854805412161391
Epoch 401
-------------------------------
Batch 1/64 loss: -1.9125757217407227
Batch 2/64 loss: -1.552154541015625
Batch 3/64 loss: -1.6001672744750977
Batch 4/64 loss: -1.8905086517333984
Batch 5/64 loss: -1.8346929550170898
Batch 6/64 loss: -1.824193000793457
Batch 7/64 loss: -1.8357810974121094
Batch 8/64 loss: -1.8927583694458008
Batch 9/64 loss: -1.4850025177001953
Batch 10/64 loss: -1.9448213577270508
Batch 11/64 loss: -1.852926254272461
Batch 12/64 loss: -1.3494338989257812
Batch 13/64 loss: -1.6584672927856445
Batch 14/64 loss: -1.7163286209106445
Batch 15/64 loss: -1.6552648544311523
Batch 16/64 loss: -1.8620491027832031
Batch 17/64 loss: -2.0578346252441406
Batch 18/64 loss: -2.104119300842285
Batch 19/64 loss: -1.9362869262695312
Batch 20/64 loss: -1.9507808685302734
Batch 21/64 loss: -1.4697837829589844
Batch 22/64 loss: -2.1120176315307617
Batch 23/64 loss: -1.944504737854004
Batch 24/64 loss: -1.8850955963134766
Batch 25/64 loss: -1.8252201080322266
Batch 26/64 loss: -1.8949432373046875
Batch 27/64 loss: -1.7858238220214844
Batch 28/64 loss: -2.0017948150634766
Batch 29/64 loss: -1.9259767532348633
Batch 30/64 loss: -1.7697858810424805
Batch 31/64 loss: -1.951798439025879
Batch 32/64 loss: -1.5931329727172852
Batch 33/64 loss: -2.0347423553466797
Batch 34/64 loss: -2.067580223083496
Batch 35/64 loss: -1.834939956665039
Batch 36/64 loss: -1.847055435180664
Batch 37/64 loss: -1.6545133590698242
Batch 38/64 loss: -1.8488044738769531
Batch 39/64 loss: -2.0247297286987305
Batch 40/64 loss: -2.0738816261291504
Batch 41/64 loss: -2.215752124786377
Batch 42/64 loss: -1.906890869140625
Batch 43/64 loss: -1.8187446594238281
Batch 44/64 loss: -1.9088692665100098
Batch 45/64 loss: -1.8660430908203125
Batch 46/64 loss: -1.5155377388000488
Batch 47/64 loss: -1.8964648246765137
Batch 48/64 loss: -1.9173955917358398
Batch 49/64 loss: -1.8059930801391602
Batch 50/64 loss: -0.9810562133789062
Batch 51/64 loss: -1.9225859642028809
Batch 52/64 loss: -1.8789892196655273
Batch 53/64 loss: -1.9874463081359863
Batch 54/64 loss: -1.9032135009765625
Batch 55/64 loss: -2.0267295837402344
Batch 56/64 loss: -1.674184799194336
Batch 57/64 loss: -1.8482093811035156
Batch 58/64 loss: -1.6874346733093262
Batch 59/64 loss: -1.9666619300842285
Batch 60/64 loss: -2.0333242416381836
Batch 61/64 loss: -1.9714961051940918
Batch 62/64 loss: -1.9567136764526367
Batch 63/64 loss: -2.0156450271606445
Batch 64/64 loss: -5.519588947296143
Epoch 401  Train loss: -1.8871740509481991  Val loss: -2.058940140242429
Epoch 402
-------------------------------
Batch 1/64 loss: -1.8983101844787598
Batch 2/64 loss: -1.8671455383300781
Batch 3/64 loss: -1.952784538269043
Batch 4/64 loss: -2.0027637481689453
Batch 5/64 loss: -2.1075539588928223
Batch 6/64 loss: -1.8452796936035156
Batch 7/64 loss: -1.8369436264038086
Batch 8/64 loss: -1.6054391860961914
Batch 9/64 loss: -1.9535694122314453
Batch 10/64 loss: -1.7808427810668945
Batch 11/64 loss: -2.1198558807373047
Batch 12/64 loss: -1.957697868347168
Batch 13/64 loss: -1.9434914588928223
Batch 14/64 loss: -1.9390959739685059
Batch 15/64 loss: -1.95428466796875
Batch 16/64 loss: -1.8553133010864258
Batch 17/64 loss: -2.1610565185546875
Batch 18/64 loss: -2.1370763778686523
Batch 19/64 loss: -1.805769920349121
Batch 20/64 loss: -1.9179530143737793
Batch 21/64 loss: -1.6286439895629883
Batch 22/64 loss: -1.8935604095458984
Batch 23/64 loss: -1.8147802352905273
Batch 24/64 loss: -2.0258102416992188
Batch 25/64 loss: -1.9794507026672363
Batch 26/64 loss: -2.0813183784484863
Batch 27/64 loss: -1.888472557067871
Batch 28/64 loss: -2.059206485748291
Batch 29/64 loss: -1.6611480712890625
Batch 30/64 loss: -1.9437408447265625
Batch 31/64 loss: -2.0157508850097656
Batch 32/64 loss: -1.8385305404663086
Batch 33/64 loss: -1.4121742248535156
Batch 34/64 loss: -2.167175769805908
Batch 35/64 loss: -1.8994779586791992
Batch 36/64 loss: -1.8263263702392578
Batch 37/64 loss: -2.0714707374572754
Batch 38/64 loss: -1.7120866775512695
Batch 39/64 loss: -1.4620475769042969
Batch 40/64 loss: -1.9845733642578125
Batch 41/64 loss: -2.0375137329101562
Batch 42/64 loss: -2.093679904937744
Batch 43/64 loss: -1.4707880020141602
Batch 44/64 loss: -1.8332929611206055
Batch 45/64 loss: -1.7290754318237305
Batch 46/64 loss: -1.5407752990722656
Batch 47/64 loss: -1.648843765258789
Batch 48/64 loss: -2.0148158073425293
Batch 49/64 loss: -1.2406368255615234
Batch 50/64 loss: -1.7935094833374023
Batch 51/64 loss: -1.6257762908935547
Batch 52/64 loss: -1.944066047668457
Batch 53/64 loss: -2.048689842224121
Batch 54/64 loss: -1.7587385177612305
Batch 55/64 loss: -1.9106006622314453
Batch 56/64 loss: -1.5635309219360352
Batch 57/64 loss: -2.160212993621826
Batch 58/64 loss: -2.1064634323120117
Batch 59/64 loss: -1.8608736991882324
Batch 60/64 loss: -1.8998823165893555
Batch 61/64 loss: -1.8330965042114258
Batch 62/64 loss: -1.4618511199951172
Batch 63/64 loss: -1.636979103088379
Batch 64/64 loss: -6.203612804412842
Epoch 402  Train loss: -1.9117549166959875  Val loss: -2.0749479864061495
Epoch 403
-------------------------------
Batch 1/64 loss: -1.688797950744629
Batch 2/64 loss: -1.711623191833496
Batch 3/64 loss: -1.7446517944335938
Batch 4/64 loss: -2.054205894470215
Batch 5/64 loss: -1.641036033630371
Batch 6/64 loss: -1.7907094955444336
Batch 7/64 loss: -2.023024082183838
Batch 8/64 loss: -2.010204792022705
Batch 9/64 loss: -1.602992057800293
Batch 10/64 loss: -1.9020557403564453
Batch 11/64 loss: -1.6786565780639648
Batch 12/64 loss: -1.869239330291748
Batch 13/64 loss: -1.9669198989868164
Batch 14/64 loss: -2.071870803833008
Batch 15/64 loss: -1.94097900390625
Batch 16/64 loss: -1.890024185180664
Batch 17/64 loss: -1.8442564010620117
Batch 18/64 loss: -2.0942578315734863
Batch 19/64 loss: -1.5749530792236328
Batch 20/64 loss: -1.965261459350586
Batch 21/64 loss: -1.9512271881103516
Batch 22/64 loss: -1.3120393753051758
Batch 23/64 loss: -1.7531728744506836
Batch 24/64 loss: -1.5777063369750977
Batch 25/64 loss: -1.6627368927001953
Batch 26/64 loss: -1.9438447952270508
Batch 27/64 loss: -2.0208773612976074
Batch 28/64 loss: -1.9858131408691406
Batch 29/64 loss: -2.131795883178711
Batch 30/64 loss: -1.759995460510254
Batch 31/64 loss: -1.6825332641601562
Batch 32/64 loss: -2.0027871131896973
Batch 33/64 loss: -0.8663196563720703
Batch 34/64 loss: -1.4090662002563477
Batch 35/64 loss: -1.873291015625
Batch 36/64 loss: -2.056279182434082
Batch 37/64 loss: -1.7348976135253906
Batch 38/64 loss: -1.8792476654052734
Batch 39/64 loss: -1.4608173370361328
Batch 40/64 loss: -1.9531216621398926
Batch 41/64 loss: -1.907851219177246
Batch 42/64 loss: -1.8592491149902344
Batch 43/64 loss: -2.0339584350585938
Batch 44/64 loss: -2.0940732955932617
Batch 45/64 loss: -1.8238248825073242
Batch 46/64 loss: -1.806497573852539
Batch 47/64 loss: -1.6091718673706055
Batch 48/64 loss: -1.9684600830078125
Batch 49/64 loss: -1.6860713958740234
Batch 50/64 loss: -1.5830411911010742
Batch 51/64 loss: -1.8020038604736328
Batch 52/64 loss: -1.8641953468322754
Batch 53/64 loss: -1.8769340515136719
Batch 54/64 loss: -1.2037277221679688
Batch 55/64 loss: -1.4115467071533203
Batch 56/64 loss: -1.781947135925293
Batch 57/64 loss: -1.6236944198608398
Batch 58/64 loss: -1.796156883239746
Batch 59/64 loss: -1.6061506271362305
Batch 60/64 loss: -1.801508903503418
Batch 61/64 loss: -2.19451904296875
Batch 62/64 loss: -1.8693442344665527
Batch 63/64 loss: -1.5653553009033203
Batch 64/64 loss: -6.17672061920166
Epoch 403  Train loss: -1.8429037393308154  Val loss: -1.8226228432147364
Epoch 404
-------------------------------
Batch 1/64 loss: -1.7580232620239258
Batch 2/64 loss: -1.924973487854004
Batch 3/64 loss: -1.4499387741088867
Batch 4/64 loss: -1.8020620346069336
Batch 5/64 loss: -1.7203197479248047
Batch 6/64 loss: -1.9239130020141602
Batch 7/64 loss: -2.0456976890563965
Batch 8/64 loss: -1.758854866027832
Batch 9/64 loss: -1.8261375427246094
Batch 10/64 loss: -1.8892173767089844
Batch 11/64 loss: -1.9740066528320312
Batch 12/64 loss: -1.9189491271972656
Batch 13/64 loss: -1.7698354721069336
Batch 14/64 loss: -1.9439353942871094
Batch 15/64 loss: -1.9509201049804688
Batch 16/64 loss: -1.7290611267089844
Batch 17/64 loss: -1.897590160369873
Batch 18/64 loss: -1.4758644104003906
Batch 19/64 loss: -1.6698999404907227
Batch 20/64 loss: -1.1054277420043945
Batch 21/64 loss: -2.0486316680908203
Batch 22/64 loss: -1.8244695663452148
Batch 23/64 loss: -1.7755584716796875
Batch 24/64 loss: -2.1943793296813965
Batch 25/64 loss: -2.0468711853027344
Batch 26/64 loss: -1.915146827697754
Batch 27/64 loss: -1.6295452117919922
Batch 28/64 loss: -1.7544546127319336
Batch 29/64 loss: -1.645864486694336
Batch 30/64 loss: -1.9784321784973145
Batch 31/64 loss: -1.6244430541992188
Batch 32/64 loss: -1.8606224060058594
Batch 33/64 loss: -2.100808620452881
Batch 34/64 loss: -1.8283076286315918
Batch 35/64 loss: -1.695633888244629
Batch 36/64 loss: -1.3167810440063477
Batch 37/64 loss: -1.7924528121948242
Batch 38/64 loss: -1.9752464294433594
Batch 39/64 loss: -1.610367774963379
Batch 40/64 loss: -1.9113130569458008
Batch 41/64 loss: -0.8492021560668945
Batch 42/64 loss: -1.43560791015625
Batch 43/64 loss: -2.0591464042663574
Batch 44/64 loss: -1.866631031036377
Batch 45/64 loss: -1.990640640258789
Batch 46/64 loss: -1.9457874298095703
Batch 47/64 loss: -1.7265653610229492
Batch 48/64 loss: -1.4947271347045898
Batch 49/64 loss: -1.720332145690918
Batch 50/64 loss: -2.173980712890625
Batch 51/64 loss: -1.6372804641723633
Batch 52/64 loss: -1.5339469909667969
Batch 53/64 loss: -2.103538990020752
Batch 54/64 loss: -1.9040522575378418
Batch 55/64 loss: -1.6908140182495117
Batch 56/64 loss: -1.7415862083435059
Batch 57/64 loss: -1.5628328323364258
Batch 58/64 loss: -1.7582969665527344
Batch 59/64 loss: -1.077225685119629
Batch 60/64 loss: -2.0107827186584473
Batch 61/64 loss: -1.6668243408203125
Batch 62/64 loss: -1.724884033203125
Batch 63/64 loss: -1.6759462356567383
Batch 64/64 loss: -5.937597751617432
Epoch 404  Train loss: -1.8175339474397547  Val loss: -1.8903320024103643
Epoch 405
-------------------------------
Batch 1/64 loss: -1.7073326110839844
Batch 2/64 loss: -2.1698150634765625
Batch 3/64 loss: -1.9289360046386719
Batch 4/64 loss: -1.7931451797485352
Batch 5/64 loss: -1.389399528503418
Batch 6/64 loss: -1.751816749572754
Batch 7/64 loss: -1.9022216796875
Batch 8/64 loss: -1.6001911163330078
Batch 9/64 loss: -1.9381299018859863
Batch 10/64 loss: -1.8213462829589844
Batch 11/64 loss: -1.7537803649902344
Batch 12/64 loss: -1.9485769271850586
Batch 13/64 loss: -1.8429079055786133
Batch 14/64 loss: -1.9585728645324707
Batch 15/64 loss: -1.8585033416748047
Batch 16/64 loss: -1.6591911315917969
Batch 17/64 loss: -2.051191806793213
Batch 18/64 loss: -2.037677764892578
Batch 19/64 loss: -1.8083233833312988
Batch 20/64 loss: -1.3771390914916992
Batch 21/64 loss: -2.047457695007324
Batch 22/64 loss: -2.088351249694824
Batch 23/64 loss: -2.06060791015625
Batch 24/64 loss: -1.6738786697387695
Batch 25/64 loss: -2.1043314933776855
Batch 26/64 loss: -1.439499855041504
Batch 27/64 loss: -1.8943710327148438
Batch 28/64 loss: -1.800537109375
Batch 29/64 loss: -1.7833070755004883
Batch 30/64 loss: -1.7458090782165527
Batch 31/64 loss: -1.8046369552612305
Batch 32/64 loss: -1.862044334411621
Batch 33/64 loss: -1.6824274063110352
Batch 34/64 loss: -1.786633014678955
Batch 35/64 loss: -1.5154285430908203
Batch 36/64 loss: -2.043006420135498
Batch 37/64 loss: -1.3658843040466309
Batch 38/64 loss: -1.7547941207885742
Batch 39/64 loss: -1.4469938278198242
Batch 40/64 loss: -1.2202625274658203
Batch 41/64 loss: -2.268984317779541
Batch 42/64 loss: -1.9206223487854004
Batch 43/64 loss: -1.8090333938598633
Batch 44/64 loss: -1.8241558074951172
Batch 45/64 loss: -1.846247673034668
Batch 46/64 loss: -1.7007970809936523
Batch 47/64 loss: -2.100566864013672
Batch 48/64 loss: -1.6879940032958984
Batch 49/64 loss: -2.0243797302246094
Batch 50/64 loss: -1.9431877136230469
Batch 51/64 loss: -2.0466156005859375
Batch 52/64 loss: -1.6543922424316406
Batch 53/64 loss: -1.7825689315795898
Batch 54/64 loss: -2.1061224937438965
Batch 55/64 loss: -1.9845995903015137
Batch 56/64 loss: -1.4204216003417969
Batch 57/64 loss: -1.9036788940429688
Batch 58/64 loss: -1.6226005554199219
Batch 59/64 loss: -1.9100399017333984
Batch 60/64 loss: -2.2059807777404785
Batch 61/64 loss: -1.8005714416503906
Batch 62/64 loss: -2.0328097343444824
Batch 63/64 loss: -2.02535343170166
Batch 64/64 loss: -5.624931812286377
Epoch 405  Train loss: -1.870727597030939  Val loss: -2.0902562747706255
Epoch 406
-------------------------------
Batch 1/64 loss: -2.177823066711426
Batch 2/64 loss: -2.087841033935547
Batch 3/64 loss: -1.6084136962890625
Batch 4/64 loss: -1.9551401138305664
Batch 5/64 loss: -1.9453492164611816
Batch 6/64 loss: -2.106372833251953
Batch 7/64 loss: -1.5614967346191406
Batch 8/64 loss: -2.238884925842285
Batch 9/64 loss: -1.8247308731079102
Batch 10/64 loss: -1.6659603118896484
Batch 11/64 loss: -1.878312587738037
Batch 12/64 loss: -2.059959888458252
Batch 13/64 loss: -1.6414146423339844
Batch 14/64 loss: -2.0121660232543945
Batch 15/64 loss: -1.7650632858276367
Batch 16/64 loss: -1.8114910125732422
Batch 17/64 loss: -1.4884586334228516
Batch 18/64 loss: -2.0373244285583496
Batch 19/64 loss: -1.5170822143554688
Batch 20/64 loss: -1.9519014358520508
Batch 21/64 loss: -1.7566843032836914
Batch 22/64 loss: -1.8278961181640625
Batch 23/64 loss: -1.7803754806518555
Batch 24/64 loss: -1.8095388412475586
Batch 25/64 loss: -2.0698604583740234
Batch 26/64 loss: -1.8957700729370117
Batch 27/64 loss: -1.9011287689208984
Batch 28/64 loss: -1.9242467880249023
Batch 29/64 loss: -1.9687166213989258
Batch 30/64 loss: -1.8621654510498047
Batch 31/64 loss: -2.004396915435791
Batch 32/64 loss: -2.052119255065918
Batch 33/64 loss: -1.9445314407348633
Batch 34/64 loss: -1.444838523864746
Batch 35/64 loss: -1.7446293830871582
Batch 36/64 loss: -1.995335578918457
Batch 37/64 loss: -2.01186466217041
Batch 38/64 loss: -1.241668701171875
Batch 39/64 loss: -2.031184196472168
Batch 40/64 loss: -1.7599449157714844
Batch 41/64 loss: -2.1784377098083496
Batch 42/64 loss: -1.6942005157470703
Batch 43/64 loss: -1.633357048034668
Batch 44/64 loss: -1.5985889434814453
Batch 45/64 loss: -1.795689582824707
Batch 46/64 loss: -2.042295455932617
Batch 47/64 loss: -1.480804443359375
Batch 48/64 loss: -1.5784912109375
Batch 49/64 loss: -1.4180803298950195
Batch 50/64 loss: -1.6638059616088867
Batch 51/64 loss: -1.978816032409668
Batch 52/64 loss: -1.7734184265136719
Batch 53/64 loss: -1.7185468673706055
Batch 54/64 loss: -1.9640932083129883
Batch 55/64 loss: -2.002535820007324
Batch 56/64 loss: -1.7545347213745117
Batch 57/64 loss: -1.9525060653686523
Batch 58/64 loss: -1.7178525924682617
Batch 59/64 loss: -1.7966947555541992
Batch 60/64 loss: -1.7353801727294922
Batch 61/64 loss: -1.2271289825439453
Batch 62/64 loss: -1.9295949935913086
Batch 63/64 loss: -1.9603157043457031
Batch 64/64 loss: -5.579930305480957
Epoch 406  Train loss: -1.8688972660139496  Val loss: -2.06301794674798
Epoch 407
-------------------------------
Batch 1/64 loss: -1.9853286743164062
Batch 2/64 loss: -1.9835596084594727
Batch 3/64 loss: -1.663558006286621
Batch 4/64 loss: -1.9403715133666992
Batch 5/64 loss: -1.696110725402832
Batch 6/64 loss: -2.0120797157287598
Batch 7/64 loss: -2.005986213684082
Batch 8/64 loss: -1.6843147277832031
Batch 9/64 loss: -1.8363103866577148
Batch 10/64 loss: -2.242030620574951
Batch 11/64 loss: -1.8968544006347656
Batch 12/64 loss: -1.8137178421020508
Batch 13/64 loss: -1.5521621704101562
Batch 14/64 loss: -1.526595115661621
Batch 15/64 loss: -1.9443740844726562
Batch 16/64 loss: -2.022972583770752
Batch 17/64 loss: -1.9041156768798828
Batch 18/64 loss: -1.8668193817138672
Batch 19/64 loss: -1.3891525268554688
Batch 20/64 loss: -1.7203378677368164
Batch 21/64 loss: -2.0664939880371094
Batch 22/64 loss: -1.9059553146362305
Batch 23/64 loss: -1.7779579162597656
Batch 24/64 loss: -2.044437885284424
Batch 25/64 loss: -2.035721778869629
Batch 26/64 loss: -1.919586181640625
Batch 27/64 loss: -1.669468879699707
Batch 28/64 loss: -1.9179115295410156
Batch 29/64 loss: -1.897841453552246
Batch 30/64 loss: -1.9254589080810547
Batch 31/64 loss: -2.017151355743408
Batch 32/64 loss: -2.1131277084350586
Batch 33/64 loss: -1.8875694274902344
Batch 34/64 loss: -2.0251688957214355
Batch 35/64 loss: -1.7841835021972656
Batch 36/64 loss: -2.0820727348327637
Batch 37/64 loss: -1.4034318923950195
Batch 38/64 loss: -2.0287508964538574
Batch 39/64 loss: -1.8133392333984375
Batch 40/64 loss: -1.1506433486938477
Batch 41/64 loss: -1.6258292198181152
Batch 42/64 loss: -2.008392810821533
Batch 43/64 loss: -1.9386396408081055
Batch 44/64 loss: -1.8367748260498047
Batch 45/64 loss: -1.389657974243164
Batch 46/64 loss: -1.772749900817871
Batch 47/64 loss: -1.9998712539672852
Batch 48/64 loss: -1.827326774597168
Batch 49/64 loss: -2.10361909866333
Batch 50/64 loss: -1.8283429145812988
Batch 51/64 loss: -1.6756372451782227
Batch 52/64 loss: -1.3738231658935547
Batch 53/64 loss: -1.9675874710083008
Batch 54/64 loss: -2.0265932083129883
Batch 55/64 loss: -1.7485785484313965
Batch 56/64 loss: -1.6412467956542969
Batch 57/64 loss: -1.5090456008911133
Batch 58/64 loss: -1.9338531494140625
Batch 59/64 loss: -1.6858148574829102
Batch 60/64 loss: -1.7765231132507324
Batch 61/64 loss: -2.0966200828552246
Batch 62/64 loss: -1.564274787902832
Batch 63/64 loss: -2.1056251525878906
Batch 64/64 loss: -6.120406627655029
Epoch 407  Train loss: -1.8851726625479903  Val loss: -2.0841272622858944
Epoch 408
-------------------------------
Batch 1/64 loss: -2.0660476684570312
Batch 2/64 loss: -2.054412841796875
Batch 3/64 loss: -2.044590950012207
Batch 4/64 loss: -1.3667755126953125
Batch 5/64 loss: -1.8618712425231934
Batch 6/64 loss: -2.041022777557373
Batch 7/64 loss: -1.686793327331543
Batch 8/64 loss: -1.8832635879516602
Batch 9/64 loss: -2.032747268676758
Batch 10/64 loss: -1.9585905075073242
Batch 11/64 loss: -2.1226916313171387
Batch 12/64 loss: -1.772878646850586
Batch 13/64 loss: -1.5857677459716797
Batch 14/64 loss: -1.996340274810791
Batch 15/64 loss: -1.87839937210083
Batch 16/64 loss: -1.780848503112793
Batch 17/64 loss: -2.027162551879883
Batch 18/64 loss: -1.5495567321777344
Batch 19/64 loss: -1.9876041412353516
Batch 20/64 loss: -1.9565706253051758
Batch 21/64 loss: -1.8852200508117676
Batch 22/64 loss: -1.892862319946289
Batch 23/64 loss: -1.9937934875488281
Batch 24/64 loss: -2.0196495056152344
Batch 25/64 loss: -1.8238353729248047
Batch 26/64 loss: -1.9117708206176758
Batch 27/64 loss: -1.8085298538208008
Batch 28/64 loss: -1.6533870697021484
Batch 29/64 loss: -1.7606983184814453
Batch 30/64 loss: -1.880052089691162
Batch 31/64 loss: -1.8188166618347168
Batch 32/64 loss: -1.6515674591064453
Batch 33/64 loss: -1.6297073364257812
Batch 34/64 loss: -1.8490066528320312
Batch 35/64 loss: -2.0080347061157227
Batch 36/64 loss: -1.654007911682129
Batch 37/64 loss: -1.571645736694336
Batch 38/64 loss: -2.0555930137634277
Batch 39/64 loss: -1.8551244735717773
Batch 40/64 loss: -2.1086668968200684
Batch 41/64 loss: -1.9121065139770508
Batch 42/64 loss: -1.7636127471923828
Batch 43/64 loss: -2.043623447418213
Batch 44/64 loss: -1.6815862655639648
Batch 45/64 loss: -1.6963987350463867
Batch 46/64 loss: -1.9622154235839844
Batch 47/64 loss: -1.863358497619629
Batch 48/64 loss: -2.0352253913879395
Batch 49/64 loss: -1.9191226959228516
Batch 50/64 loss: -2.073002815246582
Batch 51/64 loss: -1.897298812866211
Batch 52/64 loss: -1.8933391571044922
Batch 53/64 loss: -1.6614131927490234
Batch 54/64 loss: -1.688735008239746
Batch 55/64 loss: -1.7564220428466797
Batch 56/64 loss: -2.1044206619262695
Batch 57/64 loss: -1.7216863632202148
Batch 58/64 loss: -1.8751139640808105
Batch 59/64 loss: -1.4898500442504883
Batch 60/64 loss: -1.9870696067810059
Batch 61/64 loss: -1.3893709182739258
Batch 62/64 loss: -1.9242839813232422
Batch 63/64 loss: -1.527064323425293
Batch 64/64 loss: -5.947033405303955
Epoch 408  Train loss: -1.8950980597851323  Val loss: -1.9837219526677607
Epoch 409
-------------------------------
Batch 1/64 loss: -1.8509235382080078
Batch 2/64 loss: -1.9478178024291992
Batch 3/64 loss: -2.1205339431762695
Batch 4/64 loss: -2.1904525756835938
Batch 5/64 loss: -1.7582874298095703
Batch 6/64 loss: -1.8613595962524414
Batch 7/64 loss: -1.8914060592651367
Batch 8/64 loss: -1.4886302947998047
Batch 9/64 loss: -1.6741485595703125
Batch 10/64 loss: -2.0341615676879883
Batch 11/64 loss: -1.6264562606811523
Batch 12/64 loss: -1.7393569946289062
Batch 13/64 loss: -1.7623624801635742
Batch 14/64 loss: -1.911595344543457
Batch 15/64 loss: -2.0645627975463867
Batch 16/64 loss: -1.794724464416504
Batch 17/64 loss: -2.1196107864379883
Batch 18/64 loss: -1.8361940383911133
Batch 19/64 loss: -1.8747119903564453
Batch 20/64 loss: -1.9581294059753418
Batch 21/64 loss: -1.3644819259643555
Batch 22/64 loss: -1.6973905563354492
Batch 23/64 loss: -1.8133420944213867
Batch 24/64 loss: -1.750333309173584
Batch 25/64 loss: -1.6283941268920898
Batch 26/64 loss: -1.8694210052490234
Batch 27/64 loss: -2.1241369247436523
Batch 28/64 loss: -2.1235032081604004
Batch 29/64 loss: -1.8984241485595703
Batch 30/64 loss: -1.7399911880493164
Batch 31/64 loss: -1.3375864028930664
Batch 32/64 loss: -1.6182661056518555
Batch 33/64 loss: -1.5657978057861328
Batch 34/64 loss: -1.3800344467163086
Batch 35/64 loss: -2.0080952644348145
Batch 36/64 loss: -1.8611812591552734
Batch 37/64 loss: -1.8961753845214844
Batch 38/64 loss: -2.037281036376953
Batch 39/64 loss: -1.9720735549926758
Batch 40/64 loss: -1.7135801315307617
Batch 41/64 loss: -1.9203190803527832
Batch 42/64 loss: -1.7481870651245117
Batch 43/64 loss: -1.901036262512207
Batch 44/64 loss: -1.788416862487793
Batch 45/64 loss: -2.0571718215942383
Batch 46/64 loss: -1.8064956665039062
Batch 47/64 loss: -2.2314071655273438
Batch 48/64 loss: -2.090700626373291
Batch 49/64 loss: -1.9737348556518555
Batch 50/64 loss: -1.7984848022460938
Batch 51/64 loss: -2.058903217315674
Batch 52/64 loss: -1.9658899307250977
Batch 53/64 loss: -2.046657085418701
Batch 54/64 loss: -1.8973932266235352
Batch 55/64 loss: -1.7876873016357422
Batch 56/64 loss: -1.586709976196289
Batch 57/64 loss: -1.7103338241577148
Batch 58/64 loss: -1.8207998275756836
Batch 59/64 loss: -1.6304607391357422
Batch 60/64 loss: -2.031344413757324
Batch 61/64 loss: -1.7030773162841797
Batch 62/64 loss: -2.1466259956359863
Batch 63/64 loss: -1.021418571472168
Batch 64/64 loss: -6.002948760986328
Epoch 409  Train loss: -1.8843981649361405  Val loss: -2.105745977552486
Epoch 410
-------------------------------
Batch 1/64 loss: -2.0739030838012695
Batch 2/64 loss: -1.7260866165161133
Batch 3/64 loss: -1.8050737380981445
Batch 4/64 loss: -1.9597883224487305
Batch 5/64 loss: -1.8469023704528809
Batch 6/64 loss: -1.7914938926696777
Batch 7/64 loss: -1.8171892166137695
Batch 8/64 loss: -1.9860634803771973
Batch 9/64 loss: -1.8043460845947266
Batch 10/64 loss: -2.083021640777588
Batch 11/64 loss: -2.076496124267578
Batch 12/64 loss: -1.8170175552368164
Batch 13/64 loss: -1.6732959747314453
Batch 14/64 loss: -1.888662338256836
Batch 15/64 loss: -1.668391227722168
Batch 16/64 loss: -2.088442802429199
Batch 17/64 loss: -2.021862030029297
Batch 18/64 loss: -1.7781782150268555
Batch 19/64 loss: -1.5841999053955078
Batch 20/64 loss: -1.8980422019958496
Batch 21/64 loss: -1.7635231018066406
Batch 22/64 loss: -2.081390380859375
Batch 23/64 loss: -1.972120761871338
Batch 24/64 loss: -1.7972984313964844
Batch 25/64 loss: -1.826848030090332
Batch 26/64 loss: -1.4381437301635742
Batch 27/64 loss: -1.9447994232177734
Batch 28/64 loss: -1.7523622512817383
Batch 29/64 loss: -1.2981758117675781
Batch 30/64 loss: -1.950094223022461
Batch 31/64 loss: -1.442601203918457
Batch 32/64 loss: -2.0547213554382324
Batch 33/64 loss: -2.006045341491699
Batch 34/64 loss: -1.731480598449707
Batch 35/64 loss: -1.9160957336425781
Batch 36/64 loss: -1.9318628311157227
Batch 37/64 loss: -1.8899316787719727
Batch 38/64 loss: -2.119576930999756
Batch 39/64 loss: -1.8623228073120117
Batch 40/64 loss: -1.7437105178833008
Batch 41/64 loss: -1.9716744422912598
Batch 42/64 loss: -2.0006322860717773
Batch 43/64 loss: -1.772761344909668
Batch 44/64 loss: -1.987447738647461
Batch 45/64 loss: -1.6183948516845703
Batch 46/64 loss: -2.1064796447753906
Batch 47/64 loss: -2.0125503540039062
Batch 48/64 loss: -1.5872726440429688
Batch 49/64 loss: -2.059633255004883
Batch 50/64 loss: -1.692561149597168
Batch 51/64 loss: -1.8396081924438477
Batch 52/64 loss: -1.7578706741333008
Batch 53/64 loss: -2.165195941925049
Batch 54/64 loss: -2.007326126098633
Batch 55/64 loss: -1.9758358001708984
Batch 56/64 loss: -2.114074230194092
Batch 57/64 loss: -1.7614994049072266
Batch 58/64 loss: -1.7873878479003906
Batch 59/64 loss: -1.4769344329833984
Batch 60/64 loss: -1.822667121887207
Batch 61/64 loss: -1.9566655158996582
Batch 62/64 loss: -2.0562710762023926
Batch 63/64 loss: -1.895792007446289
Batch 64/64 loss: -5.6644439697265625
Epoch 410  Train loss: -1.9072381337483724  Val loss: -2.0857684735170343
Epoch 411
-------------------------------
Batch 1/64 loss: -2.158013343811035
Batch 2/64 loss: -1.6885404586791992
Batch 3/64 loss: -1.9987173080444336
Batch 4/64 loss: -1.8916478157043457
Batch 5/64 loss: -2.0035648345947266
Batch 6/64 loss: -1.7906551361083984
Batch 7/64 loss: -1.3607215881347656
Batch 8/64 loss: -1.621591567993164
Batch 9/64 loss: -1.8050308227539062
Batch 10/64 loss: -2.036332130432129
Batch 11/64 loss: -1.807851791381836
Batch 12/64 loss: -1.959345817565918
Batch 13/64 loss: -1.8716754913330078
Batch 14/64 loss: -1.6927471160888672
Batch 15/64 loss: -1.9277420043945312
Batch 16/64 loss: -1.9508056640625
Batch 17/64 loss: -1.9586896896362305
Batch 18/64 loss: -1.7428169250488281
Batch 19/64 loss: -2.132509231567383
Batch 20/64 loss: -2.087848663330078
Batch 21/64 loss: -1.933302402496338
Batch 22/64 loss: -1.9863471984863281
Batch 23/64 loss: -1.8593730926513672
Batch 24/64 loss: -2.219461441040039
Batch 25/64 loss: -2.1058120727539062
Batch 26/64 loss: -2.174731731414795
Batch 27/64 loss: -2.169093608856201
Batch 28/64 loss: -1.7304010391235352
Batch 29/64 loss: -1.7456645965576172
Batch 30/64 loss: -2.2213869094848633
Batch 31/64 loss: -1.9957542419433594
Batch 32/64 loss: -1.5799074172973633
Batch 33/64 loss: -1.385981559753418
Batch 34/64 loss: -2.052297592163086
Batch 35/64 loss: -1.8528194427490234
Batch 36/64 loss: -1.8988828659057617
Batch 37/64 loss: -1.8961381912231445
Batch 38/64 loss: -2.0127182006835938
Batch 39/64 loss: -1.9048748016357422
Batch 40/64 loss: -1.9477834701538086
Batch 41/64 loss: -2.0034847259521484
Batch 42/64 loss: -1.6952743530273438
Batch 43/64 loss: -1.7814903259277344
Batch 44/64 loss: -2.004323959350586
Batch 45/64 loss: -1.7769784927368164
Batch 46/64 loss: -1.275442123413086
Batch 47/64 loss: -2.0652875900268555
Batch 48/64 loss: -1.8994722366333008
Batch 49/64 loss: -1.7536849975585938
Batch 50/64 loss: -1.8391361236572266
Batch 51/64 loss: -1.6375846862792969
Batch 52/64 loss: -1.9864311218261719
Batch 53/64 loss: -1.7826776504516602
Batch 54/64 loss: -1.6896848678588867
Batch 55/64 loss: -1.7176094055175781
Batch 56/64 loss: -1.666712760925293
Batch 57/64 loss: -2.044236660003662
Batch 58/64 loss: -2.211256504058838
Batch 59/64 loss: -1.4753656387329102
Batch 60/64 loss: -2.166314125061035
Batch 61/64 loss: -1.9358301162719727
Batch 62/64 loss: -2.0011086463928223
Batch 63/64 loss: -1.9506502151489258
Batch 64/64 loss: -6.286240577697754
Epoch 411  Train loss: -1.9330870123470532  Val loss: -2.081563090950353
Epoch 412
-------------------------------
Batch 1/64 loss: -1.8789730072021484
Batch 2/64 loss: -2.081603527069092
Batch 3/64 loss: -2.2120766639709473
Batch 4/64 loss: -1.8688154220581055
Batch 5/64 loss: -2.068366527557373
Batch 6/64 loss: -1.9991049766540527
Batch 7/64 loss: -2.133380889892578
Batch 8/64 loss: -1.594050407409668
Batch 9/64 loss: -1.776865005493164
Batch 10/64 loss: -1.8400611877441406
Batch 11/64 loss: -2.0059919357299805
Batch 12/64 loss: -2.086136817932129
Batch 13/64 loss: -1.8724050521850586
Batch 14/64 loss: -2.118021011352539
Batch 15/64 loss: -1.9912028312683105
Batch 16/64 loss: -1.9927711486816406
Batch 17/64 loss: -1.6934070587158203
Batch 18/64 loss: -1.8078222274780273
Batch 19/64 loss: -1.8500070571899414
Batch 20/64 loss: -1.8708744049072266
Batch 21/64 loss: -1.9826602935791016
Batch 22/64 loss: -1.6572685241699219
Batch 23/64 loss: -1.9166765213012695
Batch 24/64 loss: -1.7728157043457031
Batch 25/64 loss: -1.798086166381836
Batch 26/64 loss: -2.128976345062256
Batch 27/64 loss: -1.7053165435791016
Batch 28/64 loss: -2.1132373809814453
Batch 29/64 loss: -1.826986312866211
Batch 30/64 loss: -1.8590068817138672
Batch 31/64 loss: -1.9398574829101562
Batch 32/64 loss: -2.0693130493164062
Batch 33/64 loss: -1.8778715133666992
Batch 34/64 loss: -1.9330940246582031
Batch 35/64 loss: -2.2084226608276367
Batch 36/64 loss: -1.8837242126464844
Batch 37/64 loss: -1.96220064163208
Batch 38/64 loss: -0.8380107879638672
Batch 39/64 loss: -1.817744255065918
Batch 40/64 loss: -1.956125259399414
Batch 41/64 loss: -2.0230650901794434
Batch 42/64 loss: -2.0335702896118164
Batch 43/64 loss: -1.8106060028076172
Batch 44/64 loss: -1.7330856323242188
Batch 45/64 loss: -2.1060523986816406
Batch 46/64 loss: -2.106307029724121
Batch 47/64 loss: -2.142245292663574
Batch 48/64 loss: -1.9367828369140625
Batch 49/64 loss: -2.0503406524658203
Batch 50/64 loss: -1.7065958976745605
Batch 51/64 loss: -1.9432220458984375
Batch 52/64 loss: -1.7549314498901367
Batch 53/64 loss: -1.2023391723632812
Batch 54/64 loss: -1.7896728515625
Batch 55/64 loss: -2.0058107376098633
Batch 56/64 loss: -1.6263341903686523
Batch 57/64 loss: -1.9228172302246094
Batch 58/64 loss: -1.7817621231079102
Batch 59/64 loss: -1.8035688400268555
Batch 60/64 loss: -1.6848387718200684
Batch 61/64 loss: -1.8490476608276367
Batch 62/64 loss: -1.8172006607055664
Batch 63/64 loss: -1.8926243782043457
Batch 64/64 loss: -6.129634857177734
Epoch 412  Train loss: -1.9342647702086206  Val loss: -2.097865678190775
Epoch 413
-------------------------------
Batch 1/64 loss: -1.6697263717651367
Batch 2/64 loss: -1.904834270477295
Batch 3/64 loss: -1.4959564208984375
Batch 4/64 loss: -1.9291296005249023
Batch 5/64 loss: -2.0361499786376953
Batch 6/64 loss: -2.186063289642334
Batch 7/64 loss: -1.988469123840332
Batch 8/64 loss: -1.9629597663879395
Batch 9/64 loss: -2.152543067932129
Batch 10/64 loss: -1.8938231468200684
Batch 11/64 loss: -2.075946807861328
Batch 12/64 loss: -1.9508013725280762
Batch 13/64 loss: -2.016313076019287
Batch 14/64 loss: -1.9316401481628418
Batch 15/64 loss: -1.7155561447143555
Batch 16/64 loss: -1.8705062866210938
Batch 17/64 loss: -1.363081932067871
Batch 18/64 loss: -1.5094871520996094
Batch 19/64 loss: -1.733123779296875
Batch 20/64 loss: -1.993293285369873
Batch 21/64 loss: -1.6665372848510742
Batch 22/64 loss: -2.0194191932678223
Batch 23/64 loss: -1.9147815704345703
Batch 24/64 loss: -1.80145263671875
Batch 25/64 loss: -1.7342290878295898
Batch 26/64 loss: -2.0852489471435547
Batch 27/64 loss: -2.17910099029541
Batch 28/64 loss: -2.080410957336426
Batch 29/64 loss: -1.9351768493652344
Batch 30/64 loss: -1.7592706680297852
Batch 31/64 loss: -1.5960445404052734
Batch 32/64 loss: -1.895658016204834
Batch 33/64 loss: -2.155928611755371
Batch 34/64 loss: -2.0665650367736816
Batch 35/64 loss: -1.593430519104004
Batch 36/64 loss: -1.9938688278198242
Batch 37/64 loss: -1.7527885437011719
Batch 38/64 loss: -1.7971134185791016
Batch 39/64 loss: -2.0980277061462402
Batch 40/64 loss: -2.271575927734375
Batch 41/64 loss: -2.257824420928955
Batch 42/64 loss: -1.7866897583007812
Batch 43/64 loss: -1.9725027084350586
Batch 44/64 loss: -2.0692834854125977
Batch 45/64 loss: -1.8778438568115234
Batch 46/64 loss: -2.1163601875305176
Batch 47/64 loss: -1.998809814453125
Batch 48/64 loss: -1.7790021896362305
Batch 49/64 loss: -1.9067821502685547
Batch 50/64 loss: -1.987833023071289
Batch 51/64 loss: -1.7165870666503906
Batch 52/64 loss: -1.8691024780273438
Batch 53/64 loss: -1.8454694747924805
Batch 54/64 loss: -1.6981096267700195
Batch 55/64 loss: -1.2491769790649414
Batch 56/64 loss: -1.9984121322631836
Batch 57/64 loss: -1.4820241928100586
Batch 58/64 loss: -1.850020408630371
Batch 59/64 loss: -2.007640838623047
Batch 60/64 loss: -1.7102279663085938
Batch 61/64 loss: -1.3914823532104492
Batch 62/64 loss: -1.829315185546875
Batch 63/64 loss: -1.7086687088012695
Batch 64/64 loss: -5.870510101318359
Epoch 413  Train loss: -1.9182444852941176  Val loss: -2.0416155156401015
Epoch 414
-------------------------------
Batch 1/64 loss: -1.9870257377624512
Batch 2/64 loss: -1.7277631759643555
Batch 3/64 loss: -1.9525127410888672
Batch 4/64 loss: -1.4528350830078125
Batch 5/64 loss: -1.8363637924194336
Batch 6/64 loss: -1.9575557708740234
Batch 7/64 loss: -2.100888729095459
Batch 8/64 loss: -2.0555543899536133
Batch 9/64 loss: -1.4854850769042969
Batch 10/64 loss: -1.7848749160766602
Batch 11/64 loss: -1.8085670471191406
Batch 12/64 loss: -2.216104507446289
Batch 13/64 loss: -2.1836233139038086
Batch 14/64 loss: -1.8494806289672852
Batch 15/64 loss: -1.7957496643066406
Batch 16/64 loss: -1.4814996719360352
Batch 17/64 loss: -2.0993900299072266
Batch 18/64 loss: -1.9283576011657715
Batch 19/64 loss: -2.197848320007324
Batch 20/64 loss: -1.8600177764892578
Batch 21/64 loss: -2.073944091796875
Batch 22/64 loss: -1.9280786514282227
Batch 23/64 loss: -1.8282852172851562
Batch 24/64 loss: -2.1405563354492188
Batch 25/64 loss: -1.883784294128418
Batch 26/64 loss: -1.9790668487548828
Batch 27/64 loss: -2.0184645652770996
Batch 28/64 loss: -2.0561695098876953
Batch 29/64 loss: -1.337575912475586
Batch 30/64 loss: -1.993821144104004
Batch 31/64 loss: -1.9253044128417969
Batch 32/64 loss: -2.1796927452087402
Batch 33/64 loss: -1.7370777130126953
Batch 34/64 loss: -1.9804677963256836
Batch 35/64 loss: -1.9850530624389648
Batch 36/64 loss: -1.7106409072875977
Batch 37/64 loss: -1.7237768173217773
Batch 38/64 loss: -1.71356201171875
Batch 39/64 loss: -1.7214045524597168
Batch 40/64 loss: -1.4017457962036133
Batch 41/64 loss: -1.8462409973144531
Batch 42/64 loss: -1.9361238479614258
Batch 43/64 loss: -1.9330687522888184
Batch 44/64 loss: -1.791295051574707
Batch 45/64 loss: -1.9379472732543945
Batch 46/64 loss: -1.893294334411621
Batch 47/64 loss: -2.0928220748901367
Batch 48/64 loss: -1.6644139289855957
Batch 49/64 loss: -2.2317328453063965
Batch 50/64 loss: -2.1528425216674805
Batch 51/64 loss: -1.7170324325561523
Batch 52/64 loss: -2.2580108642578125
Batch 53/64 loss: -1.915083885192871
Batch 54/64 loss: -1.7087326049804688
Batch 55/64 loss: -2.0438365936279297
Batch 56/64 loss: -1.873673439025879
Batch 57/64 loss: -2.1539697647094727
Batch 58/64 loss: -1.5326833724975586
Batch 59/64 loss: -2.103334903717041
Batch 60/64 loss: -1.7992873191833496
Batch 61/64 loss: -1.936436653137207
Batch 62/64 loss: -2.099857807159424
Batch 63/64 loss: -1.8116397857666016
Batch 64/64 loss: -5.463161945343018
Epoch 414  Train loss: -1.9389914176043341  Val loss: -2.1263521856458736
Epoch 415
-------------------------------
Batch 1/64 loss: -1.8310527801513672
Batch 2/64 loss: -2.13712739944458
Batch 3/64 loss: -2.0221095085144043
Batch 4/64 loss: -1.6906375885009766
Batch 5/64 loss: -2.02951717376709
Batch 6/64 loss: -1.869563102722168
Batch 7/64 loss: -2.0828452110290527
Batch 8/64 loss: -1.3703699111938477
Batch 9/64 loss: -2.0234017372131348
Batch 10/64 loss: -1.807699203491211
Batch 11/64 loss: -1.9669227600097656
Batch 12/64 loss: -1.8326482772827148
Batch 13/64 loss: -1.6304197311401367
Batch 14/64 loss: -2.0789265632629395
Batch 15/64 loss: -1.7988300323486328
Batch 16/64 loss: -1.9309806823730469
Batch 17/64 loss: -2.0969276428222656
Batch 18/64 loss: -1.7847213745117188
Batch 19/64 loss: -1.7697906494140625
Batch 20/64 loss: -1.8646879196166992
Batch 21/64 loss: -1.8924479484558105
Batch 22/64 loss: -1.7004337310791016
Batch 23/64 loss: -1.6961174011230469
Batch 24/64 loss: -2.090993881225586
Batch 25/64 loss: -2.1042356491088867
Batch 26/64 loss: -1.852940559387207
Batch 27/64 loss: -1.9923148155212402
Batch 28/64 loss: -2.1192026138305664
Batch 29/64 loss: -1.7420730590820312
Batch 30/64 loss: -1.6529064178466797
Batch 31/64 loss: -2.0850863456726074
Batch 32/64 loss: -1.8362712860107422
Batch 33/64 loss: -1.6716136932373047
Batch 34/64 loss: -2.025146484375
Batch 35/64 loss: -1.9647860527038574
Batch 36/64 loss: -1.7970542907714844
Batch 37/64 loss: -1.939119815826416
Batch 38/64 loss: -2.046600341796875
Batch 39/64 loss: -1.6287965774536133
Batch 40/64 loss: -1.9400634765625
Batch 41/64 loss: -1.6042041778564453
Batch 42/64 loss: -1.561513900756836
Batch 43/64 loss: -1.6416358947753906
Batch 44/64 loss: -2.151151657104492
Batch 45/64 loss: -1.623483657836914
Batch 46/64 loss: -2.0521907806396484
Batch 47/64 loss: -1.9401483535766602
Batch 48/64 loss: -2.1717796325683594
Batch 49/64 loss: -1.9575262069702148
Batch 50/64 loss: -1.2428369522094727
Batch 51/64 loss: -1.9700055122375488
Batch 52/64 loss: -1.9797916412353516
Batch 53/64 loss: -1.9743947982788086
Batch 54/64 loss: -2.0620574951171875
Batch 55/64 loss: -1.9484233856201172
Batch 56/64 loss: -1.7063417434692383
Batch 57/64 loss: -1.7953119277954102
Batch 58/64 loss: -2.052964210510254
Batch 59/64 loss: -1.9598379135131836
Batch 60/64 loss: -1.787644386291504
Batch 61/64 loss: -2.0072221755981445
Batch 62/64 loss: -1.9852204322814941
Batch 63/64 loss: -1.8518686294555664
Batch 64/64 loss: -6.160674095153809
Epoch 415  Train loss: -1.9301246231677485  Val loss: -1.8736934858499115
Epoch 416
-------------------------------
Batch 1/64 loss: -1.493936538696289
Batch 2/64 loss: -1.8710651397705078
Batch 3/64 loss: -1.9718379974365234
Batch 4/64 loss: -1.863539695739746
Batch 5/64 loss: -1.1250534057617188
Batch 6/64 loss: -1.9605140686035156
Batch 7/64 loss: -1.7425365447998047
Batch 8/64 loss: -2.2526650428771973
Batch 9/64 loss: -1.7758045196533203
Batch 10/64 loss: -1.7227344512939453
Batch 11/64 loss: -1.9173269271850586
Batch 12/64 loss: -2.11966609954834
Batch 13/64 loss: -1.7805213928222656
Batch 14/64 loss: -1.4066963195800781
Batch 15/64 loss: -2.1811370849609375
Batch 16/64 loss: -1.9106473922729492
Batch 17/64 loss: -1.9269771575927734
Batch 18/64 loss: -2.0021615028381348
Batch 19/64 loss: -1.823476791381836
Batch 20/64 loss: -2.090550422668457
Batch 21/64 loss: -2.0713210105895996
Batch 22/64 loss: -1.5939712524414062
Batch 23/64 loss: -1.8459091186523438
Batch 24/64 loss: -1.7859268188476562
Batch 25/64 loss: -1.6211490631103516
Batch 26/64 loss: -1.6900062561035156
Batch 27/64 loss: -2.100386619567871
Batch 28/64 loss: -1.9334087371826172
Batch 29/64 loss: -1.7180051803588867
Batch 30/64 loss: -1.8966989517211914
Batch 31/64 loss: -1.645186424255371
Batch 32/64 loss: -1.8315715789794922
Batch 33/64 loss: -1.864333152770996
Batch 34/64 loss: -1.948836326599121
Batch 35/64 loss: -1.7390317916870117
Batch 36/64 loss: -1.276712417602539
Batch 37/64 loss: -1.8570194244384766
Batch 38/64 loss: -1.8687143325805664
Batch 39/64 loss: -1.5931224822998047
Batch 40/64 loss: -1.7566843032836914
Batch 41/64 loss: -1.6034164428710938
Batch 42/64 loss: -1.880843162536621
Batch 43/64 loss: -1.9961023330688477
Batch 44/64 loss: -2.1416993141174316
Batch 45/64 loss: -2.039933204650879
Batch 46/64 loss: -1.5858869552612305
Batch 47/64 loss: -1.9150066375732422
Batch 48/64 loss: -1.9247832298278809
Batch 49/64 loss: -2.017742156982422
Batch 50/64 loss: -1.7163581848144531
Batch 51/64 loss: -2.070709228515625
Batch 52/64 loss: -1.5790433883666992
Batch 53/64 loss: -1.5745048522949219
Batch 54/64 loss: -1.8809194564819336
Batch 55/64 loss: -1.0884780883789062
Batch 56/64 loss: -1.8933696746826172
Batch 57/64 loss: -2.0977349281311035
Batch 58/64 loss: -1.8365745544433594
Batch 59/64 loss: -1.9303336143493652
Batch 60/64 loss: -1.7417244911193848
Batch 61/64 loss: -2.1475038528442383
Batch 62/64 loss: -1.8552837371826172
Batch 63/64 loss: -2.060757637023926
Batch 64/64 loss: -6.0539870262146
Epoch 416  Train loss: -1.8775849903331083  Val loss: -2.110461493947662
Epoch 417
-------------------------------
Batch 1/64 loss: -1.8252758979797363
Batch 2/64 loss: -1.8444128036499023
Batch 3/64 loss: -1.7596778869628906
Batch 4/64 loss: -1.8428659439086914
Batch 5/64 loss: -1.967146873474121
Batch 6/64 loss: -1.7809572219848633
Batch 7/64 loss: -2.200413703918457
Batch 8/64 loss: -1.9367237091064453
Batch 9/64 loss: -1.4867830276489258
Batch 10/64 loss: -1.8058128356933594
Batch 11/64 loss: -1.8521223068237305
Batch 12/64 loss: -1.92095947265625
Batch 13/64 loss: -1.8404273986816406
Batch 14/64 loss: -2.2607412338256836
Batch 15/64 loss: -1.7971420288085938
Batch 16/64 loss: -1.6609182357788086
Batch 17/64 loss: -1.730865478515625
Batch 18/64 loss: -1.044637680053711
Batch 19/64 loss: -2.0511112213134766
Batch 20/64 loss: -1.9641194343566895
Batch 21/64 loss: -1.9833345413208008
Batch 22/64 loss: -1.8709259033203125
Batch 23/64 loss: -1.9127874374389648
Batch 24/64 loss: -2.053783416748047
Batch 25/64 loss: -1.9239516258239746
Batch 26/64 loss: -1.8815412521362305
Batch 27/64 loss: -1.731201171875
Batch 28/64 loss: -1.6601600646972656
Batch 29/64 loss: -1.3228816986083984
Batch 30/64 loss: -1.9255399703979492
Batch 31/64 loss: -1.9147562980651855
Batch 32/64 loss: -2.0148773193359375
Batch 33/64 loss: -1.8466253280639648
Batch 34/64 loss: -1.8380088806152344
Batch 35/64 loss: -1.8131341934204102
Batch 36/64 loss: -1.7435941696166992
Batch 37/64 loss: -1.8918581008911133
Batch 38/64 loss: -2.1351866722106934
Batch 39/64 loss: -1.608499526977539
Batch 40/64 loss: -2.2007226943969727
Batch 41/64 loss: -1.9000415802001953
Batch 42/64 loss: -1.8394966125488281
Batch 43/64 loss: -1.9117326736450195
Batch 44/64 loss: -1.8601446151733398
Batch 45/64 loss: -1.9754562377929688
Batch 46/64 loss: -1.6199455261230469
Batch 47/64 loss: -1.7054376602172852
Batch 48/64 loss: -1.7864885330200195
Batch 49/64 loss: -1.8338394165039062
Batch 50/64 loss: -1.4167060852050781
Batch 51/64 loss: -1.8738317489624023
Batch 52/64 loss: -1.4654464721679688
Batch 53/64 loss: -1.9803180694580078
Batch 54/64 loss: -1.9204888343811035
Batch 55/64 loss: -1.9456777572631836
Batch 56/64 loss: -2.030627727508545
Batch 57/64 loss: -1.6002960205078125
Batch 58/64 loss: -1.7626876831054688
Batch 59/64 loss: -2.061178207397461
Batch 60/64 loss: -1.7101449966430664
Batch 61/64 loss: -1.5673646926879883
Batch 62/64 loss: -1.987166404724121
Batch 63/64 loss: -1.6441869735717773
Batch 64/64 loss: -5.852825164794922
Epoch 417  Train loss: -1.8766244402118757  Val loss: -2.047519107045177
Epoch 418
-------------------------------
Batch 1/64 loss: -1.988851547241211
Batch 2/64 loss: -1.7689971923828125
Batch 3/64 loss: -1.956223487854004
Batch 4/64 loss: -1.7172460556030273
Batch 5/64 loss: -1.5611248016357422
Batch 6/64 loss: -1.0000505447387695
Batch 7/64 loss: -1.8795833587646484
Batch 8/64 loss: -1.8882637023925781
Batch 9/64 loss: -2.005608081817627
Batch 10/64 loss: -1.9970602989196777
Batch 11/64 loss: -1.852799415588379
Batch 12/64 loss: -1.9758882522583008
Batch 13/64 loss: -2.010356903076172
Batch 14/64 loss: -1.8764429092407227
Batch 15/64 loss: -1.802868366241455
Batch 16/64 loss: -1.7816543579101562
Batch 17/64 loss: -1.9551773071289062
Batch 18/64 loss: -1.8691730499267578
Batch 19/64 loss: -1.6818199157714844
Batch 20/64 loss: -1.7714815139770508
Batch 21/64 loss: -1.9708552360534668
Batch 22/64 loss: -2.0731372833251953
Batch 23/64 loss: -1.961629867553711
Batch 24/64 loss: -1.5575666427612305
Batch 25/64 loss: -1.8141899108886719
Batch 26/64 loss: -1.8327960968017578
Batch 27/64 loss: -2.179264545440674
Batch 28/64 loss: -1.9698891639709473
Batch 29/64 loss: -1.9240946769714355
Batch 30/64 loss: -1.7633647918701172
Batch 31/64 loss: -2.1593265533447266
Batch 32/64 loss: -1.5993461608886719
Batch 33/64 loss: -1.5005617141723633
Batch 34/64 loss: -1.858656883239746
Batch 35/64 loss: -1.6978950500488281
Batch 36/64 loss: -2.093266487121582
Batch 37/64 loss: -1.9237842559814453
Batch 38/64 loss: -1.9370012283325195
Batch 39/64 loss: -2.0185909271240234
Batch 40/64 loss: -1.984635353088379
Batch 41/64 loss: -1.8759994506835938
Batch 42/64 loss: -1.9264850616455078
Batch 43/64 loss: -1.479802131652832
Batch 44/64 loss: -1.7708959579467773
Batch 45/64 loss: -1.7416906356811523
Batch 46/64 loss: -1.7918243408203125
Batch 47/64 loss: -1.968698501586914
Batch 48/64 loss: -1.9975929260253906
Batch 49/64 loss: -1.9860224723815918
Batch 50/64 loss: -1.9475202560424805
Batch 51/64 loss: -2.080137252807617
Batch 52/64 loss: -2.0453310012817383
Batch 53/64 loss: -2.0985193252563477
Batch 54/64 loss: -2.0623903274536133
Batch 55/64 loss: -1.4127883911132812
Batch 56/64 loss: -2.17718505859375
Batch 57/64 loss: -1.4493904113769531
Batch 58/64 loss: -2.0295820236206055
Batch 59/64 loss: -1.8189420700073242
Batch 60/64 loss: -1.662745475769043
Batch 61/64 loss: -1.6594791412353516
Batch 62/64 loss: -1.962895393371582
Batch 63/64 loss: -2.0540385246276855
Batch 64/64 loss: -5.847015380859375
Epoch 418  Train loss: -1.9065998675776463  Val loss: -2.0774004303712617
Epoch 419
-------------------------------
Batch 1/64 loss: -1.7938084602355957
Batch 2/64 loss: -2.1678266525268555
Batch 3/64 loss: -2.0581164360046387
Batch 4/64 loss: -1.6588268280029297
Batch 5/64 loss: -1.8362884521484375
Batch 6/64 loss: -1.6797080039978027
Batch 7/64 loss: -1.8272933959960938
Batch 8/64 loss: -1.5211715698242188
Batch 9/64 loss: -2.0968427658081055
Batch 10/64 loss: -1.4810791015625
Batch 11/64 loss: -1.9777812957763672
Batch 12/64 loss: -1.7675771713256836
Batch 13/64 loss: -1.8996973037719727
Batch 14/64 loss: -2.0216150283813477
Batch 15/64 loss: -1.8073339462280273
Batch 16/64 loss: -1.689493179321289
Batch 17/64 loss: -1.6902141571044922
Batch 18/64 loss: -1.9407100677490234
Batch 19/64 loss: -1.77630615234375
Batch 20/64 loss: -1.6988344192504883
Batch 21/64 loss: -1.901371955871582
Batch 22/64 loss: -1.4581022262573242
Batch 23/64 loss: -1.9785823822021484
Batch 24/64 loss: -2.1037254333496094
Batch 25/64 loss: -1.7934494018554688
Batch 26/64 loss: -1.8922624588012695
Batch 27/64 loss: -1.1494455337524414
Batch 28/64 loss: -1.6818342208862305
Batch 29/64 loss: -1.9228944778442383
Batch 30/64 loss: -1.9179067611694336
Batch 31/64 loss: -2.127861499786377
Batch 32/64 loss: -1.7194347381591797
Batch 33/64 loss: -1.4838571548461914
Batch 34/64 loss: -2.048358917236328
Batch 35/64 loss: -1.8114261627197266
Batch 36/64 loss: -1.963994026184082
Batch 37/64 loss: -2.1300926208496094
Batch 38/64 loss: -1.7975006103515625
Batch 39/64 loss: -1.6480636596679688
Batch 40/64 loss: -1.6009464263916016
Batch 41/64 loss: -1.3058691024780273
Batch 42/64 loss: -1.7486648559570312
Batch 43/64 loss: -1.7792253494262695
Batch 44/64 loss: -1.8421287536621094
Batch 45/64 loss: -1.954080581665039
Batch 46/64 loss: -1.7653546333312988
Batch 47/64 loss: -1.9564170837402344
Batch 48/64 loss: -1.9403257369995117
Batch 49/64 loss: -1.6536130905151367
Batch 50/64 loss: -1.917149543762207
Batch 51/64 loss: -1.9548912048339844
Batch 52/64 loss: -1.7886857986450195
Batch 53/64 loss: -1.6910209655761719
Batch 54/64 loss: -1.6059646606445312
Batch 55/64 loss: -1.8233451843261719
Batch 56/64 loss: -1.9251794815063477
Batch 57/64 loss: -1.555394172668457
Batch 58/64 loss: -1.5469045639038086
Batch 59/64 loss: -2.070241928100586
Batch 60/64 loss: -1.893296241760254
Batch 61/64 loss: -1.6614904403686523
Batch 62/64 loss: -1.9378166198730469
Batch 63/64 loss: -1.7180085182189941
Batch 64/64 loss: -6.053409576416016
Epoch 419  Train loss: -1.852498207840265  Val loss: -2.0463161796228992
Epoch 420
-------------------------------
Batch 1/64 loss: -2.100296974182129
Batch 2/64 loss: -1.9023504257202148
Batch 3/64 loss: -1.8748455047607422
Batch 4/64 loss: -2.10117244720459
Batch 5/64 loss: -2.0506486892700195
Batch 6/64 loss: -1.6703472137451172
Batch 7/64 loss: -1.8799324035644531
Batch 8/64 loss: -1.7721261978149414
Batch 9/64 loss: -1.8048028945922852
Batch 10/64 loss: -1.8851451873779297
Batch 11/64 loss: -2.087017059326172
Batch 12/64 loss: -1.9259791374206543
Batch 13/64 loss: -1.9593496322631836
Batch 14/64 loss: -1.1925392150878906
Batch 15/64 loss: -2.0185279846191406
Batch 16/64 loss: -2.0435004234313965
Batch 17/64 loss: -2.080264091491699
Batch 18/64 loss: -1.843282699584961
Batch 19/64 loss: -2.0805697441101074
Batch 20/64 loss: -1.6298847198486328
Batch 21/64 loss: -1.8997488021850586
Batch 22/64 loss: -1.8169612884521484
Batch 23/64 loss: -1.7836236953735352
Batch 24/64 loss: -1.516587257385254
Batch 25/64 loss: -1.8103485107421875
Batch 26/64 loss: -1.8185062408447266
Batch 27/64 loss: -1.6982612609863281
Batch 28/64 loss: -1.9715166091918945
Batch 29/64 loss: -2.1223931312561035
Batch 30/64 loss: -1.5932340621948242
Batch 31/64 loss: -1.6299676895141602
Batch 32/64 loss: -1.7069263458251953
Batch 33/64 loss: -1.8355884552001953
Batch 34/64 loss: -1.735466480255127
Batch 35/64 loss: -1.975295066833496
Batch 36/64 loss: -1.8927078247070312
Batch 37/64 loss: -1.3401861190795898
Batch 38/64 loss: -1.9214715957641602
Batch 39/64 loss: -1.7658624649047852
Batch 40/64 loss: -1.8088083267211914
Batch 41/64 loss: -2.013606548309326
Batch 42/64 loss: -2.103015422821045
Batch 43/64 loss: -1.3861370086669922
Batch 44/64 loss: -2.0318784713745117
Batch 45/64 loss: -1.832021713256836
Batch 46/64 loss: -1.5030460357666016
Batch 47/64 loss: -1.821537971496582
Batch 48/64 loss: -1.6066045761108398
Batch 49/64 loss: -1.8763399124145508
Batch 50/64 loss: -1.9197454452514648
Batch 51/64 loss: -1.689967155456543
Batch 52/64 loss: -1.494039535522461
Batch 53/64 loss: -1.4427118301391602
Batch 54/64 loss: -1.8677196502685547
Batch 55/64 loss: -2.085087776184082
Batch 56/64 loss: -1.482874870300293
Batch 57/64 loss: -1.8511486053466797
Batch 58/64 loss: -1.53033447265625
Batch 59/64 loss: -1.2579584121704102
Batch 60/64 loss: -1.8245363235473633
Batch 61/64 loss: -1.8403100967407227
Batch 62/64 loss: -1.9852981567382812
Batch 63/64 loss: -1.7468643188476562
Batch 64/64 loss: -5.894940376281738
Epoch 420  Train loss: -1.8534907210106943  Val loss: -1.9462075512024135
Epoch 421
-------------------------------
Batch 1/64 loss: -1.4918594360351562
Batch 2/64 loss: -1.8690261840820312
Batch 3/64 loss: -1.5588502883911133
Batch 4/64 loss: -1.9275703430175781
Batch 5/64 loss: -2.078479766845703
Batch 6/64 loss: -1.7396001815795898
Batch 7/64 loss: -1.8649287223815918
Batch 8/64 loss: -2.060520648956299
Batch 9/64 loss: -1.9079933166503906
Batch 10/64 loss: -2.1481714248657227
Batch 11/64 loss: -2.046060562133789
Batch 12/64 loss: -1.9392614364624023
Batch 13/64 loss: -2.0625476837158203
Batch 14/64 loss: -1.9173812866210938
Batch 15/64 loss: -1.9445686340332031
Batch 16/64 loss: -2.034134864807129
Batch 17/64 loss: -1.9449315071105957
Batch 18/64 loss: -1.9476814270019531
Batch 19/64 loss: -1.9035701751708984
Batch 20/64 loss: -2.102389335632324
Batch 21/64 loss: -1.9383964538574219
Batch 22/64 loss: -1.776597023010254
Batch 23/64 loss: -1.6847267150878906
Batch 24/64 loss: -1.9433050155639648
Batch 25/64 loss: -1.825429916381836
Batch 26/64 loss: -1.8982014656066895
Batch 27/64 loss: -1.889542579650879
Batch 28/64 loss: -2.0935792922973633
Batch 29/64 loss: -1.4949159622192383
Batch 30/64 loss: -1.9497041702270508
Batch 31/64 loss: -1.4635791778564453
Batch 32/64 loss: -1.6808128356933594
Batch 33/64 loss: -1.9810891151428223
Batch 34/64 loss: -1.862321376800537
Batch 35/64 loss: -1.6002206802368164
Batch 36/64 loss: -1.938089370727539
Batch 37/64 loss: -1.679184913635254
Batch 38/64 loss: -1.7713661193847656
Batch 39/64 loss: -1.5698041915893555
Batch 40/64 loss: -1.7496147155761719
Batch 41/64 loss: -1.7179880142211914
Batch 42/64 loss: -1.7431659698486328
Batch 43/64 loss: -1.6594667434692383
Batch 44/64 loss: -1.9110298156738281
Batch 45/64 loss: -1.8871698379516602
Batch 46/64 loss: -1.9576587677001953
Batch 47/64 loss: -2.152379035949707
Batch 48/64 loss: -1.9574651718139648
Batch 49/64 loss: -1.7558412551879883
Batch 50/64 loss: -2.1068124771118164
Batch 51/64 loss: -1.8356680870056152
Batch 52/64 loss: -1.865213394165039
Batch 53/64 loss: -1.738168716430664
Batch 54/64 loss: -2.0830512046813965
Batch 55/64 loss: -1.8050823211669922
Batch 56/64 loss: -1.4555416107177734
Batch 57/64 loss: -1.8012919425964355
Batch 58/64 loss: -1.9589996337890625
Batch 59/64 loss: -2.117757797241211
Batch 60/64 loss: -1.9288053512573242
Batch 61/64 loss: -1.922785758972168
Batch 62/64 loss: -1.7448854446411133
Batch 63/64 loss: -2.0220746994018555
Batch 64/64 loss: -6.127105236053467
Epoch 421  Train loss: -1.9137825928482355  Val loss: -2.0672904339033304
Epoch 422
-------------------------------
Batch 1/64 loss: -1.9462432861328125
Batch 2/64 loss: -1.9443340301513672
Batch 3/64 loss: -1.9845314025878906
Batch 4/64 loss: -2.1078081130981445
Batch 5/64 loss: -2.0242037773132324
Batch 6/64 loss: -2.002826690673828
Batch 7/64 loss: -1.9360589981079102
Batch 8/64 loss: -1.6778955459594727
Batch 9/64 loss: -1.8797922134399414
Batch 10/64 loss: -1.7306737899780273
Batch 11/64 loss: -1.7692642211914062
Batch 12/64 loss: -2.0618810653686523
Batch 13/64 loss: -1.730478286743164
Batch 14/64 loss: -1.8689498901367188
Batch 15/64 loss: -1.729949951171875
Batch 16/64 loss: -1.6121149063110352
Batch 17/64 loss: -1.7718563079833984
Batch 18/64 loss: -1.9095396995544434
Batch 19/64 loss: -1.9131083488464355
Batch 20/64 loss: -1.7819595336914062
Batch 21/64 loss: -1.5734386444091797
Batch 22/64 loss: -1.9555578231811523
Batch 23/64 loss: -1.5485315322875977
Batch 24/64 loss: -1.8196783065795898
Batch 25/64 loss: -1.8825135231018066
Batch 26/64 loss: -1.8500661849975586
Batch 27/64 loss: -1.808645248413086
Batch 28/64 loss: -1.9103288650512695
Batch 29/64 loss: -1.5387544631958008
Batch 30/64 loss: -2.0561442375183105
Batch 31/64 loss: -1.6386451721191406
Batch 32/64 loss: -1.5170907974243164
Batch 33/64 loss: -1.825901985168457
Batch 34/64 loss: -1.7301206588745117
Batch 35/64 loss: -1.7559337615966797
Batch 36/64 loss: -1.7086076736450195
Batch 37/64 loss: -1.6664257049560547
Batch 38/64 loss: -1.6632328033447266
Batch 39/64 loss: -1.7980022430419922
Batch 40/64 loss: -2.089980125427246
Batch 41/64 loss: -1.8495216369628906
Batch 42/64 loss: -1.854233741760254
Batch 43/64 loss: -1.9664878845214844
Batch 44/64 loss: -1.9395761489868164
Batch 45/64 loss: -1.8933963775634766
Batch 46/64 loss: -1.9458723068237305
Batch 47/64 loss: -1.9403610229492188
Batch 48/64 loss: -1.7456512451171875
Batch 49/64 loss: -1.9408550262451172
Batch 50/64 loss: -1.8337469100952148
Batch 51/64 loss: -1.9720325469970703
Batch 52/64 loss: -1.7779827117919922
Batch 53/64 loss: -2.006045341491699
Batch 54/64 loss: -1.8104915618896484
Batch 55/64 loss: -1.887237548828125
Batch 56/64 loss: -1.8743743896484375
Batch 57/64 loss: -1.8899197578430176
Batch 58/64 loss: -2.1190223693847656
Batch 59/64 loss: -1.9401626586914062
Batch 60/64 loss: -1.6298904418945312
Batch 61/64 loss: -1.756728172302246
Batch 62/64 loss: -1.9815359115600586
Batch 63/64 loss: -1.9559097290039062
Batch 64/64 loss: -6.025887966156006
Epoch 422  Train loss: -1.8941415094861798  Val loss: -2.12967107713837
Epoch 423
-------------------------------
Batch 1/64 loss: -1.605778694152832
Batch 2/64 loss: -1.6718835830688477
Batch 3/64 loss: -2.148209571838379
Batch 4/64 loss: -1.5636167526245117
Batch 5/64 loss: -1.886758804321289
Batch 6/64 loss: -1.4449176788330078
Batch 7/64 loss: -1.521230697631836
Batch 8/64 loss: -1.7718000411987305
Batch 9/64 loss: -1.7019405364990234
Batch 10/64 loss: -1.3059873580932617
Batch 11/64 loss: -2.1363115310668945
Batch 12/64 loss: -2.017350196838379
Batch 13/64 loss: -1.8260555267333984
Batch 14/64 loss: -1.8605852127075195
Batch 15/64 loss: -1.9870429039001465
Batch 16/64 loss: -1.8668794631958008
Batch 17/64 loss: -1.9956049919128418
Batch 18/64 loss: -1.8144140243530273
Batch 19/64 loss: -1.8249359130859375
Batch 20/64 loss: -1.6947965621948242
Batch 21/64 loss: -1.8260488510131836
Batch 22/64 loss: -1.8874988555908203
Batch 23/64 loss: -2.0114078521728516
Batch 24/64 loss: -2.1545944213867188
Batch 25/64 loss: -1.8641862869262695
Batch 26/64 loss: -1.372298240661621
Batch 27/64 loss: -1.927006721496582
Batch 28/64 loss: -1.7348222732543945
Batch 29/64 loss: -2.030649185180664
Batch 30/64 loss: -1.6179800033569336
Batch 31/64 loss: -1.5066556930541992
Batch 32/64 loss: -1.4365262985229492
Batch 33/64 loss: -2.0308380126953125
Batch 34/64 loss: -2.0280795097351074
Batch 35/64 loss: -1.7520103454589844
Batch 36/64 loss: -2.090099811553955
Batch 37/64 loss: -1.912229061126709
Batch 38/64 loss: -2.2673215866088867
Batch 39/64 loss: -2.1580471992492676
Batch 40/64 loss: -1.8404970169067383
Batch 41/64 loss: -1.8699865341186523
Batch 42/64 loss: -1.9218626022338867
Batch 43/64 loss: -2.0264158248901367
Batch 44/64 loss: -1.608449935913086
Batch 45/64 loss: -2.033337116241455
Batch 46/64 loss: -1.8523755073547363
Batch 47/64 loss: -1.8885612487792969
Batch 48/64 loss: -1.1171493530273438
Batch 49/64 loss: -1.901510238647461
Batch 50/64 loss: -1.8377914428710938
Batch 51/64 loss: -2.0113525390625
Batch 52/64 loss: -1.8517308235168457
Batch 53/64 loss: -1.7672128677368164
Batch 54/64 loss: -1.9717025756835938
Batch 55/64 loss: -1.7318954467773438
Batch 56/64 loss: -1.8866181373596191
Batch 57/64 loss: -1.6441879272460938
Batch 58/64 loss: -2.0500845909118652
Batch 59/64 loss: -1.951162338256836
Batch 60/64 loss: -1.7725844383239746
Batch 61/64 loss: -1.8868646621704102
Batch 62/64 loss: -2.180604934692383
Batch 63/64 loss: -1.8669328689575195
Batch 64/64 loss: -5.863641738891602
Epoch 423  Train loss: -1.884282392614028  Val loss: -1.99045094755507
Epoch 424
-------------------------------
Batch 1/64 loss: -1.8229265213012695
Batch 2/64 loss: -1.9966988563537598
Batch 3/64 loss: -1.808675765991211
Batch 4/64 loss: -1.8482494354248047
Batch 5/64 loss: -1.6104917526245117
Batch 6/64 loss: -2.0117125511169434
Batch 7/64 loss: -1.8285980224609375
Batch 8/64 loss: -2.1438169479370117
Batch 9/64 loss: -1.926253318786621
Batch 10/64 loss: -1.9629936218261719
Batch 11/64 loss: -1.8221063613891602
Batch 12/64 loss: -1.7208800315856934
Batch 13/64 loss: -1.8148584365844727
Batch 14/64 loss: -1.98583984375
Batch 15/64 loss: -1.947373867034912
Batch 16/64 loss: -1.7262248992919922
Batch 17/64 loss: -1.9031305313110352
Batch 18/64 loss: -1.8130979537963867
Batch 19/64 loss: -1.898524284362793
Batch 20/64 loss: -1.940922737121582
Batch 21/64 loss: -1.9953641891479492
Batch 22/64 loss: -1.835270881652832
Batch 23/64 loss: -1.570530891418457
Batch 24/64 loss: -1.7502574920654297
Batch 25/64 loss: -1.9133658409118652
Batch 26/64 loss: -1.8170242309570312
Batch 27/64 loss: -1.4346561431884766
Batch 28/64 loss: -1.798006534576416
Batch 29/64 loss: -1.749232292175293
Batch 30/64 loss: -1.5983552932739258
Batch 31/64 loss: -1.6725654602050781
Batch 32/64 loss: -1.8278288841247559
Batch 33/64 loss: -1.8987312316894531
Batch 34/64 loss: -1.7515931129455566
Batch 35/64 loss: -1.8792328834533691
Batch 36/64 loss: -1.9263877868652344
Batch 37/64 loss: -1.794936180114746
Batch 38/64 loss: -1.7684450149536133
Batch 39/64 loss: -1.8890933990478516
Batch 40/64 loss: -1.9125189781188965
Batch 41/64 loss: -1.7402591705322266
Batch 42/64 loss: -1.939131736755371
Batch 43/64 loss: -1.6761550903320312
Batch 44/64 loss: -1.8319849967956543
Batch 45/64 loss: -1.9360246658325195
Batch 46/64 loss: -1.7555856704711914
Batch 47/64 loss: -1.967470645904541
Batch 48/64 loss: -1.7906789779663086
Batch 49/64 loss: -1.9475202560424805
Batch 50/64 loss: -1.575383186340332
Batch 51/64 loss: -1.8191814422607422
Batch 52/64 loss: -1.7671022415161133
Batch 53/64 loss: -1.8901424407958984
Batch 54/64 loss: -1.7586069107055664
Batch 55/64 loss: -1.8168087005615234
Batch 56/64 loss: -1.436936378479004
Batch 57/64 loss: -1.958186149597168
Batch 58/64 loss: -1.8265495300292969
Batch 59/64 loss: -1.6740293502807617
Batch 60/64 loss: -1.6215295791625977
Batch 61/64 loss: -1.8159971237182617
Batch 62/64 loss: -1.8611326217651367
Batch 63/64 loss: -1.8741846084594727
Batch 64/64 loss: -5.6747026443481445
Epoch 424  Train loss: -1.8643667595059263  Val loss: -1.9457855748966388
Epoch 425
-------------------------------
Batch 1/64 loss: -1.7502813339233398
Batch 2/64 loss: -1.9124603271484375
Batch 3/64 loss: -1.8571958541870117
Batch 4/64 loss: -1.6797552108764648
Batch 5/64 loss: -1.445648193359375
Batch 6/64 loss: -1.4372148513793945
Batch 7/64 loss: -2.153346538543701
Batch 8/64 loss: -1.7235307693481445
Batch 9/64 loss: -1.5288419723510742
Batch 10/64 loss: -1.6962041854858398
Batch 11/64 loss: -1.7110071182250977
Batch 12/64 loss: -2.0459632873535156
Batch 13/64 loss: -1.3224363327026367
Batch 14/64 loss: -1.921539306640625
Batch 15/64 loss: -1.857818603515625
Batch 16/64 loss: -1.9225859642028809
Batch 17/64 loss: -1.665269374847412
Batch 18/64 loss: -1.7286887168884277
Batch 19/64 loss: -1.3652582168579102
Batch 20/64 loss: -1.7128801345825195
Batch 21/64 loss: -1.5215625762939453
Batch 22/64 loss: -1.9749412536621094
Batch 23/64 loss: -1.8431663513183594
Batch 24/64 loss: -1.8639583587646484
Batch 25/64 loss: -2.1830172538757324
Batch 26/64 loss: -1.832019329071045
Batch 27/64 loss: -1.8126578330993652
Batch 28/64 loss: -1.9123029708862305
Batch 29/64 loss: -1.9194226264953613
Batch 30/64 loss: -1.932206153869629
Batch 31/64 loss: -2.2900314331054688
Batch 32/64 loss: -1.9974370002746582
Batch 33/64 loss: -1.7715034484863281
Batch 34/64 loss: -2.0710134506225586
Batch 35/64 loss: -1.5809698104858398
Batch 36/64 loss: -1.8064584732055664
Batch 37/64 loss: -1.7799711227416992
Batch 38/64 loss: -1.868506908416748
Batch 39/64 loss: -1.7211289405822754
Batch 40/64 loss: -1.2152929306030273
Batch 41/64 loss: -1.8843731880187988
Batch 42/64 loss: -1.976837158203125
Batch 43/64 loss: -1.4363794326782227
Batch 44/64 loss: -1.527388572692871
Batch 45/64 loss: -1.7903738021850586
Batch 46/64 loss: -1.9932799339294434
Batch 47/64 loss: -1.7803850173950195
Batch 48/64 loss: -1.9644126892089844
Batch 49/64 loss: -2.077852725982666
Batch 50/64 loss: -1.7413387298583984
Batch 51/64 loss: -1.7051153182983398
Batch 52/64 loss: -1.9759821891784668
Batch 53/64 loss: -1.8855390548706055
Batch 54/64 loss: -1.5762720108032227
Batch 55/64 loss: -1.8594493865966797
Batch 56/64 loss: -1.4199867248535156
Batch 57/64 loss: -2.0263705253601074
Batch 58/64 loss: -1.501744270324707
Batch 59/64 loss: -2.005922317504883
Batch 60/64 loss: -1.8269610404968262
Batch 61/64 loss: -1.9261970520019531
Batch 62/64 loss: -1.3117198944091797
Batch 63/64 loss: -1.4537830352783203
Batch 64/64 loss: -6.031256198883057
Epoch 425  Train loss: -1.827554521373674  Val loss: -1.917911214926808
Epoch 426
-------------------------------
Batch 1/64 loss: -1.8493680953979492
Batch 2/64 loss: -1.3751659393310547
Batch 3/64 loss: -1.5450525283813477
Batch 4/64 loss: -1.6051054000854492
Batch 5/64 loss: -1.1855592727661133
Batch 6/64 loss: -1.8992085456848145
Batch 7/64 loss: -2.0507569313049316
Batch 8/64 loss: -1.7619543075561523
Batch 9/64 loss: -1.7269878387451172
Batch 10/64 loss: -1.7602944374084473
Batch 11/64 loss: -1.8254237174987793
Batch 12/64 loss: -1.4838027954101562
Batch 13/64 loss: -1.8968615531921387
Batch 14/64 loss: -1.8992905616760254
Batch 15/64 loss: -1.9752559661865234
Batch 16/64 loss: -1.917952060699463
Batch 17/64 loss: -1.4142837524414062
Batch 18/64 loss: -1.598555564880371
Batch 19/64 loss: -1.7688426971435547
Batch 20/64 loss: -1.9995336532592773
Batch 21/64 loss: -1.8139886856079102
Batch 22/64 loss: -1.9885406494140625
Batch 23/64 loss: -1.918189525604248
Batch 24/64 loss: -1.8448982238769531
Batch 25/64 loss: -1.650456428527832
Batch 26/64 loss: -1.6678466796875
Batch 27/64 loss: -1.7913870811462402
Batch 28/64 loss: -1.1621122360229492
Batch 29/64 loss: -1.3857898712158203
Batch 30/64 loss: -1.8326406478881836
Batch 31/64 loss: -1.847294807434082
Batch 32/64 loss: -2.1806387901306152
Batch 33/64 loss: -2.118579864501953
Batch 34/64 loss: -1.6589040756225586
Batch 35/64 loss: -1.793680191040039
Batch 36/64 loss: -2.0316381454467773
Batch 37/64 loss: -1.8713641166687012
Batch 38/64 loss: -2.083286762237549
Batch 39/64 loss: -1.7949962615966797
Batch 40/64 loss: -1.9500656127929688
Batch 41/64 loss: -1.8913240432739258
Batch 42/64 loss: -1.5416364669799805
Batch 43/64 loss: -1.9810614585876465
Batch 44/64 loss: -1.9451193809509277
Batch 45/64 loss: -1.736562728881836
Batch 46/64 loss: -1.5482168197631836
Batch 47/64 loss: -1.6909704208374023
Batch 48/64 loss: -2.123568058013916
Batch 49/64 loss: -1.5777225494384766
Batch 50/64 loss: -1.9597234725952148
Batch 51/64 loss: -1.6999931335449219
Batch 52/64 loss: -1.552006721496582
Batch 53/64 loss: -1.7590923309326172
Batch 54/64 loss: -1.8423538208007812
Batch 55/64 loss: -1.7391166687011719
Batch 56/64 loss: -1.7021856307983398
Batch 57/64 loss: -0.9663619995117188
Batch 58/64 loss: -1.7640705108642578
Batch 59/64 loss: -1.8997364044189453
Batch 60/64 loss: -1.8358745574951172
Batch 61/64 loss: -1.9785456657409668
Batch 62/64 loss: -1.936610221862793
Batch 63/64 loss: -1.9335908889770508
Batch 64/64 loss: -6.088043689727783
Epoch 426  Train loss: -1.8211298979964912  Val loss: -1.854068860974918
Epoch 427
-------------------------------
Batch 1/64 loss: -1.5231246948242188
Batch 2/64 loss: -1.7863445281982422
Batch 3/64 loss: -1.8826789855957031
Batch 4/64 loss: -1.7406988143920898
Batch 5/64 loss: -1.7425622940063477
Batch 6/64 loss: -2.081700325012207
Batch 7/64 loss: -1.3173103332519531
Batch 8/64 loss: -1.8331403732299805
Batch 9/64 loss: -1.8632564544677734
Batch 10/64 loss: -1.6833209991455078
Batch 11/64 loss: -1.6625947952270508
Batch 12/64 loss: -1.4885482788085938
Batch 13/64 loss: -1.8521156311035156
Batch 14/64 loss: -1.3464126586914062
Batch 15/64 loss: -1.5781793594360352
Batch 16/64 loss: -1.9679632186889648
Batch 17/64 loss: -1.7342548370361328
Batch 18/64 loss: -1.4997777938842773
Batch 19/64 loss: -1.2912750244140625
Batch 20/64 loss: -1.5621604919433594
Batch 21/64 loss: -1.569183349609375
Batch 22/64 loss: -1.396672248840332
Batch 23/64 loss: -1.2006940841674805
Batch 24/64 loss: -2.03732967376709
Batch 25/64 loss: -1.713383674621582
Batch 26/64 loss: -1.5824356079101562
Batch 27/64 loss: -1.5164251327514648
Batch 28/64 loss: -1.6371517181396484
Batch 29/64 loss: -1.8996877670288086
Batch 30/64 loss: -1.8920888900756836
Batch 31/64 loss: -1.9192914962768555
Batch 32/64 loss: -1.8245973587036133
Batch 33/64 loss: -1.6215085983276367
Batch 34/64 loss: -2.0228681564331055
Batch 35/64 loss: -1.8163957595825195
Batch 36/64 loss: -1.3997125625610352
Batch 37/64 loss: -1.8657331466674805
Batch 38/64 loss: -1.874800682067871
Batch 39/64 loss: -1.7336006164550781
Batch 40/64 loss: -2.030618667602539
Batch 41/64 loss: -2.0207104682922363
Batch 42/64 loss: -1.809988021850586
Batch 43/64 loss: -2.0711007118225098
Batch 44/64 loss: -1.4446792602539062
Batch 45/64 loss: -1.9038987159729004
Batch 46/64 loss: -1.8859710693359375
Batch 47/64 loss: -1.9347734451293945
Batch 48/64 loss: -1.6993412971496582
Batch 49/64 loss: -2.0267772674560547
Batch 50/64 loss: -1.6836490631103516
Batch 51/64 loss: -1.8446989059448242
Batch 52/64 loss: -1.9684600830078125
Batch 53/64 loss: -1.942692756652832
Batch 54/64 loss: -2.17010498046875
Batch 55/64 loss: -2.0120577812194824
Batch 56/64 loss: -1.8282055854797363
Batch 57/64 loss: -1.9830036163330078
Batch 58/64 loss: -1.9203429222106934
Batch 59/64 loss: -1.5086565017700195
Batch 60/64 loss: -1.6460294723510742
Batch 61/64 loss: -1.594374656677246
Batch 62/64 loss: -1.9233055114746094
Batch 63/64 loss: -1.7386550903320312
Batch 64/64 loss: -5.7554521560668945
Epoch 427  Train loss: -1.801877104067335  Val loss: -1.8959847020939045
Epoch 428
-------------------------------
Batch 1/64 loss: -2.060544490814209
Batch 2/64 loss: -2.064525604248047
Batch 3/64 loss: -1.5658893585205078
Batch 4/64 loss: -1.7655863761901855
Batch 5/64 loss: -1.738576889038086
Batch 6/64 loss: -1.6045684814453125
Batch 7/64 loss: -2.036868095397949
Batch 8/64 loss: -1.7763423919677734
Batch 9/64 loss: -1.7660980224609375
Batch 10/64 loss: -1.6807003021240234
Batch 11/64 loss: -1.7901544570922852
Batch 12/64 loss: -2.004793643951416
Batch 13/64 loss: -1.4995975494384766
Batch 14/64 loss: -1.8834552764892578
Batch 15/64 loss: -1.8801374435424805
Batch 16/64 loss: -1.7059392929077148
Batch 17/64 loss: -2.0826711654663086
Batch 18/64 loss: -2.137600898742676
Batch 19/64 loss: -1.6677007675170898
Batch 20/64 loss: -1.6064176559448242
Batch 21/64 loss: -1.2570486068725586
Batch 22/64 loss: -1.8416624069213867
Batch 23/64 loss: -1.4735298156738281
Batch 24/64 loss: -2.0032877922058105
Batch 25/64 loss: -1.5030508041381836
Batch 26/64 loss: -1.8210468292236328
Batch 27/64 loss: -1.72636079788208
Batch 28/64 loss: -1.9449667930603027
Batch 29/64 loss: -2.1429319381713867
Batch 30/64 loss: -1.9356842041015625
Batch 31/64 loss: -1.8812990188598633
Batch 32/64 loss: -1.8136568069458008
Batch 33/64 loss: -1.7921943664550781
Batch 34/64 loss: -1.9986510276794434
Batch 35/64 loss: -2.127749443054199
Batch 36/64 loss: -1.7904443740844727
Batch 37/64 loss: -1.7752981185913086
Batch 38/64 loss: -1.8153905868530273
Batch 39/64 loss: -1.3815126419067383
Batch 40/64 loss: -2.09871768951416
Batch 41/64 loss: -1.8344030380249023
Batch 42/64 loss: -1.4384355545043945
Batch 43/64 loss: -1.674534797668457
Batch 44/64 loss: -2.0731472969055176
Batch 45/64 loss: -2.095417022705078
Batch 46/64 loss: -1.9049973487854004
Batch 47/64 loss: -1.6331586837768555
Batch 48/64 loss: -1.6395196914672852
Batch 49/64 loss: -1.8450007438659668
Batch 50/64 loss: -1.784433364868164
Batch 51/64 loss: -2.0513601303100586
Batch 52/64 loss: -1.7681770324707031
Batch 53/64 loss: -1.9420642852783203
Batch 54/64 loss: -2.092535972595215
Batch 55/64 loss: -2.043485641479492
Batch 56/64 loss: -1.6238250732421875
Batch 57/64 loss: -1.8067026138305664
Batch 58/64 loss: -1.9599685668945312
Batch 59/64 loss: -1.6177911758422852
Batch 60/64 loss: -2.0135059356689453
Batch 61/64 loss: -1.7339258193969727
Batch 62/64 loss: -1.82208251953125
Batch 63/64 loss: -1.5285940170288086
Batch 64/64 loss: -5.939236640930176
Epoch 428  Train loss: -1.8639081730562097  Val loss: -1.9259709623671069
Epoch 429
-------------------------------
Batch 1/64 loss: -1.9105911254882812
Batch 2/64 loss: -1.7698516845703125
Batch 3/64 loss: -2.0197582244873047
Batch 4/64 loss: -2.0190649032592773
Batch 5/64 loss: -2.111985683441162
Batch 6/64 loss: -1.4703607559204102
Batch 7/64 loss: -2.0915141105651855
Batch 8/64 loss: -2.083162307739258
Batch 9/64 loss: -1.8330740928649902
Batch 10/64 loss: -1.7633752822875977
Batch 11/64 loss: -1.777313232421875
Batch 12/64 loss: -1.4301586151123047
Batch 13/64 loss: -1.8170738220214844
Batch 14/64 loss: -1.7892274856567383
Batch 15/64 loss: -1.9397153854370117
Batch 16/64 loss: -1.6117000579833984
Batch 17/64 loss: -2.0643324851989746
Batch 18/64 loss: -1.925227165222168
Batch 19/64 loss: -2.1628170013427734
Batch 20/64 loss: -1.7805490493774414
Batch 21/64 loss: -1.972599983215332
Batch 22/64 loss: -1.9522695541381836
Batch 23/64 loss: -1.8368988037109375
Batch 24/64 loss: -1.1138944625854492
Batch 25/64 loss: -2.182098388671875
Batch 26/64 loss: -1.946828842163086
Batch 27/64 loss: -1.8633556365966797
Batch 28/64 loss: -1.7480669021606445
Batch 29/64 loss: -2.2144250869750977
Batch 30/64 loss: -1.9004926681518555
Batch 31/64 loss: -1.6878948211669922
Batch 32/64 loss: -2.01578950881958
Batch 33/64 loss: -1.637181282043457
Batch 34/64 loss: -1.7548694610595703
Batch 35/64 loss: -1.9834966659545898
Batch 36/64 loss: -1.8470001220703125
Batch 37/64 loss: -1.9070358276367188
Batch 38/64 loss: -1.6483354568481445
Batch 39/64 loss: -2.0360569953918457
Batch 40/64 loss: -1.782064437866211
Batch 41/64 loss: -1.7029800415039062
Batch 42/64 loss: -2.111239433288574
Batch 43/64 loss: -1.539987564086914
Batch 44/64 loss: -1.686415195465088
Batch 45/64 loss: -1.9746112823486328
Batch 46/64 loss: -1.6728157997131348
Batch 47/64 loss: -2.080277919769287
Batch 48/64 loss: -1.7699851989746094
Batch 49/64 loss: -2.083303451538086
Batch 50/64 loss: -2.0503082275390625
Batch 51/64 loss: -1.831583023071289
Batch 52/64 loss: -1.7585697174072266
Batch 53/64 loss: -1.8664379119873047
Batch 54/64 loss: -1.7550344467163086
Batch 55/64 loss: -1.7879571914672852
Batch 56/64 loss: -1.9761428833007812
Batch 57/64 loss: -1.8690271377563477
Batch 58/64 loss: -1.943274974822998
Batch 59/64 loss: -1.4663410186767578
Batch 60/64 loss: -1.8502483367919922
Batch 61/64 loss: -1.811039924621582
Batch 62/64 loss: -1.9303083419799805
Batch 63/64 loss: -2.0933403968811035
Batch 64/64 loss: -5.2477006912231445
Epoch 429  Train loss: -1.8972315657372567  Val loss: -2.116535003242624
Epoch 430
-------------------------------
Batch 1/64 loss: -1.89007568359375
Batch 2/64 loss: -1.769247055053711
Batch 3/64 loss: -1.6267623901367188
Batch 4/64 loss: -2.158188819885254
Batch 5/64 loss: -1.8189258575439453
Batch 6/64 loss: -1.8969364166259766
Batch 7/64 loss: -1.731156349182129
Batch 8/64 loss: -2.182342529296875
Batch 9/64 loss: -2.0589451789855957
Batch 10/64 loss: -2.0172505378723145
Batch 11/64 loss: -1.7122154235839844
Batch 12/64 loss: -1.6360759735107422
Batch 13/64 loss: -1.810699462890625
Batch 14/64 loss: -1.925760269165039
Batch 15/64 loss: -1.9066362380981445
Batch 16/64 loss: -1.9391417503356934
Batch 17/64 loss: -1.972033977508545
Batch 18/64 loss: -1.8267526626586914
Batch 19/64 loss: -1.8790912628173828
Batch 20/64 loss: -2.1893362998962402
Batch 21/64 loss: -1.8627262115478516
Batch 22/64 loss: -1.8490676879882812
Batch 23/64 loss: -1.8834104537963867
Batch 24/64 loss: -1.5191421508789062
Batch 25/64 loss: -1.906522274017334
Batch 26/64 loss: -1.5349254608154297
Batch 27/64 loss: -1.7784767150878906
Batch 28/64 loss: -2.1344456672668457
Batch 29/64 loss: -1.7258148193359375
Batch 30/64 loss: -1.908346176147461
Batch 31/64 loss: -2.0294933319091797
Batch 32/64 loss: -1.9504308700561523
Batch 33/64 loss: -1.9585895538330078
Batch 34/64 loss: -1.967923641204834
Batch 35/64 loss: -2.033968448638916
Batch 36/64 loss: -1.857259750366211
Batch 37/64 loss: -1.5960712432861328
Batch 38/64 loss: -1.993912696838379
Batch 39/64 loss: -2.009516716003418
Batch 40/64 loss: -2.0440168380737305
Batch 41/64 loss: -1.8148441314697266
Batch 42/64 loss: -2.138814926147461
Batch 43/64 loss: -1.9945363998413086
Batch 44/64 loss: -1.1893033981323242
Batch 45/64 loss: -1.831183910369873
Batch 46/64 loss: -2.009570598602295
Batch 47/64 loss: -2.035583019256592
Batch 48/64 loss: -1.7469615936279297
Batch 49/64 loss: -1.89412260055542
Batch 50/64 loss: -1.7871160507202148
Batch 51/64 loss: -1.980766773223877
Batch 52/64 loss: -1.4791746139526367
Batch 53/64 loss: -1.5873842239379883
Batch 54/64 loss: -1.6799564361572266
Batch 55/64 loss: -1.8786773681640625
Batch 56/64 loss: -1.5734500885009766
Batch 57/64 loss: -2.061758041381836
Batch 58/64 loss: -2.124720573425293
Batch 59/64 loss: -1.4472198486328125
Batch 60/64 loss: -1.5471229553222656
Batch 61/64 loss: -1.9448347091674805
Batch 62/64 loss: -1.6693181991577148
Batch 63/64 loss: -1.8286395072937012
Batch 64/64 loss: -6.107880592346191
Epoch 430  Train loss: -1.9030212589338713  Val loss: -2.1790194953839803
Saving best model, epoch: 430
Epoch 431
-------------------------------
Batch 1/64 loss: -1.8745460510253906
Batch 2/64 loss: -1.9090280532836914
Batch 3/64 loss: -1.9096012115478516
Batch 4/64 loss: -1.4118432998657227
Batch 5/64 loss: -1.9924278259277344
Batch 6/64 loss: -2.1352577209472656
Batch 7/64 loss: -2.0055999755859375
Batch 8/64 loss: -1.9759364128112793
Batch 9/64 loss: -1.692549228668213
Batch 10/64 loss: -2.068629741668701
Batch 11/64 loss: -2.1702747344970703
Batch 12/64 loss: -2.1076736450195312
Batch 13/64 loss: -2.093888282775879
Batch 14/64 loss: -1.4660158157348633
Batch 15/64 loss: -1.7683372497558594
Batch 16/64 loss: -1.5935783386230469
Batch 17/64 loss: -2.0636825561523438
Batch 18/64 loss: -1.5539226531982422
Batch 19/64 loss: -1.844590187072754
Batch 20/64 loss: -1.8100576400756836
Batch 21/64 loss: -1.7466154098510742
Batch 22/64 loss: -1.516336441040039
Batch 23/64 loss: -1.6910696029663086
Batch 24/64 loss: -2.1010565757751465
Batch 25/64 loss: -1.7230186462402344
Batch 26/64 loss: -1.8863630294799805
Batch 27/64 loss: -1.6550636291503906
Batch 28/64 loss: -1.7206687927246094
Batch 29/64 loss: -2.093334197998047
Batch 30/64 loss: -1.9150972366333008
Batch 31/64 loss: -2.290733814239502
Batch 32/64 loss: -1.8935785293579102
Batch 33/64 loss: -1.7995290756225586
Batch 34/64 loss: -1.9989557266235352
Batch 35/64 loss: -2.009714126586914
Batch 36/64 loss: -2.165555477142334
Batch 37/64 loss: -1.9259414672851562
Batch 38/64 loss: -2.151029586791992
Batch 39/64 loss: -1.676529884338379
Batch 40/64 loss: -1.9174003601074219
Batch 41/64 loss: -2.0346412658691406
Batch 42/64 loss: -1.8072800636291504
Batch 43/64 loss: -2.064563751220703
Batch 44/64 loss: -2.0476126670837402
Batch 45/64 loss: -2.2513036727905273
Batch 46/64 loss: -1.7048015594482422
Batch 47/64 loss: -1.6198358535766602
Batch 48/64 loss: -2.075104236602783
Batch 49/64 loss: -2.0139899253845215
Batch 50/64 loss: -2.0429325103759766
Batch 51/64 loss: -2.2066688537597656
Batch 52/64 loss: -1.4509954452514648
Batch 53/64 loss: -1.9667482376098633
Batch 54/64 loss: -1.9533309936523438
Batch 55/64 loss: -1.1782398223876953
Batch 56/64 loss: -2.1443424224853516
Batch 57/64 loss: -1.9058828353881836
Batch 58/64 loss: -1.7512226104736328
Batch 59/64 loss: -2.0775346755981445
Batch 60/64 loss: -1.5671982765197754
Batch 61/64 loss: -1.723546028137207
Batch 62/64 loss: -1.927262306213379
Batch 63/64 loss: -1.8660621643066406
Batch 64/64 loss: -5.941450119018555
Epoch 431  Train loss: -1.931956392176011  Val loss: -2.065606553120302
Epoch 432
-------------------------------
Batch 1/64 loss: -1.7292823791503906
Batch 2/64 loss: -2.116466522216797
Batch 3/64 loss: -1.6983656883239746
Batch 4/64 loss: -1.8712615966796875
Batch 5/64 loss: -1.9175996780395508
Batch 6/64 loss: -1.7148466110229492
Batch 7/64 loss: -1.4651002883911133
Batch 8/64 loss: -2.091613292694092
Batch 9/64 loss: -1.9245777130126953
Batch 10/64 loss: -1.567251205444336
Batch 11/64 loss: -1.8768806457519531
Batch 12/64 loss: -1.8439569473266602
Batch 13/64 loss: -2.0025529861450195
Batch 14/64 loss: -2.080075740814209
Batch 15/64 loss: -1.7647647857666016
Batch 16/64 loss: -1.8865861892700195
Batch 17/64 loss: -1.9752483367919922
Batch 18/64 loss: -1.9355249404907227
Batch 19/64 loss: -1.686178207397461
Batch 20/64 loss: -1.962386131286621
Batch 21/64 loss: -1.7432823181152344
Batch 22/64 loss: -1.7235679626464844
Batch 23/64 loss: -1.6863384246826172
Batch 24/64 loss: -1.5982704162597656
Batch 25/64 loss: -1.958608627319336
Batch 26/64 loss: -1.4406309127807617
Batch 27/64 loss: -1.95371675491333
Batch 28/64 loss: -1.7402000427246094
Batch 29/64 loss: -1.8863019943237305
Batch 30/64 loss: -1.525395393371582
Batch 31/64 loss: -1.760110855102539
Batch 32/64 loss: -1.7958641052246094
Batch 33/64 loss: -1.9231700897216797
Batch 34/64 loss: -2.060117721557617
Batch 35/64 loss: -2.040553092956543
Batch 36/64 loss: -1.8742265701293945
Batch 37/64 loss: -2.13995361328125
Batch 38/64 loss: -1.87744140625
Batch 39/64 loss: -2.0079946517944336
Batch 40/64 loss: -2.142544746398926
Batch 41/64 loss: -1.8908138275146484
Batch 42/64 loss: -1.8672900199890137
Batch 43/64 loss: -1.8386316299438477
Batch 44/64 loss: -1.9727916717529297
Batch 45/64 loss: -1.592153549194336
Batch 46/64 loss: -2.0052146911621094
Batch 47/64 loss: -1.8464126586914062
Batch 48/64 loss: -2.0138635635375977
Batch 49/64 loss: -1.820366382598877
Batch 50/64 loss: -2.0959057807922363
Batch 51/64 loss: -1.8515982627868652
Batch 52/64 loss: -1.6512842178344727
Batch 53/64 loss: -1.9919004440307617
Batch 54/64 loss: -1.938429832458496
Batch 55/64 loss: -2.00372314453125
Batch 56/64 loss: -1.6831655502319336
Batch 57/64 loss: -1.661606788635254
Batch 58/64 loss: -1.9912300109863281
Batch 59/64 loss: -1.9961376190185547
Batch 60/64 loss: -1.9269294738769531
Batch 61/64 loss: -1.9768304824829102
Batch 62/64 loss: -2.1433162689208984
Batch 63/64 loss: -2.0378665924072266
Batch 64/64 loss: -5.986400127410889
Epoch 432  Train loss: -1.9180560336393468  Val loss: -2.1996093173207285
Saving best model, epoch: 432
Epoch 433
-------------------------------
Batch 1/64 loss: -1.6638727188110352
Batch 2/64 loss: -2.199117660522461
Batch 3/64 loss: -1.829843521118164
Batch 4/64 loss: -2.0522208213806152
Batch 5/64 loss: -2.2010750770568848
Batch 6/64 loss: -1.9028606414794922
Batch 7/64 loss: -2.0811166763305664
Batch 8/64 loss: -2.001741409301758
Batch 9/64 loss: -2.1644062995910645
Batch 10/64 loss: -1.254023551940918
Batch 11/64 loss: -1.6599540710449219
Batch 12/64 loss: -1.988534927368164
Batch 13/64 loss: -1.9678096771240234
Batch 14/64 loss: -2.057191848754883
Batch 15/64 loss: -1.1387405395507812
Batch 16/64 loss: -1.954176425933838
Batch 17/64 loss: -1.8895578384399414
Batch 18/64 loss: -1.8107719421386719
Batch 19/64 loss: -2.099315643310547
Batch 20/64 loss: -1.9539928436279297
Batch 21/64 loss: -2.1015853881835938
Batch 22/64 loss: -1.7452850341796875
Batch 23/64 loss: -1.8282198905944824
Batch 24/64 loss: -1.805246353149414
Batch 25/64 loss: -1.5354843139648438
Batch 26/64 loss: -2.029651641845703
Batch 27/64 loss: -2.2094345092773438
Batch 28/64 loss: -2.0571436882019043
Batch 29/64 loss: -2.002408981323242
Batch 30/64 loss: -1.7861976623535156
Batch 31/64 loss: -1.9477481842041016
Batch 32/64 loss: -1.4291372299194336
Batch 33/64 loss: -1.8691835403442383
Batch 34/64 loss: -1.9432382583618164
Batch 35/64 loss: -2.0642199516296387
Batch 36/64 loss: -2.055339813232422
Batch 37/64 loss: -1.998255729675293
Batch 38/64 loss: -1.9197397232055664
Batch 39/64 loss: -2.008615493774414
Batch 40/64 loss: -1.0316238403320312
Batch 41/64 loss: -1.9089865684509277
Batch 42/64 loss: -1.9407901763916016
Batch 43/64 loss: -1.4671821594238281
Batch 44/64 loss: -1.8857011795043945
Batch 45/64 loss: -1.9341974258422852
Batch 46/64 loss: -1.6051464080810547
Batch 47/64 loss: -1.9312877655029297
Batch 48/64 loss: -1.7835111618041992
Batch 49/64 loss: -1.7646732330322266
Batch 50/64 loss: -1.8206868171691895
Batch 51/64 loss: -1.7313547134399414
Batch 52/64 loss: -1.6958446502685547
Batch 53/64 loss: -1.5956544876098633
Batch 54/64 loss: -1.6871376037597656
Batch 55/64 loss: -1.83551025390625
Batch 56/64 loss: -2.254301071166992
Batch 57/64 loss: -1.8682408332824707
Batch 58/64 loss: -2.260354995727539
Batch 59/64 loss: -2.01068115234375
Batch 60/64 loss: -1.8150053024291992
Batch 61/64 loss: -1.931692123413086
Batch 62/64 loss: -2.1922779083251953
Batch 63/64 loss: -1.9250154495239258
Batch 64/64 loss: -6.025949478149414
Epoch 433  Train loss: -1.923180845672009  Val loss: -2.0948116132074204
Epoch 434
-------------------------------
Batch 1/64 loss: -2.2075600624084473
Batch 2/64 loss: -1.9052672386169434
Batch 3/64 loss: -1.8213167190551758
Batch 4/64 loss: -1.7912778854370117
Batch 5/64 loss: -1.5862579345703125
Batch 6/64 loss: -1.9500255584716797
Batch 7/64 loss: -1.9178733825683594
Batch 8/64 loss: -2.0678205490112305
Batch 9/64 loss: -2.050368309020996
Batch 10/64 loss: -2.0326576232910156
Batch 11/64 loss: -1.9652996063232422
Batch 12/64 loss: -1.9403181076049805
Batch 13/64 loss: -2.025156021118164
Batch 14/64 loss: -1.8655920028686523
Batch 15/64 loss: -2.14115047454834
Batch 16/64 loss: -2.0528078079223633
Batch 17/64 loss: -1.8522343635559082
Batch 18/64 loss: -2.0922975540161133
Batch 19/64 loss: -2.022655963897705
Batch 20/64 loss: -1.9928474426269531
Batch 21/64 loss: -1.598557472229004
Batch 22/64 loss: -1.5931167602539062
Batch 23/64 loss: -2.00053071975708
Batch 24/64 loss: -1.847743034362793
Batch 25/64 loss: -2.0091795921325684
Batch 26/64 loss: -2.1197452545166016
Batch 27/64 loss: -1.8229212760925293
Batch 28/64 loss: -2.025082588195801
Batch 29/64 loss: -1.895599365234375
Batch 30/64 loss: -1.8717308044433594
Batch 31/64 loss: -2.059393882751465
Batch 32/64 loss: -1.498809814453125
Batch 33/64 loss: -1.1494789123535156
Batch 34/64 loss: -2.0289063453674316
Batch 35/64 loss: -1.8122434616088867
Batch 36/64 loss: -1.836944580078125
Batch 37/64 loss: -1.867985725402832
Batch 38/64 loss: -2.1537322998046875
Batch 39/64 loss: -1.9128637313842773
Batch 40/64 loss: -2.105891227722168
Batch 41/64 loss: -1.7259502410888672
Batch 42/64 loss: -2.114480495452881
Batch 43/64 loss: -1.7570858001708984
Batch 44/64 loss: -2.111924171447754
Batch 45/64 loss: -1.8457236289978027
Batch 46/64 loss: -1.809098243713379
Batch 47/64 loss: -2.2110342979431152
Batch 48/64 loss: -2.1330227851867676
Batch 49/64 loss: -1.7449049949645996
Batch 50/64 loss: -2.1334686279296875
Batch 51/64 loss: -2.0268917083740234
Batch 52/64 loss: -1.9600181579589844
Batch 53/64 loss: -1.7318263053894043
Batch 54/64 loss: -1.8257746696472168
Batch 55/64 loss: -2.1417741775512695
Batch 56/64 loss: -1.8843812942504883
Batch 57/64 loss: -1.8286476135253906
Batch 58/64 loss: -2.0241684913635254
Batch 59/64 loss: -1.977022647857666
Batch 60/64 loss: -1.8925352096557617
Batch 61/64 loss: -1.795802116394043
Batch 62/64 loss: -1.96256685256958
Batch 63/64 loss: -2.0873889923095703
Batch 64/64 loss: -5.83099889755249
Epoch 434  Train loss: -1.9700389357174144  Val loss: -2.168422685865684
Epoch 435
-------------------------------
Batch 1/64 loss: -1.8641471862792969
Batch 2/64 loss: -2.11403751373291
Batch 3/64 loss: -1.9759292602539062
Batch 4/64 loss: -1.745762825012207
Batch 5/64 loss: -1.9559803009033203
Batch 6/64 loss: -1.941396713256836
Batch 7/64 loss: -1.9250550270080566
Batch 8/64 loss: -2.196056365966797
Batch 9/64 loss: -1.7647409439086914
Batch 10/64 loss: -1.7018613815307617
Batch 11/64 loss: -2.0783824920654297
Batch 12/64 loss: -2.0368051528930664
Batch 13/64 loss: -2.2353219985961914
Batch 14/64 loss: -2.075860023498535
Batch 15/64 loss: -1.7806477546691895
Batch 16/64 loss: -2.0078272819519043
Batch 17/64 loss: -1.7690925598144531
Batch 18/64 loss: -1.8182430267333984
Batch 19/64 loss: -1.9069714546203613
Batch 20/64 loss: -2.021853446960449
Batch 21/64 loss: -1.9562797546386719
Batch 22/64 loss: -1.8105945587158203
Batch 23/64 loss: -2.0035181045532227
Batch 24/64 loss: -1.6908907890319824
Batch 25/64 loss: -2.236262798309326
Batch 26/64 loss: -1.8409514427185059
Batch 27/64 loss: -1.9792571067810059
Batch 28/64 loss: -1.9920024871826172
Batch 29/64 loss: -1.8127098083496094
Batch 30/64 loss: -1.8251733779907227
Batch 31/64 loss: -1.909395694732666
Batch 32/64 loss: -1.5536656379699707
Batch 33/64 loss: -2.081666946411133
Batch 34/64 loss: -1.862903118133545
Batch 35/64 loss: -2.0194778442382812
Batch 36/64 loss: -1.9366087913513184
Batch 37/64 loss: -1.7833967208862305
Batch 38/64 loss: -1.8863401412963867
Batch 39/64 loss: -2.142460346221924
Batch 40/64 loss: -1.9722943305969238
Batch 41/64 loss: -1.8674440383911133
Batch 42/64 loss: -1.772477149963379
Batch 43/64 loss: -1.8688831329345703
Batch 44/64 loss: -1.772770881652832
Batch 45/64 loss: -2.023984909057617
Batch 46/64 loss: -1.4866485595703125
Batch 47/64 loss: -2.1331167221069336
Batch 48/64 loss: -1.9047017097473145
Batch 49/64 loss: -1.914534568786621
Batch 50/64 loss: -1.7832860946655273
Batch 51/64 loss: -2.0707645416259766
Batch 52/64 loss: -1.9827008247375488
Batch 53/64 loss: -2.0116491317749023
Batch 54/64 loss: -2.1198196411132812
Batch 55/64 loss: -2.0033693313598633
Batch 56/64 loss: -1.6611652374267578
Batch 57/64 loss: -2.0486598014831543
Batch 58/64 loss: -2.0701866149902344
Batch 59/64 loss: -2.099579334259033
Batch 60/64 loss: -1.8318147659301758
Batch 61/64 loss: -1.635416030883789
Batch 62/64 loss: -1.9387540817260742
Batch 63/64 loss: -2.003096103668213
Batch 64/64 loss: -6.094814300537109
Epoch 435  Train loss: -1.9731412775376265  Val loss: -2.053950542436842
Epoch 436
-------------------------------
Batch 1/64 loss: -2.1446123123168945
Batch 2/64 loss: -1.5104045867919922
Batch 3/64 loss: -1.9572381973266602
Batch 4/64 loss: -2.151059150695801
Batch 5/64 loss: -1.827265739440918
Batch 6/64 loss: -2.1002602577209473
Batch 7/64 loss: -1.795053482055664
Batch 8/64 loss: -1.9955568313598633
Batch 9/64 loss: -1.9082860946655273
Batch 10/64 loss: -1.9391775131225586
Batch 11/64 loss: -2.1373791694641113
Batch 12/64 loss: -1.9412193298339844
Batch 13/64 loss: -1.9525666236877441
Batch 14/64 loss: -1.8629169464111328
Batch 15/64 loss: -1.7661561965942383
Batch 16/64 loss: -1.8435306549072266
Batch 17/64 loss: -1.9565386772155762
Batch 18/64 loss: -2.087520122528076
Batch 19/64 loss: -1.9861845970153809
Batch 20/64 loss: -1.993441104888916
Batch 21/64 loss: -2.046159267425537
Batch 22/64 loss: -1.809931755065918
Batch 23/64 loss: -1.8912782669067383
Batch 24/64 loss: -1.662618637084961
Batch 25/64 loss: -1.917184829711914
Batch 26/64 loss: -1.973658561706543
Batch 27/64 loss: -1.872117042541504
Batch 28/64 loss: -1.7098798751831055
Batch 29/64 loss: -2.2558798789978027
Batch 30/64 loss: -1.8820037841796875
Batch 31/64 loss: -2.102358818054199
Batch 32/64 loss: -1.9599342346191406
Batch 33/64 loss: -2.062196731567383
Batch 34/64 loss: -2.053439140319824
Batch 35/64 loss: -1.9278717041015625
Batch 36/64 loss: -1.8733091354370117
Batch 37/64 loss: -1.9840431213378906
Batch 38/64 loss: -1.965512752532959
Batch 39/64 loss: -1.5425167083740234
Batch 40/64 loss: -2.06974458694458
Batch 41/64 loss: -1.9727611541748047
Batch 42/64 loss: -1.8605246543884277
Batch 43/64 loss: -2.0012712478637695
Batch 44/64 loss: -2.0949063301086426
Batch 45/64 loss: -2.2008914947509766
Batch 46/64 loss: -1.6484909057617188
Batch 47/64 loss: -2.1065096855163574
Batch 48/64 loss: -2.043002128601074
Batch 49/64 loss: -1.9718198776245117
Batch 50/64 loss: -1.5100822448730469
Batch 51/64 loss: -2.034118175506592
Batch 52/64 loss: -1.8200855255126953
Batch 53/64 loss: -2.1851325035095215
Batch 54/64 loss: -1.87335205078125
Batch 55/64 loss: -1.5515680313110352
Batch 56/64 loss: -1.8162508010864258
Batch 57/64 loss: -2.0074949264526367
Batch 58/64 loss: -2.13742733001709
Batch 59/64 loss: -1.7538948059082031
Batch 60/64 loss: -1.8730530738830566
Batch 61/64 loss: -1.8743009567260742
Batch 62/64 loss: -1.6219768524169922
Batch 63/64 loss: -2.093411922454834
Batch 64/64 loss: -5.932886123657227
Epoch 436  Train loss: -1.9752156500722848  Val loss: -2.118450217230623
Epoch 437
-------------------------------
Batch 1/64 loss: -1.8282146453857422
Batch 2/64 loss: -1.702958106994629
Batch 3/64 loss: -2.0048389434814453
Batch 4/64 loss: -1.5676641464233398
Batch 5/64 loss: -2.0663280487060547
Batch 6/64 loss: -1.869196891784668
Batch 7/64 loss: -1.7853050231933594
Batch 8/64 loss: -1.8193349838256836
Batch 9/64 loss: -1.8279118537902832
Batch 10/64 loss: -2.1820802688598633
Batch 11/64 loss: -2.0608348846435547
Batch 12/64 loss: -1.8665685653686523
Batch 13/64 loss: -1.9384498596191406
Batch 14/64 loss: -2.0152463912963867
Batch 15/64 loss: -1.980020523071289
Batch 16/64 loss: -2.1824913024902344
Batch 17/64 loss: -2.026444911956787
Batch 18/64 loss: -1.9883780479431152
Batch 19/64 loss: -2.0953636169433594
Batch 20/64 loss: -2.201070785522461
Batch 21/64 loss: -1.6622209548950195
Batch 22/64 loss: -1.761932373046875
Batch 23/64 loss: -1.8677854537963867
Batch 24/64 loss: -1.9915132522583008
Batch 25/64 loss: -2.0920257568359375
Batch 26/64 loss: -1.788187026977539
Batch 27/64 loss: -1.8634991645812988
Batch 28/64 loss: -2.2207164764404297
Batch 29/64 loss: -1.9345011711120605
Batch 30/64 loss: -2.074472427368164
Batch 31/64 loss: -1.7751545906066895
Batch 32/64 loss: -1.7906460762023926
Batch 33/64 loss: -1.8402595520019531
Batch 34/64 loss: -1.8763022422790527
Batch 35/64 loss: -2.1283578872680664
Batch 36/64 loss: -1.9341459274291992
Batch 37/64 loss: -1.721024990081787
Batch 38/64 loss: -1.99747896194458
Batch 39/64 loss: -2.0105748176574707
Batch 40/64 loss: -1.9386262893676758
Batch 41/64 loss: -1.1825237274169922
Batch 42/64 loss: -1.9392170906066895
Batch 43/64 loss: -1.9100565910339355
Batch 44/64 loss: -1.8849830627441406
Batch 45/64 loss: -1.6858234405517578
Batch 46/64 loss: -1.9791898727416992
Batch 47/64 loss: -1.9705352783203125
Batch 48/64 loss: -1.596426010131836
Batch 49/64 loss: -1.7048921585083008
Batch 50/64 loss: -2.047482967376709
Batch 51/64 loss: -2.0550060272216797
Batch 52/64 loss: -1.856180191040039
Batch 53/64 loss: -1.8771638870239258
Batch 54/64 loss: -1.9145402908325195
Batch 55/64 loss: -1.9682626724243164
Batch 56/64 loss: -1.8024849891662598
Batch 57/64 loss: -2.066464900970459
Batch 58/64 loss: -1.807999610900879
Batch 59/64 loss: -2.110177516937256
Batch 60/64 loss: -1.7325849533081055
Batch 61/64 loss: -1.746072769165039
Batch 62/64 loss: -2.0576658248901367
Batch 63/64 loss: -1.6253480911254883
Batch 64/64 loss: -6.017136096954346
Epoch 437  Train loss: -1.949993116715375  Val loss: -2.0973401020482645
Epoch 438
-------------------------------
Batch 1/64 loss: -2.0832595825195312
Batch 2/64 loss: -1.6975021362304688
Batch 3/64 loss: -1.8987112045288086
Batch 4/64 loss: -2.1221871376037598
Batch 5/64 loss: -1.9487648010253906
Batch 6/64 loss: -1.6984291076660156
Batch 7/64 loss: -2.0448837280273438
Batch 8/64 loss: -2.008310317993164
Batch 9/64 loss: -1.8251643180847168
Batch 10/64 loss: -1.788041114807129
Batch 11/64 loss: -1.9876470565795898
Batch 12/64 loss: -1.802243709564209
Batch 13/64 loss: -1.9100933074951172
Batch 14/64 loss: -1.9822049140930176
Batch 15/64 loss: -1.7043704986572266
Batch 16/64 loss: -1.7819509506225586
Batch 17/64 loss: -1.9407401084899902
Batch 18/64 loss: -1.8259305953979492
Batch 19/64 loss: -1.6787123680114746
Batch 20/64 loss: -1.6334114074707031
Batch 21/64 loss: -1.9133000373840332
Batch 22/64 loss: -1.6760807037353516
Batch 23/64 loss: -1.7532358169555664
Batch 24/64 loss: -1.7799081802368164
Batch 25/64 loss: -2.086275577545166
Batch 26/64 loss: -1.7214946746826172
Batch 27/64 loss: -1.9515857696533203
Batch 28/64 loss: -2.1647281646728516
Batch 29/64 loss: -1.8447790145874023
Batch 30/64 loss: -1.8886709213256836
Batch 31/64 loss: -2.0653929710388184
Batch 32/64 loss: -2.1041626930236816
Batch 33/64 loss: -2.002546787261963
Batch 34/64 loss: -1.7693734169006348
Batch 35/64 loss: -2.0848236083984375
Batch 36/64 loss: -1.9641237258911133
Batch 37/64 loss: -1.5334720611572266
Batch 38/64 loss: -1.908050537109375
Batch 39/64 loss: -1.6776399612426758
Batch 40/64 loss: -1.9625859260559082
Batch 41/64 loss: -1.8803930282592773
Batch 42/64 loss: -1.954690933227539
Batch 43/64 loss: -1.8776283264160156
Batch 44/64 loss: -2.074495792388916
Batch 45/64 loss: -1.9586520195007324
Batch 46/64 loss: -1.899714469909668
Batch 47/64 loss: -1.8798542022705078
Batch 48/64 loss: -1.7251110076904297
Batch 49/64 loss: -2.0011167526245117
Batch 50/64 loss: -1.9467363357543945
Batch 51/64 loss: -1.7605581283569336
Batch 52/64 loss: -2.0576162338256836
Batch 53/64 loss: -1.6886711120605469
Batch 54/64 loss: -1.419942855834961
Batch 55/64 loss: -1.9053335189819336
Batch 56/64 loss: -1.8097772598266602
Batch 57/64 loss: -1.8244991302490234
Batch 58/64 loss: -1.885666847229004
Batch 59/64 loss: -1.7998747825622559
Batch 60/64 loss: -1.6515398025512695
Batch 61/64 loss: -2.0675392150878906
Batch 62/64 loss: -1.7649903297424316
Batch 63/64 loss: -1.824376106262207
Batch 64/64 loss: -5.756396293640137
Epoch 438  Train loss: -1.916719440385407  Val loss: -2.1743013047680413
Epoch 439
-------------------------------
Batch 1/64 loss: -1.788015365600586
Batch 2/64 loss: -1.9385199546813965
Batch 3/64 loss: -1.836573600769043
Batch 4/64 loss: -1.7683172225952148
Batch 5/64 loss: -1.845900535583496
Batch 6/64 loss: -1.9176383018493652
Batch 7/64 loss: -1.8660163879394531
Batch 8/64 loss: -2.1248364448547363
Batch 9/64 loss: -1.6755332946777344
Batch 10/64 loss: -1.539876937866211
Batch 11/64 loss: -1.9862823486328125
Batch 12/64 loss: -1.9670333862304688
Batch 13/64 loss: -2.285402297973633
Batch 14/64 loss: -1.6089305877685547
Batch 15/64 loss: -1.996840000152588
Batch 16/64 loss: -2.0797243118286133
Batch 17/64 loss: -1.958139419555664
Batch 18/64 loss: -1.563939094543457
Batch 19/64 loss: -1.7628211975097656
Batch 20/64 loss: -1.6119365692138672
Batch 21/64 loss: -2.102181911468506
Batch 22/64 loss: -1.8820905685424805
Batch 23/64 loss: -1.8960142135620117
Batch 24/64 loss: -1.7524471282958984
Batch 25/64 loss: -1.5973320007324219
Batch 26/64 loss: -1.902522087097168
Batch 27/64 loss: -1.5843744277954102
Batch 28/64 loss: -1.5768747329711914
Batch 29/64 loss: -2.049520492553711
Batch 30/64 loss: -2.0804243087768555
Batch 31/64 loss: -1.8515357971191406
Batch 32/64 loss: -1.6399011611938477
Batch 33/64 loss: -2.0240421295166016
Batch 34/64 loss: -1.999114990234375
Batch 35/64 loss: -1.9318671226501465
Batch 36/64 loss: -2.0905699729919434
Batch 37/64 loss: -2.1195011138916016
Batch 38/64 loss: -1.9787578582763672
Batch 39/64 loss: -2.074988842010498
Batch 40/64 loss: -2.0523738861083984
Batch 41/64 loss: -2.237870216369629
Batch 42/64 loss: -1.9681634902954102
Batch 43/64 loss: -1.9908103942871094
Batch 44/64 loss: -2.0376501083374023
Batch 45/64 loss: -2.0564794540405273
Batch 46/64 loss: -1.7659692764282227
Batch 47/64 loss: -1.8815956115722656
Batch 48/64 loss: -1.8302183151245117
Batch 49/64 loss: -2.0939388275146484
Batch 50/64 loss: -1.933598518371582
Batch 51/64 loss: -1.9469289779663086
Batch 52/64 loss: -2.0450968742370605
Batch 53/64 loss: -2.150358200073242
Batch 54/64 loss: -1.5241146087646484
Batch 55/64 loss: -2.1961021423339844
Batch 56/64 loss: -1.921137809753418
Batch 57/64 loss: -1.8231358528137207
Batch 58/64 loss: -1.9673261642456055
Batch 59/64 loss: -1.7117576599121094
Batch 60/64 loss: -1.7849211692810059
Batch 61/64 loss: -1.9531636238098145
Batch 62/64 loss: -1.7155122756958008
Batch 63/64 loss: -2.0016326904296875
Batch 64/64 loss: -6.1155853271484375
Epoch 439  Train loss: -1.951888364904067  Val loss: -2.123500089874792
Epoch 440
-------------------------------
Batch 1/64 loss: -2.098041534423828
Batch 2/64 loss: -2.0038089752197266
Batch 3/64 loss: -1.908477783203125
Batch 4/64 loss: -1.7499494552612305
Batch 5/64 loss: -1.6022653579711914
Batch 6/64 loss: -2.2198572158813477
Batch 7/64 loss: -1.8980917930603027
Batch 8/64 loss: -2.130868911743164
Batch 9/64 loss: -1.9278125762939453
Batch 10/64 loss: -2.138002872467041
Batch 11/64 loss: -2.091977119445801
Batch 12/64 loss: -2.2311110496520996
Batch 13/64 loss: -1.8594703674316406
Batch 14/64 loss: -1.938776969909668
Batch 15/64 loss: -1.9405598640441895
Batch 16/64 loss: -2.113077163696289
Batch 17/64 loss: -1.9587798118591309
Batch 18/64 loss: -2.1506471633911133
Batch 19/64 loss: -1.5372304916381836
Batch 20/64 loss: -1.5045976638793945
Batch 21/64 loss: -1.6094293594360352
Batch 22/64 loss: -1.859787940979004
Batch 23/64 loss: -1.872962474822998
Batch 24/64 loss: -1.9767508506774902
Batch 25/64 loss: -2.18851900100708
Batch 26/64 loss: -1.900062084197998
Batch 27/64 loss: -1.6095285415649414
Batch 28/64 loss: -1.7453384399414062
Batch 29/64 loss: -2.026577949523926
Batch 30/64 loss: -1.9113225936889648
Batch 31/64 loss: -1.8472404479980469
Batch 32/64 loss: -1.796067237854004
Batch 33/64 loss: -1.7464103698730469
Batch 34/64 loss: -1.8262243270874023
Batch 35/64 loss: -1.944279670715332
Batch 36/64 loss: -1.9340758323669434
Batch 37/64 loss: -1.870375633239746
Batch 38/64 loss: -2.0147151947021484
Batch 39/64 loss: -1.9622325897216797
Batch 40/64 loss: -1.9697837829589844
Batch 41/64 loss: -2.0436296463012695
Batch 42/64 loss: -1.779052734375
Batch 43/64 loss: -1.9141960144042969
Batch 44/64 loss: -1.9302315711975098
Batch 45/64 loss: -1.7443103790283203
Batch 46/64 loss: -1.6547393798828125
Batch 47/64 loss: -1.9189844131469727
Batch 48/64 loss: -2.0509138107299805
Batch 49/64 loss: -1.9441165924072266
Batch 50/64 loss: -1.8156099319458008
Batch 51/64 loss: -1.979722023010254
Batch 52/64 loss: -2.1396026611328125
Batch 53/64 loss: -1.8546972274780273
Batch 54/64 loss: -2.0434422492980957
Batch 55/64 loss: -1.9103684425354004
Batch 56/64 loss: -2.0794177055358887
Batch 57/64 loss: -1.4391660690307617
Batch 58/64 loss: -1.4209833145141602
Batch 59/64 loss: -1.9697117805480957
Batch 60/64 loss: -1.7522821426391602
Batch 61/64 loss: -1.947169303894043
Batch 62/64 loss: -1.837712287902832
Batch 63/64 loss: -2.0482306480407715
Batch 64/64 loss: -6.115011215209961
Epoch 440  Train loss: -1.9516805835798674  Val loss: -2.1449819086343562
Epoch 441
-------------------------------
Batch 1/64 loss: -1.5935354232788086
Batch 2/64 loss: -2.1893930435180664
Batch 3/64 loss: -1.746638298034668
Batch 4/64 loss: -2.203972339630127
Batch 5/64 loss: -1.920919418334961
Batch 6/64 loss: -1.864640235900879
Batch 7/64 loss: -1.7972745895385742
Batch 8/64 loss: -2.0311312675476074
Batch 9/64 loss: -1.493485450744629
Batch 10/64 loss: -2.150519847869873
Batch 11/64 loss: -2.0063037872314453
Batch 12/64 loss: -1.9053049087524414
Batch 13/64 loss: -1.7314081192016602
Batch 14/64 loss: -1.733931541442871
Batch 15/64 loss: -1.7954072952270508
Batch 16/64 loss: -1.8661489486694336
Batch 17/64 loss: -1.689743995666504
Batch 18/64 loss: -1.6842212677001953
Batch 19/64 loss: -2.184779167175293
Batch 20/64 loss: -2.2208313941955566
Batch 21/64 loss: -2.098586082458496
Batch 22/64 loss: -2.205214023590088
Batch 23/64 loss: -1.9446320533752441
Batch 24/64 loss: -1.9094018936157227
Batch 25/64 loss: -1.6441154479980469
Batch 26/64 loss: -1.9514093399047852
Batch 27/64 loss: -1.8999133110046387
Batch 28/64 loss: -2.3420658111572266
Batch 29/64 loss: -1.2133560180664062
Batch 30/64 loss: -1.6537752151489258
Batch 31/64 loss: -1.8690438270568848
Batch 32/64 loss: -2.064770221710205
Batch 33/64 loss: -1.9501152038574219
Batch 34/64 loss: -2.1096138954162598
Batch 35/64 loss: -1.6221551895141602
Batch 36/64 loss: -1.6278085708618164
Batch 37/64 loss: -2.0167551040649414
Batch 38/64 loss: -1.7083930969238281
Batch 39/64 loss: -1.7340497970581055
Batch 40/64 loss: -1.887277603149414
Batch 41/64 loss: -2.059493064880371
Batch 42/64 loss: -1.9841203689575195
Batch 43/64 loss: -2.072232246398926
Batch 44/64 loss: -2.0218076705932617
Batch 45/64 loss: -2.02227783203125
Batch 46/64 loss: -2.0899157524108887
Batch 47/64 loss: -1.9281229972839355
Batch 48/64 loss: -1.9215073585510254
Batch 49/64 loss: -1.658559799194336
Batch 50/64 loss: -2.0886311531066895
Batch 51/64 loss: -1.9955296516418457
Batch 52/64 loss: -2.0431432723999023
Batch 53/64 loss: -1.8550605773925781
Batch 54/64 loss: -2.1242828369140625
Batch 55/64 loss: -2.0966176986694336
Batch 56/64 loss: -1.9806904792785645
Batch 57/64 loss: -2.0564613342285156
Batch 58/64 loss: -1.9714288711547852
Batch 59/64 loss: -1.9271092414855957
Batch 60/64 loss: -1.6930532455444336
Batch 61/64 loss: -2.1143646240234375
Batch 62/64 loss: -1.8022127151489258
Batch 63/64 loss: -2.0461697578430176
Batch 64/64 loss: -6.0777082443237305
Epoch 441  Train loss: -1.9666371102426565  Val loss: -2.0735773171755865
Epoch 442
-------------------------------
Batch 1/64 loss: -2.021672248840332
Batch 2/64 loss: -1.6644563674926758
Batch 3/64 loss: -2.2795066833496094
Batch 4/64 loss: -1.8487682342529297
Batch 5/64 loss: -1.7772207260131836
Batch 6/64 loss: -2.0126051902770996
Batch 7/64 loss: -2.0743322372436523
Batch 8/64 loss: -1.774094581604004
Batch 9/64 loss: -1.2955894470214844
Batch 10/64 loss: -1.8793492317199707
Batch 11/64 loss: -1.730025291442871
Batch 12/64 loss: -2.14886474609375
Batch 13/64 loss: -1.5913963317871094
Batch 14/64 loss: -1.634568214416504
Batch 15/64 loss: -1.680981159210205
Batch 16/64 loss: -1.9690513610839844
Batch 17/64 loss: -1.9044733047485352
Batch 18/64 loss: -1.851400375366211
Batch 19/64 loss: -1.6242704391479492
Batch 20/64 loss: -2.05155086517334
Batch 21/64 loss: -2.154236316680908
Batch 22/64 loss: -2.057415008544922
Batch 23/64 loss: -1.870924949645996
Batch 24/64 loss: -1.995823860168457
Batch 25/64 loss: -1.7346477508544922
Batch 26/64 loss: -1.8460893630981445
Batch 27/64 loss: -1.6020889282226562
Batch 28/64 loss: -1.9186277389526367
Batch 29/64 loss: -1.936647891998291
Batch 30/64 loss: -1.4913663864135742
Batch 31/64 loss: -2.0240097045898438
Batch 32/64 loss: -1.7712221145629883
Batch 33/64 loss: -1.9771151542663574
Batch 34/64 loss: -1.9248237609863281
Batch 35/64 loss: -1.7081356048583984
Batch 36/64 loss: -1.785135269165039
Batch 37/64 loss: -1.6565866470336914
Batch 38/64 loss: -1.9865388870239258
Batch 39/64 loss: -1.8195409774780273
Batch 40/64 loss: -1.871072769165039
Batch 41/64 loss: -1.9676809310913086
Batch 42/64 loss: -1.9705381393432617
Batch 43/64 loss: -2.167853832244873
Batch 44/64 loss: -2.0170974731445312
Batch 45/64 loss: -2.149087905883789
Batch 46/64 loss: -1.8204760551452637
Batch 47/64 loss: -1.9872174263000488
Batch 48/64 loss: -2.172290802001953
Batch 49/64 loss: -2.011798858642578
Batch 50/64 loss: -1.8183422088623047
Batch 51/64 loss: -1.8266973495483398
Batch 52/64 loss: -1.9665427207946777
Batch 53/64 loss: -1.7209234237670898
Batch 54/64 loss: -1.7090368270874023
Batch 55/64 loss: -2.085875988006592
Batch 56/64 loss: -1.9118590354919434
Batch 57/64 loss: -2.0071840286254883
Batch 58/64 loss: -1.4945688247680664
Batch 59/64 loss: -1.9005451202392578
Batch 60/64 loss: -1.950026512145996
Batch 61/64 loss: -2.0707106590270996
Batch 62/64 loss: -1.8679685592651367
Batch 63/64 loss: -1.9934568405151367
Batch 64/64 loss: -5.867821216583252
Epoch 442  Train loss: -1.928390142029407  Val loss: -2.0615439136413363
Epoch 443
-------------------------------
Batch 1/64 loss: -1.8300514221191406
Batch 2/64 loss: -2.002110004425049
Batch 3/64 loss: -1.7838773727416992
Batch 4/64 loss: -1.8106088638305664
Batch 5/64 loss: -1.7538623809814453
Batch 6/64 loss: -1.5156049728393555
Batch 7/64 loss: -1.9328875541687012
Batch 8/64 loss: -1.8768224716186523
Batch 9/64 loss: -1.989366054534912
Batch 10/64 loss: -1.871729850769043
Batch 11/64 loss: -1.8270511627197266
Batch 12/64 loss: -2.0648813247680664
Batch 13/64 loss: -2.2270002365112305
Batch 14/64 loss: -1.9397315979003906
Batch 15/64 loss: -1.5197534561157227
Batch 16/64 loss: -1.7796049118041992
Batch 17/64 loss: -1.851365089416504
Batch 18/64 loss: -1.7310199737548828
Batch 19/64 loss: -1.8048362731933594
Batch 20/64 loss: -1.8931779861450195
Batch 21/64 loss: -2.063082695007324
Batch 22/64 loss: -1.714064598083496
Batch 23/64 loss: -1.9082708358764648
Batch 24/64 loss: -2.1035027503967285
Batch 25/64 loss: -1.641383171081543
Batch 26/64 loss: -1.4768714904785156
Batch 27/64 loss: -2.2078375816345215
Batch 28/64 loss: -2.0012998580932617
Batch 29/64 loss: -1.7680492401123047
Batch 30/64 loss: -1.7693767547607422
Batch 31/64 loss: -1.976348876953125
Batch 32/64 loss: -2.0199708938598633
Batch 33/64 loss: -1.9395837783813477
Batch 34/64 loss: -1.8269481658935547
Batch 35/64 loss: -2.009927272796631
Batch 36/64 loss: -1.8119516372680664
Batch 37/64 loss: -1.8370637893676758
Batch 38/64 loss: -1.7557315826416016
Batch 39/64 loss: -1.7407169342041016
Batch 40/64 loss: -1.5360641479492188
Batch 41/64 loss: -1.855184555053711
Batch 42/64 loss: -1.6325702667236328
Batch 43/64 loss: -1.8585424423217773
Batch 44/64 loss: -1.9695343971252441
Batch 45/64 loss: -1.8377161026000977
Batch 46/64 loss: -1.9826669692993164
Batch 47/64 loss: -2.088165283203125
Batch 48/64 loss: -2.0409984588623047
Batch 49/64 loss: -1.9031047821044922
Batch 50/64 loss: -2.167048931121826
Batch 51/64 loss: -1.9832806587219238
Batch 52/64 loss: -1.8348884582519531
Batch 53/64 loss: -1.751143455505371
Batch 54/64 loss: -1.8982586860656738
Batch 55/64 loss: -1.841233253479004
Batch 56/64 loss: -1.717000961303711
Batch 57/64 loss: -1.642608642578125
Batch 58/64 loss: -1.767465591430664
Batch 59/64 loss: -1.7706174850463867
Batch 60/64 loss: -2.0811257362365723
Batch 61/64 loss: -2.020936965942383
Batch 62/64 loss: -1.880218505859375
Batch 63/64 loss: -1.3000469207763672
Batch 64/64 loss: -6.095227241516113
Epoch 443  Train loss: -1.906026148328594  Val loss: -2.1105452993071774
Epoch 444
-------------------------------
Batch 1/64 loss: -2.2204761505126953
Batch 2/64 loss: -1.9285621643066406
Batch 3/64 loss: -1.9346003532409668
Batch 4/64 loss: -1.821946144104004
Batch 5/64 loss: -1.5277433395385742
Batch 6/64 loss: -2.002028465270996
Batch 7/64 loss: -1.7834892272949219
Batch 8/64 loss: -1.9745759963989258
Batch 9/64 loss: -1.8157234191894531
Batch 10/64 loss: -1.4849767684936523
Batch 11/64 loss: -2.051041603088379
Batch 12/64 loss: -1.8147144317626953
Batch 13/64 loss: -2.126978874206543
Batch 14/64 loss: -1.8902244567871094
Batch 15/64 loss: -1.2893848419189453
Batch 16/64 loss: -1.8231067657470703
Batch 17/64 loss: -1.9608774185180664
Batch 18/64 loss: -1.9684839248657227
Batch 19/64 loss: -2.0411362648010254
Batch 20/64 loss: -1.9842896461486816
Batch 21/64 loss: -1.5245695114135742
Batch 22/64 loss: -1.986536979675293
Batch 23/64 loss: -2.072828769683838
Batch 24/64 loss: -1.8360109329223633
Batch 25/64 loss: -1.8400659561157227
Batch 26/64 loss: -2.0427803993225098
Batch 27/64 loss: -1.825113296508789
Batch 28/64 loss: -2.1482462882995605
Batch 29/64 loss: -1.9695749282836914
Batch 30/64 loss: -1.8932790756225586
Batch 31/64 loss: -1.9853134155273438
Batch 32/64 loss: -2.1773319244384766
Batch 33/64 loss: -1.9408140182495117
Batch 34/64 loss: -1.9760851860046387
Batch 35/64 loss: -1.7292556762695312
Batch 36/64 loss: -2.118711471557617
Batch 37/64 loss: -1.6463890075683594
Batch 38/64 loss: -1.7886848449707031
Batch 39/64 loss: -1.1100282669067383
Batch 40/64 loss: -2.070606231689453
Batch 41/64 loss: -1.5763635635375977
Batch 42/64 loss: -1.7842016220092773
Batch 43/64 loss: -2.023591995239258
Batch 44/64 loss: -2.008899688720703
Batch 45/64 loss: -2.0062570571899414
Batch 46/64 loss: -1.969149112701416
Batch 47/64 loss: -1.8477716445922852
Batch 48/64 loss: -2.1231889724731445
Batch 49/64 loss: -2.0254926681518555
Batch 50/64 loss: -1.943476676940918
Batch 51/64 loss: -2.0470008850097656
Batch 52/64 loss: -1.8334412574768066
Batch 53/64 loss: -1.6477108001708984
Batch 54/64 loss: -1.990464687347412
Batch 55/64 loss: -2.092165470123291
Batch 56/64 loss: -1.8844881057739258
Batch 57/64 loss: -2.047417163848877
Batch 58/64 loss: -1.8429269790649414
Batch 59/64 loss: -2.0150747299194336
Batch 60/64 loss: -1.7896442413330078
Batch 61/64 loss: -1.8438148498535156
Batch 62/64 loss: -2.0094690322875977
Batch 63/64 loss: -1.7507076263427734
Batch 64/64 loss: -6.079583644866943
Epoch 444  Train loss: -1.9417881255056344  Val loss: -2.1670679570883
Epoch 445
-------------------------------
Batch 1/64 loss: -1.4581565856933594
Batch 2/64 loss: -1.3893518447875977
Batch 3/64 loss: -1.3260154724121094
Batch 4/64 loss: -1.9656982421875
Batch 5/64 loss: -2.1122846603393555
Batch 6/64 loss: -1.9812211990356445
Batch 7/64 loss: -2.106367588043213
Batch 8/64 loss: -2.2219605445861816
Batch 9/64 loss: -2.1071548461914062
Batch 10/64 loss: -2.288543224334717
Batch 11/64 loss: -1.9516258239746094
Batch 12/64 loss: -2.0735244750976562
Batch 13/64 loss: -1.851675033569336
Batch 14/64 loss: -1.1023139953613281
Batch 15/64 loss: -2.0513763427734375
Batch 16/64 loss: -1.9547767639160156
Batch 17/64 loss: -1.8704910278320312
Batch 18/64 loss: -1.5889272689819336
Batch 19/64 loss: -1.6308441162109375
Batch 20/64 loss: -2.0157032012939453
Batch 21/64 loss: -1.988144874572754
Batch 22/64 loss: -1.7488417625427246
Batch 23/64 loss: -1.9461560249328613
Batch 24/64 loss: -1.9345941543579102
Batch 25/64 loss: -2.221468448638916
Batch 26/64 loss: -1.8993425369262695
Batch 27/64 loss: -1.9233741760253906
Batch 28/64 loss: -2.076864719390869
Batch 29/64 loss: -1.9758949279785156
Batch 30/64 loss: -2.021096706390381
Batch 31/64 loss: -2.2675957679748535
Batch 32/64 loss: -2.0408220291137695
Batch 33/64 loss: -1.7523527145385742
Batch 34/64 loss: -2.2053356170654297
Batch 35/64 loss: -2.049870491027832
Batch 36/64 loss: -1.7276554107666016
Batch 37/64 loss: -2.1196842193603516
Batch 38/64 loss: -1.987436294555664
Batch 39/64 loss: -1.9125957489013672
Batch 40/64 loss: -1.7989616394042969
Batch 41/64 loss: -1.962815284729004
Batch 42/64 loss: -2.1834874153137207
Batch 43/64 loss: -1.7151222229003906
Batch 44/64 loss: -1.9545226097106934
Batch 45/64 loss: -2.0039381980895996
Batch 46/64 loss: -1.9631929397583008
Batch 47/64 loss: -1.8554067611694336
Batch 48/64 loss: -2.074610710144043
Batch 49/64 loss: -2.000121593475342
Batch 50/64 loss: -1.888284683227539
Batch 51/64 loss: -1.7865209579467773
Batch 52/64 loss: -1.9363183975219727
Batch 53/64 loss: -2.0471439361572266
Batch 54/64 loss: -1.6704540252685547
Batch 55/64 loss: -1.9010190963745117
Batch 56/64 loss: -2.156097888946533
Batch 57/64 loss: -1.7381248474121094
Batch 58/64 loss: -1.9267091751098633
Batch 59/64 loss: -2.0200185775756836
Batch 60/64 loss: -1.967282772064209
Batch 61/64 loss: -2.180704116821289
Batch 62/64 loss: -2.1227941513061523
Batch 63/64 loss: -1.8113679885864258
Batch 64/64 loss: -5.986583232879639
Epoch 445  Train loss: -1.9765034712997138  Val loss: -2.212895921005826
Saving best model, epoch: 445
Epoch 446
-------------------------------
Batch 1/64 loss: -1.8689460754394531
Batch 2/64 loss: -1.9749221801757812
Batch 3/64 loss: -2.1709442138671875
Batch 4/64 loss: -2.1890625953674316
Batch 5/64 loss: -2.0918593406677246
Batch 6/64 loss: -1.8502283096313477
Batch 7/64 loss: -1.8204994201660156
Batch 8/64 loss: -2.118311882019043
Batch 9/64 loss: -2.0310635566711426
Batch 10/64 loss: -2.0040717124938965
Batch 11/64 loss: -2.1390433311462402
Batch 12/64 loss: -1.9927005767822266
Batch 13/64 loss: -2.089876174926758
Batch 14/64 loss: -1.8817377090454102
Batch 15/64 loss: -1.9258527755737305
Batch 16/64 loss: -1.6290216445922852
Batch 17/64 loss: -2.141106128692627
Batch 18/64 loss: -2.0646772384643555
Batch 19/64 loss: -2.137662887573242
Batch 20/64 loss: -1.9368276596069336
Batch 21/64 loss: -1.9020280838012695
Batch 22/64 loss: -1.7663745880126953
Batch 23/64 loss: -1.5688972473144531
Batch 24/64 loss: -1.9135980606079102
Batch 25/64 loss: -1.8133420944213867
Batch 26/64 loss: -2.020615577697754
Batch 27/64 loss: -1.7374553680419922
Batch 28/64 loss: -1.7874703407287598
Batch 29/64 loss: -2.140465259552002
Batch 30/64 loss: -2.0666403770446777
Batch 31/64 loss: -1.7871837615966797
Batch 32/64 loss: -1.457108497619629
Batch 33/64 loss: -1.760690689086914
Batch 34/64 loss: -1.721846580505371
Batch 35/64 loss: -2.215709686279297
Batch 36/64 loss: -1.8753604888916016
Batch 37/64 loss: -1.94287109375
Batch 38/64 loss: -2.110924243927002
Batch 39/64 loss: -2.221609592437744
Batch 40/64 loss: -1.8517217636108398
Batch 41/64 loss: -1.9691333770751953
Batch 42/64 loss: -2.1117396354675293
Batch 43/64 loss: -1.8383636474609375
Batch 44/64 loss: -1.9067602157592773
Batch 45/64 loss: -2.15914249420166
Batch 46/64 loss: -2.0490617752075195
Batch 47/64 loss: -2.1101760864257812
Batch 48/64 loss: -2.0758118629455566
Batch 49/64 loss: -2.1230521202087402
Batch 50/64 loss: -1.8149423599243164
Batch 51/64 loss: -1.7307500839233398
Batch 52/64 loss: -1.7547721862792969
Batch 53/64 loss: -1.6502161026000977
Batch 54/64 loss: -2.032750129699707
Batch 55/64 loss: -2.2618565559387207
Batch 56/64 loss: -1.9021291732788086
Batch 57/64 loss: -2.0446648597717285
Batch 58/64 loss: -1.9076972007751465
Batch 59/64 loss: -1.639577865600586
Batch 60/64 loss: -1.7104721069335938
Batch 61/64 loss: -1.8967199325561523
Batch 62/64 loss: -1.821329116821289
Batch 63/64 loss: -1.9037199020385742
Batch 64/64 loss: -6.1353278160095215
Epoch 446  Train loss: -1.9880260935016707  Val loss: -2.04210332496879
Epoch 447
-------------------------------
Batch 1/64 loss: -1.498946189880371
Batch 2/64 loss: -1.8486223220825195
Batch 3/64 loss: -1.7680063247680664
Batch 4/64 loss: -1.9650840759277344
Batch 5/64 loss: -1.795792579650879
Batch 6/64 loss: -1.9518890380859375
Batch 7/64 loss: -1.7622699737548828
Batch 8/64 loss: -1.7531757354736328
Batch 9/64 loss: -1.6089162826538086
Batch 10/64 loss: -1.9663505554199219
Batch 11/64 loss: -1.9840807914733887
Batch 12/64 loss: -1.9933223724365234
Batch 13/64 loss: -1.635542869567871
Batch 14/64 loss: -2.1959800720214844
Batch 15/64 loss: -1.8101530075073242
Batch 16/64 loss: -1.4684295654296875
Batch 17/64 loss: -2.0027313232421875
Batch 18/64 loss: -1.8679370880126953
Batch 19/64 loss: -1.791961669921875
Batch 20/64 loss: -1.7261276245117188
Batch 21/64 loss: -2.018054962158203
Batch 22/64 loss: -1.9502277374267578
Batch 23/64 loss: -1.150589942932129
Batch 24/64 loss: -2.097909927368164
Batch 25/64 loss: -2.1529550552368164
Batch 26/64 loss: -1.8089447021484375
Batch 27/64 loss: -1.9510383605957031
Batch 28/64 loss: -1.9614744186401367
Batch 29/64 loss: -1.5346784591674805
Batch 30/64 loss: -2.070420742034912
Batch 31/64 loss: -1.9944028854370117
Batch 32/64 loss: -1.4717597961425781
Batch 33/64 loss: -1.9146051406860352
Batch 34/64 loss: -1.9938950538635254
Batch 35/64 loss: -1.8774528503417969
Batch 36/64 loss: -1.8822288513183594
Batch 37/64 loss: -2.212705612182617
Batch 38/64 loss: -1.8669166564941406
Batch 39/64 loss: -1.7199993133544922
Batch 40/64 loss: -2.0785064697265625
Batch 41/64 loss: -1.817819595336914
Batch 42/64 loss: -2.1419239044189453
Batch 43/64 loss: -1.972947120666504
Batch 44/64 loss: -2.053868293762207
Batch 45/64 loss: -2.317122459411621
Batch 46/64 loss: -2.202213764190674
Batch 47/64 loss: -1.943704605102539
Batch 48/64 loss: -1.9256219863891602
Batch 49/64 loss: -2.1281471252441406
Batch 50/64 loss: -1.8386611938476562
Batch 51/64 loss: -1.568892478942871
Batch 52/64 loss: -2.061474323272705
Batch 53/64 loss: -1.6673717498779297
Batch 54/64 loss: -1.6064949035644531
Batch 55/64 loss: -1.95127534866333
Batch 56/64 loss: -1.9442710876464844
Batch 57/64 loss: -1.893007755279541
Batch 58/64 loss: -1.88651704788208
Batch 59/64 loss: -1.9504551887512207
Batch 60/64 loss: -1.897603988647461
Batch 61/64 loss: -2.002481460571289
Batch 62/64 loss: -2.034067153930664
Batch 63/64 loss: -1.765279769897461
Batch 64/64 loss: -6.122671127319336
Epoch 447  Train loss: -1.9336048948998545  Val loss: -2.0630202670277598
Epoch 448
-------------------------------
Batch 1/64 loss: -1.8061590194702148
Batch 2/64 loss: -1.9037094116210938
Batch 3/64 loss: -1.6304168701171875
Batch 4/64 loss: -1.7022695541381836
Batch 5/64 loss: -1.8865489959716797
Batch 6/64 loss: -1.5688800811767578
Batch 7/64 loss: -1.7940778732299805
Batch 8/64 loss: -1.8286323547363281
Batch 9/64 loss: -1.8652839660644531
Batch 10/64 loss: -1.5927839279174805
Batch 11/64 loss: -1.4817543029785156
Batch 12/64 loss: -1.8911476135253906
Batch 13/64 loss: -1.6958885192871094
Batch 14/64 loss: -2.1600728034973145
Batch 15/64 loss: -1.835052490234375
Batch 16/64 loss: -2.097661018371582
Batch 17/64 loss: -1.549616813659668
Batch 18/64 loss: -1.7110042572021484
Batch 19/64 loss: -1.9858627319335938
Batch 20/64 loss: -1.7580928802490234
Batch 21/64 loss: -1.995072841644287
Batch 22/64 loss: -1.9265966415405273
Batch 23/64 loss: -1.8401899337768555
Batch 24/64 loss: -1.9044532775878906
Batch 25/64 loss: -1.8724746704101562
Batch 26/64 loss: -1.7243242263793945
Batch 27/64 loss: -1.6774988174438477
Batch 28/64 loss: -1.85267972946167
Batch 29/64 loss: -1.9516563415527344
Batch 30/64 loss: -1.8132476806640625
Batch 31/64 loss: -1.9606995582580566
Batch 32/64 loss: -1.640517234802246
Batch 33/64 loss: -1.7086982727050781
Batch 34/64 loss: -1.4821901321411133
Batch 35/64 loss: -2.0940332412719727
Batch 36/64 loss: -1.865056037902832
Batch 37/64 loss: -1.9757347106933594
Batch 38/64 loss: -1.7449274063110352
Batch 39/64 loss: -1.7142343521118164
Batch 40/64 loss: -1.891657829284668
Batch 41/64 loss: -2.0731258392333984
Batch 42/64 loss: -1.771317481994629
Batch 43/64 loss: -1.723052978515625
Batch 44/64 loss: -2.083279609680176
Batch 45/64 loss: -1.7136106491088867
Batch 46/64 loss: -1.9030580520629883
Batch 47/64 loss: -1.7978458404541016
Batch 48/64 loss: -2.1309585571289062
Batch 49/64 loss: -1.5718574523925781
Batch 50/64 loss: -1.9431018829345703
Batch 51/64 loss: -2.051051616668701
Batch 52/64 loss: -1.7307567596435547
Batch 53/64 loss: -1.9724292755126953
Batch 54/64 loss: -1.8868131637573242
Batch 55/64 loss: -1.8048181533813477
Batch 56/64 loss: -2.0049638748168945
Batch 57/64 loss: -1.8485422134399414
Batch 58/64 loss: -2.1546835899353027
Batch 59/64 loss: -1.8441762924194336
Batch 60/64 loss: -2.028339385986328
Batch 61/64 loss: -2.2107958793640137
Batch 62/64 loss: -1.5214004516601562
Batch 63/64 loss: -1.8808975219726562
Batch 64/64 loss: -6.043694972991943
Epoch 448  Train loss: -1.8912079399707271  Val loss: -2.0402125460175715
Epoch 449
-------------------------------
Batch 1/64 loss: -1.7896614074707031
Batch 2/64 loss: -1.6201906204223633
Batch 3/64 loss: -1.8155875205993652
Batch 4/64 loss: -1.9709405899047852
Batch 5/64 loss: -1.8862910270690918
Batch 6/64 loss: -1.661616325378418
Batch 7/64 loss: -1.9158997535705566
Batch 8/64 loss: -2.1201443672180176
Batch 9/64 loss: -2.199350357055664
Batch 10/64 loss: -1.9410533905029297
Batch 11/64 loss: -1.4351072311401367
Batch 12/64 loss: -1.498946189880371
Batch 13/64 loss: -1.891214370727539
Batch 14/64 loss: -1.8173255920410156
Batch 15/64 loss: -1.903280258178711
Batch 16/64 loss: -1.7347583770751953
Batch 17/64 loss: -1.8041558265686035
Batch 18/64 loss: -1.7112207412719727
Batch 19/64 loss: -1.9317893981933594
Batch 20/64 loss: -2.060086727142334
Batch 21/64 loss: -2.3194103240966797
Batch 22/64 loss: -1.778963565826416
Batch 23/64 loss: -1.8200321197509766
Batch 24/64 loss: -1.9723529815673828
Batch 25/64 loss: -1.7295761108398438
Batch 26/64 loss: -2.001697063446045
Batch 27/64 loss: -2.102658271789551
Batch 28/64 loss: -1.813502311706543
Batch 29/64 loss: -1.812978744506836
Batch 30/64 loss: -2.0949745178222656
Batch 31/64 loss: -1.8657550811767578
Batch 32/64 loss: -2.190091609954834
Batch 33/64 loss: -1.3377676010131836
Batch 34/64 loss: -1.9620776176452637
Batch 35/64 loss: -1.9760875701904297
Batch 36/64 loss: -2.1610875129699707
Batch 37/64 loss: -2.2615957260131836
Batch 38/64 loss: -1.9425125122070312
Batch 39/64 loss: -1.8992223739624023
Batch 40/64 loss: -1.6898317337036133
Batch 41/64 loss: -1.8962912559509277
Batch 42/64 loss: -2.0036396980285645
Batch 43/64 loss: -2.1264657974243164
Batch 44/64 loss: -1.9515228271484375
Batch 45/64 loss: -2.113910675048828
Batch 46/64 loss: -1.9025945663452148
Batch 47/64 loss: -2.0050621032714844
Batch 48/64 loss: -1.8412361145019531
Batch 49/64 loss: -1.9415016174316406
Batch 50/64 loss: -1.7489395141601562
Batch 51/64 loss: -1.988752841949463
Batch 52/64 loss: -1.763702392578125
Batch 53/64 loss: -2.166879653930664
Batch 54/64 loss: -1.8753166198730469
Batch 55/64 loss: -2.052372455596924
Batch 56/64 loss: -1.8017597198486328
Batch 57/64 loss: -2.0031590461730957
Batch 58/64 loss: -1.927469253540039
Batch 59/64 loss: -1.9264297485351562
Batch 60/64 loss: -2.088014602661133
Batch 61/64 loss: -1.8975028991699219
Batch 62/64 loss: -2.050206184387207
Batch 63/64 loss: -2.0891599655151367
Batch 64/64 loss: -5.835777759552002
Epoch 449  Train loss: -1.9604630320679908  Val loss: -2.1359760376186308
Epoch 450
-------------------------------
Batch 1/64 loss: -1.806075096130371
Batch 2/64 loss: -1.6949987411499023
Batch 3/64 loss: -1.505218505859375
Batch 4/64 loss: -1.890584945678711
Batch 5/64 loss: -1.8625364303588867
Batch 6/64 loss: -2.095757484436035
Batch 7/64 loss: -1.9129962921142578
Batch 8/64 loss: -1.829127311706543
Batch 9/64 loss: -2.0167155265808105
Batch 10/64 loss: -2.053016185760498
Batch 11/64 loss: -1.7075796127319336
Batch 12/64 loss: -1.7336311340332031
Batch 13/64 loss: -2.1383748054504395
Batch 14/64 loss: -1.9721436500549316
Batch 15/64 loss: -1.8698768615722656
Batch 16/64 loss: -2.0352678298950195
Batch 17/64 loss: -1.8139781951904297
Batch 18/64 loss: -2.011662483215332
Batch 19/64 loss: -2.193589210510254
Batch 20/64 loss: -1.9456114768981934
Batch 21/64 loss: -2.1734304428100586
Batch 22/64 loss: -2.079184055328369
Batch 23/64 loss: -2.1817331314086914
Batch 24/64 loss: -2.17343807220459
Batch 25/64 loss: -1.9104423522949219
Batch 26/64 loss: -1.992356300354004
Batch 27/64 loss: -1.9020652770996094
Batch 28/64 loss: -2.0633668899536133
Batch 29/64 loss: -1.830887794494629
Batch 30/64 loss: -2.0291547775268555
Batch 31/64 loss: -1.964247703552246
Batch 32/64 loss: -1.2725954055786133
Batch 33/64 loss: -1.865534782409668
Batch 34/64 loss: -2.128222942352295
Batch 35/64 loss: -2.2620038986206055
Batch 36/64 loss: -1.7470359802246094
Batch 37/64 loss: -2.0691442489624023
Batch 38/64 loss: -1.950932502746582
Batch 39/64 loss: -2.0442662239074707
Batch 40/64 loss: -1.9399347305297852
Batch 41/64 loss: -1.9350595474243164
Batch 42/64 loss: -1.976363182067871
Batch 43/64 loss: -1.7932319641113281
Batch 44/64 loss: -1.9669132232666016
Batch 45/64 loss: -2.140824794769287
Batch 46/64 loss: -2.139371871948242
Batch 47/64 loss: -1.774470329284668
Batch 48/64 loss: -1.730422019958496
Batch 49/64 loss: -1.9965815544128418
Batch 50/64 loss: -2.0563178062438965
Batch 51/64 loss: -1.7963600158691406
Batch 52/64 loss: -1.9284086227416992
Batch 53/64 loss: -1.9363470077514648
Batch 54/64 loss: -1.7999191284179688
Batch 55/64 loss: -1.6350984573364258
Batch 56/64 loss: -1.8987817764282227
Batch 57/64 loss: -2.056835174560547
Batch 58/64 loss: -2.196107864379883
Batch 59/64 loss: -2.064181327819824
Batch 60/64 loss: -2.104351043701172
Batch 61/64 loss: -2.0313687324523926
Batch 62/64 loss: -2.0935235023498535
Batch 63/64 loss: -1.7262592315673828
Batch 64/64 loss: -5.634222507476807
Epoch 450  Train loss: -1.9870036760965983  Val loss: -2.1953397010200213
Epoch 451
-------------------------------
Batch 1/64 loss: -2.064391613006592
Batch 2/64 loss: -1.402562141418457
Batch 3/64 loss: -2.116819381713867
Batch 4/64 loss: -2.1061019897460938
Batch 5/64 loss: -1.9312362670898438
Batch 6/64 loss: -1.9086027145385742
Batch 7/64 loss: -2.2764053344726562
Batch 8/64 loss: -2.045957565307617
Batch 9/64 loss: -1.8743743896484375
Batch 10/64 loss: -2.1896395683288574
Batch 11/64 loss: -2.131333351135254
Batch 12/64 loss: -2.0349178314208984
Batch 13/64 loss: -1.9085826873779297
Batch 14/64 loss: -1.925933837890625
Batch 15/64 loss: -1.658431053161621
Batch 16/64 loss: -1.7766971588134766
Batch 17/64 loss: -1.9574804306030273
Batch 18/64 loss: -1.7654542922973633
Batch 19/64 loss: -1.926412582397461
Batch 20/64 loss: -1.8804235458374023
Batch 21/64 loss: -1.9003190994262695
Batch 22/64 loss: -1.9934463500976562
Batch 23/64 loss: -1.6980314254760742
Batch 24/64 loss: -1.9150629043579102
Batch 25/64 loss: -2.001401901245117
Batch 26/64 loss: -2.192918300628662
Batch 27/64 loss: -1.5194578170776367
Batch 28/64 loss: -1.6822395324707031
Batch 29/64 loss: -1.768864631652832
Batch 30/64 loss: -1.9197235107421875
Batch 31/64 loss: -1.9109792709350586
Batch 32/64 loss: -1.0549116134643555
Batch 33/64 loss: -1.9582014083862305
Batch 34/64 loss: -1.416050910949707
Batch 35/64 loss: -1.7576723098754883
Batch 36/64 loss: -1.5624103546142578
Batch 37/64 loss: -1.8787002563476562
Batch 38/64 loss: -1.9204902648925781
Batch 39/64 loss: -1.823300838470459
Batch 40/64 loss: -1.790217399597168
Batch 41/64 loss: -1.9012022018432617
Batch 42/64 loss: -1.7758808135986328
Batch 43/64 loss: -1.8105154037475586
Batch 44/64 loss: -1.848069190979004
Batch 45/64 loss: -1.5070161819458008
Batch 46/64 loss: -1.916391372680664
Batch 47/64 loss: -2.1422300338745117
Batch 48/64 loss: -1.8514318466186523
Batch 49/64 loss: -1.4215726852416992
Batch 50/64 loss: -2.0141868591308594
Batch 51/64 loss: -1.9845199584960938
Batch 52/64 loss: -1.945131778717041
Batch 53/64 loss: -2.0282955169677734
Batch 54/64 loss: -1.8370628356933594
Batch 55/64 loss: -1.482717514038086
Batch 56/64 loss: -1.8860816955566406
Batch 57/64 loss: -2.016979217529297
Batch 58/64 loss: -1.0288562774658203
Batch 59/64 loss: -2.0148096084594727
Batch 60/64 loss: -1.8771405220031738
Batch 61/64 loss: -1.8840837478637695
Batch 62/64 loss: -1.9230680465698242
Batch 63/64 loss: -1.8999300003051758
Batch 64/64 loss: -5.997819423675537
Epoch 451  Train loss: -1.898693266101912  Val loss: -2.1008532284870998
Epoch 452
-------------------------------
Batch 1/64 loss: -2.1006298065185547
Batch 2/64 loss: -1.960787296295166
Batch 3/64 loss: -1.9332160949707031
Batch 4/64 loss: -2.003028392791748
Batch 5/64 loss: -1.9697628021240234
Batch 6/64 loss: -1.5105628967285156
Batch 7/64 loss: -1.798318862915039
Batch 8/64 loss: -2.080097198486328
Batch 9/64 loss: -1.7834157943725586
Batch 10/64 loss: -1.8525524139404297
Batch 11/64 loss: -1.8311405181884766
Batch 12/64 loss: -1.8543930053710938
Batch 13/64 loss: -1.9871301651000977
Batch 14/64 loss: -1.8418455123901367
Batch 15/64 loss: -2.029210090637207
Batch 16/64 loss: -1.8783187866210938
Batch 17/64 loss: -2.163731575012207
Batch 18/64 loss: -1.9798002243041992
Batch 19/64 loss: -1.2129545211791992
Batch 20/64 loss: -1.6194067001342773
Batch 21/64 loss: -1.6227788925170898
Batch 22/64 loss: -1.617060661315918
Batch 23/64 loss: -1.693572998046875
Batch 24/64 loss: -1.6341991424560547
Batch 25/64 loss: -0.9958333969116211
Batch 26/64 loss: -2.019257068634033
Batch 27/64 loss: -1.6930131912231445
Batch 28/64 loss: -1.7136383056640625
Batch 29/64 loss: -1.5713090896606445
Batch 30/64 loss: -1.8610973358154297
Batch 31/64 loss: -1.8602519035339355
Batch 32/64 loss: -2.1156201362609863
Batch 33/64 loss: -1.7030010223388672
Batch 34/64 loss: -1.725996971130371
Batch 35/64 loss: -1.9636363983154297
Batch 36/64 loss: -1.969630241394043
Batch 37/64 loss: -2.0481624603271484
Batch 38/64 loss: -1.990157127380371
Batch 39/64 loss: -1.932854175567627
Batch 40/64 loss: -1.8160600662231445
Batch 41/64 loss: -1.8011789321899414
Batch 42/64 loss: -1.9658102989196777
Batch 43/64 loss: -1.8017401695251465
Batch 44/64 loss: -1.7545738220214844
Batch 45/64 loss: -1.5908775329589844
Batch 46/64 loss: -1.928560733795166
Batch 47/64 loss: -1.8789033889770508
Batch 48/64 loss: -2.0158586502075195
Batch 49/64 loss: -2.0193276405334473
Batch 50/64 loss: -2.1125588417053223
Batch 51/64 loss: -1.6991853713989258
Batch 52/64 loss: -1.6072187423706055
Batch 53/64 loss: -1.8349876403808594
Batch 54/64 loss: -2.0434136390686035
Batch 55/64 loss: -2.2092113494873047
Batch 56/64 loss: -2.032665729522705
Batch 57/64 loss: -2.1426162719726562
Batch 58/64 loss: -1.7238597869873047
Batch 59/64 loss: -1.779893398284912
Batch 60/64 loss: -2.1923351287841797
Batch 61/64 loss: -1.609914779663086
Batch 62/64 loss: -1.3205060958862305
Batch 63/64 loss: -1.8953752517700195
Batch 64/64 loss: -6.1239190101623535
Epoch 452  Train loss: -1.8900540501463647  Val loss: -2.123563432201897
Epoch 453
-------------------------------
Batch 1/64 loss: -2.065805435180664
Batch 2/64 loss: -1.6454648971557617
Batch 3/64 loss: -2.193694591522217
Batch 4/64 loss: -1.8138465881347656
Batch 5/64 loss: -1.5441932678222656
Batch 6/64 loss: -1.4900989532470703
Batch 7/64 loss: -2.001918315887451
Batch 8/64 loss: -1.5362625122070312
Batch 9/64 loss: -1.9920892715454102
Batch 10/64 loss: -1.9287266731262207
Batch 11/64 loss: -1.4235010147094727
Batch 12/64 loss: -1.623922348022461
Batch 13/64 loss: -1.5295629501342773
Batch 14/64 loss: -2.116767406463623
Batch 15/64 loss: -1.9176487922668457
Batch 16/64 loss: -1.7402992248535156
Batch 17/64 loss: -1.5858020782470703
Batch 18/64 loss: -1.7593059539794922
Batch 19/64 loss: -1.519357681274414
Batch 20/64 loss: -2.181654930114746
Batch 21/64 loss: -1.700601577758789
Batch 22/64 loss: -1.3562517166137695
Batch 23/64 loss: -1.783095359802246
Batch 24/64 loss: -1.9910774230957031
Batch 25/64 loss: -2.0703611373901367
Batch 26/64 loss: -1.9561262130737305
Batch 27/64 loss: -1.1771631240844727
Batch 28/64 loss: -2.0936121940612793
Batch 29/64 loss: -1.8365426063537598
Batch 30/64 loss: -2.1756701469421387
Batch 31/64 loss: -1.9577245712280273
Batch 32/64 loss: -2.243579864501953
Batch 33/64 loss: -2.154616355895996
Batch 34/64 loss: -2.008345603942871
Batch 35/64 loss: -2.050942897796631
Batch 36/64 loss: -1.985940933227539
Batch 37/64 loss: -2.2075018882751465
Batch 38/64 loss: -1.824066162109375
Batch 39/64 loss: -2.1039066314697266
Batch 40/64 loss: -2.012637138366699
Batch 41/64 loss: -1.9963817596435547
Batch 42/64 loss: -1.9581422805786133
Batch 43/64 loss: -1.9391694068908691
Batch 44/64 loss: -1.9709253311157227
Batch 45/64 loss: -1.8045711517333984
Batch 46/64 loss: -1.8460988998413086
Batch 47/64 loss: -2.127112865447998
Batch 48/64 loss: -2.0617475509643555
Batch 49/64 loss: -1.5035037994384766
Batch 50/64 loss: -1.6023502349853516
Batch 51/64 loss: -1.8576526641845703
Batch 52/64 loss: -1.7372093200683594
Batch 53/64 loss: -2.0720133781433105
Batch 54/64 loss: -2.108945369720459
Batch 55/64 loss: -1.871291160583496
Batch 56/64 loss: -1.9156875610351562
Batch 57/64 loss: -2.057403564453125
Batch 58/64 loss: -1.8462438583374023
Batch 59/64 loss: -1.570042610168457
Batch 60/64 loss: -2.023289680480957
Batch 61/64 loss: -2.1852803230285645
Batch 62/64 loss: -2.154468536376953
Batch 63/64 loss: -2.017385482788086
Batch 64/64 loss: -5.58394193649292
Epoch 453  Train loss: -1.9249342694002038  Val loss: -2.1443861210878774
Epoch 454
-------------------------------
Batch 1/64 loss: -1.817138671875
Batch 2/64 loss: -1.8122005462646484
Batch 3/64 loss: -1.850621223449707
Batch 4/64 loss: -2.185696601867676
Batch 5/64 loss: -1.8304862976074219
Batch 6/64 loss: -1.8479585647583008
Batch 7/64 loss: -2.0861034393310547
Batch 8/64 loss: -1.7936477661132812
Batch 9/64 loss: -1.580789566040039
Batch 10/64 loss: -1.9732275009155273
Batch 11/64 loss: -2.006415367126465
Batch 12/64 loss: -1.8681302070617676
Batch 13/64 loss: -2.1308984756469727
Batch 14/64 loss: -1.2474985122680664
Batch 15/64 loss: -2.145806312561035
Batch 16/64 loss: -1.8644018173217773
Batch 17/64 loss: -1.8849916458129883
Batch 18/64 loss: -1.972402572631836
Batch 19/64 loss: -2.1339797973632812
Batch 20/64 loss: -1.6271476745605469
Batch 21/64 loss: -1.8343143463134766
Batch 22/64 loss: -1.787003517150879
Batch 23/64 loss: -2.017544746398926
Batch 24/64 loss: -1.7626118659973145
Batch 25/64 loss: -2.1109814643859863
Batch 26/64 loss: -1.9291629791259766
Batch 27/64 loss: -1.9020051956176758
Batch 28/64 loss: -1.9936771392822266
Batch 29/64 loss: -1.833022117614746
Batch 30/64 loss: -1.5756864547729492
Batch 31/64 loss: -2.0802454948425293
Batch 32/64 loss: -2.1027421951293945
Batch 33/64 loss: -2.2145299911499023
Batch 34/64 loss: -2.2833032608032227
Batch 35/64 loss: -1.903193473815918
Batch 36/64 loss: -1.8229045867919922
Batch 37/64 loss: -1.860738754272461
Batch 38/64 loss: -1.9625797271728516
Batch 39/64 loss: -1.8388347625732422
Batch 40/64 loss: -1.8467226028442383
Batch 41/64 loss: -1.8443307876586914
Batch 42/64 loss: -2.135572910308838
Batch 43/64 loss: -1.9997668266296387
Batch 44/64 loss: -2.04056453704834
Batch 45/64 loss: -2.0380587577819824
Batch 46/64 loss: -1.991384506225586
Batch 47/64 loss: -1.9413762092590332
Batch 48/64 loss: -2.0112900733947754
Batch 49/64 loss: -2.061406135559082
Batch 50/64 loss: -1.7835545539855957
Batch 51/64 loss: -1.5254316329956055
Batch 52/64 loss: -1.7782363891601562
Batch 53/64 loss: -1.5971307754516602
Batch 54/64 loss: -1.860762596130371
Batch 55/64 loss: -1.6667566299438477
Batch 56/64 loss: -1.8623456954956055
Batch 57/64 loss: -2.0984230041503906
Batch 58/64 loss: -2.243955612182617
Batch 59/64 loss: -2.0588135719299316
Batch 60/64 loss: -1.6904211044311523
Batch 61/64 loss: -1.9511680603027344
Batch 62/64 loss: -1.7592124938964844
Batch 63/64 loss: -1.9706392288208008
Batch 64/64 loss: -6.1861958503723145
Epoch 454  Train loss: -1.9587701367396935  Val loss: -2.1279193707757798
Epoch 455
-------------------------------
Batch 1/64 loss: -1.8432159423828125
Batch 2/64 loss: -1.878666877746582
Batch 3/64 loss: -1.9078450202941895
Batch 4/64 loss: -1.8647918701171875
Batch 5/64 loss: -1.584334373474121
Batch 6/64 loss: -2.1978893280029297
Batch 7/64 loss: -2.134702682495117
Batch 8/64 loss: -2.174346446990967
Batch 9/64 loss: -2.037601947784424
Batch 10/64 loss: -2.1914491653442383
Batch 11/64 loss: -1.8806829452514648
Batch 12/64 loss: -2.028855323791504
Batch 13/64 loss: -1.9700798988342285
Batch 14/64 loss: -1.7298955917358398
Batch 15/64 loss: -1.8533687591552734
Batch 16/64 loss: -1.9692940711975098
Batch 17/64 loss: -1.984426498413086
Batch 18/64 loss: -2.1390905380249023
Batch 19/64 loss: -1.9656333923339844
Batch 20/64 loss: -2.1225199699401855
Batch 21/64 loss: -1.9635372161865234
Batch 22/64 loss: -1.8087091445922852
Batch 23/64 loss: -1.9205479621887207
Batch 24/64 loss: -2.157559394836426
Batch 25/64 loss: -1.7345638275146484
Batch 26/64 loss: -2.0472726821899414
Batch 27/64 loss: -1.707942008972168
Batch 28/64 loss: -2.2522706985473633
Batch 29/64 loss: -2.264641761779785
Batch 30/64 loss: -1.677170753479004
Batch 31/64 loss: -1.9862165451049805
Batch 32/64 loss: -2.1873788833618164
Batch 33/64 loss: -2.1031579971313477
Batch 34/64 loss: -1.4222145080566406
Batch 35/64 loss: -2.0350236892700195
Batch 36/64 loss: -2.042295455932617
Batch 37/64 loss: -2.0544967651367188
Batch 38/64 loss: -1.9601821899414062
Batch 39/64 loss: -1.8950018882751465
Batch 40/64 loss: -2.1314597129821777
Batch 41/64 loss: -1.725778579711914
Batch 42/64 loss: -2.170927047729492
Batch 43/64 loss: -2.007229804992676
Batch 44/64 loss: -1.793212890625
Batch 45/64 loss: -1.710784912109375
Batch 46/64 loss: -1.645289421081543
Batch 47/64 loss: -1.6767158508300781
Batch 48/64 loss: -1.9262266159057617
Batch 49/64 loss: -1.7339630126953125
Batch 50/64 loss: -1.6572799682617188
Batch 51/64 loss: -1.9444150924682617
Batch 52/64 loss: -1.6630878448486328
Batch 53/64 loss: -1.9501028060913086
Batch 54/64 loss: -1.9103689193725586
Batch 55/64 loss: -2.074551582336426
Batch 56/64 loss: -1.8180036544799805
Batch 57/64 loss: -2.127936363220215
Batch 58/64 loss: -1.9239535331726074
Batch 59/64 loss: -1.6373624801635742
Batch 60/64 loss: -1.9829034805297852
Batch 61/64 loss: -1.9051475524902344
Batch 62/64 loss: -1.5183439254760742
Batch 63/64 loss: -1.7724180221557617
Batch 64/64 loss: -6.155360221862793
Epoch 455  Train loss: -1.9718095255833046  Val loss: -2.0995784248273397
Epoch 456
-------------------------------
Batch 1/64 loss: -1.9605588912963867
Batch 2/64 loss: -1.9411706924438477
Batch 3/64 loss: -2.0130186080932617
Batch 4/64 loss: -2.111103057861328
Batch 5/64 loss: -1.397536277770996
Batch 6/64 loss: -2.2664332389831543
Batch 7/64 loss: -1.8320927619934082
Batch 8/64 loss: -1.7336626052856445
Batch 9/64 loss: -1.9355888366699219
Batch 10/64 loss: -2.0717225074768066
Batch 11/64 loss: -2.189302444458008
Batch 12/64 loss: -1.99711275100708
Batch 13/64 loss: -1.8600444793701172
Batch 14/64 loss: -1.7789344787597656
Batch 15/64 loss: -1.9492926597595215
Batch 16/64 loss: -1.7263946533203125
Batch 17/64 loss: -1.859814167022705
Batch 18/64 loss: -1.7995681762695312
Batch 19/64 loss: -1.775646686553955
Batch 20/64 loss: -1.9984440803527832
Batch 21/64 loss: -2.017843246459961
Batch 22/64 loss: -1.711989402770996
Batch 23/64 loss: -1.9107513427734375
Batch 24/64 loss: -1.8580799102783203
Batch 25/64 loss: -1.9586973190307617
Batch 26/64 loss: -1.9502677917480469
Batch 27/64 loss: -2.146817207336426
Batch 28/64 loss: -1.5299530029296875
Batch 29/64 loss: -1.4369888305664062
Batch 30/64 loss: -1.755293846130371
Batch 31/64 loss: -1.9382743835449219
Batch 32/64 loss: -2.184659957885742
Batch 33/64 loss: -1.9477853775024414
Batch 34/64 loss: -1.823124885559082
Batch 35/64 loss: -1.9407386779785156
Batch 36/64 loss: -1.8018827438354492
Batch 37/64 loss: -1.6518182754516602
Batch 38/64 loss: -1.909968376159668
Batch 39/64 loss: -1.8244500160217285
Batch 40/64 loss: -2.1768932342529297
Batch 41/64 loss: -2.086162567138672
Batch 42/64 loss: -1.9666414260864258
Batch 43/64 loss: -1.4712915420532227
Batch 44/64 loss: -2.0441579818725586
Batch 45/64 loss: -1.5438003540039062
Batch 46/64 loss: -1.732020378112793
Batch 47/64 loss: -2.249021530151367
Batch 48/64 loss: -1.6105833053588867
Batch 49/64 loss: -2.1535544395446777
Batch 50/64 loss: -1.9864730834960938
Batch 51/64 loss: -1.9009356498718262
Batch 52/64 loss: -2.1078877449035645
Batch 53/64 loss: -2.057565689086914
Batch 54/64 loss: -1.9577608108520508
Batch 55/64 loss: -1.8672142028808594
Batch 56/64 loss: -2.2079834938049316
Batch 57/64 loss: -2.163015365600586
Batch 58/64 loss: -2.017521381378174
Batch 59/64 loss: -2.2085208892822266
Batch 60/64 loss: -1.3602533340454102
Batch 61/64 loss: -2.018575668334961
Batch 62/64 loss: -1.976733684539795
Batch 63/64 loss: -2.116769790649414
Batch 64/64 loss: -5.30143928527832
Epoch 456  Train loss: -1.9522234299603631  Val loss: -2.0837419778620663
Epoch 457
-------------------------------
Batch 1/64 loss: -1.9494495391845703
Batch 2/64 loss: -1.7143068313598633
Batch 3/64 loss: -1.7180490493774414
Batch 4/64 loss: -1.9102897644042969
Batch 5/64 loss: -1.7928476333618164
Batch 6/64 loss: -2.073319911956787
Batch 7/64 loss: -2.0519490242004395
Batch 8/64 loss: -1.8172187805175781
Batch 9/64 loss: -0.9113712310791016
Batch 10/64 loss: -2.1253738403320312
Batch 11/64 loss: -2.016127586364746
Batch 12/64 loss: -1.6694583892822266
Batch 13/64 loss: -2.041879177093506
Batch 14/64 loss: -2.086040496826172
Batch 15/64 loss: -1.8121614456176758
Batch 16/64 loss: -2.049830436706543
Batch 17/64 loss: -1.9698419570922852
Batch 18/64 loss: -2.2200851440429688
Batch 19/64 loss: -2.0660243034362793
Batch 20/64 loss: -1.5982751846313477
Batch 21/64 loss: -2.002852439880371
Batch 22/64 loss: -2.0364770889282227
Batch 23/64 loss: -1.9072904586791992
Batch 24/64 loss: -2.1319022178649902
Batch 25/64 loss: -1.7496585845947266
Batch 26/64 loss: -1.9188032150268555
Batch 27/64 loss: -1.6193256378173828
Batch 28/64 loss: -1.543874740600586
Batch 29/64 loss: -1.5012760162353516
Batch 30/64 loss: -1.8380327224731445
Batch 31/64 loss: -1.9052162170410156
Batch 32/64 loss: -1.7124509811401367
Batch 33/64 loss: -1.9089784622192383
Batch 34/64 loss: -1.7698869705200195
Batch 35/64 loss: -1.4131050109863281
Batch 36/64 loss: -1.5591506958007812
Batch 37/64 loss: -1.6217670440673828
Batch 38/64 loss: -2.033318519592285
Batch 39/64 loss: -1.9916071891784668
Batch 40/64 loss: -1.7567138671875
Batch 41/64 loss: -1.829742431640625
Batch 42/64 loss: -1.9619455337524414
Batch 43/64 loss: -1.945603370666504
Batch 44/64 loss: -2.1117773056030273
Batch 45/64 loss: -1.4233207702636719
Batch 46/64 loss: -1.4200706481933594
Batch 47/64 loss: -1.5747604370117188
Batch 48/64 loss: -2.0251379013061523
Batch 49/64 loss: -1.6382360458374023
Batch 50/64 loss: -1.8679237365722656
Batch 51/64 loss: -1.7167224884033203
Batch 52/64 loss: -1.688899040222168
Batch 53/64 loss: -1.629929542541504
Batch 54/64 loss: -1.8975200653076172
Batch 55/64 loss: -1.677720069885254
Batch 56/64 loss: -1.7001008987426758
Batch 57/64 loss: -1.7381744384765625
Batch 58/64 loss: -1.5287532806396484
Batch 59/64 loss: -1.882857322692871
Batch 60/64 loss: -1.9189720153808594
Batch 61/64 loss: -1.9731359481811523
Batch 62/64 loss: -1.6298208236694336
Batch 63/64 loss: -1.9937000274658203
Batch 64/64 loss: -5.974512577056885
Epoch 457  Train loss: -1.863079158932555  Val loss: -2.077556413473542
Epoch 458
-------------------------------
Batch 1/64 loss: -2.0382747650146484
Batch 2/64 loss: -2.0237655639648438
Batch 3/64 loss: -1.5083484649658203
Batch 4/64 loss: -1.8213787078857422
Batch 5/64 loss: -2.076632022857666
Batch 6/64 loss: -1.9501538276672363
Batch 7/64 loss: -1.7891297340393066
Batch 8/64 loss: -2.1168861389160156
Batch 9/64 loss: -1.813798427581787
Batch 10/64 loss: -1.8176078796386719
Batch 11/64 loss: -1.8323392868041992
Batch 12/64 loss: -1.5238027572631836
Batch 13/64 loss: -1.8720431327819824
Batch 14/64 loss: -1.9899482727050781
Batch 15/64 loss: -1.9561662673950195
Batch 16/64 loss: -2.00919246673584
Batch 17/64 loss: -1.5228214263916016
Batch 18/64 loss: -1.9496135711669922
Batch 19/64 loss: -2.063119888305664
Batch 20/64 loss: -1.3672866821289062
Batch 21/64 loss: -1.9792394638061523
Batch 22/64 loss: -2.011563777923584
Batch 23/64 loss: -1.8428764343261719
Batch 24/64 loss: -2.0870471000671387
Batch 25/64 loss: -2.062602996826172
Batch 26/64 loss: -1.989628791809082
Batch 27/64 loss: -1.5718727111816406
Batch 28/64 loss: -2.14762020111084
Batch 29/64 loss: -1.9352178573608398
Batch 30/64 loss: -2.211662769317627
Batch 31/64 loss: -2.0121545791625977
Batch 32/64 loss: -2.214477062225342
Batch 33/64 loss: -1.5999984741210938
Batch 34/64 loss: -2.097683906555176
Batch 35/64 loss: -1.9509038925170898
Batch 36/64 loss: -1.775740146636963
Batch 37/64 loss: -1.6418333053588867
Batch 38/64 loss: -1.9867501258850098
Batch 39/64 loss: -2.0795345306396484
Batch 40/64 loss: -1.9758954048156738
Batch 41/64 loss: -1.5514860153198242
Batch 42/64 loss: -1.4721059799194336
Batch 43/64 loss: -2.090897560119629
Batch 44/64 loss: -2.079360008239746
Batch 45/64 loss: -1.9465608596801758
Batch 46/64 loss: -1.7805767059326172
Batch 47/64 loss: -1.3940925598144531
Batch 48/64 loss: -1.4123735427856445
Batch 49/64 loss: -1.955948829650879
Batch 50/64 loss: -1.6916532516479492
Batch 51/64 loss: -2.1814255714416504
Batch 52/64 loss: -1.8826303482055664
Batch 53/64 loss: -1.9314470291137695
Batch 54/64 loss: -2.02675724029541
Batch 55/64 loss: -1.9641199111938477
Batch 56/64 loss: -1.8850107192993164
Batch 57/64 loss: -2.189795970916748
Batch 58/64 loss: -1.4072675704956055
Batch 59/64 loss: -2.0441575050354004
Batch 60/64 loss: -2.0398316383361816
Batch 61/64 loss: -1.998286247253418
Batch 62/64 loss: -2.181671619415283
Batch 63/64 loss: -2.0916237831115723
Batch 64/64 loss: -6.000957012176514
Epoch 458  Train loss: -1.943786839877858  Val loss: -2.0570104671098113
Epoch 459
-------------------------------
Batch 1/64 loss: -2.127041816711426
Batch 2/64 loss: -1.833444595336914
Batch 3/64 loss: -1.6889400482177734
Batch 4/64 loss: -2.030533790588379
Batch 5/64 loss: -1.856898307800293
Batch 6/64 loss: -2.01650333404541
Batch 7/64 loss: -2.1397948265075684
Batch 8/64 loss: -1.6733484268188477
Batch 9/64 loss: -1.8682870864868164
Batch 10/64 loss: -1.6126899719238281
Batch 11/64 loss: -1.9276723861694336
Batch 12/64 loss: -2.157634735107422
Batch 13/64 loss: -2.1342368125915527
Batch 14/64 loss: -1.8224925994873047
Batch 15/64 loss: -1.870931625366211
Batch 16/64 loss: -1.819230079650879
Batch 17/64 loss: -1.7205543518066406
Batch 18/64 loss: -1.9787559509277344
Batch 19/64 loss: -1.365086555480957
Batch 20/64 loss: -1.6564626693725586
Batch 21/64 loss: -1.6937141418457031
Batch 22/64 loss: -2.0671496391296387
Batch 23/64 loss: -2.0152173042297363
Batch 24/64 loss: -1.962961196899414
Batch 25/64 loss: -1.8712739944458008
Batch 26/64 loss: -1.9118413925170898
Batch 27/64 loss: -1.3581390380859375
Batch 28/64 loss: -1.8501825332641602
Batch 29/64 loss: -2.080573081970215
Batch 30/64 loss: -2.0581979751586914
Batch 31/64 loss: -1.6160945892333984
Batch 32/64 loss: -1.8677597045898438
Batch 33/64 loss: -1.834299087524414
Batch 34/64 loss: -1.7310028076171875
Batch 35/64 loss: -1.5928897857666016
Batch 36/64 loss: -1.8438968658447266
Batch 37/64 loss: -1.5764055252075195
Batch 38/64 loss: -1.6099939346313477
Batch 39/64 loss: -2.248316764831543
Batch 40/64 loss: -1.5522565841674805
Batch 41/64 loss: -1.9445586204528809
Batch 42/64 loss: -1.3295774459838867
Batch 43/64 loss: -1.6646547317504883
Batch 44/64 loss: -1.4644765853881836
Batch 45/64 loss: -1.8809013366699219
Batch 46/64 loss: -1.8746938705444336
Batch 47/64 loss: -1.7895355224609375
Batch 48/64 loss: -1.900339126586914
Batch 49/64 loss: -2.1945672035217285
Batch 50/64 loss: -2.131875991821289
Batch 51/64 loss: -1.9604301452636719
Batch 52/64 loss: -2.067105293273926
Batch 53/64 loss: -1.883101463317871
Batch 54/64 loss: -1.8433313369750977
Batch 55/64 loss: -2.21665620803833
Batch 56/64 loss: -2.054109573364258
Batch 57/64 loss: -1.9250373840332031
Batch 58/64 loss: -1.3878517150878906
Batch 59/64 loss: -2.0262861251831055
Batch 60/64 loss: -2.045046329498291
Batch 61/64 loss: -1.7267322540283203
Batch 62/64 loss: -1.5710315704345703
Batch 63/64 loss: -1.6522331237792969
Batch 64/64 loss: -5.568319320678711
Epoch 459  Train loss: -1.887891425338446  Val loss: -2.077418297836461
Epoch 460
-------------------------------
Batch 1/64 loss: -1.8046607971191406
Batch 2/64 loss: -2.035250663757324
Batch 3/64 loss: -1.6055889129638672
Batch 4/64 loss: -1.8544950485229492
Batch 5/64 loss: -1.6384735107421875
Batch 6/64 loss: -1.714034080505371
Batch 7/64 loss: -2.032106399536133
Batch 8/64 loss: -1.2506084442138672
Batch 9/64 loss: -2.0594797134399414
Batch 10/64 loss: -1.9359169006347656
Batch 11/64 loss: -1.6272716522216797
Batch 12/64 loss: -1.506749153137207
Batch 13/64 loss: -2.066704750061035
Batch 14/64 loss: -1.7615609169006348
Batch 15/64 loss: -1.483917236328125
Batch 16/64 loss: -2.1941733360290527
Batch 17/64 loss: -1.8360986709594727
Batch 18/64 loss: -2.069352149963379
Batch 19/64 loss: -1.8833303451538086
Batch 20/64 loss: -1.8886852264404297
Batch 21/64 loss: -1.9418396949768066
Batch 22/64 loss: -1.6700849533081055
Batch 23/64 loss: -1.909379482269287
Batch 24/64 loss: -2.0796074867248535
Batch 25/64 loss: -1.9336576461791992
Batch 26/64 loss: -2.1346988677978516
Batch 27/64 loss: -1.5738239288330078
Batch 28/64 loss: -2.05983304977417
Batch 29/64 loss: -1.9618968963623047
Batch 30/64 loss: -2.130575180053711
Batch 31/64 loss: -1.2672185897827148
Batch 32/64 loss: -1.9049639701843262
Batch 33/64 loss: -1.7748746871948242
Batch 34/64 loss: -2.015672206878662
Batch 35/64 loss: -1.923518180847168
Batch 36/64 loss: -2.0003433227539062
Batch 37/64 loss: -1.9367733001708984
Batch 38/64 loss: -1.6533288955688477
Batch 39/64 loss: -1.939438819885254
Batch 40/64 loss: -1.499680519104004
Batch 41/64 loss: -2.16471004486084
Batch 42/64 loss: -2.063868999481201
Batch 43/64 loss: -1.9958229064941406
Batch 44/64 loss: -1.53857421875
Batch 45/64 loss: -1.9327244758605957
Batch 46/64 loss: -1.7617015838623047
Batch 47/64 loss: -1.9310259819030762
Batch 48/64 loss: -1.8445501327514648
Batch 49/64 loss: -1.884589672088623
Batch 50/64 loss: -1.9364686012268066
Batch 51/64 loss: -2.2617006301879883
Batch 52/64 loss: -1.8833093643188477
Batch 53/64 loss: -1.7462167739868164
Batch 54/64 loss: -2.042400360107422
Batch 55/64 loss: -2.0936717987060547
Batch 56/64 loss: -2.081749439239502
Batch 57/64 loss: -1.3236732482910156
Batch 58/64 loss: -1.8471388816833496
Batch 59/64 loss: -1.7380404472351074
Batch 60/64 loss: -2.0437064170837402
Batch 61/64 loss: -1.835561752319336
Batch 62/64 loss: -1.9969749450683594
Batch 63/64 loss: -1.8443140983581543
Batch 64/64 loss: -5.966592788696289
Epoch 460  Train loss: -1.9110134423947802  Val loss: -2.1488153254453257
Epoch 461
-------------------------------
Batch 1/64 loss: -1.772179126739502
Batch 2/64 loss: -1.8388471603393555
Batch 3/64 loss: -1.983759880065918
Batch 4/64 loss: -1.939195156097412
Batch 5/64 loss: -1.786097526550293
Batch 6/64 loss: -1.9345579147338867
Batch 7/64 loss: -1.8439440727233887
Batch 8/64 loss: -1.8802003860473633
Batch 9/64 loss: -1.8519668579101562
Batch 10/64 loss: -2.1071739196777344
Batch 11/64 loss: -2.1965527534484863
Batch 12/64 loss: -2.047748565673828
Batch 13/64 loss: -2.125624179840088
Batch 14/64 loss: -1.9687519073486328
Batch 15/64 loss: -1.7889795303344727
Batch 16/64 loss: -1.9281997680664062
Batch 17/64 loss: -1.9538154602050781
Batch 18/64 loss: -2.0610437393188477
Batch 19/64 loss: -2.0431385040283203
Batch 20/64 loss: -2.0679502487182617
Batch 21/64 loss: -2.076681137084961
Batch 22/64 loss: -1.9425263404846191
Batch 23/64 loss: -1.7364845275878906
Batch 24/64 loss: -1.981766700744629
Batch 25/64 loss: -1.8728790283203125
Batch 26/64 loss: -2.073622226715088
Batch 27/64 loss: -1.8393940925598145
Batch 28/64 loss: -1.843834400177002
Batch 29/64 loss: -1.979994773864746
Batch 30/64 loss: -1.974013328552246
Batch 31/64 loss: -1.8787527084350586
Batch 32/64 loss: -2.075900077819824
Batch 33/64 loss: -1.7337779998779297
Batch 34/64 loss: -1.9811897277832031
Batch 35/64 loss: -1.0070209503173828
Batch 36/64 loss: -1.7469778060913086
Batch 37/64 loss: -1.8150882720947266
Batch 38/64 loss: -1.5461511611938477
Batch 39/64 loss: -1.9747810363769531
Batch 40/64 loss: -2.0523548126220703
Batch 41/64 loss: -2.1257224082946777
Batch 42/64 loss: -1.9954757690429688
Batch 43/64 loss: -1.8995628356933594
Batch 44/64 loss: -2.0808844566345215
Batch 45/64 loss: -1.4420652389526367
Batch 46/64 loss: -2.2310800552368164
Batch 47/64 loss: -2.1302242279052734
Batch 48/64 loss: -2.1636924743652344
Batch 49/64 loss: -1.573984146118164
Batch 50/64 loss: -1.8818483352661133
Batch 51/64 loss: -1.5309505462646484
Batch 52/64 loss: -1.4070148468017578
Batch 53/64 loss: -1.9268994331359863
Batch 54/64 loss: -1.9775900840759277
Batch 55/64 loss: -1.9446039199829102
Batch 56/64 loss: -1.1829423904418945
Batch 57/64 loss: -2.1634669303894043
Batch 58/64 loss: -2.1539878845214844
Batch 59/64 loss: -2.0419201850891113
Batch 60/64 loss: -2.0280489921569824
Batch 61/64 loss: -2.033395290374756
Batch 62/64 loss: -2.137479782104492
Batch 63/64 loss: -1.8426265716552734
Batch 64/64 loss: -5.6583757400512695
Epoch 461  Train loss: -1.9512496686449239  Val loss: -2.1482250305385526
Epoch 462
-------------------------------
Batch 1/64 loss: -1.771529197692871
Batch 2/64 loss: -1.6619014739990234
Batch 3/64 loss: -1.8136258125305176
Batch 4/64 loss: -2.043973922729492
Batch 5/64 loss: -1.773681640625
Batch 6/64 loss: -2.2491488456726074
Batch 7/64 loss: -1.665989875793457
Batch 8/64 loss: -1.932389259338379
Batch 9/64 loss: -1.9725914001464844
Batch 10/64 loss: -1.8392763137817383
Batch 11/64 loss: -1.9406352043151855
Batch 12/64 loss: -1.909367561340332
Batch 13/64 loss: -2.0696611404418945
Batch 14/64 loss: -1.9679360389709473
Batch 15/64 loss: -1.9171414375305176
Batch 16/64 loss: -2.0229616165161133
Batch 17/64 loss: -2.0368313789367676
Batch 18/64 loss: -2.0890560150146484
Batch 19/64 loss: -2.197652816772461
Batch 20/64 loss: -1.9335498809814453
Batch 21/64 loss: -1.9581193923950195
Batch 22/64 loss: -1.5503644943237305
Batch 23/64 loss: -1.902775764465332
Batch 24/64 loss: -0.9886045455932617
Batch 25/64 loss: -1.6474266052246094
Batch 26/64 loss: -1.883354663848877
Batch 27/64 loss: -1.910919189453125
Batch 28/64 loss: -1.816171646118164
Batch 29/64 loss: -1.9240808486938477
Batch 30/64 loss: -2.0995678901672363
Batch 31/64 loss: -2.0811538696289062
Batch 32/64 loss: -1.7466325759887695
Batch 33/64 loss: -1.9495368003845215
Batch 34/64 loss: -1.7492351531982422
Batch 35/64 loss: -2.130621910095215
Batch 36/64 loss: -1.7407035827636719
Batch 37/64 loss: -1.5636615753173828
Batch 38/64 loss: -1.9590864181518555
Batch 39/64 loss: -2.040431022644043
Batch 40/64 loss: -1.7740449905395508
Batch 41/64 loss: -1.8968009948730469
Batch 42/64 loss: -1.465902328491211
Batch 43/64 loss: -1.7933568954467773
Batch 44/64 loss: -1.6793060302734375
Batch 45/64 loss: -1.590327262878418
Batch 46/64 loss: -1.9142818450927734
Batch 47/64 loss: -2.1820249557495117
Batch 48/64 loss: -1.9375591278076172
Batch 49/64 loss: -1.8345518112182617
Batch 50/64 loss: -2.0873141288757324
Batch 51/64 loss: -1.9524774551391602
Batch 52/64 loss: -1.5439748764038086
Batch 53/64 loss: -2.1472959518432617
Batch 54/64 loss: -2.164947509765625
Batch 55/64 loss: -1.8921847343444824
Batch 56/64 loss: -1.9420514106750488
Batch 57/64 loss: -2.049245834350586
Batch 58/64 loss: -2.0212230682373047
Batch 59/64 loss: -2.134690761566162
Batch 60/64 loss: -2.011049270629883
Batch 61/64 loss: -1.9281368255615234
Batch 62/64 loss: -1.795649528503418
Batch 63/64 loss: -1.7441596984863281
Batch 64/64 loss: -5.870451927185059
Epoch 462  Train loss: -1.934694039587881  Val loss: -1.9745196444062434
Epoch 463
-------------------------------
Batch 1/64 loss: -2.18403959274292
Batch 2/64 loss: -1.655853271484375
Batch 3/64 loss: -1.9350223541259766
Batch 4/64 loss: -1.9212169647216797
Batch 5/64 loss: -1.8961200714111328
Batch 6/64 loss: -1.9133644104003906
Batch 7/64 loss: -1.2402124404907227
Batch 8/64 loss: -1.4010143280029297
Batch 9/64 loss: -1.2636957168579102
Batch 10/64 loss: -1.7813291549682617
Batch 11/64 loss: -1.7794437408447266
Batch 12/64 loss: -1.9017372131347656
Batch 13/64 loss: -2.155423164367676
Batch 14/64 loss: -1.8134498596191406
Batch 15/64 loss: -2.1153268814086914
Batch 16/64 loss: -2.035691261291504
Batch 17/64 loss: -1.7113409042358398
Batch 18/64 loss: -1.9727087020874023
Batch 19/64 loss: -1.7037019729614258
Batch 20/64 loss: -1.5189933776855469
Batch 21/64 loss: -1.9638910293579102
Batch 22/64 loss: -1.8227691650390625
Batch 23/64 loss: -2.0841550827026367
Batch 24/64 loss: -1.8107919692993164
Batch 25/64 loss: -2.176077365875244
Batch 26/64 loss: -2.0450439453125
Batch 27/64 loss: -1.7068967819213867
Batch 28/64 loss: -2.100749969482422
Batch 29/64 loss: -1.364100456237793
Batch 30/64 loss: -1.6986169815063477
Batch 31/64 loss: -1.9818453788757324
Batch 32/64 loss: -1.8809633255004883
Batch 33/64 loss: -1.9241294860839844
Batch 34/64 loss: -1.8407278060913086
Batch 35/64 loss: -1.954463005065918
Batch 36/64 loss: -1.509016990661621
Batch 37/64 loss: -2.008230209350586
Batch 38/64 loss: -2.019404888153076
Batch 39/64 loss: -1.9189825057983398
Batch 40/64 loss: -2.1062545776367188
Batch 41/64 loss: -2.0518245697021484
Batch 42/64 loss: -1.3565120697021484
Batch 43/64 loss: -1.975296974182129
Batch 44/64 loss: -2.025289535522461
Batch 45/64 loss: -2.103761672973633
Batch 46/64 loss: -2.0161099433898926
Batch 47/64 loss: -2.2250266075134277
Batch 48/64 loss: -1.6802854537963867
Batch 49/64 loss: -1.572732925415039
Batch 50/64 loss: -2.0658135414123535
Batch 51/64 loss: -1.8601970672607422
Batch 52/64 loss: -2.1116485595703125
Batch 53/64 loss: -2.0202393531799316
Batch 54/64 loss: -2.1641087532043457
Batch 55/64 loss: -1.880356788635254
Batch 56/64 loss: -2.292224884033203
Batch 57/64 loss: -2.1393747329711914
Batch 58/64 loss: -1.5116119384765625
Batch 59/64 loss: -2.0299859046936035
Batch 60/64 loss: -2.049802303314209
Batch 61/64 loss: -2.144618511199951
Batch 62/64 loss: -2.0224733352661133
Batch 63/64 loss: -1.8232417106628418
Batch 64/64 loss: -5.87033224105835
Epoch 463  Train loss: -1.9347777665830126  Val loss: -2.203858431262249
Epoch 464
-------------------------------
Batch 1/64 loss: -1.976144790649414
Batch 2/64 loss: -1.957341194152832
Batch 3/64 loss: -1.8847661018371582
Batch 4/64 loss: -2.05645751953125
Batch 5/64 loss: -2.1960830688476562
Batch 6/64 loss: -1.9931144714355469
Batch 7/64 loss: -2.0159759521484375
Batch 8/64 loss: -1.9087114334106445
Batch 9/64 loss: -1.9099597930908203
Batch 10/64 loss: -2.1817212104797363
Batch 11/64 loss: -2.1333136558532715
Batch 12/64 loss: -1.773386001586914
Batch 13/64 loss: -1.8278388977050781
Batch 14/64 loss: -1.5115737915039062
Batch 15/64 loss: -2.1123809814453125
Batch 16/64 loss: -2.007322311401367
Batch 17/64 loss: -2.0487723350524902
Batch 18/64 loss: -2.0644240379333496
Batch 19/64 loss: -2.082411766052246
Batch 20/64 loss: -2.1102256774902344
Batch 21/64 loss: -1.7760076522827148
Batch 22/64 loss: -2.1114959716796875
Batch 23/64 loss: -1.6748180389404297
Batch 24/64 loss: -1.91070556640625
Batch 25/64 loss: -1.7611150741577148
Batch 26/64 loss: -2.0679550170898438
Batch 27/64 loss: -1.7733993530273438
Batch 28/64 loss: -1.6030387878417969
Batch 29/64 loss: -2.1988749504089355
Batch 30/64 loss: -2.182915210723877
Batch 31/64 loss: -1.4982614517211914
Batch 32/64 loss: -1.8552656173706055
Batch 33/64 loss: -2.1332335472106934
Batch 34/64 loss: -1.7638750076293945
Batch 35/64 loss: -1.6936321258544922
Batch 36/64 loss: -1.8989953994750977
Batch 37/64 loss: -1.7361974716186523
Batch 38/64 loss: -1.847557544708252
Batch 39/64 loss: -1.9275341033935547
Batch 40/64 loss: -1.6420660018920898
Batch 41/64 loss: -1.6006393432617188
Batch 42/64 loss: -1.614821434020996
Batch 43/64 loss: -2.076571464538574
Batch 44/64 loss: -2.075436592102051
Batch 45/64 loss: -1.873530387878418
Batch 46/64 loss: -2.016082763671875
Batch 47/64 loss: -1.801332950592041
Batch 48/64 loss: -2.1012368202209473
Batch 49/64 loss: -1.9497499465942383
Batch 50/64 loss: -1.637237548828125
Batch 51/64 loss: -2.123270034790039
Batch 52/64 loss: -2.0392465591430664
Batch 53/64 loss: -1.544748306274414
Batch 54/64 loss: -1.8369035720825195
Batch 55/64 loss: -2.0233612060546875
Batch 56/64 loss: -1.9459528923034668
Batch 57/64 loss: -1.845315933227539
Batch 58/64 loss: -1.8984708786010742
Batch 59/64 loss: -2.0795273780822754
Batch 60/64 loss: -2.186224937438965
Batch 61/64 loss: -1.6430964469909668
Batch 62/64 loss: -2.0828542709350586
Batch 63/64 loss: -1.825650691986084
Batch 64/64 loss: -6.215086460113525
Epoch 464  Train loss: -1.9653560170940325  Val loss: -2.1971847429308284
Epoch 465
-------------------------------
Batch 1/64 loss: -2.0580592155456543
Batch 2/64 loss: -1.9322915077209473
Batch 3/64 loss: -1.9650249481201172
Batch 4/64 loss: -2.109590530395508
Batch 5/64 loss: -2.0845284461975098
Batch 6/64 loss: -1.8884477615356445
Batch 7/64 loss: -2.1213302612304688
Batch 8/64 loss: -2.0960583686828613
Batch 9/64 loss: -2.1244149208068848
Batch 10/64 loss: -1.8322534561157227
Batch 11/64 loss: -1.8396344184875488
Batch 12/64 loss: -1.886636734008789
Batch 13/64 loss: -1.7562894821166992
Batch 14/64 loss: -1.9620361328125
Batch 15/64 loss: -2.2226362228393555
Batch 16/64 loss: -1.851881504058838
Batch 17/64 loss: -1.9050559997558594
Batch 18/64 loss: -1.904487133026123
Batch 19/64 loss: -2.099860191345215
Batch 20/64 loss: -2.1587047576904297
Batch 21/64 loss: -1.9157819747924805
Batch 22/64 loss: -1.817214012145996
Batch 23/64 loss: -1.9115629196166992
Batch 24/64 loss: -1.8957586288452148
Batch 25/64 loss: -2.0701942443847656
Batch 26/64 loss: -2.1861324310302734
Batch 27/64 loss: -2.2123231887817383
Batch 28/64 loss: -2.0681238174438477
Batch 29/64 loss: -1.945596694946289
Batch 30/64 loss: -1.7307500839233398
Batch 31/64 loss: -1.8994688987731934
Batch 32/64 loss: -2.31292724609375
Batch 33/64 loss: -1.8126869201660156
Batch 34/64 loss: -2.0076403617858887
Batch 35/64 loss: -1.9311094284057617
Batch 36/64 loss: -1.9317269325256348
Batch 37/64 loss: -1.7667865753173828
Batch 38/64 loss: -2.0031299591064453
Batch 39/64 loss: -2.033294677734375
Batch 40/64 loss: -1.613408088684082
Batch 41/64 loss: -1.550614356994629
Batch 42/64 loss: -2.0605640411376953
Batch 43/64 loss: -2.0857410430908203
Batch 44/64 loss: -2.257300853729248
Batch 45/64 loss: -1.9253530502319336
Batch 46/64 loss: -1.5700263977050781
Batch 47/64 loss: -2.1187047958374023
Batch 48/64 loss: -2.0047779083251953
Batch 49/64 loss: -1.5283384323120117
Batch 50/64 loss: -1.9600162506103516
Batch 51/64 loss: -1.829690933227539
Batch 52/64 loss: -1.930854320526123
Batch 53/64 loss: -2.0853710174560547
Batch 54/64 loss: -1.953963279724121
Batch 55/64 loss: -2.2921509742736816
Batch 56/64 loss: -2.138683795928955
Batch 57/64 loss: -1.9213504791259766
Batch 58/64 loss: -1.79793119430542
Batch 59/64 loss: -1.8553638458251953
Batch 60/64 loss: -2.0624170303344727
Batch 61/64 loss: -2.038681983947754
Batch 62/64 loss: -1.5519533157348633
Batch 63/64 loss: -1.7263917922973633
Batch 64/64 loss: -5.715030670166016
Epoch 465  Train loss: -1.9983898536831726  Val loss: -2.173658102238711
Epoch 466
-------------------------------
Batch 1/64 loss: -1.9961729049682617
Batch 2/64 loss: -1.5047807693481445
Batch 3/64 loss: -1.8150396347045898
Batch 4/64 loss: -1.4093704223632812
Batch 5/64 loss: -1.8222136497497559
Batch 6/64 loss: -2.051943302154541
Batch 7/64 loss: -1.9614667892456055
Batch 8/64 loss: -1.9254398345947266
Batch 9/64 loss: -1.8280868530273438
Batch 10/64 loss: -1.7260751724243164
Batch 11/64 loss: -1.7813520431518555
Batch 12/64 loss: -1.8108339309692383
Batch 13/64 loss: -2.0912933349609375
Batch 14/64 loss: -1.7845535278320312
Batch 15/64 loss: -1.631525993347168
Batch 16/64 loss: -1.8556394577026367
Batch 17/64 loss: -1.8509702682495117
Batch 18/64 loss: -1.917790412902832
Batch 19/64 loss: -2.024333953857422
Batch 20/64 loss: -1.7738285064697266
Batch 21/64 loss: -1.875070571899414
Batch 22/64 loss: -1.8775901794433594
Batch 23/64 loss: -2.1220288276672363
Batch 24/64 loss: -1.8990974426269531
Batch 25/64 loss: -2.0765857696533203
Batch 26/64 loss: -1.4434471130371094
Batch 27/64 loss: -1.898885726928711
Batch 28/64 loss: -2.0633625984191895
Batch 29/64 loss: -1.996361255645752
Batch 30/64 loss: -2.0336461067199707
Batch 31/64 loss: -1.9317512512207031
Batch 32/64 loss: -2.0924859046936035
Batch 33/64 loss: -1.9466514587402344
Batch 34/64 loss: -1.9023404121398926
Batch 35/64 loss: -1.6999683380126953
Batch 36/64 loss: -1.7896623611450195
Batch 37/64 loss: -1.984476089477539
Batch 38/64 loss: -1.632899284362793
Batch 39/64 loss: -2.0955257415771484
Batch 40/64 loss: -1.9665179252624512
Batch 41/64 loss: -2.156618595123291
Batch 42/64 loss: -1.9254150390625
Batch 43/64 loss: -1.9566364288330078
Batch 44/64 loss: -2.06032657623291
Batch 45/64 loss: -2.0706491470336914
Batch 46/64 loss: -1.480936050415039
Batch 47/64 loss: -1.873016357421875
Batch 48/64 loss: -2.056325912475586
Batch 49/64 loss: -2.0818843841552734
Batch 50/64 loss: -2.1288442611694336
Batch 51/64 loss: -2.129004955291748
Batch 52/64 loss: -2.051638126373291
Batch 53/64 loss: -1.8210515975952148
Batch 54/64 loss: -2.167527198791504
Batch 55/64 loss: -1.9530034065246582
Batch 56/64 loss: -2.2155895233154297
Batch 57/64 loss: -2.121204376220703
Batch 58/64 loss: -1.817126750946045
Batch 59/64 loss: -1.9890460968017578
Batch 60/64 loss: -1.7884407043457031
Batch 61/64 loss: -2.084664821624756
Batch 62/64 loss: -1.9921503067016602
Batch 63/64 loss: -2.0775070190429688
Batch 64/64 loss: -6.094744682312012
Epoch 466  Train loss: -1.9680114708694758  Val loss: -2.1456145846966614
Epoch 467
-------------------------------
Batch 1/64 loss: -2.1558279991149902
Batch 2/64 loss: -1.9662528038024902
Batch 3/64 loss: -2.055023670196533
Batch 4/64 loss: -2.1636061668395996
Batch 5/64 loss: -2.187600612640381
Batch 6/64 loss: -1.8816871643066406
Batch 7/64 loss: -2.107788562774658
Batch 8/64 loss: -1.6383132934570312
Batch 9/64 loss: -1.9379091262817383
Batch 10/64 loss: -1.6718034744262695
Batch 11/64 loss: -1.9259400367736816
Batch 12/64 loss: -1.7709674835205078
Batch 13/64 loss: -1.8901457786560059
Batch 14/64 loss: -1.6027679443359375
Batch 15/64 loss: -1.618758201599121
Batch 16/64 loss: -2.1434712409973145
Batch 17/64 loss: -1.8696823120117188
Batch 18/64 loss: -1.9534368515014648
Batch 19/64 loss: -1.5010786056518555
Batch 20/64 loss: -1.4901247024536133
Batch 21/64 loss: -1.7154121398925781
Batch 22/64 loss: -1.6196422576904297
Batch 23/64 loss: -1.9804072380065918
Batch 24/64 loss: -2.007838249206543
Batch 25/64 loss: -2.1169967651367188
Batch 26/64 loss: -1.8943424224853516
Batch 27/64 loss: -2.079120635986328
Batch 28/64 loss: -1.7312698364257812
Batch 29/64 loss: -2.0391077995300293
Batch 30/64 loss: -1.962796688079834
Batch 31/64 loss: -2.1108832359313965
Batch 32/64 loss: -2.0202279090881348
Batch 33/64 loss: -2.0562939643859863
Batch 34/64 loss: -1.9065618515014648
Batch 35/64 loss: -2.2836036682128906
Batch 36/64 loss: -1.9432458877563477
Batch 37/64 loss: -2.2359976768493652
Batch 38/64 loss: -1.9263052940368652
Batch 39/64 loss: -1.9052448272705078
Batch 40/64 loss: -2.134507656097412
Batch 41/64 loss: -2.278367519378662
Batch 42/64 loss: -1.6455698013305664
Batch 43/64 loss: -1.8530831336975098
Batch 44/64 loss: -1.908696174621582
Batch 45/64 loss: -1.810256004333496
Batch 46/64 loss: -2.0697240829467773
Batch 47/64 loss: -1.8831024169921875
Batch 48/64 loss: -1.7958478927612305
Batch 49/64 loss: -1.6220073699951172
Batch 50/64 loss: -1.8496856689453125
Batch 51/64 loss: -1.7658014297485352
Batch 52/64 loss: -1.9339704513549805
Batch 53/64 loss: -1.6591510772705078
Batch 54/64 loss: -1.837364673614502
Batch 55/64 loss: -1.9449057579040527
Batch 56/64 loss: -1.8707208633422852
Batch 57/64 loss: -2.010568141937256
Batch 58/64 loss: -2.010148048400879
Batch 59/64 loss: -2.1460676193237305
Batch 60/64 loss: -1.8356618881225586
Batch 61/64 loss: -1.961195468902588
Batch 62/64 loss: -2.068376064300537
Batch 63/64 loss: -1.745518684387207
Batch 64/64 loss: -5.954599380493164
Epoch 467  Train loss: -1.9635095184924556  Val loss: -2.142293661320742
Epoch 468
-------------------------------
Batch 1/64 loss: -1.9232063293457031
Batch 2/64 loss: -1.7533817291259766
Batch 3/64 loss: -1.8085265159606934
Batch 4/64 loss: -1.641127586364746
Batch 5/64 loss: -1.9250144958496094
Batch 6/64 loss: -1.9017162322998047
Batch 7/64 loss: -1.948552131652832
Batch 8/64 loss: -1.8867740631103516
Batch 9/64 loss: -1.818760871887207
Batch 10/64 loss: -1.8615503311157227
Batch 11/64 loss: -1.879556655883789
Batch 12/64 loss: -1.6387109756469727
Batch 13/64 loss: -1.786757469177246
Batch 14/64 loss: -1.5938472747802734
Batch 15/64 loss: -1.801426887512207
Batch 16/64 loss: -2.04672908782959
Batch 17/64 loss: -2.008544921875
Batch 18/64 loss: -1.5555315017700195
Batch 19/64 loss: -2.2258219718933105
Batch 20/64 loss: -2.1217246055603027
Batch 21/64 loss: -2.1586174964904785
Batch 22/64 loss: -1.98630952835083
Batch 23/64 loss: -2.2181992530822754
Batch 24/64 loss: -2.146583080291748
Batch 25/64 loss: -1.6738719940185547
Batch 26/64 loss: -1.964503288269043
Batch 27/64 loss: -2.129173755645752
Batch 28/64 loss: -1.765054702758789
Batch 29/64 loss: -2.150357246398926
Batch 30/64 loss: -1.995713233947754
Batch 31/64 loss: -1.6975030899047852
Batch 32/64 loss: -2.0128746032714844
Batch 33/64 loss: -1.8419032096862793
Batch 34/64 loss: -2.0764331817626953
Batch 35/64 loss: -1.978302001953125
Batch 36/64 loss: -2.122237205505371
Batch 37/64 loss: -2.0488977432250977
Batch 38/64 loss: -1.90311861038208
Batch 39/64 loss: -2.026799201965332
Batch 40/64 loss: -2.1771140098571777
Batch 41/64 loss: -1.7954411506652832
Batch 42/64 loss: -2.163694381713867
Batch 43/64 loss: -2.1098341941833496
Batch 44/64 loss: -1.8531904220581055
Batch 45/64 loss: -1.9661788940429688
Batch 46/64 loss: -2.0637736320495605
Batch 47/64 loss: -1.8219547271728516
Batch 48/64 loss: -2.212209701538086
Batch 49/64 loss: -2.1118993759155273
Batch 50/64 loss: -2.292829990386963
Batch 51/64 loss: -1.9187383651733398
Batch 52/64 loss: -2.231764793395996
Batch 53/64 loss: -2.1036367416381836
Batch 54/64 loss: -2.2130203247070312
Batch 55/64 loss: -1.92431640625
Batch 56/64 loss: -1.9796204566955566
Batch 57/64 loss: -2.178447723388672
Batch 58/64 loss: -1.8184394836425781
Batch 59/64 loss: -2.0760936737060547
Batch 60/64 loss: -2.1135711669921875
Batch 61/64 loss: -1.9992012977600098
Batch 62/64 loss: -2.1329593658447266
Batch 63/64 loss: -1.946291446685791
Batch 64/64 loss: -6.087853908538818
Epoch 468  Train loss: -2.0202953132928587  Val loss: -2.2297725480856356
Saving best model, epoch: 468
Epoch 469
-------------------------------
Batch 1/64 loss: -2.0709633827209473
Batch 2/64 loss: -2.167043685913086
Batch 3/64 loss: -1.8544654846191406
Batch 4/64 loss: -1.9272541999816895
Batch 5/64 loss: -1.891291618347168
Batch 6/64 loss: -2.0325465202331543
Batch 7/64 loss: -1.621079444885254
Batch 8/64 loss: -2.0847272872924805
Batch 9/64 loss: -1.5581254959106445
Batch 10/64 loss: -2.0726757049560547
Batch 11/64 loss: -2.0117969512939453
Batch 12/64 loss: -1.985076904296875
Batch 13/64 loss: -2.228013038635254
Batch 14/64 loss: -2.0741958618164062
Batch 15/64 loss: -2.062776565551758
Batch 16/64 loss: -1.9037590026855469
Batch 17/64 loss: -1.950089454650879
Batch 18/64 loss: -1.4313344955444336
Batch 19/64 loss: -2.0301618576049805
Batch 20/64 loss: -1.9499492645263672
Batch 21/64 loss: -1.8215904235839844
Batch 22/64 loss: -1.7496271133422852
Batch 23/64 loss: -2.0882997512817383
Batch 24/64 loss: -1.9041342735290527
Batch 25/64 loss: -2.040445327758789
Batch 26/64 loss: -2.059370994567871
Batch 27/64 loss: -2.0236945152282715
Batch 28/64 loss: -1.930100917816162
Batch 29/64 loss: -1.734485149383545
Batch 30/64 loss: -1.9002065658569336
Batch 31/64 loss: -2.0585455894470215
Batch 32/64 loss: -2.2890567779541016
Batch 33/64 loss: -2.056859016418457
Batch 34/64 loss: -1.9781494140625
Batch 35/64 loss: -2.1831154823303223
Batch 36/64 loss: -2.0620694160461426
Batch 37/64 loss: -1.8106098175048828
Batch 38/64 loss: -1.7831916809082031
Batch 39/64 loss: -2.146068572998047
Batch 40/64 loss: -2.1428394317626953
Batch 41/64 loss: -2.150247097015381
Batch 42/64 loss: -1.800429344177246
Batch 43/64 loss: -1.7417173385620117
Batch 44/64 loss: -1.9561772346496582
Batch 45/64 loss: -2.2671356201171875
Batch 46/64 loss: -1.9558091163635254
Batch 47/64 loss: -1.929166316986084
Batch 48/64 loss: -1.8665962219238281
Batch 49/64 loss: -1.5779170989990234
Batch 50/64 loss: -1.839460849761963
Batch 51/64 loss: -2.028230667114258
Batch 52/64 loss: -1.8551511764526367
Batch 53/64 loss: -2.158053398132324
Batch 54/64 loss: -2.0665035247802734
Batch 55/64 loss: -2.224853992462158
Batch 56/64 loss: -2.1798667907714844
Batch 57/64 loss: -2.086697578430176
Batch 58/64 loss: -1.9262990951538086
Batch 59/64 loss: -2.136286735534668
Batch 60/64 loss: -1.9219846725463867
Batch 61/64 loss: -1.7757377624511719
Batch 62/64 loss: -2.0731239318847656
Batch 63/64 loss: -2.172748565673828
Batch 64/64 loss: -6.246394634246826
Epoch 469  Train loss: -2.02423178915884  Val loss: -2.0892790568243598
Epoch 470
-------------------------------
Batch 1/64 loss: -1.7722463607788086
Batch 2/64 loss: -2.057584762573242
Batch 3/64 loss: -1.727644920349121
Batch 4/64 loss: -1.820913314819336
Batch 5/64 loss: -1.917165756225586
Batch 6/64 loss: -2.056382179260254
Batch 7/64 loss: -1.9246673583984375
Batch 8/64 loss: -1.9778194427490234
Batch 9/64 loss: -1.9843673706054688
Batch 10/64 loss: -1.885493278503418
Batch 11/64 loss: -1.815485954284668
Batch 12/64 loss: -1.6644515991210938
Batch 13/64 loss: -1.8821277618408203
Batch 14/64 loss: -1.8225488662719727
Batch 15/64 loss: -2.0090885162353516
Batch 16/64 loss: -1.9170446395874023
Batch 17/64 loss: -1.9847049713134766
Batch 18/64 loss: -2.0161733627319336
Batch 19/64 loss: -1.6976652145385742
Batch 20/64 loss: -1.6339397430419922
Batch 21/64 loss: -1.8248214721679688
Batch 22/64 loss: -1.8641557693481445
Batch 23/64 loss: -1.957113265991211
Batch 24/64 loss: -1.6347293853759766
Batch 25/64 loss: -1.9730262756347656
Batch 26/64 loss: -1.9659786224365234
Batch 27/64 loss: -2.0559139251708984
Batch 28/64 loss: -1.8830041885375977
Batch 29/64 loss: -2.045069694519043
Batch 30/64 loss: -2.14102840423584
Batch 31/64 loss: -1.9301509857177734
Batch 32/64 loss: -2.115983009338379
Batch 33/64 loss: -2.079833984375
Batch 34/64 loss: -1.947188377380371
Batch 35/64 loss: -2.0468063354492188
Batch 36/64 loss: -2.1843323707580566
Batch 37/64 loss: -1.7548208236694336
Batch 38/64 loss: -1.715977668762207
Batch 39/64 loss: -1.7087831497192383
Batch 40/64 loss: -1.898834228515625
Batch 41/64 loss: -2.1077070236206055
Batch 42/64 loss: -1.7148237228393555
Batch 43/64 loss: -1.89801025390625
Batch 44/64 loss: -1.9998021125793457
Batch 45/64 loss: -2.204988479614258
Batch 46/64 loss: -1.6524991989135742
Batch 47/64 loss: -1.9105348587036133
Batch 48/64 loss: -2.0015039443969727
Batch 49/64 loss: -2.053680419921875
Batch 50/64 loss: -2.022733688354492
Batch 51/64 loss: -1.862680435180664
Batch 52/64 loss: -1.7002267837524414
Batch 53/64 loss: -2.011066436767578
Batch 54/64 loss: -1.9597291946411133
Batch 55/64 loss: -2.08781099319458
Batch 56/64 loss: -1.907092571258545
Batch 57/64 loss: -2.161865711212158
Batch 58/64 loss: -2.0805697441101074
Batch 59/64 loss: -1.673126220703125
Batch 60/64 loss: -1.4212760925292969
Batch 61/64 loss: -1.9599924087524414
Batch 62/64 loss: -2.1460933685302734
Batch 63/64 loss: -1.8854198455810547
Batch 64/64 loss: -5.901120662689209
Epoch 470  Train loss: -1.9630453539829629  Val loss: -2.0223606673302927
Epoch 471
-------------------------------
Batch 1/64 loss: -1.9906573295593262
Batch 2/64 loss: -2.0807743072509766
Batch 3/64 loss: -1.7191343307495117
Batch 4/64 loss: -1.7754511833190918
Batch 5/64 loss: -1.7577495574951172
Batch 6/64 loss: -1.8873662948608398
Batch 7/64 loss: -1.9306073188781738
Batch 8/64 loss: -1.8661203384399414
Batch 9/64 loss: -2.1576013565063477
Batch 10/64 loss: -1.7681207656860352
Batch 11/64 loss: -1.6511249542236328
Batch 12/64 loss: -1.8237218856811523
Batch 13/64 loss: -2.012814521789551
Batch 14/64 loss: -1.650670051574707
Batch 15/64 loss: -1.9751310348510742
Batch 16/64 loss: -2.0354723930358887
Batch 17/64 loss: -1.9437437057495117
Batch 18/64 loss: -1.7098932266235352
Batch 19/64 loss: -2.041372776031494
Batch 20/64 loss: -1.5077171325683594
Batch 21/64 loss: -2.0772390365600586
Batch 22/64 loss: -2.110877513885498
Batch 23/64 loss: -2.1841864585876465
Batch 24/64 loss: -1.9835357666015625
Batch 25/64 loss: -2.1469197273254395
Batch 26/64 loss: -2.0573320388793945
Batch 27/64 loss: -2.075005531311035
Batch 28/64 loss: -1.994868278503418
Batch 29/64 loss: -1.994494915008545
Batch 30/64 loss: -2.110595703125
Batch 31/64 loss: -2.030862331390381
Batch 32/64 loss: -2.006098747253418
Batch 33/64 loss: -1.9545435905456543
Batch 34/64 loss: -2.229954242706299
Batch 35/64 loss: -2.041964054107666
Batch 36/64 loss: -1.9523563385009766
Batch 37/64 loss: -2.1737399101257324
Batch 38/64 loss: -1.8375043869018555
Batch 39/64 loss: -2.003964424133301
Batch 40/64 loss: -2.015866756439209
Batch 41/64 loss: -2.0335421562194824
Batch 42/64 loss: -2.0637402534484863
Batch 43/64 loss: -1.8804912567138672
Batch 44/64 loss: -2.1719164848327637
Batch 45/64 loss: -1.887864589691162
Batch 46/64 loss: -2.0174450874328613
Batch 47/64 loss: -2.037398338317871
Batch 48/64 loss: -1.8759727478027344
Batch 49/64 loss: -1.9134902954101562
Batch 50/64 loss: -2.0024328231811523
Batch 51/64 loss: -2.001506805419922
Batch 52/64 loss: -2.236354351043701
Batch 53/64 loss: -1.8885412216186523
Batch 54/64 loss: -1.4767131805419922
Batch 55/64 loss: -1.5867090225219727
Batch 56/64 loss: -1.9533863067626953
Batch 57/64 loss: -1.9515585899353027
Batch 58/64 loss: -1.7984390258789062
Batch 59/64 loss: -2.2086315155029297
Batch 60/64 loss: -2.2477211952209473
Batch 61/64 loss: -2.1848573684692383
Batch 62/64 loss: -2.1689858436584473
Batch 63/64 loss: -1.9795784950256348
Batch 64/64 loss: -5.967818737030029
Epoch 471  Train loss: -2.0127105133206236  Val loss: -2.131009183798459
Epoch 472
-------------------------------
Batch 1/64 loss: -1.7970972061157227
Batch 2/64 loss: -2.084929943084717
Batch 3/64 loss: -2.019317150115967
Batch 4/64 loss: -1.7069892883300781
Batch 5/64 loss: -2.076012134552002
Batch 6/64 loss: -2.1156082153320312
Batch 7/64 loss: -1.7495732307434082
Batch 8/64 loss: -1.9922256469726562
Batch 9/64 loss: -2.106170177459717
Batch 10/64 loss: -2.0983262062072754
Batch 11/64 loss: -2.05257511138916
Batch 12/64 loss: -2.0828003883361816
Batch 13/64 loss: -1.9535927772521973
Batch 14/64 loss: -1.5333385467529297
Batch 15/64 loss: -2.105161666870117
Batch 16/64 loss: -2.1636414527893066
Batch 17/64 loss: -2.011871337890625
Batch 18/64 loss: -2.1355133056640625
Batch 19/64 loss: -1.8828344345092773
Batch 20/64 loss: -2.0813207626342773
Batch 21/64 loss: -2.0718746185302734
Batch 22/64 loss: -1.776667594909668
Batch 23/64 loss: -2.2083282470703125
Batch 24/64 loss: -2.037081718444824
Batch 25/64 loss: -2.024280548095703
Batch 26/64 loss: -2.0603132247924805
Batch 27/64 loss: -1.9954466819763184
Batch 28/64 loss: -2.0647850036621094
Batch 29/64 loss: -1.86834716796875
Batch 30/64 loss: -1.8794889450073242
Batch 31/64 loss: -1.8068904876708984
Batch 32/64 loss: -1.5507001876831055
Batch 33/64 loss: -2.102090835571289
Batch 34/64 loss: -2.022676467895508
Batch 35/64 loss: -2.009622573852539
Batch 36/64 loss: -1.867640495300293
Batch 37/64 loss: -1.9847674369812012
Batch 38/64 loss: -2.1031737327575684
Batch 39/64 loss: -2.1101903915405273
Batch 40/64 loss: -2.1698617935180664
Batch 41/64 loss: -1.811042308807373
Batch 42/64 loss: -1.9899396896362305
Batch 43/64 loss: -1.5585451126098633
Batch 44/64 loss: -1.7495384216308594
Batch 45/64 loss: -2.1465892791748047
Batch 46/64 loss: -1.1983356475830078
Batch 47/64 loss: -1.9533076286315918
Batch 48/64 loss: -1.691793441772461
Batch 49/64 loss: -1.7687768936157227
Batch 50/64 loss: -1.853806495666504
Batch 51/64 loss: -1.967951774597168
Batch 52/64 loss: -1.9293980598449707
Batch 53/64 loss: -1.2980613708496094
Batch 54/64 loss: -2.132335662841797
Batch 55/64 loss: -1.7796592712402344
Batch 56/64 loss: -2.088566780090332
Batch 57/64 loss: -1.8090710639953613
Batch 58/64 loss: -1.733072280883789
Batch 59/64 loss: -2.06119966506958
Batch 60/64 loss: -2.0872511863708496
Batch 61/64 loss: -1.8935966491699219
Batch 62/64 loss: -1.0919828414916992
Batch 63/64 loss: -2.103837013244629
Batch 64/64 loss: -6.093550682067871
Epoch 472  Train loss: -1.9722501754760742  Val loss: -2.1107601021573306
Epoch 473
-------------------------------
Batch 1/64 loss: -2.044192314147949
Batch 2/64 loss: -2.0613527297973633
Batch 3/64 loss: -1.6818227767944336
Batch 4/64 loss: -1.6105241775512695
Batch 5/64 loss: -2.0493288040161133
Batch 6/64 loss: -2.0550661087036133
Batch 7/64 loss: -1.8417339324951172
Batch 8/64 loss: -1.8456430435180664
Batch 9/64 loss: -1.9973173141479492
Batch 10/64 loss: -1.5348939895629883
Batch 11/64 loss: -1.7269649505615234
Batch 12/64 loss: -1.3528575897216797
Batch 13/64 loss: -1.7595243453979492
Batch 14/64 loss: -1.3654346466064453
Batch 15/64 loss: -1.808140754699707
Batch 16/64 loss: -1.9866609573364258
Batch 17/64 loss: -1.2933235168457031
Batch 18/64 loss: -1.8065166473388672
Batch 19/64 loss: -1.3246841430664062
Batch 20/64 loss: -1.1301240921020508
Batch 21/64 loss: -1.4486799240112305
Batch 22/64 loss: -1.5988712310791016
Batch 23/64 loss: -1.8983440399169922
Batch 24/64 loss: -1.7997407913208008
Batch 25/64 loss: -1.7957439422607422
Batch 26/64 loss: -1.7366161346435547
Batch 27/64 loss: -1.4632911682128906
Batch 28/64 loss: -1.8846511840820312
Batch 29/64 loss: -2.0142812728881836
Batch 30/64 loss: -2.03887939453125
Batch 31/64 loss: -1.9295306205749512
Batch 32/64 loss: -1.9620018005371094
Batch 33/64 loss: -2.093763828277588
Batch 34/64 loss: -1.9290332794189453
Batch 35/64 loss: -1.8841896057128906
Batch 36/64 loss: -1.7692136764526367
Batch 37/64 loss: -1.2839851379394531
Batch 38/64 loss: -1.8131790161132812
Batch 39/64 loss: -1.7333498001098633
Batch 40/64 loss: -2.05416202545166
Batch 41/64 loss: -2.0062007904052734
Batch 42/64 loss: -1.975142478942871
Batch 43/64 loss: -1.3208036422729492
Batch 44/64 loss: -2.0335469245910645
Batch 45/64 loss: -1.7369937896728516
Batch 46/64 loss: -2.084742546081543
Batch 47/64 loss: -1.7343149185180664
Batch 48/64 loss: -1.7773666381835938
Batch 49/64 loss: -1.9658994674682617
Batch 50/64 loss: -2.021853446960449
Batch 51/64 loss: -1.4424982070922852
Batch 52/64 loss: -2.125981330871582
Batch 53/64 loss: -2.110698699951172
Batch 54/64 loss: -1.826751708984375
Batch 55/64 loss: -2.1171374320983887
Batch 56/64 loss: -1.7573347091674805
Batch 57/64 loss: -1.6258172988891602
Batch 58/64 loss: -1.9683055877685547
Batch 59/64 loss: -1.6663198471069336
Batch 60/64 loss: -2.0223894119262695
Batch 61/64 loss: -1.7748804092407227
Batch 62/64 loss: -1.9203577041625977
Batch 63/64 loss: -2.0211963653564453
Batch 64/64 loss: -5.931058406829834
Epoch 473  Train loss: -1.8492932057848164  Val loss: -2.1531311375988307
Epoch 474
-------------------------------
Batch 1/64 loss: -2.23049259185791
Batch 2/64 loss: -2.090644359588623
Batch 3/64 loss: -2.109495162963867
Batch 4/64 loss: -2.044339179992676
Batch 5/64 loss: -2.285684585571289
Batch 6/64 loss: -2.0538368225097656
Batch 7/64 loss: -2.0118370056152344
Batch 8/64 loss: -1.790511131286621
Batch 9/64 loss: -1.6956195831298828
Batch 10/64 loss: -2.153079032897949
Batch 11/64 loss: -1.8705039024353027
Batch 12/64 loss: -1.9087324142456055
Batch 13/64 loss: -1.6226768493652344
Batch 14/64 loss: -2.222443103790283
Batch 15/64 loss: -1.8711814880371094
Batch 16/64 loss: -2.1676015853881836
Batch 17/64 loss: -1.7166385650634766
Batch 18/64 loss: -1.8174018859863281
Batch 19/64 loss: -2.056985378265381
Batch 20/64 loss: -1.678511619567871
Batch 21/64 loss: -2.209493637084961
Batch 22/64 loss: -1.661118507385254
Batch 23/64 loss: -1.7174062728881836
Batch 24/64 loss: -1.638596534729004
Batch 25/64 loss: -1.761636734008789
Batch 26/64 loss: -1.7759485244750977
Batch 27/64 loss: -1.7435235977172852
Batch 28/64 loss: -2.0265793800354004
Batch 29/64 loss: -2.0421857833862305
Batch 30/64 loss: -1.956009864807129
Batch 31/64 loss: -1.9386181831359863
Batch 32/64 loss: -2.2897720336914062
Batch 33/64 loss: -2.0107288360595703
Batch 34/64 loss: -2.1132640838623047
Batch 35/64 loss: -1.9078059196472168
Batch 36/64 loss: -1.7313470840454102
Batch 37/64 loss: -2.1528005599975586
Batch 38/64 loss: -2.0620856285095215
Batch 39/64 loss: -1.9580192565917969
Batch 40/64 loss: -2.0116119384765625
Batch 41/64 loss: -2.0651817321777344
Batch 42/64 loss: -2.2146668434143066
Batch 43/64 loss: -2.083449363708496
Batch 44/64 loss: -1.7694063186645508
Batch 45/64 loss: -1.9830389022827148
Batch 46/64 loss: -1.8710908889770508
Batch 47/64 loss: -1.6317405700683594
Batch 48/64 loss: -2.0204596519470215
Batch 49/64 loss: -2.1224184036254883
Batch 50/64 loss: -1.4750242233276367
Batch 51/64 loss: -1.8888015747070312
Batch 52/64 loss: -1.4221067428588867
Batch 53/64 loss: -1.713444709777832
Batch 54/64 loss: -2.0306811332702637
Batch 55/64 loss: -1.9279661178588867
Batch 56/64 loss: -1.5975160598754883
Batch 57/64 loss: -2.1135306358337402
Batch 58/64 loss: -2.2265963554382324
Batch 59/64 loss: -1.457937240600586
Batch 60/64 loss: -1.7545795440673828
Batch 61/64 loss: -2.0236735343933105
Batch 62/64 loss: -1.8999919891357422
Batch 63/64 loss: -1.8103938102722168
Batch 64/64 loss: -5.685845851898193
Epoch 474  Train loss: -1.968232930875292  Val loss: -2.147679738572373
Epoch 475
-------------------------------
Batch 1/64 loss: -2.091825485229492
Batch 2/64 loss: -2.0057287216186523
Batch 3/64 loss: -2.148336410522461
Batch 4/64 loss: -1.8840274810791016
Batch 5/64 loss: -2.0768613815307617
Batch 6/64 loss: -2.1265993118286133
Batch 7/64 loss: -1.8729372024536133
Batch 8/64 loss: -1.961277961730957
Batch 9/64 loss: -2.072122573852539
Batch 10/64 loss: -2.1307315826416016
Batch 11/64 loss: -2.056941032409668
Batch 12/64 loss: -1.7302112579345703
Batch 13/64 loss: -2.0318222045898438
Batch 14/64 loss: -2.132176399230957
Batch 15/64 loss: -1.7288198471069336
Batch 16/64 loss: -1.9898548126220703
Batch 17/64 loss: -1.9933009147644043
Batch 18/64 loss: -1.8129596710205078
Batch 19/64 loss: -2.1411948204040527
Batch 20/64 loss: -1.5789518356323242
Batch 21/64 loss: -2.064600944519043
Batch 22/64 loss: -2.0183424949645996
Batch 23/64 loss: -2.0690484046936035
Batch 24/64 loss: -1.8837509155273438
Batch 25/64 loss: -1.414276123046875
Batch 26/64 loss: -2.051508903503418
Batch 27/64 loss: -1.8518314361572266
Batch 28/64 loss: -1.9129438400268555
Batch 29/64 loss: -1.404367446899414
Batch 30/64 loss: -1.9165277481079102
Batch 31/64 loss: -2.0487890243530273
Batch 32/64 loss: -1.969414234161377
Batch 33/64 loss: -2.0817203521728516
Batch 34/64 loss: -2.040891647338867
Batch 35/64 loss: -2.174039840698242
Batch 36/64 loss: -1.904414176940918
Batch 37/64 loss: -1.4355716705322266
Batch 38/64 loss: -2.123734474182129
Batch 39/64 loss: -2.14912748336792
Batch 40/64 loss: -1.9374232292175293
Batch 41/64 loss: -2.052417278289795
Batch 42/64 loss: -1.7824335098266602
Batch 43/64 loss: -1.9205389022827148
Batch 44/64 loss: -1.8647937774658203
Batch 45/64 loss: -1.8857016563415527
Batch 46/64 loss: -1.9324455261230469
Batch 47/64 loss: -1.8292484283447266
Batch 48/64 loss: -1.9810943603515625
Batch 49/64 loss: -1.2200126647949219
Batch 50/64 loss: -2.1072921752929688
Batch 51/64 loss: -2.2541298866271973
Batch 52/64 loss: -1.731226921081543
Batch 53/64 loss: -2.0429368019104004
Batch 54/64 loss: -2.009922504425049
Batch 55/64 loss: -2.0070619583129883
Batch 56/64 loss: -1.5259895324707031
Batch 57/64 loss: -1.8042888641357422
Batch 58/64 loss: -1.7568044662475586
Batch 59/64 loss: -2.020381450653076
Batch 60/64 loss: -1.8094840049743652
Batch 61/64 loss: -1.9945244789123535
Batch 62/64 loss: -1.8921213150024414
Batch 63/64 loss: -1.8953161239624023
Batch 64/64 loss: -6.266656875610352
Epoch 475  Train loss: -1.9770849340102252  Val loss: -2.163652295509155
Epoch 476
-------------------------------
Batch 1/64 loss: -1.996389389038086
Batch 2/64 loss: -1.6706113815307617
Batch 3/64 loss: -2.1043758392333984
Batch 4/64 loss: -1.8677496910095215
Batch 5/64 loss: -1.8500685691833496
Batch 6/64 loss: -1.918879508972168
Batch 7/64 loss: -1.5722579956054688
Batch 8/64 loss: -1.9932098388671875
Batch 9/64 loss: -2.171722888946533
Batch 10/64 loss: -2.303894519805908
Batch 11/64 loss: -2.014840602874756
Batch 12/64 loss: -1.883772850036621
Batch 13/64 loss: -2.2088093757629395
Batch 14/64 loss: -2.1870412826538086
Batch 15/64 loss: -2.01157808303833
Batch 16/64 loss: -2.032968044281006
Batch 17/64 loss: -2.000908851623535
Batch 18/64 loss: -1.4070463180541992
Batch 19/64 loss: -2.0120229721069336
Batch 20/64 loss: -1.820094108581543
Batch 21/64 loss: -2.2237281799316406
Batch 22/64 loss: -1.8224992752075195
Batch 23/64 loss: -2.1928253173828125
Batch 24/64 loss: -2.2530136108398438
Batch 25/64 loss: -1.9859189987182617
Batch 26/64 loss: -1.9526162147521973
Batch 27/64 loss: -2.029322624206543
Batch 28/64 loss: -2.1592745780944824
Batch 29/64 loss: -2.055325984954834
Batch 30/64 loss: -1.783017635345459
Batch 31/64 loss: -2.0800938606262207
Batch 32/64 loss: -1.7015209197998047
Batch 33/64 loss: -2.2923154830932617
Batch 34/64 loss: -2.1572585105895996
Batch 35/64 loss: -1.8968591690063477
Batch 36/64 loss: -2.0921545028686523
Batch 37/64 loss: -1.6186418533325195
Batch 38/64 loss: -1.9880270957946777
Batch 39/64 loss: -1.9580621719360352
Batch 40/64 loss: -1.8081583976745605
Batch 41/64 loss: -2.0709009170532227
Batch 42/64 loss: -2.050490379333496
Batch 43/64 loss: -1.6609411239624023
Batch 44/64 loss: -1.8401355743408203
Batch 45/64 loss: -1.6030468940734863
Batch 46/64 loss: -1.8009147644042969
Batch 47/64 loss: -2.148684501647949
Batch 48/64 loss: -1.8938713073730469
Batch 49/64 loss: -2.0242300033569336
Batch 50/64 loss: -2.1035194396972656
Batch 51/64 loss: -1.717787742614746
Batch 52/64 loss: -2.1515679359436035
Batch 53/64 loss: -2.0037841796875
Batch 54/64 loss: -2.0910825729370117
Batch 55/64 loss: -2.0028862953186035
Batch 56/64 loss: -1.8092899322509766
Batch 57/64 loss: -1.9851765632629395
Batch 58/64 loss: -1.9249558448791504
Batch 59/64 loss: -1.8733339309692383
Batch 60/64 loss: -1.9084844589233398
Batch 61/64 loss: -2.00919246673584
Batch 62/64 loss: -2.0986061096191406
Batch 63/64 loss: -2.0227317810058594
Batch 64/64 loss: -5.361431121826172
Epoch 476  Train loss: -2.0062049342136756  Val loss: -2.0520401132065818
Epoch 477
-------------------------------
Batch 1/64 loss: -2.1096091270446777
Batch 2/64 loss: -2.089381217956543
Batch 3/64 loss: -1.9172329902648926
Batch 4/64 loss: -1.9268074035644531
Batch 5/64 loss: -2.2262167930603027
Batch 6/64 loss: -1.7433586120605469
Batch 7/64 loss: -2.102980613708496
Batch 8/64 loss: -2.13790225982666
Batch 9/64 loss: -1.8942146301269531
Batch 10/64 loss: -1.3493270874023438
Batch 11/64 loss: -1.8536620140075684
Batch 12/64 loss: -2.015991687774658
Batch 13/64 loss: -2.1036601066589355
Batch 14/64 loss: -1.7963027954101562
Batch 15/64 loss: -1.9226446151733398
Batch 16/64 loss: -1.722580909729004
Batch 17/64 loss: -2.099400043487549
Batch 18/64 loss: -2.2057690620422363
Batch 19/64 loss: -1.9363932609558105
Batch 20/64 loss: -1.567988395690918
Batch 21/64 loss: -1.89093017578125
Batch 22/64 loss: -1.8184795379638672
Batch 23/64 loss: -1.953293800354004
Batch 24/64 loss: -1.8442573547363281
Batch 25/64 loss: -1.7152256965637207
Batch 26/64 loss: -1.886265754699707
Batch 27/64 loss: -2.0510025024414062
Batch 28/64 loss: -2.230355739593506
Batch 29/64 loss: -1.7951040267944336
Batch 30/64 loss: -1.7464008331298828
Batch 31/64 loss: -1.8440217971801758
Batch 32/64 loss: -1.773106575012207
Batch 33/64 loss: -2.1988677978515625
Batch 34/64 loss: -1.897735595703125
Batch 35/64 loss: -2.0529260635375977
Batch 36/64 loss: -2.2015767097473145
Batch 37/64 loss: -1.888779640197754
Batch 38/64 loss: -2.073941230773926
Batch 39/64 loss: -2.1233677864074707
Batch 40/64 loss: -2.1322922706604004
Batch 41/64 loss: -2.0094165802001953
Batch 42/64 loss: -1.9139480590820312
Batch 43/64 loss: -2.2477002143859863
Batch 44/64 loss: -1.9444255828857422
Batch 45/64 loss: -2.087447166442871
Batch 46/64 loss: -1.5103416442871094
Batch 47/64 loss: -1.8637237548828125
Batch 48/64 loss: -2.068748950958252
Batch 49/64 loss: -2.225581169128418
Batch 50/64 loss: -1.9831466674804688
Batch 51/64 loss: -2.030318260192871
Batch 52/64 loss: -1.8126320838928223
Batch 53/64 loss: -2.1319398880004883
Batch 54/64 loss: -1.7796635627746582
Batch 55/64 loss: -2.1788859367370605
Batch 56/64 loss: -1.9710512161254883
Batch 57/64 loss: -1.989232063293457
Batch 58/64 loss: -1.9440641403198242
Batch 59/64 loss: -2.275947093963623
Batch 60/64 loss: -2.207937240600586
Batch 61/64 loss: -1.9466590881347656
Batch 62/64 loss: -2.206228733062744
Batch 63/64 loss: -2.1073789596557617
Batch 64/64 loss: -5.9870476722717285
Epoch 477  Train loss: -2.019859738443412  Val loss: -2.1718230755468415
Epoch 478
-------------------------------
Batch 1/64 loss: -2.248777389526367
Batch 2/64 loss: -1.5862197875976562
Batch 3/64 loss: -2.051568031311035
Batch 4/64 loss: -1.8661251068115234
Batch 5/64 loss: -2.103494644165039
Batch 6/64 loss: -2.0111842155456543
Batch 7/64 loss: -2.0145578384399414
Batch 8/64 loss: -2.159280776977539
Batch 9/64 loss: -2.0489187240600586
Batch 10/64 loss: -1.9578962326049805
Batch 11/64 loss: -2.0546741485595703
Batch 12/64 loss: -1.6208643913269043
Batch 13/64 loss: -2.187551975250244
Batch 14/64 loss: -2.1034607887268066
Batch 15/64 loss: -2.0021400451660156
Batch 16/64 loss: -1.4054899215698242
Batch 17/64 loss: -2.060018539428711
Batch 18/64 loss: -2.052539825439453
Batch 19/64 loss: -2.0802512168884277
Batch 20/64 loss: -2.0884408950805664
Batch 21/64 loss: -2.2680225372314453
Batch 22/64 loss: -2.0968122482299805
Batch 23/64 loss: -2.113124370574951
Batch 24/64 loss: -2.0987329483032227
Batch 25/64 loss: -1.5380525588989258
Batch 26/64 loss: -2.128720760345459
Batch 27/64 loss: -2.001516342163086
Batch 28/64 loss: -1.9290952682495117
Batch 29/64 loss: -2.1206765174865723
Batch 30/64 loss: -1.8136930465698242
Batch 31/64 loss: -2.2206878662109375
Batch 32/64 loss: -1.8759794235229492
Batch 33/64 loss: -2.0030317306518555
Batch 34/64 loss: -1.9700870513916016
Batch 35/64 loss: -1.9672269821166992
Batch 36/64 loss: -2.01180362701416
Batch 37/64 loss: -2.026261329650879
Batch 38/64 loss: -2.1296486854553223
Batch 39/64 loss: -1.981511116027832
Batch 40/64 loss: -1.943603515625
Batch 41/64 loss: -2.151822566986084
Batch 42/64 loss: -1.9499702453613281
Batch 43/64 loss: -2.082545757293701
Batch 44/64 loss: -2.024447441101074
Batch 45/64 loss: -1.8454313278198242
Batch 46/64 loss: -1.9373159408569336
Batch 47/64 loss: -2.2276768684387207
Batch 48/64 loss: -1.8559799194335938
Batch 49/64 loss: -2.0404839515686035
Batch 50/64 loss: -1.940317153930664
Batch 51/64 loss: -1.992091178894043
Batch 52/64 loss: -2.1155309677124023
Batch 53/64 loss: -1.9901342391967773
Batch 54/64 loss: -1.8053169250488281
Batch 55/64 loss: -2.023961067199707
Batch 56/64 loss: -2.1400084495544434
Batch 57/64 loss: -2.130854606628418
Batch 58/64 loss: -1.7487754821777344
Batch 59/64 loss: -2.1101455688476562
Batch 60/64 loss: -1.6648683547973633
Batch 61/64 loss: -1.8659114837646484
Batch 62/64 loss: -1.8303308486938477
Batch 63/64 loss: -2.143254280090332
Batch 64/64 loss: -6.2362165451049805
Epoch 478  Train loss: -2.042918893402698  Val loss: -2.1694429535226725
Epoch 479
-------------------------------
Batch 1/64 loss: -2.0168895721435547
Batch 2/64 loss: -2.1040563583374023
Batch 3/64 loss: -1.7707910537719727
Batch 4/64 loss: -2.1855735778808594
Batch 5/64 loss: -2.0699825286865234
Batch 6/64 loss: -2.148500442504883
Batch 7/64 loss: -1.8196849822998047
Batch 8/64 loss: -1.9711084365844727
Batch 9/64 loss: -2.0091400146484375
Batch 10/64 loss: -1.719895362854004
Batch 11/64 loss: -1.9438047409057617
Batch 12/64 loss: -2.1542835235595703
Batch 13/64 loss: -2.201809883117676
Batch 14/64 loss: -2.066762924194336
Batch 15/64 loss: -1.971519947052002
Batch 16/64 loss: -2.0074658393859863
Batch 17/64 loss: -2.0745997428894043
Batch 18/64 loss: -1.8224029541015625
Batch 19/64 loss: -1.703878402709961
Batch 20/64 loss: -1.7633285522460938
Batch 21/64 loss: -1.6847314834594727
Batch 22/64 loss: -1.8778305053710938
Batch 23/64 loss: -2.0296130180358887
Batch 24/64 loss: -1.8764867782592773
Batch 25/64 loss: -1.9792098999023438
Batch 26/64 loss: -2.0300397872924805
Batch 27/64 loss: -1.8158159255981445
Batch 28/64 loss: -2.0784950256347656
Batch 29/64 loss: -1.5821475982666016
Batch 30/64 loss: -1.899418830871582
Batch 31/64 loss: -1.7406425476074219
Batch 32/64 loss: -1.9364404678344727
Batch 33/64 loss: -1.3970413208007812
Batch 34/64 loss: -1.7033252716064453
Batch 35/64 loss: -2.0930590629577637
Batch 36/64 loss: -2.2121949195861816
Batch 37/64 loss: -2.1879005432128906
Batch 38/64 loss: -2.2412023544311523
Batch 39/64 loss: -1.9748821258544922
Batch 40/64 loss: -1.7983245849609375
Batch 41/64 loss: -2.125694751739502
Batch 42/64 loss: -1.965296745300293
Batch 43/64 loss: -2.001089096069336
Batch 44/64 loss: -1.9412994384765625
Batch 45/64 loss: -2.0723390579223633
Batch 46/64 loss: -1.755091667175293
Batch 47/64 loss: -2.3459110260009766
Batch 48/64 loss: -1.9841656684875488
Batch 49/64 loss: -1.9537534713745117
Batch 50/64 loss: -1.947190284729004
Batch 51/64 loss: -1.8812494277954102
Batch 52/64 loss: -1.7527084350585938
Batch 53/64 loss: -2.00711727142334
Batch 54/64 loss: -1.8814725875854492
Batch 55/64 loss: -1.9385623931884766
Batch 56/64 loss: -1.6414909362792969
Batch 57/64 loss: -1.8964519500732422
Batch 58/64 loss: -2.013124942779541
Batch 59/64 loss: -1.9758234024047852
Batch 60/64 loss: -2.0981082916259766
Batch 61/64 loss: -2.2575125694274902
Batch 62/64 loss: -2.125002861022949
Batch 63/64 loss: -2.185884475708008
Batch 64/64 loss: -5.843023300170898
Epoch 479  Train loss: -2.0045943391089347  Val loss: -2.076744512184379
Epoch 480
-------------------------------
Batch 1/64 loss: -1.969508171081543
Batch 2/64 loss: -1.86529541015625
Batch 3/64 loss: -2.1473498344421387
Batch 4/64 loss: -1.831563949584961
Batch 5/64 loss: -2.132587432861328
Batch 6/64 loss: -2.1479272842407227
Batch 7/64 loss: -2.0473175048828125
Batch 8/64 loss: -2.201323986053467
Batch 9/64 loss: -2.1504926681518555
Batch 10/64 loss: -2.169764995574951
Batch 11/64 loss: -2.0226950645446777
Batch 12/64 loss: -2.204631805419922
Batch 13/64 loss: -1.8313264846801758
Batch 14/64 loss: -2.143232822418213
Batch 15/64 loss: -2.138462543487549
Batch 16/64 loss: -2.2490391731262207
Batch 17/64 loss: -1.566300392150879
Batch 18/64 loss: -2.0138978958129883
Batch 19/64 loss: -1.8851394653320312
Batch 20/64 loss: -2.1257777214050293
Batch 21/64 loss: -2.2006120681762695
Batch 22/64 loss: -1.9069809913635254
Batch 23/64 loss: -1.985544204711914
Batch 24/64 loss: -1.9098739624023438
Batch 25/64 loss: -1.9330883026123047
Batch 26/64 loss: -2.105806827545166
Batch 27/64 loss: -1.911850929260254
Batch 28/64 loss: -2.1142630577087402
Batch 29/64 loss: -1.880509853363037
Batch 30/64 loss: -1.985224723815918
Batch 31/64 loss: -2.274158477783203
Batch 32/64 loss: -2.0465288162231445
Batch 33/64 loss: -2.130796432495117
Batch 34/64 loss: -1.8140840530395508
Batch 35/64 loss: -2.076923370361328
Batch 36/64 loss: -2.307868003845215
Batch 37/64 loss: -2.030851364135742
Batch 38/64 loss: -2.282345771789551
Batch 39/64 loss: -2.2363405227661133
Batch 40/64 loss: -1.8533353805541992
Batch 41/64 loss: -2.1464128494262695
Batch 42/64 loss: -2.2492141723632812
Batch 43/64 loss: -1.7381792068481445
Batch 44/64 loss: -1.5012845993041992
Batch 45/64 loss: -1.439645767211914
Batch 46/64 loss: -2.078108310699463
Batch 47/64 loss: -1.8576526641845703
Batch 48/64 loss: -2.2557010650634766
Batch 49/64 loss: -2.1958799362182617
Batch 50/64 loss: -2.0366969108581543
Batch 51/64 loss: -2.117312431335449
Batch 52/64 loss: -2.1888222694396973
Batch 53/64 loss: -2.1550917625427246
Batch 54/64 loss: -1.8543405532836914
Batch 55/64 loss: -2.068142890930176
Batch 56/64 loss: -2.0539212226867676
Batch 57/64 loss: -1.929640769958496
Batch 58/64 loss: -1.6134090423583984
Batch 59/64 loss: -1.8020334243774414
Batch 60/64 loss: -1.959874153137207
Batch 61/64 loss: -1.8044986724853516
Batch 62/64 loss: -1.859034538269043
Batch 63/64 loss: -1.9681382179260254
Batch 64/64 loss: -6.07016658782959
Epoch 480  Train loss: -2.0589220720178942  Val loss: -2.183914971105831
Epoch 481
-------------------------------
Batch 1/64 loss: -2.3021187782287598
Batch 2/64 loss: -2.130838394165039
Batch 3/64 loss: -2.093789577484131
Batch 4/64 loss: -2.0253939628601074
Batch 5/64 loss: -1.7881898880004883
Batch 6/64 loss: -1.6652908325195312
Batch 7/64 loss: -1.9240880012512207
Batch 8/64 loss: -2.131291389465332
Batch 9/64 loss: -1.9230165481567383
Batch 10/64 loss: -2.0244975090026855
Batch 11/64 loss: -2.3838796615600586
Batch 12/64 loss: -2.2051453590393066
Batch 13/64 loss: -2.0726380348205566
Batch 14/64 loss: -2.0187463760375977
Batch 15/64 loss: -2.218489646911621
Batch 16/64 loss: -1.643193244934082
Batch 17/64 loss: -2.091249942779541
Batch 18/64 loss: -1.9232454299926758
Batch 19/64 loss: -2.045051097869873
Batch 20/64 loss: -1.7731332778930664
Batch 21/64 loss: -2.229720115661621
Batch 22/64 loss: -2.0224246978759766
Batch 23/64 loss: -1.8608145713806152
Batch 24/64 loss: -2.0952601432800293
Batch 25/64 loss: -2.1108083724975586
Batch 26/64 loss: -2.0203704833984375
Batch 27/64 loss: -2.062000274658203
Batch 28/64 loss: -1.7525625228881836
Batch 29/64 loss: -2.0478315353393555
Batch 30/64 loss: -2.130557060241699
Batch 31/64 loss: -1.958547592163086
Batch 32/64 loss: -2.0029501914978027
Batch 33/64 loss: -2.1432390213012695
Batch 34/64 loss: -1.9910283088684082
Batch 35/64 loss: -2.201692581176758
Batch 36/64 loss: -1.9744586944580078
Batch 37/64 loss: -1.9161090850830078
Batch 38/64 loss: -2.104979991912842
Batch 39/64 loss: -1.964219570159912
Batch 40/64 loss: -1.972869873046875
Batch 41/64 loss: -1.940556526184082
Batch 42/64 loss: -1.921628475189209
Batch 43/64 loss: -1.8626909255981445
Batch 44/64 loss: -1.7084741592407227
Batch 45/64 loss: -1.7891521453857422
Batch 46/64 loss: -1.8767690658569336
Batch 47/64 loss: -1.9833335876464844
Batch 48/64 loss: -1.929656982421875
Batch 49/64 loss: -2.0884547233581543
Batch 50/64 loss: -1.876572608947754
Batch 51/64 loss: -1.0997695922851562
Batch 52/64 loss: -2.10905122756958
Batch 53/64 loss: -1.8913707733154297
Batch 54/64 loss: -1.9837241172790527
Batch 55/64 loss: -1.8705711364746094
Batch 56/64 loss: -1.9863371849060059
Batch 57/64 loss: -1.5176763534545898
Batch 58/64 loss: -1.876333236694336
Batch 59/64 loss: -1.9723501205444336
Batch 60/64 loss: -2.0307083129882812
Batch 61/64 loss: -2.047163486480713
Batch 62/64 loss: -1.7387914657592773
Batch 63/64 loss: -1.72821044921875
Batch 64/64 loss: -5.558636665344238
Epoch 481  Train loss: -2.006965581108542  Val loss: -2.106859882262974
Epoch 482
-------------------------------
Batch 1/64 loss: -1.8336901664733887
Batch 2/64 loss: -2.1212682723999023
Batch 3/64 loss: -2.1897783279418945
Batch 4/64 loss: -1.793405532836914
Batch 5/64 loss: -1.9366588592529297
Batch 6/64 loss: -2.1080322265625
Batch 7/64 loss: -1.423471450805664
Batch 8/64 loss: -2.0147995948791504
Batch 9/64 loss: -1.6423168182373047
Batch 10/64 loss: -2.2281808853149414
Batch 11/64 loss: -2.2163310050964355
Batch 12/64 loss: -1.9041252136230469
Batch 13/64 loss: -2.1467628479003906
Batch 14/64 loss: -1.3666400909423828
Batch 15/64 loss: -2.090602397918701
Batch 16/64 loss: -2.206869602203369
Batch 17/64 loss: -1.7558202743530273
Batch 18/64 loss: -1.6730337142944336
Batch 19/64 loss: -2.095315933227539
Batch 20/64 loss: -2.0931568145751953
Batch 21/64 loss: -1.8380532264709473
Batch 22/64 loss: -1.4967374801635742
Batch 23/64 loss: -1.8821907043457031
Batch 24/64 loss: -1.9627799987792969
Batch 25/64 loss: -1.5224246978759766
Batch 26/64 loss: -1.8825559616088867
Batch 27/64 loss: -1.8500137329101562
Batch 28/64 loss: -1.53961181640625
Batch 29/64 loss: -2.003931999206543
Batch 30/64 loss: -2.0771803855895996
Batch 31/64 loss: -2.1102757453918457
Batch 32/64 loss: -1.8938055038452148
Batch 33/64 loss: -1.8051872253417969
Batch 34/64 loss: -2.044434070587158
Batch 35/64 loss: -1.9184761047363281
Batch 36/64 loss: -2.173184394836426
Batch 37/64 loss: -2.0189170837402344
Batch 38/64 loss: -1.9515104293823242
Batch 39/64 loss: -2.0060548782348633
Batch 40/64 loss: -1.9850692749023438
Batch 41/64 loss: -1.8388724327087402
Batch 42/64 loss: -1.9868316650390625
Batch 43/64 loss: -1.8432598114013672
Batch 44/64 loss: -1.6116933822631836
Batch 45/64 loss: -1.8773298263549805
Batch 46/64 loss: -1.961350440979004
Batch 47/64 loss: -2.0693559646606445
Batch 48/64 loss: -1.8840484619140625
Batch 49/64 loss: -2.051140785217285
Batch 50/64 loss: -1.7656373977661133
Batch 51/64 loss: -1.9217596054077148
Batch 52/64 loss: -1.7191715240478516
Batch 53/64 loss: -2.1200952529907227
Batch 54/64 loss: -1.7119245529174805
Batch 55/64 loss: -2.1536874771118164
Batch 56/64 loss: -1.994603157043457
Batch 57/64 loss: -1.9785737991333008
Batch 58/64 loss: -1.8832406997680664
Batch 59/64 loss: -2.01580810546875
Batch 60/64 loss: -2.166914463043213
Batch 61/64 loss: -1.951563835144043
Batch 62/64 loss: -2.272918701171875
Batch 63/64 loss: -1.9292488098144531
Batch 64/64 loss: -6.253780841827393
Epoch 482  Train loss: -1.9796395376616833  Val loss: -2.1241052765207193
Epoch 483
-------------------------------
Batch 1/64 loss: -2.099120616912842
Batch 2/64 loss: -1.7431535720825195
Batch 3/64 loss: -2.1191186904907227
Batch 4/64 loss: -1.78857421875
Batch 5/64 loss: -1.933237075805664
Batch 6/64 loss: -1.9081506729125977
Batch 7/64 loss: -2.111207962036133
Batch 8/64 loss: -1.7285966873168945
Batch 9/64 loss: -1.8901386260986328
Batch 10/64 loss: -2.018061637878418
Batch 11/64 loss: -1.9354848861694336
Batch 12/64 loss: -1.9336137771606445
Batch 13/64 loss: -1.6820411682128906
Batch 14/64 loss: -1.509718894958496
Batch 15/64 loss: -2.0613489151000977
Batch 16/64 loss: -1.9386863708496094
Batch 17/64 loss: -2.1542510986328125
Batch 18/64 loss: -1.9729642868041992
Batch 19/64 loss: -1.9465398788452148
Batch 20/64 loss: -1.891779899597168
Batch 21/64 loss: -1.9152603149414062
Batch 22/64 loss: -1.8359346389770508
Batch 23/64 loss: -1.9104766845703125
Batch 24/64 loss: -1.9090604782104492
Batch 25/64 loss: -1.845113754272461
Batch 26/64 loss: -1.6238908767700195
Batch 27/64 loss: -1.5908422470092773
Batch 28/64 loss: -1.812077522277832
Batch 29/64 loss: -1.8118314743041992
Batch 30/64 loss: -2.0730791091918945
Batch 31/64 loss: -1.7555675506591797
Batch 32/64 loss: -1.670745849609375
Batch 33/64 loss: -1.2073631286621094
Batch 34/64 loss: -1.8026762008666992
Batch 35/64 loss: -1.6718635559082031
Batch 36/64 loss: -2.069329261779785
Batch 37/64 loss: -1.97636079788208
Batch 38/64 loss: -2.223698616027832
Batch 39/64 loss: -1.9690418243408203
Batch 40/64 loss: -2.171082019805908
Batch 41/64 loss: -1.986551284790039
Batch 42/64 loss: -1.4979362487792969
Batch 43/64 loss: -1.8842334747314453
Batch 44/64 loss: -1.9174747467041016
Batch 45/64 loss: -1.8836593627929688
Batch 46/64 loss: -1.5898504257202148
Batch 47/64 loss: -1.9120240211486816
Batch 48/64 loss: -2.1449623107910156
Batch 49/64 loss: -1.7879819869995117
Batch 50/64 loss: -1.789438247680664
Batch 51/64 loss: -1.7852354049682617
Batch 52/64 loss: -2.0175533294677734
Batch 53/64 loss: -2.1433916091918945
Batch 54/64 loss: -1.8083019256591797
Batch 55/64 loss: -1.9812307357788086
Batch 56/64 loss: -2.0595650672912598
Batch 57/64 loss: -1.7552499771118164
Batch 58/64 loss: -1.8982858657836914
Batch 59/64 loss: -2.088315010070801
Batch 60/64 loss: -1.8465776443481445
Batch 61/64 loss: -1.8653841018676758
Batch 62/64 loss: -1.5051250457763672
Batch 63/64 loss: -2.039339065551758
Batch 64/64 loss: -6.089979648590088
Epoch 483  Train loss: -1.9288821407392913  Val loss: -2.2517039112209045
Saving best model, epoch: 483
Epoch 484
-------------------------------
Batch 1/64 loss: -2.0703558921813965
Batch 2/64 loss: -2.0291318893432617
Batch 3/64 loss: -2.2951159477233887
Batch 4/64 loss: -2.112448215484619
Batch 5/64 loss: -1.9589414596557617
Batch 6/64 loss: -1.9965972900390625
Batch 7/64 loss: -1.9438676834106445
Batch 8/64 loss: -1.5671892166137695
Batch 9/64 loss: -2.0841479301452637
Batch 10/64 loss: -2.0982723236083984
Batch 11/64 loss: -1.4172534942626953
Batch 12/64 loss: -1.7867040634155273
Batch 13/64 loss: -2.069952964782715
Batch 14/64 loss: -1.8555612564086914
Batch 15/64 loss: -1.473710060119629
Batch 16/64 loss: -2.0250988006591797
Batch 17/64 loss: -1.8340635299682617
Batch 18/64 loss: -2.107306480407715
Batch 19/64 loss: -1.9433445930480957
Batch 20/64 loss: -2.0762405395507812
Batch 21/64 loss: -2.001339912414551
Batch 22/64 loss: -2.113022804260254
Batch 23/64 loss: -1.9843859672546387
Batch 24/64 loss: -1.9059333801269531
Batch 25/64 loss: -1.7675457000732422
Batch 26/64 loss: -1.9099431037902832
Batch 27/64 loss: -1.9820685386657715
Batch 28/64 loss: -2.299260139465332
Batch 29/64 loss: -1.843240737915039
Batch 30/64 loss: -2.2231526374816895
Batch 31/64 loss: -1.9212021827697754
Batch 32/64 loss: -1.9237604141235352
Batch 33/64 loss: -1.9742774963378906
Batch 34/64 loss: -1.989152431488037
Batch 35/64 loss: -2.062758445739746
Batch 36/64 loss: -1.669560432434082
Batch 37/64 loss: -1.9922065734863281
Batch 38/64 loss: -2.110142707824707
Batch 39/64 loss: -1.6851825714111328
Batch 40/64 loss: -1.9905762672424316
Batch 41/64 loss: -2.072887420654297
Batch 42/64 loss: -2.1552953720092773
Batch 43/64 loss: -1.9276089668273926
Batch 44/64 loss: -1.8568415641784668
Batch 45/64 loss: -1.5847511291503906
Batch 46/64 loss: -1.5388436317443848
Batch 47/64 loss: -1.5732855796813965
Batch 48/64 loss: -2.2713499069213867
Batch 49/64 loss: -1.5020856857299805
Batch 50/64 loss: -2.0603089332580566
Batch 51/64 loss: -2.24629545211792
Batch 52/64 loss: -1.9654746055603027
Batch 53/64 loss: -1.9906654357910156
Batch 54/64 loss: -2.1596736907958984
Batch 55/64 loss: -1.4792823791503906
Batch 56/64 loss: -2.127164840698242
Batch 57/64 loss: -2.286233901977539
Batch 58/64 loss: -2.264185905456543
Batch 59/64 loss: -1.9234223365783691
Batch 60/64 loss: -1.9755868911743164
Batch 61/64 loss: -1.8709726333618164
Batch 62/64 loss: -2.1826887130737305
Batch 63/64 loss: -1.7825508117675781
Batch 64/64 loss: -5.756633758544922
Epoch 484  Train loss: -1.9954344655953202  Val loss: -2.1070556378446494
Epoch 485
-------------------------------
Batch 1/64 loss: -2.0151443481445312
Batch 2/64 loss: -2.021519660949707
Batch 3/64 loss: -2.11769962310791
Batch 4/64 loss: -1.7290840148925781
Batch 5/64 loss: -2.0542755126953125
Batch 6/64 loss: -1.9470224380493164
Batch 7/64 loss: -2.101527690887451
Batch 8/64 loss: -1.9952392578125
Batch 9/64 loss: -1.695383071899414
Batch 10/64 loss: -2.0826563835144043
Batch 11/64 loss: -1.7762012481689453
Batch 12/64 loss: -2.2219958305358887
Batch 13/64 loss: -2.111264228820801
Batch 14/64 loss: -2.115553379058838
Batch 15/64 loss: -1.8457202911376953
Batch 16/64 loss: -2.034632682800293
Batch 17/64 loss: -1.9452109336853027
Batch 18/64 loss: -2.002315044403076
Batch 19/64 loss: -2.07609224319458
Batch 20/64 loss: -1.7372684478759766
Batch 21/64 loss: -1.9675893783569336
Batch 22/64 loss: -2.1779842376708984
Batch 23/64 loss: -1.9698810577392578
Batch 24/64 loss: -1.791396141052246
Batch 25/64 loss: -1.6582155227661133
Batch 26/64 loss: -1.6595067977905273
Batch 27/64 loss: -1.9311270713806152
Batch 28/64 loss: -2.009899616241455
Batch 29/64 loss: -2.196871757507324
Batch 30/64 loss: -2.1469039916992188
Batch 31/64 loss: -2.194796562194824
Batch 32/64 loss: -2.084967613220215
Batch 33/64 loss: -1.9622583389282227
Batch 34/64 loss: -1.6665067672729492
Batch 35/64 loss: -2.2381300926208496
Batch 36/64 loss: -1.9282255172729492
Batch 37/64 loss: -2.2510900497436523
Batch 38/64 loss: -2.017299175262451
Batch 39/64 loss: -2.1070079803466797
Batch 40/64 loss: -1.719886302947998
Batch 41/64 loss: -1.8517799377441406
Batch 42/64 loss: -1.782771110534668
Batch 43/64 loss: -1.9898567199707031
Batch 44/64 loss: -1.893564224243164
Batch 45/64 loss: -2.038205146789551
Batch 46/64 loss: -2.0890021324157715
Batch 47/64 loss: -1.9147939682006836
Batch 48/64 loss: -1.8941287994384766
Batch 49/64 loss: -2.084414482116699
Batch 50/64 loss: -1.537649154663086
Batch 51/64 loss: -1.849318027496338
Batch 52/64 loss: -2.0724310874938965
Batch 53/64 loss: -1.9122905731201172
Batch 54/64 loss: -2.022977352142334
Batch 55/64 loss: -2.0791749954223633
Batch 56/64 loss: -2.001650810241699
Batch 57/64 loss: -2.162196159362793
Batch 58/64 loss: -1.8664836883544922
Batch 59/64 loss: -1.9697895050048828
Batch 60/64 loss: -1.5638933181762695
Batch 61/64 loss: -1.8390779495239258
Batch 62/64 loss: -2.170100688934326
Batch 63/64 loss: -1.855151653289795
Batch 64/64 loss: -6.165167331695557
Epoch 485  Train loss: -2.013645918229047  Val loss: -2.139014267020209
Epoch 486
-------------------------------
Batch 1/64 loss: -1.9290580749511719
Batch 2/64 loss: -1.6678190231323242
Batch 3/64 loss: -2.0667724609375
Batch 4/64 loss: -2.026860237121582
Batch 5/64 loss: -2.12534236907959
Batch 6/64 loss: -1.9412765502929688
Batch 7/64 loss: -2.0483083724975586
Batch 8/64 loss: -1.9352750778198242
Batch 9/64 loss: -2.0148086547851562
Batch 10/64 loss: -1.4286127090454102
Batch 11/64 loss: -2.0974645614624023
Batch 12/64 loss: -2.064962387084961
Batch 13/64 loss: -1.9408316612243652
Batch 14/64 loss: -2.0921521186828613
Batch 15/64 loss: -2.1358861923217773
Batch 16/64 loss: -1.7906360626220703
Batch 17/64 loss: -2.1002683639526367
Batch 18/64 loss: -1.859325885772705
Batch 19/64 loss: -1.7444424629211426
Batch 20/64 loss: -1.9582586288452148
Batch 21/64 loss: -1.6282472610473633
Batch 22/64 loss: -2.109036445617676
Batch 23/64 loss: -1.9617009162902832
Batch 24/64 loss: -2.219120502471924
Batch 25/64 loss: -2.031113624572754
Batch 26/64 loss: -1.7553672790527344
Batch 27/64 loss: -2.2003560066223145
Batch 28/64 loss: -1.9828014373779297
Batch 29/64 loss: -1.971972942352295
Batch 30/64 loss: -1.5449676513671875
Batch 31/64 loss: -1.938359260559082
Batch 32/64 loss: -1.3641319274902344
Batch 33/64 loss: -1.9676485061645508
Batch 34/64 loss: -1.967491626739502
Batch 35/64 loss: -2.1233205795288086
Batch 36/64 loss: -2.0008764266967773
Batch 37/64 loss: -1.6484708786010742
Batch 38/64 loss: -2.0305967330932617
Batch 39/64 loss: -2.1771602630615234
Batch 40/64 loss: -1.7683935165405273
Batch 41/64 loss: -2.0771398544311523
Batch 42/64 loss: -1.990340232849121
Batch 43/64 loss: -2.0367918014526367
Batch 44/64 loss: -2.0815882682800293
Batch 45/64 loss: -1.2074975967407227
Batch 46/64 loss: -2.001321315765381
Batch 47/64 loss: -1.9316463470458984
Batch 48/64 loss: -2.006277084350586
Batch 49/64 loss: -1.8912372589111328
Batch 50/64 loss: -2.218290328979492
Batch 51/64 loss: -1.835383415222168
Batch 52/64 loss: -2.080111026763916
Batch 53/64 loss: -1.9822192192077637
Batch 54/64 loss: -2.029663562774658
Batch 55/64 loss: -2.186997890472412
Batch 56/64 loss: -1.7509527206420898
Batch 57/64 loss: -1.9329771995544434
Batch 58/64 loss: -1.9990739822387695
Batch 59/64 loss: -2.0094504356384277
Batch 60/64 loss: -1.7952823638916016
Batch 61/64 loss: -2.0823822021484375
Batch 62/64 loss: -1.987502098083496
Batch 63/64 loss: -2.200564384460449
Batch 64/64 loss: -6.3872761726379395
Epoch 486  Train loss: -1.9994453860264199  Val loss: -2.1431146339862206
Epoch 487
-------------------------------
Batch 1/64 loss: -2.128127098083496
Batch 2/64 loss: -2.119220733642578
Batch 3/64 loss: -2.0427780151367188
Batch 4/64 loss: -2.1664419174194336
Batch 5/64 loss: -1.9898929595947266
Batch 6/64 loss: -2.173802375793457
Batch 7/64 loss: -2.1889777183532715
Batch 8/64 loss: -1.9316253662109375
Batch 9/64 loss: -2.022073745727539
Batch 10/64 loss: -2.1132760047912598
Batch 11/64 loss: -2.1438164710998535
Batch 12/64 loss: -1.671217918395996
Batch 13/64 loss: -2.05435848236084
Batch 14/64 loss: -2.1691527366638184
Batch 15/64 loss: -1.7859759330749512
Batch 16/64 loss: -2.00701904296875
Batch 17/64 loss: -1.8166518211364746
Batch 18/64 loss: -2.0388078689575195
Batch 19/64 loss: -1.9733390808105469
Batch 20/64 loss: -2.06143856048584
Batch 21/64 loss: -1.9373722076416016
Batch 22/64 loss: -1.9712872505187988
Batch 23/64 loss: -1.833221435546875
Batch 24/64 loss: -1.8152484893798828
Batch 25/64 loss: -2.230109691619873
Batch 26/64 loss: -1.9521493911743164
Batch 27/64 loss: -2.1886653900146484
Batch 28/64 loss: -2.0278172492980957
Batch 29/64 loss: -2.209113597869873
Batch 30/64 loss: -1.9134645462036133
Batch 31/64 loss: -2.102755069732666
Batch 32/64 loss: -1.6715192794799805
Batch 33/64 loss: -2.129277229309082
Batch 34/64 loss: -1.8035860061645508
Batch 35/64 loss: -2.0636463165283203
Batch 36/64 loss: -2.15726375579834
Batch 37/64 loss: -2.1154050827026367
Batch 38/64 loss: -1.8738903999328613
Batch 39/64 loss: -2.1293649673461914
Batch 40/64 loss: -1.9576311111450195
Batch 41/64 loss: -1.9597434997558594
Batch 42/64 loss: -1.9701228141784668
Batch 43/64 loss: -1.9723796844482422
Batch 44/64 loss: -1.9849128723144531
Batch 45/64 loss: -1.8842859268188477
Batch 46/64 loss: -1.998304843902588
Batch 47/64 loss: -1.809147834777832
Batch 48/64 loss: -1.9658923149108887
Batch 49/64 loss: -1.8634295463562012
Batch 50/64 loss: -2.1507463455200195
Batch 51/64 loss: -2.0837249755859375
Batch 52/64 loss: -2.2246155738830566
Batch 53/64 loss: -1.8429412841796875
Batch 54/64 loss: -1.6578445434570312
Batch 55/64 loss: -1.9149746894836426
Batch 56/64 loss: -1.9317646026611328
Batch 57/64 loss: -2.0058155059814453
Batch 58/64 loss: -1.7904272079467773
Batch 59/64 loss: -2.3141775131225586
Batch 60/64 loss: -1.907444953918457
Batch 61/64 loss: -1.7537755966186523
Batch 62/64 loss: -1.8369364738464355
Batch 63/64 loss: -1.9490318298339844
Batch 64/64 loss: -5.750452995300293
Epoch 487  Train loss: -2.0355460784014534  Val loss: -2.08935462977878
Epoch 488
-------------------------------
Batch 1/64 loss: -2.067638397216797
Batch 2/64 loss: -1.9377551078796387
Batch 3/64 loss: -2.1821699142456055
Batch 4/64 loss: -1.8727788925170898
Batch 5/64 loss: -1.7292428016662598
Batch 6/64 loss: -1.9147229194641113
Batch 7/64 loss: -2.054368495941162
Batch 8/64 loss: -1.9392409324645996
Batch 9/64 loss: -1.870121955871582
Batch 10/64 loss: -1.9377622604370117
Batch 11/64 loss: -1.8763442039489746
Batch 12/64 loss: -1.9741058349609375
Batch 13/64 loss: -1.9165840148925781
Batch 14/64 loss: -1.3516426086425781
Batch 15/64 loss: -1.9354753494262695
Batch 16/64 loss: -1.6951279640197754
Batch 17/64 loss: -1.829157829284668
Batch 18/64 loss: -1.9644532203674316
Batch 19/64 loss: -1.8020968437194824
Batch 20/64 loss: -1.3287124633789062
Batch 21/64 loss: -1.777144432067871
Batch 22/64 loss: -2.264655590057373
Batch 23/64 loss: -1.5019550323486328
Batch 24/64 loss: -2.0823259353637695
Batch 25/64 loss: -1.7278785705566406
Batch 26/64 loss: -1.8438453674316406
Batch 27/64 loss: -1.7304792404174805
Batch 28/64 loss: -2.188136100769043
Batch 29/64 loss: -1.9525580406188965
Batch 30/64 loss: -1.858088493347168
Batch 31/64 loss: -2.1844329833984375
Batch 32/64 loss: -1.9922585487365723
Batch 33/64 loss: -1.7573657035827637
Batch 34/64 loss: -2.0632190704345703
Batch 35/64 loss: -1.7860469818115234
Batch 36/64 loss: -1.9946980476379395
Batch 37/64 loss: -1.7138032913208008
Batch 38/64 loss: -1.9579153060913086
Batch 39/64 loss: -1.9692811965942383
Batch 40/64 loss: -2.097538948059082
Batch 41/64 loss: -2.0313634872436523
Batch 42/64 loss: -2.1687064170837402
Batch 43/64 loss: -2.0630483627319336
Batch 44/64 loss: -1.8863096237182617
Batch 45/64 loss: -2.0553841590881348
Batch 46/64 loss: -1.999117374420166
Batch 47/64 loss: -2.1527152061462402
Batch 48/64 loss: -2.0104598999023438
Batch 49/64 loss: -2.0625839233398438
Batch 50/64 loss: -2.34743595123291
Batch 51/64 loss: -1.9730033874511719
Batch 52/64 loss: -2.1078834533691406
Batch 53/64 loss: -2.1458168029785156
Batch 54/64 loss: -1.8620858192443848
Batch 55/64 loss: -1.9837226867675781
Batch 56/64 loss: -2.2042360305786133
Batch 57/64 loss: -2.031686305999756
Batch 58/64 loss: -2.018465995788574
Batch 59/64 loss: -1.9918441772460938
Batch 60/64 loss: -2.1577248573303223
Batch 61/64 loss: -1.853553295135498
Batch 62/64 loss: -2.2102956771850586
Batch 63/64 loss: -2.0504751205444336
Batch 64/64 loss: -6.31641149520874
Epoch 488  Train loss: -2.0035820474811628  Val loss: -2.208027856046801
Epoch 489
-------------------------------
Batch 1/64 loss: -1.868483543395996
Batch 2/64 loss: -2.186953544616699
Batch 3/64 loss: -1.8559179306030273
Batch 4/64 loss: -2.111077308654785
Batch 5/64 loss: -2.2246599197387695
Batch 6/64 loss: -2.185314655303955
Batch 7/64 loss: -1.7133302688598633
Batch 8/64 loss: -1.998152256011963
Batch 9/64 loss: -2.129265785217285
Batch 10/64 loss: -2.150796890258789
Batch 11/64 loss: -2.0520777702331543
Batch 12/64 loss: -1.8659453392028809
Batch 13/64 loss: -1.9412169456481934
Batch 14/64 loss: -1.903045654296875
Batch 15/64 loss: -1.9872732162475586
Batch 16/64 loss: -2.0649566650390625
Batch 17/64 loss: -2.0484652519226074
Batch 18/64 loss: -1.9873762130737305
Batch 19/64 loss: -2.171915054321289
Batch 20/64 loss: -1.6924915313720703
Batch 21/64 loss: -1.5840768814086914
Batch 22/64 loss: -2.2135229110717773
Batch 23/64 loss: -2.1264843940734863
Batch 24/64 loss: -1.8525619506835938
Batch 25/64 loss: -1.7912979125976562
Batch 26/64 loss: -2.1543426513671875
Batch 27/64 loss: -2.106560707092285
Batch 28/64 loss: -1.8859977722167969
Batch 29/64 loss: -2.181042194366455
Batch 30/64 loss: -2.119746208190918
Batch 31/64 loss: -2.0996222496032715
Batch 32/64 loss: -2.097158432006836
Batch 33/64 loss: -1.842228889465332
Batch 34/64 loss: -1.5916194915771484
Batch 35/64 loss: -2.187561511993408
Batch 36/64 loss: -2.157525062561035
Batch 37/64 loss: -1.9045515060424805
Batch 38/64 loss: -2.0589866638183594
Batch 39/64 loss: -2.10573673248291
Batch 40/64 loss: -2.2202749252319336
Batch 41/64 loss: -1.7761611938476562
Batch 42/64 loss: -1.7257184982299805
Batch 43/64 loss: -1.9096660614013672
Batch 44/64 loss: -1.8898887634277344
Batch 45/64 loss: -2.0769119262695312
Batch 46/64 loss: -2.2430920600891113
Batch 47/64 loss: -2.1231417655944824
Batch 48/64 loss: -1.8521728515625
Batch 49/64 loss: -2.2386474609375
Batch 50/64 loss: -1.934432029724121
Batch 51/64 loss: -2.074906349182129
Batch 52/64 loss: -2.1384077072143555
Batch 53/64 loss: -1.7970829010009766
Batch 54/64 loss: -2.17885684967041
Batch 55/64 loss: -1.9709601402282715
Batch 56/64 loss: -2.011326789855957
Batch 57/64 loss: -1.8689804077148438
Batch 58/64 loss: -1.9007844924926758
Batch 59/64 loss: -1.664576530456543
Batch 60/64 loss: -2.131923198699951
Batch 61/64 loss: -1.5243425369262695
Batch 62/64 loss: -2.2487611770629883
Batch 63/64 loss: -1.7566614151000977
Batch 64/64 loss: -6.309293270111084
Epoch 489  Train loss: -2.042180201586555  Val loss: -2.1960484350669836
Epoch 490
-------------------------------
Batch 1/64 loss: -2.028829574584961
Batch 2/64 loss: -1.8887553215026855
Batch 3/64 loss: -2.1057024002075195
Batch 4/64 loss: -2.1437134742736816
Batch 5/64 loss: -1.8954834938049316
Batch 6/64 loss: -2.026423931121826
Batch 7/64 loss: -1.2613458633422852
Batch 8/64 loss: -2.199570655822754
Batch 9/64 loss: -2.15842342376709
Batch 10/64 loss: -2.0307979583740234
Batch 11/64 loss: -2.3141837120056152
Batch 12/64 loss: -2.063753128051758
Batch 13/64 loss: -2.0076475143432617
Batch 14/64 loss: -2.0635828971862793
Batch 15/64 loss: -1.7126502990722656
Batch 16/64 loss: -2.013840675354004
Batch 17/64 loss: -2.186458110809326
Batch 18/64 loss: -2.1412811279296875
Batch 19/64 loss: -2.037905693054199
Batch 20/64 loss: -2.151251792907715
Batch 21/64 loss: -1.9190068244934082
Batch 22/64 loss: -2.1931686401367188
Batch 23/64 loss: -2.0348219871520996
Batch 24/64 loss: -1.8302817344665527
Batch 25/64 loss: -1.8448677062988281
Batch 26/64 loss: -2.1901159286499023
Batch 27/64 loss: -1.9300918579101562
Batch 28/64 loss: -2.0999879837036133
Batch 29/64 loss: -1.8865947723388672
Batch 30/64 loss: -2.2064528465270996
Batch 31/64 loss: -1.5659255981445312
Batch 32/64 loss: -1.639425277709961
Batch 33/64 loss: -2.1096529960632324
Batch 34/64 loss: -1.5070772171020508
Batch 35/64 loss: -1.8766613006591797
Batch 36/64 loss: -2.1554641723632812
Batch 37/64 loss: -2.0833797454833984
Batch 38/64 loss: -2.1892247200012207
Batch 39/64 loss: -1.9168272018432617
Batch 40/64 loss: -1.8336820602416992
Batch 41/64 loss: -1.9289169311523438
Batch 42/64 loss: -2.1377978324890137
Batch 43/64 loss: -1.7468986511230469
Batch 44/64 loss: -1.8055553436279297
Batch 45/64 loss: -1.7907676696777344
Batch 46/64 loss: -1.8220853805541992
Batch 47/64 loss: -1.9986963272094727
Batch 48/64 loss: -2.1279025077819824
Batch 49/64 loss: -1.9901094436645508
Batch 50/64 loss: -2.252498149871826
Batch 51/64 loss: -1.9968366622924805
Batch 52/64 loss: -1.895029067993164
Batch 53/64 loss: -2.225144863128662
Batch 54/64 loss: -1.9394917488098145
Batch 55/64 loss: -1.448979377746582
Batch 56/64 loss: -1.7591753005981445
Batch 57/64 loss: -1.8814311027526855
Batch 58/64 loss: -1.9622058868408203
Batch 59/64 loss: -2.164684772491455
Batch 60/64 loss: -1.879641056060791
Batch 61/64 loss: -1.5110511779785156
Batch 62/64 loss: -1.991434097290039
Batch 63/64 loss: -2.2951183319091797
Batch 64/64 loss: -5.814923286437988
Epoch 490  Train loss: -2.0134424433988682  Val loss: -2.234005787118604
Epoch 491
-------------------------------
Batch 1/64 loss: -1.9325180053710938
Batch 2/64 loss: -2.0576915740966797
Batch 3/64 loss: -1.9737777709960938
Batch 4/64 loss: -2.2786755561828613
Batch 5/64 loss: -1.9810028076171875
Batch 6/64 loss: -2.0384693145751953
Batch 7/64 loss: -2.1014723777770996
Batch 8/64 loss: -1.7568330764770508
Batch 9/64 loss: -2.0844926834106445
Batch 10/64 loss: -2.1026482582092285
Batch 11/64 loss: -2.209852695465088
Batch 12/64 loss: -2.1329545974731445
Batch 13/64 loss: -2.0953102111816406
Batch 14/64 loss: -1.397629737854004
Batch 15/64 loss: -1.8668851852416992
Batch 16/64 loss: -1.9146571159362793
Batch 17/64 loss: -1.9973764419555664
Batch 18/64 loss: -1.9977421760559082
Batch 19/64 loss: -2.0803098678588867
Batch 20/64 loss: -1.7357454299926758
Batch 21/64 loss: -2.056591033935547
Batch 22/64 loss: -1.7052984237670898
Batch 23/64 loss: -1.8520946502685547
Batch 24/64 loss: -2.024160385131836
Batch 25/64 loss: -2.0471506118774414
Batch 26/64 loss: -1.9081850051879883
Batch 27/64 loss: -1.8943305015563965
Batch 28/64 loss: -1.9156618118286133
Batch 29/64 loss: -1.8579254150390625
Batch 30/64 loss: -1.7678098678588867
Batch 31/64 loss: -1.8382530212402344
Batch 32/64 loss: -1.9524669647216797
Batch 33/64 loss: -1.9880332946777344
Batch 34/64 loss: -1.8221678733825684
Batch 35/64 loss: -2.0386762619018555
Batch 36/64 loss: -1.8555512428283691
Batch 37/64 loss: -1.5277881622314453
Batch 38/64 loss: -1.7653722763061523
Batch 39/64 loss: -1.843543529510498
Batch 40/64 loss: -1.9456233978271484
Batch 41/64 loss: -2.014615058898926
Batch 42/64 loss: -1.7901782989501953
Batch 43/64 loss: -1.5735721588134766
Batch 44/64 loss: -1.6894426345825195
Batch 45/64 loss: -2.015554428100586
Batch 46/64 loss: -2.1100006103515625
Batch 47/64 loss: -2.0222549438476562
Batch 48/64 loss: -1.9083704948425293
Batch 49/64 loss: -2.165745735168457
Batch 50/64 loss: -2.2142810821533203
Batch 51/64 loss: -1.7885112762451172
Batch 52/64 loss: -1.5128355026245117
Batch 53/64 loss: -2.155385971069336
Batch 54/64 loss: -2.020324230194092
Batch 55/64 loss: -1.7427778244018555
Batch 56/64 loss: -1.6108636856079102
Batch 57/64 loss: -1.8932304382324219
Batch 58/64 loss: -2.042679786682129
Batch 59/64 loss: -2.0979928970336914
Batch 60/64 loss: -1.835902214050293
Batch 61/64 loss: -1.6512517929077148
Batch 62/64 loss: -1.720541000366211
Batch 63/64 loss: -2.011432647705078
Batch 64/64 loss: -5.848840713500977
Epoch 491  Train loss: -1.9657584919649012  Val loss: -2.182335489803983
Epoch 492
-------------------------------
Batch 1/64 loss: -2.0155630111694336
Batch 2/64 loss: -2.2198963165283203
Batch 3/64 loss: -2.1016159057617188
Batch 4/64 loss: -1.9524297714233398
Batch 5/64 loss: -2.022721290588379
Batch 6/64 loss: -1.8958425521850586
Batch 7/64 loss: -1.9672598838806152
Batch 8/64 loss: -1.9681406021118164
Batch 9/64 loss: -2.0418338775634766
Batch 10/64 loss: -2.0452027320861816
Batch 11/64 loss: -2.0443010330200195
Batch 12/64 loss: -2.083681106567383
Batch 13/64 loss: -1.7958531379699707
Batch 14/64 loss: -1.5094289779663086
Batch 15/64 loss: -2.1204795837402344
Batch 16/64 loss: -2.112338066101074
Batch 17/64 loss: -1.3617630004882812
Batch 18/64 loss: -1.992631435394287
Batch 19/64 loss: -2.1222634315490723
Batch 20/64 loss: -1.5885248184204102
Batch 21/64 loss: -1.9479122161865234
Batch 22/64 loss: -1.993875503540039
Batch 23/64 loss: -1.8678131103515625
Batch 24/64 loss: -2.0759634971618652
Batch 25/64 loss: -1.855438232421875
Batch 26/64 loss: -1.943613052368164
Batch 27/64 loss: -1.7232441902160645
Batch 28/64 loss: -1.8354387283325195
Batch 29/64 loss: -2.055400848388672
Batch 30/64 loss: -1.9604883193969727
Batch 31/64 loss: -1.7057256698608398
Batch 32/64 loss: -2.0817832946777344
Batch 33/64 loss: -2.1604795455932617
Batch 34/64 loss: -1.6896429061889648
Batch 35/64 loss: -1.9336738586425781
Batch 36/64 loss: -2.0634684562683105
Batch 37/64 loss: -2.2216787338256836
Batch 38/64 loss: -2.015721321105957
Batch 39/64 loss: -1.917402744293213
Batch 40/64 loss: -2.0726795196533203
Batch 41/64 loss: -2.0250473022460938
Batch 42/64 loss: -1.9451656341552734
Batch 43/64 loss: -1.9378581047058105
Batch 44/64 loss: -2.007284164428711
Batch 45/64 loss: -1.7447929382324219
Batch 46/64 loss: -1.813699722290039
Batch 47/64 loss: -1.940505027770996
Batch 48/64 loss: -2.125610828399658
Batch 49/64 loss: -1.819101333618164
Batch 50/64 loss: -1.9603886604309082
Batch 51/64 loss: -2.1465306282043457
Batch 52/64 loss: -1.993086338043213
Batch 53/64 loss: -1.8395633697509766
Batch 54/64 loss: -2.0058460235595703
Batch 55/64 loss: -2.0527124404907227
Batch 56/64 loss: -1.8421564102172852
Batch 57/64 loss: -2.0774917602539062
Batch 58/64 loss: -1.9689898490905762
Batch 59/64 loss: -2.1627044677734375
Batch 60/64 loss: -2.143185615539551
Batch 61/64 loss: -1.9807820320129395
Batch 62/64 loss: -1.737574577331543
Batch 63/64 loss: -2.1468143463134766
Batch 64/64 loss: -5.896417140960693
Epoch 492  Train loss: -2.0066261758991315  Val loss: -2.2152434542416706
Epoch 493
-------------------------------
Batch 1/64 loss: -2.031675338745117
Batch 2/64 loss: -2.2543716430664062
Batch 3/64 loss: -2.075002670288086
Batch 4/64 loss: -2.120604991912842
Batch 5/64 loss: -1.8992176055908203
Batch 6/64 loss: -2.0696277618408203
Batch 7/64 loss: -2.121514320373535
Batch 8/64 loss: -2.0189990997314453
Batch 9/64 loss: -1.8133621215820312
Batch 10/64 loss: -1.914407730102539
Batch 11/64 loss: -2.1227951049804688
Batch 12/64 loss: -2.2205724716186523
Batch 13/64 loss: -1.7130212783813477
Batch 14/64 loss: -2.008547306060791
Batch 15/64 loss: -1.9400806427001953
Batch 16/64 loss: -1.933816909790039
Batch 17/64 loss: -2.0135583877563477
Batch 18/64 loss: -2.063720226287842
Batch 19/64 loss: -1.9824023246765137
Batch 20/64 loss: -2.07981538772583
Batch 21/64 loss: -1.8876523971557617
Batch 22/64 loss: -1.6307144165039062
Batch 23/64 loss: -1.7682113647460938
Batch 24/64 loss: -1.5876903533935547
Batch 25/64 loss: -1.467574119567871
Batch 26/64 loss: -1.6317777633666992
Batch 27/64 loss: -2.147937774658203
Batch 28/64 loss: -1.4061555862426758
Batch 29/64 loss: -1.819138526916504
Batch 30/64 loss: -1.5410528182983398
Batch 31/64 loss: -1.875905990600586
Batch 32/64 loss: -2.002682685852051
Batch 33/64 loss: -2.0377635955810547
Batch 34/64 loss: -1.8819432258605957
Batch 35/64 loss: -2.0358643531799316
Batch 36/64 loss: -1.7239017486572266
Batch 37/64 loss: -1.8727326393127441
Batch 38/64 loss: -2.0043864250183105
Batch 39/64 loss: -1.7474212646484375
Batch 40/64 loss: -1.8262624740600586
Batch 41/64 loss: -1.836557388305664
Batch 42/64 loss: -2.1030569076538086
Batch 43/64 loss: -1.5385265350341797
Batch 44/64 loss: -1.7062788009643555
Batch 45/64 loss: -1.8387398719787598
Batch 46/64 loss: -2.0156984329223633
Batch 47/64 loss: -1.5156655311584473
Batch 48/64 loss: -1.8570828437805176
Batch 49/64 loss: -2.0063982009887695
Batch 50/64 loss: -2.1397781372070312
Batch 51/64 loss: -1.9066038131713867
Batch 52/64 loss: -1.755561351776123
Batch 53/64 loss: -1.999114990234375
Batch 54/64 loss: -1.8474340438842773
Batch 55/64 loss: -1.8366966247558594
Batch 56/64 loss: -1.795116901397705
Batch 57/64 loss: -1.656388282775879
Batch 58/64 loss: -1.9853129386901855
Batch 59/64 loss: -2.2290453910827637
Batch 60/64 loss: -2.0161609649658203
Batch 61/64 loss: -1.9035282135009766
Batch 62/64 loss: -1.9319367408752441
Batch 63/64 loss: -1.972668170928955
Batch 64/64 loss: -5.784078121185303
Epoch 493  Train loss: -1.9454947845608581  Val loss: -2.162677764892578
Epoch 494
-------------------------------
Batch 1/64 loss: -1.7320871353149414
Batch 2/64 loss: -1.8668079376220703
Batch 3/64 loss: -1.7630538940429688
Batch 4/64 loss: -2.107145309448242
Batch 5/64 loss: -2.0507984161376953
Batch 6/64 loss: -1.8755455017089844
Batch 7/64 loss: -2.094604969024658
Batch 8/64 loss: -1.965444564819336
Batch 9/64 loss: -1.9662752151489258
Batch 10/64 loss: -2.0229291915893555
Batch 11/64 loss: -1.8788723945617676
Batch 12/64 loss: -2.0283288955688477
Batch 13/64 loss: -1.8524246215820312
Batch 14/64 loss: -2.241626739501953
Batch 15/64 loss: -1.954451560974121
Batch 16/64 loss: -2.066638946533203
Batch 17/64 loss: -1.661834716796875
Batch 18/64 loss: -1.7350778579711914
Batch 19/64 loss: -1.5313653945922852
Batch 20/64 loss: -1.7170896530151367
Batch 21/64 loss: -1.921621322631836
Batch 22/64 loss: -2.1538915634155273
Batch 23/64 loss: -1.8759307861328125
Batch 24/64 loss: -2.1602725982666016
Batch 25/64 loss: -2.1292362213134766
Batch 26/64 loss: -2.1636857986450195
Batch 27/64 loss: -2.0597963333129883
Batch 28/64 loss: -2.2161922454833984
Batch 29/64 loss: -1.8514776229858398
Batch 30/64 loss: -2.1153244972229004
Batch 31/64 loss: -1.7614936828613281
Batch 32/64 loss: -2.018861770629883
Batch 33/64 loss: -2.0706357955932617
Batch 34/64 loss: -1.9657855033874512
Batch 35/64 loss: -2.186314105987549
Batch 36/64 loss: -1.7725496292114258
Batch 37/64 loss: -2.1167869567871094
Batch 38/64 loss: -1.913980484008789
Batch 39/64 loss: -2.2915048599243164
Batch 40/64 loss: -1.824697494506836
Batch 41/64 loss: -2.129932403564453
Batch 42/64 loss: -1.753525733947754
Batch 43/64 loss: -2.1167097091674805
Batch 44/64 loss: -1.747786521911621
Batch 45/64 loss: -2.134119987487793
Batch 46/64 loss: -1.5673999786376953
Batch 47/64 loss: -2.022921085357666
Batch 48/64 loss: -1.8784542083740234
Batch 49/64 loss: -1.7365021705627441
Batch 50/64 loss: -2.204737663269043
Batch 51/64 loss: -2.00065279006958
Batch 52/64 loss: -2.0163002014160156
Batch 53/64 loss: -2.0032196044921875
Batch 54/64 loss: -1.9224648475646973
Batch 55/64 loss: -2.0316028594970703
Batch 56/64 loss: -1.8698763847351074
Batch 57/64 loss: -1.7380924224853516
Batch 58/64 loss: -2.110611915588379
Batch 59/64 loss: -2.043485641479492
Batch 60/64 loss: -1.5750904083251953
Batch 61/64 loss: -2.1683945655822754
Batch 62/64 loss: -1.751662254333496
Batch 63/64 loss: -1.9651908874511719
Batch 64/64 loss: -6.04315710067749
Epoch 494  Train loss: -2.0031928511226877  Val loss: -2.2152645333935714
Epoch 495
-------------------------------
Batch 1/64 loss: -2.1176085472106934
Batch 2/64 loss: -1.8360748291015625
Batch 3/64 loss: -2.0207018852233887
Batch 4/64 loss: -1.823420524597168
Batch 5/64 loss: -1.8691215515136719
Batch 6/64 loss: -1.2288198471069336
Batch 7/64 loss: -2.107113838195801
Batch 8/64 loss: -1.9594974517822266
Batch 9/64 loss: -1.9963693618774414
Batch 10/64 loss: -2.165501594543457
Batch 11/64 loss: -2.1247315406799316
Batch 12/64 loss: -2.020740032196045
Batch 13/64 loss: -1.8314495086669922
Batch 14/64 loss: -1.884817123413086
Batch 15/64 loss: -2.1245346069335938
Batch 16/64 loss: -1.8981742858886719
Batch 17/64 loss: -2.1467032432556152
Batch 18/64 loss: -2.1605734825134277
Batch 19/64 loss: -1.8391075134277344
Batch 20/64 loss: -2.0054798126220703
Batch 21/64 loss: -1.951474666595459
Batch 22/64 loss: -1.8926057815551758
Batch 23/64 loss: -1.8891019821166992
Batch 24/64 loss: -1.952850341796875
Batch 25/64 loss: -1.9951815605163574
Batch 26/64 loss: -2.294821262359619
Batch 27/64 loss: -2.2351160049438477
Batch 28/64 loss: -2.0136032104492188
Batch 29/64 loss: -1.8621492385864258
Batch 30/64 loss: -2.157925605773926
Batch 31/64 loss: -2.1024370193481445
Batch 32/64 loss: -1.6004838943481445
Batch 33/64 loss: -2.0199995040893555
Batch 34/64 loss: -2.1467080116271973
Batch 35/64 loss: -1.9767227172851562
Batch 36/64 loss: -1.7205324172973633
Batch 37/64 loss: -2.207223892211914
Batch 38/64 loss: -1.9294452667236328
Batch 39/64 loss: -2.1172876358032227
Batch 40/64 loss: -2.0026721954345703
Batch 41/64 loss: -1.463369369506836
Batch 42/64 loss: -1.8673877716064453
Batch 43/64 loss: -1.6996517181396484
Batch 44/64 loss: -2.165739059448242
Batch 45/64 loss: -1.983980655670166
Batch 46/64 loss: -2.0553460121154785
Batch 47/64 loss: -1.9590401649475098
Batch 48/64 loss: -1.9151630401611328
Batch 49/64 loss: -2.164613723754883
Batch 50/64 loss: -1.7595601081848145
Batch 51/64 loss: -1.436624526977539
Batch 52/64 loss: -1.7748117446899414
Batch 53/64 loss: -1.9850883483886719
Batch 54/64 loss: -1.7633600234985352
Batch 55/64 loss: -1.2112770080566406
Batch 56/64 loss: -2.0765223503112793
Batch 57/64 loss: -1.9840621948242188
Batch 58/64 loss: -2.200103759765625
Batch 59/64 loss: -1.9969120025634766
Batch 60/64 loss: -2.028324604034424
Batch 61/64 loss: -1.6688146591186523
Batch 62/64 loss: -2.376795768737793
Batch 63/64 loss: -2.346163749694824
Batch 64/64 loss: -6.183258056640625
Epoch 495  Train loss: -2.003906489353554  Val loss: -2.1864705036595926
Epoch 496
-------------------------------
Batch 1/64 loss: -2.215231418609619
Batch 2/64 loss: -2.175130844116211
Batch 3/64 loss: -2.2170896530151367
Batch 4/64 loss: -1.872786521911621
Batch 5/64 loss: -2.109433650970459
Batch 6/64 loss: -1.456650733947754
Batch 7/64 loss: -1.7531614303588867
Batch 8/64 loss: -1.9534015655517578
Batch 9/64 loss: -1.829728126525879
Batch 10/64 loss: -2.196321487426758
Batch 11/64 loss: -2.0848236083984375
Batch 12/64 loss: -2.011347770690918
Batch 13/64 loss: -1.9835443496704102
Batch 14/64 loss: -2.151404857635498
Batch 15/64 loss: -2.0409231185913086
Batch 16/64 loss: -1.816065788269043
Batch 17/64 loss: -1.4633169174194336
Batch 18/64 loss: -2.0633082389831543
Batch 19/64 loss: -2.1397757530212402
Batch 20/64 loss: -2.0302886962890625
Batch 21/64 loss: -2.1332883834838867
Batch 22/64 loss: -2.2001895904541016
Batch 23/64 loss: -2.190168857574463
Batch 24/64 loss: -1.717951774597168
Batch 25/64 loss: -1.8520631790161133
Batch 26/64 loss: -2.2562570571899414
Batch 27/64 loss: -2.017584800720215
Batch 28/64 loss: -2.2475805282592773
Batch 29/64 loss: -1.9629979133605957
Batch 30/64 loss: -1.2242517471313477
Batch 31/64 loss: -1.8517818450927734
Batch 32/64 loss: -2.1896862983703613
Batch 33/64 loss: -2.2132272720336914
Batch 34/64 loss: -2.062302589416504
Batch 35/64 loss: -1.9961652755737305
Batch 36/64 loss: -1.6774320602416992
Batch 37/64 loss: -1.9699954986572266
Batch 38/64 loss: -2.0336861610412598
Batch 39/64 loss: -2.155681610107422
Batch 40/64 loss: -2.09116268157959
Batch 41/64 loss: -1.754568099975586
Batch 42/64 loss: -1.9939956665039062
Batch 43/64 loss: -1.9474735260009766
Batch 44/64 loss: -1.887481689453125
Batch 45/64 loss: -1.915269374847412
Batch 46/64 loss: -1.901641845703125
Batch 47/64 loss: -2.039858818054199
Batch 48/64 loss: -1.8324270248413086
Batch 49/64 loss: -1.8748111724853516
Batch 50/64 loss: -2.0978755950927734
Batch 51/64 loss: -1.9567608833312988
Batch 52/64 loss: -2.050654411315918
Batch 53/64 loss: -2.1617608070373535
Batch 54/64 loss: -1.611069679260254
Batch 55/64 loss: -1.9928021430969238
Batch 56/64 loss: -2.042898654937744
Batch 57/64 loss: -1.8858208656311035
Batch 58/64 loss: -2.038206100463867
Batch 59/64 loss: -2.0610227584838867
Batch 60/64 loss: -2.0846638679504395
Batch 61/64 loss: -2.291468620300293
Batch 62/64 loss: -1.876455307006836
Batch 63/64 loss: -2.2110586166381836
Batch 64/64 loss: -6.04207181930542
Epoch 496  Train loss: -2.033706494873645  Val loss: -2.178521382439997
Epoch 497
-------------------------------
Batch 1/64 loss: -1.7285575866699219
Batch 2/64 loss: -2.0828418731689453
Batch 3/64 loss: -2.228058338165283
Batch 4/64 loss: -1.9487981796264648
Batch 5/64 loss: -2.014951705932617
Batch 6/64 loss: -2.1735734939575195
Batch 7/64 loss: -1.9989609718322754
Batch 8/64 loss: -2.0342206954956055
Batch 9/64 loss: -2.0696215629577637
Batch 10/64 loss: -1.913102149963379
Batch 11/64 loss: -2.095785617828369
Batch 12/64 loss: -1.8812103271484375
Batch 13/64 loss: -2.1762170791625977
Batch 14/64 loss: -2.338411331176758
Batch 15/64 loss: -1.9625401496887207
Batch 16/64 loss: -1.5619316101074219
Batch 17/64 loss: -2.052779197692871
Batch 18/64 loss: -1.703324317932129
Batch 19/64 loss: -2.1243019104003906
Batch 20/64 loss: -1.8435235023498535
Batch 21/64 loss: -1.9547204971313477
Batch 22/64 loss: -1.689164161682129
Batch 23/64 loss: -2.1363563537597656
Batch 24/64 loss: -2.065258026123047
Batch 25/64 loss: -1.8532562255859375
Batch 26/64 loss: -1.7931404113769531
Batch 27/64 loss: -2.063662528991699
Batch 28/64 loss: -2.0662126541137695
Batch 29/64 loss: -1.8945808410644531
Batch 30/64 loss: -2.2410154342651367
Batch 31/64 loss: -2.1726531982421875
Batch 32/64 loss: -2.019662857055664
Batch 33/64 loss: -1.7848281860351562
Batch 34/64 loss: -2.090421676635742
Batch 35/64 loss: -2.0320425033569336
Batch 36/64 loss: -1.7264814376831055
Batch 37/64 loss: -1.9218225479125977
Batch 38/64 loss: -1.9461727142333984
Batch 39/64 loss: -1.9060688018798828
Batch 40/64 loss: -1.7177953720092773
Batch 41/64 loss: -2.0107288360595703
Batch 42/64 loss: -2.007356643676758
Batch 43/64 loss: -1.6886310577392578
Batch 44/64 loss: -1.9757952690124512
Batch 45/64 loss: -1.7299108505249023
Batch 46/64 loss: -2.182328701019287
Batch 47/64 loss: -1.6355743408203125
Batch 48/64 loss: -1.6947784423828125
Batch 49/64 loss: -2.182729721069336
Batch 50/64 loss: -1.968705654144287
Batch 51/64 loss: -1.9042510986328125
Batch 52/64 loss: -1.9415063858032227
Batch 53/64 loss: -1.9876899719238281
Batch 54/64 loss: -2.0856833457946777
Batch 55/64 loss: -2.1488986015319824
Batch 56/64 loss: -1.7248153686523438
Batch 57/64 loss: -2.077383518218994
Batch 58/64 loss: -2.0961713790893555
Batch 59/64 loss: -1.549363136291504
Batch 60/64 loss: -2.0935516357421875
Batch 61/64 loss: -1.947984218597412
Batch 62/64 loss: -1.937276840209961
Batch 63/64 loss: -1.7233810424804688
Batch 64/64 loss: -5.974198818206787
Epoch 497  Train loss: -2.0044419326034246  Val loss: -2.006302574655854
Epoch 498
-------------------------------
Batch 1/64 loss: -2.0844173431396484
Batch 2/64 loss: -1.802229881286621
Batch 3/64 loss: -1.471963882446289
Batch 4/64 loss: -1.9204163551330566
Batch 5/64 loss: -2.2146921157836914
Batch 6/64 loss: -1.9144830703735352
Batch 7/64 loss: -2.0151586532592773
Batch 8/64 loss: -1.7353081703186035
Batch 9/64 loss: -1.73378324508667
Batch 10/64 loss: -1.9879398345947266
Batch 11/64 loss: -1.9338483810424805
Batch 12/64 loss: -1.6821708679199219
Batch 13/64 loss: -1.5375862121582031
Batch 14/64 loss: -1.9356813430786133
Batch 15/64 loss: -1.5459089279174805
Batch 16/64 loss: -2.0271759033203125
Batch 17/64 loss: -1.8540105819702148
Batch 18/64 loss: -1.4373464584350586
Batch 19/64 loss: -1.7845840454101562
Batch 20/64 loss: -1.7652883529663086
Batch 21/64 loss: -1.8201236724853516
Batch 22/64 loss: -1.785818099975586
Batch 23/64 loss: -1.7682533264160156
Batch 24/64 loss: -1.6856956481933594
Batch 25/64 loss: -1.733560562133789
Batch 26/64 loss: -1.8251590728759766
Batch 27/64 loss: -1.759495735168457
Batch 28/64 loss: -1.9214391708374023
Batch 29/64 loss: -2.1087722778320312
Batch 30/64 loss: -1.640660285949707
Batch 31/64 loss: -1.7046127319335938
Batch 32/64 loss: -2.1168360710144043
Batch 33/64 loss: -1.6752471923828125
Batch 34/64 loss: -1.5208740234375
Batch 35/64 loss: -1.9856414794921875
Batch 36/64 loss: -1.9749150276184082
Batch 37/64 loss: -1.9139604568481445
Batch 38/64 loss: -1.7484064102172852
Batch 39/64 loss: -1.857654094696045
Batch 40/64 loss: -1.8877439498901367
Batch 41/64 loss: -1.6786870956420898
Batch 42/64 loss: -1.9768767356872559
Batch 43/64 loss: -1.7666873931884766
Batch 44/64 loss: -1.7254977226257324
Batch 45/64 loss: -2.0336503982543945
Batch 46/64 loss: -2.066255569458008
Batch 47/64 loss: -2.0158300399780273
Batch 48/64 loss: -2.0254454612731934
Batch 49/64 loss: -2.115825653076172
Batch 50/64 loss: -1.9191551208496094
Batch 51/64 loss: -2.1375999450683594
Batch 52/64 loss: -2.0189037322998047
Batch 53/64 loss: -1.6682777404785156
Batch 54/64 loss: -1.470743179321289
Batch 55/64 loss: -1.7996253967285156
Batch 56/64 loss: -2.114443302154541
Batch 57/64 loss: -2.1609435081481934
Batch 58/64 loss: -2.0738348960876465
Batch 59/64 loss: -1.8671083450317383
Batch 60/64 loss: -1.7037792205810547
Batch 61/64 loss: -2.0495285987854004
Batch 62/64 loss: -1.8143014907836914
Batch 63/64 loss: -1.9449796676635742
Batch 64/64 loss: -5.5466485023498535
Epoch 498  Train loss: -1.9000286981171253  Val loss: -2.12800187835169
Epoch 499
-------------------------------
Batch 1/64 loss: -2.0822548866271973
Batch 2/64 loss: -2.165182113647461
Batch 3/64 loss: -1.6477346420288086
Batch 4/64 loss: -2.1070470809936523
Batch 5/64 loss: -1.8187808990478516
Batch 6/64 loss: -1.769805908203125
Batch 7/64 loss: -2.293884754180908
Batch 8/64 loss: -1.7495384216308594
Batch 9/64 loss: -1.97609281539917
Batch 10/64 loss: -2.203704833984375
Batch 11/64 loss: -1.7277636528015137
Batch 12/64 loss: -1.8799147605895996
Batch 13/64 loss: -1.8126230239868164
Batch 14/64 loss: -1.9740571975708008
Batch 15/64 loss: -2.004765510559082
Batch 16/64 loss: -1.9514856338500977
Batch 17/64 loss: -2.0361642837524414
Batch 18/64 loss: -1.8359465599060059
Batch 19/64 loss: -1.9252433776855469
Batch 20/64 loss: -2.1562747955322266
Batch 21/64 loss: -2.0671401023864746
Batch 22/64 loss: -1.561246395111084
Batch 23/64 loss: -2.158583641052246
Batch 24/64 loss: -2.06150484085083
Batch 25/64 loss: -2.0112838745117188
Batch 26/64 loss: -2.159832000732422
Batch 27/64 loss: -1.9513401985168457
Batch 28/64 loss: -1.9195032119750977
Batch 29/64 loss: -2.1435928344726562
Batch 30/64 loss: -1.9658231735229492
Batch 31/64 loss: -2.213751792907715
Batch 32/64 loss: -2.2545347213745117
Batch 33/64 loss: -1.7283053398132324
Batch 34/64 loss: -2.157517910003662
Batch 35/64 loss: -2.016122817993164
Batch 36/64 loss: -2.0451512336730957
Batch 37/64 loss: -2.0786848068237305
Batch 38/64 loss: -1.9725427627563477
Batch 39/64 loss: -2.019608497619629
Batch 40/64 loss: -2.2027297019958496
Batch 41/64 loss: -1.9833779335021973
Batch 42/64 loss: -1.7337579727172852
Batch 43/64 loss: -1.7096118927001953
Batch 44/64 loss: -1.734837532043457
Batch 45/64 loss: -2.194125175476074
Batch 46/64 loss: -1.909872055053711
Batch 47/64 loss: -1.870081901550293
Batch 48/64 loss: -2.035358428955078
Batch 49/64 loss: -1.738163948059082
Batch 50/64 loss: -1.4993515014648438
Batch 51/64 loss: -1.6078529357910156
Batch 52/64 loss: -1.919114112854004
Batch 53/64 loss: -1.968179702758789
Batch 54/64 loss: -2.1227974891662598
Batch 55/64 loss: -2.0108304023742676
Batch 56/64 loss: -2.1370863914489746
Batch 57/64 loss: -1.835123062133789
Batch 58/64 loss: -2.1900548934936523
Batch 59/64 loss: -1.7658491134643555
Batch 60/64 loss: -1.8694124221801758
Batch 61/64 loss: -1.9037790298461914
Batch 62/64 loss: -1.7066659927368164
Batch 63/64 loss: -1.6526288986206055
Batch 64/64 loss: -6.061782360076904
Epoch 499  Train loss: -1.9992363069571701  Val loss: -2.189374104398223
Epoch 500
-------------------------------
Batch 1/64 loss: -2.055661201477051
Batch 2/64 loss: -1.8487296104431152
Batch 3/64 loss: -1.8906621932983398
Batch 4/64 loss: -1.9265403747558594
Batch 5/64 loss: -2.104928493499756
Batch 6/64 loss: -1.91033935546875
Batch 7/64 loss: -2.0352354049682617
Batch 8/64 loss: -1.9503107070922852
Batch 9/64 loss: -2.12831974029541
Batch 10/64 loss: -1.9115619659423828
Batch 11/64 loss: -2.108163833618164
Batch 12/64 loss: -1.6745414733886719
Batch 13/64 loss: -2.080805778503418
Batch 14/64 loss: -2.029205322265625
Batch 15/64 loss: -2.098877429962158
Batch 16/64 loss: -1.648946762084961
Batch 17/64 loss: -2.1451563835144043
Batch 18/64 loss: -1.6411199569702148
Batch 19/64 loss: -2.052769184112549
Batch 20/64 loss: -1.5825986862182617
Batch 21/64 loss: -1.7942314147949219
Batch 22/64 loss: -2.163729190826416
Batch 23/64 loss: -2.043272018432617
Batch 24/64 loss: -1.855752944946289
Batch 25/64 loss: -2.1546549797058105
Batch 26/64 loss: -1.9258508682250977
Batch 27/64 loss: -2.2875537872314453
Batch 28/64 loss: -2.174659252166748
Batch 29/64 loss: -1.5833959579467773
Batch 30/64 loss: -1.6280689239501953
Batch 31/64 loss: -2.1114792823791504
Batch 32/64 loss: -2.1806864738464355
Batch 33/64 loss: -1.9734749794006348
Batch 34/64 loss: -1.777608871459961
Batch 35/64 loss: -2.1464099884033203
Batch 36/64 loss: -1.9461116790771484
Batch 37/64 loss: -1.9741735458374023
Batch 38/64 loss: -2.175996780395508
Batch 39/64 loss: -2.022707939147949
Batch 40/64 loss: -1.922468662261963
Batch 41/64 loss: -2.240835666656494
Batch 42/64 loss: -1.8946504592895508
Batch 43/64 loss: -1.925450325012207
Batch 44/64 loss: -1.8854742050170898
Batch 45/64 loss: -1.6569786071777344
Batch 46/64 loss: -1.951392650604248
Batch 47/64 loss: -1.882906436920166
Batch 48/64 loss: -2.1166152954101562
Batch 49/64 loss: -1.945103645324707
Batch 50/64 loss: -1.7511320114135742
Batch 51/64 loss: -1.9745903015136719
Batch 52/64 loss: -1.986435890197754
Batch 53/64 loss: -1.9340019226074219
Batch 54/64 loss: -1.3773078918457031
Batch 55/64 loss: -2.1869969367980957
Batch 56/64 loss: -2.034006118774414
Batch 57/64 loss: -1.598038673400879
Batch 58/64 loss: -1.7655153274536133
Batch 59/64 loss: -1.99774169921875
Batch 60/64 loss: -2.106172561645508
Batch 61/64 loss: -1.3711633682250977
Batch 62/64 loss: -1.8066883087158203
Batch 63/64 loss: -2.163055896759033
Batch 64/64 loss: -5.856210231781006
Epoch 500  Train loss: -1.9860576199550255  Val loss: -2.133770827984892
SLIC undersegmentation error: 0.12412920962199316
SLIC inter-cluster variation: 0.13904419774313004
SLIC number of superpixels: 21483
SLIC superpixels per image: 73.82474226804123
Model loaded
Test metrics:
-2.8898217637104677 0.319485910652921 25.952552610863368 tensor(0.2794, dtype=torch.float64) 0.7486293258476249 3.3227773147945086 22799
Inference time: 0.0030091046467679472 seconds
Relabeled undersegmentation error: 0.11814707903780067
Relabeled inter-cluster variation: 0.07005419375896436
Relabeled mean superpixels count: 260.3264604810997
Original mean superpixels count: 78.34707903780068
Done!
Job id: 488553
Job id: 492260
